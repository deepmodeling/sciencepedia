{"hands_on_practices": [{"introduction": "A central theme in the study of time-delay systems is managing conservatism in stability analysis. This practice provides a direct comparison between a simple, delay-independent stability test and a more refined, delay-dependent test enhanced by an integral inequality. By implementing both, you will gain a concrete understanding of how delay-dependent criteria can successfully certify stability in cases where simpler methods fail, highlighting their practical importance [@problem_id:2747657].", "problem": "Consider the linear time-delay system described by the retarded functional differential equation\n$$\n\\dot{x}(t) = a\\,x(t) + b\\,x(t-h),\n$$\nwith constant delay $$h \\ge 0$$ and real scalars $$a,b \\in \\mathbb{R}$$. You are asked to implement two Lyapunov-based stability certification tests and to demonstrate a case where a delay-independent test fails to detect stability while a delay-dependent test based on a Wirtinger-enhanced Lyapunov-Krasovskii functional (LKF) succeeds.\n\nYour program must implement the following two sufficient conditions:\n\n1) Delay-independent Lyapunov-Krasovskii functional (LKF) test using only a state and integral energy:\n- Consider the functional\n$$\nV(t) = p\\,x(t)^2 + \\int_{t-h}^{t} q\\,x(s)^2\\,ds,\n$$\nwith $$p > 0$$ and $$q > 0$$. Its time-derivative along solutions is\n$$\n\\dot{V}(t) = 2 p\\,x(t)\\,\\dot{x}(t) + q\\,x(t)^2 - q\\,x(t-h)^2.\n$$\nSubstituting $$\\dot{x}(t) = a\\,x(t) + b\\,x(t-h)$$ yields a quadratic form in $$[\\,x(t),\\,x(t-h)\\,]^T$$:\n$$\n\\dot{V}(t) = \n\\begin{bmatrix} x(t) \\\\ x(t-h) \\end{bmatrix}^\\top\n\\underbrace{\\begin{bmatrix}\n2 p a + q & p b \\\\\np b & -q\n\\end{bmatrix}}_{M(p,q)}\n\\begin{bmatrix} x(t) \\\\ x(t-h) \\end{bmatrix}.\n$$\nIf there exist $$p>0,q>0$$ such that $$M(p,q) \\prec 0$$ (negative definite), then the origin is asymptotically stable for all $$h \\ge 0$$. This is a delay-independent test.\n\n2) Wirtinger-enhanced delay-dependent LKF test:\n- Consider the enhanced functional\n$$\nV(t) = p\\,x(t)^2 + \\int_{t-h}^{t} q\\,x(s)^2\\,ds + \\int_{t-h}^{t}\\int_{\\xi}^{t} r\\,\\dot{x}(\\tau)^2\\,d\\tau\\,d\\xi,\n$$\nwith $$p>0, q>0, r>0$$. Its time-derivative satisfies\n$$\n\\dot{V}(t) = 2 p\\,x(t)\\,\\dot{x}(t) + q\\big(x(t)^2 - x(t-h)^2\\big) + r\\,h\\,\\dot{x}(t)^2 - r\\int_{t-h}^{t} \\dot{x}(s)^2\\,ds.\n$$\nUsing the inequality\n$$\n\\int_{t-h}^{t} \\dot{x}(s)^2 ds \\ge \\frac{1}{h}\\big(x(t) - x(t-h)\\big)^2,\n$$\nand substituting $$\\dot{x}(t) = a\\,x(t) + b\\,x(t-h)$$, one obtains an upper bound\n$$\n\\dot{V}(t) \\le \n\\begin{bmatrix} x(t) \\\\ x(t-h) \\end{bmatrix}^\\top\n\\underbrace{\\begin{bmatrix}\n2 p a + q + r h a^2 - \\frac{r}{h} & p b + r h a b + \\frac{r}{h} \\\\\np b + r h a b + \\frac{r}{h} & -q + r h b^2 - \\frac{r}{h}\n\\end{bmatrix}}_{N(p,q,r;h)}\n\\begin{bmatrix} x(t) \\\\ x(t-h) \\end{bmatrix}.\n$$\nIf there exist $$p>0, q>0, r>0$$ such that $$N(p,q,r;h) \\prec 0$$, then the origin is asymptotically stable for that specific delay $$h$$. This is a delay-dependent test strengthened by the derivative term and the integral inequality (a Wirtinger-type bound).\n\nYour task is to:\n- Implement both tests as computational procedures that search over the decision variables to detect a feasible certificate.\n- For each test, you must decide feasibility by checking whether the associated symmetric $$2\\times 2$$ matrix is negative definite, i.e., all eigenvalues are strictly negative. Use a small numerical tolerance so that a matrix is regarded as negative definite only if its largest eigenvalue is below $$-10^{-9}$$.\n\nTest suite:\n- Use the following parameter sets $$\\{(a,b,h)\\}$$:\n    1) $$a=-0.3,\\, b=-0.8,\\, h=0.5$$\n    2) $$a=-0.3,\\, b=-0.8,\\, h=1.6$$\n    3) $$a=-0.3,\\, b=-0.8,\\, h=3.0$$\n    4) $$a=-2.0,\\, b=0.5,\\, h=3.0$$\n- For each case, return a two-integer list $$[d_1,d_2]$$ where:\n    - $$d_1 \\in \\{0,1\\}$$ indicates whether the delay-independent LKF test found a certificate (1 for success, 0 for failure).\n    - $$d_2 \\in \\{0,1\\}$$ indicates whether the Wirtinger-enhanced delay-dependent LKF test found a certificate for the given $$h$$ (1 for success, 0 for failure).\n\nFinal output format:\n- Your program should produce a single line of output containing the four results as a comma-separated list of the four two-integer lists, with no spaces, enclosed in square brackets. For example:\n$$\n[[0,1],[0,1],[0,0],[1,1]]\n$$\nNo physical units are involved. Angles are not used. Percentages are not used.", "solution": "The problem has been subjected to rigorous validation and is confirmed to be valid. It is scientifically grounded in the established principles of control theory, specifically the stability analysis of time-delay systems using Lyapunov-Krasovskii functionals. The mathematical formulations for the time-derivatives of the functionals and the resulting matrix inequalities are correct. The problem is well-posed, providing a clear, objective, and complete set of specifications for which a computational solution can be developed and verified. There are no scientific inaccuracies, ambiguities, or contradictions. We shall proceed to the solution.\n\nThe problem requires the implementation of two distinct stability tests for the linear time-delay system described by the equation:\n$$\n\\dot{x}(t) = a\\,x(t) + b\\,x(t-h)\n$$\nwhere $$a, b \\in \\mathbb{R}$$ are constant coefficients and $$h \\ge 0$$ is the time delay. The objective is to determine, for several parameter sets $$\\{a, b, h\\}$$, whether each stability test can certify the asymptotic stability of the system's origin. A certificate is found if a set of positive decision variables exists that renders a specific test matrix negative definite. A symmetric matrix is considered negative definite if and only if its largest eigenvalue is strictly negative. For computational purposes, we will use the threshold specified, where the largest eigenvalue must be less than $$-10^{-9}$$.\n\nThe first test is a delay-independent condition, meaning if it is satisfied, the system is stable for all non-negative delays $$h \\ge 0$$. The second test is delay-dependent and may certify stability for a specific value of $$h$$ even when the first test fails. This demonstrates the trade-off between the generality of a stability criterion and its conservatism.\n\n### Test 1: Delay-Independent Lyapunov-Krasovskii Functional\n\nThis test utilizes the functional:\n$$\nV(t) = p\\,x(t)^2 + \\int_{t-h}^{t} q\\,x(s)^2\\,ds\n$$\nThe stability condition requires finding positive scalars $$p > 0$$ and $$q > 0$$ such that the matrix $$M(p,q)$$ is negative definite ($$M(p,q) \\prec 0$$), where:\n$$\nM(p,q) = \\begin{bmatrix}\n2 p a + q & p b \\\\\np b & -q\n\\end{bmatrix}\n$$\nThe condition is homogeneous with respect to the decision variables; if ($$p, q$$) is a feasible solution, then so is ($$\\alpha p, \\alpha q$$) for any $$\\alpha > 0$$. This allows us to fix one variable, for instance $$p=1$$, and reduce the search to a one-dimensional problem for a feasible $$q > 0$$. The computational procedure will involve a numerical search over a range of positive values for $$q$$. For each $$q$$, the matrix $$M(1, q)$$ is constructed, and its eigenvalues are computed. If both eigenvalues are found to be less than the required tolerance of $$-10^{-9}$$, a certificate has been found, and the test is successful.\n\n### Test 2: Wirtinger-Enhanced Delay-Dependent LKF\n\nThis test employs a more complex functional that includes an integral term involving the derivative of the state, augmented by the Wirtinger inequality to derive a tighter bound:\n$$\nV(t) = p\\,x(t)^2 + \\int_{t-h}^{t} q\\,x(s)^2\\,ds + \\int_{t-h}^{t}\\int_{\\xi}^{t} r\\,\\dot{x}(\\tau)^2\\,d\\tau\\,d\\xi\n$$\nThe stability condition here is to find positive scalars $$p > 0, q > 0, r > 0$$ for a *specific* delay $$h$$ such that the matrix $$N(p,q,r;h) \\prec 0$$, where:\n$$\nN(p,q,r;h) = \\begin{bmatrix}\n2 p a + q + r h a^2 - \\frac{r}{h} & p b + r h a b + \\frac{r}{h} \\\\\np b + r h a b + \\frac{r}{h} & -q + r h b^2 - \\frac{r}{h}\n\\end{bmatrix}\n$$\nSimilar to the first test, this is a feasibility problem that is homogeneous in $$p, q, r$$. We can fix $$p=1$$ and search for a pair of positive scalars ($$q, r$$). The implementation will perform a two-dimensional grid search over a predefined range of positive values for $$q$$ and $$r$$. For each pair ($$q, r$$), the matrix $$N(1,q,r;h)$$ is formed, its eigenvalues are calculated, and the negative definiteness condition is checked. If a feasible pair is found, the test is successful for the given value of $$h$$.\n\n### Computational Search Strategy\n\nFor both tests, the search for decision variables is implemented as follows:\n- **Test 1:** A one-dimensional linear search for $$q$$ is performed, with $$p=1$$ fixed. The search space for $$q$$ is a grid of points in a sufficiently large interval, for instance, `[1e-6, 100]`.\n- **Test 2:** A two-dimensional grid search for ($$q, r$$) is performed, with $$p=1$$ fixed. The search space is a Cartesian product of two linear grids for $$q$$ and $$r$$, for example, `[1e-4, 50] x [1e-4, 50]`.\n\nFor each point in the search space, the corresponding matrix ($$M$$ or $$N$$) is constructed, and its eigenvalues are computed using a robust numerical method for symmetric matrices. If the largest eigenvalue is below the tolerance $$-10^{-9}$$, the search terminates successfully. If the entire search space is exhausted without finding a certificate, the test is considered to have failed. This computational approach directly addresses the feasibility problem posed by the stability conditions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef check_neg_def(matrix: np.ndarray) -> bool:\n    \"\"\"\n    Checks if a symmetric 2x2 matrix is negative definite.\n    A matrix is negative definite if all its eigenvalues are strictly negative.\n    The check is performed against a specified numerical tolerance.\n    \"\"\"\n    # eigvalsh is efficient for symmetric matrices\n    eigenvalues = np.linalg.eigvalsh(matrix)\n    return np.max(eigenvalues) < -1e-9\n\ndef run_test_1(a: float, b: float) -> int:\n    \"\"\"\n    Implements the delay-independent LKF test by searching for a feasible certificate.\n    It fixes p=1 and performs a 1D search for q > 0.\n\n    Args:\n        a (float): System parameter 'a'.\n        b (float): System parameter 'b'.\n\n    Returns:\n        int: 1 if stable (certificate found), 0 otherwise.\n    \"\"\"\n    p = 1.0  # Fix p=1 due to homogeneity\n    \n    # Search for a feasible q > 0 on a linear grid\n    q_vals = np.linspace(1e-6, 100.0, 2000)\n    \n    for q in q_vals:\n        M = np.array([\n            [2 * p * a + q, p * b],\n            [p * b, -q]\n        ])\n        \n        if check_neg_def(M):\n            return 1\n            \n    return 0\n\ndef run_test_2(a: float, b: float, h: float) -> int:\n    \"\"\"\n    Implements the Wirtinger-enhanced delay-dependent LKF test for a given h.\n    It fixes p=1 and performs a 2D grid search for q > 0 and r > 0.\n\n    Args:\n        a (float): System parameter 'a'.\n        b (float): System parameter 'b'.\n        h (float): System delay 'h'.\n\n    Returns:\n        int: 1 if stable (certificate found), 0 otherwise.\n    \"\"\"\n    # h must be positive for this test\n    if h <= 0:\n        return 0\n\n    p = 1.0  # Fix p=1\n    \n    # Define a 2D grid for the search\n    q_vals = np.linspace(1e-4, 50.0, 150)\n    r_vals = np.linspace(1e-4, 50.0, 150)\n    \n    # Pre-calculate h-dependent terms for efficiency\n    ha2 = h * a**2\n    hb2 = h * b**2\n    hab = h * a * b\n    r_over_h = 1.0 / h\n\n    for q in q_vals:\n        for r in r_vals:\n            # Construct the N(p,q,r;h) matrix with p=1\n            r_term_11 = r * (ha2 - r_over_h)\n            r_term_12 = r * (hab + r_over_h)\n            r_term_22 = r * (hb2 - r_over_h)\n            \n            N11 = 2 * a + q + r_term_11\n            N12 = b + r_term_12\n            N22 = -q + r_term_22\n            \n            N = np.array([\n                [N11, N12],\n                [N12, N22]\n            ])\n            \n            if check_neg_def(N):\n                return 1\n                \n    return 0\n\ndef solve():\n    \"\"\"\n    Main function to run the stability tests on the provided test suite\n    and print the results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (-0.3, -0.8, 0.5),\n        (-0.3, -0.8, 1.6),\n        (-0.3, -0.8, 3.0),\n        (-2.0, 0.5, 3.0)\n    ]\n\n    results = []\n    for a, b, h in test_cases:\n        d1 = run_test_1(a, b)\n        d2 = run_test_2(a, b, h)\n        results.append(f\"[{d1},{d2}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2747657"}, {"introduction": "To reduce the conservatism of delay-dependent conditions, we often employ integral inequalities to bound terms in the derivative of the Lyapunov-Krasovskii functional ($LKF$). This exercise focuses on a key step in this process: numerically evaluating the tightness of different bounding techniques. You will compare the classic Jensen's inequality with higher-order bounds derived from Legendre polynomial expansions, gaining a quantitative feel for the trade-off between computational complexity and analytical precision [@problem_id:2747627].", "problem": "Consider a scalar time-delay functional term that appears in Lyapunov–Krasovskii functionals for time-delay systems: the quadratic integral $\\int_{0}^{h} x(s)^{2} \\, ds$ scaled by a positive scalar $Q \\gt 0$ (standing for a symmetric positive definite matrix reduced to the scalar case). For a given smooth scalar function $x(s)$ on the interval $[0,h]$, define the exact value\n$$\nI(Q,h;x) \\;=\\; Q \\int_{0}^{h} x(s)^{2} \\, ds.\n$$\nA common task in stability analysis is to lower bound $I(Q,h;x)$ using integral inequalities. Three families of such bounds are:\n- Jensen’s inequality bound, which uses only the mean value of $x(s)$ over $[0,h]$.\n- A Wirtinger-based bound that enriches the mean by the first shifted Legendre mode.\n- A Bessel–Legendre bound that truncates the orthogonal expansion of $x(s)$ on the shifted Legendre polynomial basis to a prescribed order.\n\nYour task is to compute, for each test case specified below, the following three lower bounds and report their tightness with respect to $I(Q,h;x)$:\n1. Jensen bound $L_{J}$ based on the mean of $x(s)$.\n2. Wirtinger bound $L_{W}$ based on the first two shifted Legendre modes (degree $0$ and degree $1$).\n3. Bessel–Legendre bound $L_{BL}$ based on the first three shifted Legendre modes (degree $0$, $1$, and $2$).\n\nAll angles in any trigonometric functions are in radians.\n\nFundamental base to be used:\n- Cauchy–Schwarz inequality and Jensen’s inequality for integrals.\n- Orthogonality of the shifted Legendre polynomials on $[0,1]$, namely if $P_{k}(\\tau)$ is the Legendre polynomial of degree $k$ on $[-1,1]$, then $P_{k}^{\\text{sh}}(\\tau) = P_{k}(2\\tau - 1)$ on $[0,1]$ satisfies\n$$\n\\int_{0}^{1} P_{k}^{\\text{sh}}(\\tau)\\, P_{\\ell}^{\\text{sh}}(\\tau)\\, d\\tau \\;=\\; \\begin{cases}\n\\frac{1}{2k+1}, & k = \\ell, \\\\\n0, & k \\neq \\ell.\n\\end{cases}\n$$\n- Bessel’s inequality for orthonormal expansions.\n\nDefinitions to implement:\n- Define $\\tau = s/h$ so that $s \\in [0,h]$ maps to $\\tau \\in [0,1]$ and $ds = h\\, d\\tau$.\n- Let $P_{k}^{\\text{sh}}(\\tau)$ be the degree-$k$ shifted Legendre polynomial on $[0,1]$. Using the orthonormal family $\\varphi_{k}(\\tau) = \\sqrt{2k+1}\\, P_{k}^{\\text{sh}}(\\tau)$ on $[0,1]$, define the coefficients\n$$\nc_{k} \\;=\\; \\int_{0}^{1} x(h \\tau)\\, \\varphi_{k}(\\tau)\\, d\\tau \\;=\\; \\frac{\\sqrt{2k+1}}{h}\\, \\int_{0}^{h} P_{k}^{\\text{sh}}\\!\\left(\\frac{s}{h}\\right) x(s)\\, ds.\n$$\n- The Bessel–Legendre lower bound of order $N$ is\n$$\nL_{N}(Q,h;x) \\;=\\; Q h \\sum_{k=0}^{N} c_{k}^{2} \\;=\\; \\frac{Q}{h} \\sum_{k=0}^{N} (2k+1)\\, \\left(\\int_{0}^{h} P_{k}^{\\text{sh}}\\!\\left(\\frac{s}{h}\\right) x(s)\\, ds\\right)^{2}.\n$$\n- The Jensen bound corresponds to $N = 0$, that is $L_{J} = L_{0}(Q,h;x)$.\n- The Wirtinger-based bound corresponds here to $N = 1$, that is $L_{W} = L_{1}(Q,h;x)$.\n- The Bessel–Legendre bound to use is the second-order truncation $N = 2$, that is $L_{BL} = L_{2}(Q,h;x)$.\n\nFor each test case, compute the exact integral $I(Q,h;x)$ numerically to high accuracy, compute the three lower bounds $L_{J}$, $L_{W}$, and $L_{BL}$ via the above formulas, and report the tightness ratios\n$$\n\\rho_{J} \\;=\\; \\frac{L_{J}}{I(Q,h;x)}, \\qquad\n\\rho_{W} \\;=\\; \\frac{L_{W}}{I(Q,h;x)}, \\qquad\n\\rho_{BL} \\;=\\; \\frac{L_{BL}}{I(Q,h;x)}.\n$$\n\nTest suite:\n- Case 1 (general trigonometric–affine on a unit interval): $Q = 2.0$, $h = 1.0$, and $x(s) = \\sin(2\\pi s) + 0.3\\, s - 0.1$ for $s \\in [0,1]$.\n- Case 2 (small interval behaviour): $Q = 5.0$, $h = 0.05$, and $x(s) = \\sin(2\\pi s) + 0.3\\, s - 0.1$ for $s \\in [0,0.05]$.\n- Case 3 (longer interval): $Q = 1.5$, $h = 2.0$, and $x(s) = \\sin(2\\pi s) + 0.3\\, s - 0.1$ for $s \\in [0,2]$.\n- Case 4 (polynomial in shifted Legendre basis up to degree $2$; bound becomes exact at $N=2$): $Q = 1.0$, $h = 3.0$, and\n$$\nx(s) \\;=\\; a \\;+\\; b\\,\\Big(2\\frac{s}{h} - 1\\Big) \\;+\\; c\\,\\Big(6\\Big(\\frac{s}{h}\\Big)^{2} - 6\\frac{s}{h} + 1\\Big),\n$$\nwith $a = 0.7$, $b = -1.2$, $c = 0.9$, for $s \\in [0,3]$.\n- Case 5 (highly oscillatory): $Q = 0.7$, $h = 1.0$, and $x(s) = \\sin(10\\pi s) + 0.2\\, \\cos(3\\pi s) - 0.05$ for $s \\in [0,1]$.\n\nRequired final output format:\n- For each case, compute the triple $(\\rho_{J}, \\rho_{W}, \\rho_{BL})$ and round each entry to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of triples, enclosed in square brackets, with no spaces. For example, a valid output with two cases would look like: \"[[0.123456,0.234567,0.345678],[0.987654,0.876543,0.765432]]\".", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the field of control theory and applied mathematics, specifically concerning the stability analysis of time-delay systems using Lyapunov-Krasovskii functionals. The problem is well-posed, objective, and contains all necessary information and definitions to proceed to a unique solution. The provided tasks are computationally feasible and based on established mathematical principles such as integral inequalities and orthogonal polynomial expansions.\n\nThe core of the problem is to compare the exact value of the integral term $I(Q,h;x) = Q \\int_{0}^{h} x(s)^{2} \\, ds$ with several of its lower bounds derived from a spectral expansion of the function $x(s)$. The analysis is performed in the Hilbert space of square-integrable functions, and the bounds are a direct consequence of Bessel's inequality.\n\nLet us begin by performing a change of variables to map the integration interval from $[0,h]$ to $[0,1]$. Let $\\tau = s/h$, which implies $s = h\\tau$ and $ds = h\\, d\\tau$. The integral $I(Q,h;x)$ can be rewritten as:\n$$\nI(Q,h;x) \\;=\\; Q \\int_{0}^{1} x(h\\tau)^{2} \\, (h\\, d\\tau) \\;=\\; Qh \\int_{0}^{1} [x(h\\tau)]^{2} \\, d\\tau.\n$$\nLet $y(\\tau) = x(h\\tau)$. The integral is $I = Qh \\int_{0}^{1} y(\\tau)^2 d\\tau = Qh \\|y\\|_{L^2[0,1]}^2$, where $\\| \\cdot \\|_{L^2[0,1]}$ is the standard norm on the space of square-integrable functions on the interval $[0,1]$.\n\nThe problem utilizes the basis of shifted Legendre polynomials, $P_{k}^{\\text{sh}}(\\tau)$, which are orthogonal on $[0,1]$. Their orthogonality relation is given by:\n$$\n\\int_{0}^{1} P_{k}^{\\text{sh}}(\\tau)\\, P_{\\ell}^{\\text{sh}}(\\tau)\\, d\\tau \\;=\\; \\frac{\\delta_{k\\ell}}{2k+1},\n$$\nwhere $\\delta_{k\\ell}$ is the Kronecker delta. From this, we can construct an orthonormal basis $\\{\\varphi_k(\\tau)\\}_{k=0}^{\\infty}$ for $L^2[0,1]$:\n$$\n\\varphi_{k}(\\tau) \\;=\\; \\sqrt{2k+1}\\, P_{k}^{\\text{sh}}(\\tau).\n$$\nAny function $y(\\tau) \\in L^2[0,1]$ can be expanded in this basis as $y(\\tau) = \\sum_{k=0}^{\\infty} c_k \\varphi_k(\\tau)$, where the coefficients $c_k$ are the projections of $y$ onto the basis functions:\n$$\nc_{k} \\;=\\; \\langle y, \\varphi_k \\rangle \\;=\\; \\int_{0}^{1} y(\\tau)\\, \\varphi_{k}(\\tau)\\, d\\tau.\n$$\nBy Parseval's identity, the squared norm of the function is the sum of the squares of its Fourier-Legendre coefficients: $\\|y\\|^2 = \\sum_{k=0}^{\\infty} c_k^2$. Therefore, the exact integral is:\n$$\nI(Q,h;x) \\;=\\; Qh \\sum_{k=0}^{\\infty} c_k^2.\n$$\nBessel's inequality states that for any finite truncation order $N$, the partial sum of squared coefficients provides a lower bound for the total squared norm:\n$$\n\\sum_{k=0}^{N} c_k^2 \\;\\le\\; \\|y\\|^2.\n$$\nMultiplying by $Qh$, we obtain the lower bound on the integral $I$:\n$$\nL_N(Q,h;x) \\;=\\; Qh \\sum_{k=0}^{N} c_k^2 \\;\\le\\; I(Q,h;x).\n$$\nThis is precisely the formula for the Bessel-Legendre lower bound given in the problem statement. The task is to compute this bound for truncation orders $N=0$, $N=1$, and $N=2$.\n\nTo implement the computation, we express the coefficients $c_k$ in terms of integrals over the original interval $[0,h]$:\n$$\nc_k = \\int_{0}^{1} x(h\\tau) \\sqrt{2k+1} P_k^{\\text{sh}}(\\tau) d\\tau = \\frac{\\sqrt{2k+1}}{h} \\int_{0}^{h} x(s) P_k^{\\text{sh}}(s/h) ds.\n$$\nSubstituting this into the formula for $L_N$, we get:\n$$\nL_N(Q,h;x) = Qh \\sum_{k=0}^{N} \\left(\\frac{2k+1}{h^2}\\right) \\left(\\int_{0}^{h} x(s) P_k^{\\text{sh}}(s/h) ds\\right)^2 = \\frac{Q}{h} \\sum_{k=0}^{N} (2k+1) \\left(\\int_{0}^{h} x(s) P_k^{\\text{sh}}(s/h) ds\\right)^2,\n$$\nwhich matches the provided definition.\n\nWe need the first three shifted Legendre polynomials, where $\\tau = s/h$:\n\\begin{itemize}\n    \\item $P_{0}^{\\text{sh}}(\\tau) = 1$\n    \\item $P_{1}^{\\text{sh}}(\\tau) = 2\\tau - 1 = 2\\frac{s}{h} - 1$\n    \\item $P_{2}^{\\text{sh}}(\\tau) = 6\\tau^2 - 6\\tau + 1 = 6\\left(\\frac{s}{h}\\right)^2 - 6\\frac{s}{h} + 1$\n\\end{itemize}\n\nLet us define the moments $m_k = \\int_{0}^{h} x(s) P_{k}^{\\text{sh}}(s/h) ds$. The bounds can be written as:\n\\begin{enumerate}\n    \\item Jensen bound $L_J = L_0$:\n    $$L_{J} = \\frac{Q}{h} (2(0)+1) m_0^2 = \\frac{Q}{h} \\left(\\int_0^h x(s) ds\\right)^2.$$\n    \\item Wirtinger-based bound $L_W = L_1$:\n    $$L_{W} = \\frac{Q}{h} \\left(m_0^2 + 3m_1^2\\right) = L_J + \\frac{3Q}{h} \\left(\\int_0^h \\left(2\\frac{s}{h}-1\\right)x(s) ds\\right)^2.$$\n    \\item Bessel-Legendre bound $L_{BL} = L_2$:\n    $$L_{BL} = \\frac{Q}{h} \\left(m_0^2 + 3m_1^2 + 5m_2^2\\right) = L_W + \\frac{5Q}{h} \\left(\\int_0^h \\left(6\\left(\\frac{s}{h}\\right)^2 - 6\\frac{s}{h} + 1\\right)x(s) ds\\right)^2.$$\n\\end{enumerate}\nFrom these expressions, it is clear that $L_J \\le L_W \\le L_{BL} \\le I$. The tightness of these bounds, represented by the ratios $\\rho = L/I$, is expected to improve as the order $N$ increases.\n\nFor each test case, we will compute the required definite integrals numerically using high-precision quadrature, specifically the `scipy.integrate.quad` function. Then, we use these values to assemble $I$, $L_J$, $L_W$, and $L_{BL}$, and finally calculate the tightness ratios $\\rho_J, \\rho_W, \\rho_{BL}$. For the special Case 4, where $x(s)$ is a linear combination of the first three basis polynomials, we expect the bound $L_{BL}$ to be exact, yielding $\\rho_{BL}=1.0$, as the expansion contains no higher-order terms.", "answer": "```python\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Computes Jensen, Wirtinger-based, and Bessel-Legendre lower bounds for\n    a quadratic integral term and reports their tightness.\n    \"\"\"\n\n    # Define test cases: (Q, h, function x(s), extra params for x(s))\n    test_cases = [\n        # Case 1\n        (2.0, 1.0, \n         lambda s, h, params: np.sin(2 * np.pi * s) + 0.3 * s - 0.1, \n         None),\n        # Case 2\n        (5.0, 0.05, \n         lambda s, h, params: np.sin(2 * np.pi * s) + 0.3 * s - 0.1, \n         None),\n        # Case 3\n        (1.5, 2.0, \n         lambda s, h, params: np.sin(2 * np.pi * s) + 0.3 * s - 0.1, \n         None),\n        # Case 4\n        (1.0, 3.0, \n         lambda s, h, params: params['a'] + params['b'] * (2 * s / h - 1) + \n                              params['c'] * (6 * (s / h)**2 - 6 * s / h + 1), \n         {'a': 0.7, 'b': -1.2, 'c': 0.9}),\n        # Case 5\n        (0.7, 1.0, \n         lambda s, h, params: np.sin(10 * np.pi * s) + 0.2 * np.cos(3 * np.pi * s) - 0.05, \n         None),\n    ]\n\n    # Shifted Legendre Polynomials as functions of tau = s/h\n    P0_sh = lambda tau: 1.0\n    P1_sh = lambda tau: 2.0 * tau - 1.0\n    P2_sh = lambda tau: 6.0 * tau**2 - 6.0 * tau + 1.0\n\n    results = []\n    \n    for case in test_cases:\n        Q, h, x_func, params = case\n\n        # Integrand for the exact value I\n        integrand_I = lambda s: (x_func(s, h, params))**2\n        \n        # Integrands for the moments m_k\n        integrand_m0 = lambda s: P0_sh(s / h) * x_func(s, h, params)\n        integrand_m1 = lambda s: P1_sh(s / h) * x_func(s, h, params)\n        integrand_m2 = lambda s: P2_sh(s / h) * x_func(s, h, params)\n\n        # Numerical integration using scipy.integrate.quad for high accuracy\n        I_val = Q * integrate.quad(integrand_I, 0, h)[0]\n        m0 = integrate.quad(integrand_m0, 0, h)[0]\n        m1 = integrate.quad(integrand_m1, 0, h)[0]\n        m2 = integrate.quad(integrand_m2, 0, h)[0]\n\n        # Calculate the lower bounds\n        L_J = (Q / h) * (m0**2)\n        L_W = L_J + (Q / h) * 3 * (m1**2)\n        L_BL = L_W + (Q / h) * 5 * (m2**2)\n        \n        # Protective check for I_val being close to zero\n        if np.isclose(I_val, 0):\n            # If I=0, then x(s)=0 almost everywhere. All bounds must be 0.\n            # In this scenario, define tightness as 1.0.\n            rho_J, rho_W, rho_BL = 1.0, 1.0, 1.0\n        else:\n            # Calculate the tightness ratios\n            rho_J = L_J / I_val\n            rho_W = L_W / I_val\n            rho_BL = L_BL / I_val\n\n        results.append((rho_J, rho_W, rho_BL))\n\n    # Format the output string as specified\n    formatted_results = []\n    for r_tuple in results:\n        # Round to 6 decimal places and format\n        formatted_tuple = f\"[{r_tuple[0]:.6f},{r_tuple[1]:.6f},{r_tuple[2]:.6f}]\"\n        formatted_results.append(formatted_tuple)\n\n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2747627"}, {"introduction": "This final practice synthesizes the concepts of Lyapunov-Krasovskii functionals and delay-dependent analysis into a complete computational workflow. Starting from a comprehensive LKF, you will derive the corresponding Linear Matrix Inequality ($LMI$) condition for stability. You will then implement a numerical algorithm to solve a common engineering problem: estimating the maximum stable time delay, $h_{\\max}$, thereby translating theoretical stability conditions into a practical performance metric [@problem_id:2747632].", "problem": "Consider the linear time-delay system defined by the retarded functional differential equation $ \\dot{x}(t) = A x(t) + A_d x(t - h) $, where $ A \\in \\mathbb{R}^{n \\times n} $, $ A_d \\in \\mathbb{R}^{n \\times n} $, and $ h \\ge 0 $ is a constant time delay. Starting from the fundamental definitions of a Lyapunov-Krasovskii functional (LKF) and basic calculus, use a quadratic Lyapunov-Krasovskii functional of the form $ V(x_t) = x(t)^{\\top} P x(t) + \\int_{t-h}^{t} x(s)^{\\top} Q x(s) \\, ds + \\int_{t-h}^{t} \\int_{s}^{t} \\dot{x}(\\tau)^{\\top} R \\dot{x}(\\tau) \\, d\\tau \\, ds $, where $ P \\in \\mathbb{S}_{++}^{n} $, $ Q \\in \\mathbb{S}_{+}^{n} $, and $ R \\in \\mathbb{S}_{+}^{n} $ are decision variables. By combining the product rule, the fundamental theorem of calculus, and Jensen’s inequality applied to $ \\int_{t-h}^{t} \\dot{x}(\\tau)^{\\top} R \\dot{x}(\\tau) \\, d\\tau $, derive a delay-dependent linear matrix inequality (LMI) condition on $ P $, $ Q $, $ R $ and $ h $ that guarantees $ \\dot{V}(x_t) \\le - \\epsilon \\| x(t) \\|^2 $ for some $ \\epsilon > 0 $, hence asymptotic stability of the zero solution.\n\nYou must then implement a numerical procedure to estimate the maximum admissible constant delay $ h_{\\max} $ that ensures stability using the following constraints:\n- Restrict to the special case $ n = 2 $ with $ A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix} $ and $ A_d $ as specified in the test suite.\n- Restrict the decision matrices to be scalar multiples of the identity: $ P = p I_2 $, $ Q = q I_2 $, $ R = r I_2 $ with $ p > 0 $, $ q \\ge 0 $, $ r > 0 $.\n- For a fixed $ h $, the LMI in variables $ p $, $ q $, $ r $ must be checked by testing whether the associated symmetric block matrix is negative definite. Feasibility is certified if there exist $ p $, $ q $, $ r $ in a finite search set for which the condition holds.\n- Estimate $ h_{\\max} $ via bisection over $ h \\in [0, H_{\\text{search}}] $ for a given finite $ H_{\\text{search}} $, using the feasibility check above as the oracle. If the system is feasible for all $ h \\in [0, H_{\\text{search}}] $, report $ h_{\\max} = H_{\\text{search}} $ for that test case.\n\nYou must implement the numerical search as follows:\n- For each feasibility check at a given $ h $, search over a finite grid $ \\mathcal{G}_p \\times \\mathcal{G}_q \\times \\mathcal{G}_r $ with $ \\mathcal{G}_p = \\{ 0.1, 0.5, 1, 2, 5, 10 \\} $, $ \\mathcal{G}_q = \\{ 0, 0.5, 1, 2, 5, 10 \\} $, and $ \\mathcal{G}_r = \\{ 0.1, 0.5, 1, 2, 5, 10 \\} $. Declare feasibility if any triple $ (p, q, r) $ in this grid yields a negative definite LMI matrix.\n- Use bisection with at least $ 25 $ iterations to estimate $ h_{\\max} $, starting from a small strictly positive lower bound and a finite upper bound $ H_{\\text{search}} = 5 $. If the feasibility check succeeds at $ h = H_{\\text{search}} $, then return $ h_{\\max} = H_{\\text{search}} $. If feasibility fails even at extremely small positive $ h $, return $ h_{\\max} = 0 $.\n\nTest Suite:\n- Case 1 (baseline): $ A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix} $, $ A_d = \\begin{bmatrix} 0 & 0 \\\\ 0 & -1 \\end{bmatrix} $.\n- Case 2 (no delay effect): $ A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix} $, $ A_d = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix} $.\n- Case 3 (moderate delay effect): $ A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix} $, $ A_d = 2 \\cdot \\begin{bmatrix} 0 & 0 \\\\ 0 & -1 \\end{bmatrix} $.\n- Case 4 (strong delay effect): $ A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix} $, $ A_d = 4 \\cdot \\begin{bmatrix} 0 & 0 \\\\ 0 & -1 \\end{bmatrix} $.\n\nOutput requirements:\n- Report the estimated $ h_{\\max} $ for each test case in seconds, rounded to four decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[h1,h2,h3,h4]\"), where each $ h_i $ corresponds to one test case in the order listed above.", "solution": "We consider the linear time-delay system $ \\dot{x}(t) = A x(t) + A_d x(t - h) $ with constant delay $ h \\ge 0 $. We seek a delay-dependent stability condition using a Lyapunov-Krasovskii functional (LKF). We begin from core principles: the definition of the derivative, the product rule, the fundamental theorem of calculus, and Jensen’s inequality.\n\nDefine the quadratic LKF\n$$\nV(x_t) = V_1 + V_2 + V_3,\n$$\nwith\n$$\nV_1 = x(t)^{\\top} P x(t), \\quad V_2 = \\int_{t-h}^{t} x(s)^{\\top} Q x(s) \\, ds, \\quad V_3 = \\int_{t-h}^{t} \\int_{s}^{t} \\dot{x}(\\tau)^{\\top} R \\dot{x}(\\tau) \\, d\\tau \\, ds,\n$$\nwhere $ P \\in \\mathbb{S}_{++}^{n} $, $ Q \\in \\mathbb{S}_{+}^{n} $, and $ R \\in \\mathbb{S}_{+}^{n} $. We compute derivatives term-by-term using the fundamental theorem of calculus and standard differentiation rules.\n\n1) For $ V_1 $, using the product rule and symmetry of $ P $,\n$$\n\\dot{V}_1 = \\dot{x}(t)^{\\top} P x(t) + x(t)^{\\top} P \\dot{x}(t) = 2 x(t)^{\\top} P \\dot{x}(t) = x(t)^{\\top} (A^{\\top} P + P A) x(t) + 2 x(t)^{\\top} P A_d x(t - h).\n$$\n\n2) For $ V_2 $, by the fundamental theorem of calculus,\n$$\n\\dot{V}_2 = x(t)^{\\top} Q x(t) - x(t - h)^{\\top} Q x(t - h).\n$$\n\n3) For $ V_3 $, observe that\n$$\nV_3 = \\int_{t-h}^{t} (t - s) \\dot{x}(s)^{\\top} R \\dot{x}(s) \\, ds.\n$$\nDifferentiating yields\n$$\n\\dot{V}_3 = h \\, \\dot{x}(t)^{\\top} R \\dot{x}(t) - \\int_{t-h}^{t} \\dot{x}(s)^{\\top} R \\dot{x}(s) \\, ds.\n$$\nApplying Jensen’s inequality to the convex quadratic form with $ \\dot{x} $ over the interval of length $ h $ gives\n$$\n\\int_{t-h}^{t} \\dot{x}(s)^{\\top} R \\dot{x}(s) \\, ds \\ge \\frac{1}{h} \\left( \\int_{t-h}^{t} \\dot{x}(s) \\, ds \\right)^{\\top} R \\left( \\int_{t-h}^{t} \\dot{x}(s) \\, ds \\right).\n$$\nNoting that $ \\int_{t-h}^{t} \\dot{x}(s) \\, ds = x(t) - x(t - h) $, we have the bound\n$$\n\\dot{V}_3 \\le h \\, \\dot{x}(t)^{\\top} R \\dot{x}(t) - \\frac{1}{h} \\left( x(t) - x(t - h) \\right)^{\\top} R \\left( x(t) - x(t - h) \\right).\n$$\n\nCombining $ \\dot{V}_1 $, $ \\dot{V}_2 $, and the bound on $ \\dot{V}_3 $, and substituting $ \\dot{x}(t) = A x(t) + A_d x(t-h) $, we can express the total derivative upper bound as a quadratic form in the stacked vector $ \\xi = \\begin{bmatrix} x(t) \\\\ x(t-h) \\end{bmatrix} $:\n$$\n\\dot{V}(x_t) \\le \\xi^{\\top} \\mathcal{M}(h) \\, \\xi,\n$$\nwith the block matrix\n$$\n\\mathcal{M}(h) = \\begin{bmatrix}\nM_{11} & M_{12} \\\\\nM_{12}^{\\top} & M_{22}\n\\end{bmatrix},\n$$\nwhere\n$$\n\\begin{aligned}\nM_{11} &= A^{\\top} P + P A + Q + h \\, A^{\\top} R A - \\frac{1}{h} R, \\\\\nM_{12} &= P A_d + h \\, A^{\\top} R A_d + \\frac{1}{h} R, \\\\\nM_{22} &= - Q + h \\, A_d^{\\top} R A_d - \\frac{1}{h} R.\n\\end{aligned}\n$$\nA sufficient condition for asymptotic stability is $ \\mathcal{M}(h) \\prec 0 $ for some $ P \\in \\mathbb{S}_{++}^{n} $, $ Q \\in \\mathbb{S}_{+}^{n} $, and $ R \\in \\mathbb{S}_{+}^{n} $, because this implies $ \\dot{V}(x_t) \\le -\\epsilon \\| x(t) \\|^2 $ for some $ \\epsilon > 0 $ by the S-procedure and standard compactness arguments. For a fixed $ h $, the condition $ \\mathcal{M}(h) \\prec 0 $ is a linear matrix inequality (LMI) in the decision matrices $ P $, $ Q $, and $ R $.\n\nTo make the feasibility check computationally simple and fully implementable without a dedicated semidefinite programming solver, we restrict to scalar multiples of the identity in the $ n = 2 $ case, namely $ P = p I_2 $, $ Q = q I_2 $, $ R = r I_2 $ with $ p > 0 $, $ q \\ge 0 $, $ r > 0 $. Under this restriction, $ M_{11} $, $ M_{12} $, and $ M_{22} $ become explicit functions of $ p $, $ q $, $ r $, and $ h $, and checking $ \\mathcal{M}(h) \\prec 0 $ reduces to verifying that all eigenvalues of the $ 4 \\times 4 $ symmetric matrix $ \\mathcal{M}(h) $ are strictly negative.\n\nAlgorithmic design:\n- For each fixed $ h $, perform a finite grid search over $ (p, q, r) \\in \\mathcal{G}_p \\times \\mathcal{G}_q \\times \\mathcal{G}_r $ with $ \\mathcal{G}_p = \\{ 0.1, 0.5, 1, 2, 5, 10 \\} $, $ \\mathcal{G}_q = \\{ 0, 0.5, 1, 2, 5, 10 \\} $, and $ \\mathcal{G}_r = \\{ 0.1, 0.5, 1, 2, 5, 10 \\} $. For each triple, assemble $ \\mathcal{M}(h) $ and test negative definiteness via its eigenvalues. If any triple yields a negative definite matrix, declare feasibility at that $ h $.\n- Use bisection over $ h \\in [h_{\\text{low}}, H_{\\text{search}}] $ with $ h_{\\text{low}} $ a small strictly positive number (e.g., $ 10^{-6} $) to find the supremum of feasible delays. Initialize by checking feasibility at $ h = H_{\\text{search}} = 5 $. If feasible, report $ h_{\\max} = H_{\\text{search}} $. Otherwise, ensure feasibility at a small $ h_{\\text{low}} $; if not feasible even there, report $ h_{\\max} = 0 $. If feasible at $ h_{\\text{low}} $ and infeasible at $ H_{\\text{search}} $, perform at least $ 25 $ bisection iterations to approximate $ h_{\\max} $ from below by the largest feasible $ h $ encountered.\n- The test suite comprises four cases with the same $ A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix} $ and varying $ A_d $ as listed. These cases cover a baseline, a boundary scenario with no delay coupling, and increasing delay feedback strength.\n\nNumerical output:\n- For each test case, return the estimated $ h_{\\max} $ in seconds, rounded to four decimal places.\n- Output a single line with the results in the format \"[h1,h2,h3,h4]\".\n\nThis approach is conservative due to the diagonal scalar restriction on $ P $, $ Q $, and $ R $, and due to the Jensen inequality relaxation; thus, the estimated $ h_{\\max} $ is a lower bound on the true maximum admissible delay. Nevertheless, it is systematically computable and grounded in the derived LMI condition, satisfying the requirement to use a Lyapunov-Krasovskii functional and first principles.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef assemble_M(A, Ad, h, p, q, r):\n    \"\"\"\n    Assemble the 4x4 symmetric LMI matrix M(h) using:\n    P = p * I, Q = q * I, R = r * I for 2x2 A, Ad.\n    \"\"\"\n    I = np.eye(2)\n    P = p * I\n    Q = q * I\n    R = r * I\n\n    AT = A.T\n    AdT = Ad.T\n\n    # Blocks according to the derived expressions\n    M11 = AT @ P + P @ A + Q + h * (AT @ R @ A) - (1.0 / h) * R\n    M12 = P @ Ad + h * (AT @ R @ Ad) + (1.0 / h) * R\n    M21 = M12.T\n    M22 = -Q + h * (AdT @ R @ Ad) - (1.0 / h) * R\n\n    # Form the full 4x4 block matrix\n    upper = np.hstack((M11, M12))\n    lower = np.hstack((M21, M22))\n    M = np.vstack((upper, lower))\n    # Ensure symmetry numerically\n    M = 0.5 * (M + M.T)\n    return M\n\ndef is_negative_definite(M, tol=-1e-9):\n    \"\"\"\n    Check if M is strictly negative definite by verifying eigenvalues < tol.\n    \"\"\"\n    # Use symmetric eigenvalue solver\n    evals = np.linalg.eigvalsh(M)\n    return np.max(evals) < tol\n\ndef feasible_for_h(A, Ad, h, grid_p, grid_q, grid_r):\n    \"\"\"\n    Feasibility oracle: returns True if there exist p, q, r in the provided grids\n    such that the LMI matrix M(h) is negative definite.\n    \"\"\"\n    for p in grid_p:\n        for q in grid_q:\n            for r in grid_r:\n                # p > 0, q >= 0, r > 0 ensured by grids\n                M = assemble_M(A, Ad, h, p, q, r)\n                if is_negative_definite(M):\n                    return True\n    return False\n\ndef estimate_hmax(A, Ad, H_search=5.0, max_bisect_iter=30):\n    \"\"\"\n    Estimate h_max by bisection using the feasibility oracle.\n    If feasible at H_search, return H_search.\n    If infeasible even at tiny h, return 0.0.\n    Else perform bisection to approximate the boundary from below.\n    \"\"\"\n    grid_p = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n    grid_q = [0.0, 0.5, 1.0, 2.0, 5.0, 10.0]\n    grid_r = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n\n    # Check at the upper bound\n    if feasible_for_h(A, Ad, H_search, grid_p, grid_q, grid_r):\n        return H_search\n\n    # Find a small feasible lower bound\n    small_h_candidates = [1e-3, 1e-4, 1e-5, 1e-6]\n    h_low = None\n    for h0 in small_h_candidates:\n        if feasible_for_h(A, Ad, h0, grid_p, grid_q, grid_r):\n            h_low = h0\n            break\n    if h_low is None:\n        return 0.0\n\n    h_high = H_search\n    # Bisection\n    for _ in range(max_bisect_iter):\n        h_mid = 0.5 * (h_low + h_high)\n        if feasible_for_h(A, Ad, h_mid, grid_p, grid_q, grid_r):\n            h_low = h_mid\n        else:\n            h_high = h_mid\n    return h_low\n\ndef solve():\n    # Define the test cases from the problem statement.\n    A = np.array([[0.0, 1.0],\n                  [-2.0, -3.0]])\n\n    Ad_base = np.array([[0.0, 0.0],\n                        [0.0, -1.0]])\n\n    test_cases = [\n        (A, Ad_base.copy()),                      # Case 1\n        (A, np.zeros_like(Ad_base)),             # Case 2\n        (A, 2.0 * Ad_base.copy()),               # Case 3\n        (A, 4.0 * Ad_base.copy()),               # Case 4\n    ]\n\n    H_search = 5.0\n    results = []\n    for A_case, Ad_case in test_cases:\n        h_est = estimate_hmax(A_case, Ad_case, H_search=H_search, max_bisect_iter=30)\n        # Round to four decimals\n        h_est_rounded = round(h_est + 0.0, 4)\n        results.append(h_est_rounded)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2747632"}]}