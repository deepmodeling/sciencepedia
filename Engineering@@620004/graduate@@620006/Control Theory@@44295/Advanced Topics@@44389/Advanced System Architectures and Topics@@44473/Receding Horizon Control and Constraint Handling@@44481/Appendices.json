{"hands_on_practices": [{"introduction": "A core task in implementing Receding Horizon Control is to translate the control problem into a standard format that numerical solvers can understand. This exercise guides you through the process of converting a discrete-time linear system with quadratic costs and linear constraints into a canonical Quadratic Program (QP), which is the form $\\min_{U} \\frac{1}{2} U^{\\top} H U + f(x_0)^{\\top} U$ subject to $G U \\le h(x_0)$. By explicitly constructing the Hessian matrix $H$, the linear term $f(x_0)$, and the constraint matrices $G$ and $h(x_0)$, you will gain a foundational understanding of how the MPC problem is structured for computation [@problem_id:2736366].", "problem": "Consider the discrete-time linear time-invariant system used in Model Predictive Control (MPC) also known as Receding Horizon Control (RHC), given by the state-update equation $x_{k+1}=A x_k + B u_k$, where $A=\\begin{bmatrix}1&1\\\\0&1\\end{bmatrix}$ and $B=\\begin{bmatrix}0\\\\1\\end{bmatrix}$, with state $x_k\\in\\mathbb{R}^2$ and input $u_k\\in\\mathbb{R}$. Let the stage cost be $x_k^{\\top} Q x_k + u_k^{\\top} R u_k$ with $Q=I_2$ and $R=1$, and the terminal cost be $x_N^{\\top} P x_N$ with $P=I_2$, where $I_2$ denotes the $2\\times 2$ identity matrix. The prediction horizon is $N=3$. The hard constraints are the input magnitude bound $|u_k|\\le 1$ and the state infinity-norm bound $\\lVert x_k\\rVert_{\\infty}\\le 5$ for all $k\\in\\{0,1,2\\}$. Assume the initial condition $x_0=\\begin{bmatrix}x_{01}\\\\x_{02}\\end{bmatrix}$ is given and satisfies the state bound at $k=0$. Use the standard stacked decision $U=\\begin{bmatrix}u_0&u_1&u_2\\end{bmatrix}^{\\top}$.\n\nStarting from the fundamental definitions of predicted states under an affine input sequence and the quadratic performance index, derive the explicit finite-horizon optimization in standard Quadratic Program (QP) form\n$$\n\\min_{U}\\ \\frac{1}{2} U^{\\top} H U + f(x_0)^{\\top} U + c(x_0)\\quad\\text{subject to}\\quad G U \\le h(x_0),\n$$\nwhere $H\\in\\mathbb{R}^{3\\times 3}$, $f(x_0)\\in\\mathbb{R}^{3}$, $c(x_0)\\in\\mathbb{R}$, $G\\in\\mathbb{R}^{m\\times 3}$, and $h(x_0)\\in\\mathbb{R}^{m}$ for an appropriate $m$. Your derivation must make clear how the predicted states $x_1$, $x_2$, and $x_3$ depend on $x_0$ and $U$, and how the state and input constraints are mapped to linear inequalities in $U$.\n\nAfter you have written the optimization problem in this standard QP form with explicit numeric matrices and vectors (expressing the dependence on $x_0$ where appropriate), compute the determinant of the Hessian matrix $H$. Provide the exact value of the determinant as your final answer. Do not round. The final answer must be a single real number with no units.", "solution": "We begin from the discrete-time linear dynamics $x_{k+1}=A x_k + B u_k$ with $A=\\begin{bmatrix}1&1\\\\0&1\\end{bmatrix}$ and $B=\\begin{bmatrix}0\\\\1\\end{bmatrix}$. The prediction horizon is $N=3$. The cost is the quadratic performance index\n$$\nJ=\\sum_{k=0}^{N-1}\\big(x_k^{\\top} Q x_k + u_k^{\\top} R u_k\\big) + x_N^{\\top} P x_N,\n$$\nwith $Q=I_2$, $R=1$, $P=I_2$. The constraints are $|u_k|\\le 1$ and $\\lVert x_k\\rVert_{\\infty}\\le 5$ for $k\\in\\{0,1,2\\}$.\n\nWe first construct the predicted states as affine functions of the decision vector $U=\\begin{bmatrix}u_0&u_1&u_2\\end{bmatrix}^{\\top}$ and the initial condition $x_0=\\begin{bmatrix}x_{01}\\\\x_{02}\\end{bmatrix}$. Using the powers of $A$, which for this $A$ satisfy $A^n=\\begin{bmatrix}1&n\\\\0&1\\end{bmatrix}$, and the propagated input effects $A^j B$, we obtain\n$$\nx_1 = A x_0 + B u_0,\\qquad\nx_2 = A^2 x_0 + A B\\, u_0 + B u_1,\\qquad\nx_3 = A^3 x_0 + A^2 B\\, u_0 + A B\\, u_1 + B u_2.\n$$\nWe compute the needed matrices:\n$$\nA^2=\\begin{bmatrix}1&2\\\\0&1\\end{bmatrix},\\quad A^3=\\begin{bmatrix}1&3\\\\0&1\\end{bmatrix},\\quad\nB=\\begin{bmatrix}0\\\\1\\end{bmatrix},\\quad A B=\\begin{bmatrix}1\\\\1\\end{bmatrix},\\quad A^2 B=\\begin{bmatrix}2\\\\1\\end{bmatrix}.\n$$\nHence,\n$$\nx_1 = \\begin{bmatrix}x_{01}+x_{02}\\\\ x_{02}\\end{bmatrix} + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_0,\\quad\nx_2 = \\begin{bmatrix}x_{01}+2x_{02}\\\\ x_{02}\\end{bmatrix} + \\begin{bmatrix}1\\\\1\\end{bmatrix} u_0 + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_1,\n$$\n$$\nx_3 = \\begin{bmatrix}x_{01}+3x_{02}\\\\ x_{02}\\end{bmatrix} + \\begin{bmatrix}2\\\\1\\end{bmatrix} u_0 + \\begin{bmatrix}1\\\\1\\end{bmatrix} u_1 + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_2.\n$$\nIntroduce the affine decomposition $x_k = c_k + D_k U$ with $c_1=A x_0$, $c_2=A^2 x_0$, $c_3=A^3 x_0$, and\n$$\nD_1=\\begin{bmatrix}0&0&0\\\\ 1&0&0\\end{bmatrix},\\quad\nD_2=\\begin{bmatrix}1&0&0\\\\ 1&1&0\\end{bmatrix},\\quad\nD_3=\\begin{bmatrix}2&1&0\\\\ 1&1&1\\end{bmatrix}.\n$$\nThe objective can be written as\n$$\nJ(U) = x_0^{\\top} Q x_0 + \\sum_{k=1}^{3} \\big\\|c_k + D_k U\\big\\|_2^2 + \\sum_{k=0}^{2} u_k^2.\n$$\nExpanding the quadratic terms yields\n$$\nJ(U) = U^{\\top}\\!\\Big(I_3 + \\sum_{k=1}^{3} D_k^{\\top} D_k\\Big) U + 2 \\sum_{k=1}^{3} c_k^{\\top} D_k\\, U + \\Big(x_0^{\\top} Q x_0 + \\sum_{k=1}^{3} \\|c_k\\|_2^2\\Big),\n$$\nwhere $I_3$ is the $3\\times 3$ identity matrix. Therefore, in the standard Quadratic Program (QP) form\n$$\n\\min_{U}\\ \\frac{1}{2} U^{\\top} H U + f(x_0)^{\\top} U + c(x_0),\n$$\nthe Hessian is $H=2\\Big(I_3 + \\sum_{k=1}^{3} D_k^{\\top} D_k\\Big)$, the linear term is $f(x_0)=2\\sum_{k=1}^{3} D_k^{\\top} c_k$, and the constant term is $c(x_0)=x_0^{\\top} Q x_0 + \\sum_{k=1}^{3} \\|c_k\\|_2^2$.\n\nWe now compute the matrices $D_k^{\\top} D_k$:\n$$\nD_1^{\\top} D_1=\\begin{bmatrix}1&0&0\\\\ 0&0&0\\\\ 0&0&0\\end{bmatrix},\\quad\nD_2^{\\top} D_2=\\begin{bmatrix}2&1&0\\\\ 1&1&0\\\\ 0&0&0\\end{bmatrix},\\quad\nD_3^{\\top} D_3=\\begin{bmatrix}5&3&1\\\\ 3&2&1\\\\ 1&1&1\\end{bmatrix}.\n$$\nSumming and adding $I_3$ gives\n$$\nI_3 + \\sum_{k=1}^{3} D_k^{\\top} D_k\n= \\begin{bmatrix}1&0&0\\\\ 0&1&0\\\\ 0&0&1\\end{bmatrix}\n+ \\begin{bmatrix}1&0&0\\\\ 0&0&0\\\\ 0&0&0\\end{bmatrix}\n+ \\begin{bmatrix}2&1&0\\\\ 1&1&0\\\\ 0&0&0\\end{bmatrix}\n+ \\begin{bmatrix}5&3&1\\\\ 3&2&1\\\\ 1&1&1\\end{bmatrix}\n= \\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}.\n$$\nThus the Hessian is\n$$\nH=2\\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}\n= \\begin{bmatrix}18&8&2\\\\ 8&8&2\\\\ 2&2&4\\end{bmatrix}.\n$$\nNext, compute the linear term $f(x_0)=2\\sum_{k=1}^{3} D_k^{\\top} c_k$, with $c_1=A x_0=\\begin{bmatrix}x_{01}+x_{02}\\\\ x_{02}\\end{bmatrix}$, $c_2=A^2 x_0=\\begin{bmatrix}x_{01}+2x_{02}\\\\ x_{02}\\end{bmatrix}$, $c_3=A^3 x_0=\\begin{bmatrix}x_{01}+3x_{02}\\\\ x_{02}\\end{bmatrix}$. Using $D_1^{\\top}=\\begin{bmatrix}0&1\\\\ 0&0\\\\ 0&0\\end{bmatrix}$, $D_2^{\\top}=\\begin{bmatrix}1&1\\\\ 0&1\\\\ 0&0\\end{bmatrix}$, $D_3^{\\top}=\\begin{bmatrix}2&1\\\\ 1&1\\\\ 0&1\\end{bmatrix}$, we obtain\n$$\nD_1^{\\top} c_1=\\begin{bmatrix}x_{02}\\\\ 0\\\\ 0\\end{bmatrix},\\quad\nD_2^{\\top} c_2=\\begin{bmatrix}x_{01}+3x_{02}\\\\ x_{02}\\\\ 0\\end{bmatrix},\\quad\nD_3^{\\top} c_3=\\begin{bmatrix}2x_{01}+7x_{02}\\\\ x_{01}+4x_{02}\\\\ x_{02}\\end{bmatrix},\n$$\nso that\n$$\n\\sum_{k=1}^{3} D_k^{\\top} c_k=\\begin{bmatrix}3x_{01}+11x_{02}\\\\ x_{01}+5x_{02}\\\\ x_{02}\\end{bmatrix},\\qquad\nf(x_0)=2\\begin{bmatrix}3x_{01}+11x_{02}\\\\ x_{01}+5x_{02}\\\\ x_{02}\\end{bmatrix}=\\begin{bmatrix}6x_{01}+22x_{02}\\\\ 2x_{01}+10x_{02}\\\\ 2x_{02}\\end{bmatrix}.\n$$\nThe constant term $c(x_0)$ collects all parts independent of $U$:\n$$\nc(x_0)=x_0^{\\top} x_0 + \\|A x_0\\|_2^2 + \\|A^2 x_0\\|_2^2 + \\|A^3 x_0\\|_2^2\n= \\sum_{k=0}^{3}\\big((x_{01}+k x_{02})^2 + x_{02}^2\\big).\n$$\n\nWe now express the constraints $|u_k|\\le 1$ and $\\lVert x_k\\rVert_{\\infty}\\le 5$ for $k\\in\\{0,1,2\\}$ as linear inequalities $G U\\le h(x_0)$. The input constraints yield\n$$\n\\begin{bmatrix}\n1&0&0\\\\ -1&0&0\\\\ 0&1&0\\\\ 0&-1&0\\\\ 0&0&1\\\\ 0&0&-1\n\\end{bmatrix}\n\\begin{bmatrix}u_0\\\\ u_1\\\\ u_2\\end{bmatrix}\n\\le\n\\begin{bmatrix}1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\end{bmatrix}.\n$$\nFor the state constraints at $k=0$, $\\lVert x_0\\rVert_{\\infty}\\le 5$ is a feasibility condition on $x_0$ and can be expressed as constant inequalities with zero rows in $G$:\n$$\n\\begin{bmatrix}\n0&0&0\\\\ 0&0&0\\\\ 0&0&0\\\\ 0&0&0\n\\end{bmatrix}\nU \\le\n\\begin{bmatrix}\n5 - x_{01}\\\\ 5 + x_{01}\\\\ 5 - x_{02}\\\\ 5 + x_{02}\n\\end{bmatrix}.\n$$\nFor $k=1$, we have $x_1=\\begin{bmatrix}x_{01}+x_{02}\\\\ x_{02}\\end{bmatrix}+\\begin{bmatrix}0\\\\1\\end{bmatrix} u_0$, hence\n$$\n\\begin{aligned}\n&-5 \\le x_{01}+x_{02} \\le 5 \\quad\\Rightarrow\\quad \\begin{bmatrix}0&0&0\\\\ 0&0&0\\end{bmatrix} U \\le \\begin{bmatrix}5-(x_{01}+x_{02})\\\\ 5+(x_{01}+x_{02})\\end{bmatrix},\\\\\n&-5 \\le x_{02}+u_0 \\le 5 \\quad\\Rightarrow\\quad \\begin{bmatrix}1&0&0\\\\ -1&0&0\\end{bmatrix} U \\le \\begin{bmatrix}5 - x_{02}\\\\ 5 + x_{02}\\end{bmatrix}.\n\\end{aligned}\n$$\nFor $k=2$, we have $x_2=\\begin{bmatrix}x_{01}+2x_{02}\\\\ x_{02}\\end{bmatrix}+\\begin{bmatrix}1\\\\1\\end{bmatrix} u_0 + \\begin{bmatrix}0\\\\1\\end{bmatrix} u_1$, hence\n$$\n\\begin{aligned}\n&-5 \\le x_{01}+2x_{02}+u_0 \\le 5 \\ \\Rightarrow\\\n\\begin{bmatrix}1&0&0\\\\ -1&0&0\\end{bmatrix} U \\le \\begin{bmatrix}5 - x_{01} - 2x_{02}\\\\ 5 + x_{01} + 2x_{02}\\end{bmatrix},\\\\\n&-5 \\le x_{02}+u_0+u_1 \\le 5 \\ \\Rightarrow\\\n\\begin{bmatrix}1&1&0\\\\ -1&-1&0\\end{bmatrix} U \\le \\begin{bmatrix}5 - x_{02}\\\\ 5 + x_{02}\\end{bmatrix}.\n\\end{aligned}\n$$\nStacking all the inequalities produces $G\\in\\mathbb{R}^{18\\times 3}$ and $h(x_0)\\in\\mathbb{R}^{18}$:\n$$\nG=\n\\begin{bmatrix}\n1&0&0\\\\ -1&0&0\\\\ 0&1&0\\\\ 0&-1&0\\\\ 0&0&1\\\\ 0&0&-1\\\\\n0&0&0\\\\ 0&0&0\\\\ 0&0&0\\\\ 0&0&0\\\\\n0&0&0\\\\ 0&0&0\\\\ 1&0&0\\\\ -1&0&0\\\\\n1&0&0\\\\ -1&0&0\\\\ 1&1&0\\\\ -1&-1&0\n\\end{bmatrix},\\quad\nh(x_0)=\n\\begin{bmatrix}\n1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\ 1\\\\\n5 - x_{01}\\\\ 5 + x_{01}\\\\ 5 - x_{02}\\\\ 5 + x_{02}\\\\\n5 - (x_{01}+x_{02})\\\\ 5 + (x_{01}+x_{02})\\\\ 5 - x_{02}\\\\ 5 + x_{02}\\\\\n5 - x_{01} - 2x_{02}\\\\ 5 + x_{01} + 2x_{02}\\\\ 5 - x_{02}\\\\ 5 + x_{02}\n\\end{bmatrix}.\n$$\nThis yields the requested explicit QP form with decision $U$.\n\nFinally, we compute the determinant of the Hessian $H$. Recall\n$$\nH=\\begin{bmatrix}18&8&2\\\\ 8&8&2\\\\ 2&2&4\\end{bmatrix}\n= 2 \\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}.\n$$\nLet $M=\\begin{bmatrix}9&4&1\\\\ 4&4&1\\\\ 1&1&2\\end{bmatrix}$. Then $\\det(H)=2^3 \\det(M)=8\\,\\det(M)$. Compute $\\det(M)$ by cofactor expansion along the first row:\n$$\n\\det(M)=9\\begin{vmatrix}4&1\\\\ 1&2\\end{vmatrix} - 4\\begin{vmatrix}4&1\\\\ 1&2\\end{vmatrix} + 1\\begin{vmatrix}4&4\\\\ 1&1\\end{vmatrix}\n= 9(8-1) - 4(8-1) + 1(4-4) = 9\\cdot 7 - 4\\cdot 7 + 0 = 35.\n$$\nTherefore,\n$$\n\\det(H)=8\\times 35 = 280.\n$$\nThis is an exact integer, so no rounding is needed.", "answer": "$$\\boxed{280}$$", "id": "2736366"}, {"introduction": "To guarantee that a Receding Horizon Controller can operate indefinitely without violating constraints or becoming unsolvable, we must introduce a stabilizing terminal set. This practice [@problem_id:2736411] focuses on designing such a set, $\\mathcal{X}_{f}$, which acts as a \"safe\" region where a simple feedback law can take over. You will learn to derive the mathematical conditions that ensure this terminal set is positively invariant and that all state and input constraints are satisfied within it, providing a crucial building block for proving the stability of the entire control scheme.", "problem": "Consider the discrete-time linear time-invariant system given by the state-update equation $x^{+} = A x + B u$, where\n$$\nA = \\begin{pmatrix}\n0.4 & 0.1 \\\\\n-0.2 & 0.3\n\\end{pmatrix}, \n\\quad\nB = \\begin{pmatrix}\n1 \\\\\n0.5\n\\end{pmatrix}.\n$$\nThe admissible state and input sets are polyhedral:\n$$\n\\mathcal{X} = \\{ x \\in \\mathbb{R}^{2} \\mid |x_{1}| \\leq 2, \\, |x_{2}| \\leq 1 \\},\n\\quad\n\\mathcal{U} = \\{ u \\in \\mathbb{R} \\mid |u| \\leq \\tfrac{1}{2} \\}.\n$$\nA fixed linear feedback $u = K x$ with\n$$\nK = \\begin{pmatrix}\n-0.5 & 0.2\n\\end{pmatrix}\n$$\nis implemented inside a receding horizon controller to enforce constraint satisfaction in the terminal stage. Let the terminal cost be quadratic, $V(x) = x^{\\top} P x$, where $P \\succ 0$ solves the discrete-time Lyapunov equation\n$$\n(A + B K)^{\\top} P (A + B K) - P = -\\left(Q + K^{\\top} R K\\right),\n$$\nwith $Q = I_{2}$ and $R = 1$. This choice ensures a strict quadratic Lyapunov decrease for the closed-loop system $x^{+} = (A + B K) x$ under the terminal feedback.\n\nDefine a family of polyhedral (hyper-rectangular) terminal sets parameterized by a scalar $\\alpha > 0$ as\n$$\n\\mathcal{X}_{f}(\\alpha) = \\{ x \\in \\mathbb{R}^{2} \\mid |x_{1}| \\leq \\alpha, \\, |x_{2}| \\leq \\alpha \\}.\n$$\nConstruct $\\mathcal{X}_{f}(\\alpha)$ by solving the linear inequalities induced by the constraints $x \\in \\mathcal{X}$ and $K x \\in \\mathcal{U}$ and by tightening to guarantee that the set is positively invariant for the closed-loop map $x^{+} = (A + B K) x$, leveraging the quadratic Lyapunov decrease condition. Specifically, determine the exact largest scalar $\\alpha^{\\star}$ such that:\n1. $\\mathcal{X}_{f}(\\alpha^{\\star}) \\subseteq \\mathcal{X}$,\n2. $K x \\in \\mathcal{U}$ for all $x \\in \\mathcal{X}_{f}(\\alpha^{\\star})$,\n3. $\\mathcal{X}_{f}(\\alpha^{\\star})$ is positively invariant under $x^{+} = (A + B K) x$ (so that the Lyapunov decrease condition holds along the terminal dynamics for all $x \\in \\mathcal{X}_{f}(\\alpha^{\\star})$).\n\nExpress your final answer as the exact value of $\\alpha^{\\star}$ (no units). No rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, and contains all necessary information for a unique solution. It is a standard problem in the design of terminal sets for receding horizon control. The analysis will proceed by systematically evaluating the three conditions imposed on the parameterized terminal set $\\mathcal{X}_{f}(\\alpha)$.\n\nThe system is defined by the state-update equation $x^{+} = A x + B u$, with matrices\n$$\nA = \\begin{pmatrix} 0.4 & 0.1 \\\\ -0.2 & 0.3 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix}.\n$$\nThe state and input constraints are given by the sets\n$$\n\\mathcal{X} = \\{ x \\in \\mathbb{R}^{2} \\mid |x_{1}| \\leq 2, \\, |x_{2}| \\leq 1 \\}, \\quad \\mathcal{U} = \\{ u \\in \\mathbb{R} \\mid |u| \\leq \\tfrac{1}{2} \\}.\n$$\nThe terminal feedback law is $u = K x$ with gain $K = \\begin{pmatrix} -0.5 & 0.2 \\end{pmatrix}$.\nThe family of terminal sets is $\\mathcal{X}_{f}(\\alpha) = \\{ x \\in \\mathbb{R}^{2} \\mid |x_{1}| \\leq \\alpha, \\, |x_{2}| \\leq \\alpha \\}$ for $\\alpha > 0$.\n\nWe must find the largest scalar $\\alpha^{\\star}$ such that $\\mathcal{X}_{f}(\\alpha^{\\star})$ satisfies three conditions. Each condition will impose a constraint on the value of $\\alpha$.\n\n1. Condition 1: $\\mathcal{X}_{f}(\\alpha) \\subseteq \\mathcal{X}$\nFor any state $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\in \\mathcal{X}_{f}(\\alpha)$, we have $|x_{1}| \\leq \\alpha$ and $|x_{2}| \\leq \\alpha$. For this state to also be in $\\mathcal{X}$, it must satisfy $|x_{1}| \\leq 2$ and $|x_{2}| \\leq 1$.\nTo ensure that every point in $\\mathcal{X}_{f}(\\alpha)$ is also in $\\mathcal{X}$, the bounds defining $\\mathcal{X}_{f}(\\alpha)$ must be at least as tight as the bounds defining $\\mathcal{X}$. This implies two inequalities:\n$$\n\\alpha \\leq 2\n$$\n$$\n\\alpha \\leq 1\n$$\nTo satisfy both simultaneously, we must adhere to the more restrictive one. Thus, this condition imposes the constraint:\n$$\n\\alpha \\leq 1\n$$\n\n2. Condition 2: $K x \\in \\mathcal{U}$ for all $x \\in \\mathcal{X}_{f}(\\alpha)$\nThe control input is $u = Kx = -0.5 x_1 + 0.2 x_2$. The constraint on the input is $|u| \\leq \\frac{1}{2}$.\nWe must ensure that for all $x \\in \\mathcal{X}_{f}(\\alpha)$, the inequality $|-0.5 x_1 + 0.2 x_2| \\leq \\frac{1}{2}$ holds.\nWe find the maximum absolute value of $Kx$ over the set $\\mathcal{X}_{f}(\\alpha)$. By the triangle inequality, for any $x \\in \\mathcal{X}_{f}(\\alpha)$:\n$$\n|Kx| = |-0.5 x_1 + 0.2 x_2| \\leq |-0.5||x_1| + |0.2||x_2| = 0.5|x_1| + 0.2|x_2|\n$$\nSince $|x_1| \\leq \\alpha$ and $|x_2| \\leq \\alpha$, we have:\n$$\n|Kx| \\leq 0.5\\alpha + 0.2\\alpha = 0.7\\alpha\n$$\nThis maximum value is achieved at the vertices of the square set $\\mathcal{X}_{f}(\\alpha)$, for instance at $x = \\begin{pmatrix} -\\alpha \\\\ \\alpha \\end{pmatrix}$.\nThe constraint is that this maximum value must not exceed the input limit:\n$$\n0.7\\alpha \\leq \\frac{1}{2}\n$$\nSolving for $\\alpha$, we find:\n$$\n\\alpha \\leq \\frac{1/2}{0.7} = \\frac{0.5}{0.7} = \\frac{5}{7}\n$$\n\n3. Condition 3: $\\mathcal{X}_{f}(\\alpha)$ is positively invariant under $x^{+} = (A + B K) x$\nPositive invariance requires that for any $x(k) \\in \\mathcal{X}_{f}(\\alpha)$, the next state $x(k+1) = x^{+}$ also lies in $\\mathcal{X}_{f}(\\alpha)$.\nThe closed-loop system matrix is $A_{cl} = A + BK$:\n$$\nA_{cl} = \\begin{pmatrix} 0.4 & 0.1 \\\\ -0.2 & 0.3 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} \\begin{pmatrix} -0.5 & 0.2 \\end{pmatrix} = \\begin{pmatrix} 0.4 & 0.1 \\\\ -0.2 & 0.3 \\end{pmatrix} + \\begin{pmatrix} -0.5 & 0.2 \\\\ -0.25 & 0.1 \\end{pmatrix} = \\begin{pmatrix} -0.1 & 0.3 \\\\ -0.45 & 0.4 \\end{pmatrix}\n$$\nThe set $\\mathcal{X}_{f}(\\alpha)$ can be described using the infinity norm as $\\{x \\in \\mathbb{R}^2 \\mid \\|x\\|_{\\infty} \\leq \\alpha \\}$.\nThe invariance condition is that for any $x$ with $\\|x\\|_{\\infty} \\leq \\alpha$, we must have $\\|A_{cl}x\\|_{\\infty} \\leq \\alpha$.\nWe know that $\\|A_{cl}x\\|_{\\infty} \\leq \\|A_{cl}\\|_{\\infty} \\|x\\|_{\\infty}$, where $\\|A_{cl}\\|_{\\infty}$ is the induced matrix norm, calculated as the maximum absolute row sum.\n$$\n\\|A_{cl}\\|_{\\infty} = \\max \\left( |-0.1| + |0.3|, |-0.45| + |0.4| \\right) = \\max(0.1 + 0.3, 0.45 + 0.4) = \\max(0.4, 0.85) = 0.85\n$$\nSo, if $\\|x\\|_{\\infty} \\leq \\alpha$, then $\\|x^{+}\\|_{\\infty} = \\|A_{cl}x\\|_{\\infty} \\leq 0.85 \\|x\\|_{\\infty} \\leq 0.85\\alpha$.\nFor invariance, we need $\\|x^{+}\\|_{\\infty} \\leq \\alpha$. This gives the inequality $0.85\\alpha \\leq \\alpha$. Since $\\alpha > 0$, this simplifies to $0.85 \\leq 1$, which is always true.\nTherefore, the set $\\mathcal{X}_{f}(\\alpha)$ is positively invariant for any $\\alpha > 0$. This condition imposes no upper bound on $\\alpha$. The mention of the Lyapunov function serves to confirm that this is a valid terminal set construction for RHC, but is not needed for the calculation of $\\alpha^{\\star}$ itself.\n\nCombining the constraints:\nTo find the largest possible value $\\alpha^{\\star}$, we must satisfy all derived constraints on $\\alpha$:\n$$\n\\alpha \\leq 1 \\quad \\text{(from Condition 1)}\n$$\n$$\n\\alpha \\leq \\frac{5}{7} \\quad \\text{(from Condition 2)}\n$$\nThe value of $\\alpha$ must be less than or equal to the minimum of these upper bounds:\n$$\n\\alpha^{\\star} = \\min\\left(1, \\frac{5}{7}\\right)\n$$\nSince $1 > \\frac{5}{7}$, the most restrictive constraint is $\\alpha \\leq \\frac{5}{7}$.\nThe exact largest scalar is therefore:\n$$\n\\alpha^{\\star} = \\frac{5}{7}\n$$", "answer": "$$\\boxed{\\frac{5}{7}}$$", "id": "2736411"}, {"introduction": "While theoretical design provides the foundation for a stable controller, numerical simulation is essential for verifying its performance and behavior in practice. This coding exercise [@problem_id:2736384] serves as a capstone, integrating the design of a terminal controller and set with the implementation of a full receding horizon control loop. By simulating the system from various initial conditions, you will empirically test the concept of recursive feasibility, observing how the terminal set constraint ensures that the optimization problem remains solvable at every time step, thus bridging the gap between theory and practical application.", "problem": "Consider the discrete-time, linear time-invariant system with state update equation $x_{k+1} = A x_k + B u_k$, where $x_k \\in \\mathbb{R}^2$ and $u_k \\in \\mathbb{R}$. The matrices are given by\n$$\nA = \\begin{bmatrix} 1 & 0.2 \\\\ 0 & 1 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0.02 \\\\ 0.2 \\end{bmatrix}.\n$$\nState and input constraints are componentwise box constraints\n$$\n|x_{1,k}| \\le 4,\\quad |x_{2,k}| \\le 4,\\quad |u_k| \\le 2,\n$$\nfor all time indices $k \\in \\mathbb{N}$. Define a quadratic stage cost and terminal cost using symmetric positive-definite matrices\n$$\nQ = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0.1 \\end{bmatrix},\\quad R = \\begin{bmatrix} 0.05 \\end{bmatrix}.\n$$\nLet $P \\succ 0$ be the stabilizing solution of the discrete-time algebraic Riccati equation associated with $(A,B,Q,R)$, and let $K \\in \\mathbb{R}^{1 \\times 2}$ denote the corresponding linear quadratic regulator gain. The terminal set is chosen as the ellipsoid\n$$\n\\mathcal{X}_f := \\{ x \\in \\mathbb{R}^2 \\mid x^\\top P x \\le \\alpha \\},\n$$\nwith scalar $\\alpha > 0$ designed so that $\\mathcal{X}_f$ is contained within the above box constraints and also respects the input bound under the terminal controller $u = K x$.\n\nAt each time step, define a finite-horizon, constrained model predictive control problem with horizon length $N$:\n- Decision variable sequence $u_0, u_1, \\dots, u_{N-1}$,\n- Predicted states $x_0$ (given), $x_{k+1} = A x_k + B u_k$ for $k = 0,\\dots,N-1$,\n- Objective function\n$$\nJ = \\sum_{k=0}^{N-1} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right) + x_N^\\top P x_N,\n$$\n- Subject to the box constraints on $x_k$ and $u_k$ for $k = 0,\\dots,N-1$ and the terminal constraint $x_N \\in \\mathcal{X}_f$.\n\nYou are to numerically verify recursive feasibility of the resulting receding horizon controller by simulating the closed-loop from multiple initial conditions in the feasible set as follows:\n- At each time step, solve the above optimization problem,\n- Apply only the first control input to the system,\n- Shift forward one step and repeat, for a fixed closed-loop simulation horizon of $T_{\\text{cl}}$ steps,\n- Declare the closed-loop run recursively feasible if the optimization problem is feasible at every time step and all constraints are satisfied by the applied inputs and resulting states.\n\nUse the following parameters:\n- Horizon length $N = 20$,\n- Closed-loop simulation length $T_{\\text{cl}} = 20$,\n- Terminal cost matrix $P$ as the stabilizing discrete-time algebraic Riccati solution for $(A,B,Q,R)$,\n- Terminal set $\\mathcal{X}_f = \\{ x \\mid x^\\top P x \\le \\alpha \\}$, with $\\alpha$ chosen such that $\\mathcal{X}_f$ is contained in the above state box constraints and, for all $x \\in \\mathcal{X}_f$, the terminal control $u = K x$ satisfies $|u| \\le 2$.\n\nYour program must implement the above receding horizon control law and report, for each initial condition listed below, whether the closed-loop run is recursively feasible across all $T_{\\text{cl}}$ steps. The initial conditions are:\n- $x_0^{(1)} = \\begin{bmatrix} 0.05 \\\\ -0.05 \\end{bmatrix}$,\n- $x_0^{(2)} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix}$,\n- $x_0^{(3)} = \\begin{bmatrix} -1.5 \\\\ 1.0 \\end{bmatrix}$,\n- $x_0^{(4)} = \\begin{bmatrix} 2.5 \\\\ -1.0 \\end{bmatrix}$,\n- $x_0^{(5)} = \\begin{bmatrix} -2.0 \\\\ 2.0 \\end{bmatrix}$.\n\nFundamental base and constraints to use:\n- Use the definition of receding horizon control: at each step solve a finite-horizon constrained optimization with the system model and constraints, then apply the first control action and repeat.\n- Use linear time-invariant dynamics $x_{k+1} = A x_k + B u_k$ and quadratic costs with $(Q \\succeq 0, R \\succ 0)$.\n- Enforce state and input constraints at each prediction step and a terminal state constraint $x_N \\in \\mathcal{X}_f$.\n- The terminal pair $(P,\\mathcal{X}_f)$ should be designed using standard linear quadratic regulator techniques so that $\\mathcal{X}_f$ is a positively invariant set under the terminal controller $u=Kx$ and is contained in the constraints.\n\nTest suite and required output:\n- Use the above $5$ initial conditions and the parameter values specified.\n- For each initial condition, return a boolean indicating whether recursive feasibility held for all $T_{\\text{cl}}$ steps.\n- Your program should produce a single line of output containing the results as a comma-separated list of booleans enclosed in square brackets (e.g., \"[True,False,True,True,False]\").\n\nNo physical units are involved, so none are required. All angles, if any are used, must be in radians, but no angles are used in this problem. The final output is the single line described above; do not print any additional text.", "solution": "The core of the methodology is receding horizon control (RHC), where at each time step $k$, a finite-horizon optimal control problem is solved using the current state $x_k$ as the initial state. The first element of the resulting optimal control sequence is applied to the system, and the process is repeated at the next time step. The recursive feasibility of this scheme, which is central to its practical application, is guaranteed by the proper design of a terminal cost and a terminal constraint set.\n\nThe solution is structured into three parts: first, the design of the terminal components; second, the formulation of the finite-horizon optimization problem; and third, the closed-loop simulation to verify recursive feasibility.\n\n**Part 1: Terminal Controller and Set Design**\n\nThe stability and recursive feasibility of the MPC scheme are ensured by a terminal cost matrix $P$ and a terminal constraint set $\\mathcal{X}_f$. These are derived from Linear Quadratic Regulator (LQR) theory for the given system.\n\n1.  **Terminal Cost Matrix $P$**: The matrix $P$ is the unique, symmetric, positive-definite solution to the discrete-time algebraic Riccati equation (DARE):\n    $$\n    A^\\top P A - P - (A^\\top P B)(R + B^\\top P B)^{-1}(B^\\top P A) + Q = 0\n    $$\n    This matrix $P$ serves as the terminal cost weighting matrix, defining a Lyapunov function for the local terminal controller.\n\n2.  **Terminal Controller Gain $K$**: The associated stabilizing LQR feedback gain is given by:\n    $$\n    K = -(R + B^\\top P B)^{-1}B^\\top P A\n    $$\n    The terminal control law is $u_k = Kx_k$. For any state $x$ within the terminal set $\\mathcal{X}_f$, the evolution under this controller, $x_{k+1} = (A+BK)x_k$, is guaranteed to drive the state to the origin while respecting constraints. The solution $P$ of the DARE ensures that $V(x) = x^\\top P x$ is a Lyapunov function for the closed-loop system $x_{k+1} = (A+BK)x_k$.\n\n3.  **Terminal Set $\\mathcal{X}_f$**: The terminal set is defined as a level set of the Lyapunov function:\n    $$\n    \\mathcal{X}_f = \\{ x \\in \\mathbb{R}^2 \\mid x^\\top P x \\le \\alpha \\}\n    $$\n    The parameter $\\alpha > 0$ must be chosen to ensure that for any state $x \\in \\mathcal{X}_f$, both the state and the corresponding control input $u = Kx$ satisfy the specified constraints. That is, $\\mathcal{X}_f$ must be a subset of the polytopic constraint set $\\mathcal{X} \\cap \\mathcal{U}_K$, where $\\mathcal{X} = \\{x \\mid |x_1| \\le 4, |x_2| \\le 4\\}$ and $\\mathcal{U}_K = \\{x \\mid |Kx| \\le 2\\}$.\n    \n    The condition that the ellipsoid $x^\\top P x \\le \\alpha$ is contained within a half-space $\\{x \\mid c^\\top x \\le d\\}$ (with $d>0$) is equivalent to $\\alpha \\le d^2 / (c^\\top P^{-1} c)$. We apply this to all facets of the constraint polyhedra:\n    -   State constraint $|x_1| \\le 4$: This gives two inequalities, $x_1 \\le 4$ ($c=[1, 0]^\\top$) and $-x_1 \\le 4$ ($c=[-1, 0]^\\top$). This requires $\\alpha \\le 4^2 / ([1,0]P^{-1}[1,0]^\\top) = 16 / (P^{-1})_{11}$.\n    -   State constraint $|x_2| \\le 4$: Similarly, this requires $\\alpha \\le 16 / (P^{-1})_{22}$.\n    -   Input constraint $|Kx| \\le 2$: With $K$ being a $1 \\times 2$ row vector, this requires $\\alpha \\le 2^2 / (K P^{-1} K^\\top)$.\n\n    To satisfy all constraints simultaneously, $\\alpha$ must be chosen as the minimum of these upper bounds:\n    $$\n    \\alpha = \\min \\left( \\frac{16}{(P^{-1})_{11}}, \\frac{16}{(P^{-1})_{22}}, \\frac{4}{K P^{-1} K^\\top} \\right)\n    $$\n    This choice of $\\alpha$ guarantees that any state trajectory entering $\\mathcal{X}_f$ can be kept within the state and input constraints for all future time by applying the terminal controller $u=Kx$.\n\n**Part 2: Finite-Horizon Optimal Control Problem**\n\nAt each time step of the RHC procedure, we solve the following optimization problem for the current state $x_{curr}$:\n\nFind the control sequence $U = \\{u_0, \\dots, u_{N-1}\\}$ that minimizes the cost function:\n$$\nJ(U, x_{curr}) = \\sum_{k=0}^{N-1} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right) + x_N^\\top P x_N\n$$\nsubject to:\n1.  System dynamics: $x_0 = x_{curr}$, $x_{k+1} = A x_k + B u_k$ for $k=0, \\dots, N-1$.\n2.  Input constraints: $|u_k| \\le 2$ for $k=0, \\dots, N-1$.\n3.  State path constraints: $|x_{i,k}| \\le 4$ for component $i \\in \\{1,2\\}$ and time $k=1, \\dots, N-1$.\n4.  Terminal constraint: $x_N \\in \\mathcal{X}_f$, which is $x_N^\\top P x_N \\le \\alpha$.\n\nThis problem is a convex Quadratically Constrained Quadratic Program (QCQP), as the objective is quadratic, dynamics are linear, and constraints are linear or convex quadratic. It can be solved using standard numerical optimization techniques, such as the Sequential Least Squares Programming (SLSQP) algorithm.\n\n**Part 3: Recursive Feasibility Verification**\n\nWe numerically verify recursive feasibility by simulating the closed-loop system for $T_{\\text{cl}}=20$ steps for each of the given initial conditions. The procedure is as follows:\n\n1.  Initialize the state $x_{current}$ with the given initial condition $x_0^{(i)}$.\n2.  For each time step $t = 0, \\dots, T_{\\text{cl}}-1$:\n    a.  Solve the finite-horizon optimal control problem defined in Part 2, with $x_{curr} = x_{current}$.\n    b.  If the optimizer fails to find a feasible solution (indicated by a failure flag from the solver), the simulation is declared not recursively feasible, and the procedure for this initial condition terminates.\n    c.  If a solution $U^* = \\{u_0^*, \\dots, u_{N-1}^*\\}$ is found, apply the first control input $u_{apply} = u_0^*$ to the system.\n    d.  Update the state: $x_{current} \\leftarrow A x_{current} + B u_{apply}$.\n3.  If the simulation completes all $T_{\\text{cl}}$ steps without any solver failure, the run is declared recursively feasible.\n\nThe provided Python code implements this algorithm precisely. It first computes $P$, $K$, and $\\alpha$. Then, for each initial state, it enters the simulation loop, calling a numerical optimizer at each step to solve the constrained MPC problem. The boolean feasibility result is recorded for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Implements and simulates a receding horizon controller to verify recursive feasibility\n    for a given discrete-time LTI system and a set of initial conditions.\n    \"\"\"\n    # System and MPC parameters\n    A = np.array([[1, 0.2], [0, 1]])\n    B = np.array([[0.02], [0.2]])\n    Q = np.array([[1, 0], [0, 0.1]])\n    R = np.array([[0.05]])\n    N = 20\n    T_cl = 20\n    x_max_abs = 4.0\n    u_max_abs = 2.0\n\n    # Test cases: initial conditions\n    test_cases = [\n        np.array([0.05, -0.05]),\n        np.array([1.0, 0.5]),\n        np.array([-1.5, 1.0]),\n        np.array([2.5, -1.0]),\n        np.array([-2.0, 2.0])\n    ]\n\n    # --- Part 1: Terminal Controller and Set Design ---\n\n    # Solve the Discrete-time Algebraic Riccati Equation (DARE) for P\n    P = linalg.solve_discrete_are(A, B, Q, R)\n\n    # Compute the LQR gain K\n    K = -np.linalg.inv(R + B.T @ P @ B) @ B.T @ P @ A\n\n    # Compute alpha for the terminal set X_f = {x | x'Px <= alpha}\n    def calculate_alpha(P_mat, K_mat, x_max, u_max):\n        P_inv = np.linalg.inv(P_mat)\n        \n        # From state constraints: |x_i| <= x_max\n        # alpha <= x_max^2 / (e_i' * P_inv * e_i)\n        alpha_x1 = x_max**2 / P_inv[0, 0]\n        alpha_x2 = x_max**2 / P_inv[1, 1]\n\n        # From input constraint: |Kx| <= u_max\n        # alpha <= u_max^2 / (K * P_inv * K')\n        alpha_u = u_max**2 / (K_mat @ P_inv @ K_mat.T)[0, 0]\n        \n        return min(alpha_x1, alpha_x2, alpha_u)\n\n    alpha = calculate_alpha(P, K, x_max_abs, u_max_abs)\n\n    # --- Part 2: Finite-Horizon Optimal Control Problem ---\n\n    def mpc_objective(U, x0, A_sys, B_sys, Q_cost, R_cost, P_cost, N_horizon):\n        cost = 0.0\n        x = x0.copy()\n        for k in range(N_horizon):\n            u_scalar = U[k]\n            cost += (x.T @ Q_cost @ x + u_scalar * R_cost[0, 0] * u_scalar)[0, 0]\n            x = A_sys @ x + B_sys * u_scalar\n        cost += (x.T @ P_cost @ x)[0, 0]\n        return cost\n\n    def mpc_constraints(U, x0, A_sys, B_sys, P_cost, alpha_term, x_max, N_horizon):\n        # Constraints are formulated as g(x) >= 0\n        cons = []\n        x = x0.copy()\n        for k in range(N_horizon):\n            u = U[k]\n            x_next = A_sys @ x + B_sys * u\n            \n            # Path constraints for x_1, ..., x_N\n            cons.extend([\n                x_max - x_next[0, 0], x_max + x_next[0, 0],\n                x_max - x_next[1, 0], x_max + x_next[1, 0]\n            ])\n            \n            if k == N_horizon - 1:  # Terminal constraint for x_N\n                cons.append(alpha_term - (x_next.T @ P_cost @ x_next)[0, 0])\n            \n            x = x_next\n        return np.array(cons)\n\n    # --- Part 3: Recursive Feasibility Verification ---\n\n    def check_recursive_feasibility(x0_vec):\n        x_current = x0_vec.reshape(2, 1)\n        U_warm_start = np.zeros(N)\n\n        for _ in range(T_cl):\n            if np.any(np.abs(x_current) > x_max_abs + 1e-9): # Safety check\n                return False\n\n            bounds = [(-u_max_abs, u_max_abs)] * N\n            \n            constraints_dict = {\n                'type': 'ineq',\n                'fun': mpc_constraints,\n                'args': (x_current, A, B, P, alpha, x_max_abs, N)\n            }\n\n            res = minimize(mpc_objective, U_warm_start,\n                           args=(x_current, A, B, Q, R, P, N),\n                           method='SLSQP',\n                           bounds=bounds,\n                           constraints=[constraints_dict],\n                           options={'ftol': 1e-6, 'maxiter': 200})\n\n            if not res.success:\n                return False\n\n            U_optimal = res.x\n            u0_optimal = U_optimal[0]\n\n            x_next = A @ x_current + B * u0_optimal\n            x_current = x_next\n            \n            # Use warm start for the next iteration\n            U_warm_start = np.roll(U_optimal, -1)\n            U_warm_start[-1] = 0.0\n\n        return True\n\n    results = []\n    for x0 in test_cases:\n        # Initial state constraint check\n        if np.any(np.abs(x0) > x_max_abs):\n             results.append(False)\n             continue\n        is_feasible = check_recursive_feasibility(x0)\n        results.append(is_feasible)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2736384"}]}