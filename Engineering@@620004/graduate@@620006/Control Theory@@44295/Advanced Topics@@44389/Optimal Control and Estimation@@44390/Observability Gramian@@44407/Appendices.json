{"hands_on_practices": [{"introduction": "To ground our understanding, we begin with a foundational practice that connects the mathematical definition of the observability Gramian to its core physical interpretation. The following exercise guides you through computing the infinite-horizon Gramian for a simple continuous-time system. By analyzing its algebraic properties, specifically its kernel, you will directly identify the system's unobservable subspace, making the abstract concept of observability tangible [@problem_id:2728907].", "problem": "Consider the continuous-time Linear Time-Invariant (LTI) system with state matrix $A \\in \\mathbb{R}^{3 \\times 3}$ and output matrix $C \\in \\mathbb{R}^{1 \\times 3}$ given by\n$$\nA \\;=\\; \\begin{pmatrix}\n-1 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & -3\n\\end{pmatrix}, \n\\qquad\nC \\;=\\; \\begin{pmatrix}\n1 & 1 & 0\n\\end{pmatrix}.\n$$\nStart from the definition of the infinite-horizon observability Gramian for a Hurwitz matrix $A$, and derive an explicit expression for the observability Gramian $W_{o} \\in \\mathbb{R}^{3 \\times 3}$ of the pair $(C,A)$. Then:\n- Justify from first principles why $W_{o}$ is positive semidefinite (PSD) and determine whether it is singular.\n- Using only the fundamental definition of the observability Gramian and properties that follow from it, identify the unobservable subspace of $(C,A)$ by characterizing $\\operatorname{ker}(W_{o})$ and verifying its invariance under $A$.\n- Express your final answer as the single nonzero unit-norm column vector that spans the unobservable subspace. If there are multiple valid choices, select the one whose first nonzero entry is positive.\n\nNo rounding is required. Provide the final answer as a single column vector. Do not include any units.", "solution": "The problem statement is first subjected to validation. The problem provides a continuous-time Linear Time-Invariant (LTI) system specified by a state matrix $A \\in \\mathbb{R}^{3 \\times 3}$ and an output matrix $C \\in \\mathbb{R}^{1 \\times 3}$, which are given as\n$$A = \\begin{pmatrix} -1 & 0 & 0 \\\\ 0 & -2 & 0 \\\\ 0 & 0 & -3 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix}.$$\nThe matrix $A$ is diagonal, and its eigenvalues are its diagonal entries: $\\lambda_1 = -1$, $\\lambda_2 = -2$, and $\\lambda_3 = -3$. Since all eigenvalues have negative real parts, the matrix $A$ is Hurwitz. This is the condition for the existence of the infinite-horizon observability Gramian $W_o$ as the unique solution to the Lyapunov equation $A^\\top W_o + W_o A = -C^\\top C$. The problem is scientifically grounded, well-posed, objective, and complete. All provided data and requested procedures are standard in control theory. Therefore, the problem is valid and we may proceed with the solution.\n\nThe infinite-horizon observability Gramian $W_o$ for a stable LTI system is defined by the integral\n$$W_o = \\int_{0}^{\\infty} e^{A^\\top \\tau} C^\\top C e^{A \\tau} \\,d\\tau.$$\nFirst, we compute the components of the integrand. Since matrix $A$ is diagonal, the state transition matrix $e^{At}$ is also diagonal:\n$$e^{At} = \\begin{pmatrix} e^{-t} & 0 & 0 \\\\ 0 & e^{-2t} & 0 \\\\ 0 & 0 & e^{-3t} \\end{pmatrix}.$$\nSince $A$ is a symmetric matrix ($A = A^\\top$), we have $e^{A^\\top t} = e^{At}$. The matrix $C^\\top C$ is given by\n$$C^\\top C = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}.$$\nThe term inside the integral is $e^{A^\\top t} C^\\top C e^{At}$. We can also write this as $(C e^{At})^\\top (C e^{At})$. Let us first compute the product $C e^{At}$:\n$$C e^{At} = \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} e^{-t} & 0 & 0 \\\\ 0 & e^{-2t} & 0 \\\\ 0 & 0 & e^{-3t} \\end{pmatrix} = \\begin{pmatrix} e^{-t} & e^{-2t} & 0 \\end{pmatrix}.$$\nNow we compute the integrand:\n$$(C e^{At})^\\top (C e^{At}) = \\begin{pmatrix} e^{-t} \\\\ e^{-2t} \\\\ 0 \\end{pmatrix} \\begin{pmatrix} e^{-t} & e^{-2t} & 0 \\end{pmatrix} = \\begin{pmatrix} e^{-2t} & e^{-3t} & 0 \\\\ e^{-3t} & e^{-4t} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}.$$\nTo find $W_o$, we integrate this matrix element-wise from $\\tau=0$ to $\\tau=\\infty$:\n$$W_o = \\int_{0}^{\\infty} \\begin{pmatrix} e^{-2\\tau} & e^{-3\\tau} & 0 \\\\ e^{-3\\tau} & e^{-4\\tau} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} d\\tau.$$\nThe individual integrals are:\n$$(W_o)_{11} = \\int_{0}^{\\infty} e^{-2\\tau} d\\tau = \\left[ -\\frac{1}{2}e^{-2\\tau} \\right]_0^\\infty = 0 - (-\\frac{1}{2}) = \\frac{1}{2}.$$\n$$(W_o)_{12} = (W_o)_{21} = \\int_{0}^{\\infty} e^{-3\\tau} d\\tau = \\left[ -\\frac{1}{3}e^{-3\\tau} \\right]_0^\\infty = 0 - (-\\frac{1}{3}) = \\frac{1}{3}.$$\n$$(W_o)_{22} = \\int_{0}^{\\infty} e^{-4\\tau} d\\tau = \\left[ -\\frac{1}{4}e^{-4\\tau} \\right]_0^\\infty = 0 - (-\\frac{1}{4}) = \\frac{1}{4}.$$\nThe other elements are zero. Thus, the observability Gramian is\n$$W_o = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{3} & 0 \\\\ \\frac{1}{3} & \\frac{1}{4} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}.$$\n\nNext, we justify from first principles why $W_o$ is positive semidefinite (PSD). For any vector $x \\in \\mathbb{R}^3$, the quadratic form is\n$$x^\\top W_o x = x^\\top \\left( \\int_{0}^{\\infty} e^{A^\\top \\tau} C^\\top C e^{A \\tau} d\\tau \\right) x.$$\nMoving the constant vector $x$ inside the integral gives\n$$x^\\top W_o x = \\int_{0}^{\\infty} x^\\top e^{A^\\top \\tau} C^\\top C e^{A \\tau} x \\, d\\tau = \\int_{0}^{\\infty} (C e^{A \\tau} x)^\\top (C e^{A \\tau} x) \\, d\\tau.$$\nLet $y(\\tau) = C e^{A \\tau} x$. Since $C \\in \\mathbb{R}^{1 \\times 3}$, $y(\\tau)$ is a scalar function. The integrand is then $\\|y(\\tau)\\|^2 = (y(\\tau))^2$.\n$$x^\\top W_o x = \\int_{0}^{\\infty} (y(\\tau))^2 d\\tau.$$\nSince the integrand $(y(\\tau))^2$ is non-negative for all $\\tau \\geq 0$, its integral over $[0, \\infty)$ must also be non-negative. Therefore, $x^\\top W_o x \\ge 0$ for all $x \\in \\mathbb{R}^3$, which is the definition of a positive semidefinite matrix.\n\nTo determine if $W_o$ is singular, we compute its determinant:\n$$\\det(W_o) = \\det\\begin{pmatrix} \\frac{1}{2} & \\frac{1}{3} & 0 \\\\ \\frac{1}{3} & \\frac{1}{4} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = 0.$$\nSince the determinant is zero, the matrix $W_o$ is singular.\n\nThe unobservable subspace of the pair $(C,A)$ is the kernel of the observability Gramian, $\\operatorname{ker}(W_o)$. We seek all vectors $x = (x_1, x_2, x_3)^\\top$ such that $W_o x = 0$:\n$$\\begin{pmatrix} \\frac{1}{2} & \\frac{1}{3} & 0 \\\\ \\frac{1}{3} & \\frac{1}{4} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.$$\nThis corresponds to the system of linear equations:\n\\begin{align*} \\frac{1}{2}x_1 + \\frac{1}{3}x_2 &= 0 \\\\ \\frac{1}{3}x_1 + \\frac{1}{4}x_2 &= 0 \\\\ 0 \\cdot x_3 &= 0 \\end{align*}\nThe determinant of the upper-left $2 \\times 2$ submatrix is $(\\frac{1}{2})(\\frac{1}{4}) - (\\frac{1}{3})(\\frac{1}{3}) = \\frac{1}{8} - \\frac{1}{9} = \\frac{1}{72} \\neq 0$. This submatrix is invertible, so the only solution for the first two equations is $x_1=0$ and $x_2=0$. The third equation, $0 = 0$, places no restriction on $x_3$. Thus, any vector in the kernel must be of the form $(0, 0, x_3)^\\top$. The kernel is the subspace spanned by the vector $(0, 0, 1)^\\top$:\n$$\\operatorname{ker}(W_o) = \\operatorname{span}\\left\\{ \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} \\right\\}.$$\nThis is the unobservable subspace.\n\nWe must verify that this subspace is $A$-invariant. An $A$-invariant subspace $\\mathcal{S}$ satisfies $A x \\in \\mathcal{S}$ for all $x \\in \\mathcal{S}$. Let $x$ be a vector in our found subspace, so $x = (0, 0, \\alpha)^\\top$ for some scalar $\\alpha \\in \\mathbb{R}$. Then,\n$$Ax = \\begin{pmatrix} -1 & 0 & 0 \\\\ 0 & -2 & 0 \\\\ 0 & 0 & -3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ \\alpha \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -3\\alpha \\end{pmatrix}.$$\nThe resulting vector is of the form $(0, 0, \\beta)^\\top$ with $\\beta = -3\\alpha$, so it is still in $\\operatorname{span}\\{(0, 0, 1)^\\top\\}$. Thus, $\\operatorname{ker}(W_o)$ is indeed an $A$-invariant subspace.\n\nThe final answer must be the single nonzero unit-norm column vector spanning this subspace, with the first nonzero entry being positive. The basis vector for the unobservable subspace can be chosen as $v = (0, 0, 1)^\\top$. The norm of this vector is $\\|v\\|_2 = \\sqrt{0^2 + 0^2 + 1^2} = 1$, so it is already a unit-norm vector. The two possible unit-norm basis vectors are $(0, 0, 1)^\\top$ and $(0, 0, -1)^\\top$. The first nonzero entry of $v=(0,0,1)^\\top$ is the third entry, which is $1$. Since $1 > 0$, this vector satisfies the condition.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}}\n$$", "id": "2728907"}, {"introduction": "Building on the fundamentals, we now explore the nuances of observability in more complex scenarios. This exercise presents a linear time-varying (LTV) system where the nature of observability changes over time. You will find that observing a system for a finite duration does not always guarantee that its long-term behavior can be determined, especially when unstable dynamics are hidden from the output [@problem_id:2728896]. This problem illustrates the crucial distinction between finite-time observability and the more robust property of detectability.", "problem": "Consider the linear time-varying (LTV) continuous-time system with state dimension $n=2$ given by\n$\\dot{x}(t)=A(t)\\,x(t)$ and $y(t)=C(t)\\,x(t)$ for $t\\geq 0$, where\n$A(t)$ and $C(t)$ are piecewise constant matrices defined by\n$A(t)=\\begin{cases}\n\\begin{pmatrix}\n0 & 0\\\\\n0 & 0\n\\end{pmatrix}, & 0\\leq t<1,\\\\\n\\begin{pmatrix}\n1 & 0\\\\\n0 & -1\n\\end{pmatrix}, & t\\geq 1,\n\\end{cases}\n\\quad\nC(t)=\\begin{cases}\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 1\n\\end{pmatrix}, & 0\\leq t<1,\\\\\n\\begin{pmatrix}\n0 & 0\n\\end{pmatrix}, & t\\geq 1.\n\\end{cases}\n$\nUsing only foundational definitions for the state-transition matrix and the finite-horizon observability Gramian, do the following:\n1) Compute the finite-horizon observability Gramian $W_{o}(0,1)$ associated with the interval $[0,1]$ and determine its determinant.\n2) Then, using only the definitions of observability and detectability for time-varying systems, argue whether the system is detectable over $[0,\\infty)$, and justify your conclusion by identifying any unstable unobservable modes that may exist for $t\\geq 1$.\nYour final reported answer should be the single numerical value of $\\det\\!\\big(W_{o}(0,1)\\big)$. No rounding is required.", "solution": "The problem as stated is well-posed and scientifically sound. It consists of two parts: the computation of an observability Gramian and its determinant, followed by an analysis of system detectability. We shall address each part in sequence, adhering strictly to the provided definitions.\n\nFirst, we compute the finite-horizon observability Gramian $W_{o}(0,1)$ for the interval $[0,1]$. The definition of the observability Gramian for a continuous-time LTV system on an interval $[t_0, t_f]$ is given by the integral:\n$$\nW_{o}(t_0, t_f) = \\int_{t_0}^{t_f} \\Phi(s, t_0)^T C(s)^T C(s) \\Phi(s, t_0) \\, ds\n$$\nwhere $\\Phi(t, \\tau)$ is the state-transition matrix of the system. For this problem, we are given $t_0=0$ and $t_f=1$. The integral is:\n$$\nW_{o}(0, 1) = \\int_{0}^{1} \\Phi(s, 0)^T C(s)^T C(s) \\Phi(s, 0) \\, ds\n$$\nOver the interval of integration $s \\in [0, 1)$, the system matrices are constant:\n$$\nA(s) = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} = 0_{2\\times2}\n$$\n$$\nC(s) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I_2\n$$\nThe state-transition matrix $\\Phi(t, \\tau)$ is the solution to the matrix differential equation $\\frac{d}{dt}\\Phi(t, \\tau) = A(t)\\Phi(t, \\tau)$ with the initial condition $\\Phi(\\tau, \\tau) = I$. For $t, \\tau \\in [0, 1)$, $A(t)$ is the zero matrix. Thus, $\\frac{d}{dt}\\Phi(t, \\tau) = 0_{2\\times2}$, which upon integration from $\\tau$ to $t$ yields $\\Phi(t, \\tau) = \\Phi(\\tau, \\tau) = I_2$. Specifically, for the required term $\\Phi(s, 0)$ where $s \\in [0, 1)$, we have $\\Phi(s, 0) = I_2$.\n\nSubstituting these into the integrand, we find that for $s \\in [0, 1)$, the integrand $\\Phi(s, 0)^T C(s)^T C(s) \\Phi(s, 0)$ is constant and equal to $I_2$.\nNow we can evaluate the integral for $W_{o}(0, 1)$:\n$$\nW_{o}(0, 1) = \\int_{0}^{1} I_2 \\, ds = \\int_{0}^{1} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\, ds = \\begin{pmatrix} \\int_0^1 1 \\, ds & 0 \\\\ 0 & \\int_0^1 1 \\, ds \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I_2\n$$\nThe determinant of the observability Gramian over $[0, 1]$ is therefore:\n$$\n\\det(W_{o}(0, 1)) = \\det(I_2) = 1\n$$\nThis completes the first part of the problem.\n\nSecond, we analyze the detectability of the system over the interval $[0, \\infty)$. An LTV system is defined as detectable if, for any initial time $t_0$, any initial state $x(t_0)$ that generates a zero output for all subsequent time ($y(t) = C(t)x(t) = 0$ for all $t \\ge t_0$) results in a state trajectory that converges to the origin ($\\lim_{t \\to \\infty} x(t) = 0$).\n\nLet us examine the system for $t \\ge 1$. Over this semi-infinite interval, the system is time-invariant with matrices:\n$$\nA = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n$$\n$$\nC = \\begin{pmatrix} 0 & 0 \\end{pmatrix}\n$$\nFor any state $x(t)$ with $t \\ge 1$, the output is given by $y(t) = C x(t) = \\begin{pmatrix} 0 & 0 \\end{pmatrix} x(t) = 0$. This means that for any initial time $t_0 \\ge 1$, any initial state $x(t_0)$ will produce a zero output for all $t \\ge t_0$.\n\nAccording to the definition of detectability, for any such $x(t_0)$, the resulting state trajectory $x(t)$ must tend to zero as $t \\to \\infty$. The state evolution for $t \\ge t_0 \\ge 1$ is given by $x(t) = \\exp(A(t-t_0)) x(t_0)$. The state-transition matrix for this LTI system is:\n$$\n\\exp(A\\tau) = \\begin{pmatrix} \\exp(\\tau) & 0 \\\\ 0 & \\exp(-\\tau) \\end{pmatrix}\n$$\nLet us choose $t_0 = 1$ and a non-zero initial state, for example, $x(1) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. As established, this initial state generates a zero output for all $t \\ge 1$. The resulting state trajectory is:\n$$\nx(t) = \\exp(A(t-1)) x(1) = \\begin{pmatrix} \\exp(t-1) & 0 \\\\ 0 & \\exp(-(t-1)) \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\exp(t-1) \\\\ 0 \\end{pmatrix}\n$$\nAs $t \\to \\infty$, the first component of the state, $x_1(t) = \\exp(t-1)$, diverges to infinity. Therefore, $\\lim_{t \\to \\infty} x(t) \\neq 0$. This provides a direct counterexample, proving that the system is not detectable.\n\nThe conclusion can be further justified by identifying the unstable unobservable modes for $t \\ge 1$. The LTI system $(A,C)$ for $t \\ge 1$ has eigenvalues $\\lambda_1 = 1$ and $\\lambda_2 = -1$. The eigenvalue $\\lambda_1 = 1$ is unstable since its real part is positive. The dynamics associated with this eigenvalue represent an unstable mode.\nThe observability of these modes is determined by the observability matrix $\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}$.\n$$\nC = \\begin{pmatrix} 0 & 0 \\end{pmatrix}\n$$\n$$\nCA = \\begin{pmatrix} 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\end{pmatrix}\n$$\nThus, $\\mathcal{O} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}$. The null space of $\\mathcal{O}$ is the entire state space $\\mathbb{R}^2$. This means that for $t \\ge 1$, the system is completely unobservable; no component of the state can be determined from the output. Since the unstable mode corresponding to $\\lambda_1 = 1$ lies within this unobservable subspace, there exists an unstable unobservable mode. The existence of such a mode is the definitive condition for a system to be not detectable.", "answer": "$$\n\\boxed{1}\n$$", "id": "2728896"}, {"introduction": "In our final practice, we shift from the theoretical question of *whether* a system is observable to the practical question of *how* observable it is. This exercise explores the concept of \"weak observability\" by analyzing the condition number of the Gramian, a key indicator of numerical sensitivity. By examining how the condition number behaves as a system approaches an unobservable state, you will gain insight into the profound challenges that arise in numerical state estimation and why a poorly observable system can be difficult to manage in practice [@problem_id:2728898].", "problem": "Consider the continuous-time linear time-invariant (LTI) system with state $x \\in \\mathbb{R}^{2}$ and output $y \\in \\mathbb{R}$ given by $\\dot{x}(t) = A x(t)$ and $y(t) = C x(t)$, where\n$$\nA = \\begin{pmatrix}\n-1 & 0 \\\\\n0 & -\\beta\n\\end{pmatrix}, \n\\qquad\nC = \\begin{pmatrix}\n1 & 1\n\\end{pmatrix},\n$$\nwith parameter $\\beta > 0$ and $\\beta \\neq 1$. The system matrix $A$ is Hurwitz for all such $\\beta$, so the infinite-horizon observability Gramian exists.\n\nStarting only from fundamental definitions of state transition and observability for continuous-time LTI systems, derive the infinite-horizon observability Gramian $W_{o}$ for this system, prove that $W_{o}$ is positive definite for all $\\beta > 0$, $\\beta \\neq 1$, and compute the spectral ($2$-norm) condition number $\\kappa_{2}(W_{o})$ as an explicit closed-form function of $\\beta$. Then, using your expression, explain why positive definiteness of $W_{o}$ does not imply a small condition number by analyzing the behavior of $\\kappa_{2}(W_{o})$ as $\\beta \\to 1$, and discuss the implications of large $\\kappa_{2}(W_{o})$ for numerical state estimation from the output $y(t)$.\n\nProvide as your final answer the closed-form analytic expression for $\\kappa_{2}(W_{o})$ as a function of $\\beta$. No numerical approximation is required, and no units are needed. The final answer must be a single closed-form expression.", "solution": "The problem as stated is valid. It is scientifically grounded, self-contained, and well-posed within the established framework of linear control theory. All required data and constraints are provided, and there are no internal contradictions. I will now proceed with a complete solution.\n\nThe continuous-time linear time-invariant (LTI) system is described by\n$$ \\dot{x}(t) = A x(t), \\quad y(t) = C x(t) $$\nwith state $x \\in \\mathbb{R}^{2}$, output $y \\in \\mathbb{R}$, and matrices\n$$ A = \\begin{pmatrix} -1 & 0 \\\\ 0 & -\\beta \\end{pmatrix}, \\qquad C = \\begin{pmatrix} 1 & 1 \\end{pmatrix} $$\nwhere $\\beta > 0$ and $\\beta \\neq 1$. The matrix $A$ is Hurwitz, as its eigenvalues, $\\lambda_1 = -1$ and $\\lambda_2 = -\\beta$, both have negative real parts given the constraint $\\beta > 0$.\n\nFirst, we derive the infinite-horizon observability Gramian $W_o$. The fundamental definition is given by the integral:\n$$ W_o = \\int_{0}^{\\infty} e^{A^\\top \\tau} C^\\top C e^{A \\tau} d\\tau $$\nSince $A$ is a diagonal matrix, its transpose is itself, $A^\\top = A$. The state transition matrix $e^{A\\tau}$ is also diagonal:\n$$ e^{A\\tau} = \\begin{pmatrix} e^{-\\tau} & 0 \\\\ 0 & e^{-\\beta \\tau} \\end{pmatrix} $$\nThe term $C^\\top C$ is calculated as:\n$$ C^\\top C = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} $$\nThe integrand is then:\n$$ e^{A^\\top \\tau} C^\\top C e^{A \\tau} = \\begin{pmatrix} e^{-\\tau} & 0 \\\\ 0 & e^{-\\beta \\tau} \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} e^{-\\tau} & 0 \\\\ 0 & e^{-\\beta \\tau} \\end{pmatrix} $$\n$$ = \\begin{pmatrix} e^{-\\tau} & 0 \\\\ 0 & e^{-\\beta \\tau} \\end{pmatrix} \\begin{pmatrix} e^{-\\tau} & e^{-\\beta \\tau} \\\\ e^{-\\tau} & e^{-\\beta \\tau} \\end{pmatrix} = \\begin{pmatrix} e^{-2\\tau} & e^{-(1+\\beta)\\tau} \\\\ e^{-(1+\\beta)\\tau} & e^{-2\\beta \\tau} \\end{pmatrix} $$\nWe integrate this matrix element-wise from $\\tau=0$ to $\\tau=\\infty$. Since $\\beta > 0$, the exponents $-2$, $-(1+\\beta)$, and $-2\\beta$ are all strictly negative, ensuring the convergence of the integrals.\n$$ W_{o,11} = \\int_{0}^{\\infty} e^{-2\\tau} d\\tau = \\left[ -\\frac{1}{2} e^{-2\\tau} \\right]_{0}^{\\infty} = \\frac{1}{2} $$\n$$ W_{o,12} = W_{o,21} = \\int_{0}^{\\infty} e^{-(1+\\beta)\\tau} d\\tau = \\left[ -\\frac{1}{1+\\beta} e^{-(1+\\beta)\\tau} \\right]_{0}^{\\infty} = \\frac{1}{1+\\beta} $$\n$$ W_{o,22} = \\int_{0}^{\\infty} e^{-2\\beta \\tau} d\\tau = \\left[ -\\frac{1}{2\\beta} e^{-2\\beta \\tau} \\right]_{0}^{\\infty} = \\frac{1}{2\\beta} $$\nThus, the observability Gramian is:\n$$ W_o = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{1+\\beta} \\\\ \\frac{1}{1+\\beta} & \\frac{1}{2\\beta} \\end{pmatrix} $$\nAlternatively, $W_o$ is the unique symmetric solution to the observability Lyapunov equation $A^\\top W_o + W_o A + C^\\top C = 0$, which yields the same result.\n\nNext, we prove that $W_o$ is positive definite for all $\\beta > 0, \\beta \\neq 1$. For a $2 \\times 2$ symmetric matrix, this requires its two leading principal minors to be positive.\nThe first minor is $W_{o,11} = \\frac{1}{2} > 0$.\nThe second minor is the determinant of $W_o$:\n$$ \\det(W_o) = \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2\\beta}\\right) - \\left(\\frac{1}{1+\\beta}\\right)^2 = \\frac{1}{4\\beta} - \\frac{1}{(1+\\beta)^2} $$\n$$ = \\frac{(1+\\beta)^2 - 4\\beta}{4\\beta(1+\\beta)^2} = \\frac{1 + 2\\beta + \\beta^2 - 4\\beta}{4\\beta(1+\\beta)^2} = \\frac{\\beta^2 - 2\\beta + 1}{4\\beta(1+\\beta)^2} = \\frac{(\\beta-1)^2}{4\\beta(1+\\beta)^2} $$\nGiven $\\beta > 0$, the denominator $4\\beta(1+\\beta)^2$ is strictly positive. Given $\\beta \\neq 1$, the numerator $(\\beta-1)^2$ is also strictly positive. Therefore, $\\det(W_o) > 0$. Since both leading principal minors are positive, $W_o$ is positive definite for all $\\beta > 0, \\beta \\neq 1$. This is consistent with the fact that the pair $(A, C)$ is observable if and only if $\\beta \\neq 1$.\n\nNow, we compute the spectral ($2$-norm) condition number $\\kappa_2(W_o)$, which is the ratio of the largest to the smallest eigenvalue of $W_o$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(W_o - \\lambda I) = 0$:\n$$ \\lambda^2 - \\text{tr}(W_o)\\lambda + \\det(W_o) = 0 $$\nWe have the trace $\\text{tr}(W_o) = \\frac{1}{2} + \\frac{1}{2\\beta} = \\frac{\\beta+1}{2\\beta}$ and the determinant calculated previously. The eigenvalues are:\n$$ \\lambda = \\frac{\\text{tr}(W_o) \\pm \\sqrt{\\text{tr}(W_o)^2 - 4\\det(W_o)}}{2} $$\nLet's analyze the term under the square root:\n$$ \\text{tr}(W_o)^2 - 4\\det(W_o) = \\left(\\frac{\\beta+1}{2\\beta}\\right)^2 - 4\\frac{(\\beta-1)^2}{4\\beta(1+\\beta)^2} = \\frac{(\\beta+1)^2}{4\\beta^2} - \\frac{(\\beta-1)^2}{\\beta(1+\\beta)^2} $$\nThis expression can be simplified. A more general identity is $\\text{tr}(M)^2 - 4\\det(M) = (m_{11}-m_{22})^2 + 4m_{12}^2$ for a general $2\\times2$ symmetric matrix $M$. Using this for $W_o$:\n$$ (W_{o,11}-W_{o,22})^2 + 4W_{o,12}^2 = \\left(\\frac{1}{2} - \\frac{1}{2\\beta}\\right)^2 + 4\\left(\\frac{1}{1+\\beta}\\right)^2 = \\left(\\frac{\\beta-1}{2\\beta}\\right)^2 + \\frac{4}{(1+\\beta)^2} $$\nLet $S = \\sqrt{\\left(\\frac{\\beta-1}{2\\beta}\\right)^2 + \\frac{4}{(1+\\beta)^2}}$. The eigenvalues are $\\lambda_{\\max} = \\frac{1}{2} (\\text{tr}(W_o) + S)$ and $\\lambda_{\\min} = \\frac{1}{2} (\\text{tr}(W_o) - S)$.\nThe condition number is:\n$$ \\kappa_2(W_o) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{\\text{tr}(W_o) + S}{\\text{tr}(W_o) - S} $$\nLet's find a more explicit expression for $S$:\n$$ S^2 = \\frac{(\\beta-1)^2}{4\\beta^2} + \\frac{4}{(1+\\beta)^2} = \\frac{(\\beta-1)^2(1+\\beta)^2 + 16\\beta^2}{4\\beta^2(1+\\beta)^2} = \\frac{(\\beta^2-1)^2 + 16\\beta^2}{4\\beta^2(1+\\beta)^2} $$\n$$ S^2 = \\frac{\\beta^4-2\\beta^2+1 + 16\\beta^2}{4\\beta^2(1+\\beta)^2} = \\frac{\\beta^4+14\\beta^2+1}{4\\beta^2(1+\\beta)^2} $$\nSince $\\beta > 0$, we have $S = \\frac{\\sqrt{\\beta^4+14\\beta^2+1}}{2\\beta(1+\\beta)}$.\nSubstituting $S$ and $\\text{tr}(W_o) = \\frac{\\beta+1}{2\\beta}$ into the expression for $\\kappa_2(W_o)$:\n$$ \\kappa_2(W_o) = \\frac{\\frac{\\beta+1}{2\\beta} + \\frac{\\sqrt{\\beta^4+14\\beta^2+1}}{2\\beta(1+\\beta)}}{\\frac{\\beta+1}{2\\beta} - \\frac{\\sqrt{\\beta^4+14\\beta^2+1}}{2\\beta(1+\\beta)}} $$\nMultiplying numerator and denominator by $2\\beta(1+\\beta)$ gives the final simplified expression:\n$$ \\kappa_2(W_o) = \\frac{(\\beta+1)^2 + \\sqrt{\\beta^4+14\\beta^2+1}}{(\\beta+1)^2 - \\sqrt{\\beta^4+14\\beta^2+1}} $$\n\nLastly, we analyze the behavior and implications. As $\\beta \\to 1$, the system approaches unobservability because the two system modes become identical, making them indistinguishable from the output $y(t) = x_1(t)+x_2(t)$.\nLet's examine the condition number in this limit:\n$$ \\lim_{\\beta \\to 1} \\left( (\\beta+1)^2 \\right) = (1+1)^2 = 4 $$\n$$ \\lim_{\\beta \\to 1} \\sqrt{\\beta^4+14\\beta^2+1} = \\sqrt{1+14+1} = \\sqrt{16} = 4 $$\nThe expression for $\\kappa_2(W_o)$ becomes:\n$$ \\lim_{\\beta \\to 1} \\kappa_2(W_o) = \\frac{4+4}{4-4} \\to \\infty $$\nThis analysis demonstrates that even though $W_o$ is positive definite for any $\\beta \\neq 1$, its condition number can become arbitrarily large as $\\beta$ approaches $1$. Positive definiteness only guarantees that $\\lambda_{\\min} > 0$; it does not bound the ratio $\\lambda_{\\max}/\\lambda_{\\min}$.\nThe implications for numerical state estimation are severe. The observability Gramian appears in many estimation contexts. The output energy is related to the initial state by $E_y = \\int_0^\\infty y(t)^2 dt = x(0)^\\top W_o x(0)$. A large condition number for $W_o$ implies that the level sets of $E_y$ are highly elongated ellipsoids in the state space. This means the output is very sensitive to initial state components in some directions (corresponding to $\\lambda_{\\max}$) but very insensitive to components in others (corresponding to $\\lambda_{\\min}$). The process of estimating the state $x$ from measurements of $y$ involves, in effect, inverting the relationship defined by $W_o$. When $W_o$ is ill-conditioned (large $\\kappa_2$), this inversion is numerically unstable. Small amounts of noise in the measurement $y(t)$ can lead to very large errors in the estimated state, especially in the \"weakly observable\" directions associated with small eigenvalues of $W_o$. For $\\beta \\approx 1$, this weakly observable direction is approximately that of the unobservable subspace at $\\beta=1$, which is $\\operatorname{span}\\left\\{ \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\right\\}$.", "answer": "$$ \\boxed{\\frac{(\\beta+1)^2 + \\sqrt{\\beta^4+14\\beta^2+1}}{(\\beta+1)^2 - \\sqrt{\\beta^4+14\\beta^2+1}}} $$", "id": "2728898"}]}