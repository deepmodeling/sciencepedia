{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with the canonical \"hello world\" of optimal control: the minimum-time problem for a single integrator. This exercise is foundational because it allows us to apply the complete machinery of the Pontryagin Minimum Principle (PMP) in the simplest non-trivial setting. By working through the state and costate equations and applying the minimization and transversality conditions, you will derive the intuitive \"bang-bang\" control strategy and explicitly verify the crucial theoretical result that the optimal Hamiltonian remains zero for free final-time problems [@problem_id:2732811].", "problem": "Consider the minimum-time control problem for a single integrator with bounded control. Let the state be scalar $x(t) \\in \\mathbb{R}$ and the control be $u(t) \\in \\mathbb{R}$ with the dynamics\n$$\n\\dot{x}(t) = u(t),\n$$\nsubject to the pointwise bound $|u(t)| \\leq 1$ for all $t$. The initial condition is fixed at $x(0) = x_0$, and the terminal state is fixed at $x(T) = x_f$ with $x_0, x_f \\in \\mathbb{R}$ and $x_0 \\neq x_f$. The terminal time $T$ is free and the objective is to minimize the transfer time, i.e., minimize\n$$\nJ = T.\n$$\nUsing only the fundamental statement of Pontryagin’s minimum principle (PMP), understood in its minimization form with Hamiltonian defined as $H(x,u,\\lambda) = \\lambda f(x,u) + L(x,u)$ where $\\lambda$ is the costate, derive the necessary conditions for optimality. Then determine explicitly:\n- the optimal control $u^{\\ast}(t)$,\n- the costate $\\lambda(t)$,\n- the optimal terminal time $T^{\\ast}$,\nand verify directly that the Hamiltonian along the optimal solution satisfies $H^{\\ast}(t) \\equiv 0$ for all $t \\in [0, T^{\\ast}]$. \n\nReport as your final answer the closed-form expression for the optimal terminal time $T^{\\ast}$ in terms of $x_0$ and $x_f$. No numerical evaluation is required.", "solution": "The problem is to find the minimum time to transfer a system from an initial state $x(0) = x_0$ to a final state $x(T) = x_f$ for a single integrator. The problem is valid as it is a standard, well-posed problem in optimal control theory with all necessary components defined. We will proceed with the solution using Pontryagin's Minimum Principle (PMP).\n\nThe objective is to minimize the final time $T$, which can be written as the functional:\n$$\nJ = T = \\int_{0}^{T} 1 \\, dt\n$$\nThe Lagrangian (or running cost) is therefore $L(x, u) = 1$. The state dynamics are given by $f(x, u) = u$.\n$$\n\\dot{x}(t) = u(t)\n$$\nThe control $u(t)$ is constrained by $|u(t)| \\leq 1$. The initial and final states are fixed: $x(0) = x_0$ and $x(T) = x_f$, with $x_0 \\neq x_f$. The final time $T$ is free.\n\nAccording to the problem statement, the Hamiltonian $H$ for this minimization problem is defined as:\n$$\nH(x, u, \\lambda) = L(x, u) + \\lambda f(x, u)\n$$\nSubstituting our specific functions, we have:\n$$\nH(x, u, \\lambda) = 1 + \\lambda(t) u(t)\n$$\nHere, $\\lambda(t)$ is the costate (or adjoint) variable. The necessary conditions for optimality from Pontryagin's Minimum Principle are:\n\n$1$. The state equation: The optimal state trajectory $x^{\\ast}(t)$ and control $u^{\\ast}(t)$ must satisfy the system dynamics.\n$$\n\\dot{x}^{\\ast}(t) = \\frac{\\partial H}{\\partial \\lambda} = u^{\\ast}(t)\n$$\n\n$2$. The costate equation: The costate $\\lambda(t)$ must satisfy the adjoint differential equation.\n$$\n\\dot{\\lambda}(t) = -\\frac{\\partial H}{\\partial x} = -\\frac{\\partial}{\\partial x} (1 + \\lambda(t)u(t)) = 0\n$$\nIntegrating this equation, we find that the costate must be a constant for all $t \\in [0, T^{\\ast}]$:\n$$\n\\lambda(t) = \\lambda_c \\quad (\\text{constant})\n$$\n\n$3$. The minimization condition: For all $t \\in [0, T^{\\ast}]$, the optimal control $u^{\\ast}(t)$ must minimize the Hamiltonian over the set of all admissible controls $U = \\{u \\in \\mathbb{R} : |u| \\leq 1\\}$.\n$$\nH(x^{\\ast}(t), u^{\\ast}(t), \\lambda(t)) \\leq H(x^{\\ast}(t), u, \\lambda(t)) \\quad \\forall u \\in U\n$$\nThe Hamiltonian is $H = 1 + \\lambda_c u$. This is a linear function of $u$. The control that minimizes this expression depends on the sign of the constant costate $\\lambda_c$.\n- If $\\lambda_c > 0$, the term $\\lambda_c u$ is minimized when $u$ is at its most negative value. Thus, $u^{\\ast}(t) = -1$.\n- If $\\lambda_c  0$, the term $\\lambda_c u$ is minimized when $u$ is at its most positive value. Thus, $u^{\\ast}(t) = +1$.\n- If $\\lambda_c = 0$, the Hamiltonian is $H = 1$, and is independent of $u$. The minimization condition provides no information about the control.\n\n$4$. The transversality condition: For a problem with a fixed terminal state and free terminal time, the Hamiltonian evaluated along the optimal trajectory must be identically zero.\n$$\nH^{\\ast}(t) = H(x^{\\ast}(t), u^{\\ast}(t), \\lambda(t)) \\equiv 0 \\quad \\text{for all } t \\in [0, T^{\\ast}]\n$$\nThis gives us the condition:\n$$\n1 + \\lambda_c u^{\\ast}(t) = 0\n$$\nFrom this equation, we can immediately see that the case $\\lambda_c = 0$ is impossible, as it would lead to the contradiction $1 = 0$. Therefore, the costate $\\lambda_c$ must be non-zero. This resolves the ambiguity in the minimization condition for $\\lambda_c=0$. Since $\\lambda_c$ is a non-zero constant, from $1 + \\lambda_c u^{\\ast}(t) = 0$, it follows that the optimal control $u^{\\ast}(t)$ must also be constant throughout the trajectory, with $u^{\\ast}(t) = -1/\\lambda_c$.\n\nNow we combine the minimization and transversality conditions to determine the values of $\\lambda_c$ and $u^{\\ast}$:\n- If we assume $\\lambda_c > 0$, the minimization condition requires $u^{\\ast}(t) = -1$. Substituting this into the transversality condition gives $1 + \\lambda_c(-1) = 0$, which yields $\\lambda_c = 1$. This is consistent with the initial assumption $\\lambda_c > 0$.\n- If we assume $\\lambda_c  0$, the minimization condition requires $u^{\\ast}(t) = +1$. Substituting this into the transversality condition gives $1 + \\lambda_c(+1) = 0$, which yields $\\lambda_c = -1$. This is also consistent with the initial assumption $\\lambda_c  0$.\n\nSo we have two possible scenarios for the optimal control, which remains constant over the interval $[0, T^{\\ast}]$:\n- Scenario A: $u^{\\ast}(t) = -1$ (which corresponds to $\\lambda(t) = 1$)\n- Scenario B: $u^{\\ast}(t) = +1$ (which corresponds to $\\lambda(t) = -1$)\n\nTo determine which scenario applies, we must use the boundary conditions for the state. We integrate the state equation $\\dot{x}(t) = u^{\\ast}(t)$ from $t=0$ to $t=T^{\\ast}$:\n$$\n\\int_{0}^{T^{\\ast}} \\dot{x}(t) \\, dt = \\int_{0}^{T^{\\ast}} u^{\\ast}(t) \\, dt\n$$\nSince $u^{\\ast}$ is constant, we have:\n$$\nx(T^{\\ast}) - x(0) = u^{\\ast} \\int_{0}^{T^{\\ast}} dt\n$$\n$$\nx_f - x_0 = u^{\\ast} T^{\\ast}\n$$\nThe minimal time $T^{\\ast}$ must be positive, as $x_0 \\neq x_f$. Therefore, we can write:\n$$\nT^{\\ast} = \\frac{x_f - x_0}{u^{\\ast}}\n$$\nFor $T^{\\ast}$ to be positive, the sign of $u^{\\ast}$ must be the same as the sign of the displacement $x_f - x_0$.\n- If $x_f > x_0$, then $x_f - x_0 > 0$. We must choose $u^{\\ast} = +1$. This corresponds to Scenario B.\n- If $x_f  x_0$, then $x_f - x_0  0$. We must choose $u^{\\ast} = -1$. This corresponds to Scenario A.\n\nIn summary, the optimal solution is as follows:\n- The optimal control $u^{\\ast}(t)$ is given by the sign of the total displacement:\n$$\nu^{\\ast}(t) = \\text{sgn}(x_f - x_0)\n$$\nfor all $t \\in [0, T^{\\ast}]$. Since $x_0 \\neq x_f$, $\\text{sgn}(x_f - x_0)$ is either $+1$ or $-1$.\n- The costate $\\lambda(t)$ is constant and determined by the optimal control:\n$$\n\\lambda(t) = \\lambda_c = -\\frac{1}{u^{\\ast}} = -\\frac{1}{\\text{sgn}(x_f - x_0)} = -\\text{sgn}(x_f - x_0)\n$$\n- The optimal terminal time $T^{\\ast}$ is found by substituting the optimal control into the equation for the time:\n$$\nT^{\\ast} = \\frac{x_f - x_0}{u^{\\ast}} = \\frac{x_f - x_0}{\\text{sgn}(x_f - x_0)}\n$$\nFor any non-zero real number $z$, we have $z / \\text{sgn}(z) = |z|$. Therefore, the optimal time is:\n$$\nT^{\\ast} = |x_f - x_0|\n$$\n\nFinally, we are asked to verify directly that the Hamiltonian along the optimal solution is identically zero.\nThe optimal Hamiltonian is $H^{\\ast}(t) = 1 + \\lambda(t) u^{\\ast}(t)$. Substituting the optimal values we found:\n$$\nH^{\\ast}(t) = 1 + (-\\text{sgn}(x_f - x_0)) \\times (\\text{sgn}(x_f - x_0))\n$$\nSince $\\text{sgn}(z) \\times \\text{sgn}(z) = (\\text{sgn}(z))^2 = 1$ for any $z \\neq 0$, and we know $x_f - x_0 \\neq 0$:\n$$\nH^{\\ast}(t) = 1 - 1 = 0\n$$\nThis holds for all $t \\in [0, T^{\\ast}]$. The verification is complete and confirms the consistency of our derived solution with the transversality condition that we used in the derivation.\n\nThe final expression for the optimal terminal time $T^{\\ast}$ in terms of $x_0$ and $x_f$ is $|x_f - x_0|$.", "answer": "$$\n\\boxed{|x_f - x_0|}\n$$", "id": "2732811"}, {"introduction": "Building on the single integrator, we now advance to the double integrator, a fundamental model representing many physical systems like a simple mass under force. This problem introduces a new layer of complexity, as the control decision now depends on a time-varying **switching function** derived from the costate dynamics. This practice is designed to solidify your understanding of how the PMP choreographs the sequence of control actions, showing how the sign of this switching function dictates when to apply maximum acceleration or deceleration to reach the target state in minimum time [@problem_id:2732750].", "problem": "Consider the control-affine system with two states $x_{1}$ and $x_{2}$ and a scalar control $u$ subject to a hard magnitude constraint,\n$$\n\\dot{x}_{1}(t)=x_{2}(t),\\qquad \\dot{x}_{2}(t)=u(t),\\qquad |u(t)|\\le 1,\n$$\nwith initial condition $x(0)=x_{0}\\in\\mathbb{R}^{2}$ and terminal condition $x(T)=0\\in\\mathbb{R}^{2}$ at a free final time $T\\ge 0$. Formulate the normal minimum-time optimal control problem by specifying the performance index, admissible control set, and endpoint constraints. Then, starting from the definition of Pontryagin’s Minimum Principle (PMP), construct the Hamiltonian, derive the costate dynamics, state the appropriate transversality condition associated with free final time and fixed terminal state, and characterize the minimizing control including any switching logic. Define the switching function rigorously from first principles and derive its explicit closed-form time dependence by solving the costate equations.\n\nYour final reported quantity must be the explicit analytic expression for the switching function as a function of time $t$ and the integration constants that arise from solving the costate dynamics. Provide this final expression in closed form. No numerical evaluation is required. The final answer must be a single analytic expression without units.", "solution": "The problem as stated is a standard, well-posed problem in optimal control theory and is thus deemed valid. We shall proceed with the derivation.\n\nFirst, we formalize the normal minimum-time optimal control problem. The objective is to minimize the final time $T$. This is equivalent to minimizing the cost functional $J$, which is the integral of the running cost $L(x, u) = 1$ over the time interval $[0, T]$.\nThe performance index is:\n$$\nJ(u) = \\int_{0}^{T} 1 \\, dt = T\n$$\nThe system state is given by the vector $x(t) = \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix} \\in \\mathbb{R}^2$. The state dynamics are described by the vector field $f(x, u)$:\n$$\n\\dot{x}(t) = f(x(t), u(t)) = \\begin{pmatrix} x_{2}(t) \\\\ u(t) \\end{pmatrix}\n$$\nThe control input $u(t)$ must be selected from the set of admissible controls $\\mathcal{U}$, which is defined by the hard magnitude constraint:\n$$\n\\mathcal{U} = \\{ u \\in \\mathbb{R} : |u| \\le 1 \\}\n$$\nThe endpoint constraints are the initial and terminal conditions on the state vector:\n$$\nx(0) = x_{0} = \\begin{pmatrix} x_{1,0} \\\\ x_{2,0} \\end{pmatrix}, \\quad x(T) = 0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThe final time $T \\ge 0$ is free.\n\nWe apply Pontryagin's Minimum Principle (PMP) to find the optimal control law. The principle necessitates the introduction of a costate vector $\\lambda(t) = \\begin{pmatrix} \\lambda_{1}(t) \\\\ \\lambda_{2}(t) \\end{pmatrix} \\in \\mathbb{R}^2$. The Hamiltonian $H(x, u, \\lambda)$ is defined as:\n$$\nH(x, u, \\lambda) = L(x, u) + \\lambda^{T}f(x, u)\n$$\nSubstituting the specific forms of $L$ and $f$ for this problem, we obtain:\n$$\nH(x, u, \\lambda) = 1 + \\begin{pmatrix} \\lambda_{1}  \\lambda_{2} \\end{pmatrix} \\begin{pmatrix} x_{2} \\\\ u \\end{pmatrix} = 1 + \\lambda_{1}(t)x_{2}(t) + \\lambda_{2}(t)u(t)\n$$\nThe costate dynamics are given by the adjoint equations, $\\dot{\\lambda}(t) = -\\nabla_{x} H(x(t), u(t), \\lambda(t))$:\n$$\n\\dot{\\lambda}_{1}(t) = -\\frac{\\partial H}{\\partial x_{1}} = -\\frac{\\partial}{\\partial x_{1}}(1 + \\lambda_{1}x_{2} + \\lambda_{2}u) = 0\n$$\n$$\n\\dot{\\lambda}_{2}(t) = -\\frac{\\partial H}{\\partial x_{2}} = -\\frac{\\partial}{\\partial x_{2}}(1 + \\lambda_{1}x_{2} + \\lambda_{2}u) = -\\lambda_{1}(t)\n$$\nAccording to PMP, the optimal control $u^{*}(t)$ must minimize the Hamiltonian at every instant of time $t \\in [0, T]$ over the admissible set $\\mathcal{U}$. We seek $u^*(t)$ such that:\n$$\nu^{*}(t) = \\arg\\min_{u \\in [-1, 1]} H(x^{*}(t), u, \\lambda^{*}(t)) = \\arg\\min_{u \\in [-1, 1]} (1 + \\lambda_{1}^{*}(t)x_{2}^{*}(t) + \\lambda_{2}^{*}(t)u)\n$$\nThe term $1 + \\lambda_{1}^{*}x_{2}^{*}$ is independent of $u$. The minimization is thus equivalent to minimizing the term $\\lambda_{2}^{*}(t)u$. The solution is determined by the sign of $\\lambda_{2}^{*}(t)$:\n- If $\\lambda_{2}^{*}(t) > 0$, the product $\\lambda_{2}^{*}u$ is minimized by choosing $u$ to be its most negative value, so $u^{*}(t) = -1$.\n- If $\\lambda_{2}^{*}(t)  0$, the product is minimized by choosing $u$ to be its most positive value, so $u^{*}(t) = +1$.\n- If $\\lambda_{2}^{*}(t) = 0$, the Hamiltonian is independent of $u$, and the control is not uniquely determined by this condition. Such a case is termed singular.\n\nThis control logic can be expressed compactly using the signum function, for the nonsingular case where $\\lambda_{2}^{*}(t) \\neq 0$:\n$$\nu^{*}(t) = -\\text{sgn}(\\lambda_{2}^{*}(t))\n$$\nThe problem specifies a free final time $T$ and a fixed terminal state $x(T)=0$. The associated transversality condition is that the Hamiltonian evaluated along the optimal trajectory at the final time must be zero:\n$$\nH(x^{*}(T), u^{*}(T), \\lambda^{*}(T)) = 0\n$$\nSubstituting $x_{2}^{*}(T) = 0$ into the expression for the Hamiltonian, this condition becomes:\n$$\n1 + \\lambda_{1}^{*}(T)x_{2}^{*}(T) + \\lambda_{2}^{*}(T)u^{*}(T) = 1 + \\lambda_{2}^{*}(T)u^{*}(T) = 0\n$$\nThis implies that $\\lambda_{2}^{*}(T) \\neq 0$, because if it were, the condition would reduce to $1=0$, a contradiction.\n\nThe switching function, which we denote as $\\sigma(t)$, is defined as the coefficient of the control variable $u$ in the Hamiltonian. From first principles, this is the partial derivative of the Hamiltonian with respect to the control:\n$$\n\\sigma(t) = \\frac{\\partial H}{\\partial u} = \\frac{\\partial}{\\partial u}(1 + \\lambda_{1}x_{2} + \\lambda_{2}u) = \\lambda_{2}(t)\n$$\nThe optimal control law is therefore $u^{*}(t) = -\\text{sgn}(\\sigma(t))$, provided $\\sigma(t) \\neq 0$.\n\nTo find the explicit time dependence of the switching function, we must solve the costate differential equations.\nThe first equation is $\\dot{\\lambda}_{1}(t) = 0$, which integrates to:\n$$\n\\lambda_{1}(t) = c_{1}\n$$\nwhere $c_{1}$ is a constant of integration.\nSubstituting this result into the second equation, $\\dot{\\lambda}_{2}(t) = -\\lambda_{1}(t)$, gives:\n$$\n\\dot{\\lambda}_{2}(t) = -c_{1}\n$$\nIntegrating with respect to time $t$ yields:\n$$\n\\lambda_{2}(t) = \\int -c_{1} \\, dt = -c_{1}t + c_{2}\n$$\nwhere $c_{2}$ is a second constant of integration.\n\nThe switching function is thus an affine function of time:\n$$\n\\sigma(t) = -c_{1}t + c_{2}\n$$\nThe constants $c_{1}$ and $c_{2}$ are determined by the boundary conditions of the state, $x(0)$ and $x(T)$, through the full two-point boundary value problem. PMP requires that the costate vector $\\lambda(t)$ cannot be identically zero. If $\\sigma(t) = 0$ over a finite interval of time, then $\\dot{\\sigma}(t) = \\dot{\\lambda}_{2}(t) = -c_{1} = 0$, which implies $c_{1}=0$. This, in turn, implies $\\sigma(t) = \\lambda_{2}(t) = c_{2} = 0$. So, $\\lambda_{1}(t)=0$ and $\\lambda_{2}(t)=0$, which is the trivial solution $\\lambda(t)=0$, excluded by the non-triviality condition of PMP. Therefore, singular arcs are not optimal for this problem, and the switching function can only be zero at isolated instants. The control is purely \"bang-bang\".\n\nThe problem asks for the explicit analytic expression for the switching function as a function of time $t$ and the integration constants $c_1$ and $c_2$. This expression is precisely the result of solving the costate equations for $\\lambda_2(t)$.", "answer": "$$\n\\boxed{-c_{1}t + c_{2}}\n$$", "id": "2732750"}, {"introduction": "This final practice shifts our focus from the system dynamics to the objective itself, exploring how the choice of cost function profoundly alters the optimal control strategy. Instead of minimizing time, we now seek to minimize the total control effort, measured by the $L^1$-norm of the control input, a proxy for fuel consumption. This problem [@problem_id:2732800] reveals a richer control structure because the Hamiltonian is no longer smooth, leading to a \"bang-off-bang\" strategy. This provides an accessible and intuitive introduction to the critical concept of **singular arcs**, where it is optimal to apply zero control for a period, a behavior not seen in the previous minimum-time problems.", "problem": "Consider the scalar control system governed by the ordinary differential equation $ \\dot{x}(t) = u(t) $ on a fixed horizon $ [0, T] $, with boundary conditions $ x(0) = x_{0} $ and $ x(T) = 0 $. The running cost is the $ L^{1} $-norm of the control,\n$$\nJ[u] = \\int_{0}^{T} |u(t)| \\, dt.\n$$\nAssume a physically realistic amplitude constraint $ |u(t)| \\leq U $ for a fixed $ U > 0 $, and assume the reachability condition $ T \\geq |x_{0}|/U $ so that the boundary value problem is feasible.\n\nUsing first principles and the statement of Pontryagin’s Minimum Principle (PMP), do the following:\n\n- Formulate the Hamiltonian, the adjoint equation, and the pointwise minimization condition over the compact control set $ [-U, U] $. Identify the switching function and characterize the minimizing set of controls as a function of the switching function.\n- Use this characterization to deduce the qualitative structure of optimal controls (i.e., the conditions under which the control is in a saturated “bang” state, in an “off” state, and how “bang-off-bang” structure arises from the subdifferential of the nonsmooth Hamiltonian at the switching surface).\n- Construct an optimal control that meets the boundary conditions, and determine its arc durations explicitly in terms of $ x_{0} $ and $ U $.\n- Compute the minimal value of the cost $ J^{\\star} $ as a closed-form expression in terms of $ x_{0} $ and $ U $ (you may assume the feasibility condition above). Your final reported answer must be this single expression.\n\nNo numerical approximation is required for the final expression, and no units are involved. The final answer must be reported as a single closed-form analytic expression.", "solution": "The problem proposed is a standard, well-posed problem in the field of optimal control theory. It is scientifically grounded, formally specified, and all necessary conditions for the existence of a solution are provided. We may therefore proceed directly to the solution using Pontryagin's Minimum Principle (PMP).\n\nThe problem is to minimize the cost functional\n$$\nJ[u] = \\int_{0}^{T} |u(t)| \\, dt\n$$\nsubject to the system dynamics\n$$\n\\dot{x}(t) = u(t),\n$$\nthe boundary conditions\n$$\nx(0) = x_{0}, \\quad x(T) = 0,\n$$\nand the control constraint\n$$\n|u(t)| \\leq U.\n$$\nThe feasibility of reaching the target state is guaranteed by the given condition $T \\geq |x_{0}|/U$.\n\nFirst, we formulate the Hamiltonian for this problem. The cost is in Lagrange form with integrand $L(u) = |u|$. According to the PMP, we introduce an adjoint variable (or costate) $\\lambda(t)$ and define the Hamiltonian $H(x, \\lambda, u)$ as:\n$$\nH(x, \\lambda, u) = L(u) + \\lambda(t) \\dot{x}(t) = |u| + \\lambda(t) u.\n$$\nHere we have set the abnormal multiplier $\\lambda_{0}=1$, which is standard for problems where the cost is to be minimized. The adjoint equation governs the dynamics of the costate $\\lambda(t)$:\n$$\n\\dot{\\lambda}(t) = - \\frac{\\partial H}{\\partial x} = - \\frac{\\partial}{\\partial x} \\left( |u| + \\lambda(t) u \\right) = 0.\n$$\nThis implies that the adjoint state $\\lambda(t)$ is a constant for all $t \\in [0, T]$. Let us denote this constant by $\\lambda_{c}$.\n$$\n\\lambda(t) = \\lambda_{c}.\n$$\nThe PMP states that an optimal control $u^{*}(t)$ must minimize the Hamiltonian pointwise for almost every $t \\in [0, T]$:\n$$\nu^{*}(t) = \\arg\\min_{v \\in [-U, U]} H(x(t), \\lambda(t), v) = \\arg\\min_{v \\in [-U, U]} \\left( |v| + \\lambda_{c} v \\right).\n$$\nTo find the minimizing control, we analyze the function $g(v) = |v| + \\lambda_{c} v$ on the interval $v \\in [-U, U]$. This function is piecewise linear and convex.\nWe examine its derivative (or, more formally, its subgradient) with respect to $v$:\n$\\frac{dg}{dv} = \\text{sgn}(v) + \\lambda_{c}$ for $v \\neq 0$.\n- If $\\lambda_{c} > 1$, then $\\frac{dg}{dv} > 0$ for all $v \\neq 0$. Thus, $g(v)$ is strictly increasing, and its minimum on $[-U, U]$ occurs at $v = -U$.\n- If $\\lambda_{c}  -1$, then $\\frac{dg}{dv}  0$ for all $v \\neq 0$. Thus, $g(v)$ is strictly decreasing, and its minimum on $[-U, U]$ occurs at $v = U$.\n- If $-1  \\lambda_{c}  1$, the derivative changes sign at $v=0$. For $v>0$, $\\frac{dg}{dv} = 1 + \\lambda_{c} > 0$, so $g(v)$ increases. For $v0$, $\\frac{dg}{dv} = -1 + \\lambda_{c}  0$, so $g(v)$ decreases. The minimum is uniquely at $v = 0$.\n- If $\\lambda_{c} = 1$, $g(v) = |v| + v$. For $v \\geq 0$, $g(v)=2v$. For $v  0$, $g(v)=0$. The minimum value is $0$, which is achieved for any $v \\in [-U, 0]$.\n- If $\\lambda_{c} = -1$, $g(v) = |v| - v$. For $v > 0$, $g(v)=0$. For $v \\leq 0$, $g(v)=-2v$. The minimum value is $0$, which is achieved for any $v \\in [0, U]$.\n\nSummarizing, the optimal control $u^{*}$ as a function of the constant costate $\\lambda_{c}$ is:\n$$\nu^{*}(\\lambda_{c}) \\in \\begin{cases} \\{U\\}  \\text{if } \\lambda_{c}  -1 \\\\ [0, U]  \\text{if } \\lambda_{c} = -1 \\\\ \\{0\\}  \\text{if } -1  \\lambda_{c}  1 \\\\ [-U, 0]  \\text{if } \\lambda_{c} = 1 \\\\ \\{-U\\}  \\text{if } \\lambda_{c} > 1 \\end{cases}\n$$\nThe constant $\\lambda_{c}$ is the switching function. A singular arc occurs if $|\\lambda_{c}|=1$, where the minimizing control is not unique. The existence of this singular arc is a direct consequence of the non-smoothness (subdifferentiability) of the Hamiltonian at $u=0$.\n\nNow, we must use the boundary conditions to determine which control structure is realized. The total change in state is given by integrating the dynamics:\n$$\nx(T) - x(0) = \\int_{0}^{T} u(t) \\, dt \\implies 0 - x_{0} = \\int_{0}^{T} u(t) \\, dt.\n$$\nIf we assume $x_{0} \\neq 0$, the control $u(t) = 0$ is not a solution. This rules out the case $-1  \\lambda_{c}  1$.\nThe control must be non-zero, at least on a set of positive measure.\n\nLet us consider the case $x_{0} > 0$. We must have $\\int_{0}^{T} u(t) \\, dt = -x_{0}  0$. The control must be negative on average. From our characterization of $u^{*}$, this requires $\\lambda_{c} \\geq 1$.\n- If $\\lambda_{c} > 1$, then $u^{*}(t) = -U$ for all $t$. The state evolution is $x(t) = x_{0} - Ut$. The boundary condition at $t=T$ becomes $x(T) = x_{0} - UT = 0$, which implies $T = x_{0}/U$. This is a specific instance of the feasibility condition given, $T \\geq |x_{0}|/U$. If $T=x_{0}/U$, the optimal control is a constant \"bang\" control $u^{*}(t) = -U$.\n- If $T > x_{0}/U$, a constant control of $-U$ will not work. We must therefore be on the singular arc, which corresponds to $\\lambda_{c}=1$. In this case, any measurable control function $u(t)$ taking values in $[-U, 0]$ is a candidate, provided it satisfies the integral constraint $\\int_{0}^{T} u(t) \\, dt = -x_{0}$. All such controls are optimal from the perspective of PMP. This allows for various structures, including \"bang-off\" or \"bang-off-bang\".\n\nWe are asked to construct one such optimal control. Let's construct a \"bang-off\" control. For $x_{0} > 0$, we apply maximal negative control $u(t)=-U$ for a duration $t_{1}$, and then zero control $u(t)=0$ for the remaining time $T-t_{1}$.\nThe integral constraint becomes:\n$$\n\\int_{0}^{t_{1}} (-U) \\, dt + \\int_{t_{1}}^{T} (0) \\, dt = -U t_{1} = -x_{0}.\n$$\nThis gives the duration of the \"bang\" segment as $t_{1} = x_{0}/U$. Since $T \\geq x_{0}/U=|x_{0}|/U$ is given, we have $t_{1} \\leq T$, so this construction is valid.\nThe optimal control is:\n$$\nu^{*}(t) = \\begin{cases} -U  \\text{for } t \\in [0, x_{0}/U] \\\\ 0  \\text{for } t \\in (x_{0}/U, T] \\end{cases}\n$$\nIf $x_{0}  0$, we need $\\int_{0}^{T} u(t) \\, dt = -x_{0} > 0$. This requires $\\lambda_{c} \\leq -1$. If $T > |x_{0}|/U$, we must be on the singular arc $\\lambda_{c}=-1$. The control can be any measurable function $u(t) \\in [0, U]$ satisfying the integral constraint. We construct a \"bang-off\" control with $u(t)=U$ for a duration $t_{1}$:\n$$\n\\int_{0}^{t_{1}} U \\, dt = U t_{1} = -x_{0} \\implies t_{1} = -x_{0}/U = |x_{0}|/U.\n$$\nThe condition $T \\geq |x_{0}|/U$ ensures $t_{1} \\leq T$.\n\nFor any $x_0$, we can express the duration of the bang-arc as $t_1 = |x_{0}|/U$. The control is $u^{*}(t) = -\\text{sgn}(x_{0})U$ for $t \\in [0, |x_{0}|/U]$ and $u^{*}(t)=0$ for $t \\in (|x_{0}|/U, T]$. The case $x_0=0$ is trivially handled, yielding $t_1=0$ and $u^*(t)=0$.\n\nFinally, we compute the minimal value of the cost functional, $J^{\\star}$.\n$$\nJ^{\\star} = \\int_{0}^{T} |u^{*}(t)| \\, dt = \\int_{0}^{|x_{0}|/U} |-\\text{sgn}(x_{0})U| \\, dt + \\int_{|x_{0}|/U}^{T} |0| \\, dt.\n$$\n$$\nJ^{\\star} = \\int_{0}^{|x_{0}|/U} U \\, dt = U \\left( \\frac{|x_{0}|}{U} \\right) = |x_{0}|.\n$$\nIt is a crucial feature of this problem that any of the infinitely many optimal controls on the singular arc yields the exact same minimal cost. For instance, if $x_{0}>0$, any optimal control must satisfy $u(t) \\in [-U, 0]$. Therefore, $|u(t)| = -u(t)$ for such a control. The cost is:\n$$\nJ[u] = \\int_{0}^{T} |u(t)| \\, dt = \\int_{0}^{T} (-u(t)) \\, dt = -\\int_{0}^{T} u(t) \\, dt = -(-x_{0}) = x_{0} = |x_{0}|.\n$$\nA similar argument holds for $x_{0}0$. The minimal cost is thus robustly determined.", "answer": "$$\n\\boxed{|x_{0}|}\n$$", "id": "2732800"}]}