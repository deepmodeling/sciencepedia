{"hands_on_practices": [{"introduction": "Understanding complex equations often begins with mastering the simplest case. This exercise guides you through the fundamental derivation of the Algebraic Riccati Equation (ARE) from first principles for a scalar linear system [@problem_id:2699217]. By applying the Hamilton-Jacobi-Bellman (HJB) optimality principle with a quadratic value function, you will see exactly how the terms in the ARE arise, cementing the link between optimal control theory and the resulting algebraic condition.", "problem": "Consider the infinite-horizon continuous-time quadratic optimal control problem for the single-state linear system given by $\\dot{x}(t)=a\\,x(t)+b\\,u(t)$, where $a\\in\\mathbb{R}$ and $b\\in\\mathbb{R}$, with cost functional $J(x_{0},u)=\\int_{0}^{\\infty}\\big(q\\,x(t)^{2}+r\\,u(t)^{2}\\big)\\,\\mathrm{d}t$, where $q\\ge 0$ and $r>0$. Starting from the Hamilton–Jacobi–Bellman (HJB) optimality principle for the stationary infinite-horizon problem, and assuming a quadratic candidate value function of the form $V(x)=P\\,x^{2}$ with $P\\in\\mathbb{R}$, derive from first principles the optimal feedback control $u^{*}(x)$ and the scalar continuous-time algebraic Riccati equation that $P$ must satisfy, both expressed explicitly in terms of $a$, $b$, $q$, and $r$. State any mild conditions you use to justify the steps. Provide your final answer as a row vector whose first entry is the feedback law $u^{*}(x)$ as a function of $x$, and whose second entry is the single polynomial in $P$ whose zero set defines the scalar algebraic Riccati equation. No numerical evaluation is required, and no units apply. Do not include an equality sign in either entry of your final answer.", "solution": "The problem as stated is valid. It is a fundamental and well-posed problem in the field of optimal control theory, specifically concerning the linear-quadratic regulator (LQR). It is scientifically grounded, objective, and contains all necessary information for a rigorous derivation from first principles.\n\nThe derivation proceeds from the Hamilton-Jacobi-Bellman (HJB) equation, which provides a necessary and sufficient condition for optimality in an infinite-horizon continuous-time optimal control problem. For a stationary system, the HJB equation is:\n$$ \\min_{u(t)} \\left\\{ L(x(t), u(t)) + \\nabla V(x(t))^T f(x(t), u(t)) \\right\\} = 0 $$\nHere, $V(x)$ is the optimal value function, which represents the minimum cost-to-go from state $x$. The function $L(x, u)$ is the running cost, and $f(x, u)$ represents the system dynamics.\n\nFor the given scalar system, these components are:\nSystem dynamics: $\\dot{x} = f(x, u) = a\\,x + b\\,u$, where $x, u, a, b \\in \\mathbb{R}$.\nRunning cost: $L(x, u) = q\\,x^2 + r\\,u^2$, where $q \\ge 0$ and $r > 0$.\n\nThe problem states to assume a quadratic candidate value function of the form $V(x) = P\\,x^2$ for some constant $P \\in \\mathbb{R}$. For $V(x)$ to be a valid cost function, it must be non-negative for all $x$, which implies that we must seek a solution where $P \\ge 0$. For a scalar state $x$, the gradient $\\nabla V(x)$ is the ordinary derivative $\\frac{dV}{dx}$:\n$$ \\frac{dV}{dx} = \\frac{d}{dx}(P\\,x^2) = 2\\,P\\,x $$\n\nSubstituting the system dynamics, running cost, and the derivative of the value function into the HJB equation yields:\n$$ \\min_{u} \\left\\{ (q\\,x^2 + r\\,u^2) + (2\\,P\\,x)(a\\,x + b\\,u) \\right\\} = 0 $$\nLet us expand the expression inside the minimization operator:\n$$ \\min_{u} \\left\\{ q\\,x^2 + r\\,u^2 + 2\\,a\\,P\\,x^2 + 2\\,b\\,P\\,x\\,u \\right\\} = 0 $$\nTo find the control $u$ that minimizes this expression, we can treat it as a function of $u$, let's call it $H(u)$, and find its minimum.\n$$ H(u) = r\\,u^2 + (2\\,b\\,P\\,x)u + (q\\,x^2 + 2\\,a\\,P\\,x^2) $$\nSince the problem specifies $r > 0$, $H(u)$ is a convex quadratic function of $u$ (a parabola opening upwards). Its minimum is located at the vertex, which can be found by setting the derivative with respect to $u$ equal to zero. This first-order necessary condition for a minimum is:\n$$ \\frac{\\partial H}{\\partial u} = 2\\,r\\,u + 2\\,b\\,P\\,x = 0 $$\nSolving for $u$ provides the expression for the optimal control, $u^*(x)$:\n$$ 2\\,r\\,u = -2\\,b\\,P\\,x $$\n$$ u^*(x) = -\\frac{b\\,P}{r}x $$\nThis is the optimal feedback law, expressing the control as a linear function of the state $x$.\n\nNext, to derive the algebraic Riccati equation, we substitute this optimal control $u^*(x)$ back into the minimized HJB expression, which must equal zero:\n$$ q\\,x^2 + r\\,(u^*(x))^2 + 2\\,a\\,P\\,x^2 + 2\\,b\\,P\\,x\\,(u^*(x)) = 0 $$\nSubstituting $u^*(x) = -\\frac{b\\,P}{r}x$:\n$$ q\\,x^2 + r\\left(-\\frac{b\\,P}{r}x\\right)^2 + 2\\,a\\,P\\,x^2 + 2\\,b\\,P\\,x\\left(-\\frac{b\\,P}{r}x\\right) = 0 $$\nWe simplify this equation algebraically:\n$$ q\\,x^2 + r\\left(\\frac{b^2\\,P^2}{r^2}x^2\\right) + 2\\,a\\,P\\,x^2 - \\frac{2\\,b^2\\,P^2}{r}x^2 = 0 $$\n$$ q\\,x^2 + \\frac{b^2\\,P^2}{r}x^2 + 2\\,a\\,P\\,x^2 - \\frac{2\\,b^2\\,P^2}{r}x^2 = 0 $$\nCombine the terms containing $P^2$:\n$$ q\\,x^2 + 2\\,a\\,P\\,x^2 + \\left(\\frac{b^2}{r} - \\frac{2\\,b^2}{r}\\right)P^2\\,x^2 = 0 $$\n$$ q\\,x^2 + 2\\,a\\,P\\,x^2 - \\frac{b^2}{r}P^2\\,x^2 = 0 $$\nThis equation must hold for any value of the state $x$. For any non-trivial state (i.e., $x \\neq 0$), we can divide the entire equation by $x^2$:\n$$ q + 2\\,a\\,P - \\frac{b^2}{r}P^2 = 0 $$\nThis is the scalar continuous-time algebraic Riccati equation (ARE). The constant $P$ for the optimal controller is found by solving this quadratic equation for $P$. The specific solution chosen must not only satisfy $P \\ge 0$, but also ensure the stability of the closed-loop system, whose dynamics are $\\dot{x} = (a - \\frac{b^2 P}{r})x$. Stability requires that the closed-loop pole $a_{cl} = a - \\frac{b^2 P}{r}$ is negative.\n\nThe problem requires the polynomial in $P$ whose zero set defines the ARE. This polynomial is $q + 2\\,a\\,P - \\frac{b^2}{r}P^2$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{b\\,P}{r}x & q + 2\\,a\\,P - \\frac{b^2}{r}P^2\n\\end{pmatrix}\n}\n$$", "id": "2699217"}, {"introduction": "Deriving an equation is the first step; applying it to find a meaningful solution is the next. This practice builds on the general scalar case by introducing specific numerical values and a crucial engineering requirement: stability [@problem_id:2699184]. You will solve the resulting quadratic ARE, which yields two mathematical solutions, and learn the criterion for selecting the unique, physically-relevant solution that guarantees the closed-loop system is asymptotically stable.", "problem": "Consider the scalar linear time-invariant system governed by $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ with the infinite-horizon quadratic performance index $J = \\int_{0}^{\\infty} \\big(q\\,x(t)^{2} + r\\,u(t)^{2}\\big)\\,dt$. Start from Bellman’s principle of optimality leading to the stationary Hamilton–Jacobi–Bellman (HJB) equation for the infinite-horizon case, and use a quadratic value function ansatz $V(x) = P\\,x^{2}$ with $P$ constant. By minimizing the HJB Hamiltonian with respect to $u$, derive the scalar continuous-time algebraic Riccati equation (ARE) satisfied by $P$. Then, for the specific data $a=1$, $b=1$, $q=2$, and $r=1$, solve the resulting scalar equation explicitly and select the stabilizing solution that renders the closed-loop system $\\dot{x}(t) = \\big(a - b\\,r^{-1}b\\,P\\big)\\,x(t)$ asymptotically stable. Express your final answer as a single closed-form analytic expression for the stabilizing $P$. No rounding is required.", "solution": "The starting point is the infinite-horizon stationary Hamilton–Jacobi–Bellman (HJB) equation for the optimal value function $V(x)$,\n$$\n0 \\;=\\; \\min_{u}\\,\\Big\\{\\, q\\,x^{2} + r\\,u^{2} + V_{x}(x)\\,\\big(a\\,x + b\\,u\\big) \\Big\\},\n$$\nwhere $V_{x}(x)$ denotes the derivative of $V$ with respect to $x$. We postulate a quadratic value function ansatz $V(x) = P\\,x^{2}$ with constant $P$. Then $V_{x}(x) = 2\\,P\\,x$, and the HJB Hamiltonian becomes\n$$\n\\mathcal{H}(x,u) \\;=\\; q\\,x^{2} + r\\,u^{2} + 2\\,P\\,x\\,(a\\,x + b\\,u).\n$$\nTo obtain the optimal input, minimize $\\mathcal{H}(x,u)$ with respect to $u$. The first-order optimality condition is\n$$\n\\frac{\\partial \\mathcal{H}}{\\partial u} \\;=\\; 2\\,r\\,u + 2\\,P\\,x\\,b \\;=\\; 0,\n$$\nwhich yields the optimal control law\n$$\nu^{\\star}(x) \\;=\\; -\\,\\frac{b\\,P}{r}\\,x.\n$$\nSubstitute $u^{\\star}(x)$ back into the Hamiltonian and enforce the HJB equation. First compute each term:\n- The state penalty is $q\\,x^{2}$.\n- The input penalty is $r\\,(u^{\\star})^{2} = r\\,\\Big(\\frac{b^{2}P^{2}}{r^{2}}\\,x^{2}\\Big) = \\frac{b^{2}}{r}\\,P^{2}\\,x^{2}$.\n- The coupling term is $V_{x}\\,(a\\,x + b\\,u^{\\star}) = 2\\,P\\,x\\,\\Big(a\\,x + b\\big(-\\frac{b\\,P}{r}\\,x\\big)\\Big) = \\big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\big)\\,x^{2}$.\nTherefore,\n$$\n0 \\;=\\; q\\,x^{2} + \\frac{b^{2}}{r}\\,P^{2}\\,x^{2} + \\Big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}\n\\;=\\; \\Big(q + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}.\n$$\nBecause this must hold for all $x$, the scalar continuous-time algebraic Riccati equation (ARE) for $P$ is\n$$\nq + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2} \\;=\\; 0.\n$$\n\nFor the given data $a=1$, $b=1$, $q=2$, and $r=1$, the equation becomes\n$$\n2 + 2\\,P - P^{2} \\;=\\; 0,\n$$\nor equivalently\n$$\nP^{2} - 2\\,P - 2 \\;=\\; 0.\n$$\nSolving this quadratic yields\n$$\nP \\;=\\; \\frac{2 \\pm \\sqrt{4 + 8}}{2} \\;=\\; 1 \\pm \\sqrt{3}.\n$$\n\nTo select the stabilizing solution, examine the closed-loop scalar dynamics under the optimal controller. The optimal feedback is $u^{\\star}(x) = -\\frac{b\\,P}{r}\\,x$, so the closed-loop system is\n$$\n\\dot{x}(t) \\;=\\; \\Big(a - \\frac{b^{2}}{r}\\,P\\Big)\\,x(t) \\;=\\; \\big(1 - P\\big)\\,x(t).\n$$\nAsymptotic stability requires $1 - P < 0$, i.e., $P > 1$. Among the two roots $1 \\pm \\sqrt{3}$, only $1 + \\sqrt{3}$ satisfies $P > 1$ and is nonnegative. Hence the stabilizing solution is\n$$\nP^{\\star} \\;=\\; 1 + \\sqrt{3}.\n$$", "answer": "$$\\boxed{1+\\sqrt{3}}$$", "id": "2699184"}, {"introduction": "Most real-world control challenges involve systems with multiple states. This exercise extends our analysis from scalar systems to the matrix form of the ARE, using the canonical double integrator model as a practical example [@problem_id:2699194]. You will tackle the process of setting up and solving a system of algebraic equations for the elements of the solution matrix $P$, computing the optimal feedback gain $K$, and verifying that the resulting closed-loop system is indeed stable.", "problem": "Consider the continuous-time Linear Quadratic Regulator (LQR) problem for the linear time-invariant system with state dynamics $\\dot{x}(t)=A x(t)+B u(t)$ and infinite-horizon performance index $J(x_{0})=\\int_{0}^{\\infty}\\left(x(t)^{\\top} Q x(t)+u(t)^{\\top} R u(t)\\right)\\,\\mathrm{d}t$. Starting from the Hamilton–Jacobi–Bellman (HJB) equation and the Bellman optimality principle, derive the continuous-time Algebraic Riccati Equation (ARE) by assuming a quadratic value function candidate $V(x)=x^{\\top} P x$ with a symmetric matrix $P$. Then, for the specific data\n$$\nA=\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix},\\quad B=\\begin{bmatrix}0\\\\1\\end{bmatrix},\\quad Q=I_{2},\\quad R=1,\n$$\nsolve for the symmetric matrix $P$ that yields the stabilizing solution and compute the corresponding optimal state-feedback gain $K$. Finally, verify that the closed-loop matrix $A-BK$ is Hurwitz by analyzing its eigenvalues.\n\nAssume the standard LQR existence conditions (stabilizability of $(A,B)$ and detectability of $(Q^{1/2},A)$) hold. Provide your final answer as the row vector $K$ in a single explicit analytic expression. No numerical rounding is required.", "solution": "The solution proceeds in two parts. First, a general derivation of the continuous-time Algebraic Riccati Equation is provided, as requested by the problem. Second, this equation is solved for the specific system provided to find the optimal feedback gain.\n\n**Part 1: Derivation of the Algebraic Riccati Equation (ARE)**\n\nThe foundation of this derivation is the Bellman optimality principle, which is expressed for continuous-time systems by the Hamilton-Jacobi-Bellman (HJB) equation. For the infinite-horizon LQR problem, the optimal value function $V(x) = \\min_{u} J(x)$ must satisfy the stationary HJB equation:\n$$\n\\min_{u} \\left\\{ \\frac{\\partial V}{\\partial x}^{\\top} (A x + B u) + x^{\\top} Q x + u^{\\top} R u \\right\\} = 0\n$$\nThe problem posits a quadratic candidate for the value function, $V(x) = x^{\\top} P x$, where $P$ is a symmetric positive definite matrix ($P=P^\\top \\succ 0$). The gradient of $V(x)$ with respect to $x$ is:\n$$\n\\frac{\\partial V}{\\partial x} = (P + P^{\\top})x = 2Px\n$$\nSubstituting this into the HJB equation yields:\n$$\n\\min_{u} \\left\\{ (2Px)^{\\top} (A x + B u) + x^{\\top} Q x + u^{\\top} R u \\right\\} = 0\n$$\nExpanding the first term:\n$$\n\\min_{u} \\left\\{ 2x^{\\top}PAx + 2x^{\\top}PBu + x^{\\top}Qx + u^{\\top}Ru \\right\\} = 0\n$$\nThe expression inside the minimization is the Hamiltonian, $H(x, u, P)$. To find the optimal control $u^*(t)$ that minimizes this Hamiltonian, we take its gradient with respect to $u$ and set it to zero. Since $R\\succ 0$, the Hamiltonian is convex in $u$.\n$$\n\\frac{\\partial H}{\\partial u} = 2B^{\\top}Px + 2Ru = 0\n$$\nSolving for $u$ gives the optimal control law:\n$$\nu^*(t) = -R^{-1}B^{\\top}Px(t)\n$$\nThis is a linear state-feedback law $u = -Kx$, where the optimal gain matrix is $K = R^{-1}B^{\\top}P$.\n\nNow, we substitute this optimal control $u^*$ back into the HJB equation:\n$$\n2x^{\\top}PAx + 2x^{\\top}PB(-R^{-1}B^{\\top}Px) + x^{\\top}Qx + (-R^{-1}B^{\\top}Px)^{\\top}R(-R^{-1}B^{\\top}Px) = 0\n$$\nAssuming the control weighting matrix $R$ is symmetric (so $R=R^\\top$ and $(R^{-1})^\\top=R^{-1}$), we can simplify the term for the control cost:\n$$\n(-R^{-1}B^{\\top}Px)^{\\top}R(-R^{-1}B^{\\top}Px) = x^\\top P B (R^{-1})^\\top R R^{-1} B^\\top P x = x^\\top P B R^{-1} B^\\top P x\n$$\nThe equation becomes:\n$$\n2x^{\\top}PAx - 2x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}Qx + x^{\\top}PBR^{-1}B^{\\top}Px = 0\n$$\nCombining the terms involving $PBR^{-1}B^\\top P$:\n$$\n2x^{\\top}PAx - x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}Qx = 0\n$$\nFinally, we use the identity $2x^\\top PAx = x^\\top(A^\\top P + PA)x$, which holds because $P$ is symmetric, allowing $x^\\top PAx = (x^\\top PAx)^\\top = x^\\top A^\\top P^\\top x = x^\\top A^\\top Px$. The equation is thus rewritten into the standard quadratic form in $x$:\n$$\nx^{\\top}(A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q)x = 0\n$$\nThis equation must hold for any state $x(t) \\in \\mathbb{R}^n$. This is only possible if the matrix expression inside the parentheses is the zero matrix. This gives the continuous-time Algebraic Riccati Equation (ARE):\n$$\nA^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0\n$$\n\n**Part 2: Solution for the Specific System**\n\nWe are given:\n$$\nA=\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}, \\quad B=\\begin{bmatrix}0\\\\1\\end{bmatrix}, \\quad Q=\\begin{bmatrix}1&0\\\\0&1\\end{bmatrix}, \\quad R=1\n$$\nLet the symmetric matrix $P$ be parameterized as $P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix}$. We now compute each term of the ARE.\n$$\nA^{\\top}P = \\begin{bmatrix}0&0\\\\1&0\\end{bmatrix}\\begin{bmatrix}p_{11}&p_{12}\\\\p_{12}&p_{22}\\end{bmatrix} = \\begin{bmatrix}0&0\\\\p_{11}&p_{12}\\end{bmatrix}\n$$\n$$\nPA = \\begin{bmatrix}p_{11}&p_{12}\\\\p_{12}&p_{22}\\end{bmatrix}\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix} = \\begin{bmatrix}0&p_{11}\\\\0&p_{12}\\end{bmatrix}\n$$\nThe term $PBR^{-1}B^{\\top}P$ is computed as:\n$$\nPB = \\begin{bmatrix}p_{11}&p_{12}\\\\p_{12}&p_{22}\\end{bmatrix}\\begin{bmatrix}0\\\\1\\end{bmatrix} = \\begin{bmatrix}p_{12}\\\\p_{22}\\end{bmatrix}\n$$\n$$\nB^{\\top}P = (PB)^{\\top} = \\begin{bmatrix}p_{12}&p_{22}\\end{bmatrix}\n$$\n$$\nPBR^{-1}B^{\\top}P = (PB)(R^{-1})(B^{\\top}P) = \\begin{bmatrix}p_{12}\\\\p_{22}\\end{bmatrix} (1) \\begin{bmatrix}p_{12}&p_{22}\\end{bmatrix} = \\begin{bmatrix}p_{12}^2 & p_{12}p_{22} \\\\ p_{12}p_{22} & p_{22}^2\\end{bmatrix}\n$$\nSubstituting all terms into the ARE, $A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0$:\n$$\n\\begin{bmatrix}0&p_{11}\\\\p_{11}&2p_{12}\\end{bmatrix} - \\begin{bmatrix}p_{12}^2 & p_{12}p_{22} \\\\ p_{12}p_{22} & p_{22}^2\\end{bmatrix} + \\begin{bmatrix}1&0\\\\0&1\\end{bmatrix} = \\begin{bmatrix}0&0\\\\0&0\\end{bmatrix}\n$$\n$$\n\\begin{bmatrix}1-p_{12}^2 & p_{11}-p_{12}p_{22} \\\\ p_{11}-p_{12}p_{22} & 1+2p_{12}-p_{22}^2\\end{bmatrix} = \\begin{bmatrix}0&0\\\\0&0\\end{bmatrix}\n$$\nThis matrix equality yields a system of three scalar algebraic equations:\n$$(1) \\quad 1 - p_{12}^2 = 0$$\n$$(2) \\quad p_{11} - p_{12}p_{22} = 0$$\n$$(3) \\quad 1 + 2p_{12} - p_{22}^2 = 0$$\nFrom equation $(1)$, we find $p_{12} = \\pm 1$. We must find the solution for $P$ that is positive definite ($P\\succ 0$), as this corresponds to the stabilizing solution.\nCase 1: $p_{12} = 1$.\nSubstituting into equation $(3)$: $1 + 2(1) - p_{22}^2 = 0 \\implies 3 - p_{22}^2 = 0 \\implies p_{22} = \\pm\\sqrt{3}$. For $P$ to be positive definite, its diagonal elements must be positive, so we require $p_{22} > 0$. Thus, $p_{22} = \\sqrt{3}$.\nSubstituting $p_{12}=1$ and $p_{22}=\\sqrt{3}$ into equation $(2)$: $p_{11} - (1)(\\sqrt{3}) = 0 \\implies p_{11} = \\sqrt{3}$.\nThe resulting matrix is $P = \\begin{bmatrix} \\sqrt{3} & 1 \\\\ 1 & \\sqrt{3} \\end{bmatrix}$. We check for positive definiteness using Sylvester's criterion:\nThe first leading principal minor is $p_{11} = \\sqrt{3} > 0$.\nThe second leading principal minor is $\\det(P) = (\\sqrt{3})(\\sqrt{3}) - (1)^2 = 3-1 = 2 > 0$.\nSince all leading principal minors are positive, $P$ is positive definite. This is the correct stabilizing solution.\n\nCase 2: $p_{12} = -1$.\nSubstituting into equation $(3)$: $1 + 2(-1) - p_{22}^2 = 0 \\implies -1 - p_{22}^2 = 0 \\implies p_{22}^2 = -1$. This equation has no real solution for $p_{22}$. This case is discarded.\n\nThe unique symmetric positive definite solution is $P = \\begin{bmatrix} \\sqrt{3} & 1 \\\\ 1 & \\sqrt{3} \\end{bmatrix}$.\n\nNow, we compute the optimal state-feedback gain $K$:\n$$\nK = R^{-1}B^{\\top}P = (1)\\begin{bmatrix}0&1\\end{bmatrix}\\begin{bmatrix}\\sqrt{3}&1\\\\1&\\sqrt{3}\\end{bmatrix} = \\begin{bmatrix}1&\\sqrt{3}\\end{bmatrix}\n$$\nFinally, we verify that the closed-loop system is stable. The closed-loop state matrix is $A_{cl} = A - BK$:\n$$\nA_{cl} = \\begin{bmatrix}0&1\\\\0&0\\end{bmatrix} - \\begin{bmatrix}0\\\\1\\end{bmatrix}\\begin{bmatrix}1&\\sqrt{3}\\end{bmatrix} = \\begin{bmatrix}0&1\\\\0&0\\end{bmatrix} - \\begin{bmatrix}0&0\\\\1&\\sqrt{3}\\end{bmatrix} = \\begin{bmatrix}0&1\\\\-1&-\\sqrt{3}\\end{bmatrix}\n$$\nA system is stable if its state matrix is Hurwitz, i.e., all its eigenvalues have negative real parts. We find the eigenvalues by solving the characteristic equation $\\det(A_{cl} - \\lambda I) = 0$:\n$$\n\\det\\left(\\begin{bmatrix}-\\lambda&1\\\\-1&-\\sqrt{3}-\\lambda\\end{bmatrix}\\right) = (-\\lambda)(-\\sqrt{3}-\\lambda) - (1)(-1) = \\lambda^2 + \\sqrt{3}\\lambda + 1 = 0\n$$\nFor a second-order characteristic polynomial $\\lambda^2 + a_1\\lambda + a_0 = 0$, the Routh-Hurwitz stability criterion states that the system is stable if and only if $a_1 > 0$ and $a_0 > 0$. Here, $a_1 = \\sqrt{3} > 0$ and $a_0 = 1 > 0$. The criterion is satisfied, confirming the matrix is Hurwitz. The eigenvalues are $\\lambda = \\frac{-\\sqrt{3} \\pm \\sqrt{3-4}}{2} = -\\frac{\\sqrt{3}}{2} \\pm \\frac{i}{2}$, which have negative real parts. The computed gain $K$ is indeed the stabilizing optimal gain.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & \\sqrt{3}\n\\end{pmatrix}\n}\n$$", "id": "2699194"}]}