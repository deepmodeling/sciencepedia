{"hands_on_practices": [{"introduction": "To build a strong foundation, we begin with the simplest non-trivial case: a stable, first-order continuous-time system. This exercise guides you through deriving the infinite-horizon controllability Gramian, $W_c$, directly from its integral definition. By analyzing the resulting expression [@problem_id:2696864], you will develop a core intuition for how a system's physical properties—namely its inherent stability and input gain—directly determine the minimum energy required for control.", "problem": "Consider the scalar Linear Time-Invariant (LTI) system given by $\\dot{x}(t)=-a\\,x(t)+b\\,u(t)$, where $a>0$ and $b \\neq 0$. Using only first principles and core definitions from control theory, derive the infinite-horizon controllability Gramian $W_{c}$ associated with this system. Your derivation must proceed from the definition of the finite-horizon controllability Gramian and the state-transition operator, and then take the infinite-horizon limit where appropriate, justifying existence conditions. Then, interpret how $W_{c}$ depends on $a$ and $b$ in terms of the minimal energy required to reach a given state as the time horizon grows, explaining why the dependence you obtain is consistent with the system’s stability and input coupling properties.\n\nProvide your final answer for the controllability Gramian as a closed-form expression in terms of $a$ and $b$. No numerical approximation is required, and no units are needed. The final answer must be a single closed-form expression.", "solution": "The problem statement is evaluated and determined to be valid. It is scientifically grounded in the principles of linear control theory, well-posed with sufficient and consistent conditions, and objectively stated. The problem requires the derivation of the infinite-horizon controllability Gramian for a stable, scalar, linear time-invariant system and an interpretation of the result, which is a standard and meaningful exercise in the field.\n\nThe system is described by the scalar linear time-invariant (LTI) differential equation:\n$$ \\dot{x}(t) = -a \\, x(t) + b \\, u(t) $$\nwhere the state is $x(t) \\in \\mathbb{R}$, the control input is $u(t) \\in \\mathbb{R}$, and the parameters satisfy $a > 0$ and $b \\neq 0$. This corresponds to the standard state-space form $\\dot{x}(t) = Ax(t) + Bu(t)$ with the scalar matrices $A = -a$ and $B = b$.\n\nThe state-transition operator (or matrix, in this scalar case) for an LTI system is given by the matrix exponential $\\Phi(t) = \\exp(At)$. For this system, with $A = -a$, the state-transition operator is:\n$$ \\Phi(t) = \\exp(-at) $$\n\nThe finite-horizon controllability Gramian $W_c(t_f)$ over the time interval $[0, t_f]$ is defined by the integral:\n$$ W_c(t_f) = \\int_0^{t_f} \\exp(A\\tau) B B^T \\exp(A^T\\tau) \\, d\\tau $$\nSince the system is scalar, the matrices $A$ and $B$ are equal to their transposes, i.e., $A^T = A = -a$ and $B^T = B = b$. Substituting these into the definition yields:\n$$ W_c(t_f) = \\int_0^{t_f} \\exp(-a\\tau) (b)(b) \\exp(-a\\tau) \\, d\\tau $$\n$$ W_c(t_f) = \\int_0^{t_f} b^2 \\exp(-2a\\tau) \\, d\\tau $$\nThe term $b^2$ is a constant and can be taken outside the integral:\n$$ W_c(t_f) = b^2 \\int_0^{t_f} \\exp(-2a\\tau) \\, d\\tau $$\nEvaluating the elementary integral gives:\n$$ W_c(t_f) = b^2 \\left[ \\frac{\\exp(-2a\\tau)}{-2a} \\right]_0^{t_f} $$\n$$ W_c(t_f) = b^2 \\left( \\frac{\\exp(-2at_f)}{-2a} - \\frac{\\exp(0)}{-2a} \\right) $$\n$$ W_c(t_f) = \\frac{b^2}{-2a} (\\exp(-2at_f) - 1) = \\frac{b^2}{2a} (1 - \\exp(-2at_f)) $$\n\nThe infinite-horizon controllability Gramian, denoted $W_c$, is obtained by taking the limit of $W_c(t_f)$ as the time horizon $t_f$ approaches infinity:\n$$ W_c = \\lim_{t_f \\to \\infty} W_c(t_f) = \\lim_{t_f \\to \\infty} \\left[ \\frac{b^2}{2a} (1 - \\exp(-2at_f)) \\right] $$\nThe existence of this limit depends on the convergence of the term $\\exp(-2at_f)$. The problem states that $a > 0$. Since $t_f \\to \\infty$, the exponent $-2at_f$ approaches $-\\infty$. Consequently, the exponential term converges to zero:\n$$ \\lim_{t_f \\to \\infty} \\exp(-2at_f) = 0 $$\nThis convergence is guaranteed because the system is stable. A system $\\dot{x}=Ax$ is stable if all eigenvalues of $A$ have negative real parts. Here, the single eigenvalue of $A=-a$ is precisely $-a$, which is negative because $a > 0$. The infinite-horizon controllability Gramian exists for any controllable system if and only if the system is stable.\nSubstituting the limit of the exponential term, we obtain the infinite-horizon Gramian:\n$$ W_c = \\frac{b^2}{2a} (1 - 0) = \\frac{b^2}{2a} $$\nThis result can be verified by solving the continuous-time algebraic Lyapunov equation for $W_c$, which is $AW_c + W_cA^T = -BB^T$. For this system, it becomes $(-a)W_c + W_c(-a) = -(b)(b)$, which simplifies to $-2aW_c = -b^2$, yielding $W_c = \\frac{b^2}{2a}$, confirming our derivation.\n\nNow, we interpret this result. The controllability Gramian is central to determining the minimum control energy required to steer a system from the origin to a target state $x_f$. For a general LTI system, this minimum energy over an infinite horizon is given by $E_{min} = x_f^T W_c^{-1} x_f$. For our scalar system, this becomes:\n$$ E_{min} = x_f W_c^{-1} x_f = x_f^2 W_c^{-1} $$\nUsing our derived expression for $W_c$, its inverse is:\n$$ W_c^{-1} = \\left(\\frac{b^2}{2a}\\right)^{-1} = \\frac{2a}{b^2} $$\nTherefore, the minimal energy required to reach state $x_f$ is:\n$$ E_{min} = x_f^2 \\left( \\frac{2a}{b^2} \\right) $$\n\nWe analyze the dependence on $a$ and $b$:\n1.  **Dependence on $b$ (Input Coupling):** The minimal energy $E_{min}$ is inversely proportional to $b^2$. The parameter $b$ quantifies how strongly the control input $u(t)$ influences the state dynamics. A larger magnitude of $b$ signifies a more potent control authority. This means that for a larger $|b|$, the system is \"easier\" to control, and thus less energy is required to drive the state to a desired value $x_f$. The derived relationship $E_{min} \\propto 1/b^2$ is perfectly consistent with this physical intuition.\n\n2.  **Dependence on $a$ (System Stability):** The minimal energy $E_{min}$ is directly proportional to $a$. The parameter $a$ determines the system's inherent stability; the system pole is at $s = -a$. A larger value of $a$ corresponds to a more stable system, meaning it has a stronger natural tendency to return to the equilibrium state $x=0$. To steer the state to a non-zero value $x_f$, the control input must counteract this strong restorative \"force\" (represented by the term $-ax(t)$). Therefore, a more stable system (larger $a$) is \"harder\" to push away from the origin, requiring a greater expenditure of control energy. The direct proportionality $E_{min} \\propto a$ correctly reflects this physical property.\n\nIn summary, the expression $W_c = \\frac{b^2}{2a}$ and the resulting energy dependence align precisely with the fundamental characteristics of the system's stability and input coupling.", "answer": "$$ \\boxed{\\frac{b^2}{2a}} $$", "id": "2696864"}, {"introduction": "We now transition from the continuous to the discrete-time domain, a crucial step for understanding digital control systems. This practice focuses on a simple discrete integrator, a fundamental building block in many applications. You will compute the finite-horizon controllability Gramian, $W_c(N)$, and use first principles to find the optimal control sequence that minimizes energy expenditure over a fixed number of steps, $N$ [@problem_id:2696874].", "problem": "Consider the scalar, discrete-time, Linear Time-Invariant (LTI) system given by $x_{k+1}=x_{k}+u_{k}$ with initial condition $x_{0}=0$. Let $N \\in \\mathbb{N}$ be a fixed, finite horizon and let $x_{f} \\in \\mathbb{R}$ be a prescribed terminal state value at time $k=N$. The input energy over the horizon is defined by the quadratic cost $J=\\sum_{k=0}^{N-1} u_{k}^{2}$. Using only fundamental definitions for finite-horizon reachability and the finite-horizon controllability Gramian, do the following:\n- Compute the finite-horizon controllability Gramian $W_{c}(N)$.\n- Determine, from first principles, the minimal value of the energy $J$ required to reach $x_{N}=x_{f}$ from $x_{0}=0$ in exactly $N$ steps.\n\nExpress your final result as a single row containing two closed-form expressions: first $W_{c}(N)$, and second the minimal energy as a function of $x_{f}$ and $N$. No numerical approximation is required for this problem, and no units are needed in the final answer.", "solution": "The problem statement is scrutinized and found to be valid. It is a well-posed, scientifically grounded problem within the domain of discrete-time linear control theory. All necessary data and conditions are provided, and there are no internal contradictions or ambiguities. The problem requires the application of fundamental principles, which is a rigorous and meaningful exercise. We may proceed with the solution.\n\nThe system under consideration is the scalar, discrete-time, linear time-invariant (LTI) system described by the state equation:\n$$x_{k+1} = x_{k} + u_{k}$$\nThis falls into the general form $x_{k+1} = Ax_{k} + Bu_{k}$, where the state $x_{k}$ and input $u_{k}$ are scalars. By comparison, we identify the system matrices as $A=1$ and $B=1$. The initial condition is given as $x_{0}=0$.\n\nThe first objective is to compute the finite-horizon controllability Gramian, $W_{c}(N)$, for a given horizon $N \\in \\mathbb{N}$. The definition of the discrete-time controllability Gramian over a horizon of $N$ steps is:\n$$W_{c}(N) = \\sum_{k=0}^{N-1} A^{N-k-1} B B^{T} (A^{N-k-1})^{T}$$\nSubstituting the scalar values $A=1$ and $B=1$ into this definition, we note that transposition has no effect. The expression becomes:\n$$W_{c}(N) = \\sum_{k=0}^{N-1} (1)^{N-k-1} (1) (1) ((1)^{N-k-1})$$\n$$W_{c}(N) = \\sum_{k=0}^{N-1} 1^{2(N-k-1)}$$\nSince $N$ and $k$ are integers, the exponent $2(N-k-1)$ is an integer. Any integer power of $1$ is equal to $1$. Therefore, each term in the summation is $1$. The sum consists of $N$ such terms (from $k=0$ to $k=N-1$).\n$$W_{c}(N) = \\sum_{k=0}^{N-1} 1 = N$$\nThus, the controllability Gramian is simply the horizon length $N$.\n\nThe second objective is to determine the minimum energy $J = \\sum_{k=0}^{N-1} u_{k}^{2}$ required to steer the system from the initial state $x_{0}=0$ to a specified final state $x_{N}=x_{f}$ in exactly $N$ steps. We will derive this from first principles.\n\nFirst, we express the final state $x_{N}$ in terms of the sequence of control inputs $\\{u_{k}\\}_{k=0}^{N-1}$. We can unroll the state equation recursively:\n$$x_{1} = x_{0} + u_{0} = u_{0}$$\n$$x_{2} = x_{1} + u_{1} = u_{0} + u_{1}$$\n$$x_{3} = x_{2} + u_{2} = u_{0} + u_{1} + u_{2}$$\nBy induction, the state at time $k=N$ is the sum of all control inputs applied up to time $k=N-1$:\n$$x_{N} = \\sum_{k=0}^{N-1} u_{k}$$\nThe problem specifies the terminal constraint $x_{N}=x_{f}$. This gives us the reachability constraint:\n$$\\sum_{k=0}^{N-1} u_{k} = x_{f}$$\nWe must find the control sequence $\\{u_{k}\\}$ that minimizes the cost function $J = \\sum_{k=0}^{N-1} u_{k}^{2}$ subject to this linear constraint. This is a constrained optimization problem. We employ the method of Lagrange multipliers. The Lagrangian function $\\mathcal{L}$ is defined as:\n$$\\mathcal{L}(u_{0}, u_{1}, \\dots, u_{N-1}, \\lambda) = \\sum_{k=0}^{N-1} u_{k}^{2} - \\lambda \\left( \\left( \\sum_{k=0}^{N-1} u_{k} \\right) - x_{f} \\right)$$\nFor an extremum, the partial derivatives of $\\mathcal{L}$ with respect to each control input $u_{k}$ must be zero. For any $j \\in \\{0, 1, \\dots, N-1\\}$:\n$$\\frac{\\partial \\mathcal{L}}{\\partial u_{j}} = 2u_{j} - \\lambda = 0$$\nThis implies that $u_{j} = \\frac{\\lambda}{2}$. This must hold for all $j$, which means the optimal control inputs are all equal to each other:\n$$u_{0}^{*} = u_{1}^{*} = \\dots = u_{N-1}^{*} = \\frac{\\lambda}{2}$$\nNow, we use the constraint to determine the value of the Lagrange multiplier $\\lambda$. Substituting the optimal control form into the constraint equation:\n$$\\sum_{k=0}^{N-1} \\frac{\\lambda}{2} = x_{f}$$\n$$N \\left( \\frac{\\lambda}{2} \\right) = x_{f}$$\nSolving for $\\lambda$, we find:\n$$\\lambda = \\frac{2x_{f}}{N}$$\nSubstituting this back into the expression for the optimal control inputs gives:\n$$u_{k}^{*} = \\frac{1}{2} \\left( \\frac{2x_{f}}{N} \\right) = \\frac{x_{f}}{N} \\quad \\text{for } k=0, 1, \\dots, N-1$$\nFinally, we compute the minimum energy $J_{min}$ by substituting this optimal control sequence into the cost function:\n$$J_{min} = \\sum_{k=0}^{N-1} (u_{k}^{*})^{2} = \\sum_{k=0}^{N-1} \\left( \\frac{x_{f}}{N} \\right)^{2}$$\nSince the term inside the summation is constant with respect to the index $k$, we have:\n$$J_{min} = N \\left( \\frac{x_{f}}{N} \\right)^{2} = N \\frac{x_{f}^{2}}{N^{2}} = \\frac{x_{f}^{2}}{N}$$\nThis result aligns with the general formula for minimum energy control, $J_{min} = x_{f}^{T} W_{c}(N)^{-1} x_{f}$, where for our scalar case $x_{f}^{T}$ is just $x_{f}$ and $W_{c}(N)^{-1} = N^{-1} = \\frac{1}{N}$, yielding $x_{f} (\\frac{1}{N}) x_{f} = \\frac{x_{f}^{2}}{N}$.\n\nThe two required expressions are $W_{c}(N) = N$ and the minimal energy $J_{min} = \\frac{x_{f}^{2}}{N}$.", "answer": "$$\\boxed{\\begin{pmatrix} N & \\frac{x_{f}^{2}}{N} \\end{pmatrix}}$$", "id": "2696874"}, {"introduction": "Real-world systems are often complex and may not be fully controllable. This final practice confronts this reality by presenting a multi-dimensional system with an uncontrollable mode. Your task is to move beyond simple examples by identifying the system's reachable subspace from first principles and seeing how this limitation is mathematically encoded in a singular controllability Gramian. This will enable you to calculate the minimum energy needed to steer the system to a target state that is, crucially, within its reachable set [@problem_id:2696846].", "problem": "Consider the Linear Time-Invariant (LTI) system with state dimension $3$ and a single input described by\n$$\n\\dot{x}(t) = A\\,x(t) + b\\,u(t), \\quad x(0)=0,\n$$\nwhere\n$$\nA=\\begin{pmatrix}\n0 & 0 & 0\\\\\n0 & -1 & 0\\\\\n0 & 0 & 2\n\\end{pmatrix},\n\\qquad\nb=\\begin{pmatrix}\n1\\\\\n1\\\\\n0\n\\end{pmatrix},\n$$\nand the control $u$ is square-integrable on a fixed horizon $[0,T]$. Let $T=\\ln 2$. You will investigate the finite-time reachable subspace and the minimal-energy transfer to a specified terminal state at time $T$.\n\nUsing only foundational definitions of reachability and energy in linear systems, and without assuming any pre-stated formulae for the controllability Gramian or optimal control, complete the following:\n\n1. Determine whether the system is controllable on $[0,T]$. If it is not controllable, identify a nontrivial finite-time reachable subspace at horizon $T$ and justify your claim from first principles.\n\n2. Derive the finite-horizon controllability Gramian at time $T$, and use it to rigorously justify your conclusion in part 1 by characterizing its range. Explain why the Gramian is singular yet nonzero in this example.\n\n3. Among all square-integrable inputs $u$ on $[0,T]$ that steer the system from $x(0)=0$ to the terminal state\n$$\nx(T)=x_f=\\begin{pmatrix}1\\\\ 0\\\\ 0\\end{pmatrix},\n$$\ncompute the minimal input energy\n$$\n\\int_{0}^{T} u(t)^{2}\\,dt\n$$\nin exact closed form.\n\nExpress your final answer as a single exact analytic expression with no units. Do not approximate or round your final expression.", "solution": "The problem will be validated before a solution is attempted.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following information for a Linear Time-Invariant (LTI) system:\n- State equation: $\\dot{x}(t) = A\\,x(t) + b\\,u(t)$\n- System matrices:\n  $$A=\\begin{pmatrix} 0 & 0 & 0\\\\ 0 & -1 & 0\\\\ 0 & 0 & 2 \\end{pmatrix}, \\qquad b=\\begin{pmatrix} 1\\\\ 1\\\\ 0 \\end{pmatrix}$$\n- State dimension: $n=3$, single input: $m=1$.\n- Initial condition: $x(0)=0$.\n- Control input: $u(t)$ is a square-integrable function on $[0,T]$.\n- Time horizon: $T = \\ln 2$.\n- Terminal state for Part 3:\n  $$x_f = \\begin{pmatrix} 1\\\\ 0\\\\ 0 \\end{pmatrix}$$\n- Objective for Part 3: Compute the minimal input energy $\\int_{0}^{T} u(t)^{2}\\,dt$.\n- Constraint: The derivation must use only foundational definitions and not assume pre-stated formulae for the Gramian or optimal control.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded**: The problem is a standard exercise in linear control theory, based on fundamental principles of differential equations and system dynamics. All mathematical objects are well-defined. It is scientifically valid.\n- **Well-Posed**: The problem is structured to test understanding of reachability, the controllability Gramian, and minimal energy control for a non-controllable system. Part 1 asks to characterize the reachable subspace. Part 2 asks for the Gramian, which is a tool for this characterization. Part 3 asks for the minimal energy to reach a specific state $x_f$. This part is well-posed if and only if $x_f$ lies within the reachable subspace. This condition must be verified as part of the solution, which is a standard procedure and does not invalidate the problem statement itself.\n- **Objective**: The problem is stated in precise, objective mathematical language.\n- **Completeness and Consistency**: The system is fully specified (matrices $A, b$, initial state $x(0)$) and the time horizon $T$ is given. There are no missing or contradictory conditions.\n- **Other Flaws**: The problem is not metaphorical, trivial, or outside the scope of scientific verification. It directly addresses the topic of controllability and minimal energy.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. It is a well-formulated problem in control theory that requires derivation from first principles. A complete solution will now be provided.\n\n### Solution\n\nThe solution to the given LTI system with initial condition $x(0)=0$ is given by the variation of constants formula:\n$$x(t) = \\int_{0}^{t} e^{A(t-\\tau)} b u(\\tau) d\\tau$$\nThe set of all states reachable at time $T$ is called the reachable subspace $\\mathcal{R}_T$ at time $T$.\n\n**1. Controllability and Reachable Subspace**\n\nThe system is controllable on $[0,T]$ if $\\mathcal{R}_T = \\mathbb{R}^3$. To determine $\\mathcal{R}_T$, we must first compute the state-transition matrix $e^{At}$. Since $A$ is a diagonal matrix, its matrix exponential is found by exponentiating its diagonal elements:\n$$A = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & 2 \\end{pmatrix} \\implies e^{At} = \\begin{pmatrix} e^{0t} & 0 & 0 \\\\ 0 & e^{-t} & 0 \\\\ 0 & 0 & e^{2t} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & e^{-t} & 0 \\\\ 0 & 0 & e^{2t} \\end{pmatrix}$$\nThe state $x(T)$ reachable from the origin is\n$$x(T) = \\int_{0}^{T} e^{A(T-\\tau)} b u(\\tau) d\\tau$$\nThe term $e^{A(T-\\tau)}b$ is\n$$e^{A(T-\\tau)}b = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & e^{-(T-\\tau)} & 0 \\\\ 0 & 0 & e^{2(T-\\tau)} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ e^{-(T-\\tau)} \\\\ 0 \\end{pmatrix}$$\nTherefore, any reachable state $x(T)$ has the form:\n$$x(T) = \\int_{0}^{T} \\begin{pmatrix} 1 \\\\ e^{-(T-\\tau)} \\\\ 0 \\end{pmatrix} u(\\tau) d\\tau = \\begin{pmatrix} \\int_{0}^{T} u(\\tau) d\\tau \\\\ \\int_{0}^{T} e^{-(T-\\tau)} u(\\tau) d\\tau \\\\ 0 \\end{pmatrix}$$\nThe third component of any reachable state $x(T)$ is identically zero, for any choice of square-integrable control $u(t)$. This means that the reachable subspace $\\mathcal{R}_T$ is a strict subspace of $\\mathbb{R}^3$. Specifically, any reachable state must lie in the plane spanned by the vectors $e_1 = (1,0,0)^T$ and $e_2 = (0,1,0)^T$.\nThe reachable subspace is therefore $\\mathcal{R}_T = \\text{span} \\{e_1, e_2\\}$. Since $\\mathcal{R}_T \\neq \\mathbb{R}^3$, the system is **not controllable**. The nontrivial finite-time reachable subspace at horizon $T$ is the set of all vectors of the form $(c_1, c_2, 0)^T$ for $c_1, c_2 \\in \\mathbb{R}$.\n\n**2. Controllability Gramian**\n\nThe finite-horizon controllability Gramian is defined from first principles as $W_c(T) = \\int_{0}^{T} e^{At} b b^T e^{A^T t} dt$. Since $A$ is symmetric ($A=A^T$), this is $W_c(T) = \\int_{0}^{T} e^{At} b b^T e^{At} dt$.\nFirst, we compute the product $b b^T$:\n$$b b^T = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$$\nNext, we compute the integrand $e^{At} b b^T e^{At}$:\n$$e^{At} b b^T e^{At} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & e^{-t} & 0 \\\\ 0 & 0 & e^{2t} \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & e^{-t} & 0 \\\\ 0 & 0 & e^{2t} \\end{pmatrix} = \\begin{pmatrix} 1 & e^{-t} & 0 \\\\ e^{-t} & e^{-2t} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$$\nNow, we integrate this matrix from $t=0$ to $T=\\ln 2$:\n$$W_c(T) = \\int_{0}^{T} \\begin{pmatrix} 1 & e^{-t} & 0 \\\\ e^{-t} & e^{-2t} & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} dt = \\begin{pmatrix} \\int_{0}^{T} 1 dt & \\int_{0}^{T} e^{-t} dt & 0 \\\\ \\int_{0}^{T} e^{-t} dt & \\int_{0}^{T} e^{-2t} dt & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$$\nWe evaluate the integrals with $T=\\ln 2$:\n- $\\int_{0}^{\\ln 2} 1 dt = [t]_{0}^{\\ln 2} = \\ln 2$\n- $\\int_{0}^{\\ln 2} e^{-t} dt = [-e^{-t}]_{0}^{\\ln 2} = -e^{-\\ln 2} - (-e^0) = -1/2 + 1 = 1/2$\n- $\\int_{0}^{\\ln 2} e^{-2t} dt = [-\\frac{1}{2}e^{-2t}]_{0}^{\\ln 2} = -\\frac{1}{2}e^{-2\\ln 2} - (-\\frac{1}{2}e^0) = -\\frac{1}{2}(1/4) + 1/2 = 3/8$\nSubstituting these values, the Gramian is:\n$$W_c(\\ln 2) = \\begin{pmatrix} \\ln 2 & 1/2 & 0 \\\\ 1/2 & 3/8 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$$\nThe range of the Gramian, $\\text{Range}(W_c(T))$, is the reachable subspace $\\mathcal{R}_T$. The columns of $W_c(\\ln 2)$ are $(\\ln 2, 1/2, 0)^T$, $(1/2, 3/8, 0)^T$, and $(0, 0, 0)^T$. These vectors span the $xy$-plane, which is precisely the reachable subspace $\\mathcal{R}_T$ found in Part 1.\nThe Gramian is singular because its determinant is clearly $0$ (due to the zero row and column). A singular Gramian indicates that the system is not controllable. The Gramian is nonzero because the dimension of the reachable subspace (its rank) is $2$, not $0$.\n\n**3. Minimal Energy Control**\n\nWe wish to find the minimal energy $J = \\int_{0}^{T} u(t)^2 dt$ required to steer the system from $x(0)=0$ to $x_f = (1, 0, 0)^T$. First, we confirm that $x_f$ is in the reachable subspace $\\mathcal{R}_T$. Since the third component of $x_f$ is $0$, it is indeed reachable.\n\nThe problem is to minimize the norm $\\|u\\|_{L^2}^2$ subject to the constraint $x_f = \\int_{0}^{T} e^{A(T-t)} b u(t) dt$. This is a minimum norm problem in a Hilbert space. The solution $u^*(t)$ must be a linear combination of the functions that define the constraints. The vectorial constraint corresponds to two scalar constraints:\n$$x_f = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\int_{0}^{T} \\begin{pmatrix} 1 \\\\ e^{-(T-t)} \\\\ 0 \\end{pmatrix} u(t) dt$$\nThe optimal control $u^*(t)$ must lie in the subspace spanned by the functions $g_1(t)=1$ and $g_2(t)=e^{-(T-t)}$. Thus, its form is:\n$$u^*(t) = c_1 \\cdot 1 + c_2 \\cdot e^{-(T-t)}$$\nfor some real constants $c_1, c_2$. We substitute this into the state equation to find $c_1$ and $c_2$:\n$$\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\int_{0}^{T} \\begin{pmatrix} 1 \\\\ e^{-(T-t)} \\end{pmatrix} (c_1 + c_2 e^{-(T-t)}) dt$$\n$$\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} c_1 \\int_{0}^{T} dt + c_2 \\int_{0}^{T} e^{-(T-t)} dt \\\\ c_1 \\int_{0}^{T} e^{-(T-t)} dt + c_2 \\int_{0}^{T} e^{-2(T-t)} dt \\end{pmatrix}$$\nThe integrals are the same as those calculated for the Gramian by a change of variable $\\tau=T-t$. The system of equations is:\n$$\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\ln 2 & 1/2 \\\\ 1/2 & 3/8 \\end{pmatrix} \\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix}$$\nWe only need to find $c_1$ and $c_2$. We can solve this system. From the second equation, $c_1/2 + 3c_2/8 = 0 \\implies c_1 = -3c_2/4$. Substituting into the first equation:\n$$1 = (\\ln 2)(-\\frac{3}{4}c_2) + \\frac{1}{2}c_2 = c_2 (\\frac{1}{2} - \\frac{3}{4}\\ln 2) = c_2 \\frac{2 - 3\\ln 2}{4}$$\nThus, $c_2 = \\frac{4}{2 - 3\\ln 2}$, and $c_1 = -\\frac{3}{4} \\left(\\frac{4}{2 - 3\\ln 2}\\right) = \\frac{-3}{2 - 3\\ln 2} = \\frac{3}{3\\ln 2 - 2}$.\n\nThe minimal energy is $J^* = \\int_{0}^{T} (u^*(t))^2 dt$:\n$$J^* = \\int_{0}^{T} (c_1 + c_2 e^{-(T-t)})^2 dt = \\int_{0}^{T} (c_1^2 + 2c_1c_2e^{-(T-t)} + c_2^2e^{-2(T-t)}) dt$$\n$$J^* = c_1^2 \\int_{0}^{T} dt + 2 c_1 c_2 \\int_{0}^{T} e^{-(T-t)} dt + c_2^2 \\int_{0}^{T} e^{-2(T-t)} dt$$\nThis can be written compactly as:\n$$J^* = c_1 \\left( c_1 \\int_{0}^{T} dt + c_2 \\int_{0}^{T} e^{-(T-t)} dt \\right) + c_2 \\left( c_1 \\int_{0}^{T} e^{-(T-t)} dt + c_2 \\int_{0}^{T} e^{-2(T-t)} dt \\right)$$\nUsing the linear system for $c_1, c_2$, the terms in parentheses are $1$ and $0$ respectively:\n$$J^* = c_1(1) + c_2(0) = c_1$$\nTherefore, the minimal input energy is precisely the value of $c_1$:\n$$J^* = \\frac{3}{3\\ln 2 - 2}$$\nThe denominator $3\\ln 2 - 2 = \\ln(8) - \\ln(e^2) = \\ln(8/e^2)$. Since $e \\approx 2.718$, $e^2 \\approx 7.389$, so $8/e^2 > 1$ and $\\ln(8/e^2) > 0$. The energy is positive, as required.", "answer": "$$\\boxed{\\frac{3}{3\\ln(2) - 2}}$$", "id": "2696846"}]}