{"hands_on_practices": [{"introduction": "Before tackling the full Linear Quadratic Gaussian (LQG) problem, we must master its estimation component: the Kalman filter. This first exercise builds a foundational understanding by guiding you through the derivation of the filter for the simplest non-trivial caseâ€”a scalar system. By working from the fundamental prediction and update steps to find the steady-state error variance $P$ and Kalman gain $L$, you will develop a concrete intuition for how an optimal estimator balances trust between a dynamic model and noisy measurements. [@problem_id:2719584]", "problem": "Consider the scalar, time-invariant, stochastic linear system that arises in Linear Quadratic Gaussian (LQG) control under the certainty equivalence principle:\n- State dynamics: $x_{t+1} = a\\,x_t + w_t$,\n- Measurement: $y_t = x_t + v_t$,\nwhere $\\{w_t\\}$ and $\\{v_t\\}$ are mutually independent, zero-mean, white Gaussian noise sequences with variances $\\sigma_w^2$ and $\\sigma_v^2$, respectively. Assume $a \\in \\mathbb{R}\\setminus\\{0\\}$, $\\sigma_w^2 > 0$, and $\\sigma_v^2 > 0$. Let $L$ denote the steady-state Kalman gain for estimating $x_t$ from $y_t$, and let $P$ denote the steady-state, a posteriori estimation error variance, i.e., $P = \\lim_{t\\to\\infty} \\mathbb{E}\\big[(x_t - \\hat{x}_{t|t})^2\\big]$, assuming this limit exists. Using only the core principles of linear least-squares estimation for linear Gaussian systems and without quoting any pre-solved algebraic Riccati formulas, derive and solve the steady-state fixed-point equations to obtain exact, closed-form expressions for $P$ and $L$ in terms of $a$, $\\sigma_w^2$, and $\\sigma_v^2$. Provide your final expressions in exact analytic form (no approximations). No rounding is required, and no physical units are involved. Report your final answer as the pair $(P, L)$.", "solution": "The problem statement is subject to validation.\n\nGivens are extracted verbatim:\n- State dynamics: $x_{t+1} = a\\,x_t + w_t$.\n- Measurement: $y_t = x_t + v_t$.\n- Noise: $\\{w_t\\}$ and $\\{v_t\\}$ are mutually independent, zero-mean, white Gaussian noise sequences with variances $\\mathbb{E}[w_t^2] = \\sigma_w^2$ and $\\mathbb{E}[v_t^2] = \\sigma_v^2$.\n- Parameters: $a \\in \\mathbb{R}\\setminus\\{0\\}$, $\\sigma_w^2 > 0$, and $\\sigma_v^2 > 0$.\n- Definitions: $L$ is the steady-state Kalman gain, and $P = \\lim_{t\\to\\infty} \\mathbb{E}\\big[(x_t - \\hat{x}_{t|t})^2\\big]$ is the steady-state, a posteriori estimation error variance.\n- Assumption: The limit for $P$ exists.\n- Objective: Derive and solve the steady-state fixed-point equations for $P$ and $L$ in terms of $a$, $\\sigma_w^2$, and $\\sigma_v^2$ from core principles.\n\nValidation Verdict: The problem is valid. It is scientifically grounded in established principles of stochastic estimation theory (Kalman filtering). It is well-posed, as the conditions given (and the existence assumption) guarantee a unique, stable, and meaningful steady-state solution. The problem statement is objective, complete, and contains no contradictions or scientifically unsound premises.\n\nThe solution proceeds by deriving the steady-state algebraic Riccati equation from the fundamental principles of the Kalman filter.\n\nLet $\\hat{x}_{t|t-1}$ be the *a priori* state estimate at time $t$ given measurements up to time $t-1$, and let $P_{t|t-1} = \\mathbb{E}[(x_t - \\hat{x}_{t|t-1})^2]$ be its error variance.\nLet $\\hat{x}_{t|t}$ be the *a posteriori* state estimate at time $t$ given measurements up to time $t$, and let $P_{t|t} = \\mathbb{E}[(x_t - \\hat{x}_{t|t})^2]$ be its error variance.\n\nThe Kalman filter consists of a two-step recursive process: time update (prediction) and measurement update (correction).\n\n$1$. Time Update:\nThe state propagates according to $x_{t+1} = a x_t + w_t$. The predicted state is the conditional expectation $\\hat{x}_{t+1|t} = \\mathbb{E}[a x_t + w_t | Y_t] = a \\hat{x}_{t|t}$, where $Y_t$ represents the set of measurements up to time $t$. The process noise $w_t$ is independent of past information and has zero mean.\nThe *a priori* error variance at time $t+1$ is:\n$$P_{t+1|t} = \\mathbb{E}[(x_{t+1} - \\hat{x}_{t+1|t})^2] = \\mathbb{E}[(a x_t + w_t - a \\hat{x}_{t|t})^2]$$\n$$P_{t+1|t} = \\mathbb{E}[(a(x_t - \\hat{x}_{t|t}) + w_t)^2] = a^2 \\mathbb{E}[(x_t - \\hat{x}_{t|t})^2] + 2a \\mathbb{E}[(x_t - \\hat{x}_{t|t})w_t] + \\mathbb{E}[w_t^2]$$\nSince the estimation error at time $t$, $e_{t|t} = x_t - \\hat{x}_{t|t}$, is uncorrelated with the future noise $w_t$, the cross-term is zero. Thus, we obtain the time update equation for the error variance:\n$$P_{t+1|t} = a^2 P_{t|t} + \\sigma_w^2$$\n\n$2$. Measurement Update:\nAt time $t$, we have the *a priori* estimate $\\hat{x}_{t|t-1}$ with variance $P_{t|t-1}$ and a new measurement $y_t = x_t + v_t$. The measurement error $v_t$ has variance $\\sigma_v^2$. The optimal linear least-squares estimate combines these two sources of information. For Gaussian distributions, the posterior precision is the sum of the prior precisions. The precision is the reciprocal of the variance.\n$$\\frac{1}{P_{t|t}} = \\frac{1}{P_{t|t-1}} + \\frac{1}{\\sigma_v^2}$$\nThis gives the measurement update equation for the error variance:\n$$P_{t|t} = \\left( \\frac{1}{P_{t|t-1}} + \\frac{1}{\\sigma_v^2} \\right)^{-1} = \\frac{P_{t|t-1} \\sigma_v^2}{P_{t|t-1} + \\sigma_v^2}$$\nThe Kalman gain $L_t$ is given by $L_t = \\frac{P_{t|t-1}}{P_{t|t-1} + \\sigma_v^2}$. From this, we also have the relation $P_{t|t} = (1-L_t) P_{t|t-1} = L_t \\sigma_v^2$.\n\n$3$. Steady-State Analysis:\nIn steady state, the variances become constant. Let $P = \\lim_{t\\to\\infty} P_{t|t}$ and $P^- = \\lim_{t\\to\\infty} P_{t|t-1}$. The update equations become a system of algebraic equations:\n$$(1) \\quad P^- = a^2 P + \\sigma_w^2$$\n$$(2) \\quad P = \\frac{P^- \\sigma_v^2}{P^- + \\sigma_v^2}$$\nWe substitute $(1)$ into $(2)$ to obtain a single equation for the steady-state a posteriori variance $P$:\n$$P = \\frac{(a^2 P + \\sigma_w^2) \\sigma_v^2}{(a^2 P + \\sigma_w^2) + \\sigma_v^2}$$\nMultiplying both sides by the denominator yields:\n$$P(a^2 P + \\sigma_w^2 + \\sigma_v^2) = (a^2 P + \\sigma_w^2) \\sigma_v^2$$\n$$a^2 P^2 + P\\sigma_w^2 + P\\sigma_v^2 = a^2 P\\sigma_v^2 + \\sigma_w^2\\sigma_v^2$$\nRearranging the terms gives the discrete algebraic Riccati equation for this system:\n$$a^2 P^2 + (\\sigma_w^2 + \\sigma_v^2 - a^2\\sigma_v^2) P - \\sigma_w^2\\sigma_v^2 = 0$$\n$$a^2 P^2 + (\\sigma_w^2 + (1-a^2)\\sigma_v^2) P - \\sigma_w^2\\sigma_v^2 = 0$$\n\n$4$. Solving the Riccati Equation:\nThis is a quadratic equation in $P$ of the form $A_0 P^2 + B_0 P + C_0 = 0$, with coefficients:\n$A_0 = a^2$\n$B_0 = \\sigma_w^2 + (1-a^2)\\sigma_v^2$\n$C_0 = -\\sigma_w^2\\sigma_v^2$\nThe solution for $P$ is given by the quadratic formula:\n$$P = \\frac{-B_0 \\pm \\sqrt{B_0^2 - 4A_0C_0}}{2A_0}$$\nThe discriminant is $\\Delta = B_0^2 - 4(a^2)(-\\sigma_w^2\\sigma_v^2) = (\\sigma_w^2 + (1-a^2)\\sigma_v^2)^2 + 4a^2\\sigma_w^2\\sigma_v^2$. Since $a \\neq 0$, $\\sigma_w^2 > 0$, and $\\sigma_v^2 > 0$, we have $\\Delta > 0$.\nAs $P$ represents a variance, it must be non-negative. The denominator $2a^2$ is positive. The term $\\sqrt{\\Delta} = \\sqrt{B_0^2 + 4a^2\\sigma_w^2\\sigma_v^2} > |B_0|$. Therefore, the numerator $-B_0 - \\sqrt{\\Delta}$ is always negative. To ensure $P \\ge 0$, we must choose the positive root:\n$$P = \\frac{-(\\sigma_w^2 + (1-a^2)\\sigma_v^2) + \\sqrt{(\\sigma_w^2 + (1-a^2)\\sigma_v^2)^2 + 4a^2\\sigma_w^2\\sigma_v^2}}{2a^2}$$\nTo simplify the presentation of this expression, we can rationalize the numerator:\n$$P = \\frac{-B_0 + \\sqrt{\\Delta}}{2A_0} \\times \\frac{-B_0 - \\sqrt{\\Delta}}{-B_0 - \\sqrt{\\Delta}} = \\frac{B_0^2 - \\Delta}{2A_0(-B_0 - \\sqrt{\\Delta})} = \\frac{-4A_0C_0}{2A_0(-B_0 - \\sqrt{\\Delta})} = \\frac{-2C_0}{-B_0 - \\sqrt{\\Delta}} = \\frac{2C_0}{B_0 + \\sqrt{\\Delta}}$$\nSubstituting the coefficients back:\n$$P = \\frac{2\\sigma_w^2\\sigma_v^2}{(\\sigma_w^2 + (1-a^2)\\sigma_v^2) + \\sqrt{(\\sigma_w^2 + (1-a^2)\\sigma_v^2)^2 + 4a^2\\sigma_w^2\\sigma_v^2}}$$\n\n$5$. Finding the Kalman Gain $L$:\nThe steady-state gain $L$ is related to $P$ by $P = L \\sigma_v^2$. Thus, $L = P/\\sigma_v^2$.\n$$L = \\frac{P}{\\sigma_v^2} = \\frac{2\\sigma_w^2}{(\\sigma_w^2 + (1-a^2)\\sigma_v^2) + \\sqrt{(\\sigma_w^2 + (1-a^2)\\sigma_v^2)^2 + 4a^2\\sigma_w^2\\sigma_v^2}}$$\n\nThe final result is the pair $(P, L)$.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{2\\sigma_w^2\\sigma_v^2}{(\\sigma_w^2 + (1-a^2)\\sigma_v^2) + \\sqrt{(\\sigma_w^2 + (1-a^2)\\sigma_v^2)^2 + 4a^2\\sigma_w^2\\sigma_v^2}} & \\frac{2\\sigma_w^2}{(\\sigma_w^2 + (1-a^2)\\sigma_v^2) + \\sqrt{(\\sigma_w^2 + (1-a^2)\\sigma_v^2)^2 + 4a^2\\sigma_w^2\\sigma_v^2}} \\end{pmatrix} } $$", "id": "2719584"}, {"introduction": "Having explored the estimation side, we now turn to the control component, the Linear Quadratic Regulator (LQR). This practice challenges you to derive the optimal state-feedback controller for a two-dimensional system entirely from first principles, a significant step up in complexity. By deriving the discrete-time algebraic Riccati equation from the Bellman equation and solving it for the stabilizing gain $K$, you will solidify your understanding of the link between dynamic programming and optimal control theory. [@problem_id:2719578]", "problem": "Consider the discrete-time linear time-invariant system with state update $x_{k+1} = A x_{k} + B u_{k}$ and infinite-horizon quadratic cost $J = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\mathsf{T}} Q x_{k} + u_{k}^{\\mathsf{T}} R u_{k} \\right)$, where\n$$\nA = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad\nQ = I_{2},\\quad\nR = 1.\n$$\nStarting from the principle of optimality for the dynamic programming formulation of the infinite-horizon discrete-time Linear Quadratic Regulator (LQR) problem, let the stationary value function be quadratic $V(x) = x^{\\mathsf{T}} P x$ with $P = P^{\\mathsf{T}} \\succeq 0$. Derive the matrix relation that $P$ must satisfy and solve analytically for the optimal state-feedback gain $K$ such that the optimal control is $u_{k} = - K x_{k}$. Then verify that the closed-loop matrix $A - B K$ is Schur stable by characterizing its eigenvalues. Finally, briefly explain how the same $K$ would be used with a state estimate in a Linear Quadratic Gaussian (LQG) controller by the certainty equivalence principle. Express your final answer as the exact row vector $K$ using radicals; do not approximate or round.", "solution": "The problem requires the derivation and solution of a discrete-time infinite-horizon Linear Quadratic Regulator (LQR) problem, followed by a stability analysis and a conceptual explanation of its connection to Linear Quadratic Gaussian (LQG) control.\n\n**Step 1: Problem Validation**\n\nThe problem statement provides the following givens: a discrete-time linear time-invariant system and a cost function.\n- State update equation: $x_{k+1} = A x_{k} + B u_{k}$\n- Infinite-horizon quadratic cost: $J = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} \\right)$\n- System matrices:\n$$\nA = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad\nQ = I_{2} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix},\\quad\nR = 1\n$$\n- The value function is assumed to be of the form $V(x) = x^{\\top} P x$ where $P = P^{\\top} \\succeq 0$.\n- The optimal control law is of the form $u_k = -K x_k$.\n\nThe problem is scientifically grounded in control theory, well-posed, and stated objectively. The controllability matrix for the pair $(A, B)$ is $\\mathcal{C} = \\begin{bmatrix} B & AB \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ 1 & 1 \\end{bmatrix}$, which has a determinant of $-1$ and is thus full rank. This means the system is controllable, which is a sufficient condition for stabilizability. The pair $(A, \\sqrt{Q}) = (A, I)$ is observable, as the observability matrix $\\mathcal{O} = \\begin{bmatrix} I \\\\ A^{\\top} \\end{bmatrix}$ has full column rank. Since $Q \\succeq 0$ and $R > 0$, and the system is stabilizable and detectable, a unique, positive semi-definite, stabilizing solution $P$ to the associated algebraic Riccati equation exists. The problem is valid.\n\n**Step 2: Derivation of the Discrete Algebraic Riccati Equation (DARE)**\n\nThe principle of optimality leads to the Bellman equation for the infinite-horizon value function $V(x)$:\n$$ V(x) = \\min_{u} \\left\\{ x^{\\top} Q x + u^{\\top} R u + V(Ax + Bu) \\right\\} $$\nSubstituting the quadratic value function $V(x) = x^{\\top} P x$:\n$$ x^{\\top} P x = \\min_{u} \\left\\{ x^{\\top} Q x + u^{\\top} R u + (Ax + Bu)^{\\top} P (Ax + Bu) \\right\\} $$\nTo find the optimal control $u$, we minimize the term in the braces, let's call it $J_u$. We take its derivative with respect to $u$ and set it to zero.\n$$ \\frac{\\partial J_u}{\\partial u} = \\frac{\\partial}{\\partial u} \\left( u^{\\top} R u + (Ax + Bu)^{\\top} P (Ax + Bu) \\right) = 2Ru + 2B^{\\top}P(Ax + Bu) = 0 $$\n$$ (R + B^{\\top} P B)u + B^{\\top} P A x = 0 $$\nSolving for the optimal control $u_{k}^*$ at time step $k$:\n$$ u_{k}^* = -(R + B^{\\top} P B)^{-1} B^{\\top} P A x_{k} $$\nThis gives the optimal state-feedback gain matrix $K = (R + B^{\\top} P B)^{-1} B^{\\top} P A$. Substituting $u_k^* = -K x_k$ back into the Bellman equation yields:\n$$ x^{\\top} P x = x^{\\top} Q x + (-Kx)^{\\top} R (-Kx) + (A-BK)x^{\\top} P (A-BK)x $$\nSince this must hold for all $x$, we obtain the matrix relation $P = Q + K^{\\top} R K + (A-BK)^{\\top} P (A-BK)$. A more direct form, the Discrete Algebraic Riccati Equation (DARE), is obtained by substituting $u^*$ back into the minimized expression:\n$$ P = Q + A^{\\top} P A - A^{\\top} P B (R + B^{\\top} P B)^{-1} B^{\\top} P A $$\n\n**Step 3: Solving the DARE for P**\n\nLet $P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix}$ be the symmetric positive semi-definite solution. We calculate the terms in the DARE:\n- $A^{\\top} P A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} p_{11} & p_{11}+p_{12} \\\\ p_{11}+p_{12} & p_{11}+2p_{12}+p_{22} \\end{bmatrix}$\n- $B^{\\top} P B = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = p_{22}$\n- $A^{\\top} P B = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} p_{12} \\\\ p_{12}+p_{22} \\end{bmatrix}$\n- The correction term is $\\frac{1}{1+p_{22}} (A^{\\top} P B)(B^{\\top} P A) = \\frac{1}{1+p_{22}} \\begin{bmatrix} p_{12}^2 & p_{12}(p_{12}+p_{22}) \\\\ p_{12}(p_{12}+p_{22}) & (p_{12}+p_{22})^2 \\end{bmatrix}$\n\nSubstituting these into the DARE $P = Q + A^{\\top}PA - (\\text{correction term})$ gives a system of three nonlinear equations:\n1. ($1,1$)-entry: $p_{11} = 1 + p_{11} - \\frac{p_{12}^2}{1+p_{22}} \\implies p_{12}^2 = 1+p_{22}$.\n2. ($1,2$)-entry: $p_{12} = 0 + p_{11}+p_{12} - \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}} \\implies p_{11} = \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}}$.\n3. ($2,2$)-entry: $p_{22} = 1 + p_{11}+2p_{12}+p_{22} - \\frac{(p_{12}+p_{22})^2}{1+p_{22}} \\implies 0 = 1+p_{11}+2p_{12} - \\frac{(p_{12}+p_{22})^2}{1+p_{22}}$.\n\nUsing $p_{22} = p_{12}^2 - 1$ from (1), we simplify (2): $p_{11} = \\frac{p_{12}(p_{12}+p_{12}^2-1)}{p_{12}^2} = 1+p_{12}-\\frac{1}{p_{12}}$. For $P \\succeq 0$, we need $p_{22} \\ge 0$, so $p_{12}^2 \\ge 1$.\nSubstituting $p_{11}$ and $p_{22}$ into (3):\n$0 = 1 + (1+p_{12}-\\frac{1}{p_{12}}) + 2p_{12} - \\frac{(p_{12}+p_{12}^2-1)^2}{p_{12}^2}$\n$0 = 2+3p_{12}-\\frac{1}{p_{12}} - (p_{12}+1-\\frac{1}{p_{12}})^2$\nLet $z=p_{12}$. We expand the squared term: $(z+1-1/z)^2 = z^2+1+1/z^2+2z-2-2/z = z^2+2z-1-2/z+1/z^2$.\n$0 = 2+3z-1/z - (z^2+2z-1-2/z+1/z^2) = -z^2+z+3+1/z-1/z^2$.\nMultiplying by $-z^2$ (since $p_{12} \\neq 0$) yields the quartic equation: $z^4 - z^3 - 3z^2 - z + 1 = 0$.\nThis is a reciprocal equation. Dividing by $z^2$: $(z^2+\\frac{1}{z^2}) - (z+\\frac{1}{z}) - 3 = 0$.\nLet $w = z+\\frac{1}{z}$. Then $w^2-2 = z^2+\\frac{1}{z^2}$. The equation becomes $(w^2-2) - w - 3 = 0 \\implies w^2-w-5=0$.\nThe solutions for $w$ are $w = \\frac{1 \\pm \\sqrt{1 - 4(1)(-5)}}{2} = \\frac{1 \\pm \\sqrt{21}}{2}$.\nFor $P$ to be a real matrix, $p_{12}=z$ must be real. This requires the roots of $z^2-wz+1=0$ to be real, which means $w^2-4 \\ge 0$, or $|w| \\ge 2$.\n$w_1 = (1+\\sqrt{21})/2 \\approx 2.79 > 2$. This gives real roots for $z$.\n$w_2 = (1-\\sqrt{21})/2 \\approx -1.79$. $|w_2|<2$. This would give complex roots for $z$, so we discard it.\nWe must choose $w = w_1 = (1+\\sqrt{21})/2$.\nThe roots of $z^2-w_1 z+1=0$ are $z_a, z_b=1/z_a$. For the stabilizing solution, we need $p_{22} = z^2-1 \\ge 0$, which implies $|z| \\ge 1$. We must choose the larger root, $p_{12} = z_a > 1$.\n\n**Step 4: Computing the Optimal Gain K**\n\nThe optimal gain is $K = (R + B^{\\top} P B)^{-1} B^{\\top} P A = \\frac{1}{1+p_{22}} [p_{12}, p_{12}+p_{22}]$.\nUsing $1+p_{22} = p_{12}^2$, we have $K = \\frac{1}{p_{12}^2}[p_{12}, p_{12}+p_{12}^2-1] = [1/p_{12}, 1+1/p_{12}-1/p_{12}^2]$.\nLet $k_1 = 1/p_{12}$ and $k_2 = 1+1/p_{12}-1/p_{12}^2 = 1+k_1-k_1^2$.\nSince $p_{12}$ is the larger root of $z^2-w_1 z+1=0$, $k_1=1/p_{12}$ is the smaller root of the same equation solved for $k$: $k^2 - w_1 k + 1 = 0$.\n$k_1 = \\frac{w_1 - \\sqrt{w_1^2-4}}{2}$, where $w_1 = \\frac{1+\\sqrt{21}}{2}$.\n$w_1^2-4 = (\\frac{1+\\sqrt{21}}{2})^2 - 4 = \\frac{1+2\\sqrt{21}+21}{4}-4 = \\frac{22+2\\sqrt{21}-16}{4} = \\frac{6+2\\sqrt{21}}{4} = \\frac{3+\\sqrt{21}}{2}$.\nSo, $k_1 = \\frac{\\frac{1+\\sqrt{21}}{2} - \\sqrt{\\frac{3+\\sqrt{21}}{2}}}{2} = \\frac{1+\\sqrt{21} - \\sqrt{2(3+\\sqrt{21})}}{4} = \\frac{1+\\sqrt{21} - \\sqrt{6+2\\sqrt{21}}}{4}$.\nNow we find $k_2 = 1+k_1-k_1^2$. From $k_1^2-w_1 k_1+1=0$, we have $k_1^2=w_1 k_1-1$.\n$k_2 = 1+k_1-(w_1 k_1-1) = 2+(1-w_1)k_1$.\n$1-w_1 = 1-\\frac{1+\\sqrt{21}}{2} = \\frac{1-\\sqrt{21}}{2}$.\n$k_2 = 2+\\frac{1-\\sqrt{21}}{2}k_1 = 2+\\frac{1-\\sqrt{21}}{2}\\left(\\frac{1+\\sqrt{21}-\\sqrt{6+2\\sqrt{21}}}{4}\\right) = 2+\\frac{1-21-(1-\\sqrt{21})\\sqrt{6+2\\sqrt{21}}}{8}$.\n$k_2 = 2 - \\frac{20}{8} - \\frac{1-\\sqrt{21}}{8}\\sqrt{6+2\\sqrt{21}} = -\\frac{1}{2} + \\frac{\\sqrt{21}-1}{8}\\sqrt{6+2\\sqrt{21}}$.\nSo, $K = \\begin{bmatrix} k_1 & k_2 \\end{bmatrix}$.\n\n**Step 5: Stability Verification**\n\nThe closed-loop system matrix is $A_{cl} = A - BK = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} k_1 & k_2 \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\\\ -k_1 & 1-k_2 \\end{bmatrix}$.\nThe characteristic polynomial is $\\det(\\lambda I - A_{cl}) = 0$:\n$\\det \\begin{bmatrix} \\lambda-1 & -1 \\\\ k_1 & \\lambda-(1-k_2) \\end{bmatrix} = (\\lambda-1)(\\lambda-1+k_2) + k_1 = 0$.\n$\\lambda^2 + (k_2-2)\\lambda + (1-k_2+k_1) = 0$.\nUsing the relations $k_2-2=(1-w_1)k_1$ and $1-k_2+k_1 = 1-(2+(1-w_1)k_1)+k_1 = -1+w_1k_1$. From $k_1^2 - w_1k_1 + 1 = 0$, we have $w_1k_1 = k_1^2+1$, so $1-k_2+k_1 = -1+(k_1^2+1) = k_1^2$. The polynomial becomes:\n$\\lambda^2 + (1-w_1)k_1 \\lambda + k_1^2 = 0$.\nThe term under the square root in the quadratic formula for $\\lambda$ is $( (1-w_1)k_1 )^2 - 4k_1^2 = k_1^2((1-w_1)^2 - 4)$.\n$(1-w_1)^2-4 = (\\frac{1-\\sqrt{21}}{2})^2-4 = \\frac{1-2\\sqrt{21}+21}{4}-4 = \\frac{22-2\\sqrt{21}-16}{4} = \\frac{6-2\\sqrt{21}}{4} = \\frac{3-\\sqrt{21}}{2} < 0$.\nThe roots are complex conjugates. The magnitude squared of the roots is the constant term of the monic polynomial, which is $k_1^2$.\n$|\\lambda|^2 = k_1^2$.\nSo, $|\\lambda| = |k_1|$. Since $p_{12} > 1$, we have $0 < k_1 = 1/p_{12} < 1$. The eigenvalues of the closed-loop system are strictly inside the unit circle, confirming that $A-BK$ is Schur stable.\n\n**Step 6: Certainty Equivalence Principle**\n\nThe Linear Quadratic Gaussian (LQG) control problem extends the LQR framework to systems affected by Gaussian noise. For a system described by $x_{k+1} = Ax_k + Bu_k + w_k$ and $y_k = Cx_k + v_k$, where $w_k$ and $v_k$ are zero-mean Gaussian white noise processes, the goal is to minimize the expected value of the same quadratic cost functional.\nThe solution to the LQG problem famously separates into an optimal state estimation problem and an optimal control problem. This is known as the **separation principle**.\nFirst, a Kalman filter is designed to produce an optimal estimate of the state, $\\hat{x}_k$, based on the history of measurements.\nThen, the **certainty equivalence principle** states that the optimal control law is obtained by simply using this state estimate $\\hat{x}_k$ in place of the true (and unknown) state $x_k$ in the deterministic LQR control law.\nTherefore, the LQG controller would be $u_k = -K \\hat{x}_k$, using the very same gain matrix $K$ derived in this problem. The design of the controller $(K)$ and the observer (Kalman filter) are independent. This property is a cornerstone of modern control theory but holds specifically for linear systems with Gaussian noise and quadratic costs.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1+\\sqrt{21} - \\sqrt{6+2\\sqrt{21}}}{4} & -\\frac{1}{2} + \\frac{\\sqrt{21}-1}{8}\\sqrt{6+2\\sqrt{21}} \\end{pmatrix}}\n$$", "id": "2719578"}, {"introduction": "Analytical derivations provide deep insight, but modern control engineering is built on the foundation of numerical computation. This final practice bridges that gap, challenging you to implement and verify a complete LQG design for several unstable systems using standard software tools. By computing the stabilizing control gain $K$ and observer gain $L$ and confirming the stability of the closed-loop system, you will witness the certainty equivalence principle in action and gain hands-on experience with the practical workflow of a control systems engineer. [@problem_id:2719583]", "problem": "Consider a discrete-time, linear time-invariant system with state update and noisy measurement given by $x_{k+1} = A x_k + B u_k + w_k$ and $y_k = C x_k + v_k$, where $x_k \\in \\mathbb{R}^n$, $u_k \\in \\mathbb{R}^m$, $y_k \\in \\mathbb{R}^p$, and the process noise $w_k$ and measurement noise $v_k$ are zero-mean, independent Gaussian sequences with covariances $W \\succeq 0$ and $V \\succ 0$, respectively. For the infinite-horizon Linear Quadratic Gaussian (LQG) control problem with quadratic performance index $J = \\sum_{k=0}^{\\infty} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right)$, where $Q \\succeq 0$ and $R \\succ 0$, the certainty-equivalence principle states that the optimal controller is the state-feedback law $u_k = -K \\hat{x}_k$ where $\\hat{x}_k$ is the state estimate produced by the steady-state Kalman filter. The controller gain $K$ is constructed from the stabilizing solution $P \\succeq 0$ of the discrete-time Algebraic Riccati Equation (ARE) for the control problem, and the steady-state Kalman filter gain $L$ is constructed from the stabilizing solution $S \\succeq 0$ of the dual discrete-time ARE for the estimation problem. Under standard stabilizability and detectability assumptions, the closed-loop matrix $A - B K$ must be Schur (all eigenvalues strictly inside the unit circle), and the estimation error dynamics matrix $A - L C$ must also be Schur. Your task is to compute these stabilizing solutions numerically and verify the Schur property for each.\n\nUse only mathematically sound facts as the starting point: the definitions of the discrete-time system, quadratic cost, stabilizing solution of the discrete-time Algebraic Riccati Equation, and the definitions of the Linear Quadratic Regulator (LQR) and steady-state Kalman filter in the Linear Quadratic Gaussian (LQG) framework. Do not assume any special structure beyond what is explicitly given.\n\nImplement a program that, for each test case below, performs the following steps:\n- Numerically computes the stabilizing solution $P$ to the discrete-time Algebraic Riccati Equation for the control problem and constructs the state-feedback gain $K$.\n- Numerically computes the stabilizing solution $S$ to the dual discrete-time Algebraic Riccati Equation for the estimation problem and constructs the steady-state Kalman gain $L$.\n- Verifies that all eigenvalues of $A - B K$ have magnitude strictly less than $1$.\n- Verifies that all eigenvalues of $A - L C$ have magnitude strictly less than $1$.\n\nThe program must use a small numerical tolerance $0 < \\varepsilon \\ll 1$ to implement the strict inequality, declaring stability if $\\max_i |\\lambda_i| < 1 - \\varepsilon$ for the relevant eigenvalues $\\{\\lambda_i\\}$.\n\nTest Suite:\nProvide results for the following three cases. All matrices and scalars are real-valued.\n\n- Case $1$ (unstable $2 \\times 2$ system, single input, single output):\n  - $A_1 = \\begin{bmatrix} 1.2 & 0.5 \\\\ 0 & 1.1 \\end{bmatrix}$,\n    $B_1 = \\begin{bmatrix} 1.0 \\\\ 0.3 \\end{bmatrix}$,\n    $Q_1 = \\begin{bmatrix} 1.0 & 0 \\\\ 0 & 1.0 \\end{bmatrix}$,\n    $R_1 = \\begin{bmatrix} 0.5 \\end{bmatrix}$,\n    $C_1 = \\begin{bmatrix} 1.0 & 0.0 \\end{bmatrix}$,\n    $W_1 = 0.1 \\cdot I_2$,\n    $V_1 = \\begin{bmatrix} 0.5 \\end{bmatrix}$.\n\n- Case $2$ (unstable $3 \\times 3$ system, full input, full state measurement):\n  - $A_2 = \\begin{bmatrix} 1.1 & 0.2 & 0.0 \\\\ 0.0 & 1.05 & 0.3 \\\\ 0.1 & 0.0 & 1.2 \\end{bmatrix}$,\n    $B_2 = I_3$,\n    $Q_2 = \\mathrm{diag}(2.0, 1.0, 3.0)$,\n    $R_2 = 0.8 \\cdot I_3$,\n    $C_2 = I_3$,\n    $W_2 = 0.05 \\cdot I_3$,\n    $V_2 = 0.2 \\cdot I_3$.\n\n- Case $3$ (nearly marginally unstable $2 \\times 2$ system, single input, full state measurement):\n  - $A_3 = \\begin{bmatrix} 1.000001 & 0.01 \\\\ 0.0 & 1.000001 \\end{bmatrix}$,\n    $B_3 = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}$,\n    $Q_3 = \\mathrm{diag}(0.0001, 1.0)$,\n    $R_3 = \\begin{bmatrix} 0.1 \\end{bmatrix}$,\n    $C_3 = I_2$,\n    $W_3 = 0.0001 \\cdot I_2$,\n    $V_3 = 0.001 \\cdot I_2$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain six boolean values in the following order:\n- First three entries: for Cases $1$, $2$, $3$, whether all eigenvalues of $A - B K$ lie strictly inside the unit circle.\n- Next three entries: for Cases $1$, $2$, $3$, whether all eigenvalues of $A - L C$ lie strictly inside the unit circle.\n\nFor example, the output should look like $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5,\\text{result}_6]$, where each $\\text{result}_i$ is either $\\text{True}$ or $\\text{False}$.\n\nNo physical units or angle units are involved, so no unit conversions are required. All computations must be carried out numerically with appropriate conditioning safeguards. The output must be deterministic and reproducible without randomness.", "solution": "The problem presented is a standard exercise in modern control theory, specifically within the domain of Linear Quadratic Gaussian (LQG) control for discrete-time, linear time-invariant (LTI) systems. Before proceeding to the numerical solution, it is imperative to establish the theoretical foundation upon which the calculations are based. The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution.\n\nThe system is described by the state-space equations:\n$$x_{k+1} = A x_k + B u_k + w_k$$\n$$y_k = C x_k + v_k$$\nwhere $w_k$ and $v_k$ are independent, zero-mean Gaussian white noise processes with covariance matrices $W \\succeq 0$ and $V \\succ 0$, respectively.\n\nThe objective is to design a controller that minimizes the infinite-horizon quadratic cost function:\n$$J = \\sum_{k=0}^{\\infty} \\left( x_k^\\top Q x_k + u_k^\\top R u_k \\right)$$\nwith weighting matrices $Q \\succeq 0$ and $R \\succ 0$.\n\nThe LQG framework, under the certainty equivalence principle, separates the problem into two independent components: an optimal state feedback controller (Linear Quadratic Regulator or LQR) and an optimal state estimator (Kalman filter).\n\nFirst, we design the LQR controller, assuming full state availability. The optimal control law is a linear state feedback $u_k = -K x_k$. The gain matrix $K$ is determined by the unique, stabilizing, positive semi-definite solution $P$ to the discrete-time Algebraic Riccati Equation (DARE) for control:\n$$P = A^\\top P A - (A^\\top P B)(R + B^\\top P B)^{-1}(B^\\top P A) + Q$$\nThe existence of such a stabilizing solution $P \\succeq 0$ is guaranteed if the pair $(A, B)$ is stabilizable and the pair $(A, \\sqrt{Q})$ is detectable. The optimal feedback gain is then calculated as:\n$$K = (R + B^\\top P B)^{-1} B^\\top P A$$\nThe resulting closed-loop system dynamics, $x_{k+1} = (A - B K) x_k$, are guaranteed to be stable. That is, the matrix $A - B K$ is Schur, meaning all its eigenvalues lie strictly inside the unit circle in the complex plane.\n\nSecond, we design a state estimator. Since the state $x_k$ is not measured directly but is observed through the noisy measurement $y_k$, we use a steady-state Kalman filter to generate an optimal estimate of the state, $\\hat{x}_k$. The design of this filter is dual to the LQR problem. The steady-state prediction error covariance, $S$, is the unique, stabilizing, positive semi-definite solution to the DARE for estimation:\n$$S = A S A^\\top - A S C^\\top (V + C S C^\\top)^{-1} C S A^\\top + W$$\nThe existence of such a stabilizing solution $S \\succeq 0$ is guaranteed if the pair $(A, \\sqrt{W})$ is stabilizable and the pair $(A, C)$ is detectable.\n\nThe problem specifies the construction of the Kalman filter gain matrix $L$, which is often called the corrector gain. It is computed from the covariance solution $S$ as:\n$$L = A S C^\\top (V + C S C^\\top)^{-1}$$\nStandard Kalman filter theory establishes that the eigenvalues of the matrix $A(I - L_c C)$ (where $L_c$ is the corrector gain $S C^\\top (V + C S C^\\top)^{-1}$) govern the error dynamics and are strictly inside the unit circle. The problem directs us to verify the Schur stability of the matrix $A - LC$, where $L$ is the corrector gain from the filter equations. The matrix $A-LC$ describes the error dynamics of a Luenberger-style observer $\\hat{x}_{k+1} = A\\hat{x}_k + Bu_k + L(y_k - C\\hat{x}_k)$, which is also guaranteed to be stable under the detectability condition. We will proceed with the numerical verification as instructed.\n\nThe task is to numerically solve for $P$ and $S$ for three distinct test cases, compute the corresponding gains $K$ and $L$, and then verify the Schur stability of the matrices $A - B K$ and $A - L C$. The stability check is performed by computing the eigenvalues $\\{\\lambda_i\\}$ of the respective matrix and ensuring that $\\max_i |\\lambda_i| < 1 - \\varepsilon$ for a small tolerance $\\varepsilon > 0$. We will use $\\varepsilon = 10^{-9}$. All provided test cases satisfy the required stabilizability and detectability conditions, ensuring that stabilizing solutions to the Riccati equations exist.\n\nThe computational procedure for each test case is as follows:\n1.  Solve the control DARE for $P$ using the provided matrices $A$, $B$, $Q$, and $R$.\n2.  Compute the control gain $K$ and verify if the matrix $A - B K$ is Schur.\n3.  Solve the estimation DARE for $S$ by applying the duality principle, i.e., solving the control DARE with substitutions $A \\to A^\\top$, $B \\to C^\\top$, $Q \\to W$, and $R \\to V$.\n4.  Compute the filter gain $L$ and verify if the matrix $A - L C$ is Schur.\n5.  The results of these verifications (boolean values) are collected and presented in the required format.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_discrete_are\n\ndef solve():\n    \"\"\"\n    Solves for LQR and Kalman gains for given systems and verifies\n    the stability of the resulting closed-loop and observer dynamics.\n    \"\"\"\n    epsilon = 1e-9\n\n    # Case 1 (unstable 2x2 system, single input, single output)\n    A1 = np.array([[1.2, 0.5], [0, 1.1]])\n    B1 = np.array([[1.0], [0.3]])\n    Q1 = np.array([[1.0, 0], [0, 1.0]])\n    R1 = np.array([[0.5]])\n    C1 = np.array([[1.0, 0.0]])\n    W1 = 0.1 * np.identity(2)\n    V1 = np.array([[0.5]])\n\n    # Case 2 (unstable 3x3 system, full input, full state measurement)\n    A2 = np.array([[1.1, 0.2, 0.0], [0.0, 1.05, 0.3], [0.1, 0.0, 1.2]])\n    B2 = np.identity(3)\n    Q2 = np.diag([2.0, 1.0, 3.0])\n    R2 = 0.8 * np.identity(3)\n    C2 = np.identity(3)\n    W2 = 0.05 * np.identity(3)\n    V2 = 0.2 * np.identity(3)\n\n    # Case 3 (nearly marginally unstable 2x2 system, single input, full state measurement)\n    A3 = np.array([[1.000001, 0.01], [0.0, 1.000001]])\n    B3 = np.array([[0.0], [1.0]])\n    Q3 = np.diag([0.0001, 1.0])\n    R3 = np.array([[0.1]])\n    C3 = np.identity(2)\n    W3 = 0.0001 * np.identity(2)\n    V3 = 0.001 * np.identity(2)\n\n    test_cases = [\n        (A1, B1, Q1, R1, C1, W1, V1),\n        (A2, B2, Q2, R2, C2, W2, V2),\n        (A3, B3, Q3, R3, C3, W3, V3)\n    ]\n\n    k_stability_results = []\n    l_stability_results = []\n\n    for A, B, Q, R, C, W, V in test_cases:\n        # --- LQR Controller Analysis ---\n        # Solve the discrete-time Algebraic Riccati Equation for P\n        P = solve_discrete_are(A, B, Q, R)\n\n        # Compute the LQR gain K\n        inv_term_K = np.linalg.inv(R + B.T @ P @ B)\n        K = inv_term_K @ (B.T @ P @ A)\n        \n        # Form the closed-loop matrix A - BK\n        A_cl = A - B @ K\n        \n        # Check if A - BK is Schur stable\n        eigs_K = np.linalg.eigvals(A_cl)\n        is_stable_K = np.max(np.abs(eigs_K)) < 1.0 - epsilon\n        k_stability_results.append(is_stable_K)\n\n        # --- Kalman Filter Analysis ---\n        # Solve the dual DARE for S\n        # This is done by solving for A.T, C.T, W, V\n        S = solve_discrete_are(A.T, C.T, W, V)\n        \n        # Compute the Kalman gain L\n        inv_term_L = np.linalg.inv(V + C @ S @ C.T)\n        L = S @ C.T @ inv_term_L\n        \n        # Form the estimator dynamics matrix A - LC\n        A_est = A - L @ C\n        \n        # Check if A - LC is Schur stable\n        eigs_L = np.linalg.eigvals(A_est)\n        is_stable_L = np.max(np.abs(eigs_L)) < 1.0 - epsilon\n        l_stability_results.append(is_stable_L)\n        \n    final_results = k_stability_results + l_stability_results\n    \n    # Python's bool `True` maps to string 'True'. Problem wants True/False.\n    final_results_str = [str(val) for val in final_results]\n    print(f\"[{','.join(final_results_str)}]\")\n\nsolve()\n```", "id": "2719583"}]}