{"hands_on_practices": [{"introduction": "The best way to build intuition for a complex control law is to derive it for the simplest non-trivial case. This exercise guides you through solving the LQR problem for a scalar system from first principles using the Hamilton-Jacobi-Bellman equation, which is a cornerstone of optimal control. By working through this fundamental example [@problem_id:2734387], you will gain a concrete understanding of how the Algebraic Riccati Equation (ARE) arises and how weighting matrices $Q$ and $R$ influence the optimal feedback gain.", "problem": "Consider the scalar linear time-invariant system $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ with $b \\neq 0$, $q \\ge 0$, and $r > 0$. The performance index is the infinite-horizon quadratic cost $J = \\int_{0}^{\\infty} \\big(q\\,x(t)^{2} + r\\,u(t)^{2}\\big)\\,dt$. Using first principles of dynamic programming via the Hamilton–Jacobi–Bellman equation, derive the optimal state-feedback law $u(t) = -K\\,x(t)$ that minimizes $J$ and the associated value function coefficient $P$ in the quadratic ansatz $V(x) = P\\,x^{2}$. Express both $P$ and $K$ in exact closed form in terms of $a$, $b$, $q$, and $r$, and justify the choice of the stabilizing branch. Then, in the regime $|a| \\ll \\sqrt{q\\,r}/|b|$, determine the leading-order asymptotic scaling of $K$ and briefly explain why it holds. Provide your final answer as the exact closed-form expression for $K$ as a function of $a$, $b$, $q$, and $r$ (no numerical evaluation is required).", "solution": "We begin from the Hamilton–Jacobi–Bellman (HJB) equation for infinite-horizon optimal control. For the scalar system $\\dot{x} = a\\,x + b\\,u$ and cost density $\\ell(x,u) = q\\,x^{2} + r\\,u^{2}$ with $q \\ge 0$ and $r > 0$, the value function $V(x)$ satisfies\n$$\n0 \\;=\\; \\min_{u} \\Big\\{ q\\,x^{2} + r\\,u^{2} + V_{x}(x)\\,\\big(a\\,x + b\\,u\\big) \\Big\\}.\n$$\nBy the structure of the system and the cost, it is natural to seek a quadratic value function $V(x) = P\\,x^{2}$ with an unknown constant $P \\ge 0$. Then $V_{x}(x) = 2\\,P\\,x$, and the HJB equation becomes\n$$\n0 \\;=\\; \\min_{u} \\Big\\{ q\\,x^{2} + r\\,u^{2} + 2\\,P\\,x\\,(a\\,x + b\\,u) \\Big\\}\n\\;=\\; \\min_{u} \\Big\\{ (q + 2\\,a\\,P)\\,x^{2} + r\\,u^{2} + 2\\,b\\,P\\,x\\,u \\Big\\}.\n$$\nFor each fixed $x$, the inner minimization is a convex quadratic in $u$. The minimizing input $u^{\\star}$ satisfies the first-order condition\n$$\n\\frac{\\partial}{\\partial u}\\Big( r\\,u^{2} + 2\\,b\\,P\\,x\\,u \\Big) \\;=\\; 2\\,r\\,u + 2\\,b\\,P\\,x \\;=\\; 0,\n$$\nwhich yields the optimal feedback\n$$\nu^{\\star} \\;=\\; -\\,\\frac{b\\,P}{r}\\,x.\n$$\nThis identifies the optimal static state-feedback gain as\n$$\nK \\;=\\; \\frac{b\\,P}{r}.\n$$\nSubstituting $u^{\\star}$ back into the HJB integrand yields the minimal value of the bracketed expression:\n$$\n(q + 2\\,a\\,P)\\,x^{2} + r\\,\\Big(-\\frac{b\\,P}{r}\\,x\\Big)^{2} + 2\\,b\\,P\\,x\\,\\Big(-\\frac{b\\,P}{r}\\,x\\Big)\n\\;=\\; \\Big(q + 2\\,a\\,P - \\frac{b^{2}\\,P^{2}}{r}\\Big)\\,x^{2}.\n$$\nTherefore the HJB equation reduces to the scalar algebraic Riccati equation\n$$\nq + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2} \\;=\\; 0,\n$$\nor, equivalently,\n$$\n\\frac{b^{2}}{r}\\,P^{2} - 2\\,a\\,P - q \\;=\\; 0.\n$$\nSolving this quadratic for $P$ gives\n$$\nP \\;=\\; \\frac{2\\,a \\pm \\sqrt{4\\,a^{2} + 4\\,\\frac{b^{2}}{r}\\,q}}{2\\,\\frac{b^{2}}{r}}\n\\;=\\; \\frac{a \\pm \\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}}{\\frac{b^{2}}{r}}\n\\;=\\; \\frac{r}{b^{2}}\\Big(a \\pm \\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}\\Big).\n$$\nTo select the stabilizing solution, examine the closed-loop dynamics with $u=-K\\,x$:\n$$\n\\dot{x} \\;=\\; \\big(a - b\\,K\\big)\\,x \\;=\\; \\Big(a - \\frac{b^{2}}{r}\\,P\\Big)\\,x.\n$$\nUsing the expression for $P$,\n$$\na - \\frac{b^{2}}{r}\\,P \\;=\\; a - \\Big(a \\pm \\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}\\Big) \\;=\\; \\mp\\,\\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}.\n$$\nThe stabilizing branch requires $a - \\frac{b^{2}}{r}\\,P < 0$, i.e., the negative root. Therefore we take the plus sign in $P$:\n$$\nP \\;=\\; \\frac{r}{b^{2}}\\Big(a + \\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}\\Big),\n$$\nwhich yields the exact optimal gain\n$$\nK \\;=\\; \\frac{b\\,P}{r} \\;=\\; \\frac{a + \\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}}{b}.\n$$\nThis $K$ produces the closed-loop eigenvalue $a - b\\,K = -\\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q} \\le 0$, strictly negative unless $q = 0$ and $a \\le 0$, ensuring stability in the standard nondegenerate cases.\n\nFor the asymptotic scaling, consider the regime $|a| \\ll \\sqrt{q\\,r}/|b|$. Then\n$$\n\\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}\n\\;=\\;\n|b|\\,\\sqrt{\\frac{q}{r}}\\,\\sqrt{1 + \\frac{a^{2}\\,r}{b^{2}\\,q}}\n\\;=\\;\n|b|\\,\\sqrt{\\frac{q}{r}}\\Big(1 + \\mathcal{O}\\Big(\\frac{a^{2}\\,r}{b^{2}\\,q}\\Big)\\Big),\n$$\nso\n$$\nK \\;=\\; \\frac{a}{b} + \\frac{1}{b}\\,\\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}\n\\;=\\;\n\\frac{a}{b} + \\frac{|b|}{b}\\,\\sqrt{\\frac{q}{r}} + \\mathcal{O}\\Big(\\frac{|a|^{2}}{|b|}\\,\\sqrt{\\frac{r}{q}}\\Big).\n$$\nAt leading order, the $a/b$ term is negligible relative to the term proportional to $\\sqrt{q/r}$, hence\n$$\nK \\sim \\frac{|b|}{b}\\,\\sqrt{\\frac{q}{r}}.\n$$\nIn particular, when $b > 0$, this simplifies to $K \\sim \\sqrt{q/r}$, which establishes the stated scaling behavior.\n\nThus the exact closed-form expression for the optimal gain is\n$$\nK \\;=\\; \\frac{a + \\sqrt{a^{2} + \\frac{b^{2}}{r}\\,q}}{b}.\n$$", "answer": "$$\\boxed{\\frac{a+\\sqrt{a^{2}+\\frac{b^{2}}{r}\\,q}}{b}}$$", "id": "2734387"}, {"introduction": "The existence of a unique, stabilizing LQR controller is not guaranteed for all systems; certain structural properties must hold. This practice explores the subtle but crucial conditions of stabilizability and detectability, which form the theoretical foundation of LQR design, especially when the state-weighting matrix $Q$ is singular. By analyzing when unpenalized system modes can be tolerated [@problem_id:2734399], you will develop a deeper appreciation for the guarantees that make the LQR framework both powerful and reliable.", "problem": "Consider the continuous-time Linear Quadratic Regulator (LQR) problem for the linear time-invariant system $\\dot{x}(t) = A x(t) + B u(t)$ with the cost functional\n$$\nJ(x_0,u) \\;=\\; \\int_{0}^{\\infty} \\big( x(t)^{\\top} Q x(t) + u(t)^{\\top} R u(t) \\big)\\, dt,\n$$\nwhere $Q \\succeq 0$ may be singular and $R \\succ 0$. Let $Q^{1/2}$ denote any symmetric square root of $Q$. Recall the standard structural conditions: $(A,B)$ stabilizable means every eigenvalue of $A$ with nonnegative real part is controllable, and $(C,A)$ detectable means every eigenvalue of $A$ with nonnegative real part is observable by $C$. Assume the usual LQR framework that seeks a static state feedback $u(t) = -K x(t)$ that minimizes $J(x_0,u)$ and yields a closed-loop matrix $A - B K$ with desirable stability properties.\n\nTo reason from first principles, note that when $Q \\succeq 0$ is singular there exists a coordinate transformation $x = T z$ with nonsingular $T$ such that\n$$\nT^{-\\top} Q T^{-1} \\;=\\; \\begin{bmatrix} Q_{p} & 0 \\\\ 0 & 0 \\end{bmatrix}, \\quad Q_{p} \\succeq 0,\n$$\nso that the state $z$ decomposes into a $Q$-penalized subspace and an unpenalized subspace. In this decomposition the running cost has no $z_{n}$-term (the unpenalized component), so growth of $z_{n}$ is invisible to the cost apart from any control effort it induces via $u^{\\top} R u$. Use this decomposition, together with the definitions of stabilizability and detectability, to assess when unpenalized modes can be tolerated and when they create ambiguity in the optimal control problem.\n\nWhich of the following statements are correct? Select all that apply.\n\nA. For continuous-time LQR with $Q \\succeq 0$ and $R \\succ 0$, it is sufficient that $(A,B)$ is stabilizable and $(Q^{1/2},A)$ is detectable to guarantee a unique optimal state-feedback that renders $A - B K$ Hurwitz; full observability of $(Q^{1/2},A)$ is not required.\n\nB. If an eigenvector of $A$ lies entirely in the nullspace of $Q^{1/2}$ and its eigenvalue has nonnegative real part, then growth along that mode is not penalized by $x^{\\top} Q x$; the optimal control can reduce cost by not acting on it, which can yield non-stabilizing or non-unique optimal policies. Requiring detectability of $(Q^{1/2},A)$ excludes this pathology by forcing all such unobservable modes to be asymptotically stable.\n\nC. To avoid ambiguity when $Q$ is singular, $(Q^{1/2},A)$ must be observable; detectability is not sufficient.\n\nD. When $Q$ is singular, all unobservable modes must be controllable to preserve uniqueness; otherwise the LQR problem has no optimal solution even if those modes are asymptotically stable.\n\nE. Singular $Q$ is disallowed in continuous-time LQR; one must impose $Q \\succ 0$ to ensure uniqueness of the optimal state-feedback.", "solution": "The validity of the problem statement must first be assessed.\n\n**Step 1: Extract Givens**\n- System dynamics: A continuous-time, linear time-invariant (LTI) system is given by $\\dot{x}(t) = A x(t) + B u(t)$.\n- Cost functional: $J(x_0,u) = \\int_{0}^{\\infty} \\big( x(t)^{\\top} Q x(t) + u(t)^{\\top} R u(t) \\big)\\, dt$.\n- Weighting matrices: $Q$ is positive semi-definite ($Q \\succeq 0$) and may be singular. $R$ is positive definite ($R \\succ 0$).\n- Notation: $Q^{1/2}$ denotes a symmetric square root of $Q$.\n- Definitions provided:\n    - $(A,B)$ is stabilizable: Every eigenvalue of $A$ with a nonnegative real part is controllable.\n    - $(C,A)$ is detectable: Every eigenvalue of $A$ with a nonnegative real part is observable by $C$.\n- Objective: To find a static state feedback $u(t) = -K x(t)$ that minimizes $J$ and renders the closed-loop matrix $A - B K$ Hurwitz (asymptotically stable).\n\n**Step 2: Validate Using Extracted Givens**\nThe problem presents a standard formulation from optimal control theory, specifically the infinite-horizon Linear Quadratic Regulator (LQR) problem. All definitions, such as stabilizability and detectability, are stated correctly and are standard in the field. The question posed relates to the fundamental conditions required for the existence and uniqueness of a stabilizing solution to the LQR problem, particularly in the case where the state weighting matrix $Q$ is singular. This is a classic and important aspect of LQR theory. The problem is scientifically grounded, well-posed, and uses precise, objective language. There are no contradictions, missing information, or pseudoscientific elements.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. A rigorous solution may be derived.\n\nThe optimal control for the LQR problem is given by the state feedback law $u(t) = -K x(t)$, where the gain matrix is $K = R^{-1}B^{\\top}P$. The matrix $P$ is the minimal positive semi-definite solution to the continuous-time Algebraic Riccati Equation (ARE):\n$$\nA^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0\n$$\nFor this solution to be meaningful and to result in a stable closed-loop system $\\dot{x}(t) = (A-BK)x(t)$, certain conditions on the system matrices $(A,B,Q,R)$ must hold. The key theorem in LQR theory states that a unique, positive semi-definite solution $P$ to the ARE exists, and the resulting closed-loop system is asymptotically stable, if and only if two conditions are met:\n1.  The pair $(A,B)$ is stabilizable.\n2.  The pair $(Q^{1/2}, A)$ is detectable.\n\nLet us analyze these conditions from first principles.\n\nThe stabilizability of $(A,B)$ is required to ensure that any unstable dynamics of the system can be influenced and stabilized by the control input $u(t)$. If an unstable mode (an eigenvector of $A$ corresponding to an eigenvalue $\\lambda$ with $\\Re(\\lambda) \\ge 0$) were uncontrollable, no feedback control could alter its trajectory. The state would grow without bound, causing the integral cost $J$ to become infinite. Therefore, all unstable modes must be controllable, which is the definition of stabilizability.\n\nThe detectability of $(Q^{1/2},A)$ is required to handle the case where $Q$ is singular. The term $x^{\\top}Qx$ in the cost function can be written as $\\|Q^{1/2}x\\|^2$. If a state $x$ lies in the nullspace of $Q^{1/2}$, then $Q^{1/2}x = 0$, and this state is \"invisible\" to the state penalty term. Such a state corresponds to an unobservable mode with respect to the \"output\" matrix $Q^{1/2}$.\n\nConsider an eigenvector $v$ of $A$ such that $Av = \\lambda v$ and $Q^{1/2}v = 0$. This means the mode is unobservable by $Q^{1/2}$. If we choose the control input $u(t) = 0$, the state evolves as $x(t) = c_0 e^{\\lambda t} v$ for an initial condition $x(0) = c_0v$. The cost integrand becomes:\n$$\nx(t)^{\\top}Qx(t) + u(t)^{\\top}Ru(t) = (c_0 e^{\\lambda t} v)^{\\top}Q(c_0 e^{\\lambda t} v) + 0 = |c_0|^2 e^{2\\Re(\\lambda)t} v^{\\top}Qv\n$$\nSince $Q^{1/2}v=0$, it follows that $Qv = (Q^{1/2})^2 v = 0$, so $v^{\\top}Qv=0$. The cost for this trajectory with $u(t)=0$ is exactly zero.\nIf this unobservable mode is unstable or marginally stable (i.e., $\\Re(\\lambda) \\ge 0$), the state $x(t)$ does not converge to zero. However, the cost is minimized (to zero) by applying no control. Any control effort to stabilize this mode would incur a positive cost through the $u^{\\top}Ru$ term. This leads to a contradiction with the goal of finding a *stabilizing* optimal controller. The problem becomes ill-defined.\n\nTo prevent this, we must ensure that any mode that is unobservable through $Q^{1/2}$ is inherently asymptotically stable. This is precisely the definition of detectability of the pair $(Q^{1/2},A)$: it requires that any eigenvector $v$ of $A$ that is in the nullspace of $Q^{1/2}$ must correspond to an eigenvalue $\\lambda$ with $\\Re(\\lambda) < 0$.\n\nWith this understanding, we evaluate each option.\n\n**A. For continuous-time LQR with $Q \\succeq 0$ and $R \\succ 0$, it is sufficient that $(A,B)$ is stabilizable and $(Q^{1/2},A)$ is detectable to guarantee a unique optimal state-feedback that renders $A - B K$ Hurwitz; full observability of $(Q^{1/2},A)$ is not required.**\nThis statement is a precise formulation of the standard LQR theorem. As derived above, stabilizability and detectability are the sufficient conditions for the existence of a unique, stabilizing optimal control. Observability of $(Q^{1/2},A)$ would mean that the nullspace of $Q^{1/2}$ contains no eigenvectors of $A$, which is a stricter requirement than detectability. Detectability allows for unobservable modes, as long as they are stable. Since stable unobservable modes decay to zero on their own and do not compromise the LQR problem, observability is not a necessary condition.\nVerdict: **Correct**.\n\n**B. If an eigenvector of $A$ lies entirely in the nullspace of $Q^{1/2}$ and its eigenvalue has nonnegative real part, then growth along that mode is not penalized by $x^{\\top} Q x$; the optimal control can reduce cost by not acting on it, which can yield non-stabilizing or non-unique optimal policies. Requiring detectability of $(Q^{1/2},A)$ excludes this pathology by forcing all such unobservable modes to be asymptotically stable.**\nThis statement provides the correct physical and mathematical reasoning behind the detectability condition. An eigenvector $v$ in the nullspace of $Q^{1/2}$ with an eigenvalue $\\lambda$ where $\\Re(\\lambda) \\ge 0$ represents an unstable or marginally stable mode that is not penalized by the cost functional. The optimal controller, seeking to minimize cost, would apply no control effort to this mode, resulting in an unstable or non-convergent trajectory. This is the \"pathology\". The statement correctly identifies that the condition of detectability for $(Q^{1/2},A)$ directly prevents this situation by definition, as it mandates that any such unobservable mode must be asymptotically stable ($\\Re(\\lambda) < 0$).\nVerdict: **Correct**.\n\n**C. To avoid ambiguity when $Q$ is singular, $(Q^{1/2},A)$ must be observable; detectability is not sufficient.**\nThis statement is incorrect. Observability is a sufficient condition, but it is not necessary. Detectability is the minimally required condition. If a mode is unobservable but stable, the controller can safely ignore it, and the state corresponding to this mode will decay to zero naturally. The LQR problem remains well-posed and has a unique stabilizing solution for the remaining subsystem. Therefore, detectability is sufficient.\nVerdict: **Incorrect**.\n\n**D. When $Q$ is singular, all unobservable modes must be controllable to preserve uniqueness; otherwise the LQR problem has no optimal solution even if those modes are asymptotically stable.**\nThis statement incorrectly links observability and controllability. The fundamental LQR conditions are about (i) the controllability of unstable modes (stabilizability) and (ii) the stability of unobservable modes (detectability). There is no requirement that unobservable modes must be controllable. If a mode is stable and unobservable, its controllability status is irrelevant to the existence of a stabilizing LQR solution. The controller does not need to act on it, so whether it *can* act on it is of no consequence.\nVerdict: **Incorrect**.\n\n**E. Singular $Q$ is disallowed in continuous-time LQR; one must impose $Q \\succ 0$ to ensure uniqueness of the optimal state-feedback.**\nThis statement is false. The theory of LQR is well-developed for the case of $Q \\succeq 0$. This case is crucial for many practical applications, such as output regulation, where only certain combinations of states (the output) are penalized. The condition $Q \\succ 0$ is a strong, simplifying assumption that guarantees observability of $(Q^{1/2}, A)$, but it is not necessary. The weaker conditions detailed above are sufficient.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{AB}$$", "id": "2734399"}, {"introduction": "A controller designed in continuous time is nearly always implemented on a digital computer, which operates in discrete time steps. This exercise [@problem_id:2734403] bridges this critical gap between theory and practice by examining the stability of a continuous-time LQR controller implemented with a zero-order hold. You will derive the maximum sampling period that preserves stability, revealing the fundamental trade-offs between computational constraints and control performance in any sampled-data system.", "problem": "Consider the scalar continuous-time linear time-invariant plant given by $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ with $a = 1$ and $b = 1$. A continuous-time Linear Quadratic Regulator (LQR) is designed for the infinite-horizon performance index $J = \\int_{0}^{\\infty} \\left(q\\,x(t)^{2} + r\\,u(t)^{2}\\right)\\,dt$ with $q = 1$ and $r = 1$, yielding a continuous-time state-feedback law $u(t) = -K\\,x(t)$ with fixed gain $K > 0$. The controller is then implemented in sampled-data form using Zero-Order Hold (ZOH): the input is held constant between sampling instants as $u(t) \\equiv -K\\,x(kh)$ for $t \\in [kh,(k+1)h)$, where $h > 0$ is the sampling period.\n\nStarting from fundamental definitions (state-transition matrix and the convolution integral), derive the exact discrete-time closed-loop scalar update $x_{k+1} = F(h)\\,x_{k}$ as a function of $a$, $b$, $K$, and $h$. Using the Schur-stability requirement (all eigenvalues strictly inside the unit disk), determine the largest sampling period $h_{\\max}$ such that the sampled-data closed loop remains Schur stable. Then, for the given numerical values $a = 1$, $b = 1$, $q = 1$, and $r = 1$, compute the continuous-time LQR gain $K$ and evaluate the resulting $h_{\\max}$.\n\nExpress the final sampling period in seconds. Give your final answer as an exact expression; no rounding is required.", "solution": "We begin with the scalar plant $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ and the continuous-time Linear Quadratic Regulator (LQR) design for the infinite-horizon cost $J = \\int_{0}^{\\infty} \\left(q\\,x(t)^{2} + r\\,u(t)^{2}\\right)\\,dt$. For a scalar system, the Algebraic Riccati Equation (ARE) for the optimal costate $p > 0$ is\n$$\n2 a p - \\frac{b^{2}}{r}\\,p^{2} + q = 0,\n$$\na well-tested and fundamental result in optimal control theory. The optimal feedback gain is then $K = r^{-1} b\\,p$.\n\nSolving the scalar ARE for $p$ yields\n$$\n\\frac{b^{2}}{r} p^{2} - 2 a p - q = 0\n\\quad\\Longrightarrow\\quad\np = \\frac{2 a + \\sqrt{4 a^{2} + 4 \\frac{b^{2}}{r} q}}{2 \\frac{b^{2}}{r}}\n= \\frac{r\\left(a + \\sqrt{a^{2} + \\frac{b^{2}}{r} q}\\right)}{b^{2}},\n$$\nwhere we choose the positive root to ensure $p > 0$. Therefore,\n$$\nK = \\frac{b}{r}\\,p\n= \\frac{b}{r}\\,\\frac{r\\left(a + \\sqrt{a^{2} + \\frac{b^{2}}{r} q}\\right)}{b^{2}}\n= \\frac{a + \\sqrt{a^{2} + \\frac{b^{2}}{r} q}}{b}.\n$$\n\nNext, we derive the exact sampled-data closed loop under Zero-Order Hold (ZOH). Over one sampling interval $[kh,(k+1)h)$ with constant input $u(t) \\equiv u(kh)$, the state evolution is given by the state-transition formula\n$$\nx((k+1)h) = \\exp(A h)\\,x(kh) + \\int_{0}^{h} \\exp(A \\tau)\\,B\\,u(kh)\\,d\\tau,\n$$\nwhere in the scalar case $A = a$ and $B = b$, and $\\exp(A h) = \\exp(a h)$. With the sampled implementation of the continuous-time LQR gain, we apply $u(kh) = -K\\,x(kh)$. Therefore,\n$$\nx_{k+1} = \\exp(a h)\\,x_{k} - \\left(\\int_{0}^{h} \\exp(a \\tau)\\,b\\,d\\tau\\right) K\\,x_{k},\n$$\nso the exact discrete-time closed-loop scalar multiplier is\n$$\nF(h) \\equiv \\exp(a h) - \\Gamma(h)\\,K,\n\\qquad\n\\Gamma(h) \\equiv \\int_{0}^{h} \\exp(a \\tau)\\,b\\,d\\tau.\n$$\nEvaluating the integral for $a \\neq 0$,\n$$\n\\Gamma(h) = b \\int_{0}^{h} \\exp(a \\tau)\\,d\\tau\n= b\\,\\frac{\\exp(a h) - 1}{a}.\n$$\nHence,\n$$\nF(h) = \\exp(a h) - \\frac{b K}{a}\\,\\left(\\exp(a h) - 1\\right)\n= \\left(1 - \\frac{b K}{a}\\right)\\exp(a h) + \\frac{b K}{a}.\n$$\n\nSchur stability for the scalar discrete-time system requires $|F(h)| < 1$. Because the continuous-time LQR design guarantees $a - b K < 0$ (hence $b K > a$ for $a > 0$, $b > 0$), we have $\\frac{b K}{a} > 1$, implying $1 - \\frac{b K}{a} < 0$. Since $\\exp(a h)$ is strictly increasing in $h$ for $a > 0$, $F(h)$ is strictly decreasing in $h$, with $F(0) = 1$ and $F(h) \\to -\\infty$ as $h \\to \\infty$. Therefore, the maximal sampling period $h_{\\max}$ for which $|F(h)| < 1$ holds is attained when $F(h_{\\max}) = -1$.\n\nSet $F(h) = -1$ and solve for $h$. Let $z \\equiv \\exp(a h) > 1$ for $h > 0$ and define $r_{ratio} \\equiv \\frac{b K}{a} > 1$. Then\n$$\nF(h) = (1 - r_{ratio}) z + r_{ratio} = -1\n\\quad\\Longrightarrow\\quad\n(1 - r_{ratio}) z = -1 - r_{ratio}\n\\quad\\Longrightarrow\\quad\nz = \\frac{-1 - r_{ratio}}{1 - r_{ratio}} = \\frac{1 + r_{ratio}}{r_{ratio} - 1}.\n$$\nThus,\n$$\nh_{\\max} = \\frac{1}{a}\\,\\ln\\!\\left(\\frac{1 + r_{ratio}}{r_{ratio} - 1}\\right),\n\\qquad r_{ratio} \\equiv \\frac{b K}{a}.\n$$\n\nNow specialize to the given numerical parameters $a = 1$, $b = 1$, $q = 1$, $r = 1$. The continuous-time LQR gain is\n$$\nK = \\frac{a + \\sqrt{a^{2} + \\frac{b^{2}}{r} q}}{b}\n= \\frac{1 + \\sqrt{1 + 1}}{1}\n= 1 + \\sqrt{2}.\n$$\nHence $r_{ratio} = \\frac{b K}{a} = 1 + \\sqrt{2}$. Substituting into the expression for $h_{\\max}$,\n$$\nh_{\\max}\n= \\frac{1}{1} \\ln\\!\\left(\\frac{1 + (1 + \\sqrt{2})}{(1 + \\sqrt{2}) - 1}\\right)\n= \\ln\\!\\left(\\frac{2 + \\sqrt{2}}{\\sqrt{2}}\\right)\n= \\ln\\!\\left(1 + \\sqrt{2}\\right).\n$$\nThis is an exact expression in seconds, as requested. The use of $r$ in the solution was ambiguous, as it is also a cost matrix parameter. It has been renamed to $r_{ratio}$ for clarity.", "answer": "$$\\boxed{\\ln\\!\\left(1+\\sqrt{2}\\right)}$$", "id": "2734403"}]}