{"hands_on_practices": [{"introduction": "The connection between the Hamilton-Jacobi-Bellman (HJB) equation and the Algebraic Riccati Equation (ARE) is a cornerstone of modern optimal control. This first exercise provides a hands-on derivation in the simplest possible setting: a scalar, deterministic Linear-Quadratic Regulator (LQR) problem. By working through this foundational example [@problem_id:2699184], you will see how postulating a quadratic form for the value function transforms the HJB partial differential equation into a solvable algebraic equation and learn how to select the unique solution that guarantees system stability.", "problem": "Consider the scalar linear time-invariant system governed by $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ with the infinite-horizon quadratic performance index $J = \\int_{0}^{\\infty} \\big(q\\,x(t)^{2} + r\\,u(t)^{2}\\big)\\,dt$. Start from Bellman's principle of optimality leading to the stationary Hamilton–Jacobi–Bellman (HJB) equation for the infinite-horizon case, and use a quadratic value function ansatz $V(x) = P\\,x^{2}$ with $P$ constant. By minimizing the HJB Hamiltonian with respect to $u$, derive the scalar continuous-time algebraic Riccati equation (ARE) satisfied by $P$. Then, for the specific data $a=1$, $b=1$, $q=2$, and $r=1$, solve the resulting scalar equation explicitly and select the stabilizing solution that renders the closed-loop system $\\dot{x}(t) = \\big(a - b\\,r^{-1}b\\,P\\big)\\,x(t)$ asymptotically stable. Express your final answer as a single closed-form analytic expression for the stabilizing $P$. No rounding is required.", "solution": "The starting point is the infinite-horizon stationary Hamilton–Jacobi–Bellman (HJB) equation for the optimal value function $V(x)$,\n$$\n0 \\;=\\; \\min_{u}\\,\\Big\\{\\, q\\,x^{2} + r\\,u^{2} + V_{x}(x)\\,\\big(a\\,x + b\\,u\\big) \\Big\\},\n$$\nwhere $V_{x}(x)$ denotes the derivative of $V$ with respect to $x$. We postulate a quadratic value function ansatz $V(x) = P\\,x^{2}$ with constant $P$. Then $V_{x}(x) = 2\\,P\\,x$, and the HJB Hamiltonian becomes\n$$\n\\mathcal{H}(x,u) \\;=\\; q\\,x^{2} + r\\,u^{2} + 2\\,P\\,x\\,(a\\,x + b\\,u).\n$$\nTo obtain the optimal input, minimize $\\mathcal{H}(x,u)$ with respect to $u$. The first-order optimality condition is\n$$\n\\frac{\\partial \\mathcal{H}}{\\partial u} \\;=\\; 2\\,r\\,u + 2\\,P\\,x\\,b \\;=\\; 0,\n$$\nwhich yields the optimal control law\n$$\nu^{\\star}(x) \\;=\\; -\\,\\frac{b\\,P}{r}\\,x.\n$$\nSubstitute $u^{\\star}(x)$ back into the Hamiltonian and enforce the HJB equation. First compute each term:\n- The state penalty is $q\\,x^{2}$.\n- The input penalty is $r\\,(u^{\\star})^{2} = r\\,\\Big(\\frac{b^{2}P^{2}}{r^{2}}\\,x^{2}\\Big) = \\frac{b^{2}}{r}\\,P^{2}\\,x^{2}$.\n- The coupling term is $V_{x}\\,(a\\,x + b\\,u^{\\star}) = 2\\,P\\,x\\,\\Big(a\\,x + b\\big(-\\frac{b\\,P}{r}\\,x\\big)\\Big) = \\big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\big)\\,x^{2}$.\nTherefore,\n$$\n0 \\;=\\; q\\,x^{2} + \\frac{b^{2}}{r}\\,P^{2}\\,x^{2} + \\Big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}\n\\;=\\; \\Big(q + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}.\n$$\nBecause this must hold for all $x$, the scalar continuous-time algebraic Riccati equation (ARE) for $P$ is\n$$\nq + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2} \\;=\\; 0.\n$$\n\nFor the given data $a=1$, $b=1$, $q=2$, and $r=1$, the equation becomes\n$$\n2 + 2\\,P - P^{2} \\;=\\; 0,\n$$\nor equivalently\n$$\nP^{2} - 2\\,P - 2 \\;=\\; 0.\n$$\nSolving this quadratic yields\n$$\nP \\;=\\; \\frac{2 \\pm \\sqrt{4 + 8}}{2} \\;=\\; 1 \\pm \\sqrt{3}.\n$$\n\nTo select the stabilizing solution, examine the closed-loop scalar dynamics under the optimal controller. The optimal feedback is $u^{\\star}(x) = -\\frac{b\\,P}{r}\\,x$, so the closed-loop system is\n$$\n\\dot{x}(t) \\;=\\; \\Big(a - \\frac{b^{2}}{r}\\,P\\Big)\\,x(t) \\;=\\; \\big(1 - P\\big)\\,x(t).\n$$\nAsymptotic stability requires $1 - P  0$, i.e., $P > 1$. Among the two roots $1 \\pm \\sqrt{3}$, only $1 + \\sqrt{3}$ satisfies $P > 1$ and is nonnegative. Hence the stabilizing solution is\n$$\nP^{\\star} \\;=\\; 1 + \\sqrt{3}.\n$$", "answer": "$$\\boxed{1+\\sqrt{3}}$$", "id": "2699184"}, {"introduction": "Real-world systems are rarely free of noise. This practice extends the deterministic LQR framework to a stochastic setting, a fundamental step towards more realistic modeling. You will tackle a controlled Ornstein-Uhlenbeck process, learning how to incorporate the diffusion term into the HJB equation via the generator of the process. Solving this problem will demonstrate how the optimal feedback control adapts to stabilize the system in the presence of random disturbances [@problem_id:3001633].", "problem": "Consider the infinite-horizon discounted stochastic control problem for the one-dimensional controlled Ornstein–Uhlenbeck (OU) diffusion. The state process $\\{X_{t}\\}_{t \\ge 0}$ evolves according to the controlled stochastic differential equation\n$$\n\\mathrm{d}X_{t} = \\big(-\\theta X_{t} + \\beta u_{t}\\big)\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad X_{0}=x,\n$$\nwhere $W_{t}$ is a standard Brownian motion, and $\\theta0$, $\\beta\\neq 0$, $\\sigma0$ are given constants. The control process $\\{u_{t}\\}_{t \\ge 0}$ is progressively measurable with respect to the filtration of $W_{t}$ and takes values in $\\mathbb{R}$. The objective is to minimize the discounted cost functional\n$$\nJ^{u}(x) \\equiv \\mathbb{E}\\!\\left[\\int_{0}^{\\infty} \\exp(-\\rho t)\\big(q X_{t}^{2} + r u_{t}^{2}\\big)\\,\\mathrm{d}t\\right],\n$$\nover all admissible controls, where $\\rho0$, $q0$, and $r0$ are given constants. Let $V(x)\\equiv \\inf_{u} J^{u}(x)$ denote the value function.\n\nStarting from the dynamic programming principle and the definitions of the diffusion generator and the discounted expected cost, derive the Hamilton–Jacobi–Bellman (HJB) equation for $V(x)$, solve it explicitly in closed form, and obtain the optimal stationary Markov feedback $u^{\\ast}(x)$. Explain how the optimal feedback modifies the linear drift and why this yields stabilization of the closed-loop OU dynamics. Your final answer must be given as a single analytic expression containing both the closed-form value function $V(x)$ and the optimal feedback $u^{\\ast}(x)$, written as a $1\\times 2$ row matrix with the first entry equal to $V(x)$ and the second entry equal to $u^{\\ast}(x)$. No numerical evaluation is required, and no rounding is to be performed.", "solution": "We begin with the controlled diffusion\n$$\n\\mathrm{d}X_{t} = b(X_{t},u_{t})\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad b(x,u) \\equiv -\\theta x + \\beta u,\n$$\nand the infinite-horizon discounted cost\n$$\nJ^{u}(x) = \\mathbb{E}\\!\\left[\\int_{0}^{\\infty}\\exp(-\\rho t)\\,\\ell(X_{t},u_{t})\\,\\mathrm{d}t\\right], \\quad \\ell(x,u) \\equiv q x^{2} + r u^{2},\n$$\nwith $\\rho0$, $\\theta0$, $q0$, $r0$, $\\sigma0$, and $\\beta\\neq 0$. The dynamic programming principle asserts that if $V$ is the value function, then under sufficient regularity $V$ satisfies the Hamilton–Jacobi–Bellman (HJB) equation. For a twice continuously differentiable $V$ and a discount factor $\\rho0$, the HJB for this diffusion control problem is\n$$\n\\rho V(x) = \\inf_{u\\in\\mathbb{R}}\\Big\\{\\ell(x,u) + \\mathcal{L}^{u}V(x)\\Big\\},\n$$\nwhere $\\mathcal{L}^{u}$ is the controlled generator acting on smooth test functions $f$ by\n$$\n\\mathcal{L}^{u} f(x) \\equiv b(x,u) f'(x) + \\tfrac{1}{2}\\sigma^{2} f''(x) = \\big(-\\theta x + \\beta u\\big) f'(x) + \\tfrac{1}{2}\\sigma^{2} f''(x).\n$$\nThus the HJB takes the explicit form\n$$\n\\rho V(x) = \\inf_{u\\in\\mathbb{R}}\\left\\{q x^{2} + r u^{2} + \\big(-\\theta x + \\beta u\\big)V'(x) + \\tfrac{1}{2}\\sigma^{2} V''(x)\\right\\}.\n$$\n\nWe now solve this equation. The structure is linear-quadratic in $(x,u)$, and it is natural to look for a solution of the form\n$$\nV(x) = P x^{2} + C,\n$$\nwith constants $P$ and $C$ to be determined. We compute the derivatives $V'(x) = 2 P x$ and $V''(x) = 2 P$. Substituting into the HJB gives\n$$\n\\rho \\big(P x^{2} + C\\big) = \\inf_{u\\in\\mathbb{R}}\\left\\{q x^{2} + r u^{2} + \\big(-\\theta x + \\beta u\\big)\\,2 P x + \\tfrac{1}{2}\\sigma^{2}\\cdot 2 P\\right\\}.\n$$\nThe minimization over $u$ involves the quadratic function\n$$\n\\Phi(u;x) \\equiv r u^{2} + 2 P \\beta x\\, u + \\big(q x^{2} - 2\\theta P x^{2} + \\sigma^{2} P\\big).\n$$\nFor each fixed $x$, the minimizer $u^{\\ast}(x)$ satisfies the first-order condition\n$$\n\\frac{\\partial \\Phi}{\\partial u}(u;x) = 2 r u + 2 P \\beta x = 0,\n$$\nwhich yields the stationary feedback\n$$\nu^{\\ast}(x) = -\\frac{\\beta P}{r}\\,x.\n$$\nThe second derivative $\\frac{\\partial^{2}\\Phi}{\\partial u^{2}} = 2 r0$ confirms that this is indeed the global minimizer. Substituting $u^{\\ast}$ back, we evaluate at the minimum:\n\n$$\n\\begin{aligned}\nr \\big(u^{\\ast}(x)\\big)^{2} = r \\left(\\frac{\\beta^{2} P^{2}}{r^{2}} x^{2}\\right) = \\frac{\\beta^{2} P^{2}}{r} x^{2},\\\\\n\\big(-\\theta x + \\beta u^{\\ast}(x)\\big) V'(x) = \\big(-\\theta x - \\beta \\tfrac{\\beta P}{r} x\\big)\\,2 P x = \\big(-2\\theta P - \\tfrac{2\\beta^{2} P^{2}}{r}\\big) x^{2},\\\\\n\\tfrac{1}{2}\\sigma^{2} V''(x) = \\sigma^{2} P.\n\\end{aligned}\n$$\n\nTherefore the HJB becomes, after minimization,\n$$\n\\rho P x^{2} + \\rho C = \\left[q - 2\\theta P - \\frac{\\beta^{2}}{r} P^{2}\\right] x^{2} + \\sigma^{2} P.\n$$\nMatching the coefficients of $x^{2}$ and the constants gives the coupled algebraic equations\n\n$$\n\\begin{cases}\n\\rho P = q - 2\\theta P - \\dfrac{\\beta^{2}}{r} P^{2},\\\\[6pt]\n\\rho C = \\sigma^{2} P.\n\\end{cases}\n$$\n\nThe first is an algebraic Riccati equation for $P$:\n$$\n\\frac{\\beta^{2}}{r} P^{2} + (\\rho + 2\\theta) P - q = 0.\n$$\nIts two roots are\n$$\nP_{\\pm} = \\frac{ -(\\rho + 2\\theta) \\pm \\sqrt{(\\rho + 2\\theta)^{2} + \\dfrac{4\\beta^{2}}{r} q} }{ 2 \\dfrac{\\beta^{2}}{r} } = \\frac{r}{2\\beta^{2}}\\left( -(\\rho + 2\\theta) \\pm \\sqrt{(\\rho + 2\\theta)^{2} + \\frac{4\\beta^{2}}{r} q} \\right).\n$$\nBecause $q0$, $r0$, and $\\beta\\neq 0$, the discriminant is strictly greater than $(\\rho + 2\\theta)^{2}$, so the square root exceeds $\\rho + 2\\theta$. Hence $P_{-}0$ and\n$$\nP_{+} = \\frac{r}{2\\beta^{2}}\\left( -(\\rho + 2\\theta) + \\sqrt{(\\rho + 2\\theta)^{2} + \\frac{4\\beta^{2}}{r} q} \\right)  0.\n$$\nConvexity of $V$ and finiteness of the value function select the positive stabilizing solution, so we take $P=P_{+}$. The constant $C$ is then\n$$\nC = \\frac{\\sigma^{2}}{\\rho}\\,P_{+}.\n$$\n\nCollecting, the value function and optimal feedback are\n\n$$\n\\begin{aligned}\nV(x) = P_{+} x^{2} + \\frac{\\sigma^{2}}{\\rho}\\,P_{+},\\\\\nu^{\\ast}(x) = -\\frac{\\beta P_{+}}{r}\\,x = \\frac{(\\rho + 2\\theta) - \\sqrt{(\\rho + 2\\theta)^{2} + \\dfrac{4\\beta^{2}}{r} q}}{2\\beta}\\,x.\n\\end{aligned}\n$$\n\nThe equality for $u^{\\ast}(x)$ follows by substituting the expression for $P_{+}$. To interpret stabilization, observe that under $u^{\\ast}$ the closed-loop drift becomes\n$$\n-\\theta x + \\beta u^{\\ast}(x) = -\\left(\\theta + \\frac{\\beta^{2}}{r} P_{+}\\right) x,\n$$\nwith $\\theta + \\dfrac{\\beta^{2}}{r} P_{+}  \\theta  0$. Thus the linear drift coefficient in the closed loop is strictly more negative than in open loop, yielding an Ornstein–Uhlenbeck process with stronger mean reversion to the origin. This negative linear feedback is precisely the stabilizing action that minimizes the long-run discounted quadratic cost in the presence of diffusion noise.", "answer": "$$\\boxed{\\begin{pmatrix}\n\\frac{r}{2\\beta^{2}}\\!\\left(\\! -(\\rho+2\\theta)+\\sqrt{(\\rho+2\\theta)^{2}+\\frac{4\\beta^{2}}{r}q}\\,\\right) x^{2}+\\frac{\\sigma^{2}}{\\rho}\\cdot \\frac{r}{2\\beta^{2}}\\!\\left(\\! -(\\rho+2\\theta)+\\sqrt{(\\rho+2\\theta)^{2}+\\frac{4\\beta^{2}}{r}q}\\,\\right)\n\n\\frac{(\\rho+2\\theta)-\\sqrt{(\\rho+2\\theta)^{2}+\\frac{4\\beta^{2}}{r}q}}{2\\beta}\\,x\n\\end{pmatrix}}$$", "id": "3001633"}, {"introduction": "While the LQR problems demonstrate the power of assuming smooth, quadratic value functions, this assumption is not always valid. This exercise explores a classic minimum-time problem where the true value function is not differentiable everywhere, challenging the notion of a classical solution to the HJB equation. By analyzing a candidate function and showing that it fails to satisfy the HJB equation pointwise, you will gain a concrete appreciation for why the more general framework of viscosity solutions is essential in optimal control theory [@problem_id:2752646].", "problem": "Consider the deterministic control system on the domain $\\Omega := (-1,1)$ given by the dynamics $\\dot{x}(t) = u(t)$ with control constraint $u(t) \\in [-1,1]$ for all $t \\geq 0$. Let the exit time be $\\tau := \\inf\\{ t \\geq 0 : |x(t)| = 1 \\}$ and the cost functional be $J(x_{0};u(\\cdot)) := \\int_{0}^{\\tau} 1 \\, dt$, where $x(0)=x_{0} \\in \\Omega$. Define the value function $V(x_{0})$ as the infimum of $J(x_{0};u(\\cdot))$ over all measurable controls $u(\\cdot)$ with values in $[-1,1]$. \n\nStart from the dynamic programming principle and derive the pointwise consistency condition for any sufficiently smooth candidate function $W:\\Omega \\to \\mathbb{R}$ that agrees with the boundary condition $W(x)=0$ for $|x|=1$, showing how, in the interior of $\\Omega$, the Hamilton-Jacobi-Bellman (HJB) equation constrains $W$ through an appropriate residual. Then, take the specific smooth candidate $W(x) := 1 - x^{2}$, which satisfies the boundary condition $W(\\pm 1)=0$. Using your derived HJB consistency condition, evaluate the pointwise residual at $x=0$.\n\nYour final answer must be a single real number corresponding to the value of this residual at $x=0$. No rounding is required.", "solution": "The problem asks for the derivation of the Hamilton-Jacobi-Bellman (HJB) consistency condition, starting from the dynamic programming principle (DPP), and then its application to a specific candidate function.\n\nThe system dynamics are given by $\\dot{x}(t) = u(t)$, with state $x(t) \\in \\Omega := (-1,1)$ and control $u(t) \\in [-1,1]$. The cost functional represents the time to exit the domain $\\Omega$:\n$$J(x_{0};u(\\cdot)) := \\int_{0}^{\\tau} 1 \\, dt$$\nwhere $\\tau := \\inf\\{t \\geq 0 : |x(t)| = 1\\}$. The value function $V(x)$ is the infimum of this cost over all admissible controls: $V(x) = \\inf_{u(\\cdot)} J(x; u(\\cdot))$. The running cost is $L(x,u) = 1$. The boundary condition is $V(x) = 0$ for $x \\in \\partial\\Omega$, i.e., for $|x|=1$.\n\nThe dynamic programming principle states that for any small time interval $h  0$, the value function satisfies:\n$$V(x) = \\inf_{u(\\cdot):[0,h]\\to[-1,1]} \\left\\{ \\int_0^h L(x(t), u(t)) \\, dt + V(x(h)) \\right\\}$$\nFor this specific problem, this becomes:\n$$V(x) = \\inf_{u(\\cdot):[0,h]\\to[-1,1]} \\left\\{ h + V(x(h)) \\right\\}$$\nAssuming the control $u(t)$ is a constant value $u \\in [-1,1]$ over the interval $[0, h]$, the state evolves as $x(h) = x(0) + \\int_0^h u \\, ds = x + hu$.\nIf the value function $V$ is assumed to be continuously differentiable ($C^1$), we can expand $V(x(h))$ in a Taylor series around $x$:\n$$V(x(h)) = V(x+hu) = V(x) + V'(x)(hu) + O(h^2)$$\nwhere $V'(x)$ denotes the derivative of $V$ with respect to $x$. Substituting this into the DPP equation:\n$$V(x) = \\inf_{u \\in [-1,1]} \\left\\{ h + V(x) + hV'(x)u + O(h^2) \\right\\}$$\nWe subtract $V(x)$ from both sides and divide by $h  0$:\n$$0 = \\inf_{u \\in [-1,1]} \\left\\{ 1 + V'(x)u + O(h) \\right\\}$$\nTaking the limit as $h \\to 0$, the $O(h)$ term vanishes, yielding the stationary Hamilton-Jacobi-Bellman equation that the value function $V(x)$ must satisfy in the interior of the domain $\\Omega$:\n$$0 = \\inf_{u \\in [-1,1]} \\left\\{ 1 + V'(x)u \\right\\}$$\nThis equation provides the pointwise consistency condition. For any sufficiently smooth candidate function $W(x)$, we define the HJB residual, $R_W(x)$, as the value of the HJB expression:\n$$R_W(x) := \\inf_{u \\in [-1,1]} \\left\\{ 1 + W'(x)u \\right\\}$$\nFor a candidate function to be the true value function, its residual must be zero for all $x \\in \\Omega$ and it must satisfy the boundary conditions.\n\nWe are given the candidate function $W(x) := 1 - x^2$.\nFirst, we verify the boundary condition: $W(\\pm 1) = 1 - (\\pm 1)^2 = 1 - 1 = 0$. The condition is satisfied.\nNext, we compute the derivative of $W(x)$:\n$$W'(x) = \\frac{d}{dx}(1 - x^2) = -2x$$\nWe now substitute this derivative into the expression for the residual:\n$$R_W(x) = \\inf_{u \\in [-1,1]} \\left\\{ 1 + (-2x)u \\right\\} = \\inf_{u \\in [-1,1]} \\left\\{ 1 - 2xu \\right\\}$$\nSince we are seeking the infimum, we can write:\n$$ \\inf_{u \\in [-1,1]} \\{1 - 2xu\\} = 1 - \\sup_{u \\in [-1,1]} \\{2xu\\} $$\nThe supremum of $2xu$ over $u \\in [-1,1]$ is achieved when $u$ has the same sign as $x$, yielding a value of $2|x|$. Therefore, the residual is:\n$$R_W(x) = 1 - 2|x|$$\nThe problem asks for the value of this pointwise residual at the point $x=0$. We evaluate the residual function at $x=0$:\n$$R_W(0) = 1 - 2|0| = 1$$\nAlternatively, one can directly evaluate the infimum expression at $x=0$:\n$$R_W(0) = \\inf_{u \\in [-1,1]} \\{ 1 - 2(0)u \\} = \\inf_{u \\in [-1,1]} \\{ 1 \\} = 1$$\nThe residual at $x=0$ is $1$.", "answer": "$$\\boxed{1}$$", "id": "2752646"}]}