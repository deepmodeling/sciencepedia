{"hands_on_practices": [{"introduction": "The power of Lyapunov's direct method lies in its ability to determine the stability of an equilibrium without explicitly solving the underlying differential equation. This practice serves as a foundational exercise in applying the method to a simple, yet non-trivial, nonlinear system [@problem_id:2721650]. By constructing a candidate \"energy-like\" function $V(x)$, you will rigorously verify the conditions of positive definiteness and negative definiteness of its derivative, $\\dot{V}(x)$, to certify asymptotic stability. The exercise further solidifies this understanding by requiring the construction of class-$\\mathcal{K}_{\\infty}$ functions, which provide formal bounds on the behavior of $V(x)$ and $\\dot{V}(x)$.", "problem": "Consider the autonomous Ordinary Differential Equation (ODE) $\\dot{x}=f(x)$ on $\\mathbb{R}$ with an equilibrium at the origin. A continuously differentiable function $V:\\mathbb{R}\\to\\mathbb{R}$ is called a Lyapunov function for the origin if $V(0)=0$, $V(x)>0$ for all $x\\neq 0$, and the derivative of $V$ along trajectories, given by $\\dot{V}(x)=\\nabla V(x)\\,f(x)$, satisfies $\\dot{V}(x)<0$ for all $x\\neq 0$. A function $\\alpha:[0,\\infty)\\to[0,\\infty)$ is of class $\\mathcal{K}_{\\infty}$ if it is continuous, strictly increasing, satisfies $\\alpha(0)=0$, and $\\alpha(s)\\to\\infty$ as $s\\to\\infty$.\n\nFor the scalar system $\\dot{x}=-x^{3}$, use Lyapunovâ€™s direct method to certify asymptotic stability of the origin via the following steps that must be justified from the above definitions:\n- Propose a polynomial Lyapunov candidate $V(x)$ that is $C^{1}$, positive definite, and of minimal polynomial degree capable of certifying asymptotic stability by this method.\n- Verify $V(0)=0$ and $V(x)>0$ for all $x\\neq 0$.\n- Compute $\\dot{V}(x)$ along trajectories and verify the required sign condition $\\dot{V}(x)<0$ for all $x\\neq 0$.\n- Exhibit explicit comparison functions $\\alpha_{1},\\alpha_{2},\\alpha_{3}\\in\\mathcal{K}_{\\infty}$ such that $\\alpha_{1}(|x|)\\le V(x)\\le \\alpha_{2}(|x|)$ and $\\dot{V}(x)\\le -\\alpha_{3}(|x|)$ for all $x$.\n\nProvide detailed reasoning grounded in the above definitions and conclude asymptotic stability of the origin.\n\nYour final answer must be only your chosen Lyapunov function $V(x)$ as a single closed-form expression. No units are required. If you choose a numerical constant, do not approximate it; leave it exact.", "solution": "The problem statement is first subjected to validation.\n\nGivens are extracted verbatim:\n- The autonomous Ordinary Differential Equation (ODE) is $\\dot{x}=f(x)$ on $\\mathbb{R}$ with an equilibrium at the origin.\n- A continuously differentiable function $V:\\mathbb{R}\\to\\mathbb{R}$ is a Lyapunov function if $V(0)=0$, $V(x)>0$ for all $x\\neq 0$, and $\\dot{V}(x)=\\nabla V(x)\\,f(x)$ satisfies $\\dot{V}(x)<0$ for all $x\\neq 0$.\n- A function $\\alpha:[0,\\infty)\\to[0,\\infty)$ is of class $\\mathcal{K}_{\\infty}$ if it is continuous, strictly increasing, satisfies $\\alpha(0)=0$, and $\\alpha(s)\\to\\infty$ as $s\\to\\infty$.\n- The specific system is $\\dot{x}=-x^{3}$.\n- The task is to certify asymptotic stability of the origin by:\n    1. Proposing a minimal degree, positive definite, $C^{1}$ polynomial Lyapunov candidate $V(x)$.\n    2. Verifying $V(0)=0$ and $V(x)>0$ for $x\\neq 0$.\n    3. Computing $\\dot{V}(x)$ and verifying $\\dot{V}(x)<0$ for $x\\neq 0$.\n    4. Exhibiting explicit class $\\mathcal{K}_{\\infty}$ functions $\\alpha_{1},\\alpha_{2},\\alpha_{3}$ such that $\\alpha_{1}(|x|)\\le V(x)\\le \\alpha_{2}(|x|)$ and $\\dot{V}(x)\\le -\\alpha_{3}(|x|)$.\n\nValidation:\nThe problem is scientifically grounded, well-posed, and objective. It presents a standard exercise in Lyapunov stability theory, a fundamental topic in the study of dynamical systems and control theory. All definitions provided are standard and correct. The system $\\dot{x}=-x^3$ is a simple, well-defined nonlinear system. The problem is self-contained, providing all necessary information for its solution. It does not violate any physical laws, contain contradictions, or rely on subjective claims. Therefore, the problem is deemed valid.\n\nThe solution proceeds by addressing the four required steps.\n\nStep 1: Propose a Lyapunov candidate $V(x)$.\nWe seek a polynomial function $V(x)$ of minimal degree that is continuously differentiable ($C^{1}$) and positive definite. A polynomial is positive definite only if its lowest-degree term is of even power with a positive coefficient.\nA polynomial of degree $0$ is a constant, which cannot satisfy $V(0)=0$ and $V(x)>0$ for $x\\neq 0$.\nA polynomial of degree $1$, $V(x)=ax$ for $a\\neq 0$, is not positive definite as it takes both positive and negative values.\nThus, the minimal possible degree is $2$. Let us consider a general candidate of degree $2$: $V(x) = cx^{2}$ for some constant $c$. For $V(x)$ to be positive definite, we require $c>0$.\nLet us check if such a function can certify stability. The derivative of $V(x)$ along the trajectories of $\\dot{x}=-x^{3}$ is:\n$$\n\\dot{V}(x) = \\frac{dV}{dx}\\dot{x} = (2cx)(-x^{3}) = -2cx^{4}\n$$\nSince $c>0$, the term $-2c$ is strictly negative. For any $x\\neq 0$, $x^{4}>0$, which implies $\\dot{V}(x)<0$. This satisfies the condition for a Lyapunov function. Therefore, a polynomial of degree $2$ is sufficient.\nA simple and valid choice is to set the constant $c=\\frac{1}{2}$. This choice simplifies the expression for $\\dot{V}(x)$.\nThe proposed Lyapunov candidate is $V(x) = \\frac{1}{2}x^{2}$. This function is a polynomial, and thus is continuously differentiable everywhere.\n\nStep 2: Verify positive definiteness of $V(x)$.\nThe proposed function is $V(x) = \\frac{1}{2}x^{2}$.\n- At the origin: $V(0) = \\frac{1}{2}(0)^{2} = 0$. This condition is met.\n- For any $x \\in \\mathbb{R}$ such that $x \\neq 0$, it is a fact that $x^{2} > 0$. Since $\\frac{1}{2}$ is a positive constant, their product is positive: $V(x) = \\frac{1}{2}x^{2} > 0$.\nBoth conditions for positive definiteness are satisfied.\n\nStep 3: Compute $\\dot{V}(x)$ and verify its sign condition.\nThe time derivative of $V(x)$ along the system trajectories is computed using the chain rule:\n$$\n\\dot{V}(x) = \\frac{d}{dt}V(x(t)) = \\frac{dV}{dx}\\frac{dx}{dt} = \\frac{dV}{dx}\\dot{x}\n$$\nWith $V(x) = \\frac{1}{2}x^{2}$ and $\\dot{x} = -x^{3}$, we have:\n$$\n\\frac{dV}{dx} = \\frac{d}{dx}\\left(\\frac{1}{2}x^{2}\\right) = x\n$$\nSubstituting this into the expression for $\\dot{V}(x)$:\n$$\n\\dot{V}(x) = (x)(-x^{3}) = -x^{4}\n$$\nNow, we must verify that $\\dot{V}(x) < 0$ for all $x \\neq 0$. The term $x^{4}$ is the fourth power of a real number. For any $x \\in \\mathbb{R}$ such that $x \\neq 0$, we have $x^{4} > 0$. Consequently, $\\dot{V}(x) = -x^{4} < 0$ for all $x \\neq 0$.\nThe condition on $\\dot{V}(x)$ is satisfied. The function $V(x)=\\frac{1}{2}x^2$ is a strict Lyapunov function for the given system.\n\nStep 4: Exhibit explicit comparison functions.\nWe must find class $\\mathcal{K}_{\\infty}$ functions $\\alpha_{1}$, $\\alpha_{2}$, and $\\alpha_{3}$ satisfying the inequalities. Let $s = |x|$. We have $V(x) = \\frac{1}{2}x^{2} = \\frac{1}{2}|x|^{2} = \\frac{1}{2}s^{2}$ and $\\dot{V}(x) = -x^{4} = -|x|^{4} = -s^{4}$.\nThe inequalities are:\n1. $\\alpha_{1}(s) \\le \\frac{1}{2}s^{2}$\n2. $\\frac{1}{2}s^{2} \\le \\alpha_{2}(s)$\n3. $-s^{4} \\le -\\alpha_{3}(s)$, which is equivalent to $\\alpha_{3}(s) \\le s^{4}$\n\nWe select simple power functions of the form $\\alpha(s) = cs^{p}$ with $c>0$ and $p>0$. Such functions are continuous, strictly increasing on $[0,\\infty)$, satisfy $\\alpha(0)=0$, and diverge to $\\infty$ as $s\\to\\infty$, thus belonging to class $\\mathcal{K}_{\\infty}$.\n\n- For $\\alpha_{1}(s)$: We need $\\alpha_1(s) \\le \\frac{1}{2}s^2$. We can choose $\\alpha_{1}(s) = \\frac{1}{2}s^{2}$. This function is of class $\\mathcal{K}_{\\infty}$ (with $c=\\frac{1}{2}$, $p=2$) and satisfies the inequality with equality.\n- For $\\alpha_{2}(s)$: We need $\\frac{1}{2}s^2 \\le \\alpha_2(s)$. We can choose $\\alpha_{2}(s) = \\frac{1}{2}s^{2}$. This is the same function as $\\alpha_1(s)$, is of class $\\mathcal{K}_{\\infty}$, and satisfies the inequality with equality. We could also choose $\\alpha_{2}(s) = s^{2}$ or any function $cs^2$ with $c \\ge \\frac{1}{2}$.\n- For $\\alpha_{3}(s)$: We need $\\alpha_3(s) \\le s^4$. We can choose $\\alpha_{3}(s) = s^{4}$. This function is of class $\\mathcal{K}_{\\infty}$ (with $c=1$, $p=4$) and satisfies the inequality with equality.\n\nOur explicit choices are:\n- $\\alpha_{1}(s) = \\frac{1}{2}s^{2}$\n- $\\alpha_{2}(s) = \\frac{1}{2}s^{2}$\n- $\\alpha_{3}(s) = s^{4}$\n\nThese functions satisfy all required properties.\n\nConclusion:\nWe have constructed a strict Lyapunov function $V(x) = \\frac{1}{2}x^{2}$ for the system $\\dot{x}=-x^3$ with equilibrium at the origin. The existence of such a function proves that the origin is an asymptotically stable equilibrium point. Furthermore, the existence of the class $\\mathcal{K}_{\\infty}$ functions $\\alpha_1, \\alpha_2, \\alpha_3$ satisfying the specified bounds proves that the origin is globally asymptotically stable.", "answer": "$$\n\\boxed{\\frac{1}{2}x^{2}}\n$$", "id": "2721650"}, {"introduction": "While the condition $\\dot{V}(x) \\lt 0$ guarantees asymptotic stability, it can be overly restrictive. In many practical systems, we can only establish that $\\dot{V}(x) \\le 0$. This practice delves into this critical distinction, demonstrating how stability can be concluded even when the Lyapunov function is not strictly decreasing everywhere [@problem_id:2721587]. You will utilize LaSalle's Invariance Principle to analyze the system's behavior on the set where $\\dot{V}(x)=0$, thereby clarifying the subtle but crucial difference between Lyapunov stability and asymptotic stability.", "problem": "Consider the equilibrium at the origin for autonomous nonlinear systems in two states. Start from the definitions of Lyapunov stability, asymptotic stability, positive definiteness, and the notion of the derivative of a Lyapunov candidate along trajectories. Do not assume results beyond these definitions and well-established facts such as LaSalle's Invariance Principle (LIP).\n\nTask A. Using only the fundamental definitions, specify conditions on a continuously differentiable candidate Lyapunov function $V:\\mathbb{R}^{2}\\to\\mathbb{R}_{\\ge 0}$ that are sufficient to guarantee stability (in the sense of Lyapunov) of the origin when the derivative along trajectories satisfies $\\dot V(x)\\le 0$ in a neighborhood of the origin. Explain why these same conditions do not, by themselves, guarantee asymptotic stability, and state the additional structural property (in terms of the largest invariant set contained in $\\{x:\\dot V(x)=0\\}$) that is required to conclude asymptotic stability.\n\nTask B. Consider the nonlinear system\n$$\n\\dot x_{1}=-x_{1}^{3},\\qquad \\dot x_{2}=0,\n$$\nand the continuously differentiable function\n$$\nV(x)=\\tfrac{1}{2}\\big(x_{1}^{2}+x_{2}^{2}\\big).\n$$\nUsing first principles, verify that $V$ is positive definite and radially unbounded, compute $\\dot V$ along trajectories, and determine the largest invariant set contained in $\\{x:\\dot V(x)=0\\}$. Using LaSalle's Invariance Principle (LIP), conclude whether the origin is stable or asymptotically stable for this system, and justify your conclusion without appealing to any result not derivable from the stated principles.\n\nTask C. For the same system in Task B with initial condition $x(0)=(\\alpha,\\beta)^{\\top}$, where $\\alpha,\\beta\\in\\mathbb{R}$, compute explicitly the limit $\\lim_{t\\to\\infty}x(t)$ in closed form as a function of $\\alpha$ and $\\beta$. Provide your final answer as a single row vector in terms of $\\alpha$ and $\\beta$. No rounding is required, and no units are involved.", "solution": "The problem posed is a standard exercise in nonlinear control theory and is well-posed, scientifically grounded, and internally consistent. We shall proceed with the solution, addressing each task in sequence.\n\nTask A. Analysis of Stability Conditions.\n\nAn equilibrium point, taken to be the origin $x=0$, of the autonomous system $\\dot{x}=f(x)$ where $x \\in \\mathbb{R}^{2}$ is said to be stable in the sense of Lyapunov if for any given $\\epsilon > 0$, there exists a $\\delta(\\epsilon) > 0$ such that if $\\|x(0)\\| < \\delta$, then $\\|x(t)\\| < \\epsilon$ for all $t \\ge 0$.\n\nSufficient conditions for Lyapunov stability of the origin can be established using a continuously differentiable candidate Lyapunov function $V:\\mathbb{R}^{2} \\to \\mathbb{R}_{\\ge 0}$. The conditions are as follows:\n$1$. $V(x)$ is positive definite in a neighborhood $D$ of the origin. This means $V(0)=0$ and $V(x) > 0$ for all $x \\in D \\setminus \\{0\\}$.\n$2$. The time derivative of $V(x)$ along the system's trajectories, $\\dot{V}(x) = \\nabla V(x) \\cdot f(x)$, is negative semi-definite in $D$. This means $\\dot{V}(x) \\le 0$ for all $x \\in D$.\n\nThese conditions guarantee stability because the level sets of $V(x)$ form closed boundaries around the origin. A trajectory starting inside a level set $V(x)=c$ must remain within the set $\\{x \\mid V(x) \\le c\\}$ for all future time, since $\\dot{V}(x) \\le 0$ prevents the value of $V(x(t))$ from increasing. This directly implies that by choosing a sufficiently small initial neighborhood (defined by a small level of $V$), the trajectory can be confined within any larger, desired neighborhood, thus satisfying the definition of Lyapunov stability.\n\nThese conditions do not, by themselves, guarantee asymptotic stability. An equilibrium is asymptotically stable if it is stable and all trajectories starting sufficiently close to it converge to it as $t \\to \\infty$. The condition $\\dot{V}(x) \\le 0$ allows for the possibility that $\\dot{V}(x)=0$ along trajectories that are not the equilibrium point itself. If a trajectory enters a region where $\\dot{V}(x)=0$ and remains there, the value of $V(x)$ ceases to decrease, and the trajectory may converge to a point or a set other than the origin.\n\nTo guarantee asymptotic stability, an additional condition is required. This is provided by LaSalle's Invariance Principle (LIP). Let $\\Omega \\subset D$ be a compact, positively invariant set with respect to $\\dot{x}=f(x)$. Let $V(x)$ be a continuously differentiable function such that $\\dot{V}(x) \\le 0$ in $\\Omega$. Let $E = \\{x \\in \\Omega \\mid \\dot{V}(x) = 0\\}$. According to LIP, any solution starting in $\\Omega$ approaches $M$, the largest invariant set contained in $E$. Therefore, the additional structural property required to conclude asymptotic stability of the origin is that the largest invariant set $M$ contained in $\\{x \\mid \\dot{V}(x)=0\\}$ must consist only of the origin, i.e., $M=\\{0\\}$.\n\nTask B. Analysis of the Specific System.\n\nThe system under consideration is given by the equations:\n$$\n\\dot x_{1}=-x_{1}^{3}\n$$\n$$\n\\dot x_{2}=0\n$$\nThe proposed candidate Lyapunov function is $V(x) = \\frac{1}{2}(x_{1}^{2}+x_{2}^{2})$.\n\nFirst, we verify the properties of $V(x)$.\n- **Positive definiteness**: $V(0,0) = \\frac{1}{2}(0^{2}+0^{2}) = 0$. For any $x=(x_{1},x_{2})^{\\top} \\neq (0,0)^{\\top}$, at least one of $x_{1}$ or $x_{2}$ is non-zero. Since $x_{1}^{2} \\ge 0$ and $x_{2}^{2} \\ge 0$, their sum $x_{1}^{2}+x_{2}^{2}$ is strictly positive. Thus, $V(x) > 0$ for all $x \\neq 0$. The function is positive definite on all of $\\mathbb{R}^{2}$.\n- **Radial unboundedness**: The function $V(x)$ can be written as $V(x) = \\frac{1}{2}\\|x\\|_{2}^{2}$. As $\\|x\\|_{2} \\to \\infty$, it is clear that $V(x) \\to \\infty$. The function is radially unbounded.\n\nNext, we compute the derivative of $V$ along the system's trajectories:\n$$\n\\dot{V}(x) = \\frac{\\partial V}{\\partial x_{1}}\\dot{x}_{1} + \\frac{\\partial V}{\\partial x_{2}}\\dot{x}_{2} = (x_{1})(-x_{1}^{3}) + (x_{2})(0) = -x_{1}^{4}\n$$\nSince $x_{1}^{4} \\ge 0$ for all $x_{1} \\in \\mathbb{R}$, we have $\\dot{V}(x) \\le 0$ for all $x \\in \\mathbb{R}^{2}$. The derivative is negative semi-definite.\n\nThe existence of a positive definite, radially unbounded function $V(x)$ with $\\dot{V}(x) \\le 0$ is sufficient to conclude that the origin is stable in the sense of Lyapunov. The radial unboundedness ensures that the level sets are compact, and thus any trajectory is bounded for all time.\n\nTo assess asymptotic stability, we apply LaSalle's Invariance Principle. We define the set $E$ where $\\dot{V}(x)=0$:\n$$\nE = \\{ x \\in \\mathbb{R}^{2} \\mid \\dot{V}(x)=0 \\} = \\{ x \\in \\mathbb{R}^{2} \\mid -x_{1}^{4}=0 \\} = \\{ x \\in \\mathbb{R}^{2} \\mid x_{1}=0 \\}\n$$\nThis set is the $x_{2}$-axis.\n\nNow, we find the largest invariant set $M$ contained in $E$. A trajectory $x(t)$ that remains in $E$ must satisfy $x_{1}(t)=0$ for all $t$. If $x_{1}(t)=0$, then its time derivative must also be zero, $\\dot{x}_{1}(t)=0$. The first system equation is $\\dot{x}_{1} = -x_{1}^{3}$. Substituting $x_{1}=0$ gives $0=-0^{3}$, which is satisfied. The second system equation is $\\dot{x}_{2}=0$, which integrates to $x_{2}(t)=C$, where $C$ is a constant. Thus, any trajectory of the form $x(t)=(0, C)^{\\top}$ is a valid trajectory of the system and lies entirely within $E$. The set of all such points is the entire $x_{2}$-axis. Therefore, the largest invariant set $M$ contained in $E$ is $E$ itself:\n$$\nM = \\{ x \\in \\mathbb{R}^{2} \\mid x_{1}=0 \\}\n$$\nAccording to LIP, all trajectories of the system converge to this set $M$. Since $M$ is not the singleton set $\\{0\\}$, the origin is not asymptotically stable. The system is stable, but not asymptotically stable. Any trajectory starting at $x(0)=(\\alpha, \\beta)^{\\top}$ will converge to the point $(0, \\beta)^{\\top}$ on the $x_{2}$-axis.\n\nTask C. Explicit Calculation of Trajectory Limit.\n\nWe are given the system of differential equations with initial conditions $x(0)=(\\alpha, \\beta)^{\\top}$:\n$1$. $\\dot{x}_{1} = -x_{1}^{3}$, with $x_{1}(0) = \\alpha$.\n$2$. $\\dot{x}_{2} = 0$, with $x_{2}(0) = \\beta$.\n\nFrom the second equation, $\\dot{x}_{2}(t)=0$, we integrate to find $x_{2}(t) = C$ for some constant $C$. Using the initial condition $x_{2}(0)=\\beta$, we determine that $C=\\beta$. Therefore, $x_{2}(t)=\\beta$ for all $t \\ge 0$.\n\nThe first equation, $\\frac{dx_{1}}{dt} = -x_{1}^{3}$, is a separable ordinary differential equation.\nIf $\\alpha=0$, then $x_{1}(0)=0$ is an equilibrium for this equation, so $x_{1}(t)=0$ for all $t$.\nIf $\\alpha \\neq 0$, we can separate variables:\n$$\n\\frac{dx_{1}}{x_{1}^{3}} = -dt\n$$\nIntegrating both sides from $t=0$ to $t$:\n$$\n\\int_{\\alpha}^{x_{1}(t)} s^{-3} ds = \\int_{0}^{t} -1 d\\tau\n$$\n$$\n\\left[ -\\frac{1}{2}s^{-2} \\right]_{\\alpha}^{x_{1}(t)} = -t\n$$\n$$\n-\\frac{1}{2x_{1}(t)^{2}} + \\frac{1}{2\\alpha^{2}} = -t\n$$\n$$\n\\frac{1}{2x_{1}(t)^{2}} = t + \\frac{1}{2\\alpha^{2}}\n$$\n$$\nx_{1}(t)^{2} = \\frac{1}{2t + \\frac{1}{\\alpha^{2}}} = \\frac{\\alpha^{2}}{2\\alpha^{2}t + 1}\n$$\nTaking the square root, we must choose the sign that matches the initial condition $x_{1}(0)=\\alpha$.\n$$\nx_{1}(t) = \\frac{\\alpha}{\\sqrt{2\\alpha^{2}t + 1}}\n$$\nThis formula also correctly yields $x_{1}(t)=0$ for the case $\\alpha=0$.\n\nNow we compute the limit of the solution $x(t)=(x_{1}(t), x_{2}(t))^{\\top}$ as $t \\to \\infty$.\nThe limit of the first component is:\n$$\n\\lim_{t\\to\\infty} x_{1}(t) = \\lim_{t\\to\\infty} \\frac{\\alpha}{\\sqrt{2\\alpha^{2}t + 1}} = 0\n$$\nThe limit of the second component is:\n$$\n\\lim_{t\\to\\infty} x_{2}(t) = \\lim_{t\\to\\infty} \\beta = \\beta\n$$\nThus, the limit of the trajectory is:\n$$\n\\lim_{t\\to\\infty} x(t) = \\begin{pmatrix} 0 \\\\ \\beta \\end{pmatrix}\n$$\nThis result confirms the conclusion from Task B that every trajectory converges to a point on the $x_{2}$-axis, specifically to the point determined by its initial $x_{2}$ value. The problem asks for the final answer as a single row vector.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & \\beta \\end{pmatrix}}\n$$", "id": "2721587"}, {"introduction": "Lyapunov's direct method provides particularly powerful and computationally tractable tools when applied to Linear Time-Invariant (LTI) systems of the form $\\dot{x} = Ax$. For these systems, stability analysis can be reduced to solving a matrix equation known as the continuous-time Lyapunov equation, $A^T P + PA = -Q$ [@problem_id:2721669]. This hands-on problem guides you through the process of solving for the symmetric matrix $P$ for a given system matrix $A$ and a positive definite matrix $Q$. Successfully finding a positive definite solution $P$ serves as a certificate of asymptotic stability for the system, a cornerstone result in modern control theory.", "problem": "Consider the continuous-time linear time-invariant system $\\dot{x} = A x$ with $A \\in \\mathbb{R}^{2 \\times 2}$. Using Lyapunov's second (direct) method, recall that a quadratic candidate Lyapunov function $V(x) = x^{\\top} P x$ with $P = P^{\\top}$ yields $\\dot{V}(x) = x^{\\top} \\left(A^{\\top} P + P A\\right) x$. Requiring $\\dot{V}(x) = -x^{\\top} x$ for all $x \\neq 0$ leads to the continuous-time Lyapunov equation $A^{\\top} P + P A = -I$, where $I$ is the identity matrix. \n\nLet $A = \\begin{bmatrix} -2 & 1 \\\\ -3 & -4 \\end{bmatrix}$ and $Q = I$. Solve the Lyapunov equation $A^{\\top} P + P A = -I$ for the symmetric matrix $P \\in \\mathbb{R}^{2 \\times 2}$, and verify rigorously that $P$ is positive definite using a first-principles criterion that does not assume the conclusion. Express your final answer as the explicit $2 \\times 2$ matrix $P$ in exact rational form. The final answer should be the matrix $P$ only.", "solution": "The problem is validated as sound and well-posed. The matrix $A$ is Hurwitz, as its eigenvalues are $\\lambda = -3 \\pm i\\sqrt{2}$, which both have negative real parts. This guarantees the existence of a unique, symmetric, positive definite solution $P$ for the given Lyapunov equation. We now proceed to find this solution.\n\nWe are tasked with solving the continuous-time Lyapunov equation $A^{\\top} P + P A = -I$ for a symmetric matrix $P \\in \\mathbb{R}^{2 \\times 2}$. The given matrices are:\n$$\nA = \\begin{pmatrix} -2 & 1 \\\\ -3 & -4 \\end{pmatrix}, \\quad I = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nThe transpose of $A$ is:\n$$\nA^{\\top} = \\begin{pmatrix} -2 & -3 \\\\ 1 & -4 \\end{pmatrix}\n$$\nLet the symmetric matrix $P$ be denoted as:\n$$\nP = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix}\n$$\nWe now substitute these matrices into the Lyapunov equation $A^{\\top} P + P A = -I$:\n$$\n\\begin{pmatrix} -2 & -3 \\\\ 1 & -4 \\end{pmatrix} \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} + \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} \\begin{pmatrix} -2 & 1 \\\\ -3 & -4 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n$$\nPerforming the matrix multiplications, we get:\n$$\n\\begin{pmatrix} -2p_{11} - 3p_{12} & -2p_{12} - 3p_{22} \\\\ p_{11} - 4p_{12} & p_{12} - 4p_{22} \\end{pmatrix} + \\begin{pmatrix} -2p_{11} - 3p_{12} & p_{11} - 4p_{12} \\\\ -2p_{12} - 3p_{22} & p_{12} - 4p_{22} \\end{pmatrix} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n$$\nSumming the matrices on the left-hand side yields:\n$$\n\\begin{pmatrix} -4p_{11} - 6p_{12} & p_{11} - 6p_{12} - 3p_{22} \\\\ p_{11} - 6p_{12} - 3p_{22} & 2p_{12} - 8p_{22} \\end{pmatrix} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n$$\nBy equating the corresponding elements of the matrices, we obtain a system of three linear equations for the three unknowns $p_{11}$, $p_{12}$, and $p_{22}$:\n1.  $-4p_{11} - 6p_{12} = -1 \\implies 4p_{11} + 6p_{12} = 1$\n2.  $p_{11} - 6p_{12} - 3p_{22} = 0$\n3.  $2p_{12} - 8p_{22} = -1 \\implies 8p_{22} - 2p_{12} = 1$\n\nWe solve this system. From equation (3), we express $p_{22}$ in terms of $p_{12}$:\n$$\n8p_{22} = 1 + 2p_{12} \\implies p_{22} = \\frac{1 + 2p_{12}}{8}\n$$\nSubstitute this expression for $p_{22}$ into equation (2):\n$$\np_{11} - 6p_{12} - 3\\left(\\frac{1 + 2p_{12}}{8}\\right) = 0\n$$\nMultiplying by $8$ to clear the denominator gives:\n$$\n8p_{11} - 48p_{12} - 3(1 + 2p_{12}) = 0\n$$\n$$\n8p_{11} - 48p_{12} - 3 - 6p_{12} = 0\n$$\n$$\n8p_{11} - 54p_{12} = 3\n$$\nNow we have a system of two equations for $p_{11}$ and $p_{12}$:\n(a) $4p_{11} + 6p_{12} = 1$\n(b) $8p_{11} - 54p_{12} = 3$\n\nMultiply equation (a) by $2$:\n$$\n8p_{11} + 12p_{12} = 2\n$$\nSubtract equation (b) from this new equation:\n$$\n(8p_{11} + 12p_{12}) - (8p_{11} - 54p_{12}) = 2 - 3\n$$\n$$\n66p_{12} = -1 \\implies p_{12} = -\\frac{1}{66}\n$$\nNow substitute the value of $p_{12}$ back into equation (a):\n$$\n4p_{11} + 6\\left(-\\frac{1}{66}\\right) = 1 \\implies 4p_{11} - \\frac{1}{11} = 1\n$$\n$$\n4p_{11} = 1 + \\frac{1}{11} = \\frac{12}{11} \\implies p_{11} = \\frac{3}{11}\n$$\nFinally, substitute the value of $p_{12}$ into the expression for $p_{22}$:\n$$\np_{22} = \\frac{1 + 2\\left(-\\frac{1}{66}\\right)}{8} = \\frac{1 - \\frac{1}{33}}{8} = \\frac{\\frac{32}{33}}{8} = \\frac{32}{33 \\times 8} = \\frac{4}{33}\n$$\nThus, the solution matrix $P$ is:\n$$\nP = \\begin{pmatrix} \\frac{3}{11} & -\\frac{1}{66} \\\\ -\\frac{1}{66} & \\frac{4}{33} \\end{pmatrix}\n$$\nThe problem requires rigorous verification that $P$ is positive definite. For a $2 \\times 2$ symmetric matrix, a first-principles criterion is Sylvester's criterion, which states that the matrix is positive definite if and only if all of its leading principal minors are positive.\n\nThe first leading principal minor is the top-left element, $p_{11}$.\n$$\n\\Delta_1 = p_{11} = \\frac{3}{11}\n$$\nSince $\\Delta_1 > 0$, the first condition is met.\n\nThe second leading principal minor is the determinant of the matrix $P$.\n$$\n\\Delta_2 = \\det(P) = p_{11}p_{22} - p_{12}^2 = \\left(\\frac{3}{11}\\right)\\left(\\frac{4}{33}\\right) - \\left(-\\frac{1}{66}\\right)^2\n$$\n$$\n\\det(P) = \\frac{12}{363} - \\frac{1}{4356}\n$$\nTo subtract the fractions, we find a common denominator, which is $4356$.\n$4356 = 12 \\times 363$.\n$$\n\\det(P) = \\frac{12 \\times 12}{363 \\times 12} - \\frac{1}{4356} = \\frac{144}{4356} - \\frac{1}{4356} = \\frac{143}{4356}\n$$\nSince $\\Delta_2 = \\frac{143}{4356} > 0$, the second condition is also met.\nBoth leading principal minors are positive, therefore the matrix $P$ is rigorously verified to be positive definite. The candidate function $V(x) = x^{\\top}Px$ is indeed a valid Lyapunov function that proves the asymptotic stability of the origin for the system $\\dot{x}=Ax$.\n\nThe final answer is the matrix $P$ in its exact rational form.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{11} & -\\frac{1}{66} \\\\\n-\\frac{1}{66} & \\frac{4}{33}\n\\end{pmatrix}\n}\n$$", "id": "2721669"}]}