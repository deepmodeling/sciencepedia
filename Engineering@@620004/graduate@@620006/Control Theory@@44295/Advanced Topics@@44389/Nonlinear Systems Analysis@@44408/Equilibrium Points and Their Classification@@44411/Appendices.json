{"hands_on_practices": [{"introduction": "The cornerstone of analyzing nonlinear systems is linearization, a technique that approximates the system's behavior near an equilibrium point with a simpler linear model. The stability of this linear approximation, determined by the eigenvalues of the Jacobian matrix, provides invaluable insight into the local dynamics of the original system. This foundational exercise [@problem_id:2704846] walks you through the essential steps of computing the Jacobian and its eigenvalues to classify an equilibrium, focusing on the critical case where the eigenvalues are purely imaginary, leading to a center in the linearized phase portrait.", "problem": "Consider the nonlinear autonomous system in state-space form with state vector $x \\in \\mathbb{R}^{2}$ given by\n$$\n\\dot{x}_{1}=x_{2}, \\qquad \\dot{x}_{2}=-x_{1}-x_{2}^{3}.\n$$\nRecall that an equilibrium point is a point $x^{\\ast}$ such that $f(x^{\\ast})=0$, where $f:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ is the vector field of the system, and that the Jacobian matrix $J(x)$ is defined by\n$$\nJ(x)=\\begin{bmatrix}\n\\frac{\\partial f_{1}}{\\partial x_{1}}(x) & \\frac{\\partial f_{1}}{\\partial x_{2}}(x)\\\\\n\\frac{\\partial f_{2}}{\\partial x_{1}}(x) & \\frac{\\partial f_{2}}{\\partial x_{2}}(x)\n\\end{bmatrix}.\n$$\nUsing only these definitions and the definition of eigenvalues through the characteristic polynomial of a matrix, carry out the following steps:\n1. Verify that the origin $x^{\\ast}=\\begin{bmatrix}0 & 0\\end{bmatrix}^{\\top}$ is an equilibrium point.\n2. Compute the Jacobian $J(0)$ of the vector field evaluated at the origin.\n3. Compute the eigenvalues of $J(0)$ and, based solely on these eigenvalues, classify the equilibrium of the linearized system at the origin.\n\nReport as your final answer only the pair of eigenvalues of $J(0)$, in exact form, arranged as a single row using a matrix format. No rounding is required.", "solution": "The problem as stated is well-posed, mathematically consistent, and directly solvable using standard methods from the theory of ordinary differential equations and control theory. We shall proceed with the analysis.\n\nThe system is defined by the state equations:\n$$\n\\dot{x}_{1} = f_{1}(x_{1}, x_{2}) = x_{2}\n$$\n$$\n\\dot{x}_{2} = f_{2}(x_{1}, x_{2}) = -x_{1} - x_{2}^{3}\n$$\nIn vector form, this is $\\dot{x} = f(x)$, where $x = \\begin{bmatrix} x_{1} \\\\ x_{2} \\end{bmatrix}$ and $f(x) = \\begin{bmatrix} x_{2} \\\\ -x_{1}-x_{2}^{3} \\end{bmatrix}$.\n\nStep 1: Verification of the equilibrium point.\nAn equilibrium point $x^{\\ast}$ is a state for which the system's dynamics are zero, i.e., $f(x^{\\ast}) = 0$. We must verify if the origin, $x^{\\ast} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, satisfies this condition.\nWe substitute $x_{1} = 0$ and $x_{2} = 0$ into the vector field $f(x)$:\n$$\nf(x^{\\ast}) = f(0, 0) = \\begin{bmatrix} 0 \\\\ -0 - 0^{3} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n$$\nSince $f(x^{\\ast})$ is the zero vector, the origin is indeed an equilibrium point of the system.\n\nStep 2: Computation of the Jacobian matrix.\nThe Jacobian matrix $J(x)$ of the vector field $f(x)$ is the matrix of first-order partial derivatives, given by the definition:\n$$\nJ(x) = \\begin{bmatrix} \\frac{\\partial f_{1}}{\\partial x_{1}} & \\frac{\\partial f_{1}}{\\partial x_{2}} \\\\ \\frac{\\partial f_{2}}{\\partial x_{1}} & \\frac{\\partial f_{2}}{\\partial x_{2}} \\end{bmatrix}\n$$\nWe compute each partial derivative:\n$$\n\\frac{\\partial f_{1}}{\\partial x_{1}} = \\frac{\\partial}{\\partial x_{1}}(x_{2}) = 0\n$$\n$$\n\\frac{\\partial f_{1}}{\\partial x_{2}} = \\frac{\\partial}{\\partial x_{2}}(x_{2}) = 1\n$$\n$$\n\\frac{\\partial f_{2}}{\\partial x_{1}} = \\frac{\\partial}{\\partial x_{1}}(-x_{1} - x_{2}^{3}) = -1\n$$\n$$\n\\frac{\\partial f_{2}}{\\partial x_{2}} = \\frac{\\partial}{\\partial x_{2}}(-x_{1} - x_{2}^{3}) = -3x_{2}^{2}\n$$\nAssembling these components gives the Jacobian matrix as a function of the state $x$:\n$$\nJ(x) = \\begin{bmatrix} 0 & 1 \\\\ -1 & -3x_{2}^{2} \\end{bmatrix}\n$$\nTo analyze the stability of the equilibrium at the origin, we evaluate this matrix at $x^{\\ast} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$:\n$$\nJ(0) = \\begin{bmatrix} 0 & 1 \\\\ -1 & -3(0)^{2} \\end{bmatrix} = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n$$\nThis is the matrix of the linearized system about the origin.\n\nStep 3: Computation of eigenvalues and classification.\nThe eigenvalues $\\lambda$ of the matrix $J(0)$ are found by solving the characteristic equation $\\det(J(0) - \\lambda I) = 0$, where $I$ is the $2 \\times 2$ identity matrix.\n$$\n\\det\\left( \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} - \\lambda \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\right) = 0\n$$\n$$\n\\det\\left( \\begin{bmatrix} -\\lambda & 1 \\\\ -1 & -\\lambda \\end{bmatrix} \\right) = 0\n$$\nThe determinant is calculated as:\n$$\n(-\\lambda)(-\\lambda) - (1)(-1) = \\lambda^{2} + 1\n$$\nSetting the characteristic polynomial to zero gives the equation:\n$$\n\\lambda^{2} + 1 = 0\n$$\nSolving for $\\lambda$, we find:\n$$\n\\lambda^{2} = -1\n$$\n$$\n\\lambda = \\pm\\sqrt{-1}\n$$\nThe eigenvalues are a complex conjugate pair: $\\lambda_{1} = i$ and $\\lambda_{2} = -i$.\n\nBased solely on these eigenvalues, we classify the equilibrium of the linearized system. The eigenvalues are of the form $\\lambda = \\alpha \\pm j\\beta$, where $\\alpha$ is the real part and $\\beta$ is the imaginary part. In this case, $\\alpha = 0$ and $\\beta = 1$. When the eigenvalues of a two-dimensional linear system are a purely imaginary conjugate pair (i.e., $\\alpha=0$ and $\\beta \\neq 0$), the equilibrium point is classified as a **center**. This corresponds to oscillatory behavior with constant amplitude in the vicinity of the equilibrium point for the linearized system.", "answer": "$$\n\\boxed{\\begin{pmatrix} i & -i \\end{pmatrix}}\n$$", "id": "2704846"}, {"introduction": "While linearization gives us a powerful local picture, it does not tell us the extent of the basin of attractionâ€”that is, the set of initial conditions from which trajectories converge to a stable equilibrium. To answer this, we turn to Lyapunov's direct method, a more global tool that can prove stability and estimate this region without solving the differential equations. In this practice [@problem_id:2704886], you will use a given energy-like Lyapunov function, $V(x)$, and analyze its time derivative, $\\dot{V}(x)$, to determine the largest sublevel set that is guaranteed to be within the region of attraction, providing a rigorous bound on the system's stability.", "problem": "Consider the autonomous nonlinear system in continuous time with state $x = (x_1, x_2) \\in \\mathbb{R}^2$ given by\n$$\n\\dot{x}_1 = -x_1 + x_2^2, \\qquad \\dot{x}_2 = -x_2.\n$$\nThe origin $x = 0$ is an equilibrium point. Using the direct method of Lyapunov based on first principles, proceed as follows:\n- Start from the definitions of a Lyapunov function, negative definiteness of its derivative along trajectories, and the region of attraction.\n- Consider the Lyapunov candidate\n$$\nV(x) = x_1^2 + x_2^2,\n$$\nwhich is positive definite and radially unbounded.\n- By requiring that the derivative of $V$ along trajectories is strictly negative on the boundary of the sublevel set $\\{ x \\in \\mathbb{R}^2 : V(x) = c \\}$, determine the supremum value $c^\\star$ such that every sublevel set $\\{ x \\in \\mathbb{R}^2 : V(x) \\le c \\}$ with $0 < c \\le c^\\star$ is forward invariant and contained in the region of attraction of the origin.\n\nYour final answer must be the exact value of $c^\\star$ as a single real number. Do not round.", "solution": "The problem statement has been examined and is deemed valid. It is a well-posed, scientifically grounded problem in the field of control theory, specifically concerning the application of Lyapunov's direct method to estimate the region of attraction for a nonlinear autonomous system. We may proceed with the solution.\n\nThe system is described by the state equations:\n$$\n\\begin{cases}\n\\dot{x}_1 = -x_1 + x_2^2 \\\\\n\\dot{x}_2 = -x_2\n\\end{cases}\n$$\nThe origin, $x = (x_1, x_2) = (0, 0)$, is an equilibrium point, as $\\dot{x}_1(0,0) = 0$ and $\\dot{x}_2(0,0) = 0$.\n\nThe proposed Lyapunov function candidate is $V(x) = x_1^2 + x_2^2$. This function is positive definite as $V(0) = 0$ and $V(x) > 0$ for all $x \\in \\mathbb{R}^2 \\setminus \\{0\\}$. It is also radially unbounded.\n\nAccording to Lyapunov's theorem for estimating the domain of attraction, a sublevel set $\\Omega_c = \\{ x \\in \\mathbb{R}^2 : V(x) \\le c \\}$ is a subset of the region of attraction of the origin if $c > 0$, $\\Omega_c$ is compact, and the time derivative of the Lyapunov function, $\\dot{V}(x)$, is strictly negative for all $x \\in \\Omega_c \\setminus \\{0\\}$. The sets $\\Omega_c$ for $c>0$ are closed disks centered at the origin, which are compact. We therefore need to find the largest value of $c$, which we denote $c^\\star$, such that $\\dot{V}(x) < 0$ for all $x$ satisfying $0 < V(x) \\le c^\\star$.\n\nThis is equivalent to finding the smallest value of $V(x)$ on the set where $\\dot{V}(x) = 0$ (excluding the origin itself). Any sublevel set defined by a constant smaller than this minimum value will be devoid of any points where the derivative is zero or positive, except for the origin.\n\nFirst, we compute the time derivative of $V(x)$ along the trajectories of the system:\n$$\n\\dot{V}(x) = \\frac{\\partial V}{\\partial x} \\dot{x} = \\begin{pmatrix} \\frac{\\partial V}{\\partial x_1} & \\frac{\\partial V}{\\partial x_2} \\end{pmatrix} \\begin{pmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{pmatrix}\n$$\nThe partial derivatives are $\\frac{\\partial V}{\\partial x_1} = 2x_1$ and $\\frac{\\partial V}{\\partial x_2} = 2x_2$.\nSubstituting the system dynamics, we obtain:\n$$\n\\dot{V}(x) = (2x_1)(-x_1 + x_2^2) + (2x_2)(-x_2)\n$$\n$$\n\\dot{V}(x) = -2x_1^2 + 2x_1 x_2^2 - 2x_2^2\n$$\nFor local asymptotic stability, we require $\\dot{V}(x)$ to be negative definite in a neighborhood of the origin. However, the term $2x_1 x_2^2$ can be positive and can dominate the negative definite part $-2(x_1^2 + x_2^2)$. Therefore, the origin is not globally asymptotically stable, and we must find a region where $\\dot{V}(x)$ is strictly negative.\n\nWe seek the largest constant $c^\\star$ such that the set $\\Omega_{c^\\star} = \\{x | x_1^2 + x_2^2 \\le c^\\star \\}$ is the largest such invariant region. This value $c^\\star$ is the minimum value of $V(x)$ over all non-zero points where $\\dot{V}(x) \\ge 0$. The boundary of the region where $\\dot{V}(x) < 0$ is the set of points where $\\dot{V}(x) = 0$.\nWe set $\\dot{V}(x) = 0$ for $x \\neq 0$:\n$$\n-2x_1^2 + 2x_1 x_2^2 - 2x_2^2 = 0\n$$\n$$\nx_1^2 - x_1 x_2^2 + x_2^2 = 0\n$$\nThe problem is now reduced to finding the minimum value of the function $V(x) = x_1^2 + x_2^2$ subject to the constraint $g(x_1, x_2) = x_1^2 - x_1 x_2^2 + x_2^2 = 0$, for $x \\neq 0$.\n\nFrom the constraint equation, we can write $x_1^2 + x_2^2 = x_1 x_2^2$. Therefore, we are minimizing $V(x) = x_1 x_2^2$.\nLet's express $x_2^2$ in terms of $x_1$ from the constraint:\n$$\nx_2^2(x_1 - 1) = x_1^2\n$$\nIf $x_1=1$, the equation becomes $0 = 1$, which is a contradiction. Thus, $x_1 \\neq 1$. We can write:\n$$\nx_2^2 = \\frac{x_1^2}{x_1-1}\n$$\nSince $x_2^2 \\ge 0$ and $x_1^2 \\ge 0$, and we exclude the case $x_1=0$ (which implies $x_2=0$, the origin), we must have $x_1-1 > 0$, which means $x_1 > 1$.\n\nNow we express $V$ as a function of $x_1$ alone for $x_1 > 1$:\n$$\nV(x_1) = x_1^2 + x_2^2 = x_1^2 + \\frac{x_1^2}{x_1-1}\n$$\nTo find the minimum value of $V(x_1)$, we compute its derivative with respect to $x_1$ and set it to zero:\n$$\n\\frac{dV}{dx_1} = \\frac{d}{dx_1} \\left( x_1^2 + \\frac{x_1^2}{x_1-1} \\right) = 2x_1 + \\frac{2x_1(x_1-1) - x_1^2(1)}{(x_1-1)^2}\n$$\n$$\n\\frac{dV}{dx_1} = 2x_1 + \\frac{2x_1^2 - 2x_1 - x_1^2}{(x_1-1)^2} = 2x_1 + \\frac{x_1^2 - 2x_1}{(x_1-1)^2}\n$$\n$$\n\\frac{dV}{dx_1} = \\frac{2x_1(x_1-1)^2 + x_1^2 - 2x_1}{(x_1-1)^2} = \\frac{2x_1(x_1^2 - 2x_1 + 1) + x_1^2 - 2x_1}{(x_1-1)^2}\n$$\n$$\n\\frac{dV}{dx_1} = \\frac{2x_1^3 - 4x_1^2 + 2x_1 + x_1^2 - 2x_1}{(x_1-1)^2} = \\frac{2x_1^3 - 3x_1^2}{(x_1-1)^2}\n$$\nSetting the derivative to zero to find an extremum:\n$$\n\\frac{x_1^2(2x_1 - 3)}{(x_1-1)^2} = 0\n$$\nSince $x_1>1$, the only valid solution is $2x_1 - 3 = 0$, which yields $x_1 = \\frac{3}{2}$.\nTo confirm this is a minimum, we can examine the second derivative, or observe the sign of the first derivative. For $1 < x_1 < \\frac{3}{2}$, $\\frac{dV}{dx_1} < 0$. For $x_1 > \\frac{3}{2}$, $\\frac{dV}{dx_1} > 0$. Thus, $x_1 = \\frac{3}{2}$ corresponds to a local minimum, and since it is the only critical point in the domain $x_1 > 1$, it is the global minimum.\n\nThe minimum value of $V$ is found by substituting $x_1 = \\frac{3}{2}$ back into the expression for $V(x_1)$:\n$$\nc^\\star = V\\left(\\frac{3}{2}\\right) = \\left(\\frac{3}{2}\\right)^2 + \\frac{\\left(\\frac{3}{2}\\right)^2}{\\frac{3}{2}-1}\n$$\n$$\nc^\\star = \\frac{9}{4} + \\frac{\\frac{9}{4}}{\\frac{1}{2}} = \\frac{9}{4} + \\frac{9}{2} = \\frac{9}{4} + \\frac{18}{4} = \\frac{27}{4}\n$$\nThis value $c^\\star = \\frac{27}{4}$ is the supremum such that for any $c$ with $0 < c \\le c^\\star$, the set $\\{ x \\in \\mathbb{R}^2 : V(x) \\le c \\}$ is forward invariant and contained in the region of attraction of the origin. For any $c \\in (0, \\frac{27}{4})$, $\\dot{V}(x)$ is strictly negative on the set $\\{x | 0 < V(x) \\le c\\}$.", "answer": "$$\\boxed{\\frac{27}{4}}$$", "id": "2704886"}, {"introduction": "The behavior of dynamical systems often changes dramatically as a system parameter is varied, a phenomenon known as bifurcation. One of the most important bifurcations is the Hopf bifurcation, where an equilibrium point changes stability and gives rise to a small-amplitude limit cycle, marking the onset of sustained oscillations. This exercise [@problem_id:2704876] provides a hands-on analysis of a classic system undergoing a Hopf bifurcation, guiding you to transform the dynamics into polar coordinates to uncover the amplitude equation and compute the first Lyapunov coefficient, $l_1$, which determines the stability of the emerging limit cycle.", "problem": "Consider the planar nonlinear system of ordinary differential equations (ODEs)\n$$\n\\dot{x}_{1}=\\lambda x_{1}-x_{2}-x_{1}\\left(x_{1}^{2}+x_{2}^{2}\\right),\\qquad \n\\dot{x}_{2}=x_{1}+\\lambda x_{2}-x_{2}\\left(x_{1}^{2}+x_{2}^{2}\\right),\n$$\nwhere $\\lambda \\in \\mathbb{R}$ is a real-valued bifurcation parameter, and $(x_{1},x_{2}) \\in \\mathbb{R}^{2}$. An equilibrium point is a point $(x_{1}^{\\star},x_{2}^{\\star})$ such that $\\dot{x}_{1}=\\dot{x}_{2}=0$. The linearization of the system at an equilibrium is given by its Jacobian matrix evaluated at that equilibrium, and the local behavior of solutions near the equilibrium can be classified using the eigenvalues of this Jacobian. A Hopf bifurcation occurs when a pair of complex-conjugate eigenvalues of the linearization cross the imaginary axis with nonzero speed with respect to the bifurcation parameter, while all other eigenvalues have nonzero real parts.\n\nStarting from the fundamental definitions above, analyze the equilibrium at the origin $(x_{1},x_{2})=(0,0)$ as $\\lambda$ varies near $0$. Derive the exact amplitude dynamics by transforming to polar coordinates $(r,\\theta)$ with $r=\\sqrt{x_{1}^{2}+x_{2}^{2}}$ and $\\theta=\\arctan2(x_{2},x_{1})$, without introducing any state or time rescalings. Use this derivation to determine the cubic term in the radial normal form. Define the first Lyapunov coefficient $l_{1}$ at the Hopf point $\\lambda=0$ to be the coefficient multiplying $r^{3}$ in the exact radial equation written in the form\n$$\n\\dot{r}=\\mu\\, r + l_{1}\\, r^{3}+\\text{higher-order terms in } r,\n$$\nwith $\\mu$ identified with $\\lambda$ near the bifurcation. Based on its sign, one can classify the Hopf bifurcation as supercritical (if $l_{1}<0$) or subcritical (if $l_{1}>0$), but for the purpose of this problem you must report only the value of $l_{1}$.\n\nWhat is the exact value of the first Lyapunov coefficient $l_{1}$ at $\\lambda=0$? Provide your answer as a single exact real number. No rounding is required, and no units are involved.", "solution": "The problem requires the determination of the first Lyapunov coefficient, $l_1$, for the given planar system at the Hopf bifurcation point. The validation of the problem statement is the mandatory first step.\n\n**Step 1: Extract Givens**\nThe system of ordinary differential equations (ODEs) is:\n$$\n\\dot{x}_{1}=\\lambda x_{1}-x_{2}-x_{1}\\left(x_{1}^{2}+x_{2}^{2}\\right)\n$$\n$$\n\\dot{x}_{2}=x_{1}+\\lambda x_{2}-x_{2}\\left(x_{1}^{2}+x_{2}^{2}\\right)\n$$\n- The bifurcation parameter is $\\lambda \\in \\mathbb{R}$.\n- The state variables are $(x_{1},x_{2}) \\in \\mathbb{R}^{2}$.\n- The equilibrium point to be analyzed is the origin, $(x_{1}^{\\star},x_{2}^{\\star})=(0,0)$.\n- The analysis method is a transformation to polar coordinates $(r,\\theta)$, where $r=\\sqrt{x_{1}^{2}+x_{2}^{2}}$ and $\\theta=\\arctan2(x_{2},x_{1})$.\n- The first Lyapunov coefficient $l_1$ is defined as the coefficient of the $r^3$ term in the radial equation $\\dot{r}=\\mu r + l_1 r^3 + \\text{H.O.T.}$, with $\\mu$ identified as $\\lambda$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It presents a standard model from nonlinear dynamics and bifurcation theory, specifically the normal form for a Hopf bifurcation. All definitions are standard and the required calculation is mathematically rigorous and unambiguous. There are no contradictions, missing information, or violations of scientific principles. The problem is therefore deemed **valid**.\n\n**Step 3: Solution Derivation**\nThe analysis begins by verifying the equilibrium point and its local stability properties.\n\nFirst, we confirm that $(x_1, x_2) = (0,0)$ is an equilibrium point for any value of $\\lambda$. Substituting $x_1=0$ and $x_2=0$ into the system equations yields:\n$$\n\\dot{x}_1 = \\lambda(0) - 0 - 0(0^2+0^2) = 0\n$$\n$$\n\\dot{x}_2 = 0 + \\lambda(0) - 0(0^2+0^2) = 0\n$$\nThus, the origin is indeed a fixed point.\n\nNext, we linearize the system around this equilibrium by computing the Jacobian matrix, $J$:\n$$\nJ(x_1, x_2) = \\begin{pmatrix} \\frac{\\partial \\dot{x}_1}{\\partial x_1} & \\frac{\\partial \\dot{x}_1}{\\partial x_2} \\\\ \\frac{\\partial \\dot{x}_2}{\\partial x_1} & \\frac{\\partial \\dot{x}_2}{\\partial x_2} \\end{pmatrix}\n$$\nThe partial derivatives are:\n$$\n\\frac{\\partial \\dot{x}_1}{\\partial x_1} = \\lambda - 3x_1^2 - x_2^2\n$$\n$$\n\\frac{\\partial \\dot{x}_1}{\\partial x_2} = -1 - 2x_1x_2\n$$\n$$\n\\frac{\\partial \\dot{x}_2}{\\partial x_1} = 1 - 2x_1x_2\n$$\n$$\n\\frac{\\partial \\dot{x}_2}{\\partial x_2} = \\lambda - x_1^2 - 3x_2^2\n$$\nEvaluating the Jacobian at the origin $(0,0)$:\n$$\nJ(0,0) = \\begin{pmatrix} \\lambda & -1 \\\\ 1 & \\lambda \\end{pmatrix}\n$$\nThe eigenvalues $\\sigma$ of this matrix are the roots of the characteristic equation $\\det(J(0,0) - \\sigma I) = 0$:\n$$\n(\\lambda - \\sigma)^2 - (1)(-1) = 0 \\implies (\\lambda - \\sigma)^2 = -1 \\implies \\lambda - \\sigma = \\pm i\n$$\nThe eigenvalues are $\\sigma_{1,2} = \\lambda \\pm i$.\n\nA Hopf bifurcation occurs when the real part of the complex conjugate eigenvalues crosses zero. Here, $\\text{Re}(\\sigma_{1,2})=\\lambda$. The bifurcation point is thus $\\lambda=0$. At this point, the eigenvalues are purely imaginary, $\\sigma_{1,2}=\\pm i$. The transversality condition is met, as $\\frac{d}{d\\lambda}(\\text{Re}(\\sigma))|_{\\lambda=0} = 1 \\neq 0$.\n\nTo determine the nature of the bifurcation and find the first Lyapunov coefficient, we transform the system into polar coordinates, as instructed. Let $x_1 = r\\cos\\theta$ and $x_2 = r\\sin\\theta$. The radial coordinate is $r^2 = x_1^2 + x_2^2$. Differentiating this with respect to time $t$ gives:\n$$\n2r\\dot{r} = 2x_1\\dot{x}_1 + 2x_2\\dot{x}_2 \\implies \\dot{r} = \\frac{x_1\\dot{x}_1 + x_2\\dot{x}_2}{r}\n$$\nWe substitute the given ODEs into this expression. Note that the nonlinear terms in the original equations can be written in terms of $r$:\n$$\n\\dot{x}_{1}=\\lambda x_{1}-x_{2}-x_{1}r^2\n$$\n$$\n\\dot{x}_{2}=x_{1}+\\lambda x_{2}-x_{2}r^2\n$$\nNow, we compute the numerator for the $\\dot{r}$ equation:\n$$\nx_1\\dot{x}_1 + x_2\\dot{x}_2 = x_1(\\lambda x_1 - x_2 - x_1 r^2) + x_2(x_1 + \\lambda x_2 - x_2 r^2)\n$$\n$$\n= \\lambda x_1^2 - x_1x_2 - x_1^2 r^2 + x_1x_2 + \\lambda x_2^2 - x_2^2 r^2\n$$\nThe cross-terms $-x_1x_2$ and $+x_1x_2$ cancel. We group the remaining terms:\n$$\n= \\lambda(x_1^2 + x_2^2) - (x_1^2 + x_2^2)r^2\n$$\nSubstituting $x_1^2 + x_2^2 = r^2$:\n$$\n= \\lambda r^2 - r^2 \\cdot r^2 = \\lambda r^2 - r^4\n$$\nFinally, we find the equation for $\\dot{r}$:\n$$\n\\dot{r} = \\frac{\\lambda r^2 - r^4}{r} = \\lambda r - r^3\n$$\nThis equation is the exact amplitude dynamics. It contains no higher-order terms in $r$. The problem defines the first Lyapunov coefficient, $l_1$, via the form $\\dot{r}=\\mu r + l_1 r^3 + \\dots$, where $\\mu$ is identified with the bifurcation parameter $\\lambda$.\n\nComparing our derived equation, $\\dot{r} = \\lambda r - r^3$, with the definitional form, we can directly identify the coefficients:\n- The coefficient of the linear term in $r$ is $\\lambda$, so $\\mu = \\lambda$.\n- The coefficient of the cubic term, $r^3$, is $-1$.\n\nTherefore, the first Lyapunov coefficient is $l_1 = -1$. The negative sign of $l_1$ indicates that the Hopf bifurcation is supercritical, leading to the birth of a stable limit cycle for $\\lambda > 0$. However, the problem only asks for the value of $l_1$.", "answer": "$$\\boxed{-1}$$", "id": "2704876"}]}