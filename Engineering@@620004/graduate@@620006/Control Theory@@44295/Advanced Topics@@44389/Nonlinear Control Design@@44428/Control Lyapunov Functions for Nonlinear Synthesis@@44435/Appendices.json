{"hands_on_practices": [{"introduction": "One of the most powerful applications of Control Lyapunov Function (CLF) principles is to synthesize controllers that reshape a complex nonlinear system's behavior into that of a simpler, desired one. This exercise provides hands-on practice with this core idea, often known as feedback linearization, in the context of a trajectory tracking problem. By calculating the control input that cancels the system's nonlinearities and imposes stable linear error dynamics, you will develop a foundational skill in nonlinear control synthesis [@problem_id:2695616].", "problem": "Consider the control-affine, second-order nonlinear system\n$$\n\\dot{x}_{1} = x_{2}, \\qquad \\dot{x}_{2} = -x_{1}^{3} - x_{2} + u,\n$$\nand the tracking objective of following the sinusoidal reference\n$$\nr(t) = \\sin(2 t),\n$$\nwhere angles are in radians. Define the tracking error as\n$$\ne_{1} := x_{1} - r(t), \\qquad e_{2} := x_{2} - \\dot{r}(t).\n$$\nUsing the definition of a Control Lyapunov Function (CLF), where a CLF is any continuously differentiable, positive definite function whose time derivative along the closed-loop trajectories is negative definite, synthesize a smooth, time-varying state-feedback controller that guarantees global exponential convergence of the tracking error for the above system. Your design must proceed from first principles: explicitly form the error dynamics, impose a Hurwitz linear error model, and justify the CLF decrease via a symmetric positive definite matrix solution to a Lyapunov equation.\n\nLet the desired linear error dynamics be given by\n$$\n\\dot{e}_{1} = e_{2}, \\qquad \\dot{e}_{2} = -3 e_{1} - 4 e_{2},\n$$\nso that the closed-loop error matrix is Hurwitz. Compute the corresponding CLF-based input $u(x,t)$ for the given nonlinear plant and reference $r(t)$, as an explicit expression in terms of $x_{1}$, $x_{2}$, and $t$. Provide the exact, simplified analytic expression for $u(x,t)$ as your final answer. No numerical rounding is required, and no physical units are involved.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- **System Dynamics:**\n$$\n\\dot{x}_{1} = x_{2}, \\qquad \\dot{x}_{2} = -x_{1}^{3} - x_{2} + u\n$$\n- **Reference Signal:**\n$$\nr(t) = \\sin(2 t)\n$$\n- **Tracking Error Definition:**\n$$\ne_{1} := x_{1} - r(t), \\qquad e_{2} := x_{2} - \\dot{r}(t)\n$$\n- **Desired Linear Error Dynamics:**\n$$\n\\dot{e}_{1} = e_{2}, \\qquad \\dot{e}_{2} = -3 e_{1} - 4 e_{2}\n$$\n- **Objective:** Compute the control input $u(x,t)$ that achieves these error dynamics. The synthesis must be justified using the concept of a Control Lyapunov Function (CLF).\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a standard exercise in nonlinear control theory, specifically concerning tracking control for a control-affine system using the method of feedback linearization. All provided information is scientifically sound, self-contained, and mathematically consistent. The system and reference are well-defined. The objective is clear. The problem is well-posed and allows for a unique solution for the control law $u(x, t)$. There are no contradictions, ambiguities, or violations of scientific principles.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be furnished.\n\n**Solution Derivation**\nThe objective is to synthesize a state-feedback control law $u(x,t)$ that forces the tracking error vector $e(t) = \\begin{pmatrix} e_{1}(t)  e_{2}(t) \\end{pmatrix}^T$ to converge to zero. The method employed is feedback linearization, where the nonlinear dynamics are canceled and replaced by a desired linear error dynamic.\n\nFirst, we compute the time derivatives of the reference signal $r(t)$:\n$$\nr(t) = \\sin(2 t)\n$$\n$$\n\\dot{r}(t) = \\frac{d}{dt} \\sin(2 t) = 2 \\cos(2 t)\n$$\n$$\n\\ddot{r}(t) = \\frac{d}{dt} \\left( 2 \\cos(2 t) \\right) = -4 \\sin(2 t)\n$$\n\nNext, we establish the error dynamics by differentiating the error variables $e_{1}$ and $e_{2}$ with respect to time:\n$$\n\\dot{e}_{1} = \\frac{d}{dt} (x_{1} - r(t)) = \\dot{x}_{1} - \\dot{r}(t)\n$$\nSubstituting the system dynamics $\\dot{x}_{1} = x_{2}$ gives:\n$$\n\\dot{e}_{1} = x_{2} - \\dot{r}(t)\n$$\nBy definition, $e_{2} = x_{2} - \\dot{r}(t)$, so we find:\n$$\n\\dot{e}_{1} = e_{2}\n$$\nThis result is consistent with the first equation of the desired linear error dynamics.\n\nNow, we differentiate the second error variable, $e_{2}$:\n$$\n\\dot{e}_{2} = \\frac{d}{dt} (x_{2} - \\dot{r}(t)) = \\dot{x}_{2} - \\ddot{r}(t)\n$$\nSubstituting the system dynamics for $\\dot{x}_{2}$ yields:\n$$\n\\dot{e}_{2} = (-x_{1}^{3} - x_{2} + u) - \\ddot{r}(t)\n$$\nThis is the actual dynamics for $\\dot{e}_{2}$, which contains the control input $u$. To achieve the tracking objective, we set this expression equal to the desired dynamics for $\\dot{e}_{2}$, which is given as $-3 e_{1} - 4 e_{2}$:\n$$\n-x_{1}^{3} - x_{2} + u - \\ddot{r}(t) = -3 e_{1} - 4 e_{2}\n$$\nWe can now solve for the control input $u$:\n$$\nu(x,t) = x_{1}^{3} + x_{2} + \\ddot{r}(t) - 3 e_{1} - 4 e_{2}\n$$\nThis is the general form of the control law. To obtain an explicit expression in terms of the state variables $x_1, x_2$ and time $t$, we substitute the definitions of $e_1$, $e_2$, and the expression for $\\ddot{r}(t)$:\n$$\nu(x_1, x_2, t) = x_{1}^{3} + x_{2} + (-4 \\sin(2 t)) - 3(x_{1} - r(t)) - 4(x_{2} - \\dot{r}(t))\n$$\n$$\nu(x_1, x_2, t) = x_{1}^{3} + x_{2} - 4 \\sin(2 t) - 3(x_{1} - \\sin(2 t)) - 4(x_{2} - 2 \\cos(2 t))\n$$\nDistributing the terms, we get:\n$$\nu(x_1, x_2, t) = x_{1}^{3} + x_{2} - 4 \\sin(2 t) - 3 x_{1} + 3 \\sin(2 t) - 4 x_{2} + 8 \\cos(2 t)\n$$\nFinally, we combine like terms to obtain the simplified expression for the control law:\n$$\nu(x_{1}, x_{2}, t) = x_{1}^{3} - 3 x_{1} - 3 x_{2} - \\sin(2 t) + 8 \\cos(2 t)\n$$\nThis is a smooth, time-varying state-feedback controller.\n\n**Justification via Control Lyapunov Function (CLF)**\nThe problem requires justification of the controller design via CLF principles. By construction, the control law $u(x,t)$ enforces the following linear, time-invariant error dynamics:\n$$\n\\dot{e} = A e, \\quad \\text{where} \\quad e = \\begin{pmatrix} e_{1} \\\\ e_{2} \\end{pmatrix}, \\quad A = \\begin{pmatrix} 0  1 \\\\ -3  -4 \\end{pmatrix}\n$$\nThe stability of the origin $e=0$ is determined by the eigenvalues of the matrix $A$. The characteristic equation is $\\det(A - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} -\\lambda  1 \\\\ -3  -4-\\lambda \\end{pmatrix} = (-\\lambda)(-4-\\lambda) - (1)(-3) = 4\\lambda + \\lambda^2 + 3 = 0\n$$\n$$\n\\lambda^2 + 4\\lambda + 3 = (\\lambda + 1)(\\lambda + 3) = 0\n$$\nThe eigenvalues are $\\lambda_{1} = -1$ and $\\lambda_{2} = -3$. Since both eigenvalues have negative real parts, the matrix $A$ is Hurwitz, and the error dynamics are globally exponentially stable.\n\nTo formalize this using a Lyapunov function, we consider a quadratic candidate $V(e) = e^T P e$, where $P$ is a symmetric positive definite matrix. For $V(e)$ to be a strict Lyapunov function, its time derivative along the trajectories of the system must be negative definite.\n$$\n\\dot{V}(e) = \\frac{d}{dt}(e^T P e) = \\dot{e}^T P e + e^T P \\dot{e} = (A e)^T P e + e^T P (A e) = e^T (A^T P + P A) e\n$$\nAccording to Lyapunov's theorem for linear systems, since $A$ is Hurwitz, for any symmetric positive definite matrix $Q$, there exists a unique symmetric positive definite matrix $P$ that solves the Lyapunov equation:\n$$\nA^T P + P A = -Q\n$$\nChoosing $Q=I$ (the identity matrix), we have $\\dot{V}(e) = -e^T Q e = -e^T I e = -e_{1}^{2} - e_{2}^{2}$. Since $P$ is positive definite, $V(e)$ is positive definite, and since $Q$ is positive definite, $\\dot{V}(e)$ is negative definite for all $e \\neq 0$.\n\nTherefore, $V(e)$ is a valid Lyapunov function that proves global exponential stability of the error dynamics. This same function $V(e(x,t))$ serves as a Control Lyapunov Function (CLF) for the original tracking problem. The control law $u$ was specifically designed to render $\\dot{V}$ negative definite. This fulfills the problem requirements.\nThe derived control input $u(x,t)$ ensures that the tracking error converges to zero globally and exponentially.", "answer": "$$\n\\boxed{x_{1}^{3} - 3 x_{1} - 3 x_{2} - \\sin(2 t) + 8 \\cos(2 t)}\n$$", "id": "2695616"}, {"introduction": "After designing a controller, a critical task is to determine its safe operating envelope, particularly when physical limitations like actuator saturation are present. This practice guides you through designing a stabilizing controller and then applying modern computational methods to find the largest region of guaranteed stability where input constraints are satisfied. You will connect the theoretical concept of a positively invariant set, certified by a CLF, with practical numerical verification techniques to quantify the system's region of attraction [@problem_id:2695596].", "problem": "Consider the control-affine nonlinear system in two dimensions given by the ordinary differential equation\n$$\\dot{x} = f(x) + g(x)\\,u(x), \\quad x \\in \\mathbb{R}^2,$$\nwith\n$$f(x) = \\begin{bmatrix} x_2 \\\\ -x_1 - x_1^3 - 0.5\\,x_2 \\end{bmatrix}, \\quad g(x) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},$$\nand a scalar input $u(x) \\in \\mathbb{R}$. Let the candidate Control Lyapunov Function (CLF) be the polynomial\n$$V(x) = x_1^2 + x_2^2.$$\nDefine the sublevel set\n$$\\Omega_c := \\{ x \\in \\mathbb{R}^2 \\mid V(x) \\le c \\}.$$\nThe goal is to ensure that $\\Omega_c$ is positively invariant under a CLF-based controller $u(x)$, and that the control input satisfies the polynomial input bound\n$$|u(x)| \\le u_{\\max}, \\quad u_{\\max} = 10,$$\nfor all $x \\in \\Omega_c$. Angles used in any parametrization should be in radians.\n\nStarting from the definitions of Lie derivatives and Control Lyapunov Functions, and only using foundational facts from nonlinear control and polynomial optimization, do the following:\n\n1) Derive the Lie derivatives $L_f V(x)$ and $L_g V(x)$, and design a smooth polynomial CLF-based feedback $u(x)$ such that the closed-loop derivative $\\dot{V}(x) = \\nabla V(x)^\\top \\left(f(x) + g(x) u(x)\\right)$ is negative semidefinite for all $x \\in \\mathbb{R}^2$. Justify why this property is sufficient for the positive invariance of $\\Omega_c$.\n\n2) Formulate a Sum-of-Squares (SOS) optimization to maximize $c$ subject to the existence of SOS multipliers ensuring the following sufficient conditions:\n   - Nonpositivity of $\\dot{V}(x)$ on the boundary $\\{x \\mid V(x) = c\\}$.\n   - Satisfaction of the input bound $|u(x)| \\le u_{\\max}$ inside $\\Omega_c$.\n   \n   Your SOS program should be written as a polynomial optimization with decision variables $c$ and polynomial SOS multipliers, using a standard Positivstellensatz-type certificate. The SOS constraints must be explicitly stated as polynomial identities in $x$ that are required to be SOS. Include a small positive scalar $\\varepsilon  0$ in your formulation where appropriate to avoid degeneracy.\n\n3) Because implementing a full semidefinite programming solver is out of scope for this exercise, you must also provide a numerical, sampling-based verifier for candidate values of $c$ that checks the two sufficient conditions:\n   - For all sampled points on the level set $\\{x \\mid V(x) = c\\}$, verify $\\dot{V}(x) \\le 0$ numerically.\n   - For all sampled points in $\\{x \\mid V(x) \\le c\\}$, verify $|u(x)| \\le u_{\\max}$ numerically.\n   \n   The sampling should include a uniform set of angles in $[0, 2\\pi)$ (in radians) to cover the boundary, and a polar grid over the interior of the disc $\\{x \\mid x_1^2 + x_2^2 \\le c\\}$, with sufficiently fine resolution to make a reliable determination.\n\nYour program should implement the controller you derived in part (1), evaluate the closed-loop derivative $\\dot{V}(x)$, and perform the sampling-based verification specified in part (3) for the following test suite of candidate values:\n- $c = 0.0$ (boundary case),\n- $c = 0.5$ (small set),\n- $c = 2.0$ (moderate set),\n- $c = 3.0$ (near the limit),\n- $c = 3.5$ (beyond the limit),\n- $c = 25.0$ (clearly infeasible for input bounds).\n\nFor each $c$ in the test suite, your program must output a boolean that is true if and only if both the invariance check and the input bound check pass, and false otherwise.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test suite. For example, an output with six boolean results must look like:\n\"[True,True,False,True,False,False]\".\nNo units are involved in the final numerical output. All internal angle computations, if any, must be carried out in radians.", "solution": "The problem presented is a well-posed exercise in nonlinear control theory, specifically concerning the design and verification of a Control Lyapunov Function (CLF)-based controller for a polynomial system. The system's dynamics, the proposed CLF, and the constraints are clearly defined and scientifically grounded. The tasks requested—analytical controller design, formulation of a Sum-of-Squares (SOS) optimization, and numerical verification—are standard procedures in this field. The problem is self-contained, consistent, and admits a unique, verifiable solution. We shall proceed with the derivation and implementation.\n\n### Part 1: Controller Design and Invariance Justification\n\nThe system dynamics are given by $\\dot{x} = f(x) + g(x)u(x)$, with state $x = [x_1, x_2]^\\top \\in \\mathbb{R}^2$. The vector fields are:\n$$\nf(x) = \\begin{bmatrix} x_2 \\\\ -x_1 - x_1^3 - 0.5x_2 \\end{bmatrix}, \\quad g(x) = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\n$$\nThe candidate Control Lyapunov Function is $V(x) = x_1^2 + x_2^2$. Our goal is to design a smooth polynomial controller $u(x)$ that renders the closed-loop time derivative of $V(x)$ negative semidefinite, i.e., $\\dot{V}(x) \\le 0$ for all $x \\in \\mathbb{R}^2$.\n\nThe time derivative of $V(x)$ along the system trajectories is given by $\\dot{V}(x) = \\nabla V(x)^\\top \\dot{x}$. This can be expressed using Lie derivatives:\n$$\n\\dot{V}(x) = L_f V(x) + L_g V(x) u(x)\n$$\nwhere $L_f V(x) = \\nabla V(x)^\\top f(x)$ and $L_g V(x) = \\nabla V(x)^\\top g(x)$.\n\nFirst, we compute the gradient of $V(x)$:\n$$\n\\nabla V(x) = \\begin{bmatrix} \\frac{\\partial V}{\\partial x_1} \\\\ \\frac{\\partial V}{\\partial x_2} \\end{bmatrix} = \\begin{bmatrix} 2x_1 \\\\ 2x_2 \\end{bmatrix}\n$$\nNext, we compute the Lie derivatives:\n$$\nL_f V(x) = [2x_1 \\quad 2x_2] \\begin{bmatrix} x_2 \\\\ -x_1 - x_1^3 - 0.5x_2 \\end{bmatrix} = 2x_1x_2 + 2x_2(-x_1 - x_1^3 - 0.5x_2) = -2x_1^3x_2 - x_2^2\n$$\n$$\nL_g V(x) = [2x_1 \\quad 2x_2] \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = 2x_2\n$$\nThe derivative $\\dot{V}(x)$ is therefore:\n$$\n\\dot{V}(x) = (-2x_1^3x_2 - x_2^2) + (2x_2)u(x)\n$$\nFor stabilization using a CLF, we must check if the system is controllable where needed. The CLF condition requires that for any state where $L_f V(x)  0$, we must have $L_g V(x) \\neq 0$. The problematic states are those where we lose control authority, i.e., $L_g V(x) = 0$. Here, this occurs when $2x_2=0$, or $x_2=0$. At these states, $L_f V(x) = -2x_1^3(0) - (0)^2 = 0$. Since $L_f V(x)$ is not strictly positive on the set where $L_g V(x) = 0$, the system is stabilizable with respect to $V(x)$.\n\nWe need to design a smooth polynomial controller $u(x)$ to ensure $\\dot{V}(x) \\le 0$. The term $-2x_1^3x_2$ in $L_f V(x)$ is sign-indefinite and must be handled by the controller. The most direct approach is to choose $u(x)$ to cancel this term. Let us design the controller as:\n$$\nu(x) = x_1^3\n$$\nThis controller is a smooth polynomial, as required. Substituting this into the expression for $\\dot{V}(x)$:\n$$\n\\dot{V}(x) = (-2x_1^3x_2 - x_2^2) + (2x_2)(x_1^3) = -x_2^2\n$$\nSince $-x_2^2 \\le 0$ for all $x \\in \\mathbb{R}^2$, this controller guarantees that $\\dot{V}(x)$ is negative semidefinite.\n\nThe positive invariance of a sublevel set $\\Omega_c = \\{x \\in \\mathbb{R}^2 \\mid V(x) \\le c\\}$ is a direct consequence of $\\dot{V}(x) \\le 0$. By definition, a set is positively invariant if any trajectory starting in the set remains in the set for all future time. If $x(0) \\in \\Omega_c$, then $V(x(0)) \\le c$. Since $\\frac{d}{dt}V(x(t)) = \\dot{V}(x(t)) \\le 0$, the function $V(x(t))$ is non-increasing along any trajectory. Therefore, $V(x(t)) \\le V(x(0)) \\le c$ for all $t \\ge 0$, which implies $x(t) \\in \\Omega_c$ for all $t \\ge 0$. This confirms that all sublevel sets $\\Omega_c$ are positively invariant under the action of the controller $u(x)=x_1^3$.\n\n### Part 2: Sum-of-Squares (SOS) Formulation\n\nWe are asked to formulate an SOS program to maximize $c$ such that two conditions hold:\n1. Nonpositivity of $\\dot{V}(x)$ on the boundary $\\{x \\mid V(x)=c\\}$.\n2. Satisfaction of the input bound $|u(x)| \\le u_{\\max}$ for all $x \\in \\Omega_c$.\n\nFor the controller $u(x) = x_1^3$, we have $\\dot{V}(x) = -x_2^2$. This is non-positive for all $x \\in \\mathbb{R}^2$, so it is certainly non-positive on the boundary $V(x)=c$ for any $c$. An SOS certificate for this condition is trivial. We need to certify that $-\\dot{V}(x) \\ge 0$ on $V(x)=c$. This is equivalent to certifying $x_2^2 \\ge 0$ on $V(x)=c$. As $x_2^2$ is itself an SOS polynomial, this condition is satisfied for any $c$ and imposes no constraint on the optimization.\n\nThe second condition is $|u(x)| \\le u_{\\max}$, where $u_{\\max}=10$. This is equivalent to $u_{\\max}^2 - u(x)^2 \\ge 0$. Substituting $u(x)=x_1^3$, we require $100 - x_1^6 \\ge 0$ for all $x$ in the set $\\Omega_c = \\{x \\mid V(x) \\le c\\}$, which is equivalent to $c-V(x) \\ge 0$.\n\nTo certify that a polynomial $p(x)$ is non-negative on a basic semialgebraic set $S = \\{x \\mid g_i(x) \\ge 0\\}$, we can use Putinar's Positivstellensatz. It states that if the set $S$ is compact, then a strictly positive polynomial $p(x)$ on $S$ can be written as $p(x) = s_0(x) + \\sum_i s_i(x)g_i(x)$, where $s_i(x)$ are SOS polynomials.\n\nWe want to certify that $p_2(x) = 100 - x_1^6 \\ge 0$ on the set defined by $p_1(x) = c - V(x) = c - x_1^2 - x_2^2 \\ge 0$. For robustness, we enforce a slightly stricter condition, $100 - x_1^6 - \\varepsilon \\ge 0$ for a small $\\varepsilon  0$.\n\nAccording to Putinar's Positivstellensatz, this condition holds if there exist SOS polynomials $s_0(x_1, x_2)$ and $s_1(x_1, x_2)$ such that the following polynomial identity is satisfied:\n$$\n(100 - x_1^6 - \\varepsilon) = s_0(x_1, x_2) + s_1(x_1, x_2)(c - x_1^2 - x_2^2)\n$$\nThe optimization problem is to find the maximum value of $c$ for which such SOS multipliers exist. The decision variables are the scalar $c$ and the coefficients of the polynomial multipliers $s_0$ and $s_1$.\n\nThe SOS optimization program is thus:\n$$\n\\begin{array}{ll}\n\\underset{c, s_0, s_1}{\\text{maximize}}  c \\\\\n\\text{subject to}  (100 - x_1^6 - \\varepsilon) - s_1(x_1, x_2)(c - x_1^2 - x_2^2) = s_0(x_1, x_2) \\\\\n c \\ge 0 \\\\\n s_0(x_1, x_2) \\in \\Sigma[x_1, x_2] \\\\\n s_1(x_1, x_2) \\in \\Sigma[x_1, x_2]\n\\end{array}\n$$\nwhere $\\Sigma[x_1, x_2]$ denotes the cone of SOS polynomials in variables $x_1, x_2$.\n\n### Part 3: Numerical Verification\nWe implement a numerical verification procedure for a given candidate $c$. For the controller $u(x) = x_1^3$, we check two conditions by sampling the state space.\n\n1.  **Invariance Check**: We must verify $\\dot{V}(x) \\le 0$ on the boundary $V(x)=c$. We sample points on this circle using the parametrization $x_1 = \\sqrt{c}\\cos(\\theta)$, $x_2 = \\sqrt{c}\\sin(\\theta)$ for $\\theta \\in [0, 2\\pi)$. For each point, we check if $\\dot{V}(x) = -x_2^2 \\le 0$. This is analytically true, but the procedure mandates a numerical check.\n\n2.  **Input Bound Check**: We must verify $|u(x)| \\le u_{\\max}$ for all $x$ in the disk $V(x) \\le c$. We sample points on a polar grid: $x_1 = r\\cos(\\theta)$, $x_2 = r\\sin(\\theta)$ for $r \\in [0, \\sqrt{c}]$ and $\\theta \\in [0, 2\\pi)$. For each sampled point, we compute $u(x) = x_1^3$ and check if $|u(x)| \\le 10$. The maximum value of $|u(x)| = |x_1^3|$ on the disk occurs where $|x_1|$ is maximal, i.e., at $x_1 = \\pm\\sqrt{c}$ and $x_2=0$. This leads to the analytical condition $|(\\sqrt{c})^3| \\le 10$, or $c^{3/2} \\le 10$, which simplifies to $c^3 \\le 100$, so $c \\le \\sqrt[3]{100} \\approx 4.6416$. The numerical check will approximate this result.\n\nThe code will iterate through the provided test suite of $c$ values and apply these two checks. A given $c$ is valid if and only if both checks pass for all sampled points.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the nonlinear control problem by designing a controller and\n    numerically verifying the properties for a set of candidate regions.\n    \"\"\"\n    \n    # Test suite of candidate values for c\n    test_cases = [0.0, 0.5, 2.0, 3.0, 3.5, 25.0]\n    \n    # Control input bound\n    u_max = 10.0\n    \n    # Numerical tolerance for floating point comparisons\n    tolerance = 1e-9\n    \n    # Sampling resolution\n    num_angles_boundary = 200\n    num_angles_interior = 100\n    num_radii_interior = 50\n    \n    results = []\n\n    # Controller derived in Part 1\n    def u(x1, x2):\n        return x1**3\n\n    # Closed-loop derivative of V(x) derived in Part 1\n    def v_dot(x1, x2):\n        # With u(x) = x1**3, V_dot simplifies to -x2**2\n        return -x2**2\n        \n    for c in test_cases:\n        is_c_valid = True\n        \n        # Handle the trivial case c=0.0\n        if c  tolerance:\n            # At x=(0,0), V_dot=0 and u=0. Both conditions are met.\n            results.append(True)\n            continue\n        \n        radius_c = np.sqrt(c)\n\n        # --- 1. Invariance Check on the boundary {x | V(x) = c} ---\n        thetas_boundary = np.linspace(0, 2 * np.pi, num_angles_boundary, endpoint=False)\n        for theta in thetas_boundary:\n            x1_b = radius_c * np.cos(theta)\n            x2_b = radius_c * np.sin(theta)\n            \n            # Check if V_dot is non-positive\n            if v_dot(x1_b, x2_b)  tolerance:\n                is_c_valid = False\n                break\n        \n        if not is_c_valid:\n            results.append(False)\n            continue\n            \n        # --- 2. Input Bound Check in the sublevel set {x | V(x) = c} ---\n        radii_interior = np.linspace(0, radius_c, num_radii_interior)\n        thetas_interior = np.linspace(0, 2 * np.pi, num_angles_interior, endpoint=False)\n        \n        for r in radii_interior:\n            for theta in thetas_interior:\n                x1_i = r * np.cos(theta)\n                x2_i = r * np.sin(theta)\n                \n                control_input = u(x1_i, x2_i)\n                \n                # Check if the absolute value of the control input exceeds the maximum\n                if np.abs(control_input)  u_max + tolerance:\n                    is_c_valid = False\n                    break\n            if not is_c_valid:\n                break\n                \n        results.append(is_c_valid)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2695596"}, {"introduction": "Does the existence of a Control Lyapunov Function always guarantee that we can find a well-behaved, continuous feedback law to stabilize a system? This exercise delves into this subtle but critical question by presenting a carefully constructed counterexample. By analyzing the control effort required to stabilize the system near its equilibrium, you will discover the importance of the Small Control Property (SCP) and understand why its failure can prevent the existence of any continuous stabilizing controller, even when a CLF is readily available [@problem_id:2695614].", "problem": "Consider the scalar control-affine nonlinear system given by\n$$\\dot{x} = f(x) + g(x) u,$$\nwith\n$$f(x) = x \\quad \\text{and} \\quad g(x) = x^{2},$$\nand candidate Control Lyapunov Function (CLF) $V(x) = \\tfrac{1}{2} x^{2}$. Start from the core definitions in control theory: a Control Lyapunov Function (CLF) is a positive definite and proper function $V$ such that for every $x \\neq 0$ there exists a control input $u \\in \\mathbb{R}$ making $\\dot{V}(x,u)  0$. The small control property (SCP) requires that for any $\\varepsilon  0$ there exists $\\delta  0$ such that for all $x$ with $0  |x|  \\delta$ there exists a control $u$ with $|u|  \\varepsilon$ rendering $\\dot{V}(x,u)  0$. Use only these fundamental definitions and standard calculus facts.\n\nTasks:\n- Using first principles, verify that $V(x)$ is a CLF for the given system by explicitly exhibiting, for each $x \\neq 0$, a control $u$ that yields $\\dot{V}(x,u)  0$.\n- Fix any $\\alpha \\in (0,1)$ and define the minimal control magnitude function $m(x)$ as the smallest $|u|$ such that\n$$\\dot{V}(x,u) \\leq -\\alpha x^{2} \\quad \\text{for a given} \\quad x \\neq 0.$$\nDerive an exact closed-form expression for $m(x)$ in terms of $x$ and $\\alpha$.\n- Compute the limit\n$$L(\\alpha) = \\lim_{x \\to 0} \\, |x| \\, m(x).$$\n- Briefly explain the implication of your result for the small control property (SCP) at the origin and the existence of a continuous stabilizing state feedback, using only standard definitions and well-known theorems connecting CLFs, the SCP, and continuous stabilizers.\n\nAnswer specification:\nProvide, as your final answer, the exact closed-form expression for $L(\\alpha)$ as a function of $\\alpha$. No rounding is required, and no physical units are involved. The final answer must be a single analytic expression.", "solution": "The problem will be analyzed and solved in a sequential, deductive manner, adhering strictly to the provided definitions and first principles.\n\nFirst, we must validate the problem statement. The problem provides a scalar nonlinear control system, a candidate Control Lyapunov Function (CLF), and a set of tasks involving analysis based on fundamental control theory definitions.\nThe givens are:\n- System dynamics: $\\dot{x} = f(x) + g(x) u$, where $x \\in \\mathbb{R}$ is the state and $u \\in \\mathbb{R}$ is the control input.\n- System functions: $f(x) = x$ and $g(x) = x^{2}$.\n- Candidate CLF: $V(x) = \\frac{1}{2} x^{2}$.\n- CLF definition: $V$ is a positive definite and proper function such that for every $x \\neq 0$, there exists a control $u$ making $\\dot{V}(x,u)  0$.\n- Small control property (SCP) definition: For any $\\varepsilon  0$, there exists $\\delta  0$ such that for all $x$ with $0  |x|  \\delta$, there is a control $u$ with $|u|  \\varepsilon$ for which $\\dot{V}(x,u)  0$.\n- Minimal control magnitude $m(x)$: The smallest $|u|$ such that $\\dot{V}(x,u) \\leq -\\alpha x^{2}$ for a given $x \\neq 0$ and a fixed constant $\\alpha \\in (0,1)$.\n- Limit to compute: $L(\\alpha) = \\lim_{x \\to 0} \\, |x| \\, m(x)$.\n\nThe problem is scientifically grounded in the field of nonlinear control theory, is well-posed with all necessary information provided, and is formulated using objective, unambiguous mathematical language. The statements do not violate any scientific principles, are not contradictory, and the tasks are logically structured. Therefore, the problem is deemed valid and a formal solution can be constructed.\n\nThe first task is to verify that $V(x) = \\frac{1}{2} x^{2}$ is a CLF for the system $\\dot{x} = x + x^{2} u$.\nThe function $V(x)$ is positive definite as $V(x)  0$ for all $x \\neq 0$ and $V(0) = 0$. It is also proper (radially unbounded) as $V(x) \\to \\infty$ as $|x| \\to \\infty$. We must now analyze its time derivative, $\\dot{V}$, along the system trajectories.\nUsing the chain rule, the time derivative of $V(x)$ is:\n$$ \\dot{V}(x,u) = \\frac{\\partial V}{\\partial x} \\dot{x} = \\frac{\\partial}{\\partial x} \\left(\\frac{1}{2} x^{2}\\right) (f(x) + g(x) u) $$\nSubstituting the given functions:\n$$ \\dot{V}(x,u) = x (x + x^{2} u) = x^{2} + x^{3} u $$\nIn the language of Lie derivatives, this is $\\dot{V} = L_f V + (L_g V) u$, where $L_f V = \\frac{\\partial V}{\\partial x} f(x) = x \\cdot x = x^{2}$ and $L_g V = \\frac{\\partial V}{\\partial x} g(x) = x \\cdot x^{2} = x^{3}$.\nFor $V(x)$ to be a CLF, for any state $x \\neq 0$, we must be able to find a control $u$ such that $\\dot{V}(x,u)  0$. The condition is:\n$$ x^{2} + x^{3} u  0 $$\nFor any $x \\neq 0$, the term $L_g V = x^{3}$ is non-zero. This is the crucial property that guarantees control authority. We can thus solve for $u$:\n$$ x^{3} u  -x^{2} $$\nIf $x  0$, then $x^{3}  0$, and the inequality becomes $u  -\\frac{x^{2}}{x^{3}} = -\\frac{1}{x}$. For example, one can choose $u = -\\frac{2}{x}$. This gives $\\dot{V} = x^2 + x^3(-\\frac{2}{x}) = x^2 - 2x^2 = -x^2  0$.\nIf $x  0$, then $x^{3}  0$, and dividing by a negative number reverses the inequality: $u  -\\frac{x^{2}}{x^{3}} = -\\frac{1}{x}$. For example, choosing $u = -\\frac{2}{x}$ still works. Since $x0$, $-\\frac{2}{x}0$ and $-\\frac{1}{x}0$. The condition $u  -\\frac{1}{x}$ is satisfied because $-\\frac{2}{x}  -\\frac{1}{x}$ for $x0$. The derivative is again $\\dot{V} = -x^2  0$.\nSince for any $x \\neq 0$ we can explicitly find a control $u$ that makes $\\dot{V}$ negative, the function $V(x) = \\frac{1}{2} x^{2}$ is a valid CLF for the given system.\n\nThe second task is to derive the minimal control magnitude $m(x)$ that satisfies the condition $\\dot{V}(x,u) \\leq -\\alpha x^{2}$ for a fixed $\\alpha \\in (0,1)$ and a given $x \\neq 0$.\nThe inequality is:\n$$ x^{2} + x^{3} u \\leq -\\alpha x^{2} $$\nRearranging the terms, we get:\n$$ x^{3} u \\leq -x^{2} - \\alpha x^{2} = -(1+\\alpha) x^{2} $$\nWe must find the control $u$ that satisfies this inequality and has the minimum possible absolute value, $|u|$.\nCase 1: $x  0$. Then $x^{3}  0$. The inequality is:\n$$ u \\leq -\\frac{(1+\\alpha)x^{2}}{x^{3}} = -\\frac{1+\\alpha}{x} $$\nThe set of admissible controls is $u \\in (-\\infty, -\\frac{1+\\alpha}{x}]$. Since $x  0$ and $1+\\alpha  0$, the upper bound $-\\frac{1+\\alpha}{x}$ is negative. The absolute value $|u|$ is minimized at the boundary of this set, where $u$ is closest to zero. Thus, the minimum $|u|$ is $|-\\frac{1+\\alpha}{x}| = \\frac{1+\\alpha}{x}$.\nCase 2: $x  0$. Then $x^{3}  0$. Dividing by $x^3$ reverses the inequality:\n$$ u \\geq -\\frac{(1+\\alpha)x^{2}}{x^{3}} = -\\frac{1+\\alpha}{x} $$\nThe set of admissible controls is $u \\in [-\\frac{1+\\alpha}{x}, \\infty)$. Since $x  0$ and $1+\\alpha  0$, the lower bound $-\\frac{1+\\alpha}{x}$ is positive. The absolute value $|u|$ is minimized at this lower bound. The minimum $|u|$ is $|-\\frac{1+\\alpha}{x}| = -\\frac{1+\\alpha}{x}$.\nCombining both cases, we can express the minimal control magnitude as a single function of $x$:\n$$ m(x) = \\begin{cases} \\frac{1+\\alpha}{x}  \\text{if } x0 \\\\ -\\frac{1+\\alpha}{x}  \\text{if } x0 \\end{cases} $$\nThis is equivalent to the compact expression:\n$$ m(x) = \\frac{1+\\alpha}{|x|} $$\n\nThe third task is to compute the limit $L(\\alpha) = \\lim_{x \\to 0} \\, |x| \\, m(x)$.\nSubstituting the derived expression for $m(x)$:\n$$ L(\\alpha) = \\lim_{x \\to 0} \\, |x| \\left(\\frac{1+\\alpha}{|x|}\\right) $$\nFor any $x \\neq 0$, the term $|x|$ in the numerator and denominator cancels.\n$$ L(\\alpha) = \\lim_{x \\to 0} (1+\\alpha) $$\nThe expression $(1+\\alpha)$ is a constant with respect to $x$. Therefore, the limit is simply:\n$$ L(\\alpha) = 1+\\alpha $$\n\nThe final task is to explain the implication of this result for the small control property (SCP) and the existence of a continuous stabilizing feedback.\nThe minimal control magnitude required to achieve a specified rate of decay, $m(x)$, behaves as $\\frac{1+\\alpha}{|x|}$ as $x$ approaches $0$. This means $m(x) \\to \\infty$ as $x \\to 0$. The control effort required to stabilize the system blows up near the origin.\nThe SCP requires that for any arbitrarily small control bound $\\varepsilon  0$, there exists a neighborhood of the origin (defined by $\\delta  0$) where a stabilizing control $u$ with $|u|  \\varepsilon$ can be found.\nOur analysis of the minimal control needed to just make $\\dot{V}  0$ showed that one must have $|u|  \\frac{1}{|x|}$. To find a control $|u|  \\varepsilon$, it is necessary that $\\frac{1}{|x|}  \\varepsilon$, which implies $|x|  \\frac{1}{\\varepsilon}$. This condition cannot hold for all $x$ in a neighborhood $0  |x|  \\delta$, because any such neighborhood contains points with $|x|$ arbitrarily close to $0$. Thus, for any given $\\varepsilon$, we cannot find a suitable $\\delta$. The small control property is violated at the origin.\nA cornerstone theorem by Sontag states that a system is asymptotically stabilizable by a continuous state feedback law $u=k(x)$ (with $k(0)=0$) if and only if there exists a smooth CLF that satisfies the SCP.\nSince our CLF—and indeed any CLF for this system—fails to satisfy the SCP at the origin, we conclude that no continuous feedback law can asymptotically stabilize the origin of this system. This is a manifestation of a more general principle, often related to Brockett's necessary condition for continuous stabilization, which is violated here because the control vector field $g(x)=x^2$ vanishes faster than the drift vector field $f(x)=x$ at the origin, thereby providing insufficient control authority. The non-zero value of $L(\\alpha)$ is a quantitative indicator of this failure.", "answer": "$$ \\boxed{1+\\alpha} $$", "id": "2695614"}]}