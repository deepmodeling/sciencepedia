{"hands_on_practices": [{"introduction": "The initial step in a recursive backstepping design, the choice of the first virtual control $\\alpha_1(x_1)$, is pivotal as it influences the entire recursive procedure. This exercise explores a unique scenario where the system's structure, governed by a parameter $\\beta$, allows for a particularly simple virtual control law. By working backward from desired properties—specifically, an additively separable composite Lyapunov function and a simplified final controller—you will uncover a deep connection between the system's inherent dynamics and the possibilities of the control design [@problem_id:1088218].", "problem": "Consider a second-order nonlinear system in strict-feedback form given by the differential equations:\n$$\n\\begin{aligned}\n\\dot{x}_1 &= -x_1^3 + x_1^2 x_2 \\\\\n\\dot{x}_2 &= \\beta x_1^3 + \\cos(x_2) + u\n\\end{aligned}\n$$\nwhere $u$ is the control input and $\\beta$ is a real constant. The objective is to design a stabilizing control law $u$ for the origin $(x_1, x_2) = (0,0)$ using the recursive backstepping method.\n\nThe backstepping design procedure proceeds as follows:\n1.  Consider the $x_1$-subsystem. A Lyapunov function candidate $V_1(x_1)$ is chosen, and a \"virtual control\" law $\\alpha_1(x_1)$ for the state $x_2$ is designed to stabilize this subsystem. For this problem, use the candidate Lyapunov function $V_1(x_1) = \\frac{1}{2}x_1^2$.\n2.  A change of coordinates is defined with an error variable $z_2 = x_2 - \\alpha_1(x_1)$.\n3.  A composite Lyapunov function for the full system is constructed as $V(x_1, z_2) = V_1(x_1) + \\frac{1}{2}z_2^2$.\n4.  The control law $u$ is designed to make the time derivative of $V(x_1, z_2)$ negative definite.\n\nThe structure of the resulting composite Lyapunov function in the original coordinates, $V(x_1, x_2) = V_1(x_1) + \\frac{1}{2}(x_2 - \\alpha_1(x_1))^2$, is generally not additively separable, i.e., it cannot be written as a sum of a function of $x_1$ and a function of $x_2$. For this to be the case, the virtual control $\\alpha_1(x_1)$ must be identically zero.\n\nFind the unique value of the parameter $\\beta$ for which both of the following conditions are met:\na) The composite Lyapunov function $V(x_1, x_2)$ is additively separable.\nb) The resulting stabilizing control law $u(x_1, x_2)$ is a function of $x_2$ only.", "solution": "The problem asks for the value of a parameter $\\beta$ in a nonlinear system such that a backstepping control design results in an additively separable composite Lyapunov function and a controller that is a function of only one state variable.\n\n**Step 1: Analyze the condition for additive separability**\n\nThe backstepping procedure constructs a composite Lyapunov function of the form $V(x_1, x_2) = V_1(x_1) + \\frac{1}{2}(x_2 - \\alpha_1(x_1))^2$. For this problem, $V_1(x_1) = \\frac{1}{2}x_1^2$, so\n$$\nV(x_1, x_2) = \\frac{1}{2}x_1^2 + \\frac{1}{2}(x_2 - \\alpha_1(x_1))^2 = \\frac{1}{2}x_1^2 + \\frac{1}{2}x_2^2 - x_2 \\alpha_1(x_1) + \\frac{1}{2}\\alpha_1(x_1)^2\n$$\nFor $V(x_1, x_2)$ to be additively separable, it must be of the form $A(x_1) + B(x_2)$. This requires the cross-term $-x_2 \\alpha_1(x_1)$ to vanish for all $x_1$ and $x_2$. This can only be true if $\\alpha_1(x_1) \\equiv 0$.\nSo, the first condition (additive separability) imposes the constraint that the virtual control must be zero.\n\n**Step 2: Determine the virtual control $\\alpha_1(x_1)$ and check for validity**\n\nLet's design the virtual control for the $x_1$-subsystem, $\\dot{x}_1 = -x_1^3 + x_1^2 x_2$, using the given Lyapunov candidate $V_1(x_1) = \\frac{1}{2}x_1^2$.\nThe time derivative of $V_1$ along the trajectories of the subsystem is:\n$$\n\\dot{V}_1 = \\frac{\\partial V_1}{\\partial x_1} \\dot{x}_1 = x_1(-x_1^3 + x_1^2 x_2) = -x_1^4 + x_1^3 x_2\n$$\nIn backstepping, we treat $x_2$ as a virtual control. We define a desired virtual control law $x_{2,d} = \\alpha_1(x_1)$ such that if $x_2 = \\alpha_1(x_1)$, the resulting dynamics make $\\dot{V}_1$ negative definite. The typical choice is to make $\\dot{V}_1$ equal to a desired negative definite function, e.g., $-c_1 x_1^4$ for some constant $c_1 > 0$.\n$$\n-x_1^4 + x_1^3 \\alpha_1(x_1) = -c_1 x_1^4\n$$\nFrom the separability condition, we must have $\\alpha_1(x_1) = 0$. Let's check if this choice is valid. If we set $\\alpha_1(x_1) = 0$, the expression for the stabilized part of the derivative becomes:\n$$\n\\dot{V}_1 = -x_1^4 + x_1^3 (0) = -x_1^4\n$$\nSince $-x_1^4$ is negative definite (for $x_1 \\neq 0$), the choice $\\alpha_1(x_1) = 0$ is a valid virtual control law that stabilizes the $x_1$-subsystem (by rendering its part of the Lyapunov derivative negative definite). This corresponds to choosing $c_1=1$.\n\n**Step 3: Design the control law $u$**\n\nWith $\\alpha_1(x_1) = 0$, the error variable is $z_2 = x_2 - 0 = x_2$.\nThe composite Lyapunov function is $V(x_1, x_2) = \\frac{1}{2}x_1^2 + \\frac{1}{2}x_2^2$, which is additively separable as required.\nNow, we compute the time derivative of $V$ along the trajectories of the full system:\n$$\n\\dot{V} = \\frac{\\partial V}{\\partial x_1}\\dot{x}_1 + \\frac{\\partial V}{\\partial x_2}\\dot{x}_2 = x_1 \\dot{x}_1 + x_2 \\dot{x}_2\n$$\nSubstitute the system dynamics:\n$$\n\\dot{V} = x_1(-x_1^3 + x_1^2 x_2) + x_2(\\beta x_1^3 + \\cos(x_2) + u)\n$$\n$$\n\\dot{V} = -x_1^4 + x_1^3 x_2 + \\beta x_1^3 x_2 + x_2 \\cos(x_2) + x_2 u\n$$\nGroup the terms:\n$$\n\\dot{V} = -x_1^4 + (1+\\beta)x_1^3 x_2 + x_2 \\cos(x_2) + x_2 u\n$$\nTo make $\\dot{V}$ negative definite, we must choose the control law $u$ to cancel the terms that are not negative definite, i.e., the cross-term $(1+\\beta)x_1^3 x_2$ and the term $x_2 \\cos(x_2)$. We also add a stabilizing term $-c_2 x_2^2$ where $c_2 > 0$ is a design parameter.\nA suitable control law is:\n$$\nx_2 u = -(1+\\beta)x_1^3 x_2 - x_2 \\cos(x_2) - c_2 x_2^2\n$$\nAssuming $x_2 \\neq 0$, we can write:\n$$\nu(x_1, x_2) = -(1+\\beta)x_1^3 - \\cos(x_2) - c_2 x_2\n$$\nWith this control law, the derivative of the Lyapunov function becomes:\n$$\n\\dot{V} = -x_1^4 - c_2 x_2^2\n$$\nwhich is negative definite for all $(x_1, x_2) \\neq (0,0)$. This confirms that the choice of $u$ does stabilize the system.\n\n**Step 4: Apply the condition on the control law $u$**\n\nThe second condition of the problem is that the control law $u(x_1, x_2)$ must be a function of $x_2$ only. Let's examine our derived controller:\n$$\nu(x_1, x_2) = -(1+\\beta)x_1^3 - \\cos(x_2) - c_2 x_2\n$$\nFor this expression to be independent of $x_1$, the term containing $x_1$ must be identically zero for all $x_1$.\n$$\n-(1+\\beta)x_1^3 = 0\n$$\nSince this must hold for any $x_1$, the coefficient must be zero:\n$$\n-(1+\\beta) = 0\n$$\nSolving for $\\beta$ gives:\n$$\n\\beta = -1\n$$\nThis is the unique value of $\\beta$ that satisfies both conditions of the problem.", "answer": "$$\n\\boxed{-1}\n$$", "id": "1088218"}, {"introduction": "While backstepping is prototypically applied to systems in strict-feedback form, its applicability extends to a broader class of systems. This problem challenges you to analyze a system in \"pure-feedback\" form, where the fundamental requirement is not a linear-in-the-next-state structure but the local invertibility of the virtual control path. By using core tools from nonlinear control theory, such as Lie derivatives and relative degree, you will determine not only if the backstepping recursion can be initiated but also where the resulting control law might face singularities [@problem_id:2689617].", "problem": "Consider the nonlinear control-affine system with state $x = (x_1, x_2) \\in \\mathbb{R}^2$ and input $u \\in \\mathbb{R}$:\n$$\n\\dot{x}_1 = x_1 + x_2^3, \\qquad \\dot{x}_2 = -x_2 + \\cos(x_1) + u,\n$$\nand suppose one wishes to initiate a backstepping design using the measured output $y = x_1$ as the primary regulated variable.\n\nUsing only fundamental definitions from nonlinear control (Lie derivatives, relative degree, and the strict-feedback form underpinning backstepping), rigorously verify the relative degree of the input-output pair $(u,y)$ at each step starting from $y = x_1$ and determine the largest subset of $\\mathbb{R}^2$ on which a well-defined relative degree exists. Explain, from first principles, whether and why the backstepping recursion can or cannot be initiated from the $x_1$-subsystem in this system, paying particular attention to the structural requirements of strict-feedback systems and to the nondegeneracy of the decoupling term.\n\nYour answer must culminate in the exact analytic expression of the decoupling term that multiplies $u$ in the first output derivative at which $u$ appears when differentiating $y = x_1$ along the system dynamics. Provide that expression as your final answer. No numerical approximation is required, and no units are involved.", "solution": "The system is given by the state equations:\n$$\n\\dot{x}_1 = x_1 + x_2^3\n$$\n$$\n\\dot{x}_2 = -x_2 + \\cos(x_1) + u\n$$\nThis is a control-affine system of the form $\\dot{x} = f(x) + g(x)u$, where the state is $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$, and the vector fields $f(x)$ and $g(x)$ are:\n$$\nf(x) = \\begin{pmatrix} x_1 + x_2^3 \\\\ -x_2 + \\cos(x_1) \\end{pmatrix}, \\quad g(x) = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nThe output is defined as $y = h(x) = x_1$.\n\nTo determine the relative degree of the input-output pair $(u, y)$, we must differentiate the output $y$ with respect to time until the input $u$ explicitly appears. This process is formalized using Lie derivatives. The Lie derivative of a scalar function $h(x)$ along a vector field $f(x)$ is $L_f h(x) = \\frac{\\partial h}{\\partial x} f(x)$.\n\nFirst, we compute the first time derivative of the output $y$:\n$$\n\\dot{y} = \\frac{dh}{dt} = \\frac{\\partial h}{\\partial x} \\dot{x} = \\frac{\\partial h}{\\partial x} (f(x) + g(x)u) = L_f h(x) + L_g h(x) u\n$$\nWe calculate the components $L_f h(x)$ and $L_g h(x)$. The gradient of $h(x)=x_1$ is $\\frac{\\partial h}{\\partial x} = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$.\n\nThe term $L_g h(x)$ is:\n$$\nL_g h(x) = \\frac{\\partial h}{\\partial x} g(x) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 0\n$$\nSince $L_g h(x) = 0$, the input $u$ does not appear in the first derivative of $y$. This signifies that the relative degree $r$ must be greater than $1$. The expression for $\\dot{y}$ is:\n$$\n\\dot{y} = L_f h(x) = \\frac{\\partial h}{\\partial x} f(x) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} x_1 + x_2^3 \\\\ -x_2 + \\cos(x_1) \\end{pmatrix} = x_1 + x_2^3\n$$\nNow, we compute the second time derivative of the output, $\\ddot{y}$:\n$$\n\\ddot{y} = \\frac{d}{dt} (L_f h(x)) = \\frac{\\partial (L_f h(x))}{\\partial x} \\dot{x} = \\frac{\\partial (L_f h(x))}{\\partial x} (f(x) + g(x)u) = L_f^2 h(x) + L_g L_f h(x) u\n$$\nThe term $L_g L_f h(x)$ is the coefficient of $u$, also known as the decoupling term. A well-defined relative degree $r=2$ exists if and only if this term is nonzero. Let us compute it. First, we find the gradient of $L_f h(x) = x_1 + x_2^3$:\n$$\n\\frac{\\partial (L_f h(x))}{\\partial x} = \\begin{pmatrix} \\frac{\\partial}{\\partial x_1}(x_1 + x_2^3) & \\frac{\\partial}{\\partial x_2}(x_1 + x_2^3) \\end{pmatrix} = \\begin{pmatrix} 1 & 3x_2^2 \\end{pmatrix}\n$$\nNow, we can find the decoupling term:\n$$\nL_g L_f h(x) = \\frac{\\partial (L_f h(x))}{\\partial x} g(x) = \\begin{pmatrix} 1 & 3x_2^2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 3x_2^2\n$$\nThe input $u$ appears for the first time in the second derivative of $y$. The relative degree is $r=2$ provided that the decoupling term $L_g L_f h(x) = 3x_2^2$ is non-zero. This condition, $3x_2^2 \\neq 0$, is equivalent to $x_2 \\neq 0$. Therefore, the relative degree is well-defined and equal to $2$ on the largest subset of $\\mathbb{R}^2$ given by the set $S = \\{ (x_1, x_2) \\in \\mathbb{R}^2 \\mid x_2 \\neq 0 \\}$. On the line $x_2 = 0$, the relative degree is undefined, which corresponds to a singularity in the input-output map.\n\nNext, we address whether the backstepping recursion can be initiated from the $x_1$-subsystem. Backstepping is conventionally applied to systems in a strict-feedback form, which has the cascaded structure:\n$$\n\\dot{z}_i = f_i(z_1, \\dots, z_i) + g_i(z_1, \\dots, z_i) z_{i+1}, \\quad \\text{for } i=1, \\dots, n-1\n$$\n$$\n\\dot{z}_n = f_n(z_1, \\dots, z_n) + g_n(z_1, \\dots, z_n) u\n$$\nwhere $g_i(\\cdot) \\neq 0$. The given system, with subsystems for $x_1$ and $x_2$, is:\n$$\n\\dot{x}_1 = x_1 + x_2^3\n$$\n$$\n\\dot{x}_2 = -x_2 + \\cos(x_1) + u\n$$\nThis system is not in strict-feedback form because the dynamics of $x_1$ depend nonlinearly on $x_2$ through the term $x_2^3$, rather than the required form $g_1(x_1)x_2$. It is an example of a system in \"pure-feedback\" or \"non-strict feedback\" form.\n\nDespite not being in strict-feedback form, the backstepping recursion **can** be initiated. The first step of backstepping involves treating $x_2$ as a \"virtual control\" to stabilize the $x_1$-subsystem, $\\dot{x}_1 = x_1 + x_2^3$. For a given state $x_1$, we design a desired stabilizing value for $x_2$, denoted by a virtual control law $\\alpha_1(x_1)$. To stabilize $x_1$ at the origin, for example, we can select a Lyapunov function $V_1 = \\frac{1}{2}x_1^2$. Its time derivative is $\\dot{V}_1 = x_1 \\dot{x}_1 = x_1 (x_1 + x_2^3)$. If we could set $x_2 = \\alpha_1(x_1)$, we would have $\\dot{V}_1 = x_1 (x_1 + \\alpha_1(x_1)^3)$. We can force this to be negative definite, e.g., $\\dot{V}_1 = -c_1 x_1^2$ for some design constant $c_1 > 0$, by choosing $\\alpha_1(x_1)$ such that $x_1 + \\alpha_1(x_1)^3 = -c_1 x_1$. This requires solving for $\\alpha_1(x_1)$:\n$$\n\\alpha_1(x_1)^3 = -(1+c_1)x_1\n$$\n$$\n\\alpha_1(x_1) = -\\sqrt[3]{(1+c_1)x_1}\n$$\nThe function $\\alpha_1(x_1)$ is well-defined and continuously differentiable for all $x_1 \\neq 0$. The differentiability at $x_1=0$ is also not an issue, though the derivative is singular. The crucial point is that the function $\\phi(x_2) = x_2^3$ is a global diffeomorphism from $\\mathbb{R}$ to $\\mathbb{R}$. Its invertibility allows for the explicit design of the virtual control $\\alpha_1(x_1)$. Therefore, the backstepping recursion can be successfully initiated.\n\nThe nondegeneracy of the decoupling term, $3x_2^2 \\neq 0$, is a separate issue. This condition is essential for the final step of the backstepping design (or for feedback linearization), where the actual control input $u$ is constructed to make the state $x_2$ track its desired trajectory $\\alpha_1(x_1)$. The singularity at $x_2=0$ implies that the final control law will be undefined on this manifold, as control authority is lost. However, this singularity does not prevent the conceptual initiation of the recursive design procedure.\n\nThe decoupling term that multiplies the input $u$ is the term $L_g L_f h(x)$ from the expression for the first derivative of $y$ at which $u$ appears, which is $\\ddot{y}$. As calculated previously, this term is $3x_2^2$.", "answer": "$$\n\\boxed{3x_2^2}\n$$", "id": "2689617"}, {"introduction": "Designing a controller that guarantees stability is essential, but quantifying its performance is what makes a design practical and robust. This exercise shifts the focus from design to analysis, showing how to derive a concrete performance metric for a closed-loop system obtained via backstepping. Using a quadratic Lyapunov function and standard analytical tools like Young's inequality, you will establish an explicit exponential decay rate, $\\lambda$, for the state trajectories and learn how to optimize your analysis to find the best possible performance guarantee [@problem_id:2736812].", "problem": "Consider the third-order strict-feedback plant modeled as an Ordinary Differential Equation (ODE)\n$$\n\\dot{x}_{1} = x_{2}, \\quad \\dot{x}_{2} = x_{3}, \\quad \\dot{x}_{3} = u,\n$$\nand apply recursive backstepping to stabilize the origin. Introduce the virtual controls\n$$\n\\alpha_{1}(x_{1}) = -c_{1} x_{1}, \\quad \\alpha_{2}(x_{1},x_{2}) = -c_{2} z_{2} + \\frac{\\partial \\alpha_{1}}{\\partial x_{1}} x_{2},\n$$\nand define the backstepping error coordinates\n$$\nz_{1} = x_{1}, \\quad z_{2} = x_{2} - \\alpha_{1}(x_{1}), \\quad z_{3} = x_{3} - \\alpha_{2}(x_{1},x_{2}),\n$$\nwith the actual control input chosen in the standard manner to render the closed-loop error dynamics lower-triangular with linear damping gains. Under this canonical design, the closed-loop error dynamics take the form\n$$\n\\dot{z}_{1} = -c_{1} z_{1} + z_{2}, \\quad \\dot{z}_{2} = -c_{2} z_{2} + z_{3}, \\quad \\dot{z}_{3} = -c_{3} z_{3},\n$$\nwhere $c_{1} > 0$, $c_{2} > 0$, and $c_{3} > 0$ are design gains. Let $z = \\begin{pmatrix} z_{1} & z_{2} & z_{3} \\end{pmatrix}^{\\top}$ and consider the Lyapunov candidate $V(z) = \\tfrac{1}{2} \\|z\\|^{2}$.\n\nUsing only fundamental inequalities and definitions, perform the following:\n\n1) Starting from $V(z)$, derive an upper bound for $\\dot{V}(z)$ in terms of $z_{1}$, $z_{2}$, $z_{3}$ and the gains $c_{1}$, $c_{2}$, $c_{3}$ by applying Young’s inequality to the coupling products. Introduce positive auxiliary parameters $\\varepsilon_{1} > 0$ and $\\varepsilon_{2} > 0$ to bound the cross terms.\n\n2) From this bound, derive explicit inequalities that link the gains $c_{1}$, $c_{2}$, $c_{3}$, the auxiliary parameters $\\varepsilon_{1}$, $\\varepsilon_{2}$, and the exponential decay rate $\\lambda > 0$ so that the differential inequality $\\dot{V}(z) \\leq -2 \\lambda V(z)$ holds. Conclude that these inequalities ensure $\\|z(t)\\|$ decays exponentially with rate at least $\\lambda$.\n\n3) For the specific gain choices $c_{1} = 3$, $c_{2} = 4$, and $c_{3} = 5$, choose $\\varepsilon_{1}$ and $\\varepsilon_{2}$ to maximize the guaranteed exponential decay rate $\\lambda$ subject to your inequalities from part $2)$. Compute the resulting maximum admissible $\\lambda$ guaranteed by this analysis. Round your answer to $4$ significant figures.", "solution": "The system under consideration is a third-order integrator chain:\n$$\n\\dot{x}_{1} = x_{2}, \\quad \\dot{x}_{2} = x_{3}, \\quad \\dot{x}_{3} = u\n$$\nThe problem specifies the backstepping error coordinates $z_{1}$, $z_{2}$, $z_{3}$ and the resulting closed-loop error dynamics:\n$$\n\\dot{z}_{1} = -c_{1} z_{1} + z_{2} \\\\\n\\dot{z}_{2} = -c_{2} z_{2} + z_{3} \\\\\n\\dot{z}_{3} = -c_{3} z_{3}\n$$\nwhere $c_{1}, c_{2}, c_{3}$ are positive design gains. We are to analyze the stability of the origin of this system in the $z$-coordinates using the Lyapunov candidate function $V(z) = \\frac{1}{2} \\|z\\|^{2} = \\frac{1}{2}(z_{1}^{2} + z_{2}^{2} + z_{3}^{2})$.\n\n**Part 1: Derivation of the upper bound for $\\dot{V}(z)$**\n\nFirst, we compute the time derivative of the Lyapunov function $V(z)$ along the trajectories of the error system:\n$$\n\\dot{V}(z) = \\frac{d}{dt} \\left( \\frac{1}{2} z_{1}^{2} + \\frac{1}{2} z_{2}^{2} + \\frac{1}{2} z_{3}^{2} \\right) = z_{1}\\dot{z}_{1} + z_{2}\\dot{z}_{2} + z_{3}\\dot{z}_{3}\n$$\nSubstituting the given error dynamics into this expression, we obtain:\n$$\n\\dot{V}(z) = z_{1}(-c_{1} z_{1} + z_{2}) + z_{2}(-c_{2} z_{2} + z_{3}) + z_{3}(-c_{3} z_{3})\n$$\nExpanding the terms yields:\n$$\n\\dot{V}(z) = -c_{1} z_{1}^{2} + z_{1}z_{2} - c_{2} z_{2}^{2} + z_{2}z_{3} - c_{3} z_{3}^{2}\n$$\nThis expression contains quadratic terms, which are sign-definite, and cross-product terms $z_{1}z_{2}$ and $z_{2}z_{3}$, which are not. To obtain an upper bound for $\\dot{V}(z)$, we apply Young's inequality to these cross terms. Young's inequality states that for any real numbers $a, b$ and any positive constant $\\varepsilon$, the following holds: $ab \\leq \\frac{a^2}{2\\varepsilon} + \\frac{\\varepsilon b^2}{2}$.\n\nWe apply this inequality to the term $z_{1}z_{2}$ with an auxiliary parameter $\\varepsilon_{1} > 0$:\n$$\nz_{1}z_{2} \\leq \\frac{z_{1}^{2}}{2\\varepsilon_{1}} + \\frac{\\varepsilon_{1} z_{2}^{2}}{2}\n$$\nAnd to the term $z_{2}z_{3}$ with an auxiliary parameter $\\varepsilon_{2} > 0$:\n$$\nz_{2}z_{3} \\leq \\frac{z_{2}^{2}}{2\\varepsilon_{2}} + \\frac{\\varepsilon_{2} z_{3}^{2}}{2}\n$$\nSubstituting these inequalities into the expression for $\\dot{V}(z)$:\n$$\n\\dot{V}(z) \\leq -c_{1} z_{1}^{2} + \\left( \\frac{z_{1}^{2}}{2\\varepsilon_{1}} + \\frac{\\varepsilon_{1} z_{2}^{2}}{2} \\right) - c_{2} z_{2}^{2} + \\left( \\frac{z_{2}^{2}}{2\\varepsilon_{2}} + \\frac{\\varepsilon_{2} z_{3}^{2}}{2} \\right) - c_{3} z_{3}^{2}\n$$\nGrouping the terms by $z_{1}^{2}$, $z_{2}^{2}$, and $z_{3}^{2}$, we arrive at the desired upper bound:\n$$\n\\dot{V}(z) \\leq -\\left(c_{1} - \\frac{1}{2\\varepsilon_{1}}\\right)z_{1}^{2} - \\left(c_{2} - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}}\\right)z_{2}^{2} - \\left(c_{3} - \\frac{\\varepsilon_{2}}{2}\\right)z_{3}^{2}\n$$\n\n**Part 2: Derivation of inequalities for exponential stability**\n\nWe seek to establish the condition $\\dot{V}(z) \\leq -2\\lambda V(z)$ for some exponential decay rate $\\lambda > 0$. Recalling that $V(z) = \\frac{1}{2}(z_{1}^{2} + z_{2}^{2} + z_{3}^{2})$, the condition is equivalent to:\n$$\n\\dot{V}(z) \\leq -\\lambda z_{1}^{2} - \\lambda z_{2}^{2} - \\lambda z_{3}^{2}\n$$\nComparing this with the upper bound derived in Part 1, the inequality is satisfied if the following conditions on the coefficients of $z_{i}^{2}$ hold for all $i \\in \\{1, 2, 3\\}$:\n$$\n-\\left(c_{1} - \\frac{1}{2\\varepsilon_{1}}\\right) \\leq -\\lambda \\implies c_{1} - \\frac{1}{2\\varepsilon_{1}} \\geq \\lambda\n$$\n$$\n-\\left(c_{2} - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}}\\right) \\leq -\\lambda \\implies c_{2} - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}} \\geq \\lambda\n$$\n$$\n-\\left(c_{3} - \\frac{\\varepsilon_{2}}{2}\\right) \\leq -\\lambda \\implies c_{3} - \\frac{\\varepsilon_{2}}{2} \\geq \\lambda\n$$\nThese three inequalities link the gains $c_i$, the auxiliary parameters $\\varepsilon_i$, and the decay rate $\\lambda$. The differential inequality $\\dot{V}(z) \\leq -2\\lambda V(z)$, by the Comparison Lemma, implies $V(z(t)) \\leq V(z(0)) \\exp(-2\\lambda t)$. Substituting the definition of $V(z)$ gives $\\frac{1}{2}\\|z(t)\\|^{2} \\leq \\frac{1}{2}\\|z(0)\\|^{2} \\exp(-2\\lambda t)$, which simplifies to $\\|z(t)\\| \\leq \\|z(0)\\| \\exp(-\\lambda t)$. This confirms that the state norm $\\|z(t)\\|$ decays to zero exponentially with a rate of at least $\\lambda$.\n\n**Part 3: Maximization of the decay rate $\\lambda$**\n\nWe are given the specific gains $c_{1} = 3$, $c_{2} = 4$, and $c_{3} = 5$. Our goal is to choose $\\varepsilon_{1} > 0$ and $\\varepsilon_{2} > 0$ to maximize the guaranteed decay rate $\\lambda$. To satisfy all three inequalities from Part 2, $\\lambda$ must be less than or equal to the minimum of the three left-hand side expressions:\n$$\n\\lambda \\leq \\min \\left\\{ 3 - \\frac{1}{2\\varepsilon_{1}}, \\quad 4 - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}}, \\quad 5 - \\frac{\\varepsilon_{2}}{2} \\right\\}\n$$\nTo maximize this minimum value, we should choose $\\varepsilon_{1}$ and $\\varepsilon_{2}$ such that the three arguments of the minimum function are equal. This is a standard approach for this class of optimization problem. Let the maximal rate be $\\lambda$. We set:\n$$\n\\lambda = 3 - \\frac{1}{2\\varepsilon_{1}} \\quad (A)\n$$\n$$\n\\lambda = 4 - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}} \\quad (B)\n$$\n$$\n\\lambda = 5 - \\frac{\\varepsilon_{2}}{2} \\quad (C)\n$$\nFrom equation $(A)$, we solve for $\\varepsilon_{1}$:\n$3 - \\lambda = \\frac{1}{2\\varepsilon_{1}} \\implies \\varepsilon_{1} = \\frac{1}{2(3 - \\lambda)}$. This requires $\\lambda < 3$.\nFrom equation $(C)$, we solve for $\\varepsilon_{2}$:\n$5 - \\lambda = \\frac{\\varepsilon_{2}}{2} \\implies \\varepsilon_{2} = 2(5 - \\lambda)$. This requires $\\lambda < 5$.\nNow, we substitute the expressions for $\\frac{\\varepsilon_{1}}{2}$ and $\\frac{1}{2\\varepsilon_{2}}$ into equation $(B)$.\nFrom our expressions for $\\varepsilon_1$ and $\\varepsilon_2$, we have $\\frac{\\varepsilon_{1}}{2} = \\frac{1}{4(3 - \\lambda)}$ and $\\frac{1}{2\\varepsilon_{2}} = \\frac{1}{4(5 - \\lambda)}$.\nSubstituting these into $(B)$:\n$$\n\\lambda = 4 - \\frac{1}{4(3 - \\lambda)} - \\frac{1}{4(5 - \\lambda)}\n$$\nTo solve for $\\lambda$, we rearrange the equation:\n$$\n4 - \\lambda = \\frac{1}{4(3 - \\lambda)} + \\frac{1}{4(5 - \\lambda)}\n$$\n$$\n4(4 - \\lambda) = \\frac{1}{3 - \\lambda} + \\frac{1}{5 - \\lambda}\n$$\n$$\n4(4 - \\lambda) = \\frac{(5 - \\lambda) + (3 - \\lambda)}{(3 - \\lambda)(5 - \\lambda)} = \\frac{8 - 2\\lambda}{\\lambda^{2} - 8\\lambda + 15}\n$$\n$$\n4(4 - \\lambda) = \\frac{2(4 - \\lambda)}{\\lambda^{2} - 8\\lambda + 15}\n$$\nSince $\\lambda < 3$, it follows that $\\lambda \\neq 4$. We can safely divide both sides by $4 - \\lambda$:\n$$\n4 = \\frac{2}{\\lambda^{2} - 8\\lambda + 15}\n$$\nThis simplifies to:\n$$\n2(\\lambda^{2} - 8\\lambda + 15) = 1\n$$\n$$\n2\\lambda^{2} - 16\\lambda + 30 = 1\n$$\n$$\n2\\lambda^{2} - 16\\lambda + 29 = 0\n$$\nWe solve this quadratic equation for $\\lambda$ using the quadratic formula, $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\n\\lambda = \\frac{16 \\pm \\sqrt{(-16)^{2} - 4(2)(29)}}{2(2)} = \\frac{16 \\pm \\sqrt{256 - 232}}{4} = \\frac{16 \\pm \\sqrt{24}}{4}\n$$\n$$\n\\lambda = \\frac{16 \\pm 2\\sqrt{6}}{4} = 4 \\pm \\frac{\\sqrt{6}}{2}\n$$\nThis gives two possible solutions for $\\lambda$: $\\lambda_{1} = 4 + \\frac{\\sqrt{6}}{2}$ and $\\lambda_{2} = 4 - \\frac{\\sqrt{6}}{2}$.\nAs established earlier, for $\\varepsilon_{1}$ to be positive, we must have $3 - \\lambda > 0$, which implies $\\lambda < 3$.\nWe evaluate the two solutions:\n$\\lambda_{1} = 4 + \\frac{\\sqrt{6}}{2} \\approx 4 + \\frac{2.449}{2} \\approx 5.225$. This solution violates the condition $\\lambda < 3$ and is therefore extraneous.\n$\\lambda_{2} = 4 - \\frac{\\sqrt{6}}{2} \\approx 4 - \\frac{2.449}{2} \\approx 2.775$. This solution satisfies $\\lambda < 3$.\nThus, the maximum guaranteed exponential decay rate is $\\lambda = 4 - \\frac{\\sqrt{6}}{2}$.\n\nFinally, we compute the numerical value and round to $4$ significant figures as requested.\n$$\n\\lambda = 4 - \\frac{\\sqrt{6}}{2} \\approx 4 - \\frac{2.44948974}{2} = 4 - 1.22474487 = 2.77525513...\n$$\nRounding to $4$ significant figures, we get $2.775$.\nThe optimal auxiliary parameters are $\\varepsilon_1 = \\frac{1}{2(3 - (4-\\sqrt{6}/2))} = \\frac{1}{\\sqrt{6}-2} \\approx 2.225$ and $\\varepsilon_2 = 2(5 - (4-\\sqrt{6}/2)) = 2 + \\sqrt{6} \\approx 4.449$. Both are positive, confirming the validity of the solution.", "answer": "$$\n\\boxed{2.775}\n$$", "id": "2736812"}]}