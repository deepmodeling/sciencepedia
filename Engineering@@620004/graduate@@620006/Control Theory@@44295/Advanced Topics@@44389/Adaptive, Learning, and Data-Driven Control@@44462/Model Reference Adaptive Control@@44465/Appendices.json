{"hands_on_practices": [{"introduction": "A cornerstone of modern adaptive control is the ability to guarantee stability while the system learns. This practice introduces the powerful Lyapunov-based design methodology, the gold standard for deriving stable adaptation laws. By working through the control of a simple thermal process with an unknown parameter, you will construct a Lyapunov function to systematically derive an update rule that ensures the tracking error converges to zero, providing a foundational skill for all adaptive control design [@problem_id:1591800].", "problem": "Consider the problem of controlling the temperature, $y(t)$, of a simple chemical reactor. The thermal dynamics of the reactor are described by the first-order linear differential equation:\n$$ \\dot{y}(t) = -a y(t) + b u(t) $$\nwhere $u(t)$ is the rate of heat supplied by a heater (the control input), $b$ is a known positive constant representing the heater's efficiency, and $a$ is an unknown but constant positive parameter representing the rate of heat dissipation to the environment.\n\nThe objective is to design a controller that makes the reactor's temperature $y(t)$ asymptotically track the temperature profile $y_m(t)$ of a stable reference model. The reference model is given by:\n$$ \\dot{y}_m(t) = -a_m y_m(t) + b_m r(t) $$\nwhere $a_m$ and $b_m$ are known positive constants, and $r(t)$ is a bounded reference command signal.\n\nA Model Reference Adaptive Control (MRAC) strategy is employed. The control input $u(t)$ is structured as:\n$$ u(t) = \\frac{\\hat{a}(t) - a_m}{b} y(t) + \\frac{b_m}{b} r(t) $$\nHere, $\\hat{a}(t)$ is the real-time estimate of the unknown parameter $a$. The key to this control strategy is to find an *adaptation law*, a differential equation for $\\dot{\\hat{a}}(t)$, that guarantees the stability of the system and ensures the tracking error $e(t) = y(t) - y_m(t)$ converges to zero.\n\nYour task is to derive this adaptation law using a Lyapunov-based design procedure. First, derive the differential equation that governs the tracking error $e(t)$. Then, construct a quadratic Lyapunov function candidate using the tracking error $e(t)$ and the parameter estimation error $\\tilde{a}(t) = \\hat{a}(t) - a$. Finally, use this Lyapunov function to derive the update rule for $\\dot{\\hat{a}}(t)$ that ensures stability.\n\nPresent your final answer as an expression for $\\dot{\\hat{a}}(t)$. The expression should be in terms of the tracking error $e(t)$, the plant output $y(t)$, and a positive constant $\\gamma$, which serves as the adaptation gain and should be introduced in your Lyapunov function.", "solution": "The plant is $\\dot{y}(t)=-a y(t)+b u(t)$ and the reference model is $\\dot{y}_{m}(t)=-a_{m} y_{m}(t)+b_{m} r(t)$, with $a>0$, $b>0$, $a_{m}>0$, and $b_{m}>0$. The control is\n$$\nu(t)=\\frac{\\hat{a}(t)-a_{m}}{b}y(t)+\\frac{b_{m}}{b}r(t).\n$$\nSubstituting $u(t)$ into the plant yields\n$$\n\\dot{y}(t)=-a y(t)+b\\left(\\frac{\\hat{a}(t)-a_{m}}{b}y(t)+\\frac{b_{m}}{b}r(t)\\right)=-a y(t)+(\\hat{a}(t)-a_{m})y(t)+b_{m}r(t).\n$$\nHence\n$$\n\\dot{y}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+b_{m}r(t).\n$$\nDefine the tracking error $e(t)=y(t)-y_{m}(t)$. Its derivative is\n$$\n\\dot{e}(t)=\\dot{y}(t)-\\dot{y}_{m}(t)=\\bigl(-(a+a_{m}-\\hat{a}(t))y(t)+b_{m}r(t)\\bigr)-\\bigl(-a_{m}y_{m}(t)+b_{m}r(t)\\bigr).\n$$\nThis simplifies to\n$$\n\\dot{e}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+a_{m}y_{m}(t).\n$$\nUsing $y_{m}(t)=y(t)-e(t)$, we obtain\n$$\n\\dot{e}(t)=-(a+a_{m}-\\hat{a}(t))y(t)+a_{m}(y(t)-e(t))=-a y(t)+\\hat{a}(t)y(t)-a_{m}e(t).\n$$\nIntroduce the parameter estimation error $\\tilde{a}(t)=\\hat{a}(t)-a$. Then the error dynamics become\n$$\n\\dot{e}(t)=-a_{m}e(t)+\\tilde{a}(t)\\,y(t).\n$$\n\nChoose the Lyapunov function candidate\n$$\nV(t)=\\frac{1}{2}e^{2}(t)+\\frac{1}{2\\gamma}\\tilde{a}^{2}(t),\n$$\nwhere $\\gamma>0$ is the adaptation gain. Since $a$ is constant, $\\dot{\\tilde{a}}(t)=\\dot{\\hat{a}}(t)$. The time derivative of $V$ along trajectories is\n$$\n\\dot{V}(t)=e(t)\\dot{e}(t)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\tilde{a}}(t)=e(t)\\bigl(-a_{m}e(t)+\\tilde{a}(t)\\,y(t)\\bigr)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\hat{a}}(t).\n$$\nTherefore\n$$\n\\dot{V}(t)=-a_{m}e^{2}(t)+e(t)\\tilde{a}(t)\\,y(t)+\\frac{1}{\\gamma}\\tilde{a}(t)\\dot{\\hat{a}}(t).\n$$\nTo ensure $\\dot{V}(t)\\leq 0$, choose $\\dot{\\hat{a}}(t)$ to cancel the cross term $e(t)\\tilde{a}(t)\\,y(t)$. Selecting\n$$\n\\dot{\\hat{a}}(t)=-\\gamma\\,e(t)\\,y(t)\n$$\ngives\n$$\n\\dot{V}(t)=-a_{m}e^{2}(t)\\leq 0.\n$$\nThus $V(t)$ is nonincreasing, $e(t)$ and $\\tilde{a}(t)$ are bounded, and by standard Lyapunov arguments (e.g., LaSalle or Barbalat’s lemma with bounded signals), the tracking error $e(t)$ converges to zero asymptotically. The required adaptation law is the gradient update\n$$\n\\dot{\\hat{a}}(t)=-\\gamma\\,e(t)\\,y(t).\n$$", "answer": "$$\\boxed{\\dot{\\hat{a}}(t) = -\\gamma\\,e(t)\\,y(t)}$$", "id": "1591800"}, {"introduction": "Real-world systems often feature parameters that are not just unknown, but also time-varying. This practice explores a powerful technique, linear parameterization, which allows us to extend the Lyapunov design methodology to such challenging scenarios. You will tackle a system with a sinusoidally varying control gain, learning how to structure the controller and adaptation law to handle known patterns of parameter variation, a crucial step toward designing more versatile adaptive systems [@problem_id:1591792].", "problem": "Consider a first-order dynamic system, referred to as the plant, whose behavior is described by the differential equation:\n$$ \\dot{y}_p(t) = -a_p y_p(t) + b(t) u(t) $$\nHere, $y_p(t)$ is the plant's output and $u(t)$ is the control input. The parameter $a_p$ is a known positive constant. The control effectiveness, $b(t)$, is time-varying and given by $b(t) = b_0 + b_1 \\sin(\\omega t)$, where the frequency $\\omega$ is known, but the constant amplitudes $b_0$ and $b_1$ are unknown. It is known that $b_0$ and $b_1$ are such that $b(t)$ remains strictly positive for all time $t$.\n\nThe goal is to design a Model Reference Adaptive Control (MRAC) system so that the plant output $y_p(t)$ asymptotically tracks the output $y_m(t)$ of a stable reference model. The reference model is given by:\n$$ \\dot{y}_m(t) = -a_m y_m(t) + k_m r(t) $$\nwhere $y_m(t)$ is the model output, $r(t)$ is a bounded reference command signal, and $a_m$ and $k_m$ are known positive constants chosen by the designer.\n\nThe control architecture is based on estimating the unknown parameters $b_0$ and $b_1$ with time-varying estimates $\\hat{b}_0(t)$ and $\\hat{b}_1(t)$, respectively. The control law $u(t)$ is formulated using the certainty equivalence principle. The update laws for the parameter estimates are derived using Lyapunov's direct method to ensure the stability of the system and the convergence of the tracking error, defined as $e(t) = y_p(t) - y_m(t)$, to zero. The adaptation gains for the update laws are given as positive constants $\\gamma_0$ and $\\gamma_1$.\n\nDetermine the expressions for the parameter update laws $\\dot{\\hat{b}}_0(t)$ and $\\dot{\\hat{b}}_1(t)$. Express your final answer in terms of the tracking error $e(t)$, the control input $u(t)$, the known frequency $\\omega$, the time $t$, and the adaptation gains $\\gamma_0$ and $\\gamma_1$. Present your answer as a $1 \\times 2$ row matrix, where the first element is the expression for $\\dot{\\hat{b}}_0(t)$ and the second is for $\\dot{\\hat{b}}_1(t)$.", "solution": "The objective is to make the tracking error $e(t) = y_p(t) - y_m(t)$ converge to zero. We begin by deriving the differential equation for the tracking error.\n\nThe time derivative of the error is $\\dot{e}(t) = \\dot{y}_p(t) - \\dot{y}_m(t)$.\nSubstituting the expressions for the plant and model dynamics:\n$$ \\dot{e}(t) = [-a_p y_p(t) + b(t) u(t)] - [-a_m y_m(t) + k_m r(t)] $$\nWe can add and subtract the term $a_m y_p(t)$ to the right-hand side to introduce the term $-a_m e(t)$:\n$$ \\dot{e}(t) = -a_m y_p(t) + a_m y_p(t) - a_p y_p(t) + b(t) u(t) + a_m y_m(t) - k_m r(t) $$\n$$ \\dot{e}(t) = -a_m (y_p(t) - y_m(t)) + (a_m - a_p) y_p(t) - k_m r(t) + b(t) u(t) $$\nThis simplifies to the error dynamics equation:\n$$ \\dot{e}(t) = -a_m e(t) + (a_m - a_p) y_p(t) - k_m r(t) + (b_0 + b_1 \\sin(\\omega t)) u(t) $$\nThe ideal control law $u^*(t)$ would be one that makes the terms following $-a_m e(t)$ sum to zero. This would mean:\n$$ (a_m - a_p) y_p(t) - k_m r(t) + (b_0 + b_1 \\sin(\\omega t)) u^*(t) = 0 $$\nSince $b_0$ and $b_1$ are unknown, we cannot implement this ideal control law. Instead, we use the certainty equivalence principle to formulate the control law $u(t)$ by replacing the unknown parameters $b_0$ and $b_1$ with their estimates $\\hat{b}_0(t)$ and $\\hat{b}_1(t)$:\n$$ (a_m - a_p) y_p(t) - k_m r(t) + (\\hat{b}_0(t) + \\hat{b}_1(t) \\sin(\\omega t)) u(t) = 0 $$\nSolving for $u(t)$, we get the control law:\n$$ u(t) = -\\frac{(a_m - a_p) y_p(t) - k_m r(t)}{\\hat{b}_0(t) + \\hat{b}_1(t) \\sin(\\omega t)} = \\frac{(a_p - a_m) y_p(t) + k_m r(t)}{\\hat{b}_0(t) + \\hat{b}_1(t) \\sin(\\omega t)} $$\nNow, we substitute the relationship from the control law design, $(a_m - a_p) y_p(t) - k_m r(t) = -(\\hat{b}_0(t) + \\hat{b}_1(t) \\sin(\\omega t)) u(t)$, back into the error dynamics equation:\n$$ \\dot{e}(t) = -a_m e(t) - (\\hat{b}_0(t) + \\hat{b}_1(t) \\sin(\\omega t)) u(t) + (b_0 + b_1 \\sin(\\omega t)) u(t) $$\nCombining the terms involving $u(t)$:\n$$ \\dot{e}(t) = -a_m e(t) + [(b_0 - \\hat{b}_0(t)) + (b_1 - \\hat{b}_1(t)) \\sin(\\omega t)] u(t) $$\nLet the parameter errors be $\\tilde{b}_0(t) = b_0 - \\hat{b}_0(t)$ and $\\tilde{b}_1(t) = b_1 - \\hat{b}_1(t)$. Since $b_0$ and $b_1$ are constants, their time derivatives are zero, so $\\dot{\\tilde{b}}_0 = -\\dot{\\hat{b}}_0$ and $\\dot{\\tilde{b}}_1 = -\\dot{\\hat{b}}_1$. The error dynamics become:\n$$ \\dot{e}(t) = -a_m e(t) + [\\tilde{b}_0(t) + \\tilde{b}_1(t) \\sin(\\omega t)] u(t) $$\nTo find the update laws for $\\hat{b}_0(t)$ and $\\hat{b}_1(t)$, we use a Lyapunov function candidate:\n$$ V(t) = \\frac{1}{2} e(t)^2 + \\frac{1}{2\\gamma_0} \\tilde{b}_0(t)^2 + \\frac{1}{2\\gamma_1} \\tilde{b}_1(t)^2 $$\nwhere $\\gamma_0 > 0$ and $\\gamma_1 > 0$ are the adaptation gains. The time derivative of $V(t)$ is:\n$$ \\dot{V}(t) = e(t)\\dot{e}(t) + \\frac{1}{\\gamma_0} \\tilde{b}_0(t)\\dot{\\tilde{b}}_0(t) + \\frac{1}{\\gamma_1} \\tilde{b}_1(t)\\dot{\\tilde{b}}_1(t) $$\n$$ \\dot{V}(t) = e(t)\\dot{e}(t) - \\frac{1}{\\gamma_0} \\tilde{b}_0(t)\\dot{\\hat{b}}_0(t) - \\frac{1}{\\gamma_1} \\tilde{b}_1(t)\\dot{\\hat{b}}_1(t) $$\nSubstitute the expression for $\\dot{e}(t)$:\n$$ \\dot{V}(t) = e(t) \\left[ -a_m e(t) + (\\tilde{b}_0(t) + \\tilde{b}_1(t) \\sin(\\omega t)) u(t) \\right] - \\frac{1}{\\gamma_0} \\tilde{b}_0(t)\\dot{\\hat{b}}_0(t) - \\frac{1}{\\gamma_1} \\tilde{b}_1(t)\\dot{\\hat{b}}_1(t) $$\n$$ \\dot{V}(t) = -a_m e(t)^2 + e(t) u(t) \\tilde{b}_0(t) + e(t) u(t) \\sin(\\omega t) \\tilde{b}_1(t) - \\frac{1}{\\gamma_0} \\tilde{b}_0(t)\\dot{\\hat{b}}_0(t) - \\frac{1}{\\gamma_1} \\tilde{b}_1(t)\\dot{\\hat{b}}_1(t) $$\nGroup the terms by the parameter errors $\\tilde{b}_0$ and $\\tilde{b}_1$:\n$$ \\dot{V}(t) = -a_m e(t)^2 + \\tilde{b}_0(t) \\left[ e(t) u(t) - \\frac{1}{\\gamma_0}\\dot{\\hat{b}}_0(t) \\right] + \\tilde{b}_1(t) \\left[ e(t) u(t) \\sin(\\omega t) - \\frac{1}{\\gamma_1}\\dot{\\hat{b}}_1(t) \\right] $$\nTo ensure stability (i.e., $\\dot{V}(t) \\le 0$), we choose the update laws for $\\dot{\\hat{b}}_0(t)$ and $\\dot{\\hat{b}}_1(t)$ to make the terms in the square brackets equal to zero:\n1.  $e(t) u(t) - \\frac{1}{\\gamma_0}\\dot{\\hat{b}}_0(t) = 0 \\implies \\dot{\\hat{b}}_0(t) = \\gamma_0 e(t) u(t)$\n2.  $e(t) u(t) \\sin(\\omega t) - \\frac{1}{\\gamma_1}\\dot{\\hat{b}}_1(t) = 0 \\implies \\dot{\\hat{b}}_1(t) = \\gamma_1 e(t) u(t) \\sin(\\omega t)$\nWith these update laws, the derivative of the Lyapunov function becomes $\\dot{V}(t) = -a_m e(t)^2$. Since $a_m > 0$, $\\dot{V}(t)$ is negative semi-definite, which guarantees that $e(t)$ converges to zero.\n\nThe required expressions for the parameter update laws are $\\dot{\\hat{b}}_0(t) = \\gamma_0 e(t) u(t)$ and $\\dot{\\hat{b}}_1(t) = \\gamma_1 e(t) u(t) \\sin(\\omega t)$.", "answer": "$$\\boxed{\\begin{pmatrix} \\dot{\\hat{b}}_0(t) = \\gamma_0 e(t) u(t) & \\dot{\\hat{b}}_1(t) = \\gamma_1 e(t) u(t) \\sin(\\omega t) \\end{pmatrix}}$$", "id": "1591792"}, {"introduction": "The stability guarantees of Lyapunov-based MRAC designs are not magic; they rely on profound mathematical properties of the system's error dynamics. This advanced practice delves into one such property: the Strict Positive Real (SPR) condition, which is central to many adaptive control stability proofs via the Kalman-Yakubovich-Popov (KYP) lemma. You will move from symbolic derivation to computational analysis, writing a program to determine if a system's transfer function is SPR by solving a set of linear matrix inequalities, connecting abstract theory to a concrete, verifiable test [@problem_id:2725781].", "problem": "Consider single-input single-output linear time-invariant state-space systems defined by matrices $A \\in \\mathbb{R}^{2 \\times 2}$, $B \\in \\mathbb{R}^{2 \\times 1}$, and $C \\in \\mathbb{R}^{1 \\times 2}$, with input $u \\in \\mathbb{R}$, state $x \\in \\mathbb{R}^{2}$, and output $y \\in \\mathbb{R}$. The transfer function is $G(s) = C (s I - A)^{-1} B$. A rational function $G(s)$ is strictly positive real (SPR) if it is real-rational, has no poles in $\\operatorname{Re}(s) \\ge 0$, and satisfies $\\operatorname{Re}[G(j \\omega)] > 0$ for all $\\omega \\in \\mathbb{R}$. A standard route in model reference adaptive control (MRAC) is to verify strict positive realness via a Lyapunov inequality consistent with the Kalman-Yakubovich-Popov lemma, by finding a symmetric positive definite matrix $P \\in \\mathbb{R}^{2 \\times 2}$ that satisfies the following constraints:\n- $P = P^\\top$,\n- $P B = C^\\top$,\n- $A^\\top P + P A \\prec 0$ (strict negative definiteness),\n- $C B > 0$.\n\nWhen such a matrix $P$ exists, the function $V(x) = \\tfrac{1}{2} x^\\top P x$ is a storage function demonstrating passivity with a strict margin, which implies that $G(s)$ is strictly positive real. This storage function interpretation is central in adaptive control Lyapunov analyses.\n\nTask: Write a program that, for each given triple $(A,B,C)$, determines whether there exists a symmetric positive definite matrix $P$ that satisfies $P B = C^\\top$, $A^\\top P + P A \\prec 0$, and $C B > 0$. Your program must return a boolean for each test case: $\\,\\text{True}\\,$ if such a $P$ exists, and $\\,\\text{False}\\,$ otherwise. The search should be performed in a mathematically sound and numerically robust way and must not rely on any external user input.\n\nYour program must implement the decision for the following test suite of parameter values (all entries are real and dimensionally consistent):\n- Test case $1$ (happy path, Hurwitz $A$ and feasible constraints):\n  - $A = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 3 & 3.5 \\end{bmatrix}$.\n- Test case $2$ (violates $C B > 0$):\n  - $A = \\begin{bmatrix} -1 & 0 \\\\ 0 & -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} -3 & -3.5 \\end{bmatrix}$.\n- Test case $3$ (unstable $A$):\n  - $A = \\begin{bmatrix} 0.2 & 0 \\\\ 0 & -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 3 & 3.5 \\end{bmatrix}$.\n- Test case $4$ (marginally stable $A$ with a zero eigenvalue):\n  - $A = \\begin{bmatrix} 0 & 0 \\\\ 0 & -1 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 3 & 3.5 \\end{bmatrix}$.\n- Test case $5$ (happy path with different parameters):\n  - $A = \\begin{bmatrix} -2 & 0 \\\\ 0 & -2 \\end{bmatrix}$,\n  - $B = \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}$,\n  - $C = \\begin{bmatrix} 1.8 & -0.4 \\end{bmatrix}$.\n\nImportant details and constraints you must enforce in your program’s logic:\n- $P$ must be symmetric and positive definite.\n- The equality $P B = C^\\top$ must hold exactly for the candidate $P$ used to check the strict inequality.\n- The strict matrix inequality $A^\\top P + P A \\prec 0$ must be verified via eigenvalues being strictly negative.\n- The scalar inequality $C B > 0$ must be verified directly.\n- All numeric thresholds used to judge definiteness must be explicitly justified and implemented consistently.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots]$), where each $result_i$ is either $\\text{True}$ or $\\text{False}$.\n- No angles or physical units are involved in this problem.\n\nYour program must be fully deterministic and self-contained, with no user input, and it must compute and output the results for the five test cases described above in the exact order given, as a single list on one line.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of Lyapunov stability theory and the Kalman-Yakubovich-Popov (KYP) lemma from control theory, which provides conditions for a system's transfer function to be strictly positive real (SPR). The problem is well-posed, objective, and contains all necessary information to arrive at a deterministic solution.\n\nThe task is to determine, for a given single-input single-output (SISO) linear time-invariant (LTI) system defined by matrices $(A, B, C)$, whether there exists a symmetric positive definite matrix $P$ that satisfies a set of conditions. These conditions are:\n1.  $P = P^\\top$ (Symmetry)\n2.  $P \\succ 0$ (Positive Definiteness)\n3.  $C B > 0$\n4.  $P B = C^\\top$\n5.  $A^\\top P + P A \\prec 0$ (Negative Definiteness)\n\nLet us analyze these conditions systematically.\n\nFirst, a crucial necessary condition for the existence of a positive definite matrix $P$ satisfying $A^\\top P + P A \\prec 0$ is that the matrix $A$ must be Hurwitz. A matrix is Hurwitz if all of its eigenvalues have strictly negative real parts. Let us prove this by contradiction. Suppose there exists an eigenvector $v$ of $A$ with corresponding eigenvalue $\\lambda$ such that $\\operatorname{Re}(\\lambda) \\ge 0$. Then $Av = \\lambda v$. If $A^\\top P + P A$ were negative definite, it must be that $v^* (A^\\top P + P A) v < 0$. Evaluating this expression gives:\n$$v^* (A^\\top P + P A) v = (Av)^* P v + v^* P (Av) = (\\lambda v)^* P v + v^* P (\\lambda v) = \\bar{\\lambda} v^* P v + \\lambda v^* P v$$\n$$= (\\bar{\\lambda} + \\lambda) v^* P v = 2 \\operatorname{Re}(\\lambda) v^* P v$$\nSince $P$ is required to be positive definite, $v^* P v > 0$. Given our assumption that $\\operatorname{Re}(\\lambda) \\ge 0$, the entire expression $2 \\operatorname{Re}(\\lambda) v^* P v$ must be greater than or equal to $0$. This contradicts the requirement that $v^* (A^\\top P + P A) v < 0$. Therefore, $A$ must be Hurwitz. This provides a simple initial check.\n\nSecond, the scalar condition $C B > 0$ is a direct and simple calculation. If it is not met, no solution exists.\n\nIf both of these necessary conditions are satisfied, we proceed to find if a matrix $P$ exists that satisfies the remaining constraints. The matrix $P$ is a symmetric $2 \\times 2$ matrix, so it can be written as:\n$$P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix}$$\nThis matrix has three unknown elements: $p_{11}$, $p_{12}$, and $p_{22}$. The constraint $P B = C^\\top$ provides a system of two linear equations in these three unknowns:\n$$\\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} b_1 \\\\ b_2 \\end{bmatrix} = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix}$$\nThis expands to:\n$$p_{11} b_1 + p_{12} b_2 = c_1$$\n$$p_{12} b_1 + p_{22} b_2 = c_2$$\nSince $B$ is not the zero vector in any meaningful control problem (or the given test cases), this system is underdetermined. This implies that if a solution exists, there is a one-parameter family of solutions. We can express the elements of $P$ in terms of a single free parameter, which we shall call $\\alpha$. For instance, if $b_1 \\neq 0$ and $b_2 \\neq 0$, we can set $p_{12} = \\alpha$ and solve for $p_{11}$ and $p_{22}$:\n$$p_{11}(\\alpha) = \\frac{c_1 - \\alpha b_2}{b_1}$$\n$$p_{22}(\\alpha) = \\frac{c_2 - \\alpha b_1}{b_2}$$\nIf one component of $B$ is zero, we choose a different free parameter, but the principle remains the same. The matrix $P(\\alpha)$ is now a linear function of $\\alpha$.\n\nThe problem is now reduced to finding if there exists a real number $\\alpha$ for which $P(\\alpha)$ satisfies the two matrix inequalities:\n1.  $P(\\alpha) \\succ 0$\n2.  $Q(\\alpha) = A^\\top P(\\alpha) + P(\\alpha) A \\prec 0$\n\nFor a $2 \\times 2$ symmetric matrix $M = \\begin{bmatrix} m_{11} & m_{12} \\\\ m_{12} & m_{22} \\end{bmatrix}$, positive definiteness ($M \\succ 0$) is equivalent to $m_{11} > 0$ and $\\det(M) > 0$. Negative definiteness ($M \\prec 0$) is equivalent to $m_{11} < 0$ and $\\det(M) > 0$.\n\nApplying this to $P(\\alpha)$:\n-   $p_{11}(\\alpha) > 0$: This is a linear inequality in $\\alpha$.\n-   $\\det(P(\\alpha)) > 0$: As shown in detailed derivation, substituting the expressions for $p_{ij}(\\alpha)$ yields $\\det(P(\\alpha)) = \\frac{c_1c_2 - \\alpha(CB)}{b_1b_2}$. This is also a linear inequality in $\\alpha$.\nThese two linear inequalities define an open interval $(\\alpha_{\\min,P}, \\alpha_{\\max,P})$ for $\\alpha$.\n\nApplying this to $Q(\\alpha)$:\nThe elements of $Q(\\alpha)$ are linear functions of $\\alpha$, as $P(\\alpha)$ is linear in $\\alpha$. Let $Q(\\alpha) = \\begin{bmatrix} q_{11}(\\alpha) & q_{12}(\\alpha) \\\\ q_{12}(\\alpha) & q_{22}(\\alpha) \\end{bmatrix}$.\n-   $q_{11}(\\alpha) < 0$: This is a linear inequality in $\\alpha$.\n-   $\\det(Q(\\alpha)) > 0$: Since $q_{ij}(\\alpha)$ are linear, $\\det(Q(\\alpha)) = q_{11}(\\alpha)q_{22}(\\alpha) - q_{12}(\\alpha)^2$ is a quadratic function of $\\alpha$, say $f(\\alpha) = k_2\\alpha^2 + k_1\\alpha + k_0$. We require $f(\\alpha) > 0$.\n\nThe final step is to determine if there exists an $\\alpha$ that satisfies all these inequalities simultaneously. First, we find the intersection of all the linear inequalities, which results in a single open interval $(\\alpha_{\\min}, \\alpha_{\\max})$. If this interval is empty (i.e., $\\alpha_{\\min} \\ge \\alpha_{\\max}$), no solution exists. Otherwise, we must check if this interval has a non-empty intersection with the set of $\\alpha$ for which the quadratic inequality $f(\\alpha) > 0$ holds. This is a standard analysis of the roots and sign of the quadratic polynomial $f(\\alpha)$.\n\nThe overall algorithm is:\n1.  Verify that $A$ is Hurwitz. If not, the answer is False.\n2.  Verify that $C B > 0$. If not, the answer is False.\n3.  Parameterize $P$ with a single variable $\\alpha$ based on the constraint $P B = C^\\top$.\n4.  Derive the set of linear inequalities on $\\alpha$ from $P(\\alpha) \\succ 0$ and the trace condition for $Q(\\alpha) \\prec 0$ (i.e., $q_{11}(\\alpha) < 0$). Find the intersection of these, an interval $(\\alpha_{\\min}, \\alpha_{\\max})$. If this interval is empty, return False.\n5.  Derive the quadratic inequality $\\det(Q(\\alpha)) > 0$.\n6.  Analytically determine if the solution set for the quadratic inequality has a non-empty intersection with the interval $(\\alpha_{\\min}, \\alpha_{\\max})$. If it does, a valid $P$ exists; return True. Otherwise, return False. Numerical tolerance must be used for all comparisons.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {'A': np.array([[-1., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 2\n        {'A': np.array([[-1., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[-3., -3.5]])},\n        # Test case 3\n        {'A': np.array([[0.2, 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 4\n        {'A': np.array([[0., 0.], [0., -1.]]),\n         'B': np.array([[1.], [2.]]),\n         'C': np.array([[3., 3.5]])},\n        # Test case 5\n        {'A': np.array([[-2., 0.], [0., -2.]]),\n         'B': np.array([[2.], [-1.]]),\n         'C': np.array([[1.8, -0.4]])}\n    ]\n\n    results = [_check_spr_conditions(**case) for case in test_cases]\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _check_spr_conditions(A, B, C):\n    \"\"\"\n    Checks if a symmetric positive definite P exists for the given (A, B, C).\n    \"\"\"\n    TOL = 1e-9\n\n    # Condition 1: A must be Hurwitz (all eigenvalues have negative real parts)\n    eigs_A = np.linalg.eigvals(A)\n    if np.max(np.real(eigs_A)) >= -TOL:\n        return False\n\n    # Condition 2: CB > 0\n    if (C @ B)[0, 0] = TOL:\n        return False\n\n    # Parameterize P using PB = C^T. Let P = [p11, p12; p12, p22].\n    # The elements p_ij are expressed as linear functions of a free parameter 'alpha'.\n    # p_ij(alpha) = m_ij * alpha + c_ij\n    b1, b2 = B[0, 0], B[1, 0]\n    c1, c2 = C[0, 0], C[0, 1]\n    \n    p_coeffs = {} # Stores (m, c) for each p_ij\n\n    if abs(b1) > TOL:\n        if abs(b2) > TOL: # General case, let p12 be the free parameter\n            p_coeffs['p12'] = (1.0, 0.0)\n            # p11 = (c1 - alpha * b2) / b1\n            p_coeffs['p11'] = (-b2 / b1, c1 / b1)\n            # p22 = (c2 - alpha * b1) / b2\n            p_coeffs['p22'] = (-b1 / b2, c2 / b2)\n        else: # b2 is zero, let p22 be the free parameter\n            p_coeffs['p22'] = (1.0, 0.0)\n            p_coeffs['p11'] = (0.0, c1 / b1)\n            p_coeffs['p12'] = (0.0, c2 / b1)\n    else: # b1 is zero, so b2 must be non-zero, let p11 be the free parameter\n        p_coeffs['p11'] = (1.0, 0.0)\n        p_coeffs['p12'] = (0.0, c1 / b2)\n        p_coeffs['p22'] = (0.0, c2 / b2)\n\n    p11_m, p11_c = p_coeffs['p11']\n    p12_m, p12_c = p_coeffs['p12']\n    p22_m, p22_c = p_coeffs['p22']\n\n    # Aggregate linear inequalities to find the feasible interval for alpha\n    alpha_min, alpha_max = -np.inf, np.inf\n\n    # Helper function to update the interval [alpha_min, alpha_max]\n    def update_interval(m, c, is_gt):\n        nonlocal alpha_min, alpha_max\n        # m*alpha + c > 0 if is_gt, else m*alpha + c  0\n        if abs(m)  TOL:\n            return c > TOL if is_gt else c  -TOL\n        \n        root = -c / m\n        if is_gt: # m*alpha > -c\n            if m > 0: alpha_min = max(alpha_min, root)\n            else: alpha_max = min(alpha_max, root)\n        else: # m*alpha  -c\n            if m > 0: alpha_max = min(alpha_max, root)\n            else: alpha_min = max(alpha_min, root)\n        return True\n\n    # From P > 0: p11 > 0\n    if not update_interval(p11_m, p11_c, is_gt=True): return False\n\n    # From P > 0: det(P) > 0. This is linear in alpha.\n    det_P_m = p11_m * p22_c + p11_c * p22_m - 2 * p12_m * p12_c\n    det_P_c = p11_c * p22_c - p12_c**2\n    if not update_interval(det_P_m, det_P_c, is_gt=True): return False\n\n    # From Q = A'P + PA  0.\n    a11, a12, a21, a22 = A[0,0], A[0,1], A[1,0], A[1,1]\n    \n    # Coefficients for q_ij(alpha) = m * alpha + c\n    q11_m = 2 * (a11 * p11_m + a21 * p12_m)\n    q11_c = 2 * (a11 * p11_c + a21 * p12_c)\n    q22_m = 2 * (a12 * p12_m + a22 * p22_m)\n    q22_c = 2 * (a12 * p12_c + a22 * p22_c)\n    q12_m = a11 * p12_m + a12 * p11_m + a21 * p22_m + a22 * p12_m\n    q12_c = a11 * p12_c + a12 * p11_c + a21 * p22_c + a22 * p12_c\n\n    # From Q  0: q11  0\n    if not update_interval(q11_m, q11_c, is_gt=False): return False\n\n    # Check if a consistent interval for linear constraints exists\n    if alpha_min >= alpha_max - TOL:\n        return False\n        \n    # From Q  0: det(Q) > 0. This is a quadratic inequality.\n    # f(alpha) = k2*alpha^2 + k1*alpha + k0 > 0\n    k2 = q11_m * q22_m - q12_m**2\n    k1 = q11_m * q22_c + q11_c * q22_m - 2 * q12_m * q12_c\n    k0 = q11_c * q22_c - q12_c**2\n\n    if abs(k2)  TOL: # Linear or constant case for det(Q)\n        dummy_m, dummy_c = k1, k0\n        if abs(dummy_m)  TOL:\n            return dummy_c > TOL\n        \n        root = -dummy_c / dummy_m\n        if dummy_m > 0: # alpha > root\n            return max(alpha_min, root)  alpha_max - TOL\n        else: # alpha  root\n            return alpha_min  min(alpha_max, root) - TOL\n    else: # Quadratic case\n        delta = k1**2 - 4 * k2 * k0\n        if delta  -TOL:\n            return k2 > 0\n        else:\n            delta = max(0, delta) # Handle small negative delta from precision loss\n            sqrt_delta = np.sqrt(delta)\n            r1 = (-k1 - sqrt_delta) / (2 * k2)\n            r2 = (-k1 + sqrt_delta) / (2 * k2)\n            if r1 > r2: r1, r2 = r2, r1\n            \n            if k2 > 0: # f > 0 outside roots\n                overlap1 = alpha_min  min(alpha_max, r1) - TOL\n                overlap2 = max(alpha_min, r2)  alpha_max - TOL\n                return overlap1 or overlap2\n            else: # f > 0 between roots\n                intersect_min = max(alpha_min, r1)\n                intersect_max = min(alpha_max, r2)\n                return intersect_min  intersect_max - TOL\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2725781"}]}