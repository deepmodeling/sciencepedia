{"hands_on_practices": [{"introduction": "The power of Iterative Learning Control (ILC) and Repetitive Control (RC) stems from a simple, yet profound, mathematical principle: if each learning step contracts the error, the error will eventually vanish. This exercise establishes the fundamental building block for all convergence analysis. By deriving the relationship between the convergence rate $\\gamma$ and the number of trials $k$ needed to achieve a desired error reduction, you will gain a core intuition for the speed and guaranteed performance of any linearly convergent iterative process. [@problem_id:2714829]", "problem": "A discrete-time control system is operated repetitively on the same finite-time task. An Iterative Learning Control (ILC) scheme updates the control input from trial to trial. Let the trial-to-trial tracking error at the end of each trial be denoted by $e_{k}$, where $k \\in \\mathbb{N}_{0}$ is the trial index. Assume the learning update yields a linear error propagation of the form $e_{k+1} = \\mathcal{L}\\, e_{k}$, where $\\mathcal{L}$ is a bounded linear operator on a normed vector space with an induced norm satisfying $\\|\\mathcal{L}\\| \\leq \\gamma$ for some constant $0 < \\gamma < 1$. This same framework is used for Repetitive Control (RC) when interpreting $k$ as the period index.\n\nStarting from the submultiplicativity of induced norms and without invoking any specialized convergence result beyond basic properties of logarithms and norms, derive an inequality that relates the number of trials $k$ required to reduce the error norm by a factor $\\epsilon$ (with $0 < \\epsilon < 1$) to the iteration convergence factor $\\gamma$. Then, using your derived result, determine the smallest integer number of trials $k$ such that the error norm is reduced by at least a factor $\\epsilon$ when $\\gamma = 0.83$ and $\\epsilon = 0.01$.\n\nExpress your final answer as the minimal integer $k$ only. No rounding instructions are needed; choose the smallest integer that satisfies the requirement.", "solution": "The problem statement is first subjected to a rigorous validation process.\n\nThe givens extracted from the statement are as follows:\n- A discrete-time control system is described.\n- The system operates repetitively on a finite-time task.\n- An Iterative Learning Control (ILC) or Repetitive Control (RC) scheme is used.\n- The trial/period index is $k \\in \\mathbb{N}_{0}$.\n- The error at the end of trial $k$ is $e_k$, an element of a normed vector space.\n- The error propagation is governed by the linear relationship $e_{k+1} = \\mathcal{L}\\, e_{k}$.\n- $\\mathcal{L}$ is a bounded linear operator.\n- The induced norm of the operator satisfies $\\|\\mathcal{L}\\| \\leq \\gamma$.\n- The convergence factor $\\gamma$ is a constant such that $0 < \\gamma < 1$.\n- The required reduction in error norm is by a factor $\\epsilon$, where $0 < \\epsilon < 1$.\n- The derivation must start from the submultiplicativity of induced norms and use basic properties of logarithms and norms.\n- The final calculation requires finding the smallest integer $k$ for $\\gamma = 0.83$ and $\\epsilon = 0.01$.\n\nThe problem is assessed for validity. It is a standard problem in the analysis of linear iterative systems, common in control theory, specifically in the study of ILC and RC. The model $e_{k+1} = \\mathcal{L}\\, e_{k}$ with the condition $\\|\\mathcal{L}\\| < 1$ is the canonical form for demonstrating linear convergence. The problem is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. There are no contradictions, no reliance on pseudoscience, and no ambiguities. The problem is therefore deemed valid and a solution will be provided.\n\nThe task is to derive an inequality for the number of trials $k$ required to achieve an error norm reduction of at least a factor of $\\epsilon$, and then to compute this minimal integer $k$ for the given parameters.\n\nWe begin with the error propagation dynamics:\n$$\ne_{k+1} = \\mathcal{L}\\, e_{k}\n$$\nwhere $k$ is the trial index. We take the vector norm of both sides of this equation:\n$$\n\\|e_{k+1}\\| = \\|\\mathcal{L}\\, e_{k}\\|\n$$\nThe problem specifies that the norm is an induced norm. A fundamental property of an induced norm is its submultiplicativity, which states that for a linear operator $\\mathcal{L}$ and a vector $e_k$, the inequality $\\|\\mathcal{L}\\, e_k\\| \\leq \\|\\mathcal{L}\\| \\|e_k\\|$ holds. Applying this property, we get:\n$$\n\\|e_{k+1}\\| \\leq \\|\\mathcal{L}\\| \\|e_k\\|\n$$\nWe are given that $\\|\\mathcal{L}\\| \\leq \\gamma$. Substituting this into the inequality yields the fundamental recursive relationship for the error norm:\n$$\n\\|e_{k+1}\\| \\leq \\gamma \\|e_k\\|\n$$\nThis inequality relates the error norm at trial $k+1$ to the error norm at trial $k$. We can unroll this recursion to establish a relationship between the error at trial $k$ and the initial error at trial $0$, namely $\\|e_0\\|$.\n\nFor $k=1$:\n$$\n\\|e_1\\| \\leq \\gamma \\|e_0\\|\n$$\nFor $k=2$:\n$$\n\\|e_2\\| \\leq \\gamma \\|e_1\\| \\leq \\gamma (\\gamma \\|e_0\\|) = \\gamma^2 \\|e_0\\|\n$$\nBy mathematical induction, we can prove the general relationship $\\|e_k\\| \\leq \\gamma^k \\|e_0\\|$ for any integer $k \\geq 1$.\nThe base case for $k=1$ is shown above.\nAssume the hypothesis is true for some integer $j \\geq 1$, i.e., $\\|e_j\\| \\leq \\gamma^j \\|e_0\\|$.\nThen for $j+1$, we have:\n$$\n\\|e_{j+1}\\| \\leq \\gamma \\|e_j\\| \\leq \\gamma (\\gamma^j \\|e_0\\|) = \\gamma^{j+1} \\|e_0\\|\n$$\nThe hypothesis holds for $j+1$. Thus, the inequality $\\|e_k\\| \\leq \\gamma^k \\|e_0\\|$ is proven for all $k \\geq 1$.\n\nThe problem asks for the number of trials $k$ required to reduce the error norm by a factor $\\epsilon$. This is equivalent to finding $k$ such that the ratio of the error norm at trial $k$ to the initial error norm is less than or equal to $\\epsilon$. Assuming a non-trivial initial error, i.e., $\\|e_0\\| > 0$, this condition is:\n$$\n\\frac{\\|e_k\\|}{\\|e_0\\|} \\leq \\epsilon\n$$\nFrom our derived inequality, we have $\\frac{\\|e_k\\|}{\\|e_0\\|} \\leq \\gamma^k$. Therefore, a sufficient condition to satisfy the error reduction requirement is:\n$$\n\\gamma^k \\leq \\epsilon\n$$\nThis is a key inequality relating $k$, $\\gamma$, and $\\epsilon$. To solve for $k$, we use the properties of logarithms. We take the natural logarithm of both sides:\n$$\n\\ln(\\gamma^k) \\leq \\ln(\\epsilon)\n$$\nUsing the logarithm power rule, $\\ln(a^b) = b \\ln(a)$, we obtain:\n$$\nk \\ln(\\gamma) \\leq \\ln(\\epsilon)\n$$\nTo isolate $k$, we must divide by $\\ln(\\gamma)$. It is given that $0 < \\gamma < 1$, which implies that $\\ln(\\gamma)$ is a negative number. Dividing an inequality by a negative number reverses the direction of the inequality sign.\n$$\nk \\geq \\frac{\\ln(\\epsilon)}{\\ln(\\gamma)}\n$$\nThis is the general inequality relating the number of trials $k$ to the convergence factor $\\gamma$ and the desired error reduction factor $\\epsilon$.\n\nWe now proceed to the second part of the problem: to calculate the smallest integer number of trials $k$ for the specific values $\\gamma = 0.83$ and $\\epsilon = 0.01$.\nSubstituting these values into the derived inequality:\n$$\nk \\geq \\frac{\\ln(0.01)}{\\ln(0.83)}\n$$\nThe values of the logarithms are:\n$$\n\\ln(0.01) = \\ln(10^{-2}) = -2 \\ln(10) \\approx -4.605170185988092\n$$\n$$\n\\ln(0.83) \\approx -0.186320953188556\n$$\nThe ratio is:\n$$\n\\frac{\\ln(0.01)}{\\ln(0.83)} \\approx \\frac{-4.605170185988092}{-0.186320953188556} \\approx 24.71618...\n$$\nSo, the condition on $k$ is:\n$$\nk \\geq 24.71618...\n$$\nThe problem demands the smallest integer $k$ that satisfies this condition. Since $k$ must be an integer, we must choose the smallest integer greater than or equal to $24.71618...$, which is $25$. This operation is mathematically equivalent to the ceiling function, $\\lceil 24.71618... \\rceil = 25$.\n\nTherefore, a minimum of $25$ trials is required to guarantee that the error norm is reduced by at least a factor of $0.01$.", "answer": "$$\n\\boxed{25}\n$$", "id": "2714829"}, {"introduction": "To apply ILC to real-world, finite-duration tasks, we often represent the system's entire trial-by-trial dynamics using a single matrix equation, a technique known as \"lifting\". This practice moves from the abstract convergence condition to a concrete analysis in this lifted-system framework. You will explore monotonic convergence in the $\\ell_\\infty$ norm, which corresponds to ensuring the peak error across the trial decreases with every iteration, and derive the exact range of learning gains that guarantees this desirable behavior. [@problem_id:2714828]", "problem": "Consider a Single-Input Single-Output (SISO) Iterative Learning Control (ILC) setup over a finite horizon of length $N=2$, with the lifted input-output map represented by a lower-triangular Toeplitz matrix $G \\in \\mathbb{R}^{2 \\times 2}$ formed from the plant’s first two Markov parameters. Let\n$$\nG \\;=\\; \\begin{pmatrix} g_0 & 0 \\\\\ng_1 & g_0 \\end{pmatrix},\n$$\nwith $g_0 = 0.8$ and $g_1 = 0.3$. The ILC learning update is $u_{k+1} = u_k + L e_k$, where $L \\in \\mathbb{R}^{2 \\times 2}$ is the learning filter, $u_k \\in \\mathbb{R}^2$ is the $k$-th trial input, and $e_k \\in \\mathbb{R}^2$ is the $k$-th trial tracking error. Assume a repeatable reference so that the trial-to-trial error propagation is given by the lifted linear map\n$$\ne_{k+1} \\;=\\; \\left( I - G L \\right) e_k.\n$$\nYou are to analyze monotonic convergence in the $\\ell_\\infty$ sense and contrast it with the $\\ell_2$ sense, starting only from the definitions of induced norms and fundamental norm properties. In particular:\n\n1. Using only the definition of the induced vector norm and submultiplicativity, derive a sufficient condition on $L$ that guarantees the monotone bound\n$$\n\\| e_{k+1} \\|_\\infty \\;\\le\\; \\gamma \\, \\| e_k \\|_\\infty \\quad \\text{with} \\quad \\gamma < 1,\n$$\nin terms of the induced $\\ell_\\infty$ matrix norm of $I - G L$.\n\n2. Specialize to the scalar-gain learning filter $L = \\alpha I$, with $\\alpha \\in \\mathbb{R}$. Derive the condition on $\\alpha$ that enforces $\\| I - G L \\|_\\infty < 1$ by explicitly computing the induced $\\ell_\\infty$ norm of $I - \\alpha G$ from first principles.\n\n3. For the specific numerical values $g_0 = 0.8$ and $g_1 = 0.3$, determine the supremum scalar gain\n$$\n\\alpha_\\star \\;=\\; \\sup \\left\\{ \\alpha > 0 \\;:\\; \\| I - \\alpha G \\|_\\infty < 1 \\right\\}.\n$$\nReport your final answer for $\\alpha_\\star$ as an exact value (no rounding).\n\n4. Briefly explain, without computing a numerical value, how the analogous $\\ell_2$-monotonicity condition would be posed in terms of the induced $\\ell_2$ norm, and why it can be less conservative or more conservative than the $\\ell_\\infty$-based condition depending on $G$.\n\nYour final answer must be the single exact value of $\\alpha_\\star$ with no units and no rounding instructions required.", "solution": "We begin by validating the problem. The problem statement is situated within the standard theoretical framework of Iterative Learning Control (ILC) for discrete-time, linear time-invariant systems. All components—the lifted system representation using a Toeplitz matrix of Markov parameters, the P-type ILC update law, the resulting error dynamics, and the analysis of convergence using induced matrix norms—are canonical concepts in this field. The provided numerical values are physically plausible. The problem is self-contained, unambiguous, and mathematically well-posed. The problem is therefore valid, and we may proceed to the solution.\n\nThe problem is addressed in four parts as requested.\n\n1. The trial-to-trial error propagation dynamics are given by the linear map\n$$\ne_{k+1} \\;=\\; (I - G L) e_k.\n$$\nTo establish a condition for monotonic convergence in the $\\ell_\\infty$ norm, we take the $\\ell_\\infty$ norm of both sides of this equation:\n$$\n\\| e_{k+1} \\|_\\infty \\;=\\; \\| (I - G L) e_k \\|_\\infty.\n$$\nBy the definition of an induced matrix norm, for any vector $x$ and matrix $A$, we have the inequality $\\|Ax\\| \\le \\|A\\| \\|x\\|$. Applying this property to our expression yields\n$$\n\\| (I - G L) e_k \\|_\\infty \\;\\le\\; \\| I - G L \\|_\\infty \\| e_k \\|_\\infty.\n$$\nCombining the previous steps, we obtain the bound\n$$\n\\| e_{k+1} \\|_\\infty \\;\\le\\; \\| I - G L \\|_\\infty \\| e_k \\|_\\infty.\n$$\nThe problem requires finding a condition that guarantees $\\| e_{k+1} \\|_\\infty \\le \\gamma \\| e_k \\|_\\infty$ for some constant $\\gamma < 1$. By inspection of the derived bound, this is satisfied if we choose $\\gamma = \\| I - G L \\|_\\infty$. Therefore, the sufficient condition for monotonic convergence in the $\\ell_\\infty$ sense is\n$$\n\\| I - G L \\|_\\infty < 1.\n$$\n\n2. We now specialize to the case of a scalar learning gain, $L = \\alpha I$, where $\\alpha \\in \\mathbb{R}$ is a scalar and $I$ is the $2 \\times 2$ identity matrix. The convergence condition becomes $\\| I - \\alpha G \\|_\\infty < 1$. Let us compute the matrix $I - \\alpha G$:\n$$\nI - \\alpha G \\;=\\; \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\alpha \\begin{pmatrix} g_0 & 0 \\\\ g_1 & g_0 \\end{pmatrix} \\;=\\; \\begin{pmatrix} 1 - \\alpha g_0 & 0 \\\\ -\\alpha g_1 & 1 - \\alpha g_0 \\end{pmatrix}.\n$$\nThe induced $\\ell_\\infty$ matrix norm, also known as the maximum absolute row sum norm, is defined for a matrix $A$ as $\\|A\\|_\\infty = \\max_{i} \\sum_{j} |A_{ij}|$. We apply this definition to the matrix $I - \\alpha G$.\nThe absolute sum of the elements in the first row is:\n$$\n|1 - \\alpha g_0| + |0| \\;=\\; |1 - \\alpha g_0|.\n$$\nThe absolute sum of the elements in the second row is:\n$$\n|-\\alpha g_1| + |1 - \\alpha g_0| \\;=\\; |\\alpha| |g_1| + |1 - \\alpha g_0|.\n$$\nThe $\\ell_\\infty$ norm is the maximum of these two row sums:\n$$\n\\|I - \\alpha G\\|_\\infty \\;=\\; \\max \\left( |1 - \\alpha g_0|, \\;\\; |\\alpha| |g_1| + |1 - \\alpha g_0| \\right).\n$$\nSince $|\\alpha| |g_1| \\ge 0$, the second term is always greater than or equal to the first term. Thus, the maximum is always given by the second row sum:\n$$\n\\|I - \\alpha G\\|_\\infty \\;=\\; |1 - \\alpha g_0| + |\\alpha| |g_1|.\n$$\nThe condition for monotonic convergence is therefore $|1 - \\alpha g_0| + |\\alpha| |g_1| < 1$.\n\n3. We are asked to find $\\alpha_\\star = \\sup \\{ \\alpha > 0 : \\| I - \\alpha G \\|_\\infty < 1 \\}$ for the specific values $g_0 = 0.8$ and $g_1 = 0.3$. Since we seek $\\alpha > 0$, the expression $|\\alpha|$ simplifies to $\\alpha$. The convergence condition becomes:\n$$\n|1 - 0.8 \\alpha| + 0.3 \\alpha < 1.\n$$\nTo solve this inequality, we must resolve the absolute value by considering the sign of its argument, $1 - 0.8 \\alpha$. The term is zero when $0.8 \\alpha = 1$, which corresponds to $\\alpha = 1 / 0.8 = 1.25$. We analyze two cases for $\\alpha > 0$.\nCase 1: $0 < \\alpha \\le 1.25$.\nIn this interval, $1 - 0.8 \\alpha \\ge 0$, so $|1 - 0.8 \\alpha| = 1 - 0.8 \\alpha$. The inequality is:\n$$\n(1 - 0.8 \\alpha) + 0.3 \\alpha < 1\n$$\n$$\n1 - 0.5 \\alpha < 1\n$$\n$$\n-0.5 \\alpha < 0\n$$\nThis implies $\\alpha > 0$. The solution for this case is the intersection of the domain $0 < \\alpha \\le 1.25$ and the result $\\alpha > 0$, which is the interval $(0, 1.25]$.\n\nCase 2: $\\alpha > 1.25$.\nIn this interval, $1 - 0.8 \\alpha < 0$, so $|1 - 0.8 \\alpha| = -(1 - 0.8 \\alpha) = 0.8 \\alpha - 1$. The inequality is:\n$$\n(0.8 \\alpha - 1) + 0.3 \\alpha < 1\n$$\n$$\n1.1 \\alpha - 1 < 1\n$$\n$$\n1.1 \\alpha < 2\n$$\nThis implies $\\alpha < \\frac{2}{1.1} = \\frac{20}{11}$. The solution for this case is the intersection of the domain $\\alpha > 1.25$ and the result $\\alpha < 20/11$. Note that $1.25 = 5/4$ and $20/11 \\approx 1.818$, so $1.25 < 20/11$. The interval is $(1.25, 20/11)$.\n\nCombining the results from both cases, the set of all positive $\\alpha$ satisfying the convergence condition is the union $(0, 1.25] \\cup (1.25, 20/11)$, which is the open interval $(0, 20/11)$.\nThe supremum of this set is the upper bound of the interval. Therefore,\n$$\n\\alpha_\\star \\;=\\; \\sup \\left( 0, \\frac{20}{11} \\right) \\;=\\; \\frac{20}{11}.\n$$\n\n4. The analogous condition for monotonic convergence in the $\\ell_2$ sense is $\\| I - G L \\|_2 < 1$, where $\\| \\cdot \\|_2$ denotes the induced matrix $2$-norm (the spectral norm). For $L = \\alpha I$, this becomes $\\| I - \\alpha G \\|_2 < 1$. The induced $2$-norm of a matrix $A$ is its largest singular value, $\\sigma_{\\max}(A)$, which is the square root of the largest eigenvalue of $A^T A$. Thus, the condition is $\\sigma_{\\max}(I - \\alpha G) < 1$.\n\nThe relative conservativeness of the $\\ell_\\infty$ and $\\ell_2$ conditions depends on the specific matrix $G$. For any matrix $A \\in \\mathbb{R}^{n \\times n}$, the induced norms are related by inequalities such as $\\|A\\|_2 \\le \\sqrt{n} \\|A\\|_\\infty$ and $\\|A\\|_\\infty \\le \\sqrt{n} \\|A\\|_2$, but there is no universal ordering between $\\|A\\|_2$ and $\\|A\\|_\\infty$. One can be larger, smaller, or equal to the other depending on the structure of $A$. Consequently, for a given $G$ and $\\alpha$, it is possible to have $\\|I - \\alpha G\\|_\\infty < 1$ while $\\|I - \\alpha G\\|_2 \\ge 1$, which would mean the $\\ell_2$ condition is more conservative for that $\\alpha$. Conversely, it is also possible that $\\|I - \\alpha G\\|_2 < 1$ while $\\|I - \\alpha G\\|_\\infty \\ge 1$, meaning the $\\ell_\\infty$ condition is more conservative. The choice of norm dictates the shape and size of the set of gains $\\alpha$ that guarantee monotonic convergence, and neither the $\\ell_2$ nor the $\\ell_\\infty$ condition is universally less conservative than the other. The comparison depends entirely on the numerical properties of the matrix $I - \\alpha G$.", "answer": "$$\n\\boxed{\\frac{20}{11}}\n$$", "id": "2714828"}, {"introduction": "For tasks that are periodic, such as tracking a repeating trajectory, a frequency-domain perspective offers powerful insights. In this view, the ILC or RC controller acts like a \"comb filter,\" selectively learning to cancel errors at the specific frequencies present in the periodic reference signal. This hands-on practice guides you through the process of calculating the steady-state error attenuation at each harmonic, revealing how the choice of learning filter $Q(z)$ directly shapes the ultimate tracking performance. [@problem_id:2714809]", "problem": "Consider a single-input single-output discrete-time system performing a repetitive task of known period $N \\in \\mathbb{Z}_{>0}$ samples. Let the plant be linear time-invariant with frequency response $G(\\exp(j\\omega)) \\equiv 1$ for all $\\omega \\in [-\\pi,\\pi]$. The reference $r[n]$ is $N$-periodic with discrete-time Fourier series coefficients $R(\\exp(j\\omega_k))$ at the harmonics $\\omega_k = 2\\pi k/N$ for $k \\in \\{0,1,\\dots,N-1\\}$. The control input on trial $j$ is $u_j[n]$, and the output is $y_j[n] = u_j[n]$, so the tracking error is $e_j[n] = r[n] - y_j[n]$. The controller implements Iterative Learning Control (ILC), using the standard lifted-time update\n$\nu_{j+1}[n] = \\left(Q(q^{-1}) u_j\\right)[n] + e_j[n],\n$\nwhere $q^{-1}$ is the unit delay and the learning filter $Q(z)$ is a real, symmetric finite impulse response filter given by\n$\nQ(z) = \\tfrac{1}{2} + \\tfrac{1}{4} z + \\tfrac{1}{4} z^{-1}.\n$\nBecause the task is periodic and the controller operates trial-to-trial, you may analyze each harmonic independently in the frequency domain. Assume the iteration converges to a steady state across trials.\n\nDerive, from first principles using only the definitions above and standard properties of linear time-invariant systems and the discrete-time Fourier transform, the steady-state error spectrum magnitude at the task harmonics. Specifically, obtain a closed-form expression for the harmonic-wise attenuation factor $A_k$ defined by\n$\nA_k \\triangleq \\frac{|E_{\\infty}(\\exp(j\\omega_k))|}{|R(\\exp(j\\omega_k))|},\n$\nas an explicit function of $k$ and $N$, where $\\omega_k = 2\\pi k/N$. Express your final answer as a single simplified analytic expression in terms of $k$ and $N$ only (no units). Also, in your derivation, quantify the attenuation as a function of $|Q(\\exp(j\\omega_k))|$ before substituting the specific $Q(z)$ given.\n\nNo numerical evaluation is required. Provide your final expression for $A_k$ in closed form.", "solution": "The problem statement is first subjected to validation.\n\n**Step 1: Extract Givens**\n- System type: Single-input single-output (SISO) discrete-time, linear time-invariant (LTI).\n- Task period: $N \\in \\mathbb{Z}_{>0}$ samples.\n- Plant frequency response: $G(\\exp(j\\omega)) = 1$ for all $\\omega \\in [-\\pi,\\pi]$.\n- Reference signal: $r[n]$, $N$-periodic with discrete-time Fourier series (DTFS) coefficients $R(\\exp(j\\omega_k))$ at harmonics $\\omega_k = 2\\pi k/N$ for $k \\in \\{0, 1, \\dots, N-1\\}$.\n- Control input at trial $j$: $u_j[n]$.\n- System output at trial $j$: $y_j[n] = u_j[n]$.\n- Tracking error at trial $j$: $e_j[n] = r[n] - y_j[n]$.\n- Iterative Learning Control (ILC) update law: $u_{j+1}[n] = (Q(q^{-1}) u_j)[n] + e_j[n]$.\n- Learning filter: $Q(z) = \\frac{1}{2} + \\frac{1}{4} z + \\frac{1}{4} z^{-1}$, a real, symmetric FIR filter.\n- Assumption: The iteration converges to a steady state as trial index $j \\to \\infty$.\n- Objective: Derive the steady-state harmonic-wise attenuation factor $A_k \\triangleq \\frac{|E_{\\infty}(\\exp(j\\omega_k))|}{|R(\\exp(j\\omega_k))|}$ as a function of $k$ and $N$. An intermediate step requires expressing this attenuation as a function of $Q(\\exp(j\\omega_k))$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded within the field of control theory, specifically concerning iterative learning control. All terms are standard and well-defined. The plant model $G(\\exp(j\\omega)) = 1$ is an idealization but serves as a valid simplification for theoretical analysis of the learning process itself. The problem is self-contained, providing all necessary equations and definitions. It is well-posed, as the assumption of convergence ensures a unique steady-state solution can be found. The language is objective and precise. The problem does not violate any of the criteria for invalidity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Derivation**\nThe analysis is performed in the frequency domain at the task harmonics $\\omega_k = 2\\pi k/N$. Let the DTFS coefficients of the signals $u_j[n]$, $y_j[n]$, $e_j[n]$, and $r[n]$ at frequency $\\omega_k$ be denoted by $U_j(\\exp(j\\omega_k))$, $Y_j(\\exp(j\\omega_k))$, $E_j(\\exp(j\\omega_k))$, and $R(\\exp(j\\omega_k))$, respectively.\n\nFirst, we express the system dynamics and the ILC update law in the frequency domain. The plant dynamics are given by $y_j[n] = u_j[n]$, which in the frequency domain becomes:\n$$Y_j(\\exp(j\\omega_k)) = U_j(\\exp(j\\omega_k))$$\nThe tracking error is $e_j[n] = r[n] - y_j[n]$, which transforms to:\n$$E_j(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) - Y_j(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) - U_j(\\exp(j\\omega_k))$$\nThe ILC update law is $u_{j+1}[n] = (Q(q^{-1}) u_j)[n] + e_j[n]$. Applying the DTFS, the convolution operation $(Q(q^{-1})u_j)[n]$ becomes a multiplication in the frequency domain:\n$$U_{j+1}(\\exp(j\\omega_k)) = Q(\\exp(j\\omega_k)) U_j(\\exp(j\\omega_k)) + E_j(\\exp(j\\omega_k))$$\nTo analyze the evolution of the control input across trials, we substitute the expression for the error spectrum $E_j(\\exp(j\\omega_k))$:\n$$U_{j+1}(\\exp(j\\omega_k)) = Q(\\exp(j\\omega_k)) U_j(\\exp(j\\omega_k)) + \\left( R(\\exp(j\\omega_k)) - U_j(\\exp(j\\omega_k)) \\right)$$\n$$U_{j+1}(\\exp(j\\omega_k)) = \\left( Q(\\exp(j\\omega_k)) - 1 \\right) U_j(\\exp(j\\omega_k)) + R(\\exp(j\\omega_k))$$\nThis is a first-order linear difference equation for the harmonic component $U_j(\\exp(j\\omega_k))$ with respect to the trial index $j$.\n\nThe problem assumes that the iteration converges, meaning that as $j \\to \\infty$, the control input spectrum approaches a steady-state value, $U_j(\\exp(j\\omega_k)) \\to U_{\\infty}(\\exp(j\\omega_k))$. In this steady state, $U_{j+1} = U_j = U_{\\infty}$. We can solve for $U_{\\infty}(\\exp(j\\omega_k))$:\n$$U_{\\infty}(\\exp(j\\omega_k)) = \\left( Q(\\exp(j\\omega_k)) - 1 \\right) U_{\\infty}(\\exp(j\\omega_k)) + R(\\exp(j\\omega_k))$$\n$$U_{\\infty}(\\exp(j\\omega_k)) - \\left( Q(\\exp(j\\omega_k)) - 1 \\right) U_{\\infty}(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k))$$\n$$U_{\\infty}(\\exp(j\\omega_k)) \\left( 1 - Q(\\exp(j\\omega_k)) + 1 \\right) = R(\\exp(j\\omega_k))$$\n$$U_{\\infty}(\\exp(j\\omega_k)) = \\frac{R(\\exp(j\\omega_k))}{2 - Q(\\exp(j\\omega_k))}$$\nNow, we find the steady-state error spectrum, $E_{\\infty}(\\exp(j\\omega_k))$:\n$$E_{\\infty}(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) - U_{\\infty}(\\exp(j\\omega_k))$$\n$$E_{\\infty}(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) - \\frac{R(\\exp(j\\omega_k))}{2 - Q(\\exp(j\\omega_k))}$$\n$$E_{\\infty}(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) \\left( 1 - \\frac{1}{2 - Q(\\exp(j\\omega_k))} \\right)$$\n$$E_{\\infty}(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) \\left( \\frac{2 - Q(\\exp(j\\omega_k)) - 1}{2 - Q(\\exp(j\\omega_k))} \\right)$$\n$$E_{\\infty}(\\exp(j\\omega_k)) = R(\\exp(j\\omega_k)) \\left( \\frac{1 - Q(\\exp(j\\omega_k))}{2 - Q(\\exp(j\\omega_k))} \\right)$$\nThe harmonic-wise attenuation factor $A_k$ is defined as the ratio of the magnitudes of the steady-state error spectrum and the reference spectrum:\n$$A_k = \\frac{|E_{\\infty}(\\exp(j\\omega_k))|}{|R(\\exp(j\\omega_k))|} = \\left| \\frac{1 - Q(\\exp(j\\omega_k))}{2 - Q(\\exp(j\\omega_k))} \\right|$$\nThis expression quantifies the attenuation as a function of the filter's frequency response $Q(\\exp(j\\omega_k))$, as requested.\n\nNext, we substitute the specific learning filter $Q(z) = \\frac{1}{2} + \\frac{1}{4} z + \\frac{1}{4} z^{-1}$. Its frequency response at $\\omega_k$ is:\n$$Q(\\exp(j\\omega_k)) = \\frac{1}{2} + \\frac{1}{4} \\exp(j\\omega_k) + \\frac{1}{4} \\exp(-j\\omega_k)$$\nUsing Euler's identity $\\cos(\\theta) = \\frac{\\exp(j\\theta) + \\exp(-j\\theta)}{2}$, we get:\n$$Q(\\exp(j\\omega_k)) = \\frac{1}{2} + \\frac{1}{2} \\cos(\\omega_k)$$\nSince $\\omega_k$ is a real frequency, $\\cos(\\omega_k)$ is real and ranges from $-1$ to $1$. Thus, $Q(\\exp(j\\omega_k))$ is a real value in the range $[0, 1]$. Let $Q_k = Q(\\exp(j\\omega_k))$.\nSince $0 \\le Q_k \\le 1$, the numerator of the attenuation expression, $1 - Q_k$, is non-negative ($0 \\le 1-Q_k \\le 1$). The denominator, $2 - Q_k$, is strictly positive ($1 \\le 2-Q_k \\le 2$). Therefore, the absolute value is not necessary:\n$$A_k = \\frac{1 - Q_k}{2 - Q_k} = \\frac{1 - \\left(\\frac{1}{2} + \\frac{1}{2}\\cos(\\omega_k)\\right)}{2 - \\left(\\frac{1}{2} + \\frac{1}{2}\\cos(\\omega_k)\\right)} = \\frac{\\frac{1}{2} - \\frac{1}{2}\\cos(\\omega_k)}{\\frac{3}{2} - \\frac{1}{2}\\cos(\\omega_k)} = \\frac{1 - \\cos(\\omega_k)}{3 - \\cos(\\omega_k)}$$\nTo obtain a more simplified form, we use the half-angle trigonometric identity $1 - \\cos(\\theta) = 2\\sin^{2}(\\theta/2)$.\nThe numerator becomes:\n$$1 - \\cos(\\omega_k) = 2\\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)$$\nThe denominator becomes:\n$$3 - \\cos(\\omega_k) = 3 - \\left(1 - 2\\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)\\right) = 2 + 2\\sin^{2}\\left(\\frac{\\omega_k}{2}\\right) = 2\\left(1 + \\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)\\right)$$\nSubstituting these into the expression for $A_k$:\n$$A_k = \\frac{2\\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)}{2\\left(1 + \\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)\\right)} = \\frac{\\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)}{1 + \\sin^{2}\\left(\\frac{\\omega_k}{2}\\right)}$$\nFinally, we substitute $\\omega_k = \\frac{2\\pi k}{N}$, which gives $\\frac{\\omega_k}{2} = \\frac{\\pi k}{N}$. The final expression for the attenuation factor $A_k$ as a function of $k$ and $N$ is:\n$$A_k = \\frac{\\sin^{2}\\left(\\frac{\\pi k}{N}\\right)}{1 + \\sin^{2}\\left(\\frac{\\pi k}{N}\\right)}$$\nThis is the required closed-form expression.", "answer": "$$\\boxed{\\frac{\\sin^{2}\\left(\\frac{\\pi k}{N}\\right)}{1 + \\sin^{2}\\left(\\frac{\\pi k}{N}\\right)}}$$", "id": "2714809"}]}