{"hands_on_practices": [{"introduction": "The heart of extremum seeking control is its ability to estimate the gradient of an unknown function without a direct model. This first exercise is a foundational analysis that demystifies this process. By applying Taylor series expansions and averaging theory to a canonical ESC loop, you will derive the system's effective dynamics and reveal how it emulates a gradient descent algorithm [@problem_id:2706287].", "problem": "Consider a classical single-input single-output extremum seeking control (ESC) loop for minimizing an unknown smooth static map. The plant output is modeled as $y(t) = J(\\theta(t))$, where $J \\in C^{3}(\\mathbb{R}, \\mathbb{R})$ has a unique nondegenerate minimizer at $\\theta^{\\star}$ with $J'(\\theta^{\\star}) = 0$ and $J''(\\theta^{\\star}) > 0$. The ESC loop injects a sinusoidal dither at the plant input and demodulates the output as follows:\n- The plant input is $\\theta(t) = u(t) + a \\sin(\\omega t)$ with $a > 0$ and $\\omega > 0$.\n- The plant output $y(t)$ is passed through a high-pass filter $F(s) = \\dfrac{s}{s + \\omega_{h}}$ with $\\omega_{h} > 0$, producing $r(t)$.\n- The signal $r(t)$ is multiplied by the reference $\\sin(\\omega t + \\phi)$, where $\\phi \\in \\mathbb{R}$ is a constant demodulation phase specified in radians.\n- The product is passed through a low-pass filter $G(s) = \\dfrac{\\omega_{\\ell}}{s + \\omega_{\\ell}}$ with $\\omega_{\\ell} > 0$, producing $v(t)$.\n- The adaptation law is the integrator $\\dot{u}(t) = -k\\,v(t)$ with $k > 0$.\n\nAssume standard ESC scale separation: $a$ is sufficiently small, $\\omega$ is sufficiently large such that averaging is valid, $\\omega_{\\ell} \\ll \\omega$ so that $G(s)$ passes the direct-current component and attenuates harmonics near $\\omega$ and above, and the high-pass filter $F(s)$ has steady-state sinusoidal frequency response values $F(\\mathrm{j}\\omega)$ well defined at the dither frequency.\n\nUsing only first principles (Taylor expansion, linear time-invariant sinusoidal steady-state response, trigonometric identities, and averaging), derive the leading-order averaged slow dynamics in the form\n$$\n\\dot{\\bar{u}}(t) \\;=\\; -k\\,K_{\\mathrm{eff}}\\,J'\\big(\\bar{u}(t)\\big) \\;+\\; \\text{higher-order terms in } a,\n$$\nand determine a closed-form expression for the effective scalar gain $K_{\\mathrm{eff}}$ as a function of $a$, $\\omega$, $\\omega_{h}$, and $\\phi$. You may treat the direct-current gain of $G(s)$ as $1$, i.e., $G(0) = 1$. Ignore all contributions that are higher than first order in $a$ after averaging. Provide your final result for $K_{\\mathrm{eff}}$ as a single simplified analytic expression. No numerical approximation is required.", "solution": "We begin by conducting a formal validation of the problem statement.\n\nFirst, we extract the givens verbatim:\n- Plant output model: $y(t) = J(\\theta(t))$\n- Properties of the static map: $J \\in C^{3}(\\mathbb{R}, \\mathbb{R})$ has a unique nondegenerate minimizer at $\\theta^{\\star}$ with $J'(\\theta^{\\star}) = 0$ and $J''(\\theta^{\\star}) > 0$.\n- Plant input signal: $\\theta(t) = u(t) + a \\sin(\\omega t)$, with $a > 0$ and $\\omega > 0$.\n- High-pass filter: $F(s) = \\dfrac{s}{s + \\omega_{h}}$ with $\\omega_{h} > 0$. The output is $r(t)$.\n- Demodulation signal: $\\sin(\\omega t + \\phi)$, with $\\phi \\in \\mathbb{R}$.\n- Low-pass filter: $G(s) = \\dfrac{\\omega_{\\ell}}{s + \\omega_{\\ell}}$ with $\\omega_{\\ell} > 0$. The output is $v(t)$.\n- Adaptation law: $\\dot{u}(t) = -k\\,v(t)$ with $k > 0$.\n- Assumptions: $a$ is small, $\\omega$ is large, $\\omega_{\\ell} \\ll \\omega$, the DC gain of $G(s)$ is $G(0)=1$, and $F(\\mathrm{j}\\omega)$ is well-defined.\n- Objective: Derive the averaged slow dynamics $\\dot{\\bar{u}}(t) = -k\\,K_{\\mathrm{eff}}\\,J'(\\bar{u}(t)) + \\text{h.o.t.}$ and find a closed-form expression for $K_{\\mathrm{eff}}$.\n\nNext, we validate the problem.\nThe problem is scientifically grounded, describing a standard extremum seeking control loop, a well-established topic in control theory. The components (filters, dither signal, adaptation law) and the analysis method (averaging) are canonical. The problem is well-posed; the scale separation assumptions are standard and necessary to make the averaging analysis tractable and to yield a unique leading-order dynamic model. The language is objective and mathematically precise. The setup is self-contained and free of contradictions. The problem does not violate any of the specified invalidity criteria.\n\nThe problem is therefore deemed valid. We may proceed with the solution.\n\nThe analysis hinges on the principle of averaging, for which we assume a time-scale separation where $u(t)$ is a slowly varying signal, denoted as $\\bar{u}(t)$, compared to the high-frequency dither $\\sin(\\omega t)$.\n\nFirst, we perform a Taylor series expansion of the plant output $y(t) = J(\\theta(t))$ around the slowly varying component $\\bar{u}(t)$.\n$$\ny(t) = J(\\bar{u}(t) + a \\sin(\\omega t)) = J(\\bar{u}(t)) + J'(\\bar{u}(t)) [a \\sin(\\omega t)] + \\frac{1}{2} J''(\\bar{u}(t)) [a \\sin(\\omega t)]^2 + O(a^3)\n$$\nUsing the identity $\\sin^2(x) = \\frac{1}{2}(1 - \\cos(2x))$, the expansion becomes:\n$$\ny(t) = J(\\bar{u}(t)) + a J'(\\bar{u}(t)) \\sin(\\omega t) + \\frac{a^2}{4} J''(\\bar{u}(t)) (1 - \\cos(2\\omega t)) + O(a^3)\n$$\n$$\ny(t) = \\left( J(\\bar{u}(t)) + \\frac{a^2}{4} J''(\\bar{u}(t)) \\right) + a J'(\\bar{u}(t)) \\sin(\\omega t) - \\frac{a^2}{4} J''(\\bar{u}(t)) \\cos(2\\omega t) + O(a^3)\n$$\nThis output signal $y(t)$ consists of a DC (or slowly varying) part, a component at the dither frequency $\\omega$, and a component at frequency $2\\omega$, plus higher-order terms.\n\nSecond, this signal is passed through the high-pass filter $F(s) = \\frac{s}{s+\\omega_h}$. The DC component is blocked since $F(0)=0$. We analyze the filter's steady-state response to the sinusoidal component at frequency $\\omega$, which is $a J'(\\bar{u}(t)) \\sin(\\omega t)$. The frequency response of the filter is $F(\\mathrm{j}\\omega)$. We express it in polar form:\n$$\nF(\\mathrm{j}\\omega) = \\frac{\\mathrm{j}\\omega}{\\omega_h + \\mathrm{j}\\omega}\n$$\nThe magnitude is $|F(\\mathrm{j}\\omega)| = \\frac{|\\mathrm{j}\\omega|}{|\\omega_h + \\mathrm{j}\\omega|} = \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}}$.\nThe phase is $\\angle F(\\mathrm{j}\\omega) = \\angle(\\mathrm{j}\\omega) - \\angle(\\omega_h + \\mathrm{j}\\omega) = \\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{\\omega_h}\\right)$.\n\nThe component of the filter's output $r(t)$ at frequency $\\omega$ is therefore:\n$$\nr_{\\omega}(t) = a J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\sin(\\omega t + \\angle F(\\mathrm{j}\\omega))\n$$\nThe terms at frequency $2\\omega$ and higher are also passed, but they will be removed by the subsequent low-pass filtering and averaging, so we do not need to track them for the leading-order analysis.\n\nThird, the signal $r(t)$ is multiplied by the demodulation signal $\\sin(\\omega t + \\phi)$. We are interested in the DC component of this product. Let $p(t) = r(t) \\sin(\\omega t + \\phi)$. The dominant terms contributing to the average are from $r_{\\omega}(t)$:\n$$\np(t) \\approx r_{\\omega}(t) \\sin(\\omega t + \\phi) = a J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\sin(\\omega t + \\angle F(\\mathrm{j}\\omega)) \\sin(\\omega t + \\phi)\n$$\nUsing the trigonometric identity $\\sin(A)\\sin(B) = \\frac{1}{2}[\\cos(A-B) - \\cos(A+B)]$:\n$$\np(t) = \\frac{a}{2} J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\left[ \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi) - \\cos(2\\omega t + \\angle F(\\mathrm{j}\\omega) + \\phi) \\right]\n$$\nThis product signal $p(t)$ has a DC component and a high-frequency component at $2\\omega$.\n\nFourth, this signal $p(t)$ is passed through the low-pass filter $G(s) = \\frac{\\omega_{\\ell}}{s+\\omega_{\\ell}}$. Given the assumption $\\omega_{\\ell} \\ll \\omega$, this filter attenuates the high-frequency component at $2\\omega$ and passes the DC component. The DC gain of the filter is given as $G(0)=1$. The output $v(t)$ of the low-pass filter is approximately the DC component of its input $p(t)$. By the principle of averaging, the slowly varying part of $v(t)$, denoted $\\bar{v}(t)$, is the average of $p(t)$:\n$$\n\\bar{v}(t) = \\text{avg}[p(t)] = \\frac{a}{2} J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi)\n$$\nAll other terms originating from the Taylor expansion of $y(t)$ are of higher order in $a$ or are at high frequencies that are averaged to zero.\n\nFinally, we find the averaged dynamics for $\\bar{u}(t)$. The adaptation law is $\\dot{u}(t) = -k v(t)$. Applying the averaging theorem, the evolution of the slow variable $\\bar{u}(t)$ is governed by:\n$$\n\\dot{\\bar{u}}(t) = -k \\bar{v}(t) = -k \\left[ \\frac{a}{2} |F(\\mathrm{j}\\omega)| \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi) \\right] J'(\\bar{u}(t))\n$$\nThis equation is in the desired form $\\dot{\\bar{u}}(t) = -k K_{\\mathrm{eff}} J'(\\bar{u}(t))$, where the effective gain $K_{\\mathrm{eff}}$ is:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} |F(\\mathrm{j}\\omega)| \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi)\n$$\nNow, we substitute the expressions for the magnitude and phase of $F(\\mathrm{j}\\omega)$:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\cos\\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{\\omega_h}\\right) - \\phi\\right)\n$$\nWe use the identity $\\cos(\\frac{\\pi}{2} - A) = \\sin(A)$, letting $A = \\arctan(\\frac{\\omega}{\\omega_h}) + \\phi$:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\sin\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right) + \\phi\\right)\n$$\nUsing the sum identity for sine, $\\sin(X+Y) = \\sin(X)\\cos(Y) + \\cos(X)\\sin(Y)$, with $X = \\arctan(\\frac{\\omega}{\\omega_h})$ and $Y=\\phi$:\n$$\n\\sin\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right)\\right) = \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\quad \\text{and} \\quad \\cos\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right)\\right) = \\frac{\\omega_h}{\\sqrt{\\omega^2 + \\omega_h^2}}\n$$\nSubstituting these into the sine sum formula:\n$$\n\\sin\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right) + \\phi\\right) = \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}}\\cos(\\phi) + \\frac{\\omega_h}{\\sqrt{\\omega^2 + \\omega_h^2}}\\sin(\\phi) = \\frac{\\omega\\cos(\\phi) + \\omega_h\\sin(\\phi)}{\\sqrt{\\omega^2 + \\omega_h^2}}\n$$\nFinally, we substitute this back into the expression for $K_{\\mathrm{eff}}$:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\left( \\frac{\\omega\\cos(\\phi) + \\omega_h\\sin(\\phi)}{\\sqrt{\\omega^2 + \\omega_h^2}} \\right)\n$$\nSimplifying this expression yields the final result for the effective gain:\n$$\nK_{\\mathrm{eff}} = \\frac{a \\omega (\\omega \\cos(\\phi) + \\omega_h \\sin(\\phi))}{2 (\\omega^2 + \\omega_h^2)}\n$$\nThis is the closed-form expression for the effective scalar gain $K_{\\mathrm{eff}}$ as a function of $a$, $\\omega$, $\\omega_h$, and $\\phi$.", "answer": "$$\n\\boxed{\\frac{a \\omega (\\omega \\cos(\\phi) + \\omega_h \\sin(\\phi))}{2 (\\omega^2 + \\omega_h^2)}}\n$$", "id": "2706287"}, {"introduction": "Building on the ideal case, we now consider a more realistic scenario where measurement sensors have their own dynamics. These dynamics can introduce a bias, causing the ESC system to converge to a point offset from the true extremum. This practice will guide you through quantifying this effect, demonstrating how component dynamics influence the accuracy of the gradient estimate and the overall performance of the controller [@problem_id:2706359].", "problem": "Consider a standard extremum seeking control (ESC) loop for a scalar, twice continuously differentiable static map $J(u)$, where the objective is to estimate $\\frac{dJ}{d\\theta}(\\theta)$ at a fixed, slowly varying parameter $\\theta$. The input to the map is dithered as $u(t) = \\theta + a \\sin(\\omega t)$ with small amplitude $a > 0$ and dither frequency $\\omega > 0$. The measurement chain consists of a first-order sensor low-pass filter with transfer function $H_{s}(s) = \\frac{1}{\\tau_{s} s + 1}$, followed by a first-order high-pass filter (HPF) $H_{\\mathrm{hp}}(s) = \\frac{s}{s + \\omega_{h}}$ used for baseline removal prior to demodulation, where $\\tau_{s} > 0$ and $\\omega_{h} > 0$ are design parameters. The demodulation multiplies the HPF output by $\\sin(\\omega t)$, and the product is then passed through a first-order low-pass filter (LPF) $H_{\\mathrm{lp}}(s) = \\frac{\\omega_{\\ell}}{s + \\omega_{\\ell}}$ with bandwidth $\\omega_{\\ell} > 0$ chosen so that $\\omega_{\\ell} \\ll \\omega$, effectively acting as an ideal averager that passes only the zero-frequency component. The gradient estimate is formed as\n$$\n\\hat{g}(t) \\;=\\; \\frac{2}{a}\\, H_{\\mathrm{lp}}\\Big\\{\\, \\sin(\\omega t)\\,\\cdot\\, H_{\\mathrm{hp}}\\{\\, y(t) \\,\\}\\, \\Big\\}, \\quad y(t) \\;=\\; \\big(H_{s} * J(u)\\big)(t).\n$$\nAssume $a$ is sufficiently small that a first-order Taylor expansion of $J(\\theta + a \\sin(\\omega t))$ about $\\theta$ and linear time-invariant (LTI) filtering accurately describe the leading-order behavior of the zero-frequency component after demodulation. Define the multiplicative bias coefficient $B(\\omega,\\tau_{s},\\omega_{h})$ by the steady-state relation\n$$\n\\mathbb{E}\\big[\\, \\hat{g}(t) \\,\\big] \\;=\\; B(\\omega,\\tau_{s},\\omega_{h})\\, J'(\\theta) \\;+\\; \\mathcal{O}(a^{2}),\n$$\nwhere $\\mathbb{E}[\\cdot]$ denotes averaging over the fast time scale at frequency $\\omega$.\n\nDerive, from first principles and the stated assumptions only, a closed-form analytic expression for the bias coefficient $B(\\omega,\\tau_{s},\\omega_{h})$ as an explicit real rational function of $\\omega$, $\\tau_{s}$, and $\\omega_{h}$. Your final answer must be a single analytic expression. Do not introduce any additional approximations beyond those stated. No numerical evaluation is required.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Objective function: $J(u)$, a twice continuously differentiable static map.\n- Input signal: $u(t) = \\theta + a \\sin(\\omega t)$, with amplitude $a > 0$ and frequency $\\omega > 0$.\n- Parameter: $\\theta$ is fixed or slowly varying.\n- Sensor low-pass filter (LPF): $H_{s}(s) = \\frac{1}{\\tau_{s} s + 1}$, with $\\tau_{s} > 0$.\n- High-pass filter (HPF): $H_{\\mathrm{hp}}(s) = \\frac{s}{s + \\omega_{h}}$, with $\\omega_{h} > 0$.\n- Demodulation LPF: $H_{\\mathrm{lp}}(s) = \\frac{\\omega_{\\ell}}{s + \\omega_{\\ell}}$, with $\\omega_{\\ell} \\ll \\omega$.\n- Sensor output: $y(t) = (H_{s} * J(u))(t)$.\n- Gradient estimate: $\\hat{g}(t) = \\frac{2}{a} H_{\\mathrm{lp}}\\{ \\sin(\\omega t) \\cdot H_{\\mathrm{hp}}\\{ y(t) \\} \\}$.\n- Assumptions:\n    1. The amplitude $a$ is sufficiently small to justify a first-order Taylor expansion of $J(u(t))$ about $\\theta$.\n    2. Linear time-invariant (LTI) filtering accurately describes the leading-order behavior.\n    3. The filter $H_{\\mathrm{lp}}(s)$ acts as an ideal averager passing only the zero-frequency (DC) component.\n- Definition of bias: The steady-state relation $\\mathbb{E}[\\hat{g}(t)] = B(\\omega, \\tau_{s}, \\omega_{h}) J'(\\theta) + \\mathcal{O}(a^{2})$ defines the multiplicative bias coefficient $B(\\omega, \\tau_{s}, \\omega_{h})$.\n- Objective: Derive a closed-form analytic expression for $B(\\omega, \\tau_{s}, \\omega_{h})$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, as it describes a standard configuration for analyzing extremum seeking control systems using perturbation methods. It is well-posed, with all necessary functions, parameters, and assumptions clearly defined to allow for a unique solution. The language is objective and precise. The problem does not violate any fundamental principles of control theory or signal processing. It is a formalizable and non-trivial problem in the specified field. The setup is self-contained and consistent.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be derived.\n\nThe derivation proceeds as follows.\nThe input to the static map is $u(t) = \\theta + a \\sin(\\omega t)$. For small $a$, a first-order Taylor series expansion of the output $J(u(t))$ around $\\theta$ is given by:\n$$J(u(t)) = J(\\theta + a \\sin(\\omega t)) \\approx J(\\theta) + J'(\\theta) a \\sin(\\omega t) + \\mathcal{O}(a^2)$$\nThis output signal is then passed through the sensor filter $H_s(s)$. Since the system is linear, we can analyze the constant and time-varying components separately. The constant term $J(\\theta)$ passes through $H_s(s)$, resulting in a steady-state output of $H_s(0) J(\\theta) = J(\\theta)$. The time-varying term, $a J'(\\theta) \\sin(\\omega t)$, is also filtered by $H_s(s)$.\n\nThe full sensor output is $y(t)$. This signal is then fed into the high-pass filter $H_{\\mathrm{hp}}(s)$. The DC gain of this filter is $H_{\\mathrm{hp}}(0) = 0$. Therefore, the constant component $J(\\theta)$ from the sensor output is completely rejected by the HPF. We need only consider the propagation of the alternating component.\n\nLet $v(t) = a J'(\\theta) \\sin(\\omega t)$ be the time-varying part of the map's output. The signal is processed by a cascade of two LTI filters, $H_s(s)$ and $H_{\\mathrm{hp}}(s)$. Let the combined transfer function be $H_{c}(s) = H_{\\mathrm{hp}}(s) H_{s}(s)$. The output of this filter cascade, which we denote as $z(t)$, is the steady-state response to $v(t)$. Using frequency-domain analysis, we can find $z(t)$ by evaluating the frequency response of the cascade at $s=\\mathrm{j}\\omega$ and applying it to the input signal.\n\nIt is convenient to represent the input as $v(t) = a J'(\\theta) \\operatorname{Im}\\{\\exp(\\mathrm{j}\\omega t)\\}$. The output is then:\n$$z(t) = \\operatorname{Im}\\{ H_{c}(\\mathrm{j}\\omega) \\cdot a J'(\\theta) \\exp(\\mathrm{j}\\omega t) \\}$$\nLet the complex frequency response be $H_{c}(\\mathrm{j}\\omega) = M_c \\exp(\\mathrm{j}\\phi_c)$, where $M_c = |H_{c}(\\mathrm{j}\\omega)|$ and $\\phi_c = \\angle H_{c}(\\mathrm{j}\\omega)$. Then,\n$$z(t) = a J'(\\theta) \\operatorname{Im}\\{ M_c \\exp(\\mathrm{j}\\phi_c) \\exp(\\mathrm{j}\\omega t) \\} = a J'(\\theta) M_c \\sin(\\omega t + \\phi_c)$$\nThis signal $z(t)$ is the output of the HPF. Next, it is demodulated by multiplying with $\\sin(\\omega t)$:\n$$s_{demod}(t) = z(t) \\cdot \\sin(\\omega t) = a J'(\\theta) M_c \\sin(\\omega t + \\phi_c) \\sin(\\omega t)$$\nUsing the trigonometric product-to-sum identity $\\sin A \\sin B = \\frac{1}{2}(\\cos(A-B) - \\cos(A+B))$, we get:\n$$s_{demod}(t) = a J'(\\theta) M_c \\cdot \\frac{1}{2} \\big(\\cos(\\phi_c) - \\cos(2\\omega t + \\phi_c)\\big)$$\nThe demodulated signal is then passed through the low-pass filter $H_{\\mathrm{lp}}(s)$. By the problem statement, this filter acts as an ideal averager, passing only the DC component of its input. The average value of $s_{demod}(t)$ over one period, denoted by $\\mathbb{E}[s_{demod}(t)]$, is:\n$$\\mathbb{E}[s_{demod}(t)] = \\mathbb{E}\\left[ \\frac{a J'(\\theta) M_c}{2} \\cos(\\phi_c) \\right] - \\mathbb{E}\\left[ \\frac{a J'(\\theta) M_c}{2} \\cos(2\\omega t + \\phi_c) \\right]$$\nThe average of the term $\\cos(2\\omega t + \\phi_c)$ is zero. Thus, the DC component is:\n$$\\mathbb{E}[s_{demod}(t)] = \\frac{a J'(\\theta) M_c}{2} \\cos(\\phi_c)$$\nThis can be recognized as $\\frac{a}{2} J'(\\theta) \\operatorname{Re}\\{M_c \\exp(\\mathrm{j}\\phi_c)\\} = \\frac{a}{2} J'(\\theta) \\operatorname{Re}\\{H_{c}(\\mathrm{j}\\omega)\\}$.\n\nThe DC gain of the final LPF is $H_{\\mathrm{lp}}(0) = \\frac{\\omega_{\\ell}}{0+\\omega_{\\ell}} = 1$. The expected value of the gradient estimate $\\hat{g}(t)$ is obtained by applying the LPF and the pre-factor $\\frac{2}{a}$:\n$$\\mathbb{E}[\\hat{g}(t)] = \\frac{2}{a} \\cdot H_{\\mathrm{lp}}(0) \\cdot \\mathbb{E}[s_{demod}(t)] = \\frac{2}{a} \\cdot 1 \\cdot \\left(\\frac{a}{2} J'(\\theta) \\operatorname{Re}\\{H_{c}(\\mathrm{j}\\omega)\\}\\right) = J'(\\theta) \\operatorname{Re}\\{H_{c}(\\mathrm{j}\\omega)\\}$$\nBy comparing this result with the given definition $\\mathbb{E}[\\hat{g}(t)] = B(\\omega, \\tau_{s}, \\omega_{h}) J'(\\theta) + \\mathcal{O}(a^2)$, we identify the bias coefficient as:\n$$B(\\omega, \\tau_{s}, \\omega_{h}) = \\operatorname{Re}\\{H_{c}(\\mathrm{j}\\omega)\\} = \\operatorname{Re}\\left\\{ H_{\\mathrm{hp}}(\\mathrm{j}\\omega) H_{s}(\\mathrm{j}\\omega) \\right\\}$$\nWe now compute this expression explicitly. The frequency responses of the individual filters are:\n$$H_{s}(\\mathrm{j}\\omega) = \\frac{1}{1 + \\mathrm{j}\\omega \\tau_{s}} = \\frac{1 - \\mathrm{j}\\omega \\tau_{s}}{1 + \\omega^{2} \\tau_{s}^{2}} = \\frac{1}{1 + \\omega^{2} \\tau_{s}^{2}} - \\mathrm{j}\\frac{\\omega \\tau_{s}}{1 + \\omega^{2} \\tau_{s}^{2}}$$\n$$H_{\\mathrm{hp}}(\\mathrm{j}\\omega) = \\frac{\\mathrm{j}\\omega}{\\omega_{h} + \\mathrm{j}\\omega} = \\frac{\\mathrm{j}\\omega (\\omega_{h} - \\mathrm{j}\\omega)}{\\omega_{h}^{2} + \\omega^{2}} = \\frac{\\omega^2 + \\mathrm{j}\\omega\\omega_h}{\\omega_h^2 + \\omega^2} = \\frac{\\omega^2}{\\omega_h^2 + \\omega^2} + \\mathrm{j} \\frac{\\omega\\omega_h}{\\omega_h^2 + \\omega^2}$$\nFor two complex numbers $z_1 = x_1 + i y_1$ and $z_2 = x_2 + i y_2$, the real part of their product is $\\operatorname{Re}\\{z_1 z_2\\} = x_1 x_2 - y_1 y_2$. Applying this to $H_s(\\mathrm{j}\\omega)$ and $H_{\\mathrm{hp}}(\\mathrm{j}\\omega)$:\n$$\\operatorname{Re}\\{H_{\\mathrm{hp}}(\\mathrm{j}\\omega) H_{s}(\\mathrm{j}\\omega)\\} = \\operatorname{Re}\\{H_{s}(\\mathrm{j}\\omega)\\} \\operatorname{Re}\\{H_{\\mathrm{hp}}(\\mathrm{j}\\omega)\\} - \\operatorname{Im}\\{H_{s}(\\mathrm{j}\\omega)\\} \\operatorname{Im}\\{H_{\\mathrm{hp}}(\\mathrm{j}\\omega)\\}$$\n$$B(\\omega, \\tau_{s}, \\omega_{h}) = \\left( \\frac{1}{1 + \\omega^{2} \\tau_{s}^{2}} \\right) \\left( \\frac{\\omega^2}{\\omega_h^2 + \\omega^2} \\right) - \\left( -\\frac{\\omega \\tau_{s}}{1 + \\omega^{2} \\tau_{s}^{2}} \\right) \\left( \\frac{\\omega\\omega_h}{\\omega_h^2 + \\omega^2} \\right)$$\nCombining the terms over the common denominator $(\\omega_h^2 + \\omega^2)(1 + \\omega^2 \\tau_s^2)$:\n$$B(\\omega, \\tau_{s}, \\omega_{h}) = \\frac{\\omega^2 + (\\omega \\tau_s)(\\omega \\omega_h)}{(\\omega_h^2 + \\omega^2)(1 + \\omega^2 \\tau_s^2)} = \\frac{\\omega^2 + \\omega^2 \\omega_h \\tau_s}{(\\omega_h^2 + \\omega^2)(1 + \\omega^2 \\tau_s^2)}$$\nFactoring out $\\omega^2$ from the numerator gives the final expression for the bias coefficient.\n$$B(\\omega,\\tau_{s},\\omega_{h}) = \\frac{\\omega^{2}(1 + \\omega_h \\tau_s)}{(\\omega^2 + \\omega_h^2)(1 + \\omega^2 \\tau_s^2)}$$\nThis is a real rational function of $\\omega$, $\\tau_s$, and $\\omega_h$, as required.", "answer": "$$\n\\boxed{\n\\frac{\\omega^{2}(1 + \\omega_{h} \\tau_{s})}{(\\omega^{2} + \\omega_{h}^{2})(1 + \\omega^{2} \\tau_{s}^{2})}\n}\n$$", "id": "2706359"}, {"introduction": "While accuracy is important, stability is paramount. Plant characteristics such as time delays and non-minimum phase zeros can introduce significant phase lag, potentially destabilizing the ESC loop and turning optimization into anti-optimization. This advanced exercise explores this critical failure mode, tasking you with deriving the stability boundary and calculating the maximum tolerable process delay to ensure the controller consistently moves toward the extremum [@problem_id:2706305].", "problem": "Consider an extremum seeking control (ESC) loop designed to minimize an unknown, twice continuously differentiable cost function $J(u)$ with a unique strict local minimum at $u^{\\star}$, where $J'(u^{\\star}) = 0$ and $J''(u^{\\star}) > 0$. The ESC uses a small sinusoidal perturbation to probe the cost gradient while adapting a slowly varying input. The signal definitions are as follows, with all angles in radians and all frequencies in $\\mathrm{rad/s}$:\n- The adjustable input is $x(t)$ and the plant input is $u(t) = x(t) + a \\sin(\\omega t)$, where $a > 0$ is the dither amplitude and $\\omega > 0$ is the dither frequency.\n- The measured signal is generated by passing $J(u(t))$ through a linear time-invariant channel with transfer function $H(s) = \\left(1 - \\frac{s}{z}\\right)\\exp(-s \\tau)$, where $z > 0$ models a single right-half-plane (non-minimum phase) zero at $s = +z$ and $\\tau \\ge 0$ is an input delay.\n- The ESC demodulator multiplies the measured signal by $\\sin(\\omega t)$ and passes it through an ideal low-pass filter with unit gain at zero frequency and zero phase distortion, whose cutoff is strictly below $2\\omega$ so that higher harmonics are rejected.\n- The adaptation law is $\\dot{x}(t) = -\\kappa\\,q(t)$, where $\\kappa > 0$ is small and $q(t)$ is the low-pass filtered demodulation output.\n\nAssume $a$ and $\\kappa$ are sufficiently small to justify first-order Taylor expansion and first-harmonic averaging: expand $J(x(t) + a \\sin(\\omega t))$ around $x(t)$ to first order in $a$, retain only the fundamental harmonic in the response through $H(s)$, and average the modulation products over a period. Assume all other dynamics in the loop aside from $H(s)$ and the ideal low-pass filter are negligible at frequency $\\omega$ (in particular, the low-pass filter is ideal and contributes no phase shift at any frequency retained by averaging).\n\nUsing only the sinusoidal steady-state response of linear time-invariant systems, trigonometric product-to-sum identities, and averaging arguments, derive the averaged slow dynamics of $x(t)$ near $u^{\\star}$ and determine the condition on the total phase $\\phi$ at frequency $\\omega$ that guarantees the averaged adaptation is a local descent of $J$. Then, specializing to $H(s) = \\left(1 - \\frac{s}{z}\\right)\\exp(-s \\tau)$, compute the largest input delay $\\tau_{\\max}$ (in seconds) as an explicit symbolic function of $\\omega$ and $z$ such that the averaged ESC dynamics remains a local descent direction in a neighborhood of $u^{\\star}$.\n\nExpress your final answer as a closed-form analytic expression for $\\tau_{\\max}(\\omega,z)$ in terms of $\\omega$ and $z$. Do not include units in your final expression. All angles must be in radians.", "solution": "The problem requires the derivation of the stability condition for an extremum seeking control (ESC) system and finding the maximum tolerable input delay $\\tau_{\\max}$ for a given plant channel dynamics. The analysis will proceed by applying averaging theory to the slow dynamics of the system.\n\nThe input to the unknown cost function $J(u)$ is $u(t) = x(t) + a \\sin(\\omega t)$, where $x(t)$ is the slowly varying estimate of the optimal input $u^{\\star}$, and $a \\sin(\\omega t)$ is a small dither signal with amplitude $a > 0$ and frequency $\\omega > 0$. The output of the cost function is $y(t) = J(u(t))$.\n\nSince $x(t)$ is slowly varying compared to the dither frequency $\\omega$, and the dither amplitude $a$ is small, we can analyze the system by performing a Taylor series expansion of $J(u(t))$ around $x(t)$. We expand up to the second order to capture the local curvature information, which is essential for extremum seeking.\n$$J(x(t) + a \\sin(\\omega t)) \\approx J(x(t)) + J'(x(t)) a \\sin(\\omega t) + \\frac{1}{2} J''(x(t)) (a \\sin(\\omega t))^2$$\nUsing the trigonometric identity $\\sin^2(\\theta) = \\frac{1}{2}(1 - \\cos(2\\theta))$, the expression for $y(t)$ becomes:\n$$y(t) \\approx J(x(t)) + J'(x(t)) a \\sin(\\omega t) + \\frac{a^2}{4} J''(x(t)) (1 - \\cos(2\\omega t))$$\n$$y(t) \\approx \\left( J(x(t)) + \\frac{a^2}{4} J''(x(t)) \\right) + a J'(x(t)) \\sin(\\omega t) - \\frac{a^2}{4} J''(x(t)) \\cos(2\\omega t)$$\nThis signal $y(t)$ is the input to the linear time-invariant (LTI) channel with transfer function $H(s)$. The signal $y(t)$ contains a DC component, a component at the fundamental frequency $\\omega$, and a component at the second harmonic $2\\omega$. The output of the channel, $y_m(t)$, is obtained by considering the steady-state response to each component. Let $\\phi(\\Omega) = \\angle H(\\mathrm{j}\\Omega)$ be the phase of the channel at frequency $\\Omega$.\nThe measured signal $y_m(t)$ is given by:\n$$y_m(t) \\approx H(0) \\left( J(x) + \\frac{a^2}{4} J''(x) \\right) + |H(\\mathrm{j}\\omega)| a J'(x) \\sin(\\omega t + \\phi(\\omega)) - |H(\\mathrm{j}2\\omega)| \\frac{a^2}{4} J''(x) \\cos(2\\omega t + \\phi(2\\omega))$$\nGiven $H(s) = (1 - \\frac{s}{z})\\exp(-s\\tau)$, we have $H(0) = 1$. Let $\\phi \\equiv \\phi(\\omega) = \\angle H(\\mathrm{j}\\omega)$. The expression for $y_m(t)$ simplifies to:\n$$y_m(t) \\approx J(x) + \\frac{a^2}{4} J''(x) + a |H(\\mathrm{j}\\omega)| J'(x) \\sin(\\omega t + \\phi) - \\dots$$\nwhere the ellipsis represents higher-frequency terms.\n\nThe demodulation step multiplies $y_m(t)$ by $\\sin(\\omega t)$. The resulting signal is then passed through an ideal low-pass filter (LPF), which extracts the DC (average) component. The output of the LPF is $q(t)$.\n$$q(t) = \\text{LPF}\\{ y_m(t) \\sin(\\omega t) \\}$$\nTo find the averaged value of $q(t)$, we compute the average of the product $y_m(t) \\sin(\\omega t)$ over one period $T = 2\\pi/\\omega$. The average of any term of the form $\\sin(k\\omega t + \\theta)$ or $\\cos(k\\omega t + \\theta)$ for integer $k \\ge 1$ is zero. We use the product-to-sum identity $\\sin(A)\\sin(B) = \\frac{1}{2}(\\cos(A-B) - \\cos(A+B))$.\nThe average of the demodulated signal is:\n$$q_{avg} = \\left\\langle \\left( J(x) + \\frac{a^2}{4} J''(x) + \\dots \\right) \\sin(\\omega t) \\right\\rangle + \\left\\langle a |H(\\mathrm{j}\\omega)| J'(x) \\sin(\\omega t + \\phi) \\sin(\\omega t) \\right\\rangle - \\dots$$\nThe term involving the product of DC components and $\\sin(\\omega t)$ averages to zero. The term from the second harmonic also averages to zero because $\\langle \\cos(2\\omega t + \\phi(2\\omega))\\sin(\\omega t) \\rangle = 0$. The only term that produces a non-zero average is the one from the fundamental harmonic:\n$$q_{avg} = \\left\\langle a |H(\\mathrm{j}\\omega)| J'(x) \\frac{1}{2} (\\cos(\\phi) - \\cos(2\\omega t + \\phi)) \\right\\rangle$$\n$$q_{avg} = \\frac{a}{2} |H(\\mathrm{j}\\omega)| \\cos(\\phi) J'(x)$$\nThe adaptation law for the slow variable $x(t)$ is $\\dot{x}(t) = -\\kappa q(t)$. Using averaging theory, the dynamics of the averaged system are:\n$$\\dot{x}_{avg} = -\\kappa q_{avg} = -\\kappa \\frac{a}{2} |H(\\mathrm{j}\\omega)| \\cos(\\phi) J'(x)$$\nFor the ESC to be a local descent of the cost function $J(x)$, the system must behave like a gradient descent algorithm, i.e., $\\dot{x}_{avg}$ must have the opposite sign of the gradient $J'(x)$. To analyze local stability near the optimum $u^\\star$, we linearize the dynamics around $u^{\\star}$. Let $x(t) = u^{\\star} + \\delta_x(t)$. For small $\\delta_x$, we use the Taylor expansion $J'(x) \\approx J'(u^{\\star}) + J''(u^{\\star})(x-u^{\\star})$. Since $J'(u^{\\star}) = 0$, we have $J'(x) \\approx J''(u^{\\star})\\delta_x$.\nThe dynamics of the deviation $\\delta_x(t)$ are:\n$$\\dot{\\delta}_{x,avg} = -\\left( \\frac{\\kappa a}{2} |H(\\mathrm{j}\\omega)| \\cos(\\phi) J''(u^{\\star}) \\right) \\delta_x$$\nFor local stability, the coefficient of $\\delta_x$ must be negative, so that $\\delta_x \\to 0$. Given that $\\kappa > 0$, $a > 0$, $|H(\\mathrm{j}\\omega)| > 0$, and $J''(u^\\star) > 0$ (since $u^\\star$ is a strict local minimum), the stability condition reduces to:\n$$\\cos(\\phi) > 0$$\nThis is the general condition for the phase $\\phi = \\angle H(\\mathrm{j}\\omega)$ to guarantee local descent. This condition implies $-\\frac{\\pi}{2} < \\phi < \\frac{\\pi}{2}$ (modulo $2\\pi$).\n\nNow we specialize to the given transfer function $H(s) = \\left(1 - \\frac{s}{z}\\right)\\exp(-s \\tau)$. We compute its phase at $s = \\mathrm{j}\\omega$:\n$$H(\\mathrm{j}\\omega) = \\left(1 - \\mathrm{j}\\frac{\\omega}{z}\\right)\\exp(-\\mathrm{j}\\omega \\tau)$$\nThe phase $\\phi$ is the sum of the phases of the two factors:\n$$\\phi = \\angle\\left(1 - \\mathrm{j}\\frac{\\omega}{z}\\right) + \\angle(\\exp(-\\mathrm{j}\\omega \\tau))$$\nThe first term corresponds to a complex number with a positive real part ($1$) and a negative imaginary part ($-\\omega/z$, since $\\omega, z > 0$). Its phase is given by $\\arctan(-\\omega/z) = -\\arctan(\\omega/z)$. The second term, the pure delay, contributes a phase of $-\\omega\\tau$.\nTherefore, the total phase is:\n$$\\phi = -\\arctan\\left(\\frac{\\omega}{z}\\right) - \\omega \\tau$$\nFor the averaged dynamics to be a local descent, we must satisfy $\\cos(\\phi) > 0$. Since $\\omega>0, z>0, \\tau \\ge 0$, the term $-\\arctan(\\omega/z)$ is in the interval $(-\\frac{\\pi}{2}, 0)$ and $-\\omega\\tau \\le 0$. Thus, the total phase $\\phi$ is always non-positive. The condition $\\cos(\\phi)>0$ for a non-positive angle $\\phi$ is equivalent to $\\phi > -\\frac{\\pi}{2}$.\n$$-\\arctan\\left(\\frac{\\omega}{z}\\right) - \\omega \\tau > -\\frac{\\pi}{2}$$\nWe solve for the delay $\\tau$:\n$$\\omega \\tau < \\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)$$\n$$\\tau < \\frac{1}{\\omega} \\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)\\right)$$\nThe largest input delay $\\tau_{\\max}$ for which the condition holds is the value that makes the inequality an equality.\n$$\\tau_{\\max} = \\frac{1}{\\omega} \\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)\\right)$$\nThis expression provides the maximum tolerable delay as a function of the dither frequency $\\omega$ and the non-minimum phase zero location $z$.", "answer": "$$\\boxed{\\frac{1}{\\omega} \\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)\\right)}$$", "id": "2706305"}]}