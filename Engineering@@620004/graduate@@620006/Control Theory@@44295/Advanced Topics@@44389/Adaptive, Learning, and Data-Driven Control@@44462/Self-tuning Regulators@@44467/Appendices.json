{"hands_on_practices": [{"introduction": "The certainty equivalence principle is a cornerstone of self-tuning control, but applying it naively can be perilous. A common challenge arises when the online parameter estimator produces a plant model with non-minimum phase characteristics, a situation that can occur transiently even for a truly minimum-phase system. This exercise [@problem_id:1608484] explores a crucial safety mechanism embedded in practical pole-placement regulators: how to modify the control design to avoid unstable pole-zero cancellations, ensuring robust performance despite uncertainties in the estimated model.", "problem": "A digital pole-placement self-tuning regulator is used to control a process. The regulator relies on a recursive parameter estimator that provides, at each control interval, an updated model of the plant dynamics. At a particular instant in time, the estimator identifies the numerator of the plant's discrete-time transfer function, relating the control input $u(t)$ to the plant output $y(t)$, as the polynomial $\\hat{B}(z^{-1})$.\n\nThe estimated polynomial is given by:\n$$ \\hat{B}(z^{-1}) = 0.80 - 2.00 z^{-1} + 0.80 z^{-2} $$\n\nA critical safety feature of the controller synthesis algorithm is to prevent unstable controller designs that could arise from attempting to cancel non-minimum phase zeros. The protocol is as follows:\n1.  All zeros of the estimated polynomial $\\hat{B}(z^{-1})$ are computed.\n2.  Any zero located outside the unit circle is identified as non-minimum phase.\n3.  A new polynomial, $\\hat{B}'(z^{-1})$, is constructed. Its zeros are formed by taking all the stable zeros of $\\hat{B}(z^{-1})$ and replacing each non-minimum phase zero of $\\hat{B}(z^{-1})$ with its complex-conjugate reciprocal.\n4.  The new polynomial $\\hat{B}'(z^{-1})$ is scaled by a constant factor such that its steady-state gain (i.e., its value at $z=1$) is identical to the steady-state gain of the original estimated polynomial $\\hat{B}(z^{-1})$.\n\nYour task is to calculate the coefficient of the $z^{-1}$ term in the modified, safe polynomial $\\hat{B}'(z^{-1})$. Round your final answer to three significant figures.", "solution": "We are given the estimated numerator polynomial in $z^{-1}$ as $\\hat{B}(z^{-1})=0.80-2.00 z^{-1}+0.80 z^{-2}$. The zeros in the $z$-plane are the roots of $0.80 z^{2}-2.00 z+0.80=0$, obtained by multiplying by $z^{2}$. Solving the quadratic equation,\n$$\n0.80 z^{2}-2.00 z+0.80=0 \\;\\;\\Rightarrow\\;\\; z^{2}-2.5 z+1=0,\n$$\ngives\n$$\nz=\\frac{2.5\\pm\\sqrt{(2.5)^{2}-4\\cdot 1\\cdot 1}}{2}=\\frac{2.5\\pm 1.5}{2},\n$$\nso the zeros are $z_{1}=2$ and $z_{2}=0.5$. The zero at $z=2$ is non-minimum phase (outside the unit circle), and the zero at $z=0.5$ is minimum phase (inside the unit circle).\n\nPer the protocol, replace the non-minimum phase zero $z=2$ by its complex-conjugate reciprocal, which here is $1/2=0.5$. Thus the modified zeros are $z_{1}'=0.5$ and $z_{2}'=0.5$.\n\nA polynomial in $z^{-1}$ with zeros at $z_{1}',z_{2}'$ has the form\n$$\n\\hat{B}'_{\\text{u}}(z^{-1})=k\\left(1-(z_{1}'+z_{2}')z^{-1}+z_{1}'z_{2}' z^{-2}\\right).\n$$\nWith $z_{1}'+z_{2}'=1$ and $z_{1}'z_{2}'=0.25$, this becomes\n$$\n\\hat{B}'_{\\text{u}}(z^{-1})=k\\left(1-z^{-1}+0.25\\, z^{-2}\\right).\n$$\n\nThe scaling $k$ is chosen to preserve the steady-state gain at $z=1$. The original gain is\n$$\n\\hat{B}(1)=0.80-2.00+0.80=-0.40,\n$$\nwhile the unscaled modified gain is\n$$\n\\hat{B}'_{\\text{u}}(1)=k\\left(1-1+0.25\\right)=0.25\\,k.\n$$\nEquating gives $0.25\\,k=-0.40$, hence $k=-1.6$. Therefore,\n$$\n\\hat{B}'(z^{-1})=-1.6+1.6\\,z^{-1}-0.4\\,z^{-2},\n$$\nso the coefficient of the $z^{-1}$ term is $1.6$, which to three significant figures is $1.60$.", "answer": "$$\\boxed{1.60}$$", "id": "1608484"}, {"introduction": "Moving beyond simple pole-placement, advanced self-tuning regulators often incorporate principles of optimal control to achieve superior performance. This practice [@problem_id:2743690] delves into the powerful combination of self-tuning and Linear-Quadratic (LQ) regulation. By deriving the controller gain from the Algebraic Riccati Equation at each step, we see how the control action can be systematically designed to minimize a performance-based cost function, adapting optimally to the perceived changes in plant dynamics.", "problem": "Consider the discrete-time linear time-invariant plant with unknown dynamics\n$$\nx_{k+1} = A x_k + B u_k,\\qquad y_k = C x_k + v_k,\n$$\nwhere $x_k \\in \\mathbb{R}^{n}$, $u_k \\in \\mathbb{R}^{m}$, $y_k \\in \\mathbb{R}^{p}$, $v_k$ is zero-mean white measurement noise, and $(A,B)$ are constant but unknown. You will design a certainty-equivalent self-tuning regulator (STR) for the infinite-horizon linear-quadratic (LQ) problem in which $(A,B)$ are estimated online and a linear-quadratic regulator is synthesized at each time from the current estimates. The performance index to be minimized is\n$$\nJ = \\sum_{k=0}^{\\infty} \\left( x_k^{\\top} Q x_k + u_k^{\\top} R u_k \\right),\n$$\nwith $Q \\succeq 0$ and $R \\succ 0$ known. Under the certainty equivalence principle, at each time $k$ you use the current estimates $(\\hat{A}_k,\\hat{B}_k)$ in place of $(A,B)$ when solving for the control law.\n\nSpecialize to the single-input single-output scalar case with $n=m=p=1$, $C=1$, $Q=q0$, $R=r0$, and plant\n$$\nx_{k+1} = a\\,x_k + b\\,u_k,\\qquad y_k = x_k + v_k,\n$$\nwhere $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}\\setminus\\{0\\}$ are unknown constants. Assume the parameter estimator at time $k$ has produced current estimates $\\hat{a}_k$ and $\\hat{b}_k$ that you will treat as exact for the purposes of control synthesis. Starting from first principles for the infinite-horizon discrete-time linear-quadratic regulator, derive the unique stabilizing certainty-equivalent state-feedback gain $K_k$ such that the control is $u_k = -K_k x_k$, written in closed form explicitly as a function of $\\hat{a}_k$, $\\hat{b}_k$, $q$, and $r$. Your final answer must be a single closed-form analytic expression for $K_k$. Do not round your answer.", "solution": "The problem requires the derivation of the certainty-equivalent state-feedback gain for a scalar discrete-time system in the context of an infinite-horizon linear-quadratic regulator (LQR). The design is to be performed at each time step $k$ using the current parameter estimates $(\\hat{a}_k, \\hat{b}_k)$ as if they were the true system parameters. This is the essence of the certainty equivalence principle.\n\nThe problem to be solved at each time step $k$ is a deterministic, infinite-horizon LQR problem for the system\n$$\nx_{i+1} = \\hat{a}_k x_i + \\hat{b}_k u_i,\n$$\nwith the objective to minimize the cost function\n$$\nJ = \\sum_{i=0}^{\\infty} \\left( q x_i^2 + r u_i^2 \\right),\n$$\nwhere $q0$ and $r0$ are given scalar weights. We are given that the parameter estimates are $\\hat{a}_k \\in \\mathbb{R}$ and $\\hat{b}_k \\in \\mathbb{R}\\setminus\\{0\\}$.\n\nThe solution to the infinite-horizon discrete-time LQR problem is a static state-feedback control law $u_i = -K_k x_i$. The optimal feedback gain $K_k$ is constant for the infinite-horizon problem being solved at time $k$. The gain $K_k$ is determined by the solution to the Discrete-time Algebraic Riccati Equation (DARE).\n\nFor a general LTI system $x_{i+1}=Ax_i+Bu_i$ and cost $\\sum (x_i^\\top Q x_i + u_i^\\top R u_i)$, the DARE for the cost-to-go matrix $P$ is:\n$$\nP = Q + A^{\\top} P A - A^{\\top} P B (R + B^{\\top} P B)^{-1} B^{\\top} P A.\n$$\nThe optimal gain is then given by:\n$$\nK = (R + B^{\\top} P B)^{-1} B^{\\top} P A.\n$$\nWe specialize these general matrix equations to the scalar case at hand, by substituting $A \\to \\hat{a}_k$, $B \\to \\hat{b}_k$, $Q \\to q$, $R \\to r$, and $P \\to p_k$, where $p_k$ is a scalar.\n\nThe DARE becomes a scalar algebraic equation for $p_k$:\n$$\np_k = q + \\hat{a}_k p_k \\hat{a}_k - (\\hat{a}_k p_k \\hat{b}_k) (r + \\hat{b}_k p_k \\hat{b}_k)^{-1} (\\hat{b}_k p_k \\hat{a}_k)\n$$\n$$\np_k = q + \\hat{a}_k^2 p_k - \\frac{\\hat{a}_k^2 \\hat{b}_k^2 p_k^2}{r + \\hat{b}_k^2 p_k}.\n$$\nThe corresponding scalar gain is:\n$$\nK_k = (r + \\hat{b}_k^2 p_k)^{-1} (\\hat{b}_k p_k \\hat{a}_k) = \\frac{\\hat{a}_k \\hat{b}_k p_k}{r + \\hat{b}_k^2 p_k}.\n$$\nA more direct path is to substitute $K_k = \\frac{\\hat{a}_k \\hat{b}_k p_k}{r+\\hat{b}_k^2 p_k}$ into the DARE.\nThe term $\\frac{\\hat{a}_k^2 \\hat{b}_k^2 p_k^2}{r+\\hat{b}_k^2 p_k} = (\\hat{a}_k \\hat{b}_k p_k) \\frac{\\hat{a}_k \\hat{b}_k p_k}{r+\\hat{b}_k^2 p_k} = (\\hat{a}_k \\hat{b}_k p_k) K_k$.\nSo the DARE becomes:\n$$\np_k = q + \\hat{a}_k^2 p_k - \\hat{a}_k \\hat{b}_k p_k K_k.\n$$\n$$\np_k(1 - \\hat{a}_k^2 + \\hat{a}_k \\hat{b}_k K_k) = q.\n$$\nNow we substitute $p_k = \\frac{r K_k}{\\hat{b}_k (\\hat{a}_k - K_k \\hat{b}_k)}$ into this equation:\n$$\n\\frac{r K_k}{\\hat{b}_k (\\hat{a}_k - K_k \\hat{b}_k)} (1 - \\hat{a}_k^2 + \\hat{a}_k \\hat{b}_k K_k) = q.\n$$\nMultiplying by $\\hat{b}_k (\\hat{a}_k - K_k \\hat{b}_k)$ gives:\n$$\nr K_k (1 - \\hat{a}_k^2 + \\hat{a}_k \\hat{b}_k K_k) = q \\hat{b}_k (\\hat{a}_k - K_k \\hat{b}_k).\n$$\n$$\nr K_k - r \\hat{a}_k^2 K_k + r \\hat{a}_k \\hat{b}_k K_k^2 = q \\hat{a}_k \\hat{b}_k - q \\hat{b}_k^2 K_k.\n$$\nRearranging terms yields a quadratic equation in $K_k$:\n$$\n(r \\hat{a}_k \\hat{b}_k) K_k^2 + (r - r \\hat{a}_k^2 + q \\hat{b}_k^2) K_k - q \\hat{a}_k \\hat{b}_k = 0.\n$$\nLet's define the coefficients $A' = r \\hat{a}_k \\hat{b}_k$, $B' = r(1-\\hat{a}_k^2) + q\\hat{b}_k^2$, and $C' = -q\\hat{a}_k \\hat{b}_k$. The equation is $A' K_k^2 + B' K_k + C' = 0$.\nThe solutions for $K_k$ are given by the quadratic formula:\n$$\nK_k = \\frac{-B' \\pm \\sqrt{(B')^2 - 4 A' C'}}{2 A'}.\n$$\nSubstituting the coefficients:\n$$\nK_k = \\frac{-(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2) \\pm \\sqrt{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2)^2 - 4(r\\hat{a}_k\\hat{b}_k)(-q\\hat{a}_k\\hat{b}_k)}}{2r\\hat{a}_k\\hat{b}_k}.\n$$\n$$\nK_k = \\frac{-(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2) \\pm \\sqrt{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2)^2 + 4qr\\hat{a}_k^2\\hat{b}_k^2}}{2r\\hat{a}_k\\hat{b}_k}.\n$$\nWe need to select the unique stabilizing gain. For LQR problems, under the given conditions ($q  0$ which ensures detectability, and $\\hat{b}_k \\neq 0$ which ensures controllability), there exists a unique positive semi-definite solution $p_k \\geq 0$ for the DARE which results in a stable closed-loop system. Since $q0$, it can be shown that $p_k0$.\nFrom the gain formula $K_k = \\frac{\\hat{a}_k \\hat{b}_k p_k}{r + \\hat{b}_k^2 p_k}$, since $r0$, $p_k0$, and $\\hat{b}_k^20$, the denominator is always positive. Thus, the sign of the stabilizing gain must be the same as the sign of the numerator:\n$$\n\\text{sgn}(K_k) = \\text{sgn}(\\hat{a}_k \\hat{b}_k p_k) = \\text{sgn}(\\hat{a}_k \\hat{b}_k).\n$$\nNow let's analyze the two roots from the quadratic formula. Let $S = \\sqrt{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2)^2 + 4qr\\hat{a}_k^2\\hat{b}_k^2}$. The term $S$ is strictly positive. The numerator of one root is $-B'+S$ and of the other is $-B'-S$. Since $S  |B'|$, these numerators have opposite signs: $-B'+S  0$ and $-B'-S  0$.\nThe two roots are $K_{k,1} = \\frac{-B'+S}{2A'}$ and $K_{k,2} = \\frac{-B'-S}{2A'}$.\nThe sign of $K_{k,1}$ is $\\text{sgn}(1/A') = \\text{sgn}(A')$, while the sign of $K_{k,2}$ is $\\text{sgn}(-1/A') = -\\text{sgn}(A')$.\nSince $A' = r\\hat{a}_k\\hat{b}_k$ and $r0$, we have $\\text{sgn}(A') = \\text{sgn}(\\hat{a}_k\\hat{b}_k)$.\nTo match the required sign condition $\\text{sgn}(K_k) = \\text{sgn}(\\hat{a}_k \\hat{b}_k)$, we must choose the first root, corresponding to the '$+$' sign in the numerator.\n$$\nK_k = \\frac{-(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2) + \\sqrt{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2)^2 + 4qr\\hat{a}_k^2\\hat{b}_k^2}}{2r\\hat{a}_k\\hat{b}_k}.\n$$\nThis expression is of the form $0/0$ if $\\hat{a}_k=0$. We can rationalize the numerator to obtain a form that is well-behaved as $\\hat{a}_k \\to 0$:\n$$\nK_k = \\frac{2C'}{-B' - \\sqrt{(B')^2-4A'C'}}.\n$$\nSubstituting $B'$ and $C'$:\n$$\nK_k = \\frac{2(-q\\hat{a}_k\\hat{b}_k)}{-(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2) - \\sqrt{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2)^2 + 4qr\\hat{a}_k^2\\hat{b}_k^2}}.\n$$\n$$\nK_k = \\frac{2q\\hat{a}_k\\hat{b}_k}{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2) + \\sqrt{(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2)^2 + 4qr\\hat{a}_k^2\\hat{b}_k^2}}.\n$$\nThis is the final closed-form expression for the unique stabilizing certainty-equivalent gain $K_k$.", "answer": "$$\n\\boxed{\n\\frac{2q\\hat{a}_k\\hat{b}_k}{\\left(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2\\right) + \\sqrt{\\left(r(1-\\hat{a}_k^2) + q\\hat{b}_k^2\\right)^2 + 4qr\\hat{a}_k^2\\hat{b}_k^2}}\n}\n$$", "id": "2743690"}, {"introduction": "A key question in any adaptive system is under what conditions its stability can be guaranteed. While powerful, the self-tuning framework relies on a critical, and often implicit, assumption: that the system's signals provide enough information to correctly identify the plant parameters. This advanced problem [@problem_id:2743714] constructs an insightful counterexample to demonstrate how a lack of 'persistency of excitation' can lead to parameter drift and, ultimately, instability, revealing the fundamental limits of the certainty equivalence principle.", "problem": "Consider a continuous-time, single-input single-output linear time-invariant plant with unknown parameters governed by the differential equation\n$$\n\\dot{y}(t) \\;=\\; -a\\,y(t) \\;+\\; b\\,u(t),\n$$\nwhere $a0$ and $b0$ are fixed but unknown constants, and $y(t)$ and $u(t)$ denote the plant output and control input, respectively. An indirect Self-Tuning Regulator (STR) uses certainty equivalence to assign a desired closed-loop pole at $-\\alpha$ with $\\alpha0$. Let $\\hat{a}(t)$ and $\\hat{b}(t)$ denote the online parameter estimates for $a$ and $b$. The controller implements the certainty-equivalence pole placement law\n$$\nu(t) \\;=\\; -\\,\\frac{\\hat{a}(t) - \\alpha}{\\hat{b}(t)}\\,y(t).\n$$\n\nAssume the output reference is identically zero so that $r(t)\\equiv 0$, and the estimator employs a leaky adaptation in the absence of excitation, modeled by the autonomous dynamics\n$$\n\\dot{\\hat{a}}(t) \\;=\\; -\\sigma\\,\\hat{a}(t), \n\\qquad\n\\dot{\\hat{b}}(t) \\;=\\; -\\sigma\\,\\hat{b}(t),\n$$\nwith $\\sigma0$ and initial conditions $\\hat{a}(0)=\\hat{a}_0$ and $\\hat{b}(0)=\\hat{b}_00$. Suppose the initial closed-loop pole\n$$\np(0) \\;=\\; -a \\;-\\; \\frac{b}{\\hat{b}_0}\\,\\bigl(\\hat{a}_0 - \\alpha\\bigr)\n$$\nsatisfies $p(0)0$, so that the initial closed-loop dynamics are stable and the plant output decays.\n\nStarting only from the plant equation, the stated certainty-equivalence control law, and the leaky estimator dynamics, construct a counterexample demonstrating that the lack of excitation drives the estimates $\\hat{a}(t)$ and $\\hat{b}(t)$ in such a way that the instantaneous closed-loop pole $p(t)$ eventually crosses into the open right-half plane. Derive, in closed form, the earliest time $t^\\star0$ at which the instantaneous closed-loop pole crosses the imaginary axis, i.e., the smallest $t^\\star$ satisfying $p(t^\\star)=0$, expressed as a function of the symbols $a$, $b$, $\\alpha$, $\\sigma$, $\\hat{a}_0$, and $\\hat{b}_0$. Express your final answer for $t^\\star$ in seconds as a single analytic expression. In your derivation, explicitly state which standard assumption used in stability proofs of Self-Tuning Regulators (STR) is violated by this construction and why it fails here.\n\nYour final answer must be a single closed-form analytic expression for $t^\\star$ only. Do not include any units in the final boxed answer.", "solution": "The first step is to determine the dynamics of the closed-loop system. We substitute the control law $u(t)$ into the plant equation:\n$$\n\\dot{y}(t) = -a\\,y(t) + b \\left( -\\frac{\\hat{a}(t) - \\alpha}{\\hat{b}(t)}\\,y(t) \\right)\n$$\nBy factoring out $y(t)$, we can identify the instantaneous closed-loop pole, denoted by $p(t)$:\n$$\n\\dot{y}(t) = \\left[ -a - b\\,\\frac{\\hat{a}(t) - \\alpha}{\\hat{b}(t)} \\right] y(t) = p(t)\\,y(t)\n$$\nThus, the instantaneous pole is:\n$$\np(t) = -a - b\\,\\frac{\\hat{a}(t) - \\alpha}{\\hat{b}(t)}\n$$\nNext, we must find the time evolution of the parameter estimates $\\hat{a}(t)$ and $\\hat{b}(t)$. The problem states their dynamics are governed by the autonomous first-order linear differential equations:\n$$\n\\dot{\\hat{a}}(t) = -\\sigma\\,\\hat{a}(t), \\qquad \\text{with } \\hat{a}(0) = \\hat{a}_0\n$$\n$$\n\\dot{\\hat{b}}(t) = -\\sigma\\,\\hat{b}(t), \\qquad \\text{with } \\hat{b}(0) = \\hat{b}_0\n$$\nThe solutions to these equations are simple exponential decays:\n$$\n\\hat{a}(t) = \\hat{a}_0 \\exp(-\\sigma t)\n$$\n$$\n\\hat{b}(t) = \\hat{b}_0 \\exp(-\\sigma t)\n$$\nNow we substitute these solutions back into the expression for the instantaneous pole $p(t)$:\n$$\np(t) = -a - b\\,\\frac{\\hat{a}_0 \\exp(-\\sigma t) - \\alpha}{\\hat{b}_0 \\exp(-\\sigma t)}\n$$\nThe term $\\exp(-\\sigma t)$ in the fraction can be simplified:\n$$\np(t) = -a - \\frac{b}{\\hat{b}_0} \\frac{\\hat{a}_0 \\exp(-\\sigma t) - \\alpha}{\\exp(-\\sigma t)} = -a - \\frac{b}{\\hat{b}_0} \\left( \\hat{a}_0 - \\frac{\\alpha}{\\exp(-\\sigma t)} \\right)\n$$\nThis simplifies to:\n$$\np(t) = -a - \\frac{b \\hat{a}_0}{\\hat{b}_0} + \\frac{b \\alpha}{\\hat{b}_0} \\exp(\\sigma t)\n$$\nWe can verify this expression at $t=0$. We have $p(0) = -a - \\frac{b \\hat{a}_0}{\\hat{b}_0} + \\frac{b \\alpha}{\\hat{b}_0} = -a - \\frac{b}{\\hat{b}_0}(\\hat{a}_0 - \\alpha)$, which matches the given initial condition.\n\nThe problem requires finding the earliest time $t^\\star  0$ such that the system becomes marginally stable, i.e., $p(t^\\star) = 0$. We set our expression for $p(t)$ to zero and solve for $t=t^\\star$:\n$$\n0 = -a - \\frac{b \\hat{a}_0}{\\hat{b}_0} + \\frac{b \\alpha}{\\hat{b}_0} \\exp(\\sigma t^\\star)\n$$\nWe rearrange the equation to solve for the exponential term:\n$$\n\\frac{b \\alpha}{\\hat{b}_0} \\exp(\\sigma t^\\star) = a + \\frac{b \\hat{a}_0}{\\hat{b}_0}\n$$\nMultiplying by $\\frac{\\hat{b}_0}{b \\alpha}$ (all terms are positive, so this is valid):\n$$\n\\exp(\\sigma t^\\star) = \\frac{\\hat{b}_0}{b \\alpha} \\left( a + \\frac{b \\hat{a}_0}{\\hat{b}_0} \\right) = \\frac{a \\hat{b}_0 + b \\hat{a}_0}{b \\alpha}\n$$\nTo solve for $t^\\star$, we take the natural logarithm of both sides:\n$$\n\\sigma t^\\star = \\ln\\left(\\frac{a \\hat{b}_0 + b \\hat{a}_0}{b \\alpha}\\right)\n$$\nFinally, we isolate $t^\\star$:\n$$\nt^\\star = \\frac{1}{\\sigma} \\ln\\left(\\frac{a \\hat{b}_0 + b \\hat{a}_0}{b \\alpha}\\right)\n$$\nWe must confirm that $t^\\star  0$. This requires the argument of the logarithm to be greater than $1$. The condition is $\\frac{a \\hat{b}_0 + b \\hat{a}_0}{b \\alpha}  1$. Let's check this against the initial stability condition $p(0)  0$:\n$$\n-a - \\frac{b}{\\hat{b}_0}(\\hat{a}_0 - \\alpha)  0\n$$\n$$\n-a  \\frac{b}{\\hat{b}_0}(\\hat{a}_0 - \\alpha)\n$$\n$$\n-a \\hat{b}_0  b(\\hat{a}_0 - \\alpha) = b \\hat{a}_0 - b \\alpha\n$$\n$$\nb \\alpha  a \\hat{b}_0 + b \\hat{a}_0\n$$\nDividing by $b \\alpha$ (which is positive since $b0, \\alpha0$):\n$$\n1  \\frac{a \\hat{b}_0 + b \\hat{a}_0}{b \\alpha}\n$$\nThis confirms that the initial stability condition guarantees that the argument of the logarithm is greater than $1$, thus ensuring $t^\\star  0$. Since $\\exp(\\sigma t)$ is a strictly increasing function for $t \\ge 0$, the solution for $t^\\star$ is unique.\n\n**Violated Assumption in STR Stability Proofs**\nThe standard assumption in stability proofs for Self-Tuning Regulators that is violated here is the condition of **Persistency of Excitation (PE)**. A system's signals are persistently exciting if they contain sufficient frequency content to allow for the unique identification of the system's unknown parameters.\nIn this problem, the system identification model can be written as $\\dot{y} = [-y \\quad u] \\begin{pmatrix} a \\\\ b \\end{pmatrix}$. The regressor vector is $\\phi(t) = \\begin{pmatrix} -y(t) \\\\ u(t) \\end{pmatrix}$. The PE condition requires that the integral of $\\phi(t)\\phi(t)^{\\top}$ over a finite moving time window is uniformly positive definite.\nHowever, the problem setup creates a scenario where this fails. The initial stability, $p(0)0$, ensures that the output $y(t)$ decays towards zero. Since the control input $u(t)$ is directly proportional to $y(t)$, $u(t)$ also decays to zero. Consequently, the regressor vector $\\phi(t) \\to 0$ as $t \\to \\infty$. This lack of excitation means the estimator receives no new information about the true parameters $a$ and $b$. The estimator dynamics are then dominated by the leaky term, causing the estimates $\\hat{a}(t)$ and $\\hat{b}(t)$ to decay to zero, irrespective of the true values. This parameter drift, particularly the decay of $\\hat{b}(t)$ in the denominator of the control gain, leads to an unbounded gain and eventual instability. This counterexample demonstrates that the certainty equivalence principle can fail catastrophically when the persistency of excitation condition is not met.", "answer": "$$\n\\boxed{\\frac{1}{\\sigma} \\ln\\left(\\frac{a \\hat{b}_0 + b \\hat{a}_0}{b \\alpha}\\right)}\n$$", "id": "2743714"}]}