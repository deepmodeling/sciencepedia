{"hands_on_practices": [{"introduction": "Understanding system norms begins with the ability to compute them. This first practice provides a fundamental walkthrough of calculating the $\\mathcal{H}_2$ norm for a stable, second-order system directly from its state-space representation. By solving the associated Lyapunov equation for the controllability Gramian, you will bridge the gap between the theoretical definition of the $\\mathcal{H}_2$ norm as an impulse response energy and its practical computation, a cornerstone skill in linear systems analysis [@problem_id:2711596].", "problem": "Consider the real-rational, strictly proper, single-input single-output (SISO) transfer function of a continuous-time, linear time-invariant (LTI) system\n$$\nG(s) \\;=\\; \\frac{k}{(s+a)(s+b)} \\,,\n$$\nwith real parameters satisfying $a>0$, $b>0$, and $k\\in\\mathbb{R}$, and direct feedthrough term $D=0$. The poles of $G(s)$ are simple and strictly in the open left half-plane, so the system is asymptotically stable. \n\nStarting from the definition of the squared $\\mathcal{H}_{2}$ norm of a stable, strictly proper, SISO LTI system as the total impulse-response energy, namely\n$$\n\\|G\\|_{2}^{2} \\;=\\; \\int_{0}^{\\infty} |g(t)|^{2}\\,dt \\,,\n$$\nwhere $g(t)$ is the scalar impulse response, derive the state-space expression of $\\|G\\|_{2}^{2}$ in terms of the controllability Gramian that solves a Lyapunov equation. Then, without introducing any frequency-domain integrals, do the following:\n\n1. Construct an explicit minimal state-space realization $(A,B,C,D)$ of $G(s)$ with $D=0$ using a diagonal $A$ with the system poles on the diagonal.\n2. Derive the continuous-time Lyapunov equation satisfied by the controllability Gramian $P$ and solve it analytically for your chosen realization.\n3. Evaluate the squared $\\mathcal{H}_{2}$ norm $\\|G\\|_{2}^{2}$ using your solved $P$ and simplify the expression completely.\n4. From your result for $\\|G\\|_{2}^{2}$, report the $\\mathcal{H}_{2}$ norm $\\|G\\|_{2}$ as a single closed-form analytic expression in terms of $a$, $b$, and $k$.\n\nYour final answer must be a single analytic expression. Do not introduce any numerical approximations or rounding.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and complete. It is a standard problem in linear systems theory and presents no inconsistencies or flaws. We may therefore proceed with the solution.\n\nThe squared $\\mathcal{H}_2$ norm of a stable, strictly proper, single-input single-output (SISO) linear time-invariant (LTI) system with state-space realization $(A, B, C, D=0)$ is defined by the total energy of its impulse response $g(t)$. The impulse response is given by $g(t) = C \\exp(At) B$ for $t \\ge 0$. Since $g(t)$ is a scalar, its squared magnitude is $|g(t)|^2 = g(t)^T g(t)$.\n\nThe squared $\\mathcal{H}_2$ norm can be expressed using the trace operator:\n$$\n\\|G\\|_{2}^{2} \\;=\\; \\int_{0}^{\\infty} |g(t)|^{2}\\,dt \\;=\\; \\int_{0}^{\\infty} \\text{Tr}\\left( g(t) g(t)^{T} \\right) dt\n$$\nSubstituting the expression for $g(t)$, we have:\n$$\n\\|G\\|_{2}^{2} \\;=\\; \\int_{0}^{\\infty} \\text{Tr}\\left( C \\exp(At) B B^{T} \\exp(A^{T}t) C^{T} \\right) dt\n$$\nUsing the linearity and cyclic property of the trace, we can move the integration inside:\n$$\n\\|G\\|_{2}^{2} \\;=\\; \\text{Tr}\\left( C \\left( \\int_{0}^{\\infty} \\exp(At) B B^{T} \\exp(A^{T}t) dt \\right) C^{T} \\right)\n$$\nThe integral term is the definition of the controllability Gramian $P$:\n$$\nP \\;=\\; \\int_{0}^{\\infty} \\exp(At) B B^{T} \\exp(A^{T}t) dt\n$$\nThis Gramian $P$ is the unique, symmetric, positive semi-definite solution to the continuous-time algebraic Lyapunov equation $AP + PA^{T} + BB^{T} = 0$, given that the matrix $A$ is Hurwitz (all its eigenvalues have negative real parts). The system is stated to be asymptotically stable, so this condition holds.\nThus, the squared $\\mathcal{H}_2$ norm is expressed in terms of the state-space matrices and the controllability Gramian $P$ as:\n$$\n\\|G\\|_{2}^{2} \\;=\\; \\text{Tr}\\left( C P C^{T} \\right)\n$$\nFor a SISO system, $C P C^T$ is a scalar, so we can write $\\|G\\|_{2}^{2} = C P C^{T}$. We now follow the specified steps.\n\n1. Construction of a minimal state-space realization.\nThe transfer function is $G(s) = \\frac{k}{(s+a)(s+b)}$. Since the poles at $s=-a$ and $s=-b$ are simple, we must have $a \\neq b$. We perform a partial fraction expansion:\n$$\nG(s) \\;=\\; \\frac{R_1}{s+a} + \\frac{R_2}{s+b}\n$$\nThe residues are calculated as:\n$$\nR_1 \\;=\\; \\lim_{s \\to -a} (s+a) G(s) \\;=\\; \\frac{k}{-a+b} \\;=\\; \\frac{k}{b-a}\n$$\n$$\nR_2 \\;=\\; \\lim_{s \\to -b} (s+b) G(s) \\;=\\; \\frac{k}{-b+a} \\;=\\; \\frac{k}{a-b}\n$$\nThis expansion directly leads to a diagonal (or modal) state-space realization. We define the state-space matrices $(A, B, C, D)$ as:\n$$\nA = \\begin{pmatrix} -a & 0 \\\\ 0 & -b \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} R_1 & R_2 \\end{pmatrix} = \\begin{pmatrix} \\frac{k}{b-a} & \\frac{k}{a-b} \\end{pmatrix}, \\quad D = 0\n$$\nThis realization is of order $n=2$ and is minimal because the system is controllable and observable for $a \\neq b$ and $k \\neq 0$. The matrix $A$ is diagonal with the system poles on the diagonal as required.\n\n2. Derivation and solution of the Lyapunov equation.\nThe controllability Gramian $P$ satisfies the Lyapunov equation $AP + PA^{T} + BB^{T} = 0$. We substitute the matrices from our realization. Let $P$ be a symmetric $2 \\times 2$ matrix:\n$$\nP = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix}\n$$\nThe matrix $A$ is diagonal, so $A^T=A$. The term $BB^T$ is:\n$$\nBB^{T} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}\n$$\nThe Lyapunov equation becomes:\n$$\n\\begin{pmatrix} -a & 0 \\\\ 0 & -b \\end{pmatrix} \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} + \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} \\begin{pmatrix} -a & 0 \\\\ 0 & -b \\end{pmatrix} + \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nPerforming the matrix multiplication gives:\n$$\n\\begin{pmatrix} -ap_{11} & -ap_{12} \\\\ -bp_{12} & -bp_{22} \\end{pmatrix} + \\begin{pmatrix} -ap_{11} & -bp_{12} \\\\ -ap_{12} & -bp_{22} \\end{pmatrix} + \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} -2ap_{11} + 1 & -(a+b)p_{12} + 1 \\\\ -(a+b)p_{12} + 1 & -2bp_{22} + 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nEquating the elements to zero yields a system of equations for the components of $P$:\n\\begin{itemize}\n    \\item $ -2ap_{11} + 1 = 0 \\quad \\implies \\quad p_{11} = \\frac{1}{2a} $\n    \\item $ -2bp_{22} + 1 = 0 \\quad \\implies \\quad p_{22} = \\frac{1}{2b} $\n    \\item $ -(a+b)p_{12} + 1 = 0 \\quad \\implies \\quad p_{12} = \\frac{1}{a+b} $\n\\end{itemize}\nThe controllability Gramian is therefore:\n$$\nP = \\begin{pmatrix} \\frac{1}{2a} & \\frac{1}{a+b} \\\\ \\frac{1}{a+b} & \\frac{1}{2b} \\end{pmatrix}\n$$\n\n3. Evaluation of the squared $\\mathcal{H}_2$ norm.\nWe now compute $\\|G\\|_{2}^{2} = C P C^{T}$:\n$$\n\\|G\\|_{2}^{2} = \\begin{pmatrix} \\frac{k}{b-a} & \\frac{k}{a-b} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2a} & \\frac{1}{a+b} \\\\ \\frac{1}{a+b} & \\frac{1}{2b} \\end{pmatrix} \\begin{pmatrix} \\frac{k}{b-a} \\\\ \\frac{k}{a-b} \\end{pmatrix}\n$$\nWe can factor out the scalar terms:\n$$\nC = \\frac{k}{a-b} \\begin{pmatrix} -1 & 1 \\end{pmatrix} \\quad \\text{and} \\quad C^{T} = \\frac{k}{a-b} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\|G\\|_{2}^{2} = \\frac{k^2}{(a-b)^2} \\begin{pmatrix} -1 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2a} & \\frac{1}{a+b} \\\\ \\frac{1}{a+b} & \\frac{1}{2b} \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}\n$$\nLet us evaluate the quadratic form:\n$$\n\\begin{pmatrix} -1 & 1 \\end{pmatrix} P \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} = p_{11} - 2p_{12} + p_{22} = \\frac{1}{2a} - \\frac{2}{a+b} + \\frac{1}{2b}\n$$\nCombining these terms with a common denominator:\n$$\n\\frac{b(a+b) - 4ab + a(a+b)}{2ab(a+b)} = \\frac{ab+b^2 - 4ab + a^2+ab}{2ab(a+b)} = \\frac{a^2 - 2ab + b^2}{2ab(a+b)} = \\frac{(a-b)^2}{2ab(a+b)}\n$$\nSubstituting this result back into the expression for $\\|G\\|_{2}^{2}$:\n$$\n\\|G\\|_{2}^{2} = \\frac{k^2}{(a-b)^2} \\cdot \\frac{(a-b)^2}{2ab(a+b)} = \\frac{k^2}{2ab(a+b)}\n$$\nThe term $(a-b)^2$ cancels, as expected for an expression that should be symmetric in $a$ and $b$.\n\n4. The $\\mathcal{H}_2$ norm.\nThe $\\mathcal{H}_2$ norm is the square root of the expression above. As the norm must be non-negative, we take the absolute value of $k$:\n$$\n\\|G\\|_{2} = \\sqrt{\\frac{k^2}{2ab(a+b)}} = \\frac{|k|}{\\sqrt{2ab(a+b)}}\n$$\nThis is the final closed-form expression in terms of $a$, $b$, and $k$.", "answer": "$$\n\\boxed{\\frac{|k|}{\\sqrt{2ab(a+b)}}}\n$$", "id": "2711596"}, {"introduction": "The tools of state-space analysis are powerful, but they require careful application. This exercise presents a cautionary tale, demonstrating how a non-minimal realization with hidden unstable modes can lead to invalid conclusions if the $\\mathcal{H}_2$ norm is computed naively [@problem_id:2711598]. By working through this problem, you will learn to dissect a system's internal structure, perform model reduction to find the minimal stable representation, and understand why the concept of a norm is fundamentally tied to the system's external input-output behavior.", "problem": "Consider the continuous-time, single-input single-output linear time-invariant realization with state-space matrices\n$$\nA \\;=\\; \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix}, \n\\quad B \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \n\\quad C \\;=\\; \\begin{pmatrix} 1 & 0 \\end{pmatrix}, \n\\quad D \\;=\\; 0.\n$$\nThe transfer function from input $u$ to output $y$ is therefore strictly proper. You are asked to analyze the Hardy space $\\mathcal{H}_{2}$ norm of the input-output map $G$ represented by this realization and to highlight the pitfall of working with a non-minimal realization.\n\nTasks:\n1. Using the fundamental definitions of reachability and observability (via the reachability and observability matrices) and internal stability (Hurwitz property of $A$), determine which modes are reachable and observable, and whether the full realization is internally stable. Explain why a naive attempt to compute an $\\mathcal{H}_{2}$ norm using a controllability Gramian for the full $A$ can fail or be misleading in this example.\n2. Determine the minimal (reachable and observable) internally stable realization associated with the given input-output map and write down its state-space matrices.\n3. Starting from first principles, derive the appropriate Lyapunov equation for the controllability Gramian of the minimal realization (justify existence of its solution using the Hurwitz property), solve it in closed form, and then compute $\\|G\\|_{2}$ of the transfer function represented by the minimal realization. Express your final answer as an exact real number (no rounding).", "solution": "The problem statement is scrutinized and found to be valid. It is a well-posed problem in linear control theory, presenting a classic case of a non-minimal realization with a hidden unstable mode. It is scientifically sound, objective, and contains all necessary information for a complete solution.\n\nThe solution will now proceed by addressing the three tasks in sequence.\n\nThe given continuous-time linear time-invariant (LTI) system is described by the state-space realization:\n$$\nA \\;=\\; \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix}, \n\\quad B \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \n\\quad C \\;=\\; \\begin{pmatrix} 1 & 0 \\end{pmatrix}, \n\\quad D \\;=\\; 0.\n$$\n\n**1. Analysis of Reachability, Observability, and Stability**\n\nFirst, we analyze the internal stability of the realization. A system is internally stable if and only if its state matrix $A$ is Hurwitz, meaning all its eigenvalues have strictly negative real parts. The eigenvalues of the diagonal matrix $A$ are its diagonal entries, $\\lambda_1 = -2$ and $\\lambda_2 = 1$. Since $\\text{Re}(\\lambda_2) = 1 > 0$, the matrix $A$ is not Hurwitz. Therefore, the realization is **not internally stable**.\n\nNext, we investigate reachability. A realization is reachable if and only if its reachability matrix $\\mathcal{R}$ has full rank. The state dimension is $n=2$. The reachability matrix is given by $\\mathcal{R} = \\begin{pmatrix} B & AB \\end{pmatrix}$.\n$$\nAB = \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\mathcal{R} = \\begin{pmatrix} 1 & -2 \\\\ 0 & 0 \\end{pmatrix}\n$$\nThe rank of $\\mathcal{R}$ is $1$, which is less than $n=2$. Thus, the realization is **not reachable**. The Popov-Hautus-Belevitch (PHB) test can identify which mode is unreachable. A mode $\\lambda$ is reachable if and only if $\\text{rank}\\begin{pmatrix} A - \\lambda I & B \\end{pmatrix} = n$.\nFor $\\lambda_1 = -2$: $\\text{rank}\\begin{pmatrix} A+2I & B \\end{pmatrix} = \\text{rank}\\begin{pmatrix} -2+2 & 0 & 1 \\\\ 0 & 1+2 & 0 \\end{pmatrix} = \\text{rank}\\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 3 & 0 \\end{pmatrix} = 2$. The stable mode at $\\lambda_1=-2$ is reachable.\nFor $\\lambda_2 = 1$: $\\text{rank}\\begin{pmatrix} A-I & B \\end{pmatrix} = \\text{rank}\\begin{pmatrix} -2-1 & 0 & 1 \\\\ 0 & 1-1 & 0 \\end{pmatrix} = \\text{rank}\\begin{pmatrix} -3 & 0 & 1 \\\\ 0 & 0 & 0 \\end{pmatrix} = 1$. The unstable mode at $\\lambda_2=1$ is unreachable.\n\nNext, we investigate observability. A realization is observable if and only if its observability matrix $\\mathcal{O}$ has full rank. The observability matrix is given by $\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}$.\n$$\nCA = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} -2 & 0 \\end{pmatrix}\n$$\n$$\n\\mathcal{O} = \\begin{pmatrix} 1 & 0 \\\\ -2 & 0 \\end{pmatrix}\n$$\nThe rank of $\\mathcal{O}$ is $1$, which is less than $n=2$. Thus, the realization is **not observable**. The PHB test for observability states that a mode $\\lambda$ is observable if and only if $\\text{rank}\\begin{pmatrix} A - \\lambda I \\\\ C \\end{pmatrix} = n$.\nFor $\\lambda_1 = -2$: $\\text{rank}\\begin{pmatrix} A+2I \\\\ C \\end{pmatrix} = \\text{rank}\\begin{pmatrix} 0 & 0 \\\\ 0 & 3 \\\\ 1 & 0 \\end{pmatrix} = 2$. The stable mode at $\\lambda_1=-2$ is observable.\nFor $\\lambda_2 = 1$: $\\text{rank}\\begin{pmatrix} A-I \\\\ C \\end{pmatrix} = \\text{rank}\\begin{pmatrix} -3 & 0 \\\\ 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = 1$. The unstable mode at $\\lambda_2=1$ is not observable.\n\nThe pitfall of naively computing the $\\mathcal{H}_2$ norm for this realization is as follows. The $\\mathcal{H}_2$ norm is fundamentally defined for **stable** systems. For a stable system $(A, B, C, D)$ with $A$ being Hurwitz, the controllability Gramian $P_c$ is defined by the convergent integral:\n$$\nP_c = \\int_{0}^{\\infty} \\exp(At) B B^T \\exp(A^T t) \\, dt\n$$\nThis Gramian is the unique positive semi-definite solution to the algebraic Lyapunov equation $AP_c + P_cA^T + BB^T = 0$. The $\\mathcal{H}_2$ norm is then $\\|G\\|_2^2 = \\text{Tr}(CP_cC^T)$. In the given problem, $A$ is not Hurwitz, so the integral defining $P_c$ diverges. Thus, the controllability Gramian is not defined for this system in the standard sense, and consequently the $\\mathcal{H}_2$ norm is, by first principles, not defined for this unstable realization. Although the algebraic Lyapunov equation may possess a unique solution (which it does in this case, as $\\lambda_i(A)+\\lambda_j(A) \\neq 0$ for all $i,j$), using this solution in the norm formula is an invalid procedure. The procedure accidentally gives the correct norm of the *transfer function* only because the unstable mode is both unreachable and unobservable, meaning it is decoupled from the input-output map and cancels out in the transfer function. In a general unstable system, this blind computation would yield a meaningless finite number, or the solution to the Lyapunov equation would not even be positive semi-definite, which is a required property of a Gramian.\n\n**2. Minimal Internally Stable Realization**\n\nTo find the minimal realization, we first compute the transfer function $G(s) = C(sI-A)^{-1}B+D$.\n$$\nG(s) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\left( s \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right)^{-1} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nG(s) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} s+2 & 0 \\\\ 0 & s-1 \\end{pmatrix}^{-1} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{s+2} & 0 \\\\ 0 & \\frac{1}{s-1} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nG(s) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{s+2} \\\\ 0 \\end{pmatrix} = \\frac{1}{s+2}\n$$\nThe pole at $s=1$ associated with the unstable mode is cancelled because it is both unreachable and unobservable. The input-output map is described by the stable, first-order transfer function $G(s) = \\frac{1}{s+2}$.\n\nThe minimal realization is the reachable and observable part of the system, which corresponds to this transfer function. For a scalar transfer function $G(s) = \\frac{b}{s-a}$, a minimal realization is $(A_{min}, B_{min}, C_{min}, D_{min}) = (a, k, b/k, 0)$ for any $k \\neq 0$. For $G(s) = \\frac{1}{s+2}$, we have $a=-2$ and $b=1$. A canonical choice is to set $k=1$. The minimal realization is therefore:\n$$\nA_{min} = -2, \\quad B_{min} = 1, \\quad C_{min} = 1, \\quad D_{min} = 0\n$$\nThis realization is minimal (first-order for a first-order transfer function) and internally stable, since its sole eigenvalue is $-2 < 0$.\n\n**3. $\\mathcal{H}_2$ Norm Calculation**\n\nWe now compute the $\\mathcal{H}_2$ norm using the minimal, internally stable realization $(A_{min}, B_{min}, C_{min})$. Since $A_{min}=-2$ is Hurwitz, the controllability Gramian $P_{c,min}$ exists and is the unique, positive definite solution to the Lyapunov equation:\n$$\nA_{min} P_{c,min} + P_{c,min} A_{min}^T + B_{min} B_{min}^T = 0\n$$\nAs these are scalars, we denote $P_{c,min}$ by $p_c$:\n$$\n(-2)p_c + p_c(-2) + (1)(1) = 0\n$$\n$$\n-4p_c + 1 = 0 \\implies p_c = \\frac{1}{4}\n$$\nThe controllability Gramian is $P_{c,min} = \\frac{1}{4}$.\nThe squared $\\mathcal{H}_2$ norm is given by the formula $\\|G\\|_2^2 = \\text{Tr}(C_{min} P_{c,min} C_{min}^T)$.\n$$\n\\|G\\|_2^2 = \\text{Tr}\\left((1)\\left(\\frac{1}{4}\\right)(1)\\right) = \\text{Tr}\\left(\\frac{1}{4}\\right) = \\frac{1}{4}\n$$\nThe $\\mathcal{H}_2$ norm is the square root of this value:\n$$\n\\|G\\|_2 = \\sqrt{\\frac{1}{4}} = \\frac{1}{2}\n$$\nThis result is consistent with the direct frequency-domain calculation for $G(s) = \\frac{1}{s+2}$.\n$$\n\\|G\\|_2^2 = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} |G(j\\omega)|^2 d\\omega = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{1}{\\omega^2 + 4} d\\omega = \\frac{1}{2\\pi} \\left[ \\frac{1}{2}\\arctan\\left(\\frac{\\omega}{2}\\right) \\right]_{-\\infty}^{\\infty} = \\frac{1}{2\\pi} \\left(\\frac{\\pi}{2}\\right) = \\frac{1}{4}\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "2711598"}, {"introduction": "Moving from single-input, single-output (SISO) to multiple-input, multiple-output (MIMO) systems reveals a richer and more complex set of behaviors. This problem explores the concept of the $\\mathcal{H}_{\\infty}$ norm, which measures a system's peak amplification gain, and contrasts it with the energy-based $\\mathcal{H}_2$ norm [@problem_id:2711616]. By comparing a coupled MIMO system with its decoupled counterpart, you will use singular value analysis to uncover how input-output directionality can significantly amplify system gain, a key insight for robust control design in multidimensional systems.", "problem": "Consider the following strictly proper, stable Multiple-Input Multiple-Output (MIMO) Linear Time-Invariant (LTI) transfer matrices, both with the same diagonal entries. Define\n$$\nG(s) \\;=\\; \\frac{1}{s+1}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix},\n\\qquad\nG_{d}(s) \\;=\\; \\begin{bmatrix} \\dfrac{1}{s+1} & 0 \\\\ 0 & \\dfrac{1}{s+1} \\end{bmatrix}.\n$$\nYou will compute the Hardy space $\\mathcal{H}_{2}$ system norm and the $\\mathcal{H}_{\\infty}$ system norm of both $G(s)$ and $G_{d}(s)$ starting from first principles. Use the following foundational bases only: the definitions of the $\\mathcal{H}_{2}$ norm as the square root of the frequency-domain energy integral of the trace of $G(\\mathrm{j}\\omega)G(\\mathrm{j}\\omega)^{*}$ for strictly proper, stable LTI systems, and the $\\mathcal{H}_{\\infty}$ norm as the supremum over frequency of the largest singular value of $G(\\mathrm{j}\\omega)$. Explain why the off-diagonal coupling in $G(s)$ produces an alignment of singular vector directions across frequency that yields a strictly larger $\\|G\\|_{\\infty}$ than that of the diagonal system $G_{d}(s)$ with the same diagonal entries. \n\nYour final answer must be a single row vector containing the four quantities in this order:\n$$\n\\bigl\\|G\\bigr\\|_{\\mathcal{H}_{2}},\\quad \\bigl\\|G\\bigr\\|_{\\infty},\\quad \\bigl\\|G_{d}\\bigr\\|_{\\mathcal{H}_{2}},\\quad \\bigl\\|G_{d}\\bigr\\|_{\\infty}.\n$$\nNo rounding is required. Express the final answer as exact values.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of linear systems and control theory, is well-posed, and all necessary information for its solution is provided. We will proceed with the analysis.\n\nThe problem requires the calculation of the $\\mathcal{H}_2$ and $\\mathcal{H}_{\\infty}$ norms for two systems, $G(s)$ and $G_d(s)$, and an explanation of the difference in their $\\mathcal{H}_{\\infty}$ norms. We will address each system in turn, based on the provided first principles.\n\nLet us define the complex conjugate transpose (Hermitian conjugate) of a matrix $M(s)$ as $M(s)^* \\triangleq M(-\\bar{s})^T$. For a frequency response $M(\\mathrm{j}\\omega)$, this becomes $M(\\mathrm{j}\\omega)^* = M(-\\mathrm{j}\\omega)^T$.\n\nThe $\\mathcal{H}_2$ norm for a strictly proper, stable LTI system $G(s)$ is given by the formula:\n$$\n\\|G\\|_{\\mathcal{H}_2}^2 = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\mathrm{trace}\\left(G(\\mathrm{j}\\omega)G(\\mathrm{j}\\omega)^*\\right) d\\omega\n$$\nThe $\\mathcal{H}_{\\infty}$ norm is defined as the peak gain over all frequencies:\n$$\n\\|G\\|_{\\infty} = \\sup_{\\omega \\in \\mathbb{R}} \\bar{\\sigma}(G(\\mathrm{j}\\omega))\n$$\nwhere $\\bar{\\sigma}(\\cdot)$ denotes the largest singular value of a matrix.\n\nFirst, we analyze the coupled system $G(s) = \\frac{1}{s+1}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$.\nThe frequency response is $G(\\mathrm{j}\\omega) = \\frac{1}{\\mathrm{j}\\omega+1}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$.\nIts conjugate transpose is $G(\\mathrm{j}\\omega)^* = \\left(\\frac{1}{-\\mathrm{j}\\omega+1}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\right)^T = \\frac{1}{1-\\mathrm{j}\\omega}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$.\n\nTo compute the $\\mathcal{H}_2$ norm of $G(s)$, we first find the product $G(\\mathrm{j}\\omega)G(\\mathrm{j}\\omega)^*$:\n$$\nG(\\mathrm{j}\\omega)G(\\mathrm{j}\\omega)^* = \\left(\\frac{1}{\\mathrm{j}\\omega+1}\\right)\\left(\\frac{1}{1-\\mathrm{j}\\omega}\\right) \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} = \\frac{1}{1+\\omega^2} \\begin{bmatrix} 2 & 2 \\\\ 2 & 2 \\end{bmatrix}\n$$\nThe trace of this matrix is:\n$$\n\\mathrm{trace}\\left(G(\\mathrm{j}\\omega)G(\\mathrm{j}\\omega)^*\\right) = \\mathrm{trace}\\left(\\frac{1}{1+\\omega^2} \\begin{bmatrix} 2 & 2 \\\\ 2 & 2 \\end{bmatrix}\\right) = \\frac{2}{1+\\omega^2} + \\frac{2}{1+\\omega^2} = \\frac{4}{1+\\omega^2}\n$$\nNow we integrate this expression to find the squared $\\mathcal{H}_2$ norm:\n$$\n\\|G\\|_{\\mathcal{H}_2}^2 = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{4}{1+\\omega^2} d\\omega = \\frac{4}{2\\pi} \\left[ \\arctan(\\omega) \\right]_{-\\infty}^{\\infty} = \\frac{2}{\\pi} \\left( \\frac{\\pi}{2} - \\left(-\\frac{\\pi}{2}\\right) \\right) = \\frac{2}{\\pi}(\\pi) = 2\n$$\nThus, the $\\mathcal{H}_2$ norm of $G(s)$ is $\\|G\\|_{\\mathcal{H}_2} = \\sqrt{2}$.\n\nTo compute the $\\mathcal{H}_{\\infty}$ norm of $G(s)$, we must find the largest singular value of $G(\\mathrm{j}\\omega)$ and take its supremum over $\\omega$. The singular values of $G(\\mathrm{j}\\omega)$ are given by:\n$$\n\\sigma_i(G(\\mathrm{j}\\omega)) = \\left|\\frac{1}{\\mathrm{j}\\omega+1}\\right| \\sigma_i\\left(\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\right) = \\frac{1}{\\sqrt{1+\\omega^2}} \\sigma_i\\left(\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\right)\n$$\nLet $A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$. The singular values of $A$ are the square roots of the eigenvalues of $A^T A$.\n$$\nA^T A = \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 2 & 2 \\\\ 2 & 2 \\end{bmatrix}\n$$\nThe characteristic equation is $\\det(A^T A - \\lambda I) = (2-\\lambda)^2 - 4 = 0$, which gives eigenvalues $\\lambda_1 = 4$ and $\\lambda_2 = 0$.\nThe singular values of $A$ are $\\sigma_1(A) = \\sqrt{4} = 2$ and $\\sigma_2(A) = \\sqrt{0} = 0$.\nThe largest singular value of $A$ is $\\bar{\\sigma}(A) = 2$.\nTherefore, the largest singular value of $G(\\mathrm{j}\\omega)$ as a function of $\\omega$ is:\n$$\n\\bar{\\sigma}(G(\\mathrm{j}\\omega)) = \\frac{2}{\\sqrt{1+\\omega^2}}\n$$\nThe $\\mathcal{H}_{\\infty}$ norm is the supremum of this function, which occurs at $\\omega = 0$:\n$$\n\\|G\\|_{\\infty} = \\sup_{\\omega} \\frac{2}{\\sqrt{1+\\omega^2}} = \\frac{2}{\\sqrt{1+0^2}} = 2\n$$\n\nNext, we analyze the diagonal system $G_d(s) = \\begin{bmatrix} \\frac{1}{s+1} & 0 \\\\ 0 & \\frac{1}{s+1} \\end{bmatrix} = \\frac{1}{s+1} I$.\nThe frequency response is $G_d(\\mathrm{j}\\omega) = \\frac{1}{\\mathrm{j}\\omega+1} I$.\nIts conjugate transpose is $G_d(\\mathrm{j}\\omega)^* = \\frac{1}{1-\\mathrm{j}\\omega} I$.\n\nFor the $\\mathcal{H}_2$ norm of $G_d(s)$, we compute the product:\n$$\nG_d(\\mathrm{j}\\omega)G_d(\\mathrm{j}\\omega)^* = \\left(\\frac{1}{\\mathrm{j}\\omega+1}\\right)\\left(\\frac{1}{1-\\mathrm{j}\\omega}\\right) I \\cdot I = \\frac{1}{1+\\omega^2} I = \\begin{bmatrix} \\frac{1}{1+\\omega^2} & 0 \\\\ 0 & \\frac{1}{1+\\omega^2} \\end{bmatrix}\n$$\nThe trace of this matrix is:\n$$\n\\mathrm{trace}\\left(G_d(\\mathrm{j}\\omega)G_d(\\mathrm{j}\\omega)^*\\right) = \\frac{1}{1+\\omega^2} + \\frac{1}{1+\\omega^2} = \\frac{2}{1+\\omega^2}\n$$\nIntegrating this expression gives the squared $\\mathcal{H}_2$ norm:\n$$\n\\|G_d\\|_{\\mathcal{H}_2}^2 = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{2}{1+\\omega^2} d\\omega = \\frac{2}{2\\pi} \\left[ \\arctan(\\omega) \\right]_{-\\infty}^{\\infty} = \\frac{1}{\\pi}(\\pi) = 1\n$$\nThus, the $\\mathcal{H}_2$ norm of $G_d(s)$ is $\\|G_d\\|_{\\mathcal{H}_2} = \\sqrt{1} = 1$.\n\nFor the $\\mathcal{H}_{\\infty}$ norm of $G_d(s)$, we examine its singular values. Since $G_d(\\mathrm{j}\\omega)$ is a scalar multiple of the identity matrix, its singular values are the magnitude of this scalar:\n$$\n\\bar{\\sigma}(G_d(\\mathrm{j}\\omega)) = \\bar{\\sigma}\\left(\\frac{1}{\\mathrm{j}\\omega+1} I\\right) = \\left|\\frac{1}{\\mathrm{j}\\omega+1}\\right| \\bar{\\sigma}(I) = \\frac{1}{\\sqrt{1+\\omega^2}} \\cdot 1 = \\frac{1}{\\sqrt{1+\\omega^2}}\n$$\nThe $\\mathcal{H}_{\\infty}$ norm is the supremum of this function, which occurs at $\\omega = 0$:\n$$\n\\|G_d\\|_{\\infty} = \\sup_{\\omega} \\frac{1}{\\sqrt{1+\\omega^2}} = \\frac{1}{\\sqrt{1+0^2}} = 1\n$$\n\nFinally, we must explain why $\\|G\\|_{\\infty} = 2$ is strictly larger than $\\|G_d\\|_{\\infty} = 1$.\nThe $\\mathcal{H}_{\\infty}$ norm represents the maximum amplification, or gain, the system can apply to an input signal across all frequencies and all input directions.\nFor the decoupled system $G_d(s)$, the transfer matrix is $G_d(\\mathrm{j}\\omega) = c(\\omega)I$, where $c(\\omega) = 1/(\\mathrm{j}\\omega+1)$. This system is isotropic; it scales any input vector $u$ by the complex scalar $c(\\omega)$ without changing its direction. The gain is $|c(\\omega)|$ for all input directions. The maximum possible gain is simply the maximum value of $|c(\\omega)|$, which is $\\sup_{\\omega} |c(\\omega)| = 1$.\n\nFor the coupled system $G(s)$, the transfer matrix is $G(\\mathrm{j}\\omega) = c(\\omega)A$, where $A=\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$. The gain of this system depends on the input direction. The singular value decomposition of $G(\\mathrm{j}\\omega)$ reveals this directional dependence. The right singular vectors of $G(\\mathrm{j}\\omega)$ identify the input directions, and the corresponding singular values give the amplification for those directions. The singular values of $G(\\mathrm{j}\\omega)$ are $|c(\\omega)|$ times the singular values of the constant matrix $A$. As we calculated, the largest singular value of $A$ is $\\bar{\\sigma}(A) = 2$.\nThis largest singular value corresponds to the right singular vector $v_1 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$. For an input signal $u(\\omega)$ aligned with this direction, the system gain is $|c(\\omega)|\\bar{\\sigma}(A) = 2|c(\\omega)|$.\n\nThe critical observation is that the singular vectors of the matrix $A$ are constant. This means the right singular vectors of $G(\\mathrm{j}\\omega)$ are also constant with respect to frequency $\\omega$. Specifically, the direction of maximum amplification for $G(s)$, $v_1 = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, is the same at all frequencies. This is what is meant by \"alignment of singular vector directions across frequency\". The system has a fixed, preferred input direction which it amplifies most. The overall system gain, $\\|G\\|_{\\infty}$, is the maximum of this peak directional gain over all frequencies:\n$$\n\\|G\\|_{\\infty} = \\sup_{\\omega} \\left( \\bar{\\sigma}(A) \\left|\\frac{1}{\\mathrm{j}\\omega+1}\\right| \\right) = 2 \\cdot \\sup_{\\omega} \\frac{1}{\\sqrt{1+\\omega^2}} = 2 \\cdot 1 = 2\n$$\nThe off-diagonal coupling in $G(s)$ creates constructive interference for inputs in the direction $v_1$. The input $u_1$ and $u_2$ are in phase, they pass through identical dynamics, and the outputs are summed, yielding a gain of $2$ at DC ($\\omega=0$). In contrast, $G_d(s)$ lacks this coupling mechanism for constructive interference between channels, so its gain is limited to the maximum gain of a single channel, which is $1$.\n\nThe four quantities are thus: $\\|G\\|_{\\mathcal{H}_{2}} = \\sqrt{2}$, $\\|G\\|_{\\infty}=2$, $\\|G_{d}\\|_{\\mathcal{H}_{2}}=1$, and $\\|G_{d}\\|_{\\infty}=1$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{2} & 2 & 1 & 1 \\end{pmatrix}}\n$$", "id": "2711616"}]}