{"hands_on_practices": [{"introduction": "Beyond calculating eigenvectors, a more powerful algebraic method exists for determining the structure of a matrix's Jordan Canonical Form. This practice focuses on deciphering the sizes and number of Jordan blocks directly from the sequence of nullities of the powers of $(A - \\lambda I)$. This technique provides a systematic way to construct the Jordan form, especially for larger matrices where finding a complete Jordan basis can be cumbersome [@problem_id:1014888].", "problem": "Consider a 5×5 matrix $A$ with a single eigenvalue $\\lambda$ of algebraic multiplicity 5. Given that the nullities of the powers of $A - \\lambda I$ are:\n\n$$\n\\operatorname{nullity}(A - \\lambda I) = 2, \\quad \\operatorname{nullity}((A - \\lambda I)^2) = 4, \\quad \\operatorname{nullity}((A - \\lambda I)^3) = 5.\n$$\n\nDetermine the sizes of the Jordan blocks corresponding to $\\lambda$ in the Jordan canonical form of $A$. Express your answer as a tuple of block sizes in non-increasing order.", "solution": "We have a single eigenvalue $\\lambda$ of algebraic multiplicity $5$ and denoting \n$$m_k=\\operatorname{nullity}\\bigl((A-\\lambda I)^k\\bigr),$$\nwe know \n$$m_1=2,\\quad m_2=4,\\quad m_3=5.$$ \nIf the Jordan blocks for $\\lambda$ have sizes $r_1\\ge r_2\\ge\\cdots\\ge r_s$, then \n$$m_k=\\sum_{i=1}^s\\min(k,r_i).$$ \nSince $m_1=2$, there are exactly $2$ Jordan blocks, say of sizes $r_1\\ge r_2$. \n\n1.  From $m_1=2$ we get \n   $$\\min(1,r_1)+\\min(1,r_2)=2\\;\\Longrightarrow\\;r_1\\ge1,\\;r_2\\ge1.$$\n2.  From $m_2=4$ we get \n   $$\\min(2,r_1)+\\min(2,r_2)=4\\;\\Longrightarrow\\;2+2=4,\\;\\text{so }r_1\\ge2,\\;r_2\\ge2.$$\n3.  From $m_3=5$ we get \n   $$\\min(3,r_1)+\\min(3,r_2)=5.$$\n   The only way to write $5$ as a sum of two terms each at most $3$ is $3+2$.  Hence \n   $$r_1\\ge3,\\quad r_2=2,\\quad r_1+r_2=5\\;\\Longrightarrow\\;r_1=3,\\;r_2=2.$$\nThus the Jordan block sizes are $(3,2)$.", "answer": "$$\\boxed{(3,2)}$$", "id": "1014888"}, {"introduction": "A deep understanding of the Jordan Canonical Form (JCF) requires knowing not just how to find it, but also what it represents. This exercise challenges a common misconception by exploring the relationship between a matrix's JCF and other invariants like its characteristic and minimal polynomials. By analyzing counterexamples, you will solidify your understanding of why the JCF is the ultimate criterion for determining if two matrices are similar [@problem_id:1776545].", "problem": "In linear algebra, two square matrices $A$ and $B$ are said to be similar if there exists an invertible matrix $P$ such that $B = P^{-1}AP$. A fundamental theorem states that two complex matrices are similar if and only if they have the same Jordan Canonical Form (JCF), up to a permutation of the Jordan blocks.\n\nWhile it is true that similar matrices must have the same characteristic polynomial and the same minimal polynomial, the converse is not always true. Your task is to identify a pair of matrices that serves as a counterexample to the statement: \"If two matrices have the same characteristic polynomial and the same minimal polynomial, then they are similar.\"\n\nLet $J_k(\\lambda)$ denote a $k \\times k$ Jordan block with eigenvalue $\\lambda$. For example,\n$$ J_3(\\lambda) = \\begin{pmatrix} \\lambda & 1 & 0 \\\\ 0 & \\lambda & 1 \\\\ 0 & 0 & \\lambda \\end{pmatrix} $$\nAlso, let $\\text{diag}(M_1, M_2, \\dots, M_n)$ denote a block diagonal matrix with the square matrices $M_1, M_2, \\dots, M_n$ on its diagonal.\n\nWhich of the following pairs of matrices $(A, B)$ constitutes a valid counterexample?\n\nA. $A = \\text{diag}(J_3(5), J_3(5))$, $B = \\text{diag}(J_3(5), J_2(5), J_1(5))$\n\nB. $A = \\text{diag}(J_4(5), J_2(5))$, $B = \\text{diag}(J_3(5), J_3(5))$\n\nC. $A = \\text{diag}(J_3(5), J_3(5))$, $B = \\text{diag}(J_3(2), J_3(2))$\n\nD. $A = \\text{diag}(J_3(5), J_2(5), J_1(5))$, $B = \\text{diag}(J_1(5), J_3(5), J_2(5))$", "solution": "Two complex matrices are similar if and only if they have the same Jordan canonical form, i.e., the same multiset of Jordan block sizes for each eigenvalue. For a Jordan block $J_{k}(\\lambda)$, the characteristic polynomial is $(x-\\lambda)^{k}$. For a block-diagonal matrix $\\text{diag}(J_{k_{1}}(\\lambda),\\dots,J_{k_{r}}(\\lambda))$ with a single eigenvalue $\\lambda$, the characteristic polynomial is\n$$\np(x)=(x-\\lambda)^{k_{1}+\\cdots+k_{r}},\n$$\nand the minimal polynomial is\n$$\n\\mu(x)=(x-\\lambda)^{\\max\\{k_{1},\\dots,k_{r}\\}}.\n$$\nThus two matrices with a single eigenvalue have the same characteristic and minimal polynomials precisely when the sum of the block sizes and the largest block size coincide, but they need not have the same Jordan block multiset.\n\nEvaluate each option:\n\nOption A: $A=\\text{diag}(J_{3}(5),J_{3}(5))$ and $B=\\text{diag}(J_{3}(5),J_{2}(5),J_{1}(5))$. For both matrices, the characteristic polynomial is\n$$\np_{A}(x)=p_{B}(x)=(x-5)^{6},\n$$\nand the minimal polynomial is\n$$\n\\mu_{A}(x)=\\mu_{B}(x)=(x-5)^{3}.\n$$\nHowever, the Jordan block multisets differ: $\\{3,3\\}$ versus $\\{3,2,1\\}$. Therefore $A$ and $B$ are not similar. This is a valid counterexample.\n\nOption B: $A=\\text{diag}(J_{4}(5),J_{2}(5))$ and $B=\\text{diag}(J_{3}(5),J_{3}(5))$. Both have\n$$\np_{A}(x)=p_{B}(x)=(x-5)^{6},\n$$\nbut the minimal polynomials are\n$$\n\\mu_{A}(x)=(x-5)^{4},\\quad \\mu_{B}(x)=(x-5)^{3},\n$$\nwhich are not equal. This does not meet the premise.\n\nOption C: $A=\\text{diag}(J_{3}(5),J_{3}(5))$ and $B=\\text{diag}(J_{3}(2),J_{3}(2))$. The characteristic polynomials are\n$$\np_{A}(x)=(x-5)^{6},\\quad p_{B}(x)=(x-2)^{6},\n$$\nwhich are not equal. This does not meet the premise.\n\nOption D: $A=\\text{diag}(J_{3}(5),J_{2}(5),J_{1}(5))$ and $B=\\text{diag}(J_{1}(5),J_{3}(5),J_{2}(5))$. These have identical Jordan blocks up to permutation, hence are similar by definition. This is not a counterexample.\n\nTherefore, the only valid counterexample is Option A.", "answer": "$$\\boxed{A}$$", "id": "1776545"}, {"introduction": "The Jordan form is not just an abstract classification tool; it has profound implications for the stability and robustness of dynamical systems. This advanced practice explores the sensitivity of defective matrices—those with Jordan blocks of size greater than one—to small perturbations. You will connect the algebraic structure of a simple Jordan block to the analytical concept of the pseudospectrum, revealing why the dynamics of systems represented by defective matrices can be surprisingly fragile [@problem_id:2715178].", "problem": "Consider the defective matrix $A_{0} \\in \\mathbb{C}^{2 \\times 2}$ given by $A_{0} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, which consists of a single size-$2$ Jordan block with eigenvalue $0$. Let $B = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ be an arbitrary fixed matrix with $c \\neq 0$, and consider the perturbed matrix family $A(\\delta) = A_{0} + \\delta B$ for a small scalar $\\delta \\in \\mathbb{R}$. Start from the core definitions in matrix perturbation theory and linear algebra: the characteristic polynomial, the Jordan decomposition, and the definition of the $\\varepsilon$-pseudospectrum in the matrix $2$-norm,\n$$\n\\sigma_{\\varepsilon}(A) \\triangleq \\left\\{ z \\in \\mathbb{C} : \\left\\| (z I - A)^{-1} \\right\\|_{2} \\geq \\frac{1}{\\varepsilon} \\right\\} = \\left\\{ z \\in \\mathbb{C} : \\exists \\,\\Delta \\in \\mathbb{C}^{2 \\times 2}, \\ \\|\\Delta\\|_{2} \\leq \\varepsilon, \\ z \\in \\sigma(A + \\Delta) \\right\\}.\n$$\nUsing only these foundational elements, first justify why, for generic perturbations with $c \\neq 0$, the double eigenvalue at $0$ of $A_{0}$ typically splits into two distinct eigenvalues of $A(\\delta)$ whose leading-order deviations scale like $\\delta^{1/2}$. Then connect this splitting to the small-$\\varepsilon$ geometry of $\\sigma_{\\varepsilon}(A_{0})$ by analyzing the $2$-norm of the resolvent $(z I - A_{0})^{-1}$ for $z$ near $0$, and by invoking the perturbation characterization above.\n\nDefine the outer pseudospectral radius \n$$\nr(\\varepsilon) \\triangleq \\sup \\{ |z| : z \\in \\sigma_{\\varepsilon}(A_{0}) \\}.\n$$\nDetermine the leading-order asymptotic expression of $r(\\varepsilon)$ as $\\varepsilon \\to 0^{+}$, simplifying your final result to a single closed-form analytic expression in $\\varepsilon$. No numerical rounding is required, and no units are involved. Your final answer must consist only of this single expression.", "solution": "The problem is divided into two parts. First, we must analyze the perturbation of the eigenvalues of the defective matrix $A_{0} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$ by a generic matrix. Second, we must connect this behavior to the geometry of the pseudospectrum of $A_{0}$ and determine the leading-order asymptotics of its outer radius.\n\nLet us begin with the first part: eigenvalue perturbation analysis.\nThe perturbed matrix is given by $A(\\delta) = A_{0} + \\delta B$, where $A_{0} = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$ and $B = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ with the condition $c \\neq 0$.\nThe matrix $A(\\delta)$ is explicitly\n$$\nA(\\delta) = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} + \\delta \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = \\begin{pmatrix} \\delta a & 1 + \\delta b \\\\ \\delta c & \\delta d \\end{pmatrix}.\n$$\nThe eigenvalues $\\lambda$ of $A(\\delta)$ are the roots of the characteristic polynomial $p(\\lambda) = \\det(\\lambda I - A(\\delta)) = 0$.\nWe compute the characteristic polynomial:\n$$\np(\\lambda) = \\det \\begin{pmatrix} \\lambda - \\delta a & -(1 + \\delta b) \\\\ -\\delta c & \\lambda - \\delta d \\end{pmatrix} = (\\lambda - \\delta a)(\\lambda - \\delta d) - \\delta c(1 + \\delta b).\n$$\nExpanding this expression gives\n$$\np(\\lambda) = \\lambda^{2} - \\delta(a+d)\\lambda + \\delta^{2}ad - \\delta c - \\delta^{2}bc = \\lambda^{2} - \\delta(a+d)\\lambda - \\delta c + \\delta^{2}(ad-bc) = 0.\n$$\nFor $\\delta=0$, this equation reduces to $\\lambda^{2}=0$, which corresponds to the double eigenvalue $\\lambda=0$ of the matrix $A_0$.\nFor $\\delta \\neq 0$, we solve the quadratic equation for $\\lambda$:\n$$\n\\lambda(\\delta) = \\frac{\\delta(a+d) \\pm \\sqrt{(\\delta(a+d))^{2} - 4(-\\delta c + \\delta^{2}(ad-bc))}}{2} = \\frac{\\delta(a+d) \\pm \\sqrt{\\delta^{2}(a+d)^{2} + 4\\delta c - 4\\delta^{2}(ad-bc)}}{2}.\n$$\nTo analyze the behavior for small $\\delta$, we examine the discriminant, $\\Delta_{\\lambda}$:\n$$\n\\Delta_{\\lambda} = 4\\delta c + \\delta^{2} \\left( (a+d)^{2} - 4(ad-bc) \\right).\n$$\nSince $c \\neq 0$ is given, for sufficiently small $\\delta$, the term $4\\delta c$ is the dominant term. The asymptotic behavior of the square root is\n$$\n\\sqrt{\\Delta_{\\lambda}} = \\sqrt{4\\delta c + O(\\delta^{2})} = \\sqrt{4\\delta c} \\sqrt{1 + O(\\delta)} = 2\\sqrt{c\\delta} \\left(1 + O(\\delta)\\right) = 2\\sqrt{c}\\delta^{1/2} + O(\\delta^{3/2}).\n$$\nSubstituting this back into the expression for the eigenvalues:\n$$\n\\lambda(\\delta) = \\frac{\\delta(a+d) \\pm (2\\sqrt{c}\\delta^{1/2} + O(\\delta^{3/2}))}{2} = \\pm\\sqrt{c}\\delta^{1/2} + \\frac{1}{2}(a+d)\\delta + O(\\delta^{3/2}).\n$$\nThe leading-order term in this expansion is $\\pm\\sqrt{c}\\delta^{1/2}$. This proves that a generic perturbation of size $\\delta$ splits the double eigenvalue at $0$ into two distinct eigenvalues whose deviation from $0$ scales with $\\delta^{1/2}$. This fractional power dependence is a hallmark of perturbations to defective eigenvalues.\n\nNow we proceed to the second part: the connection to the pseudospectrum and the derivation of the outer pseudospectral radius $r(\\varepsilon)$.\nThe first part of our analysis demonstrates that there exist perturbations $\\Delta = \\delta B$ of norm $\\|\\Delta\\|_{2} = |\\delta|\\|B\\|_{2}$ that move the eigenvalues by an amount of order $|\\delta|^{1/2}$. Setting $\\varepsilon = |\\delta|\\|B\\|_{2}$, this is of order $\\varepsilon^{1/2}$. The pseudospectrum $\\sigma_{\\varepsilon}(A_{0})$ is the union of all such eigenvalues over all possible perturbations $\\Delta$ with $\\|\\Delta\\|_{2} \\leq \\varepsilon$. This suggests that the extent of the pseudospectrum will scale as $\\varepsilon^{1/2}$.\n\nTo formalize this and find the precise leading-order expression for $r(\\varepsilon)$, we use the equivalent definition of the pseudospectrum via the resolvent norm:\n$$\n\\sigma_{\\varepsilon}(A_{0}) = \\left\\{ z \\in \\mathbb{C} : \\left\\| (z I - A_{0})^{-1} \\right\\|_{2} \\geq \\frac{1}{\\varepsilon} \\right\\}.\n$$\nFirst, we compute the resolvent of $A_{0}$:\n$$\n(z I - A_{0})^{-1} = \\begin{pmatrix} z & -1 \\\\ 0 & z \\end{pmatrix}^{-1} = \\frac{1}{z^{2}} \\begin{pmatrix} z & 1 \\\\ 0 & z \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{z} & \\frac{1}{z^2} \\\\ 0 & \\frac{1}{z} \\end{pmatrix}.\n$$\nLet us denote this resolvent matrix as $R(z)$. Its $2$-norm is its largest singular value, $\\|R(z)\\|_2 = \\sigma_{\\max}(R(z))$. This is given by the square root of the largest eigenvalue of $R(z)^* R(z)$.\n$$\nR(z)^*R(z) = \\begin{pmatrix} \\frac{1}{\\bar{z}} & 0 \\\\ \\frac{1}{\\bar{z}^2} & \\frac{1}{\\bar{z}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{z} & \\frac{1}{z^2} \\\\ 0 & \\frac{1}{z} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{|z|^2} & \\frac{1}{\\bar{z}z^2} \\\\ \\frac{1}{z\\bar{z}^2} & \\frac{1}{|z|^4} + \\frac{1}{|z|^2} \\end{pmatrix}.\n$$\nLet $x = 1/|z|^2$. The characteristic polynomial of this matrix is\n$$\n\\det\\begin{pmatrix} x - \\lambda_H & \\frac{z}{|z|^4} \\\\ \\frac{\\bar{z}}{|z|^4} & x^2+x - \\lambda_H \\end{pmatrix} = 0.\n$$\n$$\n(x - \\lambda_H)(x^2+x - \\lambda_H) - \\frac{|z|^2}{|z|^8} = (x - \\lambda_H)(x^2+x - \\lambda_H) - \\frac{1}{|z|^6} = 0.\n$$\nSince $x^3 = (1/|z|^2)^3 = 1/|z|^6$, the equation is $\\lambda_H^2 - (x^2+2x)\\lambda_H + x(x^2+x) - x^3 = 0$, which simplifies to $\\lambda_H^2 - (x^2+2x)\\lambda_H + x^2 = 0$.\nThe eigenvalues are $\\lambda_H = \\frac{x^2+2x \\pm \\sqrt{(x^2+2x)^2 - 4x^2}}{2} = \\frac{x^2+2x \\pm \\sqrt{x^4+4x^3}}{2}$.\nThe largest eigenvalue is $\\lambda_{\\max} = \\frac{x^2+2x + x\\sqrt{x^2+4x}}{2}$.\nThus, the squared $2$-norm of the resolvent is\n$$\n\\|(zI-A_{0})^{-1}\\|_{2}^{2} = \\frac{\\frac{1}{|z|^4} + \\frac{2}{|z|^2} + \\frac{1}{|z|^2}\\sqrt{\\frac{1}{|z|^4} + \\frac{4}{|z|^2}}}{2} = \\frac{1}{2|z|^4} \\left( 1 + 2|z|^2 + \\sqrt{1+4|z|^2} \\right).\n$$\nThe expression depends only on $|z|$, so the pseudospectra $\\sigma_{\\varepsilon}(A_0)$ are disks centered at the origin. The outer radius $r(\\varepsilon)$ is the value of $|z|$ that satisfies the boundary condition $\\|(zI-A_{0})^{-1}\\|_{2} = 1/\\varepsilon$.\n$$\n\\frac{1}{2(r(\\varepsilon))^4} \\left( 1 + 2(r(\\varepsilon))^2 + \\sqrt{1+4(r(\\varepsilon))^2} \\right) = \\frac{1}{\\varepsilon^2}.\n$$\nLet $r=r(\\varepsilon)$. We seek the asymptotic behavior of $r$ as $\\varepsilon \\to 0^{+}$, which implies $r \\to 0^{+}$. We can solve for $\\varepsilon^2$:\n$$\n\\varepsilon^2 = \\frac{2r^4}{1 + 2r^2 + \\sqrt{1+4r^2}}.\n$$\nFor small $r$, we use the Taylor expansion $\\sqrt{1+4r^2} = 1 + 2r^2 - 2r^4 + O(r^6)$.\nThe denominator becomes $1 + 2r^2 + (1 + 2r^2 - 2r^4 + O(r^6)) = 2 + 4r^2 - 2r^4 + O(r^6)$.\nSubstituting this into the expression for $\\varepsilon^2$:\n$$\n\\varepsilon^2 = \\frac{2r^4}{2 + 4r^2 - 2r^4 + O(r^6)} = \\frac{r^4}{1 + 2r^2 - r^4 + O(r^6)}.\n$$\nFor small $r$, the denominator approaches $1$. The leading-order relationship is therefore\n$$\n\\varepsilon^2 \\approx r^4.\n$$\nTaking the positive square root of both sides gives $\\varepsilon \\approx r^2$. Solving for $r=r(\\varepsilon)$, we obtain the leading-order asymptotic expression:\n$$\nr(\\varepsilon) \\approx \\sqrt{\\varepsilon}.\n$$\nThe conclusion is inescapable: the outer radius of the pseudospectrum of $A_0$ grows with the square root of the perturbation level $\\varepsilon$.", "answer": "$$\n\\boxed{\\sqrt{\\varepsilon}}\n$$", "id": "2715178"}]}