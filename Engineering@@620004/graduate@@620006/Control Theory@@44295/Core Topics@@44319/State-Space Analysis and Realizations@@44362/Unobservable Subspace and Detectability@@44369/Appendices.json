{"hands_on_practices": [{"introduction": "Understanding the unobservable subspace begins with its definition as the largest $A$-invariant subspace contained within the kernel of the output matrix $C$. This exercise provides a concrete opportunity to apply this definition directly, using an iterative algorithm to construct the unobservable subspace from first principles. By working through this calculation [@problem_id:2756462], you will gain a deep, operational understanding of how system dynamics and sensor configuration interact to define which states are hidden from view.", "problem": "Consider the continuous-time Linear Time-Invariant (LTI) system with state equation $\\dot{x} = A x$ and output equation $y = C x$, where $x \\in \\mathbb{R}^{4}$, $y \\in \\mathbb{R}$, and\n$$\nA \\;=\\; \\begin{pmatrix}\n0  1  0  0\\\\\n0  0  0  0\\\\\n0  0  0  1\\\\\n0  0  0  0\n\\end{pmatrix}, \n\\qquad\nC \\;=\\; \\begin{pmatrix}\n1  0  1  0\n\\end{pmatrix}.\n$$\nUsing only the core definitions of observability and $A$-invariance, explicitly compute a basis for the unobservable subspace $\\mathcal{N}_{o}$, defined as the largest $A$-invariant subspace contained in $\\ker C$. You must justify each step from first principles and show the logical iteration that converges to the largest $A$-invariant subspace inside $\\ker C$.\n\nFinally, state the dimension of $\\mathcal{N}_{o}$ as your answer. Your final answer must be a single real-valued number. No rounding is required and no units are involved.", "solution": "The problem requires the computation of the unobservable subspace, $\\mathcal{N}_{o}$, for the given LTI system. By definition, $\\mathcal{N}_{o}$ is the largest subspace $\\mathcal{V}$ of the state space $\\mathbb{R}^{4}$ such that $\\mathcal{V}$ is contained in the null space of $C$ ($\\mathcal{V} \\subseteq \\ker C$) and $\\mathcal{V}$ is $A$-invariant ($A\\mathcal{V} \\subseteq \\mathcal{V}$).\n\nWe will find this subspace using the iterative algorithm derived from first principles. The algorithm is initialized with the largest possible candidate subspace and is iteratively refined until the $A$-invariance property is satisfied.\n\nThe algorithm proceeds as follows:\n1.  Initialize with the subspace $\\mathcal{V}_0 = \\ker C$.\n2.  Iterate using the relation $\\mathcal{V}_{k+1} = \\mathcal{V}_k \\cap \\{x \\in \\mathbb{R}^4 \\mid Ax \\in \\mathcal{V}_k\\}$.\nThe sequence of subspaces $\\mathcal{V}_0 \\supseteq \\mathcal{V}_1 \\supseteq \\mathcal{V}_2 \\supseteq \\dots$ is guaranteed to converge in a finite number of steps to the largest $A$-invariant subspace contained in $\\ker C$.\n\n**Step I: Initialization**\nFirst, we compute the initial subspace $\\mathcal{V}_0 = \\ker C$. A vector $x = \\begin{pmatrix} x_1  x_2  x_3  x_4 \\end{pmatrix}^T$ belongs to $\\ker C$ if $Cx = 0$.\n$$\nCx = \\begin{pmatrix} 1  0  1  0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = x_1 + x_3 = 0\n$$\nThis condition implies $x_1 = -x_3$. A general vector in $\\ker C$ can be written as:\n$$\nx = \\begin{pmatrix} -x_3 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = x_2 \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + x_3 \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix} + x_4 \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\nThus, a basis for $\\mathcal{V}_0 = \\ker C$ is given by the set of vectors:\n$$\n\\left\\{ \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix} \\right\\}\n$$\nThe dimension of $\\mathcal{V}_0$ is $3$.\n\n**Step II: First Iteration**\nWe compute $\\mathcal{V}_1 = \\mathcal{V}_0 \\cap \\{x \\mid Ax \\in \\mathcal{V}_0\\}$. This is the subspace of vectors $x \\in \\mathcal{V}_0$ for which $Ax$ is also in $\\mathcal{V}_0$.\nLet $x \\in \\mathcal{V}_0$. We already know that its components satisfy $x_1 + x_3 = 0$. Now we impose the additional condition that $Ax \\in \\mathcal{V}_0$.\nFirst, compute $Ax$:\n$$\nAx = \\begin{pmatrix} 0  1  0  0\\\\ 0  0  0  0\\\\ 0  0  0  1\\\\ 0  0  0  0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{pmatrix} = \\begin{pmatrix} x_2 \\\\ 0 \\\\ x_4 \\\\ 0 \\end{pmatrix}\n$$\nFor $Ax$ to be in $\\mathcal{V}_0 = \\ker C$, its components must satisfy the condition for $\\ker C$. Let $z = Ax$. The condition is $z_1 + z_3 = 0$, which translates to $x_2 + x_4 = 0$.\nSo, vectors in $\\mathcal{V}_1$ must satisfy two conditions:\n1.  $x_1 + x_3 = 0$ (since $x \\in \\mathcal{V}_0$)\n2.  $x_2 + x_4 = 0$ (for $Ax \\in \\mathcal{V}_0$)\nA general vector $x \\in \\mathcal{V}_1$ has the form $x_3 = -x_1$ and $x_4 = -x_2$.\n$$\nx = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ -x_1 \\\\ -x_2 \\end{pmatrix} = x_1 \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\\\ 0 \\end{pmatrix} + x_2 \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ -1 \\end{pmatrix}\n$$\nA basis for $\\mathcal{V}_1$ is:\n$$\n\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ -1 \\end{pmatrix} \\right\\}\n$$\nThe dimension of $\\mathcal{V}_1$ is $2$. Since $\\mathcal{V}_1$ is a proper subspace of $\\mathcal{V}_0$, the algorithm has not yet converged.\n\n**Step III: Second Iteration**\nWe compute $\\mathcal{V}_2 = \\mathcal{V}_1 \\cap \\{x \\mid Ax \\in \\mathcal{V}_1\\}$. This is the subspace of vectors $x \\in \\mathcal{V}_1$ for which $Ax$ is also in $\\mathcal{V}_1$.\nLet $x \\in \\mathcal{V}_1$. Its components satisfy $x_1 + x_3 = 0$ and $x_2 + x_4 = 0$.\nWe check if $Ax$ lies in $\\mathcal{V}_1$.\n$$\nAx = \\begin{pmatrix} x_2 \\\\ 0 \\\\ x_4 \\\\ 0 \\end{pmatrix}\n$$\nFor $Ax$ to be in $\\mathcal{V}_1$, its components, let's call them $z_i$, must satisfy the two conditions for $\\mathcal{V}_1$:\n1.  $z_1 + z_3 = 0 \\implies x_2 + x_4 = 0$. This condition is true by definition for any $x \\in \\mathcal{V}_1$.\n2.  $z_2 + z_4 = 0 \\implies 0 + 0 = 0$. This condition is trivially satisfied.\nSince both conditions hold for any $x \\in \\mathcal{V}_1$, it follows that if $x \\in \\mathcal{V}_1$, then $Ax \\in \\mathcal{V}_1$. This means $A\\mathcal{V}_1 \\subseteq \\mathcal{V}_1$, so $\\mathcal{V}_1$ is an $A$-invariant subspace.\nThe iteration thus gives $\\mathcal{V}_2 = \\{x \\in \\mathcal{V}_1 \\mid Ax \\in \\mathcal{V}_1\\} = \\mathcal{V}_1$.\nSince $\\mathcal{V}_2 = \\mathcal{V}_1$, the algorithm has converged.\n\n**Conclusion**\nThe largest $A$-invariant subspace contained in $\\ker C$ is $\\mathcal{N}_o = \\mathcal{V}_1$. A basis for $\\mathcal{N}_o$ is:\n$$\n\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ -1 \\end{pmatrix} \\right\\}\n$$\nThe dimension of a subspace is the number of vectors in its basis. The basis for $\\mathcal{N}_o$ contains two vectors. Therefore, the dimension of the unobservable subspace $\\mathcal{N}_o$ is $2$.", "answer": "$$\n\\boxed{2}\n$$", "id": "2756462"}, {"introduction": "Having learned to identify the unobservable subspace, we now explore the critical implications of the dynamics within it. This practice [@problem_id:2756426] presents a system that is not detectable, meaning it possesses an unstable mode that is also unobservable. You will demonstrate why such a mode cannot be stabilized by any output injection gain $L$, thereby solidifying the concept that detectability is a necessary condition for achieving stable state estimation.", "problem": "Consider a linear time-invariant (LTI) system with state-space representation $\\dot{x} = A x$, $y = C x$, where $x \\in \\mathbb{R}^{2}$, $y \\in \\mathbb{R}$, and\n$$\nA = \\begin{pmatrix} 1  0 \\\\ 0  -2 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 0  1 \\end{pmatrix}.\n$$\nStarting from the foundational definitions of the unobservable subspace and detectability, do the following:\n1) Determine the unobservable subspace for the given pair $(A,C)$ and identify any eigenvalues of $A$ whose eigenvectors lie in this subspace. Justify all steps from first principles.\n2) Using only the basic properties of invariant subspaces and linear operators, explain why any eigenvalue of $A$ associated with an eigenvector in the unobservable subspace cannot be shifted by output injection of the form $A - L C$, where $L \\in \\mathbb{R}^{2 \\times 1}$ is arbitrary.\n3) Conclude whether $(A,C)$ is detectable, with a rigorous argument grounded in the definition of detectability (i.e., in terms of the stability of unobservable modes).\n4) Let the spectral abscissa of a square matrix $M$ be defined as $\\alpha(M) \\triangleq \\max \\{\\operatorname{Re}(\\lambda) : \\lambda \\text{ is an eigenvalue of } M\\}$. Compute the exact value of\n$$\n\\inf_{L \\in \\mathbb{R}^{2 \\times 1}} \\, \\alpha(A - L C).\n$$\nGive your final answer as an exact number with no units. No rounding is required.", "solution": "We begin from the basic definitions. For a linear time-invariant (LTI) system $\\dot{x} = A x$, $y = C x$, the unobservable subspace $\\mathcal{N}_{\\mathrm{obs}}$ is the largest $A$-invariant subspace contained in the kernel of the output map $C$, and can be computed for a finite-dimensional system as\n$$\n\\mathcal{N}_{\\mathrm{obs}} = \\bigcap_{k=0}^{n-1} \\ker\\!\\left(C A^{k}\\right),\n$$\nwhere $n$ is the system order. Detectability of $(A,C)$ means that every trajectory that is unobservable converges to the origin as $t \\to \\infty$, equivalently, every eigenvalue of $A$ whose eigenvector lies in the unobservable subspace has strictly negative real part.\n\nStep 1: Compute the unobservable subspace and identify associated eigenvalues. For the given matrices\n$$\nA = \\begin{pmatrix} 1  0 \\\\ 0  -2 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 0  1 \\end{pmatrix},\n$$\nwe have\n$$\nC = \\begin{pmatrix} 0  1 \\end{pmatrix}, \\quad C A = C \\begin{pmatrix} 1  0 \\\\ 0  -2 \\end{pmatrix} = \\begin{pmatrix} 0  -2 \\end{pmatrix}.\n$$\nThen\n$$\n\\ker(C) = \\left\\{ x \\in \\mathbb{R}^{2} : \\begin{pmatrix} 0  1 \\end{pmatrix} x = 0 \\right\\} = \\operatorname{span}\\!\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right\\},\n$$\nand\n$$\n\\ker(CA) = \\left\\{ x \\in \\mathbb{R}^{2} : \\begin{pmatrix} 0  -2 \\end{pmatrix} x = 0 \\right\\} = \\operatorname{span}\\!\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right\\}.\n$$\nHence\n$$\n\\mathcal{N}_{\\mathrm{obs}} = \\ker(C) \\cap \\ker(CA) = \\operatorname{span}\\!\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\right\\}.\n$$\nThe vector $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ is an eigenvector of $A$ because\n$$\nA \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\n$$\nso it corresponds to the eigenvalue $\\lambda = 1$. Therefore, the eigenvalue $\\lambda = 1$ of $A$ is unobservable. Because $\\operatorname{Re}(1) = 1  0$, it is an unstable eigenvalue.\n\nStep 2: Show immovability of the unobservable eigenvalue under output injection. Consider an arbitrary output injection gain $L \\in \\mathbb{R}^{2 \\times 1}$, and the modified matrix $A - L C$. Let $x \\in \\mathcal{N}_{\\mathrm{obs}}$. By definition of the unobservable subspace, $C x = 0$. Therefore,\n$$\n(A - L C) x = A x - L (C x) = A x - L \\cdot 0 = A x.\n$$\nThus, $\\mathcal{N}_{\\mathrm{obs}}$ is invariant for both $A$ and $A - L C$, and the action of $A - L C$ on $\\mathcal{N}_{\\mathrm{obs}}$ coincides with the action of $A$ on $\\mathcal{N}_{\\mathrm{obs}}$. Consequently, every eigenvalue of $A$ associated with an eigenvector in $\\mathcal{N}_{\\mathrm{obs}}$ is also an eigenvalue of $A - L C$ with the same value. In particular, the unobservable eigenvalue $\\lambda = 1$ persists in $A - L C$ for every $L$.\n\nStep 3: Detectability conclusion. By the definition of detectability, $(A,C)$ is detectable if every unobservable eigenvalue has strictly negative real part. We have identified an unobservable eigenvalue $\\lambda = 1$ with positive real part. Therefore, $(A,C)$ is not detectable. Equivalently, since $\\lambda = 1$ remains in the spectrum of $A - L C$ for all $L$, no choice of $L$ can render $A - L C$ a Hurwitz matrix, so stabilization by output injection is impossible.\n\nStep 4: Compute $\\inf_{L} \\alpha(A - L C)$. Let $L = \\begin{pmatrix} \\ell_{1} \\\\ \\ell_{2} \\end{pmatrix}$. Then\n$$\nL C = \\begin{pmatrix} \\ell_{1} \\\\ \\ell_{2} \\end{pmatrix} \\begin{pmatrix} 0  1 \\end{pmatrix} = \\begin{pmatrix} 0  \\ell_{1} \\\\ 0  \\ell_{2} \\end{pmatrix},\n$$\nand hence\n$$\nA - L C = \\begin{pmatrix} 1  0 \\\\ 0  -2 \\end{pmatrix} - \\begin{pmatrix} 0  \\ell_{1} \\\\ 0  \\ell_{2} \\end{pmatrix} = \\begin{pmatrix} 1  -\\ell_{1} \\\\ 0  -2 - \\ell_{2} \\end{pmatrix}.\n$$\nThis matrix is upper triangular, so its eigenvalues are the diagonal entries:\n$$\n\\lambda_{1} = 1, \\quad \\lambda_{2} = -2 - \\ell_{2}.\n$$\nTherefore, the spectral abscissa is\n$$\n\\alpha(A - L C) = \\max \\{ \\operatorname{Re}(1), \\operatorname{Re}(-2 - \\ell_{2}) \\} = \\max \\{ 1, -2 - \\ell_{2} \\}.\n$$\nMinimizing over $\\ell_{2} \\in \\mathbb{R}$ yields\n$$\n\\inf_{\\ell_{2} \\in \\mathbb{R}} \\max \\{ 1, -2 - \\ell_{2} \\} = 1,\n$$\nsince $\\lambda_{1} = 1$ is fixed and cannot be reduced by any choice of $L$. Thus,\n$$\n\\inf_{L \\in \\mathbb{R}^{2 \\times 1}} \\alpha(A - L C) = 1.\n$$\nThis confirms both the impossibility of stabilization via output injection and provides the requested exact value.", "answer": "$$\\boxed{1}$$", "id": "2756426"}, {"introduction": "In contrast to non-detectable systems, detectability allows for robust state estimation even when full observability is absent. This comprehensive exercise [@problem_id:2756420] guides you through the complete analysis of a detectable system, where an unobservable mode exists but is stable. You will first verify detectability using the Popov–Belevitch–Hautus (PBH) test and then leverage this property to design a Luenberger observer that successfully stabilizes the system's observable dynamics.", "problem": "Consider the continuous-time linear time-invariant (LTI) system with state matrix $A \\in \\mathbb{R}^{4 \\times 4}$ and output matrix $C \\in \\mathbb{R}^{1 \\times 4}$ given by\n$$\nA \\;=\\; \\begin{bmatrix}\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  -1  0 \\\\\n0  0  0  -2\n\\end{bmatrix},\n\\qquad\nC \\;=\\; \\begin{bmatrix} 1  0  0  0 \\end{bmatrix}.\n$$\nUsing only fundamental definitions and widely accepted characterizations, proceed as follows.\n1) Starting from the definition of detectability and the Popov–Belevitch–Hautus (PBH) test characterization restricted to the closed right-half plane (that is, for all complex $\\lambda$ such that $\\Re(\\lambda) \\ge 0$), determine whether the pair $(A,C)$ is detectable. Your reasoning must examine the eigenstructure relevant to $\\Re(\\lambda) \\ge 0$ and apply the PBH rank condition without invoking any unproven shortcuts.\n2) Identify the unobservable subspace of $(A,C)$ and explain whether any unobservable modes, if present, are stable, making a clear connection to detectability.\n3) Design a Luenberger observer gain $L \\in \\mathbb{R}^{4 \\times 1}$ so that the observer error dynamics matrix $A - L C$ has eigenvalues on the observable subspace at $\\{-3,\\,-4,\\,-5\\}$, while leaving any intrinsically unobservable mode unchanged. Construct $L$ by matching the characteristic polynomial implied by your target eigenvalues.\n4) Finally, compute the determinant of the resulting observer error dynamics matrix $A - L C$ for your designed $L$. Report this determinant as the final answer. The final answer is a single real-valued number without units. No rounding is required.", "solution": "The solution proceeds by addressing the four specified tasks in sequence.\n\n1) Detectability of the pair $(A,C)$.\nThe definition of detectability for an LTI system states that the pair $(A,C)$ is detectable if and only if all unobservable modes of the system are stable. An equivalent characterization is the Popov–Belevitch–Hautus (PBH) test for detectability, which requires that the matrix $\\begin{bmatrix} A - \\lambda I \\\\ C \\end{bmatrix}$ has full column rank for all $\\lambda \\in \\mathbb{C}$ such that $\\Re(\\lambda) \\ge 0$. Here, the state dimension is $n=4$, so we must check if $\\text{rank}\\begin{pmatrix} A - \\lambda I \\\\ C \\end{pmatrix} = 4$ for all such $\\lambda$.\n\nFirst, we find the eigenvalues of $A$. The matrix $A$ is block upper triangular:\n$$\nA = \\begin{bmatrix} A_{11}  A_{12} \\\\ 0  A_{22} \\end{bmatrix} = \\begin{bmatrix} \\begin{matrix} 0  1  0 \\\\ 0  0  1 \\\\ 0  0  -1 \\end{matrix}  \\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix} \\\\ \\begin{matrix} 0  0  0 \\end{matrix}  -2 \\end{bmatrix}\n$$\nThe eigenvalues of $A$ are the union of the eigenvalues of the diagonal blocks $A_{11}$ and $A_{22}$. The eigenvalues of the upper-left $3 \\times 3$ block are its diagonal entries, $\\{0, 0, -1\\}$. The eigenvalue of the bottom-right $1 \\times 1$ block is $\\{-2\\}$. Thus, the spectrum of $A$ is $\\sigma(A) = \\{0, 0, -1, -2\\}$.\n\nThe only eigenvalue $\\lambda$ of $A$ for which $\\Re(\\lambda) \\ge 0$ is $\\lambda=0$. The PBH test for observability states that an eigenvalue $\\lambda$ is unobservable if and only if $\\text{rank}\\begin{pmatrix} A - \\lambda I \\\\ C \\end{pmatrix}  n$. For detectability, we only need to verify this condition for eigenvalues in the closed right-half plane. We test for $\\lambda=0$:\n$$\n\\begin{bmatrix} A - 0 \\cdot I \\\\ C \\end{bmatrix} = \\begin{bmatrix} A \\\\ C \\end{bmatrix} = \\begin{bmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  -1  0 \\\\ 0  0  0  -2 \\\\ 1  0  0  0 \\end{bmatrix}\n$$\nThis is a $5 \\times 4$ matrix. We check for full column rank, which is rank $4$. Selecting rows $5, 1, 2, 4$ of this matrix yields a $4 \\times 4$ submatrix:\n$$\n\\begin{bmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  -2 \\end{bmatrix}\n$$\nThe determinant of this submatrix is $1 \\cdot 1 \\cdot 1 \\cdot (-2) = -2 \\ne 0$. Since we have found a $4 \\times 4$ submatrix with full rank, the rank of the $5 \\times 4$ matrix $\\begin{pmatrix} A \\\\ C \\end{pmatrix}$ is $4$. Therefore, the PBH rank condition holds for $\\lambda=0$. As this is the only eigenvalue in the closed right-half plane, the pair $(A,C)$ is detectable.\n\n2) Unobservable Subspace and Modes.\nThe unobservable subspace is the null space of the observability matrix $\\mathcal{O}$.\n$$\n\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\end{bmatrix}\n$$\nWe compute the rows:\n$C = \\begin{bmatrix} 1  0  0  0 \\end{bmatrix}$\n$CA = \\begin{bmatrix} 1  0  0  0 \\end{bmatrix} A = \\begin{bmatrix} 0  1  0  0 \\end{bmatrix}$\n$CA^2 = (CA)A = \\begin{bmatrix} 0  1  0  0 \\end{bmatrix} A = \\begin{bmatrix} 0  0  1  0 \\end{bmatrix}$\n$CA^3 = (CA^2)A = \\begin{bmatrix} 0  0  1  0 \\end{bmatrix} A = \\begin{bmatrix} 0  0  -1  0 \\end{bmatrix}$\nThe observability matrix is:\n$$\n\\mathcal{O} = \\begin{bmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  -1  0 \\end{bmatrix}\n$$\nThe fourth row is $-1$ times the third row, so the rows are linearly dependent. The first three rows are linearly independent. Thus, $\\text{rank}(\\mathcal{O}) = 3$. Since $\\text{rank}(\\mathcal{O})  4$, the system is not observable.\nThe unobservable subspace is $\\mathcal{N}(\\mathcal{O})$. We seek a vector $x = [x_1, x_2, x_3, x_4]^T$ such that $\\mathcal{O}x = 0$. This leads to the system of equations $x_1=0$, $x_2=0$, and $x_3=0$. The variable $x_4$ is free. The unobservable subspace is therefore spanned by the vector $v = [0, 0, 0, 1]^T$.\n$$\n\\mathcal{N}(\\mathcal{O}) = \\text{span}\\left\\{ \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} \\right\\}\n$$\nAn unobservable mode is an eigenvalue of $A$ associated with an eigenvector in the unobservable subspace. We check if $v$ is an eigenvector of $A$:\n$$\nAv = \\begin{bmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  -1  0 \\\\ 0  0  0  -2 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ -2 \\end{bmatrix} = -2 \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix} = -2v\n$$\nThe vector $v$ is indeed an eigenvector of $A$ with the corresponding eigenvalue $\\lambda = -2$. This eigenvalue is the system's unobservable mode.\nFor detectability, all unobservable modes must be stable, meaning their corresponding eigenvalues must have a strictly negative real part. Here, the only unobservable mode is $\\lambda = -2$, and $\\Re(-2) = -2  0$. Thus, the mode is stable. This confirms that the pair $(A,C)$ is detectable.\n\n3) Luenberger Observer Gain Design.\nWe design a gain $L = [l_1, l_2, l_3, l_4]^T$ such that the observer error dynamics matrix $A-LC$ has specified eigenvalues. The matrix $A-LC$ is:\n$$\nA - LC = A - \\begin{bmatrix} l_1 \\\\ l_2 \\\\ l_3 \\\\ l_4 \\end{bmatrix} \\begin{bmatrix} 1  0  0  0 \\end{bmatrix} = \\begin{bmatrix} -l_1  1  0  0 \\\\ -l_2  0  1  0 \\\\ -l_3  0  -1  0 \\\\ -l_4  0  0  -2 \\end{bmatrix}\n$$\nThe characteristic polynomial is $p(s) = \\det(sI - (A-LC))$.\n$$\nsI - (A-LC) = \\begin{bmatrix} s+l_1  -1  0  0 \\\\ l_2  s  -1  0 \\\\ l_3  0  s+1  0 \\\\ l_4  0  0  s+2 \\end{bmatrix}\n$$\nDue to the block triangular structure, the determinant is the product of the determinants of the diagonal blocks:\n$$\n\\det(sI - (A-LC)) = (s+2) \\cdot \\det \\begin{bmatrix} s+l_1  -1  0 \\\\ l_2  s  -1 \\\\ l_3  0  s+1 \\end{bmatrix}\n$$\nThis shows that the unobservable eigenvalue at $s=-2$ is fixed, regardless of the choice of $L$. The observer gain can only affect the observable eigenvalues. The determinant of the $3 \\times 3$ block is:\n$\\det(\\cdot) = (s+l_1)[s(s+1) - 0] - (-1)[l_2(s+1) - (-l_3)] = (s+l_1)(s^2+s) + l_2(s+1) + l_3 = s^3 + s^2 + l_1s^2 + l_1s + l_2s + l_2 + l_3 = s^3 + (1+l_1)s^2 + (l_1+l_2)s + (l_2+l_3)$.\nThe desired characteristic polynomial for the observable part is specified by the target eigenvalues $\\{-3, -4, -5\\}$:\n$p_{des}(s) = (s+3)(s+4)(s+5) = (s^2+7s+12)(s+5) = s^3+5s^2+7s^2+35s+12s+60 = s^3+12s^2+47s+60$.\nBy equating coefficients, we find the gains $l_1, l_2, l_3$:\n$s^2: 1+l_1 = 12 \\implies l_1 = 11$.\n$s^1: l_1+l_2 = 47 \\implies 11+l_2 = 47 \\implies l_2 = 36$.\n$s^0: l_2+l_3 = 60 \\implies 36+l_3 = 60 \\implies l_3 = 24$.\nThe gain $l_4$ has no effect on the eigenvalues. In the characteristic polynomial calculation, $l_4$ only appears in the term $l_4 \\det(\\text{matrix with a zero column}) = 0$. We can set it to zero for simplicity, $l_4=0$.\nThe designed observer gain is $L = \\begin{bmatrix} 11  36  24  0 \\end{bmatrix}^T$.\n\n4) Determinant of the Final Observer Error Dynamics Matrix.\nThe determinant of a matrix is the product of its eigenvalues. The eigenvalues of the designed observer error dynamics matrix $A-LC$ are the union of the placed eigenvalues and the fixed unobservable eigenvalue: $\\{-3, -4, -5, -2\\}$.\nTherefore, the determinant is:\n$$\n\\det(A-LC) = (-3) \\cdot (-4) \\cdot (-5) \\cdot (-2) = (12) \\cdot (10) = 120\n$$\nAlternatively, we calculate the determinant directly from the matrix $A-LC$ with the designed gains:\n$$\nA-LC = \\begin{bmatrix} -11  1  0  0 \\\\ -36  0  1  0 \\\\ -24  0  -1  0 \\\\ 0  0  0  -2 \\end{bmatrix}\n$$\nUsing cofactor expansion along the fourth row:\n$$\n\\det(A-LC) = (-2) \\cdot \\det \\begin{bmatrix} -11  1  0 \\\\ -36  0  1 \\\\ -24  0  -1 \\end{bmatrix}\n$$\nNow, using cofactor expansion along the second column of the $3 \\times 3$ matrix:\n$$\n\\det(A-LC) = (-2) \\cdot \\left( -1 \\cdot \\det \\begin{bmatrix} -36  1 \\\\ -24  -1 \\end{bmatrix} \\right) = (-2) \\cdot \\left( -1 \\cdot [(-36)(-1) - (1)(-24)] \\right)\n$$\n$$\n\\det(A-LC) = (-2) \\cdot (-1 \\cdot [36 + 24]) = (-2) \\cdot (-1 \\cdot 60) = (-2) \\cdot (-60) = 120\n$$\nBoth methods yield the same result. The calculation is correct.", "answer": "$$\n\\boxed{120}\n$$", "id": "2756420"}]}