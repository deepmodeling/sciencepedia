{"hands_on_practices": [{"introduction": "A cornerstone of analyzing linear systems is understanding their fundamental modes of behavior. For real systems exhibiting oscillatory or spiraling dynamics, the state matrix $A$ possesses complex conjugate eigenvalues. This exercise provides fundamental practice in constructing a real similarity transformation that converts such a matrix into its real Jordan canonical form, a rotation-scaling block that makes the underlying dynamics transparent. By working from first principles, you will solidify the connection between complex eigenstructure and the real-world behavior of second-order systems [@problem_id:2744704].", "problem": "Consider the real linear time-invariant (LTI) state-space model $\\dot{x} = A x$ with a real $2 \\times 2$ state matrix $A \\in \\mathbb{R}^{2 \\times 2}$. Recall the foundational definitions: two matrices $A$ and $J$ are similar if there exists an invertible matrix $S$ such that $S^{-1} A S = J$, and an eigenpair $(\\lambda, v)$ of $A$ satisfies $A v = \\lambda v$ with $\\lambda \\in \\mathbb{C}$ and $v \\in \\mathbb{C}^{2} \\setminus \\{0\\}$. For real $A$, nonreal eigenvalues occur in complex conjugate pairs. The real Jordan canonical form for such a pair is a real $2 \\times 2$ block representing a rotation-scaling.\n\nUsing only these definitions and properties of similarity transformations and eigenpairs, do the following:\n\n1. Starting from $A v = \\lambda v$ where $\\lambda = \\alpha + \\mathrm{i} \\beta$ with $\\alpha, \\beta \\in \\mathbb{R}$ and $v = p + \\mathrm{i} q$ with $p, q \\in \\mathbb{R}^{2}$, derive a real invertible similarity transformation $S \\in \\mathbb{R}^{2 \\times 2}$ such that $S^{-1} A S$ is the real Jordan block corresponding to the eigenvalues $\\alpha \\pm \\mathrm{i} \\beta$. Express the resulting real Jordan block explicitly in terms of $\\alpha$ and $\\beta$, and identify $\\alpha$ and $\\beta$ in terms of real invariants of $A$.\n\n2. Apply your construction to the specific matrix\n$$\nA = \\begin{pmatrix}\n3 & -5 \\\\\n2 & 1\n\\end{pmatrix},\n$$\nand produce one explicit real invertible matrix $S$ satisfying $S^{-1} A S$ equal to the real Jordan block associated with the eigenvalues of $A$. Your $S$ must be given with exact integer entries.\n\n3. Justify, using only invariants preserved by similarity (such as the trace and determinant), the necessary and sufficient condition on $A$ under which such a real $S$ exists that converts $A$ to a single real $2 \\times 2$ rotation-scaling block. Formulate this condition in terms of $\\operatorname{tr}(A)$ and $\\det(A)$.\n\nAnswer specification: Provide as your final answer only the specific matrix $S$ you obtain in part $2$, written as a $2 \\times 2$ matrix. No rounding is required and no units are involved.", "solution": "The problem as stated is well-posed, scientifically grounded, and contains all necessary information for a complete solution. We shall proceed with the derivation and calculation as requested. The problem is divided into three parts which we will address in sequence.\n\nPart 1: Derivation of the real similarity transformation and real Jordan form.\n\nWe begin with the defining equation for an eigenpair $(\\lambda, v)$ of the real matrix $A \\in \\mathbb{R}^{2 \\times 2}$, which is $A v = \\lambda v$.\nThe problem specifies a nonreal eigenvalue $\\lambda = \\alpha + \\mathrm{i} \\beta$, where $\\alpha, \\beta \\in \\mathbb{R}$ and $\\beta \\neq 0$, with a corresponding eigenvector $v = p + \\mathrm{i} q$, where $p, q \\in \\mathbb{R}^{2}$. Since $v$ is an eigenvector, $v \\neq 0$, which implies that $p$ and $q$ cannot both be the zero vector.\n\nSubstituting the complex forms of $\\lambda$ and $v$ into the eigenvalue equation:\n$$A (p + \\mathrm{i} q) = (\\alpha + \\mathrm{i} \\beta) (p + \\mathrm{i} q)$$\nUsing the linearity of matrix multiplication and expanding the right side, we obtain:\n$$A p + \\mathrm{i} A q = (\\alpha p - \\beta q) + \\mathrm{i} (\\beta p + \\alpha q)$$\nSince $A$, $p$, and $q$ are real, we can equate the real and imaginary parts of this equation. This yields two separate real vector equations:\n1. $A p = \\alpha p - \\beta q$\n2. $A q = \\beta p + \\alpha q$\n\nThese two equations describe the action of $A$ on the real vectors $p$ and $q$. We can express this relationship in matrix form. Let us define a real matrix $S$ whose columns are the vectors $p$ and $q$: $S = \\begin{pmatrix} p & q \\end{pmatrix}$. Then the action of $A$ on the columns of $S$ is given by:\n$$A S = A \\begin{pmatrix} p & q \\end{pmatrix} = \\begin{pmatrix} A p & A q \\end{pmatrix}$$\nSubstituting our expressions for $A p$ and $A q$:\n$$A S = \\begin{pmatrix} \\alpha p - \\beta q & \\beta p + \\alpha q \\end{pmatrix}$$\nWe now seek to write the right-hand side as a product of $S$ and a real $2 \\times 2$ matrix, which we will call $J$.\n$$\\begin{pmatrix} p & q \\end{pmatrix} \\begin{pmatrix} \\alpha & \\beta \\\\ -\\beta & \\alpha \\end{pmatrix} = \\begin{pmatrix} p(\\alpha) + q(-\\beta) & p(\\beta) + q(\\alpha) \\end{pmatrix} = \\begin{pmatrix} \\alpha p - \\beta q & \\beta p + \\alpha q \\end{pmatrix}$$\nBy comparison, we see that:\n$$A S = S \\begin{pmatrix} \\alpha & \\beta \\\\ -\\beta & \\alpha \\end{pmatrix}$$\nFor this to be a similarity transformation, the matrix $S$ must be invertible. This requires its column vectors $p$ and $q$ to be linearly independent. Let us prove this is the case.\nAssume, for contradiction, that $p$ and $q$ are linearly dependent. Since $v = p + \\mathrm{i} q \\neq 0$, both $p$ and $q$ cannot be zero. Furthermore, if either $p=0$ or $q=0$, the eigenvalue $\\lambda$ must be real, contradicting $\\beta \\neq 0$. For instance, if $q=0$, then $v=p$, and $Ap = \\lambda p$. Since $A$ and $p$ are real, $\\lambda$ must be real. Thus, $p$ and $q$ must be non-zero.\nIf they are linearly dependent, then there exists a non-zero scalar $k \\in \\mathbb{R}$ such that $q = k p$.\nThe eigenvector becomes $v = p + \\mathrm{i}(k p) = (1 + \\mathrm{i} k) p$.\nSubstituting this into the eigenvalue equation:\n$$A ((1 + \\mathrm{i} k) p) = \\lambda ((1 + \\mathrm{i} k) p)$$\nSince $k$ is real, $(1 + \\mathrm{i} k)$ is a non-zero complex scalar, which we can cancel from both sides:\n$$A p = \\lambda p$$\nThis equation, where $A$ and $p \\in \\mathbb{R}^{2} \\setminus \\{0\\}$ are real, implies that the eigenvalue $\\lambda$ must be real. This contradicts our initial premise that $\\lambda$ is nonreal (i.e., $\\beta \\neq 0$). Therefore, the assumption of linear dependence is false. The vectors $p$ and $q$ must be linearly independent.\n\nSince $p, q \\in \\mathbb{R}^2$ are linearly independent, the $2 \\times 2$ matrix $S = \\begin{pmatrix} p & q \\end{pmatrix}$ is invertible. We can thus pre-multiply the equation $A S = S J$ by $S^{-1}$:\n$$S^{-1} A S = J = \\begin{pmatrix} \\alpha & \\beta \\\\ -\\beta & \\alpha \\end{pmatrix}$$\nThis matrix $J$ is the real Jordan block corresponding to the complex conjugate eigenvalues $\\alpha \\pm \\mathrm{i} \\beta$.\n\nThe parameters $\\alpha$ and $\\beta$ are determined by the invariants of $A$. Since the eigenvalues are $\\lambda_1 = \\alpha + \\mathrm{i}\\beta$ and $\\lambda_2 = \\alpha - \\mathrm{i}\\beta$:\nThe trace is $\\operatorname{tr}(A) = \\lambda_1 + \\lambda_2 = (\\alpha + \\mathrm{i}\\beta) + (\\alpha - \\mathrm{i}\\beta) = 2\\alpha$.\nThus, $\\alpha = \\frac{1}{2} \\operatorname{tr}(A)$.\nThe determinant is $\\det(A) = \\lambda_1 \\lambda_2 = (\\alpha + \\mathrm{i}\\beta)(\\alpha - \\mathrm{i}\\beta) = \\alpha^2 + \\beta^2$.\nThus, $\\beta^2 = \\det(A) - \\alpha^2 = \\det(A) - \\frac{1}{4} (\\operatorname{tr}(A))^2$. We can choose $\\beta = \\sqrt{\\det(A) - \\frac{1}{4} (\\operatorname{tr}(A))^2}$, where the positive root corresponds to the choice of eigenvalue $\\lambda = \\alpha + \\mathrm{i}\\beta$ with $\\beta > 0$.\n\nPart 2: Application to the specific matrix $A = \\begin{pmatrix} 3 & -5 \\\\ 2 & 1 \\end{pmatrix}$.\n\nFirst, we find the eigenvalues of $A$ by solving the characteristic equation $\\det(A - \\lambda I) = 0$.\n$$\\det \\begin{pmatrix} 3 - \\lambda & -5 \\\\ 2 & 1 - \\lambda \\end{pmatrix} = (3 - \\lambda)(1 - \\lambda) - (2)(-5) = 0$$\n$$\\lambda^2 - 4\\lambda + 3 + 10 = 0$$\n$$\\lambda^2 - 4\\lambda + 13 = 0$$\nUsing the quadratic formula, the eigenvalues are:\n$$\\lambda = \\frac{4 \\pm \\sqrt{16 - 4(13)}}{2} = \\frac{4 \\pm \\sqrt{16 - 52}}{2} = \\frac{4 \\pm \\sqrt{-36}}{2} = \\frac{4 \\pm 6\\mathrm{i}}{2} = 2 \\pm 3\\mathrm{i}$$\nWe identify $\\alpha = 2$ and choose $\\beta = 3$. Let us find the eigenvector $v = \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix}$ corresponding to the eigenvalue $\\lambda = 2 + 3\\mathrm{i}$.\n$$(A - \\lambda I) v = \\begin{pmatrix} 3 - (2 + 3\\mathrm{i}) & -5 \\\\ 2 & 1 - (2 + 3\\mathrm{i}) \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 1 - 3\\mathrm{i} & -5 \\\\ 2 & -1 - 3\\mathrm{i} \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\nFrom the first row, we have $(1 - 3\\mathrm{i}) v_1 - 5 v_2 = 0$, which gives $v_1 = \\frac{5}{1 - 3\\mathrm{i}} v_2$.\n$$v_1 = \\frac{5(1 + 3\\mathrm{i})}{(1 - 3\\mathrm{i})(1 + 3\\mathrm{i})} v_2 = \\frac{5(1 + 3\\mathrm{i})}{1^2 + 3^2} v_2 = \\frac{5(1 + 3\\mathrm{i})}{10} v_2 = \\frac{1 + 3\\mathrm{i}}{2} v_2$$\nTo obtain an eigenvector with integer-valued real and imaginary parts, we can choose $v_2 = 2$.\nThis gives $v_1 = 1 + 3\\mathrm{i}$.\nThe eigenvector is $v = \\begin{pmatrix} 1 + 3\\mathrm{i} \\\\ 2 \\end{pmatrix}$.\nNow we decompose $v$ into its real and imaginary parts, $v = p + \\mathrm{i} q$:\n$$v = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} + \\mathrm{i} \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}$$\nSo, $p = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ and $q = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}$.\nFollowing the construction from Part 1, the similarity transformation matrix $S$ is formed by these vectors:\n$$S = \\begin{pmatrix} p & q \\end{pmatrix} = \\begin{pmatrix} 1 & 3 \\\\ 2 & 0 \\end{pmatrix}$$\nThis is a real invertible matrix with exact integer entries, as required. Its determinant is $\\det(S) = (1)(0) - (3)(2) = -6 \\neq 0$.\n\nPart 3: Condition for transformation to a rotation-scaling block.\n\nA real $2 \\times 2$ matrix $A$ can be transformed by a real similarity transformation $S$ into a rotation-scaling block $J = \\begin{pmatrix} \\alpha & \\beta \\\\ -\\beta & \\alpha \\end{pmatrix}$ if and only if $A$ and $J$ are similar. A necessary condition for similarity is that the matrices have the same eigenvalues.\nThe eigenvalues of $J$ are the roots of its characteristic polynomial:\n$$\\det(J - \\lambda I) = (\\alpha - \\lambda)^2 - (\\beta)(-\\beta) = (\\alpha - \\lambda)^2 + \\beta^2 = 0$$\nThis gives $\\lambda - \\alpha = \\pm \\mathrm{i}\\beta$, so $\\lambda = \\alpha \\pm \\mathrm{i}\\beta$.\nFor $J$ to be a genuine rotation-scaling block, a rotational component must exist, which requires $\\beta \\neq 0$. This means the eigenvalues must be a pair of non-real complex conjugates.\nSince eigenvalues are invariant under similarity transformations, the matrix $A$ must also have a pair of non-real complex conjugate eigenvalues.\n\nThe eigenvalues of $A$ are the roots of its characteristic polynomial, $p(\\lambda) = \\lambda^2 - \\operatorname{tr}(A)\\lambda + \\det(A) = 0$. The nature of these roots is determined by the discriminant of this quadratic equation, $\\Delta = (\\operatorname{tr}(A))^2 - 4\\det(A)$.\nFor the eigenvalues to be a non-real complex conjugate pair, the discriminant must be negative:\n$$\\Delta = (\\operatorname{tr}(A))^2 - 4\\det(A) < 0$$\nThis is the necessary condition.\n\nTo show sufficiency, if $(\\operatorname{tr}(A))^2 - 4\\det(A) < 0$, then the eigenvalues of $A$ are $\\lambda = \\frac{\\operatorname{tr}(A) \\pm \\mathrm{i}\\sqrt{4\\det(A) - (\\operatorname{tr}(A))^2}}{2}$. These are of the form $\\alpha \\pm \\mathrm{i}\\beta$ where $\\alpha = \\frac{1}{2}\\operatorname{tr}(A)$ and $\\beta = \\frac{1}{2}\\sqrt{4\\det(A) - (\\operatorname{tr}(A))^2} \\neq 0$.\nSince the eigenvalues are distinct, the matrix $A$ is diagonalizable over $\\mathbb{C}$. As shown in Part 1, the existence of such a complex eigenpair guarantees the existence of linearly independent real vectors $p$ and $q$ from which an invertible real matrix $S = \\begin{pmatrix}p & q\\end{pmatrix}$ can be constructed, such that $S^{-1}AS$ is a real Jordan block.\nTherefore, the necessary and sufficient condition for a real $2 \\times 2$ matrix $A$ to be similar to a single real $2 \\times 2$ rotation-scaling block is $(\\operatorname{tr}(A))^2 < 4\\det(A)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & 3 \\\\ 2 & 0 \\end{pmatrix}}\n$$", "id": "2744704"}, {"introduction": "While many matrices are diagonalizable, a significant class of systems involves matrices that are not. These \"defective\" matrices have repeated eigenvalues whose geometric multiplicity is less than their algebraic multiplicity, leading to dynamics that simple modal decomposition cannot capture. This practice guides you through the essential skill of constructing generalized eigenvector chains to build the Jordan Canonical Form, the universal structure for any linear transformation. Mastering this technique is crucial for analyzing the behavior of any linear system, and it also reveals the intimate connection between Jordan block sizes and another key similarity invariant: the minimal polynomial [@problem_id:2744729].", "problem": "Consider the linear time-invariant state matrix $A \\in \\mathbb{R}^{4 \\times 4}$ arising from a controllable single-input realization:\n$$\nA \\;=\\; \\begin{bmatrix}\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n-2 & 7 & -9 & 5\n\\end{bmatrix}.\n$$\nUsing only foundational linear algebra definitions, proceed as follows.\n\n1) Recall that a nonzero vector $v$ is a generalized eigenvector of rank $k$ associated with an eigenvalue $\\lambda$ if $(A-\\lambda I)^{k} v = 0$ and $(A-\\lambda I)^{k-1} v \\neq 0$. A generalized eigenvector chain of length $k$ for $\\lambda$ is an ordered set $\\{v_{1},\\dots,v_{k}\\}$ such that $(A-\\lambda I)v_{1}=0$ and $(A-\\lambda I) v_{j+1}=v_{j}$ for $j=1,\\dots,k-1$.\n\nConstruct a generalized eigenvector chain for the eigenvalue $\\lambda = 1$ by solving $(A-I) v_{1} = 0$ and $(A-I) v_{j+1} = v_{j}$ for $j=1,2$, with the normalization constraints $e_{4}^{\\top} v_{1} = 1$ and $e_{4}^{\\top} v_{2} = e_{4}^{\\top} v_{3} = 0$, where $e_{4}$ is the fourth standard basis vector in $\\mathbb{R}^{4}$.\n\n2) Verify that $\\lambda = 2$ is an eigenvalue by solving $(A-2 I) w = 0$ with the normalization $e_{4}^{\\top} w = 1$, and include the resulting eigenvector $w$.\n\n3) Assemble the similarity transformation matrix $T \\in \\mathbb{R}^{4 \\times 4}$ whose columns are the vectors of the chain for $\\lambda=1$ followed by the eigenvector for $\\lambda=2$, so that $T^{-1} A T$ is in Jordan canonical form (Jordan Canonical Form (JCF)) with a single Jordan block for $\\lambda=1$ and a single Jordan block for $\\lambda=2$. Explain why the lengths of the constructed chains determine the sizes of the Jordan blocks and why these sizes are similarity invariants.\n\n4) Using the chain lengths and the definition of the minimal polynomial (the unique monic polynomial of least degree that annihilates $A$), determine $m_{A}(s)$ in factored form.\n\nProvide as your final output the exact factored expression for $m_{A}(s)$ as a single analytic expression. No rounding is required. Do not include units.", "solution": "The problem as stated is scientifically grounded, self-contained, and well-posed. It presents a standard exercise in linear algebra involving the computation of generalized eigenvectors and the determination of the Jordan canonical form and minimal polynomial of a matrix. All definitions are provided and are correct, and all data are consistent. The problem is valid and a solution will be provided.\n\nThe problem requires a step-by-step analysis of the given state matrix $A$:\n$$\nA \\;=\\; \\begin{bmatrix}\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n-2 & 7 & -9 & 5\n\\end{bmatrix}\n$$\n\n1) Construction of a generalized eigenvector chain for $\\lambda = 1$.\n\nWe must find a set of vectors $\\{v_1, v_2, v_3\\}$ satisfying the specified chain equations and normalization constraints. First, we compute the matrix $A - \\lambda I$ for $\\lambda = 1$:\n$$\nA - I = \\begin{bmatrix}\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n-2 & 7 & -9 & 5\n\\end{bmatrix} - \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{bmatrix} = \\begin{bmatrix}\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & 1 & 0 \\\\\n0 & 0 & -1 & 1 \\\\\n-2 & 7 & -9 & 4\n\\end{bmatrix}\n$$\nThe first vector in the chain, $v_1$, is an eigenvector satisfying $(A-I)v_1 = 0$. Let $v_1 = [c_1, c_2, c_3, c_4]^{\\top}$. The system of equations is:\n$$\n-c_1 + c_2 = 0 \\implies c_1 = c_2 \\\\\n-c_2 + c_3 = 0 \\implies c_2 = c_3 \\\\\n-c_3 + c_4 = 0 \\implies c_3 = c_4\n$$\nThus, $c_1=c_2=c_3=c_4$. The fourth equation, $-2c_1 + 7c_2 - 9c_3 + 4c_4 = (-2+7-9+4)c_1 = 0$, is satisfied for any such vector. The normalization constraint $e_4^{\\top}v_1 = 1$ implies $c_4=1$. Therefore, $v_1 = [1, 1, 1, 1]^{\\top}$.\n\nNext, we find the generalized eigenvector $v_2$ by solving $(A-I)v_2 = v_1$, with the constraint $e_4^{\\top}v_2 = 0$. Let $v_2 = [c_1, c_2, c_3, c_4]^{\\top}$.\n$$\n\\begin{bmatrix}\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & 1 & 0 \\\\\n0 & 0 & -1 & 1 \\\\\n-2 & 7 & -9 & 4\n\\end{bmatrix}\n\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\end{bmatrix} =\n\\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{bmatrix}\n$$\nThe constraint gives $c_4=0$. From the third row: $-c_3 + c_4 = 1 \\implies -c_3 = 1 \\implies c_3 = -1$.\nFrom the second row: $-c_2 + c_3 = 1 \\implies -c_2 - 1 = 1 \\implies c_2 = -2$.\nFrom the first row: $-c_1 + c_2 = 1 \\implies -c_1 - 2 = 1 \\implies c_1 = -3$.\nThe fourth equation must be consistent: $-2(-3) + 7(-2) - 9(-1) + 4(0) = 6 - 14 + 9 = 1$. The equation holds. Thus, $v_2 = [-3, -2, -1, 0]^{\\top}$.\n\nFinally, we find the generalized eigenvector $v_3$ by solving $(A-I)v_3 = v_2$, with the constraint $e_4^{\\top}v_3 = 0$. Let $v_3 = [c_1, c_2, c_3, c_4]^{\\top}$.\n$$\n\\begin{bmatrix}\n-1 & 1 & 0 & 0 \\\\\n0 & -1 & 1 & 0 \\\\\n0 & 0 & -1 & 1 \\\\\n-2 & 7 & -9 & 4\n\\end{bmatrix}\n\\begin{bmatrix} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\end{bmatrix} =\n\\begin{bmatrix} -3 \\\\ -2 \\\\ -1 \\\\ 0 \\end{bmatrix}\n$$\nThe constraint gives $c_4=0$. From the third row: $-c_3 + c_4 = -1 \\implies -c_3 = -1 \\implies c_3=1$.\nFrom the second row: $-c_2 + c_3 = -2 \\implies -c_2 + 1 = -2 \\implies c_2 = 3$.\nFrom the first row: $-c_1 + c_2 = -3 \\implies -c_1 + 3 = -3 \\implies c_1 = 6$.\nThe fourth equation must be consistent: $-2(6) + 7(3) - 9(1) + 4(0) = -12 + 21 - 9 = 0$. The equation holds. Thus, $v_3 = [6, 3, 1, 0]^{\\top}$.\nThe generalized eigenvector chain for $\\lambda = 1$ is $\\{v_1, v_2, v_3\\} = \\{[1, 1, 1, 1]^{\\top}, [-3, -2, -1, 0]^{\\top}, [6, 3, 1, 0]^{\\top}\\}$. The length of this chain is $k=3$.\n\n2) Verification of eigenvalue $\\lambda = 2$.\n\nWe must find a non-zero vector $w$ such that $(A-2I)w = 0$.\n$$\nA-2I = \\begin{bmatrix}\n-2 & 1 & 0 & 0 \\\\\n0 & -2 & 1 & 0 \\\\\n0 & 0 & -2 & 1 \\\\\n-2 & 7 & -9 & 3\n\\end{bmatrix}\n$$\nLet $w = [c_1, c_2, c_3, c_4]^{\\top}$. The system of equations is:\n$$\n-2c_1 + c_2 = 0 \\implies c_2 = 2c_1 \\\\\n-2c_2 + c_3 = 0 \\implies c_3 = 2c_2 = 4c_1 \\\\\n-2c_3 + c_4 = 0 \\implies c_4 = 2c_3 = 8c_1\n$$\nA non-zero solution exists, confirming $\\lambda=2$ is an eigenvalue. The fourth equation, $-2c_1 + 7c_2 - 9c_3 + 3c_4 = (-2 + 7(2) - 9(4) + 3(8))c_1 = (-2+14-36+24)c_1 = 0$, is satisfied. The eigenvector is of the form $c_1[1, 2, 4, 8]^{\\top}$. The normalization $e_4^{\\top}w=1$ requires $c_4=1$, so $8c_1=1$, which gives $c_1=1/8$.\nThe eigenvector is $w = [\\frac{1}{8}, \\frac{1}{4}, \\frac{1}{2}, 1]^{\\top}$.\n\n3) Similarity Transformation and Invariance of Jordan Structure.\n\nThe similarity transformation matrix $T$ is formed by the columns $[v_1, v_2, v_3, w]$:\n$$\nT = \\begin{bmatrix}\nv_1 & v_2 & v_3 & w\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & -3 & 6 & 1/8 \\\\\n1 & -2 & 3 & 1/4 \\\\\n1 & -1 & 1 & 1/2 \\\\\n1 & 0 & 0 & 1\n\\end{bmatrix}\n$$\nThe transformation $T^{-1}AT$ maps $A$ to its Jordan canonical form $J$. The structure of $J$ is determined by the lengths of the generalized eigenvector chains. The chain relations are $Av_1 = \\lambda v_1$, $Av_2 = \\lambda v_2 + v_1$, and $Av_3 = \\lambda v_3 + v_2$ for $\\lambda=1$, and $Aw = 2w$. In matrix form, this is $A[v_1, v_2, v_3] = [v_1, v_2, v_3] J_1$ and $A[w] = [w] J_2$, where\n$$\nJ_1 = \\begin{bmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix}, \\quad J_2 = [2]\n$$\nCombining these, we get $AT = TJ$, where $J = \\text{diag}(J_1, J_2)$. The length of a generalized eigenvector chain for an eigenvalue $\\lambda$ determines the size of the corresponding Jordan block. Here, the chain for $\\lambda=1$ has length $3$, resulting in a $3 \\times 3$ Jordan block. The chain for $\\lambda=2$ has length $1$ (a simple eigenvector), resulting in a $1 \\times 1$ Jordan block.\n\nThis Jordan structure is a similarity invariant. If $B = P^{-1}AP$ for some invertible matrix $P$, then $(B-\\lambda I)^k = P^{-1}(A-\\lambda I)^k P$. This implies that the null spaces $\\ker(A-\\lambda I)^k$ and $\\ker(B-\\lambda I)^k$ are isomorphic for all $k \\ge 1$, and thus have the same dimension. The number and sizes of the Jordan blocks for a given eigenvalue $\\lambda$ are uniquely determined by the sequence of dimensions $\\dim(\\ker(A-\\lambda I)^k)$ for $k=1, 2, \\dots$. Since these dimensions are invariant under similarity, the Jordan canonical form is unique up to permutation of the blocks.\n\n4) Determination of the Minimal Polynomial $m_A(s)$.\n\nThe minimal polynomial $m_A(s)$ is the unique monic polynomial of least degree for which $m_A(A) = 0$. The roots of $m_A(s)$ are the eigenvalues of $A$. The exponent of a factor $(s-\\lambda_i)$ in the minimal polynomial is equal to the size of the largest Jordan block associated with the eigenvalue $\\lambda_i$.\nFrom our analysis:\n- The eigenvalue $\\lambda=1$ has a single Jordan block of size $3 \\times 3$. The size of the largest block is $3$.\n- The eigenvalue $\\lambda=2$ has a single Jordan block of size $1 \\times 1$. The size of the largest block is $1$.\nTherefore, the minimal polynomial must be:\n$$\nm_A(s) = (s-1)^3 (s-2)^1\n$$\nThis is consistent with the fact that for a controllable single-input system, the minimal polynomial is equal to the characteristic polynomial. The characteristic polynomial is $\\chi_A(s) = \\det(sI-A) = (s-1)^3(s-2) = s^4 - 5s^3 + 9s^2 - 7s + 2$. The factored form is derived directly from the Jordan block structure.", "answer": "$$\\boxed{(s-1)^{3}(s-2)}$$", "id": "2744729"}, {"introduction": "Our focus so far has been on the state matrix $A$. The true power of state-space analysis, however, lies in understanding the complete system, including its interaction with inputs via $B$ and outputs via $C$. This culminating exercise demonstrates the most insightful application of similarity transformations in control theory: the Kalman decomposition. You will construct a coordinate system that explicitly partitions the state space into four fundamental subspaces based on controllability and observability, revealing which parts of the system are controllable and observable, which are only controllable, only observable, or neither [@problem_id:2744735]. This decomposition is the definitive tool for understanding the structural properties of any linear system realization.", "problem": "Consider the linear time-invariant state-space system with state vector $x \\in \\mathbb{R}^{5}$, input $u \\in \\mathbb{R}$, and output $y \\in \\mathbb{R}$:\n$$\n\\dot{x} = A x + B u,\\quad y = C x,\n$$\nwhere\n$$\nA = \\begin{pmatrix}\n-4 & 0 & 0 & 0 & 0 \\\\\n0 & -1 & 0 & -2 & 0 \\\\\n0 & 0 & 7 & 0 & 0 \\\\\n0 & 0 & 0 & -2 & 0 \\\\\n0 & 0 & 0 & 0 & 5\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix},\\quad\nC = \\begin{pmatrix} 1 & -1 & 0 & 1 & 0 \\end{pmatrix}.\n$$\nStarting from the fundamental definitions of controllability and observability, construct a similarity transformation $T$ that puts the realization into the Kalman decomposition, separating the four canonical subspaces: controllable-observable, controllable-unobservable, uncontrollable-observable, and uncontrollable-unobservable. Your construction must explicitly identify the controllable subspace, the unobservable subspace, their intersections, and a basis selection that yields a block upper-triangular realization in Kalman form under the transformation $\\tilde{x} = T^{-1} x$.\n\nAfter obtaining the Kalman decomposition, report the characteristic polynomial (in the indeterminate $s$) of the controllable-and-observable block of $T^{-1} A T$. Give your final answer as a single analytic expression. No rounding is required. No physical units are involved.", "solution": "The problem requires the construction of a similarity transformation for a given linear time-invariant (LTI) system to bring it into Kalman canonical form, and then to determine the characteristic polynomial of the controllable and observable subsystem.\n\nThe system is defined by the state-space equations:\n$$ \\dot{x} = Ax + Bu, \\quad y = Cx $$\nwith matrices given as:\n$$ A = \\begin{pmatrix} -4 & 0 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & -2 & 0 \\\\ 0 & 0 & 7 & 0 & 0 \\\\ 0 & 0 & 0 & -2 & 0 \\\\ 0 & 0 & 0 & 0 & 5 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & -1 & 0 & 1 & 0 \\end{pmatrix} $$\n\nFirst, we validate the problem. The givens are the matrices $A$, $B$, and $C$, with state dimension $n=5$, input dimension $m=1$, and output dimension $p=1$. The problem statement is self-contained, scientifically grounded in established control theory, and objective. It presents a standard, well-posed problem. The problem is valid.\n\nThe solution proceeds by identifying the four fundamental subspaces of the state space $\\mathbb{R}^5$: the controllable subspace $\\mathcal{C}$, the unobservable subspace $\\mathcal{O}^\\perp$, and their intersections which define the Kalman decomposition.\n\nStep 1: Determine the Controllable Subspace $\\mathcal{C}$.\nThe controllable subspace is the range of the controllability matrix $\\mathcal{C}_M = \\begin{pmatrix} B & AB & A^2B & A^3B & A^4B \\end{pmatrix}$.\nWe compute the columns:\n$B = \\begin{pmatrix} 0 & 1 & 0 & 1 & 1 \\end{pmatrix}^T$\n$AB = \\begin{pmatrix} 0 & -3 & 0 & -2 & 5 \\end{pmatrix}^T$\n$A^2B = \\begin{pmatrix} 0 & 7 & 0 & 4 & 25 \\end{pmatrix}^T$\n$A^3B = \\begin{pmatrix} 0 & -15 & 0 & -8 & 125 \\end{pmatrix}^T$\n$A^4B = \\begin{pmatrix} 0 & 31 & 0 & 16 & 625 \\end{pmatrix}^T$\nThe controllability matrix is:\n$$ \\mathcal{C}_M = \\begin{pmatrix} 0 & 0 & 0 & 0 & 0 \\\\ 1 & -3 & 7 & -15 & 31 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ 1 & -2 & 4 & -8 & 16 \\\\ 1 & 5 & 25 & 125 & 625 \\end{pmatrix} $$\nThe first and third rows are zero. The rank is determined by the linear independence of the remaining rows. Let us examine the first three columns. The submatrix formed by rows $2$, $4$, $5$ and columns $1$, $2$, $3$ is $\\begin{pmatrix} 1 & -3 & 7 \\\\ 1 & -2 & 4 \\\\ 1 & 5 & 25 \\end{pmatrix}$, which has a determinant of $42 \\neq 0$. Thus, the rank of $\\mathcal{C}_M$ is $3$, and $\\dim(\\mathcal{C}) = 3$. The columns of $\\mathcal{C}_M$ all lie in the subspace where the first and third components are zero, which is $\\text{span}\\{e_2, e_4, e_5\\}$, where $e_i$ are the standard basis vectors. Since $\\dim(\\mathcal{C})=3$, we must have $\\mathcal{C} = \\text{span}\\{e_2, e_4, e_5\\}$.\n\nStep 2: Determine the Unobservable Subspace $\\mathcal{O}^\\perp$.\nThe unobservable subspace is the null space of the observability matrix $\\mathcal{O}_M$:\n$$ \\mathcal{O}_M = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\\\ CA^3 \\\\ CA^4 \\end{pmatrix} $$\nWe compute the rows:\n$C = \\begin{pmatrix} 1 & -1 & 0 & 1 & 0 \\end{pmatrix}$\n$CA = \\begin{pmatrix} -4 & 1 & 0 & 0 & 0 \\end{pmatrix}$\n$CA^2 = \\begin{pmatrix} 16 & -1 & 0 & 0 & 0 \\end{pmatrix}$\n$CA^3 = \\begin{pmatrix} -64 & 1 & 0 & 0 & 0 \\end{pmatrix}$\n$CA^4 = \\begin{pmatrix} 256 & -1 & 0 & 0 & 0 \\end{pmatrix}$\nA vector $x = (x_1, x_2, x_3, x_4, x_5)^T$ is in $\\mathcal{O}^\\perp$ if $\\mathcal{O}_M x = 0$. The columns corresponding to $x_3$ and $x_5$ are zero. For the remaining components, rows 2 and 3 of $\\mathcal{O}_M x = 0$ give the system $-4x_1 + x_2 = 0$ and $16x_1 - x_2 = 0$, which implies $x_1=0$ and $x_2=0$. The first row, $x_1 - x_2 + x_4 = 0$, then implies $x_4=0$. Thus, for any $x \\in \\mathcal{O}^\\perp$, we must have $x_1=x_2=x_4=0$. The null space is therefore spanned by vectors where only $x_3$ and $x_5$ can be non-zero.\nHence, the unobservable subspace is $\\mathcal{O}^\\perp = \\text{span}\\{e_3, e_5\\}$, and $\\dim(\\mathcal{O}^\\perp) = 2$.\nThe observable subspace is $\\mathcal{O} = (\\mathcal{O}^\\perp)^\\perp = \\text{span}\\{e_1, e_2, e_4\\}$.\n\nStep 3: Construct Bases for the Kalman Decomposition Subspaces.\nThe state space $\\mathbb{R}^5$ is decomposed into a direct sum of four subspaces.\n1. Controllable and observable: $S_1 = \\mathcal{C} \\cap \\mathcal{O} = \\text{span}\\{e_2, e_4, e_5\\} \\cap \\text{span}\\{e_1, e_2, e_4\\} = \\text{span}\\{e_2, e_4\\}$. A basis is $\\{e_2, e_4\\}$. $\\dim(S_1) = 2$.\n2. Controllable and unobservable: $S_2 = \\mathcal{C} \\cap \\mathcal{O}^\\perp = \\text{span}\\{e_2, e_4, e_5\\} \\cap \\text{span}\\{e_3, e_5\\} = \\text{span}\\{e_5\\}$. A basis is $\\{e_5\\}$. $\\dim(S_2) = 1$.\n3. Uncontrollable and observable: $S_3 = \\mathcal{C}^\\perp \\cap \\mathcal{O}$. First, $\\mathcal{C}^\\perp = (\\text{span}\\{e_2, e_4, e_5\\})^\\perp = \\text{span}\\{e_1, e_3\\}$. So, $S_3 = \\text{span}\\{e_1, e_3\\} \\cap \\text{span}\\{e_1, e_2, e_4\\} = \\text{span}\\{e_1\\}$. A basis is $\\{e_1\\}$. $\\dim(S_3) = 1$.\n4. Uncontrollable and unobservable: $S_4 = \\mathcal{C}^\\perp \\cap \\mathcal{O}^\\perp = \\text{span}\\{e_1, e_3\\} \\cap \\text{span}\\{e_3, e_5\\} = \\text{span}\\{e_3\\}$. A basis is $\\{e_3\\}$. $\\dim(S_4) = 1$.\n\nStep 4: Construct the Similarity Transformation.\nThe transformation matrix $T$ is formed by concatenating the basis vectors in the order $S_1, S_2, S_3, S_4$.\n$$ T = \\begin{pmatrix} e_2 & e_4 & e_5 & e_1 & e_3 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 \\\\ 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0 \\end{pmatrix} $$\nThis is a permutation matrix, so its inverse is its transpose: $T^{-1} = T^T$. The new state is $\\tilde{x} = T^{-1}x = (x_2, x_4, x_5, x_1, x_3)^T$.\n\nStep 5: Compute the Transformed System.\nThe transformed state matrix is $\\tilde{A} = T^{-1}AT$. The columns of $AT$ are $Ae_2, Ae_4, Ae_5, Ae_1, Ae_3$.\n$AT = A\\begin{pmatrix} e_2 & e_4 & e_5 & e_1 & e_3 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 & -4 & 0 \\\\ -1 & -2 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 7 \\\\ 0 & -2 & 0 & 0 & 0 \\\\ 0 & 0 & 5 & 0 & 0 \\end{pmatrix}$.\nThen $\\tilde{A} = T^{-1}(AT)$ reorders the rows of $AT$ to $(2, 4, 5, 1, 3)$:\n$$ \\tilde{A} = \\begin{pmatrix} -1 & -2 & 0 & 0 & 0 \\\\ 0 & -2 & 0 & 0 & 0 \\\\ 0 & 0 & 5 & 0 & 0 \\\\ 0 & 0 & 0 & -4 & 0 \\\\ 0 & 0 & 0 & 0 & 7 \\end{pmatrix} $$\nThis matrix is block diagonal, which is a special case of the required block upper-triangular form. The blocks correspond to the four subspaces:\n$$\n\\tilde{A} =\n\\left(\n\\begin{array}{cc|c|c|c}\n-1 & -2 & 0 & 0 & 0 \\\\\n0 & -2 & 0 & 0 & 0 \\\\\n\\hline\n0 & 0 & 5 & 0 & 0 \\\\\n\\hline\n0 & 0 & 0 & -4 & 0 \\\\\n\\hline\n0 & 0 & 0 & 0 & 7\n\\end{array}\n\\right)\n= \\begin{pmatrix} A_{co} & 0 & 0 & 0 \\\\ 0 & A_{c\\bar{o}} & 0 & 0 \\\\ 0 & 0 & A_{\\bar{c}o} & 0 \\\\ 0 & 0 & 0 & A_{\\bar{c}\\bar{o}} \\end{pmatrix}\n$$\nThe controllable-and-observable block is the top-left $2 \\times 2$ matrix:\n$$ A_{co} = \\begin{pmatrix} -1 & -2 \\\\ 0 & -2 \\end{pmatrix} $$\n\nStep 6: Determine the Characteristic Polynomial.\nThe characteristic polynomial of the controllable-and-observable block is $p(s) = \\det(sI - A_{co})$.\n$$ sI - A_{co} = s\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} -1 & -2 \\\\ 0 & -2 \\end{pmatrix} = \\begin{pmatrix} s+1 & 2 \\\\ 0 & s+2 \\end{pmatrix} $$\nThe determinant is:\n$$ p(s) = (s+1)(s+2) - (2)(0) = s^2 + 3s + 2 $$\nThis is the required characteristic polynomial.", "answer": "$$\\boxed{s^2 + 3s + 2}$$", "id": "2744735"}]}