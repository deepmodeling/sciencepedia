{"hands_on_practices": [{"introduction": "The journey into the diagonal canonical form often begins with a system described by its input-output relationship, the transfer function. This first practice demonstrates the essential technique of partial fraction expansion to transform a higher-order system into a set of parallel, independent first-order modes. By completing this exercise [@problem_id:1754750], you will gain hands-on skill in deriving a state-space representation where the system's internal dynamic modes are explicitly decoupled, a crucial first step for transparent analysis and design.", "problem": "A stable, second-order Linear Time-Invariant (LTI) system, a fundamental block in analog signal processing, is described by a transfer function $H(s)$ that connects the Laplace transform of the output, $Y(s)$, to the Laplace transform of the input, $U(s)$. The specific transfer function for this system is:\n$$H(s) = \\frac{Y(s)}{U(s)} = \\frac{5}{s^2 + 5s + 4}$$\nFor implementation purposes, this system needs to be modeled using a state-space representation, defined by the equations:\n$$\\dot{\\mathbf{x}}(t) = \\mathbf{A}\\mathbf{x}(t) + \\mathbf{B}u(t)$$\n$$y(t) = \\mathbf{C}\\mathbf{x}(t) + D u(t)$$\nA critical design specification requires that the internal state variables of the model be dynamically decoupled from one another. This is achieved by ensuring that the state matrix $\\mathbf{A}$ is a diagonal matrix. To guarantee a unique representation for verification, the diagonal elements of $\\mathbf{A}$ must be arranged such that the magnitude of the first element is strictly less than the magnitude of the second element, i.e., $|A_{11}| < |A_{22}|$.\n\nGiven this specific decoupled state-space representation, determine the numerical value of the expression $A_{22} \\cdot B_{11} + C_{12}$.", "solution": "The problem asks for the value of an expression involving elements of the state-space matrices ($\\mathbf{A}$, $\\mathbf{B}$, $\\mathbf{C}$) for a system given by the transfer function $H(s) = \\frac{5}{s^2 + 5s + 4}$. The key constraint is that the state matrix $\\mathbf{A}$ must be diagonal. This corresponds to the diagonal canonical form (or parallel realization) of the system.\n\nFirst, we need to perform a partial fraction expansion of the transfer function $H(s)$. We start by finding the poles of the system, which are the roots of the denominator polynomial:\n$$s^2 + 5s + 4 = 0$$\nFactoring the quadratic, we get:\n$$(s+1)(s+4) = 0$$\nThe poles are $p_1 = -1$ and $p_2 = -4$.\n\nNow, we can express the transfer function as:\n$$H(s) = \\frac{5}{(s+1)(s+4)} = \\frac{R_1}{s+1} + \\frac{R_2}{s+4}$$\nTo find the residues $R_1$ and $R_2$, we use the cover-up method.\nFor $R_1$:\n$$R_1 = \\left. (s+1)H(s) \\right|_{s=-1} = \\left. \\frac{5}{s+4} \\right|_{s=-1} = \\frac{5}{-1+4} = \\frac{5}{3}$$\nFor $R_2$:\n$$R_2 = \\left. (s+4)H(s) \\right|_{s=-4} = \\left. \\frac{5}{s+1} \\right|_{s=-4} = \\frac{5}{-4+1} = -\\frac{5}{3}$$\nSo the partial fraction expansion is:\n$$H(s) = \\frac{5/3}{s+1} - \\frac{5/3}{s+4}$$\nThe output $Y(s)$ can be written as the sum of two terms:\n$$Y(s) = \\left( \\frac{5/3}{s+1} \\right)U(s) + \\left( \\frac{-5/3}{s+4} \\right)U(s)$$\nThe diagonal canonical form represents the system as a parallel combination of first-order systems. We can define the state variables $X_1(s)$ and $X_2(s)$ in relation to the input $U(s)$ and the poles of the system. A standard choice is:\n$$X_1(s) = \\frac{1}{s+1}U(s) \\quad \\text{and} \\quad X_2(s) = \\frac{1}{s+4}U(s)$$\nFrom these definitions, we can write the state equations in the Laplace domain:\n$$sX_1(s) = -X_1(s) + U(s)$$\n$$sX_2(s) = -4X_2(s) + U(s)$$\nTransforming back to the time domain, where $sX(s)$ corresponds to $\\dot{x}(t)$:\n$$\\dot{x}_1(t) = -x_1(t) + u(t)$$\n$$\\dot{x}_2(t) = -4x_2(t) + u(t)$$\nThe output equation is found by expressing $Y(s)$ in terms of $X_1(s)$ and $X_2(s)$:\n$$Y(s) = \\frac{5}{3}X_1(s) - \\frac{5}{3}X_2(s)$$\nIn the time domain, this becomes:\n$$y(t) = \\frac{5}{3}x_1(t) - \\frac{5}{3}x_2(t)$$\nNow we can construct the state-space matrices $\\mathbf{A}$, $\\mathbf{B}$, $\\mathbf{C}$, and $D$.\nFrom the state equations:\n$$\\begin{pmatrix} \\dot{x}_1 \\\\ \\dot{x}_2 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -4 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} u(t)$$\nSo, $\\mathbf{A} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -4 \\end{pmatrix}$ and $\\mathbf{B} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n\nFrom the output equation:\n$$y(t) = \\begin{pmatrix} 5/3 & -5/3 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} + 0 \\cdot u(t)$$\nSo, $\\mathbf{C} = \\begin{pmatrix} 5/3 & -5/3 \\end{pmatrix}$ and $D=0$.\n\nWe must verify the ordering constraint $|A_{11}| < |A_{22}|$.\n$|A_{11}| = |-1| = 1$.\n$|A_{22}| = |-4| = 4$.\nSince $1 < 4$, the constraint is satisfied. If it were not, we would need to swap the states $x_1$ and $x_2$, which would permute the diagonal elements of $\\mathbf{A}$ and the elements of $\\mathbf{B}$ and $\\mathbf{C}$. With this ordering, we have the correct matrices.\n\nFinally, we calculate the required expression $A_{22} \\cdot B_{11} + C_{12}$.\nFrom our matrices:\n$A_{22} = -4$\n$B_{11} = 1$\n$C_{12} = -5/3$\n\nSubstituting these values into the expression:\n$$A_{22} \\cdot B_{11} + C_{12} = (-4) \\cdot (1) + \\left(-\\frac{5}{3}\\right) = -4 - \\frac{5}{3}$$\nTo combine these terms, we find a common denominator:\n$$-4 - \\frac{5}{3} = -\\frac{12}{3} - \\frac{5}{3} = -\\frac{17}{3}$$\nThe value of the expression is $-17/3$.", "answer": "$$\\boxed{-\\frac{17}{3}}$$", "id": "1754750"}, {"introduction": "With a system expressed in its diagonal canonical form, we can directly inspect its fundamental properties. This exercise [@problem_id:2700306] delves into the concept of controllability by asking you to construct a system where certain modes are immune to the control input. By working directly in the eigenbasis, you will see precisely how an eigenvector's absence from the span of the input matrix leads to an uncontrollable mode, linking the abstract theory of controllability to a clear, structural condition.", "problem": "Consider the Linear Time-Invariant (LTI) state-space system defined by $\\dot{x}(t)=A\\,x(t)+B\\,u(t)$, where $A\\in\\mathbb{R}^{n\\times n}$ and $B\\in\\mathbb{R}^{n\\times m}$. The diagonal canonical form represents $A$ in a basis of its eigenvectors so that $A$ is diagonal, and controllability can be analyzed using the structure of $B$ in that same eigenbasis. Begin from the foundational definitions of eigenvalues, eigenvectors, and controllability, and do not invoke any pre-packaged formulas that shortcut the reasoning. \n\nYour task is to explicitly construct an example with the following properties and then perform a calculation on it:\n- Choose $n=4$ and define a diagonalizable matrix $A$ with four distinct real eigenvalues. Work directly in the eigenbasis and set \n$$\nA=\\mathrm{diag}(-3,\\,-1,\\,2,\\,4).\n$$\n- Choose an input matrix $B\\in\\mathbb{R}^{4\\times 1}$ that lies entirely in the direct sum of a proper subset of the eigenspaces of $A$ so that the complementary eigenspaces are not actuated. Concretely, take\n$$\nB=\\begin{pmatrix}1\\\\-1\\\\0\\\\0\\end{pmatrix},\n$$\nso that $B$ lies in the direct sum of the first two eigenspaces of $A$.\n- Using only the core definitions of controllability (for example, the Kalman controllability matrix or the Popov–Belevitch–Hautus test), justify why the pair $(A,B)$ is uncontrollable in this construction by identifying which eigenspaces are not actuated by $B$.\n- Then, compute the rank of the Kalman controllability matrix \n$$\n\\mathcal{C}=\\big[B,\\;A B,\\;A^{2}B,\\;A^{3}B\\big].\n$$\n\nGive your final answer as an integer representing the rank of $\\mathcal{C}$. No rounding is needed. Express the final answer as a pure number without units.", "solution": "The system is given in state-space form, $\\dot{x}(t) = A x(t) + B u(t)$, where the state vector $x(t) \\in \\mathbb{R}^4$ is expressed in a basis of eigenvectors of the matrix $A$. The provided system matrices are:\n$$ A = \\mathrm{diag}(-3, -1, 2, 4) $$\n$$ B = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThe eigenvalues of $A$ are the diagonal entries: $\\lambda_1 = -3$, $\\lambda_2 = -1$, $\\lambda_3 = 2$, and $\\lambda_4 = 4$. Since $A$ is diagonal, the standard basis vectors $e_1, e_2, e_3, e_4$ are the eigenvectors corresponding to these eigenvalues, respectively.\n\nThe state equations can be written as a set of decoupled first-order differential equations for each component of the state vector $x(t) = \\begin{pmatrix} x_1(t) & x_2(t) & x_3(t) & x_4(t) \\end{pmatrix}^T$:\n$$ \\dot{x}_1(t) = -3 x_1(t) + 1 \\cdot u(t) $$\n$$ \\dot{x}_2(t) = -1 x_2(t) - 1 \\cdot u(t) $$\n$$ \\dot{x}_3(t) = 2 x_3(t) + 0 \\cdot u(t) $$\n$$ \\dot{x}_4(t) = 4 x_4(t) + 0 \\cdot u(t) $$\nA state variable, or mode, is controllable if the control input $u(t)$ can influence its dynamics. From the equations above, it is immediately apparent that the dynamics of $x_3(t)$ and $x_4(t)$ are entirely independent of the control input $u(t)$. The solutions to these are $x_3(t) = x_3(0) \\exp(2t)$ and $x_4(t) = x_4(0) \\exp(4t)$. If the initial conditions $x_3(0)$ or $x_4(0)$ are non-zero, there is no control input $u(t)$ that can drive these states to the origin. Therefore, the system cannot be steered to an arbitrary final state, and it is by definition uncontrollable. The uncontrollable modes correspond to the states $x_3$ and $x_4$, which are associated with the eigenspaces of eigenvalues $\\lambda_3=2$ and $\\lambda_4=4$. This is a direct consequence of the third and fourth rows of the input matrix $B$ being zero in this eigenbasis representation.\n\nTo provide a more formal justification using a core definition, we can utilize the Popov-Belevitch-Hautus (PBH) test. The PBH test states that the pair $(A, B)$ is controllable if and only if the matrix $[\\lambda I - A \\quad B]$ has full row rank ($n=4$) for every eigenvalue $\\lambda$ of $A$. Let us test this condition for the eigenvalue $\\lambda_3 = 2$:\n$$ [\\lambda_3 I - A \\quad B] = [2I - A \\quad B] = \\left[ \\begin{pmatrix} 2 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 2 \\end{pmatrix} - \\begin{pmatrix} -3 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 4 \\end{pmatrix} \\quad \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right] $$\n$$ = \\left[ \\begin{pmatrix} 5 & 0 & 0 & 0 \\\\ 0 & 3 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -2 \\end{pmatrix} \\quad \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\right] = \\begin{pmatrix} 5 & 0 & 0 & 0 & 1 \\\\ 0 & 3 & 0 & 0 & -1 \\\\ 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -2 & 0 \\end{pmatrix} $$\nThe third row of this matrix is entirely zero. Consequently, its rank is less than $4$. The condition for controllability fails. A similar result is obtained for $\\lambda_4 = 4$. This confirms that the system is uncontrollable.\n\nThe problem then requires the computation of the rank of the Kalman controllability matrix $\\mathcal{C} = [B \\quad AB \\quad A^2B \\quad A^3B]$. We will construct this matrix column by column.\nThe first column is $B$:\n$$ B = \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThe second column is $AB$:\n$$ AB = \\begin{pmatrix} -3 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -3 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThe third column is $A^2B = A(AB)$:\n$$ A^2B = \\begin{pmatrix} -3 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} -3 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 9 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThe fourth column is $A^3B = A(A^2B)$:\n$$ A^3B = \\begin{pmatrix} -3 & 0 & 0 & 0 \\\\ 0 & -1 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 4 \\end{pmatrix} \\begin{pmatrix} 9 \\\\ -1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -27 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nNow, assemble the controllability matrix $\\mathcal{C}$:\n$$ \\mathcal{C} = \\begin{pmatrix} 1 & -3 & 9 & -27 \\\\ -1 & 1 & -1 & 1 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{pmatrix} $$\nTo find the rank of $\\mathcal{C}$, we determine the number of linearly independent columns (or rows). The third and fourth rows are zero vectors, which means the rank of $\\mathcal{C}$ is at most $2$. We inspect the first two columns, $v_1 = \\begin{pmatrix} 1 & -1 & 0 & 0 \\end{pmatrix}^T$ and $v_2 = \\begin{pmatrix} -3 & 1 & 0 & 0 \\end{pmatrix}^T$. These two vectors are not scalar multiples of each other, and thus are linearly independent. For example, the determinant of the submatrix formed by their non-zero components is $1(1) - (-3)(-1) = 1 - 3 = -2 \\neq 0$.\nSince there are at least two linearly independent columns and the rank cannot exceed $2$, the rank of the controllability matrix $\\mathcal{C}$ is exactly $2$. This is consistent with our earlier finding that the system has two controllable modes and two uncontrollable modes. The rank of the controllability matrix is equal to the dimension of the controllable subspace, which in this case is $2$.", "answer": "$$\\boxed{2}$$", "id": "2700306"}, {"introduction": "The ultimate power of the diagonal canonical form is its ability to simplify complex design tasks. This final practice focuses on designing a Luenberger observer, a key component for estimating a system's internal state when it cannot be measured directly. You will see how the decoupled structure of the diagonal form transforms the multivariable problem of observer gain selection into a series of straightforward scalar equations, allowing you to place the error dynamic poles for each observable mode independently and with surgical precision [@problem_id:2700302].", "problem": "Consider a linear time-invariant state-space model in diagonal canonical form with state dynamics matrix $A_{d} \\in \\mathbb{R}^{4 \\times 4}$ and output matrix $C_{d} \\in \\mathbb{R}^{2 \\times 4}$ given by\n$$\nA_{d} = \\mathrm{diag}(-1,\\,2,\\,0,\\,-3), \n\\qquad\nC_{d} = \\begin{pmatrix}\n3 & 0 & 0 & 0\\\\\n0 & 0 & 2 & 0\n\\end{pmatrix}.\n$$\nA full-order Luenberger observer is implemented as\n$$\n\\dot{\\hat{x}} = A_{d}\\,\\hat{x} + L\\,(y - C_{d}\\,\\hat{x}),\n$$\nwhere $L \\in \\mathbb{R}^{4 \\times 2}$ is the observer gain to be designed. Let the estimation error be $e = x - \\hat{x}$. Under the usual construction, the estimation error dynamics follow\n$$\n\\dot{e} = (A_{d} - L\\,C_{d})\\,e.\n$$\nSuppose we want each observable mode to decay at a specified rate without introducing coupling between modes in the estimation error dynamics. In particular, require that:\n- the error mode associated with the first state coordinate decays with rate $6$ (that is, the corresponding eigenvalue of $A_{d} - L\\,C_{d}$ is $-6$),\n- the error mode associated with the third state coordinate decays with rate $4$ (that is, the corresponding eigenvalue of $A_{d} - L\\,C_{d}$ is $-4$),\n- the error modes associated with the second and fourth coordinates remain unaffected by the observer (so their eigenvalues remain $2$ and $-3$, respectively),\n- and $A_{d} - L\\,C_{d}$ remains diagonal (no cross-mode coupling in the error dynamics).\n\nUsing only fundamental definitions of the Luenberger observer error dynamics and properties of diagonal canonical form, determine the unique matrix $L$ that satisfies these requirements. Express your final answer as an explicit $4 \\times 2$ matrix. No rounding is required.", "solution": "The core of the problem is to determine the observer gain matrix $L \\in \\mathbb{R}^{4 \\times 2}$ such that the error dynamics matrix, $A_e = A_{d} - L\\,C_{d}$, meets a set of specified criteria. The state and output matrices are given as:\n$$ A_{d} = \\mathrm{diag}(-1, 2, 0, -3) = \\begin{pmatrix} -1 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -3 \\end{pmatrix} $$\n$$ C_{d} = \\begin{pmatrix} 3 & 0 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\end{pmatrix} $$\nThe observer gain matrix $L$ is a $4 \\times 2$ matrix with unknown elements:\n$$ L = \\begin{pmatrix} l_{11} & l_{12} \\\\ l_{21} & l_{22} \\\\ l_{31} & l_{32} \\\\ l_{41} & l_{42} \\end{pmatrix} $$\nThe error dynamics are governed by $\\dot{e} = (A_{d} - L\\,C_{d})e$. We first compute the product $L\\,C_{d}$:\n$$ L\\,C_{d} = \\begin{pmatrix} l_{11} & l_{12} \\\\ l_{21} & l_{22} \\\\ l_{31} & l_{32} \\\\ l_{41} & l_{42} \\end{pmatrix} \\begin{pmatrix} 3 & 0 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\end{pmatrix} = \\begin{pmatrix} 3l_{11} & 0 & 2l_{12} & 0 \\\\ 3l_{21} & 0 & 2l_{22} & 0 \\\\ 3l_{31} & 0 & 2l_{32} & 0 \\\\ 3l_{41} & 0 & 2l_{42} & 0 \\end{pmatrix} $$\nNow, we construct the error dynamics matrix $A_e = A_{d} - L\\,C_{d}$:\n$$ A_e = \\begin{pmatrix} -1 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & -3 \\end{pmatrix} - \\begin{pmatrix} 3l_{11} & 0 & 2l_{12} & 0 \\\\ 3l_{21} & 0 & 2l_{22} & 0 \\\\ 3l_{31} & 0 & 2l_{32} & 0 \\\\ 3l_{41} & 0 & 2l_{42} & 0 \\end{pmatrix} $$\n$$ A_e = \\begin{pmatrix} -1 - 3l_{11} & 0 & -2l_{12} & 0 \\\\ -3l_{21} & 2 & -2l_{22} & 0 \\\\ -3l_{31} & 0 & -2l_{32} & 0 \\\\ -3l_{41} & 0 & -2l_{42} & -3 \\end{pmatrix} $$\nA primary requirement is that $A_e$ must be a diagonal matrix, meaning all its off-diagonal elements must be zero. This condition places strict constraints on the elements of $L$.\n\\begin{itemize}\n    \\item From element $(A_e)_{1,3}$: $-2l_{12} = 0 \\implies l_{12} = 0$.\n    \\item From element $(A_e)_{2,1}$: $-3l_{21} = 0 \\implies l_{21} = 0$.\n    \\item From element $(A_e)_{2,3}$: $-2l_{22} = 0 \\implies l_{22} = 0$.\n    \\item From element $(A_e)_{3,1}$: $-3l_{31} = 0 \\implies l_{31} = 0$.\n    \\item From element $(A_e)_{4,1}$: $-3l_{41} = 0 \\implies l_{41} = 0$.\n    \\item From element $(A_e)_{4,3}$: $-2l_{42} = 0 \\implies l_{42} = 0$.\n\\end{itemize}\nThese constraints force the structure of $L$ to be:\n$$ L = \\begin{pmatrix} l_{11} & 0 \\\\ 0 & 0 \\\\ 0 & l_{32} \\\\ 0 & 0 \\end{pmatrix} $$\nWith this structure for $L$, the error dynamics matrix $A_e$ becomes diagonal:\n$$ A_e = \\begin{pmatrix} -1 - 3l_{11} & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & -2l_{32} & 0 \\\\ 0 & 0 & 0 & -3 \\end{pmatrix} $$\nThe eigenvalues of a diagonal matrix are its diagonal entries. Let's denote the eigenvalues of $A_e$ as $\\lambda'_1, \\lambda'_2, \\lambda'_3, \\lambda'_4$.\n$$ \\lambda'_1 = -1 - 3l_{11} $$\n$$ \\lambda'_2 = 2 $$\n$$ \\lambda'_3 = -2l_{32} $$\n$$ \\lambda'_4 = -3 $$\nThe problem specifies the desired locations for the eigenvalues of the observable modes.\n\\begin{enumerate}\n    \\item The eigenvalue corresponding to the first state coordinate must be $-6$:\n    $$ \\lambda'_1 = -6 \\implies -1 - 3l_{11} = -6 $$\n    $$ -3l_{11} = -5 \\implies l_{11} = \\frac{5}{3} $$\n    \\item The eigenvalue corresponding to the third state coordinate must be $-4$:\n    $$ \\lambda'_3 = -4 \\implies -2l_{32} = -4 $$\n    $$ l_{32} = 2 $$\n    \\item The eigenvalues corresponding to the second and fourth state coordinates must remain unaffected. Their original values are $2$ and $-3$. Our diagonal $A_e$ has $\\lambda'_2 = 2$ and $\\lambda'_4 = -3$, so this condition is automatically satisfied. This is a direct consequence of the fact that the second and fourth modes are unobservable, as indicated by the zero columns in $C_d$ for these states. The eigenvalues of unobservable modes cannot be altered by observer feedback.\n\\end{enumerate}\nThe values of the unknown elements in $L$ are now uniquely determined. We assemble the final matrix $L$:\n$$ L = \\begin{pmatrix} \\frac{5}{3} & 0 \\\\ 0 & 0 \\\\ 0 & 2 \\\\ 0 & 0 \\end{pmatrix} $$\nThis matrix satisfies all conditions laid out in the problem.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{5}{3} & 0 \\\\\n0 & 0 \\\\\n0 & 2 \\\\\n0 & 0\n\\end{pmatrix}\n}\n$$", "id": "2700302"}]}