{"hands_on_practices": [{"introduction": "The best way to develop intuition for abstract mathematical tests is to apply them by hand to a concrete example. This exercise provides a simple $2 \\times 2$ linear time-invariant system to do just that. You will verify the system's observability using two distinct but equivalent methods: the Kalman rank test, based on the derivatives of the output, and the Popov-Belevitch-Hautus (PBH) test, which examines the system's eigenstructure. By performing these calculations manually [@problem_id:2735989], you will see firsthand how these different perspectives converge to the same conclusion, solidifying your understanding of the fundamental principles.", "problem": "Consider the continuous-time, linear time-invariant state-space model with state dimension $n=2$ given by\n$$\\dot{x}(t)=A x(t), \\quad y(t)=C x(t),$$\nwhere\n$$A=\\begin{pmatrix}4 & -5\\\\ 2 & -3\\end{pmatrix}, \\qquad C=\\begin{pmatrix}1 & 1\\end{pmatrix}.$$\nStarting from the fundamental definition that the system is observable if and only if distinct initial states $x(0)$ produce distinct output trajectories $y(t)$ for all $t \\ge 0$, do the following:\n\n1. Using only this definition and linearity, construct the finite-dimensional linear map that sends an initial state $x(0)$ to the stacked vector of the first $n$ output time-derivatives evaluated at $t=0$, and determine its rank by hand for the given $(A,C)$.\n\n2. Independently, reason from the same definition that no nonzero mode of the homogeneous state dynamics that satisfies $\\dot{x}(t)=A x(t)$ can remain hidden in the output $y(t)$, and translate this into a computable rank condition tied to the eigenstructure of $A$. Evaluate this condition explicitly for each eigenvalue of $A$ by hand for the given $(A,C)$.\n\nConfirm that the integer ranks obtained by the two independent approaches agree. Report, as your final answer, the common rank value. No rounding is required, and no physical units are involved. Your final answer must be a single integer.", "solution": "The problem statement is subject to validation.\n\n**Step 1: Extracted Givens**\n- System model: Continuous-time, linear time-invariant (LTI).\n- State-space equations: $\\dot{x}(t)=A x(t)$, $y(t)=C x(t)$.\n- State dimension: $n=2$.\n- System matrices: $A=\\begin{pmatrix}4 & -5\\\\ 2 & -3\\end{pmatrix}$, $C=\\begin{pmatrix}1 & 1\\end{pmatrix}$.\n- Fundamental definition of observability: The system is observable if and only if distinct initial states $x(0)$ produce distinct output trajectories $y(t)$ for all $t \\ge 0$.\n- Task 1: Construct a linear map from $x(0)$ to the vector of the first $n$ output time-derivatives at $t=0$, and determine its rank for the given $(A, C)$.\n- Task 2: Reason from the same definition that no nonzero mode of the homogeneous dynamics can be hidden in the output, translate this into a rank condition related to the eigenstructure of $A$, and evaluate this condition for each eigenvalue for the given $(A, C)$.\n- Objective: Confirm the ranks from both approaches agree and report the common rank value.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is scientifically grounded, being a standard exercise in linear control theory. It is well-posed, with all necessary data ($A$, $C$, $n$) provided to compute a unique integer result. The language is objective and precise. The problem does not violate any fundamental principles, is not incomplete or contradictory, and is directly related to the specified topic of rank tests for observability. It is a formalizable and verifiable problem.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be provided.\n\nThe fundamental definition of observability states that distinct initial states $x_1(0)$ and $x_2(0)$ must lead to distinct output trajectories $y_1(t)$ and $y_2(t)$. By the principle of superposition for linear systems, this is equivalent to the condition that a non-zero initial state $x(0) \\neq 0$ must produce a non-zero output trajectory $y(t) \\not\\equiv 0$ for $t \\ge 0$. The solution to the state equation is $x(t) = \\exp(At)x(0)$, which gives the output $y(t) = C \\exp(At) x(0)$. Observability thus means that $C \\exp(At) x(0) = 0$ for all $t \\ge 0$ if and only if $x(0) = 0$.\n\n**Part 1: Observability via Output Derivatives (Kalman Rank Condition)**\nIf the output $y(t)$ is identically zero for all $t \\ge 0$, then all of its time derivatives must also be zero for all $t \\ge 0$. We evaluate these derivatives at $t=0$.\nThe output is $y(t) = C x(t)$.\nThe first derivative of the output is $\\dot{y}(t) = \\frac{d}{dt}(C x(t)) = C \\dot{x}(t) = C A x(t)$.\nIn general, the $k$-th derivative is $y^{(k)}(t) = C A^k x(t)$.\n\nFor the system to be unobservable with an initial state $x(0)$, the output and all its derivatives must be zero at $t=0$:\n$y(0) = C x(0) = 0$\n$\\dot{y}(0) = C A x(0) = 0$\n$\\ddot{y}(0) = C A^2 x(0) = 0$\n...\nBy the Cayley-Hamilton theorem, any power $A^k$ for $k \\ge n$ can be expressed as a linear combination of $\\{I, A, \\dots, A^{n-1}\\}$. Thus, it is sufficient to check only the first $n$ conditions (from derivative order $0$ to $n-1$).\nFor $n=2$, we require the vector of the first $n=2$ derivatives (orders $0$ and $1$) evaluated at $t=0$. This gives the linear mapping from the initial state $x(0)$ to this derivative vector:\n$$ \\begin{pmatrix} y(0) \\\\ \\dot{y}(0) \\end{pmatrix} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix} x(0) $$\nThis mapping is represented by the observability matrix $\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}$. The system is observable if and only if the only $x(0)$ that maps to the zero vector is $x(0)=0$. This is true if and only if the matrix $\\mathcal{O}$ has full column rank, which is $\\text{rank}(\\mathcal{O}) = n = 2$.\n\nWe now compute this rank for the given system.\nGiven $A=\\begin{pmatrix}4 & -5\\\\ 2 & -3\\end{pmatrix}$ and $C=\\begin{pmatrix}1 & 1\\end{pmatrix}$.\nFirst, we compute the product $CA$:\n$$ CA = \\begin{pmatrix}1 & 1\\end{pmatrix} \\begin{pmatrix}4 & -5\\\\ 2 & -3\\end{pmatrix} = \\begin{pmatrix}(1)(4)+(1)(2) & (1)(-5)+(1)(-3)\\end{pmatrix} = \\begin{pmatrix}6 & -8\\end{pmatrix} $$\nThe observability matrix $\\mathcal{O}$ is therefore:\n$$ \\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 6 & -8 \\end{pmatrix} $$\nTo find the rank of this $2 \\times 2$ matrix, we compute its determinant:\n$$ \\det(\\mathcal{O}) = (1)(-8) - (1)(6) = -8 - 6 = -14 $$\nSince $\\det(\\mathcal{O}) = -14 \\neq 0$, the matrix is invertible and thus has full rank. The rank is $2$.\n\n**Part 2: Observability via Eigenmodes (Popov-Belevitch-Hautus Condition)**\nWe investigate the condition that a dynamic mode of the system is \"hidden\" from the output. A mode of the system corresponds to the trajectory initiated by an eigenvector of $A$. Let $v$ be an eigenvector of $A$ with corresponding eigenvalue $\\lambda$, such that $Av = \\lambda v$ and $v \\neq 0$.\nIf the initial state is $x(0) = v$, the state trajectory is $x(t) = \\exp(At)v = e^{\\lambda t}v$.\nThe corresponding output is $y(t) = C x(t) = C (e^{\\lambda t} v) = e^{\\lambda t} (Cv)$.\nFor this mode to be unobservable, its output must be identically zero, $y(t)=0$ for all $t$. Since $e^{\\lambda t} \\neq 0$, this requires that $Cv = 0$.\nThus, the system is unobservable if and only if there exists an eigenvector $v$ of $A$ that lies in the null space of $C$. Conversely, the system is observable if and only if for every eigenvalue $\\lambda_i$ of $A$, no corresponding eigenvector $v_i$ satisfies $Cv_i=0$.\n\nThis condition can be expressed as a rank test. The two conditions $(\\lambda I - A)v = 0$ (definition of an eigenvector) and $Cv = 0$ mean that the vector $v$ is in the null space of both $(\\lambda I - A)$ and $C$. This is possible if and only if the matrix formed by stacking these two matrices does not have full column rank. The condition for observability is therefore that for each eigenvalue $\\lambda_i$ of $A$, the following matrix has full column rank $n$:\n$$ \\begin{pmatrix} \\lambda_i I - A \\\\ C \\end{pmatrix} $$\nWe evaluate this for the given system, where $n=2$. First, we find the eigenvalues of $A$ by solving the characteristic equation $\\det(\\lambda I - A)=0$.\n$$ \\det\\left(\\begin{pmatrix} \\lambda & 0 \\\\ 0 & \\lambda \\end{pmatrix} - \\begin{pmatrix} 4 & -5 \\\\ 2 & -3 \\end{pmatrix}\\right) = \\det\\begin{pmatrix} \\lambda-4 & 5 \\\\ -2 & \\lambda+3 \\end{pmatrix} = 0 $$\n$$ (\\lambda-4)(\\lambda+3) - (5)(-2) = \\lambda^2 - \\lambda - 12 + 10 = \\lambda^2 - \\lambda - 2 = 0 $$\nFactoring the quadratic equation gives $(\\lambda-2)(\\lambda+1)=0$. The eigenvalues are $\\lambda_1=2$ and $\\lambda_2=-1$.\n\nWe now check the rank condition for each eigenvalue.\nCase 1: $\\lambda_1 = 2$.\nThe matrix to be tested is:\n$$ M_1 = \\begin{pmatrix} 2I - A \\\\ C \\end{pmatrix} = \\begin{pmatrix} 2-4 & 5 \\\\ -2 & 2+3 \\\\ \\hline 1 & 1 \\end{pmatrix} = \\begin{pmatrix} -2 & 5 \\\\ -2 & 5 \\\\ 1 & 1 \\end{pmatrix} $$\nThis is a $3 \\times 2$ matrix. Its rank is at most $2$. To check if the rank is $2$, we find a $2 \\times 2$ submatrix with a non-zero determinant. Consider the submatrix formed by the first and third rows:\n$$ \\det\\begin{pmatrix} -2 & 5 \\\\ 1 & 1 \\end{pmatrix} = (-2)(1) - (5)(1) = -2 - 5 = -7 \\neq 0 $$\nSince we found a non-singular $2 \\times 2$ submatrix, the rank of $M_1$ is $2$. The condition is satisfied for $\\lambda_1=2$.\n\nCase 2: $\\lambda_2 = -1$.\nThe matrix to be tested is:\n$$ M_2 = \\begin{pmatrix} -1I - A \\\\ C \\end{pmatrix} = \\begin{pmatrix} -1-4 & 5 \\\\ -2 & -1+3 \\\\ \\hline 1 & 1 \\end{pmatrix} = \\begin{pmatrix} -5 & 5 \\\\ -2 & 2 \\\\ 1 & 1 \\end{pmatrix} $$\nAgain, we check the rank by finding a non-singular $2 \\times 2$ submatrix. Using the first and third rows:\n$$ \\det\\begin{pmatrix} -5 & 5 \\\\ 1 & 1 \\end{pmatrix} = (-5)(1) - (5)(1) = -5 - 5 = -10 \\neq 0 $$\nThe rank of $M_2$ is also $2$. The condition is satisfied for $\\lambda_2=-1$.\n\nBoth approaches confirm observability. The rank of the observability matrix $\\mathcal{O}$ is $2$. The PBH test confirms that for each eigenvalue, the test matrix has rank $2$. The common rank value is $2$.", "answer": "$$\\boxed{2}$$", "id": "2735989"}, {"introduction": "Having mastered the application of rank tests to LTI systems, it is crucial to understand their limitations. A common mistake is to assume that the PBH test can be naively applied to a linear time-varying (LTV) system by 'freezing' time and checking the rank at each instant. This problem [@problem_id:2735982] presents a powerful counterexample where such a frozen-time analysis incorrectly suggests observability. By computing the observability Gramian, you will rigorously demonstrate that the system is, in fact, unobservable, revealing the subtle ways in which time-varying dynamics can conspire to hide a state.", "problem": "Consider the linear time-varying (LTV) system with state $x(t) \\in \\mathbb{R}^{2}$, input-free dynamics, and output\n$$\n\\dot{x}(t) = A(t)\\,x(t), \n\\qquad \ny(t) = C(t)\\,x(t),\n$$\nwhere\n$$\nA(t) \\equiv \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}, \n\\qquad \nC(t) \\equiv \\begin{bmatrix} \\cos t & -\\sin t \\end{bmatrix}.\n$$\nYou may assume the standard definitions of the state transition matrix $\\Phi(t,s)$ for $\\dot{x}(t)=A(t)x(t)$ and of the finite-horizon observability Gramian for LTV systems\n$$\nW_{o}(t_{0},t_{1}) \\equiv \\int_{t_{0}}^{t_{1}} \\Phi(\\tau,t_{0})^{\\top}\\, C(\\tau)^{\\top} C(\\tau)\\, \\Phi(\\tau,t_{0}) \\, \\mathrm{d}\\tau.\n$$\nTasks:\n- Using only fundamental definitions, analyze the rank of the Popov-Belevitch-Hautus (PBH) stacked matrix at frozen times, namely $\\mathrm{rank}\\,\\begin{bmatrix} \\lambda I - A(t) \\\\ C(t) \\end{bmatrix}$, for each fixed time $t \\in \\mathbb{R}$ and all complex $\\lambda \\in \\mathbb{C}$, and explain what this frozen-time check would conclude about observability at each instant.\n- Then, compute the determinant of the finite-horizon observability Gramian $W_{o}(0,2\\pi)$.\n\nGive your final answer as the determinant of $W_{o}(0,2\\pi)$. No units are required, and no rounding is needed. Your reasoning must start from first principles (definitions of $\\Phi$ and $W_{o}$, and standard rank notions) and should not assume any specialized shortcut conditions beyond these foundations.", "solution": "The problem presents a linear time-varying (LTV) system and asks for two distinct analyses: a frozen-time observability check using the Popov-Belevitch-Hautus (PBH) criterion, and a calculation of the determinant of the finite-horizon observability Gramian. The problem statement is scientifically sound and well-posed. We will proceed with the solution.\n\nThe system is given by $\\dot{x}(t) = A(t)x(t)$ and $y(t) = C(t)x(t)$, with matrices\n$$\nA(t) = A = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}, \\qquad C(t) = \\begin{bmatrix} \\cos t & -\\sin t \\end{bmatrix}.\n$$\nThe state dimension is $n=2$. Note that the state dynamics matrix $A(t)$ is, in fact, constant.\n\nFirst, we analyze the rank of the frozen-time PBH matrix for any fixed time $t \\in \\mathbb{R}$ and any complex number $\\lambda \\in \\mathbb{C}$. The PBH matrix for the pair $(A, C(t))$ is\n$$\nM(\\lambda, t) = \\begin{bmatrix} \\lambda I - A \\\\ C(t) \\end{bmatrix} = \\begin{bmatrix} \\lambda & -1 \\\\ 1 & \\lambda \\\\ \\cos t & -\\sin t \\end{bmatrix}.\n$$\nThis is a $3 \\times 2$ matrix. For the frozen-time system to be observable, this matrix must have full column rank, which is rank $2$, for all $\\lambda \\in \\mathbb{C}$. A matrix fails to have full column rank if and only if its columns are linearly dependent. The rank of $M(\\lambda, t)$ can only drop below $2$ if $\\det(\\lambda I - A) = 0$, which means $\\lambda$ must be an eigenvalue of $A$. The characteristic equation for $A$ is\n$$\n\\det(\\lambda I - A) = \\det \\begin{pmatrix} \\lambda & -1 \\\\ 1 & \\lambda \\end{pmatrix} = \\lambda^2 + 1 = 0.\n$$\nThe eigenvalues are $\\lambda_1 = i$ and $\\lambda_2 = -i$. We must check the rank of $M(\\lambda, t)$ for these values of $\\lambda$.\n\nCase 1: $\\lambda = i$.\nThe PBH matrix becomes\n$$\nM(i, t) = \\begin{bmatrix} i & -1 \\\\ 1 & i \\\\ \\cos t & -\\sin t \\end{bmatrix}.\n$$\nThe first row is $i$ times the second row, so the first two rows are linearly dependent, as expected. The rank of the matrix is less than $2$ if and only if the third row, $[\\cos t, -\\sin t]$, is also a linear combination of the first two rows. Since the first two rows span a one-dimensional subspace generated by, for instance, the vector $[1, i]$, the condition for rank deficiency is that $[\\cos t, -\\sin t]$ must be a scalar multiple of $[1, i]$.\n$$\n[\\cos t, -\\sin t] = k [1, i] \\quad \\text{for some } k \\in \\mathbb{C}.\n$$\nThis implies $\\cos t = k$ and $-\\sin t = ki = (\\cos t)i$. For this to hold, we must have $\\sin t = -i \\cos t$. If $\\cos t \\neq 0$, this gives $\\tan t = -i$. The tangent of a real number $t$ cannot be a non-real complex number. If $\\cos t = 0$, then $t = \\frac{\\pi}{2} + m\\pi$ for some integer $m$, which implies $\\sin t = \\pm 1$. The equation becomes $\\pm 1 = -i \\cdot 0$, or $\\pm 1 = 0$, which is a contradiction. Therefore, the vector $[\\cos t, -\\sin t]$ is never a multiple of $[1, i]$ for any real $t$. The rank of $M(i, t)$ is always $2$.\n\nCase 2: $\\lambda = -i$.\nThe PBH matrix becomes\n$$\nM(-i, t) = \\begin{bmatrix} -i & -1 \\\\ 1 & -i \\\\ \\cos t & -\\sin t \\end{bmatrix}.\n$$\nSimilarly, the first two rows are linearly dependent. The rank is less than $2$ if $[\\cos t, -\\sin t]$ is a scalar multiple of $[1, -i]$.\n$$\n[\\cos t, -\\sin t] = k [1, -i] \\quad \\text{for some } k \\in \\mathbb{C}.\n$$\nThis implies $\\cos t = k$ and $-\\sin t = -ki = -(\\cos t)i$, which means $\\sin t = i \\cos t$. This gives $\\tan t = i$ for $\\cos t \\neq 0$, which is impossible for real $t$. If $\\cos t = 0$, we again reach the contradiction $\\pm 1 = 0$. The rank of $M(-i, t)$ is always $2$.\n\nSince the PBH matrix has full rank for all $\\lambda \\in \\mathbb{C}$ and for all $t \\in \\mathbb{R}$, the frozen-time analysis concludes that the system is observable at every instant of time.\n\nNext, we compute the determinant of the finite-horizon observability Gramian $W_o(t_0, t_1)$ over the interval $[0, 2\\pi]$. The definition is\n$$\nW_{o}(0, 2\\pi) = \\int_{0}^{2\\pi} \\Phi(\\tau, 0)^{\\top} C(\\tau)^{\\top} C(\\tau) \\Phi(\\tau, 0) \\, \\mathrm{d}\\tau.\n$$\nSince $A$ is a constant matrix, the state transition matrix $\\Phi(t, s)$ is given by $\\Phi(t, s) = \\exp(A(t-s))$. We need $\\Phi(\\tau, 0) = \\exp(A\\tau)$. The powers of $A$ are $A^2 = -I$, $A^3 = -A$, $A^4 = I$. Using the Taylor series expansion for the matrix exponential:\n$$\n\\exp(A\\tau) = I + A\\tau + \\frac{(A\\tau)^2}{2!} + \\frac{(A\\tau)^3}{3!} + \\dots = I \\left(1 - \\frac{\\tau^2}{2!} + \\frac{\\tau^4}{4!} - \\dots\\right) + A \\left(\\tau - \\frac{\\tau^3}{3!} + \\frac{\\tau^5}{5!} - \\dots\\right).\n$$\nThis simplifies to $\\exp(A\\tau) = I \\cos\\tau + A \\sin\\tau$.\n$$\n\\Phi(\\tau, 0) = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\cos\\tau + \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} \\sin\\tau = \\begin{bmatrix} \\cos\\tau & \\sin\\tau \\\\ -\\sin\\tau & \\cos\\tau \\end{bmatrix}.\n$$\nThe integrand is of the form $K(\\tau) = (\\cdots)^\\top(\\cdots)$. It is computationally simpler to first evaluate the product $C(\\tau)\\Phi(\\tau, 0)$.\n$$\nC(\\tau)\\Phi(\\tau, 0) = \\begin{bmatrix} \\cos\\tau & -\\sin\\tau \\end{bmatrix} \\begin{bmatrix} \\cos\\tau & \\sin\\tau \\\\ -\\sin\\tau & \\cos\\tau \\end{bmatrix}.\n$$\nPerforming the matrix multiplication gives:\n$$\nC(\\tau)\\Phi(\\tau, 0) = \\begin{bmatrix} \\cos^2\\tau + \\sin^2\\tau & \\cos\\tau\\sin\\tau - \\sin\\tau\\cos\\tau \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\end{bmatrix}.\n$$\nThis result is constant for all $\\tau$. The meaning is that the output $y(\\tau)$ depends only on the first component of the initial state $x(0)$, since $y(\\tau) = C(\\tau)\\Phi(\\tau, 0)x(0) = [1, 0]x(0) = x_1(0)$. Any initial state of the form $[0, \\alpha]^\\top$ produces zero output, making the second state component unobservable.\nNow, we can compute the integrand matrix for the Gramian:\n$$\n\\Phi(\\tau, 0)^{\\top} C(\\tau)^{\\top} C(\\tau) \\Phi(\\tau, 0) = \\left( C(\\tau) \\Phi(\\tau, 0) \\right)^{\\top} \\left( C(\\tau) \\Phi(\\tau, 0) \\right) = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}.\n$$\nThe integrand is a constant matrix. The observability Gramian is the integral of this constant matrix over the interval $[0, 2\\pi]$:\n$$\nW_{o}(0, 2\\pi) = \\int_{0}^{2\\pi} \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix} \\mathrm{d}\\tau = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix} \\int_{0}^{2\\pi} \\mathrm{d}\\tau = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix} (2\\pi) = \\begin{bmatrix} 2\\pi & 0 \\\\ 0 & 0 \\end{bmatrix}.\n$$\nThe problem asks for the determinant of this Gramian.\n$$\n\\det(W_{o}(0, 2\\pi)) = \\det\\left(\\begin{bmatrix} 2\\pi & 0 \\\\ 0 & 0 \\end{bmatrix}\\right) = (2\\pi)(0) - (0)(0) = 0.\n$$\nA singular observability Gramian confirms that the system is unobservable over the interval $[0, 2\\pi]$. This provides a crucial counterexample to the reliability of frozen-time analysis for LTV systems, as the time-variation of $C(t)$ is perfectly synchronized with the system's dynamics to mask one of the states.", "answer": "$$\\boxed{0}$$", "id": "2735982"}, {"introduction": "In practice, control theory is implemented in software, where the clean world of analytical mathematics meets the finite precision of floating-point arithmetic. This coding exercise [@problem_id:2735971] bridges this gap by tasking you with implementing both the Kalman and PBH observability tests. Your goal is to compare a naive, fixed-threshold approach for determining numerical rank against a principled, relative-tolerance method. By testing these implementations on a carefully selected suite of systems, you will gain practical insight into the challenges of numerical stability and why robust algorithms are essential for reliable engineering applications.", "problem": "Consider a linear time-invariant state-space system with state matrix $A \\in \\mathbb{R}^{n \\times n}$ and output matrix $C \\in \\mathbb{R}^{p \\times n}$. Observability is a structural property of the pair $(A,C)$ and is defined by the ability to reconstruct the initial state $x(0)$ from the output $y(t)$ over a finite interval under zero input. Two classical rank tests for observability are:\n\n- The Kalman observability matrix test: Construct the observability matrix $O = \\begin{bmatrix} C \\\\ C A \\\\ \\cdots \\\\ C A^{n-1} \\end{bmatrix} \\in \\mathbb{R}^{np \\times n}$. The pair $(A,C)$ is observable if and only if $\\operatorname{rank}(O) = n$.\n\n- The Popov-Belevitch-Hautus (PBH) test: For each eigenvalue $\\lambda$ of $A$, form the stacked matrix $\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix} \\in \\mathbb{C}^{(n+p) \\times n}$. The pair $(A,C)$ is observable if and only if $\\operatorname{rank}\\!\\left(\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix}\\right) = n$ holds for every eigenvalue $\\lambda$ of $A$ (counted with algebraic multiplicity).\n\nIn floating-point arithmetic, determining matrix rank requires a threshold to decide when a singular value is treated as zero. A naive approach uses a fixed absolute threshold $\\tau_{\\text{abs}} = 10^{-8}$, which can fail under scaling. A principled approach uses a relative tolerance scaled by a matrix norm; a standard choice is to declare singular values $s_i$ of a matrix $M \\in \\mathbb{C}^{m \\times n}$ as nonzero if $s_i > \\tau_{\\text{rel}}$, where $\\tau_{\\text{rel}} = s_{\\max}(M) \\cdot \\max(m,n) \\cdot \\epsilon_{\\text{mach}}$ and $s_{\\max}(M)$ is the largest singular value of $M$, and $\\epsilon_{\\text{mach}}$ is the machine epsilon of double precision.\n\nTask: Write a complete program that, for each provided test case $(A,C)$, computes four boolean outcomes:\n1. Kalman test using naive absolute threshold.\n2. Kalman test using principled relative tolerance scaled by the matrix $2$-norm.\n3. PBH test using naive absolute threshold.\n4. PBH test using principled relative tolerance scaled by the matrix $2$-norm.\n\nYour program must implement rank computation via the singular value decomposition and the two thresholding strategies described above. The program should use double-precision arithmetic and the machine epsilon $\\epsilon_{\\text{mach}}$ of that arithmetic.\n\nTest suite:\n- Test case $1$ (well-conditioned, observable):\n  - $A_1 = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix}$, $C_1 = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$.\n- Test case $2$ (observable but output scaled near underflow to demonstrate failure of absolute threshold):\n  - $A_2 = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix}$, $C_2 = 10^{-12} \\begin{bmatrix} 1 & 0 \\end{bmatrix}$.\n- Test case $3$ (exactly unobservable):\n  - $A_3 = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$, $C_3 = \\begin{bmatrix} 0 & 1 \\end{bmatrix}$.\n- Test case $4$ (dimension $3$, well-conditioned, observable companion form):\n  - $A_4 = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ -1 & -1 & -1 \\end{bmatrix}$, $C_4 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}$.\n\nComputational requirements:\n- Implement numerical rank via singular values. For the naive absolute threshold, treat a singular value $s$ as nonzero if $s > \\tau_{\\text{abs}}$ with $\\tau_{\\text{abs}} = 10^{-8}$. For the principled criterion, use $\\tau_{\\text{rel}} = s_{\\max}(M) \\cdot \\max(m,n) \\cdot \\epsilon_{\\text{mach}}$, where $M$ is the matrix whose rank is being assessed.\n- For the PBH test, compute all eigenvalues $\\lambda$ of $A$ numerically and check the rank condition for each $\\lambda$.\n- All mathematical results must be computed in double precision. No physical units or angles are involved.\n\nFinal output format:\n- Aggregate the results across the four test cases in order, each test case contributing a sequence of four booleans in the order listed above, and flatten into a single list of length $16$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets and without spaces, for example: $[{\\rm True},{\\rm False},{\\rm True},{\\rm True},\\ldots]$.", "solution": "The problem statement must first be subjected to rigorous validation.\n\n**Step 1: Extract Givens**\n\n- **System Model**: A linear time-invariant (LTI) system defined by state matrix $A \\in \\mathbb{R}^{n \\times n}$ and output matrix $C \\in \\mathbb{R}^{p \\times n}$.\n- **Kalman Observability Test**: The pair $(A,C)$ is observable if and only if the observability matrix $O = \\begin{bmatrix} C \\\\ CA \\\\ \\vdots \\\\ CA^{n-1} \\end{bmatrix}$ has full column rank, i.e., $\\operatorname{rank}(O) = n$.\n- **Popov-Belevitch-Hautus (PBH) Test**: The pair $(A,C)$ is observable if and only if for every eigenvalue $\\lambda$ of $A$, the matrix $\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix}$ has full column rank, i.e., $\\operatorname{rank}\\!\\left(\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix}\\right) = n$.\n- **Numerical Rank Computation**:\n  1. **Naive Absolute Threshold**: A singular value $s$ is considered non-zero if $s > \\tau_{\\text{abs}}$, where $\\tau_{\\text{abs}} = 10^{-8}$.\n  2. **Principled Relative Tolerance**: For a matrix $M \\in \\mathbb{C}^{m \\times n}$, a singular value $s_i$ is considered non-zero if $s_i > \\tau_{\\text{rel}}$, where $\\tau_{\\text{rel}} = s_{\\max}(M) \\cdot \\max(m,n) \\cdot \\epsilon_{\\text{mach}}$. Here $s_{\\max}(M)$ is the largest singular value of $M$ and $\\epsilon_{\\text{mach}}$ is the machine epsilon for double precision floating-point arithmetic.\n- **Task**: For each of the four test cases provided, compute four boolean outcomes corresponding to the two tests (Kalman, PBH) each evaluated with the two rank computation methods (naive, principled).\n- **Test Cases**:\n  - Case 1: $A_1 = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix}$, $C_1 = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$.\n  - Case 2: $A_2 = \\begin{bmatrix} 0 & 1 \\\\ -2 & -3 \\end{bmatrix}$, $C_2 = 10^{-12} \\begin{bmatrix} 1 & 0 \\end{bmatrix}$.\n  - Case 3: $A_3 = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$, $C_3 = \\begin{bmatrix} 0 & 1 \\end{bmatrix}$.\n  - Case 4: $A_4 = \\begin{bmatrix} 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ -1 & -1 & -1 \\end{bmatrix}$, $C_4 = \\begin{bmatrix} 1 & 0 & 0 \\end{bmatrix}$.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is examined for validity.\n- **Scientifically Grounded**: The problem is based on fundamental and standard results in control theory (Kalman and PBH observability tests) and numerical linear algebra (numerical rank, SVD). These are established and universally accepted principles. The problem is scientifically sound.\n- **Well-Posed**: The problem provides all necessary information: the system matrices for each test case, the precise definitions of the tests, and the exact formulas for the numerical rank thresholds. The task is clearly defined, and a unique solution is computable.\n- **Objective**: The problem is expressed using objective mathematical language, free from ambiguity or subjective claims.\n\nThe problem exhibits none of the specified flaws, such as scientific unsoundness, incompleteness, or contradiction. It is a well-defined computational problem in the specified domain of control theory.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. We will proceed with a complete solution.\n\n**Solution Derivation**\n\nThe solution requires implementing the Kalman and PBH observability tests. For each test, the rank of a specific matrix must be computed and compared to the state dimension $n$. The core of the problem lies in the numerical computation of rank using two distinct tolerance strategies.\n\n**Numerical Rank via SVD**\n\nThe rank of a matrix $M \\in \\mathbb{C}^{m \\times n}$ is the number of its non-zero singular values. In floating-point arithmetic, singular values that are analytically zero may compute to small non-zero numbers. Thus, a threshold is required to determine numerical rank. The Singular Value Decomposition (SVD) of $M$ provides its singular values $s_1 \\geq s_2 \\geq \\dots \\geq s_{\\min(m,n)} \\geq 0$. The numerical rank is the count of singular values $s_i$ greater than a chosen tolerance $\\tau$.\n\n1.  **Naive Absolute Threshold**: The tolerance is a fixed value, $\\tau_{\\text{abs}} = 10^{-8}$. The rank is the number of $s_i > \\tau_{\\text{abs}}$. This method is simple but not robust to scaling, as small singular values of a scaled-down matrix may fall below the threshold even if the matrix is of full rank.\n\n2.  **Principled Relative Tolerance**: The tolerance is scaled relative to the matrix properties: $\\tau_{\\text{rel}} = s_1 \\cdot \\max(m,n) \\cdot \\epsilon_{\\text{mach}}$, where $s_1 = s_{\\max}(M)$ is the largest singular value, and $\\epsilon_{\\text{mach}}$ is the machine epsilon (the distance from $1.0$ to the next larger representable number). This approach adapts to the scale of the matrix entries and is the standard method in high-quality numerical software.\n\nWe will implement a function to compute rank using these two methods.\n\n**Kalman Observability Test**\n\nFor a system $(A,C)$ with state dimension $n$ and output dimension $p$, the observability matrix is constructed as:\n$$ O = \\begin{bmatrix} C \\\\ CA \\\\ CA^2 \\\\ \\vdots \\\\ CA^{n-1} \\end{bmatrix} \\in \\mathbb{R}^{np \\times n} $$\nThe system is observable if $\\operatorname{rank}(O) = n$.\nThe algorithm for the Kalman test will be:\n1.  Given $A$ and $C$, determine $n = \\operatorname{dim}(A)$.\n2.  Construct the matrix $O$ by computing matrix powers $A^k$ and products $CA^k$ for $k = 0, \\dots, n-1$, and vertically stacking the results.\n3.  Compute $\\operatorname{rank}(O)$ using the naive threshold and check if it equals $n$.\n4.  Compute $\\operatorname{rank}(O)$ using the principled threshold and check if it equals $n$.\n\n**Popov-Belevitch-Hautus (PBH) Observability Test**\n\nThe PBH test provides an alternative, frequency-domain condition for observability. The system is observable if and only if for every eigenvalue $\\lambda \\in \\mathbb{C}$ of the matrix $A$, the following rank condition holds:\n$$ \\operatorname{rank}\\left(\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix}\\right) = n $$\nThe matrix $\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix}$ is an $(n+p) \\times n$ matrix. Since eigenvalues $\\lambda$ may be complex, this matrix is generally complex-valued. The SVD is well-defined for complex matrices and its singular values are real and non-negative.\nThe algorithm for the PBH test will be:\n1.  Given $A$ and $C$, determine $n = \\operatorname{dim}(A)$.\n2.  Numerically compute all eigenvalues $\\lambda_1, \\dots, \\lambda_n$ of $A$.\n3.  For each rank method (naive, principled), initialize an observability flag to `True`.\n4.  Iterate through each eigenvalue $\\lambda_j$:\n    a. Construct the PBH matrix $M_j = \\begin{bmatrix} \\lambda_j I - A \\\\ C \\end{bmatrix}$.\n    b. Compute the rank of $M_j$ using the chosen method.\n    c. If the rank is less than $n$, the test fails for this eigenvalue. Set the corresponding observability flag to `False` and one could terminate the loop for this method.\n5.  The final result for each method is the value of its observability flag after checking all eigenvalues.\n\n**Algorithmic Procedure for Each Test Case**\n\nFor each pair $(A, C)$ provided in the test suite:\n1.  Let $n$ be the number of rows/columns of $A$.\n2.  **Kalman Test (Naive)**: Construct $O$. Compute its rank using $\\tau_{\\text{abs}}$. The result is `True` if rank equals $n$, otherwise `False`.\n3.  **Kalman Test (Principled)**: Construct $O$. Compute its rank using $\\tau_{\\text{rel}}$. The result is `True` if rank equals $n$, otherwise `False`.\n4.  **PBH Test (Naive)**: Compute eigenvalues of $A$. For each eigenvalue $\\lambda$, construct $M_\\lambda$ and compute its rank using $\\tau_{\\text{abs}}$. The final result is `True` if the rank is $n$ for all eigenvalues, otherwise `False`.\n5.  **PBH Test (Principled)**: Compute eigenvalues of $A$. For each eigenvalue $\\lambda$, construct $M_\\lambda$ and compute its rank using $\\tau_{\\text{rel}}$. The final result is `True` if the rank is $n$ for all eigenvalues, otherwise `False`.\n6.  Collect the four boolean results in the specified order.\n\nThis procedure will be applied to all four test cases, and the results will be aggregated into a single list for the final output. The implementation will use double-precision floating-point numbers (`numpy.double`) and the corresponding machine epsilon.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_rank(M, method, abs_tol=1e-8):\n    \"\"\"\n    Computes the numerical rank of a matrix using SVD and a specified tolerance method.\n\n    Args:\n        M (np.ndarray): The matrix (real or complex) whose rank is to be computed.\n        method (str): The method for thresholding. Must be 'naive' or 'principled'.\n        abs_tol (float): The absolute tolerance for the 'naive' method.\n\n    Returns:\n        int: The numerical rank of the matrix.\n    \"\"\"\n    if M.size == 0:\n        return 0\n\n    s = np.linalg.svd(M, compute_uv=False)\n    \n    # s is sorted in descending order. s[0] is the largest singular value.\n    if s.size == 0:\n        return 0\n\n    if method == 'naive':\n        tol = abs_tol\n    elif method == 'principled':\n        eps_mach = np.finfo(s.dtype).eps\n        m, n = M.shape\n        # According to standard literature (e.g., Golub  Van Loan), the tolerance is\n        # relative to the largest singular value and matrix dimensions.\n        tol = s[0] * max(m, n) * eps_mach\n    else:\n        raise ValueError(\"Unknown method for rank computation. Must be 'naive' or 'principled'.\")\n\n    return np.sum(s > tol)\n\ndef check_observability(A, C):\n    \"\"\"\n    Performs four observability checks on the pair (A, C) and returns the boolean results.\n    \n    The four checks are:\n    1. Kalman test with naive absolute threshold.\n    2. Kalman test with principled relative tolerance.\n    3. PBH test with naive absolute threshold.\n    4. PBH test with principled relative tolerance.\n    \n    Args:\n        A (np.ndarray): The state matrix (n x n).\n        C (np.ndarray): The output matrix (p x n).\n        \n    Returns:\n        list[bool]: A list of four boolean values representing the outcomes of the tests.\n    \"\"\"\n    n, _ = A.shape\n    p = C.shape[0] if C.ndim > 1 else 1\n\n    # --- Kalman Test ---\n    # Construct observability matrix O\n    O = np.zeros((n * p, n), dtype=np.double)\n    if p > 0: # Handle empty C matrix case\n        O[0:p, :] = C\n        CA_power = C\n        for i in range(1, n):\n            CA_power = CA_power @ A\n            O[i*p:(i+1)*p, :] = CA_power\n\n    # 1. Kalman test with naive threshold\n    rank_kalman_naive = compute_rank(O, method='naive')\n    is_obs_kalman_naive = (rank_kalman_naive == n)\n\n    # 2. Kalman test with principled threshold\n    rank_kalman_principled = compute_rank(O, method='principled')\n    is_obs_kalman_principled = (rank_kalman_principled == n)\n    \n    # --- PBH Test ---\n    eigenvalues = np.linalg.eigvals(A)\n    \n    # 3. PBH test with naive threshold\n    is_obs_pbh_naive = True\n    for lam in eigenvalues:\n        # Construct PBH matrix for eigenvalue lam\n        M_lam = np.vstack((lam * np.eye(n, dtype=np.complex128) - A, C))\n        if compute_rank(M_lam, method='naive')  n:\n            is_obs_pbh_naive = False\n            break\n            \n    # 4. PBH test with principled threshold\n    is_obs_pbh_principled = True\n    for lam in eigenvalues:\n        # Construct PBH matrix for eigenvalue lam\n        M_lam = np.vstack((lam * np.eye(n, dtype=np.complex128) - A, C))\n        if compute_rank(M_lam, method='principled')  n:\n            is_obs_pbh_principled = False\n            break\n            \n    return [is_obs_kalman_naive, is_obs_kalman_principled, is_obs_pbh_naive, is_obs_pbh_principled]\n\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs observability checks, and prints the aggregated results.\n    \"\"\"\n    # Define the test cases from the problem statement using double precision.\n    test_cases = [\n        # Case 1: well-conditioned, observable\n        (np.array([[0, 1], [-2, -3]], dtype=np.double), \n         np.array([[1, 0]], dtype=np.double)),\n        # Case 2: observable, scaled near underflow\n        (np.array([[0, 1], [-2, -3]], dtype=np.double), \n         1e-12 * np.array([[1, 0]], dtype=np.double)),\n        # Case 3: exactly unobservable\n        (np.array([[0, 1], [0, 0]], dtype=np.double), \n         np.array([[0, 1]], dtype=np.double)),\n        # Case 4: dimension 3, observable companion form\n        (np.array([[0, 1, 0], [0, 0, 1], [-1, -1, -1]], dtype=np.double), \n         np.array([[1, 0, 0]], dtype=np.double)),\n    ]\n\n    all_results = []\n    for A, C in test_cases:\n        results = check_observability(A, C)\n        all_results.extend(results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2735971"}]}