{"hands_on_practices": [{"introduction": "The most fundamental way to understand marginal stability is to connect a system's eigenvalues directly to the long-term behavior of its state trajectories. This practice provides a direct, hands-on path to do just that. Starting from a desired set of eigenvalues $\\{0, \\pm \\mathrm{j}\\}$, you will construct the system matrix $A$ and derive its state-transition matrix $e^{At}$ from first principles, culminating in a rigorous proof of marginal stability. [@problem_id:2723355]", "problem": "Consider the continuous-time linear time-invariant (LTI) system $\\dot{x}(t)=A x(t)$ where $A \\in \\mathbb{R}^{3 \\times 3}$. Starting from the definitions of the matrix exponential and marginal stability for LTI systems, do the following:\n\n1) Construct explicitly a real matrix $A$ whose spectrum is $\\{0,\\pm \\mathrm{j}\\}$, where $\\mathrm{j}^{2}=-1$, with each eigenvalue having geometric multiplicity equal to its algebraic multiplicity.\n\n2) Using only fundamental definitions such as the power-series definition of the matrix exponential and basic linear algebra, obtain a closed-form expression for $e^{A t}$.\n\n3) Prove rigorously that all trajectories $x(t)=e^{A t} x(0)$ are bounded for all $t \\ge 0$ while the system is not asymptotically stable, thus establishing marginal stability. Your argument must not rely on unproved “shortcut” criteria; base it on the spectral properties of $A$ and the explicit form of $e^{A t}$.\n\n4) Compute the induced spectral norm $\\|e^{A t}\\|_{2}$ as an explicit function of $t \\ge 0$, and then determine the exact value of $\\sup_{t \\ge 0} \\|e^{A t}\\|_{2}$.\n\nProvide as your final answer only the single real number equal to $\\sup_{t \\ge 0} \\|e^{A t}\\|_{2}$ (no units and no rounding are required).", "solution": "The problem statement is evaluated and found to be valid. It is self-contained, scientifically grounded in the principles of linear systems theory, and mathematically well-posed. No contradictions, ambiguities, or factual unsoundness are present. We may therefore proceed with a rigorous solution.\n\nThe problem requires a four-part solution, which we address in sequence.\n\n1) Construction of the matrix $A$.\nWe are tasked with constructing a real matrix $A \\in \\mathbb{R}^{3 \\times 3}$ with the spectrum $\\sigma(A) = \\{0, \\mathrm{j}, -\\mathrm{j}\\}$, where $\\mathrm{j}^{2}=-1$. The algebraic multiplicity of each eigenvalue is $1$. The geometric multiplicity of any eigenvalue must be at least $1$ and cannot exceed its algebraic multiplicity. Therefore, the condition that geometric multiplicity equals algebraic multiplicity is automatically satisfied, as it must be $1$ for all three distinct eigenvalues. This implies that the matrix $A$ is diagonalizable over the field of complex numbers $\\mathbb{C}$.\n\nFor a real matrix to have complex eigenvalues, they must appear in conjugate pairs, which is the case for $\\pm\\mathrm{j}$. The standard approach for constructing such a real matrix is to use the real Jordan normal form. The real eigenvalue $\\lambda=0$ corresponds to a $1 \\times 1$ block $[0]$. A complex conjugate pair of eigenvalues $\\alpha \\pm \\mathrm{j}\\beta$ (here, $\\alpha=0, \\beta=1$) corresponds to a $2 \\times 2$ block of the form $\\begin{pmatrix} \\alpha & -\\beta \\\\ \\beta & \\alpha \\end{pmatrix}$.\n\nThus, we construct $A$ as the following block-diagonal matrix:\n$$A = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & -1 \\\\ 0 & 1 & 0 \\end{pmatrix}$$\nThis matrix is clearly real. Its characteristic polynomial is $\\det(\\lambda I - A) = \\det \\begin{pmatrix} \\lambda & 0 & 0 \\\\ 0 & \\lambda & 1 \\\\ 0 & -1 & \\lambda \\end{pmatrix} = \\lambda(\\lambda^2 + 1)$, which has roots $\\lambda=0$, $\\lambda=\\mathrm{j}$, and $\\lambda=-\\mathrm{j}$. The construction is correct.\n\n2) Computation of the matrix exponential $e^{At}$.\nThe problem requires using the power-series definition: $e^{M} = \\sum_{k=0}^{\\infty} \\frac{M^k}{k!}$.\nSince $A$ is a block-diagonal matrix of the form $A = \\mathrm{diag}(A_1, A_2)$, its exponential is $e^{At} = \\mathrm{diag}(e^{A_1 t}, e^{A_2 t})$.\n\nFor the first block, $A_1 = [0]$, a $1 \\times 1$ zero matrix.\n$$e^{A_1 t} = e^{[0]t} = [e^0] = [1]$$\n\nFor the second block, $A_2 = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}$. We compute its powers:\n$A_2^0 = I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$\n$A_2^1 = A_2 = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}$\n$A_2^2 = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix} = -I_2$\n$A_2^3 = A_2 \\cdot A_2^2 = A_2(-I_2) = -A_2$\n$A_2^4 = (A_2^2)^2 = (-I_2)^2 = I_2$\nThe powers of $A_2$ cycle with a period of $4$: $\\{I_2, A_2, -I_2, -A_2, \\dots \\}$.\n\nNow we substitute these into the power series for $e^{A_2 t}$:\n$$ e^{A_2 t} = \\sum_{k=0}^{\\infty} \\frac{(A_2 t)^k}{k!} = I_2 + t A_2 + \\frac{t^2}{2!} A_2^2 + \\frac{t^3}{3!} A_2^3 + \\frac{t^4}{4!} A_2^4 + \\dots $$\n$$ e^{A_2 t} = I_2 + t A_2 - \\frac{t^2}{2!} I_2 - \\frac{t^3}{3!} A_2 + \\frac{t^4}{4!} I_2 + \\dots $$\nWe group terms multiplying $I_2$ and $A_2$:\n$$ e^{A_2 t} = \\left( 1 - \\frac{t^2}{2!} + \\frac{t^4}{4!} - \\dots \\right) I_2 + \\left( t - \\frac{t^3}{3!} + \\frac{t^5}{5!} - \\dots \\right) A_2 $$\nThese are precisely the Taylor series expansions for $\\cos(t)$ and $\\sin(t)$.\n$$ e^{A_2 t} = \\cos(t) I_2 + \\sin(t) A_2 = \\cos(t)\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} + \\sin(t)\\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} \\cos(t) & -\\sin(t) \\\\ \\sin(t) & \\cos(t) \\end{pmatrix} $$\nThis matrix is a standard rotation matrix.\n\nCombining the blocks, we obtain the closed-form expression for $e^{At}$:\n$$ e^{At} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(t) & -\\sin(t) \\\\ 0 & \\sin(t) & \\cos(t) \\end{pmatrix} $$\n\n3) Proof of marginal stability.\nA continuous-time LTI system is defined as marginally stable if its trajectories $x(t)$ are bounded for all $t \\ge 0$ for any initial condition $x(0)$, but the system is not asymptotically stable.\n\nFirst, we prove that all trajectories are bounded. The state trajectory is given by $x(t) = e^{At}x(0)$. We examine its squared Euclidean norm, $\\|x(t)\\|_2^2$.\n$$ \\|x(t)\\|_2^2 = \\|e^{At}x(0)\\|_2^2 = (e^{At}x(0))^T(e^{At}x(0)) = x(0)^T (e^{At})^T e^{At} x(0) $$\nLet us examine the matrix product $(e^{At})^T e^{At}$.\n$$ (e^{At})^T = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(t) & \\sin(t) \\\\ 0 & -\\sin(t) & \\cos(t) \\end{pmatrix} $$\n$$ (e^{At})^T e^{At} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(t) & \\sin(t) \\\\ 0 & -\\sin(t) & \\cos(t) \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(t) & -\\sin(t) \\\\ 0 & \\sin(t) & \\cos(t) \\end{pmatrix} $$\n$$ = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\cos^2(t) + \\sin^2(t) & -\\cos(t)\\sin(t) + \\sin(t)\\cos(t) \\\\ 0 & -\\sin(t)\\cos(t) + \\cos(t)\\sin(t) & \\sin^2(t) + \\cos^2(t) \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = I_3 $$\nSince $(e^{At})^T e^{At} = I_3$, the matrix $e^{At}$ is an orthogonal matrix for all $t \\in \\mathbb{R}$. Orthogonal transformations preserve the Euclidean norm. Therefore,\n$$ \\|x(t)\\|_2^2 = x(0)^T I_3 x(0) = \\|x(0)\\|_2^2 $$\nThis implies $\\|x(t)\\|_2 = \\|x(0)\\|_2$ for all $t \\ge 0$. For any finite initial state $x(0)$, the norm of the trajectory is constant, and thus bounded.\n\nNext, we show the system is not asymptotically stable. Asymptotic stability requires that $\\lim_{t \\to \\infty} x(t) = 0$ for all $x(0)$. We can find a counterexample. Let $x(0) = (1, 0, 0)^T$. Then\n$$ x(t) = e^{At}x(0) = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(t) & -\\sin(t) \\\\ 0 & \\sin(t) & \\cos(t) \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nIn this case, $\\lim_{t \\to \\infty} x(t) = (1, 0, 0)^T \\neq 0$. Thus, the system is not asymptotically stable.\nSince all trajectories are bounded and the system is not asymptotically stable, it is marginally stable by definition. This argument is based on the explicit form of $e^{At}$ as required.\n\n4) Computation of $\\|e^{At}\\|_2$ and its supremum.\nThe induced $2$-norm (or spectral norm) of a matrix $M$, denoted $\\|M\\|_2$, is its largest singular value, $\\sigma_{\\max}(M)$. The singular values are the square roots of the eigenvalues of $M^T M$.\n\nIn the previous step, we proved that for our matrix $E(t) = e^{At}$, we have $E(t)^T E(t) = I_3$.\nThe eigenvalues of the identity matrix $I_3$ are all equal to $1$.\nThe singular values of $e^{At}$ are the square roots of these eigenvalues, so $\\sigma_1 = \\sigma_2 = \\sigma_3 = \\sqrt{1} = 1$.\nThe largest singular value is $\\sigma_{\\max}(e^{At}) = 1$.\nTherefore, the induced spectral norm is an explicit function of $t \\ge 0$:\n$$ \\|e^{At}\\|_2 = 1 $$\nThis is a constant function.\n\nFinally, we must determine the exact value of $\\sup_{t \\ge 0} \\|e^{At}\\|_2$.\n$$ \\sup_{t \\ge 0} \\|e^{At}\\|_2 = \\sup_{t \\ge 0} (1) = 1 $$\nThe supremum of a constant function is the constant itself.", "answer": "$$\\boxed{1}$$", "id": "2723355"}, {"introduction": "While analyzing the state-transition matrix is foundational, it is often more practical to determine stability directly from a system's characteristic polynomial. This exercise demonstrates the power of the Routh-Hurwitz criterion, a classic algebraic tool for locating the roots of a polynomial relative to the imaginary axis. You will use this method to find the precise parameter values that place a system on the boundary of stability, a state of marginal stability. [@problem_id:2723314]", "problem": "Consider a real-coefficient characteristic polynomial $p(s)$ of even degree $n \\geq 2$. Starting from the definition of marginal stability (all roots in the closed left half-plane with at least one root on the imaginary axis and no repeated roots on the imaginary axis) and the statement of the Routh–Hurwitz criterion, derive necessary and sufficient conditions under which $p(s)$ has exactly one simple conjugate pair of roots on the imaginary axis and all remaining roots in the open left half-plane. Your derivation must begin from the following foundational facts: (i) the number of roots of $p(s)$ in the open right half-plane equals the number of sign changes in the first column of the Routh array (counted with multiplicity) when interpreted via the standard limiting procedure, and (ii) when a row of zeros occurs in the Routh array, an auxiliary polynomial is formed from the immediately preceding nonzero row whose roots characterize imaginary-axis roots.\n\nThen apply your derived conditions to the fourth-degree polynomial\n$$\np(s) \\;=\\; s^{4} \\;+\\; 2 s^{3} \\;+\\; 3 s^{2} \\;+\\; 2 k s \\;+\\; 1,\n$$\nwhere $k \\in \\mathbb{R}$ is a real parameter. Determine all real values of $k$ for which the closed-loop system is marginally stable with exactly one simple conjugate pair of imaginary-axis roots and all remaining roots in the open left half-plane.\n\nExpress your final answer as exact radicals, with entries ordered from smaller to larger, in the row-matrix form specified in the answer formatting rules. No numerical approximation or rounding is required. No units are needed.", "solution": "The problem statement poses a well-defined question in the field of control theory, specifically concerning the stability analysis of a linear time-invariant system using the Routh-Hurwitz criterion. The problem is scientifically grounded, self-contained, and objective. It contains no logical contradictions, unspecified parameters, or violations of established principles. Therefore, the problem is deemed valid and a formal solution will be derived.\n\nFirst, we establish the necessary and sufficient conditions for a real-coefficient polynomial $p(s)$ of even degree $n \\ge 2$ to have exactly one simple conjugate pair of roots on the imaginary axis and all other roots in the open left-half plane (LHP).\n\nAccording to the Routh-Hurwitz criterion, the presence of roots on the imaginary axis is indicated by an entire row of the Routh array becoming zero. The roots on the imaginary axis are the roots of the auxiliary polynomial, $A(s)$, which is formed from the coefficients of the row immediately preceding the row of zeros. The auxiliary polynomial is always an even polynomial.\n\nFor the system to have exactly one simple conjugate pair of imaginary roots, say $s = \\pm j\\omega_{0}$ with $\\omega_{0} > 0$, the auxiliary polynomial $A(s)$ must be of degree $2$. If $A(s)$ were of a higher even degree (e.g., $4$, $6$, ...), it would have multiple pairs of roots, which are symmetric with respect to the origin. This would lead to either more than one pair of imaginary roots or repeated imaginary roots, both of which are disallowed by the problem statement.\n\nFor $A(s)$ to be of degree $2$, the row of zeros must be the $s^{1}$ row. Consequently, the auxiliary polynomial is formed from the coefficients of the $s^{2}$ row. Let the $s^{2}$ row be $[c_{1}, c_{2}]$. The auxiliary polynomial is $A(s) = c_{1}s^{2} + c_{2}$. For the roots of $A(s)$ to be a simple, non-zero conjugate pair on the imaginary axis, we require $s^{2} = -c_{2}/c_{1} < 0$, which implies that $c_{1}$ and $c_{2}$ must be non-zero and possess the same sign.\n\nFor all other $n-2$ roots to be in the open LHP, the Routh array must exhibit no sign changes in its first column. Assuming the leading coefficient of $p(s)$ is positive, all elements in the first column must be positive. When the $s^{1}$ row is zero, it is replaced by the coefficients of the derivative of the auxiliary polynomial, $A'(s) = 2c_{1}s$. The new $s^{1}$ row becomes $[2c_{1}, 0]$. The subsequent element in the first column, in the $s^{0}$ row, is calculated to be $c_{2}$. Thus, for the absence of sign changes, it is necessary that all elements in the first column, including $c_{1}$ and $c_{2}$, are strictly positive.\n\nIn summary, the conditions are:\n$1$. The single element in the $s^{1}$ row of the Routh array, calculated in the standard manner, must equal zero. This determines the critical value(s) of any system parameter.\n$2$. For these parameter value(s), all other elements in the first column of the array must be strictly positive. This includes the coefficients of the auxiliary polynomial from the $s^{2}$ row.\n\nWe now apply these conditions to the given polynomial:\n$$p(s) = s^{4} + 2 s^{3} + 3 s^{2} + 2 k s + 1$$\nThe coefficients are $a_{4}=1$, $a_{3}=2$, $a_{2}=3$, $a_{1}=2k$, and $a_{0}=1$.\nThe Routh array is constructed as follows:\n$$\n\\begin{array}{c|ccc}\ns^{4} & 1 & 3 & 1 \\\\\ns^{3} & 2 & 2k & \\\\\ns^{2} & c_{1} & c_{2} & \\\\\ns^{1} & d_{1} & & \\\\\ns^{0} & e_{1} & &\n\\end{array}\n$$\nThe coefficients are calculated:\n$$c_{1} = \\frac{(2)(3) - (1)(2k)}{2} = 3-k$$\n$$c_{2} = \\frac{(2)(1) - (1)(0)}{2} = 1$$\nThus, the $s^{2}$ row is $[3-k, 1]$. For stability, we require $c_{1} = 3-k > 0$, or $k < 3$. We also require $c_{2} = 1 > 0$, which is always true.\n\nNext, we calculate $d_{1}$:\n$$d_{1} = \\frac{c_{1}(2k) - (2)c_{2}}{c_{1}} = \\frac{(3-k)(2k) - (2)(1)}{3-k} = \\frac{-2k^{2} + 6k - 2}{3-k}$$\nFor the $s^{1}$ row to be a row of zeros, we must have $d_{1}=0$. This is true if the numerator is zero, provided the denominator is non-zero (which we have already required by $k<3$):\n$$-2k^{2} + 6k - 2 = 0$$\n$$k^{2} - 3k + 1 = 0$$\nSolving this quadratic equation for $k$ using the quadratic formula, $k = \\frac{-b \\pm \\sqrt{b^{2}-4ac}}{2a}$:\n$$k = \\frac{3 \\pm \\sqrt{(-3)^{2} - 4(1)(1)}}{2(1)} = \\frac{3 \\pm \\sqrt{9 - 4}}{2} = \\frac{3 \\pm \\sqrt{5}}{2}$$\nThis yields two possible values for $k$:\n$$k_{1} = \\frac{3 - \\sqrt{5}}{2} \\quad \\text{and} \\quad k_{2} = \\frac{3 + \\sqrt{5}}{2}$$\nNow, we must verify that these values of $k$ satisfy the stability requirement for the other roots, which is that all other first-column Routh elements are positive. The elements are $1$, $2$, $c_{1} = 3-k$, and $e_{1}=c_{2}=1$. The only condition to check is $3-k > 0$, i.e., $k<3$.\n\nFor $k_{1} = \\frac{3 - \\sqrt{5}}{2}$:\nSince $\\sqrt{5} > 0$, we have $3 - \\sqrt{5} < 3$, so $\\frac{3 - \\sqrt{5}}{2} < \\frac{3}{2}$. Thus, $k_{1} < 3$. The condition is satisfied.\nThe first column of the Routh array is $[1, 2, 3 - \\frac{3-\\sqrt{5}}{2}, 0, 1] = [1, 2, \\frac{3+\\sqrt{5}}{2}, 0, 1]$. All non-zero elements are positive.\n\nFor $k_{2} = \\frac{3 + \\sqrt{5}}{2}$:\nSince $\\sqrt{5} \\approx 2.236$, we have $k_{2} \\approx \\frac{3+2.236}{2} = 2.618$. This value is less than $3$. The condition $k_{2} < 3$ is satisfied.\nThe first column becomes $[1, 2, 3 - \\frac{3+\\sqrt{5}}{2}, 0, 1] = [1, 2, \\frac{3-\\sqrt{5}}{2}, 0, 1]$. Since $\\sqrt{5} < 3$, all non-zero elements are positive.\n\nBoth values of $k$ result in a Routh array with a single zero row at the $s^{1}$ position and an otherwise positive first column. This signifies marginal stability with one pair of imaginary roots given by the auxiliary polynomial $A(s) = (3-k)s^{2} + 1 = 0$, and all other roots in the LHP. The imaginary roots are $s = \\pm j\\sqrt{\\frac{1}{3-k}}$.\nSince both values satisfy all necessary and sufficient conditions, they are both solutions. Ordering them from smaller to larger, we have $\\frac{3-\\sqrt{5}}{2}$ followed by $\\frac{3+\\sqrt{5}}{2}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3-\\sqrt{5}}{2} & \\frac{3+\\sqrt{5}}{2}\n\\end{pmatrix}\n}\n$$", "id": "2723314"}, {"introduction": "A common point of confusion in stability analysis arises with repeated eigenvalues on the stability boundary (the imaginary axis or the unit circle). This exercise tackles this critical subtlety by examining a discrete-time system with a repeated eigenvalue at $z=1$. You will see how the presence of a non-trivial Jordan block, which is not apparent from the eigenvalues alone, leads to unbounded growth and instability, clarifying why eigenvalues on the stability boundary must be semi-simple for marginal stability to hold. [@problem_id:2723345]", "problem": "Consider the discrete-time linear time-invariant (LTI) system defined by $x_{k+1} = A x_k$, where $A \\in \\mathbb{R}^{3 \\times 3}$ is the controllable companion matrix associated with the monic characteristic polynomial $(z-1)^2(z-0.5)$. Expand the polynomial to determine the explicit $A$. Starting from the foundational definitions of the spectral radius, minimal polynomial, Jordan normal form, and the behavior of powers of Jordan blocks, analyze the asymptotic behavior of $A^k$ as $k \\to \\infty$.\n\nDefine the polynomial growth degree $d$ of $\\lVert A^k \\rVert$ (for any induced matrix norm) to be the unique nonnegative integer such that there exist positive constants $c_1$ and $c_2$ for which $c_1 k^d \\le \\lVert A^k \\rVert \\le c_2 k^d$ holds for all sufficiently large $k$, in the case where the spectral radius is $1$ and all eigenvalues satisfy $|\\lambda| \\le 1$. Using only first principles and well-tested facts (not shortcut formulas), derive $d$ for this $A$ and use your result to explain, in terms of the eigenstructure, why the system is not marginally stable.\n\nReport as your final answer the integer value of $d$. No rounding is required. The final answer must be given as a single integer without units.", "solution": "The problem as stated is subjected to validation.\n\n**Step 1: Extract Givens**\n- System: Discrete-time linear time-invariant (LTI) system $x_{k+1} = A x_k$.\n- Matrix $A$: $A \\in \\mathbb{R}^{3 \\times 3}$.\n- Matrix Type: Controllable companion matrix.\n- Characteristic Polynomial: $p(z) = (z-1)^2(z-0.5)$.\n- Definition: The polynomial growth degree $d$ of $\\lVert A^k \\rVert$ is the unique nonnegative integer such that $c_1 k^d \\le \\lVert A^k \\rVert \\le c_2 k^d$ for positive constants $c_1, c_2$ and sufficiently large $k$, under specified conditions.\n- Task: Derive $d$ from first principles and explain why the system is not marginally stable.\n- Final Answer: The integer value of $d$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded within the fields of linear algebra and control theory. The concepts of companion matrices, characteristic polynomials, Jordan normal forms, and system stability are standard and well-defined. The problem is self-contained, with the characteristic polynomial providing sufficient information to determine the eigenstructure of matrix $A$. The tasks are logically structured and lead to a unique, well-defined integer solution for $d$. The problem is objective and free of ambiguity. It is not trivial, as it requires a step-by-step derivation from foundational principles rather than the application of a memorized formula.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A complete, reasoned solution will be provided.\n\nWe begin by determining the explicit form of the matrix $A$. The characteristic polynomial is given as $p(z) = (z-1)^2(z-0.5)$. We expand this polynomial to find its coefficients:\n$$p(z) = (z^2 - 2z + 1)(z - 0.5)$$\n$$p(z) = z^3 - 0.5z^2 - 2z^2 + z + z - 0.5$$\n$$p(z) = z^3 - 2.5z^2 + 2z - 0.5$$\nThis is a monic polynomial of the form $p(z) = z^3 + a_2 z^2 + a_1 z + a_0$, with coefficients $a_2 = -2.5$, $a_1 = 2$, and $a_0 = -0.5$. The controllable companion matrix associated with this polynomial is:\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n-a_0 & -a_1 & -a_2\n\\end{pmatrix}\n= \\begin{pmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0.5 & -2 & 2.5\n\\end{pmatrix}\n$$\nThe eigenvalues of $A$ are the roots of its characteristic polynomial, which are $\\lambda_1 = 1$ with algebraic multiplicity $2$, and $\\lambda_2 = 0.5$ with algebraic multiplicity $1$. The spectral radius is $\\rho(A) = \\max\\{|1|, |0.5|\\} = 1$.\n\nThe structure of the Jordan normal form $J$ of $A$ is determined by the minimal polynomial $m(z)$ of $A$. A fundamental property of a controllable companion matrix is that its minimal polynomial is identical to its characteristic polynomial. Therefore, $m(z) = p(z) = (z-1)^2(z-0.5)$.\n\nThe factors of the minimal polynomial determine the sizes of the Jordan blocks.\n1. The factor $(z-1)^2$ implies that the largest Jordan block associated with the eigenvalue $\\lambda=1$ is of size $2 \\times 2$. Since the algebraic multiplicity of $\\lambda=1$ is $2$, there must be a single Jordan block of this size:\n$$J_1 = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$$\n2. The factor $(z-0.5)^1$ implies that the Jordan block associated with the eigenvalue $\\lambda=0.5$ is of size $1 \\times 1$:\n$$J_{0.5} = \\begin{pmatrix} 0.5 \\end{pmatrix}$$\nThus, the Jordan normal form of $A$ is $J = \\text{diag}(J_1, J_{0.5})$, up to permutation of blocks. There exists an invertible matrix $P$ such that $A = PJP^{-1}$.\n\nTo analyze the asymptotic behavior of $A^k$, we examine $A^k = (PJP^{-1})^k = P J^k P^{-1}$. The matrix $J^k$ is also block diagonal: $J^k = \\text{diag}(J_1^k, J_{0.5}^k)$.\n- For the block $J_{0.5}$, the power is simply $J_{0.5}^k = \\begin{pmatrix} 0.5^k \\end{pmatrix}$. As $k \\to \\infty$, this term decays to $0$.\n- For the block $J_1$, we compute its $k$-th power. Let $J_1 = I + N$, where $I$ is the $2 \\times 2$ identity matrix and $N = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$. The matrix $N$ is nilpotent with $N^2 = 0$. Using the binomial theorem, which is applicable since $I$ and $N$ commute:\n$$J_1^k = (I+N)^k = \\binom{k}{0}I^k N^0 + \\binom{k}{1}I^{k-1}N^1 + \\binom{k}{2}I^{k-2}N^2 + \\dots$$\nSince $N^m = 0$ for $m \\ge 2$, all terms from the third onward are zero.\n$$J_1^k = 1 \\cdot I \\cdot I + k \\cdot I \\cdot N = I + kN = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} + k \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & k \\\\ 0 & 1 \\end{pmatrix}$$\nCombining the blocks, we have:\n$$J^k = \\begin{pmatrix} 1 & k & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0.5^k \\end{pmatrix}$$\nThe behavior of $\\lVert A^k \\rVert$ is tied to the behavior of $\\lVert J^k \\rVert$. For any induced matrix norm, the property $\\lVert XY \\rVert \\le \\lVert X \\rVert \\lVert Y \\rVert$ and the fact that all norms on a finite-dimensional space are equivalent imply that there exist positive constants $\\tilde{c}_1, \\tilde{c}_2$ such that for all $k$:\n$$\\tilde{c}_1 \\lVert J^k \\rVert \\le \\lVert A^k \\rVert = \\lVert P J^k P^{-1} \\rVert \\le \\tilde{c}_2 \\lVert J^k \\rVert$$\nTherefore, $\\lVert A^k \\rVert$ and $\\lVert J^k \\rVert$ have the same order of polynomial growth. We examine the growth of $\\lVert J^k \\rVert$. For large $k$, the term $k$ is the fastest-growing element in the matrix $J^k$. The other elements are either constant ($1$) or decay to zero ($0.5^k$). For any matrix norm, the norm will be dominated by this linear term in $k$. For example, the infinity norm is $\\lVert J^k \\rVert_\\infty = \\max(|1|+|k|, |1|, |0.5^k|) = 1+k$. The Frobenius norm is $\\lVert J^k \\rVert_F = \\sqrt{1^2 + k^2 + 1^2 + (0.5^k)^2} = \\sqrt{k^2+2+0.25^k}$. For large $k$, both norms are asymptotically proportional to $k$. Thus, we can find positive constants $c'_1, c'_2$ such that for sufficiently large $k$:\n$$c'_1 k^1 \\le \\lVert J^k \\rVert \\le c'_2 k^1$$\nCombining this with our earlier inequality, we conclude there exist positive constants $c_1 = \\tilde{c}_1 c'_1$ and $c_2 = \\tilde{c}_2 c'_2$ such that for sufficiently large $k$:\n$$c_1 k^1 \\le \\lVert A^k \\rVert \\le c_2 k^1$$\nBy comparison with the definition of the polynomial growth degree $d$, we identify $d=1$. The growth is linear. This value $d=m_{\\max}-1$, where $m_{\\max}=2$ is the size of the largest Jordan block for an eigenvalue with magnitude $1$.\n\nFinally, we analyze the system's stability. A discrete-time LTI system is marginally stable if and only if $\\sup_{k \\ge 0} \\lVert A^k \\rVert < \\infty$. In our case, $\\lVert A^k \\rVert$ grows approximately linearly with $k$, so $\\lim_{k \\to \\infty} \\lVert A^k \\rVert = \\infty$. The norm is unbounded. Therefore, the system is not marginally stable; it is unstable. The fundamental reason for this instability, rooted in the eigenstructure of $A$, is the presence of a Jordan block of size greater than $1$ (specifically, size $2$) for an eigenvalue on the unit circle ($\\lambda=1$). For marginal stability, any eigenvalue $\\lambda$ on the unit circle ($|\\lambda|=1$) must be semi-simple, meaning its algebraic and geometric multiplicities must be equal, which is equivalent to stating that all its Jordan blocks must be of size $1 \\times 1$. This condition is violated here for $\\lambda=1$.\nThe final answer is the integer value of $d$.", "answer": "$$\\boxed{1}$$", "id": "2723345"}]}