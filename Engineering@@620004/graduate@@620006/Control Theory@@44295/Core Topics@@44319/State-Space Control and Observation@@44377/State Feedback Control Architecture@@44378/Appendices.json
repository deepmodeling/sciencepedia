{"hands_on_practices": [{"introduction": "State feedback control rests on the principle of pole placement, which allows a designer to reshape a system's dynamic response by assigning desired locations for the closed-loop eigenvalues. This exercise provides fundamental practice in this technique by tasking you with calculating the state feedback gain $K$ for a system in controllable canonical form. By matching the coefficients of the closed-loop characteristic polynomial with those of a target polynomial, you will gain direct insight into the algebraic mechanism that makes pole placement possible, including the proper handling of complex conjugate poles to ensure a real-valued controller [@problem_id:2748492].", "problem": "Consider the real, single-input single-output (SISO) linear time-invariant (LTI) system in controllable canonical form\n$$\n\\dot{x} = A x + B u,\\quad y = C x,\n$$\nwith state feedback input of the form\n$$\nu = -K x,\n$$\nwhere\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\\\\\n-1 & -4 & -6 & -4\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0\\\\\n0\\\\\n0\\\\\n1\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1 & 0 & 0 & 0\n\\end{pmatrix},\n$$\nand the gain row vector is\n$$\nK = \\begin{pmatrix}\nk_{1} & k_{2} & k_{3} & k_{4}\n\\end{pmatrix}.\n$$\nStarting only from the definition of the characteristic polynomial and the determinant, reformulate the pole-placement conditions for complex conjugate targets in a purely real-valued way to ensure that the resulting gain $K$ is real. Specifically, place the closed-loop poles at the complex conjugate pair\n$$\n-2 \\pm 3\\,\\mathrm{j},\n$$\nwhere $\\mathrm{j}$ denotes the imaginary unit with $\\mathrm{j}^{2} = -1$, together with the real poles\n$$\n-4,\\quad -5.\n$$\nDerive a real-valued system of equations for the unknowns $k_{1},k_{2},k_{3},k_{4}$ by equating the characteristic polynomial of the closed-loop matrix to the real-coefficient target polynomial obtained from these poles, and solve this system to obtain the unique real gain $K$ that achieves the desired pole placement. Provide your final answer as a single row matrix. No rounding is required, and no units are involved.", "solution": "The problem statement has been validated and is deemed a valid, well-posed problem in linear control theory. It is self-contained, scientifically grounded, and provides all necessary information to find a unique solution.\n\nThe dynamics of the closed-loop system are described by the state equation $\\dot{x} = A_{cl}x$, where the control input is the state feedback law $u = -Kx$. The closed-loop system matrix $A_{cl}$ is given by $A - BK$.\n\nGiven the system matrices\n$$\nA = \\begin{pmatrix}\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\\\\\n-1 & -4 & -6 & -4\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0\\\\\n0\\\\\n0\\\\\n1\n\\end{pmatrix}\n$$\nand the gain row vector\n$$\nK = \\begin{pmatrix}\nk_{1} & k_{2} & k_{3} & k_{4}\n\\end{pmatrix},\n$$\nthe product $BK$ is calculated as\n$$\nBK = \\begin{pmatrix}\n0\\\\\n0\\\\\n0\\\\\n1\n\\end{pmatrix}\n\\begin{pmatrix}\nk_{1} & k_{2} & k_{3} & k_{4}\n\\end{pmatrix}\n= \\begin{pmatrix}\n0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0\\\\\n0 & 0 & 0 & 0\\\\\nk_{1} & k_{2} & k_{3} & k_{4}\n\\end{pmatrix}.\n$$\nThe closed-loop matrix $A_{cl} = A - BK$ is therefore\n$$\nA_{cl} = \\begin{pmatrix}\n0 & 1 & 0 & 0\\\\\n0 & 0 & 1 & 0\\\\\n0 & 0 & 0 & 1\\\\\n-1 - k_{1} & -4 - k_{2} & -6 - k_{3} & -4 - k_{4}\n\\end{pmatrix}.\n$$\nThe poles of the closed-loop system are the eigenvalues of $A_{cl}$, which are the roots of the characteristic polynomial $P_{cl}(\\lambda) = \\det(\\lambda I - A_{cl})$.\n$$\n\\lambda I - A_{cl} = \\begin{pmatrix}\n\\lambda & -1 & 0 & 0\\\\\n0 & \\lambda & -1 & 0\\\\\n0 & 0 & \\lambda & -1\\\\\n1 + k_{1} & 4 + k_{2} & 6 + k_{3} & \\lambda + 4 + k_{4}\n\\end{pmatrix}.\n$$\nThe determinant is computed by cofactor expansion along the first column. This is a standard procedure for a companion matrix form.\n\\begin{align*}\nP_{cl}(\\lambda) &= \\lambda \\cdot \\det \\begin{pmatrix} \\lambda & -1 & 0 \\\\ 0 & \\lambda & -1 \\\\ 4 + k_{2} & 6 + k_{3} & \\lambda + 4 + k_{4} \\end{pmatrix} - (-(1+k_1)) \\cdot \\det \\begin{pmatrix} -1 & 0 & 0 \\\\ \\lambda & -1 & 0 \\\\ 0 & \\lambda & -1 \\end{pmatrix} \\\\\n&= \\lambda \\left[ \\lambda \\det \\begin{pmatrix} \\lambda & -1 \\\\ 6 + k_{3} & \\lambda + 4 + k_{4} \\end{pmatrix} + 1 \\cdot \\det \\begin{pmatrix} 0 & -1 \\\\ 4 + k_{2} & \\lambda + 4 + k_{4} \\end{pmatrix} \\right] + (1 + k_{1})(-1) \\\\\n&= \\lambda \\left[ \\lambda \\left( \\lambda(\\lambda + 4 + k_{4}) + (6 + k_{3}) \\right) + (4 + k_{2}) \\right] + (1 + k_{1}) \\\\\n&= \\lambda \\left[ \\lambda \\left( \\lambda^2 + (4 + k_{4})\\lambda + 6 + k_{3} \\right) + (4 + k_{2}) \\right] + (1 + k_{1}) \\\\\n&= \\lambda \\left[ \\lambda^3 + (4 + k_{4})\\lambda^2 + (6 + k_{3})\\lambda + (4 + k_{2}) \\right] + (1 + k_{1}) \\\\\n&= \\lambda^{4} + (4 + k_{4})\\lambda^{3} + (6 + k_{3})\\lambda^{2} + (4 + k_{2})\\lambda + (1 + k_{1}).\n\\end{align*}\nThe calculation in the original solution had a sign error in the determinant expansion but fortuitously arrived at the correct polynomial. The correct expansion is shown above. For a controllable canonical matrix, the characteristic polynomial coefficients are directly read from the last row, yielding the same result.\n\nNext, we construct the target characteristic polynomial, $P_{target}(\\lambda)$, from the desired pole locations. The desired poles are given as the complex conjugate pair $-2 \\pm 3\\mathrm{j}$ and the real poles $-4$ and $-5$. The target polynomial is the product of the corresponding factors $(\\lambda - p_{i})$. To ensure the resulting polynomial has real coefficients, we group the complex conjugate factors:\n$$\nP_{target}(\\lambda) = (\\lambda - (-2 + 3\\mathrm{j}))(\\lambda - (-2 - 3\\mathrm{j}))(\\lambda - (-4))(\\lambda - (-5)).\n$$\nThe product of the complex conjugate factors is\n$$\n((\\lambda + 2) - 3\\mathrm{j})((\\lambda + 2) + 3\\mathrm{j}) = (\\lambda+2)^{2} - (3\\mathrm{j})^{2} = \\lambda^{2} + 4\\lambda + 4 - 9\\mathrm{j}^{2} = \\lambda^{2} + 4\\lambda + 13.\n$$\nThe product of the real factors is\n$$\n(\\lambda + 4)(\\lambda + 5) = \\lambda^{2} + 9\\lambda + 20.\n$$\nNow, we multiply these two quadratic polynomials to obtain the final target polynomial:\n\\begin{align*}\nP_{target}(\\lambda) &= (\\lambda^{2} + 4\\lambda + 13)(\\lambda^{2} + 9\\lambda + 20) \\\\\n&= \\lambda^{2}(\\lambda^{2} + 9\\lambda + 20) + 4\\lambda(\\lambda^{2} + 9\\lambda + 20) + 13(\\lambda^{2} + 9\\lambda + 20) \\\\\n&= (\\lambda^{4} + 9\\lambda^{3} + 20\\lambda^{2}) + (4\\lambda^{3} + 36\\lambda^{2} + 80\\lambda) + (13\\lambda^{2} + 117\\lambda + 260) \\\\\n&= \\lambda^{4} + (9+4)\\lambda^{3} + (20+36+13)\\lambda^{2} + (80+117)\\lambda + 260 \\\\\n&= \\lambda^{4} + 13\\lambda^{3} + 69\\lambda^{2} + 197\\lambda + 260.\n\\end{align*}\nFor the pole placement to be successful, the characteristic polynomial of the closed-loop system must be identical to the target characteristic polynomial, i.e., $P_{cl}(\\lambda) = P_{target}(\\lambda)$. By equating the coefficients of like powers of $\\lambda$, we obtain a real-valued system of linear equations for the gains $k_{1}, k_{2}, k_{3}, k_{4}$.\n$$\n\\lambda^{4} + (4 + k_{4})\\lambda^{3} + (6 + k_{3})\\lambda^{2} + (4 + k_{2})\\lambda + (1 + k_{1}) = \\lambda^{4} + 13\\lambda^{3} + 69\\lambda^{2} + 197\\lambda + 260.\n$$\nComparing coefficients:\n\\begin{itemize}\n    \\item Coefficient of $\\lambda^{3}$: $4 + k_{4} = 13 \\implies k_{4} = 13 - 4 = 9$.\n    \\item Coefficient of $\\lambda^{2}$: $6 + k_{3} = 69 \\implies k_{3} = 69 - 6 = 63$.\n    \\item Coefficient of $\\lambda^{1}$: $4 + k_{2} = 197 \\implies k_{2} = 197 - 4 = 193$.\n    \\item Coefficient of $\\lambda^{0}$: $1 + k_{1} = 260 \\implies k_{1} = 260 - 1 = 259$.\n\\end{itemize}\nThis system yields a unique solution for the real-valued gains. The resulting gain vector $K$ is\n$$\nK = \\begin{pmatrix}\n259 & 193 & 63 & 9\n\\end{pmatrix}.\n$$\nThis is the unique real gain matrix that places the closed-loop poles at the specified locations.", "answer": "$$\\boxed{\\begin{pmatrix} 259 & 193 & 63 & 9 \\end{pmatrix}}$$", "id": "2748492"}, {"introduction": "While pole placement stabilizes a system, practical controllers often need to eliminate steady-state errors caused by disturbances or modeling uncertainties, a task for which integral action is uniquely suited. This practice explores the integration of an integral controller into a state feedback architecture, requiring you to analyze its effect on stability [@problem_id:2748500]. Crucially, you will discover that for nonminimum-phase systems—those with right-half plane transmission zeros—aggressive integral action can lead to instability, revealing a fundamental trade-off between performance and stability in control design.", "problem": "Consider a Single-Input Single-Output (SISO) Linear Time-Invariant (LTI) plant with state-space realization\n$$\n\\dot{x} = A x + B u,\\quad y = C x,\n$$\nwhere\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ -2 & -2 \\end{pmatrix},\\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\\quad C = \\begin{pmatrix} 1 & -1 \\end{pmatrix}.\n$$\nThis plant has a Right Half-Plane (RHP) transmission zero. A state feedback control architecture with integral action for regulation (zero reference) is implemented by augmenting the plant with an integral state and using the control law\n$$\n\\dot{\\eta} = y,\\quad u = -K x - K_I \\eta,\n$$\nwhere $K \\in \\mathbb{R}^{1\\times 2}$ is a fixed state feedback gain and $K_I \\in \\mathbb{R}$ is the integral gain. Assume the fixed state feedback gain is\n$$\nK = \\begin{pmatrix} 4 & 4 \\end{pmatrix}.\n$$\nStarting from first principles (state-space definitions, transmission zero definition, and the Routh–Hurwitz stability criterion), do the following:\n\n- Using the transmission zero definition based on the system matrices, confirm that the plant has a RHP zero.\n- Construct the augmented closed-loop system and derive its characteristic polynomial as a function of $K_I$.\n- Use the Routh–Hurwitz stability criterion for polynomials to derive the necessary and sufficient conditions on $K_I$ for internal stability of the augmented closed-loop.\n- Based on these conditions, demonstrate that sufficiently aggressive integral action destabilizes the nonminimum-phase plant by violating the stability conditions, and compute the largest admissible value of $K_I$ that guarantees internal stability.\n\nProvide your final answer as the exact largest admissible value of $K_I$ (no rounding). The final answer must be a single real number.", "solution": "The problem statement is subjected to validation and is found to be scientifically grounded, well-posed, and self-contained. It presents a standard problem in linear control theory, for which a unique and meaningful solution exists. We will proceed with the analysis as requested.\n\nFirst, we must confirm that the plant has a Right Half-Plane (RHP) transmission zero. The transmission zeros $s$ of a system described by the matrices $(A, B, C, D)$ are the complex frequencies for which the system matrix\n$$\nP(s) = \\begin{pmatrix} sI - A & -B \\\\ C & D \\end{pmatrix}\n$$\nloses rank. For the given system, $A = \\begin{pmatrix} 0 & 1 \\\\ -2 & -2 \\end{pmatrix}$, $B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, $C = \\begin{pmatrix} 1 & -1 \\end{pmatrix}$, and $D=0$. The system matrix is\n$$\nP(s) = \\begin{pmatrix} s - 0 & -1 & -0 \\\\ -(-2) & s - (-2) & -1 \\\\ 1 & -1 & 0 \\end{pmatrix} = \\begin{pmatrix} s & -1 & 0 \\\\ 2 & s+2 & -1 \\\\ 1 & -1 & 0 \\end{pmatrix}.\n$$\nThe transmission zeros are the roots of $\\det(P(s)) = 0$. We compute the determinant by cofactor expansion along the third column:\n$$\n\\det(P(s)) = (0) \\cdot C_{13} + (-1) \\cdot (-1)^{2+3} \\det\\begin{pmatrix} s & -1 \\\\ 1 & -1 \\end{pmatrix} + (0) \\cdot C_{33} = (-1)(-1)(s(-1) - (-1)(1)) = -s + 1.\n$$\nSetting $\\det(P(s)) = 0$ gives $-s + 1 = 0$, which yields the transmission zero $s=1$. Since the real part of this zero is positive, it is located in the RHP, confirming that the plant is nonminimum-phase.\n\nNext, we construct the augmented closed-loop system. The state vector is augmented with the integral state $\\eta$, such that the new state vector is $x_{aug} = \\begin{pmatrix} x \\\\ \\eta \\end{pmatrix}$. The state dynamics are $\\dot{x} = Ax + Bu$ and the integral state dynamics are $\\dot{\\eta} = y = Cx$. The control law is $u = -Kx - K_I \\eta$. Substituting the control law into the state equations yields the closed-loop system:\n$$\n\\begin{pmatrix} \\dot{x} \\\\ \\dot{\\eta} \\end{pmatrix} = \\begin{pmatrix} A & 0 \\\\ C & 0 \\end{pmatrix} \\begin{pmatrix} x \\\\ \\eta \\end{pmatrix} + \\begin{pmatrix} B \\\\ 0 \\end{pmatrix} u = \\begin{pmatrix} A & 0 \\\\ C & 0 \\end{pmatrix} \\begin{pmatrix} x \\\\ \\eta \\end{pmatrix} + \\begin{pmatrix} B \\\\ 0 \\end{pmatrix} (-Kx - K_I \\eta).\n$$\nThis can be written in the form $\\dot{x}_{aug} = A_{cl} x_{aug}$, where the closed-loop matrix $A_{cl}$ is\n$$\nA_{cl} = \\begin{pmatrix} A - BK & -BK_I \\\\ C & 0 \\end{pmatrix}.\n$$\nWe substitute the given matrices $A$, $B$, $C$, and the fixed gain $K = \\begin{pmatrix} 4 & 4 \\end{pmatrix}$:\n$$\nBK = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 4 & 4 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 4 & 4 \\end{pmatrix}.\n$$\n$$\nA - BK = \\begin{pmatrix} 0 & 1 \\\\ -2 & -2 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 4 & 4 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ -6 & -6 \\end{pmatrix}.\n$$\n$$\n-BK_I = -\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} K_I = \\begin{pmatrix} 0 \\\\ -K_I \\end{pmatrix}.\n$$\nThe complete closed-loop matrix $A_{cl}$ is a $3 \\times 3$ matrix:\n$$\nA_{cl} = \\begin{pmatrix} 0 & 1 & 0 \\\\ -6 & -6 & -K_I \\\\ 1 & -1 & 0 \\end{pmatrix}.\n$$\nThe internal stability of the system is determined by the eigenvalues of $A_{cl}$, which are the roots of the characteristic polynomial $p(s) = \\det(sI - A_{cl})$.\n$$\nsI - A_{cl} = \\begin{pmatrix} s & -1 & 0 \\\\ 6 & s+6 & K_I \\\\ -1 & 1 & s \\end{pmatrix}.\n$$\nThe determinant is calculated as:\n$$\np(s) = s \\det \\begin{pmatrix} s+6 & K_I \\\\ 1 & s \\end{pmatrix} - (-1) \\det \\begin{pmatrix} 6 & K_I \\\\ -1 & s \\end{pmatrix} = s(s(s+6) - K_I) + (6s - (-K_I))\n$$\n$$\np(s) = s(s^{2} + 6s - K_I) + 6s + K_I = s^{3} + 6s^{2} - sK_I + 6s + K_I.\n$$\nThe characteristic polynomial as a function of $K_I$ is:\n$$\np(s) = s^{3} + 6s^{2} + (6 - K_I)s + K_I.\n$$\nTo determine the conditions on $K_I$ for stability, we apply the Routh-Hurwitz criterion to this polynomial, which has the form $a_{3}s^{3} + a_{2}s^{2} + a_{1}s + a_{0}$. The coefficients are $a_{3}=1$, $a_{2}=6$, $a_{1}=6 - K_I$, and $a_{0}=K_I$. For a polynomial of order $3$ to have all its roots in the open LHP, the necessary and sufficient conditions are that all coefficients must be positive, and the inequality $a_{2}a_{1} > a_{3}a_{0}$ must hold.\n\nThe conditions are:\n1. $a_{3} = 1 > 0$ (satisfied).\n2. $a_{2} = 6 > 0$ (satisfied).\n3. $a_{1} = 6 - K_I > 0 \\implies K_I < 6$.\n4. $a_{0} = K_I > 0$.\n5. $a_{2}a_{1} > a_{3}a_{0} \\implies 6(6 - K_I) > (1)(K_I)$.\n\nExpanding the final inequality:\n$$\n36 - 6K_I > K_I\n$$\n$$\n36 > 7K_I\n$$\n$$\nK_I < \\frac{36}{7}.\n$$\nFor stability, all conditions must be met simultaneously. We have $K_I > 0$, $K_I < 6$, and $K_I < \\frac{36}{7}$. Since $\\frac{36}{7} \\approx 5.14$, the condition $K_I < \\frac{36}{7}$ is stricter than $K_I < 6$. Combining the effective constraints, the necessary and sufficient condition for the internal stability of the closed-loop system is:\n$$\n0 < K_I < \\frac{36}{7}.\n$$\nThis result demonstrates that integral action must be present ($K_I > 0$) for regulation, but if it becomes too aggressive ($K_I \\geq \\frac{36}{7}$), the system becomes unstable. This is a characteristic limitation when applying integral control to a nonminimum-phase system. The largest admissible value of $K_I$ that guarantees stability is the supremum of the interval of stability, which is the boundary value where stability is lost. This value is $\\frac{36}{7}$. At $K_I = \\frac{36}{7}$, the system has poles on the imaginary axis and is marginally stable, not asymptotically stable.", "answer": "$$\n\\boxed{\\frac{36}{7}}\n$$", "id": "2748500"}, {"introduction": "The successful transition from control theory to real-world application hinges on numerically robust algorithms, as ideal mathematical formulas can be surprisingly fragile when implemented in finite-precision arithmetic. This problem challenges you to analyze the numerical pitfalls of classic pole placement methods like Ackermann's formula, which are often presented as straightforward solutions [@problem_id:2748538]. By investigating the roles of the controllability matrix's condition number and the sensitivity of polynomial representations, you will develop a critical understanding of why certain systems are \"hard\" to control computationally, even when they are theoretically controllable.", "problem": "Consider a single-input Linear Time-Invariant (LTI) system with state equation $\\dot{x}(t)=A x(t)+B u(t)$ where $A\\in\\mathbb{R}^{n\\times n}$, $B\\in\\mathbb{R}^{n\\times 1}$, and suppose $(A,B)$ is controllable. Let the controllability matrix be $\\,\\mathcal{C}=[\\,B,\\;A B,\\;\\dots,\\;A^{n-1} B\\,]\\,\\in\\mathbb{R}^{n\\times n}$. A common state-feedback architecture is $u(t)=-K x(t)$, yielding closed-loop matrix $A_{\\mathrm{cl}}=A-BK$. One well-known synthesis route first constructs a similarity transformation $T$ that maps $(A,B)$ into a controllable companion form $(A_{\\mathrm{c}},B_{\\mathrm{c}})$ (sometimes called the controllable canonical form), and then selects a feedback $K_{\\mathrm{c}}$ in the companion coordinates to impose a desired monic characteristic polynomial $p_{\\mathrm{des}}(\\lambda)=\\lambda^{n}+\\alpha_{n-1}\\lambda^{n-1}+\\cdots+\\alpha_{0}$, followed by mapping back to the original coordinates. Another route works directly in the original coordinates by combining powers of $A$ with columns of $\\mathcal{C}$ to enforce the same polynomial constraint on $A_{\\mathrm{cl}}$.\n\nLet $\\kappa_{2}(M)=\\lVert M\\rVert_{2}\\,\\lVert M^{-1}\\rVert_{2}$ denote the spectral condition number of an invertible matrix $M$, and let $u$ denote the unit roundoff of floating-point arithmetic. Let $T$ be any invertible matrix such that $A_{\\mathrm{c}}=T^{-1}AT$ and $B_{\\mathrm{c}}=T^{-1}B=e_{n}$, where $e_{n}$ is the $n$-th standard basis vector. Let $\\mathcal{C}_{\\mathrm{c}}=[\\,e_{n},\\;A_{\\mathrm{c}}e_{n},\\;\\dots,\\;A_{\\mathrm{c}}^{n-1}e_{n}\\,]$ be the controllability matrix in the companion coordinates.\n\nSelect all statements that are correct about the numerical pitfalls of Ackermann-type state-feedback synthesis for high-order systems, and justify your selections from first principles, using only core definitions from linear systems and numerical linear algebra. In particular, analyze the roles of $\\kappa_{2}(\\mathcal{C})$ and the transformation to the companion basis.\n\nA. In any floating-point implementation that computes a state-feedback gain by first constructing any left inverse $L$ of $\\mathcal{C}$ (explicitly or implicitly) and then postprocessing with polynomial expressions in $A$, the relative forward error in the gain $K$ can, in the worst case, scale on the order of $\\kappa_{2}(\\mathcal{C})\\,u$, even if $A$ is well scaled and the polynomial is evaluated in a numerically stable manner.\n\nB. For any similarity transformation $T$ that maps $(A,B)$ to controllable companion form $(A_{\\mathrm{c}},B_{\\mathrm{c}})$, one has $\\mathcal{C}=T\\,\\mathcal{C}_{\\mathrm{c}}$ and therefore $\\kappa_{2}(T)\\ge \\kappa_{2}(\\mathcal{C})/\\kappa_{2}(\\mathcal{C}_{\\mathrm{c}})$. In particular, if $\\kappa_{2}(\\mathcal{C})$ is large while $\\kappa_{2}(\\mathcal{C}_{\\mathrm{c}})$ is moderate, then the companion-basis transformation $T$ must be ill-conditioned.\n\nC. If the desired closed-loop poles $\\{\\lambda_{i}\\}_{i=1}^{n}$ are clustered or nearly repeated, then the conversion from the pole set $\\{\\lambda_{i}\\}$ to the monic polynomial coefficients $\\{\\alpha_{k}\\}_{k=0}^{n-1}$ has a Fréchet derivative whose norm is governed by a Vandermonde-like matrix and can grow exponentially with $n$. Consequently, even with moderate $\\kappa_{2}(\\mathcal{C})$, coefficient-based computations in the companion basis become ill-conditioned.\n\nD. If $A$ is normal (diagonalizable by a unitary matrix), then for every controllable pair $(A,B)$ one necessarily has $\\kappa_{2}(\\mathcal{C})$ bounded by a polynomial in $n$ that is independent of the eigenvalues of $A$ and of $B$.\n\nE. There exists a universal constant $c>0$ such that for every controllable $(A,B)$ there is a similarity $S$ with $\\kappa_{2}(S)\\le c$ transforming the pair to $(\\tilde{A},\\tilde{B})$ whose controllability matrix $\\tilde{\\mathcal{C}}$ satisfies $\\kappa_{2}(\\tilde{\\mathcal{C}})\\le 3$.\n\nF. Orthogonal and balancing transformations can mitigate, but cannot eliminate in the worst case, the amplification of floating-point errors caused by large $\\kappa_{2}(\\mathcal{C})$ and by an ill-conditioned companion-basis map $T$ in Ackermann-type computations. In particular, there exist families of controllable systems for which no well-conditioned similarity transformation can drive the effective conditioning of the synthesis below an $\\mathcal{O}(\\kappa_{2}(\\mathcal{C}))$ barrier.\n\nChoose all that apply.", "solution": "The problem statement has been scrutinized and found to be valid. It is a well-posed problem grounded in established principles of linear systems theory and numerical linear algebra, free of scientific or logical flaws. We may therefore proceed to a complete analysis.\n\nThe problem investigates the numerical stability of so-called Ackermann-type pole placement synthesis methods. These methods compute a state-feedback gain $K$ for a given controllable system $(A, B)$ to assign a desired closed-loop characteristic polynomial $p_{\\mathrm{des}}(\\lambda)$. The two main variants are a direct computation in the original state coordinates, epitomized by Ackermann's formula, and an indirect method involving a similarity transformation to a controllable companion form. We shall analyze each statement based on first principles.\n\nA. In any floating-point implementation that computes a state-feedback gain by first constructing any left inverse $L$ of $\\mathcal{C}$ (explicitly or implicitly) and then postprocessing with polynomial expressions in $A$, the relative forward error in the gain $K$ can, in the worst case, scale on the order of $\\kappa_{2}(\\mathcal{C})\\,u$, even if $A$ is well scaled and the polynomial is evaluated in a numerically stable manner.\n\nThis statement addresses methods that rely on the inverse of the controllability matrix $\\mathcal{C}$. Since for a controllable single-input system, $\\mathcal{C}$ is an $n \\times n$ invertible matrix, its only left inverse is its unique two-sided inverse, $\\mathcal{C}^{-1}$. Ackermann's formula is the canonical example:\n$$ K = e_n^T \\mathcal{C}^{-1} p_{\\text{des}}(A) $$\nwhere $p_{\\text{des}}(A) = A^n + \\alpha_{n-1}A^{n-1} + \\dots + \\alpha_0 I$. The computation of $K$ requires either the explicit formation of $\\mathcal{C}^{-1}$ or, more likely, solving a linear system involving $\\mathcal{C}$. For example, one could compute $v^T = e_n^T \\mathcal{C}^{-1}$ by solving the system $\\mathcal{C}^T v = e_n$. From fundamental principles of numerical linear algebra, the worst-case relative error in the computed solution $\\hat{v}$ to a linear system $M x = b$ is bounded by an expression involving the condition number $\\kappa(M)$. The error in the input data and the floating-point errors incurred during factorization are amplified by $\\kappa(M)$. Specifically, the forward error in $v$ will be sensitive to $\\kappa_2(\\mathcal{C}^T) = \\kappa_2(\\mathcal{C})$. Subsequent multiplication by $p_{\\text{des}}(A)$ does not remove this sensitivity. Thus, the error in the final gain $K$ will have a component that scales with $\\kappa_2(\\mathcal{C})u$. The statement correctly identifies that the ill-conditioning of the controllability matrix is a primary source of numerical error in such algorithms.\n\nVerdict: **Correct**\n\nB. For any similarity transformation $T$ that maps $(A,B)$ to controllable companion form $(A_{\\mathrm{c}},B_{\\mathrm{c}})$, one has $\\mathcal{C}=T\\,\\mathcal{C}_{\\mathrm{c}}$ and therefore $\\kappa_{2}(T)\\ge \\kappa_{2}(\\mathcal{C})/\\kappa_{2}(\\mathcal{C}_{\\mathrm{c}})$. In particular, if $\\kappa_{2}(\\mathcal{C})$ is large while $\\kappa_{2}(\\mathcal{C}_{\\mathrm{c}})$ is moderate, then the companion-basis transformation $T$ must be ill-conditioned.\n\nWe are given $A_{\\mathrm{c}}=T^{-1}AT$ and $B_{\\mathrm{c}}=T^{-1}B$. This implies $A = TA_{\\mathrm{c}}T^{-1}$ and $B = TB_{\\mathrm{c}}$. Let us inspect the $k$-th column of the controllability matrix $\\mathcal{C}$, where $k \\in \\{0, 1, \\dots, n-1\\}$:\n$$ A^k B = (TA_{\\mathrm{c}}T^{-1})^k (TB_{\\mathrm{c}}) $$\nThe term $(TA_{\\mathrm{c}}T^{-1})^k$ expands to $T A_{\\mathrm{c}}^k T^{-1}$ due to the cancellation of adjacent $T^{-1}T$ pairs. Therefore,\n$$ A^k B = T A_{\\mathrm{c}}^k T^{-1} TB_{\\mathrm{c}} = T (A_{\\mathrm{c}}^k B_{\\mathrm{c}}) $$\nThis relation holds for every column. Assembling the columns into the full controllability matrices, we obtain $\\mathcal{C} = T \\mathcal{C}_{\\mathrm{c}}$. This proves the first part of the statement.\n\nFor the second part, we use the sub-multiplicative property of the condition number for any two invertible matrices $X, Y$: $\\kappa_2(XY) \\le \\kappa_2(X)\\kappa_2(Y)$. Applying this to $\\mathcal{C} = T \\mathcal{C}_{\\mathrm{c}}$, we get:\n$$ \\kappa_2(\\mathcal{C}) \\le \\kappa_2(T) \\kappa_2(\\mathcal{C}_{\\mathrm{c}}) $$\nSince both matrices are invertible, their condition numbers are at least $1$. We can rearrange the inequality to obtain a lower bound on $\\kappa_2(T)$:\n$$ \\kappa_2(T) \\ge \\frac{\\kappa_2(\\mathcal{C})}{\\kappa_2(\\mathcal{C}_{\\mathrm{c}})} $$\nThis confirms the inequality. The final conclusion is a direct consequence: if $\\kappa_2(\\mathcal{C})$ is large and $\\kappa_2(\\mathcal{C}_{\\mathrm{c}})$ is of a modest size, the ratio provides a large lower bound for $\\kappa_2(T)$, which signifies that the transformation matrix $T$ must be ill-conditioned. The statement accurately connects the ill-conditioning of the physical system's controllability matrix to the ill-conditioning of the transformation matrix required for the companion form method.\n\nVerdict: **Correct**\n\nC. If the desired closed-loop poles $\\{\\lambda_{i}\\}_{i=1}^{n}$ are clustered or nearly repeated, then the conversion from the pole set $\\{\\lambda_{i}\\}$ to the monic polynomial coefficients $\\{\\alpha_{k}\\}_{k=0}^{n-1}$ has a Fréchet derivative whose norm is governed by a Vandermonde-like matrix and can grow exponentially with $n$. Consequently, even with moderate $\\kappa_{2}(\\mathcal{C})$, coefficient-based computations in the companion basis become ill-conditioned.\n\nThe coefficients $\\{\\alpha_k\\}$ of the polynomial $p(\\lambda) = \\lambda^n + \\sum_{k=0}^{n-1} \\alpha_k \\lambda^k$ are elementary symmetric polynomials of its roots $\\{\\lambda_i\\}$. The problem of finding the coefficients from the roots is known to be ill-conditioned if the roots are close. This is the dual of the famous problem of finding roots from coefficients, whose ill-conditioning was demonstrated by Wilkinson. The sensitivity of the coefficients to perturbations in the roots is indeed described by the conditioning of a Vandermonde matrix. The relations $\\sum_{k=0}^{n-1}\\alpha_k\\lambda_i^k = -\\lambda_i^n$ for $i=1,\\ldots,n$ form a linear system for the coefficients $[\\alpha_0, \\dots, \\alpha_{n-1}]^T$ with a Vandermonde matrix. Such matrices are notoriously ill-conditioned when the points $\\lambda_i$ are clustered.\nThe companion-form synthesis method requires computing the gain $K_c$ in the companion coordinates from the coefficients of the desired polynomial $p_{\\text{des}}(\\lambda)$. Specifically, for the standard controllable companion form, $K_c = [\\alpha_0-a_0, \\dots, \\alpha_{n-1}-a_{n-1}]$, where $\\{a_k\\}$ are coefficients of the open-loop characteristic polynomial. Since the computation of $K_c$ directly uses the coefficients $\\{\\alpha_k\\}$, any large error in computing these coefficients from the desired poles $\\{\\lambda_i\\}$ will directly translate to a large error in $K_c$. This ill-conditioning is intrinsic to the representation of poles via polynomial coefficients and is independent of the system's own conditioning (represented by $\\kappa_2(\\mathcal{C})$). Thus, even if a system is well-conditioned in its controllability, choosing clustered poles will render any coefficient-based pole-placement method numerically fragile.\n\nVerdict: **Correct**\n\nD. If $A$ is normal (diagonalizable by a unitary matrix), then for every controllable pair $(A,B)$ one necessarily has $\\kappa_{2}(\\mathcal{C})$ bounded by a polynomial in $n$ that is independent of the eigenvalues of $A$ and of $B$.\n\nA normal matrix $A$ can be diagonalized by a unitary matrix $U$, such that $A = UDU^*$, where $D = \\text{diag}(\\lambda_1, \\dots, \\lambda_n)$ and $U^*U=I$. Let's perform a unitary change of coordinates $\\hat{x}=U^*x$. The system becomes $(\\hat{A}, \\hat{B}) = (D, U^*B)$. The controllability matrix in the new coordinates is $\\hat{\\mathcal{C}}$. The original and new controllability matrices are related by $\\mathcal{C} = U\\hat{\\mathcal{C}}$. Since $U$ is unitary, $\\kappa_2(U)=1$, and thus $\\kappa_2(\\mathcal{C}) = \\kappa_2(U\\hat{\\mathcal{C}}) = \\kappa_2(\\hat{\\mathcal{C}})$.\nThe new controllability matrix is $\\hat{\\mathcal{C}} = [\\hat{B}, D\\hat{B}, \\dots, D^{n-1}\\hat{B}]$. Let $\\hat{B} = [\\hat{b}_1, \\dots, \\hat{b}_n]^T$. A row-wise inspection reveals that:\n$$ \\hat{\\mathcal{C}} = \\text{diag}(\\hat{b}_1, \\dots, \\hat{b}_n) \\cdot \\begin{pmatrix} 1 & \\lambda_1 & \\dots & \\lambda_1^{n-1} \\\\ 1 & \\lambda_2 & \\dots & \\lambda_2^{n-1} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & \\lambda_n & \\dots & \\lambda_n^{n-1} \\end{pmatrix} = \\text{diag}(\\hat{B}) V $$\nHere, $V$ is a Vandermonde matrix formed from the eigenvalues of $A$. For the system to be controllable, the eigenvalues $\\lambda_i$ must be distinct and all components $\\hat{b}_i$ must be non-zero. The condition number is $\\kappa_2(\\mathcal{C}) = \\kappa_2(\\text{diag}(\\hat{B}) V)$. This value is highly dependent on both the eigenvalues $\\{\\lambda_i\\}$ (via $\\kappa_2(V)$) and the input vector $B$ (via $\\kappa_2(\\text{diag}(\\hat{B}))$). If the eigenvalues are clustered, $\\kappa_2(V)$ grows exponentially with $n$, and $\\kappa_2(\\mathcal{C})$ will be large. It is manifestly false that $\\kappa_2(\\mathcal{C})$ is bounded independently of the eigenvalues of $A$ and the vector $B$.\n\nVerdict: **Incorrect**\n\nE. There exists a universal constant $c>0$ such that for every controllable $(A,B)$ there is a similarity $S$ with $\\kappa_{2}(S)\\le c$ transforming the pair to $(\\tilde{A},\\tilde{B})$ whose controllability matrix $\\tilde{\\mathcal{C}}$ satisfies $\\kappa_{2}(\\tilde{\\mathcal{C}})\\le 3$.\n\nThis statement posits that the ill-conditioning of the controllability matrix is merely a coordinate-dependent artifact that can always be removed by a well-conditioned similarity transformation. Let $\\tilde{\\mathcal{C}}$ be the controllability matrix for the transformed system $(\\tilde{A}, \\tilde{B}) = (S^{-1}AS, S^{-1}B)$. The relation between the controllability matrices is $\\tilde{\\mathcal{C}} = S^{-1}\\mathcal{C}$. Thus, $\\mathcal{C} = S\\tilde{\\mathcal{C}}$.\nIf the statement were true, we would have:\n$$ \\kappa_2(\\mathcal{C}) = \\kappa_2(S\\tilde{\\mathcal{C}}) \\le \\kappa_2(S) \\kappa_2(\\tilde{\\mathcal{C}}) \\le c \\cdot 3 $$\nThis implies that for any controllable system, the condition number of its controllability matrix is bounded by a universal constant $3c$. This is demonstrably false. Consider the system representing a chain of $n$ integrators. Its controllability matrix has a condition number that grows exponentially with $n$. Therefore, no such universal constant $c$ can exist. The conditioning of the controllability matrix, or more precisely the quantity $\\inf_S \\kappa_2(S^{-1}\\mathcal{C})$, reflects an intrinsic property of the system related to its distance to the set of uncontrollable systems, and this can be arbitrarily large for some systems.\n\nVerdict: **Incorrect**\n\nF. Orthogonal and balancing transformations can mitigate, but cannot eliminate in the worst case, the amplification of floating-point errors caused by large $\\kappa_{2}(\\mathcal{C})$ and by an ill-conditioned companion-basis map $T$ in Ackermann-type computations. In particular, there exist families of controllable systems for which no well-conditioned similarity transformation can drive the effective conditioning of the synthesis below an $\\mathcal{O}(\\kappa_{2}(\\mathcal{C}))$ barrier.\n\nOrthogonal and balancing transformations are standard numerical hygiene. A balancing transformation is a diagonal similarity matrix $S$ chosen to make the norms of corresponding rows and columns of $A$ nearly equal. Applying it to $(A,B)$ gives $(\\tilde{A}, \\tilde{B}) = (S^{-1}AS, S^{-1}B)$, and the new controllability matrix is $\\tilde{\\mathcal{C}} = S^{-1}\\mathcal{C}$. This can reduce $\\kappa_2(\\mathcal{C})$, but it does not change its order of magnitude if it is fundamentally large.\nThe core issue is that the minimal condition number achievable over all similarity transformations, $\\inf_S \\kappa_2(S^{-1}\\mathcal{C})$, is a system invariant related to its distance to uncontrollability. For systems that are nearly uncontrollable, this value is large. While balancing can bring $\\kappa_2(\\mathcal{C})$ closer to this optimal value, it cannot change the optimal value itself. Errors in pole placement algorithms are fundamentally bounded by this intrinsic conditioning. Let us consider the effect of a pre-conditioning similarity transformation $S$ on a method like Ackermann's. The method is applied to $(\\tilde{A}, \\tilde{B})$, with numerical sensitivity related to $\\kappa_2(\\tilde{\\mathcal{C}})=\\kappa_2(S^{-1}\\mathcal{C})$. The final gain is $K = \\tilde{K}S^{-1}$. The overall sensitivity involves both $\\kappa_2(\\tilde{\\mathcal{C}})$ and $\\kappa_2(S)$. A rough estimate of the conditioning gives $\\kappa_2(S)\\kappa_2(S^{-1}\\mathcal{C}) \\ge \\kappa_2(S) \\frac{\\kappa_2(\\mathcal{C})}{\\kappa_2(S)} = \\kappa_2(\\mathcal{C})$. This shows that $\\kappa_2(\\mathcal{C})$ acts as an approximate lower bound for the conditioning of the two-step procedure. Thus, transformations cannot eliminate the ill-conditioning in the worst-case, which is tied to the system's properties. The statement correctly asserts that for some systems, this forms an unavoidable barrier.\n\nVerdict: **Correct**", "answer": "$$\\boxed{ABCF}$$", "id": "2748538"}]}