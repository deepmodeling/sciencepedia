{"hands_on_practices": [{"introduction": "The cornerstone of analyzing homogeneous linear time-invariant (LTI) systems is finding the exact solution, which is governed by the matrix exponential $\\exp(At)$. This exercise [@problem_id:1611524] guides you through the process of using eigendecomposition to break down the system's dynamics into its fundamental modes. Mastering this technique provides a deep intuition for how a system's initial state evolves over time based on its intrinsic properties.", "problem": "A Linear Time-Invariant (LTI) system is described by the homogeneous state-space equation $\\dot{x}(t) = Ax(t)$, where $x(t) = \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}$ is the state vector. The system matrix $A$ is given by:\n$$\nA = \\begin{pmatrix} -2  1 \\\\ 2  -3 \\end{pmatrix}\n$$\nGiven the initial state of the system at $t=0$ is $x(0) = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix}$, determine the state vector $x(t)$ for all $t \\ge 0$. Express your answer as a column vector whose components are functions of $t$.", "solution": "For the homogeneous LTI system $\\dot{x}(t)=Ax(t)$ with constant matrix $A$, the state trajectory is $x(t)=\\exp(At)x(0)$. To compute $\\exp(At)$, we can diagonalize $A$ via its eigenvalues and eigenvectors.\n\nFirst, compute the characteristic polynomial to find the eigenvalues:\n$$\n\\det(A-\\lambda I)=\\det\\begin{pmatrix}-2-\\lambda  1 \\\\ 2  -3-\\lambda\\end{pmatrix}=(\\lambda+2)(\\lambda+3)-2=\\lambda^{2}+5\\lambda+4.\n$$\nSolving $\\lambda^{2}+5\\lambda+4=0$ gives the eigenvalues $\\lambda_{1}=-1$ and $\\lambda_{2}=-4$.\n\nNext, find the corresponding eigenvectors. For $\\lambda_{1}=-1$, solve $(A+I)v=0$:\n$$\n\\begin{pmatrix}-1  1 \\\\ 2  -2\\end{pmatrix}\\begin{pmatrix}v_{1}\\\\v_{2}\\end{pmatrix}=0 \\implies v_{2}=v_{1}.\n$$\nWe can choose the eigenvector $v_{1}=\\begin{pmatrix}1\\\\1\\end{pmatrix}$. For $\\lambda_{2}=-4$, solve $(A+4I)v=0$:\n$$\n\\begin{pmatrix}2  1 \\\\ 2  1\\end{pmatrix}\\begin{pmatrix}v_{1}\\\\v_{2}\\end{pmatrix}=0 \\implies v_{2}=-2v_{1}.\n$$\nWe can choose the eigenvector $v_{2}=\\begin{pmatrix}1\\\\-2\\end{pmatrix}$.\n\nThe general solution is a linear combination of the fundamental modes associated with each eigenvector:\n$$\nx(t)=c_{1}\\exp(-t)\\begin{pmatrix}1\\\\1\\end{pmatrix}+c_{2}\\exp(-4t)\\begin{pmatrix}1\\\\-2\\end{pmatrix}.\n$$\nWe determine the coefficients $c_{1}$ and $c_{2}$ from the initial condition $x(0)=\\begin{pmatrix}2\\\\5\\end{pmatrix}$:\n$$\n\\begin{pmatrix}2\\\\5\\end{pmatrix}=c_{1}\\begin{pmatrix}1\\\\1\\end{pmatrix}+c_{2}\\begin{pmatrix}1\\\\-2\\end{pmatrix}=\\begin{pmatrix}c_{1}+c_{2}\\\\c_{1}-2c_{2}\\end{pmatrix}.\n$$\nThis gives the linear system $c_{1}+c_{2}=2$ and $c_{1}-2c_{2}=5$. Subtracting the second equation from the first yields $3c_{2}=-3$, so $c_{2}=-1$. Substituting back gives $c_{1}=3$.\n\nTherefore, the specific solution for the given initial condition is:\n$$\nx(t)=3\\exp(-t)\\begin{pmatrix}1\\\\1\\end{pmatrix}-\\exp(-4t)\\begin{pmatrix}1\\\\-2\\end{pmatrix}=\\begin{pmatrix}3\\exp(-t)-\\exp(-4t)\\\\3\\exp(-t)+2\\exp(-4t)\\end{pmatrix}.\n$$\nThis final expression represents the state vector $x(t)$ for all $t \\ge 0$.", "answer": "$$\\boxed{\\begin{pmatrix}3\\exp(-t)-\\exp(-4t)\\\\3\\exp(-t)+2\\exp(-4t)\\end{pmatrix}}$$", "id": "1611524"}, {"introduction": "While the matrix exponential is a powerful tool, it's crucial to recognize that it does not always behave like its scalar counterpart. A common pitfall is incorrectly assuming that $\\exp((A+B)t)$ equals $\\exp(At)\\exp(Bt)$, which is only true when matrices $A$ and $B$ commute. This practice [@problem_id:1611533] provides a concrete counterexample to illustrate this non-commutativity and quantify the resulting error, a vital concept for understanding approximation methods in control theory.", "problem": "In analyzing the dynamics of a simplified two-state system, the state vector evolves according to a state-space model. The system is influenced by two separate processes, described by the constant matrices $A$ and $B$.\n\nLet the matrices be:\n$$\nA = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\n$$\n$$\nB = \\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix}\n$$\n\nThe exact evolution of the system over a time interval $t$ is given by the state-transition matrix $\\Phi_{exact}(t) = \\exp((A+B)t)$. A common simplification, known as a first-order Lie-Trotter approximation, is to treat the evolutions separately, resulting in an approximate state-transition matrix $\\Phi_{approx}(t) = \\exp(At)\\exp(Bt)$.\n\nTo quantify the discrepancy introduced by this approximation, we define an error matrix $E(t) = \\Phi_{approx}(t) - \\Phi_{exact}(t)$.\n\nCalculate the value of the element in the first row and second column of the error matrix, denoted as $E_{12}$, at time $t=2$. Express your answer as a closed-form analytic expression.", "solution": "We start by computing the individual matrix exponentials $\\exp(At)$ and $\\exp(Bt)$. Both matrices $A$ and $B$ are nilpotent of order 2, meaning $A^2=0$ and $B^2=0$:\n$$\nA^{2}=\\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}=\\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix},\\quad\nB^{2}=\\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix}\\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix}=\\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}.\n$$\nThis property truncates the power series for their exponentials, yielding:\n$$\n\\exp(At)=I+tA = \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix},\\quad \\exp(Bt)=I+tB = \\begin{pmatrix} 1  0 \\\\ t  1 \\end{pmatrix}.\n$$\nThe approximate transition matrix is their product:\n$$\n\\Phi_{\\text{approx}}(t)=\\exp(At)\\exp(Bt)=(I+tA)(I+tB)=I+t(A+B)+t^{2}AB.\n$$\nTo evaluate this, we compute the product $AB$:\n$$\nAB=\\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}.\n$$\nSubstituting into the expression for $\\Phi_{\\text{approx}}(t)$:\n$$\n\\Phi_{\\text{approx}}(t)=\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}+t\\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}+t^{2}\\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}\n=\\begin{pmatrix} 1+t^{2}  t \\\\ t  1 \\end{pmatrix}.\n$$\nFor the exact transition matrix $\\Phi_{\\text{exact}}(t)$, we first compute $J = A+B = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}$. We observe that $J^2 = I$. The power series for $\\exp(Jt)$ can be separated into even and odd powers of $t$:\n$$\n\\exp(Jt) = I \\sum_{k=0, \\text{even}}^\\infty \\frac{t^k}{k!} + J \\sum_{k=1, \\text{odd}}^\\infty \\frac{t^k}{k!} = I\\cosh(t) + J\\sinh(t).\n$$\nSo, the exact matrix is:\n$$\n\\Phi_{\\text{exact}}(t)=\\begin{pmatrix} \\cosh(t)  \\sinh(t) \\\\ \\sinh(t)  \\cosh(t) \\end{pmatrix}.\n$$\nThe error matrix is the difference between the approximate and exact matrices:\n$$\nE(t)=\\Phi_{\\text{approx}}(t)-\\Phi_{\\text{exact}}(t)\n=\\begin{pmatrix} 1+t^{2}-\\cosh(t)  t-\\sinh(t) \\\\ t-\\sinh(t)  1-\\cosh(t) \\end{pmatrix}.\n$$\nThe element $E_{12}(t)$ is the entry in the first row, second column:\n$$\nE_{12}(t)=t-\\sinh(t).\n$$\nEvaluating at $t=2$ gives the final answer:\n$$\nE_{12}(2)=2-\\sinh(2).\n$$", "answer": "$$\\boxed{2-\\sinh(2)}$$", "id": "1611533"}, {"introduction": "Moving beyond LTI systems, we encounter linear time-varying (LTV) systems, where analytical solutions are often intractable. For the important class of periodic LTV systems, Floquet theory offers a powerful framework for analysis. This advanced computational exercise [@problem_id:2745820] challenges you to implement a numerical algorithm to find the constant 'generator' matrix $R$ that characterizes the system's behavior over one period, bridging theoretical concepts with practical, hands-on coding.", "problem": "Consider the homogeneous state equation for a continuous-time Linear Time-Varying (LTV) system, defined by the Ordinary Differential Equation (ODE) $\\dot{x}(t)=A(t)\\,x(t)$ with a $2\\times 2$ matrix $A(t)$ that is $T$-periodic, meaning $A(t+T)=A(t)$ for all $t$. The state-transition matrix $\\Phi(t,t_{0})$ is the unique matrix function satisfying $\\frac{d}{dt}\\Phi(t,t_{0})=A(t)\\,\\Phi(t,t_{0})$ and $\\Phi(t_{0},t_{0})=I$, where $I$ is the identity matrix. The monodromy matrix over one period is $M=\\Phi(T,0)$, which encodes the net evolution over one period when starting from the identity. A constant generator matrix $R$ can be associated to $M$ via a matrix logarithm under the condition that $M$ has no eigenvalues on the nonpositive real axis, so that a principal matrix logarithm exists. Your program must compute $M$ numerically via time-ordered integration of the matrix ODE and then compute $R$ from $M$ using a principal matrix logarithm.\n\nAlgorithmic requirements:\n- Compute $\\Phi(t,0)$ by directly integrating the matrix ODE $\\dot{\\Phi}(t,0)=A(t)\\,\\Phi(t,0)$ with initial condition $\\Phi(0,0)=I$. This realizes the time-ordered exponential numerically by evolving forward in time.\n- Set $M=\\Phi(T,0)$ at the final time $T$.\n- Compute $R$ from $M$ as the principal matrix logarithm scaled by the period, that is, compute a matrix $R$ satisfying $\\exp(R\\,T)=M$ by applying a principal matrix logarithm to $M$ and scaling by $1/T$.\n\nAngle unit specification: whenever trigonometric functions appear, interpret their arguments in radians.\n\nTest suite:\nImplement the algorithm for the following four cases. For each case, compute the scalar error specified below. All numeric constants are dimensionless, and all angles are in radians.\n\n- Case $\\mathbf{1}$ (constant, commuting benchmark):\n  - Period: $T=3$.\n  - Matrix: $A(t)=\\begin{bmatrix}-0.2  0\\\\ 0  -0.5\\end{bmatrix}$ for all $t$.\n  - Expected generator: $R_{\\text{exp}}=\\begin{bmatrix}-0.2  0\\\\ 0  -0.5\\end{bmatrix}$.\n  - Required scalar output for this case: $e_{1}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n\n- Case $\\mathbf{2}$ (diagonal periodic with zero mean, boundary where $M=I$):\n  - Period: $T=2\\pi$.\n  - Matrix: $A(t)=\\operatorname{diag}\\left(\\sin(t),-\\sin(t)\\right)$.\n  - Expected generator: $R_{\\text{exp}}=\\begin{bmatrix}0  0\\\\ 0  0\\end{bmatrix}$.\n  - Required scalar output: $e_{2}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n\n- Case $\\mathbf{3}$ (diagonal periodic with nonzero mean, commuting but time-varying):\n  - Period: $T=2\\pi$.\n  - Matrix: $A(t)=\\operatorname{diag}\\left(-0.1+0.05\\sin(2t),\\,-0.3+0.02\\cos(3t)\\right)$.\n  - Expected generator: $R_{\\text{exp}}=\\operatorname{diag}\\left(-0.1,\\,-0.3\\right)$.\n  - Required scalar output: $e_{3}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n\n- Case $\\mathbf{4}$ (noncommuting periodic, reconstruction check):\n  - Period: $T=2\\pi$.\n  - Matrix: $A(t)=\\begin{bmatrix}0  1+0.2\\sin(2t)\\\\ -\\left(1.0+0.1\\cos(t)\\right)  0\\end{bmatrix}$.\n  - No closed-form expected generator is provided.\n  - Required scalar output: $e_{4}=\\left\\|\\exp(R\\,T)-M\\right\\|_{F}$, where $\\|\\cdot\\|_{F}$ denotes the Frobenius norm.\n\nFinal output format:\n- Your program must produce a single line of output containing the list $\\left[e_{1},e_{2},e_{3},e_{4}\\right]$ as a comma-separated Python-style list.\n- Each float must be printed in scientific notation with exactly six digits after the decimal point (for example, $1.234567\\text{e-}04$).\n- No other text should be printed.\n\nYour implementation must be entirely self-contained, must not require any user input, and must use time-ordered numerical integration of the matrix ODE for $\\Phi(t,0)$, followed by a principal matrix logarithm of $M$ to obtain $R$.", "solution": "The core of this problem lies in applying the principles of Floquet theory to a periodic LTV system. The system's dynamics are described by the equation $\\dot{x}(t) = A(t)x(t)$, where $A(t+T)=A(t)$. The evolution of the system is captured by the state-transition matrix $\\Phi(t,t_0)$, which must be found by solving the matrix differential equation:\n$$\n\\frac{d}{dt}\\Phi(t, 0) = A(t)\\Phi(t, 0), \\quad \\Phi(0, 0) = I\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix. Formally, the solution involves a time-ordered exponential, $\\Phi(t, 0) = \\mathcal{T}\\exp\\left(\\int_0^t A(\\tau) d\\tau\\right)$. Except in special cases, this cannot be simplified to a standard matrix exponential. The numerical procedure specified—integrating the matrix ODE directly—is the standard method for computing this time-ordered product.\n\nFor a system with period $T$, the monodromy matrix $M=\\Phi(T,0)$ characterizes the system's evolution over a single period. Floquet's theorem guarantees that we can find a constant matrix $R$, known as the generator, such that $M = \\exp(RT)$. From this relationship, $R$ can be found by taking the matrix logarithm:\n$$\nR = \\frac{1}{T}\\log(M)\n$$\nThe problem demands the use of the principal matrix logarithm, which is unique under the condition that $M$ has no eigenvalues on the nonpositive real axis.\n\nThe numerical implementation proceeds as follows:\n1.  **ODE Integration**: The matrix ODE for $\\Phi(t,0)$ is a system of $2 \\times 2 = 4$ coupled linear first-order differential equations. To use a standard numerical solver like `scipy.integrate.solve_ivp`, the $2 \\times 2$ matrix $\\Phi$ is vectorized (flattened) into a $4 \\times 1$ state vector $y(t)$. The derivative function supplied to the solver calculates $A(t)$, reshapes $y(t)$ back to a matrix $\\Phi$, computes the product $A(t)\\Phi$, and returns the flattened result as the derivative vector $\\dot{y}(t)$. We integrate from $t=0$ to $t=T$ with the initial condition $y(0)$ corresponding to the flattened identity matrix.\n2.  **Monodromy Matrix**: The solver's output at $t=T$ gives the final state vector, which is reshaped to form the monodromy matrix $M = \\Phi(T, 0)$.\n3.  **Generator Matrix**: The generator $R$ is then calculated as $R = \\frac{1}{T}\\log(M)$ using a numerical library function for the principal matrix logarithm (`scipy.linalg.logm`).\n\nFor Cases $1$, $2$, and $3$, the matrix $A(t)$ has the property that $[A(t_1), A(t_2)]=0$ for all $t_1, t_2$. In Case $1$, this is because $A(t)$ is constant. In Cases $2$ and $3$, it is because $A(t)$ is diagonal for all $t$, and diagonal matrices commute. For such commuting systems, the time-ordered exponential simplifies to the standard matrix exponential of the integral:\n$$\n\\Phi(T, 0) = \\exp\\left(\\int_0^T A(\\tau) d\\tau\\right)\n$$\nThe generator $R$ then becomes the time-average of $A(t)$, i.e., $R = \\bar{A} = \\frac{1}{T}\\int_0^T A(\\tau) d\\tau$. This confirms the provided $R_{\\text{exp}}$ for these cases. For instance, in Case 2, $\\int_0^{2\\pi} \\sin(t) dt = 0$, so $\\bar{A}$ is the zero matrix.\n\nFor Case $4$, the matrix $A(t)$ is non-commuting. Simple evaluation shows $[A(t_1), A(t_2)] \\neq 0$. Thus, the full numerical integration of the matrix ODE is indispensable, and the generator $R$ is not simply the time-average of $A(t)$. The error metric $e_4 = \\|\\exp(RT) - M\\|_F$ acts as a verification of the numerical process, checking if the computed $R$ accurately reconstructs $M$. This error is expected to be close to machine precision.\n\nThe implementation will utilize a high-precision `RK45` integration scheme to minimize numerical error, allowing for accurate comparison with the expected results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.linalg import logm, expm\n\ndef solve():\n    \"\"\"\n    Computes the generator matrix R for four LTV systems and calculates\n    the specified error metrics.\n    \"\"\"\n\n    def compute_R_and_M(A_func, T):\n        \"\"\"\n        Computes the monodromy matrix M and the generator R for a given\n        system A(t) and period T.\n        \"\"\"\n        # Define the ODE system for the flattened state-transition matrix Phi.\n        # The state vector y has 4 elements, representing the 2x2 matrix Phi.\n        def ode_system(t, y):\n            Phi = y.reshape((2, 2))\n            A = A_func(t)\n            dPhi_dt = A @ Phi\n            return dPhi_dt.flatten()\n\n        # Initial condition Phi(0, 0) = I, flattened to a vector.\n        y0 = np.identity(2, dtype=float).flatten()\n        \n        # Numerically integrate the ODE from t=0 to t=T.\n        # We use a high-precision solver configuration to ensure accuracy.\n        # We only need the solution at the final time T.\n        sol = solve_ivp(\n            fun=ode_system,\n            t_span=[0, T],\n            y0=y0,\n            method='RK45',\n            t_eval=[T],\n            rtol=1e-13,\n            atol=1e-13\n        )\n        \n        # The monodromy matrix M is the state-transition matrix at t=T.\n        M = sol.y[:, -1].reshape((2, 2))\n        \n        # Compute the generator matrix R using the principal matrix logarithm.\n        R = logm(M) / T\n        \n        return R, M\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"case_id\": 1,\n            \"A_func\": lambda t: np.array([[-0.2, 0.0], [0.0, -0.5]]),\n            \"T\": 3.0,\n            \"R_exp\": np.array([[-0.2, 0.0], [0.0, -0.5]]),\n        },\n        {\n            \"case_id\": 2,\n            \"A_func\": lambda t: np.diag([np.sin(t), -np.sin(t)]),\n            \"T\": 2 * np.pi,\n            \"R_exp\": np.zeros((2, 2)),\n        },\n        {\n            \"case_id\": 3,\n            \"A_func\": lambda t: np.diag([-0.1 + 0.05 * np.sin(2*t), -0.3 + 0.02 * np.cos(3*t)]),\n            \"T\": 2 * np.pi,\n            \"R_exp\": np.diag([-0.1, -0.3]),\n        },\n        {\n            \"case_id\": 4,\n            \"A_func\": lambda t: np.array([[0.0, 1.0 + 0.2 * np.sin(2*t)], [-(1.0 + 0.1 * np.cos(t)), 0.0]]),\n            \"T\": 2 * np.pi,\n            \"R_exp\": None, # No analytical R_exp is provided\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A_func = case[\"A_func\"]\n        T = case[\"T\"]\n        R_exp = case[\"R_exp\"]\n        \n        R, M = compute_R_and_M(A_func, T)\n        \n        if case[\"case_id\"] in [1, 2, 3]:\n            # For cases 1-3, the error is the maximum absolute difference\n            # between the computed R and the expected R_exp.\n            error = np.max(np.abs(R - R_exp))\n        else: # case_id == 4\n            # For case 4, the error is a self-consistency check: the Frobenius norm\n            # of the difference between the reconstructed M and the original M.\n            M_reconstructed = expm(R * T)\n            error = np.linalg.norm(M_reconstructed - M, 'fro')\n            \n        results.append(error)\n\n    # Final print statement in the exact required format.\n    # e.g., [1.234567e-08,_..._]\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```", "id": "2745820"}]}