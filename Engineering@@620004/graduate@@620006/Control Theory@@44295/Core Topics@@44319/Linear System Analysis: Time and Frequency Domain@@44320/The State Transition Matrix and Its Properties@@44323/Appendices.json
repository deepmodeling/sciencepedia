{"hands_on_practices": [{"introduction": "While calculating the state transition matrix $\\Phi(t) = \\exp(At)$ for a diagonalizable matrix $A$ is a standard exercise, many physical systems are modeled by non-diagonalizable, or \"defective,\" matrices. This practice explores this crucial case, where you will derive a closed-form expression for $\\exp(At)$ for a system with a repeated eigenvalue. By connecting the matrix's Jordan form to the dynamic response, you will gain a deeper understanding of how generalized eigenvectors lead to the characteristic $t\\exp(\\lambda t)$ terms in the solution, a hallmark of modal coupling in defective systems [@problem_id:2754461].", "problem": "Consider the Linear Time-Invariant (LTI) system $\\dot{x}(t)=A\\,x(t)$, where $A\\in\\mathbb{R}^{2\\times 2}$ is constant and the state transition matrix is defined by $x(t)=\\Phi(t)\\,x(0)$ with $\\Phi(t)=\\exp(A t)$. Let\n$$\nA=\\begin{pmatrix}\n3  2 \\\\\n-2  -1\n\\end{pmatrix}.\n$$\nThis matrix has a single real eigenvalue with algebraic multiplicity $2$ and is not diagonalizable. Starting only from the series definition of the matrix exponential and the fact that a matrix satisfies its own characteristic polynomial, derive a closed-form expression for $\\exp(A t)$. Then, identify an eigenvector $v_{1}$ and a generalized eigenvector $v_{2}$ of length-two Jordan chain for $A$ and interpret the appearance of the term proportional to $t$ in $\\exp(A t)$ by explaining how $\\exp(A t)$ acts on the chain $\\{v_{1},v_{2}\\}$.\n\nProvide your final result for $\\exp(A t)$ as a single closed-form analytic $2\\times 2$ matrix expression in $t$. No numerical rounding is required and no units are involved.", "solution": "The problem as stated is well-posed, scientifically grounded, and contains all necessary information for a unique solution. The provided properties of the matrix $A$ are correct and can be verified through standard linear algebra procedures. We will proceed with the solution.\n\nFirst, we must find the characteristic polynomial of the matrix $A = \\begin{pmatrix} 3  2 \\\\ -2  -1 \\end{pmatrix}$. The characteristic equation is given by $\\det(A - \\lambda I) = 0$.\n$$\n\\det\\left(\\begin{pmatrix} 3  2 \\\\ -2  -1 \\end{pmatrix} - \\lambda \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}\\right) = \\det\\begin{pmatrix} 3-\\lambda  2 \\\\ -2  -1-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(3-\\lambda)(-1-\\lambda) - (2)(-2) = -3 - 2\\lambda + \\lambda^2 + 4 = \\lambda^2 - 2\\lambda + 1 = (\\lambda - 1)^2 = 0\n$$\nThe matrix $A$ has a single real eigenvalue $\\lambda = 1$ with algebraic multiplicity $2$. By the Cayley-Hamilton theorem, a matrix satisfies its own characteristic equation. Therefore, we have $(A - 1 \\cdot I)^2 = 0$. Let us define the matrix $N = A - I$.\n$$\nN = A - I = \\begin{pmatrix} 3  2 \\\\ -2  -1 \\end{pmatrix} - \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 2  2 \\\\ -2  -2 \\end{pmatrix}\n$$\nThe Cayley-Hamilton theorem implies that $N^2 = (A-I)^2 = 0$. This means $N$ is a nilpotent matrix of index $2$. We can write $A = I + N$.\n\nThe problem requires us to use the series definition of the matrix exponential, $\\exp(M) = \\sum_{k=0}^{\\infty} \\frac{M^k}{k!}$. We wish to find $\\exp(At)$.\n$$\n\\exp(At) = \\exp((I+N)t) = \\exp(It + Nt)\n$$\nSince the identity matrix $I$ commutes with any matrix, $It$ and $Nt$ commute. Thus, we can write $\\exp(It + Nt) = \\exp(It) \\exp(Nt)$.\nThe first term is $\\exp(It) = \\sum_{k=0}^{\\infty} \\frac{(It)^k}{k!} = I \\sum_{k=0}^{\\infty} \\frac{t^k}{k!} = I \\exp(t)$.\nThe second term is $\\exp(Nt) = \\sum_{k=0}^{\\infty} \\frac{(Nt)^k}{k!} = \\frac{(Nt)^0}{0!} + \\frac{(Nt)^1}{1!} + \\frac{(Nt)^2}{2!} + \\dots$.\nSince $N^2 = 0$, all higher powers $N^k$ for $k \\ge 2$ are also the zero matrix. The series terminates:\n$$\n\\exp(Nt) = I + Nt + 0 + 0 + \\dots = I + Nt\n$$\nCombining these results, we obtain the closed-form expression for $\\exp(At)$:\n$$\n\\exp(At) = \\exp(It) \\exp(Nt) = (I \\exp(t)) (I + Nt) = \\exp(t) (I + Nt)\n$$\nSubstituting the matrix $N = A-I$:\n$$\n\\exp(At) = \\exp(t) (I + (A - I)t)\n$$\nNow, we substitute the numerical values for the matrices $I$ and $N$:\n$$\n\\exp(At) = \\exp(t) \\left( \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + t \\begin{pmatrix} 2  2 \\\\ -2  -2 \\end{pmatrix} \\right) = \\exp(t) \\begin{pmatrix} 1+2t  2t \\\\ -2t  1-2t \\end{pmatrix}\n$$\n$$\n\\exp(At) = \\begin{pmatrix} (1+2t)\\exp(t)  2t\\exp(t) \\\\ -2t\\exp(t)  (1-2t)\\exp(t) \\end{pmatrix}\n$$\nThis is the required closed-form expression for the state transition matrix $\\Phi(t) = \\exp(At)$.\n\nNext, we identify an eigenvector $v_1$ and a generalized eigenvector $v_2$.\nAn eigenvector $v_1$ corresponding to $\\lambda=1$ must satisfy $(A-I)v_1 = 0$, which is $Nv_1 = 0$.\n$$\n\\begin{pmatrix} 2  2 \\\\ -2  -2 \\end{pmatrix} v_1 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nThis yields the equation $2v_{1x} + 2v_{1y} = 0$, or $v_{1x} = -v_{1y}$. A non-zero solution is $v_1 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$. This vector spans the one-dimensional eigenspace.\n\nA generalized eigenvector $v_2$ of a length-two Jordan chain is defined by $(A-I)v_2 = v_1$, or $Nv_2 = v_1$.\n$$\n\\begin{pmatrix} 2  2 \\\\ -2  -2 \\end{pmatrix} v_2 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\n$$\nLet $v_2 = \\begin{pmatrix} v_{2x} \\\\ v_{2y} \\end{pmatrix}$. This gives the equation $2v_{2x} + 2v_{2y} = 1$. We can choose any vector that satisfies this. A simple choice is to set $v_{2y}=0$, which gives $v_{2x} = 1/2$. So, we select $v_2 = \\begin{pmatrix} 1/2 \\\\ 0 \\end{pmatrix}$.\n\nFinally, we interpret the appearance of the term proportional to $t$ in $\\exp(At)$ by analyzing its action on the chain $\\{v_1, v_2\\}$. We use the derived formula $\\exp(At) = \\exp(t)(I+Nt)$.\n\nAction on the eigenvector $v_1$:\n$$\n\\exp(At) v_1 = \\exp(t)(I+Nt) v_1 = \\exp(t)(I v_1 + t(Nv_1))\n$$\nBy definition of the eigenvector $v_1$, we have $Nv_1 = (A-I)v_1 = 0$. Thus,\n$$\n\\exp(At) v_1 = \\exp(t)(v_1 + t \\cdot 0) = \\exp(t) v_1\n$$\nA trajectory starting along the eigenvector $v_1$ remains on the line spanned by $v_1$ and scales by the factor $\\exp(\\lambda t) = \\exp(t)$. This is the expected behavior for any eigenvector.\n\nAction on the generalized eigenvector $v_2$:\n$$\n\\exp(At) v_2 = \\exp(t)(I+Nt) v_2 = \\exp(t)(I v_2 + t(Nv_2))\n$$\nBy definition of the generalized eigenvector $v_2$, we have $Nv_2 = (A-I)v_2 = v_1$. Substituting this into the equation:\n$$\n\\exp(At) v_2 = \\exp(t)(v_2 + t v_1)\n$$\nThis result is crucial. A trajectory starting at $v_2$ does not remain on the line spanned by $v_2$. Instead, its state at time $t$ is a linear combination of the generalized eigenvector $v_2$ and the eigenvector $v_1$. The component in the direction of the eigenvector $v_1$ grows in magnitude with a factor of $t$. The term proportional to $t$ in the expression for $\\exp(At)$, which originates from the nilpotent matrix $N=A-I$, is precisely what governs this dynamic coupling. It maps the generalized eigenspace into the true eigenspace over time, producing the characteristic $t\\exp(\\lambda t)$ behavior observed in systems with defective eigenvalues.", "answer": "$$\n\\boxed{\\begin{pmatrix} (1+2t)\\exp(t)  2t\\exp(t) \\\\ -2t\\exp(t)  (1-2t)\\exp(t) \\end{pmatrix}}\n$$", "id": "2754461"}, {"introduction": "The state transition matrix is far more than a tool for calculating state trajectories; it is fundamental to analyzing a system's inherent properties, such as observability. This exercise demonstrates the profound connection between $\\Phi(t,0)$ and the system's output energy by asking you to derive the infinite-horizon observability Gramian, $W_{o}$, directly from its integral definition. By explicitly verifying that the total output energy equals the quadratic form $x(0)^{\\top}W_{o}x(0)$, you will solidify the physical meaning of the Gramian and appreciate its role in determining if a system's initial state can be inferred from its future outputs [@problem_id:2754470].", "problem": "Consider the zero-input linear time-invariant (LTI) system with state equation $\\dot{x}(t)=A x(t)$ and output equation $y(t)=C x(t)$, where\n$$\nA=\\begin{pmatrix}-1  1 \\\\ 0  -2\\end{pmatrix},\\quad C=\\begin{pmatrix}1  1\\end{pmatrix}.\n$$\nStarting from the definition of the state transition matrix $\\Phi(t,0)$ for the homogeneous system, and the zero-input solution $x(t)=\\Phi(t,0)x(0)$, proceed as follows:\n- Derive $\\Phi(t,0)$ explicitly and use it to express the output energy $\\int_{0}^{\\infty}\\|y(t)\\|^{2}\\,dt$ as a quadratic form in $x(0)$.\n- From this representation, identify and compute the infinite-horizon observability Gramian $W_{o}(0,\\infty)$ for the given pair $(A,C)$ using only $\\Phi(t,0)$ and $C$.\n- For the initial condition $x(0)=\\begin{pmatrix}2 \\\\ -1\\end{pmatrix}$, evaluate both $x(0)^{\\top}W_{o}(0,\\infty)x(0)$ and $\\int_{0}^{\\infty}\\|y(t)\\|^{2}\\,dt$, and verify that they are equal.\n\nReport the common value as your final answer. No rounding is required. The final answer must be a single real number.", "solution": "The problem statement constitutes a standard, well-posed problem in the analysis of linear time-invariant (LTI) systems. All provided data and definitions are scientifically grounded in control theory and mathematically consistent. The system matrix $A$ has eigenvalues on the open left-half plane, ensuring system stability and the convergence of the infinite-horizon integrals. The problem is therefore valid.\n\nThe solution proceeds in four stages:\n1.  Derivation of the state transition matrix $\\Phi(t,0)$.\n2.  Formulation of the output energy as a quadratic form involving the observability Gramian.\n3.  Explicit computation of the observability Gramian $W_o(0,\\infty)$.\n4.  Evaluation of both expressions for the given initial condition to verify their equality.\n\nFirst, we find the state transition matrix $\\Phi(t,0) = \\exp(At)$ for the given system matrix $A=\\begin{pmatrix}-1  1 \\\\ 0  -2\\end{pmatrix}$. As $A$ is an upper triangular matrix, its eigenvalues are its diagonal entries, $\\lambda_1 = -1$ and $\\lambda_2 = -2$. We compute the corresponding eigenvectors.\nFor $\\lambda_1 = -1$, we solve $(A - \\lambda_1 I)v_1 = 0$:\n$$\n\\begin{pmatrix}-1 - (-1)  1 \\\\ 0  -2 - (-1)\\end{pmatrix}v_1 = \\begin{pmatrix}0  1 \\\\ 0  -1\\end{pmatrix}v_1 = 0 \\implies v_1 = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}\n$$\nFor $\\lambda_2 = -2$, we solve $(A - \\lambda_2 I)v_2 = 0$:\n$$\n\\begin{pmatrix}-1 - (-2)  1 \\\\ 0  -2 - (-2)\\end{pmatrix}v_2 = \\begin{pmatrix}1  1 \\\\ 0  0\\end{pmatrix}v_2 = 0 \\implies v_2 = \\begin{pmatrix}1 \\\\ -1\\end{pmatrix}\n$$\nThe modal matrix $V$ formed by the eigenvectors and its inverse $V^{-1}$ are:\n$$\nV = \\begin{pmatrix}1  1 \\\\ 0  -1\\end{pmatrix}, \\quad V^{-1} = \\frac{1}{\\det(V)}\\begin{pmatrix}-1  -1 \\\\ 0  1\\end{pmatrix} = \\frac{1}{-1}\\begin{pmatrix}-1  -1 \\\\ 0  1\\end{pmatrix} = \\begin{pmatrix}1  1 \\\\ 0  -1\\end{pmatrix}\n$$\nThe state transition matrix is given by $\\Phi(t,0) = \\exp(At) = V \\exp(Dt) V^{-1}$, where $D$ is the diagonal matrix of eigenvalues.\n$$\n\\Phi(t,0) = \\begin{pmatrix}1  1 \\\\ 0  -1\\end{pmatrix} \\begin{pmatrix}\\exp(-t)  0 \\\\ 0  \\exp(-2t)\\end{pmatrix} \\begin{pmatrix}1  1 \\\\ 0  -1\\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix}\\exp(-t)  \\exp(-2t) \\\\ 0  -\\exp(-2t)\\end{pmatrix} \\begin{pmatrix}1  1 \\\\ 0  -1\\end{pmatrix} = \\begin{pmatrix}\\exp(-t)  \\exp(-t) - \\exp(-2t) \\\\ 0  \\exp(-2t)\\end{pmatrix}\n$$\nNext, we express the output energy, $E_y = \\int_{0}^{\\infty}\\|y(t)\\|^{2}\\,dt$. For a zero-input system, the output is $y(t) = C x(t) = C \\Phi(t,0) x(0)$. Since the output is a scalar, $\\|y(t)\\|^2 = y(t)^{\\top}y(t)$.\n$$\ny(t)^{\\top}y(t) = \\left(C \\Phi(t,0) x(0)\\right)^{\\top} \\left(C \\Phi(t,0) x(0)\\right) = x(0)^{\\top} \\Phi(t,0)^{\\top} C^{\\top} C \\Phi(t,0) x(0)\n$$\nThe energy integral is therefore:\n$$\nE_y = \\int_{0}^{\\infty} x(0)^{\\top} \\Phi(t,0)^{\\top} C^{\\top} C \\Phi(t,0) x(0) \\,dt = x(0)^{\\top} \\left(\\int_{0}^{\\infty} \\Phi(t,0)^{\\top} C^{\\top} C \\Phi(t,0) \\,dt\\right) x(0)\n$$\nThis expresses the energy as a quadratic form in $x(0)$. From this, we identify the infinite-horizon observability Gramian as:\n$$\nW_{o}(0,\\infty) = \\int_{0}^{\\infty} \\Phi(t,0)^{\\top} C^{\\top} C \\Phi(t,0) \\,dt\n$$\nTo compute this integral, we first evaluate the term $C \\Phi(t,0)$:\n$$\nC \\Phi(t,0) = \\begin{pmatrix}1  1\\end{pmatrix} \\begin{pmatrix}\\exp(-t)  \\exp(-t) - \\exp(-2t) \\\\ 0  \\exp(-2t)\\end{pmatrix} = \\begin{pmatrix}\\exp(-t)  \\exp(-t)\\end{pmatrix}\n$$\nThe integrand can be written as $(C \\Phi(t,0))^{\\top} (C \\Phi(t,0))$:\n$$\n\\begin{pmatrix}\\exp(-t) \\\\ \\exp(-t)\\end{pmatrix} \\begin{pmatrix}\\exp(-t)  \\exp(-t)\\end{pmatrix} = \\begin{pmatrix}\\exp(-2t)  \\exp(-2t) \\\\ \\exp(-2t)  \\exp(-2t)\\end{pmatrix}\n$$\nNow, we integrate this matrix from $t=0$ to $t=\\infty$. The integral of each element is:\n$$\n\\int_{0}^{\\infty} \\exp(-2t) \\,dt = \\left[-\\frac{1}{2}\\exp(-2t)\\right]_{0}^{\\infty} = 0 - \\left(-\\frac{1}{2}\\right) = \\frac{1}{2}\n$$\nThus, the observability Gramian is:\n$$\nW_{o}(0,\\infty) = \\begin{pmatrix}\\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{2}\\end{pmatrix}\n$$\nFinally, for the initial condition $x(0) = \\begin{pmatrix}2 \\\\ -1\\end{pmatrix}$, we evaluate both expressions for the energy.\nFirst, the quadratic form:\n$$\nx(0)^{\\top}W_{o}(0,\\infty)x(0) = \\begin{pmatrix}2  -1\\end{pmatrix} \\begin{pmatrix}\\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}2 \\\\ -1\\end{pmatrix}\n= \\begin{pmatrix}1-\\frac{1}{2}  1-\\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}2 \\\\ -1\\end{pmatrix}\n= \\begin{pmatrix}\\frac{1}{2}  \\frac{1}{2}\\end{pmatrix} \\begin{pmatrix}2 \\\\ -1\\end{pmatrix} = 1 - \\frac{1}{2} = \\frac{1}{2}\n$$\nSecond, we directly compute the integral. The output $y(t)$ for the given $x(0)$ is:\n$$\ny(t) = C \\Phi(t,0) x(0) = \\begin{pmatrix}\\exp(-t)  \\exp(-t)\\end{pmatrix} \\begin{pmatrix}2 \\\\ -1\\end{pmatrix} = 2\\exp(-t) - \\exp(-t) = \\exp(-t)\n$$\nThe output energy is:\n$$\n\\int_{0}^{\\infty} \\|y(t)\\|^2 \\,dt = \\int_{0}^{\\infty} (\\exp(-t))^2 \\,dt = \\int_{0}^{\\infty} \\exp(-2t) \\,dt = \\frac{1}{2}\n$$\nBoth methods yield the same value, $\\frac{1}{2}$, confirming the correctness of the derivations.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "2754470"}, {"introduction": "Moving beyond time-invariant systems, many real-world processes, especially those under digital control or with periodic dynamics, are best described as Linear Time-Varying (LTV) systems. This problem tackles a common LTV scenario where the system matrix $A(t)$ is piecewise-constant and periodic. You will leverage the powerful composition property of the state transition matrix, $\\Phi(t_2, t_0) = \\Phi(t_2, t_1)\\Phi(t_1, t_0)$, to construct the transition matrix over one full period and analyze the system's long-term stability using Floquet theory [@problem_id:2754454]. This practice bridges the gap between continuous-time LTV dynamics and discrete-time stability analysis.", "problem": "Consider the Linear Time-Varying (LTV) system described by the homogeneous state equation $\\dot{x}(t)=A(t)\\,x(t)$, where the system matrix $A(t)$ is piecewise-constant over each sampling interval and repeats periodically with period $T=0.7$. On each interval $[kT,(k+1)T)$, the matrix $A(t)$ takes the values\n$$\nA(t)=\\begin{cases}\nA_{1}=\\begin{pmatrix}-1  2 \\\\ 0  -3\\end{pmatrix},  t\\in[kT,kT+0.4) \\\\\nA_{2}=\\begin{pmatrix}-2  0 \\\\ 1  -1\\end{pmatrix},  t\\in[kT+0.4,kT+0.7)\n\\end{cases}\n$$\nand then the pattern repeats for the next sampling interval. Define the discrete-time state at sampling instants by $x[k]=x(kT)$. The sample-to-sample state evolution is given by $x[k+1]=\\Phi_{d}\\,x[k]$, where $\\Phi_{d}$ is the discrete-time state transition matrix over one sample.\n\nStarting only from the fundamental definition of the state transition matrix and basic properties of matrix exponentials and composition, derive $\\Phi_{d}$ for this system, and then compute the spectral radius $\\rho(\\Phi_{d})$ as a closed-form expression using elementary functions. Explain the stability implications of your result for the sampled dynamics. Express your final answer for $\\rho(\\Phi_{d})$ in exact form using the natural exponential function, and do not round.", "solution": "The problem statement has been validated and is deemed a well-posed, scientifically grounded problem in the field of control theory. We will proceed with the derivation.\n\nThe system is described by the linear time-varying (LTV) state equation $\\dot{x}(t) = A(t)x(t)$, where the matrix $A(t)$ is periodic with period $T=0.7$. The solution to this equation is given by $x(t) = \\Phi(t, t_0)x(t_0)$, where $\\Phi(t, t_0)$ is the state transition matrix. The discrete-time system samples the state at instants $t_k = kT$ for integer $k$. The state evolution from one sample to the next is $x[k+1] = x((k+1)T) = \\Phi((k+1)T, kT)x(kT) = \\Phi_d x[k]$. Due to the periodicity of $A(t)$, the state transition matrix over one period is constant, $\\Phi((k+1)T, kT) = \\Phi(T, 0)$. Thus, the discrete-time state transition matrix is $\\Phi_d = \\Phi(T, 0)$.\n\nThe period $T=0.7$ is partitioned into two subintervals. In the first subinterval, of duration $T_1 = 0.4$, the system matrix is $A_1 = \\begin{pmatrix} -1  2 \\\\ 0  -3 \\end{pmatrix}$. In the second subinterval, of duration $T_2 = 0.7 - 0.4 = 0.3$, the system matrix is $A_2 = \\begin{pmatrix} -2  0 \\\\ 1  -1 \\end{pmatrix}$.\n\nUsing the composition property of the state transition matrix, $\\Phi(t_2, t_0) = \\Phi(t_2, t_1)\\Phi(t_1, t_0)$, we can express $\\Phi_d$ as:\n$$\n\\Phi_d = \\Phi(T, 0) = \\Phi(T_1+T_2, T_1) \\Phi(T_1, 0)\n$$\nFor a time-invariant system $\\dot{x} = Ax$ over an interval of length $\\Delta t$, the state transition matrix is $\\exp(A \\Delta t)$. Applying this to our piecewise-constant system:\n$$\n\\Phi(T_1, 0) = \\exp(A_1 T_1) = \\exp\\left(0.4 A_1\\right)\n$$\n$$\n\\Phi(T_1+T_2, T_1) = \\exp(A_2 T_2) = \\exp\\left(0.3 A_2\\right)\n$$\nTherefore, the discrete-time state transition matrix is the product of two matrix exponentials. It is critical to maintain the correct order of multiplication:\n$$\n\\Phi_d = \\exp(0.3 A_2) \\exp(0.4 A_1)\n$$\nWe now compute the individual matrix exponentials.\n\nFirst, for $A_1 = \\begin{pmatrix} -1  2 \\\\ 0  -3 \\end{pmatrix}$, we compute $\\exp(0.4 A_1)$. Since $A_1$ is an upper triangular matrix, we can use the formula for the exponential of a $2 \\times 2$ upper triangular matrix with distinct eigenvalues. Let $M = \\begin{pmatrix} a  c \\\\ 0  b \\end{pmatrix}$. Then $\\exp(M) = \\begin{pmatrix} \\exp(a)  c \\frac{\\exp(a)-\\exp(b)}{a-b} \\\\ 0  \\exp(b) \\end{pmatrix}$.\nHere, we have the matrix $0.4 A_1 = \\begin{pmatrix} -0.4  0.8 \\\\ 0  -1.2 \\end{pmatrix}$.\n$$\n\\exp(0.4 A_1) = \\begin{pmatrix} \\exp(-0.4)  0.8 \\frac{\\exp(-0.4)-\\exp(-1.2)}{-0.4 - (-1.2)} \\\\ 0  \\exp(-1.2) \\end{pmatrix} = \\begin{pmatrix} \\exp(-0.4)  \\exp(-0.4)-\\exp(-1.2) \\\\ 0  \\exp(-1.2) \\end{pmatrix}\n$$\nSecond, for $A_2 = \\begin{pmatrix} -2  0 \\\\ 1  -1 \\end{pmatrix}$, we compute $\\exp(0.3 A_2)$. The matrix $0.3 A_2 = \\begin{pmatrix} -0.6  0 \\\\ 0.3  -0.3 \\end{pmatrix}$ is lower triangular. By analogy, for $M = \\begin{pmatrix} a  0 \\\\ c  b \\end{pmatrix}$, $\\exp(M) = \\begin{pmatrix} \\exp(a)  0 \\\\ c \\frac{\\exp(b)-\\exp(a)}{b-a}  \\exp(b) \\end{pmatrix}$.\n$$\n\\exp(0.3 A_2) = \\begin{pmatrix} \\exp(-0.6)  0 \\\\ 0.3 \\frac{\\exp(-0.3)-\\exp(-0.6)}{-0.3 - (-0.6)}  \\exp(-0.3) \\end{pmatrix} = \\begin{pmatrix} \\exp(-0.6)  0 \\\\ \\exp(-0.3)-\\exp(-0.6)  \\exp(-0.3) \\end{pmatrix}\n$$\nNow, we multiply these two matrices to find $\\Phi_d$:\n$$\n\\Phi_d = \\begin{pmatrix} \\exp(-0.6)  0 \\\\ \\exp(-0.3)-\\exp(-0.6)  \\exp(-0.3) \\end{pmatrix} \\begin{pmatrix} \\exp(-0.4)  \\exp(-0.4)-\\exp(-1.2) \\\\ 0  \\exp(-1.2) \\end{pmatrix}\n$$\nThe product is:\n$$\n\\Phi_d = \\begin{pmatrix} \\exp(-0.6)\\exp(-0.4)  \\exp(-0.6)(\\exp(-0.4)-\\exp(-1.2)) \\\\ (\\exp(-0.3)-\\exp(-0.6))\\exp(-0.4)  (\\exp(-0.3)-\\exp(-0.6))(\\exp(-0.4)-\\exp(-1.2)) + \\exp(-0.3)\\exp(-1.2) \\end{pmatrix}\n$$\nSimplifying the elements:\n$(\\Phi_d)_{11} = \\exp(-1.0)$\n$(\\Phi_d)_{12} = \\exp(-1.0) - \\exp(-1.8)$\n$(\\Phi_d)_{21} = \\exp(-0.7) - \\exp(-1.0)$\n$(\\Phi_d)_{22} = (\\exp(-0.7) - \\exp(-1.5) - \\exp(-1.0) + \\exp(-1.8)) + \\exp(-1.5) = \\exp(-0.7) - \\exp(-1.0) + \\exp(-1.8)$\n\nSo the discrete-time state transition matrix is:\n$$\n\\Phi_d = \\begin{pmatrix} \\exp(-1.0)  \\exp(-1.0) - \\exp(-1.8) \\\\ \\exp(-0.7) - \\exp(-1.0)  \\exp(-0.7) - \\exp(-1.0) + \\exp(-1.8) \\end{pmatrix}\n$$\nNext, we compute the spectral radius $\\rho(\\Phi_d)$, which is the maximum modulus of the eigenvalues of $\\Phi_d$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(\\Phi_d - \\lambda I) = 0$, which for a $2 \\times 2$ matrix is $\\lambda^2 - \\text{tr}(\\Phi_d)\\lambda + \\det(\\Phi_d) = 0$.\n\nThe trace of $\\Phi_d$ is:\n$$\n\\text{tr}(\\Phi_d) = \\exp(-1.0) + (\\exp(-0.7) - \\exp(-1.0) + \\exp(-1.8)) = \\exp(-0.7) + \\exp(-1.8)\n$$\nThe determinant of $\\Phi_d$ is found using the property $\\det(\\exp(M)) = \\exp(\\text{tr}(M))$:\n$$\n\\det(\\Phi_d) = \\det(\\exp(0.3 A_2)) \\det(\\exp(0.4 A_1)) = \\exp(\\text{tr}(0.3 A_2)) \\exp(\\text{tr}(0.4 A_1))\n$$\nWith $\\text{tr}(A_1) = -1 - 3 = -4$ and $\\text{tr}(A_2) = -2 - 1 = -3$, we have:\n$$\n\\det(\\Phi_d) = \\exp(0.3 \\times (-3)) \\exp(0.4 \\times (-4)) = \\exp(-0.9) \\exp(-1.6) = \\exp(-2.5)\n$$\nThe characteristic equation is:\n$$\n\\lambda^2 - (\\exp(-0.7) + \\exp(-1.8))\\lambda + \\exp(-2.5) = 0\n$$\nBy inspection, we observe that the sum of roots is $\\lambda_1 + \\lambda_2 = \\exp(-0.7) + \\exp(-1.8)$ and the product of roots is $\\lambda_1 \\lambda_2 = \\exp(-2.5) = \\exp(-0.7)\\exp(-1.8)$. This implies that the eigenvalues are $\\lambda_1 = \\exp(-0.7)$ and $\\lambda_2 = \\exp(-1.8)$.\n\nThe spectral radius is the maximum of the absolute values of the eigenvalues. Since both eigenvalues are positive real numbers:\n$$\n\\rho(\\Phi_d) = \\max(|\\exp(-0.7)|, |\\exp(-1.8)|) = \\max(\\exp(-0.7), \\exp(-1.8))\n$$\nBecause the exponential function is strictly increasing, and $-0.7 > -1.8$, we have $\\exp(-0.7) > \\exp(-1.8)$. Therefore, the spectral radius is:\n$$\n\\rho(\\Phi_d) = \\exp(-0.7)\n$$\nFinally, we analyze the stability implications. The discrete-time system $x[k+1] = \\Phi_d x[k]$ is asymptotically stable if and only if the spectral radius of its state matrix $\\Phi_d$ is strictly less than one, i.e., $\\rho(\\Phi_d)  1$. In our case, $\\rho(\\Phi_d) = \\exp(-0.7)$. Since $e  1$ and the exponent is negative, $0  \\exp(-0.7)  1$. Thus, the condition for asymptotic stability is met. The sampled dynamics are asymptotically stable, meaning that for any initial state $x[0]$, the state trajectory $x[k]$ converges to the zero vector as $k \\to \\infty$. By Floquet theory, this also implies that the original continuous-time periodic system $\\dot{x}(t) = A(t)x(t)$ is asymptotically stable.", "answer": "$$\n\\boxed{\\exp(-0.7)}\n$$", "id": "2754454"}]}