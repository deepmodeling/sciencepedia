{"hands_on_practices": [{"introduction": "A primary goal of feedback is to ensure stability, but what does 'stable' truly mean? This exercise challenges you to explore the crucial distinction between Bounded-Input Bounded-Output (BIBO) stability, which considers only a specific input-output channel, and internal stability, which guarantees the well-behavedness of the entire system. By analyzing a classic example, you will learn why unstable 'hidden modes' can render a system unsafe, even if it appears stable from the outside [@problem_id:2708249].", "problem": "Consider a single-input single-output linear time-invariant negative-unity-feedback interconnection in the Laplace domain with forward-path controller and plant given by $K(s)=k$ and $P(s)=\\frac{1}{s(s-1)}$, respectively. The external reference input is $r(t)$, the control signal is $u(t)$, and the measured output is $y(t)$. Assume all signals are Laplace-transformable and the feedback interconnection is well-posed for all real $k$. Use first principles of feedback interconnections, together with the definitions below, to derive your conclusions:\n\n- Bounded-Input Bounded-Output (BIBO) stability is defined as the property that every bounded external input produces a bounded measured output, equivalently that every closed-loop transfer function from exogenous inputs to measured outputs is proper and has all poles strictly in the open left half-plane.\n- Internal stability (also called asymptotic stability of the closed-loop realization) is defined as the property that all internal modes of the interconnected realization have strictly negative real parts, including those that may be unobservable or uncontrollable from the chosen input-output channel.\n\nTasks:\n1. Derive the closed-loop transfer function from $r$ to $y$ starting from the summing-junction and block-diagram relations, without invoking any pre-memorized sensitivity formulas.\n2. Using the polynomial you obtain, characterize BIBO stability of the map from $r$ to $y$ for real $k$ by analyzing the closed-loop poles from first principles.\n3. Determine the set of all real values of $k$ for which the interconnection is BIBO stable but not internally stable. Your argument must explicitly address whether any unstable internal mode can be hidden (unobservable and/or uncontrollable) by algebraic pole-zero cancellations in the closed-loop input-output map for this configuration, and explain the role of such hidden unstable modes in principle.\n\nExpress your final answer as a set using standard mathematical notation. No rounding is required, and no physical units apply.", "solution": "The problem will be analyzed by validating its premises and then proceeding through the specified tasks using first principles of linear control theory.\n\nFirst, we derive the closed-loop transfer function from the reference input $r$ to the measured output $y$. Let $R(s)$, $U(s)$, and $Y(s)$ be the Laplace transforms of $r(t)$, $u(t)$, and $y(t)$, respectively. For a negative unity feedback configuration, the error signal at the summing junction is given by:\n$$E(s) = R(s) - Y(s)$$\nThe control signal $U(s)$ is generated by the controller $K(s)$ acting on the error $E(s)$:\n$$U(s) = K(s) E(s) = k(R(s) - Y(s))$$\nThe plant output $Y(s)$ is the result of the plant $P(s)$ acting on the control signal $U(s)$:\n$$Y(s) = P(s) U(s) = \\frac{1}{s(s-1)} U(s)$$\nSubstituting the expression for $U(s)$ into the equation for $Y(s)$ yields:\n$$Y(s) = \\frac{k}{s(s-1)} (R(s) - Y(s))$$\nWe rearrange the terms to solve for the ratio $\\frac{Y(s)}{R(s)}$:\n$$Y(s) \\left(1 + \\frac{k}{s(s-1)}\\right) = \\frac{k}{s(s-1)} R(s)$$\n$$Y(s) \\left(\\frac{s(s-1) + k}{s(s-1)}\\right) = \\frac{k}{s(s-1)} R(s)$$\nThis gives the closed-loop transfer function from $r$ to $y$, which completes Task 1:\n$$T_{yr}(s) = \\frac{Y(s)}{R(s)} = \\frac{k}{s(s-1) + k} = \\frac{k}{s^2 - s + k}$$\n\nFor Task 2, we characterize the Bounded-Input Bounded-Output (BIBO) stability of the map from $r$ to $y$. This requires that all poles of the transfer function $T_{yr}(s)$ lie strictly in the open left half-plane. We examine the poles by finding the roots of the characteristic polynomial $\\Delta(s) = s^2 - s + k = 0$.\nThere are two cases based on the value of $k$.\nCase 1: $k \\neq 0$. The poles of $T_{yr}(s)$ are the roots of $s^2 - s + k = 0$. Let the roots be $p_1$ and $p_2$. According to Vieta's formulas, the sum of the roots is $p_1 + p_2 = -(-1)/1 = 1$. The sum of the real parts of the roots is $\\text{Re}(p_1 + p_2) = \\text{Re}(p_1) + \\text{Re}(p_2) = 1$. For both poles to be in the open left half-plane, it must be that $\\text{Re}(p_1) < 0$ and $\\text{Re}(p_2) < 0$. This would imply $\\text{Re}(p_1) + \\text{Re}(p_2) < 0$, which contradicts the fact that the sum of the real parts is $1$. Therefore, for any $k \\neq 0$, at least one pole does not lie in the open left half-plane, and the map from $r$ to $y$ is not BIBO stable.\nCase 2: $k=0$. The transfer function becomes $T_{yr}(s) = \\frac{0}{s^2-s} = 0$. A transfer function that is identically zero has no poles. A system with a zero transfer function is BIBO stable because any bounded input produces an output that is always zero, which is bounded.\nCombining these cases, the map from $r$ to $y$ is BIBO stable if and only if $k=0$.\n\nFor Task 3, we must find the set of real values of $k$ for which the interconnection is BIBO stable but not internally stable.\nFirst, we analyze internal stability. The internal modes of the closed-loop system are the roots of the characteristic equation $1 + P(s)K(s) = 0$, provided there are no pole-zero cancellations in the loop transfer function $L(s) = P(s)K(s)$. Here, $L(s) = \\frac{k}{s(s-1)}$, and no such cancellations occur. The characteristic equation is $1 + \\frac{k}{s(s-1)} = 0$, which simplifies to $s^2 - s + k = 0$. For the system to be internally stable, all its internal modes (the roots of this polynomial) must have strictly negative real parts. As established in the analysis for Task 2, the sum of the real parts of these roots is always $1$. This condition for stability can never be satisfied for any real value of $k$. Consequently, the interconnection is never internally stable for any $k \\in \\mathbb{R}$.\n\nNext, we analyze the BIBO stability of the interconnection. According to the problem's strict definition, this requires that *every* closed-loop transfer function from exogenous inputs to measured outputs has all its poles in the open left half-plane. Let us consider an exogenous disturbance input $d(t)$ added to the plant input. The plant output is then $Y(s) = P(s)(U(s)+D(s))$. The transfer function from this disturbance $d$ to the output $y$ is given by $T_{yd}(s) = \\frac{P(s)}{1+P(s)K(s)}$. Substituting the given expressions for $P(s)$ and $K(s)$:\n$$T_{yd}(s) = \\frac{\\frac{1}{s(s-1)}}{1+\\frac{k}{s(s-1)}} = \\frac{1}{s(s-1)+k} = \\frac{1}{s^2-s+k}$$\nFor the interconnection to be BIBO stable, the poles of $T_{yd}(s)$, which are the roots of $s^2-s+k=0$, must all lie in the open left half-plane. As shown previously, this is never true for any real $k$. Since there exists at least one input-output map that is not stable for any $k$, the interconnection is never BIBO stable.\n\nThe question asks for the set of $k$ for which the interconnection is BIBO stable AND not internally stable.\n- The condition \"the interconnection is BIBO stable\" is true for no real values of $k$. The set of such $k$ is the empty set, $\\emptyset$.\n- The condition \"the interconnection is not internally stable\" is true for all real values of $k$. The set of such $k$ is $\\mathbb{R}$.\nThe intersection of these two sets is $\\emptyset \\cap \\mathbb{R} = \\emptyset$.\n\nThe problem requires an explicit discussion of hidden modes. For $k=0$, the system is not internally stable, with modes at $s=0$ and $s=1$. However, the transfer function $T_{yr}(s)$ is zero and thus stable. This is a case of pole-zero cancellation in the context of state-space realizations: the unstable internal modes are not connected to the reference input $r$. They are \"hidden\" because they are uncontrollable from $r$. However, these modes are not hidden from all channels. They appear as poles in the disturbance transfer function $T_{yd}(s) = \\frac{1}{s(s-1)}$. The instability of this map renders the entire interconnection not BIBO stable, per the provided definition. For any $k \\neq 0$, no such cancellations occur, and the unstable internal modes appear as unstable poles in all transfer functions, including $T_{yr}(s)$ and $T_{yd}(s)$.", "answer": "$$\\boxed{\\emptyset}$$", "id": "2708249"}, {"introduction": "Beyond ensuring stability, feedback design involves managing performance trade-offs, a key one being the amplification of measurement noise. This hands-on problem asks you to quantify this effect by connecting the output variance from white noise to the $\\mathcal{H}_2$ norm of the complementary sensitivity function [@problem_id:2708252]. You will implement a practical gain-tuning algorithm to respect a noise constraint, a common task in modern control engineering.", "problem": "Consider a continuous-time, single-input single-output Linear Time-Invariant (LTI) unity-feedback loop with negative feedback, where the plant is $P(s)=\\dfrac{5}{(s+1)(s+5)}$ and the controller is $K(s)=k\\dfrac{s+1}{s/10+1}$ with scalar gain $k \\ge 0$. The measurement signal is corrupted by additive measurement noise $n(t)$ with unit (one-sided) power spectral density, idealized as continuous-time white noise of unit intensity. Assume the reference input is identically zero, so the only excitation is measurement noise injected at the sensor additively to the plant output. The closed-loop output $y(t)$ is measured and fed back, forming a standard negative-feedback interconnection.\n\nTasks to be implemented in a program:\n\n1) Derive from first principles of feedback interconnections the closed-loop transfer function $T(s)$ from measurement noise $n(t)$ to plant output $y(t)$.\n\n2) Using the definition of the $\\mathcal{H}_2$ norm for strictly proper, internally stable LTI systems and the equivalence between output variance and squared $\\mathcal{H}_2$ norm for unit-intensity white noise excitation, express the output variance $\\sigma_y^2$ in terms of the parameters of $T(s)$ and the controller gain $k$.\n\n3) For a given nonnegative $k$ and a specified variance limit $V_{\\max} \\ge 0$, compute:\n   - The noise amplification factor $\\lVert T \\rVert_2$ (the $\\mathcal{H}_2$ norm) for the given $k$.\n   - An adjusted gain $k_{\\text{adj}} \\in [0,k]$ that is as large as possible while guaranteeing the variance constraint $\\sigma_y^2 \\le V_{\\max}$.\n   - The resulting output variance at $k_{\\text{adj}}$.\n\nAll calculations must be done under the assumption that the closed loop is internally stable. If $V_{\\max}=0$, take $k_{\\text{adj}}=0$.\n\nFoundational base you must use:\n- The definition of the sensitivity and complementary sensitivity in a standard unity negative-feedback loop, built from the basic summing junction and series interconnection rules.\n- The definition of the $\\mathcal{H}_2$ norm for a strictly proper, asymptotically stable LTI system with transfer function $G(s)$: $\\lVert G \\rVert_2^2 = \\dfrac{1}{2\\pi}\\displaystyle\\int_{-\\infty}^{\\infty} \\lvert G(\\mathrm{j}\\omega) \\rvert^2 \\,\\mathrm{d}\\omega$, and equivalently $\\lVert G \\rVert_2^2 = \\operatorname{trace}(CWC^\\top)$ where $W$ is the controllability Gramian solving the continuous-time Lyapunov equation $AW + WA^\\top + BB^\\top = 0$ for a minimal realization $(A,B,C,0)$ of $G(s)$.\n- The property that, for unit-intensity white noise input, the steady-state variance of the output of a strictly proper, stable LTI system equals $\\lVert G \\rVert_2^2$.\n\nYour program must implement the above steps and produce results for the following test suite of parameter values. Each test case is a pair $(k, V_{\\max})$:\n\n- Case 1 (general): $(0.5, 10.0)$.\n- Case 2 (constraint active): $(2.0, 1.0)$.\n- Case 3 (on the boundary): $(0.75, 0.5357142857142857)$.\n- Case 4 (tight limit): $(1.0, 0.0001)$.\n- Case 5 (zero limit): $(3.0, 0.0)$.\n\nFor each case, compute three quantities:\n- The initial noise amplification factor $\\lVert T \\rVert_2$ for the given $k$.\n- The adjusted gain $k_{\\text{adj}}$ chosen to satisfy $\\sigma_y^2 \\le V_{\\max}$ while maximizing $k_{\\text{adj}} \\le k$.\n- The resulting output variance $\\sigma_y^2$ at $k_{\\text{adj}}$.\n\nNumerical and output requirements:\n- Express all final numerical outputs as dimensionless real numbers rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one sublist per test case in the same order as specified above. Each sublist must be of the form $[\\lVert T \\rVert_2, k_{\\text{adj}}, \\sigma_y^2]$ using the rounding rule above. For example, a line with two cases would look like $[[0.123456,0.100000,0.015000],[0.234567,0.200000,0.030000]]$.", "solution": "The problem presented is a standard exercise in the analysis of linear-time-invariant (LTI) feedback systems subjected to stochastic disturbances. It is scientifically grounded, well-posed, and objective. The problem statement is validated as it contains all necessary information, is internally consistent, and relies on established principles of control theory. We shall proceed with a formal, step-by-step derivation and solution.\n\nThe primary objective is to analyze the effect of measurement noise on the plant output and to design a controller gain that respects a constraint on the output variance. The system is a unity-feedback loop with plant $P(s) = \\dfrac{5}{(s+1)(s+5)}$ and controller $K(s) = k\\dfrac{s+1}{s/10+1}$. The reference input $r(t)$ is zero, and the system is excited by additive white measurement noise $n(t)$ of unit intensity.\n\n**Step 1: Derivation of the Noise-to-Output Transfer Function**\n\nThe closed-loop system dynamics are described by the following signal relationships in the Laplace domain:\n1. Plant output: $Y(s) = P(s)U(s)$\n2. Controller input: $E(s) = R(s) - (Y(s) + N(s))$\n3. Controller output: $U(s) = K(s)E(s)$\n\nGiven the reference $R(s) = 0$, the controller input simplifies to $E(s) = -(Y(s) + N(s))$.\nSubstituting this into the controller output equation gives the plant input:\n$U(s) = -K(s)(Y(s) + N(s))$\n\nThe plant output is then:\n$Y(s) = P(s)U(s) = -P(s)K(s)(Y(s) + N(s)) = -P(s)K(s)Y(s) - P(s)K(s)N(s)$\n\nTo find the transfer function from the noise input $N(s)$ to the plant output $Y(s)$, we rearrange the equation to solve for $Y(s)$:\n$Y(s) + P(s)K(s)Y(s) = -P(s)K(s)N(s)$\n$Y(s)(1 + P(s)K(s)) = -P(s)K(s)N(s)$\n\nThe desired transfer function, denoted $T(s)$, is therefore:\n$T(s) = \\dfrac{Y(s)}{N(s)} = -\\dfrac{P(s)K(s)}{1 + P(s)K(s)}$\n\nThis is the negative of the complementary sensitivity function. The loop transfer function $L(s) = P(s)K(s)$ is first computed:\n$L(s) = \\left(\\dfrac{5}{(s+1)(s+5)}\\right) \\left(k\\dfrac{s+1}{0.1s+1}\\right) = \\dfrac{5k}{(s+5)(0.1s+1)}$\nThe pole-zero cancellation at $s=-1$ is noted. Since the cancelled pole is stable, internal stability is maintained provided the simplified closed-loop system is stable.\n\nSubstituting $L(s)$ into the expression for $T(s)$:\n$T(s) = -\\dfrac{\\frac{5k}{(s+5)(0.1s+1)}}{1 + \\frac{5k}{(s+5)(0.1s+1)}} = -\\dfrac{5k}{(s+5)(0.1s+1) + 5k}$\nExpanding the denominator polynomial:\n$(s+5)(0.1s+1) + 5k = 0.1s^2 + s + 0.5s + 5 + 5k = 0.1s^2 + 1.5s + 5(1+k)$\n\nTo normalize the leading coefficient of the denominator to unity, we multiply the numerator and denominator by $10$:\n$T(s) = -\\dfrac{50k}{s^2 + 15s + 50(1+k)}$\n\n**Step 2: Stability and Output Variance**\n\nThe stability of the closed-loop system is determined by the roots of its characteristic polynomial, which is the denominator of $T(s)$: $s^2 + 15s + 50(1+k) = 0$. For a second-order polynomial, stability (all roots in the left-half plane) is guaranteed if all coefficients are positive. Given $k \\ge 0$, the coefficients $1$, $15$, and $50(1+k)$ are all positive. Thus, the closed-loop system is internally stable for all non-negative values of gain $k$.\n\nThe problem states that for a strictly proper, stable LTI system with transfer function $G(s)$ excited by unit-intensity white noise, the steady-state variance of the output is equal to the squared $\\mathcal{H}_2$ norm of the system, $\\sigma^2 = \\lVert G \\rVert_2^2$. The transfer function $T(s)$ is strictly proper and stable.\n\nFor a general second-order system $G(s) = \\dfrac{b_0}{s^2 + a_1s + a_0}$, the squared $\\mathcal{H}_2$ norm is given by the formula $\\lVert G \\rVert_2^2 = \\dfrac{b_0^2}{2a_1a_0}$.\nFor our transfer function $T(s)$, the parameters are:\n$b_0 = -50k$\n$a_1 = 15$\n$a_0 = 50(1+k)$\n\nThe output variance $\\sigma_y^2$ as a function of the gain $k$ is:\n$\\sigma_y^2(k) = \\lVert T \\rVert_2^2 = \\dfrac{(-50k)^2}{2(15)(50(1+k))} = \\dfrac{2500k^2}{1500(1+k)} = \\dfrac{5k^2}{3(1+k)}$\n\nThe noise amplification factor is the $\\mathcal{H}_2$ norm itself: $\\lVert T \\rVert_2(k) = \\sqrt{\\sigma_y^2(k)} = k\\sqrt{\\dfrac{5}{3(1+k)}}$ for $k \\ge 0$.\n\n**Step 3: Gain Adjustment Algorithm**\n\nWe must find the largest gain $k_{\\text{adj}} \\in [0, k]$ that ensures the variance constraint $\\sigma_y^2(k_{\\text{adj}}) \\le V_{\\max}$. To do this, we analyze the relationship between $\\sigma_y^2$ and $k$. The derivative of the variance with respect to $k$ is:\n$\\dfrac{d\\sigma_y^2}{dk} = \\dfrac{5}{3}\\dfrac{d}{dk}\\left(\\dfrac{k^2}{1+k}\\right) = \\dfrac{5}{3}\\dfrac{2k(1+k) - k^2}{(1+k)^2} = \\dfrac{5}{3}\\dfrac{k^2+2k}{(1+k)^2}$\nFor $k > 0$, this derivative is strictly positive. Therefore, $\\sigma_y^2(k)$ is a monotonically increasing function of $k$ for $k \\ge 0$.\n\nThis monotonicity dictates the following logic for a given input pair $(k, V_{\\max})$:\n1.  Calculate the variance at the given gain $k$: $\\sigma_y^2(k) = \\dfrac{5k^2}{3(1+k)}$.\n2.  Compare this variance to the maximum allowed variance $V_{\\max}$.\n    - If $\\sigma_y^2(k) \\le V_{\\max}$, the constraint is already satisfied. The largest possible gain in the allowed range $[0, k]$ is $k$ itself. Thus, $k_{\\text{adj}} = k$. The resulting variance is $\\sigma_y^2(k)$.\n    - If $\\sigma_y^2(k) > V_{\\max}$, the gain $k$ is too high. Due to monotonicity, the largest gain that satisfies the constraint is a value $k_{\\text{adj}} < k$ for which the variance is exactly equal to the limit, i.e., $\\sigma_y^2(k_{\\text{adj}}) = V_{\\max}$. We must solve this equation for $k_{\\text{adj}}$.\n\nThe equation to solve is:\n$\\dfrac{5k_{\\text{adj}}^2}{3(1+k_{\\text{adj}})} = V_{\\max}$\n$5k_{\\text{adj}}^2 = 3V_{\\max}(1+k_{\\text{adj}})$\n$5k_{\\text{adj}}^2 - (3V_{\\max})k_{\\text{adj}} - 3V_{\\max} = 0$\n\nThis is a quadratic equation for $k_{\\text{adj}}$. Applying the quadratic formula and selecting the non-negative root (since $k_{\\text{adj}} \\ge 0$ and $V_{\\max} \\ge 0$):\n$k_{\\text{adj}} = \\dfrac{3V_{\\max} + \\sqrt{(3V_{\\max})^2 - 4(5)(-3V_{\\max})}}{2(5)} = \\dfrac{3V_{\\max} + \\sqrt{9V_{\\max}^2 + 60V_{\\max}}}{10}$\nIn this case, the resulting variance is, by construction, $\\sigma_y^2(k_{\\text{adj}}) = V_{\\max}$.\n\nThe special case $V_{\\max}=0$ implies, from the formula for variance, that $k=0$ is the only non-negative solution. The problem statement explicitly directs that if $V_{\\max}=0$, we must set $k_{\\text{adj}}=0$.\n\nThe implementation will follow this logic for each test case.\nFor each pair $(k, V_{\\max})$, the program will compute:\n1. The initial noise amplification factor for the given $k$: $\\lVert T \\rVert_2(k) = \\sqrt{\\frac{5k^2}{3(1+k)}}$.\n2. The adjusted gain $k_{\\text{adj}}$ using the logic above.\n3. The resulting output variance at the adjusted gain: $\\sigma_y^2(k_{\\text{adj}})$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the control theory problem for a suite of test cases.\n\n    The solution involves:\n    1. Calculating the initial noise amplification (H2 norm) for a given gain k.\n    2. Determining the maximum adjusted gain k_adj <= k that satisfies a variance constraint.\n    3. Computing the output variance at k_adj.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (k_initial, V_max).\n    test_cases = [\n        (0.5, 10.0),\n        (2.0, 1.0),\n        (0.75, 0.5357142857142857),\n        (1.0, 0.0001),\n        (3.0, 0.0),\n    ]\n\n    results = []\n    \n    # Process each test case\n    for k_in, v_max in test_cases:\n        # Step 1: Compute initial noise amplification factor\n        # The output variance is sigma_y^2 = (5 * k^2) / (3 * (1 + k))\n        # The noise amplification factor is the H2 norm, which is sqrt(sigma_y^2)\n        if k_in == 0:\n            initial_variance = 0.0\n        else:\n            initial_variance = (5.0 * k_in**2) / (3.0 * (1.0 + k_in))\n        \n        h2_norm = np.sqrt(initial_variance)\n\n        # Step 2  3: Compute adjusted gain k_adj and final variance\n        \n        # Handle special case as per problem statement\n        if v_max == 0.0:\n            k_adj = 0.0\n            final_variance = 0.0\n        # If initial variance is within the limit, no adjustment is needed\n        elif initial_variance = v_max:\n            k_adj = k_in\n            final_variance = initial_variance\n        # If initial variance exceeds the limit, we must reduce the gain\n        else:\n            # We solve the quadratic equation 5*k^2 - (3*V_max)*k - 3*V_max = 0 for k.\n            # k_adj is the positive root of this equation.\n            a = 5.0\n            b = -3.0 * v_max\n            c = -3.0 * v_max\n            \n            discriminant = np.sqrt(b**2 - 4.0 * a * c)\n            k_adj = (-b + discriminant) / (2.0 * a)\n            \n            # The resulting variance is V_max by construction\n            final_variance = v_max\n            \n        results.append([h2_norm, k_adj, final_variance])\n\n    # Format the final output string exactly as required\n    formatted_cases = []\n    for case_result in results:\n        # case_result is a list [h2_norm, k_adj, final_variance]\n        # Format each number to six decimal places\n        formatted_numbers = [f\"{num:.6f}\" for num in case_result]\n        formatted_cases.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    final_output_string = f\"[{','.join(formatted_cases)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "2708252"}, {"introduction": "Real-world control problems rarely have a single objective; they require balancing performance, like tracking, with robustness, like insensitivity to noise and model uncertainty. This advanced synthesis problem introduces you to the powerful framework of mixed-sensitivity $\\mathcal{H}_{\\infty}$ control, where you will numerically optimize a controller to shape the system's response across the frequency spectrum [@problem_id:2708282]. Tackling this challenge provides a direct experience with the trade-offs at the heart of robust feedback design.", "problem": "You are asked to implement a complete, runnable program that synthesizes a continuous-time feedback controller based on feedback principles and evaluates weighted closed-loop performance in the sense of the Hardy space infinity norm ($\\mathcal{H}_{\\infty}$). The plant is linear time-invariant (LTI), and the performance objective is defined via weighted sensitivity and complementary sensitivity functions.\n\nGiven the LTI single-input single-output plant\n$$\nP(s)=\\frac{1}{s(s+1)},\n$$\nand weighting functions\n$$\nW_{1}(s)=\\frac{s/0.1+1}{s/10+1},\\qquad W_{3}(s)=\\frac{s/100+1}{s/1000+1},\n$$\nyou must synthesize a stabilizing controller chosen from the strictly proper lead-lag family\n$$\nK(s)=k\\frac{s+z}{s+p},\n$$\nwith $k0$, $z0$, $p0$, to minimize the performance index\n$$\n\\gamma=\\max\\left(\\lVert W_{1}S\\rVert_{\\infty},\\,\\lVert W_{3}T\\rVert_{\\infty}\\right),\n$$\nwhere the sensitivity function $S$ and the complementary sensitivity function $T$ are defined by the closed-loop relations\n$$\nS(s)=\\frac{1}{1+L(s)},\\qquad T(s)=\\frac{L(s)}{1+L(s)},\\qquad L(s)=P(s)K(s).\n$$\nFor a given frequency $\\omega$ in radians per second, denote $j\\omega$ as the imaginary axis evaluation. For a rational function $G(s)$, use $G(j\\omega)$ to compute magnitude responses. The $\\mathcal{H}_{\\infty}$ norm of a stable proper transfer function $G$ is\n$$\n\\lVert G\\rVert_{\\infty}=\\sup_{\\omega\\in\\mathbb{R}}\\sigma_{\\max}\\bigl(G(j\\omega)\\bigr),\n$$\nwhich for the single-input single-output case reduces to the supremum over $\\omega$ of the magnitude $\\lvert G(j\\omega)\\rvert$.\n\nYour program must:\n1. Search over $k$, $z$, $p$ to find a stabilizing controller $K(s)$ that minimizes $\\gamma$ as defined above, based on a frequency sweep approximation of the $\\mathcal{H}_{\\infty}$ norms over a sufficiently dense logarithmic grid of $\\omega$ expressed in radians per second. You must explicitly verify closed-loop stability by checking that all poles of the closed-loop characteristic polynomial have strictly negative real parts.\n2. Once the best controller parameters $(k^{\\star},z^{\\star},p^{\\star})$ are found, compute and report the achieved value of $\\gamma$, as well as the two constituent norms $\\lVert W_{1}S\\rVert_{\\infty}$ and $\\lVert W_{3}T\\rVert_{\\infty}$, using the same frequency grid.\n\nFundamental base that you must use:\n- Feedback interconnection definitions: $S(s)=\\frac{1}{1+L(s)}$, $T(s)=\\frac{L(s)}{1+L(s)}$, $L(s)=P(s)K(s)$.\n- The definition of the $\\mathcal{H}_{\\infty}$ norm as the supremum over frequency of the magnitude for single-input single-output systems.\n- Closed-loop stability test via the roots of the characteristic polynomial being strictly in the open left half-plane.\n\nYour search must be fully numeric, without using symbolic algebra or any control-specific library functions for synthesis. Frequency should be in radians per second.\n\nTest Suite and required outputs:\n- Use the fixed plant $P(s)$ and weights $W_{1}(s)$, $W_{3}(s)$ as specified above.\n- Evaluate three target levels for the performance bound $\\gamma_{\\text{target}}$: $[1.5,\\,1.2,\\,1.05]$ (all values are unitless).\n- For each $\\gamma_{\\text{target}}$ in the test suite, the program must determine whether the best synthesized controller satisfies $\\gamma  \\gamma_{\\text{target}}$ and report the tuple consisting of the boolean feasibility, the achieved $\\gamma$, the achieved $\\lVert W_{1}S\\rVert_{\\infty}$, and the achieved $\\lVert W_{3}T\\rVert_{\\infty}$, in that order.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each element is itself a list of the form $[\\text{feasible},\\gamma,\\lVert W_{1}S\\rVert_{\\infty},\\lVert W_{3}T\\rVert_{\\infty}]$.\n- For example, an output with three cases should look like: $[[\\text{True},1.23,1.10,1.08],[\\text{True},1.18,1.05,1.12],[\\text{False},1.34,1.30,1.20]]$.\n- All frequency computations must be carried out in radians per second, and no physical units are required for the final outputs.\n\nYour final answer must be a single, complete, runnable Python program that performs the synthesis by numeric search and prints only the single required line in the exact format above. No user input or external files are allowed. The answer must be self-contained and reproducible.", "solution": "The problem as stated is a valid exercise in control systems engineering. It is scientifically grounded, well-posed for numerical solution, and all terms and objectives are defined with mathematical precision. The task is to perform a numerical synthesis of a fixed-structure controller to satisfy a mixed-sensitivity $\\mathcal{H}_{\\infty}$ performance objective. We shall proceed with the solution.\n\nThe core of the problem is to find the parameters $(k, z, p)$ for a lead-lag controller\n$$\nK(s) = k\\frac{s+z}{s+p}\n$$\nwith $k0$, $z0$, and $p0$, which minimizes the performance index $\\gamma$. This index is defined as the maximum of two weighted $\\mathcal{H}_{\\infty}$ norms:\n$$\n\\gamma = \\max\\left(\\lVert W_{1}S\\rVert_{\\infty}, \\lVert W_{3}T\\rVert_{\\infty}\\right)\n$$\nThe system consists of a single-input single-output plant $P(s)$, for which the sensitivity function $S(s)$ and complementary sensitivity function $T(s)$ are given by the standard feedback relations:\n$$\nS(s) = \\frac{1}{1+L(s)}, \\quad T(s) = \\frac{L(s)}{1+L(s)}\n$$\nwhere $L(s) = P(s)K(s)$ is the open-loop transfer function. The plant and weighting functions are specified as:\n$$\nP(s) = \\frac{1}{s(s+1)}, \\quad W_{1}(s)=\\frac{s/0.1+1}{s/10+1}, \\quad W_{3}(s)=\\frac{s/100+1}{s/1000+1}\n$$\n\nA mandatory prerequisite for any solution is the stability of the closed-loop system. The characteristic polynomial of the closed-loop system is the numerator of $1+L(s)$. We derive this polynomial as:\n$$\n1+L(s) = 1 + \\frac{k(s+z)}{s(s+1)(s+p)} = \\frac{s(s+1)(s+p) + k(s+z)}{s(s+1)(s+p)}\n$$\nThe characteristic polynomial is therefore $\\Delta(s) = s^3 + (p+1)s^2 + (p+k)s + kz$. For a third-order polynomial $a_3s^3+a_2s^2+a_1s+a_0=0$, the Routh-Hurwitz stability criterion requires all coefficients to be positive and that $a_2 a_1  a_3 a_0$. Given the constraints $k0$, $z0$, $p0$, all coefficients $a_3=1$, $a_2=p+1$, $a_1=p+k$, and $a_0=kz$ are strictly positive. The stability condition thus simplifies to the single inequality:\n$$\n(p+1)(p+k)  kz\n$$\nAny set of parameters $(k, z, p)$ that violates this condition results in an unstable controller and is immediately discarded.\n\nThe problem is addressed through numerical optimization. For a single-input single-output system, the $\\mathcal{H}_{\\infty}$ norm of a stable transfer function $G(s)$ is the supremum of its magnitude along the imaginary axis:\n$$\n\\lVert G \\rVert_{\\infty} = \\sup_{\\omega \\in \\mathbb{R}} |G(j\\omega)|\n$$\nThis supremum is approximated numerically by evaluating $|G(j\\omega)|$ over a dense, logarithmically spaced grid of frequencies $\\omega$ and finding the maximum value.\n\nThe synthesis task is formulated as the following optimization problem:\n$$\n\\min_{k,z,p} \\gamma(k,z,p) \\quad \\text{subject to} \\quad k0, z0, p0 \\quad \\text{and} \\quad (p+1)(p+k)  kz\n$$\nTo manage the positivity constraints, a logarithmic change of variables is employed: $k=10^{x_1}$, $z=10^{x_2}$, $p=10^{x_3}$. The optimization is then performed over the unconstrained real variables $(x_1, x_2, x_3)$. An objective function is constructed which takes these logarithmic parameters, calculates the corresponding $(k, z, p)$, checks for stability, and if the system is stable, computes and returns $\\gamma$. If the system is unstable, the function returns an infinite penalty to guide the optimizer away from such regions.\n\nA derivative-free optimization algorithm, specifically the Nelder-Mead method provided by `scipy.optimize.minimize`, is used to find the optimal parameters. To increase the probability of finding a globally optimal solution and avoiding poor local minima, a multi-start strategy is implemented. The optimization routine is executed from several distinct initial points in the parameter space, and the best result obtained is taken as the final solution.\n\nOnce the optimal parameters $(k^{\\star}, z^{\\star}, p^{\\star})$ and the minimal performance index $\\gamma^{\\star}$ are determined, the final step involves evaluating this result against the three specified target values $\\gamma_{\\text{target}} \\in \\{1.5, 1.2, 1.05\\}$. For each target, we determine if the achieved performance is better (i.e., $\\gamma^{\\star}  \\gamma_{\\text{target}}$) and report the boolean feasibility along with the achieved $\\gamma^{\\star}$ and the constituent norms $\\lVert W_{1}S\\rVert_{\\infty}$ and $\\lVert W_{3}T\\rVert_{\\infty}$. The final output is structured as a list of these evaluation tuples, precisely following the specified format.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport sys\n\n# Suppress runtime warnings that can occur with complex numbers (e.g., divide by zero in L).\n# The optimization logic handles these cases by returning np.inf.\nnp.seterr(all='ignore')\n\ndef solve():\n    \"\"\"\n    Synthesizes a feedback controller by minimizing a mixed-sensitivity H-infinity\n    performance index and evaluates the result against specified targets.\n    \"\"\"\n    # Define the target performance levels for evaluation from the problem statement.\n    gamma_targets = [1.5, 1.2, 1.05]\n\n    # --- System and Optimization Setup ---\n\n    # Define a dense logarithmic frequency grid for H-infinity norm approximation.\n    # The range covers all relevant dynamics of the plant and weights.\n    omega = np.logspace(-3, 4, 5000)\n    s = 1j * omega\n\n    # Pre-calculate frequency responses of fixed system components.\n    # Plant: P(s) = 1 / (s * (s + 1))\n    P_s = 1 / (s * (s + 1))\n    # Weight 1: W1(s) = (s/0.1 + 1) / (s/10 + 1)\n    W1_s = (s / 0.1 + 1) / (s / 10 + 1)\n    # Weight 3: W3(s) = (s/100 + 1) / (s/1000 + 1)\n    W3_s = (s / 100 + 1) / (s / 1000 + 1)\n\n    # Cache for the optimization to avoid re-computation for the same parameters.\n    cost_cache = {}\n\n    def cost_function(log_params):\n        \"\"\"\n        Calculates the performance index gamma for a given set of controller parameters.\n        Parameters are provided in log10 scale to enforce positivity and handle wide ranges.\n        \"\"\"\n        params_tuple = tuple(log_params)\n        if params_tuple in cost_cache:\n            return cost_cache[params_tuple]\n\n        log_k, log_z, log_p = log_params\n        k = 10**log_k\n        z = 10**log_z\n        p = 10**log_p\n\n        # --- Stability Check ---\n        # Using the Routh-Hurwitz criterion for the 3rd-order characteristic polynomial:\n        # delta(s) = s^3 + (p+1)s^2 + (p+k)s + kz\n        # Condition for stability: (p+1)*(p+k)  k*z\n        if (p + 1) * (p + k) = k * z:\n            return np.inf  # Return infinity for unstable controllers\n\n        # --- Performance Calculation ---\n        # Controller: K(s) = k * (s + z) / (s + p)\n        K_s = k * (s + z) / (s + p)\n        \n        L_s = P_s * K_s\n        # Add a small epsilon to prevent division by zero if 1+L=0 at some frequency\n        S_s = 1 / (1 + L_s + 1e-12)\n        T_s = L_s / (1 + L_s + 1e-12)\n\n        # Approximate H-infinity norms by finding the maximum magnitude over the frequency grid.\n        norm_w1s = np.max(np.abs(W1_s * S_s))\n        norm_w3t = np.max(np.abs(W3_s * T_s))\n        \n        gamma = np.max([norm_w1s, norm_w3t])\n        \n        cost_cache[params_tuple] = gamma\n        return gamma\n\n    # --- Optimization using a Multi-Start Strategy ---\n    # This mitigates the risk of converging to a poor local minimum.\n    # Initial guesses for [log10(k), log10(z), log10(p)]\n    initial_guesses = [\n        [1.0, 0.0, 1.0],    # k=10, z=1, p=10 (Lead)\n        [0.0, -1.0, 1.0],   # k=1, z=0.1, p=10 (Lead)\n        [1.0, 1.0, 0.0],    # k=10, z=10, p=1 (Lag)\n        [2.0, 0.5, 2.5],    # k=100, z=~3.16, p=~316 (Lead)\n        [1.5, -0.5, 2.0],   # k=~31.6, z=~0.316, p=100 (Lead)\n    ]\n    \n    best_result = None\n    min_gamma = np.inf\n\n    for x0 in initial_guesses:\n        res = minimize(\n            cost_function,\n            x0,\n            method='Nelder-Mead',\n            options={'maxiter': 1500, 'adaptive': True}\n        )\n        if res.success and res.fun  min_gamma:\n            min_gamma = res.fun\n            best_result = res\n\n    # --- Final Evaluation ---\n    # Once the best controller is found, evaluate its performance metrics.\n    if best_result is None or not np.isfinite(min_gamma):\n        # Fallback if no stable solution is found\n        achieved_gamma = np.inf\n        achieved_norm_w1s = np.inf\n        achieved_norm_w3t = np.inf\n    else:\n        log_k_opt, log_z_opt, log_p_opt = best_result.x\n        k_opt, z_opt, p_opt = 10**log_k_opt, 10**log_z_opt, 10**log_p_opt\n\n        K_s_opt = k_opt * (s + z_opt) / (s + p_opt)\n        L_s_opt = P_s * K_s_opt\n        S_s_opt = 1 / (1 + L_s_opt + 1e-12)\n        T_s_opt = L_s_opt / (1 + L_s_opt + 1e-12)\n\n        achieved_norm_w1s = np.max(np.abs(W1_s * S_s_opt))\n        achieved_norm_w3t = np.max(np.abs(W3_s * T_s_opt))\n        achieved_gamma = np.max([achieved_norm_w1s, achieved_norm_w3t])\n\n    # --- Format Output ---\n    # Assemble the results for each target gamma.\n    results_list = []\n    for target in gamma_targets:\n        feasible = bool(achieved_gamma  target)\n        results_list.append([\n            feasible, \n            achieved_gamma, \n            achieved_norm_w1s, \n            achieved_norm_w3t\n        ])\n    \n    # Construct the output string manually to match the required format exactly\n    # (no spaces between list elements, True/False capitalized).\n    case_strings = []\n    for case in results_list:\n        case_str = f\"[{case[0]},{case[1]},{case[2]},{case[3]}]\"\n        case_strings.append(case_str)\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "2708282"}]}