{"hands_on_practices": [{"introduction": "Understanding system zeros is fundamental to control design. While often introduced as the roots of a transfer function's numerator, a more general definition arises from the state-space representation. This practice provides a concrete exercise in calculating transmission zeros for a Single-Input Single-Output (SISO) system using both the transfer function $G(s)$ and the Rosenbrock system matrix, highlighting their equivalence for minimal realizations [@problem_id:2751989].", "problem": "Consider the continuous-time, Single-Input Single-Output (SISO) linear time-invariant state-space system given by\n$$\n\\dot{x}(t)=A\\,x(t)+B\\,u(t),\\qquad y(t)=C\\,x(t)+D\\,u(t),\n$$\nwith\n$$\nA=\\begin{bmatrix}0 & 1\\\\ -2 & -3\\end{bmatrix},\\quad B=\\begin{bmatrix}0\\\\ 1\\end{bmatrix},\\quad C=\\begin{bmatrix}1 & 0\\end{bmatrix},\\quad D=0.\n$$\nTransmission zeros are defined as the complex numbers $s=z$ for which the Rosenbrock system matrix loses rank. For a SISO system, this is equivalently characterized by the roots of the determinant of the Rosenbrock system matrix\n$$\nR(s)=\\begin{bmatrix}sI-A & -B\\\\ C & D\\end{bmatrix}.\n$$\n(a) Using this definition, compute all finite transmission zeros of the given realization by analyzing $R(s)$. Report your result as a set. If there are no finite transmission zeros, report the answer as the empty-set symbol $\\,\\varnothing\\,$.\n\n(b) Independently derive the transfer function $G(s)$ from the given realization using the fundamental relation $G(s)=C\\,(sI-A)^{-1}B+D$, and deduce its finite zeros from the numerator of $G(s)$. Explain why this deduction agrees with part (a) for a minimal realization.\n\nYour final answer must be the set of finite transmission zeros. If there are none, write $\\,\\varnothing\\,$. No rounding is required. No units are required.", "solution": "The problem requires the computation of finite transmission zeros for a given state-space realization using two distinct methods and a subsequent explanation of their agreement. I will first validate the problem statement.\n\nThe givens are:\nThe state-space model:\n$$\n\\dot{x}(t)=A\\,x(t)+B\\,u(t)\n$$\n$$\ny(t)=C\\,x(t)+D\\,u(t)\n$$\nThe system matrices:\n$$\nA=\\begin{bmatrix}0 & 1\\\\ -2 & -3\\end{bmatrix},\\quad B=\\begin{bmatrix}0\\\\ 1\\end{bmatrix},\\quad C=\\begin{bmatrix}1 & 0\\end{bmatrix},\\quad D=0\n$$\nThe definition of transmission zeros via the Rosenbrock system matrix:\n$$\nR(s)=\\begin{bmatrix}sI-A & -B\\\\ C & D\\end{bmatrix}\n$$\nThe condition for transmission zeros $s=z$: the loss of rank of $R(s)$, or equivalently for a Single-Input Single-Output (SISO) system, the roots of $\\det(R(s)) = 0$.\nThe definition of the transfer function from a state-space realization:\n$$\nG(s)=C\\,(sI-A)^{-1}B+D\n$$\n\nThe problem is scientifically grounded in the principles of linear control theory. It is well-posed, providing all necessary matrices and definitions for a unique solution. The language is objective and precise. The dimensions of the matrices ($A$ is $2 \\times 2$, $B$ is $2 \\times 1$, $C$ is $1 \\times 2$, and $D$ is $1 \\times 1$) are consistent for a SISO system with two state variables. The problem is a standard exercise and does not violate any of the invalidity criteria. Therefore, the problem is valid and I will proceed with the solution.\n\nPart (a): Computation of transmission zeros using the Rosenbrock matrix.\nThe Rosenbrock system matrix is defined as $R(s) = \\begin{bmatrix}sI-A & -B\\\\ C & D\\end{bmatrix}$. First, we construct the block $sI-A$:\n$$\nsI-A = s\\begin{bmatrix}1 & 0\\\\ 0 & 1\\end{bmatrix} - \\begin{bmatrix}0 & 1\\\\ -2 & -3\\end{bmatrix} = \\begin{bmatrix}s & -1\\\\ 2 & s+3\\end{bmatrix}\n$$\nThe other blocks are $-B = \\begin{bmatrix}0\\\\ -1\\end{bmatrix}$, $C = \\begin{bmatrix}1 & 0\\end{bmatrix}$, and $D = [0]$. Assembling the Rosenbrock matrix $R(s)$:\n$$\nR(s) = \\begin{bmatrix} s & -1 & 0 \\\\ 2 & s+3 & -1 \\\\ 1 & 0 & 0 \\end{bmatrix}\n$$\nThe transmission zeros are the values of $s$ for which $\\det(R(s)) = 0$. We compute the determinant of the $3 \\times 3$ matrix $R(s)$. Cofactor expansion along the third row is most efficient due to the two zero entries:\n$$\n\\det(R(s)) = 1 \\cdot \\det\\begin{pmatrix} -1 & 0 \\\\ s+3 & -1 \\end{pmatrix} - 0 \\cdot \\det\\begin{pmatrix} s & 0 \\\\ 2 & -1 \\end{pmatrix} + 0 \\cdot \\det\\begin{pmatrix} s & -1 \\\\ 2 & s+3 \\end{pmatrix}\n$$\n$$\n\\det(R(s)) = 1 \\cdot ((-1)(-1) - (0)(s+3)) = 1 \\cdot (1 - 0) = 1\n$$\nThe determinant of the Rosenbrock system matrix is $\\det(R(s)) = 1$. The equation for the transmission zeros is $\\det(R(s)) = 0$, which becomes $1=0$. This equation has no solution for $s \\in \\mathbb{C}$. Consequently, the system has no finite transmission zeros. The set of transmission zeros is the empty set, $\\varnothing$.\n\nPart (b): Derivation of the transfer function and its zeros.\nThe transfer function is given by the formula $G(s) = C(sI-A)^{-1}B + D$. We have already computed $sI-A$. We now require its inverse. The determinant of $sI-A$ is:\n$$\n\\det(sI-A) = s(s+3) - (-1)(2) = s^2+3s+2 = (s+1)(s+2)\n$$\nThe inverse is:\n$$\n(sI-A)^{-1} = \\frac{1}{\\det(sI-A)} \\text{adj}(sI-A) = \\frac{1}{s^2+3s+2} \\begin{bmatrix}s+3 & 1\\\\ -2 & s\\end{bmatrix}\n$$\nNow, substitute this into the formula for $G(s)$, with $D=0$:\n$$\nG(s) = \\begin{bmatrix}1 & 0\\end{bmatrix} \\left( \\frac{1}{s^2+3s+2} \\begin{bmatrix}s+3 & 1\\\\ -2 & s\\end{bmatrix} \\right) \\begin{bmatrix}0\\\\ 1\\end{bmatrix}\n$$\nScalar multiplication commutes with matrix multiplication, so we can write:\n$$\nG(s) = \\frac{1}{s^2+3s+2} \\begin{bmatrix}1 & 0\\end{bmatrix} \\begin{bmatrix}s+3 & 1\\\\ -2 & s\\end{bmatrix} \\begin{bmatrix}0\\\\ 1\\end{bmatrix}\n$$\nPerform the matrix multiplications from left to right:\n$$\n\\begin{bmatrix}1 & 0\\end{bmatrix} \\begin{bmatrix}s+3 & 1\\\\ -2 & s\\end{bmatrix} = \\begin{bmatrix}1 \\cdot (s+3) + 0 \\cdot (-2) & 1 \\cdot 1 + 0 \\cdot s\\end{bmatrix} = \\begin{bmatrix}s+3 & 1\\end{bmatrix}\n$$\n$$\nG(s) = \\frac{1}{s^2+3s+2} \\begin{bmatrix}s+3 & 1\\end{bmatrix} \\begin{bmatrix}0\\\\ 1\\end{bmatrix} = \\frac{1}{s^2+3s+2} ((s+3) \\cdot 0 + 1 \\cdot 1) = \\frac{1}{s^2+3s+2}\n$$\nThe finite zeros of a transfer function are the roots of its numerator polynomial. In this case, the numerator polynomial is $N(s)=1$. The equation $N(s)=0$ is $1=0$, which has no solutions. Thus, the transfer function $G(s)$ has no finite zeros. This result is identical to that of part (a).\n\nExplanation of agreement:\nThe agreement between the two methods is not a coincidence. For a general SISO system, the determinant of the Rosenbrock matrix is related to the transfer function by the identity:\n$$\n\\det(R(s)) = \\det(sI-A) \\cdot G(s)\n$$\nWhen $G(s)$ is written in rational form as $G(s) = \\frac{N(s)}{P(s)}$, where $P(s) = \\det(sI-A)$ is the characteristic polynomial of the matrix $A$, the identity implies $\\det(R(s)) = P(s) \\frac{N(s)}{P(s)}$.\nThis simplification to $\\det(R(s)) = N(s)$ is valid if and only if there are no common factors between $P(s)$ and the polynomial that results from the calculation of $C\\,\\text{adj}(sI-A)B$. Such common factors, if they exist, represent pole-zero cancellations and correspond to system modes that are either uncontrollable or unobservable. A state-space realization for which no such cancellations occur is called a minimal realization.\nWe must verify that the given realization is minimal by checking for controllability and observability.\nControllability: The controllability matrix is $\\mathcal{C} = \\begin{bmatrix} B & AB \\end{bmatrix}$.\n$$\nAB = \\begin{bmatrix}0 & 1\\\\ -2 & -3\\end{bmatrix} \\begin{bmatrix}0\\\\ 1\\end{bmatrix} = \\begin{bmatrix}1\\\\ -3\\end{bmatrix}\n$$\n$$\n\\mathcal{C} = \\begin{bmatrix}0 & 1\\\\ 1 & -3\\end{bmatrix}\n$$\n$\\det(\\mathcal{C}) = (0)(-3) - (1)(1) = -1 \\neq 0$. The rank of $\\mathcal{C}$ is $2$, which is equal to the dimension of the state space ($n=2$). The system is controllable.\nObservability: The observability matrix is $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix}$.\n$$\nCA = \\begin{bmatrix}1 & 0\\end{bmatrix} \\begin{bmatrix}0 & 1\\\\ -2 & -3\\end{bmatrix} = \\begin{bmatrix}0 & 1\\end{bmatrix}\n$$\n$$\n\\mathcal{O} = \\begin{bmatrix}1 & 0\\\\ 0 & 1\\end{bmatrix} = I_2\n$$\n$\\det(\\mathcal{O}) = 1 \\neq 0$. The rank of $\\mathcal{O}$ is $2=n$. The system is observable.\nSince the realization is both controllable and observable, it is minimal. For a minimal realization, the set of finite transmission zeros of the state-space model is identical to the set of finite zeros of the transfer function. Our calculations confirmed this fundamental principle: both methods showed that the set of finite zeros is empty.\nIn our case, $\\det(R(s)) = 1$ and $N(s) = 1$, so the identity $\\det(R(s)) = N(s)$ holds, as expected for a minimal realization. The absence of pole-zero cancellations in a minimal realization guarantees that the zeros of $G(s)$ accurately reflect the transmission zeros of the system.", "answer": "$$\n\\boxed{\\varnothing}\n$$", "id": "2751989"}, {"introduction": "While transfer functions are powerful tools, they can sometimes mask a system's true internal behavior. This exercise explores a critical scenario where a pole-zero cancellation in the transfer function hides an unstable internal mode, a classic pitfall in control systems analysis [@problem_id:2751968]. By working through this non-minimal realization, you will gain a deeper appreciation for the concepts of controllability, observability, and the crucial distinction between input-output stability and internal stability.", "problem": "Consider the single-input single-output Linear Time-Invariant (LTI) state-space realization\n$$\n\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t) + D u(t),\n$$\nwith\n$$\nA = \\begin{bmatrix} 1 & 0 \\\\ 0 & -2 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 1 & 1 \\end{bmatrix}, \\quad D = 0.\n$$\nYour tasks are:\n1. Starting from first principles (the definition of the transfer function of a state-space realization), derive the scalar transfer function $G(s)$.\n2. Express $G(s)$ over a common denominator and demonstrate that a factor at $s=1$ cancels between the numerator and denominator.\n3. Using the foundational definitions of controllability and observability, determine whether the mode at $s=1$ is controllable and/or observable for the given realization. Explain how this relates to the cancellation observed in the input-output map.\n4. Perform a minimal realization by isolating and removing any unreachable or unobservable subspaces via a similarity transformation, and identify the minimal state-space triple $(A_{\\min}, B_{\\min}, C_{\\min})$ that realizes the same $G(s)$.\n5. Confirm that the unstable mode at $s=1$ is absent from the minimal $G(s)$, while the given realization is not internally stable because of the eigenstructure of $A$.\n\nProvide as your final answer the minimal transfer function $G_{\\min}(s)$ as a single closed-form rational expression in $s$. No numerical rounding is required or permitted. Do not include any units in your final answer.", "solution": "The problem presented is a standard exercise in linear systems theory and is well-posed, scientifically grounded, and internally consistent. It provides all necessary information for a complete analysis. We shall proceed with the solution by systematically addressing each of the stated tasks.\n\nFirst, we validate the problem statement.\n\n**Step 1: Extract Givens**\nThe single-input single-output (SISO) Linear Time-Invariant (LTI) system is defined by the state-space equations:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n$$\ny(t) = C x(t) + D u(t)\n$$\nThe provided matrices are:\n$$\nA = \\begin{bmatrix} 1 & 0 \\\\ 0 & -2 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 1 & 1 \\end{bmatrix}, \\quad D = 0\n$$\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the fundamental principles of control theory, specifically state-space analysis, transfer functions, controllability, and observability. It is well-posed, as all matrices and initial conditions (implicitly zero for transfer function derivation) are provided, leading to a unique solution. The language is objective and precise. The problem does not violate any criteria for invalidity. It is a canonical example used to illustrate the relationship between state-space properties and input-output behavior.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with a complete solution.\n\n**Task 1: Derivation of the Transfer Function $G(s)$**\nThe transfer function $G(s)$ of a state-space realization is defined as the ratio of the Laplace transform of the output, $Y(s)$, to the Laplace transform of the input, $U(s)$, under the assumption of zero initial conditions, $x(0) = 0$.\nTaking the Laplace transform of the state and output equations gives:\n$$\nsX(s) = AX(s) + BU(s)\n$$\n$$\nY(s) = CX(s) + DU(s)\n$$\nFrom the first equation, we solve for $X(s)$:\n$$\n(sI - A)X(s) = BU(s)\n$$\n$$\nX(s) = (sI - A)^{-1}BU(s)\n$$\nSubstituting this into the output equation yields:\n$$\nY(s) = C(sI - A)^{-1}BU(s) + DU(s) = [C(sI - A)^{-1}B + D]U(s)\n$$\nThus, the transfer function is given by the formula:\n$$\nG(s) = C(sI - A)^{-1}B + D\n$$\nWe now substitute the given matrices. First, we compute the term $(sI - A)^{-1}$:\n$$\nsI - A = s\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} 1 & 0 \\\\ 0 & -2 \\end{bmatrix} = \\begin{bmatrix} s-1 & 0 \\\\ 0 & s+2 \\end{bmatrix}\n$$\nThe inverse is:\n$$\n(sI - A)^{-1} = \\frac{1}{\\det(sI - A)}\\text{adj}(sI - A) = \\frac{1}{(s-1)(s+2)}\\begin{bmatrix} s+2 & 0 \\\\ 0 & s-1 \\end{bmatrix}\n$$\nNow, we compute the full expression for $G(s)$, noting that $D=0$:\n$$\nG(s) = \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\left( \\frac{1}{(s-1)(s+2)}\\begin{bmatrix} s+2 & 0 \\\\ 0 & s-1 \\end{bmatrix} \\right) \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\n$$\n$$\nG(s) = \\frac{1}{(s-1)(s+2)} \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} s+2 & 0 \\\\ 0 & s-1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\n$$\n$$\nG(s) = \\frac{1}{(s-1)(s+2)} \\begin{bmatrix} 1 & 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ s-1 \\end{bmatrix}\n$$\n$$\nG(s) = \\frac{1 \\cdot 0 + 1 \\cdot (s-1)}{(s-1)(s+2)} = \\frac{s-1}{(s-1)(s+2)}\n$$\n\n**Task 2: Demonstration of Cancellation**\nThe derived transfer function is $G(s) = \\frac{s-1}{(s-1)(s+2)}$. It is immediately apparent that a common factor of $(s-1)$ exists in both the numerator and the denominator. This represents a pole-zero cancellation at $s=1$. After cancellation, the reduced or minimal transfer function is:\n$$\nG_{\\min}(s) = \\frac{1}{s+2}\n$$\n\n**Task 3: Controllability and Observability Analysis**\nThe poles of a state-space realization correspond to the eigenvalues of the matrix $A$. Since $A$ is diagonal, its eigenvalues are $\\lambda_1 = 1$ and $\\lambda_2 = -2$. We analyze the controllability and observability of the mode at $s=1$, which corresponds to $\\lambda_1$.\n\nWe use the Popov-Belevitch-Hautus (PBH) test. A mode associated with eigenvalue $\\lambda$ is controllable if and only if $\\text{rank}[\\lambda I - A \\ | \\ B] = n$, where $n$ is the dimension of the state space. Here, $n=2$.\n\nFor controllability of the mode at $\\lambda_1 = 1$:\n$$\n[1 \\cdot I - A \\ | \\ B] = \\begin{bmatrix} 1-1 & 0 & 0 \\\\ 0 & 1-(-2) & 1 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 3 & 1 \\end{bmatrix}\n$$\nThe rank of this matrix is $1$, which is less than $n=2$. Therefore, the mode at $s=1$ is **uncontrollable**.\n\nFor observability of the mode at $\\lambda_1 = 1$: A mode is observable if and only if $\\text{rank}\\begin{bmatrix} \\lambda I - A \\\\ C \\end{bmatrix} = n$.\n$$\n\\begin{bmatrix} 1 \\cdot I - A \\\\ C \\end{bmatrix} = \\begin{bmatrix} 1-1 & 0 \\\\ 0 & 1-(-2) \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 \\\\ 0 & 3 \\\\ 1 & 1 \\end{bmatrix}\n$$\nThe first two columns are linearly independent (e.g., the submatrix $\\begin{bmatrix} 0 & 3 \\\\ 1 & 1 \\end{bmatrix}$ has determinant $-3 \\neq 0$). The rank of this matrix is $2$, which is equal to $n$. Therefore, the mode at $s=1$ is **observable**.\n\nThe cancellation observed in the input-output map $G(s)$ is a direct consequence of this result. A pole-zero cancellation occurs in the transfer function if and only if the corresponding mode is either uncontrollable or unobservable (or both). In this case, the mode at $s=1$ is uncontrollable, so it does not appear in the external, input-output description of the system after reduction.\n\n**Task 4: Minimal Realization**\nTo find a minimal realization, we perform a Kalman decomposition to isolate the uncontrollable subspace. The given system is already in a diagonal form that separates the modes. Let the state vector be $x = [x_1 \\ x_2]^T$. The state equations are:\n$$\n\\dot{x}_1(t) = 1 \\cdot x_1(t) + 0 \\cdot u(t)\n$$\n$$\n\\dot{x}_2(t) = -2 \\cdot x_2(t) + 1 \\cdot u(t)\n$$\nThe output is:\n$$\ny(t) = 1 \\cdot x_1(t) + 1 \\cdot x_2(t)\n$$\nFrom these equations, it is clear that the state $x_1$, corresponding to the mode $\\lambda=1$, is not influenced by the input $u(t)$. This confirms its uncontrollability. The state $x_2$ is influenced by the input. The system is already in a canonical form that separates the controllable and uncontrollable parts. The partition is as follows:\n$x_{uc} = x_1$ (uncontrollable part)\n$x_c = x_2$ (controllable part)\n\nThe controllable subsystem, which constitutes the minimal realization, is described by the state $x_c = x_2$. The corresponding matrices are:\n$$\nA_{\\min} = A_{c} = [-2]\n$$\n$$\nB_{\\min} = B_{c} = [1]\n$$\n$$\nC_{\\min} = C_{c} = [1]\n$$\nThis is a first-order system with state-space triple $(A_{\\min}, B_{\\min}, C_{\\min}) = (-2, 1, 1)$. The transfer function of this minimal realization is:\n$$\nG_{\\min}(s) = C_{\\min}(s - A_{\\min})^{-1}B_{\\min} = 1 \\cdot (s - (-2))^{-1} \\cdot 1 = \\frac{1}{s+2}\n$$\nThis confirms the result from Task 2.\n\n**Task 5: Stability Confirmation**\nThe minimal transfer function $G_{\\min}(s) = \\frac{1}{s+2}$ has a single pole at $s=-2$. Since the real part of this pole is negative, the minimal realization is input-output stable (BIBO stable).\n\nHowever, the original realization is defined by the matrix $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & -2 \\end{bmatrix}$. The eigenvalues of $A$ are $\\lambda_1 = 1$ and $\\lambda_2 = -2$. Internal stability (or Lyapunov stability) of a system requires all eigenvalues of its $A$ matrix to have negative real parts. The presence of the eigenvalue $\\lambda_1=1$ in the right-half plane means the system is **internally unstable**.\n\nThe unstable mode at $s=1$ is absent from the minimal transfer function $G_{\\min}(s)$ because it is an uncontrollable mode. While it cannot be excited by the input, if there is a non-zero initial condition on the first state, $x_1(0) \\neq 0$, then the state trajectory will contain the term $x_1(t) = x_1(0)e^t$, which grows without bound. Thus, the full system is unstable despite having a stable input-output map.", "answer": "$$\n\\boxed{\\frac{1}{s+2}}\n$$", "id": "2751968"}, {"introduction": "Extending the concept of zeros from SISO to Multiple-Input Multiple-Output (MIMO) systems requires a more fundamental perspective. In the MIMO case, a transmission zero represents a complex frequency at which a specific input signal direction can be completely blocked from influencing the output. This hands-on practice delves into this physical interpretation, challenging you to find not only the transmission zero but also the corresponding \"zero direction\" and internal state that achieve this output-blocking phenomenon [@problem_id:2751942].", "problem": "Let a linear time-invariant multiple-input multiple-output system be given in state-space form by matrices $A \\in \\mathbb{R}^{3 \\times 3}$, $B \\in \\mathbb{R}^{3 \\times 2}$, $C \\in \\mathbb{R}^{2 \\times 3}$, and $D \\in \\mathbb{R}^{2 \\times 2}$, with transfer matrix $G(s) = C(sI - A)^{-1}B + D$. A complex number $z \\in \\mathbb{C}$ is a transmission zero if and only if there exist nonzero vectors $x \\in \\mathbb{C}^{3}$ and $u \\in \\mathbb{C}^{2}$ satisfying $(A - zI)x + Bu = 0$ and $Cx + Du = 0$, equivalently, if the Rosenbrock system matrix $P(s) = \\begin{bmatrix} A - sI & B \\\\ C & D \\end{bmatrix}$ has a nontrivial right kernel at $s = z$. A corresponding nonzero vector $u$ is called a right zero direction.\n\nConstruct explicitly a $2 \\times 2$ transfer function matrix $G(s)$ by specifying a minimal realization $(A,B,C,D)$ that meets the following criteria:\n- $G(s)$ is strictly proper.\n- $G(s)$ has a finite transmission zero $z \\in \\mathbb{R}$ with a nontrivial right zero direction.\n- The realization is $(A,B,C,D)$ with\n  $$\n  A = \\operatorname{diag}(-1,-2,-3), \\quad\n  B = \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix}, \\quad\n  C = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix}, \\quad\n  D = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}.\n  $$\n  \nTasks:\n- Using only fundamental definitions, construct $G(s)$ and determine the real transmission zero $z$ of this system by first principles.\n- Compute a nonzero input direction $u \\in \\mathbb{R}^{2}$ in the right kernel of the Rosenbrock system matrix $P(z)$ and the corresponding state vector $x \\in \\mathbb{R}^{3}$ that achieve exact output zeroing at $s = z$, namely, solve $(A - zI)x + Bu = 0$ and $Cx + Du = 0$.\n- Normalize $u$ so that its second component equals $1$.\n- Report your final answer as a single row vector containing, in order, the scalar zero $z$, the components of the normalized input direction $u$ and the corresponding state vector $x$, i.e., $(z, u_{1}, u_{2}, x_{1}, x_{2}, x_{3})$.\n\nNo rounding is required; provide exact values. Express the final answer with no units.", "solution": "The problem presented is a standard exercise in linear control theory and is well-defined. All necessary data and definitions are provided. The system matrices $A$, $B$, $C$, and $D$ are given, and the task is to find a transmission zero and its associated state and input vectors based on the provided definition. The premise is scientifically sound and the problem is self-contained and objective. The realization is stated to be minimal, which we have verified to be correct via standard controllability and observability tests; this ensures that an analysis based on the transfer function's determinant is consistent with the state-space definition of zeros. Therefore, the problem is valid and we may proceed with the solution.\n\nThe problem defines a transmission zero $z \\in \\mathbb{C}$ as a complex number for which there exist nonzero vectors $x \\in \\mathbb{C}^{3}$ and $u \\in \\mathbb{C}^{2}$ satisfying the system of equations:\n$$\n(A - zI)x + Bu = 0\n$$\n$$\nCx + Du = 0\n$$\nWe are given the matrices:\n$$\nA = \\begin{bmatrix} -1 & 0 & 0 \\\\ 0 & -2 & 0 \\\\ 0 & 0 & -3 \\end{bmatrix}, \\quad\nB = \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix}, \\quad\nC = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix}, \\quad\nD = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}.\n$$\nSince $D$ is the zero matrix, the second equation simplifies to $Cx = 0$. Let $x = \\begin{pmatrix} x_1 & x_2 & x_3 \\end{pmatrix}^T$. The condition $Cx = 0$ becomes:\n$$\n\\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n$$\nThis yields two linear equations:\n$1.$ $x_1 + x_3 = 0 \\implies x_1 = -x_3$\n$2.$ $x_2 + x_3 = 0 \\implies x_2 = -x_3$\n\nFor a nonzero solution vector $x$ to exist, we must have $x_3 \\neq 0$. The vector $x$ must therefore be of the form $x = k \\begin{pmatrix} -1 & -1 & 1 \\end{pmatrix}^T$ for some nonzero scalar $k \\in \\mathbb{R}$.\n\nNow, we substitute this structure of $x$ into the first defining equation, $(A - zI)x = -Bu$. Let us choose a basis vector for the nullspace of $C$ by setting $k=1$, so $x = \\begin{pmatrix} -1 & -1 & 1 \\end{pmatrix}^T$. Let $u = \\begin{pmatrix} u_1 & u_2 \\end{pmatrix}^T$.\nThe equation becomes:\n$$\n\\begin{bmatrix} -1-z & 0 & 0 \\\\ 0 & -2-z & 0 \\\\ 0 & 0 & -3-z \\end{bmatrix} \\begin{bmatrix} -1 \\\\ -1 \\\\ 1 \\end{bmatrix} = - \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ u_2 \\end{bmatrix}\n$$\nCarrying out the matrix-vector multiplications, we obtain:\n$$\n\\begin{bmatrix} 1+z \\\\ 2+z \\\\ -3-z \\end{bmatrix} = \\begin{bmatrix} -u_1 - u_2 \\\\ -u_1 + u_2 \\\\ -u_2 \\end{bmatrix}\n$$\nThis vector equality gives a system of $3$ linear equations in the $3$ unknowns $z$, $u_1$, and $u_2$:\n$1$. $1+z = -u_1 - u_2$\n$2$. $2+z = -u_1 + u_2$\n$3$. $-3-z = -u_2$\n\nFrom equation $(3)$, we find $u_2 = 3+z$.\nSubstituting this into equation $(2)$: $2+z = -u_1 + (3+z) \\implies 2 = -u_1 + 3 \\implies u_1 = 1$.\nNow, substituting $u_1=1$ and $u_2=3+z$ into equation $(1)$:\n$1+z = -(1) - (3+z) \\implies 1+z = -4-z \\implies 2z = -5 \\implies z = -\\frac{5}{2}$.\n\nThus, the real transmission zero is $z = -\\frac{5}{2}$.\nWith this value for $z$, we can find the components of the input direction vector $u$:\n$u_1 = 1$\n$u_2 = 3+z = 3 - \\frac{5}{2} = \\frac{1}{2}$.\nSo, an input zero direction is $u = \\begin{pmatrix} 1 & \\frac{1}{2} \\end{pmatrix}^T$, and its corresponding state vector is $x = \\begin{pmatrix} -1 & -1 & 1 \\end{pmatrix}^T$.\n\nAs a verification, we construct the transfer function matrix $G(s) = C(sI-A)^{-1}B$.\nThe inverse of the diagonal matrix $sI-A$ is:\n$(sI-A)^{-1} = \\begin{bmatrix} \\frac{1}{s+1} & 0 & 0 \\\\ 0 & \\frac{1}{s+2} & 0 \\\\ 0 & 0 & \\frac{1}{s+3} \\end{bmatrix}$.\nThen,\n$$\nG(s) = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} \\frac{1}{s+1} & 0 & 0 \\\\ 0 & \\frac{1}{s+2} & 0 \\\\ 0 & 0 & \\frac{1}{s+3} \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix}\n$$\n$$\nG(s) = \\begin{bmatrix} \\frac{1}{s+1} & 0 & \\frac{1}{s+3} \\\\ 0 & \\frac{1}{s+2} & \\frac{1}{s+3} \\end{bmatrix} \\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} \\frac{1}{s+1} & \\frac{1}{s+1}+\\frac{1}{s+3} \\\\ \\frac{1}{s+2} & -\\frac{1}{s+2}+\\frac{1}{s+3} \\end{bmatrix}\n$$\nSimplifying the entries gives:\n$$\nG(s) = \\begin{bmatrix} \\frac{1}{s+1} & \\frac{2s+4}{(s+1)(s+3)} \\\\ \\frac{1}{s+2} & \\frac{-1}{(s+2)(s+3)} \\end{bmatrix}\n$$\nThe determinant of $G(s)$ is:\n$$\n\\det(G(s)) = \\left(\\frac{1}{s+1}\\right)\\left(\\frac{-1}{(s+2)(s+3)}\\right) - \\left(\\frac{2s+4}{(s+1)(s+3)}\\right)\\left(\\frac{1}{s+2}\\right)\n$$\n$$\n\\det(G(s)) = \\frac{-1 - (2s+4)}{(s+1)(s+2)(s+3)} = \\frac{-2s-5}{(s+1)(s+2)(s+3)}\n$$\nThe transmission zeros are the roots of the numerator polynomial of $\\det(G(s))$. Setting $-2s-5=0$ gives $s = -\\frac{5}{2}$, which confirms our result.\n\nFinally, we must normalize the input direction vector $u$ such that its second component equals $1$. Our calculated $u$ is $\\begin{pmatrix} 1 & \\frac{1}{2} \\end{pmatrix}^T$. To make the second component $1$, we must multiply the vector by a factor of $2$.\nThe normalized input vector is $u_{norm} = 2 \\cdot u = 2 \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$.\nBecause the defining system of equations is linear and homogeneous in $(x,u)$, scaling $u$ by a factor of $2$ requires scaling $x$ by the same factor to maintain the equality.\nThe corresponding state vector is $x_{norm} = 2 \\cdot x = 2 \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -2 \\\\ 2 \\end{pmatrix}$.\n\nThe final requested quantities are the scalar zero $z$, the components of the normalized input vector $u_{norm} = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix}$, and the components of the corresponding state vector $x_{norm} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$.\n$z = -\\frac{5}{2}$\n$u_1 = 2$, $u_2 = 1$\n$x_1 = -2$, $x_2 = -2$, $x_3 = 2$\n\nWe report these values as a single row vector $(z, u_{1}, u_{2}, x_{1}, x_{2}, x_{3})$.", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{5}{2} & 2 & 1 & -2 & -2 & 2 \\end{pmatrix}}\n$$", "id": "2751942"}]}