{"hands_on_practices": [{"introduction": "To truly master the principle of superposition, we must first build a solid conceptual foundation. This foundational exercise focuses on meticulously distinguishing linearity—the property that gives rise to superposition—from the separate property of time-invariance. By analyzing two carefully chosen systems, you will prove that a system can be linear without being time-invariant, and vice-versa, cementing these crucial definitions and demonstrating precisely how and why a nonlinear system violates the superposition principle [@problem_id:2733503].", "problem": "Let $\\mathcal{X}$ denote the set of all real-valued signals $x:\\mathbb{R}\\to\\mathbb{R}$ for which the expressions below are well-defined pointwise. A system is a mapping $\\mathcal{S}:\\mathcal{X}\\to\\mathcal{X}$. The following foundational operator properties will be used:\n- Linearity: $\\mathcal{S}$ is linear if for all $x_{1},x_{2}\\in\\mathcal{X}$ and all scalars $\\alpha,\\beta\\in\\mathbb{R}$, $\\mathcal{S}[\\alpha x_{1}+\\beta x_{2}]=\\alpha \\mathcal{S}[x_{1}]+\\beta \\mathcal{S}[x_{2}]$.\n- Time invariance: $\\mathcal{S}$ is time-invariant if for all $x\\in\\mathcal{X}$, all shifts $\\tau\\in\\mathbb{R}$, and all $t\\in\\mathbb{R}$, $\\mathcal{S}[x(\\cdot-\\tau)](t)=\\mathcal{S}[x](t-\\tau)$.\n- Superposition principle: the response of a linear system to a linear combination of inputs is the same linear combination of the corresponding individual responses.\n\nConsider the following two system operators on $\\mathcal{X}$:\n- $\\mathcal{S}_{1}[x](t) = (2+\\cos t)\\,x(t)$.\n- $\\mathcal{S}_{2}[x](t) = \\big(x(t)\\big)^{2}$.\n\nUsing only the above foundational definitions, complete the following tasks:\n1. Prove that $\\mathcal{S}_{1}$ is linear but time-varying, and therefore satisfies the superposition principle while not being time-invariant.\n2. Prove that $\\mathcal{S}_{2}$ is time-invariant but nonlinear, and therefore violates the superposition principle despite being time-invariant.\n3. Let $u(t)$ denote the unit step function with $u(t)=1$ for $t>0$ and $u(t)=0$ for $t<0$. Define the test signals $x_{1}(t)=\\exp(-t)\\,u(t)$ and $x_{2}(t)=\\cos t$, and the scalars $\\alpha=3$ and $\\beta=-2$. Define the superposition residuals\n$$\nr_{1}(t)\\coloneqq \\mathcal{S}_{1}[\\alpha x_{1}+\\beta x_{2}](t)-\\big(\\alpha\\,\\mathcal{S}_{1}[x_{1}](t)+\\beta\\,\\mathcal{S}_{1}[x_{2}](t)\\big),\n$$\n$$\nr_{2}(t)\\coloneqq \\mathcal{S}_{2}[\\alpha x_{1}+\\beta x_{2}](t)-\\big(\\alpha\\,\\mathcal{S}_{2}[x_{1}](t)+\\beta\\,\\mathcal{S}_{2}[x_{2}](t)\\big).\n$$\nCompute $r_{1}(1)$ and $r_{2}(1)$ explicitly. Use radian measure for trigonometric arguments. Report the two values in the order $\\big(r_{1}(1),\\,r_{2}(1)\\big)$. No rounding is required; give an exact expression.", "solution": "The problem statement is scientifically grounded, well-posed, and objective. It consists of standard exercises in the analysis of linear and nonlinear systems, based on fundamental, universally accepted definitions in control theory and signal processing. All conditions and parameters are provided, and the tasks are unambiguous. Thus, the problem is valid, and a solution will be provided.\n\nThe analysis will proceed according to the three tasks outlined.\n\nTask $1$: Analyze the properties of the system $\\mathcal{S}_{1}[x](t) = (2+\\cos t)\\,x(t)$.\n\nTo prove linearity, we must verify that for any scalars $\\alpha, \\beta \\in \\mathbb{R}$ and any signals $x_{1}, x_{2} \\in \\mathcal{X}$, the condition $\\mathcal{S}_{1}[\\alpha x_{1}+\\beta x_{2}]=\\alpha \\mathcal{S}_{1}[x_{1}]+\\beta \\mathcal{S}_{1}[x_{2}]$ holds.\nLet us evaluate the left-hand side of the linearity equation:\n$$\n\\mathcal{S}_{1}[\\alpha x_{1}+\\beta x_{2}](t) = (2+\\cos t)[\\alpha x_{1}(t)+\\beta x_{2}(t)]\n$$\nBy the distributive property of multiplication over addition in $\\mathbb{R}$:\n$$\n\\mathcal{S}_{1}[\\alpha x_{1}+\\beta x_{2}](t) = \\alpha(2+\\cos t)x_{1}(t) + \\beta(2+\\cos t)x_{2}(t)\n$$\nRecognizing the definition of $\\mathcal{S}_{1}$, this becomes:\n$$\n\\mathcal{S}_{1}[\\alpha x_{1}+\\beta x_{2}](t) = \\alpha\\,\\mathcal{S}_{1}[x_{1}](t) + \\beta\\,\\mathcal{S}_{1}[x_{2}](t)\n$$\nThis equality holds for all $t \\in \\mathbb{R}$, $x_{1}, x_{2} \\in \\mathcal{X}$, and $\\alpha, \\beta \\in \\mathbb{R}$. Therefore, the system $\\mathcal{S}_{1}$ is linear. The superposition principle is defined as the property of a linear system, so $\\mathcal{S}_{1}$ satisfies the superposition principle.\n\nTo test for time invariance, we must compare the system's response to a shifted input, $\\mathcal{S}_{1}[x(\\cdot-\\tau)](t)$, with the shifted response of the system, $\\mathcal{S}_{1}[x](t-\\tau)$, for an arbitrary time shift $\\tau \\in \\mathbb{R}$.\nThe response to a shifted input is:\n$$\n\\mathcal{S}_{1}[x(\\cdot-\\tau)](t) = (2+\\cos t)x(t-\\tau)\n$$\nThe shifted response is found by replacing $t$ with $t-\\tau$ in the original system output expression:\n$$\n\\mathcal{S}_{1}[x](t-\\tau) = (2+\\cos(t-\\tau))x(t-\\tau)\n$$\nFor the system to be time-invariant, we must have $\\mathcal{S}_{1}[x(\\cdot-\\tau)](t) = \\mathcal{S}_{1}[x](t-\\tau)$ for all $t$ and $\\tau$. This requires:\n$$\n(2+\\cos t)x(t-\\tau) = (2+\\cos(t-\\tau))x(t-\\tau)\n$$\nThis equality is not guaranteed. For any non-zero input signal $x$, the equality holds only if $2+\\cos t = 2+\\cos(t-\\tau)$, or $\\cos t = \\cos(t-\\tau)$. This is not true for a general $\\tau \\in \\mathbb{R}$. For instance, let $\\tau = \\frac{\\pi}{2}$. Then the condition is $\\cos t = \\cos(t-\\frac{\\pi}{2}) = \\sin t$, which is not true for all $t$. Thus, the system $\\mathcal{S}_{1}$ is not time-invariant; it is time-varying. This completes the proof for Task $1$.\n\nTask $2$: Analyze the properties of the system $\\mathcal{S}_{2}[x](t) = \\big(x(t)\\big)^{2}$.\n\nTo test for time invariance, we again compare the response to a shifted input with the shifted response.\nThe response to a shifted input $x(\\cdot-\\tau)$ is:\n$$\n\\mathcal{S}_{2}[x(\\cdot-\\tau)](t) = \\big(x(t-\\tau)\\big)^{2}\n$$\nThe shifted response is found by replacing $t$ with $t-\\tau$ in the output expression:\n$$\n\\mathcal{S}_{2}[x](t-\\tau) = \\big(x(t-\\tau)\\big)^{2}\n$$\nSince $\\mathcal{S}_{2}[x(\\cdot-\\tau)](t) = \\mathcal{S}_{2}[x](t-\\tau)$ for all $t$ and $\\tau$, the system $\\mathcal{S}_{2}$ is time-invariant.\n\nTo prove nonlinearity, we test the superposition condition. We evaluate the system's response to a linear combination of inputs, $\\mathcal{S}_{2}[\\alpha x_{1}+\\beta x_{2}](t)$:\n$$\n\\mathcal{S}_{2}[\\alpha x_{1}+\\beta x_{2}](t) = \\big(\\alpha x_{1}(t) + \\beta x_{2}(t)\\big)^{2} = \\alpha^{2}\\big(x_{1}(t)\\big)^{2} + 2\\alpha\\beta x_{1}(t)x_{2}(t) + \\beta^{2}\\big(x_{2}(t)\\big)^{2}\n$$\nNow, we evaluate the linear combination of the individual responses:\n$$\n\\alpha \\mathcal{S}_{2}[x_{1}](t) + \\beta \\mathcal{S}_{2}[x_{2}](t) = \\alpha\\big(x_{1}(t)\\big)^{2} + \\beta\\big(x_{2}(t)\\big)^{2}\n$$\nIn general, for non-trivial choices of inputs and scalars,\n$$\n\\alpha^{2}\\big(x_{1}(t)\\big)^{2} + 2\\alpha\\beta x_{1}(t)x_{2}(t) + \\beta^{2}\\big(x_{2}(t)\\big)^{2} \\neq \\alpha\\big(x_{1}(t)\\big)^{2} + \\beta\\big(x_{2}(t)\\big)^{2}\n$$\nFor instance, if we let $\\alpha=2$, $\\beta=0$, and $x_{1}(t)=1$, the left side is $\\mathcal{S}_{2}[2\\cdot 1](t) = (2)^{2} = 4$, while the right side is $2\\cdot\\mathcal{S}_{2}[1](t) = 2(1)^{2} = 2$. Since $4 \\neq 2$, the system $\\mathcal{S}_{2}$ is not linear. It therefore violates the superposition principle. This completes the proof for Task $2$.\n\nTask $3$: Compute the superposition residuals $r_{1}(1)$ and $r_{2}(1)$.\n\nThe first residual is defined as $r_{1}(t) = \\mathcal{S}_{1}[\\alpha x_{1}+\\beta x_{2}](t)-\\big(\\alpha\\,\\mathcal{S}_{1}[x_{1}](t)+\\beta\\,\\mathcal{S}_{1}[x_{2}](t)\\big)$. As proven in Task $1$, the system $\\mathcal{S}_{1}$ is linear. By definition of linearity, the two terms in the expression for $r_{1}(t)$ are identical. Therefore, $r_{1}(t) = 0$ for all $t \\in \\mathbb{R}$. Consequently,\n$$\nr_{1}(1) = 0\n$$\n\nThe second residual is defined as $r_{2}(t) = \\mathcal{S}_{2}[\\alpha x_{1}+\\beta x_{2}](t)-\\big(\\alpha\\,\\mathcal{S}_{2}[x_{1}](t)+\\beta\\,\\mathcal{S}_{2}[x_{2}](t)\\big)$. We must compute this at $t=1$ using $\\alpha=3$, $\\beta=-2$, $x_{1}(t)=\\exp(-t)\\,u(t)$, and $x_{2}(t)=\\cos t$. First, we evaluate the inputs at $t=1$:\n$$\nx_{1}(1) = \\exp(-1)\\,u(1) = \\exp(-1) \\cdot 1 = \\exp(-1)\n$$\n$$\nx_{2}(1) = \\cos(1)\n$$\nNow we compute the two parts of the expression for $r_{2}(1)$.\nThe first part is $\\mathcal{S}_{2}[\\alpha x_{1}+\\beta x_{2}](1)$:\n$$\n\\mathcal{S}_{2}[3x_{1} - 2x_{2}](1) = \\big(3x_{1}(1) - 2x_{2}(1)\\big)^{2} = \\big(3\\exp(-1) - 2\\cos(1)\\big)^{2}\n$$\n$$\n= 9\\big(\\exp(-1)\\big)^{2} - 2(3\\exp(-1))(2\\cos(1)) + 4\\big(\\cos(1)\\big)^{2} = 9\\exp(-2) - 12\\exp(-1)\\cos(1) + 4\\cos^{2}(1)\n$$\nThe second part is $\\alpha\\mathcal{S}_{2}[x_{1}](1) + \\beta\\mathcal{S}_{2}[x_{2}](1)$:\n$$\n3\\mathcal{S}_{2}[x_{1}](1) - 2\\mathcal{S}_{2}[x_{2}](1) = 3\\big(x_{1}(1)\\big)^{2} - 2\\big(x_{2}(1)\\big)^{2} = 3\\big(\\exp(-1)\\big)^{2} - 2\\big(\\cos(1)\\big)^{2}\n$$\n$$\n= 3\\exp(-2) - 2\\cos^{2}(1)\n$$\nFinally, we compute the difference to find $r_{2}(1)$:\n$$\nr_{2}(1) = \\big(9\\exp(-2) - 12\\exp(-1)\\cos(1) + 4\\cos^{2}(1)\\big) - \\big(3\\exp(-2) - 2\\cos^{2}(1)\\big)\n$$\n$$\nr_{2}(1) = (9-3)\\exp(-2) - 12\\exp(-1)\\cos(1) + (4 - (-2))\\cos^{2}(1)\n$$\n$$\nr_{2}(1) = 6\\exp(-2) - 12\\exp(-1)\\cos(1) + 6\\cos^{2}(1)\n$$\nThe requested values are $(r_{1}(1), r_{2}(1))$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0 & 6\\exp(-2) - 12\\exp(-1)\\cos(1) + 6\\cos^{2}(1) \\end{pmatrix}}\n$$", "id": "2733503"}, {"introduction": "The power of the superposition principle shines in the analysis of Linear Time-Invariant (LTI) systems, where it allows us to decompose complex inputs into simpler components. This practice puts theory into action, guiding you to verify superposition from first principles for a discrete-time LTI system [@problem_id:2733502]. You will use the fundamental convolution sum to compute the system's output, first for a composite input and then for its individual parts, demonstrating concretely that the sum of the individual responses equals the response of the sum.", "problem": "Consider a causal discrete-time linear time-invariant (LTI) system with impulse response specified by $h[0]=1$, $h[1]=\\alpha$, $h[2]=\\beta$, and $h[k]=0$ for all $k\\ge 3$, where $\\alpha\\in\\mathbb{R}$ and $\\beta\\in\\mathbb{R}$ are fixed constants. Let the input be $u[k]=a^{k}+b^{k}$ for $k\\ge 0$ and $u[k]=0$ for $k<0$, where $a\\in\\mathbb{R}$ and $b\\in\\mathbb{R}$ are arbitrary parameters. Assume zero initial conditions and adopt the convention that $a^{0}=1$ and $b^{0}=1$.\n\nUsing only the fundamental definitions of linearity and the convolution sum for discrete-time LTI systems, derive from first principles a closed-form expression for the zero-state output $y[k]$ for all $k\\in\\mathbb{Z}$. Then, by computing the individual outputs to $a^{k}$ and $b^{k}$ separately and invoking the superposition principle, verify that the total output equals the sum of the two individual responses. Your final result should be a single explicit expression for $y[k]$ valid for all integer $k$ (you may present it as a piecewise function of $k$). No numerical evaluation or rounding is required.", "solution": "The problem statement is subjected to validation prior to any attempt at a solution.\n\n**Step 1: Extracted Givens**\n- System description: Causal discrete-time linear time-invariant (LTI) system.\n- Impulse response: $h[0]=1$, $h[1]=\\alpha$, $h[2]=\\beta$. $h[k]=0$ for all $k \\ge 3$ and $k < 0$.\n- Input signal: $u[k]=a^{k}+b^{k}$ for $k\\ge 0$ and $u[k]=0$ for $k<0$.\n- Parameters: $\\alpha, \\beta, a, b$ are real constants ($\\mathbb{R}$).\n- Conditions: Zero initial conditions (zero-state response is required). Convention: $a^0=1$ and $b^0=1$.\n- Task:\n    1.  Derive a closed-form expression for the output $y[k]$ for all $k \\in \\mathbb{Z}$ using the convolution sum.\n    2.  Verify the result by applying the superposition principle to the individual inputs $a^k$ and $b^k$.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is analyzed against the required criteria.\n- **Scientifically Grounded and Objective**: The problem is formulated using standard, universally accepted concepts from discrete-time linear systems theory, namely convolution and superposition. All terms are defined unambiguously within this context. The premises are mathematically and scientifically sound.\n- **Well-Posed and Complete**: The problem is self-contained. The system's impulse response and the input signal are fully specified. The request for a zero-state response given zero initial conditions is standard. The provided information is necessary and sufficient to determine a unique solution for the output $y[k]$. The convention for $a^0$ and $b^0$ removes any potential ambiguity for the case where $a=0$ or $b=0$.\n- **Not Trivial or Ill-Posed**: The problem requires a methodical application of the convolution definition and careful handling of indices for different time intervals. It is a standard exercise designed to test fundamental understanding, not a triviality or a tautology.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. It is a well-defined exercise in signals and systems analysis. We will proceed with a rigorous derivation.\n\n**Derivation of the System Output**\n\nThe output $y[k]$ of a discrete-time LTI system is given by the convolution sum of the input $u[k]$ and the impulse response $h[k]$:\n$$y[k] = u[k] * h[k] = \\sum_{n=-\\infty}^{\\infty} h[n] u[k-n]$$\nThe impulse response $h[k]$ is non-zero only for $n \\in \\{0, 1, 2\\}$. Therefore, the sum simplifies to:\n$$y[k] = h[0]u[k-0] + h[1]u[k-1] + h[2]u[k-2]$$\nSubstituting the given values $h[0]=1$, $h[1]=\\alpha$, and $h[2]=\\beta$:\n$$y[k] = u[k] + \\alpha u[k-1] + \\beta u[k-2]$$\nThe input signal is given by $u[k] = (a^k + b^k)\\sigma[k]$, where $\\sigma[k]$ is the discrete-time unit step function ($\\sigma[k]=1$ for $k \\ge 0$ and $\\sigma[k]=0$ for $k < 0$). We evaluate $y[k]$ for different ranges of the integer index $k$.\n\nCase 1: $k < 0$\nFor $k<0$, the indices $k$, $k-1$, and $k-2$ are all negative. Thus, $u[k]=0$, $u[k-1]=0$, and $u[k-2]=0$.\n$$y[k] = 0 + \\alpha(0) + \\beta(0) = 0$$\n\nCase 2: $k=0$\nFor $k=0$, the indices are $0$, $-1$, and $-2$.\n$u[0] = a^0 + b^0 = 1 + 1 = 2$.\n$u[-1] = 0$ and $u[-2] = 0$.\n$$y[0] = u[0] + \\alpha u[-1] + \\beta u[-2] = 2 + \\alpha(0) + \\beta(0) = 2$$\n\nCase 3: $k=1$\nFor $k=1$, the indices are $1$, $0$, and $-1$.\n$u[1] = a^1 + b^1 = a+b$.\n$u[0] = 2$.\n$u[-1] = 0$.\n$$y[1] = u[1] + \\alpha u[0] + \\beta u[-1] = (a+b) + \\alpha(2) + \\beta(0) = a+b+2\\alpha$$\n\nCase 4: $k \\ge 2$\nFor $k \\ge 2$, the indices $k$, $k-1$, and $k-2$ are all non-negative. Therefore, $\\sigma[k]=\\sigma[k-1]=\\sigma[k-2]=1$.\n$u[k] = a^k+b^k$\n$u[k-1] = a^{k-1}+b^{k-1}$\n$u[k-2] = a^{k-2}+b^{k-2}$\n$$y[k] = (a^k+b^k) + \\alpha(a^{k-1}+b^{k-1}) + \\beta(a^{k-2}+b^{k-2})$$\nThis expression can be rearranged by grouping terms with $a$ and $b$:\n$$y[k] = (a^k + \\alpha a^{k-1} + \\beta a^{k-2}) + (b^k + \\alpha b^{k-1} + \\beta b^{k-2})$$\n$$y[k] = a^{k-2}(a^2+\\alpha a+\\beta) + b^{k-2}(b^2+\\alpha b+\\beta)$$\n\nThis concludes the direct calculation of the output $y[k]$.\n\n**Verification via Superposition Principle**\n\nThe principle of superposition states that for an LTI system, if the input is $u[k] = c_1 u_1[k] + c_2 u_2[k]$, the output is $y[k] = c_1 y_1[k] + c_2 y_2[k]$. In our case, the input is $u[k] = u_a[k] + u_b[k]$, where $u_a[k] = a^k\\sigma[k]$ and $u_b[k] = b^k\\sigma[k]$. We calculate the responses $y_a[k]$ and $y_b[k]$ separately.\n\nResponse to $u_a[k] = a^k\\sigma[k]$:\nLet $y_a[k]$ be the output for the input $u_a[k]$.\n$$y_a[k] = u_a[k] + \\alpha u_a[k-1] + \\beta u_a[k-2]$$\n- For $k<0$: $y_a[k]=0$.\n- For $k=0$: $y_a[0] = u_a[0] = a^0 = 1$.\n- For $k=1$: $y_a[1] = u_a[1] + \\alpha u_a[0] = a + \\alpha(1) = a+\\alpha$.\n- For $k\\ge2$: $y_a[k] = a^k + \\alpha a^{k-1} + \\beta a^{k-2} = a^{k-2}(a^2+\\alpha a+\\beta)$.\n\nResponse to $u_b[k] = b^k\\sigma[k]$:\nBy symmetry, the calculation for $y_b[k]$ is identical to that for $y_a[k]$, with $a$ replaced by $b$.\n- For $k<0$: $y_b[k]=0$.\n- For $k=0$: $y_b[0] = b^0 = 1$.\n- For $k=1$: $y_b[1] = b + \\alpha(1) = b+\\alpha$.\n- For $k\\ge2$: $y_b[k] = b^k + \\alpha b^{k-1} + \\beta b^{k-2} = b^{k-2}(b^2+\\alpha b+\\beta)$.\n\nNow, we sum the individual responses to verify that $y_a[k] + y_b[k] = y[k]$.\n- For $k<0$: $y_a[k]+y_b[k] = 0+0=0$, which matches $y[k]$.\n- For $k=0$: $y_a[0]+y_b[0] = 1+1=2$, which matches $y[0]$.\n- For $k=1$: $y_a[1]+y_b[1] = (a+\\alpha)+(b+\\alpha) = a+b+2\\alpha$, which matches $y[1]$.\n- For $k\\ge2$: $y_a[k]+y_b[k] = a^{k-2}(a^2+\\alpha a+\\beta) + b^{k-2}(b^2+\\alpha b+\\beta)$, which matches the expression for $y[k]$ derived previously.\n\nThe verification is complete and successful. The superposition principle is shown to hold. The total output is the sum of the responses to the individual exponential components of the input.\n\nThe final expression for the output $y[k]$ is a piecewise function.", "answer": "$$\n\\boxed{\ny[k] = \n\\begin{cases}\n0 & \\text{for } k < 0 \\\\\n2 & \\text{for } k=0 \\\\\na+b+2\\alpha & \\text{for } k=1 \\\\\na^{k-2}(a^2+\\alpha a+\\beta) + b^{k-2}(b^2+\\alpha b+\\beta) & \\text{for } k \\ge 2\n\\end{cases}\n}\n$$", "id": "2733502"}, {"introduction": "A deep understanding of a principle includes knowing its boundaries. This advanced practice ventures beyond linear systems to explore the consequences of nonlinearity, where superposition no longer holds [@problem_id:2733512]. By analyzing a diffusion process with a nonlinear term, you will uncover the phenomenon of mode coupling—where initial frequencies interact to generate entirely new frequencies in the system's response. This exercise reveals not just that superposition fails, but provides a quantitative look into the rich dynamics that emerge in its absence.", "problem": "Consider the one-dimensional partial differential equation (PDE) on the periodic domain $x \\in [0, 2\\pi]$,\n$$\n\\frac{\\partial u}{\\partial t}(x,t) \\;=\\; \\nu \\frac{\\partial^{2} u}{\\partial x^{2}}(x,t) \\;+\\; \\varepsilon \\, u(x,t)^{2},\n$$\nwith real parameters $\\nu>0$ and $\\varepsilon \\neq 0$, and with $2\\pi$-periodic boundary conditions in $x$. The initial condition is a superposition of $2$ spatial modes,\n$$\nu(x,0) \\;=\\; A \\cos(x) \\;+\\; B \\cos(2x),\n$$\nwhere $A$ and $B$ are real constants. In the linear case $\\varepsilon=0$, the principle of superposition holds. For $\\varepsilon \\neq 0$, this PDE is nonlinear and the superposition principle need not hold.\n\nUsing only foundational properties of the linear diffusion operator $\\nu \\frac{\\partial^{2}}{\\partial x^{2}}$ on a periodic domain and the definition of the Fourier series on $[0,2\\pi]$, assume $\\varepsilon$ is sufficiently small and retain only terms up to order $\\varepsilon$ in the response generated by the quadratic term. Derive, to leading order in $\\varepsilon$, the time-dependent amplitude $a_{3}(t)$ of the $\\cos(3x)$ Fourier mode created by nonlinear coupling between the initially excited modes $\\cos(x)$ and $\\cos(2x)$. Provide your final answer as a closed-form analytic expression in terms of $A$, $B$, $\\nu$, $\\varepsilon$, and $t$.\n\nNo numerical approximation or rounding is required. Express your final answer without units.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Partial Differential Equation (PDE): $\\frac{\\partial u}{\\partial t}(x,t) = \\nu \\frac{\\partial^{2} u}{\\partial x^{2}}(x,t) + \\varepsilon \\, u(x,t)^{2}$.\n- Domain and Boundary Conditions: $x \\in [0, 2\\pi]$, with $2\\pi$-periodic boundary conditions.\n- Parameters: $\\nu>0$, $\\varepsilon \\neq 0$. $A$ and $B$ are real constants.\n- Initial Condition: $u(x,0) = A \\cos(x) + B \\cos(2x)$.\n- Objective: Derive the time-dependent amplitude $a_{3}(t)$ of the $\\cos(3x)$ Fourier mode to leading order in $\\varepsilon$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem describes a reaction-diffusion equation, a standard and well-studied topic in mathematical physics and applied mathematics. The approach requested, using Fourier series and perturbation theory, is a fundamental technique for analyzing such nonlinear PDEs. The problem is scientifically sound.\n- **Well-Posedness**: The problem is a well-posed initial-boundary value problem for a parabolic PDE. The request to find a specific Fourier amplitude under a perturbation approximation is a clearly defined mathematical task.\n- **Objectivity**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective content.\n- **Conclusion**: The problem is internally consistent, scientifically grounded, and well-posed. It does not violate any of the specified validation criteria.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be derived.\n\nThe solution $u(x,t)$ to the given PDE on the periodic domain $x \\in [0, 2\\pi]$ can be represented by a Fourier series. Given the form of the PDE and the initial condition, which only contains cosine terms, the solution will remain an even function of $x$ for all time $t \\ge 0$. Thus, we seek a solution in the form of a Fourier cosine series:\n$$\nu(x,t) = \\sum_{k=0}^{\\infty} a_k(t) \\cos(kx)\n$$\nThe initial condition $u(x,0) = A \\cos(x) + B \\cos(2x)$ implies the initial values for the amplitudes: $a_1(0)=A$, $a_2(0)=B$, and $a_k(0)=0$ for all $k \\neq 1, 2$. We are asked to find the amplitude $a_3(t)$.\n\nSubstituting the Fourier series into the PDE, we obtain:\n$$\n\\sum_{k=0}^{\\infty} \\frac{d a_k}{dt} \\cos(kx) = \\nu \\sum_{k=0}^{\\infty} a_k(t) (-k^2 \\cos(kx)) + \\varepsilon \\left( \\sum_{j=0}^{\\infty} a_j(t) \\cos(jx) \\right) \\left( \\sum_{l=0}^{\\infty} a_l(t) \\cos(lx) \\right)\n$$\nThe nonlinear term is handled using the product-to-sum identity $\\cos(jx)\\cos(lx) = \\frac{1}{2}[\\cos((j+l)x) + \\cos(|j-l|x)]$.\n$$\n\\sum_{k=0}^{\\infty} \\frac{d a_k}{dt} \\cos(kx) = - \\sum_{k=0}^{\\infty} \\nu k^2 a_k(t) \\cos(kx) + \\frac{\\varepsilon}{2} \\sum_{j=0}^{\\infty} \\sum_{l=0}^{\\infty} a_j(t) a_l(t) [\\cos((j+l)x) + \\cos(|j-l|x)]\n$$\nTo obtain an ordinary differential equation (ODE) for a specific amplitude $a_m(t)$ for $m \\ge 1$, we multiply by $\\cos(mx)$ and integrate over $[0, 2\\pi]$, using the orthogonality relation $\\int_0^{2\\pi} \\cos(kx)\\cos(mx) dx = \\pi \\delta_{km}$ for $k,m \\ge 1$. This projection yields a system of coupled nonlinear ODEs for the amplitudes:\n$$\n\\frac{d a_m}{dt} + \\nu m^2 a_m(t) = \\frac{\\varepsilon}{2} \\sum_{j=0}^{\\infty} \\sum_{l=0}^{\\infty} a_j(t) a_l(t) (\\delta_{m, |j-l|} + \\delta_{m, j+l})\n$$\nWe employ a perturbation expansion for small $\\varepsilon$, writing $a_k(t) = a_k^{(0)}(t) + \\varepsilon a_k^{(1)}(t) + O(\\varepsilon^2)$.\n\nAt order $\\varepsilon^0$, the equation is linear:\n$$\n\\frac{d a_m^{(0)}}{dt} + \\nu m^2 a_m^{(0)}(t) = 0\n$$\nThe solution is $a_m^{(0)}(t) = a_m(0) \\exp(-\\nu m^2 t)$. With the initial conditions $a_1(0)=A$, $a_2(0)=B$, and $a_k(0)=0$ for $k \\neq 1,2$, the zeroth-order solution is:\n$$\na_1^{(0)}(t) = A \\exp(-\\nu t)\n$$\n$$\na_2^{(0)}(t) = B \\exp(-4\\nu t)\n$$\n$$\na_k^{(0)}(t) = 0 \\quad \\text{for } k \\neq 1, 2\n$$\n\nAt order $\\varepsilon^1$, we equate the terms proportional to $\\varepsilon$:\n$$\n\\frac{d a_m^{(1)}}{dt} + \\nu m^2 a_m^{(1)}(t) = \\frac{1}{2} \\sum_{j=0}^{\\infty} \\sum_{l=0}^{\\infty} a_j^{(0)}(t) a_l^{(0)}(t) (\\delta_{m, |j-l|} + \\delta_{m, j+l})\n$$\nThe initial condition $a_m(0)=0$ for $m \\neq 1,2$ implies that $a_m^{(n)}(0)=0$ for all orders $n$. Specifically, $a_3^{(1)}(0)=0$.\n\nWe seek the amplitude $a_3(t)$. Since $a_3^{(0)}(t)=0$, the leading-order contribution to $a_3(t)$ is $\\varepsilon a_3^{(1)}(t)$. We therefore solve the ODE for $a_3^{(1)}(t)$ by setting $m=3$:\n$$\n\\frac{d a_3^{(1)}}{dt} + 9\\nu a_3^{(1)}(t) = \\frac{1}{2} \\sum_{j,l} a_j^{(0)}(t) a_l^{(0)}(t) (\\delta_{3, |j-l|} + \\delta_{3, j+l})\n$$\nThe right-hand side is the forcing term. The only non-zero $a_k^{(0)}$ terms are for $k=1$ and $k=2$. The sum is non-zero only for pairs $(j,l)$ that produce a mode $3$. The relevant combinations are $(j,l)=(1,2)$ and $(j,l)=(2,1)$.\n- For $(j,l)=(1,2)$: $j+l=3$, $|j-l|=1$.\n- For $(j,l)=(2,1)$: $j+l=3$, $|j-l|=1$.\nThe forcing term is therefore:\n$$\n\\frac{1}{2} [a_1^{(0)}(t) a_2^{(0)}(t) (\\delta_{3,1} + \\delta_{3,3}) + a_2^{(0)}(t) a_1^{(0)}(t) (\\delta_{3,1} + \\delta_{3,3})] = \\frac{1}{2} [a_1^{(0)}a_2^{(0)}(0+1) + a_2^{(0)}a_1^{(0)}(0+1)] = a_1^{(0)}(t) a_2^{(0)}(t)\n$$\nSubstituting the expressions for $a_1^{(0)}(t)$ and $a_2^{(0)}(t)$:\n$$\na_1^{(0)}(t) a_2^{(0)}(t) = (A \\exp(-\\nu t))(B \\exp(-4\\nu t)) = AB \\exp(-5\\nu t)\n$$\nThe ODE for $a_3^{(1)}(t)$ becomes:\n$$\n\\frac{d a_3^{(1)}}{dt} + 9\\nu a_3^{(1)}(t) = AB \\exp(-5\\nu t)\n$$\nThis is a linear first-order ODE with initial condition $a_3^{(1)}(0)=0$. We solve it using an integrating factor $I(t) = \\exp(\\int 9\\nu dt) = \\exp(9\\nu t)$.\n$$\n\\frac{d}{dt} [a_3^{(1)}(t) \\exp(9\\nu t)] = AB \\exp(-5\\nu t) \\exp(9\\nu t) = AB \\exp(4\\nu t)\n$$\nIntegrating with respect to $t$:\n$$\na_3^{(1)}(t) \\exp(9\\nu t) = \\int AB \\exp(4\\nu t) dt = \\frac{AB}{4\\nu} \\exp(4\\nu t) + C\n$$\nwhere $C$ is the integration constant.\n$$\na_3^{(1)}(t) = \\frac{AB}{4\\nu} \\exp(-5\\nu t) + C \\exp(-9\\nu t)\n$$\nApplying the initial condition $a_3^{(1)}(0)=0$:\n$$\n0 = \\frac{AB}{4\\nu} \\exp(0) + C \\exp(0) = \\frac{AB}{4\\nu} + C \\implies C = -\\frac{AB}{4\\nu}\n$$\nThus, the solution for $a_3^{(1)}(t)$ is:\n$$\na_3^{(1)}(t) = \\frac{AB}{4\\nu} \\exp(-5\\nu t) - \\frac{AB}{4\\nu} \\exp(-9\\nu t) = \\frac{AB}{4\\nu} (\\exp(-5\\nu t) - \\exp(-9\\nu t))\n$$\nThe amplitude $a_3(t)$ to leading order in $\\varepsilon$ is $a_3(t) \\approx \\varepsilon a_3^{(1)}(t)$.\n$$\na_3(t) = \\frac{\\varepsilon AB}{4\\nu} (\\exp(-5\\nu t) - \\exp(-9\\nu t))\n$$\nThis expression provides the time-dependent amplitude of the $\\cos(3x)$ mode generated by the nonlinear interaction of the initial modes $\\cos(x)$ and $\\cos(2x)$. It correctly vanishes at $t=0$ and decays to zero as $t \\to \\infty$ due to diffusion.", "answer": "$$\n\\boxed{\\frac{\\varepsilon AB}{4\\nu} \\left(\\exp(-5\\nu t) - \\exp(-9\\nu t)\\right)}\n$$", "id": "2733512"}]}