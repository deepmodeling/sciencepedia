{"hands_on_practices": [{"introduction": "This first practice delves into the heart of realization theory, demonstrating how a state-space model can be constructed directly from input-output data, in this case, a sequence of Markov parameters. By forming a Hankel matrix, which captures the system's input-output dynamics, you will see that different valid factorizations of this matrix yield distinct but mathematically equivalent state-space representations. This exercise [@problem_id:2727804] establishes the foundational principle that while the internal state representation is not unique, all minimal realizations are related through a similarity transformation.", "problem": "Consider a discrete-time, Single-Input Single-Output (SISO) Linear Time-Invariant (LTI) system with zero direct-through term, whose Markov parameters are defined by $h_k = C A^{k-1} B$ for $k \\geq 1$, where $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times 1}$, and $C \\in \\mathbb{R}^{1 \\times n}$. You are given the finite sequence of Markov parameters\n$$h_1 = 0,\\quad h_2 = 1,\\quad h_3 = -3,\\quad h_4 = 7,\\quad h_5 = -15.$$\n1) Using these data, form the $2 \\times 2$ block Hankel matrices\n$$H_0 = \\begin{pmatrix} h_1 & h_2 \\\\ h_2 & h_3 \\end{pmatrix}, \\qquad H_1 = \\begin{pmatrix} h_2 & h_3 \\\\ h_3 & h_4 \\end{pmatrix}.$$\n2) Construct two realizations of order $2$ by performing two distinct full-rank factorizations of $H_0$ as $H_0 = O Q$:\n- Factorization $1$: take $O_1 = I_2$ and $Q_1 = H_0$, where $I_2$ denotes the $2 \\times 2$ identity matrix.\n- Factorization $2$: take $O_2 = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$ and $Q_2 = O_2^{-1} H_0$.\nFor each factorization $H_0 = O Q$, use only the foundational definitions of the Hankel factorization and Markov parameters, namely $H_0 = O Q$ and $H_1 = O A Q$, together with the convention that for a SISO realization of order $2$, the first row of $O$ equals $C$ and the first column of $Q$ equals $B$, to construct corresponding minimal realizations $(A_1,B_1,C_1)$ and $(A_2,B_2,C_2)$.\n\n3) Verify, starting from first principles, that the two realizations are similar, meaning there exists an invertible matrix $T \\in \\mathbb{R}^{2 \\times 2}$ such that $A_2 = T^{-1} A_1 T$, $B_2 = T^{-1} B_1$, and $C_2 = C_1 T$. Determine the explicit similarity transform $T$.\n\nReport your final answer as the explicit $2 \\times 2$ matrix $T$. No rounding is required, and no physical units are involved. The final answer must be a single closed-form analytic expression.", "solution": "The problem is valid. It is a standard exercise in linear systems theory, specifically on the non-uniqueness of state-space realizations and their relationship via similarity transformations. The provided data is self-contained, consistent, and sufficient for a unique solution.\n\nThe problem requires constructing two state-space realizations from a given sequence of Markov parameters and then finding the similarity transformation matrix $T$ that relates them.\n\nThe given sequence of Markov parameters is:\n$h_1 = 0$, $h_2 = 1$, $h_3 = -3$, $h_4 = 7$, $h_5 = -15$.\n\nStep 1: Construct the Hankel matrices $H_0$ and $H_1$.\nUsing the given values, we form the $2 \\times 2$ Hankel matrices as specified.\n$$H_0 = \\begin{pmatrix} h_1 & h_2 \\\\ h_2 & h_3 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ 1 & -3 \\end{pmatrix}$$\n$$H_1 = \\begin{pmatrix} h_2 & h_3 \\\\ h_3 & h_4 \\end{pmatrix} = \\begin{pmatrix} 1 & -3 \\\\ -3 & 7 \\end{pmatrix}$$\nThe determinant of $H_0$ is $\\det(H_0) = (0)(-3) - (1)(1) = -1 \\neq 0$, which confirms that a minimal realization of order $2$ exists.\n\nStep 2: Construct two minimal realizations $(A_1, B_1, C_1)$ and $(A_2, B_2, C_2)$.\nA realization is determined from a factorization of the Hankel matrix $H_0 = OQ$, where $O$ is an observability-related matrix and $Q$ is a controllability-related matrix. The system matrix $A$ is then found using the shifted Hankel matrix $H_1$ via the relation $H_1 = OAQ$. For a single-input, single-output (SISO) system, the vector $C$ is the first row of $O$, and the vector $B$ is the first column of $Q$.\n\nRealization 1: $(A_1, B_1, C_1)$\nThis realization is based on the factorization $H_0 = O_1 Q_1$, where:\n$$O_1 = I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$$\n$$Q_1 = H_0 = \\begin{pmatrix} 0 & 1 \\\\ 1 & -3 \\end{pmatrix}$$\nFrom the definitions:\n$C_1$ is the first row of $O_1$: $C_1 = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$.\n$B_1$ is the first column of $Q_1$: $B_1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nTo find $A_1$, we use the relation $H_1 = O_1 A_1 Q_1$. Since $O_1 = I_2$, this simplifies to $H_1 = A_1 Q_1$, which gives $A_1 = H_1 Q_1^{-1}$.\nFirst, we compute the inverse of $Q_1 = H_0$:\n$$Q_1^{-1} = H_0^{-1} = \\frac{1}{\\det(H_0)} \\begin{pmatrix} -3 & -1 \\\\ -1 & 0 \\end{pmatrix} = \\frac{1}{-1} \\begin{pmatrix} -3 & -1 \\\\ -1 & 0 \\end{pmatrix} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 0 \\end{pmatrix}$$\nNow, we compute $A_1$:\n$$A_1 = H_1 Q_1^{-1} = \\begin{pmatrix} 1 & -3 \\\\ -3 & 7 \\end{pmatrix} \\begin{pmatrix} 3 & 1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} (1)(3)+(-3)(1) & (1)(1)+(-3)(0) \\\\ (-3)(3)+(7)(1) & (-3)(1)+(7)(0) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix}$$\nThus, the first realization is $(A_1, B_1, C_1)$ with $A_1 = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix}$, $B_1 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, $C_1 = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$. This is the controllable canonical form.\n\nRealization 2: $(A_2, B_2, C_2)$\nThis realization is based on the factorization $H_0 = O_2 Q_2$, where:\n$$O_2 = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$$\nAnd $Q_2 = O_2^{-1} H_0$. First, we compute $O_2^{-1}$:\n$$O_2^{-1} = \\frac{1}{(1)(1)-(1)(0)} \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix}$$\nNow, we find $Q_2$:\n$$Q_2 = O_2^{-1} H_0 = \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & -3 \\end{pmatrix} = \\begin{pmatrix} -1 & 4 \\\\ 1 & -3 \\end{pmatrix}$$\nFrom the definitions:\n$C_2$ is the first row of $O_2$: $C_2 = \\begin{pmatrix} 1 & 1 \\end{pmatrix}$.\n$B_2$ is the first column of $Q_2$: $B_2 = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$.\nTo find $A_2$, we use $H_1 = O_2 A_2 Q_2$, which gives $A_2 = O_2^{-1} H_1 Q_2^{-1}$.\nFirst, we compute $Q_2^{-1}$:\n$$Q_2^{-1} = \\frac{1}{(-1)(-3)-(4)(1)} \\begin{pmatrix} -3 & -4 \\\\ -1 & -1 \\end{pmatrix} = \\frac{1}{-1} \\begin{pmatrix} -3 & -4 \\\\ -1 & -1 \\end{pmatrix} = \\begin{pmatrix} 3 & 4 \\\\ 1 & 1 \\end{pmatrix}$$\nNow, we compute $A_2$:\n$$A_2 = O_2^{-1} H_1 Q_2^{-1} = \\left( \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & -3 \\\\ -3 & 7 \\end{pmatrix} \\right) \\begin{pmatrix} 3 & 4 \\\\ 1 & 1 \\end{pmatrix}$$\n$$A_2 = \\begin{pmatrix} 4 & -10 \\\\ -3 & 7 \\end{pmatrix} \\begin{pmatrix} 3 & 4 \\\\ 1 & 1 \\end{pmatrix} = \\begin{pmatrix} (4)(3)+(-10)(1) & (4)(4)+(-10)(1) \\\\ (-3)(3)+(7)(1) & (-3)(4)+(7)(1) \\end{pmatrix} = \\begin{pmatrix} 2 & 6 \\\\ -2 & -5 \\end{pmatrix}$$\nThus, the second realization is $(A_2, B_2, C_2)$ with $A_2 = \\begin{pmatrix} 2 & 6 \\\\ -2 & -5 \\end{pmatrix}$, $B_2 = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$, $C_2 = \\begin{pmatrix} 1 & 1 \\end{pmatrix}$.\n\nStep 3: Determine the similarity transformation $T$.\nAny two minimal realizations $(A_1, B_1, C_1)$ and $(A_2, B_2, C_2)$ of the same system are related by a similarity transformation matrix $T$ such that $A_2 = T^{-1}A_1T$, $B_2 = T^{-1}B_1$, and $C_2 = C_1T$.\nThe matrix $T$ relates the factorization matrices as well. If $H_0 = O_1 Q_1 = O_2 Q_2$, then the relationship is $O_2 = O_1 T$ and $Q_2 = T^{-1} Q_1$.\nFrom $O_2 = O_1 T$, we can find $T = O_1^{-1} O_2$.\nIn our case, $O_1 = I_2$, so $O_1^{-1} = I_2$. Therefore, $T$ is simply $O_2$:\n$$T = I_2^{-1} O_2 = O_2 = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$$\nTo be rigorous, we verify this result using the transformation equations. We have $T = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$ and $T^{-1} = \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix}$.\n1. Verify $C_2 = C_1 T$:\n$$C_1 T = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\end{pmatrix} = C_2$$\nThis is correct.\n2. Verify $B_2 = T^{-1} B_1$:\n$$T^{-1} B_1 = \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} = B_2$$\nThis is also correct.\n3. Verify $A_2 = T^{-1} A_1 T$:\n$$T^{-1} A_1 T = \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$$\nFirst, compute $A_1 T$:\n$$A_1 T = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ -2 & -5 \\end{pmatrix}$$\nNow, pre-multiply by $T^{-1}$:\n$$T^{-1}(A_1 T) = \\begin{pmatrix} 1 & -1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ -2 & -5 \\end{pmatrix} = \\begin{pmatrix} (1)(0)+(-1)(-2) & (1)(1)+(-1)(-5) \\\\ (0)(0)+(1)(-2) & (0)(1)+(1)(-5) \\end{pmatrix} = \\begin{pmatrix} 2 & 6 \\\\ -2 & -5 \\end{pmatrix} = A_2$$\nThis is also correct. All three conditions are satisfied, confirming that the similarity transformation matrix is indeed $T = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$.\nThe final answer is the explicit form of this matrix $T$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}\n}\n$$", "id": "2727804"}, {"introduction": "A system's transfer function only describes its externally observable behavior, connecting inputs to outputs. This exercise [@problem_id:2727837] explores what happens when we introduce internal dynamics that are \"hidden\" from this input-output map. You will begin with a minimal realization and augment it with an uncontrollable state, demonstrating explicitly why the transfer function remains unchanged even as the system's internal order increases and its state matrix $A$ changes.", "problem": "Consider a Single-Input Single-Output (SISO) linear time-invariant (LTI) system. The state-space realization is defined by the equations $\\dot{x}(t) = A x(t) + B u(t)$ and $y(t) = C x(t) + D u(t)$, where $x(t)$ is the state, $u(t)$ is the input, and $y(t)$ is the output. Under zero initial conditions, the transfer function is defined as $G(s) = C (s I - A)^{-1} B + D$, with $s$ denoting the Laplace transform variable and $I$ the identity matrix of appropriate size. The system is controllable if and only if the Kalman controllability matrix $\\mathcal{C} = \\big[B \\ \\ AB \\ \\ A^{2} B \\ \\ \\dots \\ \\ A^{n-1} B\\big]$ has full row rank, where $n$ is the state dimension. A realization is minimal if it is both controllable and observable. \n\nStart from the strictly proper SISO transfer function $G(s) = \\dfrac{1}{s^{2} + 3 s + 2}$, which has McMillan degree $2$ and no pole-zero cancellations. \n\nTasks:\n- Construct a minimal state-space realization $(A, B, C, D)$ of $G(s)$ consistent with the above definitions.\n- Form a nonminimal realization $(A_{\\mathrm{aug}}, B_{\\mathrm{aug}}, C_{\\mathrm{aug}}, D_{\\mathrm{aug}})$ by augmenting your minimal realization with one additional state $x_{3}$ whose dynamics are $\\dot{x}_{3}(t) = -5 x_{3}(t)$, such that the augmented state is uncontrollable from the input and yet appears in the output with a nonzero coefficient. Ensure that the augmented dynamics are block-diagonal with respect to the original minimal dynamics, that $D_{\\mathrm{aug}} = D$, and that the augmented input does not actuate the added state.\n- Using only the foundational definitions stated at the beginning, verify that the transfer function of the augmented realization equals the original $G(s)$ and that minimality is lost by demonstrating loss of controllability for the augmented realization.\n\nFinally, provide the transfer function of the augmented realization as a single reduced rational function of $s$. No rounding is required, and no units are needed. Express your final answer solely as a function of $s$.", "solution": "The problem presented is a well-posed exercise in linear control theory. It is scientifically grounded, self-contained, and requires the application of fundamental definitions of state-space systems, minimality, and transfer functions. All givens are explicit and consistent. The problem is therefore valid, and a solution will be constructed.\n\nThe task is fundamentally about demonstrating the non-uniqueness of state-space realizations and understanding the relationship between a system's internal structure (state-space representation) and its external input-output behavior (transfer function). Specifically, that the transfer function only describes the controllable and observable subsystem.\n\nFirst, we construct a minimal state-space realization for the given strictly proper transfer function $G(s) = \\dfrac{1}{s^{2} + 3 s + 2}$. Since the system is strictly proper, the direct feedthrough term $D$ is zero, $D=0$. We can write the transfer function as $G(s) = \\dfrac{0s + 1}{s^{2} + 3s + 2}$. A standard method to obtain a minimal realization for a transfer function of this form is to use the controllable canonical form. For a general second-order system $G(s) = \\dfrac{b_1 s + b_0}{s^2 + a_1 s + a_0}$, the controllable canonical realization is given by:\n$$A = \\begin{pmatrix} 0 & 1 \\\\ -a_0 & -a_1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} b_0 & b_1 \\end{pmatrix}, \\quad D = 0$$\nFrom our given $G(s)$, we identify the coefficients: $a_1 = 3$, $a_0 = 2$, $b_1 = 0$, and $b_0 = 1$. Substituting these values yields the minimal realization $(A, B, C, D)$ of dimension $n=2$:\n$$A = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}, \\quad D = 0$$\nThis realization is minimal because its dimension, $n=2$, matches the McMillan degree of the transfer function.\n\nNext, we construct the nonminimal augmented realization $(A_{\\mathrm{aug}}, B_{\\mathrm{aug}}, C_{\\mathrm{aug}}, D_{\\mathrm{aug}})$ as specified. We augment the system with an additional state $x_3$ whose dynamics are $\\dot{x}_3(t) = -5 x_3(t)$. The augmented system must have block-diagonal dynamics, the input must not actuate the added state, $D_{\\mathrm{aug}} = D$, and the added state must appear in the output with a nonzero coefficient. Let us choose this coefficient to be $1$ for simplicity.\nThe augmented state vector is $x_{\\mathrm{aug}} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$. The resulting matrices are:\n$$A_{\\mathrm{aug}} = \\begin{pmatrix} A & 0 \\\\ 0 & -5 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 \\\\ -2 & -3 & 0 \\\\ 0 & 0 & -5 \\end{pmatrix}$$\n$$B_{\\mathrm{aug}} = \\begin{pmatrix} B \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\n$$C_{\\mathrm{aug}} = \\begin{pmatrix} C & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix}$$\n$$D_{\\mathrm{aug}} = D = 0$$\n\nNow, we must verify two properties: that the transfer function of this augmented system is identical to the original $G(s)$, and that the augmented realization is nonminimal due to a loss of controllability.\n\nTo verify the transfer function, we compute $G_{\\mathrm{aug}}(s) = C_{\\mathrm{aug}} (sI - A_{\\mathrm{aug}})^{-1} B_{\\mathrm{aug}} + D_{\\mathrm{aug}}$.\nFirst, we find the inverse of $(sI - A_{\\mathrm{aug}})$:\n$$sI - A_{\\mathrm{aug}} = \\begin{pmatrix} s & -1 & 0 \\\\ 2 & s+3 & 0 \\\\ 0 & 0 & s+5 \\end{pmatrix}$$\nDue to the block-diagonal structure, its inverse is:\n$$(sI - A_{\\mathrm{aug}})^{-1} = \\begin{pmatrix} (sI_2 - A)^{-1} & 0 \\\\ 0 & (s+5)^{-1} \\end{pmatrix}$$\nwhere $(sI_2 - A)^{-1} = \\begin{pmatrix} s & -1 \\\\ 2 & s+3 \\end{pmatrix}^{-1} = \\frac{1}{s(s+3) - (-1)(2)} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} = \\frac{1}{s^2+3s+2} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix}$.\nSubstituting this back, we have:\n$$(sI - A_{\\mathrm{aug}})^{-1} = \\begin{pmatrix} \\frac{s+3}{s^2+3s+2} & \\frac{1}{s^2+3s+2} & 0 \\\\ \\frac{-2}{s^2+3s+2} & \\frac{s}{s^2+3s+2} & 0 \\\\ 0 & 0 & \\frac{1}{s+5} \\end{pmatrix}$$\nNow we perform the full calculation for $G_{\\mathrm{aug}}(s)$:\n$$G_{\\mathrm{aug}}(s) = \\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix} (sI - A_{\\mathrm{aug}})^{-1} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\n$$G_{\\mathrm{aug}}(s) = \\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{s^2+3s+2} \\\\ \\frac{s}{s^2+3s+2} \\\\ 0 \\end{pmatrix}$$\n$$G_{\\mathrm{aug}}(s) = (1) \\left( \\frac{1}{s^2+3s+2} \\right) + (0) \\left( \\frac{s}{s^2+3s+2} \\right) + (1)(0) = \\frac{1}{s^2+3s+2}$$\nThis result confirms that $G_{\\mathrm{aug}}(s) = G(s)$. The pole at $s=-5$ associated with the augmented state $x_3$ is unobservable from the input (meaning it is uncontrollable) and thus does not appear in the transfer function, despite the state $x_3$ being coupled to the output.\n\nFinally, we verify the loss of minimality by checking the controllability of the augmented system. The state dimension is $n=3$. The controllability matrix is $\\mathcal{C}_{\\mathrm{aug}} = \\big[ B_{\\mathrm{aug}} \\ \\ A_{\\mathrm{aug}} B_{\\mathrm{aug}} \\ \\ A_{\\mathrm{aug}}^{2} B_{\\mathrm{aug}} \\big]$.\nWe compute the columns:\n$$B_{\\mathrm{aug}} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$$\n$$A_{\\mathrm{aug}} B_{\\mathrm{aug}} = \\begin{pmatrix} 0 & 1 & 0 \\\\ -2 & -3 & 0 \\\\ 0 & 0 & -5 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -3 \\\\ 0 \\end{pmatrix}$$\n$$A_{\\mathrm{aug}}^{2} B_{\\mathrm{aug}} = A_{\\mathrm{aug}} (A_{\\mathrm{aug}} B_{\\mathrm{aug}}) = \\begin{pmatrix} 0 & 1 & 0 \\\\ -2 & -3 & 0 \\\\ 0 & 0 & -5 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -3 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -3 \\\\ 7 \\\\ 0 \\end{pmatrix}$$\nThe controllability matrix is thus:\n$$\\mathcal{C}_{\\mathrm{aug}} = \\begin{pmatrix} 0 & 1 & -3 \\\\ 1 & -3 & 7 \\\\ 0 & 0 & 0 \\end{pmatrix}$$\nTo check for full-rank, we compute the determinant: $\\det(\\mathcal{C}_{\\mathrm{aug}}) = 0$ due to the row of zeros. The rank of $\\mathcal{C}_{\\mathrm{aug}}$ is $2$, which is less than the state dimension $n=3$. The system is therefore uncontrollable. Since it is not controllable, it cannot be minimal. This completes the verification.\n\nThe transfer function of the augmented realization is the result of the calculation performed above.", "answer": "$$\\boxed{\\frac{1}{s^{2} + 3s + 2}}$$", "id": "2727837"}, {"introduction": "Given a state-space realization, how can we diagnose its internal properties and predict its ultimate input-output behavior? This practice introduces the powerful Popov–Belevitch–Hautus (PBH) test to analyze a system's structure on a mode-by-mode basis. By using eigenvalues to test for controllability and observability, you will see precisely how uncontrollable or unobservable modes become \"invisible\" to the transfer function, illustrating a deep connection between the system's internal structure and its external description [@problem_id:2727800].", "problem": "Consider a single-input single-output linear time-invariant state-space realization with\n$$\nA=\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & 3\n\\end{pmatrix},\\quad\nB=\\begin{pmatrix}\n1\\\\\n0\\\\\n1\n\\end{pmatrix},\\quad\nC=\\begin{pmatrix}\n0 & 1 & 0\n\\end{pmatrix},\\quad\nD=0.\n$$\nUsing only core definitions of controllability, observability, minimality, and the Popov–Belevitch–Hautus (PBH) tests, do the following:\n\n1) Determine for which eigenvalue(s) of $A$ the PBH controllability test fails, and explain why this implies a failure of controllability.\n\n2) Determine for which eigenvalue(s) of $A$ the PBH observability test fails, and explain why this implies a failure of observability.\n\n3) Interpret your findings in terms of the input-output map and the presence of uncontrollable and unobservable modes. Conclude whether the given realization is minimal.\n\n4) Let $n_{\\min}$ denote the order of a minimal realization that is input-output equivalent to the given $(A,B,C,D)$. Compute $n_{\\min}$.\n\nThe final answer must be the single number $n_{\\min}$. No units are required. Do not provide intermediate steps in the final answer.", "solution": "The problem as stated is scientifically grounded, well-posed, and contains all necessary information for a unique solution. It is a standard exercise in linear systems theory and is therefore valid.\n\nThe provided state-space realization is given by the matrices:\n$$\nA=\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & 3\n\\end{pmatrix},\\quad\nB=\\begin{pmatrix}\n1\\\\\n0\\\\\n1\n\\end{pmatrix},\\quad\nC=\\begin{pmatrix}\n0 & 1 & 0\n\\end{pmatrix},\\quad\nD=0\n$$\nThe state matrix $A$ is diagonal, so its eigenvalues are the diagonal elements: $\\lambda_1 = 1$, $\\lambda_2 = -2$, and $\\lambda_3 = 3$. The order of the system is $n=3$.\n\n1) To determine controllability, we apply the Popov–Belevitch–Hautus (PBH) test. A linear time-invariant system $(A, B)$ is controllable if and only if the matrix $[sI-A \\quad B]$ has full row rank for all complex numbers $s$. Specifically, for each eigenvalue $\\lambda_i$ of $A$, the condition $\\text{rank}([\\lambda_i I - A \\quad B]) = n$ must hold. If this condition fails for any eigenvalue, the system is uncontrollable.\n\nWe test this condition for each eigenvalue:\nFor $\\lambda_1 = 1$:\n$$\n[\\lambda_1 I - A \\quad B] = [1 \\cdot I - A \\quad B] = \\begin{pmatrix}\n1-1 & 0 & 0 & 1 \\\\\n0 & 1-(-2) & 0 & 0 \\\\\n0 & 0 & 1-3 & 1\n\\end{pmatrix} = \\begin{pmatrix}\n0 & 0 & 0 & 1 \\\\\n0 & 3 & 0 & 0 \\\\\n0 & 0 & -2 & 1\n\\end{pmatrix}\n$$\nThe rank of this matrix is $3$, as its second, third, and fourth columns are linearly independent. Thus, the mode associated with $\\lambda_1 = 1$ is controllable.\n\nFor $\\lambda_2 = -2$:\n$$\n[\\lambda_2 I - A \\quad B] = [-2 \\cdot I - A \\quad B] = \\begin{pmatrix}\n-2-1 & 0 & 0 & 1 \\\\\n0 & -2-(-2) & 0 & 0 \\\\\n0 & 0 & -2-3 & 1\n\\end{pmatrix} = \\begin{pmatrix}\n-3 & 0 & 0 & 1 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & -5 & 1\n\\end{pmatrix}\n$$\nThis matrix contains a row of zeros, so its rank is less than $3$. The rank is $2$. The PBH test fails for the eigenvalue $\\lambda_2 = -2$. This failure implies that the system is uncontrollable. The dynamic mode corresponding to $e^{-2t}$ cannot be influenced by the input $u(t)$. This is because the second component of the state vector, $x_2(t)$, evolves according to $\\dot{x}_2(t) = -2x_2(t)$, which is decoupled from the input.\n\nFor $\\lambda_3 = 3$:\n$$\n[\\lambda_3 I - A \\quad B] = [3 \\cdot I - A \\quad B] = \\begin{pmatrix}\n3-1 & 0 & 0 & 1 \\\\\n0 & 3-(-2) & 0 & 0 \\\\\n0 & 0 & 3-3 & 1\n\\end{pmatrix} = \\begin{pmatrix}\n2 & 0 & 0 & 1 \\\\\n0 & 5 & 0 & 0 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\nThe rank of this matrix is $3$. The mode associated with $\\lambda_3 = 3$ is controllable.\n\nIn summary, the PBH controllability test fails only for the eigenvalue $\\lambda = -2$.\n\n2) To determine observability, we use the dual form of the PBH test. The system $(A, C)$ is observable if and only if the matrix $\\begin{pmatrix} sI - A \\\\ C \\end{pmatrix}$ has full column rank for all complex numbers $s$. This requires $\\text{rank}\\left(\\begin{pmatrix} \\lambda_i I - A \\\\ C \\end{pmatrix}\\right) = n$ for each eigenvalue $\\lambda_i$ of $A$.\n\nWe test this condition for each eigenvalue:\nFor $\\lambda_1 = 1$:\n$$\n\\begin{pmatrix} \\lambda_1 I - A \\\\ C \\end{pmatrix} = \\begin{pmatrix} 1-1 & 0 & 0 \\\\ 0 & 1-(-2) & 0 \\\\ 0 & 0 & 1-3 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 3 & 0 \\\\ 0 & 0 & -2 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nThe first column of this matrix is a zero vector. Therefore, its rank is less than $3$. The rank is $2$. The PBH test fails for $\\lambda_1 = 1$. This implies the system is unobservable. The mode $e^{t}$ is not visible at the output.\n\nFor $\\lambda_2 = -2$:\n$$\n\\begin{pmatrix} \\lambda_2 I - A \\\\ C \\end{pmatrix} = \\begin{pmatrix} -2-1 & 0 & 0 \\\\ 0 & -2-(-2) & 0 \\\\ 0 & 0 & -2-3 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} -3 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & -5 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nThe three columns of this matrix are linearly independent. Its rank is $3$. The mode associated with $\\lambda_2 = -2$ is observable.\n\nFor $\\lambda_3 = 3$:\n$$\n\\begin{pmatrix} \\lambda_3 I - A \\\\ C \\end{pmatrix} = \\begin{pmatrix} 3-1 & 0 & 0 \\\\ 0 & 3-(-2) & 0 \\\\ 0 & 0 & 3-3 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & 5 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nThe third column of this matrix is a zero vector. Its rank is $2$, which is less than $3$. The PBH test fails for $\\lambda_3 = 3$. The mode $e^{3t}$ is unobservable.\n\nIn summary, the PBH observability test fails for eigenvalues $\\lambda = 1$ and $\\lambda = 3$.\n\n3) The analysis reveals that the system dynamics can be decomposed. The state space can be partitioned based on controllability and observability properties of the modes (Kalman decomposition).\n- The mode associated with $\\lambda_1 = 1$ is controllable but unobservable.\n- The mode associated with $\\lambda_2 = -2$ is uncontrollable but observable.\n- The mode associated with $\\lambda_3 = 3$ is controllable but unobservable.\n\nThe input-output map, represented by the transfer function $G(s) = C(sI-A)^{-1}B + D$, only reflects the part of the system that is both controllable and observable.\n$$\nG(s) = \\begin{pmatrix} 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} s-1 & 0 & 0 \\\\ 0 & s+2 & 0 \\\\ 0 & 0 & s-3 \\end{pmatrix}^{-1} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} + 0\n$$\n$$\nG(s) = \\begin{pmatrix} 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{s-1} & 0 & 0 \\\\ 0 & \\frac{1}{s+2} & 0 \\\\ 0 & 0 & \\frac{1}{s-3} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\n$$\nG(s) = \\begin{pmatrix} 0 & \\frac{1}{s+2} & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} = 0 \\cdot \\frac{1}{s-1} + \\frac{1}{s+2} \\cdot 0 + 0 \\cdot \\frac{1}{s-3} = 0\n$$\nThe transfer function is $G(s) = 0$. This is because there are no modes that are simultaneously controllable and observable. The uncontrollable mode at $\\lambda = -2$ is \"cancelled\" because the input cannot excite it. The unobservable modes at $\\lambda=1$ and $\\lambda=3$ are \"cancelled\" because they do not appear in the output.\nA realization is defined as minimal if and only if it is both completely controllable and completely observable. Since the given realization is neither, it is not minimal.\n\n4) The order of a minimal realization, denoted $n_{\\min}$, is equal to the dimension of the controllable and observable subspace of the state space. As established, this dimension is zero. Equivalently, $n_{\\min}$ is the McMillan degree of the transfer function $G(s)$. For a scalar transfer function $G(s) = \\frac{N(s)}{P(s)}$ where $N(s)$ and $P(s)$ are coprime polynomials, the degree is the degree of the denominator $P(s)$. The transfer function $G(s) = 0$ can be written as $G(s) = \\frac{0}{1}$. Here, $N(s) = 0$ and $P(s) = 1$. The degree of the denominator polynomial is $0$. Therefore, the order of a minimal realization is $n_{\\min} = 0$. A minimal realization would consist of no states, with the input-output relationship given by $y(t) = Du(t) = 0 \\cdot u(t) = 0$.", "answer": "$$\n\\boxed{0}\n$$", "id": "2727800"}]}