{"hands_on_practices": [{"introduction": "To build a reliable data-driven constitutive model, the choice of input features is paramount. Instead of using raw tensor components, which can violate physical principles, we must use features that inherently respect material symmetries and objectivity. This exercise [@problem_id:2629384] explores this concept by having you compute the principal invariants of the right Cauchy-Green tensor, $C$, for a simple shear deformation. Understanding why these invariants, $I_1$, $I_2$, and $I_3$, form a complete and objective basis is the first step toward designing physically-consistent neural network models for isotropic materials.", "problem": "A data-driven surrogate for an isotropic hyperelastic material must respect material frame indifference (objectivity) and isotropy. In a finite deformation setting, a common approach is to encode the deformation via the right Cauchy–Green tensor $C$ and to use its principal invariants as invariant features. Consider the homogeneous simple shear deformation with deformation gradient\n$$\nF=\\begin{pmatrix}1  \\gamma  0\\\\ 0  1  0\\\\ 0  0  1\\end{pmatrix},\n$$\nwhere $\\gamma \\in \\mathbb{R}$ is the shear parameter. Starting only from the kinematic definition of the right Cauchy–Green tensor $C=F^{\\mathsf{T}}F$ and the definitions of the principal invariants of a second-order tensor $C$,\n- compute $C$,\n- compute the three principal invariants $I_{1}$, $I_{2}$, and $I_{3}$ of $C$,\n- and, using the basic representation theorem for isotropic tensor functions, identify which scalar invariants of $C$ suffice to represent any compressible isotropic hyperelastic stored-energy density and how this set reduces in the incompressible limit.\n\nExplain your reasoning clearly, starting from first principles of continuum kinematics and invariance requirements. For the purposes of data-driven constitutive modeling, briefly justify why these invariants form a suitable feature set.\n\nYour final reported answer must be the row vector containing the three principal invariants as functions of $\\gamma$, written as $\\begin{pmatrix}I_{1}  I_{2}  I_{3}\\end{pmatrix}$. No units are required, and no rounding is needed.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- Deformation gradient: $F=\\begin{pmatrix}1  \\gamma  0\\\\ 0  1  0\\\\ 0  0  1\\end{pmatrix}$, with $\\gamma \\in \\mathbb{R}$.\n- Definition of right Cauchy–Green tensor: $C=F^{\\mathsf{T}}F$.\n- Task 1: Compute $C$.\n- Task 2: Compute the three principal invariants $I_{1}$, $I_{2}$, and $I_{3}$ of $C$.\n- Task 3: Justify the set of scalar invariants for representing compressible and incompressible isotropic hyperelastic stored-energy density functions using the representation theorem for isotropic tensor functions.\n- Task 4: Justify why these invariants are a suitable feature set for data-driven constitutive modeling.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the principles of continuum mechanics, specifically finite deformation kinematics and the theory of material symmetry. It is well-posed, with a clear and unambiguous set of instructions and definitions that lead to a unique and meaningful solution. The problem is objective and free of any subjective or speculative content. It is a standard, fundamental exercise in solid mechanics and is directly relevant to the-state-of-the-art topic of data-driven constitutive modeling. All definitions are standard and the mathematical steps are rigorously verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A complete, reasoned solution will be provided.\n\nThe solution proceeds systematically, as requested.\n\nFirst, we compute the right Cauchy–Green tensor $C$ from the given deformation gradient $F$. The definition is $C = F^{\\mathsf{T}}F$.\nThe deformation gradient is given as:\n$$\nF = \\begin{pmatrix} 1  \\gamma  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\nIts transpose, $F^{\\mathsf{T}}$, is:\n$$\nF^{\\mathsf{T}} = \\begin{pmatrix} 1  0  0 \\\\ \\gamma  1  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\nNow, we perform the matrix multiplication $C = F^{\\mathsf{T}}F$:\n$$\nC = \\begin{pmatrix} 1  0  0 \\\\ \\gamma  1  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1  \\gamma  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} 1\\cdot1 + 0\\cdot0 + 0\\cdot0  1\\cdot\\gamma + 0\\cdot1 + 0\\cdot0  1\\cdot0 + 0\\cdot0 + 0\\cdot1 \\\\ \\gamma\\cdot1 + 1\\cdot0 + 0\\cdot0  \\gamma\\cdot\\gamma + 1\\cdot1 + 0\\cdot0  \\gamma\\cdot0 + 1\\cdot0 + 0\\cdot1 \\\\ 0\\cdot1 + 0\\cdot0 + 1\\cdot0  0\\cdot\\gamma + 0\\cdot1 + 1\\cdot0  0\\cdot0 + 0\\cdot0 + 1\\cdot1 \\end{pmatrix}\n$$\nThis calculation yields the right Cauchy–Green tensor:\n$$\nC = \\begin{pmatrix} 1  \\gamma  0 \\\\ \\gamma  1+\\gamma^{2}  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\nNext, we compute the three principal invariants of $C$, denoted by $I_{1}$, $I_{2}$, and $I_{3}$. The general definitions for a second-order tensor $C$ in three dimensions are:\n$I_1(C) = \\mathrm{tr}(C)$\n$I_2(C) = \\frac{1}{2} [(\\mathrm{tr}(C))^2 - \\mathrm{tr}(C^2)]$ or, equivalently, the sum of the principal minors.\n$I_3(C) = \\det(C)$\n\nThe first invariant, $I_1$, is the trace of $C$:\n$$\nI_1 = \\mathrm{tr}(C) = C_{11} + C_{22} + C_{33} = 1 + (1+\\gamma^2) + 1 = 3 + \\gamma^2\n$$\nThe third invariant, $I_3$, is the determinant of $C$:\n$$\nI_3 = \\det\\begin{pmatrix} 1  \\gamma  0 \\\\ \\gamma  1+\\gamma^{2}  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\nExpanding along the third column gives:\n$$\nI_3 = 1 \\cdot \\det\\begin{pmatrix} 1  \\gamma \\\\ \\gamma  1+\\gamma^{2} \\end{pmatrix} = 1 \\cdot (1(1+\\gamma^2) - \\gamma \\cdot \\gamma) = 1+\\gamma^2 - \\gamma^2 = 1\n$$\nThis result is expected, as $I_3 = (\\det(F))^2$ and for the given simple shear, $\\det(F) = 1$. This signifies that the deformation is isochoric (volume-preserving).\n\nThe second invariant, $I_2$, is computed as the sum of the principal minors of $C$:\n$$\nI_2 = \\det\\begin{pmatrix} C_{22}  C_{23} \\\\ C_{32}  C_{33} \\end{pmatrix} + \\det\\begin{pmatrix} C_{11}  C_{13} \\\\ C_{31}  C_{33} \\end{pmatrix} + \\det\\begin{pmatrix} C_{11}  C_{12} \\\\ C_{21}  C_{22} \\end{pmatrix}\n$$\n$$\nI_2 = \\det\\begin{pmatrix} 1+\\gamma^2  0 \\\\ 0  1 \\end{pmatrix} + \\det\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + \\det\\begin{pmatrix} 1  \\gamma \\\\ \\gamma  1+\\gamma^2 \\end{pmatrix}\n$$\n$$\nI_2 = (1+\\gamma^2) + 1 + (1+\\gamma^2 - \\gamma^2) = (1+\\gamma^2) + 1 + 1 = 3 + \\gamma^2\n$$\nThus, for simple shear, we find the special condition that $I_1 = I_2$. The principal invariants are:\n$I_1 = 3 + \\gamma^2$\n$I_2 = 3 + \\gamma^2$\n$I_3 = 1$\n\nNow, we address the representation of the stored-energy density function, $\\Psi$.\nFor a hyperelastic material, $\\Psi = \\Psi(F)$. The principle of material frame indifference (objectivity) requires that the energy be independent of superimposed rigid-body rotations. This implies that $\\Psi$ can only be a function of the stretch part of the deformation, which is captured by the right Cauchy-Green tensor $C = F^{\\mathsf{T}}F$. So, we write $\\Psi = \\hat{\\Psi}(C)$.\nFor an isotropic material, the energy function must also be independent of rotations of the reference configuration, meaning $\\hat{\\Psi}(Q^{\\mathsf{T}}CQ) = \\hat{\\Psi}(C)$ for all rotation tensors $Q$. The representation theorem for isotropic scalar functions of a symmetric tensor (the Cauchy-Rivlin-Ericksen theorem) states that such a function can be expressed as a function of the principal invariants of the tensor.\nTherefore, for a **compressible isotropic hyperelastic material**, the stored-energy density must be of the form:\n$$\n\\Psi = \\Psi(I_1, I_2, I_3)\n$$\nThis set of three scalar invariants, $(I_1, I_2, I_3)$, is sufficient to represent any such material law.\n\nIn the **incompressible limit**, the material is constrained to have no volume change, which means $\\det(F) = J = 1$. As we have established, $I_3 = J^2$, so the incompressibility constraint is equivalent to the algebraic constraint $I_3=1$. When this constraint is imposed, $I_3$ is no longer an independent variable. The stored-energy density for an **incompressible isotropic hyperelastic material** therefore reduces to a function of the first two invariants:\n$$\n\\Psi = \\Psi(I_1, I_2)\n$$\nThe constraint $I_3=1$ is enforced via a Lagrange multiplier, typically interpreted as a hydrostatic pressure $p$, which does not contribute to the stored energy.\n\nFinally, we justify the use of these invariants as features for data-driven constitutive modeling.\n1.  **Enforcement of Physical Principles**: By using the invariants $(I_1, I_2, I_3)$ as the input features to a machine learning model (e.g., a neural network) that aims to learn the function $\\Psi$, one automatically enforces both material frame indifference and isotropy. Any function of these invariants is, by construction, objective and isotropic. This hard-codes fundamental physical laws into the model, which is a far more robust approach than hoping a model learns these symmetries from raw tensor components.\n2.  **Dimensionality Reduction**: The deformation state is fully described by $C$, which has $6$ independent components. The invariants reduce this $6$-dimensional input space to a $3$-dimensional space (or $2$-dimensional for incompressible materials). This greatly simplifies the learning task, reduces the risk of overfitting, and lowers the amount of experimental data required to train a reliable model, a concept critical for mitigating the \"curse of dimensionality\".\n3.  **Completeness**: The set of principal invariants forms an integrity basis. This means they are a complete set, and no information about the deformation state (up to a rotation) is lost by using them. The model is therefore provided with all necessary information to predict the energy.\n\nIn summary, the principal invariants of the right Cauchy–Green tensor are not merely a convenient choice of variables; they constitute a theoretically rigorous foundation for constructing data-driven models of isotropic materials that are consistent with the fundamental principles of mechanics.", "answer": "$$\n\\boxed{\\begin{pmatrix} 3+\\gamma^{2}  3+\\gamma^{2}  1 \\end{pmatrix}}\n$$", "id": "2629384"}, {"introduction": "Once a constitutive model is formulated, even with physically-motivated features, it must be rigorously verified against fundamental principles. The principle of material frame indifference, or objectivity, is a non-negotiable constraint that dictates how stress predictions must transform under observer rotations. This practice [@problem_id:2629347] challenges you to translate this abstract principle into a concrete numerical test, implementing the rotational equivariance check for the first Piola-Kirchhoff stress. Performing such verification is a critical skill for validating any new data-driven constitutive law and distinguishing physically sound models from fallacious ones.", "problem": "You are given the task of designing and implementing a programmatic verification of rotational equivariance for a data-driven first Piola–Kirchhoff stress model in solid mechanics. Treat all quantities as dimensionless. Use the following fundamental base: the principle of material frame indifference, which asserts that the stored energy density per reference volume is invariant under superposed rigid body rotations. The objective is to derive from first principles the correct rotational transformation law that the stress must satisfy, to define a rigorous numerical acceptance criterion, and to implement a deterministic test suite that evaluates multiple input cases.\n\nThe verification problem is purely mathematical and logical: you will implement two parametric mappings from the deformation gradient to the first Piola–Kirchhoff stress, define a set of rotation matrices from the Special Orthogonal group (SO) of degree $3$, and check the rotational equivariance condition over a prescribed set of rotations.\n\nDefinitions and constraints:\n- Let $F \\in \\mathbb{R}^{3 \\times 3}$ denote the deformation gradient.\n- Let $P(F) \\in \\mathbb{R}^{3 \\times 3}$ denote the first Piola–Kirchhoff stress predicted by a model.\n- Let $Q \\in \\mathrm{SO}(3)$ denote a proper orthogonal tensor satisfying $Q^{\\mathsf{T}} Q = I$ and $\\det(Q) = 1$.\n- Rotational equivariance of the first Piola–Kirchhoff stress under superposed rigid body rotations requires that, for all $Q \\in \\mathrm{SO}(3)$, an objective model must satisfy an appropriate transformation law derived from material frame indifference.\n- The Frobenius norm of a matrix $A$ is $\\|A\\|_{\\mathrm{F}} = \\sqrt{\\sum_{i,j} A_{ij}^{2}}$.\n\nModel family to test:\n1. Equivariant invariant-based mapping: define $C(F) = F^{\\mathsf{T}} F$ and\n   $$P_{\\theta}(F) = a_{0} F + a_{1} F C(F) + a_{2} F \\left(C(F)\\right)^{2},$$\n   with parameters $\\theta = (a_{0}, a_{1}, a_{2}) \\in \\mathbb{R}^{3}$. This mapping depends only on $F$ through $C(F)$ and is therefore intended to satisfy the correct transformation property under rotations.\n2. Perturbed non-equivariant mapping that violates objectivity by introducing a fixed lab-frame direction $b \\in \\mathbb{R}^{3}$:\n   $$\\tilde{P}_{\\theta,\\delta}(F) = P_{\\theta}(F) + \\delta \\, b \\otimes \\left(F b\\right),$$\n   where $(b \\otimes v)_{ij} = b_{i} v_{j}$, $b = [1, 0, 0]^{\\mathsf{T}}$, and $\\delta \\ge 0$ is a scalar perturbation amplitude.\n\nRotation set:\nUse the following deterministic set of rotations. All angles must be interpreted in radians.\n- About the $z$-axis with angles $\\theta \\in \\{0, \\pi/3, \\pi/2\\}$:\n  $$R_{z}(\\theta) = \\begin{bmatrix} \\cos\\theta  -\\sin\\theta  0 \\\\ \\sin\\theta  \\cos\\theta  0 \\\\ 0  0  1 \\end{bmatrix}.$$\n- About the $x$-axis with angle $\\pi$:\n  $$R_{x}(\\pi) = \\begin{bmatrix} 1  0  0 \\\\ 0  -1  0 \\\\ 0  0  -1 \\end{bmatrix}.$$\n- About the $y$-axis with angle $-\\pi/4$:\n  $$R_{y}(-\\pi/4) = \\begin{bmatrix} \\cos(\\pi/4)  0  -\\sin(\\pi/4) \\\\ 0  1  0 \\\\ \\sin(\\pi/4)  0  \\cos(\\pi/4) \\end{bmatrix}.$$\n\nAcceptance criterion:\n- For a given $F$ and a given model $M(\\cdot)$ (either $P_{\\theta}$ or $\\tilde{P}_{\\theta,\\delta}$), define the worst-case relative equivariance error over the rotation set $\\mathcal{Q}$ as\n  $$\\mathrm{err}(F; M, \\mathcal{Q}) = \\max_{Q \\in \\mathcal{Q}} \\frac{\\left\\| M(QF) - Q \\, M(F) \\right\\|_{\\mathrm{F}}}{\\max\\left(\\left\\|M(F)\\right\\|_{\\mathrm{F}}, 10^{-12}\\right)}.$$\n- The model passes for that $F$ if $\\mathrm{err}(F; M, \\mathcal{Q}) \\le \\varepsilon$, where the tolerance is $\\varepsilon = 10^{-9}$.\n\nTest suite:\n- Use parameter vector $\\theta = (a_{0}, a_{1}, a_{2}) = (0.5, -0.1, 0.03)$.\n- Use the following deformation gradients:\n  1. $F_{1} = \\begin{bmatrix} 1.1  0.2  0.0 \\\\ 0.0  0.9  0.1 \\\\ 0.0  0.0  1.2 \\end{bmatrix}$.\n  2. $F_{2} = \\begin{bmatrix} 10^{-3}  0.0  0.0 \\\\ 0.0  1.0  0.5 \\\\ 0.0  0.0  1.0 \\end{bmatrix}$.\n  3. $F_{3} = \\begin{bmatrix} 1.0  -0.3  0.2 \\\\ 0.1  1.2  0.4 \\\\ -0.2  0.0  0.8 \\end{bmatrix}$.\n  4. $F_{4} = I = \\begin{bmatrix} 1.0  0.0  0.0 \\\\ 0.0  1.0  0.0 \\\\ 0.0  0.0  1.0 \\end{bmatrix}$.\n- Construct five test cases, each consisting of a model choice, a deformation gradient, and, if applicable, a perturbation amplitude:\n  1. Equivariant model $P_{\\theta}$ with $F = F_{1}$.\n  2. Equivariant model $P_{\\theta}$ with $F = F_{2}$.\n  3. Equivariant model $P_{\\theta}$ with $F = F_{4}$.\n  4. Perturbed model $\\tilde{P}_{\\theta,\\delta}$ with $F = F_{3}$ and $\\delta = 5 \\times 10^{-2}$.\n  5. Perturbed model $\\tilde{P}_{\\theta,\\delta}$ with $F = F_{1}$ and $\\delta = 10^{-12}$.\n\nComputation and output:\n- Implement deterministic generation of the rotation set $\\mathcal{Q}$ defined above.\n- For each test case, compute $\\mathrm{err}(F; M, \\mathcal{Q})$ and check if it is less than or equal to $\\varepsilon = 10^{-9}$.\n- Your program should produce a single line of output containing the five boolean results in the order of the test cases as a comma-separated list enclosed in square brackets, for example, $[ \\mathrm{True}, \\mathrm{False}, \\dots ]$.\n- Angles are in radians. All quantities are dimensionless. No external input is allowed; the program must run as-is and print the result line only.", "solution": "The problem requires the design and implementation of a programmatic verification for the rotational equivariance of a first Piola–Kirchhoff stress model. This task must originate from first principles, specifically the principle of material frame indifference.\n\n**1. Derivation of the Rotational Equivariance Condition**\n\nThe principle of material frame indifference, also known as objectivity, posits that the constitutive laws of a material must be independent of the observer's frame of reference. For a hyperelastic material, this is expressed through the scalar stored energy density function, $\\Psi$, which depends on the deformation gradient $F \\in \\mathbb{R}^{3 \\times 3}$. A change of observer from a reference frame to a frame rotated by a proper orthogonal tensor $Q \\in \\mathrm{SO}(3)$ (where $Q^{\\mathsf{T}}Q = I$ and $\\det(Q)=1$) transforms the deformation gradient to $F' = QF$. Objectivity demands that the stored energy, a physical scalar quantity, remains invariant under such a transformation:\n$$ \\Psi(F) = \\Psi(QF) \\quad \\forall Q \\in \\mathrm{SO}(3) $$\nThe first Piola–Kirchhoff (PK1) stress tensor, $P$, is defined as the derivative of the stored energy density with respect to the deformation gradient:\n$$ P_{ij}(F) = \\frac{\\partial \\Psi}{\\partial F_{ij}}(F) $$\nTo derive the transformation law for $P(F)$, we differentiate the objectivity condition $\\Psi(F) = \\Psi(QF)$ with respect to $F$. A rigorous approach uses directional derivatives. Let $H \\in \\mathbb{R}^{3 \\times 3}$ be an arbitrary perturbation. The directional derivative of $\\Psi$ at $F$ in the direction $H$ is given by the trace inner product:\n$$ D\\Psi(F)[H] = \\mathrm{tr}\\left( \\left(\\frac{\\partial \\Psi}{\\partial F}(F)\\right)^{\\mathsf{T}} H \\right) = \\mathrm{tr}(P(F)^{\\mathsf{T}} H) $$\nApplying the chain rule to the right-hand side of the objectivity condition, $\\Psi(QF)$, we find its derivative with respect to $F$ in the direction $H$:\n$$ D\\Psi(QF)[QH] = \\mathrm{tr}(P(QF)^{\\mathsf{T}} (QH)) $$\nSince $\\Psi(F) = \\Psi(QF)$, their derivatives must be equal:\n$$ \\mathrm{tr}(P(F)^{\\mathsf{T}} H) = \\mathrm{tr}(P(QF)^{\\mathsf{T}} Q H) $$\nUsing the cyclic property of the trace, $\\mathrm{tr}(ABC) = \\mathrm{tr}(BCA)$, on the right-hand side, we get:\n$$ \\mathrm{tr}(P(F)^{\\mathsf{T}} H) = \\mathrm{tr}(H P(QF)^{\\mathsf{T}} Q) $$\nThis equality must hold for any arbitrary matrix $H$. This is possible only if the terms multiplying $H$ within the trace are identical, which implies:\n$$ P(F)^{\\mathsf{T}} = P(QF)^{\\mathsf{T}} Q $$\nTaking the transpose of both sides yields $P(F) = (P(QF)^{\\mathsf{T}} Q)^{\\mathsf{T}} = Q^{\\mathsf{T}} P(QF)$. Finally, pre-multiplying by $Q$ and using the property $QQ^{\\mathsf{T}}=I$ for orthogonal matrices, we arrive at the definitive transformation law for the first Piola–Kirchhoff stress:\n$$ P(QF) = Q P(F) $$\nThis is the condition of rotational equivariance that any objective constitutive model $M(\\cdot)$ for the PK1 stress must satisfy. The problem's error metric, involving $\\| M(QF) - Q M(F) \\|_{\\mathrm{F}}$, correctly formalizes this physical requirement.\n\n**2. Analysis of the Constitutive Models**\n\nWe analyze the two given models against the derived equivariance condition.\n\n**Model 1: Equivariant Invariant-Based Mapping**\nThe model is defined as $P_{\\theta}(F) = a_{0} F + a_{1} F C(F) + a_{2} F (C(F))^{2}$, where $C(F) = F^{\\mathsf{T}} F$ is the right Cauchy-Green tensor. To verify its objectivity, we examine its behavior under the transformation $F \\to QF$. First, the right Cauchy-Green tensor transforms as:\n$$ C(QF) = (QF)^{\\mathsf{T}}(QF) = F^{\\mathsf{T}}Q^{\\mathsf{T}}QF = F^{\\mathsf{T}}IF = F^{\\mathsf{T}}F = C(F) $$\nIt is invariant. Now, substituting $QF$ into the model equation:\n$$ P_{\\theta}(QF) = a_{0}(QF) + a_{1}(QF)C(QF) + a_{2}(QF)(C(QF))^{2} $$\nSince $C(QF) = C(F)$, we can write:\n$$ P_{\\theta}(QF) = a_{0}QF + a_{1}QFC(F) + a_{2}QF(C(F))^{2} = Q \\left( a_{0}F + a_{1}FC(F) + a_{2}F(C(F))^{2} \\right) = Q P_{\\theta}(F) $$\nThis model satisfies the equivariance condition identically. Any error measured in a numerical test will be due to floating-point precision limitations and is expected to be well below the tolerance $\\varepsilon = 10^{-9}$.\n\n**Model 2: Perturbed Non-Equivariant Mapping**\nThis model, $\\tilde{P}_{\\theta,\\delta}(F) = P_{\\theta}(F) + \\delta \\, b \\otimes (F b)$, introduces a dependence on a fixed vector $b = [1, 0, 0]^{\\mathsf{T}}$. Let us test its transformation property:\n$$ \\tilde{P}_{\\theta,\\delta}(QF) = P_{\\theta}(QF) + \\delta \\, b \\otimes ((QF)b) = Q P_{\\theta}(F) + \\delta \\, b \\otimes (Q F b) $$\nThe equivariance condition requires $\\tilde{P}_{\\theta,\\delta}(QF) = Q \\tilde{P}_{\\theta,\\delta}(F)$. We evaluate the right side of this required equality:\n$$ Q \\tilde{P}_{\\theta,\\delta}(F) = Q (P_{\\theta}(F) + \\delta \\, b \\otimes (F b)) = Q P_{\\theta}(F) + \\delta Q (b \\otimes (F b)) $$\nUsing the property that a matrix $Q$ acts on a tensor product as $Q(u \\otimes v) = (Qu) \\otimes v$, we find $Q (b \\otimes (F b)) = (Qb) \\otimes (Fb)$. Thus, for the model to be equivariant, we need:\n$$ Q P_{\\theta}(F) + \\delta \\, b \\otimes (Q F b) = Q P_{\\theta}(F) + \\delta \\, (Qb) \\otimes (Fb) $$\nThis simplifies to $b \\otimes (Q F b) = (Qb) \\otimes (Fb)$, which is not true in general for $Q \\neq I$, as $b$ is a fixed vector while $Qb$ is not. The introduction of the fixed directional vector $b$ breaks objectivity. For $\\delta  0$, this model will produce a non-zero equivariance error, the magnitude of which will determine if it passes or fails the numerical test.\n\n**3. Algorithmic Design for Verification**\n\nThe verification process is implemented as a deterministic algorithm.\n- First, the set of five rotation matrices $\\mathcal{Q}$ is constructed as specified.\n- Two functions, one for each model ($P_{\\theta}$ and $\\tilde{P}_{\\theta,\\delta}$), are implemented to compute the stress tensor for a given deformation gradient $F$.\n- An error calculation function is defined. It takes the model, $F$, and the rotation set $\\mathcal{Q}$ as inputs. For a given $F$ and model $M$, it computes the reference stress $M(F)$ and its Frobenius norm. It then iterates over all $Q \\in \\mathcal{Q}$, computing the relative error $\\left\\| M(QF) - Q M(F) \\right\\|_{\\mathrm{F}} / \\max(\\left\\|M(F)\\right\\|_{\\mathrm{F}}, 10^{-12})$ for each. The function returns the maximum relative error found across the set $\\mathcal{Q}$.\n- The main script defines the five test cases. It iterates through them, calling the error function with the appropriate model, $F$, and parameters ($\\theta$, $\\delta$).\n- The computed error for each case is compared against the tolerance $\\varepsilon = 10^{-9}$. A boolean result (`True` for pass, `False` for fail) is recorded.\n- Finally, the collected list of five boolean results is formatted into the required output string. This provides a clear, verifiable, and principle-based assessment of each model's compliance with material frame indifference.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a deterministic test suite to verify the rotational equivariance\n    of two families of first Piola-Kirchhoff stress models.\n    \"\"\"\n\n    # --- Problem Definitions ---\n\n    # Model parameters\n    theta = (0.5, -0.1, 0.03)  # (a0, a1, a2)\n    b = np.array([1.0, 0.0, 0.0])\n\n    # Acceptance criterion\n    epsilon = 1e-9\n\n    # --- Constitutive Models ---\n\n    def model_p(F, a0, a1, a2):\n        \"\"\"Equivariant invariant-based mapping.\"\"\"\n        # Right Cauchy-Green tensor C = F^T F\n        C = F.T @ F\n        # P = a0*F + a1*F*C + a2*F*C^2\n        # Use np.linalg.matrix_power for C^2\n        P = a0 * F + a1 * (F @ C) + a2 * (F @ np.linalg.matrix_power(C, 2))\n        return P\n\n    def model_p_tilde(F, a0, a1, a2, delta, b_vec):\n        \"\"\"Perturbed non-equivariant mapping.\"\"\"\n        P_base = model_p(F, a0, a1, a2)\n        # Perturbation: delta * (b outer (F*b))\n        perturbation = delta * np.outer(b_vec, F @ b_vec)\n        return P_base + perturbation\n\n    # --- Rotation Set Generation ---\n\n    def get_rotation_set():\n        \"\"\"Generates the deterministic set of rotation matrices Q.\"\"\"\n        Q_set = []\n        \n        # Rotations about z-axis\n        for angle in [0, np.pi/3, np.pi/2]:\n            c, s = np.cos(angle), np.sin(angle)\n            Rz = np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]])\n            Q_set.append(Rz)\n            \n        # Rotation about x-axis by pi\n        c, s = np.cos(np.pi), np.sin(np.pi)\n        Rx = np.array([[1, 0, 0], [0, c, -s], [0, s, c]])\n        Q_set.append(Rx)\n        \n        # Rotation about y-axis by -pi/4\n        # The problem statement gives the matrix directly. We implement it\n        # R_y(-pi/4) = [[cos(pi/4), 0, -sin(pi/4)], [0, 1, 0], [sin(pi/4), 0, cos(pi/4)]]\n        angle = -np.pi / 4\n        # Standard rotation matrix for angle alpha is [[c,0,s],[0,1,0],[-s,0,c]]\n        c, s = np.cos(angle), np.sin(angle)\n        Ry = np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]])\n        # This is equivalent to the matrix in the problem description.\n        Q_set.append(Ry)\n        \n        return Q_set\n\n    # --- Error Calculation ---\n\n    def calculate_equivariance_error(model_func, F, Q_set, params):\n        \"\"\"\n        Computes the worst-case relative equivariance error for a given model and F.\n        \"\"\"\n        # Calculate reference stress P(F)\n        M_F = model_func(F, **params)\n        \n        # Denominator for relative error, with stability guard\n        norm_M_F = np.linalg.norm(M_F, 'fro')\n        denominator = max(norm_M_F, 1e-12)\n        \n        max_error = 0.0\n        for Q in Q_set:\n            # Deformation gradient in rotated frame\n            QF = Q @ F\n            \n            # Stress in rotated frame: M(QF)\n            M_QF = model_func(QF, **params)\n            \n            # Rotated stress from reference frame: Q * M(F)\n            Q_M_F = Q @ M_F\n            \n            # Error norm\n            error_norm = np.linalg.norm(M_QF - Q_M_F, 'fro')\n            \n            # Relative error\n            relative_error = error_norm / denominator\n            \n            if relative_error > max_error:\n                max_error = relative_error\n                \n        return max_error\n    \n    # --- Test Suite Execution ---\n    \n    # Deformation Gradients\n    F1 = np.array([[1.1, 0.2, 0.0], [0.0, 0.9, 0.1], [0.0, 0.0, 1.2]])\n    F2 = np.array([[1e-3, 0.0, 0.0], [0.0, 1.0, 0.5], [0.0, 0.0, 1.0]])\n    F3 = np.array([[1.0, -0.3, 0.2], [0.1, 1.2, 0.4], [-0.2, 0.0, 0.8]])\n    F4 = np.identity(3)\n\n    # Test cases definition\n    test_cases = [\n        {'model': 'P', 'F': F1, 'delta': None},\n        {'model': 'P', 'F': F2, 'delta': None},\n        {'model': 'P', 'F': F4, 'delta': None},\n        {'model': 'P_tilde', 'F': F3, 'delta': 5e-2},\n        {'model': 'P_tilde', 'F': F1, 'delta': 1e-12},\n    ]\n\n    Q_set = get_rotation_set()\n    results = []\n\n    a0, a1, a2 = theta\n    \n    for case in test_cases:\n        F = case['F']\n        \n        if case['model'] == 'P':\n            params = {'a0': a0, 'a1': a1, 'a2': a2}\n            error = calculate_equivariance_error(model_p, F, Q_set, params)\n        else: # P_tilde\n            delta = case['delta']\n            params = {'a0': a0, 'a1': a1, 'a2': a2, 'delta': delta, 'b_vec': b}\n            error = calculate_equivariance_error(model_p_tilde, F, Q_set, params)\n        \n        # Check against tolerance\n        passed = (error = epsilon)\n        results.append(passed)\n\n    # Final output formatting\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2629347"}, {"introduction": "A powerful aspect of data-driven constitutive modeling is its seamless integration with both machine learning optimization frameworks and established computational mechanics solvers. This advanced exercise [@problem_id:2629337] delves into the mathematical machinery that makes this possible, using the chain rule to derive expressions for both the training gradients and the consistent tangent modulus. By deriving these quantities from a single hyperelastic potential, $\\Psi_{\\theta}(C)$, you will see how automatic differentiation provides the necessary derivatives to train the model's parameters $\\theta$ and to implement it efficiently within an implicit finite element code, ensuring thermodynamic consistency.", "problem": "A compressible hyperelastic material is modeled by a scalar strain energy density expressed through a parameterized function $\\Psi_{\\theta}(C) = g_{\\theta}(z(C))$, where $C \\in \\mathbb{R}^{3 \\times 3}$ is the right Cauchy–Green tensor and $g_{\\theta}:\\mathbb{R}^{3} \\to \\mathbb{R}$ is a twice continuously differentiable mapping represented by a neural network with parameters $\\theta$. The network inputs are the invariant-based features $z(C) = \\big(I_{1}(C), I_{2}(C), \\ln J(C)\\big)$, where $I_{1}(C) = \\operatorname{tr}(C)$, $I_{2}(C) = \\tfrac{1}{2}\\big((\\operatorname{tr} C)^{2} - \\operatorname{tr}(C^{2})\\big)$, and $J(C) = \\sqrt{\\det C}$. The Second Piola–Kirchhoff stress is defined by $S(C,\\theta) = 2\\,\\partial \\Psi_{\\theta}(C) / \\partial C$. The training objective uses the Mandel representation for symmetric tensors: for any symmetric $A \\in \\mathbb{R}^{3 \\times 3}$, define $A^{M} = \\big(A_{11}, A_{22}, A_{33}, \\sqrt{2}\\,A_{23}, \\sqrt{2}\\,A_{13}, \\sqrt{2}\\,A_{12}\\big)^{\\top} \\in \\mathbb{R}^{6}$. The loss over $N$ data pairs $\\{(C^{(n)}, S^{(n)})\\}_{n=1}^{N}$ is\n$$\n\\mathcal{L}(\\theta) = \\frac{1}{2}\\sum_{n=1}^{N} \\big\\| S^{M}(C^{(n)},\\theta) - \\big(S^{(n)}\\big)^{M} \\big\\|_{2}^{2},\n$$\nwhere $S^{M}(C,\\theta) = 2\\,\\frac{\\partial \\Psi_{\\theta}(C)}{\\partial C^{M}}$ denotes the Mandel vector of $S(C,\\theta)$. Assume access to exact derivatives of $g_{\\theta}$ with respect to both $z$ and $\\theta$ by Automatic Differentiation (AD).\n\nStarting from the definitions of hyperelasticity and the chain rule, and using only tensor calculus identities that follow from differentiating scalar functions of symmetric tensors, carry out the following:\n\n1. Derive an explicit expression for the gradient $\\partial \\mathcal{L} / \\partial \\theta$ in terms of the residuals $S^{M}(C^{(n)},\\theta) - \\big(S^{(n)}\\big)^{M}$, the mixed Jacobian–Hessian of $g_{\\theta}$ with respect to $(\\theta,z)$, and the Jacobian of the invariant map $z(C)$ with respect to $C^{M}$. Keep the result in symbolic form; do not substitute any particular architecture of $g_{\\theta}$.\n\n2. Derive the consistent algorithmic tangent (material) matrix in the Mandel basis, defined by $\\mathbb{C}^{M}(C,\\theta) = \\partial S^{M}(C,\\theta)/\\partial E^{M}$, where $E = \\tfrac{1}{2}(C - I)$ is the Green–Lagrange strain and $I$ is the identity. Express $\\mathbb{C}^{M}(C,\\theta)$ solely in terms of the Jacobian and Hessian of $g_{\\theta}$ with respect to $z$, the Jacobian of $z(C)$ with respect to $C^{M}$, and the second derivatives of the invariants with respect to $C^{M}$. Show, by construction, that the resulting $\\mathbb{C}^{M}$ is symmetric.\n\nYour final answer must be a single, closed-form analytic expression for $\\mathbb{C}^{M}(C,\\theta)$ in terms of the quantities specified. No numerical evaluation is required, and no units are to be reported in the final answer.", "solution": "The problem statement has been evaluated and is determined to be valid. It is scientifically grounded in the principles of continuum mechanics and data-driven modeling, is well-posed, objective, and internally consistent. We shall proceed with the derivation.\n\nThe problem requires two derivations. First, the gradient of the loss function $\\mathcal{L}(\\theta)$ with respect to the neural network parameters $\\theta$. Second, the consistent algorithmic tangent matrix $\\mathbb{C}^{M}$ in the Mandel basis.\n\nLet us begin with the first task: the derivation of the gradient $\\partial \\mathcal{L} / \\partial \\theta$. The loss function is given as\n$$\n\\mathcal{L}(\\theta) = \\frac{1}{2}\\sum_{n=1}^{N} \\big\\| S^{M}(C^{(n)},\\theta) - \\big(S^{(n)}\\big)^{M} \\big\\|_{2}^{2}\n$$\nFor clarity, we will consider a single data point and omit the superscript $(n)$. The residual vector for one data point is $r(\\theta) = S^{M}(C,\\theta) - S_{\\text{data}}^{M}$. The contribution of this single point to the loss is $\\frac{1}{2} r(\\theta)^T r(\\theta)$. The gradient of the total loss is the sum of the gradients from each data point. Applying the chain rule to the contribution from one data point gives:\n$$\n\\frac{\\partial}{\\partial \\theta} \\left(\\frac{1}{2} r^T r \\right) = \\left(\\frac{\\partial r}{\\partial \\theta}\\right)^T r\n$$\nThe derivative of the residual vector $r$ with respect to the parameter vector $\\theta$ is\n$$\n\\frac{\\partial r}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} \\left( S^{M}(C,\\theta) - S_{\\text{data}}^{M} \\right) = \\frac{\\partial S^{M}(C,\\theta)}{\\partial \\theta}\n$$\nHere, $\\partial S^{M}/\\partial \\theta$ is a Jacobian matrix of size $6 \\times |\\theta|$, where $|\\theta|$ is the number of parameters. We now evaluate this term. By definition, the Second Piola-Kirchhoff stress in Mandel form is $S^M(C, \\theta) = 2 \\frac{\\partial \\Psi_{\\theta}(C)}{\\partial C^M}$, where $\\Psi_{\\theta}(C) = g_{\\theta}(z(C))$.\n$$\n\\frac{\\partial S^{M}(C,\\theta)}{\\partial \\theta} = 2 \\frac{\\partial}{\\partial \\theta} \\left( \\frac{\\partial \\Psi_{\\theta}(C)}{\\partial C^M} \\right)\n$$\nSince the strain energy function $\\Psi_{\\theta}$ is assumed to be twice continuously differentiable (as $g_{\\theta}$ is $C^2$), we can interchange the order of differentiation (Clairaut's theorem for mixed partials):\n$$\n\\frac{\\partial S^{M}(C,\\theta)}{\\partial \\theta} = 2 \\frac{\\partial}{\\partial C^M} \\left( \\frac{\\partial \\Psi_{\\theta}(C)}{\\partial \\theta} \\right)\n$$\nThe term inside the parenthesis is a scalar function of $C$ and $\\theta$, differentiated by $\\theta$. We evaluate this derivative first. The dependence on $\\theta$ is only through the function $g_{\\theta}$. Let us write $g(z, \\theta)$ to be explicit.\n$$\n\\frac{\\partial \\Psi_{\\theta}(C)}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta} g(z(C), \\theta)\n$$\nNote that $z(C)$ does not depend on $\\theta$. Now we substitute this back and apply the chain rule for the differentiation with respect to $C^M$:\n$$\n\\frac{\\partial S^{M}(C,\\theta)}{\\partial \\theta} = 2 \\frac{\\partial}{\\partial C^M} \\left( \\frac{\\partial g(z(C), \\theta)}{\\partial \\theta} \\right) = 2 \\left( \\frac{\\partial z(C)}{\\partial C^M} \\right)^T \\frac{\\partial}{\\partial z} \\left( \\frac{\\partial g(z, \\theta)}{\\partial \\theta} \\right) = 2 \\left( \\frac{\\partial z}{\\partial C^M} \\right)^T \\frac{\\partial^2 g}{\\partial z \\partial \\theta}\n$$\nHere, $\\frac{\\partial z}{\\partial C^M}$ is the $3 \\times 6$ Jacobian of the invariant map, and $\\frac{\\partial^2 g}{\\partial z \\partial \\theta}$ is the $3 \\times |\\theta|$ mixed Jacobian-Hessian matrix of $g$ with respect to $z$ and $\\theta$.\n\nNow we can write the full expression for the gradient of the loss function $\\mathcal{L}(\\theta)$. Summing over all $N$ data points:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{n=1}^{N} \\left( \\frac{\\partial S^{M}(C^{(n)},\\theta)}{\\partial \\theta} \\right)^T \\left( S^{M}(C^{(n)},\\theta) - \\big(S^{(n)}\\big)^{M} \\right)\n$$\nSubstituting our derived expression for the Jacobian of the stress:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = \\sum_{n=1}^{N} \\left( 2 \\left(\\frac{\\partial z^{(n)}}{\\partial C^M}\\right)^T \\frac{\\partial^2 g^{(n)}}{\\partial z \\partial \\theta} \\right)^T \\left( S^{M}(C^{(n)},\\theta) - \\big(S^{(n)}\\big)^{M} \\right)\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\theta} = 2 \\sum_{n=1}^{N} \\left(\\frac{\\partial^2 g^{(n)}}{\\partial z \\partial \\theta}\\right)^T \\left(\\frac{\\partial z^{(n)}}{\\partial C^M}\\right) \\left( S^{M}(C^{(n)},\\theta) - \\big(S^{(n)}\\big)^{M} \\right)\n$$\nwhere for brevity $g^{(n)}$ denotes $g(z(C^{(n)}), \\theta)$ and $z^{(n)}$ denotes $z(C^{(n)})$. This completes the first part of the problem.\n\nNext, we address the second task: the derivation of the consistent algorithmic tangent matrix $\\mathbb{C}^{M}(C,\\theta)$, defined as $\\partial S^{M}(C,\\theta)/\\partial E^{M}$, where $E = \\frac{1}{2}(C - I)$ is the Green-Lagrange strain tensor.\n\nFirst, we establish the relationship between derivatives with respect to $E^M$ and $C^M$. From the definition of $E$, we have $C = 2E + I$. In Mandel vector form, this is $C^M = 2E^M + I^M$. Therefore, $dC^M = 2dE^M$. Using the chain rule, for any function $f$, we have $\\frac{\\partial f}{\\partial E^M_i} = \\sum_j \\frac{\\partial C^M_j}{\\partial E^M_i} \\frac{\\partial f}{\\partial C^M_j} = \\sum_j 2\\delta_{ij} \\frac{\\partial f}{\\partial C^M_j} = 2\\frac{\\partial f}{\\partial C^M_i}$. In vector notation, this is $\\frac{\\partial}{\\partial E^M} = 2 \\frac{\\partial}{\\partial C^M}$.\n\nThe tangent matrix is then:\n$$\n\\mathbb{C}^{M} = \\frac{\\partial S^{M}}{\\partial E^{M}} = 2 \\frac{\\partial S^{M}}{\\partial C^{M}}\n$$\nSubstituting the expression for $S^M = 2\\frac{\\partial \\Psi_{\\theta}}{\\partial C^M}$:\n$$\n\\mathbb{C}^{M} = 2 \\frac{\\partial}{\\partial C^{M}} \\left( 2 \\frac{\\partial \\Psi_{\\theta}}{\\partial C^{M}} \\right) = 4 \\frac{\\partial^2 \\Psi_{\\theta}}{(\\partial C^{M})^2}\n$$\nThis expression demonstrates that $\\mathbb{C}^{M}$ is $4$ times the Hessian matrix of the strain energy scalar potential $\\Psi_{\\theta}$ with respect to the vector $C^M$. Since $\\Psi_{\\theta}$ is a $C^2$ function, its Hessian matrix is symmetric by Clairaut's theorem. Thus, $\\mathbb{C}^{M}$ is constructed to be a symmetric matrix.\n\nWe now expand this second derivative. The strain energy is $\\Psi_{\\theta}(C) = g_{\\theta}(z(C))$. The first derivative of $\\Psi_{\\theta}$ with respect to $C^M$ is found using the chain rule. In index notation, for components $i=1, \\dots, 6$:\n$$\n\\frac{\\partial \\Psi_{\\theta}}{\\partial C^M_i} = \\sum_{k=1}^{3} \\frac{\\partial g_{\\theta}}{\\partial z_k} \\frac{\\partial z_k}{\\partial C^M_i}\n$$\nTo find the second derivative, we differentiate this expression with respect to $C^M_j$:\n$$\n\\frac{\\partial^2 \\Psi_{\\theta}}{\\partial C^M_j \\partial C^M_i} = \\frac{\\partial}{\\partial C^M_j} \\left( \\sum_{k=1}^{3} \\frac{\\partial g_{\\theta}}{\\partial z_k} \\frac{\\partial z_k}{\\partial C^M_i} \\right)\n$$\nApplying the product rule:\n$$\n\\frac{\\partial^2 \\Psi_{\\theta}}{\\partial C^M_j \\partial C^M_i} = \\sum_{k=1}^{3} \\left[ \\frac{\\partial}{\\partial C^M_j}\\left(\\frac{\\partial g_{\\theta}}{\\partial z_k}\\right) \\frac{\\partial z_k}{\\partial C^M_i} + \\frac{\\partial g_{\\theta}}{\\partial z_k} \\frac{\\partial^2 z_k}{\\partial C^M_j \\partial C^M_i} \\right]\n$$\nThe first term in the bracket is expanded using the chain rule again:\n$$\n\\frac{\\partial}{\\partial C^M_j}\\left(\\frac{\\partial g_{\\theta}}{\\partial z_k}\\right) = \\sum_{l=1}^{3} \\frac{\\partial^2 g_{\\theta}}{\\partial z_l \\partial z_k} \\frac{\\partial z_l}{\\partial C^M_j}\n$$\nSubstituting this back, we obtain the full expression for the Hessian of $\\Psi_{\\theta}$:\n$$\n\\frac{\\partial^2 \\Psi_{\\theta}}{\\partial C^M_j \\partial C^M_i} = \\sum_{k=1}^{3} \\sum_{l=1}^{3} \\frac{\\partial z_l}{\\partial C^M_j} \\frac{\\partial^2 g_{\\theta}}{\\partial z_l \\partial z_k} \\frac{\\partial z_k}{\\partial C^M_i} + \\sum_{k=1}^{3} \\frac{\\partial g_{\\theta}}{\\partial z_k} \\frac{\\partial^2 z_k}{\\partial C^M_j \\partial C^M_i}\n$$\nThis component-wise expression can be written more compactly in matrix form. Let $J_{z,C^M} = \\frac{\\partial z}{\\partial C^M}$ be the $3 \\times 6$ Jacobian of the invariants, $H_{g,z} = \\frac{\\partial^2 g_{\\theta}}{(\\partial z)^2}$ be the $3 \\times 3$ Hessian of the network output, and $H_{z_k,C^M} = \\frac{\\partial^2 z_k}{(\\partial C^M)^2}$ be the $6 \\times 6$ Hessian of the $k$-th invariant feature. The Hessian of $\\Psi_{\\theta}$ is:\n$$\n\\frac{\\partial^2 \\Psi_{\\theta}}{(\\partial C^M)^2} = (J_{z,C^M})^T H_{g,z} J_{z,C^M} + \\sum_{k=1}^{3} \\frac{\\partial g_{\\theta}}{\\partial z_k} H_{z_k,C^M}\n$$\nFinally, multiplying by $4$ gives the expression for the algorithmic tangent matrix $\\mathbb{C}^M$:\n$$\n\\mathbb{C}^{M}(C,\\theta) = 4 \\left[ \\left(\\frac{\\partial z(C)}{\\partial C^M}\\right)^T \\frac{\\partial^2 g_{\\theta}(z)}{(\\partial z)^2} \\frac{\\partial z(C)}{\\partial C^M} + \\sum_{k=1}^3 \\frac{\\partial g_{\\theta}(z)}{\\partial z_k} \\frac{\\partial^2 z_k(C)}{(\\partial C^M)^2} \\right]\n$$\nThe symmetry of this expression is confirmed by inspection. The matrix $\\frac{\\partial^2 g_{\\theta}}{(\\partial z)^2}$ is a Hessian and is symmetric. The first term is of the form $A^T B A$ with $B$ symmetric, which is a symmetric matrix. Each matrix $\\frac{\\partial^2 z_k}{(\\partial C^M)^2}$ is also a Hessian of a scalar function $z_k(C)$ and is therefore symmetric. The second term is a linear combination of symmetric matrices, which is also symmetric. The sum of two symmetric matrices is symmetric. This confirms the symmetry of $\\mathbb{C}^M$ by construction.\n\nThis is the required expression for the consistent tangent matrix, expressed in terms of the specified quantities.", "answer": "$$\n\\boxed{4 \\left[ \\left(\\frac{\\partial z(C)}{\\partial C^M}\\right)^T \\frac{\\partial^2 g_{\\theta}(z)}{(\\partial z)^2} \\frac{\\partial z(C)}{\\partial C^M} + \\sum_{k=1}^{3} \\frac{\\partial g_{\\theta}(z)}{\\partial z_k} \\frac{\\partial^2 z_k(C)}{(\\partial C^M)^2} \\right]}\n$$", "id": "2629337"}]}