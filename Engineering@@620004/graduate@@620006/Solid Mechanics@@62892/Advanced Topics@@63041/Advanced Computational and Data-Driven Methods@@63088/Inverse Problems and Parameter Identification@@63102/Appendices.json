{"hands_on_practices": [{"introduction": "Before embarking on a complex parameter identification campaign, a crucial first question must be answered: is the planned experiment even capable of uniquely determining the parameters of interest? This concept, known as structural identifiability, examines whether the model parameters can be distinguished from one another based on the observable outputs, assuming perfect, noise-free data. This exercise [@problem_id:2650373] provides a sharp, analytical exploration of this question for a common scenario in material testing, demonstrating how the choice of experiment fundamentally constrains what can be learned about the material's constitutive behavior.", "problem": "Consider an isotropic, compressible Neo-Hookean solid characterized by the shear modulus $\\mu$ and the bulk modulus $\\kappa$. Assume experiments are performed in small strain uniaxial tension on a prismatic specimen with traction-free lateral faces. The only measured quantity is the axial Cauchy stress $\\sigma_{11}$ as a function of the applied axial strain $\\varepsilon_{11}$ over a continuum of sufficiently small strains (so that linearization is valid), and no lateral strains are recorded. Adopt the small-strain limit of the compressible Neo-Hookean model, which reduces to linear isotropic elasticity with Lamé parameters $\\lambda_{L}$ and $\\mu$, and bulk modulus $\\kappa = \\lambda_{L} + \\frac{2}{3}\\mu$.\n\nUsing only fundamental small-strain relations, set up the forward mapping from $(\\mu,\\kappa)$ to the measured response $\\sigma_{11}(\\varepsilon_{11})$ under the traction-free lateral boundary condition. Then perform a structural identifiability analysis based on first-order sensitivity of the output with respect to $(\\mu,\\kappa)$, considering the entire noiseless dataset $\\{\\varepsilon_{11} \\mapsto \\sigma_{11}(\\varepsilon_{11})\\}$ in the infinitesimal strain regime. Determine a nonzero two-component row vector $(c_{\\mu},c_{\\kappa})$ that spans the one-dimensional nullspace of the sensitivity map; equivalently, find $(c_{\\mu},c_{\\kappa}) \\neq (0,0)$ such that the first-order variation of the predicted $\\sigma_{11}$ vanishes for all small $\\varepsilon_{11}$ when the parameters are perturbed as $\\delta \\mu = s\\,c_{\\mu}$, $\\delta \\kappa = s\\,c_{\\kappa}$ for any scalar $s$.\n\nProvide your final answer as a single explicit row vector $(c_{\\mu},c_{\\kappa})$ in terms of $\\mu$ and $\\kappa$ that spans this structurally unidentifiable direction. No numerical rounding is required. Do not include units in your final answer.", "solution": "The problem as stated is subjected to validation before any solution is attempted.\n\nStep 1: Extract Givens\n- Material Model: Isotropic, compressible Neo-Hookean solid, with its small-strain limit reducing to linear isotropic elasticity.\n- Parameters: Shear modulus $\\mu$ and bulk modulus $\\kappa$.\n- Constitutive Relations: The small-strain limit corresponds to linear elasticity with Lamé parameters $\\lambda_{L}$ and $\\mu$. The bulk modulus is defined as $\\kappa = \\lambda_{L} + \\frac{2}{3}\\mu$.\n- Experimental Setup: Small strain uniaxial tension on a prismatic specimen.\n- Boundary Conditions: Traction-free lateral faces, implying $\\sigma_{22} = \\sigma_{33} = 0$.\n- Measured Quantity: The axial Cauchy stress $\\sigma_{11}$ as a function of the applied axial strain $\\varepsilon_{11}$. Lateral strains are not measured.\n- Task:\n  1.  Establish the forward mapping from the parameters $(\\mu, \\kappa)$ to the measured response $\\sigma_{11}(\\varepsilon_{11})$.\n  2.  Conduct a first-order structural identifiability analysis.\n  3.  Determine a nonzero row vector $(c_{\\mu}, c_{\\kappa})$ that spans the nullspace of the sensitivity map, such that the first-order variation of $\\sigma_{11}$ vanishes for perturbations of $(\\mu, \\kappa)$ in the direction of this vector.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as it is based on the fundamental theory of linear elasticity, a standard and well-established framework in solid mechanics. The relationships between elastic constants ($\\kappa$, $\\mu$, $\\lambda_L$) are standard. The experimental configuration (uniaxial tension) is a classical setup. The concept of structural identifiability and sensitivity analysis is a rigorous mathematical tool used in parameter identification and inverse problems. The problem is well-posed, objective, and contains sufficient information for a unique solution (up to a scaling factor for the basis vector). It does not violate any scientific principles, is not based on false premises, and uses precise, unambiguous language. The problem is non-trivial and tests fundamental concepts in mechanics and inverse problem theory.\n\nStep 3: Verdict and Action\nThe problem is deemed valid. A complete, reasoned solution will be provided.\n\nThe core of the problem is to determine the relationship between the measured stress-strain response and the underlying material parameters $\\mu$ and $\\kappa$, and then to analyze which combinations of parameters are indistinguishable from the measurement.\n\nFirst, the forward model must be derived. The constitutive equation for a linear isotropic elastic material is given by:\n$$\n\\sigma_{ij} = \\lambda_{L} \\varepsilon_{kk} \\delta_{ij} + 2\\mu \\varepsilon_{ij}\n$$\nwhere $\\boldsymbol{\\sigma}$ is the Cauchy stress tensor, $\\boldsymbol{\\varepsilon}$ is the infinitesimal strain tensor, $\\delta_{ij}$ is the Kronecker delta, and $\\varepsilon_{kk} = \\text{tr}(\\boldsymbol{\\varepsilon})$ is the volumetric strain. The problem specifies a uniaxial tension test along the $1$-direction with traction-free lateral surfaces. This implies the stress tensor has the form:\n$$\n\\sigma_{11} \\neq 0, \\quad \\sigma_{22} = 0, \\quad \\sigma_{33} = 0\n$$\nAnd all shear components are zero. Due to axisymmetry of the loading and material isotropy, the lateral strains are equal: $\\varepsilon_{22} = \\varepsilon_{33}$. Let us denote the axial strain as $\\varepsilon_{11}$ and the lateral strain as $\\varepsilon_{\\text{L}} = \\varepsilon_{22} = \\varepsilon_{33}$. The trace of the strain tensor is $\\varepsilon_{kk} = \\varepsilon_{11} + 2\\varepsilon_{\\text{L}}$.\n\nThe constitutive relations for the diagonal components of stress are:\n$$\n\\sigma_{11} = \\lambda_{L} (\\varepsilon_{11} + 2\\varepsilon_{\\text{L}}) + 2\\mu \\varepsilon_{11} \\\\\n\\sigma_{22} = \\lambda_{L} (\\varepsilon_{11} + 2\\varepsilon_{\\text{L}}) + 2\\mu \\varepsilon_{\\text{L}} = 0 \\\\\n\\sigma_{33} = \\lambda_{L} (\\varepsilon_{11} + 2\\varepsilon_{\\text{L}}) + 2\\mu \\varepsilon_{\\text{L}} = 0\n$$\nFrom the condition $\\sigma_{22} = 0$, we solve for the lateral strain $\\varepsilon_{\\text{L}}$ in terms of the axial strain $\\varepsilon_{11}$:\n$$\n(\\lambda_{L} + 2\\mu)\\varepsilon_L + \\lambda_{L}\\varepsilon_L + \\lambda_{L}\\varepsilon_{11} = 0\n$$\n$$\n(2\\lambda_{L} + 2\\mu)\\varepsilon_{\\text{L}} = -\\lambda_{L}\\varepsilon_{11} \\implies \\varepsilon_{\\text{L}} = -\\frac{\\lambda_{L}}{2(\\lambda_{L} + \\mu)} \\varepsilon_{11}\n$$\nNow, we substitute this expression for $\\varepsilon_{\\text{L}}$ into the equation for the axial stress $\\sigma_{11}$:\n$$\n\\sigma_{11} = \\left[ \\lambda_{L} \\left(1 - 2\\frac{\\lambda_{L}}{2(\\lambda_{L} + \\mu)}\\right) + 2\\mu \\right] \\varepsilon_{11}\n$$\n$$\n\\sigma_{11} = \\left[ \\lambda_{L} \\left(\\frac{\\lambda_{L} + \\mu - \\lambda_{L}}{\\lambda_{L} + \\mu}\\right) + 2\\mu \\right] \\varepsilon_{11} = \\left[ \\frac{\\lambda_{L}\\mu}{\\lambda_{L} + \\mu} + 2\\mu \\right] \\varepsilon_{11}\n$$\n$$\n\\sigma_{11} = \\left[ \\frac{\\lambda_{L}\\mu + 2\\mu(\\lambda_{L} + \\mu)}{\\lambda_{L} + \\mu} \\right] \\varepsilon_{11} = \\left[ \\frac{3\\lambda_{L}\\mu + 2\\mu^2}{\\lambda_{L} + \\mu} \\right] \\varepsilon_{11}\n$$\nThe term in the brackets is the Young's modulus, $E$. Thus, $\\sigma_{11} = E \\varepsilon_{11}$. The only observable from this experiment is $E$.\nThe task requires the forward mapping from $(\\mu, \\kappa)$. We must express $E$ in terms of $\\mu$ and $\\kappa$. We are given $\\kappa = \\lambda_{L} + \\frac{2}{3}\\mu$, which implies $\\lambda_{L} = \\kappa - \\frac{2}{3}\\mu$. Substituting this into the expression for $E$:\n$$\nE(\\mu, \\kappa) = \\frac{3\\left(\\kappa - \\frac{2}{3}\\mu\\right)\\mu + 2\\mu^2}{\\left(\\kappa - \\frac{2}{3}\\mu\\right) + \\mu} = \\frac{3\\kappa\\mu - 2\\mu^2 + 2\\mu^2}{\\kappa + \\frac{1}{3}\\mu} = \\frac{3\\kappa\\mu}{\\kappa + \\frac{1}{3}\\mu}\n$$\nSimplifying this expression gives the well-known relation:\n$$\nE(\\mu, \\kappa) = \\frac{9\\kappa\\mu}{3\\kappa + \\mu}\n$$\nThe forward map from the parameters $(\\mu, \\kappa)$ to the continuum of measurements $\\{\\varepsilon_{11} \\mapsto \\sigma_{11}(\\varepsilon_{11})\\}$ is fully characterized by the scalar observable $E(\\mu, \\kappa)$.\n\nNext, we perform the structural identifiability analysis. A direction $(c_{\\mu}, c_{\\kappa})$ in the parameter space is unidentifiable if a first-order perturbation along this direction, $(\\delta\\mu, \\delta\\kappa) = s(c_{\\mu}, c_{\\kappa})$, produces no change in the observable quantity $E$. Mathematically, the directional derivative of $E$ in the direction $(c_{\\mu}, c_{\\kappa})$ must be zero.\n$$\n\\nabla E \\cdot (c_{\\mu}, c_{\\kappa}) = \\frac{\\partial E}{\\partial \\mu}c_{\\mu} + \\frac{\\partial E}{\\partial \\kappa}c_{\\kappa} = 0\n$$\nThis means the vector $(c_{\\mu}, c_{\\kappa})$ must be orthogonal to the gradient of $E$, $\\nabla E = (\\frac{\\partial E}{\\partial \\mu}, \\frac{\\partial E}{\\partial \\kappa})$. A vector that spans the nullspace of the sensitivity map is any vector proportional to $(\\frac{\\partial E}{\\partial \\kappa}, -\\frac{\\partial E}{\\partial \\mu})$.\n\nWe compute the partial derivatives of $E(\\mu, \\kappa)$:\n$$\n\\frac{\\partial E}{\\partial \\mu} = \\frac{\\partial}{\\partial \\mu}\\left(\\frac{9\\kappa\\mu}{3\\kappa + \\mu}\\right) = \\frac{(9\\kappa)(3\\kappa + \\mu) - (9\\kappa\\mu)(1)}{(3\\kappa + \\mu)^2} = \\frac{27\\kappa^2 + 9\\kappa\\mu - 9\\kappa\\mu}{(3\\kappa + \\mu)^2} = \\frac{27\\kappa^2}{(3\\kappa + \\mu)^2}\n$$\n$$\n\\frac{\\partial E}{\\partial \\kappa} = \\frac{\\partial}{\\partial \\kappa}\\left(\\frac{9\\kappa\\mu}{3\\kappa + \\mu}\\right) = \\frac{(9\\mu)(3\\kappa + \\mu) - (9\\kappa\\mu)(3)}{(3\\kappa + \\mu)^2} = \\frac{27\\kappa\\mu + 9\\mu^2 - 27\\kappa\\mu}{(3\\kappa + \\mu)^2} = \\frac{9\\mu^2}{(3\\kappa + \\mu)^2}\n$$\nThe condition for the unidentifiable direction $(c_{\\mu}, c_{\\kappa})$ becomes:\n$$\n\\left(\\frac{27\\kappa^2}{(3\\kappa + \\mu)^2}\\right)c_{\\mu} + \\left(\\frac{9\\mu^2}{(3\\kappa + \\mu)^2}\\right)c_{\\kappa} = 0\n$$\nAssuming physical parameters $\\mu > 0$ and $\\kappa > 0$, the denominator $(3\\kappa + \\mu)^2$ is nonzero, so we can multiply by it:\n$$\n27\\kappa^2 c_{\\mu} + 9\\mu^2 c_{\\kappa} = 0\n$$\nDividing by $9$ gives a simpler relation:\n$$\n3\\kappa^2 c_{\\mu} + \\mu^2 c_{\\kappa} = 0\n$$\nWe need to find a non-zero vector $(c_{\\mu}, c_{\\kappa})$ that satisfies this equation. This equation defines a one-dimensional subspace (a line through the origin) in the $(c_{\\mu}, c_{\\kappa})$ plane. We can find a basis vector for this space. A simple choice is to set:\n$$\nc_{\\mu} = \\mu^2\n$$\nSubstituting this into the equation yields:\n$$\n3\\kappa^2 (\\mu^2) + \\mu^2 c_{\\kappa} = 0\n$$\nSince $\\mu \\neq 0$, we can divide by $\\mu^2$:\n$$\n3\\kappa^2 + c_{\\kappa} = 0 \\implies c_{\\kappa} = -3\\kappa^2\n$$\nTherefore, a vector that spans the nullspace of the sensitivity map is $(c_{\\mu}, c_{\\kappa}) = (\\mu^2, -3\\kappa^2)$. This vector is non-zero for any physically meaningful material. This result indicates that from a measurement of Young's modulus alone, one cannot uniquely determine the shear and bulk moduli. Infinitesimal changes in the parameters according to this vector will leave the Young's modulus unchanged to first order.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\mu^2 & -3\\kappa^2 \\end{pmatrix}}\n$$", "id": "2650373"}, {"introduction": "While the analysis of structural identifiability [@problem_id:2650373] assumes perfect data, real-world measurements are invariably contaminated with noise and, more problematically, occasional gross errors or outliers. Standard least-squares estimators, which are optimal for Gaussian noise, are notoriously sensitive to such outliers, potentially leading to highly skewed parameter estimates. This practice [@problem_id:2650354] delves into the world of robust statistics, tasking you with implementing and comparing estimators based on the Huber and Student's-t loss functions, which are designed to automatically down-weight the influence of outliers and provide more reliable results.", "problem": "Consider a one-dimensional axially loaded, prismatic bar of length $L$ and cross-sectional area $A$ made of a linearly elastic, homogeneous, isotropic material with Young’s modulus $E$. Under an applied axial force $F$, the axial stress is $\\sigma = F/A$, the axial strain is $\\varepsilon = \\sigma/E$, and the end-shortening (axial displacement) is $u = \\varepsilon L$. Combining these definitions gives the forward model $u = FL/(AE)$. Suppose we seek to identify $E$ from multiple load–displacement measurements $\\{(F_i, u_i^{\\mathrm{obs}})\\}_{i=1}^N$ in the presence of measurement noise and possible outliers. To obtain a linear inverse problem in the unknown, define the compliance $p = 1/E$, so that the forward model for each datum becomes $u_i = c_i p$ with $c_i = F_i L / A$.\n\nThe inverse problem is to estimate $E$ (equivalently $p$) from data $\\{(c_i, u_i^{\\mathrm{obs}})\\}_{i=1}^N$ by minimizing a sum of data misfit losses over residuals $r_i(p) = u_i^{\\mathrm{obs}} - c_i p$. Starting from the principles of linear elasticity and maximum likelihood estimation, formulate the following three estimators:\n- A Gaussian (least-squares) estimator that minimizes $\\sum_{i=1}^N \\rho_{\\mathrm{G}}(r_i)$, where $\\rho_{\\mathrm{G}}(r) = \\frac{1}{2}(r/s)^2$ up to an arbitrary positive scale $s$.\n- A Huber estimator that minimizes $\\sum_{i=1}^N \\rho_{\\mathrm{H}}(r_i)$, where $\\rho_{\\mathrm{H}}(r)$ is the Huber loss with threshold $\\delta$. Use a robust, data-driven threshold specified by $\\delta = 1.345\\, s$, where $s$ is a robust residual scale estimated at each iteration as $s = 1.4826 \\, \\mathrm{MAD}(r)$ with $\\mathrm{MAD}(r) = \\mathrm{median}_i(|r_i - \\mathrm{median}_j(r_j)|)$, and with a strictly positive numerical floor if needed to avoid division by zero.\n- A Student’s-$t$ estimator that minimizes $\\sum_{i=1}^N \\rho_{\\mathrm{t}}(r_i)$, where $\\rho_{\\mathrm{t}}(r) = \\frac{\\nu+1}{2}\\,\\log\\!\\left(1 + \\frac{r^2}{\\nu s^2}\\right)$ with degrees of freedom $\\nu$ and robust scale $s$ as above.\n\nYour task is to derive, from first principles, the normal equations for the Gaussian case and the first-order optimality conditions for the Huber and Student’s-$t$ cases, and to implement an algorithm that:\n- Computes the Gaussian estimate in closed form.\n- Solves the Huber and Student’s-$t$ cases using an iteratively reweighted least squares procedure derived from the influence function $\\psi(r) = \\partial \\rho(r)/\\partial r$, using $w_i = \\psi(r_i)/r_i$ as the iteration weights and updating $p$ by weighted least squares at each iteration. Recompute the robust scale $s$ and, for the Huber loss, the threshold $\\delta$ at each iteration. Use a fixed $\\nu$ for the Student’s-$t$ loss. Iterate until the change in $p$ is below a user-chosen tolerance or a maximum iteration count is reached. Enforce the physical admissibility constraint $E > 0$ (equivalently $p > 0$) during optimization.\n\nExpress the final answers for $E$ in gigapascals (GPa), rounded to three decimal places.\n\nTest suite. Use the following physically consistent parameters and observed data. In all cases, take $L = 2$ m, $A = 10^{-4}$ m$^2$, and the true modulus $E_{\\mathrm{true}} = 210$ GPa, which is used only to generate the noise-free forward responses but is unknown to the inverse solver.\n\n- Case $\\#1$ (well-behaved data): $N = 4$, loads $\\{F_i\\} = [5000, 10000, 15000, 20000]$ N. The corresponding noise-free displacements are $[FL/(AE_{\\mathrm{true}})] = [c_i/E_{\\mathrm{true}}] = [10^8, 2\\cdot 10^8, 3\\cdot 10^8, 4\\cdot 10^8]/(210\\cdot 10^9)$ m. The observed displacements include small noise: $u^{\\mathrm{obs}} = [0.0004763904761904762, 0.0009522809523809524, 0.0014287214285714286, 0.0019047119047619049]$ m.\n- Case $\\#2$ (two large outliers): Same loads as Case $\\#1$. Observed displacements: $u^{\\mathrm{obs}} = [0.0004763904761904762, 0.0014522809523809524, 0.0008287214285714286, 0.0019047119047619049]$ m.\n- Case $\\#3$ (near-zero load and a severe outlier): $N = 4$, loads $\\{F_i\\} = [0, 2000, 4000, 30000]$ N. Observed displacements: $u^{\\mathrm{obs}} = [0.0000001, 0.0001906761904761905, 0.000380852380952381, 0.001857142857142857]$ m.\n\nFor the Student’s-$t$ loss, use $\\nu = 3$ for all cases. For Huber, compute $\\delta$ from the robust scale $s$ at each iteration as specified. For all three cases, you may initialize the iterative methods at the Gaussian (least-squares) estimate. Use any reasonable numerical tolerance and iteration cap that ensures convergence for these data.\n\nFinal output format. Your program should produce a single line of output containing, in order, for Cases $\\#1$ through $\\#3$, the triplets of estimated moduli in GPa under Gaussian, Huber, and Student’s-$t$ losses, rounded to three decimal places, aggregated as a single list of lists, for example:\n- Output shape: $[[E_{\\mathrm{G},1}, E_{\\mathrm{H},1}, E_{\\mathrm{t},1}], [E_{\\mathrm{G},2}, E_{\\mathrm{H},2}, E_{\\mathrm{t},2}], [E_{\\mathrm{G},3}, E_{\\mathrm{H},3}, E_{\\mathrm{t},3}]]$.\n- Unit instruction: Express all entries in GPa.\n- Rounding instruction: Round each entry to exactly three decimal places.\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[[210.000,210.000,210.000],[...],...]\").", "solution": "The problem as stated is subjected to rigorous validation.\n\n**Step 1: Extracted Givens**\n- **Physical Model**: A one-dimensional prismatic bar of length $L$, area $A$, and Young's modulus $E$.\n- **Forward Model**: The end-shortening $u$ under axial force $F$ is given by $u = FL/(AE)$.\n- **Inverse Problem Formulation**:\n    - Unknown parameter: compliance $p = 1/E$.\n    - Linearized Model: $u_i = c_i p$, where $c_i = F_i L / A$.\n    - Data: A set of $N$ measurements $\\{(F_i, u_i^{\\mathrm{obs}})\\}_{i=1}^N$.\n    - Objective: Estimate $p$ by minimizing a cost function $J(p) = \\sum_{i=1}^N \\rho(r_i)$ over the residuals $r_i(p) = u_i^{\\mathrm{obs}} - c_i p$.\n- **Loss Functions**:\n    1.  **Gaussian**: $\\rho_{\\mathrm{G}}(r) = \\frac{1}{2}(r/s)^2$.\n    2.  **Huber**: $\\rho_{\\mathrm{H}}(r)$, a Huber loss with a data-driven threshold $\\delta = 1.345\\, s$, where $s$ is a robust scale estimate.\n    3.  **Student's-t**: $\\rho_{\\mathrm{t}}(r) = \\frac{\\nu+1}{2}\\,\\log\\!\\left(1 + \\frac{r^2}{\\nu s^2}\\right)$ with degrees of freedom $\\nu$.\n- **Robust Scale Estimation**: $s = 1.4826 \\, \\mathrm{MAD}(r)$, where $\\mathrm{MAD}(r) = \\mathrm{median}_i(|r_i - \\mathrm{median}_j(r_j)|)$. A positive numerical floor is advised.\n- **Algorithmic Requirements**:\n    - Derive normal equations for the Gaussian case and provide a closed-form solution.\n    - Derive first-order optimality conditions for Huber and Student's-t cases.\n    - Implement an Iteratively Reweighted Least Squares (IRLS) procedure for Huber and Student's-t, where weights are defined by $w_i = \\psi(r_i)/r_i$ and $\\psi(r) = \\partial \\rho/\\partial r$. The scale $s$ and threshold $\\delta$ must be recomputed at each iteration.\n    - Enforce the physical admissibility constraint $E > 0$ (i.e., $p > 0$).\n- **Test Data**:\n    - Common parameters: $L = 2$ m, $A = 10^{-4}$ m$^2$, $\\nu = 3$ for the Student's-t estimator.\n    - Case $\\#1$: Well-behaved data with forces $\\{F_i\\} = [5000, 10000, 15000, 20000]$ N and corresponding displacements $u^{\\mathrm{obs}} = [0.00047639..., 0.00095228..., 0.00142872..., 0.00190471...]$ m.\n    - Case $\\#2$: Data with two outliers, same forces as Case $\\#1$, but $u^{\\mathrm{obs}} = [0.00047639..., 0.00145228..., 0.00082872..., 0.00190471...]$ m.\n    - Case $\\#3$: Data with a near-zero load and a severe outlier, forces $\\{F_i\\} = [0, 2000, 4000, 30000]$ N and $u^{\\mathrm{obs}} = [0.0000001, 0.00019067..., 0.00038085..., 0.00185714...]$ m.\n\n**Step 2: Validation Using Extracted Givens**\nThe problem is assessed for validity.\n- **Scientifically Grounded**: The problem is based on the fundamental theory of linear elasticity and established principles of statistical parameter estimation (maximum likelihood, robust regression). This is sound.\n- **Well-Posed**: The formulation leads to convex optimization problems for a single parameter, which admit unique and stable solutions. The problem is well-posed.\n- **Objective**: The problem is stated using precise mathematical and physical terminology, free of subjectivity or ambiguity.\n- **Completeness**: All necessary parameters, data, and algorithmic constraints are provided. The problem is self-contained.\n- **Realism**: The physical parameters and data are consistent and realistic for a typical engineering scenario involving experimental measurement. The presence of noise and outliers is a practical concern addressed by the specified methods.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, objective, and complete. It represents a standard, non-trivial task in inverse problem theory applied to solid mechanics. Therefore, the problem is deemed **valid**, and a solution will be furnished.\n\n---\n\n**Solution Derivations**\n\nThe objective is to find the compliance $p$ that minimizes the total loss, $J(p) = \\sum_{i=1}^N \\rho(r_i(p))$, where $r_i(p) = u_i^{\\mathrm{obs}} - c_i p$. The first-order necessary condition for a minimum is that the derivative of the objective function with respect to the unknown parameter $p$ must be zero:\n$$\n\\frac{dJ}{dp} = \\sum_{i=1}^N \\frac{d\\rho(r_i)}{dr_i} \\frac{dr_i}{dp} = 0\n$$\nThe derivative of the residual is $\\frac{dr_i}{dp} = -c_i$. The derivative of the loss function $\\rho$ with respect to its argument is the influence function, $\\psi(r) = d\\rho/dr$. The optimality condition is therefore:\n$$\n\\sum_{i=1}^N \\psi(r_i) (-c_i) = 0 \\quad \\implies \\quad \\sum_{i=1}^N c_i \\psi(r_i(p)) = 0\n$$\n\n**1. Gaussian (Least-Squares) Estimator**\nFor the Gaussian case, the loss is $\\rho_{\\mathrm{G}}(r) = \\frac{1}{2s^2} r^2$. The constant factor $\\frac{1}{2s^2}$ can be ignored for minimization, so we effectively minimize $J_{LS}(p) = \\sum_{i=1}^N r_i^2$. The influence function is $\\psi_{\\mathrm{G}}(r) = r$.\nSubstituting into the optimality condition:\n$$\n\\sum_{i=1}^N c_i r_i = \\sum_{i=1}^N c_i (u_i^{\\mathrm{obs}} - c_i p) = 0\n$$\nRearranging for $p$ yields the normal equation:\n$$\n\\left(\\sum_{i=1}^N c_i^2\\right) p = \\sum_{i=1}^N c_i u_i^{\\mathrm{obs}}\n$$\nThis gives the closed-form solution for the least-squares estimate, $p_{\\mathrm{LS}}$:\n$$\np_{\\mathrm{LS}} = \\frac{\\sum_{i=1}^N c_i u_i^{\\mathrm{obs}}}{\\sum_{i=1}^N c_i^2} = \\frac{\\mathbf{c}^T \\mathbf{u}^{\\mathrm{obs}}}{\\mathbf{c}^T \\mathbf{c}}\n$$\nwhere $\\mathbf{c} = [c_1, \\dots, c_N]^T$ and $\\mathbf{u}^{\\mathrm{obs}} = [u_1^{\\mathrm{obs}}, \\dots, u_N^{\\mathrm{obs}}]^T$.\n\n**2. Iteratively Reweighted Least Squares (IRLS) for Robust Estimators**\nFor the Huber and Student's-t estimators, the optimality condition $\\sum_i c_i \\psi(r_i(p)) = 0$ is nonlinear in $p$ and requires an iterative solution. The IRLS algorithm is derived by defining a weight function $w(r) = \\psi(r)/r$. The optimality condition can then be rewritten as:\n$$\n\\sum_{i=1}^N c_i w(r_i) r_i = \\sum_{i=1}^N c_i w(r_i) (u_i^{\\mathrm{obs}} - c_i p) = 0\n$$\nThis equation is linear in $p$ if the weights $w_i$ are held constant. This suggests an iterative procedure. At iteration $k+1$, given the estimate $p^{(k)}$, we compute residuals $r_i^{(k)}$, then weights $w_i^{(k)} = w(r_i^{(k)})$, and solve for the new estimate $p^{(k+1)}$:\n$$\n\\left(\\sum_{i=1}^N w_i^{(k)} c_i^2\\right) p^{(k+1)} = \\sum_{i=1}^N w_i^{(k)} c_i u_i^{\\mathrm{obs}}\n$$\n$$\np^{(k+1)} = \\frac{\\sum_{i=1}^N w_i^{(k)} c_i u_i^{\\mathrm{obs}}}{\\sum_{i=1}^N w_i^{(k)} c_i^2} = \\frac{\\mathbf{c}^T \\mathbf{W}^{(k)} \\mathbf{u}^{\\mathrm{obs}}}{\\mathbf{c}^T \\mathbf{W}^{(k)} \\mathbf{c}}\n$$\nwhere $\\mathbf{W}^{(k)}$ is a diagonal matrix with entries $w_i^{(k)}$. The iteration proceeds until convergence, i.e., $|p^{(k+1)} - p^{(k)}|$ is smaller than a prescribed tolerance.\n\n**2.1. Huber Estimator**\nThe Huber influence function is $\\psi_{\\mathrm{H}}(r) = \\mathrm{min}(|r|, \\delta) \\, \\mathrm{sgn}(r)$. The weight function is therefore:\n$$\nw_{\\mathrm{H}}(r) = \\frac{\\psi_{\\mathrm{H}}(r)}{r} = \\begin{cases} 1 & |r| \\le \\delta \\\\ \\delta/|r| & |r| > \\delta \\end{cases} = \\mathrm{min}(1, \\delta/|r|)\n$$\nAt each IRLS iteration, the robust scale $s^{(k)}$ is computed from the current residuals $\\mathbf{r}^{(k)}$, and the threshold is updated as $\\delta^{(k)} = 1.345 s^{(k)}$. These values are used to compute the weights $w_i^{(k)}$.\n\n**2.2. Student's-t Estimator**\nThe loss is $\\rho_{\\mathrm{t}}(r) = \\frac{\\nu+1}{2}\\log(1 + \\frac{r^2}{\\nu s^2})$. The influence function is:\n$$\n\\psi_{\\mathrm{t}}(r) = \\frac{d\\rho_t}{dr} = \\frac{\\nu+1}{2} \\cdot \\frac{1}{1 + r^2/(\\nu s^2)} \\cdot \\frac{2r}{\\nu s^2} = \\frac{(\\nu+1)r}{\\nu s^2 + r^2}\n$$\nThe corresponding weight function is:\n$$\nw_{\\mathrm{t}}(r) = \\frac{\\psi_{\\mathrm{t}}(r)}{r} = \\frac{\\nu+1}{\\nu s^2 + r^2}\n$$\nAt each IRLS iteration, the robust scale $s^{(k)}$ is computed from the current residuals $\\mathbf{r}^{(k)}$, which is then used to calculate the weights $w_i^{(k)}$.\n\n**3. Physical Admissibility**\nThe physical constraint $E > 0$ implies $p > 0$. In the IRLS update, the denominator $\\sum w_i c_i^2$ is guaranteed to be positive, as $w_i > 0$ for both Huber and Student's-t estimators and $c_i^2 \\ge 0$. The numerator $\\sum w_i c_i u_i^{\\mathrm{obs}}$ is expected to be positive for physically reasonable data where applied forces $F_i$ (and thus $c_i$) and measured displacements $u_i^{\\mathrm{obs}}$ have the same sign. If a numerical update were to yield $p \\le 0$, it is projected onto the admissible set by clamping it at a small positive value $\\epsilon_p > 0$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for Young's modulus E using Gaussian, Huber, and Student's-t estimators\n    for three different data cases.\n    \"\"\"\n    # Common physical parameters\n    L = 2.0  # m\n    A = 1.0e-4  # m^2\n\n    # Test suite containing three cases\n    test_cases = [\n        {\n            \"F\": np.array([5000, 10000, 15000, 20000]),  # N\n            \"u_obs\": np.array([0.0004763904761904762, 0.0009522809523809524, \n                               0.0014287214285714286, 0.0019047119047619049])  # m\n        },\n        {\n            \"F\": np.array([5000, 10000, 15000, 20000]),  # N\n            \"u_obs\": np.array([0.0004763904761904762, 0.0014522809523809524, \n                               0.0008287214285714286, 0.0019047119047619049])  # m\n        },\n        {\n            \"F\": np.array([0, 2000, 4000, 30000]),  # N\n            \"u_obs\": np.array([0.0000001, 0.0001906761904761905, \n                               0.000380852380952381, 0.001857142857142857])  # m\n        }\n    ]\n\n    # IRLS algorithm parameters\n    nu = 3.0  # Degrees of freedom for Student's-t loss\n    tol = 1.0e-12  # Convergence tolerance for compliance p\n    max_iter = 100  # Maximum number of iterations\n    s_floor = 1.0e-12  # Numerical floor for robust scale s\n    p_floor = 1.0e-15  # Numerical floor for compliance p (to enforce p > 0)\n\n    all_results = []\n\n    for case in test_cases:\n        F = case[\"F\"]\n        u_obs = case[\"u_obs\"]\n        c = F * L / A  # Model coefficients\n\n        # --- Gaussian (Least-Squares) Estimator ---\n        # Closed-form solution: p_ls = (c^T u_obs) / (c^T c)\n        p_ls_numerator = np.dot(c, u_obs)\n        p_ls_denominator = np.dot(c, c)\n        p_ls = p_ls_numerator / p_ls_denominator if p_ls_denominator > 0 else 0.0\n        \n        # Ensure physical admissibility\n        p_ls = max(p_ls, p_floor)\n        E_g_gpa = (1.0 / p_ls) / 1.0e9\n\n        case_results = [E_g_gpa]\n\n        # --- Huber Estimator (IRLS) ---\n        p_h = p_ls  # Initialize with LS estimate\n        for _ in range(max_iter):\n            r = u_obs - c * p_h\n            \n            # Robust scale estimation (MAD)\n            med_r = np.median(r)\n            mad = np.median(np.abs(r - med_r))\n            s = max(1.4826 * mad, s_floor)\n            delta = 1.345 * s\n\n            # Calculate weights\n            abs_r = np.abs(r)\n            # Handle r_i -> 0 case by setting weight to 1\n            weights_h = np.ones_like(r)\n            nonzero_r_mask = abs_r > 1e-12\n            weights_h[nonzero_r_mask] = np.minimum(1.0, delta / abs_r[nonzero_r_mask])\n            \n            # Weighted least squares update\n            numerator = np.dot(c, weights_h * u_obs)\n            denominator = np.dot(c, weights_h * c)\n            \n            p_h_new = numerator / denominator if denominator > 0 else p_h\n            p_h_new = max(p_h_new, p_floor)  # Enforce positivity\n\n            if np.abs(p_h_new - p_h) < tol:\n                p_h = p_h_new\n                break\n            \n            p_h = p_h_new\n        \n        E_h_gpa = (1.0 / p_h) / 1.0e9\n        case_results.append(E_h_gpa)\n        \n        # --- Student's-t Estimator (IRLS) ---\n        p_t = p_ls  # Initialize with LS estimate\n        for _ in range(max_iter):\n            r = u_obs - c * p_t\n\n            # Robust scale estimation (MAD)\n            med_r = np.median(r)\n            mad = np.median(np.abs(r - med_r))\n            s = max(1.4826 * mad, s_floor)\n            \n            # Calculate weights\n            weights_t = (nu + 1.0) / (nu * s**2 + r**2)\n            \n            # Weighted least squares update\n            numerator = np.dot(c, weights_t * u_obs)\n            denominator = np.dot(c, weights_t * c)\n\n            p_t_new = numerator / denominator if denominator > 0 else p_t\n            p_t_new = max(p_t_new, p_floor) # Enforce positivity\n\n            if np.abs(p_t_new - p_t) < tol:\n                p_t = p_t_new\n                break\n            \n            p_t = p_t_new\n\n        E_t_gpa = (1.0 / p_t) / 1.0e9\n        case_results.append(E_t_gpa)\n        \n        all_results.append(case_results)\n\n    # Format the final output string according to the problem specification\n    final_output_parts = []\n    for case_res_list in all_results:\n        formatted_list = [f\"{val:.3f}\" for val in case_res_list]\n        final_output_parts.append(f\"[{','.join(formatted_list)}]\")\n    \n    print(f\"[{','.join(final_output_parts)}]\")\n\nsolve()\n```", "id": "2650354"}, {"introduction": "Having explored identifiability and data robustness in simpler contexts, we now turn to a challenge at the heart of modern computational mechanics: identifying parameters in complex, nonlinear models. For systems described by partial differential equations, such as a hyperelastic body, calculating the gradient of a misfit functional needed for optimization can be a daunting task, especially with many parameters. This advanced practice [@problem_id:2650370] introduces the powerful adjoint method, an elegant and exceptionally efficient technique for computing gradients at a cost nearly independent of the number of parameters, asking you to derive the adjoint system and gradient expressions for a nonlinear hyperelasticity problem.", "problem": "A homogeneous hyperelastic body occupying a bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^{3}$ in its reference configuration is subjected to a quasi-static displacement-controlled experiment. The boundary $\\partial \\Omega$ is partitioned into a Dirichlet part $\\Gamma_{D}$ and a Neumann part $\\Gamma_{N}$ with $\\Gamma_{D} \\cup \\Gamma_{N} = \\partial \\Omega$ and $\\Gamma_{D} \\cap \\Gamma_{N} = \\emptyset$. There are no body forces. At a discrete sequence of load steps $i = 1, \\dots, M$, a displacement $\\bar{\\boldsymbol{u}}_{i}$ is prescribed on $\\Gamma_{D}$, while $\\Gamma_{N}$ is traction-free.\n\nAssume the specimen is nearly incompressible, with the Jacobian of the deformation gradient $J \\approx 1$, but do not impose the constraint $J = 1$ exactly. Instead, adopt a compressible Neo-Hookean stored-energy density\n$$\n\\psi(\\boldsymbol{F}; \\mu, \\kappa) = \\frac{\\mu}{2}\\left(I_{1} - 3 - 2 \\ln J\\right) + \\frac{\\kappa}{2}\\left(\\ln J\\right)^{2},\n$$\nwhere $\\boldsymbol{F} = \\boldsymbol{I} + \\nabla \\boldsymbol{u}$ is the deformation gradient, $J = \\det \\boldsymbol{F}$, $I_{1} = \\mathrm{tr}(\\boldsymbol{C})$, and $\\boldsymbol{C} = \\boldsymbol{F}^{\\mathsf{T}}\\boldsymbol{F}$. The first Piola–Kirchhoff stress is $\\boldsymbol{P} = \\partial \\psi / \\partial \\boldsymbol{F}$. The balance of linear momentum in weak form for load step $i$ is: find $\\boldsymbol{u}_{i}$ with $\\boldsymbol{u}_{i} = \\bar{\\boldsymbol{u}}_{i}$ on $\\Gamma_{D}$ such that, for all virtual displacements $\\boldsymbol{w} \\in \\mathcal{V}_{0} := \\{\\boldsymbol{w} \\in [H^{1}(\\Omega)]^{3} : \\boldsymbol{w} = \\boldsymbol{0} \\text{ on } \\Gamma_{D}\\}$,\n$$\nr_{i}(\\boldsymbol{u}_{i}; \\mu, \\kappa)(\\boldsymbol{w}) := \\int_{\\Omega} \\boldsymbol{P}(\\boldsymbol{F}(\\boldsymbol{u}_{i}); \\mu, \\kappa) : \\nabla \\boldsymbol{w} \\, \\mathrm{d}V = 0.\n$$\n\nLet $\\boldsymbol{N}$ denote the outward unit normal in the reference configuration. The measured scalar load-displacement data consist of resultant forces $\\widehat{R}_{i}$ along a fixed unit direction $\\boldsymbol{e}$ at the steps $i=1,\\dots,M$. The model-predicted reaction resultant is defined by\n$$\nR_{i}(\\boldsymbol{u}_{i}; \\mu, \\kappa) := \\int_{\\Gamma_{D}} \\left(\\boldsymbol{P}(\\boldsymbol{F}(\\boldsymbol{u}_{i}); \\mu, \\kappa)\\, \\boldsymbol{N}\\right)\\cdot \\boldsymbol{e} \\, \\mathrm{d}A.\n$$\nIntroduce a fixed, sufficiently smooth extension field $\\boldsymbol{v}^{\\star} \\in [H^{1}(\\Omega)]^{3}$ satisfying the essential boundary prescription $\\boldsymbol{v}^{\\star} = \\boldsymbol{e}$ on $\\Gamma_{D}$ and $\\boldsymbol{v}^{\\star} = \\boldsymbol{0}$ on $\\Gamma_{N}$. By the divergence theorem, this yields the equivalent volume representation\n$$\nR_{i}(\\boldsymbol{u}_{i}; \\mu, \\kappa) = \\int_{\\Omega} \\boldsymbol{P}(\\boldsymbol{F}(\\boldsymbol{u}_{i}); \\mu, \\kappa) : \\nabla \\boldsymbol{v}^{\\star} \\, \\mathrm{d}V.\n$$\n\nDefine the weighted least-squares misfit\n$$\n\\Phi(\\mu, \\kappa) = \\frac{1}{2} \\sum_{i=1}^{M} \\alpha_{i} \\left(R_{i}(\\boldsymbol{u}_{i}; \\mu, \\kappa) - \\widehat{R}_{i}\\right)^{2},\n$$\nwith given positive weights $\\alpha_{i}$. For each step $i$, let $\\mathbb{A}_{i}(\\boldsymbol{u}_{i}; \\mu, \\kappa)$ denote the fourth-order material tangent $\\mathbb{A}_{i} = \\partial \\boldsymbol{P} / \\partial \\boldsymbol{F}$ evaluated at $\\boldsymbol{F}(\\boldsymbol{u}_{i})$.\n\nUsing only fundamental balance laws, hyperelastic constitutive definitions, and the calculus of variations, derive an adjoint-based expression for the gradient of $\\Phi$ with respect to $(\\mu, \\kappa)$. You must:\n- Formulate the adjoint problem at each step $i$ in a weak form that enforces homogeneous essential conditions on $\\Gamma_{D}$ for the adjoint displacement $\\boldsymbol{\\lambda}_{i} \\in \\mathcal{V}_{0}$.\n- Provide the final expressions for $\\partial \\Phi / \\partial \\mu$ and $\\partial \\Phi / \\partial \\kappa$ as volume integrals that involve only $(\\boldsymbol{u}_{i}, \\boldsymbol{\\lambda}_{i})$, the measured data $\\widehat{R}_{i}$, the weights $\\alpha_{i}$, and known kinematic quantities.\n\nExpress your final answer as a single row vector containing the two gradient components in closed form, using the symbols defined above. No numerical evaluation is required. Do not simplify by imposing $J = 1$; retain the exact expressions in terms of $J$. The answer must be a single analytical expression. Units are not required. Angles, if any, must be in radians. Round nothing; provide exact expressions.", "solution": "The user has provided a valid, well-posed problem in the field of computational solid mechanics, specifically concerning parameter identification using an adjoint-based sensitivity analysis. The problem is scientifically grounded, free of contradictions, and contains all necessary information to perform the requested derivation.\n\nThe objective is to derive the gradient of the least-squares functional $\\Phi(\\mu, \\kappa)$ with respect to the material parameters $(\\mu, \\kappa)$. The functional is given by\n$$\n\\Phi(\\mu, \\kappa) = \\frac{1}{2} \\sum_{i=1}^{M} \\alpha_{i} \\left(R_{i}(\\boldsymbol{u}_{i}; \\mu, \\kappa) - \\widehat{R}_{i}\\right)^{2}\n$$\nwhere $\\boldsymbol{u}_{i} = \\boldsymbol{u}_{i}(\\mu, \\kappa)$ is the solution to the balance of linear momentum for load step $i$, which constitutes an implicit dependence on the parameters. Let $p$ represent a generic parameter, $p \\in \\{\\mu, \\kappa\\}$. Applying the chain rule, a component of the gradient is\n$$\n\\frac{\\mathrm{d} \\Phi}{\\mathrm{d} p} = \\sum_{i=1}^{M} \\alpha_{i} \\left(R_{i} - \\widehat{R}_{i}\\right) \\frac{\\mathrm{d} R_{i}}{\\mathrm{d} p}\n$$\nThe core of the adjoint method is to efficiently compute the total derivative of the reaction force, $\\frac{\\mathrm{d} R_{i}}{\\mathrm{d} p}$. The model-predicted reaction $R_{i}$ is given by\n$$\nR_{i}(\\boldsymbol{u}_{i}; p) = \\int_{\\Omega} \\boldsymbol{P}(\\boldsymbol{F}(\\boldsymbol{u}_{i}); p) : \\nabla \\boldsymbol{v}^{\\star} \\, \\mathrm{d}V\n$$\nIts total derivative with respect to $p$ is\n$$\n\\frac{\\mathrm{d} R_{i}}{\\mathrm{d} p} = \\frac{\\partial R_{i}}{\\partial p} + \\frac{\\partial R_{i}}{\\partial \\boldsymbol{u}_{i}} \\left[ \\frac{\\mathrm{d} \\boldsymbol{u}_{i}}{\\mathrm{d} p} \\right]\n$$\nThe first term accounts for the explicit dependence of $\\boldsymbol{P}$ on $p$, and the second term, a Gâteaux derivative in the direction of the sensitivity $\\dot{\\boldsymbol{u}}_{i} := \\frac{\\mathrm{d} \\boldsymbol{u}_{i}}{\\mathrm{d} p}$, accounts for the implicit dependence through the state variable $\\boldsymbol{u}_{i}$.\nThe explicit derivative is\n$$\n\\frac{\\partial R_{i}}{\\partial p} = \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{v}^{\\star} \\, \\mathrm{d}V\n$$\nThe implicit term is\n$$\n\\frac{\\partial R_{i}}{\\partial \\boldsymbol{u}_{i}} [\\dot{\\boldsymbol{u}}_{i}] = \\int_{\\Omega} \\left( \\frac{\\partial \\boldsymbol{P}}{\\partial \\boldsymbol{F}} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\right) : \\nabla \\boldsymbol{v}^{\\star} \\, \\mathrm{d}V = \\int_{\\Omega} \\nabla \\boldsymbol{v}^{\\star} : \\mathbb{A}_{i} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\, \\mathrm{d}V\n$$\nwhere $\\mathbb{A}_{i} = \\frac{\\partial \\boldsymbol{P}}{\\partial \\boldsymbol{F}}$ is the material tangent. The sensitivity $\\dot{\\boldsymbol{u}}_{i} \\in \\mathcal{V}_{0}$ since the prescribed boundary condition $\\bar{\\boldsymbol{u}}_{i}$ does not depend on the material parameters. The governing equation for $\\dot{\\boldsymbol{u}}_{i}$ is found by differentiating the weak form of the state equation, $r_{i}(\\boldsymbol{u}_{i}; p)(\\boldsymbol{w}) = 0$, with respect to $p$:\n$$\n\\frac{\\mathrm{d} r_{i}}{\\mathrm{d} p}(\\boldsymbol{w}) = \\int_{\\Omega} \\left( \\frac{\\partial \\boldsymbol{P}}{\\partial \\boldsymbol{F}} : \\nabla \\dot{\\boldsymbol{u}}_{i} + \\frac{\\partial \\boldsymbol{P}}{\\partial p} \\right) : \\nabla \\boldsymbol{w} \\, \\mathrm{d}V = 0 \\quad \\forall \\boldsymbol{w} \\in \\mathcal{V}_{0}\n$$\nThis can be written as the sensitivity equation: Find $\\dot{\\boldsymbol{u}}_{i} \\in \\mathcal{V}_{0}$ such that\n$$\n\\int_{\\Omega} \\nabla \\boldsymbol{w} : \\mathbb{A}_{i} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\, \\mathrm{d}V = - \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{w} \\, \\mathrm{d}V \\quad \\forall \\boldsymbol{w} \\in \\mathcal{V}_{0}\n$$\nThe adjoint method is introduced to avoid solving this equation for each parameter. We define an adjoint problem for an auxiliary variable $\\boldsymbol{\\lambda}_{i} \\in \\mathcal{V}_{0}$. The weak form is constructed to eliminate the unknown sensitivity $\\dot{\\boldsymbol{u}}_{i}$ from the derivative expression. The adjoint equation is defined as: Find $\\boldsymbol{\\lambda}_{i} \\in \\mathcal{V}_{0}$ such that\n$$\n\\int_{\\Omega} \\nabla \\boldsymbol{w} : \\mathbb{A}_{i} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V = -\\frac{\\partial R_{i}}{\\partial \\boldsymbol{u}_{i}}[\\boldsymbol{w}] = - \\int_{\\Omega} \\nabla \\boldsymbol{v}^{\\star} : \\mathbb{A}_{i} : \\nabla \\boldsymbol{w} \\, \\mathrm{d}V \\quad \\forall \\boldsymbol{w} \\in \\mathcal{V}_{0}\n$$\nThis is the required weak formulation of the adjoint problem with homogeneous essential boundary conditions on $\\Gamma_D$. The material tangent $\\mathbb{A}$ for a hyperelastic material possesses major symmetry, implying the tangent bilinear form is symmetric.\nNow, we use this construction. First, set the test function $\\boldsymbol{w}$ in the adjoint equation to the sensitivity $\\dot{\\boldsymbol{u}}_{i} \\in \\mathcal{V}_{0}$:\n$$\n\\int_{\\Omega} \\nabla \\dot{\\boldsymbol{u}}_{i} : \\mathbb{A}_{i} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V = - \\int_{\\Omega} \\nabla \\boldsymbol{v}^{\\star} : \\mathbb{A}_{i} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\, \\mathrm{d}V = - \\frac{\\partial R_{i}}{\\partial \\boldsymbol{u}_{i}} [\\dot{\\boldsymbol{u}}_{i}]\n$$\nDue to the symmetry of the bilinear form, $\\int_{\\Omega} \\nabla \\dot{\\boldsymbol{u}}_{i} : \\mathbb{A}_{i} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V = \\int_{\\Omega} \\nabla \\boldsymbol{\\lambda}_{i} : \\mathbb{A}_{i} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\, \\mathrm{d}V$. Thus,\n$$\n\\frac{\\partial R_{i}}{\\partial \\boldsymbol{u}_{i}} [\\dot{\\boldsymbol{u}}_{i}] = - \\int_{\\Omega} \\nabla \\boldsymbol{\\lambda}_{i} : \\mathbb{A}_{i} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\, \\mathrm{d}V\n$$\nNext, set the test function $\\boldsymbol{w}$ in the sensitivity equation to the adjoint variable $\\boldsymbol{\\lambda}_{i} \\in \\mathcal{V}_{0}$:\n$$\n\\int_{\\Omega} \\nabla \\boldsymbol{\\lambda}_{i} : \\mathbb{A}_{i} : \\nabla \\dot{\\boldsymbol{u}}_{i} \\, \\mathrm{d}V = - \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V\n$$\nCombining the last two results gives an expression for the implicit part of the derivative without $\\dot{\\boldsymbol{u}}_{i}$:\n$$\n\\frac{\\partial R_{i}}{\\partial \\boldsymbol{u}_{i}} [\\dot{\\boldsymbol{u}}_{i}] = - \\left( - \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V \\right) = \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V\n$$\nSubstituting this into the total derivative of $R_{i}$ yields\n$$\n\\frac{\\mathrm{d} R_{i}}{\\mathrm{d} p} = \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{v}^{\\star} \\, \\mathrm{d}V + \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : \\nabla \\boldsymbol{\\lambda}_{i} \\, \\mathrm{d}V = \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}}{\\partial p} : (\\nabla \\boldsymbol{v}^{\\star} + \\nabla \\boldsymbol{\\lambda}_{i}) \\, \\mathrm{d}V\n$$\nThe gradient of the cost functional is then\n$$\n\\frac{\\mathrm{d} \\Phi}{\\mathrm{d} p} = \\sum_{i=1}^{M} \\alpha_{i} (R_{i} - \\widehat{R}_{i}) \\int_{\\Omega} \\frac{\\partial \\boldsymbol{P}_{i}}{\\partial p} : (\\nabla \\boldsymbol{v}^{\\star} + \\nabla \\boldsymbol{\\lambda}_{i}) \\, \\mathrm{d}V\n$$\nTo obtain the specific components of the gradient, we must compute the partial derivatives of the first Piola-Kirchhoff stress $\\boldsymbol{P}$ with respect to $\\mu$ and $\\kappa$. The stored-energy density is $\\psi(\\boldsymbol{F}; \\mu, \\kappa) = \\frac{\\mu}{2}\\left(I_{1} - 3 - 2 \\ln J\\right) + \\frac{\\kappa}{2}\\left(\\ln J\\right)^{2}$.\nUsing the relations $\\frac{\\partial I_{1}}{\\partial \\boldsymbol{F}} = 2\\boldsymbol{F}$ and $\\frac{\\partial \\ln J}{\\partial \\boldsymbol{F}} = \\boldsymbol{F}^{-\\mathsf{T}}$, the stress is\n$$\n\\boldsymbol{P} = \\frac{\\partial \\psi}{\\partial \\boldsymbol{F}} = \\frac{\\mu}{2}(2\\boldsymbol{F} - 2\\boldsymbol{F}^{-\\mathsf{T}}) + \\frac{\\kappa}{2}(2\\ln J) \\boldsymbol{F}^{-\\mathsf{T}} = \\mu(\\boldsymbol{F} - \\boldsymbol{F}^{-\\mathsf{T}}) + \\kappa(\\ln J) \\boldsymbol{F}^{-\\mathsf{T}}\n$$\nThe partial derivatives with respect to the parameters are straightforward:\n$$\n\\frac{\\partial \\boldsymbol{P}}{\\partial \\mu} = \\boldsymbol{F} - \\boldsymbol{F}^{-\\mathsf{T}}\n$$\n$$\n\\frac{\\partial \\boldsymbol{P}}{\\partial \\kappa} = (\\ln J) \\boldsymbol{F}^{-\\mathsf{T}}\n$$\nSubstituting these expressions into the formula for $\\frac{\\mathrm{d} \\Phi}{\\mathrm{d} p}$, we obtain the components of the gradient. For each load step $i$, $\\boldsymbol{F}_i = \\boldsymbol{F}(\\boldsymbol{u}_i)$ and $J_i = \\det(\\boldsymbol{F}_i)$.\nThe gradient component with respect to $\\mu$ is\n$$\n\\frac{\\partial \\Phi}{\\partial \\mu} = \\sum_{i=1}^{M} \\alpha_{i} (R_{i} - \\widehat{R}_{i}) \\int_{\\Omega} (\\boldsymbol{F}_{i} - \\boldsymbol{F}_{i}^{-\\mathsf{T}}) : (\\nabla \\boldsymbol{v}^{\\star} + \\nabla \\boldsymbol{\\lambda}_{i}) \\, \\mathrm{d}V\n$$\nThe gradient component with respect to $\\kappa$ is\n$$\n\\frac{\\partial \\Phi}{\\partial \\kappa} = \\sum_{i=1}^{M} \\alpha_{i} (R_{i} - \\widehat{R}_{i}) \\int_{\\Omega} (\\ln J_{i}) \\boldsymbol{F}_{i}^{-\\mathsf{T}} : (\\nabla \\boldsymbol{v}^{\\star} + \\nabla \\boldsymbol{\\lambda}_{i}) \\, \\mathrm{d}V\n$$\nThese expressions depend only on the solutions of the forward problems $\\boldsymbol{u}_i$ (which determine $\\boldsymbol{F}_i$, $J_i$, and $R_i$), the solutions of the adjoint problems $\\boldsymbol{\\lambda}_i$, the measured data $\\widehat{R}_i$, the weights $\\alpha_i$, and the known field $\\boldsymbol{v}^{\\star}$, as required.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\sum_{i=1}^{M} \\alpha_{i} \\left(R_{i} - \\widehat{R}_{i}\\right) \\int_{\\Omega} (\\boldsymbol{F}_{i} - \\boldsymbol{F}_{i}^{-\\mathsf{T}}) : (\\nabla \\boldsymbol{v}^{\\star} + \\nabla \\boldsymbol{\\lambda}_{i}) \\, \\mathrm{d}V & \\sum_{i=1}^{M} \\alpha_{i} \\left(R_{i} - \\widehat{R}_{i}\\right) \\int_{\\Omega} (\\ln J_{i}) \\boldsymbol{F}_{i}^{-\\mathsf{T}} : (\\nabla \\boldsymbol{v}^{\\star} + \\nabla \\boldsymbol{\\lambda}_{i}) \\, \\mathrm{d}V \\end{pmatrix}}\n$$", "id": "2650370"}]}