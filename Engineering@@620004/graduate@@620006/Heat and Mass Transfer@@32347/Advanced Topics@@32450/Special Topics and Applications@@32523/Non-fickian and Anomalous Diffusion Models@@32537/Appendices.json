{"hands_on_practices": [{"introduction": "The mean-square displacement (MSD) is the primary metric for characterizing diffusive processes. While classical diffusion exhibits a linear growth of MSD with time, anomalous diffusion is defined by a power-law scaling, $\\langle x^2(t) \\rangle \\propto t^{\\alpha}$, where the exponent $\\alpha \\neq 1$ reveals the nature of the transport. This foundational exercise [@problem_id:2512376] guides you through the analytical derivation of this scaling directly from the time-fractional diffusion equation (TFDE), providing a rigorous link between the fractional operator and the resulting subdiffusive behavior.", "problem": "Consider the one-dimensional time-fractional diffusion equation (TFDE) with a Caputo time derivative of order $0\\alpha1$,\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} C(x,t) = D\\,\\frac{\\partial^{2} C(x,t)}{\\partial x^{2}}, \\quad x\\in\\mathbb{R},\\; t0,\n$$\nsubject to the point-source initial condition $C(x,0^{+})=\\delta(x)$ and the normalization constraint $\\int_{-\\infty}^{\\infty} C(x,t)\\,dx = 1$ for all $t0$. The generalized diffusivity $D0$ has the units $\\mathrm{m^{2}\\,s^{-\\alpha}}$. The Caputo derivative is defined for a sufficiently smooth function $f$ by\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} f(t) = \\frac{1}{\\Gamma(1-\\alpha)} \\int_{0}^{t} \\frac{f'(\\tau)}{(t-\\tau)^{\\alpha}}\\,d\\tau.\n$$\nLet the mean-square displacement be defined by\n$$\n\\langle x^{2}(t)\\rangle = \\int_{-\\infty}^{\\infty} x^{2}\\,C(x,t)\\,dx.\n$$\nStarting only from the governing equation, the initial condition, and the normalization constraint, derive a closed-form analytic expression for $\\langle x^{2}(t)\\rangle$ as a function of $D$, $\\alpha$, and $t$. You may use standard properties of the Fourier transform and the Laplace transform, including the Laplace transform of the Caputo derivative. Report the final result as a single closed-form expression. Assume that if $D$ is in $\\mathrm{m^{2}\\,s^{-\\alpha}}$ and $t$ is in $\\mathrm{s}$, then $\\langle x^{2}(t)\\rangle$ is in $\\mathrm{m^{2}}$; do not include units in your final boxed expression. No numerical rounding is required; provide an exact symbolic expression.", "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It describes a standard model of anomalous subdiffusion in mathematical physics. We are tasked to find the mean-square displacement (MSD), defined as:\n$$\n\\langle x^{2}(t)\\rangle = \\int_{-\\infty}^{\\infty} x^{2}\\,C(x,t)\\,dx\n$$\nWe will proceed by deriving a differential equation for $\\langle x^{2}(t)\\rangle$ directly from the governing time-fractional diffusion equation (TFDE). The governing equation is:\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} C(x,t) = D\\,\\frac{\\partial^{2} C(x,t)}{\\partial x^{2}}\n$$\nWe begin by applying the Caputo time-derivative operator, ${}^{\\mathrm{C}}D_{t}^{\\alpha}$, to the definition of $\\langle x^{2}(t)\\rangle$.\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} \\langle x^{2}(t)\\rangle = {}^{\\mathrm{C}}D_{t}^{\\alpha} \\left[ \\int_{-\\infty}^{\\infty} x^{2}\\,C(x,t)\\,dx \\right]\n$$\nUnder the assumption that the concentration profile $C(x,t)$ and its derivatives decay sufficiently rapidly as $|x| \\to \\infty$, which is physically required for a conserved quantity diffusing from a point source in an infinite domain, we can interchange the derivative and integral operators.\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} \\langle x^{2}(t)\\rangle = \\int_{-\\infty}^{\\infty} x^{2}\\,\\left({}^{\\mathrm{C}}D_{t}^{\\alpha} C(x,t)\\right)\\,dx\n$$\nNow, we substitute the right-hand side of the TFDE into the integrand:\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} \\langle x^{2}(t)\\rangle = \\int_{-\\infty}^{\\infty} x^{2}\\,\\left(D\\,\\frac{\\partial^{2} C(x,t)}{\\partial x^{2}}\\right)\\,dx = D \\int_{-\\infty}^{\\infty} x^{2}\\,\\frac{\\partial^{2} C(x,t)}{\\partial x^{2}}\\,dx\n$$\nWe evaluate the integral on the right-hand side using integration by parts. Let $u = x^{2}$ and $dv = \\frac{\\partial^{2} C}{\\partial x^{2}}\\,dx$. Then $du = 2x\\,dx$ and $v = \\frac{\\partial C}{\\partial x}$.\n$$\n\\int_{-\\infty}^{\\infty} x^{2}\\,\\frac{\\partial^{2} C}{\\partial x^{2}}\\,dx = \\left[ x^{2}\\,\\frac{\\partial C}{\\partial x} \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} 2x\\,\\frac{\\partial C}{\\partial x}\\,dx\n$$\nThe boundary term $\\left[ x^{2}\\,\\frac{\\partial C}{\\partial x} \\right]_{-\\infty}^{\\infty}$ vanishes because the concentration and its gradient must approach zero at infinity for a physically meaningful solution. Thus, we are left with:\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} \\langle x^{2}(t)\\rangle = -2D \\int_{-\\infty}^{\\infty} x\\,\\frac{\\partial C}{\\partial x}\\,dx\n$$\nWe apply integration by parts a second time to the remaining integral. Let $u = x$ and $dv = \\frac{\\partial C}{\\partial x}\\,dx$. Then $du = dx$ and $v = C(x,t)$.\n$$\n\\int_{-\\infty}^{\\infty} x\\,\\frac{\\partial C}{\\partial x}\\,dx = \\left[ x\\,C(x,t) \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} C(x,t)\\,dx\n$$\nAgain, the boundary term $\\left[ x\\,C(x,t) \\right]_{-\\infty}^{\\infty}$ vanishes. This leaves:\n$$\n\\int_{-\\infty}^{\\infty} x\\,\\frac{\\partial C}{\\partial x}\\,dx = - \\int_{-\\infty}^{\\infty} C(x,t)\\,dx\n$$\nSubstituting this result back, we obtain:\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} \\langle x^{2}(t)\\rangle = -2D \\left( - \\int_{-\\infty}^{\\infty} C(x,t)\\,dx \\right) = 2D \\int_{-\\infty}^{\\infty} C(x,t)\\,dx\n$$\nThe problem provides the normalization constraint $\\int_{-\\infty}^{\\infty} C(x,t)\\,dx = 1$ for all $t0$. Applying this constraint yields a simple fractional ordinary differential equation for $\\langle x^{2}(t)\\rangle$:\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} \\langle x^{2}(t)\\rangle = 2D\n$$\nTo solve this equation, we require an initial condition for $\\langle x^{2}(t)\\rangle$. We can find this from the initial condition for the concentration, $C(x,0^{+})=\\delta(x)$.\n$$\n\\langle x^{2}(0^{+})\\rangle = \\int_{-\\infty}^{\\infty} x^{2}\\,C(x,0^{+})\\,dx = \\int_{-\\infty}^{\\infty} x^{2}\\,\\delta(x)\\,dx = 0\n$$\nSo we must solve the initial value problem:\n$$\n{}^{\\mathrm{C}}D_{t}^{\\alpha} y(t) = 2D, \\quad y(0) = 0\n$$\nwhere $y(t) = \\langle x^{2}(t)\\rangle$. The solution to the equation ${}^{\\mathrm{C}}D_{t}^{\\alpha} y(t) = f(t)$ with initial condition $y(0) = 0$ is given by applying the Riemann-Liouville fractional integral operator $J^{\\alpha}$ to $f(t)$.\n$$\ny(t) = J^{\\alpha}[f(t)] = \\frac{1}{\\Gamma(\\alpha)} \\int_{0}^{t} (t-\\tau)^{\\alpha-1} f(\\tau)\\,d\\tau\n$$\nIn our case, $f(t)$ is the constant $2D$.\n$$\n\\langle x^{2}(t)\\rangle = \\frac{1}{\\Gamma(\\alpha)} \\int_{0}^{t} (t-\\tau)^{\\alpha-1} (2D)\\,d\\tau = \\frac{2D}{\\Gamma(\\alpha)} \\int_{0}^{t} (t-\\tau)^{\\alpha-1}\\,d\\tau\n$$\nTo evaluate the integral, we make the substitution $u = t - \\tau$, which means $du = -d\\tau$. The limits of integration change from $\\tau=0$ to $u=t$ and $\\tau=t$ to $u=0$.\n$$\n\\int_{0}^{t} (t-\\tau)^{\\alpha-1}\\,d\\tau = \\int_{t}^{0} u^{\\alpha-1} (-du) = \\int_{0}^{t} u^{\\alpha-1}\\,du = \\left[ \\frac{u^{\\alpha}}{\\alpha} \\right]_{0}^{t} = \\frac{t^{\\alpha}}{\\alpha}\n$$\nSubstituting this result back gives the expression for the MSD:\n$$\n\\langle x^{2}(t)\\rangle = \\frac{2D}{\\Gamma(\\alpha)} \\left( \\frac{t^{\\alpha}}{\\alpha} \\right) = \\frac{2D t^{\\alpha}}{\\alpha \\Gamma(\\alpha)}\n$$\nFinally, using the property of the Gamma function, $\\Gamma(z+1)=z\\Gamma(z)$, we have $\\alpha\\Gamma(\\alpha) = \\Gamma(\\alpha+1)$. This simplifies the expression to:\n$$\n\\langle x^{2}(t)\\rangle = \\frac{2D t^{\\alpha}}{\\Gamma(\\alpha+1)}\n$$\nThis expression describes subdiffusion, where the mean-square displacement grows as a power-law in time with an exponent $\\alpha$ less than $1$. For the normal diffusion case where $\\alpha=1$, we recover the classical result $\\langle x^{2}(t)\\rangle = \\frac{2D t}{\\Gamma(2)} = 2Dt$.", "answer": "$$\n\\boxed{\\frac{2D t^{\\alpha}}{\\Gamma(\\alpha+1)}}\n$$", "id": "2512376"}, {"introduction": "Observing an anomalous scaling exponent is often just the beginning; the deeper scientific question concerns the underlying physical mechanism. Anomalous transport can arise from fundamentally different processes, such as temporal memory (particles waiting for long times) or spatial non-locality (particles making long jumps). This practice problem [@problem_id:2512419] challenges you to think like an experimentalist, using a set of hypothetical measurements of MSD, waiting times, and jump lengths to deduce which class of models provides a more consistent physical explanation.", "problem": "An experiment tracks tracer particles diffusing through a cross-linked hydrogel at temperature $T$, yielding a mean squared displacement (MSD) of the form $\\langle x^{2}(t)\\rangle = A\\, t^{0.7}$ over three decades in time, where $A$ is a known positive constant with appropriate units. Two complementary single-particle statistics are also measured from the same trajectories:\n\n1. The empirical waiting-time probability density between successive jumps, $\\psi(\\tau)$, exhibits a heavy tail consistent with $\\psi(\\tau)\\sim C\\,\\tau^{-(1+\\mu)}$ over an intermediate asymptotic range $\\tau\\in[\\tau_{0},\\tau_{c}]$, with an exponent estimate $\\mu=0.68\\pm 0.03$ and finite normalization constant $C$.\n2. The empirical jump-length probability density, $\\lambda(\\ell)$, exhibits algebraic tails $\\lambda(\\ell)\\sim D\\,|\\ell|^{-(1+\\beta)}$ for $|\\ell|\\ge \\ell_{0}$, with $\\beta=1.8\\pm 0.1$ and finite normalization constant $D$.\n\nAssume the tracer dynamics can be modeled by a random walk with independent and identically distributed waiting times and jumps, and consider the following plausible coarse-grained descriptions: (i) a Continuous Time Random Walk (CTRW) with heavy-tailed waiting times (temporal nonlocality), and (ii) a model with heavy-tailed jump lengths such as a Lévy flight or a Lévy walk (spatial nonlocality). You may assume that all measured second moments of the displacement are finite on the experimental timescale, and that the MSD scaling $\\langle x^{2}(t)\\rangle\\propto t^{\\alpha}$ defines the anomalous diffusion exponent $\\alpha$.\n\nUsing only fundamental definitions and widely accepted properties of these models, do the following:\n\n(a) From the MSD observation, compute the anomalous diffusion exponent $\\alpha$.\n\n(b) Based on the reported heavy-tailed statistics, reason from first principles whether nonlocal-in-time or nonlocal-in-space mechanisms are more consistent with the observed MSD scaling and finite second moments.\n\nReport only the numeric value of the anomalous exponent $\\alpha$ as your final answer. Express $\\alpha$ as a pure number (no units) and round to three significant figures.", "solution": "We begin from the definition of the mean squared displacement (MSD) for a one-dimensional tracer position $x(t)$,\n$$\n\\langle x^{2}(t)\\rangle \\equiv \\int_{-\\infty}^{\\infty} x^{2}\\, p(x,t)\\, dx,\n$$\nwhere $p(x,t)$ is the probability density of displacement at time $t$ and angular brackets denote an ensemble average. In classical Fickian diffusion, conservation of probability along with Fick’s law and Gaussian central limit behavior imply $\\langle x^{2}(t)\\rangle \\propto t$. Anomalous diffusion is defined by the scaling law\n$$\n\\langle x^{2}(t)\\rangle \\propto t^{\\alpha},\n$$\nwith $0\\alpha1$ indicating subdiffusion and $1\\alpha2$ indicating superdiffusion.\n\nPart (a): The experiment reports\n$$\n\\langle x^{2}(t)\\rangle = A\\, t^{0.7},\n$$\nwith $A0$ constant. Comparing to the definition $\\langle x^{2}(t)\\rangle \\propto t^{\\alpha}$, we identify directly that the anomalous diffusion exponent is\n$$\n\\alpha = 0.7.\n$$\n\nPart (b): We now assess mechanisms using first principles of random walks with heavy-tailed statistics.\n\nConsider a Continuous Time Random Walk (CTRW) with independent and identically distributed waiting times and jumps. Let $\\psi(\\tau)$ be the waiting-time probability density and $\\lambda(\\ell)$ be the jump-length probability density. The Montroll–Weiss formalism relates the Fourier–Laplace transform of $p(x,t)$ to $\\psi$ and $\\lambda$ by\n$$\n\\tilde{p}(k,s) = \\frac{1-\\tilde{\\psi}(s)}{s}\\, \\frac{1}{1-\\tilde{\\psi}(s)\\,\\hat{\\lambda}(k)},\n$$\nwhere $\\tilde{\\psi}(s)$ is the Laplace transform of $\\psi(\\tau)$ and $\\hat{\\lambda}(k)$ is the Fourier transform of $\\lambda(\\ell)$. For heavy-tailed waiting times with\n$$\n\\psi(\\tau)\\sim C\\, \\tau^{-(1+\\mu)}, \\quad 0\\mu1,\n$$\none has asymptotically $\\tilde{\\psi}(s)\\approx 1 - (s \\tau_{\\mu})^{\\mu}$ as $s\\to 0$, where $\\tau_{\\mu}$ is a characteristic time scale depending on the microscopic details. Under the assumption that $\\lambda(\\ell)$ has a finite second moment (e.g., Gaussian or sufficiently narrow-tailed jumps), a small-$k$ expansion gives $\\hat{\\lambda}(k)\\approx 1 - \\frac{\\sigma^{2}}{2}k^{2}$ for $k\\to 0$, with jump variance $\\sigma^{2}$. Substituting these into the Montroll–Weiss expression and expanding for small $s$ and $k$, one obtains the long-time, large-scale asymptotics\n$$\n\\tilde{p}(k,s) \\approx \\frac{s^{\\mu-1}}{s^{\\mu} + K_{\\mu} k^{2}},\n$$\nwith a generalized diffusivity $K_{\\mu}=\\sigma^{2}/(2 \\tau_{\\mu}^{\\mu})$. Inverting the Laplace transform yields a time-fractional diffusion equation with a Caputo derivative of order $\\mu$, and the MSD scales as\n$\n\\langle x^{2}(t)\\rangle \\sim \\frac{2 K_{\\mu}}{\\Gamma(1+\\mu)}\\, t^{\\mu}.\n$\nThus, for a CTRW with heavy-tailed waiting times, the anomalous exponent equals the waiting-time tail index:\n$$\n\\alpha = \\mu \\in (0,1),\n$$\nand the motion is subdiffusive with finite MSD for all $t$.\n\nNow consider an alternative mechanism: heavy-tailed jump lengths with\n$$\n\\lambda(\\ell)\\sim D\\, |\\ell|^{-(1+\\beta)}, \\quad 0\\beta2,\n$$\nand finite-mean or light-tailed waiting times. For a Lévy flight, the second moment of $\\lambda(\\ell)$ diverges when $\\beta2$, and the spatial propagator $p(x,t)$ exhibits stable-law tails with infinite variance. Consequently, the MSD either diverges or is undefined, which is incompatible with the experiment’s finite MSD. For a Lévy walk, the physical velocity coupling regularizes the motion so that the MSD can be finite; however, the asymptotic scaling for $1\\beta2$ is superdiffusive,\n$$\n\\langle x^{2}(t)\\rangle \\propto t^{\\alpha}, \\quad \\alpha = 3 - \\beta \\in (1,2),\n$$\nreflecting persistent ballistic segments. This is incompatible with the observed subdiffusive exponent $\\alpha=0.71$.\n\nComparing the measurements to these first-principles consequences:\n- The measured MSD exponent $\\alpha=0.7$ indicates subdiffusion with finite second moment.\n- The observed waiting-time tail index $\\mu=0.68\\pm 0.03$ lies near $0.7$ and, in a CTRW picture, directly predicts $\\alpha\\approx \\mu$, consistent with the MSD.\n- The observed jump-length tail index $\\beta=1.8\\pm 0.1$ implies either an infinite MSD (Lévy flight) or superdiffusion with $\\alpha=3-\\beta\\approx 1.2$ (Lévy walk), both inconsistent with the experimental MSD.\n\nTherefore, nonlocal-in-time dynamics arising from heavy-tailed waiting times (temporal memory) are the more plausible mechanism underlying the observed subdiffusion, while nonlocal-in-space mechanisms based on heavy-tailed jump lengths are inconsistent with the finite, subdiffusive MSD.\n\nFinally, per part (a) and the reporting instruction, the anomalous exponent is $\\alpha=0.7$. Rounding to three significant figures yields $0.700$.", "answer": "$$\\boxed{0.700}$$", "id": "2512419"}, {"introduction": "Bridging the gap from analytical theory to practical application requires robust numerical methods, and non-Fickian models present a unique computational challenge. The \"memory\" inherent in fractional derivatives, represented by convolution with a power-law kernel like $K(t) \\propto t^{-\\alpha}$, makes direct time-stepping computationally expensive due to the need to store the entire process history. This exercise [@problem_id:2512393] delves into a powerful and widely used solution: approximating the kernel with a sum-of-exponentials to transform the non-local convolution into a set of efficient, local recursive updates.", "problem": "A time-fractional non-Fickian diffusion model replaces the classical Fickian memoryless flux with a hereditary kernel. The Caputo time-fractional derivative of order $\\alpha\\in(0,1)$ uses the memory kernel $K(t)=\\dfrac{t^{-\\alpha}}{\\Gamma(1-\\alpha)}$, which appears in the convolution $\\int_{0}^{t}K(t-\\tau)\\,g(\\tau)\\,d\\tau$. Direct time-stepping with this power-law kernel $K(t)$ is memory-expensive because it requires storing and reusing the entire history at each step. A widely used acceleration strategy is to approximate $K(t)$ by a sum of exponentials so that the convolution can be updated recursively with constant cost per step.\n\nYour task is to derive and implement a fast sum-of-exponentials approximation to the power-law kernel that is uniformly accurate on a finite time window $[t_{\\min},t_{\\max}]$, and to estimate its approximation error on that window by direct sampling.\n\nStart from the following foundational facts only.\n\n- The Caputo memory kernel for order $\\alpha\\in(0,1)$ is $K(t)=\\dfrac{t^{-\\alpha}}{\\Gamma(1-\\alpha)}$ for $t>0$, where $\\Gamma(\\cdot)$ is the Gamma function.\n- The Laplace transform identity, valid for $\\alpha\\in(0,1)$, is\n$$\n\\int_{0}^{\\infty} s^{\\alpha-1}\\,e^{-s t}\\,ds \\;=\\; \\Gamma(\\alpha)\\,t^{-\\alpha},\\quad t>0.\n$$\n\nPart A (derivation).\n\n- Using the identity above, derive the integral representation\n$$\nK(t)\\;=\\;\\frac{1}{\\Gamma(1-\\alpha)\\,\\Gamma(\\alpha)}\\int_{0}^{\\infty} s^{\\alpha-1}e^{-s t}\\,ds,\\quad t>0.\n$$\n- Perform the change of variables $s=e^{x}$ to show\n$$\nK(t)\\;=\\;c_{\\alpha}\\int_{-\\infty}^{\\infty} e^{\\alpha x}\\,e^{-t e^{x}}\\,dx,\\quad\\text{where}\\quad c_{\\alpha}=\\frac{1}{\\Gamma(1-\\alpha)\\,\\Gamma(\\alpha)}.\n$$\n- Approximate the integral over $x\\in\\mathbb{R}$ by the trapezoidal rule on a uniform grid $x_{k}=x_{\\min}+k h$, for $k=0,1,\\dots,N-1$, with spacing $h>0$, truncated to the finite interval $[x_{\\min},x_{\\max}]$. Show that this yields a sum-of-exponentials approximation on $[t_{\\min},t_{\\max}]$ of the form\n$$\nK(t)\\;\\approx\\;\\sum_{k=0}^{N-1} w_{k}\\,e^{-\\lambda_{k}\\,t},\\quad\n\\lambda_{k}=e^{x_{k}},\\quad\nw_{k}=c_{\\alpha}\\,h\\,e^{\\alpha x_{k}}.\n$$\n- Propose a deterministic rule for choosing $x_{\\min}$ and $x_{\\max}$ in terms of $\\alpha$, $t_{\\min}$, $t_{\\max}$ and a dimensionless safety margin $M>0$, motivated by the peak of the integrand at $s\\sim \\alpha/t$. One acceptable choice is\n$$\ns_{\\min}=\\frac{\\alpha}{t_{\\max}}\\,e^{-M},\\quad\ns_{\\max}=\\frac{\\alpha}{t_{\\min}}\\,e^{+M},\\quad\nx_{\\min}=\\log s_{\\min},\\quad\nx_{\\max}=\\log s_{\\max},\\quad\nN=1+\\left\\lceil\\frac{x_{\\max}-x_{\\min}}{h}\\right\\rceil.\n$$\nExplain why this choice captures the dominant contributions to the integral uniformly for all $t\\in[t_{\\min},t_{\\max}]$.\n\nPart B (algorithm and error estimation).\n\n- Implement a function that, given $\\alpha\\in(0,1)$, $t_{\\min}>0$, $t_{\\max}>t_{\\min}$, grid spacing $h>0$, and margin $M>0$, returns the sum-of-exponentials parameters $\\{(\\lambda_{k},w_{k})\\}_{k=0}^{N-1}$ constructed as above.\n- Implement a function that evaluates the maximal relative error of the approximation on a logarithmically spaced grid $\\{t_{j}\\}$ of $J$ points in $[t_{\\min},t_{\\max}]$:\n$$\n\\varepsilon_{\\max}\\;=\\;\\max_{1\\le j\\le J}\\frac{\\left|\\sum_{k=0}^{N-1}w_{k}e^{-\\lambda_{k} t_{j}}-K(t_{j})\\right|}{K(t_{j})}.\n$$\nThe quantity $\\varepsilon_{\\max}$ is dimensionless and no units are required.\n- For each test case below, your program must report the pair $[N,\\varepsilon_{\\max}]$, where $N$ is the number of exponentials and $\\varepsilon_{\\max}$ is the maximal relative error computed on $J$ logarithmically spaced points.\n\nTest suite.\n\n- Use $J=1000$ evaluation points for all cases.\n- Case $1$: $\\alpha=0.5$, $t_{\\min}=10^{-3}$, $t_{\\max}=10^{0}$, $h=0.5$, $M=6$.\n- Case $2$: $\\alpha=0.1$, $t_{\\min}=10^{-4}$, $t_{\\max}=10^{1}$, $h=0.4$, $M=8$.\n- Case $3$: $\\alpha=0.9$, $t_{\\min}=10^{-3}$, $t_{\\max}=10^{0}$, $h=0.4$, $M=8$.\n\nFinal output format.\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each entry must itself be a two-element list $[N,\\varepsilon_{\\max}]$ as specified above, in the same order as the test suite. For example, the printed line should look like $[[N_{1},\\varepsilon_{\\max,1}],[N_{2},\\varepsilon_{\\max,2}],[N_{3},\\varepsilon_{\\max,3}]]$.", "solution": "The problem statement has been rigorously validated and found to be scientifically sound, well-posed, and objective. It presents a standard and important problem in the numerical analysis of fractional differential equations. The premises are factually correct, the definitions are unambiguous, and the described task is formalizable into a solvable problem. It is neither trivial nor ill-posed. Therefore, I will proceed with the complete derivation and algorithmic specification as requested.\n\nThe derivation of the sum-of-exponentials approximation for the Caputo kernel $K(t)$ proceeds in four steps as outlined.\n\nFirst, we establish the integral representation of the kernel. The problem provides the definition of the kernel for a time-fractional derivative of order $\\alpha \\in (0,1)$ as\n$$\nK(t) = \\frac{t^{-\\alpha}}{\\Gamma(1-\\alpha)}, \\quad t0,\n$$\nwhere $\\Gamma(\\cdot)$ is the Euler Gamma function. We are also given the Laplace transform identity\n$$\n\\Gamma(\\alpha) t^{-\\alpha} = \\int_{0}^{\\infty} s^{\\alpha-1} e^{-st} ds, \\quad t0.\n$$\nFrom this identity, we can express $t^{-\\alpha}$ as $t^{-\\alpha} = \\frac{1}{\\Gamma(\\alpha)} \\int_{0}^{\\infty} s^{\\alpha-1} e^{-st} ds$. Substituting this into the definition of $K(t)$ directly yields the required integral representation:\n$$\nK(t) = \\frac{1}{\\Gamma(1-\\alpha)} \\left( \\frac{1}{\\Gamma(\\alpha)} \\int_{0}^{\\infty} s^{\\alpha-1} e^{-st} ds \\right) = \\frac{1}{\\Gamma(1-\\alpha)\\Gamma(\\alpha)} \\int_{0}^{\\infty} s^{\\alpha-1} e^{-st} ds.\n$$\n\nSecond, we perform a change of variables to transform the integral into a form more amenable to numerical quadrature. Let the integration variable be changed from $s$ to $x$ via the substitution $s = e^x$. This implies $ds = e^x dx$. As $s$ ranges from $0$ to $\\infty$, the new variable $x$ ranges from $-\\infty$ to $\\infty$. The term $s^{\\alpha-1}$ becomes $(e^x)^{\\alpha-1} = e^{(\\alpha-1)x}$. The integral transforms as follows:\n$$\n\\int_{0}^{\\infty} s^{\\alpha-1} e^{-st} ds = \\int_{-\\infty}^{\\infty} e^{(\\alpha-1)x} e^{-t e^x} (e^x dx) = \\int_{-\\infty}^{\\infty} e^{\\alpha x - x} e^{-t e^x} e^x dx = \\int_{-\\infty}^{\\infty} e^{\\alpha x} e^{-t e^x} dx.\n$$\nThus, the kernel $K(t)$ is expressed as an integral over the entire real line:\n$$\nK(t) = c_{\\alpha} \\int_{-\\infty}^{\\infty} e^{\\alpha x} e^{-t e^x} dx,\n$$\nwhere the constant $c_{\\alpha}$ is defined as $c_{\\alpha} = \\frac{1}{\\Gamma(1-\\alpha)\\Gamma(\\alpha)}$.\n\nThird, we approximate this infinite integral using a numerical quadrature rule. The problem specifies the trapezoidal rule on a uniform grid, which is a highly effective method for integrals over $\\mathbb{R}$ when the integrand decays to zero sufficiently fast at $\\pm\\infty$. The integral is truncated to a finite interval $[x_{\\min}, x_{\\max}]$ and discretized with a uniform step size $h$. Let the grid points be $x_k = x_{\\min} + kh$ for $k=0, 1, \\dots, N-1$, where $N$ is the number of points. The trapezoidal rule (which, for an exponentially decaying integrand on $\\mathbb{R}$, simplifies to a rectangular rule with weights equal to the step size $h$) approximates the integral as:\n$$\n\\int_{x_{\\min}}^{x_{\\max}} f(x) dx \\approx h \\sum_{k=0}^{N-1} f(x_k).\n$$\nApplying this to our integrand $f(x, t) = e^{\\alpha x} e^{-t e^x}$, we obtain the approximation for $K(t)$:\n$$\nK(t) \\approx c_{\\alpha} h \\sum_{k=0}^{N-1} e^{\\alpha x_k} e^{-t e^{x_k}}.\n$$\nThis expression is precisely a sum of exponentials in the variable $t$. By defining the quadrature nodes $\\lambda_k = e^{x_k}$ and the corresponding weights $w_k = c_{\\alpha} h e^{\\alpha x_k}$, we arrive at the desired form:\n$$\nK(t) \\approx \\sum_{k=0}^{N-1} w_k e^{-\\lambda_k t}.\n$$\n\nFourth, we must justify the choice of the truncated integration domain $[x_{\\min}, x_{\\max}]$. The approximation must be uniformly accurate for all $t$ in a given window $[t_{\\min}, t_{\\max}]$. The integrand, $f(x, t) = e^{\\alpha x} e^{-t e^x}$, has a single peak with respect to $x$ for any fixed $t0$. To find the location of this peak, we set its partial derivative with respect to $x$ to zero:\n$$\n\\frac{\\partial f}{\\partial x} = \\alpha e^{\\alpha x} e^{-t e^x} - t e^x e^{\\alpha x} e^{-t e^x} = f(x,t) (\\alpha - t e^x) = 0.\n$$\nThis gives the peak location $e^x = \\alpha/t$, or $x_{\\text{peak}}(t) = \\log(\\alpha/t)$. As $t$ varies from $t_{\\min}$ to $t_{\\max}$, the peak of the integrand moves over the interval $[\\log(\\alpha/t_{\\max}), \\log(\\alpha/t_{\\min})]$. For the quadrature to be accurate, the integration domain $[x_{\\min}, x_{\\max}]$ must contain this entire range of peak locations. The integrand decays rapidly away from its peak. The proposed rule,\n$$\nx_{\\min} = \\log(\\alpha/t_{\\max}) - M, \\quad x_{\\max} = \\log(\\alpha/t_{\\min}) + M,\n$$\nconstructs an interval that contains the range of peak locations and extends it symmetrically by a dimensionless safety margin $M$. This ensures that for any $t \\in [t_{\\min}, t_{\\max}]$, the peak of the integrand is well within the quadrature domain, and the contributions from the tails outside $[x_{\\min}, x_{\\max}]$ are negligible, provided $M$ is sufficiently large. The number of quadrature points $N$ is chosen to cover this domain with the specified spacing $h$: $N = 1 + \\lceil(x_{\\max}-x_{\\min})/h\\rceil$.\n\nFor the implementation, we define an algorithm based on this derivation. First, a function computes the sum-of-exponentials parameters. Given $\\alpha, t_{\\min}, t_{\\max}, h, M$, it calculates $c_{\\alpha}, x_{\\min}, x_{\\max}$, and $N$. It then generates the grid $x_k$ and computes the sets $\\{\\lambda_k\\}$ and $\\{w_k\\}$ according to the derived formulae. Second, an error estimation function takes these parameters and evaluates the quality of the approximation. It constructs a fine, logarithmically spaced grid of $J$ points $\\{t_j\\}$ over $[t_{\\min}, t_{\\max}]$. At each point $t_j$, it computes the exact kernel value $K(t_j)$ using the Gamma function and the approximate value by summing the exponential series. The maximal relative error $\\varepsilon_{\\max}$ over this grid is then determined. This procedure provides a reliable estimate of the approximation's accuracy across the target time window. The necessary special functions, $\\Gamma(\\cdot)$, are available in the `scipy.special` library. All array operations are vectorized using `numpy` for efficiency.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Derives and implements a sum-of-exponentials approximation for the\n    Caputo fractional derivative kernel and evaluates its accuracy.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, t_min, t_max, h, M)\n        (0.5, 1e-3, 1.0, 0.5, 6),\n        (0.1, 1e-4, 10.0, 0.4, 8),\n        (0.9, 1e-3, 1.0, 0.4, 8),\n    ]\n\n    # Number of evaluation points for error estimation.\n    J = 1000\n\n    results = []\n    for case in test_cases:\n        alpha, t_min, t_max, h, M = case\n\n        # Part A: Derive sum-of-exponentials parameters {lambda_k, w_k}\n        \n        # Calculate the integration bounds in the s-domain and x-domain\n        s_min = (alpha / t_max) * np.exp(-M)\n        s_max = (alpha / t_min) * np.exp(M)\n        x_min = np.log(s_min)\n        x_max = np.log(s_max)\n        \n        # Determine the number of quadrature points, N, to cover the interval [x_min, x_max]\n        # The number of points is the number of intervals plus one.\n        num_intervals = int(np.ceil((x_max - x_min) / h))\n        N = num_intervals + 1\n        \n        # Construct the uniform grid for the trapezoidal rule\n        k = np.arange(N)\n        x_k = x_min + k * h\n        \n        # Calculate the constant c_alpha\n        c_alpha = 1.0 / (gamma(alpha) * gamma(1.0 - alpha))\n        \n        # Calculate the exponents (lambda_k) and weights (w_k)\n        lambdas = np.exp(x_k)\n        weights = c_alpha * h * np.exp(alpha * x_k)\n        \n        # Part B: Estimate the maximal relative error\n\n        # Create a logarithmically spaced grid of J points for t\n        t_grid = np.logspace(np.log10(t_min), np.log10(t_max), J)\n        \n        # Calculate the exact kernel values, K(t)\n        K_exact = (t_grid**(-alpha)) / gamma(1.0 - alpha)\n        \n        # Calculate the approximate kernel values using the sum-of-exponentials\n        # This is vectorized for efficiency: weights are (N,1), exp term is (N,J)\n        K_approx = np.sum(weights[:, np.newaxis] * np.exp(-lambdas[:, np.newaxis] * t_grid[np.newaxis, :]), axis=0)\n        \n        # Compute the relative error at each point in t_grid\n        relative_errors = np.abs(K_approx - K_exact) / K_exact\n        \n        # Find the maximum relative error over the interval\n        max_relative_error = np.max(relative_errors)\n        \n        results.append([N, max_relative_error])\n\n    # Final print statement in the exact required format.\n    # The format [[N1,eps1],[N2,eps2],...] without extra spaces is achieved\n    # by constructing the string representation for each pair manually.\n    formatted_results = [f\"[{N},{eps}]\" for N, eps in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2512393"}]}