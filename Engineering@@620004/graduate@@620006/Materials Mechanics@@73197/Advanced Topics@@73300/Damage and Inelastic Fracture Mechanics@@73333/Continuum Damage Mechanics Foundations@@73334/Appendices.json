{"hands_on_practices": [{"introduction": "The first step in modeling material degradation is to define a criterion for when damage begins. Different materials respond differently to complex loading; for instance, brittle materials are often sensitive to maximum tensile stresses, while ductile materials are governed by shear. This practice [@problem_id:2873780] provides a foundational exercise in calculating and comparing two of the most common scalar measures used for damage initiation: a Rankine-type equivalent strain, sensitive to tension, and a von Mises-type equivalent strain, which captures deviatoric (shape-changing) effects.", "problem": "An isotropic, homogeneous thin slab is modeled under small-strain kinematics within the framework of Continuum Damage Mechanics (CDM). Consider a proportional biaxial tension state in plane strain, so that the principal strains are $ \\varepsilon_{1} = 0.020 $, $ \\varepsilon_{2} = 0.010 $, and $ \\varepsilon_{3} = 0 $. Two common scalar strain measures used to trigger damage initiation are considered:\n\n- A Rankine-type measure that initiates when the maximum tensile principal strain becomes critical.\n- A von Mises (second deviatoric invariant, often called $J_{2}$) measure that initiates when a scalar equivalent strain constructed from the deviatoric part of the small-strain tensor becomes critical.\n\nStarting from first principles of small-strain kinematics and isotropy, compute the scalar equivalent strain for each measure at the given state and then compute the difference between the two, defined as $ \\Delta = \\varepsilon_{\\mathrm{VM}} - \\varepsilon_{\\mathrm{R}} $, where $ \\varepsilon_{\\mathrm{VM}} $ is the von Mises-type equivalent strain and $ \\varepsilon_{\\mathrm{R}} $ is the Rankine-type equivalent strain. Express the final answer as a dimensionless decimal number, and round your answer to four significant figures.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is based on fundamental principles of continuum mechanics and can be solved directly from the provided information. Therefore, a solution will be provided.\n\nThe state of strain is given by the principal components of the small-strain tensor $\\boldsymbol{\\varepsilon}$. In the principal coordinate system, the strain tensor is represented by the diagonal matrix:\n$$ \\boldsymbol{\\varepsilon} = \\begin{pmatrix} \\varepsilon_{1} & 0 & 0 \\\\ 0 & \\varepsilon_{2} & 0 \\\\ 0 & 0 & \\varepsilon_{3} \\end{pmatrix} $$\nThe given values are $\\varepsilon_{1} = 0.020$, $\\varepsilon_{2} = 0.010$, and $\\varepsilon_{3} = 0$.\n\nFirst, we determine the Rankine-type equivalent strain, $\\varepsilon_{\\mathrm{R}}$. This measure is defined as the maximum tensile principal strain. For the given strain state, the principal strains are all positive or zero, so they are all tensile or neutral. The maximum value is:\n$$ \\varepsilon_{\\mathrm{R}} = \\max(\\varepsilon_{1}, \\varepsilon_{2}, \\varepsilon_{3}) = \\max(0.020, 0.010, 0) $$\n$$ \\varepsilon_{\\mathrm{R}} = 0.020 $$\n\nNext, we determine the von Mises-type equivalent strain, $\\varepsilon_{\\mathrm{VM}}$. This measure is constructed from the deviatoric part of the strain tensor. The strain tensor $\\boldsymbol{\\varepsilon}$ can be decomposed into its volumetric (or hydrostatic) and deviatoric parts. The volumetric strain, $\\varepsilon_{\\mathrm{v}}$, is the trace of the strain tensor:\n$$ \\varepsilon_{\\mathrm{v}} = \\mathrm{tr}(\\boldsymbol{\\varepsilon}) = \\varepsilon_{1} + \\varepsilon_{2} + \\varepsilon_{3} $$\nSubstituting the given values:\n$$ \\varepsilon_{\\mathrm{v}} = 0.020 + 0.010 + 0 = 0.030 $$\nThe mean strain, $\\varepsilon_{\\mathrm{m}}$, is one-third of the volumetric strain:\n$$ \\varepsilon_{\\mathrm{m}} = \\frac{1}{3} \\varepsilon_{\\mathrm{v}} = \\frac{1}{3} (0.030) = 0.010 $$\nThe deviatoric strain tensor, $\\mathbf{e}$, is defined as $\\mathbf{e} = \\boldsymbol{\\varepsilon} - \\varepsilon_{\\mathrm{m}} \\mathbf{I}$, where $\\mathbf{I}$ is the second-order identity tensor. The principal components of the deviatoric strain tensor, $e_i$, are:\n$$ e_{1} = \\varepsilon_{1} - \\varepsilon_{\\mathrm{m}} = 0.020 - 0.010 = 0.010 $$\n$$ e_{2} = \\varepsilon_{2} - \\varepsilon_{\\mathrm{m}} = 0.010 - 0.010 = 0 $$\n$$ e_{3} = \\varepsilon_{3} - \\varepsilon_{\\mathrm{m}} = 0 - 0.010 = -0.010 $$\n\nThe von Mises-type equivalent strain is defined based on the second invariant of the deviatoric strain tensor, $J_{2}$. The invariant $J_{2}$ is defined as:\n$$ J_{2} = \\frac{1}{2} e_{ij} e_{ji} = \\frac{1}{2} (e_{1}^{2} + e_{2}^{2} + e_{3}^{2}) $$\nSubstituting the principal deviatoric strains:\n$$ J_{2} = \\frac{1}{2} \\left[ (0.010)^{2} + (0)^{2} + (-0.010)^{2} \\right] = \\frac{1}{2} (0.0001 + 0 + 0.0001) = 0.0001 $$\nThe standard definition for the von Mises equivalent strain, which is work-conjugate to the von Mises stress under incompressible plastic flow, is:\n$$ \\varepsilon_{\\mathrm{VM}} = \\sqrt{\\frac{4}{3} J_{2}} $$\nAlternatively, this can be expressed directly in terms of principal strains:\n$$ \\varepsilon_{\\mathrm{VM}} = \\frac{\\sqrt{2}}{3} \\sqrt{(\\varepsilon_{1} - \\varepsilon_{2})^{2} + (\\varepsilon_{2} - \\varepsilon_{3})^{2} + (\\varepsilon_{3} - \\varepsilon_{1})^{2}} $$\nUsing the calculated value of $J_{2}$:\n$$ \\varepsilon_{\\mathrm{VM}} = \\sqrt{\\frac{4}{3} (0.0001)} = \\sqrt{\\frac{0.0004}{3}} = \\frac{\\sqrt{0.0004}}{\\sqrt{3}} = \\frac{0.02}{\\sqrt{3}} $$\nNumerically, this is approximately $\\varepsilon_{\\mathrm{VM}} \\approx 0.011547$.\n\nFinally, we compute the difference $\\Delta = \\varepsilon_{\\mathrm{VM}} - \\varepsilon_{\\mathrm{R}}$:\n$$ \\Delta = \\frac{0.02}{\\sqrt{3}} - 0.020 = 0.020 \\left( \\frac{1}{\\sqrt{3}} - 1 \\right) $$\nCalculating the numerical value:\n$$ \\Delta \\approx 0.011547 - 0.020 = -0.008453 $$\nThe problem requires the answer to be rounded to four significant figures. The calculated value is $\\Delta \\approx -0.00845299...$. The first significant figure is $8$. Rounding to four significant figures gives $-0.008453$.", "answer": "$$\n\\boxed{-0.008453}\n$$", "id": "2873780"}, {"introduction": "Once damage initiates, its evolution must be tracked over time or with increasing load. This is typically described by a rate equation, an ordinary differential equation governing the damage variable $D$. This exercise [@problem_id:2873731] challenges you to discretize such an evolution law using the robust backward Euler method, a cornerstone of computational mechanics for its stability. By deriving and implementing this local update algorithm, you will gain hands-on experience with the core 'return mapping' logic used in finite element codes to update material state variables, all while enforcing physical constraints like irreversibility.", "problem": "Consider a standard scalar isotropic damage variable $D \\in [0,1]$ in continuum damage mechanics subject to an evolution law governed by a nonnegative driving function. Let the evolution be prescribed by the rate equation\n$$\\dot{D} = \\lambda \\langle \\tilde{\\varepsilon} - \\kappa \\rangle_+,$$\nwhere $\\lambda \\gt 0$ is a material parameter, $\\kappa \\ge 0$ is a constant threshold, $\\tilde{\\varepsilon}$ is a known equivalent strain-like driving quantity at the current time (treated as given data at the step level), and $\\langle x \\rangle_+ = \\max(x,0)$ denotes the Macaulay bracket. Assume the thermodynamic irreversibility $D_{n+1} \\ge D_n$ and the bound $D_{n+1} \\le 1$. All quantities are dimensionless.\n\nStarting only from the definition of the damage rate equation, the Macaulay bracket, and standard implicit time discretization, do the following:\n\n1) Derive the backward Euler (Backward Euler (BE)) fully implicit time discretization over a time step of size $\\Delta t \\gt 0$ from time $t_n$ to $t_{n+1} = t_n + \\Delta t$, yielding a scalar nonlinear local residual $R(D_{n+1})$ that must vanish at the solution.\n\n2) Using the definition of the Macaulay bracket and the irreversibility and bound constraints, determine the active-set structure of $R(D_{n+1})$ and derive a robust local update algorithm for $D_{n+1}$ in terms of $D_n$, $\\Delta t$, $\\lambda$, $\\kappa$, and the given $\\tilde{\\varepsilon}_{n+1}$. Your update must enforce $D_{n+1} \\in [D_n,1]$.\n\n3) Provide the scalar derivative of the residual with respect to $D_{n+1}$ in the sense of a consistent algorithmic tangent where applicable, and clearly state the cases where the derivative is not defined or not required due to active constraints.\n\nImplement the resulting local update in a program that, for each test case, returns the updated damage $D_{n+1}$. Treat all variables as dimensionless scalars. Do not use any external input; the program must compute and print the answers for the following test suite of six cases, each given as $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1})$:\n\n- Case A (happy path, active evolution): $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1}) = (\\,0.2,\\,0.1,\\,5.0,\\,0.01,\\,0.05\\,)$.\n- Case B (inactive, below threshold): $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1}) = (\\,0.6,\\,0.5,\\,10.0,\\,0.2,\\,0.1\\,)$.\n- Case C (boundary of activation, exactly at threshold): $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1}) = (\\,0.3,\\,1.0,\\,3.0,\\,0.15,\\,0.15\\,)$.\n- Case D (saturation to the upper bound): $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1}) = (\\,0.95,\\,1.0,\\,2.0,\\,0.1,\\,0.8\\,)$.\n- Case E (stiff time scale and small driving, checks numerical scaling): $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1}) = (\\,0.0,\\,1.0\\times 10^{-6},\\,1.0\\times 10^{6},\\,0.0,\\,1.0\\times 10^{-3}\\,)$.\n- Case F (irreversibility under unloading): $(D_n,\\Delta t,\\lambda,\\kappa,\\tilde{\\varepsilon}_{n+1}) = (\\,0.7,\\,1.0,\\,1.0,\\,1.0,\\,0.9\\,)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $\"[r_1,r_2,\\dots]\"$), where each entry is the computed $D_{n+1}$ for the corresponding test case in the order A, B, C, D, E, F. Each entry must be a decimal number. No physical units are required because all quantities are dimensionless. The program must be entirely self-contained and runnable as-is in the specified environment.", "solution": "The problem presented is a standard, well-posed exercise in computational inelasticity, specifically concerning the numerical integration of a simple rate-dependent isotropic damage model. The task is to derive and implement a robust local update algorithm, which in this context is a return mapping algorithm. The derivation proceeds from first principles of time discretization and constrained optimization.\n\nThe problem is validated as scientifically grounded, well-posed, and objective. It contains no inconsistencies or ambiguities. All necessary data are provided. We proceed with the solution.\n\nThe primary steps are: 1) time discretization of the evolution equation, 2) derivation of a closed-form update by analyzing the Kuhn-Tucker conditions for the constrained problem, and 3) derivation of the consistent algorithmic tangent for use in a Newton-Raphson-based implicit finite element code.\n\n**1. Backward Euler Discretization and Local Residual**\n\nThe evolution of the damage variable $D$ is governed by the first-order ordinary differential equation:\n$$\n\\dot{D} = \\lambda \\langle \\tilde{\\varepsilon} - \\kappa \\rangle_+\n$$\nwhere $\\dot{D} = \\frac{dD}{dt}$, $\\lambda > 0$ is a fluidity parameter, $\\kappa \\ge 0$ is a static threshold for damage activation, $\\tilde{\\varepsilon}$ is the equivalent strain driving the damage process, and $\\langle x \\rangle_+ = \\max(x, 0)$ is the Macaulay bracket, which enforces the non-negativity of the damage rate.\n\nWe perform a time discretization over the interval $[t_n, t_{n+1}]$, where $\\Delta t = t_{n+1} - t_n$ is the time step size. Using a fully implicit, first-order backward Euler (BE) scheme, the time derivative $\\dot{D}$ at time $t_{n+1}$ is approximated as:\n$$\n\\dot{D}(t_{n+1}) \\approx \\frac{D(t_{n+1}) - D(t_n)}{\\Delta t} = \\frac{D_{n+1} - D_n}{\\Delta t}\n$$\nIn a fully implicit scheme, the right-hand side of the evolution law is also evaluated at time $t_{n+1}$:\n$$\n\\lambda \\langle \\tilde{\\varepsilon}(t_{n+1}) - \\kappa \\rangle_+ = \\lambda \\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+\n$$\nEquating the two expressions gives the discrete evolution equation:\n$$\n\\frac{D_{n+1} - D_n}{\\Delta t} = \\lambda \\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+\n$$\nIt is crucial to note that the problem specifies $\\tilde{\\varepsilon}_{n+1}$ as a given quantity at the step level, independent of the unknown $D_{n+1}$. This simplifies the problem significantly, as it decouples the damage update from other field variables.\n\nThe local residual, $R(D_{n+1})$, is the function that must equal zero at the solution. It is standard to define it from the discrete evolution equation:\n$$\nR(D_{n+1}) = D_{n+1} - D_n - \\Delta t \\lambda \\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+\n$$\nFinding $D_{n+1}$ requires solving the system comprised of the equation $R(D_{n+1}) = 0$ subject to the irreversibility constraint $D_{n+1} \\ge D_n$ and the saturation constraint $D_{n+1} \\le 1$.\n\n**2. Active-Set Structure and Robust Update Algorithm**\n\nThe problem of finding $D_{n+1}$ is a constrained optimization problem. The solution is governed by the Karush-Kuhn-Tucker (KKT) conditions. Let us define a trial value, $D_{n+1}^{\\text{trial}}$, as the solution to the unconstrained equation $R(D_{n+1}) = 0$:\n$$\nD_{n+1}^{\\text{trial}} = D_n + \\Delta t \\lambda \\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+\n$$\nThe final solution $D_{n+1}$ is a projection of this trial state onto the admissible interval $[D_n, 1]$. An active-set analysis reveals the structure of the solution.\n\nThere are two primary conditions to check: damage activation and damage saturation.\n\nCase 1: Inactive state (elastic behavior with respect to damage).\nThis occurs when the driving force does not exceed the threshold: $\\tilde{\\varepsilon}_{n+1} \\le \\kappa$.\nIn this case, the Macaulay bracket evaluates to zero: $\\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+ = 0$.\nThe trial value becomes:\n$$\nD_{n+1}^{\\text{trial}} = D_n + 0 = D_n\n$$\nThis value satisfies both constraints trivially: $D_n \\ge D_n$ and $D_n \\le 1$ (since $D_n$ is a valid state from the previous step). The update is therefore:\n$$\nD_{n+1} = D_n \\quad \\text{if} \\quad \\tilde{\\varepsilon}_{n+1} \\le \\kappa\n$$\n\nCase 2: Active state (damage evolution).\nThis occurs when the driving force exceeds the threshold: $\\tilde{\\varepsilon}_{n+1} > \\kappa$.\nThe Macaulay bracket is active: $\\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+ = \\tilde{\\varepsilon}_{n+1} - \\kappa > 0$.\nThe trial value is:\n$$\nD_{n+1}^{\\text{trial}} = D_n + \\Delta t \\lambda (\\tilde{\\varepsilon}_{n+1} - \\kappa)\n$$\nSince $\\Delta t > 0$, $\\lambda > 0$, and $(\\tilde{\\varepsilon}_{n+1} - \\kappa) > 0$, it is guaranteed that $D_{n+1}^{\\text{trial}} > D_n$. The irreversibility constraint $D_{n+1} \\ge D_n$ is automatically satisfied. We only need to enforce the saturation constraint $D_{n+1} \\le 1$.\n\nThis leads to two sub-cases:\n\nSub-case 2a: Active, non-saturated.\nIf $D_{n+1}^{\\text{trial}} \\le 1$, the trial value is admissible. The update is:\n$$\nD_{n+1} = D_{n+1}^{\\text{trial}}\n$$\n\nSub-case 2b: Active, saturated.\nIf $D_{n+1}^{\\text{trial}} > 1$, the trial value violates the saturation limit. The damage is constrained to its maximum possible value. The update is:\n$$\nD_{n+1} = 1\n$$\n\nCombining all cases yields a single, robust, closed-form update algorithm. The value of $D_{n+1}$ is the projection of the trial state onto the admissible interval $[D_n, 1]$. Since $D_{n+1}^{\\text{trial}} \\ge D_n$ is always true, this projection simplifies to taking the minimum with the upper bound $1$:\n$$\nD_{n+1} = \\min\\left(1, D_{n+1}^{\\text{trial}}\\right)\n$$\nSubstituting the expression for $D_{n+1}^{\\text{trial}}$ gives the complete update rule:\n$$\nD_{n+1} = \\min\\left(1, D_n + \\Delta t \\lambda \\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+\\right)\n$$\n\n**3. Algorithmic Tangent**\n\nThe algorithmic tangent is the derivative of the residual equation with respect to the unknown variable, in this case $\\frac{\\partial R}{\\partial D_{n+1}}$. This quantity is fundamental for a Newton-Raphson solver used in implicit finite element methods to solve a global system of equations where material state variables like $D_{n+1}$ are coupled to other fields (e.g., displacements).\n\nThe residual is $R(D_{n+1}) = D_{n+1} - D_n - \\Delta t \\lambda \\langle \\tilde{\\varepsilon}_{n+1} - \\kappa \\rangle_+$.\nPer the problem statement, $\\tilde{\\varepsilon}_{n+1}$ is given data and is not a function of $D_{n+1}$. Consequently, the entire term following $D_{n+1}$ in the residual expression is constant with respect to $D_{n+1}$.\n\nThe applicability of the tangent derivative depends on the active set.\n\nCase 1: Active, non-saturated state ($\\tilde{\\varepsilon}_{n+1} > \\kappa$ and $D_{n+1}^{\\text{trial}} < 1$).\nIn this case, the solution $D_{n+1}$ is found by solving the unconstrained residual equation. The Macaulay bracket is resolved as $(\\tilde{\\varepsilon}_{n+1} - \\kappa)$. The residual being solved is effectively:\n$$\nR(D_{n+1}) = D_{n+1} - D_n - \\Delta t \\lambda (\\tilde{\\varepsilon}_{n+1} - \\kappa) = 0\n$$\nThe consistent algorithmic tangent is the derivative of this expression with respect to $D_{n+1}$:\n$$\nK_T = \\frac{\\partial R}{\\partial D_{n+1}} = 1\n$$\nThis is the only case where the tangent is required and has a non-trivial meaning in a Newton-Raphson scheme. A value of $1$ signifies that the equation for $D_{n+1}$ is linear and uncoupled in this specific formulation.\n\nCase 2: Inactive or saturated states.\nIf $\\tilde{\\varepsilon}_{n+1} \\le \\kappa$, the solution is fixed by the constraint $D_{n+1} = D_n$.\nIf $\\tilde{\\varepsilon}_{n+1} > \\kappa$ but the trial state leads to saturation, the solution is fixed by the constraint $D_{n+1} = 1$.\nIn both scenarios, $D_{n+1}$ is not a free variable to be solved for via root-finding on the residual $R(D_{n+1})$. Instead, it is determined by an inequality constraint that has become active. In a numerical solver, this degree of freedom would be removed from the system of equations. Therefore, the algorithmic tangent is not defined or, more accurately, not required for these cases, as the variable is prescribed.\n\nIn summary, the derivative of the residual is $1$ but is only meaningful in the active, non-saturated regime.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the updated damage variable D_{n+1} for a set of test cases\n    based on a rate-dependent isotropic damage model.\n    \"\"\"\n\n    # Test cases are given as tuples: (D_n, delta_t, lambda, kappa, eps_tilde_np1)\n    test_cases = [\n        # Case A (happy path, active evolution)\n        (0.2, 0.1, 5.0, 0.01, 0.05),\n        # Case B (inactive, below threshold)\n        (0.6, 0.5, 10.0, 0.2, 0.1),\n        # Case C (boundary of activation, exactly at threshold)\n        (0.3, 1.0, 3.0, 0.15, 0.15),\n        # Case D (saturation to the upper bound)\n        (0.95, 1.0, 2.0, 0.1, 0.8),\n        # Case E (stiff time scale and small driving)\n        (0.0, 1.0e-6, 1.0e6, 0.0, 1.0e-3),\n        # Case F (irreversibility under unloading)\n        (0.7, 1.0, 1.0, 1.0, 0.9),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        D_n, delta_t, lam, kappa, eps_tilde_np1 = case\n\n        # The core of the update algorithm is derived from the backward Euler\n        # discretization and application of irreversibility and saturation constraints.\n        # The evolution law is: dot(D) = lambda * <eps_tilde - kappa>_+\n        # Discretized form: (D_{n+1} - D_n) / delta_t = lambda * <eps_tilde_{n+1} - kappa>_+\n        # This gives a trial value for D_{n+1}:\n        # D_trial_{n+1} = D_n + delta_t * lambda * <eps_tilde_{n+1} - kappa>_+\n        \n        # The Macaulay bracket <x>_+ is implemented as max(0, x).\n        driving_force = eps_tilde_np1 - kappa\n        macaulay_term = max(0.0, driving_force)\n        \n        # Calculate the trial damage value for the next step.\n        D_np1_trial = D_n + delta_t * lam * macaulay_term\n        \n        # The final damage value D_{n+1} must be in the interval [D_n, 1].\n        # The formulation of D_np1_trial ensures D_np1_trial >= D_n automatically.\n        # We only need to enforce the saturation constraint D_{n+1} <= 1.\n        D_np1 = min(1.0, D_np1_trial)\n        \n        results.append(D_np1)\n\n    # Format the results as a comma-separated list in brackets, as specified.\n    # Using a general format specifier to handle floating point numbers cleanly.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2873731"}, {"introduction": "A theoretical model is only as good as its ability to predict real-world behavior, which requires that its parameters be calibrated against experimental data. This final practice [@problem_id:2873718] provides hands-on experience in this critical step of parameter identification. You will implement a least-squares optimization routine to determine the key parameters of an exponential softening law, ensuring the model's stress-strain response accurately matches a set of hypothetical experimental measurements. This exercise brings together the theoretical framework of damage mechanics with the practical, data-driven reality of material characterization.", "problem": "Consider a small-strain, scalar isotropic Continuum Damage Mechanics (CDM) model for a uniaxial tensile test. Under the strain equivalence hypothesis, the nominal Cauchy stress $\\,\\sigma\\,$ relates to the strain $\\,\\varepsilon\\,$ through the damage variable $\\,D \\in [0,1]\\,$ as\n$$\n\\sigma = \\left(1 - D\\right) E \\varepsilon,\n$$\nwhere $\\,E\\,$ is the Young’s modulus. In the post-peak tensile softening regime of a quasi-brittle material, assume that the nominal stress is prescribed to follow an exponential decay law parameterized by two positive strains $\\,\\varepsilon_0\\,$ and $\\,\\varepsilon_f\\,$ with $\\,\\varepsilon_f > \\varepsilon_0\\,$, namely\n$$\n\\sigma_{\\mathrm{model}}(\\varepsilon; \\varepsilon_0,\\varepsilon_f) = E \\, \\varepsilon_0 \\, \\exp\\!\\left(-\\frac{\\varepsilon - \\varepsilon_0}{\\varepsilon_f - \\varepsilon_0}\\right),\n\\quad \\text{for } \\varepsilon \\ge \\varepsilon_0,\n$$\nwhich ensures continuity at the onset of softening $\\,\\varepsilon=\\varepsilon_0\\,$, where $\\,\\sigma_{\\mathrm{model}}(\\varepsilon_0; \\varepsilon_0,\\varepsilon_f) = E \\varepsilon_0\\,$, and a characteristic decay length governed by $\\,\\varepsilon_f - \\varepsilon_0\\,$. All given data in this problem lie in the post-peak softening regime, i.e., $\\,\\varepsilon_i \\ge \\varepsilon_0\\,$.\n\nCalibration task. Given a set of measured uniaxial softening data $\\{(\\varepsilon_i,\\sigma_i)\\}_{i=1}^n$ and a known modulus $\\,E\\,$, determine the parameters $\\,\\varepsilon_0\\,$ and $\\,\\varepsilon_f\\,$ by minimizing the sum of squared residuals between measured and modeled stresses:\n$$\n\\min_{\\varepsilon_0,\\varepsilon_f} \\; J(\\varepsilon_0,\\varepsilon_f) \n= \\sum_{i=1}^{n} \\left[\\sigma_{\\mathrm{model}}(\\varepsilon_i; \\varepsilon_0,\\varepsilon_f) - \\sigma_i \\right]^2\n\\quad \\text{subject to} \\quad \\varepsilon_0 > 0,\\; \\varepsilon_f > \\varepsilon_0.\n$$\n\nUnits and reporting. Strain $\\,\\varepsilon\\,$ is dimensionless. Stress $\\,\\sigma\\,$ and modulus $\\,E\\,$ are in pascals $\\,(\\mathrm{Pa})\\,$. Your program must compute $\\,\\varepsilon_0\\,$ and $\\,\\varepsilon_f\\,$ for each test case and output them as dimensionless decimal numbers. Round each reported parameter to a maximum of $\\,8\\,$ significant digits in the final output formatting.\n\nTest suite. For each case below, use the provided Young’s modulus $\\,E\\,$ and the measured pairs $\\{(\\varepsilon_i,\\sigma_i)\\}$, with all $\\,\\sigma_i\\,$ in $\\,\\mathrm{Pa}\\,$ and all $\\,\\varepsilon_i\\,$ dimensionless. Each case contains only post-peak data.\n\n- Case A (happy path, moderate softening span):\n  - Modulus: $\\,E = 5.0 \\times 10^{10}\\,\\mathrm{Pa}\\,$.\n  - Data (pairs $(\\varepsilon,\\sigma)$):\n    - $\\,\\left(0.0002,\\,10000000.0\\right)\\,$,\n    - $\\,\\left(0.0004,\\,8187307.530779818\\right)\\,$,\n    - $\\,\\left(0.0006,\\,6703200.460356393\\right)\\,$,\n    - $\\,\\left(0.0009,\\,4965853.037914095\\right)\\,$,\n    - $\\,\\left(0.0012,\\,3678794.411714423\\right)\\,$,\n    - $\\,\\left(0.0016,\\,2465969.639416065\\right)\\,$,\n    - $\\,\\left(0.0020,\\,1652988.8822158656\\right)\\,$.\n\n- Case B (boundary-like, sharp softening with short characteristic span):\n  - Modulus: $\\,E = 5.0 \\times 10^{10}\\,\\mathrm{Pa}\\,$.\n  - Data (pairs $(\\varepsilon,\\sigma)$):\n    - $\\,\\left(0.00015,\\,7500000.0\\right)\\,$,\n    - $\\,\\left(0.00018,\\,5556136.655112884\\right)\\,$,\n    - $\\,\\left(0.00020,\\,4548979.94784475\\right)\\,$,\n    - $\\,\\left(0.00023,\\,3369967.2308791618\\right)\\,$,\n    - $\\,\\left(0.00025,\\,2759095.8087858175\\right)\\,$,\n    - $\\,\\left(0.00028,\\,2043988.4477550946\\right)\\,$,\n    - $\\,\\left(0.00032,\\,1370126.43039551\\right)\\,$.\n\n- Case C (edge case, wide softening span with long tail):\n  - Modulus: $\\,E = 5.0 \\times 10^{10}\\,\\mathrm{Pa}\\,$.\n  - Data (pairs $(\\varepsilon,\\sigma)$):\n    - $\\,\\left(0.00010,\\,5000000.0\\right)\\,$,\n    - $\\,\\left(0.000825,\\,3894003.9153570245\\right)\\,$,\n    - $\\,\\left(0.00155,\\,3032653.298563167\\right)\\,$,\n    - $\\,\\left(0.002275,\\,2361832.7637050735\\right)\\,$,\n    - $\\,\\left(0.00300,\\,1839397.2058572115\\right)\\,$,\n    - $\\,\\left(0.003725,\\,1432523.9843009505\\right)\\,$,\n    - $\\,\\left(0.005175,\\,868869.7172522257\\right)\\,$.\n\nProgram requirements.\n- Implement a solver that computes the pair $\\,(\\varepsilon_0,\\varepsilon_f)\\,$ minimizing the stated least-squares objective under the strict inequalities $\\,\\varepsilon_0 > 0\\,$ and $\\,\\varepsilon_f > \\varepsilon_0\\,$. These inequalities must be enforced numerically; for example, by a parameter transformation that guarantees positivity and ordering.\n- The final program output should be a single line containing a list with three entries, one per test case, where each entry is itself a list $[\\varepsilon_0,\\varepsilon_f]$ formatted without spaces and with each floating-point number rounded to at most $\\,8\\,$ significant digits. For example: $\\,\\left[[\\varepsilon_{0,A},\\varepsilon_{f,A}],[\\varepsilon_{0,B},\\varepsilon_{f,B}],[\\varepsilon_{0,C},\\varepsilon_{f,C}]\\right]\\,$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[[resultA0,resultAf],[resultB0,resultBf],[resultC0,resultCf]]\").", "solution": "The problem posed is a parameter identification task within the framework of continuum damage mechanics. It requires the determination of two model parameters, the strain at the onset of softening, $\\varepsilon_0$, and a characteristic strain governing softening decay, $\\varepsilon_f$. These parameters are to be calibrated by minimizing the discrepancy between a theoretical stress-strain model and a set of experimental data points. This is a standard nonlinear least-squares optimization problem.\n\nThe function to be minimized, representing the sum of squared residuals, is given by $J(\\varepsilon_0, \\varepsilon_f)$:\n$$\nJ(\\varepsilon_0, \\varepsilon_f) = \\sum_{i=1}^{n} \\left[ \\sigma_{\\mathrm{model}}(\\varepsilon_i; \\varepsilon_0, \\varepsilon_f) - \\sigma_i \\right]^2\n$$\nThe stress predicted by the model, $\\sigma_{\\mathrm{model}}$, at a given strain $\\varepsilon_i$ is defined by the exponential softening law:\n$$\n\\sigma_{\\mathrm{model}}(\\varepsilon_i; \\varepsilon_0, \\varepsilon_f) = E \\, \\varepsilon_0 \\, \\exp\\left(-\\frac{\\varepsilon_i - \\varepsilon_0}{\\varepsilon_f - \\varepsilon_0}\\right)\n$$\nHere, $E$ is the Young’s modulus, and $\\{\\sigma_i, \\varepsilon_i\\}$ are the pairs of measured stress and strain.\n\nThis optimization must adhere to physical constraints. The parameters must be positive, and softening must occur after its onset, which imposes the strict inequalities $\\varepsilon_0 > 0$ and $\\varepsilon_f > \\varepsilon_0$. Furthermore, the problem states that the given data lie in the post-peak softening regime, meaning $\\varepsilon_i \\ge \\varepsilon_0$ for all data points $i$. This implies a crucial upper bound for the search space of $\\varepsilon_0$:\n$$\n\\varepsilon_0 \\le \\min_{i} \\{\\varepsilon_i\\}\n$$\n\nTo facilitate a robust numerical solution, we perform a change of variables. Let us define a new parameter vector $\\boldsymbol{p} = [p_0, p_1]$ such that:\n$$\np_0 = \\varepsilon_0\n$$\n$$\np_1 = \\varepsilon_f - \\varepsilon_0\n$$\nIn terms of these new variables, the constraints become more straightforward. The condition $\\varepsilon_0 > 0$ translates to $p_0 > 0$. The condition $\\varepsilon_f > \\varepsilon_0$ implies $p_0 + p_1 > p_0$, which simplifies to $p_1 > 0$. The condition $\\varepsilon_0 \\le \\min_{i} \\{\\varepsilon_i\\}$ becomes $p_0 \\le \\min_{i} \\{\\varepsilon_i\\}$.\n\nThe optimization problem can now be reformulated as minimizing the objective function $J(p_0, p_1)$ with respect to $p_0$ and $p_1$:\n$$\nJ(p_0, p_1) = \\sum_{i=1}^{n} \\left[ E \\, p_0 \\, \\exp\\left(-\\frac{\\varepsilon_i - p_0}{p_1}\\right) - \\sigma_i \\right]^2\n$$\nsubject to the simple box constraints:\n$$\n0 < p_0 \\le \\min_{i}\\{\\varepsilon_i\\}\n$$\n$$\np_1 > 0\n$$\nThis structure is ideally suited for numerical solvers that support bound constraints, such as the L-BFGS-B (Limited-memory Broyden–Fletcher–Goldfarb–Shanno algorithm with bounds) method. This algorithm is implemented in Python's `scipy.optimize.minimize` function.\n\nThe solution will be implemented as follows:\n$1$. For each test case, the objective function $J(p_0, p_1)$ is defined using the provided material modulus $E$ and experimental data $\\{\\varepsilon_i, \\sigma_i\\}$.\n$2$. The bounds for the optimization variables are set. For $p_0$, the bounds are $(0, \\min_i\\{\\varepsilon_i\\}]$, and for $p_1$, the lower bound is $0$. In numerical practice, a small positive value (e.g., $10^{-15}$) is used for the lower bounds to ensure strict positivity.\n$3$. An initial guess for $(p_0, p_1)$ is required to start the iterative optimization process. A logical choice for the initial $p_0$ is a value just inside its feasible range, such as $0.9 \\times \\min_i\\{\\varepsilon_i\\}$. For $p_1$, which represents the characteristic width of the softening curve, the strain range of the data, $\\max_i\\{\\varepsilon_i\\} - \\min_i\\{\\varepsilon_i\\}$, is a reasonable starting estimate.\n$4$. The L-BFGS-B algorithm is then employed to find the optimal parameter set $(p_{0,\\mathrm{opt}}, p_{1,\\mathrm{opt}})$ that minimizes the objective function.\n$5$. Finally, these optimal parameters are transformed back into the physically meaningful parameters $\\varepsilon_0$ and $\\varepsilon_f$:\n$$\n\\varepsilon_{0,\\mathrm{opt}} = p_{0,\\mathrm{opt}}\n$$\n$$\n\\varepsilon_{f,\\mathrm{opt}} = p_{0,\\mathrm{opt}} + p_{1,\\mathrm{opt}}\n$$\nThe computed values are then formatted to a maximum of $8$ significant digits as required for the final output. Given that the provided data are noise-free and perfectly match the model for specific parameters, the optimization is expected to yield a minimum chi-squared value of effectively zero.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves for the optimal damage model parameters e0 and ef for three test cases\n    by minimizing the sum of squared residuals.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"E\": 5.0e10,\n            \"data\": np.array([\n                (0.0002, 10000000.0),\n                (0.0004, 8187307.530779818),\n                (0.0006, 6703200.460356393),\n                (0.0009, 4965853.037914095),\n                (0.0012, 3678794.411714423),\n                (0.0016, 2465969.639416065),\n                (0.0020, 1652988.8822158656),\n            ])\n        },\n        {\n            \"E\": 5.0e10,\n            \"data\": np.array([\n                (0.00015, 7500000.0),\n                (0.00018, 5556136.655112884),\n                (0.00020, 4548979.94784475),\n                (0.00023, 3369967.2308791618),\n                (0.00025, 2759095.8087858175),\n                (0.00028, 2043988.4477550946),\n                (0.00032, 1370126.43039551),\n            ])\n        },\n        {\n            \"E\": 5.0e10,\n            \"data\": np.array([\n                (0.00010, 5000000.0),\n                (0.000825, 3894003.9153570245),\n                (0.00155, 3032653.298563167),\n                (0.002275, 2361832.7637050735),\n                (0.00300, 1839397.2058572115),\n                (0.003725, 1432523.9843009505),\n                (0.005175, 868869.7172522257),\n            ])\n        }\n    ]\n    \n    # Objective function to minimize (sum of squared residuals)\n    def objective_function(p, E, eps_data, sig_data):\n        \"\"\"\n        Calculates the sum of squared residuals for the given parameters.\n        p[0] = e0\n        p[1] = ef - e0\n        \"\"\"\n        p0, p1 = p\n        # The term (eps_data - p0) is guaranteed non-negative by the bounds\n        # The term p1 is guaranteed positive by the bounds\n        # This prevents numerical issues like division by zero or log of negative number\n        sigma_model = E * p0 * np.exp(-(eps_data - p0) / p1)\n        residuals = sigma_model - sig_data\n        return np.sum(residuals**2)\n\n    all_results = []\n    \n    for case in test_cases:\n        E = case[\"E\"]\n        data = case[\"data\"]\n        eps_data = data[:, 0]\n        sig_data = data[:, 1]\n        \n        eps_min = np.min(eps_data)\n        eps_max = np.max(eps_data)\n        \n        # Bounds for the optimization variables [p0, p1]\n        # p0 = e0, so 0 < p0 <= eps_min\n        # p1 = ef - e0, so p1 > 0\n        bounds = ((1e-15, eps_min), (1e-15, np.inf))\n        \n        # Initial guess for the optimizer\n        # A good guess helps convergence, especially for non-convex problems\n        p0_guess = 0.9 * eps_min\n        p1_guess = eps_max - eps_min\n        initial_guess = [p0_guess, p1_guess]\n        \n        # Perform the optimization using L-BFGS-B which supports bounds\n        result = minimize(\n            objective_function,\n            initial_guess,\n            args=(E, eps_data, sig_data),\n            method='L-BFGS-B',\n            bounds=bounds\n        )\n        \n        p0_opt, p1_opt = result.x\n        \n        # Convert back to the original parameters e0 and ef\n        e0 = p0_opt\n        ef = p0_opt + p1_opt\n        \n        all_results.append([e0, ef])\n\n    # Format the results into the required string format\n    output_parts = []\n    for res_pair in all_results:\n        e0, ef = res_pair\n        # Format each number to at most 8 significant digits using '.8g'\n        s_e0 = format(e0, '.8g')\n        s_ef = format(ef, '.8g')\n        output_parts.append(f\"[{s_e0},{s_ef}]\")\n    \n    final_output_string = f\"[{','.join(output_parts)}]\"\n    \n    print(final_output_string)\n\nsolve()\n```", "id": "2873718"}]}