{"hands_on_practices": [{"introduction": "This practice will guide you through the foundational exercise of deriving the macroscopic behavior of a viscoelastic material from its representation as a mechanical model. We will use the Standard Linear Solid (SLS) model, a combination of springs and a dashpot, to derive its governing differential equation. From there, you will determine the material's response to standard test conditions: the relaxation modulus $E(t)$ from a step strain and the creep compliance $J(t)$ from a step stress, solidifying the link between mechanical models and observable material functions [@problem_id:2898541].", "problem": "A uniaxial Standard Linear Solid (SLS) consists of a linear elastic spring of modulus $E_{1}$ in parallel with a Maxwell element composed of a linear elastic spring of modulus $E_{2}$ in series with a Newtonian dashpot of viscosity $\\eta$. Assume small strain, isothermal, one-dimensional deformation with zero pre-history. Use only the fundamental constitutive laws for the spring, $\\sigma = E\\,\\varepsilon$, and the dashpot, $\\sigma = \\eta\\,\\dot{\\varepsilon}$, along with series/parallel compatibility and equilibrium, to proceed as follows:\n\n1) Derive a single differential equation relating the total stress $\\sigma(t)$ and the total strain $\\varepsilon(t)$ for the SLS, expressed solely in terms of $E_{1}$, $E_{2}$, and $\\eta$.\n\n2) Define the relaxation modulus $E(t)$ by the stress response to a unit-step strain history $\\varepsilon(t) = \\varepsilon_{0}\\,H(t)$ via $\\sigma(t) = E(t)\\,\\varepsilon_{0}$, where $H(t)$ is the Heaviside step function and $\\varepsilon_{0}$ is an arbitrary constant strain amplitude. From the differential equation in part (1), solve for $E(t)$, ensuring correct treatment of any jump conditions at $t=0^{+}$.\n\n3) Define the creep compliance $J(t)$ by the strain response to a unit-step stress history $\\sigma(t) = \\sigma_{0}\\,H(t)$ via $\\varepsilon(t) = J(t)\\,\\sigma_{0}$, where $\\sigma_{0}$ is an arbitrary constant stress amplitude. From the same differential equation, solve for $J(t)$, including the correct jump condition at $t=0^{+}$.\n\n4) Compute the one-sided Laplace transforms $\\tilde{E}(s)$ and $\\tilde{J}(s)$ of the functions $E(t)$ and $J(t)$, with $s$ the Laplace variable, under zero pre-history. Then, simplify the product $[s\\,\\tilde{J}(s)]\\,[s\\,\\tilde{E}(s)]$ to a single analytic expression. Express your final answer as this simplified product.\n\nAssume $E_{1} > 0$, $E_{2} > 0$, and $\\eta > 0$. No numerical evaluation is required. The final answer must be a single closed-form expression with no units.", "solution": "The problem statement is a standard exercise in linear viscoelasticity, specifically concerning the Standard Linear Solid (SLS) model. It is scientifically grounded, well-posed, internally consistent, and contains all necessary information for a unique solution. Therefore, the problem is deemed valid and a full solution is presented below.\n\nThe problem asks for a four-part derivation concerning the SLS model. We will address each part systematically. The model consists of a spring with modulus $E_1$ in parallel with a Maxwell element. The Maxwell element itself consists of a spring with modulus $E_2$ in series with a dashpot of viscosity $\\eta$. Let $\\sigma$ and $\\varepsilon$ denote the total stress and total strain on the composite material.\n\n1) Derivation of the governing differential equation.\n\nLet the branch with spring $E_1$ be branch 1, and the Maxwell element be branch M. Since they are in parallel, the total strain $\\varepsilon$ is common to both, and the total stress $\\sigma$ is the sum of the stresses in each branch:\n$$ \\varepsilon_1(t) = \\varepsilon_M(t) = \\varepsilon(t) $$\n$$ \\sigma(t) = \\sigma_1(t) + \\sigma_M(t) $$\nFor spring 1, the constitutive law is simply:\n$$ \\sigma_1(t) = E_1 \\varepsilon(t) $$\nThe Maxwell element consists of spring $E_2$ and dashpot $\\eta$ in series. The stress is common to both components, and the strains add up:\n$$ \\sigma_M(t) = \\sigma_2(t) = \\sigma_{\\eta}(t) $$\n$$ \\varepsilon_M(t) = \\varepsilon_2(t) + \\varepsilon_{\\eta}(t) $$\nSince $\\varepsilon_M = \\varepsilon$, we have $\\varepsilon = \\varepsilon_2 + \\varepsilon_{\\eta}$. Differentiating with respect to time $t$:\n$$ \\dot{\\varepsilon}(t) = \\dot{\\varepsilon}_2(t) + \\dot{\\varepsilon}_{\\eta}(t) $$\nThe constitutive laws for the components of the Maxwell element are:\n$$ \\sigma_2 = E_2 \\varepsilon_2 \\implies \\dot{\\varepsilon}_2 = \\frac{\\dot{\\sigma}_2}{E_2} = \\frac{\\dot{\\sigma}_M}{E_2} $$\n$$ \\sigma_{\\eta} = \\eta \\dot{\\varepsilon}_{\\eta} \\implies \\dot{\\varepsilon}_{\\eta} = \\frac{\\sigma_{\\eta}}{\\eta} = \\frac{\\sigma_M}{\\eta} $$\nSubstituting these into the time-differentiated strain equation for the Maxwell element gives its governing equation:\n$$ \\dot{\\varepsilon} = \\frac{\\dot{\\sigma}_M}{E_2} + \\frac{\\sigma_M}{\\eta} $$\nTo obtain a single equation relating total stress $\\sigma$ and total strain $\\varepsilon$, we eliminate $\\sigma_M$. From the parallel sum, $\\sigma_M = \\sigma - \\sigma_1 = \\sigma - E_1 \\varepsilon$. Differentiating this gives $\\dot{\\sigma}_M = \\dot{\\sigma} - E_1 \\dot{\\varepsilon}$. Substituting these expressions for $\\sigma_M$ and $\\dot{\\sigma}_M$ into the Maxwell element's equation:\n$$ \\dot{\\varepsilon} = \\frac{\\dot{\\sigma} - E_1 \\dot{\\varepsilon}}{E_2} + \\frac{\\sigma - E_1 \\varepsilon}{\\eta} $$\nMultiplying by $E_2 \\eta$ to clear denominators:\n$$ E_2 \\eta \\dot{\\varepsilon} = \\eta(\\dot{\\sigma} - E_1 \\dot{\\varepsilon}) + E_2(\\sigma - E_1 \\varepsilon) $$\n$$ E_2 \\eta \\dot{\\varepsilon} = \\eta \\dot{\\sigma} - E_1 \\eta \\dot{\\varepsilon} + E_2 \\sigma - E_1 E_2 \\varepsilon $$\nFinally, collecting terms for $\\sigma$ and $\\varepsilon$ on opposite sides, we arrive at the governing differential equation for the Standard Linear Solid:\n$$ E_2 \\sigma + \\eta \\dot{\\sigma} = E_1 E_2 \\varepsilon + (E_1 + E_2) \\eta \\dot{\\varepsilon} $$\n\n2) Derivation of the relaxation modulus $E(t)$.\n\nThe relaxation modulus $E(t)$ is defined by the stress response $\\sigma(t)$ to a unit-step strain $\\varepsilon(t) = \\varepsilon_0 H(t)$, where $\\sigma(t) = E(t) \\varepsilon_0$. The strain rate is $\\dot{\\varepsilon}(t) = \\varepsilon_0 \\delta(t)$, where $\\delta(t)$ is the Dirac delta function. Substituting this into the governing differential equation:\n$$ E_2 \\sigma(t) + \\eta \\dot{\\sigma}(t) = E_1 E_2 \\varepsilon_0 H(t) + (E_1 + E_2) \\eta \\varepsilon_0 \\delta(t) $$\nTo find the initial condition for $\\sigma(t)$ at $t=0^+$, we integrate the equation from $t=0^-$ to $t=0^+$. Assuming zero pre-history, $\\sigma(0^-) = 0$.\n$$ \\int_{0^-}^{0^+} (E_2 \\sigma + \\eta \\dot{\\sigma}) dt = \\int_{0^-}^{0^+} (E_1 E_2 \\varepsilon_0 H(t) + (E_1+E_2)\\eta\\varepsilon_0 \\delta(t)) dt $$\n$$ 0 + \\eta[\\sigma(0^+) - \\sigma(0^-)] = 0 + (E_1+E_2)\\eta\\varepsilon_0 $$\n$$ \\eta \\sigma(0^+) = (E_1 + E_2) \\eta \\varepsilon_0 \\implies \\sigma(0^+) = (E_1 + E_2)\\varepsilon_0 $$\nFor $t>0$, $\\delta(t)=0$ and $H(t)=1$. The differential equation becomes a homogeneous first-order ODE for stress:\n$$ E_2 \\sigma + \\eta \\dot{\\sigma} = E_1 E_2 \\varepsilon_0 \\implies \\dot{\\sigma} + \\frac{E_2}{\\eta} \\sigma = \\frac{E_1 E_2}{\\eta} \\varepsilon_0 $$\nThe solution is of the form $\\sigma(t) = \\sigma_h(t) + \\sigma_p(t)$. The particular solution is the steady-state response, $\\sigma_p = E_1 \\varepsilon_0$. The homogeneous solution is $\\sigma_h(t) = C \\exp(-\\frac{E_2}{\\eta} t)$.\nThe general solution for $t>0$ is $\\sigma(t) = E_1 \\varepsilon_0 + C \\exp(-\\frac{E_2}{\\eta} t)$.\nUsing the initial condition $\\sigma(0^+) = (E_1+E_2)\\varepsilon_0$:\n$$ (E_1+E_2)\\varepsilon_0 = E_1 \\varepsilon_0 + C \\implies C = E_2 \\varepsilon_0 $$\nSo, the stress response is $\\sigma(t) = (E_1 + E_2 \\exp(-\\frac{E_2}{\\eta} t))\\varepsilon_0$ for $t > 0$. By definition, $E(t) = \\sigma(t)/\\varepsilon_0$. Including the Heaviside function for $t \\ge 0$:\n$$ E(t) = \\left( E_1 + E_2 \\exp\\left(-\\frac{E_2}{\\eta} t\\right) \\right) H(t) $$\n\n3) Derivation of the creep compliance $J(t)$.\n\nThe creep compliance $J(t)$ is defined by the strain response $\\varepsilon(t)$ to a unit-step stress $\\sigma(t) = \\sigma_0 H(t)$, where $\\varepsilon(t) = J(t) \\sigma_0$. The stress rate is $\\dot{\\sigma}(t) = \\sigma_0 \\delta(t)$. Substituting into the governing DE:\n$$ E_2 \\sigma_0 H(t) + \\eta \\sigma_0 \\delta(t) = E_1 E_2 \\varepsilon(t) + (E_1 + E_2) \\eta \\dot{\\varepsilon}(t) $$\nIntegrating from $t=0^-$ to $t=0^+$ with zero pre-history ($\\varepsilon(0^-)=0$) to find $\\varepsilon(0^+)$:\n$$ \\int_{0^-}^{0^+} (E_2\\sigma_0 H(t) + \\eta\\sigma_0\\delta(t)) dt = \\int_{0^-}^{0^+} (E_1 E_2 \\varepsilon + (E_1+E_2)\\eta\\dot{\\varepsilon}) dt $$\n$$ 0 + \\eta\\sigma_0 = 0 + (E_1+E_2)\\eta[\\varepsilon(0^+) - \\varepsilon(0^-)] $$\n$$ \\eta\\sigma_0 = (E_1+E_2)\\eta\\varepsilon(0^+) \\implies \\varepsilon(0^+) = \\frac{\\sigma_0}{E_1+E_2} $$\nFor $t>0$, $\\delta(t)=0$ and $H(t)=1$. The DE for strain is:\n$$ E_2 \\sigma_0 = E_1 E_2 \\varepsilon + (E_1+E_2)\\eta\\dot{\\varepsilon} \\implies \\dot{\\varepsilon} + \\frac{E_1 E_2}{(E_1+E_2)\\eta} \\varepsilon = \\frac{E_2 \\sigma_0}{(E_1+E_2)\\eta} $$\nThe particular solution (steady-state) is $\\varepsilon_p = \\frac{\\sigma_0}{E_1}$. The homogeneous solution is $\\varepsilon_h(t) = C \\exp\\left(-\\frac{E_1 E_2}{(E_1+E_2)\\eta} t\\right)$.\nThe general solution for $t>0$ is $\\varepsilon(t) = \\frac{\\sigma_0}{E_1} + C \\exp\\left(-\\frac{E_1 E_2}{(E_1+E_2)\\eta} t\\right)$.\nUsing the initial condition $\\varepsilon(0^+) = \\frac{\\sigma_0}{E_1+E_2}$:\n$$ \\frac{\\sigma_0}{E_1+E_2} = \\frac{\\sigma_0}{E_1} + C \\implies C = \\sigma_0\\left(\\frac{1}{E_1+E_2} - \\frac{1}{E_1}\\right) = -\\frac{E_2 \\sigma_0}{E_1(E_1+E_2)} $$\nThe strain response is $\\varepsilon(t) = \\left(\\frac{1}{E_1} - \\frac{E_2}{E_1(E_1+E_2)} \\exp\\left(-\\frac{E_1 E_2}{(E_1+E_2)\\eta} t\\right)\\right) \\sigma_0$. By definition, $J(t) = \\varepsilon(t)/\\sigma_0$:\n$$ J(t) = \\left( \\frac{1}{E_1} - \\frac{E_2}{E_1(E_1+E_2)} \\exp\\left(-\\frac{E_1 E_2}{\\eta(E_1+E_2)} t\\right) \\right) H(t) $$\n\n4) Laplace transforms and their product.\n\nA general result of linear viscoelasticity theory states that the Laplace transforms of the relaxation modulus and creep compliance are related by $[s\\tilde{E}(s)][s\\tilde{J}(s)] = 1$. We will verify this by direct computation.\nWe take the one-sided Laplace transform of the governing differential equation, using $\\mathcal{L}\\{\\dot{f}(t)\\} = s\\tilde{f}(s) - f(0^-)$. With zero pre-history, this simplifies to $s\\tilde{f}(s)$.\n$$ E_2 \\tilde{\\sigma}(s) + \\eta s \\tilde{\\sigma}(s) = E_1 E_2 \\tilde{\\varepsilon}(s) + (E_1 + E_2) \\eta s \\tilde{\\varepsilon}(s) $$\n$$ \\tilde{\\sigma}(s) (E_2 + s\\eta) = \\tilde{\\varepsilon}(s) (E_1 E_2 + s\\eta(E_1+E_2)) $$\nThe operational moduli are defined as $s\\tilde{E}(s) = \\tilde{\\sigma}(s)/\\tilde{\\varepsilon}(s)$ and $s\\tilde{J}(s) = \\tilde{\\varepsilon}(s)/\\tilde{\\sigma}(s)$.\nFrom the transformed DE, we find these directly:\n$$ s\\tilde{E}(s) = \\frac{\\tilde{\\sigma}(s)}{\\tilde{\\varepsilon}(s)} = \\frac{E_1 E_2 + s\\eta(E_1+E_2)}{E_2 + s\\eta} $$\n$$ s\\tilde{J}(s) = \\frac{\\tilde{\\varepsilon}(s)}{\\tilde{\\sigma}(s)} = \\frac{E_2 + s\\eta}{E_1 E_2 + s\\eta(E_1+E_2)} $$\nNow we compute the required product:\n$$ [s\\tilde{E}(s)] [s\\tilde{J}(s)] = \\left( \\frac{E_1 E_2 + s\\eta(E_1+E_2)}{E_2 + s\\eta} \\right) \\left( \\frac{E_2 + s\\eta}{E_1 E_2 + s\\eta(E_1+E_2)} \\right) $$\nThe terms in the numerators and denominators cancel precisely:\n$$ [s\\tilde{E}(s)] [s\\tilde{J}(s)] = 1 $$\nThis confirms the validity of the derived expressions for $E(t)$ and $J(t)$ and verifies a fundamental identity of linear viscoelasticity for this specific model. The simplified analytic expression for the product is $1$.", "answer": "$$\\boxed{1}$$", "id": "2898541"}, {"introduction": "In linear viscoelasticity, the creep compliance $J(t)$ and relaxation modulus $G(t)$ are not independent; they are two sides of the same coin, offering different perspectives on a material's time-dependent response. This exercise will allow you to practice the essential skill of converting one function into the other using the power of the Laplace transform. Starting with a given analytical form for $J(t)$, you will derive the corresponding $G(t)$ and verify the consistency of their limiting behaviors at short and long times, a critical check in any viscoelastic analysis [@problem_id:2919023].", "problem": "A one-dimensional, small-deformation, time-translationally invariant linear viscoelastic polymer is characterized by the hereditary constitutive relations that connect the stress history and the strain history through the creep compliance $J(t)$ and the relaxation modulus $G(t)$. An experiment measures the creep compliance under a unit step stress and finds\n$$\nJ(t) \\;=\\; J_{0} \\;+\\; J_{1}\\bigl(1-\\exp(-t/\\tau)\\bigr),\n$$\nwith $J_{0}>0$, $J_{1}>0$, and $\\tau>0$ independent of time. Starting from the hereditary integral definitions of linear viscoelasticity and standard properties of linear time-invariant systems, derive an explicit closed-form expression for the relaxation modulus $G(t)$ corresponding to the given $J(t)$. Then verify the instantaneous and long-time limits by showing that $\\lim_{t\\to 0^{+}}G(t)$ and $\\lim_{t\\to \\infty}G(t)$ are consistent with the measured $J(t)$. Express your final result as a single closed-form function of $t$, $J_{0}$, $J_{1}$, and $\\tau$; do not substitute numerical values. No rounding is required, and no specific units are required for the symbolic expression.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and complete. It is a standard problem in the theory of linear viscoelasticity and can be solved using established principles. Therefore, a solution will be provided.\n\nThe fundamental constitutive relations for a one-dimensional linear time-invariant viscoelastic material can be expressed in hereditary integral form. A direct consequence of these relations, most readily shown using the Laplace transform, is a concise algebraic relationship between the Laplace transforms of the relaxation modulus $G(t)$ and the creep compliance $J(t)$. Let $\\bar{G}(s) = \\mathcal{L}\\{G(t)\\}$ and $\\bar{J}(s) = \\mathcal{L}\\{J(t)\\}$ be the Laplace transforms of these functions. The relationship is\n$$\ns^2 \\bar{G}(s) \\bar{J}(s) = 1\n$$\nThis equation forms the basis of our derivation. The problem requires us to find $G(t)$ given $J(t)$. The strategy is to first compute the Laplace transform of the given $J(t)$, then use the above relation to find $\\bar{G}(s)$, and finally compute the inverse Laplace transform of $\\bar{G}(s)$ to obtain $G(t)$.\n\nThe given creep compliance is:\n$$\nJ(t) = J_{0} + J_{1}\\bigl(1-\\exp(-t/\\tau)\\bigr) = J_{0} + J_{1} - J_{1}\\exp(-t/\\tau)\n$$\nwhere $J_0 > 0$, $J_1 > 0$, and $\\tau > 0$. We compute its Laplace transform, $\\bar{J}(s)$:\n$$\n\\bar{J}(s) = \\mathcal{L}\\{J_{0} + J_{1} - J_{1}\\exp(-t/\\tau)\\}\n$$\nUsing the standard Laplace transform pairs $\\mathcal{L}\\{c\\} = c/s$ for a constant $c$ and $\\mathcal{L}\\{\\exp(-at)\\} = 1/(s+a)$, we obtain:\n$$\n\\bar{J}(s) = \\frac{J_{0} + J_{1}}{s} - \\frac{J_{1}}{s + 1/\\tau}\n$$\nTo simplify, we combine the terms over a common denominator:\n$$\n\\bar{J}(s) = \\frac{(J_{0} + J_{1})(s + 1/\\tau) - J_{1}s}{s(s + 1/\\tau)} = \\frac{(J_{0} + J_{1})s + (J_{0} + J_{1})/\\tau - J_{1}s}{s(s + 1/\\tau)}\n$$\n$$\n\\bar{J}(s) = \\frac{J_{0}s + (J_{0} + J_{1})/\\tau}{s(s + 1/\\tau)}\n$$\nNow, we find $\\bar{G}(s)$ using the relation $\\bar{G}(s) = 1/(s^2 \\bar{J}(s))$:\n$$\n\\bar{G}(s) = \\frac{1}{s^2} \\left[ \\frac{s(s + 1/\\tau)}{J_{0}s + (J_{0} + J_{1})/\\tau} \\right] = \\frac{s + 1/\\tau}{s(J_{0}s + (J_{0} + J_{1})/\\tau)}\n$$\nTo facilitate the inverse transform, we factor $J_0$ from the denominator:\n$$\n\\bar{G}(s) = \\frac{s + 1/\\tau}{s J_{0} \\left(s + \\frac{J_{0} + J_{1}}{J_{0}\\tau}\\right)} = \\frac{1}{J_{0}} \\left[ \\frac{s + 1/\\tau}{s \\left(s + \\frac{J_{0} + J_{1}}{J_{0}\\tau}\\right)} \\right]\n$$\nWe perform a partial fraction expansion on the term in the brackets. Let $\\beta = \\frac{J_{0} + J_{1}}{J_{0}\\tau}$.\n$$\n\\frac{s + 1/\\tau}{s(s+\\beta)} = \\frac{A}{s} + \\frac{B}{s+\\beta}\n$$\nThe coefficients $A$ and $B$ are found using the residue method:\n$$\nA = \\lim_{s\\to 0} s \\left[ \\frac{s + 1/\\tau}{s(s+\\beta)} \\right] = \\frac{1/\\tau}{\\beta} = \\frac{1/\\tau}{(J_{0} + J_{1})/(J_{0}\\tau)} = \\frac{J_{0}}{J_{0}+J_{1}}\n$$\n$$\nB = \\lim_{s\\to -\\beta} (s+\\beta) \\left[ \\frac{s + 1/\\tau}{s(s+\\beta)} \\right] = \\frac{-\\beta + 1/\\tau}{-\\beta} = 1 - \\frac{1/\\tau}{\\beta} = 1 - A = 1 - \\frac{J_{0}}{J_{0}+J_{1}} = \\frac{J_{1}}{J_{0}+J_{1}}\n$$\nSubstituting these coefficients back into the expression for $\\bar{G}(s)$:\n$$\n\\bar{G}(s) = \\frac{1}{J_{0}} \\left[ \\left(\\frac{J_{0}}{J_{0}+J_{1}}\\right)\\frac{1}{s} + \\left(\\frac{J_{1}}{J_{0}+J_{1}}\\right)\\frac{1}{s+\\beta} \\right]\n$$\nDistributing the $1/J_{0}$ factor:\n$$\n\\bar{G}(s) = \\frac{1}{J_{0}+J_{1}} \\frac{1}{s} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} \\frac{1}{s+\\beta}\n$$\nNow we compute the inverse Laplace transform, $G(t) = \\mathcal{L}^{-1}\\{\\bar{G}(s)\\}$, term by term. Substituting back the expression for $\\beta$:\n$$\nG(t) = \\mathcal{L}^{-1}\\left\\{ \\frac{1}{J_{0}+J_{1}} \\frac{1}{s} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} \\frac{1}{s+\\frac{J_{0}+J_{1}}{J_{0}\\tau}} \\right\\}\n$$\n$$\nG(t) = \\frac{1}{J_{0}+J_{1}} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} \\exp\\left(-\\frac{J_{0}+J_{1}}{J_{0}\\tau} t\\right)\n$$\nThis is the explicit closed-form expression for the relaxation modulus $G(t)$.\n\nThe second part of the problem is to verify the limiting behaviors. The general relations for the initial and final values are $G(0^{+}) = 1/J(0^{+})$ and $G(\\infty) = 1/J(\\infty)$.\n\nFirst, we evaluate the limits of the given $J(t)$:\nInstantaneous compliance ($t \\to 0^{+}$):\n$$\nJ(0^{+}) = \\lim_{t\\to 0^{+}} \\left[J_{0} + J_{1}\\bigl(1-\\exp(-t/\\tau)\\bigr)\\right] = J_{0} + J_{1}(1 - 1) = J_{0}\n$$\nLong-time compliance ($t \\to \\infty$):\n$$\nJ(\\infty) = \\lim_{t\\to \\infty} \\left[J_{0} + J_{1}\\bigl(1-\\exp(-t/\\tau)\\bigr)\\right] = J_{0} + J_{1}(1 - 0) = J_{0} + J_{1}\n$$\n\nNext, we evaluate the limits of our derived $G(t)$:\nInstantaneous modulus ($t \\to 0^{+}$):\n$$\nG(0^{+}) = \\lim_{t\\to 0^{+}} \\left[ \\frac{1}{J_{0}+J_{1}} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} \\exp\\left(-\\frac{J_{0}+J_{1}}{J_{0}\\tau} t\\right) \\right]\n$$\n$$\nG(0^{+}) = \\frac{1}{J_{0}+J_{1}} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} = \\frac{J_{0} + J_{1}}{J_{0}(J_{0}+J_{1})} = \\frac{1}{J_{0}}\n$$\nLong-time modulus ($t \\to \\infty$):\n$$\nG(\\infty) = \\lim_{t\\to \\infty} \\left[ \\frac{1}{J_{0}+J_{1}} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} \\exp\\left(-\\frac{J_{0}+J_{1}}{J_{0}\\tau} t\\right) \\right]\n$$\n$$\nG(\\infty) = \\frac{1}{J_{0}+J_{1}} + 0 = \\frac{1}{J_{0}+J_{1}}\n$$\n\nFinally, we check for consistency:\nFor the instantaneous limit, we must have $G(0^{+}) = 1/J(0^{+})$. Our results give $1/J_{0} = 1/J_{0}$, which is correct.\nFor the long-time limit, we must have $G(\\infty) = 1/J(\\infty)$. Our results give $1/(J_{0}+J_{1}) = 1/(J_{0}+J_{1})$, which is also correct.\nThe derived expression for $G(t)$ is therefore consistent with the physical expectations at short and long times.", "answer": "$$\n\\boxed{\n\\frac{1}{J_{0}+J_{1}} + \\frac{J_{1}}{J_{0}(J_{0}+J_{1})} \\exp\\left(-\\frac{J_{0}+J_{1}}{J_{0}\\tau} t\\right)\n}\n$$", "id": "2919023"}, {"introduction": "Moving from pure theory to experimental practice, this problem addresses the crucial task of connecting mathematical models to real-world data. You will explore how to fit a generalized Maxwell model, represented by a Prony series, to a set of noisy relaxation modulus measurements. This exercise focuses on formulating the task as a linear least-squares problem and, importantly, delves into the concept of parameter identifiability—a practical challenge that determines whether model parameters can be uniquely estimated from the available data [@problem_id:2898527].", "problem": "An isothermal, linear viscoelastic solid is tested in uniaxial stress relaxation. By the Boltzmann superposition principle, the stress response to a strain history $\\varepsilon(t)$ is given by\n$$\n\\sigma(t) = \\int_{0}^{t} G(t-s)\\,\\frac{d\\varepsilon(s)}{ds}\\,ds,\n$$\nwhere $G(t)$ is the relaxation modulus. For a unit step strain of amplitude $\\varepsilon_{0}$ applied at $t=0$, i.e., $\\varepsilon(t)=\\varepsilon_{0}H(t)$ with the Heaviside step function $H(t)$, the measured stress satisfies $\\sigma(t) = \\varepsilon_{0} G(t)$. An experiment provides noisy measurements $\\{(t_i, G_{\\mathrm{exp}}(t_i))\\}_{i=1}^{N}$ of the relaxation modulus over a finite window $t \\in [0,T_{\\max}]$. Assume that the material is modeled by a generalized Maxwell representation with a finite number $K$ of characteristic times that are fixed and known, collected in the set $\\{\\tau_k\\}_{k=1}^{K}$, and that the relaxation modulus is representable as a linear superposition of known basis functions parameterized by $\\{\\tau_k\\}_{k=1}^{K}$ together with a time-independent equilibrium contribution.\n\nWhich of the following statements correctly (i) formulates a linear least-squares estimation problem to determine the unknown amplitudes associated with the known characteristic times from the experimental data and (ii) characterizes when these amplitudes are identifiable from the data? Select all that apply.\n\nA. With fixed $\\{\\tau_k\\}_{k=1}^{K}$, model $G(t_i)$ as a linear combination of a constant term and the basis functions $e^{-t_i/\\tau_k}$. Let $y \\in \\mathbb{R}^{N}$ have entries $y_i=G_{\\mathrm{exp}}(t_i)$. Define a design matrix $A \\in \\mathbb{R}^{N \\times (K+1)}$ by $A_{i,0}=1$ and $A_{i,k}=e^{-t_i/\\tau_k}$ for $k=1,\\dots,K$. Estimate the unknown coefficient vector $x=[G_{\\infty}, G_1,\\dots,G_K]^{\\top}$ by solving the weighted least-squares problem\n$$\n\\min_{x \\in \\mathbb{R}^{K+1}} \\,\\|W^{1/2}(Ax - y)\\|_2^2,\n$$\nwhere $W=\\mathrm{diag}(w_1,\\dots,w_N)$ with $w_i>0$ chosen inversely proportional to the noise variance at $t_i$. This produces a unique solution if and only if $A$ has full column rank.\n\nB. Because the exponentials can be linearized for small $t/\\tau_k$, take $A_{i,k}=t_i/\\tau_k$ and fit $G(t_i) \\approx G_{\\infty} + \\sum_{k=1}^{K} G_k (t_i/\\tau_k)$ by ordinary least squares. Identifiability of the amplitudes then only requires $N \\ge K+1$.\n\nC. The amplitudes $G_k$ and the equilibrium modulus $G_{\\infty}$ are structurally identifiable from $\\{(t_i,G_{\\mathrm{exp}}(t_i))\\}_{i=1}^{N}$ with fixed $\\{\\tau_k\\}_{k=1}^{K}$ if and only if the columns of the design matrix built from the functions $\\{1, e^{-t/\\tau_1},\\dots,e^{-t/\\tau_K}\\}$ evaluated at $\\{t_i\\}_{i=1}^{N}$ are linearly independent, equivalently if $A^{\\top}WA$ is positive definite for some positive diagonal $W$. In practice, if some $\\tau_k \\gg T_{\\max}$, then $e^{-t_i/\\tau_k} \\approx 1$ over the data window and the corresponding column becomes nearly collinear with the constant column, making $G_k$ and $G_{\\infty}$ unidentifiable or severely ill-conditioned; similarly, if some $\\tau_j$ and $\\tau_k$ are very close relative to the sampling times, their columns are nearly collinear, degrading identifiability.\n\nD. Because $G(t)$ is completely monotone for linear viscoelastic solids, one must impose $G_k \\ge 0$ and $G_{\\infty} \\ge 0$ to obtain identifiability; without these nonnegativity constraints, the amplitudes cannot be uniquely determined even if the design matrix has full column rank.\n\nE. It is preferable to fit in the Laplace domain: compute a numerical Laplace transform $\\tilde{G}(s)$ of $G_{\\mathrm{exp}}(t)$, set $s_k=1/\\tau_k$, and solve the linear system $\\tilde{G}(s_k)=G_{\\infty}/s_k + \\sum_{j=1}^{K} G_j/(s_k+1/\\tau_j)$ for the amplitudes. This approach yields a linear least-squares problem with improved identifiability over the time-domain formulation regardless of the sampling window.", "solution": "Starting from the Boltzmann superposition principle,\n$$\n\\sigma(t) = \\int_{0}^{t} G(t-s)\\,\\frac{d\\varepsilon(s)}{ds}\\,ds,\n$$\nand considering a relaxation experiment in which a step strain $\\varepsilon(t)=\\varepsilon_0 H(t)$ is applied at $t=0$, we obtain\n$$\n\\sigma(t) = \\int_{0}^{t} G(t-s)\\,\\varepsilon_0 \\delta(s)\\,ds = \\varepsilon_0 G(t),\n$$\nwhere $\\delta(s)$ is the Dirac delta distribution and $H(t)$ is the Heaviside function. Thus the measured relaxation modulus $G(t)$ directly characterizes the stress response to the step strain.\n\nIn a generalized Maxwell representation, the relaxation modulus of a linear viscoelastic solid with a finite number $K$ of Maxwell branches in parallel with an equilibrium spring can be represented as a Prony series:\n$$\nG(t) = G_{\\infty} + \\sum_{k=1}^{K} G_k\\,e^{-t/\\tau_k},\n$$\nwhere $G_{\\infty}$ is the equilibrium modulus, $G_k$ are amplitudes, and $\\tau_k$ are the characteristic relaxation times. If the set of relaxation times $\\{\\tau_k\\}_{k=1}^{K}$ is fixed and known, the model is linear in the unknown amplitudes $\\{G_k\\}_{k=1}^{K}$ and $G_{\\infty}$.\n\nGiven noisy measurements $\\{(t_i, G_{\\mathrm{exp}}(t_i))\\}_{i=1}^{N}$, define the data vector $y \\in \\mathbb{R}^{N}$ with entries $y_i = G_{\\mathrm{exp}}(t_i)$. Construct the design matrix $A \\in \\mathbb{R}^{N \\times (K+1)}$ with first column $A_{i,0}=1$ corresponding to the constant $G_{\\infty}$, and subsequent columns $A_{i,k}=e^{-t_i/\\tau_k}$ for $k=1,\\dots,K$. Define the unknown parameter vector $x = [G_{\\infty}, G_1,\\dots,G_K]^{\\top} \\in \\mathbb{R}^{K+1}$. Under an additive noise model with possibly heteroscedastic variances, one formulates the weighted linear least-squares problem\n$$\n\\min_{x \\in \\mathbb{R}^{K+1}} \\,\\|W^{1/2}(Ax - y)\\|_2^2,\n$$\nwhere $W=\\mathrm{diag}(w_1,\\dots,w_N)$ with $w_i>0$ typically chosen as $w_i \\propto 1/\\mathrm{Var}[\\text{noise at } t_i]$. The normal equations are\n$$\n(A^{\\top} W A)\\,x = A^{\\top} W y.\n$$\nExistence and uniqueness of the minimizer require that $A$ have full column rank, which is equivalent to $A^{\\top} W A$ being positive definite for any positive diagonal $W$.\n\nIdentifiability of amplitudes follows from the linear independence of the columns of $A$ evaluated at the sampled times. The function set $\\{1, e^{-t/\\tau_1},\\dots,e^{-t/\\tau_K}\\}$ is linearly independent over $t \\in (0,\\infty)$ for distinct $\\{\\tau_k\\}$ in the continuous sense, but discrete sampling can induce near-dependencies. Specifically:\n- If some $\\tau_k \\gg T_{\\max}$ and the data do not extend to sufficiently long times, then $e^{-t_i/\\tau_k} \\approx 1 - t_i/\\tau_k \\approx 1$ over the measurement window, so the corresponding column is nearly collinear with the constant column, making $G_k$ and $G_{\\infty}$ indistinguishable or poorly conditioned.\n- If some $\\tau_j$ and $\\tau_k$ are very close relative to the resolution of the sampling times $\\{t_i\\}$, then $e^{-t_i/\\tau_j}$ and $e^{-t_i/\\tau_k}$ are nearly proportional, leading to ill-conditioning and a loss of practical identifiability for the separate amplitudes.\n- Conversely, if the sampling times span the relevant time scales so that the columns are not linearly dependent, then $A$ has full column rank and the least-squares solution is unique. Nonnegativity constraints $G_k \\ge 0$ and $G_{\\infty} \\ge 0$ can encode physical admissibility and improve numerical robustness, but they are not required for mathematical identifiability when $A$ has full column rank.\n\nOption-by-option analysis:\n\nOption A: This option constructs the correct linear model in terms of a constant plus exponential basis functions evaluated at the measurement times, with unknown coefficient vector $x$. The weighted least-squares objective $\\|W^{1/2}(Ax - y)\\|_2^2$ is the appropriate formulation under heteroscedastic Gaussian noise, and uniqueness is correctly tied to $A$ having full column rank. This is correct.\n\nOption B: Replacing the exponential basis $e^{-t_i/\\tau_k}$ by its small-argument linearization $t_i/\\tau_k$ is not justified over general measurement windows and does not represent the generalized Maxwell model. Moreover, identifiability does not reduce merely to $N \\ge K+1$; full column rank of the correct design matrix is required, and $N \\ge K+1$ is necessary but not sufficient. This is incorrect.\n\nOption C: This precisely states the identifiability condition in terms of linear independence of the sampled basis functions and the positive definiteness of $A^{\\top}WA$. It also correctly notes the practical degeneracies when $\\tau_k \\gg T_{\\max}$ (near-collinearity with the constant column) and when relaxation times are too close relative to sampling resolution (near-collinearity among exponential columns), which degrade identifiability. This is correct.\n\nOption D: While $G_k \\ge 0$ and $G_{\\infty} \\ge 0$ are physically motivated for passive, thermodynamically admissible materials and can regularize the fit, they are not necessary for uniqueness of the least-squares solution. If $A$ has full column rank, the unconstrained least-squares problem has a unique solution regardless of sign constraints. Therefore, nonnegativity is not required for identifiability in the linear-algebraic sense. This is incorrect.\n\nOption E: Transform-domain fitting by numerical Laplace transform is highly ill-posed in the presence of noise and finite windows. The suggested algebraic system is not a linear least-squares problem in the time-domain data and does not, in general, improve identifiability; numerical Laplace transforms amplify noise and are sensitive to truncation. The claim of improved identifiability regardless of sampling is unfounded. This is incorrect.", "answer": "$$\\boxed{AC}$$", "id": "2898527"}]}