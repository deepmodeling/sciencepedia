{"hands_on_practices": [{"introduction": "在高通量材料筛选中，系统地探索庞大的化学成分空间是发现新材料的第一步。本练习将指导你如何从第一性原理出发，为三元体系构建一个离散的成分网格[@problem_id:2479781]。通过这个练习，你将学会如何确定网格分辨率，以确保基于该网格构建的代理模型的预测误差在可接受的范围内，这对于平衡计算成本和模型精度至关重要。", "problem": "在一次三元合金系统的高通量筛选活动中，您计划将成分单形离散化，以便为一个光滑的属性场构建一个数据驱动的代理模型。设三元成分单形定义为 $S = \\{(x_1,x_2,x_3) \\in \\mathbb{R}^3 : x_i \\ge 0,\\ \\sum_{i=1}^{3} x_i = 1\\}$，并通过 $(x_1,x_2) \\in \\mathbb{R}^2$ 对 $S$ 进行参数化，其中 $x_3 = 1 - x_1 - x_2$。考虑一个分辨率为 $m \\in \\mathbb{N}$ 的重心坐标网格，该网格由所有重心坐标为 $\\left(\\frac{i}{m}, \\frac{j}{m}, \\frac{k}{m}\\right)$ 的成分组成，其中 $i,j,k \\in \\mathbb{Z}_{\\ge 0}$ 且 $i+j+k = m$。该网格在 $(x_1,x_2)$ 平面中导出一种标准的分段线性三角剖分，该剖分由全等的等腰直角三角形组成，其直角边长度为 $\\frac{1}{m}$。\n\n假设目标属性是一个实值函数 $f:S \\to \\mathbb{R}$，它在 $S$ 上是二次连续可微的，并且其（关于 $(x_1,x_2)$ 的）Hessian 矩阵具有一致的算子范数界 $\\|\\nabla^2 f(x)\\|_2 \\le M$，对所有 $x \\in S$ 成立，其中 $M$ 是一个已知常数。您将使用根据网格节点上的值构建的分段线性插值来近似 $f$。\n\n从第一性原理出发，完成以下任务：\n\n1) 使用组合论证，通过计算方程 $i+j+k=m$ 的非负整数解的数量，推导唯一网格成分数 $N(m)$ 的封闭形式表达式。\n\n2) 使用带有积分或拉格朗日余项的多维泰勒定理，并结合网格中等腰直角三角形的几何形状，获得最坏情况下逐点插值误差的一个充分界（用 $M$、$m$ 和三角形边长表示）。由此，推导出关于 $m$ 的一个充分条件，以保证一致插值误差最多为预设的容差 $\\varepsilon > 0$。\n\n3) 对于 $M = 500$ 和 $\\varepsilon = 3.0 \\times 10^{-3}$，计算满足您所推导的充分条件的最小整数分辨率 $m$，然后计算 $N(m)$。\n\n将您的最终答案表示为您找到的最小 $m$ 所对应的 $N(m)$ 的精确整数值。不要包含单位，也不要四舍五入；报告精确的整数。", "solution": "该问题提出了关于三元成分单形上属性函数的数值近似的三个任务。我们将从基本原理出发，依次解决每个任务。\n\n首先，我们必须确定在给定分辨率 $m$ 下的网格点数 $N(m)$。网格点由重心坐标 $(\\frac{i}{m}, \\frac{j}{m}, \\frac{k}{m})$ 定义，其中 $i, j, k$ 是非负整数，满足 $i+j+k=m$。因此，这种唯一成分的数量 $N(m)$ 等价于方程 $i+j+k=m$ 的非负整数解的数量。这是一个经典的组合问题，可以使用“隔板法”解决。我们要将 $m$ 个相同的物品（星）分配到 3 个不同的箱子（由 $i, j, k$ 索引）中。这等价于将 $m$ 个星和 $3-1=2$ 个隔板排成一列。序列中的总位置数为 $m+2$。不同排列的数量是从 $m+2$ 个可用位置中为 2 个隔板选择位置的方法数。这由二项式系数 $\\binom{m+2}{2}$ 给出。\n因此，网格点的数量为：\n$$N(m) = \\binom{m+2}{2} = \\frac{(m+2)!}{2!(m+2-2)!} = \\frac{(m+2)(m+1)}{2}$$\n\n其次，我们必须推导分辨率 $m$ 的一个充分条件，以确保一致插值误差不超过容差 $\\varepsilon$。近似是在定义域的三角剖分上对函数 $f(x)$ 进行的分段线性插值 $L(x)$。此插值的误差由函数 $f$ 的光滑度和网格中三角形的大小决定。\n设 $x=(x_1, x_2)$ 为平面中的坐标。函数为 $f(x)$。误差为 $E(x) = f(x) - L(x)$。根据问题陈述，$f$ 是二次连续可微的（$C^2$），其 Hessian 矩阵 $\\nabla^2 f(x)$ 具有一致的算子范数界 $\\|\\nabla^2 f(x)\\|_2 \\le M$。\n对于网格中的单个三角形 $T$，有限元逼近理论中的一个标准结果（可由泰勒定理推导）提供了逐点插值误差的一个上界。对于三角形 $T$ 上的线性插值，该界由以下公式给出：\n$$\\max_{x \\in T} |f(x) - L(x)| \\le C h_T^2 \\max_{y \\in T} \\|\\nabla^2 f(y)\\|_2$$\n其中 $h_T$ 是三角形的直径（其最长边的长度），$C$ 是一个取决于三角形几何形状的常数。对于一般的凸域，一个广泛使用的常数是 $C = \\frac{1}{8}$，它源于一维情况。\n问题陈述指出，该网格通过直角边长度为 $h = \\frac{1}{m}$ 的全等等腰直角三角形导出三角剖分。这样一个三角形的直径 $h_T$ 是其斜边的长度：\n$$h_T = \\sqrt{h^2 + h^2} = \\sqrt{2h^2} = h\\sqrt{2} = \\frac{\\sqrt{2}}{m}$$\n将此结果以及给定的 Hessian 范数界代入误差公式，我们得到单个三角形内误差的界：\n$$\\max_{x \\in T} |f(x) - L(x)| \\le \\frac{1}{8} h_T^2 M = \\frac{1}{8} \\left(\\frac{\\sqrt{2}}{m}\\right)^2 M = \\frac{1}{8} \\left(\\frac{2}{m^2}\\right) M = \\frac{M}{4m^2}$$\n由于网格中所有三角形都是全等的，这个界在整个定义域 $S$ 上是一致的。一致插值误差为 $\\sup_{x \\in S} |f(x) - L(x)|$。因此，我们可以陈述该误差最多为 $\\varepsilon$ 的充分条件：\n$$\\frac{M}{4m^2} \\le \\varepsilon$$\n解出 $m$，我们得到对分辨率的要求条件：\n$$m^2 \\ge \\frac{M}{4\\varepsilon} \\implies m \\ge \\sqrt{\\frac{M}{4\\varepsilon}} = \\frac{1}{2}\\sqrt{\\frac{M}{\\varepsilon}}$$\n由于 $m$ 必须是整数，保证所需精度的最小整数分辨率是 $m_{min} = \\left\\lceil \\frac{1}{2}\\sqrt{\\frac{M}{\\varepsilon}} \\right\\rceil$。\n\n第三，我们针对给定的值 $M=500$ 和 $\\varepsilon = 3.0 \\times 10^{-3}$，计算具体的最小整数分辨率 $m$ 以及相应的网格点数 $N(m)$。\n使用上面推导的条件：\n$$m \\ge \\frac{1}{2}\\sqrt{\\frac{500}{3.0 \\times 10^{-3}}} = \\frac{1}{2}\\sqrt{\\frac{5 \\times 10^2}{3 \\times 10^{-3}}} = \\frac{1}{2}\\sqrt{\\frac{5}{3} \\times 10^5}$$\n进行数值计算：\n$$m \\ge \\frac{1}{2}\\sqrt{166666.66...} \\approx \\frac{1}{2}(408.248...) \\approx 204.124$$\n由于 $m$ 必须是整数，满足此条件的最小整数值是 $m = 205$。\n\n现在，我们使用第一部分推导的公式计算该分辨率下唯一网格成分的数量 $N(m)$：\n$$N(m) = \\frac{(m+1)(m+2)}{2}$$\n代入 $m=205$：\n$$N(205) = \\frac{(205+1)(205+2)}{2} = \\frac{206 \\times 207}{2} = 103 \\times 207 = 21321$$\n因此，必须筛选至少 21321 种成分，以确保插值误差低于指定容差。", "answer": "$$\\boxed{21321}$$", "id": "2479781"}, {"introduction": "一个机器学习模型的真正价值在于其预测全新材料属性的能力，这被称为外推（extrapolation），而非仅仅在已知材料类型中进行内插（interpolation）。本练习聚焦于评估模型的关键挑战：如何设计严谨的验证策略来检验模型对外推的性能，例如预测含有训练集中未出现过的元素的化合物。通过对比“留一元素法”（LOEO）等策略与传统随机划分的差异[@problem_id:2479777]，你将深刻理解为何标准交叉验证可能会高估模型的实际发现能力。", "problem": "一个材料信息学团队正在构建一个监督回归模型，用于预测无机晶体化合物的每原子生成能。每个样本由一个输入向量 $x$ 表示，该向量包含成分描述符、元素级嵌入和晶体结构原型标签。目标值是 $y \\in \\mathbb{R}$。设输入和目标上的数据生成分布为 $P(X,Y)$，并设 $f_{\\theta}$ 是一个在独立同分布 (i.i.d.) 假设下，使用绝对误差损失 $\\ell(\\hat{y},y) = |\\hat{y}-y|$，通过经验风险最小化 (ERM) 训练的模型。\n\n将样本集 $S$（大小为 $|S|$）上的经验风险定义为\n$$\n\\hat{R}_{S}(f) = \\frac{1}{|S|} \\sum_{(x_i,y_i)\\in S} \\ell\\big(f(x_i),y_i\\big),\n$$\n并将分布 $Q$ 下的总体风险定义为\n$$\nR_{Q}(f) = \\mathbb{E}_{(X,Y)\\sim Q}\\big[\\ell\\big(f(X),Y\\big)\\big].\n$$\n在从同一批化合物中抽取的随机训练/测试集划分中，i.i.d. 假设意味着 $P_{\\text{train}}(X,Y) \\approx P_{\\text{test}}(X,Y)$，因此对于足够大的测试集，$R_{P_{\\text{test}}}(f)$ 可以用 $\\hat{R}_{\\text{test}}(f)$ 来近似。\n\n然而，该团队最终关心的是对以下情况的分布外外推能力：(i) 包含训练集中未见元素的成分，以及 (ii) 属于训练集中未见原型的结构。设 $\\mathcal{E}(x)$ 表示 $x$ 中存在的化学元素集合，并设 $\\mathrm{proto}(x) \\in \\mathcal{P}$ 表示 $x$ 的晶体原型标签。该团队怀疑，在随机划分下出现的低误差，部分是由于训练集和测试集之间共享的元素和原型导致的目标泄漏，这使得模型能够记忆特定于元素或原型的相关性。\n\n哪个选项指定了评估划分方法及其基本原理，能够正确测试对新元素和新原型的外推能力，并解释了这些划分方法如何能揭示随机划分可能隐藏的失效模式？\n\nA. 通过以下方式定义留一元素交叉验证 (LOEO)：对于数据集中观察到的周期表子集中的每个元素 $e$，将测试折设置为 $\\mathcal{D}^{\\text{test}}_{e} = \\{(x,y): e \\in \\mathcal{E}(x)\\}$，训练折设置为其补集，并计算诸如平均绝对误差 $\\mathrm{MAE} = \\hat{R}_{\\text{test}}(f)$ 等指标。通过以下方式定义留一原型交叉验证 (LOPO)：对于每个原型 $p \\in \\mathcal{P}$，将测试折设置为 $\\mathcal{D}^{\\text{test}}_{p} = \\{(x,y): \\mathrm{proto}(x)=p\\}$，并在其补集上进行训练。作为随机划分的基准，首先按精确的简约化学式或结构标识符进行分组，并保持分组完整，以避免划分间的近重复泄漏。如果模型依赖于在 $P_{\\text{train}}$ 下学习到的特定于元素或原型的相关性，那么在 LOEO 和 LOPO 下，测试分布 $P_{\\text{test}}$ 在元素或原型维度上的支撑集将与 $P_{\\text{train}}$ 的不相交，因此与分组随机划分相比，$R_{P_{\\text{test}}}(f)$ 会显著增加，从而揭示随机 i.i.d. 划分可能隐藏的失效模式（例如，词汇外元素嵌入或原型记忆）。\n\nB. 使用带重要性加权的 $k$ 折随机划分，在损失函数中增加稀有元素的权重，即最小化 $\\sum_{(x,y)\\in S} w(x)\\,\\ell(f(x),y)$，其中 $w(x) \\propto 1/\\pi(\\mathcal{E}(x))$，$\\pi$ 是经验元素频率。因为稀有元素得到了强调，所以该方案下的性能可以测试对未见元素的外推能力；类似地，原型稀有度加权可以测试对未见原型的外推能力。\n\nC. 通过将包含选定元素 $e$ 的所有化合物同时保留在训练集和测试集中来定义留一元素交叉验证，但在测试时屏蔽元素级嵌入中 $e$ 的条目，以便模型看不到它。由于模型必须在没有被屏蔽的元素通道的情况下进行推断，因此这测试了对新元素的外推能力。对于原型，在测试时屏蔽原型特征，同时将所有原型保留在训练和测试中。\n\nD. 对于原型，执行分层 $k$ 折交叉验证，以使每个折的训练集和测试集都保持相同的原型分布 $\\mathrm{proto}(x)$。这确保了公平性，并测试了原型外推能力，因为原型的比例在不同划分中保持不变。对于元素，执行随机划分，因为原型分层已经控制了结构相关性。\n\n选择唯一的最佳选项。", "solution": "首先将对问题陈述的科学性和逻辑完整性进行验证。\n\n### 第 1 步：提取已知条件\n- **任务：** 构建一个监督回归模型 $f_{\\theta}$，用于预测无机晶体化合物的每原子生成能 $y \\in \\mathbb{R}$。\n- **输入特征：** 一个输入向量 $x$，包含成分描述符、元素级嵌入和晶体结构原型标签 $\\mathrm{proto}(x) \\in \\mathcal{P}$。\n- **数据分布：** 一个数据生成分布 $P(X,Y)$。\n- **训练：** 在从 $P(X,Y)$ 中独立同分布抽取的训练集上进行经验风险最小化 (ERM)。\n- **损失函数：** 绝对误差，$\\ell(\\hat{y},y) = |\\hat{y}-y|$。\n- **经验风险：** 在集合 $S$ 上，$\\hat{R}_{S}(f) = \\frac{1}{|S|} \\sum_{(x_i,y_i)\\in S} \\ell\\big(f(x_i),y_i\\big)$。\n- **总体风险：** 在分布 $Q$ 下，$R_{Q}(f) = \\mathbb{E}_{(X,Y)\\sim Q}\\big[\\ell\\big(f(X),Y\\big)\\big]$。\n- **标准评估：** 对于随机划分，$P_{\\text{train}}(X,Y) \\approx P_{\\text{test}}(X,Y)$，且 $\\hat{R}_{\\text{test}}(f)$ 近似于 $R_{P_{\\text{test}}}(f)$。\n- **主要目标：** 评估对以下情况的分布外 (OOD) 外推性能：\n    1.  包含训练期间未见元素的成分。设 $\\mathcal{E}(x)$ 为 $x$ 中的元素集合。\n    2.  属于训练期间未见原型的结构。\n- **假设：** 随机划分下的低误差可能是由于模型记忆了训练集和测试集中都存在的特定于元素或原型的相关性（目标泄漏）。\n- **问题：** 确定哪种评估策略能正确测试这些外推能力，并揭示随机划分可能隐藏的失效模式。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据既定标准对问题陈述进行评估：\n- **科学上合理：** 该问题是材料信息学中的一个典型且关键的任务。预测生成能、使用指定的特征以及训练回归模型都是标准做法。分布内 (i.i.d.) 和分布外 (OOD) 泛化之间的区别是机器学习中一个基础且前沿的主题，此处应用于现实的科学背景。\n- **适定性：** 问题阐述清晰。它定义了目标（测试外推能力）、背景（材料属性预测）和特定的 OOD 挑战（新元素、新原型）。它要求一种评估方法，对此在机器学习文献中存在一个正确的、标准的解决方案。\n- **客观性：** 语言正式且无歧义。所有术语，如 ERM、风险和 i.i.d.，都是统计学习理论中的标准术语。问题不含主观论断。\n\n该问题未表现出任何无效性标志。它不是科学上不合理、不可形式化、不完整、不切实际、不适定或琐碎的。它提出了一个关于科学领域中鲁棒模型评估的有意义且不琐碎的问题。\n\n### 第 3 步：结论与行动\n问题陈述是**有效的**。将推导解决方案。\n\n### 推导\n问题的核心在于机器学习背景下内插和外推之间的区别。\n在独立同分布 (i.i.d.) 数据集上使用随机划分的标准交叉验证测试的是模型的内插能力。在这种情况下，训练分布 $P_{\\text{train}}$ 和测试分布 $P_{\\text{test}}$ 被假定为相同 ($P_{\\text{train}} = P_{\\text{test}} = P$)。一个测试样本 $(x, y)$ 是新的，但它的特征（例如 $x$ 中的元素和结构原型）极有可能已经在训练集中的其他样本里被观察到。模型的任务本质上是为熟悉组件的新组合预测一个值。\n\n相比之下，外推要求模型能够泛化到与训练数据有系统性差异的输入。这构成了一个分布外 (OOD) 挑战，其中 $P_{\\text{test}} \\neq P_{\\text{train}}$。问题指定了两个这样的 OOD 挑战：\n1.  **对新元素的泛化：** 模型必须预测一个包含训练集中完全未出现过的元素的化合物的生成能。\n2.  **对新原型的泛化：** 模型必须预测一个其晶体结构原型完全未在训练集中出现过的化合物的生成能。\n\n为了设计一个能测试这些能力的评估，必须构建这样的训练-测试划分：测试集包含特定元素（或原型）的实例，而训练集保证不包含该相同元素（或原型）的任何实例。这会沿着感兴趣的特征维度强制产生一个分布偏移，$P_{\\text{test}} \\neq P_{\\text{train}}$。\n\n对此的标准方法是**留一分组交叉验证**。\n- **对于元素：** 这被称为留一元素交叉验证 (LOEO)。对于完整数据集中存在的每个元素 $e$，创建一个折，其中测试集包含所有含元素 $e$ 的化合物，而训练集包含所有*不*含元素 $e$ 的化合物。模型在后者上训练，在前者上评估。与随机划分评估相比，在这种设置下的高误差表明，模型严重依赖于在训练期间见过元素 $e$，并且无法泛化其关于周期表的知识来推断 $e$ 的行为。\n- **对于原型：** 这被称为留一原型交叉验证 (LOPO)。逻辑是相同的。对于每个原型 $p$，测试集由所有具有该原型的结构组成，而训练集则不包含任何该原型。高误差表明模型仅仅记忆了标签 $p$ 和目标值之间的相关性，而不是从定义该原型的几何或拓扑特征中学习潜在的结构-性质关系。\n\n一个合适的比较基准是一个鲁棒的 i.i.d. 评估。简单的随机划分容易受到“近重复”泄漏的影响（例如，非常相似的成分最终出现在训练集和测试集中）。一个更好的基准是**分组随机划分**，即首先按化合物或结构对数据进行分组，并将属于同一组的所有样本一起保留在训练集或测试集中。这可以防止模型在训练数据的细微变体上进行测试。\n\n通过将 LOEO/LOPO 划分上的性能与分组随机划分上的性能进行比较，可以量化模型的外推能力。一个小的性能下降表明良好的泛化能力，而一个大的下降则表示外推失败。\n\n### 逐项分析\n- **A. 通过以下方式定义留一元素交叉验证 (LOEO)...**\n  该选项精确地描述了正确的留一分组方法。对于元素，它定义了 LOEO 测试折 $\\mathcal{D}^{\\text{test}}_{e} = \\{(x,y): e \\in \\mathcal{E}(x)\\}$ 并在其补集上训练。对于原型，它定义了 LOPO 测试折 $\\mathcal{D}^{\\text{test}}_{p} = \\{(x,y): \\mathrm{proto}(x)=p\\}$ 并在其补集上训练。它正确地提出使用分组随机划分作为强基准，以避免近重复泄漏。其基本原理也完全合理：它指出这些划分在感兴趣的维度上造成了 $P_{\\text{train}}$ 和 $P_{\\text{test}}$ 之间不相交的支撑集，并且误差（$R_{P_{\\text{test}}}(f)$）的大幅增加揭示了外推失败，如词汇外元素嵌入或原型记忆，而这些是随机 i.i.d. 划分可能隐藏的。这与推导完全一致。\n  **结论：正确。**\n\n- **B. 使用带重要性加权的 $k$ 折随机划分...**\n  该选项建议修改训练目标以增加稀有元素的权重，通过最小化 $\\sum w(x)\\,\\ell(f(x),y)$。这种技术解决了 i.i.d. 框架内的数据不平衡问题。它有助于模型从它*确实*看到的少数稀有元素样本中更好地学习，但它并不测试对它*从未*见过的元素的外推能力。训练集仍然包含所有元素，因此任务不是问题陈述所要求的那种 OOD 任务。该选项混淆了从稀疏数据中学习与对外推到新数据类别。\n  **结论：不正确。**\n\n- **C. 通过将包含选定元素 $e$ 的所有化合物同时保留在训练集和测试集中来定义留一元素交叉验证...**\n  该选项存在根本性缺陷。将测试数据包含在训练集中构成了严重的数据泄漏，并使任何由此产生的性能指标无效。模型可以通过简单地记忆测试集样本来达到零误差。此外，在测试时屏蔽特征评估的是模型对缺失数据的鲁棒性，这与外推到全新的、未见的特征值（例如，一个新元素）是不同的任务。这种方法没有正确地测试问题中定义的外推能力。\n  **结论：不正确。**\n\n- **D. 对于原型，执行分层 $k$ 折交叉验证...**\n  该选项提出了与要求完全相反的方法。分层交叉验证确保了特征（在此是原型）的分布在训练集和测试集中是*相同*的。这是一种*强制*执行 i.i.d. 假设并获得模型内插性能稳定估计的技术。它被明确设计用来*防止*测试外推能力所需的那种分布偏移。因此，所提供的基本原理完全是颠倒的。对元素使用随机划分同样也只测试 i.i.d. 性能。\n  **结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "2479777"}, {"introduction": "实际的材料设计往往需要在多个相互冲突的目标之间进行权衡，例如同时追求高稳定性和高催化活性，这使得优化过程成为一个多目标问题。本练习介绍了一个关键的性能指标——超体积（Hypervolume）[@problem_id:2479712]，它能够将一组最优折衷解（即帕累托前沿）的质量量化为一个单一数值。掌握这一工具，你便能客观地比较不同筛选策略或模型所产生的候选材料集的优劣。", "problem": "在用于材料发现的多目标高通量筛选（HTS）中，机器学习模型通过平衡相互冲突的目标来指导候选材料的选择。考虑两个归一化、无量纲的目标 $f_1$ 和 $f_2$ 的双目标最小化问题，例如预测的合成难度和预测的环境负担。对于模型建议的候选有限集 $S$，其全局质量可以通过超体积（HV）指标来评估，该指标定义为目标空间中某个区域的二维勒贝格测度，该区域（i）在最小化条件下被 $S$ 中至少一个点弱支配，并且（ii）由一个选定的参考点 $r=(r_1,r_2)$ 界定，该参考点在分量上不优于 $S$ 中的所有点。\n\n从最小化条件下的帕累托支配和 $\\mathbb{R}^2$ 中集合的勒贝格测度的核心定义出发，完成以下任务：\n\n1) 在双目标和有限非支配集 $S=\\{(x_i,y_i)\\}_{i=1}^m$ 的特殊情况下，推导超体积（HV）指标的闭式表达式。该集合中的点按 $x_i$ 严格递增排序时，对应的 $y_i$ 严格递减，且参考点 $r=(r_1,r_2)$ 满足对所有 $i$ 都有 $x_i \\le r_1$ 和 $y_i \\le r_2$。你的推导必须从第一性原理开始：弱帕累托支配的定义以及 $\\mathbb{R}^2$ 中轴对齐矩形并集的面积（勒贝格测度）。\n\n2) 使用你推导的表达式，计算两个非支配点集的超体积（HV），这两个点集总结了针对同一参考点 $r=(3.0,3.0)$ 的两次连续模型引导的HTS活动：\n- 基准集 $S_0=\\{(1.0,2.0),\\,(1.6,1.2),\\,(2.3,0.95)\\}$。\n- 改进集 $S_1=\\{(0.9,1.9),\\,(1.4,1.1),\\,(2.0,0.9)\\}$。\n\n3) 报告超体积（HV）的改进量，定义为 $HV(S_1;r)-HV(S_0;r)$，以单个实数形式表示。将你的最终答案表示为一个无量纲数，并将最终数值答案四舍五入到四位有效数字。", "solution": "该问题要求计算点集 $S = \\{(x_i, y_i)\\}_{i=1}^m$ 相对于参考点 $r = (r_1, r_2)$ 的超体积。目标是最小化。根据定义，超体积是目标空间中被 $S$ 中至少一个点弱支配并由参考点 $r$ 界定的区域的二维勒贝格测度（面积）。鉴于对所有 $i$ 都有 $x_i \\le r_1$ 和 $y_i \\le r_2$，该区域在数学上表示为：\n$$ \\mathcal{A} = \\bigcup_{i=1}^m [x_i, r_1] \\times [y_i, r_2] $$\n超体积是该集合的测度，即 $HV(S;r) = \\mu(\\mathcal{A})$。\n\n**第1部分：超体积（HV）表达式的推导**\n\n为了推导该测度的闭式表达式，我们利用集合 $S$ 的给定性质。点集 $S=\\{(x_i, y_i)\\}_{i=1}^m$ 已按 $x_i$ 严格递增排序。由于该集合是非支配的，这也意味着对应的 $y_i$ 严格递减：$y_1 > y_2 > \\dots > y_m$。\n\n我们可以通过将由参考点 $r$ 和帕累托前沿 $S$ 界定的总区域分解为一系列不相交的水平矩形条带，来计算其面积。我们将 $y$ 轴从 $r_2$ 向下划分，以 $S$ 中各点的 $y$ 坐标为界。为方便起见，我们定义 $y_0 = r_2$。\n\n考虑由 $y=y_{i-1}$ 和 $y=y_i$ 界定的第 $i$ 个水平条带（对于 $i=1, \\dots, m$）。对于此条带内的任何点 $(x,y)$，要被 $S$ 中的点弱支配，必须存在某个 $s_j = (x_j, y_j) \\in S$ 使得 $x \\ge x_j$ 和 $y \\ge y_j$。\n在 $y \\in [y_i, y_{i-1}]$ 这个区间内，条件 $y \\ge y_j$ 仅对 $j \\ge i$ 成立。因此，为了被支配，点 $(x,y)$ 的 $x$ 坐标必须满足 $x \\ge \\min\\{x_j | j \\ge i\\}$。由于排序性质 $x_i  x_{i+1}  \\dots  x_m$，该最小值为 $x_i$。\n\n因此，在第 $i$ 个水平条带中，被支配区域是矩形 $[x_i, r_1] \\times [y_i, y_{i-1}]$。这些矩形对于不同的 $i$ 是不相交的，并且它们的并集构成了整个超体积区域 $\\mathcal{A}$。\n\n第 $i$ 个矩形的面积为 $(r_1 - x_i) \\times (y_{i-1} - y_i)$。\n总超体积是所有这些不相交矩形面积的总和：\n$$ HV(S;r) = \\sum_{i=1}^{m} (r_1 - x_i)(y_{i-1} - y_i), \\quad \\text{其中 } y_0 = r_2 $$\n这个闭式表达式使我们能够直接计算超体积。\n\n**第2部分：超体积计算**\n\n参考点为 $r=(r_1,r_2)=(3.0,3.0)$。因此，$r_1=3.0$，$r_2=3.0$。我们设 $y_0 = r_2 = 3.0$。\n\n**对于基准集 $S_0=\\{(1.0,2.0),\\,(1.6,1.2),\\,(2.3,0.95)\\}$**：\n点按 $x$ 坐标排序。我们有：\n$s_1=(x_1,y_1)=(1.0, 2.0)$\n$s_2=(x_2,y_2)=(1.6, 1.2)$\n$s_3=(x_3,y_3)=(2.3, 0.95)$\n应用公式：\n$HV(S_0;r) = (r_1-x_1)(y_0-y_1) + (r_1-x_2)(y_1-y_2) + (r_1-x_3)(y_2-y_3)$\n$HV(S_0;r) = (3.0 - 1.0)(3.0 - 2.0) + (3.0 - 1.6)(2.0 - 1.2) + (3.0 - 2.3)(1.2 - 0.95)$\n$HV(S_0;r) = (2.0)(1.0) + (1.4)(0.8) + (0.7)(0.25)$\n$HV(S_0;r) = 2.0 + 1.12 + 0.175 = 3.295$\n\n**对于改进集 $S_1=\\{(0.9,1.9),\\,(1.4,1.1),\\,(2.0,0.9)\\}$**：\n点按 $x$ 坐标排序。我们有：\n$s'_1=(x'_1,y'_1)=(0.9, 1.9)$\n$s'_2=(x'_2,y'_2)=(1.4, 1.1)$\n$s'_3=(x'_3,y'_3)=(2.0, 0.9)$\n应用公式（其中 $y'_0 = r_2 = 3.0$）：\n$HV(S_1;r) = (r_1-x'_1)(y'_0-y'_1) + (r_1-x'_2)(y'_1-y'_2) + (r_1-x'_3)(y'_2-y'_3)$\n$HV(S_1;r) = (3.0 - 0.9)(3.0 - 1.9) + (3.0 - 1.4)(1.9 - 1.1) + (3.0 - 2.0)(1.1 - 0.9)$\n$HV(S_1;r) = (2.1)(1.1) + (1.6)(0.8) + (1.0)(0.2)$\n$HV(S_1;r) = 2.31 + 1.28 + 0.20 = 3.790$\n\n**第3部分：超体积改进量**\n\n超体积的改进量是两者之差：\n$HV(S_1;r) - HV(S_0;r) = 3.790 - 3.295 = 0.495$\n\n问题要求将答案四舍五入到四位有效数字。\n$0.4950$\n\n最终答案是 $0.4950$。", "answer": "$$\n\\boxed{0.4950}\n$$", "id": "2479712"}]}