## Applications and Interdisciplinary Connections

Having grasped the principles of what it means to wrong someone in their capacity as a knower, we can now embark on a journey to see these ideas in action. It is one thing to define an injustice in the abstract; it is quite another to witness its consequences etched into the fabric of our most critical institutions. You might be surprised to find that the subtle act of granting or withholding credibility is not a minor social foul, but a powerful force that shapes life and death decisions in the clinic, gets baked into the algorithms that govern our future, and can even rewrite our understanding of the past. In seeing how this single, powerful idea—epistemic injustice—manifests across so many different domains, we begin to appreciate a beautiful, if unsettling, unity in the way knowledge, power, and justice are intertwined.

### The Clinic: Where Testimony is a Matter of Life and Death

There is perhaps no place where being believed is more immediately consequential than in a hospital. When a person reports a symptom, they are offering testimony about their own internal world, a world to which they have unique access. The proper uptake of this testimony is the bedrock of medical diagnosis and care. Yet, it is here, in these high-stakes encounters, that testimonial injustice often appears in its starkest forms.

Consider an Indigenous patient arriving in an emergency department describing acute chest pain. The clinician, perhaps influenced by a harmful stereotype about certain groups being prone to "drug-seeking" or "anxiety," dismisses the patient's testimony. The life-threatening possibility of a heart attack is set aside in favor of a psychological explanation, and a potentially life-saving [electrocardiogram](@entry_id:153078) is denied [@problem_id:4986411]. This is not a simple misdiagnosis; it is a failure of listening rooted in prejudice. The patient is wronged not just by receiving poor medical care, but by being treated as an unreliable narrator of their own suffering. The same tragic pattern can be seen when a patient with a history of substance use disorder describes severe withdrawal symptoms and is labeled "drug-seeking" instead of being offered life-saving treatment [@problem_id:4848719], or when a patient with a psychosis diagnosis reports debilitating side effects from a medication, only to have their testimony dismissed as "manipulative" or a symptom of their illness [@problem_id:4747502].

This is testimonial injustice: a credibility deficit assigned due to the speaker's identity. But sometimes the problem is not that the clinician disbelieves the patient, but that the entire medical system lacks the concepts to understand what is being said. This is its sibling concept, *hermeneutical injustice*. Imagine a clinic whose framework is built exclusively around abstinence-only treatment for addiction. When a patient tries to discuss their need for harm reduction—like clean needles or overdose prevention counseling—the staff may not have the shared language to frame these as legitimate health goals. The patient's requests are misinterpreted as "noncompliance" because the system has a conceptual blind spot [@problem_id:4848719]. Similarly, when a psychiatric evaluation system like the DSM and its corresponding electronic health record (EHR) templates have no categories for culturally or spiritually meaningful experiences, a patient's attempt to describe their reality in those terms can be rendered unintelligible, pathologized, or ignored [@problem_id:4747502].

These injustices are compounded for those who live at the intersection of multiple marginalized identities. For an elderly immigrant woman with mild cognitive impairment, prejudices about age, cognitive ability, and language can converge to disastrous effect. When she reports that her son is taking her money, a nurse might discount her testimony as "confusion." The structural lack of a qualified medical interpreter or a culturally adapted screening tool for elder abuse means she is not given the resources to make her experience understood. Both a testimonial and a hermeneutical wrong occur at once, leaving her vulnerable and potentially silencing a legally mandated report to Adult Protective Services [@problem_id:4859767]. These are not just ethical failings; they can have profound legal consequences, as a capacity assessment tainted by such injustices can be ruled unlawful, violating statutes that presume a patient's capacity and demand that all practical steps be taken to support their decision-making [@problem_id:4473083].

### The Digital Ghost in the Machine: Epistemic Injustice in the Age of AI

One might hope that computers, free from human prejudice, could offer a more objective way forward. The reality, however, is that artificial intelligence often becomes a powerful amplifier for the very injustices we seek to escape. The reason is simple: AI models learn from data, and clinical data is, in large part, a fossil record of past human decisions.

Let's return to the emergency department. A hospital implements an AI tool to help prioritize which patients get pain medication. The tool is trained on years of EHR data. What does this data contain? It contains the patient's self-reported pain score, say on a scale from 0 to 10. But it also contains the clinician's decisions: whether they documented the pain as "severe," and whether they actually ordered analgesia.

Now, if clinicians have historically been applying a credibility deficit to patients from a stereotyped group ($G=1$), they will have been systematically less likely to order analgesia for them than for patients from a comparison group ($G=0$), *even when they report the exact same level of pain and have similar clinical conditions*. We can see this by comparing the probability of receiving analgesia for the two groups, holding the pain report $R$ and other clinical factors $S$ constant. If $P(A=1 \mid R, S, G=1)  P(A=1 \mid R, S, G=0)$, we have found a statistical signature of testimonial injustice in the data [@problem_id:4415701].

When an AI is trained on this data, it learns this unjust pattern as a rule. It learns that, for a given level of reported pain, the "correct" output is to be less likely to recommend treatment for a person from group $G=1$. The AI doesn't have a prejudiced mind, but it perfectly reproduces the behavior that arises from one. The human bias becomes a digital ghost in the machine.

Worse still, this can create a pernicious feedback loop. A clinician sees the AI's recommendation (which is already biased) and is influenced by it, making them even less likely to treat the patient from the stereotyped group. This new, biased decision is recorded in the EHR and becomes the training data for the next version of the AI, making it even more biased [@problem_id:4421141]. The system becomes a self-reinforcing engine of inequity. Naive technical fixes, like simply removing the patient's group identity from the model's input, fail because the AI can easily learn proxies for that identity from other data points. The injustice is not in one variable; it is woven into the relationships between all the variables.

### Rewriting the Past, Building the Future: Beyond the Clinic

The long shadow of epistemic injustice extends far beyond the walls of the clinic and the code of an algorithm. It shapes our very understanding of the past and points the way toward building a more just future.

What does a 19th-century nurse's notebook have in common with a 21st-century AI? Both are archives of knowledge, and both can be distorted by the same epistemic forces. When a historian studies the history of women in medicine, they are at the mercy of the evidentiary record. If, for a century, archivists and male physicians systematically discounted the testimony of women practitioners—summarizing their notes while quoting men verbatim, filing their clinical observations as "ancillary"—then the historical record itself is skewed. Testimonial injustice has effectively edited the past, diminishing the perceived contributions of women knowers. Likewise, if the medical vocabulary of the era lacked a concept for postpartum depression, women's letters describing their suffering might be filed away under "domestic troubles." This hermeneutical gap renders a whole category of experience invisible to future historians, creating a silence in the archive where knowledge should be [@problem_id:4773298].

So what is to be done? If these injustices are so deeply embedded in our systems and practices, how can we fight back? The answer, it turns out, is not just to tell individuals to "listen better." The answer is to redesign the systems that decide who gets to speak, who gets believed, and who helps create the concepts we use to understand our world.

One powerful approach is found in the world of research, with a method called Community-Based Participatory Research (CBPR). Imagine a team trying to design a screening tool for social determinants of health, like food or housing insecurity, for a diverse pediatric clinic. A pilot shows the tool isn't working well for Spanish-speaking caregivers. Instead of "experts" trying to fix it from afar, CBPR brings the caregivers to the table as equal partners. By forming a remunerated caregiver advisory board with shared governance, the team can co-create a tool that uses locally meaningful language, addressing hermeneutical injustice. By granting caregivers epistemic authority over how to define and measure their own experiences, the process directly counters testimonial injustice. The result is not only a more just process, but a more scientifically valid tool [@problem_id:5206084].

This principle can be scaled up to the level of hospital policy. To truly reshape the ethics of expertise, we must democratize it. Instead of a clinical policy committee made up solely of clinicians, imagine a "co-production" committee where patient representatives from marginalized communities have equal voting rights. Imagine a system where the reasoning behind decisions is public, and where communities have a formal pathway to challenge policies using their own lived experience as evidence [@problem_id:4866459]. This is not merely about consultation; it is about a fundamental redistribution of power. It is about acknowledging that the patient is not just a subject of care, but an expert in their own right.

From the quiet dismissal of a single patient's testimony to the structural biases of our institutions, we see a common thread. Justice is not merely about how we distribute resources, but about how we distribute credibility and understanding. To build a healthier and more equitable world, we must become better architects of our epistemic systems, ensuring that every voice has the power not just to speak, but to be truly heard.