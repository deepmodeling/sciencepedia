## Introduction
In modern software development, understanding the intricate web of interactions within a large codebase is a monumental challenge. How can we reason about a program's behavior without running it for every possible input? The answer lies in [static analysis](@entry_id:755368), and one of its cornerstone tools is the [call graph](@entry_id:747097)—a blueprint of how functions communicate. This article demystifies a specific, powerful variant: the **may-[call graph](@entry_id:747097)**. It addresses the crucial gap between a program's static source code and its dynamic runtime behavior, revealing how a map of *possible* calls enables profound insights. We will first delve into the principles and mechanisms behind constructing this map, distinguishing between static possibility and dynamic reality. Subsequently, we will explore the diverse applications of this blueprint, from optimizing performance and finding bugs to fortifying software against security threats.

## Principles and Mechanisms

Imagine you have a detailed map of a country's entire road network. This map shows every city and every single road that connects them, from the grandest superhighways to the most obscure country lanes. This map is a static, complete picture of all possible journeys. Now, think of an actual trip you take from one city to another. This trip is a dynamic event—a specific sequence of roads you travel. You don't take every road on the map; you only follow one particular path.

This is the most crucial distinction to grasp when we talk about a program's structure: the difference between the **map** and the **territory**. The program's source code is like the map, and a **may-[call graph](@entry_id:747097)** is the most faithful representation of that map. The program's actual execution on a given input is the trip, a dynamic journey through the landscape described by the map.

### A Tale of Two Worlds: The Static Map and the Dynamic Journey

A computer program is a collection of functions, our "cities." When one function, say `main`, calls another function, `calculate`, we can think of it as a road leading from `main` to `calculate`. A **static [call graph](@entry_id:747097)** is a complete map of these roads. For every function in the program, we draw a point, and if function `A` contains code that *might* call function `B`, we draw a directed arrow—a one-way street—from `A` to `B`.

The beauty of this map is that it tells us what is *possible*. But it doesn't tell us what *will* happen in any single run of the program. A simple piece of code can create a fascinating divergence between the static map and the dynamic journey. Consider a single function `f` that does nothing but call itself, with no way to stop—an infinite recursion [@problem_id:3237183].

-   The **static map** is absurdly simple: one city, `f`, with a single road looping back onto itself. It's a roundabout.
-   The **dynamic journey**, however, is an infinite highway stretching to the horizon. The first call to `f` is the entry ramp. This call instance then calls `f` again, creating a second, distinct instance, and so on, forever. The execution trace is a non-repeating, endless path: $f_0 \to f_1 \to f_2 \to \dots$.

This reveals a profound truth: the static [call graph](@entry_id:747097) is not a Directed Acyclic Graph (DAG) because the [self-loop](@entry_id:274670) is a cycle. Yet, the graph of what actually happens during execution *is* acyclic! Each call is a new, unique event in time. The machine's **call stack**, which keeps track of active calls, grows deeper and deeper with each step down this infinite road. The maximum depth of this stack is a dynamic property, a feature of the journey, not the map [@problem_id:3274453]. A map showing a cycle only tells us that long or even infinite journeys are *possible*; it doesn't describe the journey itself.

### Drawing the Map: Certainty, Possibility, and Soundness

How do we, or more importantly, how does a compiler, draw this map? For the simplest cases, it's like reading road signs. If the compiler sees a line `B();` inside the body of function `A()`, it adds an edge $A \to B$ to its graph. By scanning the entire program, it can build up a list of all these direct connections [@problem_id:3673768].

But what kind of map are we building? Are we interested only in the guaranteed superhighways, or in every last footpath? This choice leads to two different kinds of graphs [@problem_id:3625857]:

-   A **must-[call graph](@entry_id:747097)** includes an edge $A \to B$ only if the call from `A` to `B` is *guaranteed* to happen every single time `A` is executed. This is a map of certainty. It's useful for a compiler to gauge the "profitability" of an optimization. If a call is guaranteed, the benefit of optimizing it will always be realized.

-   A **may-[call graph](@entry_id:747097)**, the focus of our discussion, includes an edge $A \to B$ if the call is *possible* on at least one execution path. This is a map of possibility. Its defining characteristic is **soundness**, which in this context means it is an **over-approximation**. A sound may-[call graph](@entry_id:747097) must contain every call that could ever occur at runtime. It can contain extra edges for calls that are actually impossible, but it must *never* miss a possible one.

Why is this so important? Imagine a compiler is trying to prove that a program is safe. It uses the may-[call graph](@entry_id:747097) to see all functions that could possibly be called. If the map is missing a road—if it's **unsound**—the compiler might incorrectly conclude a dangerous operation is unreachable when it's not. For safety, we must have a complete map of all possibilities, even if it includes some "phantom roads" that can never be traveled. From this, a fundamental relationship emerges: the set of "must" edges is always a subset of the set of "may" edges ($E_{\text{must}} \subseteq E_{\text{may}}$) [@problem_id:3625857].

### The Fog of War: Navigating Indirect Calls

Drawing a map of direct calls is straightforward. The real challenge—and where the true artistry of [compiler design](@entry_id:271989) shines—is in navigating the "fog of war" created by **[indirect calls](@entry_id:750609)**. This happens in languages like C/C++ with function pointers, or in object-oriented languages with virtual methods. The code doesn't say "call `B`." It says "call the function whose address is stored in this variable `p`."

The destination is no longer written on the signpost; it's written on a slip of paper held by the variable `p`. To draw our map, we must figure out all the possible addresses that could end up on that slip of paper. This is the domain of **[points-to analysis](@entry_id:753542)**.

Think of this analysis as a detective mapping a network of spies [@problem_id:3625868]. The detective starts with a few known facts, like "variable `p` is initially given the address of function `f`." The map starts with $p \to \{f\}$. Then, the detective finds more clues:
1.  A note says, "variable `q` should be a copy of `p`." The detective dutifully updates the map: $q \to \{f\}$.
2.  Another note says, "if `q` can point to `f`, then `p` might also be updated to point to `g`." Since the map for `q` contains `f`, the detective adds `g` to `p`'s set: $p \to \{f, g\}$.
3.  This new fact about `p` might unlock other clues elsewhere!

The detective must repeatedly sweep through all the clues, propagating new information until no new connections can be found. This iterative process of reaching a stable state is known as finding a **fixed point** [@problem_id:3625934]. The analysis begins with an empty map (the bottom of a lattice) and continually adds edges based on the program's rules. Because the set of all possible functions is finite, this process is guaranteed to terminate, leaving us with a sound over-approximation of where every pointer could possibly point.

This same principle applies to object-oriented languages. A call like `shape.draw()` is an indirect call. Which `draw` method is invoked? It depends on the actual runtime type of the `shape` object. A simple analysis called **Class Hierarchy Analysis (CHA)** makes a coarse guess: `shape` could be any class that inherits from the declared `Shape` type. But a more precise [points-to analysis](@entry_id:753542) can narrow down the set of actual types the `shape` variable might hold at that specific point in the code, allowing us to prune impossible targets from our may-[call graph](@entry_id:747097) [@problem_id:3625937].

### The Payoff: How a Better Map Sharpens Our Vision

Is this monumental effort to build a precise may-[call graph](@entry_id:747097) just an academic exercise? Far from it. A more precise map allows a compiler to understand a program with stunning clarity, enabling optimizations that would otherwise be impossible.

Consider a beautiful example from [@problem_id:3647952]. A program has an indirect function call `p(x)`. A crude [call graph](@entry_id:747097) analysis (like CHA or a simple [reachability](@entry_id:271693) analysis) sees that `p` could point to either function `f` (which always returns 41) or function `g` (which returns its input). When the compiler tries to figure out the result of `p(1)`, it sees two possibilities: the result could be `f(1)=41` or `g(1)=1`. Since it can't decide between them, it must give up and declare the result "unknown" (represented as $\top$ in analysis lattices).

Now, watch what happens with a more powerful, [flow-sensitive analysis](@entry_id:749460). It notices that the branch of code that would assign `g` to `p` is actually unreachable. It proves this path is a "phantom road." Its refined may-[call graph](@entry_id:747097) shows only one possible target for `p`: the function `f`. With this sharpened vision, the compiler now knows with certainty that the call `p(1)` will be `f(1)`, which evaluates to `41`. It can then perform further calculations, deducing that the program's final result is the constant `42`. A better map didn't just clean up a diagram; it transformed an unknown quantity into a hard fact.

### Frontiers and Trade-offs: Reflection and Reality

The quest for a perfect map has its own frontiers and practical limits. What happens when a program can invent its destinations on the fly? Some languages support **reflection**, allowing code to construct a method's name from a string at runtime, like `invoke("m" + "2")`. To map this, the compiler must become a linguist, analyzing all possible string values that could be created [@problem_id:3625850]. This is further complicated by **dynamic class loading**. What if the string refers to a method in a class that doesn't even exist when the analysis is run? To remain sound, the analysis must either assume a **closed world** (no new code will be loaded) or conservatively add an edge to a generic "unknown code" node, acknowledging the limits of its knowledge.

Finally, [static analysis](@entry_id:755368) is fundamentally about possibility. It produces a map of all roads, but tells us nothing about the traffic. This is where the world of [static analysis](@entry_id:755368) beautifully intersects with the dynamic world of **profiling**. By running the program on typical inputs, we can create a "heat map," annotating each edge in our may-[call graph](@entry_id:747097) with its observed execution frequency [@problem_id:3625916].

We cannot use this heat map to prove a cold road is unused—a different input might send a flood of traffic down it. So, for correctness-critical decisions, we must still rely on the complete, sound may-[call graph](@entry_id:747097). But for heuristic decisions, like where to focus optimization effort, the profile is invaluable. A compiler can use this hybrid map to spend its time optimizing the "hot" superhighways where performance gains will be most impactful. This elegant fusion of static possibility and dynamic probability is at the heart of modern, high-performance compilers. The may-[call graph](@entry_id:747097) is not just a map; it is the essential blueprint for understanding, optimizing, and securing the software that powers our world.