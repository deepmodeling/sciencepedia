{"hands_on_practices": [{"introduction": "在开始任何激动人心的基因发现之旅前，我们必须先确保数据的纯净与可靠。本练习将你置于GWAS分析师的角色，面对一份真实的（尽管是假设的）原始数据集，挑战你根据数据的经验分布来制定一套严谨的质量控制（QC）方案。通过这个实践，你将学会如何在数据保留与伪影去除之间做出明智的权衡，这是确保下游分析结果有效性的关键第一步。[@problem_id:2830645]", "problem": "您获得一个全基因组关联研究 (GWAS) 数据集，其中包含 $n = 12{,}000$ 名经过基因分型的个体（病例 $= 5{,}000$，对照 $= 7{,}000$）和 $m = 700{,}000$ 个常染色体单核苷酸多态性 (SNPs)，这些数据是在标准芯片聚类和基因型检出后获得的。您计划使用常见的GWAS指标进行关联分析前的质量控制 (QC)：个体基因型检出率和缺失率、SNP基因型检出率和缺失率、常染色体杂合率、基于X染色体的性别推断、亲缘关系以及哈迪-温伯格平衡 (HWE)。为具体起见，假设从原始数据中得出以下经验性摘要：\n\n- 个体基因型缺失率（未检出基因型的比例）主峰值接近 $0.003$，第 $95$ 百分位数为 $0.012$，并有一个长右尾延伸至 $0.12$。另有一个约 $150$ 名个体的次级聚类，其缺失率在 $0.06$ 到 $0.10$ 之间。\n- SNP基因型缺失率峰值接近 $0.002$，第 $95$ 百分位数为 $0.015$，并有一个长尾延伸至 $0.25$。在 $0.06$ 附近有一个次峰，涉及约 $12{,}000$ 个SNP。\n- 常染色体杂合率，在一个包含 $100{,}000$ 个近似独立SNP的连锁不平衡 (LD) 剪枝集上计算，近似呈正态分布，均值为 $0.315$，标准差为 $0.012$。在 $0.36$（约 $30$ 个个体）和 $0.28$（约 $20$ 个个体）处存在离群聚类。\n- 使用X染色体非拟常染色体区近交系数 ($F_X$) 进行的X染色体性别推断显示，报告为男性的个体 ($n \\approx 5{,}800$) 的 $F_X$ 分布均值约为 $0.95$，标准差为 $0.05$；报告为女性的个体 ($n \\approx 6{,}200$) 的 $F_X$ 分布均值约为 $0.02$，标准差为 $0.03$。约有 $40$ 名报告为女性的个体其 $F_X > 0.85$，以及 $25$ 名报告为男性的个体其 $F_X < 0.15$。\n- 通过相同源 (IBD) 比例 $\\hat{\\pi}$ 估计的成对亲缘关系显示，约有 $60$ 对重复样本或同卵 (MZ) 双胞胎其 $\\hat{\\pi} > 0.98$， $220$ 对推定的一级亲属其 $\\hat{\\pi} \\in [0.40, 0.60]$，以及 $300$ 对推定的二级亲属其 $\\hat{\\pi} \\in [0.18, 0.25]$。其余配对的 $\\hat{\\pi} < 0.05$。\n- 在对照组中计算的HWE精确检验 $p$ 值显示，其分布接近均匀分布，但小 $p$ 值富集：约有 $25{,}000$ 个SNP的 $p < 10^{-4}$，以及 $1{,}200$ 个SNP的 $p < 10^{-6}$。$p < 10^{-6}$ 的SNP富集于较高的缺失率（缺失率中位数约为 $0.06$）。\n\n定义：个体基因型检出率是指单个个体在所有SNP中非缺失基因型检出的比例；SNP基因型检出率是指单个SNP在所有个体中非缺失基因型检出的比例。常染色体杂合率是指单个个体在一组剪枝后的常染色体SNP中杂合基因型的比例。X染色体近交系数 $F_X$ 对于男性（半合子）接近 $1$，对于具有典型二倍体X基因型的女性则接近 $0$。IBD比例 $\\hat{\\pi}$ 是一对个体间基因组IBD共享部分的估计比例，对于重复样本/同卵双胞胎，其典型期望值接近 $1.0$，一级亲属为 $0.5$，二级亲属为 $0.25$。在哈迪-温伯格平衡下，给定等位基因频率 $p$ 和 $q = 1 - p$，基因型频率满足 $p^2$、$2pq$、$q^2$；在大型远缘繁殖和随机交配的群体中，HWE检验的 $p$ 值在零假设下近似呈均匀分布。\n\n您必须选择一个QC方案，该方案既能正确定义这些指标，又能设定在保留高质量数据与去除可能的人为误差之间取得平衡的阈值，并且仅使用上述经验性摘要和GWAS QC的基本原则。哪个选项最能达到这个目标？\n\nA. 个体：如果缺失率 $> 0.02$（等同于检出率 $< 0.98$），则排除；SNP：如果缺失率 $> 0.02$（等同于检出率 $< 0.98$），则排除；杂合率：标记并排除在LD剪枝SNP上计算出的均值 $\\pm 3$ 倍标准差之外的常染色体离群值；性别检查：如果 $F_X \\ge 0.80$ 则判定为男性，如果 $F_X \\le 0.20$ 则判定为女性，并排除不一致或性别模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的样本中移除一个，以将亲缘关系限制在最多三级亲属；HWE：在对照组中计算，并排除 $p < 10^{-6}$ 的SNP。\n\nB. 个体：如果缺失率 $> 0.005$，则排除；SNP：如果缺失率 $> 0.005$，则排除；杂合率：排除在均值 $\\pm 2$ 倍标准差之外的个体；性别检查：通过 $F_X \\ge 0.50$ 判定为男性，通过 $F_X < 0.50$ 判定为女性；亲缘关系：仅使用 $\\hat{\\pi} > 0.35$ 移除重复样本和一级亲属；HWE：在所有样本中计算，并排除 $p < 10^{-4}$ 的SNP。\n\nC. 个体：如果缺失率 $> 0.08$，则排除；SNP：如果缺失率 $> 0.08$，则排除；杂合率：排除在均值 $\\pm 5$ 倍标准差之外的个体；性别检查：跳过基于X染色体的性别推断以最大化保留样本；亲缘关系：从每对 $\\hat{\\pi} > 0.10$ 的样本中移除一个；HWE：在对照组中计算，并排除 $p < 10^{-2}$ 的SNP。\n\nD. 个体：如果缺失率 $> 0.02$，则排除；SNP：当次要等位基因频率 (MAF) $\\ge 0.01$ 时，如果缺失率 $> 0.02$ 则排除，但当 MAF $< 0.01$ 时允许缺失率高达 $0.05$；杂合率：排除在均值 $\\pm 3$ 倍标准差之外的个体；性别检查：使用 $F_X \\ge 0.80$ 判定为男性，使用 $F_X \\le 0.20$ 判定为女性，并移除不一致或性别模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.125$ 的样本中移除一个；HWE：在对照组中计算，并排除 $p < 10^{-6}$ 的SNP。\n\nE. 个体：如果缺失率 $> 0.02$，则排除；SNP：如果缺失率 $> 0.02$，则排除；杂合率：排除在均值 $\\pm 3$ 倍标准差之外的个体；性别检查：同A选项；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的样本中移除一个；HWE：在对照组中计算，并根据使用 $m = 700{,}000$ 的Bonferroni校正，排除 $p < 7.1 \\times 10^{-8}$ 的SNP。\n\n选择唯一最佳的选项。", "solution": "任务是评估几种为全基因组关联研究 (GWAS) 提出的质量控制 (QC) 方案，并选择最佳方案。评估必须基于已确立的GWAS QC原则以及问题陈述中提供的具体经验数据摘要。\n\n首先，我将验证问题陈述的有效性。\n\n### 第一步：提取已知条件\n- 样本：$n = 12,000$ 个个体（病例 $= 5,000$，对照 $= 7,000$）。\n- 遗传数据：$m = 700,000$ 个常染色体单核苷酸多态性 (SNPs)。\n- 个体基因型缺失率：峰值 $\\approx 0.003$，第 $95$ 百分位数为 $0.012$，尾部延伸至 $0.12$。一个约 $150$ 个个体的次级聚类，其缺失率在 $[0.06, 0.10]$ 之间。\n- SNP基因型缺失率：峰值 $\\approx 0.002$，第 $95$ 百分位数为 $0.015$，尾部延伸至 $0.25$。在 $\\approx 0.06$ 处有一个次峰，涉及约 $12,000$ 个SNP。\n- 常染色体杂合率：在 $100,000$ 个LD剪枝后的SNP上，近似呈正态分布，均值 $\\mu = 0.315$，标准差 $\\sigma = 0.012$。存在离群聚类，分别在 $0.36$（约 $30$ 个个体）和 $0.28$（约 $20$ 个个体）。\n- X染色体性别推断 ($F_X$)：对于报告为男性的个体，$F_X$ 分布均值为 $0.95$，$\\sigma = 0.05$。对于报告为女性的个体，$F_X$ 分布均值为 $0.02$，$\\sigma = 0.03$。约有 $40$ 名报告为女性的个体其 $F_X > 0.85$，约有 $25$ 名报告为男性的个体其 $F_X < 0.15$。\n- 成对亲缘关系 ($\\hat{\\pi}$): 约 $60$ 对重复样本/同卵双胞胎 ($\\hat{\\pi} > 0.98$)，约 $220$ 对一级亲属 ($\\hat{\\pi} \\in [0.40, 0.60]$)，约 $300$ 对二级亲属 ($\\hat{\\pi} \\in [0.18, 0.25]$)。\n- 哈迪-温伯格平衡 (HWE)：对照组中的 $p$ 值在低端富集。约 $25,000$ 个SNP的 $p < 10^{-4}$，约 $1,200$ 个SNP的 $p < 10^{-6}$。这些低 $p$ 值的SNP在高缺失率上富集。\n- 所有指标的定义均已提供且为标准定义。\n\n### 第二步：使用提取的已知条件进行验证\n该问题具有科学依据。所有指标及其描述的经验分布对于一个大型人类GWAS数据集来说是现实的。问题设定良好，要求基于所提供的数据选择最佳QC方案，这是生物信息学中的一个标准任务。语言客观、精确。问题是自洽的，没有矛盾。提供的数据足以做出有原则的选择。\n\n### 第三步：判断与行动\n该问题有效。我将继续进行分析。\n\n### 基于第一性原理和数据推导合理的QC方案\n\n一个合理的QC方案必须移除可能的人为误差，同时尽可能保留高质量的数据。每个阈值都应由所提供的经验分布来证明其合理性。\n\n1.  **个体基因型缺失率**：大多数个体的缺失率非常低（峰值为 $0.003$，第 $95$ 百分位数为 $0.012$）。在 $0.06-0.10$ 附近有一个明显的低质量样本聚类。标准阈值通常为 $0.02$ 或 $0.05$。阈值设为 $0.02$ 将移除低质量样本的长尾和整个离群聚类，同时保留超过 $95\\%$ 的个体。这是一个合理的选择。\n\n2.  **SNP基因型缺失率**：情况与个体缺失率类似。绝大多数SNP的缺失率很低（峰值 $0.002$，第 $95$ 百分位数为 $0.015$）。在 $0.06$ 附近存在一个有问题的SNP的次峰。阈值设为 $0.02$ 是合理的，因为它移除了长尾，保留了超过 $95\\%$ 的SNP，并针对了有问题的模式。\n\n3.  **常染色体杂合率**：数据服从均值为 $\\mu=0.315$、标准差为 $\\sigma=0.012$ 的正态分布，并伴有离群聚类。我们检查这些聚类以标准差为单位的偏离程度。\n    -   高杂合率聚类在 $0.36$ 处：$z = (0.36 - 0.315) / 0.012 = 0.045 / 0.012 = 3.75$。\n    -   低杂合率聚类在 $0.28$ 处：$z = (0.28 - 0.315) / 0.012 = -0.035 / 0.012 \\approx -2.92$。\n    均值 $\\pm 3\\sigma$ 的阈值对应于区间 $[0.315 - 3(0.012), 0.315 + 3(0.012)] = [0.279, 0.351]$。这是一个极好的选择，因为它正确地将高杂合率个体识别为离群值（$0.36 > 0.351$）。它也正确地标记了处于低杂合率聚类边缘的个体（$0.28$ 接近边界 $0.279$）。$\\pm 3\\sigma$ 规则是识别正态分布数据中离群值的标准方法。\n\n4.  **性别检查**：X染色体近交系数 $F_X$ 的分布明显是双峰的。对于男性，均值为 $0.95$（$\\sigma=0.05$）。对于女性，均值为 $0.02$（$\\sigma=0.03$）。需要明确的阈值来对个体进行分类并识别不一致情况。让我们考虑 $\\mu \\pm 3\\sigma$ 的区间：\n    -   男性范围：$[0.95 - 3(0.05), 0.95 + 3(0.05)] = [0.80, 1.10]$。\n    -   女性范围：$[0.02 - 3(0.03), 0.02 + 3(0.03)] = [-0.07, 0.11]$。\n    基于此，设定遗传男性 $F_X \\ge 0.80$ 和遗传女性 $F_X \\le 0.20$ 的阈值是一个稳健的选择。$0.20$ 和 $0.80$ 之间的空间可作为模糊情况（如性染色体非整倍体）的缓冲区。问题指出存在报告为女性但 $F_X > 0.85$ 的个体，以及报告为男性但 $F_X < 0.15$ 的个体。这些阈值将正确地将他们识别为性别不符，必须排除。\n\n5.  **亲缘关系**：GWAS需要一个（大部分）无亲缘关系的样本。重复样本、同卵双胞胎和一级亲属必须被移除。通常也需要移除二级亲属以确保独立性。数据显示，二级亲属的 $\\hat{\\pi}$ 聚类在 $[0.18, 0.25]$ 范围内。阈值 $\\hat{\\pi} > 0.185$ 是一个很好的选择，可以移除这个群体中的配对以及更近的关系（一级亲属、重复样本）。这是一个由数据驱动的阈值，针对观察到的分布。\n\n6.  **哈迪-温伯格平衡 (HWE)**：HWE检验是检测基因分型错误的工具。a) 在病例-对照研究中，必须**仅在对照组中**进行，因为真正的关联可能导致病例组或整个样本中出现HWE偏离。b) $p$ 值阈值应足够严格以移除可能的错误，但又不能过于严格以致无效。数据显示，极低 $p$ 值的SNP富集（$1,200$ 个SNP的 $p < 10^{-6}$），这些SNP还与高缺失率相关。这强烈表明这些SNP是人为误差。因此，由数据可以很好地证明，阈值 $p < 10^{-6}$ 可以专门针对这群低质量SNP。应用Bonferroni校正（例如，$p < 0.05/700,000 \\approx 7 \\times 10^{-8}$）不适用于QC筛选；它过于严格，将无法移除许多有问题的SNP。\n\n基于此分析，最佳方案结合了这些有原则且由数据驱动的选择。我现在将根据这个理想方案评估每个选项。\n\n### 逐项分析选项\n\n**A. 个体：如果缺失率 $> 0.02$，则排除；SNP：如果缺失率 $> 0.02$，则排除；杂合率：标记并排除在均值 $\\pm 3$ 倍标准差之外的常染色体离群值；性别检查：如果 $F_X \\ge 0.80$ 则判定为男性，如果 $F_X \\le 0.20$ 则判定为女性，并排除不一致或性别模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的样本中移除一个；HWE：在对照组中计算，并排除 $p < 10^{-6}$ 的SNP。**\n\n- **评估**：此选项中的每一步都与基于经验数据和第一性原理推导出的最佳方案完美契合。缺失率、杂合率、性别检查、亲缘关系和HWE的阈值都是正确且由所提供的数据充分证明的。\n- **结论**：**正确**。\n\n**B. 个体：如果缺失率 $> 0.005$，则排除；SNP：如果缺失率 $> 0.005$，则排除；杂合率：排除在均值 $\\pm 2$ 倍标准差之外的个体；性别检查：通过 $F_X \\ge 0.50$ 判定为男性，通过 $F_X < 0.50$ 判定为女性；亲缘关系：仅使用 $\\hat{\\pi} > 0.35$ 移除重复样本和一级亲属；HWE：在所有样本中计算，并排除 $p < 10^{-4}$ 的SNP。**\n\n- **评估**：该方案存在严重缺陷。缺失率 ($>0.005$) 和杂合率 ($\\pm 2\\sigma$) 阈值过于严格，会丢弃过多的有效数据。性别检查阈值 ($F_X=0.5$) 粗糙且不够稳健。亲缘关系筛选 ($\\hat{\\pi} > 0.35$) 过于宽松，会保留二级亲属。至关重要的是，在所有样本中计算HWE对于病例-对照研究是错误的。\n- **结论**：**错误**。\n\n**C. 个体：如果缺失率 $> 0.08$，则排除；SNP：如果缺失率 $> 0.08$，则排除；杂合率：排除在均值 $\\pm 5$ 倍标准差之外的个体；性别检查：跳过基于X染色体的性别推断；亲缘关系：从每对 $\\hat{\\pi} > 0.10$ 的样本中移除一个；HWE：在对照组中计算，并排除 $p < 10^{-2}$ 的SNP。**\n\n- **评估**：该方案过于宽松，会保留低质量数据。缺失率阈值 $>0.08$ 会保留已知的离群样本和SNP。$\\pm 5\\sigma$ 的杂合率规则是无效的。跳过性别检查是重大的程序错误。HWE阈值 $p < 10^{-2}$ 过于宽容。亲缘关系阈值 ($\\hat{\\pi} > 0.10$) 反而过于严格，移除了比标准做法更远的亲属。\n- **结论**：**错误**。\n\n**D. 个体：如果缺失率 $> 0.02$，则排除；SNP：当次要等位基因频率 (MAF) $\\ge 0.01$ 时，如果缺失率 $> 0.02$ 则排除，但当 MAF $< 0.01$ 时允许缺失率高达 $0.05$；杂合率：排除在均值 $\\pm 3$ 倍标准差之外的个体；性别检查：使用 $F_X \\ge 0.80$ 判定为男性，使用 $F_X \\le 0.20$ 判定为女性，并移除不一致或性别模糊的个体；亲缘关系：从每对 $\\hat{\\pi} > 0.125$ 的样本中移除一个；HWE：在对照组中计算，并排除 $p < 10^{-6}$ 的SNP。**\n\n- **评估**：这是一个很强的方案，与A非常相似。然而，*在问题陈述的背景下*，它相对于A有两个微妙的弱点。首先，依赖MAF的SNP缺失率规则，虽然是一个好的实践，但引入了经验总结中未提供的信息（MAF），违反了“仅使用上述经验性摘要”的指令。其次，亲缘关系阈值 $\\hat{\\pi} > 0.125$ 是三级亲属的理论值，而选项A中的阈值 $\\hat{\\pi} > 0.185$ 更能贴合观察到的数据，恰好在二级亲属聚类的边界处进行切割。因此，A更能被问题的数据直接支持。\n- **结论**：**错误**。\n\n**E. 个体：如果缺失率 $> 0.02$，则排除；SNP：如果缺失率 $> 0.02$，则排除；杂合率：排除在均值 $\\pm 3$ 倍标准差之外的个体；性别检查：同A选项；亲缘关系：从每对 $\\hat{\\pi} > 0.185$ 的样本中移除一个；HWE：在对照组中计算，并根据使用 $m = 700{,}000$ 的Bonferroni校正，排除 $p < 7.1 \\times 10^{-8}$ 的SNP。**\n\n- **评估**：该选项除了HWE阈值外，与A完全相同。将严格的Bonferroni校正阈值 ($p < 7.1 \\times 10^{-8}$) 用于HWE作为QC筛选在概念上是错误的。它过于严格，将无法移除在 $p < 10^{-6}$ 处观察到的约 $1,200$ 个有问题SNP的聚类，违背了此QC步骤的目的。\n- **结论**：**错误**。\n\n### 结论\n选项A提出了一个完整且一致的QC方案，其中每一步都逻辑合理，每个阈值都直接由问题陈述中提供的经验数据分布所证明。它代表了在移除人为误差和保留高质量数据之间的最佳平衡。", "answer": "$$\\boxed{A}$$", "id": "2830645"}, {"introduction": "数据清理完毕后，我们便进入了核心的关联分析阶段。本练习聚焦于现代GWAS中广泛使用的线性混合模型（Linear Mixed Model, LMM），并揭示其中一个微妙而关键的统计陷阱：“近端污染”（proximal contamination）。通过理解随机效应如何错误地“吸收”待测变异的信号，你将亲手推导出“留一染色体法”（Leave-One-Chromosome-Out, LOCO）这一优雅的解决方案，以确保关联分析的准确性和稳健性。[@problem_id:2830658]", "problem": "在一个使用线性混合模型的数量性状全基因组关联研究中，您分析了 $n$ 个个体，其表型向量为 $y \\in \\mathbb{R}^{n}$。标准的线性混合模型将表型描述为固定协变量效应、一个待检验的单位点效应、一个多基因背景以及残差噪声的总和。多基因背景被建模为一个零均值的高斯随机效应，其协方差与根据全基因组范围的单核苷酸多态性计算出的遗传相关（亲缘）矩阵成正比。令 $s \\in \\mathbb{R}^{n}$ 表示待检验变异的标准化基因型向量。该模型既用于零假设检验，也用于估计变异效应。一个核心要求是，在零假设下，关联p值是经过校准的，即当变异没有效应时，它们具有正确的分布。\n\n从关于线性混合模型的公认事实和多变量高斯向量的性质出发（例如，高斯向量的条件化和线性投影仍然是高斯分布，以及协方差定义了随机效应可以吸收信号的方向），解释“近端污染”的机制：当亲缘矩阵由包含待检验变异（或同一染色体上处于强连锁不平衡的变异）的全基因组标记构建时，多基因随机效应会吸收一部分待检验变异的信号，从而使检验统计量偏小，并导致效应估计产生偏差。然后，推导出一个有原则的对亲缘矩阵构建的修正方法，该方法能打破这种吸收现象，同时保持对亲缘关系和群体结构的控制，并论证为什么这种修正能恢复整个基因组在零假设下检验统计量的校准。\n\n在存在连锁不平衡的情况下，以下哪种策略源于您的推导，并能在控制亲缘关系和群体结构的同时保持校准？\n\nA. 一次性使用所有标记（包括每个变异）构建一个单一的亲缘矩阵，并将其用于所有检验。\n\nB. 对每个待检验的变异，在移除该确切变异后重新计算亲缘矩阵，并保留所有其他标记。\n\nC. 对于给定染色体上的每个待检验变异，在排除该染色体上所有标记后重新计算亲缘矩阵，并将这种针对特定染色体的排除法用于该染色体上的检验。\n\nD. 用来自全基因组标记的少数几个主成分替换混合模型中的随机效应，并使用以这些主成分为协变量的普通最小二乘法进行所有检验。", "solution": "在尝试任何解答之前，需要对问题陈述进行验证。\n\n### 步骤1：提取已知信息\n-   研究是一个数量性状的全基因组关联研究（GWAS）。\n-   个体数量为 $n$。\n-   表型由向量 $y \\in \\mathbb{R}^{n}$ 表示。\n-   统计模型是线性混合模型（LMM）。\n-   用于表型 $y$ 的线性混合模型包括：固定协变量效应、一个单位点效应、一个多基因背景和残差噪声。\n-   多基因背景是一个随机效应，建模为零均值高斯分布，其协方差与遗传相关（亲缘）矩阵 $K$ 成正比。\n-   亲缘矩阵 $K$ 是根据全基因组范围的单核苷酸多态性（SNP）计算的。\n-   待检验变异的标准化基因型向量表示为 $s \\in \\mathbb{R}^{n}$。\n-   一个关键要求是在零假设下关联p值得到校准（即它们服从均匀分布）。\n-   问题提出了“近端污染”的存在：当 $K$ 使用包含待检验变异或处于强连锁不平衡（LD）的变异的标记构建时，多基因随机效应会吸收一部分待检验变异的信号。\n-   这种吸收据称会使检验统计量偏小并导致效应估计产生偏差。\n-   任务是解释此机制，推导一个有原则的亲缘矩阵构建修正方法来解决它，并从给定选项中确定正确的策略。\n\n### 步骤2：使用提取的已知信息进行验证\n对问题陈述的有效性进行评估。\n\n-   **科学依据：** 对线性混合模型的描述对于其在数量遗传学和GWAS中的应用是标准且准确的。模型结构、使用亲缘矩阵建模多基因效应和控制群体结构/亲缘关系，以及“近端污染”现象，都是统计遗传学领域中公认的基本概念。该问题基于可靠的统计学和遗传学原理。\n-   **定义明确：** 问题定义清晰。它要求解释一个已知的统计学伪影，并推导一个标准、公认的解决方案。问题的结构旨在引导出一个在现代GWAS软件中广泛实施的、唯一的概念性结论。\n-   **客观性：** 语言技术性强、精确，且没有主观性或歧义。术语如“线性混合模型”、“亲缘矩阵”、“连锁不平衡”和“p值校准”在在此上下文中都是标准的，并具有明确的含义。\n\n### 步骤3：结论与行动\n问题陈述是有效的。这是一个关于统计遗传学中一个关键方法论问题的、表述清晰的问题。将推导解答。\n\n### 解答推导\n\n一个样本量为 $n$ 的数量性状 $y$ 的标准线性混合模型由下式给出：\n$$\ny = X\\beta + s\\gamma + u + \\epsilon\n$$\n其中：\n-   $y$ 是表型值的 $n \\times 1$ 向量。\n-   $X$ 是一个 $n \\times c$ 的矩阵，包含 $c$ 个固定效应协变量（例如，年龄、性别和用于表示祖源的主成分）。\n-   $\\beta$ 是协变量对应的效应大小的 $c \\times 1$ 向量。\n-   $s$ 是待检验SNP的 $n \\times 1$ 标准化基因型向量。\n-   $\\gamma$ 是待检验SNP的标量固定效应，是关注的参数。\n-   $u$ 是一个 $n \\times 1$ 的随机向量，代表来自全基因组所有其他变异的累积多基因效应。它被建模为从一个多变量正态分布中抽取，即 $u \\sim \\mathcal{N}(0, \\sigma_g^2 K)$，其中 $\\sigma_g^2$ 是多基因方差分量，$K$ 是 $n \\times n$ 的遗传相关矩阵（亲缘矩阵）。\n-   $\\epsilon$ 是非遗传和环境残差的 $n \\times 1$ 随机向量，建模为 $\\epsilon \\sim \\mathcal{N}(0, \\sigma_e^2 I)$，其中 $\\sigma_e^2$ 是残差方差，$I$ 是 $n \\times n$ 的单位矩阵。\n\n关联检验的零假设是 $H_0: \\gamma = 0$。检验统计量（通常来自似然比检验或得分检验）评估在模型中包含 $s\\gamma$ 项的显著性。为使该检验有效，当 $H_0$ 为真时，检验统计量必须服从其理论零分布（例如，$\\chi^2_1$ 分布）。\n\n**近端污染的机制**\n\n亲缘矩阵 $K$ 通常是根据大量的 $M$ 个全基因组标记估计的。一个标准的估计量是 $K = \\frac{1}{M} \\sum_{j=1}^M s_j s_j^T$，其中 $s_j$ 是第 $j$ 个标记的标准化基因型向量。\n\n当用于构建 $K$ 的标记集 $\\{s_j\\}_{j=1}^M$ 包含待检验的SNP $s$ 或与 $s$ 处于强连锁不平衡（LD）的SNP时，问题就出现了。假设待检验的SNP为某个索引 $k$ 对应的 $s_k$。\n\n通过在创建 $K$ 的求和中包含 $s_k$，我们明确地将项 $\\frac{1}{M} s_k s_k^T$ 包含在随机效应 $u$ 的协方差结构中。这意味着模型先验地假设任何投影到向量 $s_k$ 方向上的表型方差都可能成为多基因随机背景的一部分。\n\n当我们接着对同一个SNP $s_k$ 检验一个*固定*效应 $\\gamma$ 时，便产生了冲突。模型必须将与 $s_k$ 相关的表型信号在固定效应项 $s_k\\gamma$ 和随机效应项 $u$ 之间进行划分。由于 $u$ 的协方差被明确设计为包含沿 $s_k$ 方向的变异，随机效应 $u$ 将“吸收”或“吸纳”一部分真实的固定效应信号。这是固定效应和随机效应的定义向量非正交时出现的典型混淆案例。\n\n这种吸收有两个主要后果：\n1.  **有偏的效应估计：** 估计值 $\\hat{\\gamma}$ 将会偏向于零，因为部分效应被错误地归因于随机项 $u$。\n2.  **偏小的检验统计量：** $\\gamma$ 的检验统计量将比应有的值小，导致统计功效的损失。在零假设下，这也可能导致整个基因组的检验统计量出现细微但系统性的偏小，从而导致校准失效（即，p值系统性地大于零假设下的期望值）。这是因为即使待检验SNP处于零假设下，与附近真实致病变异的连锁不平衡（LD）也会产生一个局部信号，该信号会被受污染的随机效应吸收，从而再次使检验统计量偏小。\n\n如果我们检验SNP $s_k$，但亲缘矩阵 $K$ 包含另一个与 $s_k$ 处于高连锁不平衡（LD）的SNP $s_j$，同样的问题也会发生。在这种情况下，它们的基因型向量高度相关（$s_k \\approx \\rho s_j$），因此在构建 $K$ 时包含 $s_j$ 会在 $u$ 的协方差中提供一个与待检验的固定效应向量 $s_k$ 近似共线的向量，从而导致同样的吸收现象。这就是“近端污染”，因为污染源自与待检验标记在遗传上相近（因此处于LD）的标记。\n\n**对亲缘矩阵构建的有原则的修正**\n\n为了消除这种混淆，我们必须确保随机效应 $u$ 和固定效应 $s\\gamma$ 不是使用重叠的信息定义的。用于检验固定效应的向量 $s$ 必须与为多基因随机背景定义的变异空间正交。\n\n实现这一点的一个直接方法是，仅使用与待检验标记 $s$ 不存在连锁不平衡（LD）的标记来构建亲缘矩阵 $K$。由于减数分裂和重组的性质，不同染色体上的标记通常不存在LD（除了由群体结构引起的远程相关性，而LMM的设计正是为了全局性地捕捉这种相关性）。在同一条染色体内，LD在邻近的标记间很强，并随距离增加而衰减。\n\n因此，一个有原则且稳健的策略是按染色体对基因组进行划分。当检验特定染色体（比如染色体 $i$）上的任何SNP时，我们应该使用一个*仅*由所有其他染色体上的标记构建的亲缘矩阵来对多基因背景进行建模。\n\n令 $K_{(-i)}$ 为由*不*在染色体 $i$ 上的所有SNP计算出的亲缘矩阵。当检验位于染色体 $i$ 上的一个SNP $s$ 时，模型变为：\n$$\ny = X\\beta + s\\gamma + u_{(-i)} + \\epsilon\n$$\n其中 $u_{(-i)} \\sim \\mathcal{N}(0, \\sigma_g^2 K_{(-i)})$。\n\n这种被称为“排除单条染色体法”（Leave-One-Chromosome-Out, LOCO）的方法，确保了待检验的固定效应 $s\\gamma$ 不会与随机效应 $u_{(-i)}$ 相混淆。随机效应对来自染色体 $1, 2, ..., i-1, i+1, ...$ 的背景进行建模，而固定效应对染色体 $i$ 上的局部信号进行建模。这正确地将检验信号与背景模型分离开来，打破了近端污染的机制。这恢复了检验统计量的校准，并为染色体 $i$ 上的变异提供了无偏的效应估计，同时仍然控制了由基因组其余部分引起的群体结构和多基因背景。此过程对每条染色体重复进行。\n\n### 选项评估\n\n**A. 一次性使用所有标记（包括每个变异）构建一个单一的亲缘矩阵，并将其用于所有检验。**\n这是*导致*近端污染的标准方法。如上文推导，在构建亲缘矩阵时包含待检验变异（或处于LD的变异）会导致检验统计量偏小和估计值有偏。该策略无法保持校准。\n**结论：不正确**\n\n**B. 对每个待检验的变异，在移除该确切变异后重新计算亲缘矩阵，并保留所有其他标记。**\n这种修正是不足的。虽然它移除了待检验变异 $s$ 的直接包含，但未能考虑LD。与 $s$ 直接相邻并处于高LD的标记将保留在亲缘矩阵的计算中。它们与 $s$ 的高相关性意味着随机效应仍会吸收来自 $s$ 的信号，近端污染将持续存在。这种方法在计算上也令人望而却步，需要为每个SNP检验重新计算一次亲缘矩阵。\n**结论：不正确**\n\n**C. 对于给定染色体上的每个待检验变异，在排除该染色体上所有标记后重新计算亲缘矩阵，并将这种针对特定染色体的排除法用于该染色体上的检验。**\n这就是上文推导的“排除单条染色体法”（LOCO）策略。它正确地将被检验的信号（在一条染色体上）与多基因背景模型（由所有其他染色体构建）分离开来，从而消除了近端污染。它保持了对亲缘关系和群体结构的控制，因为这些是由其余染色体捕捉到的全基因组属性。该策略恢复了检验统计量的校准。\n**结论：正确**\n\n**D. 用来自全基因组标记的少数几个主成分替换混合模型中的随机效应，并使用以这些主成分为协变量的普通最小二乘法进行所有检验。**\n这描述的是一种替代的建模策略（PCA + OLS），而不是对LMM亲缘矩阵构建的修正。虽然使用主成分作为协变量可以控制群体结构，但众所周知，当性状存在显著的多基因成分时，其功效低于LMM，因为它没有明确地对由隐性亲缘关系和数千个微小效应变异引起的协方差进行建模。问题要求的是*在LMM框架内对亲缘矩阵构建*的有原则的修正，而不是替换模型。此外，当亲缘关系未被完全捕捉时，使用PC的OLS可能会遭受其自身形式的检验统计量膨胀。此选项并非从推导中得出。\n**结论：不正确**", "answer": "$$\\boxed{C}$$", "id": "2830658"}, {"introduction": "本章的最后一个实践将我们带到GWAS的前沿领域：处理来自下一代测序（Next-Generation Sequencing, NGS）数据中的罕见变异。在这个动手编码练习中，你将通过从头构建一个模拟过程，来探索基因型不确定性的影响。你会发现，在低覆盖度和测序错误存在的情况下，简单地“判定”一个基因型（硬调用）会引入偏差，而优雅地整合概率信息（软调用或基因型似然性）才是提高罕见变异关联研究效力和准确性的关键。[@problem_id:2830588]", "problem": "要求您实现一个自包含的模拟与分析程序，以评估在数量性状位点 (QTL) 定位和全基因组关联研究 (GWAS) 的稀有变异检测背景下，相对于硬性基因型判定，整合基因型似然如何在多大程度上改善校准。您的程序必须模拟具有真实覆盖度变异和碱基识别错误的二代测序数据，然后计算并比较两种基因型剂量估计量下的校准情况。\n\n使用的基本依据和假设：\n- 哈代-温伯格平衡 (Hardy–Weinberg Equilibrium, HWE)：对于一个二倍体生物，给定次要等位基因频率 $p \\in (0,1)$，在随机交配的条件下，基因型 $G \\in \\{0,1,2\\}$ 的先验概率为 $P(G=0) = (1-p)^2$、$P(G=1) = 2p(1-p)$ 和 $P(G=2) = p^2$。\n- 测序读数的二项采样 (Binomial sampling of reads)：给定总覆盖度 $N \\in \\{0,1,2,\\dots\\}$ 和由真实基因型及测序错误所决定的单位读数备择等位基因概率 $q \\in [0,1]$，备择等位基因读数计数 $K$ 服从分布 $K \\sim \\mathrm{Binomial}(N,q)$。\n- 过度离散的覆盖度 (Overdispersed coverage)：为模拟跨样本和位点的覆盖度变异，假设 $N$ 服从负二项分布，其均值为 $\\mu > 0$，整数离散参数为 $r \\in \\{1,2,3,\\dots\\}$，参数化后使得 $\\mathbb{E}[N] = \\mu$ 且 $\\mathrm{Var}[N] = \\mu + \\mu^2/r$。\n- 对称的碱基识别错误 (Symmetric base-calling error)：设单位碱基错误率为 $\\varepsilon \\in (0,1/2)$，并假设各读数之间独立。在备择等位基因与任何非备择判定的二元区分下，一个读数报告备择等位基因的概率为：\n  - 当 $G=0$ 时，$q = \\varepsilon$\n  - 当 $G=1$ 时，$q = 1/2$\n  - 当 $G=2$ 时，$q = 1-\\varepsilon$\n- 基因型似然与贝叶斯法则：对于一个位点和样本上观测到的一对数据 $(N,K)$，基因型似然满足 $P(D \\mid G=g) \\propto q_g^K (1-q_g)^{N-K}$ (不考虑在归一化中会消去的组合因子)，且后验概率遵循 $P(G=g \\mid D) \\propto P(D \\mid G=g) P(G=g)$。\n\n需要计算的目标：\n- 两种剂量（次要等位基因计数）估计量：\n  - 硬性判定剂量 $\\hat{d}_{\\mathrm{hard}}$：后验概率的众数，映射到 $\\{0,1,2\\}$。\n  - 整合剂量 $\\hat{d}_{\\mathrm{soft}}$：后验均值 $\\sum_{g \\in \\{0,1,2\\}} g \\, P(G=g \\mid D)$。\n- 设真实剂量为 $d_{\\mathrm{true}} \\in \\{0,1,2\\}$。将每个估计量下的均方误差定义为在所有样本和位点上 $(\\hat{d} - d_{\\mathrm{true}})^2$ 的平均值。将改善量定义为\n$$\n\\Delta = \\mathrm{MSE}(\\hat{d}_{\\mathrm{hard}}) - \\mathrm{MSE}(\\hat{d}_{\\mathrm{soft}}).\n$$\n您的程序必须为每个测试用例输出 $\\Delta$。\n\n需实现的模拟设计：\n- 对于每个测试用例，模拟 $L$ 个具有相同次要等位基因频率 $p$ 的独立位点，以及每个位点上的 $N_{\\mathrm{samples}}$ 个独立的二倍体个体。\n- 对每个个体和位点，从 $G \\sim \\mathrm{Binomial}(2,p)$ (这满足HWE) 中抽取真实基因型 $G$，然后从均值为 $\\mu$、离散参数为 $r$ 的 $\\mathrm{NegBin}(r, \\mu)$ 中抽取覆盖度 $N$，接着使用上述对称错误模型（错误率为 $\\varepsilon$），从 $\\mathrm{Binomial}(N, q_G)$ 中抽取备择等位基因读数 $K$。\n- 使用贝叶斯法则、HWE先验和二项似然计算后验概率 $P(G=g \\mid D)$ (其中 $g \\in \\{0,1,2\\})$；然后计算 $\\hat{d}_{\\mathrm{soft}}$ 和 $\\hat{d}_{\\mathrm{hard}}$，最后计算如上定义的 $\\Delta$。\n\n需要证明的原理：\n- 在整个测试套件中，通过经验证明使用 $\\hat{d}_{\\mathrm{soft}}$ 相对于 $\\hat{d}_{\\mathrm{hard}}$ 减少了平方误差（即 $\\Delta \\ge 0$），从而改善了校准。\n\n实现要求：\n- 为保证可复现性，使用固定的伪随机种子 $1337$。\n- 不要假设存在任何外部文件；所有内容必须在内存中模拟。\n- 避免在零覆盖度时出现未定义行为；当 $N=0$ 时，后验概率应简化为先验概率。\n\n测试套件：\n精确实现以下四个测试用例，每个用例为一个元组 $(N_{\\mathrm{samples}}, L, p, \\mu, r, \\varepsilon)$：\n- 用例 1：$(2000, 50, 0.01, 12.0, 5, 0.005)$\n- 用例 2：$(2000, 50, 0.005, 3.0, 3, 0.01)$\n- 用例 3：$(4000, 80, 0.001, 8.0, 4, 0.02)$\n- 用例 4：$(3000, 40, 0.0005, 1.0, 2, 0.02)$\n\n输出内容：\n- 对每个用例，计算 $\\Delta$ 并以十进制数表示。报告结果时四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含四个结果，以逗号分隔并用方括号括起，顺序与上述用例一致。例如：\"[0.012345,0.000678,0.001234,0.000056]\"。", "solution": "该问题陈述已经过严格验证，被确定为是适定的、有科学依据且内部一致的。它提出了一个来自统计遗传学的标准（尽管简化了）模型，并要求对估计量的性能进行计算分析。我们现在将进行正式的求解。\n\n目标是通过使用后验均值估计量（软判定）代替后验众数估计量（硬判定），来量化基因型剂量估计的改善程度。这种改善通过均方误差 (Mean Squared Error, MSE) 的减少来衡量，记为 $\\Delta = \\mathrm{MSE}(\\hat{d}_{\\mathrm{hard}}) - \\mathrm{MSE}(\\hat{d}_{\\mathrm{soft}})$。其背景是分析来自新一代测序数据的稀有变异，其中低等位基因频率和可变的读数覆盖度带来了显著的不确定性。\n\n该分析通过蒙特卡洛模拟进行。对于由参数 $(N_{\\mathrm{samples}}, L, p, \\mu, r, \\varepsilon)$ 定义的每个测试用例，我们为一个二倍体群体模拟总共 $N_{\\mathrm{total}} = N_{\\mathrm{samples}} \\times L$ 个独立的位点。\n\n**1. 数据模拟**\n\n对 $N_{\\mathrm{total}}$ 个数据点中的每一个进行的模拟都分三步进行，以仿真生物学和技术过程：\n\n- **真实基因型生成：** 真实基因型 $G$ 代表次要等位基因的计数，是为每个个体的每个位点抽取的。在哈代-温伯格平衡 (Hardy-Weinberg Equilibrium, HWE) 的假设下，基因型服从二项分布，试验次数为 2 (对于二倍体生物)，成功概率等于次要等位基因频率 (Minor Allele Frequency, MAF)，即 $p$。\n$$\nd_{\\mathrm{true}} = G \\sim \\mathrm{Binomial}(2, p)\n$$\n\n- **测序覆盖度模拟：** 读数覆盖度 $N$ 在个体和位点间是可变的。这种过度离散性使用负二项分布来建模，该分布由其均值 $\\mu$ 和整数离散参数 $r$ 参数化。其概率质量函数满足 $\\mathbb{E}[N] = \\mu$ 且 $\\mathrm{Var}[N] = \\mu + \\mu^2/r$。这对应于成功次数 $n=r$ 和成功概率 $p_{\\mathrm{NB}} = r / (r+\\mu)$ 的标准参数化。\n$$\nN \\sim \\mathrm{NegativeBinomial}(n=r, p=r/(r+\\mu))\n$$\n\n- **备择等位基因读数计数模拟：** 给定真实基因型 $G$ 和总覆盖度 $N$，支持备择等位基因的读数数量 $K$ 从二项分布中采样。在任何给定读数上观察到备择等位基因的概率 $q_G$ 取决于真实基因型 $G$ 和对称的碱基识别错误率 $\\varepsilon$。\n$$\nK \\sim \\mathrm{Binomial}(N, q_G)\n$$\n其中，单位读数的备择等位基因概率 $q_G$ 由下式给出：\n$$\nq_G = \\begin{cases} \\varepsilon & \\text{若 } G=0 \\\\ 1/2 & \\text{若 } G=1 \\\\ 1-\\varepsilon & \\text{若 } G=2 \\end{cases}\n$$\n\n**2. 基因型的贝叶斯推断**\n\n对于每个模拟数据点 $(N, K)$，我们应用贝叶斯定理来计算每个可能基因型 $g \\in \\{0, 1, 2\\}$ 的后验概率。后验概率与似然和先验概率的乘积成正比。\n\n- **先验概率：** 关于基因型的先验信念由来自群体 MAF $p$ 的 HWE 概率给出：\n$$\nP(G=g) = \\begin{cases} (1-p)^2 & \\text{若 } g=0 \\\\ 2p(1-p) & \\text{若 } g=1 \\\\ p^2 & \\text{若 } g=2 \\end{cases}\n$$\n\n- **似然函数：** 在给定真实基因型 $g$ 的情况下，从 $N$ 个总读数中观察到 $K$ 个备择等位基因读数的似然由二项概率质量函数给出：\n$$\nP(D \\mid G=g) = \\binom{N}{K} q_g^K (1-q_g)^{N-K}\n$$\n其中 $D$ 表示数据 $(N,K)$。\n\n- **后验概率：** 基因型 $g$ 的后验概率则为：\n$$\nP(G=g \\mid D) = \\frac{P(D \\mid G=g) P(G=g)}{\\sum_{i=0}^{2} P(D \\mid G=i) P(G=i)}\n$$\n为确保数值稳定性，计算在对数空间中执行。对数后验概率计算如下：\n$$\n\\log P(G=g \\mid D) = \\left( \\log P(D \\mid G=g) + \\log P(G=g) \\right) - \\mathrm{logsumexp}_{i=0}^{2} \\left( \\log P(D \\mid G=i) + \\log P(G=i) \\right)\n$$\n零覆盖度 ($N=0$) 的特殊情况在此公式中得到自然处理。如果 $N=0$，则 $K=0$，似然项 $P(D \\mid G=g)$ 对所有 $g$ 都变为 $1$，导致后验概率恢复为先验概率，这是正确的。\n\n**3. 剂量估计与误差计算**\n\n从后验分布 $P(G=g \\mid D)$ 中，我们计算两种不同的剂量估计量：\n\n- **硬性判定剂量 ($\\hat{d}_{\\mathrm{hard}}$)：** 这是最大后验 (Maximum A Posteriori, MAP) 估计，对应于具有最高后验概率的基因型。\n$$\n\\hat{d}_{\\mathrm{hard}} = \\underset{g \\in \\{0,1,2\\}}{\\mathrm{argmax}} \\, P(G=g \\mid D)\n$$\n该估计量丢弃了所有关于不确定性的信息。\n\n- **整合剂量 ($\\hat{d}_{\\mathrm{soft}}$)：** 这是基因型分布的后验均值，它对不确定性进行了积分。\n$$\n\\hat{d}_{\\mathrm{soft}} = \\mathbb{E}[G \\mid D] = \\sum_{g=0}^{2} g \\cdot P(G=g \\mid D)\n$$\n根据贝叶斯决策理论，后验均值是最小化均方误差 (MSE) 的最优估计量。\n\n最后，通过对所有 $N_{\\mathrm{total}}$ 次模拟中估计值与真实模拟剂量 $d_{\\mathrm{true}}$ 之间差值的平方进行平均，来计算每个估计量的 MSE。\n$$\n\\mathrm{MSE}(\\hat{d}) = \\frac{1}{N_{\\mathrm{total}}} \\sum_{j=1}^{N_{\\mathrm{total}}} (\\hat{d}_j - d_{\\mathrm{true}, j})^2\n$$\n计算最终指标 $\\Delta = \\mathrm{MSE}(\\hat{d}_{\\mathrm{hard}}) - \\mathrm{MSE}(\\hat{d}_{\\mathrm{soft}})$。我们期望 $\\Delta \\ge 0$，这表明整合剂量估计量在平方误差方面校准得更好。\n\n整个过程使用固定的伪随机种子 $1337$ 来实现，以确保可复现性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import nbinom, binom\nfrom scipy.special import logsumexp\n\ndef compute_delta_for_case(n_samples, l_loci, p_maf, mu, r, epsilon, rng):\n    \"\"\"\n    Simulates sequencing data and computes the improvement in MSE from using\n    soft vs. hard genotype calls.\n\n    Args:\n        n_samples (int): Number of diploid individuals.\n        l_loci (int): Number of independent loci.\n        p_maf (float): Minor allele frequency.\n        mu (float): Mean coverage.\n        r (int): Dispersion parameter for coverage.\n        epsilon (float): Symmetric base-calling error rate.\n        rng (np.random.Generator): A numpy random number generator instance.\n\n    Returns:\n        float: The calculated improvement, Delta = MSE(hard) - MSE(soft).\n    \"\"\"\n\n    n_total = n_samples * l_loci\n    \n    # 1. Priors and Genotype-dependent probabilities\n    # HWE prior probabilities P(G=g) for g in {0, 1, 2}\n    prior_probs = np.array([(1 - p_maf)**2, 2 * p_maf * (1 - p_maf), p_maf**2])\n    log_priors = np.log(prior_probs)\n\n    # Per-read alternate allele probability q_g, given genotype g\n    q_vec = np.array([epsilon, 0.5, 1 - epsilon])\n\n    # 2. Simulation steps\n    # Step 2.1: Simulate true genotypes (dosages) from Binomial(2, p)\n    # This correctly models diploid genotypes under HWE.\n    d_true = rng.binomial(2, p_maf, size=n_total)\n\n    # Step 2.2: Simulate overdispersed read coverage N from Negative Binomial\n    # Parameterize for scipy.stats.nbinom using mean (mu) and dispersion (r)\n    p_nb = r / (r + mu)\n    # n_nb = r\n    N = nbinom.rvs(n=r, p=p_nb, size=n_total, random_state=rng)\n    \n    # Step 2.3: Simulate alternate read counts K from Binomial(N, q_G)\n    # The probability of success q_G depends on the true genotype G.\n    q_true = q_vec[d_true]\n    K = rng.binomial(N, q_true)\n\n    # 3. Bayesian Inference\n    # Calculate log-likelihoods P(K|N, G=g) for each g in {0, 1, 2}\n    # This creates a (3, N_total) array where rows correspond to G=0, 1, 2.\n    # The calculation is vectorized over all N_total data points.\n    log_likelihoods = np.zeros((3, n_total))\n    for g in range(3):\n        # binom.logpmf is numerically stable and handles N=0 cases correctly.\n        log_likelihoods[g, :] = binom.logpmf(K, N, q_vec[g])\n\n    # Combine with log-priors to get unnormalized log-posteriors\n    # Broadcasting log_priors of shape (3,1) over log_likelihoods of shape (3, n_total)\n    log_unnorm_posterior = log_likelihoods + log_priors[:, np.newaxis]\n\n    # Normalize using the log-sum-exp trick to get log-posteriors\n    log_marginal_likelihood = logsumexp(log_unnorm_posterior, axis=0)\n    log_posterior = log_unnorm_posterior - log_marginal_likelihood\n    \n    # Convert back to linear scale for posterior probabilities\n    posterior_probs = np.exp(log_posterior)\n\n    # 4. Compute Dosage Estimators\n    # Hard call dosage (MAP estimate)\n    d_hat_hard = np.argmax(posterior_probs, axis=0)\n\n    # Soft call dosage (posterior mean)\n    genotypes = np.array([0, 1, 2])\n    d_hat_soft = genotypes @ posterior_probs\n\n    # 5. Calculate Mean Squared Error and Delta\n    mse_hard = np.mean((d_hat_hard - d_true)**2)\n    mse_soft = np.mean((d_hat_soft - d_true)**2)\n    \n    delta = mse_hard - mse_soft\n    return delta\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print results.\n    \"\"\"\n    # Initialize a single random number generator for reproducibility.\n    rng = np.random.default_rng(1337)\n\n    # Define the test cases from the problem statement:\n    # (N_samples, L, p, mu, r, epsilon)\n    test_cases = [\n        (2000, 50, 0.01, 12.0, 5, 0.005),\n        (2000, 50, 0.005, 3.0, 3, 0.01),\n        (4000, 80, 0.001, 8.0, 4, 0.02),\n        (3000, 40, 0.0005, 1.0, 2, 0.02),\n    ]\n\n    results = []\n    for case in test_cases:\n        delta = compute_delta_for_case(*case, rng=rng)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{res:.6f}' for res in results)}]\")\n\nsolve()\n```", "id": "2830588"}]}