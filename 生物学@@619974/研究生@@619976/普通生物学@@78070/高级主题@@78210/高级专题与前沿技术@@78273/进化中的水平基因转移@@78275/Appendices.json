{"hands_on_practices": [{"introduction": "定量理解水平基因转移（HGT）的速率是研究其进化影响的基础。本练习将经典的实验室终点接合实验与基于质量作用动力学的数学模型相结合，引导学生从第一性原理推导出关键参数——接合率 $\\beta$ 的估计量 [@problem_id:2806039]。这项实践是定量微生物遗传学中的一项基础训练，它加深了对基因转移动力学过程的理解。", "problem": "经典的终点平板接合分析法用于量化质粒介导的接合速率，这是一种水平基因转移的形式。将携带自转移质粒的供体细胞（初始密度为 $D_0$，单位为菌落形成单位/毫升）与受体细胞（初始密度为 $R_0$）在滤膜上混合，并孵育固定时间 $t$。该分析在营养限制条件下进行，以防止在接合期间发生细胞分裂，仅发生接合（质粒从供体转移到受体）。在时间 $t$ 时，将细胞重悬并涂布在选择性培养基上，该培养基仅对转接合子进行计数，从而得到观测到的转接合子计数 $T_t$（单位为每次重悬液的毫升数）。\n\n采用以下基于质量作用定律的机理描述：每个受体细胞经历一个时间均匀的转化为转接合子的风险，风险率等于每个单位时间 $\\beta D(t)$，其中 $\\beta$ 是接合速率常数，$D(t)$ 是供体密度。在此分析中，供体在接合后保留质粒，并且不因转移而被消耗。在接合期间，假设 $D(t) \\equiv D_0$（供体不生长且不损失），受体转化为转接合子，无分裂或死亡，没有质粒的分离性丢失，并且细胞在滤膜上均匀分布，因此质量作用接触率适用。\n\n从这些假设出发，并且在所述模型之外不引入任何特别的近似，推导出接合速率 $\\beta$ 的一个闭式最大似然估计量 $\\hat{\\beta}$，该估计量仅用 $D_0$、$R_0$、$T_t$ 和 $t$ 表示。明确说明该估计量是渐近无偏的所需满足的最小生物学和统计学假设，并说明在何种极限情况下，稀有事件近似能产生一个无偏的一阶估计量。将 $\\hat{\\beta}$ 以单一符号表达式的形式给出；最终表达式的任何地方都不要包含单位。", "solution": "所述问题具有科学依据，提法恰当且内部一致。它描述了微生物遗传学中一个标准的实验场景，使用了经典的质量作用动力学模型。所有推导所需统计估计量的必要参数和条件均已提供。因此，我们可以进行推导。\n\n该模型的核心是受体细胞密度 $R(t)$ 的变化率。根据质量作用定律和问题的规定，受体转化为转接合子的速率与受体密度 $R(t)$ 和供体密度 $D(t)$ 的乘积成正比。单个受体细胞的风险率被给出为 $\\beta D(t)$。因此，受体种群密度的变化率为：\n$$ \\frac{dR(t)}{dt} = - (\\beta D(t)) R(t) $$\n问题陈述中要求假设供体密度恒定，即 $D(t) \\equiv D_0$，因为在接合间隔 $t$ 内供体不被消耗也不生长。该微分方程简化为：\n$$ \\frac{dR(t)}{dt} = -\\beta D_0 R(t) $$\n这是一个一阶可分离常微分方程，初始条件为 $R(t=0) = R_0$。我们通过积分求解：\n$$ \\int_{R_0}^{R(t)} \\frac{dR'}{R'} = \\int_0^t -\\beta D_0 dt' $$\n$$ \\ln(R(t)) - \\ln(R_0) = -\\beta D_0 t $$\n$$ R(t) = R_0 \\exp(-\\beta D_0 t) $$\n该方程描述了在时间 $t$ 时剩余的受体细胞密度。转接合子的密度 $T(t)$ 是初始受体密度减去剩余受体密度，因为细胞只被转化而不死亡或分裂：\n$$ T(t) = R_0 - R(t) = R_0 (1 - \\exp(-\\beta D_0 t)) $$\n这个表达式代表了转接合子的期望密度。观测值是经验测量值 $T_t$。\n\n为了推导最大似然估计量（MLE），我们必须为观测到的计数建立一个概率模型。让我们考虑给定体积内初始种群 $N_R$ 个受体细胞的命运。每个细胞经历一个随机过程，它要么转化为转接合子，要么保持为受体。根据我们的确定性模型，任何单个受体细胞在时间 $t$ 之前成为转接合子的概率 $p$ 是：\n$$ p = \\frac{T(t)}{R_0} = 1 - \\exp(-\\beta D_0 t) $$\n它保持为受体的概率是 $1-p = \\exp(-\\beta D_0 t)$。假设每个细胞的命运是独立事件，那么从初始的 $N_R$ 个受体中观测到的转接合子数量 $N_T$ 服从二项分布：\n$$ P(N_T | N_R, p) = \\binom{N_R}{N_T} p^{N_T} (1-p)^{N_R - N_T} $$\n参数 $\\beta$ 的似然函数 $L(\\beta)$ 与此概率成正比。我们可以用观测到的密度 $T_t$ 和 $R_0$ 来表示它，注意到 $N_T/N_R = T_t/R_0$。\n$$ L(\\beta) \\propto \\left(1 - \\exp(-\\beta D_0 t)\\right)^{N_T} \\left(\\exp(-\\beta D_0 t)\\right)^{N_R - N_T} $$\n最大化对数似然函数 $\\ell(\\beta) = \\ln L(\\beta)$ 更为方便：\n$$ \\ell(\\beta) = C + N_T \\ln\\left(1 - \\exp(-\\beta D_0 t)\\right) + (N_R - N_T) \\ln\\left(\\exp(-\\beta D_0 t)\\right) $$\n$$ \\ell(\\beta) = C + N_T \\ln\\left(1 - \\exp(-\\beta D_0 t)\\right) - (N_R - N_T) \\beta D_0 t $$\n为了找到最大似然估计量 $\\hat{\\beta}$，我们将 $\\ell(\\beta)$ 对 $\\beta$ 的导数设为零：\n$$ \\frac{d\\ell}{d\\beta} = N_T \\frac{D_0 t \\exp(-\\beta D_0 t)}{1 - \\exp(-\\beta D_0 t)} - (N_R - N_T) D_0 t = 0 $$\n假设 $D_0 t \\neq 0$，我们可以除以这一项：\n$$ \\frac{N_T \\exp(-\\hat{\\beta} D_0 t)}{1 - \\exp(-\\hat{\\beta} D_0 t)} = N_R - N_T $$\n$$ N_T \\exp(-\\hat{\\beta} D_0 t) = (N_R - N_T) (1 - \\exp(-\\hat{\\beta} D_0 t)) $$\n$$ N_T \\exp(-\\hat{\\beta} D_0 t) = N_R - N_T - (N_R - N_T) \\exp(-\\hat{\\beta} D_0 t) $$\n$$ (N_T + N_R - N_T) \\exp(-\\hat{\\beta} D_0 t) = N_R - N_T $$\n$$ N_R \\exp(-\\hat{\\beta} D_0 t) = N_R - N_T $$\n两边除以 $N_R$ 并代入观测密度（用 $T_t/R_0$ 替代 $N_T/N_R$）：\n$$ \\exp(-\\hat{\\beta} D_0 t) = 1 - \\frac{N_T}{N_R} = 1 - \\frac{T_t}{R_0} $$\n通过取自然对数来求解 $\\hat{\\beta}$：\n$$ -\\hat{\\beta} D_0 t = \\ln\\left(1 - \\frac{T_t}{R_0}\\right) $$\n$$ \\hat{\\beta} = -\\frac{1}{D_0 t} \\ln\\left(1 - \\frac{T_t}{R_0}\\right) $$\n这就是 $\\beta$ 的闭式最大似然估计量。它在 $0 \\le T_t < R_0$ 的条件下是良定义的。\n\n为使该最大似然估计量 $\\hat{\\beta}$ 渐近无偏，所需的最小假设是：\n1. **生物学假设**：接合过程必须遵循指定的模型。这意味着细胞充分混合，每个受体的接合事件是独立的，并且所述条件（无生长、无死亡、无质粒丢失、供体密度恒定）是对现实的良好近似。\n2. **统计学假设**：初始受体细胞数量 $N_R$ 必须很大。最大似然估计量的渐近性质在大样本量极限下成立，此处的样本量即为 $N_R \\to \\infty$。在这些条件下，$\\hat{\\beta}$ 的分布收敛于一个以 $\\beta$ 的真实值为中心的正态分布。\n\n稀有事件近似产生一个一阶估计量。这个机制对应于接合概率很小的情况，即当乘积 $\\beta D_0 t$ 很小时。在这种情况下，我们预期转接合子比例 $T_t/R_0$ 会很小。我们使用自然对数的泰勒展开式，对于小的 $x$，有 $\\ln(1-x) \\approx -x$。令 $x = T_t/R_0$：\n$$ \\hat{\\beta} \\approx -\\frac{1}{D_0 t} \\left(-\\frac{T_t}{R_0}\\right) = \\frac{T_t}{R_0 D_0 t} $$\n这是常用的一阶估计量。为使该估计量无偏，其期望值必须等于真实参数 $\\beta$。观测密度 $T_t$ 的期望值是模型的预测值 $E[T_t] = R_0 (1 - \\exp(-\\beta D_0 t))$。\n$$ E\\left[\\frac{T_t}{R_0 D_0 t}\\right] = \\frac{E[T_t]}{R_0 D_0 t} = \\frac{R_0 (1 - \\exp(-\\beta D_0 t))}{R_0 D_0 t} = \\frac{1 - \\exp(-\\beta D_0 t)}{D_0 t} $$\n将其设为等于 $\\beta$ 需要 $\\frac{1 - \\exp(-\\beta D_0 t)}{\\beta D_0 t} = 1$。此方程仅在 $\\beta D_0 t \\to 0$ 的极限情况下才成立。因此，一阶估计量仅在无限稀有事件的极限状态下是无偏的。对于任何有限的 $\\beta D_0 t > 0$，该估计量是有偏的，会低估 $\\beta$ 的真实值，因为对于 $z>0$，有 $1 - \\exp(-z) < z$。", "answer": "$$ \\boxed{-\\frac{1}{D_0 t} \\ln\\left(1 - \\frac{T_t}{R_0}\\right)} $$", "id": "2806039"}, {"introduction": "系统发育不一致性是推断水平基因转移事件的核心证据之一。本练习要求学生实现一个算法，用以量化基因树和物种树之间的拓扑差异 [@problem_id:2806011]。在简约性框架下，这个差异（通过“有根子树剪接和重嫁接”距离来衡量）直接对应于解释基因树与物种树冲突所需的最少转移事件数，是计算进化生物学中的一项核心技能。", "problem": "您的任务是形式化一个基于简约性的和解模型，用于处理基因树和物种树之间的水平基因转移。工作将完全在单拷贝设定下进行：每个物种在基因树中仅出现一次。在此模式下，如果只计算水平基因转移事件（不允许基因复制和丢失），将基因树与物种树进行和解所需的最小转移边数等于两棵有根树之间的有根子树剪接距离。\n\n从以下基本定义和事实开始：\n- 一棵有根、叶标记、严格二叉树，其每个内部节点都恰好有两个子节点，并有一个指定的根。每个叶节点都由一个物种名称标记。\n- 在只允许转移的单拷贝模式下，于简约性框架中将基因树与物种树进行和解，等同于最小化水平转移边的数量。当应用这些转移时，物种树的拓扑结构会转变为基因树的拓扑结构。这个数量等于有根子树剪接距离，即所需操作的最小次数。其中，一次操作指的是通过切断一条边来移除一个连通子树，并通过细分一个目标边（在该处创建一个新的内部节点）来重新连接它，从而保持树为有根严格二叉树。\n- 对于具有相同叶集合的有根树，在这种仅考虑转移的简约性设定下，每个转移事件都精确对应于一次有根子树剪接移动。\n\n您的任务是实现一个程序，该程序能够：\n- 解析以Newick字符串形式给出的、基于四个分类单元 $\\{A,B,C,D\\}$ 的共享叶集合的有根二叉树。\n- 计算将基因树与物种树进行和解所需的最小水平转移边数，该数量等于两棵树之间的有根子树剪接距离。\n\n您必须实现一个通用算法，通过广度优先搜索来探索有根子树剪接邻居的空间，以计算精确的最小距离。您的实现必须：\n- 将树表示为有根、严格二叉、叶标记的结构。\n- 通过剪去任意非根节点的子树，并将其重新连接到残余树的任意一条边（通过细分该边）或在残余树之上创建一个新根，来生成所有单步有根子树剪接邻居。通过将其剩余的子节点重新连接到其父节点，来移除因剪切而产生的任何度为1的内部节点，以保持树为有根严格二叉树。\n- 使用一种对有根树的规范、顺序无关的编码，以便在搜索过程中，仅因子节点顺序不同而等效的树被识别为同一棵树。\n\n测试套件中的所有输入都恰好涉及四个分类单元，并要求整数输出。不涉及物理单位或角度单位。最终输出必须是整数。\n\n测试套件：\n- 案例 $1$：物种树 $S_1 = \\text{\"((A,B),(C,D))\"}$，基因树 $G_1 = \\text{\"((A,B),(C,D))\"}$。预期的最小转移数是一个整数。\n- 案例 $2$：物种树 $S_2 = \\text{\"((A,B),(C,D))\"}$，基因树 $G_2 = \\text{\"(((A,B),C),D)\"}$。预期的最小转移数是一个整数。\n- 案例 $3$：物种树 $S_3 = \\text{\"((A,B),(C,D))\"}$，基因树 $G_3 = \\text{\"((A,C),(B,D))\"}$。预期的最小转移数是一个整数。\n- 案例 $4$：物种树 $S_4 = \\text{\"(((A,C),B),D)\"}$，基因树 $G_4 = \\text{\"(((A,B),C),D)\"}$。预期的最小转移数是一个整数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[r1,r2,r3,r4]”），其中 $r_i$ 是按上述顺序为案例 $i$ 计算出的最小转移边数。", "solution": "所提出的问题是计算系统发育学中一个明确定义的问题。它要求在一个特定的简约性模型下，计算将基因树与物种树进行和解所需的最小水平基因转移事件数。该模型将转移次数等同于两棵树之间的有根子树剪接（rSPR）距离。该问题在科学上是合理的、内容是自包含的，并且在算法上是可处理的，因为它涉及生物信息学中的既定概念。\n\n任务是在一个图中找到物种树 $S$ 和基因树 $G$ 之间的最短路径，该图的顶点代表给定叶集合上所有可能的有根严格二叉树拓扑，而边代表一次单独的rSPR操作。给定四个分类单元的叶集合 $\\{A, B, C, D\\}$，可能的树拓扑数量是有限的，具体为 $(2 \\times 4 - 3)!! = 5 \\times 3 \\times 1 = 15$。由于每次rSPR操作的统一成本为 $1$，因此该问题可以使用广度优先搜索（BFS）算法来解决。\n\n解决方案的核心组成部分如下：\n\n_1. 树的表示_：树被表示为一个相互连接的节点系统。每个节点都拥有指向其父节点和两个子节点的指针。叶节点通过一个分类单元标签（例如，'$A$'）来区分，而内部节点没有直接标签，而是由它们所根植的子树中所有叶标签的集合来定义。\n\n_2. 树的规范编码_：为了在搜索过程中管理状态空间，特别是用于识别已访问过的树，一个规范的表示是必要的。这种编码必须对任何内部节点的子节点排序保持不变。一个递归定义提供了这样的编码：\n- 叶节点的规范形式是其标签。\n- 内部节点的规范形式是通过首先获取其两个子节点 $c_1$ 和 $c_2$ 的规范形式来构建的。然后按字典序对这两个字符串进行排序，得到 $s_1$ 和 $s_2$，使得 $s_1 \\le s_2$。该内部节点的规范形式便是字符串 $\"(\" + s_1 + \",\" + s_2 + \")\"$.\n例如，一个结构为 $((D,C),(B,A))$ 的树将被规范化为 `\"((A,B),(C,D))\"`。\n\n_3. rSPR邻居生成_：BFS算法通过为给定树 $T$ 生成所有单步rSPR邻居来探索状态空间。此过程包括两个步骤：剪枝和嫁接。\n- _剪枝_：选择并切断连接父节点 $p$ 和非根子节点 $c$ 的边 $(p, c)$。这将分离出以 $c$ 为根的子树 $T_c$。节点 $p$ 现在只有一个子节点，将被移除：其剩余的子节点直接连接到 $p$ 的父节点（如果 $p$ 是根节点，则成为新的根）。这样就留下了一个残余树 $T'$。\n- _嫁接_：然后将被剪下的子树 $T_c$ 重新连接。有两种嫁接的可能性：\n    a. 细分残余树 $T'$ 中的一条现有边 $(u,v)$。一个新节点 $n$ 被插入到这条边上，成为 $v$ 的父节点。被剪下的子树 $T_c$ 作为 $n$ 的另一个子节点被连接。\n    b. 创建一个新根。为整棵树创建一个新的根节点，其两个子节点分别是残余树 $T'$ 的根和被剪下子树 $T_c$ 的根。\n\n_4. 广度优先搜索（BFS）_：BFS算法系统地寻找最短路径。\n- 用起始物种树和距离 $0$ 来初始化一个队列。\n- 一个集合 `visited` 用于存储已遇到树的规范形式，以防止重复计算。\n- 算法通过从队列中取出一棵树来进行，检查它是否是目标基因树。如果不是，则生成其所有唯一的rSPR邻居。\n- 任何其规范形式未被访问过的邻居，都将被添加到 `visited` 集合中，并以递增后的距离入队。\n- 当出队树的规范形式与目标基因树的规范形式匹配时，搜索终止。其关联的距离就是所需的最小转移次数。\n\n这种结构化的方法保证能够找到最短的rSPR距离，从而按要求正确地形式化了基于简约性的水平基因转移和解。该实现将首先将Newick字符串解析为基于节点的树结构，然后应用前述的BFS算法，并结合规范编码和邻居生成逻辑。", "answer": "```python\nimport collections\nimport copy\n\nclass Node:\n    \"\"\"Represents a node in a rooted binary tree.\"\"\"\n    def __init__(self, label=None):\n        self.label = label\n        self.parent = None\n        self.left = None\n        self.right = None\n\n    def __repr__(self):\n        if self.label:\n            return f\"Node('{self.label}')\"\n        return f\"Node(internal)\"\n\ndef parse_newick(newick_str):\n    \"\"\"\n    Parses a Newick string into a tree of Node objects.\n    This parser is designed for strictly binary trees.\n    \"\"\"\n    s = newick_str.strip()\n    if not s.startswith('('):\n        return Node(label=s)\n\n    # Remove outer parentheses\n    content = s[1:-1]\n    \n    # Find the split comma\n    balance = 0\n    split_idx = -1\n    for i, char in enumerate(content):\n        if char == '(':\n            balance += 1\n        elif char == ')':\n            balance -= 1\n        elif char == ',' and balance == 0:\n            split_idx = i\n            break\n            \n    left_str = content[:split_idx]\n    right_str = content[split_idx+1:]\n\n    parent_node = Node()\n    parent_node.left = parse_newick(left_str)\n    parent_node.right = parse_newick(right_str)\n    \n    # Set parent pointers\n    if parent_node.left:\n        parent_node.left.parent = parent_node\n    if parent_node.right:\n        parent_node.right.parent = parent_node\n        \n    return parent_node\n\ndef get_canonical_form(node):\n    \"\"\"\n    Computes a canonical, order-invariant string representation of the tree.\n    \"\"\"\n    if node.label:\n        return node.label\n    \n    left_form = get_canonical_form(node.left)\n    right_form = get_canonical_form(node.right)\n    \n    # Sort children's canonical forms lexicographically\n    if left_form > right_form:\n        left_form, right_form = right_form, left_form\n        \n    return f\"({left_form},{right_form})\"\n\ndef get_all_nodes(root):\n    \"\"\"Returns a list of all nodes in the tree via pre-order traversal.\"\"\"\n    nodes = []\n    stack = [root]\n    while stack:\n        node = stack.pop()\n        if node:\n            nodes.append(node)\n            stack.append(node.right)\n            stack.append(node.left)\n    return nodes\n    \ndef generate_spr_neighbors(root):\n    \"\"\"\n    Generates all unique rSPR neighbors for a given tree.\n    Returns a set of canonical forms of the neighbors.\n    \"\"\"\n    neighbors = set()\n    original_root_form = get_canonical_form(root)\n\n    # Get all nodes that can be pruned (any non-root node)\n    nodes_in_tree = get_all_nodes(root)\n    nodes_to_prune = [n for n in nodes_in_tree if n.parent is not None]\n\n    for node_to_prune in nodes_to_prune:\n        # --- 1. Prune step ---\n        # Deepcopy to create a mutable version of the tree for this prune operation\n        root_copy = copy.deepcopy(root)\n        \n        # Find the corresponding nodes in the copied tree\n        # This mapping is safe because deepcopy preserves structure\n        path_to_prune_node = []\n        curr = node_to_prune\n        while curr.parent:\n            if curr.parent.left == curr:\n                path_to_prune_node.append('L')\n            else:\n                path_to_prune_node.append('R')\n            curr = curr.parent\n        \n        pruned_node_copy = root_copy\n        for move in reversed(path_to_prune_node):\n            pruned_node_copy = pruned_node_copy.left if move == 'L' else pruned_node_copy.right\n\n        parent_copy = pruned_node_copy.parent\n        sibling_copy = parent_copy.left if parent_copy.right == pruned_node_copy else parent_copy.right\n        grandparent_copy = parent_copy.parent\n\n        # Perform wiring to suppress the degree-2 node\n        if grandparent_copy:\n            if grandparent_copy.left == parent_copy:\n                grandparent_copy.left = sibling_copy\n            else:\n                grandparent_copy.right = sibling_copy\n            sibling_copy.parent = grandparent_copy\n            residual_root = root_copy\n        else: # parent was the root\n            residual_root = sibling_copy\n            sibling_copy.parent = None\n        \n        pruned_subtree_root = pruned_node_copy\n        pruned_subtree_root.parent = None\n\n        # --- 2. Regraft step ---\n        # Get all edges in the residual tree\n        residual_nodes = get_all_nodes(residual_root)\n        edges_to_graft = []\n        for n in residual_nodes:\n            if n.parent is not None:\n                edges_to_graft.append((n.parent, n))\n\n        # a) Regraft by subdividing an edge\n        for p_graft, c_graft in edges_to_graft:\n            # Need fresh copies for each new topology\n            res_root_copy = copy.deepcopy(residual_root)\n            pruned_part_copy = copy.deepcopy(pruned_subtree_root)\n            \n            # Find the graft edge in the copied residual tree\n            path_to_child = []\n            curr = c_graft\n            while curr.parent:\n                if curr.parent.left == curr:\n                    path_to_child.append('L')\n                else:\n                    path_to_child.append('R')\n                curr = curr.parent\n\n            graft_child_copy = res_root_copy\n            for move in reversed(path_to_child):\n                graft_child_copy = graft_child_copy.left if move == 'L' else graft_child_copy.right\n\n            graft_parent_copy = graft_child_copy.parent\n\n            # Create new node and insert\n            new_node = Node()\n            new_node.left = graft_child_copy\n            new_node.right = pruned_part_copy\n            graft_child_copy.parent = new_node\n            pruned_part_copy.parent = new_node\n            \n            if graft_parent_copy.left == graft_child_copy:\n                graft_parent_copy.left = new_node\n            else:\n                graft_parent_copy.right = new_node\n            new_node.parent = graft_parent_copy\n            \n            new_tree_form = get_canonical_form(res_root_copy)\n            if new_tree_form != original_root_form:\n                 neighbors.add(new_tree_form)\n\n        # b) Regraft above the residual root\n        new_root = Node()\n        new_root.left = residual_root\n        new_root.right = pruned_subtree_root\n        residual_root.parent = new_root\n        pruned_subtree_root.parent = new_root\n        \n        new_tree_form = get_canonical_form(new_root)\n        if new_tree_form != original_root_form:\n            neighbors.add(new_tree_form)\n\n    return neighbors\n\ndef solve():\n    test_cases = [\n        (\"((A,B),(C,D))\", \"((A,B),(C,D))\"),\n        (\"((A,B),(C,D))\", \"(((A,B),C),D)\"),\n        (\"((A,B),(C,D))\", \"((A,C),(B,D))\"),\n        (\"(((A,C),B),D)\", \"(((A,B),C),D)\")\n    ]\n\n    results = []\n    for species_str, gene_str in test_cases:\n        species_tree = parse_newick(species_str)\n        gene_tree = parse_newick(gene_str)\n\n        start_form = get_canonical_form(species_tree)\n        target_form = get_canonical_form(gene_tree)\n\n        if start_form == target_form:\n            results.append(0)\n            continue\n\n        # BFS for shortest path\n        queue = collections.deque([(start_form, species_tree, 0)])\n        visited = {start_form}\n\n        distance = -1\n        while queue:\n            current_form, current_tree, dist = queue.popleft()\n\n            if current_form == target_form:\n                distance = dist\n                break\n\n            neighbor_forms = generate_spr_neighbors(current_tree)\n            \n            for neighbor_form in neighbor_forms:\n                if neighbor_form not in visited:\n                    visited.add(neighbor_form)\n                    # We need the tree structure to generate the next layer of neighbors\n                    neighbor_tree = parse_newick(neighbor_form)\n                    queue.append((neighbor_form, neighbor_tree, dist + 1))\n        \n        results.append(distance)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2806011"}, {"introduction": "水平基因转移常常会在宿主基因组中留下可检测的组成特征“足迹”，例如GC含量和密码子使用的异常。本练习指导学生设计一个动态规划算法，基于这些基因组特征对染色体进行分段，从而以统计上严谨的方式识别潜在的“基因组岛” [@problem_id:2805995]。这是变点检测方法在现代基因组学中的一个重要实际应用，有助于从大规模测序数据中发掘HGT事件。", "problem": "设计并实现一个程序，该程序对一维双特征基因组窗口序列执行变点分割，以使用统计学上合理的准则来识别候选的水平转移基因组岛。其生物学基础如下。水平基因转移将 DNA 片段引入宿主基因组，由于不同的突变偏好和选择机制（与分子生物学中心法则 DNA → RNA → 蛋白质 一致），这些片段的碱基组成和密码子使用通常会偏离基因组背景。能够捕捉这些偏差的两个稳健的窗口级特征是鸟嘌呤-胞嘧啶 (GC) 含量和密码子使用偏好度量（密码子偏好，CB）。这些特征在同质基因组区域内可被建模为近似平稳的，而在对应于潜在基因组岛的片段中则发生偏移。\n\n从一个基本的统计建模基础出发，我们为观测到的特征序列假设以下生成模型。设有 $n$ 个窗口，索引为 $i \\in \\{1,\\dots,n\\}$。对于每个窗口 $i$，我们观测到一个特征向量 $x_i \\in \\mathbb{R}^2$，其两个分量分别是 GC 含量和密码子偏好。基因组被划分为 $K$ 个连续的片段，其断点 $1 \\le \\tau_1 < \\tau_2 < \\cdots < \\tau_{K-1} < n$ 未知。对于每个包含索引 $i \\in \\{\\tau_{s-1}+1,\\dots,\\tau_s\\}$ 的片段 $s \\in \\{1,\\dots,K\\}$（其中 $\\tau_0 = 0$ 且 $\\tau_K = n$），数据服从一个多元正态分布，该分布具有片段特有的均值和共享的协方差：\n$$\nx_i \\mid s \\sim \\mathcal{N}(\\mu_s, \\Sigma), \\quad \\mu_s \\in \\mathbb{R}^2, \\quad \\Sigma \\in \\mathbb{R}^{2 \\times 2} \\text{ positive definite, independent of } s.\n$$\n在实际分析中，$\\Sigma$ 是未知的，应使用无偏样本协方差从整个序列中估计，并为保证数值稳定性，添加一个小的岭正则化项 $\\epsilon I_2$，其中 $I_2$ 表示 $2 \\times 2$ 的单位矩阵，$\\epsilon > 0$ 是一个非常小的值。\n\n使用此模型，通过在片段均值 $\\{\\mu_s\\}$ 下最大化高斯对数似然，同时使用贝叶斯信息准则 (BIC) 惩罚模型复杂度，来定义一个选择 $K$ 和断点 $\\{\\tau_s\\}$ 的统计准则。具体来说，在维度 $d = 2$ 的情况下，对自由均值参数的数量进行与 $K$ 呈线性关系的惩罚，每个片段的惩罚项为：\n$$\n\\gamma = \\frac{1}{2} d \\log n.\n$$\n你的程序必须计算出带惩罚的目标函数在所有满足最小片段长度约束 $m_{\\min} \\in \\mathbb{N}$ 的分割方案中的精确最大化子：\n- 对于一个跨越索引 $a+1,\\dots,b$ 且长度为 $\\ell = b-a$ 的候选片段，令 $\\bar{x}_{a:b} = \\frac{1}{\\ell}\\sum_{i=a+1}^b x_i$ 表示其经验均值。证明在对 $\\mu_s$ 最大化高斯似然后，该片段对未加惩罚的目标函数的贡献可以写为（不计一个与分割无关的加性常数）：\n$$\nS(a,b) = \\ell \\, \\bar{x}_{a:b}^{\\top} \\Sigma^{-1} \\bar{x}_{a:b}.\n$$\n- 因此，需要最大化的总体带惩罚的目标函数为：\n$$\n\\sum_{s=1}^K S(\\tau_{s-1}, \\tau_s) - \\gamma K,\n$$\n约束条件为对所有 $s$ 都有 $\\tau_s - \\tau_{s-1} \\ge m_{\\min}$。\n\n算法要求：\n- 实现一个运行时间为 $\\mathcal{O}(n^2)$ 的精确动态规划算法，以找到最优集合 $\\{\\tau_s\\}_{s=1}^{K-1}$ 和 $K$。使用累积和方法，确保对任意 $a<b$ 都能在 $\\mathcal{O}(1)$ 时间内计算 $S(a,b)$。\n- 使用无偏样本协方差从所有 $n$ 个观测值中估计 $\\Sigma$，并在求逆之前加上岭项 $\\epsilon I_2$，其中 $\\epsilon = 10^{-6}$。\n- 强制执行最小片段长度 $m_{\\min}$。\n- 以 0-based 索引的索引列表形式返回断点，其中索引 $i$ 处的断点表示在窗口 $i$ 和 $i+1$ 之间发生变化。例如，对于 $n=180$ 个窗口，分割成长度为 $[60,40,80]$ 的片段对应于断点 $[59,99]$。\n\n测试套件的数据生成：\n- 对于每个测试用例，根据模型合成数据：对每个片段 $s$，从 $\\mathcal{N}(\\mu_s, \\Sigma_{\\text{true}})$ 中抽取独立样本并将其连接起来，其中 $\\Sigma_{\\text{true}}$ 是对角矩阵，对角线元素为指定的方差。使用给定的随机种子初始化一个可复现的伪随机数生成器。将特征顺序表示为 $(\\text{GC}, \\text{CB})$。\n- 对于每个测试用例，你的程序必须使用提供的参数在内部生成数据，使用指定的 $m_{\\min}$ 运行分割算法，并输出断点。\n\n测试套件（五个用例）：\n- 用例 1 (理想情况；一个岛):\n  - 片段长度: $[60,40,80]$。\n  - 片段均值: $[(0.36,0.48),(0.52,0.62),(0.37,0.49)]$。\n  - 真实协方差 (对角方差): $[0.0004,0.0004]$。\n  - 最小片段长度: $5$。\n  - 种子: $7$。\n- 用例 2 (无变化；应倾向于单个片段):\n  - 片段长度: $[150]$。\n  - 片段均值: $[(0.40,0.55)]$。\n  - 真实协方差 (对角方差): $[0.0009,0.0009]$。\n  - 最小片段长度: $5$。\n  - 种子: $11$。\n- 用例 3 (多个岛；交替组成):\n  - 片段长度: $[50,30,40,25,35]$。\n  - 片段均值: $[(0.38,0.50),(0.50,0.60),(0.39,0.51),(0.53,0.63),(0.38,0.49)]$。\n  - 真实协方差 (对角方差): $[0.0004,0.0004]$。\n  - 最小片段长度: $5$。\n  - 种子: $13$。\n- 用例 4 (对比度弱；通常应拒绝额外的片段):\n  - 片段长度: $[80,30,70]$。\n  - 片段均值: $[(0.40,0.55),(0.41,0.56),(0.40,0.55)]$。\n  - 真实协方差 (对角方差): $[0.0009,0.0009]$。\n  - 最小片段长度: $5$。\n  - 种子: $17$。\n- 用例 5 (短序列；小岛):\n  - 片段长度: $[6,3,3]$。\n  - 片段均值: $[(0.36,0.48),(0.52,0.62),(0.36,0.48)]$。\n  - 真实协方差 (对角方差): $[0.0004,0.0004]$。\n  - 最小片段长度: $3$。\n  - 种子: $19$。\n\n角度或物理单位不适用。此问题中的所有概率和分数必须表示为小数（例如，$0.40$ 而不是百分比）。\n\n程序输入输出规范：\n- 程序不得读取任何输入，并且必须使用上述参数在内部生成合成数据集。\n- 你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，列表内是所有测试用例的结果。每个元素对应一个测试用例，其本身也是一个由方括号括起来的逗号分隔列表，包含该用例的 0-based 断点索引。例如，一个有效的输出可能看起来像 `[[59,99],[],[50,90,115],[],[5,8]]`，其中 `[]` 表示一个空列表，但你的程序必须打印不带空格的实际整数，并在没有断点的情况下使用空列表。", "solution": "提出的问题经过了严格验证，并被证实是有效的。它在统计遗传学方面有科学依据，是良定的，并且为获得唯一的、可计算的解所需的所有参数均已提供。因此，我们可以着手解决。\n\n目标是找到一组断点 $\\{\\tau_s\\}_{s=0}^K$（其中 $\\tau_0=0$ 且 $\\tau_K=n$），将一个包含 $n$ 个二维特征向量的序列 $\\{x_i\\}_{i=1}^n$ 分割成 $K$ 个连续的片段。此分割必须最大化带惩罚的目标函数：\n$$\n\\mathcal{O}(\\{\\tau_s\\}) = \\sum_{s=1}^K S(\\tau_{s-1}, \\tau_s) - \\gamma K\n$$\n其中，从索引 $a+1$ 到 $b$ 的片段得分 $S(a,b)$ 和惩罚项 $\\gamma$ 在问题描述中已定义。分割受到最小片段长度 $m_{\\min}$ 的约束，即对于所有 $s=1, \\dots, K$，都有 $\\tau_s - \\tau_{s-1} \\ge m_{\\min}$。\n\n首先，我们必须推导出片段得分 $S(a,b)$ 的表达式。片段 $s$（从索引 $a+1$ 到 $b$）中的数据 $x_i$ 被建模为从多元正态分布 $\\mathcal{N}(\\mu_s, \\Sigma)$ 中的抽样。该片段的对数似然为：\n$$\n\\log\\mathcal{L}_s(\\mu_s) = \\sum_{i=a+1}^{b} \\log p(x_i \\mid \\mu_s, \\Sigma) = \\sum_{i=a+1}^{b} \\left( C - \\frac{1}{2}(x_i - \\mu_s)^\\top \\Sigma^{-1} (x_i - \\mu_s) \\right)\n$$\n其中 $C = -\\frac{d}{2}\\log(2\\pi) - \\frac{1}{2}\\log|\\Sigma|$ 是一个不依赖于 $\\mu_s$ 的常数。为了对 $\\mu_s$ 最大化此似然，我们必须最小化二次型之和。对 $\\mu_s$ 求梯度并令其为零，可以得到均值的最大似然估计 (MLE)，即该片段的样本均值：\n$$\n\\hat{\\mu}_s = \\frac{1}{b-a} \\sum_{i=a+1}^{b} x_i = \\bar{x}_{a:b}\n$$\n将 $\\hat{\\mu}_s$ 代回对数似然函数，得到该片段的最大化似然值：\n$$\n\\log\\mathcal{L}_s^* = \\max_{\\mu_s} \\log\\mathcal{L}_s(\\mu_s) = (b-a)C - \\frac{1}{2} \\sum_{i=a+1}^{b} (x_i - \\bar{x}_{a:b})^\\top \\Sigma^{-1} (x_i - \\bar{x}_{a:b})\n$$\n二次项可以展开为：\n$$\n\\sum_{i=a+1}^{b} (x_i - \\bar{x}_{a:b})^\\top \\Sigma^{-1} (x_i - \\bar{x}_{a:b}) = \\left(\\sum_{i=a+1}^{b} x_i^\\top \\Sigma^{-1} x_i\\right) - (b-a) \\bar{x}_{a:b}^\\top \\Sigma^{-1} \\bar{x}_{a:b}\n$$\n对于一个划分 $\\{\\tau_s\\}$，其总的未加惩罚的目标是所有片段的最大化对数似然之和，即 $\\sum_{s=1}^K \\log\\mathcal{L}_s^*$：\n$$\n\\sum_{s=1}^K \\log\\mathcal{L}_s^* = \\sum_{s=1}^K \\left[ (b_s-a_s)C - \\frac{1}{2} \\left( \\left(\\sum_{i=a_s+1}^{b_s} x_i^\\top \\Sigma^{-1} x_i\\right) - (b_s-a_s) \\bar{x}_{a_s:b_s}^\\top \\Sigma^{-1} \\bar{x}_{a_s:b_s} \\right) \\right]\n$$\n其中 $(a_s, b_s) = (\\tau_{s-1}, \\tau_s)$。重新整理并使用记号 $S(a,b) = (b-a)\\bar{x}_{a:b}^\\top\\Sigma^{-1}\\bar{x}_{a:b}$ 和 $\\ell_s=b_s-a_s$ 可得：\n$$\n\\sum_{s=1}^K \\log\\mathcal{L}_s^* = nC - \\frac{1}{2} \\sum_{i=1}^{n} x_i^\\top \\Sigma^{-1} x_i + \\frac{1}{2} \\sum_{s=1}^K S(\\tau_{s-1}, \\tau_s)\n$$\n项 $nC$ 和 $\\sum_{i=1}^{n} x_i^\\top \\Sigma^{-1} x_i$ 相对于划分的选择是常数。因此，最大化未加惩罚的对数似然等价于最大化 $\\sum_{s=1}^K S(\\tau_{s-1}, \\tau_s)$。问题中定义的带惩罚目标 $\\sum S - \\gamma K$ 是变点分析中的一种标准形式。这证实了使用 $S(a,b)$ 作为片段质量得分核心的有效性。\n\n这个优化问题可以通过动态规划精确求解。令 $dp[j]$ 为包含前 $j$ 个窗口的数据前缀 $\\{x_1, \\dots, x_j\\}$ 的一个分割所能得到的带惩罚目标的最大值。我们要求解 $dp[n]$。通过考虑倒数第二个片段所有可能的终点 $i$（此时最后一个片段从 $i+1$ 延伸到 $j$），可以推导出递推关系。\n$$\ndp[j] = \\max_{0 \\le i < j, \\, j-i \\ge m_{\\min}} \\left\\{ dp[i] + S(i, j) - \\gamma \\right\\}\n$$\n这里的 $S(i,j)$ 中的索引 $i$ 和 $j$ 指的是从 $0$ 到 $n$ 的 0-based 序列索引，因此从 $i$ 到 $j-1$ 的片段长度为 $j-i$。基本情况是 $dp[0]=0$，表示一个得分为零的空前缀。每向划分中增加一个片段，就会产生一次惩罚 $\\gamma$。\n\n该算法流程如下：\n1. 对每个测试用例，使用指定的片段长度、均值、协方差和随机种子生成总长度为 $n$ 的数据序列 $X = (x_0, \\dots, x_{n-1})$。\n2. 估计共享的协方差矩阵 $\\Sigma$。首先，计算整个序列 $X$ 的无偏样本协方差。然后，为保证数值稳定性，加上一个小的岭正则化项 $\\epsilon I_2$，其中 $\\epsilon=10^{-6}$。最后，计算其逆矩阵 $\\Sigma^{-1}$。\n3. 计算惩罚项 $\\gamma = \\frac{1}{2}d\\log n = \\log n$，因为特征维度 $d=2$。\n4. 为了能以 $\\mathcal{O}(1)$ 的时间复杂度计算片段得分，预先计算特征向量的累积和。令 $C_X[k] = \\sum_{l=0}^{k-1} x_l$。那么从索引 $i$ 到 $j-1$ 的片段中的向量和为 $C_X[j] - C_X[i]$。此长度为 $\\ell=j-i$ 的片段得分 $S(i, j)$ 即可表示为 $\\frac{1}{\\ell} (C_X[j]-C_X[i])^\\top \\Sigma^{-1} (C_X[j]-C_X[i])$。\n5. 初始化两个大小为 $n+1$ 的数组：`dp` 用于存储最大得分，`ptr` 用于存储回溯指针以重建最优划分。设置 $dp[0]=0$，所有其他的 $dp[j]$ 设为 $-\\infty$。\n6. 从 1 到 $n$ 迭代 $j$。对每个 $j$，从 $0$ 到 $j - m_{\\min}$ 迭代 $i$。计算以片段 $[i, j-1]$ 结尾的新划分的得分：`score = dp[i] + S(i, j) - gamma`。如果此得分大于当前的 $dp[j]$，则更新 $dp[j]$ 为 `score` 并设置 $ptr[j] = i$。\n7. 动态规划表填充完毕后，从 $ptr[n]$ 开始回溯以重建最优断点。从 `curr = n` 开始，重复找到前一个断点 `prev = ptr[curr]`，并将 `prev-1` 添加到断点列表中（如果 `prev > 0`）。将列表反转以获得最终排好序的断点。此过程也隐式地确定了最优的片段数 $K$。\n\n由于对 $j$ 和 $i$ 的嵌套循环，该动态规划算法的时间复杂度为 $\\mathcal{O}(n^2)$，存储动态规划表的空间复杂度为 $\\mathcal{O}(n)$。在给定的约束条件下，这是计算上可行的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the change-point segmentation for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"lengths\": [60, 40, 80],\n            \"means\": [(0.36, 0.48), (0.52, 0.62), (0.37, 0.49)],\n            \"variances\": [0.0004, 0.0004],\n            \"m_min\": 5,\n            \"seed\": 7,\n        },\n        {\n            \"lengths\": [150],\n            \"means\": [(0.40, 0.55)],\n            \"variances\": [0.0009, 0.0009],\n            \"m_min\": 5,\n            \"seed\": 11,\n        },\n        {\n            \"lengths\": [50, 30, 40, 25, 35],\n            \"means\": [(0.38, 0.50), (0.50, 0.60), (0.39, 0.51), (0.53, 0.63), (0.38, 0.49)],\n            \"variances\": [0.0004, 0.0004],\n            \"m_min\": 5,\n            \"seed\": 13,\n        },\n        {\n            \"lengths\": [80, 30, 70],\n            \"means\": [(0.40, 0.55), (0.41, 0.56), (0.40, 0.55)],\n            \"variances\": [0.0009, 0.0009],\n            \"m_min\": 5,\n            \"seed\": 17,\n        },\n        {\n            \"lengths\": [6, 3, 3],\n            \"means\": [(0.36, 0.48), (0.52, 0.62), (0.36, 0.48)],\n            \"variances\": [0.0004, 0.0004],\n            \"m_min\": 3,\n            \"seed\": 19,\n        },\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # 1. Generate synthetic data\n        rng = np.random.default_rng(case[\"seed\"])\n        segments_data = []\n        cov_true = np.diag(case[\"variances\"])\n        for length, mean in zip(case[\"lengths\"], case[\"means\"]):\n            segment = rng.multivariate_normal(mean, cov_true, size=length)\n            segments_data.append(segment)\n        \n        X = np.concatenate(segments_data, axis=0)\n        n, d = X.shape\n        m_min = case[\"m_min\"]\n\n        # 2. Estimate shared covariance and penalty\n        if n > 1:\n            cov_est = np.cov(X, rowvar=False, ddof=1)\n        else: # Handle case with a single data point\n             cov_est = np.zeros((d,d))\n\n        epsilon = 1e-6\n        sigma_reg = cov_est + epsilon * np.identity(d)\n        sigma_inv = np.linalg.inv(sigma_reg)\n        \n        gamma = d / 2.0 * np.log(n) if n > 0 else 0\n\n        # 3. Pre-compute cumulative sums\n        # cum_sums[k] stores sum of x_0 to x_{k-1}\n        cum_sums = np.zeros((n + 1, d))\n        cum_sums[1:] = np.cumsum(X, axis=0)\n        \n        # 4. Dynamic Programming\n        dp = np.full(n + 1, -np.inf)\n        pointers = np.zeros(n + 1, dtype=int)\n        dp[0] = 0\n\n        for j in range(1, n + 1):\n            for i in range(j):\n                length = j - i\n                if length >= m_min:\n                    # Calculate S(i, j)\n                    sum_vec = cum_sums[j] - cum_sums[i]\n                    # S(a,b) = l * x_bar.T * Sigma_inv * x_bar\n                    #      = l * (sum/l).T * Sigma_inv * (sum/l)\n                    #      = (1/l) * sum.T * Sigma_inv * sum\n                    s_ij = (1.0 / length) * (sum_vec.T @ sigma_inv @ sum_vec)\n                    \n                    score = dp[i] + s_ij - gamma\n                    if score > dp[j]:\n                        dp[j] = score\n                        pointers[j] = i\n\n        # 5. Backtrack to find breakpoints\n        breakpoints = []\n        current_idx = n\n        while current_idx > 0:\n            prev_idx = pointers[current_idx]\n            if prev_idx > 0:\n                # Breakpoint is between (prev_idx - 1) and prev_idx\n                breakpoints.append(prev_idx - 1)\n            current_idx = prev_idx\n            \n        breakpoints.sort()\n        all_results.append(breakpoints)\n\n    # Final print statement in the exact required format\n    results_str = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2805995"}]}