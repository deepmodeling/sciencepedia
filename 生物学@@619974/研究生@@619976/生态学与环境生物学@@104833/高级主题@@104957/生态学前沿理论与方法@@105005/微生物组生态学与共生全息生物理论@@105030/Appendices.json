{"hands_on_practices": [{"introduction": "分析微生物组数据的第一步，通常是量化单个样本内的多样性，即α多样性。本练习将指导您使用基于Hill数的“真实多样性”框架，将群落的丰度数据转换为一个直观的度量——有效物种数 ${}^{1}D$。通过这个计算，您可以将抽象的香农熵值转化为对群落均匀度的具体理解，这是生态学研究中的一项基本技能 [@problem_id:2509172]。", "problem": "为了量化一个珊瑚全息生物（即动物宿主及其相关的微生物共生体）肠道微生物组的宿主内（alpha）多样性，我们对其进行了取样。观察到四种占主导地位的细菌扩增子序列变体（ASVs），其计数分别为 $[40, 30, 20, 10]$，总计 $100$ 个读数。将这些计数视为单个宿主内每个ASV的个体丰度，并假设所有读数都已正确分配到这四个ASV。\n\n使用基于香农熵（使用自然对数，以自然单位衡量）的alpha多样性的信息论定义以及Hill数框架，计算该样本的阶数 $q=1$ 的有效物种数，记为 ${}^{1}D$。将最终答案表示为一个纯数（无量纲），并将结果四舍五入到四位有效数字。", "solution": "对问题陈述进行审查后，认定其是有效的。它在科学上基于生态学理论，在数学上是适定的，并为获得唯一解提供了所有必要的数据。我们可以进行计算。\n\n该问题要求根据一组给定的扩增子序列变体（ASV）计数，计算阶数 $q=1$ 的有效物种数，记为 ${}^{1}D$。该量是Hill数多样性指数家族中的一员。Hill数（或称阶数为 $q$ 的真实多样性）的通用公式如下：\n$$\n{}^{q}D = \\left( \\sum_{i=1}^{S} p_i^q \\right)^{\\frac{1}{1-q}}\n$$\n其中，$S$ 是物种（在本例中为ASV）的总数，$p_i$ 是第 $i$ 个物种的相对丰度。\n\n给定的四个ASV的计数为 $n_1 = 40$，$n_2 = 30$，$n_3 = 20$ 和 $n_4 = 10$。读数总数 $N$ 是这些计数的总和：\n$$\nN = \\sum_{i=1}^{4} n_i = 40 + 30 + 20 + 10 = 100\n$$\n这与问题陈述中提供的值一致。ASV的数量为 $S=4$。\n\n相对丰度 $p_i = n_i/N$ 计算如下：\n$$\np_1 = \\frac{40}{100} = 0.4\n$$\n$$\np_2 = \\frac{30}{100} = 0.3\n$$\n$$\np_3 = \\frac{20}{100} = 0.2\n$$\n$$\np_4 = \\frac{10}{100} = 0.1\n$$\n这些相对丰度的总和必须等于 $1$：$\\sum_{i=1}^{4} p_i = 0.4 + 0.3 + 0.2 + 0.1 = 1.0$。\n\n由于指数中存在 $1/(1-q)$ 这一项，${}^{q}D$ 的通用公式在 $q=1$ 时是未定义的。为了求得 ${}^{1}D$ 的值，我们必须计算当 $q \\to 1$ 时该表达式的极限。该极限产生一个与香农熵相关的结果。香农熵 $H'$ 定义为：\n$$\nH' = - \\sum_{i=1}^{S} p_i \\ln(p_i)\n$$\n阶数 $q=1$ 的Hill数是香non熵的指数：\n$$\n{}^{1}D = \\lim_{q \\to 1} {}^{q}D = \\exp(H') = \\exp\\left(-\\sum_{i=1}^{S} p_i \\ln(p_i)\\right)\n$$\n这个度量 ${}^{1}D$ 被解释为：产生与观测样本相同的香农熵值所需的等丰度物种的数量。\n\n现在，我们根据指定的自然对数，为给定的相对丰度计算香农熵 $H'$。\n$$\nH' = - \\left( p_1 \\ln(p_1) + p_2 \\ln(p_2) + p_3 \\ln(p_3) + p_4 \\ln(p_4) \\right)\n$$\n$$\nH' = - \\left( 0.4 \\ln(0.4) + 0.3 \\ln(0.3) + 0.2 \\ln(0.2) + 0.1 \\ln(0.1) \\right)\n$$\n数值计算各项：\n$$\n0.4 \\ln(0.4) \\approx 0.4 \\times (-0.9162907) \\approx -0.3665163\n$$\n$$\n0.3 \\ln(0.3) \\approx 0.3 \\times (-1.2039728) \\approx -0.3611918\n$$\n$$\n0.2 \\ln(0.2) \\approx 0.2 \\times (-1.6094379) \\approx -0.3218876\n$$\n$$\n0.1 \\ln(0.1) \\approx 0.1 \\times (-2.3025851) \\approx -0.2302585\n$$\n将这些值相加：\n$$\n\\sum_{i=1}^{4} p_i \\ln(p_i) \\approx -0.3665163 - 0.3611918 - 0.3218876 - 0.2302585 = -1.2798542\n$$\n因此，香农熵为：\n$$\nH' = -(-1.2798542) = 1.2798542\n$$\n现在，我们计算有效物种数 ${}^{1}D$：\n$$\n{}^{1}D = \\exp(H') = \\exp(1.2798542)\n$$\n$$\n{}^{1}D \\approx 3.596093\n$$\n问题要求将结果四舍五入到四位有效数字。前四位有效数字是 $3$、$5$、$9$ 和 $6$。第五位数字是 $0$，所以我们不进位。\n$$\n{}^{1}D \\approx 3.596\n$$\n该值表示阶数为 $1$ 的真实多样性，以样本中有效ASV的数量来衡量。它是一个无量纲的量。", "answer": "$$\n\\boxed{3.596}\n$$", "id": "2509172"}, {"introduction": "要准确比较不同样本中的微生物组构成，必须首先处理高通量测序数据固有的成分性（compositionality）问题。中心对数比（CLR）变换是一种关键方法，它能将相对丰度数据映射到一个不受单位和总和约束的空间中，以便进行稳健的统计分析。此练习将让您亲手计算CLR值，并理解在处理数据中的零值时所用伪计数（pseudocount）的重要性和影响 [@problem_id:2509199]。", "problem": "一个珊瑚全息生物体被建模为一个宿主及其相关的微生物群落，由于测序的限制，其分类单元计数是成分性的。对两个单独的宿主（表示为样本 $\\mathrm{H}_1$ 和样本 $\\mathrm{H}_2$）就相同的 $D=4$ 个细菌分类单元 $\\{T_1,T_2,T_3,T_4\\}$ 进行了调查。观测到的计数向量（单位为读数）为：\n- $\\mathrm{H}_1$: $\\big(0,\\;30,\\;10,\\;10\\big)$\n- $\\mathrm{H}_2$: $\\big(5,\\;15,\\;0,\\;20\\big)$\n\n因为零的存在使得无法取对数，所以为每个计数添加了 $\\alpha=0.5$ 的伪计数。使用成分数据分析中的中心对数比（CLR）变换，样本 $s$ 中分类单元 $i$ 的变换值定义如下\n$$\n\\mathrm{CLR}_i^{(s)} \\;=\\; \\ln\\!\\left(\\frac{x_i^{(s)}+\\alpha}{g\\!\\left(\\mathbf{x}^{(s)}+\\alpha\\mathbf{1}\\right)}\\right),\n$$\n其中 $\\mathbf{x}^{(s)}=(x_1^{(s)},\\dots,x_D^{(s)})$ 是样本 $s$ 的计数向量，$\\mathbf{1}$ 是 $D$ 维全1向量，而 $g(\\cdot)$ 是几何平均值，$g(\\mathbf{z})=\\left(\\prod_{j=1}^D z_j\\right)^{1/D}$。\n\n仅从成分数据和 CLR 变换的核心定义以及对数和相关性的标准性质出发，完成以下任务：\n1) 使用 $\\alpha=0.5$ 计算 $\\mathrm{H}_1$ 和 $\\mathrm{H}_2$ 的 CLR 变换向量。\n2) 计算两个 CLR 向量在分类单元间的皮尔逊相关系数，将这四个分类单元视为成对观测值。\n\n在你的推理过程中，请论证引入伪计数 $\\alpha$ 如何影响几何平均值并进而影响 CLR 值，并从机理上解释当零出现在不同分类单元中时，这种零值处理方法如何改变样本间下游相关性的符号和大小。将最终的相关系数表示为无单位的小数。将最终的数值答案四舍五入到 $4$ 位有效数字。", "solution": "该问题涉及来自两个珊瑚全息生物体样本的成分性微生物组计数数据。测序数据是成分性的，因为只保留了相对信息；中心对数比（CLR）变换是一种标准方法，通过计算相对于几何平均值的对数比，将成分从单纯形映射到实向量空间。计数中的零值使得无法取对数，因此在变换前，需向每个分量添加一个伪计数 $\\alpha0$。我们从核心定义开始。\n\n设分类单元数量 $D=4$。对于样本 $s\\in\\{\\mathrm{H}_1,\\mathrm{H}_2\\}$，其计数向量为 $\\mathbf{x}^{(s)}=(x_1^{(s)},\\dots,x_4^{(s)})$，定义伪计数调整后的向量为 $\\mathbf{z}^{(s)}=\\mathbf{x}^{(s)}+\\alpha\\mathbf{1}$，其分量为 $z_i^{(s)}=x_i^{(s)}+\\alpha$。几何平均值为\n$$\ng\\!\\left(\\mathbf{z}^{(s)}\\right)\\;=\\;\\left(\\prod_{j=1}^{4} z_j^{(s)}\\right)^{1/4}.\n$$\nCLR 分量为\n$$\n\\mathrm{CLR}_i^{(s)} \\;=\\; \\ln\\!\\left(\\frac{z_i^{(s)}}{g(\\mathbf{z}^{(s)})}\\right)\n\\;=\\; \\ln z_i^{(s)} \\;-\\; \\frac{1}{4}\\sum_{j=1}^4 \\ln z_j^{(s)}.\n$$\n根据定义，对于每个 $s$，都有 $\\sum_{i=1}^4 \\mathrm{CLR}_i^{(s)}=0$。\n\n步骤 1：使用 $\\alpha=0.5$ 计算 $\\mathrm{H}_1$ 和 $\\mathrm{H}_2$ 的 CLR 变换向量。\n\n对于 $\\mathrm{H}_1$，$\\mathbf{x}^{(\\mathrm{H}_1)}=(0,30,10,10)$，所以\n$$\n\\mathbf{z}^{(\\mathrm{H}_1)}=(0.5,\\;30.5,\\;10.5,\\;10.5).\n$$\n计算对数：\n$$\n\\ln z_1^{(\\mathrm{H}_1)}=\\ln 0.5=-0.6931471805599453,\n$$\n$$\n\\ln z_2^{(\\mathrm{H}_1)}=\\ln 30.5\\approx 3.417726683613366,\n$$\n$$\n\\ln z_3^{(\\mathrm{H}_1)}=\\ln z_4^{(\\mathrm{H}_1)}=\\ln 10.5\\approx 2.351375257163478.\n$$\n对数的均值为\n$$\n\\bar{\\ell}^{(\\mathrm{H}_1)}=\\frac{1}{4}\\sum_{j=1}^4 \\ln z_j^{(\\mathrm{H}_1)}=\\frac{-0.6931471805599453+3.417726683613366+2\\times 2.351375257163478}{4}\\approx 1.8568325043450942.\n$$\n因此 CLR 分量为\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_1)}=\\big(\\,-0.6931471805599453-\\bar{\\ell}^{(\\mathrm{H}_1)},\\;3.417726683613366-\\bar{\\ell}^{(\\mathrm{H}_1)},\\;2.351375257163478-\\bar{\\ell}^{(\\mathrm{H}_1)},\\;2.351375257163478-\\bar{\\ell}^{(\\mathrm{H}_1)}\\,\\big),\n$$\n即，\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_1)}\\approx\\big(-2.5499796849050395,\\;1.5608941792682718,\\;0.4945427528183837,\\;0.4945427528183837\\big).\n$$\n\n对于 $\\mathrm{H}_2$，$\\mathbf{x}^{(\\mathrm{H}_2)}=(5,15,0,20)$，所以\n$$\n\\mathbf{z}^{(\\mathrm{H}_2)}=(5.5,\\;15.5,\\;0.5,\\;20.5).\n$$\n计算对数：\n$$\n\\ln z_1^{(\\mathrm{H}_2)}=\\ln 5.5\\approx 1.7047480922384254,\n$$\n$$\n\\ln z_2^{(\\mathrm{H}_2)}=\\ln 15.5\\approx 2.740840023925201,\n$$\n$$\n\\ln z_3^{(\\mathrm{H}_2)}=\\ln 0.5=-0.6931471805599453,\n$$\n$$\n\\ln z_4^{(\\mathrm{H}_2)}=\\ln 20.5\\approx 3.020424886144363.\n$$\n对数的均值为\n$$\n\\bar{\\ell}^{(\\mathrm{H}_2)}=\\frac{1}{4}\\sum_{j=1}^4 \\ln z_j^{(\\mathrm{H}_2)}=\\frac{1.7047480922384254+2.740840023925201-0.6931471805599453+3.020424886144363}{4}\\approx 1.693216455437011.\n$$\n因此 CLR 分量为\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_2)}=\\big(\\,1.7047480922384254-\\bar{\\ell}^{(\\mathrm{H}_2)},\\;2.740840023925201-\\bar{\\ell}^{(\\mathrm{H}_2)},\\;-0.6931471805599453-\\bar{\\ell}^{(\\mathrm{H}_2)},\\;3.020424886144363-\\bar{\\ell}^{(\\mathrm{H}_2)}\\,\\big),\n$$\n即，\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_2)}\\approx\\big(0.011531636801414384,\\;1.0476235684881902,\\;-2.386363635996956,\\;1.3272084307073518\\big).\n$$\n\n步骤 2：计算两个 CLR 向量在分类单元间的皮尔逊相关系数。\n\n设 $\\mathbf{c}^{(1)}=\\mathrm{CLR}^{(\\mathrm{H}_1)}$ 且 $\\mathbf{c}^{(2)}=\\mathrm{CLR}^{(\\mathrm{H}_2)}$。跨 $4$ 个分类单元的皮尔逊相关系数为\n$$\nr \\;=\\; \\frac{\\sum_{i=1}^{4}\\left(c^{(1)}_i-\\bar{c}^{(1)}\\right)\\left(c^{(2)}_i-\\bar{c}^{(2)}\\right)}{\\sqrt{\\sum_{i=1}^{4}\\left(c^{(1)}_i-\\bar{c}^{(1)}\\right)^2}\\;\\sqrt{\\sum_{i=1}^{4}\\left(c^{(2)}_i-\\bar{c}^{(2)}\\right)^2}},\n$$\n其中 $\\bar{c}^{(s)}$ 是 $\\mathbf{c}^{(s)}$ 各分量的均值。对于任意 CLR 向量，$\\sum_{i=1}^4 c^{(s)}_i=0$，因此 $\\bar{c}^{(s)}=0$。故相关系数可简化为\n$$\nr \\;=\\; \\frac{\\sum_{i=1}^{4} c^{(1)}_i c^{(2)}_i}{\\sqrt{\\sum_{i=1}^{4}\\left(c^{(1)}_i\\right)^2}\\;\\sqrt{\\sum_{i=1}^{4}\\left(c^{(2)}_i\\right)^2}}.\n$$\n使用计算出的值：\n- 分子：\n$$\n\\sum_{i=1}^{4} c^{(1)}_i c^{(2)}_i \\approx\n(-2.5499796849050395)(0.011531636801414384) + (1.5608941792682718)(1.0476235684881902) \\\\\n+ (0.4945427528183837)(-2.386363635996956) + (0.4945427528183837)(1.3272084307073518)\n\\approx 1.0820246.\n$$\n- 分母项：\n$$\n\\sum_{i=1}^{4}\\left(c^{(1)}_i\\right)^2 \\approx (-2.5499796849050395)^2+(1.5608941792682718)^2+2\\times(0.4945427528183837)^2 \\approx 9.427928,\n$$\n$$\n\\sum_{i=1}^{4}\\left(c^{(2)}_i\\right)^2 \\approx (0.011531636801414384)^2+(1.0476235684881902)^2+(-2.386363635996956)^2+(1.3272084307073518)^2 \\approx 8.553857.\n$$\n因此，\n$$\nr \\;\\approx\\; \\frac{1.0820246}{\\sqrt{9.427928\\times 8.553857}} \\;\\approx\\; \\frac{1.0820246}{8.980264} \\;\\approx\\; 0.120489.\n$$\n四舍五入到 $4$ 位有效数字，相关系数为 $0.1205$。\n\n零值处理及其对相关性影响的概念性论证：在成分数据中，只有比率是有意义的。CLR 变换将每个分量映射为其与样本几何平均值的对数比：\n$$\n\\mathrm{CLR}_i^{(s)}=\\ln\\!\\left(x_i^{(s)}+\\alpha\\right) - \\frac{1}{D}\\sum_{j=1}^{D}\\ln\\!\\left(x_j^{(s)}+\\alpha\\right).\n$$\n引入伪计数 $\\alpha$ 会在对数尺度上非线性地移动所有分量。对于大计数 $x_i^{(s)}\\gg \\alpha$，变化量 $\\ln(x_i^{(s)}+\\alpha)-\\ln x_i^{(s)}\\approx \\alpha/x_i^{(s)}$ 很小，但对于零值和稀有分类单元 $x_i^{(s)}\\approx 0$，该项变为 $\\ln \\alpha$，这是一个相对于样本对数几何平均值的大负向偏移。由于几何平均值也依赖于所有的 $\\ln(x_j^{(s)}+\\alpha)$，添加 $\\alpha$ 会同时改变对数比的分子和分母，其中最大的影响来自稀疏的分类单元。\n\n在下游的样本间相关性分析中，协方差项 $\\sum_i c^{(1)}_i c^{(2)}_i$ 对于零值是否出现在跨样本的相同分类单元中非常敏感。如果一个分类单元在一个样本中为零但在另一个样本中不为零，其 CLR 项对于含零的样本往往具有相反的符号和较大的量级，从而产生一个大的负乘积，这会降低相关性。如果零值在跨样本的相同分类单元中同时出现，它们的大负值 CLR 值会相互对齐，从而增加对协方差的正向贡献。这些效应的大小取决于 $\\alpha$：较大的 $\\alpha$ 会减小零值的负 CLR 值的极端程度（从而减小其影响），而较小的 $\\alpha$ 则会加剧这种极端程度。因此，当零值在不同分类单元间的分布不同时，通过伪计数进行零值处理会直接调节 CLR 向量的尺度以及样本间相关性的符号和大小。", "answer": "$$\\boxed{0.1205}$$", "id": "2509199"}, {"introduction": "掌握了数据变换方法后，下一步便是探索多个微生物组样本之间的相似性与差异（即β多样性），并揭示其背后的环境驱动因素。主坐标分析（PCoA）是一种核心的降维和可视化技术，它能将复杂的样本间距离矩阵转化为直观的排序图。通过这个实践，您将学习从计算Bray-Curtis非相似性到执行PCoA，并最终将排序轴与环境梯度关联起来的完整分析流程 [@problem_id:2509183]。", "problem": "给定三个独立的测试用例，每个测试用例包含一个全息生物丰度表（样本×分类单元）和在相同样本上测量的相应环境梯度矩阵（样本×梯度）。您的任务是编写一个程序，为每个测试用例计算样本间的 Bray–Curtis 相异性，对该相异性矩阵执行主坐标分析（PCoA），并通过相关性分析，根据环境梯度来解释前两个 PCoA 轴。\n\n从以下基本原理开始：\n- 两个非负丰度向量 $\\mathbf{x}$ 和 $\\mathbf{y}$ 之间的 Bray–Curtis 相异性定义为\n$$\nd_{\\mathrm{BC}}(\\mathbf{x},\\mathbf{y}) \\;=\\; \\frac{\\sum_{k} \\left| x_k - y_k \\right|}{\\sum_{k} \\left( x_k + y_k \\right)},\n$$\n当 $\\sum_k \\left( x_k + y_k \\right) \\gt 0$ 时，该定义是明确的。\n- 主坐标分析（经典多维标度法）接受一个 $n \\times n$ 的距离矩阵 $\\mathbf{D}$，计算平方距离 $\\mathbf{D}^{(2)}$（其元素为 $D_{ij}^2$），并对其进行双重中心化以获得 Gram 矩阵\n$$\n\\mathbf{B} \\;=\\; -\\tfrac{1}{2} \\, \\mathbf{J} \\, \\mathbf{D}^{(2)} \\, \\mathbf{J}, \\quad \\text{with } \\mathbf{J} \\;=\\; \\mathbf{I}_n \\;-\\; \\tfrac{1}{n}\\mathbf{1}\\mathbf{1}^\\top,\n$$\n然后对 $\\mathbf{B}$ 进行特征分解，得到特征值 $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_n$ 和相应的标准正交特征向量。PCoA 坐标由 $\\mathbf{X} = \\mathbf{V}_+ \\, \\mathrm{diag}(\\sqrt{\\lambda_+})$ 给出，其中只使用正特征值 $\\lambda_+$ 及其特征向量 $\\mathbf{V}_+$。轴 $j$ 的解释变异比例为 $\\lambda_j \\big/ \\sum_{\\lambda_i \\gt 0} \\lambda_i$。\n- 为了根据环境梯度向量 $\\mathbf{g}$ 解释排序轴 $\\mathbf{a}$，使用 Pearson 积矩相关系数\n$$\nr(\\mathbf{a},\\mathbf{g}) \\;=\\; \\frac{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)\\left(g_i - \\bar{g}\\right)}{\\sqrt{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)^2} \\, \\sqrt{\\sum_{i=1}^n \\left(g_i - \\bar{g}\\right)^2}}.\n$$\n\n程序要求：\n- 对于每个测试用例，根据丰度表计算样本间的 Bray–Curtis 相异性矩阵，执行上述 PCoA，并提取前两个轴（如果正特征值少于两个，则将缺失的轴的解释比例视为 $0$，其得分视为空向量）。\n- 对于前两个轴的每一个，计算其与每个环境梯度（列）的 Pearson 相关性，并找到使绝对相关性最大化的梯度的索引。梯度使用基于 $0$ 的索引。如果绝对相关性出现平局，选择最小的梯度索引。报告所选梯度的带符号相关系数。\n- 将所有浮点输出四舍五入到 $6$ 位小数。输出中不包括物理单位；比例以小数形式报告，而非百分比。\n\n输出格式：\n- 对于每个测试用例，按以下顺序生成一个包含 $6$ 个元素的列表：\n  $[\\text{prop\\_axis1}, \\text{prop\\_axis2}, \\text{best\\_grad\\_idx\\_axis1}, \\text{best\\_grad\\_idx\\_axis2}, \\text{corr\\_axis1\\_best}, \\text{corr\\_axis2\\_best}]$，\n  其中 $\\text{prop\\_axis1}$ 和 $\\text{prop\\_axis2}$ 是 $[0,1]$ 范围内的浮点数， $\\text{best\\_grad\\_idx\\_axis1}$ 和 $\\text{best\\_grad\\_idx\\_axis2}$ 是整数，最后两个是 $\\left[-1,1\\right]$ 范围内的带符号相关系数（浮点数）。\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，形式为由逗号分隔的各用例列表的列表，并用一对总的方括号括起来。例如：\"[[...],[...],[...]]\"，不含空格。\n\n测试套件：\n- 测试用例 $1$（沿物理化学梯度的微生物组）：\n  - 丰度表 $\\mathbf{X}_1$（行是样本 $S_1$ 到 $S_5$，列是分类单元 $T_1$ 到 $T_4$）：\n    - $S_1$: $[60, 25, 10, 5]$\n    - $S_2$: $[50, 30, 15, 5]$\n    - $S_3$: $[30, 30, 25, 15]$\n    - $S_4$: $[15, 25, 30, 30]$\n    - $S_5$: $[5, 15, 30, 50]$\n  - 环境梯度 $\\mathbf{G}_1$，有两列，行序相同：\n    - 梯度 $0$（pH，无单位）：$[6.5, 6.8, 7.0, 7.2, 7.5]$\n    - 梯度 $1$（盐度，实用盐度单位视为数值）：$[31.0, 28.2, 26.4, 24.3, 22.1]$\n- 测试用例 $2$（膳食纤维梯度和微弱的温度变化）：\n  - 丰度表 $\\mathbf{X}_2$（行是样本 $S_1$ 到 $S_6$，列是分类单元 $T_1$ 到 $T_4$）：\n    - $S_1$: $[80, 30, 5, 5]$\n    - $S_2$: $[70, 25, 10, 5]$\n    - $S_3$: $[60, 20, 15, 5]$\n    - $S_4$: $[10, 15, 30, 45]$\n    - $S_5$: $[5, 10, 30, 55]$\n    - $S_6$: $[8, 12, 28, 42]$\n  - 环境梯度 $\\mathbf{G}_2$：\n    - 梯度 $0$（纤维，任意单位）：$[0.10, 0.20, 0.35, 0.70, 0.82, 0.95]$\n    - 梯度 $1$（温度，任意单位）：$[15.0, 15.5, 15.0, 16.0, 16.5, 16.0]$\n- 测试用例 $3$（重复样本和部分重叠的梯度）：\n  - 丰度表 $\\mathbf{X}_3$（行是样本 $S_1$ 到 $S_4$，列是分类单元 $T_1$ 到 $T_4$）：\n    - $S_1$: $[40, 30, 20, 10]$\n    - $S_2$: $[40, 30, 20, 10]$\n    - $S_3$: $[10, 20, 30, 40]$\n    - $S_4$: $[12, 18, 30, 40]$\n  - 环境梯度 $\\mathbf{G}_3$：\n    - 梯度 $0$（溶解氧，任意单位）：$[5.0, 5.0, 8.0, 8.2]$\n    - 梯度 $1$（深度，任意单位）：$[100.0, 100.0, 50.0, 55.0]$\n\n边界情况和决胜规则：\n- 如果正特征值少于 $2$ 个，则将缺失轴的解释比例设置为 $0$，并将其得分视为空向量，从而与任何梯度的相关性都为 $0$，最佳梯度索引为 $-1$。\n- 如果两个或更多梯度与某一轴的绝对相关性完全相同，则选择最小的梯度索引。\n\n您的程序必须实现所述的所有计算，并按顺序以 \"[[...],[...],[...]]\" 格式（无空格）准确打印一行，其中包含三个测试用例的结果。将所有浮点结果四舍五入到 $6$ 位小数。", "solution": "我们从相异性、排序和相关性的定义出发，构建一个有原则的计算方法，在全息生物框架内将微生物群落组成映射到环境梯度上。\n\n相异性的第一原理：对于给定的非负丰度向量 $\\mathbf{x}$ 和 $\\mathbf{y}$，我们使用 Bray–Curtis 相异性，\n$$\nd_{\\mathrm{BC}}(\\mathbf{x},\\mathbf{y}) \\;=\\; \\frac{\\sum_{k} \\left| x_k - y_k \\right|}{\\sum_{k} \\left( x_k + y_k \\right)}.\n$$\n这种相异性植根于生态学理论，因为它对相对丰度敏感，并忽略了共同缺失的情况。在算法上，对于一个大小为 $n \\times p$（样本×分类单元）的丰度矩阵 $\\mathbf{X}$，我们计算所有成对相异性，形成一个 $n \\times n$ 的矩阵 $\\mathbf{D}$，其元素为 $D_{ij} = d_{\\mathrm{BC}}(\\mathbf{X}_{i\\cdot}, \\mathbf{X}_{j\\cdot})$。在计算上，分子是 $\\sum_k \\left| X_{ik} - X_{jk} \\right|$，分母是 $\\sum_k \\left( X_{ik} + X_{jk} \\right)$，这可以简化为样本总和之和 $\\sum_k X_{ik} + \\sum_k X_{jk}$；如果两个总和都为零（在我们的测试套件中不会出现），则相异性可以定义为 $0$。\n\n从距离到欧几里得嵌入：主坐标分析通过对平方距离进行双重中心化，将距离转换为一个中心化的内积（Gram）矩阵，\n$$\n\\mathbf{B} \\;=\\; -\\tfrac{1}{2} \\, \\mathbf{J} \\, \\mathbf{D}^{(2)} \\, \\mathbf{J}, \\quad \\text{with } \\mathbf{J} \\;=\\; \\mathbf{I}_n \\;-\\; \\tfrac{1}{n}\\mathbf{1}\\mathbf{1}^\\top.\n$$\n这源于在中心化坐标系中连接欧几里得距离与内积的恒等式。对于像 Bray–Curtis 这样的非欧几里得相异性，$\\mathbf{B}$ 可能会有负特征值。标准的、经过充分测试的方法是只保留正特征值 $\\lambda_i \\gt 0$ 及其特征向量来构建坐标，\n$$\n\\mathbf{X} \\;=\\; \\mathbf{V}_+ \\, \\mathrm{diag}\\left( \\sqrt{\\lambda_+} \\right),\n$$\n其中 $\\mathbf{X}$ 的列是 PCoA 轴（主坐标）。轴 $j$ 的解释变异计算为 $\\lambda_j \\big/ \\sum_{\\lambda_i \\gt 0} \\lambda_i$，这会在谱的正值部分上产生一个在 $\\left[0,1\\right]$ 范围内、总和为 $1$ 的合适比例。如果正特征值少于两个，我们将缺失轴的解释比例定义为 $0$，轴得分定义为空向量。\n\n通过环境梯度解释轴：给定一个轴得分向量 $\\mathbf{a} \\in \\mathbb{R}^n$ 和一个环境梯度 $\\mathbf{g} \\in \\mathbb{R}^n$，我们计算 Pearson 相关系数\n$$\nr(\\mathbf{a},\\mathbf{g}) \\;=\\; \\frac{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)\\left(g_i - \\bar{g}\\right)}{\\sqrt{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)^2} \\, \\sqrt{\\sum_{i=1}^n \\left(g_i - \\bar{g}\\right)^2}},\n$$\n它在一个中心化和标准化的尺度上衡量线性关联。对于每个轴，我们选择具有最大绝对相关性的环境梯度，报告该梯度的基于 $0$ 的索引和带符号的相关系数。由于特征向量的方向（符号）是任意的，除非有参考，否则相关的符号在生态学上没有意义；因此，选择是基于绝对值，但报告的是带符号的值。如果轴的方差为零（例如，没有对应的正特征值），我们将其相关性定义为 $0$，并将最佳梯度索引设置为 $-1$。如果多个梯度在绝对相关性上打平，我们选择最小的索引以保持确定性。\n\n每个测试用例的算法步骤：\n1. 输入丰度矩阵 $\\mathbf{X}$ 和环境矩阵 $\\mathbf{G}$。\n2. 对每个样本对使用上述公式计算 Bray–Curtis 距离矩阵 $\\mathbf{D}$；强制执行对称性和对角线为零。\n3. 通过逐元素平方计算 $\\mathbf{D}^{(2)}$，然后进行双重中心化以获得 $\\mathbf{B} = -\\tfrac{1}{2} \\mathbf{J} \\mathbf{D}^{(2)} \\mathbf{J}$，其中 $\\mathbf{J} = \\mathbf{I} - \\frac{1}{n} \\mathbf{1}\\mathbf{1}^\\top$。\n4. 对 $\\mathbf{B}$ 进行特征分解，按降序对特征值排序，并只保留正特征值（大于一个小的数值容差）及相应的特征向量，以形成坐标矩阵 $\\mathbf{X}_{\\mathrm{PCoA}}$，其列由 $\\sqrt{\\lambda_i}$ 缩放。\n5. 如果存在，则将前两个轴的解释比例计算为 $\\lambda_1 / \\sum \\lambda_+$ 和 $\\lambda_2 / \\sum \\lambda_+$；否则，将缺失的比例设置为 $0$。\n6. 对于前两个轴中的每一个（如果缺失则为空向量），计算与 $\\mathbf{G}$ 的每一列的 Pearson 相关性。选择使绝对相关性最大化的梯度索引（通过最小索引解决平局）并记录该梯度的带符号相关值。如果轴得分是常数，将所有相关性定义为 $0$，最佳梯度索引定义为 $-1$。\n7. 将所有浮点结果四舍五入到 $6$ 位小数，并按要求的顺序组装每个测试用例的列表。\n8. 打印一行，其中包含一个带括号的、由逗号分隔的三个用例列表的列表，不含空格。\n\n支持该测试套件的生态学解释：\n- 测试用例 $1$ 模拟了沿物理化学梯度（pH 增加，盐度减少）的单调群落组成变化，通常会产生一个与这些梯度对齐的主导第一轴；两个梯度都信息丰富，但在数值上并非完全共线，因此可以通过绝对相关性找到唯一的最佳匹配。\n- 测试用例 $2$ 具有与膳食纤维含量相关的显著变化和微弱的温度变化，因此第一轴应主要与纤维梯度对齐。\n- 测试用例 $3$ 包含重复样本，这会导致零距离并可能降低维度；该方法对正特征值的处理和定义的回退机制确保了即使在某个轴不可用或较弱时也能产生稳健、确定性的输出。\n\n所有计算均遵循所述定义，不依赖快捷公式，四舍五入确保了用于评估的一致、可机检的输出。", "answer": "```python\nimport numpy as np\n\ndef bray_curtis_distance_matrix(X: np.ndarray) - np.ndarray:\n    \"\"\"\n    Compute the Bray-Curtis dissimilarity matrix for samples (rows) in X.\n    X: n_samples x n_features, nonnegative.\n    Returns: n_samples x n_samples symmetric matrix with zeros on diagonal.\n    \"\"\"\n    n = X.shape[0]\n    D = np.zeros((n, n), dtype=float)\n    # Precompute row sums to speed up denominator computation\n    row_sums = X.sum(axis=1)\n    for i in range(n):\n        xi = X[i]\n        sumi = row_sums[i]\n        for j in range(i + 1, n):\n            xj = X[j]\n            sumj = row_sums[j]\n            denom = sumi + sumj\n            if denom = 0:\n                d = 0.0  # both samples all-zero; define distance as 0\n            else:\n                num = np.abs(xi - xj).sum()\n                d = num / denom\n            D[i, j] = d\n            D[j, i] = d\n    return D\n\ndef pcoa_from_distance(D: np.ndarray, tol: float = 1e-12):\n    \"\"\"\n    Perform PCoA (classical MDS) on a distance matrix D.\n    Returns eigenvalues (sorted descending), coordinates matrix with only positive eigenvalues.\n    \"\"\"\n    n = D.shape[0]\n    # Square distances\n    D2 = D ** 2.0\n    # Double-centering\n    J = np.eye(n) - np.ones((n, n)) / n\n    B = -0.5 * (J @ D2 @ J)\n    # Eigen-decomposition (symmetric)\n    w, V = np.linalg.eigh(B)\n    # Sort in descending order\n    idx = np.argsort(w)[::-1]\n    w = w[idx]\n    V = V[:, idx]\n    # Keep positive eigenvalues\n    pos_mask = w  tol\n    w_pos = w[pos_mask]\n    V_pos = V[:, pos_mask]\n    # Coordinates scaled by sqrt of eigenvalues\n    if w_pos.size  0:\n        coords = V_pos * np.sqrt(w_pos)\n    else:\n        coords = np.zeros((n, 0), dtype=float)\n    return w, w_pos, coords\n\ndef pearson_correlation(x: np.ndarray, y: np.ndarray) - float:\n    \"\"\"\n    Compute Pearson correlation between two 1D arrays.\n    If either has zero variance, return 0.0.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    y = np.asarray(y, dtype=float)\n    x_mean = x.mean()\n    y_mean = y.mean()\n    x_centered = x - x_mean\n    y_centered = y - y_mean\n    sx = np.sqrt(np.sum(x_centered ** 2))\n    sy = np.sqrt(np.sum(y_centered ** 2))\n    if sx == 0.0 or sy == 0.0:\n        return 0.0\n    cov = np.sum(x_centered * y_centered)\n    r = cov / (sx * sy)\n    # Clamp small numerical deviations\n    if r  1.0:\n        r = 1.0\n    elif r  -1.0:\n        r = -1.0\n    return r\n\ndef interpret_axes(coords: np.ndarray, env: np.ndarray, num_axes: int = 2):\n    \"\"\"\n    For the first num_axes axes, compute best matching environmental gradient by absolute correlation.\n    Returns:\n      best_indices: list of ints (length num_axes)\n      best_correlations: list of floats (signed, length num_axes)\n    If an axis is missing (coords has fewer columns), treat axis vector as zeros,\n    set best index to -1 and correlation to 0.0.\n    \"\"\"\n    n, k = coords.shape\n    m = env.shape[1]\n    best_indices = []\n    best_correlations = []\n    for axis in range(num_axes):\n        if axis  k:\n            axis_scores = coords[:, axis]\n        else:\n            axis_scores = np.zeros(n, dtype=float)\n        # Compute correlations to each env gradient\n        if np.allclose(axis_scores, axis_scores[0] if len(axis_scores)  0 else 0.0):\n            # Zero variance\n            best_indices.append(-1)\n            best_correlations.append(0.0)\n            continue\n        corrs = []\n        for j in range(m):\n            r = pearson_correlation(axis_scores, env[:, j])\n            corrs.append(r)\n        # Choose by max absolute correlation, break ties by smallest index\n        abs_corrs = np.abs(corrs)\n        max_abs = np.max(abs_corrs)\n        candidates = [j for j, ac in enumerate(abs_corrs) if np.isclose(ac, max_abs, atol=1e-12)]\n        best_j = min(candidates)\n        best_indices.append(int(best_j))\n        best_correlations.append(float(corrs[best_j]))\n    return best_indices, best_correlations\n\ndef round6(x: float) - float:\n    # Round to 6 decimals and avoid -0.0\n    r = float(np.round(x + 0.0, 6))\n    if r == -0.0:\n        r = 0.0\n    return r\n\ndef format_case_output(case_output):\n    # case_output is a list of values (floats and ints)\n    # We must produce a string like [f1,f2,i1,i2,f3,f4] with no spaces\n    parts = []\n    for v in case_output:\n        if isinstance(v, int):\n            parts.append(str(v))\n        else:\n            # ensure 6 decimal places\n            parts.append(f\"{v:.6f}\")\n    return \"[\" + \",\".join(parts) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Test case 1\n    X1 = np.array([\n        [60, 25, 10, 5],\n        [50, 30, 15, 5],\n        [30, 30, 25, 15],\n        [15, 25, 30, 30],\n        [5, 15, 30, 50],\n    ], dtype=float)\n    G1 = np.column_stack([\n        np.array([6.5, 6.8, 7.0, 7.2, 7.5], dtype=float),      # pH\n        np.array([31.0, 28.2, 26.4, 24.3, 22.1], dtype=float)  # salinity\n    ])\n\n    # Test case 2\n    X2 = np.array([\n        [80, 30, 5, 5],\n        [70, 25, 10, 5],\n        [60, 20, 15, 5],\n        [10, 15, 30, 45],\n        [5, 10, 30, 55],\n        [8, 12, 28, 42],\n    ], dtype=float)\n    G2 = np.column_stack([\n        np.array([0.10, 0.20, 0.35, 0.70, 0.82, 0.95], dtype=float),  # fiber\n        np.array([15.0, 15.5, 15.0, 16.0, 16.5, 16.0], dtype=float)   # temperature\n    ])\n\n    # Test case 3\n    X3 = np.array([\n        [40, 30, 20, 10],\n        [40, 30, 20, 10],\n        [10, 20, 30, 40],\n        [12, 18, 30, 40],\n    ], dtype=float)\n    G3 = np.column_stack([\n        np.array([5.0, 5.0, 8.0, 8.2], dtype=float),     # oxygen\n        np.array([100.0, 100.0, 50.0, 55.0], dtype=float)  # depth\n    ])\n\n    test_cases = [\n        (X1, G1),\n        (X2, G2),\n        (X3, G3),\n    ]\n\n    results = []\n    for X, G in test_cases:\n        D = bray_curtis_distance_matrix(X)\n        w_all, w_pos, coords = pcoa_from_distance(D, tol=1e-12)\n        # Proportions explained by first two axes among positive eigenvalues\n        if w_pos.size  0:\n            total_pos = float(np.sum(w_pos))\n        else:\n            total_pos = 0.0\n        if w_pos.size = 1 and total_pos  0.0:\n            prop1 = w_pos[0] / total_pos\n        else:\n            prop1 = 0.0\n        if w_pos.size = 2 and total_pos  0.0:\n            prop2 = w_pos[1] / total_pos\n        else:\n            prop2 = 0.0\n        # Interpret axes\n        best_indices, best_corrs = interpret_axes(coords, G, num_axes=2)\n        # Round floats to 6 decimals\n        prop1_r = round6(prop1)\n        prop2_r = round6(prop2)\n        corr1_r = round6(best_corrs[0])\n        corr2_r = round6(best_corrs[1])\n        # Assemble output for this case\n        case_output = [prop1_r, prop2_r, best_indices[0], best_indices[1], corr1_r, corr2_r]\n        results.append(case_output)\n\n    # Final print statement in the exact required format: one line, no spaces.\n    out = \"[\" + \",\".join(format_case_output(case) for case in results) + \"]\"\n    print(out)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2509183"}]}