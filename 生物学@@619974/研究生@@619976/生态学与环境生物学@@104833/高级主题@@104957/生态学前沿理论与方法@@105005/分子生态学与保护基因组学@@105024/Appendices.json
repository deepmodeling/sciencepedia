{"hands_on_practices": [{"introduction": "在进行任何生物学推断之前，我们必须确保数据的可靠性。本练习旨在解决基因组学中一个常见的技术伪影——参考偏倚（reference bias），即携带非参考等位基因的测序读段（reads）由于与参考基因组差异较大而无法被正确比对。您将学习如何对这种偏倚进行建模，估算其影响，并预测生物信息学缓解策略将如何提高数据质量，这是任何基因组学研究中至关重要的第一步。[@problem_id:2510246]", "problem": "一项关于某种受威胁岛屿蜥蜴的保护基因组学研究正在评估短读长全基因组重测序数据中的参考偏向。研究人员在短插入/缺失（indels）的$5$个碱基对范围内，识别出了一组杂合单核苷酸多态性位点，已知这种情况会加剧参考偏向的比对。将在这些杂合位点处的等位基因平衡定义为支持变异等位基因的比对读段所占的比例，记为 $b$。在无偏采样和孟德尔分离定律下，一个真正的二倍体杂合子位点的预期 $b$ 值为 $0.5$。假设以下基本原则：(i) 读取的读段是在杂合位点上对等位基因进行采样的独立伯努利试验；(ii) 在没有比对偏向的情况下，观测到支持变异等位基因的读段的概率为 $0.5$；(iii) 在indel附近的比对过程中，会优先导致一部分比例为 $c$ 的支持变异等位基因的读段比对失败，而支持参考等位基因的读段则没有损失地完成比对；(iv) 所有考虑的位点都是真正的杂合子；(v) 测序深度足够大，因此适合使用一个在整个数据池中具有共同的变异等位基因概率的二项分布模型。\n\n在 $N$ 个此类位点中，汇总的观测计数为：在 $D_{\\text{obs}} = 50{,}000$ 个总比对读段中，有 $A_{\\text{obs}} = 18{,}500$ 个读段支持变异等位基因。使用以上假设：\n\n1) 从二项分布采样模型和等位基因平衡的定义出发，推导出观测到的变异等位基因概率的最大似然估计 $\\hat{b}$，并根据所述的比对丢失模型，推导出用 $b$ 表示 $c$ 的表达式。然后，使用观测计数计算出隐含的 $\\hat{c}$。\n\n2) 一个结合了围绕indel进行联合重比对和感知变异的图比对算法的缓解方案，预计能恢复之前丢失的变异等位基因读段中的 $r = 0.65$ 的比例，而不会改变参考等位基因读段的比对。在相同模型下，预测缓解措施实施后的预期等位基因平衡 $b'$。将你的答案四舍五入到四位有效数字。最终答案以不带单位的小数形式表示。\n\n最终数值答案只需要 $b'$ 的值。", "solution": "首先对问题陈述进行严格的验证过程。\n\n逐字提取已知条件：\n- 等位基因平衡 $b$ 是支持变异等位基因的比对读段的比例。\n- 在无偏采样下，预期的 $b$ 为 $0.5$。\n- (i) 读段是独立的伯努利试验。\n- (ii) 在无偏向时，观测到变异等位基因读段的概率为 $0.5$。\n- (iii) 一部分比例为 $c$ 的变异等位基因读段比对失败；参考等位基因读段比对无损失。\n- (iv) 所有位点都是真正的杂合子。\n- (v) 模型是一个具有共同变异等位基因概率的二项分布。\n- 观测到的变异等位基因读段数，$A_{\\text{obs}} = 18{,}500$。\n- 观测到的总比对读段数，$D_{\\text{obs}} = 50{,}000$。\n- 一项缓解计划恢复了先前丢失的变异等位基因读段中比例为 $r = 0.65$ 的部分。\n\n根据标准进行验证：\n- **科学依据：** 该问题是合理的。它提出了一个简化但标准的下一代测序中参考偏向的模型，这是基因组学中有详细记载的现象。使用二项分布模型来描述读段计数是一项基本且恰当的统计假设。\n- **良态问题：** 该问题提供了推导唯一解所需的所有必要数据和一组明确的假设。\n- **客观性：** 该问题以精确、定量且无偏的技术语言陈述。\n\n结论：该问题有效，因为它科学上合理，内容自洽，且属良态问题。我们可以着手求解。\n\n按要求分两部分解决该问题。\n\n第1部分：推导 $\\hat{b}$、 $c(b)$ 并计算 $\\hat{c}$。\n\n在总共 $D_{\\text{obs}}$ 个比对读段中观测到 $A_{\\text{obs}}$ 个变异等位基因读段的数量，可以建模为从一个二项分布 $A \\sim \\text{Binomial}(D_{\\text{obs}}, b)$ 中抽样，其中 $b$ 是观测到变异等位基因读段的概率。$b$ 的似然函数为：\n$$L(b; A_{\\text{obs}}, D_{\\text{obs}}) = \\binom{D_{\\text{obs}}}{A_{\\text{obs}}} b^{A_{\\text{obs}}} (1-b)^{D_{\\text{obs}}-A_{\\text{obs}}}$$\n为了找到最大似然估计（MLE）$\\hat{b}$，我们最大化对数似然函数：\n$$\\ln L(b) = \\ln\\binom{D_{\\text{obs}}}{A_{\\text{obs}}} + A_{\\text{obs}}\\ln(b) + (D_{\\text{obs}}-A_{\\text{obs}})\\ln(1-b)$$\n对 $b$ 求导并将导数置零以求得最大值：\n$$\\frac{d}{db}\\ln L(b) = \\frac{A_{\\text{obs}}}{b} - \\frac{D_{\\text{obs}}-A_{\\text{obs}}}{1-b} = 0$$\n求解 $b$：\n$$A_{\\text{obs}}(1-b) = (D_{\\text{obs}}-A_{\\text{obs}})b$$\n$$A_{\\text{obs}} = b D_{\\text{obs}}$$\n因此，观测到的变异等位基因概率的MLE是样本比例：\n$$\\hat{b} = \\frac{A_{\\text{obs}}}{D_{\\text{obs}}}$$\n使用给定数据：\n$$\\hat{b} = \\frac{18{,}500}{50{,}000} = 0.37$$\n\n接下来，我们推导比对丢失比例 $c$ 关于等位基因平衡 $b$ 的表达式。让我们考虑一个来自真实杂合位点的初始大样本池，包含总共 $K$ 个读段。根据假设(iv)和(ii)，这些读段由 $\\frac{K}{2}$ 个参考等位基因读段和 $\\frac{K}{2}$ 个变异等位基因读段组成。\n根据假设(iii)：\n- 比对上的参考等位基因读段数：$R_{\\text{map}} = \\frac{K}{2}$。\n- 比对上的变异等位基因读段数：$A_{\\text{map}} = (1-c)\\frac{K}{2}$。\n比对上的总读段数为 $D_{\\text{map}} = R_{\\text{map}} + A_{\\text{map}} = \\frac{K}{2} + (1-c)\\frac{K}{2} = \\frac{K}{2}(2-c)$。\n等位基因平衡 $b$ 是比对上的变异等位基因读段数与总比对读段数之比：\n$$b = \\frac{A_{\\text{map}}}{D_{\\text{map}}} = \\frac{(1-c)\\frac{K}{2}}{\\frac{K}{2}(2-c)} = \\frac{1-c}{2-c}$$\n为了用 $b$ 表示 $c$，我们对此方程求解 $c$：\n$$b(2-c) = 1-c$$\n$$2b - bc = 1-c$$\n$$c - bc = 1-2b$$\n$$c(1-b) = 1-2b$$\n$$c = \\frac{1-2b}{1-b}$$\n我们现在可以通过代入 $\\hat{b}$ 来计算 $c$ 的MLE，记为 $\\hat{c}$：\n$$\\hat{c} = \\frac{1-2\\hat{b}}{1-\\hat{b}} = \\frac{1-2(0.37)}{1-0.37} = \\frac{1-0.74}{0.63} = \\frac{0.26}{0.63} = \\frac{26}{63}$$\n\n第2部分：预测缓解措施实施后的预期等位基因平衡 $b'$。\n\n该缓解策略恢复了先前丢失的变异等位基因读段中的一部分，比例为 $r=0.65$。参考等位基因读段的数量保持不变。\n缓解前丢失的变异等位基因读段数量为 $c\\frac{K}{2}$。\n通过缓解措施恢复的变异等位基因读段数量为 $r \\left( c\\frac{K}{2} \\right)$。\n新的比对上的变异等位基因读段数 $A'_{\\text{map}}$ 是原始比对上的数量与恢复的数量之和：\n$$A'_{\\text{map}} = A_{\\text{map}} + r c \\frac{K}{2} = (1-c)\\frac{K}{2} + rc\\frac{K}{2} = (1-c+rc)\\frac{K}{2} = (1-c(1-r))\\frac{K}{2}$$\n新的总比对读段数 $D'_{\\text{map}}$ 是比对上的参考读段数与新的比对上的变异读段数之和：\n$$D'_{\\text{map}} = R_{\\text{map}} + A'_{\\text{map}} = \\frac{K}{2} + (1-c(1-r))\\frac{K}{2} = \\frac{K}{2}(1 + 1-c(1-r)) = \\frac{K}{2}(2-c(1-r))$$\n缓解措施实施后的预期等位基因平衡 $b'$ 是 $A'_{\\text{map}}$ 与 $D'_{\\text{map}}$ 之比：\n$$b' = \\frac{A'_{\\text{map}}}{D'_{\\text{map}}} = \\frac{(1-c(1-r))\\frac{K}{2}}{\\frac{K}{2}(2-c(1-r))} = \\frac{1-c(1-r)}{2-c(1-r)}$$\n我们代入估计值 $\\hat{c} = \\frac{26}{63}$ 和给定的恢复比例 $r = 0.65$：\n首先，我们计算项 $c(1-r)$：\n$$\\hat{c}(1-r) = \\frac{26}{63} (1-0.65) = \\frac{26}{63} (0.35) = \\frac{26}{63} \\times \\frac{35}{100} = \\frac{26}{63} \\times \\frac{7}{20} = \\frac{26 \\times 7}{9 \\times 7 \\times 20} = \\frac{26}{180} = \\frac{13}{90}$$\n现在，我们将其代入 $b'$ 的表达式中：\n$$b' = \\frac{1 - \\frac{13}{90}}{2 - \\frac{13}{90}} = \\frac{\\frac{90-13}{90}}{\\frac{180-13}{90}} = \\frac{77}{167}$$\n为了提供最终的数值答案，我们计算小数值并四舍五入到四位有效数字：\n$$b' = \\frac{77}{167} \\approx 0.4610778...$$\n四舍五入到四位有效数字得到 $0.4611$。", "answer": "$$\\boxed{0.4611}$$", "id": "2510246"}, {"introduction": "与哈迪-温伯格平衡（Hardy-Weinberg equilibrium）的预期相比，种群遗传学中一个常见的观察是杂合子缺失。这种模式可能源于生物学过程，如近交（inbreeding），也可能源于抽样伪影，如瓦伦德效应（Wahlund effect），即混合了遗传上不同的种群。本实践问题将帮助您掌握一个强大的、基于似然（likelihood-based）的统计框架来检验这些相互竞争的假说，这是准确诊断种群结构和交配系统的关键技能。[@problem_id:2510217]", "problem": "在一个由 $N = 400$ 个二倍体个体组成的混合样本中，对一个双等位基因的单核苷酸多态性（等位基因 $A$ 和 $a$）进行了基因分型。这些个体是沿着一个横跨两个部分隔离的同类群的样带收集的。混合样本的基因型计数为 $n_{AA} = 130$、$n_{Aa} = 150$ 和 $n_{aa} = 120$。来自每个同类群的独立基线测序提供了等位基因 $A$ 的分层等位基因频率：同类群 $1$ 的频率为 $p_{1} = 0.30$，同类群 $2$ 的频率为 $p_{2} = 0.70$。抽样工作表明，在混合样本中，来自两个同类群的混合比例相等，因此 $w_{1} = 0.5$ 且 $w_{2} = 0.5$。\n\n构建一个基于似然的检验，以区分由单个泛交群体内近交导致的杂合子缺失，与由 Wahlund 效应（具有不同等位基因频率的两个哈迪-温伯格同类群的混合）导致的杂合子缺失。将混合基因型计数视为一个具有三类的多项式样本。在近交模型下，假设一个由等位基因频率 $p$ 和近交系数 $F$ 表征的单个群体；在 Wahlund 模型下，假设一个具有给定 $(p_{1},p_{2})$ 和 $(w_{1},w_{2})$ 的双同类群混合体，且同类群内部无近交。\n\n将检验统计量定义为\n$$S \\equiv 2\\left[\\ln L_{\\text{inbreeding}}(\\widehat{p},\\widehat{F}\\,|\\,\\text{data}) - \\ln L_{\\text{Wahlund}}(p_{1},p_{2},w_{1},w_{2}\\,|\\,\\text{data})\\right],$$\n其中 $\\widehat{p}$ 和 $\\widehat{F}$ 是近交模型下的最大似然估计，而 Wahlund 模型除了固定的 $(p_{1},p_{2},w_{1},w_{2})$ 之外没有使用其他自由参数。计算上述数据中 $S$ 的数值。将答案四舍五入至四位有效数字。仅提供 $S$ 的值，无需单位。", "solution": "本题要求计算一个似然比检验统计量 $S$，用以比较两种用于解释二倍体个体混合样本中杂合子缺失的竞争模型。第一个模型假定存在一个有近交的单一泛交群体。第二个模型假定存在 Wahlund 效应，该效应源于两个亚群的混合，且每个亚群都处于哈迪-温伯格平衡状态。本题具有科学依据，论述严谨，并包含了获得唯一解所需的所有信息。\n\n观测数据包括来自 $N=400$ 个体样本的基因型计数：$n_{AA} = 130$，$n_{Aa} = 150$ 和 $n_{aa} = 120$。这些计数之和为 $N$，因此 $130 + 150 + 120 = 400$。题中说明，这些计数可被视为来自一个具有三类的多项式分布的单个样本。\n\n设三种基因型 $AA$、$Aa$ 和 $aa$ 的概率分别为 $\\pi_{AA}$、$\\pi_{Aa}$ 和 $\\pi_{aa}$，其中 $\\pi_{AA} + \\pi_{Aa} + \\pi_{aa} = 1$。观测计数 $(n_{AA}, n_{Aa}, n_{aa})$ 的对数似然函数由下式给出：\n$$ \\ln L(\\pi_{AA}, \\pi_{Aa}, \\pi_{aa} \\,|\\, \\text{data}) = \\ln\\left(\\frac{N!}{n_{AA}! n_{Aa}! n_{aa}!}\\right) + n_{AA} \\ln(\\pi_{AA}) + n_{Aa} \\ln(\\pi_{Aa}) + n_{aa} \\ln(\\pi_{aa}) $$\n为了计算似然比，可以忽略常数组合项。我们使用对数似然函数的核心部分：\n$$ \\ell(\\pi_{AA}, \\pi_{Aa}, \\pi_{aa}) = n_{AA} \\ln(\\pi_{AA}) + n_{Aa} \\ln(\\pi_{Aa}) + n_{aa} \\ln(\\pi_{aa}) $$\n\n首先，我们分析近交模型。该模型由两个参数表征：等位基因 $A$ 的等位基因频率 $p$ 和近交系数 $F$。预期的基因型频率为：\n$$ \\pi_{AA}(p, F) = p^2 + p(1-p)F $$\n$$ \\pi_{Aa}(p, F) = 2p(1-p)(1-F) $$\n$$ \\pi_{aa}(p, F) = (1-p)^2 + p(1-p)F $$\n我们需要求出 $p$ 和 $F$ 的最大似然估计（MLE），记为 $\\widehat{p}$ 和 $\\widehat{F}$。一个具有两个自由参数的模型被用于拟合具有两个自由度（三类总和为一）的数据。这代表一个饱和模型，意味着该模型可以完美拟合观测频率。基因型频率的 MLE 就是观测到的样本频率：\n$$ \\widehat{\\pi}_{AA} = \\frac{n_{AA}}{N} = \\frac{130}{400} = 0.325 $$\n$$ \\widehat{\\pi}_{Aa} = \\frac{n_{Aa}}{N} = \\frac{150}{400} = 0.375 $$\n$$ \\widehat{\\pi}_{aa} = \\frac{n_{aa}}{N} = \\frac{120}{400} = 0.300 $$\n在近交模型下，将这些频率代入对数似然函数的核心部分，即可得到最大化的对数似然 $\\ln L_{\\text{inbreeding}}$：\n$$ \\ln L_{\\text{inbreeding}} = \\ell(\\widehat{\\pi}_{AA}, \\widehat{\\pi}_{Aa}, \\widehat{\\pi}_{aa}) = 130 \\ln(0.325) + 150 \\ln(0.375) + 120 \\ln(0.300) $$\n使用计算器计算自然对数：\n$$ \\ln(0.325) \\approx -1.12393006 $$\n$$ \\ln(0.375) \\approx -0.98082925 $$\n$$ \\ln(0.300) \\approx -1.20397280 $$\n$$ \\ln L_{\\text{inbreeding}} \\approx 130(-1.12393006) + 150(-0.98082925) + 120(-1.20397280) $$\n$$ \\ln L_{\\text{inbreeding}} \\approx -146.110908 - 147.124388 - 144.476736 = -437.712032 $$\n\n接下来，我们分析 Wahlund 模型。此模型没有需要从数据中估计的自由参数；所有参数均已给定。样本是来自两个同类群的混合体，其混合比例为 $w_{1} = w_{2} = 0.5$，等位基因频率为 $p_{1} = 0.30$ 和 $p_{2} = 0.70$。在每个同类群内部，基因型均符合哈迪-温伯格比例。\n对于同类群 1：\n$$ \\pi_{AA,1} = p_1^2 = (0.30)^2 = 0.09 $$\n$$ \\pi_{Aa,1} = 2p_1(1-p_1) = 2(0.30)(0.70) = 0.42 $$\n$$ \\pi_{aa,1} = (1-p_1)^2 = (0.70)^2 = 0.49 $$\n对于同类群 2：\n$$ \\pi_{AA,2} = p_2^2 = (0.70)^2 = 0.49 $$\n$$ \\pi_{Aa,2} = 2p_2(1-p_2) = 2(0.70)(0.30) = 0.42 $$\n$$ \\pi_{aa,2} = (1-p_2)^2 = (0.30)^2 = 0.09 $$\n混合样本中的预期基因型频率（$\\pi_W$）是加权平均值：\n$$ \\pi_{AA,W} = w_1 \\pi_{AA,1} + w_2 \\pi_{AA,2} = 0.5(0.09) + 0.5(0.49) = 0.045 + 0.245 = 0.29 $$\n$$ \\pi_{Aa,W} = w_1 \\pi_{Aa,1} + w_2 \\pi_{Aa,2} = 0.5(0.42) + 0.5(0.42) = 0.21 + 0.21 = 0.42 $$\n$$ \\pi_{aa,W} = w_1 \\pi_{aa,1} + w_2 \\pi_{aa,2} = 0.5(0.49) + 0.5(0.09) = 0.245 + 0.045 = 0.29 $$\nWahlund 模型的对数似然 $\\ln L_{\\text{Wahlund}}$ 是使用这些固定频率计算的：\n$$ \\ln L_{\\text{Wahlund}} = \\ell(\\pi_{AA,W}, \\pi_{Aa,W}, \\pi_{aa,W}) = 130 \\ln(0.29) + 150 \\ln(0.42) + 120 \\ln(0.29) $$\n$$ \\ln L_{\\text{Wahlund}} = 250 \\ln(0.29) + 150 \\ln(0.42) $$\n使用计算器计算自然对数：\n$$ \\ln(0.29) \\approx -1.23787435 $$\n$$ \\ln(0.42) \\approx -0.86750054 $$\n$$ \\ln L_{\\text{Wahlund}} \\approx 250(-1.23787435) + 150(-0.86750054) $$\n$$ \\ln L_{\\text{Wahlund}} \\approx -309.468588 - 130.125081 = -439.593669 $$\n\n最后，我们计算检验统计量 $S$：\n$$ S = 2\\left[\\ln L_{\\text{inbreeding}}(\\widehat{p},\\widehat{F}\\,|\\,\\text{data}) - \\ln L_{\\text{Wahlund}}(p_{1},p_{2},w_{1},w_{2}\\,|\\,\\text{data})\\right] $$\n$$ S = 2 \\left( -437.712032 - (-439.593669) \\right) $$\n$$ S = 2 \\left( -437.712032 + 439.593669 \\right) $$\n$$ S = 2 \\left( 1.881637 \\right) $$\n$$ S = 3.763274 $$\n将结果四舍五入到四位有效数字，得到 $3.763$。", "answer": "$$\\boxed{3.763}$$", "id": "2510217"}, {"introduction": "保护基因组学的一个核心目标是理解种群的历史动态，如分化和基因流。本练习将向您介绍近似贝叶斯计算（Approximate Bayesian Computation, ABC），这是一种灵活而强大的、基于模拟的方法。当直接计算似然函数不可行时，ABC可用于比较复杂的人口统计学模型。您将实施一个完整的ABC工作流程，从模拟数据到模型选择，以区分“隔离-迁移”（isolation-with-migration）模型和“二次接触”（secondary contact）模型，这是现代人口统计推断中的一项顶尖技能。[@problem_id:2510225]", "problem": "您的任务是实现一个完整的、可复现的近似贝叶斯计算 (ABC) 模型选择框架，以区分分子生态学和保护基因组学中常研究的两种种群情景：隔离-迁徙（isolation-with-migration）和次级接触（secondary contact）。您的实现必须是自包含的，并且必须能够为多个观测数据集计算模型后验概率，以及基于样本外分类准确率进行经验充分性诊断。\n\n设计必须基于基本原理和经过充分检验的事实：\n- 根据赖特-费舍尔（Wright–Fisher）模型，溯祖理论（Coalescent theory）意味着种群历史（如分化时间和基因流）决定了谱系的分布，而谱系分布又决定了如位点频率谱（SFS）和连锁不平衡（LD）等摘要统计量。\n- 贝叶斯定理指出，对于模型 $M$ 和数据（此处为摘要统计量）$S$，后验概率满足 $P(M \\mid S) \\propto P(S \\mid M) P(M)$。在ABC中，$P(S \\mid M)$ 是通过模拟并接受与观测值相近的模拟摘要统计量来近似的。\n- 统计学中的充分性概念：如果 $P(M \\mid S) = P(M \\mid T(S))$，则统计量 $T(S)$ 对于 $M$ 是充分的。在处理复杂模型的实践中，我们通过评估 $T(S)$ 在样本外预测 $M$ 的能力来凭经验评估其近似充分性。\n\n请使用下文的定义和生成规则实现以下内容。\n\n摘要统计量的核心定义：\n- 位点频率谱 (SFS)：使用三个总和为 $1$ 的区间。将这些解释为汇集自两个种群的稀有、中等和高频变异的粗粒度比例：$S_{\\text{SFS}} = [s_1, s_2, s_3]$，其中 $s_1 + s_2 + s_3 = 1$ 且每个 $s_i \\in [0,1]$。\n- 连锁不平衡 (LD)：使用在距离 $d \\in \\{1, 5, 10\\}$（任意单位）下的三个 $r^2$ 值，$S_{\\text{LD}} = [\\ell_1, \\ell_2, \\ell_3]$，其中 $\\ell_j \\in [0,1]$。\n- 完整的摘要统计量向量为 $S = [s_1, s_2, s_3, \\ell_1, \\ell_2, \\ell_3]$。\n\n种群模型和模拟先验：\n- 隔离-迁徙 (IM)：参数为分化时间 $T \\sim \\text{Uniform}(0.2, 2.0)$ 和对称迁移率 $m \\sim \\text{Uniform}(0.0, 0.1)$。\n- 次级接触 (SC)：参数为分化时间 $T \\sim \\text{Uniform}(0.2, 2.0)$，接触前的隔离持续时间 $T_c \\sim \\text{Uniform}(0.0, 0.3)$，以及一个近期接触脉冲参数 $p \\sim \\text{Uniform}(0.1, 0.5)$。\n\n摘要统计量的生成规则（简化的但有机制动机；所有随机性在重复实验间独立）：\n- 在 IM 模型下，生成 SFS 区间如下\n  - $\\mu_2 = 0.45 + 0.5\\, m \\, e^{-T}$，$\\mu_1 = 0.35 - 0.2\\, m + 0.1\\, e^{-T}$，其中 $s_1 \\sim \\mathcal{N}(\\mu_1, 0.05^2)$，$s_2 \\sim \\mathcal{N}(\\mu_2, 0.05^2)$，以及 $s_3 = 1 - s_1 - s_2 + \\epsilon$，$\\epsilon \\sim \\mathcal{N}(0, 0.02^2)$。生成后，将每个 $s_i$ 限制在 $[10^{-6}, 1]$ 范围内，并重新归一化以使 $s_1 + s_2 + s_3 = 1$。\n  - LD 在距离 $d \\in \\{1, 5, 10\\}$ 处的衰减：振幅 $A = 0.35 - 0.5\\, m$，基线 $b = 0.06 + 0.04\\, e^{-T}$，衰减率 $\\lambda = 0.4 + 1.5\\, m + 0.4/(1+T)$。对于每个 $d$，生成 $\\ell(d) = \\min\\{1, \\max\\{0, A \\, e^{-\\lambda d} + b + \\eta\\}\\}$，其中 $\\eta \\sim \\mathcal{N}(0, 0.01^2)$。\n- 在 SC 模型下，生成 SFS 区间如下\n  - $\\mu_2 = 0.30 + 0.2\\, p \\, e^{-T_c}$，$\\mu_1 = 0.45 + 0.1\\, e^{-T} - 0.1\\, p$，其中 $s_1 \\sim \\mathcal{N}(\\mu_1, 0.05^2)$，$s_2 \\sim \\mathcal{N}(\\mu_2, 0.05^2)$，以及 $s_3 = 1 - s_1 - s_2 + \\epsilon$，$\\epsilon \\sim \\mathcal{N}(0, 0.02^2)$。生成后，按上述方式进行限制和重新归一化。\n  - LD 在距离 $d \\in \\{1, 5, 10\\}$ 处的衰减：振幅 $A = 0.6 + 0.2\\, p$，基线 $b = 0.03 + 0.02\\, e^{-T}$，衰减率 $\\lambda = 0.2 + 0.1\\, p$。对于每个 $d$，按上述方式生成 $\\ell(d)$，其中 $\\eta \\sim \\mathcal{N}(0, 0.01^2)$。\n\nABC 模型选择规范：\n- 使用相等的模型先验 $P(\\text{IM}) = P(\\text{SC}) = 0.5$。\n- 使用上述的先验和生成规则，在 IM 模型下模拟 $N_{\\text{IM}} = 12000$ 个摘要统计量，在 SC 模型下模拟 $N_{\\text{SC}} = 12000$ 个摘要统计量。为确保可复现性，对这些模拟使用固定的随机种子 $7$。\n- 通过使用汇集了 $N_{\\text{IM}} + N_{\\text{SC}}$ 次模拟的均值和标准差，对摘要统计量的 $6$ 个分量进行 $z$-score 标准化。对观测到的摘要统计量应用相同的变换。\n- 对于一个观测到的摘要统计量 $S^{\\star}$，计算其在标准化空间中与每个模拟摘要统计量的欧几里得距离，即 $d_i = \\lVert \\tilde{S}^{\\star} - \\tilde{S}_i \\rVert_2$。将汇集了两个模型所有距离的第 $q$-分位数（$q = 0.01$）确定为全局接受阈值 $\\epsilon$。接受所有满足 $d_i \\le \\epsilon$ 的模拟。\n- 通过来自每个模型的被接受模拟的比例来近似后验模型概率。具体来说，报告 $\\hat{P}(\\text{IM} \\mid S^{\\star}) = n_{\\text{acc,IM}}/(n_{\\text{acc,IM}} + n_{\\text{acc,SC}})$，其中 $n_{\\text{acc,IM}}$ 和 $n_{\\text{acc,SC}}$ 分别是来自 IM 和 SC 模型的被接受模拟的计数。\n\n经验充分性诊断：\n- 训练一个逻辑回归分类器，根据 $6$ 维标准化摘要统计量预测模型标签。通过将前 $9000$ 个 IM 模拟和前 $9000$ 个 SC 模拟作为训练集，余下的 $3000$ 个 IM 模拟和 $3000$ 个 SC 模拟作为测试集，来划分这 $24000$ 次模拟（在给定固定种子的情况下，此划分是确定性的）。使用全批量梯度下降法，进行 $500$ 次迭代，学习率为 $0.1$，通过最小化带 $\\ell_2$ 惩罚系数 $\\alpha = 0.01$ 的正则化负对数似然来拟合逻辑回归。不要对偏置项进行惩罚。将测试集上的样本外准确率以小数形式报告。\n- 可解释性指南（无需输出布尔值）：更高的准确率表明摘要统计量保留了更多关于模型身份的信息，并且在这种情况下更接近于对模型选择是充分的。\n\n观测测试用例：\n- 在生成观测摘要统计量时，使用一个独立的固定随机种子 $13$，以避免与模拟池耦合。对于每个案例，使用下面的模型和参数值以及与上述相同的生成规则，生成单个观测摘要统计量。\n  - 案例 1 (类IM)：IM 模型，参数 $T = 0.6$, $m = 0.06$。\n  - 案例 2 (类SC)：SC 模型，参数 $T = 1.0$, $T_c = 0.1$, $p = 0.4$。\n  - 案例 3 (模糊的IM)：IM 模型，参数 $T = 1.5$, $m = 0.01$。\n  - 案例 4 (中度的SC)：SC 模型，参数 $T = 0.8$, $T_c = 0.25$, $p = 0.15$。\n\n数值和输出要求：\n- 所有随机数生成必须遵循指定的种子：模拟使用种子 $7$；观测摘要统计量使用种子 $13$。\n- 使用给定的距离 $d \\in \\{1, 5, 10\\}$，并在本练习中将其视为无量纲。\n- 您的程序应生成单行输出，包含一个有 $5$ 个条目的列表：案例 1、案例 2、案例 3 和案例 4 的隔离-迁徙模型近似后验概率（按此顺序），最后是逻辑回归的测试准确率。每个值必须四舍五入到恰好三位小数。要求的输出格式是单行，用方括号括起来的逗号分隔列表，例如：“[0.913,0.072,0.554,0.128,0.922]”。", "solution": "该问题要求实现一个近似贝叶斯计算 (ABC) 模型选择框架。在群体遗传学等领域，这是一个常见的任务，因为在这些领域中，似然函数难以处理，但从模型中模拟数据是可行的。目标是区分一对种群的两种竞争性种群历史：隔离-迁徙 (IM) 模型和次级接触 (SC) 模型。解决方案由两个主要的计算任务组成：为四个特定的观测数据集估计 ABC 后验概率，以及对所用摘要统计量的统计充分性进行经验评估。\n\n首先，我们必须建立模拟过程的基础。我们的生成模型是复杂群体遗传过程的简化表示。IM 模型由两个参数表征：分化时间 $T$ 和连续对称的迁移率 $m$。这些参数的先验分布为 $T \\sim \\text{Uniform}(0.2, 2.0)$ 和 $m \\sim \\text{Uniform}(0.0, 0.1)$。SC 模型涉及一个初始的完全隔离期，随后发生一次基因流事件。它由三个参数描述：初始分化时间 $T \\sim \\text{Uniform}(0.2, 2.0)$，接触前的隔离持续时间 $T_c \\sim \\text{Uniform}(0.0, 0.3)$，以及代表次级接触脉冲强度的参数 $p \\sim \\text{Uniform}(0.1, 0.5)$。\n\n对于每个模型，我们必须生成一个大的摘要统计量参考表。问题指定总共进行 $N_{\\text{sim}} = N_{\\text{IM}} + N_{\\text{SC}} = 12000 + 12000 = 24000$ 次模拟。单个数据点的模拟过程如下：\n1.  选择一个模型，IM 或 SC。\n2.  从各自的先验分布中抽取一组参数。\n3.  使用提供的带有随机噪声分量的确定性函数，生成一个 $6$ 维的摘要统计量向量 $S = [s_1, s_2, s_3, \\ell_1, \\ell_2, \\ell_3]$。前三个分量 $s_i$ 代表粗粒度的位点频率谱 (SFS)，后三个分量 $\\ell_j$ 代表不同物理距离 $d \\in \\{1, 5, 10\\}$ 处的连锁不平衡 (LD)。\n整个模拟过程由固定的随机种子 $7$ 控制，以确保完全的可复现性。\n\n该框架的第二部分是 ABC 模型选择算法本身。由于摘要统计量（$s_i$ 和 $\\ell_j$）具有不同的尺度和方差，标准化步骤至关重要。摘要统计量向量的 $6$ 个分量中的每一个都使用在整个 $24000$ 次模拟的参考表中计算出的全局均值 $\\mu_k$ 和标准差 $\\sigma_k$ 进行 $z$-score 标准化：$\\tilde{S}_k = (S_k - \\mu_k) / \\sigma_k$ 对于 $k \\in \\{1, \\dots, 6\\}$。在进行比较之前，任何观测到的摘要统计量向量 $S^{\\star}$ 都必须使用相同的 $\\mu_k$ 和 $\\sigma_k$ 应用相同的变换。\n\nABC 的核心是基于距离度量和接受阈值。对于一个给定的（已标准化的）观测摘要统计量向量 $\\tilde{S}^{\\star}$，我们计算其与参考表中每个标准化摘要统计量向量 $\\tilde{S}_i$ 的欧几里得距离 $d_i = \\lVert \\tilde{S}^{\\star} - \\tilde{S}_i \\rVert_2$。然后，我们将所有 $24000$ 个计算距离数组的 $q=0.01$ 分位数定义为接受阈值 $\\epsilon$。任何满足 $d_i \\le \\epsilon$ 的模拟 $i$ 都被视为“已接受”。\n\n然后，模型的后验概率基于已接受集合的构成来近似。根据贝叶斯定理，$P(M \\mid S^{\\star}) \\propto P(S^{\\star} \\mid M) P(M)$。在模型先验概率相等的情况下，即 $P(\\text{IM}) = P(\\text{SC}) = 0.5$，这简化为 $P(M \\mid S^{\\star}) \\propto P(S^{\\star} \\mid M)$。在 ABC 中，似然 $P(S^{\\star} \\mid M)$ 由来自模型 $M$ 的模拟中落入接受区域的比例来近似。因此，IM 模型的后验概率被估计为在已接受的模拟中，由 IM 模型生成的模拟所占的比例：\n$$ \\hat{P}(\\text{IM} \\mid S^{\\star}) = \\frac{n_{\\text{acc,IM}}}{n_{\\text{acc,IM}} + n_{\\text{acc,SC}}} $$\n其中 $n_{\\text{acc,IM}}$ 和 $n_{\\text{acc,SC}}$ 分别是来自 IM 和 SC 模型的已接受模拟的数量。对四个指定的观测测试用例中的每一个重复此过程，这些测试用例是使用独立的随机种子 $13$ 在固定参数下生成的。\n\n第三个组成部分是经验充分性诊断。如果一组摘要统计量保留了所有用于区分模型的相关信息，则该组统计量对模型选择是“充分的”。我们通过训练一个分类器以根据摘要统计量预测模型标签来凭经验评估此属性。高的分类准确率表明统计量是信息丰富的，因此是近似充分的。为此，我们使用逻辑回归模型。该模型根据标准化的摘要统计量 $\\tilde{S}$ 预测 SC 模型 ($y=1$) 与 IM 模型 ($y=0$) 的概率。预测由 sigmoid 函数给出：$\\hat{y} = \\sigma(\\mathbf{w}^T \\tilde{S} + b) = (1 + \\exp(-(\\mathbf{w}^T \\tilde{S} + b)))^{-1}$。\n\n模型参数，即权重 $\\mathbf{w}$ 和偏置 $b$，通过使用梯度下降最小化正则化的负对数似然（二元交叉熵）来优化。损失函数为：\n$$ J(\\mathbf{w}, b) = -\\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} \\left[ y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) \\right] + \\frac{\\alpha}{2} \\lVert\\mathbf{w}\\rVert_2^2 $$\n按照规定，偏置项 $b$ 不进行正则化。优化在由每个模型的前 $9000$ 个模拟组成的训练集上执行。使用学习率 $\\eta=0.1$ 和正则化强度 $\\alpha=0.01$ 进行 $500$ 次迭代的梯度更新为：\n$$ \\mathbf{w} \\leftarrow \\mathbf{w} - \\eta \\left( \\frac{1}{N_{\\text{train}}} \\mathbf{X}_{\\text{train}}^T (\\hat{\\mathbf{y}} - \\mathbf{y}_{\\text{train}}) + \\alpha \\mathbf{w} \\right) $$\n$$ b \\leftarrow b - \\eta \\left( \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (\\hat{y}_i - y_i) \\right) $$\n训练后，分类器的性能在由每个模型余下的 $3000$ 个模拟组成的独立测试集上进行评估。样本外准确率，即在该测试集上正确预测模型标签的比例，作为我们的诊断指标。高准确率将为 ABC 模型选择的结果提供信心。\n\n最终的实现将按顺序执行这些步骤：生成参考表，计算标准化参数，生成观测数据点，对每个数据点执行 ABC 模型选择，最后训练和评估逻辑回归分类器以报告样本外准确率。所有数值输出将四舍五入到三位小数。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a complete ABC model-choice framework and empirical sufficiency diagnostic.\n    \"\"\"\n\n    # --- Generative Functions for Summary Statistics ---\n\n    def generate_summaries(model_name, n_sims, params=None):\n        \"\"\"\n        Generates summary statistics for a given model.\n        If params are provided, it's a fixed simulation. Otherwise, draw from priors.\n        \"\"\"\n        summaries = np.zeros((n_sims, 6))\n        d_values = np.array([1, 5, 10])\n\n        # Draw parameters from priors if not provided\n        if params is None:\n            if model_name == 'IM':\n                T = np.random.uniform(0.2, 2.0, n_sims)\n                m = np.random.uniform(0.0, 0.1, n_sims)\n            elif model_name == 'SC':\n                T = np.random.uniform(0.2, 2.0, n_sims)\n                T_c = np.random.uniform(0.0, 0.3, n_sims)\n                p = np.random.uniform(0.1, 0.5, n_sims)\n        else:\n            if model_name == 'IM':\n                T, m = params['T'], params['m']\n            elif model_name == 'SC':\n                T, T_c, p = params['T'], params['T_c'], params['p']\n\n        # Generate summaries based on model\n        if model_name == 'IM':\n            # SFS\n            mu2 = 0.45 + 0.5 * m * np.exp(-T)\n            mu1 = 0.35 - 0.2 * m + 0.1 * np.exp(-T)\n            s1 = np.random.normal(mu1, 0.05, n_sims)\n            s2 = np.random.normal(mu2, 0.05, n_sims)\n            epsilon = np.random.normal(0, 0.02, n_sims)\n            s3 = 1 - s1 - s2 + epsilon\n            \n            sfs = np.vstack([s1, s2, s3]).T\n            sfs = np.clip(sfs, 1e-6, 1)\n            sfs_sum = sfs.sum(axis=1, keepdims=True)\n            sfs = sfs / sfs_sum\n            summaries[:, :3] = sfs\n\n            # LD\n            A = 0.35 - 0.5 * m\n            b = 0.06 + 0.04 * np.exp(-T)\n            lam = 0.4 + 1.5 * m + 0.4 / (1 + T)\n            for j, d_val in enumerate(d_values):\n                eta = np.random.normal(0, 0.01, n_sims)\n                ld = A * np.exp(-lam * d_val) + b + eta\n                summaries[:, 3 + j] = np.clip(ld, 0, 1)\n\n        elif model_name == 'SC':\n            # SFS\n            mu2 = 0.30 + 0.2 * p * np.exp(-T_c)\n            mu1 = 0.45 + 0.1 * np.exp(-T) - 0.1 * p\n            s1 = np.random.normal(mu1, 0.05, n_sims)\n            s2 = np.random.normal(mu2, 0.05, n_sims)\n            epsilon = np.random.normal(0, 0.02, n_sims)\n            s3 = 1 - s1 - s2 + epsilon\n            \n            sfs = np.vstack([s1, s2, s3]).T\n            sfs = np.clip(sfs, 1e-6, 1)\n            sfs_sum = sfs.sum(axis=1, keepdims=True)\n            sfs = sfs / sfs_sum\n            summaries[:, :3] = sfs\n\n            # LD\n            A = 0.6 + 0.2 * p\n            b = 0.03 + 0.02 * np.exp(-T)\n            lam = 0.2 + 0.1 * p\n            for j, d_val in enumerate(d_values):\n                eta = np.random.normal(0, 0.01, n_sims)\n                ld = A * np.exp(-lam * d_val) + b + eta\n                summaries[:, 3 + j] = np.clip(ld, 0, 1)\n                \n        return summaries if n_sims > 1 else summaries[0]\n\n    # --- Logistic Regression Implementation ---\n    def train_and_evaluate_logistic_regression(X_train, y_train, X_test, y_test):\n        n_train, n_features = X_train.shape\n        lr = 0.1\n        alpha = 0.01\n        n_iters = 500\n\n        # Initialize weights and bias\n        w = np.zeros(n_features)\n        b = 0.0\n\n        # Full-batch gradient descent\n        for _ in range(n_iters):\n            linear_model = X_train @ w + b\n            y_predicted = 1 / (1 + np.exp(-linear_model))\n\n            # Compute gradients\n            dw = (1 / n_train) * (X_train.T @ (y_predicted - y_train)) + alpha * w\n            db = (1 / n_train) * np.sum(y_predicted - y_train)\n\n            # Update weights and bias\n            w -= lr * dw\n            b -= lr * db\n\n        # Evaluate on test set\n        test_linear_model = X_test @ w + b\n        y_test_predicted = 1 / (1 + np.exp(-test_linear_model))\n        y_test_predicted_cls = (y_test_predicted > 0.5).astype(int)\n        \n        accuracy = np.mean(y_test_predicted_cls == y_test)\n        return accuracy\n\n\n    # --- Main Workflow ---\n\n    # 1. Generate reference tables\n    N_IM, N_SC = 12000, 12000\n    np.random.seed(7)\n    sims_im = generate_summaries('IM', n_sims=N_IM)\n    sims_sc = generate_summaries('SC', n_sims=N_SC)\n    \n    ref_table = np.vstack([sims_im, sims_sc])\n    model_labels = np.hstack([np.zeros(N_IM, dtype=int), np.ones(N_SC, dtype=int)])\n\n    # 2. Standardize summary statistics\n    mean_summaries = ref_table.mean(axis=0)\n    std_summaries = ref_table.std(axis=0)\n    std_summaries[std_summaries == 0] = 1 # Avoid division by zero\n    \n    ref_table_std = (ref_table - mean_summaries) / std_summaries\n\n    # 3. Generate observed test cases\n    np.random.seed(13)\n    test_cases_params = [\n        {'model': 'IM', 'params': {'T': 0.6, 'm': 0.06}},      # Case 1\n        {'model': 'SC', 'params': {'T': 1.0, 'T_c': 0.1, 'p': 0.4}},  # Case 2\n        {'model': 'IM', 'params': {'T': 1.5, 'm': 0.01}},      # Case 3\n        {'model': 'SC', 'params': {'T': 0.8, 'T_c': 0.25, 'p': 0.15}} # Case 4\n    ]\n    \n    observed_summaries = np.array([\n        generate_summaries(case['model'], n_sims=1, params=case['params'])\n        for case in test_cases_params\n    ])\n\n    observed_summaries_std = (observed_summaries - mean_summaries) / std_summaries\n\n    # 4. ABC Model Choice\n    results = []\n    q_threshold = 0.01\n\n    for obs_std in observed_summaries_std:\n        distances = np.linalg.norm(ref_table_std - obs_std, axis=1)\n        epsilon = np.quantile(distances, q_threshold)\n        \n        accepted_indices = np.where(distances = epsilon)[0]\n        \n        if len(accepted_indices) == 0:\n            p_im = 0.5 # Ambiguous case, defaults to prior\n        else:\n            accepted_labels = model_labels[accepted_indices]\n            n_acc_im = np.sum(accepted_labels == 0)\n            n_acc_sc = np.sum(accepted_labels == 1)\n            p_im = n_acc_im / (n_acc_im + n_acc_sc)\n        \n        results.append(p_im)\n\n    # 5. Empirical Sufficiency Diagnostic\n    n_train_per_model = 9000\n    n_test_per_model = 3000\n\n    X_train = np.vstack([ref_table_std[:n_train_per_model], \n                         ref_table_std[N_IM:N_IM + n_train_per_model]])\n    y_train = np.hstack([np.zeros(n_train_per_model), np.ones(n_train_per_model)])\n\n    X_test = np.vstack([ref_table_std[n_train_per_model:N_IM],\n                        ref_table_std[N_IM + n_train_per_model:]])\n    y_test = np.hstack([np.zeros(n_test_per_model), np.ones(n_test_per_model)])\n\n    accuracy = train_and_evaluate_logistic_regression(X_train, y_train, X_test, y_test)\n    results.append(accuracy)\n\n    # 6. Final Output\n    print(f\"[{','.join(f'{x:.3f}' for x in results)}]\")\n\nsolve()\n```", "id": "2510225"}]}