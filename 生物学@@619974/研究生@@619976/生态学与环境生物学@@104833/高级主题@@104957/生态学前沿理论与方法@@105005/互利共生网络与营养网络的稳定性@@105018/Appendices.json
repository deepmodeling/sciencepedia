{"hands_on_practices": [{"introduction": "在我们深入研究一个群落的稳定性之前，必须首先解决一个更基本的问题：所有物种是否都能以正的种群数量共存？这是可行性（feasibility）的核心概念。这个练习将这个生物学问题转化为一个精确的数学问题，要求您判断一个给定的内禀增长率向量 $r$ 是否落在由相互作用矩阵所生成的可行性锥（feasibility cone）之内，这是一个理解共存问题的强大几何框架 [@problem_id:2510805]。通过解决这个问题，您将获得应用线性代数来预测多物种共存潜力的实践经验。", "problem": "考虑一个由 $n$ 个物种组成的互惠群落，其由广义Lotka-Volterra（GLV）方程描述：\n$$\\frac{dx_{i}}{dt} = x_{i}\\left(r_{i} + \\sum_{j=1}^{n} A_{ij} x_{j}\\right), \\quad i=1,\\dots,n,$$\n其中 $x_{i}$ 是物种 $i$ 的丰度，$r_{i}$ 是其内在人均增长率，$A_{ij}$ 是物种 $j$ 对物种 $i$ 的人均效应。一个严格可行平衡点是指所有物种的丰度 $x_{i}^{\\ast} > 0$ 的稳态。\n\n可行性等价于存在一个向量 $x^{\\ast} \\in \\mathbb{R}^{n}_{>0}$ 使得\n$$r + A x^{\\ast} = 0,$$\n或者等价地，\n$$r = (-A)\\,x^{\\ast} \\quad \\text{其中} \\quad x^{\\ast} \\in \\mathbb{R}^{n}_{\\ge 0}.$$\n定义由 $-A$ 的列向量生成的可行锥为\n$$\\mathcal{C}(-A) = \\left\\{ \\sum_{j=1}^{n} \\alpha_{j} c_{j} \\,:\\, \\alpha_{j} \\ge 0 \\ \\text{对所有 } j \\right\\},$$\n其中 $c_{j}$ 表示 $-A$ 的第 $j$ 列。当且仅当存在一个严格可行平衡点时，才有 $r \\in \\mathcal{C}(-A)$。\n\n一个由一个植物物种（索引为1）和两个动物互惠者（索引为2和3）组成的二分互惠网络，其相互作用矩阵为\n$$A \\;=\\; \\begin{pmatrix}\n-1.0 & 0.3 & 0.2 \\\\\n0.4 & -1.1 & -0.1 \\\\\n0.5 & -0.2 & -1.2\n\\end{pmatrix},$$\n其中，植物-动物功能群之间的正的非对角线项表示互惠效益，而动物功能群内部的负的非对角线项表示竞争。考虑内在增长率向量\n$$r \\;=\\; \\begin{pmatrix} 0.05 \\\\ 0.02 \\\\ 0.03 \\end{pmatrix}.$$\n\n仅使用GLV模型的第一性原理和上述锥定义，判断 $r$ 是否位于可行锥 $\\mathcal{C}(-A)$ 内，如果是，则计算求解 $r = (-A)\\,x^{\\ast}$ 的唯一严格可行平衡点 $x^{\\ast}$。将你的最终答案表示为向量 $x^{\\ast}$，使用与 $x$ 相同的任意丰度单位，并四舍五入到四位有效数字。你的最终答案必须是一个单独的行向量。最终答案中不要包含任何单位。", "solution": "该问题陈述是一个应用于群落生态学的、定义明确的线性代数练习。它在科学上基于已确立的Lotka-Volterra系统理论，包含了所有必要的数据，并且没有矛盾或含糊之处。因此，它被认为是有效的。\n\n核心任务是确定给定的内在增长率向量 $r$ 是否允许一个严格可行平衡点 $x^{\\ast}$ 的存在，其中所有物种的丰度均为正。根据问题定义，这等价于确定向量 $r$ 是否位于可行锥 $\\mathcal{C}(-A)$ 内，该锥是矩阵 $-A$ 列向量的所有非负线性组合的集合。在数学上，这需要解线性方程组 $r = (-A)x^{\\ast}$ 并验证解向量 $x^{\\ast}$ 的所有分量都是严格为正的，即对所有 $i$ 都有 $x_{i}^{\\ast} > 0$。\n\n给定的相互作用矩阵是：\n$$A = \\begin{pmatrix} -1.0 & 0.3 & 0.2 \\\\ 0.4 & -1.1 & -0.1 \\\\ 0.5 & -0.2 & -1.2 \\end{pmatrix}$$\n内在增长率向量是：\n$$r = \\begin{pmatrix} 0.05 \\\\ 0.02 \\\\ 0.03 \\end{pmatrix}$$\n需要求解的方程组是 $r = (-A)x^{\\ast}$，可以写成 $(-A)x^{\\ast} = r$。首先，我们构建矩阵 $-A$：\n$$-A = -\\begin{pmatrix} -1.0 & 0.3 & 0.2 \\\\ 0.4 & -1.1 & -0.1 \\\\ 0.5 & -0.2 & -1.2 \\end{pmatrix} = \\begin{pmatrix} 1.0 & -0.3 & -0.2 \\\\ -0.4 & 1.1 & 0.1 \\\\ -0.5 & 0.2 & 1.2 \\end{pmatrix}$$\n该线性系统是：\n$$\\begin{pmatrix} 1.0 & -0.3 & -0.2 \\\\ -0.4 & 1.1 & 0.1 \\\\ -0.5 & 0.2 & 1.2 \\end{pmatrix} \\begin{pmatrix} x_{1}^{\\ast} \\\\ x_{2}^{\\ast} \\\\ x_{3}^{\\ast} \\end{pmatrix} = \\begin{pmatrix} 0.05 \\\\ 0.02 \\\\ 0.03 \\end{pmatrix}$$\n为了确定是否存在唯一解，我们计算矩阵 $-A$ 的行列式。\n$$\\det(-A) = 1.0 \\left( (1.1)(1.2) - (0.1)(0.2) \\right) - (-0.3) \\left( (-0.4)(1.2) - (0.1)(-0.5) \\right) + (-0.2) \\left( (-0.4)(0.2) - (1.1)(-0.5) \\right)$$\n$$\\det(-A) = 1.0(1.32 - 0.02) + 0.3(-0.48 + 0.05) - 0.2(-0.08 + 0.55)$$\n$$\\det(-A) = 1.0(1.30) + 0.3(-0.43) - 0.2(0.47)$$\n$$\\det(-A) = 1.30 - 0.129 - 0.094 = 1.077$$\n由于 $\\det(-A) = 1.077 \\neq 0$，矩阵 $-A$ 是可逆的，因此存在唯一解 $x^{\\ast}$。解由 $x^{\\ast} = (-A)^{-1}r$ 给出。\n\n我们使用伴随矩阵法计算逆矩阵 $(-A)^{-1}$，公式为 $(-A)^{-1} = \\frac{1}{\\det(-A)}\\text{adj}(-A)$。伴随矩阵是代数余子式矩阵的转置。\n$-A$ 的代数余子式矩阵 $C$ 是：\n$$C_{11} = 1.30, \\quad C_{12} = 0.43, \\quad C_{13} = 0.47$$\n$$C_{21} = 0.32, \\quad C_{22} = 1.10, \\quad C_{23} = -0.05$$\n$$C_{31} = 0.19, \\quad C_{32} = -0.02, \\quad C_{33} = 0.98$$\n所以，伴随矩阵是：\n$$\\text{adj}(-A) = C^{T} = \\begin{pmatrix} 1.30 & 0.32 & 0.19 \\\\ 0.43 & 1.10 & -0.02 \\\\ 0.47 & -0.05 & 0.98 \\end{pmatrix}$$\n逆矩阵是：\n$$(-A)^{-1} = \\frac{1}{1.077} \\begin{pmatrix} 1.30 & 0.32 & 0.19 \\\\ 0.43 & 1.10 & -0.02 \\\\ 0.47 & -0.05 & 0.98 \\end{pmatrix}$$\n现在，我们计算平衡向量 $x^{\\ast}$：\n$$x^{\\ast} = (-A)^{-1}r = \\frac{1}{1.077} \\begin{pmatrix} 1.30 & 0.32 & 0.19 \\\\ 0.43 & 1.10 & -0.02 \\\\ 0.47 & -0.05 & 0.98 \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 0.02 \\\\ 0.03 \\end{pmatrix}$$\n$$x^{\\ast} = \\frac{1}{1.077} \\begin{pmatrix} (1.30)(0.05) + (0.32)(0.02) + (0.19)(0.03) \\\\ (0.43)(0.05) + (1.10)(0.02) - (0.02)(0.03) \\\\ (0.47)(0.05) - (0.05)(0.02) + (0.98)(0.03) \\end{pmatrix}$$\n$$x^{\\ast} = \\frac{1}{1.077} \\begin{pmatrix} 0.065 + 0.0064 + 0.0057 \\\\ 0.0215 + 0.0220 - 0.0006 \\\\ 0.0235 - 0.0010 + 0.0294 \\end{pmatrix} = \\frac{1}{1.077} \\begin{pmatrix} 0.0771 \\\\ 0.0429 \\\\ 0.0519 \\end{pmatrix}$$\n对每个分量进行最后的除法运算：\n$$x_{1}^{\\ast} = \\frac{0.0771}{1.077} \\approx 0.0715877...$$\n$$x_{2}^{\\ast} = \\frac{0.0429}{1.077} \\approx 0.0398328...$$\n$$x_{3}^{\\ast} = \\frac{0.0519}{1.077} \\approx 0.0481894...$$\n所有分量 $x_{1}^{\\ast}$、$x_{2}^{\\ast}$ 和 $x_{3}^{\\ast}$ 都是严格为正的。这证实了向量 $r$ 位于可行锥 $\\mathcal{C}(-A)$ 内，并且存在一个严格可行平衡点。\n\n按要求将结果四舍五入到四位有效数字：\n$$x_{1}^{\\ast} \\approx 0.07159$$\n$$x_{2}^{\\ast} \\approx 0.03983$$\n$$x_{3}^{\\ast} \\approx 0.04819$$\n平衡丰度向量为 $x^{\\ast} = (0.07159, 0.03983, 0.04819)^{T}$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.07159 & 0.03983 & 0.04819\n\\end{pmatrix}\n}\n$$", "id": "2510805"}, {"introduction": "一旦我们确定共存是可能的，下一个关键问题是这种状态是否稳定。一个不稳定的平衡点，即使所有物种密度都为正，在生态学上也是脆弱的，无法在微小扰动下持续存在。这个实践将探讨一个互惠共生系统中合作与稳定之间的经典矛盾关系 [@problem_id:2510887]。您将从第一性原理出发，推导出互惠强度 $m$ 压倒自我调节的稳定力量 $d$ 从而导致不稳定的临界阈值，这个练习揭示了一个基本原则：互惠共生关系若要稳定，必须受到自我限制的调节。", "problem": "考虑一个三物种广义 Lotka–Volterra (GLV) 系统，其物种丰度为 $x_{1}(t)$、$x_{2}(t)$ 和 $x_{3}(t)$，由以下方程组决定\n$$\n\\frac{dx_{i}}{dt} \\;=\\; x_{i}\\!\\left(r_{i} \\;+\\; \\sum_{j=1}^{3} a_{ij}\\, x_{j}\\right), \\quad i \\in \\{1,2,3\\},\n$$\n其中 $r = (r_{1},r_{2},r_{3})^{\\top}$ 是内禀增长率向量，$A=(a_{ij})$ 是相互作用矩阵。假设所有内禀增长率相等且为正，即 $r_{1}=r_{2}=r_{3}=r$ 且 $r>0$。相互作用矩阵是对称且三对角的，\n$$\nA \\;=\\; \\begin{pmatrix}\n-d & m & 0 \\\\\nm & -d & m \\\\\n0 & m & -d\n\\end{pmatrix},\n$$\n其中对角线上的自调节强度 $d>0$，相邻物种间的互惠耦合强度 $m\\ge 0$。\n\n从 GLV 系统的定义性质、平衡点的定义以及局部稳定性的线性化原理出发，根据第一性原理推导使系统存在严格正平衡点 $x^{\\ast} \\in \\mathbb{R}^{3}_{>0}$ 且该平衡点是局部渐近稳定的关于 $d$ 和 $m$ 的条件。然后，确定 $m_{\\max}$ 作为 $d$ 的函数所能取得的最大值，使得对于任意 $0 \\le m < m_{\\max}$，系统都存在一个严格正且局部渐近稳定的平衡点。将你的最终答案表示为仅含 $d$ 的单个闭式表达式。无需四舍五入，也无需单位。你的最终答案必须仅为 $m_{\\max}$ 的表达式。", "solution": "所述问题提法恰当，有科学依据，并包含了获得唯一解所需的所有信息。分析过程首先在于确立严格正平衡点存在的条件，其次在于确定该平衡点局部渐近稳定的条件。\n\n设物种丰度由向量 $\\mathbf{x} = (x_1, x_2, x_3)^{\\top}$ 表示。广义 Lotka-Volterra (GLV) 系统由下式给出\n$$\n\\frac{dx_{i}}{dt} = x_{i} \\left(r_{i} + \\sum_{j=1}^{3} a_{ij} x_{j}\\right), \\quad i \\in \\{1, 2, 3\\}\n$$\n其参数为 $r_{1}=r_{2}=r_{3}=r>0$，相互作用矩阵为\n$$\nA = \\begin{pmatrix}\n-d & m & 0 \\\\\nm & -d & m \\\\\n0 & m & -d\n\\end{pmatrix}\n$$\n其中 $d>0$ 且 $m \\ge 0$。\n\n通过令 $\\frac{d\\mathbf{x}}{dt} = \\mathbf{0}$，可以找到一个平衡解 $\\mathbf{x}^* = (x_1^*, x_2^*, x_3^*)^{\\top}$。我们寻求一个严格正平衡点，其中对于所有 $i \\in \\{1, 2, 3\\}$ 都有 $x_i^* > 0$。对于这样的平衡点，条件简化为线性系统：\n$$\nr_{i} + \\sum_{j=1}^{3} a_{ij} x_{j}^* = 0, \\quad \\text{for } i \\in \\{1, 2, 3\\}\n$$\n写成矩阵形式为 $A \\mathbf{x}^* = -\\mathbf{r}$，其中 $\\mathbf{r} = (r, r, r)^{\\top}$。方程组为：\n\\begin{align*}\n-d x_1^* + m x_2^* \\quad &= -r \\quad (1) \\\\\nm x_1^* - d x_2^* + m x_3^* &= -r \\quad (2) \\\\\nm x_2^* - d x_3^* &= -r \\quad (3)\n\\end{align*}\n由方程 $(1)$ 和 $(3)$ 可得 $d x_1^* - r = m x_2^* = d x_3^* - r$，这意味着 $d x_1^* = d x_3^*$。由于 $d>0$，必有 $x_1^* = x_3^*$。这种对称性可从相互作用矩阵 $A$ 的结构中预见到。\n\n将 $x_3^* = x_1^*$ 代入方程 $(2)$ 得到 $2m x_1^* - d x_2^* = -r$。现在我们得到一个关于 $x_1^*$ 和 $x_2^*$ 的二元线性方程组：\n\\begin{align*}\n-d x_1^* + m x_2^* &= -r \\\\\n2m x_1^* - d x_2^* &= -r\n\\end{align*}\n求解此方程组，例如将第一个方程乘以 $d$，第二个方程乘以 $m$ 并相加，可得 $(-d^2 + 2m^2)x_1^* = -dr - mr = -r(d+m)$。这得出：\n$$\nx_1^* = \\frac{-r(d+m)}{2m^2 - d^2} = \\frac{r(d+m)}{d^2 - 2m^2}\n$$\n由 $x_1^* = x_3^*$，我们有 $x_3^* = \\frac{r(d+m)}{d^2 - 2m^2}$。现在，我们求解 $x_2^*$。由方程 $(1)$ 可知，$m x_2^* = d x_1^* - r$。\n$$\nm x_2^* = d \\left( \\frac{r(d+m)}{d^2 - 2m^2} \\right) - r = r \\left( \\frac{d(d+m)}{d^2 - 2m^2} - 1 \\right) = r \\left( \\frac{d^2+md - (d^2 - 2m^2)}{d^2 - 2m^2} \\right) = r \\frac{md+2m^2}{d^2 - 2m^2} = r \\frac{m(d+2m)}{d^2 - 2m^2}\n$$\n当 $m>0$ 时，两边除以 $m$ 可得 $x_2^* = \\frac{r(d+2m)}{d^2 - 2m^2}$。若 $m=0$，系统解耦，可得 $x_i^*=r/d > 0$。推导出的公式与此极限情况一致。\n\n为使平衡点为严格正 ($x_i^* > 0$)，鉴于 $r>0$，$d>0$ 和 $m \\ge 0$，分子 $r(d+m)$ 和 $r(d+2m)$ 是严格正的。因此，正性的条件完全取决于公共分母的符号：\n$$\nd^2 - 2m^2 > 0 \\implies d^2 > 2m^2\n$$\n由于 $d$ 和 $m$ 为非负数，这等价于 $d > \\sqrt{2} m$，或 $m < d/\\sqrt{2}$。\n\n接下来，我们分析此平衡点的局部渐近稳定性。稳定性由在平衡点 $\\mathbf{x}^*$ 处计算的雅可比矩阵 $J$ 的特征值决定。雅可比矩阵的元素为：\n$$\nJ_{ik}(\\mathbf{x}) = \\frac{\\partial \\dot{x}_i}{\\partial x_k} = \\delta_{ik}\\left(r_{i} + \\sum_{j=1}^{3} a_{ij} x_{j}\\right) + x_{i} a_{ik}\n$$\n在平衡点 $\\mathbf{x}^*$ 处，括号中的项为零，因此雅可比矩阵为 $J^* = J(\\mathbf{x}^*)$，其元素为 $J_{ik}^* = x_i^* a_{ik}$。这可以写成矩阵形式 $J^* = D_x A$，其中 $D_x = \\text{diag}(x_1^*, x_2^*, x_3^*)$ 是一个对角元为正的对角矩阵。\n\n如果 $J^*$ 的所有特征值都具有负实部，则该平衡点是局部渐近稳定的。为分析 $J^* = D_x A$ 的特征值，我们进行相似变换，该变换不改变特征值。令 $D_x^{1/2} = \\text{diag}(\\sqrt{x_1^*}, \\sqrt{x_2^*}, \\sqrt{x_3^*})$。考虑矩阵 $S$：\n$$\nS = D_x^{1/2} A D_x^{1/2}\n$$\n雅可比矩阵 $J^*$ 与 $S$ 相似，因为 $S = D_x^{-1/2} J^* D_x^{1/2}$。由于 $A$ 是实对称矩阵，且 $D_x^{1/2}$ 是实对角矩阵（因此也是对称的），所以矩阵 $S$ 也是实对称的：\n$$\nS^{\\top} = (D_x^{1/2} A D_x^{1/2})^{\\top} = (D_x^{1/2})^{\\top} A^{\\top} (D_x^{1/2})^{\\top} = D_x^{1/2} A D_x^{1/2} = S\n$$\n实对称矩阵只有实特征值。因此，$S$ 的特征值，也即 $J^*$ 的特征值，都是实数。要实现渐近稳定，所有特征值必须严格为负。这等价于矩阵 $S$ 是负定矩阵的条件。\n\n一个矩阵 $S$ 是负定的，当且仅当对于所有非零向量 $\\mathbf{z}$，都有 $\\mathbf{z}^{\\top} S \\mathbf{z} < 0$。代入 $S$ 的定义：\n$$\n\\mathbf{z}^{\\top} (D_x^{1/2} A D_x^{1/2}) \\mathbf{z} < 0\n$$\n令 $\\mathbf{y} = D_x^{1/2} \\mathbf{z}$。由于 $D_x^{1/2}$ 可逆，$\\mathbf{y}$ 是非零向量当且仅当 $\\mathbf{z}$ 是非零向量。该条件变为：\n$$\n\\mathbf{y}^{\\top} A \\mathbf{y} < 0\n$$\n对于所有非零向量 $\\mathbf{y}$。这正是矩阵 $A$ 是负定的定义。\n\n为确定对称矩阵 $A$ 何时为负定，我们对矩阵 $-A$ 应用西尔维斯特准则 (Sylvester's criterion)。矩阵 $-A$ 必须是正定的，这意味着它的所有顺序主子式都必须严格为正。\n$$\n-A = \\begin{pmatrix}\nd & -m & 0 \\\\\n-m & d & -m \\\\\n0 & -m & d\n\\end{pmatrix}\n$$\n第一个顺序主子式是 $\\Delta_1 = d$。条件是 $\\Delta_1 > 0$，而已知 $d>0$。\n第二个顺序主子式是：\n$$\n\\Delta_2 = \\det \\begin{pmatrix} d & -m \\\\ -m & d \\end{pmatrix} = d^2 - m^2\n$$\n条件是 $\\Delta_2 > 0$，这意味着 $d^2 > m^2$，或者说 $d > m$（因为 $d, m \\ge 0$）。\n第三个顺序主子式是 $\\Delta_3 = \\det(-A)$：\n$$\n\\Delta_3 = d(d^2 - m^2) - (-m)(-md) = d^3 - dm^2 - dm^2 = d^3 - 2dm^2 = d(d^2 - 2m^2)\n$$\n条件是 $\\Delta_3 > 0$。由于 $d>0$，这可以简化为 $d^2 - 2m^2 > 0$，即 $d > \\sqrt{2} m$。\n\n稳定性的条件集合是 $\\{d>0, d>m, d>\\sqrt{2} m\\}$。由于 $\\sqrt{2} \\approx 1.414 > 1$，条件 $d > \\sqrt{2} m$ 是最严格的，并且它蕴含了 $d>m$。因此，局部渐近稳定的条件是 $m < d/\\sqrt{2}$。\n\n值得注意的是，存在严格正平衡点的条件（$m < d/\\sqrt{2}$）与其局部渐近稳定的条件是完全相同的。因此，系统存在一个严格正且局部渐近稳定的平衡点，当且仅当 $0 \\le m < d/\\sqrt{2}$。\n\n问题要求找出最大的 $m_{\\max}$ 值，使得对于区间 $0 \\le m < m_{\\max}$ 内的任意 $m$，所求的平衡点都存在且稳定。根据我们推导出的条件 $0 \\le m < d/\\sqrt{2}$，我们可以直接确定 $m_{\\max}$。\n$$\nm_{\\max} = \\frac{d}{\\sqrt{2}}\n$$", "answer": "$$\\boxed{\\frac{d}{\\sqrt{2}}}$$", "id": "2510887"}, {"introduction": "超越单纯的分析，我们现在转向一个处于生态保护和管理核心的实际问题：如果一个生态网络不稳定或接近临界点，我们如何才能最有效地进行干预？这个计算问题介绍了一种来自矩阵微扰理论的强大技术来指导此类干预措施 [@problem_id:2510908]。您将计算“最优微扰方向”，以确定哪些相互作用强度为增强网络稳定性提供了最有效的途径。这项实践将理论稳定性分析与应用于生态系统管理的、数据驱动的决策联系起来。", "problem": "给定代表生态网络群落雅可比矩阵（群落矩阵）的实方阵，其中对角线元素表示自调控，非对角线元素表示种间相互作用的净效应。局部稳定性由主导特征值决定，该特征值定义为具有最大实部的特征值。考虑一个由二进制掩码选定的相互作用系数子集发生的一阶（无穷小）微小变化。您的任务是，对每个测试用例，计算单位弗罗贝尼乌斯范数下的容许扰动方向，该方向能最有效地一阶降低主导特征值的实部，并报告相应的最大瞬时下降值。\n\n使用的基本原理包括：矩阵的特征值和左/右特征向量的定义，以及针对单特征值的一阶矩阵微扰理论。假设在所有提供的案例中，主导特征值都是单特征值。设主导特征值的实部表示为 $\\Re\\{\\lambda_{\\max}(A)\\}$。设 $A \\in \\mathbb{R}^{n \\times n}$ 表示群落矩阵，设 $M \\in \\{0,1\\}^{n \\times n}$ 是指定哪些元素可以被改变的二进制掩码。您必须限制扰动 $\\Delta \\in \\mathbb{R}^{n \\times n}$ 同时满足两个约束条件：(i) 逐元素支撑约束 $M \\odot \\Delta = \\Delta$（只有掩码值为1的元素才能为非零值），以及 (ii) 单位弗罗贝尼乌斯范数约束 $\\|\\Delta\\|_{\\mathrm{F}} = 1$。在所有满足条件的 $\\Delta$ 中，计算在 $A$ 点上能使 $\\Re\\{\\lambda_{\\max}(A)\\}$ 产生最大瞬时下降（最负的一阶方向导数）的方向，并报告此最大瞬时下降的值。如果没有元素被允许改变（即掩码全为零），则容许方向为零矩阵，报告的值必须为 $0$。\n\n角度单位不适用。不存在物理单位。所有输出必须是实数。\n\n测试套件。对于下方的每个测试用例，$A$是群落矩阵，$M$是容许改变元素的二进制掩码：\n- 测试用例 $1$（类互惠网络；仅非对角线元素可变）：\n  - $A_1 = \\begin{bmatrix} -0.5 & 0.3 & 0.2 \\\\ 0.4 & -0.6 & 0.1 \\\\ 0.2 & 0.15 & -0.4 \\end{bmatrix}$\n  - $M_1 = \\begin{bmatrix} 0 & 1 & 1 \\\\ 1 & 0 & 1 \\\\ 1 & 1 & 0 \\end{bmatrix}$\n- 测试用例 $2$（类营养网络；仅指定的跨功能群链接子集可变）：\n  - $A_2 = \\begin{bmatrix} -0.7 & 0.0 & -0.9 & 0.0 \\\\ 0.3 & -0.5 & 0.0 & -0.6 \\\\ 0.8 & 0.0 & -0.9 & 0.0 \\\\ 0.0 & 0.7 & 0.2 & -0.4 \\end{bmatrix}$\n  - $M_2$ 在位置 $(0,2)$、$(1,3)$、$(3,2)$ 处为1，其余位置为0，即，\n    $M_2 = \\begin{bmatrix} 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\end{bmatrix}$\n- 测试用例 $3$（无容许变化；掩码全为零）：\n  - $A_3 = \\begin{bmatrix} -0.3 & 0.2 & 0.0 \\\\ 0.1 & -0.4 & 0.1 \\\\ 0.0 & 0.2 & -0.5 \\end{bmatrix}$\n  - $M_3 = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$\n- 测试用例 $4$（捕食者-猎物振荡子系统；仅该子系统可变）：\n  - $A_4 = \\begin{bmatrix} -0.1 & -1.2 & 0.0 \\\\ 1.5 & -0.1 & 0.0 \\\\ 0.0 & 0.0 & -0.8 \\end{bmatrix}$\n  - $M_4 = \\begin{bmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$\n\n精确计算要求：\n- 设 $\\lambda_{\\max}(A)$ 表示 $A$ 的具有最大实部的特征值。如果实部存在并列，则可以使用任意一个并列的特征值；所提供的测试套件避免了精确并列的情况。\n- 计算 $\\Re\\{\\lambda_{\\max}(A)\\}$ 在 $A$ 点沿容许方向的一阶方向导数，并选择单位弗罗贝尼乌斯范数的容许方向，以使该导数最小化（即，给出最大的瞬时下降）。\n- 对每个测试用例，报告这个最小化的方向导数值（一个 $\\le 0$ 的实数）。如果 $M$ 是零掩码，则报告 $0$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含按顺序排列的测试用例结果，格式为方括号括起来的逗号分隔列表，例如 $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$。\n- 每个 $\\text{result}_k$ 必须是一个浮点数，表示单位弗罗贝尼乌斯范数容许扰动下 $\\Re\\{\\lambda_{\\max}(A_k)\\}$ 的最大瞬时下降值。", "solution": "该问题经评估为有效，因为它科学地基于生态网络稳定性分析和矩阵微扰理论的既定原理，问题设定良好，具有明确的目标和约束，并以精确、客观的数学语言表达。\n\n目标是在无穷小扰动 $\\Delta \\in \\mathbb{R}^{n \\times n}$ 下，找到群落矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的主导特征值实部 $\\Re\\{\\lambda_{\\max}(A)\\}$ 的最大瞬时下降率。这等价于找到 $\\Re\\{\\lambda_{\\max}(A)\\}$ 在容许扰动 $\\Delta$ 方向上的方向导数的最小值。容许扰动受到两个条件的约束：\n1.  支撑约束：扰动只能影响二进制掩码 $M \\in \\{0,1\\}^{n \\times n}$ 中非零的 $A$ 元素。这表示为 $M \\odot \\Delta = \\Delta$，其中 $\\odot$ 表示逐元素的哈达玛积。\n2.  归一化约束：扰动必须具有单位弗罗贝尼乌斯范数，即 $\\|\\Delta\\|_{\\mathrm{F}} = 1$。\n\n解决方案通过使用一阶矩阵微扰理论，推导出该最小值的显式表达式。\n\n设 $\\lambda$ 是矩阵 $A$ 的一个单特征值，其对应的右特征向量为 $v$，左特征向量为 $w$。它们由以下关系定义：\n$$Av = \\lambda v$$\n$$w^T A = \\lambda w^T$$\n第二个方程等价于 $A^T w = \\lambda w$。问题陈述保证，对于所有给定的测试用例，主导特征值 $\\lambda_{\\max}(A)$ 都是单特征值。\n\n根据一阶微扰理论，由矩阵 $A$ 的无穷小扰动 $dA$ 引起的特征值 $\\lambda$ 的变化由下式给出：\n$$d\\lambda = \\frac{w^T (dA) v}{w^T v}$$\n对于单特征值，这个归一化因子 $w^T v$ 是非零的。\n\n为了找到最大下降率，我们将其表述为方向导数。$\\lambda$ 在 $A$ 点沿矩阵 $\\Delta$ 方向的方向导数为：\n$$D_{\\Delta}\\lambda(A) = \\frac{w^T \\Delta v}{w^T v}$$\n我们可以将此导数表示为弗罗贝尼乌斯内积，$\\langle X, Y \\rangle_{\\mathrm{F}} = \\text{tr}(X^T Y)$。项 $w^T \\Delta v$ 可写作：\n$$w^T \\Delta v = \\sum_{i,j} w_i \\Delta_{ij} v_j = \\sum_{i,j} (v_j w_i) \\Delta_{ij} = \\text{tr}((v w^T)^T \\Delta) = \\langle v w^T, \\Delta \\rangle_{\\mathrm{F}}$$\n因此，方向导数为：\n$$D_{\\Delta}\\lambda(A) = \\frac{\\langle v w^T, \\Delta \\rangle_{\\mathrm{F}}}{w^T v} = \\left\\langle \\frac{v w^T}{w^T v}, \\Delta \\right\\rangle_{\\mathrm{F}}$$\n这揭示了特征值 $\\lambda$ 相对于矩阵 $A$ 的梯度是 $\\nabla_A \\lambda = \\frac{w v^T}{w^T v}$。请注意，正确的梯度是 $\\frac{w v^T}{w^T v}$，其第 $(i,j)$ 个元素是 $\\frac{w_i v_j}{w^T v}$，对应于 $\\frac{\\partial \\lambda}{\\partial A_{ij}}$。内积变为 $\\text{tr}((\\nabla_A\\lambda)^T \\Delta) = \\text{tr}(\\frac{v w^T}{w^T v} \\Delta) = \\frac{w^T \\Delta v}{w^T v}$，这是一致的。\n我们使用正确的梯度 $\\nabla_A \\lambda = \\frac{w v^T}{w^T v}$。因此 $D_{\\Delta}\\lambda(A) = \\langle \\nabla_A \\lambda, \\Delta \\rangle_{\\mathrm{F}} = \\sum_{i,j} (\\nabla_A \\lambda)_{ij} \\Delta_{ij}$。\n\n我们的任务是最小化主导特征值 $\\lambda_{\\max}$ 实部的方向导数。由于扰动 $\\Delta$ 是实矩阵，我们有：\n$$D_{\\Delta}\\Re\\{\\lambda_{\\max}\\} = \\Re\\{D_{\\Delta}\\lambda_{\\max}\\} = \\Re\\{\\langle \\nabla_A \\lambda_{\\max}, \\Delta \\rangle_{\\mathrm{F}}\\} = \\langle \\Re\\{\\nabla_A \\lambda_{\\max}\\}, \\Delta \\rangle_{\\mathrm{F}}$$\n设 $G = \\Re\\{\\nabla_A \\lambda_{\\max}\\} = \\Re\\left\\{\\frac{w v^T}{w^T v}\\right\\}$，其中 $v$ 和 $w$ 对应于 $\\lambda_{\\max}$。目标是在给定约束下最小化 $\\langle G, \\Delta \\rangle_{\\mathrm{F}}$。\n\n支撑约束 $M \\odot \\Delta = \\Delta$ 限制了搜索空间。我们可以将其并入目标函数：\n$$\\langle G, \\Delta \\rangle_{\\mathrm{F}} = \\langle G, M \\odot \\Delta \\rangle_{\\mathrm{F}} = \\langle M \\odot G, \\Delta \\rangle_{\\mathrm{F}}$$\n设 $G' = M \\odot G$。问题简化为在 $\\|\\Delta\\|_{\\mathrm{F}} = 1$ 的约束下最小化 $\\langle G', \\Delta \\rangle_{\\mathrm{F}}$。\n\n根据柯西-施瓦茨不等式，对于任意两个矩阵 $X$ 和 $Y$，我们有 $|\\langle X, Y \\rangle_{\\mathrm{F}}| \\le \\|X\\|_{\\mathrm{F}} \\|Y\\|_{\\mathrm{F}}$。当 $\\Delta$ 的方向与 $G'$ 的方向完全相反时，内积达到最小值：\n$$\\Delta_{\\text{opt}} = -\\frac{G'}{\\|G'\\|_{\\mathrm{F}}}$$\n方向导数的最小值为：\n$$\\min_{\\Delta} \\langle G', \\Delta \\rangle_{\\mathrm{F}} = \\left\\langle G', -\\frac{G'}{\\|G'\\|_{\\mathrm{F}}} \\right\\rangle_{\\mathrm{F}} = -\\frac{\\|G'\\|_{\\mathrm{F}}^2}{\\|G'\\|_{\\mathrm{F}}} = -\\|G'\\|_{\\mathrm{F}}$$\n如果 $G'$ 是零矩阵（当 $M$ 是零矩阵时发生），则范数为 $0$，最小值为 $0$。\n\n因此，最大瞬时下降的最终表达式为：\n$$-\\|G'\\|_{\\mathrm{F}} = -\\left\\| M \\odot \\Re\\left\\{\\frac{w v^T}{w^T v}\\right\\} \\right\\|_{\\mathrm{F}}$$\n其中 $v$ 和 $w$ 分别是对应于矩阵 $A$ 的主导特征值 $\\lambda_{\\max}$ 的右特征向量和左特征向量。\n\n每个测试用例 $(A, M)$ 的计算步骤如下：\n1.  如果掩码 $M$ 是零矩阵，则结果为 $0.0$。\n2.  计算 $A$ 的特征值和右特征向量。确定主导特征值 $\\lambda_{\\max}$（实部最大的那个）及其对应的右特征向量 $v$。\n3.  计算转置矩阵 $A^T$ 的特征值和右特征向量。其特征值将与 $A$ 的相同。确定 $A^T$ 中对应于 $\\lambda_{\\max}$ 的特征向量 $w$。这个 $w$ 就是 $A$ 的左特征向量。\n4.  计算梯度矩阵 $G = \\Re\\left\\{\\frac{w v^T}{w^T v}\\right\\}$。请注意，如果 $\\lambda_{\\max}$ 是复数，则标量积 $w^T v$ 和外积 $w v^T$ 必须能处理复值向量。数值库返回的特征向量通常是归一化的，但分母 $w^T v$ 对梯度的正确缩放至关重要，并且通常不等于 $1$。\n5.  将掩码应用于梯度矩阵：$G' = M \\odot G$。\n6.  计算掩码后梯度的弗罗贝尼乌斯范数 $\\|G'\\|_{\\mathrm{F}}$。\n7.  最终结果是该范数的负值，即 $-\\|G'\\|_{\\mathrm{F}}$。该值保证小于或等于零。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all defined test cases and prints the results.\n    \"\"\"\n\n    def calculate_max_decrease(A, M):\n        \"\"\"\n        Computes the maximal instantaneous decrease of the real part of the \n        dominant eigenvalue of matrix A, for admissible perturbations defined by mask M.\n\n        Args:\n            A (np.ndarray): The square community matrix.\n            M (np.ndarray): The binary mask of admissible perturbations.\n\n        Returns:\n            float: The minimal value of the directional derivative, which represents\n                   the maximal instantaneous decrease (a non-positive number).\n        \"\"\"\n        # If the mask M is all zeros, no changes are allowed. The derivative is 0.\n        if not np.any(M):\n            return 0.0\n\n        # Step 1: Compute eigenvalues and right eigenvectors of A.\n        eigvals, right_eigvecs = np.linalg.eig(A)\n\n        # Step 2: Identify the dominant eigenvalue (largest real part) and its right eigenvector.\n        dominant_idx = np.argmax(eigvals.real)\n        lambda_max = eigvals[dominant_idx]\n        v = right_eigvecs[:, dominant_idx]\n\n        # Step 3: Compute the corresponding left eigenvector. This is the right\n        # eigenvector of A.T corresponding to the same eigenvalue lambda_max.\n        eigvals_T, left_eigvecs = np.linalg.eig(A.T)\n        \n        # Find the index of the eigenvalue in the transposed system that is closest to lambda_max.\n        # This handles potential floating point inaccuracies or reordering of eigenvalues.\n        left_dominant_idx = np.argmin(np.abs(eigvals_T - lambda_max))\n        w = left_eigvecs[:, left_dominant_idx]\n\n        # Step 4: Calculate the gradient of the eigenvalue with respect to an entry A_ij.\n        # The gradient matrix is G = (w v^T) / (w^T v).\n        w_dot_v = np.dot(w, v)\n        \n        # The problem statement guarantees a simple eigenvalue, so w_dot_v is non-zero.\n        # For a robust implementation, one could check if np.isclose(w_dot_v, 0),\n        # but it is not necessary for the given problem constraints.\n        grad_lambda = np.outer(w, v) / w_dot_v\n\n        # Step 5: We are interested in the derivative of the real part of the eigenvalue.\n        # For a real perturbation Delta, this is controlled by the real part of the gradient.\n        real_grad = grad_lambda.real\n\n        # Step 6: Apply the binary mask M to the gradient. This restricts the perturbation\n        # direction to the subspace of admissible changes.\n        masked_grad = M * real_grad\n\n        # Step 7: The maximal instantaneous decrease is the minimum value of the directional\n        # derivative, which equals the negative of the Frobenius norm of the masked gradient.\n        norm_masked_grad = np.linalg.norm(masked_grad, 'fro')\n\n        return -norm_masked_grad\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        (np.array([[-0.5, 0.3, 0.2], \n                   [0.4, -0.6, 0.1], \n                   [0.2, 0.15, -0.4]]),\n         np.array([[0, 1, 1], \n                   [1, 0, 1], \n                   [1, 1, 0]])),\n        # Test case 2\n        (np.array([[-0.7, 0.0, -0.9, 0.0], \n                   [0.3, -0.5, 0.0, -0.6], \n                   [0.8, 0.0, -0.9, 0.0], \n                   [0.0, 0.7, 0.2, -0.4]]),\n         np.array([[0, 0, 1, 0], \n                   [0, 0, 0, 1], \n                   [0, 0, 0, 0], \n                   [0, 0, 1, 0]])),\n        # Test case 3\n        (np.array([[-0.3, 0.2, 0.0], \n                   [0.1, -0.4, 0.1], \n                   [0.0, 0.2, -0.5]]),\n         np.array([[0, 0, 0], \n                   [0, 0, 0], \n                   [0, 0, 0]])),\n        # Test case 4\n        (np.array([[-0.1, -1.2, 0.0], \n                   [1.5, -0.1, 0.0], \n                   [0.0, 0.0, -0.8]]),\n         np.array([[1, 1, 0], \n                   [1, 1, 0], \n                   [0, 0, 0]]))\n    ]\n\n    results = []\n    for A, M in test_cases:\n        result = calculate_max_decrease(A, M)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "2510908"}]}