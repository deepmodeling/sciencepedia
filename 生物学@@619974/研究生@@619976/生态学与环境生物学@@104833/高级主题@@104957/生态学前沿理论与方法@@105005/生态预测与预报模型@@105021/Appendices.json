{"hands_on_practices": [{"introduction": "在构建复杂的预测模型之前，理解系统本身固有的可预测性至关重要。本次实践从一个经典的生态学模型——逻辑斯蒂映射（logistic map）入手，探索混沌动力学如何从根本上限制我们的预测能力。你将通过动手推导李雅普诺夫指数（Lyapunov exponent）这一衡量混沌的关键指标，并将其与预测时域（forecast horizon）这一实际概念直接联系起来，从而深刻理解初始条件的敏感依赖性是如何为预测设定一个硬性上限的。[@problem_id:2482775]", "problem": "考虑用作简单、理想化种群模型的混沌逻辑斯谛映射，\n$$\nx_{t+1} = f(x_t) = r\\,x_t\\,(1-x_t),\n$$\n其中 $r=4$ 且状态 $x_t \\in (0,1)$。假设系统在其不变概率密度函数 (PDF) 下在 $(0,1)$ 上是遍历的，并且该不变 PDF 存在且绝对连续。\n\nA部分：从一维映射的（最大）李雅普诺夫指数的定义出发，\n$$\n\\lambda = \\lim_{n\\to\\infty} \\frac{1}{n}\\sum_{t=0}^{n-1} \\ln|f'(x_t)|,\n$$\n并应用遍历性，用基于不变 PDF 的系综平均代替时间平均，推导在 $r=4$ 时李雅普诺夫指数 $\\lambda$ 的闭式表达式。您的推导必须明确且自包含。\n\nB部分：在一个短期生态预测中，初始条件 $x_0$ 是通过 $m$ 个独立同分布 (i.i.d.) 的观测值估计得出的，\n$$\ny_i = x_0 + \\varepsilon_i,\\quad i=1,\\dots,m,\n$$\n其中观测误差 $\\varepsilon_i$ 是高斯分布、零均值且独立的，标准差为 $\\sigma_{\\text{obs}}$。初始条件的估计值是样本均值 $\\hat{x}_0 = \\frac{1}{m}\\sum_{i=1}^m y_i$，产生的初始估计误差为 $e_0 = \\hat{x}_0 - x_0$，其标准差为 $\\sigma_0 = \\sigma_{\\text{obs}}/\\sqrt{m}$。假设此后为自由运行预测（无后续同化），并使用线性化误差动力学，结合A部分的李雅普诺夫指数和遍历性，将预报时效为 $n$ 时的均方根误差 (RMSE)，\n$$\n\\text{RMSE}(n) \\approx \\sigma_0 \\exp(\\lambda n),\n$$\n与用户定义的容差 $\\delta>0$ 关联起来。将预报时限 $n^\\ast$ 定义为使 $\\text{RMSE}(n)=\\delta$ 成立的最小非负实数 $n$，并推导 $n^\\ast$ 关于 $\\lambda$、$\\delta$ 和 $\\sigma_0$ 的闭式表达式。\n\nC部分：对于\n$$\nm=5,\\quad \\sigma_{\\text{obs}}=0.01,\\quad \\delta=0.1,\n$$\n使用自然对数对 $n^\\ast$ 进行数值计算。将预报时限的最终数值答案四舍五入到三位有效数字，并以时间步长为单位表示。本问题的最终答案必须是对应于 $n^\\ast$ 的单个实数（以时间步长为单位）。", "solution": "该问题是良定的且在科学上是合理的，可以进行严格求解。按要求，解答分为三部分。\n\nA部分：李雅普诺夫指数 $\\lambda$ 的推导。\n一维映射 $f(x)$ 的李雅普诺夫指数 $\\lambda$ 由时间平均定义：\n$$\n\\lambda = \\lim_{n\\to\\infty} \\frac{1}{n}\\sum_{t=0}^{n-1} \\ln|f'(x_t)|\n$$\n问题指出该系统是遍历的。根据遍历性假说，时间平均可以由不变概率密度函数 (PDF) $\\rho(x)$ 加权的系综（空间）平均代替：\n$$\n\\lambda = \\int_0^1 \\ln|f'(x)| \\rho(x) \\,dx\n$$\n对于参数 $r=4$ 的逻辑斯谛映射 $x_{t+1} = f(x_t) = r x_t (1-x_t)$，其函数为 $f(x) = 4x(1-x)$。其导数为 $f'(x) = 4 - 8x$。\n对于 $r=4$，已知逻辑斯谛映射具有一个绝对连续不变测度，其对应的反正弦概率密度函数为：\n$$\n\\rho(x) = \\frac{1}{\\pi\\sqrt{x(1-x)}}\n$$\n问题陈述确认了这样一个 PDF 的存在性，因此我们通过将 $f'(x)$ 和 $\\rho(x)$ 代入 $\\lambda$ 的积分表达式来继续：\n$$\n\\lambda = \\int_0^1 \\ln|4 - 8x| \\frac{1}{\\pi\\sqrt{x(1-x)}} \\,dx\n$$\n为计算此积分，我们进行变量替换。分母的形式提示我们进行 $x = \\sin^2(\\theta)$ 的代换。这意味着 $dx = 2\\sin(\\theta)\\cos(\\theta)\\,d\\theta$。$x$ 从 $0$ 到 $1$ 的积分限对应于 $\\theta$ 从 $0$ 到 $\\frac{\\pi}{2}$ 的积分限。\n被积函数中的各项变换如下：\n分母项 $\\sqrt{x(1-x)}$ 变为 $\\sqrt{\\sin^2(\\theta)(1-\\sin^2(\\theta))} = \\sqrt{\\sin^2(\\theta)\\cos^2(\\theta)} = \\sin(\\theta)\\cos(\\theta)$，其中 $\\theta \\in [0, \\frac{\\pi}{2}]$。\n对数内的表达式变为 $|4 - 8\\sin^2(\\theta)| = |4(1-2\\sin^2(\\theta))| = |4\\cos(2\\theta)|$。\n将这些代入 $\\lambda$ 的积分中：\n$$\n\\lambda = \\frac{1}{\\pi} \\int_0^{\\pi/2} \\ln|4\\cos(2\\theta)| \\frac{1}{\\sin(\\theta)\\cos(\\theta)} (2\\sin(\\theta)\\cos(\\theta))\\,d\\theta\n$$\n$$\n\\lambda = \\frac{2}{\\pi} \\int_0^{\\pi/2} \\ln|4\\cos(2\\theta)|\\,d\\theta\n$$\n利用对数的性质，我们可以分解被积函数：\n$$\n\\lambda = \\frac{2}{\\pi} \\int_0^{\\pi/2} (\\ln(4) + \\ln|\\cos(2\\theta)|)\\,d\\theta = \\frac{2}{\\pi} \\left[ \\int_0^{\\pi/2} \\ln(4)\\,d\\theta + \\int_0^{\\pi/2} \\ln|\\cos(2\\theta)|\\,d\\theta \\right]\n$$\n第一个积分是平凡的：$\\int_0^{\\pi/2} \\ln(4)\\,d\\theta = \\ln(4) \\left[\\theta\\right]_0^{\\pi/2} = \\frac{\\pi}{2}\\ln(4)$。\n第二个积分 $\\int_0^{\\pi/2} \\ln|\\cos(2\\theta)|\\,d\\theta$ 是一个已知结果。令 $u = 2\\theta$，则 $du = 2 d\\theta$。\n$$\n\\int_0^{\\pi/2} \\ln|\\cos(2\\theta)|\\,d\\theta = \\frac{1}{2} \\int_0^\\pi \\ln|\\cos(u)|\\,du\n$$\n这是积分学中的一个标准结果：$\\int_0^{\\pi/2} \\ln(\\sin(x))\\,dx = \\int_0^{\\pi/2} \\ln(\\cos(x))\\,dx = -\\frac{\\pi}{2}\\ln(2)$。\n积分 $\\int_0^\\pi \\ln|\\cos(u)|\\,du$ 可以被证明等于 $\\int_0^{\\pi/2} \\ln(\\cos(u))\\,du + \\int_{\\pi/2}^\\pi \\ln(-\\cos(u))\\,du$。第二部分计算得出 $\\int_0^{\\pi/2} \\ln(\\sin(v))\\,dv$。因此，$\\frac{1}{2} \\int_0^\\pi \\ln|\\cos(u)|\\,du = \\frac{1}{2} (2 \\times (-\\frac{\\pi}{2}\\ln(2))) = -\\frac{\\pi}{2}\\ln(2)$。\n将这些结果代回 $\\lambda$ 的表达式中：\n$$\n\\lambda = \\frac{2}{\\pi} \\left[ \\frac{\\pi}{2}\\ln(4) - \\frac{\\pi}{2}\\ln(2) \\right] = \\ln(4) - \\ln(2) = \\ln(2^2) - \\ln(2) = 2\\ln(2) - \\ln(2) = \\ln(2)\n$$\n李雅普诺夫指数的闭式表达式为 $\\lambda = \\ln(2)$。\n\nB部分：预报时限 $n^\\ast$ 的推导。\n问题给出了预报时效为 $n$ 时的均方根误差 (RMSE) 的近似公式：\n$$\n\\text{RMSE}(n) \\approx \\sigma_0 \\exp(\\lambda n)\n$$\n预报时限 $n^\\ast$ 被定义为使 RMSE 达到指定容差 $\\delta > 0$ 的最小非负实数 $n$。我们令 $\\text{RMSE}(n^\\ast) = \\delta$：\n$$\n\\delta = \\sigma_0 \\exp(\\lambda n^\\ast)\n$$\n为求得 $n^\\ast$ 的表达式，我们对此方程进行代数求解。首先，分离指数项：\n$$\n\\frac{\\delta}{\\sigma_0} = \\exp(\\lambda n^\\ast)\n$$\n对两边取自然对数：\n$$\n\\ln\\left(\\frac{\\delta}{\\sigma_0}\\right) = \\ln(\\exp(\\lambda n^\\ast)) = \\lambda n^\\ast\n$$\n最后，解出 $n^\\ast$：\n$$\nn^\\ast = \\frac{1}{\\lambda} \\ln\\left(\\frac{\\delta}{\\sigma_0}\\right)\n$$\n这就是预报时限 $n^\\ast$ 关于 $\\lambda$、$\\delta$ 和初始误差标准差 $\\sigma_0$ 的闭式表达式。\n\nC部分：$n^\\ast$ 的数值计算。\n给定以下数值：\n观测次数 $m=5$。\n观测误差标准差 $\\sigma_{\\text{obs}}=0.01$。\n误差容差 $\\delta=0.1$。\n从A部分可知，李雅普诺夫指数 $\\lambda = \\ln(2)$。\n初始误差标准差 $\\sigma_0$ 由 $\\sigma_0 = \\sigma_{\\text{obs}}/\\sqrt{m}$ 给出。代入数值：\n$$\n\\sigma_0 = \\frac{0.01}{\\sqrt{5}}\n$$\n现在，将所有值代入 $n^\\ast$ 的表达式中：\n$$\nn^\\ast = \\frac{1}{\\ln(2)} \\ln\\left(\\frac{0.1}{0.01/\\sqrt{5}}\\right)\n$$\n化简对数内的项：\n$$\n\\frac{0.1}{0.01/\\sqrt{5}} = \\frac{10^{-1}}{10^{-2}/\\sqrt{5}} = 10\\sqrt{5}\n$$\n$n^\\ast$ 的表达式变为：\n$$\nn^\\ast = \\frac{\\ln(10\\sqrt{5})}{\\ln(2)}\n$$\n我们现在计算其数值：\n$$\nn^\\ast = \\frac{\\ln(10 \\times 2.2360679...)}{\\ln(2)} = \\frac{\\ln(22.360679...)}{0.693147...} = \\frac{3.107232...}{0.693147...} \\approx 4.4828\n$$\n问题要求将答案四舍五入到三位有效数字。\n$$\nn^\\ast \\approx 4.48 \\text{ 时间步长}\n$$", "answer": "$$\n\\boxed{4.48}\n$$", "id": "2482775"}, {"introduction": "当我们有了模型结构后，下一步就是将其与数据进行拟合。在此过程中，一个常见的挑战是“同效异参性”（equifinality），即多组截然不同的参数组合却能产生几乎同样好的预测结果，这给模型解释和应用带来了困扰。在本次实践中，你将运用剖面似然分析（profile likelihood analysis）这一精密的统计技术，在一个状态空间模型中诊断同效异参性问题，并学习如何据此提出最有价值的新数据采集建议，这是构建稳健、可靠生态模型的关键技能。[@problem_id:2482790]", "problem": "您的任务是编写一个完整、可运行的程序，该程序利用剖面似然在一个生态预测模型中检测参数集之间的等效终局性，并据此提出额外的数据来解决该问题。生态背景是Gompertz种群模型的一个线性高斯状态空间表达形式，用于处理对数丰度时间序列。您的程序必须遵循基于原则的设计，从标准概率法则和关于高斯状态空间模型的成熟理论出发，并且必须生成一行具有指定内容和格式的输出。\n\n模型与基础：\n- 考虑由下式定义的状态过程\n$$\nz_{t+1} = \\phi z_t + c + \\eta_t,\n$$\n其中 $\\eta_t \\sim \\mathcal{N}(0,\\sigma_p^2)$ 是独立同分布的过程新息，$\\mathcal{N}$ 表示具有给定方差的高斯分布。观测过程为\n$$\ny_t = z_t + \\epsilon_t,\n$$\n其中 $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma_o^2)$ 是独立同分布的测量误差，且与 $\\eta_t$ 独立。参数向量为 $\\theta = (\\phi,c,\\sigma_p,\\sigma_o)$。\n\n- 对于给定的时间序列 $\\{y_t\\}_{t=1}^T$，在此线性高斯状态空间模型下，单步预测分布是高斯分布。精确的对数似然可以通过迭代应用由高斯共轭性所蕴含的卡尔曼滤波器预测-更新递归来计算：\n  1. 预测步骤（状态）：从后验 $(m_t, P_t)$，通过下式得到先验 $(m_{t+1|t}, P_{t+1|t})$\n  $$\n  m_{t+1|t} = \\phi m_t + c,\\quad P_{t+1|t} = \\phi^2 P_t + \\sigma_p^2.\n  $$\n  2. 对 $y_{t+1}$ 的观测预测：\n  $$\n  \\hat{y}_{t+1} = m_{t+1|t},\\quad S_{t+1} = P_{t+1|t} + \\sigma_o^2,\\quad v_{t+1} = y_{t+1} - \\hat{y}_{t+1}.\n  $$\n  3. 更新步骤（状态）：使用卡尔曼增益 $K_{t+1} = P_{t+1|t} / S_{t+1}$，\n  $$\n  m_{t+1} = m_{t+1|t} + K_{t+1} v_{t+1},\\quad P_{t+1} = P_{t+1|t} - K_{t+1}^2 S_{t+1}.\n  $$\n  $y_{t+1}$ 的单步预测对数似然贡献为\n  $$\n  \\ell_{t+1} = -\\tfrac{1}{2}\\left(\\log(2\\pi) + \\log S_{t+1} + \\frac{v_{t+1}^2}{S_{t+1}}\\right).\n  $$\n  对状态使用弥散先验，初始化 $m_1 = y_1$ 和一个大的方差（例如，$P_1 = 10^6$），然后对 $t = 1,\\dots,T-1$ 应用上述步骤，以计算总和 $\\ell = \\sum_{t=1}^{T-1} \\ell_{t+1}$。\n\n- 预报技巧度量：将 $y_{t+1}$ 的点预测定义为 $\\hat{y}_{t+1}=m_{t+1|t}$。将单步预测均方根误差 (RMSE) 定义为\n$$\n\\mathrm{RMSE}(\\theta) = \\sqrt{\\frac{1}{T-1}\\sum_{t=1}^{T-1} \\left(y_{t+1} - \\hat{y}_{t+1}\\right)^2}.\n$$\n\n剖面似然与等效终局性：\n- 对于焦点标量参数 $\\psi \\in \\{\\phi, c, \\sigma_p, \\sigma_o\\}$，其在网格 $\\mathcal{G}_\\psi$ 上的剖面对数似然为\n$$\n\\ell_p(\\psi) = \\max_{\\theta \\setminus \\{\\psi\\}} \\ \\ell(\\theta),\n$$\n其中 $\\ell(\\theta)$ 是卡尔曼滤波器的对数似然。类似地，将每个固定 $\\psi$ 下可达到的最小预报误差定义为\n$$\n\\mathrm{RMSE}_p(\\psi) = \\min_{\\theta \\setminus \\{\\psi\\}} \\ \\mathrm{RMSE}(\\theta).\n$$\n- 按如下方式检测等效终局性。对每个 $\\psi$ 计算：\n  - 集合 $\\mathcal{A}_\\psi = \\{\\psi \\in \\mathcal{G}_\\psi : \\ell_p(\\psi) \\ge \\ell_{\\max} - \\Delta\\}$，其中 $\\ell_{\\max} = \\max_{\\psi \\in \\mathcal{G}_\\psi} \\ell_p(\\psi)$ 且 $\\Delta = \\tfrac{1}{2}\\chi^2_{1,0.95}$，$\\chi^2_{1,0.95}$ 是具有1个自由度的卡方分布的 $0.95$ 分位数。\n  - 集合 $\\mathcal{B}_\\psi = \\{\\psi \\in \\mathcal{G}_\\psi : \\mathrm{RMSE}_p(\\psi) \\le (1+\\varepsilon)\\min_{\\psi \\in \\mathcal{G}_\\psi} \\mathrm{RMSE}_p(\\psi)\\}$，其中 $\\varepsilon = 0.05$。\n  - 交集 $\\mathcal{I}_\\psi = \\mathcal{A}_\\psi \\cap \\mathcal{B}_\\psi$。定义离散宽度比\n  $$\n  w_\\psi = \\frac{|\\mathcal{I}_\\psi|}{|\\mathcal{G}_\\psi|}.\n  $$\n  如果 $\\max_{\\psi} w_\\psi \\ge \\tau$ 且 $\\tau = 0.3$，则宣告存在等效终局性。表现出最强等效终局性的参数是达到最大 $w_\\psi$ 的那个 $\\psi$（若出现平局，则选择如下面所定义的最小索引）。\n- 为了量化所检测到的 $\\psi^\\star$ 的等效参数值之间预报技巧的相似性，计算技巧差距\n$$\ng = \\frac{\\max_{\\psi \\in \\mathcal{I}_{\\psi^\\star}} \\mathrm{RMSE}_p(\\psi) - \\min_{\\psi \\in \\mathcal{I}_{\\psi^\\star}} \\mathrm{RMSE}_p(\\psi)}{\\min_{\\psi \\in \\mathcal{I}_{\\psi^\\star}} \\mathrm{RMSE}_p(\\psi)}.\n$$\n如果未检测到等效终局性，则令 $g = 0$。\n\n程序要求：\n- 完全按照上述规定，实现基于精确卡尔曼滤波器的对数似然和单步预测RMSE。\n- 为保证可复现性，使用以下固定网格：\n  - 剖面网格：\n    - $\\phi$: $\\mathcal{G}_\\phi = \\{\\text{从 } 0.2 \\text{ 到 } 1.2 \\text{ 的 } 21 \\text{ 个线性间隔点}\\}$。\n    - $c$: $\\mathcal{G}_c = \\{\\text{从 } -0.1 \\text{ 到 } 0.5 \\text{ 的 } 21 \\text{ 个线性间隔点}\\}$。\n    - $\\sigma_p$: $\\mathcal{G}_{\\sigma_p} = \\{\\text{从 } 0.03 \\text{ 到 } 0.6 \\text{ 的 } 21 \\text{ 个对数间隔点}\\}$。\n    - $\\sigma_o$: $\\mathcal{G}_{\\sigma_o} = \\{\\text{从 } 0.03 \\text{ 到 } 0.6 \\text{ 的 } 21 \\text{ 个对数间隔点}\\}$。\n  - 用于剖面分析的滋扰参数网格：\n    - $\\phi$: $\\{\\text{从 } 0.0 \\text{ 到 } 1.2 \\text{ 的 } 11 \\text{ 个线性间隔点}\\}$。\n    - $c$: $\\{\\text{从 } -0.3 \\text{ 到 } 0.7 \\text{ 的 } 11 \\text{ 个线性间隔点}\\}$。\n    - $\\sigma_p$: $\\{\\text{从 } 0.01 \\text{ 到 } 1.0 \\text{ 的 } 11 \\text{ 个对数间隔点}\\}$。\n    - $\\sigma_o$: $\\{\\text{从 } 0.01 \\text{ 到 } 1.0 \\text{ 的 } 11 \\text{ 个对数间隔点}\\}$。\n  此处，“线性间隔”(linspace) 指在线性尺度上均匀分布，“对数间隔”(logspace) 指在对数尺度上均匀分布，适用于严格为正的界限。\n\n测试套件：\n- 严格使用以下三个时间序列（无量纲对数丰度），每个序列均以给定顺序的实数列表形式提供。\n  - 案例1（长度16）：\n    $$\n    [\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\n    0.1,\\,\n    0.285,\\,\n    0.44225,\\,\n    0.5769125,\\,\n    0.690375625,\\,\n    0.78681928125,\\,\n    0.8687963890625,\\,\n    0.938477930703125,\\,\n    0.9977062410976562,\\,\n    1.0480503049320078,\\,\n    1.0908427591922066,\\,\n    1.1272163453133756,\\,\n    1.1581338935163692,\\,\n    1.1844138094889148,\\,\n    1.2067517380655776,\\,\n    1.22573997735574\n    \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,]\n    $$\n  - 案例2（长度8）：\n    $$\n    [\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\n    0.22,\\,\n    0.28,\\,\n    0.29,\\,\n    0.35,\\,\n    0.34,\\,\n    0.42,\\,\n    0.40,\\,\n    0.47\n    \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,]\n    $$\n  - 案例3（长度16）：\n    $$\n    [\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\n    0.52,\\,\n    0.49,\\,\n    0.51,\\,\n    0.5,\\,\n    0.53,\\,\n    0.48,\\,\n    0.5,\\,\n    0.51,\\,\n    0.49,\\,\n    0.5,\\,\n    0.52,\\,\n    0.47,\\,\n    0.5,\\,\n    0.51,\\,\n    0.5,\\,\n    0.49\n    \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,]\n    $$\n\n索引、决策阈值和提议代码：\n- 参数索引必须按如下方式编码为整数：$\\phi \\rightarrow 0$, $c \\rightarrow 1$, $\\sigma_p \\rightarrow 2$, $\\sigma_o \\rightarrow 3$。\n- 等效终局性决策阈值必须严格使用上述定义：$\\Delta = \\tfrac{1}{2}\\chi^2_{1,0.95}$, $\\varepsilon = 0.05$, 以及 $\\tau = 0.3$。\n- 如果检测到具有最大宽度比 $w_\\psi$ 的参数存在等效终局性，使用以下整数代码提议一种额外的单一数据类型以最直接地解决该问题：\n  - $0$：不需要额外数据（仅在未检测到等效终局性时使用）。\n  - $1$：提高时间分辨率或增加时间序列长度（更多时间点）。\n  - $2$：在每个时间点重复观测，以更好地估计 $\\sigma_o$。\n  - $3$：重复过程单元（平行种群），以更好地估计 $\\sigma_p$。\n  - $4$：测量一个影响截距 $c$ 的环境协变量。\n  映射规则：如果检测到的参数是 $\\phi$，输出 $1$；如果是 $c$，输出 $4$；如果是 $\\sigma_o$，输出 $2$；如果是 $\\sigma_p$，输出 $3$。\n\n输出规范：\n- 对三个案例中的每一个，计算：\n  - 一个整数等效终局性标志 $f \\in \\{0,1\\}$（$1$ 表示检测到等效终局性），\n  - 具有最大 $w_\\psi$ 的参数的整数索引 $p$（如果 $f=0$，则使用 $-1$），\n  - 整数提议代码 $d$（如果 $f=0$，则使用 $0$），\n  - 按上述定义的技巧差距浮点数 $g$（如果 $f=0$，则使用 $0.0$）。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，列表内容为三个案例的结果，每个结果本身是一个形如 $[f,p,d,g]$ 的列表。例如，一个语法正确的输出是\n$$\n[[1,0,1,0.0375],[0,-1,0,0.0],[1,3,2,0.0123]]\n$$\n其中的实际数值由您在所提供的测试套件上的实现确定。不得打印任何额外文本。", "solution": "所提出的问题是开发并实现一个计算程序，用于在一个生态预测模型中检测和表征等效终局性。该模型是Gompertz种群动态的一个线性高斯状态空间表示。该程序必须基于剖面似然原理。如果检测到等效终局性，必须根据预定义的启发式规则提供收集额外数据的建议。问题陈述的有效性得到确认；它具有科学依据、提法明确、客观，并为得出唯一解提供了所有必要信息。我们现在从第一性原理推导所需算法。\n\n该系统由对数丰度 $z_t$ 的状态过程和测量值 $y_t$ 的观测过程描述。\n状态过程：\n$$\nz_{t+1} = \\phi z_t + c + \\eta_t, \\quad \\eta_t \\sim \\mathcal{N}(0, \\sigma_p^2)\n$$\n观测过程：\n$$\ny_t = z_t + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0, \\sigma_o^2)\n$$\n完整的参数向量是 $\\theta = (\\phi, c, \\sigma_p, \\sigma_o)$。对于给定的观测时间序列 $\\{y_t\\}_{t=1}^T$，我们的首要任务是计算对数似然函数 $\\ell(\\theta) = \\log P(\\{y_t\\}_{t=1}^T | \\theta)$ 和单步预测误差。\n\n**1. 通过卡尔曼滤波器计算对数似然和预报误差**\n\n对于线性高斯状态空间模型，精确的对数似然可以通过预测误差分解来计算，其中递归地寻找条件分布的算法是卡尔曼滤波器。状态 $z_t$ 在给定截至时间 $t$ 的观测值 $Y_t = \\{y_1, \\dots, y_t\\}$ 条件下的分布是高斯的：$P(z_t | Y_t, \\theta) = \\mathcal{N}(z_t | m_t, P_t)$。该滤波器在每个时间点 $t = 1, \\dots, T-1$ 分两步进行。\n\n首先是 **预测步骤**：将状态分布在时间上向前投影。在时间 $t$ 的后验分布 $\\mathcal{N}(m_t, P_t)$ 通过状态方程传播，得到时间 $t+1$ 的先验分布：\n$$\nP(z_{t+1} | Y_t, \\theta) = \\mathcal{N}(z_{t+1} | m_{t+1|t}, P_{t+1|t})\n$$\n其矩为：\n$$\nm_{t+1|t} = \\phi m_t + c\n$$\n$$\nP_{t+1|t} = \\phi^2 P_t + \\sigma_p^2\n$$\n这个关于状态 $z_{t+1}$ 的先验导出了下一个观测值 $y_{t+1}$ 的预测分布：\n$$\nP(y_{t+1} | Y_t, \\theta) = \\mathcal{N}(y_{t+1} | \\hat{y}_{t+1}, S_{t+1})\n$$\n其均值为 $\\hat{y}_{t+1} = m_{t+1|t}$，方差为 $S_{t+1} = P_{t+1|t} + \\sigma_o^2$。项 $v_{t+1} = y_{t+1} - \\hat{y}_{t+1}$ 是单步预测误差或新息。\n\n其次是 **更新步骤**：使用新的观测值 $y_{t+1}$ 通过贝叶斯法则更新状态分布，得到时间 $t+1$ 的后验分布：\n$$\nP(z_{t+1} | Y_{t+1}, \\theta) = \\mathcal{N}(z_{t+1} | m_{t+1}, P_{t+1})\n$$\n更新后的矩由下式给出：\n$$\nK_{t+1} = P_{t+1|t} / S_{t+1} \\quad (\\text{卡尔曼增益})\n$$\n$$\nm_{t+1} = m_{t+1|t} + K_{t+1} v_{t+1}\n$$\n$$\nP_{t+1} = P_{t+1|t} - K_{t+1}^2 S_{t+1}\n$$\n总对数似然是单步预测对数似然的总和：\n$$\n\\ell(\\theta) = \\sum_{t=1}^{T-1} \\log P(y_{t+1} | Y_t, \\theta) = \\sum_{t=1}^{T-1} \\left( -\\frac{1}{2}\\log(2\\pi) - \\frac{1}{2}\\log S_{t+1} - \\frac{1}{2}\\frac{v_{t+1}^2}{S_{t+1}} \\right)\n$$\n递归以对状态 $z_1$ 的弥散先验进行初始化。遵循规范，我们设置 $m_1 = y_1$ 和 $P_1 = 10^6$。单步预测均方根误差 (RMSE) 从新息中计算得出：\n$$\n\\mathrm{RMSE}(\\theta) = \\sqrt{\\frac{1}{T-1}\\sum_{t=1}^{T-1} v_{t+1}^2}\n$$\n\n**2. 剖面似然和剖面RMSE**\n\n等效终局性，即多个不同参数集对数据产生相似良好拟合的情况，使用剖面似然进行分析。对于一个焦点参数 $\\psi$（可以是 $\\phi, c, \\sigma_p, \\sigma_o$ 中的任意一个），剖面对数似然 $\\ell_p(\\psi)$ 是通过改变所有其他（滋扰）参数可实现的最大对数似然。\n$$\n\\ell_p(\\psi) = \\max_{\\theta \\setminus \\{\\psi\\}} \\ell(\\theta)\n$$\n类似地，剖面RMSE衡量在固定 $\\psi$ 时的最小预报误差：\n$$\n\\mathrm{RMSE}_p(\\psi) = \\min_{\\theta \\setminus \\{\\psi\\}} \\mathrm{RMSE}(\\theta)\n$$\n优化通过在指定的滋扰参数网格上进行网格搜索来执行。对于焦点参数网格 $\\mathcal{G}_\\psi$ 中的每个点 $\\psi_j$，我们对滋扰参数各自网格中的所有值组合评估 $\\ell(\\theta)$ 和 $\\mathrm{RMSE}(\\theta)$，并保留最大的 $\\ell$ 和最小的 RMSE。\n\n**3. 等效终局性检测**\n\n通过检查剖面似然和剖面RMSE曲面的平坦度来检测等效终局性。\n一个基于似然的 $\\psi$ 置信集定义为：\n$$\n\\mathcal{A}_\\psi = \\{\\psi \\in \\mathcal{G}_\\psi : \\ell_p(\\psi) \\ge \\ell_{\\max} - \\Delta\\}\n$$\n其中 $\\ell_{\\max} = \\max_{\\psi \\in \\mathcal{G}_\\psi} \\ell_p(\\psi)$，而 $\\Delta = \\frac{1}{2}\\chi^2_{1,0.95}$ 是基于威尔克斯定理对 $95\\%$ 置信区间的阈值。\n一个基于预报技巧的合理参数集定义为：\n$$\n\\mathcal{B}_\\psi = \\{\\psi \\in \\mathcal{G}_\\psi : \\mathrm{RMSE}_p(\\psi) \\le (1+\\varepsilon)\\min_{\\psi \\in \\mathcal{G}_\\psi} \\mathrm{RMSE}_p(\\psi)\\}\n$$\n其相对误差容限为 $\\varepsilon = 0.05$。\n这些集合的交集 $\\mathcal{I}_\\psi = \\mathcal{A}_\\psi \\cap \\mathcal{B}_\\psi$ 包含的参数值既在统计上合理，又能产生近乎最优的预报。参数 $\\psi$ 的等效终局性程度由该集合的相对大小量化：\n$$\nw_\\psi = \\frac{|\\mathcal{I}_\\psi|}{|\\mathcal{G}_\\psi|}\n$$\n如果所有参数中的最大宽度比超过阈值 $\\tau=0.3$，即 $\\max_\\psi w_\\psi \\ge 0.3$，则宣告存在等效终局性。使 $w_\\psi$ 最大化的参数 $\\psi^\\star$ 被认为受等效终局性影响最严重。\n\n**4. 技巧差距和数据提议**\n\n如果为参数 $\\psi^\\star$ 检测到等效终局性，我们通过技巧差距 $g$ 来量化等效参数值之间预报技巧的变化：\n$$\ng = \\frac{\\max_{\\psi \\in \\mathcal{I}_{\\psi^\\star}} \\mathrm{RMSE}_p(\\psi) - \\min_{\\psi \\in \\mathcal{I}_{\\psi^\\star}} \\mathrm{RMSE}_p(\\psi)}{\\min_{\\psi \\in \\mathcal{I}_{\\psi^\\star}} \\mathrm{RMSE_p}(\\psi)}\n$$\n这量化了等效终局性集合内表现最好和最差的参数之间预报误差的相对差异。如果未检测到等效终局性，则将 $g$ 设置为 $0$。\n\n最后，根据哪个参数 $\\psi^\\star$ 表现出最强的等效终局性，提出收集新数据的建议。该映射基于每个参数在模型中的作用：\n- $\\phi$ 控制时间动态：通过更多的时间点来解决（提议代码 $1$）。\n- $c$ 是截距/均值回归水平：通过测量环境驱动因素来解决（提议代码 $4$）。\n- $\\sigma_p$ 是过程方差：通过重复过程单元（例如，平行种群）来解决（提议代码 $3$）。\n- $\\sigma_o$ 是观测方差：通过在每个时间点重复观测来解决（提议代码 $2$）。\n\n如果未检测到等效终局性，则不提议新数据（代码 $0$）。记录等效终局性最强的参数的索引，如果未检测到，则设为 $-1$。这完成了该算法的正式规范。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\nimport itertools\n\ndef solve():\n    \"\"\"\n    Main solver function to perform equifinality analysis for all test cases.\n    \"\"\"\n    \n    # --- Define problem constants, thresholds, and grids ---\n    \n    # Test cases\n    test_cases = [\n        [0.1, 0.285, 0.44225, 0.5769125, 0.690375625, 0.78681928125,\n         0.8687963890625, 0.938477930703125, 0.9977062410976562, 1.0480503049320078,\n         1.0908427591922066, 1.1272163453133756, 1.1581338935163692, 1.1844138094889148,\n         1.2067517380655776, 1.22573997735574],\n        [0.22, 0.28, 0.29, 0.35, 0.34, 0.42, 0.40, 0.47],\n        [0.52, 0.49, 0.51, 0.5, 0.53, 0.48, 0.5, 0.51, 0.49, 0.5,\n         0.52, 0.47, 0.5, 0.51, 0.5, 0.49]\n    ]\n\n    # Parameter names and indices\n    PARAM_NAMES = ['phi', 'c', 'sigma_p', 'sigma_o']\n    PARAM_INDICES = {name: i for i, name in enumerate(PARAM_NAMES)}\n\n    # Parameter grids for profiling\n    PROFILE_GRIDS = {\n        'phi': np.linspace(0.2, 1.2, 21),\n        'c': np.linspace(-0.1, 0.5, 21),\n        'sigma_p': np.logspace(np.log10(0.03), np.log10(0.6), 21),\n        'sigma_o': np.logspace(np.log10(0.03), np.log10(0.6), 21)\n    }\n\n    # Nuisance parameter grids for optimization\n    NUISANCE_GRIDS = {\n        'phi': np.linspace(0.0, 1.2, 11),\n        'c': np.linspace(-0.3, 0.7, 11),\n        'sigma_p': np.logspace(np.log10(0.01), np.log10(1.0), 11),\n        'sigma_o': np.logspace(np.log10(0.01), np.log10(1.0), 11)\n    }\n    \n    # Decision thresholds and constants\n    DELTA = 0.5 * chi2.ppf(0.95, df=1)\n    EPSILON = 0.05\n    TAU = 0.3\n    \n    # Proposal code mapping: param_index -> data_code\n    PROPOSAL_MAP = {0: 1, 1: 4, 2: 3, 3: 2}\n\n    # --- Core functions ---\n\n    def kalman_filter_loglik_rmse(theta, y):\n        \"\"\"\n        Computes log-likelihood and RMSE using the Kalman filter.\n        theta: tuple (phi, c, sigma_p, sigma_o)\n        y: numpy array of time series data\n        \"\"\"\n        phi, c, sigma_p, sigma_o = theta\n        T = len(y)\n        \n        m_t = y[0]\n        P_t = 1e6\n        \n        log_likelihood_sum = 0.0\n        squared_error_sum = 0.0\n        \n        for t in range(1, T):\n            # Prediction\n            m_pred = phi * m_t + c\n            P_pred = phi**2 * P_t + sigma_p**2\n            \n            # Observation prediction\n            y_hat = m_pred\n            v = y[t] - y_hat\n            S = P_pred + sigma_o**2\n            \n            if S = 0: # Numerical stability\n                return -np.inf, np.inf\n\n            # Log-likelihood contribution\n            log_likelihood_sum += -0.5 * (np.log(2 * np.pi) + np.log(S) + v**2 / S)\n            squared_error_sum += v**2\n\n            # Update\n            K = P_pred / S\n            m_t = m_pred + K * v\n            P_t = P_pred - K**2 * S\n\n        rmse = np.sqrt(squared_error_sum / (T - 1))\n        return log_likelihood_sum, rmse\n\n    # --- Main processing loop ---\n    \n    final_results = []\n    \n    for y_case in test_cases:\n        y_data = np.array(y_case)\n        w_values = []\n        all_profiles = {}\n\n        # Profile each of the 4 parameters\n        for focal_param_idx, focal_param_name in enumerate(PARAM_NAMES):\n            profile_loglik = []\n            profile_rmse = []\n            \n            nuisance_param_names = [p for p in PARAM_NAMES if p != focal_param_name]\n            nuisance_grids = [NUISANCE_GRIDS[name] for name in nuisance_param_names]\n\n            for focal_val in PROFILE_GRIDS[focal_param_name]:\n                max_loglik = -np.inf\n                min_rmse = np.inf\n                \n                # Grid search over nuisance parameters\n                for nuisance_vals in itertools.product(*nuisance_grids):\n                    params = {focal_param_name: focal_val}\n                    for i, name in enumerate(nuisance_param_names):\n                        params[name] = nuisance_vals[i]\n                    \n                    theta = (params['phi'], params['c'], params['sigma_p'], params['sigma_o'])\n                    \n                    loglik, rmse = kalman_filter_loglik_rmse(theta, y_data)\n                    \n                    max_loglik = max(max_loglik, loglik)\n                    min_rmse = min(min_rmse, rmse)\n                \n                profile_loglik.append(max_loglik)\n                profile_rmse.append(min_rmse)\n\n            profile_loglik = np.array(profile_loglik)\n            profile_rmse = np.array(profile_rmse)\n            all_profiles[focal_param_name] = {'loglik': profile_loglik, 'rmse': profile_rmse}\n\n            # Calculate width ratio w_psi\n            l_max = np.max(profile_loglik)\n            rmse_min = np.min(profile_rmse)\n\n            # Check for invalid profiles (e.g., all -inf)\n            if np.isinf(l_max) or np.isinf(rmse_min):\n                w = 0.0\n            else:\n                A_indices = np.where(profile_loglik >= l_max - DELTA)[0]\n                B_indices = np.where(profile_rmse = (1.0 + EPSILON) * rmse_min)[0]\n                I_indices = np.intersect1d(A_indices, B_indices)\n                w = len(I_indices) / len(PROFILE_GRIDS[focal_param_name])\n            \n            w_values.append(w)\n\n        # Equifinality decision logic\n        max_w = np.max(w_values)\n        \n        if max_w >= TAU:\n            f = 1\n            p = np.argmax(w_values)\n            d = PROPOSAL_MAP[p]\n            \n            # Calculate skill gap g\n            winning_param_name = PARAM_NAMES[p]\n            profile_for_g = all_profiles[winning_param_name]\n            \n            l_max_g = np.max(profile_for_g['loglik'])\n            rmse_min_g = np.min(profile_for_g['rmse'])\n            \n            A_indices_g = np.where(profile_for_g['loglik'] >= l_max_g - DELTA)[0]\n            B_indices_g = np.where(profile_for_g['rmse'] = (1.0 + EPSILON) * rmse_min_g)[0]\n            I_indices_g = np.intersect1d(A_indices_g, B_indices_g)\n            \n            rmses_in_I = profile_for_g['rmse'][I_indices_g]\n            min_rmse_in_I = np.min(rmses_in_I)\n            max_rmse_in_I = np.max(rmses_in_I)\n            \n            g = (max_rmse_in_I - min_rmse_in_I) / min_rmse_in_I if min_rmse_in_I > 0 else 0.0\n\n        else:\n            f = 0\n            p = -1\n            d = 0\n            g = 0.0\n            \n        final_results.append([f, p, d, g])\n\n    # Format and print the final output\n    case_strings = [f\"[{res[0]},{res[1]},{res[2]},{res[3]:.4g}]\" for res in final_results]\n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "2482790"}, {"introduction": "在掌握了模型的内在局限和诊断工具之后，生态预测的最终目标之一是主动提升模型的预测能力，这通常意味着需要战略性地规划未来的数据采集工作。这项高级实践将你置于决策者的角色，运用贝叶斯优化实验设计（Bayesian optimal experimental design）的原理来分配有限的监测预算。你将学习如何优化一个观测网络，以最大程度地降低对特定生态指标的预测不确定性，这是生态预测前沿领域中的一个强大概念。[@problem_id:2482812]", "problem": "您的任务是设计一个程序，通过在观测站点间分配固定的监测投入来增强一个生态观测网络，以最小化某个指定生态状态线性泛函的后验预测方差。其数学背景如下。未知的生态状态是一个向量 $\\theta \\in \\mathbb{R}^d$，服从高斯先验 $\\theta \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)$，其中 $\\mu_0 \\in \\mathbb{R}^d$ 且 $\\Sigma_0 \\in \\mathbb{R}^{d \\times d}$ 是对称正定矩阵。您可以假设 $\\mu_0$ 是已知的，但它不影响方差的计算。共有 $m$ 个候选观测站点。若以非负的投入 $e_i \\ge 0$ 对站点 $i \\in \\{1,\\dots,m\\}$ 进行采样，会得到一个标量观测值，其模型为 $y_i = h_i^\\top \\theta + \\varepsilon_i$，其中 $h_i \\in \\mathbb{R}^d$ 是已知的，观测误差 $\\varepsilon_i$ 是独立的，且 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2 / e_i)$。这遵循了抽样理论中常见的方差-投入关系，即方差与投入成反比减小。各项投入必须满足一个固定的总预算 $\\sum_{i=1}^m e_i = B$，其中 $B \\ge 0$ 是给定的。预测目标是一个线性泛函 $\\psi = g^\\top \\theta$，其中 $g \\in \\mathbb{R}^d$ 是已知的。目标是在观测任何数据之前，选择投入向量 $e = (e_1,\\dots,e_m)$ 以最小化 $\\psi$ 的期望后验预测方差。期望信息增益可以通过高斯模型下 $\\psi$ 不确定性的减少来量化。在线性高斯设定下，期望后验方差仅依赖于设计 $e$ 而不依赖于尚未观测到的数据。\n\n仅从高斯条件作用定律、观测误差的独立性以及上面指定的 $\\varepsilon_i$ 的方差-投入关系出发，推导出关于 $\\psi$ 的期望后验预测方差作为 $e$ 的函数的优化目标，并建立一个计算方法来找到满足约束条件 $\\sum_i e_i = B$ 和 $e_i \\ge 0$ 的最优 $e$。您的程序应使用一种基于梯度的、有理论依据的连续优化方法，为下面的每个测试用例数值求解这个分配问题，然后报告优化后的投入分配以及最小化的 $\\psi$ 的期望后验预测方差。所有的算术和线性代数运算都必须在实数上进行。\n\n测试套件。对每个案例 $k$，给定维度 $d_k$、站点数 $m_k$、先验协方差 $\\Sigma_{0,k}$、站点向量 $h_{i,k}$、噪声尺度参数 $\\sigma_{i,k}^2$、目标向量 $g_k$ 和预算 $B_k$。在所有案例中，假设 $\\mu_{0,k}$ 是任意的，并且不影响方差计算。\n\n- 案例 $1$（通用情况，多方向信息丰富）：\n  - $d_1 = 3$， $m_1 = 3$。\n  - $\\Sigma_{0,1} = \\begin{bmatrix} 1.0  0.2  0.1 \\\\ 0.2  0.5  0.1 \\\\ 0.1  0.1  1.5 \\end{bmatrix}$。\n  - $h_{1,1}^\\top = [1.0, 0.2, 0.0]$，$h_{2,1}^\\top = [0.3, 1.0, 0.5]$，$h_{3,1}^\\top = [0.0, 0.2, 1.0]$。\n  - $\\sigma_{1,1}^2 = 2.0$，$\\sigma_{2,1}^2 = 1.5$，$\\sigma_{3,1}^2 = 3.0$。\n  - $g_1^\\top = [0.5, 0.3, 0.2]$。\n  - $B_1 = 4.0$。\n\n- 案例 $2$（边界情况：预算为零）：\n  - 与案例 $1$ 相同，除了 $B_2 = 0.0$。\n\n- 案例 $3$（混合信息几何，站点数多于状态维度）：\n  - $d_3 = 2$，$m_3 = 4$。\n  - $\\Sigma_{0,3} = \\begin{bmatrix} 1.0  0.3 \\\\ 0.3  1.2 \\end{bmatrix}$。\n  - $h_{1,3}^\\top = [1.0, 0.0]$，$h_{2,3}^\\top = [0.0, 1.0]$，$h_{3,3}^\\top = [0.7, 0.7]$，$h_{4,3}^\\top = [1.0, -0.2]$。\n  - $\\sigma_{1,3}^2 = 0.6$，$\\sigma_{2,3}^2 = 2.0$，$\\sigma_{3,3}^2 = 1.5$，$\\sigma_{4,3}^2 = 0.8$。\n  - $g_3^\\top = [1.0, 0.5]$。\n  - $B_3 = 3.0$。\n\n您的程序必须对每个案例 $k \\in \\{1,2,3\\}$，计算出最优分配 $e^\\star_k$ 和 $\\psi_k = g_k^\\top \\theta_k$ 的最小化期望后验预测方差 $v^\\star_k$。然后生成单行输出，包含一个长度为 3 的列表，其中第 $k$ 个元素本身是一个列表，由 $e^\\star_k$ 的 $m_k$ 个元素和 $v^\\star_k$ 组成。将每个投入 $e^\\star_{i,k}$ 四舍五入到恰好 4 位小数，并将每个最小化方差 $v^\\star_k$ 四舍五入到恰好 6 位小数。最终输出必须是形如 $[\\,[e^\\star_{1,1},\\dots,e^\\star_{m_1,1},v^\\star_1],\\,[e^\\star_{1,2},\\dots,e^\\star_{m_2,2},v^\\star_2],\\,[e^\\star_{1,3},\\dots,e^\\star_{m_3,3},v^\\star_3]\\,]$ 的单行文本，逗号和方括号需与所示完全一致，且不插入空格。\n\n角度单位不适用。没有需要报告的物理单位。所有输出都必须是实数。程序不得读取任何输入，必须运行至完成，并仅打印指定的单行输出。", "solution": "所提出的问题是贝叶斯最优实验设计中一个适定的、有科学依据的练习。它是 c-最优性的一个具体实例，其目标是最小化未知状态参数的单个线性组合的后验方差。该问题是有效的，可以使用贝叶斯统计和凸优化的既定原则来解决。我们将着手推导解决方案。\n\n问题在线性高斯框架内定义。未知状态是一个 $d$ 维向量 $\\theta \\in \\mathbb{R}^d$，服从高斯先验分布：\n$$\n\\theta \\sim \\mathcal{N}(\\mu_0, \\Sigma_0)\n$$\n其中 $\\mu_0$ 是先验均值，$\\Sigma_0$ 是 $d \\times d$ 对称正定先验协方差矩阵。\n\n在 $m$ 个站点进行观测。对每个站点 $i \\in \\{1, \\dots, m\\}$，观测值 $y_i$ 是状态 $\\theta$ 的线性函数，并被独立高斯噪声所干扰：\n$$\ny_i = h_i^\\top \\theta + \\varepsilon_i\n$$\n观测向量 $h_i \\in \\mathbb{R}^d$ 是已知的。噪声项 $\\varepsilon_i$ 是独立的，服从正态分布 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2 / e_i)$，其中 $e_i \\ge 0$ 是在站点 $i$ 的采样投入，$\\sigma_i^2$ 是一个已知的比例因子。总投入受预算 $B$ 的约束，即 $\\sum_{i=1}^m e_i = B$。\n\n我们可以将整个观测集合 $y = (y_1, \\dots, y_m)^\\top$ 用一个向量方程表示：\n$$\ny = H\\theta + \\varepsilon\n$$\n其中 $H$ 是一个 $m \\times d$ 的设计矩阵，其行是 $h_i^\\top$，而 $\\varepsilon = (\\varepsilon_1, \\dots, \\varepsilon_m)^\\top$ 是噪声项向量。由于 $\\varepsilon_i$ 的独立性，$\\varepsilon$ 的协方差矩阵是对角的：\n$$\n\\Sigma_\\varepsilon(e) = \\text{Cov}(\\varepsilon) = \\text{diag}\\left(\\frac{\\sigma_1^2}{e_1}, \\frac{\\sigma_2^2}{e_2}, \\dots, \\frac{\\sigma_m^2}{e_m}\\right)\n$$\n因此，给定状态 $\\theta$ 时数据 $y$ 的似然为 $y|\\theta \\sim \\mathcal{N}(H\\theta, \\Sigma_\\varepsilon(e))$。\n\n我们关心的是在结合观测信息后 $\\theta$ 的后验分布。根据线性高斯模型的贝叶斯定理，后验分布 $p(\\theta|y)$ 也是高斯的，即 $\\theta|y \\sim \\mathcal{N}(\\mu_e, \\Sigma_e)$。后验协方差矩阵 $\\Sigma_e$ 由后验精度矩阵 $\\Lambda_e$ 的逆给出，而后验精度矩阵是先验精度 $\\Lambda_0 = \\Sigma_0^{-1}$ 与从数据中获得的精度之和，后者由似然的费雪信息矩阵 $H^\\top\\Sigma_\\varepsilon(e)^{-1}H$ 表示。\n$$\n\\Lambda_e = \\Sigma_e^{-1} = \\Sigma_0^{-1} + H^\\top\\Sigma_\\varepsilon(e)^{-1}H\n$$\n对角噪声协方差矩阵的逆是：\n$$\n\\Sigma_\\varepsilon(e)^{-1} = \\text{diag}\\left(\\frac{e_1}{\\sigma_1^2}, \\frac{e_2}{\\sigma_2^2}, \\dots, \\frac{e_m}{\\sigma_m^2}\\right)\n$$\n将此代入数据精度的表达式中得到：\n$$\nH^\\top\\Sigma_\\varepsilon(e)^{-1}H = \\sum_{i=1}^m h_i \\left(\\frac{e_i}{\\sigma_i^2}\\right) h_i^\\top = \\sum_{i=1}^m \\frac{e_i}{\\sigma_i^2} h_i h_i^\\top\n$$\n这里，$h_i h_i^\\top$ 是一个 $d \\times d$ 的秩为1的矩阵（一个外积）。因此，$\\theta$ 的后验协方差是：\n$$\n\\Sigma_e = \\left( \\Sigma_0^{-1} + \\sum_{i=1}^m \\frac{e_i}{\\sigma_i^2} h_i h_i^\\top \\right)^{-1}\n$$\n该模型的一个关键特征是，后验协方差 $\\Sigma_e$ 依赖于实验设计（投入分配 $e$），而不依赖于将要观测到的具体数据值 $y$。因此，“期望后验预测方差”就是用这个依赖于设计的协方差矩阵计算出的后验方差。\n\n目标是最小化线性泛函 $\\psi = g^\\top\\theta$ 的后验预测方差。对于给定的 $\\theta$ 后验分布，$\\psi$ 的方差为：\n$$\n\\text{Var}(\\psi|\\text{data}) = g^\\top \\text{Var}(\\theta|\\text{data}) g = g^\\top \\Sigma_e g\n$$\n这就得到了我们需要最小化的目标函数 $V(e)$：\n$$\nV(e) = g^\\top \\left( \\Sigma_0^{-1} + \\sum_{i=1}^m \\frac{e_i}{\\sigma_i^2} h_i h_i^\\top \\right)^{-1} g\n$$\n优化问题是找到投入向量 $e = (e_1, \\dots, e_m)^\\top$ 来求解：\n$$\n\\min_{e \\in \\mathbb{R}^m} V(e) \\quad \\text{约束条件为} \\quad \\sum_{i=1}^m e_i = B \\quad \\text{且} \\quad e_i \\ge 0 \\text{ 对所有 } i.\n$$\n这是一个凸优化问题。目标函数 $V(e)$ 是矩阵凸函数 $X \\mapsto g^\\top X^{-1} g$ （在正定矩阵锥上）与一个从 $e$ 到后验精度矩阵的仿射映射的复合。约束集（一个单纯形）也是凸的。凸性确保了任何由合适算法找到的局部最小值也是全局最小值。\n\n为了使用基于梯度的优化算法，我们必须计算 $V(e)$ 的梯度。令 $M(e) = \\Sigma_0^{-1} + \\sum_{i=1}^m \\frac{e_i}{\\sigma_i^2} h_i h_i^\\top = \\Sigma_e^{-1}$。使用链式法则和矩阵求逆的导数恒等式 $\\frac{d}{dt}A^{-1} = -A^{-1} \\frac{dA}{dt} A^{-1}$，可以求得 $V(e)$ 关于 $e_k$ 的偏导数：\n$$\n\\frac{\\partial V(e)}{\\partial e_k} = g^\\top \\frac{\\partial M(e)^{-1}}{\\partial e_k} g = g^\\top \\left( -M(e)^{-1} \\frac{\\partial M(e)}{\\partial e_k} M(e)^{-1} \\right) g\n$$\n$M(e)$ 关于 $e_k$ 的导数就是 $e_k$ 的系数：\n$$\n\\frac{\\partial M(e)}{\\partial e_k} = \\frac{1}{\\sigma_k^2} h_k h_k^\\top\n$$\n将此代回，并回顾 $\\Sigma_e = M(e)^{-1}$，我们得到：\n$$\n\\frac{\\partial V(e)}{\\partial e_k} = - g^\\top \\Sigma_e \\left( \\frac{1}{\\sigma_k^2} h_k h_k^\\top \\right) \\Sigma_e g\n$$\n由于 $g^\\top \\Sigma_e h_k$ 是一个标量，我们可以重新排列表达式：\n$$\n\\frac{\\partial V(e)}{\\partial e_k} = - \\frac{1}{\\sigma_k^2} (g^\\top \\Sigma_e h_k) (h_k^\\top \\Sigma_e g) = - \\frac{1}{\\sigma_k^2} (h_k^\\top \\Sigma_e g)^2\n$$\n梯度向量是 $\\nabla_e V(e) = \\left(\\frac{\\partial V(e)}{\\partial e_1}, \\dots, \\frac{\\partial V(e)}{\\partial e_m}\\right)^\\top$。\n\n数值解将使用序列最小二乘规划（SLSQP）算法获得，这是一种适用于约束非线性优化的基于梯度的方法。该方法在 `scipy.optimize.minimize` 库函数中可用。我们将提供目标函数 $V(e)$、其解析雅可比（梯度）$\\nabla_e V(e)$、等式约束 $\\sum_i e_i - B = 0$ 和非负性边界 $e_i \\ge 0$。一个均匀分配，$e_i = B/m$，可作为优化器的合理初始猜测。\n\n对于预算 $B=0$ 的特殊情况，不可能进行采样，因此对所有 $i$ 都有 $e_i=0$。后验分布与先验分布相同，方差即为 $\\psi$ 的先验方差，即 $g^\\top\\Sigma_0 g$。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the ecological monitoring effort allocation problem for the given test cases.\n    \"\"\"\n    \n    # Define test cases\n    test_cases = [\n        # Case 1\n        {\n            \"d\": 3, \"m\": 3,\n            \"Sigma0\": np.array([[1.0, 0.2, 0.1], [0.2, 0.5, 0.1], [0.1, 0.1, 1.5]]),\n            \"H\": np.array([[1.0, 0.2, 0.0], [0.3, 1.0, 0.5], [0.0, 0.2, 1.0]]),\n            \"sigma2\": np.array([2.0, 1.5, 3.0]),\n            \"g\": np.array([0.5, 0.3, 0.2]),\n            \"B\": 4.0\n        },\n        # Case 2\n        {\n            \"d\": 3, \"m\": 3,\n            \"Sigma0\": np.array([[1.0, 0.2, 0.1], [0.2, 0.5, 0.1], [0.1, 0.1, 1.5]]),\n            \"H\": np.array([[1.0, 0.2, 0.0], [0.3, 1.0, 0.5], [0.0, 0.2, 1.0]]),\n            \"sigma2\": np.array([2.0, 1.5, 3.0]),\n            \"g\": np.array([0.5, 0.3, 0.2]),\n            \"B\": 0.0\n        },\n        # Case 3\n        {\n            \"d\": 2, \"m\": 4,\n            \"Sigma0\": np.array([[1.0, 0.3], [0.3, 1.2]]),\n            \"H\": np.array([[1.0, 0.0], [0.0, 1.0], [0.7, 0.7], [1.0, -0.2]]),\n            \"sigma2\": np.array([0.6, 2.0, 1.5, 0.8]),\n            \"g\": np.array([1.0, 0.5]),\n            \"B\": 3.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        e_star, v_star = solve_one_case(**case)\n        formatted_e = [f\"{val:.4f}\" for val in e_star]\n        formatted_v = f\"{v_star:.6f}\"\n        results.append(f'[{\",\".join(map(str, formatted_e))},{formatted_v}]')\n\n    print(f'[{\",\".join(results)}]')\n\ndef solve_one_case(d, m, Sigma0, H, sigma2, g, B):\n    \"\"\"\n    Solves a single instance of the effort allocation problem.\n    \"\"\"\n    # Handle the trivial case of zero budget\n    if B == 0.0:\n        e_star = np.zeros(m)\n        v_star = g.T @ Sigma0 @ g\n        return e_star, v_star\n\n    # Pre-compute the inverse of the prior covariance\n    Sigma0_inv = np.linalg.inv(Sigma0)\n\n    def objective(e, g_vec, S0_inv, H_mat, s2_vec):\n        \"\"\" The objective function V(e) to be minimized. \"\"\"\n        # Compute information gain from observations: sum(e_i/sigma_i^2 * h_i h_i^T)\n        info_gain = np.einsum('i,ij,ik->jk', e / s2_vec, H_mat, H_mat)\n        \n        # Posterior precision matrix M(e)\n        M = S0_inv + info_gain\n        \n        try:\n            # Posterior covariance matrix Sigma_e = M(e)^-1\n            Sigma_e = np.linalg.inv(M)\n        except np.linalg.LinAlgError:\n            # Return a large number if matrix is singular\n            return np.inf\n\n        # Posterior variance of psi = g^T theta\n        variance = g_vec.T @ Sigma_e @ g_vec\n        return variance\n\n    def jacobian(e, g_vec, S0_inv, H_mat, s2_vec):\n        \"\"\" The Jacobian (gradient) of the objective function. \"\"\"\n        # Compute information gain and posterior covariance as in the objective\n        info_gain = np.einsum('i,ij,ik->jk', e / s2_vec, H_mat, H_mat)\n        M = S0_inv + info_gain\n        \n        try:\n            Sigma_e = np.linalg.inv(M)\n        except np.linalg.LinAlgError:\n            return np.full_like(e, np.inf)\n\n        # Gradient component: grad_k = - (h_k^T Sigma_e g)^2 / sigma_k^2\n        # Vectorized computation for all k:\n        term = H_mat @ Sigma_e @ g_vec\n        grad = - (term**2) / s2_vec\n        return grad\n\n    # Initial guess: uniform allocation\n    e_init = np.full(m, B / m)\n\n    # Constraints: sum(e_i) = B\n    constraints = ({'type': 'eq', 'fun': lambda e: np.sum(e) - B})\n\n    # Bounds: e_i >= 0\n    bounds = [(0, None) for _ in range(m)]\n\n    # Perform the optimization\n    res = minimize(\n        objective,\n        e_init,\n        args=(g, Sigma0_inv, H, sigma2),\n        method='SLSQP',\n        jac=jacobian,\n        constraints=constraints,\n        bounds=bounds,\n        tol=1e-12,\n        options={'maxiter': 500}\n    )\n\n    e_star = res.x\n    # clean up small negative values from numerical precision issues\n    e_star[e_star  1e-9] = 0.0\n\n    v_star = res.fun\n    \n    return e_star, v_star\n\nsolve()\n```", "id": "2482812"}]}