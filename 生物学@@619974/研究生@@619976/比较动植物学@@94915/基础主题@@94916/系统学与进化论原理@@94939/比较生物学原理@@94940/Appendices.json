{"hands_on_practices": [{"introduction": "比较生物学的一个核心任务是重建进化历史。最大简约法是系统发育学中的一个基本原则，它主张最简单的解释（即需要最少进化改变的解释）是最好的。本练习将通过一个具体案例，指导您手动计算在不同系统发育树假设下，一组性状演化所需的最小改变次数，从而深入理解简约法在选择最佳进化树过程中的应用逻辑 [@problem_id:1769709]。", "problem": "一位进化生物学家正在研究三种新发现的地外脊椎动物之间的亲缘关系：*Aquasaurus fluitans*（物种A）、*Arboraptor saltans*（物种B）和*Xerocolossus lapis*（物种C）。一个相关的、更为原始的物种 *Geochelone antiqua* 被用作外群，为系统发育分析定根。该生物学家汇编了关于四个不同可遗传性状的数据：\n\n1.  **皮肤质地**：可以是光滑、有鳞或有甲。\n2.  **主要食性**：可以是植食性、肉食性或杂食性。\n3.  **肢体数量**：可以是4个或6个。\n4.  **生物发光**：可以是无或有。\n\n每个物种的性状状态如下：\n\n-   ***Geochelone antiqua***（外群）：光滑、植食性、4个肢体、无生物发光\n-   ***Aquasaurus fluitans***（A）：光滑、肉食性、6个肢体、有生物发光\n-   ***Arboraptor saltans***（B）：有鳞、肉食性、4个肢体、无生物发光\n-   ***Xerocolossus lapis***（C）：有甲、植食性、4个肢体、无生物发光\n\n针对物种A、B和C之间的进化关系，提出了两种相互竞争的假说：\n\n-   **假说1**：物种B和C的亲缘关系最近，形成一个分支，该分支是物种A的姐妹群。这种关系可以表示为 (A, (B, C))。\n-   **假说2**：物种A和B的亲缘关系最近，形成一个分支，该分支是物种C的姐妹群。这种关系可以表示为 (C, (A, B))。\n\n使用最大简约性原则（该原则指出，对观测数据的首选解释是最简单的那个），确定两种假说中更简约的那个假说所需的最小进化事件数（性状状态改变次数）。", "solution": "假设：每个性状都是无序且权重相等；外群状态极化每个性状，因此根（祖先）状态等于外群状态。我们计算在每个假定的有根拓扑结构上（外群连接在根部）所需的最小状态改变次数（Fitch简约法）。\n\n分类单元状态：\n- 外群（根部的祖先状态）：皮肤 = 光滑；食性 = 植食性；肢体 = 4；生物发光 = 无。\n- A：光滑、肉食性、6、有。\n- B：有鳞、肉食性、4、无。\n- C：有甲、植食性、4、无。\n\n定义两种内群拓扑结构：\n- 假说1 (H1)：$(A,(B,C))$。\n- 假说2 (H2)：$(C,(A,B))$。\n\n在每个假说下逐个性状的简约性计数：\n\n1) 皮肤质地（光滑/有鳞/有甲），根 = 光滑。\n- H1 $(A,(B,C))$：将内群根指定为光滑，以与A匹配，无需改变。在分支 $(B,C)$ 中，末端为有鳞和有甲，因此每个末端都需要从其祖先到其自身的一次改变。最小改变次数：$2$。\n- H2 $(C,(A,B))$：根 = 光滑，在通往C的分支上放置一个变为有甲的改变，在通往B的分支上放置一个变为有鳞的改变（保持A为光滑）。最小改变次数：$2$。\n因此，对于H1和H2，皮肤的成本均为$2$。\n\n2) 主要食性（植食性/肉食性/杂食性），存在的状态：仅植食性和肉食性，根 = 植食性。\n- H1 $(A,(B,C))$：设内群根为植食性。那么A（肉食性）在其分支上需要$1$次改变。在 $(B,C)$ 中，选择内部状态为植食性（以匹配根）；B（肉食性）需要$1$次改变；C（植食性）需要$0$次改变。总计：$2$次改变。\n- H2 $(C,(A,B))$：根 = 植食性，通过在通往 $(A,B)$ 分支的支上进行一次改变，将 $(A,B)$ 的内部状态设置为肉食性；然后A和B各需要$0$次改变；C（植食性）需要$0$次改变。总计：$1$次改变。\n因此，食性的成本对于H1是$2$，对于H2是$1$。\n\n3) 肢体数量（4或6），根 = $4$。\n- H1 $(A,(B,C))$：设内群根 $=4$；A $=6$ 在其分支上需要$1$次改变；$(B,C)$ 均为$=4$，因此没有额外的改变。总计：$1$。\n- H2 $(C,(A,B))$：选择 $(A,B)$ 的内部状态为$4$以匹配根；A $=6$ 在A的分支上需要$1$次改变；B $=4$ 需要$0$次改变；C $=4$ 需要$0$次改变。总计：$1$。\n因此，对于H1和H2，肢体的成本均为$1$。\n\n4) 生物发光（无/有），根 = 无。\n- H1 $(A,(B,C))$：根为无；A为有，在A的分支上需要$1$次改变；$(B,C)$ 均为无，需要$0$次改变。总计：$1$。\n- H2 $(C,(A,B))$：选择 $(A,B)$ 的内部状态为无；A为有，在A的分支上需要$1$次改变；B为无，需要$0$次改变；C为无，需要$0$次改变。总计：$1$。\n因此，对于H1和H2，生物发光的成本均为$1$。\n\n对所有性状求和：\n- H1 总改变次数：皮肤 $2$ + 食性 $2$ + 肢体 $1$ + 生物发光 $1$ $= 6$。\n- H2 总改变次数：皮肤 $2$ + 食性 $1$ + 肢体 $1$ + 生物发光 $1$ $= 5$。\n\n因此，更简约的假说是 $(C,(A,B))$，需要最少$5$次进化改变。", "answer": "$$\\boxed{5}$$", "id": "1769709"}, {"introduction": "在跨物种比较研究中，物种并非独立的统计单位，因为它们共享不同程度的进化历史。系统发育独立比较法 (Phylogenetically Independent Contrasts, PICs) 是一种经典而强大的方法，用于在检验连续性状间的相关性时校正系统发育带来的非独立性。本练习将引导您完成计算 PICs 的完整步骤，从原始的物种性状数据和系统发育树出发，将其转换为一组统计上独立的比较值，这是进行任何严谨的进化相关性分析的基础 [@problem_id:2604309]。", "problem": "一名研究人员希望检验两个连续性状——体型 $X$ 和叶面积 $Y$——在一组相关物种间是否相关，同时使用系统发育独立比较（PICs）方法来考虑共同祖先的影响。\n\n假设在一个有根二叉树上，连续性状的演化遵循布朗运动模型，其中方差随分支长度线性累积，且不同分支上的增量是独立的。分支长度代表演化时间。\n\n考虑一个有四个末端分类单元 $A$、$B$、$C$ 和 $D$ 的有根树，其拓扑结构和分支长度如下（所有分支长度单位任意但一致）：从根节点到内部节点 $N_{1}$ 的分支长度为 $0.5$，从 $N_{1}$ 到分类单元 $A$ 和 $B$ 的末端分支长度分别为 $0.6$ 和 $0.4$；从根节点到内部节点 $N_{2}$ 的分支长度为 $0.6$，从 $N_{2}$ 到分类单元 $C$ 和 $D$ 的末端分支长度分别为 $0.7$ 和 $0.3$。该树可概括为 $((A:0.6,B:0.4):0.5,(C:0.7,D:0.3):0.6)$。\n\n观察到的两个性状的末端值如下：\n- $X$：$x_{A}=5.2$，$x_{B}=4.6$，$x_{C}=6.1$，$x_{D}=5.5$。\n- $Y$：$y_{A}=2.6$，$y_{B}=2.2$，$y_{C}=3.1$，$y_{D}=2.7$。\n\n任务：\n1. 使用布朗运动假设和所提供的分支长度，从末端向根节点方向，计算在节点 $N_{1}$、$N_{2}$ 和根节点处性状 $X$ 和 $Y$ 的标准化系统发育独立比较（PICs）。在每个节点，将比较定义为“先列出的后裔减去后列出的后裔”，并对两个性状使用相同的减法顺序以使符号具有可比性（即，在 $N_{1}$ 处使用 $A-B$，在 $N_{2}$ 处使用 $C-D$，在根节点处使用 $N_{1}-N_{2}$）。\n2. 使用一个约束通过原点的线性模型（通过原点的回归），将 $Y$ 的标准化比较对 $X$ 的标准化比较进行回归。在标准化PICs的布朗运动模型下，该回归检验了性状间的相关性。\n3. 此回归的估计斜率是多少？将您的答案四舍五入到四位有效数字。以纯数字形式（无单位）表示您的答案。", "solution": "由 Felsenstein 发展的系统发育独立比较（PICs）方法，将相关的末端数据转换为一组独立的、标准化的值。对于一个给定的节点，它有两个直接后裔 $i$ 和 $j$，其性状值分别为 $x_i$ 和 $x_j$ ，从父节点 $k$ 到它们的分支长度分别为 $v_{k,i}$ 和 $v_{k,j}$，其步骤如下：\n1.  计算标准化比较：$PIC = \\frac{x_i - x_j}{\\sqrt{v_{k,i} + v_{k,j}}}$。\n2.  估计父节点 $k$ 处的节点值：$\\hat{x}_k = \\frac{(x_i/v_{k,i}) + (x_j/v_{k,j})}{1/v_{k,i} + 1/v_{k,j}}}$。\n3.  更新从节点 $k$ 到其祖先的分支长度。新的长度 $v'$ 是原始长度 $v$ 加上对节点估计值方差的调整：$v'_{k, \\text{ancestor}} = v_{k, \\text{ancestor}} + \\frac{v_{k,i} v_{k,j}}{v_{k,i} + v_{k,j}}}$。\n\n计算从末端向根节点进行。对于这个四分类单元的树，有 $4-1=3$ 个独立比较。\n\n首先，我们计算节点 $N_1$ 处分类单元 $A$ 和 $B$ 之间的比较。\n分支长度为 $v_{N_1,A}=0.6$ 和 $v_{N_1,B}=0.4$。\n对于性状 $X$：\n- 原始比较：$C_{X,N_1} = x_A - x_B = 5.2 - 4.6 = 0.6$。\n- 比较的方差：$v_{N_1,A} + v_{N_1,B} = 0.6 + 0.4 = 1.0$。\n- 标准化比较：$PIC_{X,N_1} = \\frac{0.6}{\\sqrt{1.0}} = 0.6$。\n对于性状 $Y$：\n- 原始比较：$C_{Y,N_1} = y_A - y_B = 2.6 - 2.2 = 0.4$。\n- 比较的方差：$1.0$。\n- 标准化比较：$PIC_{Y,N_1} = \\frac{0.4}{\\sqrt{1.0}} = 0.4$。\n\n接下来，我们估计在 $N_1$ 处的节点值并更新其分支长度。\n- 性状 $X$ 的节点值：$\\hat{x}_{N_1} = \\frac{x_A/v_{N_1,A} + x_B/v_{N_1,B}}{1/v_{N_1,A} + 1/v_{N_1,B}} = \\frac{5.2/0.6 + 4.6/0.4}{1/0.6 + 1/0.4} = \\frac{121/6}{25/6} = \\frac{121}{25} = 4.84$。\n- 性状 $Y$ 的节点值：$\\hat{y}_{N_1} = \\frac{y_A/v_{N_1,A} + y_B/v_{N_1,B}}{1/v_{N_1,A} + 1/v_{N_1,B}} = \\frac{2.6/0.6 + 2.2/0.4}{1/0.6 + 1/0.4} = \\frac{59/6}{25/6} = \\frac{59}{25} = 2.36$。\n- 从根节点到 $N_1$ 的原始分支长度为 $v_{R,N_1} = 0.5$。从这个新的复合末端 $N_1$ 到根节点的更新后分支长度是：\n$v'_{N_1} = v_{R,N_1} + \\frac{v_{N_1,A}v_{N_1,B}}{v_{N_1,A} + v_{N_1,B}} = 0.5 + \\frac{0.6 \\times 0.4}{0.6 + 0.4} = 0.5 + 0.24 = 0.74$。\n\n第二，我们计算节点 $N_2$ 处分类单元 $C$ 和 $D$ 之间的比较。\n分支长度为 $v_{N_2,C}=0.7$ 和 $v_{N_2,D}=0.3$。\n对于性状 $X$：\n- 原始比较：$C_{X,N_2} = x_C - x_D = 6.1 - 5.5 = 0.6$。\n- 比较的方差：$v_{N_2,C} + v_{N_2,D} = 0.7 + 0.3 = 1.0$。\n- 标准化比较：$PIC_{X,N_2} = \\frac{0.6}{\\sqrt{1.0}} = 0.6$。\n对于性状 $Y$：\n- 原始比较：$C_{Y,N_2} = y_C - y_D = 3.1 - 2.7 = 0.4$。\n- 比较的方差：$1.0$。\n- 标准化比较：$PIC_{Y,N_2} = \\frac{0.4}{\\sqrt{1.0}} = 0.4$。\n\n接下来，我们估计在 $N_2$ 处的节点值并更新其分支长度。\n- 性状 $X$ 的节点值：$\\hat{x}_{N_2} = \\frac{x_C/v_{N_2,C} + x_D/v_{N_2,D}}{1/v_{N_2,C} + 1/v_{N_2,D}} = \\frac{6.1/0.7 + 5.5/0.3}{1/0.7 + 1/0.3} = \\frac{568/21}{100/21} = \\frac{568}{100} = 5.68$。\n- 性状 $Y$ 的节点值：$\\hat{y}_{N_2} = \\frac{y_C/v_{N_2,C} + y_D/v_{N_2,D}}{1/v_{N_2,C} + 1/v_{N_2,D}} = \\frac{3.1/0.7 + 2.7/0.3}{1/0.7 + 1/0.3} = \\frac{282/21}{100/21} = \\frac{282}{100} = 2.82$。\n- 从根节点到 $N_2$ 的原始分支长度为 $v_{R,N_2} = 0.6$。从这个新的复合末端 $N_2$ 到根节点的更新后分支长度是：\n$v'_{N_2} = v_{R,N_2} + \\frac{v_{N_2,C}v_{N_2,D}}{v_{N_2,C} + v_{N_2,D}} = 0.6 + \\frac{0.7 \\times 0.3}{0.7 + 0.3} = 0.6 + 0.21 = 0.81$。\n\n第三，我们计算在根节点处复合节点 $N_1$ 和 $N_2$ 之间的最终比较。\n用于比较的值是估计的节点值 $\\hat{x}_{N_1}, \\hat{y}_{N_1}$ 和 $\\hat{x}_{N_2}, \\hat{y}_{N_2}$。方差基于更新后的分支长度 $v'_{N_1}$ 和 $v'_{N_2}$。\n对于性状 $X$：\n- 原始比较：$C_{X,R} = \\hat{x}_{N_1} - \\hat{x}_{N_2} = 4.84 - 5.68 = -0.84$。\n- 比较的方差：$v'_{N_1} + v'_{N_2} = 0.74 + 0.81 = 1.55$。\n- 标准化比较：$PIC_{X,R} = \\frac{-0.84}{\\sqrt{1.55}}$。\n对于性状 $Y$：\n- 原始比较：$C_{Y,R} = \\hat{y}_{N_1} - \\hat{y}_{N_2} = 2.36 - 2.82 = -0.46$。\n- 比较的方差：$1.55$。\n- 标准化比较：$PIC_{Y,R} = \\frac{-0.46}{\\sqrt{1.55}}$。\n\n现在，我们整理三对标准化比较 ($PIC_X$, $PIC_Y$)：\n1.  在 $N_1$ 处：$(0.6, 0.4)$\n2.  在 $N_2$ 处：$(0.6, 0.4)$\n3.  在根节点 $R$ 处：$(\\frac{-0.84}{\\sqrt{1.55}}, \\frac{-0.46}{\\sqrt{1.55}})$\n\n最后一步是通过原点将 $PIC_Y$ 值对 $PIC_X$ 值进行回归。模型是 $y_i = \\beta x_i + \\epsilon_i$。斜率 $\\beta$ 的公式是：\n$$ \\beta = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_i^2} $$\n其中 $x_i$ 是 $PIC_X$ 值，$y_i$ 是 $PIC_Y$ 值，且 $n=3$。\n\n我们计算分子 $\\sum x_i y_i$：\n$$ \\sum x_i y_i = (0.6)(0.4) + (0.6)(0.4) + \\left(\\frac{-0.84}{\\sqrt{1.55}}\\right)\\left(\\frac{-0.46}{\\sqrt{1.55}}\\right) $$\n$$ \\sum x_i y_i = 0.24 + 0.24 + \\frac{(-0.84)(-0.46)}{1.55} = 0.48 + \\frac{0.3864}{1.55} $$\n$$ \\sum x_i y_i = \\frac{0.48 \\times 1.55 + 0.3864}{1.55} = \\frac{0.744 + 0.3864}{1.55} = \\frac{1.1304}{1.55} $$\n\n我们计算分母 $\\sum x_i^2$：\n$$ \\sum x_i^2 = (0.6)^2 + (0.6)^2 + \\left(\\frac{-0.84}{\\sqrt{1.55}}\\right)^2 $$\n$$ \\sum x_i^2 = 0.36 + 0.36 + \\frac{(-0.84)^2}{1.55} = 0.72 + \\frac{0.7056}{1.55} $$\n$$ \\sum x_i^2 = \\frac{0.72 \\times 1.55 + 0.7056}{1.55} = \\frac{1.116 + 0.7056}{1.55} = \\frac{1.8216}{1.55} $$\n\n最后，我们计算斜率 $\\beta$：\n$$ \\beta = \\frac{\\sum x_i y_i}{\\sum x_i^2} = \\frac{1.1304 / 1.55}{1.8216 / 1.55} = \\frac{1.1304}{1.8216} \\approx 0.620553359... $$\n四舍五入到四位有效数字，估计的斜率为 $0.6206$。", "answer": "$$\\boxed{0.6206}$$", "id": "2604309"}, {"introduction": "现代比较生物学越来越多地依赖于复杂的统计模型来检验具体的进化假说。本练习将带您超越简约法等经典方法，进入基于模型的推断领域，利用马尔可夫 $k$-状态 (Mk) 模型来量化趋同演化的可能性。您将通过构建一个完整的计算流程，从最大似然法估计模型参数，到计算特定进化事件（如趋同演化）的后验概率，从而体验如何在一个严谨的统计框架下检验复杂的进化模式 [@problem_id:2604329]。", "problem": "一个在固定系统发育树上演化的离散形态性状，可以使用马尔可夫 $k$-状态 (Mk) 模型，建模为一个连续时间马尔可夫链 (CTMC)。给定一个有根、分叉、分支长度固定的参考树 $T$，以及一个包含 $n$ 个分类单元和 $m$ 个离散特征的形态学矩阵。其中一个特征被指定为焦点特征，并带有一个焦点状态。将焦点特征的趋同性定义为：所有表现出焦点状态的分类单元的最近共同祖先 (MRCA) 本身不具备该焦点状态这一事件。在 Mk 模型下，并假设根节点处为均匀平稳分布，您必须计算在给定焦点特征的观测叶尖状态的条件下，此趋同事件的后验概率。其中，Mk 模型的转移速率参数需要通过对树 $T$ 上的焦点特征数据进行最大似然估计来获得。\n\n您的推导必须仅基于以下原则：\n- 树上的 CTMC 的转移概率由瞬时速率矩阵的矩阵指数给出，且 Mk 模型的非对角线转移速率均相等。\n- 在 CTMC 下，树上叶尖状态的似然值可以通过动态规划计算，该规划从叶尖到根节点聚合条件概率。\n- 内部节点的祖先状态的后验分布，是通过结合子树的似然值、树其余部分的贡献以及根节点的先验分布得到的。\n\n您的程序必须：\n- 通过最大化树 $T$ 上观测到的叶尖状态的似然值，来估计焦点特征的 Mk 速率参数 $q$。\n- 在观测到的叶尖状态、估计的 $q$ 和 Mk 模型为条件下，计算所有处于焦点状态的分类单元的 MRCA 不处于焦点状态的后验概率。\n- 如果表现出焦点状态的分类单元少于两个，按照惯例将所求概率定义为 $0$。\n- 将每个最终概率表示为 $[0,1]$ 区间内的小数。\n\n您的实现必须对任意数量的状态 $k \\ge 2$ 具有通用性。Mk 模型下的转移矩阵必须根据 CTMC 理论从第一性原理计算得出，不得使用模型定义之外的任何捷径。\n\n测试套件。对所有案例使用以下固定的树 $T$。该树由从父节点到子节点的有向边指定，分支长度以任意时间单位表示：\n- 节点：内部节点为 N0 (根)、N1、N2、N3、N4；叶尖为 A、B、C、D、E、F。\n- 带长度的边：$(\\text{N0},\\text{N1}, 0.5)$, $(\\text{N0},\\text{N2}, 0.6)$, $(\\text{N1},\\text{A}, 0.4)$, $(\\text{N1},\\text{B}, 0.4)$, $(\\text{N2},\\text{C}, 0.3)$, $(\\text{N2},\\text{N3}, 0.5)$, $(\\text{N3},\\text{D}, 0.4)$, $(\\text{N3},\\text{N4}, 0.5)$, $(\\text{N4},\\text{E}, 0.2)$, $(\\text{N4},\\text{F}, 0.2)$。所有分支长度均为非负实数；此处它们是 $0.5$, $0.6$, $0.4$, $0.4$, $0.3$, $0.5$, $0.4$, $0.5$, $0.2$, $0.2$。\n\n对所有特征矩阵使用分类单元顺序 $\\{\\text{A},\\text{B},\\text{C},\\text{D},\\text{E},\\text{F}\\}$。对于每个测试用例，形态学矩阵是一个包含 $n=6$ 行和 $m$ 列的数组，每个条目是一个整数状态码。只有焦点特征列用于拟合 $q$ 和计算所要求的概率。\n\n- 案例 $1$ (理想路径，具有非姐妹群相似性的二元焦点特征):\n  - 形态学矩阵 ($m=2$):\n    - A: $[1, 0]$\n    - B: $[0, 1]$\n    - C: $[0, 0]$\n    - D: $[0, 1]$\n    - E: $[0, 0]$\n    - F: $[1, 1]$\n  - 焦点特征索引: $0$ (从零开始索引)\n  - 焦点状态: $1$\n- 案例 $2$ (特征形成一个明显的进化支，趋同性不大可能):\n  - 形态学矩阵 ($m=2$):\n    - A: $[0, 1]$\n    - B: $[0, 0]$\n    - C: $[0, 0]$\n    - D: $[1, 2]$\n    - E: $[1, 0]$\n    - F: $[1, 1]$\n  - 焦点特征索引: $0$\n  - 焦点状态: $1$\n- 案例 $3$ (边界情况，只有一个分类单元处于焦点状态):\n  - 形态学矩阵 ($m=2$):\n    - A: $[0, 0]$\n    - B: $[1, 2]$\n    - C: $[0, 1]$\n    - D: $[0, 1]$\n    - E: $[0, 0]$\n    - F: $[0, 2]$\n  - 焦点特征索引: $0$\n  - 焦点状态: $1$\n- 案例 $4$ (推广到 $k=3$ 个状态):\n  - 形态学矩阵 ($m=2$):\n    - A: $[0, 2]$\n    - B: $[1, 0]$\n    - C: $[1, 1]$\n    - D: $[0, 2]$\n    - E: $[1, 1]$\n    - F: $[0, 0]$\n  - 焦点特征索引: $1$\n  - 焦点状态: $2$\n\n角度单位不适用。没有物理单位。所有输出都是概率，必须以小数形式报告，而不是百分比。\n\n最终输出格式。您的程序应生成单行输出，其中包含上述案例的四个概率，以逗号分隔的列表形式，并用方括号括起来，顺序为案例 $1$、案例 $2$、案例 $3$、案例 $4$，每个值四舍五入到小数点后恰好六位。例如：$[\\dots]$。", "solution": "任务是在给定已知系统发育树叶尖的性状状态数据集的条件下，计算一个特定进化事件——性状趋同——的后验概率。这是以性状演化的马尔可夫 $k$-状态 (Mk) 模型为条件的，其中唯一的模型参数，一个速率 $q$，是使用最大似然原理从数据中估计出来的。\n\n逻辑步骤如下：\n1.  对 Mk 模型进行数学定义。\n2.  将观测到的叶尖状态的似然值表述为速率参数 $q$ 的函数。这通过使用 Felsenstein 的剪枝算法来实现。\n3.  通过数值最大化似然函数，找到速率参数的最大似然估计值 $q_{ML}$。\n4.  确定表现出焦点状态的分类单元的最近共同祖先 (MRCA)。\n5.  使用树上的双向（向上和向下）算法，在观测数据和 $q_{ML}$ 的条件下，计算 MRCA 节点处状态的后验概率分布。\n6.  根据定义，趋同概率即为 MRCA 不处于焦点状态的后验概率。\n\n**1. Mk 性状演化模型**\n\nMk 模型是针对具有 $k$ 个离散状态的性状的连续时间马尔可夫链 (CTMC)。演化过程由一个 $k \\times k$ 的瞬时速率矩阵 $Q$ 描述。对于 Mk 模型，所有不同状态之间的可能转移都以相同的速率发生，我们将其表示为参数 $q$。对角线元素被定义为使得矩阵的行和为零。\n\n$$\nQ_{ij} =\n\\begin{cases}\n    q & \\text{if } i \\neq j \\\\\n    -(k-1)q & \\text{if } i = j\n\\end{cases}\n$$\n\n对于长度为 $t$ 的分支，其转移概率矩阵 $P(t)$ 由矩阵指数 $P(t) = e^{Qt}$ 给出。对于 $Q$ 的这种特定结构，我们可以推导出一个封闭形式的解：\n\n$$\nP_{ij}(t) =\n\\begin{cases}\n    \\frac{1}{k} + \\frac{k-1}{k} e^{-kqt} & \\text{if } i = j \\\\\n    \\frac{1}{k} - \\frac{1}{k} e^{-kqt} & \\text{if } i \\neq j\n\\end{cases}\n$$\n\n该公式由 $Q$ 的谱分解推导得出，并给出了在时间间隔 $t$ 内从状态 $i$ 转移到状态 $j$ 的概率。\n\n**2. 似然值计算：剪枝算法（向上遍历）**\n\n为了估计 $q$，我们需要似然函数 $L(q) = P(D | T, q)$，其中 $D$ 代表树 $T$ 叶尖的观测状态。这可以通过 Felsenstein 的剪枝算法高效计算，该算法是对树进行后序遍历（从叶尖到根）。\n\n对于树中的每个节点 $u$，我们计算一个条件似然向量 $L_u$，其中 $L_u(s)$ 是在给定节点 $u$ 处于状态 $s$ 的条件下，观测到以 $u$ 为根的子树中状态的概率。\n\n-   **对于叶尖节点 $u$**：如果观测状态为 $s_{obs}$，则似然向量是一个独热向量：$L_u(s) = \\delta_{s, s_{obs}}$，其中 $\\delta$ 是克罗内克 delta。\n-   **对于内部节点 $u$**：其子节点为 $v$ 和 $w$，分别由长度为 $t_v$ 和 $t_w$ 的分支连接，似然向量通过递归计算得出：\n    $$ L_u(s) = \\left( \\sum_{s' \\in \\text{states}} P_{ss'}(t_v) L_v(s') \\right) \\cdot \\left( \\sum_{s'' \\in \\text{states}} P_{ss''}(t_w) L_w(s'') \\right) $$\n    用向量表示法，这可以写成 $L_u = (P(t_v)L_v) \\odot (P(t_w)L_w)$，其中 $\\odot$ 表示逐元素（哈达玛）积。\n\n-   **总似然值**：在计算出根节点 $r$ 的 $L_r$ 后，通过对所有可能的根状态进行平均来获得总似然值，并按其先验概率加权。假设根节点处为均匀平稳分布，则任何状态 $s$ 的先验概率为 $\\pi_s = 1/k$。\n    $$ L(q) = \\sum_{s=0}^{k-1} \\pi_s L_r(s) = \\frac{1}{k} \\sum_{s=0}^{k-1} L_r(s) $$\n\n**3. $q$ 的最大似然估计**\n\n最大似然估计值 $q_{ML}$ 是使 $L(q)$ 最大化的 $q$ 值。在计算上，最大化对数似然 $\\ln L(q)$ 或等效地最小化负对数似然 $-\\ln L(q)$ 更为稳定。这是一个一维优化问题，可以使用标准数值方法求解。\n\n$$ q_{ML} = \\arg\\min_q (-\\ln L(q)) $$\n\n**4. 祖先状态重建（向下遍历）**\n\n为了计算内部节点状态的后验概率，我们必须将其下方子树的信息（“向上”似然值 $L_u$）与树其余部分的信息（“向下”似然值）结合起来。令 $A_u(s) = P(\\text{data outside } u\\text{'s subtree} | S_u=s)$ 为给定节点 $u$ 处于状态 $s$ 时，节点 $u$“上方”数据的概率。这些值通过对树进行前序遍历（从根到叶尖）来计算。\n\n-   **对于根节点 $r$**：“向下”似然值就是先验概率分布：$A_r(s) = \\pi_s = 1/k$。\n-   **对于子节点 $v$**：令 $u$ 为其父节点， $w$ 为其兄弟节点。设分支长度分别为 $t_v$ （从 $u$ 到 $v$） 和 $t_w$ （从 $u$ 到 $w$）。向下的似然向量 $A_v$ 是根据父节点的向下似然 $A_u$ 和兄弟节点的向上似然 $L_w$ 计算得出的：\n    $$ A_v = P(t_v)^T (A_u \\odot (P(t_w)L_w)) $$\n\n数据与节点 $u$ 处于状态 $s$ 的联合概率为 $P(D, S_u=s) = A_u(s) L_u(s)$。对于任何节点 $u$ ，总似然值 $P(D)$ 为 $\\sum_s A_u(s) L_u(s)$。\n\n**5. 后验概率与趋同事件**\n\n在给定数据 $D$ 和速率 $q_{ML}$ 的情况下，内部节点 $u$ 处于状态 $s$ 的后验概率由贝叶斯定理给出：\n$$ P(S_u=s | D, q_{ML}) = \\frac{P(D, S_u=s)}{P(D)} = \\frac{A_u(s)L_u(s)}{\\sum_{s'} A_u(s')L_u(s')} $$\n分母是总似然值 $L(q_{ML})$。\n\n问题将趋同定义为所有具有焦点状态 $s_{focal}$ 的分类单元的 MRCA 本身不具备状态 $s_{focal}$ 的事件。设 $m$ 为该 MRCA 节点。所需的概率是：\n$$ P(\\text{convergence}) = P(S_m \\neq s_{focal} | D, q_{ML}) = 1 - P(S_m = s_{focal} | D, q_{ML}) $$\n\n**特殊情况**：如果表现出焦点状态的分类单元数量少于两个，则在此上下文中 MRCA 没有明确的意义。根据问题要求，该概率设置为 $0$。\n\n以下实现将此完整过程应用于测试用例。它首先构建树，然后对于每个用例，识别焦点分类单元及其 MRCA。它执行数值优化以找到 $q_{ML}$，然后执行双向算法来计算 MRCA 处的后验状态分布，最后计算趋同概率。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nfrom collections import deque\n\nclass Node:\n    \"\"\"Represents a node in the phylogenetic tree.\"\"\"\n    def __init__(self, name):\n        self.name = name\n        self.parent = None\n        self.children = []\n        self.branch_length = 0.0  # Length of branch leading to this node\n        self.is_tip = True\n        self.state = None\n        self.up_likelihoods = None\n        self.down_likelihoods = None\n\n    def add_child(self, child, branch_length):\n        self.children.append(child)\n        child.parent = self\n        child.branch_length = branch_length\n        self.is_tip = False\n\ndef build_tree(edges, taxa_order):\n    \"\"\"Builds the tree from edge list and returns nodes dictionary and root.\"\"\"\n    nodes = {name: Node(name) for name in taxa_order}\n    all_node_names = set(taxa_order)\n    for p, c, _ in edges:\n        all_node_names.add(p)\n        all_node_names.add(c)\n    \n    for name in all_node_names:\n        if name not in nodes:\n            nodes[name] = Node(name)\n\n    parent_map = {c: p for p, c, _ in edges}\n    root_name = (set(parent_map.values()) - set(parent_map.keys())).pop()\n\n    for p, c, bl in edges:\n        nodes[p].add_child(nodes[c], bl)\n        \n    # Set tip states based on data later\n    return nodes, nodes[root_name]\n\ndef get_post_order_traversal(root):\n    \"\"\"Returns a list of nodes in post-order.\"\"\"\n    traversal = []\n    stack = [root]\n    visited = set()\n    while stack:\n        node = stack.pop()\n        if node not in visited:\n            visited.add(node)\n            traversal.insert(0, node)\n            for child in node.children:\n                stack.append(child)\n    return traversal\n\ndef get_pre_order_traversal(root):\n    \"\"\"Returns a list of nodes in pre-order.\"\"\"\n    traversal = []\n    stack = [root]\n    while stack:\n        node = stack.pop()\n        traversal.append(node)\n        # Add children in reverse to process them in order for next iteration\n        for child in reversed(node.children):\n            stack.append(child)\n    return traversal\n\ndef get_transition_matrix(t, q, k):\n    \"\"\"Computes the Mk transition probability matrix P(t).\"\"\"\n    if k == 1:\n        return np.array([[1.0]])\n    val = k * q * t\n    p_diag = (1.0 / k) + ((k - 1.0) / k) * np.exp(-val)\n    p_offdiag = (1.0 / k) - (1.0 / k) * np.exp(-val)\n    P = np.full((k, k), p_offdiag)\n    np.fill_diagonal(P, p_diag)\n    return P\n\ndef compute_up_likelihoods(nodes_post_order, tip_states, q, k):\n    \"\"\"Computes up-likelihoods for all nodes (Pass 1).\"\"\"\n    for node in nodes_post_order:\n        if node.is_tip:\n            state = tip_states[node.name]\n            node.up_likelihoods = np.zeros(k)\n            if state  k:\n                node.up_likelihoods[state] = 1.0\n        else:\n            c1, c2 = node.children\n            P1 = get_transition_matrix(c1.branch_length, q, k)\n            P2 = get_transition_matrix(c2.branch_length, q, k)\n            L1 = P1 @ c1.up_likelihoods\n            L2 = P2 @ c2.up_likelihoods\n            node.up_likelihoods = L1 * L2\n\ndef compute_down_likelihoods(nodes_pre_order, root_prior, q, k):\n    \"\"\"Computes down-likelihoods for all nodes (Pass 2).\"\"\"\n    root = nodes_pre_order[0]\n    root.down_likelihoods = root_prior\n    \n    for p_node in nodes_pre_order:\n        if p_node.is_tip:\n            continue\n        \n        c1, c2 = p_node.children\n        \n        # Down-likelihood for c1\n        Pt_c1 = get_transition_matrix(c1.branch_length, q, k).T\n        Pt_c2 = get_transition_matrix(c2.branch_length, q, k)\n        L_c2 = c2.up_likelihoods\n        V_c2 = Pt_c2 @ L_c2\n        A_p = p_node.down_likelihoods\n        c1.down_likelihoods = Pt_c1 @ (A_p * V_c2)\n\n        # Down-likelihood for c2\n        Pt_c2 = get_transition_matrix(c2.branch_length, q, k).T\n        Pt_c1 = get_transition_matrix(c1.branch_length, q, k)\n        L_c1 = c1.up_likelihoods\n        V_c1 = Pt_c1 @ L_c1\n        c2.down_likelihoods = Pt_c2 @ (A_p * V_c1)\n\n\ndef find_mrca(nodes, taxa_subset):\n    \"\"\"Finds the MRCA of a subset of taxa.\"\"\"\n    if not taxa_subset:\n        return None\n    \n    paths_to_root = []\n    for taxon_name in taxa_subset:\n        path = []\n        curr = nodes[taxon_name]\n        while curr:\n            path.append(curr)\n            curr = curr.parent\n        paths_to_root.append(path)\n\n    first_path_nodes = set(paths_to_root[0])\n    common_ancestors = first_path_nodes.intersection(*[set(p) for p in paths_to_root[1:]])\n    \n    mrca = None\n    max_depth = -1\n    root = paths_to_root[0][-1]\n    \n    depths = {root: 0}\n    q = deque([root])\n    while q:\n        node = q.popleft()\n        for child in node.children:\n            depths[child] = depths[node] + 1\n            q.append(child)\n\n    for ancestor in common_ancestors:\n        if depths[ancestor] > max_depth:\n            max_depth = depths[ancestor]\n            mrca = ancestor\n            \n    return mrca\n\ndef solve():\n    edges = [\n        ('N0', 'N1', 0.5), ('N0', 'N2', 0.6), ('N1', 'A', 0.4), ('N1', 'B', 0.4),\n        ('N2', 'C', 0.3), ('N2', 'N3', 0.5), ('N3', 'D', 0.4), ('N3', 'N4', 0.5),\n        ('N4', 'E', 0.2), ('N4', 'F', 0.2)\n    ]\n    taxa_order = ['A', 'B', 'C', 'D', 'E', 'F']\n\n    test_cases = [\n        {\n            \"matrix\": [[1, 0], [0, 1], [0, 0], [0, 1], [0, 0], [1, 1]],\n            \"focal_trait_idx\": 0, \"focal_state\": 1\n        },\n        {\n            \"matrix\": [[0, 1], [0, 0], [0, 0], [1, 2], [1, 0], [1, 1]],\n            \"focal_trait_idx\": 0, \"focal_state\": 1\n        },\n        {\n            \"matrix\": [[0, 0], [1, 2], [0, 1], [0, 1], [0, 0], [0, 2]],\n            \"focal_trait_idx\": 0, \"focal_state\": 1\n        },\n        {\n            \"matrix\": [[0, 2], [1, 0], [1, 1], [0, 2], [1, 1], [0, 0]],\n            \"focal_trait_idx\": 1, \"focal_state\": 2\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        focal_trait_data = [row[case[\"focal_trait_idx\"]] for row in case[\"matrix\"]]\n        tip_states = dict(zip(taxa_order, focal_trait_data))\n        focal_state = case[\"focal_state\"]\n        \n        k = max(focal_trait_data) + 1\n        taxa_in_focal_state = [taxon for taxon, state in tip_states.items() if state == focal_state]\n\n        if len(taxa_in_focal_state)  2:\n            results.append(0.0)\n            continue\n            \n        nodes, root = build_tree(edges, taxa_order)\n        post_order_nodes = get_post_order_traversal(root)\n        pre_order_nodes = get_pre_order_traversal(root)\n\n\n        def neg_log_likelihood(q, nodes_post_order, tip_states, k, root):\n            if q = 0:\n                return np.inf\n            compute_up_likelihoods(nodes_post_order, tip_states, q, k)\n            total_likelihood = np.sum(root.up_likelihoods) / k\n            if total_likelihood = 0:\n                return np.inf\n            return -np.log(total_likelihood)\n\n        opt_result = minimize_scalar(\n            neg_log_likelihood,\n            args=(post_order_nodes, tip_states, k, root),\n            bounds=(1e-9, 100),\n            method='bounded'\n        )\n        q_ml = opt_result.x\n\n        compute_up_likelihoods(post_order_nodes, tip_states, q_ml, k)\n        total_likelihood = np.sum(root.up_likelihoods) / k\n\n        root_prior = np.full(k, 1.0 / k)\n        compute_down_likelihoods(pre_order_nodes, root_prior, q_ml, k)\n        \n        mrca_node = find_mrca(nodes, taxa_in_focal_state)\n\n        posterior_mrca = (mrca_node.up_likelihoods * mrca_node.down_likelihoods) / total_likelihood\n        \n        prob_mrca_in_focal_state = posterior_mrca[focal_state]\n        prob_convergence = 1.0 - prob_mrca_in_focal_state\n        \n        results.append(prob_convergence)\n\n    print(f\"[{','.join([f'{p:.6f}' for p in results])}]\")\n\nsolve()\n```", "id": "2604329"}]}