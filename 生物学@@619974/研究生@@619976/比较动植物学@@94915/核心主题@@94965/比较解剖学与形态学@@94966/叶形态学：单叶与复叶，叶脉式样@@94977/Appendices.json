{"hands_on_practices": [{"introduction": "叶片维管系统的水分运输效率对光合作用和植物生存至关重要。这一效率受物理定律的支配，特别是哈根-泊肃叶方程（Hagen-Poiseuille equation），它将流量与导管（叶脉）的几何形状联系起来。本练习从第一性原理出发，探讨了末级脉半径的微小变化如何对整个叶片的水力导度（一个关键的生理性状）产生巨大的、非线性的影响，从而为理解叶片设计的生物物理约束奠定基础。[@problem_id:2586001]", "problem": "在比较叶片形态学中，由于叶片分裂程度的不同，同一物种的单叶和羽状复叶的细脉半径可能不同，而由于相似的碳分配，每片叶子的细脉总长度则可保持相当。假设动力黏度为 $\\mu$ 的木质部汁液呈层流状态，并将末端细脉网络近似为 $N$ 个相同的并联圆柱形导管，每个导管的半径为 $r$，长度为 $L_{\\mathrm{tot}}/N$，其中 $L_{\\mathrm{tot}}$ 是叶片投入的固定的细脉总长度， $N$ 是从叶柄到叶肉并联作用的细脉端到端路径的数量。主脉和叶柄不是速率限制因素，且不存在气穴现象。水力阻力串联相加，水力导度并联相加。\n\n从圆柱形导管的 Poiseuille 定律 $R = \\dfrac{8 \\mu L}{\\pi r^{4}}$ 出发，推导该网络模型的叶片级水力导度 $K_{\\mathrm{leaf}}(r; \\mu, L_{\\mathrm{tot}}, N)$。然后，考虑两片叶子，它们的 $\\mu$、 $L_{\\mathrm{tot}}$ 和 $N$ 相同（例如，一个单叶和一个复叶形态，具有相同的细脉总长度和相同的并联末端路径数），但细脉半径不同，分别为 $r_{1}$ 和 $r_{2}$。定义半径比 $\\alpha = r_{2}/r_{1}$。将导度比 $K_{\\mathrm{leaf}}(r_{2})/K_{\\mathrm{leaf}}(r_{1})$ 仅用 $\\alpha$ 表示为一个单一的闭式解析表达式。最终表达式中不要包含任何单位。", "solution": "在尝试任何解答之前，将对问题进行验证。\n\n### 步骤1：提取已知条件\n问题陈述中提供了以下信息：\n- **控制方程**：单个圆柱形导管的水力阻力 $R$ 的 Poiseuille 定律为 $R = \\dfrac{8 \\mu L}{\\pi r^{4}}$，其中 $\\mu$ 是动力黏度， $L$ 是长度， $r$ 是半径。\n- **网络模型**：叶片细脉网络被近似为 $N$ 个并联的相同圆柱形导管。\n- **导管几何形状**： $N$ 个导管中的每一个半径为 $r$，长度为 $L_{\\mathrm{tot}}/N$。\n- **固定参数**：细脉总长度 $L_{\\mathrm{tot}}$、并联路径数 $N$ 和动力黏度 $\\mu$ 在比较中是恒定的。\n- **回路法则**：水力阻力串联相加，水力导度并联相加。导度 $K$ 是阻力 $R$ 的倒数，即 $K=1/R$。\n- **比较案例**：比较两片叶子，它们仅在细脉半径上有所不同，分别指定为 $r_{1}$ 和 $r_{2}$。\n- **定义**：半径比定义为 $\\alpha = r_{2}/r_{1}$。\n- **目标1**：推导叶片级水力导度 $K_{\\mathrm{leaf}}(r; \\mu, L_{\\mathrm{tot}}, N)$。\n- **目标2**：将导度比 $K_{\\mathrm{leaf}}(r_{2})/K_{\\mathrm{leaf}}(r_{1})$ 表示为 $\\alpha$ 的函数。\n\n### 步骤2：使用提取的已知条件进行验证\n对问题进行验证。\n- **科学依据**：该问题基于哈根-泊肃叶方程（流体动力学的基本定律），并将其应用于模拟木质部中的汁液流动。这是植物生物物理学中一种标准且成熟的方法。所有假设，如层流和理想化的圆柱几何形状，都是一阶生物物理模型的标准假设。该问题是科学合理的。\n- **适定性**：该问题是适定的。它提供了推导出唯一解所需的所有必要方程、参数和约束。目标陈述清晰，并且可以从已知条件通过数学方法实现。\n- **客观性**：该问题以精确、客观和定量的术语陈述。没有歧义或主观内容。\n\n### 步骤3：结论与行动\n该问题是 **有效的**。这是一个将已建立的物理原理应用于生物系统的直接练习。现在开始推导解。\n\n按要求，推导过程分两部分进行。\n\n首先，我们推导叶片级水力导度 $K_{\\mathrm{leaf}}$ 的表达式。叶片被建模为一组 $N$ 个并联的相同导管。我们必须首先找到单个导管的水力阻力，我们将其表示为 $R_{\\mathrm{conduit}}$。\n根据所提供的数据，一个此类导管的长度为 $L = L_{\\mathrm{tot}}/N$，其半径为 $r$。将这些代入 Poiseuille 定律：\n$$R_{\\mathrm{conduit}} = \\frac{8 \\mu L}{\\pi r^{4}} = \\frac{8 \\mu (L_{\\mathrm{tot}}/N)}{\\pi r^{4}} = \\frac{8 \\mu L_{\\mathrm{tot}}}{\\pi N r^{4}}$$\n叶片的总阻力 $R_{\\mathrm{leaf}}$ 是这 $N$ 个并联的相同导管的等效阻力。对于并联的电阻，总电阻的倒数是各个电阻倒数之和：\n$$\\frac{1}{R_{\\mathrm{leaf}}} = \\sum_{i=1}^{N} \\frac{1}{R_{\\mathrm{conduit}}} = \\frac{N}{R_{\\mathrm{conduit}}}$$\n因此，叶片总阻力为：\n$$R_{\\mathrm{leaf}} = \\frac{R_{\\mathrm{conduit}}}{N} = \\frac{1}{N} \\left( \\frac{8 \\mu L_{\\mathrm{tot}}}{\\pi N r^{4}} \\right) = \\frac{8 \\mu L_{\\mathrm{tot}}}{\\pi N^{2} r^{4}}$$\n水力导度 $K$ 定义为阻力的倒数， $K = 1/R$。因此，叶片级导度 $K_{\\mathrm{leaf}}$ 为：\n$$K_{\\mathrm{leaf}}(r; \\mu, L_{\\mathrm{tot}}, N) = \\frac{1}{R_{\\mathrm{leaf}}} = \\frac{\\pi N^{2} r^{4}}{8 \\mu L_{\\mathrm{tot}}}$$\n这完成了第一个目标。或者，也可以使用导度并联相加的法则。单个导管的导度是 $K_{\\text{conduit}} = 1/R_{\\text{conduit}} = \\frac{\\pi N r^4}{8 \\mu L_{\\text{tot}}}$。对于 $N$ 个并联的此类导管，总导度为 $K_{\\mathrm{leaf}} = N \\cdot K_{\\text{conduit}} = N \\left(\\frac{\\pi N r^4}{8 \\mu L_{\\text{tot}}}\\right) = \\frac{\\pi N^2 r^4}{8 \\mu L_{\\text{tot}}}$，这验证了结果。\n\n其次，我们确定两片仅在细脉半径（$r_{1}$ 和 $r_{2}$）上不同的叶子的导度比。参数 $\\mu$、 $L_{\\mathrm{tot}}$ 和 $N$ 对两片叶子都是相同的。\n对于半径为 $r_{1}$ 的第一片叶子，其导度为：\n$$K_{\\mathrm{leaf}}(r_{1}) = \\frac{\\pi N^{2} r_{1}^{4}}{8 \\mu L_{\\mathrm{tot}}}$$\n对于半径为 $r_{2}$ 的第二片叶子，其导度为：\n$$K_{\\mathrm{leaf}}(r_{2}) = \\frac{\\pi N^{2} r_{2}^{4}}{8 \\mu L_{\\mathrm{tot}}}$$\n我们需要求出比率 $K_{\\mathrm{leaf}}(r_{2})/K_{\\mathrm{leaf}}(r_{1})$。\n$$\\frac{K_{\\mathrm{leaf}}(r_{2})}{K_{\\mathrm{leaf}}(r_{1})} = \\frac{\\left( \\frac{\\pi N^{2} r_{2}^{4}}{8 \\mu L_{\\mathrm{tot}}} \\right)}{\\left( \\frac{\\pi N^{2} r_{1}^{4}}{8 \\mu L_{\\mathrm{tot}}} \\right)}$$\n所有公共因子都消去了，只剩下包含半径的项：\n$$\\frac{K_{\\mathrm{leaf}}(r_{2})}{K_{\\mathrm{leaf}}(r_{1})} = \\frac{r_{2}^{4}}{r_{1}^{4}} = \\left( \\frac{r_{2}}{r_{1}} \\right)^{4}$$\n问题将半径比定义为 $\\alpha = r_{2}/r_{1}$。将此定义代入表达式中，得到导度比的最终结果：\n$$\\frac{K_{\\mathrm{leaf}}(r_{2})}{K_{\\mathrm{leaf}}(r_{1})} = \\alpha^{4}$$\n这就是所要求的、仅用 $\\alpha$ 表示的导度比的闭式解析表达式。", "answer": "$$\\boxed{\\alpha^{4}}$$", "id": "2586001"}, {"introduction": "在理解了单个叶脉的水流物理学基础上，我们可以构建模型来研究叶片的整体结构——例如单叶与复叶——如何影响其生理性能。本练习将水力学中的“欧姆定律”类比与结构尺度律相结合，将叶片形态（如叶脉密度、小叶数量）与一个关键的功能性状——最大气孔导度——联系起来。这项实践挑战您像理论生态学家一样思考，推导出一个预测模型，解释不同的叶片建造成本策略如何导致不同的水分利用潜力，并展示了尺度律在连接不同组织层次的形态与功能方面的强大作用。[@problem_id:2585943]", "problem": "一位比较植物生理学家正在建立一个机理模型，来预测叶片结构（单叶与复叶）和脉序模式如何影响最大气孔导度。考虑一片在稳态下与大气交换水蒸气的叶片。设单位叶面积的蒸腾通量为 $E$，单位叶面积的气孔导度为 $g_s$。驱动水汽梯度由饱和水汽压差（VPD）表征，记为 $D$。假设在稳态条件下，质量守恒和扩散导致 $E \\propto g_s D$ 的正比关系，并且通过叶片的水流遵循水力学中的欧姆定律类似物，因此叶片两端的水势降 $\\Delta \\Psi$ 与通过叶片的通量成正比，与其水力导度成反比。面积为 $A_i$、脉长密度为 $V$ 的叶片模块的绝对叶片水力导度 $K_i$ 遵循标度律 $K_i = k\\,V^{\\beta}\\,A_i^{\\gamma}$，其中 $k$、$\\beta$ 和 $\\gamma$ 是反映材料和网络特性的正常数。水力并联模块的导度线性相加。\n\n两片叶子具有相同的总叶片面积 $A$，并经历相同的土壤-叶片安全阈值 $\\Delta \\Psi_{\\max} = \\Psi_s - \\Psi_{\\min}$，其中 $\\Psi_s$ 是土壤水势，$\\Psi_{\\min}$ 是在气穴化风险变得不可接受地高之前，叶片可耐受的最低水势。两片叶子的叶片外阻力可以忽略不计或完全相同。\n\n- 叶片 S（单叶）：一个单一的叶片模块，脉长密度为 $V_s$，面积为 $A$。\n- 叶片 C（复叶）：由 $N$ 个相同的小叶并联组成，每个小叶的面积为 $A/N$，脉长密度为 $V_c$。\n\n仅使用所描述的基本正比关系（即，稳态正比关系 $E \\propto g_s D$、叶片上的水力通量-水势降关系以及导度的并联相加），并利用标度律 $K_i = k\\,V^{\\beta}\\,A_i^{\\gamma}$，推导每种叶片类型的单位总叶面积的最大气孔导度，需满足叶片水势降不超过 $\\Delta \\Psi_{\\max}$ 的约束条件。然后，定义复叶与单叶单位面积最大气孔导度之比 $R$，并将 $R$ 表示为仅包含 $N$、$V_c$、$V_s$、$\\beta$ 和 $\\gamma$ 的闭合形式符号表达式。请勿代入任何数值。最终答案必须以单一解析表达式的形式给出。最终答案中不需要单位。", "solution": "该问题陈述具有科学依据，提法恰当，客观且自成体系。因此，该问题是有效的。解题过程首先将给定的物理正比关系形式化，以推导最大气孔导度的表达式，然后将该表达式应用于单叶和复叶结构。\n\n让我们首先将给定的关系形式化。单位叶面积的蒸腾通量 $E$ 与单位面积的气孔导度 $g_s$ 和饱和水汽压差 $D$ 成正比。\n$$E = c_1 g_s D$$\n其中 $c_1$ 是一个比例常数。总面积为 $A$ 的叶片的总蒸腾速率，即总水通量，为 $E_{total} = E \\times A$。\n$$E_{total} = c_1 g_s D A$$\n叶片两端的水势降 $\\Delta\\Psi$ 遵循水力学中的欧姆定律类似物。它与总通量 $E_{total}$ 成正比，与叶片总水力导度 $K_{leaf}$ 成反比。\n$$\\Delta\\Psi = c_2 \\frac{E_{total}}{K_{leaf}}$$\n其中 $c_2$ 是另一个比例常数。\n\n该系统受最大允许水势降 $\\Delta\\Psi_{\\max}$ 的约束。此极限对应于最大气孔导度 $g_{s, \\max}$，因此也对应于最大总蒸腾速率 $E_{total, \\max}$。将 $E_{total}$ 的表达式代入并令 $\\Delta\\Psi = \\Delta\\Psi_{\\max}$，可得：\n$$\\Delta\\Psi_{\\max} = c_2 \\frac{c_1 g_{s, \\max} D A}{K_{leaf}}$$\n我们可以重新整理该方程，解出单位面积的最大气孔导度 $g_{s, \\max}$：\n$$g_{s, \\max} = \\frac{\\Delta\\Psi_{\\max}}{c_1 c_2 D} \\frac{K_{leaf}}{A}$$\n对于两种叶片类型，项 $\\frac{\\Delta\\Psi_{\\max}}{c_1 c_2 D}$ 是一个常数，因为它们具有相同的 $\\Delta\\Psi_{\\max}$ 并且经历相同的 $D$。让我们将这个组合常数记为 $C_{env}$。\n$$g_{s, \\max} = C_{env} \\frac{K_{leaf}}{A}$$\n这表明，最大气孔导度与总叶片水力导度与总叶面积之比成正比。我们现在必须确定单叶（S）和复叶（C）的 $K_{leaf}$。\n\n对于单叶，即叶片 S，其叶片由一个面积为 $A$、脉长密度为 $V_s$ 的单一模块组成。单个模块的水力导度 $K_i$，其面积为 $A_i$，脉长密度为 $V$，由标度律 $K_i = k V^{\\beta} A_i^{\\gamma}$ 给出。对于叶片 S，$A_i = A$ 且 $V = V_s$。因此，其总水力导度为：\n$$K_{leaf}^{(S)} = k (V_s)^{\\beta} A^{\\gamma}$$\n单叶的单位面积最大气孔导度为：\n$$g_{s, \\max}^{(S)} = C_{env} \\frac{K_{leaf}^{(S)}}{A} = C_{env} \\frac{k (V_s)^{\\beta} A^{\\gamma}}{A} = C_{env} k (V_s)^{\\beta} A^{\\gamma-1}$$\n\n对于复叶，即叶片 C，其叶片由 $N$ 个相同的小叶水力并联组成。总叶面积为 $A$，所以每个小叶的面积为 $A_i = A/N$。每个小叶的脉长密度为 $V_c$。首先，我们使用给定的标度律计算单个小叶的水力导度 $K_{leaflet}$：\n$$K_{leaflet} = k (V_c)^{\\beta} \\left(\\frac{A}{N}\\right)^{\\gamma} = k (V_c)^{\\beta} A^{\\gamma} N^{-\\gamma}$$\n由于 $N$ 个小叶是并联的，它们的导度线性相加，得到复叶的总水力导度：\n$$K_{leaf}^{(C)} = \\sum_{i=1}^{N} K_{leaflet} = N \\cdot K_{leaflet} = N \\left( k (V_c)^{\\beta} A^{\\gamma} N^{-\\gamma} \\right)$$\n$$K_{leaf}^{(C)} = k (V_c)^{\\beta} A^{\\gamma} N^{1-\\gamma}$$\n那么，复叶的单位总面积最大气孔导度为：\n$$g_{s, \\max}^{(C)} = C_{env} \\frac{K_{leaf}^{(C)}}{A} = C_{env} \\frac{k (V_c)^{\\beta} A^{\\gamma} N^{1-\\gamma}}{A} = C_{env} k (V_c)^{\\beta} A^{\\gamma-1} N^{1-\\gamma}$$\n\n问题要求计算复叶与单叶的最大气孔导度之比 $R$。\n$$R = \\frac{g_{s, \\max}^{(C)}}{g_{s, \\max}^{(S)}}$$\n代入推导出的 $g_{s, \\max}^{(C)}$ 和 $g_{s, \\max}^{(S)}$ 表达式：\n$$R = \\frac{C_{env} k (V_c)^{\\beta} A^{\\gamma-1} N^{1-\\gamma}}{C_{env} k (V_s)^{\\beta} A^{\\gamma-1}}$$\n公共项 $C_{env}$、$k$ 和 $A^{\\gamma-1}$ 被约去，得到比率 $R$ 的最终表达式：\n$$R = \\frac{(V_c)^{\\beta} N^{1-\\gamma}}{(V_s)^{\\beta}}$$\n这可以更紧凑地写为：\n$$R = N^{1-\\gamma} \\left(\\frac{V_c}{V_s}\\right)^{\\beta}$$\n该表达式仅依赖于 $N$、$V_c$、$V_s$、$\\beta$ 和 $\\gamma$，与问题陈述的要求一致。", "answer": "$$\\boxed{N^{1-\\gamma} \\left(\\frac{V_c}{V_s}\\right)^{\\beta}}$$", "id": "2585943"}, {"introduction": "现代植物学研究越来越依赖计算工具来分析大量的形态学数据集。叶脉模式的分类，这一经典的植物学任务，可以通过机器学习实现自动化。本练习应用朴素贝叶斯分类器（一种监督学习中的基础算法），根据可量化的特征（如网眼大小和脉环存在与否）来划分叶脉类型。通过从零开始实施这个分类器，您将获得计算形态计量学完整流程的实践经验：从模型选择、利用真实数据进行参数估计，到最终的预测和分类。这个练习弥合了经典形态学与数据科学之间的鸿沟，为您提供了当代生物学研究所需的关键技能。[@problem_id:2586028]", "problem": "您的任务是形式化并实现一个监督分类器，该分类器使用两个形态计量特征来指定脉序类型：网眼大小和次级脉环存在与否。在比较植物学中，网眼是指网状脉序中由细脉完全包围的最小区域，而环状的次级脉是曲行脉模式的特征。为确保科学真实性，按如下方式对脉序类别和这些特征进行建模。\n\n使用以下定义和假设作为基本基础：\n- 形态学定义：\n  - 网眼大小以平方毫米（$\\text{mm}^2$）为单位进行测量。\n  - 次级脉环的存在与否被记为一个二元指标：存在（1）或不存在（0）。\n  - 脉序类别 $Y$ 在 $\\{0,1,2\\}$ 中取值，映射关系为：$0$ 代表平行脉， $1$ 代表具有曲行脉（环状）次级脉的网状脉， $2$ 代表具有直行脉（非环状，到达叶缘）次级脉的网状脉。\n- 基于贝叶斯定理和朴素贝叶斯独立性假设的概率建模假设：\n  - 贝叶斯定理：对于任何类别 $k$， $P(Y=k \\mid X=x) \\propto P(Y=k)\\,P(X=x \\mid Y=k)$。\n  - 给定类别下的条件独立性：对于特征 $X_1$ （网眼大小）和 $X_2$ （脉环存在与否），$P(X_1, X_2 \\mid Y=k) = P(X_1 \\mid Y=k)\\,P(X_2 \\mid Y=k)$。\n  - 类条件分布：$X_1 \\mid Y=k$ 是均值为 $\\mu_k$ 、方差为 $\\sigma_k^2$ 的高斯（正态）分布，而 $X_2 \\mid Y=k$ 是成功概率为 $p_k$ 的伯努利分布。\n\n训练数据以带标签的三元组 $(y, a, \\ell)$ 的形式提供，其中 $y$ 是类别标签， $a$ 是以 $\\mathrm{mm}^2$ 为单位的网眼大小， $\\ell$ 是脉环存在与否：\n- 类别 $0$ （平行脉）： $(0, 0.005, 0)$、$(0, 0.012, 0)$、$(0, 0.008, 0)$、$(0, 0.000, 0)$、$(0, 0.015, 0)$。\n- 类别 $1$ （曲行脉）： $(1, 1.2, 1)$、$(1, 0.9, 1)$、$(1, 1.6, 1)$、$(1, 0.7, 1)$。\n- 类别 $2$ （直行脉）： $(2, 0.3, 0)$、$(2, 0.4, 0)$、$(2, 0.25, 0)$、$(2, 0.5, 0)$。\n\n根据这些数据，您必须：\n- 使用计数通过最大似然估计来估计类别先验概率 $P(Y=k)$。\n- 通过最大似然估计来估计 $X_1 \\mid Y=k$ 的高斯参数 $\\mu_k$ 和 $\\sigma_k^2$。\n- 使用 $\\alpha=1$ 的加法（Laplace）平滑来估计 $X_2 \\mid Y=k$ 的伯努利参数 $p_k$。\n\n然后，对于每个测试用例，在上述模型下计算最大后验类别 $\\arg\\max_k P(Y=k \\mid X=x)$。如果两个或多个类别的后验概率完全相等，则选择最小的类别索引。您可以使用对数进行计算以保持数值稳定性。所有概率都是无单位的；网眼大小必须以 $\\mathrm{mm}^2$ 为单位处理。\n\n测试集（每个用例为 $(a, \\ell)$，其中 $a$ 的单位是 $\\mathrm{mm}^2$，$ \\ell \\in \\{0,1\\}$）：\n- 用例 1： $(0.010, 0)$\n- 用例 2： $(1.10, 1)$\n- 用例 3： $(0.35, 0)$\n- 用例 4： $(0.80, 0)$\n- 用例 5： $(0.00, 1)$\n- 用例 6： $(0.60, 1)$\n\n您的程序必须：\n- 按规定实现训练参数估计和分类。\n- 生成单行输出，其中包含测试集的预测类别标签，格式为方括号内由逗号分隔的整数列表，无空格，顺序与测试用例相同（例如，$[0,1,2]$）。", "solution": "在尝试给出解决方案之前，需对问题陈述进行验证。\n\n**步骤1：提取已知信息**\n\n- **形态学定义**：\n  - 网眼大小 ($X_1$)：以 $\\mathrm{mm}^2$ 为单位测量。\n  - 次级脉环存在与否 ($X_2$)：二元指标，$1$ 为存在，$0$ 为不存在。\n  - 脉序类别 ($Y$)：\n    - $Y=0$：平行脉。\n    - $Y=1$：网状脉，曲行脉。\n    - $Y=2$：网状脉，直行脉。\n\n- **概率模型**：\n  - 将使用朴素贝叶斯分类器。\n  - 贝叶斯定理：$P(Y=k \\mid X=x) \\propto P(Y=k) P(X=x \\mid Y=k)$。\n  - 条件独立性：$P(X_1, X_2 \\mid Y=k) = P(X_1 \\mid Y=k) P(X_2 \\mid Y=k)$。\n  - 类条件分布：\n    - $X_1 \\mid Y=k \\sim \\mathcal{N}(\\mu_k, \\sigma_k^2)$ (高斯)。\n    - $X_2 \\mid Y=k \\sim \\text{Bernoulli}(p_k)$。\n\n- **训练数据**：\n  - 类别 $0$： $(0, 0.005, 0), (0, 0.012, 0), (0, 0.008, 0), (0, 0.000, 0), (0, 0.015, 0)$。\n  - 类别 $1$： $(1, 1.2, 1), (1, 0.9, 1), (1, 1.6, 1), (1, 0.7, 1)$。\n  - 类别 $2$： $(2, 0.3, 0), (2, 0.4, 0), (2, 0.25, 0), (2, 0.5, 0)$。\n\n- **参数估计规则**：\n  - 类别先验概率 $P(Y=k)$：最大似然估计 (MLE)。\n  - 高斯参数 $(\\mu_k, \\sigma_k^2)$：MLE。\n  - 伯努利参数 $p_k$：使用 $\\alpha=1$ 的加法（Laplace）平滑。\n\n- **分类规则**：\n  - 方法：最大后验 (MAP) 估计，即 $\\arg\\max_k P(Y=k \\mid X=x)$。\n  - 数值方法：使用对数以保证稳定性。\n  - 平局处理：选择最小的类别索引 $k$。\n\n- **测试集**：\n  - 用例 1: $(a=0.010, \\ell=0)$\n  - 用例 2: $(a=1.10, \\ell=1)$\n  - 用例 3: $(a=0.35, \\ell=0)$\n  - 用例 4: $(a=0.80, \\ell=0)$\n  - 用例 5: $(a=0.00, \\ell=1)$\n  - 用例 6: $(a=0.60, \\ell=1)$\n\n**步骤2：使用提取的已知信息进行验证**\n\n根据指定标准对问题进行评估。\n- **科学依据**：该问题基于植物学（叶脉序模式）和统计机器学习（朴素贝叶斯分类）的标准概念。选择高斯分布和伯努利分布分别对连续特征和二元特征进行建模是一种常规且合理的简化。对于一个简化模型来说，数据值是合理的。\n- **良态问题**：问题定义完整。它提供了训练数据、精确的概率模型、参数估计方法（MLE、Laplace平滑）、分类规则（MAP）以及平局处理条件。可以确定一个唯一、稳定且有意义的解。\n- **客观性**：该问题使用了精确、无歧义的术语和定量定义。它不包含主观或基于观点的陈述。\n\n该问题没有表现出科学上的不健全、不完整、矛盾或其他列出的缺陷。\n\n**步骤3：结论与行动**\n\n问题是**有效的**。将构建一个解决方案。\n\n**求解推导**\n\n任务是实现一个朴素贝叶斯分类器。目标是对于给定的特征集 $X=(X_1, X_2)=(a, \\ell)$（其中 $a$ 是网眼大小，$\\ell$ 是脉环存在与否）预测最可能的类别 $Y=k$。这通过找到使后验概率最大化的类别 $k$ 来实现，这一原则被称为最大后验（MAP）估计。\n\n$$ \\hat{k} = \\arg\\max_{k \\in \\{0, 1, 2\\}} P(Y=k \\mid X_1=a, X_2=\\ell) $$\n\n根据贝叶斯定理，后验概率正比于先验概率和似然的乘积：\n$$ P(Y=k \\mid X) \\propto P(Y=k) P(X \\mid Y=k) $$\n\n朴素贝叶斯的类条件独立性假设允许似然项被分解为：\n$$ P(X \\mid Y=k) = P(X_1=a \\mid Y=k) P(X_2=\\ell \\mid Y=k) $$\n\n综合以上，决策规则是：\n$$ \\hat{k} = \\arg\\max_{k \\in \\{0, 1, 2\\}} P(Y=k) P(X_1=a \\mid Y=k) P(X_2=\\ell \\mid Y=k) $$\n\n为了防止数值下溢并简化计算，我们最大化该表达式的对数。由于对数是单调函数，这会产生相同的结果。每个类别 $k$ 的分数为：\n$$ \\text{score}(k) = \\log P(Y=k) + \\log P(X_1=a \\mid Y=k) + \\log P(X_2=\\ell \\mid Y=k) $$\n\n问题要求从提供的训练数据中估计这些概率分布的参数。\n\n**1. 参数估计（训练阶段）**\n\n设 $N$ 为训练样本总数，$N_k$ 为类别 $k$ 中的样本数。这里，$N_0=5$，$N_1=4$，$N_2=4$，所以总数为 $N = 5+4+4=13$。\n\n**1.1. 类别先验概率 $P(Y=k)$**\n多项式概率的最大似然估计给出样本频率：\n$$ P(Y=k) = \\frac{N_k}{N} $$\n- $P(Y=0) = 5/13$\n- $P(Y=1) = 4/13$\n- $P(Y=2) = 4/13$\n\n**1.2. 网眼大小 $X_1 \\mid Y=k$ 的高斯参数**\n分布为 $P(X_1=a \\mid Y=k) = \\mathcal{N}(a; \\mu_k, \\sigma_k^2)$。均值 $\\mu_k$ 的 MLE 是样本均值，方差 $\\sigma_k^2$ 的 MLE 是分母为 $N_k$ 的样本方差。\n$$ \\mu_k = \\frac{1}{N_k} \\sum_{i=1}^{N_k} a_i^{(k)} \\quad \\quad \\sigma_k^2 = \\frac{1}{N_k} \\sum_{i=1}^{N_k} (a_i^{(k)} - \\mu_k)^2 $$\n\n- **类别 0 (平行脉)**： $a^{(0)} = \\{0.005, 0.012, 0.008, 0.000, 0.015\\}$\n  - $\\mu_0 = \\frac{1}{5}(0.040) = 0.008$\n  - $\\sigma_0^2 = \\frac{1}{5}((0.005-0.008)^2 + \\dots + (0.015-0.008)^2) = \\frac{1}{5}(1.38 \\times 10^{-4}) = 2.76 \\times 10^{-5}$\n\n- **类别 1 (曲行脉)**： $a^{(1)} = \\{1.2, 0.9, 1.6, 0.7\\}$\n  - $\\mu_1 = \\frac{1}{4}(4.4) = 1.1$\n  - $\\sigma_1^2 = \\frac{1}{4}((1.2-1.1)^2 + \\dots + (0.7-1.1)^2) = \\frac{1}{4}(0.46) = 0.115$\n\n- **类别 2 (直行脉)**： $a^{(2)} = \\{0.3, 0.4, 0.25, 0.5\\}$\n  - $\\mu_2 = \\frac{1}{4}(1.45) = 0.3625$\n  - $\\sigma_2^2 = \\frac{1}{4}((0.3-0.3625)^2 + \\dots + (0.5-0.3625)^2) = \\frac{1}{4}(0.036875) = 0.00921875$\n\n**1.3. 脉环存在与否 $X_2 \\mid Y=k$ 的伯努利参数**\n分布为 $P(X_2=\\ell \\mid Y=k) = p_k^\\ell (1-p_k)^{1-\\ell}$。参数 $p_k = P(X_2=1 \\mid Y=k)$ 使用 $\\alpha=1$ 的 Laplace 平滑进行估计。该特征的结果数量为 $K=2$（存在或不存在）。\n$$ p_k = \\frac{N_{k,1} + \\alpha}{N_k + K\\alpha} = \\frac{N_{k,1} + 1}{N_k + 2} $$\n其中 $N_{k,1}$ 是类别 $k$ 中脉环存在（$\\ell=1$）的样本计数。\n\n- **类别 0**：$N_0=5$，$\\ell=1$ 的样本数为 $N_{0,1}=0$。\n  - $p_0 = (0+1)/(5+2) = 1/7$\n- **类别 1**：$N_1=4$，$\\ell=1$ 的样本数为 $N_{1,1}=4$。\n  - $p_1 = (4+1)/(4+2) = 5/6$\n- **类别 2**：$N_2=4$，$\\ell=1$ 的样本数为 $N_{2,1}=0$。\n  - $p_2 = (0+1)/(4+2) = 1/6$\n\n**2. 分类阶段（推理）**\n\n对于每个测试样本 $(a, \\ell)$，我们计算每个类别 $k \\in \\{0, 1, 2\\}$ 的分数，并选择分数最高的类别。\n\n对数概率项是：\n- **对数先验**：$\\log P(Y=k)$\n- **$X_1$ 的对数似然**：高斯 PDF 的对数为：\n  $$ \\log P(X_1=a \\mid Y=k) = -\\frac{(a-\\mu_k)^2}{2\\sigma_k^2} - \\frac{1}{2}\\log(2\\pi\\sigma_k^2) $$\n- **$X_2$ 的对数似然**：伯努利概率质量函数的对数为：\n  $$ \\log P(X_2=\\ell \\mid Y=k) = \\ell \\log p_k + (1-\\ell)\\log(1-p_k) $$\n\n总分是这三项的总和。最终预测的类别为 $\\hat{k} = \\arg\\max_k \\text{score}(k)$，平局时选择最小的 $k$。对每个测试用例，这些计算都以编程方式实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a Naive Bayes classifier for leaf venation patterns.\n    \"\"\"\n\n    # --- Training Data ---\n    # Data is structured as a dictionary where keys are class labels\n    # and values are lists of (areole_size, loop_presence) tuples.\n    training_data = {\n        0: [(0.005, 0), (0.012, 0), (0.008, 0), (0.000, 0), (0.015, 0)],\n        1: [(1.2, 1), (0.9, 1), (1.6, 1), (0.7, 1)],\n        2: [(0.3, 0), (0.4, 0), (0.25, 0), (0.5, 0)]\n    }\n\n    # --- Test Suite ---\n    test_cases = [\n        (0.010, 0),\n        (1.10, 1),\n        (0.35, 0),\n        (0.80, 0),\n        (0.00, 1),\n        (0.60, 1),\n    ]\n\n    # --- Parameter Estimation (Training) ---\n    \n    classes = sorted(training_data.keys())\n    num_classes = len(classes)\n    params = {}\n\n    total_samples = sum(len(v) for v in training_data.values())\n\n    for k in classes:\n        samples = training_data[k]\n        num_k_samples = len(samples)\n\n        # 1. Estimate class priors P(Y=k) using MLE\n        prior_k = num_k_samples / total_samples\n\n        # 2. Estimate Gaussian parameters (mu, sigma^2) for areole size\n        areole_sizes = np.array([s[0] for s in samples])\n        mu_k = np.mean(areole_sizes)\n        # np.var uses N in denominator, which is correct for MLE\n        sigma2_k = np.var(areole_sizes)\n        \n        # Guard against zero variance for numerical stability in the unlikely event\n        # that all training samples for a feature in a class are identical.\n        # Problem data does not trigger this, but it is good practice.\n        if sigma2_k == 0.0:\n            # Add a very small number to variance if it's zero\n            sigma2_k = 1e-9 \n\n        # 3. Estimate Bernoulli parameter 'p' for loop presence\n        # using Laplace smoothing with alpha=1\n        loop_presences = np.array([s[1] for s in samples])\n        num_loops_present = np.sum(loop_presences)\n        alpha = 1.0\n        num_outcomes = 2  # (present=1, absent=0)\n        p_k = (num_loops_present + alpha) / (num_k_samples + num_outcomes * alpha)\n\n        params[k] = {\n            'log_prior': np.log(prior_k),\n            'mu': mu_k,\n            'sigma2': sigma2_k,\n            'p_loop': p_k\n        }\n\n    # --- Classification (Inference) ---\n    \n    predictions = []\n    for a, l in test_cases:\n        scores = {}\n        for k in classes:\n            # Retrieve trained parameters for class k\n            param_k = params[k]\n            log_prior = param_k['log_prior']\n            mu = param_k['mu']\n            sigma2 = param_k['sigma2']\n            p_loop = param_k['p_loop']\n\n            # Calculate log-likelihood for areole size (Gaussian)\n            log_likelihood_areole = -0.5 * np.log(2 * np.pi * sigma2) - ((a - mu)**2) / (2 * sigma2)\n\n            # Calculate log-likelihood for loop presence (Bernoulli)\n            if l == 1:\n                log_likelihood_loop = np.log(p_loop)\n            else: # l == 0\n                log_likelihood_loop = np.log(1 - p_loop)\n\n            # Calculate total log-posterior score\n            scores[k] = log_prior + log_likelihood_areole + log_likelihood_loop\n\n        # Find the class with the maximum score\n        # Tie-breaking: choose the smallest class index k, which is handled naturally\n        # by iterating through sorted keys if max() returns the first max found.\n        best_class = max(scores, key=scores.get)\n        predictions.append(best_class)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, predictions))}]\")\n\nsolve()\n```", "id": "2586028"}]}