{"hands_on_practices": [{"introduction": "在我们解释空间模式之前，首先需要一种定量的方法来判断一个基因的表达究竟是呈现空间组织性，还是仅仅是随机分布。本练习将引导您使用高斯过程模型（Gaussian Process model）这一强大的统计工具，将基因表达的总变异分解为空间效应和随机噪声两部分。通过计算空间效应解释的方差比例（Proportion of Variance Explained, PVE），您将掌握一项从空间转录组数据中识别关键空间基因的基础技能 [@problem_id:2890143]。", "problem": "给定人类淋巴结组织切片中趋化因子基因 CXCL13 的空间分辨信使核糖核酸 (mRNA) 测量值。假设以下基本前提：分子生物学的中心法则（脱氧核糖核酸到核糖核酸到蛋白质），以及一个经过充分验证的观察结果，即对数归一化的空间转录本计数由于免疫组织中的微解剖生态位而表现出空间自相关性，并叠加有独立的测量噪声。将所有空间点的对数归一化 CXCL13 表达建模为空间随机效应模型：对于一个包含 $n$ 个空间点（坐标为 $\\{\\mathbf{x}_i \\in \\mathbb{R}^2\\}_{i=1}^n$，单位为微米）的样本，观测到的表达向量 $\\mathbf{y} \\in \\mathbb{R}^n$ 满足\n$$\n\\mathbf{y} = \\mu \\mathbf{1} + \\mathbf{s} + \\boldsymbol{\\varepsilon},\n$$\n其中 $\\mu \\in \\mathbb{R}$ 是一个未知的全局均值，$\\mathbf{s} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_s^2 \\mathbf{K})$ 是一个零均值高斯过程空间效应，其方差为 $\\sigma_s^2 \\ge 0$，各向同性平方指数核函数 $\\mathbf{K}$ 定义为\n$$\nK_{ij} = \\exp\\left(-\\frac{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2^2}{2 \\ell^2}\\right),\n$$\n并且 $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_e^2 \\mathbf{I})$ 是独立的残差噪声，其方差为 $\\sigma_e^2 \\ge 0$。长度尺度 $\\ell > 0$ 控制空间衰减，并对每个样本确定性地设置为不同空间点之间所有成对欧几里得距离的中位数，单位为微米。由空间效应解释的方差比例 (PVE) 定义为\n$$\n\\mathrm{PVE} = \\frac{\\sigma_s^2}{\\sigma_s^2 + \\sigma_e^2}。\n$$\n\n任务：对于下面列出的每个样本，在上述模型下，通过最大化 $\\mathbf{y}$ 的高斯边际对数似然来估计 $\\sigma_s^2$ 和 $\\sigma_e^2$。其中 $\\ell$ 按指定方式固定，并将 $\\mu$ 视为一个未知的滋扰参数，通过其最大似然值联合估计。使用基于协方差矩阵 Cholesky 分解的数值稳定方法。如果 $\\mathbf{y}$ 的总样本方差在数值上可忽略不计（定义为小于 $10^{-12}$），则该样本的 $\\mathrm{PVE}$ 定义为 $0.0$。报告每个样本估计的 $\\mathrm{PVE}$，形式为 $[0,1]$ 范围内的十进制数，四舍五入到 $3$ 位小数。\n\n物理单位：所有坐标均以微米 ($\\mu$m) 为单位。输出是无量纲的，必须表示为十进制数。\n\n角度单位：不适用。\n\n百分比：不适用；以十进制数报告。\n\n测试套件（四个样本）。所有样本共享相同的 $n = 9$ 个空间位置，这些位置由笛卡尔积 $\\{0,50,100\\} \\times \\{0,50,100\\}$（单位为微米）给出，排序如下：\n- 空间点 $1$：$(0,0)$\n- 空间点 $2$：$(0,50)$\n- 空间点 $3$：$(0,100)$\n- 空间点 $4$：$(50,0)$\n- 空间点 $5$：$(50,50)$\n- 空间点 $6$：$(50,100)$\n- 空间点 $7$：$(100,0)$\n- 空间点 $8$：$(100,50)$\n- 空间点 $9$：$(100,100)$\n\n对于每个样本，观测到的对数归一化 CXCL13 表达向量 $\\mathbf{y}$（按上述空间点顺序）为：\n\n- 样本 A（中心周围有明显的空间生态位）：$\\mathbf{y}^{(A)} = [4.2, 5.8, 4.1, 6.0, 10.5, 6.2, 3.9, 5.7, 4.0]$。\n- 样本 B（空间结构较弱）：$\\mathbf{y}^{(B)} = [5.1, 5.0, 5.2, 4.9, 5.1, 5.0, 5.2, 5.0, 5.3]$。\n- 样本 C（无明显空间结构；异质噪声）：$\\mathbf{y}^{(C)} = [7.4, 3.1, 5.6, 8.0, 2.7, 4.9, 6.2, 7.9, 3.5]$。\n- 样本 D（边界情况；基本无方差）：$\\mathbf{y}^{(D)} = [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]$。\n\n算法要求：\n- 对于每个样本，计算 $\\ell$ 作为 $\\{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2 : 1 \\le i < j \\le 9\\}$ 的中位数。\n- 对于固定的 $\\ell$，关于 $(\\sigma_s^2, \\sigma_e^2)$ 最大化高斯边际对数似然，其中 $\\sigma_s^2 \\ge 0$ 且 $\\sigma_e^2 \\ge 0$，并且 $\\mu$ 在其最大似然估计处被轮廓化（profiled out）。\n- 通过协方差矩阵 $\\boldsymbol{\\Sigma} = \\sigma_s^2 \\mathbf{K} + \\sigma_e^2 \\mathbf{I}$ 的 Cholesky 分解，使用数值稳定的方法评估对数似然。\n- 如上定义 $\\mathrm{PVE}$，并四舍五入到 $3$ 位小数。\n\n最终输出格式：您的程序应生成单行输出，其中包含与样本 A、B、C 和 D 对应的四个 $\\mathrm{PVE}$ 值，按此顺序排列，四舍五入到 $3$ 位小数，格式为用方括号括起来的逗号分隔列表（例如，$[0.732,0.058,0.113,0.000]$）。", "solution": "该问题是有效的。它在科学上基于空间统计学和分子生物学的原理，特别是使用了高斯过程模型，这是一种分析空间转录组学等空间分辨数据的标准方法。该问题是适定的，提供了所有必要的数据和明确的目标：通过最大化轮廓对数似然来估计方差分量。其表述是客观且数学上精确的。\n\n解决方案的步骤是，首先为感兴趣的参数——解释方差比例 (PVE)——推导出轮廓对数似然函数，然后对每个数据样本进行数值最大化。\n\n**1. 模型设定与似然**\n\n观测到的对数归一化表达向量 $\\mathbf{y} \\in \\mathbb{R}^n$ 的模型由下式给出：\n$$\n\\mathbf{y} = \\mu \\mathbf{1} + \\mathbf{s} + \\boldsymbol{\\varepsilon}\n$$\n其中 $\\mu$ 是全局均值，$\\mathbf{s} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_s^2 \\mathbf{K})$ 是空间效应，$\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_e^2 \\mathbf{I})$ 是独立噪声。因此，总数据向量 $\\mathbf{y}$ 服从多元正态分布：\n$$\n\\mathbf{y} \\sim \\mathcal{N}(\\mu\\mathbf{1}, \\boldsymbol{\\Sigma})\n$$\n其中协方差矩阵 $\\boldsymbol{\\Sigma}$ 为 $\\boldsymbol{\\Sigma} = \\sigma_s^2 \\mathbf{K} + \\sigma_e^2 \\mathbf{I}$。需要估计的参数是方差 $\\sigma_s^2 \\ge 0$ 和 $\\sigma_e^2 \\ge 0$，而均值 $\\mu$ 是一个滋扰参数。\n\n$\\mathbf{y}$ 的对数似然函数（忽略常数项）为：\n$$\n\\mathcal{L}(\\mu, \\sigma_s^2, \\sigma_e^2) = -\\frac{1}{2} (\\mathbf{y} - \\mu \\mathbf{1})^\\top \\boldsymbol{\\Sigma}^{-1} (\\mathbf{y} - \\mu \\mathbf{1}) - \\frac{1}{2} \\log \\det(\\boldsymbol{\\Sigma})\n$$\n\n**2. 参数化与轮廓化**\n\n为简化优化过程，我们根据解释方差比例 (PVE)（记作 $\\alpha \\in [0, 1]$）和一个总方差项对协方差矩阵进行重新参数化。令 $\\alpha = \\frac{\\sigma_s^2}{\\sigma_s^2 + \\sigma_e^2}$。我们可以定义一个总方差参数，但为了进行轮廓化，使用 $\\sigma_e^2$ 和比率 $v = \\sigma_s^2 / \\sigma_e^2$ 更为方便。一种更稳定、更直接的方法是直接通过 $\\alpha$ 和一个总尺度因子进行参数化。设总方差为 $\\sigma_{tot}^2 = \\sigma_s^2 + \\sigma_e^2$。则 $\\sigma_s^2 = \\alpha \\sigma_{tot}^2$ 且 $\\sigma_e^2 = (1-\\alpha) \\sigma_{tot}^2$。协方差矩阵变为：\n$$\n\\boldsymbol{\\Sigma}(\\alpha, \\sigma_{tot}^2) = \\sigma_{tot}^2 \\left( \\alpha \\mathbf{K} + (1-\\alpha) \\mathbf{I} \\right) = \\sigma_{tot}^2 \\mathbf{V}(\\alpha)\n$$\n其中 $\\mathbf{V}(\\alpha) = \\alpha \\mathbf{K} + (1-\\alpha) \\mathbf{I}$。对数似然则为：\n$$\n\\mathcal{L}(\\mu, \\alpha, \\sigma_{tot}^2) = -\\frac{1}{2\\sigma_{tot}^2} (\\mathbf{y} - \\mu\\mathbf{1})^\\top \\mathbf{V}(\\alpha)^{-1} (\\mathbf{y} - \\mu\\mathbf{1}) - \\frac{n}{2} \\log(\\sigma_{tot}^2) - \\frac{1}{2} \\log\\det(\\mathbf{V}(\\alpha))\n$$\n我们对该似然函数关于参数进行最大化。问题要求将 $\\mu$ 视为滋扰参数。我们可以通过将其替换为其最大似然估计 (MLE) 来“轮廓化（profile it out）”，对于固定的 $\\alpha$ 和 $\\sigma_{tot}^2$，该估计是广义最小二乘 (GLS) 估计：\n$$\n\\hat{\\mu}(\\alpha) = \\frac{\\mathbf{1}^\\top \\mathbf{V}(\\alpha)^{-1} \\mathbf{y}}{\\mathbf{1}^\\top \\mathbf{V}(\\alpha)^{-1} \\mathbf{1}}\n$$\n我们也可以轮廓化总方差 $\\sigma_{tot}^2$。对 $\\mathcal{L}$ 关于 $\\sigma_{tot}^2$ 求导并令其为零，得到其 MLE：\n$$\n\\hat{\\sigma}_{tot}^2(\\alpha) = \\frac{1}{n} (\\mathbf{y} - \\hat{\\mu}(\\alpha)\\mathbf{1})^\\top \\mathbf{V}(\\alpha)^{-1} (\\mathbf{y} - \\hat{\\mu}(\\alpha)\\mathbf{1}) = \\frac{Q(\\alpha)}{n}\n$$\n其中我们将 $Q(\\alpha)$ 定义为 GLS 残差平方和。将 $\\hat{\\mu}(\\alpha)$ 和 $\\hat{\\sigma}_{tot}^2(\\alpha)$ 代回似然函数，得到轮廓对数似然，它只是 $\\alpha$ 的函数：\n$$\n\\mathcal{L}_{prof}(\\alpha) \\propto -\\frac{n}{2} \\log(Q(\\alpha)) - \\frac{1}{2} \\log\\det(\\mathbf{V}(\\alpha))\n$$\n最大化 $\\mathcal{L}_{prof}(\\alpha)$ 等价于最小化其负值（乘以 2 后）：\n$$\nf(\\alpha) = n \\log(Q(\\alpha)) + \\log\\det(\\mathbf{V}(\\alpha))\n$$\nPVE 的估计值是最小化此目标函数的 $\\alpha \\in [0, 1]$ 的值。\n\n**3. 算法与数值策略**\n\n每个样本的总体算法如下：\n\n1.  **特殊情况处理**：根据题目要求，如果 $\\mathbf{y}$ 的样本方差小于 $10^{-12}$，我们设置 $\\mathrm{PVE} = 0.0$ 并且不进行优化。这处理了没有方差可解释的情况，如样本 D。\n\n2.  **核函数预计算**：所有样本的空间点坐标 $\\{\\mathbf{x}_i\\}_{i=1}^n$ 都是固定的。\n    a. 我们计算 $i < j$ 的所有成对欧几里得距离 $\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2$。对于 $n=9$ 个空间点，这会得到 $9 \\times 8 / 2 = 36$ 个唯一的距离。\n    b. 长度尺度 $\\ell$ 被确定为这 $36$ 个距离的中位数。\n    c. 然后计算核矩阵 $\\mathbf{K}$，其元素为 $K_{ij} = \\exp\\left(-\\frac{\\lVert \\mathbf{x}_i - \\mathbf{x}_j \\rVert_2^2}{2 \\ell^2}\\right)$。\n\n3.  **数值优化**：我们使用数值优化程序，通过在区间 $[0, 1]$ 上最小化目标函数 $f(\\alpha)$ 来找到最优的 $\\alpha$。\n\n4.  **目标函数的稳定评估**：对于 $f(\\alpha)$ 的每次评估，我们必须以数值稳定的方式计算 $Q(\\alpha)$ 和 $\\log\\det(\\mathbf{V}(\\alpha))$。\n    a. 首先，构建矩阵 $\\mathbf{V}(\\alpha) = \\alpha \\mathbf{K} + (1-\\alpha) \\mathbf{I}$。\n    b. 执行 Cholesky 分解 $\\mathbf{V}(\\alpha) = \\mathbf{L}\\mathbf{L}^\\top$，其中 $\\mathbf{L}$ 是一个下三角矩阵。这是一种检查正定性且数值稳定的可靠方法。\n    c. 对数行列式计算为 $\\log\\det(\\mathbf{V}(\\alpha)) = 2 \\sum_{i=1}^n \\log(L_{ii})$。\n    d. 涉及 $\\mathbf{V}(\\alpha)^{-1}$ 的项，例如 $\\mathbf{V}(\\alpha)^{-1}\\mathbf{y}$，通过使用 $\\mathbf{L}$ 求解线性方程组来计算。对于一个向量 $\\mathbf{v}$，我们通过先求解 $\\mathbf{L}\\mathbf{w} = \\mathbf{v}$ 得到 $\\mathbf{w}$（前向替换），然后求解 $\\mathbf{L}^\\top\\mathbf{z} = \\mathbf{w}$ 得到 $\\mathbf{z}$（后向替换），从而找到 $\\mathbf{z} = \\mathbf{V}(\\alpha)^{-1}\\mathbf{v}$。这样可以避免显式矩阵求逆。\n    e. 利用这些稳定组件，我们计算 $\\hat{\\mu}(\\alpha)$、残差向量 $\\mathbf{r} = \\mathbf{y} - \\hat{\\mu}(\\alpha)\\mathbf{1}$，以及最后的二次型 $Q(\\alpha) = \\mathbf{r}^\\top \\mathbf{V}(\\alpha)^{-1} \\mathbf{r}$。计算 $Q(\\alpha)$ 的一种稳定方法是求解 $\\mathbf{L}\\mathbf{w}_r = \\mathbf{r}$ 得到 $\\mathbf{w}_r$，然后 $Q(\\alpha) = \\mathbf{w}_r^\\top \\mathbf{w}_r$。\n\n5.  **最终结果**：$f(\\alpha)$ 的最小化者即为估计的 PVE，然后按要求四舍五入到 $3$ 位小数。此过程应用于四个样本中的每一个。", "answer": "```python\nimport numpy as np\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.optimize import minimize_scalar\nfrom scipy.linalg import cholesky, solve_triangular\n\ndef solve():\n    \"\"\"\n    Solves the spatial transcriptomics variance component estimation problem.\n    \"\"\"\n    # Define the fixed spatial locations for all samples\n    coords_list = [\n        (0.0, 0.0), (0.0, 50.0), (0.0, 100.0),\n        (50.0, 0.0), (50.0, 50.0), (50.0, 100.0),\n        (100.0, 0.0), (100.0, 50.0), (100.0, 100.0)\n    ]\n    coords = np.array(coords_list, dtype=np.float64)\n    n = coords.shape[0]\n\n    # Define the observed expression vectors for each sample\n    test_cases = [\n        np.array([4.2, 5.8, 4.1, 6.0, 10.5, 6.2, 3.9, 5.7, 4.0], dtype=np.float64), # Sample A\n        np.array([5.1, 5.0, 5.2, 4.9, 5.1, 5.0, 5.2, 5.0, 5.3], dtype=np.float64), # Sample B\n        np.array([7.4, 3.1, 5.6, 8.0, 2.7, 4.9, 6.2, 7.9, 3.5], dtype=np.float64), # Sample C\n        np.array([2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], dtype=np.float64)  # Sample D\n    ]\n\n    # --- Pre-computation of the spatial kernel ---\n    # 1. Compute length-scale 'l' as the median of pairwise distances\n    pairwise_distances = pdist(coords)\n    l_scale = np.median(pairwise_distances)\n\n    # 2. Compute the squared-exponential kernel matrix 'K'\n    sq_dist_matrix = squareform(pairwise_distances**2)\n    K = np.exp(-sq_dist_matrix / (2 * l_scale**2))\n    \n    # --- Negative Profiled Log-Likelihood Function Factory ---\n    def get_objective_function(y, K_matrix):\n        \"\"\"\n        Returns the objective function to be minimized.\n        The objective function is the negative profiled log-likelihood for the PVE parameter 'alpha'.\n        \"\"\"\n        n_spots = len(y)\n        ones_vec = np.ones(n_spots)\n\n        def objective(alpha):\n            \"\"\"\n            Computes the value of the objective function for a given alpha (PVE).\n            alpha is in [0, 1].\n            \"\"\"\n            # Define V(alpha) = alpha*K + (1-alpha)*I\n            V_matrix = alpha * K_matrix + (1 - alpha) * np.identity(n_spots)\n\n            try:\n                # Cholesky factorization for stability\n                L = cholesky(V_matrix, lower=True)\n            except np.linalg.LinAlgError:\n                # If matrix is not positive definite, return a large value\n                # to penalize this region of the parameter space.\n                return np.inf\n\n            # log determinant of V\n            log_det_V = 2 * np.sum(np.log(np.diag(L)))\n\n            # Solve for V_inv @ y and V_inv @ 1 using forward/backward substitution\n            y_tilde = solve_triangular(L, y, lower=True)\n            z_y = solve_triangular(L.T, y_tilde, lower=False)\n            \n            o_tilde = solve_triangular(L, ones_vec, lower=True)\n            z_1 = solve_triangular(L.T, o_tilde, lower=False)\n\n            # GLS estimate of the mean mu\n            mu_hat = np.sum(z_y) / np.sum(z_1)\n\n            # Quadratic form Q(alpha)\n            residual = y - mu_hat\n            w_r = solve_triangular(L, residual, lower=True)\n            Q = np.dot(w_r, w_r)\n\n            # Guard against log(0) for perfect fits\n            if Q < 1e-20:\n                return -np.inf\n\n            # Final objective value (from profiled log-likelihood)\n            return n_spots * np.log(Q) + log_det_V\n\n        return objective\n\n    # --- Process each sample ---\n    results = []\n    for y_vec in test_cases:\n        # Special case: if sample has negligible variance, PVE is defined as 0\n        if np.var(y_vec, ddof=0) < 1e-12:\n            pve = 0.0\n        else:\n            # Create the objective function for the current sample\n            objective_func = get_objective_function(y_vec, K)\n            \n            # Find the PVE (alpha) that minimizes the objective function\n            res = minimize_scalar(\n                objective_func,\n                bounds=(0, 1),\n                method='bounded'\n            )\n            pve = res.x\n            \n        results.append(pve)\n    \n    # Format results as specified\n    rounded_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(rounded_results)}]\")\n\nsolve()\n```", "id": "2890143"}, {"introduction": "免疫组织被组织成功能性的微解剖区域，这些区域通常由多个关键基因的共表达来定义。本实践将指导您完成一个完整的生物信息学工作流程，从空间转录组数据中识别这些区域——在本例中是三级淋巴结构（Tertiary Lymphoid Structures, TLS）。您将应用特征工程、无监督聚类和空间滤波技术，将原始基因表达计数转化为具有生物学意义的组织结构图，这是空间生物学中的一项核心技能 [@problem_id:2890083]。", "problem": "您将获得代表发炎肺组织以及潜在三级淋巴结构 (TLS) 的合成空间转录组学数据。目标是通过对 CXCL13、CCL19 和外周淋巴结地址素 (PNAd) 这三个配体/特征通道进行聚类来算法化地识别 TLS，并根据提供的组织学衍生的二元 TLS 标注来验证预测的 TLS。三级淋巴结构 (TLS) 是异位淋巴聚集体，通常富含趋化因子 CXCL13 和 CCL19，并以表达外周淋巴结地址素 (PNAd) 的特殊脉管系统为特征。\n\n您的程序必须仅使用第一性原理和核心定义来实现以下流程：\n\n- 从分子生物学中心法则出发，其中转录产生可在空间位点上量化为计数的信使核糖核酸 (mRNA)。用三个通道的观测计数组成的三维特征向量来表示每个位点。\n- 对计数应用单调方差稳定变换，使用自然对数：对于每个观测到的计数 $x \\in \\mathbb{R}_{\\ge 0}$，通过 $x_{\\mathrm{log}} = \\log(1 + x)$ 进行变换。\n- 使用 $z$-score 对每个特征在所有位点上进行标准化：对于一个样本均值为 $\\mu_f$、样本标准差为 $\\sigma_f$ 的特征 $f$，每个变换后的值为 $z = \\frac{x_{\\mathrm{log}} - \\mu_f}{\\sigma_f}$，并约定如果 $\\sigma_f = 0$，则该特征的所有标准化值都设为 $0$。\n- 在标准化的三维空间中，使用 $k$-means 目标函数将位点聚类成 $k = 2$ 个簇。该目标是最小化簇内欧几里得距离的平方和。使用欧几里得距离 $d(\\mathbf{u}, \\mathbf{v}) = \\|\\mathbf{u} - \\mathbf{v}\\|_2$，通过选择特征总和为最小和最大的位点的特征向量作为初始质心来进行确定性初始化，并迭代直至分配结果稳定。如果出现空簇，则将其质心重新初始化为距离另一个簇的质心最远的点。\n- 将其质心在三个标准化特征上的均值更大的簇指定为“TLS 簇”。这编码了一个生物学预期，即 TLS 与共同升高的 CXCL13、CCL19 和 PNAd 特征信号共定位。\n- 通过仅保留那些属于大小至少为指定阈值 $\\tau$ 的连通分量（使用 4-邻域邻接：上、下、左、右）的预测 TLS 位点，来强制执行空间连续性。移除所有较小的预测 TLS 连通分量。\n- 使用 $F_1$ 分数验证预测的 TLS 与组织学 TLS 标注。设真正例为 $TP$，假正例为 $FP$，假负例为 $FN$。计算精确率 $P = \\frac{TP}{TP + FP}$（如果 $TP + FP = 0$ 则定义为 $0$），召回率 $R = \\frac{TP}{TP + FN}$（如果 $TP + FN = 0$ 则定义为 $0$），以及\n$$\nF_1 =\n\\begin{cases}\n1, & \\text{if the number of positives in both prediction and ground truth is } 0 \\\\\n\\frac{2 P R}{P + R}, & \\text{if } P + R > 0 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n$$\n这种约定避免了当预测和真实情况都没有正例位点时出现未定义值的情况。\n\n实现上述流程并在以下三个测试用例上运行。在每个测试用例中，您都会得到一个 $5 \\times 5$ 大小的位点网格。每个网格以三个计数矩阵（分别对应 CXCL13、CCL19 和 PNAd 通道）和一个二元组织学掩码的形式给出，其中 $1$ 表示 TLS 标签，$0$ 表示背景。对于邻接性，在此网格上使用 4-邻域连通性。程序不得接受任何输入；必须将这些数据集嵌入程序中。\n\n测试用例 1 (理想路径：紧凑的高表达 TLS)：\n- 网格大小：$5 \\times 5$。\n- CXCL13 计数：\n$$\n\\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 60 & 60 & 60 & 1 \\\\\n1 & 60 & 60 & 60 & 1 \\\\\n1 & 60 & 60 & 60 & 1 \\\\\n1 & 1 & 1 & 1 & 1\n\\end{bmatrix}\n$$\n- CCL19 计数：\n$$\n\\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 50 & 50 & 50 & 1 \\\\\n1 & 50 & 50 & 50 & 1 \\\\\n1 & 50 & 50 & 50 & 1 \\\\\n1 & 1 & 1 & 1 & 1\n\\end{bmatrix}\n$$\n- PNAd 特征计数：\n$$\n\\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 40 & 40 & 40 & 1 \\\\\n1 & 40 & 40 & 40 & 1 \\\\\n1 & 40 & 40 & 40 & 1 \\\\\n1 & 1 & 1 & 1 & 1\n\\end{bmatrix}\n$$\n- 组织学 TLS 掩码：\n$$\n\\begin{bmatrix}\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 1 & 0 \\\\\n0 & 1 & 1 & 1 & 0 \\\\\n0 & 1 & 1 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{bmatrix}\n$$\n- 连续性阈值：$\\tau = 5$。\n\n测试用例 2 (边缘案例：分散的高表达但无组织学 TLS)：\n- 网格大小：$5 \\times 5$。\n- CXCL13 计数：\n$$\n\\begin{bmatrix}\n60 & 1 & 1 & 1 & 60 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n60 & 1 & 1 & 1 & 60\n\\end{bmatrix}\n$$\n- CCL19 计数：\n$$\n\\begin{bmatrix}\n50 & 1 & 1 & 1 & 50 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n50 & 1 & 1 & 1 & 50\n\\end{bmatrix}\n$$\n- PNAd 特征计数：\n$$\n\\begin{bmatrix}\n40 & 1 & 1 & 1 & 40 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n40 & 1 & 1 & 1 & 40\n\\end{bmatrix}\n$$\n- 组织学 TLS 掩码：\n$$\n\\begin{bmatrix}\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{bmatrix}\n$$\n- 连续性阈值：$\\tau = 3$。\n\n测试用例 3 (边界条件：组织学 TLS 小于连续性阈值)：\n- 网格大小：$5 \\times 5$。\n- CXCL13 计数：\n$$\n\\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 20 & 20 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1\n\\end{bmatrix}\n$$\n- CCL19 计数：\n$$\n\\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 18 & 18 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1\n\\end{bmatrix}\n$$\n- PNAd 特征计数：\n$$\n\\begin{bmatrix}\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 15 & 15 & 1 \\\\\n1 & 1 & 1 & 1 & 1 \\\\\n1 & 1 & 1 & 1 & 1\n\\end{bmatrix}\n$$\n- 组织学 TLS 掩码：\n$$\n\\begin{bmatrix}\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 1 & 1 & 0 \\\\\n0 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & 0\n\\end{bmatrix}\n$$\n- 连续性阈值：$\\tau = 3$。\n\n角度单位不适用。没有需要报告的物理单位。您的程序应生成单行输出，其中包含三个测试用例的 $F_1$ 分数，形式为方括号内的逗号分隔列表，每个值四舍五入到三位小数（例如，$[0.997,0.000,1.000]$）。输出必须严格为这一行，不得包含多余的空格。", "solution": "提交以供评估的问题陈述被认为是有效的。它具有科学依据、问题明确且客观。它基于分子生物学、统计学和计算机科学的既定原则，提出了一个明确定义的算法任务。数据、约束条件和评估指标的规定足够精确，足以得出一个唯一且可验证的解决方案。我们现在将继续进行所需流程的形式化推导和实现。\n\n任务是从合成的空间转录组学数据中识别三级淋巴结构 (TLS)。解决方案被构建为一个多步计算流程，我们将从第一性原理开始构建。\n\n**1. 数据表示与预处理**\n\n分子生物学中心法则假定遗传信息从 DNA 流向 RNA 再到蛋白质。空间转录组学在空间分辨的位置（或称“位点”）量化转录产生的信使 RNA (mRNA) 产物。对于由网格坐标 $(i, j)$ 定位的每个位点，数据提供了三个特定基因特征信号（CXCL13、CCL19 和 PNAd）的 mRNA 计数。因此，网格中的 $N$ 个位点中的每一个都由一个非负整数计数的三维特征向量表示，$\\mathbf{x} = [x_{CXCL13}, x_{CCL19}, x_{PNAd}]^T \\in \\mathbb{N}_0^3$。\n\n众所周知，转录组学计数数据表现出大的动态范围和异方差性（方差依赖于均值）。一个常见且强制性的步骤是应用方差稳定变换。根据问题规范，我们使用对数变换。对于每个计数 $x_k$，变换后的值 $x_{k, \\mathrm{log}}$ 计算如下：\n$$\nx_{k, \\mathrm{log}} = \\log(1 + x_k)\n$$\n加 1 确保零计数映射到 $0$，并避免对数在零处的奇异性。\n\n变换之后，每个特征（基因特征信号）都必须进行标准化，以便为基于距离的聚类提供一个共同的尺度。我们采用 $z$-score 变换。对于每个特征 $f \\in \\{CXCL13, CCL19, PNAd\\}$，我们计算其在所有 $N$ 个位点上的样本均值 $\\mu_f$ 和样本标准差 $\\sigma_f$。然后将每个对数变换后的值 $x_{f, \\mathrm{log}}$ 标准化为 $z_f$：\n$$\nz_f = \\frac{x_{f, \\mathrm{log}} - \\mu_f}{\\sigma_f}\n$$\n如果一个特征在所有位点上的方差为零（$\\sigma_f = 0$），则其所有标准化值都定义为 $0$。结果是一组包含 $N$ 个标准化特征向量的集合 $\\{\\mathbf{z}_1, \\mathbf{z}_2, \\dots, \\mathbf{z}_N\\}$，其中每个 $\\mathbf{z}_i \\in \\mathbb{R}^3$。\n\n**2. K-means 聚类**\n\n识别任务的核心是根据位点的基因特征信号谱将其划分为两组——潜在的 TLS 和背景组织。我们使用 $k=2$ 的 $k$-means 聚类。目标是找到 $N$ 个位点的一个划分 $S = \\{S_1, S_2\\}$，以最小化簇内欧几里得距离的平方和。设 $\\mathbf{c}_j$ 为簇 $S_j$ 的质心。要最小化的目标函数是：\n$$\n\\sum_{j=1}^{2} \\sum_{\\mathbf{z} \\in S_j} \\|\\mathbf{z} - \\mathbf{c}_j\\|_2^2\n$$\n其中 $\\|\\cdot\\|_2$ 是欧几里得范数。算法按以下步骤进行：\n\n- **初始化**：质心必须进行确定性初始化。我们计算每个标准化特征向量 $\\mathbf{z}_i$ 的分量之和。选择其特征向量产生最小和最大总和的两个位点，它们的特征向量成为初始质心 $\\mathbf{c}_1$ 和 $\\mathbf{c}_2$。\n- **迭代**：算法在两个步骤之间进行迭代，直到聚类分配不再改变。\n    1.  **分配步骤**：每个位点的特征向量 $\\mathbf{z}_i$ 被分配到对应于最近质心 $\\mathbf{c}_j$ 的簇 $S_j$。分配基于最小化欧几里得距离：\n        $$\n        j^* = \\arg\\min_{j \\in \\{1, 2\\}} d(\\mathbf{z}_i, \\mathbf{c}_j) = \\arg\\min_{j \\in \\{1, 2\\}} \\|\\mathbf{z}_i - \\mathbf{c}_j\\|_2\n        $$\n    2.  **更新步骤**：每个簇的质心被重新计算为分配给它的所有特征向量的均值：\n        $$\n        \\mathbf{c}_j = \\frac{1}{|S_j|} \\sum_{\\mathbf{z} \\in S_j} \\mathbf{z}\n        $$\n- **空簇处理**：如果更新步骤导致出现空簇 $S_j$（即 $|S_j| = 0$），其质心 $\\mathbf{c}_j$ 将被重新初始化。它被设置为距离另一个非空簇的质心最远的特征向量 $\\mathbf{z}_i$。这可以防止算法坍缩成单个簇。\n\n**3. TLS 簇指定**\n\n收敛后，我们得到两个簇。从生物学上讲，TLS 的特征是 CXCL13、CCL19 和 PNAd 的共同上调。在标准化的特征空间中，这对应于一个其质心在三个分量上具有更高平均值的簇。设最终质心为 $\\mathbf{c}_1 = [c_{11}, c_{12}, c_{13}]^T$ 和 $\\mathbf{c}_2 = [c_{21}, c_{22}, c_{23}]^T$。我们将“TLS 簇”指定为质心分量均值最大的簇 $j^*$：\n$$\nj^* = \\arg\\max_{j \\in \\{1, 2\\}} \\left( \\frac{1}{3} \\sum_{l=1}^{3} c_{jl} \\right)\n$$\n所有分配给簇 $S_{j^*}$ 的位点被赋予初步预测标签 $1$ (TLS)，所有其他位点被标记为 $0$ (非 TLS)。这就产生了一个二元预测掩码。\n\n**4. 空间连续性滤波**\n\nTLS 是有组织的结构，而不是分散的单个细胞。因此，有效的预测必须强制执行空间连续性。我们对二元预测掩码应用一个后处理滤波器。我们识别标记为 $1$ 的位点的连通分量。连通性由网格上的 4-邻域定义：如果两个位点共享一条边（上、下、左、右），则它们是相邻的。这可以通过图遍历算法（如广度优先搜索 (BFS) 或深度优先搜索 (DFS)）来实现。\n对于每个预测的 TLS 位点的连通分量，我们计算其大小（位点数）。任何大小小于给定阈值 $\\tau$ 的分量都被认为是生物学上不重要的噪声或伪影。此类小分量内的所有位点的标签都从 $1$ 恢复为 $0$。这个滤波步骤通过只保留具有最小尺寸的空间连贯结构来优化预测结果。\n\n**5. 性能验证**\n\n最后一步是使用 $F_1$ 分数来定量验证滤波后的预测掩码与真实组织学标注。$F_1$ 分数是精确率和召回率的调和平均值。首先，我们计算真正例 ($TP$)、假正例 ($FP$) 和假负例 ($FN$) 的数量：\n- $TP$：正确预测为 TLS 的位点数（预测=1，真实=1）。\n- $FP$：错误预测为 TLS 的位点数（预测=1，真实=0）。\n- $FN$：错误预测为非 TLS 的位点数（预测=0，真实=1）。\n\n然后计算精确率 ($P$) 和召回率 ($R$)：\n$$\nP = \\frac{TP}{TP + FP} \\quad \\text{(defined as 0 if } TP + FP = 0)\n$$\n$$\nR = \\frac{TP}{TP + FN} \\quad \\text{(defined as 0 if } TP + FN = 0)\n$$\n$F_1$ 分数根据提供的特定规则计算：\n$$\nF_1 =\n\\begin{cases}\n1, & \\text{if } TP+FP=0 \\text{ and } TP+FN=0 \\\\\n\\frac{2 P R}{P + R}, & \\text{if } P + R > 0 \\\\\n0, & \\text{otherwise}\n\\end{cases}\n$$\n第一种情况正确地处理了预测和真实情况均不包含正例的场景，这应被视为一次完美匹配 ($F_1 = 1$)。然后，将这整个流程应用于所提供的三个测试用例中的每一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the full TLS identification and validation pipeline.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {\n            \"cxcl13\": np.array([\n                [1, 1, 1, 1, 1],\n                [1, 60, 60, 60, 1],\n                [1, 60, 60, 60, 1],\n                [1, 60, 60, 60, 1],\n                [1, 1, 1, 1, 1]\n            ]),\n            \"ccl19\": np.array([\n                [1, 1, 1, 1, 1],\n                [1, 50, 50, 50, 1],\n                [1, 50, 50, 50, 1],\n                [1, 50, 50, 50, 1],\n                [1, 1, 1, 1, 1]\n            ]),\n            \"pnad\": np.array([\n                [1, 1, 1, 1, 1],\n                [1, 40, 40, 40, 1],\n                [1, 40, 40, 40, 1],\n                [1, 40, 40, 40, 1],\n                [1, 1, 1, 1, 1]\n            ]),\n            \"histology\": np.array([\n                [0, 0, 0, 0, 0],\n                [0, 1, 1, 1, 0],\n                [0, 1, 1, 1, 0],\n                [0, 1, 1, 1, 0],\n                [0, 0, 0, 0, 0]\n            ]),\n            \"tau\": 5\n        },\n        # Test case 2\n        {\n            \"cxcl13\": np.array([\n                [60, 1, 1, 1, 60],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [60, 1, 1, 1, 60]\n            ]),\n            \"ccl19\": np.array([\n                [50, 1, 1, 1, 50],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [50, 1, 1, 1, 50]\n            ]),\n            \"pnad\": np.array([\n                [40, 1, 1, 1, 40],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [40, 1, 1, 1, 40]\n            ]),\n            \"histology\": np.array([\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0]\n            ]),\n            \"tau\": 3\n        },\n        # Test case 3\n        {\n            \"cxcl13\": np.array([\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 20, 20, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1]\n            ]),\n            \"ccl19\": np.array([\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 18, 18, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1]\n            ]),\n            \"pnad\": np.array([\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 15, 15, 1],\n                [1, 1, 1, 1, 1],\n                [1, 1, 1, 1, 1]\n            ]),\n            \"histology\": np.array([\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 1, 1, 0],\n                [0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0]\n            ]),\n            \"tau\": 3\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        cxcl13, ccl19, pnad, histology, tau = case[\"cxcl13\"], case[\"ccl19\"], case[\"pnad\"], case[\"histology\"], case[\"tau\"]\n        \n        # Combine channels into a feature matrix\n        shape = cxcl13.shape\n        n_spots = shape[0] * shape[1]\n        features = np.stack([cxcl13.flatten(), ccl19.flatten(), pnad.flatten()], axis=1)\n\n        # 1. Log transform\n        log_features = np.log1p(features)\n        \n        # 2. Z-score standardization\n        mean = np.mean(log_features, axis=0)\n        std = np.std(log_features, axis=0)\n        \n        # Handle std == 0 case\n        z_scores = np.zeros_like(log_features)\n        non_zero_std_mask = std != 0\n        if np.any(non_zero_std_mask):\n            z_scores[:, non_zero_std_mask] = (log_features[:, non_zero_std_mask] - mean[non_zero_std_mask]) / std[non_zero_std_mask]\n\n        # 3. K-means clustering (k=2)\n        # Initialization\n        feature_sums = np.sum(z_scores, axis=1)\n        min_idx, max_idx = np.argmin(feature_sums), np.argmax(feature_sums)\n        centroids = np.array([z_scores[min_idx], z_scores[max_idx]])\n        \n        assignments = np.zeros(n_spots, dtype=int)\n        \n        while True:\n            old_assignments = assignments.copy()\n            \n            # Assignment step\n            distances = np.sqrt(((z_scores[:, np.newaxis, :] - centroids[np.newaxis, :, :])**2).sum(axis=2))\n            assignments = np.argmin(distances, axis=1)\n            \n            # Update step\n            new_centroids = np.zeros_like(centroids)\n            for i in range(2):\n                points_in_cluster = z_scores[assignments == i]\n                if len(points_in_cluster) == 0:\n                    # Empty cluster handling\n                    other_centroid = centroids[1 - i]\n                    dists_to_other = np.linalg.norm(z_scores - other_centroid, axis=1)\n                    farthest_point_idx = np.argmax(dists_to_other)\n                    new_centroids[i] = z_scores[farthest_point_idx]\n                else:\n                    new_centroids[i] = np.mean(points_in_cluster, axis=0)\n            \n            centroids = new_centroids\n            \n            if np.array_equal(assignments, old_assignments):\n                break\n\n        # 4. Designate TLS cluster\n        centroid_means = np.mean(centroids, axis=1)\n        tls_cluster_label = np.argmax(centroid_means)\n        \n        prediction_mask_flat = (assignments == tls_cluster_label).astype(int)\n        prediction_mask = prediction_mask_flat.reshape(shape)\n\n        # 5. Spatial contiguity filtering\n        visited = np.zeros(shape, dtype=bool)\n        filtered_prediction_mask = np.zeros(shape, dtype=int)\n        \n        for r in range(shape[0]):\n            for c in range(shape[1]):\n                if prediction_mask[r, c] == 1 and not visited[r, c]:\n                    component = []\n                    q = [(r, c)]\n                    visited[r, c] = True\n                    \n                    while q:\n                        curr_r, curr_c = q.pop(0)\n                        component.append((curr_r, curr_c))\n                        \n                        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n                            nr, nc = curr_r + dr, curr_c + dc\n                            if 0 <= nr < shape[0] and 0 <= nc < shape[1] and \\\n                               prediction_mask[nr, nc] == 1 and not visited[nr, nc]:\n                                visited[nr, nc] = True\n                                q.append((nr, nc))\n                    \n                    if len(component) >= tau:\n                        for comp_r, comp_c in component:\n                            filtered_prediction_mask[comp_r, comp_c] = 1\n\n        # 6. Validation with F1 score\n        pred_flat = filtered_prediction_mask.flatten()\n        truth_flat = histology.flatten()\n        \n        tp = np.sum((pred_flat == 1) & (truth_flat == 1))\n        fp = np.sum((pred_flat == 1) & (truth_flat == 0))\n        fn = np.sum((pred_flat == 0) & (truth_flat == 1))\n        \n        num_pos_pred = tp + fp\n        num_pos_true = tp + fn\n        \n        if num_pos_pred == 0 and num_pos_true == 0:\n            f1 = 1.0\n        else:\n            precision = tp / num_pos_pred if num_pos_pred > 0 else 0.0\n            recall = tp / num_pos_true if num_pos_true > 0 else 0.0\n            \n            if precision + recall > 0:\n                f1 = 2 * (precision * recall) / (precision + recall)\n            else:\n                f1 = 0.0\n        \n        results.append(f\"{f1:.3f}\")\n\n    # Final print statement\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2890083"}, {"introduction": "空间生物学研究常常需要整合来自多个来源的信息来检验复杂的假说。这项高级练习将挑战您去探究一个缺氧基因特征是否在生发中心（germinal centers）内固有地升高，或者其定位是否可以被一个混杂因素——即与供氧血管的距离——所解释。通过构建一个能够校正此混杂因素的模拟和分析模型，您将实践一项科学探究中的关键技能：区分真实的生物学关联与空间上的共现 [@problem_id:2890183]。", "problem": "给定一个概念性流程，用于评估在对脉管系统进行校正后，缺氧相关基因特征是否仍局限于淋巴组织中的生发中心 (GCs)。其中，脉管系统通过 CD31 的免疫荧光 (IF) 进行标记，基因特征通过空间转录组学 (ST) 进行测量。您必须将其形式化为可复现的算法，并将其实现为一个程序。\n\n假设与基本原理：\n- 在组织中，氧气输送受到与血管距离的限制，因此缺氧程度随与血管距离的增加而增加。这是生理学和肿瘤免疫学中一个公认的观察结果。\n- 空间转录组学测量空间索引位置（点）上的基因表达。缺氧特征分数是每个点上的一个连续变量。\n- 我们使用一个生成模型来模拟组织切片，然后应用一个源自普通最小二乘法 (OLS) 的统计检验。该检验基于 OLS 最小化残差平方和的定义。\n- 我们将脉管系统图视为一个从 CD31 的免疫荧光 (IF) 派生出的二值掩码，并使用每个点到最近血管的欧几里得距离作为协变量来校正氧气供应。\n\n生成过程的数学公式：\n- 考虑一个大小为 $N \\times N$ 的方形网格，代表坐标 $(x_i,y_i)$ 归一化到 $[0,1] \\times [0,1]$ 的 ST 点。令 $i \\in \\{1,\\dots,n\\}$ 为点的索引，其中 $n = N^2$。\n- 为位于生发中心 (GC) 内的点 $i$ 定义一个二值指示变量 $G_i \\in \\{0,1\\}$，其中 GC 被建模为具有固定中心和与 $N$ 成正比的半径的圆形。\n- 令 $V$ 为一个二值掩码，如果网格位置 $(p,q)$ 位于血管上（CD31 的 IF 呈阳性），则 $V_{pq} = 1$，否则 $V_{pq}=0$。定义 $D_i \\ge 0$ 为点 $i$ 到最近血管的欧几里得距离，单位为像素。\n- 点 $i$ 的缺氧分数通过以下公式模拟：\n$$\nH_i \\;=\\; \\beta_0 \\;+\\; \\beta_{\\text{GC}} \\, G_i \\;+\\; \\gamma \\, \\bigl(1 - e^{-D_i/\\lambda}\\bigr) \\;+\\; \\theta_1 x_i \\;+\\; \\theta_2 y_i \\;+\\; \\theta_3 x_i y_i \\;+\\; \\varepsilon_i,\n$$\n其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立误差，$\\gamma \\ge 0$ 控制由血管距离引起的缺氧，$\\lambda > 0$ 是以像素为单位的长度尺度。\n\n用于校正脉管系统和空间趋势的分析模型：\n- 拟合一个 OLS 回归模型，该模型对到血管的距离和一个低阶空间多项式进行校正：\n$$\nH_i \\;=\\; \\alpha_0 \\;+\\; \\alpha_{\\text{GC}} \\, G_i \\;+\\; \\alpha_1 D_i \\;+\\; \\alpha_2 D_i^2 \\;+\\; \\alpha_3 x_i \\;+\\; \\alpha_4 y_i \\;+\\; \\alpha_5 x_i^2 \\;+\\; \\alpha_6 y_i^2 \\;+\\; \\alpha_7 x_i y_i \\;+\\; \\eta_i,\n$$\n其中 $\\eta_i$ 是均值为零的误差。该模型通过 $D_i$ 和 $D_i^2$ 来表示对脉管系统的校正，并通过 $x_i$ 和 $y_i$ 的多项式项来移除广泛的空间趋势。\n- 令 $\\widehat{\\alpha}_{\\text{GC}}$ 为 $\\alpha_{\\text{GC}}$ 的 OLS 估计值。在标准 OLS 假设下，用于检验单侧假设 $H_0: \\alpha_{\\text{GC}} \\le 0$ 与 $H_1: \\alpha_{\\text{GC}} > 0$ 的 $t$-统计量为：\n$$\nt \\;=\\; \\frac{\\widehat{\\alpha}_{\\text{GC}}}{\\widehat{\\mathrm{SE}}(\\widehat{\\alpha}_{\\text{GC}})},\n$$\n其中 $\\widehat{\\mathrm{SE}}(\\widehat{\\alpha}_{\\text{GC}})$ 从估计的残差方差和格拉姆矩阵的逆矩阵获得。单侧 $p$-值为 $p = 1 - F_{t,\\nu}(t)$（当 $t \\ge 0$ 时），以及 $p = 1$（当 $t < 0$ 时），其中 $F_{t,\\nu}$ 是具有 $\\nu = n - p$ 个自由度的学生 t 分布的累积分布函数，$p$ 是拟合参数的数量。\n\n您的任务：\n- 如上所述，实现一个模拟器和分析程序。对于每个测试用例，构建网格，创建 GC 掩码和血管掩码，计算 $D_i$，使用指定参数通过生成模型模拟 $H_i$，拟合分析模型，计算 $H_0: \\alpha_{\\text{GC}} \\le 0$ 的单侧 $p$-值，最后返回一个布尔值，指示 GC 效应是否仍然局域化（在显著性水平 $\\alpha = 0.01$ 下拒绝 $H_0$）。\n- 对于所有测试用例，程序必须使用以下固定的 GC 几何结构：两个圆形 GC，中心位于归一化坐标 $(0.35,0.35)$ 和 $(0.68,0.62)$，半径为 $r = \\lceil r_{\\text{frac}} \\cdot N \\rceil$，其中 $r_{\\text{frac}}$ 是一个指定的分数。如果一个点的中心落在一个或两个圆形内，则该点位于 GC 内部。\n- 血管掩码构建为垂直的血管线：对于整数列索引 $q \\in \\{0,\\dots,N-1\\}$，如果 $q \\bmod s = \\lfloor s/2 \\rfloor$，则对所有的 $p$ 设置 $V_{pq}=1$，其中 $s$ 是指定的血管间距（以像素为单位）。所有其他条目均为 $0$。\n\n所有测试用例中生成模型的固定常量：\n- 使用 $\\beta_0 = 0$。\n- 使用 $(\\theta_1,\\theta_2,\\theta_3) = (0.5,-0.3,0.2)$。\n\n统计决策：\n- 对所有测试用例使用显著性水平 $\\alpha = 0.01$。\n- 为每个测试用例报告一个布尔值：如果 $p < \\alpha$ 则为 $true$，否则为 $false$。\n\n测试套件：\n提供以下参数集的结果。每个测试用例是一个元组 $(N, r_{\\text{frac}}, s, \\beta_{\\text{GC}}, \\gamma, \\lambda, \\sigma, \\text{seed})$：\n- 用例 1：$(35, \\; 0.14, \\; 6, \\; 2.0, \\; 1.5, \\; 4.0, \\; 0.4, \\; 12345)$。\n- 用例 2：$(35, \\; 0.14, \\; 6, \\; 0.0, \\; 1.5, \\; 4.0, \\; 0.4, \\; 23456)$。\n- 用例 3：$(35, \\; 0.14, \\; 4, \\; 1.5, \\; 3.0, \\; 2.0, \\; 0.5, \\; 34567)$。\n- 用例 4：$(25, \\; 0.16, \\; 5, \\; 0.05, \\; 1.5, \\; 3.0, \\; 2.0, \\; 45678)$。\n- 用例 5：$(35, \\; 0.14, \\; 6, \\; -0.8, \\; 1.5, \\; 4.0, \\; 0.4, \\; 56789)$。\n\n输出规格：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[true,false,true,false,true]\"）。该列表必须包含与上述五个用例按顺序列出的 5 个布尔值。\n- 不涉及物理单位或角度单位。不要打印任何额外的文本。", "solution": "我们将生物学问题形式化为一个基于第一性原理的统计假设检验。从生理学角度看，氧张力随与血管距离的增加而降低；因此，缺氧基因的表达随与脉管系统距离的增加而增加。空间转录组学 (ST) 为每个点提供缺氧特征分数，而 CD31 的免疫荧光 (IF) 则产生一个二值血管掩码。由于细胞密度高和代谢需求大，生发中心 (GCs) 被假设为缺氧微环境；我们想知道缺氧特征是否独立于脉管系统而局限在 GC 内。\n\n模拟是在一个大小为 $N \\times N$ 的方形网格上定义的。每个点 $i$ 的归一化坐标为 $(x_i,y_i) \\in [0,1]^2$。两个圆形生发中心 (GCs) 由中心点 $(0.35,0.35)$ 和 $(0.68,0.62)$ 以及半径 $r = \\lceil r_{\\text{frac}} N \\rceil$（以像素为单位）定义。如果一个点位于至少一个 GC 内，则 GC 指示变量 $G_i$ 等于 $1$，否则等于 $0$。\n\n脉管系统掩码被构建为垂直线：取一个以像素为单位的间距参数 $s$，并将索引为 $q$ 且满足 $q \\bmod s = \\lfloor s/2 \\rfloor$ 的列中的所有位置设为血管（$V_{pq}=1$），其他位置设为非血管（$V_{pq}=0$）。距离 $D_i$ 是从点 $i$ 到最近血管的欧几里得距离，通过欧几里得距离变换计算得出。这在离散网格上是良定义的，并近似于切片中的物理距离。\n\n缺氧分数的生成模型为：\n$$\nH_i \\;=\\; \\beta_0 \\;+\\; \\beta_{\\text{GC}} \\, G_i \\;+\\; \\gamma \\, \\bigl(1 - e^{-D_i/\\lambda}\\bigr) \\;+\\; \\theta_1 x_i \\;+\\; \\theta_2 y_i \\;+\\; \\theta_3 x_i y_i \\;+\\; \\varepsilon_i,\n$$\n其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 为独立噪声，$\\beta_0 = 0$，$(\\theta_1,\\theta_2,\\theta_3) = (0.5, -0.3, 0.2)$，以及 $(\\beta_{\\text{GC}},\\gamma,\\lambda,\\sigma)$ 按每个测试用例指定。项 $\\gamma(1 - e^{-D_i/\\lambda})$ 捕捉了缺氧随与血管距离的单调增加，是一个简单的、受扩散-反应启发的、具有生物学合理性的变换。空间多项式项移除了由于批次或解剖学梯度而在组织切片中经常观察到的粗略空间趋势。\n\n我们通过使用普通最小二乘法 (OLS) 回归来校正脉管系统和空间趋势进行分析：\n$$\nH_i \\;=\\; \\alpha_0 \\;+\\; \\alpha_{\\text{GC}} \\, G_i \\;+\\; \\alpha_1 D_i \\;+\\; \\alpha_2 D_i^2 \\;+\\; \\alpha_3 x_i \\;+\\; \\alpha_4 y_i \\;+\\; \\alpha_5 x_i^2 \\;+\\; \\alpha_6 y_i^2 \\;+\\; \\alpha_7 x_i y_i \\;+\\; \\eta_i.\n$$\nOLS 源自最小二乘法的核心定义：选择参数以最小化 $\\sum_{i=1}^{n} (H_i - \\widehat{H}_i)^2$，这会产生正规方程 $X^\\top X \\widehat{\\alpha} = X^\\top H$，当 $X^\\top X$ 可逆时，其解为 $\\widehat{\\alpha} = (X^\\top X)^{-1} X^\\top H$。这里 $X$ 是设计矩阵，其列对应于截距、$G_i$、$D_i$、$D_i^2$、$x_i$、$y_i$、$x_i^2$、$y_i^2$、$x_i y_i$。\n\n我们通过检验单侧假设 $H_0: \\alpha_{\\text{GC}} \\le 0$ 与 $H_1: \\alpha_{\\text{GC}} > 0$ 来量化校正后的局域化程度。在标准 OLS 假设下，$t$-统计量的抽样分布\n$$\nt \\;=\\; \\frac{\\widehat{\\alpha}_{\\text{GC}}}{\\widehat{\\mathrm{SE}}(\\widehat{\\alpha}_{\\text{GC}})}\n$$\n遵循自由度为 $\\nu = n - p$ 的学生 t 分布，其中 $p$ 是拟合参数的数量。标准误由估计的残差方差 $\\widehat{\\sigma}^2 = \\frac{1}{\\nu}\\sum_{i=1}^{n} \\widehat{\\eta}_i^2$ 以及与 $G_i$ 系数对应的 $(X^\\top X)^{-1}$ 的 $(2,2)$ 项派生而来：\n$$\n\\widehat{\\mathrm{SE}}(\\widehat{\\alpha}_{\\text{GC}}) \\;=\\; \\sqrt{\\widehat{\\sigma}^2 \\,\\left[(X^\\top X)^{-1}\\right]_{(G,G)}}.\n$$\n单侧 $p$-值计算如下：如果 $t \\ge 0$，则 $p = 1 - F_{t,\\nu}(t)$；否则 $p=1$。\n\n决策规则：在显著性水平 $\\alpha = 0.01$下，如果 $p < \\alpha$，我们拒绝 $H_0$（并宣布在校正后缺氧仍然局限于 GCs）。这编码了免疫学假设，即 GCs 表现出超出由邻近脉管系统和广泛空间趋势所能解释的升高的缺氧特征。\n\n每个测试用例的算法步骤：\n1. 构建 $N \\times N$ 网格和归一化坐标数组 $(x_i,y_i)$。\n2. 使用两个固定中心和半径 $r = \\lceil r_{\\text{frac}} N \\rceil$ 构建 GC 掩码；相应地分配 $G_i$。\n3. 使用间距 $s$ 构建血管掩码；计算欧几里得距离变换以获得 $D_i$。\n4. 使用指定的参数和固定的随机种子从生成模型生成 $H_i$ 以确保可复现性。\n5. 构建设计矩阵 $X$ 和响应向量 $H$；通过求解正规方程拟合 OLS，计算残差方差、标准误、t-统计量和单侧 p-值。\n6. 如果 $p < 0.01$ 则返回 $true$，否则返回 $false$。\n\n测试覆盖范围的基本原理：\n- 用例 1（理想路径）：强的正 GC 效应、中等的血管效应和低噪声应导致拒绝 ($true$)。\n- 用例 2（零假设）：零 GC 效应不应显著 ($false$)。\n- 用例 3（潜在混淆）：强的血管效应和更密集的血管会增加混淆，但在校正后，强的正 GC 效应应仍然显著 ($true$)。\n- 用例 4（低信号、高噪声、较小网格）：非常小的正 GC 效应和高噪声不应显著 ($false$)。\n- 用例 5（负效应）：用于检验正性的单侧检验不应拒绝 ($false$)。\n\n程序必须输出单行：一个按用例顺序排列的包含五个布尔值的列表。", "answer": "```python\nimport numpy as np\nfrom scipy import ndimage\nfrom scipy.stats import t as student_t\n\ndef make_grid(N):\n    # Normalized coordinates in [0,1]\n    y_idx, x_idx = np.indices((N, N))\n    x = (x_idx + 0.5) / N\n    y = (y_idx + 0.5) / N\n    return x, y\n\ndef make_gc_mask(N, r_frac):\n    # Two circular GCs with fixed centers in normalized coordinates\n    centers = [(0.35, 0.35), (0.68, 0.62)]\n    x, y = make_grid(N)\n    gc_mask = np.zeros((N, N), dtype=bool)\n    r = int(np.ceil(r_frac * N))\n    r2 = (r / N) ** 2  # radius in normalized coordinate squared\n    for cx, cy in centers:\n        dist2 = (x - cx) ** 2 + (y - cy) ** 2\n        gc_mask |= dist2 <= r2\n    return gc_mask\n\ndef make_vessel_mask(N, spacing):\n    # Vertical vessel lines: columns where q % spacing == spacing//2\n    mask = np.zeros((N, N), dtype=bool)\n    col_indices = np.arange(N)\n    vessel_cols = (col_indices % spacing) == (spacing // 2)\n    mask[:, vessel_cols] = True\n    return mask\n\ndef distance_to_vessels(vessel_mask):\n    # Euclidean distance transform: distance from False to nearest True\n    # For spots on a vessel, distance is zero.\n    inv_mask = ~vessel_mask\n    dist = ndimage.distance_transform_edt(inv_mask)\n    return dist\n\ndef simulate_hypoxia(N, r_frac, spacing, beta_gc, gamma, lam, sigma, seed):\n    # Build masks and covariates\n    x, y = make_grid(N)\n    gc_mask = make_gc_mask(N, r_frac)\n    vessel_mask = make_vessel_mask(N, spacing)\n    D = distance_to_vessels(vessel_mask)\n\n    # Flatten all arrays\n    x_f = x.ravel()\n    y_f = y.ravel()\n    G_f = gc_mask.ravel().astype(float)\n    D_f = D.ravel().astype(float)\n\n    # Generative parameters\n    beta0 = 0.0\n    theta1, theta2, theta3 = 0.5, -0.3, 0.2\n\n    # Random noise\n    rng = np.random.default_rng(seed)\n    eps = rng.normal(loc=0.0, scale=sigma, size=N*N)\n\n    # Hypoxia signal\n    # Use transform (1 - exp(-D/lam)), with lam in pixel units (same as D)\n    H = (beta0\n         + beta_gc * G_f\n         + gamma * (1.0 - np.exp(-D_f / lam))\n         + theta1 * x_f\n         + theta2 * y_f\n         + theta3 * x_f * y_f\n         + eps)\n    return H, G_f, D_f, x_f, y_f\n\ndef ols_t_test_gc(H, G, D, x, y):\n    n = H.shape[0]\n    # Design matrix columns:\n    # 0: intercept\n    # 1: GC indicator\n    # 2: D\n    # 3: D^2\n    # 4: x\n    # 5: y\n    # 6: x^2\n    # 7: y^2\n    # 8: x*y\n    X = np.column_stack([\n        np.ones(n),\n        G,\n        D,\n        D**2,\n        x,\n        y,\n        x**2,\n        y**2,\n        x * y\n    ])\n    p = X.shape[1]\n    # OLS via normal equations\n    XTX = X.T @ X\n    # Use pseudo-inverse for numerical stability\n    XTX_inv = np.linalg.pinv(XTX, rcond=1e-12)\n    beta_hat = XTX_inv @ (X.T @ H)\n    resid = H - X @ beta_hat\n    df = n - p\n    rss = float(resid.T @ resid)\n    s2 = rss / df\n    cov_hat = s2 * XTX_inv\n    # Index of GC coefficient is 1\n    se_gc = np.sqrt(max(cov_hat[1, 1], 0.0))\n    beta_gc_hat = beta_hat[1]\n    # Guard against zero standard error (degenerate)\n    if se_gc == 0.0:\n        # If no variability, set t to 0 (no evidence)\n        t_stat = 0.0\n    else:\n        t_stat = beta_gc_hat / se_gc\n    # One-sided p-value for H1: alpha_GC > 0\n    if t_stat <= 0:\n        pval = 1.0\n    else:\n        pval = 1.0 - student_t.cdf(t_stat, df)\n    return pval\n\ndef analyze_case(params):\n    N, r_frac, spacing, beta_gc, gamma, lam, sigma, seed = params\n    H, G, D, x, y = simulate_hypoxia(N, r_frac, spacing, beta_gc, gamma, lam, sigma, seed)\n    pval = ols_t_test_gc(H, G, D, x, y)\n    # Decision at alpha = 0.01\n    return pval < 0.01\n\ndef solve():\n    # Define the test cases as specified\n    test_cases = [\n        (35, 0.14, 6, 2.0, 1.5, 4.0, 0.4, 12345),\n        (35, 0.14, 6, 0.0, 1.5, 4.0, 0.4, 23456),\n        (35, 0.14, 4, 1.5, 3.0, 2.0, 0.5, 34567),\n        (25, 0.16, 5, 0.05, 1.5, 3.0, 2.0, 45678),\n        (35, 0.14, 6, -0.8, 1.5, 4.0, 0.4, 56789),\n    ]\n\n    results = []\n    for case in test_cases:\n        decision = analyze_case(case)\n        results.append(decision)\n\n    # Print in the exact required format: lowercase booleans\n    # Convert Python True/False to 'true'/'false'\n    out = \"[\" + \",\".join(\"true\" if r else \"false\" for r in results) + \"]\"\n    print(out)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2890183"}]}