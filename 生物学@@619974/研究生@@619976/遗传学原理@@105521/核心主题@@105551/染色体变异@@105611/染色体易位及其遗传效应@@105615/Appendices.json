{"hands_on_practices": [{"introduction": "在遗传学中，精确的沟通至关重要。国际人类细胞遗传学命名系统 (International System for Human Cytogenomic Nomenclature, ISCN) 是描述染色体异常的标准化语言，如同遗传咨询和研究中的“语法”。本练习旨在训练您一项基本技能：解读一个典型易位的ISCN命名，即与慢性粒细胞白血病相关的费城染色体易位。通过这个练习，您将理解一行简洁的符号是如何精确描述一个复杂的、具有重大临床意义的分子事件的。[@problem_id:2798391]", "problem": "一个体细胞核型写作 $46,XY,t(9;22)(q34;q11.2)$。根据国际人类细胞遗传学命名系统 (ISCN) 的规则，以及衍生染色体 $der(n)$ 是保留了 $n$ 号染色体着丝粒的结构重排染色体这一定义，请解读此表示法，以判断哪条衍生染色体是 $der(9)$ 和 $der(22)$，并确定哪个基因座重新定位到哪条衍生染色体上。假设断裂点发生在 $9q34$ 上的 $ABL1$ 基因座和 $22q11.2$ 上的 $BCR$（断裂点簇集区）基因座内，并且断裂点远端的片段发生了相互交换，没有发生其他额外的重排。\n\n哪个选项正确地指出了 $der(9)$ 和 $der(22)$ 的身份以及 $ABL1$ 和 $BCR$ 的重新定位情况？\n\nA. $der(22)$（费城染色体）携带来自 $q34$ 的 $9q$ 远端片段（包括 $ABL1$），而 $der(9)$ 携带来自 $q11.2$ 的 $22q$ 远端片段（包括 $BCR$）；因此 $ABL1$ 重新定位到 $der(22)$，$BCR$ 重新定位到 $der(9)$。\n\nB. $der(9)$（费城染色体）携带来自 $q34$ 的 $9q$ 远端片段（包括 $ABL1$），而 $der(22)$ 携带来自 $q11.2$ 的 $22q$ 远端片段（包括 $BCR$）；因此 $ABL1$ 重新定位到 $der(9)$，$BCR$ 重新定位到 $der(22)$。\n\nC. $ABL1$ 和 $BCR$ 都重新定位到 $der(22)$，使得 $der(9)$ 上没有任何与断裂点相关的基因座。\n\nD. $(q34;q11.2)$ 处的断裂点不影响 $ABL1$ 或 $BCR$，因为它们位于 $p$ 臂上；两个基因都保留在它们原来的染色体上，没有发生重新定位。\n\nE. $der(22)$ 在 $22q11.2$ 处保留了 $BCR$ 且未获得 $ABL1$ 序列，而 $ABL1$ 重新定位到 $der(9)$；因此 $BCR$ 没有移动，而 $ABL1$ 移动到了 $9$ 号染色体。", "solution": "在尝试解答之前，必须首先严格验证问题陈述的科学合理性和一致性。\n\n### 步骤1：提取已知信息\n该问题提供了以下信息：\n-   体细胞核型：$46,XY,t(9;22)(q34;q11.2)$\n-   命名系统：国际人类细胞遗传学命名系统 (ISCN)\n-   衍生染色体的定义：$der(n)$ 是保留了 $n$ 号染色体着丝粒的结构重排染色体。\n-   断裂点位置：断裂点发生在 $9q34$ 上的 $ABL1$ 基因座和 $22q11.2$ 上的 $BCR$（断裂点簇集区）基因座内。\n-   易位机制：断裂点远端的片段发生了相互交换。\n-   约束条件：没有发生其他额外的重排。\n\n### 步骤2：使用提取的已知信息进行验证\n根据既定标准对问题陈述进行评估：\n-   **科学依据：** 该问题描述了 $t(9;22)(q34;q11.2)$ 相互易位，这是一种有充分文献记载的细胞遗传学畸变，它导致了费城染色体的形成。$ABL1$ 和 $BCR$ 基因被正确定位到这些染色体带上。ISCN 命名法和衍生染色体的定义在人类遗传学中是标准规范。整个前提在事实上是正确的，并基于细胞遗传学的基本原理。\n-   **适定性：** 该问题提供了推导最终衍生染色体结构所需的所有必要信息。核型已指定，断裂点已确定，交换机制被定义为相互交换，并且给出了衍生染色体的命名规则。这使得推导出唯一且明确的解决方案成为可能。\n-   **客观性：** 该问题使用了精确、标准且无偏见的科学语言。没有主观或模棱可可的术语。\n\n问题陈述没有显示任何缺陷。它在科学上不是不合理的、不完整的、矛盾的或非适定的。这是医学遗传学中一个标准的、正式的问题。\n\n### 步骤3：结论与行动\n问题有效。现在将推导解决方案。\n\n### 推导过程\n给定的核型是 $46,XY,t(9;22)(q34;q11.2)$。必须解构此表示法。\n1.  $46,XY$：表示一个男性个体共有 46 条染色体。这是体细胞背景。\n2.  $t(9;22)$：表示 9 号染色体和 22 号染色体之间发生了易位（$t$）。\n3.  $(q34;q11.2)$：指明了断裂点。9 号染色体的断裂发生在长臂（$q$）的 $34$ 带。22 号染色体的断裂发生在长臂（$q$）的 $11.2$ 带。\n\n该易位被描述为“断裂点远端片段的相互交换”。这意味着：\n-   9 号染色体在 $9q34$ 处断裂。从该断裂点到长臂端粒的片段（$9q$ 远端片段）被交换。\n-   22 号染色体在 $22q11.2$ 处断裂。从该断裂点到长臂端粒的片段（$22q$ 远端片段）被交换。\n\n由此产生的重排染色体被称为衍生染色体（$der$）。根据所提供的定义，$der(n)$ 保留了原始 $n$ 号染色体的着丝粒。\n-   **$der(9)$**：这条染色体由 9 号染色体完整的短臂（$p$）和着丝粒，加上其长臂近端部分直到 $9q34$ 断裂点组成。22 号染色体 $22q11.2$ 远端的片段连接到这个断裂点上。因此，$der(9)$ 的结构是 $(9\\text{pter} \\rightarrow 9q34)::(22q11.2 \\rightarrow 22\\text{qter})$。\n-   **$der(22)$**：这条染色体由 22 号染色体完整的短臂（$p$）和着丝粒，加上其长臂近端部分直到 $22q11.2$ 断裂点组成。9 号染色体 $9q34$ 远端的片段连接到这个断裂点上。因此，$der(22)$ 的结构是 $(22\\text{pter} \\rightarrow 22q11.2)::(9q34 \\rightarrow 9\\text{qter})$。$der(22)$ 是两条衍生染色体中明显较小的一条，在历史上被称为费城染色体。\n\n现在，我们必须考虑基因的位置。\n-   $ABL1$ 基因位于 $9q34$。断裂点就在这个基因内部。$9q34$ 远端的片段包含了 $ABL1$ 编码序列的大部分。这个片段易位到了 22 号染色体上。因此，$ABL1$ 序列重新定位到了 $der(22)$ 上。\n-   $BCR$ 基因位于 $22q11.2$。断裂点就在这个基因内部。$22q11.2$ 远端的片段包含了 $BCR$ 基因的远端部分。这个片段易位到了 9 号染色体上。因此，来自 $BCR$ 基因座的序列重新定位到了 $der(9)$ 上。\n\n这种易位在医学上的重要后果是在 $der(22)$（费城染色体）上形成了一个新的融合基因 $BCR-ABL1$。这是当（保留在 $der(22)$ 骨架上的）$BCR$ 基因的近端部分与易位过来的 $ABL1$ 基因的远端部分融合时发生的。\n\n### 逐项分析选项\n\n**A. $der(22)$（费城染色体）携带来自 $q34$ 的 $9q$ 远端片段（包括 $ABL1$），而 $der(9)$ 携带来自 $q11.2$ 的 $22q$ 远端片段（包括 $BCR$）；因此 $ABL1$ 重新定位到 $der(22)$，$BCR$ 重新定位到 $der(9)$。**\n-   $der(22)$ 被正确地识别为费城染色体。\n-   它正确地指出 $der(22)$ 携带含有 $ABL1$ 序列的 $9q$ 远端片段。\n-   它正确地指出 $der(9)$ 携带 $22q$ 远端片段，该片段包含 $BCR$ 基因座的一部分。\n-   $ABL1$ 重新定位到 $der(22)$ 且 $BCR$（或其一部分）重新定位到 $der(9)$ 的结论是相互易位的直接且准确的结果。\n-   **结论：正确。**\n\n**B. $der(9)$（费城染色体）携带来自 $q34$ 的 $9q$ 远端片段（包括 $ABL1$），而 $der(22)$ 携带来自 $q11.2$ 的 $22q$ 远端片段（包括 $BCR$）；因此 $ABL1$ 重新定位到 $der(9)$，$BCR$ 重新定位到 $der(22)$。**\n-   该选项错误地将 $der(9)$ 识别为费城染色体。费城染色体是 $der(22)$。这个初始错误使整个陈述无效。\n-   **结论：不正确。**\n\n**C. $ABL1$ 和 $BCR$ 都重新定位到 $der(22)$，使得 $der(9)$ 上没有任何与断裂点相关的基因座。**\n-   这描述了一个复杂的或非相互的事件，与问题陈述中指定的“相互交换”相矛盾。在相互易位中，$der(9)$ 必须接收来自 22 号染色体的片段，该片段包含 $BCR$ 基因的一部分。\n-   **结论：不正确。**\n\n**D. $(q34;q11.2)$ 处的断裂点不影响 $ABL1$ 或 $BCR$，因为它们位于 $p$ 臂上；两个基因都保留在它们原来的染色体上，没有发生重新定位。**\n-   表示法 $q34$ 和 $q11.2$ 明确指的是长臂（$q$），而不是短臂（$p$）。\n-   问题陈述指出断裂点位于 $ABL1$ 和 $BCR$ 基因座 *内部*，这直接反驳了它们不受影响的说法。\n-   **结论：不正确。**\n\n**E. $der(22)$ 在 $22q11.2$ 处保留了 $BCR$ 且未获得 $ABL1$ 序列，而 $ABL1$ 重新定位到 $der(9)$；因此 $BCR$ 没有移动，而 $ABL1$ 移动到了 $9$ 号染色体。**\n-   这个陈述是一连串的错误。$der(22)$ *确实* 获得了 $ABL1$ 序列；这是中心事件。$ABL1$ 重新定位到 $der(22)$，而不是 $der(9)$。$BCR$ 基因被断裂，所以说它“没有移动”是错误的；其远端部分移动到了 $der(9)$。最后一句“$ABL1$ 移动到了 9 号染色体”是无意义的，因为它本来就起源于 9 号染色体。\n-   **结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "2798391"}, {"introduction": "掌握了如何描述易位之后，下一步是预测其遗传后果。对于平衡易位的携带者而言，其主要风险在于减数分裂过程中可能产生遗传物质不平衡的配子，从而导致后代出现严重的健康问题。本练习将让您扮演一位遗传咨询师的角色，您需要运用概率推理和给定的经验数据，为一名罗伯逊易位携带者计算其生育唐氏综合征患儿的风险。这个实践将抽象的减数分裂机制与具体的临床风险评估联系起来。[@problem_id:2798339]", "problem": "一位携带染色体 14 和 21 之间罗伯逊易位（记作 $rob(14;21)$）的女性，通过三价体配对和分离产生减数分裂产物。假设其伴侣核型正常，受精相对于配子类别是随机发生的，且合子后存活至活产仅取决于合子核型。请使用以下经验支持的假设：\n\n- 在 $rob(14;21)$ 的卵子发生过程中，三价体取向导致两种分离模式：交互分离和邻近分离。交互分离的概率为 $0.72$，邻近分离的概率为 $0.28$。\n- 与正常精子受精后，交互分离产生细胞遗传学正常的或平衡易位的合子（两者对于21号染色体均为整倍体），而邻近分离则产生不平衡的受孕体，即 $21$三体或 $21$单体。\n- 在邻近分离类别中，两种不平衡的结果（$21$三体和 $21$单体）出现的频率相等。\n- 一个 $21$三体受孕体存活至活产的概率为 $0.30$；一个 $21$单体受孕体存活至活产的概率为 $0$。\n\n仅使用罗伯逊易位中的减数分裂分离原理和基本概率，计算这位 $rob(14;21)$ 女性携带者每次受孕产下患有 $21$三体综合征活婴的无条件风险。请将您的答案以小数形式表示，并四舍五入到四位有效数字。", "solution": "题目陈述已经过评估并被确定为有效。它在科学上基于人类遗传学原理，提法恰当、客观，并包含得出唯一解所需的所有信息。我们将继续进行计算。\n\n目标是计算每次受孕产下患有 $21$三体综合征活婴的无条件风险。这个风险是一系列概率事件的结果。让我们根据所提供的数据定义相关事件及其概率。\n\n设 $A$ 为卵子发生过程中的交互分离事件。题目陈述其概率为：\n$$ P(A) = 0.72 $$\n设 $B$ 为邻近分离事件。其概率为：\n$$ P(B) = 0.28 $$\n这些概率之和为 $P(A) + P(B) = 0.72 + 0.28 = 1$，这与题目陈述一致。\n\n患有 $21$三体综合征的受孕体仅由邻近分离产生。在邻近分离产物类别中，与正常配子受精后有两种可能的不平衡结果会导致非整倍体合子：一种导致 $21$三体，另一种导致 $21$单体。题目陈述这两种情况频率相等。\n设 $T_{21}$ 为受孕体为 $21$三体的事件。设 $M_{21}$ 为受孕体为 $21$单体的事件。在邻近分离（$B$）发生的条件下，条件概率为：\n$$ P(T_{21} | B) = 0.5 $$\n$$ P(M_{21} | B) = 0.5 $$\n交互分离（$A$）导致整倍体受孕（核型正常或平衡易位携带者），因此在交互分离发生的条件下，$21$三体受孕的概率为零：\n$$ P(T_{21} | A) = 0 $$\n\n受孕体为 $21$三体的总概率 $P(T_{21})$，可以使用全概率定律计算：\n$$ P(T_{21}) = P(T_{21} | A) P(A) + P(T_{21} | B) P(B) $$\n代入给定值：\n$$ P(T_{21}) = (0 \\times 0.72) + (0.5 \\times 0.28) $$\n$$ P(T_{21}) = 0 + 0.14 $$\n$$ P(T_{21}) = 0.14 $$\n这是任何一次受孕形成 $21$三体合子的概率。\n\n题目要求的是产下*活婴*的风险。这包含了合子后的存活概率。设 $S_{T21}$ 为 $21$三体受孕体存活至活产的事件。题目给出此概率为：\n$$ P(S_{T21} | T_{21}) = 0.30 $$\n我们被要求计算产下患有 $21$三体综合征活婴的无条件概率。这对应于受孕体为 $21$三体*并且*该受孕体存活至活产的联合概率。这记作 $P(T_{21} \\cap S_{T21})$。\n使用条件概率的定义，$P(T_{21} \\cap S_{T21}) = P(S_{T21} | T_{21}) \\times P(T_{21})$。\n\n我们已具备最终计算所需的所有要素：\n$$ P(\\text{21三体活产}) = P(S_{T21} | T_{21}) \\times P(T_{21}) $$\n代入已计算和给定的值：\n$$ P(\\text{21三体活产}) = 0.30 \\times 0.14 $$\n$$ P(\\text{21三体活产}) = 0.042 $$\n\n题目要求答案以小数形式表示，并四舍五入到四位有效数字。计算出的值 $0.042$ 有两位有效数字。为将其表示为四位有效数字，我们在后面追加两个零。\n$$ 0.04200 $$\n这是最终答案。这位女性携带者每次受孕产下患有 $21$三体综合征活婴的无条件风险为 $4.2\\%$。", "answer": "$$\n\\boxed{0.04200}\n$$", "id": "2798339"}, {"introduction": "前面的练习关注了易位的描述及其后果，而本练习将视角转向其起源：为什么染色体断裂在基因组的某些位置比其他位置更频繁？染色体的“脆弱性”并非随机分布，而是与特定的基因组特征（如GC含量和复制时间）相关。本练习将带您进入计算基因组学的前沿，通过构建一个逻辑回归模型来预测潜在的断裂点热点。这项实践不仅能加深您对易位生物学基础的理解，也体现了现代遗传学研究融合生物学、统计学和计算科学的跨学科特点。[@problem_id:2798351]", "problem": "当脱氧核糖核酸（DNA）中的双链断裂被错误修复，导致非同源染色体连接在一起时，就会发生染色体易位。断裂点的空间分布是不均匀的，并且根据经验与分子特征相关，例如鸟嘌呤-胞嘧啶（GC）含量、复制时间、基因密度和 RNA-DNA 杂合链环（R-loop）的形成倾向。考虑将一个基因组区间是否包含易位断裂点建模为一个由这些特征驱动的二元结果。\n\n假设基因组被划分为由 $i \\in \\{1,\\dots,n\\}$ 索引的区间。对每个区间 $i$，定义一个包含显式截距项的特征向量 $\\mathbf{x}_i \\in \\mathbb{R}^5$，$\\mathbf{x}_i = (1, x_{i1}, x_{i2}, x_{i3}, x_{i4})$，其中：\n- $x_{i1}$ 是 GC 含量，以 $[0,1]$ 内的分数表示，\n- $x_{i2}$ 是复制时间，以 S 期的分数表示，在 $[0,1]$ 范围内（值越大表示复制越早），\n- $x_{i3}$ 是基因密度，表示为区间内编码碱基的比例，在 $[0,1]$ 范围内，\n- $x_{i4}$ 是 R-loop 倾向性，以 $[0,1]$ 内的分数表示。\n\n令 $y_i \\in \\{0,1\\}$ 表示区间 $i$ 是否包含一个已确认的易位断裂点。假设在给定特征的条件下，$y_i$ 是来自成功概率为 $p_i$ 的伯努利分布的独立抽样，并使用带有 logit 链接函数的广义线性模型（GLM），使得对数优势比（log-odds）是特征的线性函数。从这些假设和伯努利试验的独立性出发，推导在强度为 $\\lambda \\ge 0$ 的不惩罚截距项的 $\\ell_2$（岭）惩罚下，系数 $\\boldsymbol{\\beta} \\in \\mathbb{R}^5$ 的惩罚最大似然估计量。您的推导必须从伯努利似然和 logit 链接的定义开始，并得出一个可计算的目标函数及其梯度，以适用于数值优化。\n\n然后实现一个程序：\n- 通过最小化下面每个独立训练集的负惩罚对数似然来拟合系数 $\\boldsymbol{\\beta}$，\n- 在每种情况下，为指定的单区间特征向量 $\\mathbf{x}_\\star$ 计算预测的断裂点概率 $\\hat{p}_\\star$，\n- 仅使用通用数值优化器或您自己的基于梯度的求解器（不调用黑盒机器学习模型），\n- 在 $\\ell_2$ 项中将截距视为未惩罚。\n\n您的实现应该是确定性的和数值稳定的。\n\n测试套件：\n对于每个案例，训练设计矩阵以 $(x_{i1}, x_{i2}, x_{i3}, x_{i4})$ 的行形式给出，并带有一个隐式截距。所有特征都是无单位的分数。结果标签为 $y_i \\in \\{0,1\\}$。正则化强度 $\\lambda$ 按案例给出。对于每个案例，在训练后，为给定的 $\\mathbf{x}_\\star$ 计算标量预测概率 $\\hat{p}_\\star$。\n\n- 案例 A（通用，混合信号）：\n  - 训练特征 $(x_{i1}, x_{i2}, x_{i3}, x_{i4})$ 和标签：\n    1. $(0.40, 0.70, 0.10, 0.30) \\rightarrow y_1 = 1$\n    2. $(0.35, 0.20, 0.05, 0.10) \\rightarrow y_2 = 0$\n    3. $(0.55, 0.80, 0.20, 0.40) \\rightarrow y_3 = 1$\n    4. $(0.60, 0.65, 0.25, 0.50) \\rightarrow y_4 = 1$\n    5. $(0.30, 0.30, 0.08, 0.12) \\rightarrow y_5 = 0$\n    6. $(0.45, 0.50, 0.12, 0.20) \\rightarrow y_6 = 0$\n    7. $(0.70, 0.85, 0.30, 0.60) \\rightarrow y_7 = 1$\n    8. $(0.38, 0.40, 0.09, 0.18) \\rightarrow y_8 = 0$\n    9. $(0.52, 0.75, 0.22, 0.45) \\rightarrow y_9 = 1$\n    10. $(0.48, 0.55, 0.14, 0.22) \\rightarrow y_{10} = 0$\n    11. $(0.62, 0.78, 0.26, 0.55) \\rightarrow y_{11} = 1$\n    12. $(0.33, 0.35, 0.07, 0.15) \\rightarrow y_{12} = 0$\n  - 正则化：$\\lambda = 1.0$\n  - 为 $\\mathbf{x}_\\star = (0.50, 0.60, 0.15, 0.25)$ 进行预测。\n\n- 案例 B（近可分边缘案例；强正则化）：\n  - 训练特征和标签：\n    1. $(0.80, 0.90, 0.35, 0.70) \\rightarrow y_1 = 1$\n    2. $(0.78, 0.88, 0.34, 0.65) \\rightarrow y_2 = 1$\n    3. $(0.20, 0.15, 0.03, 0.05) \\rightarrow y_3 = 0$\n    4. $(0.22, 0.18, 0.04, 0.06) \\rightarrow y_4 = 0$\n    5. $(0.82, 0.92, 0.36, 0.72) \\rightarrow y_5 = 1$\n    6. $(0.18, 0.12, 0.02, 0.04) \\rightarrow y_6 = 0$\n    7. $(0.25, 0.20, 0.05, 0.08) \\rightarrow y_7 = 0$\n    8. $(0.77, 0.86, 0.33, 0.60) \\rightarrow y_8 = 1$\n  - 正则化：$\\lambda = 10.0$\n  - 为 $\\mathbf{x}_\\star = (0.75, 0.85, 0.32, 0.58)$ 进行预测。\n\n- 案例 C（平衡，中等信号；弱正则化）：\n  - 训练特征和标签：\n    1. $(0.50, 0.50, 0.12, 0.30) \\rightarrow y_1 = 1$\n    2. $(0.47, 0.48, 0.11, 0.28) \\rightarrow y_2 = 0$\n    3. $(0.53, 0.52, 0.13, 0.31) \\rightarrow y_3 = 1$\n    4. $(0.40, 0.45, 0.09, 0.20) \\rightarrow y_4 = 0$\n    5. $(0.60, 0.60, 0.15, 0.35) \\rightarrow y_5 = 1$\n    6. $(0.42, 0.46, 0.10, 0.22) \\rightarrow y_6 = 0$\n    7. $(0.58, 0.58, 0.14, 0.34) \\rightarrow y_7 = 1$\n    8. $(0.45, 0.47, 0.10, 0.24) \\rightarrow y_8 = 0$\n  - 正则化：$\\lambda = 0.1$\n  - 为 $\\mathbf{x}_\\star = (0.55, 0.56, 0.13, 0.33)$ 进行预测。\n\n最终输出规范：\n您的程序应生成单行输出，其中包含三个预测概率，以逗号分隔的列表形式并用方括号括起来，顺序为案例 A、案例 B、案例 C。每个概率必须四舍五入到恰好 $6$ 位小数。例如，输出格式必须与 $[\\hat{p}_A,\\hat{p}_B,\\hat{p}_C]$ 完全一样，没有空格，其中每个 $\\hat{p}$ 是一个小数点后有 $6$ 位数字的十进制字符串。", "solution": "该问题要求为一个逻辑回归模型推导其惩罚最大似然估计量，该模型使用 $\\ell_2$ 惩罚（岭回归）且不对截距项进行惩罚。在此推导之后，必须提供一个实现来将此模型拟合到给定的数据集并计算预测。\n\n让我们从正式推导开始。\n\n**1. 模型设定**\n\n第 $i$ 个基因组区间的结果变量 $y_i$ 是一个二元指标，$y_i \\in \\{0, 1\\}$。我们假设它在给定特征向量 $\\mathbf{x}_i$ 的条件下服从伯努利分布。\n$$\ny_i | \\mathbf{x}_i \\sim \\text{Bernoulli}(p_i)\n$$\n成功概率 $p_i = P(y_i=1 | \\mathbf{x}_i)$ 使用带有 logit 链接函数的广义线性模型（GLM）进行建模。区间 $i$ 的特征向量为 $\\mathbf{x}_i = (1, x_{i1}, x_{i2}, x_{i3}, x_{i4})^T \\in \\mathbb{R}^5$，系数向量为 $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^T \\in \\mathbb{R}^5$。\n\nlogit 链接函数将概率 $p_i$ 与特征的线性组合关联起来：\n$$\n\\text{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right) = \\mathbf{x}_i^T \\boldsymbol{\\beta}\n$$\n链接函数的逆函数，即 sigmoid 函数 $\\sigma(z) = \\frac{1}{1+e^{-z}}$，给出了概率 $p_i$：\n$$\np_i = \\sigma(\\mathbf{x}_i^T \\boldsymbol{\\beta}) = \\frac{1}{1 + e^{-\\mathbf{x}_i^T \\boldsymbol{\\beta}}}\n$$\n\n**2. 似然函数**\n\n单个伯努利观测值 $y_i$ 的概率质量函数为：\n$$\nP(y_i | \\mathbf{x}_i, \\boldsymbol{\\beta}) = p_i^{y_i} (1 - p_i)^{1-y_i}\n$$\n给定一个包含 $n$ 个独立观测值的数据集 $\\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$，总似然函数 $L(\\boldsymbol{\\beta})$ 是各个概率的乘积：\n$$\nL(\\boldsymbol{\\beta}) = \\prod_{i=1}^n P(y_i | \\mathbf{x}_i, \\boldsymbol{\\beta}) = \\prod_{i=1}^n p_i^{y_i} (1 - p_i)^{1-y_i}\n$$\n在分析和计算上，处理对数似然函数 $\\ell(\\boldsymbol{\\beta}) = \\ln L(\\boldsymbol{\\beta})$ 更为方便：\n$$\n\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\ln \\left( p_i^{y_i} (1 - p_i)^{1-y_i} \\right) = \\sum_{i=1}^n \\left[ y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i) \\right]\n$$\n我们可以利用 logit 链接函数的性质，用 $\\boldsymbol{\\beta}$ 来表示对数似然。一个常见且稳定的公式是通过注意到 $\\ln(p_i) = \\ln(\\sigma(\\mathbf{x}_i^T \\boldsymbol{\\beta}))$ 和 $\\ln(1-p_i) = \\ln(1-\\sigma(\\mathbf{x}_i^T \\boldsymbol{\\beta}))$ 推导出来的：\n$$\n\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) - \\ln(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}) \\right]\n$$\n\n**3. 带惩罚的目标函数**\n\n我们的目标是找到 $\\boldsymbol{\\beta}$ 的惩罚最大似然估计。我们引入一个强度为 $\\lambda \\ge 0$ 的 $\\ell_2$ 惩罚（岭惩罚）。问题规定截距项 $\\beta_0$ 不受惩罚。设 $p=4$ 为不包括截距的特征数量。惩罚项 $R(\\boldsymbol{\\beta})$ 为：\n$$\nR(\\boldsymbol{\\beta}) = \\frac{\\lambda}{2} \\sum_{j=1}^{p} \\beta_j^2\n$$\n常规的 $\\frac{1}{2}$ 因子简化了梯度计算。\n\n惩罚对数似然为 $\\ell_p(\\boldsymbol{\\beta}) = \\ell(\\boldsymbol{\\beta}) - R(\\boldsymbol{\\beta})$。最大化 $\\ell_p(\\boldsymbol{\\beta})$ 等价于最小化其负数，我们将其定义为目标函数 $J(\\boldsymbol{\\beta})$：\n$$\nJ(\\boldsymbol{\\beta}) = -\\ell_p(\\boldsymbol{\\beta}) = -\\ell(\\boldsymbol{\\beta}) + R(\\boldsymbol{\\beta})\n$$\n代入 $\\ell(\\boldsymbol{\\beta})$ 和 $R(\\boldsymbol{\\beta})$ 的表达式，我们得到最终要最小化的目标函数：\n$$\nJ(\\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left[ \\ln(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}) - y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) \\right] + \\frac{\\lambda}{2} \\sum_{j=1}^{p} \\beta_j^2\n$$\n该函数是凸函数，当 $\\lambda > 0$ 时，它是严格凸函数，这保证了存在唯一最小值。\n\n**4. 用于数值优化的梯度**\n\n为了使用基于梯度的优化算法最小化 $J(\\boldsymbol{\\beta})$，我们必须计算其梯度 $\\nabla_{\\boldsymbol{\\beta}} J(\\boldsymbol{\\beta})$。我们计算关于每个系数 $\\beta_j$ 的偏导数。\n\n首先，考虑目标函数的无惩罚部分。对于任何 $\\beta_j$（$j \\in \\{0, \\dots, p\\}$）：\n$$\n\\frac{\\partial}{\\partial \\beta_j} \\left( \\sum_{i=1}^n \\left[ \\ln(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}) - y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) \\right] \\right) = \\sum_{i=1}^n \\left[ \\frac{\\partial}{\\partial \\beta_j} \\ln(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}) - \\frac{\\partial}{\\partial \\beta_j} y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) \\right]\n$$\n使用链式法则：\n$$\n\\frac{\\partial}{\\partial \\beta_j} \\ln(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}) = \\frac{1}{1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}}} \\cdot e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}} \\cdot \\frac{\\partial (\\mathbf{x}_i^T \\boldsymbol{\\beta})}{\\partial \\beta_j} = \\sigma(\\mathbf{x}_i^T \\boldsymbol{\\beta}) \\cdot x_{ij} = p_i x_{ij}\n$$\n以及：\n$$\n\\frac{\\partial}{\\partial \\beta_j} y_i (\\mathbf{x}_i^T \\boldsymbol{\\beta}) = y_i x_{ij}\n$$\n所以，负对数似然的梯度是：\n$$\n\\sum_{i=1}^n (p_i - y_i) x_{ij}\n$$\n接下来，惩罚项的梯度是：\n$$\n\\frac{\\partial R(\\boldsymbol{\\beta})}{\\partial \\beta_j} = \\frac{\\partial}{\\partial \\beta_j} \\left( \\frac{\\lambda}{2} \\sum_{k=1}^{p} \\beta_k^2 \\right) = \\begin{cases} \\lambda \\beta_j & \\text{if } j \\in \\{1,\\dots,p\\} \\\\ 0 & \\text{if } j=0 \\end{cases}\n$$\n将这些结合起来，总目标函数 $J(\\boldsymbol{\\beta})$ 的偏导数为：\n$$\n\\frac{\\partial J}{\\partial \\beta_j} = \\sum_{i=1}^n (p_i - y_i) x_{ij} + \\begin{cases} \\lambda \\beta_j & \\text{if } j \\in \\{1,\\dots,p\\} \\\\ 0 & \\text{if } j=0 \\end{cases}\n$$\n在矩阵表示法中，令 $\\mathbf{X}$ 为 $n \\times (p+1)$ 的设计矩阵，其行是 $\\mathbf{x}_i^T$，$\\mathbf{y}$ 是 $n \\times 1$ 的结果向量，$\\mathbf{p}$ 是 $n \\times 1$ 的预测概率向量 $p_i = \\sigma(\\mathbf{X}\\boldsymbol{\\beta})_i$。令 $\\boldsymbol{\\beta}^* = (0, \\beta_1, \\dots, \\beta_p)^T$。梯度向量为：\n$$\n\\nabla_{\\boldsymbol{\\beta}} J(\\boldsymbol{\\beta}) = \\mathbf{X}^T (\\mathbf{p} - \\mathbf{y}) + \\lambda \\boldsymbol{\\beta}^*\n$$\n这个目标函数 $J(\\boldsymbol{\\beta})$ 及其梯度 $\\nabla_{\\boldsymbol{\\beta}} J(\\boldsymbol{\\beta})$ 适用于任何标准的数值优化程序，例如 L-BFGS-B。计算 $\\ln(1 + e^{\\mathbf{x}_i^T \\boldsymbol{\\beta}})$ 项时必须小心以保持数值稳定性，例如使用 log-sum-exp 技巧：$\\ln(1+e^z) = \\max(0,z) + \\ln(1+e^{-|z|})$。\n\n**5. 预测**\n\n一旦通过最小化 $J(\\boldsymbol{\\beta})$ 找到最优系数 $\\hat{\\boldsymbol{\\beta}}$，就可以使用逆链接函数计算新特征向量 $\\mathbf{x}_\\star$ 的预测概率 $\\hat{p}_\\star$：\n$$\n\\hat{p}_\\star = \\sigma(\\mathbf{x}_\\star^T \\hat{\\boldsymbol{\\beta}}) = \\frac{1}{1 + e^{-\\mathbf{x}_\\star^T \\hat{\\boldsymbol{\\beta}}}}\n$$\n\n这样就完成了所需的推导。实现将遵循这些推导出的方程。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Solves the penalized logistic regression problem for three test cases.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            \"X\": np.array([\n                [0.40, 0.70, 0.10, 0.30], [0.35, 0.20, 0.05, 0.10],\n                [0.55, 0.80, 0.20, 0.40], [0.60, 0.65, 0.25, 0.50],\n                [0.30, 0.30, 0.08, 0.12], [0.45, 0.50, 0.12, 0.20],\n                [0.70, 0.85, 0.30, 0.60], [0.38, 0.40, 0.09, 0.18],\n                [0.52, 0.75, 0.22, 0.45], [0.48, 0.55, 0.14, 0.22],\n                [0.62, 0.78, 0.26, 0.55], [0.33, 0.35, 0.07, 0.15]\n            ]),\n            \"y\": np.array([1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0]),\n            \"lambda_reg\": 1.0,\n            \"x_star\": np.array([0.50, 0.60, 0.15, 0.25])\n        },\n        # Case B\n        {\n            \"X\": np.array([\n                [0.80, 0.90, 0.35, 0.70], [0.78, 0.88, 0.34, 0.65],\n                [0.20, 0.15, 0.03, 0.05], [0.22, 0.18, 0.04, 0.06],\n                [0.82, 0.92, 0.36, 0.72], [0.18, 0.12, 0.02, 0.04],\n                [0.25, 0.20, 0.05, 0.08], [0.77, 0.86, 0.33, 0.60]\n            ]),\n            \"y\": np.array([1, 1, 0, 0, 1, 0, 0, 1]),\n            \"lambda_reg\": 10.0,\n            \"x_star\": np.array([0.75, 0.85, 0.32, 0.58])\n        },\n        # Case C\n        {\n            \"X\": np.array([\n                [0.50, 0.50, 0.12, 0.30], [0.47, 0.48, 0.11, 0.28],\n                [0.53, 0.52, 0.13, 0.31], [0.40, 0.45, 0.09, 0.20],\n                [0.60, 0.60, 0.15, 0.35], [0.42, 0.46, 0.10, 0.22],\n                [0.58, 0.58, 0.14, 0.34], [0.45, 0.47, 0.10, 0.24]\n            ]),\n            \"y\": np.array([1, 0, 1, 0, 1, 0, 1, 0]),\n            \"lambda_reg\": 0.1,\n            \"x_star\": np.array([0.55, 0.56, 0.13, 0.33])\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        X_train = case[\"X\"]\n        y_train = case[\"y\"]\n        lambda_reg = case[\"lambda_reg\"]\n        x_star = case[\"x_star\"]\n\n        # 1. Add intercept term to training data\n        intercept_train = np.ones((X_train.shape[0], 1))\n        X_b_train = np.c_[intercept_train, X_train]\n\n        # 2. Define objective function and gradient for the optimizer\n        def objective_and_grad(beta):\n            # linear combination\n            z = X_b_train @ beta\n\n            # Numerically stable calculation of log(1 + exp(z))\n            # log(1+exp(z)) = log(exp(0)+exp(z)) = logsumexp(0,z)\n            # Use max(0,z) + log(1+exp(-|z|)) to avoid overflow\n            lse = np.maximum(0, z) + np.log(1 + np.exp(-np.abs(z)))\n            \n            # Negative log-likelihood (cross-entropy loss)\n            log_loss = np.sum(lse - y_train * z)\n\n            # L2 penalty term (excluding intercept)\n            beta_no_intercept = beta[1:]\n            l2_penalty = 0.5 * lambda_reg * np.dot(beta_no_intercept, beta_no_intercept)\n\n            # Total cost\n            cost = log_loss + l2_penalty\n\n            # Gradient calculation\n            # Numerically stable sigmoid\n            p = 1 / (1 + np.exp(-z))\n            \n            # Gradient of log-loss part\n            grad_log_loss = X_b_train.T @ (p - y_train)\n\n            # Gradient of L2 penalty part\n            grad_penalty = lambda_reg * beta\n            grad_penalty[0] = 0.0  # Do not penalize intercept\n\n            gradient = grad_log_loss + grad_penalty\n            \n            return cost, gradient\n\n        # 3. Fit the model by minimizing the objective function\n        initial_beta = np.zeros(X_b_train.shape[1])\n        res = minimize(\n            fun=objective_and_grad,\n            x0=initial_beta,\n            method='L-BFGS-B',\n            jac=True,  # fun returns both objective and jacobian\n        )\n        beta_hat = res.x\n\n        # 4. Predict probability for the test vector x_star\n        x_star_b = np.insert(x_star, 0, 1) # Add intercept term\n        z_star = x_star_b @ beta_hat\n        p_star = 1 / (1 + np.exp(-z_star))\n\n        results.append(p_star)\n\n    # 5. Format and print the final output\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2798351"}]}