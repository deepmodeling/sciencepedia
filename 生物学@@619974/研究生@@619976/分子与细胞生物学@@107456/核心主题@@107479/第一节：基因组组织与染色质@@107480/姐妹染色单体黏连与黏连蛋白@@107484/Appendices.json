{"hands_on_practices": [{"introduction": "要深入理解黏连蛋白的功能，我们必须从其核心引擎——由ATP驱动的机械化学循环——入手。通过引入特定的点突变来“冻结”这个循环中的某个特定状态，是研究分子马达的经典策略。本练习 [@problem_id:2964819] 聚焦于一个关键的 Walker B 突变，该突变能结合ATP但无法水解它。这提供了一个绝佳的机会，让您练习从一个基础的分子缺陷出发，推导其对黏连蛋白加载、环挤压和染色质驻留时间等多个宏观功能的连锁效应，从而建立起对黏连蛋白工作原理的机理层面认知。", "problem": "黏连蛋白内的一个染色体结构维持 (SMC) 家族的三磷酸腺苷酶 (ATPase) 利用 ATP 驱动的机械化学循环来加载到 DNA 上、挤出环，并在染色质上进行动态交换（结合与解离）。考虑 Smc3 中的一个 Walker B 突变，该突变消除了 ATP 水解能力，但保留了 ATP 结合和头部接合的能力。假设以下基本事实：(i) ATP 结合促进 SMC 头部接合以及与加载蛋白 Nipped-B 样蛋白 (NIPBL，也称为 Scc2) 一起抓取 DNA，(ii) 每个循环中至少需要 $1$ 次 ATP 水解事件才能完成有效的拓扑加载（DNA 捕获），并实现环挤出核心的抓取和滑动状态之间的转换，以及 (iii) 由 Wings apart 样蛋白 (Wapl) 介导的非核酸酶解离需要一个依赖于 ATP 水解的头部解离步骤。使用一个最小动力学模型，其中有效加载频率与一个水解依赖性速率 $k_{\\mathrm{load}}$ 成正比，环挤出速度 $v$ 与 ATP 周转率 $k_{\\mathrm{cat}}$ 成正比，染色质停留时间 $\\tau$ 通过 $\\tau \\approx 1/k_{\\mathrm{off}}$ 与一个水解依赖性解离速率 $k_{\\mathrm{off}}$ 成反比，请预测以下可观测量相对于野生型在体内的定性变化方向：(a) 加载频率，(b) 环挤出速度，和 (c) 染色质停留时间。选择最佳的单个选项。\n\nA. 加载频率降低；环挤出速度接近于零；停留时间增加。\n\nB. 加载频率增加；环挤出速度增加；停留时间减少。\n\nC. 加载频率不变；环挤出速度接近于零；停留时间不变。\n\nD. 加载频率降低；环挤出速度不变；停留时间减少。\n\nE. 加载频率增加；环挤出速度接近于零；停留时间增加。", "solution": "在尝试解答之前，将对问题陈述进行验证。\n\n### 问题验证\n\n**步骤 1：提取已知信息**\n问题提供了以下信息：\n1.  **系统**：一个染色体结构维持 (SMC) 家族的三磷酸腺苷酶 (ATPase)，具体是指黏连蛋白复合体。\n2.  **功能**：该复合体利用 ATP 驱动的机械化学循环进行三个关键过程：加载到 DNA 上、挤出 DNA 环以及在染色质上进行动态交换（结合与解离）。\n3.  **扰动**：Smc3 亚基中的一个 Walker B 突变。\n4.  **突变的后果**：该突变消除了 ATP 水解能力，但保留了 ATP 结合和 SMC 头部接合的能力。\n5.  **前提 (i)**：ATP 结合对于 SMC 头部接合以及与加载蛋白 NIPBL (Scc2) 协同抓取 DNA 是必需的。\n6.  **前提 (ii)**：每个循环中至少需要一次 ($1$) ATP 水解事件才能完成有效的拓扑加载（即 DNA 捕获），并实现环挤出所必需的抓取和滑动状态之间的转换。\n7.  **前提 (iii)**：由 Wapl 介导的黏连蛋白从染色质上的释放（非核酸酶介导的释放）依赖于一个由 ATP 水解驱动的头部解离步骤。\n8.  **动力学模型**：\n    *   有效加载频率与一个水解依赖性速率 $k_{\\mathrm{load}}$ 成正比。\n    *   环挤出速度 $v$ 与 ATP 周转率 $k_{\\mathrm{cat}}$ 成正比。\n    *   染色质停留时间 $\\tau$ 近似为一个水解依赖性解离速率 $k_{\\mathrm{off}}$ 的倒数，即 $\\tau \\approx 1/k_{\\mathrm{off}}$。\n\n**步骤 2：使用提取的已知信息进行验证**\n根据所需标准对问题进行评估：\n*   **科学依据**：该问题植根于有关黏连蛋白复合体功能的分子和细胞生物学既定原理。ATP 结合和水解的作用、Walker B 基序、加载和释放因子（NIPBL, Wapl）以及环挤出过程都与当前的科学文献一致。所描述的突变是研究 ATPase 机制的标准实验工具。该问题在科学上是合理的。\n*   **问题的适定性**：该问题定义了一个特定的扰动（突变）及其直接的生化效应（无水解）。然后，它要求基于一系列明确的前提和一个简化的动力学模型，来判断三个明确定义的可观测量的定性效应。这种结构使得可以推导出一个唯一的、合乎逻辑的解。\n*   **客观性**：语言技术性强、精确，且没有主观或模棱两可的术语。\n*   **完整性和一致性**：问题是自洽的。它提供了所有必要的公理——“基本事实”和“最小动力学模型”——以便在不需要与设定相矛盾的外部信息的情况下推导出答案。这些前提是内部一致的。\n\n**步骤 3：结论与行动**\n问题陈述有效。这是一个在分子生物物理学领域中表述良好的问题。我将继续推导解决方案。\n\n### 解题推导\n\n这个问题的核心要素是 Smc3 的 Walker B 基序中指定的突变，该突变导致 ATP 水解能力被消除，但保留了 ATP 结合及随后的头部接合能力。因此，该复合体被阻滞在一种 ATP 结合、头部接合的构象中。我们将根据所提供的前提，分析这一突变对三个指定可观测量的影响。\n\n**1. 加载频率分析**\n问题指出，有效加载频率与一个水解依赖性速率 $k_{\\mathrm{load}}$ 成正比。此外，前提 (ii) 明确指出，“每个循环中至少需要 $1$ 次 ATP 水解事件才能完成有效的拓扑加载”。由于该突变消除了 ATP 水解，循环无法越过初始的 ATP 结合、头部接合状态以实现对 DNA 的拓扑捕获。有效加载的限速步骤需要水解，其速率常数实际上降至零。因此，有效加载速率 $k_{\\mathrm{load}}$ 必然急剧下降。虽然可能会发生与 DNA 的初始的、非有效性的结合（前提 (i)），但将此状态转变为拓扑加载的复合体的过程被阻断了。因此，总的加载频率降低。\n\n**2. 环挤出速度分析**\n问题定义了环挤出速度 $v$ 与 ATP 周转率 $k_{\\mathrm{cat}}$ 成正比。ATP 周转率是整个循环的速率：ATP 结合、水解和产物释放。该突变在水解步骤中止了循环。这意味着循环无法完成，因此周转率 $k_{\\mathrm{cat}}$ 变为零。由于 $v$ 与 $k_{\\mathrm{cat}}$ 成正比，环挤出速度 $v$ 必然接近于零。这一结论得到了前提 (ii) 的支持，该前提指出环挤出所需的状态转换依赖于 ATP 水解。如果没有水解，该复合体就被锁定在一个静态的 DNA 抓取状态，无法执行挤出过程的迭代步骤。\n\n**3. 染色质停留时间分析**\n染色质停留时间 $\\tau$ 由关系式 $\\tau \\approx 1/k_{\\mathrm{off}}$ 给出，其中 $k_{\\mathrm{off}}$ 是一个依赖于 ATP 水解的解离速率。前提 (iii) 指出，由 Wapl 介导的黏连蛋白从染色质上释放的主要机制，需要一个依赖于 ATP 水解的 SMC 头部解离步骤。通过消除 ATP 水解，该突变阻止了这种头部解离，从而阻断了 Wapl 介导的释放途径。这导致解离速率 $k_{\\mathrm{off}}$ 接近于零。因此，停留时间 $\\tau$ 作为 $k_{\\mathrm{off}}$ 的倒数，将会急剧增加，理论上接近无穷大。突变的黏连蛋白复合体被困在染色质上。\n\n**预测总结：**\n*   (a) 加载频率：降低。\n*   (b) 环挤出速度：接近于零。\n*   (c) 染色质停留时间：增加。\n\n### 选项评估\n\n*   **A. 加载频率降低；环挤出速度接近于零；停留时间增加。** 此选项与对所有三个可观测量的推导结果完全匹配。**正确**。\n\n*   **B. 加载频率增加；环挤出速度增加；停留时间减少。** 此选项对所有三个可观测量都是错误的。缺乏 ATP 水解会阻断所有这些过程，或者在停留时间的情况下产生相反的效果。**错误**。\n\n*   **C. 加载频率不变；环挤出速度接近于零；停留时间不变。** 此选项在加载频率和停留时间方面是错误的。有效的加载依赖于水解，而释放的阻断会显著增加停留时间。**错误**。\n\n*   **D. 加载频率降低；环挤出速度不变；停留时间减少。** 此选项在环挤出速度和停留时间方面是错误的。速度取决于 ATP 周转，而停留时间是增加而不是减少。**错误**。\n\n*   **E. 加载频率增加；环挤出速度接近于零；停留时间增加。** 此选项错误地指出加载频率增加。它混淆了初始的 DNA 结合和头部接合（这可能因 ATP 结合状态而稳定）与*有效*拓扑加载的总频率，后者严格依赖于水解，因此被阻断。**错误**。\n\n基于这一严谨的分析，只有选项 A 与所提供的黏连蛋白功能模型及指定突变的影响相符。", "answer": "$$\\boxed{A}$$", "id": "2964819"}, {"introduction": "在理解了黏连蛋白的内在马达机制后，下一步是探究其在活细胞复杂环境中的动态行为。荧光漂白后恢复 (FRAP) 和单分子追踪 (SMT) 等活细胞成像技术，为我们定量测量蛋白质动力学（如驻留时间、可移动组分和结合/解离速率）提供了强有力的工具。这项练习 [@problem_id:2964766] 旨在培养解读真实世界生物物理数据的关键技能。您需要将抽象的动力学参数（如 $k_{\\text{on}}$ 和 $k_{\\text{off}}$）与黏连蛋白加载、稳定和释放等生物过程联系起来，并理解这些过程如何反映在具体的实验测量结果中。", "problem": "一个实验室使用光漂白后荧光恢复（FRAP）和单分子追踪（SMT）技术，研究活体哺乳动物细胞中黏连蛋白复合体在染色质上的动力学。黏连蛋白由 Nipped-B-like protein (NIPBL)–MAU2 加载到染色体上，在复制后通过 Structural Maintenance of Chromosomes 3 (SMC3) 乙酰化和 sororin 进行稳定，并由 Wings apart-like protein homolog (WAPL) 释放。该实验室旨在量化黏连蛋白的驻留时间和流动相分数如何反映加载、稳定和释放过程。以下基本事实被作为基本依据：(i) FRAP 测量由分子运输和结合-解离交换驱动的荧光恢复；(ii) SMT 解析单个标记分子的轨迹，从而能够将其分类为扩散状态和染色质结合状态，并推断出扩散系数和结合态的停留时间；(iii) 在一个最小双态模型中，自由扩散状态和染色质结合状态之间的转换由一个有效结合（on）速率 $k_{\\mathrm{on}}$（与游离黏连蛋白浓度 $C$ 成正比）和一个解离（off）速率 $k_{\\mathrm{off}}$ 控制；(iv) 稳定对应于 $k_{\\mathrm{off}}$ 的降低，释放对应于 $k_{\\mathrm{off}}$ 的增加，加载则对应于在给定浓度 $C$ 下 $k_{\\mathrm{on}}$ 的增加。\n\n下列哪个陈述正确地将 FRAP 和 SMT 的可测量参数与黏连蛋白的加载、稳定和释放联系起来？选择所有适用项。\n\nA. 在细胞核内反应主导的条件下（扩散相对于结合-解离速度快），染色质结合的黏连蛋白的FRAP恢复过程可以很好地用一个单指数函数来近似，该函数趋近于漂白前的强度，其表观速率常数为 $k_{\\mathrm{app}} \\approx k_{\\mathrm{on}} C + k_{\\mathrm{off}}$；因此，耗尽可减少释放的 Wings apart-like protein homolog (WAPL) 预计会降低 $k_{\\mathrm{off}}$ 并减慢恢复速度（即 $k_{\\mathrm{app}}$ 变小），这表明驻留时间增加。\n\nB. 通过 Structural Maintenance of Chromosomes 3 (SMC3) 乙酰化和 sororin 稳定染色质上的黏连蛋白会增加长时间尺度下的 FRAP 流动相分数 $M$ ，因为在观察窗口内有更多分子保持可交换状态。\n\nC. 在用双态模型（扩散系数为 $D$ 的扩散状态 vs. 染色质结合状态）分析的 SMT 中，结合态停留时间的存活函数遵循 $S(t)=\\exp(-k_{\\mathrm{off}} t)$，得出的平均驻留时间为 $\\tau_b = 1/k_{\\mathrm{off}}$；sororin 的缺失会缩短 $\\tau_b$，而不必定改变 $D$。\n\nD. 有效加载速率由乘积 $k_{\\mathrm{on}} C$ 反映，当核内浓度 $C$ 已知时，可通过量化 SMT 中从扩散到结合的转换频率（到达事件）来估计该值；耗尽 Nipped-B-like protein (NIPBL) 会降低 $k_{\\mathrm{on}}$，从而在不直接改变 $k_{\\mathrm{off}}$ 的情况下降低稳态时的结合分数。\n\nE. 在扩散限制的 FRAP 中（扩散相对于结合-解离速度慢），恢复半衰期 $t_{1/2}$ 直接反映 $1/k_{\\mathrm{off}}$，并且基本上与漂白区域的形状和大小无关。\n\nF. 增加 Wings apart-like protein homolog (WAPL) 的活性会增加长时间尺度下的 FRAP 不动相分数，并增加 SMT 中长寿命停留时间的比例。", "solution": "在尝试任何解答之前，将首先验证问题陈述。\n\n### 步骤 1：提取已知信息\n问题陈述中提供了以下信息：\n- **技术：** 使用光漂白后荧光恢复（FRAP）和单分子追踪（SMT）研究活体哺乳动物细胞中的黏连蛋白动力学。\n- **生物组分：**\n    - 黏连蛋白：被研究的复合体。\n    - Nipped-B-like protein (NIPBL)–MAU2：将黏连蛋白加载到染色体上。\n    - Structural Maintenance of Chromosomes 3 (SMC3) 乙酰化和 sororin：在复制后稳定染色质上的黏连蛋白。\n    - Wings apart-like protein homolog (WAPL)：释放黏连蛋白。\n- **基本事实与模型：**\n    - (i) FRAP 测量由分子运输和结合-解离交换驱动的恢复过程。\n    - (ii) SMT 解析单个分子的轨迹，将其分类为扩散状态和染色质结合状态，得出扩散系数（$D$）和结合态停留时间（$\\tau_b$）。\n    - (iii) 一个最小双态模型（自由扩散 vs. 染色质结合）被假定。状态转换由一个有效结合速率常数 $k_{\\mathrm{on}}$（整体速率与游离黏连蛋白浓度 $C$ 成正比）和一个解离速率常数 $k_{\\mathrm{off}}$ 控制。\n    - (iv) 生物学功能与动力学参数之间的联系被定义为：稳定对应于 $k_{\\mathrm{off}}$ 的降低；释放对应于 $k_{\\mathrm{off}}$ 的增加；加载对应于在给定浓度 $C$ 下 $k_{\\mathrm{on}}$ 的增加。\n\n### 步骤 2：使用提取的已知信息进行验证\n根据科学依据、适定性和客观性标准对问题陈述进行评估。\n\n- **科学依据：** 该问题牢固地植根于分子与细胞生物学和生物物理学的既定原理。对黏连蛋白调控的描述（由 NIPBL-MAU2 加载，由 SMC3 乙酰化/sororin 稳定，由 WAPL 释放）准确地反映了当前的科学共识。对 FRAP 和 SMT 背后的物理原理及其在双态动力学模型中的应用的描述是该领域的标准。该问题在科学上是合理的。\n- **适定性：** 该问题提供了一个清晰的理论框架（一个双态动力学模型），并明确定义了生物过程（加载、稳定、释放）与模型动力学参数（$k_{\\mathrm{on}}$、$k_{\\mathrm{off}}$）之间的映射关系。问题要求在可测量的实验参数和这些生物过程之间建立正确的逻辑联系，这是一个明确定义的任务。问题是自洽的，并提供了足够的信息来评估选项。\n- **客观性：** 语言技术性强、精确，且没有主观或模棱两可的术语。在给定的框架内，这些陈述以事实或可检验的假设形式呈现。\n\n### 步骤 3：结论与行动\n问题陈述是有效的。它在科学上合理，具有适定性和客观性。将通过分析每个选项来推导解决方案。\n\n### 推导与选项分析\n\n问题的核心是将所提供的双态动力学模型应用于解释在黏连蛋白调控机制受到各种扰动的情况下，FRAP 和 SMT 实验的结果。关键关系如下：\n- 驻留时间：$\\tau_b = 1/k_{\\mathrm{off}}$\n- 稳定：降低 $k_{\\mathrm{off}}$，增加 $\\tau_b$。\n- 释放：增加 $k_{\\mathrm{off}}$，降低 $\\tau_b$。\n- 加载：增加 $k_{\\mathrm{on}}$。\n\n**A. 在细胞核内反应主导的条件下（扩散相对于结合-解离速度快），染色质结合的黏连蛋白的FRAP恢复过程可以很好地用一个单指数函数来近似，该函数趋近于漂白前的强度，其表观速率常数为 $k_{\\mathrm{app}} \\approx k_{\\mathrm{on}} C + k_{\\mathrm{off}}$；因此，耗尽可减少释放的 Wings apart-like protein homolog (WAPL) 预计会降低 $k_{\\mathrm{off}}$ 并减慢恢复速度（即 $k_{\\mathrm{app}}$ 变小），这表明驻留时间增加。**\n\n必须根据其提供的前提来评估该陈述的逻辑。\n$1$. 问题陈述 WAPL 促进释放，因此其耗尽会减少释放。根据给定的框架（第 iv 点），释放的减少对应于解离速率常数 $k_{\\mathrm{off}}$ 的降低。\n$2$. 该陈述提出了一个表观恢复速率常数 $k_{\\mathrm{app}} \\approx k_{\\mathrm{on}} C + k_{\\mathrm{off}}$。如果 $k_{\\mathrm{off}}$ 降低而 $k_{\\mathrm{on}}C$ 保持不变，则 $k_{\\mathrm{app}}$ 将会降低。\n$3$. 较小的速率常数（$k_{\\mathrm{app}}$）意味着过程更慢。因此，$k_{\\mathrm{app}}$ 的降低对应于更慢的荧光恢复。\n$4$. 在染色质上的平均驻留时间为 $\\tau_b = 1/k_{\\mathrm{off}}$。$k_{\\mathrm{off}}$ 的降低导致 $\\tau_b$ 的增加。因此，观察到的较慢恢复正确地表明了驻留时间的增加。\n基于所提供的模型，该推理链在内部是一致且正确的。\n\n结论：**正确**。\n\n**B. 通过 Structural Maintenance of Chromosomes 3 (SMC3) 乙酰化和 sororin 稳定染色质上的黏连蛋白会增加长时间尺度下的 FRAP 流动相分数 $M$ ，因为在观察窗口内有更多分子保持可交换状态。**\n\n根据问题中的定义（第 iv 点），稳定对应于 $k_{\\mathrm{off}}$ 的降低。这意味着平均驻留时间 $\\tau_b = 1/k_{\\mathrm{off}}$ 增加。在 FRAP 实验中，流动相分数 $M$ 由那些能够在实验时间尺度内从漂白区域交换出去的分子组成。如果分子结合的时间非常长（高 $\\tau_b$），可能比实验时间还长，它们将不会被周围区域的荧光分子替换，并将表现为不动相分数（$1-M$）的一部分。因此，稳定（更长的结合时间）预计会*减少*流动相分数 $M$，而不是增加它。所提供的理由（“因为在观察窗口内有更多分子保持可交换状态”）与稳定的实际效果相反。\n\n结论：**不正确**。\n\n**C. 在用双态模型（扩散系数为 $D$ 的扩散状态 vs. 染色质结合状态）分析的 SMT 中，结合态停留时间的存活函数遵循 $S(t)=\\exp(-k_{\\mathrm{off}} t)$，得出的平均驻留时间为 $\\tau_b = 1/k_{\\mathrm{off}}$；sororin 的缺失会缩短 $\\tau_b$，而不必定改变 $D$。**\n\n该陈述检验了 SMT 分析。\n$1$. 对于由恒定速率 $k_{\\mathrm{off}}$ 表征的一级解离过程，一个分子保持结合至少时间 $t$ 的概率由存活函数 $S(t) = \\exp(-k_{\\mathrm{off}} t)$ 给出。这是随机过程理论的一个标准结果。\n$2$. 平均驻留时间 $\\tau_b$ 是停留时间分布的期望值，计算公式为 $\\int_0^\\infty t \\cdot p(t) dt$ 其中 $p(t) = -dS/dt$，或更简单地为 $\\int_0^\\infty S(t) dt$。积分 $\\int_0^\\infty \\exp(-k_{\\mathrm{off}} t) dt = 1/k_{\\mathrm{off}}$。这是正确的。\n$3$. 问题陈述 sororin 参与稳定过程。稳定意味着降低 $k_{\\mathrm{off}}$。因此，sororin 的缺失将导致去稳定化，即 $k_{\\mathrm{off}}$ 的*增加*。\n$4$. 由于 $\\tau_b = 1/k_{\\mathrm{off}}$， $k_{\\mathrm{off}}$ 的增加导致 $\\tau_b$ 的减少（缩短）。\n$5$. 扩散系数 $D$ 表征*自由*、非结合状态的黏连蛋白的运动。sororin 的功能与*结合*态的稳定性有关。没有先验理由认为改变结合态的稳定性会影响非结合分子的扩散。因此，陈述其发生“而不必定改变 $D$”是正确的。\n陈述的所有部分都是正确的。\n\n结论：**正确**。\n\n**D. 有效加载速率由乘积 $k_{\\mathrm{on}} C$ 反映，当核内浓度 $C$ 已知时，可通过量化 SMT 中从扩散到结合的转换频率（到达事件）来估计该值；耗尽 Nipped-B-like protein (NIPBL) 会降低 $k_{\\mathrm{on}}$，从而在不直接改变 $k_{\\mathrm{off}}$ 的情况下降低稳态时的结合分数。**\n\n该陈述讨论了加载过程。\n$1$. 双分子结合反应的速率与反应物浓度的乘积成正比。对于一个黏连蛋白分子与染色质结合，每个自由黏连蛋白分子的结合事件速率与可用结合位点的浓度成正比，而总结合事件速率与自由黏连蛋白的浓度 $C$ 成正比。乘积 $k_{\\mathrm{on}} C$ 代表一个自由分子变为结合状态的伪一级速率常数。SMT 通过追踪单个分子，可以直接观察从扩散状态到静止（结合）状态的转变，从而量化这个速率。这部分是正确的。\n$2$. 问题将 NIPBL 确定为黏连蛋白加载因子，而加载对应于 $k_{\\mathrm{on}}$ 的增加。因此，耗尽 NIPBL 预计会降低 $k_{\\mathrm{on}}$。\n$3$. 结合态（$B$）和自由态（$F$，浓度为 $C$）黏连蛋白之间的稳态平衡由结合速率与解离速率的比率决定。在平衡状态下，结合速率 = 解离速率。结合黏连蛋白的分数取决于平衡常数，该常数与 $k_{\\mathrm{on}}/k_{\\mathrm{off}}$ 相关。如果 $k_{\\mathrm{on}}$ 降低而 $k_{\\mathrm{off}}$ 保持不变，平衡将向自由态移动，从而降低结合黏连蛋白的分数。\n$4$. 问题将加载（NIPBL 依赖性）和释放（WAPL 依赖性）定义为分别影响 $k_{\\mathrm{on}}$ 和 $k_{\\mathrm{off}}$ 的不同过程。因此，假设耗尽加载因子 NIPBL 会降低 $k_{\\mathrm{on}}$ 而不直接影响释放速率 $k_{\\mathrm{off}}$ 是正确的。\n陈述的所有部分都是一致且正确的。\n\n结论：**正确**。\n\n**E. 在扩散限制的 FRAP 中（扩散相对于结合-解离速度慢），恢复半衰期 $t_{1/2}$ 直接反映 $1/k_{\\mathrm{off}}$，并且基本上与漂白区域的形状和大小无关。**\n\n该陈述描述了扩散限制的 FRAP。在这种情况下，假定结合/解离动力学比扩散快得多。荧光恢复的速率限制步骤是未漂白分子扩散到漂白区域所需的时间。因此，恢复动力学由扩散系数 $D$ 决定。特征恢复时间（例如，$t_{1/2}$）与 $w^2/D$ 成正比，其中 $w$ 是漂白点的半径或特征尺寸。因此，恢复时间强烈依赖于漂白区域的大小和形状，并且是 $D$ 的量度，而不是 $1/k_{\\mathrm{off}}$ 的量度。该陈述在两方面都是不正确的。\n\n结论：**不正确**。\n\n**F. 增加 Wings apart-like protein homolog (WAPL) 的活性会增加长时间尺度下的 FRAP 不动相分数，并增加 SMT 中长寿命停留时间的比例。**\n\n该陈述检验了增加 WAPL 活性的影响。\n$1$. 问题陈述 WAPL 介导黏连蛋白的释放，因此增加其活性意味着增加释放速率。这对应于 $k_{\\mathrm{off}}$ 的*增加*。\n$2$. 增加的 $k_{\\mathrm{off}}$ 导致更短的平均驻留时间 $\\tau_b = 1/k_{\\mathrm{off}}$。分子交换更迅速。在 FRAP 中，这将导致更快和更完全的恢复，意味着不动相分数的*减少*。该陈述声称是增加，这是不正确的。\n$3$. 在 SMT 中，增加的 $k_{\\mathrm{off}}$ 意味着结合事件平均而言更短。这将导致长寿命停留时间的比例*减少*，因为整个停留时间的分布向更短的时间移动。该陈述声称是增加，这是不正确的。\n该陈述中的两个主张都是不正确的。\n\n结论：**不正确**。", "answer": "$$\\boxed{ACD}$$", "id": "2964766"}, {"introduction": "最后，我们将视角从单个复合物的动态行为放大到它们在塑造大规模染色体结构中的集体功能。拓扑关联结构域 (TAD) 边界的“绝缘性”是黏连蛋白活性所产生的一个关键功能性输出，并且可以通过高通量染色体构象捕获 (Hi-C) 数据进行量化。这项高级实践 [@problem_id:2964851] 将带您从概念理解走向动手计算分析。您将学习如何将一个生物学概念（TAD边界）形式化为一个可计算的指标，并应用严谨的统计方法来检验该领域的一个核心假说：黏连蛋白是维持TAD边界所必需的。", "problem": "给你多份重复的染色体接触矩阵，这些矩阵代表了在 Cohesin 复合体耗尽前后，基因座-基因座之间的接触频率。你的目标是形式化并计算在指定候选位置索引处的、一种基于绝缘的边界强度，然后使用单侧配对检验在匹配的重复样本间进行测试，以判断边界强度是否在 Cohesin 耗尽后下降，并对所有索引进行多重假设校正。\n\n基本定义：\n- 设一个染色体接触图谱由一个对称矩阵 $C \\in \\mathbb{R}_{\\ge 0}^{N \\times N}$ 表示，其中 $C_{ab} = C_{ba}$ 表示区间 $a$ 和 $b$ 之间的接触频率，这里 $0 \\le a,b \\le N-1$。\n- 对于一个区间索引 $i$ 和一个正整数窗口半径 $w$，定义跨越总和 $S_i(C; w)$ 为窗口内跨越区间 $i$ 和 $i+1$ 之间垂直分割的总接触频率：\n$$\nS_i(C; w) \\equiv \\sum_{a = \\max(0,\\, i-w+1)}^{i} \\;\\; \\sum_{b = i+1}^{\\min(N-1,\\, i+w)} C_{ab}.\n$$\n- 为了数值稳定性，定义一个伪计数 $\\varepsilon > 0$ 和稳定化对数跨越值 $X_i(C; w, \\varepsilon) \\equiv \\ln\\!\\big(S_i(C; w) + \\varepsilon\\big)$。\n- 对于一个侧翼大小 $d \\in \\mathbb{N}$，定义索引 $i$ 处的边界强度为侧翼的平均对数跨越值与中心的对数跨越值之间的对比：\n$$\nB_i(C; w, d, \\varepsilon) \\equiv \\frac{1}{2}\\left(\\frac{1}{d}\\sum_{k=1}^{d} X_{i-k}(C; w, \\varepsilon) + \\frac{1}{d}\\sum_{k=1}^{d} X_{i+k}(C; w, \\varepsilon)\\right) - X_i(C; w, \\varepsilon).\n$$\n- 资格条件：为使 $B_i(C; w, d, \\varepsilon)$ 能够被明确定义且无边缘裁剪，索引 $i$ 必须满足 $i - d \\ge w - 1$ 和 $i + d \\le N - 1 - w$。只有这样的 $i$ 才有资格进行假设检验。\n\n跨匹配重复样本的统计检验：\n- 假设我们有 $R$ 份用于对照条件（Cohesin 耗尽前）的匹配重复接触矩阵 $\\{C^{\\text{pre}}_r\\}_{r=1}^{R}$，以及 $R$ 份用于实验条件（Cohesin 耗尽后）的匹配重复接触矩阵 $\\{C^{\\text{post}}_r\\}_{r=1}^{R}$。对每个合格的索引 $i$，计算每种条件下配对的重复样本边界强度，并构成差异\n$$\nD_{i,r} \\equiv B_i\\!\\left(C^{\\text{post}}_r; w, d, \\varepsilon\\right) - B_i\\!\\left(C^{\\text{pre}}_r; w, d, \\varepsilon\\right), \\quad r = 1,\\dots,R.\n$$\n- 对每个合格的 $i$ 进行一次单侧配对 $t$ 检验，以评估原假设 $H_0: \\mu_i \\ge 0$ 与备择假设 $H_1: \\mu_i &lt; 0$，其中 $\\mu_i$ 是 $D_{i,r}$ 的总体均值。设 $\\bar{D}_i$ 为 $\\{D_{i,r}\\}_{r=1}^{R}$ 的样本均值， $s_i$ 为自由度为 $R-1$ 的样本标准差。检验统计量为\n$$\nt_i \\equiv \\frac{\\bar{D}_i}{s_i / \\sqrt{R}}.\n$$\n如果 $s_i = 0$，则根据保守规则定义单侧 $p$ 值：如果 $\\bar{D}_i &lt; 0$，则 $p_i = 0$；如果 $\\bar{D}_i = 0$，则 $p_i = 0.5$；如果 $\\bar{D}_i &gt; 0$，则 $p_i = 1$。否则，当 $s_i &gt; 0$ 时，将 $p_i$ 定义为自由度为 $R-1$ 的学生 $t$ 分布在 $t_i$ 处的累积分布函数值：\n$$\np_i \\equiv F_{t_{R-1}}(t_i).\n$$\n- 在候选集中的 $m$ 个合格索引上，使用 Benjamini–Hochberg 程序在伪发现率水平 $\\alpha \\in (0,1)$ 下进行多重假设检验校正。设 $m$ 个 $p$ 值按升序排序为 $p_{(1)} \\le \\dots \\le p_{(m)}$。找到\n$$\nk^\\star \\equiv \\max\\left\\{ k \\in \\{1,\\dots,m\\} \\,\\middle|\\, p_{(k)} \\le \\frac{k}{m}\\alpha \\right\\},\n$$\n如果存在这样的 $k^\\star$；否则，不拒绝任何假设。拒绝所有满足 $p_i \\le p_{(k^\\star)}$ 的假设。报告被拒绝的假设总数。\n\n你的任务：\n- 为每个提供的测试用例实现上述定义和统计检验。\n- 对每个测试用例，输出一个整数：在指定的 $\\alpha$ 水平下，经过 Benjamini–Hochberg 校正后，被判定为显著（即边界强度在Cohesin耗尽后下降）的候选索引的数量。\n- 将所有测试用例的结果汇总为一行，形式为方括号内包含的逗号分隔列表。\n\n测试套件：\n对于每个测试用例，你将获得：\n- 候选边界索引列表 $\\mathcal{I}$（从零开始）。\n- Cohesin 耗尽前后的匹配重复矩阵列表。\n- 参数 $w$、$d$、$\\varepsilon$ 和 $\\alpha$。\n\n所有矩阵均为对称矩阵，其元素为非负数，且尺寸较小以允许直接实现。\n\n测试用例1（理想情况，一个内部边界明显下降）：\n- $N = 8$, $R = 4$, $\\mathcal{I} = [3, 1, 6]$, $w = 2$, $d = 1$, $\\varepsilon = 10^{-6}$, $\\alpha = 0.1$。\n- 对每个重复样本 $r \\in \\{1,2,3,4\\}$，为所有 $a &lt; b$ 设置基线接触 $C_{ab} = 10$，并满足对称性 $C_{ba} = C_{ab}$ 及 $C_{aa} = 0$。仅修改索引 $i = 3$ 处分割区的四个跨越单元格：$(2,4)$, $(2,5)$, $(3,4)$, $(3,5)$。\n    - 重复样本1：在这四个单元格中，耗尽前的值设为 $2$，耗尽后的值设为 $20$。\n    - 重复样本2：在这四个单元格中，耗尽前的值设为 $3$，耗尽后的值设为 $19$。\n    - 重复样本3：在这四个单元格中，耗尽前的值设为 $2.5$，耗尽后的值设为 $18$。\n    - 重复样本4：在这四个单元格中，耗尽前的值设为 $3.5$，耗尽后的值设为 $21$。\n- 所有其他矩阵元素保持为基线值 $10$。\n\n测试用例2（资格边界条件且无变化）：\n- $N = 7$, $R = 3$, $\\mathcal{I} = [1, 5, 3]$, $w = 2$, $d = 2$, $\\varepsilon = 10^{-6}$, $\\alpha = 0.2$。\n- 对于每个重复样本 $r \\in \\{1,2,3\\}$ 以及两种条件（耗尽前和耗尽后），将所有非对角线元素设为 $10$，强制对称，并设置 $C_{aa} = 0$。两种条件之间没有差异。不满足资格约束的索引必须从测试中排除。\n\n测试用例3（边界强度增加，而非减少）：\n- $N = 6$, $R = 4$, $\\mathcal{I} = [2, 3]$, $w = 1$, $d = 1$, $\\varepsilon = 10^{-6}$, $\\alpha = 0.05$。\n- 对于每个重复样本 $r \\in \\{1,2,3,4\\}$，为所有非对角线元素设置基线值 $5$，满足对称性且 $C_{aa} = 0$。仅修改在 $w=1$ 时，分割区 $i=3$ 处的单个跨越单元格，即 $(3,4)$：\n    - 耗尽前：$(3,4) = (4,3) = 5$（基线值）。\n    - 耗尽后：$(3,4) = (4,3) = 1$（跨越减少），所有其他元素保持基线值。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3]\"），每个结果是为相应测试用例发现的边界强度显著下降的整数数量。", "solution": "在尝试任何解决方案之前，对问题陈述进行严格验证。\n\n### 步骤1：提取已知信息\n问题提供了以下定义和程序：\n- 染色体接触图谱是一个对称矩阵 $C \\in \\mathbb{R}_{\\ge 0}^{N \\times N}$。\n- 在索引 $i$ 处，窗口半径为 $w$ 的跨越总和是 $S_i(C; w) \\equiv \\sum_{a = \\max(0,\\, i-w+1)}^{i} \\;\\; \\sum_{b = i+1}^{\\min(N-1,\\, i+w)} C_{ab}$。\n- 稳定化对数跨越值是 $X_i(C; w, \\varepsilon) \\equiv \\ln\\!\\big(S_i(C; w) + \\varepsilon\\big)$，其中伪计数 $\\varepsilon > 0$。\n- 在索引 $i$ 处，侧翼大小为 $d$ 的边界强度是 $B_i(C; w, d, \\varepsilon) \\equiv \\frac{1}{2}\\left(\\frac{1}{d}\\sum_{k=1}^{d} X_{i-k}(C; w, \\varepsilon) + \\frac{1}{d}\\sum_{k=1}^{d} X_{i+k}(C; w, \\varepsilon)\\right) - X_i(C; w, \\varepsilon)$。\n- 一个索引 $i$ 有资格进行测试，当且仅当 $i - d \\ge w - 1$ 和 $i + d \\le N - 1 - w$。\n- 对于 $R$ 份耗尽前矩阵 $\\{C^{\\text{pre}}_r\\}_{r=1}^{R}$ 和耗尽后矩阵 $\\{C^{\\text{post}}_r\\}_{r=1}^{R}$ 的匹配重复样本，配对差异为 $D_{i,r} \\equiv B_i\\!\\left(C^{\\text{post}}_r\\right) - B_i\\!\\left(C^{\\text{pre}}_r\\right)$。\n- 对每个合格索引 $i$ 的差异 $\\{D_{i,r}\\}_{r=1}^R$ 进行单侧配对 $t$ 检验，以检验原假设 $H_0: \\mu_i \\ge 0$ 与备择假设 $H_1: \\mu_i < 0$。\n- 检验统计量是 $t_i \\equiv \\frac{\\bar{D}_i}{s_i / \\sqrt{R}}$，其中 $\\bar{D}_i$ 和 $s_i$ 是样本均值和样本标准差。\n- $p$ 值 $p_i$ 是根据学生 $t$ 分布的累积分布函数 $F_{t_{R-1}}(t_i)$ 计算的，并对 $s_i=0$ 的情况进行特殊处理。\n- 使用 Benjamini–Hochberg 程序在伪发现率 $\\alpha$ 下对 $m$ 个合格索引进行多重假设检验校正，具体规则是找到 $k^\\star \\equiv \\max\\left\\{ k \\in \\{1,\\dots,m\\} \\,\\middle|\\, p_{(k)} \\le \\frac{k}{m}\\alpha \\right\\}$ 并拒绝所有满足 $p_i \\le p_{(k^\\star)}$ 的假设。\n- 提供了三个具体的测试用例，包含所有参数和数据生成规则。\n\n### 步骤2：使用提取的已知信息进行验证\n根据既定标准对问题进行评估：\n- **科学依据充分：** 该问题植根于染色体结构的既定生物学背景。Cohesin 蛋白复合体被认为是拓扑关联结构域（TADs）的主要驱动因素。“绝缘分数”或“边界强度”的概念是利用染色体构象捕获数据（如 Hi-C）量化 TAD 边界的标准方法。Cohesin 耗尽会削弱这些边界（即降低其强度）的假设是该领域的核心信条。所提供的公式是对这些概念的合理且明确的形式化表述。\n- **定义明确且客观：** 该问题在数学上是严谨的。所有术语都通过精确的公式进行了明确定义。统计程序，包括对边缘情况（$s_i=0$）的处理和多重检验校正，都得到了无歧义的规定。该问题以客观、正式的语言陈述。\n- **完整性与一致性：** 该问题是自洽的。每个测试用例都包含所有必要的参数（$N, R, \\mathcal{I}, w, d, \\varepsilon, \\alpha$）以及用于构建输入矩阵的明确指令。不存在内部矛盾。\n\n### 步骤3：结论与行动\n问题陈述是**有效的**。这是一个定义明确、科学合理且计算上可行的问题。将提供一个解决方案。\n\n### 基于原则的解决方案设计\n任务是实现指定的计算流程，以确定在多种测试场景下，Cohesin 耗尽后强度显著下降的基因组边界数量。通过系统地实现所提供的定义来构建解决方案。\n\n1.  **资格筛选：** 对每个测试用例，首先筛选候选索引列表 $\\mathcal{I}$，只保留那些有“资格”进行边界强度计算且不会产生边缘伪影的索引 $i$。一个索引 $i$ 合格的条件是它同时满足 $i - d \\ge w - 1$ 和 $i + d \\le N - 1 - w$，其中 $N$ 是矩阵维度，$w$ 是窗口半径，$d$ 是侧翼大小。如果没有合格的索引，该测试用例的分析将终止，显著性发现为零。\n\n2.  **边界强度计算：** 分析的核心是量化边界强度的函数 $B_i(C; w, d, \\varepsilon)$。其计算是分层的：\n    - 首先，对给定的矩阵 $C$、索引 $i$ 和窗口 $w$ 计算跨越总和 $S_i(C; w)$。该总和表示在指定菱形区域内，跨越索引 $i$ 处分割的总接触频率。求和的范围是矩阵元素 $C_{ab}$，其中 $a \\in [\\max(0,\\, i-w+1), i]$ 且 $b \\in [i+1, \\min(N-1,\\, i+w)]$。\n    - 其次，计算稳定化对数跨越值 $X_i(C; w, \\varepsilon) = \\ln(S_i(C; w) + \\varepsilon)$。对数变换可以处理高度偏斜的接触频率，而伪计数 $\\varepsilon$ 确保了对小值或零值的和的数值稳定性。\n    - 最后，边界强度 $B_i$ 计算为侧翼区域的平均对数跨越值与中心对数跨越值之间的差值：$B_i = \\frac{1}{2d} \\sum_{k=1}^{d} (X_{i-k} + X_{i+k}) - X_i$。一个高的正值表示强绝缘（一个好的边界），因为与邻近区域相比，i 处的跨越值较低。\n\n3.  **配对统计检验：** 对每个合格索引 $i$，我们评估在 '前' 和 '后' Cohesin 耗尽条件下边界强度的变化。\n    - 对每个重复样本 $r \\in \\{1,\\dots,R\\}$，计算配对差异 $D_{i,r} = B_i(C^{\\text{post}}_r) - B_i(C^{\\text{pre}}_r)$。$D_{i,r}$ 的负值表示该重复样本的边界强度下降。\n    - 差异集合 $\\{D_{i,r}\\}_{r=1}^R$ 随后进行单侧配对 $t$ 检验。原假设 $H_0: \\mu_i \\ge 0$（平均边界强度无下降）与备择假设 $H_1: \\mu_i < 0$（平均边界强度下降）进行检验。\n    - 计算样本均值 $\\bar{D}_i$ 和样本标准差 $s_i$（自由度为 $R-1$）。\n    - 一个特殊规则处理 $s_i=0$ 的情况：如果 $\\bar{D}_i < 0$, $p_i=0$；如果 $\\bar{D}_i = 0$, $p_i=0.5$；如果 $\\bar{D}_i > 0$, $p_i=1$。\n    - 如果 $s_i > 0$，则计算 $t$ 统计量 $t_i = \\bar{D}_i / (s_i / \\sqrt{R})$，并通过自由度为 $R-1$ 的学生 $t$ 分布的累积分布函数获得 $p$ 值 $p_i = F_{t_{R-1}}(t_i)$。\n\n4.  **多重假设校正：** 所有 $m$ 个合格索引的 $p$ 值集合 $\\{p_i\\}$ 必须进行多重比较校正。在指定的伪发现率 $\\alpha$ 下，应用 Benjamini–Hochberg (BH) 程序。\n    - 将 $m$ 个 p 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n    - 找到满足 $p_{(k^\\star)} \\le \\frac{k^\\star}{m}\\alpha$ 的最大整数 $k^\\star$。\n    - 如果存在这样的 $k^\\star$，显著性阈值被设为 $p_{(k^\\star)}$。最终结果是所有小于或等于此阈值的原始（未排序）p 值 $p_i$ 的数量。如果不存在这样的 $k^\\star$，则不拒绝任何假设，并且计数为零。\n\n这种结构化的、基于原则的方法确保了对指定的生物数据分析问题的正确和稳健的实现。", "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef compute_crossing_sum(C, i, w, N):\n    \"\"\"Computes the crossing-sum S_i(C; w).\"\"\"\n    a_start = max(0, i - w + 1)\n    a_end = i + 1\n    b_start = i + 1\n    b_end = min(N, i + w + 1)\n    \n    # Return 0 if the summation window is empty\n    if a_start >= a_end or b_start >= b_end:\n        return 0.0\n    \n    return np.sum(C[a_start:a_end, b_start:b_end])\n\ndef compute_log_crossing(C, i, w, epsilon, N, memo_X):\n    \"\"\"Computes the stabilized log-crossing X_i, with memoization.\"\"\"\n    # Use tuple (matrix id, index) as key for memoization\n    memo_key = (id(C), i)\n    if memo_key in memo_X:\n        return memo_X[memo_key]\n    \n    s_i = compute_crossing_sum(C, i, w, N)\n    x_i = np.log(s_i + epsilon)\n    memo_X[memo_key] = x_i\n    return x_i\n\ndef compute_boundary_strength(C, i, w, d, epsilon, N, memo_X):\n    \"\"\"Computes the boundary strength B_i.\"\"\"\n    x_i_center = compute_log_crossing(C, i, w, epsilon, N, memo_X)\n    \n    left_flank_sum = 0.0\n    for k in range(1, d + 1):\n        left_flank_sum += compute_log_crossing(C, i - k, w, epsilon, N, memo_X)\n    \n    right_flank_sum = 0.0\n    for k in range(1, d + 1):\n        right_flank_sum += compute_log_crossing(C, i + k, w, epsilon, N, memo_X)\n        \n    avg_flank_log_crossing = (left_flank_sum / d + right_flank_sum / d) / 2.0\n    \n    b_i = avg_flank_log_crossing - x_i_center\n    return b_i\n\ndef process_case(case_data):\n    \"\"\"\n    Processes a single test case from data generation to final count of significant results.\n    \"\"\"\n    N, R, I_candidate, w, d, epsilon, alpha, matrices_pre, matrices_post = case_data\n\n    # Step 1: Filter for eligible indices based on problem constraints\n    eligible_indices = []\n    for i in I_candidate:\n        if (i - d >= w - 1) and (i + d <= N - 1 - w):\n            eligible_indices.append(i)\n    \n    if not eligible_indices:\n        return 0\n\n    p_values_map = {}\n    \n    # Step 2: For each eligible index, perform the paired t-test\n    memo_X = {} # Memoization for log-crossing values, reset for each case\n    for i in eligible_indices:\n        D_i_r = []\n        for r in range(R):\n            C_pre = matrices_pre[r]\n            C_post = matrices_post[r]\n            \n            B_pre = compute_boundary_strength(C_pre, i, w, d, epsilon, N, memo_X)\n            B_post = compute_boundary_strength(C_post, i, w, d, epsilon, N, memo_X)\n            \n            D_i_r.append(B_post - B_pre)\n        \n        D_i_r_array = np.array(D_i_r)\n        mean_D = np.mean(D_i_r_array)\n        std_D = np.std(D_i_r_array, ddof=1) if R > 1 else 0.0\n        \n        p_i = 0.0\n        if std_D == 0:\n            if mean_D < 0:\n                p_i = 0.0\n            elif mean_D == 0:\n                p_i = 0.5\n            else: # mean_D > 0\n                p_i = 1.0\n        else:\n            t_stat = mean_D / (std_D / np.sqrt(R))\n            p_i = stats.t.cdf(t_stat, df=R - 1)\n        \n        p_values_map[i] = p_i\n\n    # Step 3: Apply Benjamini-Hochberg correction\n    m = len(eligible_indices)\n    original_p_values = list(p_values_map.values())\n    sorted_p_values = sorted(original_p_values)\n    \n    k_star_val = 0\n    p_thresh = -1.0\n    \n    for k in range(m, 0, -1):\n        if sorted_p_values[k-1] <= (k / m) * alpha:\n            k_star_val = k\n            p_thresh = sorted_p_values[k-1]\n            break\n            \n    if k_star_val == 0:\n        return 0\n    else:\n        significant_count = sum(1 for p in original_p_values if p <= p_thresh)\n        return significant_count\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the analysis, and print results.\n    \"\"\"\n    test_cases_data = []\n\n    # Test Case 1 Definition\n    N1, R1, I1, w1, d1, eps1, alpha1 = 8, 4, [3, 1, 6], 2, 1, 1e-6, 0.1\n    mats_pre1, mats_post1 = [], []\n    baseline1 = np.full((N1, N1), 10.0)\n    np.fill_diagonal(baseline1, 0)\n    pre_mod_vals1 = [2.0, 3.0, 2.5, 3.5]\n    post_mod_vals1 = [20.0, 19.0, 18.0, 21.0]\n    mod_cells1 = [(2, 4), (2, 5), (3, 4), (3, 5)]\n    for r in range(R1):\n        C_pre = baseline1.copy()\n        C_post = baseline1.copy()\n        for i_mod, j_mod in mod_cells1:\n            C_pre[i_mod, j_mod] = C_pre[j_mod, i_mod] = pre_mod_vals1[r]\n            C_post[i_mod, j_mod] = C_post[j_mod, i_mod] = post_mod_vals1[r]\n        mats_pre1.append(C_pre)\n        mats_post1.append(C_post)\n    test_cases_data.append((N1, R1, I1, w1, d1, eps1, alpha1, mats_pre1, mats_post1))\n    \n    # Test Case 2 Definition\n    N2, R2, I2, w2, d2, eps2, alpha2 = 7, 3, [1, 5, 3], 2, 2, 1e-6, 0.2\n    mat2 = np.full((N2, N2), 10.0)\n    np.fill_diagonal(mat2, 0)\n    mats_pre2 = [mat2.copy() for _ in range(R2)]\n    mats_post2 = [mat2.copy() for _ in range(R2)]\n    test_cases_data.append((N2, R2, I2, w2, d2, eps2, alpha2, mats_pre2, mats_post2))\n\n    # Test Case 3 Definition\n    N3, R3, I3, w3, d3, eps3, alpha3 = 6, 4, [2, 3], 1, 1, 1e-6, 0.05\n    baseline3 = np.full((N3, N3), 5.0)\n    np.fill_diagonal(baseline3, 0)\n    C_post3 = baseline3.copy()\n    C_post3[3, 4] = C_post3[4, 3] = 1.0\n    mats_pre3 = [baseline3.copy() for _ in range(R3)]\n    mats_post3 = [C_post3.copy() for _ in range(R3)]\n    test_cases_data.append((N3, R3, I3, w3, d3, eps3, alpha3, mats_pre3, mats_post3))\n    \n    results = [process_case(case) for case in test_cases_data]\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2964851"}]}