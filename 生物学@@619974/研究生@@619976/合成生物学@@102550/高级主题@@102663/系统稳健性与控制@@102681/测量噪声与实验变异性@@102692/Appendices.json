{"hands_on_practices": [{"introduction": "在定量生物学中，许多关键量不是直接测量的，而是通过几个基础测量值计算得出的。本实践介绍了误差传播的基本原理，让您能够根据其输入的不确定性来估计衍生量的不确定性。您将学习构建一个“不确定性预算”，这是一个关键工具，用于识别实验中主要的噪声来源，并指导如何提高测量精度 [@problem_id:2749348]。", "problem": "考虑一个合成生物学中的高通量荧光分析，其中启动子的活性以相对于参考的校准后倍数变化来报告。所报告的量是四个联合分布随机变量 $X = (I_s, I_r, B, k)$ 的函数 $Q$，定义为\n$$\nQ = \\frac{k\\,(I_s - B)}{I_r - B},\n$$\n其中 $I_s$ 是样本的仪器报告平均强度，$I_r$ 是参考的仪器报告平均强度，$B$ 是在同一次运行中测量的背景偏移，$k$ 是一个将任意单位映射到归一化标度的校准因子。假设 $(I_s, I_r, B, k)$ 在其均值 $\\mu = (\\mu_s, \\mu_r, \\mu_b, k_0)$ 附近可以很好地近似为联合高斯分布，其标准差为 $\\sigma = (\\sigma_s, \\sigma_r, \\sigma_b, \\sigma_k)$。假设 $I_s$ 和 $I_r$ 的相关系数为 $\\rho$，并且 $B$ 和 $k$ 与 $(I_s, I_r)$ 相互独立，也彼此独立。您可以假设在所有测试案例中 $\\mu_r > \\mu_b$ 且 $\\mu_s > \\mu_b$，以保证分母在线性化点为正。\n\n任务1（推导）：仅从方差和协方差的定义、通过一阶泰勒展开进行线性化以及线性变换的协方差传播的第一性原理出发，推导出 $\\mathrm{Var}(Q)$ 的一阶近似，用在均值 $\\mu$ 处计算的 $Q$ 的梯度和 $X$ 的协方差矩阵来表示。将梯度分量明确表示为 $Q$ 对 $I_s$、$I_r$、$B$ 和 $k$ 的偏导数，并在 $(\\mu_s, \\mu_r, \\mu_b, k_0)$ 处计算。不要调用任何现成的“捷径”公式；而是根据期望、方差、协方差和一阶泰勒近似的定义来构建结果。\n\n任务2（不确定度预算）：使用任务1中的线性化方差，将总近似方差表示为可归因于 $I_s$、$I_r$、$B$ 和 $k$ 的边际方差以及 $I_s$ 和 $I_r$ 之间协方差的贡献之和。将每一项的分数贡献定义为该项除以总近似方差。注意，协方差贡献可以为负；请以带符号的小数形式报告。将标准不确定度 $u_Q$ 定义为总近似方差的正平方根。\n\n任务3（计算与报告）：对于下面测试套件中的每一组参数，计算 $u_Q$ 以及对应于 $I_s$、$I_r$、$B$、$k$ 和 $I_s$ 与 $I_r$ 之间协方差的各项的分数贡献。对于每种情况，按 $[u_Q, f_{I_s}, f_{I_r}, f_B, f_k, f_{\\mathrm{cov}}]$ 的顺序输出一个包含六个浮点数的列表，其中每个 $f_{\\cdot}$ 是在任务2中定义的分数贡献。将每个值四舍五入到六位小数。\n\n测试套件（每种情况以 $(\\mu_s, \\sigma_s, \\mu_r, \\sigma_r, \\mu_b, \\sigma_b, k_0, \\sigma_k, \\rho)$ 的形式给出）：\n- 情况 A：$(\\mu_s, \\sigma_s, \\mu_r, \\sigma_r, \\mu_b, \\sigma_b, k_0, \\sigma_k, \\rho) = (10000, 300, 8000, 250, 500, 50, 1.0, 0.02, 0.6)$。\n- 情况 B（分母差值小）：$(\\mu_s, \\sigma_s, \\mu_r, \\sigma_r, \\mu_b, \\sigma_b, k_0, \\sigma_k, \\rho) = (700, 30, 600, 30, 500, 20, 1.0, 0.05, 0.6)$。\n- 情况 C（无相关性，精确背景）：$(\\mu_s, \\sigma_s, \\mu_r, \\sigma_r, \\mu_b, \\sigma_b, k_0, \\sigma_k, \\rho) = (9500, 400, 9000, 400, 0, 0, 0.8, 0.01, 0.0)$。\n- 情况 D（强正相关）：$(\\mu_s, \\sigma_s, \\mu_r, \\sigma_r, \\mu_b, \\sigma_b, k_0, \\sigma_k, \\rho) = (12000, 600, 11000, 600, 400, 80, 1.2, 0.03, 0.95)$。\n\n最终输出格式：您的程序应生成单行输出，包含一个Python风格的列表，内含四个子列表，按A、B、C、D的顺序排列。每个子列表必须是 $[u_Q, f_{I_s}, f_{I_r}, f_B, f_k, f_{\\mathrm{cov}}]$ 的形式，每个条目均四舍五入到六位小数。例如，一个包含两个假设情况的输出可能看起来像 $[[x_{11}, x_{12}, x_{13}, x_{14}, x_{15}, x_{16}],[x_{21}, x_{22}, x_{23}, x_{24}, x_{25}, x_{26}]]$，其中每个 $x_{ij}$ 是一个四舍五入到六位的小数。无需物理单位；报告纯数字。不涉及角度。不得使用百分比；分数贡献必须是小数。", "solution": "我们从第一性原理开始。设 $X = (I_s, I_r, B, k)^{\\top}$ 为一个随机向量，其均值为 $\\mu = (\\mu_s, \\mu_r, \\mu_b, k_0)^{\\top}$，协方差矩阵为 $\\Sigma$。考虑标量函数\n$$\nQ(X) = \\frac{k\\,(I_s - B)}{I_r - B}.\n$$\n通过对 $Q$ 在均值 $\\mu$ 附近的一阶泰勒展开（线性化），我们有\n$$\nQ(X) \\approx Q(\\mu) + \\nabla Q(\\mu)^{\\top} (X - \\mu),\n$$\n其中 $\\nabla Q(\\mu)$ 是在 $\\mu$ 处计算的 $Q$ 的梯度。对两边取方差，并使用线性变换的方差和协方差定义，即对于常数向量 $a$ 和协方差为 $\\Sigma$ 的随机向量 $X$，我们有 $\\mathrm{Var}(a^{\\top}X) = a^{\\top}\\Sigma a$，从而得到一阶（德尔塔方法）近似\n$$\n\\mathrm{Var}(Q) \\approx \\nabla Q(\\mu)^{\\top} \\,\\Sigma\\, \\nabla Q(\\mu).\n$$\n\n接下来需要计算梯度分量。定义 $N = I_s - B$ 和 $D = I_r - B$，则 $Q = k\\,N/D$。使用商法则和链式法则，在计算偏导数时保持其他变量不变，我们得到\n$$\n\\frac{\\partial Q}{\\partial k} = \\frac{N}{D},\n\\qquad\n\\frac{\\partial Q}{\\partial I_s} = \\frac{k}{D},\n\\qquad\n\\frac{\\partial Q}{\\partial I_r} = -\\,\\frac{k\\,N}{D^2},\n\\qquad\n\\frac{\\partial Q}{\\partial B} = k\\,\\frac{N - D}{D^2}.\n$$\n在均值点 $(\\mu_s, \\mu_r, \\mu_b, k_0)$ 处求值，得到 $N_0 = \\mu_s - \\mu_b$，$D_0 = \\mu_r - \\mu_b$，以及梯度向量\n$$\ng = \\nabla Q(\\mu) =\n\\begin{bmatrix}\n\\frac{\\partial Q}{\\partial I_s} \\\\\n\\frac{\\partial Q}{\\partial I_r} \\\\\n\\frac{\\partial Q}{\\partial B} \\\\\n\\frac{\\partial Q}{\\partial k}\n\\end{bmatrix}_{\\mu}\n=\n\\begin{bmatrix}\n\\frac{k_0}{D_0} \\\\\n-\\,\\frac{k_0\\,N_0}{D_0^2} \\\\\nk_0\\,\\frac{N_0 - D_0}{D_0^2} \\\\\n\\frac{N_0}{D_0}\n\\end{bmatrix}.\n$$\n\n在所述假设下，协方差矩阵 $\\Sigma$ 具有以下非零项：$\\mathrm{Var}(I_s) = \\sigma_s^2$，$\\mathrm{Var}(I_r) = \\sigma_r^2$，$\\mathrm{Var}(B) = \\sigma_b^2$，$\\mathrm{Var}(k) = \\sigma_k^2$，以及 $\\mathrm{Cov}(I_s, I_r) = \\rho\\,\\sigma_s\\,\\sigma_r$。所有涉及 $B$ 或 $k$ 与其他变量的协方差均为零，并且根据定义，$\\mathrm{Cov}(I_s, I_s) = \\sigma_s^2$，$\\mathrm{Cov}(I_r, I_r) = \\sigma_r^2$，$\\mathrm{Cov}(B, B) = \\sigma_b^2$，$\\mathrm{Cov}(k, k) = \\sigma_k^2$。\n\n因此，代入二次型可得\n$$\n\\mathrm{Var}(Q) \\approx\n\\left(\\frac{\\partial Q}{\\partial I_s}\\right)^{2}\\sigma_s^{2}\n+\n\\left(\\frac{\\partial Q}{\\partial I_r}\\right)^{2}\\sigma_r^{2}\n+\n\\left(\\frac{\\partial Q}{\\partial B}\\right)^{2}\\sigma_b^{2}\n+\n\\left(\\frac{\\partial Q}{\\partial k}\\right)^{2}\\sigma_k^{2}\n+\n2\\left(\\frac{\\partial Q}{\\partial I_s}\\right)\\left(\\frac{\\partial Q}{\\partial I_r}\\right)\\mathrm{Cov}(I_s, I_r).\n$$\n此表达式是双线性形式 $g^{\\top}\\Sigma g$ 以及 $\\Sigma$ 的指定稀疏性的直接应用。标准不确定度则定义为\n$$\nu_Q = \\sqrt{\\mathrm{Var}(Q)}.\n$$\n\n对于不确定度预算，定义以下可加贡献：\n$$\nT_{I_s} = \\left(\\frac{\\partial Q}{\\partial I_s}\\right)^{2}\\sigma_s^{2},\\quad\nT_{I_r} = \\left(\\frac{\\partial Q}{\\partial I_r}\\right)^{2}\\sigma_r^{2},\\quad\nT_{B} = \\left(\\frac{\\partial Q}{\\partial B}\\right)^{2}\\sigma_b^{2},\\quad\nT_{k} = \\left(\\frac{\\partial Q}{\\partial k}\\right)^{2}\\sigma_k^{2},\\quad\nT_{\\mathrm{cov}} = 2\\left(\\frac{\\partial Q}{\\partial I_s}\\right)\\left(\\frac{\\partial Q}{\\partial I_r}\\right)\\rho\\,\\sigma_s\\,\\sigma_r.\n$$\n总和为\n$$\nT_{\\mathrm{tot}} = T_{I_s} + T_{I_r} + T_{B} + T_{k} + T_{\\mathrm{cov}},\n$$\n并且在 $T_{\\mathrm{tot}} > 0$ 的条件下，$u_Q = \\sqrt{T_{\\mathrm{tot}}}$。分数贡献则定义为\n$$\nf_{I_s} = \\frac{T_{I_s}}{T_{\\mathrm{tot}}},\\quad\nf_{I_r} = \\frac{T_{I_r}}{T_{\\mathrm{tot}}},\\quad\nf_{B} = \\frac{T_{B}}{T_{\\mathrm{tot}}},\\quad\nf_{k} = \\frac{T_{k}}{T_{\\mathrm{tot}}},\\quad\nf_{\\mathrm{cov}} = \\frac{T_{\\mathrm{cov}}}{T_{\\mathrm{tot}}}.\n$$\n注意 $f_{\\mathrm{cov}}$ 可以为负，特别是当 $\\rho > 0$ 时，因为对于 $N_0, D_0, k_0 > 0$，有 $\\frac{\\partial Q}{\\partial I_s} > 0$ 和 $\\frac{\\partial Q}{\\partial I_r} < 0$，这使得 $T_{\\mathrm{cov}}$ 为负，并可能减少总方差。\n\n针对每种情况的算法步骤：\n1.  计算 $N_0 = \\mu_s - \\mu_b$ 和 $D_0 = \\mu_r - \\mu_b$。\n2.  计算在 $\\mu$ 处的梯度分量：$\\frac{\\partial Q}{\\partial I_s} = k_0/D_0$，$\\frac{\\partial Q}{\\partial I_r} = -k_0 N_0/D_0^2$，$\\frac{\\partial Q}{\\partial B} = k_0 (N_0 - D_0)/D_0^2$，$\\frac{\\partial Q}{\\partial k} = N_0/D_0$。\n3.  使用给定的标准差和 $\\rho$ 计算五个贡献 $T_{I_s}$、$T_{I_r}$、$T_{B}$、$T_{k}$、$T_{\\mathrm{cov}}$。\n4.  求和得到 $T_{\\mathrm{tot}}$，然后得到 $u_Q = \\sqrt{T_{\\mathrm{tot}}}$，并通过将每个 $T_{\\cdot}$ 除以 $T_{\\mathrm{tot}}$ 来计算分数贡献 $f_{\\cdot}$。\n5.  将 $u_Q$ 和所有的 $f_{\\cdot}$ 四舍五入到六位小数，并按指定顺序报告。\n\n将此过程应用于所提供的测试套件，即可得到所需输出。只要 $D_0$ 不太小，并且参数集满足 $\\mu_r > \\mu_b$ 和 $\\mu_s > \\mu_b$（这已由测试套件保证），计算过程就是数值稳定的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_uncertainty_and_budget(mu_s, sigma_s, mu_r, sigma_r, mu_b, sigma_b, k0, sigma_k, rho):\n    # Compute N0 and D0\n    N0 = mu_s - mu_b\n    D0 = mu_r - mu_b\n\n    # Gradient components at the mean\n    dQ_dIs = k0 / D0\n    dQ_dIr = -k0 * N0 / (D0 ** 2)\n    dQ_dB  = k0 * (N0 - D0) / (D0 ** 2)\n    dQ_dk  = N0 / D0\n\n    # Variances and covariance\n    var_Is = sigma_s ** 2\n    var_Ir = sigma_r ** 2\n    var_B  = sigma_b ** 2\n    var_k  = sigma_k ** 2\n    cov_IsIr = rho * sigma_s * sigma_r\n\n    # Contributions\n    T_Is  = (dQ_dIs ** 2) * var_Is\n    T_Ir  = (dQ_dIr ** 2) * var_Ir\n    T_B   = (dQ_dB  ** 2) * var_B\n    T_k   = (dQ_dk  ** 2) * var_k\n    T_cov = 2.0 * dQ_dIs * dQ_dIr * cov_IsIr\n\n    T_tot = T_Is + T_Ir + T_B + T_k + T_cov\n\n    # Numerical guard: total variance should be non-negative; clamp tiny negatives to zero due to rounding\n    if T_tot < 0 and abs(T_tot) < 1e-15:\n        T_tot = 0.0\n    if T_tot <= 0:\n        # In pathological cases (not expected in the test suite), return zeros\n        u_Q = 0.0\n        f_Is = f_Ir = f_B = f_k = f_cov = 0.0\n    else:\n        u_Q = np.sqrt(T_tot)\n        f_Is  = T_Is  / T_tot\n        f_Ir  = T_Ir  / T_tot\n        f_B   = T_B   / T_tot\n        f_k   = T_k   / T_tot\n        f_cov = T_cov / T_tot\n\n    return u_Q, f_Is, f_Ir, f_B, f_k, f_cov\n\ndef fmt6(x: float) -> str:\n    s = f\"{x:.6f}\"\n    # Normalize negative zero to zero\n    if s == \"-0.000000\":\n        s = \"0.000000\"\n    return s\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (mu_s, sigma_s, mu_r, sigma_r, mu_b, sigma_b, k0, sigma_k, rho)\n    test_cases = [\n        (10000.0, 300.0, 8000.0, 250.0, 500.0, 50.0, 1.0, 0.02, 0.6),   # Case A\n        (700.0,   30.0,  600.0,  30.0,  500.0, 20.0, 1.0, 0.05, 0.6),   # Case B\n        (9500.0,  400.0, 9000.0, 400.0, 0.0,   0.0,  0.8, 0.01, 0.0),   # Case C\n        (12000.0, 600.0, 11000.0,600.0, 400.0, 80.0, 1.2, 0.03, 0.95),  # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        mu_s, sigma_s, mu_r, sigma_r, mu_b, sigma_b, k0, sigma_k, rho = case\n        u_Q, f_Is, f_Ir, f_B, f_k, f_cov = compute_uncertainty_and_budget(\n            mu_s, sigma_s, mu_r, sigma_r, mu_b, sigma_b, k0, sigma_k, rho\n        )\n        # Round and format to six decimals as strings\n        formatted = [\n            fmt6(u_Q),\n            fmt6(f_Is),\n            fmt6(f_Ir),\n            fmt6(f_B),\n            fmt6(f_k),\n            fmt6(f_cov),\n        ]\n        results.append(f\"[{','.join(formatted)}]\")\n\n    # Final print statement in the exact required format: single line with list of sublists.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2749348"}, {"introduction": "在理解了如何传播已知误差之后，一个核心任务是直接根据实验数据（尤其是单细胞测量数据）对噪声结构进行建模。本练习将指导您拟合并比较三种典型的计数数据统计模型——泊松（Poisson）模型、负二项（Negative Binomial）模型和零膨胀泊松（Zero-Inflated Poisson）模型，它们分别对应于不同的生物学和技术噪声来源。通过应用最大似然估计（Maximum Likelihood Estimation）和赤池信息准则（Akaike Information Criterion），您将掌握选择最佳模型来描述数据变异性的关键技能，这是严谨定量分析的基石 [@problem_id:2749367]。", "problem": "您正在分析来自合成基因回路的单细胞信使核糖核酸 (mRNA) 计数测量数据。每个数据集由在固定条件下测量的细胞的独立同分布的非负整数计数组成。测量噪声和生物变异性可以使用已有的离散分布进行建模：用于描述内在生灭噪声的泊松模型、用于描述源于细胞间变异的过度离散的负二项 (NB) 模型，以及用于描述源于基因非活性亚群或测量丢失的结构性零值的零膨胀泊松 (ZIP) 模型。您必须仅从核心概率定义（概率质量函数、重复样本的独立性和混合建模）和关于使用基于似然的标准进行模型选择的经过充分检验的事实出发，构建最大似然估计，比较模型，并报告噪声的标量摘要。\n\n使用的基本原则：\n- 将每个细胞的计数视为一个非负整数值随机变量的独立实现。\n- 泊松模型假定一个单一的率参数 $\\lambda$。\n- 负二项 (NB) 模型假定一个均值-过度离散表示法，其中均值为 $\\mu$，离散 (大小) 参数为正数 $r$，使得方差超过均值。\n- 零膨胀泊松 (ZIP) 模型是一个双组分混合模型，具有结构性零概率 $\\pi$ 和一个率参数为 $\\lambda$ 的泊松分量，其产生的零值或为结构性零，或来自泊松分量。\n- 使用最大似然估计 (MLE) 从观测到的计数中为每个模型估计参数。\n- 使用根据最大化对数似然和自由参数数量 $k$ 定义的赤池信息准则 (AIC)，为每个数据集选择 AIC 最小的模型。\n- 选择模型后，通过变异系数的平方 $\\mathrm{CV}^2$ 来总结噪声，其定义为 $\\mathrm{Var}(X)/[\\mathbb{E}(X)]^2$，并在选定模型及其 MLE 下进行计算。\n\n您的程序必须为每个数据集实现以下任务：\n- 直接根据模型定义和重复样本的独立性假设，为三种模型（泊松、NB、ZIP）中的每一种构建似然函数。不要假定任何不能从这些定义中推导出的结果。\n- 计算每个模型的 MLE，若有闭合形式解则使用，否则通过数值最大化方法，并遵守模型定义所隐含的参数约束。\n- 使用自由参数数量 $k$（泊松模型 $k$ 为 $1$，负二项模型为 $2$，零膨胀泊松模型为 $2$）计算最大化对数似然和赤池信息准则 (AIC)。\n- 选择 AIC 最小的模型。\n- 使用所选模型的拟合参数，计算模型所隐含的变异系数的平方 $\\mathrm{CV}^2$。\n\n约束和实现要求：\n- 将所有数据集视为无单位的计数。不涉及物理单位。\n- 不使用角度。\n- 所有最终数值输出必须四舍五入到 $6$ 位小数。\n- 对于每个数据集，生成一对 $[m, c]$，其中 $m$ 是所选模型的整数代码，c 是四舍五入后的 $\\mathrm{CV}^2$：\n  - $m = 0$ 代表泊松模型，\n  - $m = 1$ 代表负二项模型，\n  - $m = 2$ 代表零膨胀泊松模型。\n- 您的程序应生成单行输出，其中包含一个由这些按数据集生成的结果组成的、以逗号分隔的列表，并用方括号括起来，例如：$[[m_1,c_1],[m_2,c_2],\\ldots]$。\n\n测试套件 (数据集)：\n- 数据集 $1$ (典型的内在噪声): $[8,12,9,11,10,7,13,10,9,11,8,12,10,9,11]$。\n- 数据集 $2$ (过度离散但无明显零膨胀): $[0,3,2,25,18,7,0,15,12,30,4,6,21,9,11,17,5]$。\n- 数据集 $3$ (显著的零膨胀): $[0,0,0,0,0,0,0,0,0,0,0,0,6,4,7,3,5,8,2,6]$。\n- 数据集 $4$ (罕见表达的边界情况): $[0,0,0,0,0,1,0,0,0,1]$。\n\n最终输出格式：\n- 您的程序必须打印单行，其中包含一个由 $4$ 个列表组成的列表，每个数据集一个，顺序与上文完全一致。每个内部列表必须是 $[m,c]$，其中 $m$ 的定义如上，c 等于所选模型的 $\\mathrm{CV}^2$ 并四舍五入到 $6$ 位小数。例如，一个有效的输出看起来像 $[[0,0.123456],[1,3.141593],[2,0.271828],[2,42.000000]]$。", "solution": "该问题要求对单细胞 mRNA 计数数据进行严格的统计分析。目标是从三个候选模型——泊松、负二项 (NB) 和零膨胀泊松 (ZIP) ——中为四个数据集中的每一个识别最合适的统计模型，并使用选定的模型量化基础过程的噪声。这项任务是最大似然估计 (MLE) 和基于信息论的模型选择的标准应用。整个过程将从概率论和统计学的基本原理推导出来。\n\n设一个计数数据集表示为 $D = \\{x_1, x_2, \\ldots, x_n\\}$，代表一个随机变量 $X$ 的 $n$ 个独立同分布 (i.i.d.) 的观测值。\n\n**1. 模型定义和似然函数**\n\n分析的基础是构建似然函数 $L(\\theta | D)$，它是在给定模型参数 $\\theta$ 的情况下观测到数据 $D$ 的联合概率。由于 i.i.d. 假设，似然是单个概率质量函数 (PMF) 的乘积：$L(\\theta | D) = \\prod_{i=1}^{n} P(X=x_i | \\theta)$。为了计算稳定性和数学上的便利，我们使用对数似然 $\\ln L(\\theta | D) = \\sum_{i=1}^{n} \\ln P(X=x_i | \\theta)$。\n\n*   **泊松模型**：该模型由单个率参数 $\\lambda > 0$ 定义，该参数代表分布的均值和方差。其 PMF 为：\n    $$ P(X=k | \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\n    在泊松模型下，数据集 $D$ 的对数似然函数为：\n    $$ \\ln L(\\lambda | D) = \\sum_{i=1}^{n} (x_i \\ln \\lambda - \\lambda - \\ln(x_i!)) = (\\ln \\lambda) \\sum_{i=1}^{n} x_i - n\\lambda - \\sum_{i=1}^{n} \\ln(x_i!) $$\n\n*   **负二项 (NB) 模型**：NB 模型能适应过度离散（方差大于均值）的情况。这里它由其均值 $\\mu > 0$ 和一个正的离散参数 $r > 0$ 进行参数化。方差由 $\\mathrm{Var}(X) = \\mu + \\mu^2/r$ 给出。PMF 从标准的 $(r, p)$ 参数化推导而来，其中 $p = r/(r+\\mu)$：\n    $$ P(X=k | \\mu, r) = \\frac{\\Gamma(k+r)}{k!\\Gamma(r)} \\left(\\frac{r}{r+\\mu}\\right)^r \\left(\\frac{\\mu}{r+\\mu}\\right)^k $$\n    其中 $\\Gamma(\\cdot)$ 是伽马函数。对数似然为：\n    $$ \\ln L(\\mu, r | D) = \\sum_{i=1}^{n} \\left[ \\ln\\Gamma(x_i+r) - \\ln\\Gamma(r) - \\ln(x_i!) + r\\ln\\left(\\frac{r}{r+\\mu}\\right) + x_i\\ln\\left(\\frac{\\mu}{r+\\mu}\\right) \\right] $$\n\n*   **零膨胀泊松 (ZIP) 模型**：这是一个双组分混合模型，用于处理具有过多零计数的数据集。它由一个泊松率 $\\lambda > 0$ 和一个零膨胀概率 $0 \\le \\pi < 1$ 进行参数化。观测到零的概率为 $\\pi$（来自“结构性零”过程），或为 $(1-\\pi)e^{-\\lambda}$（来自泊松过程）。\n    其 PMF 为：\n    $$\n    P(X=k | \\pi, \\lambda) = \n    \\begin{cases} \n    \\pi + (1-\\pi)e^{-\\lambda} & \\text{若 } k=0 \\\\\n    (1-\\pi)\\frac{\\lambda^k e^{-\\lambda}}{k!} & \\text{若 } k > 0\n    \\end{cases}\n    $$\n    设 $n_0$ 为零计数的数量，$D_{>0}$ 为数据集中的非零计数。对数似然为：\n    $$ \\ln L(\\pi, \\lambda | D) = n_0 \\ln(\\pi + (1-\\pi)e^{-\\lambda}) + \\sum_{x_i \\in D_{>0}} \\ln\\left((1-\\pi)\\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!}\\right) $$\n\n**2. 最大似然估计 (MLE)**\n\nMLE 的原则指导我们寻找使对数似然函数 $\\ln L(\\theta | D)$ 最大化的参数值 $\\hat{\\theta}_{MLE}$。\n\n*   对于**泊松**模型，$\\lambda$ 的 MLE 通过将对数似然的导数设为零来找到，这会得出一个闭合形式的解：\n    $$ \\frac{\\partial \\ln L}{\\partial \\lambda} = \\frac{1}{\\lambda}\\sum_{i=1}^{n}x_i - n = 0 \\implies \\hat{\\lambda}_{MLE} = \\frac{1}{n}\\sum_{i=1}^{n}x_i = \\bar{x} $$\n    MLE 是样本均值。\n\n*   对于 **NB** 和 **ZIP** 模型，不存在通用的 MLE 闭合形式解。因此，我们必须借助数值方法来最大化对数似然函数，同时遵守参数约束（$\\mu, r, \\lambda > 0$ 和 $0 \\le \\pi < 1$）。我们将使用拟牛顿算法，特别是 L-BFGS-B，来最小化负对数似然，该算法能有效处理箱式约束。\n\n**3. 模型选择**\n\n为了比较具有不同参数数量的模型，我们使用赤池信息准则 (AIC)。AIC 提供了模型质量的相对度量，它在拟合优度（最大化的对数似然）和模型复杂度（自由参数的数量 $k$）之间进行权衡。AIC 最低的模型是首选。\n$$ \\mathrm{AIC} = 2k - 2\\ln L(\\hat{\\theta}_{MLE} | D) $$\n每个模型的自由参数数量指定如下：\n*   泊松：$k=1$ (参数 $\\lambda$)\n*   负二项：$k=2$ (参数 $\\mu, r$)\n*   零膨胀泊松：$k=2$ (参数 $\\pi, \\lambda$)\n\n**4. 噪声量化：变异系数的平方 ($\\mathrm{CV}^2$)**\n\n在选择了最佳拟合模型后，生物噪声通过变异系数的平方来总结，其定义为 $\\mathrm{CV}^2 = \\mathrm{Var}(X) / [\\mathbb{E}(X)]^2$。期望 $\\mathbb{E}(X)$ 和方差 $\\mathrm{Var}(X)$ 使用所选模型的 MLE 参数计算得出。\n\n*   **泊松**：$\\mathbb{E}(X) = \\lambda$, $\\mathrm{Var}(X) = \\lambda$。\n    $$ \\mathrm{CV}^2 = \\frac{\\lambda}{\\lambda^2} = \\frac{1}{\\lambda} $$\n*   **负二项**：$\\mathbb{E}(X) = \\mu$, $\\mathrm{Var}(X) = \\mu + \\mu^2/r$。\n    $$ \\mathrm{CV}^2 = \\frac{\\mu + \\mu^2/r}{\\mu^2} = \\frac{1}{\\mu} + \\frac{1}{r} $$\n*   **零膨胀泊松**：$\\mathbb{E}(X) = (1-\\pi)\\lambda$, $\\mathrm{Var}(X) = (1-\\pi)\\lambda(1+\\pi\\lambda)$。\n    $$ \\mathrm{CV}^2 = \\frac{(1-\\pi)\\lambda(1+\\pi\\lambda)}{((1-\\pi)\\lambda)^2} = \\frac{1+\\pi\\lambda}{(1-\\pi)\\lambda} $$\n\n**5. 计算实现**\n\n所述过程在一个 Python 程序中实现。对于每个数据集，定义函数来计算三种模型中每一种的负对数似然。对于 NB 和 ZIP 模型，使用 `scipy.optimize.minimize` 来找到最小化该函数的参数值。在获得所有模型的 MLE 参数后，计算它们相应的 AIC 值并进行比较，以选择最优模型。最后，使用胜出模型的参数计算 $\\mathrm{CV}^2$。最终结果按指定格式进行格式化。", "answer": "```python\nimport numpy as np\nfrom scipy import optimize\nfrom scipy import special\n\ndef solve():\n    \"\"\"\n    Main solver function to process all datasets and print the final results.\n    \"\"\"\n    test_cases = [\n        [8, 12, 9, 11, 10, 7, 13, 10, 9, 11, 8, 12, 10, 9, 11],\n        [0, 3, 2, 25, 18, 7, 0, 15, 12, 30, 4, 6, 21, 9, 11, 17, 5],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 4, 7, 3, 5, 8, 2, 6],\n        [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n    ]\n\n    results = []\n    for data_list in test_cases:\n        data = np.array(data_list)\n        result = analyze_dataset(data)\n        results.append(result)\n\n    # Format output as a string representation of a list of lists.\n    # Ex: [[0,0.1],[1,0.56789]]\n    output_str = \"[\" + \",\".join([f\"[{m},{c}]\" for m, c in results]) + \"]\"\n    print(output_str)\n\ndef analyze_dataset(data):\n    \"\"\"\n    Analyzes a single dataset: fits all three models, selects the best one via AIC,\n    and computes its CV^2.\n    \"\"\"\n    # Small epsilon to avoid log(0) issues in optimization bounds.\n    epsilon = 1e-9\n\n    # --- Poisson Model ---\n    # Closed-form MLE\n    lambda_mle = np.mean(data)\n    if lambda_mle == 0: # All-zero data case\n        logL_pois = 0\n        cv2_pois = 0.0\n    else:\n        logL_pois = np.sum(\n            data * np.log(lambda_mle) - lambda_mle - special.gammaln(data + 1)\n        )\n        cv2_pois = 1.0 / lambda_mle\n    k_pois = 1\n    aic_pois = 2 * k_pois - 2 * logL_pois\n    \n    # --- Negative Binomial Model ---\n    def neg_logL_nb(params, data):\n        mu, r = params\n        # Use scipy's nbinom logpmf for numerical stability\n        # p = r / (r + mu)\n        # Using log-transformed p to prevent underflow inside logpmf\n        log_p = np.log(r) - np.log(r + mu)\n        # Scipy's nbinom takes n=r and p.\n        logpmf_vals = special.log_ndtr(-log_p * r)\n        # The above is not scipy.stats.nbinom.logpmf but a different function.\n        # Direct implementation is more transparent.\n        if r <= 0 or mu <= 0: return np.inf\n        \n        # log(Gamma(k+r)) - log(k!) - log(Gamma(r))\n        # gammaln(data+r) - gammaln(data+1) - gammaln(r)\n        term1 = special.gammaln(data + r) - special.gammaln(data + 1) - special.gammaln(r)\n        term2 = r * np.log(r) - r * np.log(r + mu)\n        term3 = data * np.log(mu) - data * np.log(r + mu)\n        \n        logL = np.sum(term1 + term2 + term3)\n        return -logL\n\n    # Initial guess using method of moments\n    mean_data = np.mean(data)\n    var_data = np.var(data, ddof=1) if len(data) > 1 else 0\n    mu_init = mean_data if mean_data > 0 else epsilon\n    if var_data > mean_data:\n        r_init = mean_data**2 / (var_data - mean_data)\n    else:\n        # Under-dispersed, NB approaches Poisson, so r is large\n        r_init = 1000.0\n    \n    res_nb = optimize.minimize(\n        neg_logL_nb,\n        x0=[mu_init, r_init],\n        args=(data,),\n        method='L-BFGS-B',\n        bounds=[(epsilon, None), (epsilon, None)]\n    )\n\n    mu_mle_nb, r_mle_nb = res_nb.x\n    logL_nb = -res_nb.fun\n    k_nb = 2\n    aic_nb = 2 * k_nb - 2 * logL_nb\n    cv2_nb = (1.0 / mu_mle_nb) + (1.0 / r_mle_nb)\n\n    # --- Zero-Inflated Poisson Model ---\n    def neg_logL_zip(params, data, n0, non_zeros):\n        pi, lam = params\n        if not (0 <= pi < 1 and lam > 0): return np.inf\n        \n        logL_zeros = n0 * np.log(pi + (1 - pi) * np.exp(-lam))\n        \n        n_pos = len(non_zeros)\n        if n_pos > 0:\n            logL_non_zeros = n_pos * np.log(1 - pi) + \\\n                             np.sum(non_zeros) * np.log(lam) - \\\n                             n_pos * lam - \\\n                             np.sum(special.gammaln(non_zeros + 1))\n        else: # Case of all zeros\n            logL_non_zeros = 0\n            \n        logL = logL_zeros + logL_non_zeros\n        return -logL\n\n    n0 = np.sum(data == 0)\n    non_zeros = data[data > 0]\n\n    # Initial guesses\n    pi_init = n0 / len(data)\n    if len(non_zeros) > 0:\n        lam_init = np.mean(non_zeros)\n    else:\n        lam_init = epsilon # all zeros case\n    \n    # Ensure pi_init is not 1 to avoid log(0)\n    if pi_init >= 1.0:\n        pi_init = 1.0 - epsilon\n\n    res_zip = optimize.minimize(\n        neg_logL_zip,\n        x0=[pi_init, lam_init],\n        args=(data, n0, non_zeros),\n        method='L-BFGS-B',\n        bounds=[(0, 1.0 - epsilon), (epsilon, None)]\n    )\n\n    pi_mle_zip, lam_mle_zip = res_zip.x\n    logL_zip = -res_zip.fun\n    k_zip = 2\n    aic_zip = 2 * k_zip - 2 * logL_zip\n    \n    mean_zip = (1 - pi_mle_zip) * lam_mle_zip\n    if mean_zip > 0 :\n        cv2_zip = ((1 - pi_mle_zip) * lam_mle_zip * (1 + pi_mle_zip * lam_mle_zip)) / mean_zip**2\n    else:\n        cv2_zip = 0.0\n\n    # Model selection\n    models = {\n        'poisson': (0, aic_pois, cv2_pois),\n        'nb': (1, aic_nb, cv2_nb),\n        'zip': (2, aic_zip, cv2_zip)\n    }\n\n    # Handle cases where optimization might fail for NB/ZIP, giving high AIC.\n    # Poisson is always stable.\n    best_model_name = 'poisson'\n    min_aic = aic_pois\n\n    if not res_nb.success: aic_nb = np.inf\n    if not res_zip.success: aic_zip = np.inf\n    \n    if aic_nb < min_aic:\n        min_aic = aic_nb\n        best_model_name = 'nb'\n\n    if aic_zip < min_aic:\n        min_aic = aic_zip\n        best_model_name = 'zip'\n\n    model_code, _, cv2_val = models[best_model_name]\n    \n    return [model_code, round(cv2_val, 6)]\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2749367"}, {"introduction": "虽然统计模型提供了一个强大的框架，但现实世界的数据往往是“混乱的”，可能包含违反模型假设的严重错误或异常值。本实践介绍了稳健估计（robust estimation）的概念，这是一套即使在小部分数据被任意破坏的情况下依然能保持稳定性的技术。您将实现一个均值中位数（median-of-means）估计器，以可靠地计算启动子活性并自动标记异常数据点，确保您的结论不会被实验假象所扭曲 [@problem_id:2749352]。", "problem": "一个人工合成的遗传构建体在一个微生物底盘中驱动一个荧光报告基因。每次重复测量包含一个荧光读数和一个在600纳米波长下的同步光密度（OD600），这两者共同近似了启动子活性，即单位生物量的荧光强度。在实践中，实验变异性包括乘性噪声（例如，增益波动）和罕见的重大误差（例如，移液错误、堵塞或气泡），从而产生一小部分离群值。为在处理离群值的同时稳健地估计启动子活性，考虑采用对数比率模型。在该模型中，每次重复$(i = 1,\\dots,n)$产生一对正实数$(F_i, D_i)$：以等效荧光素分子数（MEFL）为单位的荧光读数$F_i$和一个无量纲的光密度$D_i$。定义对数比率$y_i = \\log F_i - \\log D_i$。假设一个加性污染模型$y_i = \\mu + \\varepsilon_i$，其中$\\mu$是目标位置参数（对数启动子活性），噪声$\\varepsilon_i$主要来自一个轻尾分布，但可能包含一小部分未知的、任意大的离群值。\n\n任务：根据稳健统计学的基本原理，使用均值中位数方法实现一个针对$\\mu$的稳健位置估计器。请按以下步骤操作。\n\n- 将$n$个对数比率$y_i$划分为$B$个不相交的块，这些块保持原始顺序且大小尽可能相等。例如，如果$n = q B + r$且$0 \\le r  B$，则先形成$r$个大小为$q+1$的块，然后是$B-r$个大小为$q$的块。\n- 计算每个块的均值，然后取这$B$个块均值的中位数。这个均值中位数就是估计量$\\widehat{\\mu}$。\n- 使用相对于$\\widehat{\\mu}$的中位数绝对偏差（MAD）来估计尺度：$\\widehat{\\sigma} = c_{\\mathrm{MAD}} \\cdot \\operatorname{median}_i \\left| y_i - \\widehat{\\mu} \\right|$，其中$c_{\\mathrm{MAD}} = 1.4826$以确保与高斯分布的标准差一致。为保证数值稳定性，如果$\\widehat{\\sigma} = 0$，则将其替换为一个小的正值$\\sigma_{\\min} = 10^{-6}$。\n- 通过对稳健残差进行阈值处理来标记离群值：如果$\\left| y_i - \\widehat{\\mu} \\right| > c \\cdot \\widehat{\\sigma}$（其中$c = 3.0$），则重复样本$i$是一个离群值。\n- 以$\\widehat{A} = \\exp\\left(\\widehat{\\mu}\\right)$的形式报告原始尺度上的最终启动子活性，单位为每单位光密度的等效荧光素分子数（MEFL per OD）。同时，以小数形式报告离群值比例$f = \\left(\\text{被标记的重复样本数量}\\right)/n$。\n\n您必须严格按照上述描述实现算法。所有计算必须使用自然对数和指数函数。每个测试用例的最终答案必须是四舍五入到六位小数的浮点数。以MEFL per OD为单位隐式地表示$\\widehat{A}$（不要在输出中附加单位），并以小数形式（而非百分比）表示$f$。\n\n测试套件。对于每个案例，您将获得荧光数组$F$（单位为MEFL）、光密度数组$D$（无量纲）以及块数$B$。\n\n- 案例1（干净的重复样本，中等变异性），$n = 12$，$B = 3$:\n  - $F_1 = [4900, 5100, 5050, 4950, 5150, 4850, 5000, 5250, 4800, 5200, 4750, 5050]$\n  - $D_1 = [0.98, 1.02, 1.01, 0.99, 1.03, 0.97, 1.00, 1.05, 0.96, 1.04, 0.95, 1.00]$\n- 案例2（包含重大离群值的重复样本），$n = 20$，$B = 4$:\n  - $F_2 = [2950, 3050, 3000, 3100, 2900, 3150, 2850, 3200, 3180, 2820, 3050, 20000, 8000, 2000, 100, 2900, 2800, 3300, 3100, 2950]$\n  - $D_2 = [0.98, 1.01, 1.00, 1.02, 0.99, 1.03, 0.97, 1.05, 1.04, 0.96, 1.00, 1.01, 0.20, 1.60, 1.00, 1.02, 0.95, 1.08, 1.10, 0.99]$\n- 案例3（重尾变异性），$n = 25$，$B = 5$:\n  - $F_3 = [12000, 11000, 13000, 12500, 11500, 13500, 11200, 12800, 13200, 11300, 12700, 11800, 13100, 10900, 12900, 12100, 11600, 13300, 11900, 12200, 16000, 8000, 20000, 7000, 12600]$\n  - $D_3 = [1.00, 0.92, 1.08, 1.05, 0.97, 1.10, 0.94, 1.02, 1.06, 0.95, 1.03, 0.99, 1.07, 0.93, 1.04, 1.01, 0.96, 1.09, 0.98, 1.00, 1.12, 0.90, 1.15, 0.88, 1.05]$\n- 案例4（小样本量$n$，两个极端离群值），$n = 7$，$B = 2$:\n  - $F_4 = [4000, 4100, 3900, 4050, 3950, 10000, 100]$\n  - $D_4 = [1.00, 1.02, 0.98, 1.01, 1.00, 0.50, 1.20]$\n\n要求的程序输出。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为：\n$[\\widehat{A}_1, f_1, \\widehat{A}_2, f_2, \\widehat{A}_3, f_3, \\widehat{A}_4, f_4]$，\n每个浮点数都四舍五入到六位小数。不应打印任何其他文本。", "solution": "该问题要求实现一个稳健的统计程序，用于从受到噪声和重大误差影响的实验数据中估计启动子活性。在进行求解之前，必须对问题陈述进行严格的验证。\n\n该问题具有科学依据。使用荧光报告基因和光密度来测量启动子活性是合成生物学中的一项标准技术。对数比率变换$y_i = \\log F_i - \\log D_i$是一种合理的统计方法，可将生物测量中常见的带有乘性误差的模型转换为加性误差模型$y_i = \\mu + \\varepsilon_i$。这种变换能使测量尺度线性化并稳定方差。核心挑战是离群值的存在，对此，稳健统计估计量是正确的理论工具。所提出的均值中位数估计量是一种成熟的方法，以其高崩溃点而闻名，意味着它可以在不失效的情况下容忍相当大比例的离群值。使用中位数绝对偏差（MAD）进行尺度估计也是一种标准的稳健技术，与均值中位数位置估计量互补。\n\n该问题是适定的。它提供了一个明确的、分步的算法，包括所有必要的参数和常量（$c_{\\mathrm{MAD}} = 1.4826$，$\\sigma_{\\min} = 10^{-6}$，$c = 3.0$）。所有测试用例的数据均已提供，并且精确指定了所需的输出格式。该算法是确定性的，确保了唯一解。问题陈述是客观的，没有推测，并且不包含任何科学或逻辑上的矛盾。\n\n因此，该问题被认为是有效的。将根据指定的基本原理构建解决方案。\n\n目标是从对数比率$y_i$中找到位置参数$\\mu$的稳健估计。像样本均值这样的标准估计量是不稳健的，因为单个离群值就可以任意地破坏估计值。均值中位数估计量提供了这种所需的稳健性。\n\n让我们按照指定的算法步骤进行。\n\n**第1步：数据变换**\n对于每次重复$i$测得的荧光$F_i$和光密度$D_i$，我们计算对数比率。比率$A_i = F_i / D_i$代表该次重复的启动子活性。噪声被假定为乘性的。通过取自然对数，我们将问题转换到一个加性噪声域：\n$$\ny_i = \\log(A_i) = \\log(F_i / D_i) = \\log F_i - \\log D_i\n$$\n统计模型是$y_i = \\mu + \\varepsilon_i$，其中$\\mu = \\mathbb{E}[y_i]$是真实的对数启动子活性，$\\varepsilon_i$是噪声项，包含典型的测量波动和罕见的大离群值。\n\n**第2步：分区**\n将$n$个对数比率的集合$\\{y_1, y_2, \\dots, y_n\\}$划分为$B$个不相交的块，同时保持原始序列顺序。设$n = qB + r$，其中$q$是商，$r$是余数（$0 \\le r  B$）。分区规则规定我们先形成$r$个大小为$q+1$的块，然后是$B-r$个大小为$q$的块。这确保了各块的大小尽可能相等。\n\n**第3步：位置的均值中位数估计（$\\widehat{\\mu}$）**\n对于每个块$b \\in \\{1, \\dots, B\\}$，我们计算其包含的$y_i$值的算术平均值。设其为$M_b$。块均值的集合是$\\{M_1, M_2, \\dots, M_B\\}$。那么$\\mu$的均值中位数估计量就是这些块均值的样本中位数：\n$$\n\\widehat{\\mu} = \\operatorname{median}\\{M_1, M_2, \\dots, M_B\\}\n$$\n这个估计量是稳健的。如果一个离群值污染了一个块，其均值$M_b$可能会变得任意大或小。然而，只要被离群值污染的块少于$B/2$个，块均值的中位数就不会受到影响，从而提供了一个可靠的$\\mu$的估计。\n\n**第4步：尺度的稳健估计（$\\widehat{\\sigma}$）**\n为了识别离群值，我们需要一个对数据尺度或离散度的稳健度量。标准差是不稳健的。我们使用相对于估计位置$\\widehat{\\mu}$的中位数绝对偏差（MAD）。首先，我们计算所有$i=1, \\dots, n$的绝对残差$|y_i - \\widehat{\\mu}|$。MAD是这些值的中位数。\n尺度估计量$\\widehat{\\sigma}$是MAD的一个缩放版本：\n$$\n\\widehat{\\sigma} = c_{\\mathrm{MAD}} \\cdot \\operatorname{median}_i \\{|y_i - \\widehat{\\mu}|\\}\n$$\n常数$c_{\\mathrm{MAD}} = 1.4826$的选择是为了确保对于从高斯分布中抽取的数据，$\\widehat{\\sigma}$是标准差的一致估计量。它由标准正态累积分布函数$\\Phi$导出，为$1/\\Phi^{-1}(0.75)$。\n为了数值稳定性，如果$\\widehat{\\sigma}$计算结果为0（当超过50%的$y_i$值等于$\\widehat{\\mu}$时会发生这种情况），则将其设置为一个小的正数下限值$\\sigma_{\\min} = 10^{-6}$。\n\n**第5步：离群值识别**\n有了位置（$\\widehat{\\mu}$）和尺度（$\\widehat{\\sigma}$）的稳健估计，我们可以使用“Z-score”的稳健版本来识别离群值。如果一个重复样本$i$的对数比率$y_i$与估计中心$\\widehat{\\mu}$的距离过远（以稳健尺度$\\widehat{\\sigma}$为单位衡量），则将其标记为离群值。判据是：\n$$\n|y_i - \\widehat{\\mu}|  c \\cdot \\widehat{\\sigma}\n$$\n其中问题指定了阈值乘数$c = 3.0$。这对应于适用于稳健估计量的“3-sigma”法则。\n离群值比例$f$是被标记的重复样本数量除以总重复样本数量$n$。\n\n**第6步：最终报告**\n启动子活性的最终估计值$\\widehat{A}$是通过将对数尺度上的估计值$\\widehat{\\mu}$转换回原始线性尺度得到的：\n$$\n\\widehat{A} = \\exp(\\widehat{\\mu})\n$$\n这个值$\\widehat{A}$代表了所有重复样本中启动子活性的几何平均值的稳健估计。每个测试用例要报告的结果是数值对$(\\widehat{A}, f)$，数值需四舍五入到六位小数。\n\n现在，实现将针对每个提供的测试用例遵循这些确切的步骤。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the median-of-means robust estimator for promoter activity\n    and applies it to a suite of test cases.\n    \"\"\"\n\n    C_MAD = 1.4826\n    SIGMA_MIN = 1e-6\n    OUTLIER_THRESHOLD_C = 3.0\n\n    test_cases = [\n        {\n            \"F\": np.array([4900, 5100, 5050, 4950, 5150, 4850, 5000, 5250, 4800, 5200, 4750, 5050]),\n            \"D\": np.array([0.98, 1.02, 1.01, 0.99, 1.03, 0.97, 1.00, 1.05, 0.96, 1.04, 0.95, 1.00]),\n            \"B\": 3\n        },\n        {\n            \"F\": np.array([2950, 3050, 3000, 3100, 2900, 3150, 2850, 3200, 3180, 2820, 3050, 20000, 8000, 2000, 100, 2900, 2800, 3300, 3100, 2950]),\n            \"D\": np.array([0.98, 1.01, 1.00, 1.02, 0.99, 1.03, 0.97, 1.05, 1.04, 0.96, 1.00, 1.01, 0.20, 1.60, 1.00, 1.02, 0.95, 1.08, 1.10, 0.99]),\n            \"B\": 4\n        },\n        {\n            \"F\": np.array([12000, 11000, 13000, 12500, 11500, 13500, 11200, 12800, 13200, 11300, 12700, 11800, 13100, 10900, 12900, 12100, 11600, 13300, 11900, 12200, 16000, 8000, 20000, 7000, 12600]),\n            \"D\": np.array([1.00, 0.92, 1.08, 1.05, 0.97, 1.10, 0.94, 1.02, 1.06, 0.95, 1.03, 0.99, 1.07, 0.93, 1.04, 1.01, 0.96, 1.09, 0.98, 1.00, 1.12, 0.90, 1.15, 0.88, 1.05]),\n            \"B\": 5\n        },\n        {\n            \"F\": np.array([4000, 4100, 3900, 4050, 3950, 10000, 100]),\n            \"D\": np.array([1.00, 1.02, 0.98, 1.01, 1.00, 0.50, 1.20]),\n            \"B\": 2\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        F_arr, D_arr, B = case[\"F\"], case[\"D\"], case[\"B\"]\n        n = len(F_arr)\n\n        # Step 1: Compute log-ratios\n        y = np.log(F_arr) - np.log(D_arr)\n\n        # Step 2: Partition data into B blocks\n        q = n // B\n        r = n % B\n        \n        block_sizes = [q + 1] * r + [q] * (B - r)\n        blocks = []\n        current_pos = 0\n        for size in block_sizes:\n            blocks.append(y[current_pos : current_pos + size])\n            current_pos += size\n\n        # Step 3: Compute median-of-means for mu_hat\n        block_means = np.array([np.mean(block) for block in blocks])\n        mu_hat = np.median(block_means)\n\n        # Step 4: Estimate scale using MAD\n        abs_residuals = np.abs(y - mu_hat)\n        mad = np.median(abs_residuals)\n        sigma_hat = C_MAD * mad\n        if sigma_hat == 0.0:\n            sigma_hat = SIGMA_MIN\n\n        # Step 5: Flag outliers\n        is_outlier = np.abs(y - mu_hat)  OUTLIER_THRESHOLD_C * sigma_hat\n        num_outliers = np.sum(is_outlier)\n        f_outliers = num_outliers / n\n\n        # Step 6: Report final promoter activity\n        A_hat = np.exp(mu_hat)\n\n        results.append(f\"{A_hat:.6f}\")\n        results.append(f\"{f_outliers:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2749352"}]}