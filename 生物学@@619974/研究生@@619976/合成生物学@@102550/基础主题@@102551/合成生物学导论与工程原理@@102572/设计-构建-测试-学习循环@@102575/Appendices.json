{"hands_on_practices": [{"introduction": "“测试”阶段是设计-构建-测试-学习（DBTL）循环的核心，它要求精确的实验操作以生成可靠的数据。本练习将带你实践一项关键的实验技能——制备浓度梯度，这对于表征任何工程生物系统的剂量反应曲线都至关重要。通过这个计算，你将能更好地理解如何为“学习”阶段准备高质量的定量数据 [@problem_id:1428071]。", "problem": "一名系统生物学实验室的学生正在执行“设计-构建-测试-学习”循环中的“测试”阶段。他们正在表征一个被工程化到*大肠杆菌* (*E. coli*)中的合成基因回路。该回路被设计用于表达一种荧光蛋白，其荧光水平取决于外部诱导剂分子L-arabinose的浓度。为了创建剂量-反应曲线，学生必须在96孔微孔板上将细菌培养物暴露于精确控制的诱导剂浓度梯度中。\n\n实验在微孔板的A行中进行制备。使用了以下参数：\n- L-arabinose母液的浓度为 $C_{stock} = 500$ mM。\n- A行中每个含有细菌培养物和诱导剂的孔的最终体积为 $V_{final} = 200$ µL。\n- 第一个孔A1的制备方法是，将 $V_{prep} = 4.0$ µL的L-arabinose母液直接加入到足量细菌培养物中，以达到最终体积。\n- 为了产生后续的浓度，进行了两倍系列稀释。该过程包括从前一个孔向后一个孔转移 $V_{transfer} = 100$ µL的液体，从A1转移到A2开始。在进行转移之前，每个后续的孔（A2, A3等）中已含有 $100$ µL的细菌培养物。混合后，对系列中的下一个孔（例如，从A2到A3）重复此过程。\n\n计算孔A8中L-arabinose的最终浓度。答案以微摩尔 (µM) 为单位，并四舍五入到三位有效数字。", "solution": "将一定体积的母液与一定体积的培养物混合至最终体积后，孔中的浓度由质量守恒定律给出：\n$$\nC_{\\text{final}}=C_{\\text{stock}}\\frac{V_{\\text{stock}}}{V_{\\text{final}}}.\n$$\n对于孔A1，$C_{\\text{stock}}=500\\ \\text{mM}$，$V_{\\text{stock}}=4.0$ 微升，以及 $V_{\\text{final}}=200$ 微升，因此\n$$\nC_{\\text{A1}}=500\\,\\text{mM}\\times\\frac{4.0}{200}=500\\,\\text{mM}\\times\\frac{1}{50}=10\\,\\text{mM}.\n$$\n对于每个后续的孔，将 $V_{\\text{transfer}}=100$ 微升的液体转移到已含有 $100$ 微升培养物的孔中，从而产生两倍的稀释。因此，每一步都将浓度乘以 $\\frac{1}{2}$：\n$$\nC_{\\text{A}(n+1)}=\\frac{1}{2}C_{\\text{A}n}.\n$$\n从A1到A8，共有 $7$ 次这样的稀释，所以\n$$\nC_{\\text{A8}}=C_{\\text{A1}}\\left(\\frac{1}{2}\\right)^{7}=10\\,\\text{mM}\\times\\frac{1}{128}=\\frac{10}{128}\\,\\text{mM}=0.078125\\,\\text{mM}.\n$$\n使用 $1\\,\\text{mM}=1000\\,\\text{micromolar}$ 将毫摩尔浓度转换为微摩尔浓度：\n$$\nC_{\\text{A8}}=0.078125\\times 1000=78.125\\ \\text{micromolar}.\n$$\n四舍五入到三位有效数字，得到 $78.1$ µM。", "answer": "$$\\boxed{78.1}$$", "id": "1428071"}, {"introduction": "在合成生物学中，一个“设计”的成功与否往往依赖于其所处的生物学“背景”。本练习模拟了一个常见挑战：一个在克隆菌株中完美工作的基因线路，在转移到表达菌株后却意外失效。通过分析这一现象，你将学会如何从失败的“测试”结果中提炼出宝贵的“学习”见解，诊断出问题根源，这正是DBTL循环中迭代优化的关键一步 [@problem_id:1428108]。", "problem": "一个合成生物学团队正在遵循“设计-构建-测试-学习 (DBTL)”循环来创建一个简单的遗传开关。他们的“设计”是一个旨在用作诱导型表达系统的质粒。该质粒包含两个关键组分：\n1. 一个表达 LacI 阻遏蛋白的基因，由一个弱的组成型启动子驱动。\n2. 一个绿色荧光蛋白 (GFP) 的基因，由一个强的、可被 LacI 阻遏的启动子 (`P_lac`) 驱动。\n\n该团队“构建”了此质粒，并在两种不同的 *E. coli* 菌株中对其进行“测试”。\n- **测试 1：** 在克隆菌株 *E. coli* DH5α 中，该线路工作完美。在没有诱导剂的情况下，细胞表现出非常低的荧光；加入诱导剂后，则表现出高荧光。\n- **测试 2：** 将完全相同的质粒转移到蛋白表达菌株 *E. coli* BL21(DE3) 中。在此菌株中，该线路失效。即使在完全没有任何诱导剂的情况下，细胞也表现出很高的 GFP 荧光。\n\n现在，在“学习”阶段，团队必须提出一个假说来解释这种宿主依赖性失效。根据已知的克隆菌株与蛋白表达菌株的一般特性，以下哪个假说最能合理解释在 BL21(DE3) 中观察到的高基础（渗漏）表达？\n\nA. 在 BL21(DE3) 的细胞质中，GFP 蛋白折叠成其有活性的荧光构象的效率远高于 DH5α，导致相同量的蛋白产生更高的荧光信号。\n\nB. 与 DH5α 宿主相比，在 BL21(DE3) 宿主环境中，质粒的复制起始点导致每个细胞的质粒拷贝数显著更高。\n\nC. BL21(DE3) 菌株具有更高浓度的内源性蛋白酶，这些蛋白酶特异性地降解 LacI 阻遏蛋白，从而降低其与 `P_lac` 启动子结合的能力。\n\nD. BL21(DE3) 中的核糖体翻译 `gfp` mRNA 序列的速度显著快于 DH5α 中的核糖体，导致 GFP 的快速积累。", "solution": "我们首先确定该线路的调控逻辑。LacI 阻遏蛋白由一个弱的组成型启动子产生，而 GFP 报告基因则由一个强的、受 LacI 阻遏的 $P_{\\text{lac}}$ 启动子驱动。在没有诱导剂的情况下，如果具有活性的 LacI 四聚体的细胞内浓度相对于 $P_{\\text{lac}}$ 操纵子位点的数量和启动子的内在强度足够高，则阻遏成功。当（质粒）被转移到不同宿主中时，任何降低有效 LacI 阻遏作用或增加 $P_{\\text{lac}}$ 有效转录驱动力的因素，都可能表现为高基础荧光。\n\n现在，我们根据克隆菌株（如 DH5α）和蛋白表达菌株（如 BL21(DE3)）的已知一般特性，以及 LacI 阻遏的机理要求，来评估每个假说。\n\n- 假说 A（在 BL21(DE3) 中折叠得到改善）：提高折叠效率会使每个 GFP 分子的荧光信号按一个乘法因子 $f$ 进行缩放，而不会改变 $P_{\\text{lac}}$ 的转录状态。这会影响读出灵敏度，但不会将一个被紧密阻遏的启动子转变为转录去阻遏状态。完全归因于折叠的高基础荧光将意味着，在 DH5α 中的相同低基础表达仅仅是更难检测到而已，然而观察到的现象是 BL21(DE3) 中阻遏作用的定性失效。因此，这不是渗漏转录最可能的原因。\n\n- 假说 B（在 BL21(DE3) 中质粒拷贝数更高）：令 $N$ 表示质粒拷贝数。操纵子位点的数量与 $N$ 成正比。由弱启动子产生的 LacI 总量也与 $N$ 成正比，但由于 LacI 启动子弱而 $P_{\\text{lac}}$ 强，有效的阻遏需要活性阻遏蛋白的数量大大超过可用操纵子位点的数量，这还要考虑到结合化学计量、非特异性结合和随机波动。在实践中，高拷贝数可以滴定掉阻遏蛋白，而对基于 lac 的启动子进行严密控制通常需要提高 LacI 的表达水平（例如，lacI^{q}）来克服操纵子滴定效应。宿主依赖性的对类 ColE1 复制起始点的控制差异可以改变 $N$，并且表达宿主产生的 $N$ 可能与克隆菌株不同。因此，BL21(DE3) 中 $N$ 的增加是一个合理的通用机制，它通过使强 $P_{\\text{lac}}$ 的需求量超过弱 LacI 的供应量来增加基础表达，从而导致渗漏。\n\n- 假说 C（在 BL21(DE3) 中有更高水平的降解 LacI 的蛋白酶）：BL21(DE3) 的一个决定性特征是它缺乏蛋白酶（特别是 lon^{-}、ompT^{-}），这减少了重组蛋白的蛋白水解。“更高浓度的特异性降解 LacI 的内源性蛋白酶”这一说法与此一般特性相矛盾。这个假说不合理。\n\n- 假说 D（在 BL21(DE3) 中翻译速度更快）：没有普遍的特性表明 BL21(DE3) 的核糖体对任意基因的 mRNA 的翻译速度“显著快于”DH5α 的核糖体。此外，任何全局性的翻译速率增加都会同时影响 LacI 和 GFP，并且不会选择性地消除阻遏作用。这对于渗漏转录来说，不是一个有说服力的或普遍的解释。\n\n在这些选项中，与 lac 阻遏线路中一个已知的、常见的失效模式——因基因剂量增加导致的操纵子滴定——相符的机制是假说 B。它解释了为什么弱表达的 LacI（来自弱组成型启动子）在 DH5α 中可能足够，但如果宿主环境增加了质粒拷贝数，从而增加了需要被阻遏的强 $P_{\\text{lac}}$ 启动子的数量，那么在 BL21(DE3) 中就会失效。它也符合更广泛的原理，即宿主依赖的复制控制可以调节拷贝数，从而调节对阻遏蛋白的需求。", "answer": "$$\\boxed{B}$$", "id": "1428108"}, {"introduction": "DBTL循环的精髓在于通过学习不断优化设计，而一个高效的“设计”阶段能极大加速这一进程。本练习将引导你超越直觉，运用统计学和计算方法来规划实验。你将学习如何通过最大化Fisher信息矩阵的行列式（D-最优性准则），来理性地“设计”一组能够提供最多参数信息的实验条件，从而使后续的“测试”与“学习”环节事半功倍 [@problem_id:2782988]。", "problem": "在合成生物学的“设计-构建-测试-学习”（Design-Build-Test-Learn, DBTL）循环中，“设计”步骤旨在选择实验输入，以最大化“学习”步骤的学习质量。考虑一个诱导型基因表达系统，其中稳态报告基因水平通过对诱导物浓度的希尔（Hill）响应进行建模。设确定性平均响应由希尔函数 $f(x;\\boldsymbol{\\theta})$ 给出，其中诱导物浓度 $x$ 严格为正，参数向量为 $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n)$，且 $\\alpha \\in \\mathbb{R}$，$\\beta \\in \\mathbb{R}$，$K \\in \\mathbb{R}_{>0}$，$n \\in \\mathbb{R}_{>0}$。假设存在方差为 $\\sigma^2$ 的方差齐性的独立高斯测量噪声，因此在输入 $x_i$ 处的每次观测 $y_i$ 满足 $y_i = f(x_i;\\boldsymbol{\\theta}) + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 且各个 $\\varepsilon_i$ 相互独立。目标是在有界输入的条件下，选择一个诱导物浓度的多重集，该多重集对于在指定的名义参数值下估计 $\\boldsymbol{\\theta}$ 是 D-最优的。\n\n使用以下基本依据：\n- 希尔平均响应为 $f(x;\\boldsymbol{\\theta}) = \\alpha + \\beta \\dfrac{x^n}{K^n + x^n}$。\n- 对于方差 $\\sigma^2$ 已知的独立高斯观测，一个实验设计 $\\{x_1,\\ldots,x_m\\}$ 的费雪信息矩阵（Fisher Information Matrix, FIM）为 $I(\\boldsymbol{\\theta}) = \\dfrac{1}{\\sigma^2} \\sum_{i=1}^{m} \\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right)\\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right)^\\top$。\n- D-最优准则旨在最大化 $\\det\\!\\left(I(\\boldsymbol{\\theta})\\right)$，当 $I(\\boldsymbol{\\theta})$ 为正定时，这等价于最大化 $\\log \\det\\!\\left(I(\\boldsymbol{\\theta})\\right)$。\n\n任务：编写一个完整程序，在以下约束和约定下，为下面的每个测试用例计算一个 D-最优精确设计：\n- 您必须从允许的诱导物浓度的有限候选集 $\\Gamma \\subset (0,\\infty)$ 中，选择恰好 $m$ 次试验作为一个多重集。重复选择对应于在相同浓度下的技术重复。输入边界由 $\\Gamma$ 强制执行。\n- 对于给定的测试用例，将 $\\boldsymbol{\\theta}$ 和 $\\sigma$ 视为用于局部 D-最优设计的已知名义常数。\n- 如果一个设计的 $I(\\boldsymbol{\\theta})$ 是奇异的，则定义 $\\log \\det\\!\\left(I(\\boldsymbol{\\theta})\\right) = -\\infty$。在 $\\log \\det$ 的值达到最大值（容差为 $\\tau = 10^{-12}$）的所有设计中，选择按升序排序后字典序最小的浓度多重集作为决胜规则。\n- 所有浓度必须以微摩尔浓度（micromolar）为单位，按非递减顺序列出，并以浮点数形式报告。重复值表示重复实验。\n- 角度不会出现。输出中没有百分比。\n\n您的程序必须从第一性原理出发计算 $\\nabla_{\\boldsymbol{\\theta}} f(x;\\boldsymbol{\\theta})$，并通过对从 $\\Gamma$ 中抽取的大小为 $m$ 的所有多重集进行穷举搜索来评估 D-最优设计。\n\n测试套件：\n- 案例 1（正常路径）：\n  - $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n) = (10.0, 90.0, 50.0, 2.0)$\n  - $\\sigma = 5.0$\n  - $\\Gamma = [1.0, 5.0, 10.0, 20.0, 40.0, 60.0, 80.0, 100.0]$ 微摩尔浓度\n  - $m = 4$\n- 案例 2（候选值有界且接近解离常数，噪声更高）：\n  - $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n) = (5.0, 95.0, 10.0, 2.0)$\n  - $\\sigma = 10.0$\n  - $\\Gamma = [2.0, 5.0, 10.0, 20.0]$ 微摩尔浓度\n  - $m = 4$\n- 案例 3（欠定边缘情况，其中 $m < \\dim(\\boldsymbol{\\theta})$）：\n  - $\\boldsymbol{\\theta} = (\\alpha,\\beta,K,n) = (2.0, 18.0, 2.0, 3.0)$\n  - $\\sigma = 1.0$\n  - $\\Gamma = [0.5, 1.0, 2.0, 4.0]$ 微摩尔浓度\n  - $m = 2$\n\n要求的最终输出格式：您的程序应生成单行输出，其中包含三个设计。每个设计都是一个微摩尔浓度列表，四舍五入到小数点后六位，并聚合为一个由方括号括起来的逗号分隔列表，例如 `[[x_{1,1},x_{1,2},\\ldots],[x_{2,1},\\ldots],[x_{3,1},\\ldots]]`。打印的行中不得有任何空格。\n\n科学真实性说明：\n- 所有候选浓度都严格为正，以避免对数中的不可微性。\n- “学习”步骤使用最大似然估计（Maximum Likelihood Estimation, MLE），其渐近协方差是真实参数处 FIM 的逆矩阵，这为 DBTL 循环中的设计采用 D-最优性提供了动机。", "solution": "该问题要求确定一个 D-最优实验设计，以估计希尔（Hill）函数模型的 4 个参数 $\\boldsymbol{\\theta} = (\\alpha, \\beta, K, n)$。该设计由一个包含 $m$ 个诱导物浓度的多重集 $\\{x_1, \\ldots, x_m\\}$ 组成，这些浓度选自一个有限候选集 $\\Gamma$。D-最优准则旨在最大化费雪信息矩阵（FIM）$I(\\boldsymbol{\\theta})$ 的行列式，或等价地，其对数 $\\log \\det(I(\\boldsymbol{\\theta}))$。\n\n平均响应由希尔函数给出：\n$$f(x;\\boldsymbol{\\theta}) = \\alpha + \\beta \\dfrac{x^n}{K^n + x^n}$$\n对于方差为 $\\sigma^2$ 的独立高斯观测，一个设计 $D = \\{x_1, \\ldots, x_m\\}$ 的 FIM 为：\n$$I(\\boldsymbol{\\theta}) = \\frac{1}{\\sigma^2} \\sum_{i=1}^{m} \\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right) \\left(\\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})\\right)^\\top$$\n最大化 $\\det(I(\\boldsymbol{\\theta}))$ 等价于最大化 $\\det\\left(\\sum_{i=1}^{m} \\mathbf{g}_i \\mathbf{g}_i^\\top\\right)$，其中 $\\mathbf{g}_i = \\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})$，因为常数前置因子 $1/\\sigma^2$ 不会改变最优解的位置。我们定义未缩放的信息矩阵 $M(D) = \\sum_{x_i \\in D} \\mathbf{g}_i \\mathbf{g}_i^\\top$，并寻求最大化其对数行列式 $\\log \\det(M(D))$。\n\n第一性原理推导始于计算梯度向量 $\\nabla_{\\boldsymbol{\\theta}} f(x;\\boldsymbol{\\theta})$，它由函数对 $\\boldsymbol{\\theta}$ 中每个参数的偏导数组成。\n\n1.  对基础水平 $\\alpha$ 的导数：\n    $$\\frac{\\partial f}{\\partial \\alpha} = 1$$\n\n2.  对动态范围 $\\beta$ 的导数：\n    $$\\frac{\\partial f}{\\partial \\beta} = \\frac{x^n}{K^n + x^n}$$\n\n3.  对解离常数 $K$ 的导数：\n    $$\\frac{\\partial f}{\\partial K} = \\beta \\frac{\\partial}{\\partial K} \\left( \\frac{x^n}{K^n + x^n} \\right) = \\beta x^n \\frac{\\partial}{\\partial K} \\left( (K^n + x^n)^{-1} \\right)$$\n    使用链式法则：\n    $$\\frac{\\partial f}{\\partial K} = \\beta x^n \\left( -1 \\cdot (K^n + x^n)^{-2} \\cdot \\frac{\\partial}{\\partial K}(K^n) \\right) = -\\beta x^n (K^n + x^n)^{-2} (n K^{n-1})$$\n    $$\\frac{\\partial f}{\\partial K} = - \\frac{\\beta n K^{n-1} x^n}{(K^n + x^n)^2}$$\n\n4.  对希尔系数 $n$ 的导数：\n    $$\\frac{\\partial f}{\\partial n} = \\beta \\frac{\\partial}{\\partial n} \\left( \\frac{x^n}{K^n + x^n} \\right)$$\n    使用恒等式 $a^b = e^{b \\ln a}$ 并对 $g(n) = \\frac{u(n)}{v(n)}$ 应用商法则，其中 $u(n) = x^n$ 且 $v(n) = K^n + x^n$：\n    $$\\frac{\\partial u}{\\partial n} = x^n \\ln x \\quad \\text{和} \\quad \\frac{\\partial v}{\\partial n} = K^n \\ln K + x^n \\ln x$$\n    $$\\frac{\\partial g}{\\partial n} = \\frac{v \\frac{\\partial u}{\\partial n} - u \\frac{\\partial v}{\\partial n}}{v^2} = \\frac{(K^n + x^n)(x^n \\ln x) - x^n(K^n \\ln K + x^n \\ln x)}{(K^n + x^n)^2}$$\n    $$= \\frac{K^n x^n \\ln x + (x^n)^2 \\ln x - K^n x^n \\ln K - (x^n)^2 \\ln x}{(K^n + x^n)^2} = \\frac{K^n x^n (\\ln x - \\ln K)}{(K^n + x^n)^2}$$\n    因此，\n    $$\\frac{\\partial f}{\\partial n} = \\frac{\\beta K^n x^n \\ln(x/K)}{(K^n + x^n)^2}$$\n\n在名义参数 $\\boldsymbol{\\theta}$ 下，对于给定浓度 $x$ 的完整梯度向量是：\n$$\\nabla_{\\boldsymbol{\\theta}} f(x;\\boldsymbol{\\theta}) = \\begin{pmatrix} 1 \\\\ \\frac{x^n}{K^n + x^n} \\\\ - \\frac{\\beta n K^{n-1} x^n}{(K^n + x^n)^2} \\\\ \\frac{\\beta K^n x^n \\ln(x/K)}{(K^n + x^n)^2} \\end{pmatrix}$$\n\n解决方案通过对从候选集 $\\Gamma$ 中抽取的大小为 $m$ 的所有可能多重集进行穷举搜索来找到。这对应于可重复组合。如果 $|\\Gamma|=k$，则此类多重集的数量为 $\\binom{k+m-1}{m}$。对于每个候选设计 $D = \\{x_1, \\ldots, x_m\\}$，计算过程如下：\n1.  初始化一个 $4 \\times 4$ 的零矩阵 $M(D)$。\n2.  对于 $D$ 中的每个浓度 $x_i$，使用名义参数值计算梯度向量 $\\mathbf{g}_i = \\nabla_{\\boldsymbol{\\theta}} f(x_i;\\boldsymbol{\\theta})$。\n3.  计算外积 $\\mathbf{g}_i \\mathbf{g}_i^\\top$（这是一个 $4 \\times 4$ 的秩为 1 的矩阵），并将其加到 $M(D)$ 上。\n4.  对 $D$ 中所有的 $x_i$ 求和后，计算目标函数值，即所得矩阵 $M(D)$ 的对数行列式。如果 $M(D)$ 是奇异的，其行列式为 $0$，其对数行列式定义为 $-\\infty$。这可以通过检查 `numpy.linalg.slogdet` 返回的符号在数值上进行处理。\n\n最优设计是使该目标函数最大化的设计。生成一个包含所有候选设计及其相应对数行列式值的列表。确定最大对数行列式 $\\mathcal{L}_{max}$。所有对数行列式 $\\mathcal{L}$ 满足 $|\\mathcal{L} - \\mathcal{L}_{max}| \\le \\tau$（其中容差为 $\\tau = 10^{-12}$）的设计都被视为最优。在该最优设计集合中，问题指定选择其排序后的非递减浓度序列在字典序上最小的那个。\n\n对于案例 3，其中试验次数 $m=2$ 小于参数数量 $d=4$，FIM 必然是奇异的。矩阵 $M(D)$ 是 $m=2$ 个秩为 1 的矩阵之和，因此其秩至多为 2。一个秩小于 4 的 $4 \\times 4$ 矩阵的行列式为 0。因此，所有可能的设计都会得到 $-\\infty$ 的目标值。决胜规则成为唯一的选择准则。因此，最优设计是从 $\\Gamma$ 中选取的、大小为 2 且字典序最小的多重集，即 $\\{0.5, 0.5\\}$。这表明了对问题中关于欠定情况准则的正确解释。", "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Computes D-optimal designs for three test cases by exhaustive search.\n    \"\"\"\n    test_cases = [\n        {\n            \"theta\": (10.0, 90.0, 50.0, 2.0),  # (alpha, beta, K, n)\n            \"sigma\": 5.0,\n            \"gamma\": [1.0, 5.0, 10.0, 20.0, 40.0, 60.0, 80.0, 100.0],\n            \"m\": 4,\n        },\n        {\n            \"theta\": (5.0, 95.0, 10.0, 2.0),\n            \"sigma\": 10.0,\n            \"gamma\": [2.0, 5.0, 10.0, 20.0],\n            \"m\": 4,\n        },\n        {\n            \"theta\": (2.0, 18.0, 2.0, 3.0),\n            \"sigma\": 1.0,\n            \"gamma\": [0.5, 1.0, 2.0, 4.0],\n            \"m\": 2,\n        },\n    ]\n\n    all_results = []\n    tau = 1e-12\n\n    def get_gradient(x, theta):\n        \"\"\"\n        Computes the gradient of the Hill function f with respect to theta.\n        theta = (alpha, beta, K, n)\n        \"\"\"\n        alpha, beta, K, n = theta\n        \n        # To prevent log(0) or division by zero, though problem constraints make it unlikely\n        if x = 0 or K = 0:\n            return np.zeros(4)\n\n        x_n = x**n\n        K_n = K**n\n        denominator = K_n + x_n\n        \n        if denominator == 0:\n            return np.zeros(4)\n        \n        common_term_beta = x_n / denominator\n        \n        # Partial derivatives\n        df_d_alpha = 1.0\n        df_d_beta = common_term_beta\n        df_d_K = -beta * n * (K**(n - 1)) * x_n / (denominator**2)\n        df_d_n = beta * K_n * x_n * np.log(x / K) / (denominator**2)\n        \n        return np.array([df_d_alpha, df_d_beta, df_d_K, df_d_n])\n\n    for case in test_cases:\n        theta = case[\"theta\"]\n        gamma = case[\"gamma\"]\n        m = case[\"m\"]\n        \n        num_params = len(theta)\n        \n        design_candidates = itertools.combinations_with_replacement(gamma, m)\n        \n        evaluated_designs = []\n        \n        for design in design_candidates:\n            fim_unscaled = np.zeros((num_params, num_params))\n            for x_i in design:\n                g = get_gradient(x_i, theta)\n                fim_unscaled += np.outer(g, g)\n            \n            sign, logdet = np.linalg.slogdet(fim_unscaled)\n            \n            # If matrix is singular or not positive definite, logdet is -inf\n            if sign = 0:\n                objective_value = -np.inf\n            else:\n                objective_value = logdet\n            \n            evaluated_designs.append((objective_value, list(design)))\n\n        # Find the maximum log-determinant value\n        if not evaluated_designs:\n            # Should not happen with the given constraints\n            all_results.append([])\n            continue\n            \n        max_log_det = -np.inf\n        for log_det_val, _ in evaluated_designs:\n            if log_det_val > max_log_det:\n                max_log_det = log_det_val\n        \n        # Filter for designs that are optimal within the tolerance\n        best_designs = []\n        for log_det_val, design in evaluated_designs:\n            if abs(log_det_val - max_log_det) = tau:\n                best_designs.append(design)\n        \n        # The first item in best_designs is the lexicographically smallest\n        # because itertools.combinations_with_replacement generates them in order.\n        optimal_design = best_designs[0]\n        all_results.append(optimal_design)\n\n    # Format the final output string exactly as specified\n    def format_list(lst):\n        return f\"[{','.join(f'{x:.6f}' for x in lst)}]\"\n\n    results_as_strings = [format_list(res) for res in all_results]\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```", "id": "2782988"}]}