{"hands_on_practices": [{"introduction": "本实践旨在连接原始实验测量数据与生物部件注册库所必需的标准化参数。可靠的表征是工程生物学的基石，本练习将模拟一个完整的数据处理流程：将时序荧光和光密度数据转化为标准的相对启动子单位（RPU）。随后，你将使用无处不在的诱导系统模型——希尔函数，对这些标准化测量值进行拟合，以提取最大活性 ($\\alpha$)、灵敏度 ($K$) 和协同性 ($n$) 等关键生物物理参数 [@problem_id:2775671]。对于希望为合成生物学社区贡献高质量、可复用部件的研究者而言，掌握这一工作流程至关重要。", "problem": "您正在构建一个标准化的启动子元件表征流程，以便在生物元件库中进行注册。遵循合成生物学中的常规做法，您将通过在相同条件下测量的参考启动子活性来对目标启动子活性进行归一化，从而估算相对启动子单位 (Relative Promoter Units, RPU)，然后将希尔函数 (Hill function) 拟合到诱导-响应数据，并报告参数估计值及其置信区间。\n\n您必须遵循的基本原理和定义：\n- 中心法则 (Central Dogma)：转录和翻译产生报告蛋白，其丰度决定了荧光强度。\n- 荧光强度与单位培养液体积内的报告蛋白量成正比；光密度 (Optical Density, OD) 与生物质浓度成正比。\n- 在平衡指数生长期，当生物量平稳增加时，在短时间窗口内，培养物中单位生物量的平均报告蛋白量近似恒定。在此区间内，减去测量背景后，校正后的荧光 $F_{\\mathrm{corr}}$ 与校正后的OD $\\mathrm{OD}_{\\mathrm{corr}}$ 呈线性关系，线性回归 $F_{\\mathrm{corr}} \\approx s \\,\\mathrm{OD}_{\\mathrm{corr}} + b$ 的斜率 $s$ 可作为启动子活性的代理指标。\n- 相对启动子单位 (RPU) 定义为：在相同诱导条件下收集的匹配时间序列数据中，目标启动子斜率与参考启动子斜率之比。\n- 许多启动子的诱导-响应曲线可以很好地用希尔函数 (Hill function) $f(I) = \\dfrac{\\alpha I^n}{K^n + I^n}$ 描述，其中 $I$ 是诱导剂浓度，$\\alpha$ 是以 RPU 为单位的最大活性， $K$ 是半最大诱导剂浓度 (单位为 $\\mu\\mathrm{M}$)，$n$ 是无量纲的希尔系数 (Hill coefficient)。\n\n您的任务是：\n1. 对于每个测试用例，使用下面指定的确定性数据生成模型，为参考启动子和目标启动子在多种诱导剂浓度下生成时间序列的光密度和荧光数据。减去随时间变化的测量背景以获得校正后的信号。\n2. 对于每种诱导剂浓度，通过在指定的 OD 窗口内对校正后的荧光与校正后的 OD 进行普通最小二乘线性回归，估算启动子活性斜率 $s$。计算每种诱导剂下的 RPU 为 $s_{\\mathrm{target}}/s_{\\mathrm{ref}}$。\n3. 使用非线性最小二乘法将希尔函数 $f(I)$ 拟合到 RPU 与 $I$ 的数据，并设置正值边界 $\\alpha > 0$, $K > 0$ 以及范围 $0.5 \\le n \\le 5.0$。使用由回归返回的参数协方差矩阵，估算 $\\alpha$、 $K$ 和 $n$ 的渐近 $95\\%$ 置信区间。其中，使用学生t分布 (Student's t) 的临界值，其自由度等于数据点数量减去拟合参数的数量。\n4. 对于每个测试用例，报告一个包含9个浮点数的扁平列表，顺序为：$\\alpha$, $K$, $n$, $\\alpha_{\\mathrm{low}}$, $\\alpha_{\\mathrm{high}}$, $K_{\\mathrm{low}}$, $K_{\\mathrm{high}}$, $n_{\\mathrm{low}}$, $n_{\\mathrm{high}}$，其中 “low” 和 “high” 表示 $95\\%$ 置信区间的下限和上限。$K$ 以 $\\mu\\mathrm{M}$ 为单位表示，所有其他参数均为无量纲数。将所有输出数字四舍五入到六位小数。\n\n确定性数据生成模型（无随机性）：\n- 对于每个测试用例，您会得到一组参数，用于定义时间网格、诱导剂浓度、生长、背景信号、仪器扰动以及真实的目标启动子响应。根据这些参数，为每个诱导剂浓度 $I_i$ 和时间点 $t_j$ 生成以下信号：\n    - 真实生物量轨迹：$\\mathrm{OD}_{\\mathrm{true}}(t_j) = \\mathrm{OD}_0 \\exp(r \\, t_j)$。\n    - 背景信号：$\\mathrm{OD}_{\\mathrm{blank}}(t_j) = \\beta_0 + \\beta_1 t_j$, $F_{\\mathrm{bg}}(t_j) = \\phi_0 + \\phi_1 t_j$。\n    - 参考启动子荧光：$F_{\\mathrm{ref}}(i,j) = F_{\\mathrm{bg}}(t_j) + s_{\\mathrm{ref}} \\, \\mathrm{OD}_{\\mathrm{true}}(t_j) + A_{\\mathrm{ref}} \\sin(\\omega_{\\mathrm{ref}} t_j + \\psi_{\\mathrm{ref}} i)$，并带有一个小的 OD 扰动 $\\delta \\mathrm{OD}_{\\mathrm{ref}}(i,j) = A_{\\mathrm{OD}} \\cos(\\omega_{\\mathrm{OD}} t_j + \\psi_{\\mathrm{OD}} i)$ 添加到测量的 OD 中：$\\mathrm{OD}_{\\mathrm{ref}}(i,j) = \\mathrm{OD}_{\\mathrm{true}}(t_j) + \\delta \\mathrm{OD}_{\\mathrm{ref}}(i,j)$。\n    - 目标启动子荧光：$F_{\\mathrm{tar}}(i,j) = F_{\\mathrm{bg}}(t_j) + s_{\\mathrm{tar}}(I_i) \\, \\mathrm{OD}_{\\mathrm{true}}(t_j) + A_{\\mathrm{tar}} \\sin(\\omega_{\\mathrm{tar}} t_j + \\psi_{\\mathrm{tar}} i)$，其中 $\\mathrm{OD}_{\\mathrm{tar}}(i,j) = \\mathrm{OD}_{\\mathrm{true}}(t_j) + \\delta \\mathrm{OD}_{\\mathrm{tar}}(i,j)$，此处的 $\\delta \\mathrm{OD}_{\\mathrm{tar}}(i,j)$ 使用与参考 OD 扰动相同的形式和振幅。目标单位生物量荧光斜率为 $s_{\\mathrm{tar}}(I_i) = s_{\\mathrm{ref}} \\cdot \\dfrac{\\alpha_{\\mathrm{true}} I_i^{n_{\\mathrm{true}}}}{K_{\\mathrm{true}}^{n_{\\mathrm{true}}} + I_i^{n_{\\mathrm{true}}}}$。\n    - 校正后信号：$\\mathrm{OD}_{\\mathrm{corr}} = \\mathrm{OD}_{\\mathrm{meas}} - \\mathrm{OD}_{\\mathrm{blank}}$, $F_{\\mathrm{corr}} = F_{\\mathrm{meas}} - F_{\\mathrm{bg}}$。\n- 对于斜率估计，仅使用 $\\mathrm{OD}_{\\mathrm{corr}} \\in [0.06, 0.30]$ 的时间点。如果满足此条件的点少于三个，则退而使用所有可用点。通过普通最小二乘法拟合 $F_{\\mathrm{corr}}$ 与 $\\mathrm{OD}_{\\mathrm{corr}}$ 来获得斜率。如果由于极低诱导时的扰动导致拟合斜率非正，则用一个小的正数下限 $10^{-9}$ 替换它，以保持物理合理性。\n- 计算每个诱导剂浓度 $I_i$ 下的 RPU 为 $\\mathrm{RPU}(I_i) = s_{\\mathrm{tar}}(I_i)/s_{\\mathrm{ref}}$。\n\n非线性回归和置信区间：\n- 使用非线性最小二乘法将 $f(I) = \\dfrac{\\alpha I^n}{K^n + I^n}$ 拟合到 $(I_i, \\mathrm{RPU}(I_i))$ 数据对，边界为 $\\alpha \\in (10^{-12}, 10^{6})$、$K \\in (10^{-9}, 10^{6})$ 和 $n \\in [0.5, 5.0]$。根据数据使用合理的初始猜测值（例如，$\\alpha$ 初始化为观测到的最大 RPU， $K$ 初始化为接近半最大值时的正诱导剂浓度， $n$ 初始化为 $2.0$）。\n- 设 $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{K}, \\hat{n})$ 为拟合参数，$\\Sigma$ 为优化器返回的参数协方差矩阵。标准误差为 $\\mathrm{SE}(\\hat{\\theta}_k) = \\sqrt{\\Sigma_{kk}}$。设自由度为 $d = N - 3$，其中 $N$ 是 $(I_i, \\mathrm{RPU}(I_i))$ 数据对的数量。计算每个参数的双侧 $95\\%$ 置信区间为 $\\hat{\\theta}_k \\pm t_{0.975, d} \\cdot \\mathrm{SE}(\\hat{\\theta}_k)$，其中 $t_{0.975, d}$ 是自由度为 $d$ 的学生t分布 (Student's t distribution) 的 $0.975$ 分位数。如果 $d \\le 0$，则使用标准正态分位数 $1.96$ 进行近似。\n\n测试套件（三个用例）：\n- 用例1（理想情况，宽动态范围）：\n    - 时间网格：$t_j = j \\Delta t$, $j = 0,\\dots,5$, $\\Delta t = 0.5$ 小时。\n    - 诱导剂浓度 (单位 $\\mu\\mathrm{M}$): $I = [0, 1, 3, 10, 30, 100]$。\n    - 生长：$\\mathrm{OD}_0 = 0.05$, $r = 0.9 \\,\\mathrm{h}^{-1}$。\n    - 背景：$\\mathrm{OD}_{\\mathrm{blank}}(t) = 0.005 + 0.001 t$, $F_{\\mathrm{bg}}(t) = 40 + 3 t$。\n    - 参考斜率：$s_{\\mathrm{ref}} = 9000$。\n    - 真实目标希尔参数：$\\alpha_{\\mathrm{true}} = 2.0$, $K_{\\mathrm{true}} = 12.0 \\,\\mu\\mathrm{M}$, $n_{\\mathrm{true}} = 2.2$。\n    - 扰动：$A_{\\mathrm{OD}} = 0.002$, $\\omega_{\\mathrm{OD}} = 0.3$, $\\psi_{\\mathrm{OD}} = 0.2$; $A_{\\mathrm{ref}} = 50$, $\\omega_{\\mathrm{ref}} = 0.7$, $\\psi_{\\mathrm{ref}} = 0.15$; $A_{\\mathrm{tar}} = 60$, $\\omega_{\\mathrm{tar}} = 0.6$, $\\psi_{\\mathrm{tar}} = 0.17$。\n- 用例2（低动态范围，小 $K$ 值）：\n    - 时间网格：$t_j = j \\Delta t$, $j = 0,\\dots,5$, $\\Delta t = 0.6$ 小时。\n    - 诱导剂浓度 (单位 $\\mu\\mathrm{M}$): $I = [0, 0.5, 1.0, 2.0, 4.0]$。\n    - 生长：$\\mathrm{OD}_0 = 0.06$, $r = 0.6 \\,\\mathrm{h}^{-1}$。\n    - 背景：$\\mathrm{OD}_{\\mathrm{blank}}(t) = 0.004 + 0.0008 t$, $F_{\\mathrm{bg}}(t) = 30 + 2 t$。\n    - 参考斜率：$s_{\\mathrm{ref}} = 12000$。\n    - 真实目标希尔参数：$\\alpha_{\\mathrm{true}} = 0.6$, $K_{\\mathrm{true}} = 1.5 \\,\\mu\\mathrm{M}$, $n_{\\mathrm{true}} = 1.2$。\n    - 扰动：$A_{\\mathrm{OD}} = 0.0015$, $\\omega_{\\mathrm{OD}} = 0.3$, $\\psi_{\\mathrm{OD}} = 0.2$; $A_{\\mathrm{ref}} = 30$, $\\omega_{\\mathrm{ref}} = 0.7$, $\\psi_{\\mathrm{ref}} = 0.15$; $A_{\\mathrm{tar}} = 35$, $\\omega_{\\mathrm{tar}} = 0.6$, $\\psi_{\\mathrm{tar}} = 0.17$。\n- 用例3（高协同性）：\n    - 时间网格：$t_j = j \\Delta t$, $j = 0,\\dots,5$, $\\Delta t = 0.4$ 小时。\n    - 诱导剂浓度 (单位 $\\mu\\mathrm{M}$): $I = [0, 5, 8, 10, 12, 20, 50]$。\n    - 生长：$\\mathrm{OD}_0 = 0.04$, $r = 1.1 \\,\\mathrm{h}^{-1}$。\n    - 背景：$\\mathrm{OD}_{\\mathrm{blank}}(t) = 0.003 + 0.0009 t$, $F_{\\mathrm{bg}}(t) = 35 + 2.5 t$。\n    - 参考斜率：$s_{\\mathrm{ref}} = 8000$。\n    - 真实目标希尔参数：$\\alpha_{\\mathrm{true}} = 1.5$, $K_{\\mathrm{true}} = 10.0 \\,\\mu\\mathrm{M}$, $n_{\\mathrm{true}} = 3.0$。\n    - 扰动：$A_{\\mathrm{OD}} = 0.0025$, $\\omega_{\\mathrm{OD}} = 0.3$, $\\psi_{\\mathrm{OD}} = 0.2$; $A_{\\mathrm{ref}} = 40$, $\\omega_{\\mathrm{ref}} = 0.7$, $\\psi_{\\mathrm{ref}} = 0.15$; $A_{\\mathrm{tar}} = 45$, $\\omega_{\\mathrm{tar}} = 0.6$, $\\psi_{\\mathrm{tar}} = 0.17$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的、包含27个数字的逗号分隔的扁平列表。这些数字应按顺序串联用例1、用例2和用例3的九个数字结果。每个浮点数必须四舍五入到六位小数，$K$ 值必须以 $\\mu\\mathrm{M}$ 为单位，而所有其他参数都是无量纲的。例如：\"[a1,K1,n1,low_a1,high_a1,low_K1,high_K1,low_n1,high_n1,a2,K2,n2,...]\"。", "solution": "我们设计了一个计算流程，该流程与生物元件库中使用的标准化启动子表征原则保持一致。该流程包括三个阶段：信号校正与活性提取、RPU 计算、以及带不确定性量化的希尔函数拟合。\n\n首先，我们的方法基于基本的生物物理和测量原理：\n- 根据中心法则，启动子活性调节报告基因的转录和翻译；累积的报告蛋白浓度影响测量的荧光强度。在平衡指数生长的适度时间窗口内，单位生物量的报告蛋白的产生和稀释达到一种准稳态行为。\n- 在给定波长下的光密度与生物质浓度成正比。因此，在一个生长呈指数的短时间区间内，校正后的荧光 $F_{\\mathrm{corr}}$（减去背景）与校正后的 OD $\\mathrm{OD}_{\\mathrm{corr}}$（减去空白对照）近似成正比。\n- 拟合线性模型 $F_{\\mathrm{corr}} \\approx s \\,\\mathrm{OD}_{\\mathrm{corr}} + b$ 会得到一个斜率 $s$，它代表了该区间内单位生物量的报告蛋白荧光。假设其他因素（如成熟和降解）在匹配的条件下被充分捕获或近似恒定，该斜率可作为启动子活性的代理指标。\n\n其次，为了实现跨实验的标准化并在元件库中共享，我们计算相对启动子单位 (RPU)，其定义为在相同条件下测量的目标启动子活性与一个良好表征的参考启动子活性之比。如果 $s_{\\mathrm{tar}}(I_i)$ 和 $s_{\\mathrm{ref}}(I_i)$ 分别表示在诱导剂浓度 $I_i$ 下目标和参考启动子的斜率，那么 $\\mathrm{RPU}(I_i) = s_{\\mathrm{tar}}(I_i)/s_{\\mathrm{ref}}(I_i)$。这种归一化消除了仪器相关的尺度和培养条件的影响，从而产生一个无量纲的响应曲线。\n\n第三，我们使用非线性最小二乘法将经典的希尔函数\n$$\nf(I) = \\frac{\\alpha I^n}{K^n + I^n}\n$$\n拟合到 $(I_i, \\mathrm{RPU}(I_i))$ 数据。我们对参数施加物理上有意义的域约束：$\\alpha > 0$, $K > 0$ 以及 $0.5 \\le n \\le 5.0$。设拟合参数为 $\\hat{\\alpha}$, $\\hat{K}$ 和 $\\hat{n}$。非线性回归返回一个近似的参数协方差矩阵 $\\Sigma$，通常由 $\\sigma^2 (J^{\\top} J)^{-1}$ 给出，其中 $J$ 是最优点处的雅可比矩阵 (Jacobian)，$\\sigma^2$ 是根据拟合估计的残差方差。每个参数的边际标准误差为 $\\mathrm{SE}(\\hat{\\theta}_k) = \\sqrt{\\Sigma_{kk}}$。当有 $N$ 个数据点和 $P=3$ 个拟合参数时，自由度为 $d = N - P$。每个参数的双侧 $95\\%$ 置信区间为\n$$\n\\hat{\\theta}_k \\pm t_{0.975, d} \\cdot \\mathrm{SE}(\\hat{\\theta}_k),\n$$\n其中 $t_{0.975, d}$ 是学生t分布 (Student's t distribution) 的分位数。如果 $d \\le 0$，我们退而使用标准正态分位数 $1.96$。\n\n映射到测试套件的算法步骤：\n\n1. 数据生成：\n   - 对每个测试用例，构建时间网格 $t_j = j \\Delta t$ 并计算 $\\mathrm{OD}_{\\mathrm{true}}(t_j) = \\mathrm{OD}_0 e^{r t_j}$。计算背景 $F_{\\mathrm{bg}}(t_j)$ 和 $\\mathrm{OD}_{\\mathrm{blank}}(t_j)$。\n   - 对每个诱导剂浓度 $I_i$，计算真实的目标斜率 $s_{\\mathrm{tar}}(I_i) = s_{\\mathrm{ref}} \\cdot \\dfrac{\\alpha_{\\mathrm{true}} I_i^{n_{\\mathrm{true}}}}{K_{\\mathrm{true}}^{n_{\\mathrm{true}}} + I_i^{n_{\\mathrm{true}}}}$。\n   - 通过添加确定性的正弦扰动来构建测量信号，以模拟仪器和生物学变异：\n     - $\\mathrm{OD}_{\\mathrm{ref}}(i,j) = \\mathrm{OD}_{\\mathrm{true}}(t_j) + A_{\\mathrm{OD}} \\cos(\\omega_{\\mathrm{OD}} t_j + \\psi_{\\mathrm{OD}} i)$,\n     - $F_{\\mathrm{ref}}(i,j) = F_{\\mathrm{bg}}(t_j) + s_{\\mathrm{ref}} \\mathrm{OD}_{\\mathrm{true}}(t_j) + A_{\\mathrm{ref}} \\sin(\\omega_{\\mathrm{ref}} t_j + \\psi_{\\mathrm{ref}} i)$,\n     - $\\mathrm{OD}_{\\mathrm{tar}}(i,j) = \\mathrm{OD}_{\\mathrm{true}}(t_j) + A_{\\mathrm{OD}} \\cos(\\omega_{\\mathrm{OD}} t_j + \\psi_{\\mathrm{OD}} i)$,\n     - $F_{\\mathrm{tar}}(i,j) = F_{\\mathrm{bg}}(t_j) + s_{\\mathrm{tar}}(I_i) \\mathrm{OD}_{\\mathrm{true}}(t_j) + A_{\\mathrm{tar}} \\sin(\\omega_{\\mathrm{tar}} t_j + \\psi_{\\mathrm{tar}} i)$.\n\n2. 信号校正与斜率提取：\n   - 对于每个 $(i,j)$，计算 $\\mathrm{OD}_{\\mathrm{corr,ref}}(i,j) = \\mathrm{OD}_{\\mathrm{ref}}(i,j) - \\mathrm{OD}_{\\mathrm{blank}}(t_j)$ 和 $F_{\\mathrm{corr,ref}}(i,j) = F_{\\mathrm{ref}}(i,j) - F_{\\mathrm{bg}}(t_j)$。对目标启动子进行类似的校正。\n   - 选择 $\\mathrm{OD}_{\\mathrm{corr}} \\in [0.06, 0.30]$ 的时间点。如果满足此条件的点少于三个，则使用所有可用点。\n   - 使用普通最小二乘法拟合 $F_{\\mathrm{corr}}$ 与 $\\mathrm{OD}_{\\mathrm{corr}}$，以获得每个启动子和诱导剂浓度下的斜率。如果由于低信号扰动导致斜率为非正，则用 $10^{-9}$ 替换。\n\n3. RPU 计算：\n   - 对于每个 $I_i$，根据提取的斜率计算 $\\mathrm{RPU}(I_i) = s_{\\mathrm{tar}}(I_i)/s_{\\mathrm{ref}}$。\n\n4. 希尔拟合与不确定性分析：\n   - 将 $f(I)$ 拟合到 $(I_i, \\mathrm{RPU}(I_i))$，并设置边界：$\\alpha \\in (10^{-12}, 10^{6}), K \\in (10^{-9}, 10^{6}), n \\in [0.5, 5.0]$。使用初始猜测值 $\\alpha_0 = \\max_i \\mathrm{RPU}(I_i)$, $K_0$ 为接近半最大值时的正诱导剂浓度（如果需要，则回退到正 $I$ 值的中位数），$n_0 = 2.0$。\n   - 从拟合中获得 $\\hat{\\alpha}$, $\\hat{K}$, $\\hat{n}$ 和协方差 $\\Sigma$。使用自由度为 $d = N - 3$ 的学生t分位数 $t_{0.975, d}$ 计算标准误差和 $95\\%$ 置信区间。\n\n5. 输出：\n   - 对于每个测试用例，按顺序输出九个数字 $\\hat{\\alpha}$, $\\hat{K}$, $\\hat{n}$, $\\alpha_{\\mathrm{low}}$, $\\alpha_{\\mathrm{high}}$, $K_{\\mathrm{low}}$, $K_{\\mathrm{high}}$, $n_{\\mathrm{low}}$, $n_{\\mathrm{high}}$，每个数字四舍五入到六位小数。将三个用例的结果连接成一个扁平列表，并以指定格式作为单行打印。\n\n该方法将测量物理学（荧光与 OD 的正比关系）、标准化活性定义 (RPU) 和一个机理响应模型（希尔函数）联系起来，提供了适用于元件库元数据的参数估计和置信区间。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\nfrom scipy.stats import t as student_t\n\ndef hill_function(I, alpha, K, n):\n    # Hill function with broadcasting support\n    I = np.asarray(I, dtype=float)\n    return alpha * (I ** n) / (K ** n + I ** n)\n\ndef generate_case(time_steps, dt, I_array, OD0, r, od_blank_params, f_bg_params,\n                  s_ref, true_params, perturb_params):\n    \"\"\"\n    Generate deterministic time-course data for reference and target promoters.\n    Returns dictionary with keys:\n    - t: time vector (T,)\n    - I: inducer vector (N_I,)\n    - OD_blank: (T,)\n    - F_bg: (T,)\n    - OD_ref: (N_I, T)\n    - F_ref: (N_I, T)\n    - OD_tar: (N_I, T)\n    - F_tar: (N_I, T)\n    \"\"\"\n    t = np.arange(time_steps, dtype=float) * dt\n    I = np.array(I_array, dtype=float)\n    T = t.size\n    N = I.size\n\n    # Growth\n    OD_true = OD0 * np.exp(r * t)\n\n    # Backgrounds\n    beta0, beta1 = od_blank_params\n    phi0, phi1 = f_bg_params\n    OD_blank = beta0 + beta1 * t\n    F_bg = phi0 + phi1 * t\n\n    # True target slope as function of I\n    alpha_true, K_true, n_true = true_params\n    s_tar_I = s_ref * hill_function(I, alpha_true, K_true, n_true)\n\n    # Perturbations\n    A_OD, w_OD, psi_OD = perturb_params['OD']\n    A_ref, w_ref, psi_ref = perturb_params['ref']\n    A_tar, w_tar, psi_tar = perturb_params['tar']\n\n    # Allocate arrays\n    OD_ref = np.zeros((N, T), dtype=float)\n    F_ref = np.zeros((N, T), dtype=float)\n    OD_tar = np.zeros((N, T), dtype=float)\n    F_tar = np.zeros((N, T), dtype=float)\n\n    for idx in range(N):\n        # OD perturbations (same for ref and tar for simplicity)\n        delta_OD = A_OD * np.cos(w_OD * t + psi_OD * idx)\n        od_meas = OD_true + delta_OD\n\n        # Reference signals\n        OD_ref[idx, :] = od_meas\n        F_ref[idx, :] = F_bg + s_ref * OD_true + A_ref * np.sin(w_ref * t + psi_ref * idx)\n\n        # Target signals\n        OD_tar[idx, :] = od_meas\n        F_tar[idx, :] = F_bg + s_tar_I[idx] * OD_true + A_tar * np.sin(w_tar * t + psi_tar * idx)\n\n    return {\n        't': t,\n        'I': I,\n        'OD_blank': OD_blank,\n        'F_bg': F_bg,\n        'OD_ref': OD_ref,\n        'F_ref': F_ref,\n        'OD_tar': OD_tar,\n        'F_tar': F_tar\n    }\n\ndef select_window_and_slope(OD_corr, F_corr, od_min=0.06, od_max=0.30, min_points=3):\n    \"\"\"\n    Select points in OD window and compute slope of F vs OD using OLS.\n    If fewer than min_points in window, use all points.\n    Returns slope (float).\n    \"\"\"\n    OD_corr = np.asarray(OD_corr, dtype=float)\n    F_corr = np.asarray(F_corr, dtype=float)\n\n    mask = (OD_corr >= od_min) & (OD_corr <= od_max)\n    if np.count_nonzero(mask) < min_points:\n        x = OD_corr\n        y = F_corr\n    else:\n        x = OD_corr[mask]\n        y = F_corr[mask]\n\n    # Fit linear model y = m x + b\n    if x.size < 2:\n        # Fallback if degenerate: return tiny positive slope\n        return 1e-9\n    # Use numpy polyfit for slope\n    m, b = np.polyfit(x, y, 1)\n    if not np.isfinite(m) or m <= 0:\n        # Enforce physical plausibility: non-negative slope\n        m = 1e-9\n    return float(m)\n\ndef fit_hill_with_ci(I, y):\n    \"\"\"\n    Fit Hill function to (I, y) with bounds and compute 95% CI.\n    Returns (alpha, K, n, alpha_low, alpha_high, K_low, K_high, n_low, n_high)\n    \"\"\"\n    I = np.asarray(I, dtype=float)\n    y = np.asarray(y, dtype=float)\n\n    # Initial guesses\n    alpha0 = float(np.max(y))\n    # Estimate K0: choose I closest to half-max among positive I\n    half = alpha0 / 2.0 if alpha0 > 0 else 1.0\n    pos_mask = I > 0\n    if np.any(pos_mask):\n        I_pos = I[pos_mask]\n        y_pos = y[pos_mask]\n        # Find index with y closest to half\n        idx = int(np.argmin(np.abs(y_pos - half)))\n        K0 = float(I_pos[idx])\n    else:\n        K0 = 1.0\n    if K0 <= 0:\n        # Fallback to median positive I or 1.0\n        K0 = float(np.median(I[I > 0])) if np.any(I > 0) else 1.0\n    n0 = 2.0\n\n    # Bounds\n    lower_bounds = (1e-12, 1e-9, 0.5)\n    upper_bounds = (1e6, 1e6, 5.0)\n\n    # Fit\n    try:\n        popt, pcov = curve_fit(\n            hill_function, I, y,\n            p0=(alpha0, K0, n0),\n            bounds=(lower_bounds, upper_bounds),\n            maxfev=100000\n        )\n    except Exception:\n        # In rare failure, return NaNs\n        return [np.nan]*9\n\n    alpha_hat, K_hat, n_hat = popt\n\n    # Compute standard errors\n    if pcov is None or not np.all(np.isfinite(pcov)):\n        se = np.array([np.nan, np.nan, np.nan], dtype=float)\n    else:\n        # Ensure non-negative diagonal\n        diag = np.diag(pcov)\n        diag = np.where(diag < 0, np.nan, diag)\n        se = np.sqrt(diag)\n\n    # Degrees of freedom\n    dof = max(0, len(I) - 3)\n    if dof > 0 and np.isfinite(se).all():\n        tcrit = float(student_t.ppf(0.975, dof))\n    else:\n        tcrit = 1.96\n\n    # Confidence intervals\n    def ci_centered(est, se_val):\n        if not np.isfinite(se_val):\n            return (np.nan, np.nan)\n        low = est - tcrit * se_val\n        high = est + tcrit * se_val\n        return (float(low), float(high))\n\n    alpha_low, alpha_high = ci_centered(alpha_hat, se[0])\n    K_low, K_high = ci_centered(K_hat, se[1])\n    n_low, n_high = ci_centered(n_hat, se[2])\n\n    return [float(alpha_hat), float(K_hat), float(n_hat),\n            alpha_low, alpha_high, K_low, K_high, n_low, n_high]\n\ndef process_case(case):\n    \"\"\"\n    Given a generated case dict, compute RPUs across inducer concentrations,\n    fit Hill, and return the 9-number result list.\n    \"\"\"\n    I = case['I']\n    t = case['t']\n    OD_blank = case['OD_blank']\n    F_bg = case['F_bg']\n    OD_ref_meas = case['OD_ref']\n    F_ref_meas = case['F_ref']\n    OD_tar_meas = case['OD_tar']\n    F_tar_meas = case['F_tar']\n\n    N = I.size\n    T = t.size\n\n    # Correct signals\n    # Broadcast backgrounds across inducer index\n    OD_blank_b = OD_blank.reshape(1, T)\n    F_bg_b = F_bg.reshape(1, T)\n\n    OD_ref_corr = OD_ref_meas - OD_blank_b\n    F_ref_corr = F_ref_meas - F_bg_b\n    OD_tar_corr = OD_tar_meas - OD_blank_b\n    F_tar_corr = F_tar_meas - F_bg_b\n\n    # Compute slopes per inducer\n    slopes_ref = np.zeros(N, dtype=float)\n    slopes_tar = np.zeros(N, dtype=float)\n    for i in range(N):\n        slopes_ref[i] = select_window_and_slope(OD_ref_corr[i, :], F_ref_corr[i, :])\n        slopes_tar[i] = select_window_and_slope(OD_tar_corr[i, :], F_tar_corr[i, :])\n\n    # Compute RPU; avoid division by zero\n    with np.errstate(divide='ignore', invalid='ignore'):\n        rpu = slopes_tar / slopes_ref\n    # Replace non-finite or negative with small positive floor\n    rpu = np.where(~np.isfinite(rpu) | (rpu <= 0), 1e-9, rpu)\n\n    # Fit Hill and compute CI\n    fit_results = fit_hill_with_ci(I, rpu)\n    return fit_results\n\ndef solve():\n    # Define test cases as per the problem statement.\n\n    test_cases = []\n\n    # Case 1\n    params1 = {\n        'time_steps': 6,\n        'dt': 0.5,\n        'I': [0, 1, 3, 10, 30, 100],\n        'OD0': 0.05,\n        'r': 0.9,\n        'od_blank_params': (0.005, 0.001),\n        'f_bg_params': (40.0, 3.0),\n        's_ref': 9000.0,\n        'true_params': (2.0, 12.0, 2.2),\n        'perturb_params': {\n            'OD': (0.002, 0.3, 0.2),\n            'ref': (50.0, 0.7, 0.15),\n            'tar': (60.0, 0.6, 0.17),\n        }\n    }\n    test_cases.append(params1)\n\n    # Case 2\n    params2 = {\n        'time_steps': 6,\n        'dt': 0.6,\n        'I': [0, 0.5, 1.0, 2.0, 4.0],\n        'OD0': 0.06,\n        'r': 0.6,\n        'od_blank_params': (0.004, 0.0008),\n        'f_bg_params': (30.0, 2.0),\n        's_ref': 12000.0,\n        'true_params': (0.6, 1.5, 1.2),\n        'perturb_params': {\n            'OD': (0.0015, 0.3, 0.2),\n            'ref': (30.0, 0.7, 0.15),\n            'tar': (35.0, 0.6, 0.17),\n        }\n    }\n    test_cases.append(params2)\n\n    # Case 3\n    params3 = {\n        'time_steps': 6,\n        'dt': 0.4,\n        'I': [0, 5, 8, 10, 12, 20, 50],\n        'OD0': 0.04,\n        'r': 1.1,\n        'od_blank_params': (0.003, 0.0009),\n        'f_bg_params': (35.0, 2.5),\n        's_ref': 8000.0,\n        'true_params': (1.5, 10.0, 3.0),\n        'perturb_params': {\n            'OD': (0.0025, 0.3, 0.2),\n            'ref': (40.0, 0.7, 0.15),\n            'tar': (45.0, 0.6, 0.17),\n        }\n    }\n    test_cases.append(params3)\n\n    results_flat = []\n\n    for p in test_cases:\n        # Generate data for the case\n        case_data = generate_case(\n            time_steps=p['time_steps'],\n            dt=p['dt'],\n            I_array=p['I'],\n            OD0=p['OD0'],\n            r=p['r'],\n            od_blank_params=p['od_blank_params'],\n            f_bg_params=p['f_bg_params'],\n            s_ref=p['s_ref'],\n            true_params=p['true_params'],\n            perturb_params=p['perturb_params']\n        )\n        # Process case: compute slopes, RPUs, fit Hill, obtain CI\n        res = process_case(case_data)\n        results_flat.extend(res)\n\n    # Round to six decimals and print in required format.\n    results_str = [\"{:.6f}\".format(x) if np.isfinite(x) else \"nan\" for x in results_flat]\n    print(\"[\" + \",\".join(results_str) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2775671"}, {"introduction": "除了功能表征，生物部件的物理完整性——其DNA序列——对于标准化和可重复性也至关重要。本练习将让你扮演质量控制专家的角色，构建一个计算流程，以验证部件序列是否与其预期设计相符 [@problem_id:2775656]。你将实现一个测序错误的概率模型，并使用基础的生物信息学算法进行序列比对，最终在一个贝叶斯框架下计算后验概率 $P(H_1 \\mid R, S_k)$，以判断观测序列与其参考设计的匹配程度。这个实践提供了对支撑可靠部件注册库的严格计算验证方法的亲手体验。", "problem": "您的任务是在标准化生物元件和元件注册库的背景下，实现一个自包含的测序验证流程。注册库提供一个有限的预期元件序列集合，每个序列表示为核苷酸字母表 $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$ 上的字符串。给定一个观测到的读段序列，您必须将其与每个预期序列进行比对，在指定测序仪错误模型下的最大似然比对中标出碱基级别的错配，并计算观测读段是由预期元件而非背景模型生成的后验概率。所有计算必须基于下述的概率论和序列比对的基本原理。\n\n基本假设和定义：\n- 设预期序列为 $S$，观测读段为 $R$。\n- 假设测序仪采用独立单事件错误模型，其参数为 $p_{\\mathrm{sub}}$、$p_{\\mathrm{ins}}$ 和 $p_{\\mathrm{del}}$，每个参数都在开区间 $(0,1)$ 内，分别代表替换、插入和删除的概率。\n- 在正确元件假设下，对于替换事件，当将 $S$ 中的一个碱基 $x \\in \\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$ 与 $R$ 中的一个碱基 $y \\in \\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$ 进行比对时：\n  - 若 $x = y$，发射概率为 $(1 - p_{\\mathrm{sub}})$。\n  - 若 $x \\neq y$，发射到任何其他三种碱基的概率均为 $p_{\\mathrm{sub}} / 3$。\n- 在正确元件假设下，对于插入事件，将每个插入的碱基视为一个独立事件，概率为 $p_{\\mathrm{ins}}$，并假设插入的碱基种类在 $\\{ \\mathrm{A}, \\mathrm{C}, \\mathrm{G}, \\mathrm{T} \\}$ 上均匀分布，因此每个插入的碱基贡献一个因子 $p_{\\mathrm{ins}} / 4$。\n- 在正确元件假设下，对于删除事件，每个被删除的碱基贡献一个因子 $p_{\\mathrm{del}}$。\n- 设背景模型为一个独立同分布的核苷酸过程，其碱基概率 $q_{\\mathrm{A}}, q_{\\mathrm{C}}, q_{\\mathrm{G}}, q_{\\mathrm{T}}$ 之和为 $1$。在背景模型下，读段 $R$ 的似然值是其所有碱基对应背景概率的乘积。\n\n比对要求：\n- 对于每个预期序列 $S$，使用动态规划计算其与 $R$ 的全局比对，以在正确元件假设下最大化对数似然。允许的移动包括：\n  - 对角线移动：将 $S[i]$ 与 $R[j]$ 对齐，如果 $S[i] = R[j]$ 则加上 $\\log(1 - p_{\\mathrm{sub}})$，否则加上 $\\log(p_{\\mathrm{sub}} / 3)$。\n  - 向上移动：删除 $S[i]$，并加上 $\\log(p_{\\mathrm{del}})$。\n  - 向左移动：相对于 $S$ 插入 $R[j]$，并加上 $\\log(p_{\\mathrm{ins}} / 4)$。\n- 使用由上述插入和删除概率所隐含的线性空位罚分的全局比对。在动态规划中，得分相同的平局可以任意解决，但在报告后验概率最高的最佳元件时，必须通过选择最小的索引来打破平局。\n\n后验概率要求：\n- 对于每个具有先验概率 $\\pi_k \\in (0,1)$ 的预期元件 $S_k$，为观测读段 $R$ 定义两个竞争性假设：\n  - $H_1$：$R$ 是通过测序仪错误模型从 $S_k$ 生成的。\n  - $H_0$：$R$ 是由具有碱基概率 $q_{\\mathrm{A}}, q_{\\mathrm{C}}, q_{\\mathrm{G}}, q_{\\mathrm{T}}$ 的背景模型生成的。\n- 设 $\\mathcal{L}_1$表示在 $H_1$ 假设下通过最优比对获得的最大似然值，$\\mathcal{L}_0$表示在 $H_0$ 假设下的背景似然值。根据贝叶斯定理，正确性的后验概率为\n  $$ P(H_1 \\mid R, S_k) \\;=\\; \\frac{\\mathcal{L}_1 \\, \\pi_k}{\\mathcal{L}_1 \\, \\pi_k + \\mathcal{L}_0 \\, (1 - \\pi_k)}. $$\n- 为保证数值稳定性，您的计算可以在对数域中进行。\n\n错配标记：\n- 沿着所选最佳元件的最大似然比对，计算碱基级别错配的数量，其定义为 $S[i] \\neq R[j]$ 的对齐的对角线位置的数量。不要将插入或删除计入此错配计数。\n\n每个测试用例的决策规则和输出：\n- 对于每个包含一组预期元件 $\\{ S_k \\}$ 及相应先验概率 $\\{ \\pi_k \\}$ 的测试用例，计算每个 $k$ 的 $P(H_1 \\mid R, S_k)$，并选择使后验概率最大化的索引 $k^\\ast$。如果有两个或更多元件的后验概率在浮点运算中完全相等，则选择最小的索引。\n- 为该测试用例报告一个结果三元组 $[k^\\ast, M^\\ast, P^\\ast]$，其中 $k^\\ast$ 是使用从零开始的索引选择的元件索引，$M^\\ast$ 是其最大似然比对的错配计数，$P^\\ast$ 是该元件的后验概率，以小数形式四舍五入到六位小数（非分数，也无百分号）。\n\n本问题不涉及角度单位和物理单位。\n\n测试套件与参数：\n实现您的程序以在内部运行以下测试用例集，无需外部输入。每个用例都指定了预期元件序列、观测读段、测序仪错误参数、背景碱基概率以及元件的先验概率。\n\n- 用例 A:\n  - 预期元件: $[\\mathrm{ATGACCAT}, \\mathrm{ATGACCAG}]$\n  - 观测读段: $\\mathrm{ATGACCAT}$\n  - 错误模型: $p_{\\mathrm{sub}} = 0.001$, $p_{\\mathrm{ins}} = 0.000001$, $p_{\\mathrm{del}} = 0.000001$\n  - 背景: $q_{\\mathrm{A}} = 0.25$, $q_{\\mathrm{C}} = 0.25$, $q_{\\mathrm{G}} = 0.25$, $q_{\\mathrm{T}} = 0.25$\n  - 先验概率: $[\\pi_0 = 0.5, \\pi_1 = 0.5]$\n- 用例 B:\n  - 预期元件: $[\\mathrm{ATGACCAT}, \\mathrm{ATGACCAG}]$\n  - 观测读段: $\\mathrm{ATGACCAG}$\n  - 错误模型: $p_{\\mathrm{sub}} = 0.02$, $p_{\\mathrm{ins}} = 0.001$, $p_{\\mathrm{del}} = 0.001$\n  - 背景: $q_{\\mathrm{A}} = 0.25$, $q_{\\mathrm{C}} = 0.25$, $q_{\\mathrm{G}} = 0.25$, $q_{\\mathrm{T}} = 0.25$\n  - 先验概率: $[\\pi_0 = 0.5, \\pi_1 = 0.5]$\n- 用例 C:\n  - 预期元件: $[\\mathrm{TTGACA}]$\n  - 观测读段: $\\mathrm{TTGACAA}$\n  - 错误模型: $p_{\\mathrm{sub}} = 0.005$, $p_{\\mathrm{ins}} = 0.01$, $p_{\\mathrm{del}} = 0.005$\n  - 背景: $q_{\\mathrm{A}} = 0.25$, $q_{\\mathrm{C}} = 0.25$, $q_{\\mathrm{G}} = 0.25$, $q_{\\mathrm{T}} = 0.25$\n  - 先验概率: $[\\pi_0 = 0.8]$\n- 用例 D:\n  - 预期元件: $[\\mathrm{GCTAGC}]$\n  - 观测读段: $\\mathrm{GCTAGC}$\n  - 错误模型: $p_{\\mathrm{sub}} = 0.3$, $p_{\\mathrm{ins}} = 0.05$, $p_{\\mathrm{del}} = 0.05$\n  - 背景: $q_{\\mathrm{A}} = 0.25$, $q_{\\mathrm{C}} = 0.25$, $q_{\\mathrm{G}} = 0.25$, $q_{\\mathrm{T}} = 0.25$\n  - 先验概率: $[\\pi_0 = 0.1]$\n- 用例 E:\n  - 预期元件: $[\\mathrm{AACCGGTT}, \\mathrm{AACCGGTA}]$\n  - 观测读段: $\\mathrm{AACCGGTC}$\n  - 错误模型: $p_{\\mathrm{sub}} = 0.01$, $p_{\\mathrm{ins}} = 0.001$, $p_{\\mathrm{del}} = 0.001$\n  - 背景: $q_{\\mathrm{A}} = 0.25$, $q_{\\mathrm{C}} = 0.25$, $q_{\\mathrm{G}} = 0.25$, $q_{\\mathrm{T}} = 0.25$\n  - 先验概率: $[\\pi_0 = 0.5, \\pi_1 = 0.5]$\n\n最终输出格式：\n- 您的程序应产生单行输出，其中包含一个Python风格的结果列表，每个结果都是一个列表 $[k^\\ast, M^\\ast, P^\\ast]$，与上面列出的用例按相同顺序对应。该行必须只包含此列表，各项之间用逗号分隔，并用方括号括起来。\n\n不应读取任何用户输入。所有计算必须在程序内部自包含。所有概率必须按上面给出的方式作为小数处理，并且任何要求的四舍五入必须按规定应用于最终的后验概率。", "solution": "对问题陈述进行验证。\n\n步骤1：提取的已知条件\n- **任务**：为标准化生物元件实现一个测序验证流程。\n- **每个测试用例的输入**：一组预期元件序列 $\\{S_k\\}$、一个观测读段序列 $R$、测序仪错误参数 $p_{\\mathrm{sub}}, p_{\\mathrm{ins}}, p_{\\mathrm{del}} \\in (0, 1)$、背景核苷酸概率 $\\{q_{\\mathrm{A}}, q_{\\mathrm{C}}, q_{\\mathrm{G}}, q_{\\mathrm{T}}\\}$，以及每个元件的先验概率 $\\{\\pi_k\\} \\in (0, 1)$。\n- **假设 $H_1$ (正确元件)**：读段 $R$ 是从一个预期序列 $S$ 经由指定的错误概率生成的。\n  - 一个比对上的碱基对 $(x, y)$（其中 $x \\in S, y \\in R$）的发射概率：如果 $x=y$ 则为 $(1 - p_{\\mathrm{sub}})$，如果 $x \\neq y$ 则为 $p_{\\mathrm{sub}}/3$。\n  - $R$ 中插入一个碱基的概率：$p_{\\mathrm{ins}}/4$。\n  - 从 $S$ 中删除一个碱基的概率：$p_{\\mathrm{del}}$。\n- **假设 $H_0$ (背景)**：读段 $R$ 是由一个 i.i.d 背景模型根据概率 $q_{\\mathrm{base}}$生成的。似然值 $\\mathcal{L}_0$ 是 $R$ 中所有碱基对应这些概率的乘积。\n- **比对**：必须使用全局比对（Needleman-Wunsch）来寻找在 $H_1$ 假设下给定 $S$ 时 $R$ 的最大对数似然。分数为概率的对数：$\\log(1 - p_{\\mathrm{sub}})$、$\\log(p_{\\mathrm{sub}}/3)$、$\\log(p_{\\mathrm{ins}}/4)$ 和 $\\log(p_{\\mathrm{del}})$。\n- **后验概率**：对于每个元件 $S_k$，计算 $P(H_1 \\mid R, S_k) = \\frac{\\mathcal{L}_1 \\, \\pi_k}{\\mathcal{L}_1 \\, \\pi_k + \\mathcal{L}_0 \\, (1 - \\pi_k)}$，其中 $\\mathcal{L}_1$ 是来自比对的最大似然值。\n- **错配计数**：沿着最佳元件的最大似然比对路径，计算替换（$S[i]$ 与 $R[j]$ 对齐且 $S[i] \\neq R[j]$）的数量。\n- **决策规则**：选择使后验概率最大化的元件索引 $k^*$。通过选择最小的索引来打破平局。\n- **输出**：对于每个测试用例，输出一个三元组 $[k^*, M^*, P^*]$，其中 $k^*$ 是所选索引，$M^*$ 是其错配计数，$P^*$ 是其四舍五入到六位小数的后验概率。\n\n步骤2：验证\n- **科学依据**：该问题是生物信息学和概率论基本原理的应用。使用动态规划进行序列比对、测序仪错误的概率建模以及贝叶斯推断都是计算生物学中标准且成熟的方法。该模型虽是简化版，但科学上是有效的。\n- **适定性**：该问题以数学的精确性进行了规定。所有输入、参数和目标函数都有明确定义。动态规划框架保证了可以找到最大似然比对得分。后验概率的公式和打破平局的规则确保了唯一解的存在。\n- **客观性**：问题陈述语言精确、无偏、正式，不含主观因素。\n\n步骤3：结论\n问题有效。这是一个定义明确的生物信息学计算练习，需要正确应用已建立的算法和概率原理。我将继续进行求解。\n\n解决方案需要一个系统性的、基于原理的方法。对于每个测试用例，必须针对每个预期元件序列 $S_k$ 和观测读段 $R$ 执行一系列计算。\n\n首先，我们处理背景假设 $H_0$。在此模型下，读段 $R$ 被假定由一个独立同分布过程生成。观测到 $R = r_1 r_2 \\dots r_n$ 的似然值为 $\\mathcal{L}_0$ 。为了数值稳定性，我们在对数域中操作。对数似然为：\n$$ \\log \\mathcal{L}_0 = \\sum_{j=1}^{|R|} \\log q_{r_j} $$\n其中 $q_{r_j}$ 是读段 $R$ 中位置 $j$ 的核苷酸 $r_j$ 的背景概率。\n\n接下来，我们评估正确元件假设 $H_1$。读段 $R$ 从特定元件 $S_k$ 生成的似然值 $\\mathcal{L}_{1,k}$ 是通过找到它们之间最可能的比对来确定的。这等同于最大化比对中所有事件（匹配、替换、插入、删除）的对数概率之和。这是一个经典的全局比对问题，可以用类似于Needleman-Wunsch的动态规划算法解决。\n\n设 $S_k$ 的长度为 $m$，$R$ 的长度为 $n$。我们构建一个大小为 $(m+1) \\times (n+1)$ 的动态规划表 $D$，其中 $D_{i,j}$ 存储将前缀 $S_k[1..i]$ 与 $R[1..j]$ 比对的最大对数似然。比对操作的得分定义如下：\n- 匹配得分: $s_{\\mathrm{match}} = \\log(1 - p_{\\mathrm{sub}})$\n- 替换得分: $s_{\\mathrm{sub}} = \\log(p_{\\mathrm{sub}} / 3)$\n- 插入得分: $s_{\\mathrm{ins}} = \\log(p_{\\mathrm{ins}} / 4)$\n- 删除得分: $s_{\\mathrm{del}} = \\log(p_{\\mathrm{del}})$\n\n带有线性空位罚分的全局比对的DP表初始化如下：\n$$ D_{0,0} = 0 $$\n$$ D_{i,0} = i \\cdot s_{\\mathrm{del}} \\quad \\text{for } i \\in [1, m] $$\n$$ D_{0,j} = j \\cdot s_{\\mathrm{ins}} \\quad \\text{for } j \\in [1, n] $$\n\n填充表格其余部分的递推关系（对于 $i \\in [1, m]$ 和 $j \\in [1, n]$）是：\n$$ D_{i,j} = \\max \\begin{cases} D_{i-1,j-1} + s(S_k[i], R[j]) & \\text{(匹配/错配)} \\\\ D_{i-1,j} + s_{\\mathrm{del}} & \\text{(删除)} \\\\ D_{i,j-1} + s_{\\mathrm{ins}} & \\text{(插入)} \\end{cases} $$\n其中，如果 $S_k[i] = R[j]$，则 $s(S_k[i], R[j])$ 为 $s_{\\mathrm{match}}$，否则为 $s_{\\mathrm{sub}}$。$S_k$ 和 $R$ 比对的最大对数似然是最后一个单元格的值，$\\log \\mathcal{L}_{1,k} = D_{m,n}$。\n\n为了确定错配计数 $M^*$，我们必须重建最优比对路径。这通过一个回溯过程实现，从单元格 $(m,n)$ 开始，通过遵循每一步导致最大得分的选择，回溯到 $(0,0)$。在回溯过程中，对于每个从 $(i,j)$ 到 $(i-1,j-1)$ 且 $S_k[i] \\neq R[j]$ 的对角线移动，我们增加一个计数器。\n\n在计算出 $\\log \\mathcal{L}_0$ 和 $\\log \\mathcal{L}_{1,k}$ 后，我们可以求出后验概率 $P(H_1 \\mid R, S_k)$。问题给出了公式：\n$$ P(H_1 \\mid R, S_k) = \\frac{\\mathcal{L}_1 \\, \\pi_k}{\\mathcal{L}_1 \\, \\pi_k + \\mathcal{L}_0 \\, (1 - \\pi_k)} $$\n为了防止小似然值导致的数值下溢，将其重新表述为对数空间计算：\n$$ P(H_1 \\mid R, S_k) = \\frac{1}{1 + \\frac{\\mathcal{L}_0(1-\\pi_k)}{\\mathcal{L}_1\\pi_k}} = \\frac{1}{1 + \\exp\\left(\\log\\left(\\frac{\\mathcal{L}_0(1-\\pi_k)}{\\mathcal{L}_1\\pi_k}\\right)\\right)} $$\n$$ P(H_1 \\mid R, S_k) = \\left(1 + \\exp\\left( (\\log\\mathcal{L}_0 + \\log(1-\\pi_k)) - (\\log\\mathcal{L}_{1,k} + \\log\\pi_k) \\right)\\right)^{-1} $$\n这个表达式是数值稳定的，可以使用标准浮点运算进行计算。\n\n最后，对于每个测试用例，我们为所有候选元件 $\\{S_k\\}$ 计算此后验概率。选择对应于最大后验概率的索引 $k^*$，并通过选择最小索引来打破平局。报告此胜出元件的错配计数 $M^*$ 和四舍五入后的后验概率 $P^*$。整个过程封装在提供的代码中。", "answer": "```python\nimport numpy as np\n\ndef align_and_count_mismatches(S, R, log_p_match, log_p_sub, log_p_ins, log_p_del):\n    \"\"\"\n    Performs global alignment to find max log-likelihood and counts mismatches.\n    \"\"\"\n    m, n = len(S), len(R)\n    # DP table for scores\n    dp = np.full((m + 1, n + 1), -np.inf)\n    # Traceback table: 0 for diagonal, 1 for up (deletion), 2 for left (insertion)\n    trace = np.zeros((m + 1, n + 1), dtype=int)\n\n    # Initialization\n    dp[0, 0] = 0\n    for i in range(1, m + 1):\n        dp[i, 0] = i * log_p_del\n        trace[i, 0] = 1\n    for j in range(1, n + 1):\n        dp[0, j] = j * log_p_ins\n        trace[0, j] = 2\n\n    # Fill DP table\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            match_mismatch_score = log_p_match if S[i - 1] == R[j - 1] else log_p_sub\n            \n            scores = [\n                dp[i - 1, j - 1] + match_mismatch_score,  # Diagonal\n                dp[i - 1, j] + log_p_del,              # Up (Deletion)\n                dp[i, j - 1] + log_p_ins               # Left (Insertion)\n            ]\n            \n            best_score_idx = np.argmax(scores)\n            dp[i, j] = scores[best_score_idx]\n            trace[i, j] = best_score_idx\n\n    log_L1 = dp[m, n]\n\n    # Traceback for mismatch count\n    mismatches = 0\n    i, j = m, n\n    while i > 0 or j > 0:\n        move = trace[i, j]\n        if move == 0:  # Diagonal move\n            if S[i - 1] != R[j - 1]:\n                mismatches += 1\n            i -= 1\n            j -= 1\n        elif move == 1:  # Up move (deletion)\n            i -= 1\n        else:  # Left move (insertion)\n            j -= 1\n            \n    return log_L1, mismatches\n\ndef solve():\n    test_cases = [\n        {\n            \"parts\": [\"ATGACCAT\", \"ATGACCAG\"],\n            \"read\": \"ATGACCAT\",\n            \"params\": {\"p_sub\": 0.001, \"p_ins\": 1e-6, \"p_del\": 1e-6},\n            \"background\": {\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"T\": 0.25},\n            \"priors\": [0.5, 0.5]\n        },\n        {\n            \"parts\": [\"ATGACCAT\", \"ATGACCAG\"],\n            \"read\": \"ATGACCAG\",\n            \"params\": {\"p_sub\": 0.02, \"p_ins\": 0.001, \"p_del\": 0.001},\n            \"background\": {\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"T\": 0.25},\n            \"priors\": [0.5, 0.5]\n        },\n        {\n            \"parts\": [\"TTGACA\"],\n            \"read\": \"TTGACAA\",\n            \"params\": {\"p_sub\": 0.005, \"p_ins\": 0.01, \"p_del\": 0.005},\n            \"background\": {\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"T\": 0.25},\n            \"priors\": [0.8]\n        },\n        {\n            \"parts\": [\"GCTAGC\"],\n            \"read\": \"GCTAGC\",\n            \"params\": {\"p_sub\": 0.3, \"p_ins\": 0.05, \"p_del\": 0.05},\n            \"background\": {\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"T\": 0.25},\n            \"priors\": [0.1]\n        },\n        {\n            \"parts\": [\"AACCGGTT\", \"AACCGGTA\"],\n            \"read\": \"AACCGGTC\",\n            \"params\": {\"p_sub\": 0.01, \"p_ins\": 0.001, \"p_del\": 0.001},\n            \"background\": {\"A\": 0.25, \"C\": 0.25, \"G\": 0.25, \"T\": 0.25},\n            \"priors\": [0.5, 0.5]\n        }\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        R = case[\"read\"]\n        params = case[\"params\"]\n        p_sub, p_ins, p_del = params[\"p_sub\"], params[\"p_ins\"], params[\"p_del\"]\n        log_p_match = np.log(1 - p_sub)\n        log_p_sub = np.log(p_sub / 3)\n        log_p_ins = np.log(p_ins / 4)\n        log_p_del = np.log(p_del)\n\n        log_q_map = {base: np.log(p) for base, p in case[\"background\"].items()}\n        log_L0 = sum(log_q_map[base] for base in R)\n\n        part_results = []\n        for S_k, pi_k in zip(case[\"parts\"], case[\"priors\"]):\n            log_L1_k, mismatches = align_and_count_mismatches(S_k, R, log_p_match, log_p_sub, log_p_ins, log_p_del)\n\n            # Compute posterior probability in log space for stability\n            log_pi_k = np.log(pi_k)\n            log_1_minus_pi_k = np.log(1 - pi_k)\n            \n            term_H1 = log_L1_k + log_pi_k\n            term_H0 = log_L0 + log_1_minus_pi_k\n            \n            # Posterior = 1 / (1 + exp(term_H0 - term_H1))\n            diff_log_terms = term_H0 - term_H1\n            posterior = 1.0 / (1.0 + np.exp(diff_log_terms))\n            \n            part_results.append({\n                \"posterior\": posterior,\n                \"mismatches\": mismatches\n            })\n        \n        # Determine the best part based on max posterior, with tie-breaking\n        best_part_idx, max_posterior = -1, -1.0\n        for i, res in enumerate(part_results):\n            if res[\"posterior\"] > max_posterior:\n                max_posterior = res[\"posterior\"]\n                best_part_idx = i\n\n        best_mismatches = part_results[best_part_idx][\"mismatches\"]\n        \n        final_results.append([\n            best_part_idx,\n            best_mismatches,\n            round(max_posterior, 6)\n        ])\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "2775656"}, {"introduction": "标准化的最终目标是创建可互操作、可查询的生物部件集合。本实践聚焦于如何从一个使用语义网技术（如资源描述框架RDF和合成生物学开放语言SBOL）的现代部件注册库中检索信息。你将学习使用RDF的标准查询语言SPARQL来构建形式化查询，以便根据特定标准（如其功能——序列本体论角色，以及定量性能数据）来查找部件 [@problem_id:2775693]。对于希望高效导航和利用日益增长的公共生物部件资源的研究者来说，掌握这项技能至关重要。", "problem": "您的任务是形式化一个查询构建问题，该问题基于生物部件的标准化及其在知识库中的注册，这些知识库通过资源描述框架 (RDF) 接口（例如 SynBioHub）公开数据，SynBioHub 将合成生物学开放语言 (SBOL) 数据编码为 RDF。您将生成 SPARQL（RDF 结构化查询语言）查询，以根据序列本体论 (Sequence Ontology) 角色和数值表征阈值来检索标准化部件，并演示正确的分页和排序。您的程序不会查询实时端点；相反，它将通过算法构建查询字符串，并验证其是否符合正式指定的约束。\n\n基本和核心定义：\n- 资源描述框架 (RDF) 将知识建模为“主体-谓词-客体”形式的三元组。一个三元组可以写为 $(s, p, o)$。\n- 统一资源标识符 (URI) 和国际化资源标识符 (IRI) 是 RDF 资源的标准化标识符。\n- 合成生物学开放语言 (SBOL) 表示生物部件，例如组件及其角色；在 RDF 形式中，一个部件可以是一个类型为 $sbol:ComponentDefinition$ 的节点，其角色来自序列本体论 (SO)。\n- 序列本体论 (SO) 为序列特征类型分配 IRI；转录终止子由 $so:0000141$ 表示，其前缀为 $so: \\langle http://purl.obolibrary.org/obo/SO_ \\rangle$，展开后为 IRI $\\langle http://purl.obolibrary.org/obo/SO_0000141 \\rangle$。\n- SPARQL 是一种用于 RDF 的声明式查询语言。SELECT、WHERE、FILTER、ORDER BY、LIMIT 和 OFFSET 等子句用于检索、约束、排序和分页结果。ORDER BY 子句支持 $ASC(\\cdot)$ 或 $DESC(\\cdot)$ 来指定升序或降序。\n\n问题要求：\n- 您的任务是为每个参数集生成一个 SPARQL SELECT 查询，以检索所有类型为 $sbol:ComponentDefinition$ 且具有序列本体论 (Sequence Ontology) 角色 $so:0000141$（终止子）的 SBOL 部件。每个此类部件都必须有一个数值表征，在本练习中我们称之为相对启动子单位 (Relative Promoter Units, RPU)，它被建模为与该部件链接的测量资源。查询必须至少返回变量 $?part$、$?label$ 和 $?rpu$；当按显示标识符排序时，还必须额外返回 $?displayId$。\n- 需假定的 RDF 词汇表如下：\n  - 前缀：\n    - $rdf:$ $\\langle http://www.w3.org/1999/02/22-rdf-syntax-ns\\# \\rangle$\n    - $rdfs:$ $\\langle http://www.w3.org/2000/01/rdf-schema\\# \\rangle$\n    - $xsd:$ $\\langle http://www.w3.org/2001/XMLSchema\\# \\rangle$\n    - $sbol:$ $\\langle http://sbols.org/v2\\# \\rangle$\n    - $so:$ $\\langle http://purl.obolibrary.org/obo/SO_ \\rangle$\n    - $meas:$ $\\langle http://example.org/measurement\\# \\rangle$\n  - WHERE 子句中必需的三元组模式：\n    - $?part \\ rdf:type \\ sbol:ComponentDefinition.$\n    - $?part \\ sbol:role \\ so:0000141.$\n    - $?part \\ rdfs:label \\ ?label.$\n    - $?part \\ meas:hasMeasurement \\ ?m.$\n    - $?m \\ rdf:type \\ meas:Measurement.$\n    - $?m \\ meas:type \\ meas:RPU.$\n    - $?m \\ meas:value \\ ?rpu.$\n  - 数值阈值过滤必须使用形式为 $FILTER(xsd:decimal(?rpu) > T)$ 的 SPARQL FILTER 子句来强制执行，其中 $T$ 是数值阈值参数。\n  - 排序和分页：\n    - 设排序键为 $K \\in \\{\\text{\"label\"}, \\text{\"rpu\"}, \\text{\"displayId\"}\\}$，排序方向为 $D \\in \\{\\text{\"ASC\"}, \\text{\"DESC\"}\\}$。\n    - 如果 $K = \\text{\"label\"}$，则包含 $ORDER \\ BY \\ D(?label)$。\n    - 如果 $K = \\text{\"rpu\"}$，则包含 $ORDER \\ BY \\ D(xsd:decimal(?rpu))$。\n    - 如果 $K = \\text{\"displayId\"}$，您还必须在 WHERE 子句中包含三元组模式 $?part \\ sbol:displayId \\ ?displayId.$，在投影（SELECT 子句）中包含 $?displayId$，并包含 $ORDER \\ BY \\ D(?displayId)$。\n    - 使用 $LIMIT \\ L$ 和 $OFFSET \\ O$ 进行分页，其中 $L$ 是最大行数，$O$ 是行偏移量。\n- 您的程序必须为每个参数集构建 SPARQL 查询字符串，然后验证构建的字符串是否包含由参数所暗示的正确结构组件。为每个参数集输出一个布尔值，指示构建的查询是否满足该情况下的所有必需约束。\n\n输入规范：\n- 没有运行时输入；相反，您必须硬编码以下参数元组 $(T, L, O, K, D)$ 的测试套件：\n  1. $(T{=}1.0, \\ L{=}25, \\ O{=}0, \\ K{=}\\text{\"label\"}, \\ D{=}\\text{\"ASC\"})$\n  2. $(T{=}0.0, \\ L{=}10, \\ O{=}20, \\ K{=}\\text{\"rpu\"}, \\ D{=}\\text{\"DESC\"})$\n  3. $(T{=}3.5, \\ L{=}50, \\ O{=}100, \\ K{=}\\text{\"displayId\"}, \\ D{=}\\text{\"ASC\"})$\n  4. $(T{=}2.0, \\ L{=}0, \\ O{=}0, \\ K{=}\\text{\"rpu\"}, \\ D{=}\\text{\"ASC\"})$  (限制为零的边界情况)\n  5. $(T{=}-1.0, \\ L{=}5, \\ O{=}5, \\ K{=}\\text{\"label\"}, \\ D{=}\\text{\"DESC\"})$  (负阈值的边缘情况)\n\n您的程序必须为每个构建的查询检查的验证标准：\n- 所有上述必需的 PREFIX 声明的存在性。\n- 所有必需的 WHERE 三元组模式的存在性，包括仅当 $K = \\text{\"displayId\"}$ 时才出现 $sbol:displayId$ 三元组。\n- FILTER 子句必须是 $FILTER(xsd:decimal(?rpu) > T)$ 的精确形式，其中 $T$ 实例化为测试用例的数值阈值。\n- SELECT 子句必须包含 $?part$、$?label$ 和 $?rpu$，并且当且仅当 $K = \\text{\"displayId\"}$ 时才包含 $?displayId$。\n- ORDER BY 子句必须与上面指定的参数化排序键和方向匹配，包括当 $K = \\text{\"rpu\"}$ 时所需的 $xsd:decimal$ 类型转换。\n- LIMIT 和 OFFSET 值必须与 $L$ 和 $O$ 完全匹配。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。例如，如果所有五个测试用例都通过了各自的验证，则输出将是 $[\\text{True},\\text{True},\\text{True},\\text{True},\\text{True}]$。实际输出应为 $[\\text{b}_1,\\text{b}_2,\\text{b}_3,\\text{b}_4,\\text{b}_5]$，其中每个 $\\text{b}_i$ 是一个布尔值。\n\n角度单位、物理单位和百分比：\n- 不涉及角度单位或物理单位。所有数值阈值都是纯数字。不要输出任何百分比。\n\n您的解决方案必须是一个完整、可运行的 Python 程序，它为提供的测试套件构建并验证 SPARQL 查询，并按上述规定打印所需的单行布尔列表。", "solution": "问题陈述经评估为有效。它在科学上基于合成生物学数据管理领域，使用了 RDF、SBOL 和 SPARQL 等既定标准。要求是客观、适定且自洽的，为算法实现提供了清晰的基础。任务是构建并验证 SPARQL 查询，这是一个形式化且可验证的过程。\n\n该解决方案的架构是一个 Python 程序，它为每个提供的参数集 $(T, L, O, K, D)$ 执行两个顺序操作：查询构建和查询验证。这种方法确保程序不仅生成所需的输出，而且还根据问题的严格规范对其自身逻辑进行内部验证。\n\n首先，设计一个查询生成函数。该函数接受一组参数作为输入：一个数值阈值 $T$、一个限制 $L$、一个偏移量 $O$、一个排序键 $K \\in \\{\\text{\"label\"}, \\text{\"rpu\"}, \\text{\"displayId\"}\\}$ 和一个排序方向 $D \\in \\{\\text{\"ASC\"}, \\text{\"DESC\"}\\}$。它系统地从其构成子句组装成一个 SPARQL 查询字符串。\n\n`PREFIX` 子句是静态的，包括所有六个必需的命名空间前缀：$rdf:$, $rdfs:$, $xsd:$, $sbol:$, $so:$ 和 $meas:$。\n\n`SELECT` 子句是动态构建的。它始终投影变量 $?part$、$?label$ 和 $?rpu$。关键是，如果排序键 $K$ 被指定为 $\\text{\"displayId\"}$，变量 $?displayId$ 也会被包含在投影中。\n\n`WHERE` 子句包含一组固定的七个三元组模式，这些模式定义了要匹配的核心图结构。这些模式确定由 $?part$ 标识的资源必须是 $sbol:ComponentDefinition$，具有终止子 ($so:0000141$) 的序列本体论角色，并通过一个中间测量资源 $?m$ 与类型为 $meas:RPU$ 的数值测量相关联。如果排序键 $K$ 是 $\\text{\"displayId\"}$，一个额外的三元组模式 $?part \\ sbol:displayId \\ ?displayId.$ 会被附加到 `WHERE` 子句中。最后，包含一个形式为 $FILTER(xsd:decimal(?rpu) > T)$ 的 `FILTER` 表达式，以强制执行对测量值的数值阈值约束。\n\n查询修饰符最后附加。`ORDER BY` 子句的内容由参数 $K$ 和 $D$ 决定。对于 $K=\\text{\"label\"}$，它变为 $ORDER \\ BY \\ D(?label)$。对于 $K=\\text{\"rpu\"}$，它是 $ORDER \\ BY \\ D(xsd:decimal(?rpu))$，这能正确地对值进行数值排序。对于 $K=\\text{\"displayId\"}$，它是 $ORDER \\ BY \\ D(?displayId)$。`LIMIT` 和 `OFFSET` 子句直接从参数 $L$ 和 $O$ 填充以处理分页。\n\n其次，实现一个验证函数来检查生成的查询字符串的正确性。此步骤对于确认构建逻辑遵守所有约束至关重要。验证是对生成字符串的一系列检查：\n1.  **前缀**：确认所有必需的 `PREFIX` 声明的存在性。\n2.  **SELECT 子句**：它验证 `SELECT` 子句包含 $?part$、$?label$ 和 $?rpu$。它还对 $?displayId$ 强制执行“当且仅当”条件：当 $K = \\text{\"displayId\"}$ 时，其存在是强制性的，否则是禁止的。\n3.  **WHERE 子句**：它检查所有强制性三元组模式的存在性。类似地，它对 $?part \\ sbol:displayId \\ ?displayId.$ 模式强制执行“当且仅当”条件。\n4.  **FILTER 子句**：它验证 `FILTER` 子句是否以 $FILTER(xsd:decimal(?rpu) > T)$ 的确切形式存在，其中 $T$ 实例化为该测试用例的特定值。\n5.  **ORDER BY 子句**：它确认 `ORDER BY` 子句与由参数 $K$ 和 $D$ 决定的结构相匹配。\n6.  **LIMIT 和 OFFSET**：它确保 `LIMIT` 和 `OFFSET` 子句以正确的整数值 $L$ 和 $O$ 存在。\n\n程序迭代五个硬编码的测试用例。对于每个用例，它生成查询并运行验证逻辑。验证的布尔结果被存储。最终输出是这些布尔值的列表，按要求格式化为单个字符串。此设计为指定问题提供了一个健壮且可验证的解决方案。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_and_verify_query(T, L, O, K, D):\n    \"\"\"\n    Generates a SPARQL query based on the given parameters and verifies its structure.\n\n    Args:\n        T (float): The numeric threshold for RPU.\n        L (int): The LIMIT for pagination.\n        O (int): The OFFSET for pagination.\n        K (str): The sort key (\"label\", \"rpu\", or \"displayId\").\n        D (str): The sort direction (\"ASC\" or \"DESC\").\n\n    Returns:\n        bool: True if the generated query passes all verification checks, False otherwise.\n    \"\"\"\n    \n    # 1. Query Construction\n    \n    prefixes = [\n        \"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\",\n        \"PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\",\n        \"PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\",\n        \"PREFIX sbol: <http://sbols.org/v2#>\",\n        \"PREFIX so: <http://purl.obolibrary.org/obo/SO_>\",\n        \"PREFIX meas: <http://example.org/measurement#>\"\n    ]\n    prefix_str = \"\\n\".join(prefixes)\n\n    select_vars = \"?part ?label ?rpu\"\n    if K == \"displayId\":\n        select_vars += \" ?displayId\"\n    select_clause = f\"SELECT {select_vars}\"\n\n    where_patterns = [\n        \"?part rdf:type sbol:ComponentDefinition.\",\n        \"?part sbol:role so:0000141.\",\n        \"?part rdfs:label ?label.\",\n        \"?part meas:hasMeasurement ?m.\",\n        \"?m rdf:type meas:Measurement.\",\n        \"?m meas:type meas:RPU.\",\n        \"?m meas:value ?rpu.\"\n    ]\n    if K == \"displayId\":\n        where_patterns.append(\"?part sbol:displayId ?displayId.\")\n    \n    filter_clause_str = f\"FILTER(xsd:decimal(?rpu) > {str(T)})\"\n    \n    where_patterns_str = \"  \" + \"\\n  \".join(where_patterns)\n    where_clause = f\"WHERE {{\\n{where_patterns_str}\\n  {filter_clause_str}\\n}}\"\n\n    order_by_clause = \"\"\n    if K == \"label\":\n        order_by_clause = f\"ORDER BY {D}(?label)\"\n    elif K == \"rpu\":\n        order_by_clause = f\"ORDER BY {D}(xsd:decimal(?rpu))\"\n    elif K == \"displayId\":\n        order_by_clause = f\"ORDER BY {D}(?displayId)\"\n\n    limit_clause = f\"LIMIT {L}\"\n    offset_clause = f\"OFFSET {O}\"\n    \n    modifiers_str = \"\\n\".join([order_by_clause, limit_clause, offset_clause])\n\n    query = \"\\n\".join([prefix_str, select_clause, where_clause, modifiers_str])\n\n    # 2. Query Verification\n\n    # Check Prefixes\n    if not all(p in query for p in prefixes):\n        return False\n\n    # Check SELECT clause\n    try:\n        select_part = query.split(\"SELECT\")[1].split(\"WHERE\")[0]\n        if not (\"?part\" in select_part and \"?label\" in select_part and \"?rpu\" in select_part):\n            return False\n        if K == \"displayId\":\n            if \"?displayId\" not in select_part:\n                return False\n        else: # \"if and only if\" check\n            if \"?displayId\" in select_part:\n                return False\n    except IndexError:\n        return False\n\n    # Check WHERE triple patterns\n    base_where_patterns = [\n        \"?part rdf:type sbol:ComponentDefinition.\",\n        \"?part sbol:role so:0000141.\",\n        \"?part rdfs:label ?label.\",\n        \"?part meas:hasMeasurement ?m.\",\n        \"?m rdf:type meas:Measurement.\",\n        \"?m meas:type meas:RPU.\",\n        \"?m meas:value ?rpu.\"\n    ]\n    if not all(p in query for p in base_where_patterns):\n        return False\n    \n    displayid_pattern = \"?part sbol:displayId ?displayId.\"\n    if K == \"displayId\":\n        if displayid_pattern not in query:\n            return False\n    else: # \"if and only if\" check\n        if displayid_pattern in query:\n            return False\n\n    # Check FILTER clause\n    expected_filter = f\"FILTER(xsd:decimal(?rpu) > {str(T)})\"\n    if expected_filter not in query:\n        return False\n\n    # Check ORDER BY clause\n    if order_by_clause not in query:\n        return False\n\n    # Check LIMIT and OFFSET clauses\n    if f\"LIMIT {L}\" not in query or f\"OFFSET {O}\" not in query:\n        return False\n        \n    return True\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 25, 0, \"label\", \"ASC\"),\n        (0.0, 10, 20, \"rpu\", \"DESC\"),\n        (3.5, 50, 100, \"displayId\", \"ASC\"),\n        (2.0, 0, 0, \"rpu\", \"ASC\"),\n        (-1.0, 5, 5, \"label\", \"DESC\"),\n    ]\n\n    results = []\n    for case in test_cases:\n        T, L, O, K, D = case\n        is_valid = generate_and_verify_query(T, L, O, K, D)\n        results.append(is_valid)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2775693"}]}