{"hands_on_practices": [{"introduction": "在系统生物学中，获得一个统计上显著的p值仅仅是科学探究的开始，而非终点。本练习旨在阐明一个核心概念：统计关联不等于生物学上的因果关系，这是解读任何观测性数据的基石。通过分析一个微小RNA（miRNA）和其靶蛋白之间相关性的案例，你将学会如何避免科学推理中一个常见且严重的错误，即混淆相关性与因果性。[@problem_id:1438456]", "problem": "在一项旨在理解蛋白质调控的系统生物学研究中，一个研究团队调查了一种名为miR-451的微小RNA (miRNA) 与一种名为糖酵解抑制因子 (Glycolysis-Inhibiting Factor, GIF) 的蛋白质之间可能存在的联系。该团队的假说是，miR-451通过靶向GIF的信使RNA (mRNA) 使其降解，从而直接导致GIF的下调。\n\n为检验此假说，他们从200名患者身上收集了组织样本，并测量了每个样本中miR-451和GIF蛋白的表达水平。对数据进行统计分析后，他们发现miR-451和GIF的表达之间的皮尔逊相关系数为 $r = -0.72$。该相关性的p值经计算为 $p = 0.0011$。\n\n基于此结果，一位初级研究员得出结论，认为这些数据为miR-451直接抑制GIF表达的因果假说提供了明确的证据。然而，首席研究员认为这个结论言过其实。\n\n下列哪个陈述提供了最根本且准确的原因，来解释为什么这个统计上显著的相关性本身不足以证明一个直接的因果调控关系？\n\nA. $0.0011$的p值在$0.05$的alpha水平上是统计显著的，但在更严格的$0.001$的alpha水平上则不显著。因此，这一发现仍可能是一个随机假象。\n\nB. 200名患者的样本量不足以建立因果联系；这类主张需要来自数千个个体的数据。\n\nC. 负相关系数表示随着miR-451水平的增加，GIF蛋白水平也增加，这与所提出的抑制作用相矛盾。\n\nD. 皮尔逊相关系数只衡量线性关系的强度。真实的生物学相互作用可能是非线性的，这使得该分析对于得出结论无效。\n\nE. 观察到的相关性可能由第三个未测量的生物学因素（一个混杂因素）引起，例如一个主转录因子，它同时促进miR-451的表达并抑制编码GIF的基因的表达。", "solution": "我们首先对报告的统计数据所代表的含义进行形式化说明。设 $X$ 表示miR-451的表达，设 $Y$ 表示在 $n=200$ 个样本中的GIF蛋白表达。皮尔逊相关系数 $r=-0.72$ 是对总体相关性 $\\rho=\\operatorname{Corr}(X,Y)$ 的一个估计。所进行的假设检验是标准的 $H_{0}:\\rho=0$ 对立于 $H_{1}:\\rho\\neq 0$。报告的 $p=0.0011$ 是在 $H_{0}$ 成立的条件下，观测到样本相关性的绝对值至少与 $|r|$ 一样极端的概率。因此，该统计结果支持拒绝 $H_{0}$，并得出总体中 $\\rho\\neq 0$ 的结论。\n\n然而，拒绝 $H_{0}$ 并不能建立一个直接的因果效应 $X\\to Y$。一个统计上显著的相关性是一种关联；因果关系需要额外的假设或设计（例如，随机化、受控扰动、纵向识别或对混杂因素的严格调整）。关键的局限性在于，相关性可以由多种不包含直接调控关系的因果结构产生。\n\n为了具体地说明这一点，考虑一个简单的结构方程模型，其中存在第三个未测量的因素 $Z$（例如一个主调控因子），它同时影响 $X$ 和 $Y$：\n$$\nX=\\alpha Z+\\epsilon_{X},\\quad Y=\\beta Z+\\epsilon_{Y},\n$$\n其中 $\\operatorname{Cov}(Z,\\epsilon_{X})=0$、$\\operatorname{Cov}(Z,\\epsilon_{Y})=0$ 且 $\\operatorname{Cov}(\\epsilon_{X},\\epsilon_{Y})=0$。那么 $X$ 和 $Y$ 之间的协方差为\n$$\n\\operatorname{Cov}(X,Y)=\\operatorname{Cov}(\\alpha Z+\\epsilon_{X},\\,\\beta Z+\\epsilon_{Y})=\\alpha\\beta\\,\\operatorname{Var}(Z).\n$$\n如果 $\\alpha>0$ 且 $\\beta<0$，那么 $\\operatorname{Cov}(X,Y)<0$，因此 $\\rho<0$，这就在 $X$ 和 $Y$ 之间产生了一个负相关，而没有任何从 $X$ 到 $Y$ 的直接因果联系。这明确地证明了相关性——无论其多么强或在统计上多么显著——都可能由一个混杂因素 $Z$ 产生。\n\n这种可能性与样本量或显著性阈值的问题是不同的。具体来说：\n- 选项A关注显著性水平的选择。即使 $p<0.001$（更严格），根本问题依然存在：$\\rho\\neq 0$ 的显著性并不意味着 $X\\to Y$。\n- 选项B声称 $n=200$ 不足以确立因果关系；仅凭样本量无法建立因果关系，因果关系取决于研究设计和可识别性，而不仅仅是 $n$。\n- 选项C误解了符号的含义：$r=-0.72$ 意味着当 $X$ 增加时， $Y$ 趋于减少，这在关联层面上与抑制性假说是一致的，并不矛盾。\n- 选项D指出皮尔逊系数衡量的是线性关联，但即使是完美的线性关联也不意味着直接的因果关系；非线性不是这里的核心问题。\n\n因此，相关性不足以证明直接因果调控关系的最根本且准确的原因是，可能存在一个未测量的混杂因素同时驱动这两个变量，正如上面所形式化的那样。这恰恰是选项E所描述的情况。", "answer": "$$\\boxed{E}$$", "id": "1438456"}, {"introduction": "理解了统计结果的含义（以及其局限）之后，下一步是确保该结果本身的有效性。此练习聚焦于如何选择正确的统计工具，通过比较应用广泛的卡方检验（chi-squared test）与费雪精确检验（Fisher's exact test）来实现。你将学到为何检验背后的假设至关重要，尤其是在处理生物学实验中常见的小样本数据时，这对于得出可靠结论是必不可少的。[@problem_id:1438416]", "problem": "在一项旨在理解蛋白质信号网络的系统生物学实验中，一位研究人员进行了一项蛋白质组范围的分析。其目标是研究蛋白质的磷酸化状态与其是否为激酶之间是否存在非随机关联。研究人员从实验数据中整理出以下观察结果：\n\n- 在一个由5个被鉴定为磷酸化的蛋白质样本中，有3个是已知的激酶。\n- 在另一个由100个被鉴定为未磷酸化的蛋白质样本中，有10个是已知的激酶。\n\n研究人员希望进行一项统计检验，以确定在磷酸化组和非磷酸化组之间，激酶的比例是否存在显著差异。一位同事建议，对于此项分析，费希尔精确检验(Fisher's Exact Test)比更常用的皮尔逊卡方检验(Pearson's chi-squared test)更合适。\n\n在这一特定情景下，下列哪个陈述为选择费希尔精确检验而非卡方检验提供了最准确的统计学理由？\n\nA. 总样本量（$N=105$）很大，导致卡方统计量被人为地夸大，而费希尔精确检验是为较小的总样本量设计的。\n\nB. 卡方检验的有效性要求数据必须服从正态分布，而这一假设在此处不成立。费希尔精确检验是一种非参数替代方法，不需要此假设。\n\nC. 卡方检验是一种近似方法，其有效性取决于每个类别中的期望频率足够大。在该数据集中，原假设下至少有一个期望频率过小，使得该近似方法不可靠。\n\nD. 磷酸化组中的观测计数（3和2）都是奇数，这是一种已知的情况，会导致连续的卡方分布不能很好地近似数据的离散特性。\n\nE. 应使用费希尔精确检验，因为它提供了关联强度的度量（比值比），而卡方检验只提供p值。", "solution": "我们想要检验在磷酸化组和非磷酸化组中，激酶的比例是否相同。设行代表磷酸化状态$P$和$\\bar{P}$，列代表激酶状态$K$和$\\bar{K}$。观测到的计数为\n$$\nO_{PK}=3,\\quad O_{P\\bar{K}}=2,\\quad O_{\\bar{P}K}=10,\\quad O_{\\bar{P}\\bar{K}}=90.\n$$\n行总计为 $n_{P}=5$ 和 $n_{\\bar{P}}=100$，列总计为 $m_{K}=13$ 和 $m_{\\bar{K}}=92$，总计为 $N=105$。\n\n在激酶比例在两组间相等的原假设下，一个 $2\\times 2$ 表中的期望计数由下式给出\n$$\nE_{ij}=\\frac{(\\text{row total}_{i})(\\text{column total}_{j})}{N}.\n$$\n因此，\n$$\nE_{PK}=\\frac{n_{P}m_{K}}{N}=\\frac{5\\cdot 13}{105}=\\frac{13}{21},\\quad\nE_{P\\bar{K}}=\\frac{n_{P}m_{\\bar{K}}}{N}=\\frac{5\\cdot 92}{105}=\\frac{92}{21},\n$$\n$$\nE_{\\bar{P}K}=\\frac{n_{\\bar{P}}m_{K}}{N}=\\frac{100\\cdot 13}{105}=\\frac{260}{21},\\quad\nE_{\\bar{P}\\bar{K}}=\\frac{n_{\\bar{P}}m_{\\bar{K}}}{N}=\\frac{100\\cdot 92}{105}=\\frac{1840}{21}.\n$$\n\n皮尔逊卡方近似有效的标准条件是所有期望计数都足够大（通常每个 $E_{ij}\\geq 5$）。此处，\n$$\nE_{PK}=\\frac{13}{21}<1<5,\\qquad E_{P\\bar{K}}=\\frac{92}{21}<5,\n$$\n所以至少有两个期望计数小于$5$。这违反了卡方近似方法要可靠所需的大样本条件。\n\n相比之下，费希尔精确检验以固定的边际为条件，并提供一个精确的$p$值，而不需要大的期望计数。因此，在这种情况下，它更受青睐。\n\n评估各个选项：\n- A 是不正确的：问题不在于$N$大，选择费希尔检验也不是因为总样本量$N$小，而是因为某些期望计数小。\n- B 是不正确的：卡方检验不要求数据呈正态分布；它依赖于对单元格计数的大样本近似。\n- C 是正确的：当期望频率很小时，卡方近似可能不可靠，本数据中就出现了这种情况。\n- D 是不正确的：观测计数的奇偶性无关紧要。\n- E 是误导性的：两种方法都可以报告比值比；这不是选择费希尔检验的主要原因。\n\n因此，最准确的理由是，由于该数据集中存在较小的期望频率，卡方近似不可靠，因此倾向于使用费希尔精确检验。", "answer": "$$\\boxed{C}$$", "id": "1438416"}, {"introduction": "现代系统生物学实验，如基因组学或蛋白质组学研究，常常需要同时检验成千上万个假设。这个实践将带你从单一检验的情境走向应对多重检验的挑战，在这种情况下，假阳性的风险会急剧累积。你将亲手实现Benjamini-Hochberg（BH）程序，这是一种控制伪发现率（False Discovery Rate, FDR）的强大方法，为从大规模数据集中识别真实信号提供了坚实的框架。[@problem_id:2399004]", "problem": "给定一个受磷酸化蛋白质组学研究启发的的多重检验场景。考虑与一组p值和目标错误发现率（FDR）水平相关的一族零假设。针对 $m$ 个检验，水平为 $q \\in (0,1)$ 的 Benjamini-Hochberg (BH) 程序定义如下。令 $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$ 表示排序后的p值。定义\n$$\nk^{\\star} = \\max\\left\\{k \\in \\{1,\\dots,m\\} : p_{(k)} \\le \\frac{k}{m} q \\right\\},\n$$\n约定空集上的最大值为 $k^{\\star}=0$。BH 程序恰好拒绝具有 $k^{\\star}$ 个最小p值的 $k^{\\star}$ 个假设。定义决策阈值\n$$\n\\tau = \\begin{cases}\n\\frac{k^{\\star}}{m} q, & \\text{if } k^{\\star} \\ge 1,\\\\\n0, & \\text{if } k^{\\star} = 0.\n\\end{cases}\n$$\n您的任务是实现这一精确的决策规则，并为下面的每个测试用例计算并报告有序对 $(k^{\\star}, \\tau)$。\n\n该测试套件包含五个用例，旨在探究正确性、边界行为、相同值处理和可扩展性。在每种情况下，p值都应被视为闭区间 $[0,1]$ 内的给定实数，并且必须严格按照上述 BH 定义进行应用。\n\n测试用例：\n- 用例 A (小规模，含边界值): $m=5$，p值为 $[0.0,\\,0.2,\\,0.5,\\,1.0,\\,0.8]$，$q=0.1$。\n- 用例 B (无拒绝): $m=4$，p值为 $[0.2,\\,0.4,\\,0.6,\\,0.8]$，$q=0.01$。\n- 用例 C (小p值中存在相同值): $m=5$，p值为 $[0.0005,\\,0.0005,\\,0.001,\\,0.01,\\,0.02]$，$q=0.05$。\n- 用例 D ($m=15000$ 的确定性大规模混合): 按如下方式构建备择p值和零假设p值的确定性混合。令 $m_{\\mathrm{alt}}=1500$ 且 $m_{\\mathrm{null}}=13500$，因此 $m_{\\mathrm{alt}}+m_{\\mathrm{null}}=15000$。定义备择集 $\\{p^{(\\mathrm{A})}_i\\}_{i=1}^{m_{\\mathrm{alt}}}$ 为 $p^{(\\mathrm{A})}_i = \\left(\\frac{i - 0.5}{1500}\\right)^2$，其中 $i=1,2,\\dots,1500$。定义零假设集 $\\{p^{(\\mathrm{N})}_j\\}_{j=1}^{m_{\\mathrm{null}}}$ 为 $p^{(\\mathrm{N})}_j = \\frac{j - 0.5}{13500}$，其中 $j=1,2,\\dots,13500$。全部 $15000$ 个p值的集合是这两个集合的多重集并集，顺序任意。使用 $q=0.01$。\n- 用例 E (在决策边界上出现相等情况): $m=10$，p值为 $[0.5,\\,0.99,\\,0.6,\\,0.04,\\,0.001,\\,0.95,\\,0.8,\\,0.61,\\,0.9,\\,0.07]$，$q=0.2$。\n\n最终输出格式：\n- 对于 A、B、C、D、E 顺序的每个用例，计算如上定义的 $k^{\\star}$ 和 $\\tau$。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[k^{\\star}_{\\mathrm{A}}, \\tau_{\\mathrm{A}}, k^{\\star}_{\\mathrm{B}}, \\tau_{\\mathrm{B}}, k^{\\star}_{\\mathrm{C}}, \\tau_{\\mathrm{C}}, k^{\\star}_{\\mathrm{D}}, \\tau_{\\mathrm{D}}, k^{\\star}_{\\mathrm{E}}, \\tau_{\\mathrm{E}}]$。$k^{\\star}$ 条目必须是整数，每个 $\\tau$ 必须使用标准舍入法保留到 $12$ 位小数。不涉及物理单位；所有量均为无量纲实数。", "solution": "在尝试求解之前，必须首先对问题陈述进行严格验证。\n\n**步骤1：提取给定信息**\n逐字提供以下数据和定义：\n- 与一组p值和目标错误发现率（FDR）水平 $q \\in (0,1)$ 相关的一族零假设。\n- 针对 $m$ 个检验，水平为 $q$ 的 Benjamini-Hochberg (BH) 程序已定义。\n- $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$ 表示排序后的p值。\n- 拒绝的假设数量为 $k^{\\star} = \\max\\left\\{k \\in \\{1,\\dots,m\\} : p_{(k)} \\le \\frac{k}{m} q \\right\\}$。\n- 一个约定指出，空集上的最大值为 $k^{\\star}=0$。\n- BH 程序拒绝与 $k^{\\star}$ 个最小p值相对应的假设。\n- 决策阈值定义为 $\\tau = \\begin{cases} \\frac{k^{\\star}}{m} q, & \\text{if } k^{\\star} \\ge 1,\\\\ 0, & \\text{if } k^{\\star} = 0. \\end{cases}$\n- 任务是为五个测试用例计算并报告有序对 $(k^{\\star}, \\tau)$。\n- 用例 A: $m=5$，p值为 $[0.0,\\,0.2,\\,0.5,\\,1.0,\\,0.8]$，$q=0.1$。\n- 用例 B: $m=4$，p值为 $[0.2,\\,0.4,\\,0.6,\\,0.8]$，$q=0.01$。\n- 用例 C: $m=5$，p值为 $[0.0005,\\,0.0005,\\,0.001,\\,0.01,\\,0.02]$，$q=0.05$。\n- 用例 D: $m=15000$。由 $m_{\\mathrm{alt}}=1500$ 个备择p值（定义为 $p^{(\\mathrm{A})}_i = \\left(\\frac{i - 0.5}{1500}\\right)^2$，其中 $i=1,2,\\dots,1500$）和 $m_{\\mathrm{null}}=13500$ 个零假设p值（定义为 $p^{(\\mathrm{N})}_j = \\frac{j - 0.5}{13500}$，其中 $j=1,2,\\dots,13500$）构成的确定性混合。完整集合是这两个集合的并集。FDR水平为 $q=0.01$。\n- 用例 E: $m=10$，p值为 $[0.5,\\,0.99,\\,0.6,\\,0.04,\\,0.001,\\,0.95,\\,0.8,\\,0.61,\\,0.9,\\,0.07]$，$q=0.2$。\n- 最终输出必须是包含 $[k^{\\star}_{\\mathrm{A}}, \\tau_{\\mathrm{A}}, k^{\\star}_{\\mathrm{B}}, \\tau_{\\mathrm{B}}, k^{\\star}_{\\mathrm{C}}, \\tau_{\\mathrm{C}}, k^{\\star}_{\\mathrm{D}}, \\tau_{\\mathrm{D}}, k^{\\star}_{\\mathrm{E}}, \\tau_{\\mathrm{E}}]$ 的单行，其中 $k^{\\star}$ 为整数，$\\tau$ 保留到 $12$ 位小数。\n\n**步骤2：使用提取的给定信息进行验证**\n根据所需标准评估问题：\n- **科学依据**：该问题基于 Benjamini-Hochberg 程序，这是统计方法学中控制多重假设检验中错误发现率的基石。这是一种标准且经过严格建立的技术，其在磷酸化蛋白质组学研究中的应用是一个典型例子。问题在事实上是合理的。\n- **定义明确**：$k^{\\star}$ 和 $\\tau$ 的定义精确且在数学上无歧义。对于任何有效的p值输入集和参数 $q$，该程序保证唯一的结果。\n- **客观性**：问题使用精确的数学定义和数值数据来表述。它不包含主观、推测性或基于意见的陈述。\n- **完整与一致**：每个测试用例的所有必要参数（$m$、p值、$q$）都已明确提供。定义是自洽的。\n- **现实且可行**：p值是有效的（在 $[0,1]$ 区间内），并且计算任务使用标准数值库是可行的。\n- 问题已完全指定，并且属于计算生物学领域，特别是在假设检验框架内。\n\n**步骤3：结论与行动**\n问题是有效的。这是一个基于成熟统计理论的、定义明确的计算练习。现在将构建一个完整的解决方案。\n\n问题的核心是实现 Benjamini-Hochberg (BH) 程序。对于每个测试用例，我们给定 $m$ 个p值和一个目标错误发现率（FDR）$q$。$(k^{\\star}, \\tau)$ 的计算遵循一个清晰的算法。\n\n首先，必须将给定的 $m$ 个p值集合 $\\{p_1, p_2, \\dots, p_m\\}$ 按非递减顺序排序，以产生排序后的p值 $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$。\n\n其次，我们确定 $k^{\\star}$，它是集合 $\\{1, 2, \\dots, m\\}$ 中满足 BH 条件的最大索引 $k$：\n$$\np_{(k)} \\le \\frac{k}{m} q\n$$\n如果不存在这样的 $k$，则根据问题的明确约定，取 $k^{\\star}$ 为 $0$。一种直接的计算策略是，对从 $1$ 到 $m$ 的每个 $k$ 检查此条件，并找出满足条件的最大 $k$。\n\n第三，一旦找到 $k^{\\star}$，就计算决策阈值 $\\tau$。如果 $k^{\\star} \\ge 1$，则 $\\tau$ 是在该索引处的 BH 边界值：$\\tau = \\frac{k^{\\star}}{m} q$。如果没有假设被拒绝，即 $k^{\\star} = 0$，则阈值就是 $\\tau = 0$。\n\n此程序将应用于每个测试用例。\n\n用例 A: $m=5$，p值为 $[0.0, 0.2, 0.5, 1.0, 0.8]$，$q=0.1$。\n排序后的p值为 $p_{(1)}=0.0$, $p_{(2)}=0.2$, $p_{(3)}=0.5$, $p_{(4)}=0.8$, $p_{(5)}=1.0$。\n对于 $k \\in \\{1, 2, 3, 4, 5\\}$，BH阈值 $\\frac{k}{m}q$ 计算为：$[0.02, 0.04, 0.06, 0.08, 0.1]$。\n- 对于 $k=1$：$p_{(1)} = 0.0 \\le 0.02$。条件满足。\n- 对于 $k=2$：$p_{(2)} = 0.2 \\not\\le 0.04$。条件不满足。\n- 后续对 $k > 2$ 的检查也将失败，因为在此区域 $p_{(k)}$ 的增长速度快于线性阈值。\n满足条件的最大（也是唯一）的 $k$ 是 $k=1$。因此，$k^{\\star}=1$。\n对应的阈值为 $\\tau = \\frac{1}{5}(0.1) = 0.02$。\n\n用例 B: $m=4$，p值为 $[0.2, 0.4, 0.6, 0.8]$，$q=0.01$。\np值已经排序。$p_{(1)}=0.2$, $p_{(2)}=0.4$, $p_{(3)}=0.6$, $p_{(4)}=0.8$。\nBH阈值为 $[0.0025, 0.005, 0.0075, 0.01]$。\n比较显示，对于每个 $k \\in \\{1, 2, 3, 4\\}$，都有 $p_{(k)} > \\frac{k}{m}q$。\n满足条件的 $k$ 集合为空。根据约定，$k^{\\star}=0$。\n因此，阈值为 $\\tau = 0$。\n\n用例 C: $m=5$，p值为 $[0.0005, 0.0005, 0.001, 0.01, 0.02]$，$q=0.05$。\np值已经排序。\nBH阈值为 $[0.01, 0.02, 0.03, 0.04, 0.05]$。\n- 对于 $k=1$：$p_{(1)}=0.0005 \\le 0.01$。\n- 对于 $k=2$：$p_{(2)}=0.0005 \\le 0.02$。\n- 对于 $k=3$：$p_{(3)}=0.001 \\le 0.03$。\n- 对于 $k=4$：$p_{(4)}=0.01 \\le 0.04$。\n- 对于 $k=5$：$p_{(5)}=0.02 \\le 0.05$。\n对于所有从 $1$ 到 $5$ 的 $k$，条件都满足。其中最大的 $k$ 是 $5$。\n因此，$k^{\\star}=5$。阈值为 $\\tau = \\frac{5}{5}(0.05) = 0.05$。\n\n用例 D: $m=15000$，$q=0.01$。\np值通过两个集合的并集生成：一个备择集，有 $m_{\\mathrm{alt}}=1500$ 个值，$p^{(\\mathrm{A})}_i = \\left(\\frac{i - 0.5}{1500}\\right)^2$；一个零假设集，有 $m_{\\mathrm{null}}=13500$ 个值，$p^{(\\mathrm{N})}_j = \\frac{j - 0.5}{13500}$。\n考虑到大量的检验（$m=15000$），手动计算是不切实际的。解决方案需要一种计算方法：\n1. 生成 $1500$ 个备择p值和 $13500$ 个零假设p值。\n2. 将它们合并成一个包含 $15000$ 个p值的数组。\n3. 对此数组进行排序，以获得 $p_{(1)}, \\dots, p_{(15000)}$。\n4. 为 $k=1, \\dots, 15000$ 创建一个 BH 阈值数组 $\\frac{k}{15000}(0.01)$。\n5. 找到所有满足 $p_{(k)} \\le \\frac{k}{15000}(0.01)$ 的索引 $k$，并选择其中最大的 $k$ 作为 $k^{\\star}$。\n6. 基于此 $k^{\\star}$ 计算 $\\tau$。\n最终答案中的实现将执行这些步骤。\n\n用例 E: $m=10$，p值为 $[0.5, 0.99, 0.6, 0.04, 0.001, 0.95, 0.8, 0.61, 0.9, 0.07]$，$q=0.2$。\n排序后的p值为 $p_{(1)}=0.001, p_{(2)}=0.04, p_{(3)}=0.07, p_{(4)}=0.5, p_{(5)}=0.6, p_{(6)}=0.61, p_{(7)}=0.8, p_{(8)}=0.9, p_{(9)}=0.95, p_{(10)}=0.99$。\nBH阈值 $\\frac{k}{10}(0.2)$ 为 $[0.02, 0.04, 0.06, 0.08, 0.1, 0.12, 0.14, 0.16, 0.18, 0.2]$。\n- 对于 $k=1$：$p_{(1)}=0.001 \\le 0.02$。满足。\n- 对于 $k=2$：$p_{(2)}=0.04 \\le 0.04$。满足。非严格不等式处理了相等情况。\n- 对于 $k=3$：$p_{(3)}=0.07 \\not\\le 0.06$。不满足。\n满足条件的最大 $k$ 是 $k=2$。\n因此，$k^{\\star}=2$。阈值为 $\\tau = \\frac{2}{10}(0.2) = 0.04$。\n\n最终的程序将系统地将此逻辑应用于所有用例，并按规定格式化结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Benjamini-Hochberg procedure parameters (k*, tau)\n    for a suite of test cases.\n    \"\"\"\n\n    def benjamini_hochberg(p_values: list[float] | np.ndarray, q: float) -> tuple[int, float]:\n        \"\"\"\n        Applies the Benjamini-Hochberg procedure to a set of p-values.\n\n        Args:\n            p_values: A list or numpy array of p-values.\n            q: The target False Discovery Rate (FDR) level.\n\n        Returns:\n            A tuple (k_star, tau) where k_star is the number of rejected hypotheses\n            and tau is the decision threshold.\n        \"\"\"\n        p_values_arr = np.array(p_values)\n        m = len(p_values_arr)\n\n        if m == 0:\n            return 0, 0.0\n\n        # 1. Sort the p-values in non-decreasing order.\n        p_sorted = np.sort(p_values_arr)\n\n        # 2. Find k_star.\n        k = np.arange(1, m + 1)\n        thresholds = (k / m) * q\n\n        # Find all indices where the BH condition p_(k) <= (k/m)*q is met.\n        # np.where returns indices where the condition is true.\n        # Python arrays are 0-indexed, so p_sorted[i] corresponds to p_(i+1).\n        satisfying_indices = np.where(p_sorted <= thresholds)[0]\n\n        if satisfying_indices.size == 0:\n            # The maximum over an empty set is defined as 0.\n            k_star = 0\n        else:\n            # The largest k is found from the last index that satisfied the condition.\n            # Convert 0-based index to 1-based k.\n            k_star = satisfying_indices[-1] + 1\n        \n        # 3. Calculate tau based on k_star.\n        if k_star > 0:\n            tau = (k_star / m) * q\n        else:\n            tau = 0.0\n            \n        return k_star, tau\n\n    # Define test cases from the problem statement\n    test_cases_params = [\n        # Case A\n        {'p_values': [0.0, 0.2, 0.5, 1.0, 0.8], 'q': 0.1},\n        # Case B\n        {'p_values': [0.2, 0.4, 0.6, 0.8], 'q': 0.01},\n        # Case C\n        {'p_values': [0.0005, 0.0005, 0.001, 0.01, 0.02], 'q': 0.05},\n        # Case D\n        {'p_values': None, 'q': 0.01}, # p-values to be generated\n        # Case E\n        {'p_values': [0.5, 0.99, 0.6, 0.04, 0.001, 0.95, 0.8, 0.61, 0.9, 0.07], 'q': 0.2},\n    ]\n\n    # Generate p-values for Case D\n    m_alt = 1500\n    m_null = 13500\n    i = np.arange(1, m_alt + 1)\n    j = np.arange(1, m_null + 1)\n    p_alt = ((i - 0.5) / m_alt)**2\n    p_null = (j - 0.5) / m_null\n    p_D = np.concatenate((p_alt, p_null))\n    test_cases_params[3]['p_values'] = p_D\n\n    results = []\n    for case in test_cases_params:\n        k_star, tau = benjamini_hochberg(case['p_values'], case['q'])\n        results.append(str(k_star))\n        # Format tau to 12 decimal places as specified.\n        results.append(f\"{tau:.12f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2399004"}]}