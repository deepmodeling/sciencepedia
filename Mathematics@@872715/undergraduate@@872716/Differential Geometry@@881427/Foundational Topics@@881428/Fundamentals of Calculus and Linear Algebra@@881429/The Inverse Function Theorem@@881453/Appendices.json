{"hands_on_practices": [{"introduction": "We begin with the foundational application of the Inverse Function Theorem in a single dimension. This practice reinforces the core relationship between the derivative of a function and its inverse. The exercise [@problem_id:30441] requires you to first find a point's pre-image under the function and then apply the theorem, building essential problem-solving skills for handling inverse functions.", "problem": "Consider a real-valued function $f: \\mathbb{R} \\to \\mathbb{R}$ defined by the polynomial:\n$$\nf(x) = x^5 + 2x^3 + x\n$$\nThe derivative of this function is $f'(x) = 5x^4 + 6x^2 + 1$. Since $f'(x) > 0$ for all $x \\in \\mathbb{R}$, the function $f$ is strictly increasing and therefore possesses a differentiable inverse function, which we denote by $f^{-1}$.\n\nThe derivative of the inverse function at a point $y_0$ in the range of $f$ can be found using the formula from the Inverse Function Theorem:\n$$\n(f^{-1})'(y_0) = \\frac{1}{f'(x_0)}\n$$\nwhere $x_0$ is the unique value such that $f(x_0) = y_0$.\n\nUsing this information, calculate the exact value of the derivative of the inverse function $f^{-1}$ at the point $y_0 = 4$.", "solution": "We have \n$$f(x)=x^5+2x^3+x,$$\nso\n$$f'(x)=5x^4+6x^2+1.$$\nSince for all real $x$, $5x^4\\ge0$, $6x^2\\ge0$ and $1>0$, it follows that $f'(x)>0$.  Hence $f$ is strictly increasing and admits a differentiable inverse $f^{-1}$.  By the Inverse Function Theorem, for $y_0\\in \\mathrm{Range}(f)$ and the unique $x_0$ with $f(x_0)=y_0$,\n$$(f^{-1})'(y_0)=\\frac1{f'(x_0)}.$$\n\nWe wish to compute $(f^{-1})'(4)$.  First find $x_0$ such that\n$$f(x_0)=x_0^5+2x_0^3+x_0=4.$$\nBy inspection $x_0=1$ gives $1^5+2\\cdot1^3+1=1+2+1=4$.  Thus $x_0=1$.\n\nNext, evaluate $f'$ at $x_0=1$:\n$$f'(1)=5\\cdot1^4+6\\cdot1^2+1=5+6+1=12.$$\n\nTherefore,\n$$(f^{-1})'(4)=\\frac1{f'(1)}=\\frac1{12}.$$", "answer": "$$\\boxed{\\frac{1}{12}}$$", "id": "30441"}, {"introduction": "Moving from a single variable to a multivariable map, the role of the derivative is now played by the Jacobian matrix. The Inverse Function Theorem guarantees a smooth map is a local diffeomorphism—meaning it is locally invertible with a smooth inverse—if its Jacobian determinant is non-zero. This exercise [@problem_id:1677188] asks you to find the precise points where this condition fails, a crucial step in understanding the geometry of transformations in the plane.", "problem": "Consider a smooth map $F: \\mathbb{R}^2 \\to \\mathbb{R}^2$ defined by the transformation $F(x,y) = (u(x,y), v(x,y))$, where the component functions are given by $u(x,y) = x^3 - 3xy^2$ and $v(x,y) = 3x^2y - y^3$.\n\nA map is called a local diffeomorphism at a point if it restricts to a diffeomorphism (a smooth map with a smooth inverse) in some open neighborhood of that point.\n\nDetermine the coordinates of all points $(x,y)$ in the plane $\\mathbb{R}^2$ at which the map $F$ fails to be a local diffeomorphism. If there is only one such point with coordinates $(a,b)$, present your answer as a single row matrix $\\begin{pmatrix} a & b \\end{pmatrix}$. If there are multiple points, list each point's coordinate pair as a row in a column matrix.", "solution": "We consider the smooth map $F: \\mathbb{R}^{2} \\to \\mathbb{R}^{2}$ given by $F(x,y) = (u(x,y), v(x,y))$ with $u(x,y) = x^{3} - 3 x y^{2}$ and $v(x,y) = 3 x^{2} y - y^{3}$. A point $(x_{0},y_{0})$ is a point where $F$ is a local diffeomorphism if the Jacobian matrix $DF(x_{0},y_{0})$ is invertible; that is, if $\\det DF(x_{0},y_{0}) \\neq 0$ by the inverse function theorem.\n\nCompute the Jacobian matrix. First compute the partial derivatives:\n$$\nu_{x} = \\frac{\\partial}{\\partial x}(x^{3} - 3 x y^{2}) = 3 x^{2} - 3 y^{2}, \\quad\nu_{y} = \\frac{\\partial}{\\partial y}(x^{3} - 3 x y^{2}) = - 6 x y,\n$$\n$$\nv_{x} = \\frac{\\partial}{\\partial x}(3 x^{2} y - y^{3}) = 6 x y, \\quad\nv_{y} = \\frac{\\partial}{\\partial y}(3 x^{2} y - y^{3}) = 3 x^{2} - 3 y^{2}.\n$$\nThus the Jacobian matrix is\n$$\nDF(x,y) = \\begin{pmatrix}\n3 x^{2} - 3 y^{2} & - 6 x y \\\\\n6 x y & 3 x^{2} - 3 y^{2}\n\\end{pmatrix}.\n$$\nCompute its determinant:\n$$\n\\det DF(x,y) = (3 x^{2} - 3 y^{2})^{2} - (-6 x y)(6 x y)\n= 9(x^{2} - y^{2})^{2} + 36 x^{2} y^{2}.\n$$\nCombine terms to simplify:\n$$\n9(x^{2} - y^{2})^{2} + 36 x^{2} y^{2}\n= 9\\big[(x^{2} - y^{2})^{2} + 4 x^{2} y^{2}\\big]\n= 9\\big[x^{4} - 2 x^{2} y^{2} + y^{4} + 4 x^{2} y^{2}\\big]\n= 9(x^{4} + 2 x^{2} y^{2} + y^{4})\n= 9(x^{2} + y^{2})^{2}.\n$$\nTherefore,\n$$\n\\det DF(x,y) = 9(x^{2} + y^{2})^{2}.\n$$\nIt follows that $\\det DF(x,y) = 0$ if and only if $x^{2} + y^{2} = 0$, which holds if and only if $(x,y) = (0,0)$. Hence, by the inverse function theorem, $F$ is a local diffeomorphism at every point $(x,y) \\neq (0,0)$.\n\nTo verify that $F$ fails to be a local diffeomorphism at $(0,0)$, observe that writing $(x,y)$ in polar coordinates $x = r \\cos\\theta$, $y = r \\sin\\theta$, we have\n$$\nu + i v = (x + i y)^{3} = (r \\exp(i \\theta))^{3} = r^{3} \\exp(3 i \\theta),\n$$\nso\n$$\nu = r^{3} \\cos(3\\theta), \\quad v = r^{3} \\sin(3\\theta).\n$$\nFor any fixed $r > 0$ sufficiently small and any $\\theta$, the three distinct points with angles $\\theta$, $\\theta + \\frac{2\\pi}{3}$, and $\\theta + \\frac{4\\pi}{3}$ map to the same $(u,v)$, since $\\exp(3 i \\theta)$ is $2\\pi$-periodic in $\\theta$ with period $\\frac{2\\pi}{3}$. Thus $F$ is not locally injective at $(0,0)$ and cannot be a local diffeomorphism there.\n\nConsequently, the only point where $F$ fails to be a local diffeomorphism is $(0,0)$.", "answer": "$$\\boxed{\\begin{pmatrix} 0 & 0 \\end{pmatrix}}$$", "id": "1677188"}, {"introduction": "The Inverse Function Theorem is not just a theoretical guarantee of existence; it is a powerful computational tool. It provides an explicit formula for the Jacobian matrix of the inverse map, namely $J_{F^{-1}} = (J_F)^{-1}$, without needing to find the inverse map itself. This practice [@problem_id:1677204] demonstrates this utility by asking you to calculate the sensitivity of a sensor's inferred position to a change in its signal, a task that translates to finding a specific entry in the inverse Jacobian matrix.", "problem": "A sensor in a 2D plane with Cartesian coordinates $(x, y)$ measures two signals, $u$ and $v$. These signals are related to the sensor's position by the mapping $F: \\mathbb{R}^2 \\to \\mathbb{R}^2$ given by:\n$$ u(x, y) = (x+a)^2 + y^2 $$\n$$ v(x, y) = (x-a)^2 + y^2 $$\nwhere $a$ is a known positive constant representing a characteristic length of the setup.\n\nAn operator needs to determine the sensor's position $(x, y)$ from the measured signals $(u, v)$. This requires understanding the local behavior of the inverse map $F^{-1}(u, v) = (x(u,v), y(u,v))$. A key quantity for this analysis is the sensitivity of the inferred $x$-position to a small change in the signal $u$. This sensitivity is given by the partial derivative $\\frac{\\partial x}{\\partial u}$.\n\nCalculate the value of this partial derivative, $\\frac{\\partial x}{\\partial u}$, for the local inverse map, evaluated at the specific sensor position $(x_0, y_0) = (0, b)$, where $b$ is a known positive constant. Express your answer as an analytic expression in terms of $a$ and $b$.", "solution": "We are given the forward map $F:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ defined by\n$$\nu(x,y)=(x+a)^{2}+y^{2},\\qquad v(x,y)=(x-a)^{2}+y^{2},\n$$\nwith $a>0$. The local inverse map $F^{-1}(u,v)=(x(u,v),y(u,v))$ exists where the Jacobian determinant of $F$ is nonzero, and its Jacobian is the matrix inverse of the Jacobian of $F$ by the inverse function theorem:\n$$\nJ_{F^{-1}}(u,v)=\\left(J_{F}(x,y)\\right)^{-1},\\quad \\text{with}\\quad J_{F}=\\begin{pmatrix}\\frac{\\partial u}{\\partial x}&\\frac{\\partial u}{\\partial y}\\\\\n\\frac{\\partial v}{\\partial x}&\\frac{\\partial v}{\\partial y}\\end{pmatrix}.\n$$\nCompute the partial derivatives:\n$$\n\\frac{\\partial u}{\\partial x}=2(x+a),\\quad \\frac{\\partial u}{\\partial y}=2y,\\quad \\frac{\\partial v}{\\partial x}=2(x-a),\\quad \\frac{\\partial v}{\\partial y}=2y.\n$$\nThus,\n$$\nJ_{F}(x,y)=\\begin{pmatrix}2(x+a)&2y\\\\\n2(x-a)&2y\\end{pmatrix}.\n$$\nThe determinant is\n$$\n\\det J_{F}= \\left(2(x+a)\\right)\\left(2y\\right)-\\left(2y\\right)\\left(2(x-a)\\right)=4y\\left[(x+a)-(x-a)\\right]=8ay.\n$$\nAt $(x_{0},y_{0})=(0,b)$ with $b>0$, we have $\\det J_{F}=8ab\\neq 0$, so the inverse exists locally. The inverse of a $2\\times 2$ matrix $\\begin{pmatrix}A&B\\\\ C&D\\end{pmatrix}$ is $\\frac{1}{AD-BC}\\begin{pmatrix}D&-B\\\\ -C&A\\end{pmatrix}$. Applying this to $J_{F}$ gives\n$$\n\\left(J_{F}\\right)^{-1}=\\frac{1}{8ay}\\begin{pmatrix}2y&-2y\\\\\n-2(x-a)&2(x+a)\\end{pmatrix}.\n$$\nBy definition,\n$$\nJ_{F^{-1}}=\\begin{pmatrix}\\frac{\\partial x}{\\partial u}&\\frac{\\partial x}{\\partial v}\\\\\n\\frac{\\partial y}{\\partial u}&\\frac{\\partial y}{\\partial v}\\end{pmatrix}=\\left(J_{F}\\right)^{-1}.\n$$\nTherefore, the desired sensitivity is the $(1,1)$ entry:\n$$\n\\frac{\\partial x}{\\partial u}=\\frac{2y}{8ay}=\\frac{1}{4a}.\n$$\nEvaluating at $(x_{0},y_{0})=(0,b)$ leaves the same value since $y=b>0$ cancels:\n$$\n\\left.\\frac{\\partial x}{\\partial u}\\right|_{(x_{0},y_{0})=(0,b)}=\\frac{1}{4a}.\n$$", "answer": "$$\\boxed{\\frac{1}{4a}}$$", "id": "1677204"}]}