{"hands_on_practices": [{"introduction": "The first step in mastering the geometry of surfaces is to become fluent in the fundamental calculations. The first fundamental form is defined by its coefficients $E$, $F$, and $G$, which are derived from the partial derivatives of a surface parametrization. This exercise [@problem_id:1674248] provides essential practice in computing these coefficients and the associated area element for a paraboloid, a classic and important example in geometry.", "problem": "A surface in three-dimensional Euclidean space, $\\mathbb{R}^3$, is defined by the parametrization $\\mathbf{x}(u, v) = (u\\cos v, u\\sin v, u^2)$, for parameters $u>0$ and $v \\in [0, 2\\pi)$. The first fundamental form of this surface is described by a matrix whose components are commonly denoted by $E$, $F$, and $G$. Find the determinant of this matrix, which corresponds to the expression $EG - F^2$. Express your answer in terms of $u$ and $v$ where applicable.", "solution": "We use the definitions of the first fundamental form for a parametrized surface $\\mathbf{x}(u,v)$: $E=\\mathbf{x}_{u}\\cdot\\mathbf{x}_{u}$, $F=\\mathbf{x}_{u}\\cdot\\mathbf{x}_{v}$, and $G=\\mathbf{x}_{v}\\cdot\\mathbf{x}_{v}$. For $\\mathbf{x}(u,v)=(u\\cos v,\\,u\\sin v,\\,u^{2})$, compute the partial derivatives:\n$$\n\\mathbf{x}_{u}=(\\cos v,\\,\\sin v,\\,2u),\\qquad \\mathbf{x}_{v}=(-u\\sin v,\\,u\\cos v,\\,0).\n$$\nThen\n$$\nE=\\mathbf{x}_{u}\\cdot\\mathbf{x}_{u}=\\cos^{2}v+\\sin^{2}v+(2u)^{2}=1+4u^{2},\n$$\n$$\nF=\\mathbf{x}_{u}\\cdot\\mathbf{x}_{v}=(\\cos v)(-u\\sin v)+(\\sin v)(u\\cos v)+ (2u)(0)=0,\n$$\n$$\nG=\\mathbf{x}_{v}\\cdot\\mathbf{x}_{v}=(-u\\sin v)^{2}+(u\\cos v)^{2}+0=u^{2}(\\sin^{2}v+\\cos^{2}v)=u^{2}.\n$$\nTherefore, the determinant of the first fundamental form is\n$$\nEG-F^{2}=(1+4u^{2})\\,u^{2}-0=u^{2}+4u^{4}=u^{2}(1+4u^{2}).\n$$", "answer": "$$\\boxed{u^{2}+4u^{4}}$$", "id": "1674248"}, {"introduction": "Moving beyond basic computation, we can explore one of the most profound ideas in differential geometry: the distinction between intrinsic and extrinsic properties. The first fundamental form captures the intrinsic geometry of a surface—properties like curve lengths and areas that an inhabitant living on the surface could measure. This exercise [@problem_id:3070676] uses the familiar cylinder to demonstrate how two different parametrizations can describe intrinsically identical surfaces (isometry) that are not simply rigid rotations or translations of each other in space (congruence).", "problem": "Let $R>0$ be fixed. Consider the right circular cylinder of radius $R$ in Euclidean three-dimensional space $\\mathbb{R}^{3}$, viewed as a smooth surface. Work with two distinct smooth parametrizations $X$ and $Y$ defined on the same parameter domain $\\mathbb{R}\\times(0,2\\pi)$, where the parameters are denoted $(u,v)$.\n\n1. Construct an explicit parametrization $X(u,v)$ of the cylinder by using the axial coordinate and the angular coordinate in the conventional way.\n2. Construct a second explicit parametrization $Y(u,v)$ of the same cylinder by “twisting” the angle linearly along the axis: use a fixed nonzero real constant $a$ and define the angular coordinate to depend on $u$.\n3. Using only the definition of the first fundamental form (the Riemannian metric induced by the Euclidean inner product on the tangent plane via the pushforward of the parametrization), compute the coefficients $E$, $F$, and $G$ of the first fundamental form for each parametrization.\n4. Argue carefully, from first principles, that these two parametrizations are isometric yet not congruent as parametrized surfaces in $\\mathbb{R}^{3}$. In particular, justify why no single rigid motion of $\\mathbb{R}^{3}$ (composition of a constant orthogonal linear map and a translation) transforms $X$ pointwise into $Y$ on the entire parameter domain when $a\\neq 0$, while there exists a smooth reparametrization of the domain that identifies their induced metrics.\n5. Finally, use your computed first fundamental forms to obtain the common value of the infinitesimal area factor $\\sqrt{EG - F^{2}}$ (the square root of the Gram determinant) for both parametrizations. Express your final answer as a closed-form analytic expression in $R$.\n\nNo numerical approximation is required; give the exact expression.", "solution": "The problem as stated is mathematically sound, self-contained, and well-posed. It presents a standard exercise in the differential geometry of surfaces, exploring the fundamental concepts of parametrization, the first fundamental form, isometry, and congruence. All terms are well-defined, and the tasks are logically structured, leading to a verifiable result. Therefore, we proceed with a full solution.\n\nThe problem asks for a five-part analysis of two different parametrizations of a right circular cylinder of fixed radius $R > 0$ in Euclidean three-dimensional space $\\mathbb{R}^{3}$. The parameter domain for both is given as $U = \\mathbb{R}\\times(0,2\\pi)$, with parameters $(u,v)$.\n\nPart 1: Construction of the parametrization $X(u,v)$.\nThe conventional parametrization of a right circular cylinder of radius $R$ aligned with the $z$-axis uses the axial coordinate for one parameter and the angular coordinate for the other. We let $u$ be the axial coordinate (height) and $v$ be the angle in the $x,y$-plane. The Cartesian coordinates $(x,y,z)$ are then given by:\n$x = R \\cos(v)$\n$y = R \\sin(v)$\n$z = u$\nThus, the first parametrization is the vector-valued function $X: U \\to \\mathbb{R}^{3}$ defined by:\n$$X(u,v) = (R \\cos(v), R \\sin(v), u)$$\n\nPart 2: Construction of the parametrization $Y(u,v)$.\nThe second parametrization is constructed by \"twisting\" the angle linearly along the axis. This means the angle in the $x,y$-plane will be a function of both $u$ and $v$. We introduce a fixed nonzero real constant $a \\neq 0$. The angular coordinate is defined as $v + au$. The axial coordinate remains $u$. This gives the parametrization $Y: U \\to \\mathbb{R}^{3}$:\n$$Y(u,v) = (R \\cos(v+au), R \\sin(v+au), u)$$\nBoth $X(U)$ and $Y(U)$ trace out the same surface in $\\mathbb{R}^{3}$, namely the cylinder defined by $x^{2} + y^{2} = R^{2}$.\n\nPart 3: Computation of the coefficients of the first fundamental form.\nThe coefficients $E$, $F$, and $G$ of the first fundamental form are defined by the inner products of the partial derivative vectors of the parametrization. For a generic parametrization $Z(u,v)$, we have $Z_u = \\frac{\\partial Z}{\\partial u}$ and $Z_v = \\frac{\\partial Z}{\\partial v}$. The coefficients are $E = \\langle Z_u, Z_u \\rangle$, $F = \\langle Z_u, Z_v \\rangle$, and $G = \\langle Z_v, Z_v \\rangle$, where $\\langle \\cdot, \\cdot \\rangle$ is the standard Euclidean dot product in $\\mathbb{R}^{3}$.\n\nFor the parametrization $X(u,v)$:\nThe partial derivatives are:\n$X_u = \\frac{\\partial}{\\partial u} (R \\cos(v), R \\sin(v), u) = (0, 0, 1)$\n$X_v = \\frac{\\partial}{\\partial v} (R \\cos(v), R \\sin(v), u) = (-R \\sin(v), R \\cos(v), 0)$\nThe coefficients are:\n$E_X = \\langle X_u, X_u \\rangle = \\langle (0, 0, 1), (0, 0, 1) \\rangle = 0^{2} + 0^{2} + 1^{2} = 1$\n$F_X = \\langle X_u, X_v \\rangle = \\langle (0, 0, 1), (-R \\sin(v), R \\cos(v), 0) \\rangle = 0 \\cdot (-R \\sin(v)) + 0 \\cdot (R \\cos(v)) + 1 \\cdot 0 = 0$\n$G_X = \\langle X_v, X_v \\rangle = \\langle (-R \\sin(v), R \\cos(v), 0), (-R \\sin(v), R \\cos(v), 0) \\rangle = (-R \\sin(v))^{2} + (R \\cos(v))^{2} + 0^{2} = R^{2}(\\sin^{2}(v) + \\cos^{2}(v)) = R^{2}$\nThe first fundamental form for $X$ is $ds_X^2 = 1 du^{2} + 0 du dv + R^{2} dv^{2} = du^{2} + R^{2} dv^{2}$.\n\nFor the parametrization $Y(u,v)$:\nThe partial derivatives are:\n$Y_u = \\frac{\\partial}{\\partial u} (R \\cos(v+au), R \\sin(v+au), u) = (-aR \\sin(v+au), aR \\cos(v+au), 1)$\n$Y_v = \\frac{\\partial}{\\partial v} (R \\cos(v+au), R \\sin(v+au), u) = (-R \\sin(v+au), R \\cos(v+au), 0)$\nThe coefficients are:\n$E_Y = \\langle Y_u, Y_u \\rangle = (-aR \\sin(v+au))^{2} + (aR \\cos(v+au))^{2} + 1^{2} = a^{2}R^{2}(\\sin^{2}(v+au) + \\cos^{2}(v+au)) + 1 = a^{2}R^{2} + 1$\n$F_Y = \\langle Y_u, Y_v \\rangle = (-aR \\sin(v+au))(-R \\sin(v+au)) + (aR \\cos(v+au))(R \\cos(v+au)) + 1 \\cdot 0 = aR^{2}(\\sin^{2}(v+au) + \\cos^{2}(v+au)) = aR^{2}$\n$G_Y = \\langle Y_v, Y_v \\rangle = (-R \\sin(v+au))^{2} + (R \\cos(v+au))^{2} + 0^{2} = R^{2}(\\sin^{2}(v+au) + \\cos^{2}(v+au)) = R^{2}$\nThe first fundamental form for $Y$ is $ds_Y^2 = (a^{2}R^{2} + 1) du^{2} + 2aR^{2} du dv + R^{2} dv^{2}$.\n\nPart 4: Argument for isometry without congruence.\nTwo parametrizations are isometric if there exists a smooth reparametrization of the domain (a diffeomorphism) that transforms one first fundamental form into the other. This means they define the same intrinsic geometry.\nLet us define a change of coordinates from a new system $(u', v')$ to the $(u,v)$ system of $X$:\nLet $u' = u$ and $v' = v+au$. This is a diffeomorphism $\\psi: \\mathbb{R}^{2} \\to \\mathbb{R}^{2}$ given by $\\psi(u,v) = (u,v+au)$. Its inverse is $\\psi^{-1}(u',v')=(u', v'-au')$.\nNow, consider the composition $X \\circ \\psi$:\n$X(\\psi(u,v)) = X(u, v+au) = (R \\cos(v+au), R \\sin(v+au), u)$\nThis is precisely the parametrization $Y(u,v)$. Since $Y = X \\circ \\psi$, $Y$ is a reparametrization of $X$. By definition, a reparametrization preserves the intrinsic geometry, so the parametrizations $X$ and $Y$ are isometric. The fact that their induced metrics are related by the Jacobian of the reparametrization confirms this. The metric tensor for $X$ is $g_X = \\begin{pmatrix} 1 & 0 \\\\ 0 & R^{2} \\end{pmatrix}$. The Jacobian of $\\psi(u,v)=(u,v+au)$ is $J = \\begin{pmatrix} 1 & 0 \\\\ a & 1 \\end{pmatrix}$. The transformed metric tensor is $g_Y = J^{T} g_X J = \\begin{pmatrix} 1 & a \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & R^{2} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ a & 1 \\end{pmatrix} = \\begin{pmatrix} 1+a^{2}R^{2} & aR^{2} \\\\ aR^{2} & R^{2} \\end{pmatrix}$, which matches the coefficients $(E_Y, F_Y, G_Y)$ computed directly.\n\nTwo parametrizations $X$ and $Y$ are congruent if there exists a single rigid motion (isometry of the ambient space $\\mathbb{R}^{3}$) $T(\\mathbf{p}) = A\\mathbf{p} + \\mathbf{b}$, where $A$ is an orthogonal matrix and $\\mathbf{b}$ is a constant vector, such that $Y(u,v) = T(X(u,v))$ for all $(u,v) \\in U$.\nA rigid motion maps straight lines to straight lines. Let us examine the images of the coordinate lines in the parameter domain $U$.\nFor the parametrization $X$, the $u$-parameter curves (where $v=v_0$ is constant) are given by $c(u) = X(u,v_0) = (R \\cos(v_0), R \\sin(v_0), u)$. These are vertical straight lines on the cylinder's surface.\nFor the parametrization $Y$, the $u$-parameter curves (where $v=v_0$ is constant) are given by $h(u) = Y(u,v_0) = (R \\cos(v_0+au), R \\sin(v_0+au), u)$. These curves are helices winding around the cylinder. Since $a \\neq 0$, these helices are not straight lines.\nBecause the parametrization $X$ maps the grid of $u$-lines to a family of straight lines, while the parametrization $Y$ maps the same grid to a family of helices, there can be no rigid motion $T$ that transforms the image of $X$ pointwise into the image of $Y$. If such a $T$ existed, it would have to map the straight lines generated by $X$ to the helices generated by $Y$, which is impossible. Therefore, the parametrizations are not congruent. This highlights the distinction between intrinsic properties (isometry), which are independent of the embedding in $\\mathbb{R}^{3}$, and extrinsic properties (congruence), which depend on the shape in the ambient space.\n\nPart 5: Computation of the infinitesimal area factor.\nThe infinitesimal area factor is given by the expression $\\sqrt{EG - F^{2}}$. We compute this for both parametrizations.\nFor $X$:\n$\\sqrt{E_X G_X - F_X^{2}} = \\sqrt{1 \\cdot R^{2} - 0^{2}} = \\sqrt{R^{2}} = R$ (since $R>0$).\n\nFor $Y$:\n$\\sqrt{E_Y G_Y - F_Y^{2}} = \\sqrt{(a^{2}R^{2} + 1)R^{2} - (aR^{2})^{2}} = \\sqrt{a^{2}R^{4} + R^{2} - a^{2}R^{4}} = \\sqrt{R^{2}} = R$.\n\nThe value of the area factor is indeed common to both parametrizations and is equal to $R$. This is consistent with the fact that they are isometric via a reparametrization with a Jacobian determinant of $1$. The area element $dA = \\sqrt{EG-F^2} du dv = R du dv$ is the same for both coordinate systems.\nThe final closed-form analytic expression for the common value of the infinitesimal area factor $\\sqrt{EG-F^2}$ is simply $R$.", "answer": "$$\\boxed{R}$$", "id": "3070676"}, {"introduction": "To bridge the gap between abstract theory and modern application, this final practice delves into the computational world of geometric analysis. In fields like computer graphics and engineering, surfaces are often represented by a set of sampled points rather than a perfect analytical formula. This problem [@problem_id:3070673] challenges you to develop a numerical method to approximate the first fundamental form from such data and to investigate the stability of your approximation, particularly near singularities where the geometry degenerates and numerical methods can fail.", "problem": "You are given smooth parametrizations of surfaces in three-dimensional Euclidean space and asked to build a computational pipeline that approximates the first fundamental form coefficients from sampled points using finite differences and inner products, and then to assess numerical stability near singularities. The first fundamental form on a parametrized surface is defined by the symmetric matrix with entries $g_{ij} = \\langle \\partial_i X, \\partial_j X \\rangle$, where $X(u,v)$ is a smooth parametrization into $\\mathbb{R}^3$, $\\partial_1 X = \\partial X/\\partial u$, $\\partial_2 X = \\partial X/\\partial v$, and $\\langle \\cdot, \\cdot \\rangle$ is the standard Euclidean inner product.\n\nYour program must approximate the metric coefficients at a given point $(u_0,v_0)$ using only sampled values of $X$ on a discrete grid via a symmetric central finite difference scheme:\n- Approximate $\\partial X/\\partial u$ at $(u_0,v_0)$ by the symmetric difference $\\left(X(u_0+h,v_0) - X(u_0-h,v_0)\\right)/(2h)$.\n- Approximate $\\partial X/\\partial v$ at $(u_0,v_0)$ by the symmetric difference $\\left(X(u_0,v_0+h) - X(u_0,v_0-h)\\right)/(2h)$.\n\nFrom these approximations, compute the $2 \\times 2$ matrix $g$ with entries $E = \\langle X_u, X_u \\rangle$, $F = \\langle X_u, X_v \\rangle$, and $G = \\langle X_v, X_v \\rangle$. The angle variables below are to be interpreted in radians.\n\nFrom first principles, the foundational base you must use is:\n- The definition of the first fundamental form: $g_{ij}(u,v) = \\langle \\partial_i X(u,v), \\partial_j X(u,v) \\rangle$.\n- The symmetric central finite difference approximation for first derivatives with step $h$.\n- The Euclidean inner product in $\\mathbb{R}^3$.\n\nYou must also compute the exact (analytical) first fundamental form for each test surface at the specified point to enable an error assessment, and then assess stability via an observed convergence order and a conditioning diagnostic.\n\nDefinitions for error and stability assessment:\n- For a given step $h$, define the Frobenius-norm relative error\n$$\n\\mathrm{err}(h) = \\frac{\\|g_h - g_{\\text{true}}\\|_F}{\\max(\\|g_{\\text{true}}\\|_F, \\varepsilon)},\n$$\nwhere $g_h$ is the finite-difference approximation, $g_{\\text{true}}$ is the analytical metric, $\\|\\cdot\\|_F$ denotes the Frobenius norm, and $\\varepsilon$ is a tiny positive stabilizer (take $\\varepsilon = 10^{-30}$).\n- Using three step sizes $h_1 > h_2 > h_3$, estimate the empirical convergence order\n$$\np \\approx \\frac{\\log(\\mathrm{err}(h_3)) - \\log(\\mathrm{err}(h_1))}{\\log(h_3) - \\log(h_1)}.\n$$\n- As a conditioning diagnostic at the smallest step $h_3$, compute the spectral condition number of the symmetric matrix $g_{h_3}$ as\n$$\n\\kappa(g_{h_3}) = \n\\begin{cases}\n\\lambda_{\\max}(g_{h_3})/\\lambda_{\\min}(g_{h_3}), & \\text{if } \\lambda_{\\min}(g_{h_3}) > 0,\\\\\n10^{16}, & \\text{otherwise},\n\\end{cases}\n$$\nwhere $\\lambda_{\\min}$ and $\\lambda_{\\max}$ are the smallest and largest eigenvalues of $g_{h_3}$, respectively. This assigns a large sentinel value when the matrix is not numerically positive definite, indicating severe ill-conditioning.\n\nTest suite:\nFor each of the following test cases, use the step sizes $h \\in \\{10^{-1}, 10^{-2}, 10^{-3}\\}$, and compute the three quantities: the relative error at $h=10^{-3}$, the estimated order $p$, and the condition number $\\kappa(g_{10^{-3}})$. All angle quantities are in radians.\n\n- Test case $1$ (happy path, well-conditioned): A standard torus with major radius $R=2$ and minor radius $r=0.6$, parametrized by\n$$\nX(u,v) = \\big((R + r \\cos u)\\cos v,\\ (R + r \\cos u)\\sin v,\\ r \\sin u\\big),\n$$\nevaluated at $(u_0,v_0) = (1.0, 0.8)$.\nAnalytical first fundamental form at $(u,v)$:\n$$\nE = r^2,\\quad F = 0,\\quad G = (R + r \\cos u)^2.\n$$\n\n- Test case $2$ (coordinate singularity proximity): The unit sphere in $\\mathbb{R}^3$ with spherical coordinates\n$$\nX(u,v) = \\big(\\sin u \\cos v,\\ \\sin u \\sin v,\\ \\cos u\\big),\n$$\nevaluated at $(u_0,v_0) = (10^{-6}, 0.8)$.\nAnalytical first fundamental form at $(u,v)$:\n$$\nE = 1,\\quad F = 0,\\quad G = \\sin^2 u.\n$$\n\n- Test case $3$ (geometric singularity proximity): A right circular cone of slope $1$,\n$$\nX(u,v) = \\big(u \\cos v,\\ u \\sin v,\\ u\\big),\n$$\nevaluated at $(u_0,v_0) = (10^{-6}, 1.3)$.\nAnalytical first fundamental form at $(u,v)$:\n$$\nE = 2,\\quad F = 0,\\quad G = u^2.\n$$\n\nRequired final output format:\n- Your program should produce a single line of output containing a list of three lists, one per test case, where each inner list has three floating-point numbers in this order: $[\\mathrm{err}(10^{-3}),\\ p,\\ \\kappa(g_{10^{-3}})]$.\n- For example, the printed structure must look like $[[e_1,\\ p_1,\\ \\kappa_1],[e_2,\\ p_2,\\ \\kappa_2],[e_3,\\ p_3,\\ \\kappa_3]]$ with no spaces required beyond those inserted by standard Python list formatting.\n\nAngle unit requirement:\n- All angles are in radians.\n\nThere are no physical units in this problem.\n\nYour program must be entirely self-contained with no user input and must adhere to the required output format exactly.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of differential geometry and numerical analysis, well-posed with a clear objective and sufficient data, and free from any contradictions, ambiguities, or factual inaccuracies. We may therefore proceed with a complete solution.\n\nThe core task is to analyze the numerical approximation of the first fundamental form of a surface. For a surface in three-dimensional Euclidean space, $\\mathbb{R}^3$, parametrized by a smooth map $X(u,v): \\Omega \\subset \\mathbb{R}^2 \\to \\mathbb{R}^3$, the first fundamental form is a symmetric $2 \\times 2$ matrix, denoted by $g$, which equips the surface with a metric. This metric allows for the measurement of lengths, angles, and areas on the surface. Its components, $g_{ij}$, are defined by the inner products of the tangent basis vectors, $\\partial_1 X = \\partial X/\\partial u$ and $\\partial_2 X = \\partial X/\\partial v$. In classical notation, these components are:\n$$\ng = \\begin{pmatrix} E & F \\\\ F & G \\end{pmatrix}\n\\quad \\text{where} \\quad\n\\begin{cases}\nE(u,v) = \\langle \\partial_u X, \\partial_u X \\rangle \\\\\nF(u,v) = \\langle \\partial_u X, \\partial_v X \\rangle \\\\\nG(u,v) = \\langle \\partial_v X, \\partial_v X \\rangle\n\\end{cases}\n$$\nThe inner product $\\langle \\cdot, \\cdot \\rangle$ is the standard Euclidean dot product in $\\mathbb{R}^3$. For a valid (non-degenerate) parametrization, the tangent vectors $\\partial_u X$ and $\\partial_v X$ are linearly independent, which implies that the matrix $g$ is positive definite, i.e., its determinant $EG - F^2 > 0$.\n\nThe problem requires us to approximate this matrix $g$ at a point $(u_0, v_0)$ not from the analytical derivatives, but from sampled points of the surface $X(u,v)$ on a discrete grid. The specified method is the symmetric central finite difference scheme to approximate the partial derivatives. For a step size $h > 0$, the approximations are:\n$$\n\\partial_u X(u_0, v_0) \\approx X_u^h = \\frac{X(u_0+h, v_0) - X(u_0-h, v_0)}{2h}\n$$\n$$\n\\partial_v X(u_0, v_0) \\approx X_v^h = \\frac{X(u_0, v_0+h) - X(u_0, v_0-h)}{2h}\n$$\nThese formulae provide a second-order approximation to the true derivatives, meaning the truncation error is proportional to $h^2$. Subsequently, the components of the approximate metric tensor, $g_h$, are computed using these approximate tangent vectors:\n$$\ng_h = \\begin{pmatrix} E_h & F_h \\\\ F_h & G_h \\end{pmatrix}\n\\quad \\text{where} \\quad\n\\begin{cases}\nE_h = \\langle X_u^h, X_u^h \\rangle \\\\\nF_h = \\langle X_u^h, X_v^h \\rangle \\\\\nG_h = \\langle X_v^h, X_v^h \\rangle\n\\end{cases}\n$$\nTo evaluate the quality of this approximation, three metrics are computed:\n\n1.  **Relative Error**: The Frobenius-norm relative error, $\\mathrm{err}(h)$, quantifies the difference between the computed matrix $g_h$ and the exact analytical matrix $g_{\\text{true}}$. The Frobenius norm of a matrix $A$ is $\\|A\\|_F = \\sqrt{\\sum_{i,j} |a_{ij}|^2}$. The formula is:\n    $$\n    \\mathrm{err}(h) = \\frac{\\|g_h - g_{\\text{true}}\\|_F}{\\max(\\|g_{\\text{true}}\\|_F, \\varepsilon)}\n    $$\n    where $\\varepsilon = 10^{-30}$ is a small positive number to prevent division by zero if $g_{\\text{true}}$ were the zero matrix.\n\n2.  **Empirical Convergence Order**: Since the central difference scheme is second-order accurate ($O(h^2)$), the error $\\mathrm{err}(h)$ should behave as $C h^p$ where the theoretical order $p$ is $2$. We can estimate $p$ from numerical results at different step sizes, $h_1$ and $h_3$. Taking the logarithm gives $\\log(\\mathrm{err}(h)) = \\log(C) + p \\log(h)$. This is a linear relationship between $\\log(\\mathrm{err})$ and $\\log(h)$, with slope $p$. The order $p$ can thus be estimated by the slope of the line connecting two points $(\\log(h_1), \\log(\\mathrm{err}(h_1)))$ and $(\\log(h_3), \\log(\\mathrm{err}(h_3)))$:\n    $$\n    p \\approx \\frac{\\log(\\mathrm{err}(h_3)) - \\log(\\mathrm{err}(h_1))}{\\log(h_3) - \\log(h_1)}\n    $$\n\n3.  **Condition Number**: The spectral condition number $\\kappa(A) = \\lambda_{\\max}(A) / \\lambda_{\\min}(A)$ of a positive-definite symmetric matrix $A$ measures its sensitivity to perturbations. For the metric tensor $g$, a large condition number indicates that the parametrization is near a singularity. At such a point, the basis vectors $(\\partial_u X, \\partial_v X)$ are nearly linearly dependent, meaning the mapping from the parameter domain $(u,v)$ to the surface in $\\mathbb{R}^3$ is highly distorted. Eigenvalues of $g$ correspond to the squared principal scaling factors of this mapping. A large ratio of eigenvalues signifies that an infinitesimal circle in the $(u,v)$ plane is mapped to a highly eccentric ellipse on the surface. The problem specifies a sentinel value of $10^{16}$ if the numerically computed matrix $g_h$ is not positive definite ($\\lambda_{\\min} \\le 0$), a sign of severe numerical instability.\n\nThe implementation will proceed by defining Python functions for each surface parametrization and its corresponding analytical first fundamental form. A general procedure will then be applied to each test case:\n1.  Set the parameters for the surface and the evaluation point $(u_0, v_0)$.\n2.  Compute the exact metric tensor $g_{\\text{true}}$ at $(u_0, v_0)$ using the provided analytical formulae.\n3.  For each step size $h \\in \\{10^{-1}, 10^{-2}, 10^{-3}\\}$, compute the approximate tangent vectors $X_u^h$ and $X_v^h$, and from them, the approximate metric tensor $g_h$.\n4.  Calculate the relative error $\\mathrm{err}(h)$ for each $h$.\n5.  Use the errors at $h_1 = 10^{-1}$ and $h_3 = 10^{-3}$ to estimate the convergence order $p$.\n6.  Compute the spectral condition number $\\kappa(g_{10^{-3}})$ of the metric tensor at the smallest step size.\n7.  Collect the results $[\\mathrm{err}(10^{-3}), p, \\kappa(g_{10^{-3}})]$ for each test case.\n\n**Analysis of Test Cases:**\n-   **Case 1 (Torus)**: At $(u_0, v_0) = (1.0, 0.8)$, the parametrization is regular and far from any degeneracy. We anticipate a convergence order $p \\approx 2$ and a small, well-behaved condition number.\n-   **Case 2 (Sphere)**: The evaluation point is $(u_0, v_0) = (10^{-6}, 0.8)$. Since $u_0$ is extremely close to $0$, this point is near the North Pole, a coordinate singularity of spherical coordinates. Here, $G = \\sin^2 u \\approx u^2 \\approx 10^{-12}$ while $E=1$. The eigenvalues of $g$ will be approximately $1$ and $10^{-12}$, leading to an extremely large condition number $\\kappa \\approx 10^{12}$. The numerical stability is expected to be poor.\n-   **Case 3 (Cone)**: The evaluation point is $(u_0, v_0) = (10^{-6}, 1.3)$, which is very close to the cone's apex at $u=0$. The apex is a geometric singularity (the surface is not differentiable there), and for the parametrization, it is also a coordinate singularity where $\\partial_v X = 0$. Similar to the sphere, $G = u^2 \\approx 10^{-12}$ while $E=2$. The eigenvalues will be approximately $2$ and $10^{-12}$, yielding a very large condition number and challenging the numerical method.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the problem's test suite.\n    It computes numerical approximations of the first fundamental form for three surfaces,\n    calculates error, convergence order, and condition number, and prints the results.\n    \"\"\"\n\n    # --- Surface Parametrizations ---\n\n    def x_torus(u, v, R=2.0, r=0.6):\n        \"\"\"Parametrization of a torus.\"\"\"\n        return np.array([\n            (R + r * np.cos(u)) * np.cos(v),\n            (R + r * np.cos(u)) * np.sin(v),\n            r * np.sin(u)\n        ])\n\n    def x_sphere(u, v):\n        \"\"\"Parametrization of a unit sphere.\"\"\"\n        return np.array([\n            np.sin(u) * np.cos(v),\n            np.sin(u) * np.sin(v),\n            np.cos(u)\n        ])\n\n    def x_cone(u, v):\n        \"\"\"Parametrization of a right circular cone.\"\"\"\n        return np.array([\n            u * np.cos(v),\n            u * np.sin(v),\n            u\n        ])\n\n    # --- Analytical First Fundamental Forms ---\n\n    def g_true_torus(u, v, R=2.0, r=0.6):\n        \"\"\"Analytical first fundamental form for the torus.\"\"\"\n        E = r**2\n        F = 0.0\n        G = (R + r * np.cos(u))**2\n        return np.array([[E, F], [F, G]])\n\n    def g_true_sphere(u, v):\n        \"\"\"Analytical first fundamental form for the unit sphere.\"\"\"\n        E = 1.0\n        F = 0.0\n        G = np.sin(u)**2\n        return np.array([[E, F], [F, G]])\n\n    def g_true_cone(u, v):\n        \"\"\"Analytical first fundamental form for the right circular cone.\"\"\"\n        E = 2.0\n        F = 0.0\n        G = u**2\n        return np.array([[E, F], [F, G]])\n\n    # --- Computational Core ---\n\n    def approximate_g(X_func, u0, v0, h, params):\n        \"\"\"\n        Approximates the first fundamental form matrix g at (u0, v0)\n        using a symmetric central finite difference scheme.\n        \"\"\"\n        # Approximate partial derivatives\n        X_u_h = (X_func(u0 + h, v0, **params) - X_func(u0 - h, v0, **params)) / (2 * h)\n        X_v_h = (X_func(u0, v0 + h, **params) - X_func(u0, v0 - h, **params)) / (2 * h)\n        \n        # Compute coefficients E, F, G from inner products\n        E_h = np.dot(X_u_h, X_u_h)\n        F_h = np.dot(X_u_h, X_v_h)\n        G_h = np.dot(X_v_h, X_v_h)\n        \n        return np.array([[E_h, F_h], [F_h, G_h]])\n\n    def compute_metrics(X_func, g_true_func, params, uv0, hs):\n        \"\"\"\n        Computes the required metrics: relative error, convergence order, and condition number.\n        \"\"\"\n        u0, v0 = uv0\n        h1, h2, h3 = hs\n        epsilon = 1e-30\n\n        # Compute true metric\n        g_true = g_true_func(u0, v0, **params)\n        norm_g_true = np.linalg.norm(g_true, 'fro')\n\n        # Compute approximations and errors\n        g_h = [approximate_g(X_func, u0, v0, h, params) for h in hs]\n        g_h1, g_h2, g_h3 = g_h\n\n        errors = [np.linalg.norm(g_approx - g_true, 'fro') / max(norm_g_true, epsilon) for g_approx in g_h]\n        err_h1, err_h2, err_h3 = errors\n\n        # Compute convergence order p\n        # p = log(err3/err1) / log(h3/h1)\n        # Check for zero or non-positive errors to avoid log domain errors\n        if err_h1 = 0 or err_h3 = 0:\n            p = np.nan  # Indicate failure to compute order\n        else:\n            p = (np.log(err_h3) - np.log(err_h1)) / (np.log(h3) - np.log(h1))\n\n        # Compute condition number kappa\n        eigenvalues = np.linalg.eigvalsh(g_h3)\n        lambda_min, lambda_max = eigenvalues[0], eigenvalues[1]\n        \n        if lambda_min > 0:\n            kappa = lambda_max / lambda_min\n        else:\n            kappa = 1e16\n\n        return [err_h3, p, kappa]\n\n    # --- Test Suite Definition ---\n\n    test_cases = [\n        {\n            \"X_func\": x_torus,\n            \"g_true_func\": g_true_torus,\n            \"params\": {\"R\": 2.0, \"r\": 0.6},\n            \"uv0\": (1.0, 0.8),\n        },\n        {\n            \"X_func\": x_sphere,\n            \"g_true_func\": g_true_sphere,\n            \"params\": {},\n            \"uv0\": (1e-6, 0.8),\n        },\n        {\n            \"X_func\": x_cone,\n            \"g_true_func\": g_true_cone,\n            \"params\": {},\n            \"uv0\": (1e-6, 1.3),\n        },\n    ]\n    \n    step_sizes = [1e-1, 1e-2, 1e-3]\n    results = []\n\n    for case in test_cases:\n        result = compute_metrics(\n            case[\"X_func\"],\n            case[\"g_true_func\"],\n            case[\"params\"],\n            case[\"uv0\"],\n            step_sizes\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The string representation is used to match the example format exactly.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3070673"}]}