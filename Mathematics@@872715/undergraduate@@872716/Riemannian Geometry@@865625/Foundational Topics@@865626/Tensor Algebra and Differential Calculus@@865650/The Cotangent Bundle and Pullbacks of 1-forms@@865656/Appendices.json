{"hands_on_practices": [{"introduction": "To truly grasp the concept of the pullback, we must get our hands dirty with computation. This first practice problem is a direct application of the definitions, guiding you through the essential mechanics of calculating a pullback in local coordinates. By performing the calculation and then verifying it against the fundamental definition involving the differential map, you will solidify the connection between the abstract theory and a concrete computational algorithm [@problem_id:3069053].", "problem": "Let $U \\subset \\mathbb{R}^{3}$ and $V \\subset \\mathbb{R}^{3}$ be open sets with standard coordinates on $U$ denoted by $(x_{1}, x_{2}, x_{3})$ and on $V$ denoted by $(u, v, w)$. Consider the smooth map $F : U \\to V$ defined by $F(x_{1}, x_{2}, x_{3}) = (u, v, w)$ with\n$$u = x_{1} x_{2}, \\quad v = x_{2} + x_{3}, \\quad w = x_{1}^{2} + x_{3}.$$\nLet $\\alpha$ be the $1$-form on $V$ given by\n$$\\alpha(u, v, w) = \\big(u^{2} + v\\big) \\, du + \\big(u v + \\sin(w)\\big) \\, dv + \\exp\\big(u v\\big) \\, dw.$$\nUsing the definition of the pullback of a $1$-form and the coordinate-induced bases on tangent and cotangent spaces, compute the pullback $F^{*}\\alpha$ as a $1$-form on $U$ written in the basis $\\{dx_{1}, dx_{2}, dx_{3}\\}$. Then evaluate the coefficient functions of $F^{*}\\alpha$ at the point $p = (1, 2, 0)$, and provide the resulting row matrix of the three coefficients multiplying $dx_{1}$, $dx_{2}$, and $dx_{3}$, respectively.\n\nYour final answer must be expressed as a single row matrix using the LaTeX $\\texttt{pmatrix}$ environment with exact values (no rounding). Additionally, verify each component at $p$ directly from the defining property of the pullback that for any $v \\in T_{p}U$,\n$$(F^{*}\\alpha)_{p}(v) = \\alpha_{F(p)}\\big(dF_{p}(v)\\big),$$\nby checking the values on the coordinate vector fields $\\frac{\\partial}{\\partial x_{1}}, \\frac{\\partial}{\\partial x_{2}}, \\frac{\\partial}{\\partial x_{3}}$ at $p$.", "solution": "The problem is well-posed and self-contained, providing all necessary definitions and data for a unique solution. It is a standard exercise in differential geometry concerning the computation of a pullback of a differential $1$-form. We will proceed with the solution.\n\nThe problem asks us to compute the pullback $F^{*}\\alpha$ of a $1$-form $\\alpha$ on $V \\subset \\mathbb{R}^{3}$ by a smooth map $F: U \\to V$, where $U \\subset \\mathbb{R}^{3}$. We are given the coordinates $(x_{1}, x_{2}, x_{3})$ on $U$ and $(u, v, w)$ on $V$.\n\nThe map $F$ is defined by the component functions:\n$$u(x_{1}, x_{2}, x_{3}) = x_{1} x_{2}$$\n$$v(x_{1}, x_{2}, x_{3}) = x_{2} + x_{3}$$\n$$w(x_{1}, x_{2}, x_{3}) = x_{1}^{2} + x_{3}$$\n\nThe $1$-form $\\alpha$ on $V$ is given by:\n$$\\alpha = \\alpha_u \\, du + \\alpha_v \\, dv + \\alpha_w \\, dw = \\big(u^{2} + v\\big) \\, du + \\big(u v + \\sin(w)\\big) \\, dv + \\exp\\big(u v\\big) \\, dw$$\n\nThe pullback $F^{*}\\alpha$ is a $1$-form on $U$. By definition, it is computed as:\n$$F^{*}\\alpha = (\\alpha_u \\circ F) \\, d(u \\circ F) + (\\alpha_v \\circ F) \\, d(v \\circ F) + (\\alpha_w \\circ F) \\, d(w \\circ F)$$\nThis is often written more simply as:\n$$F^{*}\\alpha = \\big(u^{2} + v\\big)\\big|_{F} \\, du + \\big(u v + \\sin(w)\\big)\\big|_{F} \\, dv + \\exp\\big(u v\\big)\\big|_{F} \\, dw$$\nwhere it is understood that $u, v, w$ are substituted with their expressions in terms of $x_1, x_2, x_3$, and $du, dv, dw$ are computed in terms of $dx_1, dx_2, dx_3$.\n\nFirst, we substitute the component functions of $F$ into the coefficients of $\\alpha$:\n\\begin{itemize}\n    \\item $\\alpha_u \\circ F = (x_{1} x_{2})^{2} + (x_{2} + x_{3}) = x_{1}^{2} x_{2}^{2} + x_{2} + x_{3}$\n    \\item $\\alpha_v \\circ F = (x_{1} x_{2})(x_{2} + x_{3}) + \\sin(x_{1}^{2} + x_{3}) = x_{1} x_{2}^{2} + x_{1} x_{2} x_{3} + \\sin(x_{1}^{2} + x_{3})$\n    \\item $\\alpha_w \\circ F = \\exp\\big((x_{1} x_{2})(x_{2} + x_{3})\\big) = \\exp(x_{1} x_{2}^{2} + x_{1} x_{2} x_{3})$\n\\end{itemize}\n\nNext, we compute the differentials of the component functions of $F$:\n\\begin{itemize}\n    \\item $du = \\frac{\\partial u}{\\partial x_{1}} dx_{1} + \\frac{\\partial u}{\\partial x_{2}} dx_{2} + \\frac{\\partial u}{\\partial x_{3}} dx_{3} = x_{2} \\, dx_{1} + x_{1} \\, dx_{2}$\n    \\item $dv = \\frac{\\partial v}{\\partial x_{1}} dx_{1} + \\frac{\\partial v}{\\partial x_{2}} dx_{2} + \\frac{\\partial v}{\\partial x_{3}} dx_{3} = 1 \\, dx_{2} + 1 \\, dx_{3} = dx_{2} + dx_{3}$\n    \\item $dw = \\frac{\\partial w}{\\partial x_{1}} dx_{1} + \\frac{\\partial w}{\\partial x_{2}} dx_{2} + \\frac{\\partial w}{\\partial x_{3}} dx_{3} = 2x_{1} \\, dx_{1} + 1 \\, dx_{3} = 2x_{1} \\, dx_{1} + dx_{3}$\n\\end{itemize}\n\nNow, we substitute these expressions back into the formula for $F^{*}\\alpha$:\n$$F^{*}\\alpha = (x_{1}^{2} x_{2}^{2} + x_{2} + x_{3})(x_{2} \\, dx_{1} + x_{1} \\, dx_{2}) + (x_{1} x_{2}^{2} + x_{1} x_{2} x_{3} + \\sin(x_{1}^{2} + x_{3}))(dx_{2} + dx_{3}) + \\exp(x_{1} x_{2}^{2} + x_{1} x_{2} x_{3})(2x_{1} \\, dx_{1} + dx_{3})$$\n\nWe group the terms by $dx_{1}$, $dx_{2}$, and $dx_{3}$ to find the coefficient functions of $F^{*}\\alpha$ in the basis $\\{dx_{1}, dx_{2}, dx_{3}\\}$. Let $F^{*}\\alpha = g_{1} dx_{1} + g_{2} dx_{2} + g_{3} dx_{3}$.\n\nCoefficient of $dx_{1}$:\n$$g_{1}(x_{1}, x_{2}, x_{3}) = (x_{1}^{2} x_{2}^{2} + x_{2} + x_{3})x_{2} + \\exp(x_{1} x_{2}^{2} + x_{1} x_{2} x_{3})(2x_{1})$$\n$$g_{1}(x_{1}, x_{2}, x_{3}) = x_{1}^{2} x_{2}^{3} + x_{2}^{2} + x_{2} x_{3} + 2x_{1} \\exp(x_{1} x_{2}^{2} + x_{1} x_{2} x_{3})$$\n\nCoefficient of $dx_{2}$:\n$$g_{2}(x_{1}, x_{2}, x_{3}) = (x_{1}^{2} x_{2}^{2} + x_{2} + x_{3})x_{1} + (x_{1} x_{2}^{2} + x_{1} x_{2} x_{3} + \\sin(x_{1}^{2} + x_{3}))$$\n$$g_{2}(x_{1}, x_{2}, x_{3}) = x_{1}^{3} x_{2}^{2} + x_{1} x_{2} + x_{1} x_{3} + x_{1} x_{2}^{2} + x_{1} x_{2} x_{3} + \\sin(x_{1}^{2} + x_{3})$$\n\nCoefficient of $dx_{3}$:\n$$g_{3}(x_{1}, x_{2}, x_{3}) = (x_{1} x_{2}^{2} + x_{1} x_{2} x_{3} + \\sin(x_{1}^{2} + x_{3})) + \\exp(x_{1} x_{2}^{2} + x_{1} x_{2} x_{3})$$\n\nNext, we evaluate these coefficient functions at the point $p = (1, 2, 0)$.\nAt $p = (x_{1}, x_{2}, x_{3}) = (1, 2, 0)$:\n$$g_{1}(1, 2, 0) = (1)^{2}(2)^{3} + (2)^{2} + (2)(0) + 2(1) \\exp((1)(2)^{2} + (1)(2)(0))$$\n$$g_{1}(1, 2, 0) = 8 + 4 + 0 + 2 \\exp(4) = 12 + 2\\exp(4)$$\n\n$$g_{2}(1, 2, 0) = (1)^{3}(2)^{2} + (1)(2) + (1)(0) + (1)(2)^{2} + (1)(2)(0) + \\sin((1)^{2} + 0)$$\n$$g_{2}(1, 2, 0) = 4 + 2 + 0 + 4 + 0 + \\sin(1) = 10 + \\sin(1)$$\n\n$$g_{3}(1, 2, 0) = (1)(2)^{2} + (1)(2)(0) + \\sin((1)^{2} + 0) + \\exp((1)(2)^{2} + (1)(2)(0))$$\n$$g_{3}(1, 2, 0) = 4 + 0 + \\sin(1) + \\exp(4) = 4 + \\sin(1) + \\exp(4)$$\n\nSo, the coefficients of $F^{*}\\alpha$ at $p=(1, 2, 0)$ are $(12 + 2\\exp(4), 10 + \\sin(1), 4 + \\sin(1) + \\exp(4))$.\n\nNow, we verify this result using the fundamental definition of the pullback: for any tangent vector $X_p \\in T_p U$, we have $(F^{*}\\alpha)_p(X_p) = \\alpha_{F(p)}(dF_p(X_p))$. We check this for the basis vectors $X_p = \\frac{\\partial}{\\partial x_{i}}\\big|_p$ for $i=1, 2, 3$.\nThe components of $(F^*\\alpha)_p$ are precisely $(F^{*}\\alpha)_p(\\frac{\\partial}{\\partial x_{i}}\\big|_p) = g_{i}(p)$.\nWe must show that $\\alpha_{F(p)}(dF_p(\\frac{\\partial}{\\partial x_{i}}\\big|_p)) = g_{i}(p)$.\n\nFirst, find the point $q = F(p) \\in V$:\n$q = F(1, 2, 0) = (u(1,2,0), v(1,2,0), w(1,2,0)) = (1 \\cdot 2, 2+0, 1^2+0) = (2, 2, 1)$.\n\nNext, evaluate the $1$-form $\\alpha$ at $q=(2, 2, 1)$:\n$$\\alpha_q = \\big(u^{2} + v\\big)\\big|_q \\, du + \\big(u v + \\sin(w)\\big)\\big|_q \\, dv + \\exp\\big(u v\\big)\\big|_q \\, dw$$\n$$\\alpha_q = (2^{2} + 2) \\, du + (2 \\cdot 2 + \\sin(1)) \\, dv + \\exp(2 \\cdot 2) \\, dw$$\n$$\\alpha_q = 6 \\, du + (4 + \\sin(1)) \\, dv + \\exp(4) \\, dw$$\n\nThe differential map $dF_p$ is represented by the Jacobian matrix of $F$ evaluated at $p$.\n$$J_F = \\begin{pmatrix} \\frac{\\partial u}{\\partial x_1}  \\frac{\\partial u}{\\partial x_2}  \\frac{\\partial u}{\\partial x_3} \\\\ \\frac{\\partial v}{\\partial x_1}  \\frac{\\partial v}{\\partial x_2}  \\frac{\\partial v}{\\partial x_3} \\\\ \\frac{\\partial w}{\\partial x_1}  \\frac{\\partial w}{\\partial x_2}  \\frac{\\partial w}{\\partial x_3} \\end{pmatrix} = \\begin{pmatrix} x_2  x_1  0 \\\\ 0  1  1 \\\\ 2x_1  0  1 \\end{pmatrix}$$\nAt $p=(1, 2, 0)$, the matrix is:\n$$dF_p = J_F(1, 2, 0) = \\begin{pmatrix} 2  1  0 \\\\ 0  1  1 \\\\ 2  0  1 \\end{pmatrix}$$\nThe images of the basis vectors $\\frac{\\partial}{\\partial x_i}\\big|_p$ under $dF_p$ are the columns of this matrix, expressed in the basis $\\{\\frac{\\partial}{\\partial u}\\big|_q, \\frac{\\partial}{\\partial v}\\big|_q, \\frac{\\partial}{\\partial w}\\big|_q\\}$:\n$$dF_p\\left(\\frac{\\partial}{\\partial x_1}\\Big|_p\\right) = 2 \\frac{\\partial}{\\partial u}\\Big|_q + 0 \\frac{\\partial}{\\partial v}\\Big|_q + 2 \\frac{\\partial}{\\partial w}\\Big|_q$$\n$$dF_p\\left(\\frac{\\partial}{\\partial x_2}\\Big|_p\\right) = 1 \\frac{\\partial}{\\partial u}\\Big|_q + 1 \\frac{\\partial}{\\partial v}\\Big|_q + 0 \\frac{\\partial}{\\partial w}\\Big|_q$$\n$$dF_p\\left(\\frac{\\partial}{\\partial x_3}\\Big|_p\\right) = 0 \\frac{\\partial}{\\partial u}\\Big|_q + 1 \\frac{\\partial}{\\partial v}\\Big|_q + 1 \\frac{\\partial}{\\partial w}\\Big|_q$$\n\nFinally, we apply $\\alpha_q$ to these vectors:\nFor $i=1$:\n$$\\alpha_q\\left(dF_p\\left(\\frac{\\partial}{\\partial x_1}\\Big|_p\\right)\\right) = \\left(6 \\, du + (4 + \\sin(1)) \\, dv + \\exp(4) \\, dw\\right)\\left(2 \\frac{\\partial}{\\partial u} + 2 \\frac{\\partial}{\\partial w}\\right) = 6(2) + (4+\\sin(1))(0) + \\exp(4)(2) = 12 + 2\\exp(4)$$\nThis matches $g_1(1, 2, 0)$.\n\nFor $i=2$:\n$$\\alpha_q\\left(dF_p\\left(\\frac{\\partial}{\\partial x_2}\\Big|_p\\right)\\right) = \\left(6 \\, du + (4 + \\sin(1)) \\, dv + \\exp(4) \\, dw\\right)\\left(1 \\frac{\\partial}{\\partial u} + 1 \\frac{\\partial}{\\partial v}\\right) = 6(1) + (4+\\sin(1))(1) + \\exp(4)(0) = 10 + \\sin(1)$$\nThis matches $g_2(1, 2, 0)$.\n\nFor $i=3$:\n$$\\alpha_q\\left(dF_p\\left(\\frac{\\partial}{\\partial x_3}\\Big|_p\\right)\\right) = \\left(6 \\, du + (4 + \\sin(1)) \\, dv + \\exp(4) \\, dw\\right)\\left(1 \\frac{\\partial}{\\partial v} + 1 \\frac{\\partial}{\\partial w}\\right) = 6(0) + (4+\\sin(1))(1) + \\exp(4)(1) = 4 + \\sin(1) + \\exp(4)$$\nThis matches $g_3(1, 2, 0)$.\n\nThe verification is successful. The coefficients of $F^{*}\\alpha$ at $p=(1, 2, 0)$ are as calculated. The final answer is the row matrix of these three coefficients.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n12 + 2\\exp(4)  10 + \\sin(1)  4 + \\sin(1) + \\exp(4)\n\\end{pmatrix}\n}\n$$", "id": "3069053"}, {"introduction": "Pullbacks are not just abstract tools; they provide the rigorous framework for concepts you may have already encountered, such as changing coordinate systems. This exercise connects the pullback to the familiar transformation between Cartesian and polar coordinates [@problem_id:3069042]. By calculating the pullback of the standard basis $1$-forms and the area element, you will see precisely how the machinery of differential forms formalizes the change of variables from multivariable calculus.", "problem": "Let $M=(0,\\infty)\\times(0,2\\pi)$ with coordinates $(r,\\theta)$ and $N=\\mathbb{R}^2$ with coordinates $(x,y)$. Consider the smooth map $F:M\\to N$ given by the polar-to-Cartesian conversion $F(r,\\theta)=(r\\cos\\theta,\\,r\\sin\\theta)$. Let $dx,dy$ denote the standard coordinate $1$-forms on $N$, and let $dr,d\\theta$ denote the standard coordinate $1$-forms on $M$. Using only the core definitions of the cotangent bundle and the pullback of $1$-forms by a smooth map, do the following:\n\n1. Compute the pullbacks $F^{*}(dx)$ and $F^{*}(dy)$ explicitly as linear combinations of $dr$ and $d\\theta$.\n2. Using the definitions of the functions $r(x,y)=\\sqrt{x^{2}+y^{2}}$ and $\\theta(x,y)$ (the continuous branch of the polar angle on $\\mathbb{R}^{2}\\setminus\\{(0,0)\\}$ with values in $(0,2\\pi)$), express $dr$ and $d\\theta$ in terms of $dx$ and $dy$ and verify that these relations are compatible with your expressions for $F^{*}(dx)$ and $F^{*}(dy)$.\n3. Finally, determine the unique coefficient function $C(r,\\theta)$ such that $F^{*}(dx\\wedge dy)=C(r,\\theta)\\,dr\\wedge d\\theta$.\n\nProvide $C(r,\\theta)$ as your final answer. No rounding is needed.", "solution": "The problem is well-posed and mathematically sound. We shall proceed with a systematic, step-by-step solution based on the definitions of pullbacks of differential forms.\n\nLet $M = (0,\\infty) \\times (0,2\\pi)$ be a manifold with local coordinates $(r,\\theta)$, and let $N = \\mathbb{R}^2$ be a manifold with global coordinates $(x,y)$. The smooth map $F: M \\to N$ is given by the polar-to-Cartesian coordinate transformation:\n$$F(r, \\theta) = (x(r,\\theta), y(r,\\theta)) = (r\\cos\\theta, r\\sin\\theta)$$\nLet $x, y$ also denote the coordinate projection functions on $N$. The components of the map $F$ are thus $x \\circ F: M \\to \\mathbb{R}$ where $(x \\circ F)(r, \\theta) = r\\cos\\theta$, and $y \\circ F: M \\to \\mathbb{R}$ where $(y \\circ F)(r, \\theta) = r\\sin\\theta$.\n\n**Part 1: Computation of $F^{*}(dx)$ and $F^{*}(dy)$**\n\nThe pullback of a $1$-form is defined by its action on tangent vectors. However, a more direct method for coordinate $1$-forms relies on a core property of the exterior derivative and pullbacks: for any smooth function $g$ on $N$, the pullback of its differential $dg$ is given by $F^{*}(dg) = d(g \\circ F)$. This is a direct consequence of the chain rule.\n\nApplying this property to the coordinate functions $x$ and $y$ on $N$, we compute the pullbacks of the basis $1$-forms $dx$ and $dy$.\n\nFor $dx$:\n$$F^{*}(dx) = d(x \\circ F) = d(r\\cos\\theta)$$\nUsing the definition of the exterior derivative on $M$, we expand this expression in the basis $\\{dr, d\\theta\\}$:\n$$d(r\\cos\\theta) = \\frac{\\partial(r\\cos\\theta)}{\\partial r} dr + \\frac{\\partial(r\\cos\\theta)}{\\partial\\theta} d\\theta$$\nThe partial derivatives are:\n$$\\frac{\\partial(r\\cos\\theta)}{\\partial r} = \\cos\\theta$$\n$$\\frac{\\partial(r\\cos\\theta)}{\\partial\\theta} = -r\\sin\\theta$$\nThus, the pullback of $dx$ is:\n$$F^{*}(dx) = \\cos\\theta \\, dr - r\\sin\\theta \\, d\\theta$$\n\nFor $dy$:\n$$F^{*}(dy) = d(y \\circ F) = d(r\\sin\\theta)$$\nSimilarly, we expand this in the basis $\\{dr, d\\theta\\}$:\n$$d(r\\sin\\theta) = \\frac{\\partial(r\\sin\\theta)}{\\partial r} dr + \\frac{\\partial(r\\sin\\theta)}{\\partial\\theta} d\\theta$$\nThe partial derivatives are:\n$$\\frac{\\partial(r\\sin\\theta)}{\\partial r} = \\sin\\theta$$\n$$\\frac{\\partial(r\\sin\\theta)}{\\partial\\theta} = r\\cos\\theta$$\nThus, the pullback of $dy$ is:\n$$F^{*}(dy) = \\sin\\theta \\, dr + r\\cos\\theta \\, d\\theta$$\n\n**Part 2: Inverse Relations and Verification**\n\nWe are given the functions $r(x,y) = \\sqrt{x^2+y^2}$ and $\\theta(x,y)$ (the appropriate branch of the angle) defined on a subset of $N$. We compute their exterior derivatives $dr$ and $d\\theta$ as $1$-forms on $N$.\n\nFor $dr$:\n$$dr = d\\left(\\sqrt{x^2+y^2}\\right) = \\frac{\\partial(\\sqrt{x^2+y^2})}{\\partial x} dx + \\frac{\\partial(\\sqrt{x^2+y^2})}{\\partial y} dy$$\nThe partial derivatives are:\n$$\\frac{\\partial}{\\partial x}\\left(\\sqrt{x^2+y^2}\\right) = \\frac{2x}{2\\sqrt{x^2+y^2}} = \\frac{x}{r}$$\n$$\\frac{\\partial}{\\partial y}\\left(\\sqrt{x^2+y^2}\\right) = \\frac{2y}{2\\sqrt{x^2+y^2}} = \\frac{y}{r}$$\nSo, $dr = \\frac{x}{r} dx + \\frac{y}{r} dy$. On the image of $F$, we have $x = r\\cos\\theta$ and $y = r\\sin\\theta$, so we can write this as:\n$$dr = \\cos\\theta \\, dx + \\sin\\theta \\, dy$$\n\nFor $d\\theta$:\nIt is often more convenient to start from an implicit definition such as $\\tan\\theta = y/x$. Taking the exterior derivative of both sides:\n$$d(\\tan\\theta) = d\\left(\\frac{y}{x}\\right)$$\n$$\\sec^2\\theta \\, d\\theta = \\frac{x\\,dy - y\\,dx}{x^2}$$\nSolving for $d\\theta$:\n$$d\\theta = \\cos^2\\theta \\left(\\frac{x\\,dy - y\\,dx}{x^2}\\right) = \\frac{\\cos^2\\theta}{x^2}(x\\,dy - y\\,dx)$$\nUsing $x=r\\cos\\theta$, we have $x^2 = r^2\\cos^2\\theta$, so:\n$$d\\theta = \\frac{1}{r^2}(x\\,dy - y\\,dx) = -\\frac{y}{r^2} dx + \\frac{x}{r^2} dy$$\nOn the image of $F$, this becomes:\n$$d\\theta = -\\frac{r\\sin\\theta}{r^2} dx + \\frac{r\\cos\\theta}{r^2} dy = -\\frac{\\sin\\theta}{r} dx + \\frac{\\cos\\theta}{r} dy$$\n\nWe now have two systems of linear equations. The first relates $\\{F^*(dx), F^*(dy)\\}$ to $\\{dr, d\\theta\\}$ on the manifold $M$:\n(1) $F^{*}(dx) = \\cos\\theta \\, dr - r\\sin\\theta \\, d\\theta$\n(2) $F^{*}(dy) = \\sin\\theta \\, dr + r\\cos\\theta \\, d\\theta$\n\nThe second relates $\\{dr, d\\theta\\}$ to $\\{dx, dy\\}$ on the manifold $N$:\n(A) $dr = \\cos\\theta \\, dx + \\sin\\theta \\, dy$\n(B) $d\\theta = -\\frac{\\sin\\theta}{r} dx + \\frac{\\cos\\theta}{r} dy$\n\nTo verify compatibility, we can solve the second system for $dx$ and $dy$. Multiply (B) by $r$:\n(B') $r\\,d\\theta = -\\sin\\theta \\, dx + \\cos\\theta \\, dy$\nTo eliminate $dy$, multiply (A) by $\\cos\\theta$ and (B') by $\\sin\\theta$ and subtract:\n$$\\cos\\theta dr - r\\sin\\theta d\\theta = (\\cos^2\\theta dx + \\sin\\theta\\cos\\theta dy) - (-\\sin^2\\theta dx + \\sin\\theta\\cos\\theta dy)$$\n$$\\cos\\theta dr - r\\sin\\theta d\\theta = (\\cos^2\\theta + \\sin^2\\theta) dx = dx$$\nTo eliminate $dx$, multiply (A) by $\\sin\\theta$ and (B') by $\\cos\\theta$ and add:\n$$\\sin\\theta dr + r\\cos\\theta d\\theta = (\\sin\\theta\\cos\\theta dx + \\sin^2\\theta dy) + (-\\sin\\theta\\cos\\theta dx + \\cos^2\\theta dy)$$\n$$\\sin\\theta dr + r\\cos\\theta d\\theta = (\\sin^2\\theta + \\cos^2\\theta) dy = dy$$\n\nSo we have derived the inverse relations on $N$:\n$$dx = \\cos\\theta \\, dr - r\\sin\\theta \\, d\\theta$$\n$$dy = \\sin\\theta \\, dr + r\\cos\\theta \\, d\\theta$$\nHere, all forms are on $N$. When we apply the pullback $F^*$ to these equations, we use the fact that $F^*$ is a linear operator and acts on functions by composition. As established in the problem setup, $r\\circ F$ is the coordinate $r$ on $M$, and $\\theta \\circ F$ is the coordinate $\\theta$ on $M$. Consequently, $F^*(dr)=d(r\\circ F)=dr$ and $F^*(d\\theta)=d(\\theta\\circ F)=d\\theta$. The pullback of functions like $\\cos\\theta$ and $r$ also results in the corresponding functions on $M$. Applying $F^*$ to the equations for $dx$ and $dy$ directly yields the expressions for $F^*(dx)$ and $F^*(dy)$ found in Part 1. This demonstrates full compatibility.\n\n**Part 3: Determination of $C(r,\\theta)$**\n\nWe need to find the function $C(r,\\theta)$ such that $F^{*}(dx\\wedge dy)=C(r,\\theta)\\,dr\\wedge d\\theta$. A core property of the pullback operator is that it commutes with the wedge product: $F^{*}(\\alpha \\wedge \\beta) = F^{*}(\\alpha) \\wedge F^{*}(\\beta)$.\n\nUsing this property and the results from Part 1:\n$$F^{*}(dx \\wedge dy) = F^{*}(dx) \\wedge F^{*}(dy)$$\n$$F^{*}(dx \\wedge dy) = (\\cos\\theta \\, dr - r\\sin\\theta \\, d\\theta) \\wedge (\\sin\\theta \\, dr + r\\cos\\theta \\, d\\theta)$$\nWe expand this using the distributive property of the wedge product and its anti-commutative nature ($dr \\wedge dr = 0$, $d\\theta \\wedge d\\theta = 0$, $d\\theta \\wedge dr = -dr \\wedge d\\theta$).\n$$F^{*}(dx \\wedge dy) = (\\cos\\theta \\, dr \\wedge \\sin\\theta \\, dr) + (\\cos\\theta \\, dr \\wedge r\\cos\\theta \\, d\\theta) - (r\\sin\\theta \\, d\\theta \\wedge \\sin\\theta \\, dr) - (r\\sin\\theta \\, d\\theta \\wedge r\\cos\\theta \\, d\\theta)$$\nThe first and fourth terms are zero:\n$$F^{*}(dx \\wedge dy) = 0 + r\\cos^2\\theta \\, (dr \\wedge d\\theta) - r\\sin^2\\theta \\, (d\\theta \\wedge dr) - 0$$\nUsing $d\\theta \\wedge dr = -dr \\wedge d\\theta$:\n$$F^{*}(dx \\wedge dy) = r\\cos^2\\theta \\, (dr \\wedge d\\theta) + r\\sin^2\\theta \\, (dr \\wedge d\\theta)$$\nFactoring out the common terms:\n$$F^{*}(dx \\wedge dy) = r(\\cos^2\\theta + \\sin^2\\theta) (dr \\wedge d\\theta)$$\nSince $\\cos^2\\theta + \\sin^2\\theta = 1$:\n$$F^{*}(dx \\wedge dy) = r \\, dr \\wedge d\\theta$$\nBy comparing this result to the required form $F^{*}(dx\\wedge dy)=C(r,\\theta)\\,dr\\wedge d\\theta$, we identify the coefficient function:\n$$C(r, \\theta) = r$$\nThis result is the Jacobian determinant of the coordinate transformation, representing how the area element transforms under the map $F$.", "answer": "$$\\boxed{r}$$", "id": "3069042"}, {"introduction": "Beyond mere calculation, it is crucial to understand the algebraic properties that make pullbacks so powerful. This exercise focuses on a cornerstone principle: a $1$-form is uniquely determined by its action on a basis of the tangent space. Through a concrete example, you will verify the equality of two $1$-forms that are defined differently but are, in fact, the same, illustrating key properties like the linearity of the pullback and its commutation with the exterior derivative [@problem_id:3069038].", "problem": "Let $M$ be a smooth manifold and let $T_p M$ denote the tangent space at a point $p \\in M$, with $T_p^{*} M$ the cotangent space at $p$. A $1$-form at $p$ is a linear functional in $T_p^{*} M$. Starting from the definition of the cotangent space as the dual vector space to $T_p M$, derive a criterion that determines when two $1$-forms $\\alpha, \\beta \\in T_p^{*} M$ are equal solely in terms of their values on a basis of $T_p M$.\n\nThen illustrate this criterion concretely on $M = \\mathbb{R}^{3}$ as follows. Let $p = (1,-1,2) \\in \\mathbb{R}^{3}$ and let $F : \\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ be the smooth map with component functions\n$$\nF(x,y,z) = \\big(f_{1}(x,y,z), f_{2}(x,y,z), f_{3}(x,y,z)\\big) = \\big(x + y^{2},\\; 2y - z,\\; xz\\big).\n$$\nOn the target $\\mathbb{R}^{3}$ with standard coordinates $(U,V,W)$, consider the $1$-form $\\theta = dU + 3\\,dV - dW$. Define\n$$\n\\alpha := \\big(F^{*}\\theta\\big)_{p} \\in T_{p}^{*}\\mathbb{R}^{3}, \\qquad \\beta := d\\big(f_{1} + 3 f_{2} - f_{3}\\big)_{p} \\in T_{p}^{*}\\mathbb{R}^{3}.\n$$\nUsing the standard basis $\\{e_{1}, e_{2}, e_{3}\\} = \\left\\{\\left(\\frac{\\partial}{\\partial x}\\right)_{p}, \\left(\\frac{\\partial}{\\partial y}\\right)_{p}, \\left(\\frac{\\partial}{\\partial z}\\right)_{p}\\right\\}$ of $T_{p}\\mathbb{R}^{3}$, compute the triple\n$$\n\\big((\\alpha - \\beta)(e_{1}),\\; (\\alpha - \\beta)(e_{2}),\\; (\\alpha - \\beta)(e_{3})\\big).\n$$\nExpress your final answer as a single row matrix. No rounding is required.", "solution": "The problem consists of two parts. First, we must derive a criterion for the equality of two $1$-forms at a point $p \\in M$ based on their values on a basis of the tangent space $T_p M$. Second, we must apply this criterion to a concrete example in $\\mathbb{R}^{3}$ by calculating the action of the difference of two specific $1$-forms, $\\alpha$ and $\\beta$, on the standard basis vectors.\n\n**Part 1: Derivation of the Criterion for Equality of 1-Forms**\n\nLet $M$ be a smooth manifold and $p \\in M$ be a point. The tangent space $T_p M$ is a real vector space of dimension $n = \\dim M$. The cotangent space at $p$, denoted $T_p^{*} M$, is defined as the dual vector space of $T_p M$. That is, $T_p^{*} M = \\text{Hom}(T_p M, \\mathbb{R})$, the space of all linear functionals from $T_p M$ to $\\mathbb{R}$. An element $\\omega \\in T_p^{*} M$ is called a covector or a $1$-form at $p$.\n\nWe want to find a criterion to determine when two $1$-forms $\\alpha, \\beta \\in T_p^{*} M$ are equal. Let $\\{e_1, e_2, \\dots, e_n\\}$ be any basis for the vector space $T_p M$.\n\n1.  **Necessity $(\\implies)$**: Assume $\\alpha = \\beta$. By definition of equality of functions, this means $\\alpha(v) = \\beta(v)$ for all vectors $v \\in T_p M$. Since the basis vectors $e_i$ are elements of $T_p M$, it follows directly that $\\alpha(e_i) = \\beta(e_i)$ for all $i \\in \\{1, 2, \\dots, n\\}$.\n\n2.  **Sufficiency $(\\impliedby)$**: Assume that $\\alpha(e_i) = \\beta(e_i)$ for all basis vectors $e_i$ where $i \\in \\{1, 2, \\dots, n\\}$. We must show that this implies $\\alpha(v) = \\beta(v)$ for any arbitrary vector $v \\in T_p M$.\n    Let $v \\in T_p M$. Since $\\{e_i\\}_{i=1}^n$ is a basis, $v$ can be written as a unique linear combination of the basis vectors:\n    $$\n    v = \\sum_{i=1}^{n} c^i e_i\n    $$\n    for some scalars $c^i \\in \\mathbb{R}$.\n    Now, we evaluate $\\alpha(v)$. Since $\\alpha$ is a linear functional, we have:\n    $$\n    \\alpha(v) = \\alpha\\left(\\sum_{i=1}^{n} c^i e_i\\right) = \\sum_{i=1}^{n} c^i \\alpha(e_i)\n    $$\n    Similarly, for the linear functional $\\beta$:\n    $$\n    \\beta(v) = \\beta\\left(\\sum_{i=1}^{n} c^i e_i\\right) = \\sum_{i=1}^{n} c^i \\beta(e_i)\n    $$\n    By our initial assumption, $\\alpha(e_i) = \\beta(e_i)$ for each $i$. Therefore, the two sums are equal:\n    $$\n    \\sum_{i=1}^{n} c^i \\alpha(e_i) = \\sum_{i=1}^{n} c^i \\beta(e_i)\n    $$\n    This implies $\\alpha(v) = \\beta(v)$. As this holds for any arbitrary vector $v \\in T_p M$, we conclude that the functionals $\\alpha$ and $\\beta$ are identical, i.e., $\\alpha = \\beta$.\n\nThus, the criterion is: **Two $1$-forms $\\alpha, \\beta \\in T_p^{*} M$ are equal if and only if they agree on a basis of $T_p M$.**\n\nThis means to show $\\alpha = \\beta$, it is sufficient to check that $(\\alpha - \\beta)(e_i) = 0$ for all basis vectors $e_i$.\n\n**Part 2: Concrete Illustration and Computation**\n\nWe are given $M = \\mathbb{R}^{3}$, $p = (1, -1, 2)$. The map is $F:\\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ with component functions $f_1(x,y,z) = x+y^2$, $f_2(x,y,z) = 2y-z$, and $f_3(x,y,z) = xz$. The target space has coordinates $(U,V,W)$. The $1$-form on the target is $\\theta = dU + 3dV - dW$.\nThe two $1$-forms at $p$ are $\\alpha = (F^{*}\\theta)_p$ and $\\beta = d(f_1 + 3f_2 - f_3)_p$.\n\nA key property of pullbacks and the exterior derivative is that they commute, i.e., $F^{*}(dG) = d(G \\circ F)$ for any smooth function $G$. Also, the pullback operation $F^*$ is linear. Let $U, V, W$ also denote the coordinate functions on the target $\\mathbb{R}^3$. Then $\\theta = dU + 3dV - dW = d(U+3V-W)$.\nUsing linearity of the pullback and the commutation property:\n$$\n\\alpha = (F^{*}\\theta)_p = \\big(F^{*}(dU + 3dV - dW)\\big)_p = \\big(F^{*}(dU) + 3F^{*}(dV) - F^{*}(dW)\\big)_p\n$$\n$$\n= \\big(d(U \\circ F) + 3d(V \\circ F) - d(W \\circ F)\\big)_p\n$$\nBy definition of the component functions of $F$, we have $f_1 = U \\circ F$, $f_2 = V \\circ F$, and $f_3 = W \\circ F$. Substituting these in:\n$$\n\\alpha = \\big(df_1 + 3df_2 - df_3\\big)_p\n$$\nUsing the linearity of the exterior derivative $d(f+g) = df+dg$ and $d(cf)=cdf$ for a constant $c$:\n$$\n\\alpha = d(f_1 + 3f_2 - f_3)_p\n$$\nThis is precisely the definition of $\\beta$. Thus, we expect $\\alpha = \\beta$, which would mean $(\\alpha - \\beta)$ is the zero $1$-form, and its evaluation on any vector, including the basis vectors, must be $0$. We will now verify this by direct computation.\n\nLet $H(x,y,z) = f_1 + 3f_2 - f_3 = (x+y^2) + 3(2y-z) - xz = x + y^2 + 6y - 3z - xz$.\nThen $\\beta = dH_p$. We evaluate $\\beta$ on the standard basis vectors $e_1 = (\\frac{\\partial}{\\partial x})_p$, $e_2 = (\\frac{\\partial}{\\partial y})_p$, $e_3 = (\\frac{\\partial}{\\partial z})_p$.\nThe action of the differential of a function on a coordinate basis vector is the corresponding partial derivative:\n$$\n\\beta(e_1) = dH_p(e_1) = \\frac{\\partial H}{\\partial x}\\bigg|_p = (1-z)\\big|_{(1,-1,2)} = 1-2 = -1\n$$\n$$\n\\beta(e_2) = dH_p(e_2) = \\frac{\\partial H}{\\partial y}\\bigg|_p = (2y+6)\\big|_{(1,-1,2)} = 2(-1)+6 = 4\n$$\n$$\n\\beta(e_3) = dH_p(e_3) = \\frac{\\partial H}{\\partial z}\\bigg|_p = (-3-x)\\big|_{(1,-1,2)} = -3-1 = -4\n$$\n\nNow we compute the values of $\\alpha = (F^{*}\\theta)_p$ on the same basis. By definition, $\\alpha(v) = \\theta_{F(p)}(dF_p(v))$ for any $v \\in T_p \\mathbb{R}^3$.\nFirst, find the point $q=F(p)$ in the target manifold:\n$$\nq = F(1, -1, 2) = (1+(-1)^2, 2(-1)-2, 1(2)) = (2, -4, 2)\n$$\nNext, find the differential $dF_p$. Its matrix representation in the standard bases is the Jacobian matrix of $F$ evaluated at $p$:\n$$\nJ_F(x,y,z) = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial x}  \\frac{\\partial f_1}{\\partial y}  \\frac{\\partial f_1}{\\partial z} \\\\ \\frac{\\partial f_2}{\\partial x}  \\frac{\\partial f_2}{\\partial y}  \\frac{\\partial f_2}{\\partial z} \\\\ \\frac{\\partial f_3}{\\partial x}  \\frac{\\partial f_3}{\\partial y}  \\frac{\\partial f_3}{\\partial z} \\end{pmatrix} = \\begin{pmatrix} 1  2y  0 \\\\ 0  2  -1 \\\\ z  0  x \\end{pmatrix}\n$$\nEvaluating at $p=(1,-1,2)$:\n$$\nJ_F(p) = \\begin{pmatrix} 1  2(-1)  0 \\\\ 0  2  -1 \\\\ 2  0  1 \\end{pmatrix} = \\begin{pmatrix} 1  -2  0 \\\\ 0  2  -1 \\\\ 2  0  1 \\end{pmatrix}\n$$\nThis matrix gives the coordinates of the vectors $dF_p(e_i)$ in the basis $\\{(\\frac{\\partial}{\\partial U})_q, (\\frac{\\partial}{\\partial V})_q, (\\frac{\\partial}{\\partial W})_q\\}$ of $T_q\\mathbb{R}^3$:\n$$\ndF_p(e_1) = 1\\left(\\frac{\\partial}{\\partial U}\\right)_q + 0\\left(\\frac{\\partial}{\\partial V}\\right)_q + 2\\left(\\frac{\\partial}{\\partial W}\\right)_q\n$$\n$$\ndF_p(e_2) = -2\\left(\\frac{\\partial}{\\partial U}\\right)_q + 2\\left(\\frac{\\partial}{\\partial V}\\right)_q + 0\\left(\\frac{\\partial}{\\partial W}\\right)_q\n$$\n$$\ndF_p(e_3) = 0\\left(\\frac{\\partial}{\\partial U}\\right)_q - 1\\left(\\frac{\\partial}{\\partial V}\\right)_q + 1\\left(\\frac{\\partial}{\\partial W}\\right)_q\n$$\nNow apply $\\theta_q = (dU)_q + 3(dV)_q - (dW)_q$ to these vectors. Recall that $\\{dU, dV, dW\\}$ is the dual basis to $\\{\\frac{\\partial}{\\partial U}, \\frac{\\partial}{\\partial V}, \\frac{\\partial}{\\partial W}\\}$.\n$$\n\\alpha(e_1) = \\theta_q(dF_p(e_1)) = ((dU)_q + 3(dV)_q - (dW)_q)\\left(1\\left(\\frac{\\partial}{\\partial U}\\right)_q + 2\\left(\\frac{\\partial}{\\partial W}\\right)_q\\right) = 1(1) + 3(0) - 1(2) = -1\n$$\n$$\n\\alpha(e_2) = \\theta_q(dF_p(e_2)) = ((dU)_q + 3(dV)_q - (dW)_q)\\left(-2\\left(\\frac{\\partial}{\\partial U}\\right)_q + 2\\left(\\frac{\\partial}{\\partial V}\\right)_q\\right) = 1(-2) + 3(2) - 1(0) = 4\n$$\n$$\n\\alpha(e_3) = \\theta_q(dF_p(e_3)) = ((dU)_q + 3(dV)_q - (dW)_q)\\left(-1\\left(\\frac{\\partial}{\\partial V}\\right)_q + 1\\left(\\frac{\\partial}{\\partial W}\\right)_q\\right) = 1(0) + 3(-1) - 1(1) = -4\n$$\nWe have found that $\\alpha(e_1) = -1$, $\\alpha(e_2) = 4$, and $\\alpha(e_3) = -4$. These are identical to the values for $\\beta$.\nAccording to our derived criterion, since $\\alpha$ and $\\beta$ agree on a basis, they must be the same $1$-form: $\\alpha = \\beta$.\n\nFinally, we compute the required triple:\n$$\n(\\alpha - \\beta)(e_1) = \\alpha(e_1) - \\beta(e_1) = -1 - (-1) = 0\n$$\n$$\n(\\alpha - \\beta)(e_2) = \\alpha(e_2) - \\beta(e_2) = 4 - 4 = 0\n$$\n$$\n(\\alpha - \\beta)(e_3) = \\alpha(e_3) - \\beta(e_3) = -4 - (-4) = 0\n$$\nThe resulting triple is $(0, 0, 0)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0  0  0\n\\end{pmatrix}\n}\n$$", "id": "3069038"}]}