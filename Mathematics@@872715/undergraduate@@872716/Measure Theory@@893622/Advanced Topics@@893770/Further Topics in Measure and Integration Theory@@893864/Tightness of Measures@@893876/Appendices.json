{"hands_on_practices": [{"introduction": "To begin, let's explore the concept of tightness with a foundational exercise. This problem strips away complexity by using a sequence of simple, two-point probability distributions. By determining the condition under which this family of measures remains tight, you will gain a direct and intuitive understanding of what it means to prevent probability mass from \"escaping to infinity\" [@problem_id:1462682].", "problem": "Consider a sequence of probability measures $\\{\\mu_n\\}_{n=1}^{\\infty}$ defined on the real line $\\mathbb{R}$ equipped with its Borel sigma-algebra. Each measure $\\mu_n$ in the sequence is given by\n$$\n\\mu_n = \\frac{1}{2}\\delta_{-a_n} + \\frac{1}{2}\\delta_{a_n}\n$$\nwhere $\\{a_n\\}_{n=1}^{\\infty}$ is a sequence of non-negative real numbers, and $\\delta_x$ denotes the Dirac measure that assigns a mass of 1 to the point $x$ and 0 to any set not containing $x$.\n\nA sequence of probability measures $\\{\\mu_n\\}$ is defined as being tight if for every $\\epsilon > 0$, there exists a compact set $K \\subset \\mathbb{R}$ such that $\\mu_n(K) \\ge 1 - \\epsilon$ for all $n \\in \\{1, 2, 3, \\dots\\}$.\n\nWhich of the following is the necessary and sufficient condition on the sequence $\\{a_n\\}$ for the sequence of measures $\\{\\mu_n\\}$ to be tight?\n\nA. The sequence $\\{a_n\\}$ must converge.\nB. The sequence $\\{a_n\\}$ must be bounded.\nC. The sequence $\\{a_n\\}$ must converge to 0.\nD. The sum $\\sum_{n=1}^{\\infty} a_n$ must be finite.\nE. The sequence $\\{a_n\\}$ must have only a finite number of distinct values.", "solution": "By definition, the family $\\{\\mu_{n}\\}$ is tight if and only if for every $\\epsilon>0$ there exists a compact $K\\subset \\mathbb{R}$ such that $\\mu_{n}(K)\\geq 1-\\epsilon$ for all $n$.\n\nOn $\\mathbb{R}$, compact sets are bounded. Hence, there exists $R>0$ with $K\\subset [-R,R]$. By monotonicity of measures,\n$$\n\\mu_{n}([-R,R]) \\geq \\mu_{n}(K) \\geq 1-\\epsilon \\quad \\text{for all } n.\n$$\nFor any fixed $R\\geq 0$ and any $n$, the measure of the interval is\n$$\n\\mu_{n}([-R,R])=\\frac{1}{2}\\delta_{-a_{n}}([-R,R])+\\frac{1}{2}\\delta_{a_{n}}([-R,R])=\n\\begin{cases}\n1,  a_{n}\\leq R,\\\\\n0,  a_{n}>R,\n\\end{cases}\n$$\nbecause either both atoms $\\{-a_{n},a_{n}\\}$ lie inside $[-R,R]$ (when $a_{n}\\leq R$) or both lie outside (when $a_{n}>R$). Since $1-\\epsilon$ can be chosen to be greater than 0 (e.g., for $\\epsilon\\in(0,1)$), the inequality $\\mu_{n}([-R,R])\\geq 1-\\epsilon$ forces $\\mu_{n}([-R,R])=1$, hence $a_{n}\\leq R$ for all $n$. Therefore, tightness implies that $\\{a_{n}\\}$ is bounded.\n\nConversely, if $\\{a_{n}\\}$ is bounded, let $A=\\sup_{n}a_{n}\\infty$ and choose $K=[-A,A]$, which is compact. Then for every $n$ both atoms lie in $K$, so\n$$\n\\mu_{n}(K)=1 \\geq 1-\\epsilon \\quad \\text{for all } \\epsilon>0.\n$$\nThus the family $\\{\\mu_{n}\\}$ is tight.\n\nHence, the necessary and sufficient condition is that $\\{a_{n}\\}$ be bounded. Evaluating the options:\n- A (convergence) is stronger than needed and not necessary.\n- B (boundedness) is exactly the required condition.\n- C (convergence to $0$) is not necessary.\n- D (finiteness of $\\sum a_{n}$) is irrelevant to tightness here.\n- E (finitely many distinct values) implies boundedness but is not necessary.\n\nTherefore, the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1462682"}, {"introduction": "Moving from discrete to continuous distributions, this practice introduces a powerful and widely-used technique for establishing tightness. Rather than checking the definition directly, we can often use moment conditions. This exercise, involving a family of Gaussian measures, demonstrates how a uniform bound on the second moment can guarantee tightness for the entire family, a result elegantly shown using Markov's inequality [@problem_id:1458421].", "problem": "In measure theory, the concept of tightness is crucial for studying the convergence of probability measures. A family of probability measures $\\{\\nu_\\alpha\\}_{\\alpha \\in I}$ on the real line $\\mathbb{R}$ (equipped with its Borel sigma-algebra) is said to be **tight** if for every $\\epsilon > 0$, there exists a compact set $K \\subset \\mathbb{R}$ such that $\\nu_\\alpha(K^c) \\le \\epsilon$ for all $\\alpha \\in I$. Here, $K^c$ denotes the complement of $K$.\n\nConsider the family of all Gaussian measures on $\\mathbb{R}$. A Gaussian measure, denoted $N(\\mu, \\sigma^2)$, is a probability measure with mean $\\mu \\in \\mathbb{R}$ and variance $\\sigma^2 \\ge 0$. If $\\sigma^2 > 0$, its probability density function is given by $f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$. If $\\sigma^2 = 0$, the measure is the Dirac delta measure $\\delta_\\mu$ centered at $\\mu$.\n\nLet $\\mathcal{F}$ be the family of all such Gaussian measures $N(\\mu, \\sigma^2)$ where the mean $\\mu$ and variance $\\sigma^2$ are constrained by the inequality:\n$$ \\mu^2 + \\sigma^2 \\le 1 $$\n\nWhich of the following statements about the family $\\mathcal{F}$ is true?\n\nA. The family $\\mathcal{F}$ is tight.\nB. The family $\\mathcal{F}$ is not tight because the means $\\mu$ can vary.\nC. The family $\\mathcal{F}$ is not tight because the variances $\\sigma^2$ can be arbitrarily close to zero.\nD. The family $\\mathcal{F}$ is not tight because the support of each individual Gaussian measure with $\\sigma^2 > 0$ is the entire real line, which is not compact.\nE. The tightness of the family $\\mathcal{F}$ cannot be determined without more information.", "solution": "We must determine whether the family $\\mathcal{F}=\\{N(\\mu,\\sigma^{2}): \\mu^{2}+\\sigma^{2}\\le 1\\}$ is tight on $\\mathbb{R}$. By definition, tightness means: for every $\\epsilon>0$, there exists a compact $K\\subset \\mathbb{R}$ such that, for all $\\nu\\in \\mathcal{F}$, $\\nu(K^{c})\\le\\epsilon$.\n\nFix any $N(\\mu,\\sigma^{2})\\in \\mathcal{F}$ and let $X\\sim N(\\mu,\\sigma^{2})$. Its second moment is\n$$\n\\mathbb{E}[X^{2}]=\\operatorname{Var}(X)+(\\mathbb{E}X)^{2}=\\sigma^{2}+\\mu^{2}\\le 1,\n$$\nby the constraint defining $\\mathcal{F}$. Apply Markov's inequality to the nonnegative random variable $X^{2}$: for any $R>0$,\n$$\n\\mathbb{P}(|X|>R)=\\mathbb{P}(X^{2}>R^{2})\\le \\frac{\\mathbb{E}[X^{2}]}{R^{2}}\\le \\frac{1}{R^{2}}.\n$$\nNow fix $\\epsilon>0$ and choose $R=\\epsilon^{-1/2}$. Let $K=[-R,R]$, which is compact in $\\mathbb{R}$. Then, uniformly over all $\\nu\\in \\mathcal{F}$,\n$$\n\\nu(K^{c})=\\mathbb{P}(|X|>R)\\le \\frac{1}{R^2} = \\epsilon.\n$$\nTherefore, for every $\\epsilon>0$, there exists a compact $K$ such that $\\sup_{\\nu\\in\\mathcal{F}}\\nu(K^{c})\\le \\epsilon$, proving that $\\mathcal{F}$ is tight.\n\nConsequently, statement A is true. The alternatives are false for the following reasons: B is false because variation in means does not prevent tightness here; indeed $\\mu^{2}\\le 1$ is part of what ensures uniformly bounded second moments. C is false because allowing $\\sigma^{2}\\to 0$ only concentrates mass and does not harm tightness; the same bound applies even to Dirac measures. D is false because tightness does not require compact support; it requires that most mass lie in some compact set uniformly across the family, which we have shown. E is false because the given constraint is sufficient to establish tightness.", "answer": "$$\\boxed{A}$$", "id": "1458421"}, {"introduction": "After seeing that a uniform moment bound is a sufficient condition for tightness, a natural question arises: is it also a necessary one? This final practice challenges that assumption with a carefully constructed counterexample. You will analyze a sequence of measures that is indeed tight, yet whose first moments are unbounded, revealing a crucial subtlety in the theory of weak convergence [@problem_id:1462684].", "problem": "In measure theory, a family of probability measures $\\{\\mu_{\\alpha}\\}_{\\alpha \\in I}$ on the real line $\\mathbb{R}$ is called **tight** if for every $\\epsilon > 0$, there exists a compact set $K \\subset \\mathbb{R}$ such that $\\mu_{\\alpha}(\\mathbb{R} \\setminus K) \\le \\epsilon$ for all $\\alpha \\in I$. For a probability measure on $\\mathbb{R}$, this is equivalent to the condition that for every $\\epsilon > 0$, there exists a real number $R > 0$ such that $\\mu_{\\alpha}(\\mathbb{R} \\setminus [-R, R]) \\le \\epsilon$ for all $\\alpha \\in I$.\n\nThe first moment of a probability measure $\\mu$ is given by $M_1(\\mu) = \\int_{\\mathbb{R}} |x| d\\mu(x)$.\n\nConsider a sequence of probability measures $\\{\\mu_n\\}_{n \\in \\mathbb{N}}$ on $\\mathbb{R}$ defined by:\n$$ \\mu_n = \\left(1 - \\frac{1}{n^2}\\right)\\delta_0 + \\frac{1}{n^2}\\delta_{n^3} $$\nwhere $n \\ge 1$ is an integer and $\\delta_x$ denotes the Dirac measure concentrated at point $x$. Let $M_1(\\mu_n)$ be the first moment of the measure $\\mu_n$.\n\nWhich of the following statements accurately describes the properties of the sequence $\\{\\mu_n\\}$ and its first moments?\n\nA. The sequence of measures $\\{\\mu_n\\}$ is tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is bounded.\nB. The sequence of measures $\\{\\mu_n\\}$ is not tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is bounded.\nC. The sequence of measures $\\{\\mu_n\\}$ is not tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is unbounded.\nD. The sequence of measures $\\{\\mu_n\\}$ is tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is unbounded.", "solution": "For each $n \\in \\mathbb{N}$, the measure is $\\mu_{n}=\\left(1-\\frac{1}{n^{2}}\\right)\\delta_{0}+\\frac{1}{n^{2}}\\delta_{n^{3}}$. Its first moment is\n$$\nM_{1}(\\mu_{n})=\\int_{\\mathbb{R}}|x|\\,d\\mu_{n}(x)=\\left(1-\\frac{1}{n^{2}}\\right)\\cdot 0+\\frac{1}{n^{2}}\\cdot n^{3}=n,\n$$\nso the sequence $\\{M_{1}(\\mu_{n})\\}$ is unbounded.\n\nTo show tightness of $\\{\\mu_{n}\\}$, fix $\\epsilon>0$. Let $N$ be an integer such that $1/N^2  \\epsilon$. Choose a real number $R \\ge (N-1)^3$. For any $n\\in\\mathbb{N}$:\n- If $n  N$, then $n^3 \\le (N-1)^3 \\le R$. The support of $\\mu_n$ is $\\{0, n^3\\}$, which is contained in $[-R, R]$. Thus, $\\mu_{n}(\\mathbb{R}\\setminus[-R,R])=0$.\n- If $n \\ge N$, then the mass outside any set containing 0 is at most $1/n^2$. Thus, $\\mu_{n}(\\mathbb{R}\\setminus[-R,R]) \\le \\frac{1}{n^2} \\le \\frac{1}{N^2}  \\epsilon$.\n\nIn either case, for a suitably chosen $R$ (dependent on $\\epsilon$), we have $\\mu_{n}(\\mathbb{R}\\setminus[-R,R])  \\epsilon$ for all $n$. This proves tightness.\n\nThus the sequence $\\{\\mu_{n}\\}$ is tight, while $\\{M_{1}(\\mu_{n})\\}$ is unbounded. The correct choice is D.", "answer": "$$\\boxed{D}$$", "id": "1462684"}]}