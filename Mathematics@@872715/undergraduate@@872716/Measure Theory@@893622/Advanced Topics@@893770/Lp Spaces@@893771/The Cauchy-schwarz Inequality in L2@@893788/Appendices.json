{"hands_on_practices": [{"introduction": "The Cauchy-Schwarz inequality is a foundational tool for establishing bounds on integrals that might otherwise be difficult to evaluate directly. This first practice provides a concrete example from signal processing, where we want to determine the maximum possible output of a linear system. By treating the integral as an inner product in $L^2$, you can use the inequality to find a sharp upper bound on the system's output based solely on the energy of the input signal [@problem_id:1449337].", "problem": "Consider a linear time-invariant system whose response to a sharp impulse at time $t=0$ is described by the function $k(t) = e^{-t}$ for $t \\ge 0$. This function is known as the system's impulse response or kernel. When an input signal $f(t)$ is applied to this system for $t \\ge 0$, the total output is measured by the weighted integral $O = \\int_0^\\infty k(t) f(t) \\, dt$.\n\nThe input signal $f(t)$ is restricted to the space of functions with finite energy, denoted by $L^2([0,\\infty))$. The energy of a signal $f(t)$ is defined as the square of its $L^2$-norm, $E = \\|f\\|_2^2 = \\int_0^\\infty |f(t)|^2 \\, dt$.\n\nYour task is to find the sharpest possible upper bound on the magnitude of the output, $|O|$. Specifically, determine the smallest constant $C$ for which the inequality\n$$ \\left| \\int_0^\\infty e^{-t} f(t) \\, dt \\right| \\le C \\|f\\|_2 $$\nholds for every function $f$ in $L^2([0,\\infty))$.\n\nExpress your answer for the constant $C$ as an exact symbolic expression.", "solution": "Let $k(t)=\\exp(-t)$ for $t \\ge 0$. For any $f \\in L^{2}([0,\\infty))$, the output is\n$$\nO=\\int_{0}^{\\infty} k(t) f(t)\\, dt.\n$$\nBy the Cauchy–Schwarz inequality in $L^{2}$,\n$$\n\\left| \\int_{0}^{\\infty} k(t) f(t)\\, dt \\right| \\le \\left( \\int_{0}^{\\infty} |k(t)|^{2}\\, dt \\right)^{\\frac{1}{2}} \\left( \\int_{0}^{\\infty} |f(t)|^{2}\\, dt \\right)^{\\frac{1}{2}} = \\|k\\|_{2}\\, \\|f\\|_{2}.\n$$\nThus any admissible constant $C$ must satisfy $C \\ge \\|k\\|_{2}$. Compute $\\|k\\|_{2}$:\n$$\n\\|k\\|_{2}^{2}=\\int_{0}^{\\infty} \\exp(-2t)\\, dt=\\left[-\\frac{1}{2}\\exp(-2t)\\right]_{0}^{\\infty}=\\frac{1}{2},\n$$\nso\n$$\n\\|k\\|_{2}=\\frac{1}{\\sqrt{2}}.\n$$\nTherefore\n$$\n\\left| \\int_{0}^{\\infty} \\exp(-t) f(t)\\, dt \\right| \\le \\frac{1}{\\sqrt{2}} \\|f\\|_{2}.\n$$\nSharpness follows from the equality condition in Cauchy–Schwarz: taking $f(t)=\\alpha k(t)$ with any nonzero scalar $\\alpha$ yields equality. Hence the smallest constant is $C=\\|k\\|_{2}=\\frac{1}{\\sqrt{2}}$.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{2}}}$$", "id": "1449337"}, {"introduction": "Beyond simply bounding quantities, the geometric structure of $L^2$ spaces allows us to solve optimization problems. A classic example is finding the best approximation of one signal using a scaled version of another. This exercise guides you through minimizing the \"error energy\" between two functions, revealing that the optimal solution corresponds to the geometric concept of orthogonal projection, a direct and powerful consequence of the Hilbert space structure that the Cauchy-Schwarz inequality helps define [@problem_id:1449353].", "problem": "In the field of signal processing, a common task is to approximate a given complex-valued signal $f(t)$ with a scaled version of a simpler, known template signal $g(t)$. This is often done over a specific time interval, say from $t=a$ to $t=b$. The quality of the approximation is measured by the \"energy\" of the error signal, $e(t) = f(t) - c g(t)$, where $c$ is a complex-valued scaling constant.\n\nThe space of these signals is the set of complex-valued, square-integrable functions on the interval $[a, b]$, denoted $L^2([a, b], \\mathbb{C})$. The energy of a signal $h(t)$ in this space is given by the square of its $L^2$-norm, $\\|h\\|_{L^2}^2 = \\int_a^b |h(t)|^2 dt$.\n\nGiven two signals $f(t)$ and $g(t)$ in $L^2([a, b], \\mathbb{C})$, where $g(t)$ is not identically the zero function, find the complex constant $c$ that provides the best approximation of $f(t)$ by $cg(t)$. The best approximation is the one that minimizes the approximation error, which is quantified by minimizing the norm of the difference, $\\|f - c g\\|_{L^2}$.\n\nYour task is to find a general expression for this optimal complex constant $c$ in terms of the functions $f(t)$ and $g(t)$ and the interval endpoints $a$ and $b$. The overbar notation $\\overline{z}$ denotes the complex conjugate of $z$.", "solution": "Let $L^{2}([a,b],\\mathbb{C})$ be equipped with the standard inner product $\\langle u,v\\rangle=\\int_{a}^{b}u(t)\\,\\overline{v(t)}\\,dt$, which is linear in the first argument and conjugate-linear in the second. For a complex scalar $c$, define the squared error functional\n$$\nJ(c)=\\|f-cg\\|_{L^{2}}^{2}=\\langle f-cg,\\,f-cg\\rangle.\n$$\nUsing linearity, conjugate-linearity, and conjugate symmetry $\\langle u,v\\rangle=\\overline{\\langle v,u\\rangle}$, expand $J(c)$ as\n$$\nJ(c)=\\langle f,f\\rangle-c\\,\\langle g,f\\rangle-\\overline{c}\\,\\langle f,g\\rangle+|c|^{2}\\,\\langle g,g\\rangle.\n$$\nTo minimize $J(c)$ over $c\\in\\mathbb{C}$, treat $c$ and $\\overline{c}$ as independent variables (Wirtinger calculus) and set the derivative with respect to $\\overline{c}$ to zero:\n$$\n\\frac{\\partial J}{\\partial\\overline{c}}=-\\langle f,g\\rangle+c\\,\\langle g,g\\rangle=0.\n$$\nSolving for $c$ gives\n$$\nc=\\frac{\\langle f,g\\rangle}{\\langle g,g\\rangle}.\n$$\nSince $g$ is not identically zero in $L^{2}$, one has $\\langle g,g\\rangle=\\int_{a}^{b}|g(t)|^{2}\\,dt0$, so the minimizer is unique. Writing the inner products explicitly,\n$$\nc=\\frac{\\int_{a}^{b}f(t)\\,\\overline{g(t)}\\,dt}{\\int_{a}^{b}|g(t)|^{2}\\,dt}.\n$$\nEquivalently, this $c$ is characterized by the orthogonality condition $\\langle f-cg,\\,g\\rangle=0$, which is the projection of $f$ onto the one-dimensional subspace spanned by $g$.", "answer": "$$\\boxed{\\frac{\\int_{a}^{b}f(t)\\,\\overline{g(t)}\\,dt}{\\int_{a}^{b}|g(t)|^{2}\\,dt}}$$", "id": "1449353"}, {"introduction": "This final practice explores a deeper application of the $L^2$ framework, demonstrating a fundamental relationship between a function and its derivative. The resulting inequality, a version of Wirtinger's inequality, is crucial in fields like the calculus of variations and the study of differential equations, where it's often necessary to control the size of a function by the size of its rate of change. This problem showcases the power of combining the Cauchy-Schwarz inequality's principles with Fourier analysis to derive profound analytical results [@problem_id:1449335].", "problem": "Consider the vector space $H$ of all real-valued, continuously differentiable functions $f: [0, 2\\pi] \\to \\mathbb{R}$ that satisfy two conditions:\n1. The function is periodic on the interval $[0, 2\\pi]$, meaning $f(0) = f(2\\pi)$.\n2. The function has a mean value of zero, i.e., $\\int_0^{2\\pi} f(x) dx = 0$.\n\nFor any function $g$ in the space of square-integrable functions on $[0, 2\\pi]$, its squared $L^2$-norm is defined as $\\|g\\|_{L^2}^2 = \\int_0^{2\\pi} |g(x)|^2 dx$.\n\nThere exists a fundamental relationship between the norm of a function $f \\in H$ and the norm of its derivative $f'$. This relationship can be expressed by an inequality of the form $\\|f\\|_{L^2}^2 \\le C \\|f'\\|_{L^2}^2$, which holds for all non-zero functions $f \\in H$.\n\nDetermine the smallest possible value of the constant $C$ for which this inequality is always true.", "solution": "We use the Fourier series of a real-valued, continuously differentiable, $2\\pi$-periodic, mean-zero function. The mean-zero condition implies the zeroth Fourier coefficient vanishes. Thus $f$ admits the complex Fourier expansion\n$$\nf(x)=\\sum_{n\\in\\mathbb{Z}\\setminus\\{0\\}} c_{n}\\exp(i n x),\n$$\nwith coefficients $c_{n}=\\frac{1}{2\\pi}\\int_{0}^{2\\pi} f(x)\\exp(-i n x)\\,dx$ and $c_{-n}=\\overline{c_{n}}$ because $f$ is real-valued. Differentiating termwise (justified by $C^{1}$-regularity),\n$$\nf'(x)=\\sum_{n\\in\\mathbb{Z}\\setminus\\{0\\}} i n\\,c_{n}\\exp(i n x).\n$$\nBy orthogonality of the exponentials, using $\\int_{0}^{2\\pi} \\exp(i(n-m)x)\\,dx=2\\pi\\,\\delta_{nm}$, Parseval’s identity gives\n$$\n\\|f\\|_{L^{2}}^{2}=\\int_{0}^{2\\pi} |f(x)|^{2}\\,dx=\\int_{0}^{2\\pi}\\Big(\\sum_{n} c_{n}\\exp(i n x)\\Big)\\Big(\\sum_{m} \\overline{c_{m}}\\exp(-i m x)\\Big)\\,dx=2\\pi\\sum_{n\\neq 0} |c_{n}|^{2},\n$$\nand similarly\n$$\n\\|f'\\|_{L^{2}}^{2}=\\int_{0}^{2\\pi} |f'(x)|^{2}\\,dx=2\\pi\\sum_{n\\neq 0} n^{2}|c_{n}|^{2}.\n$$\nFor each $n\\neq 0$ we have $n^{2}\\geq 1$, hence $|c_{n}|^{2}\\leq n^{2}|c_{n}|^{2}$. Summing over $n\\neq 0$ yields\n$$\n\\sum_{n\\neq 0} |c_{n}|^{2}\\leq \\sum_{n\\neq 0} n^{2}|c_{n}|^{2}.\n$$\nMultiplying both sides by $2\\pi$ gives\n$$\n\\|f\\|_{L^{2}}^{2}\\leq \\|f'\\|_{L^{2}}^{2},\n$$\nso the inequality holds with $C=1$.\n\nTo prove optimality, take $f(x)=A\\cos x+B\\sin x$ with constants $A,B\\in\\mathbb{R}$. Then $f$ is $2\\pi$-periodic and has mean zero. Its derivative is $f'(x)=-A\\sin x+B\\cos x$. Orthogonality of $\\sin x$ and $\\cos x$ gives\n$$\n\\|f\\|_{L^{2}}^{2}=\\int_{0}^{2\\pi}\\big(A^{2}\\cos^{2}x+B^{2}\\sin^{2}x\\big)\\,dx=\\pi(A^{2}+B^{2}),\n$$\nand\n$$\n\\|f'\\|_{L^{2}}^{2}=\\int_{0}^{2\\pi}\\big(A^{2}\\sin^{2}x+B^{2}\\cos^{2}x\\big)\\,dx=\\pi(A^{2}+B^{2}).\n$$\nHence $\\|f\\|_{L^{2}}^{2}=\\|f'\\|_{L^{2}}^{2}$, so any $C1$ would violate the inequality for such $f$. Therefore the smallest possible constant is $C=1$.", "answer": "$$\\boxed{1}$$", "id": "1449335"}]}