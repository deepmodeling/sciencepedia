{"hands_on_practices": [{"introduction": "The Gram-Schmidt process is a fundamental constructive tool in linear algebra and functional analysis, allowing us to transform any set of linearly independent vectors into an orthonormal one. This exercise provides direct, hands-on experience with this algorithm in the context of the function space $L^2([0, 1])$, where vectors are functions and the inner product is defined by an integral. Mastering this procedure is essential for building orthonormal bases tailored to specific problems [@problem_id:1850529].", "problem": "Consider the real Hilbert space $L^2([0, 1])$ of square-integrable functions on the interval $[0, 1]$, equipped with the inner product defined as $\\langle f, g \\rangle = \\int_0^1 f(t)g(t) dt$. Let $S = \\{v_1(t), v_2(t), v_3(t)\\}$ be an ordered set of linearly independent functions, where $v_1(t) = 1$, $v_2(t) = t$, and $v_3(t) = t^2$.\n\nBy applying the Gram-Schmidt orthonormalization process to the set $S$ in the given order, a set of orthonormal polynomials $\\{p_0(t), p_1(t), p_2(t)\\}$ is generated.\n\nDetermine the expression for the third polynomial, $p_2(t)$.", "solution": "We work in $L^{2}([0,1])$ with inner product $\\langle f,g\\rangle=\\int_{0}^{1}f(t)g(t)\\,dt$ and apply Gramâ€“Schmidt to $v_{1}(t)=1$, $v_{2}(t)=t$, $v_{3}(t)=t^{2}$.\n\nFirst, set $w_{1}=v_{1}$. Then $\\langle w_{1},w_{1}\\rangle=\\int_{0}^{1}1\\,dt=1$, hence $p_{0}=w_{1}/\\|w_{1}\\|=1$.\n\nNext, compute\n$$\nw_{2}=v_{2}-\\frac{\\langle v_{2},w_{1}\\rangle}{\\langle w_{1},w_{1}\\rangle}w_{1}=t-\\left(\\int_{0}^{1}t\\,dt\\right)\\cdot 1=t-\\frac{1}{2}.\n$$\nIts norm is\n$$\n\\|w_{2}\\|^{2}=\\int_{0}^{1}\\left(t-\\frac{1}{2}\\right)^{2}dt=\\int_{0}^{1}\\left(t^{2}-t+\\frac{1}{4}\\right)dt=\\frac{1}{3}-\\frac{1}{2}+\\frac{1}{4}=\\frac{1}{12},\n$$\nso $p_{1}=w_{2}/\\|w_{2}\\|=2\\sqrt{3}\\left(t-\\frac{1}{2}\\right)$.\n\nFor the third vector,\n$$\nw_{3}=v_{3}-\\frac{\\langle v_{3},w_{1}\\rangle}{\\langle w_{1},w_{1}\\rangle}w_{1}-\\frac{\\langle v_{3},w_{2}\\rangle}{\\langle w_{2},w_{2}\\rangle}w_{2}.\n$$\nCompute the inner products:\n$$\n\\langle v_{3},w_{1}\\rangle=\\int_{0}^{1}t^{2}\\,dt=\\frac{1}{3},\\qquad\n\\langle v_{3},w_{2}\\rangle=\\int_{0}^{1}t^{2}\\left(t-\\frac{1}{2}\\right)dt=\\int_{0}^{1}\\left(t^{3}-\\frac{1}{2}t^{2}\\right)dt=\\frac{1}{4}-\\frac{1}{6}=\\frac{1}{12}.\n$$\nSince $\\langle w_{1},w_{1}\\rangle=1$ and $\\langle w_{2},w_{2}\\rangle=\\frac{1}{12}$, it follows that\n$$\nw_{3}=t^{2}-\\frac{1/3}{1}\\cdot 1-\\frac{1/12}{1/12}\\left(t-\\frac{1}{2}\\right)=t^{2}-\\frac{1}{3}-\\left(t-\\frac{1}{2}\\right)=t^{2}-t+\\frac{1}{6}.\n$$\nNow normalize $w_{3}$. Its norm squared is\n$$\n\\|w_{3}\\|^{2}=\\int_{0}^{1}\\left(t^{2}-t+\\frac{1}{6}\\right)^{2}dt\n=\\int_{0}^{1}\\left(t^{4}-2t^{3}+\\frac{4}{3}t^{2}-\\frac{1}{3}t+\\frac{1}{36}\\right)dt\n=\\frac{1}{5}-\\frac{1}{2}+\\frac{4}{9}-\\frac{1}{6}+\\frac{1}{36}=\\frac{1}{180}.\n$$\nThus $\\|w_{3}\\|=\\sqrt{\\frac{1}{180}}=\\frac{1}{6\\sqrt{5}}$, and the normalized polynomial is\n$$\np_{2}(t)=\\frac{w_{3}(t)}{\\|w_{3}\\|}=6\\sqrt{5}\\left(t^{2}-t+\\frac{1}{6}\\right)=\\sqrt{5}\\left(6t^{2}-6t+1\\right).\n$$", "answer": "$$\\boxed{\\sqrt{5}\\left(6t^{2}-6t+1\\right)}$$", "id": "1850529"}, {"introduction": "An orthonormal system is 'complete' if it is large enough to represent any vector in the space. A key test for completeness is to check if any non-zero vector is orthogonal to every element of the system; if such a vector exists, the system is incomplete. This problem offers a clear and intuitive example of an incomplete system within the familiar space $\\ell^2$, sharpening our understanding of what completeness truly means by demonstrating its absence [@problem_id:1850501].", "problem": "Let $\\ell^2$ be the Hilbert space consisting of all infinite sequences of complex numbers $x = (x_1, x_2, x_3, \\ldots)$ for which the series $\\sum_{n=1}^{\\infty} |x_n|^2$ converges. The inner product for two vectors $x = (x_1, x_2, \\ldots)$ and $y = (y_1, y_2, \\ldots)$ in $\\ell^2$ is defined as $\\langle x, y \\rangle = \\sum_{n=1}^{\\infty} x_n \\overline{y_n}$, where $\\overline{y_n}$ is the complex conjugate of $y_n$.\n\nThe standard basis for $\\ell^2$ is the set of vectors $\\{e_n\\}_{n=1}^{\\infty}$, where for each $n$, the vector $e_n$ is the sequence that has a $1$ in the $n$-th position and $0$s in all other positions. This set is known to be a Complete Orthonormal System (C.O.N.S.) for $\\ell^2$. An orthonormal system is defined as 'complete' if the only vector in the space that is orthogonal to every vector in the system is the zero vector.\n\nNow, consider the subsystem $S_{odd} = \\{e_{2k-1}\\}_{k=1}^{\\infty}$, which is formed by taking only the basis vectors with odd indices (i.e., $e_1, e_3, e_5, \\ldots$).\n\nWhich one of the following non-zero vectors in $\\ell^2$ is orthogonal to every vector in the subsystem $S_{odd}$?\n\nA. $v_A = e_1$\n\nB. $v_B = e_2$\n\nC. $v_C = e_1 + e_3$\n\nD. $v_D = e_1 - e_2$\n\nE. $v_E = \\sum_{n=1}^{\\infty} \\frac{1}{n} e_n$", "solution": "The problem asks us to identify which of the given non-zero vectors is orthogonal to every vector in the set $S_{odd} = \\{e_{2k-1}\\}_{k=1}^{\\infty}$. A vector $v$ is orthogonal to every vector in $S_{odd}$ if its inner product with every vector in $S_{odd}$ is zero. That is, we must have $\\langle v, e_{2k-1} \\rangle = 0$ for all positive integers $k$.\n\nThe standard basis $\\{e_n\\}_{n=1}^{\\infty}$ is an orthonormal system, which means that the inner product of any two basis vectors is given by the Kronecker delta: $\\langle e_m, e_n \\rangle = \\delta_{mn}$, where $\\delta_{mn} = 1$ if $m=n$ and $\\delta_{mn} = 0$ if $m \\neq n$. This property is key to solving the problem.\n\nLet's test each of the given options:\n\n**Option A: $v_A = e_1$**\nWe need to check if $\\langle e_1, e_{2k-1} \\rangle = 0$ for all $k \\ge 1$. Let's test the case where $k=1$. The corresponding vector in $S_{odd}$ is $e_{2(1)-1} = e_1$. The inner product is $\\langle e_1, e_1 \\rangle = 1$. Since this is not equal to zero, $v_A$ is not orthogonal to all vectors in $S_{odd}$.\n\n**Option B: $v_B = e_2$**\nWe need to check if $\\langle e_2, e_{2k-1} \\rangle = 0$ for all $k \\ge 1$. Using the orthonormality property, this inner product is equal to $\\delta_{2, 2k-1}$. For any positive integer $k$, the number $2k-1$ is always an odd number (1, 3, 5, ...). The number 2 is an even number. Therefore, $2 \\neq 2k-1$ for any integer $k \\ge 1$. This implies that the Kronecker delta $\\delta_{2, 2k-1}$ is always 0. So, $\\langle e_2, e_{2k-1} \\rangle = 0$ for all $k \\ge 1$. This means the vector $e_2$ is orthogonal to every vector in the subsystem $S_{odd}$. Since $e_2$ is a non-zero vector, its existence demonstrates that $S_{odd}$ is not a complete system.\n\n**Option C: $v_C = e_1 + e_3$**\nWe check the orthogonality condition. Let's take the first vector in $S_{odd}$, which is $e_1$ (for $k=1$).\n$$ \\langle v_C, e_1 \\rangle = \\langle e_1 + e_3, e_1 \\rangle $$\nUsing the linearity of the inner product in the first argument:\n$$ \\langle e_1, e_1 \\rangle + \\langle e_3, e_1 \\rangle = 1 + 0 = 1 $$\nSince the result is not zero, $v_C$ is not orthogonal to all vectors in $S_{odd}$.\n\n**Option D: $v_D = e_1 - e_2$**\nAgain, let's test against the vector $e_1$ from $S_{odd}$.\n$$ \\langle v_D, e_1 \\rangle = \\langle e_1 - e_2, e_1 \\rangle = \\langle e_1, e_1 \\rangle - \\langle e_2, e_1 \\rangle = 1 - 0 = 1 $$\nThe result is not zero, so $v_D$ is not the correct choice.\n\n**Option E: $v_E = \\sum_{n=1}^{\\infty} \\frac{1}{n} e_n$**\nThis vector is in $\\ell^2$ because the series of squared coefficients $\\sum_{n=1}^{\\infty} |\\frac{1}{n}|^2 = \\sum_{n=1}^{\\infty} \\frac{1}{n^2} = \\frac{\\pi^2}{6}$ converges. We test for orthogonality against $e_1$ (for $k=1$).\n$$ \\langle v_E, e_1 \\rangle = \\left\\langle \\sum_{n=1}^{\\infty} \\frac{1}{n} e_n, e_1 \\right\\rangle $$\nDue to the continuity of the inner product, we can write:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{n} \\langle e_n, e_1 \\rangle = \\sum_{n=1}^{\\infty} \\frac{1}{n} \\delta_{n1} $$\nThis sum has only one non-zero term, which occurs when $n=1$. The value is $\\frac{1}{1} \\delta_{11} = 1$. Since the inner product is not zero, $v_E$ is not orthogonal to all vectors in $S_{odd}$.\n\nBased on the analysis of all options, only $v_B = e_2$ is orthogonal to every vector in the subsystem $S_{odd}$.", "answer": "$$\\boxed{B}$$", "id": "1850501"}, {"introduction": "Parseval's identity is a cornerstone result for complete orthonormal systems, equating the squared norm of a vector to the sum of the squared magnitudes of its Fourier coefficients. This practice challenges us to see what happens when we relax the 'normal' condition and work with a system that is merely orthogonal. By deriving the generalized form of Parseval's identity, we gain a deeper appreciation for the role normalization plays in this fundamental theorem [@problem_id:1850519].", "problem": "Let $H$ be a complex Hilbert space with an inner product denoted by $\\langle \\cdot, \\cdot \\rangle$ and its induced norm by $\\|x\\| = \\sqrt{\\langle x, x \\rangle}$. Consider a set of non-zero vectors $\\{v_n\\}_{n=1}^{\\infty}$ that forms a complete orthogonal system in $H$. This means that for any two distinct indices $n$ and $m$, $\\langle v_n, v_m \\rangle = 0$, and for any vector $x \\in H$, the vector $x$ can be represented as the series $x = \\sum_{n=1}^{\\infty} c_n v_n$ for some complex coefficients $c_n$. Note that the system is not necessarily orthonormal, so $\\|v_n\\|$ is not necessarily equal to 1.\n\nFor an arbitrary vector $x \\in H$, which of the following expressions correctly represents the squared norm, $\\|x\\|^2$?\n\nA. $\\sum_{n=1}^{\\infty} \\frac{|\\langle x, v_n \\rangle|^2}{\\|v_n\\|^2}$\n\nB. $\\sum_{n=1}^{\\infty} \\frac{|\\langle x, v_n \\rangle|^2}{\\|v_n\\|^4}$\n\nC. $\\sum_{n=1}^{\\infty} |\\langle x, v_n \\rangle|^2$\n\nD. $\\sum_{n=1}^{\\infty} |\\langle x, v_n \\rangle|^2 \\|v_n\\|^2$\n\nE. $\\sum_{n=1}^{\\infty} \\frac{\\langle x, v_n \\rangle^2}{\\|v_n\\|^2}$", "solution": "Let $\\{v_{n}\\}_{n=1}^{\\infty}$ be an orthogonal and complete system of nonzero vectors in a complex Hilbert space $H$, and let $x \\in H$. By completeness, there exist coefficients $c_{n} \\in \\mathbb{C}$ such that the series converges in $H$:\n$$\nx=\\sum_{n=1}^{\\infty} c_{n} v_{n}.\n$$\nFor the partial sums $s_{N}=\\sum_{n=1}^{N} c_{n} v_{n}$, orthogonality gives\n$$\n\\|s_{N}\\|^{2}=\\left\\langle \\sum_{n=1}^{N} c_{n} v_{n}, \\sum_{m=1}^{N} c_{m} v_{m}\\right\\rangle=\\sum_{n=1}^{N}\\sum_{m=1}^{N} c_{n}\\overline{c_{m}}\\langle v_{n},v_{m}\\rangle=\\sum_{n=1}^{N} |c_{n}|^{2}\\|v_{n}\\|^{2}.\n$$\nSince $s_{N} \\to x$ in norm, the continuity of the norm implies\n$$\n\\|x\\|^{2}=\\lim_{N\\to\\infty}\\|s_{N}\\|^{2}=\\sum_{n=1}^{\\infty} |c_{n}|^{2}\\|v_{n}\\|^{2}.\n$$\nNext, we relate $c_{n}$ to inner products. Using orthogonality (and assuming linearity in the first argument):\n$$\n\\langle x,v_{k}\\rangle=\\left\\langle \\sum_{n=1}^{\\infty} c_{n} v_{n}, v_k \\right\\rangle = \\sum_{n=1}^{\\infty} c_{n} \\langle v_n, v_k \\rangle = c_{k}\\langle v_{k},v_{k}\\rangle = c_k \\|v_k\\|^2.\n$$\nThis gives $c_{k}=\\frac{\\langle x,v_{k}\\rangle}{\\|v_{k}\\|^{2}}$. Substituting this into the norm identity gives:\n$$\n\\|x\\|^{2}=\\sum_{n=1}^{\\infty} |c_{n}|^{2}\\|v_{n}\\|^{2}=\\sum_{n=1}^{\\infty} \\left|\\frac{\\langle x,v_{n}\\rangle}{\\|v_{n}\\|^{2}}\\right|^{2} \\|v_n\\|^2 = \\sum_{n=1}^{\\infty} \\frac{|\\langle x,v_{n}\\rangle|^{2}}{\\|v_{n}\\|^{4}} \\|v_n\\|^2 = \\sum_{n=1}^{\\infty} \\frac{|\\langle x,v_{n}\\rangle|^{2}}{\\|v_{n}\\|^{2}}.\n$$\nTherefore the correct choice is A. Options C and D correspond to the orthonormal case (C) or incorrect scaling (D), B has an extra factor of $\\|v_{n}\\|^{2}$ in the denominator, and E omits the modulus, which is invalid in the complex setting.", "answer": "$$\\boxed{A}$$", "id": "1850519"}]}