{"hands_on_practices": [{"introduction": "We begin our exploration with a situation where completeness is guaranteed: a finite-dimensional vector space. The space of polynomials of degree at most 2, denoted $P_2[0, 1]$, is a subspace of $C[0, 1]$ with a fixed dimension. In this exercise [@problem_id:1850957], you will see that a Cauchy sequence of such polynomials converges to another polynomial of at most degree 2, illustrating the important theorem that all finite-dimensional normed spaces are complete.", "problem": "Consider the vector space $C[0, 1]$ which consists of all continuous real-valued functions defined on the interval $[0, 1]$. This space is equipped with the supremum norm, defined as $\\|f\\|_{\\infty} = \\sup_{x \\in [0, 1]} |f(x)|$, which makes it a complete normed vector space (a Banach space). Let $P_2[0, 1]$ be the subspace of $C[0, 1]$ that contains all polynomials of degree at most 2.\n\nA sequence of polynomials $\\{p_k\\}_{k=1}^{\\infty}$ in $P_2[0, 1]$ is defined by $p_k(x) = a_k x^2 + b_k x + c_k$. The coefficients for each polynomial in the sequence are given by the following real sequences:\n$$ a_k = 4 \\left(1 - \\frac{1}{3^k}\\right) $$\n$$ b_k = \\frac{k^2 - k + 1}{2k^2 + 3} $$\n$$ c_k = \\sum_{j=0}^{k} \\frac{(-1)^j}{2^j} $$\nIt is given that this sequence of polynomials $\\{p_k\\}$ converges in the norm of $C[0, 1]$ to a limit function $p(x)$. Determine the explicit form of this limit function $p(x)$.", "solution": "We are given $p_{k}(x)=a_{k}x^{2}+b_{k}x+c_{k}$ with\n$$\na_{k}=4\\left(1-\\frac{1}{3^{k}}\\right),\\quad b_{k}=\\frac{k^{2}-k+1}{2k^{2}+3},\\quad c_{k}=\\sum_{j=0}^{k}\\frac{(-1)^{j}}{2^{j}}.\n$$\nTo find the limit $p(x)$ in the supremum norm on $[0,1]$, it suffices to compute the limits of the coefficients and then verify uniform convergence. Define\n$$\na=\\lim_{k\\to\\infty}a_{k},\\quad b=\\lim_{k\\to\\infty}b_{k},\\quad c=\\lim_{k\\to\\infty}c_{k}.\n$$\n\nFirst, since $\\lim_{k\\to\\infty}3^{-k}=0$, we have\n$$\na=\\lim_{k\\to\\infty}4\\left(1-\\frac{1}{3^{k}}\\right)=4.\n$$\n\nNext, for $b_{k}$, divide numerator and denominator by $k^{2}$ to obtain\n$$\nb=\\lim_{k\\to\\infty}\\frac{k^{2}-k+1}{2k^{2}+3}=\\lim_{k\\to\\infty}\\frac{1-\\frac{1}{k}+\\frac{1}{k^{2}}}{2+\\frac{3}{k^{2}}}=\\frac{1}{2}.\n$$\n\nFor $c_{k}$, recognize a geometric series with first term $1$ and ratio $r=-\\frac{1}{2}$. The partial sum is\n$$\nc_{k}=\\frac{1-(-\\frac{1}{2})^{k+1}}{1-(-\\frac{1}{2})}=\\frac{1-(-\\frac{1}{2})^{k+1}}{\\frac{3}{2}}=\\frac{2}{3}\\left(1-(-\\tfrac{1}{2})^{k+1}\\right),\n$$\nso\n$$\nc=\\lim_{k\\to\\infty}c_{k}=\\frac{2}{3}.\n$$\n\nDefine $p(x)=ax^{2}+bx+c=4x^{2}+\\frac{1}{2}x+\\frac{2}{3}$. To verify convergence in the supremum norm, for any $x\\in[0,1]$,\n$$\n|p_{k}(x)-p(x)|=\\left|(a_{k}-a)x^{2}+(b_{k}-b)x+(c_{k}-c)\\right|\\leq |a_{k}-a|+|b_{k}-b|+|c_{k}-c|.\n$$\nTaking the supremum over $x\\in[0,1]$,\n$$\n\\|p_{k}-p\\|_{\\infty}\\leq |a_{k}-a|+|b_{k}-b|+|c_{k}-c|\\to 0 \\quad \\text{as } k\\to\\infty.\n$$\nThus $p_{k}\\to p$ in $C[0,1]$, and the limit function is\n$$\np(x)=4x^{2}+\\frac{1}{2}x+\\frac{2}{3}.\n$$", "answer": "$$\\boxed{4x^{2}+\\frac{1}{2}x+\\frac{2}{3}}$$", "id": "1850957"}, {"introduction": "Having seen the stability of finite-dimensional subspaces, we now ask what happens when the degree of the polynomials is not bounded. The space of all polynomials, $P[-1, 1]$, is an infinite-dimensional subspace of $C[-1, 1]$. This foundational practice [@problem_id:1850999] uses a sequence of polynomials, derived from a binomial expansion, to construct a uniform limit that is continuous but not a polynomial, thereby proving that $P[-1, 1]$ is not a complete space.", "problem": "Let $C[-1, 1]$ denote the vector space of all continuous real-valued functions defined on the closed interval $[-1, 1]$. This space is equipped with the supremum norm, defined for any function $g \\in C[-1, 1]$ as $\\|g\\|_{\\infty} = \\sup_{x \\in [-1, 1]} |g(x)|$.\n\nConsider the sequence of functions $\\{p_N(x)\\}_{N=0}^{\\infty}$ defined for $x \\in [-1, 1]$ by the formula:\n$$p_N(x) = \\sum_{n=0}^{N} \\binom{1/2}{n} (-1)^n (1-x^2)^n$$\nwhere $\\binom{r}{n} = \\frac{r(r-1)\\cdots(r-n+1)}{n!}$ for $n \\ge 1$ and $\\binom{r}{0} = 1$ is the generalized binomial coefficient.\n\nEach function $p_N(x)$ in the sequence is a polynomial in the variable $x$. It is given that this sequence converges with respect to the supremum norm to a limit function $f(x)$ in the space $C[-1, 1]$. Determine the explicit functional form of $f(x)$.", "solution": "We first rewrite the defining polynomial as\n$$\np_{N}(x)=\\sum_{n=0}^{N}\\binom{1/2}{n}(-1)^{n}(1-x^{2})^{n}=\\sum_{n=0}^{N}\\binom{1/2}{n}(x^{2}-1)^{n}.\n$$\nRecall the generalized binomial theorem: for any real $r$ and any $y$ with $|y|<1$,\n$$\n(1+y)^{r}=\\sum_{n=0}^{\\infty}\\binom{r}{n}y^{n}.\n$$\nApplying this with $r=\\frac{1}{2}$ and $y=x^{2}-1$, for each fixed $x$ with $|x|<1$ (so that $x^{2}-1\\in(-1,0)$ and hence $|y|<1$), the infinite series satisfies\n$$\n\\sum_{n=0}^{\\infty}\\binom{1/2}{n}(x^{2}-1)^{n}=(1+(x^{2}-1))^{1/2}=(x^{2})^{1/2}=|x|.\n$$\nTherefore, for every $x$ with $|x|<1$, the pointwise limit of the partial sums is\n$$\n\\lim_{N\\to\\infty}p_{N}(x)=|x|.\n$$\nAt the endpoints $x=\\pm 1$ we have\n$$\np_{N}(\\pm 1)=\\sum_{n=0}^{N}\\binom{1/2}{n}(\\pm 1)^{2n-2n}0^{n}=1,\n$$\nbecause the term with $n=0$ equals $1$ and every term with $n\\ge 1$ contains the factor $0^{n}=0$. Hence\n$$\n\\lim_{N\\to\\infty}p_{N}(\\pm 1)=1=|\\pm 1|.\n$$\nBy the hypothesis, $p_{N}\\to f$ in the supremum norm on $[-1,1]$, so the convergence is uniform and the limit $f$ is continuous on $[-1,1]$. Since $p_{N}(x)\\to |x|$ for all $x$ with $|x|<1$ and also at $x=\\pm 1$, and $|x|$ is continuous on $[-1,1]$, it follows by uniqueness of the uniform limit that\n$$\nf(x)=|x| \\quad \\text{for all } x\\in[-1,1].\n$$", "answer": "$$\\boxed{|x|}$$", "id": "1850999"}, {"introduction": "The incompleteness we observed is not unique to the space of polynomials. Consider the space of continuously differentiable functions, $C^1[-1, 1]$, another vital subspace of $C[-1, 1]$. This exercise [@problem_id:1850985] presents a sequence of smooth functions that converges to a limit function which is not differentiable everywhere, demonstrating that $C^1[-1, 1]$ is also incomplete under the supremum norm.", "problem": "Consider the space of continuously differentiable functions on the interval $[-1, 1]$, denoted by $C^1[-1, 1]$. For each positive integer $n$, define a function $f_n: [-1, 1] \\to \\mathbb{R}$ by the rule:\n$$f_n(t) = \\frac{1}{n} \\ln(\\cosh(nt))$$\nEach function $f_n(t)$ is an element of $C^1[-1, 1]$. It is given that the sequence of functions $\\{f_n\\}_{n=1}^\\infty$ converges uniformly on $[-1, 1]$ to a limit function $f(t)$.\n\nLet the limit function be $f(t) = \\lim_{n\\to\\infty} f_n(t)$. Your task is to analyze the differentiability of this limit function at the origin. Specifically, calculate the value of the following expression:\n$$L = \\lim_{h \\to 0^+} \\frac{f(h) - f(0)}{h} - \\lim_{h \\to 0^-} \\frac{f(h) - f(0)}{h}$$", "solution": "The problem asks for the evaluation of a specific expression involving the limit function $f(t)$ of the sequence $f_n(t) = \\frac{1}{n} \\ln(\\cosh(nt))$.\n\nFirst, we must determine the limit function $f(t) = \\lim_{n\\to\\infty} f_n(t)$. We can analyze this limit by considering three cases for the value of $t \\in [-1, 1]$.\n\nCase 1: $t > 0$.\nWe use the definition of the hyperbolic cosine, $\\cosh(x) = \\frac{e^x + e^{-x}}{2}$.\n$$f_n(t) = \\frac{1}{n} \\ln\\left(\\frac{e^{nt} + e^{-nt}}{2}\\right)$$\nWe can factor out the dominant term, $e^{nt}$, from the argument of the logarithm:\n$$f_n(t) = \\frac{1}{n} \\ln\\left(\\frac{e^{nt}(1 + e^{-2nt})}{2}\\right)$$\nUsing the properties of logarithms, $\\ln(ab) = \\ln(a) + \\ln(b)$ and $\\ln(a/b) = \\ln(a) - \\ln(b)$:\n$$f_n(t) = \\frac{1}{n} \\left[ \\ln(e^{nt}) + \\ln(1 + e^{-2nt}) - \\ln(2) \\right]$$\n$$f_n(t) = \\frac{1}{n} \\left[ nt + \\ln(1 + e^{-2nt}) - \\ln(2) \\right]$$\n$$f_n(t) = t + \\frac{\\ln(1 + e^{-2nt})}{n} - \\frac{\\ln(2)}{n}$$\nNow, we take the limit as $n \\to \\infty$. Since $t > 0$, the term $e^{-2nt}$ approaches 0.\n$$\\lim_{n\\to\\infty} f_n(t) = \\lim_{n\\to\\infty} \\left( t + \\frac{\\ln(1 + e^{-2nt})}{n} - \\frac{\\ln(2)}{n} \\right)$$\n$$f(t) = t + 0 - 0 = t$$\n\nCase 2: $t < 0$.\nLet $t = -s$ where $s > 0$. Since $\\cosh(x)$ is an even function, $\\cosh(nt) = \\cosh(-ns) = \\cosh(ns)$.\nThe calculation proceeds exactly as in Case 1, with $s$ in place of $t$.\n$$f_n(t) = f_n(-s) = \\frac{1}{n} \\ln(\\cosh(ns))$$\nFrom the result of Case 1, we know that $\\lim_{n\\to\\infty} \\frac{1}{n} \\ln(\\cosh(ns)) = s$.\nSubstituting back $s = -t$, we get:\n$$f(t) = s = -t$$\n\nCase 3: $t = 0$.\n$$f_n(0) = \\frac{1}{n} \\ln(\\cosh(0)) = \\frac{1}{n} \\ln(1) = 0$$\nThus, $f(0) = \\lim_{n\\to\\infty} 0 = 0$.\n\nCombining all three cases, the limit function is:\n$$f(t) = \\begin{cases} t & \\text{if } t > 0 \\\\ 0 & \\text{if } t = 0 \\\\ -t & \\text{if } t < 0 \\end{cases}$$\nThis is the absolute value function, $f(t) = |t|$.\n\nNow we must evaluate the expression $L = \\lim_{h \\to 0^+} \\frac{f(h) - f(0)}{h} - \\lim_{h \\to 0^-} \\frac{f(h) - f(0)}{h}$.\nThis expression is the difference between the right-hand derivative and the left-hand derivative of $f(t)$ at $t=0$.\n\nLet's calculate the first term, which is the right-hand derivative $f'_+(0)$:\n$$\\lim_{h \\to 0^+} \\frac{f(h) - f(0)}{h} = \\lim_{h \\to 0^+} \\frac{|h| - |0|}{h}$$\nSince $h \\to 0^+$, $h$ is positive, so $|h|=h$.\n$$\\lim_{h \\to 0^+} \\frac{h - 0}{h} = \\lim_{h \\to 0^+} \\frac{h}{h} = \\lim_{h \\to 0^+} 1 = 1$$\n\nNext, let's calculate the second term, which is the left-hand derivative $f'_{-}(0)$:\n$$\\lim_{h \\to 0^-} \\frac{f(h) - f(0)}{h} = \\lim_{h \\to 0^-} \\frac{|h| - |0|}{h}$$\nSince $h \\to 0^-$, $h$ is negative, so $|h|=-h$.\n$$\\lim_{h \\to 0^-} \\frac{-h - 0}{h} = \\lim_{h \\to 0^-} \\frac{-h}{h} = \\lim_{h \\to 0^-} -1 = -1$$\n\nFinally, we compute the value of $L$:\n$$L = (\\text{right-hand derivative}) - (\\text{left-hand derivative}) = 1 - (-1) = 2$$\nThe value of the expression is 2. This result demonstrates that the right-hand and left-hand derivatives at $t=0$ are not equal, which confirms that the limit function $f(t)=|t|$ is not differentiable at $t=0$.", "answer": "$$\\boxed{2}$$", "id": "1850985"}]}