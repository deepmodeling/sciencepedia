{"hands_on_practices": [{"introduction": "A foundational step in studying any collection of mathematical objects is to understand how they interact under basic algebraic operations. This exercise explores the behavior of finite-rank operators under addition, establishing a fundamental upper bound on the rank of a sum of two such operators. By working through this problem, you will confirm that the set of finite-rank operators forms a vector subspace within the larger space of all linear operators, a key structural property that underpins much of their theory [@problem_id:1849832].", "problem": "Let $V$ and $W$ be vector spaces over a field $\\mathbb{F}$. A linear operator is a function $L: V \\to W$ such that $L(c\\mathbf{u} + \\mathbf{v}) = cL(\\mathbf{u}) + L(\\mathbf{v})$ for all vectors $\\mathbf{u}, \\mathbf{v} \\in V$ and all scalars $c \\in \\mathbb{F}$. The image of an operator $L$, denoted $\\text{Im}(L)$, is the set of all possible output vectors, i.e., $\\text{Im}(L) = \\{L(\\mathbf{v}) \\mid \\mathbf{v} \\in V\\}$. The rank of an operator $L$, denoted $\\text{rank}(L)$, is defined as the dimension of its image, i.e., $\\text{rank}(L) = \\dim(\\text{Im}(L))$.\n\nConsider two linear operators, $S: V \\to W$ and $T: V \\to W$. Suppose that $\\text{rank}(S) = n$ and $\\text{rank}(T) = m$, where $n$ and $m$ are finite non-negative integers. Let their sum be the operator $(S+T): V \\to W$ defined by $(S+T)(\\mathbf{v}) = S(\\mathbf{v}) + T(\\mathbf{v})$ for all $\\mathbf{v} \\in V$.\n\nWhich of the following expressions represents the tightest possible upper bound on the rank of the sum, $\\text{rank}(S+T)$, that holds true for any such operators $S$ and $T$?\n\nA. $n+m$\n\nB. $nm$\n\nC. $\\max(n,m)$\n\nD. $|n-m|$\n\nE. $\\min(n,m)$", "solution": "By linearity, for every $v \\in V$,\n$$(S+T)(v) = S(v) + T(v) \\in \\operatorname{Im}(S) + \\operatorname{Im}(T).$$\nHence\n$$\\operatorname{Im}(S+T) \\subseteq \\operatorname{Im}(S) + \\operatorname{Im}(T).$$\nTaking dimensions and using the inequality for subspaces $U,V \\subseteq W$,\n$$\\dim(U+V) = \\dim(U) + \\dim(V) - \\dim(U \\cap V) \\leq \\dim(U) + \\dim(V),$$\nwe obtain\n$$\\operatorname{rank}(S+T) = \\dim(\\operatorname{Im}(S+T)) \\leq \\dim(\\operatorname{Im}(S) + \\operatorname{Im}(T)) \\leq \\dim(\\operatorname{Im}(S)) + \\dim(\\operatorname{Im}(T)) = n + m.$$\nThus $\\operatorname{rank}(S+T) \\leq n + m$ always holds.\n\nTo show this bound is tight, take $W=V$ and decompose $V$ as a direct sum $V = A \\oplus B$ with $\\dim(A) = n$ and $\\dim(B) = m$. Define $S: V \\to V$ and $T: V \\to V$ by projections\n$$S(a+b) = a, \\quad T(a+b) = b \\quad \\text{for } a \\in A,\\, b \\in B.$$\nThen $\\operatorname{rank}(S) = n$, $\\operatorname{rank}(T) = m$, and\n$$(S+T)(a+b) = a+b,$$\nso $S+T$ is the identity on $V$ and\n$$\\operatorname{rank}(S+T) = \\dim(V) = n + m.$$\nTherefore the upper bound $n+m$ is attained and hence is the tightest possible among the given options. The other proposed bounds can be violated (for example, when $n=m=1$, one can achieve $\\operatorname{rank}(S+T)=2$, contradicting options C, D, E, and B), so the correct tight universal upper bound is $n+m$.", "answer": "$$\\boxed{A}$$", "id": "1849832"}, {"introduction": "Finite-rank operators are constructed from simpler, rank-one operators, which serve as their essential building blocks. This practice invites you to analyze the spectral properties—the eigenvalues and eigenvectors—of a canonical rank-one operator, $T(x) = \\langle x, u \\rangle u$. Mastering the structure of this operator is a crucial step towards understanding the spectral theory of more general compact and self-adjoint operators, as it provides a clear and manageable model of their behavior [@problem_id:1849806].", "problem": "In the mathematical formalism of functional analysis, operators on Hilbert spaces are fundamental. A simple yet important class of operators are the finite-rank operators. Consider a complex Hilbert space $H$ with an inner product denoted by $\\langle \\cdot, \\cdot \\rangle$ and the induced norm $\\|v\\| = \\sqrt{\\langle v, v \\rangle}$.\n\nLet $u$ be a fixed, non-zero vector in $H$. We define a rank-one linear operator $T: H \\to H$ by the rule:\n$$T(x) = \\langle x, u \\rangle u$$\nfor any vector $x \\in H$. This type of operator appears in various contexts, including the approximation of compact operators and in models of quantum measurement.\n\nThe eigenvectors of $T$ are the non-zero vectors $x$ that are transformed into scalar multiples of themselves, i.e., $T(x) = \\lambda x$ for some scalar eigenvalue $\\lambda$. It can be shown that the operator $T$ has exactly one non-zero eigenvalue. Your task is to find this unique non-zero eigenvalue and to characterize its corresponding eigenspace.\n\nWhich of the following pairs correctly identifies the non-zero eigenvalue $\\lambda$ and its associated eigenspace $E_{\\lambda}$?\n\nA. $\\lambda = 1$; $E_{\\lambda}$ is the set of all vectors orthogonal to $u$.\n\nB. $\\lambda = \\|u\\|$; $E_{\\lambda}$ is the set of all scalar multiples of $u$.\n\nC. $\\lambda = \\|u\\|^2$; $E_{\\lambda}$ is the set of all vectors orthogonal to $u$.\n\nD. $\\lambda = \\|u\\|^2$; $E_{\\lambda}$ is the set of all scalar multiples of $u$.\n\nE. $\\lambda = \\langle u,u \\rangle^2$; $E_{\\lambda}$ is the set of all scalar multiples of $u$.", "solution": "We adopt the standard functional analysis convention that the inner product on a complex Hilbert space is linear in its first argument and conjugate-linear in its second. With this convention, the map $T:H\\to H$ defined by $T(x)=\\langle x,u\\rangle u$ is linear.\n\nWe seek all non-zero $x\\in H$ and scalars $\\lambda\\in\\mathbb{C}$ such that\n$$\nT(x)=\\lambda x \\quad\\Longleftrightarrow\\quad \\langle x,u\\rangle u=\\lambda x.\n$$\nFirst, observe that for every $x\\in H$, $T(x)$ lies in the one-dimensional subspace $\\operatorname{span}\\{u\\}$. Therefore, if $\\lambda\\neq 0$ and $T(x)=\\lambda x$, the right-hand side $\\lambda x$ must also lie in $\\operatorname{span}\\{u\\}$, which implies $x\\in\\operatorname{span}\\{u\\}$.\n\nThus any eigenvector corresponding to a non-zero eigenvalue must be a scalar multiple of $u$. Let $x=cu$ with $c\\in\\mathbb{C}$ and $c\\neq 0$. Then\n$$\nT(x)=T(cu)=\\langle cu,u\\rangle u=c\\langle u,u\\rangle u.\n$$\nThe eigenvalue equation $T(x)=\\lambda x$ becomes\n$$\nc\\langle u,u\\rangle u=\\lambda(cu).\n$$\nSince $c\\neq 0$ and $u\\neq 0$, we can cancel $c u$ to obtain\n$$\n\\lambda=\\langle u,u\\rangle=\\|u\\|^{2}.\n$$\nHence the unique non-zero eigenvalue is $\\|u\\|^{2}$, and its eigenspace is precisely\n$$\nE_{\\|u\\|^{2}}=\\operatorname{span}\\{u\\}=\\{cu:\\,c\\in\\mathbb{C}\\}.\n$$\nFor completeness, note that if $x\\perp u$, then $\\langle x,u\\rangle=0$ and $T(x)=0$, so such $x$ are eigenvectors for the eigenvalue $0$, not for the non-zero eigenvalue.\n\nTherefore, the correct choice is the pair with $\\lambda=\\|u\\|^{2}$ and eigenspace equal to all scalar multiples of $u$, which corresponds to option D.", "answer": "$$\\boxed{D}$$", "id": "1849806"}, {"introduction": "The abstract theory of finite-rank operators finds concrete and powerful applications in the study of integral equations, a cornerstone of applied mathematics and physics. This problem bridges the gap between abstract definitions and practical examples by focusing on an integral operator on the function space $L^2([0,1])$. You will discover how operators with a \"separable\" or \"degenerate\" kernel are inherently of finite rank and uncover the elegant connection between the operator's rank and the algebraic properties of its kernel representation [@problem_id:1849822].", "problem": "Consider the Hilbert space $H = L^2([0,1])$ of square-integrable complex-valued functions on the interval $[0,1]$, equipped with the standard inner product $\\langle f, g \\rangle = \\int_0^1 f(t) \\overline{g(t)} dt$. Let $T: H \\to H$ be an integral operator defined by\n$$ (Tx)(t) = \\int_0^1 K(t,s) x(s) \\, ds $$\nwhere the kernel $K(t,s)$ is a polynomial in the variables $t$ and $s$ given by\n$$ K(t,s) = \\sum_{i=0}^{N} \\sum_{j=0}^{M} c_{ij} t^i s^j $$\nHere, $N$ and $M$ are non-negative integers, and the coefficients $c_{ij}$ are real constants. These coefficients form an $(N+1) \\times (M+1)$ matrix $C$ where the entry in the $i$-th row and $j$-th column is $c_{ij}$ (with indices $i$ from $0$ to $N$ and $j$ from $0$ to $M$). The rank of the operator $T$ is defined as the dimension of its range, $\\mathrm{dim}(\\mathrm{ran}(T))$.\n\nWhich of the following statements correctly describes the rank of the operator $T$?\n\nA. The rank of $T$ is always $(N+1)(M+1)$.\n\nB. The rank of $T$ is always $\\min(N+1, M+1)$.\n\nC. The rank of $T$ is equal to the rank of the matrix $C$.\n\nD. The rank of $T$ is equal to $N+M+2$.\n\nE. The rank of $T$ could be infinite if the matrix $C$ is chosen appropriately.", "solution": "Let $H=L^{2}([0,1])$ and let $T:H\\to H$ be given by\n$$\n(Tx)(t)=\\int_{0}^{1}K(t,s)x(s)\\,ds,\\quad K(t,s)=\\sum_{i=0}^{N}\\sum_{j=0}^{M}c_{ij}t^{i}s^{j}.\n$$\nFor any $x\\in H$, write the moments\n$$\nm_{j}(x)=\\int_{0}^{1}s^{j}x(s)\\,ds,\\quad j=0,\\dots,M.\n$$\nThen\n$$\n(Tx)(t)=\\sum_{i=0}^{N}\\sum_{j=0}^{M}c_{ij}t^{i}m_{j}(x)=\\sum_{i=0}^{N}\\Big(\\sum_{j=0}^{M}c_{ij}m_{j}(x)\\Big)t^{i}.\n$$\nHence $\\mathrm{ran}(T)\\subseteq\\mathrm{span}\\{1,t,\\dots,t^{N}\\}$, so $T$ has finite rank and, in particular, cannot have infinite rank.\n\nDefine linear maps\n$$\n\\Phi:H\\to\\mathbb{C}^{M+1},\\quad \\Phi(x)=(m_{0}(x),\\dots,m_{M}(x)),\n$$\n$$\nU:\\mathbb{C}^{N+1}\\to H,\\quad U(b_{0},\\dots,b_{N})=\\sum_{i=0}^{N}b_{i}t^{i},\n$$\nand view the coefficient matrix $C=(c_{ij})$ as a linear map $C:\\mathbb{C}^{M+1}\\to\\mathbb{C}^{N+1}$. Then\n$$\nT=U\\circ C\\circ\\Phi.\n$$\nWe claim that $\\Phi$ is surjective. Restrict $\\Phi$ to the finite-dimensional subspace $P_{M}=\\mathrm{span}\\{1,s,\\dots,s^{M}\\}\\subset H$. Relative to the basis $\\{s^{k}\\}_{k=0}^{M}$ of $P_{M}$ and the standard basis of $\\mathbb{C}^{M+1}$, the matrix of $\\Phi|_{P_{M}}$ is the Gram (Hilbert) matrix\n$$\nG_{jk}=\\int_{0}^{1}s^{j+k}\\,ds,\\quad j,k=0,\\dots,M.\n$$\nSince $\\{s^{k}\\}_{k=0}^{M}$ are linearly independent in $H$, this Gram matrix is positive definite and thus invertible. Therefore $\\Phi|_{P_{M}}:P_{M}\\to\\mathbb{C}^{M+1}$ is an isomorphism, which implies $\\Phi(H)=\\mathbb{C}^{M+1}$.\n\nIt follows that\n$$\n\\mathrm{Im}(C\\circ\\Phi)=\\mathrm{Im}(C),\n$$\nand hence\n$$\n\\mathrm{ran}(T)=U(\\mathrm{Im}(C)).\n$$\nThe map $U$ is injective: if $U(b)=0$ in $H$, then the polynomial $\\sum_{i=0}^{N}b_{i}t^{i}$ vanishes almost everywhere on $[0,1]$, hence is identically zero, so all $b_{i}=0$. Therefore $U$ preserves dimensions of subspaces of $\\mathbb{C}^{N+1}$, and we obtain\n$$\n\\mathrm{dim}(\\mathrm{ran}(T))=\\mathrm{dim}(\\mathrm{Im}(C))=\\mathrm{rank}(C).\n$$\nThus the rank of $T$ is equal to the rank of the matrix $C$. Consequently, among the given options, only statement C is correct; in particular, the rank is finite and bounded by $\\min(N+1,M+1)$, so none of A, B, D, or E holds in general.", "answer": "$$\\boxed{C}$$", "id": "1849822"}]}