{"hands_on_practices": [{"introduction": "Before venturing into infinite dimensions, it is crucial to ground our understanding in the familiar territory of linear algebra. The Spectral Theorem for compact self-adjoint operators is a powerful generalization of the fact that Hermitian matrices are diagonalizable. This exercise [@problem_id:590644] provides a concrete warm-up by asking you to find the eigenvalues of a simple $2 \\times 2$ self-adjoint operator, reinforcing this fundamental connection.", "problem": "Consider the compact self-adjoint operator $A$ acting on the Hilbert space $\\mathbb{C}^2$ defined by the matrix representation:\n\n$$\nA = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}.\n$$\n\nFind the eigenvalues of $A$.", "solution": "To find the eigenvalues of $A$, solve the characteristic equation $\\det(A - \\lambda I) = 0$, where $I$ is the $2 \\times 2$ identity matrix. The matrix $A - \\lambda I$ is:\n\n$$\nA - \\lambda I = \\begin{pmatrix} 2 - \\lambda & 1 \\\\ 1 & 2 - \\lambda \\end{pmatrix}.\n$$\n\nThe determinant is:\n\n$$\n\\det(A - \\lambda I) = (2 - \\lambda)(2 - \\lambda) - (1)(1) = (2 - \\lambda)^2 - 1.\n$$\n\nSet the determinant equal to zero:\n\n$$\n(2 - \\lambda)^2 - 1 = 0.\n$$\n\nExpand the equation:\n\n$$\n4 - 4\\lambda + \\lambda^2 - 1 = \\lambda^2 - 4\\lambda + 3 = 0.\n$$\n\nSolve the quadratic equation using the quadratic formula:\n\n$$\n\\lambda = \\frac{4 \\pm \\sqrt{(-4)^2 - 4 \\cdot 1 \\cdot 3}}{2} = \\frac{4 \\pm \\sqrt{16 - 12}}{2} = \\frac{4 \\pm \\sqrt{4}}{2} = \\frac{4 \\pm 2}{2}.\n$$\n\nThe solutions are:\n\n$$\n\\lambda_1 = \\frac{4 + 2}{2} = 3, \\quad \\lambda_2 = \\frac{4 - 2}{2} = 1.\n$$\n\nThus, the eigenvalues of $A$ are $1$ and $3$.", "answer": "\\[\n\\boxed{1}\\quad\\text{and}\\quad\\boxed{3}\n\\]", "id": "590644"}, {"introduction": "We now transition from finite-dimensional spaces to the infinite-dimensional setting of a general Hilbert space. This problem [@problem_id:1881659] introduces a finite-rank operator, which serves as a vital conceptual bridge. The structure of this operator is simple enough that its eigenvalues and eigenspaces can be determined almost by inspection, helping to build intuition for how an operator's definition can directly reveal its spectral decomposition.", "problem": "Let $H$ be a complex Hilbert space with inner product $\\langle \\cdot, \\cdot \\rangle$. Let $u$ and $v$ be two orthonormal vectors in $H$, meaning $\\langle u, u \\rangle = 1$, $\\langle v, v \\rangle = 1$, and $\\langle u, v \\rangle = 0$. Consider the linear operator $A: H \\to H$ defined by the action\n$$ A(x) = \\alpha \\langle x, u \\rangle u + \\beta \\langle x, v \\rangle v $$\nfor any vector $x \\in H$. Here, $\\alpha$ and $\\beta$ are distinct, non-zero real constants.\n\nLet $E_\\lambda$ denote the eigenspace corresponding to an eigenvalue $\\lambda$. Which of the following statements correctly describes all non-zero eigenvalues of $A$ and their corresponding eigenspaces?\n\nA. The non-zero eigenvalues are $\\alpha$ and $\\beta$. The corresponding eigenspaces are $E_{\\alpha} = \\text{span}\\{u\\}$ and $E_{\\beta} = \\text{span}\\{v\\}$.\n\nB. The non-zero eigenvalues are $\\alpha$ and $\\beta$. The corresponding eigenspaces are $E_{\\alpha} = \\text{span}\\{v\\}$ and $E_{\\beta} = \\text{span}\\{u\\}$.\n\nC. The only non-zero eigenvalue is $\\alpha+\\beta$. The corresponding eigenspace is $E_{\\alpha+\\beta} = \\text{span}\\{u, v\\}$.\n\nD. The non-zero eigenvalues are $\\alpha+\\beta$ and $\\alpha-\\beta$. The corresponding eigenspaces are $E_{\\alpha+\\beta} = \\text{span}\\{u+v\\}$ and $E_{\\alpha-\\beta} = \\text{span}\\{u-v\\}$.\n\nE. The only non-zero eigenvalue is 1. The corresponding eigenspace is $E_1 = \\text{span}\\{u, v\\}$.\n\nF. The non-zero eigenvalues are $\\alpha^2$ and $\\beta^2$. The corresponding eigenspaces are $E_{\\alpha^2} = \\text{span}\\{u\\}$ and $E_{\\beta^2} = \\text{span}\\{v\\}$.", "solution": "Because $u$ and $v$ are orthonormal, every $x \\in H$ decomposes uniquely as\n$$\nx=\\langle x,u\\rangle u+\\langle x,v\\rangle v+z,\n$$\nwhere $z$ is orthogonal to both $u$ and $v$. By the definition of $A$,\n$$\nA(x)=\\alpha\\langle x,u\\rangle u+\\beta\\langle x,v\\rangle v,\n$$\nso in particular\n$$\nA(u)=\\alpha\\langle u,u\\rangle u+\\beta\\langle u,v\\rangle v=\\alpha u,\n\\quad\nA(v)=\\alpha\\langle v,u\\rangle u+\\beta\\langle v,v\\rangle v=\\beta v,\n$$\nand for any $z$ orthogonal to both $u$ and $v$,\n$$\nA(z)=\\alpha\\langle z,u\\rangle u+\\beta\\langle z,v\\rangle v=0.\n$$\nHence $u$ is an eigenvector with eigenvalue $\\alpha$, $v$ is an eigenvector with eigenvalue $\\beta$, and any vector orthogonal to $\\mathrm{span}\\{u,v\\}$ is an eigenvector with eigenvalue $0$.\n\nTo find all non-zero eigenvalues and their eigenspaces, let $x$ be an eigenvector with eigenvalue $\\lambda\\neq 0$. Write $x=a u+b v+z$ with $z$ orthogonal to $u$ and $v$. Then\n$$\nA(x)=\\alpha a\\,u+\\beta b\\,v=\\lambda(a u+b v+z).\n$$\nBy orthogonality of $u$, $v$, and $z$, comparing coefficients gives\n$$\n\\lambda z=0 \\implies z=0\\quad(\\text{since }\\lambda\\neq 0),\n$$\nand\n$$\n(\\alpha-\\lambda)a=0,\\qquad (\\beta-\\lambda)b=0.\n$$\nIf $a\\neq 0$, then $\\lambda=\\alpha$ and $b=0$, so $x\\in\\mathrm{span}\\{u\\}$. If $b\\neq 0$, then $\\lambda=\\beta$ and $a=0$, so $x\\in\\mathrm{span}\\{v\\}$. Since $\\alpha\\neq\\beta$, $a$ and $b$ cannot both be non-zero for the same $\\lambda$. Therefore the only non-zero eigenvalues are $\\alpha$ and $\\beta$, with eigenspaces $E_{\\alpha}=\\mathrm{span}\\{u\\}$ and $E_{\\beta}=\\mathrm{span}\\{v\\}$.\n\nThis corresponds exactly to option A.", "answer": "$$\\boxed{A}$$", "id": "1881659"}, {"introduction": "A major application of the Spectral Theorem lies in the study of integral operators, which are central to many areas of mathematics and physics. This exercise [@problem_id:1881664] explores a classic example of a compact self-adjoint integral operator whose spectrum is infinite. Solving it demonstrates a powerful technique: transforming the integral eigenvalue equation into a more familiar differential equation with boundary conditions, thereby linking functional analysis with the theory of Sturm-Liouville problems.", "problem": "Consider the Hilbert space $L^2([0,1])$ consisting of complex-valued, square-integrable functions on the interval $[0,1]$, equipped with the standard inner product $\\langle f, g \\rangle = \\int_0^1 f(x) \\overline{g(x)} \\,dx$. Let $T$ be a linear operator on this space defined by:\n$$ (Tf)(x) = \\int_0^1 K(x,t) f(t) \\,dt $$\nwhere the kernel $K(x,t)$ is given by\n$$ K(x,t) = 1 - \\max(x,t). $$\nThis operator is compact and self-adjoint, and thus its spectrum consists of a sequence of real eigenvalues.\n\nDetermine the general expressions for the non-zero eigenvalues $\\lambda_n$ and their corresponding real-valued, normalized eigenfunctions $\\phi_n(x)$ for $n \\in \\{1, 2, 3, \\dots\\}$. The eigenvalues should be indexed in decreasing order, i.e., $\\lambda_1 > \\lambda_2 > \\lambda_3 > \\dots > 0$.\n\nYour answer should be a composite expression containing the formula for $\\lambda_n$ as the first component and the formula for $\\phi_n(x)$ as the second component.", "solution": "We are given the compact self-adjoint integral operator on $L^{2}([0,1])$,\n$$\n(Tf)(x)=\\int_{0}^{1}K(x,t)f(t)\\,dt,\\quad K(x,t)=1-\\max(x,t).\n$$\nFor an eigenpair $(\\lambda,\\phi)$ with $\\lambda\\neq 0$, the eigenvalue equation is\n$$\n\\lambda\\,\\phi(x)=\\int_{0}^{1}\\bigl(1-\\max(x,t)\\bigr)\\phi(t)\\,dt.\n$$\nWriting the integral piecewise in $t$ for fixed $x$ gives\n$$\n\\lambda\\,\\phi(x)=(1-x)\\int_{0}^{x}\\phi(t)\\,dt+\\int_{x}^{1}(1-t)\\phi(t)\\,dt.\n$$\nDefine $F(x)=\\int_{0}^{x}\\phi(t)\\,dt$, so that $F'(x)=\\phi(x)$. Differentiate both sides with respect to $x$:\n- The derivative of $(1-x)F(x)$ is $-F(x)+(1-x)\\phi(x)$.\n- The derivative of $\\int_{x}^{1}(1-t)\\phi(t)\\,dt$ is $-(1-x)\\phi(x)$ by Leibniz's rule.\nHence\n$$\n\\lambda\\,\\phi'(x)=-F(x)=-\\int_{0}^{x}\\phi(t)\\,dt.\n$$\nDifferentiate once more to obtain\n$$\n\\lambda\\,\\phi''(x)=-\\phi(x),\n$$\nthat is,\n$$\n\\phi''(x)+\\frac{1}{\\lambda}\\,\\phi(x)=0.\n$$\nThe boundary conditions follow from the integral form:\n- Evaluating the first derivative relation at $x=0$ gives $\\lambda\\,\\phi'(0)=0$, hence $\\phi'(0)=0$.\n- Evaluating the original eigenvalue equation at $x=1$ gives $\\lambda\\,\\phi(1)=0$, hence $\\phi(1)=0$.\n\nThus $\\phi$ solves the Sturmâ€“Liouville problem\n$$\n\\phi''(x)+\\mu^{2}\\phi(x)=0,\\quad \\phi'(0)=0,\\quad \\phi(1)=0,\n$$\nwith $\\mu^{2}=\\frac{1}{\\lambda}$. The general solution is $\\phi(x)=A\\cos(\\mu x)+B\\sin(\\mu x)$. The condition $\\phi'(0)=0$ implies $B\\mu=0$, hence $B=0$ (since $\\lambda\\neq 0$ implies $\\mu\\neq 0$). Therefore $\\phi(x)=A\\cos(\\mu x)$, and the condition $\\phi(1)=0$ requires\n$$\n\\cos(\\mu)=0\\quad\\Longrightarrow\\quad \\mu=\\frac{(2n-1)\\pi}{2},\\quad n\\in\\{1,2,3,\\dots\\}.\n$$\nHence the corresponding nonzero eigenvalues are\n$$\n\\lambda_{n}=\\frac{1}{\\mu_{n}^{2}}=\\frac{4}{(2n-1)^{2}\\pi^{2}},\n$$\nwhich are strictly decreasing in $n$. The associated (real) eigenfunctions are $\\phi_{n}(x)=A_{n}\\cos\\!\\bigl(\\mu_{n}x\\bigr)$.\n\nTo normalize, compute\n$$\n\\int_{0}^{1}\\cos^{2}\\!\\bigl(\\mu_{n}x\\bigr)\\,dx=\\frac{1}{2}+\\frac{\\sin(2\\mu_{n})}{4\\mu_{n}}=\\frac{1}{2},\n$$\nsince $\\sin(2\\mu_{n})=\\sin\\bigl((2n-1)\\pi\\bigr)=0$. Therefore choose $A_{n}=\\sqrt{2}$ to achieve $\\|\\phi_{n}\\|_{2}=1$.\n\nThus, for $n\\in\\{1,2,3,\\dots\\}$,\n$$\n\\lambda_{n}=\\frac{4}{(2n-1)^{2}\\pi^{2}},\\qquad \\phi_{n}(x)=\\sqrt{2}\\,\\cos\\!\\left(\\frac{(2n-1)\\pi}{2}\\,x\\right).\n$$\nThese satisfy the required ordering $\\lambda_{1}>\\lambda_{2}>\\cdots>0$ and are real-valued and normalized.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{4}{(2n-1)^{2}\\pi^{2}} & \\sqrt{2}\\,\\cos\\!\\left(\\frac{(2n-1)\\pi}{2}\\,x\\right)\\end{pmatrix}}$$", "id": "1881664"}]}