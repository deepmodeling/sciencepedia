{"hands_on_practices": [{"introduction": "Establishing the uniform convergence of a series of functions is a crucial first step in analyzing the properties of its sum. This practice provides a direct application of the Weierstrass M-test, one of the most powerful tools for this purpose [@problem_id:2332404]. By finding a dominant convergent series of numbers, we can rigorously prove that the resulting sum function is continuous everywhere on the real line.", "problem": "Consider the function $f(x)$ defined by the series of functions:\n$$f(x) = \\sum_{n=1}^{\\infty} \\frac{1}{n^2 + x^2}$$\nThe domain of this function is the set of all real numbers, $\\mathbb{R}$. Analyze the continuity of $f(x)$ on its domain. Which of the following statements is correct?\n\nA. The function $f(x)$ is continuous on $\\mathbb{R}$ because the series converges uniformly on $\\mathbb{R}$.\n\nB. The function $f(x)$ is continuous on $\\mathbb{R}$ because it is a sum of continuous functions, and any sum of continuous functions is also continuous.\n\nC. The function $f(x)$ is not continuous on $\\mathbb{R}$ because the series of functions does not converge uniformly on $\\mathbb{R}$.\n\nD. The function $f(x)$ is not continuous on $\\mathbb{R}$ because the series diverges when $x=0$.\n\nE. The continuity of $f(x)$ cannot be determined because the convergence of the series depends on the value of $x$.", "solution": "Let $g_{n}(x) = \\frac{1}{n^{2} + x^{2}}$ for each $n \\in \\mathbb{N}$. For every fixed $n$, the denominator satisfies $n^{2} + x^{2} \\geq n^{2}  0$ for all $x \\in \\mathbb{R}$, hence $g_{n}$ is well defined and continuous on $\\mathbb{R}$.\n\nTo analyze the convergence of the series of functions $\\sum_{n=1}^{\\infty} g_{n}(x)$ uniformly on $\\mathbb{R}$, apply the Weierstrass M-test. For all $x \\in \\mathbb{R}$ and all $n \\in \\mathbb{N}$,\n$$\n0 \\leq g_{n}(x) = \\frac{1}{n^{2} + x^{2}} \\leq \\frac{1}{n^{2}} =: M_{n}.\n$$\nThe numerical series $\\sum_{n=1}^{\\infty} M_{n} = \\sum_{n=1}^{\\infty} \\frac{1}{n^{2}}$ converges. Therefore, by the Weierstrass M-test, the series $\\sum_{n=1}^{\\infty} g_{n}(x)$ converges uniformly on $\\mathbb{R}$.\n\nSince each $g_{n}$ is continuous on $\\mathbb{R}$ and the series converges uniformly on $\\mathbb{R}$, the sum\n$$\nf(x) = \\sum_{n=1}^{\\infty} \\frac{1}{n^{2} + x^{2}}\n$$\nis the uniform limit of continuous functions and hence is continuous on $\\mathbb{R}$.\n\nWe now evaluate the options:\n- A is true: the function is continuous on $\\mathbb{R}$ because the series converges uniformly on $\\mathbb{R}$ by the Weierstrass M-test.\n- B is false: an infinite sum of continuous functions is not necessarily continuous without uniform convergence; here continuity follows specifically from uniform convergence.\n- C is false: the series does converge uniformly on $\\mathbb{R}$, as shown.\n- D is false: at $x=0$, one has $f(0) = \\sum_{n=1}^{\\infty} \\frac{1}{n^{2}}$, which converges.\n- E is false: the continuity can be determined, and the series converges uniformly for all $x \\in \\mathbb{R}$.\n\nThus, the correct statement is A.", "answer": "$$\\boxed{A}$$", "id": "2332404"}, {"introduction": "Not all sequences that converge pointwise do so uniformly, and understanding this distinction is fundamental. This exercise explores a classic example of a sequence of functions that converges pointwise to zero but fails to converge uniformly [@problem_id:1342740]. By calculating the maximum value of each function in the sequence, you will see directly why the supremum of the differences does not approach zero, which is the hallmark of non-uniform convergence.", "problem": "In a simplified model of a transient physical process, the intensity of a signal at a normalized position $x \\in [0, 1]$ is described by the function $I_n(x) = n x (1-x)^n$, where $n$ is a positive integer parameter characterizing the process. For each value of $n$, the signal has a peak intensity, $M_n$, which is the maximum value of $I_n(x)$ on the interval $[0, 1]$. To assess the behavior of this system for very large parameter values, we are interested in the asymptotic limit of these peak intensities.\n\nCalculate the exact value of the limit $L = \\lim_{n \\to \\infty} M_n$.", "solution": "We consider $I_{n}(x) = n x (1-x)^{n}$ for $x \\in [0,1]$ and fixed positive integer $n$. The endpoints give $I_{n}(0) = 0$ and $I_{n}(1) = 0$. To find the interior extrema, compute the derivative:\n$$\nI_{n}'(x) = n (1-x)^{n} + n x \\cdot n (1-x)^{n-1} \\cdot (-1) = n (1-x)^{n-1} \\big( (1-x) - n x \\big).\n$$\nThus\n$$\nI_{n}'(x) = n (1-x)^{n-1} \\big( 1 - (n+1) x \\big).\n$$\nSetting $I_{n}'(x)=0$ yields either $1-x=0$ (i.e., $x=1$, an endpoint) or $1-(n+1)x=0$, which gives the unique interior critical point\n$$\nx^{\\ast} = \\frac{1}{n+1}.\n$$\nFor $x \\in (0,1)$, the factor $n(1-x)^{n-1}$ is positive, so the sign of $I_{n}'(x)$ is determined by $1-(n+1)x$. Hence $I_{n}'(x)  0$ for $x  \\frac{1}{n+1}$ and $I_{n}'(x)  0$ for $x  \\frac{1}{n+1}$. Therefore $x^{\\ast}$ is the unique maximizer on $(0,1)$, and the maximum value is\n$$\nM_{n} = I_{n}\\!\\left( \\frac{1}{n+1} \\right) = n \\cdot \\frac{1}{n+1} \\left( 1 - \\frac{1}{n+1} \\right)^{n} = \\frac{n}{n+1} \\left( \\frac{n}{n+1} \\right)^{n}.\n$$\nTo find the limit $L = \\lim_{n \\to \\infty} M_{n}$, we consider the logarithm of the expression:\n$$\n\\ln M_{n} = \\ln\\left(\\frac{n}{n+1}\\right) + n \\ln\\left(\\frac{n}{n+1}\\right) = (n+1) \\ln\\left(1 - \\frac{1}{n+1}\\right).\n$$\nLet $m = n+1$. As $m \\to \\infty$, we can use L'HÃ´pital's rule or a standard Taylor expansion for the limit:\n$$\n\\lim_{m \\to \\infty} m \\ln\\!\\left(1 - \\frac{1}{m}\\right) = \\lim_{m \\to \\infty} \\frac{\\ln(1 - 1/m)}{1/m}.\n$$\nSetting $t=1/m$, the limit becomes $\\lim_{t \\to 0^{+}} \\frac{\\ln(1 - t)}{t} = -1$.\nTherefore,\n$$\n\\lim_{n \\to \\infty} \\ln M_{n} = -1,\n$$\nand by the continuity of the exponential function,\n$$\nL = \\lim_{n \\to \\infty} M_{n} = \\exp(-1).\n$$\nThus the exact asymptotic limit is $\\exp(-1)$.", "answer": "$$\\boxed{\\exp(-1)}$$", "id": "1342740"}, {"introduction": "Often in mathematical analysis, the convergence of a series depends on a parameter, and our task is to find the exact conditions that guarantee a desired property. This problem challenges you to determine for which values of the parameter $\\alpha$ the given series converges uniformly on the interval $[0, 1]$ [@problem_id:1342730]. The solution involves a careful analysis of the maximum value of each term in the series, linking the uniform convergence of functions to the convergence criteria of numerical p-series.", "problem": "Consider the series of functions $\\sum_{n=1}^{\\infty} f_n(x)$ defined on the interval $I = [0, 1]$, where the general term is given by\n$$f_n(x) = n^{\\alpha} \\left(x^{n + \\frac{1}{2}} - x^n\\right)$$\nfor some real parameter $\\alpha \\in \\mathbb{R}$.\n\nDetermine the condition on the parameter $\\alpha$ that guarantees the series converges uniformly on the interval $I$.\n\nA. $\\alpha \\leq 0$\n\nB. $\\alpha  -\\frac{1}{2}$\n\nC. $\\alpha  0$\n\nD. $\\alpha  \\frac{1}{2}$\n\nE. $\\alpha  1$", "solution": "We start by rewriting the general term as\n$$f_{n}(x)=n^{\\alpha}\\big(x^{n+\\frac{1}{2}}-x^{n}\\big)=n^{\\alpha}x^{n}\\big(x^{\\frac{1}{2}}-1\\big).$$\nOn $[0,1]$ we have $x^{\\frac{1}{2}}-1\\leq 0$, so $f_{n}(x)\\leq 0$ for $x\\in(0,1]$ and $f_{n}(0)=0$. To test uniform convergence, a sufficient condition is the Weierstrass M-test via $\\sum \\sup_{x\\in[0,1]}|f_{n}(x)|$.\n\nFix $n$ and set $u=x^{\\frac{1}{2}}\\in[0,1]$. Then\n$$|f_{n}(x)|=n^{\\alpha}x^{n}\\big(1-x^{\\frac{1}{2}}\\big)=n^{\\alpha}u^{2n}(1-u).$$\nDefine $h(u)=u^{2n}(1-u)$ on $[0,1]$. Its derivative is\n$$h'(u)=2n\\,u^{2n-1}(1-u)-u^{2n}=u^{2n-1}\\big(2n-(2n+1)u\\big).$$\nCritical points occur at $u=0$ and $u=\\frac{2n}{2n+1}$. Since $h(0)=h(1)=0$ and $h(u)0$ on $(0,1)$, the maximum on $[0,1]$ is attained at $u^{*}=\\frac{2n}{2n+1}$. Therefore\n$$\\sup_{x\\in[0,1]}|f_{n}(x)|=n^{\\alpha}\\,h(u^{*})=n^{\\alpha}\\left(\\frac{2n}{2n+1}\\right)^{2n}\\frac{1}{2n+1}.$$\nUsing the limit\n$$\\left(\\frac{2n}{2n+1}\\right)^{2n}=\\left(1-\\frac{1}{2n+1}\\right)^{2n}\\longrightarrow \\exp(-1) \\quad\\text{as }n\\to\\infty,$$\nwe obtain the asymptotic behavior\n$$\\sup_{x\\in[0,1]}|f_{n}(x)|\\sim \\frac{\\exp(-1)}{2}\\,n^{\\alpha-1}.$$\nHence\n$$\\sum_{n=1}^{\\infty}\\sup_{x\\in[0,1]}|f_{n}(x)|\\quad\\text{converges if and only if}\\quad \\alpha-1-1\\ \\Longleftrightarrow\\ \\alpha0.$$\nBy the Weierstrass M-test, for $\\alpha0$ the series converges uniformly (in fact, absolutely uniformly) on $[0,1]$.\n\nWe now show that uniform convergence fails for $\\alpha\\geq 0$. First, for $\\alpha=0$,\n$$\\sum_{n=1}^{\\infty}f_{n}(x)=\\sum_{n=1}^{\\infty}\\big(x^{n+\\frac{1}{2}}-x^{n}\\big)=\\frac{x^{\\frac{3}{2}}}{1-x}-\\frac{x}{1-x}=\\frac{x\\big(x^{\\frac{1}{2}}-1\\big)}{1-x}=-\\frac{x}{1+x^{\\frac{1}{2}}}.$$\nAs $x\\to 1^{-}$ this tends to $-\\frac{1}{2}$, whereas at $x=1$ each term is $0$, so the pointwise sum equals $0$. Thus the pointwise limit on $[0,1]$ is discontinuous at $x=1$, which is impossible for a uniform limit of continuous functions. Hence no uniform convergence for $\\alpha=0$.\n\nFor $\\alpha0$, let $x=\\exp(-\\delta)$ with $0\\delta\\leq 1$. Then\n$$|x^{\\frac{1}{2}}-1|=1-\\exp\\!\\left(-\\frac{\\delta}{2}\\right)\\geq \\frac{\\delta}{4},$$\nsince $\\exp(-y)\\leq 1-\\frac{y}{2}$ for $y\\in[0,1]$. Moreover,\n$$\\sum_{n=1}^{\\infty}n^{\\alpha}x^{n}\\geq \\sum_{n=1}^{\\lfloor 1/\\delta\\rfloor}n^{\\alpha}\\exp(-\\delta n)\\geq \\exp(-1)\\sum_{n=1}^{\\lfloor 1/\\delta\\rfloor}n^{\\alpha}\\geq \\exp(-1)\\int_{0}^{1/\\delta}t^{\\alpha}\\,dt=\\frac{\\exp(-1)}{\\alpha+1}\\,\\delta^{-(\\alpha+1)}.$$\nTherefore\n$$\\left|\\sum_{n=1}^{\\infty}f_{n}(x)\\right|=|x^{\\frac{1}{2}}-1|\\sum_{n=1}^{\\infty}n^{\\alpha}x^{n}\\geq \\frac{\\delta}{4}\\cdot \\frac{\\exp(-1)}{\\alpha+1}\\,\\delta^{-(\\alpha+1)}=\\frac{1}{4\\exp(1)(\\alpha+1)}\\,\\delta^{-\\alpha}\\xrightarrow[\\delta\\to 0^{+}]{}\\infty.$$\nThus the pointwise sum is unbounded near $x=1$ (while at $x=1$ the sum equals $0$ termwise), again contradicting the continuity required by uniform convergence. Hence uniform convergence fails for all $\\alpha0$.\n\nCombining both directions, the series converges uniformly on $[0,1]$ if and only if $\\alpha0$, which corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1342730"}]}