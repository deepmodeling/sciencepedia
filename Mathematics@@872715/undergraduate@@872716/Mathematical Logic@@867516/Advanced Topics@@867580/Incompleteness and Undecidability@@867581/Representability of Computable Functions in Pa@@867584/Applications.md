## Applications and Interdisciplinary Connections

The preceding chapters have established the technical foundations of representability: the principle that the properties of [computable functions](@entry_id:152169) and relations can be formally expressed and proven within a sufficiently strong axiomatic system such as Peano Arithmetic ($PA$). While the construction of representing formulas is an achievement in itself, the true significance of representability lies not in its existence, but in its profound applications. It is the critical bridge that allows a formal theory to reason about its own structure and limitations, leading to some of the most celebrated and startling results in the foundations of mathematics and computer science.

This chapter explores these consequences. We will demonstrate how representability enables the *[arithmetization of metamathematics](@entry_id:151507)*, allowing concepts like "formula" and "proof" to be treated as objects of arithmetic. This leads directly to the construction of self-referential sentences via the Diagonal Lemma, the engine behind the great limitative theorems of Gödel and Tarski. We will then trace the deep connections to [computability theory](@entry_id:149179), showing how representability provides a formal link between proof and algorithm, and explore the limits of what arithmetic can express about computation. Finally, we will touch upon modern frontiers, including [provability logic](@entry_id:149023) and mechanized mathematics, where these foundational ideas continue to bear fruit.

### The Arithmetization of Syntax

The first and most crucial application of representability is its role in the *[arithmetization of syntax](@entry_id:151516)*. The statements of mathematics are syntactic objects—finite strings of symbols. Metamathematics, the study of mathematics itself, makes claims about these objects: "this string is a [well-formed formula](@entry_id:152026)," "this sequence of formulas is a valid proof," or "this formula is the result of substituting a term into another formula." The goal of [arithmetization](@entry_id:268283), pioneered by Gödel, is to translate these metamathematical statements into statements about natural numbers, so that a theory of arithmetic like $PA$ can reason about them.

This translation begins with a Gödel numbering, an effective scheme that assigns a unique natural number (a "code") to every symbol, formula, and finite sequence of formulas. The key insight is that for any reasonable Gödel numbering scheme, the fundamental syntactic relations become primitive recursive relations on the [natural numbers](@entry_id:636016). For instance, the property of a number $x$ being the code of a [well-formed formula](@entry_id:152026), which we might denote $\mathrm{isFormula}(x)$, can be checked by an algorithm. This algorithm would decode the number $x$ into a sequence of symbols and verify that it adheres to the recursive rules of formula construction (e.g., checking for balanced parentheses, correct operator placement, etc.). Such [parsing](@entry_id:274066) algorithms, involving bounded searches and mechanical checks on the structure of the coded string, can be defined using only composition and [primitive recursion](@entry_id:638015). Therefore, relations like $\mathrm{isFormula}(x)$, $\mathrm{isTerm}(x)$, and, most importantly, the proof relation $\mathrm{Proof}_{PA}(y,x)$—which holds if $y$ is the code of a valid $PA$-proof of the formula with code $x$—are all primitive recursive.

Once a metamathematical relation is shown to be primitive recursive, the representability theorem immediately applies. It guarantees the existence of a formula in the language of arithmetic that formally captures this relation within $PA$. For the proof relation, this means there is a formula $\mathsf{Prf}_{PA}(u,v)$ that $PA$ can use to talk about its own proofs. This step is the linchpin of the entire program: the syntactic, external concept of provability is imported into the semantic, internal world of arithmetic. From this, one can define the famous *[provability predicate](@entry_id:634685)* $\mathsf{Prov}_{PA}(v)$ as $\exists u \, \mathsf{Prf}_{PA}(u,v)$, which formally expresses "the formula with code $v$ is provable in $PA$."

### The Diagonal Lemma and the Power of Self-Reference

The ability to represent syntactic operations within $PA$ enables the construction of sentences that refer to themselves. This is not a vague, paradoxical notion but a rigorously defined syntactic trick, formalized by the Diagonal Lemma (or Fixed-Point Lemma).

The lemma states that for any formula $\psi(v)$ with one free variable, there exists a sentence $\theta$ such that $PA$ can prove the equivalence $\theta \leftrightarrow \psi(\overline{\ulcorner \theta \urcorner})$. In essence, the sentence $\theta$ asserts "I have the property $\psi$." This result is a direct consequence of representability and holds for any formula $\psi(v)$, no matter how complex.

The proof of the lemma is a masterful application of [arithmetization](@entry_id:268283). It relies on a specific primitive [recursive function](@entry_id:634992), the "[diagonalization](@entry_id:147016) function" $d(n)$. This function takes the Gödel number $n$ of a formula with one free variable, say $\alpha(x)$, and outputs the Gödel number of the sentence formed by substituting the numeral for $n$ into $\alpha(x)$ itself: $d(\ulcorner\alpha(x)\urcorner) = \ulcorner\alpha(\overline{\ulcorner\alpha(x)\urcorner})\urcorner$. Since $d(n)$ is primitive recursive, there is a formula $D(x, y)$ that represents it in $PA$. By composing this formula $D(x,y)$ with the given formula $\psi(v)$, one can construct the desired fixed-point sentence $\theta$. The ability to internalize the syntactic map $n \mapsto d(n)$ as a formal object within arithmetic is precisely what delivers the fixed point. The result is a chain of provable equivalences within $PA$ that establishes the self-referential property of $\theta$ without recourse to any semantic or model-theoretic assumptions.

Furthermore, the construction is effective: there is a primitive [recursive function](@entry_id:634992) that, given the code of a formula $\psi(x)$, computes the code of its fixed point $\theta$. This is known as the uniform version of the Diagonal Lemma, and the entire verification of its correctness can be formalized within $PA$ itself.

### Foundational Limitative Theorems

The machinery of [arithmetization](@entry_id:268283) and self-reference provides the tools to prove some of the most profound [limitations of formal systems](@entry_id:638047).

#### Gödel's First Incompleteness Theorem

The most famous application of representability is the proof of Gödel's First Incompleteness Theorem. The theorem states that any consistent, effectively axiomatized theory strong enough to represent all [primitive recursive functions](@entry_id:155169) (a class that includes $PA$) is necessarily incomplete. That is, there are sentences in its language that can neither be proven nor disproven within the theory.

The proof elegantly combines the components we have discussed. First, the [arithmetization of syntax](@entry_id:151516) allows for the definition of the [provability predicate](@entry_id:634685), $\mathsf{Prov}_{PA}(x)$. Then, the Diagonal Lemma is applied to the *negation* of this predicate, $\neg\mathsf{Prov}_{PA}(x)$. This yields a sentence, typically denoted $G$, such that $PA \vdash G \leftrightarrow \neg\mathsf{Prov}_{PA}(\overline{\ulcorner G \urcorner})$. This "Gödel sentence" $G$ asserts its own unprovability.

A careful analysis shows that if $PA$ is consistent, it cannot prove $G$. For if it did, $\mathsf{Prov}_{PA}(\overline{\ulcorner G \urcorner})$ would be true and provable, but $G$ asserts its negation, leading to a contradiction. Furthermore, if $PA$ is not only consistent but also sound (or, in Gödel's original proof, $\omega$-consistent), it cannot prove $\neg G$ either. Thus, $G$ is an undecidable sentence, demonstrating the incompleteness of $PA$. The representability of the proof relation is the non-negotiable prerequisite that gets this entire argument off the ground.

#### Tarski's Undefinability of Truth Theorem

A similar self-referential argument, also powered by the Diagonal Lemma, leads to Tarski's theorem on the [undefinability of truth](@entry_id:152489). This theorem states that the set of Gödel numbers of true sentences in the standard model of arithmetic cannot be defined by any formula within the language of arithmetic itself.

The proof is a [reductio ad absurdum](@entry_id:276604). Suppose there were a formula $\mathsf{True}(x)$ that defined truth. That is, for any sentence $\phi$, $\mathsf{True}(\overline{\ulcorner\phi\urcorner})$ is true in the [standard model](@entry_id:137424) if and only if $\phi$ is true in the standard model. We could then apply the Diagonal Lemma to the formula $\neg\mathsf{True}(x)$ to construct a "liar sentence" $\lambda$ such that $PA \vdash \lambda \leftrightarrow \neg\mathsf{True}(\overline{\ulcorner\lambda\urcorner})$. This sentence asserts its own falsehood. This leads to an immediate contradiction: $\lambda$ is true if and only if $\neg\mathsf{True}(\overline{\ulcorner\lambda\urcorner})$ is true, which by the definition of our hypothetical truth predicate, is true if and only if $\lambda$ is false. The only way to escape the paradox is to conclude that the initial assumption—the existence of a formula $\mathsf{True}(x)$—was false. This proof relies critically on the [arithmetization of syntax](@entry_id:151516) via Gödel numbering and the existence of a self-referential sentence guaranteed by the Diagonal Lemma, which in turn rests on the representability of the primitive recursive substitution function.

### Connections to Computability Theory

Representability forges a deep and explicit link between the logical world of formal proofs and the algorithmic world of computation. The very definition of a computable (or recursive) function can be seen as the class of functions whose behavior can, in principle, be captured by a [formal system](@entry_id:637941).

#### Arithmetization of Computation and Church's Theorem

The [arithmetization](@entry_id:268283) program extends beyond syntax to computation itself. Any formal [model of computation](@entry_id:637456), such as a Turing machine, operates via a set of simple, discrete rules. A machine's entire state at any moment (its configuration) can be encoded by a single number, and a finite computation can be encoded as a finite sequence of such numbers, which can itself be encoded by one master Gödel number. The crucial fact is that the relation "$c$ is the code for a valid, halting computation of machine $M$ on input $n$" is primitive recursive. This predicate is often called Kleene's T-predicate.

Because this predicate is primitive recursive, it is representable by a $\Delta_0$ formula in $PA$. Consequently, the statement "$M$ halts on input $n$"—which is equivalent to "there exists a halting computation $c$"—can be expressed by a $\Sigma_1$ formula of the form $\exists c \, \mathbf{T}(m, n, c)$, where $\mathbf{T}$ is the $\Delta_0$ formula representing the T-predicate. This provides a uniform and effective map from any algorithm (identified by its index) to a $\Sigma_1$ formula representing the relation it computes.

This connection has profound consequences. One is a proof of the [undecidability](@entry_id:145973) of $PA$ (a result known as Church's Theorem). If the set of theorems of $PA$ were decidable, one could solve the Halting Problem—a known [undecidable problem](@entry_id:271581). The reduction works as follows: to determine if machine $M$ halts on input $n$, construct the corresponding $\Sigma_1$ sentence $\phi_{M,n}$ and use the hypothetical decision procedure to check if $PA \vdash \phi_{M,n}$. Because $PA$ is sound and proves all true $\Sigma_1$ sentences ($\Sigma_1$-completeness), this would decide halting. Since this is impossible, the set of $PA$'s theorems must be undecidable.

#### The Limits of Representability

While representability connects [logic and computation](@entry_id:270730), it also delineates their shared limitations. Not every computable function is representable in the strongest sense. Consider the [characteristic function](@entry_id:141714) of [the halting problem](@entry_id:265241), $\chi_K(e,x)$, which is $1$ if the $e$-th program halts on input $x$ and $0$ otherwise. If this total function were representable as a total function in $PA$, there would be a formula $F(e,x,y)$ such that for any $(e,x)$, $PA$ would prove either $F(\overline{e},\overline{x},\overline{1})$ or $F(\overline{e},\overline{x},\overline{0})$. Since the set of $PA$ theorems is recursively enumerable, one could build an algorithm that searches for a proof of either statement. This algorithm would always terminate and would thus decide the Halting Problem. As this is impossible, we must conclude that $\chi_K$ is not representable as a total function in $PA$, despite its graph being arithmetically definable. This shows a subtle limit on the power of [formal systems](@entry_id:634057) to capture even basic computational notions.

#### The Recursion Theorem Analogy

The parallel between logic and computability is beautifully illustrated by the analogy between the Diagonal Lemma and Kleene's Second Recursion Theorem. The Diagonal Lemma provides a formula $\theta$ that is a fixed point for a syntactic transformation $\psi$. Kleene's Recursion Theorem provides a program index $e$ that is a fixed point for a computable transformation of programs $f$, such that the program $\varphi_e$ behaves identically to the program $\varphi_{f(e)}$.

Both theorems are about self-reference, and both are proven using a similar "diagonal" construction. In logic, the mechanism is the representability of the syntactic substitution function. In [computability](@entry_id:276011), the mechanism is the $s$-$m$-$n$ theorem, which allows a program to be specialized with data, including its own code. This correspondence is not an accident; it reveals that self-reference is a fundamental property of any system, be it logical or computational, that is powerful enough to encode and manipulate its own descriptions.

### Advanced Topics and Modern Frontiers

The ideas flowing from representability continue to shape research in mathematical logic and computer science.

#### Provability Logic

Instead of just using the [provability predicate](@entry_id:634685) $\mathsf{Prov}_{PA}(x)$ as a tool, we can study it as a mathematical object in its own right. The field of Provability Logic investigates the properties of this predicate that are provable within $PA$ itself. Three key properties, known as the Hilbert-Bernays-Löb (HBL) derivability conditions, are:
1. If $PA \vdash \varphi$, then $PA \vdash \mathsf{Prov}_{PA}(\overline{\ulcorner\varphi\urcorner})$.
2. $PA \vdash \mathsf{Prov}_{PA}(\overline{\ulcorner\varphi \to \psi\urcorner}) \to (\mathsf{Prov}_{PA}(\overline{\ulcorner\varphi\urcorner}) \to \mathsf{Prov}_{PA}(\overline{\ulcorner\psi\urcorner}))$.
3. $PA \vdash \mathsf{Prov}_{PA}(\overline{\ulcorner\varphi\urcorner}) \to \mathsf{Prov}_{PA}(\overline{\ulcorner\mathsf{Prov}_{PA}(\overline{\ulcorner\varphi\urcorner})\urcorner})$.

The proofs of these conditions within $PA$ are themselves exercises in representability. They rely on formalizing arguments about proofs: condition (2) formalizes the use of Modus Ponens, while condition (3) formalizes the proof of condition (1). These proofs are possible because the syntactic manipulations involved are primitive recursive and thus representable in $PA$, and because the predicate $\mathsf{Prov}_{PA}(x)$ has a simple $\Sigma_1$ structure that $PA$ can reason about effectively.

#### Mechanized Metatheory and Formal Verification

The constructive nature of the representability theorems has profound implications for modern computer science. The claim that there is an "effective procedure" to convert a description of a [recursive function](@entry_id:634992) into a representing formula is not merely theoretical; it means one can write an actual program—a "proof-producing compiler"—that performs this translation. Such programs have been implemented in formal proof assistants (e.g., Coq, Isabelle/HOL, Lean), providing concrete, machine-verified instances of these foundational theorems.

This opens up the field of *mechanized metatheory*, where the correctness of these compilers can be formally proven. For instance, one can create a program that takes the code for any [partial recursive function](@entry_id:634948) and outputs both a $\Sigma_1$ formula representing its graph and a formal $PA$-proof of its functionality (i.e., that it defines at most one output for any input). If one also provides a proof of the function's totality, the compiler can combine these to produce a proof of strong representability.

Remarkably, the metatheory required to prove the correctness of such a compiler for [primitive recursive functions](@entry_id:155169) is not the full power of [set theory](@entry_id:137783), or even $PA$ itself. The proof can be carried out in a much weaker system known as $I\Sigma_1$ (Peano Arithmetic with induction restricted to $\Sigma_1$ formulas). This demonstrates that the core of [arithmetization](@entry_id:268283) rests on surprisingly minimal logical assumptions, a deep result from the field of [proof theory](@entry_id:151111).

In conclusion, the representability of [computable functions](@entry_id:152169) is the cornerstone upon which the modern understanding of the foundations of mathematics is built. It is the mechanism that translates informal notions of syntax, proof, and algorithm into the concrete language of arithmetic, unlocking the door to the stunning discoveries of Gödel, Tarski, Church, and Kleene, and continuing to inform the frontiers of [logic and computation](@entry_id:270730) today.