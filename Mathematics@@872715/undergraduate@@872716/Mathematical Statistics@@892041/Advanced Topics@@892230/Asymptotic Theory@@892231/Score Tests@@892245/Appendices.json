{"hands_on_practices": [{"introduction": "This first exercise provides a hands-on derivation of the score test for a Bernoulli proportion, which is one of its most fundamental and common applications. By working through this problem, you will see how the general score test formula simplifies into the well-known z-test for proportions, connecting abstract theory to a familiar statistical tool. This practice is essential for understanding how to test hypotheses about binary outcomes, such as success/failure rates or error rates in digital communication [@problem_id:1953755].", "problem": "Consider a simplified model for a digital communication channel where individual bits are transmitted. The transmission of each bit is subject to a potential bit-flip error (a 0 becomes a 1, or a 1 becomes a 0) with a constant probability $p$. We can model the occurrence of an error for each bit as an independent Bernoulli trial. Let $X_i$ be a random variable for the $i$-th bit transmission, where $X_i=1$ if an error occurs and $X_i=0$ if the transmission is successful.\n\nAn engineer collects a random sample of $n$ transmissions to test if the error rate equals a specific design value, $p_0$. The total number of observed bit-flip errors in the sample is denoted by $T = \\sum_{i=1}^{n} X_i$.\n\nYour task is to construct the Rao's score test statistic for the null hypothesis $H_0: p = p_0$ against the alternative hypothesis $H_a: p \\neq p_0$. Express the statistic as a function of the sample size $n$, the total number of observed errors $T$, and the hypothesized error rate $p_0$.", "solution": "We model $X_{i} \\sim \\text{Bernoulli}(p)$ independently, so $T=\\sum_{i=1}^{n}X_{i} \\sim \\text{Binomial}(n,p)$. The likelihood for $p$ given $T$ is\n$$\nL(p;T)=\\binom{n}{T}p^{T}(1-p)^{n-T},\n$$\nand the log-likelihood is\n$$\n\\ell(p)=\\ln L(p;T)=\\ln\\binom{n}{T}+T\\ln p+(n-T)\\ln(1-p).\n$$\nThe score function is the first derivative with respect to $p$:\n$$\nU(p)=\\frac{\\partial \\ell}{\\partial p}=\\frac{T}{p}-\\frac{n-T}{1-p}.\n$$\nThe Fisher information is\n$$\nI(p)=-\\mathbb{E}\\!\\left[\\frac{\\partial^{2}\\ell}{\\partial p^{2}}\\right]\n=-\\mathbb{E}\\!\\left[-\\frac{T}{p^{2}}-\\frac{n-T}{(1-p)^{2}}\\right]\n=\\frac{n}{p(1-p)},\n$$\nusing $\\mathbb{E}[T]=np$. Under the null hypothesis $H_{0}:p=p_{0}$ with $0<p_{0}<1$, evaluate the score and information at $p_{0}$:\n$$\nU(p_{0})=\\frac{T}{p_{0}}-\\frac{n-T}{1-p_{0}}=\\frac{T-np_{0}}{p_{0}(1-p_{0})},\\qquad I(p_{0})=\\frac{n}{p_{0}(1-p_{0})}.\n$$\nRao’s score test statistic is\n$$\nS=\\frac{U(p_{0})^{2}}{I(p_{0})}\n=\\frac{\\left(\\dfrac{T-np_{0}}{p_{0}(1-p_{0})}\\right)^{2}}{\\dfrac{n}{p_{0}(1-p_{0})}}\n=\\frac{(T-np_{0})^{2}}{n\\,p_{0}(1-p_{0})}.\n$$\nEquivalently, the standardized score is $Z=(T-np_{0})/\\sqrt{n\\,p_{0}(1-p_{0})}$ and $S=Z^{2}$.", "answer": "$$\\boxed{\\frac{(T-np_{0})^{2}}{n\\,p_{0}(1-p_{0})}}$$", "id": "1953755"}, {"introduction": "Building on the principles of hypothesis testing, this practice explores the score test within the context of a geometric distribution, often used to model waiting times for a first success. You will derive the test statistic for a hypothesized defect rate in a manufacturing process, demonstrating the versatility of the score test for different discrete probability models. This exercise reinforces the mechanical steps of calculating the score function and Fisher information for a non-Bernoulli distribution [@problem_id:1953900].", "problem": "A quality control engineer is monitoring a production line for a specific type of electronic component. The number of components tested until the first defective one is found, denoted by the random variable $X$, is assumed to follow a geometric distribution. The probability mass function (PMF) is given by $f(x; p) = p(1-p)^{x-1}$ for $x = 1, 2, 3, \\dots$, where $p$ is the probability that a component is defective.\n\nHistorically, the defect rate has been stable at a known value $p_0$. To evaluate a recent modification to the manufacturing process, the engineer collects a random sample of $n$ independent observations, $X_1, X_2, \\dots, X_n$, where each $X_i$ represents the number of trials until the first defective component is found in a given inspection run.\n\nTo determine if the defect rate has changed from its historical value, the engineer wishes to test the null hypothesis $H_0: p = p_0$. Based on this scenario, derive the general form of the Rao's score test statistic for this hypothesis test. Express your answer as a closed-form analytic expression in terms of the sample size $n$, the hypothesized defect rate $p_0$, and the sample mean $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i$.", "solution": "We observe independent $X_{1},\\dots,X_{n}$ with geometric PMF $f(x;p)=p(1-p)^{x-1}$ for $x\\in\\{1,2,\\dots\\}$. The likelihood is\n$$\nL(p)=\\prod_{i=1}^{n} p(1-p)^{x_{i}-1}=p^{n}(1-p)^{\\sum_{i=1}^{n}x_{i}-n}=p^{n}(1-p)^{n\\bar{X}-n}.\n$$\nHence the log-likelihood is\n$$\n\\ell(p)=\\ln L(p)=n\\ln p+(n\\bar{X}-n)\\ln(1-p).\n$$\nThe score function is\n$$\nU(p)=\\frac{\\partial \\ell(p)}{\\partial p}=\\frac{n}{p}-\\frac{n\\bar{X}-n}{1-p}=n\\left(\\frac{1}{p}-\\frac{\\bar{X}-1}{1-p}\\right).\n$$\nThe second derivative is\n$$\n\\ell''(p)=\\frac{\\partial^{2}\\ell(p)}{\\partial p^{2}}=-\\frac{n}{p^{2}}-\\frac{n\\bar{X}-n}{(1-p)^{2}}.\n$$\nThe (expected) Fisher information is $I(p)=-\\mathbb{E}_{p}[\\ell''(p)]$. Using the geometric mean $\\mathbb{E}_{p}[X]=\\frac{1}{p}$, we have $\\mathbb{E}_{p}[n\\bar{X}-n]=n\\left(\\frac{1}{p}-1\\right)=n\\frac{1-p}{p}$, so\n$$\nI(p)=\\frac{n}{p^{2}}+\\frac{n\\frac{1-p}{p}}{(1-p)^{2}}=\\frac{n}{p^{2}}+\\frac{n}{p(1-p)}=\\frac{n}{p^{2}(1-p)}.\n$$\nRao’s score test statistic for testing $H_{0}:p=p_{0}$ is\n$$\nS=\\frac{U(p_{0})^{2}}{I(p_{0})}.\n$$\nEvaluating $U$ and $I$ at $p_{0}$ gives\n$$\nU(p_{0})=n\\left(\\frac{1}{p_{0}}-\\frac{\\bar{X}-1}{1-p_{0}}\\right)=\\frac{n\\left(1-p_{0}\\bar{X}\\right)}{p_{0}(1-p_{0})}, \\quad I(p_{0})=\\frac{n}{p_{0}^{2}(1-p_{0})}.\n$$\nTherefore,\n$$\nS=\\frac{\\left[\\frac{n\\left(1-p_{0}\\bar{X}\\right)}{p_{0}(1-p_{0})}\\right]^{2}}{\\frac{n}{p_{0}^{2}(1-p_{0})}}=n\\,\\frac{\\left(1-p_{0}\\bar{X}\\right)^{2}}{1-p_{0}}.\n$$\nUnder $H_{0}$, $S$ is asymptotically $\\chi^{2}$ with one degree of freedom.", "answer": "$$\\boxed{n\\,\\frac{\\left(1-p_{0}\\bar{X}\\right)^{2}}{1-p_{0}}}$$", "id": "1953900"}, {"introduction": "This problem transitions from derivation to application, using a continuous distribution commonly found in economics—the Pareto distribution—to model wealth. You will not only derive the score test for the shape parameter but also calculate its numerical value using sample data. This exercise highlights how score tests are used in practice to evaluate economic theories and provides a concrete example of testing parameters in a continuous model [@problem_id:1953913].", "problem": "Economists are studying a model of wealth distribution in a particular country. They model the wealth $X$ of an individual, measured in millions of dollars, using a Pareto Type I distribution. The probability density function (PDF) is given by $f(x; \\alpha, x_m) = \\frac{\\alpha x_m^\\alpha}{x^{\\alpha+1}}$ for $x \\ge x_m > 0$. The minimum wealth parameter $x_m$ is known to be fixed at $x_m = 1$ million dollars. The shape parameter $\\alpha$, which determines the degree of wealth inequality, is unknown.\n\nA dominant economic theory proposes that the shape parameter is $\\alpha = 1.5$. To test this theory, a random sample of $n=100$ individuals is collected. The data from this sample yields the summary statistic $\\sum_{i=1}^{100} \\ln(x_i) = 75$, where $x_i$ is the wealth of the $i$-th individual in the sample.\n\nCalculate the value of the Rao's score test statistic for testing the null hypothesis $H_0: \\alpha = 1.5$. Round your final answer to four significant figures.", "solution": "For a Pareto Type I distribution with known $x_{m}=1$, the density is $f(x;\\alpha)=\\alpha x^{-(\\alpha+1)}$ for $x\\geq 1$. For an i.i.d. sample $\\{x_{i}\\}_{i=1}^{n}$, the log-likelihood is\n$$\n\\ell(\\alpha)=\\sum_{i=1}^{n}\\left[\\ln(\\alpha)-(\\alpha+1)\\ln(x_{i})\\right]\n= n\\ln(\\alpha)-(\\alpha+1)\\sum_{i=1}^{n}\\ln(x_{i}).\n$$\nThe score function is\n$$\nU(\\alpha)=\\frac{\\partial \\ell}{\\partial \\alpha}=\\frac{n}{\\alpha}-\\sum_{i=1}^{n}\\ln(x_{i}),\n$$\nand the Fisher information is\n$$\nI(\\alpha)=-\\mathbb{E}\\left[\\frac{\\partial^{2}\\ell}{\\partial \\alpha^{2}}\\right]\n=-\\mathbb{E}\\left[-\\frac{n}{\\alpha^{2}}\\right]=\\frac{n}{\\alpha^{2}}.\n$$\nRao’s score test statistic for testing $H_{0}:\\alpha=\\alpha_{0}$ is\n$$\nS=\\frac{U(\\alpha_{0})^{2}}{I(\\alpha_{0})}.\n$$\nWith $n=100$, $\\sum_{i=1}^{100}\\ln(x_{i})=75$, and $\\alpha_{0}=1.5$, compute\n$$\nU(\\alpha_{0})=\\frac{100}{1.5}-75=\\frac{200}{3}-75=\\frac{200}{3}-\\frac{225}{3}=-\\frac{25}{3},\n$$\nand\n$$\nI(\\alpha_{0})=\\frac{100}{(1.5)^{2}}=\\frac{100}{\\frac{9}{4}}=\\frac{400}{9}.\n$$\nTherefore,\n$$\nS=\\frac{\\left(-\\frac{25}{3}\\right)^{2}}{\\frac{400}{9}}=\\frac{\\frac{625}{9}}{\\frac{400}{9}}=\\frac{625}{400}=1.5625.\n$$\nRounded to four significant figures, the test statistic is $1.563$.", "answer": "$$\\boxed{1.563}$$", "id": "1953913"}]}