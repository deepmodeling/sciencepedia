{"hands_on_practices": [{"introduction": "This first exercise provides a practical application of the core ANOVA formulas. Starting with the sums of squares—the basic measures of variation between and within groups—you will compute the F-statistic step-by-step. Mastering this process is essential for understanding how ANOVA translates raw data into a testable hypothesis about group means. [@problem_id:1960654]", "problem": "An agricultural research institute is conducting a study to compare the effectiveness of four different newly developed organic fertilizer compositions on the yield of a particular crop. A total of 20 identical plots of land are available for the experiment. These plots are randomly divided into four groups, with each group of 5 plots being treated with one of the four distinct fertilizer compositions. At the end of the growing season, the crop yield is measured for each plot.\n\nA statistical analysis of the collected data reveals the following information:\n- The variation in crop yield between the four different fertilizer groups, known as the between-groups sum of squares, is 85.5.\n- The random variation in crop yield within each of the fertilizer groups, known as the within-groups sum of squares, is 131.2.\n\nTo determine if there is a statistically significant difference in the mean crop yield among the four fertilizer groups, an F-statistic must be calculated as part of an Analysis of Variance (ANOVA). Calculate the value of this F-statistic based on the data provided. Round your final answer to three significant figures.", "solution": "We have an ANOVA with four groups and a total of $N=20$ observations, so the number of groups is $k=4$. The between-groups sum of squares is given as $\\text{SSB}=85.5$, and the within-groups sum of squares is $\\text{SSW}=131.2$.\n\nThe F-statistic in a one-way ANOVA is defined as\n$$\nF=\\frac{\\text{MSB}}{\\text{MSW}},\n$$\nwhere the mean square between groups is\n$$\n\\text{MSB}=\\frac{\\text{SSB}}{df_{\\text{between}}}=\\frac{\\text{SSB}}{k-1},\n$$\nand the mean square within groups is\n$$\n\\text{MSW}=\\frac{\\text{SSW}}{df_{\\text{within}}}=\\frac{\\text{SSW}}{N-k}.\n$$\n\nCompute the degrees of freedom:\n$$\ndf_{\\text{between}}=k-1=4-1=3, \\quad df_{\\text{within}}=N-k=20-4=16.\n$$\n\nCompute the mean squares:\n$$\n\\text{MSB}=\\frac{85.5}{3}=28.5, \\quad \\text{MSW}=\\frac{131.2}{16}=8.2.\n$$\n\nTherefore, the F-statistic is\n$$\nF=\\frac{28.5}{8.2}=\\frac{285}{82}\\approx 3.475609756\\ldots\n$$\nRounded to three significant figures,\n$$\nF\\approx 3.48.\n$$", "answer": "$$\\boxed{3.48}$$", "id": "1960654"}, {"introduction": "Now, let's use a thought experiment to build deeper intuition for the F-test. What happens if, by some chance, the sample means of all your experimental groups turn out to be identical? This hypothetical scenario [@problem_id:1960676] cuts to the heart of what the numerator of the F-statistic, the Mean Square Between groups ($MSB$), truly represents and clarifies its role in the analysis.", "problem": "A team of biostatisticians is conducting a study to compare the efficacy of $k$ new drug formulations designed to lower systolic blood pressure. The study involves $N$ subjects, who are randomly assigned to one of the $k$ treatment groups. Let $n_i$ be the number of subjects in group $i$, for $i=1, \\dots, k$. The study is designed such that $k \\ge 2$ and each group has at least two subjects, i.e., $n_i \\ge 2$ for all $i$.\n\nAfter the treatment period, the reduction in systolic blood pressure is measured for each subject. Let $y_{ij}$ be the measurement for the $j$-th subject in the $i$-th group. The sample mean of the blood pressure reduction for group $i$ is denoted by $\\bar{y}_{i.}$.\n\nUpon analyzing the initial results, the team observes a peculiar outcome: the sample mean reduction is exactly the same for all $k$ groups. That is, $\\bar{y}_{1.} = \\bar{y}_{2.} = \\dots = \\bar{y}_{k.}$. However, the measurements within at least one of the groups are not all identical, which implies that there is some non-zero sample variance within the overall dataset.\n\nThe team decides to proceed with a one-way Analysis of Variance (ANOVA) to formally test for differences between the group means. Based on the observation that all sample means are identical, what is the numerical value of the F-statistic that they will compute?", "solution": "In a one-way ANOVA with $k$ groups and total sample size $N=\\sum_{i=1}^{k} n_{i}$, define the group means $\\bar{y}_{i.}=\\frac{1}{n_{i}}\\sum_{j=1}^{n_{i}} y_{ij}$ and the grand mean\n$$\n\\bar{y}_{..}=\\frac{1}{N}\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}} y_{ij}=\\frac{1}{N}\\sum_{i=1}^{k} n_{i}\\bar{y}_{i.}.\n$$\nThe between-groups sum of squares is\n$$\nSSB=\\sum_{i=1}^{k} n_{i}\\bigl(\\bar{y}_{i.}-\\bar{y}_{..}\\bigr)^{2}.\n$$\nGiven the observation that all sample means are identical, $\\bar{y}_{1.}=\\cdots=\\bar{y}_{k.}$, it follows that $\\bar{y}_{i.}=\\bar{y}_{..}$ for every $i$, hence\n$$\nSSB=\\sum_{i=1}^{k} n_{i}\\cdot 0^{2}=0.\n$$\nThe within-groups sum of squares is\n$$\nSSW=\\sum_{i=1}^{k}\\sum_{j=1}^{n_{i}}\\bigl(y_{ij}-\\bar{y}_{i.}\\bigr)^{2}.\n$$\nSince at least one group has non-identical measurements, at least one term in this sum is positive, and all terms are nonnegative, so $SSW > 0$.\n\nThe mean squares are\n$$\nMSB=\\frac{SSB}{k-1}, \\qquad MSW=\\frac{SSW}{N-k}.\n$$\nBecause $k\\ge 2$, the denominator $k-1 > 0$, hence $MSB=0$. Also, since each $n_{i}\\ge 2$ and $k\\ge 2$, we have $N\\ge 2k$ and thus $N-k\\ge k\\ge 2$, so the denominator of $MSW$ is positive and, with $SSW>0$, it follows that $MSW>0$.\n\nThe ANOVA F-statistic is\n$$\nF=\\frac{MSB}{MSW}=\\frac{0}{MSW}=0.\n$$\nTherefore, the computed F-statistic is zero.", "answer": "$$\\boxed{0}$$", "id": "1960676"}, {"introduction": "The F-statistic is ultimately a ratio comparing the variation between groups to the variation within them. This final practice [@problem_id:1960670] asks you to reason about the outcome of the test when this ratio becomes very small. By considering a case where the random, within-group variation dwarfs the systematic, between-group variation, you will strengthen your understanding of how the F-value leads to a statistical conclusion via the p-value.", "problem": "In a one-way Analysis of Variance (ANOVA), a researcher is testing the null hypothesis that the means of $k$ different groups are all equal ($H_0: \\mu_1 = \\mu_2 = \\dots = \\mu_k$). The test involves calculating two key measures of variance: the Mean Square Between groups (MSB), which quantifies the variation among the sample means of the groups, and the Mean Square Within groups (MSW), which quantifies the average variation within each of the groups.\n\nAfter collecting data and performing the initial calculations, the researcher finds that the MSW is substantially larger than the MSB. Based on this specific finding, what is the most logical inference about the p-value associated with the F-test statistic?\n\nA. The p-value will be very close to 0.\n\nB. The p-value will be very close to 1.\n\nC. The p-value will be approximately 0.5.\n\nD. The p-value cannot be determined without the specific degrees of freedom.", "solution": "We consider a one-way ANOVA with null hypothesis $H_{0}: \\mu_{1}=\\mu_{2}=\\dots=\\mu_{k}$. The standard test statistic for comparing the between-group and within-group variability is the $F$-ratio defined by\n$$\nF=\\frac{\\text{MSB}}{\\text{MSW}}.\n$$\nUnder $H_{0}$ and standard ANOVA assumptions, this statistic follows an $F$ distribution with degrees of freedom $(k-1,\\,N-k)$, where $N$ is the total sample size. That is,\n$$\nF \\sim F_{k-1,\\,N-k}\\quad \\text{under }H_{0}.\n$$\nThe ANOVA $F$-test is right-tailed, rejecting $H_{0}$ for large values of $F$. The corresponding p-value for an observed value $f_{\\text{obs}}$ is\n$$\np=\\Pr\\!\\left(F_{k-1,\\,N-k}\\ge f_{\\text{obs}}\\right)=1-F_{F_{k-1,\\,N-k}}(f_{\\text{obs}}),\n$$\nwhere $F_{F_{k-1,\\,N-k}}$ denotes the cumulative distribution function of the $F$ distribution with degrees of freedom $(k-1,\\,N-k)$.\n\nThe researcher finds that $\\text{MSW}$ is substantially larger than $\\text{MSB}$. This implies\n$$\nf_{\\text{obs}}=\\frac{\\text{MSB}}{\\text{MSW}} \\ll 1.\n$$\nBecause the $F$ distribution has support on $(0,\\infty)$ and the test is right-tailed, when $f_{\\text{obs}}$ is very small, the upper-tail probability\n$$\n\\Pr\\!\\left(F_{k-1,\\,N-k}\\ge f_{\\text{obs}}\\right)\n$$\nis close to $1$, regardless of the specific degrees of freedom. Therefore, a substantially smaller $\\text{MSB}$ relative to $\\text{MSW}$ yields a very small observed $F$ statistic and consequently a p-value very close to $1$.\n\nHence, the most logical inference is that the p-value will be very close to $1$.", "answer": "$$\\boxed{B}$$", "id": "1960670"}]}