{"hands_on_practices": [{"introduction": "In time series analysis, we often apply simple transformations to our data. A fundamental question is whether these transformations preserve the essential properties of the series, such as stationarity. This first exercise [@problem_id:1964359] explores the most basic transformation: adding a constant value to every point in a weakly stationary process, which simulates a simple shift in the baseline of the data.", "problem": "A data scientist is analyzing a time series representing daily sales fluctuations of a product. Let the true, underlying sales fluctuation process be denoted by $\\{X_t\\}$, where $t$ is the time in days. The process $\\{X_t\\}$ is known to be **weakly stationary**. A time series $\\{Z_t\\}$ is defined as weakly stationary if it satisfies the following three conditions for all valid time indices $t$ and $s$:\n1. The mean is a finite constant: $\\mathbb{E}[Z_t] = \\mu$.\n2. The variance is a finite, non-zero constant: $\\text{Var}(Z_t) = \\sigma^2$.\n3. The autocovariance between any two points depends only on the time lag between them: $\\text{Cov}(Z_t, Z_s) = \\gamma(|t-s|)$.\n\nDue to a consistent seasonal promotional event, the daily sales figures are observed to have a constant positive shift. This new observed time series is modeled as $Y_t = X_t + c$, where $c$ is a non-zero real constant representing the average increase in sales from the promotion.\n\nBased on the information provided, which of the following statements correctly describes the process $\\{Y_t\\}$?\n\nA. $Y_t$ is weakly stationary.\n\nB. $Y_t$ is not stationary because its mean depends on time $t$.\n\nC. $Y_t$ is not stationary because its variance depends on time $t$.\n\nD. $Y_t$ is not stationary because its autocovariance function depends on the specific time points $t$ and $s$, not just their lag.\n\nE. $Y_t$ cannot be weakly stationary because the constant $c$ is non-zero.", "solution": "To determine if the process $Y_t = X_t + c$ is weakly stationary, we must check if it satisfies the three conditions for weak stationarity, given that $X_t$ is a weakly stationary process.\n\nThe properties of the weakly stationary process $X_t$ are:\n- $\\mathbb{E}[X_t] = \\mu_X$, where $\\mu_X$ is a constant.\n- $\\text{Var}(X_t) = \\sigma_X^2$, where $\\sigma_X^2$ is a finite constant.\n- $\\text{Cov}(X_t, X_s) = \\gamma_X(|t-s|)$, a function only of the lag $|t-s|$.\n\nNow, let's analyze the process $Y_t = X_t + c$.\n\n**Condition 1: Mean of $Y_t$**\nWe compute the expected value of $Y_t$ using the linearity of the expectation operator.\n$$ \\mathbb{E}[Y_t] = \\mathbb{E}[X_t + c] $$\n$$ \\mathbb{E}[Y_t] = \\mathbb{E}[X_t] + \\mathbb{E}[c] $$\nSince $c$ is a constant, its expected value is just $c$. We know $\\mathbb{E}[X_t] = \\mu_X$.\n$$ \\mathbb{E}[Y_t] = \\mu_X + c $$\nLet $\\mu_Y = \\mu_X + c$. Since both $\\mu_X$ and $c$ are constants, their sum $\\mu_Y$ is also a constant. The mean of $Y_t$ does not depend on time $t$. Therefore, the first condition for weak stationarity is satisfied. This eliminates option B.\n\n**Condition 2: Variance of $Y_t$**\nWe compute the variance of $Y_t$. A key property of variance is that adding a constant to a random variable does not change its variance, i.e., $\\text{Var}(Z+k) = \\text{Var}(Z)$ for any random variable $Z$ and constant $k$.\n$$ \\text{Var}(Y_t) = \\text{Var}(X_t + c) $$\n$$ \\text{Var}(Y_t) = \\text{Var}(X_t) $$\nSince $X_t$ is weakly stationary, its variance is a constant $\\sigma_X^2$.\n$$ \\text{Var}(Y_t) = \\sigma_X^2 $$\nThe variance of $Y_t$ is a finite constant and does not depend on time $t$. Therefore, the second condition is satisfied. This eliminates option C.\n\n**Condition 3: Autocovariance of $Y_t$**\nWe compute the autocovariance of $Y_t$ between time $t$ and time $s$. A key property of covariance is its invariance to constant shifts, i.e., $\\text{Cov}(A+a, B+b) = \\text{Cov}(A,B)$ for random variables $A, B$ and constants $a, b$.\n$$ \\text{Cov}(Y_t, Y_s) = \\text{Cov}(X_t + c, X_s + c) $$\n$$ \\text{Cov}(Y_t, Y_s) = \\text{Cov}(X_t, X_s) $$\nSince $X_t$ is weakly stationary, its autocovariance depends only on the lag $|t-s|$.\n$$ \\text{Cov}(Y_t, Y_s) = \\gamma_X(|t-s|) $$\nLet $\\gamma_Y(k) = \\gamma_X(k)$ where $k = |t-s|$. The autocovariance of $Y_t$ depends only on the time lag $k$, not on the specific times $t$ and $s$. Therefore, the third condition is satisfied. This eliminates option D.\n\n**Conclusion**\nThe process $Y_t$ satisfies all three conditions for weak stationarity: its mean is constant, its variance is constant, and its autocovariance function depends only on the time lag. Thus, $Y_t$ is a weakly stationary process. The fact that $c$ is non-zero simply shifts the mean of the process but does not affect its stationarity, so option E is false. The correct statement is that $Y_t$ is weakly stationary.", "answer": "$$\\boxed{A}$$", "id": "1964359"}, {"introduction": "A process can fail to be stationary in different ways. This next practice [@problem_id:1964357] presents a hypothetical scenario where a process's mean level switches between two values depending on the time index. This exercise challenges you to meticulously apply the three conditions of weak stationarity to see which ones hold and which ones are violated, reinforcing that all three must be satisfied.", "problem": "Consider a time series process $X_t$ defined for all integers $t$. The process is constructed based on an underlying white noise process $\\epsilon_t$. The white noise process is a sequence of independent and identically distributed random variables with mean $E[\\epsilon_t] = 0$ and a constant, finite variance $Var(\\epsilon_t) = \\sigma^2 > 0$.\n\nThe process $X_t$ is defined as follows:\n$$\nX_t = \\begin{cases}\n\\epsilon_t  \\text{if } t \\text{ is an even integer} \\\\\n10 + \\epsilon_t  \\text{if } t \\text{ is an odd integer}\n\\end{cases}\n$$\n\nA time series process is considered weakly stationary (or covariance stationary) if it satisfies the following three conditions:\n1.  The mean, $E[X_t]$, is a constant that does not depend on time $t$.\n2.  The variance, $Var(X_t)$, is a constant that does not depend on time $t$.\n3.  The autocovariance, $Cov(X_t, X_{t-h})$, for any lag $h \\neq 0$, depends only on the lag $h$ and not on the time $t$.\n\nWhich of the following statements accurately describes the stationarity of the process $X_t$?\n\nA. The process is weakly stationary.\n\nB. Only condition 1 is satisfied.\n\nC. Only condition 2 is satisfied.\n\nD. Only conditions 1 and 3 are satisfied.\n\nE. Only conditions 2 and 3 are satisfied.\n\nF. None of the three conditions are satisfied.", "solution": "We analyze the three weak stationarity conditions for $X_{t}$ defined by $X_{t}=\\epsilon_{t}$ for even $t$ and $X_{t}=10+\\epsilon_{t}$ for odd $t$, where $\\{\\epsilon_{t}\\}$ is white noise with $E[\\epsilon_{t}]=0$ and $\\operatorname{Var}(\\epsilon_{t})=\\sigma^{2}$, and $\\epsilon_{t}$ are independent across $t$.\n\n1) Mean: By linearity of expectation and since adding a constant shifts the mean, we have\n$$\nE[X_{t}] =\n\\begin{cases}\nE[\\epsilon_{t}]=0  \\text{if $t$ is even} \\\\\nE[10+\\epsilon_{t}]=10+E[\\epsilon_{t}]=10  \\text{if $t$ is odd}\n\\end{cases}\n$$\nThus $E[X_{t}]$ depends on $t$ (alternates between $0$ and $10$), so condition 1 fails.\n\n2) Variance: Using $\\operatorname{Var}(a+Y)=\\operatorname{Var}(Y)$ for any constant $a$, we obtain\n$$\n\\operatorname{Var}(X_{t}) =\n\\begin{cases}\n\\operatorname{Var}(\\epsilon_{t})=\\sigma^{2}  \\text{if $t$ is even} \\\\\n\\operatorname{Var}(10+\\epsilon_{t})=\\operatorname{Var}(\\epsilon_{t})=\\sigma^{2}  \\text{if $t$ is odd}\n\\end{cases}\n$$\nHence $\\operatorname{Var}(X_{t})=\\sigma^{2}$ for all $t$, so condition 2 holds.\n\n3) Autocovariance: For $h\\neq 0$, using bilinearity of covariance, $\\operatorname{Cov}(a,Y)=0$ for constants $a$, and independence of white noise across time, we have\n$$\n\\operatorname{Cov}(X_{t},X_{t-h})\n=\\operatorname{Cov}(\\mu_{t}+\\epsilon_{t},\\,\\mu_{t-h}+\\epsilon_{t-h})\n=\\operatorname{Cov}(\\epsilon_{t},\\epsilon_{t-h}),\n$$\nwhere $\\mu_{t}\\in\\{0,10\\}$ is the deterministic shift. Since $\\epsilon_{t}$ and $\\epsilon_{t-h}$ are independent for $h\\neq 0$, $\\operatorname{Cov}(\\epsilon_{t},\\epsilon_{t-h})=0$. Therefore $\\operatorname{Cov}(X_{t},X_{t-h})=0$ for all $t$ when $h\\neq 0$, which depends only on $h$ and not on $t$. Thus condition 3 holds. For completeness, at $h=0$ the autocovariance is $\\operatorname{Var}(X_{t})=\\sigma^{2}$, which is also independent of $t$ as shown in condition 2.\n\nConclusion: Only conditions 2 and 3 are satisfied.", "answer": "$$\\boxed{E}$$", "id": "1964357"}, {"introduction": "Real-world time series often contain multiple sources of non-stationarity, such as seasonal patterns and underlying trends. This final problem [@problem_id:1964398] models such a complex scenario by combining a deterministic periodic component with a stochastic trend known as a random walk. By analyzing this composite process, you will see how different factors can simultaneously violate all three conditions of weak stationarity, highlighting the need for more advanced modeling techniques.", "problem": "A time series process $\\{X_t\\}$ for $t=1, 2, 3, \\ldots$ is constructed to model a system with both a recurring seasonal pattern and a cumulative random shock. The process is defined as an additive model:\n$$X_t = S_t + M_t$$\n\nThe components of the model are specified as follows:\n- The seasonal component is given by $S_t = A \\cos\\left(\\frac{2\\pi t}{T}\\right)$, where $A$ is a non-zero real constant representing the amplitude and $T$ is a positive integer constant representing the period of the cycle.\n- The cumulative shock component, $M_t$, is defined by a random walk process starting from zero: $M_t = M_{t-1} + \\epsilon_t$ for $t \\ge 1$, with $M_0 = 0$.\n- The term $\\{\\epsilon_t\\}$ is a white noise process, meaning the variables $\\epsilon_t$ are independent and identically distributed with a mean of zero, $E[\\epsilon_t] = 0$, and a constant, finite, non-zero variance, $Var(\\epsilon_t) = \\sigma^2$.\n\nA time series process is considered weakly stationary if it satisfies the following three fundamental conditions:\n1. The mean of the process is constant for all time $t$.\n2. The variance of the process is finite and constant for all time $t$.\n3. The autocovariance between the process values at time $t$ and $t+h$ depends only on the lag $h$ and not on the time $t$.\n\nBased on the definitions provided, which of the three conditions for weak stationarity are violated by the process $\\{X_t\\}$?\n\nA. Only condition 1 (constant mean) is violated.\n\nB. Only condition 2 (constant variance) is violated.\n\nC. Only conditions 1 and 2 are violated.\n\nD. Only conditions 2 and 3 are violated.\n\nE. All three conditions (1, 2, and 3) are violated.\n\nF. The process $\\{X_t\\}$ is weakly stationary; no conditions are violated.", "solution": "We analyze the mean, variance, and autocovariance of the process $X_{t} = S_{t} + M_{t}$, where $S_{t} = A \\cos\\left(\\frac{2\\pi t}{T}\\right)$ is deterministic and $M_{t} = \\sum_{i=1}^{t} \\epsilon_{i}$ is a random walk with $\\epsilon_{t}$ independent, identically distributed, $E[\\epsilon_{t}] = 0$, and $\\operatorname{Var}(\\epsilon_{t}) = \\sigma^{2}$.\n\nFirst, the mean:\n$$\nE[X_{t}] = E[S_{t}] + E[M_{t}] = A \\cos\\left(\\frac{2\\pi t}{T}\\right) + 0 = A \\cos\\left(\\frac{2\\pi t}{T}\\right).\n$$\nSince $A \\ne 0$, this depends on $t$ and is not constant. Therefore, condition 1 (constant mean) is violated.\n\nSecond, the variance:\n$$\n\\operatorname{Var}(X_{t}) = \\operatorname{Var}(S_{t} + M_{t}) = \\operatorname{Var}(S_{t}) + \\operatorname{Var}(M_{t}) + 2\\,\\operatorname{Cov}(S_{t}, M_{t}).\n$$\nBecause $S_{t}$ is deterministic, $\\operatorname{Var}(S_{t}) = 0$ and $\\operatorname{Cov}(S_{t}, M_{t}) = 0$. Hence,\n$$\n\\operatorname{Var}(X_{t}) = \\operatorname{Var}(M_{t}) = \\operatorname{Var}\\!\\left(\\sum_{i=1}^{t} \\epsilon_{i}\\right) = \\sum_{i=1}^{t} \\operatorname{Var}(\\epsilon_{i}) = t \\sigma^{2},\n$$\nusing independence. This is finite for each $t$ but not constant in $t$; it grows linearly. Therefore, condition 2 (constant variance) is violated.\n\nThird, the autocovariance at lag $h$:\n$$\n\\gamma_{X}(t,h) = \\operatorname{Cov}(X_{t}, X_{t+h}) = \\operatorname{Cov}(S_{t} + M_{t}, S_{t+h} + M_{t+h}).\n$$\nDeterministic terms have zero covariance with random terms, so\n$$\n\\gamma_{X}(t,h) = \\operatorname{Cov}(M_{t}, M_{t+h}).\n$$\nUsing the random walk decomposition $M_{t+h} = M_{t} + \\sum_{i=t+1}^{t+h} \\epsilon_{i}$ with independent increments,\n$$\n\\operatorname{Cov}(M_{t}, M_{t+h}) = \\operatorname{Cov}\\!\\left(M_{t}, M_{t}\\right) + \\operatorname{Cov}\\!\\left(M_{t}, \\sum_{i=t+1}^{t+h} \\epsilon_{i}\\right) = \\operatorname{Var}(M_{t}) + 0 = t \\sigma^{2}.\n$$\nThis depends on $t$ and not solely on $h$, so condition 3 (autocovariance depends only on lag) is violated.\n\nTherefore, all three conditions for weak stationarity are violated.", "answer": "$$\\boxed{E}$$", "id": "1964398"}]}