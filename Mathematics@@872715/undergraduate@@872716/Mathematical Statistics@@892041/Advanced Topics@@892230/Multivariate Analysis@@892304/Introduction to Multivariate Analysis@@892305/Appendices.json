{"hands_on_practices": [{"introduction": "The first step in any multivariate analysis is to summarize the data. While the mean vector tells us about central tendency, the sample covariance matrix, $S$, is the cornerstone for understanding the variability and inter-relationships within the data. This exercise [@problem_id:1924314] provides fundamental practice in computing this matrix from a small, bivariate dataset, reinforcing the core definition and calculation that underlies many advanced statistical methods.", "problem": "An agricultural scientist is studying a new species of plant. They collect data on the height (in centimeters) and the number of leaves for a small sample of three plants. The measurements are recorded as pairs (height, number of leaves). The three data points, treated as 2-dimensional column vectors, are:\n$$ \\mathbf{x}_1 = \\begin{pmatrix} 1 \\\\ 4 \\end{pmatrix}, \\quad \\mathbf{x}_2 = \\begin{pmatrix} 2 \\\\ 7 \\end{pmatrix}, \\quad \\mathbf{x}_3 = \\begin{pmatrix} 6 \\\\ 1 \\end{pmatrix} $$\nAssuming these three data points represent a random sample from a larger population, calculate the unbiased sample covariance matrix, $S$, for this bivariate dataset. Express your answer as a 2x2 matrix.", "solution": "To compute the unbiased sample covariance matrix for a bivariate sample, use the definition\n$$S=\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(\\mathbf{x}_{i}-\\bar{\\mathbf{x}}\\right)\\left(\\mathbf{x}_{i}-\\bar{\\mathbf{x}}\\right)^{T},$$\nwhere $n$ is the sample size and $\\bar{\\mathbf{x}}$ is the sample mean vector given by\n$$\\bar{\\mathbf{x}}=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}.$$\nWith $n=3$ and data $\\mathbf{x}_{1}=\\begin{pmatrix}1\\\\4\\end{pmatrix}$, $\\mathbf{x}_{2}=\\begin{pmatrix}2\\\\7\\end{pmatrix}$, $\\mathbf{x}_{3}=\\begin{pmatrix}6\\\\1\\end{pmatrix}$, the mean vector is\n$$\\bar{\\mathbf{x}}=\\frac{1}{3}\\begin{pmatrix}1+2+6\\\\4+7+1\\end{pmatrix}=\\begin{pmatrix}3\\\\4\\end{pmatrix}.$$\nCompute deviations:\n$$\\mathbf{d}_{1}=\\mathbf{x}_{1}-\\bar{\\mathbf{x}}=\\begin{pmatrix}-2\\\\0\\end{pmatrix},\\quad \\mathbf{d}_{2}=\\mathbf{x}_{2}-\\bar{\\mathbf{x}}=\\begin{pmatrix}-1\\\\3\\end{pmatrix},\\quad \\mathbf{d}_{3}=\\mathbf{x}_{3}-\\bar{\\mathbf{x}}=\\begin{pmatrix}3\\\\-3\\end{pmatrix}.$$\nCompute outer products:\n$$\\mathbf{d}_{1}\\mathbf{d}_{1}^{T}=\\begin{pmatrix}4&0\\\\0&0\\end{pmatrix},\\quad \\mathbf{d}_{2}\\mathbf{d}_{2}^{T}=\\begin{pmatrix}1&-3\\\\-3&9\\end{pmatrix},\\quad \\mathbf{d}_{3}\\mathbf{d}_{3}^{T}=\\begin{pmatrix}9&-9\\\\-9&9\\end{pmatrix}.$$\nSum them:\n$$\\sum_{i=1}^{3}\\mathbf{d}_{i}\\mathbf{d}_{i}^{T}=\\begin{pmatrix}4+1+9&0-3-9\\\\0-3-9&0+9+9\\end{pmatrix}=\\begin{pmatrix}14&-12\\\\-12&18\\end{pmatrix}.$$\nDivide by $n-1=2$ to obtain the unbiased sample covariance matrix:\n$$S=\\frac{1}{2}\\begin{pmatrix}14&-12\\\\-12&18\\end{pmatrix}=\\begin{pmatrix}7&-6\\\\-6&9\\end{pmatrix}.$$", "answer": "$$\\boxed{\\begin{pmatrix}7 & -6 \\\\ -6 & 9\\end{pmatrix}}$$", "id": "1924314"}, {"introduction": "Once we have a covariance matrix, we can use its components—the variances on the diagonal and the covariances off-diagonal—to answer practical questions. This practice problem [@problem_id:1924317] demonstrates how to calculate the variance of a linear combination of two random variables, a foundational skill essential for fields ranging from finance to biology. It bridges the gap between simply describing data and actively using its statistical properties for analysis.", "problem": "A sociologist is analyzing data from a study on hereditary characteristics. The study focuses on the heights of fathers and their adult sons within a certain population. Let $X_1$ be the random variable representing the height of a father and $X_2$ be the random variable representing the height of his son, with both heights measured in centimeters (cm).\n\nAfter collecting a large number of samples, the sociologist determines the covariance matrix for the random vector $[X_1, X_2]^T$. The elements of the covariance matrix, $\\Sigma$, are given as:\n- The variance of the fathers' heights, $Var(X_1) = 49 \\text{ cm}^2$.\n- The variance of the sons' heights, $Var(X_2) = 64 \\text{ cm}^2$.\n- The covariance between the fathers' and sons' heights, $Cov(X_1, X_2) = 30 \\text{ cm}^2$.\n\nThe sociologist is interested in the variability of the height difference between generations. Calculate the variance of the difference in height, $D = X_1 - X_2$. Express your answer in cm$^2$.", "solution": "We are asked for the variance of the difference $D = X_{1} - X_{2}$. For any two random variables $X$ and $Y$ and constants $a$ and $b$, the variance of a linear combination satisfies\n$$\n\\operatorname{Var}(aX + bY) = a^{2}\\operatorname{Var}(X) + b^{2}\\operatorname{Var}(Y) + 2ab\\,\\operatorname{Cov}(X,Y).\n$$\nHere, let $a=1$, $b=-1$, $X=X_{1}$, and $Y=X_{2}$. Then\n$$\n\\operatorname{Var}(D) = \\operatorname{Var}(X_{1} - X_{2}) = \\operatorname{Var}(X_{1}) + \\operatorname{Var}(X_{2}) - 2\\,\\operatorname{Cov}(X_{1},X_{2}).\n$$\nSubstituting the given values,\n$$\n\\operatorname{Var}(D) = 49 + 64 - 2 \\cdot 30 = 113 - 60 = 53.\n$$\nThus, the variance of the height difference is $53$ in $\\text{cm}^{2}$.", "answer": "$$\\boxed{53}$$", "id": "1924317"}, {"introduction": "Beyond describing existing variables, multivariate analysis provides powerful tools for transforming data into a more insightful representation. This exercise [@problem_id:1924285] introduces the core mechanism of Principal Component Analysis (PCA), a technique that creates new, uncorrelated variables that capture maximum variance. You will perform the key algebraic step of this method by finding the orthogonal transformation that diagonalizes the covariance matrix, a process equivalent to finding its eigenvalues and eigenvectors.", "problem": "An analyst is studying a simplified model of the daily percentage returns of two stocks. The returns are represented by a zero-mean random vector $\\mathbf{X} = \\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix}$, which has the covariance matrix\n$$\n\\Sigma = \\begin{pmatrix} 13 & -4 \\\\ -4 & 7 \\end{pmatrix}\n$$\nThe analyst wishes to construct a new pair of variables, called principal components, $\\mathbf{Y} = \\begin{pmatrix} Y_1 \\\\ Y_2 \\end{pmatrix}$, by applying a linear transformation $\\mathbf{Y} = \\mathbf{A} \\mathbf{X}$, where $\\mathbf{A}$ is a $2 \\times 2$ real matrix. The transformation must satisfy the following three conditions:\n1.  The new variables $Y_1$ and $Y_2$ must be uncorrelated.\n2.  The transformation matrix $\\mathbf{A}$ must be an orthogonal matrix.\n3.  To ensure a unique solution, the variance of $Y_1$ must be greater than or equal to the variance of $Y_2$, and the first entry of each row of matrix $\\mathbf{A}$ must be non-negative.\n\nDetermine the transformation matrix $\\mathbf{A}$.", "solution": "We seek a linear transformation $\\mathbf{Y}=\\mathbf{A}\\mathbf{X}$ with $\\mathbf{A}$ real $2\\times 2$, such that:\n- $Y_{1}$ and $Y_{2}$ are uncorrelated, i.e., $\\operatorname{Cov}(\\mathbf{Y})=\\mathbf{A}\\Sigma\\mathbf{A}^{\\top}$ is diagonal.\n- $\\mathbf{A}$ is orthogonal, i.e., $\\mathbf{A}\\mathbf{A}^{\\top}=\\mathbf{I}$.\n- $\\operatorname{Var}(Y_{1})\\geq\\operatorname{Var}(Y_{2})$, and the first entry of each row of $\\mathbf{A}$ is non-negative.\n\nFor a real symmetric covariance matrix $\\Sigma$, there exists an orthogonal matrix whose rows are orthonormal eigenvectors of $\\Sigma$, and this orthogonally diagonalizes $\\Sigma$. Therefore, we choose the rows of $\\mathbf{A}$ to be orthonormal eigenvectors of $\\Sigma$, ordered so that the first has the larger eigenvalue. Then $\\mathbf{A}\\Sigma\\mathbf{A}^{\\top}$ is diagonal with the eigenvalues on the diagonal.\n\nCompute eigenvalues of $\\Sigma=\\begin{pmatrix}13 & -4 \\\\ -4 & 7\\end{pmatrix}$ from the characteristic equation:\n$$\n\\det(\\Sigma-\\lambda \\mathbf{I})=\\det\\begin{pmatrix}13-\\lambda & -4 \\\\ -4 & 7-\\lambda\\end{pmatrix}\n=(13-\\lambda)(7-\\lambda)-16\n=\\lambda^{2}-20\\lambda+75=0.\n$$\nThus\n$$\n\\lambda_{1,2}=\\frac{20\\pm\\sqrt{400-300}}{2}=\\frac{20\\pm 10}{2},\n$$\nso the eigenvalues are $\\lambda_{1}=15$ and $\\lambda_{2}=5$, with $\\lambda_{1}>\\lambda_{2}$.\n\nFind a corresponding eigenvector for $\\lambda_{1}=15$ by solving $(\\Sigma-15\\mathbf{I})\\mathbf{v}=\\mathbf{0}$:\n$$\n\\begin{pmatrix}-2 & -4 \\\\ -4 & -8\\end{pmatrix}\\begin{pmatrix}x \\\\ y\\end{pmatrix}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\n\\implies -2x-4y=0 \\implies x=-2y.\n$$\nAn eigenvector is $\\begin{pmatrix}-2 \\\\ 1\\end{pmatrix}$. To satisfy the sign convention (first entry non-negative), multiply by $-1$ to get $\\begin{pmatrix}2 \\\\ -1\\end{pmatrix}$. Normalize to unit length:\n$$\n\\left\\|\\begin{pmatrix}2 \\\\ -1\\end{pmatrix}\\right\\|=\\sqrt{2^{2}+(-1)^{2}}=\\sqrt{5},\\quad\n\\mathbf{u}_{1}=\\begin{pmatrix}\\frac{2}{\\sqrt{5}} \\\\ -\\frac{1}{\\sqrt{5}}\\end{pmatrix}.\n$$\n\nFor $\\lambda_{2}=5$, solve $(\\Sigma-5\\mathbf{I})\\mathbf{v}=\\mathbf{0}$:\n$$\n\\begin{pmatrix}8 & -4 \\\\ -4 & 2\\end{pmatrix}\\begin{pmatrix}x \\\\ y\\end{pmatrix}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\n\\implies 8x-4y=0 \\implies y=2x.\n$$\nAn eigenvector is $\\begin{pmatrix}1 \\\\ 2\\end{pmatrix}$, already with a non-negative first entry. Normalize:\n$$\n\\left\\|\\begin{pmatrix}1 \\\\ 2\\end{pmatrix}\\right\\|=\\sqrt{1^{2}+2^{2}}=\\sqrt{5},\\quad\n\\mathbf{u}_{2}=\\begin{pmatrix}\\frac{1}{\\sqrt{5}} \\\\ \\frac{2}{\\sqrt{5}}\\end{pmatrix}.\n$$\n\nChoose the rows of $\\mathbf{A}$ as these orthonormal eigenvectors, ordered so that the first row corresponds to the larger eigenvalue $\\lambda_{1}=15$, ensuring $\\operatorname{Var}(Y_{1})\\geq\\operatorname{Var}(Y_{2})$. Thus\n$$\n\\mathbf{A}=\\begin{pmatrix}\n\\frac{2}{\\sqrt{5}} & -\\frac{1}{\\sqrt{5}} \\\\\n\\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}}\n\\end{pmatrix}.\n$$\nThis $\\mathbf{A}$ is orthogonal (its rows are orthonormal), has non-negative first entries in each row, and yields\n$$\n\\operatorname{Cov}(\\mathbf{Y})=\\mathbf{A}\\Sigma\\mathbf{A}^{\\top}=\\begin{pmatrix}15 & 0 \\\\ 0 & 5\\end{pmatrix},\n$$\nso $Y_{1}$ and $Y_{2}$ are uncorrelated with $\\operatorname{Var}(Y_{1})>\\operatorname{Var}(Y_{2})$, as required.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{2}{\\sqrt{5}} & -\\frac{1}{\\sqrt{5}} \\\\ \\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}}\\end{pmatrix}}$$", "id": "1924285"}]}