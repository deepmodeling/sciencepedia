{"hands_on_practices": [{"introduction": "This first exercise serves as a crucial warm-up for hierarchical modeling. It demonstrates the fundamental Bayesian mechanism of updating a general belief with specific evidence. You will see how a prior belief about the quality of all manufacturing lines—a population-level characteristic—is refined using data from a single new line to produce a more accurate posterior estimate for that specific line's performance [@problem_id:1920799].", "problem": "A technology company, \"Quantum Circuits Inc.\", manufactures highly sensitive quantum processors. The quality control process involves multiple identical fabrication lines. Based on extensive historical data from all lines, the company has established a prior belief about the defect rate, $p$, of any given fabrication line. This belief is modeled by a Beta distribution with parameters $\\alpha = 3$ and $\\beta = 147$.\n\nA new fabrication line, \"Line Gamma,\" is brought online. To assess its performance, a test batch of $n = 850$ processors is produced and inspected. In this batch, $k = 22$ defective processors are found.\n\nAssuming the number of defective processors in a batch follows a Binomial distribution, calculate the updated Bayesian point estimate for the defect rate of Line Gamma, $p_{\\gamma}$. Use the mean of the posterior distribution as your point estimate.\n\nProvide your answer as a single numerical value, rounded to three significant figures.", "solution": "We model the defect rate $p$ with a Beta prior and a Binomial likelihood. The prior is $p \\sim \\mathrm{Beta}(\\alpha,\\beta)$ with $\\alpha=3$ and $\\beta=147$. The data consist of $k=22$ defectives out of $n=850$, modeled as $k \\mid p,n \\sim \\mathrm{Binomial}(n,p)$.\n\nBy Beta-Binomial conjugacy, the posterior for $p$ is\n$$\np \\mid k,n \\sim \\mathrm{Beta}(\\alpha+k,\\ \\beta+n-k).\n$$\nSubstituting the given values,\n$$\n\\alpha_{\\text{post}}=\\alpha+k=3+22=25,\\qquad \\beta_{\\text{post}}=\\beta+n-k=147+850-22=975.\n$$\nThe posterior mean, used as the Bayesian point estimate, is\n$$\n\\mathbb{E}[p \\mid k,n]=\\frac{\\alpha_{\\text{post}}}{\\alpha_{\\text{post}}+\\beta_{\\text{post}}}\n=\\frac{\\alpha+k}{\\alpha+\\beta+n}\n=\\frac{3+22}{3+147+850}\n=\\frac{25}{1000}\n=0.025.\n$$\nRounded to three significant figures, this is $0.0250$.", "answer": "$$\\boxed{0.0250}$$", "id": "1920799"}, {"introduction": "Here, we explore the central concept of \"borrowing strength,\" a key advantage of hierarchical models. By working through a clinical trial scenario, you will derive an empirical Bayes estimate that intelligently combines a single patient's noisy measurement with the average trend observed across all patients. This process, known as shrinkage, leads to more robust and reliable estimates for individuals by leveraging the power of the group [@problem_id:1920805].", "problem": "In a clinical trial for a new cancer therapy, researchers model the treatment response for each patient. The response is characterized by a patient-specific true log-growth rate, denoted by $k_i$ for patient $i$, where a negative value indicates tumor shrinkage. The true rate $k_i$ is not directly observable. Instead, a noisy log-growth rate, $d_i$, is measured for each patient.\n\nThe researchers adopt a hierarchical Bayesian model to combine information across patients. The model is structured as follows:\n\n1.  **Observation Model**: The measured log-growth rate $d_i$ for patient $i$ is assumed to be normally distributed around the true rate $k_i$ with a known, constant variance $s^2$, representing measurement error.\n    $$d_i | k_i, s^2 \\sim \\mathcal{N}(k_i, s^2)$$\n\n2.  **Population Model**: The patient-specific true rates $k_i$ are assumed to be drawn from a common population distribution, which is normal with an unknown mean $\\mu$ and an unknown variance $\\tau^2$. This distribution represents the overall efficacy and patient-to-patient variability of the therapy.\n    $$k_i | \\mu, \\tau^2 \\sim \\mathcal{N}(\\mu, \\tau^2)$$\n\nAn initial study provides data from $N$ patients, yielding measured log-growth rates $\\{d_1, d_2, \\ldots, d_N\\}$. The population hyperparameters $\\mu$ and $\\tau^2$ are estimated from this data using the method of moments, yielding \"plug-in\" estimates $\\hat{\\mu}$ and $\\hat{\\tau}^2$. These estimates are computed as:\n-   $\\hat{\\mu} = \\bar{d}$, where $\\bar{d} = \\frac{1}{N} \\sum_{i=1}^{N} d_i$.\n-   $\\hat{\\tau}^2 = S_d^2 - s^2$, where $S_d^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (d_i - \\bar{d})^2$ is the sample variance of the measurements. You may assume that the study data is such that $S_d^2 > s^2$, ensuring $\\hat{\\tau}^2 > 0$.\n\nNow, a new patient, indexed by $N+1$, enters the trial, and their measured log-growth rate is observed to be $d_{N+1}$. Using the previously estimated hyperparameters, we want to find the best estimate for this new patient's *true* log-growth rate, $k_{N+1}$.\n\nYour task is to derive an expression for the empirical Bayes estimate of $k_{N+1}$, which is defined as its posterior mean, $E[k_{N+1} | d_{N+1}, \\hat{\\mu}, \\hat{\\tau}^2]$. Express your final answer in terms of $\\bar{d}$, $S_d^2$, $s^2$, and $d_{N+1}$.", "solution": "We start with the hierarchical model: for a new patient,\n$$d_{N+1} \\mid k_{N+1}, s^{2} \\sim \\mathcal{N}(k_{N+1}, s^{2}), \\quad k_{N+1} \\mid \\mu, \\tau^{2} \\sim \\mathcal{N}(\\mu, \\tau^{2}).$$\nUsing Bayes’ rule with the conjugate normal-normal pair, the posterior of $k_{N+1}$ given $\\mu$, $\\tau^{2}$, $s^{2}$, and $d_{N+1}$ is normal with precision equal to the sum of prior and likelihood precisions. Completing the square in the exponent,\n$$\\ln p(k_{N+1} \\mid d_{N+1}, \\mu, \\tau^{2}, s^{2})=\\text{const}-\\frac{1}{2s^{2}}(d_{N+1}-k_{N+1})^{2}-\\frac{1}{2\\tau^{2}}(k_{N+1}-\\mu)^{2},$$\nwhich is quadratic in $k_{N+1}$ with coefficient of $k_{N+1}^{2}$ equal to $\\frac{1}{s^{2}}+\\frac{1}{\\tau^{2}}$ and linear term coefficient equal to $\\frac{d_{N+1}}{s^{2}}+\\frac{\\mu}{\\tau^{2}}$. Therefore, the posterior mean is\n$$E[k_{N+1} \\mid d_{N+1}, \\mu, \\tau^{2}]=\\frac{\\frac{d_{N+1}}{s^{2}}+\\frac{\\mu}{\\tau^{2}}}{\\frac{1}{s^{2}}+\\frac{1}{\\tau^{2}}}=\\frac{\\tau^{2} d_{N+1}+s^{2}\\mu}{\\tau^{2}+s^{2}}.$$\nIn the empirical Bayes approach we plug in the method-of-moments estimates $\\hat{\\mu}=\\bar{d}$ and $\\hat{\\tau}^{2}=S_{d}^{2}-s^{2}$, yielding\n$$E[k_{N+1} \\mid d_{N+1}, \\hat{\\mu}, \\hat{\\tau}^{2}]=\\frac{(S_{d}^{2}-s^{2})\\, d_{N+1}+s^{2}\\,\\bar{d}}{(S_{d}^{2}-s^{2})+s^{2}}=\\frac{(S_{d}^{2}-s^{2})\\, d_{N+1}+s^{2}\\,\\bar{d}}{S_{d}^{2}}.$$\nEquivalently, this can be written as a shrinkage estimator\n$$\\left(1-\\frac{s^{2}}{S_{d}^{2}}\\right)d_{N+1}+\\frac{s^{2}}{S_{d}^{2}}\\bar{d},$$\nwhich makes explicit the data-driven weight $1-\\frac{s^{2}}{S_{d}^{2}}$ on $d_{N+1}$ toward the overall mean $\\bar{d}$.", "answer": "$$\\boxed{\\frac{(S_{d}^{2}-s^{2})\\, d_{N+1}+s^{2}\\,\\bar{d}}{S_{d}^{2}}}$$", "id": "1920805"}, {"introduction": "Hierarchical models are versatile and can be applied to more than just mean parameters. This practice expands your skills by focusing on the estimation of variance, modeling the precision of different experimental labs. You will use a conjugate Normal-Inverse-Gamma model to update your belief about a specific lab's measurement variance, reinforcing how the hierarchical framework provides a unified approach for learning about all aspects of a system [@problem_id:1920769].", "problem": "A research consortium is coordinating experiments across several university labs to measure a fundamental physical constant, the decay rate $\\lambda$ of a newly discovered particle. From a high-precision experiment at a national laboratory, the true value of this constant is known to be $\\lambda_{\\text{true}} = 5.20$ s$^{-1}$. The measurements from the university labs are subject to random error.\n\nA hierarchical Bayesian model is proposed to analyze the data. The measurements $x_i$ from any given lab are modeled as draws from a Normal distribution $N(\\lambda_{\\text{true}}, \\sigma^2)$, where the lab-specific variance $\\sigma^2$ is unknown. Based on prior experience with these types of experiments, the variances $\\sigma^2$ across different labs are themselves modeled as random variables drawn from a common Inverse-Gamma distribution, $IG(\\alpha, \\beta)$. The Probability Density Function (PDF) of an $IG(a, b)$ distribution is given by $p(y; a, b) = \\frac{b^a}{\\Gamma(a)} y^{-(a+1)} \\exp(-\\frac{b}{y})$ for $y > 0$. For this consortium, the hyperparameters have been established as $\\alpha = 3$ and $\\beta = 0.500$ s$^{-2}$.\n\nOne particular lab, 'Lab K', conducts an experiment and obtains the following five measurements ($n_K=5$) of the decay rate (in s$^{-1}$):\n$$ \\{5.35, 4.90, 5.70, 5.05, 5.50\\} $$\n\nCalculate the posterior expected value of the measurement variance, $\\sigma_K^2$, for Lab K, given their experimental data. Express your answer in s$^{-2}$, rounded to three significant figures.", "solution": "We model the five measurements $x_{1:n}$ from Lab K as $x_{i} \\mid \\sigma^{2} \\sim N(\\lambda_{\\text{true}}, \\sigma^{2})$ with known $\\lambda_{\\text{true}}$, and prior $\\sigma^{2} \\sim IG(\\alpha, \\beta)$ having density $p(y;\\alpha,\\beta)=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}y^{-(\\alpha+1)}\\exp\\!\\left(-\\frac{\\beta}{y}\\right)$ for $y>0$. For $n$ observations with known mean, the likelihood is proportional to\n$$\nL(\\sigma^{2}\\mid x_{1:n}) \\propto (\\sigma^{2})^{-n/2}\\exp\\!\\left(-\\frac{S}{2\\sigma^{2}}\\right),\n$$\nwhere $S=\\sum_{i=1}^{n}(x_{i}-\\lambda_{\\text{true}})^{2}$. Combining with the prior yields the conjugate posterior\n$$\n\\sigma^{2}\\mid x_{1:n} \\sim IG\\!\\left(\\alpha+\\frac{n}{2},\\,\\beta+\\frac{S}{2}\\right).\n$$\nFor $IG(a,b)$ under this parameterization, the mean exists for $a>1$ and equals $\\mathbb{E}[Y]=\\frac{b}{a-1}$. Therefore,\n$$\n\\mathbb{E}[\\sigma^{2}\\mid x_{1:n}] \\;=\\; \\frac{\\beta+\\frac{S}{2}}{\\alpha+\\frac{n}{2}-1}.\n$$\n\nFor Lab K, $\\lambda_{\\text{true}}=5.20$, $x_{1:5}=\\{5.35,\\,4.90,\\,5.70,\\,5.05,\\,5.50\\}$, $\\alpha=3$, and $\\beta=0.500$. Compute the residuals relative to $\\lambda_{\\text{true}}$:\n$$\n\\{0.15,\\,-0.30,\\,0.50,\\,-0.15,\\,0.30\\},\n$$\nso\n$$\nS=\\sum (x_{i}-\\lambda_{\\text{true}})^{2}=0.15^{2}+(-0.30)^{2}+0.50^{2}+(-0.15)^{2}+0.30^{2}=0.475.\n$$\nHence the posterior parameters are\n$$\n\\alpha^{\\prime}=\\alpha+\\frac{n}{2}=3+\\frac{5}{2}=5.5,\\qquad\n\\beta^{\\prime}=\\beta+\\frac{S}{2}=0.500+\\frac{0.475}{2}=0.7375.\n$$\nThe posterior mean of $\\sigma^{2}$ is\n$$\n\\mathbb{E}[\\sigma^{2}\\mid x_{1:5}]=\\frac{\\beta^{\\prime}}{\\alpha^{\\prime}-1}=\\frac{0.7375}{5.5-1}=\\frac{0.7375}{4.5}=\\frac{59}{360}\\approx 0.163888\\ldots\n$$\nRounded to three significant figures, this is $0.164$ in units of s$^{-2}$.", "answer": "$$\\boxed{0.164}$$", "id": "1920769"}]}