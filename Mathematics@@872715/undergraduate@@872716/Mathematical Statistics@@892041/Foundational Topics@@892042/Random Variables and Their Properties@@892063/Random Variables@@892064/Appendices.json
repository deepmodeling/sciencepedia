{"hands_on_practices": [{"introduction": "Many complex problems in probability can be simplified by using the right tool. This practice introduces the powerful technique of indicator random variables combined with the linearity of expectation. This method allows us to find the expected value of a sum of variables even when they are not independent, sidestepping difficult combinatorial calculations, as demonstrated in this classic problem set in a modern data-center context [@problem_id:1329488].", "problem": "A data center operates $N$ specialized servers, where each server is designated to run a specific computational task from a set of $N$ unique tasks. During a system-wide reboot, the task assignment scheduler malfunctions. It reassigns the $N$ tasks to the $N$ servers completely at random. The reassignment is a permutation, meaning that each server receives exactly one task and each task is assigned to exactly one server. All $N!$ possible permutations (assignments) are equally likely.\n\nWhat is the expected number of servers that are assigned their originally designated task? Express your answer as a function of $N$.", "solution": "Let $X$ be the random variable representing the total number of servers that receive their correctly designated task. We are asked to find the expected value of $X$, denoted as $E[X]$.\n\nTo solve this, we can express $X$ as a sum of indicator random variables. Let's define an indicator random variable $X_i$ for each server $i$, where $i$ ranges from $1$ to $N$. The variable $X_i$ is defined as follows:\n$$\nX_i = \\begin{cases} 1  \\text{if server } i \\text{ is assigned its correct task} \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nThe total number of correctly assigned servers, $X$, is the sum of these individual indicator variables because each $X_i$ that equals 1 contributes one count to the total.\n$$\nX = X_1 + X_2 + \\dots + X_N = \\sum_{i=1}^{N} X_i\n$$\nThe key property we will use is the linearity of expectation. This property states that the expected value of a sum of random variables is equal to the sum of their individual expected values. This holds true even if the random variables are not independent.\n$$\nE[X] = E\\left[\\sum_{i=1}^{N} X_i\\right] = \\sum_{i=1}^{N} E[X_i]\n$$\nNow, we must find the expected value of a single indicator variable, $E[X_i]$. By the definition of expected value for a discrete random variable, $E[X_i]$ is calculated as the sum of each possible value multiplied by its probability:\n$$\nE[X_i] = (1) \\cdot P(X_i = 1) + (0) \\cdot P(X_i = 0) = P(X_i = 1)\n$$\nSo, the problem reduces to finding the probability that any given server, say server $i$, is assigned its correct task.\n\nConsider server $i$. There are $N$ unique tasks available to be assigned to it. Since the assignment is completely random, each of the $N$ tasks has an equal probability of being assigned to server $i$. Only one of these tasks is the correct one for server $i$.\nTherefore, the probability that server $i$ is assigned its correct task is:\n$$\nP(X_i = 1) = \\frac{1}{N}\n$$\nThis means the expected value of the indicator variable $X_i$ is:\n$$\nE[X_i] = \\frac{1}{N}\n$$\nThis probability, and thus the expectation, is the same for every server from $i=1$ to $N$.\n\nFinally, we can substitute this result back into the sum for the total expectation $E[X]$:\n$$\nE[X] = \\sum_{i=1}^{N} E[X_i] = \\sum_{i=1}^{N} \\frac{1}{N}\n$$\nThis summation consists of $N$ identical terms, each equal to $1/N$. Therefore, the sum is:\n$$\nE[X] = N \\times \\frac{1}{N} = 1\n$$\nThe expected number of correctly assigned servers is 1. Notably, this result is independent of the total number of servers $N$ (assuming $N \\ge 1$).", "answer": "$$\\boxed{1}$$", "id": "1329488"}, {"introduction": "After understanding expectation, we often explore relationships between random variables, with covariance being a key measure of linear association. A frequent misconception is to assume that if the covariance between two variables is zero, they must be independent. This exercise provides a hands-on opportunity to challenge that assumption by constructing a specific joint distribution where covariance is zero, yet the variables are demonstrably dependent, a critical lesson for any statistician [@problem_id:1922916].", "problem": "Consider a pair of discrete random variables $(X, Y)$ whose joint probability mass function (PMF), denoted by $p(x, y) = P(X=x, Y=y)$, has non-zero values only at four specific points. These probabilities are given as:\n- $p(-1, 0) = \\frac{1}{3}$\n- $p(1, 0) = \\frac{1}{6}$\n- $p(0, -1) = \\frac{1}{4}$\n- $p(0, 1) = \\frac{1}{4}$\n\nFor all other pairs $(x, y)$, the joint PMF is $p(x, y) = 0$.\n\nYour task is to compute two quantities based on this distribution. First, calculate the covariance between $X$ and $Y$, denoted as $\\text{Cov}(X,Y)$. Second, calculate the value of $\\delta = P(X=1)P(Y=0) - P(X=1, Y=0)$, which is a measure related to the independence of the events $\\{X=1\\}$ and $\\{Y=0\\}$.\n\nPresent your final answer as an ordered pair $(\\text{Cov}(X,Y), \\delta)$.", "solution": "We use the definitions of expectation and covariance for discrete random variables. The covariance is defined by $\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]$. The given joint PMF has support at $(-1,0)$ with probability $\\frac{1}{3}$, $(1,0)$ with probability $\\frac{1}{6}$, $(0,-1)$ with probability $\\frac{1}{4}$, and $(0,1)$ with probability $\\frac{1}{4}$, and zero elsewhere. The total probability is $\\frac{1}{3}+\\frac{1}{6}+\\frac{1}{4}+\\frac{1}{4}=1$, so it is a valid PMF.\n\nFirst, compute the marginals. For $X$:\n$$\nP(X=-1)=\\frac{1}{3},\\quad P(X=1)=\\frac{1}{6},\\quad P(X=0)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}.\n$$\nFor $Y$:\n$$\nP(Y=0)=\\frac{1}{3}+\\frac{1}{6}=\\frac{1}{2},\\quad P(Y=-1)=\\frac{1}{4},\\quad P(Y=1)=\\frac{1}{4}.\n$$\n\nCompute expectations using $\\mathbb{E}[X]=\\sum_{x} x\\,P(X=x)$ and $\\mathbb{E}[Y]=\\sum_{y} y\\,P(Y=y)$:\n$$\n\\mathbb{E}[X]=(-1)\\cdot \\frac{1}{3}+1\\cdot \\frac{1}{6}+0\\cdot \\frac{1}{2}=-\\frac{1}{6},\n$$\n$$\n\\mathbb{E}[Y]=0\\cdot \\frac{1}{2}+(-1)\\cdot \\frac{1}{4}+1\\cdot \\frac{1}{4}=0.\n$$\n\nCompute $\\mathbb{E}[XY]$ using $\\mathbb{E}[XY]=\\sum_{x,y} xy\\,p(x,y)$ over the support:\n$$\n\\mathbb{E}[XY]=(-1\\cdot 0)\\cdot \\frac{1}{3}+(1\\cdot 0)\\cdot \\frac{1}{6}+(0\\cdot (-1))\\cdot \\frac{1}{4}+(0\\cdot 1)\\cdot \\frac{1}{4}=0.\n$$\n\nTherefore, by the covariance formula,\n$$\n\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]=0-\\left(-\\frac{1}{6}\\right)\\cdot 0=0.\n$$\n\nNext, compute $\\delta=P(X=1)P(Y=0)-P(X=1,Y=0)$ from the marginals and joint probability:\n$$\n\\delta=\\left(\\frac{1}{6}\\right)\\left(\\frac{1}{2}\\right)-\\frac{1}{6}=\\frac{1}{12}-\\frac{1}{6}=-\\frac{1}{12}.\n$$\n\nThus, the ordered pair $(\\operatorname{Cov}(X,Y),\\delta)$ is $\\left(0,-\\frac{1}{12}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} 0  -\\frac{1}{12} \\end{pmatrix}}$$", "id": "1922916"}, {"introduction": "The theory of random variables is not limited to discrete events; it extends seamlessly into the continuous domain. This problem transitions from discrete counts to continuous measurements, exploring a classic scenario involving uniformly distributed random variables [@problem_id:1329532]. You will apply principles of geometric probability, translating a physical constraint—the ability of three segments to form a triangle—into a problem of comparing areas within a sample space, providing a visual and intuitive way to handle joint continuous distributions.", "problem": "A fiber-optic telecommunications cable of total length $L$ is produced. During manufacturing, the cable is susceptible to point defects. It is found that for a particular batch, exactly two defects occur on each cable. The locations of these two defects along the cable's length, measured from one end, are modeled as independent random variables, each uniformly distributed over the interval $[0, L]$. A quality control procedure requires the cable to be cut at the locations of these two defects. This process results in three shorter segments of cable. For a cable to pass quality control, it must be possible to form a triangle using these three segments. What is the probability that a randomly selected cable from this batch passes the quality control check? Express your answer as an exact fraction.", "solution": "Let the two defect locations be $U$ and $V$, modeled as independent $\\mathrm{Uniform}(0,L)$ random variables. Order them as $X_{1}=\\min(U,V)$ and $X_{2}=\\max(U,V)$. Cutting at $X_{1}$ and $X_{2}$ produces segment lengths\n$$\nA=X_{1},\\quad B=X_{2}-X_{1},\\quad C=L-X_{2},\n$$\nwith $A,B,C\\geq 0$ and $A+B+C=L$.\n\nA necessary and sufficient condition for three positive lengths to form a (nondegenerate) triangle is that each length is strictly less than the sum of the other two. Because $A+B+C=L$, this is equivalent to\n$$\n\\max\\{A,B,C\\}\\frac{L}{2}.\n$$\nThe event of equality (a degenerate triangle) has probability zero and does not affect the final probability.\n\nNormalize by $L$ by defining\n$$\na=\\frac{A}{L},\\quad b=\\frac{B}{L},\\quad c=\\frac{C}{L}=1-a-b.\n$$\nThe pair $(X_{1},X_{2})$ has constant density on the triangle $\\{(x_{1},x_{2}):0\\leq x_{1}\\leq x_{2}\\leq L\\}$. The linear change of variables $(a,b)=(X_{1}/L,(X_{2}-X_{1})/L)$ has Jacobian determinant $L^{-2}$, so $(a,b)$ is uniformly distributed over the triangle\n$$\nT=\\{(a,b):a\\geq 0,\\;b\\geq 0,\\;a+b\\leq 1\\},\n$$\nwith respect to area. The area of $T$ is\n$$\n\\mathrm{Area}(T)=\\frac{1}{2}.\n$$\n\nThe triangle condition becomes\n$$\n\\max\\{a,b,1-a-b\\}\\frac{1}{2}.\n$$\nLet $S=\\{(a,b)\\in T:\\;a\\tfrac{1}{2},\\;b\\tfrac{1}{2},\\;1-a-b\\tfrac{1}{2}\\}$. Because the distribution on $T$ is uniform, the desired probability equals $\\mathrm{Area}(S)/\\mathrm{Area}(T)$.\n\nCompute $\\mathrm{Area}(S)$ by complement. In $T$, the regions $\\{a\\geq \\tfrac{1}{2}\\}$, $\\{b\\geq \\tfrac{1}{2}\\}$, and $\\{1-a-b\\geq \\tfrac{1}{2}\\}$ are three disjoint corner triangles, each congruent to the triangle with vertices $(\\tfrac{1}{2},0)$, $(1,0)$, and $(\\tfrac{1}{2},\\tfrac{1}{2})$. Each such triangle has base $\\tfrac{1}{2}$ and height $\\tfrac{1}{2}$, hence area\n$$\n\\frac{\\tfrac{1}{2}\\cdot \\tfrac{1}{2}}{2}=\\frac{1}{8}.\n$$\nTherefore,\n$$\n\\mathrm{Area}(S)=\\mathrm{Area}(T)-3\\cdot \\frac{1}{8}=\\frac{1}{2}-\\frac{3}{8}=\\frac{1}{8}.\n$$\nThus the probability is\n$$\n\\frac{\\mathrm{Area}(S)}{\\mathrm{Area}(T)}=\\frac{\\tfrac{1}{8}}{\\tfrac{1}{2}}=\\frac{1}{4}.\n$$\nThis value is independent of $L$, as expected by scale invariance.", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "1329532"}]}