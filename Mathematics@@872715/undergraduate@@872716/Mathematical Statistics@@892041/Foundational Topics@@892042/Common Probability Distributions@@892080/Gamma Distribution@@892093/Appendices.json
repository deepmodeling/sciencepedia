{"hands_on_practices": [{"introduction": "The theoretical formulas for the mean and variance of a Gamma distribution are not just abstract concepts; they are powerful tools for real-world modeling. This first exercise demonstrates a fundamental technique known as the method of moments, where we use observed statistics (like a sample mean and variance) to determine the specific parameters of the distribution that best fit our data. By working backward from the moments, you will see how to connect empirical observations to a theoretical probability model.", "problem": "A continuous random variable $X$ is said to follow a Gamma distribution with a shape parameter $\\alpha  0$ and a rate parameter $\\beta  0$, denoted as $X \\sim \\text{Gamma}(\\alpha, \\beta)$, if its probability density function (PDF) is given by:\n$$f(x; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x}$$\nfor $x  0$, and $f(x) = 0$ for $x \\le 0$. Here, $\\Gamma(\\alpha)$ is the Gamma function.\n\nThe mean (expected value) $\\mu$ and the variance $\\sigma^2$ of a Gamma-distributed random variable are given by the following formulas:\n$$ \\mu = \\frac{\\alpha}{\\beta} $$\n$$ \\sigma^2 = \\frac{\\alpha}{\\beta^2} $$\n\nGiven a Gamma distribution with a known mean $\\mu$ and a known variance $\\sigma^2$, derive an expression for the shape parameter $\\alpha$ in terms of $\\mu$ and $\\sigma^2$. Using this derived expression, calculate the specific value of $\\alpha$ for a Gamma distribution with a mean of $\\mu = 12$ and a variance of $\\sigma^2 = 36$.", "solution": "We start from the definitions\n$$\\mu = \\frac{\\alpha}{\\beta}, \\quad \\sigma^2 = \\frac{\\alpha}{\\beta^2}.$$\nSolving the first equation for $\\beta$ gives $\\beta = \\frac{\\alpha}{\\mu}$. Substituting this into the variance expression yields\n$$\\sigma^2 = \\frac{\\alpha}{\\bigl(\\frac{\\alpha}{\\mu}\\bigr)^2}\n= \\frac{\\alpha}{\\frac{\\alpha^2}{\\mu^2}}\n= \\frac{\\mu^2}{\\alpha}.$$\nRearranging leads to\n$$\\alpha = \\frac{\\mu^2}{\\sigma^2}.$$\n\nFor $\\mu = 12$ and $\\sigma^2 = 36$, we have\n$$\\alpha = \\frac{12^2}{36} = \\frac{144}{36} = 4.$$", "answer": "$$\\boxed{4}$$", "id": "7987"}, {"introduction": "Beyond the average value (mean), we often want to know the single most likely outcome, or the 'peak' of the probability distribution. This value is known as the mode, and for skewed distributions like the Gamma, it can differ significantly from the mean. In this practice problem, you will use basic calculus to find the mode of a Gamma distribution modeling the lifetime of a critical component, providing a direct and intuitive interpretation of the distribution's shape parameter.", "problem": "The operational lifetime of a critical power system on a deep-space probe is modeled as a continuous random variable $T$. This system is composed of several redundant components that activate sequentially. Due to this structure, the total lifetime $T$ (in years) is found to follow a Gamma distribution.\n\nThe probability density function (PDF) for a Gamma-distributed random variable $T$ is given by:\n$$f(t; \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} t^{\\alpha-1} \\exp(-\\beta t) \\quad \\text{for } t > 0$$\nwhere $\\Gamma(\\alpha)$ is the Gamma function, $\\alpha  0$ is the shape parameter, and $\\beta  0$ is the rate parameter.\n\nFor this specific power system, extensive testing and analysis have determined the parameters to be $\\alpha = 4.5$ and $\\beta = 0.5$ per year.\n\nDetermine the single most probable operational lifetime for this power system. Express your answer in years.", "solution": "We are asked for the single most probable operational lifetime, which is the mode of the Gamma distribution. For a Gamma random variable $T$ with parameters $\\alpha0$ and $\\beta0$ and density\n$$\nf(t;\\alpha,\\beta)=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}t^{\\alpha-1}\\exp(-\\beta t), \\quad t0,\n$$\nthe mode can be obtained by maximizing $f(t)$ over $t0$. It is convenient to maximize $\\ln f(t)$ since the logarithm is a strictly increasing function.\n\nCompute\n$$\n\\ln f(t)=\\alpha\\ln \\beta - \\ln \\Gamma(\\alpha) + (\\alpha-1)\\ln t - \\beta t.\n$$\nDifferentiate with respect to $t$:\n$$\n\\frac{d}{dt}\\ln f(t)=\\frac{\\alpha-1}{t}-\\beta.\n$$\nSet the derivative to zero for critical points:\n$$\n\\frac{\\alpha-1}{t}-\\beta=0 \\;\\;\\Longrightarrow\\;\\; t^{\\ast}=\\frac{\\alpha-1}{\\beta}.\n$$\nCheck that this is a maximum: the second derivative is\n$$\n\\frac{d^{2}}{dt^{2}}\\ln f(t)=-\\frac{\\alpha-1}{t^{2}},\n$$\nwhich is negative for all $t0$ when $\\alpha1$. Therefore, if $\\alpha1$, the unique mode is $t^{\\ast}=(\\alpha-1)/\\beta$. If $\\alpha\\leq 1$, the mode is at the boundary $t=0$. In our case, $\\alpha=4.51$, so the interior mode applies.\n\nSubstitute the given parameters $\\alpha=4.5$ and $\\beta=0.5$:\n$$\nt^{\\ast}=\\frac{4.5-1}{0.5}=\\frac{3.5}{0.5}=7.\n$$\nThus, the single most probable operational lifetime is $7$ years.", "answer": "$$\\boxed{7}$$", "id": "1919361"}, {"introduction": "The Gamma distribution often arises as the sum of independent exponential random variables, but what happens when the number of terms in that sum is itself random? This final exercise explores a fascinating scenario modeling repeated attempts over a network, where the total time is a sum of a *geometrically* distributed number of exponential waiting times. You will discover a surprising and elegant result about this mixture distribution, highlighting the deep and often non-obvious connections between different probability families.", "problem": "In a simplified model of a server attempting to communicate with a client over an unreliable network, a data packet must be transmitted repeatedly until it is received successfully.\n\nThe number of transmission attempts, $N$, required to achieve a single successful transmission follows a geometric distribution with probability of success $p$ on any given attempt. The probability mass function (PMF) for $N$ is given by $P(N=k) = (1-p)^{k-1}p$ for $k = 1, 2, 3, \\ldots$.\n\nThe time required for each individual transmission attempt, denoted by $T_i$ for the $i$-th attempt, is an independent and identically distributed random variable. Each $T_i$ follows an exponential distribution with a rate parameter $\\lambda  0$.\n\nLet $Y$ be the total time elapsed until the packet is successfully transmitted. Thus, $Y$ is the sum of the times of all attempts required, i.e., $Y = \\sum_{i=1}^{N} T_i$.\n\nDetermine the probability density function (PDF) of the total time $Y$. Your final answer should be an analytical expression for this PDF, denoted as $f_Y(y)$, for $y  0$.", "solution": "Let $N$ be geometric with parameter $p$, so $P(N=k)=(1-p)^{k-1}p$ for $k=1,2,\\ldots$. Let $\\{T_{i}\\}$ be independent and identically distributed as $\\operatorname{Exp}(\\lambda)$ and independent of the success/failure outcomes determining $N$. Define $Y=\\sum_{i=1}^{N}T_{i}$.\n\nCondition on $N=k$. Then $Y\\mid(N=k)$ is the sum of $k$ i.i.d. exponential random variables with rate $\\lambda$, hence $Y\\mid(N=k)$ has an Erlang (Gamma) distribution with shape $k$ and rate $\\lambda$, whose probability density function is\n$$\nf_{Y\\mid N=k}(y)=\\frac{\\lambda^{k}}{(k-1)!}y^{k-1}\\exp(-\\lambda y),\\quad y0.\n$$\nBy the law of total probability for densities,\n$$\nf_{Y}(y)=\\sum_{k=1}^{\\infty}P(N=k)\\,f_{Y\\mid N=k}(y),\\quad y0.\n$$\nSubstitute the expressions for $P(N=k)$ and $f_{Y\\mid N=k}(y)$:\n$$\nf_{Y}(y)=\\sum_{k=1}^{\\infty}(1-p)^{k-1}p\\cdot\\frac{\\lambda^{k}}{(k-1)!}y^{k-1}\\exp(-\\lambda y),\\quad y0.\n$$\nFactor out the terms that do not depend on $k$ and rewrite the series:\n$$\nf_{Y}(y)=p\\,\\lambda\\,\\exp(-\\lambda y)\\sum_{k=1}^{\\infty}\\frac{\\bigl((1-p)\\lambda y\\bigr)^{k-1}}{(k-1)!},\\quad y0.\n$$\nRecognize the power series for the exponential function:\n$$\n\\sum_{k=1}^{\\infty}\\frac{\\bigl((1-p)\\lambda y\\bigr)^{k-1}}{(k-1)!}=\\exp\\bigl((1-p)\\lambda y\\bigr).\n$$\nTherefore,\n$$\nf_{Y}(y)=p\\,\\lambda\\,\\exp(-\\lambda y)\\exp\\bigl((1-p)\\lambda y\\bigr)=p\\,\\lambda\\,\\exp(-p\\lambda y),\\quad y0.\n$$\nThus, the total time to a successful transmission is exponential with rate $p\\lambda$.", "answer": "$$\\boxed{p\\,\\lambda\\,\\exp(-p\\,\\lambda\\,y)}$$", "id": "1919304"}]}