{"hands_on_practices": [{"introduction": "Every probability distribution is characterized by key parameters and properties. For the chi-squared distribution, the degrees of freedom parameter, $k$, is central, directly determining its shape, mean, and variance. This first exercise reinforces this fundamental relationship and is a crucial first step in understanding the behavior of this distribution. [@problem_id:2324]", "problem": "A random variable $X$ is known to follow a chi-squared distribution, denoted as $X \\sim \\chi^2(k)$, where $k$ is the number of degrees of freedom. The chi-squared distribution is a continuous probability distribution widely used in statistical inference.\n\nThe fundamental properties of a chi-squared distribution with $k$ degrees of freedom are its mean (expected value) and variance:\n- Mean: $E[X] = k$\n- Variance: $\\text{Var}(X) = 2k$\n\nGiven that a specific chi-squared random variable $X$ has a mean value of $\\mu = 6$, derive the variance of $X$.", "solution": "For $X\\sim\\chi^2(k)$ we have the standard results  \n$$E[X]=k,\\qquad \\mathrm{Var}(X)=2k.$$  \nWe are given $E[X]=\\mu=6$, hence  \n$$k=6.$$  \nSubstituting into the variance formula gives  \n$$\\mathrm{Var}(X)=2k=2\\cdot6=12.$$", "answer": "$$\\boxed{12}$$", "id": "2324"}, {"introduction": "Beyond its properties, the true nature of a distribution is revealed by its construction. The chi-squared distribution is defined as the sum of squared independent standard normal variables. This problem challenges you to think algorithmically, translating this abstract definition into a concrete computational procedure, a skill essential for modern statistical simulation and Monte Carlo methods. [@problem_id:1903721]", "problem": "In the development of a custom statistical simulation library, a programmer is tasked with creating a function to generate random variates from a chi-squared distribution with $k$ degrees of freedom, denoted as $\\chi^2(k)$, where $k$ is a positive integer. The only available tool is a pre-existing function, `get_std_normal()`, which returns a single random number drawn from the standard normal distribution, $N(0, 1)$.\n\nThe programmer must design an algorithm that correctly produces a single random variate from the $\\chi^2(k)$ distribution by making one or more calls to `get_std_normal()`. Which of the following proposed algorithms correctly accomplishes this task?\n\nA. Initialize a variable `sum_of_squares` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, add $z^2$ to `sum_of_squares`. The final value of `sum_of_squares` is the result.\n\nB. Initialize a variable `sum_val` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, and add $z$ to `sum_val`. The final value of `sum_val` is the result.\n\nC. Initialize a variable `sum_val` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, and add $z$ to `sum_val`. The final result is `sum_val` squared.\n\nD. Call `get_std_normal()` exactly once to get a value $z$. The result is $k \\times z$.\n\nE. Initialize a variable `sum_of_squares` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, add $z^2$ to `sum_of_squares`. The final result is `sum_of_squares` divided by $k$.", "solution": "Let $Z_{1},\\dots,Z_{k}$ be independent standard normal random variables, each obtained by a call to get_std_normal(), so $Z_{i} \\sim N(0,1)$ and the $Z_{i}$ are independent. By the defining property of the chi-squared distribution, the sum of squares\n$$\nQ=\\sum_{i=1}^{k} Z_{i}^{2}\n$$\nhas the $\\chi^{2}(k)$ distribution. This can be verified, for example, via the moment generating function: for $t\\frac{1}{2}$, the mgf of $Z_{i}^{2}$ is $(1-2t)^{-1/2}$, and by independence\n$$\nM_{Q}(t)=\\prod_{i=1}^{k}(1-2t)^{-1/2}=(1-2t)^{-k/2},\n$$\nwhich is the mgf of $\\chi^{2}(k)$. Therefore, computing the sum of the squares of $k$ independent standard normals is exactly the correct algorithm.\n\nNow assess each proposed algorithm:\n\nA. This computes $Q=\\sum_{i=1}^{k} Z_{i}^{2}$, which by definition has distribution $\\chi^{2}(k)$. Hence A is correct.\n\nB. This computes $S=\\sum_{i=1}^{k} Z_{i}$, which is normal with $S \\sim N(0,k)$, not chi-squared. Hence B is incorrect.\n\nC. This computes $S^{2}$ where $S=\\sum_{i=1}^{k} Z_{i} \\sim N(0,k)$. Then $S/\\sqrt{k} \\sim N(0,1)$ and $S^{2}=k\\,(S/\\sqrt{k})^{2}$, so $S^{2}$ has the distribution $k \\cdot \\chi^{2}(1)$, which is not $\\chi^{2}(k)$ unless $k=1$. Hence C is incorrect in general.\n\nD. This computes $k Z$ for a single $Z \\sim N(0,1)$, yielding $N(0,k^{2})$, not chi-squared. Hence D is incorrect.\n\nE. This computes $\\frac{1}{k}\\sum_{i=1}^{k} Z_{i}^{2}=\\frac{1}{k}\\,\\chi^{2}(k)$, a scaled chi-squared variable, not $\\chi^{2}(k)$. Hence E is incorrect.\n\nTherefore, the only correct algorithm is A.", "answer": "$$\\boxed{A}$$", "id": "1903721"}, {"introduction": "The power of the chi-squared distribution lies in its wide-ranging applications in statistical inference. One of its most important roles is in hypothesis testing, such as the goodness-of-fit test. This final practice problem places you in the role of a researcher, using a calculated test statistic and a standard chi-squared table to determine a p-valueâ€”a core skill for drawing conclusions from data. [@problem_id:1903706]", "problem": "A team of agronomists is studying the inheritance of flower color in a newly discovered plant species. According to their genetic model, cross-breeding a specific pair of parent plants should produce offspring with four distinct flower colors (Red, Blue, Yellow, White) in a fixed theoretical ratio. To test this model, they conduct an experiment and count the number of offspring in each color category.\n\nThey use the chi-squared goodness-of-fit test. The test statistic, denoted by $X$, is calculated from the observed and expected counts. Under the assumption that their genetic model is correct (the null hypothesis), this test statistic $X$ follows a chi-squared distribution. The number of degrees of freedom ($df$) for this test is given by $k - 1$, where $k$ is the number of categories (in this case, the four flower colors).\n\nAfter completing their experiment, the agronomists calculate a test statistic value of $X_{\\text{obs}} = 6.251$. In statistical testing, the p-value is the probability of obtaining a test result at least as extreme as the one that was actually observed, assuming the null hypothesis is true. For this test, a more extreme result corresponds to a larger value of the test statistic.\n\nUsing the provided table of cumulative probabilities for the chi-squared distribution, $P(X \\le \\chi^2)$, determine the probability that a random variable following the appropriate chi-squared distribution is greater than the observed test statistic of $6.251$. Express your answer as a decimal.\n\n**Table of Cumulative Probabilities for the Chi-Squared Distribution**\nThe table below gives values of $\\chi^2$ for selected degrees of freedom ($df$) and cumulative probabilities $p$. The entry for a given row and column is the value $\\chi^2$ such that $P(X \\le \\chi^2) = p$.\n\n| | **Cumulative Probability (p)** | | | |\n| :---: | :---: | :---: | :---: | :---: |\n| **df** | **0.05** | **0.10** | **0.90** | **0.95** |\n| **2** | 0.103 | 0.211 | 4.605 | 5.991 |\n| **3** | 0.352 | 0.584 | 6.251 | 7.815 |\n| **4** | 0.711 | 1.064 | 7.779 | 9.488 |", "solution": "We have $k=4$ color categories, so the chi-squared goodness-of-fit test has degrees of freedom $df=k-1=4-1=3$. The observed test statistic is $X_{\\text{obs}}=6.251$. We want the probability $P(X6.251)$ where $X\\sim\\chi^{2}_{3}$.\n\nFrom the provided table for $df=3$, the entry at cumulative probability $p=0.90$ is $\\chi^{2}=6.251$. By definition of the table, this means $P(X\\leq 6.251)=0.90$.\n\nTherefore,\n$$\nP(X6.251)=1-P(X\\leq 6.251)=1-0.90=0.10.\n$$", "answer": "$$\\boxed{0.10}$$", "id": "1903706"}]}