{"hands_on_practices": [{"introduction": "In many practical applications, from finance to engineering, we are interested in how the combination of different random sources behaves. This exercise provides a sharp insight into the nature of covariance by relating it directly to the more familiar concept of variance. By examining the variance of the difference between two random variables, you will derive an expression for their covariance, a technique that is not only elegant but also immensely practical in fields like portfolio management for quantifying how asset returns move in relation to one another [@problem_id:1947644].", "problem": "In portfolio management, understanding the interplay between different assets is crucial for risk assessment. An analyst is examining two assets, Asset P and Asset Q. Let the random variable $X$ represent the annual return of Asset P and the random variable $Y$ represent the annual return of Asset Q.\n\nFrom historical market data, the analyst has determined the following quantities:\n- The variance of the annual return of Asset P is $Var(X) = v_P$.\n- The variance of the annual return of Asset Q is $Var(Y) = v_Q$.\n\nTo evaluate a potential hedging strategy, the analyst also considers a new portfolio constructed by taking a long position in Asset P and a short position in Asset Q. The annual return of this new portfolio is thus represented by the random variable $Z = X - Y$. The variance of this combined return has been calculated as $Var(Z) = v_Z$.\n\nBased solely on these three known variances, $v_P$, $v_Q$, and $v_Z$, derive a general expression for the covariance between the annual returns of Asset P and Asset Q, denoted as $Cov(X, Y)$.", "solution": "We are given random variables $X$ and $Y$ with variances $Var(X)=v_{P}$ and $Var(Y)=v_{Q}$, and define $Z=X-Y$ with $Var(Z)=v_{Z}$. The variance of a linear combination of two random variables is given by\n$$\nVar(aX+bY)=a^{2}Var(X)+b^{2}Var(Y)+2ab\\,Cov(X,Y).\n$$\nSet $a=1$ and $b=-1$ to match $Z=X-Y$. Then\n$$\nVar(Z)=Var(X-Y)=1^{2}Var(X)+(-1)^{2}Var(Y)+2(1)(-1)Cov(X,Y)=Var(X)+Var(Y)-2\\,Cov(X,Y).\n$$\nSubstitute the known variances:\n$$\nv_{Z}=v_{P}+v_{Q}-2\\,Cov(X,Y).\n$$\nSolve for $Cov(X,Y)$:\n$$\n2\\,Cov(X,Y)=v_{P}+v_{Q}-v_{Z} \\quad \\Rightarrow \\quad Cov(X,Y)=\\frac{v_{P}+v_{Q}-v_{Z}}{2}.\n$$", "answer": "$$\\boxed{\\frac{v_{P}+v_{Q}-v_{Z}}{2}}$$", "id": "1947644"}, {"introduction": "A crucial milestone in understanding covariance is recognizing its limitations. While independence between two random variables implies zero covariance, the reverse is not true. This practice is designed to solidify this key concept by presenting a scenario where two variables are clearly dependent, yet their covariance is zero. By working through this example [@problem_id:1947625], you will see firsthand that covariance measures only the strength of the *linear* relationship between variables, not dependence in general.", "problem": "In the development of a high-precision gyroscope, the random error in its angular velocity measurement is modeled by a continuous random variable $X$. The probability density function (PDF) for this error is given by $f(x) = C x^2$ for any $x$ in the interval $[-1, 1]$, and $f(x)=0$ otherwise. Here, $C$ is a normalization constant. To analyze potential systematic biases, an engineer wants to study the statistical relationship between the error $X$ and the square of the error $X^2$, which relates to the kinetic energy of the rotational fluctuations.\n\nCalculate the covariance between the error $X$ and its square $X^2$.", "solution": "We are given a continuous random variable $X$ with probability density function $f(x)=C x^{2}$ for $x \\in [-1,1]$ and $f(x)=0$ otherwise. First, determine the normalization constant $C$ by requiring that the total probability is one:\n$$\n\\int_{-1}^{1} f(x)\\,dx=\\int_{-1}^{1} C x^{2}\\,dx = C \\int_{-1}^{1} x^{2}\\,dx = C \\left[\\frac{x^{3}}{3}\\right]_{-1}^{1} = C \\left(\\frac{1}{3}-\\left(-\\frac{1}{3}\\right)\\right) = C \\cdot \\frac{2}{3} = 1.\n$$\nThus,\n$$\nC = \\frac{3}{2}.\n$$\nThe covariance between $X$ and $X^{2}$ is defined by\n$$\n\\operatorname{Cov}(X,X^{2}) = \\mathbb{E}[X^{3}] - \\mathbb{E}[X]\\mathbb{E}[X^{2}].\n$$\nCompute the moments needed.\n\nFirst, compute $\\mathbb{E}[X]$:\n$$\n\\mathbb{E}[X] = \\int_{-1}^{1} x f(x)\\,dx = \\int_{-1}^{1} x \\left(\\frac{3}{2} x^{2}\\right)\\,dx = \\frac{3}{2} \\int_{-1}^{1} x^{3}\\,dx = \\frac{3}{2} \\cdot 0 = 0,\n$$\nsince $x^{3}$ is an odd function integrated over a symmetric interval.\n\nNext, compute $\\mathbb{E}[X^{2}]$:\n$$\n\\mathbb{E}[X^{2}] = \\int_{-1}^{1} x^{2} f(x)\\,dx = \\int_{-1}^{1} x^{2} \\left(\\frac{3}{2} x^{2}\\right)\\,dx = \\frac{3}{2} \\int_{-1}^{1} x^{4}\\,dx = \\frac{3}{2} \\left[\\frac{x^{5}}{5}\\right]_{-1}^{1} = \\frac{3}{2} \\cdot \\frac{2}{5} = \\frac{3}{5}.\n$$\n\nFinally, compute $\\mathbb{E}[X^{3}]$:\n$$\n\\mathbb{E}[X^{3}] = \\int_{-1}^{1} x^{3} f(x)\\,dx = \\int_{-1}^{1} x^{3} \\left(\\frac{3}{2} x^{2}\\right)\\,dx = \\frac{3}{2} \\int_{-1}^{1} x^{5}\\,dx = \\frac{3}{2} \\cdot 0 = 0,\n$$\nsince $x^{5}$ is also odd over $[-1,1]$.\n\nTherefore,\n$$\n\\operatorname{Cov}(X,X^{2}) = \\mathbb{E}[X^{3}] - \\mathbb{E}[X]\\mathbb{E}[X^{2}] = 0 - 0 \\cdot \\frac{3}{5} = 0.\n$$", "answer": "$$\\boxed{0}$$", "id": "1947625"}, {"introduction": "The concepts of covariance and correlation extend naturally from pairs of variables to sequences and time series, forming the bedrock of stochastic processes. This exercise challenges you to analyze the correlation structure that emerges within cumulative sums of independent random variables, a model frequently used for phenomena like random walks or signal integration. By determining the correlation between a partial sum at an early time and a later time [@problem_id:1947618], you will uncover a fundamental principle of how memory and dependence can build up in dynamic systems.", "problem": "In the field of signal processing, it is common to analyze time-series data by examining cumulative sums. Consider a sequence of experimental measurements where the error on day $i$ is represented by a random variable $X_i$. Let the sequence of errors, $X_1, X_2, \\dots, X_n$, be independent and identically distributed (i.i.d.) random variables, each with an expected value of zero and a finite, non-zero variance $\\sigma^2$.\n\nTo study the propagation of error over time, an analyst considers the cumulative error up to day $k$, defined as the partial sum $S_k = \\sum_{i=1}^k X_i$. The analyst is interested in understanding the statistical relationship between the cumulative error at an early time point and a later one.\n\nGiven two time points $m$ and $n$ such that $1 \\le m  n$, determine the correlation coefficient, $\\rho(S_m, S_n)$, between the cumulative sum at day $m$ and the cumulative sum at day $n$. Express your answer as a closed-form analytic expression in terms of $m$ and $n$.", "solution": "Let $X_{1},\\dots,X_{n}$ be i.i.d. with $\\mathbb{E}[X_{i}]=0$ and $\\operatorname{Var}(X_{i})=\\sigma^{2}$, and define $S_{k}=\\sum_{i=1}^{k}X_{i}$. First, compute the mean and variance of $S_{k}$:\n$$\n\\mathbb{E}[S_{k}]=\\sum_{i=1}^{k}\\mathbb{E}[X_{i}]=0,\n\\qquad\n\\operatorname{Var}(S_{k})=\\sum_{i=1}^{k}\\operatorname{Var}(X_{i})=k\\sigma^{2},\n$$\nsince the $X_{i}$ are independent so all cross-covariances vanish.\n\nFor $1\\leq mn$, write $S_{n}=S_{m}+R$, where $R=\\sum_{i=m+1}^{n}X_{i}$. Because $S_{m}$ depends only on $X_{1},\\dots,X_{m}$ and $R$ depends only on $X_{m+1},\\dots,X_{n}$, independence of the $X_{i}$ implies that $S_{m}$ and $R$ are independent. Thus,\n$$\n\\operatorname{Cov}(S_{m},S_{n})\n=\\operatorname{Cov}(S_{m},S_{m}+R)\n=\\operatorname{Cov}(S_{m},S_{m})+\\operatorname{Cov}(S_{m},R)\n=\\operatorname{Var}(S_{m})+0\n=m\\sigma^{2}.\n$$\nAlso,\n$$\n\\operatorname{Var}(S_{m})=m\\sigma^{2},\\qquad \\operatorname{Var}(S_{n})=n\\sigma^{2}.\n$$\nThe correlation coefficient is\n$$\n\\rho(S_{m},S_{n})\n=\\frac{\\operatorname{Cov}(S_{m},S_{n})}{\\sqrt{\\operatorname{Var}(S_{m})\\,\\operatorname{Var}(S_{n})}}\n=\\frac{m\\sigma^{2}}{\\sqrt{(m\\sigma^{2})(n\\sigma^{2})}}\n=\\frac{m}{\\sqrt{mn}}\n=\\sqrt{\\frac{m}{n}}.\n$$", "answer": "$$\\boxed{\\sqrt{\\frac{m}{n}}}$$", "id": "1947618"}]}