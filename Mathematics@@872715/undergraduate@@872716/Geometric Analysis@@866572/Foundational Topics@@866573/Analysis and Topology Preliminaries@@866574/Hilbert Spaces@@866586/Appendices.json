{"hands_on_practices": [{"introduction": "In Euclidean geometry, orthogonality means perpendicular. In the abstract world of Hilbert spaces, this concept is generalized through the inner product, where two vectors are orthogonal if their inner product is zero. This exercise challenges our standard intuition by asking us to test for orthogonality in $\\mathbb{R}^2$ using a non-standard, weighted inner product, highlighting that geometric properties are fundamentally tied to the chosen algebraic structure [@problem_id:2301285].", "problem": "Consider the vector space $\\mathbb{R}^2$ equipped with a non-standard inner product defined as follows for any two vectors $u = (u_1, u_2)$ and $v = (v_1, v_2)$ in $\\mathbb{R}^2$:\n$$\n\\langle u, v \\rangle = 2u_1v_1 + u_2v_2\n$$\nLet a set of vectors $S$ be given by $S = \\{ (1, 1), (1, -1) \\}$.\n\nWhich of the following statements accurately describes the set $S$ with respect to the given inner product?\n\nA. The set $S$ is orthogonal.\n\nB. The set $S$ is orthonormal.\n\nC. The set $S$ is linearly independent but not orthogonal.\n\nD. The set $S$ is linearly dependent.", "solution": "We work in $\\mathbb{R}^{2}$ with inner product defined by $\\langle u,v\\rangle=2u_{1}v_{1}+u_{2}v_{2}$. Let $v_{1}=(1,1)$ and $v_{2}=(1,-1)$.\n\nTo test orthogonality, use the definition: vectors are orthogonal if their inner product is zero. Compute\n$$\n\\langle v_{1},v_{2}\\rangle=2\\cdot 1\\cdot 1+1\\cdot(-1)=2-1=1\\neq 0,\n$$\nso $S$ is not orthogonal. Therefore, it is not orthonormal either, since orthonormality requires both orthogonality and unit norms.\n\nFor completeness, compute the norms induced by the inner product. By definition, $\\|v\\|^{2}=\\langle v,v\\rangle$. Thus\n$$\n\\|v_{1}\\|^{2}=\\langle (1,1),(1,1)\\rangle=2\\cdot 1\\cdot 1+1\\cdot 1=3,\\qquad\n\\|v_{2}\\|^{2}=\\langle (1,-1),(1,-1)\\rangle=2\\cdot 1\\cdot 1+(-1)\\cdot(-1)=3.\n$$\nHence both have norm $\\sqrt{3}$, not $1$, and they are not orthogonal, so not orthonormal.\n\nTo test linear independence, use the definition: $v_{1},v_{2}$ are linearly independent if $a v_{1}+b v_{2}=(0,0)$ implies $a=b=0$. Write\n$$\na(1,1)+b(1,-1)=(a+b,\\,a-b)=(0,0).\n$$\nThis yields the system $a+b=0$ and $a-b=0$. Adding gives $2a=0$ so $a=0$, and then $b=0$. Therefore $v_{1},v_{2}$ are linearly independent.\n\nCombining these results, the set $S$ is linearly independent but not orthogonal.", "answer": "$$\\boxed{C}$$", "id": "2301285"}, {"introduction": "Orthonormal bases are the bedrock of many powerful techniques in Hilbert spaces, but how do we construct them? This practice walks through the Gram-Schmidt process, a systematic algorithm for converting any set of linearly independent vectors into an orthonormal set. By applying this process to simple polynomials, you will derive the first few Legendre polynomials, a cornerstone of mathematical physics and approximation theory [@problem_id:2301260].", "problem": "Consider the real vector space of polynomials defined on the interval $[-1, 1]$. This space is equipped with an inner product defined for any two polynomials $f(x)$ and $g(x)$ as:\n$$\n\\langle f, g \\rangle = \\int_{-1}^{1} f(x) g(x) dx\n$$\nYou are given a set of three linearly independent polynomials $S = \\{v_1(x), v_2(x), v_3(x)\\}$, where $v_1(x) = 1$, $v_2(x) = x$, and $v_3(x) = x^2$.\n\nApply the Gram-Schmidt process to the set $S$ to construct an orthonormal set of polynomials $\\{u_1(x), u_2(x), u_3(x)\\}$. Present the three resulting orthonormal polynomials as your final answer.", "solution": "We work in the real inner-product space of polynomials on $[-1,1]$ with $\\langle f,g\\rangle=\\int_{-1}^{1} f(x)g(x)\\,dx$. Apply Gram-Schmidt to $v_{1}(x)=1$, $v_{2}(x)=x$, $v_{3}(x)=x^{2}$.\n\nFirst vector: set $u_{1}'=v_{1}$. Its norm is\n$$\n\\|u_{1}'\\|=\\sqrt{\\langle v_{1},v_{1}\\rangle}=\\sqrt{\\int_{-1}^{1}1\\,dx}=\\sqrt{2}.\n$$\nThus the first orthonormal vector is\n$$\nu_{1}(x)=\\frac{v_{1}(x)}{\\|u_{1}'\\|}=\\frac{1}{\\sqrt{2}}.\n$$\n\nSecond vector: orthogonalize $v_{2}$ against $u_{1}$,\n$$\nw_{2}=v_{2}-\\langle v_{2},u_{1}\\rangle u_{1}.\n$$\nCompute the coefficient\n$$\n\\langle v_{2},u_{1}\\rangle=\\int_{-1}^{1}x\\cdot \\frac{1}{\\sqrt{2}}\\,dx=\\frac{1}{\\sqrt{2}}\\int_{-1}^{1}x\\,dx=0,\n$$\nso $w_{2}=x$. Its norm is\n$$\n\\|w_{2}\\|=\\sqrt{\\langle x,x\\rangle}=\\sqrt{\\int_{-1}^{1}x^{2}\\,dx}=\\sqrt{\\frac{2}{3}}.\n$$\nNormalize to obtain\n$$\nu_{2}(x)=\\frac{w_{2}}{\\|w_{2}\\|}=\\sqrt{\\frac{3}{2}}\\,x.\n$$\n\nThird vector: orthogonalize $v_{3}$ against $u_{1}$ and $u_{2}$,\n$$\nw_{3}=v_{3}-\\langle v_{3},u_{1}\\rangle u_{1}-\\langle v_{3},u_{2}\\rangle u_{2}.\n$$\nCompute the coefficients\n$$\n\\langle v_{3},u_{1}\\rangle=\\int_{-1}^{1}x^{2}\\cdot \\frac{1}{\\sqrt{2}}\\,dx=\\frac{1}{\\sqrt{2}}\\int_{-1}^{1}x^{2}\\,dx=\\frac{1}{\\sqrt{2}}\\cdot \\frac{2}{3}=\\frac{\\sqrt{2}}{3},\n$$\n$$\n\\langle v_{3},u_{2}\\rangle=\\int_{-1}^{1}x^{2}\\cdot \\sqrt{\\frac{3}{2}}\\,x\\,dx=\\sqrt{\\frac{3}{2}}\\int_{-1}^{1}x^{3}\\,dx=0.\n$$\nHence\n$$\nw_{3}=x^{2}-\\frac{\\sqrt{2}}{3}\\cdot \\frac{1}{\\sqrt{2}}=x^{2}-\\frac{1}{3}.\n$$\nIts norm is\n$$\n\\|w_{3}\\|=\\sqrt{\\langle w_{3},w_{3}\\rangle}=\\sqrt{\\int_{-1}^{1}\\left(x^{2}-\\frac{1}{3}\\right)^{2}dx}\n=\\sqrt{\\int_{-1}^{1}\\left(x^{4}-\\frac{2}{3}x^{2}+\\frac{1}{9}\\right)dx}\n=\\sqrt{\\frac{2}{5}-\\frac{4}{9}+\\frac{2}{9}}\n=\\sqrt{\\frac{8}{45}}.\n$$\nNormalize to obtain\n$$\nu_{3}(x)=\\frac{w_{3}}{\\|w_{3}\\|}=\\sqrt{\\frac{45}{8}}\\left(x^{2}-\\frac{1}{3}\\right)=\\sqrt{\\frac{5}{8}}\\,(3x^{2}-1).\n$$\n\nTherefore, an orthonormal set obtained from $\\{1,x,x^{2}\\}$ is\n$$\nu_{1}(x)=\\frac{1}{\\sqrt{2}},\\quad u_{2}(x)=\\sqrt{\\frac{3}{2}}\\,x,\\quad u_{3}(x)=\\sqrt{\\frac{5}{8}}\\,(3x^{2}-1).\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{\\sqrt{2}}  \\sqrt{\\frac{3}{2}}\\,x  \\sqrt{\\frac{5}{8}}\\,(3x^{2}-1)\\end{pmatrix}}$$", "id": "2301260"}, {"introduction": "One of the most powerful applications of Hilbert space geometry is finding the \"best\" approximation of a complex function using simpler ones. This exercise demonstrates the concept of orthogonal projection, which provides the solution to this approximation problem. You will project the transcendental function $\\exp(x)$ onto a subspace of linear polynomials, finding the closest possible straight-line representation in the $L^2$ sense [@problem_id:2301247].", "problem": "Consider the Hilbert space $L^2[0,1]$, which consists of all square-integrable real-valued functions on the interval $[0, 1]$. This space is equipped with the inner product defined as $\\langle f, g \\rangle = \\int_0^1 f(x)g(x) \\,dx$. Let $U$ be the two-dimensional subspace of $L^2[0,1]$ spanned by the basis functions $g_1(x) = 1$ and $g_2(x) = x$. Your task is to find the orthogonal projection of the function $f(x) = \\exp(x)$ onto this subspace $U$.\n\nExpress your answer as a function of $x$ in the form $Ax + B$, where $A$ and $B$ are constants.", "solution": "We seek the orthogonal projection of $f(x)=\\exp(x)$ onto the subspace $U=\\operatorname{span}\\{1,x\\}$ in $L^{2}[0,1]$. Let the projection be $p(x)=Ax+B$. The orthogonality conditions with respect to the basis $\\{1,x\\}$ are\n$$\n\\langle f-p,1\\rangle=\\int_{0}^{1}\\left(\\exp(x)-(Ax+B)\\right)\\,dx=0,\\quad\n\\langle f-p,x\\rangle=\\int_{0}^{1}x\\left(\\exp(x)-(Ax+B)\\right)\\,dx=0.\n$$\n\nCompute each integral symbolically:\n- Using the fundamental theorem of calculus, $\\int_{0}^{1}\\exp(x)\\,dx=\\exp(1)-1$.\n- $\\int_{0}^{1}Ax\\,dx=A\\int_{0}^{1}x\\,dx=\\frac{A}{2}$.\n- $\\int_{0}^{1}B\\,dx=B$.\nThus the first equation is\n$$\n\\left(\\exp(1)-1\\right)-\\left(\\frac{A}{2}+B\\right)=0 \\quad\\Longrightarrow\\quad \\frac{A}{2}+B=\\exp(1)-1.\n$$\n\nFor the second condition:\n- By integration by parts, $\\int x\\exp(x)\\,dx=(x-1)\\exp(x)+C$, hence\n$$\n\\int_{0}^{1}x\\exp(x)\\,dx=\\left[(x-1)\\exp(x)\\right]_{0}^{1}=0-(-1)=1.\n$$\n- $\\int_{0}^{1}x^{2}\\,dx=\\frac{1}{3}$ and $\\int_{0}^{1}x\\,dx=\\frac{1}{2}$.\nThus the second equation is\n$$\n1-A\\cdot\\frac{1}{3}-B\\cdot\\frac{1}{2}=0 \\quad\\Longrightarrow\\quad \\frac{A}{3}+\\frac{B}{2}=1.\n$$\n\nSolve the linear system\n$$\n\\frac{A}{2}+B=\\exp(1)-1,\\qquad \\frac{A}{3}+\\frac{B}{2}=1.\n$$\nFrom the first equation, $B=\\exp(1)-1-\\frac{A}{2}$. Substitute into the second:\n$$\n\\frac{A}{3}+\\frac{1}{2}\\left(\\exp(1)-1-\\frac{A}{2}\\right)=1\n\\;\\Longrightarrow\\;\n\\frac{A}{12}+\\frac{\\exp(1)-1}{2}=1\n\\;\\Longrightarrow\\;\n\\frac{A}{12}=\\frac{3-\\exp(1)}{2}\n\\;\\Longrightarrow\\;\nA=6\\left(3-\\exp(1)\\right)=18-6\\exp(1).\n$$\nThen\n$$\nB=\\exp(1)-1-\\frac{A}{2}=\\exp(1)-1-3\\left(3-\\exp(1)\\right)=4\\exp(1)-10.\n$$\n\nTherefore, the orthogonal projection is\n$$\np(x)=\\left(18-6\\exp(1)\\right)x+\\left(4\\exp(1)-10\\right).\n$$", "answer": "$$\\boxed{\\left(18-6\\exp(1)\\right)x+\\left(4\\exp(1)-10\\right)}$$", "id": "2301247"}]}