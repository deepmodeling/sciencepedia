{"hands_on_practices": [{"introduction": "The existence of smooth functions with compact support is a cornerstone of modern analysis, distinguishing the world of $C^{\\infty}$ functions from real-analytic ones. This first practice is foundational; you will construct the canonical \"bump\" function, a smooth mound that lives inside a unit ball and vanishes everywhere else. Mastering this construction and rigorously proving its smoothness is the first step toward building any partition of unity [@problem_id:3059002].", "problem": "Let $n \\in \\mathbb{N}$ and let $\\|\\cdot\\|$ denote the Euclidean norm on $\\mathbb{R}^{n}$. A function $\\eta : \\mathbb{R}^{n} \\to \\mathbb{R}$ is said to be of class $C^{\\infty}$ (infinitely continuously differentiable) if all of its partial derivatives of every order exist and are continuous on $\\mathbb{R}^{n}$. A function $\\eta$ is called radial if there exists a one-variable function $\\rho : [0,\\infty) \\to \\mathbb{R}$ such that $\\eta(x) = \\rho(\\|x\\|)$ for all $x \\in \\mathbb{R}^{n}$. A function $\\eta$ is said to have compact support in the closed unit ball $\\overline{B(0,1)} = \\{ x \\in \\mathbb{R}^{n} : \\|x\\| \\le 1 \\}$ if $\\eta(x) = 0$ whenever $\\|x\\| > 1$.\n\nUsing only the fundamental facts that compositions of $C^{\\infty}$ functions are $C^{\\infty}$, and that the exponential function and polynomial functions are $C^{\\infty}$ on their domains, construct a radial function $\\eta \\in C^{\\infty}(\\mathbb{R}^{n})$ such that $\\eta(x) = 0$ for all $\\|x\\| \\ge 1$ and $\\eta(x) > 0$ for all $\\|x\\|  1$. Prove rigorously that $\\eta$ is $C^{\\infty}$ at the boundary $\\{ x \\in \\mathbb{R}^{n} : \\|x\\| = 1 \\}$ by showing that every partial derivative of $\\eta$ of any order extends continuously to the boundary and equals $0$ there.\n\nYour final answer must be the explicit closed-form analytical expression for the constructed function $\\eta(x)$, written as a single expression. No rounding is required and no physical units are involved.", "solution": "The problem statement is a valid exercise in real analysis, specifically concerning the construction of a smooth bump function. It is mathematically well-posed, self-contained, and scientifically grounded. We shall proceed with the construction and proof.\n\nThe goal is to construct a radial function $\\eta \\in C^{\\infty}(\\mathbb{R}^{n})$ such that $\\eta(x) > 0$ for $\\|x\\|  1$ and $\\eta(x) = 0$ for $\\|x\\| \\ge 1$. The construction relies on a one-dimensional auxiliary function that is $C^{\\infty}$ but not analytic.\n\nLet us first define a function $g: \\mathbb{R} \\to \\mathbb{R}$ as follows:\n$$ g(t) = \\begin{cases} \\exp\\left(-\\frac{1}{t}\\right)  \\text{if } t > 0 \\\\ 0  \\text{if } t \\le 0 \\end{cases} $$\nWe will prove that $g(t)$ is a $C^{\\infty}$ function on $\\mathbb{R}$. The function is clearly $C^{\\infty}$ for $t \\neq 0$, as it is a composition of $C^{\\infty}$ functions (the exponential function and $t \\mapsto -1/t$) for $t > 0$, and the zero function for $t  0$. The critical point to investigate is $t=0$.\n\nFirst, we check continuity at $t=0$. The left-sided limit is $\\lim_{t \\to 0^-} g(t) = 0$, which equals $g(0)$. For the right-sided limit, let $s = 1/t$. As $t \\to 0^+$, $s \\to \\infty$.\n$$ \\lim_{t \\to 0^+} g(t) = \\lim_{t \\to 0^+} \\exp\\left(-\\frac{1}{t}\\right) = \\lim_{s \\to \\infty} \\exp(-s) = 0 $$\nSince the left and right limits both equal $g(0)$, the function $g$ is continuous at $t=0$.\n\nNext, we prove that all derivatives of $g$ exist at $t=0$ and are equal to $0$. We will show by induction that for any integer $k \\ge 0$, the $k$-th derivative of $g(t)$ for $t>0$ has the form $g^{(k)}(t) = P_k(1/t) \\exp(-1/t)$ for some polynomial $P_k$, and that the derivative at $t=0$ is $g^{(k)}(0)=0$.\n\nThe base case $k=0$ is $g(t) = P_0(1/t) \\exp(-1/t)$ with $P_0(s)=1$. We have already shown $g(0)=0$.\n\nAssume for some integer $k \\ge 0$ that for $t>0$, $g^{(k)}(t) = P_k(1/t) \\exp(-1/t)$ for some polynomial $P_k$, and that $g^{(k)}(0)=0$. For $t>0$, the $(k+1)$-th derivative is found by the chain and product rules:\n$$ g^{(k+1)}(t) = \\frac{d}{dt} \\left[ P_k\\left(\\frac{1}{t}\\right)\\exp\\left(-\\frac{1}{t}\\right) \\right] = P_k'\\left(\\frac{1}{t}\\right) \\left(-\\frac{1}{t^2}\\right) \\exp\\left(-\\frac{1}{t}\\right) + P_k\\left(\\frac{1}{t}\\right) \\exp\\left(-\\frac{1}{t}\\right) \\left(\\frac{1}{t^2}\\right) $$\nLet $s=1/t$. Then $g^{(k+1)}(t) = \\left[ -s^2 P_k'(s) + s^2 P_k(s) \\right] \\exp(-s)$. The term in the brackets, $P_{k+1}(s) = s^2(P_k(s) - P_k'(s))$, is a polynomial in $s=1/t$. Thus, the inductive form is maintained for $t>0$.\n\nNow we must show that $g^{(k+1)}(0)=0$. By definition of the derivative:\n$$ g^{(k+1)}(0) = \\lim_{t \\to 0} \\frac{g^{(k)}(t) - g^{(k)}(0)}{t} $$\nThe left-sided limit is $\\lim_{t \\to 0^-} \\frac{0-0}{t} = 0$. For the right-sided limit:\n$$ \\lim_{t \\to 0^+} \\frac{g^{(k)}(t)}{t} = \\lim_{t \\to 0^+} \\frac{1}{t} P_k\\left(\\frac{1}{t}\\right) \\exp\\left(-\\frac{1}{t}\\right) $$\nLet $s=1/t$. As $t \\to 0^+$, $s \\to \\infty$. The limit becomes $\\lim_{s \\to \\infty} s P_k(s) \\exp(-s)$. Let $Q(s) = s P_k(s)$, which is also a polynomial. We need to show that $\\lim_{s \\to \\infty} Q(s) \\exp(-s) = 0$ for any polynomial $Q$.\n\nLet $Q(s)$ be a polynomial of degree $m$. It is sufficient to show that $\\lim_{s \\to \\infty} s^j \\exp(-s) = 0$ for any non-negative integer $j$. From the Taylor series expansion of the exponential function, we know that for $s>0$, $\\exp(s) = \\sum_{k=0}^{\\infty} \\frac{s^k}{k!}$. Since all terms are positive, we can bound $\\exp(s)$ from below by any single term, for instance, $\\exp(s) > \\frac{s^{j+1}}{(j+1)!}$.\nThis gives us the inequality for $s>0$:\n$$ 0  s^j \\exp(-s) = \\frac{s^j}{\\exp(s)}  \\frac{s^j}{s^{j+1}/(j+1)!} = \\frac{(j+1)!}{s} $$\nAs $s \\to \\infty$, the term $\\frac{(j+1)!}{s} \\to 0$. By the Squeeze Theorem, we conclude that $\\lim_{s \\to \\infty} s^j \\exp(-s) = 0$. This holds for any term in the polynomial $Q(s)$, so $\\lim_{s \\to \\infty} Q(s) \\exp(-s) = 0$.\n\nThus, $g^{(k+1)}(0) = 0$. By induction, $g^{(k)}(0)=0$ for all $k \\ge 0$. This confirms that $g(t)$ is of class $C^{\\infty}$ on $\\mathbb{R}$.\n\nNow, we construct the desired function $\\eta(x)$. The function must be radial, so it will depend on $\\|x\\|$. We want it to be positive for $\\|x\\|  1$ and zero for $\\|x\\| \\ge 1$. Let us define $\\eta(x)$ using our $C^{\\infty}$ function $g(t)$:\n$$ \\eta(x) = g(1-\\|x\\|^2) $$\nwhere $\\|x\\|^2 = \\sum_{i=1}^n x_i^2$. Let's analyze this function:\n1.  If $\\|x\\|  1$, then $0  \\|x\\|^2  1$, which implies $1-\\|x\\|^2 > 0$. In this case, $\\eta(x) = \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right)$. Since the argument of the exponential is finite, $\\eta(x) > 0$.\n2.  If $\\|x\\| \\ge 1$, then $\\|x\\|^2 \\ge 1$, which implies $1-\\|x\\|^2 \\le 0$. In this case, by definition of $g$, $\\eta(x) = 0$.\n\nThis function satisfies the positivity and support conditions. We must now prove that $\\eta(x)$ is of class $C^{\\infty}(\\mathbb{R}^n)$.\nLet $u(x) = 1-\\|x\\|^2$. As $\\|x\\|^2$ is a polynomial in the components of $x$, $u(x)$ is a $C^{\\infty}$ function on $\\mathbb{R}^n$. Our function is $\\eta(x) = g(u(x))$.\n\n-   In the open ball $B(0,1) = \\{x \\in \\mathbb{R}^n : \\|x\\|  1\\}$, the function $u(x)$ maps to the interval $(0, 1]$. On this interval for its argument, $g$ is $C^{\\infty}$. Since $\\eta(x)$ is a composition of $C^{\\infty}$ functions ($g$ and $u$) in this domain, it is $C^{\\infty}$ on $B(0,1)$.\n-   In the open set $\\{x \\in \\mathbb{R}^n : \\|x\\| > 1\\}$, $u(x)  0$, so $\\eta(x)$ is identically zero. The zero function is $C^{\\infty}$.\n-   The critical region is the boundary sphere $S^{n-1} = \\{x \\in \\mathbb{R}^n : \\|x\\|=1\\}$. We must show that for any multi-index $\\alpha$, the partial derivative $\\partial^{\\alpha}\\eta(x)$ is continuous at any point $x_0$ with $\\|x_0\\|=1$. Since $\\partial^{\\alpha}\\eta(x) = 0$ for $\\|x\\|>1$, we need to show that $\\lim_{x \\to x_0, \\|x\\|1} \\partial^{\\alpha}\\eta(x) = 0$.\n\nThe partial derivatives of $\\eta(x) = g(u(x))$ for $\\|x\\|1$ are found using the multivariate chain rule (FaÃ  di Bruno's formula). Any partial derivative $\\partial^{\\alpha}\\eta$ is a sum of terms of the form:\n$$ C \\cdot g^{(k)}(u(x)) \\cdot \\prod_{j} (\\partial^{\\beta_j} u(x)) $$\nwhere $1 \\le k \\le |\\alpha|$, $C$ is a constant, and $\\beta_j$ are multi-indices. The derivatives of $u(x)=1-\\|x\\|^2$ are polynomials in the components of $x$ (e.g., $\\partial_i u = -2x_i$, $\\partial_i \\partial_j u = -2\\delta_{ij}$, and higher derivatives are zero). Therefore, for $\\|x\\|1$, $\\partial^{\\alpha}\\eta(x)$ can be expressed as a finite sum:\n$$ \\partial^{\\alpha}\\eta(x) = \\sum_{k=1}^{|\\alpha|} Q_k(x) g^{(k)}(1-\\|x\\|^2) $$\nwhere each $Q_k(x)$ is a polynomial in the components $x_1, \\ldots, x_n$.\nFor $\\|x\\|1$, we have $1-\\|x\\|^2 > 0$, so we can substitute the form of $g^{(k)}$:\n$$ \\partial^{\\alpha}\\eta(x) = \\sum_{k=1}^{|\\alpha|} Q_k(x) P_k\\left(\\frac{1}{1-\\|x\\|^2}\\right) \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right) $$\nwhere $P_k$ are the polynomials from our analysis of $g(t)$. Let $x_0$ be a point with $\\|x_0\\|=1$. We examine the limit of a generic term in the sum as $x \\to x_0$ from within the ball $\\|x\\|1$:\n$$ \\lim_{x \\to x_0, \\|x\\|1} Q_k(x) P_k\\left(\\frac{1}{1-\\|x\\|^2}\\right) \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right) $$\nLet $t=1-\\|x\\|^2$. As $x \\to x_0$ with $\\|x\\|1$, we have $t \\to 0^+$. The polynomial $Q_k(x)$ is continuous, so $\\lim_{x\\to x_0} Q_k(x) = Q_k(x_0)$. The limit becomes:\n$$ Q_k(x_0) \\cdot \\lim_{t \\to 0^+} P_k\\left(\\frac{1}{t}\\right) \\exp\\left(-\\frac{1}{t}\\right) $$\nAs established during the analysis of $g(t)$, this limit is $0$. Since every term in the sum for $\\partial^{\\alpha}\\eta(x)$ approaches $0$ as $x \\to x_0$, we have $\\lim_{x \\to x_0, \\|x\\|1} \\partial^{\\alpha}\\eta(x) = 0$.\nSince $\\partial^{\\alpha}\\eta(x) \\equiv 0$ for $\\|x\\|>1$, the limit from outside the ball is also $0$. Thus, for any multi-index $\\alpha$, the partial derivative $\\partial^{\\alpha}\\eta(x)$ is continuous across the boundary $\\|x\\|=1$ and equals $0$ on it.\nThis completes the proof that $\\eta(x)$ is of class $C^{\\infty}$ on all of $\\mathbb{R}^n$.\n\nThe constructed function is:\n$$ \\eta(x) = \\begin{cases} \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right)  \\text{if } \\|x\\|  1 \\\\ 0  \\text{if } \\|x\\| \\ge 1 \\end{cases} $$\nThis function is radial, $C^{\\infty}$ on $\\mathbb{R}^n$, positive on the open unit ball, and zero on and outside the boundary of the unit ball, as required.", "answer": "$$\n\\boxed{\n\\eta(x) = \\begin{cases} \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right)  \\text{if } \\|x\\|  1 \\\\ 0  \\text{if } \\|x\\| \\ge 1 \\end{cases}\n}\n$$", "id": "3059002"}, {"introduction": "With the basic bump function in hand, we can build more versatile tools. This exercise challenges you to construct a \"plateau\" function, which is constant and equal to one on a smaller ball and smoothly transitions to zero, all while being supported within a larger ball. Such functions are essential for smoothly \"cutting off\" other functions, a common task when localizing properties in geometric analysis [@problem_id:3058989].", "problem": "Let $n\\in\\mathbb{N}$ and consider the Euclidean space $\\mathbb{R}^{n}$ with the Euclidean norm $|x|$. Using only core definitions and well-tested facts from geometric analysis (in particular the definitions of support, smooth functions, and Lebesgue measure), construct explicitly a function $f\\in C^{\\infty}(\\mathbb{R}^{n})$ whose support satisfies $\\operatorname{supp} f\\subset B(0,1)$ and which is identically $1$ on $B(0,1/2)$. Explain, from first principles, what the geometric shape of $\\operatorname{supp} f$ is and why. Finally, compute the exact $n$-dimensional Lebesgue measure of $\\operatorname{supp} f$ and present it as a closed-form analytic expression. Your final answer must be a single analytic expression. Do not approximate or round.", "solution": "The problem is valid as it is a standard, well-posed problem in geometric analysis, specifically concerning the construction of smooth bump functions, a fundamental tool for creating partitions of unity. The premises are mathematically sound and the objectives are clearly defined.\n\nWe proceed with the explicit construction of the function $f(x)$, the characterization of its support, and the computation of the measure of its support.\n\n**Part 1: Explicit Construction of the Function $f$**\n\nThe construction of a smooth bump function is typically achieved by composing a basic smooth transition function with a radial coordinate.\n\n**Step 1.1: The Auxiliary Function $h(t)$**\nFirst, we define an auxiliary function $h: \\mathbb{R} \\to \\mathbb{R}$ which is smooth but non-analytic. Let\n$$\nh(t) = \\begin{cases} \\exp(-1/t)  \\text{if } t > 0 \\\\ 0  \\text{if } t \\le 0 \\end{cases}\n$$\nWe must establish that $h(t)$ is a smooth function, i.e., $h \\in C^{\\infty}(\\mathbb{R})$. For $t0$, $h(t)$ is constant ($0$), so it is smooth. For $t>0$, $h(t) = \\exp(-1/t)$ is a composition of smooth functions, so it is smooth. The only point of concern is $t=0$. We must show that all derivatives of $h(t)$ exist at $t=0$ and are equal to $0$.\n\nWe can show by induction that for $t>0$, the $k$-th derivative of $h(t)$ has the form $h^{(k)}(t) = P_k(1/t) \\exp(-1/t)$ for some polynomial $P_k$.\nFor $k=0$, $h^{(0)}(t) = h(t) = 1 \\cdot \\exp(-1/t)$, so $P_0(y) = 1$.\nAssume the statement holds for some $k \\ge 0$. Then for $t>0$:\n$$\nh^{(k+1)}(t) = \\frac{d}{dt} \\left( P_k(1/t) \\exp(-1/t) \\right) = P_k'(1/t) \\cdot \\left(-\\frac{1}{t^2}\\right) \\exp(-1/t) + P_k(1/t) \\cdot \\exp(-1/t) \\cdot \\left(\\frac{1}{t^2}\\right)\n$$\n$$\nh^{(k+1)}(t) = \\left( \\frac{1}{t^2} (P_k(1/t) - P_k'(1/t)) \\right) \\exp(-1/t)\n$$\nLetting $y=1/t$, the term in the parenthesis is a polynomial in $y$. Let $Q(y) = y^2(P_k(y) - P_k'(y))$. Then $h^{(k+1)}(t) = Q(1/t) \\exp(-1/t)$. This completes the induction.\n\nNow we show that $\\lim_{t \\to 0^+} h^{(k)}(t) = 0$ for all $k \\ge 0$. This is equivalent to showing $\\lim_{y \\to \\infty} P_k(y) \\exp(-y) = 0$. Since the exponential function grows faster than any polynomial, this limit is indeed $0$. By the definition of the derivative, $h^{(k)}(0) = \\lim_{t \\to 0} \\frac{h^{(k-1)}(t) - h^{(k-1)}(0)}{t}$. Since the left-sided derivatives are all $0$ and we have shown the right-sided limits of all derivatives are $0$, we conclude that $h^{(k)}(0)=0$ for all $k \\ge 0$. Thus, $h \\in C^{\\infty}(\\mathbb{R})$.\n\n**Step 1.2: The Smooth Step Function $g(t)$**\nUsing $h(t)$, we construct a function $g(t)$ that transitions smoothly from $0$ to $1$ over the interval $[0,1]$. Let\n$$\ng(t) = \\frac{h(t)}{h(t) + h(1-t)}\n$$\nThe denominator $h(t) + h(1-t)$ is never zero for any $t \\in \\mathbb{R}$, because for it to be zero, both $h(t)$ and $h(1-t)$ must be zero, which would require $t \\le 0$ and $1-t \\le 0$ simultaneously. This implies $t \\le 0$ and $t \\ge 1$, which is impossible. Since $h$ is smooth and the denominator is never zero, $g(t)$ is a smooth function, $g \\in C^{\\infty}(\\mathbb{R})$.\nThe properties of $g(t)$ are:\n- If $t \\le 0$, $h(t)=0$, so $g(t) = 0$.\n- If $t \\ge 1$, $h(1-t)=0$, so $g(t) = \\frac{h(t)}{h(t)} = 1$.\n- If $0  t  1$, $0  g(t)  1$.\n\n**Step 1.3: The Final Function $f(x)$**\nThe problem requires a radially symmetric function. We want $f(x)$ to be $1$ for $|x| \\le 1/2$ and to be $0$ for $|x|$ large enough so that its support is contained in $B(0,1)$. We can choose the transition to occur in the radial interval $[1/2, 3/4]$.\n\nLet's define a normalized radial variable $t$:\n$$\nt(r) = \\frac{r - 1/2}{3/4 - 1/2} = \\frac{r - 1/2}{1/4} = 4r - 2\n$$\nWhen $r = |x| = 1/2$, $t=0$. When $r = |x| = 3/4$, $t=1$.\nWe define our function $f: \\mathbb{R}^n \\to \\mathbb{R}$ as:\n$$\nf(x) = 1 - g(4|x| - 2)\n$$\nLet's verify its properties:\n- If $|x| \\le 1/2$, then $4|x| - 2 \\le 0$. Thus $g(4|x| - 2) = 0$, and $f(x) = 1 - 0 = 1$. This satisfies the condition that $f(x) \\equiv 1$ on $B(0,1/2)$ (and on its closure).\n- If $|x| \\ge 3/4$, then $4|x| - 2 \\ge 1$. Thus $g(4|x| - 2) = 1$, and $f(x) = 1 - 1 = 0$.\n- If $1/2  |x|  3/4$, then $0  4|x| - 2  1$. Thus $0  g(4|x| - 2)  1$, which implies $0  f(x)  1$.\n\nThe function $f(x)$ is $C^{\\infty}(\\mathbb{R}^n)$. For any $x \\neq 0$, $|x|$ is a smooth function of $x$. Since $g$ is smooth, their composition $f(x)$ is smooth. At $x=0$, we have $|x|  1/2$, so $f(x)$ is locally constant (equal to $1$) in a neighborhood of the origin. A constant function is smooth. Therefore, $f \\in C^{\\infty}(\\mathbb{R}^n)$.\n\n**Part 2: The Support of $f$**\n\nThe support of a function, denoted $\\operatorname{supp} f$, is defined as the closure of the set of points where the function is non-zero:\n$$\n\\operatorname{supp} f = \\overline{\\{x \\in \\mathbb{R}^n \\mid f(x) \\neq 0\\}}\n$$\nFrom our construction of $f(x)$:\n- $f(x) = 0$ if and only if $g(4|x|-2) = 1$. This occurs when $4|x|-2 \\ge 1$, which is equivalent to $4|x| \\ge 3$, or $|x| \\ge 3/4$.\n- $f(x) \\neq 0$ if and only if $|x|  3/4$.\nSo, the set where $f(x)$ is non-zero is precisely the open ball of radius $3/4$ centered at the origin:\n$$\n\\{x \\in \\mathbb{R}^n \\mid f(x) \\neq 0\\} = B(0, 3/4) = \\{x \\in \\mathbb{R}^n \\mid |x|  3/4\\}\n$$\nThe support is the closure of this set:\n$$\n\\operatorname{supp} f = \\overline{B(0, 3/4)} = \\{x \\in \\mathbb{R}^n \\mid |x| \\le 3/4\\}\n$$\nThis set is the closed $n$-dimensional ball of radius $R = 3/4$ centered at the origin. Geometrically, this is a closed interval for $n=1$, a closed disk for $n=2$, a solid sphere for $n=3$, and a solid $n$-hyperball in general.\n\nThe problem requires $\\operatorname{supp} f \\subset B(0,1)$. Our support is $\\overline{B(0, 3/4)}$. For any point $x \\in \\overline{B(0, 3/4)}$, we have $|x| \\le 3/4$. Since $3/4  1$, it follows that $|x|  1$, which means $x \\in B(0,1)$. Thus, the condition $\\overline{B(0, 3/4)} \\subset B(0,1)$ is satisfied.\n\n**Part 3: Lebesgue Measure of the Support**\n\nWe need to compute the $n$-dimensional Lebesgue measure, $\\lambda_n$, of $\\operatorname{supp} f = \\overline{B(0, 3/4)}$. The Lebesgue measure of a closed ball is the same as that of the corresponding open ball, which is its volume. The volume of an $n$-dimensional ball of radius $R$ is given by the well-known formula:\n$$\nV_n(R) = \\frac{\\pi^{n/2}}{\\Gamma(\\frac{n}{2} + 1)} R^n\n$$\nwhere $\\Gamma$ is the Gamma function.\n\nFor our case, the radius is $R = 3/4$. Substituting this into the formula gives:\n$$\n\\lambda_n(\\operatorname{supp} f) = V_n(3/4) = \\frac{\\pi^{n/2}}{\\Gamma(\\frac{n}{2} + 1)} \\left(\\frac{3}{4}\\right)^n\n$$\nThis is the required exact, closed-form analytic expression for the measure of the support of our constructed function $f$.", "answer": "$$\\boxed{\\frac{\\pi^{n/2}}{\\Gamma\\left(\\frac{n}{2} + 1\\right)} \\left(\\frac{3}{4}\\right)^n}$$", "id": "3058989"}, {"introduction": "Partitions of unity are not just an elegant construction; they are a powerful tool for solving concrete problems. This practice demonstrates their utility in a classic analytical task: evaluating an integral with a singularity. By using a partition of unity to decompose the function, you will see how to isolate the problematic singularity and handle it separately, showcasing the \"divide and conquer\" power of this method [@problem_id:3058995].", "problem": "Let $\\mathbb{R}^{2}$ be covered by the two open sets $U_{1} = B(0,2)$ and $U_{2} = \\mathbb{R}^{2} \\setminus \\overline{B(0,1)}$. Let $\\chi \\in C_{c}^{\\infty}(\\mathbb{R}^{2})$ satisfy $0 \\leq \\chi \\leq 1$, $\\chi \\equiv 1$ on $B(0,1)$, and $\\mathrm{supp}(\\chi) \\subset B(0,2)$. Define $\\psi := 1 - \\chi$. Then $(\\chi,\\psi)$ is a partition of unity subordinate to $\\{U_{1},U_{2}\\}$ in the sense that $\\chi + \\psi \\equiv 1$, $\\mathrm{supp}(\\chi) \\subset U_{1}$, and $\\mathrm{supp}(\\psi) \\subset U_{2}$. Consider the singular kernel $x \\mapsto \\ln|x|$ and the smooth function $f(x) := \\exp(-|x|^{2})$. Define\n$$\nI := \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta f(x) \\, dx.\n$$\nUsing only the core definitions of partitions of unity, properties of smooth functions, and standard integration by parts in $\\mathbb{R}^{2}$, do the following:\n- Explain why the partition of unity localizes $I$ by writing $f = \\chi f + \\psi f$ and hence $I = \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\chi f) \\, dx + \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\psi f) \\, dx$.\n- Argue why the second integral is taken entirely over a region where $\\ln|x|$ is smooth and can be treated by classical integration by parts without producing any singular contribution.\n- For the first integral, justify rigorously how to isolate the singularity in a ball by introducing a small radius $\\varepsilon > 0$, restricting the domain to an annulus, and applying the divergence theorem (integration by parts) to reduce the computation to a boundary term on $\\partial B(0,\\varepsilon)$. Carefully take the limit as $\\varepsilon \\to 0$.\nCompute the exact value of $I$. Express the final answer in exact form.", "solution": "The value to compute is the integral $I := \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta f(x) \\, dx$, where $f(x) = \\exp(-|x|^{2})$. The integral is improper due to the singularity of $\\ln|x|$ at $x=0$. We use the provided partition of unity $(\\chi, \\psi)$ to analyze the integral.\n\nFirst, we decompose the function $f$ using the partition of unity: $f(x) = 1 \\cdot f(x) = (\\chi(x) + \\psi(x))f(x) = \\chi(x)f(x) + \\psi(x)f(x)$. By the linearity of the Laplacian operator $\\Delta$ and the integral, we can write $I$ as the sum of two integrals:\n$$\nI = \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\chi f)(x) \\, dx + \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\psi f)(x) \\, dx =: I_{1} + I_{2}.\n$$\nThis decomposition localizes the problem. The first integral, $I_{1}$, involves a function $\\chi f$ with support near the origin, thus containing the singularity of $\\ln|x|$. The second integral, $I_{2}$, involves a function $\\psi f$ whose support is away from the origin, thus avoiding the singularity.\n\nLet's analyze the second integral, $I_{2}$. The integrand is $\\ln|x| \\Delta(\\psi f)(x)$. The support of the function $\\psi f$ is contained in $\\mathrm{supp}(\\psi)$. We are given that $\\mathrm{supp}(\\psi) \\subset U_{2} = \\mathbb{R}^{2} \\setminus \\overline{B(0,1)}$. This means that for any $x$ in the domain of integration of $I_{2}$, we have $|x| \\ge 1$. In this region, the function $x \\mapsto \\ln|x|$ is smooth ($C^{\\infty}$). The function $\\psi f$ is smooth and has compact support. Let $g(x) := (\\psi f)(x)$. Then $I_{2} = \\int_{\\mathbb{R}^2} \\ln|x| \\Delta g(x) dx$. We can use Green's Second Identity, which states that for smooth functions $u$ and $v$ where at least one has compact support, $\\int_{\\mathbb{R}^2} (u \\Delta v - v \\Delta u) dx = 0$. Let $u(x) = \\ln|x|$ and $v(x) = g(x)$. Then,\n$$\nI_{2} = \\int_{\\mathbb{R}^{2}} g(x) \\Delta(\\ln|x|) \\, dx.\n$$\nWe compute the Laplacian of $\\ln|x|$ for $x \\neq 0$. Let $r = |x| = \\sqrt{x_{1}^{2} + x_{2}^{2}}$. Then $\\ln|x| = \\ln r$. The gradient is $\\nabla(\\ln r) = \\frac{x}{r^{2}}$. The Laplacian is $\\Delta(\\ln r) = \\nabla \\cdot \\nabla(\\ln r) = \\nabla \\cdot (\\frac{x}{r^2})$. In Cartesian coordinates,\n$$\n\\Delta(\\ln r) = \\frac{\\partial^{2}}{\\partial x_{1}^{2}}(\\ln r) + \\frac{\\partial^{2}}{\\partial x_{2}^{2}}(\\ln r) = \\frac{r^{2} - 2x_{1}^{2}}{r^{4}} + \\frac{r^{2} - 2x_{2}^{2}}{r^{4}} = \\frac{2r^{2} - 2(x_{1}^{2}+x_{2}^{2})}{r^{4}} = \\frac{2r^{2}-2r^{2}}{r^{4}} = 0.\n$$\nSince the support of $g(x)=\\psi f(x)$ is contained in the region where $|x|\\ge 1$, the origin $x=0$ is excluded. Thus, $\\Delta(\\ln|x|)=0$ everywhere on the support of the integrand of $I_{2}$. Consequently,\n$$\nI_{2} = \\int_{\\mathbb{R}^{2}} g(x) \\cdot 0 \\, dx = 0.\n$$\n\nNow we focus on the first integral, $I_{1} = \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\chi f)(x) \\, dx$. Let $h(x) := (\\chi f)(x)$. The function $h(x)$ is smooth and has compact support contained in $\\mathrm{supp}(\\chi) \\subset B(0,2)$. The singularity of $\\ln|x|$ at $x=0$ lies within the support of $h(x)$, since $\\chi \\equiv 1$ on $B(0,1)$. To evaluate $I_{1}$, we must regularize the integral by excising a small ball of radius $\\varepsilon > 0$ around the origin. Let $D_{\\varepsilon} = B(0,R) \\setminus \\overline{B(0,\\varepsilon)}$, where $R=2$ so that $\\mathrm{supp}(h) \\subset B(0,2)$. Then,\n$$\nI_{1} = \\lim_{\\varepsilon \\to 0} \\int_{D_{\\varepsilon}} \\ln|x| \\, \\Delta h(x) \\, dx.\n$$\nWe apply Green's Second Identity on the domain $D_{\\varepsilon}$ to the functions $u(x)=\\ln|x|$ and $v(x)=h(x)$. On $D_{\\varepsilon}$, $\\Delta u = \\Delta(\\ln|x|) = 0$.\n$$\n\\int_{D_{\\varepsilon}} u \\Delta v \\, dx = \\int_{\\partial D_{\\varepsilon}} (u \\nabla v - v \\nabla u) \\cdot n \\, dS,\n$$\nwhere $n$ is the outward unit normal vector to the boundary $\\partial D_{\\varepsilon}$. The boundary consists of two parts: $\\partial B(0,2)$ and $\\partial B(0,\\varepsilon)$.\nThe support of $h(x)$ is contained strictly within $B(0,2)$, so $h$ and its derivatives are zero on $\\partial B(0,2)$. Therefore, the boundary integral over $\\partial B(0,2)$ vanishes.\nWe are left with the integral over $\\partial B(0,\\varepsilon)$. On this boundary, the outward normal vector from $D_{\\varepsilon}$ points towards the origin, so $n = -x/|x| = -x/\\varepsilon$.\n\\begin{align*}\n\\int_{D_{\\varepsilon}} \\ln|x| \\Delta h(x) \\, dx = \\int_{\\partial B(0,\\varepsilon)} (\\ln|x| \\nabla h(x) - h(x) \\nabla\\ln|x|) \\cdot \\left(-\\frac{x}{\\varepsilon}\\right) \\, dS \\\\\n= -\\int_{\\partial B(0,\\varepsilon)} \\ln(\\varepsilon) (\\nabla h(x) \\cdot \\frac{x}{\\varepsilon}) \\, dS + \\int_{\\partial B(0,\\varepsilon)} h(x) (\\nabla\\ln|x| \\cdot \\frac{x}{\\varepsilon}) \\, dS.\n\\end{align*}\nLet's analyze these two terms in the limit $\\varepsilon \\to 0$.\nFor the first term, since $h(x)$ is smooth, its gradient $\\nabla h(x)$ is bounded near the origin. Let $M$ be an upper bound for $|\\nabla h(x) \\cdot x/\\varepsilon|$ on $\\partial B(0,\\varepsilon)$. The magnitude of this term is bounded by $|\\ln(\\varepsilon)| \\cdot M \\cdot (2\\pi\\varepsilon)$, which is proportional to $\\varepsilon \\ln \\varepsilon$. As $\\varepsilon \\to 0$, $\\lim_{\\varepsilon \\to 0} \\varepsilon \\ln \\varepsilon = 0$. So, the first term vanishes in the limit.\nFor the second term, we have $\\nabla\\ln|x| = \\nabla\\ln r = x/r^{2}$. On $\\partial B(0,\\varepsilon)$, $r=\\varepsilon$, so $\\nabla\\ln|x| = x/\\varepsilon^2$. The dot product is $\\nabla\\ln|x| \\cdot (x/\\varepsilon) = (x/\\varepsilon^2) \\cdot (x/\\varepsilon) = |x|^2/\\varepsilon^3 = \\varepsilon^2/\\varepsilon^3 = 1/\\varepsilon$.\nThe integral becomes:\n$$\n\\int_{\\partial B(0,\\varepsilon)} h(x) \\frac{1}{\\varepsilon} \\, dS = \\frac{1}{\\varepsilon} \\int_{\\partial B(0,\\varepsilon)} h(x) \\, dS.\n$$\nBy the Mean Value Theorem for integrals, there exists a point $x_{\\varepsilon} \\in \\partial B(0,\\varepsilon)$ such that $\\int_{\\partial B(0,\\varepsilon)} h(x) \\, dS = h(x_{\\varepsilon}) \\cdot (\\text{length of } \\partial B(0,\\varepsilon)) = h(x_{\\varepsilon}) \\cdot 2\\pi\\varepsilon$.\nSo, the second term is $\\frac{1}{\\varepsilon} (h(x_{\\varepsilon}) \\cdot 2\\pi\\varepsilon) = 2\\pi h(x_{\\varepsilon})$.\nAs $\\varepsilon \\to 0$, $x_{\\varepsilon} \\to 0$. Since $h(x)$ is continuous, $\\lim_{\\varepsilon \\to 0} h(x_{\\varepsilon}) = h(0)$.\nThe limit of the second term is $2\\pi h(0)$.\nWe calculate $h(0) = (\\chi f)(0) = \\chi(0)f(0)$. By definition, $\\chi(0)=1$ because $0 \\in B(0,1)$. Also, $f(0)=\\exp(-|0|^2)=1$. Thus, $h(0)=1 \\cdot 1 = 1$.\nTherefore, $I_{1} = \\lim_{\\varepsilon \\to 0} (0 + 2\\pi h(x_{\\varepsilon})) = 2\\pi h(0) = 2\\pi$.\n\nFinally, we combine the results for $I_{1}$ and $I_{2}$:\n$$\nI = I_{1} + I_{2} = 2\\pi + 0 = 2\\pi.\n$$", "answer": "$$\\boxed{2\\pi}$$", "id": "3058995"}]}