{"hands_on_practices": [{"introduction": "To begin, let's explore a straightforward scenario that builds intuition for how compound Poisson processes work. In this problem, the 'jumps'—representing rainfall from an event—are of a constant size. This simplification allows us to directly link the total accumulated rainfall to the number of events, which follows a simple Poisson distribution, providing a clear first step into analyzing these processes [@problem_id:1290788].", "problem": "In a specific semi-arid region, significant rainfall events are rare. Observations over several decades suggest that the occurrences of these events can be modeled as a Poisson process with an average rate of $\\lambda$ events per year. Climatological data also indicates that each significant rainfall event, when it happens, consistently delivers a total of $c$ millimeters of precipitation. Assume the amounts of rain from different events are independent.\n\nCalculate the probability that the total accumulated rainfall from these significant events over a single year will be no more than $2c$. Express your answer as a symbolic expression in terms of $\\lambda$.", "solution": "Let $N$ denote the number of significant rainfall events in one year. By the defining property of a Poisson process, the count of events in a time interval of length $t$ is Poisson distributed with parameter $\\lambda t$. For $t=1$ year, we have\n$$\nN \\sim \\text{Poisson}(\\lambda),\n$$\nso\n$$\n\\mathbb{P}(N=k)=\\exp(-\\lambda)\\frac{\\lambda^{k}}{k!}, \\quad k=0,1,2,\\ldots\n$$\nEach event contributes exactly $c$ millimeters, so the total annual rainfall from these events is\n$$\nR=cN.\n$$\nAssuming $c0$, the condition $R \\leq 2c$ is equivalent to $cN \\leq 2c$, which is equivalent to $N \\leq 2$. Therefore,\n$$\n\\mathbb{P}(R \\leq 2c)=\\mathbb{P}(N \\leq 2)=\\sum_{k=0}^{2}\\mathbb{P}(N=k)=\\sum_{k=0}^{2}\\exp(-\\lambda)\\frac{\\lambda^{k}}{k!}.\n$$\nFactoring out $\\exp(-\\lambda)$ gives\n$$\n\\mathbb{P}(R \\leq 2c)=\\exp(-\\lambda)\\left(1+\\lambda+\\frac{\\lambda^{2}}{2}\\right)=\\exp(-\\lambda)\\sum_{k=0}^{2}\\frac{\\lambda^{k}}{k!}.\n$$", "answer": "$$\\boxed{\\exp(-\\lambda)\\left(1+\\lambda+\\frac{\\lambda^{2}}{2}\\right)}$$", "id": "1290788"}, {"introduction": "Having seen a case with constant jumps, we now move to a more general and realistic model where the size of each jump is a random variable. This practice focuses on calculating the mean and variance of the total displacement, which are the two most crucial descriptors of a stochastic process's behavior over time. Mastering this calculation using the laws of total expectation and variance is a fundamental skill for working with any compound Poisson process [@problem_id:1317627].", "problem": "A subatomic particle moves in one dimension. Its motion is characterized by a series of instantaneous displacements caused by collisions. The number of collisions in a time interval of length $t$, denoted by $N(t)$, follows a Poisson process with rate $\\lambda$. Each collision causes a displacement $Y_i$ for $i=1, 2, \\dots$. The displacements $\\{Y_i\\}$ are independent and identically distributed random variables, and they are also independent of the process $N(t)$.\n\nThe distribution of each displacement $Y_i$ is as follows:\n- A displacement of $+\\delta$ with probability $p$.\n- A displacement of $-2\\delta$ with probability $q$.\n- A displacement of $0$ with probability $1-p-q$.\n\nHere, $\\delta$ is a positive constant representing a fundamental length scale, and $p$ and $q$ are probabilities. Let $X(t) = \\sum_{i=1}^{N(t)} Y_i$ be the net displacement of the particle after time $t$. If no collisions occur, the displacement is zero.\n\nDetermine the mean, $E[X(t)]$, and the variance, $\\text{Var}(X(t))$, of the particle's net displacement after time $t$. The final answer should be a pair of expressions, one for the mean and one for the variance, in terms of $\\lambda, t, \\delta, p,$ and $q$.", "solution": "Let $N(t)$ be Poisson with parameter $\\lambda t$, independent of the i.i.d. displacements $\\{Y_{i}\\}$. Define $X(t)=\\sum_{i=1}^{N(t)} Y_{i}$, with the convention $X(t)=0$ if $N(t)=0$.\n\nFirst compute the first and second moments of a single displacement $Y$. By the given distribution,\n$$\nE[Y]=\\delta \\cdot p+(-2\\delta)\\cdot q+0\\cdot(1-p-q)=\\delta(p-2q),\n$$\nand\n$$\nE[Y^{2}]=\\delta^{2}\\cdot p+(4\\delta^{2})\\cdot q+0\\cdot(1-p-q)=\\delta^{2}(p+4q).\n$$\n\nConditioning on $N(t)=n$, we have a sum of $n$ i.i.d. terms, so\n$$\nE[X(t)\\mid N(t)=n]=n\\,E[Y]=n\\,\\delta(p-2q),\n$$\nand\n$$\n\\text{Var}(X(t)\\mid N(t)=n)=n\\,\\text{Var}(Y)=n\\,(E[Y^{2}]-(E[Y])^{2}).\n$$\n\nUsing the law of total expectation and that $E[N(t)]=\\lambda t$ for $N(t)\\sim\\text{Poisson}(\\lambda t)$, we obtain\n$$\nE[X(t)]=E\\big[E[X(t)\\mid N(t)]\\big]=E[N(t)]\\,E[Y]=\\lambda t\\,\\delta(p-2q).\n$$\n\nUsing the law of total variance,\n$$\n\\text{Var}(X(t))=E\\big[\\text{Var}(X(t)\\mid N(t))\\big]+\\text{Var}\\big(E[X(t)\\mid N(t)]\\big).\n$$\nSubstituting the conditional moments and noting $\\text{Var}(N(t))=\\lambda t$ gives\n$$\n\\text{Var}(X(t))=E[N(t)]\\,\\text{Var}(Y)+\\text{Var}(N(t))\\,(E[Y])^{2}\n=\\lambda t\\big(\\text{Var}(Y)+(E[Y])^{2}\\big)=\\lambda t\\,E[Y^{2}].\n$$\nWith $E[Y^{2}]=\\delta^{2}(p+4q)$ from above, we conclude\n$$\n\\text{Var}(X(t))=\\lambda t\\,\\delta^{2}(p+4q).\n$$\n\nTherefore, the mean and variance are\n$$\nE[X(t)]=\\lambda t\\,\\delta(p-2q),\\qquad \\text{Var}(X(t))=\\lambda t\\,\\delta^{2}(p+4q).\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\lambda t \\delta (p-2 q)  \\lambda t \\delta^{2} (p+4 q)\\end{pmatrix}}$$", "id": "1317627"}, {"introduction": "Our final practice explores a more complex and realistic system composed of the sum of two independent compound Poisson processes. This type of model is vital in areas like insurance, where claims might arise from different independent sources. This exercise challenges you to synthesize your understanding by conditioning on the total number of events and applying the law of total variance to find the conditional variance of the aggregate sum [@problem_id:715555].", "problem": "Consider a stochastic process $S(t)$ defined as the sum of two independent compound Poisson processes:\n$$ S(t) = \\sum_{i=1}^{N_1(t)} X_i + \\sum_{j=1}^{N_2(t)} Y_j $$\nHere, $N_1(t)$ and $N_2(t)$ are independent Poisson processes with constant arrival rates $\\lambda_1  0$ and $\\lambda_2  0$, respectively.\n\nThe jump sizes, $\\{X_i\\}_{i\\geq 1}$, are independent and identically distributed (i.i.d.) random variables with mean $E[X_i] = \\mu_X$ and variance $\\text{Var}(X_i) = \\sigma_X^2$.\nSimilarly, the jump sizes, $\\{Y_j\\}_{j\\geq 1}$, are i.i.d. random variables with mean $E[Y_j] = \\mu_Y$ and variance $\\text{Var}(Y_j) = \\sigma_Y^2$.\n\nAll sources of randomness—the processes $N_1(t)$ and $N_2(t)$, and the sequences of jump sizes $\\{X_i\\}$ and $\\{Y_j\\}$—are mutually independent.\n\nThe total number of jumps occurring up to time $t$ is $N(t) = N_1(t) + N_2(t)$.\n\nFor a given positive integer $n$ and time $t0$, derive a closed-form expression for the conditional variance of the aggregate sum, $\\text{Var}(S(t) | N(t) = n)$, in terms of $n$, $\\lambda_1$, $\\lambda_2$, $\\mu_X$, $\\sigma_X^2$, $\\mu_Y$, and $\\sigma_Y^2$.", "solution": "1. Conditional distribution of $N_1(t)$ given $N(t)=n$:  \nSince $N_1(t)\\sim\\text{Pois}(\\lambda_1 t)$, $N_2(t)\\sim\\text{Pois}(\\lambda_2 t)$ and are independent,  \n$$N_1(t)\\mid N_1(t)+N_2(t)=n\\sim\\text{Bin}\\Bigl(n,\\;p\\Bigr),\\quad p=\\frac{\\lambda_1}{\\lambda_1+\\lambda_2}.$$\n\n2. Write $S(t)=S_X+S_Y$ with  \n$$S_X=\\sum_{i=1}^{N_1}X_i,\\quad S_Y=\\sum_{j=1}^{N_2}Y_j.$$  \nCondition on $N_1=k$ and $N=n$:  \n$$\\text{Var}\\bigl(S\\mid N_1=k,N=n\\bigr)=k\\,\\sigma_X^2+(n-k)\\,\\sigma_Y^2,$$  \n$$E\\bigl[S\\mid N_1=k,N=n\\bigr]=k\\,\\mu_X+(n-k)\\,\\mu_Y.$$\n\n3. Use the law of total variance:  \n$$\\text{Var}(S\\mid N=n)=E\\bigl[\\text{Var}(S\\mid N_1,n)\\bigr]+\\text{Var}\\bigl[E(S\\mid N_1,n)\\bigr].$$  \nCompute each term:  \nE[Var] term:  \n$$E\\bigl[k\\,\\sigma_X^2+(n-k)\\sigma_Y^2\\bigr]\n=\\sigma_X^2\\,E[k]+\\sigma_Y^2\\,(n-E[k])\n=n\\Bigl(p\\,\\sigma_X^2+(1-p)\\,\\sigma_Y^2\\Bigr).$$  \nVar[E] term:  \n$$\\text{Var}\\bigl[k\\,\\mu_X+(n-k)\\mu_Y\\bigr]\n=(\\mu_X-\\mu_Y)^2\\,\\text{Var}(k)\n=(\\mu_X-\\mu_Y)^2\\,n\\,p(1-p).$$\n\n4. Combine and substitute $p=\\frac{\\lambda_1}{\\lambda_1+\\lambda_2}$:  \n$$\\text{Var}(S\\mid N=n)\n=n\\Bigl(p\\,\\sigma_X^2+(1-p)\\sigma_Y^2\\Bigr)\n+n\\,p(1-p)\\,(\\mu_X-\\mu_Y)^2.$$\n$$\n\\text{Var}(S\\mid N=n)\n=n\\Bigl(\\frac{\\lambda_1}{\\lambda_1+\\lambda_2}\\sigma_X^2\n+\\frac{\\lambda_2}{\\lambda_1+\\lambda_2}\\sigma_Y^2\\Bigr)\n+n\\frac{\\lambda_1\\lambda_2}{(\\lambda_1+\\lambda_2)^2}(\\mu_X-\\mu_Y)^2.\n$$", "answer": "$$\\boxed{n\\Bigl(\\frac{\\lambda_1}{\\lambda_1+\\lambda_2}\\sigma_X^2+\\frac{\\lambda_2}{\\lambda_1+\\lambda_2}\\sigma_Y^2\\Bigr)+n\\frac{\\lambda_1\\lambda_2}{(\\lambda_1+\\lambda_2)^2}(\\mu_X-\\mu_Y)^2}$$", "id": "715555"}]}