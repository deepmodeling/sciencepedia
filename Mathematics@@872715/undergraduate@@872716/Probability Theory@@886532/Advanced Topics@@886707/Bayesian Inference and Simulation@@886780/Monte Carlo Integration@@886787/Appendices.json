{"hands_on_practices": [{"introduction": "The most intuitive application of Monte Carlo methods is the \"hit-or-miss\" approach, which is particularly well-suited for estimating probabilities or geometric areas. By generating random samples and checking whether they fall inside a region of interest, we can approximate the region's size or the probability of an event. This exercise [@problem_id:1376841] provides a direct, hands-on application of this core principle using a small, manageable dataset, making it an ideal starting point for understanding how simulation translates into estimation.", "problem": "A robotics engineer is testing a new navigation algorithm. The final position error of a robot in a 2D plane is modeled by two independent random variables, $X$ and $Y$, representing the errors in the two perpendicular axes. Both $X$ and $Y$ follow a standard normal distribution, which has a Probability Density Function (PDF) given by $f(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$ for $-\\infty < z < \\infty$. The robot's test is considered a success if its final position error lies within a unit circle centered at the origin, i.e., if the condition $X^2 + Y^2 < 1$ is met.\n\nTo estimate the probability of a successful test, the engineer runs a simulation and generates a small set of random samples for the pair $(X, Y)$. The following ten pairs of values are generated:\n(0.52, -0.31), (-1.21, 0.44), (0.87, 0.73), (-0.05, 0.55), (1.57, -0.62),\n(-0.48, 0.19), (0.91, -0.25), (-1.10, -0.89), (0.33, 0.15), (0.60, -0.95).\n\nUsing this set of ten simulated data points, estimate the probability of a successful test. Express your answer as a decimal rounded to three significant figures.", "solution": "We are asked to estimate the probability of success using the given sample of size $n=10$. Define the success event $S=\\{X^{2}+Y^{2}<1\\}$. The Monte Carlo estimator of $p=\\mathbb{P}(S)$ based on samples $\\{(X_{i},Y_{i})\\}_{i=1}^{n}$ is\n$$\n\\hat{p}=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{1}\\{X_{i}^{2}+Y_{i}^{2}<1\\}.\n$$\nWe evaluate $X_{i}^{2}+Y_{i}^{2}$ for each pair and compare with $1$:\n- $(0.52,-0.31)$: $0.52^{2}+(-0.31)^{2}=0.2704+0.0961=0.36651$ (success).\n- $(-1.21,0.44)$: $(-1.21)^{2}+0.44^{2}=1.4641+0.1936=1.6577>1$ (failure).\n- $(0.87,0.73)$: $0.87^{2}+0.73^{2}=0.7569+0.5329=1.2898>1$ (failure).\n- $(-0.05,0.55)$: $(-0.05)^{2}+0.55^{2}=0.0025+0.3025=0.30501$ (success).\n- $(1.57,-0.62)$: $1.57^{2}+(-0.62)^{2}=2.4649+0.3844=2.8493>1$ (failure).\n- $(-0.48,0.19)$: $(-0.48)^{2}+0.19^{2}=0.2304+0.0361=0.26651$ (success).\n- $(0.91,-0.25)$: $0.91^{2}+(-0.25)^{2}=0.8281+0.0625=0.89061$ (success).\n- $(-1.10,-0.89)$: $(-1.10)^{2}+(-0.89)^{2}=1.2100+0.7921=2.0021>1$ (failure).\n- $(0.33,0.15)$: $0.33^{2}+0.15^{2}=0.1089+0.0225=0.13141$ (success).\n- $(0.60,-0.95)$: $0.60^{2}+(-0.95)^{2}=0.3600+0.9025=1.2625>1$ (failure).\n\nThere are $k=5$ successes out of $n=10$, so\n$$\n\\hat{p}=\\frac{k}{n}=\\frac{5}{10}=0.5.\n$$\nRounded to three significant figures, this is $0.500$.", "answer": "$$\\boxed{0.500}$$", "id": "1376841"}, {"introduction": "While simple Monte Carlo integration is a powerful tool, its efficiency can vary dramatically depending on the problem. The accuracy of our estimate for a given number of samples is determined by the estimator's variance. This exercise [@problem_id:2188171] delves into this crucial concept by asking you to compare the variances for two different integrals. By working through this problem, you will develop a deeper theoretical understanding of what makes a function \"hard\" or \"easy\" to integrate with Monte Carlo methods, a key insight for any practical application.", "problem": "In numerical analysis, the simple Monte Carlo method can be used to approximate a definite integral $I = \\int_0^1 f(x) \\,dx$. The estimator for the integral, denoted by $\\hat{I}_N$, is constructed by drawing $N$ independent random samples $X_1, X_2, \\dots, X_N$ from a uniform distribution on the interval $[0, 1]$, and then calculating the sample mean of the function $f$ evaluated at these points:\n$$\n\\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^N f(X_i)\n$$\nThe accuracy of this estimator is often assessed by its variance, $\\text{Var}(\\hat{I}_N)$.\n\nConsider two different integrals:\n1. $I_A = \\int_0^1 x^8 \\,dx$\n2. $I_B = \\int_0^1 x^2 \\,dx$\n\nLet $\\hat{I}_{A,N}$ and $\\hat{I}_{B,N}$ be the respective simple Monte Carlo estimators for $I_A$ and $I_B$, both constructed using the same number of samples, $N$.\n\nCalculate the exact value of the ratio of the variances of these two estimators, $\\frac{\\text{Var}(\\hat{I}_{A,N})}{\\text{Var}(\\hat{I}_{B,N})}$. Express your answer as an exact fraction in simplest form.", "solution": "The problem asks for the ratio of the variances of two Monte Carlo estimators, $\\frac{\\text{Var}(\\hat{I}_{A,N})}{\\text{Var}(\\hat{I}_{B,N})}$.\n\nLet's first establish the general formula for the variance of a simple Monte Carlo estimator $\\hat{I}_N = \\frac{1}{N} \\sum_{i=1}^N f(X_i)$, where $X_i$ are independent and identically distributed (i.i.d.) random variables.\n$$\n\\text{Var}(\\hat{I}_N) = \\text{Var}\\left(\\frac{1}{N} \\sum_{i=1}^N f(X_i)\\right)\n$$\nUsing the properties of variance, since the samples are independent:\n$$\n\\text{Var}(\\hat{I}_N) = \\frac{1}{N^2} \\sum_{i=1}^N \\text{Var}(f(X_i)) = \\frac{1}{N^2} \\cdot N \\cdot \\text{Var}(f(X)) = \\frac{1}{N} \\text{Var}(f(X))\n$$\nHere, $X$ is a single random variable with the same distribution as each $X_i$. In this problem, $X$ is uniformly distributed on $[0, 1]$, denoted $X \\sim U(0,1)$.\n\nThe variance of the random variable $f(X)$ is given by the formula $\\text{Var}(f(X)) = E[(f(X))^2] - (E[f(X)])^2$.\nFor a random variable $X \\sim U(0,1)$, the expectation of any function $g(X)$ is $E[g(X)] = \\int_0^1 g(x) \\cdot 1 \\,dx$.\nTherefore, we have:\n$E[f(X)] = \\int_0^1 f(x) \\,dx$\n$E[(f(X))^2] = \\int_0^1 (f(x))^2 \\,dx$\nSubstituting these into the variance formula:\n$$\n\\text{Var}(f(X)) = \\int_0^1 (f(x))^2 \\,dx - \\left(\\int_0^1 f(x) \\,dx\\right)^2\n$$\nSo, the variance of the estimator is:\n$$\n\\text{Var}(\\hat{I}_N) = \\frac{1}{N} \\left[ \\int_0^1 (f(x))^2 \\,dx - \\left(\\int_0^1 f(x) \\,dx\\right)^2 \\right]\n$$\nNow, we apply this formula to our two cases.\n\nCase A: $f_A(x) = x^8$\nFirst, we calculate the necessary integrals:\n$$\n\\int_0^1 f_A(x) \\,dx = \\int_0^1 x^8 \\,dx = \\left[ \\frac{x^9}{9} \\right]_0^1 = \\frac{1}{9}\n$$\n$$\n\\int_0^1 (f_A(x))^2 \\,dx = \\int_0^1 (x^8)^2 \\,dx = \\int_0^1 x^{16} \\,dx = \\left[ \\frac{x^{17}}{17} \\right]_0^1 = \\frac{1}{17}\n$$\nNow we compute the variance of $f_A(X)$:\n$$\n\\text{Var}(f_A(X)) = \\frac{1}{17} - \\left(\\frac{1}{9}\\right)^2 = \\frac{1}{17} - \\frac{1}{81} = \\frac{81 - 17}{17 \\cdot 81} = \\frac{64}{1377}\n$$\nThe variance of the estimator $\\hat{I}_{A,N}$ is:\n$$\n\\text{Var}(\\hat{I}_{A,N}) = \\frac{1}{N} \\frac{64}{1377}\n$$\n\nCase B: $f_B(x) = x^2$\nFirst, we calculate the necessary integrals:\n$$\n\\int_0^1 f_B(x) \\,dx = \\int_0^1 x^2 \\,dx = \\left[ \\frac{x^3}{3} \\right]_0^1 = \\frac{1}{3}\n$$\n$$\n\\int_0^1 (f_B(x))^2 \\,dx = \\int_0^1 (x^2)^2 \\,dx = \\int_0^1 x^4 \\,dx = \\left[ \\frac{x^5}{5} \\right]_0^1 = \\frac{1}{5}\n$$\nNow we compute the variance of $f_B(X)$:\n$$\n\\text{Var}(f_B(X)) = \\frac{1}{5} - \\left(\\frac{1}{3}\\right)^2 = \\frac{1}{5} - \\frac{1}{9} = \\frac{9 - 5}{45} = \\frac{4}{45}\n$$\nThe variance of the estimator $\\hat{I}_{B,N}$ is:\n$$\n\\text{Var}(\\hat{I}_{B,N}) = \\frac{1}{N} \\frac{4}{45}\n$$\n\nFinally, we compute the ratio of the two variances. The factor $\\frac{1}{N}$ is common to both and cancels out.\n$$\n\\frac{\\text{Var}(\\hat{I}_{A,N})}{\\text{Var}(\\hat{I}_{B,N})} = \\frac{\\frac{1}{N} \\frac{64}{1377}}{\\frac{1}{N} \\frac{4}{45}} = \\frac{\\frac{64}{1377}}{\\frac{4}{45}} = \\frac{64}{1377} \\cdot \\frac{45}{4}\n$$\nWe can simplify this expression:\n$$\n\\frac{64}{4} \\cdot \\frac{45}{1377} = 16 \\cdot \\frac{45}{1377}\n$$\nWe recall from our calculation of $\\text{Var}(f_A(X))$ that $1377 = 17 \\cdot 81$. We also know $45 = 5 \\cdot 9$ and $81 = 9 \\cdot 9$.\n$$\n16 \\cdot \\frac{5 \\cdot 9}{17 \\cdot 81} = 16 \\cdot \\frac{5 \\cdot 9}{17 \\cdot 9 \\cdot 9} = 16 \\cdot \\frac{5}{17 \\cdot 9} = \\frac{80}{153}\n$$\nThe fraction $\\frac{80}{153}$ is in simplest form since $80 = 2^4 \\cdot 5$ and $153 = 3^2 \\cdot 17$ have no common prime factors.", "answer": "$$\\boxed{\\frac{80}{153}}$$", "id": "2188171"}, {"introduction": "Building on the concept of estimator variance, we can explore techniques to actively improve the efficiency of our simulations. Importance sampling is one of the most fundamental variance reduction methods, where we strategically choose a non-uniform sampling distribution to focus on the \"important\" regions of the integrand. This advanced exercise [@problem_id:2414609] powerfully illustrates how a well-chosen sampling distribution can drastically reduce variance and accelerate convergence, while a poorly chosen one can perform even worse than a simple uniform sampling approach.", "problem": "Consider the integral of a nonnegative integrand over a finite interval. Let the target integral be\n$$\nI = \\int_{0}^{1} f(x)\\,dx,\n$$\nwith $f(x) = x^{m}$ for a fixed exponent $m$ satisfying $m  -1$. Define the crude Monte Carlo estimator as the random variable $Y_{\\mathrm{c}} = f(U)$ with $U \\sim \\mathrm{Uniform}(0,1)$, and define the importance sampling estimator with a probability density function $p(x)$ on $[0,1]$ as $Y_{\\mathrm{is}} = f(X)/p(X)$ with $X \\sim p$. The per-sample variances of these unbiased estimators are, by definition,\n$$\n\\mathrm{Var}(Y_{\\mathrm{c}}) = \\mathbb{E}[Y_{\\mathrm{c}}^{2}] - I^{2}, \\qquad \\mathrm{Var}(Y_{\\mathrm{is}}) = \\mathbb{E}[Y_{\\mathrm{is}}^{2}] - I^{2}.\n$$\nFor the importance sampling density, consider the Beta distribution on $[0,1]$ with parameters $\\alpha  0$ and $\\beta  0$,\n$$\np(x) = \\frac{x^{\\alpha - 1}(1 - x)^{\\beta - 1}}{B(\\alpha,\\beta)},\n$$\nwhere $B(\\alpha,\\beta)$ is the Beta function. Assume parameter choices that make all quantities finite; in particular, assume $\\beta  2$ and $\\alpha  2m + 2$ to ensure that $\\mathbb{E}[Y_{\\mathrm{is}}^{2}]$ exists.\n\nFor each parameter set $(m,\\alpha,\\beta)$ in the following test suite, compute the ratio\n$$\nr = \\frac{\\mathrm{Var}(Y_{\\mathrm{is}})}{\\mathrm{Var}(Y_{\\mathrm{c}})},\n$$\nand produce the results in the specified format.\n\nTest suite (each triple is $(m,\\alpha,\\beta)$):\n\n- Case 1: $(2,\\tfrac{1}{2},\\tfrac{3}{2})$.\n- Case 2: $(2,1,1)$.\n- Case 3: $(2,\\tfrac{5}{2},1)$.\n- Case 4: $(2,3,1)$.\n\nFinal Output Format: Your program should produce a single line of output containing the results for the cases, in the order listed above, as a comma-separated list enclosed in square brackets (for example, $[r_{1},r_{2}]$). Each number must be rounded to $6$ decimal places. No additional text should be printed.", "solution": "The problem requires the computation of the ratio $r = \\mathrm{Var}(Y_{\\mathrm{is}})/\\mathrm{Var}(Y_{\\mathrm{c}})$, where $\\mathrm{Var}(Y_{\\mathrm{c}})$ is the variance of the crude Monte Carlo estimator and $\\mathrm{Var}(Y_{\\mathrm{is}})$ is the variance of the importance sampling estimator for the integral $I = \\int_{0}^{1} f(x)\\,dx$ with $f(x) = x^{m}$. The analysis proceeds by deriving analytical expressions for each variance.\n\nFirst, we calculate the exact value of the integral $I$. For $m > -1$:\n$$\nI = \\int_{0}^{1} x^{m} \\, dx = \\left[ \\frac{x^{m+1}}{m+1} \\right]_{0}^{1} = \\frac{1}{m+1}\n$$\n\nNext, we derive the variance of the crude Monte Carlo estimator, $Y_{\\mathrm{c}} = U^m$, where $U \\sim \\mathrm{Uniform}(0,1)$. The variance is defined as $\\mathrm{Var}(Y_{\\mathrm{c}}) = \\mathbb{E}[Y_{\\mathrm{c}}^{2}] - I^{2}$. The second moment $\\mathbb{E}[Y_{\\mathrm{c}}^{2}]$ is:\n$$\n\\mathbb{E}[Y_{\\mathrm{c}}^{2}] = \\mathbb{E}[(U^m)^2] = \\mathbb{E}[U^{2m}] = \\int_{0}^{1} u^{2m} \\cdot 1 \\, du = \\frac{1}{2m+1}\n$$\nThis requires $2m+1 > 0$, or $m > -1/2$. The given condition $m > -1$ and the test case $m=2$ satisfy this. The variance is therefore:\n$$\n\\mathrm{Var}(Y_{\\mathrm{c}}) = \\frac{1}{2m+1} - \\left(\\frac{1}{m+1}\\right)^2 = \\frac{(m+1)^2 - (2m+1)}{(2m+1)(m+1)^2} = \\frac{m^2 + 2m + 1 - 2m - 1}{(2m+1)(m+1)^2} = \\frac{m^2}{(2m+1)(m+1)^2}\n$$\n\nNow, we derive the variance of the importance sampling estimator, $Y_{\\mathrm{is}} = f(X)/p(X)$, where $X$ is drawn from the Beta distribution with density $p(x) = x^{\\alpha - 1}(1 - x)^{\\beta - 1} / B(\\alpha, \\beta)$. The variance is $\\mathrm{Var}(Y_{\\mathrm{is}}) = \\mathbb{E}[Y_{\\mathrm{is}}^{2}] - I^{2}$. The second moment $\\mathbb{E}[Y_{\\mathrm{is}}^{2}]$ is calculated as:\n$$\n\\mathbb{E}[Y_{\\mathrm{is}}^{2}] = \\int_{0}^{1} \\left(\\frac{f(x)}{p(x)}\\right)^2 p(x) \\, dx = \\int_{0}^{1} \\frac{f(x)^2}{p(x)} \\, dx\n$$\nSubstituting $f(x) = x^m$ and the density $p(x)$:\n$$\n\\mathbb{E}[Y_{\\mathrm{is}}^{2}] = \\int_{0}^{1} \\frac{(x^m)^2}{\\frac{x^{\\alpha - 1}(1 - x)^{\\beta - 1}}{B(\\alpha, \\beta)}} \\, dx = B(\\alpha, \\beta) \\int_{0}^{1} x^{2m - \\alpha + 1} (1 - x)^{1 - \\beta} \\, dx\n$$\nThe integral is a Beta function integral, $B(a,b) = \\int_0^1 t^{a-1}(1-t)^{b-1}dt$. We rewrite the integrand's exponents accordingly:\n$$\n\\mathbb{E}[Y_{\\mathrm{is}}^{2}] = B(\\alpha, \\beta) \\int_{0}^{1} x^{(2m - \\alpha + 2) - 1} (1 - x)^{(2 - \\beta) - 1} \\, dx\n$$\nThis integral is equal to $B(2m - \\alpha + 2, 2 - \\beta)$. The existence of this integral is guaranteed by the problem constraints $\\alpha  2m + 2$ and $\\beta  2$. Thus, the second moment is:\n$$\n\\mathbb{E}[Y_{\\mathrm{is}}^{2}] = B(\\alpha, \\beta) B(2m - \\alpha + 2, 2 - \\beta)\n$$\nThe variance for the importance sampling estimator is:\n$$\n\\mathrm{Var}(Y_{\\mathrm{is}}) = B(\\alpha, \\beta) B(2m - \\alpha + 2, 2 - \\beta) - \\frac{1}{(m+1)^2}\n$$\n\nFinally, the ratio $r$ is given by the general formula:\n$$\nr = \\frac{\\mathrm{Var}(Y_{\\mathrm{is}})}{\\mathrm{Var}(Y_{\\mathrm{c}})} = \\frac{B(\\alpha, \\beta) B(2m - \\alpha + 2, 2 - \\beta) - \\frac{1}{(m+1)^2}}{\\frac{m^2}{(2m+1)(m+1)^2}}\n$$\n\nFor all test cases, the exponent is $m=2$. We can specialize the formulas:\n$I = \\frac{1}{2+1} = \\frac{1}{3}$.\n$\\mathrm{Var}(Y_{\\mathrm{c}}) = \\frac{2^2}{(2(2)+1)(2+1)^2} = \\frac{4}{5 \\cdot 9} = \\frac{4}{45}$.\nThe ratio $r$ for $m=2$ becomes:\n$$\nr = \\frac{B(\\alpha, \\beta) B(6 - \\alpha, 2 - \\beta) - \\frac{1}{9}}{\\frac{4}{45}} = \\frac{45}{4} \\left( B(\\alpha, \\beta) B(6 - \\alpha, 2 - \\beta) - \\frac{1}{9} \\right)\n$$\n\nNow we compute the ratio for each test case.\n\nCase 1: $(m,\\alpha,\\beta) = (2, \\frac{1}{2}, \\frac{3}{2})$.\nWe have $\\alpha = 0.5$ and $\\beta = 1.5$.\n$r = \\frac{45}{4} \\left( B(0.5, 1.5) B(5.5, 0.5) - \\frac{1}{9} \\right)$.\nUsing the relation $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$:\n$B(0.5, 1.5) = B(\\frac{1}{2}, \\frac{3}{2}) = \\frac{\\Gamma(1/2)\\Gamma(3/2)}{\\Gamma(2)} = \\frac{\\sqrt{\\pi} \\cdot (1/2)\\sqrt{\\pi}}{1!} = \\frac{\\pi}{2}$.\n$B(5.5, 0.5) = B(\\frac{11}{2}, \\frac{1}{2}) = \\frac{\\Gamma(11/2)\\Gamma(1/2)}{\\Gamma(6)} = \\frac{(945/32)\\sqrt{\\pi} \\cdot \\sqrt{\\pi}}{5!} = \\frac{945\\pi}{32 \\cdot 120} = \\frac{63\\pi}{256}$.\n$r = \\frac{45}{4} \\left( \\frac{\\pi}{2} \\cdot \\frac{63\\pi}{256} - \\frac{1}{9} \\right) = \\frac{45}{4} \\frac{63\\pi^2}{512} - \\frac{45}{36} = \\frac{2835\\pi^2}{2048} - \\frac{5}{4} = \\frac{2835\\pi^2 - 2560}{2048}$.\nNumerically, this is approximately $12.408172$.\n\nCase 2: $(m,\\alpha,\\beta) = (2, 1, 1)$.\nHere, $\\alpha=1, \\beta=1$, so $p(x) = \\frac{x^0(1-x)^0}{B(1,1)} = 1$, which is the uniform distribution. The importance sampling scheme is identical to the crude Monte Carlo scheme. Therefore, $\\mathrm{Var}(Y_{\\mathrm{is}}) = \\mathrm{Var}(Y_{\\mathrm{c}})$ and the ratio $r$ must be $1$.\nVerifying with the formula:\n$r = \\frac{45}{4} \\left( B(1, 1) B(5, 1) - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( 1 \\cdot \\frac{1}{5} - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{1}{5} - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{9-5}{45} \\right) = \\frac{45}{4} \\frac{4}{45} = 1$.\n\nCase 3: $(m,\\alpha,\\beta) = (2, \\frac{5}{2}, 1)$.\nWe have $\\alpha = 2.5$ and $\\beta = 1$. The formula for $B(a,1)$ is $1/a$.\n$r = \\frac{45}{4} \\left( B(2.5, 1) B(3.5, 1) - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{1}{2.5} \\cdot \\frac{1}{3.5} - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{2}{5} \\cdot \\frac{2}{7} - \\frac{1}{9} \\right)$.\n$r = \\frac{45}{4} \\left( \\frac{4}{35} - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{36 - 35}{315} \\right) = \\frac{45}{4 \\cdot 315} = \\frac{1}{4 \\cdot 7} = \\frac{1}{28}$.\nNumerically, this is approximately $0.035714$.\n\nCase 4: $(m,\\alpha,\\beta) = (2, 3, 1)$.\nHere, $\\alpha = 3$ and $\\beta = 1$. The sampling density is $p(x) = \\frac{x^{3-1}}{B(3,1)} = \\frac{x^2}{1/3} = 3x^2$. The integrand is $f(x)=x^2$. Since $p(x) \\propto f(x)$, the estimator $Y_{\\mathrm{is}} = \\frac{f(X)}{p(X)} = \\frac{X^2}{3X^2} = \\frac{1}{3}$ is a constant. The variance of a constant is zero. Thus, $r=0$.\nVerifying with the formula:\n$r = \\frac{45}{4} \\left( B(3, 1) B(3, 1) - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{1}{3} \\cdot \\frac{1}{3} - \\frac{1}{9} \\right) = \\frac{45}{4} \\left( \\frac{1}{9} - \\frac{1}{9} \\right) = 0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import beta\n\ndef solve():\n    \"\"\"\n    Computes the ratio of variances for importance sampling vs. crude Monte Carlo\n    for the integral of f(x) = x^m from 0 to 1.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 0.5, 1.5),  # Case 1\n        (2, 1, 1),      # Case 2\n        (2, 2.5, 1),    # Case 3\n        (2, 3, 1)       # Case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        m, alpha, beta_p = case\n\n        # General formula for the variance of the crude Monte Carlo estimator.\n        # Var(Y_c) = E[f(U)^2] - I^2 = integral(x^(2m))dx - (integral(x^m)dx)^2\n        #          = 1/(2m+1) - 1/((m+1)^2)\n        #          = m^2 / ((2m+1)*(m+1)^2)\n        var_c = m**2 / ((2 * m + 1) * (m + 1)**2)\n\n        # General formula for the variance of the importance sampling estimator.\n        # Var(Y_is) = E[(f(X)/p(X))^2] - I^2 = integral(f(x)^2/p(x))dx - I^2\n        #           = B(alpha, beta) * B(2m - alpha + 2, 2 - beta) - 1/((m+1)^2)\n        # The conditions m  -1, alpha  0, beta  0, alpha  2m+2, beta  2 are met.\n        term1 = beta(alpha, beta_p)\n        term2 = beta(2 * m - alpha + 2, 2 - beta_p)\n        var_is = term1 * term2 - 1 / ((m + 1)**2)\n        \n        # The ratio r = Var(Y_is) / Var(Y_c).\n        # var_c is non-zero since m=2 is used in all test cases.\n        ratio = var_is / var_c\n        \n        results.append(ratio)\n\n    # Format the results to 6 decimal places as required.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2414609"}]}