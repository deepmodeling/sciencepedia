{"hands_on_practices": [{"introduction": "Our journey into the practical application of product measures begins with the most fundamental task: ensuring a function can serve as a valid joint probability density function. This exercise focuses on finding the normalization constant for a joint PDF of two independent exponential random variables. It's a perfect illustration of how Fubini's theorem allows us to simplify a double integral into a product of two simpler, single-variable integrals, a technique that is foundational for working with joint distributions [@problem_id:1381004].", "problem": "A researcher proposes a model for the joint behavior of two continuous random variables, $X$ and $Y$. The proposed joint probability density function is given by:\n$$\nf(x,y) = \\begin{cases} K \\exp(-\\alpha x - \\beta y)  \\text{for } x \\ge 0 \\text{ and } y \\ge 0 \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nwhere $\\alpha$ and $\\beta$ are given positive constants. For this function to be a valid joint probability density function, the constant $K$ must be chosen appropriately. Determine the expression for the normalization constant $K$ in terms of $\\alpha$ and $\\beta$.", "solution": "To be a valid joint probability density function, $f(x,y)$ must integrate to $1$ over its support. The support here is $\\{(x,y): x \\ge 0, y \\ge 0\\}$. Therefore, we require\n$$\n\\iint_{\\mathbb{R}^{2}} f(x,y)\\,dx\\,dy \\;=\\; \\int_{0}^{\\infty}\\int_{0}^{\\infty} K\\,\\exp(-\\alpha x - \\beta y)\\,dy\\,dx \\;=\\; 1.\n$$\nSince the integrand factors into a function of $x$ times a function of $y$, we separate the integrals:\n$$\n\\int_{0}^{\\infty}\\int_{0}^{\\infty} K\\,\\exp(-\\alpha x - \\beta y)\\,dy\\,dx \\;=\\; K \\left(\\int_{0}^{\\infty} \\exp(-\\alpha x)\\,dx\\right)\\left(\\int_{0}^{\\infty} \\exp(-\\beta y)\\,dy\\right).\n$$\nUsing the standard result for $\\alpha0$ and $\\beta0$,\n$$\n\\int_{0}^{\\infty} \\exp(-\\alpha x)\\,dx \\;=\\; \\frac{1}{\\alpha}, \n\\qquad\n\\int_{0}^{\\infty} \\exp(-\\beta y)\\,dy \\;=\\; \\frac{1}{\\beta},\n$$\nwe obtain\n$$\nK \\cdot \\frac{1}{\\alpha} \\cdot \\frac{1}{\\beta} \\;=\\; 1.\n$$\nSolving for $K$ gives\n$$\nK \\;=\\; \\alpha \\beta.\n$$\nThis choice ensures that the total probability over the support equals $1$, as required.", "answer": "$$\\boxed{\\alpha\\beta}$$", "id": "1381004"}, {"introduction": "With a valid joint PDF, we can compute probabilities of complex events. This practice moves beyond simple rectangular domains and asks for the probability that one random variable is greater than the square of another, $P(Y \\gt X^2)$. This requires careful setup of the integration limits, a crucial skill for applying multivariate calculus to solve real-world probability problems and for understanding the geometric interpretation of probability in higher dimensions [@problem_id:1380981].", "problem": "A technology company is testing a new generation of processors. The performance of each processor is characterized by two independent metrics, a processing speed index $X$ and a memory access efficiency $Y$. Due to inherent randomness in the fabrication process, both $X$ and $Y$ are modeled as independent random variables, each uniformly distributed on the interval $[0, 1]$.\n\nA processor is deemed 'premium quality' if its metrics satisfy the inequality $Y  X^2$. All other processors are classified as 'standard quality'.\n\nCalculate the probability that a randomly selected processor is of premium quality. Express your answer as a fraction in simplest form.", "solution": "Let $X$ and $Y$ be independent and uniformly distributed on $[0,1]$. The joint probability density function is $f_{X,Y}(x,y)=1$ for $(x,y)\\in[0,1]^{2}$ and $0$ otherwise.\n\nThe processor is premium quality if $Y  X^{2}$. Therefore, the desired probability is the integral of the joint density over the region $\\{(x,y)\\in[0,1]^{2}: yx^{2}\\}$:\n$$\n\\mathbb{P}(YX^{2})=\\int_{0}^{1}\\int_{x^{2}}^{1} 1 \\, dy \\, dx.\n$$\nFirst evaluate the inner integral:\n$$\n\\int_{x^{2}}^{1} 1 \\, dy = 1 - x^{2}.\n$$\nThen integrate with respect to $x$:\n$$\n\\int_{0}^{1} (1 - x^{2}) \\, dx = \\left[x - \\frac{x^{3}}{3}\\right]_{0}^{1} = 1 - \\frac{1}{3} = \\frac{2}{3}.\n$$\nThus, the probability that a randomly selected processor is premium quality is $\\frac{2}{3}$.", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "1380981"}, {"introduction": "The principles of product measures are not confined to pairs of continuous variables; they powerfully unite discrete and continuous worlds. This final exercise tackles a hybrid scenario involving a discrete Poisson random variable and a continuous exponential one. By conditioning on the discrete variable, we can leverage the law of total probability to solve for $P(N \\lt X)$, demonstrating a versatile and powerful technique for problems that mix different types of random variables [@problem_id:1380951].", "problem": "In a simplified model of a biological system, the number of mutations, $N$, occurring in a cell's genome over a specific time period is described by a Poisson random variable with a mean of $\\lambda  0$. The time until this cell is inspected and replaced, denoted by $X$ and measured in the same time periods, is modeled as an independent exponential random variable with a rate parameter $\\mu  0$.\n\nA failure event is defined to occur if the number of mutations $N$ is strictly less than the time $X$ until the cell's replacement. Calculate the probability of this failure event, $P(N  X)$.\n\nExpress your final answer as a closed-form analytic expression in terms of $\\lambda$ and $\\mu$.", "solution": "Let $N$ be Poisson with mean $\\lambda$, so for $n \\in \\{0,1,2,\\dots\\}$,\n$$\n\\Pr(N=n) = \\exp(-\\lambda)\\frac{\\lambda^{n}}{n!}.\n$$\nLet $X$ be exponential with rate $\\mu$, independent of $N$, so for $t \\geq 0$,\n$$\n\\Pr(Xt) = \\exp(-\\mu t).\n$$\nThe event $\\{NX\\}$ is the same as $\\{XN\\}$. Using the law of total probability conditioning on $N$ and independence,\n$$\n\\Pr(NX) = \\sum_{n=0}^{\\infty} \\Pr(Xn)\\Pr(N=n).\n$$\nSubstitute the tail probability of $X$ and the pmf of $N$:\n$$\n\\Pr(NX) = \\sum_{n=0}^{\\infty} \\exp(-\\mu n)\\,\\exp(-\\lambda)\\frac{\\lambda^{n}}{n!}\n= \\exp(-\\lambda)\\sum_{n=0}^{\\infty} \\frac{\\left(\\lambda \\exp(-\\mu)\\right)^{n}}{n!}.\n$$\nUsing the exponential series $\\sum_{n=0}^{\\infty} a^{n}/n! = \\exp(a)$,\n$$\n\\Pr(NX) = \\exp(-\\lambda)\\,\\exp\\!\\left(\\lambda \\exp(-\\mu)\\right)\n= \\exp\\!\\left(-\\lambda + \\lambda \\exp(-\\mu)\\right)\n= \\exp\\!\\left(-\\lambda\\left(1-\\exp(-\\mu)\\right)\\right).\n$$", "answer": "$$\\boxed{\\exp\\!\\left(-\\lambda\\left(1-\\exp(-\\mu)\\right)\\right)}$$", "id": "1380951"}]}