{"hands_on_practices": [{"introduction": "We begin by connecting the abstract definition of the Lebesgue integral to a familiar, concrete example. This exercise asks you to calculate the expected value of a fair six-sided die roll, a concept you've likely encountered before. By formally representing the outcome as a simple function and computing its integral with respect to the probability measure, you will see how the new framework rigorously captures our existing intuition.", "problem": "Consider the experiment of rolling a single fair six-sided die. This process is modeled by the probability space $(\\Omega, \\mathcal{F}, P)$, where the sample space is $\\Omega = \\{1, 2, 3, 4, 5, 6\\}$, the sigma-algebra $\\mathcal{F}$ is the power set of $\\Omega$, and the probability measure $P$ is defined by $P(A) = \\frac{|A|}{6}$ for any event $A \\in \\mathcal{F}$.\nLet the random variable $X: \\Omega \\to \\mathbb{R}$ represent the outcome of the roll, such that $X(\\omega) = \\omega$ for any outcome $\\omega \\in \\Omega$.\nThe expected value of $X$, denoted $E[X]$, is defined as the Lebesgue integral of $X$ with respect to the measure $P$, i.e., $E[X] = \\int_{\\Omega} X \\, dP$.\nBy representing the random variable $X$ as a simple function in its canonical form, calculate its expected value. Express your final answer as a decimal number rounded to two significant figures.", "solution": "The random variable $X:\\Omega\\to\\mathbb{R}$ takes finitely many values, so it is a simple function. Its canonical representation is given by the sum over its distinct values multiplied by the indicators of their preimages:\n$$\nX(\\omega)=\\sum_{k=1}^{6} k\\,\\mathbf{1}_{\\{\\omega\\in\\Omega:X(\\omega)=k\\}}(\\omega)=\\sum_{k=1}^{6} k\\,\\mathbf{1}_{\\{k\\}}(\\omega),\n$$\nsince $X(\\omega)=\\omega$ and therefore $\\{\\omega:X(\\omega)=k\\}=\\{k\\}$. The Lebesgue integral of a simple function $\\phi=\\sum_{i=1}^{n} a_{i}\\mathbf{1}_{A_{i}}$ with respect to a measure $P$ is\n$$\n\\int_{\\Omega} \\phi \\, dP=\\sum_{i=1}^{n} a_{i} P(A_{i}).\n$$\nApplying this to $X$, we obtain\n$$\nE[X]=\\int_{\\Omega} X\\, dP=\\sum_{k=1}^{6} k\\,P(\\{k\\}).\n$$\nBy the given probability measure $P(A)=\\frac{|A|}{6}$, we have $P(\\{k\\})=\\frac{1}{6}$ for each $k\\in\\{1,2,3,4,5,6\\}$. Hence,\n$$\nE[X]=\\sum_{k=1}^{6} k \\cdot \\frac{1}{6}=\\frac{1}{6}\\sum_{k=1}^{6} k=\\frac{1}{6}\\cdot \\frac{6\\cdot 7}{2}=\\frac{21}{6}=\\frac{7}{2}=3.5.\n$$\nExpressed as a decimal rounded to two significant figures, the result is $3.5$.", "answer": "$$\\boxed{3.5}$$", "id": "1360918"}, {"introduction": "Having grounded our understanding in a discrete setting, we now turn to continuous random variables. This practice considers a random variable defined on the unit interval $[0, 1]$ with the standard Lebesgue measure. You will apply the definition of expectation as a Lebesgue integral, discovering the crucial link that for continuous functions on a closed interval, this integral is equivalent to the familiar Riemann integral.", "problem": "Consider a probability space $(\\Omega, \\mathcal{F}, P)$, which serves as a mathematical model for a random experiment. In our specific case, the sample space $\\Omega$ is the closed unit interval $[0, 1]$. The collection of events, $\\mathcal{F}$, is the Borel $\\sigma$-algebra on $[0, 1]$, denoted $\\mathcal{B}([0, 1])$. The probability measure $P$ is the standard Lebesgue measure on $[0, 1]$, which we will denote by $\\lambda$. This setup effectively models the selection of a point uniformly at random from the interval $[0, 1]$.\n\nA real-valued random variable $X$ is defined on this probability space. For any outcome $\\omega \\in \\Omega$, the random variable is given by the function $X(\\omega) = \\omega^3 + \\omega$.\n\nUsing the definition of the expectation of a random variable as a Lebesgue integral with respect to the probability measure, calculate the expected value of $X$, denoted $E[X]$.", "solution": "The expected value of a random variable $X$ defined on a probability space $(\\Omega, \\mathcal{F}, P)$ is given by the Lebesgue integral of $X$ over the sample space $\\Omega$ with respect to the probability measure $P$. The formula is:\n$$E[X] = \\int_{\\Omega} X(\\omega) \\, dP(\\omega)$$\n\nIn this problem, we are given:\n- The sample space $\\Omega = [0, 1]$.\n- The probability measure $P = \\lambda$, the Lebesgue measure on $[0, 1]$.\n- The random variable $X(\\omega) = \\omega^3 + \\omega$.\n\nSubstituting these into the definition of expectation, we get:\n$$E[X] = \\int_{[0, 1]} (\\omega^3 + \\omega) \\, d\\lambda(\\omega)$$\n\nThe random variable $X(\\omega) = \\omega^3 + \\omega$ is a continuous function on the interval $[0, 1]$. A fundamental theorem of measure theory states that if a function is Riemann integrable on a closed and bounded interval $[a, b]$, then it is also Lebesgue integrable on that interval, and the values of the two integrals are identical. Since any continuous function on a closed and bounded interval is Riemann integrable, we can evaluate the Lebesgue integral by computing the corresponding Riemann integral.\n\nThus, we can write:\n$$E[X] = \\int_{0}^{1} (\\omega^3 + \\omega) \\, d\\omega$$\n\nWe now evaluate this standard definite integral using the power rule for integration:\n$$E[X] = \\left[ \\frac{\\omega^{3+1}}{3+1} + \\frac{\\omega^{1+1}}{1+1} \\right]_{0}^{1}$$\n$$E[X] = \\left[ \\frac{\\omega^4}{4} + \\frac{\\omega^2}{2} \\right]_{0}^{1}$$\n\nNext, we apply the Fundamental Theorem of Calculus by substituting the limits of integration:\n$$E[X] = \\left( \\frac{1^4}{4} + \\frac{1^2}{2} \\right) - \\left( \\frac{0^4}{4} + \\frac{0^2}{2} \\right)$$\n$$E[X] = \\left( \\frac{1}{4} + \\frac{1}{2} \\right) - (0 + 0)$$\n$$E[X] = \\frac{1}{4} + \\frac{2}{4}$$\n$$E[X] = \\frac{3}{4}$$\n\nTherefore, the expected value of the random variable $X$ is $\\frac{3}{4}$.", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1418553"}, {"introduction": "A primary motivation for developing the Lebesgue integral was its superior handling of limit operations. This exercise explores a classic scenario where the limit of expectations does not equal the expectation of the limit. Analyzing this sequence of functions [@problem_id:1360914] demonstrates why we cannot naively swap limits and integrals and underscores the importance of convergence theorems like the Monotone and Dominated Convergence Theorems.", "problem": "Consider a sequence of random variables $\\{X_n\\}_{n=1}^{\\infty}$ defined on the probability space $(\\Omega, \\mathcal{F}, P)$, where the sample space is the unit interval $\\Omega = [0, 1]$, the sigma-algebra $\\mathcal{F}$ is the Borel sigma-algebra on $[0,1]$, and the probability measure $P$ is the Lebesgue measure on $[0,1]$ (corresponding to a continuous uniform distribution).\n\nEach random variable in the sequence is defined by the function $X_n(\\omega) = n \\cdot I_{(0, 1/n)}(\\omega)$, where $I_A(\\omega)$ is the indicator function for the set $A$, which equals 1 if $\\omega \\in A$ and 0 otherwise.\n\nThis sequence can be interpreted as a simplified model for a series of high-intensity, short-duration phenomena. As $n$ increases, the magnitude of the outcome, $n$, grows, while the interval over which it occurs, $(0, 1/n)$, shrinks.\n\nYour task is to analyze the limiting behavior of the expectations of this sequence.\n1.  First, calculate the limit of the expected values, denoted as $L_E = \\lim_{n \\to \\infty} E[X_n]$.\n2.  Second, determine the pointwise limit of the sequence of random variables, which we'll call $X(\\omega) = \\lim_{n \\to \\infty} X_n(\\omega)$ for each $\\omega \\in [0, 1]$. Then, calculate the expectation of this limiting random variable, denoted as $E_L = E[X]$.\n\nProvide the values of $L_E$ and $E_L$ as an ordered pair $(L_E, E_L)$.", "solution": "We are given $X_{n}(\\omega)=n\\,I_{(0,1/n)}(\\omega)$ on $\\Omega=[0,1]$ with Lebesgue measure $P$. By definition of expectation for a nonnegative measurable function,\n$$\nE[X_{n}]=\\int_{0}^{1}X_{n}(\\omega)\\,d\\omega=\\int_{0}^{1}n\\,I_{(0,1/n)}(\\omega)\\,d\\omega.\n$$\nUsing linearity of the integral and the property $\\int I_{A}\\,dP=P(A)$,\n$$\nE[X_{n}]=n\\,P\\big((0,1/n)\\big)=n\\cdot\\frac{1}{n}=1.\n$$\nTherefore, the limit of the expectations is\n$$\nL_{E}=\\lim_{n\\to\\infty}E[X_{n}]=\\lim_{n\\to\\infty}1=1.\n$$\n\nNext, fix $\\omega\\in[0,1]$ and analyze the pointwise limit $X(\\omega)=\\lim_{n\\to\\infty}X_{n}(\\omega)$. If $\\omega=0$, then $I_{(0,1/n)}(0)=0$ for all $n$, hence $X_{n}(0)=0$ for all $n$ and $\\lim_{n\\to\\infty}X_{n}(0)=0$. If $\\omega0$, choose $N\\in\\mathbb{N}$ with $N\\frac{1}{\\omega}$, which implies that for all $n\\geq N$ we have $\\frac{1}{n}\\omega$, so $\\omega\\notin(0,1/n)$ and $I_{(0,1/n)}(\\omega)=0$. Thus $X_{n}(\\omega)=0$ for all sufficiently large $n$, and therefore $\\lim_{n\\to\\infty}X_{n}(\\omega)=0$. It follows that\n$$\nX(\\omega)=0\\quad\\text{for all }\\omega\\in[0,1].\n$$\nHence $X\\equiv 0$ almost everywhere, and its expectation is\n$$\nE_{L}=E[X]=\\int_{0}^{1}0\\,d\\omega=0.\n$$\n\nTherefore, the ordered pair is $(L_{E},E_{L})=(1,0)$.", "answer": "$$\\boxed{\\begin{pmatrix}1  0\\end{pmatrix}}$$", "id": "1360914"}]}