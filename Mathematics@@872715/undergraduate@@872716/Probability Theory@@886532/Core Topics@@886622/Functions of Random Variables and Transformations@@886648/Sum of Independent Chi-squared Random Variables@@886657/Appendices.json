{"hands_on_practices": [{"introduction": "A foundational skill in working with random variables is calculating their expected values. This first practice provides a direct application of the linearity of expectation, a powerful tool that simplifies complex problems. By calculating the expected value of a performance metric modeled as a scaled sum of two independent chi-squared variables, you will reinforce your understanding of the mean of a $\\chi^2$ distribution and its behavior in linear combinations [@problem_id:1391097].", "problem": "An aerospace engineer is evaluating the performance of a satellite's navigation system. The total system error is influenced by two independent subsystems: a Global Positioning System (GPS) receiver and an Inertial Measurement Unit (IMU). The normalized squared positional error from the GPS receiver is a random variable $E_1$, and the corresponding error from the IMU is a random variable $E_2$. Both errors are measured in units of meters squared ($m^2$). Based on extensive testing, $E_1$ is found to follow a chi-squared distribution with 2 degrees of freedom, and $E_2$ is found to follow an independent chi-squared distribution with 4 degrees of freedom. A key performance metric, $M$, for the combined system is defined as $M = 5(E_1 + E_2)$.\n\nCalculate the expected value of this performance metric, $M$. Express your answer in units of $m^2$.", "solution": "Let $E_{1} \\sim \\chi^2(2)$ and $E_{2} \\sim \\chi^2(4)$, independent. The performance metric is $M=5(E_{1}+E_{2})$. By linearity of expectation,\n$$\n\\mathbb{E}[M]=\\mathbb{E}\\big[5(E_{1}+E_{2})\\big]=5\\big(\\mathbb{E}[E_{1}]+\\mathbb{E}[E_{2}]\\big).\n$$\nFor a chi-squared random variable with $k$ degrees of freedom, $X \\sim \\chi^2(k)$, we can represent $X$ as a gamma random variable $X \\sim \\Gamma(\\alpha,\\theta)$ with shape $\\alpha=\\frac{k}{2}$ and scale $\\theta=2$. The mean of a gamma random variable is $\\mathbb{E}[X]=\\alpha\\theta$, hence\n$$\n\\mathbb{E}[\\chi^2(k)]=\\frac{k}{2}\\cdot 2=k.\n$$\nTherefore,\n$$\n\\mathbb{E}[E_{1}]=2, \\quad \\mathbb{E}[E_{2}]=4,\n$$\nand\n$$\n\\mathbb{E}[M]=5(2+4)=30.\n$$\nSince $E_{1}$ and $E_{2}$ are in units of $m^{2}$ and $M$ is a scalar multiple of their sum, $\\mathbb{E}[M]$ is $30$ in units of $m^{2}$.", "answer": "$$\\boxed{30}$$", "id": "1391097"}, {"introduction": "The most significant feature of independent chi-squared variables is their additive property: their sum is also a chi-squared variable with degrees of freedom equal to the sum of the individual degrees of freedom. This exercise challenges you to apply this principle in reverse, a common task in statistical modeling known as variance decomposition. By identifying the distribution of an unknown component in a sum, you will solidify your grasp of this fundamental theorem [@problem_id:1391082].", "problem": "In a statistical analysis of experimental data, a summary statistic $Z$ is calculated. It is known that $Z$ follows a chi-squared distribution with 15 degrees of freedom, denoted as $Z \\sim \\chi^2(15)$.\n\nThis statistic $Z$ is found to be the sum of two independent components, $X$ and $Y$, such that $Z = X + Y$. The component $X$ is known to model a specific source of variation and follows a chi-squared distribution with 9 degrees of freedom, i.e., $X \\sim \\chi^2(9)$.\n\nIdentify the probability distribution of the component $Y$.\n\nA. The Normal distribution with mean 6 and variance 12, $N(6, 12)$.\n\nB. The chi-squared distribution with 24 degrees of freedom, $\\chi^2(24)$.\n\nC. The chi-squared distribution with 6 degrees of freedom, $\\chi^2(6)$.\n\nD. The Student's t-distribution with 6 degrees of freedom, $t(6)$.", "solution": "We are given that $Z \\sim \\chi^{2}(15)$, $X \\sim \\chi^{2}(9)$, and $Z = X + Y$ with $X$ and $Y$ independent. We seek the distribution of $Y$.\n\nUse the moment generating function (MGF) of the chi-squared distribution: if $W \\sim \\chi^{2}(k)$, then for $t  \\frac{1}{2}$,\n$$\nM_{W}(t) = (1 - 2t)^{-k/2}.\n$$\nSince $Z = X + Y$ with independence, the MGF factorizes:\n$$\nM_{Z}(t) = M_{X}(t) M_{Y}(t).\n$$\nThus,\n$$\nM_{Y}(t) = \\frac{M_{Z}(t)}{M_{X}(t)} = \\frac{(1 - 2t)^{-15/2}}{(1 - 2t)^{-9/2}} = (1 - 2t)^{-6/2}.\n$$\nRecognizing this as the MGF of a chi-squared distribution with $6$ degrees of freedom, we conclude\n$$\nY \\sim \\chi^{2}(6).\n$$\nTherefore, the correct option is C.", "answer": "$$\\boxed{C}$$", "id": "1391082"}, {"introduction": "Moving beyond the properties of a simple sum, this practice explores the statistical relationship between different combinations of random variables. You will calculate the covariance between the sum ($S=X+Y$) and the difference ($D=X-Y$) of two independent chi-squared variables. This problem illustrates how fundamental properties like variance and independence govern the interactions between more complex statistical constructs, providing deeper insight into the structure of the data [@problem_id:1391110].", "problem": "In the quality control process for a newly designed dual-filament lamp, the energy output fluctuations of its two independent segments, A and B, are analyzed. Statistical models based on extensive testing have shown that the scaled energy fluctuation of segment A, denoted by the random variable $X$, follows a chi-squared distribution with $k_A$ degrees of freedom. Similarly, the scaled energy fluctuation of segment B, denoted by $Y$, follows a chi-squared distribution with $k_B$ degrees of freedom. The two segments are manufactured and operate independently.\n\nAn engineer is interested in the statistical relationship between the total fluctuation of the lamp, defined as $S = X + Y$, and the imbalance in fluctuation between the segments, defined as $D = X - Y$.\n\nDetermine the covariance between the total fluctuation $S$ and the imbalance $D$, denoted as $\\text{Cov}(S, D)$. Express your answer as an analytic expression in terms of the parameters $k_A$ and $k_B$.", "solution": "Let $X \\sim \\chi^2(k_A)$ and $Y \\sim \\chi^2(k_B)$ be independent. Define $S=X+Y$ and $D=X-Y$. We seek $\\text{Cov}(S,D)$.\n\nUse the definition and bilinearity of covariance:\n$$\n\\text{Cov}(S,D)=\\text{Cov}(X+Y,\\,X-Y)=\\text{Cov}(X,X)-\\text{Cov}(X,Y)+\\text{Cov}(Y,X)-\\text{Cov}(Y,Y).\n$$\nIndependence implies $\\text{Cov}(X,Y)=\\text{Cov}(Y,X)=0$, and $\\text{Cov}(X,X)=\\text{Var}(X)$, $\\text{Cov}(Y,Y)=\\text{Var}(Y)$. Hence,\n$$\n\\text{Cov}(S,D)=\\text{Var}(X)-\\text{Var}(Y).\n$$\nFor a chi-squared random variable with $k$ degrees of freedom, $\\text{Var}(\\chi^2(k))=2k$. Therefore,\n$$\n\\text{Cov}(S,D)=2k_{A}-2k_{B}=2\\left(k_{A}-k_{B}\\right).\n$$\nThis provides the required analytic expression in terms of $k_{A}$ and $k_{B}$.", "answer": "$$\\boxed{2\\left(k_{A}-k_{B}\\right)}$$", "id": "1391110"}]}