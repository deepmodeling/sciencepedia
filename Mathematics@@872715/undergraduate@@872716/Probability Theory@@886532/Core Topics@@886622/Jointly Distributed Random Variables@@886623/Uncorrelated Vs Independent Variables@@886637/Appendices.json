{"hands_on_practices": [{"introduction": "This first practice problem provides a foundational counterexample to the common misconception that uncorrelated variables must be independent. By examining a carefully constructed joint probability distribution on just three points, you can directly calculate the relevant expectations and see how variables can have a clear structural dependency while still exhibiting zero covariance. This exercise is key to building a solid intuition for the distinction between these two fundamental concepts. [@problem_id:1408655]", "problem": "Consider a system described by two random variables, $X$ and $Y$. The joint probability distribution of these variables is discrete and concentrated on three points in the plane. The allowed pairs of values $(x, y)$ are $(-1, 1)$, $(1, 1)$, and $(0, -2)$. The system has an equal probability of being found in any of these three states.\n\nBased on this information, select the statement that correctly describes the relationship between the random variables $X$ and $Y$.\n\nA. $X$ and $Y$ are independent and uncorrelated.\n\nB. $X$ and $Y$ are independent but correlated.\n\nC. $X$ and $Y$ are dependent but uncorrelated.\n\nD. $X$ and $Y$ are dependent and correlated.\n\nE. The relationship cannot be determined from the given information.", "solution": "The joint distribution is uniform over the three points $(-1,1)$, $(1,1)$, and $(0,-2)$, so each has probability $\\frac{1}{3}$. The marginals are\n$$\nP(X=-1)=\\frac{1}{3},\\quad P(X=1)=\\frac{1}{3},\\quad P(X=0)=\\frac{1}{3},\n$$\n$$\nP(Y=1)=\\frac{2}{3},\\quad P(Y=-2)=\\frac{1}{3}.\n$$\nTo test independence, use the criterion $P(X=x,Y=y)=P(X=x)P(Y=y)$ for all $(x,y)$. Consider $(x,y)=(0,1)$: the joint probability is\n$$\nP(X=0,Y=1)=0,\n$$\nwhile the product of marginals is\n$$\nP(X=0)P(Y=1)=\\frac{1}{3}\\cdot\\frac{2}{3}=\\frac{2}{9}\\neq 0.\n$$\nHence $X$ and $Y$ are not independent, so they are dependent.\n\nTo test for uncorrelatedness, compute the covariance $\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]$. First,\n$$\n\\mathbb{E}[X]=(-1)\\cdot\\frac{1}{3}+1\\cdot\\frac{1}{3}+0\\cdot\\frac{1}{3}=0,\n$$\n$$\n\\mathbb{E}[Y]=1\\cdot\\frac{1}{3}+1\\cdot\\frac{1}{3}+(-2)\\cdot\\frac{1}{3}=0,\n$$\nand\n$$\n\\mathbb{E}[XY]=(-1)(1)\\cdot\\frac{1}{3}+(1)(1)\\cdot\\frac{1}{3}+(0)(-2)\\cdot\\frac{1}{3}=0.\n$$\nTherefore,\n$$\n\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]=0-0=0,\n$$\nso $X$ and $Y$ are uncorrelated.\n\nCombining both results, $X$ and $Y$ are dependent but uncorrelated.", "answer": "$$\\boxed{C}$$", "id": "1408655"}, {"introduction": "Building on the foundational example, this problem moves from an abstract distribution to a concrete scenario involving sampling from an urn. Here, you must first derive the joint behavior of the variables from the physical process of drawing balls without replacement. This practice deepens your understanding by showing how the properties of dependence and uncorrelatedness can emerge from the structure of a real-world experiment. [@problem_id:1408661]", "problem": "An urn contains three distinct balls, with the numbers $\\{-1, 0, 1\\}$ written on them. Two balls are drawn sequentially from the urn without replacement. Let the random variable $X$ be the number on the first ball drawn, and let the random variable $Z$ be the product of the numbers on the two balls drawn.\n\nWhich of the following statements accurately describes the relationship between the random variables $X$ and $Z$?\n\nA. $X$ and $Z$ are independent and uncorrelated.\n\nB. $X$ and $Z$ are independent but correlated.\n\nC. $X$ and $Z$ are dependent but uncorrelated.\n\nD. $X$ and $Z$ are dependent and correlated.", "solution": "Let the urn contain the set $S=\\{-1,0,1\\}$. Two balls are drawn sequentially without replacement, generating ordered outcomes; there are $3 \\times 2=6$ equally likely ordered pairs.\n\nBy definition, $X$ is the value of the first draw, so $P(X=x)=\\frac{1}{3}$ for each $x \\in \\{-1,0,1\\}$.\n\nDefine $Y$ as the value of the second draw; then $Z=XY$.\n\nTo test independence of $X$ and $Z$, use the criterion $P(Z=z \\mid X=x)=P(Z=z)$ for all $(x,z)$. First compute the marginal distribution of $Z$ from the $6$ ordered outcomes:\n- If the pair contains $0$, then $Z=0$. There are $4$ such ordered pairs, so $P(Z=0)=\\frac{4}{6}=\\frac{2}{3}$.\n- If the pair is $\\{-1,1\\}$ in either order, then $Z=-1$. There are $2$ such ordered pairs, so $P(Z=-1)=\\frac{2}{6}=\\frac{1}{3}$.\nNow compute $P(Z=0 \\mid X=0)$. Given $X=0$, the second draw is either $-1$ or $1$, and in both cases $Z=0\\cdot(\\cdot)=0$, so $P(Z=0 \\mid X=0)=1$. Since $P(Z=0 \\mid X=0)\\neq P(Z=0)$, $X$ and $Z$ are dependent.\n\nTo test whether they are uncorrelated, compute the covariance $\\operatorname{Cov}(X,Z)=\\mathbb{E}[XZ]-\\mathbb{E}[X]\\mathbb{E}[Z]$.\n- By symmetry, $\\mathbb{E}[X]=\\frac{(-1)+0+1}{3}=0$.\n- From the distribution of $Z$, $\\mathbb{E}[Z]=0 \\cdot \\frac{2}{3}+(-1)\\cdot \\frac{1}{3}=-\\frac{1}{3}$.\n- Compute $\\mathbb{E}[XZ]$ via the law of total expectation:\n  For $X=1$, the remaining values for the second draw are $-1$ and $0$, each with probability $\\frac{1}{2}$, so $Z$ is $-1$ or $0$ with equal probability. Thus $\\mathbb{E}[XZ \\mid X=1]=\\frac{(-1)+0}{2}=-\\frac{1}{2}$.\n  For $X=-1$, the remaining values are $0$ and $1$, so $Z$ is $0$ or $-1$ with equal probability, and $XZ=(-1)\\cdot Z$ is $0$ or $1$, hence $\\mathbb{E}[XZ \\mid X=-1]=\\frac{0+1}{2}=\\frac{1}{2}$.\n  For $X=0$, $Z=0$ deterministically, so $\\mathbb{E}[XZ \\mid X=0]=0$.\n  Therefore,\n  $$\\mathbb{E}[XZ]=\\sum_{x \\in \\{-1,0,1\\}} P(X=x)\\,\\mathbb{E}[XZ \\mid X=x]=\\frac{1}{3}\\left(\\frac{1}{2}+0-\\frac{1}{2}\\right)=0.$$\nHence $\\operatorname{Cov}(X,Z)=0-0\\cdot\\left(-\\frac{1}{3}\\right)=0$, so $X$ and $Z$ are uncorrelated.\n\nConclusion: $X$ and $Z$ are dependent (not independent) but uncorrelated.\n\nTherefore, the correct option is C.", "answer": "$$\\boxed{C}$$", "id": "1408661"}, {"introduction": "This final exercise extends the concept from discrete to continuous random variables, demonstrating its broad applicability. By analyzing a point chosen uniformly from a symmetric triangular region, you'll use integral calculus to explore the relationship between the coordinates. This practice provides a powerful visual intuition, showing how geometric symmetry in a continuous sample space can result in zero correlation between variables that are clearly dependent. [@problem_id:1408647]", "problem": "A point $(X,Y)$ is chosen according to a uniform probability distribution from the two-dimensional region defined by the interior of the triangle with vertices at $(0,0)$, $(1,1)$, and $(1,-1)$. Based on this information, determine the relationship between the random variables $X$ and $Y$.\n\nWhich of the following statements is true?\nA. $X$ and $Y$ are independent and correlated.\n\nB. $X$ and $Y$ are independent and uncorrelated.\n\nC. $X$ and $Y$ are dependent and correlated.\n\nD. $X$ and $Y$ are dependent and uncorrelated.", "solution": "The region is the interior of the triangle with vertices at $(0,0)$, $(1,1)$, and $(1,-1)$. Its set description is\n$$\nR=\\{(x,y): 0 \\leq x \\leq 1,\\ -x \\leq y \\leq x\\}.\n$$\nThe area of $R$ is\n$$\nA=\\int_{0}^{1}\\int_{-x}^{x} 1 \\, dy \\, dx=\\int_{0}^{1} 2x \\, dx=1.\n$$\nSince $(X,Y)$ is uniformly distributed over $R$, the joint density is\n$$\nf_{X,Y}(x,y)=\\begin{cases}\n1,  (x,y)\\in R,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThe marginal density of $X$ is\n$$\nf_{X}(x)=\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)\\,dy=\\int_{-x}^{x} 1 \\, dy=2x,\\quad 0 \\leq x \\leq 1,\n$$\nand $f_{X}(x)=0$ otherwise. The marginal density of $Y$ is, for $-1 \\leq y \\leq 1$,\n$$\nf_{Y}(y)=\\int_{-\\infty}^{\\infty} f_{X,Y}(x,y)\\,dx=\\int_{|y|}^{1} 1 \\, dx=1-|y|,\n$$\nand $f_{Y}(y)=0$ otherwise.\n\nTo test independence, compare $f_{X,Y}(x,y)$ to $f_{X}(x)f_{Y}(y)$. On $R$,\n$$\nf_{X}(x)f_{Y}(y)=2x\\,(1-|y|),\n$$\nwhich is not identically equal to $1=f_{X,Y}(x,y)$ over $R$. Therefore $X$ and $Y$ are not independent; they are dependent.\n\nTo test correlation, compute the covariance. First,\n$$\n\\mathbb{E}[Y]=\\int_{0}^{1}\\int_{-x}^{x} y \\cdot 1 \\, dy \\, dx=\\int_{0}^{1}\\left[\\frac{y^{2}}{2}\\right]_{-x}^{x} dx=\\int_{0}^{1} \\left(\\frac{x^{2}}{2}-\\frac{x^{2}}{2}\\right) dx=0.\n$$\nNext,\n$$\n\\mathbb{E}[XY]=\\int_{0}^{1}\\int_{-x}^{x} xy \\cdot 1 \\, dy \\, dx=\\int_{0}^{1} x \\left[\\frac{y^{2}}{2}\\right]_{-x}^{x} dx=\\int_{0}^{1} x \\left(\\frac{x^{2}}{2}-\\frac{x^{2}}{2}\\right) dx=0.\n$$\nThus,\n$$\n\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]=0-\\mathbb{E}[X]\\cdot 0=0,\n$$\nso $X$ and $Y$ are uncorrelated.\n\nCombining the two conclusions: $X$ and $Y$ are dependent and uncorrelated. The correct choice is D.", "answer": "$$\\boxed{D}$$", "id": "1408647"}]}