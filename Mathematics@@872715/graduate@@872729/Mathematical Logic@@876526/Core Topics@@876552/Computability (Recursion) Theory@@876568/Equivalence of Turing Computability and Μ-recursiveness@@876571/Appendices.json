{"hands_on_practices": [{"introduction": "Kleene's Normal Form Theorem is a pivotal result, asserting that any computable function can be expressed in a standard form using a single application of the $\\mu$-operator. However, the theorem is often first presented for unary functions. This practice challenges you to formalize the extension of this powerful theorem to functions of any arity, a necessary step in demonstrating the full scope of $\\mu$-recursiveness [@problem_id:2972638]. Mastering this involves the essential technique of using primitive recursive pairing functions to encode multiple inputs into a single number, a fundamental method for aligning different models of computation.", "problem": "Suppose a standard Gödel (Kurt Gödel) numbering of Turing programs is fixed, together with a unary Kleene normal form: there exist a primitive recursive ternary relation $T(e,x,y)$ and a total primitive recursive function $U(y)$ such that for every unary partial $\\mu$-recursive function $g:\\mathbb{N}\\to\\mathbb{N}$ there is an index $e_g$ with $g(x)=U(\\mu y\\, T(e_g,x,y))$ whenever $g(x)$ is defined. Let $k\\geq 2$ and let $f:\\mathbb{N}^k\\to\\mathbb{N}$ be a $k$-ary partial $\\mu$-recursive function. The goal is to obtain a uniform normal form for all arities $k$ by reducing multi-argument inputs to the unary case in a way that preserves primitive recursiveness and uniformity of the witnessing objects.\n\nWhich option correctly achieves this goal?\n\nA. Fix, for each $k\\geq 1$, a primitive recursive tupling function $\\tau_k:\\mathbb{N}^k\\to\\mathbb{N}$ with primitive recursive projections $\\rho_{k,i}:\\mathbb{N}\\to\\mathbb{N}$ for $i\\in\\{1,\\dots,k\\}$. For each $k$-ary $f$, define the unary $g(z)\\!:=\\! f(\\rho_{k,1}(z),\\dots,\\rho_{k,k}(z))$, apply the unary normal form to $g$ to obtain an index $e$, and then set $T_k(e,\\vec{x},y)\\!:=\\! T(e,\\tau_k(\\vec{x}),y)$ and $U_k\\!:=\\! U$. This yields, uniformly in $k$, a normal form $f(\\vec{x})=U_k(\\mu y\\, T_k(e,\\vec{x},y))$ whenever $f(\\vec{x})$ is defined.\n\nB. Keep the inputs separate by generalizing minimization to range over vectors: let $\\mu\\vec{y}$ minimize over $\\vec{y}\\in\\mathbb{N}^k$, and define $T_k(e,\\vec{x},\\vec{y})$ to simulate $k$ independent computations on $x_1,\\dots,x_k$ with the same index $e$. Then define $U_k$ to decode from $\\vec{y}$ the output. This dispenses with any need to encode tuples into a single natural number.\n\nC. Use the $s$-$m$-$n$ theorem alone to eliminate extra arguments: for each fixed $(x_2,\\dots,x_k)$ obtain $e'(\\,x_2,\\dots,x_k\\,)$ such that $x_1\\mapsto f(x_1,\\dots,x_k)$ is computed by index $e'(\\,x_2,\\dots,x_k\\,)$, and apply the unary normal form to $x_1\\mapsto f(x_1,\\dots,x_k)$ with index depending on $(x_2,\\dots,x_k)$. This avoids any tuple encoding and still yields a normal form with a $\\mu$-operator over a single $y$.\n\nD. Because the arity $k$ changes the shape of computation histories, it is necessary to replace $U$ by a family $\\{U_k\\}_{k\\geq 1}$ in which $U_k$ depends on $k$ in an essentially non-primitive-recursive way; no primitive recursive adjustment using tupling can make a single $U$ work uniformly across all $k$.", "solution": "## Problem Validation ##\n\n### Step 1: Extract Givens\n- A fixed standard Gödel numbering of Turing programs is assumed.\n- A unary Kleene normal form is given for any unary partial $\\mu$-recursive function $g:\\mathbb{N}\\to\\mathbb{N}$.\n- This normal form states the existence of a primitive recursive ternary relation $T(e,x,y)$ and a total primitive recursive unary function $U(y)$.\n- For any such $g$, there exists an index $e_g$ such that $g(x)=U(\\mu y\\, T(e_g,x,y))$ holds whenever $g(x)$ is defined. The expression $\\mu y\\, P(y)$ denotes the smallest natural number $y$ for which the predicate $P(y)$ is true.\n- We are given a $k$-ary partial $\\mu$-recursive function $f:\\mathbb{N}^k\\to\\mathbb{N}$ where $k\\geq 2$.\n- The goal is to find a method to construct a uniform normal form for functions of any arity $k$, by reducing the multi-argument case to the unary case.\n- The method must preserve primitive recursiveness and uniformity of the \"witnessing objects\" (i.e., the generalized T-predicate and U-function).\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding (Critical):** The problem is\n  firmly grounded in computability theory, a branch of mathematical logic. Kleene's Normal Form Theorem is a fundamental result in this field. The concepts of Gödel numbering, primitive recursive functions, $\\mu$-recursive functions, and the T-predicate are all standard and well-defined. The problem asks for a standard generalization of this theorem. The premises are factually sound.\n- **Well-Posed:** The problem is well-posed. It asks for the correct procedure among several options to generalize a known mathematical theorem. A unique, correct procedure exists and is a standard part of the theory of computation.\n- **Objective (Critical):** The language used is formal, precise, and objective, employing standard terminology from mathematical logic. There are no subjective or ambiguous statements.\n- **Other Flaws:** The problem is self-contained, not contradictory, mathematically feasible, well-structured, and non-trivial. It directly addresses a core concept in the equivalence of Turing computability and $\\mu$-recursiveness.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. All conditions for a valid problem are met. I will now proceed to derive the solution and evaluate the given options.\n\n## Solution Derivation ##\n\nThe task is to generalize the Kleene normal form from unary functions to $k$-ary functions for any $k \\geq 2$. The normal form for a unary partial $\\mu$-recursive function $g$ with index $e_g$ is given as $g(x) = U(\\mu y\\, T(e_g, x, y))$. Here, $T$ is a primitive recursive predicate that is true if $y$ is the Gödel number of a halting computation of the machine with index $e_g$ on input $x$. $U$ is a primitive recursive function that extracts the result of the computation from the Gödel number $y$.\n\nTo handle a $k$-ary function $f(x_1, \\dots, x_k)$, the standard technique is to reduce it to a unary function by encoding the input vector $(x_1, \\dots, x_k)$ into a single natural number. This requires a set of a tupling function and projection functions.\n\nFor each $k \\geq 1$, we need a bijective (or at least injective) mapping $\\tau_k: \\mathbb{N}^k \\to \\mathbb{N}$. We also need the corresponding inverse projection functions $\\rho_{k,i}: \\mathbb{N} \\to \\mathbb{N}$ for $i \\in \\{1, \\dots, k\\}$, such that $\\rho_{k,i}(\\tau_k(x_1, \\dots, x_k)) = x_i$ for all $i$. For this framework to be compatible with primitive recursion, the function $\\tau_k$ and all projection functions $\\rho_{k,i}$ must be primitive recursive.\n\nSuch functions exist. For instance, one can iterate the Cantor pairing function $\\pi(a,b) = \\frac{1}{2}(a+b)(a+b+1)+b$, which is primitive recursive and has primitive recursive projections. We can define $\\tau_k(x_1, \\dots, x_k)$ for $k \\ge 2$ as $\\tau_k(x_1, \\dots, x_k) = \\pi(x_1, \\tau_{k-1}(x_2, \\dots, x_k))$. This entire family of tupling and projection functions can be defined uniformly and are all primitive recursive.\n\nGiven a $k$-ary partial $\\mu$-recursive function $f:\\mathbb{N}^k\\to\\mathbb{N}$, we can define a corresponding unary function $g:\\mathbb{N}\\to\\mathbb{N}$ as follows:\n$$ g(z) := f(\\rho_{k,1}(z), \\rho_{k,2}(z), \\dots, \\rho_{k,k}(z)) $$\nSince $f$ is partial $\\mu$-recursive and the projection functions $\\rho_{k,i}$ are primitive recursive (and thus total $\\mu$-recursive), their composition $g$ is also a partial $\\mu$-recursive function.\n\nBy the given unary Kleene normal form theorem, there exists an index $e_g$ for the function $g$ such that:\n$$ g(z) = U(\\mu y \\ldotp T(e_g, z, y)) $$\n\nNow we can express $f$ in terms of this construction. Let $\\vec{x} = (x_1, \\dots, x_k)$. Then we have:\n$$ f(\\vec{x}) = g(\\tau_k(\\vec{x})) $$\nSubstituting the normal form for $g(z)$ with $z = \\tau_k(\\vec{x})$ yields:\n$$ f(\\vec{x}) = U(\\mu y \\ldotp T(e_g, \\tau_k(\\vec{x}), y)) $$\n\nThis expression already has the desired structure. To make it a formal $k$-ary normal form, we can define a new $k$-ary T-predicate, $T_k$, and a new output function, $U_k$.\nLet's define $T_k$ for an arbitrary index $e$ and input vector $\\vec{x}$ as:\n$$ T_k(e, \\vec{x}, y) \\equiv T(e, \\tau_k(\\vec{x}), y) $$\nSince $T$ is a primitive recursive relation and $\\tau_k$ is a primitive recursive function, their composition $T_k$ is also a primitive recursive relation.\n\nFor the output function, we can simply set $U_k = U$. The function $U$ already extracts the output from a valid computation history $y$, and the structure of this history does not need to change. The normal form for $f$ then becomes:\n$$ f(\\vec{x}) = U_k(\\mu y \\ldotp T_k(e_g, \\vec{x}, y)) $$\nFor any $k$-ary partial $\\mu$-recursive function $f$, there exists such an index $e_g$ (computable from the index for $f$), and the witnessing objects $T_k$ and $U_k$ are primitive recursive (and constructed uniformly from $T$, $U$, and a uniform family of tupling functions). This successfully generalizes the normal form.\n\n## Option-by-Option Analysis ##\n\n**A. Fix, for each $k\\geq 1$, a primitive recursive tupling function $\\tau_k:\\mathbb{N}^k\\to\\mathbb{N}$ with primitive recursive projections $\\rho_{k,i}:\\mathbb{N}\\to\\mathbb{N}$ for $i\\in\\{1,\\dots,k\\}$. For each $k$-ary $f$, define the unary $g(z)\\!:=\\! f(\\rho_{k,1}(z),\\dots,\\rho_{k,k}(z))$, apply the unary normal form to $g$ to obtain an index $e$, and then set $T_k(e,\\vec{x},y)\\!:=\\! T(e,\\tau_k(\\vec{x}),y)$ and $U_k\\!:=\\! U$. This yields, uniformly in $k$, a normal form $f(\\vec{x})=U_k(\\mu y\\, T_k(e,\\vec{x},y))$ whenever $f(\\vec{x})$ is defined.**\n\nThis option precisely describes the standard construction derived above. It correctly identifies the need for primitive recursive tupling and projection functions, shows how to reduce the $k$-ary function $f$ to a unary function $g$, applies the existing normal form, and correctly defines the new predicate $T_k$ as a composition of $T$ and $\\tau_k$, while leaving $U$ unchanged. This construction is indeed uniform and preserves primitive recursiveness. The resulting equation corresponds exactly to our derived result.\n**Verdict: Correct.**\n\n**B. Keep the inputs separate by generalizing minimization to range over vectors: let $\\mu\\vec{y}$ minimize over $\\vec{y}\\in\\mathbb{N}^k$, and define $T_k(e,\\vec{x},\\vec{y})$ to simulate $k$ independent computations on $x_1,\\dots,x_k$ with the same index $e$. Then define $U_k$ to decode from $\\vec{y}$ the output. This dispenses with any need to encode tuples into a single natural number.**\n\nThis option is flawed. The standard $\\mu$-operator operates over $\\mathbb{N}$. To define minimization over vectors $\\vec{y} \\in \\mathbb{N}^k$, one must first establish a well-ordering on $\\mathbb{N}^k$, which is computationally equivalent to defining an invertible mapping from $\\mathbb{N}$ to $\\mathbb{N}^k$, thereby re-introducing encoding. Furthermore, the description of $T_k$ simulating \"$k$ independent computations\" is a misrepresentation of how a general $k$-ary function works; $f(\\vec{x})$ is a single computation on a tuple, not $k$ separate ones.\n**Verdict: Incorrect.**\n\n**C. Use the $s$-$m$-$n$ theorem alone to eliminate extra arguments: for each fixed $(x_2,\\dots,x_k)$ obtain $e'(\\,x_2,\\dots,x_k\\,)$ such that $x_1\\mapsto f(x_1,\\dots,x_k)$ is computed by index $e'(\\,x_2,\\dots,x_k\\,)$, and apply the unary normal form to $x_1\\mapsto f(x_1,\\dots,x_k)$ with index depending on $(x_2,\\dots,x_k)$. This avoids any tuple encoding and still yields a normal form with a $\\mu$-operator over a single $y$.**\n\nThis option misapplies the $s$-$m$-$n$ theorem for this purpose. The theorem would yield an index $e'$ that is a function of the inputs $x_2, \\dots, x_k$. The resulting expression for $f(x_1, \\dots, x_k)$ would therefore involve an index that changes with the input, i.e., $U(\\mu y \\ldotp T(s(e_f, x_2, \\dots, x_k), x_1, y))$. A normal form theorem requires a single, fixed index $e$ for the function $f$ to be slotted into a fixed predicate $T_k(e, \\vec{x}, y)$. The index cannot depend on the arguments $\\vec{x}$.\n**Verdict: Incorrect.**\n\n**D. Because the arity $k$ changes the shape of computation histories, it is necessary to replace $U$ by a family $\\{U_k\\}_{k\\geq 1}$ in which $U_k$ depends on $k$ in an essentially non-primitive-recursive way; no primitive recursive adjustment using tupling can make a single $U$ work uniformly across all $k$.**\n\nThis option makes a claim that is demonstrably false. As shown in the derivation and in option A, a primitive recursive adjustment via input tupling is precisely what allows the original unary machinery, including the single function $U$, to work for any arity $k$. The computation history $y$ is for the equivalent unary function on the encoded input, and $U$ is designed to extract the result from such a history, regardless of how the input was originally structured. There is no need for a non-primitive-recursive family of output functions.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2972638"}, {"introduction": "The computational power of $\\mu$-recursion stems from the unbounded search performed by the $\\mu$-operator, but this introduces a significant implementation challenge: the predicate being searched may itself be partial. A simple, sequential simulation would get stuck if it encountered a non-terminating sub-computation. This exercise guides you through designing a robust simulation strategy on a Turing machine using dovetailing, a method of interleaving computations to ensure fair progress [@problem_id:2972630]. This practice is key to understanding the proof that all $\\mu$-recursive functions are indeed Turing-computable, as it requires building a concrete algorithm to manage a potentially infinite search space.", "problem": "Let $R \\colon \\mathbb{N}^2 \\to \\mathbb{N}$ be a partial computable function, and suppose $R$ is computed by a fixed Turing machine $M_R$ that, on input $(x,y)$, either halts with an output in $\\mathbb{N}$ or diverges. Consider the unbounded minimization operator $\\mu$ applied to $R$ to define a partial function $f \\colon \\mathbb{N} \\to \\mathbb{N}$ by\n$$\nf(x) = \\mu y \\, [ R(x,y) = 0 ],\n$$\nwith the following semantics: $f(x)$ is defined to be the least $y$ such that $R(x,y)$ halts with output $0$, provided that for all $z  y$ the computations $R(x,z)$ halt (necessarily with outputs not equal to $0$);\notherwise $f(x)$ is undefined. This is the standard unbounded $\\mu$-minimization schema used in the definition of partial $\\mu$-recursive functions.\n\nIn proving the equivalence between Turing computability and $\\mu$-recursiveness, one must show how to simulate the $\\mu$-operator on a Turing machine, even when $R$ itself is given by a partial computation. A correct simulation must satisfy two constraints:\n- It must be extensionally correct with respect to the $\\mu$-semantics above, i.e., it returns the least $y$ with $R(x,y)=0$ only when all smaller indices have halted with nonzero outputs, and it diverges in the cases mandated by the definition.\n- It must ensure fair progress both over the search space $y \\in \\mathbb{N}$ and within the ongoing computations of $M_R(x,y)$, so that no single index $y$ or simulation of $M_R(x,y)$ is starved of steps.\n\nWhich of the following strategies specifies a correct dovetailing simulation for computing $f(x)$ from $M_R$?\n\nA. For input $x$, initialize an array of simulation states $\\sigma_y$ for all $y \\in \\mathbb{N}$, each set to the start configuration of $M_R$ on $(x,y)$. Proceed in stages $s = 0,1,2,\\dots$. At stage $s$, for every $y \\le s$, advance the simulation $\\sigma_y$ by exactly one step of $M_R$. Maintain a table of outcomes recording, for each $y$, whether $M_R(x,y)$ has halted and, if so, with which output. After each stage, check whether there exists some $y$ such that:\n- $M_R(x,y)$ has halted with output $0$, and\n- for all $z  y$, $M_R(x,z)$ has halted with outputs not equal to $0$.\nIf such a $y$ exists, output the least such $y$ and halt;\notherwise continue to the next stage. If no such $y$ ever satisfies these conditions, the simulation never halts.\n\nB. For input $x$, test indices sequentially. For $y = 0,1,2,\\dots$, run $M_R(x,y)$ to completion. If it halts with output $0$, output $y$ and halt;\nif it halts with a nonzero output, increment $y$ and repeat;\nif it diverges, loop forever and never consider larger $y$.\n\nC. For input $x$, dovetail the simulations by stages $s = 0,1,2,\\dots$;\nat stage $s$, for all $y \\le s$, perform one step of the simulation of $M_R(x,y)$. As soon as any $M_R(x,y)$ halts with output $0$, immediately output $y$ and halt, without checking the status of smaller indices.\n\nD. For input $x$, dovetail the simulations by stages $s = 0,1,2,\\dots$. At stage $s$, for all $y \\le s$, perform one step of the simulation of $M_R(x,y)$. When some $M_R(x,y)$ halts with output $0$, output $y$ and halt if, for each $z  y$, either $M_R(x,z)$ has already halted with a nonzero output or has been simulated for more than $y$ steps;\notherwise continue.\n\nSelect all options that correctly satisfy both the fair progress constraint and the $\\mu$-semantics stated above.", "solution": "The problem asks for a correct simulation strategy for the unbounded minimization operator, $\\mu$, applied to a partial computable function $R(x,y)$, to compute $f(x) = \\mu y \\, [ R(x,y) = 0 ]$. The provided semantics for this operation are crucial: $f(x)$ is defined and equals $y$ if and only if $R(x,y)=0$ and for all $z  y$, $R(x,z)$ is defined and non-zero. Otherwise, $f(x)$ is undefined. A correct simulation, which would be performed by a Turing machine, must satisfy two constraints: fair progress and extensional correctness.\n\nLet's establish the core principles for a correct simulation.\n$R \\colon \\mathbb{N}^2 \\to \\mathbb{N}$ is a partial computable function, meaning for any given input $(x,y)$, the computation of $R(x,y)$ by its Turing machine $M_R$ may not halt. To compute $f(x)$, we must potentially evaluate $R(x,y)$ for an unbounded number of values $y \\in \\{0, 1, 2, \\dots\\}$.\n\n1.  **Fair Progress**: Since any single computation $M_R(x,y)$ could diverge, a sequential search (testing $y=0$, then $y=1$, etc., running each to completion) is not viable. If $M_R(x,0)$ diverged, the simulation would get stuck and never test $y=1, 2, \\dots$. Therefore, a method of interleaving the computations for different values of $y$ is necessary. This technique is known as **dovetailing**. A common approach is to proceed in stages $s=0, 1, 2, \\dots$. In each stage $s$, a finite amount of work is done on a growing, but finite, set of computations (e.g., on $M_R(x,y)$ for all $y \\le s$). This ensures that for any $y$ and any number of steps $k$, there is a stage $s$ by which the simulation of $M_R(x,y)$ has been performed for at least $k$ steps. This prevents starvation.\n\n2.  **Extensional Correctness**: The simulation must strictly adhere to the given semantics of $\\mu$. At any point, if the simulation halts and outputs a value $y$, it must have verified the following conditions:\n    a. The computation of $M_R(x,y)$ has halted with output $0$.\n    b. For all natural numbers $z  y$, the computations of $M_R(x,z)$ have halted with outputs not equal to $0$.\n    c. The value $y$ is the least natural number satisfying condition (a).\n\nIf for a given $x$, no such $y$ exists, the simulation must never halt, correctly reflecting that $f(x)$ is undefined. This can happen if, for example, the least $y$ with $R(x,y)=0$ is such that for some $z  y$, $R(x,z)$ is undefined.\n\nNow, we evaluate each proposed strategy against these principles.\n\n**Option A:**\n\nThis strategy proposes a dovetailing simulation organized in stages $s = 0, 1, 2, \\dots$. At stage $s$, it advances the simulations of $M_R(x,y)$ for all $y \\le s$ by one step. This is a valid dovetailing scheme that ensures fair progress for both the search over $y$ and the execution of each individual computation $M_R(x,y)$.\n\nFor extensional correctness, after each stage, the strategy checks for the existence of a $y$ that satisfies the precise conditions of the $\\mu$-operator:\n1.  $M_R(x,y)$ has halted with output $0$.\n2.  For all $z  y$, $M_R(x,z)$ has halted with an output other than $0$.\n\nIf such a $y$ is found, the strategy outputs the *least* such $y$. This check is a direct implementation of the definition of $f(x)$. If the conditions for $f(x)=y$ are met, then all relevant computations (for $z \\le y$) will eventually halt. The stage-based simulation guarantees that there will be a stage $s$ by which all these computations have completed. At that stage, or shortly thereafter, the check will succeed, and the algorithm will find the minimal $y$ satisfying the criteria and halt with the correct output. If no such $y$ exists, the conditions will never be met, and the simulation will correctly run forever. This strategy satisfies both fair progress and extensional correctness.\n\nVerdict: **Correct**.\n\n**Option B:**\n\nThis strategy proposes a sequential search: test $y=0$, then $y=1$, and so on, running each computation $M_R(x,y)$ to completion. This approach fundamentally violates the fair progress constraint. If, for instance, $R(x,0)$ is undefined, the simulation of $M_R(x,0)$ will run forever. The algorithm will become permanently stuck on the $y=0$ case and will never proceed to test $y=1, 2, \\dots$, even if $f(x)$ should have been defined with a value greater than $0$ (or, as per the rules, undefined for a different reason). This is the classic pitfall that dovetailing is designed to avoid.\n\nVerdict: **Incorrect**.\n\n**Option C:**\n\nThis strategy uses a correct dovetailing method for fair progress, identical to that in option A. However, it fails on extensional correctness. The halting condition is \"as soon as *any* $M_R(x,y)$ halts with output $0$, immediately output $y$ and halt\". This is flawed for two reasons:\n1.  It does not guarantee minimality. A computation $M_R(x,y_1)$ for a larger $y_1$ might be much shorter than a computation $M_R(x,y_0)$ for a smaller $y_0$, where both result in $0$. This strategy could prematurely halt with $y_1$, violating the \"least $y$\" requirement of the $\\mu$-operator.\n2.  It completely ignores the critical condition that for $f(x)$ to be $y$, all computations $M_R(x,z)$ for $z  y$ must have halted with non-zero outputs. This strategy would incorrectly produce an output even if one of the required prior computations, say $M_R(x,0)$, was still running or had diverged.\n\nVerdict: **Incorrect**.\n\n**Option D:**\n\nThis strategy also uses a correct dovetailing method, ensuring fair progress. However, its condition for halting is a flawed attempt to fix the issues in option C. It proposes to halt and output $y$ if $M_R(x,y)$ has produced $0$ and for each $z  y$, either $M_R(x,z)$ has halted with a non-zero output, or it has been simulated for \"more than $y$ steps\". The clause \"or has been simulated for more than $y$ steps\" is not sound. There is no theorem in computability theory stating that if a computation has not halted after a certain number of steps (related to an output value from another computation), it can be assumed to either diverge or produce a non-interfering result. A computation $M_R(x,z)$ could run for $y+100$ steps and then halt with output $0$, which would mean that $y$ was not the minimal value. Or it could run for $y+100$ steps and then diverge, meaning $f(x)$ should be undefined. The condition requires that these computations *actually halt*. This strategy makes an unsubstantiated guess and thus fails to be extensionally correct.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "2972630"}, {"introduction": "The equivalence of diverse computational models like Turing machines and $\\mu$-recursive functions suggests that the class of \"computable\" functions is natural and fundamental. But how sensitive is this class to our specific choices of data representation? This thought experiment investigates whether changing the encoding of numbers via a bijective map $e: \\mathbb{N} \\to \\mathbb{N}$ can alter which functions are deemed computable [@problem_id:2972645]. By establishing the conditions on the map $e$, you will reinforce your understanding of the closure properties of computable functions and appreciate the profound robustness implied by the Church-Turing thesis.", "problem": "Let $\\mathbb{N}$ denote the set of natural numbers. Consider partial $\\mu$-recursive functions $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$, obtained from the initial functions (zero, successor, projections) by closing under composition, primitive recursion, and unbounded minimalization. A function is Turing-computable if it is computable by a Turing Machine (TM) on standard encodings of inputs from $\\mathbb{N}^k$ to outputs in $\\mathbb{N}$. It is a well-tested fact that the class of partial $\\mu$-recursive functions coincides with the class of Turing-computable partial functions.\n\nFix an arity $k\\geq 1$. Suppose we change the encoding of inputs and outputs by a bijection $e:\\mathbb{N}\\to\\mathbb{N}$. Define the componentwise lift $e^{(k)}:\\mathbb{N}^k\\to\\mathbb{N}^k$ by $e^{(k)}(x_1,\\dots,x_k)=(e(x_1),\\dots,e(x_k))$, and its inverse componentwise lift $\\left(e^{-1}\\right)^{(k)}$. Given a partial function $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$, define the translated function $g:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$ by\n$$\ng \\;=\\; e^{-1}\\circ f\\circ e^{(k)}.\n$$\nIn the following options, each statement describes conditions under which such a change of encoding preserves, reflects, or fails to preserve the class of computable functions (both in the sense of Turing-computability and in the sense of $\\mu$-recursiveness). Select all statements that are correct.\n\nA. If $e$ and $e^{-1}$ are primitive recursive total functions, then for every $k\\geq 1$ and every partial function $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$, $f$ is Turing-computable (equivalently, partial $\\mu$-recursive) if and only if $g=e^{-1}\\circ f\\circ e^{(k)}$ is Turing-computable (equivalently, partial $\\mu$-recursive).\n\nB. It suffices that $e$ is a bijection; no computability condition on $e$ or $e^{-1}$ is required for the preservation and reflection of computability under the translation $g=e^{-1}\\circ f\\circ e^{(k)}$.\n\nC. The preservation under $g=e^{-1}\\circ f\\circ e^{(k)}$ holds only for total functions $f:\\mathbb{N}^k\\to\\mathbb{N}$; for partial functions $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$ the property can fail, even when $e$ and $e^{-1}$ are primitive recursive.\n\nD. Preservation under $g=e^{-1}\\circ f\\circ e^{(k)}$ requires that $e$ and $e^{-1}$ be computable within a fixed time bound (for instance, polynomial time); otherwise unbounded minimalization in the definition of $\\mu$-recursiveness cannot be simulated, so computability may be lost.\n\nE. Even if $e$ and $e^{-1}$ are primitive recursive, preservation can fail unless one also assumes a primitive recursive tuple-coding/decoding to represent $\\mathbb{N}^k$ as $\\mathbb{N}$; without this additional assumption, pre- and post-composition by $e$ and $e^{-1}$ may not be absorbed by the closure properties of $\\mu$-recursiveness.", "solution": "The problem asks for the conditions on a bijection $e:\\mathbb{N}\\to\\mathbb{N}$ under which the transformation of a function $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$ to $g = e^{-1}\\circ f\\circ e^{(k)}$ preserves the property of being Turing-computable (equivalently, partial $\\mu$-recursive).\n\nLet the class of partial computable functions of arity $k$ be denoted by $\\mathcal{C}_k$. The question is, under what conditions on $e$ is it true that for any $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$, $f \\in \\mathcal{C}_k$ if and only if $g = e^{-1}\\circ f\\circ e^{(k)} \\in \\mathcal{C}_k$?\n\nThis is an \"if and only if\" statement, so we must analyze two directions.\n\nDirection 1: If $f \\in \\mathcal{C}_k$, when is $g \\in \\mathcal{C}_k$?\nThe function $g$ is defined by the composition $g(\\vec{x}) = e^{-1}(f(e(x_1), \\dots, e(x_k)))$. The computation of $g(\\vec{x})$ involves three stages:\n1.  Compute the tuple $(e(x_1), \\dots, e(x_k))$. This requires computing the function $e$ for each component of the input vector $\\vec{x}$. For this stage to be algorithmically performable, the function $e$ must be computable. Since $e$ is a bijection on $\\mathbb{N}$, it is a total function. So, we require $e$ to be a total computable function. If $e$ is computable, then the function $e^{(k)}: \\mathbb{N}^k \\to \\mathbb{N}^k$ defined by $e^{(k)}(\\vec{x}) = (e(x_1), \\dots, e(x_k))$ is also computable. This is because a Turing Machine can be constructed to run the Turing Machine for $e$ sequentially on each input component.\n2.  Compute $f$ on the result of the first stage. We assume $f$ is computable, so this stage is algorithmically performable by definition.\n3.  Compute $e^{-1}$ on the result of the second stage. For this to be algorithmic, the function $e^{-1}$ must be computable. Since $e^{-1}$ is also a bijection on $\\mathbb{N}$, we require it to be a total computable function.\n\nThe class of partial computable functions is closed under composition. The function $g$ is a composition of $e^{-1}$, $f$, and functions involving $e$ and projections. If $e$, $e^{-1}$, and $f$ are all computable, their composition $g$ will also be computable. Thus, for the \"if\" part to hold for all computable $f$, we need $e$ and $e^{-1}$ to be computable.\n\nDirection 2: If $g \\in \\mathcal{C}_k$, when is $f \\in \\mathcal{C}_k$?\nWe can express $f$ in terms of $g$ by rearranging the definition:\n$g = e^{-1}\\circ f\\circ e^{(k)}$\n$e \\circ g = e \\circ e^{-1}\\circ f\\circ e^{(k)}$\n$e \\circ g = f\\circ e^{(k)}$\n$e \\circ g \\circ (e^{(k)})^{-1} = f\\circ e^{(k)} \\circ (e^{(k)})^{-1}$\n$f = e \\circ g \\circ (e^{-1})^{(k)}$\nHere, $(e^{-1})^{(k)}$ is the componentwise application of $e^{-1}$.\nThe argument is perfectly symmetric. The computation of $f(\\vec{y})$ involves computing $(e^{-1})^{(k)}(\\vec{y})$, then $g$ on the result, then $e$ on the result of that. For $f$ to be computable for any computable $g$, we require $e^{-1}$ and $e$ to be total computable functions.\n\nCombining both directions, the property of computability is preserved and reflected if and only if both $e$ and its inverse $e^{-1}$ are total computable functions. A bijection $e:\\mathbb{N}\\to\\mathbb{N}$ for which both $e$ and $e^{-1}$ are computable is called a computable permutation or a recursive permutation. The result is that the class of computable functions is invariant under re-encoding of the natural numbers if and only if the re-encoding map is a computable permutation.\n\nNow we evaluate each option.\n\n**A. If $e$ and $e^{-1}$ are primitive recursive total functions, then for every $k\\geq 1$ and every partial function $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$, $f$ is Turing-computable (equivalently, partial $\\mu$-recursive) if and only if $g=e^{-1}\\circ f\\circ e^{(k)}$ is Turing-computable (equivalently, partial $\\mu$-recursive).**\n\nThe class of primitive recursive functions is a subset of the class of total computable (total $\\mu$-recursive) functions. The condition stated in this option, that $e$ and $e^{-1}$ are primitive recursive, is a stronger condition than needed (computable is sufficient), but it is certainly sufficient. If $e$ and $e^{-1}$ are primitive recursive, they are total and computable. As derived above, this is the sufficient condition for the preservation and reflection of computability. The class of partial $\\mu$-recursive functions is closed under composition with total computable functions. Since $e$ and $e^{-1}$ are computable, the transformation from $f$ to $g$ and from $g$ to $f$ are compositions with computable functions, which preserves membership in the class of partial $\\mu$-recursive functions.\n\nVerdict: **Correct**.\n\n**B. It suffices that $e$ is a bijection; no computability condition on $e$ or $e^{-1}$ is required for the preservation and reflection of computability under the translation $g=e^{-1}\\circ f\\circ e^{(k)}$.**\n\nThis statement is false. If $e$ is not computable, it can map computable structures to non-computable ones. For a counterexample, let $H \\subset \\mathbb{N}$ be a non-computable (but computably enumerable) set, such as the Halting set. Let $f:\\mathbb{N} \\to \\mathbb{N}$ be the constant function $f(x) = 0$ for all $x$. The function $f$ is primitive recursive and thus computable. Let us construct a bijection $e:\\mathbb{N} \\to \\mathbb{N}$ such that $g = e^{-1} \\circ f \\circ e$ is not computable. Consider $g(x) = e^{-1}(f(e(x))) = e^{-1}(0)$. For $g$ to be non-computable, the function $g(x)$ which is constant with value $e^{-1}(0)$ must somehow encode non-computable information. This is not possible as a constant function is always computable. Let's construct the counterexample the other way. Let $g(x)=0$ be computable. We seek a non-computable $f$ and a bijection $e$ such that $f = e \\circ g \\circ e^{-1}$. This gives $f(y) = e(g(e^{-1}(y))) = e(0)$. So $f$ is a constant function, which is computable. This path is also difficult.\n\nA better approach is to use a non-computable function and show it can be transformed into a computable one. Let $f = \\chi_H$ be the characteristic function of the Halting set $H$. $f$ is not computable. We want to find a bijection $e$ such that $g = e^{-1} \\circ \\chi_H \\circ e$ *is* computable. Since $H$ is undecidable, both $H$ and its complement $\\mathbb{N}\\setminus H$ are infinite. Let $e$ be a bijection that maps $H$ to the set of even numbers $E$ and $\\mathbb{N}\\setminus H$ to the set of odd numbers $O$. Such a bijection exists. However, $e$ itself is not computable, because computing $e(x)$ would require deciding if $x \\in H$. Now, let's analyze $g(y) = e^{-1}(\\chi_H(e(y)))$.\n- If $y \\in E$, then $e(y) \\in H$, so $\\chi_H(e(y))=1$. Then $g(y) = e^{-1}(1)$. Since $1 \\in O$, $e^{-1}(1) \\in \\mathbb{N}\\setminus H$.\n- If $y \\in O$, then $e(y) \\in \\mathbb{N}\\setminus H$, so $\\chi_H(e(y))=0$. Then $g(y) = e^{-1}(0)$. Since $0 \\in E$, $e^{-1}(0) \\in H$.\nThis construction does not immediately yield a simple computable function. A clearer construction is as follows: let $f$ be the non-computable function $\\chi_H$. Let $g$ be the computable function $g(x) = x \\pmod 2$. We seek $e$ such that $e \\circ g = f \\circ e$. This requires $e(x \\pmod 2) = f(e(x))$. For even $x$, $e(0)=f(e(x))$; for odd $x$, $e(1)=f(e(x))$. Let $e$ map even numbers to $\\mathbb{N}\\setminus H$ and odd numbers to $H$. This is possible if we can arrange for $e(0) \\in \\mathbb{N}\\setminus H$ and $e(1) \\in H$ and $f$ be constant on these image sets. Specifically, we need $f(y)=e(0)$ for all $y \\in e(E)$ and $f(y)=e(1)$ for all $y \\in e(O)$. With $f=\\chi_H$, this means either $e(0)=0$ and $e(1)=1$ (and $e(E) \\subseteq \\mathbb{N}\\setminus H$, $e(O) \\subseteq H$), or $e(0)=1$ and $e(1)=0$ (and $e(E) \\subseteq H$, $e(O) \\subseteq \\mathbb{N}\\setminus H$). Either way, such a bijection $e$ can be constructed, but it will not be computable. We have found a non-computable function $f$ and a computable function $g$ that are related by $g = e^{-1} \\circ f \\circ e$ for a non-computable $e$. Thus, computability is not preserved.\n\nVerdict: **Incorrect**.\n\n**C. The preservation under $g=e^{-1}\\circ f\\circ e^{(k)}$ holds only for total functions $f:\\mathbb{N}^k\\to\\mathbb{N}$; for partial functions $f:\\mathbb{N}^k\\rightharpoonup\\mathbb{N}$ the property can fail, even when $e$ and $e^{-1}$ are primitive recursive.**\n\nThis statement is false. The argument for preservation based on closure under composition applies equally well to partial functions. Let's see this on the level of Turing Machines. Given a TM $M_f$ for a partial function $f$, and TMs $M_e$ and $M_{e^{-1}}$ for total functions $e$ and $e^{-1}$, we can construct a TM $M_g$ for $g$. $M_g$ on input $\\vec{x}$ first simulates $M_e$ on each component of $\\vec{x}$ to get $\\vec{y}=e^{(k)}(\\vec{x})$. Since $e$ is total, this step always halts. Then, $M_g$ simulates $M_f$ on $\\vec{y}$. If this simulation halts with output $z$, $M_g$ simulates $M_{e^{-1}}$ on $z$ to get $w$, which it outputs. If the simulation of $M_f$ on $\\vec{y}$ does not halt, then $M_g$ does not halt on $\\vec{x}$. This corresponds exactly to the definition of $g = e^{-1}\\circ f\\circ e^{(k)}$. The domain of $g$ is precisely the set of $\\vec{x}$ such that $e^{(k)}(\\vec{x})$ is in the domain of $f$. The procedure defines a valid TM for the partial function $g$. The argument is symmetric for expressing $f$ in terms of $g$. Therefore, the property holds for partial functions.\n\nVerdict: **Incorrect**.\n\n**D. Preservation under $g=e^{-1}\\circ f\\circ e^{(k)}$ requires that $e$ and $e^{-1}$ be computable within a fixed time bound (for instance, polynomial time); otherwise unbounded minimalization in the definition of $\\mu$-recursiveness cannot be simulated, so computability may be lost.**\n\nThis statement confuses computability with computational complexity. The definition of a computable function (whether by Turing Machines or $\\mu$-recursion) does not impose any limit on the time or space resources required for the computation, as long as it terminates for inputs in the function's domain. Unbounded minimalization ($\\mu$-operator) is precisely the feature that allows $\\mu$-recursive functions to model all possible algorithms, including those with non-primitive recursive runtime complexity (like the Ackermann function). As long as $e$ and $e^{-1}$ are computable (i.e., there exist algorithms that compute them in finite time for any input), the composition argument holds. The complexity of $e$ and $e^{-1}$ affects the complexity of $g$, but not its computability. For example, if $f$, $e$, and $e^{-1}$ are all computable, $g$ is also computable, even if $e$ takes an exceedingly long time to compute.\n\nVerdict: **Incorrect**.\n\n**E. Even if $e$ and $e^{-1}$ are primitive recursive, preservation can fail unless one also assumes a primitive recursive tuple-coding/decoding to represent $\\mathbb{N}^k$ as $\\mathbb{N}$; without this additional assumption, pre- and post-composition by $e$ and $e^{-1}$ may not be absorbed by the closure properties of $\\mu$-recursiveness.**\n\nThis statement reflects a misunderstanding of the standard definition of partial $\\mu$-recursive functions. The theory is developed for functions $f:\\mathbb{N}^k \\to \\mathbb{N}$ for any arity $k \\geq 1$. The closure properties are defined directly on these multi-argument functions. For example, composition is defined as $h(g_1(\\vec{x}), \\dots, g_m(\\vec{x}))$. The function $f \\circ e^{(k)}$ is notation for the function $F(\\vec{x}) = f(e(x_1), \\dots, e(x_k))$, which is a composition of $f$ with the functions $g_i(\\vec{x}) = e(\\pi_i^k(\\vec{x}))$ where $\\pi_i^k$ are the initial projection functions. If $e$ is primitive recursive, so are the $g_i$. The composition of a partial $\\mu$-recursive function $f$ with primitive recursive functions results in a partial $\\mu$-recursive function. The final composition with $e^{-1}$, $g(\\vec{x}) = e^{-1}(F(\\vec{x}))$, is also a valid composition that preserves $\\mu$-recursiveness. The entire argument is formalizable within the standard calculus of multi-argument $\\mu$-recursive functions without any need to explicitly code tuples into single natural numbers. Such coding is a tool used to prove equivalences (like with single-tape Turing Machines), but it is not a prerequisite for the theory itself.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "2972645"}]}