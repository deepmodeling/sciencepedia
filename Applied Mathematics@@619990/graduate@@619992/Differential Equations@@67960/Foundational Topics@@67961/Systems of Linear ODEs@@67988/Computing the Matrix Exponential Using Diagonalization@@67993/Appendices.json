{"hands_on_practices": [{"introduction": "This first practice problem demonstrates a key simplifying principle in matrix exponentiation. When a matrix is block-diagonal, its exponential can be found by exponentiating each block separately, a divide-and-conquer strategy that significantly reduces complexity. This exercise [@problem_id:958179] allows you to apply this principle and practice computing the exponential of a fundamental $2 \\times 2$ matrix, solidifying the core concepts in a manageable context.", "problem": "Consider a block-diagonal matrix $A$ defined as:\n$$\nA = \\begin{bmatrix}\n0 & -2 & 0 \\\\\n2 & 0 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n$$\nThis matrix consists of two diagonalizable blocks: a $2 \\times 2$ block $\\begin{bmatrix} 0 & -2 \\\\ 2 & 0 \\end{bmatrix}$ and a $1 \\times 1$ block $\\begin{bmatrix} 1 \\end{bmatrix}$. Compute the matrix exponential $e^A$. Express the result as a single $3 \\times 3$ matrix with exact symbolic entries, using standard mathematical functions and constants. The final answer must be fully simplified.", "solution": "1. Decompose \n$$\nA=\\begin{pmatrix}0&-2&0\\\\2&0&0\\\\0&0&1\\end{pmatrix}\n=\\begin{pmatrix}A_2&0\\\\0&1\\end{pmatrix},\\quad\nA_2=\\begin{pmatrix}0&-2\\\\2&0\\end{pmatrix}.\n$$\n2. Note $A_2^2=\\begin{pmatrix}-4&0\\\\0&-4\\end{pmatrix}=-4I_2$.  Hence the series for $\\exp(A_2)$ splits into even and odd terms:\n$$\n\\exp(A_2)=\\sum_{k=0}^\\infty\\frac{A_2^{2k}}{(2k)!}\n+\\sum_{k=0}^\\infty\\frac{A_2^{2k+1}}{(2k+1)!}\n=I_2\\sum_{k=0}^\\infty\\frac{(-4)^k}{(2k)!}\n+A_2\\sum_{k=0}^\\infty\\frac{(-4)^k}{(2k+1)!}.\n$$\n3. Recognize the series\n$$\n\\sum_{k=0}^\\infty\\frac{(-4)^k}{(2k)!}=\\cos(2), \n\\qquad\n\\sum_{k=0}^\\infty\\frac{(-4)^k}{(2k+1)!}=\\frac{\\sin(2)}{2}.\n$$\nThus\n$$\n\\exp(A_2)=\\cos(2)\\,I_2+\\frac{\\sin(2)}{2}\\,A_2\n=\\begin{pmatrix}\\cos2&-\\sin2\\\\\\sin2&\\cos2\\end{pmatrix}.\n$$\n4. For the $1\\times1$ block, $\\exp(1)=e$.  By block‐diagonality,\n$$\n\\exp(A)=\\begin{pmatrix}\\exp(A_2)&0\\\\0&\\exp(1)\\end{pmatrix}\n=\\begin{pmatrix}\\cos2&-\\sin2&0\\\\\\sin2&\\cos2&0\\\\0&0&e\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\cos(2)&-\\sin(2)&0\\\\\\sin(2)&\\cos(2)&0\\\\0&0&e\\end{pmatrix}}$$", "id": "958179"}, {"introduction": "Moving beyond simple cases, this problem explores the elegant interplay between the eigensystems of related matrices. You will investigate a system whose governing matrix is the sum of a local interaction matrix and a global one, $B = A + k J$. This exercise [@problem_id:1085162] reveals a powerful principle: when matrices share eigenvectors, the diagonalization of their sum becomes beautifully simple, providing a deep insight into how structural changes in a system are reflected in its dynamics.", "problem": "Consider a system of four interacting components, whose states are described by the vector $\\mathbf{x}(t) = [x_1(t), x_2(t), x_3(t), x_4(t)]^T$. The evolution of the system is governed by the system of linear ordinary differential equations $\\frac{d\\mathbf{x}}{dt} = B\\mathbf{x}$. The $4 \\times 4$ matrix $B$ is given by the sum of two matrices, $B = A + k J$. The first matrix, $A$, represents a fixed local interaction pattern:\n$$A = \\begin{pmatrix} -4 & 1 & 1 & 0 \\\\ 1 & -4 & 0 & 1 \\\\ 1 & 0 & -4 & 1 \\\\ 0 & 1 & 1 & -4 \\end{pmatrix}$$\nThe second term, $kJ$, represents a global interaction of uniform strength $k$, where $J$ is the $4 \\times 4$ matrix of all ones, i.e., $J_{ij} = 1$ for all $i,j$. The system is initialized at $t=0$ with the state $\\mathbf{x}(0) = [1, 0, 0, 0]^T$.\n\nYour task is to find a closed-form expression for the sum of the states, $S(t) = \\sum_{i=1}^4 x_i(t)$, as a function of time $t$ and the parameter $k$.", "solution": "The problem asks for the sum of the components of the solution vector $\\mathbf{x}(t)$ for the system of ODEs $\\frac{d\\mathbf{x}}{dt} = B\\mathbf{x}$ with a given initial condition $\\mathbf{x}(0)$.\n\nThe formal solution to this system is given by the matrix exponential:\n$$ \\mathbf{x}(t) = e^{Bt} \\mathbf{x}(0) $$\nTo compute the matrix exponential $e^{Bt}$, we first need to find the eigenvalues and eigenvectors of the matrix $B$, i.e., we need to diagonalize it. The matrix $B$ is given by $B = A + k J$, where\n$$ A = \\begin{pmatrix} -4 & 1 & 1 & 0 \\\\ 1 & -4 & 0 & 1 \\\\ 1 & 0 & -4 & 1 \\\\ 0 & 1 & 1 & -4 \\end{pmatrix}, \\quad J = \\begin{pmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{pmatrix} $$\nThe key idea is to first find the eigenvalues and eigenvectors of $A$, and then determine how they are affected by the addition of the term $kJ$.\n\n**Step 1: Diagonalization of A**\n\nLet $\\lambda$ be an eigenvalue of $A$ and $\\mathbf{v}$ be the corresponding eigenvector, so $A\\mathbf{v} = \\lambda\\mathbf{v}$. The characteristic equation is $\\det(A - \\lambda I) = 0$. Let $x = -4-\\lambda$.\n$$ \\det \\begin{pmatrix} x & 1 & 1 & 0 \\\\ 1 & x & 0 & 1 \\\\ 1 & 0 & x & 1 \\\\ 0 & 1 & 1 & x \\end{pmatrix} = x(x^3-2x) - (x^2) + (-x^2) = x^4 - 4x^2 = x^2(x-2)(x+2) = 0 $$\nThe roots for $x$ are $0$ (with multiplicity 2), $2$, and $-2$.\nThe eigenvalues of $A$ are $\\lambda = -4-x$:\n- $x=2 \\implies \\lambda = -6$\n- $x=0 \\implies \\lambda = -4$ (multiplicity 2)\n- $x=-2 \\implies \\lambda = -2$\n\nThe eigenvectors of $A$ are:\n- $\\lambda_1 = -6, \\mathbf{v}_1 = [-1, 1, 1, -1]^T$\n- $\\lambda_2 = -4, \\mathbf{v}_2 = [1, 0, 0, -1]^T$\n- $\\lambda_3 = -4, \\mathbf{v}_3 = [0, 1, -1, 0]^T$\n- $\\lambda_4 = -2, \\mathbf{v}_4 = [1, 1, 1, 1]^T$\n\n**Step 2: Diagonalization of B**\n\nNow consider the matrix $B = A + k J$. Noting that $J = \\mathbf{1}\\mathbf{1}^T$ where $\\mathbf{1}=[1,1,1,1]^T=\\mathbf{v}_4$.\nLet's apply $B$ to the eigenvectors of $A$:\n$$ B\\mathbf{v}_i = (A + k\\mathbf{v}_4\\mathbf{v}_4^T)\\mathbf{v}_i = A\\mathbf{v}_i + k\\mathbf{v}_4(\\mathbf{v}_4^T \\mathbf{v}_i) $$\nThe eigenvectors $\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3, \\mathbf{v}_4$ are orthogonal.\n- For $i=1, 2, 3$, $\\mathbf{v}_4^T \\mathbf{v}_i = \\mathbf{v}_4 \\cdot \\mathbf{v}_i = 0$.\nSo, $B\\mathbf{v}_i = A\\mathbf{v}_i = \\lambda_i \\mathbf{v}_i$ for $i=1,2,3$.\nThe eigenvectors $\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3$ are also eigenvectors of $B$ with the same eigenvalues $\\mu_1 = -6$ and $\\mu_2 = \\mu_3 = -4$.\n- For $i=4$: $\\mathbf{v}_4^T \\mathbf{v}_4 = \\|\\mathbf{v}_4\\|^2 = 1^2+1^2+1^2+1^2=4$.\n$$ B\\mathbf{v}_4 = A\\mathbf{v}_4 + k\\mathbf{v}_4(\\mathbf{v}_4^T \\mathbf{v}_4) = \\lambda_4 \\mathbf{v}_4 + k\\mathbf{v}_4(4) = (\\lambda_4+4k)\\mathbf{v}_4 = (-2+4k)\\mathbf{v}_4 $$\nSo $\\mathbf{v}_4$ is an eigenvector of $B$ with eigenvalue $\\mu_4 = -2+4k$.\n\nThe eigenvalues of $B$ are $\\mu_1=-6, \\mu_2=-4, \\mu_3=-4, \\mu_4=4k-2$. The eigenvectors are the same as for $A$.\n\n**Step 3: Construct the solution**\n\nThe solution is $\\mathbf{x}(t) = e^{Bt}\\mathbf{x}(0) = P e^{D_B t} P^{-1} \\mathbf{x}(0)$, where $P$ is the matrix of eigenvectors and $D_B$ is the diagonal matrix of eigenvalues.\nThe normalized eigenvectors are:\n$\\hat{\\mathbf{v}}_1 = \\frac{1}{2}[-1, 1, 1, -1]^T$, $\\hat{\\mathbf{v}}_2 = \\frac{1}{\\sqrt{2}}[1, 0, 0, -1]^T$, $\\hat{\\mathbf{v}}_3 = \\frac{1}{\\sqrt{2}}[0, 1, -1, 0]^T$, $\\hat{\\mathbf{v}}_4 = \\frac{1}{2}[1, 1, 1, 1]^T$.\n$P = [\\hat{\\mathbf{v}}_1, \\hat{\\mathbf{v}}_2, \\hat{\\mathbf{v}}_3, \\hat{\\mathbf{v}}_4]$. Since $A$ and $B$ are symmetric, $P$ is orthogonal, so $P^{-1}=P^T$.\n$\\mathbf{x}(0) = [1, 0, 0, 0]^T$.\nWe need to find the projection of $\\mathbf{x}(0)$ onto the eigenspace: $\\mathbf{c} = P^T \\mathbf{x}(0)$.\n$$ \\mathbf{c} = \\begin{pmatrix} -1/2 & 1/2 & 1/2 & -1/2 \\\\ 1/\\sqrt{2} & 0 & 0 & -1/\\sqrt{2} \\\\ 0 & 1/\\sqrt{2} & -1/\\sqrt{2} & 0 \\\\ 1/2 & 1/2 & 1/2 & 1/2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -1/2 \\\\ 1/\\sqrt{2} \\\\ 0 \\\\ 1/2 \\end{pmatrix} $$\nThe solution is $\\mathbf{x}(t) = P e^{D_B t} \\mathbf{c}$.\n$$ e^{D_B t}\\mathbf{c} = \\begin{pmatrix} e^{-6t} & 0 & 0 & 0 \\\\ 0 & e^{-4t} & 0 & 0 \\\\ 0 & 0 & e^{-4t} & 0 \\\\ 0 & 0 & 0 & e^{(4k-2)t} \\end{pmatrix} \\begin{pmatrix} -1/2 \\\\ 1/\\sqrt{2} \\\\ 0 \\\\ 1/2 \\end{pmatrix} = \\begin{pmatrix} -1/2 e^{-6t} \\\\ 1/\\sqrt{2} e^{-4t} \\\\ 0 \\\\ 1/2 e^{(4k-2)t} \\end{pmatrix} $$\n$\\mathbf{x}(t) = P(e^{D_B t}\\mathbf{c}) = -\\frac{1}{2}e^{-6t}\\hat{\\mathbf{v}}_1 + \\frac{1}{\\sqrt{2}}e^{-4t}\\hat{\\mathbf{v}}_2 + 0\\cdot\\hat{\\mathbf{v}}_3 + \\frac{1}{2}e^{(4k-2)t}\\hat{\\mathbf{v}}_4$.\n\n**Step 4: Compute the sum S(t)**\n\nWe need to compute $S(t) = \\sum_{i=1}^4 x_i(t) = \\mathbf{1}^T \\mathbf{x}(t)$, where $\\mathbf{1}=[1,1,1,1]^T$.\nNotice that $\\mathbf{1} = \\mathbf{v}_4 = 2\\hat{\\mathbf{v}}_4$.\nDue to orthogonality of the aigenvectors, $\\mathbf{1}^T \\hat{\\mathbf{v}}_i = \\mathbf{v}_4^T \\hat{\\mathbf{v}}_i = 0$ for $i=1,2,3$. And $\\mathbf{1}^T \\hat{\\mathbf{v}}_4 = \\mathbf{v}_4^T (\\frac{1}{2}\\mathbf{v}_4) = \\frac{1}{2}\\|\\mathbf{v}_4\\|^2 = \\frac{4}{2} = 2$.\n$$ S(t) = \\mathbf{1}^T \\left( -\\frac{1}{2}e^{-6t}\\hat{\\mathbf{v}}_1 + \\frac{1}{\\sqrt{2}}e^{-4t}\\hat{\\mathbf{v}}_2 + \\frac{1}{2}e^{(4k-2)t}\\hat{\\mathbf{v}}_4 \\right) $$\n$$ S(t) = -\\frac{1}{2}e^{-6t}(\\mathbf{1}^T\\hat{\\mathbf{v}}_1) + \\frac{1}{\\sqrt{2}}e^{-4t}(\\mathbf{1}^T\\hat{\\mathbf{v}}_2) + \\frac{1}{2}e^{(4k-2)t}(\\mathbf{1}^T\\hat{\\mathbf{v}}_4) $$\n$$ S(t) = -\\frac{1}{2}e^{-6t}(0) + \\frac{1}{\\sqrt{2}}e^{-4t}(0) + \\frac{1}{2}e^{(4k-2)t}(2) $$\n$$ S(t) = e^{(4k-2)t} $$\n\n**Alternative Method (Shortcut)**\nLet $S(t)=\\sum_i x_i(t) = \\mathbf{1}^T \\mathbf{x}(t)$.\nTaking the time derivative: $\\frac{dS}{dt} = \\mathbf{1}^T \\frac{d\\mathbf{x}}{dt} = \\mathbf{1}^T B \\mathbf{x}$.\nLet's analyze the vector $\\mathbf{1}^T B$:\n$$ \\mathbf{1}^T B = \\mathbf{1}^T (A + k J) = \\mathbf{1}^T A + k \\mathbf{1}^T J $$\nThe row vector $\\mathbf{1}^T A$ is $[1,1,1,1]A = [-2, -2, -2, -2] = -2[1,1,1,1] = -2\\mathbf{1}^T$.\nThe term $\\mathbf{1}^T J = [1,1,1,1] \\begin{pmatrix} 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\\\ 1 & 1 & 1 & 1 \\end{pmatrix} = [4,4,4,4] = 4\\mathbf{1}^T$.\nSo, $\\mathbf{1}^T B = -2\\mathbf{1}^T + k(4\\mathbf{1}^T) = (4k-2)\\mathbf{1}^T$.\nSubstituting this into the derivative equation for $S(t)$:\n$$ \\frac{dS}{dt} = (4k-2)\\mathbf{1}^T \\mathbf{x} = (4k-2)S(t) $$\nThis is a simple first-order ODE for $S(t)$. The solution is $S(t) = S(0)e^{(4k-2)t}$.\nThe initial condition is $S(0) = \\sum x_i(0) = 1+0+0+0=1$.\nThus, the final solution is $S(t) = e^{(4k-2)t}$.", "answer": "$$ \\boxed{e^{(4k-2)t}} $$", "id": "1085162"}, {"introduction": "A true mastery of any technique includes understanding its limitations. This final practice problem challenges you to analyze a matrix that cannot be diagonalized, a situation that arises in various physical and engineering systems. By working through this exercise [@problem_id:2704054], you will learn to identify non-diagonalizable matrices from first principles and appreciate why the standard diagonalization procedure fails, giving you a more complete and robust understanding of matrix exponentiation.", "problem": "Consider the continuous-time linear time-invariant (LTI) system $\\dot{x}(t)=A x(t)$ on $\\mathbb{R}^{2}$ with the real matrix\n$$\nA=\\begin{bmatrix}2&0\\\\ 1&2\\end{bmatrix},\n$$\nendowed with the standard Euclidean inner product on $\\mathbb{R}^{2}$. Use only core definitions and well-tested facts as the starting point of your reasoning.\n\n- Determine from first principles whether $A$ is normal with respect to the Euclidean inner product. Justify your conclusion directly from the definition of normality.\n\n- Explain the implications of your finding for diagonalization: decide whether $A$ is diagonalizable over $\\mathbb{C}$ and whether it is unitarily diagonalizable, and justify each decision by appealing to the eigenstructure implied by the definition of diagonalizability.\n\n- Derive the state-transition matrix $e^{A t}$ from fundamental constructions and compute the induced two-norm $\\|e^{A t}\\|_{2}$ for $t\\ge 0$. From your exact expression, produce at least one explicit, closed-form upper bound $\\beta(t)$ such that $\\|e^{A t}\\|_{2}\\le \\beta(t)$ for all $t\\ge 0$, obtained without asymptotic approximations.\n\nReport your final answer as the exact analytic expression of $\\|e^{A t}\\|_{2}$ as a function of $t\\ge 0$. No numeric rounding is required, and no physical units are involved.", "solution": "We begin with core definitions. A real matrix $A$ is normal (with respect to the Euclidean inner product) if and only if $A^{\\top}A=AA^{\\top}$. A matrix is diagonalizable over $\\mathbb{C}$ if and only if there exists an invertible matrix $V$ such that $V^{-1} A V$ is diagonal; it is unitarily diagonalizable if and only if it is normal, equivalently there exists a unitary $U$ such that $U^{*} A U$ is diagonal. The induced two-norm of a real matrix $M$ is $\\|M\\|_{2}=\\sqrt{\\lambda_{\\max}(M^{\\top}M)}$, where $\\lambda_{\\max}$ denotes the largest eigenvalue.\n\nStep one: check normality. Compute $A^{\\top}$, $A^{\\top}A$, and $AA^{\\top}$:\n$$\nA=\\begin{bmatrix}2&0\\\\ 1&2\\end{bmatrix},\\qquad\nA^{\\top}=\\begin{bmatrix}2&1\\\\ 0&2\\end{bmatrix}.\n$$\nThen\n$$\nA^{\\top}A=\\begin{bmatrix}2&1\\\\ 0&2\\end{bmatrix}\\begin{bmatrix}2&0\\\\ 1&2\\end{bmatrix}\n=\\begin{bmatrix}5&2\\\\ 2&4\\end{bmatrix},\\qquad\nAA^{\\top}=\\begin{bmatrix}2&0\\\\ 1&2\\end{bmatrix}\\begin{bmatrix}2&1\\\\ 0&2\\end{bmatrix}\n=\\begin{bmatrix}4&2\\\\ 2&5\\end{bmatrix}.\n$$\nSince $A^{\\top}A\\neq AA^{\\top}$, the matrix $A$ is not normal.\n\nStep two: consequences for diagonalization. The characteristic polynomial of $A$ is\n$$\n\\chi_{A}(\\lambda)=\\det(\\lambda I - A)=\\det\\!\\begin{bmatrix}\\lambda-2&0\\\\ -1&\\lambda-2\\end{bmatrix}=(\\lambda-2)^{2}.\n$$\nThus the spectrum consists of the single eigenvalue $\\lambda=2$ with algebraic multiplicity $2$. The eigenspace is the null space of $A-2I$:\n$$\nA-2I=\\begin{bmatrix}0&0\\\\ 1&0\\end{bmatrix},\\quad (A-2I)\\begin{bmatrix}x_{1}\\\\ x_{2}\\end{bmatrix}=\\begin{bmatrix}0\\\\ x_{1}\\end{bmatrix},\n$$\nso eigenvectors satisfy $x_{1}=0$ with $x_{2}$ free, hence the eigenspace is one-dimensional, $\\mathrm{span}\\{\\begin{bmatrix}0\\\\ 1\\end{bmatrix}\\}$. Therefore the geometric multiplicity is $1<2$, and $A$ is not diagonalizable over $\\mathbb{C}$. Moreover, since $A$ is not normal, it is not unitarily diagonalizable. The lack of diagonalizability implies that the Jordan normal form contains a single Jordan block of size $2$ at $\\lambda=2$, and the matrix exponential $e^{A t}$ will exhibit a polynomial growth factor (linear in $t$) multiplied by an exponential factor $e^{2 t}$.\n\nStep three: compute $e^{A t}$ and its induced two-norm. Decompose $A$ into its Jordan–Chevalley form as $A=2I+N$, where\n$$\nN:=A-2I=\\begin{bmatrix}0&0\\\\ 1&0\\end{bmatrix},\\qquad N^{2}=0.\n$$\nUsing $N^{2}=0$, the exponential of $N t$ is\n$$\ne^{N t}=I+N t.\n$$\nSince $2I$ commutes with $N$, we have\n$$\ne^{A t}=e^{(2I+N)t}=e^{2 t}\\,e^{N t}=e^{2 t}\\,(I+N t)=e^{2 t}\\begin{bmatrix}1&0\\\\ t&1\\end{bmatrix}.\n$$\nSet $B:=I+N t=\\begin{bmatrix}1&0\\\\ t&1\\end{bmatrix}$. Then\n$$\n\\|e^{A t}\\|_{2}=e^{2 t}\\,\\|B\\|_{2}.\n$$\nTo evaluate $\\|B\\|_{2}$, compute $B^{\\top}B$:\n$$\nB^{\\top}B=\\begin{bmatrix}1&t\\\\ 0&1\\end{bmatrix}\\begin{bmatrix}1&0\\\\ t&1\\end{bmatrix}\n=\\begin{bmatrix}1+t^{2}&t\\\\ t&1\\end{bmatrix}.\n$$\nThe eigenvalues of the symmetric matrix $\\begin{bmatrix}1+t^{2}&t\\\\ t&1\\end{bmatrix}$ are the roots of\n$$\n\\lambda^{2}-\\mathrm{tr}(B^{\\top}B)\\,\\lambda+\\det(B^{\\top}B)=0,\\qquad \\mathrm{tr}(B^{\\top}B)=2+t^{2},\\quad \\det(B^{\\top}B)=1.\n$$\nTherefore\n$$\n\\lambda_{\\max}(B^{\\top}B)=\\frac{(2+t^{2})+\\sqrt{(2+t^{2})^{2}-4}}{2}\n=\\frac{2+t^{2}+\\sqrt{t^{4}+4 t^{2}}}{2}\n=\\frac{2+t^{2}+|t|\\sqrt{t^{2}+4}}{2}.\n$$\nFor $t\\ge 0$, this simplifies to\n$$\n\\lambda_{\\max}(B^{\\top}B)=\\frac{2+t^{2}+t\\sqrt{t^{2}+4}}{2}.\n$$\nHence\n$$\n\\|B\\|_{2}=\\sqrt{\\lambda_{\\max}(B^{\\top}B)}\n=\\sqrt{\\frac{2+t^{2}+t\\sqrt{t^{2}+4}}{2}},\n$$\nand the exact induced two-norm of the transition matrix is\n$$\n\\|e^{A t}\\|_{2}=e^{2 t}\\sqrt{\\frac{2+t^{2}+t\\sqrt{t^{2}+4}}{2}},\\qquad t\\ge 0.\n$$\n\nExplicit bounds obtained directly from the exact expression include, for all $t\\ge 0$:\n- Using the Frobenius norm inequality $\\|M\\|_{2}\\le \\|M\\|_{F}$ and $\\|B\\|_{F}=\\sqrt{2+t^{2}}$,\n$$\n\\|e^{A t}\\|_{2}\\le e^{2 t}\\sqrt{2+t^{2}}.\n$$\n- Using the logarithmic norm (matrix measure) with respect to the Euclidean norm, $\\mu_{2}(A)=\\lambda_{\\max}\\!\\left(\\tfrac{A+A^{\\top}}{2}\\right)=\\lambda_{\\max}\\!\\left(\\begin{bmatrix}2&1/2\\\\ 1/2&2\\end{bmatrix}\\right)=\\frac{5}{2}$, the classical bound yields\n$$\n\\|e^{A t}\\|_{2}\\le \\exp\\!\\big(\\mu_{2}(A)\\,t\\big)=\\exp\\!\\big(\\tfrac{5}{2}\\,t\\big).\n$$\nFinally, the exact expression shows the asymptotic behavior $\\|e^{A t}\\|_{2}\\sim t\\,e^{2 t}$ as $t\\to\\infty$, reflecting the non-normal, nondiagonalizable Jordan block structure at the repeated eigenvalue $2$.", "answer": "$$\\boxed{\\exp(2 t)\\,\\sqrt{\\frac{2+t^{2}+t\\sqrt{t^{2}+4}}{2}}}$$", "id": "2704054"}]}