{"hands_on_practices": [{"introduction": "The statistical properties of eigenvalues, such as their tendency to repel each other, are a cornerstone of random matrix theory. This exercise provides a hands-on derivation of this phenomenon for the simplest non-trivial case: a $2 \\times 2$ matrix from the Gaussian Orthogonal Ensemble (GOE). By performing a change of variables from the matrix elements to its eigenvalues, you will explicitly calculate the Jacobian of the transformation and uncover the famous $|\\lambda_1 - \\lambda_2|$ repulsion term, providing a concrete foundation for understanding more general results [@problem_id:652134].", "problem": "The Gaussian Orthogonal Ensemble (GOE) is a set of random real symmetric matrices. For the $N=2$ case, consider a matrix $H$ of the form:\n$$H = \\begin{pmatrix} a & c \\\\ c & b \\end{pmatrix}$$\nThe independent matrix elements $a, b, c$ are random variables. Their joint probability density function (PDF) is given by\n$$P(a,b,c) = C \\exp\\left(-\\frac{1}{2}(a^2+b^2+2c^2)\\right)$$\nwhere $C$ is a normalization constant. This distribution corresponds to the more general form $P(H) \\propto \\exp\\left(-\\frac{1}{2}\\text{Tr}(H^2)\\right)$.\n\nLet the two eigenvalues of $H$ be $\\lambda_1$ and $\\lambda_2$. Your task is to find the joint probability density function $p(\\lambda_1, \\lambda_2)$ for these two eigenvalues. The function must be normalized such that $\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} p(\\lambda_1, \\lambda_2) d\\lambda_1 d\\lambda_2 = 1$.", "solution": "The problem is to find the joint probability density function (JPDF) of the eigenvalues of a $2 \\times 2$ GOE matrix, starting from the JPDF of its elements. This requires a change of variables from the matrix elements $(a, b, c)$ to the eigenvalues $(\\lambda_1, \\lambda_2)$ and the parameters describing the eigenvectors.\n\n**1. Diagonalization of the Matrix**\nA real symmetric matrix $H$ can be diagonalized by an orthogonal matrix $O$, such that $H = O \\Lambda O^T$, where $\\Lambda = \\text{diag}(\\lambda_1, \\lambda_2)$ is the diagonal matrix of eigenvalues. For a $2 \\times 2$ matrix, the orthogonal matrix $O \\in O(2)$ can be parameterized by a single angle $\\theta$. We can write a rotation matrix (an element of $SO(2)$) as:\n$$O(\\theta) = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$$\nThe most general $O(2)$ matrix also includes reflections, but the parameterization by $\\theta$ covers all distinct sets of eigenvectors, as we will see.\n\n**2. Change of Variables**\nWe express the matrix elements $(a, b, c)$ in terms of $(\\lambda_1, \\lambda_2, \\theta)$:\n$$H = O\\Lambda O^T = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix} \\begin{pmatrix} \\lambda_1 & 0 \\\\ 0 & \\lambda_2 \\end{pmatrix} \\begin{pmatrix} \\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta \\end{pmatrix}$$\n$$H = \\begin{pmatrix} \\lambda_1 \\cos^2\\theta + \\lambda_2 \\sin^2\\theta & (\\lambda_1 - \\lambda_2)\\sin\\theta\\cos\\theta \\\\ (\\lambda_1 - \\lambda_2)\\sin\\theta\\cos\\theta & \\lambda_1 \\sin^2\\theta + \\lambda_2 \\cos^2\\theta \\end{pmatrix}$$\nThis gives the transformation equations:\n$a = \\lambda_1 \\cos^2\\theta + \\lambda_2 \\sin^2\\theta$\n$b = \\lambda_1 \\sin^2\\theta + \\lambda_2 \\cos^2\\theta$\n$c = (\\lambda_1 - \\lambda_2)\\sin\\theta\\cos\\theta$\n\n**3. The Jacobian of the Transformation**\nThe volume element transforms as $da\\,db\\,dc = |J| \\,d\\lambda_1\\,d\\lambda_2\\,d\\theta$, where $J$ is the Jacobian determinant:\n$$J = \\det\\left(\\frac{\\partial(a,b,c)}{\\partial(\\lambda_1, \\lambda_2, \\theta)}\\right)$$\nThe partial derivatives are:\n$\\frac{\\partial a}{\\partial \\lambda_1} = \\cos^2\\theta$, $\\frac{\\partial a}{\\partial \\lambda_2} = \\sin^2\\theta$, $\\frac{\\partial a}{\\partial \\theta} = -2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta$\n$\\frac{\\partial b}{\\partial \\lambda_1} = \\sin^2\\theta$, $\\frac{\\partial b}{\\partial \\lambda_2} = \\cos^2\\theta$, $\\frac{\\partial b}{\\partial \\theta} = 2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta$\n$\\frac{\\partial c}{\\partial \\lambda_1} = \\sin\\theta\\cos\\theta$, $\\frac{\\partial c}{\\partial \\lambda_2} = -\\sin\\theta\\cos\\theta$, $\\frac{\\partial c}{\\partial \\theta} = (\\lambda_1-\\lambda_2)(\\cos^2\\theta-\\sin^2\\theta)$\n\nThe determinant is:\n$$J = \\begin{vmatrix} \\cos^2\\theta & \\sin^2\\theta & -2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta \\\\ \\sin^2\\theta & \\cos^2\\theta & 2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta \\\\ \\sin\\theta\\cos\\theta & -\\sin\\theta\\cos\\theta & (\\lambda_1-\\lambda_2)(\\cos^2\\theta-\\sin^2\\theta) \\end{vmatrix}$$\nAdding the first row to the second row simplifies the matrix:\n$$J = \\begin{vmatrix} \\cos^2\\theta & \\sin^2\\theta & -2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta \\\\ 1 & 1 & 0 \\\\ \\sin\\theta\\cos\\theta & -\\sin\\theta\\cos\\theta & (\\lambda_1-\\lambda_2)(\\cos^2\\theta-\\sin^2\\theta) \\end{vmatrix}$$\nExpanding along the second row:\n$$J = -1 \\cdot \\det\\begin{pmatrix} \\sin^2\\theta & -2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta \\\\ -\\sin\\theta\\cos\\theta & (\\lambda_1-\\lambda_2)(\\cos^2\\theta-\\sin^2\\theta) \\end{pmatrix} + 1 \\cdot \\det\\begin{pmatrix} \\cos^2\\theta & -2(\\lambda_1-\\lambda_2)\\sin\\theta\\cos\\theta \\\\ \\sin\\theta\\cos\\theta & (\\lambda_1-\\lambda_2)(\\cos^2\\theta-\\sin^2\\theta) \\end{pmatrix}$$\n$$J = (\\lambda_1-\\lambda_2) \\left[ -\\sin^2\\theta(\\cos^2\\theta-\\sin^2\\theta) + 2\\sin^2\\theta\\cos^2\\theta + \\cos^2\\theta(\\cos^2\\theta-\\sin^2\\theta) + 2\\sin^2\\theta\\cos^2\\theta \\right]$$\n$$J = (\\lambda_1-\\lambda_2) \\left[ (\\cos^2\\theta-\\sin^2\\theta)(\\cos^2\\theta-\\sin^2\\theta) + 4\\sin^2\\theta\\cos^2\\theta \\right]$$\n$$J = (\\lambda_1-\\lambda_2) \\left[ (\\cos^2\\theta-\\sin^2\\theta)^2 + (2\\sin\\theta\\cos\\theta)^2 \\right] = (\\lambda_1-\\lambda_2)[\\cos^2(2\\theta) + \\sin^2(2\\theta)] = \\lambda_1-\\lambda_2$$\nThe absolute value for the volume element is $|J| = |\\lambda_1 - \\lambda_2|$.\n\n**4. Transforming the Probability Density**\nThe exponent in the PDF is proportional to $\\text{Tr}(H^2)$. Due to the cyclic property of the trace:\n$$\\text{Tr}(H^2) = \\text{Tr}((O\\Lambda O^T)^2) = \\text{Tr}(O\\Lambda^2 O^T) = \\text{Tr}(\\Lambda^2) = \\lambda_1^2 + \\lambda_2^2$$\nThe PDF in terms of the new variables is:\n$$P(\\lambda_1, \\lambda_2, \\theta) = C \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right)$$\nThe probability element is:\n$$P(a,b,c)da\\,db\\,dc = C \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right) |\\lambda_1-\\lambda_2| \\,d\\lambda_1\\,d\\lambda_2\\,d\\theta$$\nTo find the JPDF for the eigenvalues, we must integrate out the angular dependence $\\theta$. The transformation from $(a,b,c)$ to $(\\lambda_1, \\lambda_2, \\theta)$ shows that $H$ is periodic in $\\theta$ with period $\\pi$ (since $2\\theta$ is the argument in trig functions). Thus, we integrate $\\theta$ over $[0, \\pi)$ to cover the space of distinct eigenvector orientations once.\n$$p_{\\text{un}}(\\lambda_1, \\lambda_2) = \\int_0^{\\pi} C \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right) |\\lambda_1-\\lambda_2| \\,d\\theta$$\nSince the integrand is independent of $\\theta$, the integral is trivial:\n$$p_{\\text{un}}(\\lambda_1, \\lambda_2) = C \\pi |\\lambda_1-\\lambda_2| \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right)$$\nThis gives the unnormalized JPDF. Let's define a new normalization constant $Z = 1/(C\\pi)$. Then $p(\\lambda_1,\\lambda_2) = \\frac{1}{Z} |\\lambda_1-\\lambda_2| \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right)$.\n\n**5. Normalization**\nWe find $Z$ by enforcing $\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} p(\\lambda_1, \\lambda_2) d\\lambda_1 d\\lambda_2 = 1$.\n$$Z = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} |\\lambda_1-\\lambda_2| \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right) d\\lambda_1 d\\lambda_2$$\nWe perform a change of variables to simplify the integral. Let:\n$u = \\frac{\\lambda_1+\\lambda_2}{\\sqrt{2}}$, $v = \\frac{\\lambda_1-\\lambda_2}{\\sqrt{2}}$\nThis corresponds to a rotation of the coordinate system by $\\pi/4$. The Jacobian of this transformation is 1. The inverse transformation is $\\lambda_1 = (u+v)/\\sqrt{2}, \\lambda_2 = (u-v)/\\sqrt{2}$.\nThe terms in the integral become:\n$\\lambda_1^2 + \\lambda_2^2 = \\frac{1}{2}(u+v)^2 + \\frac{1}{2}(u-v)^2 = u^2+v^2$\n$|\\lambda_1-\\lambda_2| = |\\sqrt{2}v|$\nThe integral for $Z$ becomes:\n$$Z = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} |\\sqrt{2}v| \\exp\\left(-\\frac{1}{2}(u^2+v^2)\\right) du dv$$\n$$Z = \\sqrt{2} \\left(\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{u^2}{2}\\right) du\\right) \\left(\\int_{-\\infty}^{\\infty} |v|\\exp\\left(-\\frac{v^2}{2}\\right) dv\\right)$$\nThe first integral is a standard Gaussian integral:\n$$\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{u^2}{2}\\right) du = \\sqrt{2\\pi}$$\nThe second integral can be evaluated as:\n$$\\int_{-\\infty}^{\\infty} |v|\\exp\\left(-\\frac{v^2}{2}\\right) dv = 2 \\int_{0}^{\\infty} v\\exp\\left(-\\frac{v^2}{2}\\right) dv$$\nUsing substitution $w = v^2/2$, $dw = v\\,dv$:\n$$2 \\int_0^\\infty \\exp(-w) dw = 2 [-\\exp(-w)]_0^\\infty = 2(0 - (-1)) = 2$$\nCombining these results:\n$$Z = \\sqrt{2} \\cdot \\sqrt{2\\pi} \\cdot 2 = 4\\sqrt{\\pi}$$\nThe normalized JPDF for the eigenvalues is therefore:\n$$p(\\lambda_1, \\lambda_2) = \\frac{1}{Z} |\\lambda_1-\\lambda_2| \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right)$$\n$$p(\\lambda_1, \\lambda_2) = \\frac{1}{4\\sqrt{\\pi}} |\\lambda_1-\\lambda_2| \\exp\\left(-\\frac{1}{2}(\\lambda_1^2+\\lambda_2^2)\\right)$$", "answer": "$$ \\boxed{p(\\lambda_1, \\lambda_2) = \\frac{1}{4\\sqrt{\\pi}} |\\lambda_1 - \\lambda_2| \\exp\\left(-\\frac{1}{2}(\\lambda_1^2 + \\lambda_2^2)\\right)} $$", "id": "652134"}, {"introduction": "While direct integration can be used to find the density of states, more powerful tools are often needed to analyze the properties of these distributions in the large-$N$ limit. The Stieltjes transform is one such indispensable tool, acting as a generating function for the moments of a spectral distribution. This practice problem tasks you with using an algebraic equation for the Stieltjes transform of the Wigner semicircle law to efficiently compute its higher moments, showcasing a method that is far more elegant than direct integration [@problem_id:652122].", "problem": "In random matrix theory, the eigenvalue distribution of large Hermitian matrices from certain ensembles converges to a deterministic limit. For the Gaussian Unitary Ensemble (GUE) in the large matrix size limit, this limiting distribution is the Wigner semicircle distribution. The standard Wigner semicircle law has a probability density function given by:\n$$\n\\rho(\\lambda) = \\begin{cases} \\frac{1}{2\\pi} \\sqrt{4-\\lambda^2} & \\text{if } |\\lambda| \\le 2 \\\\ 0 & \\text{if } |\\lambda| > 2 \\end{cases}\n$$\n\nThe moments of this distribution are defined as $M_k = \\int_{-\\infty}^{\\infty} \\lambda^k \\rho(\\lambda) d\\lambda$. The even moments, $M_{2n}$, are particularly significant as they are given by the $n$-th Catalan number, $C_n = \\frac{1}{n+1}\\binom{2n}{n}$, which counts the number of non-crossing pairings of $2n$ points on a circle.\n\nA powerful tool for studying such distributions is the Stieltjes transform (or resolvent), defined as:\n$$\nG(z) = \\int_{-\\infty}^{\\infty} \\frac{\\rho(\\lambda)}{z-\\lambda} d\\lambda, \\quad z \\in \\mathbb{C} \\setminus [-2, 2]\n$$\nFor large $|z|$, the Stieltjes transform has a series expansion in terms of the moments:\n$$\nG(z) = \\sum_{k=0}^{\\infty} \\frac{M_k}{z^{k+1}}\n$$\nIt can be shown that for the standard Wigner semicircle distribution, the Stieltjes transform satisfies the following quadratic equation:\n$$\nG(z)^2 - zG(z) + 1 = 0\n$$\nUsing this algebraic equation for $G(z)$ and its series expansion, calculate the sixth moment, $M_6$, of the standard Wigner semicircle distribution.", "solution": "1.  **Rearrange the algebraic equation.**\n    The Stieltjes transform $G(z)$ for the standard Wigner semicircle distribution satisfies the quadratic equation $G(z)^2 - zG(z) + 1 = 0$. We can rearrange this to a form that is more convenient for series expansion:\n    $$zG(z) = 1 + G(z)^2$$\n\n2.  **Use the series expansion of G(z).**\n    For large $|z|$, $G(z)$ can be expanded in a series involving the moments $M_k = \\int \\lambda^k \\rho(\\lambda)d\\lambda$:\n    $$G(z) = \\sum_{k=0}^{\\infty} \\frac{M_k}{z^{k+1}} = \\frac{M_0}{z} + \\frac{M_1}{z^2} + \\frac{M_2}{z^3} + \\dots$$\n    Substituting this into our rearranged equation gives:\n    $$z \\left(\\sum_{k=0}^{\\infty} \\frac{M_k}{z^{k+1}}\\right) = 1 + \\left(\\sum_{k=0}^{\\infty} \\frac{M_k}{z^{k+1}}\\right)^2$$\n    $$\\sum_{k=0}^{\\infty} \\frac{M_k}{z^k} = 1 + \\left(\\frac{M_0}{z} + \\frac{M_1}{z^2} + \\frac{M_2}{z^3} + \\dots\\right)^2$$\n\n3.  **Equate coefficients to find the moments.**\n    We now expand the two sides and equate the coefficients of the powers of $1/z$.\n    $$M_0 + \\frac{M_1}{z} + \\frac{M_2}{z^2} + \\frac{M_3}{z^3} + \\frac{M_4}{z^4} + \\frac{M_5}{z^5} + \\frac{M_6}{z^6} + \\dots = 1 + \\frac{M_0^2}{z^2} + \\frac{2M_0M_1}{z^3} + \\frac{M_1^2 + 2M_0M_2}{z^4} + \\frac{2M_0M_3 + 2M_1M_2}{z^5} + \\frac{M_2^2 + 2M_0M_4 + 2M_1M_3}{z^6} + \\dots$$\n    By comparing terms order by order:\n    -   $z^0$: $M_0 = 1$. (This is required for any normalized probability distribution).\n    -   $z^{-1}$: $M_1 = 0$. (The mean is zero, as the distribution is symmetric around $\\lambda=0$).\n    -   $z^{-2}$: $M_2 = M_0^2 = 1^2 = 1$.\n    -   $z^{-3}$: $M_3 = 2M_0M_1 = 2(1)(0) = 0$.\n    -   $z^{-4}$: $M_4 = M_1^2 + 2M_0M_2 = 0^2 + 2(1)(1) = 2$.\n    -   $z^{-5}$: $M_5 = 2M_0M_3 + 2M_1M_2 = 2(1)(0) + 2(0)(1) = 0$.\n    -   $z^{-6}$: $M_6 = M_2^2 + 2M_0M_4 + 2M_1M_3 = 1^2 + 2(1)(2) + 2(0)(0) = 1 + 4 = 5$.\n\nThe sixth moment, $M_6$, is 5. This matches the third Catalan number, $C_3 = \\frac{1}{3+1}\\binom{2\\cdot 3}{3} = \\frac{1}{4} \\cdot \\frac{6!}{3!3!} = \\frac{20}{4} = 5$.", "answer": "$$\\boxed{5}$$", "id": "652122"}, {"introduction": "The landscape of random matrix theory extends beyond Hermitian matrices to non-Hermitian ensembles, whose eigenvalues are typically scattered across the complex plane. This exercise introduces a powerful method rooted in potential theory to determine the eigenvalue density for a generalized complex Ginibre ensemble. By treating the eigenvalues as a two-dimensional Coulomb gas in an external potential $V$, you will use the relation $\\rho(z) \\propto \\Delta V$ to derive the shape and properties of the eigenvalue cloud, demonstrating a profound connection between electrostatics and spectral theory [@problem_id:652099].", "problem": "In the study of non-Hermitian random matrices, the complex Ginibre ensemble provides a fundamental model. Consider a generalization of this ensemble where the joint probability density of the complex eigenvalues $z_1, z_2, \\ldots, z_N$ of an $N \\times N$ random matrix is given by\n$$\nP(z_1, \\ldots, z_N) = \\frac{1}{Z_N} \\prod_{j<k} |z_j - z_k|^2 \\exp\\left(-N \\sum_{j=1}^N V(|z_j|)\\right)\n$$\nwhere $Z_N$ is a normalization constant and $V(r) = r^{2\\alpha}$ is a radially symmetric potential with a real parameter $\\alpha > 0$. For $\\alpha=1$, this corresponds to the standard complex Ginibre ensemble.\n\nIn the large $N$ limit, the empirical eigenvalue density $\\rho_N(z) = \\frac{1}{N} \\sum_{k=1}^N \\delta^{(2)}(z-z_k)$ converges to a deterministic limiting density $\\rho(z)$. For the potential $V(r) = r^{2\\alpha}$, this limiting density is non-zero only within a circular disk of radius $R$, i.e., $\\rho(z) = 0$ for $|z| > R$. Within this disk, the density is given by the formula from potential theory:\n$$\n\\rho(z) = \\frac{1}{4\\pi} \\Delta V(|z|)\n$$\nwhere $\\Delta = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$ is the Laplacian operator in the complex plane $z=x+iy$.\n\nThe radius $R$ of the support disk is determined by the normalization condition $\\int_{|z| \\le R} \\rho(z) d^2z = 1$.\n\nDefine a scaled radial variable $x = |z|/R$. The probability density function of this scaled radius, $g(x)$, can be found from the limiting eigenvalue density $\\rho(z)$.\n\nYour task is to calculate the mean value of this scaled radial variable, $\\mathbb{E}[x]$, for an eigenvalue chosen at random from this distribution. Express your answer in terms of the parameter $\\alpha$.", "solution": "The problem asks for the mean of the scaled radial distribution of eigenvalues for a generalized Ginibre ensemble. The steps are:\n1.  Calculate the limiting eigenvalue density $\\rho(z)$ using the given formula.\n2.  Determine the radius of the support disk, $R$, by normalizing the density.\n3.  Derive the probability density function for the radial coordinate, $p(r)$.\n4.  Transform $p(r)$ to the probability density function for the scaled radius, $g(x)$, where $x=r/R$.\n5.  Compute the expectation value $\\mathbb{E}[x] = \\int x g(x) dx$.\n\n**Step 1: Calculate the limiting eigenvalue density $\\rho(z)$**\n\nThe potential is given by $V(|z|) = |z|^{2\\alpha}$. In Cartesian coordinates $z = x+iy$, this is $V(x,y) = (x^2+y^2)^\\alpha$. The limiting density is $\\rho(z) = \\frac{1}{4\\pi} \\Delta V$. Let's compute the Laplacian $\\Delta V$.\n\nFirst derivatives:\n$$\n\\frac{\\partial V}{\\partial x} = \\alpha(x^2+y^2)^{\\alpha-1}(2x)\n$$\n$$\n\\frac{\\partial V}{\\partial y} = \\alpha(x^2+y^2)^{\\alpha-1}(2y)\n$$\n\nSecond derivatives:\n$$\n\\frac{\\partial^2 V}{\\partial x^2} = 4\\alpha(\\alpha-1)x^2(x^2+y^2)^{\\alpha-2} + 2\\alpha(x^2+y^2)^{\\alpha-1}\n$$\n$$\n\\frac{\\partial^2 V}{\\partial y^2} = 4\\alpha(\\alpha-1)y^2(x^2+y^2)^{\\alpha-2} + 2\\alpha(x^2+y^2)^{\\alpha-1}\n$$\n\nThe Laplacian is the sum of the second partial derivatives:\n$$\n\\Delta V = \\frac{\\partial^2 V}{\\partial x^2} + \\frac{\\partial^2 V}{\\partial y^2} = 4\\alpha(\\alpha-1)(x^2+y^2)(x^2+y^2)^{\\alpha-2} + 4\\alpha(x^2+y^2)^{\\alpha-1}\n$$\n$$\n\\Delta V = 4\\alpha(\\alpha-1)(x^2+y^2)^{\\alpha-1} + 4\\alpha(x^2+y^2)^{\\alpha-1} = 4\\alpha^2(x^2+y^2)^{\\alpha-1} = 4\\alpha^2 r^{2\\alpha-2}\n$$\nwhere $r=|z|=\\sqrt{x^2+y^2}$.\n\nThe eigenvalue density is therefore:\n$$\n\\rho(z) = \\rho(r) = \\frac{1}{4\\pi} (4\\alpha^2 r^{2\\alpha-2}) = \\frac{\\alpha^2}{\\pi} r^{2\\alpha-2}\n$$\nThis density is valid for $0 \\le r \\le R$ and is zero for $r > R$.\n\n**Step 2: Determine the radius of support $R$**\n\nThe radius $R$ is determined by the normalization condition $\\int \\rho(z) d^2z = 1$. We integrate over the disk of radius $R$. In polar coordinates, $d^2z = r dr d\\theta$.\n$$\n\\int_{|z| \\le R} \\rho(z) d^2z = \\int_0^{2\\pi} d\\theta \\int_0^R \\left(\\frac{\\alpha^2}{\\pi} r^{2\\alpha-2}\\right) r dr = 1\n$$\n$$\n2\\pi \\frac{\\alpha^2}{\\pi} \\int_0^R r^{2\\alpha-1} dr = 1\n$$\n$$\n2\\alpha^2 \\left[\\frac{r^{2\\alpha}}{2\\alpha}\\right]_0^R = 1\n$$\n$$\n\\alpha R^{2\\alpha} = 1\n$$\nSolving for $R$ gives:\n$$\nR^{2\\alpha} = \\frac{1}{\\alpha} \\implies R = \\left(\\frac{1}{\\alpha}\\right)^{1/(2\\alpha)}\n$$\n\n**Step 3: Derive the radial probability density $p(r)$**\n\nThe radial probability density $p(r)$ is obtained by integrating $\\rho(z)$ over the angular coordinate:\n$$\np(r) = \\int_0^{2\\pi} \\rho(r) r d\\theta = 2\\pi r \\rho(r)\n$$\nSubstituting the expression for $\\rho(r)$:\n$$\np(r) = 2\\pi r \\left(\\frac{\\alpha^2}{\\pi} r^{2\\alpha-2}\\right) = 2\\alpha^2 r^{2\\alpha-1}\n$$\nThis is valid for $0 \\le r \\le R$.\n\n**Step 4: Derive the scaled radial density $g(x)$**\n\nThe scaled radial variable is $x = r/R$, so $r = xR$. The probability density $g(x)$ for the scaled variable $x$ is related to $p(r)$ by the change of variables formula: $g(x)dx = p(r)dr$.\n$$\ng(x) = p(r) \\frac{dr}{dx} = p(xR) \\cdot R\n$$\nSubstituting the expressions for $p(r)$ and $r=xR$:\n$$\ng(x) = \\left(2\\alpha^2 (xR)^{2\\alpha-1}\\right) R = 2\\alpha^2 R^{2\\alpha} x^{2\\alpha-1}\n$$\nNow, substitute the value of $R^{2\\alpha} = 1/\\alpha$:\n$$\ng(x) = 2\\alpha^2 \\left(\\frac{1}{\\alpha}\\right) x^{2\\alpha-1} = 2\\alpha x^{2\\alpha-1}\n$$\nThis density is valid for $0 \\le x \\le 1$. We can check its normalization:\n$$\n\\int_0^1 g(x) dx = \\int_0^1 2\\alpha x^{2\\alpha-1} dx = \\left[x^{2\\alpha}\\right]_0^1 = 1-0=1\n$$\nThe density is correctly normalized.\n\n**Step 5: Compute the mean value $\\mathbb{E}[x]$**\n\nThe mean value of the scaled radius $x$ is given by the integral:\n$$\n\\mathbb{E}[x] = \\int_0^1 x g(x) dx\n$$\nSubstituting the expression for $g(x)$:\n$$\n\\mathbb{E}[x] = \\int_0^1 x (2\\alpha x^{2\\alpha-1}) dx = \\int_0^1 2\\alpha x^{2\\alpha} dx\n$$\nEvaluating the integral:\n$$\n\\mathbb{E}[x] = 2\\alpha \\left[\\frac{x^{2\\alpha+1}}{2\\alpha+1}\\right]_0^1 = 2\\alpha \\left(\\frac{1^{2\\alpha+1}}{2\\alpha+1} - 0\\right)\n$$\n$$\n\\mathbb{E}[x] = \\frac{2\\alpha}{2\\alpha+1}\n$$\nThis is the final answer. For the standard Ginibre case where $\\alpha=1$, the mean scaled radius is $\\mathbb{E}[x] = 2/3$.", "answer": "$$\n\\boxed{\\frac{2\\alpha}{2\\alpha+1}}\n$$", "id": "652099"}]}