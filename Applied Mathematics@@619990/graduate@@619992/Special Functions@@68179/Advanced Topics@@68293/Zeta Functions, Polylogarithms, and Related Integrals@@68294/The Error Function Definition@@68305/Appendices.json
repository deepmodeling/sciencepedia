{"hands_on_practices": [{"introduction": "Evaluating integrals involving special functions often requires creative analytical techniques. This first practice introduces a particularly elegant and powerful method: differentiation under the integral sign, famously known as Feynman's trick. By strategically introducing a parameter, we can transform a challenging integral into a simpler differential equation, which can then be solved to find the value of the original integral [@problem_id:782549]. This exercise is not just about finding an answer; it's about developing a versatile tool for your mathematical arsenal.", "problem": "The error function, denoted by $\\operatorname{erf}(x)$, is a non-elementrary function that arises in probability, statistics, and the solution of partial differential equations. It is defined by the integral:\n$$\n\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} dt\n$$\nThe error function is an odd function, with $\\operatorname{erf}(0) = 0$ and $\\lim_{x\\to\\infty} \\operatorname{erf}(x) = 1$. The prefactor $\\frac{2}{\\sqrt{\\pi}}$ is a normalization constant that ensures this limit.\n\nYour task is to evaluate the following definite integral, which involves a product of a Gaussian function and the error function.\n\nCalculate the value of the integral $I$:\n$$\nI = \\int_0^\\infty e^{-x^2} \\operatorname{erf}(x) dx\n$$", "solution": "1. Define the auxiliary integral\n$$\nJ(a)=\\int_{0}^{\\infty}e^{-x^{2}}\\operatorname{erf}(a x)\\,dx.\n$$\n2. Differentiate under the integral sign:\n$$\n\\frac{dJ}{da}\n=\\int_{0}^{\\infty}e^{-x^{2}}\\frac{d}{da}\\operatorname{erf}(a x)\\,dx\n=\\int_{0}^{\\infty}e^{-x^{2}}\\frac{2}{\\sqrt\\pi}\\,x\\,e^{-a^{2}x^{2}}\\,dx\n=\\frac{2}{\\sqrt\\pi}\\int_{0}^{\\infty}x\\,e^{-(1+a^{2})x^{2}}\\,dx.\n$$\n3. Evaluate the Gaussian integral:\n$$\n\\int_{0}^{\\infty}x\\,e^{-\\beta x^{2}}\\,dx\n=\\frac{1}{2\\beta}\n\\quad\\Longrightarrow\\quad\n\\frac{dJ}{da}\n=\\frac{2}{\\sqrt\\pi}\\cdot\\frac{1}{2(1+a^{2})}\n=\\frac{1}{\\sqrt\\pi\\,(1+a^{2})}.\n$$\n4. Integrate with respect to $a$:\n$$\nJ(a)\n=\\frac{1}{\\sqrt\\pi}\\arctan(a)+C.\n$$\nSince $J(0)=0$, we have $C=0$, so\n$$\nJ(a)=\\frac{1}{\\sqrt\\pi}\\arctan(a).\n$$\n5. The desired integral is $I=J(1)$:\n$$\nI\n=J(1)\n=\\frac{1}{\\sqrt\\pi}\\arctan(1)\n=\\frac{1}{\\sqrt\\pi}\\cdot\\frac{\\pi}{4}\n=\\frac{\\sqrt\\pi}{4}.\n$$", "answer": "$$\\boxed{\\frac{\\sqrt{\\pi}}{4}}$$", "id": "782549"}, {"introduction": "The error function is far more than a mathematical abstraction; it is a fundamental tool in probability and statistics, intrinsically linked to the cumulative distribution function of the ubiquitous normal distribution. This practice moves from pure analytical evaluation to a concrete application in this domain [@problem_id:782679]. Here, you will calculate the conditional expectation of a function of a standard normal random variable, a task that requires a firm grasp of both probability theory and the integral properties of the error function, reinforcing its practical significance.", "problem": "A random variable $X$ follows the standard normal distribution, characterized by the probability density function (PDF) $f(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$. The error function, denoted $\\operatorname{erf}(z)$, is a special function of key importance in probability and physics, defined by the integral:\n$$\n\\operatorname{erf}(z) = \\frac{2}{\\sqrt{\\pi}} \\int_0^z e^{-t^2} dt\n$$\nYour task is to compute the conditional expectation of $\\operatorname{erf}(X)$ given that the random variable $X$ takes a positive value. That is, calculate the value of $E[\\operatorname{erf}(X) | X > 0]$.", "solution": "1. We wish to compute \n$$E[\\operatorname{erf}(X)\\mid X>0]=\\frac{1}{P(X>0)}\\int_0^\\infty\\operatorname{erf}(x)\\,\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}dx =2\\int_0^\\infty\\operatorname{erf}(x)\\,\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}dx.$$\n2. Set \n$$I=\\int_0^\\infty\\operatorname{erf}(x)e^{-x^2/2}dx.$$\nUsing the known antiderivative $\\int e^{-x^2/2}dx=\\sqrt{\\frac\\pi2}\\,\\operatorname{erf}\\!\\bigl(x/\\sqrt2\\bigr)$ and integrating by parts with $u=\\operatorname{erf}(x)$, $dv=e^{-x^2/2}dx$, one finds after simplification\n$$I=\\sqrt2\\int_0^\\infty e^{-t^2}\\,\\operatorname{erfc}\\!\\bigl(t/\\sqrt2\\bigr)\\,dt.$$\nHence\n$$E[\\operatorname{erf}(X)\\mid X>0] =\\frac{2}{\\sqrt{2\\pi}}\\,I =\\frac{2}{\\sqrt\\pi}\\int_0^\\infty e^{-t^2}\\,\\operatorname{erfc}\\!\\bigl(t/\\sqrt2\\bigr)\\,dt.$$\n3. Write $\\operatorname{erfc}(t/\\sqrt2)=1-\\operatorname{erf}(t/\\sqrt2)$ and split the integral:\n$$\\int_0^\\infty e^{-t^2}\\,dt=\\frac{\\sqrt\\pi}{2},\\quad \\int_0^\\infty e^{-t^2}\\operatorname{erf}\\!\\bigl(t/\\sqrt2\\bigr)dt =I(1,1/\\sqrt2)$$\nwhere \n$$I(p,q)=\\int_0^\\infty e^{-p^2x^2}\\operatorname{erf}(qx)\\,dx =\\frac{1}{p\\sqrt\\pi}\\arctan\\!\\Bigl(\\frac{q}{p}\\Bigr).$$\nThus\n$$\\int_0^\\infty e^{-t^2}\\operatorname{erf}(t/\\sqrt2)dt =\\frac{1}{\\sqrt\\pi}\\arctan\\!\\bigl(1/\\sqrt2\\bigr),$$\nand \n$$\\int_0^\\infty e^{-t^2}\\,\\operatorname{erfc}(t/\\sqrt2)\\,dt =\\frac{\\sqrt\\pi}{2}-\\frac{1}{\\sqrt\\pi}\\arctan\\!\\bigl(1/\\sqrt2\\bigr).$$\n4. Finally,\n$$E[\\operatorname{erf}(X)\\mid X>0] =\\frac{2}{\\sqrt\\pi}\\Bigl(\\frac{\\sqrt\\pi}{2}-\\frac{1}{\\sqrt\\pi}\\arctan\\!\\tfrac1{\\sqrt2}\\Bigr) =1-\\frac{2}{\\pi}\\arctan\\!\\tfrac1{\\sqrt2} =\\frac{2}{\\pi}\\arctan(\\sqrt2).$$", "answer": "$$\\boxed{\\frac{2}{\\pi}\\arctan(\\sqrt{2})}$$", "id": "782679"}, {"introduction": "While analytical solutions are elegant, most real-world applications of special functions like $\\operatorname{erf}(x)$ rely on accurate and efficient numerical computation, especially since its defining integral lacks an elementary antiderivative. This final hands-on practice bridges the gap between theoretical definition and practical implementation [@problem_id:2397742]. You will develop a program to compute the error function from its integral definition using adaptive Gaussian quadrature, a highly effective numerical method, and validate your results against established library functions. This exercise provides invaluable insight into the computational backbone of scientific software.", "problem": "Design and implement a complete, runnable program that computes the error function using Gaussian quadrature and validates it against trusted library implementations. Your program must satisfy all of the following requirements.\n\n1) Foundations to use. Begin from the core definition of Gaussian quadrature for weight functions on standard domains and the orthogonality of classical polynomials. In particular, use the facts that the Legendre polynomials $P_n(x)$ are orthogonal on $[-1,1]$ with respect to weight $w(x)=1$, and that Gaussian quadrature selects nodes at the zeros of $P_n(x)$ with associated positive weights to produce exact integration for polynomials up to degree $2n-1$. From this starting point, derive a rule to approximate a definite integral on a general interval $[a,b]$ and justify the use of a composite strategy by partitioning the interval. Avoid providing any shortcut integration formulas in your derivation; instead, rely only on the orthogonality of $P_n(x)$, properties of linear changes of variables, and the well-tested fact that Gaussian quadrature with $n$ points integrates any polynomial of degree up to $2n-1$ exactly on $[-1,1]$.\n\n2) Target quantity. Use the definition of the error function\n$$\n\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2}\\, dt,\n$$\nand compute it numerically by evaluating the integral with Gaussian quadrature. Your approach must handle any real $x$ by correctly orienting the integral if $x<0$. You may use the oddness of $\\operatorname{erf}(x)$, namely $\\operatorname{erf}(-x)=-\\operatorname{erf}(x)$, if you justify it from the integral definition.\n\n3) Algorithmic requirements.\n- Implement an $n$-point Gauss–Legendre quadrature rule on $[-1,1]$, then map it to an arbitrary interval $[a,b]$ by a linear change of variables derived from first principles, and apply it in a composite fashion over subintervals of $[a,b]$.\n- Use an adaptive refinement in the number of subintervals: start with a single panel and repeatedly double the number of panels until the change in the composite quadrature value is within a requested absolute tolerance $T_{\\mathrm{abs}}$ plus relative tolerance $T_{\\mathrm{rel}}$ scaled by the current estimate. Both tolerances must be user-specified constants in your code.\n- Use a smoothness-aware rule size by choosing a reasonably large but fixed number of nodes per panel to exploit the analyticity of $e^{-t^2}$.\n\n4) Comparison with trusted references. For each test input $x$, compute three quantities: the Gaussian-quadrature approximation $\\widehat{\\operatorname{erf}}(x)$, a reference value from a standard library implementation, and the absolute error defined as $|\\widehat{\\operatorname{erf}}(x) - \\operatorname{erf}_{\\mathrm{ref}}(x)|$. You must compare with at least one trusted function from a scientific library. Use radians by default; no physical units are involved in this computation.\n\n5) Test suite. Your program must evaluate the following set of inputs covering nominal, boundary, and challenging regimes:\n- $x \\in \\{\\, 0,\\; 10^{-8},\\; 0.5,\\; 1.0,\\; -1.3,\\; 2.0,\\; 5.0 \\,\\}$.\n- Use $n=16$ Gauss–Legendre nodes per panel.\n- Use absolute tolerance $T_{\\mathrm{abs}}=10^{-12}$ and relative tolerance $T_{\\mathrm{rel}}=10^{-12}$ for the adaptive refinement in the number of panels.\n\n6) Final output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test input $x$, output a list with four floating-point numbers in the order $[\\widehat{\\operatorname{erf}}(x), \\operatorname{erf}_{\\mathrm{math}}(x), \\operatorname{erf}_{\\mathrm{scipy}}(x), E_{\\max}(x)]$, where $\\operatorname{erf}_{\\mathrm{math}}$ is from the standard math library, $\\operatorname{erf}_{\\mathrm{scipy}}$ is from a scientific library, and $E_{\\max}(x)$ is the maximum absolute discrepancy between your approximation and the two library values. The final line must therefore look like\n$[\\,[\\widehat{\\operatorname{erf}}(x_1), \\operatorname{erf}_{\\mathrm{math}}(x_1), \\operatorname{erf}_{\\mathrm{scipy}}(x_1), E_{\\max}(x_1)], \\ldots, [\\widehat{\\operatorname{erf}}(x_m), \\operatorname{erf}_{\\mathrm{math}}(x_m), \\operatorname{erf}_{\\mathrm{scipy}}(x_m), E_{\\max}(x_m)]\\,]$\nwith no extra text before or after it.\n\nYour program must be entirely self-contained, deterministic, and must not require any user input, external files, or network access.", "solution": "The objective is to compute the error function, defined as\n$$\n\\operatorname{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2}\\, dt\n$$\nfor a set of real numbers $x$, using a custom-implemented adaptive Gaussian quadrature algorithm. The results will be validated against trusted library functions.\n\n**1. Foundations of Gauss-Legendre Quadrature**\n\nThe core of the method is the $n$-point Gauss-Legendre quadrature rule for approximating definite integrals over the canonical interval $[-1, 1]$. An integral of a function $f(\\xi)$ is approximated by a weighted sum:\n$$\n\\int_{-1}^{1} f(\\xi) \\, d\\xi \\approx \\sum_{i=1}^{n} w_i f(\\xi_i)\n$$\nFor Gauss-Legendre quadrature, the nodes $\\xi_i$ are the $n$ distinct real roots of the Legendre polynomial of degree $n$, $P_n(\\xi)$, which are known to lie in the open interval $(-1, 1)$. The corresponding weights $w_i$ are all positive and are chosen such that the formula is exact for any polynomial of degree up to $2n-1$. This high degree of accuracy is a consequence of the orthogonality of the Legendre polynomials on $[-1, 1]$ with respect to the weight function $w(\\xi)=1$. We will not derive the values of $\\xi_i$ and $w_i$ here, as this is a standard result; we shall obtain them from a trusted numerical library source, as is common practice.\n\n**2. Transformation for an Arbitrary Integration Interval $[a,b]$**\n\nTo apply this rule to an integral over a general interval $[a,b]$, we must perform a linear change of variables that maps $\\xi \\in [-1, 1]$ to $t \\in [a,b]$. Let this transformation be $t(\\xi) = c_1 \\xi + c_2$. We require $t(-1)=a$ and $t(1)=b$, which gives a system of two linear equations for the coefficients $c_1$ and $c_2$:\n$$\n\\begin{cases}\na = -c_1 + c_2 \\\\\nb = c_1 + c_2\n\\end{cases}\n$$\nSolving this system yields $c_1 = \\frac{b-a}{2}$ and $c_2 = \\frac{a+b}{2}$. Thus, the transformation is:\n$$\nt(\\xi) = \\frac{b-a}{2}\\xi + \\frac{a+b}{2}\n$$\nThe differential element transforms accordingly: $dt = \\frac{b-a}{2} d\\xi$. Substituting this into the integral of a function $g(t)$ gives:\n$$\n\\int_{a}^{b} g(t) \\, dt = \\int_{-1}^{1} g\\left(\\frac{b-a}{2}\\xi + \\frac{a+b}{2}\\right) \\frac{b-a}{2} \\, d\\xi\n$$\nApplying the $n$-point Gauss-Legendre quadrature rule to the integral on the right-hand side, we obtain the formula for a general interval $[a,b]$:\n$$\n\\int_{a}^{b} g(t) \\, dt \\approx \\frac{b-a}{2} \\sum_{i=1}^{n} w_i \\, g\\left(\\frac{b-a}{2}\\xi_i + \\frac{a+b}{2}\\right)\n$$\nThis derivation fulfills the requirement of building the general rule from first principles.\n\n**3. Composite Quadrature and Adaptive Refinement**\n\nWhile a single application of the Gauss-Legendre rule is powerful, its accuracy depends on how well the integrand $g(t)$ can be approximated by a single polynomial of degree $2n-1$ over the entire interval $[a,b]$. For long intervals or functions with varying behavior, it is more effective to partition the interval $[a,b]$ into $M$ smaller subintervals, or panels, and apply the quadrature rule to each. This is the composite quadrature rule.\n\nLet the interval $[a,b]$ be divided into $M$ panels of equal width $h = (b-a)/M$. The $j$-th panel is $[t_{j-1}, t_j]$, where $t_j = a + jh$ for $j \\in \\{1, \\dots, M\\}$. The total integral is the sum of the integrals over each panel:\n$$\n\\int_{a}^{b} g(t) \\, dt = \\sum_{j=1}^{M} \\int_{t_{j-1}}^{t_j} g(t) \\, dt \\approx \\sum_{j=1}^{M} \\frac{h}{2} \\sum_{i=1}^{n} w_i \\, g\\left(\\frac{h}{2}\\xi_i + \\frac{t_{j-1}+t_j}{2}\\right)\n$$\nThe problem requires an adaptive scheme to determine the number of panels $M$. We begin with a small number of panels (e.g., $M=1$) and compute the integral estimate, $I_M$. We then double the number of panels to $2M$ and compute a new estimate, $I_{2M}$. This process is repeated until the change between successive estimates is acceptably small. The convergence criterion is specified as:\n$$\n|I_{2M} - I_M| \\le T_{\\mathrm{abs}} + T_{\\mathrm{rel}} |I_{2M}|\n$$\nwhere $T_{\\mathrm{abs}}$ and $T_{\\mathrm{rel}}$ are the absolute and relative tolerances, both set to $10^{-12}$. This ensures that the result is stable to the requested precision. The number of quadrature nodes per panel, $n$, is fixed at $16$, a choice well-suited for the smooth, analytic integrand $e^{-t^2}$.\n\n**4. Application to the Error Function**\n\nThe target quantity is $\\operatorname{erf}(x)$. For $x > 0$, the integration is over $[0,x]$. For $x=0$, the integral is trivially $0$. For $x  0$, the upper limit of integration is less than the lower limit. We can handle this by using the property that $\\operatorname{erf}(x)$ is an odd function, i.e., $\\operatorname{erf}(-x) = -\\operatorname{erf}(x)$. We justify this from the integral definition.\nLet $x > 0$. Then $-x  0$:\n$$\n\\operatorname{erf}(-x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{-x} e^{-t^2} \\, dt\n$$\nLet $u = -t$, so $du = -dt$. The integration limits become: $t=0 \\implies u=0$ and $t=-x \\implies u=x$.\n$$\n\\operatorname{erf}(-x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-(-u)^2} (-du) = - \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-u^2} \\, du = -\\operatorname{erf}(x)\n$$\nThis property is proven. Therefore, for any $x0$, we can compute $\\operatorname{erf}(|x|)$ and negate the result. The computational problem is thus reduced to evaluating the integral over $[0, |x|]$ for any $x \\neq 0$.\n\nThe final algorithm is as follows:\n1.  For a given input $x$, handle the trivial case $x=0$.\n2.  Determine the sign of $x$ and set the integration interval to $[a,b] = [0, |x|]$.\n3.  Obtain the $n=16$ Gauss-Legendre nodes $\\xi_i$ and weights $w_i$.\n4.  Apply the adaptive composite quadrature scheme described above to approximate $I = \\int_{0}^{|x|} e^{-t^2} \\, dt$.\n5.  The final result is $\\widehat{\\operatorname{erf}}(x) = \\operatorname{sign}(x) \\cdot \\frac{2}{\\sqrt{\\pi}} I$.\n6.  This result is then compared with values from `math.erf` and `scipy.special.erf`, and the maximum absolute error $E_{\\max}$ is calculated.\n\nThe extraneous instruction \"Use radians by default\" in the problem description is nonsensical for the error function, whose argument is dimensionless, and is therefore ignored.", "answer": "```python\nimport math\nimport numpy as np\nfrom scipy.special import erf as erf_scipy\nfrom scipy.special import roots_legendre\n\ndef compute_erf_quadrature(x, n, tol_abs, tol_rel):\n    \"\"\"\n    Computes the error function erf(x) using adaptive composite Gaussian quadrature.\n\n    Args:\n        x (float): The point at which to evaluate erf(x).\n        n (int): The number of Gauss-Legendre nodes per panel.\n        tol_abs (float): The absolute tolerance for convergence.\n        tol_rel (float): The relative tolerance for convergence.\n\n    Returns:\n        float: The numerical approximation of erf(x).\n    \"\"\"\n    if x == 0.0:\n        return 0.0\n\n    sign = np.sign(x)\n    b = abs(x)\n    a = 0.0\n\n    # Get Gauss-Legendre nodes and weights for the canonical interval [-1, 1]\n    xi, w = roots_legendre(n)\n\n    # Pre-calculate the integrand function\n    integrand = lambda t: np.exp(-t**2)\n\n    def compute_composite_integral(num_panels):\n        \"\"\"Helper to compute integral with a fixed number of panels.\"\"\"\n        h = (b - a) / num_panels\n        \n        # Vectorized computation of evaluation points for all panels\n        # panel_midpoints shape: (num_panels,)\n        panel_midpoints = a + h * (np.arange(num_panels) + 0.5)\n        \n        # t_eval_points shape: (n, num_panels)\n        # xi[:, np.newaxis] broadcasts over panel_midpoints\n        t_eval_points = panel_midpoints[np.newaxis, :] + (h/2) * xi[:, np.newaxis]\n        \n        # Evaluate integrand at all points\n        integrand_values = integrand(t_eval_points)\n        \n        # Apply weights and sum up contributions\n        # w[:, np.newaxis] broadcasts over integrand_values\n        integral_sum = np.sum(w[:, np.newaxis] * integrand_values)\n        \n        return (h / 2.0) * integral_sum\n\n    # Adaptive refinement loop\n    num_panels = 1\n    max_iterations = 20  # Safety break to prevent infinite loops\n\n    old_integral = compute_composite_integral(num_panels)\n\n    for _ in range(max_iterations):\n        num_panels *= 2\n        new_integral = compute_composite_integral(num_panels)\n        \n        # Check for convergence using the specified mixed tolerance\n        if abs(new_integral - old_integral) = tol_abs + tol_rel * abs(new_integral):\n            final_integral = new_integral\n            break\n        \n        old_integral = new_integral\n    else:\n        # This part is executed if the loop finishes without a 'break'\n        raise RuntimeError(f\"Adaptive quadrature did not converge for x={x} within {max_iterations} iterations.\")\n\n    return sign * (2.0 / math.sqrt(math.pi)) * final_integral\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    test_cases = [0.0, 1e-8, 0.5, 1.0, -1.3, 2.0, 5.0]\n    n_nodes = 16\n    abs_tol = 1e-12\n    rel_tol = 1e-12\n\n    results = []\n    for x in test_cases:\n        # Compute the erf approximation using the implemented quadrature\n        erf_hat = compute_erf_quadrature(x, n_nodes, abs_tol, rel_tol)\n        \n        # Get reference values from standard libraries\n        ref_math = math.erf(x)\n        ref_scipy = erf_scipy(x)\n        \n        # Calculate the maximum absolute error against the two references\n        error_math = abs(erf_hat - ref_math)\n        error_scipy = abs(erf_hat - ref_scipy)\n        e_max = max(error_math, error_scipy)\n        \n        results.append([erf_hat, ref_math, ref_scipy, e_max])\n\n    # Format the output exactly as specified in the problem statement\n    # This creates a string representation of a list of lists of floats.\n    output_str_list = []\n    for r in results:\n        # Manually format each inner list to ensure no extra whitespace\n        inner_str = f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\"\n        output_str_list.append(inner_str)\n    \n    final_output = f\"[{','.join(output_str_list)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2397742"}]}