{"hands_on_practices": [{"introduction": "The journey into a specific Lie algebra begins with understanding its elements. The Lie algebra $\\mathfrak{su}(2)$, intimately connected to the physics of quantum spin and the geometry of the Lie group $SU(2)$, is defined as the space of $2 \\times 2$ skew-hermitian, traceless matrices. This exercise [@problem_id:1678762] provides fundamental practice in translating these abstract properties into a concrete basis, illustrating how the algebra's vector space structure is derived directly from the properties of its corresponding group.", "problem": "In quantum mechanics, the state of a spin-1/2 particle is described by a vector in a two-dimensional complex Hilbert space. The transformations on these states that preserve physical properties are represented by the Special Unitary group in two dimensions, $SU(2)$. The \"infinitesimal generators\" of these transformations form the Lie algebra of the group, denoted $\\mathfrak{su}(2)$.\n\nThe Lie algebra $\\mathfrak{su}(2)$ is defined as the set of all $2 \\times 2$ complex matrices $X$ that satisfy two specific conditions:\n1.  $X$ is skew-hermitian, meaning its conjugate transpose $X^\\dagger$ is equal to its negative, i.e., $X^\\dagger = -X$.\n2.  $X$ is traceless, meaning the sum of its diagonal elements is zero, i.e., $\\text{tr}(X) = 0$.\n\nThis set of matrices forms a vector space over the real numbers. Which of the following sets of matrices constitutes a basis for the real vector space $\\mathfrak{su}(2)$?\n\nA. $\\left\\{ \\begin{pmatrix} 0 & i \\\\ i & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix} \\right\\}$\n\nB. $\\left\\{ \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\right\\}$\n\nC. $\\left\\{ \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix} \\right\\}$\n\nD. $\\left\\{ \\begin{pmatrix} 0 & i \\\\ i & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & 1+i \\\\ -1+i & 0 \\end{pmatrix} \\right\\}$\n\nE. $\\left\\{ \\begin{pmatrix} i & 0 \\\\ 0 & i \\end{pmatrix}, \\begin{pmatrix} 0 & i \\\\ -i & 0 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\right\\}$", "solution": "To solve this problem, we first determine the general form of a matrix belonging to the Lie algebra $\\mathfrak{su}(2)$ and then check which of the given options provides a valid basis for the space of such matrices. A basis must consist of a set of linearly independent vectors (in this case, matrices) that span the entire vector space.\n\nLet's consider an arbitrary $2 \\times 2$ complex matrix $X$:\n$$\nX = \\begin{pmatrix} z_1 & z_2 \\\\ z_3 & z_4 \\end{pmatrix}\n$$\nwhere $z_1, z_2, z_3, z_4$ are complex numbers.\n\nFirst, we apply the traceless condition: $\\text{tr}(X) = 0$.\n$$\nz_1 + z_4 = 0 \\implies z_4 = -z_1\n$$\nSo, the matrix must have the form:\n$$\nX = \\begin{pmatrix} z_1 & z_2 \\\\ z_3 & -z_1 \\end{pmatrix}\n$$\n\nNext, we apply the skew-hermitian condition: $X^\\dagger = -X$. The conjugate transpose $X^\\dagger$ is:\n$$\nX^\\dagger = \\begin{pmatrix} \\overline{z_1} & \\overline{z_3} \\\\ \\overline{z_2} & \\overline{z_4} \\end{pmatrix} = \\begin{pmatrix} \\overline{z_1} & \\overline{z_3} \\\\ \\overline{z_2} & -\\overline{z_1} \\end{pmatrix}\n$$\nAnd $-X$ is:\n$$\n-X = \\begin{pmatrix} -z_1 & -z_2 \\\\ -z_3 & z_1 \\end{pmatrix}\n$$\nEquating the two matrices, $X^\\dagger = -X$, gives us a set of conditions on the elements:\n1. $\\overline{z_1} = -z_1$\n2. $\\overline{z_3} = -z_2$\n\nFrom condition (1), if we write $z_1 = a + ib$ where $a, b \\in \\mathbb{R}$, then $\\overline{z_1} = a - ib$. The condition becomes $a - ib = -(a+ib) = -a - ib$, which implies $2a = 0$, so $a=0$. This means $z_1$ must be purely imaginary. Let's write $z_1 = ic$ for some real number $c$.\n\nFrom condition (2), let's write $z_2 = x + iy$ and $z_3 = u + iv$ for real numbers $x, y, u, v$. The condition $\\overline{z_3} = -z_2$ becomes $u - iv = -(x+iy) = -x - iy$. Equating real and imaginary parts, we get $u = -x$ and $-v = -y \\implies v = y$.\nSo, $z_3 = -x + iy$.\nWe see that $z_3 = -(x-iy) = -\\overline{z_2}$. This is just a restatement of the condition.\n\nSo, the elements are constrained as:\n$z_1 = ic$\n$z_2 = x + iy$\n$z_3 = -x + iy$\n$z_4 = -z_1 = -ic$\nwhere $x, y, c$ are arbitrary real numbers.\n\nSubstituting these back into the matrix $X$:\n$$\nX = \\begin{pmatrix} ic & x+iy \\\\ -x+iy & -ic \\end{pmatrix}\n$$\nWe can decompose this general form into a linear combination over the real numbers $x, y, c$:\n$$\nX = x \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix} + y \\begin{pmatrix} 0 & i \\\\ i & 0 \\end{pmatrix} + c \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix}\n$$\nThis shows that any matrix in $\\mathfrak{su}(2)$ is a real linear combination of the three matrices:\n$$\nB_1 = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\quad B_2 = \\begin{pmatrix} 0 & i \\\\ i & 0 \\end{pmatrix}, \\quad B_3 = \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix}\n$$\nThese three matrices are linearly independent over the real numbers. Therefore, the dimension of the real vector space $\\mathfrak{su}(2)$ is 3, and the set $\\{B_1, B_2, B_3\\}$ forms a basis.\n\nNow we evaluate the given options:\n\nA. The set is $\\left\\{ \\begin{pmatrix} 0 & i \\\\ i & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix} \\right\\}$. This is exactly the set $\\{B_2, B_1, B_3\\}$ we derived. Since the order of elements in a set does not matter, this is a valid basis for $\\mathfrak{su}(2)$.\n\nB. The set is $\\left\\{ M_1, M_2, M_3 \\right\\} = \\left\\{ \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\right\\}$. These are the Pauli matrices. Let's check $M_1$. $M_1^\\dagger = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} = M_1$. Since $M_1^\\dagger \\neq -M_1$, it is not skew-hermitian. Thus, this set is not a basis for $\\mathfrak{su}(2)$. (These matrices form a basis for the space of $2 \\times 2$ traceless *hermitian* matrices).\n\nC. The first matrix is $M_1 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$. Its trace is $\\text{tr}(M_1) = 1+1=2 \\neq 0$. It is not in $\\mathfrak{su}(2)$. Thus, this set cannot be a basis.\n\nD. The set is $\\left\\{ M_1, M_2, M_3 \\right\\} = \\left\\{ \\begin{pmatrix} 0 & i \\\\ i & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\begin{pmatrix} 0 & 1+i \\\\ -1+i & 0 \\end{pmatrix} \\right\\}$. We can see that $M_3 = M_2 + M_1$. Since one matrix is a linear combination of the others, the set is linearly dependent over the real numbers and cannot form a basis.\n\nE. The first matrix is $M_1 = \\begin{pmatrix} i & 0 \\\\ 0 & i \\end{pmatrix}$. Its trace is $\\text{tr}(M_1) = i+i=2i \\neq 0$. It is not in $\\mathfrak{su}(2)$. Thus, this set cannot be a basis.\n\nBased on our analysis, only the set in Option A satisfies all the properties required for a basis of $\\mathfrak{su}(2)$.", "answer": "$$\\boxed{A}$$", "id": "1678762"}, {"introduction": "A Lie algebra is more than just a vector space; its defining feature is the non-associative multiplication given by the Lie bracket. This entire algebraic structure is encoded in how basis elements commute, a relationship quantified by coefficients known as structure constants. This practice [@problem_id:1678779] focuses on this core concept by having you compute a Lie bracket for the fundamental Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, making the abstract notion of an algebraic structure tangible through direct matrix calculation.", "problem": "The Special Linear Group in two dimensions, denoted $SL(2, \\mathbb{R})$, is the set of all $2 \\times 2$ real matrices with a determinant of 1. Its associated Lie algebra, denoted $\\mathfrak{sl}(2, \\mathbb{R})$, is the vector space of all $2 \\times 2$ real matrices with a trace of zero. The Lie bracket operation on this algebra is defined by the commutator: $[A, B] = AB - BA$ for any two matrices $A, B \\in \\mathfrak{sl}(2, \\mathbb{R})$.\n\nConsider the following set of matrices, which forms a basis for $\\mathfrak{sl}(2, \\mathbb{R})$:\n$$A_1 = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}, \\quad A_2 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad A_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$$\nThe Lie bracket of any two basis elements is itself an element of the algebra and can therefore be expressed as a linear combination of the basis elements. For the specific bracket $[A_1, A_2]$, we can write:\n$$[A_1, A_2] = c_{12}^1 A_1 + c_{12}^2 A_2 + c_{12}^3 A_3$$\nwhere the coefficients $c_{12}^k$ are real numbers known as structure constants.\n\nDetermine the values of the coefficients in the triplet $(c_{12}^1, c_{12}^2, c_{12}^3)$. Your final answer should be presented as a row matrix with three entries.", "solution": "We use the Lie bracket definition $[A_{1},A_{2}] = A_{1}A_{2} - A_{2}A_{1}$ and compute each product explicitly.\n\nFirst, compute $A_{1}A_{2}$:\n$$\nA_{1}A_{2} =\n\\begin{pmatrix}\n0 & 1 \\\\\n-1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 1 \\\\\n1 & 0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0\\cdot 0 + 1\\cdot 1 & 0\\cdot 1 + 1\\cdot 0 \\\\\n-1\\cdot 0 + 0\\cdot 1 & -1\\cdot 1 + 0\\cdot 0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}\n= A_{3}.\n$$\n\nNext, compute $A_{2}A_{1}$:\n$$\nA_{2}A_{1} =\n\\begin{pmatrix}\n0 & 1 \\\\\n1 & 0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & 1 \\\\\n-1 & 0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0\\cdot 0 + 1\\cdot (-1) & 0\\cdot 1 + 1\\cdot 0 \\\\\n1\\cdot 0 + 0\\cdot (-1) & 1\\cdot 1 + 0\\cdot 0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-1 & 0 \\\\\n0 & 1\n\\end{pmatrix}\n= -A_{3}.\n$$\n\nTherefore,\n$$\n[A_{1},A_{2}] = A_{1}A_{2} - A_{2}A_{1} = A_{3} - (-A_{3}) = 2A_{3}.\n$$\n\nExpressing $[A_{1},A_{2}]$ as a linear combination of the basis $\\{A_{1},A_{2},A_{3}\\}$, we have\n$$\n[A_{1},A_{2}] = 0\\cdot A_{1} + 0\\cdot A_{2} + 2\\cdot A_{3}.\n$$\nThus the structure constants are $(c_{12}^{1}, c_{12}^{2}, c_{12}^{3}) = (0, 0, 2)$.", "answer": "$$\\boxed{\\begin{pmatrix} 0 & 0 & 2 \\end{pmatrix}}$$", "id": "1678779"}, {"introduction": "To classify Lie algebras and probe their structure, we utilize powerful invariants derived from the algebra itself. The Killing form, defined as $B(X, Y) = \\text{tr}(\\text{ad}(X) \\circ \\text{ad}(Y))$, is a canonical symmetric bilinear form built from the adjoint representation of the algebra, where $\\text{ad}(X)(Z) = [X, Z]$. This capstone exercise [@problem_id:1054721] offers a hands-on computation of this central object for $\\mathfrak{sl}(2, \\mathbb{R})$, a process that reveals deep structural properties like semisimplicity.", "problem": "Consider the Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, which is the set of all $2 \\times 2$ real matrices with trace zero. The Lie bracket operation is given by the standard matrix commutator $[A, B] = AB - BA$. A standard basis for this real vector space, which we will denote as $\\{X_1, X_2, X_3\\}$, is given by the ordered set of matrices:\n$$\nX_1 = H = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}, \\quad X_2 = E = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad X_3 = F = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}\n$$\nFor any finite-dimensional Lie algebra $\\mathfrak{g}$, the adjoint representation, $\\text{ad}$, is a map from $\\mathfrak{g}$ to the Lie algebra of linear transformations on $\\mathfrak{g}$, denoted $\\mathfrak{gl}(\\mathfrak{g})$. It is defined by $\\text{ad}(X)(Y) = [X,Y]$ for all $X,Y \\in \\mathfrak{g}$.\n\nThe Killing form is a symmetric bilinear form on $\\mathfrak{g}$ defined as $B(X,Y) = \\text{tr}(\\text{ad}(X) \\circ \\text{ad}(Y))$, where $\\text{tr}$ denotes the trace of the linear transformation.\n\nLet $\\kappa$ be the matrix representation of the Killing form with respect to the ordered basis $\\{H, E, F\\}$. The elements of this matrix are given by $\\kappa_{ij} = B(X_i, X_j)$.\n\nCalculate the determinant of the Killing form matrix, $\\det(\\kappa)$.", "solution": "1. Definitions:\n$$\\ad(X)(Y)=[X,Y],\\qquad B(X,Y)=\\tr\\bigl(\\ad(X)\\circ\\ad(Y)\\bigr).$$\n\n2. Lie brackets (structure constants):\n$$[H,E]=2E,\\quad [H,F]=-2F,\\quad [E,F]=H,\\quad [F,E]=-H.$$\n\n3. Matrices of $\\ad(H),\\ad(E),\\ad(F)$ in basis $(H,E,F)$:\n$$\\ad(H)=\\begin{pmatrix}\n0&0&0\\\\\n0&2&0\\\\\n0&0&-2\n\\end{pmatrix},\\ \n\\ad(E)=\\begin{pmatrix}\n0&0&1\\\\\n-2&0&0\\\\\n0&0&0\n\\end{pmatrix},\\ \n\\ad(F)=\\begin{pmatrix}\n0&-1&0\\\\\n0&0&0\\\\\n2&0&0\n\\end{pmatrix}.$$\n\n4. Compute Killing form entries:\n$$B(H,H)=\\tr(\\ad(H)^2)=0^2+2^2+(-2)^2=8,$$\n$$B(H,E)=\\tr(\\ad(H)\\ad(E))=0,\\quad B(H,F)=0,$$\n$$B(E,E)=\\tr(\\ad(E)^2)=0,\\quad B(F,F)=0,$$\n$$B(E,F)=\\tr(\\ad(E)\\ad(F))\n=\\tr\\!\\begin{pmatrix}2&0&0\\\\0&2&0\\\\0&0&0\\end{pmatrix}=4,$$\n$$B(F,E)=4.$$\n\n5. Killing form matrix and its determinant:\n$$\\kappa=\\begin{pmatrix}\n8&0&0\\\\\n0&0&4\\\\\n0&4&0\n\\end{pmatrix},\\quad\n\\det(\\kappa)=8\\,(0\\cdot0-4\\cdot4)=-128.$$", "answer": "$$\\boxed{-128}$$", "id": "1054721"}]}