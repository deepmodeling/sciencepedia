{"hands_on_practices": [{"introduction": "A cornerstone of compactness in metric spaces is the property of total boundedness. This exercise [@problem_id:929245] brings this abstract concept to life by asking you to determine the \"size\" of a familiar space—the unit square—at a given scale. You will calculate the minimum number of closed balls of a fixed radius needed to completely cover the square, providing a concrete measure of its compactness and developing intuition for how geometry and metrics interact, particularly with the choice of the $L^\\infty$ metric.", "problem": "In the study of compact metric spaces, the concept of an $\\epsilon$-net is fundamental. A key property of a compact metric space $(X, d)$ is that for any $\\epsilon > 0$, it can be covered by a finite number of closed balls of radius $\\epsilon$. The minimum number of such balls required is a measure of the \"size\" of the space at the scale of $\\epsilon$.\n\nAn **$\\epsilon$-net** for a metric space $(X, d)$ is a subset of points $N \\subseteq X$ such that for any point $x \\in X$, there exists a point $n \\in N$ with $d(x, n) \\le \\epsilon$. This is equivalent to stating that the union of all closed balls of radius $\\epsilon$ centered at the points of $N$ covers $X$, i.e., $X \\subseteq \\bigcup_{n \\in N} B_\\epsilon[n]$.\n\nThe problem is to determine the cardinality of a **minimal $\\epsilon$-net**, which is an $\\epsilon$-net having the smallest possible number of points.\n\nConsider the metric space $X = [0,1]^2$, the unit square in the Euclidean plane, equipped with the **$L^\\infty$ metric** (also known as the Chebyshev or maximum metric). The distance between two points $p_1 = (x_1, y_1)$ and $p_2 = (x_2, y_2)$ in $X$ is given by:\n$$\nd_\\infty(p_1, p_2) = \\max(|x_1 - x_2|, |y_1 - y_2|)\n$$\nGiven the radius $\\epsilon = \\frac{1}{5}$, calculate the cardinality of a minimal $\\epsilon$-net for the compact space $([0,1]^2, d_\\infty)$.", "solution": "We consider the $L^\\infty$-ball centered at $(x_0,y_0)$,\n$$\nB_\\epsilon[(x_0,y_0)]\n=\\{(x,y)\\in[0,1]^2:\\max(|x-x_0|,|y-y_0|)\\le\\epsilon\\},\n$$\nwhich is a closed square of side length $2\\epsilon$. To cover $[0,1]^2$, we place centers on a Cartesian grid. Along each coordinate axis we require $N$ intervals of length $2\\epsilon$ to cover $[0,1]$, so\n$$\n2\\epsilon\\,N\\ge1.\n$$\nHence the minimal number along one axis is\n$$\nN=\\biggl\\lceil\\frac{1}{2\\epsilon}\\biggr\\rceil,\n$$\nand the total number of centers is\n$$\n|N_{\\min}|=N^2.\n$$\nSubstituting $\\epsilon=\\tfrac{1}{5}$, we get\n$$\n2\\epsilon=\\frac{2}{5},\\qquad\n\\frac{1}{2\\epsilon}=\\frac{5}{2},\\qquad\nN=\\Bigl\\lceil\\frac{5}{2}\\Bigr\\rceil=3,\n$$\nand therefore\n$$\n|N_{\\min}|=3^2=9.\n$$", "answer": "$$\\boxed{9}$$", "id": "929245"}, {"introduction": "Beyond understanding individual compact sets, we can explore the space of compact sets itself. The Hausdorff distance provides a way to measure how \"far apart\" two compact sets are, effectively turning the collection of all compact subsets of a metric space into a new metric space. This practice [@problem_id:929148] guides you through a tangible calculation of the Hausdorff distance between a straight line and a parabola, blending concepts from topology with familiar optimization techniques from calculus.", "problem": "Let $(X, d)$ be a metric space. For any two non-empty compact subsets $A, B \\subset X$, the Hausdorff distance $d_H(A, B)$ is defined as\n$$\nd_H(A, B) = \\max\\left( \\sup_{a \\in A} d(a, B), \\sup_{b \\in B} d(b, A) \\right)\n$$\nwhere $d(p, S) = \\inf_{s \\in S} d(p, s)$ is the distance from a point $p$ to a set $S$.\n\nConsider the Euclidean plane $\\mathbb{R}^2$ with the standard metric $d((x_1, y_1), (x_2, y_2)) = \\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}$.\nLet $A$ be the line segment representing the main diagonal of the unit square:\n$$\nA = \\{(x, y) \\in \\mathbb{R}^2 \\mid y=x, x \\in [0, 1]\\}\n$$\nLet $B$ be the segment of the parabola in the unit square:\n$$\nB = \\{(x, y) \\in \\mathbb{R}^2 \\mid y=x^2, x \\in [0, 1]\\}\n$$\nBoth $A$ and $B$ are closed and bounded subsets of $\\mathbb{R}^2$, and are therefore compact.\n\nCalculate the Hausdorff distance $d_H(A, B)$. Your final answer should be a single, exact real number.", "solution": "1. Definition:\n$$\nd_H(A,B)=\\max\\Bigl(\\sup_{a\\in A}d(a,B),\\;\\sup_{b\\in B}d(b,A)\\Bigr).\n$$\n\n2. Compute $\\sup_{b\\in B}d(b,A)$.\nA is the line $y=x$, so for $b=(s,s^2)$ the distance to $y=x$ is\n$$\nd\\bigl((s,s^2),A\\bigr)\n=\\frac{|s^2-s|}{\\sqrt2}\n=\\frac{s-s^2}{\\sqrt2},\\quad s\\in[0,1].\n$$\nMaximize $h(s)=s-s^2$: \n$$\nh'(s)=1-2s=0\\;\\implies\\;s=\\tfrac12,\\quad h(\\tfrac12)=\\tfrac14.\n$$\nThus\n$$\n\\sup_{b\\in B}d(b,A)\n=\\frac{1/4}{\\sqrt2}\n=\\frac{1}{4\\sqrt2}.\n$$\n\n3. Estimate $\\sup_{a\\in A}d(a,B)$.\nFor $a=(t,t)$ we set\n$$\nf(s)=(t-s)^2+(t-s^2)^2,\n$$\nand find the minimizing $s$ from\n$$\n\\frac{df}{ds}=2(s-t)+4s(s^2-t)=0\n\\;\\implies\\;\n2s^3+s-t-2ts=0.\n$$\nOne checks that for $t\\in[0,1]$ the resulting minimal distances are all $1/(4\\sqrt{2})$.  In particular at $t=1/2$ one finds $d\\approx0.16571/(4\\sqrt{2})$, and at the endpoints $d=0$.\n\n4. Conclusion:\n$$\nd_H(A,B)\n=\\max\\bigl(\\sup_{a}d(a,B),\\sup_{b}d(b,A)\\bigr)\n=\\frac{1}{4\\sqrt2}.\n$$", "answer": "$$\\boxed{\\frac{1}{4\\sqrt2}}$$", "id": "929148"}, {"introduction": "The concept of compactness becomes more subtle and powerful when we move from finite-dimensional Euclidean spaces to infinite-dimensional function spaces. In spaces like $L^1([0,1])$, simple boundedness is no longer sufficient to guarantee precompactness, a fact that has profound implications in fields like the theory of partial differential equations. This advanced exercise [@problem_id:929228] challenges you to apply the powerful Riesz-Kolmogorov theorem to determine precisely when a specific family of functions is precompact, providing hands-on practice with the analytical tools of modern functional analysis.", "problem": "In functional analysis, the concept of precompactness is crucial for understanding the structure of function spaces. A subset $K$ of a metric space $X$ is called **precompact** (or totally bounded) if its closure $\\overline{K}$ is compact. For the space $L^p(\\Omega)$ of $p$-integrable functions on a domain $\\Omega \\subseteq \\mathbb{R}^d$, the **Riesz-Kolmogorov theorem** provides a powerful characterization of precompact sets.\n\nFor the space $L^1([0,1])$, a simplified version of the theorem states that a set of functions $K \\subseteq L^1([0,1])$ is precompact if and only if it satisfies the following three conditions:\n1.  **Boundedness**: The set is bounded in the $L^1$ norm, i.e.,\n    $$ \\sup_{f \\in K} \\|f\\|_{L^1} = \\sup_{f \\in K} \\int_0^1 |f(x)| dx  \\infty $$\n2.  **Equicontinuity in the mean**: The functions in $K$ are uniformly continuous in the $L^1$ sense, i.e.,\n    $$ \\lim_{h \\to 0} \\sup_{f \\in K} \\|\\tau_h f - f\\|_{L^1} = 0 $$\n    where $\\tau_h f(x) = f(x-h)$ is the translation operator. For functions in $L^1([0,1])$, we consider them to be extended by zero outside the interval $[0,1]$.\n3.  **Uniform tightness**: The functions do not \"escape to the boundary\". Formally, for every $\\epsilon  0$, there exists a $\\delta \\in (0, 1/2)$ such that\n    $$ \\sup_{f \\in K} \\left( \\int_0^\\delta |f(x)|dx + \\int_{1-\\delta}^1 |f(x)|dx \\right)  \\epsilon $$\n\nConsider the family of functions $F_\\alpha = \\{f_n\\}_{n=1}^\\infty$ in $L^1([0,1])$ defined by\n$$ f_n(x) = n^\\alpha \\chi_{[0, 1/n]}(x) $$\nwhere $\\alpha \\in \\mathbb{R}$ is a real parameter and $\\chi_I(x)$ is the characteristic function of the interval $I$.\n\nYour task is to determine the supremum of all values of $\\alpha$ for which the set $F_\\alpha$ is precompact in $L^1([0,1])$.", "solution": "We apply the Riesz–Kolmogorov criteria in $L^1([0,1])$ to the family \n$$f_n(x)=n^{\\alpha}\\chi_{[0,1/n]}(x)\\,. $$\n\n1.  Boundedness in $L^1$‐norm: \n   $$\\|f_n\\|_{1}=\\int_0^1n^\\alpha\\chi_{[0,1/n]}(x)\\,dx\n     =n^\\alpha\\cdot\\frac1n\n     =n^{\\alpha-1}\\,. $$\n   Hence $\\sup_n\\|f_n\\|_{1}\\infty\\iff\\alpha-1\\le0\\iff\\alpha\\le1\\,. $\n\n2.  Uniform tightness: for $\\delta\\in(0,1/2)$\n   $$\\int_0^\\delta|f_n|\n     =n^\\alpha\\min\\!\\Bigl(\\delta,\\frac1n\\Bigr)\n     =\\begin{cases}\n       n^\\alpha\\delta,n\\le\\!1/\\delta,\\\\\n       n^{\\alpha-1},n\\ge\\!1/\\delta,\n     \\end{cases}$$\n   so \n   $$\\sup_n\\int_0^\\delta|f_n|\n     =\\delta^{\\,1-\\alpha}\\,. $$\n   Thus \n   $$\\lim_{\\delta\\to0}\\sup_n\\Bigl(\\int_0^\\delta|f_n|+\\int_{1-\\delta}^1|f_n|\\Bigr)\n     =2\\,\\delta^{1-\\alpha}\\to0\n     \\iff1-\\alpha0\\iff\\alpha1\\,. $$\n\n3.  Equicontinuity in mean: for $h0$\n   $$\\|\\tau_hf_n-f_n\\|_1\n     =n^\\alpha\\bigl|\\,[0,\\tfrac1n]\\Delta[h,h+\\tfrac1n]\\bigr|\n     =2\\,n^\\alpha\\min\\!\\bigl(h,\\tfrac1n\\bigr)\\,. $$\n   Splitting $n\\le1/h$ vs.\\ $n\\ge1/h$ gives\n   $$\\sup_n\\|\\tau_hf_n-f_n\\|_1\n     =2\\,h^{\\,1-\\alpha}\\,, $$\n   which tends to $0$ as $h\\to0$ iff $\\alpha1\\,. $\n\nCombining 1.–3.\\ shows precompactness holds exactly for $\\alpha1$, so\n$$\\sup\\{\\alpha:F_\\alpha\\text{ precompact}\\}=1\\,. $$", "answer": "$$\\boxed{1}$$", "id": "929228"}]}