{"hands_on_practices": [{"introduction": "A solid understanding of complete metric spaces begins with a precise grasp of the Cauchy criterion. A common misconception is to believe that if the distance between consecutive terms of a sequence, $d(x_n, x_{n+1})$, approaches zero, the sequence must be Cauchy. This exercise directly confronts this misunderstanding, asking you to identify a counterexample within the real numbers. Mastering this distinction is a crucial first step before analyzing the more complex structures of complete function spaces [@problem_id:1288503].", "problem": "In the study of metric spaces, we are interested in criteria for determining when a sequence converges. A fundamental concept related to convergence is that of a Cauchy sequence. Consider the following proposition regarding sequences in a metric space:\n\n**Proposition P:** For any sequence $\\{x_n\\}_{n=1}^{\\infty}$ in a metric space $(X, d)$, if the distance between consecutive terms approaches zero, i.e., $\\lim_{n \\to \\infty} d(x_n, x_{n+1}) = 0$, then the sequence $\\{x_n\\}$ must be a Cauchy sequence.\n\nYour task is to determine whether Proposition P is true or false. If it is false, you must identify a counterexample. Which of the following sequences, considered within the metric space of real numbers $(\\mathbb{R}, d)$ with the standard metric $d(x, y) = |x - y|$, serves as a counterexample to Proposition P?\n\nA. $x_n = \\frac{1}{n^2}$\n\nB. $x_n = 5 - 3^{-n}$\n\nC. $x_n = \\sum_{k=1}^{n} \\frac{1}{k}$\n\nD. $x_n = \\frac{2n+1}{n+2}$\n\nE. $x_n = \\sum_{k=1}^{n} \\frac{1}{k!}$", "solution": "We recall the Cauchy criterion in a metric space: a sequence $\\{x_{n}\\}$ is Cauchy if for every $\\varepsilon > 0$ there exists $N \\in \\mathbb{N}$ such that for all $m,n \\geq N$ one has $d(x_m, x_n)  \\varepsilon$. Proposition P claims that $\\lim_{n \\to \\infty} d(x_{n},x_{n+1})=0$ implies $\\{x_{n}\\}$ is Cauchy. This implication is false in $(\\mathbb{R},|\\cdot|)$, as shown by the harmonic partial sums.\n\nConsider option C: $x_{n}=\\sum_{k=1}^{n}\\frac{1}{k}$. Then the distance between consecutive terms is\n$$\n|x_{n+1}-x_{n}|=\\left|\\sum_{k=1}^{n+1}\\frac{1}{k}-\\sum_{k=1}^{n}\\frac{1}{k}\\right|=\\frac{1}{n+1} \\to 0 \\quad \\text{as } n \\to \\infty,\n$$\nso the hypothesis of Proposition P holds. However, $\\{x_{n}\\}$ is not Cauchy. To see this, fix $\\varepsilon=\\frac{1}{2}$. For any $N \\in \\mathbb{N}$, take $n \\geq N$ and $m=2n$. Then\n$$\n|x_m - x_n| = \\sum_{k=n+1}^{2n}\\frac{1}{k} \\geq \\sum_{k=n+1}^{2n}\\frac{1}{2n} = \\frac{n}{2n} = \\frac{1}{2} = \\varepsilon,\n$$\nso the Cauchy condition fails. Therefore, Proposition P is false, and option C provides a counterexample in $(\\mathbb{R},|\\cdot|)$.\n\nFor completeness, the other options are not counterexamples because each sequence converges in $\\mathbb{R}$, and in any metric space every convergent sequence is Cauchy:\n- A: $x_{n}=\\frac{1}{n^{2}} \\to 0$.\n- B: $x_{n}=5-3^{-n} \\to 5$.\n- D: $x_{n}=\\frac{2n+1}{n+2} \\to 2$.\n- E: $x_{n}=\\sum_{k=1}^{n}\\frac{1}{k!} \\to \\exp(1)-1$.\nThus only C serves as a counterexample.", "answer": "$$\\boxed{C}$$", "id": "1288503"}, {"introduction": "In many fields of science and engineering, complex functions are approximated by simpler ones, like polynomials. This raises a critical theoretical question: does the space of all polynomials, equipped with a natural metric for uniform convergence, contain all the limits of its own Cauchy sequences? This practice invites you to explore the completeness of the space of polynomials as a subspace of continuous functions on $[0, 1]$. The result is a foundational insight into why spaces like $C[0,1]$ are preferred over polynomials in many areas of analysis [@problem_id:2291794].", "problem": "In many areas of scientific computing and approximation theory, complex continuous functions are approximated by polynomials. This practice relies on the properties of the space of polynomials. Let $C[0, 1]$ denote the set of all real-valued continuous functions defined on the closed interval $[0, 1]$. This set forms a metric space when equipped with the supremum metric, defined as $d_\\infty(f, g) = \\sup_{x \\in [0, 1]} |f(x) - g(x)|$ for any two functions $f, g \\in C[0, 1]$.\n\nNow, consider the subset $P \\subset C[0, 1]$ that consists of all polynomial functions. The set $P$ with the inherited metric $d_\\infty$ forms a metric space, which we denote as $(P, d_\\infty)$.\n\nWhich of the following statements about the metric space $(P, d_\\infty)$ is correct?\n\nA. The space $(P, d_\\infty)$ is a complete metric space.\n\nB. There exists at least one Cauchy sequence in $(P, d_\\infty)$ whose limit is a continuous function on $[0, 1]$ but is not a polynomial.\n\nC. Every Cauchy sequence of functions in $(P, d_\\infty)$ converges to a limit that is also a polynomial.\n\nD. The set $P$ is a closed subset of the metric space $(C[0, 1], d_\\infty)$.", "solution": "To determine which statement is correct, we need to investigate the completeness of the metric space $(P, d_\\infty)$. A metric space is complete if and only if every Cauchy sequence in that space converges to a limit that is also within the space.\n\nLet's test this definition for the space of polynomials $(P, d_\\infty)$. To show that $(P, d_\\infty)$ is *not* complete, we need to construct a counterexample: a sequence of polynomials $\\{p_n\\}_{n=1}^{\\infty}$ where each $p_n \\in P$, such that $\\{p_n\\}$ is a Cauchy sequence with respect to the metric $d_\\infty$, but its limit is a function $f \\in C[0, 1]$ that is not a polynomial (i.e., $f \\notin P$).\n\nA classic way to construct such a sequence is by using the Taylor series expansion of a non-polynomial analytic function, for example, the exponential function $f(x) = \\exp(x)$. The Taylor series for $\\exp(x)$ around $x=0$ is given by $\\sum_{k=0}^{\\infty} \\frac{x^k}{k!}$.\n\nLet us define a sequence of polynomials $\\{p_n\\}_{n=1}^{\\infty}$ by the partial sums of this Taylor series:\n$$p_n(x) = \\sum_{k=0}^{n} \\frac{x^k}{k!}$$\nEach $p_n(x)$ is a polynomial of degree $n$, so $p_n \\in P$ for all $n \\in \\mathbb{N}$.\n\nFirst, we must show that this sequence $\\{p_n\\}$ is a Cauchy sequence in $(P, d_\\infty)$.\nLet $m, n \\in \\mathbb{N}$ with $m > n$. The distance between $p_m$ and $p_n$ is:\n$$d_\\infty(p_m, p_n) = \\sup_{x \\in [0, 1]} |p_m(x) - p_n(x)|$$\n$$d_\\infty(p_m, p_n) = \\sup_{x \\in [0, 1]} \\left| \\sum_{k=0}^{m} \\frac{x^k}{k!} - \\sum_{k=0}^{n} \\frac{x^k}{k!} \\right| = \\sup_{x \\in [0, 1]} \\left| \\sum_{k=n+1}^{m} \\frac{x^k}{k!} \\right|$$\nFor $x \\in [0, 1]$, all terms in the sum are non-negative, so we can remove the absolute value signs. The function $g(x) = \\sum_{k=n+1}^{m} \\frac{x^k}{k!}$ is an increasing function of $x$ on $[0, 1]$, so its supremum is at $x=1$.\n$$d_\\infty(p_m, p_n) = \\sum_{k=n+1}^{m} \\frac{1^k}{k!} = \\sum_{k=n+1}^{m} \\frac{1}{k!}$$\nThe infinite series $\\sum_{k=0}^{\\infty} \\frac{1}{k!}$ is known to converge (to the value $e$). A fundamental property of convergent series is that the sequence of their partial sums is a Cauchy sequence. Therefore, for any $\\epsilon > 0$, there exists an integer $N$ such that for all $m > n > N$, the tail of the series is bounded: $\\sum_{k=n+1}^{m} \\frac{1}{k!}  \\epsilon$.\nThis implies that for any $\\epsilon > 0$, there exists an $N$ such that for all $m > n > N$, $d_\\infty(p_m, p_n)  \\epsilon$. Thus, $\\{p_n\\}$ is a Cauchy sequence in $(P, d_\\infty)$.\n\nNext, we identify the limit of this sequence. It is a well-known result from real analysis that the Taylor series for $\\exp(x)$ converges uniformly to $\\exp(x)$ on any bounded interval. Uniform convergence on $[0,1]$ is equivalent to convergence in the supremum metric $d_\\infty$.\nSo, the sequence of polynomials $\\{p_n\\}$ converges to the function $f(x) = \\exp(x)$.\n$$\\lim_{n\\to\\infty} d_\\infty(p_n, f) = \\lim_{n\\to\\infty} \\sup_{x \\in [0, 1]} \\left| \\sum_{k=0}^{n} \\frac{x^k}{k!} - \\exp(x) \\right| = 0$$\nThe limit function $f(x) = \\exp(x)$ is continuous on $[0, 1]$, so $f \\in C[0, 1]$. However, $\\exp(x)$ is not a polynomial function (for instance, its derivative is never zero, whereas the higher-order derivatives of any non-constant polynomial must eventually be zero). Therefore, the limit of our Cauchy sequence, $f(x) = \\exp(x)$, is not in the set $P$.\n\nWe have found a Cauchy sequence $\\{p_n\\}$ in $(P, d_\\infty)$ that converges to a limit $f \\notin P$. This demonstrates that the space $(P, d_\\infty)$ is not complete.\n\nNow let's evaluate the given options:\nA. The space $(P, d_\\infty)$ is a complete metric space. This is false, as we have just shown.\nB. There exists at least one Cauchy sequence in $(P, d_\\infty)$ whose limit is a continuous function on $[0, 1]$ but is not a polynomial. This is true. Our sequence $\\{p_n\\}$ is a prime example.\nC. Every Cauchy sequence of functions in $(P, d_\\infty)$ converges to a limit that is also a polynomial. This is the definition of completeness for the space $(P, d_\\infty)$. Since the space is not complete, this statement is false.\nD. The set $P$ is a closed subset of the metric space $(C[0, 1], d_\\infty)$. It is a theorem that a subspace of a complete metric space is complete if and only if it is closed. The space $(C[0, 1], d_\\infty)$ is known to be a complete metric space. Since its subspace $(P, d_\\infty)$ is not complete, the set $P$ cannot be a closed subset of $C[0, 1]$. In fact, our counterexample shows that $P$ is not closed, as it does not contain all of its limit points (the function $\\exp(x)$ is a limit point of $P$ but is not in $P$). Thus, this statement is false.\n\nThe only correct statement is B.", "answer": "$$\\boxed{B}$$", "id": "2291794"}, {"introduction": "Having established that some seemingly well-behaved function spaces are not complete, we turn to a constructive question: how can we define a metric to ensure completeness? This practice investigates the space of continuously differentiable functions, $C^1[0,1]$, under a metric that controls both the functions and their derivatives. Proving the completeness of this space is not just an academic exercise; it is a cornerstone for establishing existence and uniqueness theorems for solutions to differential equations, a central topic in modern analysis [@problem_id:1288523].", "problem": "Let $C^1[0,1]$ denote the vector space of all real-valued functions that are continuously differentiable on the closed interval $[0,1]$. We can define a metric $d$ on this space for any two functions $f, g \\in C^1[0,1]$ as follows:\n$$d(f,g) = \\sup_{x\\in[0,1]}|f(x)-g(x)| + \\sup_{x\\in[0,1]}|f'(x)-g'(x)|$$\nA fundamental property a metric space can have is completeness, which means that every Cauchy sequence in the space converges to a limit that is also within the space. The completeness of function spaces is a cornerstone of modern analysis, particularly in the study of differential equations where solutions are often constructed as limits of sequences of approximate solutions.\n\nConsider a Cauchy sequence $\\{f_n\\}_{n=1}^{\\infty}$ in the metric space $(C^1[0,1], d)$. Which one of the following statements correctly describes the completeness of this space and provides the valid reasoning?\n\nA. The space is not complete. A Cauchy sequence $\\{f_n\\}$ guarantees that the functions themselves converge uniformly to a limit function $f$, but the sequence of derivatives $\\{f'_n\\}$ might not converge, which means the limit $f$ is not necessarily differentiable.\n\nB. The space is not complete. Although a Cauchy sequence $\\{f_n\\}$ in this metric ensures that both $\\{f_n\\}$ and $\\{f'_n\\}$ converge uniformly to some functions $f$ and $g$ respectively, there is no guarantee that the limit of the derivatives equals the derivative of the limit (i.e., that $f' = g$).\n\nC. The space is not complete. A Cauchy sequence ensures $\\{f_n\\}$ and $\\{f'_n\\}$ converge uniformly to $f$ and $g$ respectively, and that $f'=g$. However, the limit function $g$ is not guaranteed to be continuous, so the limit function $f$ might not be an element of $C^1[0,1]$.\n\nD. The space is complete. A Cauchy sequence $\\{f_n\\}$ in this metric implies that $\\{f_n\\}$ and $\\{f'_n\\}$ are both Cauchy sequences in the space of continuous functions with the sup-norm. The completeness of the latter space implies $\\{f_n\\}$ and $\\{f'_n\\}$ converge uniformly to continuous functions $f$ and $g$ respectively. A fundamental theorem of analysis then guarantees that $f$ is differentiable and $f' = g$, which confirms that the limit $f$ is in $C^1[0,1]$.", "solution": "Let $\\{f_{n}\\}$ be a Cauchy sequence in $\\left(C^{1}[0,1],d\\right)$ with\n$$\nd(f_{n},f_{m})=\\sup_{x\\in[0,1]}|f_{n}(x)-f_{m}(x)|+\\sup_{x\\in[0,1]}|f_{n}'(x)-f_{m}'(x)|.\n$$\nBy the Cauchy property, for every $\\varepsilon>0$ there exists $N$ such that for all $m,n\\geq N$,\n$$\n\\sup_{x\\in[0,1]}|f_{n}(x)-f_{m}(x)| \\leq d(f_{n},f_{m})  \\varepsilon, \\quad \\text{and} \\quad \\sup_{x\\in[0,1]}|f_{n}'(x)-f_{m}'(x)| \\leq d(f_{n},f_{m})  \\varepsilon.\n$$\nHence $\\{f_{n}\\}$ and $\\{f_{n}'\\}$ are Cauchy sequences in $\\left(C[0,1],\\|\\cdot\\|_{\\infty}\\right)$. Since $\\left(C[0,1],\\|\\cdot\\|_{\\infty}\\right)$ is complete, there exist $f,g\\in C[0,1]$ such that\n$$\n\\|f_{n}-f\\|_{\\infty}\\to 0,\\qquad \\|f_{n}'-g\\|_{\\infty}\\to 0\\quad\\text{as }n\\to\\infty.\n$$\n\nWe now show that $f$ is differentiable and $f'=g$. For each $n$ and each $x\\in[0,1]$, the fundamental theorem of calculus for $C^{1}$ functions gives\n$$\nf_{n}(x)=f_{n}(0)+\\int_{0}^{x} f_{n}'(t)\\,dt.\n$$\nTaking limits as $n\\to\\infty$:\n- Since $f_{n}\\to f$ uniformly, we have $f_{n}(0)\\to f(0)$.\n- Since $f_{n}'\\to g$ uniformly, we have for each $x\\in[0,1]$,\n$$\n\\left|\\int_{0}^{x} f_{n}'(t)\\,dt-\\int_{0}^{x} g(t)\\,dt\\right| \\leq \\int_{0}^{x} |f_{n}'(t)-g(t)|\\,dt \\leq \\|f_{n}'-g\\|_{\\infty} \\to 0.\n$$\nTherefore,\n$$\nf(x)=f(0)+\\int_{0}^{x} g(t)\\,dt\\quad\\text{for all }x\\in[0,1].\n$$\nBy the fundamental theorem of calculus for continuous integrands, the right-hand side defines a differentiable function with derivative $g$, hence $f\\in C^{1}[0,1]$ and $f'=g$.\n\nThus every Cauchy sequence in $\\left(C^{1}[0,1],d\\right)$ converges to a limit in $C^{1}[0,1]$, so the space is complete. This is exactly the content of option D; options A, B, and C fail because the uniform limit of derivatives together with uniform convergence of the functions ensures $f'=g$, and $g$ is continuous as a uniform limit of continuous functions.", "answer": "$$\\boxed{D}$$", "id": "1288523"}]}