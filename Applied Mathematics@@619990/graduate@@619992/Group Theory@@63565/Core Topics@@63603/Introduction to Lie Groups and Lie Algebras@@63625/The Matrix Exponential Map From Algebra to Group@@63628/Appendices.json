{"hands_on_practices": [{"introduction": "The matrix exponential, defined as an infinite series, forms the very heart of the map from a Lie algebra to its Lie group. While this infinite sum can seem daunting, certain structural properties of the algebra element can lead to profound simplifications. This first exercise explores one such crucial case: nilpotent matrices, for which the exponential series elegantly truncates to a finite polynomial. By working through this problem [@problem_id:818269], you will see firsthand how an algebraic property like nilpotency makes the journey from algebra to group a simple and direct calculation.", "problem": "Consider a matrix $X$ that is an element of the Lie algebra $\\mathfrak{sl}(3, \\mathbb{R})$, which is the space of $3 \\times 3$ real matrices with a trace of zero. The matrix $X$ is parameterized by a real number $\\alpha$ and is given by:\n$$\nX(\\alpha) = \\begin{pmatrix}\n\\frac{\\alpha-2}{2} & \\frac{\\alpha+2}{2} & \\frac{2-\\alpha}{2} \\\\\n-1 & 1 & 1 \\\\\n\\frac{\\alpha}{2} & \\frac{\\alpha}{2} & -\\frac{\\alpha}{2}\n\\end{pmatrix}\n$$\nIt is a known property of $X(\\alpha)$ that it is a nilpotent matrix for any real value of $\\alpha$.\n\nThe matrix $X(\\alpha)$ is mapped to an element $G(\\alpha)$ of the corresponding Lie group $SL(3, \\mathbb{R})$ through the matrix exponential map, $G(\\alpha) = \\exp(X(\\alpha))$. The exponential of a matrix is defined by its Taylor series expansion:\n$$\n\\exp(X) = I + X + \\frac{1}{2!}X^2 + \\frac{1}{3!}X^3 + \\dots = \\sum_{k=0}^{\\infty} \\frac{1}{k!}X^k\n$$\nwhere $I$ is the $3 \\times 3$ identity matrix.\n\nGiven that the element in the first row and second column of the resulting matrix $G(\\alpha)$ is $G_{12} = 7$, derive the value of the parameter $\\alpha$.", "solution": "The problem asks for the value of the parameter $\\alpha$ given a specific entry of the matrix $G(\\alpha) = \\exp(X(\\alpha))$.\n\nFirst, let's verify that $X(\\alpha) \\in \\mathfrak{sl}(3, \\mathbb{R})$ by checking if its trace is zero.\n$$\n\\text{Tr}(X) = X_{11} + X_{22} + X_{33} = \\frac{\\alpha-2}{2} + 1 + \\left(-\\frac{\\alpha}{2}\\right) = \\frac{\\alpha}{2} - 1 + 1 - \\frac{\\alpha}{2} = 0\n$$\nThe trace is indeed zero for any value of $\\alpha$.\n\nThe problem states that $X(\\alpha)$ is a nilpotent matrix. For a $3 \\times 3$ matrix, nilpotency implies that $X^k = 0$ for some integer $k \\le 3$. A key property of nilpotent matrices is that their characteristic polynomial is $p(\\lambda) = (-\\lambda)^n$. For a $3 \\times 3$ matrix, this means $p(\\lambda) = -\\lambda^3$. By the Cayley-Hamilton theorem, a matrix satisfies its own characteristic equation, so we must have $X^3 = 0$.\n\nThe nilpotency of $X$ simplifies the infinite series for the matrix exponential. Since $X^3 = 0$, all higher powers $X^k$ for $k \\ge 3$ are also zero. The series truncates:\n$$\nG(\\alpha) = \\exp(X(\\alpha)) = I + X(\\alpha) + \\frac{1}{2}X(\\alpha)^2\n$$\n\nWe are given $G_{12} = 7$. From the expression for $G(\\alpha)$, we can write the component $G_{12}$ as:\n$$\nG_{12} = I_{12} + X_{12} + \\frac{1}{2}(X^2)_{12}\n$$\nThe components of the identity matrix are $I_{ij} = \\delta_{ij}$, so $I_{12} = 0$.\nFrom the definition of $X(\\alpha)$, we have $X_{12} = \\frac{\\alpha+2}{2}$.\n\nThe main task is to compute the $(1,2)$-entry of $X^2$. According to the rule of matrix multiplication, $(X^2)_{ij} = \\sum_{k=1}^3 X_{ik} X_{kj}$. For the $(1,2)$-entry:\n$$\n(X^2)_{12} = X_{11}X_{12} + X_{12}X_{22} + X_{13}X_{32}\n$$\nSubstituting the entries of $X(\\alpha)$:\n$$\nX_{11} = \\frac{\\alpha-2}{2}, \\quad X_{12} = \\frac{\\alpha+2}{2}, \\quad X_{13} = \\frac{2-\\alpha}{2}\n$$\n$$\nX_{22} = 1, \\quad X_{32} = \\frac{\\alpha}{2}\n$$\nNow, we compute the product:\n$$\n(X^2)_{12} = \\left(\\frac{\\alpha-2}{2}\\right)\\left(\\frac{\\alpha+2}{2}\\right) + \\left(\\frac{\\alpha+2}{2}\\right)(1) + \\left(\\frac{2-\\alpha}{2}\\right)\\left(\\frac{\\alpha}{2}\\right)\n$$\nLet's simplify this expression term by term:\n$$\n(X^2)_{12} = \\frac{(\\alpha-2)(\\alpha+2)}{4} + \\frac{\\alpha+2}{2} + \\frac{(2-\\alpha)\\alpha}{4}\n$$\n$$\n(X^2)_{12} = \\frac{\\alpha^2-4}{4} + \\frac{2(\\alpha+2)}{4} + \\frac{2\\alpha-\\alpha^2}{4}\n$$\nCombine the numerators:\n$$\n(X^2)_{12} = \\frac{(\\alpha^2-4) + (2\\alpha+4) + (2\\alpha-\\alpha^2)}{4}\n$$\n$$\n(X^2)_{12} = \\frac{\\alpha^2 - 4 + 2\\alpha + 4 + 2\\alpha - \\alpha^2}{4} = \\frac{4\\alpha}{4} = \\alpha\n$$\nSo, the $(1,2)$-entry of $X^2$ is simply $\\alpha$.\n\nNow we can assemble the expression for $G_{12}$:\n$$\nG_{12} = I_{12} + X_{12} + \\frac{1}{2}(X^2)_{12} = 0 + \\frac{\\alpha+2}{2} + \\frac{1}{2}(\\alpha)\n$$\n$$\nG_{12} = \\frac{\\alpha+2}{2} + \\frac{\\alpha}{2} = \\frac{\\alpha+2+\\alpha}{2} = \\frac{2\\alpha+2}{2} = \\alpha+1\n$$\nWe are given that $G_{12} = 7$. Therefore, we can set up the final equation for $\\alpha$:\n$$\n\\alpha+1 = 7\n$$\nSolving for $\\alpha$:\n$$\n\\alpha = 7 - 1 = 6\n$$\nThe value of the parameter $\\alpha$ is 6.", "answer": "$$\n\\boxed{6}\n$$", "id": "818269"}, {"introduction": "A cornerstone property of the exponential map states that if two algebra elements $X$ and $Y$ commute (i.e., $[X, Y]=0$), then their corresponding group elements $\\exp(X)$ and $\\exp(Y)$ also commute. But does this implication work in reverse? This exercise challenges you to investigate that very question within the fundamental framework of $\\mathfrak{sl}(2, \\mathbb{R})$. You will discover that commutativity in the group does not necessarily require commutativity in the algebra, revealing a subtle but critical feature of the exponential map [@problem_id:818152].", "problem": "In the study of Lie theory, the matrix exponential map provides a bridge from a Lie algebra $\\mathfrak{g}$ to its corresponding Lie group $G$. For the special linear Lie algebra $\\mathfrak{sl}(2, \\mathbb{R})$, consisting of $2 \\times 2$ real matrices with zero trace, this map is given by $X \\mapsto \\exp(X)$, where $X \\in \\mathfrak{sl}(2, \\mathbb{R})$ and $\\exp(X) \\in SL(2, \\mathbb{R})$. A fundamental property is that if two generators $X, Y \\in \\mathfrak{g}$ commute (i.e., their Lie bracket $[X, Y] = XY - YX = 0$), then their corresponding group elements $\\exp(X)$ and $\\exp(Y)$ also commute. However, the converse is not generally true: it is possible for $\\exp(X)$ and $\\exp(Y)$ to commute even when $[X, Y] \\neq 0$.\n\nConsider two generators from $\\mathfrak{sl}(2, \\mathbb{R})$ defined as:\n$$\nX = \\begin{pmatrix} \\lambda & 0 \\\\ 0 & -\\lambda \\end{pmatrix}\n$$\n$$\nY(\\alpha) = \\begin{pmatrix} 0 & \\alpha \\\\ \\beta & 0 \\end{pmatrix}\n$$\nHere, $\\lambda$ is a non-zero real constant, $\\beta$ is a fixed negative real constant, and $\\alpha$ is a positive real parameter.\n\nDetermine the smallest positive value of the parameter $\\alpha$ for which the group elements $G_X = \\exp(X)$ and $G_Y = \\exp(Y(\\alpha))$ commute, under the condition that the generators $X$ and $Y(\\alpha)$ themselves do not commute. Express your answer as a symbolic expression in terms of $\\beta$.", "solution": "The problem asks for the smallest positive value of $\\alpha$ such that $\\exp(X)$ and $\\exp(Y(\\alpha))$ commute, given that $X$ and $Y(\\alpha)$ do not.\n\nFirst, let's compute the matrix exponentials. For the diagonal matrix $X$, the exponential is straightforward:\n$$\nG_X = \\exp(X) = \\begin{pmatrix} e^\\lambda & 0 \\\\ 0 & e^{-\\lambda} \\end{pmatrix}\n$$\n\nFor the matrix $Y(\\alpha)$, we first compute its square:\n$$\nY^2 = \\begin{pmatrix} 0 & \\alpha \\\\ \\beta & 0 \\end{pmatrix} \\begin{pmatrix} 0 & \\alpha \\\\ \\beta & 0 \\end{pmatrix} = \\begin{pmatrix} \\alpha\\beta & 0 \\\\ 0 & \\alpha\\beta \\end{pmatrix} = \\alpha\\beta I\n$$\nSince $\\alpha > 0$ and $\\beta  0$, their product $\\alpha\\beta$ is negative. Let $\\mu^2 = -\\alpha\\beta$, where $\\mu$ is a positive real number. Thus, $Y^2 = -\\mu^2 I$. We can use the Taylor series expansion for the exponential, separating even and odd powers:\n$$\n\\exp(Y) = \\sum_{n=0}^{\\infty} \\frac{Y^n}{n!} = \\sum_{k=0}^{\\infty} \\frac{Y^{2k}}{(2k)!} + \\sum_{k=0}^{\\infty} \\frac{Y^{2k+1}}{(2k+1)!}\n$$\nUsing $Y^{2k} = (-\\mu^2)^k I = (-1)^k \\mu^{2k} I$ and $Y^{2k+1} = (-1)^k \\mu^{2k} Y$:\n$$\n\\exp(Y) = \\left(\\sum_{k=0}^{\\infty} \\frac{(-1)^k \\mu^{2k}}{(2k)!}\\right)I + \\left(\\sum_{k=0}^{\\infty} \\frac{(-1)^k \\mu^{2k}}{(2k+1)!}\\right)Y\n$$\nRecognizing the series for cosine and sine (divided by $\\mu$), we get the well-known formula:\n$$\nG_Y = \\exp(Y) = (\\cos\\mu) I + \\frac{\\sin\\mu}{\\mu} Y = \\begin{pmatrix} \\cos\\mu  \\frac{\\alpha\\sin\\mu}{\\mu} \\\\ \\frac{\\beta\\sin\\mu}{\\mu}  \\cos\\mu \\end{pmatrix}\n$$\n\nNow, we impose the commutativity condition: $G_X G_Y = G_Y G_X$.\n$$\nG_X G_Y = \\begin{pmatrix} e^\\lambda\\cos\\mu  e^\\lambda\\frac{\\alpha\\sin\\mu}{\\mu} \\\\ e^{-\\lambda}\\frac{\\beta\\sin\\mu}{\\mu}  e^{-\\lambda}\\cos\\mu \\end{pmatrix}\n$$\n$$\nG_Y G_X = \\begin{pmatrix} e^\\lambda\\cos\\mu  e^{-\\lambda}\\frac{\\alpha\\sin\\mu}{\\mu} \\\\ e^\\lambda\\frac{\\beta\\sin\\mu}{\\mu}  e^{-\\lambda}\\cos\\mu \\end{pmatrix}\n$$\nFor these two matrices to be equal, their corresponding elements must be equal. The diagonal elements are already identical. Equating the off-diagonal elements gives two conditions:\n$$\ne^\\lambda\\frac{\\alpha\\sin\\mu}{\\mu} = e^{-\\lambda}\\frac{\\alpha\\sin\\mu}{\\mu} \\implies (e^\\lambda - e^{-\\lambda})\\frac{\\alpha\\sin\\mu}{\\mu} = 0\n$$\n$$\ne^{-\\lambda}\\frac{\\beta\\sin\\mu}{\\mu} = e^\\lambda\\frac{\\beta\\sin\\mu}{\\mu} \\implies (e^{-\\lambda} - e^\\lambda)\\frac{\\beta\\sin\\mu}{\\mu} = 0\n$$\nWe are given that $\\lambda \\neq 0$, so $e^\\lambda \\neq e^{-\\lambda}$. Also, $\\alpha > 0$ and $\\beta  0$. Therefore, for these equations to hold, we must have $\\sin\\mu = 0$. This implies that $\\mu$ must be an integer multiple of $\\pi$, so $\\mu = n\\pi$ for $n \\in \\mathbb{Z}$. Since $\\mu = \\sqrt{-\\alpha\\beta}$ must be positive, we take $n$ to be a positive integer, $n \\in \\{1, 2, 3, \\dots\\}$.\n\nSubstituting back the definition of $\\mu$:\n$$\n\\mu^2 = n^2\\pi^2 \\implies -\\alpha\\beta = n^2\\pi^2\n$$\nSolving for $\\alpha$:\n$$\n\\alpha = -\\frac{n^2\\pi^2}{\\beta}\n$$\nWe are looking for the smallest positive value of $\\alpha$. Since $\\beta  0$, the expression $-\\frac{\\pi^2}{\\beta}$ is positive. The smallest positive value for $\\alpha$ corresponds to the smallest positive integer value for $n$, which is $n=1$.\n$$\n\\alpha_{\\min} = -\\frac{\\pi^2}{\\beta}\n$$\nFinally, we must confirm that $X$ and $Y$ do not commute.\n$$\n[X, Y] = XY - YX = \\begin{pmatrix} 0  2\\lambda\\alpha \\\\ -2\\lambda\\beta  0 \\end{pmatrix}\n$$\nSince $\\lambda \\neq 0$, $\\alpha > 0$, and $\\beta \\neq 0$, the commutator $[X, Y]$ is not the zero matrix. Thus, the condition is satisfied.", "answer": "$$\\boxed{-\\frac{\\pi^2}{\\beta}}$$", "id": "818152"}, {"introduction": "At first glance, exponentiating a complex matrix from a high-dimensional Lie algebra like $\\mathfrak{so}(4)$ may appear computationally prohibitive. This final practice demonstrates that the most effective path is often not brute force, but elegant simplification. The key lies in recognizing the underlying structure of the algebra element and finding a basis in which it takes a much simpler, block-diagonal form. This problem [@problem_id:818294] will guide you through this powerful strategy, showing how a change of basis can transform a seemingly intractable problem into a manageable one, thereby revealing the beautiful geometric nature of the resulting group element.", "problem": "In the study of Lie groups and their algebras, the exponential map provides a bridge from the algebra to the group. For matrix Lie groups, the Lie algebra $\\mathfrak{g}$ is a vector space of matrices, and the Lie group $G$ consists of invertible matrices. The map is the standard matrix exponential, $R = \\exp(X)$ for $X \\in \\mathfrak{g}$ and $R \\in G$.\n\nConsider the Lie group $SO(4)$, the group of $4 \\times 4$ real orthogonal matrices with determinant 1. Its Lie algebra, denoted $\\mathfrak{so}(4)$, consists of all $4 \\times 4$ real skew-symmetric matrices.\n\nLet a specific element $X$ of the Lie algebra $\\mathfrak{so}(4)$ be given by the matrix:\n$$\nX = \\begin{pmatrix}\n0  -(\\cos\\phi)\\alpha  -(\\sin\\phi)\\beta  0 \\\\\n(\\cos\\phi)\\alpha  0  0  (\\sin\\phi)\\alpha \\\\\n(\\sin\\phi)\\beta  0  0  -(\\cos\\phi)\\beta \\\\\n0  -(\\sin\\phi)\\alpha  (\\cos\\phi)\\beta  0\n\\end{pmatrix}\n$$\nwhere $\\alpha$, $\\beta$, and $\\phi$ are real parameters.\n\nDerive the matrix element $R_{11}$ of the resulting group element $R = \\exp(X)$.", "solution": "The problem asks for the $(1,1)$ entry of the matrix $R = \\exp(X)$, where $X$ is a given $4 \\times 4$ skew-symmetric matrix from $\\mathfrak{so}(4)$. A direct computation of the power series for $\\exp(X)$ would be very complicated. The key insight is to simplify $X$ by a change of basis.\n\nThe matrix $X$ has a structure suggesting it is a rotated version of a simpler, block-diagonal matrix. Let's consider a similarity transformation by an orthogonal matrix $P$. If we can find a simpler matrix $X_0$ such that $X = P X_0 P^T$, then the exponential is given by $R = \\exp(X) = \\exp(P X_0 P^T) = P \\exp(X_0) P^T$.\n\nLet $P$ be a rotation matrix in the $(x_1, x_4)$ plane by an angle $\\phi$:\n$$\nP = \\begin{pmatrix}\n\\cos\\phi  0  0  \\sin\\phi \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n-\\sin\\phi  0  0  \\cos\\phi\n\\end{pmatrix}\n$$\nLet's define a simple block-diagonal matrix $X_0$ in $\\mathfrak{so}(4)$ that represents two independent rotations: one with rate $\\alpha$ in the $(x_1, x_2)$ plane and one with rate $\\beta$ in the $(x_3, x_4)$ plane. The generators for these are $L_{12}$ and $L_{34}$, respectively. Let $X_0 = \\alpha L_{12} - \\beta L_{34}$.\n$$\nX_0 = \\begin{pmatrix}\n0  -\\alpha  0  0 \\\\\n\\alpha  0  0  0 \\\\\n0  0  0  \\beta \\\\\n0  0  -\\beta  0\n\\end{pmatrix}\n$$\nOne can verify by direct computation that $X = P X_0 P^T$. For example, the $(1,2)$ element is $(P X_0 P^T)_{12} = (\\cos\\phi)(-\\alpha) = -(\\cos\\phi)\\alpha$, and the $(2,4)$ element is $(P X_0 P^T)_{24} = (\\alpha)(-\\sin\\phi) = -(\\sin\\phi)\\alpha$. The given matrix $X$ is indeed the result of this similarity transformation.\n\nWith this decomposition, we can easily exponentiate the simple matrix $X_0$. The two blocks in $X_0$ correspond to commuting generators, so we can exponentiate them separately:\n$$ \\exp(X_0) = \\exp(\\alpha L_{12}) \\exp(-\\beta L_{34}) $$\nThe exponential of a planar rotation generator is a rotation matrix in that plane.\n$$ \\exp(\\alpha L_{12}) = \\begin{pmatrix} \\cos\\alpha  -\\sin\\alpha  0  0 \\\\ \\sin\\alpha  \\cos\\alpha  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\end{pmatrix} $$\n$$ \\exp(-\\beta L_{34}) = \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  0  0 \\\\ 0  0  \\cos\\beta  \\sin\\beta \\\\ 0  0  -\\sin\\beta  \\cos\\beta \\end{pmatrix} $$\nMultiplying these gives the exponential of $X_0$, which we denote as $R_0$:\n$$\nR_0 = \\exp(X_0) = \\begin{pmatrix}\n\\cos\\alpha  -\\sin\\alpha  0  0 \\\\\n\\sin\\alpha  \\cos\\alpha  0  0 \\\\\n0  0  \\cos\\beta  \\sin\\beta \\\\\n0  0  -\\sin\\beta  \\cos\\beta\n\\end{pmatrix}\n$$\nFinally, we compute $R = P R_0 P^T$. We only need the element $R_{11}$.\n$$ R_{11} = (P R_0 P^T)_{11} = \\sum_{k,l=1}^4 P_{1k} (R_0)_{kl} (P^T)_{l1} $$\nSince $P^T_{l1} = P_{1l}$, this is $R_{11} = \\sum_{k,l=1}^4 P_{1k} P_{1l} (R_0)_{kl}$.\nThe first row of $P$ is $(P_{11}, P_{12}, P_{13}, P_{14}) = (\\cos\\phi, 0, 0, \\sin\\phi)$. Thus, only terms where indices $k$ and $l$ are either 1 or 4 will contribute.\n\\begin{align*}\nR_{11} = P_{11}P_{11}(R_0)_{11} + P_{11}P_{14}(R_0)_{14} + P_{14}P_{11}(R_0)_{41} + P_{14}P_{14}(R_0)_{44} \\\\\n= (\\cos^2\\phi)(R_0)_{11} + (\\cos\\phi\\sin\\phi)(R_0)_{14} + (\\sin\\phi\\cos\\phi)(R_0)_{41} + (\\sin^2\\phi)(R_0)_{44}\n\\end{align*}\nFrom the matrix $R_0$, we have $(R_0)_{11} = \\cos\\alpha$, $(R_0)_{44} = \\cos\\beta$, and the off-diagonal block elements $(R_0)_{14} = (R_0)_{41} = 0$.\nSubstituting these values gives the final result:\n$$\nR_{11} = \\cos^2\\phi \\cos\\alpha + \\sin^2\\phi \\cos\\beta\n$$", "answer": "$$\n\\boxed{\\cos^2\\phi \\cos\\alpha + \\sin^2\\phi \\cos\\beta}\n$$", "id": "818294"}]}