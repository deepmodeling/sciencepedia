{"hands_on_practices": [{"introduction": "While it is a basic property that the sum of two martingales remains a martingale, what happens when we combine them non-linearly? This practice explores this question by considering the maximum, $U_n = \\max(M_n, N_n)$, and minimum, $V_n = \\min(M_n, N_n)$, of two martingales. This exercise reveals how the convexity of the `max` function and concavity of the `min` function predictably generate submartingales and supermartingales, respectively, illustrating a powerful and generalizable application of Jensen's inequality [@problem_id:1295475].", "problem": "Let $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ be a filtration on a probability space $(\\Omega, \\mathcal{F}, P)$. Consider two discrete-time stochastic processes, $\\{M_n\\}_{n \\ge 0}$ and $\\{N_n\\}_{n \\ge 0}$, both of which are known to be martingales with respect to this same filtration.\n\nTwo new processes, $\\{U_n\\}_{n \\ge 0}$ and $\\{V_n\\}_{n \\ge 0}$, are constructed as follows for all $n \\ge 0$:\n$$U_n = \\max(M_n, N_n)$$\n$$V_n = \\min(M_n, N_n)$$\n\nA stochastic process $\\{X_n\\}_{n \\ge 0}$ is classified as a martingale if $E[X_{n+1}|\\mathcal{F}_n] = X_n$, a submartingale if $E[X_{n+1}|\\mathcal{F}_n] \\ge X_n$, and a supermartingale if $E[X_{n+1}|\\mathcal{F}_n] \\le X_n$, assuming the process is adapted and integrable.\n\nDetermine the general classification of the processes $\\{U_n\\}$ and $\\{V_n\\}$.\n\nA. $U_n$ is a martingale and $V_n$ is a martingale.\n\nB. $U_n$ is a supermartingale and $V_n$ is a submartingale.\n\nC. $U_n$ is a submartingale and $V_n$ is a supermartingale.\n\nD. $U_n$ is a submartingale and $V_n$ is a submartingale.\n\nE. $U_n$ is a supermartingale and $V_n$ is a supermartingale.\n\nF. The classifications cannot be determined without more information.", "solution": "Because $\\{M_{n}\\}$ and $\\{N_{n}\\}$ are martingales with respect to $\\{\\mathcal{F}_{n}\\}$, they are adapted and integrable, and so are any of their linear combinations. The processes $\\{U_{n}\\}$ and $\\{V_{n}\\}$ are adapted since they are pointwise functions of adapted variables. For integrability, note that\n$$|U_{n}|=\\max(|M_{n}|,|N_{n}|)\\le |M_{n}|+|N_{n}|,$$\nand similarly $|V_{n}|=\\min(|M_{n}|,|N_{n}|)\\le |M_{n}|+|N_{n}|$, hence both are integrable when $M_{n}$ and $N_{n}$ are.\n\nUse the identities\n$$U_{n}=\\max(M_{n},N_{n})=\\frac{1}{2}\\Big((M_{n}+N_{n})+|M_{n}-N_{n}|\\Big),$$\n$$V_{n}=\\min(M_{n},N_{n})=\\frac{1}{2}\\Big((M_{n}+N_{n})-|M_{n}-N_{n}|\\Big).$$\nSince the sum of martingales is a martingale, $\\frac{1}{2}(M_{n}+N_{n})$ is a martingale. The difference $\\{M_{n}-N_{n}\\}$ is also a martingale. The function $x\\mapsto |x|$ is convex, so by conditional Jensen's inequality,\n$$|M_{n}-N_{n}|=\\big|E[M_{n+1}-N_{n+1}\\mid \\mathcal{F}_{n}]\\big|\\le E[\\,|M_{n+1}-N_{n+1}|\\,\\mid \\mathcal{F}_{n}],$$\nwhich shows that $\\{|M_{n}-N_{n}|\\}$ is a submartingale. Therefore,\n$$E[U_{n+1}\\mid \\mathcal{F}_{n}]=\\frac{1}{2}\\Big(E[M_{n+1}+N_{n+1}\\mid \\mathcal{F}_{n}]+E[|M_{n+1}-N_{n+1}|\\mid \\mathcal{F}_{n}]\\Big)$$\n$$=\\frac{1}{2}\\Big((M_{n}+N_{n})+E[|M_{n+1}-N_{n+1}|\\mid \\mathcal{F}_{n}]\\Big)\\ge \\frac{1}{2}\\Big((M_{n}+N_{n})+|M_{n}-N_{n}|\\Big)=U_{n},$$\nso $\\{U_{n}\\}$ is a submartingale. Similarly,\n$$E[V_{n+1}\\mid \\mathcal{F}_{n}]=\\frac{1}{2}\\Big((M_{n}+N_{n})-E[|M_{n+1}-N_{n+1}|\\mid \\mathcal{F}_{n}]\\Big)\\le \\frac{1}{2}\\Big((M_{n}+N_{n})-|M_{n}-N_{n}|\\Big)=V_{n},$$\nso $\\{V_{n}\\}$ is a supermartingale.\n\nEquivalently, one can note that $\\max$ is convex on $\\mathbb{R}^{2}$ and apply multivariate conditional Jensen to the vector martingale $(M_{n},N_{n})$ to get that $\\{\\max(M_{n},N_{n})\\}$ is a submartingale; then $\\min(M_{n},N_{n})=-\\max(-M_{n},-N_{n})$ is a supermartingale since $-M$ and $-N$ are martingales.\n\nThus, in the given options, $U_{n}$ is a submartingale and $V_{n}$ is a supermartingale.", "answer": "$$\\boxed{C}$$", "id": "1295475"}, {"introduction": "Applying a deterministic function to a stochastic process is a fundamental technique for analysis and modeling. This exercise focuses on how a function's curvature transforms a martingale by asking you to classify the process $X_n = \\sqrt{M_n}$ derived from a positive martingale $\\{M_n\\}$. Through a direct application of Jensen's inequality, you will see how a concave transformation systematically produces a supermartingale, solidifying a core principle in the study of these processes [@problem_id:1390425].", "problem": "Let $\\{Y_k\\}_{k \\geq 1}$ be a sequence of positive, independent and identically distributed (i.i.d.) random variables defined on a probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$. Let $\\{\\mathcal{F}_n\\}_{n \\geq 0}$ be the natural filtration generated by this sequence, i.e., $\\mathcal{F}_0 = \\{\\emptyset, \\Omega\\}$ and $\\mathcal{F}_n = \\sigma(Y_1, \\dots, Y_n)$ for $n \\geq 1$.\n\nConsider a discrete-time stochastic process $\\{M_n\\}_{n \\geq 0}$ defined by $M_0 = 1$ and $M_n = \\prod_{k=1}^n Y_k$ for $n \\geq 1$. You are given that $\\{M_n\\}_{n \\geq 0}$ is a martingale with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\geq 0}$.\n\nNow, define a new process $\\{X_n\\}_{n \\geq 0}$ by $X_n = \\sqrt{M_n}$. Based on the information provided, determine the general classification of the process $\\{X_n\\}_{n \\geq 0}$.\n\nA. $X_n$ is a submartingale.\n\nB. $X_n$ is a supermartingale.\n\nC. $X_n$ is a martingale.\n\nD. The classification depends on the specific distribution of the $Y_k$, and cannot be determined in general.", "solution": "We are given a positive martingale $\\{M_{n}\\}_{n \\geq 0}$ with respect to $\\{\\mathcal{F}_{n}\\}_{n \\geq 0}$, where $M_{0}=1$ and $M_{n}=\\prod_{k=1}^{n} Y_{k}$, and we define $X_{n}=\\sqrt{M_{n}}=M_{n}^{1/2}$.\n\nFirst, recall the martingale property:\n$$\n\\mathbb{E}\\!\\left[M_{n+1}\\mid \\mathcal{F}_{n}\\right]=M_{n}, \\quad n \\geq 0.\n$$\nDefine $f:(0,\\infty)\\to \\mathbb{R}$ by $f(x)=x^{1/2}$. The function $f$ is concave on $(0,\\infty)$, so by the conditional Jensen inequality for concave functions,\n$$\n\\mathbb{E}\\!\\left[f(M_{n+1})\\mid \\mathcal{F}_{n}\\right]\\leq f\\!\\left(\\mathbb{E}\\!\\left[M_{n+1}\\mid \\mathcal{F}_{n}\\right]\\right).\n$$\nUsing the martingale property of $M_{n}$, this yields\n$$\n\\mathbb{E}\\!\\left[X_{n+1}\\mid \\mathcal{F}_{n}\\right]=\\mathbb{E}\\!\\left[f(M_{n+1})\\mid \\mathcal{F}_{n}\\right]\\leq f(M_{n})=X_{n},\n$$\nwhich is exactly the supermartingale inequality.\n\nTo verify integrability of $X_{n}$, note that $M_{n}\\geq 0$ and, since $\\{M_{n}\\}$ is a martingale with $M_{0}=1$, we have $\\mathbb{E}[M_{n}]=\\mathbb{E}[M_{0}]=1$ for all $n$. For $p\\in(0,1)$, the function $x\\mapsto x^{p}$ is concave, and by Jensen,\n$$\n\\mathbb{E}\\!\\left[M_{n}^{1/2}\\right]\\leq \\left(\\mathbb{E}[M_{n}]\\right)^{1/2}=1,\n$$\nso $X_{n}$ is integrable. Therefore, $\\{X_{n}\\}$ is a supermartingale with respect to $\\{\\mathcal{F}_{n}\\}$.\n\nIn general it is not a martingale unless the degenerate case $Y_{k}=1$ almost surely holds, but the correct general classification is supermartingale.", "answer": "$$\\boxed{B}$$", "id": "1390425"}, {"introduction": "This advanced practice moves from the qualitative classification of processes to a deep quantitative analysis, highlighting the practical power of martingale theory. You will analyze the simple symmetric random walk—the canonical example of a martingale—to assess the tightness of the Azuma–Hoeffding inequality, a cornerstone concentration bound. This exercise provides hands-on experience connecting discrete combinatorics and large deviation theory, revealing the deep relationship between martingale properties and the exponential decay of tail probabilities [@problem_id:2972976].", "problem": "Let $\\{X_{k}\\}_{k=1}^{n}$ be independent Rademacher random variables, meaning $\\mathbb{P}(X_{k}=1)=\\mathbb{P}(X_{k}=-1)=\\frac{1}{2}$ for each $k$. Define the discrete-time process $M_{k}=\\sum_{i=1}^{k}X_{i}$ adapted to the natural filtration $\\mathcal{F}_{k}=\\sigma(X_{1},\\dots,X_{k})$. It is known that the Azuma–Hoeffding inequality for bounded-difference martingales asserts that if $\\{|M_{k}-M_{k-1}|\\leq c_{k}\\}$ almost surely for each $k$ and $t0$, then\n$$\n\\mathbb{P}\\big(M_{n}-M_{0}\\geq t\\big)\\leq \\exp\\!\\Big(-\\frac{t^{2}}{2\\sum_{k=1}^{n}c_{k}^{2}}\\Big).\n$$\nIn this setup, the increments satisfy $|M_{k}-M_{k-1}|=|X_{k}|=1$ almost surely.\n\nYou are asked to carry out a first-principles derivation using exact combinatorics and asymptotics to produce a quantitative comparison between the exact tail probability and the Azuma–Hoeffding bound, thereby assessing tightness up to constants.\n\nTasks:\n- Justify from first principles that $\\{M_{k}\\}_{k\\geq 0}$ is a discrete-time martingale and that $|M_{k}-M_{k-1}|=1$ almost surely.\n- For a fixed $a\\in(0,1)$, write the exact formula for the tail probability $\\mathbb{P}(M_{n}\\geq a n)$ in terms of binomial coefficients.\n- Using Stirling’s approximation for factorials, derive a large deviations rate function $I(a)$ such that\n$$\n\\mathbb{P}(M_{n}\\geq a n)=\\exp\\!\\big(-n\\,I(a)+o(n)\\big)\\quad\\text{as }n\\to\\infty.\n$$\n- Compare the exponential rate $\\exp(-n I(a))$ with the Azuma–Hoeffding upper bound $\\exp\\!\\big(-\\frac{a^{2}n}{2}\\big)$ in the regime of small deviations $a\\to 0$, and determine the limit\n$$\nL=\\lim_{a\\to 0}\\frac{I(a)}{a^{2}/2}.\n$$\n\nAnswer specification: Your final reported answer must be the single real number $L$ as defined above. No rounding is required.", "solution": "The problem statement is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n-   $\\{X_{k}\\}_{k=1}^{n}$ are independent Rademacher random variables, with $\\mathbb{P}(X_{k}=1)=\\mathbb{P}(X_{k}=-1)=\\frac{1}{2}$ for each $k$.\n-   The discrete-time process is $M_{k}=\\sum_{i=1}^{k}X_{i}$.\n-   The natural filtration is $\\mathcal{F}_{k}=\\sigma(X_{1},\\dots,X_{k})$.\n-   The Azuma–Hoeffding inequality is given as: if $\\{|M_{k}-M_{k-1}|\\leq c_{k}\\}$ almost surely, then for $t0$, $\\mathbb{P}\\big(M_{n}-M_{0}\\geq t\\big)\\leq \\exp\\!\\Big(-\\frac{t^{2}}{2\\sum_{k=1}^{n}c_{k}^{2}}\\Big)$.\n-   The increments satisfy $|M_{k}-M_{k-1}|=|X_{k}|=1$ almost surely.\n-   A fixed parameter $a\\in(0,1)$ is used to define the tail event $\\mathbb{P}(M_{n}\\geq a n)$.\n-   The asymptotic form of the tail probability is given as $\\mathbb{P}(M_{n}\\geq a n)=\\exp\\!\\big(-n\\,I(a)+o(n)\\big)$ as $n\\to\\infty$.\n-   The final quantity to be determined is the limit $L=\\lim_{a\\to 0}\\frac{I(a)}{a^{2}/2}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in probability theory, connecting the theory of martingales, combinatorics, and large deviations.\n-   **Scientifically Grounded**: The problem is rooted in fundamental, universally accepted principles of probability theory, including martingales, binomial distributions, Stirling's approximation, and large deviation theory (specifically Cramér's theorem). All concepts are standard and mathematically rigorous.\n-   **Well-Posed**: The problem is clearly structured with a sequence of tasks that logically lead to a unique, well-defined numerical answer for the limit $L$. The information provided is sufficient and consistent.\n-   **Objective**: The problem is stated using precise mathematical language, free from any ambiguity, subjectivity, or non-scientific claims.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is mathematically sound, self-contained, and well-posed. A full solution will be provided.\n\n### Solution Derivation\n\n**Justification of Martingale Property and Bounded Differences**\nWe are given the process $M_{k} = \\sum_{i=1}^{k} X_{i}$ for $k \\geq 1$, with $M_{0}=0$, adapted to the filtration $\\mathcal{F}_{k} = \\sigma(X_{1}, \\dots, X_{k})$. To demonstrate that $\\{M_{k}\\}_{k \\geq 0}$ is a martingale with respect to $\\{\\mathcal{F}_{k}\\}_{k \\geq 0}$, we must verify three conditions:\n$1$. $M_{k}$ is $\\mathcal{F}_{k}$-measurable for each $k \\geq 0$. This holds by definition, as $M_{k}$ is a function of the random variables $X_1, \\dots, X_k$ which generate $\\mathcal{F}_{k}$.\n$2$. $M_{k}$ is integrable, i.e., $\\mathbb{E}[|M_{k}|]  \\infty$. Using the triangle inequality, we have $\\mathbb{E}[|M_{k}|] = \\mathbb{E}[|\\sum_{i=1}^{k} X_{i}|] \\leq \\sum_{i=1}^{k} \\mathbb{E}[|X_{i}|]$. Since $X_{i}$ takes values in $\\{-1, 1\\}$, $|X_{i}|=1$ almost surely. Thus, $\\mathbb{E}[|X_{i}|]=1$, which gives $\\mathbb{E}[|M_{k}|] \\leq \\sum_{i=1}^{k} 1 = k  \\infty$.\n$3$. The core martingale property $\\mathbb{E}[M_{k} | \\mathcal{F}_{k-1}] = M_{k-1}$ for $k \\geq 1$.\n$$\n\\mathbb{E}[M_{k} | \\mathcal{F}_{k-1}] = \\mathbb{E}[M_{k-1} + X_{k} | \\mathcal{F}_{k-1}]\n$$\nBy linearity of conditional expectation,\n$$\n\\mathbb{E}[M_{k} | \\mathcal{F}_{k-1}] = \\mathbb{E}[M_{k-1} | \\mathcal{F}_{k-1}] + \\mathbb{E}[X_{k} | \\mathcal{F}_{k-1}]\n$$\nSince $M_{k-1}$ is $\\mathcal{F}_{k-1}$-measurable, $\\mathbb{E}[M_{k-1} | \\mathcal{F}_{k-1}] = M_{k-1}$. Since $X_{k}$ is independent of $\\mathcal{F}_{k-1} = \\sigma(X_{1}, \\dots, X_{k-1})$, its conditional expectation equals its unconditional expectation: $\\mathbb{E}[X_{k} | \\mathcal{F}_{k-1}] = \\mathbb{E}[X_{k}]$. The expectation of a Rademacher random variable is $\\mathbb{E}[X_{k}] = 1 \\cdot \\mathbb{P}(X_{k}=1) + (-1) \\cdot \\mathbb{P}(X_{k}=-1) = 1 \\cdot \\frac{1}{2} - 1 \\cdot \\frac{1}{2} = 0$.\nTherefore, $\\mathbb{E}[M_{k} | \\mathcal{F}_{k-1}] = M_{k-1} + 0 = M_{k-1}$.\nAll three conditions are satisfied, so $\\{M_k\\}_{k\\geq 0}$ is a discrete-time martingale.\nFor the increments, we have $M_{k}-M_{k-1} = (\\sum_{i=1}^{k} X_{i}) - (\\sum_{i=1}^{k-1} X_{i}) = X_{k}$ for $k \\ge 1$. As established, $|X_{k}|=1$ almost surely. Hence, $|M_{k}-M_{k-1}|=1$ almost surely.\n\n**Exact Formula for Tail Probability**\nLet $U_{n}$ be the number of variables in $\\{X_{1}, \\dots, X_{n}\\}$ that are equal to $1$. Consequently, $n-U_{n}$ variables are equal to $-1$. The sum $M_{n}$ can be expressed as:\n$$\nM_{n} = 1 \\cdot U_{n} + (-1) \\cdot (n - U_{n}) = 2U_{n} - n\n$$\nSince the $X_{k}$ are independent and identically distributed with $\\mathbb{P}(X_k=1)=1/2$, the random variable $U_{n}$ follows a binomial distribution, $U_{n} \\sim \\text{Bin}(n, 1/2)$. The probability mass function is $\\mathbb{P}(U_{n}=j) = \\binom{n}{j} (\\frac{1}{2})^{j} (\\frac{1}{2})^{n-j} = \\binom{n}{j} 2^{-n}$.\nThe event of interest is $M_{n} \\geq a n$. In terms of $U_{n}$, this is $2U_{n}-n \\geq an$, which simplifies to $U_{n} \\geq \\frac{n(1+a)}{2}$.\nThe exact tail probability is the sum of probabilities for all integer values of $j$ satisfying this condition:\n$$\n\\mathbb{P}(M_{n} \\geq a n) = \\mathbb{P}\\Big(U_{n} \\geq \\frac{n(1+a)}{2}\\Big) = \\sum_{j=\\lceil n(1+a)/2 \\rceil}^{n} \\mathbb{P}(U_{n}=j)\n$$\nSubstituting the binomial probability, we get:\n$$\n\\mathbb{P}(M_{n} \\geq a n) = 2^{-n} \\sum_{j=\\lceil n(1+a)/2 \\rceil}^{n} \\binom{n}{j}\n$$\n\n**Large Deviations Rate Function**\nWe seek the rate function $I(a)$ in the expression $\\mathbb{P}(M_{n}\\geq a n)=\\exp(-n\\,I(a)+o(n))$. This is a classic large deviation result. The probability of the sum is dominated by the probability of the most likely term in the sum, which for large $n$ corresponds to the lower limit of the summation. Let $p = j/n$. The event $M_{n} \\geq an$ corresponds to the empirical mean of \"+1\" outcomes being $U_n/n \\geq (1+a)/2$.\nAccording to Cramér's theorem, the rate function is the Legendre-Fenchel transform of the cumulant generating function of the underlying random variables. For i.i.d. Bernoulli trials $Y_i \\sim \\text{Bernoulli}(q)$, the rate function for the empirical mean $\\bar{Y}_n$ to be $p$ is given by the Kullback-Leibler divergence $I(p) = D_{KL}(p\\|q) = p\\ln(p/q) + (1-p)\\ln((1-p)/(1-q))$.\nIn our case, the variables are $Y_{i} = (X_{i}+1)/2 \\sim \\text{Bernoulli}(1/2)$, so $q=1/2$. The deviation is to $p=(1+a)/2$.\nThe rate function for the event $\\mathbb{P}(U_{n}/n \\geq (1+a)/2)$ is thus determined by the value $p=(1+a)/2$.\n$$\nI(a) = \\Big(\\frac{1+a}{2}\\Big)\\ln\\Big(\\frac{(1+a)/2}{1/2}\\Big) + \\Big(1-\\frac{1+a}{2}\\Big)\\ln\\Big(\\frac{1-(1+a)/2}{1/2}\\Big)\n$$\n$$\nI(a) = \\Big(\\frac{1+a}{2}\\Big)\\ln(1+a) + \\Big(\\frac{1-a}{2}\\Big)\\ln(1-a)\n$$\nThis is the desired large deviations rate function.\n\n**Comparison and Limit Calculation**\nThe Azuma-Hoeffding inequality for this process, with $c_{k}=1$ for all $k$, and $t=an$, gives the bound:\n$$\n\\mathbb{P}(M_{n}\\geq a n) \\leq \\exp\\left(-\\frac{(an)^2}{2\\sum_{k=1}^n 1^2}\\right) = \\exp\\left(-\\frac{a^2 n^2}{2n}\\right) = \\exp\\left(-n\\frac{a^2}{2}\\right)\n$$\nThis implies an upper bound on the rate of decay, suggesting a comparison of $I(a)$ with $a^2/2$. We now compute the specified limit $L = \\lim_{a\\to 0}\\frac{I(a)}{a^{2}/2}$.\nTo evaluate this limit, we find the Taylor series expansion of $I(a)$ around $a=0$. We use the series for $\\ln(1+x)$:\n$$\n\\ln(1+x) = x - \\frac{x^2}{2} + \\frac{x^3}{3} - \\frac{x^4}{4} + O(x^5)\n$$\nFirst, we expand $(1+a)\\ln(1+a)$:\n$$\n(1+a)\\ln(1+a) = (1+a)\\Big(a - \\frac{a^2}{2} + \\frac{a^3}{3} - \\frac{a^4}{4} + O(a^5)\\Big) = a + \\frac{a^2}{2} - \\frac{a^3}{6} + \\frac{a^4}{12} + O(a^5)\n$$\nNext, we expand $(1-a)\\ln(1-a)$ by substituting $-a$ for $a$:\n$$\n(1-a)\\ln(1-a) = -a + \\frac{a^2}{2} + \\frac{a^3}{6} + \\frac{a^4}{12} + O(a^5)\n$$\nNow we combine these into the expression for $I(a)$:\n$$\nI(a) = \\frac{1}{2} \\Big[ \\Big(a + \\frac{a^2}{2} - \\frac{a^3}{6} + \\frac{a^4}{12}\\Big) + \\Big(-a + \\frac{a^2}{2} + \\frac{a^3}{6} + \\frac{a^4}{12}\\Big) + O(a^5) \\Big]\n$$\n$$\nI(a) = \\frac{1}{2} \\Big[ a^2 + \\frac{a^4}{6} + O(a^5) \\Big] = \\frac{a^2}{2} + \\frac{a^4}{12} + O(a^5)\n$$\nFinally, we compute the limit:\n$$\nL = \\lim_{a\\to 0}\\frac{I(a)}{a^{2}/2} = \\lim_{a\\to 0}\\frac{\\frac{a^2}{2} + \\frac{a^4}{12} + O(a^5)}{a^2/2} = \\lim_{a\\to 0}\\Big(1 + \\frac{a^2}{6} + O(a^3)\\Big) = 1\n$$\nThe limit is $1$. This demonstrates that for small deviations (small $a$), the Azuma-Hoeffding inequality is tight in its exponential rate, capturing the correct $a^2/2$ term. The factor of $1$ signifies asymptotic equivalence of the rates in this regime.", "answer": "$$\\boxed{1}$$", "id": "2972976"}]}