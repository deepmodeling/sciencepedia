{"hands_on_practices": [{"introduction": "Establishing path continuity is a cornerstone of stochastic analysis, and the Kolmogorov Continuity Theorem offers a powerful criterion based on moment bounds of process increments. This first practice problem [@problem_id:2983270] challenges you to bridge the gap between the accessible second-moment properties of Gaussian processes and the higher-order moment conditions required by the theorem. By deriving a general condition for path continuity, you will develop a foundational skill for analyzing a wide array of important stochastic models.", "problem": "Let $\\{X_{t}\\}_{t \\in [0,1]}$ be a centered Gaussian process with covariance function $R(s,t) = \\mathbb{E}[X_{s} X_{t}]$, so that for any $s,t \\in [0,1]$ the second moment of the increment is given by $\\mathbb{E}[|X_{t} - X_{s}|^{2}] = R(t,t) + R(s,s) - 2 R(s,t)$. Assume there exist constants $C > 0$ and $H > 0$ such that for all $s,t \\in [0,1]$,\n$$\n\\mathbb{E}[|X_{t} - X_{s}|^{2}] \\leq C\\, |t - s|^{2H}.\n$$\nUsing only properties of Gaussian random variables and the Kolmogorov continuity theorem (KCT), derive a sufficient condition on the second moment $\\mathbb{E}[|X_{t} - X_{s}|^{2}]$ that ensures the existence of a modification of $\\{X_{t}\\}_{t \\in [0,1]}$ with almost surely continuous sample paths. Then, from that condition, determine the largest Hölder exponent $\\gamma_{\\mathrm{max}} \\in (0,1)$ (expressed purely in terms of $H$) that KCT guarantees for the sample paths of the modification on $[0,1]$. \n\nYour final answer should be a single closed-form analytic expression for $\\gamma_{\\mathrm{max}}$.", "solution": "The problem asks for two things: first, to derive a sufficient condition on the second moment of the increment of a centered Gaussian process $\\{X_t\\}_{t \\in [0,1]}$ that guarantees the existence of a modification with almost surely continuous sample paths, using the Kolmogorov continuity theorem (KCT); second, to determine the largest Hölder exponent $\\gamma_{\\mathrm{max}}$ guaranteed by this theorem.\n\nLet's begin by stating a standard version of the Kolmogorov continuity theorem. A stochastic process $\\{X_t\\}_{t \\in T}$ on a compact interval $T \\subset \\mathbb{R}$ (here $T=[0,1]$) has a modification with a.s. continuous sample paths if there exist constants $p>0$, $\\alpha>0$, and $K>0$ such that for all $s,t \\in [0,1]$,\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq K |t-s|^{1+\\alpha}.\n$$\nFurthermore, this modification has sample paths that are locally Hölder continuous with any exponent $\\gamma \\in (0, \\frac{\\alpha}{p})$.\n\nThe problem provides a centered Gaussian process $\\{X_t\\}_{t \\in [0,1]}$ and specifies a condition on the second moment of its increments:\n$$\n\\mathbb{E}[|X_t - X_s|^2] \\leq C |t-s|^{2H}\n$$\nfor some constants $C>0$ and $H>0$.\n\nOur first task is to show that this condition is sufficient for the KCT to hold. To do this, we must relate the given second moment to the $p$-th moment required by the theorem. The key is that $\\{X_t\\}$ is a Gaussian process.\nFor any $s, t \\in [0,1]$, the increment $Y_{s,t} = X_t - X_s$ is a random variable. Since $\\{X_t\\}$ is a Gaussian process, any linear combination of its components is Gaussian. Thus, $Y_{s,t}$ is a Gaussian random variable. As the process is centered, $\\mathbb{E}[X_t] = 0$ for all $t$, which implies that the increment has zero mean:\n$$\n\\mathbb{E}[Y_{s,t}] = \\mathbb{E}[X_t - X_s] = \\mathbb{E}[X_t] - \\mathbb{E}[X_s] = 0 - 0 = 0.\n$$\nThe variance of the increment is $\\sigma_{s,t}^2 = \\mathbb{E}[Y_{s,t}^2] = \\mathbb{E}[|X_t - X_s|^2]$. So, $Y_{s,t} \\sim \\mathcal{N}(0, \\sigma_{s,t}^2)$.\n\nNow, we compute the $p$-th absolute moment of $Y_{s,t}$ for an arbitrary $p > 0$. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0,1)$. We can write $Y_{s,t} = \\sigma_{s,t} Z$. Then,\n$$\n\\mathbb{E}[|Y_{s,t}|^p] = \\mathbb{E}[|\\sigma_{s,t} Z|^p] = \\sigma_{s,t}^p \\mathbb{E}[|Z|^p] = (\\mathbb{E}[|X_t - X_s|^2])^{p/2} \\mathbb{E}[|Z|^p].\n$$\nThe quantity $\\mathbb{E}[|Z|^p]$ is a finite constant for any $p>0$. Let's denote this constant by $M_p$. It can be expressed in terms of the Gamma function as $M_p = 2^{p/2}\\pi^{-1/2}\\Gamma(\\frac{p+1}{2})$.\nSubstituting the given inequality for the second moment, we obtain a bound for the $p$-th moment:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq (C|t-s|^{2H})^{p/2} M_p = C^{p/2} M_p |t-s|^{pH}.\n$$\nLet's define a new constant $K_p = C^{p/2} M_p$. The moment inequality becomes:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq K_p |t-s|^{pH}.\n$$\nTo apply the KCT, we need to find a value of $p>0$ such that the exponent $pH$ is strictly greater than $1$. That is, we need to find $p>0$ and $\\alpha>0$ such that $pH = 1+\\alpha$. This is equivalent to finding a $p>0$ such that $pH > 1$.\nSince $H>0$ is given, we can always choose such a $p$. For example, we can choose any $p > 1/H$. With such a choice, we set $\\alpha = pH - 1 > 0$. Then the condition of the KCT is satisfied with constants $p$, $\\alpha$, and $K=K_p$.\n\nTherefore, the condition that there exist constants $C>0$ and $H>0$ such that $\\mathbb{E}[|X_{t} - X_{s}|^{2}] \\leq C |t-s|^{2H}$ is a sufficient condition to ensure the existence of a modification of $\\{X_t\\}$ with almost surely continuous sample paths. This completes the first part of the problem.\n\nNow, for the second part, we must determine the largest Hölder exponent $\\gamma_{\\mathrm{max}}$ guaranteed by this application of the KCT. The theorem guarantees that the sample paths of the modification are Hölder continuous for any exponent $\\gamma$ such that\n$$\n0  \\gamma  \\frac{\\alpha}{p}.\n$$\nSubstituting our expression $\\alpha = pH-1$, we find that the paths are Hölder continuous for any exponent $\\gamma$ satisfying\n$$\n0  \\gamma  \\frac{pH-1}{p} = H - \\frac{1}{p}.\n$$\nThis result is valid for any choice of $p$ such that $p > 1/H$. To find the best possible guarantee on the Hölder exponent, we should maximize the upper bound $H - 1/p$. This is achieved by making $p$ as large as possible. As we let $p \\to \\infty$, the term $1/p \\to 0$, and the upper bound for $\\gamma$ approaches $H$.\n\nThis means that for any $\\gamma_0  H$, we can find a sufficiently large $p$ such that $\\gamma_0  H - 1/p$. Specifically, we need $1/p  H - \\gamma_0$, which is equivalent to $p > 1/(H - \\gamma_0)$. Since $\\gamma_0  H$, $H-\\gamma_0 > 0$, so such a $p$ always exists.\nTherefore, the KCT guarantees that the sample paths are Hölder continuous for *every* exponent $\\gamma$ in the interval $(0, H)$.\n\nThe problem asks for the largest Hölder exponent $\\gamma_{\\mathrm{max}}$ that is guaranteed. This corresponds to the supremum of the set of guaranteed exponents, which is the interval $(0, H)$. The supremum of this set is $H$. The problem specifies that $\\gamma_{\\mathrm{max}} \\in (0,1)$, which is consistent with the typical range for $H$ in many applications (like for fractional Brownian motion), implying that the context is for $H \\in (0,1)$.\n\nThus, the largest Hölder exponent is $\\gamma_{\\mathrm{max}} = H$.", "answer": "$$\\boxed{H}$$", "id": "2983270"}, {"introduction": "With the general principle established, we now apply our tools to a canonical example: fractional Brownian motion (fBm), a process central to modeling long-range dependence. This exercise [@problem_id:2983264] provides hands-on practice in calculating the moments of a specific, named process and using the Kolmogorov Continuity Theorem to quantify its path regularity. You will see concretely how the famous Hurst parameter $H$ dictates the Hölder continuity of the sample paths, reinforcing the link between a process's covariance structure and its geometric properties.", "problem": "Let $\\{B_{t}^{H}\\}_{t \\ge 0}$ be a fractional Brownian motion with Hurst parameter $H \\in (0,1)$, defined as a centered Gaussian process with covariance $\\mathbb{E}[B_{t}^{H} B_{s}^{H}] = \\frac{1}{2} \\left(t^{2H} + s^{2H} - |t-s|^{2H}\\right)$ for all $s,t \\ge 0$. Fix an even integer $p \\ge 2$. Using the moment formula for centered Gaussian random variables and the covariance structure above, derive an upper bound of the form $\\mathbb{E}\\!\\left(|B_{t}^{H} - B_{s}^{H}|^{p}\\right) \\le C_{p} |t-s|^{Hp}$, where $C_{p}$ depends only on $p$ and not on $s,t$. Then invoke the Kolmogorov continuity theorem (KCT), which in one-dimensional time asserts that if there exist $p>0$ and $\\delta>0$ such that $\\mathbb{E}\\!\\left(|X_{t} - X_{s}|^{p}\\right) \\le K |t-s|^{1+\\delta}$ for all $s,t$ in a compact interval with some constant $K$, then there is a modification whose sample paths are Hölder continuous of any exponent $\\gamma \\in (0, \\delta/p)$, to deduce the maximal Hölder exponent guaranteed by this bound when $p$ is chosen so that $Hp1$. Express your final answer as a closed-form analytic expression in terms of $H$ and $p$.", "solution": "The problem requires us to perform a two-part analysis. First, we must derive an upper bound for the $p$-th moment of the increments of a fractional Brownian motion (fBm). Second, we must use this bound in conjunction with the Kolmogorov continuity theorem (KCT) to determine the maximal Hölder exponent guaranteed by this specific analysis.\n\n### Step 1: Derivation of the Moment Bound\n\nLet $\\{B_t^H\\}_{t \\ge 0}$ be a fractional Brownian motion with Hurst parameter $H \\in (0,1)$. By definition, it is a centered Gaussian process. This means that any linear combination of the random variables $B_t^H$ is a Gaussian random variable.\n\nConsider the increment of the process between times $s$ and $t$, which we denote as $X_{s,t} = B_t^H - B_s^H$. As a linear combination of two random variables from the process, $X_{s,t}$ is itself a Gaussian random variable. Since the process is centered, its mean is zero:\n$$\n\\mathbb{E}[X_{s,t}] = \\mathbb{E}[B_t^H - B_s^H] = \\mathbb{E}[B_t^H] - \\mathbb{E}[B_s^H] = 0 - 0 = 0\n$$\nSo, $X_{s,t}$ is a centered Gaussian random variable. Its distribution is fully characterized by its variance, $\\sigma_{s,t}^2 = \\mathbb{E}[X_{s,t}^2]$. We compute this variance using the given covariance function $\\mathbb{E}[B_u^H B_v^H] = \\frac{1}{2}(u^{2H} + v^{2H} - |u-v|^{2H})$.\n\n$$\n\\sigma_{s,t}^2 = \\mathbb{E}[(B_t^H - B_s^H)^2] = \\mathbb{E}[(B_t^H)^2] - 2\\mathbb{E}[B_t^H B_s^H] + \\mathbb{E}[(B_s^H)^2]\n$$\nThe variance of $B_u^H$ at any time $u$ is found by setting $v=u$ in the covariance function:\n$$\n\\mathbb{E}[(B_u^H)^2] = \\mathbb{E}[B_u^H B_u^H] = \\frac{1}{2}(u^{2H} + u^{2H} - |u-u|^{2H}) = \\frac{1}{2}(2u^{2H}) = u^{2H}\n$$\nSubstituting this and the covariance term back into the variance expression for the increment:\n$$\n\\sigma_{s,t}^2 = t^{2H} + s^{2H} - 2 \\left[ \\frac{1}{2}(t^{2H} + s^{2H} - |t-s|^{2H}) \\right]\n$$\n$$\n\\sigma_{s,t}^2 = t^{2H} + s^{2H} - (t^{2H} + s^{2H} - |t-s|^{2H})\n$$\n$$\n\\sigma_{s,t}^2 = t^{2H} + s^{2H} - t^{2H} - s^{2H} + |t-s|^{2H} = |t-s|^{2H}\n$$\nThus, the increment $B_t^H - B_s^H$ is a centered Gaussian random variable with variance $|t-s|^{2H}$. We can write $B_t^H - B_s^H \\sim \\mathcal{N}(0, |t-s|^{2H})$.\nLet $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0,1)$. Then we can represent the increment as:\n$$\nB_t^H - B_s^H = |t-s|^H Z\n$$\nWe are asked to find an upper bound for $\\mathbb{E}[|B_t^H - B_s^H|^p]$ where $p$ is an even integer and $p \\ge 2$.\n$$\n\\mathbb{E}[|B_t^H - B_s^H|^p] = \\mathbb{E}[||t-s|^H Z|^p] = |t-s|^{Hp} \\mathbb{E}[|Z|^p]\n$$\nSince $p$ is an even integer, $|Z|^p = Z^p$. We need to compute the $p$-th moment of a standard normal distribution. For an even integer $p$, this is given by the formula for the moments of a Gaussian:\n$$\n\\mathbb{E}[Z^p] = (p-1)!! = (p-1)(p-3)\\cdots 3 \\cdot 1\n$$\nThis constant depends only on $p$. Let's denote it by $C_p = (p-1)!!$. So, we have an exact expression for the moment:\n$$\n\\mathbb{E}[|B_t^H - B_s^H|^p] = C_p |t-s|^{Hp}\n$$\nThis serves as the required upper bound $\\mathbb{E}[|B_t^H - B_s^H|^p] \\le C_p |t-s|^{Hp}$, where the inequality is in fact an equality.\n\n### Step 2: Application of the Kolmogorov Continuity Theorem\n\nThe Kolmogorov continuity theorem (one-dimensional version) states that if a stochastic process $\\{X_t\\}$ satisfies the condition\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\le K|t-s|^{1+\\delta}\n$$\nfor some constants $p>0$, $K>0$, $\\delta>0$, and for all $s,t$ in a compact interval, then there exists a modification of the process which is almost surely Hölder continuous with any exponent $\\gamma$ such that $\\gamma \\in (0, \\delta/p)$. The problem asks for the maximal Hölder exponent guaranteed by this theorem, which is the supremum of this interval for $\\gamma$.\n\nWe compare our derived moment bound with the condition of the theorem:\n$$\n\\mathbb{E}[|B_t^H - B_s^H|^p] = C_p |t-s|^{Hp}\n$$\nWe identify the constants by setting $K = C_p$ and matching the exponents:\n$$\n1 + \\delta = Hp\n$$\nThe problem specifies that we must choose $p$ such that $Hp > 1$. This condition ensures that $\\delta = Hp - 1 > 0$, which is a necessary requirement for the theorem to yield a non-trivial conclusion about Hölder continuity.\n\nWith $\\delta = Hp - 1$, the theorem guarantees that the sample paths of a modification of fBm are Hölder continuous for any exponent $\\gamma$ satisfying:\n$$\n0  \\gamma  \\frac{\\delta}{p}\n$$\nThe maximal Hölder exponent guaranteed by this bound is the supremum of the possible values for $\\gamma$:\n$$\n\\gamma_{\\max} = \\frac{\\delta}{p} = \\frac{Hp - 1}{p} = H - \\frac{1}{p}\n$$\nThis expression gives the guaranteed Hölder exponent in terms of the Hurst parameter $H$ and the chosen moment order $p$. It is important to note that this is the exponent guaranteed by this specific application of KCT; the true Hölder exponent of fBm paths is known to be any value less than $H$, which can be seen as the limit of our result as $p \\to \\infty$. However, for a fixed even integer $p$ satisfying $Hp>1$, the guaranteed exponent is precisely $H - 1/p$.", "answer": "$$\\boxed{H - \\frac{1}{p}}$$", "id": "2983264"}, {"introduction": "We have seen the power of the Kolmogorov Continuity Theorem in action, but how does this remarkable result truly work? This final exercise [@problem_id:2983299] invites you to look \"under the hood\" by reconstructing the elegant core argument of the theorem's proof using a dyadic chaining method. By building a random modulus of continuity from first principles—employing only basic tools like Markov's inequality and the Borel–Cantelli lemma—you will gain a profound and lasting intuition for the deep connection between moment bounds and sample path regularity.", "problem": "Consider a one-dimensional Itô diffusion $X=(X_{t})_{t\\in[0,1]}$ solving the stochastic differential equation (SDE) $dX_{t}=b(X_{t})\\,dt+\\sigma(X_{t})\\,dW_{t}$ on the compact interval $[0,1]$, where $W$ is a standard Brownian motion, and the coefficients $b$ and $\\sigma$ are measurable functions ensuring existence of a weak solution with finite moments. Assume that for some fixed $p>0$ and $\\eta>0$, there exists a finite constant $C>0$ such that for all $s,t\\in[0,1]$,\n$$\n\\mathbb{E}\\big(|X_{t}-X_{s}|^{p}\\big)\\le C\\,|t-s|^{1+\\eta}.\n$$\nA random modulus of continuity is a random function $w:(0,1]\\to[0,\\infty)$ such that for each $\\delta\\in(0,1]$,\n$$\n\\sup_{|t-s|\\le\\delta}|X_{t}-X_{s}|\\le w(\\delta)\\quad\\text{almost surely (a.s.)}.\n$$\nUsing only foundational tools from probability theory (Markov's inequality, the union bound, and the Borel–Cantelli lemma), and elementary chaining over dyadic partitions of $[0,1]$, construct a random modulus of continuity $w(\\delta)$ and prove that for any $\\gamma\\eta/p$ there holds $w(\\delta)=O(\\delta^{\\gamma})$ a.s. as $\\delta\\downarrow 0$. Finally, determine the largest exponent $\\gamma^{\\star}$ (expressed solely in terms of $p$ and $\\eta$) such that for every $\\gamma\\gamma^{\\star}$ the above conclusion holds. Report your final answer as a single simplified analytic expression in terms of $p$ and $\\eta$.", "solution": "This problem asks us to reconstruct the core argument of the Kolmogorov continuity theorem's proof using a dyadic chaining method. The goal is to show that the given moment condition, $\\mathbb{E}\\big[|X_{t}-X_{s}|^{p}\\big]\\le C\\,|t-s|^{1+\\eta}$, implies that the process has a modulus of continuity $w(\\delta)$ that behaves like $\\delta^\\gamma$ for any $\\gamma  \\eta/p$.\n\nThe strategy involves three main steps:\n1.  Use Markov's inequality and the union bound to control the probability of large increments over dyadic time intervals.\n2.  Apply the Borel–Cantelli lemma to show that, almost surely, these increments are well-behaved for all sufficiently fine partitions.\n3.  Use a \"chaining\" argument to extend this control from the dyadic points to all points in the interval $[0,1]$.\n\nLet's fix an exponent $\\gamma$ such that $0  \\gamma  \\eta/p$.\nFor each integer $n \\ge 1$, we consider the dyadic partition of $[0,1]$ with points $t_k = k 2^{-n}$ for $k=0, 1, \\dots, 2^n$. The length of each interval is $2^{-n}$.\nLet's find the probability that the increment over one such interval, $[t_k, t_{k+1}]$, exceeds the threshold $(2^{-n})^\\gamma$. Using Markov's inequality and the given moment condition:\n$$\n\\mathbb{P}\\left(|X_{t_{k+1}} - X_{t_k}| > (2^{-n})^\\gamma\\right) \\le \\frac{\\mathbb{E}\\left[|X_{t_{k+1}} - X_{t_k}|^p\\right]}{((2^{-n})^\\gamma)^p} \\le \\frac{C |t_{k+1}-t_k|^{1+\\eta}}{(2^{-n})^{p\\gamma}} = \\frac{C (2^{-n})^{1+\\eta}}{2^{-np\\gamma}} = C 2^{-n(1+\\eta-p\\gamma)}.\n$$\nNow, let $E_n$ be the event that *at least one* of these increments at level $n$ is too large. There are $2^n$ such intervals, so by the union bound:\n$$\n\\mathbb{P}(E_n) \\le \\sum_{k=0}^{2^n-1} \\mathbb{P}\\left(|X_{t_{k+1}} - X_{t_k}| > (2^{-n})^\\gamma\\right) \\le 2^n \\cdot C 2^{-n(1+\\eta-p\\gamma)} = C 2^{n(p\\gamma-\\eta)}.\n$$\nTo apply the Borel–Cantelli lemma, we need to check if the series $\\sum_{n=1}^\\infty \\mathbb{P}(E_n)$ converges. This is a geometric series with ratio $2^{p\\gamma-\\eta}$. It converges if and only if the exponent is negative, i.e., $p\\gamma - \\eta  0$, which is exactly the condition $\\gamma  \\eta/p$ that we assumed.\n\nSince $\\sum \\mathbb{P}(E_n)  \\infty$, the Borel–Cantelli lemma tells us that with probability 1, only a finite number of the events $E_n$ will occur. This means for almost every sample path $\\omega$, there exists an integer $N(\\omega)$ such that for all $n \\ge N(\\omega)$, the event $E_n$ does not happen. In other words, for all $n \\ge N(\\omega)$ and all $k \\in \\{0, \\dots, 2^n-1\\}$, we have:\n$$\n|X_{t_{k+1}}(\\omega) - X_{t_k}(\\omega)| \\le (2^{-n})^\\gamma.\n$$\nThis establishes control over the increments on the dense set of dyadic points. A more detailed chaining argument (which is a standard part of the full proof) shows that this bound on dyadic increments implies that the process has a continuous modification which is Hölder continuous with exponent $\\gamma$. This means there is a random constant $K_\\gamma(\\omega)$ such that for all $s,t \\in [0,1]$, $|X_t(\\omega) - X_s(\\omega)| \\le K_\\gamma(\\omega)|t-s|^\\gamma$.\n\nThis implies that for any $\\delta \\in (0,1]$, the random modulus of continuity satisfies $w(\\delta) = \\sup_{|t-s|\\le\\delta}|X_{t}-X_{s}| \\le K_\\gamma \\delta^\\gamma$ almost surely. By definition, this means $w(\\delta) = O(\\delta^\\gamma)$ a.s. as $\\delta \\downarrow 0$.\n\nThis entire argument works for any $\\gamma$ in the interval $(0, \\eta/p)$. The problem asks for the largest exponent $\\gamma^\\star$ such that the conclusion holds for all $\\gamma  \\gamma^\\star$. This is the supremum of the interval $(0, \\eta/p)$.\n\nThus, $\\gamma^\\star = \\eta/p$.", "answer": "$$\\boxed{\\frac{\\eta}{p}}$$", "id": "2983299"}]}