{"hands_on_practices": [{"introduction": "Before we can analyze the properties of a sample path, we must first be certain that a continuous path even exists. This practice will guide you through a foundational argument using Kolmogorov's continuity theorem, showing how moment estimates on a process's increments guarantee the existence of a continuous version. This exercise [@problem_id:2994569] is fundamental for understanding why we can confidently speak of \"continuous sample paths\" for solutions to Stochastic Differential Equations (SDEs) under standard conditions.", "problem": "Consider a $d$-dimensional Itô diffusion $\\{X_{t}\\}_{t \\in [0,T]}$ defined on a complete filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$ by the stochastic differential equation\n$$\ndX_{t} = b(X_{t})\\,dt + \\sigma(X_{t})\\,dW_{t}, \\quad X_{0} \\in \\mathbb{R}^{d},\n$$\nwhere $W_{t}$ is a standard $m$-dimensional Brownian motion and $b:\\mathbb{R}^{d} \\to \\mathbb{R}^{d}$ and $\\sigma:\\mathbb{R}^{d} \\to \\mathbb{R}^{d \\times m}$ satisfy the global Lipschitz and linear growth conditions:\n$$\n|b(x)-b(y)| + \\|\\sigma(x)-\\sigma(y)\\| \\leq L |x-y| \\quad \\text{for all } x,y \\in \\mathbb{R}^{d},\n$$\n$$\n|b(x)| + \\|\\sigma(x)\\| \\leq K (1+|x|) \\quad \\text{for all } x \\in \\mathbb{R}^{d},\n$$\nwith constants $L,K > 0$. Starting from Kolmogorov's continuity theorem and using only fundamental properties of Itô integrals, Brownian motion, and the stated Lipschitz and growth conditions, derive the minimal moment exponent in the sense of the infimum $p_{\\star}$ over all $p>0$ such that one can guarantee the existence of a continuous version of $\\{X_{t}\\}_{t \\in [0,T]}$ on $[0,T]$ via moment increment bounds and Kolmogorov's criterion. Your final answer must be a single real number equal to that infimum $p_{\\star}$. No rounding is required.", "solution": "The problem requires the determination of the infimum $p_{\\star}$ of all positive exponents $p$ for which the existence of a continuous version of the Itô process $\\{X_t\\}_{t \\in [0,T]}$ can be proven using Kolmogorov's continuity theorem.\n\nKolmogorov's continuity theorem asserts that a stochastic process $\\{X_t\\}_{t \\in [0,T]}$ defined on a probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$ possesses a continuous modification if there exist constants $C > 0$, $p > 0$, and $\\alpha > 0$ such that for all $s,t \\in [0,T]$, the following moment condition is satisfied:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq C |t-s|^{1+\\alpha}\n$$\nThe core of the task is to establish a bound on the $p$-th moment of the increment $|X_t - X_s|$ and to identify for which values of $p$ the resulting exponent of $|t-s|$ is strictly greater than $1$.\n\nThe Itô process $\\{X_t\\}$ is defined by the stochastic differential equation:\n$$\ndX_{t} = b(X_{t})\\,dt + \\sigma(X_{t})\\,dW_{t}\n$$\nFor any $s, t \\in [0,T]$ with $s < t$, the increment $X_t - X_s$ can be written in integral form as:\n$$\nX_t - X_s = \\int_s^t b(X_u)\\,du + \\int_s^t \\sigma(X_u)\\,dW_u\n$$\nWe need to estimate the $p$-th moment $\\mathbb{E}[|X_t - X_s|^p]$ for $p>0$. Using the inequality $|a+b|^p \\leq c_p(|a|^p + |b|^p)$, where $c_p = 2^{p-1}$ for $p \\geq 1$ and $c_p = 1$ for $0 < p \\leq 1$, we can separate the contributions from the drift and diffusion terms:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq c_p \\left( \\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right] + \\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right] \\right)\n$$\n\nFirst, we bound the drift term, $\\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right]$. Using Hölder's inequality (or Jensen's inequality for integrals when $p \\geq 1$), we have:\n$$\n\\left|\\int_s^t b(X_u)\\,du\\right|^p \\leq \\left(\\int_s^t |b(X_u)|\\,du\\right)^p \\leq (t-s)^{p-1} \\int_s^t |b(X_u)|^p\\,du\n$$\nTaking the expectation and applying Fubini's theorem:\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right] \\leq (t-s)^{p-1} \\int_s^t \\mathbb{E}[|b(X_u)|^p]\\,du\n$$\nA standard result for SDEs with coefficients satisfying the global Lipschitz and linear growth conditions is that for any $q \\ge 1$ and $T>0$, the moments of $X_t$ are uniformly bounded on $[0,T]$, i.e., $\\sup_{t \\in [0,T]} \\mathbb{E}[|X_t|^q] < \\infty$. Given the linear growth condition $|b(x)| \\leq K(1+|x|)$, we have $|b(x)|^p \\leq K^p(1+|x|)^p \\leq c_p' K^p (1+|x|^p)$ for some constant $c_p'$. Consequently, $\\mathbb{E}[|b(X_u)|^p]$ is uniformly bounded on $[0,T]$ by some constant $C_{b,p,T}$.\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t b(X_u)\\,du\\right|^p\\right] \\leq (t-s)^{p-1} \\int_s^t C_{b,p,T}\\,du = C_{b,p,T} (t-s)^p\n$$\nThis bound holds for $p \\geq 1$. A similar argument using Jensen's inequality for expectations demonstrates this bound also holds for $0 < p < 1$.\n\nSecond, we bound the diffusion term, $\\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right]$. We apply the Burkholder-Davis-Gundy (BDG) inequality, which states that for any $p > 0$, there exists a constant $C_p > 0$ such that:\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right] \\leq C_p \\mathbb{E}\\left[ \\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\right]\n$$\nwhere $\\|\\cdot\\|$ denotes the Frobenius norm on $\\mathbb{R}^{d \\times m}$. We now need to bound the right-hand side.\nIf $p \\geq 2$, then the exponent $p/2 \\geq 1$. By Hölder's inequality:\n$$\n\\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\leq (t-s)^{p/2 - 1} \\int_s^t (\\|\\sigma(X_u)\\|^2)^{p/2}\\,du = (t-s)^{p/2-1} \\int_s^t \\|\\sigma(X_u)\\|^p\\,du\n$$\nTaking the expectation and using the uniform boundedness of moments of $\\sigma(X_u)$ (which follows from the linear growth condition on $\\sigma$ and moment bounds on $X_u$), we find a constant $C_{\\sigma,p,T}$:\n$$\n\\mathbb{E}\\left[ \\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\right] \\leq (t-s)^{p/2-1} \\int_s^t \\mathbb{E}[\\|\\sigma(X_u)\\|^p]\\,du \\leq C_{\\sigma,p,T} (t-s)^{p/2}\n$$\nIf $0 < p < 2$, then the exponent $p/2 \\in (0,1)$. We can use Jensen's inequality for the concave function $z \\mapsto z^{p/2}$ on the expectation:\n$$\n\\mathbb{E}\\left[ \\left( \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right)^{p/2} \\right] \\leq \\left( \\mathbb{E}\\left[ \\int_s^t \\|\\sigma(X_u)\\|^2\\,du \\right] \\right)^{p/2} = \\left( \\int_s^t \\mathbb{E}[\\|\\sigma(X_u)\\|^2]\\,du \\right)^{p/2}\n$$\nSince $\\mathbb{E}[\\|\\sigma(X_u)\\|^2]$ is uniformly bounded on $[0,T]$ by some constant $C'_{\\sigma,p,T}$, we get:\n$$\n\\left( \\int_s^t C'_{\\sigma,p,T}\\,du \\right)^{p/2} = (C'_{\\sigma,p,T}(t-s))^{p/2} = (C'_{\\sigma,p,T})^{p/2} (t-s)^{p/2}\n$$\nThus, for any $p > 0$, the diffusion term is bounded by a multiple of $(t-s)^{p/2}$:\n$$\n\\mathbb{E}\\left[\\left|\\int_s^t \\sigma(X_u)\\,dW_u\\right|^p\\right] \\leq K_p (t-s)^{p/2}\n$$\nfor some constant $K_p$.\n\nCombining the bounds for the drift and diffusion terms, we have for any $p>0$:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq c_p \\left( C_{b,p,T} (t-s)^p + K_p (t-s)^{p/2} \\right)\n$$\nFor small $|t-s| > 0$, the overall rate of convergence to zero is determined by the term with the smaller exponent. Since $p > p/2$ for all $p > 0$, the dominant term is $(t-s)^{p/2}$. Therefore, there exists a constant $C'_{p,T}$ such that for all $s,t \\in [0,T]$:\n$$\n\\mathbb{E}[|X_t - X_s|^p] \\leq C'_{p,T} |t-s|^{p/2}\n$$\nTo satisfy the condition of Kolmogorov's continuity theorem, the exponent of $|t-s|$ must be strictly greater than $1$. That is, we require:\n$$\n\\frac{p}{2} > 1 \\implies p > 2\n$$\nThis derivation shows that for any chosen moment exponent $p > 2$, we can establish the necessary bound $\\mathbb{E}[|X_t - X_s|^p] \\le C |t-s|^{1+\\alpha}$ with $1+\\alpha = p/2 > 1$, thus guaranteeing the existence of a continuous modification of $\\{X_t\\}$. The set of exponents $p$ for which this argument holds is $(2, \\infty)$. The problem asks for the infimum of this set.\nThe infimum of the set $(2, \\infty)$ is $2$.\nTherefore, the minimal moment exponent required by this method is $p_{\\star} = 2$.", "answer": "$$\\boxed{2}$$", "id": "2994569"}, {"introduction": "Having established the existence of continuous paths, we now seek to quantify their regularity, or \"roughness\". This problem explores the concept of $p$-variation, a powerful tool that reveals how a solution to an SDE driven by Brownian motion inherits the path roughness of the underlying noise. By determining the critical threshold for finite $p$-variation [@problem_id:2994547], you will gain a concrete understanding of why these paths are fundamentally non-differentiable and possess a roughness identical to that of Brownian motion.", "problem": "Consider a one-dimensional stochastic differential equation (SDE) on a fixed finite horizon $[0,T]$ given by\n$$\ndX_{t} \\;=\\; b(X_{t})\\,dt \\;+\\; \\sigma(X_{t})\\,dW_{t}, \\qquad X_{0}\\in\\mathbb{R},\n$$\nwhere $W$ is a standard Brownian motion, and the drift $b:\\mathbb{R}\\to\\mathbb{R}$ and diffusion coefficient $\\sigma:\\mathbb{R}\\to\\mathbb{R}$ are globally Lipschitz and bounded functions. Let the sup norms be denoted by $\\|b\\|_{\\infty} := \\sup_{x\\in\\mathbb{R}} |b(x)|$ and $\\|\\sigma\\|_{\\infty} := \\sup_{x\\in\\mathbb{R}} |\\sigma(x)|$, and assume $T>0$ is fixed.\n\nFor $p\\ge 1$, define the $p$-variation of a continuous function $Y:[0,T]\\to\\mathbb{R}$ by\n$$\nV_{p}(Y;[0,T]) \\;:=\\; \\sup_{\\Pi}\\;\\sum_{i=0}^{n-1} \\big| Y_{t_{i+1}} - Y_{t_{i}} \\big|^{p},\n$$\nwhere the supremum is taken over all finite partitions $\\Pi=\\{0=t_{0}<t_{1}<\\cdots<t_{n}=T\\}$ of $[0,T]$.\n\nStarting from the decomposition of $X$ into its drift and martingale components, and using only foundational facts about bounded variation paths, continuous local martingales, and classical path properties of Brownian motion, do the following:\n\n1. Derive an almost sure upper bound on $V_{p}(X;[0,T])$ in terms of $V_{p}(W;[0,\\|\\sigma\\|_{\\infty}^{2}T])$, $T$, and the sup norms $\\|b\\|_{\\infty}$ and $\\|\\sigma\\|_{\\infty}$. Your bound should be explicit and obtained by first bounding the contribution of the drift path and then reducing the martingale part to a Brownian motion via a monotone time change.\n\n2. Determine the minimal threshold value $p_{\\star}$ such that, almost surely, $V_{p}(X;[0,T])<\\infty$ for all $p>p_{\\star}$ and $V_{p}(X;[0,T])=\\infty$ for all $p\\le p_{\\star}$.\n\nReport the threshold $p_{\\star}$ as your final answer. The final answer must be a single real number. No rounding is required.", "solution": "The stochastic differential equation is given in its differential form as $dX_{t} = b(X_{t})\\,dt + \\sigma(X_{t})\\,dW_{t}$ with initial condition $X_{0}\\in\\mathbb{R}$. In integral form, the solution $X_t$ over the time horizon $[0,T]$ is written as:\n$$\nX_{t} \\;=\\; X_{0} \\;+\\; \\int_{0}^{t} b(X_{s})\\,ds \\;+\\; \\int_{0}^{t} \\sigma(X_{s})\\,dW_{s}\n$$\nWe can decompose the process $X_t$ into a constant initial value $X_0$, a drift component $A_t$, and a martingale component $M_t$:\n$$\nA_{t} := \\int_{0}^{t} b(X_{s})\\,ds \\qquad \\text{and} \\qquad M_{t} := \\int_{0}^{t} \\sigma(X_{s})\\,dW_{s}\n$$\nThus, $X_t = X_0 + A_t + M_t$. The $p$-variation is invariant under addition of a constant, so $V_{p}(X;[0,T]) = V_{p}(A+M;[0,T])$.\n\nFor any two continuous functions $Y$ and $Z$, and for $p \\ge 1$, the function $f(x)=|x|^p$ is convex. By Minkowski's inequality (or simply $|a+b| \\le |a|+|b|$ and convexity), we have $|a+b|^p \\le (2\\max(|a|,|b|))^p \\le 2^p \\max(|a|^p, |b|^p) \\le 2^p(|a|^p+|b|^p)$. A tighter and more standard inequality for $p \\ge 1$ is $|a+b|^p \\le 2^{p-1}(|a|^p + |b|^p)$. Applying this to the increments of $A_t+M_t$ over an interval $[t_i, t_{i+1}]$ of a partition $\\Pi$:\n$$\n| (A_{t_{i+1}}+M_{t_{i+1}}) - (A_{t_{i}}+M_{t_{i}}) |^p = | (A_{t_{i+1}}-A_{t_{i}}) + (M_{t_{i+1}}-M_{t_{i}}) |^p \\le 2^{p-1} \\left( |A_{t_{i+1}}-A_{t_{i}}|^p + |M_{t_{i+1}}-M_{t_{i}}|^p \\right)\n$$\nSumming over all intervals in the partition and taking the supremum over all partitions $\\Pi$, we obtain a bound for the $p$-variation of the sum:\n$$\nV_{p}(X;[0,T]) \\;\\le\\; 2^{p-1} \\left( V_{p}(A;[0,T]) + V_{p}(M;[0,T]) \\right)\n$$\n\n### Part 1: Derivation of the Upper Bound\n\nWe will bound the $p$-variation of the drift and martingale components separately.\n\n**1. Bounding the $p$-variation of the drift component, $V_{p}(A;[0,T])$:**\nThe drift path is $A_t = \\int_0^t b(X_s)ds$. Since $b$ is bounded by $\\|b\\|_{\\infty}$, the path $A_t$ is Lipschitz continuous. For any $s, t \\in [0,T]$:\n$$\n|A_t - A_s| = \\left| \\int_s^t b(X_u)du \\right| \\le \\int_s^t |b(X_u)|du \\le \\|b\\|_{\\infty} |t-s|\n$$\nConsider any finite partition $\\Pi=\\{0=t_0 < t_1 < \\dots < t_n = T\\}$. The increment over $[t_i, t_{i+1}]$ is bounded by $|A_{t_{i+1}}-A_{t_{i}}| \\le \\|b\\|_{\\infty}(t_{i+1}-t_i)$.\nThe sum for the $p$-variation is:\n$$\n\\sum_{i=0}^{n-1} |A_{t_{i+1}}-A_{t_{i}}|^p \\le \\sum_{i=0}^{n-1} \\left( \\|b\\|_{\\infty}(t_{i+1}-t_i) \\right)^p = \\|b\\|_{\\infty}^{p} \\sum_{i=0}^{n-1} (t_{i+1}-t_i)^p\n$$\nTo find an upper bound for the supremum over all partitions, we can bound the term $\\sum (t_{i+1}-t_i)^p$. Since $p \\ge 1$, we have $\\sum_{i=0}^{n-1} h_i^p \\le (\\sum_{i=0}^{n-1} h_i)^p$ for non-negative $h_i$. Here, $\\sum (t_{i+1}-t_i) = T$.\nSo, $\\sum_{i=0}^{n-1} (t_{i+1}-t_i)^p \\le T^p$. The supremum is achieved for the trivial partition $\\{0,T\\}$.\nTherefore, we have a simple upper bound for the $p$-variation of $A_t$:\n$$\nV_{p}(A;[0,T]) = \\sup_{\\Pi} \\sum_{i=0}^{n-1} |A_{t_{i+1}}-A_{t_{i}}|^p \\le (\\|b\\|_{\\infty}T)^p\n$$\n\n**2. Bounding the $p$-variation of the martingale component, $V_{p}(M;[0,T])$:**\nThe martingale component is $M_t = \\int_0^t \\sigma(X_s)dW_s$. This is a continuous local martingale. Its quadratic variation process is $\\langle M \\rangle_t = \\int_0^t \\sigma^2(X_s)ds$.\nBy the Dambis-Dubins-Schwarz theorem, there exists a standard Brownian motion, which we denote $\\tilde{W}$, such that $M_t = \\tilde{W}_{\\langle M \\rangle_t}$ for all $t \\ge 0$.\nThe process $\\tau(t) := \\langle M \\rangle_t$ is a continuous, non-decreasing time-change.\nThe $p$-variation of $M_t$ is given by:\n$$\nV_{p}(M;[0,T]) = \\sup_{\\Pi} \\sum_{i=0}^{n-1} |M_{t_{i+1}}-M_{t_i}|^p = \\sup_{\\Pi} \\sum_{i=0}^{n-1} |\\tilde{W}_{\\tau(t_{i+1})} - \\tilde{W}_{\\tau(t_i)}|^p\n$$\nLet a partition $\\Pi=\\{t_i\\}$ of $[0,T]$ be given. Let $s_i = \\tau(t_i)$. Since $\\tau(t)$ is continuous and non-decreasing, the set of points $\\{s_i\\}$ forms an ordered set $0=s_0 \\le s_1 \\le \\dots \\le s_n = \\tau(T)$. This set induces a partition of the interval $[0, \\tau(T)]$. The supremum over all partitions $\\Pi$ of $[0,T]$ is thus bounded by the supremum over all partitions of the time-changed interval $[0, \\tau(T)]$:\n$$\nV_{p}(M;[0,T]) \\le V_{p}(\\tilde{W}; [0, \\tau(T)])\n$$\nThe length of this new time interval, $\\tau(T)$, is a random variable. We can bound it using the fact that $\\sigma$ is bounded by $\\|\\sigma\\|_{\\infty}$:\n$$\n\\tau(T) = \\int_0^T \\sigma^2(X_s)ds \\le \\int_0^T \\|\\sigma\\|_{\\infty}^2 ds = \\|\\sigma\\|_{\\infty}^2 T\n$$\nThe $p$-variation is a non-decreasing function of the length of the interval. Therefore:\n$$\nV_{p}(\\tilde{W}; [0, \\tau(T)]) \\le V_{p}(\\tilde{W}; [0, \\|\\sigma\\|_{\\infty}^2 T])\n$$\nSince $\\tilde{W}$ is a standard Brownian motion, it has the same law as $W$. So, we can write the bound in terms of $W$:\n$$\nV_{p}(M;[0,T]) \\le V_{p}(W; [0, \\|\\sigma\\|_{\\infty}^2 T]) \\quad \\text{almost surely.}\n$$\n\n**3. Final Upper Bound:**\nCombining the bounds for the drift and martingale parts, we get the almost sure upper bound on $V_{p}(X;[0,T])$:\n$$\nV_{p}(X;[0,T]) \\le 2^{p-1} \\left( (\\|b\\|_{\\infty}T)^p + V_{p}(W; [0, \\|\\sigma\\|_{\\infty}^2 T]) \\right)\n$$\n\n### Part 2: Determination of the Threshold $p_{\\star}$\n\nA classical result from Paul Lévy concerning the path properties of Brownian motion states that, for any time interval $[0,S]$ with $S>0$, a standard Brownian motion $W$ has sample paths with:\n- Finite $p$-variation for all $p>2$, i.e., $V_p(W;[0,S]) < \\infty$ a.s.\n- Infinite $p$-variation for all $p\\le2$, i.e., $V_p(W;[0,S]) = \\infty$ a.s.\n\nThe path regularity of $X_t$ is determined by the interplay between its drift component $A_t$ and martingale component $M_t$.\n\nThe drift component $A_t$ is a Lipschitz path, so it has finite $1$-variation, $V_1(A;[0,T]) \\le \\|b\\|_{\\infty}T < \\infty$. A foundational result states that if a path has finite $q$-variation, its $p$-variation is zero for any $p>q$. Thus, for any $p>1$, $V_p(A;[0,T]) = 0$.\n\nNow we analyze the finiteness of $V_p(X;[0,T])$.\nFor $p>1$, we have $V_p(A;[0,T])=0$. The inequalities relating the variations are:\n$$\nV_{p}(X;[0,T]) \\le 2^{p-1} V_{p}(M;[0,T])\n$$\n$$\nV_{p}(M;[0,T]) = V_{p}(X-A;[0,T]) \\le 2^{p-1}(V_{p}(X;[0,T]) + V_{p}(A;[0,T])) = 2^{p-1}V_{p}(X;[0,T])\n$$\nThese two inequalities imply that for $p>1$, $V_p(X;[0,T])$ is finite if and only if $V_p(M;[0,T])$ is finite. So, for $p>1$, the threshold $p_{\\star}$ for $X_t$ is the same as for its martingale part $M_t$.\n\n**Case 1: $p > 2$**\nSince $p>2$, we know $V_p(W; [0, \\|\\sigma\\|_{\\infty}^2 T]) < \\infty$ almost surely. From the bound derived in Part 1, we have\n$$\nV_p(M;[0,T]) \\le V_p(W; [0, \\|\\sigma\\|_{\\infty}^2 T]) < \\infty \\quad \\text{a.s.}\n$$\nSince $p>2>1$, the finiteness of $V_p(M)$ implies the finiteness of $V_p(X)$. Thus, for $p>2$, $V_p(X;[0,T]) < \\infty$ a.s.\n\n**Case 2: $p \\le 2$**\nWe need to show $V_p(X;[0,T]) = \\infty$ a.s., assuming the SDE is non-trivial (i.e., $\\sigma$ is not identically zero).\nLet's first establish this for the martingale part $M_t$. We want to show $V_p(M;[0,T]) = \\infty$ a.s. for $p \\le 2$. Unless $\\sigma(X_s)=0$ for almost every $s \\in [0,T]$ (a trivial case we exclude), the time-change $\\tau(T) = \\int_0^T \\sigma^2(X_s)ds > 0$ almost surely. Let $S=\\tau(T)$. The Brownian path $\\tilde{W}$ on $[0,S]$ has infinite $p$-variation for $p \\le 2$. We need to show this property is inherited by $M_t = \\tilde{W}_{\\tau(t)}$.\nFor any partition $\\Pi'=\\{0=s_0 < s_1 < \\dots < s_m=S\\}$ of $[0,S]$, we know $\\sum_{j=0}^{m-1} |\\tilde{W}_{s_{j+1}} - \\tilde{W}_{s_j}|^p$ can be made arbitrarily large by choosing a suitable partition.\nThe function $\\tau:[0,T] \\to [0,S]$ is continuous and surjective a.s. Let $t_j = \\min\\{u \\in [0,T] : \\tau(u) = s_j\\}$. This defines an ordered set of points $0=t_0 \\le t_1 \\le \\dots \\le t_m=T$. We can form a partition $\\Pi$ of $[0,T]$ containing these points. The variation sum over $\\Pi$ will be at least the sum over the increments between the points $t_j$:\n$$\nV_p(M;[0,T]) \\ge \\sum_{j=0}^{m-1} |M_{t_{j+1}} - M_{t_j}|^p = \\sum_{j=0}^{m-1} |\\tilde{W}_{\\tau(t_{j+1})} - \\tilde{W}_{\\tau(t_j)}|^p \\ge \\sum_{j=0}^{m-1} |\\tilde{W}_{s_{j+1}} - \\tilde{W}_{s_j}|^p\n$$\nSince the right-hand side can be made arbitrarily large by choosing partitions $\\Pi'$ of $[0,S]$, we must have $V_p(M;[0,T]) = \\infty$ a.s for $p \\le 2$.\nNow we relate this to $V_p(X;[0,T])$.\n- For $p \\in (1, 2]$: As shown before, $V_p(X)$ is finite iff $V_p(M)$ is. Since $V_p(M)=\\infty$, it follows that $V_p(X)=\\infty$.\n- For $p=1$: We have $V_1(M;[0,T])=\\infty$ a.s. The drift path $A_t$ has finite $1$-variation, $V_1(A;[0,T]) < \\infty$. Assume, for contradiction, that $X_t=A_t+M_t$ has finite $1$-variation. Then $M_t = X_t - A_t$ would also need to have finite $1$-variation, since $V_1(M) \\le V_1(X) + V_1(A) < \\infty$, which contradicts the fact that $V_1(M)=\\infty$. Therefore, $V_1(X;[0,T])=\\infty$ a.s.\n\nCombining all cases, we find that $V_p(X;[0,T]) < \\infty$ a.s. for $p>2$ and $V_p(X;[0,T]) = \\infty$ a.s. for $p \\le 2$.\nThe minimal threshold value is therefore $p_{\\star}=2$.", "answer": "$$\\boxed{2}$$", "id": "2994547"}, {"introduction": "The existence and uniqueness of solution paths hinge on key regularity assumptions for an SDE's coefficients, particularly the Lipschitz condition. This exercise challenges that assumption, presenting a classic counterexample where a sequence of well-behaved SDEs converges to a limiting equation whose non-Lipschitz coefficient shatters pathwise uniqueness. Working through this problem [@problem_id:2994562] illuminates the profound importance of the Lipschitz condition and introduces the related concept of local time, a measure of a path's \"occupation density\" at a point.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\ge 0},\\mathbb{P})$ be a filtered probability space supporting a one-dimensional standard Brownian motion $W=(W_t)_{t\\ge 0}$. Consider, for each $n\\in\\mathbb{N}$, the stochastic differential equation (SDE)\n$$\ndX^{(n)}_t \\,=\\, \\sigma_n\\!\\left(X^{(n)}_t\\right)\\, dW_t,\\qquad X^{(n)}_0 \\,=\\, 0,\n$$\nwith diffusion coefficient $\\sigma_n:\\mathbb{R}\\to\\mathbb{R}$ given by\n$$\n\\sigma_n(x)\\,=\\,\\tanh(n x).\n$$\nAlso consider the limiting non-Lipschitz diffusion equation\n$$\ndX_t \\,=\\, \\operatorname{sgn}(X_t)\\, dW_t,\\qquad X_0 \\,=\\, 0,\n$$\nwhere $\\operatorname{sgn}(x)=\\mathbf{1}_{\\{x>0\\}}-\\mathbf{1}_{\\{x<0\\}}$.\n\nTasks:\n- Using solely the fundamental definitions of strong solutions for stochastic differential equations and the classical existence and uniqueness theory for Lipschitz coefficients, establish that for each fixed $n\\in\\mathbb{N}$ the process $X^{(n)}\\equiv 0$ is the unique strong solution on $[0,\\infty)$.\n- Argue from first principles why the coefficient $x\\mapsto \\operatorname{sgn}(x)$ violates the Lipschitz condition at $x=0$, and explain how this non-Lipschitz discontinuity leads to failure of pathwise uniqueness for the limiting equation. Construct, at a conceptual level, a nontrivial weak solution to the limiting equation that leaves $0$ immediately with probability $1$.\n- Using the above, construct a counterexample to continuity of solution maps in the uniform path norm: show that the sequence of strong solutions $(X^{(n)})_{n\\in\\mathbb{N}}$ does not converge in the uniform norm on $[0,T]$ to any nontrivial solution of the limiting equation for any fixed $T>0$; that is, demonstrate an explicit mechanism of divergence in path norm caused by the non-Lipschitz limit coefficient at $0$.\n- To identify a quantitative signature of the sample path irregularity at the non-Lipschitz point $x=0$, let $L_t^0(W)$ denote the symmetric local time accumulated by the standard Brownian motion $W$ at level $0$ up to time $t$. Compute the exact expression for the expectation $\\mathbb{E}\\!\\left[L_T^0(W)\\right]$ for a fixed $T>0$. Your final answer must be a single closed-form analytic expression involving $T$, with no rounding.\n\nProvide your final answer as the exact analytic expression specified in the last task. No units are required.", "solution": "The problem consists of four main tasks. We will address them in sequence.\n\nFirst task: To establish that for each fixed $n\\in\\mathbb{N}$, the process $X^{(n)}\\equiv 0$ is the unique strong solution to the SDE $dX^{(n)}_t = \\sigma_n(X^{(n)}_t)\\, dW_t$ with $X^{(n)}_0 = 0$.\n\nThe classical existence and uniqueness theorem for strong solutions to SDEs requires the coefficients to be locally Lipschitz and to satisfy a linear growth condition. We will show that for any fixed $n\\in\\mathbb{N}$, the coefficient $\\sigma_n(x) = \\tanh(nx)$ is globally Lipschitz.\nThe derivative of $\\sigma_n(x)$ with respect to $x$ is given by\n$$\n\\frac{d}{dx}\\sigma_n(x) = \\frac{d}{dx}\\tanh(nx) = n \\operatorname{sech}^2(nx).\n$$\nThe hyperbolic secant function, $\\operatorname{sech}(z)$, has a maximum value of $1$ at $z=0$. Therefore, its square, $\\operatorname{sech}^2(z)$, also has a maximum value of $1$. This implies that the derivative of $\\sigma_n(x)$ is uniformly bounded:\n$$\n\\left|\\frac{d}{dx}\\sigma_n(x)\\right| = |n \\operatorname{sech}^2(nx)| \\le n.\n$$\nBy the Mean Value Theorem, for any $x, y \\in \\mathbb{R}$, there exists a point $c$ between $x$ and $y$ such that\n$$\n\\sigma_n(x) - \\sigma_n(y) = \\left(\\frac{d}{dx}\\sigma_n\\right)(c) \\cdot (x-y).\n$$\nTaking the absolute value, we obtain the global Lipschitz condition:\n$$\n|\\sigma_n(x) - \\sigma_n(y)| = \\left|\\left(\\frac{d}{dx}\\sigma_n\\right)(c)\\right| |x-y| \\le n|x-y|.\n$$\nThe Lipschitz constant is $L_n = n$.\nFurthermore, the function $\\sigma_n(x) = \\tanh(nx)$ is bounded, since $|\\tanh(z)| \\le 1$ for all $z \\in \\mathbb{R}$. This means $|\\sigma_n(x)| \\le 1$, which satisfies the linear growth condition $| \\sigma_n(x) | \\le K(1+|x|)$ for any $K \\ge 1$.\nSince the coefficient $\\sigma_n(x)$ is globally Lipschitz and satisfies the linear growth condition, the classical theorem guarantees the existence of a unique strong solution for any given initial condition.\nWe now verify that the process $X^{(n)}_t \\equiv 0$ for all $t\\ge 0$ is a solution. The initial condition is satisfied, as $X^{(n)}_0=0$. Substituting $X^{(n)}_t=0$ into the SDE, the left side is $d(0) = 0$. The right side is\n$$\n\\sigma_n(X^{(n)}_t)\\, dW_t = \\sigma_n(0)\\, dW_t = \\tanh(n \\cdot 0)\\, dW_t = \\tanh(0)\\, dW_t = 0 \\cdot dW_t = 0.\n$$\nSince both sides are equal, $X^{(n)}_t \\equiv 0$ is a strong solution. By the uniqueness guaranteed by the theorem, it must be the only strong solution.\n\nSecond task: To analyze the limiting coefficient $\\sigma(x) = \\operatorname{sgn}(x)$ and the failure of pathwise uniqueness.\nThe function is given by $\\sigma(x) = \\operatorname{sgn}(x) = \\mathbf{1}_{\\{x>0\\}} - \\mathbf{1}_{\\{x<0\\}}$, which implies $\\operatorname{sgn}(0)=0$. For this function to be locally Lipschitz at $x=0$, there must exist a constant $L>0$ and a neighborhood of $0$, say $(-\\delta, \\delta)$, such that for all $y_1, y_2 \\in (-\\delta, \\delta)$, $|\\operatorname{sgn}(y_1) - \\operatorname{sgn}(y_2)| \\le L|y_1 - y_2|$.\nLet us test this condition with $y_2 = 0$ and $y_1 = x > 0$. We have:\n$$\n|\\operatorname{sgn}(x) - \\operatorname{sgn}(0)| = |1 - 0| = 1.\n$$\nThe condition would require $1 \\le L|x-0| = Lx$. This implies $L \\ge 1/x$. As $x \\to 0^+$, the required constant $L$ must tend to infinity. Therefore, no such finite $L$ exists in any neighborhood of $0$, and the coefficient $\\sigma(x)=\\operatorname{sgn}(x)$ is not locally Lipschitz at $x=0$.\nThis failure of the Lipschitz condition opens the possibility of non-uniqueness of solutions. The limiting SDE is $dX_t = \\operatorname{sgn}(X_t)dW_t$ with $X_0=0$.\nAs before, one can immediately verify that $X_t \\equiv 0$ is a solution, known as the trivial solution.\nTo construct a nontrivial weak solution, let $(B_t)_{t\\ge 0}$ be a standard one-dimensional Brownian motion starting at $B_0=0$ on some probability space. Define a new process $(W_t)_{t\\ge 0}$ by the Itô integral\n$$\nW_t = \\int_0^t \\operatorname{sgn}(B_s) dB_s.\n$$\nThe integrand $f(t,\\omega) = \\operatorname{sgn}(B_s(\\omega))$ is adapted. Its quadratic variation is $\\langle W \\rangle_t = \\int_0^t (\\operatorname{sgn}(B_s))^2 ds$. Since the set of times $\\{s : B_s=0\\}$ has Lebesgue measure zero almost surely, $(\\operatorname{sgn}(B_s))^2 = 1$ for almost every $s$. Thus, $\\langle W \\rangle_t = \\int_0^t 1 ds = t$. By Lévy's characterization theorem, $W_t$ is a standard Brownian motion.\nFrom the definition of $W_t$, we have $dW_t = \\operatorname{sgn}(B_s) dB_s$. We can invert this relationship:\n$$\ndB_s = \\frac{1}{\\operatorname{sgn}(B_s)} dW_s = \\operatorname{sgn}(B_s) dW_s,\n$$\nagain using $(\\operatorname{sgn}(x))^2=1$ for $x \\neq 0$.\nNow, let us define the solution process $X_t = B_t$. Its stochastic differential is $dX_t = dB_t$. Substituting the expression for $dB_t$, we get:\n$$\ndX_t = \\operatorname{sgn}(B_t) dW_t = \\operatorname{sgn}(X_t) dW_t.\n$$\nThe initial condition $X_0 = B_0 = 0$ is satisfied. Thus, the pair $(X, W) = (B, \\int \\operatorname{sgn}(B)dB)$ constitutes a weak solution to the limiting SDE. This solution is nontrivial; for any $t>0$, $\\mathbb{P}(X_t \\ne 0) = 1$. The trajectories of $X_t=B_t$ leave the origin at $t=0$ immediately with probability $1$. This demonstrates the failure of pathwise uniqueness, as we have found at least two distinct solutions ($X_t \\equiv 0$ and $X_t = B_t$) for the same SDE.\n\nThird task: To construct a counterexample to the continuity of solution maps.\nFor each $n \\in \\mathbb{N}$, the unique strong solution is $X^{(n)}_t \\equiv 0$. The sequence of solutions is the constant sequence of the zero process, $(0, 0, 0, \\dots)$. We consider convergence in the uniform norm on $[0,T]$ for a fixed $T>0$, which is defined as $\\|X\\|_{\\infty,T} = \\sup_{t \\in [0,T]} |X_t|$.\nThe limit of this sequence of solutions is\n$$\n\\lim_{n\\to\\infty} X^{(n)} = 0 \\quad (\\text{in the uniform norm}).\n$$\nThe limit is the zero process $X_t \\equiv 0$. The zero process is a solution to the limiting SDE, as shown above.\nThe task is to show that this sequence does not converge to any *nontrivial* solution. Let $X_t$ be a nontrivial solution, for instance, the one constructed in the second task, $X_t=B_t$ for a standard Brownian motion $B_t$. We examine the convergence of $X^{(n)}$ to $X$:\n$$\n\\|X^{(n)} - X\\|_{\\infty, T} = \\|0 - B\\|_{\\infty, T} = \\sup_{t \\in [0,T]} |B_t|.\n$$\nFor convergence to hold, this quantity must converge to $0$ in probability or almost surely. However, for any $T>0$, the random variable $M_T^* = \\sup_{t \\in [0,T]} |B_t|$ is strictly positive with probability $1$. Its distribution is well-known, and $\\mathbb{P}(M_T^* > \\epsilon) > 0$ for any $\\epsilon > 0$. Thus, $X^{(n)}$ does not converge to the nontrivial solution $X_t=B_t$ in the uniform norm.\nThe mechanism of divergence is rooted in the \"jump\" in the properties of the coefficient at $n=\\infty$. For any finite $n$, the coefficient $\\sigma_n(x)$ is Lipschitz, which enforces pathwise uniqueness. Since $\\sigma_n(0)=0$, the solution is \"pinned\" at the origin, yielding $X^{(n)}_t \\equiv 0$. The sequence of solutions $(X^{(n)})$ therefore converges to the pinned solution $X \\equiv 0$. However, the limiting coefficient $\\sigma(x)=\\operatorname{sgn}(x)$ is not Lipschitz at $0$, which \"unpins\" the SDE and allows for other, diffusive solutions that are not accessible as limits of the sequence $(X^{(n)})$. This illustrates a failure of continuity for the map from coefficient to solution space when the topology on the coefficients (here, pointwise convergence) is too weak to preserve the Lipschitz property.\n\nFourth task: To compute the expectation of the symmetric local time of Brownian motion at $0$ up to time $T$.\nLet $W_t$ be a standard Brownian motion and $L_t^0(W)$ be its symmetric local time at level $0$.\nWe use Tanaka's formula for the function $f(x)=|x|$ applied to the Brownian motion $W_t$:\n$$\n|W_t| = |W_0| + \\int_0^t \\operatorname{sgn}(W_s) dW_s + L_t^0(W).\n$$\nSince $W_0=0$, the formula simplifies to\n$$\n|W_t| = \\int_0^t \\operatorname{sgn}(W_s) dW_s + L_t^0(W).\n$$\nWe wish to compute $\\mathbb{E}[L_T^0(W)]$ for a fixed $T>0$. By rearranging the formula and taking expectations, we get:\n$$\n\\mathbb{E}[L_T^0(W)] = \\mathbb{E}[|W_T|] - \\mathbb{E}\\left[\\int_0^T \\operatorname{sgn}(W_s) dW_s\\right].\n$$\nThe integral term $M_t = \\int_0^t \\operatorname{sgn}(W_s) dW_s$ is an Itô integral. The integrand $f(s,\\omega) = \\operatorname{sgn}(W_s(\\omega))$ is adapted. We check the square-integrability condition for it to be a zero-mean martingale:\n$$\n\\mathbb{E}\\left[ \\int_0^T (\\operatorname{sgn}(W_s))^2 ds \\right] = \\mathbb{E}\\left[ \\int_0^T 1 \\, ds \\right] = \\mathbb{E}[T] = T < \\infty.\n$$\nSince this condition holds, the Itô integral $M_T$ is a martingale with $\\mathbb{E}[M_T] = M_0 = 0$.\nTherefore, the expectation of the integral term is zero:\n$$\n\\mathbb{E}\\left[\\int_0^T \\operatorname{sgn}(W_s) dW_s\\right] = 0.\n$$\nThis simplifies our calculation to:\n$$\n\\mathbb{E}[L_T^0(W)] = \\mathbb{E}[|W_T|].\n$$\nThe random variable $W_T$ follows a normal distribution with mean $0$ and variance $T$, i.e., $W_T \\sim N(0, T)$. Its probability density function (PDF) is $f(x) = \\frac{1}{\\sqrt{2\\pi T}} \\exp\\left(-\\frac{x^2}{2T}\\right)$.\nThe expectation of $|W_T|$ is calculated by integrating $|x|$ against this PDF:\n$$\n\\mathbb{E}[|W_T|] = \\int_{-\\infty}^{\\infty} |x| \\frac{1}{\\sqrt{2\\pi T}} \\exp\\left(-\\frac{x^2}{2T}\\right) dx.\n$$\nSince the integrand is an even function, we can simplify the integral:\n$$\n\\mathbb{E}[|W_T|] = 2 \\int_{0}^{\\infty} x \\frac{1}{\\sqrt{2\\pi T}} \\exp\\left(-\\frac{x^2}{2T}\\right) dx.\n$$\nWe perform a substitution. Let $u = \\frac{x^2}{2T}$. Then $du = \\frac{2x}{2T}dx = \\frac{x}{T}dx$, which implies $x dx = T du$. When $x=0$, $u=0$; as $x\\to\\infty$, $u\\to\\infty$.\nSubstituting into the integral:\n$$\n\\mathbb{E}[|W_T|] = \\frac{2}{\\sqrt{2\\pi T}} \\int_0^{\\infty} \\exp(-u) (T du) = \\frac{2T}{\\sqrt{2\\pi T}} \\int_0^{\\infty} \\exp(-u) du.\n$$\nThe definite integral $\\int_0^{\\infty} \\exp(-u) du$ is equal to $1$.\n$$\n\\mathbb{E}[|W_T|] = \\frac{2T}{\\sqrt{2\\pi T}} = \\frac{2T}{\\sqrt{2\\pi}\\sqrt{T}} = \\frac{2\\sqrt{T}}{\\sqrt{2\\pi}} = \\sqrt{\\frac{4T}{2\\pi}} = \\sqrt{\\frac{2T}{\\pi}}.\n$$\nSo, the final answer for the expectation of the local time is $\\sqrt{\\frac{2T}{\\pi}}$.", "answer": "$$\\boxed{\\sqrt{\\frac{2T}{\\pi}}}$$", "id": "2994562"}]}