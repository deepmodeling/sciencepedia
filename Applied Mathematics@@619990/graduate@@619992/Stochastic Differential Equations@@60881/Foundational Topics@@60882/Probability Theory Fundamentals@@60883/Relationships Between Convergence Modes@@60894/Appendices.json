{"hands_on_practices": [{"introduction": "Mastering the theory of stochastic processes begins with a precise understanding of its language. This first exercise serves as a foundational check, ensuring you can rigorously define and differentiate the primary modes of convergence: almost sure, in probability, in distribution, and in $L^p$. By examining these definitions for both simple random variables and more complex càdlàg processes in Skorokhod space, you will solidify your understanding of the subtle hierarchy and key implications that connect them [@problem_id:2994139].", "problem": "Let $\\left(\\Omega,\\mathcal{F},\\mathbb{P}\\right)$ be a probability space and let $\\{X_n\\}_{n\\ge 1}$ and $X$ be real-valued random variables. Let $\\{X^n\\}_{n\\ge 1}$ and $X$ be $\\mathbb{R}^d$-valued càdlàg processes on $[0,T]$ (right-continuous with left limits), regarded as random elements taking values in $D([0,T];\\mathbb{R}^d)$, the space of càdlàg functions endowed with the Skorokhod $J_1$ metric $d_{J_1}$, which makes $D([0,T];\\mathbb{R}^d)$ a Polish (complete separable metric) space. Throughout, $p\\ge 1$ and $T\\in(0,\\infty)$ are fixed.\n\nSelect all options that are correct. Each option makes a precise statement about definitions of convergence modes for random variables and processes and about standard implications and non-implications among these modes, including any required side conditions.\n\nA. Definitions. For real-valued random variables:\n- $X_n \\to X$ almost surely (almost surely (a.s.)) means $\\mathbb{P}\\!\\left(\\lim_{n\\to\\infty}|X_n - X|=0\\right)=1$.\n- $X_n \\to X$ in probability means $\\forall \\varepsilon>0,\\ \\mathbb{P}(|X_n - X|>\\varepsilon)\\to 0$ as $n\\to\\infty$.\n- $X_n \\Rightarrow X$ in distribution means the laws converge weakly, equivalently $\\lim_{n\\to\\infty}\\mathbb{E}[f(X_n)]=\\mathbb{E}[f(X)]$ for every bounded continuous $f:\\mathbb{R}\\to\\mathbb{R}$.\n- $X_n \\to X$ in $L^p$ means $\\mathbb{E}[|X_n - X|^p]\\to 0$.\nFor $\\mathbb{R}^d$-valued càdlàg processes viewed as $D([0,T];\\mathbb{R}^d)$-valued random elements:\n- $X^n \\to X$ almost surely means $\\mathbb{P}\\!\\left(d_{J_1}(X^n,X)\\to 0\\right)=1$.\n- $X^n \\to X$ in probability means $d_{J_1}(X^n,X)\\to 0$ in probability.\n- $X^n \\Rightarrow X$ in distribution means the laws on $D([0,T];\\mathbb{R}^d)$ converge weakly with respect to $d_{J_1}$.\n- $X^n \\to X$ in $L^p$ (uniform-in-time $L^p$) means $\\mathbb{E}\\!\\left[\\sup_{t\\in[0,T]}|X^n_t - X_t|^p\\right]\\to 0$.\n\nB. Implications and non-implications (random variables and processes). For random variables: $L^p$ convergence implies convergence in probability; almost sure convergence implies convergence in probability; and convergence in probability implies convergence in distribution. The same implication chain holds for processes when $d_{J_1}$ is used for almost sure and in probability, and when $L^p$ uses the supremum norm in time as in Option A. Convergence in distribution to a constant (deterministic) limit implies convergence in probability to that constant. In general, convergence in distribution does not imply convergence in probability, and convergence in probability does not imply almost sure convergence, although one can always extract a subsequence that converges almost surely on the same probability space. Moreover, convergence in probability does not imply $L^p$ convergence even if $\\sup_n \\mathbb{E}[|X_n|^p]<\\infty$.\n\nC. Finite-dimensional distributions suffice. If $\\{X^n\\}$ are $\\mathbb{R}^d$-valued càdlàg processes and for every finite collection of times $t_1,\\dots,t_k\\in[0,T]$ the vector $(X^n_{t_1},\\dots,X^n_{t_k})$ converges in distribution to $(X_{t_1},\\dots,X_{t_k})$, then $X^n \\Rightarrow X$ in $D([0,T];\\mathbb{R}^d)$ with the Skorokhod $J_1$ topology, without any further conditions.\n\nD. Pointwise almost sure convergence of sample paths implies Skorokhod almost sure convergence. If for every $t\\in[0,T]$ one has $X^n_t \\to X_t$ almost surely, and the sample paths are càdlàg, then $X^n \\to X$ almost surely in $D([0,T];\\mathbb{R}^d)$ endowed with $d_{J_1}$.\n\nE. Subsequence principle in separable metric spaces. If random elements $Y_n$ taking values in a separable metric space $(S,d)$ satisfy $Y_n \\to Y$ in probability, then there exists a subsequence $Y_{n_k}$ such that $Y_{n_k} \\to Y$ almost surely. In particular, this holds for $S=D([0,T];\\mathbb{R}^d)$ with $d=d_{J_1}$.\n\nF. Tightness from weak convergence in $D([0,T];\\mathbb{R}^d)$. If $X^n \\Rightarrow X$ in $D([0,T];\\mathbb{R}^d)$ with the Skorokhod $J_1$ topology, then the sequence of laws $\\{\\mathcal{L}(X^n)\\}_{n\\ge 1}$ is tight in $D([0,T];\\mathbb{R}^d)$.", "solution": "The problem statement provides a standard framework for discussing convergence of random variables and stochastic processes. It is scientifically grounded, well-posed, and objective. All terms and spaces are standard in modern probability theory. The problem is valid.\n\nA. Definitions. For real-valued random variables:\n- $X_n \\to X$ almost surely (a.s.) means $\\mathbb{P}\\!\\left(\\lim_{n\\to\\infty}|X_n - X|=0\\right)=1$. This is the correct standard definition for almost sure convergence of real-valued random variables.\n- $X_n \\to X$ in probability means $\\forall \\varepsilon>0,\\ \\mathbb{P}(|X_n - X|>\\varepsilon)\\to 0$ as $n\\to\\infty$. This is the correct standard definition of convergence in probability.\n- $X_n \\Rightarrow X$ in distribution means the laws converge weakly, which, by the Portmanteau Theorem, is equivalent to $\\lim_{n\\to\\infty}\\mathbb{E}[f(X_n)]=\\mathbb{E}[f(X)]$ for every bounded continuous function $f:\\mathbb{R}\\to\\mathbb{R}$. This is a correct and standard definition of convergence in distribution.\n- $X_n \\to X$ in $L^p$ means $\\mathbb{E}[|X_n - X|^p]\\to 0$. This is the correct definition of convergence in the $L^p$ norm for $p \\ge 1$.\nFor $\\mathbb{R}^d$-valued càdlàg processes viewed as $D([0,T];\\mathbb{R}^d)$-valued random elements:\nThe definitions provided are the correct generalizations of the above modes of convergence to random elements in a metric space, where the metric space is $(D([0,T];\\mathbb{R}^d), d_{J_1})$.\n- $X^n \\to X$ almost surely means $\\mathbb{P}\\!\\left(d_{J_1}(X^n,X)\\to 0\\right)=1$. Correct.\n- $X^n \\to X$ in probability means $d_{J_1}(X^n,X)\\to 0$ in probability, i.e., $\\forall \\varepsilon>0, \\mathbb{P}(d_{J_1}(X^n,X)>\\varepsilon) \\to 0$. Correct.\n- $X^n \\Rightarrow X$ in distribution means the laws on $D([0,T];\\mathbb{R}^d)$ converge weakly. Correct by definition.\n- $X^n \\to X$ in $L^p$ (uniform-in-time $L^p$) means $\\mathbb{E}\\!\\left[\\sup_{t\\in[0,T]}|X^n_t - X_t|^p\\right]\\to 0$. This is a standard, albeit very strong, definition for the convergence of stochastic processes. It is a valid definition for a mode of convergence.\nAll definitions listed in this option are standard and correctly stated.\nVerdict: **Correct**.\n\nB. Implications and non-implications (random variables and processes).\n- For random variables: The chain of implications $L^p$ convergence $\\implies$ convergence in probability, and almost sure convergence $\\implies$ convergence in probability, and convergence in probability $\\implies$ convergence in distribution is a cornerstone of probability theory. These are all correct.\n- For processes: The same implication chain is claimed to hold.\n    - Uniform-in-time $L^p$ convergence $\\implies$ convergence in probability w.r.t. $d_{J_1}$: We have the inequality $d_{J_1}(x,y) \\le \\sup_{t \\in [0,T]} |x(t) - y(t)|$ for any two paths $x, y \\in D([0,T];\\mathbb{R}^d)$. Let $Z_n = \\sup_{t \\in [0,T]} |X^n_t - X_t|$. The hypothesis is $\\mathbb{E}[Z_n^p] \\to 0$. By Markov's inequality, for any $\\varepsilon > 0$, $\\mathbb{P}(d_{J_1}(X^n, X) > \\varepsilon) \\le \\mathbb{P}(Z_n > \\varepsilon) \\le \\frac{\\mathbb{E}[Z_n^p]}{\\varepsilon^p} \\to 0$. The implication holds.\n    - The implications (a.s. in $d_{J_1}$) $\\implies$ (in probability in $d_{J_1}$) $\\implies$ (in distribution) hold for random elements in any metric space.\n- Convergence in distribution to a constant, $X_n \\Rightarrow c$, implies convergence in probability to that constant, $X_n \\to c$. This is a standard result. For any $\\varepsilon > 0$, $\\mathbb{P}(|X_n - c| > \\varepsilon) = \\mathbb{P}(X_n > c+\\varepsilon) + \\mathbb{P}(X_n < c-\\varepsilon)$. The convergence of distribution functions $F_{X_n}(x) \\to F_c(x)$ at continuity points $x$ of $F_c$ shows that this probability tends to $0$.\n- The counter-implications are also standard. A standard counterexample shows convergence in distribution does not imply convergence in probability: let $X \\sim \\text{Bernoulli}(1/2)$ and set $X_n = X$ for all $n$. Let $Y=1-X$. Then $X_n \\Rightarrow Y$ (as they are identically distributed), but $|X_n-Y| = |2X-1|=1$ a.s., so they do not converge in probability. The \"typewriter\" sequence is a standard example showing that convergence in probability does not imply a.s. convergence.\n- The statement that for a sequence converging in probability one can always extract an almost surely convergent subsequence is a fundamental theorem (and is the content of Option E).\n- Finally, convergence in probability does not imply $L^p$ convergence, even with the condition $\\sup_n \\mathbb{E}[|X_n|^p]<\\infty$. Consider $X_n = n^{1/p} \\mathbf{1}_{(0, 1/n]}$ on $(\\Omega, \\mathcal{F}, \\mathbb{P}) = ((0,1], \\mathcal{B}, \\lambda)$. Then $\\mathbb{P}(|X_n|> \\varepsilon) = 1/n \\to 0$ for large enough $n$, so $X_n \\to 0$ in probability. Also, $\\mathbb{E}[|X_n|^p] = \\int_0^1 (n^{1/p})^p \\mathbf{1}_{(0,1/n]}(x) dx = n \\cdot (1/n) = 1$. Thus $\\sup_n \\mathbb{E}[|X_n|^p] = 1 < \\infty$. However, $\\mathbb{E}[|X_n-0|^p] = 1$, which does not converge to $0$.\nAll statements in this option are correct.\nVerdict: **Correct**.\n\nC. Finite-dimensional distributions suffice. This statement claims that convergence of all finite-dimensional distributions (FDDs) of $\\{X^n\\}$ to those of $X$ is sufficient for weak convergence $X^n \\Rightarrow X$ in $D([0,T];\\mathbb{R}^d)$. This is false. FDD convergence is one of the two conditions required for weak convergence in Skorokhod space. The other, indispensable condition is that the sequence of laws $\\{\\mathcal{L}(X^n)\\}_{n\\ge 1}$ must be tight. Tightness is a condition that prevents the sample paths from being too \"irregular,\" ensuring that no probability mass is lost at infinity in the function space. Without tightness, one can construct counterexamples, such as a sequence of processes whose paths oscillate with increasing frequency, for which the FDDs converge to zero, but the process does not converge to the zero process in the Skorokhod topology.\nVerdict: **Incorrect**.\n\nD. Pointwise almost sure convergence of sample paths implies Skorokhod almost sure convergence. The statement is that if for a.e. $\\omega$, the sample path $X^n(\\cdot, \\omega)$ converges pointwise for all $t \\in [0,T]$ to $X(\\cdot, \\omega)$, then $X^n(\\cdot, \\omega)$ converges to $X(\\cdot, \\omega)$ in the Skorokhod metric $d_{J_1}$. This is false. Pointwise convergence of a sequence of functions does not imply convergence in the Skorokhod topology, even if the limit function is well-behaved. Consider the deterministic sequence of functions $f_n(t) = \\mathbf{1}_{[1-1/n, 1)}(t)$ on $[0,1]$. For each $t \\in [0,1]$, $\\lim_{n\\to\\infty} f_n(t) = 0$. The limit function $f(t)=0$ is continuous, hence càdlàg. Let's compute the Skorokhod distance $d_{J_1}(f_n, f)$. Using the definition $d_{J_1}(x,y) = \\inf_{\\lambda \\in \\Lambda} \\max( \\|x - y \\circ \\lambda \\|_\\infty, \\|\\lambda - \\mathrm{id}\\|_\\infty )$, where $\\Lambda$ is the set of strictly increasing continuous bijections of $[0,T]$ onto itself. With $f_n$ and $f=0$, we have $d_{J_1}(f_n, 0) = \\inf_{\\lambda \\in \\Lambda} \\max( \\|f_n \\|_\\infty, \\|\\lambda - \\mathrm{id}\\|_\\infty)$. Since $\\|f_n\\|_\\infty = \\sup_t |\\mathbf{1}_{[1-1/n, 1)}(t)| = 1$, the distance is $d_{J_1}(f_n, 0) = \\inf_{\\lambda \\in \\Lambda} \\max(1, \\|\\lambda - \\mathrm{id}\\|_\\infty) = 1$. The distance does not converge to $0$. Thus, a.s. pointwise convergence does not imply a.s. Skorokhod convergence.\nVerdict: **Incorrect**.\n\nE. Subsequence principle in separable metric spaces. The statement is that if random elements $Y_n$ in a separable metric space $(S,d)$ converge in probability to $Y$, then there exists a subsequence $\\{Y_{n_k}\\}$ that converges almost surely to $Y$. This is a fundamental theorem of probability theory. The separability of $S$ ensures that $d(Y_n, Y)$ is a well-defined real-valued random variable. The proof is constructive: since $d(Y_n, Y) \\to 0$ in probability, one can choose an increasing sequence of indices $\\{n_k\\}$ such that for each $k \\in \\mathbb{N}$, $\\mathbb{P}(d(Y_{n_k}, Y) > 1/k) < 1/2^k$. Since the series $\\sum_{k=1}^\\infty \\mathbb{P}(d(Y_{n_k}, Y) > 1/k)$ converges, the Borel-Cantelli lemma implies that $\\mathbb{P}(\\limsup_{k\\to\\infty} \\{d(Y_{n_k}, Y) > 1/k\\}) = 0$. This means that for almost every $\\omega$, $d(Y_{n_k}(\\omega), Y(\\omega)) \\to 0$ as $k\\to\\infty$, which is the definition of almost sure convergence. The space $D([0,T];\\mathbb{R}^d)$ with the Skorokhod metric $d_{J_1}$ is a Polish space, and therefore separable, so this principle applies.\nVerdict: **Correct**.\n\nF. Tightness from weak convergence in $D([0,T];\\mathbb{R}^d)$. The statement is that if $X^n \\Rightarrow X$ in $D([0,T];\\mathbb{R}^d)$, then the sequence of laws $\\{\\mathcal{L}(X^n)\\}$ is tight. This is a direct consequence of one direction of Prohorov's theorem. Prohorov's theorem states that for a family of probability measures on a Polish space, relative compactness (in the weak topology) is equivalent to tightness. Weak convergence of a sequence of measures $\\{\\mu_n\\}$ to a measure $\\mu$ implies that the set $\\{\\mu_n : n\\ge 1\\}$ is relatively compact. Hence, the sequence $\\{\\mu_n\\}$ must be tight. In this problem, the space $S=D([0,T];\\mathbb{R}^d)$ is Polish, the laws $\\mathcal{L}(X^n)$ are probability measures on $S$, and $X^n \\Rightarrow X$ means that the laws $\\mathcal{L}(X^n)$ converge weakly to $\\mathcal{L}(X)$. Therefore, by Prohorov's theorem, the sequence of laws $\\{\\mathcal{L}(X^n)\\}_{n\\ge 1}$ is tight.\nVerdict: **Correct**.", "answer": "$$\\boxed{ABEF}$$", "id": "2994139"}, {"introduction": "While convergence in distribution is a relatively weak notion, the Skorokhod Representation Theorem provides a powerful bridge to the strongest mode of convergence: almost sure convergence. This exercise explores this fundamental theorem, demonstrating how weak convergence on a Polish space like $D([0,T])$ can be transformed into a pathwise convergent sequence on a new, cleverly constructed probability space [@problem_id:2994133]. Understanding this \"coupling\" technique is essential, as it is a cornerstone for proving many results in weak convergence theory.", "problem": "Fix $T>0$ and let $\\{X_n\\}_{n\\ge 1}$ be random elements of $D([0,T])$, the space of right-continuous functions with left limits (càdlàg functions) on $[0,T]$, equipped with the Skorokhod $J_1$ topology, defined on a probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$. Suppose $X_n$ converges in distribution to a random element $X$ in $D([0,T])$ under the $J_1$ topology. Recall the core definitions: a Polish space is a complete, separable metric space; convergence in distribution of random elements in a metric space means weak convergence of their laws. Based on these foundational notions, select all statements that are valid consequences of this setting and correctly reflect the Skorokhod representation framework and its implications for upgrading convergence in distribution to almost sure (a.s.) convergence on a new probability space.\n\nA. There exists a probability space $(\\Omega',\\mathcal{F}',\\mathbb{P}')$ and random elements $Y_n, Y$ in $D([0,T])$ defined on $(\\Omega',\\mathcal{F}',\\mathbb{P}')$ such that $Y_n \\stackrel{d}{=} X_n$, $Y \\stackrel{d}{=} X$, and $Y_n \\to Y$ $\\mathbb{P}'$-almost surely in the $D([0,T])$ $J_1$ metric.\n\nB. From $X_n \\Rightarrow X$ in $D([0,T])$ under $J_1$, one can (without further assumptions) construct versions on the original space $(\\Omega,\\mathcal{F},\\mathbb{P})$ such that $\\sup_{t\\in[0,T]} |X_n(t)-X(t)| \\to 0$ $\\mathbb{P}$-almost surely.\n\nC. The Skorokhod representation theorem does not apply here because $D([0,T])$ with the $J_1$ topology is not separable, hence not Polish.\n\nD. Under the coupling in which $Y_n \\to Y$ almost surely in the $J_1$ topology on $D([0,T])$, it follows that for every $t\\in[0,T]$ at which the sample path $Y$ is continuous, one has $Y_n(t)\\to Y(t)$ almost surely.\n\nE. If $X$ has almost surely continuous sample paths on $[0,T]$, then under the Skorokhod coupling one actually has $\\sup_{t\\in[0,T]} |Y_n(t)-Y(t)| \\to 0$ almost surely on $(\\Omega',\\mathcal{F}',\\mathbb{P}')$.", "solution": "The problem statement is critically reviewed before a solution is attempted.\n\n### Step 1: Extract Givens\n- $T>0$ is a fixed positive real number.\n- $\\{X_n\\}_{n\\ge 1}$ is a sequence of random elements of $D([0,T])$.\n- $D([0,T])$ is the space of right-continuous functions with left limits (càdlàg functions) on the interval $[0,T]$.\n- The space $D([0,T])$ is equipped with the Skorokhod $J_1$ topology.\n- The random elements $\\{X_n\\}$ are defined on a probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$.\n- The sequence $X_n$ converges in distribution to a random element $X$ in $D([0,T])$, denoted $X_n \\Rightarrow X$.\n- A Polish space is a complete, separable metric space.\n- Convergence in distribution of random elements in a metric space is defined as weak convergence of their laws (probability measures).\n\n### Step 2: Validate Using Extracted Givens\nThe problem is posited within the standard mathematical framework of weak convergence of stochastic processes.\n- **Scientifically Grounded:** The problem is based on established, core concepts of modern probability theory, specifically the theory of weak convergence on function spaces. The space $D([0,T])$ with the $J_1$ topology is a cornerstone of this theory.\n- **Well-Posed:** The problem provides a clear hypothesis ($X_n \\Rightarrow X$ in $D([0,T])$) and asks for valid consequences based on established theorems. This structure permits a unique and definite determination of the truth value of each statement. A critical premise is that $D([0,T])$ with the $J_1$ topology is a Polish space. This is a standard result: the space is separable (e.g., by considering step functions with rational jump points and values) and can be equipped with a complete metric (the Skorokhod metric, $d_{J_1}$) that induces the $J_1$ topology.\n- **Objective:** The language is formal and mathematical, free from ambiguity or subjectivity, with the exception of some potential linguistic sloppiness in the options, which is a matter for analysis, not a flaw in the problem setup itself.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. It is a well-posed question about the implications of weak convergence in the Skorokhod space $D([0,T])$, grounded in established mathematical theory. We may proceed with the solution.\n\n### Derivation and Option Analysis\nThe central hypothesis is that $X_n \\Rightarrow X$, where $X_n$ and $X$ are random elements in the space $D([0,T])$ equipped with the $J_1$ topology. As established, this space is metrizable as a complete separable metric space (a Polish space). The key theoretical tool for analyzing the options is the Skorokhod representation theorem.\n\n**Skorokhod's Representation Theorem:** Let $S$ be a Polish space and let $\\{P_n\\}, P$ be probability measures on its Borel $\\sigma$-algebra. If $P_n$ converges weakly to $P$, then there exist $S$-valued random variables $Y_n, Y$ defined on a common probability space $(\\Omega',\\mathcal{F}',\\mathbb{P}')$ such that:\n1. $Y_n$ has law $P_n$ for each $n \\in \\mathbb{N}$.\n2. $Y$ has law $P$.\n3. $Y_n \\to Y$ $\\mathbb{P}'$-almost surely.\n\nIn our setting, $S$ is the space $D([0,T])$ with the metric $d_{J_1}$ inducing the $J_1$ topology. The weak convergence of laws $\\mathbb{P}_{X_n} \\rightharpoonup \\mathbb{P}_X$ is precisely the condition $X_n \\Rightarrow X$. The theorem thus guarantees the existence of a \"coupling\".\n\n**Option-by-Option Analysis:**\n\n**A. There exists a probability space $(\\Omega',\\mathcal{F}',\\mathbb{P}')$ and random elements $Y_n, Y$ in $D([0,T])$ defined on $(\\Omega',\\mathcal{F}',\\mathbb{P}')$ such that $Y_n \\stackrel{d}{=} X_n$, $Y \\stackrel{d}{=} X$, and $Y_n \\to Y$ $\\mathbb{P}'$-almost surely in the $D([0,T])$ $J_1$ metric.**\n\nThis statement is a direct and accurate formulation of the Skorokhod representation theorem applied to the given context. The hypothesis $X_n \\Rightarrow X$ means the laws of $X_n$ converge weakly to the law of $X$. Since $D([0,T])$ with the $J_1$ topology is a Polish space, the theorem's conditions are met. The conclusion is that one can find new random elements $Y_n$ and $Y$ on a potentially new probability space $(\\Omega',\\mathcal{F}',\\mathbb{P}')$ that are equal in distribution to the original ones ($Y_n \\stackrel{d}{=} X_n$, $Y \\stackrel{d}{=} X$) and for which the convergence is upgraded from \"in distribution\" to \"almost sure\". The convergence $Y_n \\to Y$ $\\mathbb{P}'$-a.s. happens in the topology of the Polish space, which is the $J_1$ topology, or equivalently, with respect to the $d_{J_1}$ metric.\n\nVerdict: **Correct**.\n\n**B. From $X_n \\Rightarrow X$ in $D([0,T])$ under $J_1$, one can (without further assumptions) construct versions on the original space $(\\Omega,\\mathcal{F},\\mathbb{P})$ such that $\\sup_{t\\in[0,T]} |X_n(t)-X(t)| \\to 0$ $\\mathbb{P}$-almost surely.**\n\nThis statement is incorrect for two critical reasons:\n1. The construction of the almost surely convergent sequence cannot, in general, be performed on the *original* probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$. The theorem only guarantees existence on *some* probability space, typically $([0,1], \\mathcal{B}, \\lambda)$.\n2. The mode of convergence is stronger than what is guaranteed. Almost sure convergence is guaranteed in the metric of the space, which is the $J_1$ metric $d_{J_1}$. Convergence in the supremum norm, $d_\\infty(f,g) = \\sup_{t\\in[0,T]} |f(t)-g(t)|$, is strictly stronger than convergence in the $J_1$ metric. For instance, the sequence of functions $f_n(t) = \\mathbf{1}_{[1/n, T]}(t)$ converges in the $J_1$ metric to $f(t) = \\mathbf{1}_{[0,T]}(t)$, but the supremum distance $\\|f_n - f\\|_{\\infty}$ is $1$ for all $n$. Thus, even on the new space, upgrading to sup-norm convergence requires additional assumptions (see option E).\n\nVerdict: **Incorrect**.\n\n**C. The Skorokhod representation theorem does not apply here because $D([0,T])$ with the $J_1$ topology is not separable, hence not Polish.**\n\nThis statement is factually incorrect. A space is Polish if it is separable and completely metrizable. It is a fundamental result in the theory of stochastic processes that the Skorokhod space $D([0,T])$ with the $J_1$ topology is indeed separable. A countable dense subset can be constructed, for example, from the set of all step functions whose jump points and values are rational numbers. It is also completely metrizable. Therefore, $D([0,T])$ is a Polish space, and the Skorokhod representation theorem is applicable.\n\nVerdict: **Incorrect**.\n\n**D. Under the coupling in which $Y_n \\to Y$ almost surely in the $J_1$ topology on $D([0,T])$, it follows that for every $t\\in[0,T]$ at which the sample path $Y$ is continuous, one has $Y_n(t)\\to Y(t)$ almost surely.**\n\nThe phrasing of this statement is slightly imprecise but points to a correct and fundamental property of the $J_1$ topology. Let's clarify the intended meaning. The almost sure convergence $Y_n \\to Y$ in the $J_1$ topology means there is a set $A \\subseteq \\Omega'$ with $\\mathbb{P}'(A)=1$ such that for every $\\omega' \\in A$, the sequence of sample paths $Y_n(\\cdot, \\omega')$ converges to the sample path $Y(\\cdot, \\omega')$ in the $J_1$ metric. A key property of this convergence is that if a sequence of functions $y_n \\to y$ in the $J_1$ topology, then $y_n(t) \\to y(t)$ for every point $t$ at which the limit function $y$ is continuous.\nApplying this to our setting: for any $\\omega' \\in A$, the sequence of numbers $Y_n(t, \\omega')$ converges to $Y(t, \\omega')$ for all $t$ in the set of continuity points of the path $Y(\\cdot, \\omega')$.\nThe most reasonable interpretation of the statement in D is the following assertion, which is frequently stated with similar (if slightly loose) language: \"Almost surely, the sequence of sample paths $Y_n$ converges to $Y$ pointwise at every continuity point of the limit path $Y$.\" In formal terms: $\\mathbb{P}'(\\{\\omega' \\mid \\forall t \\in C(Y(\\cdot,\\omega')), Y_n(t,\\omega') \\to Y(t,\\omega')\\}) = 1$, where $C(y)$ is the set of continuity points of a function $y$. This statement is a direct consequence of the almost sure $J_1$ convergence, as argued above. The set in the probability argument contains $A$, which has measure $1$. Thus, the statement is correct under this standard interpretation.\n\nVerdict: **Correct**.\n\n**E. If $X$ has almost surely continuous sample paths on $[0,T]$, then under the Skorokhod coupling one actually has $\\sup_{t\\in[0,T]} |Y_n(t)-Y(t)| \\to 0$ almost surely on $(\\Omega',\\mathcal{F}',\\mathbb{P}')$.**\n\nThis statement introduces the additional condition that the limit process $X$ has continuous sample paths almost surely, i.e., $\\mathbb{P}(X \\in C[0,T])=1$. In the coupled space, this means $Y$ also has continuous paths a.s., so $\\mathbb{P}'(Y \\in C[0,T])=1$. We have a fundamental theorem connecting the $J_1$ topology and the uniform (supremum) topology: if a sequence of functions $y_n \\in D([0,T])$ converges to a *continuous* function $y \\in C([0,T])$ in the $J_1$ topology, then the convergence also holds in the uniform topology, i.e., $\\sup_{t\\in[0,T]} |y_n(t) - y(t)| \\to 0$.\nWe can apply this theorem pathwise. We know that $Y_n \\to Y$ a.s. in the $J_1$ metric. Let $A$ be the set of $\\omega'$ (with $\\mathbb{P}'(A)=1$) where this convergence holds. Let $B$ be the set of $\\omega'$ (with $\\mathbb{P}'(B)=1$) where $Y(\\cdot, \\omega')$ is continuous. For any $\\omega'$ in the intersection $A \\cap B$ (which also has measure $1$), we have a sequence of functions $Y_n(\\cdot, \\omega')$ converging in the $J_1$ metric to a continuous function $Y(\\cdot, \\omega')$. By the aforementioned theorem, for any such $\\omega'$, we have $\\sup_{t\\in[0,T]} |Y_n(t, \\omega') - Y(t, \\omega')| \\to 0$. Since this holds on a set of $\\mathbb{P}'$-measure $1$, the statement is true.\n\nVerdict: **Correct**.", "answer": "$$\\boxed{ADE}$$", "id": "2994133"}, {"introduction": "The choice of topology on a function space is not merely a theoretical abstraction; it has profound practical consequences for the stability of solutions to stochastic differential equations. This practice provides a hands-on thought experiment to investigate the continuity of the solution map for an SDE with jumps [@problem_id:2994150]. By comparing the behavior under the uniform topology versus the Skorokhod $J_1$ topology, you will discover why the latter is indispensable for developing a robust theory for processes with discontinuous paths.", "problem": "Consider a stochastic differential equation with jumps driven by a càdlàg (right-continuous with left limits) signal in the following pathwise form: for a vector field $V:\\mathbb{R}^d\\to\\mathbb{R}^{d\\times m}$, the solution $X:[0,T]\\to\\mathbb{R}^d$ responds continuously to the continuous part of the signal and instantaneously to each jump according to a canonical jump rule induced by $V$. In particular, at a jump time $t$ of the driving signal $z:[0,T]\\to\\mathbb{R}^m$ of size $\\Delta z_t$, the state $X_{t-}$ is updated to $X_t$ by applying the flow generated by $V$ over the increment $\\Delta z_t$; between jumps it evolves according to the driven dynamics dictated by $V$ and the continuous part of $z$. This canonical jump-driven evolution is known to coincide with the Marcus (canonical) interpretation of jump stochastic differential equations. \n\nLet $\\mathbb{D}([0,T],\\mathbb{R}^m)$ denote the Skorokhod space of càdlàg paths. Two classical topologies on $\\mathbb{D}([0,T],\\mathbb{R}^m)$ are:\n\n- The uniform (supremum) topology with metric $d_\\infty(z^1,z^2) := \\sup_{t\\in[0,T]} \\Vert z^1(t)-z^2(t)\\Vert$.\n- The Skorokhod $J_1$ topology, defined via strictly increasing, onto time changes $\\lambda:[0,T]\\to[0,T]$ with $d_{J_1}(z^1,z^2) := \\inf_{\\lambda} \\max\\left( \\sup_{t\\in[0,T]} \\Vert \\lambda(t)-t\\Vert, \\sup_{t\\in[0,T]} \\Vert z^1(\\lambda(t)) - z^2(t)\\Vert \\right)$.\n\nFix $T>0$, $t_0\\in(0,T)$, and a signal $z\\in\\mathbb{D}([0,T],\\mathbb{R}^m)$ with a single jump of size $\\xi\\in\\mathbb{R}^m$ at time $t_0$. For each $n\\in\\mathbb{N}$, define $z^n\\in\\mathbb{D}([0,T],\\mathbb{R}^m)$ to be equal to $z$ except that the single jump at $t_0$ is replaced by two jumps of size $\\xi/2$ occurring at times $t_0 - 1/n$ and $t_0 + 1/n$. Let $X$ and $X^n$ be the corresponding Marcus solutions driven by $z$ and $z^n$, with the same initial condition $X_0\\in\\mathbb{R}^d$.\n\nAssume the vector field $V$ is globally Lipschitz and of linear growth: there exist constants $L>0$ and $K>0$ such that for all $x,y\\in\\mathbb{R}^d$,\n$$\n\\Vert V(x) - V(y) \\Vert \\le L \\Vert x-y\\Vert, \\qquad \\Vert V(x)\\Vert \\le K(1+\\Vert x\\Vert).\n$$\n\nAnswer the following multiple choice question. Your goal is to reason from the topological definitions above and the Marcus jump-update structure to explain the relationship between convergence modes of the driving signals and continuity of the solution map (the Itô/Marcus map) at discontinuous drivers.\n\nWhich of the following statements are correct?\n\nA. Under the uniform topology on $\\mathbb{D}([0,T],\\mathbb{R}^m)$, the solution map $z\\mapsto X$ for jump-driven equations is continuous at every càdlàg driver $z$, provided the coefficients are globally Lipschitz as above.\n\nB. The sequence $(z^n)_{n\\ge 1}$ converges to $z$ in the Skorokhod $J_1$ topology but not in the uniform topology. Under the stated Lipschitz and linear growth conditions on $V$, the Marcus solution map $z\\mapsto X$ is continuous in the $J_1$ topology at $z$, so $X^n\\to X$ in $J_1$.\n\nC. For jump stochastic differential equations driven by càdlàg signals, continuity of the solution map in the $J_1$ topology holds under globally Lipschitz coefficients with linear growth. The uniform topology fails to capture stability at discontinuous drivers because arbitrarily small perturbations in jump times cannot be made small in the supremum norm without exactly matching the jump schedule.\n\nD. Continuity of the solution map for jump-driven equations can never hold in the Skorokhod $J_1$ topology; one must instead use the Skorokhod $M_1$ topology to recover any form of continuity.\n\nSelect all correct options. Justify your choices based solely on the definitions provided and the canonical Marcus jump-update structure, without appealing to shortcut formulas. Your reasoning should explicitly identify where uniform topology fails and under what conditions the $J_1$ topology succeeds for jump stochastic differential equations.", "solution": "We begin from the topological definitions and the canonical (Marcus) jump-update structure. The driver space $\\mathbb{D}([0,T],\\mathbb{R}^m)$ encodes jumps. The uniform topology uses the supremum norm $d_\\infty$, which does not allow any time rearrangement; the Skorokhod $J_1$ topology allows small, strictly increasing time changes $\\lambda$ to align jump times while controlling both the size of the time change and the discrepancy in path values under the time change. \n\nBy construction, $z$ has a single jump of size $\\xi$ at $t_0$, while for each $n$, $z^n$ has two jumps of size $\\xi/2$ at $t_0 - 1/n$ and $t_0 + 1/n$. We first analyze convergence of $(z^n)$ to $z$ under the two topologies:\n\n1. Uniform topology $d_\\infty$: If two càdlàg paths $z^1,z^2$ have jumps at different times or with different sizes, the supremum norm discrepancy near the jump cannot be small. In our case, for any $n$, on the interval $\\left[t_0,\\,t_0+\\frac{1}{n}\\right)$, the path $z^n$ has performed only the first half-jump $\\xi/2$ (since the second half-jump occurs later at $t_0+1/n$), whereas $z$ has performed the full jump $\\xi$ immediately at $t_0$. Therefore, on $\\left[t_0,\\,t_0+\\frac{1}{n}\\right)$,\n$$\n\\Vert z^n(t) - z(t) \\Vert \\ge \\left\\Vert \\frac{\\xi}{2} - \\xi \\right\\Vert = \\frac{1}{2}\\Vert \\xi\\Vert,\n$$\nand consequently $\\sup_{t\\in[0,T]} \\Vert z^n(t)-z(t)\\Vert \\ge \\frac{1}{2}\\Vert \\xi\\Vert$ for all $n$. Hence, $d_\\infty(z^n,z) \\not\\to 0$. Thus $(z^n)$ does not converge to $z$ under the uniform topology.\n\n2. Skorokhod $J_1$ topology $d_{J_1}$: We can construct a time change $\\lambda_n$ that compresses the small interval containing the two jumps of $z^n$ onto the single jump time $t_0$ of $z$. For example, define $\\lambda_n$ to be the identity outside a small neighborhood of $t_0$, and map both $t_0 - 1/n$ and $t_0 + 1/n$ to $t_0$ with a strictly increasing, piecewise linear interpolation so that the two jumps of $z^n$ are applied in rapid succession within a vanishingly small time window that is sent to $t_0$ by $\\lambda_n$. Then $\\sup_{t\\in[0,T]} \\Vert \\lambda_n(t)-t\\Vert \\le \\frac{1}{n} \\to 0$, and by construction, on the time-changed argument $z^n\\circ\\lambda_n$, the two half-jumps occur arbitrarily close to $t_0$. Because $z$ has the full jump $\\xi$ at $t_0$, and $z^n\\circ\\lambda_n$ has two jumps $\\xi/2$ that coalesce to $t_0$, we have $\\sup_{t\\in[0,T]} \\Vert z^n(\\lambda_n(t)) - z(t) \\Vert \\to 0$ as $n\\to\\infty$. Therefore $d_{J_1}(z^n,z)\\to 0$.\n\nWe now address the continuity of the solution map under these two topologies.\n\nCanonical Marcus jump-update structure: At a jump of size $\\eta\\in\\mathbb{R}^m$, the solution updates by flowing along the vector field $V$ scaled by $\\eta$ for unit control time. Denote this jump-update by the mapping $\\Phi_\\eta:\\mathbb{R}^d\\to\\mathbb{R}^d$, defined as the endpoint at control time $1$ of the ordinary differential equation $\\dot{y}(s) = V(y(s))\\eta$ with initial condition $y(0)=x$. Between jumps, the solution responds continuously to the continuous part of the driver according to the driven dynamics. Two key structural properties used below are:\n\n- Continuity of $\\Phi_\\eta$ in both arguments: for globally Lipschitz $V$, the map $(x,\\eta)\\mapsto \\Phi_\\eta(x)$ is continuous and locally Lipschitz in $x$, and continuous in $\\eta$.\n- Additive composition for successive jumps with the same orientation: for any $\\eta\\in\\mathbb{R}^m$, applying two successive jump-updates of size $\\eta/2$ equals applying a single jump-update of size $\\eta$, i.e., $\\Phi_{\\eta/2}\\circ \\Phi_{\\eta/2} = \\Phi_\\eta$. This follows from the linear dependence of the ODE $\\dot{y}(s)=V(y(s))\\eta$ on the parameter $\\eta$ when concatenated over successive unit control times.\n\nContinuity in $J_1$: The $J_1$ topology permits aligning jump times via time changes. For our sequence $(z^n)$, the two half-jumps in $z^n$ are brought to $t_0$ in the time-changed path $z^n\\circ\\lambda_n$. Under globally Lipschitz $V$ with linear growth, standard stability of ODE flows implies that between jumps, perturbations in the driver lead to small perturbations of the trajectory, and at jumps, the update is continuous in the jump size. Moreover, because $\\Phi_{\\xi/2}\\circ\\Phi_{\\xi/2}=\\Phi_\\xi$, the net effect of the two half-jumps equals the effect of the single full jump in the limit as the time window collapses to a point under $\\lambda_n$. Therefore, there exists a sequence of time changes $\\lambda_n$ such that\n$$\n\\sup_{t\\in[0,T]} \\Vert \\lambda_n(t)-t\\Vert \\to 0 \\quad \\text{and} \\quad \\sup_{t\\in[0,T]} \\Vert X^n(\\lambda_n(t)) - X(t)\\Vert \\to 0,\n$$\nwhich exactly asserts that $X^n\\to X$ in the $J_1$ topology. This establishes continuity of the solution map $z\\mapsto X$ at $z$ under $J_1$.\n\nFailure of the uniform topology: The uniform topology does not allow any time-change; thus nearby jump times cannot be aligned. As demonstrated, $(z^n)$ does not converge to $z$ in $d_\\infty$. More generally, any sequence that perturbs jump times by amounts that do not vanish exactly at the jump will fail to be close in the supremum norm by at least a fixed fraction of the jump size on a nontrivial interval. Consequently, the uniform topology is too strong to capture stability of solutions at discontinuous drivers produced by physically natural approximations (e.g., multiple small jumps coalescing to one). Continuity of the solution map at such points in the sense of the uniform topology is either false or vacuous for relevant approximations: even if the map is continuous along sequences that converge in $d_\\infty$ (which forces exact agreement of the jump schedule asymptotically), those sequences exclude the typical convergence scenarios of jump-driven signals. Therefore, for jump stochastic differential equations, $J_1$ is the appropriate topology for continuity, whereas the uniform topology fails to provide a robust notion of continuity at discontinuous drivers.\n\nWe now analyze each option:\n\nOption A: It claims uniform continuity at every càdlàg driver $z$ under global Lipschitz coefficients. The uniform topology requires matching jumps exactly; perturbations in jump times, even if small, induce fixed-size discrepancies in $d_\\infty$. As shown, sequences like $(z^n)$ do not converge in the uniform topology, and continuity under $d_\\infty$ is not available in general at discontinuous drivers. Moreover, even restricting to sequences that do converge in $d_\\infty$, uniform continuity at a point with jumps is not guaranteed solely by Lipschitz coefficients because the uniform topology disallows the time-alignment needed to control the effect of nearby jump clusters. Thus, this statement is Incorrect.\n\nOption B: It asserts $z^n\\to z$ in $J_1$ but not uniformly, and continuity of the Marcus solution map under $J_1$ at $z$ (with $X^n\\to X$ in $J_1$). We proved $d_{J_1}(z^n,z)\\to 0$ by constructing appropriate $\\lambda_n$ and showed $d_\\infty(z^n,z)\\not\\to 0$. Under globally Lipschitz and linear growth $V$, the Marcus solution map is continuous in $J_1$, with the key identity $\\Phi_{\\xi/2}\\circ\\Phi_{\\xi/2}=\\Phi_\\xi$ and stability of flows yielding $X^n\\to X$ in $J_1$. Therefore, this statement is Correct.\n\nOption C: It states that $J_1$ continuity of the solution map for jump SDEs holds under globally Lipschitz coefficients with linear growth, and explains why the uniform topology fails at discontinuous drivers (no time-change to align jumps, so small perturbations in jump times cannot be small in the supremum norm). This matches the derivation: global Lipschitz and linear growth ensure stability of the continuous evolution and continuity of jump updates; $J_1$ allows time alignment of jumps, making continuity viable; $d_\\infty$ lacks this alignment and therefore fails to capture stability at jumps. Hence, this statement is Correct.\n\nOption D: It claims that $J_1$ continuity never holds and only $M_1$ can restore continuity. This contradicts the demonstrated $J_1$ continuity for the Marcus solution map under globally Lipschitz and linear growth conditions and appropriate time alignment. Therefore, this statement is Incorrect.\n\nIn summary, the correct statements are B and C, which identify the failure mechanism of the uniform topology and the conditions under which the Skorokhod $J_1$ topology yields continuity for jump stochastic differential equations via the canonical (Marcus) pathwise interpretation.", "answer": "$$\\boxed{BC}$$", "id": "2994150"}]}