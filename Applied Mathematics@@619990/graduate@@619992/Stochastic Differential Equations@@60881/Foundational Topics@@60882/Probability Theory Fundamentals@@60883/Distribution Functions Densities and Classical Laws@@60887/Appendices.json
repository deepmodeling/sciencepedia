{"hands_on_practices": [{"introduction": "The journey into the world of stochastic processes begins with a solid understanding of its most fundamental building block: Brownian motion. This first exercise takes you back to basics, challenging you to derive the probability density function for an increment of Brownian motion directly from its axiomatic definition. By working from first principles—namely, the properties of stationary, independent, and Gaussian increments—you will build the iconic Gaussian kernel that underpins the entire theory of diffusion processes [@problem_id:2973114]. This practice is essential for internalizing how abstract properties translate into concrete mathematical forms and provides a bedrock for all further study.", "problem": "Consider a real-valued stochastic process $(B_t)_{t \\ge 0}$ with $B_0 = 0$ almost surely and continuous sample paths, such that for any $0 \\leq s < t$, the increment $B_t - B_s$ is Gaussian, and increments over disjoint time intervals are independent and stationary. Assume the normalization $\\operatorname{Var}(B_1) = 1$, which fixes the scale and identifies a standard Brownian motion model.\n\nStarting from these defining properties and only using foundational facts about Gaussian distributions, independence, stationarity, and characteristic functions, derive the law of the increment $B_t - B_s$ as a function of the lag $t - s$. Then, from this law, compute the Probability Density Function (PDF) of the increment $B_t - B_s$ evaluated at a generic real argument $x \\in \\mathbb{R}$.\n\nYour final answer must be a single closed-form analytic expression giving the PDF in terms of $t - s$ and $x$. No rounding is required.", "solution": "The problem statement describes a real-valued stochastic process $(B_t)_{t \\ge 0}$ which is a standard one-dimensional Brownian motion. We are tasked with deriving the probability density function (PDF) of the increment $B_t - B_s$ for $0 \\leq s < t$ from the given axiomatic properties.\n\nThe defining properties provided are:\n1.  $B_0 = 0$ almost surely.\n2.  The sample paths $t \\mapsto B_t$ are continuous.\n3.  Increments over disjoint time intervals are independent. For any $0 \\leq t_1 < t_2 \\leq t_3 < t_4$, the random variables $B_{t_2} - B_{t_1}$ and $B_{t_4} - B_{t_3}$ are independent.\n4.  The increment $B_t - B_s$ has a Gaussian (normal) distribution for any $0 \\leq s < t$.\n5.  The distribution of the increment $B_t - B_s$ is stationary, meaning it depends only on the time difference $t-s$.\n6.  The process is normalized by $\\operatorname{Var}(B_1) = 1$.\n7.  The problem refers to this as a \"standard Brownian motion model,\" which definitionally implies a zero-mean process.\n\nLet us determine the law of the increment $B_t - B_s$. Since we are given that it is a Gaussian distribution, its law is completely determined by its mean and variance.\n\nFirst, we determine the mean of the increment, $\\mathbb{E}[B_t - B_s]$.\nLet $\\mu(t) = \\mathbb{E}[B_t]$ for $t \\ge 0$. From the property $B_0=0$ a.s., we have $\\mu(0) = \\mathbb{E}[B_0] = 0$.\nFor any $s$ and $t$ with $0 \\leq s < t$, we can write $B_t = B_s + (B_t - B_s)$. By linearity of expectation, we have $\\mathbb{E}[B_t] = \\mathbb{E}[B_s] + \\mathbb{E}[B_t - B_s]$.\nThe stationarity of increments implies that the distribution of $B_t - B_s$ is the same as the distribution of $B_{t-s} - B_0 = B_{t-s}$. Therefore, $\\mathbb{E}[B_t - B_s] = \\mathbb{E}[B_{t-s}]$.\nSubstituting this into the previous equation gives $\\mathbb{E}[B_t] = \\mathbb{E}[B_s] + \\mathbb{E}[B_{t-s}]$, or $\\mu(t) = \\mu(s) + \\mu(t-s)$. This is Cauchy's functional equation for the function $\\mu$.\nThe continuity of sample paths implies that $\\mu(t)$ is a continuous function of $t$. The only continuous solutions to Cauchy's functional equation are of the form $\\mu(t) = ct$ for some constant $c$.\nAs the problem identifies the process as a \"standard Brownian motion,\" this implies the process has zero drift, which means $\\mathbb{E}[B_t] = 0$ for all $t$. This corresponds to setting the constant $c=0$.\nTherefore, $\\mathbb{E}[B_t] = 0$ for all $t \\ge 0$.\nThe mean of the increment is then $\\mathbb{E}[B_t - B_s] = \\mathbb{E}[B_t] - \\mathbb{E}[B_s] = 0 - 0 = 0$.\n\nNext, we determine the variance of the increment, $\\operatorname{Var}(B_t - B_s)$.\nLet $v(t) = \\operatorname{Var}(B_t) = \\operatorname{Var}(B_t - B_0)$. Since $\\mathbb{E}[B_t]=0$, we have $v(t) = \\mathbb{E}[B_t^2]$.\nFrom $B_0=0$, it follows that $v(0) = \\operatorname{Var}(B_0) = 0$.\nThe stationarity of increments implies that the distribution of $B_t - B_s$ depends only on $t-s$. Consequently, its variance must also depend only on $t-s$.\nSo, $\\operatorname{Var}(B_t - B_s) = \\operatorname{Var}(B_{t-s} - B_0) = v(t-s)$.\nNow consider the identity $B_t = B_s + (B_t - B_s)$ for $0 \\leq s < t$.\nThe intervals $[0,s]$ and $[s,t]$ are disjoint, so the increments $B_s - B_0 = B_s$ and $B_t-B_s$ are independent.\nFor independent random variables, the variance of the sum is the sum of the variances.\nThus, $\\operatorname{Var}(B_t) = \\operatorname{Var}(B_s + (B_t - B_s)) = \\operatorname{Var}(B_s) + \\operatorname{Var}(B_t - B_s)$.\nUsing our notation, this becomes $v(t) = v(s) + v(t-s)$. This is again Cauchy's functional equation for the function $v(t)$.\nThe continuity of paths implies that $v(t)$ is a continuous function of $t$. To see this, $v(t-s) = \\operatorname{Var}(B_t-B_s) = \\mathbb{E}[(B_t-B_s)^2]$. As $t \\to s$, the continuity of paths means $B_t \\to B_s$, and it can be shown this convergence also holds in $L^2$, so $\\mathbb{E}[(B_t-B_s)^2] \\to 0$. This implies $v(u) \\to 0$ as $u \\to 0^+$, which shows $v$ is continuous at $0$. With the functional equation, this implies $v$ is continuous for all $t \\ge 0$.\nThe continuous solutions to Cauchy's functional equation are $v(t) = kt$ for some constant $k$.\nWe are given the normalization condition $\\operatorname{Var}(B_1) = 1$. In our notation, this is $v(1)=1$.\nSubstituting $t=1$ into our solution form gives $v(1) = k \\cdot 1 = k$. Thus, $k=1$.\nSo, the variance function is $v(t) = t$.\nThe variance of the increment $B_t - B_s$ is then $\\operatorname{Var}(B_t - B_s) = v(t-s) = t-s$.\n\nIn summary, the increment $B_t - B_s$ follows a Gaussian distribution with mean $\\mu = 0$ and variance $\\sigma^2 = t-s$. This specifies its law: $B_t - B_s \\sim \\mathcal{N}(0, t-s)$.\n\nFinally, we compute the Probability Density Function (PDF) for this distribution. The PDF of a general Gaussian random variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ at a point $x \\in \\mathbb{R}$ is given by the formula:\n$$f(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$$\nFor the increment $B_t - B_s$, we substitute $\\mu=0$ and $\\sigma^2 = t-s$. The PDF, evaluated at a generic argument $x$, is therefore:\n$$p(x; t-s) = \\frac{1}{\\sqrt{2\\pi(t-s)}} \\exp\\left(-\\frac{(x - 0)^2}{2(t-s)}\\right)$$\n$$p(x; t-s) = \\frac{1}{\\sqrt{2\\pi(t-s)}} \\exp\\left(-\\frac{x^2}{2(t-s)}\\right)$$\nThis is the required closed-form analytic expression for the PDF of the increment $B_t - B_s$.", "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{2\\pi(t-s)}} \\exp\\left(-\\frac{x^2}{2(t-s)}\\right)}\n$$", "id": "2973114"}, {"introduction": "Once we have established the law of Brownian motion, we can explore its profound symmetries. This problem focuses on the crucial concept of scaling, a property that reveals a deep connection between the process's behavior at different time and space resolutions. You will first verify the scaling relation for the transition density of Brownian motion by leveraging its connection to the heat equation, a powerful technique that avoids using the explicit formula [@problem_id:2973073]. Armed with this symmetry, you will then deduce how key statistical quantities, such as moments, evolve over time, illustrating how abstract properties can be a powerful tool for practical calculations.", "problem": "Let $(B_t)_{t \\ge 0}$ be a $d$-dimensional Brownian motion (BM), that is, a continuous-time stochastic process with stationary independent increments, starting at $B_0 = x \\in \\mathbb{R}^d$, and with generator $\\frac{1}{2}\\Delta$, where $\\Delta$ is the Laplacian on $\\mathbb{R}^d$. Let $p_t(x,y)$ denote its transition probability density function (PDF), so that for each fixed $t>0$ and $x \\in \\mathbb{R}^d$, the function $y \\mapsto p_t(x,y)$ is the unique fundamental solution to the Kolmogorov forward partial differential equation (PDE), also known as the heat equation,\n$$\n\\partial_t p_t(x,y) = \\frac{1}{2}\\Delta_y p_t(x,y), \\qquad \\lim_{t \\downarrow 0} p_t(x,\\cdot) = \\delta_x \\text{ in the sense of distributions.}\n$$\nWithout using any explicit closed form for $p_t(x,y)$, verify the scaling relation\n$$\np_t(x,y) \\;=\\; t^{-d/2}\\, p_1\\!\\left(\\frac{x}{\\sqrt{t}},\\,\\frac{y}{\\sqrt{t}}\\right), \\qquad t>0,\\; x,y \\in \\mathbb{R}^d.\n$$\nThen, using this scaling and the spatial homogeneity of Brownian motion, deduce how the $q$-th absolute radial moment\n$$\nM_q(t;x) \\;:=\\; \\mathbb{E}_x\\!\\left[\\,|B_t - x|^q\\,\\right]\n$$\nscales with $t$ for any fixed $q \\ge 0$, and determine the exact constant of proportionality in closed form as a function of $d$ and $q$. Express your final answer as a single analytic expression for $M_q(t;x)$ in terms of $t$, $d$, and $q$ (note that by spatial homogeneity it does not depend on $x$). No numerical approximation is required.", "solution": "The solution proceeds in three parts as requested by the problem.\n\n**Part 1: Verification of the Scaling Relation**\n\nWe are asked to verify the scaling relation\n$$p_t(x,y) = t^{-d/2} p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{y}{\\sqrt{t}}\\right)$$\nby showing that the right-hand side satisfies the same heat equation and initial condition as $p_t(x,y)$. The uniqueness of the fundamental solution then implies their equality.\n\nLet's define a function $\\tilde{p}_t(x,y)$ as the right-hand side of the proposed relation:\n$$\\tilde{p}_t(x,y) := t^{-d/2} p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{y}{\\sqrt{t}}\\right)$$\nWe will show that $\\tilde{p}_t(x,y)$ satisfies $\\partial_t \\tilde{p}_t(x,y) = \\frac{1}{2}\\Delta_y \\tilde{p}_t(x,y)$ and $\\lim_{t\\downarrow 0} \\tilde{p}_t(x, \\cdot) = \\delta_x$.\n\nThis is a specific instance of the general scaling property of the heat equation. Let's introduce the scaling transformation: $s = c^2 t$, $\\xi = cx$, $\\eta = cy$ for some constant $c>0$. The function $p_t(x,y)$ transforms into $p_{s/c^2}(\\xi/c, \\eta/c)$.\nConsider the function $u_c(t,x,y) = c^d p_{c^2t}(cx, cy)$. We check if it satisfies the heat equation.\nThe time derivative is:\n$$\\partial_t u_c(t,x,y) = c^d \\cdot c^2 \\cdot (\\partial_s p_s)(c^2 t, cx, cy)\\Big|_{s=c^2t} = c^{d+2} (\\partial_s p_s)(s, cx, cy)$$\nThe Laplacian with respect to $y$ is:\n$$\\Delta_y u_c(t,x,y) = c^d \\cdot c^2 \\cdot (\\Delta_\\eta p_{c^2t})(cx, cy)\\Big|_{\\eta=cy} = c^{d+2} (\\Delta_\\eta p_s)(s, cx, \\eta)$$\nSince $p_s(\\xi, \\eta)$ satisfies the heat equation $\\partial_s p_s = \\frac{1}{2}\\Delta_\\eta p_s$, we have:\n$$\\partial_t u_c(t,x,y) = c^{d+2} \\left[ \\frac{1}{2} (\\Delta_\\eta p_s)(s, cx, \\eta) \\right] = \\frac{1}{2} c^{d+2} (\\Delta_\\eta p_s)(s, cx, \\eta) = \\frac{1}{2} \\Delta_y u_c(t,x,y)$$\nThus, $u_c(t,x,y)$ also satisfies the heat equation.\n\nNext, we check the initial condition. For any smooth, compactly supported test function $\\phi(y)$, we examine the limit as $t \\downarrow 0$:\n$$ \\lim_{t\\downarrow 0} \\int_{\\mathbb{R}^d} u_c(t,x,y) \\phi(y) dy = \\lim_{t\\downarrow 0} \\int_{\\mathbb{R}^d} c^d p_{c^2t}(cx, cy) \\phi(y) dy $$\nLet's change the integration variable to $z = cy$. Then $y = z/c$ and $dy = c^{-d} dz$.\n$$ = \\lim_{t\\downarrow 0} \\int_{\\mathbb{R}^d} c^d p_{c^2t}(cx, z) \\phi(z/c) (c^{-d} dz) = \\lim_{t\\downarrow 0} \\int_{\\mathbb{R}^d} p_{c^2t}(cx, z) \\phi(z/c) dz $$\nAs $t \\downarrow 0$, the time argument $c^2t$ also goes to $0$. By the definition of $p_t$ as a fundamental solution, the distribution $p_{c^2t}(cx, \\cdot)$ converges to the Dirac delta distribution $\\delta_{cx}(\\cdot)$. Therefore, the integral converges to the test function evaluated at $cx$:\n$$ \\int_{\\mathbb{R}^d} \\delta_{cx}(z) \\phi(z/c) dz = \\phi(cx/c) = \\phi(x) $$\nThis is precisely the definition of convergence to $\\delta_x$ in the sense of distributions. Thus, $\\lim_{t\\downarrow 0} u_c(t,x,\\cdot) = \\delta_x$.\n\nSince $u_c(t,x,y)$ satisfies the same PDE and initial condition as $p_t(x,y)$, by the uniqueness of the fundamental solution, we must have $u_c(t,x,y) = p_t(x,y)$.\n$$ p_t(x,y) = c^d p_{c^2 t}(cx, cy) $$\nThis scaling relation is valid for any $c > 0$. To obtain the specific form requested, we choose $c = 1/\\sqrt{t}$. With this choice, $c^2 t = 1$.\n$$ p_t(x,y) = (t^{-1/2})^d p_1(t^{-1/2}x, t^{-1/2}y) = t^{-d/2} p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{y}{\\sqrt{t}}\\right) $$\nThis completes the verification of the scaling relation.\n\n**Part 2: Scaling of the Moment $M_q(t;x)$**\n\nThe $q$-th absolute radial moment is defined as $M_q(t;x) = \\mathbb{E}_x[|B_t - x|^q]$. Using the PDF $p_t(x,y)$, this is expressed as an integral:\n$$ M_q(t;x) = \\int_{\\mathbb{R}^d} |y-x|^q p_t(x,y) dy $$\nNow, we substitute the scaling relation derived in Part 1:\n$$ M_q(t;x) = \\int_{\\mathbb{R}^d} |y-x|^q \\left( t^{-d/2} p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{y}{\\sqrt{t}}\\right) \\right) dy $$\nWe perform a change of integration variable. Let $z = \\frac{y-x}{\\sqrt{t}}$. This implies $y = x + z\\sqrt{t}$ and the Jacobian determinant gives $dy = (\\sqrt{t})^d dz = t^{d/2} dz$. Also, $|y-x|^q = |z\\sqrt{t}|^q = t^{q/2} |z|^q$. The arguments of $p_1$ become $\\frac{x}{\\sqrt{t}}$ and $\\frac{y}{\\sqrt{t}} = \\frac{x+z\\sqrt{t}}{\\sqrt{t}} = \\frac{x}{\\sqrt{t}} + z$.\nSubstituting these into the integral:\n$$ M_q(t;x) = \\int_{\\mathbb{R}^d} (t^{q/2}|z|^q) \\left( t^{-d/2} p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{x}{\\sqrt{t}} + z\\right) \\right) (t^{d/2} dz) $$\n$$ M_q(t;x) = t^{q/2} \\int_{\\mathbb{R}^d} |z|^q p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{x}{\\sqrt{t}} + z\\right) dz $$\nThe spatial homogeneity of Brownian motion implies that its transition density is spatially invariant, i.e., $p_t(x,y)$ depends only on the displacement vector $y-x$. Thus, $p_1(\\xi, \\eta) = p_1(0, \\eta-\\xi)$. Applying this to our integral:\n$$ p_1\\left(\\frac{x}{\\sqrt{t}}, \\frac{x}{\\sqrt{t}} + z\\right) = p_1\\left(0, \\left(\\frac{x}{\\sqrt{t}} + z\\right) - \\frac{x}{\\sqrt{t}}\\right) = p_1(0, z) $$\nThe integral is now independent of $x$:\n$$ M_q(t;x) = t^{q/2} \\int_{\\mathbb{R}^d} |z|^q p_1(0,z) dz $$\nThe integral is a constant that depends only on the dimension $d$ and the moment order $q$. Let us denote this constant by $C_{d,q}$.\n$$ C_{d,q} = \\int_{\\mathbb{R}^d} |z|^q p_1(0,z) dz = \\mathbb{E}_0[|B_1|^q] $$\nTherefore, the moment scales with time as:\n$$ M_q(t;x) = C_{d,q} \\, t^{q/2} $$\nThis shows that $M_q(t;x)$ scales as $t^{q/2}$ and is independent of the starting position $x$.\n\n**Part 3: Calculation of the Proportionality Constant**\n\nTo find the constant $C_{d,q}$, we must now use the explicit form for $p_1(0,z)$. For a $d$-dimensional Brownian motion with generator $\\frac{1}{2}\\Delta$, the process $B_t$ starting at $0$ has a multivariate normal distribution with mean $0$ and covariance matrix $tI_d$. Its PDF is $p_t(0,y) = (2\\pi t)^{-d/2} \\exp(-|y|^2/(2t))$. For $t=1$, this is:\n$$ p_1(0,z) = (2\\pi)^{-d/2} \\exp(-|z|^2/2) $$\nThe constant $C_{d,q}$ is the integral:\n$$ C_{d,q} = \\int_{\\mathbb{R}^d} |z|^q (2\\pi)^{-d/2} \\exp(-|z|^2/2) dz $$\nTo evaluate this integral, we switch to $d$-dimensional hyperspherical coordinates. Let $r = |z|$ be the radius. The volume element is $dz = r^{d-1} dr d\\Omega_{d-1}$, where $d\\Omega_{d-1}$ is the surface element of the unit $(d-1)$-sphere, $S^{d-1}$. The integral of $d\\Omega_{d-1}$ over the sphere is its surface area, $A_{d-1} = \\frac{2\\pi^{d/2}}{\\Gamma(d/2)}$.\nSince the integrand depends only on $r$, we can separate the radial and angular parts:\n$$ C_{d,q} = (2\\pi)^{-d/2} \\left(\\int_{S^{d-1}} d\\Omega_{d-1}\\right) \\left(\\int_0^\\infty r^q \\exp(-r^2/2) r^{d-1} dr\\right) $$\n$$ C_{d,q} = (2\\pi)^{-d/2} \\cdot \\frac{2\\pi^{d/2}}{\\Gamma(d/2)} \\cdot \\int_0^\\infty r^{q+d-1} \\exp(-r^2/2) dr $$\n$$ C_{d,q} = 2^{-d/2}\\pi^{-d/2} \\cdot \\frac{2\\pi^{d/2}}{\\Gamma(d/2)} \\cdot \\int_0^\\infty r^{q+d-1} \\exp(-r^2/2) dr = \\frac{2^{1-d/2}}{\\Gamma(d/2)} \\int_0^\\infty r^{q+d-1} \\exp(-r^2/2) dr $$\nLet's evaluate the remaining radial integral, $I_{rad} = \\int_0^\\infty r^{q+d-1} \\exp(-r^2/2) dr$. We use the substitution $u = r^2/2$. Then $r^2 = 2u$, so $r = \\sqrt{2u}$, and $dr = \\frac{1}{\\sqrt{2u}} du$.\n$$ I_{rad} = \\int_0^\\infty (2u)^{(q+d-1)/2} \\exp(-u) \\frac{du}{\\sqrt{2u}} $$\n$$ I_{rad} = \\int_0^\\infty 2^{(q+d-1)/2} u^{(q+d-1)/2} \\exp(-u) 2^{-1/2} u^{-1/2} du $$\n$$ I_{rad} = 2^{(q+d-2)/2} \\int_0^\\infty u^{(q+d-2)/2} \\exp(-u) du $$\nThe exponent of $u$ can be written as $\\frac{d+q}{2} - 1$. The integral is now in the form of the Gamma function, $\\Gamma(k) = \\int_0^\\infty u^{k-1} e^{-u} du$.\n$$ I_{rad} = 2^{(d+q-2)/2} \\Gamma\\left(\\frac{d+q}{2}\\right) $$\nNow we substitute this back into the expression for $C_{d,q}$:\n$$ C_{d,q} = \\frac{2^{1-d/2}}{\\Gamma(d/2)} \\cdot 2^{(d+q-2)/2} \\Gamma\\left(\\frac{d+q}{2}\\right) $$\nCombining the powers of $2$:\n$$ 2^{1 - d/2 + (d+q-2)/2} = 2^{(2-d+d+q-2)/2} = 2^{q/2} $$\nSo the constant is:\n$$ C_{d,q} = 2^{q/2} \\frac{\\Gamma\\left(\\frac{d+q}{2}\\right)}{\\Gamma\\left(\\frac{d}{2}\\right)} $$\nFinally, we write the full expression for the moment $M_q(t;x)$:\n$$ M_q(t;x) = C_{d,q} \\, t^{q/2} = \\left(2^{q/2} \\frac{\\Gamma\\left(\\frac{d+q}{2}\\right)}{\\Gamma\\left(\\frac{d}{2}\\right)}\\right) t^{q/2} = (2t)^{q/2} \\frac{\\Gamma\\left(\\frac{d+q}{2}\\right)}{\\Gamma\\left(\\frac{d}{2}\\right)} $$\nThis is the final analytical expression for the $q$-th absolute radial moment.", "answer": "$$\\boxed{(2t)^{q/2} \\frac{\\Gamma\\left(\\frac{d+q}{2}\\right)}{\\Gamma\\left(\\frac{d}{2}\\right)}}$$", "id": "2973073"}, {"introduction": "Different stochastic differential equations give rise to different probability laws on path space, but how can we rigorously distinguish them? This practice delves into this advanced question, exploring the distinct roles of the drift and diffusion coefficients in shaping the law of an Itô process. By analyzing several scenarios, you will confront the fundamental difference between an equivalent change of measure, which can alter the drift (Girsanov's Theorem), and a change in the diffusion coefficient, which results in mutually singular measures [@problem_id:2973146]. This exercise illuminates the role of quadratic variation as an almost-sure path property that serves as an unalterable signature of the process's intrinsic randomness.", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\in[0,T]},\\mathbb{P})$ supporting a one-dimensional Brownian motion (BM) $W=(W_t)_{t\\in[0,T]}$ with $W_0=0$. For deterministic, bounded, measurable functions $b,\\tilde{b}:[0,T]\\to\\mathbb{R}$ and constants $\\sigma,\\sigma'>0$, define the processes $X$, $Y$, and $Z$ by the stochastic differential equations (SDEs)\n$$\ndX_t = b(t)\\,dt + \\sigma\\,dW_t,\\quad X_0=0,\n$$\n$$\ndY_t = \\tilde{b}(t)\\,dt + \\sigma\\,dW_t,\\quad Y_0=0,\n$$\n$$\ndZ_t = \\sigma'\\,dW_t,\\quad Z_0=0.\n$$\nView $X$, $Y$, and $Z$ as random elements of the path space $C([0,T];\\mathbb{R})$ with its Borel $\\sigma$-algebra, and denote their induced laws on path space by $\\mathbb{P}^X$, $\\mathbb{P}^Y$, and $\\mathbb{P}^Z$. Recall the definition of quadratic variation: for a continuous semimartingale $M$, the quadratic variation $\\langle M\\rangle_t$ is the limit in probability (and almost surely for continuous martingales) of the partition sums $\\sum_{k}(M_{t_{k+1}}-M_{t_k})^2$ as the mesh of the partition $\\{0=t_0<t_1<\\dots<t_n=t\\}$ tends to $0$. Also recall the well-tested fact that, under suitable square-integrability conditions (e.g., Novikov's condition), changes in the drift of an Itô process can be realized by an equivalent change of measure (Girsanov's theorem), while equivalent measure changes do not alter quadratic variation.\n\nWhich of the following statements are true?\n\nA. If $b-\\tilde{b}\\in L^2([0,T])$ and an exponential integrability condition ensuring applicability of Girsanov's theorem holds, then $\\mathbb{P}^X$ and $\\mathbb{P}^Y$ are mutually absolutely continuous on $C([0,T];\\mathbb{R})$.\n\nB. If $\\sigma\\neq\\sigma'$, then $\\mathbb{P}^X$ and $\\mathbb{P}^Z$ are mutually singular on $C([0,T];\\mathbb{R})$ because the quadratic variations $\\langle X\\rangle_t$ and $\\langle Z\\rangle_t$ are almost surely different deterministic functions of $t$.\n\nC. For each fixed $t\\in(0,T]$, both $X_t$ and $Z_t$ have Gaussian densities with respect to Lebesgue measure on $\\mathbb{R}$ that are mutually absolutely continuous; therefore, $\\mathbb{P}^X$ and $\\mathbb{P}^Z$ are mutually absolutely continuous on path space.\n\nD. Suppose we replace the constant diffusion $\\sigma$ in $X$ by a bounded, deterministic function $\\tilde{\\sigma}:[0,T]\\to(0,\\infty)$ such that $\\tilde{\\sigma}(t)\\neq\\sigma$ only on a set of Lebesgue measure zero. Then the resulting path law is still mutually singular with $\\mathbb{P}^X$.\n\nE. There is no equivalent change of probability measure on $C([0,T];\\mathbb{R})$ that transforms a BM-driven Itô process with diffusion coefficient $\\sigma$ into one with a different diffusion coefficient $\\sigma'$ (with $\\sigma\\neq\\sigma'$), because an equivalent measure cannot alter quadratic variation.\n\nSelect all correct options.", "solution": "The processes are defined by the SDEs:\n$$dX_t = b(t)\\,dt + \\sigma\\,dW_t,\\quad X_0=0$$\n$$dY_t = \\tilde{b}(t)\\,dt + \\sigma\\,dW_t,\\quad Y_0=0$$\n$$dZ_t = \\sigma'\\,dW_t,\\quad Z_0=0$$\nwhere $b(t)$ and $\\tilde{b}(t)$ are deterministic, bounded, measurable functions, and $\\sigma, \\sigma' > 0$ are constants. Their respective laws on the path space $C([0,T];\\mathbb{R})$ are denoted $\\mathbb{P}^X$, $\\mathbb{P}^Y$, and $\\mathbb{P}^Z$.\n\nWe will analyze each statement individually.\n\n**A. If $b-\\tilde{b}\\in L^2([0,T])$ and an exponential integrability condition ensuring applicability of Girsanov's theorem holds, then $\\mathbb{P}^X$ and $\\mathbb{P}^Y$ are mutually absolutely continuous on $C([0,T];\\mathbb{R})$.**\n\nThis statement addresses the relationship between the laws of two Itô processes that share the same diffusion coefficient but have different drifts. This is the canonical application of Girsanov's theorem.\n\nLet's consider the law $\\mathbb{P}^Y$. Under this measure, the canonical process on path space, let's call it $\\omega_t$, satisfies the SDE $d\\omega_t = \\tilde{b}(t)\\,dt + \\sigma\\,dW_t^{\\mathbb{P}^Y}$, where $W^{\\mathbb{P}^Y}$ is a Brownian motion under $\\mathbb{P}^Y$.\n\nWe wish to know if there exists a measure $\\mathbb{P}_{new}$ that is equivalent to $\\mathbb{P}^Y$ (i.e., mutually absolutely continuous) such that under $\\mathbb{P}_{new}$, the canonical process $\\omega_t$ satisfies $d\\omega_t = b(t)\\,dt + \\sigma\\,dW_t^{\\mathbb{P}_{new}}$. This would mean $\\mathbb{P}_{new}$ is the same as $\\mathbb{P}^X$.\n\nAccording to Girsanov's theorem, such a change of measure is possible if the process $\\theta_t$ defined by the change in drift, $b(t)\\,dt - \\tilde{b}(t)\\,dt = \\sigma \\theta_t \\,dW_t^{\\mathbb{P}^Y}$, satisfies certain conditions. Here, $\\theta_t = (b(t)-\\tilde{b}(t))/\\sigma$.\n\nFor the measures to be equivalent, the Girsanov exponential $L_T = \\exp\\left( \\int_0^T \\theta_s \\,dW_s^{\\mathbb{P}^Y} - \\frac{1}{2} \\int_0^T \\theta_s^2 \\,ds \\right)$ must be a martingale, which is ensured if Novikov's condition holds: $\\mathbb{E}_{\\mathbb{P}^Y}\\left[\\exp\\left(\\frac{1}{2}\\int_0^T \\theta_s^2 \\,ds\\right)\\right] < \\infty$.\n\nSince $b(t)$ and $\\tilde{b}(t)$ are deterministic functions, so is $\\theta_t$. The expectation is therefore trivial, and the condition reduces to requiring that the integral $\\int_0^T \\theta_s^2 \\,ds$ is finite.\n$$\\int_0^T \\theta_s^2 \\,ds = \\int_0^T \\left(\\frac{b(s)-\\tilde{b}(s)}{\\sigma}\\right)^2 ds = \\frac{1}{\\sigma^2} \\int_0^T (b(s)-\\tilde{b}(s))^2 ds < \\infty$$\nThis is equivalent to requiring $b-\\tilde{b} \\in L^2([0,T])$. The problem statement explicitly assumes this condition. The mentioned \"exponential integrability condition\" is Novikov's condition, which is automatically satisfied as shown. Thus, $\\mathbb{P}^X$ is absolutely continuous with respect to $\\mathbb{P}^Y$.\n\nFor mutual absolute continuity, we also need $\\mathbb{P}^Y$ to be absolutely continuous with respect to $\\mathbb{P}^X$. This involves a change of drift from $b(t)$ to $\\tilde{b}(t)$, with the Girsanov kernel being $(\\tilde{b}(t)-b(t))/\\sigma$. The condition is the same, $\\tilde{b}-b \\in L^2([0,T])$, which is equivalent to $b-\\tilde{b} \\in L^2([0,T])$.\n\nTherefore, the condition $b-\\tilde{b}\\in L^2([0,T])$ guarantees that $\\mathbb{P}^X$ and $\\mathbb{P}^Y$ are mutually absolutely continuous.\n\n**Verdict: Correct.**\n\n**B. If $\\sigma\\neq\\sigma'$, then $\\mathbb{P}^X$ and $\\mathbb{P}^Z$ are mutually singular on $C([0,T];\\mathbb{R})$ because the quadratic variations $\\langle X\\rangle_t$ and $\\langle Z\\rangle_t$ are almost surely different deterministic functions of $t$.**\n\nThe quadratic variation of an Itô process $dM_t = \\mu_t\\,dt + \\nu_t\\,dW_t$ is given by $\\langle M \\rangle_t = \\int_0^t \\nu_s^2 \\,ds$.\nFor the process $X_t$, the drift is $\\mu_t = b(t)$ and the diffusion is $\\nu_t = \\sigma$. Its quadratic variation is:\n$$\\langle X \\rangle_t = \\int_0^t \\sigma^2 \\,ds = \\sigma^2 t$$\nThis holds $\\mathbb{P}^X$-almost surely for every path.\nFor the process $Z_t$, the drift is $\\mu_t=0$ and the diffusion is $\\nu_t = \\sigma'$. Its quadratic variation is:\n$$\\langle Z \\rangle_t = \\int_0^t (\\sigma')^2 \\,ds = (\\sigma')^2 t$$\nThis holds $\\mathbb{P}^Z$-almost surely for every path.\n\nLet's define a set of paths in $C([0,T];\\mathbb{R})$ based on their quadratic variation:\n$$A = \\left\\{ \\omega \\in C([0,T];\\mathbb{R}) \\mid \\langle \\omega \\rangle_t = \\sigma^2 t \\text{ for all } t \\in [0,T] \\right\\}$$\nBy the properties of the process $X$, we have $\\mathbb{P}^X(A) = 1$.\n\nNow, let's consider the probability of this set $A$ under the measure $\\mathbb{P}^Z$. Under $\\mathbb{P}^Z$, a path $\\omega$ almost surely has quadratic variation $\\langle \\omega \\rangle_t = (\\sigma')^2 t$. The problem states that $\\sigma \\neq \\sigma'$, which implies $\\sigma^2 \\neq (\\sigma')^2$ since $\\sigma, \\sigma'>0$.\nTherefore, for a path $\\omega$ drawn according to $\\mathbb{P}^Z$, it is almost surely true that its quadratic variation is not $\\sigma^2 t$ for any $t>0$. Thus, such a path cannot be in $A$. This means $\\mathbb{P}^Z(A) = 0$.\n\nWe have found a measurable set $A$ such that $\\mathbb{P}^X(A) = 1$ and $\\mathbb{P}^Z(A) = 0$. This is the definition of mutual singularity of the measures $\\mathbb{P}^X$ and $\\mathbb{P}^Z$. The reasoning provided in the statement is precisely this argument.\n\n**Verdict: Correct.**\n\n**C. For each fixed $t\\in(0,T]$, both $X_t$ and $Z_t$ have Gaussian densities with respect to Lebesgue measure on $\\mathbb{R}$ that are mutually absolutely continuous; therefore, $\\mathbb{P}^X$ and $\\mathbb{P}^Z$ are mutually absolutely continuous on path space.**\n\nLet's analyze the distribution of the random variables $X_t$ and $Z_t$ for a fixed $t \\in (0,T]$.\nThe solution to the SDE for $X_t$ is $X_t = \\int_0^t b(s)\\,ds + \\sigma W_t$. Since $b(s)$ is deterministic, $\\int_0^t b(s)\\,ds$ is a constant for a fixed $t$. The random variable $W_t$ is normally distributed as $N(0,t)$. Thus, $X_t$ is a Gaussian random variable with mean $\\mathbb{E}[X_t] = \\int_0^t b(s)\\,ds$ and variance $\\text{Var}(X_t) = \\text{Var}(\\sigma W_t) = \\sigma^2 \\text{Var}(W_t) = \\sigma^2 t$. So, $X_t \\sim N(\\int_0^t b(s)ds, \\sigma^2 t)$.\n\nThe solution for $Z_t$ is $Z_t = \\sigma' W_t$. This is a Gaussian random variable with mean $\\mathbb{E}[Z_t] = 0$ and variance $\\text{Var}(Z_t) = (\\sigma')^2 t$. So, $Z_t \\sim N(0, (\\sigma')^2 t)$.\n\nBoth $X_t$ and $Z_t$ have Gaussian densities on $\\mathbb{R}$. Any two Gaussian distributions on $\\mathbb{R}$ (with non-zero variance) have supports equal to the entire real line, and thus their probability measures are mutually absolutely continuous with respect to each other (and with respect to Lebesgue measure). The first part of the statement is true.\n\nThe statement's conclusion is \"...therefore, $\\mathbb{P}^X$ and $\\mathbb{P}^Z$ are mutually absolutely continuous on path space.\" This inference is invalid. The equivalence of finite-dimensional distributions (such as the marginals at a single time $t$) does not imply the equivalence of the full path space measures. As established in the analysis of statement B, if $\\sigma \\neq \\sigma'$, the path space measures $\\mathbb{P}^X$ and $\\mathbb{P}^Z$ are mutually singular. This provides a direct counterexample to the logical step \"therefore\". The statement as a whole represents a logical fallacy.\n\n**Verdict: Incorrect.**\n\n**D. Suppose we replace the constant diffusion $\\sigma$ in $X$ by a bounded, deterministic function $\\tilde{\\sigma}:[0,T]\\to(0,\\infty)$ such that $\\tilde{\\sigma}(t)\\neq\\sigma$ only on a set of Lebesgue measure zero. Then the resulting path law is still mutually singular with $\\mathbb{P}^X$.**\n\nLet the new process be $\\tilde{X}$, satisfying $d\\tilde{X}_t = b(t)\\,dt + \\tilde{\\sigma}(t)\\,dW_t$ with $\\tilde{X}_0=0$. Its law is $\\mathbb{P}^{\\tilde{X}}$. We are comparing $\\mathbb{P}^{\\tilde{X}}$ with $\\mathbb{P}^X$.\n\nThe quadratic variation of $X$ is $\\langle X \\rangle_t = \\int_0^t \\sigma^2 ds = \\sigma^2 t$.\nThe quadratic variation of $\\tilde{X}$ is $\\langle \\tilde{X} \\rangle_t = \\int_0^t \\tilde{\\sigma}(s)^2 ds$.\n\nSince $\\tilde{\\sigma}(s) = \\sigma$ for almost every $s$ (with respect to Lebesgue measure), it follows that $\\tilde{\\sigma}(s)^2 = \\sigma^2$ almost everywhere. The Lebesgue integral of functions that are equal almost everywhere is the same. Therefore, $\\int_0^t \\tilde{\\sigma}(s)^2 ds = \\int_0^t \\sigma^2 ds = \\sigma^2 t$.\nSo, $\\langle \\tilde{X} \\rangle_t = \\langle X \\rangle_t$ for all $t$. The quadratic variation, which distinguishes processes with different diffusion coefficients, is identical in this case.\n\nMore formally, consider the difference between the two processes. Let $X_t = \\int_0^t b(s)ds + \\int_0^t \\sigma dW_s$ and $\\tilde{X}_t = \\int_0^t b(s)ds + \\int_0^t \\tilde{\\sigma}(s)dW_s$. The Itô stochastic integral has the property that if the integrand is zero almost everywhere with respect to the measure $dt$, then the stochastic integral is zero.\nLet $D_t = \\tilde{X}_t - X_t = \\int_0^t (\\tilde{\\sigma}(s) - \\sigma) dW_s$.\nThe Itô isometry gives $\\mathbb{E}[D_t^2] = \\mathbb{E}[(\\int_0^t (\\tilde{\\sigma}(s) - \\sigma) dW_s)^2] = \\int_0^t (\\tilde{\\sigma}(s) - \\sigma)^2 ds$.\nSince $\\tilde{\\sigma}(s) = \\sigma$ a.e., the integrand is zero a.e., and the integral is zero.\n$\\mathbb{E}[D_t^2]=0$ implies $D_t=0$ almost surely for each $t$. Since $D_t$ is a continuous martingale, this implies that the process $D_t$ is a.s. identically zero for all $t \\in [0,T]$.\nTherefore, the processes $X_t$ and $\\tilde{X}_t$ are indistinguishable, meaning they are equal for all $t$ almost surely. Indistinguishable processes have identical laws on path space. So, $\\mathbb{P}^X = \\mathbb{P}^{\\tilde{X}}$.\nIdentical laws are the opposite of mutually singular laws.\n\n**Verdict: Incorrect.**\n\n**E. There is no equivalent change of probability measure on $C([0,T];\\mathbb{R})$ that transforms a BM-driven Itô process with diffusion coefficient $\\sigma$ into one with a different diffusion coefficient $\\sigma'$ (with $\\sigma\\neq\\sigma'$), because an equivalent measure cannot alter quadratic variation.**\n\nThis statement generalizes the finding from statement B. Let $\\mathbb{P}_\\sigma$ be the law of a process with diffusion coefficient $\\sigma$, and $\\mathbb{P}_{\\sigma'}$ be the law for diffusion $\\sigma'$. We are asked if $\\mathbb{P}_\\sigma$ and $\\mathbb{P}_{\\sigma'}$ can be equivalent measures when $\\sigma \\neq \\sigma'$.\n\nTwo measures $\\mathbb{P}$ and $\\mathbb{Q}$ are equivalent if they have the same null sets, i.e., for any measurable set $A$, $\\mathbb{P}(A)=0 \\iff \\mathbb{Q}(A)=0$.\n\nAs shown in the analysis of B, the measure $\\mathbb{P}_\\sigma$ is concentrated on the set of paths $A_\\sigma = \\{\\omega \\mid \\langle \\omega \\rangle_t = \\sigma^2 t, \\forall t \\in [0,T]\\}$. This means $\\mathbb{P}_\\sigma(A_\\sigma) = 1$. Consequently, $\\mathbb{P}_\\sigma(A_\\sigma^c) = 0$.\nSimilarly, the measure $\\mathbb{P}_{\\sigma'}$ is concentrated on the set $A_{\\sigma'} = \\{\\omega \\mid \\langle \\omega \\rangle_t = (\\sigma')^2 t, \\forall t \\in [0,T]\\}$. This means $\\mathbb{P}_{\\sigma'}(A_{\\sigma'}) = 1$.\n\nIf $\\sigma \\neq \\sigma'$, the sets $A_\\sigma$ and $A_{\\sigma'}$ are disjoint. Therefore, $A_\\sigma \\subseteq A_{\\sigma'}^c$.\nWe know $\\mathbb{P}_{\\sigma'}(A_{\\sigma'}^c)=0$. Since $A_\\sigma$ is a subset of $A_{\\sigma'}^c$, we must have $\\mathbb{P}_{\\sigma'}(A_\\sigma) = 0$.\nHowever, we have $\\mathbb{P}_\\sigma(A_\\sigma)=1$.\nSince we have found a set $A_\\sigma$ for which $\\mathbb{P}_\\sigma(A_\\sigma) = 1$ and $\\mathbb{P}_{\\sigma'}(A_\\sigma) = 0$, the measures cannot be equivalent. By definition, they are mutually singular.\n\nThe reasoning provided, \"because an equivalent measure cannot alter quadratic variation,\" is a correct, if slightly informal, statement of the principle. The quadratic variation is a functional of the path itself. An equivalent change of measure re-weights probabilities of sets of paths but cannot move a path from having one quadratic variation to another. Since the measures $\\mathbb{P}_\\sigma$ and $\\mathbb{P}_{\\sigma'}$ are concentrated on disjoint sets defined by the quadratic variation property, they cannot be equivalent. This is a fundamental result, often related to the Feldman-Hájek theorem for Gaussian measures.\n\n**Verdict: Correct.**", "answer": "$$\\boxed{ABE}$$", "id": "2973146"}]}