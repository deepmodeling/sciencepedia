{"hands_on_practices": [{"introduction": "This first exercise grounds the abstract concepts of stopping times and martingales in a tangible and classic problem. You will rigorously prove that a first-passage time is a valid stopping time, confirming your understanding of the crucial measurability condition that underpins the theory of stochastic processes [@problem_id:2992982]. By then applying the Optional Stopping Theorem to a specific martingale, you'll see how these theoretical tools lead to powerful and elegant results in a practical calculation.", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\ge 0},\\mathbb{P})$ that satisfies the usual conditions and carries a standard Brownian motion $(W_t)_{t\\ge 0}$ adapted to $(\\mathcal{F}_t)_{t\\ge 0}$. Fix constants $a>0$, $T\\in(0,\\infty)$, and $\\theta\\in\\mathbb{R}$. Define the random time\n$$\n\\tau \\coloneqq \\inf\\{t\\ge 0:\\,|W_t|\\ge a\\}\\wedge T,\n$$\nand the process\n$$\nM_t \\coloneqq \\exp\\!\\big(\\theta W_t-\\tfrac{1}{2}\\theta^2 t\\big), \\quad t\\ge 0.\n$$\nStarting only from the definitions of stopping time and martingale, and standard properties of Brownian motion (such as independent, stationary increments and continuity of sample paths), do the following:\n\n1. Prove that $\\tau$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-stopping time and that it is bounded by $T$. In your justification, explicitly establish the measurability of the event $\\{\\tau\\le t\\}$ with respect to $\\mathcal{F}_t$.\n\n2. Prove that $(M_t)_{t\\ge 0}$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-martingale and that $M_t$ is integrable for each $t\\ge 0$. Carefully justify that $M_\\tau$ is a well-defined integrable random variable and is measurable with respect to $\\mathcal{F}$.\n\n3. Compute the value of $\\mathbb{E}[M_\\tau]$. Your final answer must be a single real number. No rounding is required.", "solution": "This problem is a valid exercise in stochastic calculus. We will address the three parts of the problem sequentially.\n\nPart 1: Prove that $\\tau$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-stopping time and that it is bounded by $T$.\n\nFirst, we prove that $\\tau$ is bounded. The random time $\\tau$ is defined as\n$$\n\\tau \\coloneqq \\inf\\{t\\ge 0:\\,|W_t|\\ge a\\}\\wedge T.\n$$\nThe notation $A \\wedge B$ denotes the minimum of $A$ and $B$. Thus, for any sample path $\\omega \\in \\Omega$, the value of $\\tau(\\omega)$ is given by $\\min(\\inf\\{t\\ge 0:\\,|W_t(\\omega)|\\ge a\\}, T)$. By the definition of the minimum, it is always true that $\\tau(\\omega) \\le T$. Since $T$ is a finite constant, the random variable $\\tau$ is bounded above by $T$.\n\nNext, we prove that $\\tau$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-stopping time. By definition, a random time $\\tau$ is a stopping time with respect to the filtration $(\\mathcal{F}_t)_{t\\ge 0}$ if the event $\\{\\tau \\le t\\}$ is in the $\\sigma$-algebra $\\mathcal{F}_t$ for every $t \\ge 0$.\nLet us analyze the event $\\{\\tau \\le t\\}$. We can write $\\tau = \\tau_a \\wedge T$, where $\\tau_a \\coloneqq \\inf\\{t\\ge 0:\\,|W_t|\\ge a\\}$. The event $\\{\\tau \\le t\\}$ can be expressed as\n$$\n\\{\\tau \\le t\\} = \\{\\tau_a \\wedge T \\le t\\} = \\{\\tau_a \\le t\\} \\cup \\{T \\le t\\}.\n$$\nWe consider two cases for $t$.\nCase 1: $t \\ge T$. In this case, the condition $T \\le t$ is always true, so the event $\\{T \\le t\\}$ is the entire sample space $\\Omega$. Since $\\Omega \\in \\mathcal{F}_t$ for any $t$, the union $\\{\\tau_a \\le t\\} \\cup \\Omega = \\Omega$ is also in $\\mathcal{F}_t$.\nCase 2: $0 \\le t < T$. In this case, the condition $T \\le t$ is never true, so the event $\\{T \\le t\\}$ is the empty set $\\emptyset$. The union becomes $\\{\\tau_a \\le t\\} \\cup \\emptyset = \\{\\tau_a \\le t\\}$. We must show that $\\{\\tau_a \\le t\\} \\in \\mathcal{F}_t$.\n\nThe event $\\{\\tau_a \\le t\\}$ is the set of all sample paths $\\omega$ for which there exists a time $s \\in [0, t]$ such that $|W_s(\\omega)| \\ge a$. This is equivalent to the event $\\{\\sup_{s \\in [0,t]} |W_s| \\ge a\\}$.\nA standard property of Brownian motion is that its sample paths $s \\mapsto W_s(\\omega)$ are continuous for almost all $\\omega$. For a continuous function on a closed interval $[0,t]$, its supremum is attained. The continuity of paths allows us to write the supremum over the uncountable set $[0,t]$ as a supremum over a countable dense subset, such as the rational numbers $\\mathbb{Q} \\cap [0,t]$.\n$$\n\\{\\sup_{s \\in [0,t]} |W_s| \\ge a\\} = \\{\\sup_{s \\in [0,t]\\cap\\mathbb{Q}} |W_s| \\ge a\\}.\n$$\nThe event on the right can be expressed using countable set operations. An equivalent formulation is\n$$\n\\{\\sup_{s \\in [0,t]} |W_s| \\ge a\\} = \\bigcap_{n=1}^\\infty \\bigcup_{s \\in [0,t]\\cap\\mathbb{Q}} \\left\\{ |W_s| > a - \\frac{1}{n} \\right\\}.\n$$\nFor any fixed time $s \\in [0,t]\\cap\\mathbb{Q}$, the random variable $W_s$ is adapted to the filtration, meaning $W_s$ is $\\mathcal{F}_s$-measurable. Since $s \\le t$, the filtration is non-decreasing ($\\mathcal{F}_s \\subseteq \\mathcal{F}_t$), so $W_s$ is also $\\mathcal{F}_t$-measurable. The function $x \\mapsto |x|$ is a continuous (and thus Borel) function, so $|W_s|$ is also $\\mathcal{F}_t$-measurable. Consequently, for any real number $c$, the set $\\{|W_s| > c\\}$ is an event in $\\mathcal{F}_t$.\nThe set $[0,t]\\cap\\mathbb{Q}$ is a countable set. A $\\sigma$-algebra is closed under countable unions. Therefore, for each integer $n \\ge 1$, the event $\\bigcup_{s \\in [0,t]\\cap\\mathbb{Q}} \\{|W_s| > a - 1/n\\}$ belongs to $\\mathcal{F}_t$.\nA $\\sigma$-algebra is also closed under countable intersections. Thus, the event $\\bigcap_{n=1}^\\infty \\bigcup_{s \\in [0,t]\\cap\\mathbb{Q}} \\{|W_s| > a - 1/n\\}$ is in $\\mathcal{F}_t$.\nThis shows that for $0 \\le t < T$, the event $\\{\\tau \\le t\\} = \\{\\tau_a \\le t\\}$ is in $\\mathcal{F}_t$.\n\nCombining both cases, we have established that for any $t \\ge 0$, the event $\\{\\tau \\le t\\} \\in \\mathcal{F}_t$. Therefore, $\\tau$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-stopping time.\n\nPart 2: Prove that $(M_t)_{t\\ge 0}$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-martingale and justify the properties of $M_\\tau$.\n\nA process $(M_t)_{t\\ge 0}$ is a martingale with respect to the filtration $(\\mathcal{F}_t)_{t\\ge 0}$ if it satisfies three conditions:\n1.  $M_t$ is $\\mathcal{F}_t$-measurable for all $t\\ge 0$.\nThe process is defined as $M_t = \\exp(\\theta W_t - \\frac{1}{2}\\theta^2 t)$. The Brownian motion $W_t$ is adapted to $(\\mathcal{F}_t)$, meaning $W_t$ is $\\mathcal{F}_t$-measurable. Any constant is also $\\mathcal{F}_t$-measurable. The functions of multiplication and addition are measurable, so the expression $\\theta W_t - \\frac{1}{2}\\theta^2 t$ is $\\mathcal{F}_t$-measurable. The exponential function $x \\mapsto \\exp(x)$ is continuous, hence Borel-measurable. The composition of a measurable function and a Borel-measurable function is measurable. Therefore, $M_t$ is $\\mathcal{F}_t$-measurable for all $t \\ge 0$.\n\n2.  $M_t$ is integrable for all $t\\ge 0$, i.e., $\\mathbb{E}[|M_t|] < \\infty$.\nSince the exponential function outputs only positive values, $|M_t| = M_t$. We compute its expectation:\n$$\n\\mathbb{E}[M_t] = \\mathbb{E}\\left[\\exp\\left(\\theta W_t - \\frac{1}{2}\\theta^2 t\\right)\\right] = \\exp\\left(-\\frac{1}{2}\\theta^2 t\\right) \\mathbb{E}\\left[\\exp(\\theta W_t)\\right].\n$$\nFor a standard Brownian motion, $W_t$ is a normally distributed random variable with mean $0$ and variance $t$, i.e., $W_t \\sim \\mathcal{N}(0, t)$. The moment-generating function of a normal random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is $\\mathbb{E}[\\exp(uX)] = \\exp(\\mu u + \\frac{1}{2}\\sigma^2 u^2)$. For $W_t$, we have $\\mu=0$ and $\\sigma^2=t$. With $u=\\theta$, we get:\n$$\n\\mathbb{E}[\\exp(\\theta W_t)] = \\exp\\left(0 \\cdot \\theta + \\frac{1}{2}t\\theta^2\\right) = \\exp\\left(\\frac{1}{2}\\theta^2 t\\right).\n$$\nSubstituting this back into the expectation of $M_t$:\n$$\n\\mathbb{E}[M_t] = \\exp\\left(-\\frac{1}{2}\\theta^2 t\\right) \\exp\\left(\\frac{1}{2}\\theta^2 t\\right) = 1.\n$$\nSince $\\mathbb{E}[|M_t|] = \\mathbb{E}[M_t] = 1$, which is finite, $M_t$ is integrable for all $t \\ge 0$.\n\n3.  $\\mathbb{E}[M_t | \\mathcal{F}_s] = M_s$ for all $0 \\le s < t$.\nWe compute the conditional expectation:\n$$\n\\mathbb{E}[M_t | \\mathcal{F}_s] = \\mathbb{E}\\left[\\exp\\left(\\theta W_t - \\frac{1}{2}\\theta^2 t\\right) \\bigg| \\mathcal{F}_s\\right].\n$$\nWe rewrite the argument of the exponential by adding and subtracting terms involving $W_s$ and $s$:\n$$\n\\theta W_t - \\frac{1}{2}\\theta^2 t = \\theta(W_t - W_s + W_s) - \\frac{1}{2}\\theta^2(t - s + s) = \\left(\\theta(W_t - W_s) - \\frac{1}{2}\\theta^2(t-s)\\right) + \\left(\\theta W_s - \\frac{1}{2}\\theta^2 s\\right).\n$$\nSo, $M_t = \\exp(\\theta(W_t - W_s) - \\frac{1}{2}\\theta^2(t-s)) \\cdot M_s$.\nThe term $M_s = \\exp(\\theta W_s - \\frac{1}{2}\\theta^2 s)$ is $\\mathcal{F}_s$-measurable, so it can be taken out of the conditional expectation:\n$$\n\\mathbb{E}[M_t | \\mathcal{F}_s] = M_s \\cdot \\mathbb{E}\\left[\\exp\\left(\\theta(W_t - W_s) - \\frac{1}{2}\\theta^2(t-s)\\right) \\bigg| \\mathcal{F}_s\\right].\n$$\nThe increment $W_t - W_s$ is independent of the $\\sigma$-algebra $\\mathcal{F}_s$ by the definition of Brownian motion. Therefore, the random variable $\\exp(\\theta(W_t-W_s) - \\frac{1}{2}\\theta^2(t-s))$ is also independent of $\\mathcal{F}_s$, and its conditional expectation is just its unconditional expectation:\n$$\n\\mathbb{E}[M_t | \\mathcal{F}_s] = M_s \\cdot \\mathbb{E}\\left[\\exp\\left(\\theta(W_t - W_s) - \\frac{1}{2}\\theta^2(t-s)\\right)\\right].\n$$\nThe increment $W_t - W_s$ is normally distributed as $\\mathcal{N}(0, t-s)$. Using the same logic as in point 2, with variance $t-s$, we find:\n$$\n\\mathbb{E}[\\exp(\\theta(W_t - W_s))] = \\exp\\left(\\frac{1}{2}(t-s)\\theta^2\\right).\n$$\nThe expectation term becomes:\n$$\n\\exp\\left(-\\frac{1}{2}\\theta^2(t-s)\\right) \\cdot \\mathbb{E}[\\exp(\\theta(W_t - W_s))] = \\exp\\left(-\\frac{1}{2}\\theta^2(t-s)\\right) \\exp\\left(\\frac{1}{2}\\theta^2(t-s)\\right) = 1.\n$$\nThus, we have shown $\\mathbb{E}[M_t | \\mathcal{F}_s] = M_s \\cdot 1 = M_s$. All three conditions are satisfied, so $(M_t)_{t\\ge 0}$ is an $(\\mathcal{F}_t)_{t\\ge 0}$-martingale.\n\nNow we justify the properties of $M_\\tau$.\n-   $M_\\tau$ is well-defined: The sample paths of Brownian motion $t \\mapsto W_t(\\omega)$ are continuous. Since $\\theta, \\theta^2$ are constants, the function $t \\mapsto \\theta W_t(\\omega) - \\frac{1}{2}\\theta^2 t$ is also continuous. The exponential function is continuous, so the process paths $t \\mapsto M_t(\\omega)$ are continuous. Since $\\tau$ is a random variable taking values in $[0, T]$, the composition $M_\\tau(\\omega) \\coloneqq M_{\\tau(\\omega)}(\\omega)$ is well-defined.\n-   $M_\\tau$ is measurable with respect to $\\mathcal{F}$: A general theorem states that if $X_t$ is an adapted process with right-continuous paths and $\\tau$ is a stopping time, then $X_\\tau$ is $\\mathcal{F}_\\tau$-measurable. Our process $M_t$ has continuous paths, so it is right-continuous. The filtration is assumed to satisfy the usual conditions, which includes right-continuity. Thus, $M_\\tau$ is $\\mathcal{F}_\\tau$-measurable. The full $\\sigma$-algebra $\\mathcal{F}$ contains all $\\mathcal{F}_t$, and since $\\tau$ is a bounded stopping time, it can be shown that $\\mathcal{F}_\\tau \\subseteq \\mathcal{F}_T \\subseteq \\mathcal{F}$. Thus $M_\\tau$ is $\\mathcal{F}$-measurable.\n-   $M_\\tau$ is integrable: We need to show $\\mathbb{E}[|M_\\tau|] < \\infty$. As $M_\\tau > 0$, this is $\\mathbb{E}[M_\\tau] < \\infty$. By definition of $\\tau$, for any $t < \\tau$, we have $|W_t| < a$. By continuity of paths, at time $\\tau$, we must have $|W_\\tau| \\le a$. Also, $\\tau \\ge 0$, which implies $-\\frac{1}{2}\\theta^2 \\tau \\le 0$. We can bound $M_\\tau$:\n$$\nM_\\tau = \\exp\\left(\\theta W_\\tau - \\frac{1}{2}\\theta^2 \\tau\\right) \\le \\exp(\\theta W_\\tau).\n$$\nFurthermore, $\\theta W_\\tau \\le |\\theta| |W_\\tau| \\le |\\theta| a$. So,\n$$\nM_\\tau \\le \\exp(|\\theta| a).\n$$\nSince $M_\\tau$ is a positive random variable that is bounded above by the finite constant $\\exp(|\\theta| a)$, its expectation is finite: $\\mathbb{E}[M_\\tau] \\le \\exp(|\\theta| a) < \\infty$. Thus, $M_\\tau$ is an integrable random variable.\n\nPart 3: Compute the value of $\\mathbb{E}[M_\\tau]$.\n\nWe will use the Optional Stopping Theorem. There are several versions of this theorem. The simplest version states that if $(M_t)_{t\\ge 0}$ is a martingale and $\\tau$ is a bounded stopping time, then $\\mathbb{E}[M_\\tau] = \\mathbb{E}[M_0]$.\nFrom Part 1, we established that $\\tau \\le T$, and since $T$ is a finite constant, $\\tau$ is a bounded stopping time.\nFrom Part 2, we proved that $(M_t)_{t\\ge 0}$ is a martingale.\nThe conditions for the simplest version of the Optional Stopping Theorem are met. Therefore, we can conclude that\n$$\n\\mathbb{E}[M_\\tau] = \\mathbb{E}[M_0].\n$$\nWe compute $\\mathbb{E}[M_0]$. A standard Brownian motion starts at $0$, so $W_0=0$ almost surely.\n$$\nM_0 = \\exp\\left(\\theta W_0 - \\frac{1}{2}\\theta^2 \\cdot 0\\right) = \\exp(\\theta \\cdot 0 - 0) = \\exp(0) = 1.\n$$\nThe random variable $M_0$ is the constant $1$. Its expectation is\n$$\n\\mathbb{E}[M_0] = \\mathbb{E}[1] = 1.\n$$\nTherefore, by the Optional Stopping Theorem,\n$$\n\\mathbb{E}[M_\\tau] = 1.\n$$\nThis result is independent of the values of $a$, $T$, and $\\theta$.", "answer": "$$\n\\boxed{1}\n$$", "id": "2992982"}, {"introduction": "Building on the properties of individual martingales, this practice delves into their interaction by constructing the covariation process from first principles. This concept is fundamental to multivariate stochastic calculus and ItÃ´'s formula, quantifying how two processes vary together [@problem_id:2992980]. This exercise will strengthen your skills in using polarization identities and uniqueness arguments, which are common techniques in stochastic analysis, while also introducing the important notion of predictability.", "problem": "Let $\\left(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\ge 0},\\mathbb{P}\\right)$ be a filtered probability space satisfying the usual conditions, and let $X$ and $Y$ be real-valued, continuous local martingales adapted to $(\\mathcal{F}_{t})_{t\\ge 0}$ with $X_{0}=Y_{0}=0$. Recall the following foundational fact: for every continuous local martingale $M$, there exists a unique continuous, adapted, increasing process $[M]$ with $[M]_{0}=0$ such that $M^{2}-[M]$ is a local martingale. The predictable $\\sigma$-algebra $\\mathcal{P}$ on $\\Omega\\times\\mathbb{R}_{+}$ is the smallest $\\sigma$-algebra making all left-continuous adapted processes measurable.\n\nYour tasks are as follows.\n\n1) Using only the foundational fact stated above, construct a process $[X,Y]$ that can be interpreted as the covariation between $X$ and $Y$. Justify that your construction does not depend on arbitrary choices.\n\n2) Prove that $[X,Y]$ is symmetric in $(X,Y)$ and bilinear in each argument over $\\mathbb{R}$ when restricted to the class of continuous local martingales. In particular, show that for any real constants $a,b$ and continuous local martingales $X_{1},X_{2},Y$, one has $[aX_{1}+bX_{2},Y]=a[X_{1},Y]+b[X_{2},Y]$ and $[X,Y]=[Y,X]$.\n\n3) Prove that $[X,Y]$ is a predictable process, that is, its trajectory viewed as a function on $\\Omega\\times\\mathbb{R}_{+}$ is measurable with respect to the predictable $\\sigma$-algebra $\\mathcal{P}$.\n\n4) Let $(B^{1}_{t})_{t\\ge 0}$ and $(B^{2}_{t})_{t\\ge 0}$ be two independent standard Brownian motions on the same filtered probability space (with their natural completed filtration) and set $X=B^{1}$, $Y=B^{2}$. Compute the covariation $[X,Y]_{t}$ for a fixed but arbitrary $t>0$. Express your final answer as a single closed-form analytic expression. No rounding is required, and no units are involved. The final answer must be a single number or a single symbolic expression, without inequalities or equations.", "solution": "The problem is dissected into four distinct tasks concerning the covariation of continuous local martingales. We shall address each task systematically.\n\nLet $\\left(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\ge 0},\\mathbb{P}\\right)$ be a filtered probability space satisfying the usual conditions. Let $X$ and $Y$ be two real-valued, continuous local martingales with $X_0 = Y_0 = 0$. The foundational fact states that for any such process $M$, there is a unique continuous, adapted, increasing process $[M]$ with $[M]_0=0$ such that $M^2 - [M]$ is a continuous local martingale.\n\n**1) Construction of the Covariation Process $[X, Y]$**\n\nThe construction of the covariation process $[X, Y]$ can be achieved using the polarization identity, which expresses a product in terms of squares. For any two real numbers $x, y \\in \\mathbb{R}$, we have $xy = \\frac{1}{4}\\left((x+y)^2 - (x-y)^2\\right)$. We apply this identity to the processes $X$ and $Y$.\n\nSince $X$ and $Y$ are continuous local martingales, their sum $X+Y$ and difference $X-Y$ are also continuous local martingales. Applying the foundational fact to $X+Y$ and $X-Y$, there exist unique continuous, adapted, increasing processes $[X+Y]$ and $[X-Y]$ starting at $0$ such that $(X+Y)^2 - [X+Y]$ and $(X-Y)^2 - [X-Y]$ are local martingales.\n\nLet us consider the product process $XY$. Using the polarization identity, we can write:\n$$\nX_t Y_t = \\frac{1}{4} \\left( (X_t+Y_t)^2 - (X_t-Y_t)^2 \\right)\n$$\nWe can rewrite this expression by adding and subtracting the corresponding quadratic variation terms:\n$$\nX_t Y_t = \\frac{1}{4} \\left( \\left((X_t+Y_t)^2 - [X+Y]_t\\right) - \\left((X_t-Y_t)^2 - [X-Y]_t\\right) + \\left([X+Y]_t - [X-Y]_t\\right) \\right)\n$$\nLet $L_{1,t} = (X_t+Y_t)^2 - [X+Y]_t$ and $L_{2,t} = (X_t-Y_t)^2 - [X-Y]_t$. By construction, $L_1$ and $L_2$ are local martingales. The expression for $X_t Y_t$ becomes:\n$$\nX_t Y_t = \\frac{1}{4} \\left( L_{1,t} - L_{2,t} \\right) + \\frac{1}{4} \\left( [X+Y]_t - [X-Y]_t \\right)\n$$\nThis is the Doob-Meyer decomposition of the semimartingale $XY$. The term $\\frac{1}{4}(L_1 - L_2)$ is a local martingale, being a linear combination of local martingales. The term $\\frac{1}{4}([X+Y] - [X-Y])$ is a continuous, adapted process starting at $0$. Since $[X+Y]$ and $[X-Y]$ are increasing, their difference is a process of finite variation.\n\nThis motivates the definition of the covariation process $[X,Y]$ as the finite-variation part of this decomposition:\n$$\n[X,Y]_t := \\frac{1}{4} \\left( [X+Y]_t - [X-Y]_t \\right)\n$$\nBy this construction, the process $X_t Y_t - [X,Y]_t$ is a local martingale.\n\nThis construction does not depend on arbitrary choices. The processes $[X+Y]$ and $[X-Y]$ are uniquely determined by the foundational fact. Since $[X,Y]$ is defined explicitly in terms of these unique processes, $[X,Y]$ is itself unique. It is the unique continuous, adapted process of finite variation starting at $0$ such that $XY - [X,Y]$ is a local martingale.\n\n**2) Symmetry and Bilinearity of the Covariation**\n\nWe now prove the requested properties based on our construction.\n\n**Symmetry:** We must show that $[X,Y] = [Y,X]$.\nBy definition,\n$$\n[Y,X]_t = \\frac{1}{4} \\left( [Y+X]_t - [Y-X]_t \\right)\n$$\nSince addition is commutative, $X+Y = Y+X$, and thus by uniqueness, $[X+Y] = [Y+X]$.\nFor the second term, consider the process $M = X-Y$. Then $Y-X = -M$. We need to show that $[M] = [-M]$. The process $(-M)^2 - [-M]$ is a local martingale by definition. But $(-M)^2=M^2$, so $M^2 - [-M]$ is a local martingale. We also know that $M^2 - [M]$ is a local martingale. The difference, $(M^2 - [M]) - (M^2 - [-M]) = [-M] - [M]$, must also be a local martingale. This difference is a continuous process of finite variation starting at $0$. The only such process is the zero process. Hence, $[-M] = [M]$. Applying this with $M=X-Y$, we get $[Y-X]=[-(X-Y)]=[X-Y]$.\nSubstituting these back into the expression for $[Y,X]_t$:\n$$\n[Y,X]_t = \\frac{1}{4} \\left( [X+Y]_t - [X-Y]_t \\right) = [X,Y]_t\n$$\nThus, the covariation is symmetric.\n\n**Bilinearity:** We need to show that for any real constants $a,b$ and continuous local martingales $X_1, X_2, Y$, we have $[aX_1+bX_2, Y] = a[X_1, Y] + b[X_2, Y]$.\nWe will use the characterization that for any continuous local martingales $U$ and $V$, $[U,V]$ is the unique continuous adapted process of finite variation such that $UV - [U,V]$ is a local martingale.\nLet $Z = aX_1 + bX_2$. We want to find $[Z,Y]$. We know that:\n$X_1 Y - [X_1,Y]$ is a local martingale.\n$X_2 Y - [X_2,Y]$ is a local martingale.\nSince the set of local martingales is a vector space, any linear combination of local martingales is a local martingale. Therefore, for constants $a$ and $b$:\n$$\na(X_1 Y - [X_1,Y]) + b(X_2 Y - [X_2,Y]) \\quad \\text{is a local martingale.}\n$$\nRearranging the terms, we find that\n$$\n(aX_1 Y + bX_2 Y) - (a[X_1,Y] + b[X_2,Y]) \\quad \\text{is a local martingale.}\n$$\nThis can be written as:\n$$\n(aX_1+bX_2)Y - (a[X_1,Y] + b[X_2,Y]) \\quad \\text{is a local martingale.}\n$$\nLet's define a process $C_t = a[X_1,Y]_t + b[X_2,Y]_t$. The process $C$ is a linear combination of continuous adapted processes of finite variation, so it is also a continuous adapted process of finite variation. The above shows that $(aX_1+bX_2)Y - C$ is a local martingale.\nBy the uniqueness of the covariation process, $C$ must be the covariation of $aX_1+bX_2$ and $Y$. That is:\n$$\n[aX_1+bX_2, Y] = C = a[X_1, Y] + b[X_2, Y]\n$$\nThis establishes linearity in the first argument. The linearity in the second argument follows from symmetry: $[X, aY_1+bY_2] = [aY_1+bY_2, X] = a[Y_1,X]+b[Y_2,X] = a[X,Y_1]+b[X,Y_2]$. Thus, the covariation is bilinear.\n\n**3) Predictability of the Covariation**\n\nA process is predictable if it is measurable with respect to the predictable $\\sigma$-algebra $\\mathcal{P}$, which is defined as the smallest $\\sigma$-algebra making all left-continuous adapted processes measurable.\n\nFrom our construction, $[X,Y]_t = \\frac{1}{4}([X+Y]_t - [X-Y]_t)$. To show $[X,Y]$ is predictable, it suffices to show that for any continuous local martingale $M$, its quadratic variation $[M]$ is a predictable process.\n\nAccording to the foundational fact, for a continuous local martingale $M$, the process $[M]$ is continuous and adapted. A process whose sample paths are continuous is necessarily left-continuous. Thus, $[M]$ is a left-continuous adapted process.\n\nBy the given definition of the predictable $\\sigma$-algebra $\\mathcal{P}$, all left-continuous adapted processes are, by definition, measurable with respect to $\\mathcal{P}$. Therefore, the process $[M]$ is predictable.\n\nSince $X+Y$ and $X-Y$ are continuous local martingales, their quadratic variations $[X+Y]$ and $[X-Y]$ are predictable processes. The set of predictable processes is a vector space, closed under linear combinations. Consequently, the process\n$$\n[X,Y] = \\frac{1}{4}[X+Y] - \\frac{1}{4}[X-Y]\n$$\nbeing a linear combination of predictable processes, is also predictable.\n\n**4) Covariation of Independent Brownian Motions**\n\nWe are given $X_t = B^1_t$ and $Y_t = B^2_t$, where $(B^1_t)_{t\\ge 0}$ and $(B^2_t)_{t\\ge 0}$ are two independent standard Brownian motions. We need to compute $[X,Y]_t = [B^1, B^2]_t$.\n\nWe will determine if the process $M_t = B^1_t B^2_t$ is a martingale. If it is, then its finite-variation part in the Doob-Meyer decomposition must be zero.\nLet $s<t$. We compute the conditional expectation $\\mathbb{E}[B^1_t B^2_t | \\mathcal{F}_s]$, where $\\mathcal{F}_s = \\sigma(B^1_u, B^2_u, u \\le s)$.\nWe write $B^1_t = B^1_s + (B^1_t-B^1_s)$ and $B^2_t = B^2_s + (B^2_t-B^2_s)$.\n\\begin{align*}\n\\mathbb{E}[B^1_t B^2_t | \\mathcal{F}_s] &= \\mathbb{E}[(B^1_s + (B^1_t-B^1_s))(B^2_s + (B^2_t-B^2_s)) | \\mathcal{F}_s] \\\\\n&= \\mathbb{E}[B^1_s B^2_s | \\mathcal{F}_s] + \\mathbb{E}[B^1_s(B^2_t-B^2_s) | \\mathcal{F}_s] + \\mathbb{E}[(B^1_t-B^1_s)B^2_s | \\mathcal{F}_s] + \\mathbb{E}[(B^1_t-B^1_s)(B^2_t-B^2_s) | \\mathcal{F}_s]\n\\end{align*}\nSince $B^1_s$ and $B^2_s$ are $\\mathcal{F}_s$-measurable, they can be treated as constants in the conditional expectation. The increments $(B^1_t-B^1_s)$ and $(B^2_t-B^2_s)$ are independent of $\\mathcal{F}_s$.\n\\begin{align*}\n\\mathbb{E}[B^1_t B^2_t | \\mathcal{F}_s] &= B^1_s B^2_s + B^1_s \\mathbb{E}[B^2_t-B^2_s | \\mathcal{F}_s] + B^2_s \\mathbb{E}[B^1_t-B^1_s | \\mathcal{F}_s] + \\mathbb{E}[(B^1_t-B^1_s)(B^2_t-B^2_s) | \\mathcal{F}_s] \\\\\n&= B^1_s B^2_s + B^1_s \\mathbb{E}[B^2_t-B^2_s] + B^2_s \\mathbb{E}[B^1_t-B^1_s] + \\mathbb{E}[(B^1_t-B^1_s)(B^2_t-B^2_s)]\n\\end{align*}\nThe increments have zero mean: $\\mathbb{E}[B^1_t-B^1_s]=0$ and $\\mathbb{E}[B^2_t-B^2_s]=0$. Since the processes $B^1$ and $B^2$ are independent, the increments over the same interval $(s,t]$ are also independent. Therefore,\n$$\n\\mathbb{E}[(B^1_t-B^1_s)(B^2_t-B^2_s)] = \\mathbb{E}[B^1_t-B^1_s] \\mathbb{E}[B^2_t-B^2_s] = 0 \\cdot 0 = 0.\n$$\nSubstituting these results back, we obtain:\n$$\n\\mathbb{E}[B^1_t B^2_t | \\mathcal{F}_s] = B^1_s B^2_s + B^1_s \\cdot 0 + B^2_s \\cdot 0 + 0 = B^1_s B^2_s.\n$$\nThis shows that the process $M_t = B^1_t B^2_t$ is a martingale, and thus a local martingale.\nWe have the decomposition $M_t = M_t + 0$.\nWe also have the defining decomposition $M_t = (M_t - [B^1, B^2]_t) + [B^1, B^2]_t$, where $M_t - [B^1, B^2]_t$ is a local martingale and $[B^1, B^2]_t$ is a continuous adapted process of finite variation starting at $0$.\nBy the uniqueness of this decomposition, we must have $[B^1, B^2]_t = 0$ for all $t \\ge 0$.\nTherefore, for any fixed $t > 0$, the value is $0$.", "answer": "$$\\boxed{0}$$", "id": "2992980"}]}