{"hands_on_practices": [{"introduction": "Understanding how different sources of randomness contribute to the total uncertainty in a system is a fundamental skill in stochastic modeling. A powerful tool for this is the law of total variance, which allows us to decompose the variance of a random variable into components related to underlying and conditional uncertainties. This exercise provides a concrete, two-stage experiment to practice applying this law, helping to build intuition for analyzing hierarchical models. [@problem_id:1292256]", "problem": "Consider a two-stage random experiment. In the first stage, a random variable $X$ is generated from a continuous uniform distribution over the interval $[-1, 1]$. In the second stage, conditioned on the outcome $X=x$, a second random variable $Y$ is generated from a normal distribution with a mean of $x$ and a variance of $x^2 + 1$.\n\nDetermine the total variance of the random variable $Y$, denoted as $\\text{Var}(Y)$.\n\nExpress your answer as a single closed-form analytic expression, which may be a fraction.", "solution": "Let $X \\sim \\text{Uniform}([-1,1])$, so its density is $f_{X}(x) = \\frac{1}{2}$ for $x \\in [-1,1]$. Compute its first two moments:\n$$\n\\mathbb{E}[X] = \\int_{-1}^{1} x \\cdot \\frac{1}{2} \\, dx = 0,\n$$\n$$\n\\mathbb{E}[X^{2}] = \\int_{-1}^{1} x^{2} \\cdot \\frac{1}{2} \\, dx = \\frac{1}{2} \\left[ \\frac{x^{3}}{3} \\right]_{-1}^{1} = \\frac{1}{2} \\cdot \\frac{2}{3} = \\frac{1}{3}.\n$$\nHence,\n$$\n\\mathrm{Var}(X) = \\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2} = \\frac{1}{3}.\n$$\nConditioned on $X=x$, we have $Y|X=x \\sim \\mathcal{N}(x, x^{2}+1)$, so\n$$\n\\mathbb{E}[Y \\mid X] = X, \\qquad \\mathrm{Var}(Y \\mid X) = X^{2} + 1.\n$$\nBy the law of total variance,\n$$\n\\mathrm{Var}(Y) = \\mathbb{E}[\\mathrm{Var}(Y \\mid X)] + \\mathrm{Var}(\\mathbb{E}[Y \\mid X]).\n$$\nCompute each term:\n$$\n\\mathbb{E}[\\mathrm{Var}(Y \\mid X)] = \\mathbb{E}[X^{2} + 1] = \\mathbb{E}[X^{2}] + 1 = \\frac{1}{3} + 1 = \\frac{4}{3},\n$$\n$$\n\\mathrm{Var}(\\mathbb{E}[Y \\mid X]) = \\mathrm{Var}(X) = \\frac{1}{3}.\n$$\nTherefore,\n$$\n\\mathrm{Var}(Y) = \\frac{4}{3} + \\frac{1}{3} = \\frac{5}{3}.\n$$", "answer": "$$\\boxed{\\frac{5}{3}}$$", "id": "1292256"}, {"introduction": "In many scientific and engineering fields, a key task is to estimate a hidden or unknown signal from noisy measurements. A crucial aspect of this process is to quantify the remaining uncertainty after an observation is made. This problem, set in the context of a binary communication system, demonstrates how conditional variance serves as a precise measure of this residual uncertainty, forming a conceptual bridge to the core ideas of Bayesian estimation and filtering theory. [@problem_id:1351903]", "problem": "In a binary communication system, a transmitter sends a signal level $\\mu$ which is chosen randomly from the set $\\{-1, 1\\}$. The two levels are equiprobable, meaning $P(\\mu = 1) = P(\\mu = -1) = 1/2$. The signal is corrupted by additive noise, modeled as a random variable $N$ that follows a standard Normal distribution with mean 0 and variance 1. The receiver measures the final signal $X = \\mu + N$. An engineer observes a specific value $X=x$ at the receiver. Based on this observation, the engineer wants to quantify their remaining uncertainty about which signal level $\\mu$ was originally sent.\n\nAs a measure of this uncertainty, calculate the variance of the original signal $\\mu$, conditioned on the observation that $X = x$. That is, find an expression for $\\text{Var}(\\mu | X = x)$.\n\nYour answer should be a closed-form analytical expression in terms of $x$.", "solution": "We are given a binary input $\\mu \\in \\{-1,1\\}$ with $P(\\mu=1)=P(\\mu=-1)=\\frac{1}{2}$, additive noise $N \\sim \\mathcal{N}(0,1)$ independent of $\\mu$, and observation $X=\\mu+N$. For a realized value $X=x$, we want $\\text{Var}(\\mu \\mid X=x)$.\n\nBy Bayes' rule,\n$$\nP(\\mu=1 \\mid X=x)=\\frac{f_{X \\mid \\mu}(x \\mid 1) P(\\mu=1)}{f_{X \\mid \\mu}(x \\mid 1) P(\\mu=1)+f_{X \\mid \\mu}(x \\mid -1) P(\\mu=-1)}.\n$$\nSince $X \\mid \\mu=m$ is Gaussian with mean $m$ and variance $1$, its density is\n$$\nf_{X \\mid \\mu}(x \\mid m)=\\frac{1}{\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{(x-m)^{2}}{2}\\right).\n$$\nUsing $P(\\mu=1)=P(\\mu=-1)=\\frac{1}{2}$ and canceling common factors, we obtain\n$$\nP(\\mu=1 \\mid X=x)=\\frac{\\exp\\!\\left(-\\frac{(x-1)^{2}}{2}\\right)}{\\exp\\!\\left(-\\frac{(x-1)^{2}}{2}\\right)+\\exp\\!\\left(-\\frac{(x+1)^{2}}{2}\\right)}.\n$$\nSimplify the exponents:\n$$\n-\\frac{(x-1)^{2}}{2}=-\\frac{x^{2}}{2}+x-\\frac{1}{2}, \n\\quad\n-\\frac{(x+1)^{2}}{2}=-\\frac{x^{2}}{2}-x-\\frac{1}{2}.\n$$\nMultiplying numerator and denominator by $\\exp\\!\\left(\\frac{x^{2}}{2}+\\frac{1}{2}\\right)$ gives\n$$\nP(\\mu=1 \\mid X=x)=\\frac{\\exp(x)}{\\exp(x)+\\exp(-x)}=\\frac{1}{1+\\exp(-2x)}.\n$$\nTherefore,\n$$\nP(\\mu=-1 \\mid X=x)=1-P(\\mu=1 \\mid X=x)=\\frac{1}{1+\\exp(2x)}.\n$$\nThe conditional mean is\n$$\n\\mathbb{E}[\\mu \\mid X=x]=(+1)P(\\mu=1 \\mid X=x)+(-1)P(\\mu=-1 \\mid X=x)\n=2P(\\mu=1 \\mid X=x)-1=\\tanh(x),\n$$\nsince\n$$\n2\\left(\\frac{1}{1+\\exp(-2x)}\\right)-1=\\frac{1-\\exp(-2x)}{1+\\exp(-2x)}=\\tanh(x).\n$$\nNext, use $\\text{Var}(\\mu \\mid X=x)=\\mathbb{E}[\\mu^{2} \\mid X=x]-\\big(\\mathbb{E}[\\mu \\mid X=x]\\big)^{2}$. Because $\\mu \\in \\{-1,1\\}$, we have $\\mu^{2}=1$ deterministically, hence $\\mathbb{E}[\\mu^{2} \\mid X=x]=1$. Therefore,\n$$\n\\text{Var}(\\mu \\mid X=x)=1-\\tanh^{2}(x)=\\frac{1}{\\cosh^{2}(x)}.\n$$\nEither form is an equivalent closed-form expression in terms of $x$.", "answer": "$$\\boxed{1-\\tanh^{2}(x)}$$", "id": "1351903"}, {"introduction": "Moving beyond simple random variables, we now tackle the behavior of a stochastic process over time. This advanced problem explores the properties of a standard Brownian motion, a cornerstone model for continuous-time random phenomena. By calculating the variance of the process at a future time $t$, conditioned on the event that it has already reached a certain level $a$, you will engage with deeper concepts such as the reflection principle and the analysis of path-dependent properties of stochastic processes. [@problem_id:1292240]", "problem": "Let $\\{B_t\\}_{t \\ge 0}$ be a standard one-dimensional Brownian motion starting from the origin, i.e., $B_0=0$. For a fixed positive level $a > 0$, the first passage time to this level is defined as the random variable $\\tau_a = \\inf\\{s > 0 : B_s = a\\}$.\n\nConsider a fixed time horizon $t > 0$. Your task is to determine the variance of the Brownian motion's position at time $t$, conditioned on the event that the process has reached the level $a$ at some point before or at time $t$.\n\nFind an analytical expression for $\\text{Var}(B_t | \\tau_a \\le t)$ in terms of $a$ and $t$. Your final expression may involve the standard normal cumulative distribution function (CDF), denoted by $\\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du$, and its corresponding probability density function (PDF), $\\phi(z) = \\frac{d\\Phi(z)}{dz}$.", "solution": "Let $M_{t}=\\sup_{0\\le s\\le t}B_{s}$. Since Brownian paths are continuous, the events $\\{\\tau_{a}\\le t\\}$ and $\\{M_{t}\\ge a\\}$ differ at most by a null set, so conditioning on $\\{\\tau_{a}\\le t\\}$ is equivalent to conditioning on $\\{M_{t}\\ge a\\}$.\n\nBy the reflection principle, for any bounded measurable function $g$,\n$$\n\\mathbb{E}\\!\\left[g(B_{t})\\,\\mathbf{1}_{\\{M_{t}\\ge a\\}}\\right]\n=\\mathbb{E}\\!\\left[\\big(g(B_{t})+g(2a-B_{t})\\big)\\,\\mathbf{1}_{\\{B_{t}\\ge a\\}}\\right].\n$$\nIn particular, the crossing probability is\n$$\n\\mathbb{P}(M_{t}\\ge a)=2\\,\\mathbb{P}(B_{t}\\ge a)=2\\big(1-\\Phi(a/\\sqrt{t})\\big).\n$$\n\nFirst conditional moment. With $g(x)=x$,\n$$\n\\mathbb{E}\\!\\left[B_{t}\\,\\mathbf{1}_{\\{M_{t}\\ge a\\}}\\right]\n=\\mathbb{E}\\!\\left[(B_{t}+2a-B_{t})\\,\\mathbf{1}_{\\{B_{t}\\ge a\\}}\\right]\n=2a\\,\\mathbb{P}(B_{t}\\ge a).\n$$\nTherefore,\n$$\n\\mathbb{E}\\!\\left[B_{t}\\mid M_{t}\\ge a\\right]\n=\\frac{2a\\,\\mathbb{P}(B_{t}\\ge a)}{2\\,\\mathbb{P}(B_{t}\\ge a)}=a.\n$$\n\nSecond conditional moment. With $g(x)=x^{2}$,\n$$\n\\mathbb{E}\\!\\left[B_{t}^{2}\\,\\mathbf{1}_{\\{M_{t}\\ge a\\}}\\right]\n=\\mathbb{E}\\!\\left[\\big(B_{t}^{2}+(2a-B_{t})^{2}\\big)\\,\\mathbf{1}_{\\{B_{t}\\ge a\\}}\\right]\n=\\mathbb{E}\\!\\left[(2B_{t}^{2}-4aB_{t}+4a^{2})\\,\\mathbf{1}_{\\{B_{t}\\ge a\\}}\\right].\n$$\nLet $X=B_{t}\\sim N(0,t)$ and set $z=a/\\sqrt{t}$. Using standard truncated normal identities,\n$$\n\\mathbb{P}(X\\ge a)=1-\\Phi(z),\\quad\n\\mathbb{E}[X\\,\\mathbf{1}_{\\{X\\ge a\\}}]=\\sqrt{t}\\,\\phi(z),\\quad\n\\mathbb{E}[X^{2}\\,\\mathbf{1}_{\\{X\\ge a\\}}]=t\\big(1-\\Phi(z)\\big)+t z\\,\\phi(z).\n$$\nHence,\n$$\n\\mathbb{E}\\!\\left[B_{t}^{2}\\,\\mathbf{1}_{\\{M_{t}\\ge a\\}}\\right]\n=2\\Big(t(1-\\Phi(z))+t z \\phi(z)\\Big)-4a\\big(\\sqrt{t}\\,\\phi(z)\\big)+4a^{2}\\big(1-\\Phi(z)\\big).\n$$\nUsing $a=\\sqrt{t}\\,z$, this becomes\n$$\n\\mathbb{E}\\!\\left[B_{t}^{2}\\,\\mathbf{1}_{\\{M_{t}\\ge a\\}}\\right]\n=2t\\big(1-\\Phi(z)\\big)-2t z \\phi(z)+4t z^{2}\\big(1-\\Phi(z)\\big).\n$$\nTherefore,\n$$\n\\mathbb{E}\\!\\left[B_{t}^{2}\\mid M_{t}\\ge a\\right]\n=\\frac{2t\\big(1-\\Phi(z)\\big)-2t z \\phi(z)+4t z^{2}\\big(1-\\Phi(z)\\big)}{2\\big(1-\\Phi(z)\\big)}\n=t\\big(1+2z^{2}\\big)-\\frac{t z \\phi(z)}{1-\\Phi(z)}.\n$$\n\nVariance. Using $\\mathbb{E}[B_{t}\\mid M_{t}\\ge a]=a=\\sqrt{t}\\,z$,\n$$\n\\operatorname{Var}(B_{t}\\mid M_{t}\\ge a)\n=\\mathbb{E}[B_{t}^{2}\\mid M_{t}\\ge a]-a^{2}\n=t\\big(1+2z^2\\big) - \\frac{t z \\phi(z)}{1-\\Phi(z)} - t z^2\n=t\\big(1+z^{2}\\big)-\\frac{t z \\phi(z)}{1-\\Phi(z)}.\n$$\nRewriting in terms of $a$ and $t$ with $z=a/\\sqrt{t}$ yields\n$$\n\\operatorname{Var}(B_{t}\\mid \\tau_{a}\\le t)\n= t + a^{2} - a\\sqrt{t}\\,\\frac{\\phi\\!\\left(\\frac{a}{\\sqrt{t}}\\right)}{1-\\Phi\\!\\left(\\frac{a}{\\sqrt{t}}\\right)}.\n$$\nThis expression is equivalent to $t(1+z^{2})-t z\\,\\phi(z)/(1-\\Phi(z))$ with $z=a/\\sqrt{t}$ and satisfies the expected limits as $a/\\sqrt{t}\\to 0^{+}$ and $a/\\sqrt{t}\\to\\infty$.", "answer": "$$\\boxed{t+a^{2}-a\\sqrt{t}\\,\\frac{\\phi\\!\\left(\\frac{a}{\\sqrt{t}}\\right)}{1-\\Phi\\!\\left(\\frac{a}{\\sqrt{t}}\\right)}}$$", "id": "1292240"}]}