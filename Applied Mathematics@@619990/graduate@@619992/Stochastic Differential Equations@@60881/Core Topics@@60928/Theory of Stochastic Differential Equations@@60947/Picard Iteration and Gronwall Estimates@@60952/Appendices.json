{"hands_on_practices": [{"introduction": "To build a solid foundation for solving stochastic differential equations, we first need to understand the fundamental properties of the integral operator at the heart of the SDE. This exercise challenges you to critically examine the roles of the Lipschitz and linear growth conditions, which are the cornerstones of the existence and uniqueness theorem. By analyzing the properties of the associated mapping $\\Phi$, you will verify why it acts as a contraction only on sufficiently small time intervals, a crucial insight that motivates the entire constructive proof [@problem_id:2990634].", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\in[0,T]},\\mathbb{P})$ satisfying the usual conditions and supporting an $m$-dimensional standard Brownian motion $W=(W_{t})_{t\\in[0,T]}$. Fix $d\\in\\mathbb{N}$ and consider the stochastic differential equation in integral form\n$$\nX_{t} \\;=\\; X_{0} \\;+\\; \\int_{0}^{t} b(s,X_{s})\\,ds \\;+\\; \\int_{0}^{t} \\sigma(s,X_{s})\\,dW_{s}, \\qquad t\\in[0,T],\n$$\nwhere $b:[0,T]\\times\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ and $\\sigma:[0,T]\\times\\mathbb{R}^{d}\\to\\mathbb{R}^{d\\times m}$ are Borel measurable and progressively measurable in the time variable. Assume the following global Lipschitz and linear growth conditions: there exists a constant $L>0$ such that for all $t\\in[0,T]$ and $x,y\\in\\mathbb{R}^{d}$,\n$$\n\\lvert b(t,x)-b(t,y)\\rvert \\;+\\; \\lVert \\sigma(t,x)-\\sigma(t,y)\\rVert \\;\\le\\; L\\,\\lvert x-y\\rvert,\n$$\nand there exists a constant $K>0$ such that for all $t\\in[0,T]$ and $x\\in\\mathbb{R}^{d}$,\n$$\n\\lvert b(t,x)\\rvert^{2} \\;+\\; \\lVert \\sigma(t,x)\\rVert^{2} \\;\\le\\; K\\big(1+\\lvert x\\rvert^{2}\\big).\n$$\nLet $X_{0}$ be $(\\mathcal{F}_{0})$-measurable with $\\mathbb{E}\\lvert X_{0}\\rvert^{2}<\\infty$. Define the Picard iteration $(X^{(n)})_{n\\in\\mathbb{N}}$ by $X^{(0)}_{t}\\equiv X_{0}$ and\n$$\nX^{(n+1)}_{t} \\;=\\; X_{0} \\;+\\; \\int_{0}^{t} b\\big(s,X^{(n)}_{s}\\big)\\,ds \\;+\\; \\int_{0}^{t} \\sigma\\big(s,X^{(n)}_{s}\\big)\\,dW_{s}, \\qquad t\\in[0,T].\n$$\nConsider the mapping $\\Phi$ acting on progressively measurable processes with finite norm\n$$\n\\lVert X\\rVert \\;:=\\; \\Big(\\mathbb{E}\\,\\sup_{0\\le t\\le T} \\lvert X_{t}\\rvert^{2}\\Big)^{1/2},\n$$\ndefined by\n$$\n\\big(\\Phi(X)\\big)_{t} \\;:=\\; X_{0} \\;+\\; \\int_{0}^{t} b(s,X_{s})\\,ds \\;+\\; \\int_{0}^{t} \\sigma(s,X_{s})\\,dW_{s}.\n$$\nUsing only foundational tools such as the integral form of the stochastic differential equation, Itô's isometry for stochastic integrals, the Burkholder–Davis–Gundy (BDG) inequality, and Gronwall's inequality, determine which of the following statements are true. Select all that apply.\n\nA. For any $T>0$, the mapping $\\Phi$ is a contraction in the norm $\\lVert\\cdot\\rVert$ on the space of progressively measurable processes, and hence the Picard iteration converges in $\\lVert\\cdot\\rVert$ to a unique fixed point on $[0,T]$.\n\nB. There exists $T^{\\ast}>0$, depending only on $L$ and universal constants, such that for all $T\\in(0,T^{\\ast})$, the mapping $\\Phi$ is a contraction in the norm $\\lVert\\cdot\\rVert$, so the Picard iteration converges in $\\lVert\\cdot\\rVert$ to a unique fixed point on $[0,T]$.\n\nC. Under the stated global Lipschitz and linear growth conditions and $\\mathbb{E}\\lvert X_{0}\\rvert^{2}<\\infty$, there exists a constant $C(T)$ depending on $L$, $K$, and $T$ such that any solution $X$ satisfies the moment bound $\\mathbb{E}\\,\\sup_{0\\le t\\le T} \\lvert X_{t}\\rvert^{2} \\le C(T)\\,\\big(1+\\mathbb{E}\\lvert X_{0}\\rvert^{2}\\big)$.\n\nD. If $b$ and $\\sigma$ are locally Lipschitz in the spatial variable and satisfy the linear growth condition, then pathwise uniqueness holds on $[0,T]$ for nonexplosive solutions.\n\nE. If $b$ and $\\sigma$ are merely measurable and satisfy the linear growth condition (but not any Lipschitz condition), then the Picard iteration $(X^{(n)})_{n\\in\\mathbb{N}}$ still converges in the norm $\\lVert\\cdot\\rVert$ to a solution on any $[0,T]$.", "solution": "The problem statement presents a classical setup for a stochastic differential equation (SDE) under global Lipschitz and linear growth conditions. The core of the problem is to evaluate several standard theoretical results concerning the existence, uniqueness, and properties of solutions to such an SDE, particularly in the context of Picard iteration. The problem is well-posed and scientifically sound, based on foundational principles of stochastic calculus. We shall proceed to analyze each statement using the prescribed tools.\n\nLet $X$ and $Y$ be two progressively measurable processes belonging to the space $\\mathcal{S}_T := \\{ Z \\text{ progressively measurable} : \\lVert Z \\rVert^2 = \\mathbb{E} \\sup_{0 \\le t \\le T} \\lvert Z_t \\rvert^2 < \\infty \\}$. This space, equipped with the norm $\\lVert\\cdot\\rVert$, is a Banach space. The mapping $\\Phi$ is defined as:\n$$\n(\\Phi(Z))_t = X_0 + \\int_0^t b(s, Z_s) ds + \\int_0^t \\sigma(s, Z_s) dW_s.\n$$\nA solution to the SDE is a fixed point of $\\Phi$.\n\nFirst, let us estimate the distance between $\\Phi(X)$ and $\\Phi(Y)$ in the norm $\\lVert\\cdot\\rVert$:\n$$\n(\\Phi(X))_t - (\\Phi(Y))_t = \\int_0^t (b(s,X_s) - b(s,Y_s)) ds + \\int_0^t (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s.\n$$\nUsing the inequality $(a+b)^2 \\le 2a^2 + 2b^2$, we have for any $t \\in [0,T]$:\n$$\n\\lvert (\\Phi(X))_t - (\\Phi(Y))_t \\rvert^2 \\le 2 \\left\\lvert \\int_0^t (b(s,X_s) - b(s,Y_s)) ds \\right\\rvert^2 + 2 \\left\\lvert \\int_0^t (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s \\right\\rvert^2.\n$$\nTaking the supremum over $t \\in [0,T]$ and then the expectation:\n$$\n\\lVert \\Phi(X) - \\Phi(Y) \\rVert^2 \\le 2 \\mathbb{E} \\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t (b(s,X_s) - b(s,Y_s)) ds \\right\\rvert^2 + 2 \\mathbb{E} \\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s \\right\\rvert^2.\n$$\nFor the drift term, using the Cauchy-Schwarz inequality:\n$$\n\\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t \\dots ds \\right\\rvert^2 \\le \\sup_{0 \\le t \\le T} \\left( t \\int_0^t \\lvert b(s,X_s) - b(s,Y_s) \\rvert^2 ds \\right) \\le T \\int_0^T L^2 \\lvert X_s - Y_s \\rvert^2 ds.\n$$\nTaking expectation, we get $T L^2 \\int_0^T \\mathbb{E} \\lvert X_s - Y_s \\rvert^2 ds \\le T L^2 \\int_0^T \\lVert X-Y \\rVert^2 ds = T^2 L^2 \\lVert X-Y \\rVert^2$.\n\nFor the diffusion term, using the Burkholder-Davis-Gundy (BDG) inequality, there exists a universal constant $C_{BDG} > 0$ such that:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le T} \\left\\lvert \\int_0^t \\dots dW_s \\right\\rvert^2 \\le C_{BDG} \\mathbb{E} \\int_0^T \\lVert \\sigma(s,X_s) - \\sigma(s,Y_s) \\rVert^2 ds.\n$$\nUsing the Lipschitz condition, this is bounded by $C_{BDG} L^2 \\mathbb{E} \\int_0^T \\lvert X_s - Y_s \\rvert^2 ds \\le C_{BDG} L^2 T \\lVert X-Y \\rVert^2$.\n\nCombining these bounds, we get:\n$$\n\\lVert \\Phi(X) - \\Phi(Y) \\rVert^2 \\le 2(T^2 L^2 + C_{BDG} T L^2) \\lVert X-Y \\rVert^2 = 2 L^2 (T^2 + C_{BDG} T) \\lVert X-Y \\rVert^2.\n$$\nThe mapping $\\Phi$ is a contraction if $2 L^2 (T^2 + C_{BDG} T) < 1$.\n\n**Analysis of Option A:**\nThe statement claims that for any $T > 0$, $\\Phi$ is a contraction. The condition for contraction is $2 L^2 (T^2 + C_{BDG} T) < 1$. The term $2 L^2 (T^2 + C_{BDG} T)$ is a strictly increasing function of $T$ for $T>0$. For any given $L>0$, one can choose $T$ large enough to violate this condition. For instance, if $T > 1/(\\sqrt{2}L)$, then $T^2 > 1/(2L^2)$, so $2L^2T^2 > 1$, making the contraction condition false. Therefore, $\\Phi$ is not a contraction for all $T>0$. The convergence of Picard iterations on arbitrary intervals $[0,T]$ is typically proven by showing that some power $\\Phi^k$ of the map is a contraction, or by using a weighted norm, not by $\\Phi$ itself being a contraction.\nVerdict: **Incorrect**.\n\n**Analysis of Option B:**\nThe statement claims there exists a small enough time horizon $T^* > 0$ for which $\\Phi$ is a contraction. Let $f(T) = 2 L^2 (T^2 + C_{BDG} T)$. We have $f(T) \\to 0$ as $T \\to 0^+$. Since $f(T)$ is continuous and increasing for $T>0$, there must exist some $T^* > 0$ such that for all $T \\in (0, T^*)$, we have $f(T) < 1$. This $T^*$ depends on $L$ and the universal constant $C_{BDG}$. For such a $T$, $\\Phi$ is a contraction mapping on the Banach space $\\mathcal{S}_T$. By the Banach fixed-point theorem, $\\Phi$ has a unique fixed point, and the Picard iteration $X^{(n+1)} = \\Phi(X^{(n)})$ converges to this fixed point in the norm $\\lVert\\cdot\\rVert$.\nVerdict: **Correct**.\n\n**Analysis of Option C:**\nThis statement concerns an a priori moment bound for any solution $X$. We start from the integral form of the SDE:\n$$\nX_t = X_0 + \\int_0^t b(s,X_s) ds + \\int_0^t \\sigma(s,X_s) dW_s.\n$$\nUsing $(a+b+c)^2 \\le 3(a^2+b^2+c^2)$, we bound $\\sup_{0 \\le t \\le u} \\lvert X_t \\rvert^2$ for any $u \\in [0,T]$:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le u} \\lvert X_t \\rvert^2 \\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3 \\mathbb{E} \\sup_{0 \\le t \\le u} \\left\\lvert \\int_0^t b(s,X_s) ds \\right\\rvert^2 + 3 \\mathbb{E} \\sup_{0 \\le t \\le u} \\left\\lvert \\int_0^t \\sigma(s,X_s) dW_s \\right\\rvert^2.\n$$\nUsing Cauchy-Schwarz, BDG, and the linear growth condition $\\lvert b(t,x)\\rvert^2 + \\lVert\\sigma(t,x)\\rVert^2 \\le K(1+\\lvert x\\rvert^2)$:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le u} \\left\\lvert \\dots \\right\\rvert^2 \\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3 T \\mathbb{E}\\int_0^u \\lvert b(s,X_s) \\rvert^2 ds + 3 C_{BDG} \\mathbb{E}\\int_0^u \\lVert \\sigma(s,X_s) \\rVert^2 ds.\n$$\n$$\n\\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3(T K + C_{BDG} K) \\int_0^u \\mathbb{E}(1+\\lvert X_s \\rvert^2) ds.\n$$\nLet $\\psi(u) = \\mathbb{E} \\sup_{0 \\le t \\le u} \\lvert X_t \\rvert^2$. Since $\\mathbb{E}\\lvert X_s \\rvert^2 \\le \\psi(s)$, we get for $u \\in [0,T]$:\n$$\n\\psi(u) \\le 3 \\mathbb{E}\\lvert X_0 \\rvert^2 + 3K(T+C_{BDG}) \\int_0^u (1+\\psi(s)) ds.\n$$\nLet $A = 3\\mathbb{E}\\lvert X_0 \\rvert^2$ and $C' = 3K(T+C_{BDG})$. The inequality is $\\psi(u) \\le A + C'u + C'\\int_0^u \\psi(s)ds$.\nApplying Gronwall's inequality (in the form $f(t) \\le g(t) + \\int_0^t h f(s)ds$ with non-decreasing $g$ leads to $f(t) \\le g(t)e^{ht}$), or more precisely by solving the associated differential inequality, we find $\\psi(u) \\le (1+A)e^{C'u} - 1$.\nFor $u=T$:\n$$\n\\mathbb{E} \\sup_{0 \\le t \\le T} \\lvert X_t \\rvert^2 \\le (1 + 3\\mathbb{E}\\lvert X_0 \\rvert^2) \\exp(3K(T+C_{BDG}) T) - 1.\n$$\nThis bound can be written in the form $C(T)(1+\\mathbb{E}\\lvert X_0 \\rvert^2)$ by choosing a sufficiently large constant $C(T)$. For example, $C(T) = 3\\exp(3K(T+C_{BDG})T)$ works, since $3e^{C'T}\\mathbb{E}|X_0|^2 + e^{C'T}-1 \\le 3e^{C'T}(1+\\mathbb{E}|X_0|^2)$. This constant depends on $K$ and $T$. The statement indicates a dependency on $L$, $K$, and $T$, which is not contradictory as a function of $K$ and $T$ is trivially also a function of $L$, $K$, and $T$.\nVerdict: **Correct**.\n\n**Analysis of Option D:**\nThe statement concerns pathwise uniqueness under local Lipschitz and linear growth conditions. Let $X$ and $Y$ be two nonexplosive solutions with the same initial condition $X_0 = Y_0$. Let $D_t = X_t - Y_t$. For any integer $R > 0$, define the stopping time $\\tau_R = \\inf\\{t \\in [0,T] : \\lvert X_t \\rvert \\ge R \\text{ or } \\lvert Y_t \\rvert \\ge R \\}$, with $\\inf \\emptyset = T$. Since solutions are nonexplosive, $\\tau_R \\to T$ almost surely as $R \\to \\infty$.\nFor $t \\in [0,T]$, consider the stopped process difference $D_{t \\wedge \\tau_R}$.\n$$\nD_{t \\wedge \\tau_R} = \\int_0^{t \\wedge \\tau_R} (b(s,X_s) - b(s,Y_s)) ds + \\int_0^{t \\wedge \\tau_R} (\\sigma(s,X_s) - \\sigma(s,Y_s)) dW_s.\n$$\nFor any $s \\le t \\wedge \\tau_R$, we have $\\lvert X_s \\rvert < R$ and $\\lvert Y_s \\rvert < R$. By the local Lipschitz condition, there is a constant $L_R$ such that $\\lvert b(s,X_s) - b(s,Y_s) \\rvert + \\lVert \\sigma(s,X_s) - \\sigma(s,Y_s) \\rVert \\le L_R \\lvert D_s \\rvert$.\nLet $f(t) = \\mathbb{E} \\lvert D_{t \\wedge \\tau_R} \\rvert^2$. Using Itô's isometry and Cauchy-Schwarz:\n$$\nf(t) = \\mathbb{E} \\left\\lvert \\int_0^t \\mathbb{1}_{s \\le \\tau_R} (b(s,X_s) - \\dots) ds \\right\\rvert^2 + \\mathbb{E} \\left\\lvert \\int_0^t \\mathbb{1}_{s \\le \\tau_R} (\\sigma(s,X_s) - \\dots) dW_s \\right\\rvert^2\n$$\n$$\nf(t) \\le T \\mathbb{E} \\int_0^t \\mathbb{1}_{s \\le \\tau_R} L_R^2 \\lvert D_s \\rvert^2 ds + \\mathbb{E} \\int_0^t \\mathbb{1}_{s \\le \\tau_R} L_R^2 \\lvert D_s \\rvert^2 ds\n$$\n$$\nf(t) \\le (T+1)L_R^2 \\int_0^t \\mathbb{E}\\lvert D_{s \\wedge \\tau_R} \\rvert^2 ds = (T+1)L_R^2 \\int_0^t f(s) ds.\n$$\nSince $f(0) = \\mathbb{E}\\lvert D_0 \\rvert^2 = 0$, Gronwall's inequality implies $f(t) = 0$ for all $t \\in [0,T]$.\nThis means $X_{t \\wedge \\tau_R} = Y_{t \\wedge \\tau_R}$ almost surely for all $t$. As this holds for any $R$, and $\\tau_R \\to T$ a.s., we conclude that $X_t = Y_t$ almost surely for all $t \\in [0,T]$. The linear growth condition ensures solutions are nonexplosive, so the premise of the statement is consistent.\nVerdict: **Correct**.\n\n**Analysis of Option E:**\nThis statement claims that Picard iteration converges even without a Lipschitz condition, provided linear growth holds. This is false. The Lipschitz condition is fundamental to the proof of convergence, as it ensures that the operator $\\Phi$ is a contraction on a small interval (or that one of its powers is). Without any modulus of continuity condition on the coefficients, the Picard sequence is not guaranteed to be a Cauchy sequence.\nConsider the deterministic ordinary differential equation $\\frac{dx}{dt} = \\sqrt{\\lvert x \\rvert}$ with $x(0)=0$, which can be viewed as an SDE with $\\sigma=0$. The coefficient $b(x)=\\sqrt{\\lvert x \\rvert}$ is not Lipschitz at $0$ but satisfies a linear growth condition. The Picard iteration starts with $X^{(0)}_t = 0$. Then $X^{(1)}_t = \\int_0^t b(X^{(0)}_s) ds = 0$, and so on. The sequence converges to the trivial solution $X_t=0$. However, $X_t = t^2/4$ is another solution. The iteration fails to find this solution. More critically, the iteration is not guaranteed to converge at all in general cases. For instance, for the SDE $dX_t=\\text{sgn}(X_t)dW_t$ (with $\\text{sgn}(0)=1$), the Picard sequence does not converge. Therefore, the statement is false.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{BCD}$$", "id": "2990634"}, {"introduction": "Knowing that the SDE operator is a local contraction is the first step; the next is to build a global solution from this property. This practice formalizes the context by defining the appropriate function space, $\\mathcal{S}^2$, where solutions reside. It then guides you through the standard method of constructing a unique global solution by 'stitching' together the local solutions guaranteed by the contraction mapping principle, a powerful and widely applicable technique in the analysis of differential equations [@problem_id:2990637].", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\in[0,T]},\\mathbb{P})$ satisfying the usual conditions, and let $(W_t)_{t\\in[0,T]}$ be an $\\mathbb{R}^m$-valued standard Brownian motion adapted to $(\\mathcal{F}_t)_{t\\in[0,T]}$. Let $d$ and $m$ be fixed positive integers, and let $X_0$ be an $\\mathcal{F}_0$-measurable $\\mathbb{R}^d$-valued random variable with $\\mathbb{E}[|X_0|^2]<\\infty$. Consider the stochastic integral equation\n$$\nX_t \\;=\\; X_0 \\;+\\; \\int_0^t b(s,X_s)\\,ds \\;+\\; \\int_0^t \\sigma(s,X_s)\\,dW_s,\\qquad t\\in[0,T],\n$$\nwhere $b:[0,T]\\times\\mathbb{R}^d\\to\\mathbb{R}^d$ and $\\sigma:[0,T]\\times\\mathbb{R}^d\\to\\mathbb{R}^{d\\times m}$ are jointly measurable and adapted in the sense that $b(t,X_t)$ and $\\sigma(t,X_t)$ are progressively measurable for any adapted process $(X_t)_{t\\in[0,T]}$. Assume the following global Lipschitz and linear growth conditions hold: there exist constants $L\\ge 0$ and $M\\ge 0$ such that for all $t\\in[0,T]$ and $x,y\\in\\mathbb{R}^d$,\n$$\n|b(t,x)-b(t,y)| \\;+\\; \\lVert\\sigma(t,x)-\\sigma(t,y)\\rVert_{\\mathrm{F}} \\;\\le\\; L\\,|x-y|,\n$$\nand\n$$\n|b(t,x)|^2 \\;+\\; \\lVert\\sigma(t,x)\\rVert_{\\mathrm{F}}^2 \\;\\le\\; M\\,\\big(1+|x|^2\\big),\n$$\nwhere $\\lVert\\cdot\\rVert_{\\mathrm{F}}$ denotes the Frobenius norm on $\\mathbb{R}^{d\\times m}$.\n\nDefine the mapping $\\Phi$ on a space of adapted processes by\n$$\n\\big(\\Phi(X)\\big)_t \\;:=\\; X_0 \\;+\\; \\int_0^t b(s,X_s)\\,ds \\;+\\; \\int_0^t \\sigma(s,X_s)\\,dW_s,\\qquad t\\in[0,T].\n$$\nConsider the following function spaces and norms:\n- $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ is the space of all $(\\mathcal{F}_t)$-adapted, continuous $\\mathbb{R}^d$-valued processes $X$ with finite norm\n$$\n\\lVert X\\rVert_{\\mathcal{S}^2_T} \\;:=\\; \\Big(\\mathbb{E}\\big[\\sup_{t\\in[0,T]}|X_t|^2\\big]\\Big)^{1/2}.\n$$\n- $\\mathcal{H}^2([0,T];\\mathbb{R}^d)$ is the space of all predictable $\\mathbb{R}^d$-valued processes $X$ with finite norm\n$$\n\\lVert X\\rVert_{\\mathcal{H}^2_T} \\;:=\\; \\Big(\\mathbb{E}\\big[\\int_0^T |X_t|^2\\,dt\\big]\\Big)^{1/2}.\n$$\n\nUsing only the foundational definitions of stochastic integrals, adaptedness, the global Lipschitz and linear growth conditions above, and well-tested inequalities for stochastic integrals such as the Burkholder–Davis–Gundy (BDG) inequality and Gronwall-type estimates, determine which of the following statements are true:\n\nA. Under the stated assumptions, the mapping $\\Phi$ takes $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ into itself, i.e., for any $X\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$, one has $\\Phi(X)\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$.\n\nB. There exists a time $T^\\star>0$, depending only on the Lipschitz constant $L$ (and dimension-dependent BDG constants), such that for all $T\\in(0,T^\\star)$, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\lVert\\cdot\\rVert_{\\mathcal{S}^2_T}$.\n\nC. Under the same assumptions, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for every $T>0$.\n\nD. In $\\mathcal{H}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\lVert\\cdot\\rVert_{\\mathcal{H}^2_T}$, the mapping $\\Phi$ is a strict contraction for any $T>0$ under the stated assumptions.\n\nE. Even if $\\Phi$ is not a contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for a given $T>0$, one can still construct a unique strong solution on $[0,T]$ by performing Picard iteration on a finite partition of $[0,T]$ into subintervals on which $\\Phi$ is a contraction, and then use a Gronwall estimate to propagate uniqueness across subintervals.\n\nSelect all that apply.", "solution": "The problem statement is a standard formulation of the existence and uniqueness problem for a stochastic differential equation (SDE) under global Lipschitz and linear growth conditions. All components of the problem are well-defined and standard in the theory of SDEs. The problem is scientifically grounded, well-posed, and objective. We may proceed to the solution.\n\nWe analyze each statement individually. Let $X$ and $Y$ be processes in the appropriate function spaces.\n\n### Statement A\n\n**Statement A: Under the stated assumptions, the mapping $\\Phi$ takes $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ into itself, i.e., for any $X\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$, one has $\\Phi(X)\\in\\mathcal{S}^2([0,T];\\mathbb{R}^d)$.**\n\nLet $X \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$. This means $X$ is an adapted, continuous process such that $\\lVert X\\rVert_{\\mathcal{S}^2_T}^2 = \\mathbb{E}[\\sup_{t\\in[0,T]}|X_t|^2] < \\infty$. We need to show that $Y = \\Phi(X)$ also satisfies $\\lVert Y\\rVert_{\\mathcal{S}^2_T} < \\infty$. The process $Y_t$ is given by:\n$$ Y_t = X_0 + \\int_0^t b(s,X_s)\\,ds + \\int_0^t \\sigma(s,X_s)\\,dW_s $$\nUsing the inequality $(a+b+c)^2 \\le 3(a^2+b^2+c^2)$, we have for any $t\\in[0,T]$:\n$$ |Y_t|^2 \\le 3|X_0|^2 + 3\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 + 3\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2 $$\nTaking the supremum over $t \\in [0,T]$ on both sides:\n$$ \\sup_{t\\in[0,T]}|Y_t|^2 \\le 3|X_0|^2 + 3\\sup_{t\\in[0,T]}\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 + 3\\sup_{t\\in[0,T]}\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2 $$\nTaking the expectation:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}|Y_t|^2\\right] \\le 3\\mathbb{E}[|X_0|^2] + 3\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2\\right] + 3\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2\\right] $$\nWe analyze each term. $\\mathbb{E}[|X_0|^2] < \\infty$ is given.\n\nFor the Lebesgue integral term, by the Cauchy-Schwarz inequality for integrals:\n$$ \\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 \\le \\left(\\int_0^t |b(s,X_s)|\\,ds\\right)^2 \\le \\left(\\int_0^t 1^2\\,ds\\right)\\left(\\int_0^t |b(s,X_s)|^2\\,ds\\right) = t\\int_0^t |b(s,X_s)|^2\\,ds $$\nTherefore, $\\sup_{t\\in[0,T]}\\left|\\int_0^t b(s,X_s)\\,ds\\right|^2 \\le T\\int_0^T |b(s,X_s)|^2\\,ds$. Using the linear growth condition $|b(t,x)|^2 \\le M(1+|x|^2)$:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\dots\\right|^2\\right] \\le T\\mathbb{E}\\left[\\int_0^T M(1+|X_s|^2)\\,ds\\right] = TM \\int_0^T(1+\\mathbb{E}[|X_s|^2])\\,ds $$\nSince $\\mathbb{E}[|X_s|^2] \\le \\mathbb{E}[\\sup_{u\\in[0,T]}|X_u|^2] = \\lVert X\\rVert_{\\mathcal{S}^2_T}^2 < \\infty$, this term is finite.\n\nFor the stochastic integral term, we use the Burkholder-Davis-Gundy (BDG) inequality for $p=2$, which states there is a constant $C_2>0$ such that:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\sigma(s,X_s)\\,dW_s\\right|^2\\right] \\le C_2 \\mathbb{E}\\left[\\left\\langle\\int_0^\\cdot \\sigma dW\\right\\rangle_T\\right] = C_2 \\mathbb{E}\\left[\\int_0^T \\lVert\\sigma(s,X_s)\\rVert_{\\mathrm{F}}^2\\,ds\\right] $$\nUsing the linear growth condition $\\lVert\\sigma(t,x)\\rVert_{\\mathrm{F}}^2 \\le M(1+|x|^2)$:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t \\dots\\right|^2\\right] \\le C_2 M \\mathbb{E}\\left[\\int_0^T (1+|X_s|^2)\\,ds\\right] = C_2 M \\int_0^T(1+\\mathbb{E}[|X_s|^2])\\,ds < \\infty $$\nCombining the bounds, we have shown that $\\mathbb{E}[\\sup_{t\\in[0,T]}|Y_t|^2]$ is bounded by a finite quantity that depends on $\\mathbb{E}[|X_0|^2]$, $\\lVert X\\rVert_{\\mathcal{S}^2_T}$, $T$, $M$, and $C_2$. Thus, if $X \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$, then $\\Phi(X) \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$.\n\n**Verdict on A: Correct**\n\n### Statements B and C\n\n**Statement B: There exists a time $T^\\star>0$, depending only on the Lipschitz constant $L$ (and dimension-dependent BDG constants), such that for all $T\\in(0,T^\\star)$, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\lVert\\cdot\\rVert_{\\mathcal{S}^2_T}$.**\n\n**Statement C: Under the same assumptions, the mapping $\\Phi$ is a strict contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for every $T>0$.**\n\nLet $X, Y \\in \\mathcal{S}^2([0,T];\\mathbb{R}^d)$. We analyze the norm of the difference $\\Phi(X)-\\Phi(Y)$:\n$$ (\\Phi(X))_t - (\\Phi(Y))_t = \\int_0^t (b(s,X_s)-b(s,Y_s))\\,ds + \\int_0^t (\\sigma(s,X_s)-\\sigma(s,Y_s))\\,dW_s $$\nLet $\\Delta X_t = X_t-Y_t$. Using the same procedure as for statement A:\n$$ \\lVert\\Phi(X)-\\Phi(Y)\\rVert_{\\mathcal{S}^2_T}^2 = \\mathbb{E}\\left[\\sup_{t\\in[0,T]}|(\\Phi(X))_t - (\\Phi(Y))_t|^2\\right] $$\n$$ \\le 2\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t (b(s,X_s)-b(s,Y_s))\\,ds\\right|^2\\right] + 2\\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t (\\sigma(s,X_s)-\\sigma(s,Y_s))\\,dW_s\\right|^2\\right] $$\nUsing the global Lipschitz condition $|b(t,x)-b(t,y)| + \\lVert\\sigma(t,x)-\\sigma(t,y)\\rVert_{\\mathrm{F}} \\le L|x-y|$:\nThe Lebesgue integral term is bounded as:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t\\dots\\right|^2\\right] \\le T\\mathbb{E}\\left[\\int_0^T |b(s,X_s)-b(s,Y_s)|^2\\,ds\\right] \\le T L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2\\,ds\\right] \\le T^2 L^2 \\lVert\\Delta X\\rVert_{\\mathcal{S}^2_T}^2 $$\nThe stochastic integral term is bounded using BDG:\n$$ \\mathbb{E}\\left[\\sup_{t\\in[0,T]}\\left|\\int_0^t\\dots\\right|^2\\right] \\le C_2 \\mathbb{E}\\left[\\int_0^T \\lVert\\sigma(s,X_s)-\\sigma(s,Y_s)\\rVert_{\\mathrm{F}}^2\\,ds\\right] \\le C_2 L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2\\,ds\\right] \\le C_2 T L^2 \\lVert\\Delta X\\rVert_{\\mathcal{S}^2_T}^2 $$\nCombining these, we get:\n$$ \\lVert\\Phi(X)-\\Phi(Y)\\rVert_{\\mathcal{S}^2_T}^2 \\le (2T^2 L^2 + 2C_2 T L^2) \\lVert\\Delta X\\rVert_{\\mathcal{S}^2_T}^2 = 2L^2(T^2+C_2 T)\\lVert X-Y\\rVert_{\\mathcal{S}^2_T}^2 $$\nFor $\\Phi$ to be a strict contraction, we need the factor $K(T) = 2L^2(T^2+C_2 T)$ to be strictly less than $1$.\nThe function $K(T)$ is continuous in $T$, and $K(0)=0$. For $L>0$, we can choose $T > 0$ small enough such that $K(T) < 1$. Specifically, we need $T^2+C_2 T < 1/(2L^2)$. The positive root of $T^2+C_2 T - 1/(2L^2)=0$ defines a threshold $T^\\star$. For any $T \\in (0, T^\\star)$, $\\Phi$ is a strict contraction. This confirms statement B.\n\nHowever, as $T$ increases, $K(T)$ also increases without bound. For any $L>0$, we can find a $T$ large enough such that $K(T) \\ge 1$. For example, if $T = 1/(L\\sqrt{2})$, then $T^2 = 1/(2L^2)$, so $K(T) = 2L^2(1/(2L^2) + C_2/(L\\sqrt{2}))=1+2\\sqrt{2}C_2 L > 1$. Therefore, $\\Phi$ is not a strict contraction for every $T>0$. This refutes statement C.\n\n**Verdict on B: Correct**\n**Verdict on C: Incorrect**\n\n### Statement D\n\n**Statement D: In $\\mathcal{H}^2([0,T];\\mathbb{R}^d)$ equipped with the norm $\\lVert\\cdot\\rVert_{\\mathcal{H}^2_T}$, the mapping $\\Phi$ is a strict contraction for any $T>0$ under the stated assumptions.**\n\nFirst, one must verify that $\\Phi$ maps $\\mathcal{H}^2$ to itself. Similar calculations as in A (but integrating over $t\\in[0,T]$ and using Fubini's theorem) confirm this.\nNow, we test for contraction in the norm $\\lVert Z\\rVert_{\\mathcal{H}^2_T}^2 = \\mathbb{E}[\\int_0^T |Z_t|^2\\,dt]$. Let $\\Delta Z_t = (\\Phi(X))_t - (\\Phi(Y))_t$.\n$$ \\lVert\\Delta Z\\rVert_{\\mathcal{H}^2_T}^2 = \\mathbb{E}\\left[\\int_0^T |\\Delta Z_t|^2\\,dt\\right] \\le 2\\mathbb{E}\\left[\\int_0^T \\left|\\int_0^t \\dots_b\\right|^2 dt\\right] + 2\\mathbb{E}\\left[\\int_0^T \\left|\\int_0^t \\dots_\\sigma\\right|^2 dt\\right] $$\nwhere $\\dots_b$ and $\\dots_\\sigma$ denote the respective integrands from the difference equation.\nFor the first term, using C-S, Fubini's theorem, and the Lipschitz condition:\n$$ \\mathbb{E}\\left[\\int_0^T \\left(t\\int_0^t |b_s-b'_s|^2 ds\\right) dt\\right] \\le L^2 \\mathbb{E}\\left[\\int_0^T t\\int_0^t |\\Delta X_s|^2 ds dt\\right] = L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 \\left(\\int_s^T t\\,dt\\right) ds\\right] $$\n$$ = L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 \\frac{T^2-s^2}{2} ds\\right] \\le \\frac{L^2T^2}{2} \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 ds\\right] = \\frac{L^2T^2}{2} \\lVert X-Y\\rVert_{\\mathcal{H}^2_T}^2 $$\nFor the second term, using Ito's isometry, Fubini's theorem, and the Lipschitz condition:\n$$ \\mathbb{E}\\left[\\int_0^T \\left|\\int_0^t \\dots_\\sigma\\right|^2 dt\\right] = \\int_0^T \\mathbb{E}\\left[\\left|\\int_0^t \\dots_\\sigma\\right|^2\\right] dt = \\int_0^T \\mathbb{E}\\left[\\int_0^t \\lVert\\sigma_s-\\sigma'_s\\rVert_{\\mathrm{F}}^2 ds\\right] dt $$\n$$ \\le L^2 \\mathbb{E}\\left[\\int_0^T \\int_0^t |\\Delta X_s|^2 ds dt\\right] = L^2 \\mathbb{E}\\left[\\int_0^T |\\Delta X_s|^2 (T-s) ds\\right] \\le L^2 T \\lVert X-Y\\rVert_{\\mathcal{H}^2_T}^2 $$\nCombining these bounds:\n$$ \\lVert\\Phi(X)-\\Phi(Y)\\rVert_{\\mathcal{H}^2_T}^2 \\le \\left(2\\cdot\\frac{L^2T^2}{2} + 2\\cdot L^2 T\\right) \\lVert X-Y\\rVert_{\\mathcal{H}^2_T}^2 = L^2(T^2+2T) \\lVert X-Y\\rVert_{\\mathcal{H}^2_T}^2 $$\nThe contraction factor $K'(T) = L^2(T^2+2T)$ is not less than $1$ for all $T>0$. Similar to the $\\mathcal{S}^2$ case, this only holds for small $T$. Therefore, statement D is false.\n\n**Verdict on D: Incorrect**\n\n### Statement E\n\n**Statement E: Even if $\\Phi$ is not a contraction on $\\mathcal{S}^2([0,T];\\mathbb{R}^d)$ for a given $T>0$, one can still construct a unique strong solution on $[0,T]$ by performing Picard iteration on a finite partition of $[0,T]$ into subintervals on which $\\Phi$ is a contraction, and then use a Gronwall estimate to propagate uniqueness across subintervals.**\n\nThis statement describes the standard proof of global existence and uniqueness for SDEs with globally Lipschitz coefficients.\n1.  **Existence via Partitioning:** As established in B, for any given $L$, there exists a $T^\\star > 0$ such that for any time interval of length less than $T^\\star$, the map $\\Phi$ (suitably defined on that interval) is a contraction on the corresponding space $\\mathcal{S}^2$. By the Banach fixed-point theorem, this guarantees a unique local solution. To obtain a solution on a larger interval $[0,T]$, we can partition it as $0=t_0 < t_1 < \\dots < t_N=T$ where $t_{k+1}-t_k < T^\\star$. A solution is constructed on $[0, t_1]$. The value $X_{t_1}$ serves as the initial condition for a new SDE on $[t_1, t_2]$, for which a solution can be constructed. This procedure is repeated or \"stitched\" together to form a solution on the entire interval $[0,T]$. This is the essence of \"performing Picard iteration on a finite partition...\".\n\n2.  **Uniqueness via Gronwall's Inequality:** To show that the constructed solution is the *unique* solution on $[0,T]$, suppose $X_t$ and $Y_t$ are two solutions. Let $\\phi(t) = \\mathbb{E}[|X_t - Y_t|^2]$. Following an argument similar to B but without suprema (and using Ito isometry instead of BDG), we find:\n    $$ \\phi(t) = \\mathbb{E}[|X_t - Y_t|^2] \\le \\mathbb{E}\\left[t\\int_0^t L^2|X_s-Y_s|^2 ds\\right] + \\mathbb{E}\\left[\\int_0^t L^2|X_s-Y_s|^2 ds\\right] $$\n    $$ \\phi(t) \\le L^2(t+1)\\int_0^t \\mathbb{E}[|X_s-Y_s|^2] ds = L^2(t+1)\\int_0^t \\phi(s) ds $$\n    Since $t \\le T$, we have $\\phi(t) \\le L^2(T+1)\\int_0^t \\phi(s) ds$. We have $\\phi(0) = \\mathbb{E}[|X_0-Y_0|^2] = 0$. By the integral form of Gronwall's inequality, this implies $\\phi(t)=0$ for all $t\\in[0,T]$, establishing uniqueness. While the statement's phrasing \"propagate uniqueness across subintervals\" is slightly informal, it correctly captures the essence of how the local existence arguments are combined with a global uniqueness proof (via Gronwall's inequality) to ensure a single, unique solution on the entire interval $[0,T]$.\n\nThe procedure described is a valid and standard method in SDE theory.\n\n**Verdict on E: Correct**", "answer": "$$\\boxed{ABE}$$", "id": "2990637"}, {"introduction": "This practice serves as a capstone, where the abstract theory of Picard iteration and Gronwall's inequality meets concrete application. You will work with the ubiquitous linear SDE, which models phenomena like geometric Brownian motion, and apply the theoretical machinery to bound the iterates and argue for convergence. The exercise culminates in deriving the exact second moment of the solution, allowing you to compare the general bounds obtained from Gronwall's inequality with the sharp result from an explicit calculation, thereby solidifying your understanding of the theory's power and limitations [@problem_id:2990636].", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\ge 0},\\mathbb{P})$ be a filtered probability space supporting a one-dimensional standard Brownian motion $W=(W_t)_{t \\ge 0}$. Consider the linear stochastic differential equation (SDE)\n$$\ndX_t \\;=\\; \\alpha \\, X_t \\, dt \\;+\\; \\beta \\, X_t \\, dW_t, \n\\qquad X_0 \\;=\\; x_0,\n$$\nwhere $\\alpha,\\beta \\in \\mathbb{R}$ are fixed constants and $x_0 \\in \\mathbb{R}$ is deterministic. Define the Picard iteration $(X^{(n)})_{n \\ge 0}$ by\n$$\nX^{(0)}_t \\;=\\; x_0,\n\\qquad\nX^{(n+1)}_t \\;=\\; x_0 \\;+\\; \\int_{0}^{t} \\alpha \\, X^{(n)}_s \\, ds \\;+\\; \\int_{0}^{t} \\beta \\, X^{(n)}_s \\, dW_s,\n\\quad n \\ge 0.\n$$\nUsing only the defining properties of the Itô integral, the Itô isometry for square-integrable martingales, and the deterministic Gronwall inequality, carry out the following steps for a fixed but arbitrary finite horizon $T>0$:\n- Establish that each Picard iterate $X^{(n)}$ is well-defined, adapted, and square-integrable, and derive an explicit bound of the form\n$$\n\\mathbb{E}\\big[|X^{(n)}_t|^{2}\\big] \\;\\le\\; A \\, \\exp\\!\\big(B\\,t\\big)\n\\quad \\text{for all } t \\in [0,T],\n$$\nfor some constants $A,B>0$ depending only on $\\alpha,\\beta,x_0$, and $T$. Provide explicit choices of $A$ and $B$ that you can justify by your estimates.\n- Using your bounds and a contraction argument on sufficiently small time intervals, argue that the Picard iteration converges (hence the SDE has a unique solution) in the space $L^{2}\\big([0,T] \\times \\Omega\\big)$.\n\nThen, for the limiting solution $X$, compute $\\mathbb{E}\\big[|X_t|^{2}\\big]$ exactly for each $t \\ge 0$ and determine the smallest constant $C \\in \\mathbb{R}$ such that\n$$\n\\mathbb{E}\\big[|X_t|^{2}\\big] \\;\\le\\; |x_0|^{2} \\, \\exp\\!\\big(C\\,t\\big)\n\\quad \\text{for all } t \\ge 0.\n$$\nReport the value of $C$ as a closed-form analytic expression.", "solution": "This problem analyzes a linear SDE where coefficients $b(t,x) = \\alpha x$ and $\\sigma(t,x) = \\beta x$ are globally Lipschitz and satisfy a linear growth condition. The problem is well-posed and asks for a standard analysis of the associated Picard iteration and the exact second moment of the solution.\n\n**Part 1: Uniform Bound on Picard Iterates**\n\nWe aim to find constants $A, B > 0$ such that $\\mathbb{E}[|X^{(n)}_t|^2] \\le A \\exp(Bt)$ for all $n \\ge 0$ and $t \\in [0,T]$. Each iterate $X^{(n)}$ is well-defined and adapted. We establish a uniform bound on the second moments by induction.\n\nUsing the inequality $(a+b+c)^2 \\le 3a^2 + 3b^2 + 3c^2$:\n$$\n|X^{(n+1)}_t|^2 \\le 3|x_0|^2 + 3\\left|\\int_0^t \\alpha X^{(n)}_s \\, ds\\right|^2 + 3\\left|\\int_0^t \\beta X^{(n)}_s \\, dW_s\\right|^2\n$$\nTaking expectations, using the Cauchy-Schwarz inequality for the Lebesgue integral and the Itô isometry for the stochastic integral:\n$$\n\\mathbb{E}\\big[|X^{(n+1)}_t|^2\\big] \\le 3|x_0|^2 + 3\\alpha^2 \\mathbb{E}\\left[\\left(\\int_0^t X^{(n)}_s ds\\right)^2\\right] + 3\\beta^2 \\mathbb{E}\\left[\\int_0^t |X^{(n)}_s|^2 ds\\right]\n$$\nApplying Cauchy-Schwarz again: $(\\int_0^t X^{(n)}_s ds)^2 \\le t \\int_0^t |X^{(n)}_s|^2 ds$. Since $t \\in [0,T]$:\n$$\n\\mathbb{E}\\big[|X^{(n+1)}_t|^2\\big] \\le 3|x_0|^2 + (3\\alpha^2 T + 3\\beta^2) \\int_0^t \\mathbb{E}\\big[|X^{(n)}_s|^2\\big] ds\n$$\nLet's choose $A = 3|x_0|^2$ and $B = 3\\alpha^2 T + 3\\beta^2$. We prove $\\mathbb{E}[|X^{(n)}_t|^2] \\le A e^{Bt}$ by induction.\n- **Base case ($n=0$):** $\\mathbb{E}[|X^{(0)}_t|^2] = |x_0|^2 \\le 3|x_0|^2 e^{Bt}$ is true since $B \\ge 0$.\n- **Inductive step:** Assume $\\mathbb{E}[|X^{(n)}_s|^2] \\le A e^{Bs}$ for all $s \\in [0,t]$.\n$$\n\\mathbb{E}\\big[|X^{(n+1)}_t|^2\\big] \\le A + B \\int_0^t \\mathbb{E}\\big[|X^{(n)}_s|^2\\big] ds \\le A + B \\int_0^t A e^{Bs} ds = A + A(e^{Bt} - 1) = A e^{Bt}\n$$\nThe induction holds. To strictly satisfy the problem's requirement of $A,B > 0$, one can choose $A = \\max(1, 3|x_0|^2)$ and $B = \\max(1, 3\\alpha^2 T + 3\\beta^2)$.\n\n**Part 2: Convergence Argument**\n\nWe show the Picard operator $\\Phi$ is a contraction on $L^2([0,T_0] \\times \\Omega)$ for a sufficiently small time horizon $T_0 > 0$. Let $\\mathcal{H}_t = L^2([0,t] \\times \\Omega)$ with norm $\\lVert Y \\rVert_{\\mathcal{H}_t}^2 = \\mathbb{E}[\\int_0^t |Y_s|^2 ds]$.\n$$\n(\\Phi(Y) - \\Phi(Z))_s = \\int_0^s \\alpha(Y_u - Z_u)du + \\int_0^s \\beta(Y_u - Z_u)dW_u\n$$\nTaking the second moment and bounding as before:\n$$\n\\mathbb{E}\\big[|(\\Phi(Y) - \\Phi(Z))_s|^2\\big] \\le (2\\alpha^2 s + 2\\beta^2) \\int_0^s \\mathbb{E}\\big[|Y_u-Z_u|^2\\big] du = (2\\alpha^2 s + 2\\beta^2) \\lVert Y-Z \\rVert_{\\mathcal{H}_s}^2\n$$\nNow we compute the norm of the difference:\n$$\n\\lVert \\Phi(Y) - \\Phi(Z) \\rVert_{\\mathcal{H}_{T_0}}^2 = \\int_0^{T_0} \\mathbb{E}\\big[|(\\Phi(Y) - \\Phi(Z))_s|^2\\big]ds \\le \\int_0^{T_0} (2\\alpha^2 s + 2\\beta^2) \\lVert Y-Z \\rVert_{\\mathcal{H}_s}^2 ds\n$$\nSince $\\lVert Y-Z \\rVert_{\\mathcal{H}_s}^2 \\le \\lVert Y-Z \\rVert_{\\mathcal{H}_{T_0}}^2$:\n$$\n\\lVert \\Phi(Y) - \\Phi(Z) \\rVert_{\\mathcal{H}_{T_0}}^2 \\le \\left(\\int_0^{T_0} (2\\alpha^2 s + 2\\beta^2)ds\\right) \\lVert Y-Z \\rVert_{\\mathcal{H}_{T_0}}^2 = (\\alpha^2 T_0^2 + 2\\beta^2 T_0) \\lVert Y-Z \\rVert_{\\mathcal{H}_{T_0}}^2\n$$\nThe mapping $\\Phi$ is a contraction if the factor $K(T_0) = \\alpha^2 T_0^2 + 2\\beta^2 T_0  1$. Since $K(T_0) \\to 0$ as $T_0 \\to 0$, we can choose a time $T_0 > 0$ small enough for this to hold. By the Banach fixed-point theorem, a unique solution exists on $[0, T_0]$. This procedure can be repeated on subsequent intervals $[T_0, 2T_0], \\dots$ to construct a unique solution on the entire interval $[0,T]$.\n\n**Part 3: Exact Second Moment and Constant C**\n\nWe apply Itô's formula to $f(x)=x^2$ with the solution process $X_t$. The dynamics are $dX_t = \\alpha X_t dt + \\beta X_t dW_t$.\nThe Itô differential is $df(X_t) = f'(X_t)dX_t + \\frac{1}{2}f''(X_t)d\\langle X, X \\rangle_t$.\nHere, $f'(x)=2x$, $f''(x)=2$, and $d\\langle X, X \\rangle_t = (\\beta X_t)^2 dt = \\beta^2 X_t^2 dt$.\n$$\nd(X_t^2) = 2X_t (\\alpha X_t dt + \\beta X_t dW_t) + \\frac{1}{2}(2)(\\beta^2 X_t^2 dt) = (2\\alpha + \\beta^2)X_t^2 dt + 2\\beta X_t^2 dW_t\n$$\nIntegrating and taking expectations, let $m(t) = \\mathbb{E}[X_t^2]$. Since the expectation of the stochastic integral is zero, we get:\n$$\n\\mathbb{E}[X_t^2] - \\mathbb{E}[X_0^2] = \\int_0^t (2\\alpha + \\beta^2)\\mathbb{E}[X_s^2] ds \\quad\\implies\\quad m(t) - m(0) = \\int_0^t (2\\alpha + \\beta^2)m(s) ds\n$$\nDifferentiating with respect to $t$, we obtain the ordinary differential equation $m'(t) = (2\\alpha + \\beta^2) m(t)$.\nWith the initial condition $m(0) = |x_0|^2$, the solution is:\n$$\nm(t) = |x_0|^2 \\exp\\big((2\\alpha + \\beta^2)t\\big)\n$$\nWe seek the smallest constant $C$ such that $\\mathbb{E}[|X_t|^2] \\le |x_0|^2 \\exp(Ct)$. By direct comparison, this constant is $C = 2\\alpha + \\beta^2$.", "answer": "$$\n\\boxed{2\\alpha + \\beta^{2}}\n$$", "id": "2990636"}]}