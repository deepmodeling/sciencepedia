{"hands_on_practices": [{"introduction": "The Feynman-Kac formula provides a powerful bridge between probability theory and the theory of partial differential equations. This first practice problem [@problem_id:3001146] offers a concrete application of this principle by asking you to solve a classic initial-boundary value problem for the heat equation. By working through the solution, you will gain hands-on experience in translating a probabilistic representation—the expected value of a functional of a killed Brownian motion—into a deterministic PDE and solving it using standard analytical techniques.", "problem": "Consider a one-dimensional standard Brownian motion $X = (X_{s})_{s \\geq 0}$ started at $x \\in (0,a)$, where $a>0$ is fixed, and let $\\tau_{D} = \\inf\\{s \\geq 0 : X_{s} \\notin (0,a)\\}$ denote the first exit time of $X$ from the open interval $D=(0,a)$. The process is absorbed at the boundary $\\{0,a\\}$, so that paths are killed upon exiting $D$. The infinitesimal generator of $X$ is given by the second-order differential operator $L = \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}$ acting on twice continuously differentiable functions with compact support in $D$.\n\nWith zero potential $V \\equiv 0$, the Feynman-Kac representation for the initial-boundary value problem for the heat equation in $D$ with absorbing boundary conditions and initial data $g$ and boundary data $\\varphi$ takes the form\n$$\nu(t,x) = \\mathbb{E}_{x}\\!\\left[g(X_{t})\\,\\mathbf{1}_{\\{t<\\tau_{D}\\}}\\right] + \\mathbb{E}_{x}\\!\\left[\\varphi\\!\\left(X_{\\tau_{D}}\\right)\\,\\mathbf{1}_{\\{\\tau_{D}\\leq t\\}}\\right],\n$$\nwhere $t>0$ and $x \\in (0,a)$.\n\nSpecialize to the choices\n$$\ng(x) = \\sin\\!\\left(\\frac{2\\pi x}{a}\\right) + \\frac{1}{2}\\sin\\!\\left(\\frac{5\\pi x}{a}\\right), \\qquad \\varphi \\equiv 0 \\text{ on } \\{0,a\\}.\n$$\nStarting from the fundamental definitions of the generator and the Feynman-Kac representation, derive the corresponding initial-boundary value problem and compute a closed-form expression for $u(t,x)$ for $t>0$ and $x \\in (0,a)$. Your final answer must be a single analytic expression for $u(t,x)$ in terms of $t$, $x$, and $a$. Do not round or approximate.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the established theory of stochastic differential equations and partial differential equations, specifically the Feynman-Kac formula and its relation to the heat equation. The problem is well-posed, providing a complete set of conditions (generator, domain, initial data, boundary data) that guarantee a unique, stable solution. The terminology is precise and objective, with no ambiguities or contradictions.\n\nThe task is to first derive the initial-boundary value problem (IBVP) corresponding to the given Feynman-Kac representation, and second, to compute the explicit solution $u(t,x)$.\n\nThe provided Feynman-Kac representation is\n$$\nu(t,x) = \\mathbb{E}_{x}\\!\\left[g(X_{t})\\,\\mathbf{1}_{\\{t<\\tau_{D}\\}}\\right] + \\mathbb{E}_{x}\\!\\left[\\varphi\\!\\left(X_{\\tau_{D}}\\right)\\,\\mathbf{1}_{\\{\\tau_{D}\\leq t\\}}\\right]\n$$\nThis is the probabilistic solution to a forward parabolic partial differential equation (PDE) for $u(t,x)$ where $t$ is the time variable and $x$ is the spatial variable. The infinitesimal generator of the process $X$, given as $L = \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}$, defines the spatial differential operator in the PDE. The potential is given as $V \\equiv 0$.\n\nThe governing PDE on the domain $D=(0,a)$ is therefore the heat equation:\n$$\n\\frac{\\partial u}{\\partial t} = L u \\implies \\frac{\\partial u}{\\partial t}(t,x) = \\frac{1}{2}\\frac{\\partial^{2}u}{\\partial x^{2}}(t,x), \\quad \\text{for } t > 0, x \\in (0,a)\n$$\n\nThe initial condition at $t=0$ is determined by the function $g(x)$. For $t \\to 0^+$, the probability that the process has exited the domain, $\\mathbb{P}_x(\\tau_D \\le t)$, approaches $0$. Thus, $u(t,x) \\to \\mathbb{E}_x[g(X_0)] = g(x)$. The initial condition is:\n$$\nu(0,x) = g(x) = \\sin\\!\\left(\\frac{2\\pi x}{a}\\right) + \\frac{1}{2}\\sin\\!\\left(\\frac{5\\pi x}{a}\\right), \\quad \\text{for } x \\in (0,a)\n$$\n\nThe boundary conditions are determined by the function $\\varphi$. The term $\\mathbb{E}_{x}\\!\\left[\\varphi\\!\\left(X_{\\tau_{D}}\\right)\\,\\mathbf{1}_{\\{\\tau_{D}\\leq t\\}}\\right]$ represents the influence of the boundary. The specified condition is $\\varphi \\equiv 0$ on the boundary $\\partial D = \\{0,a\\}$, which corresponds to absorbing boundary conditions. This implies that the solution must vanish at the boundaries for all time $t>0$. These are homogeneous Dirichlet boundary conditions:\n$$\nu(t,0) = 0 \\quad \\text{and} \\quad u(t,a) = 0, \\quad \\text{for } t > 0\n$$\n\nCombining these, the full IBVP is:\nPDE: $\\frac{\\partial u}{\\partial t} = \\frac{1}{2}\\frac{\\partial^{2} u}{\\partial x^{2}}$ for $t>0$ and $x \\in (0,a)$.\nBC: $u(t,0) = 0$ and $u(t,a) = 0$ for $t>0$.\nIC: $u(0,x) = \\sin(\\frac{2\\pi x}{a}) + \\frac{1}{2}\\sin(\\frac{5\\pi x}{a})$ for $x \\in (0,a)$.\n\nTo solve this IBVP, we use the method of separation of variables. We seek solutions of the form $u(t,x) = T(t)X(x)$. Substituting this into the PDE yields:\n$$\nT'(t)X(x) = \\frac{1}{2}T(t)X''(x)\n$$\nSeparating the variables, we get:\n$$\n\\frac{2T'(t)}{T(t)} = \\frac{X''(x)}{X(x)} = -\\lambda\n$$\nwhere $-\\lambda$ is the separation constant. This gives rise to two ordinary differential equations:\n$1$. $X''(x) + \\lambda X(x) = 0$\n$2$. $T'(t) + \\frac{\\lambda}{2}T(t) = 0$\n\nFirst, we solve the spatial equation for $X(x)$ subject to the boundary conditions $X(0)=0$ and $X(a)=0$.\nFor non-trivial solutions, the separation constant $\\lambda$ must be positive. Let $\\lambda = k^2$ for some $k>0$. The general solution is $X(x) = c_1\\cos(kx) + c_2\\sin(kx)$.\nThe condition $X(0)=0$ implies $c_1=0$.\nThe solution becomes $X(x) = c_2\\sin(kx)$.\nThe condition $X(a)=0$ implies $c_2\\sin(ka)=0$. Since we seek a non-trivial solution ($c_2 \\neq 0$), we must have $\\sin(ka)=0$. This occurs when $ka = n\\pi$ for any positive integer $n$ (since $k>0$, $a>0$).\nThe allowed values for $k$ are $k_n = \\frac{n\\pi}{a}$ for $n = 1, 2, 3, \\ldots$.\nThe corresponding eigenvalues are $\\lambda_n = k_n^2 = \\left(\\frac{n\\pi}{a}\\right)^2$.\nThe eigenfunctions are $X_n(x) = \\sin\\left(\\frac{n\\pi x}{a}\\right)$.\n\nNext, we solve the temporal equation for each eigenvalue $\\lambda_n$:\n$$\nT_n'(t) + \\frac{\\lambda_n}{2}T_n(t) = 0 \\implies T_n'(t) = -\\frac{1}{2}\\left(\\frac{n\\pi}{a}\\right)^2 T_n(t)\n$$\nThe solution for $T_n(t)$ is an exponential decay:\n$$\nT_n(t) = b_n \\exp\\left(-\\frac{n^2\\pi^2}{2a^2}t\\right)\n$$\nwhere $b_n$ are constants.\n\nBy the principle of superposition, the general solution $u(t,x)$ is an infinite series of the products $T_n(t)X_n(x)$:\n$$\nu(t,x) = \\sum_{n=1}^{\\infty} b_n \\exp\\left(-\\frac{n^2\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{n\\pi x}{a}\\right)\n$$\n\nTo find the coefficients $b_n$, we apply the initial condition $u(0,x)=g(x)$:\n$$\nu(0,x) = \\sum_{n=1}^{\\infty} b_n \\sin\\left(\\frac{n\\pi x}{a}\\right) = g(x) = \\sin\\left(\\frac{2\\pi x}{a}\\right) + \\frac{1}{2}\\sin\\left(\\frac{5\\pi x}{a}\\right)\n$$\nThe system of functions $\\{\\sin(\\frac{n\\pi x}{a})\\}_{n=1}^{\\infty}$ is orthogonal on the interval $[0,a]$. The initial condition $g(x)$ is already expressed as a finite sum in this basis. By comparing the terms in the series with the given expression for $g(x)$, we can identify the non-zero coefficients by inspection.\nThe term $\\sin(\\frac{2\\pi x}{a})$ corresponds to $n=2$, so we have $b_2=1$.\nThe term $\\frac{1}{2}\\sin(\\frac{5\\pi x}{a})$ corresponds to $n=5$, so we have $b_5=\\frac{1}{2}$.\nAll other coefficients $b_n$ for $n \\notin \\{2, 5\\}$ are zero.\n\nSubstituting these coefficients back into the general solution, the infinite series collapses into just two terms:\n$$\nu(t,x) = b_2 \\exp\\left(-\\frac{2^2\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{2\\pi x}{a}\\right) + b_5 \\exp\\left(-\\frac{5^2\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{5\\pi x}{a}\\right)\n$$\n$$\nu(t,x) = 1 \\cdot \\exp\\left(-\\frac{4\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{2\\pi x}{a}\\right) + \\frac{1}{2} \\exp\\left(-\\frac{25\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{5\\pi x}{a}\\right)\n$$\nSimplifying the exponential terms, we arrive at the final closed-form expression for the solution:\n$$\nu(t,x) = \\exp\\left(-\\frac{2\\pi^2 t}{a^2}\\right) \\sin\\left(\\frac{2\\pi x}{a}\\right) + \\frac{1}{2} \\exp\\left(-\\frac{25\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{5\\pi x}{a}\\right)\n$$\nThis expression is valid for $t>0$ and $x \\in (0,a)$.", "answer": "$$\n\\boxed{\\exp\\left(-\\frac{2\\pi^2 t}{a^2}\\right) \\sin\\left(\\frac{2\\pi x}{a}\\right) + \\frac{1}{2} \\exp\\left(-\\frac{25\\pi^2 t}{2a^2}\\right) \\sin\\left(\\frac{5\\pi x}{a}\\right)}\n$$", "id": "3001146"}, {"introduction": "The elegance of the Feynman-Kac representation lies in its broad applicability, extending beyond continuous diffusion processes. This exercise [@problem_id:3001177] moves into the realm of jump processes, specifically a Compound Poisson Process, demonstrating the formula's robustness. Tackling this problem will strengthen your ability to work with infinitesimal generators for non-local operators and to compute expectations involving random sums, a crucial skill in fields modeling events like insurance claims or financial shocks.", "problem": "Consider a one-dimensional Compound Poisson Process (CPP) $\\{X_{s}: s \\geq 0\\}$ defined by\n$$\nX_{s} \\equiv x + \\sum_{i=1}^{N_{s}} J_{i},\n$$\nwhere $x \\in \\mathbb{R}$ is the initial state, $\\{N_{s}: s \\geq 0\\}$ is a Poisson process with constant intensity $\\eta > 0$, and $\\{J_{i}\\}_{i \\in \\mathbb{N}}$ are independent and identically distributed jump sizes, independent of $\\{N_{s}\\}$. Suppose $J_{i} \\sim \\mathcal{N}(\\mu_{J}, \\sigma_{J}^{2})$ with $\\mu_{J} \\in \\mathbb{R}$ and $\\sigma_{J} > 0$. Let the potential be constant $V(x) \\equiv \\lambda$ for some $\\lambda \\geq 0$. Define the backward integro-differential problem for $u: [0,T] \\times \\mathbb{R} \\to \\mathbb{R}$:\n$$\n\\partial_{t} u(t,x) + \\mathcal{A} u(t,x) - \\lambda\\, u(t,x) = 0, \\quad t \\in [0,T), \\quad x \\in \\mathbb{R},\n$$\nwith terminal condition\n$$\nu(T,x) = g(x),\n$$\nwhere $g(x) = \\exp(\\beta x)$ for a fixed $\\beta \\in \\mathbb{R}$ satisfying the integrability condition that the moment generating function of $J_{1}$ is finite at $\\beta$. The generator $\\mathcal{A}$ of the CPP acts on sufficiently regular and bounded functions $f$ by\n$$\n\\mathcal{A} f(x) = \\eta \\int_{\\mathbb{R}} \\big(f(x+y) - f(x)\\big)\\,\\mu(dy),\n$$\nwhere $\\mu$ denotes the law of $J_{1}$.\n\nStarting from the infinitesimal generator characterization of $\\mathcal{A}$ and fundamental martingale arguments based on Dynkin’s formula and multiplicative functionals associated with potentials, derive a probabilistic representation for $u(t,x)$ and compute it explicitly for the given data. Your final answer must be a single closed-form analytic expression in terms of the parameters $t, x, T, \\eta, \\mu_{J}, \\sigma_{J}, \\lambda,$ and $\\beta$. No numerical rounding is required.", "solution": "The problem statement is internally consistent, scientifically grounded in the theory of stochastic processes, and well-posed. All required data and conditions are provided to derive a unique, meaningful solution. Thus, the problem is valid.\n\nThe problem asks for the solution $u(t,x)$ to the backward integro-differential equation:\n$$\n\\partial_{t} u(t,x) + \\mathcal{A} u(t,x) - \\lambda\\, u(t,x) = 0, \\quad t \\in [0,T), \\quad x \\in \\mathbb{R}\n$$\nwith terminal condition $u(T,x) = g(x) = \\exp(\\beta x)$. The operator $\\mathcal{A}$ is the infinitesimal generator of a Compound Poisson Process (CPP) $\\{X_s\\}$.\n\nThe solution to this class of problems is given by the Feynman-Kac formula, which provides a probabilistic representation for $u(t,x)$. We first establish this representation using the requested martingale argument.\n\nLet $\\{X_s\\}_{s \\ge t}$ be the CPP starting from $X_t = x$. Define a new process $Y_s$ for $s \\in [t, T]$ by\n$$\nY_s = \\exp\\left(-\\int_t^s \\lambda \\, dr\\right) u(s, X_s) = \\exp(-\\lambda(s-t)) u(s, X_s)\n$$\nwhere we have used the fact that the potential is a constant $V(x) = \\lambda$. We will show that $\\{Y_s\\}_{s \\in [t,T]}$ is a martingale under the filtration generated by $\\{X_s\\}$.\n\nBy applying Dynkin's formula (a generalization of Itô's lemma for processes with jumps) to the function $f(s,y) = \\exp(-\\lambda(s-t)) u(s,y)$ and the process $X_s$, we have:\n$$\n\\mathbb{E}[f(T, X_T)] - f(t, X_t) = \\mathbb{E}\\left[\\int_t^T \\left(\\frac{\\partial}{\\partial s} + \\mathcal{A}\\right)f(s,X_s) \\, ds\\right]\n$$\nLet's compute the term inside the integral. The generator $\\mathcal{A}$ acts on the spatial variable $x$, so we have:\n$$\n\\left(\\frac{\\partial}{\\partial s} + \\mathcal{A}\\right)f(s,y) = \\frac{\\partial}{\\partial s}\\left(\\exp(-\\lambda(s-t)) u(s,y)\\right) + \\mathcal{A}_y\\left(\\exp(-\\lambda(s-t)) u(s,y)\\right)\n$$\n$$\n= -\\lambda \\exp(-\\lambda(s-t)) u(s,y) + \\exp(-\\lambda(s-t)) \\frac{\\partial u}{\\partial s}(s,y) + \\exp(-\\lambda(s-t)) \\mathcal{A}_y u(s,y)\n$$\n$$\n= \\exp(-\\lambda(s-t)) \\left( \\frac{\\partial u}{\\partial s}(s,y) + \\mathcal{A}_y u(s,y) - \\lambda u(s,y) \\right)\n$$\nSince $u(s,y)$ is the solution to the given integro-differential equation, the term in the parenthesis is zero. Therefore, $\\left(\\frac{\\partial}{\\partial s} + \\mathcal{A}\\right)f(s,X_s) = 0$ for all $s \\in [t,T]$.\n\nThis simplifies Dynkin's formula to:\n$$\n\\mathbb{E}[f(T, X_T)] - f(t, X_t) = 0\n$$\nSubstituting back the definition of $f$ and noting $X_t=x$, we get:\n$$\nf(t,x) = \\mathbb{E}[f(T, X_T) | X_t = x]\n$$\n$$\n\\exp(-\\lambda(t-t)) u(t,x) = \\mathbb{E}[\\exp(-\\lambda(T-t)) u(T, X_T) | X_t = x]\n$$\nUsing the terminal condition $u(T,x) = g(x)$, we arrive at the Feynman-Kac representation for the solution:\n$$\nu(t,x) = \\exp(-\\lambda(T-t)) \\mathbb{E}[g(X_T) | X_t = x]\n$$\nGiven $g(x) = \\exp(\\beta x)$, the task reduces to computing the expectation:\n$$\nu(t,x) = \\exp(-\\lambda(T-t)) \\mathbb{E}[\\exp(\\beta X_T) | X_t = x]\n$$\nThe CPP is a process with stationary and independent increments. The evolution of the process from time $t$ to $T$ is equivalent in law to a process evolving over a time interval of duration $T-t$ starting from $X_t=x$. Thus, we can write $X_T$ as:\n$$\nX_T = x + \\sum_{i=1}^{N_{T-t}} J_i\n$$\nwhere $N_{T-t}$ is a Poisson random variable with parameter $\\eta(T-t)$. The sum is zero if $N_{T-t}=0$. We can now compute the expectation:\n$$\n\\mathbb{E}[\\exp(\\beta X_T) | X_t = x] = \\mathbb{E}\\left[\\exp\\left(\\beta \\left(x + \\sum_{i=1}^{N_{T-t}} J_i\\right)\\right)\\right] = \\exp(\\beta x) \\mathbb{E}\\left[\\exp\\left(\\beta \\sum_{i=1}^{N_{T-t}} J_i\\right)\\right]\n$$\nWe use the law of total expectation, conditioning on the number of jumps $N_{T-t}=k$:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\beta \\sum_{i=1}^{N_{T-t}} J_i\\right)\\right] = \\mathbb{E}_{N_{T-t}}\\left[ \\mathbb{E}\\left[ \\exp\\left(\\beta \\sum_{i=1}^{k} J_i\\right) \\bigg| N_{T-t}=k \\right] \\right]\n$$\nSince the jump sizes $\\{J_i\\}$ are independent and identically distributed, and independent of the Poisson process $\\{N_s\\}$, this becomes:\n$$\n\\mathbb{E}_{N_{T-t}}\\left[ \\prod_{i=1}^{k} \\mathbb{E}[\\exp(\\beta J_i)] \\bigg| N_{T-t}=k \\right] = \\mathbb{E}_{N_{T-t}}\\left[ (M_J(\\beta))^k \\bigg| N_{T-t}=k \\right]\n$$\nwhere $M_J(\\beta) = \\mathbb{E}[\\exp(\\beta J_1)]$ is the moment generating function (MGF) of a single jump $J_1$. The problem statement guarantees that this MGF is finite. The random variable is $N_{T-t}$, so the expectation is $\\mathbb{E}[(M_J(\\beta))^{N_{T-t}}]$.\n\nThis is the definition of the probability generating function (PGF) of $N_{T-t}$ evaluated at $z=M_J(\\beta)$. The PGF of a Poisson random variable $K$ with parameter $\\theta$ is $P_K(z) = \\mathbb{E}[z^K] = \\exp(\\theta(z-1))$. In our case, the random variable is $N_{T-t}$ with parameter $\\theta = \\eta(T-t)$. Therefore,\n$$\n\\mathbb{E}[(M_J(\\beta))^{N_{T-t}}] = \\exp\\left(\\eta(T-t) (M_J(\\beta)-1)\\right)\n$$\nNext, we compute the MGF $M_J(\\beta)$ for the given jump distribution $J_1 \\sim \\mathcal{N}(\\mu_J, \\sigma_J^2)$. The MGF of a normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is $\\exp(\\mu z + \\frac{1}{2}\\sigma^2 z^2)$. Thus,\n$$\nM_J(\\beta) = \\exp\\left(\\mu_J \\beta + \\frac{1}{2}\\sigma_J^2 \\beta^2\\right)\n$$\nSubstituting this into the expression for the expectation:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\beta \\sum_{i=1}^{N_{T-t}} J_i\\right)\\right] = \\exp\\left(\\eta(T-t) \\left(\\exp\\left(\\mu_J \\beta + \\frac{1}{2}\\sigma_J^2 \\beta^2\\right) - 1\\right)\\right)\n$$\nCombining all the pieces, we get the full expression for $u(t,x)$:\n$$\nu(t,x) = \\exp(-\\lambda(T-t)) \\cdot \\exp(\\beta x) \\cdot \\exp\\left(\\eta(T-t) \\left(\\exp\\left(\\mu_J \\beta + \\frac{1}{2}\\sigma_J^2 \\beta^2\\right) - 1\\right)\\right)\n$$\nWe can combine the exponents to obtain the final closed-form solution:\n$$\nu(t,x) = \\exp\\left(\\beta x - \\lambda(T-t) + \\eta(T-t) \\left(\\exp\\left(\\mu_J \\beta + \\frac{1}{2}\\sigma_J^2 \\beta^2\\right) - 1\\right)\\right)\n$$\nThis can be rewritten to group the terms multiplied by $(T-t)$:\n$$\nu(t,x) = \\exp\\left(\\beta x + (T-t)\\left( \\eta\\left(\\exp\\left(\\mu_J \\beta + \\frac{1}{2}\\sigma_J^2 \\beta^2\\right) - 1\\right) - \\lambda \\right)\\right)\n$$\nThis is the explicit solution for $u(t,x)$.", "answer": "$$\\boxed{\\exp\\left(\\beta x + (T-t)\\left(\\eta\\left(\\exp\\left(\\mu_J \\beta + \\frac{1}{2}\\sigma_J^2 \\beta^2\\right) - 1\\right) - \\lambda\\right)\\right)}$$", "id": "3001177"}, {"introduction": "Beyond simply finding solutions, the Feynman-Kac formula offers deep insights into the qualitative behavior of stochastic systems. This advanced exercise [@problem_id:3001112] delves into the connection between the long-term survival probability of a killed process and the spectral theory of its generator. By deriving the exponential decay rate of the survival functional, you will establish a concrete link to the spectral bound of the generator and the spectral radius of the semigroup, a sophisticated and powerful concept in the analysis of stochastic processes.", "problem": "Consider the one-dimensional Stochastic Differential Equation (SDE) $dX_{t} = dW_{t}$ for $t \\geq 0$, where $W_{t}$ is a standard Brownian motion and $X_{0} = x \\in (0,L)$ with $L>0$. Let $\\tau := \\inf\\{t \\geq 0 : X_{t} \\notin (0,L)\\}$ be the first exit time from the open interval $(0,L)$, so that the process is killed when it hits $0$ or $L$. Fix a constant potential $V(x) \\equiv \\lambda$ with $\\lambda > 0$, and define the survival functional\n$$\nu(t,x) := \\mathbb{E}^{x}\\!\\left[\\exp\\!\\left(-\\int_{0}^{t} V(X_{s})\\,ds\\right)\\mathbf{1}_{\\{t<\\tau\\}}\\right].\n$$\nThe family of linear operators $(T_{t})_{t \\geq 0}$ acting on $L^{2}(0,L)$ defined by\n$$\n(T_{t}f)(x) := \\mathbb{E}^{x}\\!\\left[\\exp\\!\\left(-\\int_{0}^{t} V(X_{s})\\,ds\\right) f(X_{t})\\,\\mathbf{1}_{\\{t<\\tau\\}}\\right]\n$$\nforms a strongly continuous positive contraction semigroup associated to the killed process and potential. Starting from the infinitesimal generator of the killed Brownian motion on $(0,L)$ with Dirichlet boundary conditions, and using Itô’s lemma together with core properties of the Markov semigroup, carry out the following:\n\n- Derive the initial-boundary value problem for the survival functional $u(t,x)$ as a parabolic Partial Differential Equation (PDE) on $(0,L)$.\n- Solve this PDE by separation of variables and eigenfunction expansion, expressing $u(t,x)$ as a series in the Dirichlet Laplacian eigenfunctions on $(0,L)$.\n- From your solution, extract the leading large-time exponential decay rate and identify it with the spectral bound of the generator of $(T_{t})_{t \\geq 0}$ acting on $L^{2}(0,L)$.\n- Use this identification to compute the spectral radius $r(T_{t})$ of the semigroup $(T_{t})_{t \\geq 0}$ in closed form for general $t>0$.\n\nYour final answer must be the explicit expression for $r(T_{t})$ as a function of $t$, $L$, and $\\lambda$. No rounding is required.", "solution": "The problem requires a multi-step analysis starting from a stochastic process, connecting it to a partial differential equation (PDE) via the Feynman-Kac formalism, solving the PDE, and finally using spectral theory to determine the spectral radius of the associated semigroup.\n\n### Step 1: Problem Validation\n\n**1.1. Extraction of Givens:**\n- Stochastic Differential Equation (SDE): $dX_{t} = dW_{t}$ for $t \\geq 0$.\n- $W_{t}$ is a standard Brownian motion.\n- Initial condition: $X_{0} = x \\in (0,L)$ with $L>0$.\n- First exit time: $\\tau := \\inf\\{t \\geq 0 : X_{t} \\notin (0,L)\\}$. The process is killed at the boundary.\n- Potential: $V(x) = \\lambda$, a positive constant ($\\lambda > 0$).\n- Survival functional: $u(t,x) := \\mathbb{E}^{x}\\!\\left[\\exp\\!\\left(-\\int_{0}^{t} V(X_{s})\\,ds\\right)\\mathbf{1}_{\\{t<\\tau\\}}\\right]$.\n- Semigroup: $(T_{t}f)(x) := \\mathbb{E}^{x}\\!\\left[\\exp\\!\\left(-\\int_{0}^{t} V(X_{s})\\,ds\\right) f(X_{t})\\,\\mathbf{1}_{\\{t<\\tau\\}}\\right]$.\n\n**1.2. Validation:**\n- **Scientific Grounding:** The problem is based on the well-established Feynman-Kac formula, which provides a rigorous connection between parabolic PDEs and expectations of functionals of stochastic processes. The use of semigroups and their generators is a cornerstone of modern analysis and its applications to differential equations. The problem is scientifically and mathematically sound.\n- **Well-Posedness:** The SDE for a standard Brownian motion, the definition of the exit time from a bounded interval, and the constant potential constitute a classic, well-posed problem setup in stochastic analysis. The questions asked lead to a unique and meaningful solution.\n- **Objectivity and Completeness:** The problem is stated using precise mathematical language and definitions. All necessary components (the SDE, domain, potential, and boundary behavior via killing) are specified, making the problem self-contained.\n\n**1.3. Verdict:**\nThe problem is valid as it is mathematically sound, well-posed, and complete.\n\n### Step 2: Derivation of the PDE for $u(t,x)$\n\nThe function $u(t,x)$ is given by $u(t,x) = (T_t \\mathbf{1})(x)$, where $\\mathbf{1}$ is the function equal to $1$ for all $x \\in (0,L)$. The family of operators $(T_t)_{t \\ge 0}$ forms a semigroup whose infinitesimal generator is $\\mathcal{A} = \\frac{1}{2}\\Delta - V(x)$, where $\\Delta = \\frac{d^2}{dx^2}$ is the Laplacian. The domain of $\\mathcal{A}$ incorporates Dirichlet boundary conditions due to the killing of the process at the boundaries of $(0,L)$. Therefore, $u(t,x)$ must satisfy the abstract Cauchy problem $\\frac{d}{dt} u(t, \\cdot) = \\mathcal{A} u(t, \\cdot)$, with initial condition $u(0, \\cdot) = \\mathbf{1}$.\n\nExplicitly, the PDE is:\n$$\n\\frac{\\partial u}{\\partial t}(t,x) = \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2}(t,x) - V(x)u(t,x)\n$$\nSince $V(x) = \\lambda$, this becomes:\n$$\n\\frac{\\partial u}{\\partial t} = \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2} - \\lambda u, \\quad \\text{for } t>0 \\text{ and } x \\in (0,L).\n$$\nThe boundary conditions are derived from the definition of the exit time $\\tau$. If the process starts at $x=0$ or $x=L$, the exit is immediate, so $\\tau=0$. For any $t>0$, the condition $t<\\tau$ is not met, making the indicator function $\\mathbf{1}_{\\{t<\\tau\\}}$ equal to $0$. Thus, we have Dirichlet boundary conditions:\n$$\nu(t,0) = 0 \\quad \\text{and} \\quad u(t,L) = 0 \\quad \\text{for } t>0.\n$$\nThe initial condition is found by setting $t=0$:\n$$\nu(0,x) = \\mathbb{E}^{x}\\!\\left[\\exp(0) \\cdot \\mathbf{1}_{\\{0<\\tau\\}}\\right] = \\mathbb{E}^{x}[\\mathbf{1}_{\\{0<\\tau\\}}].\n$$\nFor any starting point $x \\in (0,L)$, the time to exit $\\tau$ is strictly positive with probability $1$. Therefore, $\\mathbf{1}_{\\{0<\\tau\\}} = 1$, and the initial condition is:\n$$\nu(0,x) = 1 \\quad \\text{for } x \\in (0,L).\n$$\nThe initial-boundary value problem for $u(t,x)$ is therefore:\n$$\n\\begin{cases}\n\\frac{\\partial u}{\\partial t} = \\frac{1}{2}\\frac{\\partial^2 u}{\\partial x^2} - \\lambda u, & x \\in (0,L), t>0 \\\\\nu(t,0) = u(t,L) = 0, & t>0 \\\\\nu(0,x) = 1, & x \\in (0,L)\n\\end{cases}\n$$\n\n### Step 3: Solution of the PDE by Separation of Variables\n\nWe look for a solution of the form $u(t,x) = T(t)X(x)$. Substituting this into the PDE gives:\n$$\nT'(t)X(x) = \\frac{1}{2}T(t)X''(x) - \\lambda T(t)X(x).\n$$\nDividing by $T(t)X(x)$ separates the variables:\n$$\n\\frac{T'(t)}{T(t)} + \\lambda = \\frac{1}{2}\\frac{X''(x)}{X(x)} = -\\mu,\n$$\nwhere $-\\mu$ is the separation constant. This gives two ordinary differential equations:\n1. $T'(t) + (\\lambda+\\mu)T(t) = 0 \\implies T(t) = C e^{-(\\lambda+\\mu)t}$.\n2. $X''(x) + 2\\mu X(x) = 0$.\n\nThe boundary conditions $u(t,0)=u(t,L)=0$ imply $X(0)=0$ and $X(L)=0$. The Sturm-Liouville problem for $X(x)$ has non-trivial solutions only for $2\\mu > 0$. The general solution is $X(x) = A\\sin(\\sqrt{2\\mu}x) + B\\cos(\\sqrt{2\\mu}x)$.\n$X(0)=0 \\implies B=0$.\n$X(L)=0 \\implies A\\sin(\\sqrt{2\\mu}L) = 0$. For $A \\neq 0$, we need $\\sqrt{2\\mu}L = n\\pi$ for an integer $n \\ge 1$.\nThis quantizes the separation constant:\n$$\n\\sqrt{2\\mu_n} = \\frac{n\\pi}{L} \\implies \\mu_n = \\frac{n^2\\pi^2}{2L^2}, \\quad n=1, 2, 3, \\dots\n$$\nThe corresponding eigenfunctions are $X_n(x) = \\sin\\left(\\frac{n\\pi x}{L}\\right)$.\nThe general solution for $u(t,x)$ is a superposition of these modes:\n$$\nu(t,x) = \\sum_{n=1}^{\\infty} c_n e^{-(\\lambda+\\mu_n)t} X_n(x) = \\sum_{n=1}^{\\infty} c_n \\exp\\left(-\\left(\\lambda + \\frac{n^2\\pi^2}{2L^2}\\right)t\\right) \\sin\\left(\\frac{n\\pi x}{L}\\right).\n$$\nThe coefficients $c_n$ are determined by the initial condition $u(0,x)=1$:\n$$\n1 = \\sum_{n=1}^{\\infty} c_n \\sin\\left(\\frac{n\\pi x}{L}\\right).\n$$\nThis is the Fourier sine series of the constant function $f(x)=1$ on $(0,L)$. The coefficients are given by:\n$$\nc_n = \\frac{2}{L}\\int_0^L 1 \\cdot \\sin\\left(\\frac{n\\pi x}{L}\\right) dx = \\frac{2}{L} \\left[-\\frac{L}{n\\pi}\\cos\\left(\\frac{n\\pi x}{L}\\right)\\right]_0^L = -\\frac{2}{n\\pi}(\\cos(n\\pi) - 1) = \\frac{2(1 - (-1)^n)}{n\\pi}.\n$$\nIf $n$ is even, $c_n=0$. If $n$ is odd, $n=2k+1$ for $k=0,1,2,\\dots$, then $c_{2k+1} = \\frac{2(1 - (-1))}{ (2k+1)\\pi} = \\frac{4}{(2k+1)\\pi}$.\nThe full solution is:\n$$\nu(t,x) = \\sum_{k=0}^{\\infty} \\frac{4}{(2k+1)\\pi} \\exp\\left(-\\left(\\lambda + \\frac{(2k+1)^2\\pi^2}{2L^2}\\right)t\\right) \\sin\\left(\\frac{(2k+1)\\pi x}{L}\\right).\n$$\n\n### Step 4: Large-Time Decay and Spectral Identification\n\nFor large $t$, the sum is dominated by the term with the slowest exponential decay rate. The decay exponents are $\\lambda + \\frac{n^2\\pi^2}{2L^2}$. Since $\\lambda > 0$, all exponents are positive. The smallest exponent corresponds to the smallest value of $n$, which is $n=1$.\nThe leading large-time decay rate is thus:\n$$\n\\alpha = \\lambda + \\frac{\\pi^2}{2L^2}.\n$$\nAs $t \\to \\infty$, $u(t,x) \\sim \\frac{4}{\\pi} e^{-\\alpha t} \\sin\\left(\\frac{\\pi x}{L}\\right)$.\n\nThe generator of the semigroup $(T_t)_{t \\ge 0}$ is $\\mathcal{A} = \\frac{1}{2}\\frac{d^2}{dx^2} - \\lambda$ with domain $D(\\mathcal{A}) = H^2(0,L) \\cap H_0^1(0,L)$, where $H_0^1$ implies Dirichlet boundary conditions. The operator $\\mathcal{A}$ is self-adjoint. Its spectrum $\\sigma(\\mathcal{A})$ consists of its eigenvalues. The eigenvalues of the Dirichlet Laplacian $\\frac{d^2}{dx^2}$ on $(0,L)$ are $-\\frac{n^2\\pi^2}{L^2}$ for $n=1,2,\\dots$.\nThus, the eigenvalues of $\\mathcal{A}$ are:\n$$\n\\nu_n = -\\frac{1}{2}\\frac{n^2\\pi^2}{L^2} - \\lambda, \\quad n=1, 2, 3, \\dots\n$$\nThe spectral bound of $\\mathcal{A}$ is defined as $s(\\mathcal{A}) = \\sup\\{\\text{Re}(\\nu) : \\nu \\in \\sigma(\\mathcal{A})\\}$. Since all eigenvalues are real, this is the largest eigenvalue:\n$$\ns(\\mathcal{A}) = \\sup_{n \\ge 1} \\left(-\\frac{n^2\\pi^2}{2L^2} - \\lambda\\right) = -\\frac{\\pi^2}{2L^2} - \\lambda.\n$$\nThe long-time behavior of the semigroup is governed by the spectral bound, such that for large $t$, $\\|T_t\\| \\sim e^{s(\\mathcal{A})t}$. The exponential decay rate of solutions to $\\frac{du}{dt}=\\mathcal{A}u$ is $-s(\\mathcal{A})$.\nIn our case, the decay rate is $-s(\\mathcal{A}) = -(-\\frac{\\pi^2}{2L^2} - \\lambda) = \\frac{\\pi^2}{2L^2} + \\lambda$.\nThis precisely matches the decay rate $\\alpha$ we found from the explicit PDE solution.\n\n### Step 5: Spectral Radius of the Semigroup $T_t$\n\nFor a semigroup generated by a self-adjoint operator $\\mathcal{A}$, the spectral mapping theorem states that the spectrum of the operator $T_t = e^{t\\mathcal{A}}$ is given by $\\sigma(T_t) = e^{t\\sigma(\\mathcal{A})}$.\nThus, the spectrum of $T_t$ is the set of values:\n$$\n\\sigma(T_t) = \\left\\{ \\exp(t\\nu_n) \\right\\}_{n=1}^{\\infty} = \\left\\{ \\exp\\left(t\\left(-\\frac{n^2\\pi^2}{2L^2} - \\lambda\\right)\\right) \\right\\}_{n=1}^{\\infty}.\n$$\nThe spectral radius $r(T_t)$ is the supremum of the absolute values of the elements in the spectrum:\n$$\nr(T_t) = \\sup_{\\zeta \\in \\sigma(T_t)} |\\zeta|.\n$$\nSince $t>0$, $\\lambda>0$, and $n \\ge 1$, all eigenvalues $\\nu_n$ of $\\mathcal{A}$ are real and negative. Therefore, their exponentials $e^{t\\nu_n}$ are real, positive, and less than $1$.\nThe spectral radius is simply the largest value in the spectrum of $T_t$:\n$$\nr(T_t) = \\sup_{n \\ge 1} \\left\\{ \\exp(t\\nu_n) \\right\\} = \\exp\\left(t \\cdot \\sup_{n \\ge 1} \\{\\nu_n\\}\\right) = \\exp(t \\cdot s(\\mathcal{A})).\n$$\nSubstituting the value of the spectral bound $s(\\mathcal{A})$:\n$$\nr(T_t) = \\exp\\left(t\\left(-\\frac{\\pi^2}{2L^2} - \\lambda\\right)\\right) = \\exp\\left(-\\left(\\lambda + \\frac{\\pi^2}{2L^2}\\right)t\\right).\n$$\nThis is the closed-form expression for the spectral radius of the semigroup operator $T_t$.", "answer": "$$\n\\boxed{\\exp\\left(-\\left(\\lambda + \\frac{\\pi^2}{2L^2}\\right)t\\right)}\n$$", "id": "3001112"}]}