{"hands_on_practices": [{"introduction": "The theoretical construction of the Itô integral begins by defining it for simple, step-function-like processes and then extending it to a much larger class of integrands through a limit procedure. This exercise provides a hands-on walkthrough of this fundamental construction. By approximating a continuous, deterministic function with a sequence of simple predictable processes, you will see how the corresponding sequence of integrals converges in the $L^2$ sense, making the abstract machinery of the theory concrete [@problem_id:2971978].", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\in[0,1]},\\mathbb{P})$ be a filtered probability space supporting a standard Brownian motion $(W_{t})_{t\\in[0,1]}$, where $(\\mathcal{F}_{t})_{t\\in[0,1]}$ is the usual augmentation of the natural filtration of $(W_{t})_{t\\in[0,1]}$. Consider the bounded predictable process $H:[0,1]\\times\\Omega\\to\\mathbb{R}$ given by $H(t,\\omega)=h(t)$, where $h(t)=\\min(t,1/2)$ for $t\\in[0,1]$. Using the construction of the Itô integral on the square-integrable space $L^{2}(\\Omega\\times[0,1])$, perform the following steps from first principles:\n\n1. Define a sequence $(H^{(n)})_{n\\in\\mathbb{N}}$ of simple predictable processes that approximates $H$ in $L^{2}(\\Omega\\times[0,1])$. Each $H^{(n)}$ must be of the form $H^{(n)}(t,\\omega)=\\sum_{k=0}^{n-1}\\xi_{k}^{(n)}(\\omega)\\,\\mathbf{1}_{(t_{k}^{(n)},t_{k+1}^{(n)}]}(t)$ for a partition $0=t_{0}^{(n)}<t_{1}^{(n)}<\\cdots<t_{n}^{(n)}=1$, with $\\xi_{k}^{(n)}$ being $\\mathcal{F}_{t_{k}^{(n)}}$-measurable.\n\n2. For each $n\\in\\mathbb{N}$, express the Itô integral $\\int_{0}^{1}H^{(n)}(t,\\omega)\\,\\mathrm{d}W_{t}(\\omega)$ explicitly as a finite sum of Brownian increments.\n\n3. Using only the independence and variance properties of Brownian motion increments (i.e., for $0\\leq s<t\\leq 1$, $W_{t}-W_{s}$ is centered normal with variance $t-s$ and independent of $\\mathcal{F}_{s}$), compute $\\mathbb{E}\\big[\\,\\big|\\int_{0}^{1}H^{(n)}(t)\\,\\mathrm{d}W_{t}\\big|^{2}\\,\\big]$ in terms of the partition and $\\xi_{k}^{(n)}$.\n\n4. Show that $\\big(\\int_{0}^{1}H^{(n)}(t)\\,\\mathrm{d}W_{t}\\big)_{n\\in\\mathbb{N}}$ is a Cauchy sequence in $L^{2}(\\Omega)$ and that its limit defines $\\int_{0}^{1}H(t)\\,\\mathrm{d}W_{t}$ via closure of the Itô integral on $L^{2}(\\Omega\\times[0,1])$.\n\n5. Compute the exact value of the limit $\\lim_{n\\to\\infty}\\mathbb{E}\\big[\\,\\big|\\int_{0}^{1}H^{(n)}(t)\\,\\mathrm{d}W_{t}\\big|^{2}\\,\\big]$, which equals $\\mathbb{E}\\big[\\,\\big|\\int_{0}^{1}H(t)\\,\\mathrm{d}W_{t}\\big|^{2}\\,\\big]$.\n\nProvide your final answer as a single exact number. No rounding is required.", "solution": "The problem is well-defined and mathematically sound. It provides a complete and consistent setup for constructing a specific Itô integral from first principles. The process follows the standard procedure for extending the Itô integral from simple predictable processes to the space $L^{2}(\\Omega\\times[0,1])$. All premises are based on established theorems in stochastic calculus. We proceed with the solution by following the five steps prescribed.\n\nThe process to be integrated is $H(t, \\omega) = h(t) = \\min(t, 1/2)$ for $t \\in [0,1]$. Since $H$ is deterministic and continuous, it is a bounded predictable process and belongs to the space $L^{2}(\\Omega\\times[0,1])$.\n\n**1. Definition of the Approximating Sequence**\n\nWe define a sequence of simple predictable processes $(H^{(n)})_{n\\in\\mathbb{N}}$ that approximates $H$. For each $n \\in \\mathbb{N}$, we consider a uniform partition of the interval $[0,1]$:\n$$0 = t_{0}^{(n)} < t_{1}^{(n)} < \\cdots < t_{n}^{(n)} = 1$$\nwhere $t_{k}^{(n)} = k/n$ for $k \\in \\{0, 1, \\dots, n\\}$.\n\nWe define the simple process $H^{(n)}$ by sampling the deterministic function $h(t)$ at the left endpoint of each subinterval:\n$$H^{(n)}(t, \\omega) = \\sum_{k=0}^{n-1} h(t_{k}^{(n)}) \\mathbf{1}_{(t_{k}^{(n)}, t_{k+1}^{(n)}]}(t)$$\nwhere $\\mathbf{1}_{A}$ is the indicator function of a set $A$. Substituting the definitions of $h$ and $t_k^{(n)}$, we get:\n$$H^{(n)}(t, \\omega) = \\sum_{k=0}^{n-1} \\min\\left(\\frac{k}{n}, \\frac{1}{2}\\right) \\mathbf{1}_{(\\frac{k}{n}, \\frac{k+1}{n}]}(t)$$\nFor each $k$, the coefficient $\\xi_{k}^{(n)} = \\min(k/n, 1/2)$ is a constant, and thus is trivially $\\mathcal{F}_{t_{k}^{(n)}}$-measurable. Hence, each $H^{(n)}$ is a simple predictable process.\n\nThis sequence converges to $H$ in $L^{2}(\\Omega\\times[0,1])$. The squared norm of the difference is:\n$$\\mathbb{E}\\left[\\int_{0}^{1} (H^{(n)}(t) - H(t))^{2} \\,\\mathrm{d}t\\right] = \\int_{0}^{1} \\left(\\sum_{k=0}^{n-1} h\\left(\\frac{k}{n}\\right) \\mathbf{1}_{(\\frac{k}{n}, \\frac{k+1}{n}]}(t) - h(t)\\right)^{2} \\,\\mathrm{d}t$$\nSince $h(t)$ is a continuous function on $[0,1]$, the step-function approximation $H^{(n)}$ converges to $H$ in $L^{2}([0,1])$. The integral converges to $0$ as $n \\to \\infty$, confirming that $H^{(n)} \\to H$ in $L^{2}(\\Omega\\times[0,1])$.\n\n**2. Itô Integral of the Simple Process**\n\nBy the definition of the Itô integral for a simple process, the integral of $H^{(n)}$ is given by:\n$$\\int_{0}^{1} H^{(n)}(t, \\omega) \\,\\mathrm{d}W_{t}(\\omega) = \\sum_{k=0}^{n-1} h(t_{k}^{(n)}) \\left(W_{t_{k+1}^{(n)}} - W_{t_{k}^{(n)}}\\right)$$\nSubstituting the specific forms of $h$ and the partition points:\n$$\\int_{0}^{1} H^{(n)}(t, \\omega) \\,\\mathrm{d}W_{t}(\\omega) = \\sum_{k=0}^{n-1} \\min\\left(\\frac{k}{n}, \\frac{1}{2}\\right) \\left(W_{(k+1)/n} - W_{k/n}\\right)$$\nThis is a finite sum of random variables, where each term consists of a constant coefficient multiplying an increment of the Brownian motion.\n\n**3. Expectation of the Squared Integral of $H^{(n)}$**\n\nWe compute the expectation of the squared Itô integral of $H^{(n)}$. Let $I(H^{(n)}) = \\int_{0}^{1} H^{(n)}(t) \\,\\mathrm{d}W_{t}$.\n$$\\mathbb{E}\\left[ \\left|I(H^{(n)})\\right|^{2} \\right] = \\mathbb{E}\\left[ \\left( \\sum_{k=0}^{n-1} h(t_{k}^{(n)}) (W_{t_{k+1}^{(n)}} - W_{t_{k}^{(n)}}) \\right)^{2} \\right]$$\nLet $\\Delta W_k^{(n)} = W_{t_{k+1}^{(n)}} - W_{t_k^{(n)}}$ and $h_k^{(n)} = h(t_{k}^{(n)})$. The expression becomes:\n$$\\mathbb{E}\\left[ \\left(\\sum_{k=0}^{n-1} h_k^{(n)} \\Delta W_k^{(n)}\\right) \\left(\\sum_{j=0}^{n-1} h_j^{(n)} \\Delta W_j^{(n)}\\right) \\right] = \\sum_{j,k=0}^{n-1} h_j^{(n)} h_k^{(n)} \\mathbb{E}\\left[ \\Delta W_j^{(n)} \\Delta W_k^{(n)} \\right]$$\nWe use the properties of Brownian motion increments:\n- For $j \\neq k$, say $j < k$, the intervals $(t_j^{(n)}, t_{j+1}^{(n)}]$ and $(t_k^{(n)}, t_{k+1}^{(n)}]$ are disjoint. The increment $\\Delta W_k^{(n)}$ is independent of the filtration $\\mathcal{F}_{t_k^{(n)}}$. Since $t_{j+1}^{(n)} \\le t_k^{(n)}$, $\\Delta W_j^{(n)}$ is $\\mathcal{F}_{t_{j+1}^{(n)}}$-measurable, and thus $\\mathcal{F}_{t_k^{(n)}}$-measurable. Therefore, $\\Delta W_j^{(n)}$ and $\\Delta W_k^{(n)}$ are independent.\n- All increments are centered, i.e., $\\mathbb{E}[\\Delta W_i^{(n)}] = 0$.\nSo, for $j \\neq k$, $\\mathbb{E}[\\Delta W_j^{(n)} \\Delta W_k^{(n)}] = \\mathbb{E}[\\Delta W_j^{(n)}] \\mathbb{E}[\\Delta W_k^{(n)}] = 0 \\cdot 0 = 0$.\n\nThe sum simplifies to the terms where $j=k$:\n$$\\mathbb{E}\\left[ |I(H^{(n)})|^2 \\right] = \\sum_{k=0}^{n-1} (h_k^{(n)})^2 \\mathbb{E}\\left[ (\\Delta W_k^{(n)})^2 \\right]$$\nThe variance of a Brownian increment is $\\mathbb{E}[(\\Delta W_k^{(n)})^2] = \\text{Var}(W_{t_{k+1}^{(n)}} - W_{t_k^{(n)}}) = t_{k+1}^{(n)} - t_k^{(n)}$.\nThis yields the Itô isometry for simple processes:\n$$\\mathbb{E}\\left[ \\left|\\int_{0}^{1} H^{(n)}(t)\\,\\mathrm{d}W_{t}\\right|^{2} \\right] = \\sum_{k=0}^{n-1} h(t_{k}^{(n)})^{2} (t_{k+1}^{(n)} - t_{k}^{(n)})$$\nSubstituting our specific choices:\n$$\\mathbb{E}\\left[ \\left|\\int_{0}^{1} H^{(n)}(t)\\,\\mathrm{d}W_{t}\\right|^{2} \\right] = \\sum_{k=0}^{n-1} \\left(\\min\\left(\\frac{k}{n}, \\frac{1}{2}\\right)\\right)^{2} \\left(\\frac{1}{n}\\right)$$\n\n**4. The Cauchy Sequence Argument**\n\nThe construction of the Itô integral for a general process $H \\in L^{2}(\\Omega \\times [0,1])$ relies on showing that for any sequence $(H^{(n)})_{n\\in\\mathbb{N}}$ of simple predictable processes converging to $H$ in $L^{2}(\\Omega\\times[0,1])$, the sequence of integrals $(I(H^{(n)}))_{n\\in\\mathbb{N}}$ is a Cauchy sequence in $L^{2}(\\Omega)$.\nBy linearity of the Itô integral for simple processes, $I(H^{(n)}) - I(H^{(m)}) = I(H^{(n)} - H^{(m)})$. Since $H^{(n)} - H^{(m)}$ is also a simple predictable process, we can apply the Itô isometry:\n$$ \\| I(H^{(n)}) - I(H^{(m)}) \\|_{L^2(\\Omega)}^{2} = \\mathbb{E}\\left[|I(H^{(n)})-I(H^{(m)})|^2\\right] = \\mathbb{E}\\left[\\left|I(H^{(n)}-H^{(m)})\\right|^2\\right] $$\n$$ = \\mathbb{E}\\left[\\int_0^1 (H^{(n)}(t) - H^{(m)}(t))^2 \\,\\mathrm{d}t\\right] = \\|H^{(n)} - H^{(m)}\\|_{L^2(\\Omega \\times [0,1])}^2 $$\nAs established in step 1, the sequence $(H^{(n)})_{n\\in\\mathbb{N}}$ converges to $H$ in $L^{2}(\\Omega \\times [0,1])$. A convergent sequence in a normed space is a Cauchy sequence. Thus, for any $\\epsilon > 0$, there exists an $N$ such that for all $n,m > N$, $\\|H^{(n)} - H^{(m)}\\|_{L^2(\\Omega \\times [0,1])} < \\epsilon$.\nFrom the isometry, this implies $\\|I(H^{(n)}) - I(H^{(m)})\\|_{L^2(\\Omega)} < \\epsilon$ for all $n,m > N$. Therefore, the sequence of integrals $(I(H^{(n)}))_{n\\in\\mathbb{N}}$ is a Cauchy sequence in the space $L^{2}(\\Omega)$.\nSince $L^{2}(\\Omega)$ is a complete space (a Hilbert space), this Cauchy sequence converges to a limit. This limit is defined as the Itô integral of $H$, denoted $\\int_{0}^{1} H(t)\\,\\mathrm{d}W_{t}$. The definition is independent of the choice of approximating sequence.\n\n**5. Computation of the Limit**\n\nWe now compute the exact value of the limit of the expectation found in step 3. The Itô isometry extends by continuity to all processes in $L^{2}(\\Omega\\times[0,1])$. Therefore,\n$$\\mathbb{E}\\left[\\left|\\int_{0}^{1} H(t)\\,\\mathrm{d}W_{t}\\right|^{2}\\right] = \\lim_{n\\to\\infty} \\mathbb{E}\\left[\\left|\\int_{0}^{1} H^{(n)}(t)\\,\\mathrm{d}W_{t}\\right|^{2}\\right] = \\mathbb{E}\\left[\\int_0^1 H(t)^2 \\,\\mathrm{d}t\\right]$$\nSince $H(t)$ is deterministic, this simplifies to:\n$$\\mathbb{E}\\left[\\left|\\int_{0}^{1} H(t)\\,\\mathrm{d}W_{t}\\right|^{2}\\right] = \\int_0^1 H(t)^2 \\,\\mathrm{d}t = \\int_0^1 \\left(\\min\\left(t, \\frac{1}{2}\\right)\\right)^2 \\,\\mathrm{d}t$$\nThe term we are asked to compute is this limit. The sum derived in step 3 is a Riemann sum for this integral:\n$$\\lim_{n\\to\\infty} \\sum_{k=0}^{n-1} \\left(\\min\\left(\\frac{k}{n}, \\frac{1}{2}\\right)\\right)^{2} \\frac{1}{n} = \\int_{0}^{1} \\left(\\min\\left(t, \\frac{1}{2}\\right)\\right)^{2} \\,\\mathrm{d}t$$\nWe split the integral based on the definition of the $\\min$ function:\n$$\\int_{0}^{1} \\left(\\min\\left(t, \\frac{1}{2}\\right)\\right)^{2} \\,\\mathrm{d}t = \\int_{0}^{1/2} t^{2} \\,\\mathrm{d}t + \\int_{1/2}^{1} \\left(\\frac{1}{2}\\right)^{2} \\,\\mathrm{d}t$$\nWe evaluate each integral separately:\n$$\\int_{0}^{1/2} t^{2} \\,\\mathrm{d}t = \\left[ \\frac{t^{3}}{3} \\right]_{0}^{1/2} = \\frac{(1/2)^{3}}{3} - 0 = \\frac{1/8}{3} = \\frac{1}{24}$$\n$$\\int_{1/2}^{1} \\left(\\frac{1}{2}\\right)^{2} \\,\\mathrm{d}t = \\int_{1/2}^{1} \\frac{1}{4} \\,\\mathrm{d}t = \\frac{1}{4} [t]_{1/2}^{1} = \\frac{1}{4} \\left(1 - \\frac{1}{2}\\right) = \\frac{1}{4} \\cdot \\frac{1}{2} = \\frac{1}{8}$$\nThe total value is the sum of these two results:\n$$\\frac{1}{24} + \\frac{1}{8} = \\frac{1}{24} + \\frac{3}{24} = \\frac{4}{24} = \\frac{1}{6}$$\nThus, the value of the limit is $1/6$.", "answer": "$$\n\\boxed{\\frac{1}{6}}\n$$", "id": "2971978"}, {"introduction": "The convergence at the heart of the Itô integral's construction is guaranteed by a cornerstone of stochastic calculus: the Itô isometry. This powerful identity establishes a direct link between the squared $L^2$-norm of the stochastic integral and the squared $L^2$-norm of its integrand. This practice guides you through the derivation of the isometry for simple processes and its extension to the full space $\\mathcal{H}^2$, before applying it to compute the variance of an integral and bound its tail probability [@problem_id:2971985].", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t \\in [0,T]},\\mathbb{P})$ satisfying the usual conditions and carrying a standard Brownian motion $W=(W_{t})_{t \\in [0,T]}$. Let $\\mathcal{H}^{2}$ denote the space of predictable processes $H=(H_{t})_{t \\in [0,T]}$ such that $\\mathbb{E}\\!\\left[\\int_{0}^{T} H_{t}^{2}\\,dt\\right]<\\infty$. The Itô integral is constructed on $\\mathcal{H}^{2}$ by first defining it on simple predictable processes and then extending by continuity.\n\nStarting from the foundational properties of Brownian motion (independent increments, Gaussian increments with mean $0$ and variance $t$, and the tower property of conditional expectation), do the following:\n\n- For a simple predictable process $H_{t}=\\sum_{k=1}^{n}\\xi_{k}\\,\\mathbf{1}_{(t_{k-1},t_{k}]}(t)$ with $0=t_{0}<t_{1}<\\cdots<t_{n}=T$ and each $\\xi_{k}$ being $\\mathcal{F}_{t_{k-1}}$-measurable and square-integrable, use the definition $\\int_{0}^{T} H_{t}\\,dW_{t}:=\\sum_{k=1}^{n}\\xi_{k}\\big(W_{t_{k}}-W_{t_{k-1}}\\big)$ to derive an explicit formula for the $L^{2}$-norm of $\\int_{0}^{T} H_{t}\\,dW_{t}$ in terms of $\\mathbb{E}\\!\\left[\\int_{0}^{T} H_{t}^{2}\\,dt\\right]$.\n\n- Explain how this identity extends from simple predictable processes to all of $\\mathcal{H}^{2}$ via density and continuity arguments.\n\n- Let $h(t):=\\sin(\\omega t)$ for fixed $\\omega>0$, and consider the Itô integral $X:=\\int_{0}^{T} h(t)\\,dW_{t}$. Using only the preceding construction and consequences, provide the explicit closed-form expression for the Chebyshev upper bound of the tail probability $B(\\omega,T,r)$ defined by $B(\\omega,T,r):=\\frac{\\mathbb{E}[X^{2}]}{r^{2}}$ for an arbitrary threshold $r>0$. Your final answer must be the single analytic expression for $B(\\omega,T,r)$ in terms of $\\omega$, $T$, and $r$.", "solution": "The problem is valid as it constitutes a standard, well-posed exercise in the theory of stochastic calculus, resting on established mathematical principles and definitions. All provided information is self-contained and consistent.\n\nThe problem is addressed in three parts as requested: derivation of the Itô isometry for simple processes, extension to the space $\\mathcal{H}^2$, and application to a specific deterministic integrand to find a Chebyshev bound.\n\nPart 1: Derivation of the Itô Isometry for Simple Predictable Processes\n\nLet $H_t$ be a simple predictable process defined as $H_{t}=\\sum_{k=1}^{n}\\xi_{k}\\,\\mathbf{1}_{(t_{k-1},t_{k}]}(t)$, where $0=t_{0}<t_{1}<\\cdots<t_{n}=T$ is a partition of $[0,T]$, and each $\\xi_k$ is a square-integrable, $\\mathcal{F}_{t_{k-1}}$-measurable random variable. The Itô integral for $H_t$ is defined as $I(H) := \\int_{0}^{T} H_{t}\\,dW_{t} = \\sum_{k=1}^{n}\\xi_{k}(W_{t_{k}}-W_{t_{k-1}})$. Let $\\Delta W_k = W_{t_k} - W_{t_{k-1}}$. We want to compute the squared $L^2$-norm of $I(H)$, which is $\\mathbb{E}[I(H)^2]$.\n\n$$\n\\mathbb{E}\\left[I(H)^{2}\\right] = \\mathbb{E}\\left[\\left(\\sum_{k=1}^{n}\\xi_{k}\\,\\Delta W_{k}\\right)^{2}\\right] = \\mathbb{E}\\left[\\sum_{k=1}^{n}\\sum_{j=1}^{n}\\xi_{k}\\xi_{j}\\,\\Delta W_{k}\\Delta W_{j}\\right]\n$$\n\nBy linearity of expectation, we can write this as:\n$$\n\\mathbb{E}\\left[I(H)^{2}\\right] = \\sum_{k=1}^{n}\\sum_{j=1}^{n}\\mathbb{E}\\left[\\xi_{k}\\xi_{j}\\,\\Delta W_{k}\\Delta W_{j}\\right]\n$$\n\nWe analyze the terms in the sum based on the indices $j$ and $k$.\n\nCase 1: $j > k$.\nWe use the tower property of conditional expectation, conditioning on $\\mathcal{F}_{t_{j-1}}$.\n$$\n\\mathbb{E}\\left[\\xi_{k}\\xi_{j}\\,\\Delta W_{k}\\Delta W_{j}\\right] = \\mathbb{E}\\left[\\mathbb{E}\\left[\\xi_{k}\\xi_{j}\\,\\Delta W_{k}\\Delta W_{j}\\,|\\,\\mathcal{F}_{t_{j-1}}\\right]\\right]\n$$\nSince $k < j$, we have $t_k \\le t_{j-1}$. By definition, $\\xi_k$ is $\\mathcal{F}_{t_{k-1}}$-measurable, $\\Delta W_k = W_{t_k} - W_{t_{k-1}}$ is $\\mathcal{F}_{t_k}$-measurable, and $\\xi_j$ is $\\mathcal{F}_{t_{j-1}}$-measurable. Thus, $\\xi_k$, $\\xi_j$, and $\\Delta W_k$ are all $\\mathcal{F}_{t_{j-1}}$-measurable. We can pull them out of the inner conditional expectation:\n$$\n\\mathbb{E}\\left[\\xi_{k}\\xi_{j}\\,\\Delta W_{k}\\,\\mathbb{E}\\left[\\Delta W_{j}\\,|\\,\\mathcal{F}_{t_{j-1}}\\right]\\right]\n$$\nThe increment $\\Delta W_j = W_{t_j} - W_{t_{j-1}}$ is independent of the filtration $\\mathcal{F}_{t_{j-1}}$. Therefore, $\\mathbb{E}[\\Delta W_j | \\mathcal{F}_{t_{j-1}}] = \\mathbb{E}[\\Delta W_j]$. Since Brownian motion has zero-mean increments, $\\mathbb{E}[\\Delta W_j] = 0$. Consequently, for any $j>k$, the term is $0$.\n\nCase 2: $k > j$.\nBy a symmetric argument, these terms are also $0$.\n\nCase 3: $j = k$.\nThe sum reduces to the diagonal terms:\n$$\n\\mathbb{E}\\left[I(H)^{2}\\right] = \\sum_{k=1}^{n}\\mathbb{E}\\left[\\xi_{k}^{2}\\,(\\Delta W_{k})^{2}\\right]\n$$\nAgain, using the tower property, we condition on $\\mathcal{F}_{t_{k-1}}$:\n$$\n\\mathbb{E}\\left[\\xi_{k}^{2}\\,(\\Delta W_{k})^{2}\\right] = \\mathbb{E}\\left[\\mathbb{E}\\left[\\xi_{k}^{2}\\,(\\Delta W_{k})^{2}\\,|\\,\\mathcal{F}_{t_{k-1}}\\right]\\right]\n$$\nThe random variable $\\xi_k$ is $\\mathcal{F}_{t_{k-1}}$-measurable, so we can factor it out:\n$$\n\\mathbb{E}\\left[\\xi_{k}^{2}\\,\\mathbb{E}\\left[(\\Delta W_{k})^{2}\\,|\\,\\mathcal{F}_{t_{k-1}}\\right]\\right]\n$$\nThe increment $\\Delta W_k = W_{t_k} - W_{t_{k-1}}$ is independent of $\\mathcal{F}_{t_{k-1}}$, so $\\mathbb{E}[(\\Delta W_k)^2 | \\mathcal{F}_{t_{k-1}}] = \\mathbb{E}[(\\Delta W_k)^2]$, which is the variance of the increment, given by $\\text{Var}(W_{t_k}-W_{t_{k-1}}) = t_k - t_{k-1}$.\nSubstituting this back, the term becomes $\\mathbb{E}[\\xi_k^2 (t_k - t_{k-1})]$.\nSumming over $k$, we get:\n$$\n\\mathbb{E}\\left[I(H)^{2}\\right] = \\sum_{k=1}^{n}\\mathbb{E}\\left[\\xi_{k}^{2}\\,(t_k - t_{k-1})\\right] = \\sum_{k=1}^{n}\\mathbb{E}\\left[\\xi_{k}^{2}\\right](t_k - t_{k-1})\n$$\n\nNow we compute the quantity $\\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\,dt\\right]$. For our simple process, $H_t^2 = \\sum_{k=1}^n \\xi_k^2 \\mathbf{1}_{(t_{k-1}, t_k]}(t)$.\n$$\n\\int_{0}^{T} H_{t}^{2}\\,dt = \\int_{0}^{T} \\sum_{k=1}^{n} \\xi_{k}^{2}\\,\\mathbf{1}_{(t_{k-1},t_{k}]}(t)\\,dt = \\sum_{k=1}^{n} \\xi_{k}^{2} \\int_{t_{k-1}}^{t_{k}} dt = \\sum_{k=1}^{n} \\xi_{k}^{2}\\,(t_k - t_{k-1})\n$$\nTaking the expectation and using its linearity:\n$$\n\\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\,dt\\right] = \\mathbb{E}\\left[\\sum_{k=1}^{n} \\xi_{k}^{2}\\,(t_k - t_{k-1})\\right] = \\sum_{k=1}^{n} \\mathbb{E}\\left[\\xi_{k}^{2}\\right](t_k - t_{k-1})\n$$\nAlternatively, by Fubini's theorem (since the integrand is non-negative):\n$$\n\\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\,dt\\right] = \\int_{0}^{T} \\mathbb{E}\\left[H_{t}^{2}\\right]\\,dt = \\sum_{k=1}^{n} \\int_{t_{k-1}}^{t_{k}} \\mathbb{E}\\left[\\xi_{k}^{2}\\right]\\,dt = \\sum_{k=1}^{n} \\mathbb{E}\\left[\\xi_{k}^{2}\\right](t_k - t_{k-1})\n$$\nComparing the two results, we have established the Itô isometry for simple predictable processes:\n$$\n\\mathbb{E}\\left[\\left(\\int_{0}^{T} H_{t}\\,dW_{t}\\right)^{2}\\right] = \\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\,dt\\right]\n$$\nThis means the squared $L^2(\\Omega)$-norm of the stochastic integral equals the squared norm of the integrand in the space $\\mathcal{H}^2$.\n\nPart 2: Extension to $\\mathcal{H}^2$\n\nThe extension of the Itô integral and its isometry property from the space of simple predictable processes (let's denote it $\\mathcal{S}$) to the full space $\\mathcal{H}^2$ is a standard construction based on a density argument.\n1. It is a fundamental result that the space $\\mathcal{S}$ of simple predictable processes is a dense subspace of the Hilbert space $\\mathcal{H}^2$ with the norm $\\|H\\|_{\\mathcal{H}^2} = \\sqrt{\\mathbb{E}[\\int_0^T H_t^2 dt]}$. This means for any $H \\in \\mathcal{H}^2$, there exists a sequence of simple processes $\\{H_n\\}_{n\\geq 1} \\subset \\mathcal{S}$ such that $H_n \\to H$ in $\\mathcal{H}^2$, i.e., $\\lim_{n \\to \\infty} \\|H_n - H\\|_{\\mathcal{H}^2} = 0$.\n2. The Itô integration map $I: \\mathcal{S} \\to L^2(\\Omega, \\mathcal{F}_T, \\mathbb{P})$, defined by $I(H) = \\int_0^T H_t dW_t$, is an isometry, as derived in Part 1. This means $\\|I(H_n) - I(H_m)\\|_{L^2(\\Omega)} = \\|H_n - H_m\\|_{\\mathcal{H}^2}$ for any $H_n, H_m \\in \\mathcal{S}$.\n3. If $\\{H_n\\}$ is a sequence in $\\mathcal{S}$ converging to $H \\in \\mathcal{H}^2$, it is a Cauchy sequence in $\\mathcal{H}^2$. Because $I$ is an isometry, the sequence of integrals $\\{I(H_n)\\}$ is a Cauchy sequence in the space $L^2(\\Omega)$.\n4. The space $L^2(\\Omega)$ is a complete Hilbert space, so every Cauchy sequence converges. Therefore, the limit $Y = \\lim_{n \\to \\infty} I(H_n)$ exists in $L^2(\\Omega)$.\n5. We define the Itô integral for $H \\in \\mathcal{H}^2$ to be this limit: $\\int_0^T H_t dW_t := \\lim_{n\\to\\infty} \\int_0^T H_{n,t} dW_t$. This definition is consistent, as the limit is independent of the particular choice of approximating sequence $\\{H_n\\}$.\n6. The isometry property extends to all of $\\mathcal{H}^2$ by the continuity of the norm. For $H \\in \\mathcal{H}^2$ and its approximating sequence $\\{H_n\\} \\subset \\mathcal{S}$:\n$$\n\\left\\|\\int_0^T H_t dW_t\\right\\|_{L^2(\\Omega)}^2 = \\|I(H)\\|_{L^2(\\Omega)}^2 = \\lim_{n\\to\\infty} \\|I(H_n)\\|_{L^2(\\Omega)}^2 = \\lim_{n\\to\\infty} \\|H_n\\|_{\\mathcal{H}^2}^2 = \\|H\\|_{\\mathcal{H}^2}^2\n$$\nThus, the property $\\mathbb{E}[(\\int_0^T H_t dW_t)^2] = \\mathbb{E}[\\int_0^T H_t^2 dt]$ holds for all $H \\in \\mathcal{H}^2$.\n\nPart 3: Calculation of the Chebyshev Bound\n\nWe are given the integrand $h(t) = \\sin(\\omega t)$ for $t \\in [0,T]$ and $\\omega > 0$. This is a deterministic, continuous function, so it is predictable. To confirm it belongs to $\\mathcal{H}^2$, we check its norm:\n$$\n\\mathbb{E}\\left[\\int_0^T h(t)^2 dt\\right] = \\mathbb{E}\\left[\\int_0^T \\sin^2(\\omega t) dt\\right] = \\int_0^T \\sin^2(\\omega t) dt\n$$\nThe last equality holds because the integrand is deterministic. Since $\\sin^2(\\omega t)$ is a bounded continuous function on the finite interval $[0,T]$, the integral is finite. Thus, $h(t) \\in \\mathcal{H}^2$.\n\nWe consider the Itô integral $X = \\int_0^T h(t) dW_t = \\int_0^T \\sin(\\omega t) dW_t$.\nThe Chebyshev bound is given by $B(\\omega, T, r) = \\frac{\\mathbb{E}[X^2]}{r^2}$. We need to compute $\\mathbb{E}[X^2]$.\nUsing the Itô isometry extended to $\\mathcal{H}^2$:\n$$\n\\mathbb{E}[X^2] = \\mathbb{E}\\left[\\left(\\int_0^T \\sin(\\omega t) dW_t\\right)^2\\right] = \\mathbb{E}\\left[\\int_0^T \\sin^2(\\omega t) dt\\right] = \\int_0^T \\sin^2(\\omega t) dt\n$$\nWe compute the definite integral using the identity $\\sin^2(x) = \\frac{1 - \\cos(2x)}{2}$:\n$$\n\\int_0^T \\sin^2(\\omega t) dt = \\int_0^T \\frac{1 - \\cos(2\\omega t)}{2} dt = \\frac{1}{2}\\left[t - \\frac{\\sin(2\\omega t)}{2\\omega}\\right]_0^T\n$$\nEvaluating at the limits:\n$$\n= \\frac{1}{2}\\left(\\left(T - \\frac{\\sin(2\\omega T)}{2\\omega}\\right) - \\left(0 - \\frac{\\sin(0)}{2\\omega}\\right)\\right) = \\frac{1}{2}\\left(T - \\frac{\\sin(2\\omega T)}{2\\omega}\\right) = \\frac{T}{2} - \\frac{\\sin(2\\omega T)}{4\\omega}\n$$\nSo, we have $\\mathbb{E}[X^2] = \\frac{T}{2} - \\frac{\\sin(2\\omega T)}{4\\omega}$.\nThe Chebyshev upper bound $B(\\omega, T, r)$ is therefore:\n$$\nB(\\omega, T, r) = \\frac{\\mathbb{E}[X^2]}{r^2} = \\frac{1}{r^2}\\left(\\frac{T}{2} - \\frac{\\sin(2\\omega T)}{4\\omega}\\right)\n$$\nThis is the required closed-form expression.", "answer": "$$\n\\boxed{\\frac{1}{r^{2}}\\left(\\frac{T}{2} - \\frac{\\sin(2\\omega T)}{4\\omega}\\right)}\n$$", "id": "2971985"}, {"introduction": "The domain of the Itô integral is carefully restricted to integrands that are *predictable*, a condition more stringent than being merely *adapted*. This is not an arbitrary technicality; it is a conceptual necessity that prevents paradoxes related to \"seeing into the future.\" This exercise illuminates this crucial distinction by having you analyze a classic example of a process that is adapted but fails to be predictable, and thereby cannot serve as an integrand in the standard $L^2$ construction [@problem_id:2971981].", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$ satisfying the usual conditions (complete and right-continuous). Consider the Lebesgue square-integrable space (L²) on $[0,T] \\times \\Omega$ with norm given by the Itô isometry norm $\\|H\\|_{L^{2}}^{2} = \\mathbb{E}\\left[\\int_{0}^{T} |H_{t}|^{2}\\, \\mathrm{d}t\\right]$, and recall that the standard $L^{2}$ construction of the Itô integral $\\int_{0}^{T} H_{t}\\, \\mathrm{d}W_{t}$ is defined for processes $H$ that are predictable and square-integrable, by completion of simple predictable integrands.\n\nDefine the process $H = \\{H_{t}\\}_{t \\in [0,T]}$ by $H_{t} = \\mathbf{1}_{\\{W_{t} > 0\\}}$.\n\n- Using only foundational facts about Brownian motion and filtrations, determine whether $H$ is adapted and whether it is predictable. Provide a conceptual argument, grounded in the structure of the predictable $\\sigma$-algebra and the nature of the zero set of Brownian motion, to conclude that $H$ is adapted but not predictable.\n\n- Explain why, in the standard $L^{2}$ construction of the Itô integral, $H$ cannot serve as an integrand, despite being square-integrable.\n\n- Compute the quantity $\\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\, \\mathrm{d}t\\right]$. Express your final answer as a closed-form analytic expression in terms of $T$ (no units). If any numerical approximation is needed, round to four significant figures; otherwise, give the exact expression.", "solution": "The problem is evaluated to be valid as it is scientifically grounded in the theory of stochastic processes, well-posed, objective, and internally consistent. It presents a standard, non-trivial question about the construction of the Itô integral.\n\nThe problem requires a three-part analysis of the process $H_{t} = \\mathbf{1}_{\\{W_{t} > 0\\}}$ for a standard one-dimensional Brownian motion $\\{W_{t}\\}_{t \\geq 0}$ on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$ satisfying the usual conditions.\n\n**Part 1: Adaptedness and Predictability of $H$**\n\nA process $\\{X_{t}\\}_{t \\geq 0}$ is said to be **adapted** to the filtration $\\{\\mathcal{F}_{t}\\}_{t \\geq 0}$ if for every $t \\geq 0$, the random variable $X_{t}$ is $\\mathcal{F}_{t}$-measurable. For the given process $H_{t} = \\mathbf{1}_{\\{W_{t} > 0\\}}$, we must check if $H_{t}$ is $\\mathcal{F}_{t}$-measurable for each $t \\in [0,T]$.\n\nThe filtration $\\{\\mathcal{F}_{t}\\}_{t \\geq 0}$ is the one generated by the Brownian motion, so $\\mathcal{F}_{t}$ contains all information about the path of the Brownian motion up to time $t$. Formally, $\\mathcal{F}_{t} = \\sigma(W_{s} : s \\leq t)$, appropriately completed and made right-continuous. By definition, the random variable $W_{t}$ is $\\mathcal{F}_{t}$-measurable. The indicator function $\\mathbf{1}_{A}$ of a set $A$ is measurable with respect to a $\\sigma$-algebra $\\mathcal{G}$ if and only if the set $A$ is in $\\mathcal{G}$. Here, we need to check if the set $\\{\\omega \\in \\Omega : W_{t}(\\omega) > 0\\}$ is in $\\mathcal{F}_{t}$. This set can be written as $W_{t}^{-1}((0, \\infty))$. Since $(0, \\infty)$ is a Borel set in $\\mathbb{R}$ and $W_{t}$ is an $\\mathcal{F}_{t}$-measurable real-valued random variable, its preimage $W_{t}^{-1}((0, \\infty))$ is an element of $\\mathcal{F}_{t}$. Therefore, $H_{t}$ is $\\mathcal{F}_{t}$-measurable for all $t \\geq 0$, and the process $H$ is **adapted**.\n\nA process $\\{X_{t}\\}_{t \\geq 0}$ is said to be **predictable** if, as a map from $[0,T] \\times \\Omega$ to $\\mathbb{R}$, it is measurable with respect to the predictable $\\sigma$-algebra $\\mathcal{P}$. The predictable $\\sigma$-algebra is generated by all left-continuous adapted processes. A key conceptual interpretation of predictability is that the value of the process at time $t$, $X_{t}$, is determined by the history of the process strictly before time $t$, i.e., by the information contained in the pre-$t$ sigma-algebra, $\\mathcal{F}_{t-} = \\sigma(\\bigcup_{s<t} \\mathcal{F}_{s})$.\n\nThe process $H_{t} = \\mathbf{1}_{\\{W_{t} > 0\\}}$ is **not predictable**. The conceptual argument is as follows. A process being predictable means its value at time $t$ should not depend on the \"new\" information arriving precisely at time $t$. The value of $H_t$ is determined by the sign of $W_t$. The specific value of $W_t$ contains information that is not fully determined by the collection of values $\\{W_s\\}_{s<t}$, particularly at times $t$ when $W_t=0$.\n\nA Brownian path starting at $0$ has a set of zeros $\\{t: W_t=0\\}$ which is, with probability one, a closed, perfect, and nowhere dense set of Lebesgue measure zero. Near any such zero $t_0 > 0$, the path oscillates across $0$ infinitely often. This means that knowledge of the path in any interval $(t_0-\\epsilon, t_0)$ does not determine the sign of the path immediately after $t_0$.\nThe value of $H_t$ depends on the instantaneous value of $W_t$. At a time $t_0$ where $W_{t_0}=0$, the value $H_{t_0}=0$. However, for times $t$ arbitrarily close to $t_0$, $W_t$ can be positive or negative, causing $H_t$ to jump between $1$ and $0$. A process whose value at time $t$ depends on inspecting the value of the driving Brownian motion at that same instant $t$ is using contemporaneous information. The framework of Itô integration, for which predictable processes are the correct class of integrands, forbids such \"insider information\". The investment strategy (the integrand) at time $t$ must be decided based on information available just before time $t$. Since $H_t$ violates this principle, it is not predictable.\n\nMore formally, a hallmark of predictable processes is that they cannot have discontinuities at totally inaccessible stopping times. While the first hitting time of $0$ for a Brownian motion starting at $0$ is not a good example, if we consider a Brownian motion started at $x \\neq 0$, the first hitting time of $0$ is a totally inaccessible stopping time. The process $H_t$ would be discontinuous at this time, proving it is not predictable. This principle extends to the standard case.\n\n**Part 2: $H$ as an Integrand in the $L^2$ Construction**\n\nThe standard $L^{2}$ theory for constructing the Itô integral $\\int_{0}^{T} X_{t}\\, \\mathrm{d}W_{t}$ is defined for the class of integrands $X$ that satisfy two conditions:\n1. $X$ must be a predictable process.\n2. $X$ must be square-integrable, i.e., $\\mathbb{E}\\left[\\int_{0}^{T} X_{t}^{2}\\, \\mathrm{d}t\\right] < \\infty$.\n\nThe construction begins by defining the integral for simple predictable processes (which form a dense subset) and then extends it by completeness to all predictable processes in $L^2([0,T] \\times \\Omega)$. As established in Part 1, the process $H_{t} = \\mathbf{1}_{\\{W_{t} > 0\\}}$ is not predictable. Although we will show in Part 3 that it is square-integrable, its failure to meet the predictability requirement means it does not belong to the domain of integrands for which the standard Itô integral is defined. The entire construction is predicated on the property of predictability, which $H$ lacks.\n\n**Part 3: Computation of $\\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\, \\mathrm{d}t\\right]$**\n\nWe wish to compute the quantity $\\|H\\|_{L^{2}}^{2} = \\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\, \\mathrm{d}t\\right]$.\nThe process is $H_{t} = \\mathbf{1}_{\\{W_{t} > 0\\}}$. Its square is given by:\n$$H_{t}^{2} = \\left(\\mathbf{1}_{\\{W_{t} > 0\\}}\\right)^{2} = \\mathbf{1}_{\\{W_{t} > 0\\}}$$\nThis is because the indicator function only takes values $0$ and $1$, and $1^2 = 1$.\nSo we need to compute:\n$$\\mathbb{E}\\left[\\int_{0}^{T} \\mathbf{1}_{\\{W_{t} > 0\\}}\\, \\mathrm{d}t\\right]$$\nThe integrand $\\mathbf{1}_{\\{W_{t} > 0\\}}$ is a non-negative function of $(t, \\omega)$. Thus, by Tonelli's theorem, we can interchange the expectation and the integral:\n$$\\mathbb{E}\\left[\\int_{0}^{T} \\mathbf{1}_{\\{W_{t} > 0\\}}\\, \\mathrm{d}t\\right] = \\int_{0}^{T} \\mathbb{E}\\left[\\mathbf{1}_{\\{W_{t} > 0\\}}\\right]\\, \\mathrm{d}t$$\nThe expectation of an indicator function is the probability of the event it indicates:\n$$\\mathbb{E}\\left[\\mathbf{1}_{\\{W_{t} > 0\\}}\\right] = \\mathbb{P}(W_{t} > 0)$$\nFor a standard one-dimensional Brownian motion, $W_{0} = 0$, and for any $t > 0$, the random variable $W_{t}$ follows a normal distribution with mean $0$ and variance $t$, i.e., $W_{t} \\sim N(0, t)$. The probability density function of a normal distribution with mean $0$ is symmetric about $0$. Therefore, for any $t > 0$:\n$$\\mathbb{P}(W_{t} > 0) = \\frac{1}{2}$$\nFor the specific time $t=0$, we have $W_{0}=0$, so $\\mathbb{P}(W_{0} > 0) = \\mathbb{P}(0 > 0) = 0$.\nThe integral is over the interval $[0,T]$. The value of the integrand $\\mathbb{P}(W_t>0)$ is $1/2$ for all $t \\in (0, T]$ and $0$ at $t=0$. Since changing the value of an integrand at a single point does not affect the value of its Lebesgue integral, we have:\n$$\\int_{0}^{T} \\mathbb{P}(W_{t} > 0)\\, \\mathrm{d}t = \\int_{0}^{T} \\frac{1}{2}\\, \\mathrm{d}t$$\nEvaluating this elementary integral gives:\n$$\\int_{0}^{T} \\frac{1}{2}\\, \\mathrm{d}t = \\frac{1}{2} \\left[t\\right]_{0}^{T} = \\frac{1}{2}(T - 0) = \\frac{T}{2}$$\nThus, $\\mathbb{E}\\left[\\int_{0}^{T} H_{t}^{2}\\, \\mathrm{d}t\\right] = \\frac{T}{2}$. This confirms that for any finite $T$, the process $H$ is square-integrable.", "answer": "$$\\boxed{\\frac{T}{2}}$$", "id": "2971981"}]}