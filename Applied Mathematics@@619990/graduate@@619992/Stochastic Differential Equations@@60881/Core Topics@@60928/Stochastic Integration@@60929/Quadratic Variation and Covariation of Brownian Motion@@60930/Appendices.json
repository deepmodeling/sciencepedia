{"hands_on_practices": [{"introduction": "To truly understand quadratic variation, it is essential to go back to its roots. This exercise challenges you to derive the fundamental scaling property of the quadratic variation of a Brownian motion, $[aW]_t = a^2t$, directly from its definition as a limit of sums of squares. By working through the convergence in $L^2$, you will solidify your understanding of why quadratic variation is a non-trivial feature of stochastic processes and how it emerges from the statistical properties of Brownian increments [@problem_id:2992125].", "problem": "Let $\\{W_{s}\\}_{s \\geq 0}$ be a standard Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{s}\\}_{s \\geq 0},\\mathbb{P})$ satisfying the usual conditions. Recall the following foundational characterization of Brownian motion: (i) $\\{W_{s}\\}_{s \\geq 0}$ has continuous sample paths, (ii) $W_{0}=0$, (iii) for $0 \\leq s  u$, the increment $W_{u}-W_{s}$ is independent of $\\mathcal{F}_{s}$ and is Gaussian with mean $0$ and variance $u-s$, and (iv) increments over disjoint intervals are independent.\n\nFor a continuous process $\\{X_{s}\\}_{0 \\leq s \\leq t}$, define its quadratic variation at time $t$ by\n$$\n[X]_{t} \\text{ is the limit in probability of } \\sum_{i=0}^{n-1} \\bigl(X_{t_{i+1}} - X_{t_{i}}\\bigr)^{2}\n$$\nalong any sequence of partitions $\\pi^{n} = \\{0 = t_{0}  t_{1}  \\cdots  t_{n} = t\\}$ with mesh size $\\|\\pi^{n}\\| := \\max_{0 \\leq i \\leq n-1} (t_{i+1} - t_{i})$ satisfying $\\|\\pi^{n}\\| \\to 0$ as $n \\to \\infty$.\n\nFix $t > 0$ and a constant $a \\in \\mathbb{R}$. Consider the process $X_{s} := a W_{s}$. Using only the above fundamental characterization of Brownian motion and the definition of quadratic variation via partitions, compute the limit in probability of\n$$\n\\sum_{i=0}^{n-1} \\bigl(X_{t_{i+1}} - X_{t_{i}}\\bigr)^{2}\n=\n\\sum_{i=0}^{n-1} \\bigl(a(W_{t_{i+1}} - W_{t_{i}})\\bigr)^{2}\n$$\nas $n \\to \\infty$ with $\\|\\pi^{n}\\| \\to 0$, and determine $[aW]_{t}$ explicitly as a closed-form expression in terms of $a$ and $t$. Provide your final answer as a single analytic expression. No rounding is required.", "solution": "The problem is valid. It is a well-posed, scientifically grounded question within the domain of stochastic calculus, with all necessary information provided for a rigorous solution.\n\nWe are asked to compute the quadratic variation $[X]_t$ of the process $X_s := aW_s$, where $\\{W_s\\}_{s \\geq 0}$ is a standard Brownian motion and $a \\in \\mathbb{R}$ is a constant. The computation must be performed using the definition of quadratic variation as a limit in probability.\n\nLet $\\pi^n = \\{0 = t_0  t_1  \\dots  t_n = t\\}$ be a sequence of partitions of the interval $[0, t]$ such that its mesh, $\\|\\pi^n\\| := \\max_{0 \\leq i \\leq n-1} (t_{i+1} - t_i)$, approaches $0$ as $n \\to \\infty$. The quadratic variation $[X]_t$ is defined as the limit in probability of the sum\n$$\nS_n := \\sum_{i=0}^{n-1} (X_{t_{i+1}} - X_{t_i})^2\n$$\nas $\\|\\pi^n\\| \\to 0$.\n\nSubstituting the definition of $X_s$, we have\n$$\nS_n = \\sum_{i=0}^{n-1} (aW_{t_{i+1}} - aW_{t_i})^2 = a^2 \\sum_{i=0}^{n-1} (W_{t_{i+1}} - W_{t_i})^2.\n$$\nTo find the limit in probability of $S_n$, we will first compute its mean and variance. The strategy is to show that $S_n$ converges in $L^2$ to a constant, which implies convergence in probability to the same constant. Convergence in $L^2$ of a sequence of random variables $\\{Y_n\\}$ to a constant $c$ is established if $\\mathbb{E}[Y_n] \\to c$ and $\\text{Var}(Y_n) \\to 0$.\n\nLet $\\Delta t_i = t_{i+1} - t_i$ and $\\Delta W_i = W_{t_{i+1}} - W_{t_i}$. From the properties of Brownian motion, the increment $\\Delta W_i$ is a Gaussian random variable with mean $0$ and variance $\\Delta t_i$. That is, $\\Delta W_i \\sim \\mathcal{N}(0, \\Delta t_i)$.\n\nFirst, we compute the expectation of $S_n$:\n$$\n\\mathbb{E}[S_n] = \\mathbb{E}\\left[ a^2 \\sum_{i=0}^{n-1} (\\Delta W_i)^2 \\right].\n$$\nBy the linearity of expectation,\n$$\n\\mathbb{E}[S_n] = a^2 \\sum_{i=0}^{n-1} \\mathbb{E}[(\\Delta W_i)^2].\n$$\nThe term $\\mathbb{E}[(\\Delta W_i)^2]$ is the variance of $\\Delta W_i$, since its mean is $0$.\n$$\n\\mathbb{E}[(\\Delta W_i)^2] = \\text{Var}(\\Delta W_i) + (\\mathbb{E}[\\Delta W_i])^2 = \\Delta t_i + 0^2 = \\Delta t_i.\n$$\nSubstituting this back into the expression for $\\mathbb{E}[S_n]$:\n$$\n\\mathbb{E}[S_n] = a^2 \\sum_{i=0}^{n-1} \\Delta t_i = a^2 \\sum_{i=0}^{n-1} (t_{i+1} - t_i).\n$$\nThis is a telescoping sum on the partition points, which evaluates to\n$$\n\\mathbb{E}[S_n] = a^2 (t_n - t_0) = a^2 (t - 0) = a^2 t.\n$$\nThe expectation of $S_n$ is a constant $a^2 t$, independent of the specific partition $\\pi^n$. This suggests that the limit in probability is $a^2 t$.\n\nNext, we compute the variance of $S_n$ to show that it converges to $0$.\n$$\n\\text{Var}(S_n) = \\text{Var}\\left( a^2 \\sum_{i=0}^{n-1} (\\Delta W_i)^2 \\right) = (a^2)^2 \\text{Var}\\left( \\sum_{i=0}^{n-1} (\\Delta W_i)^2 \\right) = a^4 \\text{Var}\\left( \\sum_{i=0}^{n-1} (\\Delta W_i)^2 \\right).\n$$\nAccording to property (iv) of Brownian motion, increments over disjoint time intervals are independent. Thus, the random variables $\\Delta W_i$ and $\\Delta W_j$ are independent for $i \\neq j$. Consequently, their squares, $(\\Delta W_i)^2$ and $(\\Delta W_j)^2$, are also independent. For a sum of independent random variables, the variance of the sum is the sum of the variances:\n$$\n\\text{Var}(S_n) = a^4 \\sum_{i=0}^{n-1} \\text{Var}((\\Delta W_i)^2).\n$$\nTo compute $\\text{Var}((\\Delta W_i)^2)$, we use the formula $\\text{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$:\n$$\n\\text{Var}((\\Delta W_i)^2) = \\mathbb{E}[((\\Delta W_i)^2)^2] - (\\mathbb{E}[(\\Delta W_i)^2])^2 = \\mathbb{E}[(\\Delta W_i)^4] - (\\Delta t_i)^2.\n$$\nWe need the fourth moment of the centered Gaussian random variable $\\Delta W_i \\sim \\mathcal{N}(0, \\Delta t_i)$. For a general centered Normal random variable $Z \\sim \\mathcal{N}(0, \\sigma^2)$, the fourth moment is $\\mathbb{E}[Z^4] = 3\\sigma^4$. In our case, $\\sigma^2 = \\Delta t_i$, so\n$$\n\\mathbb{E}[(\\Delta W_i)^4] = 3(\\Delta t_i)^2.\n$$\nSubstituting this result into the variance expression:\n$$\n\\text{Var}((\\Delta W_i)^2) = 3(\\Delta t_i)^2 - (\\Delta t_i)^2 = 2(\\Delta t_i)^2.\n$$\nNow, we can find the variance of $S_n$:\n$$\n\\text{Var}(S_n) = a^4 \\sum_{i=0}^{n-1} 2(\\Delta t_i)^2 = 2a^4 \\sum_{i=0}^{n-1} (\\Delta t_i)^2.\n$$\nWe need to show that this variance tends to $0$ as the mesh of the partition $\\|\\pi^n\\| \\to 0$. We can bound the sum:\n$$\n\\sum_{i=0}^{n-1} (\\Delta t_i)^2 = \\sum_{i=0}^{n-1} (\\Delta t_i) \\cdot (\\Delta t_i) \\leq \\sum_{i=0}^{n-1} \\left( \\max_{0 \\leq j \\leq n-1} (\\Delta t_j) \\right) \\cdot (\\Delta t_i) = \\|\\pi^n\\| \\sum_{i=0}^{n-1} \\Delta t_i = \\|\\pi^n\\| t.\n$$\nTherefore, the variance of $S_n$ is bounded:\n$$\n0 \\leq \\text{Var}(S_n) \\leq 2a^4 t \\|\\pi^n\\|.\n$$\nAs $n \\to \\infty$, we are given that $\\|\\pi^n\\| \\to 0$. By the Squeeze Theorem, $\\text{Var}(S_n) \\to 0$.\n\nSince $\\mathbb{E}[S_n] = a^2 t$ and $\\text{Var}(S_n) \\to 0$ as $\\|\\pi^n\\| \\to 0$, the sequence of random variables $S_n$ converges in $L^2$ to the constant $a^2 t$. Convergence in $L^2$ implies convergence in probability.\nFormally, by Chebyshev's inequality, for any $\\epsilon  0$:\n$$\n\\mathbb{P}(|S_n - \\mathbb{E}[S_n]|  \\epsilon) \\leq \\frac{\\text{Var}(S_n)}{\\epsilon^2}.\n$$\nSubstituting our results:\n$$\n\\mathbb{P}(|S_n - a^2 t|  \\epsilon) \\leq \\frac{\\text{Var}(S_n)}{\\epsilon^2}.\n$$\nTaking the limit as $\\|\\pi^n\\| \\to 0$:\n$$\n\\lim_{\\|\\pi^n\\| \\to 0} \\mathbb{P}(|S_n - a^2 t|  \\epsilon) \\leq \\lim_{\\|\\pi^n\\| \\to 0} \\frac{\\text{Var}(S_n)}{\\epsilon^2} = 0.\n$$\nThis shows that $S_n$ converges in probability to $a^2 t$. Therefore, the quadratic variation of $X_s = aW_s$ at time $t$ is\n$$\n[aW]_t = [X]_t = a^2 t.\n$$", "answer": "$$\\boxed{a^{2}t}$$", "id": "2992125"}, {"introduction": "Once the basic properties of quadratic variation are established, we can use them as powerful algebraic tools. This practice focuses on the bilinearity of the quadratic covariation bracket, a property that allows us to compute the covariation of complex processes by breaking them down into simpler components. You will apply these rules to linear combinations of independent Brownian motions, a common task in portfolio modeling and multivariate stochastic calculus [@problem_id:1328954].", "problem": "In the theory of stochastic processes, the quadratic covariation, denoted as $[X, Y]_t$ for two processes $X_t$ and $Y_t$, is a fundamental concept that measures how they vary together. Let $B_{1,t}$ and $B_{2,t}$ be two independent standard Brownian motions, defined for time $t \\ge 0$. A standard Brownian motion $B_t$ is defined by its characteristic quadratic variation $[B, B]_t = t$. Furthermore, due to their independence, the quadratic covariation of $B_{1,t}$ and $B_{2,t}$ is $[B_{1}, B_{2}]_t = 0$.\n\nConsider two new processes, $X_t$ and $Y_t$, constructed from these Brownian motions as follows:\n$$X_t = B_{1,t} + 3B_{2,t}$$\n$$Y_t = 2B_{1,t} - 5B_{2,t}$$\nCalculate the quadratic covariation process $[X, Y]_t$. Your answer should be an expression in terms of the time variable $t$.", "solution": "We use the bilinearity and scaling properties of quadratic covariation for semimartingales: for constants $a, b, c, d$ and processes $U, V$, one has $[aU + bV, cU + dV] = ac[U, U] + ad[U, V] + bc[V, U] + bd[V, V]$, and $[cU, dV] = cd[U, V]$. For independent standard Brownian motions $B_{1,t}$ and $B_{2,t}$, $[B_{1}, B_{1}]_{t} = t$, $[B_{2}, B_{2}]_{t} = t$, and $[B_{1}, B_{2}]_{t} = [B_{2}, B_{1}]_{t} = 0$.\n\nGiven $X_{t} = B_{1,t} + 3B_{2,t}$ and $Y_{t} = 2B_{1,t} - 5B_{2,t}$, apply bilinearity:\n$$\n[X, Y]_{t} = [B_{1} + 3B_{2},\\, 2B_{1} - 5B_{2}]_{t}\n= 2[B_{1}, B_{1}]_{t} - 5[B_{1}, B_{2}]_{t} + 6[B_{2}, B_{1}]_{t} - 15[B_{2}, B_{2}]_{t}.\n$$\nUsing the properties above, this reduces to\n$$\n[X, Y]_{t} = 2t - 15t = -13t.\n$$\nThus, the quadratic covariation process is $[X, Y]_{t} = -13t$.", "answer": "$$\\boxed{-13 t}$$", "id": "1328954"}, {"introduction": "Beyond direct computation, the quadratic variation of a process can be elegantly determined from its semimartingale decomposition. This advanced exercise introduces Tanaka's formula for the absolute value of a Brownian motion, $|W_t|$, which separates the process into a local martingale and a finite variation part (the local time). By analyzing this decomposition, you will see how the quadratic variation is entirely captured by the martingale component, providing a profound insight into the structure of stochastic processes [@problem_id:2992119].", "problem": "Let $\\{W_{t}\\}_{t \\ge 0}$ be a standard one-dimensional Brownian motion with $W_{0} \\in \\mathbb{R}$, adapted to its natural filtration, and let $|W|_{t} \\coloneqq |W_{t}|$. Denote by $L_{t}^{0}$ the semimartingale local time at level $0$ of $W$. \n\n(a) Carefully state the Tanaka formula, making precise the definition you use for the function $\\operatorname{sgn}:\\mathbb{R} \\to \\mathbb{R}$.\n\n(b) Using only fundamental properties of quadratic variation and covariation for continuous semimartingales, the fact that processes of finite variation have zero quadratic variation and zero covariation with continuous local martingales, and the basic identity for stochastic integrals with respect to Brownian motion,\n$$\n\\Big[\\int_{0}^{\\cdot} H_{s} \\, dW_{s}\\Big]_{t} \\;=\\; \\int_{0}^{t} H_{s}^{2} \\, ds \\quad \\text{for all } t \\ge 0,\n$$\ncompute the quadratic variation process $[\\,|W|\\,]_{t}$ for $t \\ge 0$. You may use without proof that Brownian motion spends zero Lebesgue time at any fixed spatial point, and you should explicitly justify any step that uses finite variation or covariation properties. \n\nYour final answer must be a single closed-form expression in $t$. No numerical approximation is required.", "solution": "(a) The Tanaka-Meyer formula provides a semimartingale decomposition for convex functions of a continuous semimartingale. For the specific case of the function $f(x) = |x|$ applied to a standard one-dimensional Brownian motion $\\{W_{t}\\}_{t \\ge 0}$, the formula is known as Tanaka's formula.\n\nFirst, we must define the sign function, $\\operatorname{sgn}:\\mathbb{R} \\to \\mathbb{R}$. The value of this function at $x=0$ can be chosen arbitrarily from $\\{-1, 0, 1\\}$, as the set of times $\\{t \\ge 0 \\mid W_{t}=0\\}$ has Lebesgue measure zero almost surely, which ensures the value of the stochastic integral in the formula is unaffected by this choice. A standard and convenient definition is:\n$$\n\\operatorname{sgn}(x) \\coloneqq\n\\begin{cases}\n1  \\text{if } x  0 \\\\\n0  \\text{if } x = 0 \\\\\n-1  \\text{if } x  0\n\\end{cases}\n$$\nWith this definition, Tanaka's formula for $|W|_{t} \\coloneqq |W_{t}|$ is given by:\n$$\n|W|_{t} = |W_{0}| + \\int_{0}^{t} \\operatorname{sgn}(W_{s}) \\, dW_{s} + L_{t}^{0}\n$$\nwhere $\\{W_{t}\\}_{t \\ge 0}$ is a standard one-dimensional Brownian motion with starting value $W_{0} \\in \\mathbb{R}$, and $L_{t}^{0}$ is the symmetric semimartingale local time of $W$ at level $0$.\n\n(b) To compute the quadratic variation process $[\\,|W|\\,]_{t}$, we start from the semimartingale decomposition of $|W|_{t}$ provided by Tanaka's formula in part (a). Let us define the processes $M_{t}$ and $A_{t}$ for $t \\ge 0$ as follows:\n$$\nM_{t} \\coloneqq \\int_{0}^{t} \\operatorname{sgn}(W_{s}) \\, dW_{s}\n$$\n$$\nA_{t} \\coloneqq L_{t}^{0}\n$$\nThe constant term $|W_{0}|$ does not contribute to the quadratic variation, as $[X+c]_{t} = [X]_{t}$ for any constant $c$. Thus, we can write:\n$$\n[\\,|W|\\,]_{t} = [\\,|W| - |W_{0}|\\,]_{t} = [M + A]_{t}\n$$\nUsing the bilinearity property of the quadratic covariation bracket, we have:\n$$\n[\\,|W|\\,]_{t} = [M]_{t} + 2[M, A]_{t} + [A]_{t}\n$$\nThe problem permits the use of fundamental properties of quadratic variation for continuous semimartingales. We apply these properties to the terms $[A]_{t}$ and $[M, A]_{t}$.\n\nFirst, the process $A_{t} = L_{t}^{0}$ is the local time of $W$ at $0$. It is a continuous and non-decreasing process, which implies it is a process of finite variation on any compact interval $[0, T]$. The problem states as a given property that processes of finite variation have zero quadratic variation. Therefore, we have:\n$$\n[A]_{t} = [L^{0}]_{t} = 0\n$$\nThis is an explicit application of the provided rules.\n\nSecond, the process $M_{t}$ is an It√¥ stochastic integral with respect to Brownian motion, which defines it as a continuous local martingale. The process $A_{t} = L_{t}^{0}$ is, as established, a continuous process of finite variation. The problem states that processes of finite variation have zero covariation with continuous local martingales. Applying this rule gives:\n$$\n[M, A]_{t} = \\left[\\int_{0}^{\\cdot} \\operatorname{sgn}(W_{s}) \\, dW_{s}, L^{0}\\right]_{t} = 0\n$$\nThis is another explicit application of the provided rules.\n\nSubstituting these two results, $[A]_{t}=0$ and $[M, A]_{t}=0$, back into the expression for $[\\,|W|\\,]_{t}$, we find that the quadratic variation of $|W|_{t}$ is equal to the quadratic variation of its continuous local martingale part:\n$$\n[\\,|W|\\,]_{t} = [M]_{t} + 2(0) + 0 = [M]_{t} = \\left[\\int_{0}^{\\cdot} \\operatorname{sgn}(W_{s}) \\, dW_{s}\\right]_{t}\n$$\nNow, we use the specific identity provided in the problem statement for the quadratic variation of a stochastic integral:\n$$\n\\left[\\int_{0}^{\\cdot} H_{s} \\, dW_{s}\\right]_{t} = \\int_{0}^{t} H_{s}^{2} \\, ds\n$$\nIn our case, the integrand is $H_{s} = \\operatorname{sgn}(W_{s})$. Substituting this into the identity yields:\n$$\n[\\,|W|\\,]_{t} = \\int_{0}^{t} (\\operatorname{sgn}(W_{s}))^{2} \\, ds\n$$\nBased on our definition of the $\\operatorname{sgn}$ function, its square is:\n$$\n(\\operatorname{sgn}(x))^{2} =\n\\begin{cases}\n1^{2} = 1  \\text{if } x  0 \\\\\n0^{2} = 0  \\text{if } x = 0 \\\\\n(-1)^{2} = 1  \\text{if } x  0\n\\end{cases}\n$$\nThus, $(\\operatorname{sgn}(x))^{2} = 1$ for $x \\neq 0$, and $(\\operatorname{sgn}(x))^{2} = 0$ for $x=0$. This can be expressed using an indicator function: $(\\operatorname{sgn}(x))^{2} = 1_{x \\neq 0}$. Applying this to our integral:\n$$\n[\\,|W|\\,]_{t} = \\int_{0}^{t} 1_{W_{s} \\ne 0} \\, ds\n$$\nWe can rewrite the integrand as $1_{W_{s} \\ne 0} = 1 - 1_{W_{s} = 0}$. The integral becomes:\n$$\n[\\,|W|\\,]_{t} = \\int_{0}^{t} (1 - 1_{W_{s} = 0}) \\, ds = \\int_{0}^{t} 1 \\, ds - \\int_{0}^{t} 1_{W_{s} = 0} \\, ds\n$$\nThe first term is simply $t$. For the second term, the problem allows us to use the fact that Brownian motion spends zero Lebesgue time at any fixed spatial point. For the point $0$, this means that the Lebesgue measure of the set $\\{s \\in [0, t] \\mid W_{s} = 0\\}$ is $0$ almost surely. The integral of the indicator function of this set is precisely its Lebesgue measure:\n$$\n\\int_{0}^{t} 1_{W_{s} = 0} \\, ds = \\operatorname{Lebesgue}\\left(\\{s \\in [0, t] \\mid W_{s} = 0\\}\\right) = 0 \\quad \\text{a.s.}\n$$\nSubstituting this result back, we obtain the final expression for the quadratic variation:\n$$\n[\\,|W|\\,]_{t} = t - 0 = t\n$$\nThis result is independent of the starting value $W_0$ and holds for all $t \\ge 0$.", "answer": "$$\\boxed{t}$$", "id": "2992119"}]}