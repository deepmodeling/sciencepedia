{"hands_on_practices": [{"introduction": "We begin our practical exploration with a foundational exercise: constructing a martingale from a simple, predictable process. This practice challenges you to compute the Itô integral of an indicator function, connecting the abstract definition of the integral directly to the tangible properties of Brownian motion increments [@problem_id:2986765]. By calculating the integral's distribution, expectation, and variance, you will build a concrete intuition for how the integration process transforms a deterministic integrand into a random outcome with a clear probabilistic structure.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\ge 0},\\mathbb{P})$ be a filtered probability space supporting a one-dimensional standard Brownian motion $W=(W_t)_{t\\ge 0}$ with its usual augmentation. Fix constants $T>0$ and $0\\le a<b<\\infty$. Consider the elementary predictable process $H=(H_s)_{s\\ge 0}$ defined by $H_s=\\mathbf{1}_{(a,b]}(s)$, and the Itô stochastic integral\n$$\nX_T \\coloneqq \\int_0^T H_s\\,dW_s.\n$$\nStarting only from the definition of the Itô integral for elementary predictable processes and the defining properties of Brownian motion (independent, stationary, Gaussian increments with variance equal to the increment length) together with the Itô isometry, do the following:\n- Compute $X_T$ explicitly in terms of $W$ and the times $a,b,T$.\n- Identify the distribution of $X_T$, its expectation, and its variance, all expressed in closed form as functions of $a,b,T$.\n- Briefly justify why the process $X_t\\coloneqq\\int_0^t \\mathbf{1}_{(a,b]}(s)\\,dW_s$ is a martingale in the Brownian filtration and explain how this example is consistent with the martingale representation property in Brownian filtrations.\n\nDefine $x\\wedge y\\coloneqq \\min\\{x,y\\}$. Your final answer must present, in a single expression, the value of $\\int_0^T \\mathbf{1}_{(a,b]}(s)\\,dW_s$, its law written as a centered normal with its variance parameter, its expectation, and its variance, in that order. No numerical approximation is required.", "solution": "The problem statement is a well-posed exercise in the theory of stochastic integration with respect to Brownian motion. It is scientifically sound, self-contained, and objective. All terms are standard in the field of stochastic differential equations. The problem is therefore valid. We proceed with the solution.\n\nThe problem asks for several quantities related to the Itô stochastic integral $X_T \\coloneqq \\int_0^T H_s\\,dW_s$, where $H_s = \\mathbf{1}_{(a,b]}(s)$ is an elementary predictable process, and $W_t$ is a standard one-dimensional Brownian motion. The constants satisfy $T>0$ and $0 \\le a < b < \\infty$. The definition $x\\wedge y\\coloneqq \\min\\{x,y\\}$ is used.\n\n**1. Explicit Computation of $X_T$**\n\nThe Itô integral is defined over the time interval $[0, T]$. The integrand $H_s = \\mathbf{1}_{(a,b]}(s)$ is non-zero only for $s \\in (a, b]$. Therefore, the integral is effectively over the intersection of these two intervals, which is $(a, b] \\cap [0, T]$. Given that $0 \\le a$, this intersection is the interval $(a, b \\wedge T]$. The integral is non-zero only if this interval is non-empty, which means $a < b \\wedge T$.\n\nWe can formalize this by considering three cases based on the relationship between $T$ and the interval $(a, b]$.\n\nCase 1: $0 < T \\le a$.\nFor any $s \\in [0, T]$, we have $s \\le a$, so $s \\notin (a, b]$. This implies $H_s = \\mathbf{1}_{(a,b]}(s) = 0$ for all $s$ in the integration interval $[0, T]$. Thus,\n$$ X_T = \\int_0^T 0 \\, dW_s = 0. $$\n\nCase 2: $a < T \\le b$.\nThe integral can be split using the additivity property:\n$$ X_T = \\int_0^T \\mathbf{1}_{(a,b]}(s) \\, dW_s = \\int_0^a \\mathbf{1}_{(a,b]}(s) \\, dW_s + \\int_a^T \\mathbf{1}_{(a,b]}(s) \\, dW_s. $$\nOn the interval $[0, a]$, the integrand is $0$. On the interval $(a, T]$, we have $a < s \\le T \\le b$, so the integrand is $1$. The integral becomes:\n$$ X_T = \\int_0^a 0 \\, dW_s + \\int_a^T 1 \\, dW_s = 0 + (W_T - W_a) = W_T - W_a. $$\n\nCase 3: $T > b$.\nWe split the integral at points $a$ and $b$:\n$$ X_T = \\int_0^a 0 \\, dW_s + \\int_a^b 1 \\, dW_s + \\int_b^T 0 \\, dW_s = 0 + (W_b - W_a) + 0 = W_b - W_a. $$\n\nWe can unify these three cases into a single expression using the minimum notation $x \\wedge y$. Let us test the expression $W_{b \\wedge T} - W_{a \\wedge T}$.\n- If $T \\le a$, then $a \\wedge T = T$ and $b \\wedge T = T$. The expression is $W_T - W_T = 0$. This matches Case 1.\n- If $a < T \\le b$, then $a \\wedge T = a$ and $b \\wedge T = T$. The expression is $W_T - W_a$. This matches Case 2.\n- If $T > b$, then $a \\wedge T = a$ and $b \\wedge T = b$. The expression is $W_b - W_a$. This matches Case 3.\n\nThus, the explicit form of the stochastic integral is:\n$$ X_T = W_{b \\wedge T} - W_{a \\wedge T}. $$\n\n**2. Distribution, Expectation, and Variance of $X_T$**\n\nThe random variable $X_T = W_{b \\wedge T} - W_{a \\wedge T}$ is an increment of a standard Brownian motion. Let $t_1 = a \\wedge T$ and $t_2 = b \\wedge T$. Since $a < b$, it follows that $a \\wedge T \\le b \\wedge T$, so $t_1 \\le t_2$.\nAccording to the properties of standard Brownian motion, the increment $W_{t_2} - W_{t_1}$ is a normally distributed random variable with mean $0$ and variance $t_2 - t_1$.\nTherefore, the distribution of $X_T$ is Gaussian (normal):\n$$ X_T \\sim \\mathcal{N}(0, (b \\wedge T) - (a \\wedge T)). $$\n\nFrom this distribution, we can directly identify the expectation and variance:\n- Expectation: $\\mathbb{E}[X_T] = 0$.\n- Variance: $\\text{Var}(X_T) = (b \\wedge T) - (a \\wedge T)$.\n\nWe can verify the variance using the Itô isometry, which states that $\\mathbb{E}[(\\int_0^T H_s dW_s)^2] = \\mathbb{E}[\\int_0^T H_s^2 ds]$. Since $H_s$ is a deterministic process, this simplifies to $\\int_0^T H_s^2 ds$.\n$$ \\text{Var}(X_T) = \\mathbb{E}[X_T^2] - (\\mathbb{E}[X_T])^2 = \\int_0^T (\\mathbf{1}_{(a,b]}(s))^2 ds - 0^2 = \\int_0^T \\mathbf{1}_{(a,b]}(s) ds. $$\nThis integral is the Lebesgue measure of the interval $(a,b] \\cap [0,T]$, which is $(b \\wedge T) - (a \\wedge T)$. This confirms our result.\n\n**3. Martingale Property of $X_t$**\n\nLet $X_t = \\int_0^t \\mathbf{1}_{(a,b]}(s) \\, dW_s$. Based on our previous calculation, we have $X_t = W_{b \\wedge t} - W_{a \\wedge t}$. To show that $(X_t)_{t \\ge 0}$ is a martingale with respect to the Brownian filtration $(\\mathcal{F}_t)_{t \\ge 0}$, we must verify three conditions:\n1.  $X_t$ is $\\mathcal{F}_t$-measurable for all $t \\ge 0$.\n    Since $a \\wedge t \\le t$ and $b \\wedge t \\le t$, both $W_{a \\wedge t}$ and $W_{b \\wedge t}$ are $\\mathcal{F}_t$-measurable. Their difference, $X_t$, is therefore also $\\mathcal{F}_t$-measurable. The process is adapted.\n2.  $\\mathbb{E}[|X_t|] < \\infty$ for all $t \\ge 0$.\n    As shown above, $X_t \\sim \\mathcal{N}(0, (b \\wedge t) - (a \\wedge t))$. The absolute moments of a Gaussian random variable are all finite. Thus, $X_t$ is integrable.\n3.  For all $s < t$, $\\mathbb{E}[X_t | \\mathcal{F}_s] = X_s$.\n    We use the property that Brownian motion itself is a martingale, which implies $\\mathbb{E}[W_u | \\mathcal{F}_s] = W_{u \\wedge s}$ for any $u \\ge 0$.\n    \\begin{align*}\n    \\mathbb{E}[X_t | \\mathcal{F}_s] &= \\mathbb{E}[W_{b \\wedge t} - W_{a \\wedge t} | \\mathcal{F}_s] \\\\\n    &= \\mathbb{E}[W_{b \\wedge t} | \\mathcal{F}_s] - \\mathbb{E}[W_{a \\wedge t} | \\mathcal{F}_s] \\\\\n    &= W_{(b \\wedge t) \\wedge s} - W_{(a \\wedge t) \\wedge s}\n    \\end{align*}\n    Using the associativity of the minimum operator and the fact that $s < t \\implies s \\wedge t = s$, we have:\n    $$ (b \\wedge t) \\wedge s = b \\wedge (t \\wedge s) = b \\wedge s $$\n    $$ (a \\wedge t) \\wedge s = a \\wedge (t \\wedge s) = a \\wedge s $$\n    Substituting these back, we get:\n    $$ \\mathbb{E}[X_t | \\mathcal{F}_s] = W_{b \\wedge s} - W_{a \\wedge s} = X_s. $$\nAll three conditions are met, hence $(X_t)_{t\\ge 0}$ is a martingale. This is consistent with the general theorem that Itô integrals of square-integrable predictable processes are martingales.\n\n**4. Consistency with Martingale Representation**\n\nThe martingale representation theorem states that any martingale $(M_t)_{t \\ge 0}$ relative to the Brownian filtration $(\\mathcal{F}_t)_{t \\ge 0}$ can be represented as a stochastic integral of the form $M_t = M_0 + \\int_0^t K_s \\, dW_s$ for some predictable process $K_s$.\n\nOur process $X_t = \\int_0^t \\mathbf{1}_{(a,b]}(s) \\, dW_s$ is constructed as such a stochastic integral (with $X_0=0$ and $K_s = \\mathbf{1}_{(a,b]}(s)$), and we have just proven it is a martingale. This provides a direct, constructive example of the principle underlying the representation theorem. We have built a martingale from a stochastic integral.\n\nConversely, a related version of the theorem (the Clark-Ocone formula) states that any $\\mathcal{F}_T$-measurable, square-integrable random variable $F$ can be written as $F = \\mathbb{E}[F] + \\int_0^T K_s \\, dW_s$. Our random variable is $X_T = W_{b \\wedge T} - W_{a \\wedge T}$. It is $\\mathcal{F}_T$-measurable and square-integrable. Its expectation is $0$. The theorem guarantees the existence of a representing integrand $K_s$. This problem explicitly provides it: $K_s = \\mathbf{1}_{(a,b]}(s)$. This example thus serves as a concrete illustration of the martingale representation property.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nW_{b \\wedge T} - W_{a \\wedge T} & \\mathcal{N}\\left(0, (b \\wedge T) - (a \\wedge T)\\right) & 0 & (b \\wedge T) - (a \\wedge T)\n\\end{pmatrix}\n}\n$$", "id": "2986765"}, {"introduction": "Having built a martingale from an integrand, we now address the inverse problem central to the Martingale Representation Theorem: for a given random variable, can we find the unique integrand that represents it? This practice guides you through the explicit derivation of the integrand for the time-integral of a Brownian path, $R = \\int_0^T W_u du$ [@problem_id:772770]. This exercise showcases a powerful and widely applicable technique that involves calculating a conditional expectation martingale and applying Itô's calculus to uncover its differential structure.", "problem": "Let $\\{W_t\\}_{t \\ge 0}$ be a standard one-dimensional Brownian motion on a probability space $(\\Omega, \\mathcal{F}, P)$, and let $\\{\\mathcal{F}_t\\}_{t \\ge 0}$ be the natural filtration generated by $W_t$. The Martingale Representation Theorem states that any random variable $R$ that is square-integrable and measurable with respect to the sigma-algebra $\\mathcal{F}_T$ for some fixed time $T > 0$ can be uniquely represented in the form:\n$$\nR = \\mathbb{E}[R] + \\int_0^T H_s dW_s\n$$\nwhere $H_s$ is a unique predictable process with respect to the filtration $\\{\\mathcal{F}_s\\}_{s \\ge 0}$ such that $\\int_0^T \\mathbb{E}[H_s^2] ds < \\infty$.\n\nConsider the random variable $R$ defined by the time-integral of the Brownian motion path up to time $T$:\n$$\nR = \\int_0^T W_u du\n$$\nThis random variable is $\\mathcal{F}_T$-measurable and square-integrable. Your task is to derive the explicit functional form of the integrand process $H_s$ for $s \\in [0, T]$ in the martingale representation of $R$.", "solution": "The goal is to find the predictable process $H_s$ in the martingale representation of the random variable $R = \\int_0^T W_u du$. The representation is given by:\n$$\nR = \\mathbb{E}[R] + \\int_0^T H_s dW_s\n$$\n\nFirst, we calculate the expected value of $R$. Since the expected value of a standard Brownian motion at any time $u$ is $\\mathbb{E}[W_u] = 0$, we have:\n$$\n\\mathbb{E}[R] = \\mathbb{E}\\left[\\int_0^T W_u du\\right] = \\int_0^T \\mathbb{E}[W_u] du = \\int_0^T 0 \\, du = 0\n$$\nSo the representation simplifies to $R = \\int_0^T H_s dW_s$.\n\nTo find $H_s$, we consider the martingale $M_t$ defined by the conditional expectation of $R$ with respect to the filtration $\\mathcal{F}_t$:\n$$\nM_t = \\mathbb{E}[R | \\mathcal{F}_t], \\quad t \\in [0, T]\n$$\nBy the definition of conditional expectation, $M_t$ is a martingale. We have $M_T = \\mathbb{E}[R | \\mathcal{F}_T] = R$ (since $R$ is $\\mathcal{F}_T$-measurable) and $M_0 = \\mathbb{E}[R | \\mathcal{F}_0] = \\mathbb{E}[R] = 0$.\n\nAccording to the Martingale Representation Theorem, any $\\{\\mathcal{F}_t\\}$-martingale can be represented as a stochastic integral with respect to the Brownian motion $W_t$. Thus, there exists a predictable process, which we can also denote by $H_s$, such that:\n$$\nM_t = M_0 + \\int_0^t H_s dW_s\n$$\nIn differential form, this is $dM_t = H_t dW_t$. Our strategy is to find an explicit expression for $M_t$ and then compute its stochastic differential to identify $H_t$.\n\nLet's express $M_t$ using the definition of $R$:\n$$\nM_t = \\mathbb{E}\\left[\\int_0^T W_u du \\bigg| \\mathcal{F}_t\\right]\n$$\nUsing the linearity of conditional expectation and the integral, we can write:\n$$\nM_t = \\int_0^T \\mathbb{E}[W_u | \\mathcal{F}_t] du\n$$\nWe split the integral at time $t$:\n$$\nM_t = \\int_0^t \\mathbb{E}[W_u | \\mathcal{F}_t] du + \\int_t^T \\mathbb{E}[W_u | \\mathcal{F}_t] du\n$$\nNow we evaluate the conditional expectation $\\mathbb{E}[W_u | \\mathcal{F}_t]$:\n1.  For $u \\le t$: $W_u$ is known at time $t$, so it is $\\mathcal{F}_t$-measurable. Thus, $\\mathbb{E}[W_u | \\mathcal{F}_t] = W_u$.\n2.  For $u > t$: We can write $W_u = W_t + (W_u - W_t)$. The increment $W_u - W_t$ is independent of the past information $\\mathcal{F}_t$ and has mean zero. Therefore:\n    $$\n    \\mathbb{E}[W_u | \\mathcal{F}_t] = \\mathbb{E}[W_t + (W_u - W_t) | \\mathcal{F}_t] = \\mathbb{E}[W_t | \\mathcal{F}_t] + \\mathbb{E}[W_u - W_t | \\mathcal{F}_t] = W_t + 0 = W_t\n    $$\n\nSubstituting these back into the expression for $M_t$:\n$$\nM_t = \\int_0^t W_u du + \\int_t^T W_t du\n$$\nThe second integral is with respect to $u$, and $W_t$ is constant in this context:\n$$\n\\int_t^T W_t du = W_t \\int_t^T du = W_t [u]_t^T = W_t (T-t)\n$$\nSo, the explicit expression for the martingale is:\n$$\nM_t = \\int_0^t W_u du + (T-t) W_t\n$$\nNow, we find the stochastic differential $dM_t$. Let's analyze the two terms separately.\nThe first term is $\\int_0^t W_u du$. Its differential is simply $W_t dt$.\nThe second term is $(T-t)W_t$. We use Itô's formula for a function $f(t, x) = (T-t)x$, with $x=W_t$. The partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial t} = -x, \\quad \\frac{\\partial f}{\\partial x} = T-t, \\quad \\frac{\\partial^2 f}{\\partial x^2} = 0\n$$\nItô's formula for $df(t, W_t)$ is:\n$$\ndf = \\left(\\frac{\\partial f}{\\partial t} + \\mu_t \\frac{\\partial f}{\\partial x} + \\frac{1}{2} \\sigma_t^2 \\frac{\\partial^2 f}{\\partial x^2}\\right)dt + \\sigma_t \\frac{\\partial f}{\\partial x} dW_t\n$$\nFor $W_t$, we have $dW_t = 0 \\cdot dt + 1 \\cdot dW_t$, so $\\mu_t = 0$ and $\\sigma_t = 1$.\n$$\nd((T-t)W_t) = (-W_t + 0 \\cdot(T-t) + \\frac{1}{2}\\cdot 1^2 \\cdot 0)dt + 1 \\cdot (T-t) dW_t = -W_t dt + (T-t) dW_t\n$$\nCombining the differentials:\n$$\ndM_t = d\\left(\\int_0^t W_u du\\right) + d((T-t)W_t) = W_t dt + [-W_t dt + (T-t)dW_t]\n$$\nThe $dt$ terms cancel out:\n$$\ndM_t = (W_t - W_t)dt + (T-t)dW_t = (T-t)dW_t\n$$\nComparing this with the general form $dM_t = H_t dW_t$, we can identify the integrand process $H_t$:\n$$\nH_t = T-t\n$$\nThe question asks for the process $H_s$ for $s \\in [0, T]$, which is obtained by replacing the time variable $t$ with $s$.\n$$\nH_s = T-s\n$$", "answer": "$$ \\boxed{T-s} $$", "id": "772770"}, {"introduction": "Our final practice delves into the profound relationship between the martingale representation and the Wiener chaos expansion, two pillars of modern stochastic analysis. By examining the Doléans-Dade exponential, $X = \\exp(\\theta W_T - \\frac{1}{2}\\theta^2 T)$, you will derive its chaos expansion and its martingale representation integrand [@problem_id:2986772]. This exercise illuminates how the predictable integrand in one representation is linked to the kernels of the other, revealing a deep structural consistency within the theory of Brownian filtrations.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\in [0,T]},\\mathbb{P})$ be a filtered probability space supporting a one-dimensional standard Brownian motion $W=(W_t)_{t \\in [0,T]}$ with its natural (completed and right-continuous) filtration. For a deterministic function $g \\in L^{2}([0,T])$, define the Wiener integral $W(g)=\\int_{0}^{T} g(s)\\, \\mathrm{d}W_{s}$ and, for each integer $n \\geq 1$, the $n$-fold multiple Wiener–Itô integral $I_{n}(f)$ for symmetric kernels $f \\in L_{\\mathrm{sym}}^{2}([0,T]^{n})$, normalized so that $\\mathbb{E}[I_{n}(f)^{2}] = n!\\,\\|f\\|_{L^{2}([0,T]^{n})}^{2}$. Consider the terminal random variable\n$$\nX \\;=\\; \\exp\\!\\big(\\theta W_{T} - \\tfrac{1}{2}\\theta^{2} T\\big),\n$$\nwhere $\\theta \\in \\mathbb{R}$ is fixed. Starting from the foundational properties of Brownian motion and the definition of the multiple Wiener–Itô integrals, derive the Wiener chaos expansion of $X$ as a series of multiple integrals with deterministic symmetric kernels. Then, using the martingale representation theorem in the Brownian filtration, express the unique predictable integrand $\\varphi=(\\varphi_{t})_{t\\in[0,T]}$ such that $X = \\mathbb{E}[X] + \\int_{0}^{T} \\varphi_{t}\\,\\mathrm{d}W_{t}$, and verify that the first-order chaos kernel obtained in your expansion coincides with the zeroth-chaos component (i.e., the deterministic part) of the integrand. Your final answer must be the explicit closed-form expression of the Wiener chaos expansion of $X$ in terms of $I_{n}$ and deterministic kernels. No rounding is required and no physical units are involved.", "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- A filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\in [0,T]},\\mathbb{P})$.\n- A one-dimensional standard Brownian motion $W=(W_t)_{t \\in [0,T]}$ with its natural filtration.\n- A deterministic function $g \\in L^{2}([0,T])$.\n- The Wiener integral $W(g)=\\int_{0}^{T} g(s)\\, \\mathrm{d}W_{s}$.\n- The $n$-fold multiple Wiener–Itô integral $I_{n}(f)$ for symmetric kernels $f \\in L_{\\mathrm{sym}}^{2}([0,T]^{n})$.\n- The normalization for the multiple integral: $\\mathbb{E}[I_{n}(f)^{2}] = n!\\,\\|f\\|_{L^{2}([0,T]^{n})}^{2}$.\n- The terminal random variable $X = \\exp(\\theta W_{T} - \\tfrac{1}{2}\\theta^{2} T)$, for a fixed $\\theta \\in \\mathbb{R}$.\n- The tasks are:\n    1. Derive the Wiener chaos expansion of $X$.\n    2. Express the predictable integrand $\\varphi=(\\varphi_{t})_{t\\in[0,T]}$ from the martingale representation $X = \\mathbb{E}[X] + \\int_{0}^{T} \\varphi_{t}\\,\\mathrm{d}W_{t}$.\n    3. Verify that the first-order chaos kernel of $X$ coincides with the zeroth-chaos component of $\\varphi_{t}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the required criteria.\n- **Scientifically Grounded**: The problem is formulated entirely within the standard mathematical framework of stochastic calculus, specifically Itô calculus, Malliavin calculus, and the theory of Wiener chaos expansions. All concepts, including Brownian motion, Doléans-Dade exponential (the random variable $X$), multiple Wiener-Itô integrals, and the martingale representation theorem, are fundamental and rigorously defined in probability theory.\n- **Well-Posed**: The problem is well-posed. The random variable $X$ is a square-integrable, $\\mathcal{F}_T$-measurable random variable, so its Wiener chaos expansion exists and is unique. The martingale representation of such a variable is also guaranteed to exist and be unique. The tasks are precise and lead to a unique, meaningful solution.\n- **Objective**: The problem is stated in purely formal, mathematical language. It is free from ambiguity, subjectivity, or opinion-based claims.\n- **Other Flaws**: The problem is complete, consistent, and relevant to the specified topic. It does not contain any scientific falsehoods, unrealistic assumptions, or structural defects. It is a standard, non-trivial problem in advanced stochastic analysis.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A complete, reasoned solution will be provided.\n\n### Solution Derivation\nThe problem asks for three things: the Wiener chaos expansion of $X$, its martingale representation integrand $\\varphi_t$, and a verification relating the two.\n\n**Part 1: Wiener Chaos Expansion of $X$**\n\nThe random variable is $X = \\exp(\\theta W_{T} - \\frac{1}{2}\\theta^{2} T)$. This is the Doléans-Dade exponential or Wick exponential of $\\theta W_T$. The chaos expansion of such a variable is related to Hermite polynomials. The generating function for the Hermite polynomials $H_n(x; \\sigma^2)$ is given by:\n$$\n\\exp(zx - \\tfrac{1}{2}z^2\\sigma^2) = \\sum_{n=0}^{\\infty} \\frac{z^n}{n!} H_n(x; \\sigma^2)\n$$\nBy setting $z=\\theta$, $x=W_T$, and $\\sigma^2=T$ (since the variance of $W_T$ is $T$), we can directly write the expansion of $X$ as:\n$$\nX = \\sum_{n=0}^{\\infty} \\frac{\\theta^n}{n!} H_n(W_T; T)\n$$\nA fundamental result in Wiener chaos theory connects Hermite polynomials of a Wiener integral with multiple Wiener-Itô integrals. Specifically, for a function $h \\in L^2([0,T])$, the following identity holds:\n$$\nH_n\\left(\\int_0^T h(s) dW_s; \\|h\\|_{L^2([0,T])}^2\\right) = I_n(h^{\\otimes n})\n$$\nwhere $h^{\\otimes n}(t_1, \\dots, t_n) = h(t_1)h(t_2)\\cdots h(t_n)$ is the $n$-fold tensor product of $h$, and $I_n$ is the multiple Wiener-Itô integral with the normalization given in the problem.\nIn our case, $W_T = \\int_0^T 1 \\, dW_s$. We choose the function $h(s) = \\mathbf{1}_{[0,T]}(s)$, which is the indicator function on the interval $[0,T]$. Its squared $L^2$-norm is $\\|h\\|_{L^2([0,T])}^2 = \\int_0^T 1^2 \\, ds = T$.\nTherefore, we have the identity:\n$$\nH_n(W_T; T) = I_n(\\mathbf{1}_{[0,T]}^{\\otimes n})\n$$\nwhere $\\mathbf{1}_{[0,T]}^{\\otimes n}(t_1, \\dots, t_n) = \\mathbf{1}_{[0,T]^n}(t_1, \\dots, t_n)$ is the indicator function on the hypercube $[0,T]^n$. This kernel is symmetric.\nSubstituting this into the series for $X$, we obtain its Wiener chaos expansion:\n$$\nX = \\sum_{n=0}^{\\infty} \\frac{\\theta^n}{n!} I_n(\\mathbf{1}_{[0,T]}^{\\otimes n})\n$$\nThis is the desired expansion. The kernel for the $n$-th chaos is the symmetric function $f_n(t_1, \\dots, t_n) = \\frac{\\theta^n}{n!} \\mathbf{1}_{[0,T]^n}(t_1, \\dots, t_n)$.\n\n**Part 2: Martingale Representation Integrand $\\varphi_t$**\n\nThe martingale representation theorem states that for a square-integrable, $\\mathcal{F}_T$-measurable random variable $X$, there exists a unique predictable process $\\varphi_t$ such that $X = \\mathbb{E}[X] + \\int_0^T \\varphi_s dW_s$. The Clark-Ocone formula provides an explicit expression for $\\varphi_t$ in terms of the Malliavin derivative $D$:\n$$\n\\varphi_t = \\mathbb{E}[D_t X | \\mathcal{F}_t]\n$$\nFirst, we compute the Malliavin derivative of $X$. The operator $D_t$ acts as a derivative, and for the Brownian motion, $D_t W_s = \\mathbf{1}_{[0,s]}(t)$. Thus, $D_t W_T = \\mathbf{1}_{[0,T]}(t) = 1$ for $t \\in [0,T]$. Using the chain rule for the Malliavin derivative:\n$$\nD_t X = D_t \\left( \\exp(\\theta W_T - \\tfrac{1}{2}\\theta^2 T) \\right) = \\exp(\\theta W_T - \\tfrac{1}{2}\\theta^2 T) \\cdot D_t(\\theta W_T) = X \\cdot \\theta (D_t W_T) = \\theta X\n$$\nNext, we compute the conditional expectation of $D_t X$ given $\\mathcal{F}_t$:\n$$\n\\varphi_t = \\mathbb{E}[\\theta X | \\mathcal{F}_t] = \\theta \\mathbb{E}\\left[\\exp(\\theta W_T - \\tfrac{1}{2}\\theta^2 T) \\Big| \\mathcal{F}_t\\right]\n$$\nTo evaluate this, we decompose $W_T = W_t + (W_T - W_t)$. The increment $W_T - W_t$ is independent of $\\mathcal{F}_t$ and follows a normal distribution $N(0, T-t)$.\n\\begin{align*}\n\\mathbb{E}\\left[\\exp(\\theta W_T) \\Big| \\mathcal{F}_t\\right] &= \\mathbb{E}\\left[\\exp(\\theta(W_t + W_T - W_t)) \\Big| \\mathcal{F}_t\\right] \\\\\n&= \\exp(\\theta W_t) \\mathbb{E}\\left[\\exp(\\theta(W_T - W_t)) \\Big| \\mathcal{F}_t\\right] \\\\\n&= \\exp(\\theta W_t) \\mathbb{E}\\left[\\exp(\\theta(W_T - W_t))\\right] \\\\\n&= \\exp(\\theta W_t) \\exp\\left(\\tfrac{1}{2}\\theta^2(T-t)\\right)\n\\end{align*}\nSubstituting this back into the expression for $\\varphi_t$:\n$$\n\\varphi_t = \\theta \\exp(-\\tfrac{1}{2}\\theta^2 T) \\left( \\exp(\\theta W_t) \\exp\\left(\\tfrac{1}{2}\\theta^2(T-t)\\right) \\right) = \\theta \\exp(\\theta W_t - \\tfrac{1}{2}\\theta^2 t)\n$$\nThus, the integrand is the process $\\varphi_t = \\theta \\exp(\\theta W_t - \\tfrac{1}{2}\\theta^2 t)$.\n\n**Part 3: Verification**\n\nWe must verify that the first-order chaos kernel of $X$ coincides with the zeroth-chaos component of the integrand $\\varphi_t$.\n\nThe Wiener chaos expansion of $X$ is $X = \\sum_{n=0}^{\\infty} I_n(f_n)$, with kernels $f_n(t_1, \\dots, t_n) = \\frac{\\theta^n}{n!} \\mathbf{1}_{[0,T]^n}(t_1, \\dots, t_n)$. The first-order chaos kernel ($n=1$) is:\n$$\nf_1(t_1) = \\frac{\\theta^1}{1!} \\mathbf{1}_{[0,T]}(t_1) = \\theta \\, \\mathbf{1}_{[0,T]}(t_1)\n$$\nThis is the function which is equal to the constant $\\theta$ for $t_1 \\in [0,T]$ and $0$ otherwise.\n\nNow, we find the zeroth-chaos component of the integrand process $\\varphi_t = \\theta \\exp(\\theta W_t - \\frac{1}{2}\\theta^2 t)$. The zeroth-chaos component of a random process is its expectation.\n$$\n\\text{Zeroth-chaos component of } \\varphi_t = \\mathbb{E}[\\varphi_t] = \\mathbb{E}\\left[\\theta \\exp(\\theta W_t - \\tfrac{1}{2}\\theta^2 t)\\right]\n$$\nSince $W_t \\sim N(0,t)$, its moment generating function is $\\mathbb{E}[\\exp(\\theta W_t)]=\\exp(\\frac{1}{2}\\theta^2 t)$.\n$$\n\\mathbb{E}[\\varphi_t] = \\theta \\exp(-\\tfrac{1}{2}\\theta^2 t) \\mathbb{E}[\\exp(\\theta W_t)] = \\theta \\exp(-\\tfrac{1}{2}\\theta^2 t) \\exp(\\tfrac{1}{2}\\theta^2 t) = \\theta\n$$\nThe zeroth-chaos component of the process $\\varphi_t$ is the deterministic function $g(t) = \\theta$ for all $t \\in [0,T]$.\n\nComparing the two results:\n- The first-order kernel of $X$ is the function $f_1(t) = \\theta$ for $t \\in [0,T]$.\n- The zeroth-chaos component of $\\varphi_t$ is the function $g(t) = \\theta$ for $t \\in [0,T]$.\n\nThe two functions are identical on the interval $[0,T]$. The verification is complete.\n\nThe final answer required is the explicit closed-form expression of the Wiener chaos expansion of $X$. Based on Part 1, this is:\n$$\nX = \\sum_{n=0}^{\\infty} \\frac{\\theta^n}{n!} I_n\\left(\\mathbf{1}_{[0,T]}^{\\otimes n}\\right)\n$$\nwhere $I_n$ is the $n$-th multiple Wiener-Itô integral and $\\mathbf{1}_{[0,T]}^{\\otimes n}$ is the symmetric kernel given by $\\mathbf{1}_{[0,T]}^{\\otimes n}(t_1, \\dots, t_n) = \\prod_{i=1}^n \\mathbf{1}_{[0,T]}(t_i)$.", "answer": "$$\n\\boxed{\\sum_{n=0}^{\\infty} \\frac{\\theta^n}{n!} I_n\\left(\\mathbf{1}_{[0,T]}^{\\otimes n}\\right)}\n$$", "id": "2986772"}]}