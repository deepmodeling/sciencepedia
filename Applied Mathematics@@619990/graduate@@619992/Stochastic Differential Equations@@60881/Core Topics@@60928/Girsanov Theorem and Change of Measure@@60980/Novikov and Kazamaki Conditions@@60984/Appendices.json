{"hands_on_practices": [{"introduction": "This first practice serves as a fundamental warm-up for applying martingality conditions. We will explore a scenario with a deterministic integrand, which represents the simplest non-trivial case for a stochastic integral. By directly computing the components of Novikov's condition [@problem_id:2989059], you will see why it is readily satisfied on any finite time horizon for such processes, providing a solid foundation before we tackle more complex stochastic integrands.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\ge 0},\\mathbb{P})$ be a filtered probability space supporting a standard Brownian motion $W$. Fix an integer $m \\ge 0$ and define the deterministic function $\\theta:[0,\\infty) \\to \\mathbb{R}$ by $\\theta_t = 1 + t^{m}$. Consider the continuous local martingale $M_t = \\int_{0}^{t} \\theta_s \\, dW_s$ and its Doléans–Dade exponential $Z_t = \\exp\\!\\big(M_t - \\tfrac{1}{2}\\langle M \\rangle_t\\big)$, where $\\langle M \\rangle_t = \\int_{0}^{t} \\theta_s^{2} \\, ds$ denotes the quadratic variation of $M$.\n\nStarting from the definition of the Itô integral for deterministic integrands and well-known properties of the normal distribution, do the following:\n\n1. Prove that $\\theta$ has polynomial growth and that $\\int_{0}^{T} \\theta_s^{2} \\, ds < \\infty$ for every finite $T>0$.\n2. Use this to justify that Novikov’s condition $\\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2}\\int_{0}^{T} \\theta_s^{2} \\, ds\\right)\\right] < \\infty$ holds for every finite $T>0$.\n3. Compute the exact value of $\\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2}\\int_{0}^{T} \\theta_s^{2} \\, ds\\right)\\right]$ as a closed-form expression in terms of $T$ and $m$.\n4. Derive explicit bounds in $T$ and $m$ for this expectation, including an upper bound of the form $\\exp\\!\\big(\\tfrac{1}{2} K_m T^{2m+1}\\big)$ that is valid for all $T \\ge 1$, where $K_m$ is an explicit constant depending only on $m$.\n\nYour final reported answer must be the exact closed-form expression obtained in item 3, expressed as a function of $T$ and $m$. No rounding is required.", "solution": "The problem statement is critically evaluated for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- A filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\ge 0},\\mathbb{P})$.\n- A standard one-dimensional Brownian motion $W = (W_t)_{t \\ge 0}$.\n- A fixed integer $m \\ge 0$.\n- A deterministic function $\\theta:[0,\\infty) \\to \\mathbb{R}$ defined by $\\theta_t = 1 + t^{m}$.\n- A continuous local martingale $M_t = \\int_{0}^{t} \\theta_s \\, dW_s$.\n- The Doléans–Dade exponential of $M$, given by $Z_t = \\exp\\!\\big(M_t - \\tfrac{1}{2}\\langle M \\rangle_t\\big)$.\n- The quadratic variation of $M$, given by $\\langle M \\rangle_t = \\int_{0}^{t} \\theta_s^{2} \\, ds$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is situated in the well-established mathematical framework of Itô calculus and martingale theory. All terms and concepts—filtered probability space, Brownian motion, Itô integral, quadratic variation, Doléans–Dade exponential, and Novikov's condition—are standard and rigorously defined in this field. The function $\\theta_t = 1 + t^{m}$ is a simple, deterministic polynomial, which is a common choice for an integrand in textbook examples. The tasks are sequential, logical, and involve direct application and verification of theoretical principles.\n\n1.  **Scientific or Factual Unsoundness**: The problem is mathematically sound and adheres to the established principles of stochastic calculus.\n2.  **Non-Formalizable or Irrelevant**: The problem is a formal mathematical exercise directly relevant to the topic of martingales and stochastic exponentials.\n3.  **Incomplete or Contradictory Setup**: The problem is self-contained. All necessary definitions and constraints (e.g., $m \\ge 0$ is an integer) are provided. There are no contradictions.\n4.  **Unrealistic or Infeasible**: Not applicable, as the problem is purely mathematical.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-posed, with tasks that lead to a unique and meaningful solution.\n6.  **Pseudo-Profound, Trivial, or Tautological**: While the verification of Novikov's condition for a deterministic integrand is straightforward, it tests a crucial understanding of the theory. The subsequent calculations require non-trivial integration and algebraic manipulation. The problem is substantive.\n7.  **Outside Scientific Verifiability**: All claims can be rigorously proven using standard mathematical methods.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Solution Derivation\n\nThe solution will be structured according to the four tasks specified in the problem statement.\n\n**1. Polynomial Growth and Integrability of $\\theta_t$**\n\nThe function is given by $\\theta_t = 1 + t^{m}$ for $t \\ge 0$ and an integer $m \\ge 0$.\nA function $f(t)$ is said to have polynomial growth if there exist constants $C > 0$ and $k \\ge 0$ such that $|f(t)| \\le C(1+|t|)^k$ for all $t$ in its domain. For $\\theta_t$, its absolute value on $[0, \\infty)$ is $|\\theta_t| = 1+t^m$. We can choose $C=1$ and $k=m$. Then $|\\theta_t| = 1+t^m \\le (1+t)^m + 1$. A simpler bound is $|\\theta_t| = 1+t^m$ for $t \\ge 0$, which directly proves polynomial growth. Since $m \\ge 0$ is an integer, $\\theta_t$ is a polynomial in $t$, which by definition has polynomial growth.\n\nNext, we must show that $\\int_{0}^{T} \\theta_s^{2} \\, ds < \\infty$ for every finite $T>0$.\nThe integrand is $\\theta_s^2 = (1+s^m)^2 = 1 + 2s^m + s^{2m}$.\nThis is a continuous polynomial function of $s$. The definite integral of a continuous function over a finite interval $[0, T]$ is always finite. Explicitly computing the integral, we have:\n$$\n\\int_{0}^{T} \\theta_s^{2} \\, ds = \\int_{0}^{T} (1 + 2s^m + s^{2m}) \\, ds\n$$\nSince $m \\ge 0$ is an integer, $m+1 \\ge 1$ and $2m+1 \\ge 1$. Thus, the integration is straightforward:\n$$\n\\int_{0}^{T} (1 + 2s^m + s^{2m}) \\, ds = \\left[s + \\frac{2s^{m+1}}{m+1} + \\frac{s^{2m+1}}{2m+1}\\right]_0^T\n$$\n$$\n= \\left(T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\\right) - (0) = T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\n$$\nFor any finite $T>0$ and integer $m \\ge 0$, this expression evaluates to a finite real number. This completes the first part.\n\n**2. Justification of Novikov’s Condition**\n\nNovikov's condition for $M_t = \\int_0^t \\theta_s dW_s$ to be a martingale up to time $T$ is given by:\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\langle M \\rangle_T\\right)\\right] < \\infty\n$$\nwhere $\\langle M \\rangle_T = \\int_{0}^{T} \\theta_s^{2} \\, ds$.\nA crucial point here is that the integrand $\\theta_s$ is a **deterministic** function of time. Consequently, its quadratic variation, $\\langle M \\rangle_T$, is also a deterministic quantity, not a random variable.\nFrom part 1, we calculated this deterministic value:\n$$\n\\langle M \\rangle_T = \\int_{0}^{T} \\theta_s^{2} \\, ds = T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\n$$\nLet us denote this finite constant by $C(T, m)$. The expectation in Novikov's condition becomes:\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2} C(T, m)\\right)\\right]\n$$\nThe expression inside the expectation, $\\exp(\\frac{1}{2} C(T, m))$, is a constant with respect to the probability measure $\\mathbb{P}$. The expectation of a constant is the constant itself. Therefore:\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\langle M \\rangle_T\\right)\\right] = \\exp\\!\\left(\\frac{1}{2}\\langle M \\rangle_T\\right) = \\exp\\!\\left(\\frac{1}{2}\\left(T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\\right)\\right)\n$$\nSince we established in part 1 that $\\langle M \\rangle_T$ is a finite number for any finite $T>0$, its exponential is also a finite positive number. Thus, Novikov's condition $\\mathbb{E}[\\exp(\\frac{1}{2}\\langle M \\rangle_T)] < \\infty$ is satisfied for all finite $T>0$. This implies that $Z_t$ is a true martingale on any interval $[0, T]$.\n\n**3. Exact Value of the Expectation**\n\nThe task is to compute the exact value of $\\mathbb{E}[\\exp(\\frac{1}{2}\\int_{0}^{T} \\theta_s^{2} \\, ds)]$. As established in part 2, this is simply $\\exp(\\frac{1}{2}\\int_{0}^{T} \\theta_s^{2} \\, ds)$. Using the result of the integral from part 1:\n$$\n\\int_{0}^{T} \\theta_s^{2} \\, ds = T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\n$$\nTherefore, the exact value of the expectation is:\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\int_{0}^{T} \\theta_s^{2} \\, ds\\right)\\right] = \\exp\\left(\\frac{1}{2}\\left(T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\\right)\\right)\n$$\nThis expression can be rewritten as:\n$$\n\\exp\\left(\\frac{T}{2} + \\frac{T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2(2m+1)}\\right)\n$$\nThis is the closed-form expression required.\n\n**4. Explicit Bounds for the Expectation**\n\nWe need to find a constant $K_m$ such that for all $T \\ge 1$:\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\int_{0}^{T} \\theta_s^{2} \\, ds\\right)\\right] \\le \\exp\\!\\big(\\tfrac{1}{2} K_m T^{2m+1}\\big)\n$$\nTaking the natural logarithm of both sides, this inequality is equivalent to:\n$$\n\\frac{1}{2}\\left(T + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1}\\right) \\le \\frac{1}{2} K_m T^{2m+1}\n$$\n$$\nT + \\frac{2T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2m+1} \\le K_m T^{2m+1}\n$$\nSince $T \\ge 1$, we can divide by $T^{2m+1}$ without changing the inequality direction:\n$$\n\\frac{T}{T^{2m+1}} + \\frac{2T^{m+1}}{(m+1)T^{2m+1}} + \\frac{T^{2m+1}}{(2m+1)T^{2m+1}} \\le K_m\n$$\n$$\n\\frac{1}{T^{2m}} + \\frac{2}{(m+1)T^m} + \\frac{1}{2m+1} \\le K_m\n$$\nLet $f(T) = \\frac{1}{T^{2m}} + \\frac{2}{(m+1)T^m} + \\frac{1}{2m+1}$. We need to find an upper bound for $f(T)$ for $T \\ge 1$.\nThe derivative with respect to $T$ is $f'(T) = -2m T^{-2m-1} - \\frac{2m}{(m+1)}T^{-m-1}$.\nIf $m=0$, then $f'(T)=0$ and $f(T) = 1 + 2 + 1 = 4$. So we can take $K_0=4$.\nIf $m>0$, then both terms in $f'(T)$ are negative for $T>0$. Thus, $f(T)$ is a strictly decreasing function of $T$ for $T \\ge 1$.\nThe maximum value of $f(T)$ on the interval $[1, \\infty)$ must therefore occur at the left endpoint, $T=1$.\n$$\n\\sup_{T \\ge 1} f(T) = f(1) = \\frac{1}{1^{2m}} + \\frac{2}{(m+1)1^m} + \\frac{1}{2m+1} = 1 + \\frac{2}{m+1} + \\frac{1}{2m+1}\n$$\nWe can choose $K_m$ to be this value:\n$$\nK_m = 1 + \\frac{2}{m+1} + \\frac{1}{2m+1}\n$$\nThis is an explicit constant depending only on $m$, as required. For example, if $m=1$, $K_1 = 1 + \\frac{2}{2} + \\frac{1}{3} = 2 + \\frac{1}{3} = \\frac{7}{3}$.\nThis upper bound is valid for all $T \\ge 1$.", "answer": "$$\\boxed{\\exp\\left(\\frac{T}{2} + \\frac{T^{m+1}}{m+1} + \\frac{T^{2m+1}}{2(2m+1)}\\right)}$$", "id": "2989059"}, {"introduction": "Novikov's condition is a powerful tool, but is it the final word on martingality for stochastic exponentials? This exercise explores that question by constructing a compelling counterexample [@problem_id:2989055]. You will demonstrate that even when Novikov's condition fails spectacularly, the Doléans-Dade exponential $\\mathcal{E}(M)$ can still be a true martingale, highlighting that this famous condition is sufficient, but not necessary. This practice deepens your understanding of the subtle interplay between local and true martingales.", "problem": "Let $\\left(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\geq 0},\\mathbb{P}\\right)$ be a filtered probability space supporting a standard one-dimensional Brownian motion $W=(W_{t})_{t\\geq 0}$ and an $\\mathcal{F}_{0}$-measurable random variable $X$ that is independent of $W$ and is standard normal. Fix a finite time horizon $T$ with $T\\geq 1$. Define the continuous local martingale $M=(M_{t})_{t\\in[0,T]}$ by\n$$\nM_{t} \\equiv \\int_{0}^{t} X\\, dW_{s} = X\\,W_{t},\n$$\nand its quadratic variation by $\\langle M\\rangle_{t}=\\int_{0}^{t} X^{2}\\, ds=X^{2}t$. Consider the Doléans–Dade exponential of $M$, namely\n$$\n\\mathcal{E}(M)_{t} \\equiv \\exp\\!\\left(M_{t}-\\tfrac{1}{2}\\langle M\\rangle_{t}\\right)=\\exp\\!\\left(XW_{t}-\\tfrac{1}{2}X^{2}t\\right), \\quad t\\in[0,T].\n$$\nStarting only from the definitions of quadratic variation, conditional expectation, and the independence of $X$ and $W$, and using only well-tested properties of the Gaussian distribution, do the following:\n- Show that Novikov’s condition fails on $[0,T]$ by proving that\n$$\n\\mathbb{E}\\left[\\exp\\!\\left(\\tfrac{1}{2}\\langle M\\rangle_{T}\\right)\\right]=\\mathbb{E}\\left[\\exp\\!\\left(\\tfrac{1}{2}X^{2}T\\right)\\right]=\\infty.\n$$\n- Show nevertheless that $\\mathcal{E}(M)$ is a true martingale on $[0,T]$ by computing $\\mathbb{E}\\left[\\mathcal{E}(M)_{T}\\right]$ via conditioning on $X$.\n\nWhat is the value of $\\mathbb{E}\\left[\\mathcal{E}(M)_{T}\\right]$? Provide your final answer as a single exact number with no units.", "solution": "The problem requires us to analyze the martingale properties of a specific Doléans-Dade exponential, $\\mathcal{E}(M)_{t}$, on a finite time horizon $[0,T]$ where $T \\geq 1$. We are given a continuous local martingale $M_{t} = X W_{t}$, where $X \\sim N(0,1)$ is an $\\mathcal{F}_{0}$-measurable random variable independent of the standard one-dimensional Brownian motion $W=(W_{t})_{t\\geq 0}$. The quadratic variation of $M$ is $\\langle M \\rangle_{t} = X^2 t$. The Doléans-Dade exponential is $\\mathcal{E}(M)_{t} = \\exp(XW_{t}-\\frac{1}{2}X^{2}t)$.\n\nFirst, we will demonstrate that Novikov's condition fails for the given process on the interval $[0,T]$. Novikov's condition provides a sufficient criterion for the Doléans-Dade exponential of a continuous local martingale to be a true martingale. The condition states that if $\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M\\rangle_{T}\\right)\\right] < \\infty$, then $\\mathcal{E}(M)$ is a uniformly integrable martingale on $[0,T]$. We are asked to show this condition does not hold.\nSubstituting the given quadratic variation $\\langle M \\rangle_{T} = X^2 T$, the expression becomes:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\tfrac{1}{2}\\langle M\\rangle_{T}\\right)\\right] = \\mathbb{E}\\left[\\exp\\left(\\tfrac{1}{2}X^{2}T\\right)\\right].\n$$\nTo compute this expectation, we use the fact that $X$ is a standard normal random variable, $X \\sim N(0,1)$, with probability density function (PDF) $f_{X}(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{x^2}{2})$. The expectation is calculated by integrating against this density:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\tfrac{1}{2}X^{2}T\\right)\\right] = \\int_{-\\infty}^{\\infty} \\exp\\left(\\tfrac{1}{2}x^{2}T\\right) f_{X}(x) \\, dx = \\int_{-\\infty}^{\\infty} \\exp\\left(\\tfrac{1}{2}x^{2}T\\right) \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\tfrac{x^2}{2}\\right) \\, dx.\n$$\nCombining the exponential terms, we get:\n$$\n\\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} \\exp\\left(\\tfrac{1}{2}x^{2}T - \\tfrac{1}{2}x^{2}\\right) \\, dx = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} \\exp\\left(\\tfrac{1}{2}x^{2}(T-1)\\right) \\, dx.\n$$\nThe problem specifies that $T \\geq 1$. We must analyze the convergence of this integral.\nIf $T=1$, the exponent is $0$, and the integral becomes:\n$$\n\\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} \\exp(0) \\, dx = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} 1 \\, dx = \\infty.\n$$\nIf $T > 1$, the term $T-1$ is strictly positive. The integrand $\\exp\\left(\\frac{1}{2}x^{2}(T-1)\\right)$ grows exponentially as $|x| \\to \\infty$. Consequently, the integral does not converge.\nIn both cases, for $T \\geq 1$, the expectation is infinite:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\tfrac{1}{2}\\langle M\\rangle_{T}\\right)\\right] = \\infty.\n$$\nThis demonstrates that Novikov's condition fails on the interval $[0,T]$.\n\nNext, we will show that $\\mathcal{E}(M)$ is nonetheless a true martingale on $[0,T]$. A continuous local martingale $L=(L_t)_{t\\ge 0}$ is a true martingale on $[0,T]$ if and only if $\\mathbb{E}[L_t] = L_0$ for all $t \\in [0,T]$. It is sufficient to show that $\\mathbb{E}[\\mathcal{E}(M)_T] = \\mathcal{E}(M)_0$.\nFirst, let's compute $\\mathcal{E}(M)_0$. At $t=0$, we have $W_0=0$, so $M_0 = XW_0 = 0$ and $\\langle M \\rangle_0 = X^2 \\cdot 0 = 0$. Therefore,\n$$\n\\mathcal{E}(M)_0 = \\exp(M_0 - \\tfrac{1}{2}\\langle M \\rangle_0) = \\exp(0 - 0) = 1.\n$$\nNow we must compute $\\mathbb{E}[\\mathcal{E}(M)_T]$ and show it equals $1$. We have:\n$$\n\\mathbb{E}\\left[\\mathcal{E}(M)_{T}\\right] = \\mathbb{E}\\left[\\exp\\left(XW_{T}-\\tfrac{1}{2}X^{2}T\\right)\\right].\n$$\nWe use the law of total expectation (the tower property) by conditioning on the random variable $X$. Since $X$ and the process $W$ are independent, this is a potent tool.\n$$\n\\mathbb{E}\\left[\\mathcal{E}(M)_{T}\\right] = \\mathbb{E}\\left[\\mathbb{E}\\left[\\exp\\left(XW_{T}-\\tfrac{1}{2}X^{2}T\\right) \\bigg| X\\right]\\right].\n$$\nLet's evaluate the inner conditional expectation. For a given realization $X=x$, this is:\n$$\n\\mathbb{E}\\left[\\exp\\left(xW_{T}-\\tfrac{1}{2}x^{2}T\\right) \\bigg| X=x\\right] = \\mathbb{E}\\left[\\exp\\left(xW_{T}-\\tfrac{1}{2}x^{2}T\\right)\\right]\n$$\nwhere the equality holds due to the independence of $W_T$ and $X$. We can factor out the term that does not depend on $W_T$:\n$$\n\\exp\\left(-\\tfrac{1}{2}x^{2}T\\right) \\mathbb{E}\\left[\\exp(xW_{T})\\right].\n$$\nThe term $\\mathbb{E}[\\exp(xW_{T})]$ is the moment-generating function (MGF) of the random variable $W_T$, evaluated at $x$. Since $W$ is a standard Brownian motion, $W_T$ is a normally distributed random variable with mean $0$ and variance $T$, i.e., $W_T \\sim N(0,T)$. The MGF of a general normal random variable $Z \\sim N(\\mu, \\sigma^2)$ is $M_Z(s) = \\exp(\\mu s + \\frac{1}{2}\\sigma^2 s^2)$. For $W_T$, we have $\\mu=0$ and $\\sigma^2=T$. Thus, its MGF is $M_{W_T}(s) = \\exp(\\frac{1}{2}Ts^2)$. Evaluating at $s=x$:\n$$\n\\mathbb{E}\\left[\\exp(xW_{T})\\right] = \\exp\\left(\\tfrac{1}{2}Tx^2\\right).\n$$\nSubstituting this result back into the expression for the conditional expectation, we obtain:\n$$\n\\exp\\left(-\\tfrac{1}{2}x^{2}T\\right) \\cdot \\exp\\left(\\tfrac{1}{2}Tx^2\\right) = \\exp(0) = 1.\n$$\nThis shows that the conditional expectation $\\mathbb{E}[\\mathcal{E}(M)_{T} | X]$ is equal to $1$ almost surely.\nFinally, we take the expectation over $X$:\n$$\n\\mathbb{E}\\left[\\mathcal{E}(M)_{T}\\right] = \\mathbb{E}\\left[1\\right] = 1.\n$$\nSince $\\mathbb{E}[\\mathcal{E}(M)_T] = 1 = \\mathcal{E}(M)_0$, we have proven that $\\mathcal{E}(M)$ is a true martingale on the interval $[0,T]$. This result illustrates that Novikov's condition is a sufficient, but not a necessary, condition for a local martingale to be a true martingale.\n\nThe value of $\\mathbb{E}\\left[\\mathcal{E}(M)_{T}\\right]$ is therefore $1$.", "answer": "$$\\boxed{1}$$", "id": "2989055"}, {"introduction": "Having seen that Novikov's condition is not necessary, we now turn to a weaker, yet still sufficient, criterion: the Kazamaki condition. This hands-on problem asks you to build a process where Novikov's condition fails, but the martingale property can still be established using this alternative test [@problem_id:2989058]. By explicitly calculating the required exponential moments, you will directly contrast the two conditions and appreciate how Kazamaki's condition expands our toolkit for analyzing changes of measure.", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion on a filtered probability space satisfying the usual conditions, and fix a deterministic time horizon $T>0$. Define the predictable process $\\theta = \\{\\theta_{t}\\}_{0 \\leq t \\leq T}$ by\n$$\n\\theta_{t} \\coloneqq \\frac{3}{T}\\,|W_{T/2}|\\,\\mathbf{1}_{(T/2,\\,T]}(t),\n$$\nand define the continuous local martingale\n$$\nM_{t} \\coloneqq \\int_{0}^{t} \\theta_{s}\\,dW_{s}, \\qquad 0 \\leq t \\leq T.\n$$\nYou may use only the following fundamental inputs: the definition of the Itô integral, the independent increments and Gaussianity of Brownian motion, the tower property of conditional expectation, and the elementary Gaussian integral\n$$\n\\int_{\\mathbb{R}} \\exp\\!\\Big(-\\frac{x^{2}}{2\\sigma^{2}}+\\beta x\\Big)\\,\\frac{dx}{\\sqrt{2\\pi\\sigma^{2}}} \\;=\\; \\exp\\!\\Big(\\frac{\\beta^{2}\\sigma^{2}}{2}\\Big)\n$$\ntogether with its specialization to compute $\\mathbb{E}[\\exp(\\alpha Z^{2})]$ when $Z \\sim \\mathcal{N}(0,\\sigma^{2})$ and the condition for its finiteness.\n\nTasks:\n- Derive the quadratic variation $\\langle M \\rangle_{T}$ explicitly in terms of $W_{T/2}$.\n- Using first principles, determine whether Novikov’s condition $\\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2}\\langle M \\rangle_{T}\\right)\\right] < \\infty$ holds or fails.\n- Using first principles, determine whether Kazamaki’s condition holds on $[0,T]$ by verifying that $\\{\\exp(\\tfrac{1}{2}M_{t})\\}_{0 \\leq t \\leq T}$ is a submartingale with finite expectation at time $T$.\n- Compute the exact value of the exponential moment $\\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2} M_{T}\\right)\\right]$.\n\nGive your final answer for $\\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2} M_{T}\\right)\\right]$ as a single exact expression. No rounding is required.", "solution": "We proceed step by step from the stated fundamentals.\n\n1) Quadratic variation. Since $\\theta_{t} = 0$ for $t \\leq T/2$ and $\\theta_{t} = \\frac{3}{T}|W_{T/2}|$ (which is $\\mathcal{F}_{T/2}$-measurable) for $t \\in (T/2, T]$, the Itô integral reduces to\n$$\nM_{t} \\;=\\; \\int_{T/2}^{t} \\frac{3}{T}\\,|W_{T/2}|\\,dW_{s}, \\qquad t \\in [T/2, T],\n$$\nand $M_{t}=0$ for $t \\leq T/2$. Hence the quadratic variation is\n$$\n\\langle M \\rangle_{T}\n\\;=\\; \\int_{0}^{T} \\theta_{s}^{2}\\,ds\n\\;=\\; \\int_{T/2}^{T} \\Big(\\frac{3}{T}\\,|W_{T/2}|\\Big)^{2}\\,ds\n\\;=\\; \\frac{9}{T^{2}}\\,W_{T/2}^{2}\\,\\Big(T - \\frac{T}{2}\\Big)\n\\;=\\; \\frac{9}{2T}\\,W_{T/2}^{2}.\n$$\n\n2) Novikov’s condition. Novikov’s condition on $[0,T]$ asks whether\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\langle M \\rangle_{T}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\cdot \\frac{9}{2T}\\,W_{T/2}^{2}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{4T}\\,W_{T/2}^{2}\\right)\\right]\n$$\nis finite. Since $W_{T/2} \\sim \\mathcal{N}(0, T/2)$, write $W_{T/2} = \\sqrt{T/2}\\,Z$ with $Z \\sim \\mathcal{N}(0,1)$. Then\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{4T}\\,W_{T/2}^{2}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{4T}\\cdot \\frac{T}{2}\\,Z^{2}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{8}\\,Z^{2}\\right)\\right].\n$$\nFor a centered normal $Z$ with variance $1$, the standard Gaussian integral yields\n$$\n\\mathbb{E}\\!\\left[\\exp(\\alpha Z^{2})\\right]\n=\n\\begin{cases}\n\\frac{1}{\\sqrt{1-2\\alpha}}, & \\text{if } \\alpha < \\frac{1}{2}, \\\\\n\\infty, & \\text{if } \\alpha \\ge \\frac{1}{2}.\n\\end{cases}\n$$\nHere $\\alpha = 9/8 > 1/2$, hence\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\langle M \\rangle_{T}\\right)\\right] \\;=\\; \\infty,\n$$\nso Novikov’s condition fails on $[0,T]$.\n\n3) Kazamaki’s condition. First, we show that $\\{\\exp(\\frac{1}{2}M_{t})\\}_{0 \\le t \\le T}$ is a submartingale. For $0 \\le s \\le t \\le T$, using the independent increments of Brownian motion and the fact that $M_{t}-M_{s}$ is conditionally centered Gaussian with variance $\\langle M \\rangle_{t}-\\langle M \\rangle_{s}$ that is $\\mathcal{F}_{s}$-measurable, we obtain\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}M_{t}\\right)\\Big|\\mathcal{F}_{s}\\right]\n\\;=\\; \\exp\\!\\left(\\frac{1}{2}M_{s}\\right)\\,\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}(M_{t}-M_{s})\\right)\\Big|\\mathcal{F}_{s}\\right]\n\\;=\\; \\exp\\!\\left(\\frac{1}{2}M_{s}\\right)\\,\\exp\\!\\left(\\frac{1}{8}\\big(\\langle M \\rangle_{t}-\\langle M \\rangle_{s}\\big)\\right)\n\\;\\ge\\; \\exp\\!\\left(\\frac{1}{2}M_{s}\\right).\n$$\nThus $\\exp(\\frac{1}{2}M_{t})$ is a nonnegative submartingale. To verify Kazamaki’s condition on $[0,T]$ it suffices to show $\\mathbb{E}[\\exp(\\frac{1}{2}M_{T})] < \\infty$, because then by the submartingale property and the optional sampling theorem for bounded stopping times $\\tau \\le T$,\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2}M_{\\tau}\\right)\\right]\n\\;\\le\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\tfrac{1}{2}M_{T}\\right)\\right]\n\\;<\\;\\infty.\n$$\nHence Kazamaki’s condition holds provided $\\mathbb{E}[\\exp(\\frac{1}{2}M_{T})] < \\infty$; we now compute this quantity explicitly.\n\n4) Exact computation of $\\mathbb{E}[\\exp(\\frac{1}{2}M_{T})]$. For $t \\in (T/2, T]$,\n$$\nM_{t}\n\\;=\\; \\int_{T/2}^{t} \\frac{3}{T}\\,|W_{T/2}|\\,dW_{s}\n\\;=\\; \\frac{3}{T}\\,|W_{T/2}|\\,\\big(W_{t}-W_{T/2}\\big),\n$$\nso\n$$\nM_{T}\n\\;=\\; \\frac{3}{T}\\,|W_{T/2}|\\,\\big(W_{T}-W_{T/2}\\big).\n$$\nConditionally on $\\mathcal{F}_{T/2}$, the increment $W_{T}-W_{T/2}$ is $\\mathcal{N}(0, T/2)$ and independent of $\\mathcal{F}_{T/2}$. Therefore, conditionally on $\\mathcal{F}_{T/2}$, $M_{T}$ is centered Gaussian with variance\n$$\n\\operatorname{Var}(M_{T}\\,|\\,\\mathcal{F}_{T/2})\n\\;=\\; \\Big(\\frac{3}{T}\\,|W_{T/2}|\\Big)^{2}\\cdot \\frac{T}{2}\n\\;=\\; \\frac{9}{2T}\\,W_{T/2}^{2}\n\\;=\\; \\langle M \\rangle_{T}.\n$$\nUsing the Gaussian moment generating function for a centered normal with variance $v$, $\\mathbb{E}[\\exp(\\lambda X)\\,|\\,v] = \\exp(\\frac{1}{2}\\lambda^{2} v)$, we obtain\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}M_{T}\\right)\\Big|\\mathcal{F}_{T/2}\\right]\n\\;=\\; \\exp\\!\\left(\\frac{1}{2}\\cdot \\frac{1}{4}\\,\\langle M \\rangle_{T}\\right)\n\\;=\\; \\exp\\!\\left(\\frac{1}{8}\\,\\langle M \\rangle_{T}\\right).\n$$\nTaking expectations and substituting the expression for $\\langle M \\rangle_{T}$,\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}M_{T}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{8}\\cdot \\frac{9}{2T}\\,W_{T/2}^{2}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{16T}\\,W_{T/2}^{2}\\right)\\right].\n$$\nAgain write $W_{T/2} = \\sqrt{T/2}\\,Z$ with $Z \\sim \\mathcal{N}(0,1)$:\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{16T}\\,W_{T/2}^{2}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{16T}\\cdot \\frac{T}{2}\\,Z^{2}\\right)\\right]\n\\;=\\; \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{9}{32}\\,Z^{2}\\right)\\right].\n$$\nUsing the Gaussian integral for $\\mathbb{E}[\\exp(\\alpha Z^{2})]$ with $\\alpha = 9/32$, which satisfies $2\\alpha = 9/16 < 1$, we have\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}M_{T}\\right)\\right]\n\\;=\\; \\frac{1}{\\sqrt{1 - 2\\alpha}}\n\\;=\\; \\frac{1}{\\sqrt{1 - \\frac{9}{16}}}\n\\;=\\; \\frac{1}{\\sqrt{\\frac{7}{16}}}\n\\;=\\; \\frac{4}{\\sqrt{7}}.\n$$\n\nSummary:\n- $\\langle M \\rangle_{T} = \\frac{9}{2T}\\,W_{T/2}^{2}$.\n- Novikov’s condition fails because $\\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2}\\langle M \\rangle_{T}\\right)\\right] = \\infty$.\n- Kazamaki’s condition holds since $\\exp(\\frac{1}{2}M_{t})$ is a submartingale and $\\mathbb{E}[\\exp(\\frac{1}{2}M_{T})] = 4/\\sqrt{7} < \\infty$.\n- The required exponential moment is exactly $\\mathbb{E}[\\exp(\\frac{1}{2}M_{T})] = 4/\\sqrt{7}$.", "answer": "$$\\boxed{\\frac{4}{\\sqrt{7}}}$$", "id": "2989058"}]}