{"hands_on_practices": [{"introduction": "A deep understanding of reflected processes requires mastering their description through partial differential equations. This first exercise [@problem_id:2993641] addresses a critical and subtle point: the distinction between boundary conditions for the forward (Fokker-Planck) and backward Kolmogorov equations. By deriving the correct zero-flux condition from the principle of probability conservation, you will see why naively applying the generator's boundary conditions to the probability density leads to fundamentally incorrect results.", "problem": "Consider a one-dimensional reflected Itô diffusion on the closed interval $[0,1]$ with normal reflection at both endpoints, defined via the Skorokhod problem as follows. Let $W_t$ be a standard Brownian motion, and let $b:[0,1]\\to\\mathbb{R}$ and $\\sigma:[0,1]\\to(0,\\infty)$ be continuous functions. The reflected process $X_t$ satisfies $X_t\\in[0,1]$ for all $t\\ge 0$ and\n$$\nX_t \\;=\\; X_0 \\;+\\; \\int_0^t b(X_s)\\,ds \\;+\\; \\int_0^t \\sigma(X_s)\\,dW_s \\;+\\; K_t^0 \\;-\\; K_t^1,\n$$\nwhere $K_t^0$ and $K_t^1$ are continuous nondecreasing processes of bounded variation such that $K_0^0=K_0^1=0$, $K_t^0$ increases only when $X_t=0$, and $K_t^1$ increases only when $X_t=1$ (they push the process inward along the inward unit normals at the boundary). This is the canonical Skorokhod decomposition for normal reflection in $[0,1]$.\n\nA common confusion in the literature is to conflate two distinct boundary prescriptions:\n- The backward Kolmogorov boundary condition that characterizes the domain of the infinitesimal generator acting on test functions $f$ for expectations of the form $\\mathbb{E}[f(X_t)]$, which in the presence of normal reflection imposes $f'(0)=f'(1)=0$.\n- The forward Kolmogorov (Fokker–Planck) boundary condition that governs the time evolution of the probability density $p(t,x)$ of $X_t$, which must enforce conservation of probability mass under reflection.\n\nTo expose this confusion, consider the explicit case $b(x)\\equiv 1$ and $\\sigma(x)\\equiv 2$ on $[0,1]$. A purported stationary solution for the density $p(x)$ is presented with the boundary condition $p'(0)=p'(1)=0$ “because the process is reflected,” by appealing to the backward perspective. Your task is to decide, by deriving the correct forward boundary condition from first principles, whether such a Neumann condition on $p$ is appropriate and what boundary condition must replace it.\n\nWhich option correctly states the boundary condition that a stationary density $p(x)$ must satisfy at $x=0$ and $x=1$ for the reflected diffusion above, and thereby identifies the error caused by confusing backward and forward boundary prescriptions?\n\nA. $p'(0)=p'(1)=0$.\n\nB. $p(0)=p(1)=0$.\n\nC. $J(0)=J(1)=0$, where $J(x)=b(x)\\,p(x)-\\dfrac{1}{2}\\,\\partial_x\\big(\\sigma^2(x)\\,p(x)\\big)$ is the probability flux.\n\nD. $J'(0)=J'(1)=0$.\n\nE. $\\sigma^2(0)\\,p'(0)=\\sigma^2(1)\\,p'(1)=0$ (independent of $b$).\n\nAnswer the question by starting from the definitions of the Skorokhod problem, the infinitesimal generator, and probability conservation in the forward equation; derive the forward boundary condition for the density and use the explicit case $b\\equiv 1$, $\\sigma\\equiv 2$ to demonstrate how the incorrect identification of backward and forward boundary prescriptions leads to an erroneous condition on $p$.", "solution": "### Derivation of the Forward Boundary Condition\n\nThe evolution of the probability density function $p(t,x)$ of the process $X_t$ is described by the forward Kolmogorov equation, also known as the Fokker-Planck equation. For a general Itô diffusion, this equation takes the form of a continuity equation:\n$$ \\frac{\\partial p(t,x)}{\\partial t} = - \\frac{\\partial J(t,x)}{\\partial x} $$\nwhere $J(t,x)$ is the probability flux (or probability current). The flux is given by:\n$$ J(t,x) = b(x)p(t,x) - \\frac{1}{2}\\frac{\\partial}{\\partial x}\\left(\\sigma^2(x)p(t,x)\\right) $$\nThe process $X_t$ is confined to the interval $[0,1]$. The reflection at the boundaries $x=0$ and $x=1$ is a physical constraint that prevents probability mass from leaving the domain. This is mathematically expressed by imposing that the probability flux across the boundaries must be zero. Therefore, a reflecting boundary is characterized by the condition:\n$$ J(t,x) = 0 \\quad \\text{at } x=0 \\text{ and } x=1 $$\nThis ensures the conservation of total probability within the interval, as\n$$ \\frac{d}{dt} \\int_0^1 p(t,x)\\,dx = \\int_0^1 \\frac{\\partial p(t,x)}{\\partial t}\\,dx = - \\int_0^1 \\frac{\\partial J(t,x)}{\\partial x}\\,dx = -[J(t,1) - J(t,0)] = -[0 - 0] = 0. $$\nA stationary density, denoted $p(x)$, is a time-independent solution to the Fokker-Planck equation, meaning $\\frac{\\partial p}{\\partial t} = 0$. This implies:\n$$ -\\frac{d J(x)}{dx} = 0 $$\nwhere $J(x)$ is the stationary flux. Integrating with respect to $x$ shows that $J(x)$ must be a constant for all $x \\in [0,1]$. Since the boundary conditions $J(0)=0$ and $J(1)=0$ must hold for any time-independent solution, the constant flux must be zero. Thus, for a reflected process with a stationary distribution, the probability flux is identically zero throughout the domain:\n$$ J(x) = b(x)p(x) - \\frac{1}{2}\\frac{d}{dx}\\left(\\sigma^2(x)p(x)\\right) = 0 \\quad \\text{for all } x \\in [0,1]. $$\nThe boundary conditions are, in particular, $J(0)=0$ and $J(1)=0$. This is the fundamental condition that the stationary density $p(x)$ must satisfy at the boundaries.\n\n### Analysis of the Purported Confusion\n\nThe confusion described in the problem arises from conflating the above forward boundary condition on the density $p(x)$ with the backward boundary condition on test functions $f(x)$ used to define the domain of the infinitesimal generator, $\\mathcal{A}$. The generator is given by:\n$$ \\mathcal{A}f(x) = b(x)f'(x) + \\frac{1}{2}\\sigma^2(x)f''(x) $$\nFor a process with normal reflection at boundaries $x=0$ and $x=1$, the domain of $\\mathcal{A}$ is restricted to functions $f \\in C^2([0,1])$ that satisfy the Neumann boundary conditions:\n$$ f'(0) = 0 \\quad \\text{and} \\quad f'(1) = 0. $$\nThese conditions ensure that the generator properly accounts for the reflection (local time) at the boundaries. The error is to incorrectly impose these conditions, intended for test functions $f$ in the backward formulation, onto the probability density $p$ in the forward formulation.\n\nTo demonstrate the consequence of this error, we use the specific case $b(x)=1$ and $\\sigma(x)=2$.\nThe correct stationary boundary condition is $J(0)=J(1)=0$. The stationary flux is:\n$$ J(x) = 1 \\cdot p(x) - \\frac{1}{2}\\frac{d}{dx}(2^2 p(x)) = p(x) - 2p'(x) $$\nSo, the correct boundary conditions are:\n$$ p(0) - 2p'(0) = 0 \\implies p'(0) = \\frac{1}{2}p(0) $$\n$$ p(1) - 2p'(1) = 0 \\implies p'(1) = \\frac{1}{2}p(1) $$\nThese are Robin-type boundary conditions.\n\nThe incorrect condition, arising from the confusion, would be to set $p'(0)=0$ and $p'(1)=0$. If we substitute these erroneous conditions into the correct physical requirement above, we get:\n- If $p'(0)=0$, then $p(0) - 2(0) = 0 \\implies p(0)=0$.\n- If $p'(1)=0$, then $p(1) - 2(0) = 0 \\implies p(1)=0$.\nThis would lead to Dirichlet boundary conditions ($p(0)=p(1)=0$), which describe a process that is *absorbed* at the boundaries, not reflected. This fundamentally changes the nature of the stochastic process and demonstrates that confusing the backward and forward boundary conditions is a critical error.\n\n### Evaluation of Options\n\n**A. $p'(0)=p'(1)=0$.**\nThis is the Neumann boundary condition that applies to test functions $f$ in the domain of the backward generator. Applying it to the density $p$ is the error the problem aims to expose.\n**Verdict: Incorrect.**\n\n**B. $p(0)=p(1)=0$.**\nThis is a Dirichlet boundary condition, which models absorption at the boundaries. It is not the correct condition for a reflected process. While the erroneous application of the Neumann condition in the specific case implies this result, it is not the fundamental boundary condition for reflection.\n**Verdict: Incorrect.**\n\n**C. $J(0)=J(1)=0$, where $J(x)=b(x)\\,p(x)-\\dfrac{1}{2}\\,\\partial_x\\big(\\sigma^2(x)\\,p(x)\\big)$ is the probability flux.**\nThis is the zero-flux boundary condition. As derived from the first principle of probability conservation for a process confined to an interval, this is the correct condition for reflecting boundaries in the Fokker-Planck formalism. The formula for the flux $J(x)$ is also correctly stated.\n**Verdict: Correct.**\n\n**D. $J'(0)=J'(1)=0$.**\nIn the stationary state, the Fokker-Planck equation reduces to $\\frac{dJ}{dx}=0$ for all $x \\in [0,1]$. This implies $J'(x)=0$ everywhere in the interior, not just at the boundaries. This is a property of the stationary solution, but it is not the boundary condition itself. The physical boundary condition is a constraint on the value of the flux $J$ at the boundary, not its derivative.\n**Verdict: Incorrect.**\n\n**E. $\\sigma^2(0)\\,p'(0)=\\sigma^2(1)\\,p'(1)=0$ (independent of $b$).**\nSince $\\sigma(x)>0$ is given, this is equivalent to $p'(0)=p'(1)=0$, which is option A. This is the erroneous Neumann condition. Furthermore, the claim of independence from the drift $b$ is false, as shown by our derived Robin condition $p'(x) = \\frac{1}{2}p(x)$ for the case $b(x)=1$, which clearly involves the density $p(x)$ and hence is related to the integrated effect of the drift.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{C}$$", "id": "2993641"}, {"introduction": "The Skorokhod problem is not just a theoretical curiosity; it is a cornerstone for modeling complex, constrained systems like communication and manufacturing networks. This practice [@problem_id:2993602] challenges you to apply the theory to a tangible example: a two-station tandem queueing network. You will derive the key components of its limiting Semimartingale Reflected Brownian Motion (SRBM), namely the drift $\\theta$, covariance $\\Gamma$, and reflection matrix $R$, and use them to assess the system's stability, providing a direct link between abstract diffusion theory and practical performance analysis.", "problem": "Consider a two-station tandem open network operating under heavy-traffic diffusion scaling. External customers arrive to station $1$ according to a renewal process with rate $\\lambda = \\frac{9}{10}$ and squared coefficient of variation $c_{a}^{2} = 2$. Service times at stations $1$ and $2$ are independent across jobs and stations, with mean service rates $\\mu_{1} = 1$ and $\\mu_{2} = \\frac{11}{10}$, and squared coefficients of variation $c_{s,1}^{2} = \\frac{3}{2}$ and $c_{s,2}^{2} = \\frac{1}{2}$, respectively. All primitive processes are mutually independent. Jobs departing station $1$ proceed immediately to station $2$ with probability $1$, and jobs departing station $2$ leave the network. Assume First-In–First-Out (FIFO) service at both stations.\n\nUnder diffusion scaling, the centered netput process $W(t)$ for the buffer content vector $Q(t) \\in \\mathbb{R}_{+}^{2}$ is modeled as a two-dimensional Brownian motion with drift vector $\\theta \\in \\mathbb{R}^{2}$ and covariance matrix $\\Gamma \\in \\mathbb{R}^{2 \\times 2}$. The queue-length process is constrained to the nonnegative orthant via an obliquely reflected Skorokhod map, so that\n$$\nQ(t) \\;=\\; Q(0) \\;+\\; W(t) \\;+\\; R\\,Y(t),\n$$\nwhere $R \\in \\mathbb{R}^{2 \\times 2}$ collects the reflection directions as its columns, and $Y(t) \\in \\mathbb{R}_{+}^{2}$ is a vector of nondecreasing regulator processes that increase only when the corresponding component of $Q(t)$ is on the boundary. The reflection directions are assumed to be induced by instantaneous flow conservation consistent with the routing: when reflection occurs at station $1$, a unit of regulator increases buffer $1$ while simultaneously reducing the routed push to buffer $2$; when reflection occurs at station $2$, a unit of regulator increases only buffer $2$ (departures exit the network).\n\nDerive from first principles the data $(\\theta,\\Gamma,R)$ of the semimartingale reflected Brownian motion (SRBM) describing $Q(t)$.\n\nDefine the stability margin\n$$\nm \\;:=\\; \\max\\bigl\\{ \\bigl(R^{-1}\\theta\\bigr)_{1},\\; \\bigl(R^{-1}\\theta\\bigr)_{2} \\bigr\\}.\n$$\nCompute $m$ exactly. Your final answer must be a single exact value (no approximation or rounding). No units are required.", "solution": "The problem requires the derivation of the parameters $(\\theta, \\Gamma, R)$ for a semimartingale reflected Brownian motion (SRBM) that approximates a two-station tandem queueing network in heavy traffic. Subsequently, we must compute the stability margin $m$.\n\nThe system consists of two stations in series. We denote the primitive stochastic processes as follows:\n1.  $A(t)$: The external arrival process to station $1$. This is a renewal process with rate $\\lambda = \\frac{9}{10}$ and squared coefficient of variation (SCV) $c_{a}^{2} = 2$.\n2.  $S_1(t)$: The potential service completion process at station $1$. This is a renewal process with rate $\\mu_1 = 1$ and SCV $c_{s,1}^{2} = \\frac{3}{2}$.\n3.  $S_2(t)$: The potential service completion process at station $2$. This is a renewal process with rate $\\mu_2 = \\frac{11}{10}$ and SCV $c_{s,2}^{2} = \\frac{1}{2}$.\nThese three processes are assumed to be mutually independent.\n\nUnder diffusion scaling, each renewal process $N(t)$ with rate $\\nu$ and SCV $c^2$ is approximated by a Brownian motion with drift: $N(t) \\approx \\nu t + \\sqrt{\\nu c^2} B(t)$, where $B(t)$ is a standard one-dimensional Brownian motion.\n\nThe unconstrained netput process, $W(t) = (W_1(t), W_2(t))^T$, represents the change in queue lengths without the boundary constraints. For a tandem queue, the flow is sequential: arrivals to station $1$ are external, and arrivals to station $2$ are the departures from station $1$.\nThe netput at station $1$ is the difference between external arrivals and potential service completions at station $1$.\n$$W_1(t) = A(t) - S_1(t)$$\nThe netput at station $2$ is the difference between arrivals from station $1$ (which are its potential departures) and potential service completions at station $2$.\n$$W_2(t) = S_1(t) - S_2(t)$$\nThus, the vector netput process is $W(t) = (A(t) - S_1(t), S_1(t) - S_2(t))^T$.\n\n**1. Derivation of the Drift Vector $\\theta$**\n\nThe drift vector $\\theta$ of the Brownian motion $W(t)$ is given by the vector of mean rates of the netput processes.\n$$\n\\theta = \\lim_{t\\to\\infty} \\frac{1}{t} E[W(t)] = \\begin{pmatrix} E[A(t)]/t - E[S_1(t)]/t \\\\ E[S_1(t)]/t - E[S_2(t)]/t \\end{pmatrix}\n$$\nThe mean rates are given by the rates of the underlying renewal processes.\n$$\n\\theta = \\begin{pmatrix} \\lambda - \\mu_1 \\\\ \\mu_1 - \\mu_2 \\end{pmatrix}\n$$\nSubstituting the given values:\n$\\theta_1 = \\frac{9}{10} - 1 = -\\frac{1}{10}$\n$\\theta_2 = 1 - \\frac{11}{10} = -\\frac{1}{10}$\nSo, the drift vector is $\\theta = \\begin{pmatrix} -1/10 \\\\ -1/10 \\end{pmatrix}$.\n\n**2. Derivation of the Covariance Matrix $\\Gamma$**\n\nThe covariance matrix $\\Gamma$ is given by $\\Gamma_{ij} = \\lim_{t\\to\\infty} \\frac{1}{t} \\text{Cov}(W_i(t), W_j(t))$.\nThe diffusion approximations for the independent primitive processes are:\n$A(t) \\approx \\lambda t + \\sqrt{\\lambda c_a^2} B_a(t)$\n$S_1(t) \\approx \\mu_1 t + \\sqrt{\\mu_1 c_{s,1}^2} B_1(t)$\n$S_2(t) \\approx \\mu_2 t + \\sqrt{\\mu_2 c_{s,2}^2} B_2(t)$\nwhere $B_a, B_1, B_2$ are independent standard Brownian motions.\n\nThe diagonal elements of $\\Gamma$ are the variances:\n$\\Gamma_{11} = \\lim_{t\\to\\infty} \\frac{1}{t} \\text{Var}(A(t) - S_1(t)) = \\lambda c_a^2 + \\mu_1 c_{s,1}^2$\n$\\Gamma_{22} = \\lim_{t\\to\\infty} \\frac{1}{t} \\text{Var}(S_1(t) - S_2(t)) = \\mu_1 c_{s,1}^2 + \\mu_2 c_{s,2}^2$\n\nThe off-diagonal elements are the covariances:\n$\\Gamma_{12} = \\lim_{t\\to\\infty} \\frac{1}{t} \\text{Cov}(A(t) - S_1(t), S_1(t) - S_2(t))$\nSince $A(t)$, $S_1(t)$, and $S_2(t)$ are independent processes, the covariance is only due to the common term $S_1(t)$:\n$\\Gamma_{12} = \\lim_{t\\to\\infty} \\frac{1}{t} \\text{Cov}(-S_1(t), S_1(t)) = -\\lim_{t\\to\\infty} \\frac{1}{t} \\text{Var}(S_1(t)) = -\\mu_1 c_{s,1}^2$\nSince $\\Gamma$ is symmetric, $\\Gamma_{21} = \\Gamma_{12}$.\n\nSubstituting the given values:\n$\\lambda c_a^2 = \\frac{9}{10} \\times 2 = \\frac{9}{5}$\n$\\mu_1 c_{s,1}^2 = 1 \\times \\frac{3}{2} = \\frac{3}{2}$\n$\\mu_2 c_{s,2}^2 = \\frac{11}{10} \\times \\frac{1}{2} = \\frac{11}{20}$\n\n$\\Gamma_{11} = \\frac{9}{5} + \\frac{3}{2} = \\frac{18}{10} + \\frac{15}{10} = \\frac{33}{10}$\n$\\Gamma_{22} = \\frac{3}{2} + \\frac{11}{20} = \\frac{30}{20} + \\frac{11}{20} = \\frac{41}{20}$\n$\\Gamma_{12} = \\Gamma_{21} = -\\frac{3}{2}$\n\nSo, the covariance matrix is $\\Gamma = \\begin{pmatrix} 33/10 & -3/2 \\\\ -3/2 & 41/20 \\end{pmatrix}$.\n\n**3. Derivation of the Reflection Matrix $R$**\n\nThe reflection matrix $R$ describes the direction of control applied at the boundaries of the state space $\\mathbb{R}_{+}^{2}$.\n- When the queue at station $1$ is empty ($Q_1(t) = 0$), a regulator process $Y_1(t)$ acts. The problem states this \"increases buffer $1$ while simultaneously reducing the routed push to buffer $2$\". An increase in buffer $1$ means the first component of the reflection vector $R_1$ is positive (normalized to $1$). A reduction in the routed push to buffer $2$ means that an arrival that would have gone to station $2$ does not occur, which is a negative contribution to the queue length $Q_2$. This is modeled by a negative second component in $R_1$ (normalized to $-1$). Thus, the first column of $R$ is $R_1 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$.\n- When the queue at station $2$ is empty ($Q_2(t) = 0$), a regulator process $Y_2(t)$ acts. The problem states this \"increases only buffer $2$\". This means the corresponding reflection vector $R_2$ has a zero component for station $1$ and a positive component for station $2$ (normalized to $1$). Thus, the second column of $R$ is $R_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n\nCombining these, the reflection matrix is $R = \\begin{pmatrix} 1 & 0 \\\\ -1 & 1 \\end{pmatrix}$.\nThe parameters of the SRBM are $(\\theta, \\Gamma, R) = \\left( \\begin{pmatrix} -1/10 \\\\ -1/10 \\end{pmatrix}, \\begin{pmatrix} 33/10 & -3/2 \\\\ -3/2 & 41/20 \\end{pmatrix}, \\begin{pmatrix} 1 & 0 \\\\ -1 & 1 \\end{pmatrix} \\right)$.\n\n**4. Computation of the Stability Margin $m$**\n\nThe stability margin is defined as $m = \\max\\bigl\\{ \\bigl(R^{-1}\\theta\\bigr)_{1},\\; \\bigl(R^{-1}\\theta\\bigr)_{2} \\bigr\\}$.\nFirst, we find the inverse of $R$:\n$\\det(R) = (1)(1) - (0)(-1) = 1$.\n$R^{-1} = \\frac{1}{\\det(R)} \\begin{pmatrix} 1 & -0 \\\\ -(-1) & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix}$.\n\nNext, we compute the vector $\\delta = R^{-1}\\theta$, which represents the drift of the workload process.\n$$\n\\delta = R^{-1}\\theta = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} -1/10 \\\\ -1/10 \\end{pmatrix}\n$$\nThe components of $\\delta$ are:\n$\\delta_1 = (1)(-\\frac{1}{10}) + (0)(-\\frac{1}{10}) = -\\frac{1}{10}$\n$\\delta_2 = (1)(-\\frac{1}{10}) + (1)(-\\frac{1}{10}) = -\\frac{2}{10} = -\\frac{1}{5}$\n\nFinally, we compute the stability margin $m$ by taking the maximum of these components:\n$$\nm = \\max\\{-\\frac{1}{10}, -\\frac{1}{5}\\}\n$$\nSince $-\\frac{1}{10} = -0.1$ and $-\\frac{1}{5} = -0.2$, the maximum value is $-\\frac{1}{10}$.\n$$\nm = -\\frac{1}{10}\n$$", "answer": "$$\\boxed{-\\frac{1}{10}}$$", "id": "2993602"}, {"introduction": "The elegance of the Skorokhod problem in convex domains can mask its underlying subtleties. This final exercise [@problem_id:2998947] explores what happens when we venture into a non-convex domain, revealing a fascinating breakdown of the theory's guarantees. By analyzing a specific family of paths in a wedge-shaped domain, you will demonstrate that the Skorokhod map is not always Lipschitz continuous, a result that has profound implications for the pathwise uniqueness of solutions to reflected SDEs.", "problem": "Consider the Skorokhod problem for constrained paths in a nonconvex domain in $\\mathbb{R}^{2}$, defined as follows. Let the domain be $$D \\equiv \\{(x_{1},x_{2}) \\in \\mathbb{R}^{2}: x_{2} \\geq -|x_{1}|\\},$$ whose boundary consists of the two rays $$\\Gamma_{+} \\equiv \\{(x,y) \\in \\mathbb{R}^{2}: y=-x,\\ x \\geq 0\\}, \\qquad \\Gamma_{-} \\equiv \\{(x,y) \\in \\mathbb{R}^{2}: y=x,\\ x \\leq 0\\},$$ meeting at the re-entrant corner $(0,0)$. On each boundary component, impose normal reflection: on $\\Gamma_{+}$ the inward unit normal is $$n_{+} \\equiv \\left(\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}}\\right),$$ and on $\\Gamma_{-}$ the inward unit normal is $$n_{-} \\equiv \\left(-\\frac{1}{\\sqrt{2}},\\frac{1}{\\sqrt{2}}\\right).$$ At the corner $(0,0)$, the normal cone is the closed convex cone generated by $\\{n_{+},n_{-}\\}$.\n\nFor a continuous input path $w:[0,T] \\to \\mathbb{R}^{2}$, a Skorokhod solution on $D$ is a pair $(X,L)$ consisting of a continuous path $X:[0,T] \\to \\overline{D}$ and a nondecreasing function $L:[0,T] \\to \\mathbb{R}_{+}$ with $L(0)=0$, such that\n- $X(t) = w(t) + \\int_{0}^{t} \\nu(s)\\, \\mathrm{d}L(s)$ for $t \\in [0,T]$, where $\\nu(s)$ is a measurable selection of inward unit normals at $X(s)$ (that is, $\\nu(s) \\in \\{n_{+}\\}$ if $X(s) \\in \\Gamma_{+}$, $\\nu(s) \\in \\{n_{-}\\}$ if $X(s) \\in \\Gamma_{-}$, and $\\nu(s)$ lies in the normal cone at $(0,0)$ if $X(s)=(0,0)$),\n- $L$ increases only when $X$ is on the boundary, in the sense that for all Borel sets $A \\subset [0,T]$, $$\\int_{A} \\mathbf{1}_{\\{X(s)\\in D^{\\circ}\\}} \\, \\mathrm{d}L(s) = 0,$$ where $D^{\\circ}$ denotes the interior of $D$.\n\nLet $\\|\\cdot\\|_{\\infty}$ denote the sup norm on $\\mathbb{R}^{2}$, defined as $\\|(x_{1},x_{2})\\|_{\\infty} \\equiv \\max\\{|x_{1}|,|x_{2}|\\}$. Consider the family of input paths\n$$w^{\\epsilon}(t) \\equiv (\\epsilon,-t), \\qquad t \\in [0,T],$$\nparametrized by $\\epsilon \\in \\mathbb{R}$. For $\\epsilon>0$ (respectively $\\epsilon<0$), take the minimal Skorokhod solution that slides along $\\Gamma_{+}$ (respectively along $\\Gamma_{-}$) after first boundary contact; denote these solutions by $X^{\\epsilon}$.\n\nTasks:\n1. Starting from the definitions above, derive explicit formulas for $X^{\\epsilon}(t)$ for $\\epsilon>0$ and for $\\epsilon<0$, by enforcing boundary contact and normal reflection after first contact time.\n2. Use these formulas to compute, for fixed $T>0$ and $\\epsilon>0$, the quotient\n$$Q(\\epsilon,T) \\equiv \\frac{\\sup_{0 \\leq t \\leq T}\\big\\|X^{\\epsilon}(t) - X^{-\\epsilon}(t)\\big\\|_{\\infty}}{\\sup_{0 \\leq t \\leq T}\\big\\|w^{\\epsilon}(t) - w^{-\\epsilon}(t)\\big\\|_{\\infty}}.$$\n3. Evaluate the limit $\\lim_{\\epsilon \\downarrow 0} Q(\\epsilon,T)$ and provide this value as your final answer. No rounding is required, and no units are involved.\n\nExplain how this construction exhibits a counterexample showing that the Skorokhod map fails to be Lipschitz in the nonconvex domain $D$, and why it implies that pathwise uniqueness may fail for the corresponding reflected stochastic differential equation (SDE) $\\,\\mathrm{d}X_{t} = b\\, \\mathrm{d}t + \\mathrm{d}K_{t}\\,$ with constant drift $b \\equiv (0,-1)$ and normal reflection on $\\partial D$.", "solution": "### Solution\n\nThe solution proceeds in three parts as requested by the problem statement.\n\n**1. Derivation of Explicit Formulas for $X^{\\epsilon}(t)$**\n\nLet's first consider the case $\\epsilon > 0$. The input path is $w^{\\epsilon}(t) = (\\epsilon, -t)$. The path starts at $w^{\\epsilon}(0) = (\\epsilon, 0)$, which is in the interior of the domain $D$ since $0 > -|\\epsilon| = -\\epsilon$. The path moves vertically downward until it hits the boundary $\\partial D$. The boundary is defined by $x_2 = -|x_1|$. For $x_1 = \\epsilon > 0$, the relevant part of the boundary is $\\Gamma_+$, where $x_2 = -x_1$.\nThe first contact time $t_c$ occurs when the path coordinates $(\\epsilon, -t)$ satisfy $-t = -\\epsilon$, which gives $t_c = \\epsilon$.\nFor $t \\in [0, \\epsilon]$, the path is in the interior of $D$, so there is no reflection. Thus, $L(t)=0$ and $X^{\\epsilon}(t) = w^{\\epsilon}(t) = (\\epsilon, -t)$.\nThe contact point is $X^{\\epsilon}(\\epsilon) = (\\epsilon, -\\epsilon)$, which lies on $\\Gamma_{+}$.\nFor $t > \\epsilon$, the problem states that the solution slides along $\\Gamma_{+}$. The path $X^{\\epsilon}(t)$ must remain on $\\Gamma_{+}$, meaning its coordinates $(X_1(t), X_2(t))$ must satisfy $X_2(t) = -X_1(t)$. The reflection occurs in the direction of the inward normal $n_{+} = (\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})$.\nThe Skorokhod problem, expressed in differential form, is $dX^{\\epsilon}(t) = dw^{\\epsilon}(t) + n_{+}dL(t)$.\nThe differential of the input path is $dw^{\\epsilon}(t) = (0,-1)dt$.\nSo, $(dX_1(t), dX_2(t)) = (0, -dt) + (\\frac{1}{\\sqrt{2}}dL(t), \\frac{1}{\\sqrt{2}}dL(t))$.\nFrom the constraint $X_2(t) = -X_1(t)$, we have $dX_2(t) = -dX_1(t)$.\n$-dt + \\frac{1}{\\sqrt{2}}dL(t) = -(\\frac{1}{\\sqrt{2}}dL(t))$, which simplifies to $dt = \\frac{2}{\\sqrt{2}}dL(t) = \\sqrt{2}dL(t)$.\nThus, $dL(t) = \\frac{1}{\\sqrt{2}}dt$ for $t > \\epsilon$.\nSubstituting this back into the expressions for the differentials of the coordinates:\n$dX_1(t) = \\frac{1}{\\sqrt{2}} dL(t) = \\frac{1}{\\sqrt{2}} (\\frac{1}{\\sqrt{2}}dt) = \\frac{1}{2}dt$.\n$dX_2(t) = -dt + \\frac{1}{\\sqrt{2}} dL(t) = -dt + \\frac{1}{2}dt = -\\frac{1}{2}dt$.\nTo find $X^{\\epsilon}(t)$ for $t > \\epsilon$, we integrate from the contact time $\\epsilon$:\n$X_1(t) = X_1(\\epsilon) + \\int_{\\epsilon}^{t} \\frac{1}{2}ds = \\epsilon + \\frac{1}{2}(t-\\epsilon) = \\frac{t+\\epsilon}{2}$.\n$X_2(t) = X_2(\\epsilon) + \\int_{\\epsilon}^{t} -\\frac{1}{2}ds = -\\epsilon - \\frac{1}{2}(t-\\epsilon) = -\\frac{t+\\epsilon}{2}$.\nSo for $\\epsilon > 0$, the solution is:\n$$ X^{\\epsilon}(t) = \\begin{cases} (\\epsilon, -t) & \\text{if } 0 \\leq t \\leq \\epsilon \\\\ \\left(\\frac{t+\\epsilon}{2}, -\\frac{t+\\epsilon}{2}\\right) & \\text{if } \\epsilon < t \\leq T \\end{cases} $$\n\nNext, let's consider the case $\\epsilon < 0$. The input path is $w^{\\epsilon}(t) = (\\epsilon, -t)$. For $x_1 = \\epsilon < 0$, the relevant boundary is $\\Gamma_{-}$, where $x_2=x_1$. The first contact occurs when $-t = \\epsilon$, which gives the contact time $t_c = -\\epsilon > 0$.\nFor $t \\in [0, -\\epsilon]$, we have $X^{\\epsilon}(t) = w^{\\epsilon}(t) = (\\epsilon, -t)$.\nThe contact point is $X^{\\epsilon}(-\\epsilon) = (\\epsilon, -(-\\epsilon)) = (\\epsilon, \\epsilon)$.\nFor $t > -\\epsilon$, the solution slides along $\\Gamma_{-}$, so $X_1(t) = X_2(t)$, and the reflection normal is $n_{-} = (-\\frac{1}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}})$.\nThe differential form is $dX^{\\epsilon}(t) = dw^{\\epsilon}(t) + n_{-}dL(t)$.\n$(dX_1(t), dX_2(t)) = (0, -dt) + (-\\frac{1}{\\sqrt{2}}dL(t), \\frac{1}{\\sqrt{2}}dL(t))$.\nThe constraint $X_1(t) = X_2(t)$ implies $dX_1(t) = dX_2(t)$.\n$-\\frac{1}{\\sqrt{2}}dL(t) = -dt + \\frac{1}{\\sqrt{2}}dL(t)$, which again yields $dL(t) = \\frac{1}{\\sqrt{2}}dt$.\nSubstituting back:\n$dX_1(t) = -\\frac{1}{\\sqrt{2}} dL(t) = -\\frac{1}{2}dt$.\n$dX_2(t) = -dt + \\frac{1}{\\sqrt{2}} dL(t) = -\\frac{1}{2}dt$.\nIntegrating from $t_c = -\\epsilon$:\n$X_1(t) = X_1(-\\epsilon) + \\int_{-\\epsilon}^{t} -\\frac{1}{2}ds = \\epsilon - \\frac{1}{2}(t-(-\\epsilon)) = \\frac{\\epsilon-t}{2}$.\n$X_2(t) = X_2(-\\epsilon) + \\int_{-\\epsilon}^{t} -\\frac{1}{2}ds = \\epsilon - \\frac{1}{2}(t+\\epsilon) = \\frac{\\epsilon-t}{2}$.\nSo for $\\epsilon < 0$, the solution is:\n$$ X^{\\epsilon}(t) = \\begin{cases} (\\epsilon, -t) & \\text{if } 0 \\leq t \\leq -\\epsilon \\\\ \\left(\\frac{\\epsilon-t}{2}, \\frac{\\epsilon-t}{2}\\right) & \\text{if } -\\epsilon < t \\leq T \\end{cases} $$\n\n**2. Computation of the Quotient $Q(\\epsilon,T)$**\n\nWe fix $\\epsilon > 0$ and compute the two suprema in the definition of $Q(\\epsilon,T)$.\nFirst, the denominator:\n$w^{\\epsilon}(t) - w^{-\\epsilon}(t) = (\\epsilon, -t) - (-\\epsilon, -t) = (2\\epsilon, 0)$.\nThe sup norm is $\\|w^{\\epsilon}(t) - w^{-\\epsilon}(t)\\|_{\\infty} = \\max\\{|2\\epsilon|, |0|\\} = 2\\epsilon$.\nSince this is constant for all $t$, the supremum is also $2\\epsilon$:\n$$ \\sup_{0 \\leq t \\leq T}\\big\\|w^{\\epsilon}(t) - w^{-\\epsilon}(t)\\big\\|_{\\infty} = 2\\epsilon $$\nNext, the numerator. We need the expression for $X^{-\\epsilon}(t)$, which we get by taking the formula for $\\epsilon<0$ and replacing $\\epsilon$ with $-\\epsilon$:\n$$ X^{-\\epsilon}(t) = \\begin{cases} (-\\epsilon, -t) & \\text{if } 0 \\leq t \\leq \\epsilon \\\\ \\left(\\frac{-\\epsilon-t}{2}, \\frac{-\\epsilon-t}{2}\\right) & \\text{if } \\epsilon < t \\leq T \\end{cases} $$\nNow we compute the difference $X^{\\epsilon}(t) - X^{-\\epsilon}(t)$ in two intervals.\nFor $t \\in [0, \\epsilon]$:\n$X^{\\epsilon}(t) - X^{-\\epsilon}(t) = (\\epsilon, -t) - (-\\epsilon, -t) = (2\\epsilon, 0)$.\n$\\|X^{\\epsilon}(t) - X^{-\\epsilon}(t)\\|_{\\infty} = 2\\epsilon$.\nFor $t \\in (\\epsilon, T]$:\n$X^{\\epsilon}(t) - X^{-\\epsilon}(t) = \\left(\\frac{t+\\epsilon}{2}, -\\frac{t+\\epsilon}{2}\\right) - \\left(\\frac{-\\epsilon-t}{2}, \\frac{-\\epsilon-t}{2}\\right) = \\left(\\frac{t+\\epsilon - (-\\epsilon-t)}{2}, \\frac{-(t+\\epsilon) - (-\\epsilon-t)}{2}\\right) = \\left(\\frac{2t+2\\epsilon}{2}, 0\\right) = (t+\\epsilon, 0)$.\n$\\|X^{\\epsilon}(t) - X^{-\\epsilon}(t)\\|_{\\infty} = \\max\\{|t+\\epsilon|, |0|\\} = t+\\epsilon$, since $t > \\epsilon > 0$.\nTo find the supremum over $[0, T]$, we consider the function $f(t) = \\|X^{\\epsilon}(t) - X^{-\\epsilon}(t)\\|_{\\infty}$. We have $f(t) = 2\\epsilon$ for $t \\in [0, \\epsilon]$ and $f(t) = t+\\epsilon$ for $t \\in (\\epsilon, T]$. For $t > \\epsilon$, the function $t+\\epsilon$ is strictly increasing. Since $T>0$ is fixed, for sufficiently small $\\epsilon$, we have $T>\\epsilon$. The maximum value must occur at $t=T$.\n$$ \\sup_{0 \\leq t \\leq T}\\big\\|X^{\\epsilon}(t) - X^{-\\epsilon}(t)\\big\\|_{\\infty} = T+\\epsilon $$\nThe quotient is therefore:\n$$ Q(\\epsilon,T) = \\frac{T+\\epsilon}{2\\epsilon} $$\n\n**3. Evaluation of the Limit and Interpretation**\n\nWe now evaluate the limit as $\\epsilon$ approaches $0$ from the positive side:\n$$ \\lim_{\\epsilon \\downarrow 0} Q(\\epsilon,T) = \\lim_{\\epsilon \\downarrow 0} \\frac{T+\\epsilon}{2\\epsilon} = \\lim_{\\epsilon \\downarrow 0} \\left(\\frac{T}{2\\epsilon} + \\frac{1}{2}\\right) = +\\infty $$\nThis result demonstrates that the Skorokhod map, which maps an input path $w$ to a reflected path $X$, is not Lipschitz continuous on the non-convex domain $D$. A map $\\mathcal{S}$ is Lipschitz if there exists a constant $C$ such that $\\|\\mathcal{S}(w_1) - \\mathcal{S}(w_2)\\| \\leq C \\|w_1 - w_2\\|$ for all inputs $w_1, w_2$. Our calculation shows that the ratio of output distance to input distance can be arbitrarily large, so no such finite constant $C$ exists.\n\nThis has a direct consequence for the uniqueness of solutions to reflected stochastic differential equations (SDEs). Consider the SDE $dX_{t} = b\\, \\mathrm{d}t + \\mathrm{d}K_{t}$ with constant drift $b = (0,-1)$ and normal reflection on $\\partial D$. The solution to this ODE with reflection starting from $X_0 = x_0$ is given by applying the Skorokhod map to the unconstrained path $w(t) = x_0 + bt$.\nThe failure of the Skorokhod map to be Lipschitz continuous leads to the failure of pathwise uniqueness for SDEs in this domain. If we start the SDE at the corner, $X_0 = (0,0)$, the driving path is $w(t) = (0,-t)$. The limits of the paths we constructed show that there are at least two distinct solutions:\n$X^{+}(t) = \\lim_{\\epsilon \\downarrow 0} X^{\\epsilon}(t) = (\\frac{t}{2}, -\\frac{t}{2})$\n$X^{-}(t) = \\lim_{\\epsilon \\downarrow 0} X^{-\\epsilon}(t) = (-\\frac{t}{2}, -\\frac{t}{2})$\nBoth $X^{+}(t)$ and $X^{-}(t)$ are valid solutions to the reflected ODE starting at $(0,0)$, demonstrating the failure of pathwise uniqueness. $X^{+}(t)$ corresponds to a solution that immediately slides along $\\Gamma_{+}$, while $X^{-}(t)$ slides along $\\Gamma_{-}$.", "answer": "$$\\boxed{\\infty}$$", "id": "2998947"}]}