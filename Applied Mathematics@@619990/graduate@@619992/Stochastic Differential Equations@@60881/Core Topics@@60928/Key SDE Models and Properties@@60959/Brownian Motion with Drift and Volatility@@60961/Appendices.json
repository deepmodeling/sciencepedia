{"hands_on_practices": [{"introduction": "Understanding the evolution of a stochastic process's statistical properties, such as its mean and variance, is crucial for its analysis. This exercise provides hands-on practice with Itô's formula, a central tool in stochastic calculus for finding the dynamics of a function of a stochastic process. By deriving a recursive relationship for the moments of a Brownian motion with drift, you will gain a deeper appreciation for how its statistical profile changes over time [@problem_id:2970465].", "id": "2970465", "problem": "Consider a one-dimensional Itô process driven by a standard Brownian motion (also called a Wiener process), defined by $X_t = x_0 + \\mu t + \\sigma W_t$ with constants $x_0 \\in \\mathbb{R}$, $\\mu \\in \\mathbb{R}$, and $\\sigma \\in (0,\\infty)$. For each integer $n \\geq 0$, define the $n$-th raw moment $m_n(t) = \\mathbb{E}[X_t^n]$. Using only the foundational properties of Brownian motion and the statement of Itô's formula for $C^2$ functions $f$, derive a deterministic recursion in $t$ for the sequence $\\{m_n(t)\\}_{n \\geq 0}$, including its initial conditions. Then solve this recursion explicitly for $n = 1$, $n = 2$, and $n = 3$ to obtain closed-form expressions for $m_1(t)$, $m_2(t)$, and $m_3(t)$ as functions of $t$, $x_0$, $\\mu$, and $\\sigma$. Provide your final explicit expressions for $m_1(t)$, $m_2(t)$, and $m_3(t)$.", "solution": "The problem statement is scientifically grounded, well-posed, objective, and self-contained. It is a standard problem in the field of stochastic differential equations and is therefore valid.\n\nThe process $X_t$ is an arithmetic Brownian motion (or a generalized Wiener process), whose dynamics are described by the stochastic differential equation (SDE):\n$$\ndX_t = \\mu dt + \\sigma dW_t\n$$\nwith a deterministic initial condition $X_0 = x_0$. Here, $W_t$ is a standard Wiener process, and $x_0 \\in \\mathbb{R}$, $\\mu \\in \\mathbb{R}$, and $\\sigma \\in (0, \\infty)$ are constants.\n\nWe are asked to find a recursion for the $n$-th raw moments, defined as $m_n(t) = \\mathbb{E}[X_t^n]$. We will use Itô's formula for the function $f(x) = x^n$. For any integer $n \\geq 2$, this function is of class $C^\\infty$, and thus is a $C^2$ function, satisfying the prerequisite for the formula.\n\nThe general form of Itô's formula for a function $f(t,x)$ applied to an Itô process $X_t$ is:\n$$\ndf(t, X_t) = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x} dX_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2} (dX_t)^2\n$$\nFor our case, $f(x) = x^n$, which does not explicitly depend on $t$. The partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial t} = 0, \\quad \\frac{\\partial f}{\\partial x} = n x^{n-1}, \\quad \\frac{\\partial^2 f}{\\partial x^2} = n(n-1) x^{n-2}\n$$\nThe quadratic variation term, $(dX_t)^2$, is calculated using the multiplication rules of Itô calculus ($dt \\cdot dt = 0$, $dt \\cdot dW_t = 0$, and $dW_t \\cdot dW_t = dt$):\n$$\n(dX_t)^2 = (\\mu dt + \\sigma dW_t)^2 = \\mu^2 (dt)^2 + 2\\mu\\sigma dt dW_t + \\sigma^2 (dW_t)^2 = \\sigma^2 dt\n$$\nSubstituting these expressions into Itô's formula for $f(X_t) = X_t^n$, we obtain:\n$$\nd(X_t^n) = n X_t^{n-1} dX_t + \\frac{1}{2} n(n-1) X_t^{n-2} (dX_t)^2\n$$\n$$\nd(X_t^n) = n X_t^{n-1} (\\mu dt + \\sigma dW_t) + \\frac{1}{2} n(n-1) X_t^{n-2} (\\sigma^2 dt)\n$$\nGrouping the $dt$ and $dW_t$ terms gives the SDE for $X_t^n$:\n$$\nd(X_t^n) = \\left( n \\mu X_t^{n-1} + \\frac{n(n-1)}{2} \\sigma^2 X_t^{n-2} \\right) dt + n \\sigma X_t^{n-1} dW_t\n$$\nIntegrating this equation from $s=0$ to $s=t$ yields:\n$$\nX_t^n - X_0^n = \\int_0^t \\left( n \\mu X_s^{n-1} + \\frac{n(n-1)}{2} \\sigma^2 X_s^{n-2} \\right) ds + \\int_0^t n \\sigma X_s^{n-1} dW_s\n$$\nWe now take the expectation of both sides. Key properties we use are:\n$1$. The initial condition is deterministic, so $\\mathbb{E}[X_0^n] = \\mathbb{E}[x_0^n] = x_0^n$.\n$2$. The expectation of an Itô integral with respect to a Wiener process is zero, i.e., $\\mathbb{E}\\left[\\int_0^t g(s, \\omega) dW_s\\right] = 0$ for a suitable integrand $g$.\n$3$. By the stochastic Fubini theorem, we can interchange expectation and the time integral.\nApplying these, we get:\n$$\n\\mathbb{E}[X_t^n] - x_0^n = \\mathbb{E}\\left[ \\int_0^t \\left( n \\mu X_s^{n-1} + \\frac{n(n-1)}{2} \\sigma^2 X_s^{n-2} \\right) ds \\right]\n$$\n$$\nm_n(t) - x_0^n = \\int_0^t \\left( n \\mu \\mathbb{E}[X_s^{n-1}] + \\frac{n(n-1)}{2} \\sigma^2 \\mathbb{E}[X_s^{n-2}] \\right) ds\n$$\nSubstituting the moment definition $m_k(t) = \\mathbb{E}[X_t^k]$:\n$$\nm_n(t) - x_0^n = \\int_0^t \\left( n \\mu m_{n-1}(s) + \\frac{n(n-1)}{2} \\sigma^2 m_{n-2}(s) \\right) ds\n$$\nThe first part of the problem asks for a deterministic recursion. Differentiating with respect to $t$ using the Fundamental Theorem of Calculus gives an ordinary differential equation (ODE) for $m_n(t)$:\n$$\n\\frac{d}{dt} m_n(t) = n \\mu m_{n-1}(t) + \\frac{n(n-1)}{2} \\sigma^2 m_{n-2}(t)\n$$\nThis recursion is valid for $n \\geq 2$. For $n=0$ and $n=1$, we have:\n- For $n=0$: $m_0(t) = \\mathbb{E}[X_t^0] = \\mathbb{E}[1] = 1$.\n- For $n=1$: The formula gives $\\frac{d}{dt} m_1(t) = 1 \\cdot \\mu m_0(t) + \\frac{1(0)}{2} \\sigma^2 m_{-1}(t) = \\mu m_0(t) = \\mu$.\nThe initial condition for each ODE is $m_n(0) = \\mathbb{E}[X_0^n] = x_0^n$.\n\nNow we solve this system of ODEs for $n=1, 2, 3$.\n\n**First moment ($n=1$):**\nThe ODE is $\\frac{d}{dt} m_1(t) = \\mu$, with the initial condition $m_1(0) = x_0^1 = x_0$.\nIntegrating with respect to $t$ gives $m_1(t) = \\mu t + C_1$.\nApplying the initial condition: $m_1(0) = x_0 \\implies C_1 = x_0$.\nThus, the first moment is:\n$$m_1(t) = x_0 + \\mu t$$\n\n**Second moment ($n=2$):**\nThe ODE is $\\frac{d}{dt} m_2(t) = 2 \\mu m_1(t) + \\frac{2(1)}{2} \\sigma^2 m_0(t) = 2 \\mu m_1(t) + \\sigma^2 m_0(t)$.\nSubstituting the expressions for $m_1(t)$ and $m_0(t)$:\n$$\n\\frac{d}{dt} m_2(t) = 2 \\mu (x_0 + \\mu t) + \\sigma^2 (1) = 2 \\mu x_0 + 2 \\mu^2 t + \\sigma^2\n$$\nThe initial condition is $m_2(0) = x_0^2$. Integrating with respect to $t$:\n$$\nm_2(t) = \\int (2 \\mu x_0 + 2 \\mu^2 t + \\sigma^2) dt = 2 \\mu x_0 t + \\mu^2 t^2 + \\sigma^2 t + C_2\n$$\nApplying the initial condition: $m_2(0) = x_0^2 \\implies C_2 = x_0^2$.\nThus, the second moment is:\n$$\nm_2(t) = x_0^2 + 2 \\mu x_0 t + \\mu^2 t^2 + \\sigma^2 t\n$$\nThis can be written more compactly as:\n$$m_2(t) = (x_0 + \\mu t)^2 + \\sigma^2 t$$\n\n**Third moment ($n=3$):**\nThe ODE is $\\frac{d}{dt} m_3(t) = 3 \\mu m_2(t) + \\frac{3(2)}{2} \\sigma^2 m_1(t) = 3 \\mu m_2(t) + 3 \\sigma^2 m_1(t)$.\nSubstituting the expressions for $m_1(t)$ and $m_2(t)$:\n$$\n\\frac{d}{dt} m_3(t) = 3 \\mu \\left( (x_0 + \\mu t)^2 + \\sigma^2 t \\right) + 3 \\sigma^2 (x_0 + \\mu t)\n$$\nExpanding the terms:\n$$\n\\frac{d}{dt} m_3(t) = 3 \\mu (x_0^2 + 2\\mu x_0 t + \\mu^2 t^2 + \\sigma^2 t) + 3x_0\\sigma^2 + 3\\mu\\sigma^2 t\n$$\n$$\n\\frac{d}{dt} m_3(t) = 3\\mu x_0^2 + 6\\mu^2 x_0 t + 3\\mu^3 t^2 + 3\\mu\\sigma^2 t + 3x_0\\sigma^2 + 3\\mu\\sigma^2 t\n$$\nCollecting terms by powers of $t$:\n$$\n\\frac{d}{dt} m_3(t) = (3\\mu x_0^2 + 3x_0\\sigma^2) + (6\\mu^2 x_0 + 6\\mu\\sigma^2)t + 3\\mu^3 t^2\n$$\nThe initial condition is $m_3(0) = x_0^3$. Integrating with respect to $t$:\n$$\nm_3(t) = \\int \\left( (3\\mu x_0^2 + 3x_0\\sigma^2) + (6\\mu^2 x_0 + 6\\mu\\sigma^2)t + 3\\mu^3 t^2 \\right) dt\n$$\n$$\nm_3(t) = (3\\mu x_0^2 + 3x_0\\sigma^2)t + (3\\mu^2 x_0 + 3\\mu\\sigma^2)t^2 + \\mu^3 t^3 + C_3\n$$\nApplying the initial condition: $m_3(0) = x_0^3 \\implies C_3 = x_0^3$.\n$$\nm_3(t) = x_0^3 + (3\\mu x_0^2 + 3x_0\\sigma^2)t + (3\\mu^2 x_0 + 3\\mu\\sigma^2)t^2 + \\mu^3 t^3\n$$\nThis expression can be rearranged into a more insightful form:\n$$\nm_3(t) = (x_0^3 + 3\\mu x_0^2 t + 3\\mu^2 x_0 t^2 + \\mu^3 t^3) + (3x_0\\sigma^2 t + 3\\mu\\sigma^2 t^2)\n$$\n$$\nm_3(t) = (x_0 + \\mu t)^3 + 3\\sigma^2 t(x_0 + \\mu t)\n$$\n\nThe final explicit expressions for the first three moments are provided in the final answer.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx_0 + \\mu t & (x_0 + \\mu t)^2 + \\sigma^2 t & (x_0 + \\mu t)^3 + 3 \\sigma^2 t (x_0 + \\mu t)\n\\end{pmatrix}\n}\n$$"}, {"introduction": "Stochastic processes often possess elegant and sometimes surprising symmetries that reveal deeper structural properties. This exercise explores the behavior of a Brownian motion with drift under the transformation of time reversal. By analyzing the resulting process, you will apply the core definitions of stationarity and independence of increments to determine if this symmetry holds and what it implies about the process's parameters [@problem_id:1286690].", "id": "1286690", "problem": "Consider a stochastic process $X_t$ for time $t \\in [0, T]$, which is a Brownian motion with a constant drift $\\mu$ and constant volatility $\\sigma > 0$. The process starts at $X_0=0$. Recall that such a process can be represented as $X_t = \\mu t + \\sigma W_t$, where $W_t$ is a standard Brownian motion. A process $W_t$ is a standard Brownian motion if: (i) $W_0=0$; (ii) for any $0 \\le s < t$, the increment $W_t - W_s$ is a normally distributed random variable with mean 0 and variance $t-s$; (iii) for any non-overlapping time intervals, the corresponding increments are independent random variables; and (iv) the sample paths $t \\mapsto W_t$ are continuous.\n\nNow, let's define a new time-reversed process $Y_t$ on the same time interval $t \\in [0, T]$ as follows:\n$$Y_t = X_{T-t} - X_T$$\nDetermine the nature of the process $Y_t$. Which of the following statements is correct?\n\nA. $Y_t$ is a Brownian motion with drift $\\mu$ and volatility $\\sigma$.\nB. $Y_t$ is a Brownian motion with drift $-\\mu$ and volatility $\\sigma$.\nC. $Y_t$ is a Brownian motion with drift $0$ and volatility $\\sigma$.\nD. $Y_t$ is not a Brownian motion because its increments are not independent.\n\n", "solution": "We start from the given process $X_{t}=\\mu t+\\sigma W_{t}$ with $W_{t}$ a standard Brownian motion and define, for $t\\in[0,T]$,\n$$\nY_{t}=X_{T-t}-X_{T}.\n$$\nExpanding using the representation of $X$ gives\n$$\nY_{t}=\\mu(T-t)+\\sigma W_{T-t}-\\mu T-\\sigma W_{T}=-\\mu t+\\sigma\\bigl(W_{T-t}-W_{T}\\bigr).\n$$\nDefine the time-reversed Brownian motion\n$$\n\\widehat{W}_{t}:=W_{T}-W_{T-t},\\qquad t\\in[0,T].\n$$\nThen $W_{T-t}-W_{T}=-\\widehat{W}_{t}$, so\n$$\nY_{t}=-\\mu t-\\sigma\\widehat{W}_{t}.\n$$\nWe now verify that $\\widehat{W}_{t}$ is a standard Brownian motion. First, $\\widehat{W}_{0}=W_{T}-W_{T}=0$. Continuity follows from the continuity of $W$. For $0\\leq s<t\\leq T$,\n$$\n\\widehat{W}_{t}-\\widehat{W}_{s}=(W_{T}-W_{T-t})-(W_{T}-W_{T-s})=W_{T-s}-W_{T-t}.\n$$\nThe increment $W_{T-s}-W_{T-t}$ is Gaussian with mean $0$ and variance $(T-s)-(T-t)=t-s$ by stationary increments of $W$. Moreover, for disjoint intervals $(s_{1},t_{1}]$ and $(s_{2},t_{2}]$ in $[0,T]$, the corresponding intervals for $W$ are $[T-t_{1},T-s_{1}]$ and $[T-t_{2},T-s_{2}]$, which are disjoint; hence the increments of $\\widehat{W}$ over disjoint time intervals are independent by independence of increments of $W$. Therefore $\\widehat{W}$ is a standard Brownian motion.\n\nSince the negative of a standard Brownian motion is also a standard Brownian motion, we can write $-\\widehat{W}_{t}=\\widetilde{W}_{t}$ with $\\widetilde{W}$ a standard Brownian motion. Hence\n$$\nY_{t}=-\\mu t+\\sigma\\widetilde{W}_{t}.\n$$\nEquivalently, for $0\\leq s<t\\leq T$,\n$$\nY_{t}-Y_{s}=-\\mu(t-s)+\\sigma\\bigl(W_{T-t}-W_{T-s}\\bigr),\n$$\nwhich is normally distributed with mean $-\\mu(t-s)$ and variance $\\sigma^{2}(t-s)$, and these increments are independent over disjoint intervals. Also $Y_{0}=0$. Therefore $Y$ is a Brownian motion with drift $-\\mu$ and volatility $\\sigma$.\n\nThus the correct statement is that $Y_{t}$ is a Brownian motion with drift $-\\mu$ and volatility $\\sigma$.", "answer": "$$\\boxed{B}$$"}, {"introduction": "Bridging the gap between abstract theory and concrete application is a key skill in the sciences. This practice guides you from the theoretical properties of Brownian motion to the implementation of an exact path simulation algorithm. By leveraging the fact that increments are independent and Gaussian, you will construct a method to generate a sample path that has the exact same statistical distribution as the true process, a technique fundamental to Monte Carlo methods in finance and physics [@problem_id:2970492].", "id": "2970492", "problem": "Consider the stochastic differential equation (SDE) $dX_t = \\mu \\, dt + \\sigma \\, dW_t$ with initial condition $X_0 = x_0$, where $W_t$ is a standard Brownian motion. Use only the foundational properties of Brownian motion: $W_0 = 0$, independent increments, and for $0 \\le s < t$, $W_t - W_s$ is Gaussian with mean $0$ and variance $t - s$. The process $X_t$ obeys $X_t = x_0 + \\mu t + \\sigma W_t$. Derive, from these properties, an exact path simulation scheme for $X_t$ on a fixed time grid $0 = t_0 < t_1 < \\cdots < t_n = T$ that relies on independent random variables drawn from the standard normal distribution, and justify why the scheme is exact (i.e., why its output has the same finite-dimensional distributions as $X_t$). You must then implement this exact scheme as a program to produce numerical results for the test suite below.\n\nImplementation requirements:\n- For each test case, simulate a single sample path on the provided grid using independent draws from the standard normal distribution and a reproducible pseudo-random generator initialized with the specified integer seed. No approximations beyond the basic random sampling are permitted.\n- For each test case, compute and return only the terminal value $X_T$ corresponding to the final grid time $T$.\n- To ensure deterministic outputs, you must use the given seed for each test case. The terminal values must be rounded to $10$ decimal places.\n- Your program should produce a single line of output containing the terminal values for all test cases, as a comma-separated list enclosed in square brackets, for example $[v_1,v_2,v_3,v_4]$, where each $v_i$ is the rounded terminal value for test case $i$.\n\nTest suite:\n- Test case $1$: $x_0 = 1.2$, $\\mu = -0.3$, $\\sigma = 0.7$, grid $t = [0.0, 0.1, 0.5, 1.0]$, seed $20231011$.\n- Test case $2$: $x_0 = 0.0$, $\\mu = 2.5$, $\\sigma = 0.0$, grid $t = [0.0, 0.3, 0.7, 1.0]$, seed $777$.\n- Test case $3$: $x_0 = -3.0$, $\\mu = 0.0$, $\\sigma = 2.0$, grid $t = [0.0, 0.25, 0.5, 0.9, 1.3]$, seed $12345$.\n- Test case $4$: $x_0 = 0.5$, $\\mu = 1 \\times 10^{-9}$, $\\sigma = 1.0$, grid $t = [0.0, 10^{-6}, 2 \\times 10^{-6}, 10^{-4}, 3 \\times 10^{-4}]$, seed $98765$.\n\nAnswer specification:\n- The output values are real numbers (floats).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, rounded to $10$ decimal places, in the same order as the test cases: $[v_1,v_2,v_3,v_4]$.", "solution": "The user has requested the derivation and implementation of an exact simulation scheme for a stochastic process described by the stochastic differential equation (SDE) for Brownian motion with drift.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **SDE:** $dX_t = \\mu \\, dt + \\sigma \\, dW_t$\n*   **Initial Condition:** $X_0 = x_0$\n*   **Process Solution:** $X_t = x_0 + \\mu t + \\sigma W_t$\n*   **Brownian Motion Properties:** $W_t$ is a standard Brownian motion with $W_0 = 0$, independent increments, and for $0 \\le s < t$, the increment $W_t - W_s$ is a Gaussian random variable with mean $0$ and variance $t-s$, denoted $W_t - W_s \\sim \\mathcal{N}(0, t-s)$.\n*   **Simulation Grid:** A fixed, discrete time grid $0 = t_0 < t_1 < \\cdots < t_n = T$.\n*   **Implementation Task:** Simulate a single path of $X_t$ for each test case, returning the terminal value $X_T = X_{t_n}$, rounded to $10$ decimal places. The simulation must be reproducible using a specified seed for each case.\n*   **Test Cases:**\n    1.  $x_0 = 1.2$, $\\mu = -0.3$, $\\sigma = 0.7$, grid $t = [0.0, 0.1, 0.5, 1.0]$, seed $20231011$.\n    2.  $x_0 = 0.0$, $\\mu = 2.5$, $\\sigma = 0.0$, grid $t = [0.0, 0.3, 0.7, 1.0]$, seed $777$.\n    3.  $x_0 = -3.0$, $\\mu = 0.0$, $\\sigma = 2.0$, grid $t = [0.0, 0.25, 0.5, 0.9, 1.3]$, seed $12345$.\n    4.  $x_0 = 0.5$, $\\mu = 1 \\times 10^{-9}$, $\\sigma = 1.0$, grid $t = [0.0, 10^{-6}, 2 \\times 10^{-6}, 10^{-4}, 3 \\times 10^{-4}]$, seed $98765$.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientific Grounding:** The problem is fundamentally sound. It describes Arithmetic Brownian Motion, a cornerstone model in stochastic calculus and quantitative finance. The provided SDE, its analytical solution, and the properties of Brownian motion are all standard and correct.\n*   **Well-Posedness:** The problem is well-posed. It requests the derivation and implementation of a known, exact simulation algorithm. All required parameters ($x_0$, $\\mu$, $\\sigma$), the simulation grid, and random seeds are provided, ensuring that a unique, deterministic (given the seed), and meaningful solution (the simulated path) can be computed.\n*   **Objectivity:** The problem statement is objective, using precise mathematical language and providing clear, unambiguous instructions.\n\n**Step 3: Verdict and Action**\n\nThe problem is scientifically valid, well-posed, and completely specified. There are no contradictions, ambiguities, or factual errors. Therefore, we proceed to the solution.\n\n### Derivation and Justification of the Exact Simulation Scheme\n\nThe objective is to simulate the value of the process $X_t$ at the discrete time points $t_0, t_1, \\ldots, t_n$. The basis for an exact simulation scheme is the analytical solution to the SDE, which is given as $X_t = x_0 + \\mu t + \\sigma W_t$.\n\nConsider two consecutive time points, $t_{i-1}$ and $t_i$, from the grid, where $i \\in \\{1, 2, \\ldots, n\\}$. We can write the value of the process at each of these points using the analytical solution:\n$$X_{t_i} = x_0 + \\mu t_i + \\sigma W_{t_i}$$\n$$X_{t_{i-1}} = x_0 + \\mu t_{i-1} + \\sigma W_{t_{i-1}}$$\n\nSubtracting the second equation from the first yields a relationship for the increment of the process $X_t$:\n$$X_{t_i} - X_{t_{i-1}} = (\\mu t_i - \\mu t_{i-1}) + (\\sigma W_{t_i} - \\sigma W_{t_{i-1}})$$\nRearranging this equation gives an iterative formula for $X_{t_i}$:\n$$X_{t_i} = X_{t_{i-1}} + \\mu (t_i - t_{i-1}) + \\sigma (W_{t_i} - W_{t_{i-1}})$$\n\nLet $\\Delta t_i = t_i - t_{i-1}$ be the time step. The equation becomes:\n$$X_{t_i} = X_{t_{i-1}} + \\mu \\Delta t_i + \\sigma (W_{t_i} - W_{t_{i-1}})$$\n\nThe core of the simulation lies in modeling the Brownian increment, $W_{t_i} - W_{t_{i-1}}$. Based on the fundamental properties of Brownian motion provided in the problem, for any $s < t$, the increment $W_t - W_s$ is a normally distributed random variable with mean $0$ and variance $t-s$. Therefore, for our time step $\\Delta t_i$:\n$$W_{t_i} - W_{t_{i-1}} \\sim \\mathcal{N}(0, \\Delta t_i)$$\n\nA random variable $Y \\sim \\mathcal{N}(0, \\sigma^2)$ can be expressed as $Y = \\sigma Z$, where $Z \\sim \\mathcal{N}(0, 1)$ is a standard normal random variable. Applying this to the Brownian increment, we have:\n$$W_{t_i} - W_{t_{i-1}} = \\sqrt{\\Delta t_i} \\cdot Z_i$$\nwhere $Z_i$ represents an independent draw from the standard normal distribution, $Z_i \\sim \\mathcal{N}(0, 1)$.\n\nSubstituting this back into our iterative formula, we obtain the exact simulation scheme:\n$$X_{t_i} = X_{t_{i-1}} + \\mu \\Delta t_i + \\sigma \\sqrt{\\Delta t_i} Z_i$$\n\nThe simulation procedure is as follows:\n1.  Initialize the process at time $t_0 = 0$ with the given initial value: $X_{t_0} = x_0$.\n2.  For each step $i$ from $1$ to $n$:\n    a. Calculate the time interval $\\Delta t_i = t_i - t_{i-1}$.\n    b. Generate an independent random variate $Z_i$ from the standard normal distribution $\\mathcal{N}(0, 1)$.\n    c. Update the process value using the derived scheme: $X_{t_i} = X_{t_{i-1}} + \\mu \\Delta t_i + \\sigma \\sqrt{\\Delta t_i} Z_i$.\n3.  The final value, $X_{t_n}$, is the required terminal value $X_T$.\n\n**Justification of Exactness:**\nThis scheme is termed \"exact\" because the joint distribution of the simulated values $(X_{t_0}, X_{t_1}, \\ldots, X_{t_n})$ is identical to the joint distribution of the true process sampled at those same time points. This is a direct consequence of our derivation. We did not approximate the SDE (as in the Euler-Maruyama method, which discretizes $dX_t$). Instead, we started from the exact integrated solution $X_t = x_0 + \\mu t + \\sigma W_t$ and used its properties. The increments of the simulated process, $X_{t_i} - X_{t_{i-1}}$, are defined to have the exact same distribution as the increments of the true process:\n$$X_{t_i} - X_{t_{i-1}} \\sim \\mathcal{N}(\\mu \\Delta t_i, \\sigma^2 \\Delta t_i)$$\nFurthermore, because the random draws $Z_i$ are independent, the simulated increments are also independent, correctly matching the independent increments property of the underlying Brownian motion. Summing our iterative steps confirms this:\n$$X_{t_n} = X_{t_0} + \\sum_{i=1}^{n} (\\mu \\Delta t_i + \\sigma \\sqrt{\\Delta t_i} Z_i) = x_0 + \\mu \\sum_{i=1}^{n} \\Delta t_i + \\sigma \\sum_{i=1}^{n} (W_{t_i} - W_{t_{i-1}})$$\nThe sums telescope perfectly: $\\sum \\Delta t_i = t_n - t_0 = T$ and $\\sum(W_{t_i} - W_{t_{i-1}}) = W_{t_n} - W_{t_0} = W_T$. This recovers the exact solution at the terminal time, $X_T = x_0 + \\mu T + \\sigma W_T$, demonstrating that the terminal value (and by extension, the entire path) has the correct distribution.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements an exact simulation scheme for Brownian motion with drift.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"x0\": 1.2, \"mu\": -0.3, \"sigma\": 0.7,\n            \"t_grid\": [0.0, 0.1, 0.5, 1.0],\n            \"seed\": 20231011\n        },\n        {\n            \"x0\": 0.0, \"mu\": 2.5, \"sigma\": 0.0,\n            \"t_grid\": [0.0, 0.3, 0.7, 1.0],\n            \"seed\": 777\n        },\n        {\n            \"x0\": -3.0, \"mu\": 0.0, \"sigma\": 2.0,\n            \"t_grid\": [0.0, 0.25, 0.5, 0.9, 1.3],\n            \"seed\": 12345\n        },\n        {\n            \"x0\": 0.5, \"mu\": 1e-9, \"sigma\": 1.0,\n            \"t_grid\": [0.0, 1e-6, 2e-6, 1e-4, 3e-4],\n            \"seed\": 98765\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        x0 = case[\"x0\"]\n        mu = case[\"mu\"]\n        sigma = case[\"sigma\"]\n        t_grid = case[\"t_grid\"]\n        seed = case[\"seed\"]\n\n        # Initialize the pseudo-random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        # Initialize the process value and time.\n        x_current = x0\n        t_prev = t_grid[0]\n\n        # Iterate through the time grid to simulate the path.\n        # The first time point t_grid[0] is the initial condition.\n        for t_current in t_grid[1:]:\n            # Calculate the time step.\n            dt = t_current - t_prev\n            \n            # Generate an independent draw from the standard normal distribution N(0, 1).\n            z = rng.normal(0.0, 1.0)\n            \n            # Apply the exact update formula:\n            # X_t = X_{t-1} + mu * dt + sigma * sqrt(dt) * Z\n            # The stochastic component is sigma * dW, where dW ~ N(0, dt).\n            # This is equivalent to sigma * sqrt(dt) * Z, where Z ~ N(0, 1).\n            drift_term = mu * dt\n            stochastic_term = sigma * np.sqrt(dt) * z\n            \n            x_current += drift_term + stochastic_term\n            \n            # Update the previous time for the next iteration.\n            t_prev = t_current\n\n        # After the loop, x_current holds the terminal value X_T.\n        # Round the final result to 10 decimal places as required.\n        terminal_value = round(x_current, 10)\n        results.append(terminal_value)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"}]}