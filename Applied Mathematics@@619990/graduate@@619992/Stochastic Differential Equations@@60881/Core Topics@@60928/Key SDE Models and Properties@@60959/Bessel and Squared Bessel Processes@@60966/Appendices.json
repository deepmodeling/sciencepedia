{"hands_on_practices": [{"introduction": "A crucial first step in understanding any stochastic process is to characterize its fundamental statistical properties. This exercise guides you through the derivation of the mean and variance for a squared Bessel process, or $\\mathrm{BESQ}^{\\delta}$ process, directly from its stochastic differential equation (SDE). By applying core principles of stochastic calculus, such as Itô's isometry and the properties of local martingales, you will build a solid foundation for analyzing more complex features of the process [@problem_id:2969839]. This practice is essential for developing the analytical rigor needed to work with SDEs, particularly in handling the integrability conditions that distinguish local martingales from true martingales.", "problem": "Let $\\{X_t\\}_{t \\geq 0}$ be the squared Bessel process of dimension $\\delta \\geq 0$ (often denoted $\\mathrm{BESQ}^{\\delta}$) started from $X_0 = x \\geq 0$, defined as the unique nonnegative strong solution to the stochastic differential equation (SDE)\n$$\ndX_t = \\delta \\, dt + 2 \\sqrt{X_t} \\, dW_t, \\qquad X_0 = x,\n$$\nwhere $\\{W_t\\}_{t \\geq 0}$ is a standard one-dimensional Brownian motion. The infinitesimal generator $\\mathcal{L}$ of $\\{X_t\\}$ acts on twice continuously differentiable functions $f \\in C^2(\\mathbb{R}_+)$ by\n$$\n\\mathcal{L} f(y) = \\delta \\, f'(y) + 2 y \\, f''(y), \\qquad y \\geq 0,\n$$\nwith the convention that the domain of $\\mathcal{L}$ contains functions $f$ of at most polynomial growth.\n\nUsing only fundamental definitions and well-tested facts from stochastic calculus (in particular Dynkin's formula, properties of continuous local martingales, and Itô's isometry), derive closed-form expressions for the expectation $\\mathbb{E}[X_t]$ and the variance $\\operatorname{Var}(X_t)$ at a fixed time $t \\geq 0$. Your derivation must carefully justify each step, including measurability and integrability where needed, and any use of Fubini's theorem or Tonelli's theorem must be explicitly justified.\n\nProvide the final expressions in terms of $x$, $\\delta$, and $t$. No numerical approximation is required.", "solution": "The problem as stated is well-posed, scientifically grounded, and contains all necessary information for a unique solution. It is a standard problem in the theory of stochastic differential equations concerning the moments of a squared Bessel process. I will proceed with the derivation.\n\nThe goal is to find the expectation $\\mathbb{E}[X_t]$ and the variance $\\operatorname{Var}(X_t)$ of the squared Bessel process $\\{X_t\\}_{t \\geq 0}$ with dimension $\\delta \\geq 0$ and initial value $X_0 = x \\geq 0$. The process is defined by the stochastic differential equation (SDE):\n$$\ndX_t = \\delta \\, dt + 2 \\sqrt{X_t} \\, dW_t, \\qquad X_0 = x\n$$\n\nFirst, we will compute the expectation $\\mathbb{E}[X_t]$.\nWe can formally integrate the SDE from time $0$ to $t$:\n$$\nX_t - X_0 = \\int_0^t \\delta \\, ds + \\int_0^t 2 \\sqrt{X_s} \\, dW_s\n$$\nSubstituting $X_0 = x$ and taking the expectation on both sides yields:\n$$\n\\mathbb{E}[X_t] - x = \\delta t + \\mathbb{E}\\left[\\int_0^t 2 \\sqrt{X_s} \\, dW_s\\right]\n$$\nThe term $M_t = \\int_0^t 2 \\sqrt{X_s} \\, dW_s$ is an Itô integral, which defines a continuous local martingale starting at $M_0 = 0$. For its expectation to be zero, $M_t$ must be a true martingale, not just a local one. A sufficient condition for this is the fulfillment of the Novikov condition, or more simply, that $\\mathbb{E}[\\langle M \\rangle_t]  \\infty$. The quadratic variation of $M_t$ is given by:\n$$\n\\langle M \\rangle_t = \\int_0^t (2\\sqrt{X_s})^2 \\, ds = \\int_0^t 4 X_s \\, ds\n$$\nThus, we need to show that $\\mathbb{E}[\\int_0^t 4 X_s \\, ds]  \\infty$. Since $X_s \\geq 0$ for all $s$ (as it is the unique non-negative solution), we can apply Tonelli's theorem to exchange the expectation and the integral:\n$$\n\\mathbb{E}\\left[\\int_0^t 4 X_s \\, ds\\right] = 4 \\int_0^t \\mathbb{E}[X_s] \\, ds\n$$\nThis means we need to establish that $\\mathbb{E}[X_s]$ is finite and integrable over $[0, t]$. We can demonstrate this using a stopping-time argument. Let $\\tau_n = \\inf\\{s \\geq 0 : X_s \\geq n\\}$ for $n \\in \\mathbb{N}$. The stopped process $M_{t \\wedge \\tau_n}$ is a bounded continuous local martingale, and therefore a true martingale. Hence, $\\mathbb{E}[M_{t \\wedge \\tau_n}] = 0$.\nTaking the expectation of the stopped SDE, we have:\n$$\n\\mathbb{E}[X_{t \\wedge \\tau_n}] = \\mathbb{E}[X_0] + \\mathbb{E}[\\delta (t \\wedge \\tau_n)] + \\mathbb{E}[M_{t \\wedge \\tau_n}] = x + \\delta \\mathbb{E}[t \\wedge \\tau_n]\n$$\nFor $\\delta \\geq 0$, the squared Bessel process does not explode to infinity in finite time, which means $\\lim_{n \\to \\infty} \\tau_n = \\infty$ almost surely. By the Monotone Convergence Theorem, since $t \\wedge \\tau_n \\uparrow t$ almost surely, we have $\\lim_{n \\to \\infty} \\mathbb{E}[t \\wedge \\tau_n] = t$.\nSince $X_t \\geq 0$, we can apply Fatou's Lemma:\n$$\n\\mathbb{E}[X_t] = \\mathbb{E}[\\liminf_{n \\to \\infty} X_{t \\wedge \\tau_n}] \\leq \\liminf_{n \\to \\infty} \\mathbb{E}[X_{t \\wedge \\tau_n}] = \\lim_{n \\to \\infty} (x + \\delta \\mathbb{E}[t \\wedge \\tau_n]) = x + \\delta t\n$$\nThis establishes that $\\mathbb{E}[X_s]$ is finite for any $s \\geq 0$. As $X$ is a continuous process, the map $s \\mapsto \\mathbb{E}[X_s]$ is continuous, which ensures its integrability on $[0,t]$. Therefore, $\\int_0^t \\mathbb{E}[X_s] \\, ds  \\infty$, which confirms that $\\mathbb{E}[\\langle M \\rangle_t]  \\infty$.\nSo, $M_t$ is a martingale, and $\\mathbb{E}[M_t] = 0$.\nTaking the expectation of $X_t = x + \\delta t + M_t$, we get:\n$$\n\\mathbb{E}[X_t] = x + \\delta t\n$$\nAlternatively, using Dynkin's formula with the function $f(y) = y$. We have $f'(y) = 1$ and $f''(y) = 0$. The infinitesimal generator acts as $\\mathcal{L}f(y) = \\delta f'(y) + 2y f''(y) = \\delta$. Dynkin's formula, $\\mathbb{E}[f(X_t)] - f(x) = \\mathbb{E}[\\int_0^t \\mathcal{L}f(X_s) ds]$, gives $\\mathbb{E}[X_t] - x = \\mathbb{E}[\\int_0^t \\delta ds] = \\delta t$. The application of this formula is justified by the same martingale argument presented above.\n\nNext, we will compute the variance $\\operatorname{Var}(X_t)$.\nThe variance is defined as $\\operatorname{Var}(X_t) = \\mathbb{E}[(X_t - \\mathbb{E}[X_t])^2]$. From our previous results:\n$$\nX_t - \\mathbb{E}[X_t] = (x + \\delta t + M_t) - (x + \\delta t) = M_t\n$$\nTherefore, $\\operatorname{Var}(X_t) = \\mathbb{E}[M_t^2]$. Since $M_t$ is a martingale with $\\mathbb{E}[M_t]=0$, its second moment is equal to the expectation of its quadratic variation: $\\mathbb{E}[M_t^2] = \\mathbb{E}[\\langle M \\rangle_t]$. This is a direct consequence of Itô's isometry.\nWe have already computed the quadratic variation: $\\langle M \\rangle_t = \\int_0^t 4 X_s \\, ds$.\nSo,\n$$\n\\operatorname{Var}(X_t) = \\mathbb{E}\\left[\\int_0^t 4 X_s \\, ds\\right]\n$$\nUsing Tonelli's theorem again, which is justified as $X_s \\geq 0$:\n$$\n\\operatorname{Var}(X_t) = \\int_0^t 4 \\mathbb{E}[X_s] \\, ds\n$$\nNow, we substitute the expression we found for the expectation, $\\mathbb{E}[X_s] = x + \\delta s$:\n$$\n\\operatorname{Var}(X_t) = \\int_0^t 4(x + \\delta s) \\, ds = 4 \\left[ xs + \\frac{\\delta s^2}{2} \\right]_0^t\n$$\nEvaluating the definite integral gives:\n$$\n\\operatorname{Var}(X_t) = 4 \\left( xt + \\frac{\\delta t^2}{2} \\right) = 4xt + 2\\delta t^2\n$$\nThus, we have derived the closed-form expressions for the expectation and variance of the squared Bessel process at time $t$.\n\nThe expectation is $\\mathbb{E}[X_t] = x + \\delta t$.\nThe variance is $\\operatorname{Var}(X_t) = 4xt + 2\\delta t^2$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx + \\delta t  4xt + 2\\delta t^2\n\\end{pmatrix}\n}\n$$", "id": "2969839"}, {"introduction": "Beyond static moments, the dynamic behavior of a process's path is of central interest. This practice explores the concept of hitting probabilities, a cornerstone in the theory of one-dimensional diffusions. You will determine the probability that a Bessel process reaches a certain level $a$ before returning to the origin by solving a boundary value problem associated with its infinitesimal generator [@problem_id:2969808]. This exercise beautifully illustrates the powerful connection between stochastic processes and partial differential equations, showing how an analytical approach can solve purely probabilistic questions.", "problem": "Consider a Bessel process of dimension $\\delta \\in (0,2)$, denoted by $(R_t)_{t \\geq 0}$, started at $R_0 = r \\in (0,a)$ with $a0$. The Bessel process is defined as the unique strong solution to the stochastic differential equation\n$$\n\\mathrm{d}R_t = \\mathrm{d}W_t + \\frac{\\delta - 1}{2 R_t} \\,\\mathrm{d}t,\n$$\nwhere $(W_t)_{t \\geq 0}$ is a standard one-dimensional Brownian motion. Let $\\tau_0 := \\inf\\{t \\geq 0 : R_t = 0\\}$ and $\\tau_a := \\inf\\{t \\geq 0 : R_t = a\\}$ denote the first hitting times of $0$ and $a$, respectively. Define the infinitesimal generator $L$ of $(R_t)_{t \\geq 0}$ on functions $f \\in C^2((0,\\infty))$ via\n$$\nL f(r) := \\frac{1}{2} f''(r) + \\frac{\\delta - 1}{2 r} f'(r).\n$$\nUsing the principle that harmonic functions for the generator $L$ characterize hitting probabilities for one-dimensional diffusions, determine the closed-form expression for\n$$\n\\mathbb{P}_r\\big(\\tau_a  \\tau_0\\big)\n$$\nby solving the boundary value problem $L f = 0$ on $(0,a)$ with boundary conditions $f(0) = 0$ and $f(a) = 1$. Your final answer must be a single analytic expression in terms of $r$, $a$, and $\\delta$. Do not round your answer.", "solution": "The problem asks for the probability $\\mathbb{P}_r\\big(\\tau_a  \\tau_0\\big)$ for a Bessel process $(R_t)_{t \\geq 0}$ of dimension $\\delta \\in (0,2)$ starting at $R_0 = r \\in (0,a)$. This quantity can be found by solving a specific boundary value problem.\n\nLet $f(r) = \\mathbb{P}_r\\big(\\tau_a  \\tau_0\\big)$ be the probability that the process hits the level $a$ before it hits the origin $0$, given it starts at $r$. For a one-dimensional diffusion process, this probability function $f(r)$ is harmonic with respect to the infinitesimal generator $L$ of the process on the interval $(0,a)$. This means that $f(r)$ must satisfy the ordinary differential equation (ODE) $L f(r) = 0$ for $r \\in (0,a)$.\n\nThe infinitesimal generator is given as\n$$\nL f(r) = \\frac{1}{2} f''(r) + \\frac{\\delta - 1}{2 r} f'(r).\n$$\nSetting $L f(r) = 0$, we obtain the following second-order linear homogeneous ODE:\n$$\n\\frac{1}{2} f''(r) + \\frac{\\delta - 1}{2 r} f'(r) = 0.\n$$\nMultiplying by $2$ simplifies the equation to:\n$$\nf''(r) + \\frac{\\delta - 1}{r} f'(r) = 0.\n$$\nTo solve this ODE, we introduce an auxiliary function $g(r) = f'(r)$. The equation then becomes a first-order linear ODE for $g(r)$:\n$$\ng'(r) + \\frac{\\delta - 1}{r} g(r) = 0.\n$$\nThis is a separable equation, which we can write as:\n$$\n\\frac{g'(r)}{g(r)} = - \\frac{\\delta - 1}{r}.\n$$\nIntegrating both sides with respect to $r$:\n$$\n\\int \\frac{g'(r)}{g(r)} \\mathrm{d}r = \\int -\\frac{\\delta - 1}{r} \\mathrm{d}r.\n$$\nThis yields:\n$$\n\\ln|g(r)| = -(\\delta - 1)\\ln|r| + C_1,\n$$\nwhere $C_1$ is a constant of integration. Since the process is defined for $r  0$, we can drop the absolute value signs:\n$$\n\\ln(g(r)) = (1 - \\delta)\\ln(r) + C_1 = \\ln(r^{1-\\delta}) + C_1.\n$$\nExponentiating both sides, we get:\n$$\ng(r) = \\exp(\\ln(r^{1-\\delta}) + C_1) = \\exp(C_1) r^{1-\\delta}.\n$$\nLetting $C_2 = \\exp(C_1)$, we have $g(r) = C_2 r^{1-\\delta}$. Recalling that $g(r) = f'(r)$, we have:\n$$\nf'(r) = C_2 r^{1-\\delta}.\n$$\nTo find $f(r)$, we integrate $f'(r)$ with respect to $r$:\n$$\nf(r) = \\int C_2 r^{1-\\delta} \\mathrm{d}r.\n$$\nThe problem specifies that $\\delta \\in (0,2)$, which implies that the exponent $1-\\delta \\neq -1$. Therefore, the integration is straightforward:\n$$\nf(r) = C_2 \\frac{r^{1-\\delta+1}}{1-\\delta+1} + C_3 = C_2 \\frac{r^{2-\\delta}}{2-\\delta} + C_3.\n$$\nRedefining the constant $C_2 / (2-\\delta)$ as a new constant $A$ and $C_3$ as $B$, the general solution for $f(r)$ is:\n$$\nf(r) = A r^{2-\\delta} + B.\n$$\nNow, we must apply the boundary conditions provided in the problem statement, which are derived from the interpretation of $f(r)$ as a hitting probability.\nThe boundary conditions are $f(0)=0$ and $f(a)=1$.\n1.  The condition $f(0)=0$ means that if the process starts at the origin (or infinitesimally close to it), the probability of hitting $a$ before returning to $0$ is $0$. This reflects the fact that $\\tau_0=0$ if $R_0 = 0$.\n    We evaluate the limit of $f(r)$ as $r \\to 0^+$:\n    $$\n    \\lim_{r\\to 0^+} f(r) = \\lim_{r\\to 0^+} (A r^{2-\\delta} + B) = 0.\n    $$\n    Since $\\delta \\in (0,2)$, the exponent $2-\\delta$ is strictly positive. Thus, $\\lim_{r\\to 0^+} r^{2-\\delta} = 0$. The equation becomes:\n    $$\n    A \\cdot 0 + B = 0 \\implies B = 0.\n    $$\n    The solution simplifies to $f(r) = A r^{2-\\delta}$.\n\n2.  The condition $f(a)=1$ means that if the process starts at the boundary $a$, it has already hit $a$, so the probability of hitting $a$ before $0$ is $1$.\n    Applying this condition:\n    $$\n    f(a) = A a^{2-\\delta} = 1.\n    $$\n    We can now solve for the constant $A$:\n    $$\n    A = \\frac{1}{a^{2-\\delta}} = a^{-(2-\\delta)} = a^{\\delta-2}.\n    $$\nSubstituting this value of $A$ back into the expression for $f(r)$, we obtain the final solution for the hitting probability:\n$$\nf(r) = (a^{\\delta-2}) r^{2-\\delta} = \\frac{r^{2-\\delta}}{a^{2-\\delta}}.\n$$\nThis can be written more compactly as:\n$$\n\\mathbb{P}_r\\big(\\tau_a  \\tau_0\\big) = \\left(\\frac{r}{a}\\right)^{2-\\delta}.\n$$\nThis expression is the closed-form solution for the desired probability in terms of the initial position $r$, the boundary $a$, and the dimension $\\delta$.", "answer": "$$\\boxed{\\left(\\frac{r}{a}\\right)^{2-\\delta}}$$", "id": "2969808"}, {"introduction": "This exercise bridges the gap between abstract theory and computational practice by tasking you with building an exact simulator for the squared Bessel process. Unlike approximation schemes such as Euler-Maruyama, an exact sampler allows for the generation of random variables that follow the true transition law of the process, a significant advantage in many applications. You will leverage the deep connection between the $\\mathrm{BESQ}^{\\delta}$ process and the noncentral chi-square distribution to implement this sampler [@problem_id:2969795]. To close the loop, you will then use your simulator to numerically verify the theoretical moments you derived in the first practice, developing essential skills in Monte Carlo methods and model validation.", "problem": "Let $\\left(X_t\\right)_{t \\geq 0}$ be the squared Bessel process of dimension $\\delta$, denoted $\\mathrm{BESQ}^{\\delta}$, defined as the unique strong solution to the stochastic differential equation\n$$\ndX_t = \\delta\\, dt + 2 \\sqrt{X_t}\\, dW_t,\\quad X_0 = x_0 \\geq 0\n$$\nwhere $\\left(W_t\\right)_{t \\geq 0}$ is a standard one-dimensional Brownian motion. The Markov semigroup of $\\mathrm{BESQ}^{\\delta}$ has a transition density expressible in terms of the modified Bessel function of the first kind. A classical fact is that the transition law over a time increment is intimately connected to the noncentral chi-square distribution.\n\nDesign and implement an exact simulator for $\\mathrm{BESQ}^{\\delta}$ over a single time increment $\\Delta t  0$ that samples $X_{t+\\Delta t}$ given $X_t = x$ by reducing the transition law to sampling from a noncentral chi-square distribution (without using any approximation schemes such as Euler–Maruyama). Your simulator must produce exact marginal samples at the specified future time from the Markov transition. Then verify its correctness by comparing empirical moments against the theoretical moments obtained from Itô calculus.\n\nStart from the fundamental base:\n- The squared Bessel process $\\mathrm{BESQ}^{\\delta}$ satisfies the stochastic differential equation\n$$\ndX_t = \\delta\\, dt + 2 \\sqrt{X_t}\\, dW_t.\n$$\n- The Kolmogorov forward equation for the transition density $p(t,x,y)$ of a Markov diffusion with generator\n$$\n\\mathcal{L} f(y) = \\delta f'(y) + 2 y f''(y)\n$$\nand Itô's formula for polynomial functions of $X_t$ yield closed-form expressions for the first two moments:\n$$\n\\mathbb{E}[X_t] = x_0 + \\delta t,\\qquad \\mathrm{Var}(X_t) = 2 \\delta t^2 + 4 x_0 t.\n$$\n- The noncentral chi-square distribution with degrees of freedom $k  0$ and noncentrality parameter $\\lambda \\geq 0$ has probability density function\n$$\nf(z; k, \\lambda) = \\frac{1}{2} \\exp\\!\\left(-\\frac{z+\\lambda}{2}\\right) \\left(\\frac{z}{\\lambda}\\right)^{\\nu/2} I_{\\nu}\\!\\left(\\sqrt{\\lambda z}\\right),\\quad z0,\\ \\nu=\\frac{k}{2}-1\n$$\nwhere $I_{\\nu}$ is the modified Bessel function of the first kind.\n\nYour program must:\n1. Implement an exact one-step $\\mathrm{BESQ}^{\\delta}$ transition sampler based on noncentral chi-square sampling for arbitrary current state $x \\geq 0$, dimension parameter $\\delta  0$, and time increment $\\Delta t  0$.\n2. Use this sampler to generate independent samples of $X_T$ at a fixed horizon $T$ directly (one step), and in another case via two consecutive exact steps of size $T/2$ (two steps).\n3. For each specified test case, compute the empirical mean and variance from the Monte Carlo samples, and compare with the theoretical mean and variance given by the formulas above. Report whether both empirical mean and variance are within predefined tolerances of the theoretical values.\n\nTest suite:\n- Case 1 (general happy path): $\\delta = 3.0$, $x_0 = 1.5$, $T = 2.0$, one-step sampling, with tolerances $\\varepsilon_{\\mathrm{mean}} = 0.01$ and $\\varepsilon_{\\mathrm{var}} = 0.03$ on relative error.\n- Case 2 (boundary at zero state): $\\delta = 0.5$, $x_0 = 0.0$, $T = 1.0$, one-step sampling, with tolerances $\\varepsilon_{\\mathrm{mean}} = 0.015$ and $\\varepsilon_{\\mathrm{var}} = 0.05$ on relative error.\n- Case 3 (moderate dimension): $\\delta = 1.0$, $x_0 = 4.0$, $T = 0.75$, one-step sampling, with tolerances $\\varepsilon_{\\mathrm{mean}} = 0.01$ and $\\varepsilon_{\\mathrm{var}} = 0.03$ on relative error.\n- Case 4 (small time increment and large noncentrality parameter): $\\delta = 10.0$, $x_0 = 0.5$, $T = 0.001$, one-step sampling, with tolerances $\\varepsilon_{\\mathrm{mean}} = 0.02$ and $\\varepsilon_{\\mathrm{var}} = 0.08$ on relative error.\n- Case 5 (semigroup consistency via two exact steps): $\\delta = 2.0$, $x_0 = 3.0$, $T = 1.0$, two-step sampling with $\\Delta t = 0.5$, with tolerances $\\varepsilon_{\\mathrm{mean}} = 0.01$ and $\\varepsilon_{\\mathrm{var}} = 0.03$ on relative error.\n\nFor all test cases, draw $N = 100000$ independent samples per verification. Use a fixed random seed to ensure reproducibility.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true,true,false,true,true]\"). Each entry corresponds to the test case in the order presented and is a boolean indicating whether both the empirical mean and variance matched the theoretical values within the specified tolerances.\n- No physical units or angles are involved. All results are dimensionless real numbers.", "solution": "### Problem Validation\n\n#### Step 1: Extract Givens\n- **Process Definition**: The squared Bessel process of dimension $\\delta$, $\\mathrm{BESQ}^{\\delta}$, is defined by the stochastic differential equation (SDE):\n$$\ndX_t = \\delta\\, dt + 2 \\sqrt{X_t}\\, dW_t,\\quad X_0 = x_0 \\geq 0\n$$\nwhere $(W_t)_{t \\geq 0}$ is a standard one-dimensional Brownian motion.\n- **Theoretical Moments**: The first two moments of $X_t$ are given by:\n$$\n\\mathbb{E}[X_t] = x_0 + \\delta t\n$$\n$$\n\\mathrm{Var}(X_t) = 2 \\delta t^2 + 4 x_0 t\n$$\n- **Noncentral Chi-Square PDF**: The probability density function (PDF) for a noncentral chi-square distribution with degrees of freedom $k  0$ and noncentrality parameter $\\lambda \\geq 0$ is:\n$$\nf(z; k, \\lambda) = \\frac{1}{2} \\exp\\!\\left(-\\frac{z+\\lambda}{2}\\right) \\left(\\frac{z}{\\lambda}\\right)^{\\nu/2} I_{\\nu}\\!\\left(\\sqrt{\\lambda z}\\right),\\quad z0,\\ \\nu=\\frac{k}{2}-1\n$$\nwhere $I_{\\nu}$ is the modified Bessel function of the first kind.\n- **Task Requirements**:\n    1. Implement an exact one-step sampler for the $\\mathrm{BESQ}^{\\delta}$ transition, from state $x$ over time $\\Delta t$, using the noncentral chi-square distribution.\n    2. Use the sampler to generate $N=100000$ independent samples for various test cases.\n    3. Verify correctness by comparing empirical mean and variance with theoretical values, checking if relative errors are within specified tolerances.\n    4. Use a fixed random seed for reproducibility.\n- **Test Suite**:\n    - **Case 1**: $\\delta = 3.0$, $x_0 = 1.5$, $T = 2.0$, one-step, $\\varepsilon_{\\mathrm{mean}} = 0.01$, $\\varepsilon_{\\mathrm{var}} = 0.03$.\n    - **Case 2**: $\\delta = 0.5$, $x_0 = 0.0$, $T = 1.0$, one-step, $\\varepsilon_{\\mathrm{mean}} = 0.015$, $\\varepsilon_{\\mathrm{var}} = 0.05$.\n    - **Case 3**: $\\delta = 1.0$, $x_0 = 4.0$, $T = 0.75$, one-step, $\\varepsilon_{\\mathrm{mean}} = 0.01$, $\\varepsilon_{\\mathrm{var}} = 0.03$.\n    - **Case 4**: $\\delta = 10.0$, $x_0 = 0.5$, $T = 0.001$, one-step, $\\varepsilon_{\\mathrm{mean}} = 0.02$, $\\varepsilon_{\\mathrm{var}} = 0.08$.\n    - **Case 5**: $\\delta = 2.0$, $x_0 = 3.0$, $T = 1.0$, two-step with $\\Delta t = 0.5$, $\\varepsilon_{\\mathrm{mean}} = 0.01$, $\\varepsilon_{\\mathrm{var}} = 0.03$.\n\n#### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is well-grounded in the theory of stochastic differential equations and stochastic processes. The $\\mathrm{BESQ}^{\\delta}$ process is a fundamental object of study. The SDE, moment formulas, and the connection to the noncentral chi-square distribution are standard, mathematically proven results.\n2.  **Well-Posed**: The problem is well-posed. It asks for the implementation and verification of a known exact simulation algorithm. All parameters and conditions for each test case are explicitly provided, including the number of samples and error tolerances. A unique and meaningful solution (the implementation and its verification) exists.\n3.  **Objective**: The problem is stated in precise, objective mathematical language. The validation criteria (comparison of moments) are quantitative and unambiguous.\n\n#### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, objective, and self-contained. It contains no contradictions, ambiguities, or unsound premises. The validation is successful. I will proceed with the solution.\n\n### Solution\n\nThe core of this problem is to devise an exact simulation algorithm for the transition of a squared Bessel process, $\\mathrm{BESQ}^{\\delta}$, and verify its correctness. The specified method relies on the established connection between the transition law of a $\\mathrm{BESQ}^{\\delta}$ process and the noncentral chi-square distribution.\n\n**1. The Exact Simulation Principle: Connection to Noncentral Chi-Square Distribution**\n\nLet $(X_t)_{t \\geq 0}$ be a $\\mathrm{BESQ}^{\\delta}$ process with initial state $X_t = x$. We aim to sample the value of the process at a future time $t+\\Delta t$. The transition probability density, $p(\\Delta t, x, y)$, for a transition from $x$ to $y$ over a time interval $\\Delta t$ is given by:\n$$\np(\\Delta t, x, y) = \\frac{1}{2\\Delta t} \\left(\\frac{y}{x}\\right)^{(\\delta-2)/4} \\exp\\left(-\\frac{x+y}{2\\Delta t}\\right) I_{(\\delta-2)/2}\\left(\\frac{\\sqrt{xy}}{\\Delta t}\\right)\n$$\nwhere $I_{\\nu}$ is the modified Bessel function of the first kind of order $\\nu = (\\delta-2)/2$.\n\nThe problem states that this distribution is related to the noncentral chi-square distribution, $\\chi'^2_k(\\lambda)$, with $k$ degrees of freedom and noncentrality parameter $\\lambda$. Let $Z \\sim \\chi'^2_k(\\lambda)$. Its PDF is given in the problem statement, which we can write as:\n$$\nf_Z(z; k, \\lambda) = \\frac{1}{2} \\exp\\left(-\\frac{z+\\lambda}{2}\\right) \\left(\\frac{z}{\\lambda}\\right)^{(k-2)/4} I_{(k-2)/2}(\\sqrt{\\lambda z})\n$$\nWe seek a scaled random variable $Y=cZ$ whose distribution matches that of $X_{t+\\Delta t}$. The PDF of $Y$ is found by a change of variables: $f_Y(y) = \\frac{1}{c} f_Z(y/c)$.\n$$\nf_Y(y) = \\frac{1}{c} \\left[ \\frac{1}{2} \\exp\\left(-\\frac{y/c+\\lambda}{2}\\right) \\left(\\frac{y/c}{\\lambda}\\right)^{(k-2)/4} I_{(k-2)/2}(\\sqrt{\\lambda y/c}) \\right]\n$$\nMatching $f_Y(y)$ with $p(\\Delta t, x, y)$, we compare the terms:\n- **Exponential term**: The argument of the exponential in $f_Y(y)$ is $-\\frac{y}{2c} - \\frac{\\lambda}{2}$. The argument in $p(\\Delta t, x, y)$ is $-\\frac{y}{2\\Delta t} - \\frac{x}{2\\Delta t}$. Equating these gives $c=\\Delta t$ and $\\lambda = x/\\Delta t$.\n- **Bessel function term**: The argument of $I_{\\nu}$ in $f_Y(y)$ becomes $\\sqrt{(x/\\Delta t) \\cdot y / \\Delta t} = \\frac{\\sqrt{xy}}{\\Delta t}$, which matches the argument in $p(\\Delta t, x, y)$.\n- **Power term and order**: The power term in $f_Y(y)$ becomes $\\left( \\frac{y/\\Delta t}{x/\\Delta t} \\right)^{(k-2)/4} = \\left(\\frac{y}{x}\\right)^{(k-2)/4}$. To match the power $(\\delta-2)/4$ in $p(\\Delta t, x, y)$, we must have $k=\\delta$. This also implies the orders of the Bessel functions, $(\\delta-2)/2$, are consistent.\n- **Prefactor**: The prefactor in $f_Y(y)$ is $\\frac{1}{2c} = \\frac{1}{2\\Delta t}$, which matches perfectly.\n\nThis confirms the relationship: if $X_t=x$, the law of $X_{t+\\Delta t}$ is identical to the law of the random variable $\\Delta t \\cdot Z$, where $Z$ is a noncentral chi-square random variable with parameters:\n- Degrees of freedom: $k = \\delta$\n- Noncentrality parameter: $\\lambda = x/\\Delta t$\n\nThis provides a direct, exact sampling algorithm:\n1. Given $x$, $\\delta$, $\\Delta t$.\n2. Compute $k = \\delta$ and $\\lambda = x/\\Delta t$.\n3. Sample a value $z$ from $\\chi'^2_k(\\lambda)$.\n4. The sample for $X_{t+\\Delta t}$ is $y = \\Delta t \\cdot z$.\n\nA special case arises when $x=0$, leading to $\\lambda=0$. A noncentral chi-square distribution with zero noncentrality is simply a central chi-square distribution, $\\chi^2_k$. This is consistent with the fact that a $\\mathrm{BESQ}^{\\delta}$ starting at $0$ is the sum of squares of $\\delta$ independent standard Brownian motions.\n\n**2. Monte Carlo Verification Procedure**\n\nTo verify the correctness of this sampler, we use a Monte Carlo approach. For each test case, we generate a large number ($N=100000$) of independent samples of $X_T$ and compare the empirical mean and variance of these samples to their theoretical counterparts.\n\nThe theoretical moments at time $T$, starting from $x_0$, are:\n$$\n\\mathbb{E}[X_T] = x_0 + \\delta T\n$$\n$$\n\\mathrm{Var}(X_T) = 2 \\delta T^2 + 4 x_0 T\n$$\n\nFor a set of $N$ generated samples $\\{y_1, y_2, \\dots, y_N\\}$, the empirical moments are:\n$$\n\\text{Mean}_{\\text{emp}} = \\frac{1}{N}\\sum_{i=1}^{N} y_i, \\qquad \\text{Var}_{\\text{emp}} = \\frac{1}{N}\\sum_{i=1}^{N} (y_i - \\text{Mean}_{\\text{emp}})^2\n$$\n\nThe validation checks if the relative errors are within the specified tolerances, $\\varepsilon_{\\mathrm{mean}}$ and $\\varepsilon_{\\mathrm{var}}$:\n$$\n\\left| \\frac{\\text{Mean}_{\\text{emp}} - \\mathbb{E}[X_T]}{\\mathbb{E}[X_T]} \\right| \\leq \\varepsilon_{\\mathrm{mean}} \\quad \\text{and} \\quad \\left| \\frac{\\text{Var}_{\\text{emp}} - \\mathrm{Var}(X_T)}{\\mathrm{Var}(X_T)} \\right| \\leq \\varepsilon_{\\mathrm{var}}\n$$\nSince all parameters ($\\delta, T, x_0$) are non-negative and not simultaneously zero, the theoretical moments are positive, and division by zero is not a concern. For the test cases, the problem constraints ($\\delta > 0, T > 0, x_0 \\ge 0$) ensure this.\n\n**3. Implementation for Test Cases**\n\n- **One-Step Sampling (Cases 1-4)**: The samples for $X_T$ are generated in a single step with $\\Delta t = T$ and current state $x = x_0$.\n- **Two-Step Sampling (Case 5)**: This case verifies the Chapman-Kolmogorov property of the Markov process. We simulate from $t=0$ to $t=T$ in two steps of size $\\Delta t = T/2$.\n    1. **Step 1 (t=0 to t=T/2)**: Generate $N$ samples of $X_{T/2}$ given $X_0 = x_0$. The noncentrality parameter is $\\lambda_1 = x_0 / (T/2)$. This yields an array of intermediate states, $\\{x^{(i)}_{T/2}\\}_{i=1}^N$.\n    2. **Step 2 (t=T/2 to t=T)**: For each intermediate state $x^{(i)}_{T/2}$, we sample a final state $X_T^{(i)}$. The key is that the noncentrality parameter for the second step, $\\lambda_2^{(i)} = x^{(i)}_{T/2} / (T/2)$, is now different for each of the $N$ parallel simulations. Scientific computing libraries like SciPy allow the noncentrality parameter of the `ncx2` distribution to be an array, which perfectly suits this task.\nThe final set of samples $\\{X_T^{(i)}\\}_{i=1}^N$ is then used to compute the empirical moments, which are compared against the theoretical moments at time $T$.\n\nA fixed random seed is used to ensure the Monte Carlo simulation is reproducible. The implementation will use `numpy` for numerical operations and `scipy.stats.ncx2` for sampling from the noncentral chi-square distribution.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import ncx2\n\ndef solve():\n    \"\"\"\n    Implements and verifies an exact simulator for the squared Bessel process (BESQ)\n    by reducing its transition law to sampling from a noncentral chi-square distribution.\n    \"\"\"\n    \n    # A fixed random seed ensures reproducibility of the Monte Carlo simulation.\n    RANDOM_SEED = 42\n    \n    # Number of independent samples for Monte Carlo verification.\n    NUM_SAMPLES = 100000\n\n    test_cases = [\n        # Case 1: General happy path\n        {'delta': 3.0, 'x0': 1.5, 'T': 2.0, 'steps': 1, 'tol_mean': 0.01, 'tol_var': 0.03},\n        # Case 2: Boundary at zero state\n        {'delta': 0.5, 'x0': 0.0, 'T': 1.0, 'steps': 1, 'tol_mean': 0.015, 'tol_var': 0.05},\n        # Case 3: Moderate dimension\n        {'delta': 1.0, 'x0': 4.0, 'T': 0.75, 'steps': 1, 'tol_mean': 0.01, 'tol_var': 0.03},\n        # Case 4: Small time increment and large noncentrality\n        {'delta': 10.0, 'x0': 0.5, 'T': 0.001, 'steps': 1, 'tol_mean': 0.02, 'tol_var': 0.08},\n        # Case 5: Semigroup consistency via two exact steps\n        {'delta': 2.0, 'x0': 3.0, 'T': 1.0, 'steps': 2, 'tol_mean': 0.01, 'tol_var': 0.03},\n    ]\n\n    results = []\n\n    # Seeding the global random number generator for reproducibility.\n    # The scipy.stats functions will use this global state.\n    np.random.seed(RANDOM_SEED)\n\n    for case in test_cases:\n        delta = case['delta']\n        x0 = case['x0']\n        T = case['T']\n        steps = case['steps']\n        tol_mean = case['tol_mean']\n        tol_var = case['tol_var']\n\n        # --- Theoretical Moments Calculation ---\n        # E[X_T] = x0 + delta * T\n        # Var(X_T) = 2 * delta * T^2 + 4 * x0 * T\n        theoretical_mean = x0 + delta * T\n        theoretical_var = 2 * delta * T**2 + 4 * x0 * T\n\n        # --- Monte Carlo Simulation ---\n        dt = T / steps\n        current_x_samples = np.full(NUM_SAMPLES, x0)\n\n        for _ in range(steps):\n            # Degrees of freedom for the noncentral chi-square distribution is delta.\n            k = delta\n            # Noncentrality parameter is current state / time increment.\n            # This can be a scalar (for step 1) or an array (for subsequent steps).\n            noncentrality = current_x_samples / dt\n            \n            # Sample from the underlying chi-square distribution.\n            # The ncx2.rvs function can handle an array of noncentrality parameters.\n            chi2_samples = ncx2.rvs(df=k, nc=noncentrality, size=NUM_SAMPLES)\n            \n            # Scale the samples to get the BESQ process values.\n            current_x_samples = dt * chi2_samples\n\n        final_samples = current_x_samples\n\n        # --- Verification ---\n        empirical_mean = np.mean(final_samples)\n        # Using ddof=0 for population variance estimate, which is standard in MC.\n        empirical_var = np.var(final_samples, ddof=0)\n        \n        # Calculate relative errors.\n        # Theoretical moments are always positive given the problem constraints (delta>0, T>0, x0>=0).\n        rel_err_mean = np.abs(empirical_mean - theoretical_mean) / theoretical_mean\n        rel_err_var = np.abs(empirical_var - theoretical_var) / theoretical_var\n\n        # Check if both mean and variance are within tolerance.\n        is_valid = (rel_err_mean = tol_mean) and (rel_err_var = tol_var)\n        results.append(str(is_valid).lower())\n\n    # --- Final Output ---\n    # The output string must be in the format \"[true,false,...]\"\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2969795"}]}