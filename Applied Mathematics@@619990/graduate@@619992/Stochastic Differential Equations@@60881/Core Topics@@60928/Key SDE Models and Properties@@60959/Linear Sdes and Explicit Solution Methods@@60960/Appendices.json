{"hands_on_practices": [{"introduction": "The explicit solution to a general linear stochastic differential equation is typically found using an integrating factor method, where the factor is a stochastic exponential. This exercise reverses the process, asking you to verify that the standard solution form indeed satisfies the original equation. By applying Itô's product rule and carefully tracking all terms, you will gain a hands-on appreciation for the interplay between drift, diffusion, and the crucial quadratic covariation that arises from the interaction of different stochastic components. This practice is fundamental to mastering the mechanics of Itô calculus and understanding the structure of SDE solutions. [@problem_id:2985096]", "problem": "Let $\\{(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\in [0,T]}, \\mathbb{P})\\}$ be a filtered probability space satisfying the usual conditions, carrying a one-dimensional standard Brownian motion (SBM) $W = (W_t)_{t \\in [0,T]}$. Let $a, \\sigma, f, g : [0,T] \\to \\mathbb{R}$ be deterministic, continuous, and bounded functions, and let $x_0 \\in \\mathbb{R}$ be a fixed initial value. Consider the linear stochastic differential equation (SDE)\n$$\ndX_t \\;=\\; a(t)\\,X_t\\,dt \\;+\\; \\sigma(t)\\,X_t\\,dW_t \\;+\\; f(t)\\,dt \\;+\\; g(t)\\,dW_t, \n\\qquad X_0 \\;=\\; x_0.\n$$\nDefine the stochastic exponential (also called the Doléans-Dade exponential) associated with the semimartingale $\\int_0^t \\sigma(s)\\,dW_s + \\int_0^t a(s)\\,ds$ by\n$$\n\\Lambda_t \\;=\\; \\exp\\!\\Bigg(\\int_0^t \\sigma(s)\\,dW_s \\;+\\; \\int_0^t a(s)\\,ds \\;-\\; \\frac{1}{2}\\int_0^t \\sigma(s)^2\\,ds\\Bigg),\n\\qquad t \\in [0,T].\n$$\nConsider the following candidate explicit solution with an as-yet unspecified deterministic correction term $c : [0,T] \\to \\mathbb{R}$:\n$$\nX_t \\;=\\; \\Lambda_t \\left( x_0 \\;+\\; \\int_0^t \\Lambda_s^{-1}\\,\\big(f(s) + c(s)\\big)\\,ds \\;+\\; \\int_0^t \\Lambda_s^{-1}\\,g(s)\\,dW_s \\right).\n$$\nUsing only Itô’s product rule and the characterization of quadratic covariation for continuous semimartingales, verify that the above $X_t$ satisfies the given SDE if and only if $c$ is chosen appropriately. Determine the unique closed-form expression for $c(t)$ in terms of $\\sigma(t)$ and $g(t)$ such that the verification succeeds. Your final answer must be this expression, simplified as a single analytic formula. No rounding is required, and no units are involved.", "solution": "The problem requires the determination of a deterministic function $c(t)$ such that a given candidate process $X_t$ is the solution to a specified linear stochastic differential equation (SDE). The verification will be performed using Itô's calculus, specifically the product rule for semimartingales.\n\nThe SDE is given by:\n$$\ndX_t = (a(t)X_t + f(t))\\,dt + (\\sigma(t)X_t + g(t))\\,dW_t, \\quad X_0 = x_0\n$$\n\nThe candidate solution is of the form $X_t = \\Lambda_t Y_t$, where $\\Lambda_t$ is the stochastic exponential term and $Y_t$ is the process in parentheses. Let us define these two processes explicitly:\n$$\n\\Lambda_t = \\exp\\left(\\int_0^t \\sigma(s)\\,dW_s + \\int_0^t a(s)\\,ds - \\frac{1}{2}\\int_0^t \\sigma(s)^2\\,ds\\right)\n$$\n$$\nY_t = x_0 + \\int_0^t \\Lambda_s^{-1}\\,(f(s) + c(s))\\,ds + \\int_0^t \\Lambda_s^{-1}\\,g(s)\\,dW_s\n$$\nOur strategy is to compute the differential $dX_t$ using Itô's product rule and then equate the resulting drift and diffusion coefficients with those of the given SDE.\n\nFirst, we determine the differential $d\\Lambda_t$. Let $Z_t = \\int_0^t \\sigma(s)\\,dW_s + \\int_0^t a(s)\\,ds - \\frac{1}{2}\\int_0^t \\sigma(s)^2\\,ds$. Then $\\Lambda_t = \\exp(Z_t)$. The differential of $Z_t$ is:\n$$\ndZ_t = \\sigma(t)\\,dW_t + a(t)\\,dt - \\frac{1}{2}\\sigma(t)^2\\,dt = \\left(a(t) - \\frac{1}{2}\\sigma(t)^2\\right)dt + \\sigma(t)\\,dW_t\n$$\nApplying Itô's formula to $\\Lambda_t = F(Z_t)$ with $F(z) = \\exp(z)$, we have $F'(z) = \\exp(z)$ and $F''(z) = \\exp(z)$. The quadratic variation of $Z_t$ is $d\\langle Z \\rangle_t = (\\sigma(t))^2\\,dt = \\sigma(t)^2\\,dt$.\n$$\nd\\Lambda_t = F'(Z_t)\\,dZ_t + \\frac{1}{2}F''(Z_t)\\,d\\langle Z \\rangle_t\n$$\n$$\nd\\Lambda_t = \\exp(Z_t)\\left[\\left(a(t) - \\frac{1}{2}\\sigma(t)^2\\right)dt + \\sigma(t)\\,dW_t\\right] + \\frac{1}{2}\\exp(Z_t)\\,\\sigma(t)^2\\,dt\n$$\nSubstituting $\\Lambda_t = \\exp(Z_t)$ and simplifying:\n$$\nd\\Lambda_t = \\Lambda_t\\left(a(t) - \\frac{1}{2}\\sigma(t)^2\\right)dt + \\Lambda_t\\sigma(t)\\,dW_t + \\frac{1}{2}\\Lambda_t\\sigma(t)^2\\,dt\n$$\n$$\nd\\Lambda_t = \\Lambda_t a(t)\\,dt + \\Lambda_t \\sigma(t)\\,dW_t\n$$\nThis confirms that $\\Lambda_t$ is the solution to the homogeneous multiplicative part of the SDE.\n\nNext, we find the differential of $Y_t$. From its definition as a sum of a constant, a Lebesgue integral, and an Itô integral, its differential is given directly by:\n$$\ndY_t = \\Lambda_t^{-1}\\,(f(t) + c(t))\\,dt + \\Lambda_t^{-1}\\,g(t)\\,dW_t\n$$\n\nNow we apply Itô's product rule to $X_t = \\Lambda_t Y_t$:\n$$\ndX_t = Y_t\\,d\\Lambda_t + \\Lambda_t\\,dY_t + d\\langle \\Lambda, Y \\rangle_t\n$$\nThe quadratic covariation term $d\\langle \\Lambda, Y \\rangle_t$ is computed from the diffusion parts of $d\\Lambda_t$ and $dY_t$. The diffusion part of $d\\Lambda_t$ is $\\Lambda_t \\sigma(t)\\,dW_t$ and the diffusion part of $dY_t$ is $\\Lambda_t^{-1}g(t)\\,dW_t$.\n$$\nd\\langle \\Lambda, Y \\rangle_t = (\\Lambda_t \\sigma(t)) \\cdot (\\Lambda_t^{-1} g(t))\\,dt = \\sigma(t) g(t)\\,dt\n$$\n\nWe substitute the expressions for $d\\Lambda_t$, $dY_t$, and $d\\langle \\Lambda, Y \\rangle_t$ into the product rule:\n$$\ndX_t = Y_t \\left( \\Lambda_t a(t)\\,dt + \\Lambda_t \\sigma(t)\\,dW_t \\right) + \\Lambda_t \\left( \\Lambda_t^{-1}(f(t) + c(t))\\,dt + \\Lambda_t^{-1}g(t)\\,dW_t \\right) + \\sigma(t) g(t)\\,dt\n$$\nSimplifying and distributing terms:\n$$\ndX_t = a(t) \\Lambda_t Y_t \\,dt + \\sigma(t) \\Lambda_t Y_t \\,dW_t + (f(t) + c(t))\\,dt + g(t)\\,dW_t + \\sigma(t) g(t)\\,dt\n$$\nSubstitute back $X_t = \\Lambda_t Y_t$:\n$$\ndX_t = a(t) X_t \\,dt + \\sigma(t) X_t \\,dW_t + (f(t) + c(t))\\,dt + g(t)\\,dW_t + \\sigma(t) g(t)\\,dt\n$$\nWe group the terms by $dt$ and $dW_t$ to identify the drift and diffusion coefficients:\n$$\ndX_t = \\underbrace{\\left( a(t)X_t + f(t) + c(t) + \\sigma(t)g(t) \\right)}_{\\text{Drift}} dt + \\underbrace{\\left( \\sigma(t)X_t + g(t) \\right)}_{\\text{Diffusion}} dW_t\n$$\nNow, we compare this with the original SDE:\n$$\ndX_t = \\left( a(t)X_t + f(t) \\right) dt + \\left( \\sigma(t)X_t + g(t) \\right) dW_t\n$$\nThe diffusion coefficients are identical: $\\sigma(t)X_t + g(t)$. For the candidate to be a true solution, the drift coefficients must also be identical. Therefore, we set them equal:\n$$\na(t)X_t + f(t) + c(t) + \\sigma(t)g(t) = a(t)X_t + f(t)\n$$\nSubtracting $a(t)X_t + f(t)$ from both sides leaves:\n$$\nc(t) + \\sigma(t)g(t) = 0\n$$\nSolving for $c(t)$ yields the unique expression:\n$$\nc(t) = -\\sigma(t)g(t)\n$$\nThis choice of $c(t)$ ensures that the drift of the derived SDE matches the drift of the original SDE, thus verifying that the candidate form is indeed the solution. The function $c(t)$ serves as a correction term that accounts for the interaction between the multiplicative noise term proportional to $\\sigma(t)$ and the additive noise term proportional to $g(t)$, which manifests through the quadratic covariation term in Itô's product rule.", "answer": "$$\\boxed{-\\sigma(t)g(t)}$$", "id": "2985096"}, {"introduction": "The principles of scalar linear SDEs readily extend to matrix-valued processes, which are essential in disciplines like control theory, financial engineering, and system biology. This problem challenges you to apply the multi-dimensional Itô's lemma to a key property of the fundamental solution matrix: its determinant. Deriving the resulting SDE, a result known as the stochastic Liouville formula, provides a powerful tool for analyzing system stability and understanding how noise drives the expansion or contraction of state-space volume. [@problem_id:2985117]", "problem": "Let $\\{W^{i}_{t}\\}_{i=1}^{m}$ be a standard $m$-dimensional Brownian motion (BM) on a filtered probability space supporting a $d \\times d$ matrix-valued stochastic differential equation (SDE). Consider the linear matrix SDE for the fundamental solution $\\Phi_{t} \\in \\mathbb{R}^{d \\times d}$,\n$$\nd\\Phi_{t} \\;=\\; A_{t}\\,\\Phi_{t}\\,dt \\;+\\; \\sum_{i=1}^{m} B_{i,t}\\,\\Phi_{t}\\,dW^{i}_{t}, \n\\qquad \\Phi_{0} \\;=\\; I_{d},\n$$\nwhere $A_{t}$ and $B_{i,t}$ are progressively measurable $\\mathbb{R}^{d \\times d}$-valued processes with suitable integrability and boundedness so that the SDE admits a unique strong solution with $\\Phi_{t} \\in \\mathrm{GL}(d)$ almost surely for all $t \\ge 0$. Starting from the Itô formula for functions on $\\mathbb{R}^{d \\times d}$ and the basic matrix calculus identities, derive the stochastic differential equation satisfied by $\\ln \\det(\\Phi_{t})$ and hence obtain an explicit closed-form expression for $\\det(\\Phi_{t})$ in terms of $\\mathrm{tr}(A_{t})$ and $\\mathrm{tr}(B_{i,t}^{2})$. Your derivation must proceed from first principles, including identification of the Fréchet derivative and Hessian of the function $M \\mapsto \\ln \\det(M)$, and must use only the cyclicity of the trace and the product rule together with Itô’s lemma. Express your final answer for $\\det(\\Phi_{t})$ as a single closed-form analytic expression. No numerical evaluation is required.", "solution": "The problem is to derive the stochastic differential equation (SDE) for the process $Y_{t} = \\ln \\det(\\Phi_{t})$, where $\\Phi_{t}$ is the fundamental solution to a linear matrix SDE, and subsequently to find a closed-form expression for $\\det(\\Phi_{t})$.\n\nThe given SDE for $\\Phi_{t} \\in \\mathbb{R}^{d \\times d}$ is:\n$$\nd\\Phi_{t} = A_{t}\\,\\Phi_{t}\\,dt + \\sum_{i=1}^{m} B_{i,t}\\,\\Phi_{t}\\,dW^{i}_{t}\n$$\nwith the initial condition $\\Phi_{0} = I_{d}$, the $d \\times d$ identity matrix. The processes $A_{t}$ and $B_{i,t}$ are $\\mathbb{R}^{d \\times d}$-valued and progressively measurable. We are given that $\\Phi_{t}$ is almost surely in the general linear group $\\mathrm{GL}(d)$, meaning $\\det(\\Phi_{t}) \\neq 0$ for all $t \\ge 0$. Since $\\det(\\Phi_{0}) = \\det(I_{d}) = 1 > 0$ and the paths of $\\det(\\Phi_t)$ are continuous, we must have $\\det(\\Phi_{t}) > 0$ almost surely, which ensures that $Y_{t} = \\ln \\det(\\Phi_{t})$ is a well-defined real-valued process.\n\nWe apply the multidimensional Itô's lemma to the function $f: \\mathrm{GL}(d) \\to \\mathbb{R}$ defined by $f(M) = \\ln \\det(M)$. The process $\\Phi_{t}$ can be viewed as a vector in $\\mathbb{R}^{d^2}$. Let $\\Phi_{t,jk}$ denote the element in the $j$-th row and $k$-th column of $\\Phi_t$. The Itô's lemma for $Y_{t} = f(\\Phi_{t})$ is:\n$$\ndY_{t} = \\sum_{j,k=1}^{d} \\frac{\\partial f}{\\partial M_{jk}}(\\Phi_{t}) d\\Phi_{t,jk} + \\frac{1}{2} \\sum_{j,k,p,q=1}^{d} \\frac{\\partial^2 f}{\\partial M_{jk}\\partial M_{pq}}(\\Phi_{t}) d\\langle \\Phi_{jk}, \\Phi_{pq} \\rangle_{t}\n$$\nThe differential of $\\Phi_{t}$ is given by:\n$$\nd\\Phi_{t,jk} = (A_{t}\\Phi_{t})_{jk} dt + \\sum_{i=1}^{m} (B_{i,t}\\Phi_{t})_{jk} dW^{i}_{t}\n$$\nThe quadratic covariation term is:\n$$\nd\\langle \\Phi_{jk}, \\Phi_{pq} \\rangle_{t} = \\sum_{i=1}^{m} (B_{i,t}\\Phi_{t})_{jk} (B_{i,t}\\Phi_{t})_{pq} dt\n$$\nFirst, we must compute the Fréchet derivative (gradient) and the Hessian of $f(M) = \\ln \\det(M)$.\n\nThe derivative of the determinant function is given by Jacobi's formula: $d(\\det(M)) = \\mathrm{tr}(\\mathrm{adj}(M) dM) = \\det(M) \\mathrm{tr}(M^{-1} dM)$. From this, the partial derivative of $\\det(M)$ with respect to its element $M_{jk}$ is the $(j,k)$-th cofactor of $M$, which can be written as $(\\det(M) (M^{-T}))_{jk} = \\det(M) (M^{-1})_{kj}$.\nThe derivative of $f(M) = \\ln \\det(M)$ is found using the chain rule:\n$$\n\\frac{\\partial f}{\\partial M_{jk}} = \\frac{1}{\\det(M)} \\frac{\\partial \\det(M)}{\\partial M_{jk}} = \\frac{1}{\\det(M)} \\det(M) (M^{-1})_{kj} = (M^{-1})_{kj}\n$$\nIn matrix notation, the gradient of $f(M)$ is $D f(M) = (M^{-1})^{T}$.\n\nNext, we compute the second partial derivatives (the Hessian). We differentiate $\\frac{\\partial f}{\\partial M_{jk}} = (M^{-1})_{kj}$ with respect to $M_{pq}$. Using the formula for the derivative of a matrix inverse, $\\frac{\\partial M^{-1}}{\\partial M_{pq}} = -M^{-1} E_{pq} M^{-1}$, where $E_{pq}$ is the matrix unit with a $1$ at position $(p,q)$ and zeros elsewhere.\n$$\n\\frac{\\partial^2 f}{\\partial M_{jk}\\partial M_{pq}} = \\frac{\\partial (M^{-1})_{kj}}{\\partial M_{pq}} = (-M^{-1} E_{pq} M^{-1})_{kj} = -\\sum_{r,s} (M^{-1})_{kr} (E_{pq})_{rs} (M^{-1})_{sj} = -(M^{-1})_{kp} (M^{-1})_{qj}\n$$\nNow we substitute these derivatives into Itô's lemma.\n\nThe first term (drift and diffusion from the first derivative) is:\n$$\n\\sum_{j,k=1}^{d} \\frac{\\partial f}{\\partial M_{jk}}(\\Phi_{t}) d\\Phi_{t,jk} = \\sum_{j,k=1}^{d} (\\Phi_{t}^{-1})_{kj} d\\Phi_{t,jk} = \\mathrm{tr}(\\Phi_{t}^{-1} d\\Phi_{t})\n$$\nSubstituting the SDE for $d\\Phi_{t}$:\n$$\n\\mathrm{tr}(\\Phi_{t}^{-1} d\\Phi_{t}) = \\mathrm{tr}\\left(\\Phi_{t}^{-1} \\left( A_{t}\\Phi_{t}dt + \\sum_{i=1}^{m} B_{i,t}\\Phi_{t}dW^{i}_{t} \\right)\\right)\n$$\nUsing the linearity and cyclicity of the trace operator ($\\mathrm{tr}(XY) = \\mathrm{tr}(YX)$):\n$$\n\\mathrm{tr}(\\Phi_{t}^{-1} A_{t}\\Phi_{t}) = \\mathrm{tr}(A_{t})\n$$\n$$\n\\mathrm{tr}(\\Phi_{t}^{-1} B_{i,t}\\Phi_{t}) = \\mathrm{tr}(B_{i,t})\n$$\nSo, the first part contributes:\n$$\n\\mathrm{tr}(A_{t}) dt + \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,t}) dW^{i}_{t}\n$$\n\nThe second term (the Itô correction from the second derivative) is:\n$$\n\\frac{1}{2} \\sum_{j,k,p,q=1}^{d} \\frac{\\partial^2 f}{\\partial M_{jk}\\partial M_{pq}}(\\Phi_{t}) d\\langle \\Phi_{jk}, \\Phi_{pq} \\rangle_{t} = \\frac{1}{2} \\sum_{j,k,p,q=1}^{d} (-(\\Phi_{t}^{-1})_{kp} (\\Phi_{t}^{-1})_{qj}) \\left( \\sum_{i=1}^{m} (B_{i,t}\\Phi_{t})_{jk} (B_{i,t}\\Phi_{t})_{pq} \\right) dt\n$$\nLet's rearrange the summation for each $i$:\n$$\n-\\frac{1}{2} \\sum_{j,k,p,q=1}^{d} (\\Phi_{t}^{-1})_{qj} (B_{i,t}\\Phi_{t})_{jk} (\\Phi_{t}^{-1})_{kp} (B_{i,t}\\Phi_{t})_{pq} dt\n$$\nWe recognize matrix products inside the summation:\n$\\sum_{j,k} (\\Phi_{t}^{-1})_{qj} (B_{i,t}\\Phi_{t})_{jk} = (\\Phi_{t}^{-1} B_{i,t} \\Phi_{t})_{qk}$\nLet $C_{i,t} = \\Phi_{t}^{-1} B_{i,t} \\Phi_{t}$. The expression becomes:\n$$\n-\\frac{1}{2} \\sum_{p,q,k} C_{i,t,qk} (\\Phi_{t}^{-1})_{kp} (B_{i,t}\\Phi_{t})_{pq} dt\n$$\nThis seems overly complicated. Let's group the terms differently:\n$$\n-\\frac{1}{2} \\sum_{i=1}^{m} \\left( \\sum_{j,q} (\\Phi_{t}^{-1})_{qj} \\left( \\sum_{k} (B_{i,t}\\Phi_{t})_{jk} \\left( \\sum_{p} (\\Phi_{t}^{-1})_{kp} (B_{i,t}\\Phi_{t})_{pq} \\right) \\right) \\right) dt\n$$\nLet's simplify the inner sums:\n$\\sum_{p} (\\Phi_{t}^{-1})_{kp} (B_{i,t}\\Phi_{t})_{pq} = (\\Phi_{t}^{-1}B_{i,t}\\Phi_{t})_{kq}$\nThe expression becomes:\n$$\n-\\frac{1}{2} \\sum_{i=1}^{m} \\left( \\sum_{j,q} (\\Phi_{t}^{-1})_{qj} \\sum_{k} (B_{i,t}\\Phi_{t})_{jk} (\\Phi_{t}^{-1}B_{i,t}\\Phi_{t})_{kq} \\right) dt\n$$\n$\\sum_{k} (B_{i,t}\\Phi_{t})_{jk} (\\Phi_{t}^{-1}B_{i,t}\\Phi_{t})_{kq} = (B_{i,t}\\Phi_{t} \\Phi_{t}^{-1}B_{i,t}\\Phi_{t})_{jq} = (B_{i,t}^2 \\Phi_{t})_{jq}$\nThe expression simplifies to:\n$$\n-\\frac{1}{2} \\sum_{i=1}^{m} \\left( \\sum_{j,q} (\\Phi_{t}^{-1})_{qj} (B_{i,t}^2 \\Phi_{t})_{jq} \\right) dt\n$$\nThe sum $\\sum_{j,q} (\\Phi_{t}^{-1})_{qj} (B_{i,t}^2 \\Phi_{t})_{jq}$ is the trace of the product $\\Phi_{t}^{-1}(B_{i,t}^2 \\Phi_{t})$.\n$$\n\\mathrm{tr}(\\Phi_{t}^{-1} B_{i,t}^2 \\Phi_{t}) = \\mathrm{tr}(B_{i,t}^2)\n$$\nThus, the second derivative term contributes:\n$$\n-\\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,t}^2) dt\n$$\nCombining all terms, we obtain the SDE for $Y_{t} = \\ln \\det(\\Phi_{t})$:\n$$\nd(\\ln \\det(\\Phi_{t})) = \\left( \\mathrm{tr}(A_{t}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,t}^2) \\right) dt + \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,t}) dW^{i}_{t}\n$$\nThis is the first part of the required derivation.\n\nTo obtain the expression for $\\det(\\Phi_{t})$, we integrate the SDE for $Y_{t} = \\ln \\det(\\Phi_{t})$ from $0$ to $t$:\n$$\nY_{t} - Y_{0} = \\int_{0}^{t} \\left( \\mathrm{tr}(A_{s}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,s}^2) \\right) ds + \\sum_{i=1}^{m} \\int_{0}^{t} \\mathrm{tr}(B_{i,s}) dW^{i}_{s}\n$$\nGiven $\\Phi_{0} = I_{d}$, we have $Y_{0} = \\ln \\det(I_{d}) = \\ln(1) = 0$.\nSo,\n$$\n\\ln \\det(\\Phi_{t}) = \\int_{0}^{t} \\left( \\mathrm{tr}(A_{s}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,s}^2) \\right) ds + \\sum_{i=1}^{m} \\int_{0}^{t} \\mathrm{tr}(B_{i,s}) dW^{i}_{s}\n$$\nThe problem demands an explicit closed-form expression for $\\det(\\Phi_{t})$ \"in terms of $\\mathrm{tr}(A_{t})$ and $\\mathrm{tr}(B_{i,t}^{2})$\". The general solution above contains stochastic integral terms involving $\\mathrm{tr}(B_{i,s})$. For the final expression to conform to the problem's requirement, these stochastic integral terms must vanish. A stochastic integral $\\int_{0}^{t} f(s,\\omega) dW_{s}$ is identically zero if and only if the integrand $f(s,\\omega)$ is zero almost everywhere. Therefore, the problem statement implicitly requires that $\\mathrm{tr}(B_{i,t}) = 0$ for all $i=1,\\dots,m$ and for almost every $t \\ge 0$. Under this condition, the SDE for $\\ln\\det(\\Phi_t)$ simplifies to a random ordinary differential equation:\n$$\nd(\\ln \\det(\\Phi_{t})) = \\left( \\mathrm{tr}(A_{t}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,t}^2) \\right) dt\n$$\nIntegrating this from $0$ to $t$ yields:\n$$\n\\ln \\det(\\Phi_{t}) = \\int_{0}^{t} \\left( \\mathrm{tr}(A_{s}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,s}^2) \\right) ds\n$$\nExponentiating both sides gives the final expression for $\\det(\\Phi_{t})$:\n$$\n\\det(\\Phi_{t}) = \\exp\\left( \\int_{0}^{t} \\left( \\mathrm{tr}(A_{s}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,s}^2) \\right) ds \\right)\n$$\nThis is the required closed-form expression, also known as the stochastic Liouville formula or Abel-Jacobi-Liouville formula under the condition that the diffusion vector fields are divergence-free (which in this linear case corresponds to the matrices $B_i$ being traceless).", "answer": "$$\\boxed{\\exp\\left(\\int_{0}^{t} \\left(\\mathrm{tr}(A_{s}) - \\frac{1}{2} \\sum_{i=1}^{m} \\mathrm{tr}(B_{i,s}^{2})\\right) ds\\right)}$$", "id": "2985117"}, {"introduction": "The stochastic exponential, $\\mathcal{E}(M)_t$, is the cornerstone of explicit solutions for linear SDEs and is fundamentally a local martingale. However, it is not always a true martingale, a distinction with profound theoretical and practical consequences, especially when changing probability measures. This exercise guides you through a carefully constructed scenario where Novikov's condition—a sufficient test for the martingale property—fails. By explicitly solving the SDE and analyzing the solution's limiting behavior, you will develop a concrete understanding of what happens at the boundary of the theory and why conditions like Novikov's are so important. [@problem_id:2985077]", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\ge 0},\\mathbb{P})$ support a standard Brownian motion $W=(W_t)_{t \\ge 0}$ and an independent Bernoulli random variable $\\xi$ with $\\mathbb{P}(\\xi=1)=p \\in (0,1)$ and $\\mathbb{P}(\\xi=0)=1-p$. Define the progressively measurable process $b=(b_t)_{t \\in [0,1)}$ by $b_t=\\xi (1-t)^{-1/2}$ for $t \\in [0,1)$ and $b_1:=0$. Consider the linear Stochastic Differential Equation (SDE)\n$$\ndX_t \\;=\\; X_t\\,b_t\\,dW_t,\\qquad X_0=1,\\qquad t \\in [0,1).\n$$\nTasks:\n- Starting from the definition of the Doléans–Dade exponential as the unique strong solution of a linear SDE driven by Brownian motion, derive an explicit expression for $X_t$ for $t \\in [0,1)$.\n- Using first principles and well-tested facts about exponential local martingales, verify that Novikov’s condition fails on $[0,1]$ for the process $b$.\n- Prove that $X_t$ admits a limit $X_1:=\\lim_{t \\uparrow 1}X_t$ almost surely (a.s.), and identify $X_1$ explicitly in terms of $\\xi$.\n- Finally, compute the expectation $\\mathbb{E}[X_1]$ as a function of $p$. Express your final answer as a closed-form analytic expression. No rounding is required.", "solution": "The problem asks for a four-part analysis of the solution to a linear stochastic differential equation (SDE). We address each part sequentially.\n\nThe SDE is given by\n$$\ndX_t = X_t b_t dW_t, \\qquad X_0=1, \\qquad t \\in [0,1)\n$$\nwhere $b_t = \\xi (1-t)^{-1/2}$ for $t \\in [0,1)$, with $\\xi$ being a Bernoulli random variable independent of the standard Brownian motion $W_t$. We have $\\mathbb{P}(\\xi=1)=p$ and $\\mathbb{P}(\\xi=0)=1-p$ for $p \\in (0,1)$.\n\n**Part 1: Explicit expression for $X_t$ for $t \\in [0,1)$**\n\nThe given SDE is a standard form for a Doléans-Dade exponential, also known as a stochastic exponential. The unique strong solution to an SDE of the form $dZ_t = Z_t dM_t$ with $Z_0=1$, where $M_t$ is a continuous local martingale, is given by $Z_t = \\mathcal{E}(M)_t$.\n\nIn our case, the driving process is the Itô integral $M_t = \\int_0^t b_s dW_s$. Since $b_s$ is progressively measurable and satisfies $\\int_0^t b_s^2 ds  \\infty$ almost surely for each $t \\in [0,1)$, $M_t$ is a continuous local martingale. Its quadratic variation process is $\\langle M \\rangle_t = \\int_0^t b_s^2 ds$.\n\nLet us compute this quadratic variation. Since $\\xi$ is a Bernoulli random variable, it only takes values $0$ or $1$, so $\\xi^2 = \\xi$.\n$$\n\\langle M \\rangle_t = \\int_0^t b_s^2 ds = \\int_0^t \\left(\\xi (1-s)^{-1/2}\\right)^2 ds = \\xi^2 \\int_0^t (1-s)^{-1} ds = \\xi \\int_0^t \\frac{1}{1-s} ds\n$$\nThe integral evaluates to:\n$$\n\\int_0^t \\frac{1}{1-s} ds = [-\\ln(1-s)]_0^t = -\\ln(1-t) - (-\\ln(1-0)) = -\\ln(1-t)\n$$\nThus, the quadratic variation is $\\langle M \\rangle_t = -\\xi \\ln(1-t)$.\n\nThe explicit solution for $X_t$ is given by the formula for the Doléans-Dade exponential:\n$$\nX_t = \\mathcal{E}(M)_t = \\exp\\left( M_t - \\frac{1}{2}\\langle M \\rangle_t \\right)\n$$\nSubstituting the expressions for $M_t$ and $\\langle M \\rangle_t$, we obtain:\n$$\nX_t = \\exp\\left( \\int_0^t \\xi (1-s)^{-1/2} dW_s - \\frac{1}{2} (-\\xi \\ln(1-t)) \\right) = \\exp\\left( \\xi \\int_0^t (1-s)^{-1/2} dW_s + \\frac{1}{2}\\xi \\ln(1-t) \\right)\n$$\nThis is the explicit expression for $X_t$ for $t \\in [0,1)$.\n\n**Part 2: Verification that Novikov's condition fails**\n\nNovikov's condition states that the local martingale $X_t=\\mathcal{E}(M)_t$ is a true martingale on the interval $[0,T]$ if $\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M \\rangle_T\\right)\\right]  \\infty$. We need to check this condition for our process on the interval $[0,1]$, so we set $T=1$.\n\nFirst, we determine the quadratic variation at time $t=1$:\n$$\n\\langle M \\rangle_1 = \\lim_{t \\uparrow 1} \\langle M \\rangle_t = \\lim_{t \\uparrow 1} (-\\xi \\ln(1-t))\n$$\nAs $t \\uparrow 1$, $(1-t) \\downarrow 0$, so $\\ln(1-t) \\to -\\infty$. Therefore:\n$$\n\\langle M \\rangle_1 = \\begin{cases} \\infty  \\text{if } \\xi=1 \\\\ 0  \\text{if } \\xi=0 \\end{cases}\n$$\nNow, we evaluate the expectation in Novikov's condition using the law of total expectation, conditioning on the value of $\\xi$:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right)\\right] = \\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right) \\Big| \\xi=1\\right]\\mathbb{P}(\\xi=1) + \\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right) \\Big| \\xi=0\\right]\\mathbb{P}(\\xi=0)\n$$\nIf $\\xi=1$, $\\langle M \\rangle_1 = \\infty$, so $\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right) = \\exp(\\infty) = \\infty$.\nIf $\\xi=0$, $\\langle M \\rangle_1 = 0$, so $\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right) = \\exp(0) = 1$.\n\nSubstituting these into the expectation formula with $\\mathbb{P}(\\xi=1)=p$ and $\\mathbb{P}(\\xi=0)=1-p$:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right)\\right] = (\\infty) \\cdot p + (1) \\cdot (1-p)\n$$\nSince $p \\in (0,1)$, $p0$, the first term is infinite. Thus, the expectation is infinite:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2}\\langle M \\rangle_1\\right)\\right] = \\infty\n$$\nNovikov's condition is not satisfied on the interval $[0,1]$.\n\n**Part 3: Almost sure limit $X_1$ and its identification**\n\nWe need to compute $X_1 := \\lim_{t \\uparrow 1} X_t$ almost surely. We analyze the limit by conditioning on $\\xi$.\n\nCase 1: $\\xi = 0$.\nIf $\\xi=0$, then $b_t=0$ for all $t$. The SDE becomes $dX_t = 0$ with $X_0=1$. The solution is trivially $X_t=1$ for all $t \\in [0,1)$. The limit is $\\lim_{t \\uparrow 1} X_t = 1$.\nUsing our explicit formula for $X_t$:\n$$\nX_t = \\exp\\left( 0 \\cdot \\int_0^t (1-s)^{-1/2} dW_s + \\frac{1}{2} \\cdot 0 \\cdot \\ln(1-t) \\right) = \\exp(0) = 1\n$$\nThe limit is indeed $1$.\n\nCase 2: $\\xi = 1$.\nIf $\\xi=1$, the expression for $X_t$ is:\n$$\nX_t = \\exp\\left( \\int_0^t (1-s)^{-1/2} dW_s + \\frac{1}{2} \\ln(1-t) \\right)\n$$\nLet's analyze the term in the exponent. Let $Y_t = \\int_0^t (1-s)^{-1/2} dW_s$. This is a continuous local martingale with quadratic variation $\\langle Y \\rangle_t = \\int_0^t (1-s)^{-1} ds = -\\ln(1-t)$.\nBy the Dambis-Dubins-Schwarz theorem, $Y_t$ can be represented as a time-changed Brownian motion: $Y_t = B_{\\langle Y \\rangle_t}$, where $B$ is a standard Brownian motion.\nSo, $Y_t = B_{-\\ln(1-t)}$.\nSubstituting this into the expression for $X_t$:\n$$\nX_t = \\exp\\left( B_{-\\ln(1-t)} - \\frac{1}{2}(-\\ln(1-t)) \\right)\n$$\nLet $u = -\\ln(1-t)$. As $t \\uparrow 1$, we have $u \\to \\infty$. So we are interested in the limit:\n$$\n\\lim_{u \\to \\infty} \\exp\\left( B_u - \\frac{1}{2}u \\right)\n$$\nThis is the limit of a geometric Brownian motion with drift $-\\frac{1}{2}$ and volatility $1$. By the law of the iterated logarithm, $\\limsup_{u\\to\\infty} \\frac{|B_u|}{\\sqrt{2u \\ln \\ln u}} = 1$, which implies that $\\lim_{u\\to\\infty} \\frac{B_u}{u}=0$ almost surely. Therefore, the term $-\\frac{1}{2}u$ dominates the term $B_u$ for large $u$.\n$$\n\\lim_{u \\to \\infty} \\left(B_u - \\frac{1}{2}u\\right) = -\\infty \\quad \\text{a.s.}\n$$\nConsequently, the limit of the exponential is:\n$$\n\\lim_{u \\to \\infty} \\exp\\left( B_u - \\frac{1}{2}u \\right) = \\lim_{z \\to -\\infty} \\exp(z) = 0 \\quad \\text{a.s.}\n$$\nSo, if $\\xi=1$, we have $\\lim_{t \\uparrow 1} X_t = 0$ almost surely.\n\nCombining both cases, the almost sure limit $X_1$ is:\n$$\nX_1 = \\begin{cases} 0  \\text{if } \\xi=1 \\\\ 1  \\text{if } \\xi=0 \\end{cases}\n$$\nThis can be written compactly in terms of $\\xi$ as $X_1 = 1-\\xi$.\n\n**Part 4: Computation of $\\mathbb{E}[X_1]$**\n\nWe have identified $X_1 = 1-\\xi$. We can now compute its expectation directly.\n$$\n\\mathbb{E}[X_1] = \\mathbb{E}[1-\\xi]\n$$\nBy linearity of expectation:\n$$\n\\mathbb{E}[X_1] = 1 - \\mathbb{E}[\\xi]\n$$\nThe random variable $\\xi$ follows a Bernoulli distribution with parameter $p$. Its expectation is given by:\n$$\n\\mathbb{E}[\\xi] = 1 \\cdot \\mathbb{P}(\\xi=1) + 0 \\cdot \\mathbb{P}(\\xi=0) = 1 \\cdot p + 0 \\cdot (1-p) = p\n$$\nSubstituting this back, we find the expectation of $X_1$:\n$$\n\\mathbb{E}[X_1] = 1-p\n$$\nThis is the final analytical expression for the expectation. Note that for any $t1$, $X_t$ is a true martingale, so $\\mathbb{E}[X_t]=X_0=1$. However, $\\lim_{t\\uparrow 1}\\mathbb{E}[X_t] = 1 \\neq \\mathbb{E}[X_1]=1-p$. The interchange of limit and expectation is not permitted, which is consistent with the failure of Novikov's condition and the fact that $X_t$ is a strict local martingale on $[0,1]$.", "answer": "$$\\boxed{1-p}$$", "id": "2985077"}]}