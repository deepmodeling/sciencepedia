{"hands_on_practices": [{"introduction": "Understanding the Itô product rule begins with its application to continuous processes. This first exercise [@problem_id:2982685] challenges you to derive one of the cornerstone results of stochastic calculus from first principles. By applying the product rule to a martingale squared and invoking the uniqueness of the Doob-Meyer decomposition, you will rigorously establish the form of the predictable quadratic variation for a standard Itô integral, cementing your grasp of this fundamental concept.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t \\geq 0},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions and carrying a standard one-dimensional Brownian motion $B=(B_{t})_{t \\geq 0}$. Let $H=(H_{t})_{t \\geq 0}$ be a real-valued predictable process such that for every $T>0$ one has $\\mathbb{E}\\!\\left[\\int_{0}^{T} H_{s}^{2}\\,ds\\right]<\\infty$. Define the stochastic integral\n$$\nM_{t} := \\int_{0}^{t} H_{s}\\,dB_{s}, \\quad t \\geq 0,\n$$\nwhich is a square-integrable continuous martingale.\n\nUsing only foundational tools for continuous semimartingales, namely Itô's product rule, properties of Brownian motion increments, and the Doob–Meyer decomposition (DMD) for submartingales, determine the predictable quadratic variation process $\\langle M\\rangle = (\\langle M\\rangle_{t})_{t \\geq 0}$ in closed form as a function of $t$. Your final answer must be a single analytical expression depending on $t$ and $H$. Do not assume any specialized formulas for $\\langle M\\rangle$ beyond what can be derived from these principles.", "solution": "The problem asks for the predictable quadratic variation process, denoted $\\langle M \\rangle = (\\langle M\\rangle_{t})_{t \\geq 0}$, of the continuous martingale $M_{t} := \\int_{0}^{t} H_{s}\\,dB_{s}$. The process $\\langle M \\rangle$ is defined by the Doob–Meyer decomposition (DMD) of the submartingale $M_{t}^{2}$. Specifically, $M_{t}^{2}$ can be uniquely decomposed as the sum of a continuous local martingale and a continuous, non-decreasing, predictable process of finite variation starting at zero. This latter process is $\\langle M \\rangle_{t}$. Our strategy will be to find this decomposition explicitly.\n\nFirst, we apply Itô's product rule for continuous semimartingales, which states that for two such processes $X$ and $Y$, the differential of their product is $d(X_t Y_t) = X_t dY_t + Y_t dX_t + d\\langle X, Y \\rangle_t$. Let's apply this with $X_{t} = Y_{t} = M_{t}$.\nThe process $M_t$ is a continuous semimartingale (in fact, a continuous local martingale). Applying the rule gives:\n$$\nd(M_{t}^{2}) = M_{t} dM_{t} + M_{t} dM_{t} + d\\langle M, M \\rangle_{t} = 2M_{t} dM_{t} + d\\langle M \\rangle_{t}\n$$\nIntegrating this from $t=0$ to a generic time $t \\geq 0$, we get:\n$$\nM_{t}^{2} - M_{0}^{2} = \\int_{0}^{t} 2M_{s}\\,dM_{s} + \\int_{0}^{t} d\\langle M \\rangle_{s}\n$$\nFrom the definition of $M_t$, we have $M_{0} = \\int_{0}^{0} H_s\\,dB_s = 0$. By definition, the quadratic variation process starts at zero, so $\\langle M \\rangle_{0} = 0$. The equation simplifies to:\n$$\nM_{t}^{2} = 2\\int_{0}^{t} M_{s}\\,dM_{s} + \\langle M \\rangle_{t}\n$$\nThe integral $\\int_{0}^{t} M_{s}\\,dM_{s}$ is a stochastic integral with respect to the continuous local martingale $M_s$. The integrand $M_s$ is an adapted process. Therefore, the process $N_{t}^{(1)} := 2\\int_{0}^{t} M_{s}\\,dM_{s}$ is a continuous local martingale. The process $A_{t}^{(1)} := \\langle M \\rangle_{t}$ is, by definition, a continuous, non-decreasing, and predictable process of finite variation starting at $0$. Thus, the equation $M_{t}^{2} = N_{t}^{(1)} + A_{t}^{(1)}$ provides one such decomposition for the submartingale $M_{t}^{2}$.\n\nNext, we establish a second decomposition for $M_{t}^{2}$ using the properties of Brownian motion. Let us define a process $A_{t}^{(2)} := \\int_{0}^{t} H_{s}^{2}\\,ds$.\nSince $H_s$ is a predictable process, $H_s^2$ is also a predictable process. The integral of a non-negative predictable process with respect to Lebesgue measure yields a continuous, non-decreasing, and predictable process. Since $H_s^2 \\ge 0$, $A_{t}^{(2)}$ is non-decreasing. The condition $\\mathbb{E}[\\int_{0}^{T} H_s^2 ds] < \\infty$ implies that $\\int_{0}^{T} H_s^2 ds < \\infty$ almost surely, ensuring $A_t^{(2)}$ is continuous for $t \\in [0, T]$. Finally, as an integral of a predictable process, $A_t^{(2)}$ is itself predictable. Thus, $A_{t}^{(2)}$ is a valid candidate for the predictable part in a Doob-Meyer decomposition.\n\nNow, consider the process $N_{t}^{(2)} := M_{t}^{2} - A_{t}^{(2)} = M_{t}^{2} - \\int_{0}^{t} H_{s}^{2}\\,ds$. We will show that $N_{t}^{(2)}$ is a continuous martingale. It is continuous because both $M_t^2$ and $A_t^{(2)}$ are continuous. To show it is a martingale, we need to show that for any $0 \\leq s < t$, $\\mathbb{E}[N_{t}^{(2)} - N_{s}^{(2)} | \\mathcal{F}_{s}] = 0$.\nThis is equivalent to showing $\\mathbb{E}[M_{t}^{2} - M_{s}^{2} | \\mathcal{F}_{s}] = \\mathbb{E}[\\int_{s}^{t} H_{u}^{2}\\,du | \\mathcal{F}_{s}]$.\nWe have $M_{t} - M_{s} = \\int_{s}^{t} H_{u}\\,dB_{u}$. Since $M_s$ is $\\mathcal{F}_s$-measurable and $\\mathbb{E}[M_t - M_s | \\mathcal{F}_s] = 0$ (martingale property of $M_t$), we calculate:\n$$\n\\mathbb{E}[M_{t}^{2} - M_{s}^{2} | \\mathcal{F}_{s}] = \\mathbb{E}[(M_{t} - M_{s} + M_{s})^{2} - M_{s}^{2} | \\mathcal{F}_{s}] = \\mathbb{E}[(M_{t} - M_{s})^{2} + 2M_s(M_t - M_s) + M_s^2 - M_s^2 | \\mathcal{F}_{s}]\n$$\n$$\n= \\mathbb{E}[(M_{t} - M_{s})^{2} | \\mathcal{F}_{s}] + 2M_{s}\\mathbb{E}[M_{t} - M_{s} | \\mathcal{F}_{s}] = \\mathbb{E}\\left[\\left(\\int_{s}^{t} H_{u}\\,dB_{u}\\right)^{2} \\Big| \\mathcal{F}_{s}\\right]\n$$\nThis identity is known as the conditional Itô isometry. We demonstrate it for simple predictable processes first. Let $H_u = \\sum_{i=0}^{n-1} \\xi_i \\mathbf{1}_{(t_i, t_{i+1}]}(u)$ for a partition $s=t_0 < \\dots < t_n = t$, where each $\\xi_i$ is a bounded $\\mathcal{F}_{t_i}$-measurable random variable.\n$$\n\\int_{s}^{t} H_{u}\\,dB_{u} = \\sum_{i=0}^{n-1} \\xi_{i} (B_{t_{i+1}} - B_{t_i})\n$$\nSquaring and taking conditional expectation with respect to $\\mathcal{F}_s$:\n$$\n\\mathbb{E}\\left[\\left(\\sum_{i=0}^{n-1} \\xi_{i} (B_{t_{i+1}} - B_{t_i})\\right)^{2} \\Big| \\mathcal{F}_{s}\\right] = \\sum_{i,j=0}^{n-1} \\mathbb{E}[\\xi_i \\xi_j (B_{t_{i+1}}-B_{t_i})(B_{t_{j+1}}-B_{t_j}) | \\mathcal{F}_s]\n$$\nFor $i<j$, the increment $B_{t_{j+1}}-B_{t_j}$ is independent of $\\mathcal{F}_{t_j}$. The term $\\xi_i \\xi_j (B_{t_{i+1}}-B_{t_i})$ is $\\mathcal{F}_{t_j}$-measurable. So, by the tower property and independence, the cross-terms ($i \\neq j$) vanish. We are left with diagonal terms ($i=j$):\n$$\n\\sum_{i=0}^{n-1} \\mathbb{E}[\\xi_{i}^{2} (B_{t_{i+1}} - B_{t_i})^{2} | \\mathcal{F}_{s}] = \\sum_{i=0}^{n-1} \\mathbb{E}\\big[\\mathbb{E}[\\xi_{i}^{2} (B_{t_{i+1}} - B_{t_i})^{2} | \\mathcal{F}_{t_i}] \\big| \\mathcal{F}_{s}\\big]\n$$\nSince $\\xi_i$ is $\\mathcal{F}_{t_i}$-measurable and $B_{t_{i+1}}-B_{t_i}$ is independent of $\\mathcal{F}_{t_i}$ with variance $t_{i+1}-t_i$:\n$$\n= \\sum_{i=0}^{n-1} \\mathbb{E}\\big[\\xi_{i}^{2} \\mathbb{E}[(B_{t_{i+1}} - B_{t_i})^{2} | \\mathcal{F}_{t_i}] \\big| \\mathcal{F}_{s}\\big] = \\sum_{i=0}^{n-1} \\mathbb{E}[\\xi_{i}^{2} (t_{i+1} - t_i) | \\mathcal{F}_{s}]\n$$\nOn the other hand, for this simple process $H_u$, we have $\\int_{s}^{t} H_{u}^{2}\\,du = \\sum_{i=0}^{n-1} \\xi_{i}^{2}(t_{i+1}-t_i)$. So,\n$$\n\\mathbb{E}\\left[\\int_{s}^{t} H_{u}^{2}\\,du \\Big| \\mathcal{F}_{s}\\right] = \\mathbb{E}\\left[\\sum_{i=0}^{n-1} \\xi_{i}^{2}(t_{i+1}-t_i) \\Big| \\mathcal{F}_{s}\\right] = \\sum_{i=0}^{n-1} \\mathbb{E}[\\xi_i^2(t_{i+1}-t_i) | \\mathcal{F}_s]\n$$\nThe identity holds for simple processes. By a standard approximation argument, it extends to all $H$ satisfying the given integrability condition. Thus, we have confirmed that $N_t^{(2)} = M_t^2 - \\int_0^t H_s^2 ds$ is a continuous martingale.\n\nWe now have two decompositions for the continuous submartingale $M_{t}^{2}$:\n1. $M_{t}^{2} = N_{t}^{(1)} + A_{t}^{(1)} = \\left(2\\int_{0}^{t} M_{s}\\,dM_{s}\\right) + \\langle M \\rangle_{t}$\n2. $M_{t}^{2} = N_{t}^{(2)} + A_{t}^{(2)} = \\left(M_{t}^{2} - \\int_{0}^{t} H_{s}^{2}\\,ds\\right) + \\left(\\int_{0}^{t} H_{s}^{2}\\,ds\\right)$\n\nIn both cases, we have decomposed $M_t^2$ into a continuous local martingale ($N^{(1)}$, $N^{(2)}$) and a continuous, non-decreasing, predictable process ($A^{(1)}$, $A^{(2)}$). The Doob–Meyer decomposition for a continuous submartingale is unique. Therefore, the corresponding components of these two decompositions must be equal. Comparing the predictable, non-decreasing parts, we must have $A_{t}^{(1)} = A_{t}^{(2)}$.\n$$\n\\langle M \\rangle_{t} = \\int_{0}^{t} H_{s}^{2}\\,ds\n$$\nThis result provides the closed-form expression for the predictable quadratic variation process of the Itô integral $M_t$.", "answer": "$$\\boxed{\\int_{0}^{t} H_{s}^{2}\\,ds}$$", "id": "2982685"}, {"introduction": "While the continuous part of the Itô product rule is a direct extension of standard calculus, the jump component is a purely stochastic feature with profound implications. This practice problem [@problem_id:2982652] provides a powerful motivation for the jump-covariation term by framing it in a practical context of numerical approximation. You will calculate the explicit bias introduced by ignoring the product of simultaneous jumps, revealing how this abstract term corresponds to a tangible and predictable error in modeling.", "problem": "Consider a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\geq 0}, \\mathbb{P})$ supporting the following processes:\n- Two standard Brownian motions $W$ and $B$ with instantaneous correlation $\\rho \\in (-1,1)$, that is $d\\langle W, B \\rangle_t = \\rho \\, dt$.\n- A Poisson process $N$ with constant intensity $\\lambda > 0$.\n- An independent and identically distributed sequence of $\\mathbb{R}^2$-valued jump sizes $(U_i, V_i)_{i \\in \\mathbb{N}}$ with $\\mathbb{E}[|U|] < \\infty$, $\\mathbb{E}[|V|] < \\infty$, and $\\mathbb{E}[|U V|] < \\infty$, independent of $(W,B)$ and $N$.\n\nDefine two jump-diffusion semimartingales $(X_t)_{t \\geq 0}$ and $(Y_t)_{t \\geq 0}$ by\n$$\nX_t = X_0 + \\int_0^t \\mu_X \\, ds + \\int_0^t \\sigma_X \\, dW_s + \\sum_{i=1}^{N_t} U_i,\n\\qquad\nY_t = Y_0 + \\int_0^t \\mu_Y \\, ds + \\int_0^t \\sigma_Y \\, dB_s + \\sum_{i=1}^{N_t} V_i,\n$$\nwhere $\\mu_X, \\mu_Y \\in \\mathbb{R}$ and $\\sigma_X, \\sigma_Y > 0$ are constants. The jump component $\\sum_{i=1}^{N_t} (U_i, V_i)$ represents simultaneous jumps (common shocks) in both $X$ and $Y$.\n\nLet $T > 0$ be a fixed finite time horizon and let $\\pi = \\{0 = t_0 < t_1 < \\dots < t_n = T\\}$ be any partition of $[0,T]$ with mesh $|\\pi| = \\max_k (t_{k+1} - t_k)$. Consider the discretization of the product $X_T Y_T$ that omits the jump cross-term, defined by\n$$\n\\widehat{(XY)}_T := X_0 Y_0 + \\sum_{k=0}^{n-1} X_{t_k} \\big( Y_{t_{k+1}} - Y_{t_k} \\big) + \\sum_{k=0}^{n-1} Y_{t_k} \\big( X_{t_{k+1}} - X_{t_k} \\big) + [X^c, Y^c]_T,\n$$\nwhere $[X^c, Y^c]_T$ denotes the quadratic covariation of the continuous local martingale parts of $X$ and $Y$ over $[0,T]$.\n\nDefine the bias over $[0,T]$ by\n$$\nB_T := \\mathbb{E}\\big[ X_T Y_T - \\widehat{(XY)}_T \\big].\n$$\n\nStarting only from the semimartingale decomposition and the definition of quadratic covariation, prove that ignoring the jump cross-term $\\Delta X \\, \\Delta Y$ yields a bias that is first-order in the horizon $T$. Then, compute $B_T$ in closed form in terms of $\\lambda$ and the jump-size moments. Your final answer must be a single closed-form analytic expression for $B_T$.", "solution": "The objective is to compute the bias $B_T = \\mathbb{E}\\big[ X_T Y_T - \\widehat{(XY)}_T \\big]$. We begin by finding an exact expression for the product $X_T Y_T$ using Itô's product rule for semimartingales. For two semimartingales $X$ and $Y$, the rule is:\n$$\nd(X_t Y_t) = X_{t-} dY_t + Y_{t-} dX_t + d[X, Y]_t\n$$\nIntegrating from $t=0$ to $t=T$ yields:\n$$\nX_T Y_T - X_0 Y_0 = \\int_0^T X_{s-} dY_s + \\int_0^T Y_{s-} dX_s + [X, Y]_T\n$$\n$$\n\\implies X_T Y_T = X_0 Y_0 + \\int_0^T X_{s-} dY_s + \\int_0^T Y_{s-} dX_s + [X, Y]_T\n$$\nThe quadratic covariation $[X, Y]_t$ of two semimartingales can be decomposed into the contribution from their continuous parts and their jump parts:\n$$\n[X, Y]_t = [X^c, Y^c]_t + \\sum_{0 < s \\le t} \\Delta X_s \\Delta Y_s\n$$\nwhere $X^c$ and $Y^c$ are the continuous local martingale parts of $X$ and $Y$, and $\\Delta Z_s = Z_s - Z_{s-}$ denotes the jump of a process $Z$ at time $s$.\n\nSubstituting this decomposition into the expression for $X_T Y_T$:\n$$\nX_T Y_T = X_0 Y_0 + \\int_0^T X_{s-} dY_s + \\int_0^T Y_{s-} dX_s + [X^c, Y^c]_T + \\sum_{0 < s \\le T} \\Delta X_s \\Delta Y_s\n$$\nNow, we consider the provided approximation $\\widehat{(XY)}_T$:\n$$\n\\widehat{(XY)}_T = X_0 Y_0 + \\sum_{k=0}^{n-1} X_{t_k} \\big( Y_{t_{k+1}} - Y_{t_k} \\big) + \\sum_{k=0}^{n-1} Y_{t_k} \\big( X_{t_{k+1}} - X_{t_k} \\big) + [X^c, Y^c]_T\n$$\nThe sum terms are Riemann-Stieltjes sum approximations for the Itô stochastic integrals. As the mesh of the partition $|\\pi| = \\max_k(t_{k+1}-t_k)$ tends to zero, these sums converge in probability to the corresponding Itô integrals. The difference $X_T Y_T - \\widehat{(XY)}_T$ in this limit becomes the jump covariation term.\n$$\nX_T Y_T - \\lim_{|\\pi|\\to 0} \\widehat{(XY)}_T = \\sum_{0 < s \\le T} \\Delta X_s \\Delta Y_s\n$$\nThis term represents the quadratic covariation arising from the simultaneous jumps of $X$ and $Y$. The problem statement describes $\\widehat{(XY)}_T$ as omitting the \"jump cross-term\", which confirms this interpretation. The bias $B_T$ is the expectation of this difference.\n$$\nB_T = \\mathbb{E}\\left[ X_T Y_T - \\widehat{(XY)}_T \\right] = \\mathbb{E}\\left[ \\sum_{0 < s \\le T} \\Delta X_s \\Delta Y_s \\right]\n$$\nThe jumps of the processes $X_t$ and $Y_t$ are driven by the compound Poisson process. Specifically, jumps occur at the event times $T_i$ of the Poisson process $N_t$.\nThe jump sizes at a jump time $s=T_i$ are:\n$$\n\\Delta X_{T_i} = X_{T_i} - X_{T_i-} = U_i\n$$\n$$\n\\Delta Y_{T_i} = Y_{T_i} - Y_{T_i-} = V_i\n$$\nFor any time $s$ that is not a jump time of $N_t$, $\\Delta X_s=0$ and $\\Delta Y_s=0$.\nThe sum of jump products can therefore be written as:\n$$\n\\sum_{0 < s \\le T} \\Delta X_s \\Delta Y_s = \\sum_{i=1}^{N_T} U_i V_i\n$$\nThe bias is the expectation of this random sum:\n$$\nB_T = \\mathbb{E}\\left[ \\sum_{i=1}^{N_T} U_i V_i \\right]\n$$\nTo compute this expectation, we use the law of total expectation (also known as Wald's identity in this context), conditioning on the number of jumps $N_T$:\n$$\nB_T = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\sum_{i=1}^{N_T} U_i V_i \\bigg| N_T \\right] \\right]\n$$\nGiven $N_T = n$, and since the jump sizes $(U_i, V_i)$ are i.i.d. and independent of $N_T$:\n$$\n\\mathbb{E}\\left[ \\sum_{i=1}^{n} U_i V_i \\right] = \\sum_{i=1}^{n} \\mathbb{E}[U_i V_i] = n \\, \\mathbb{E}[UV]\n$$\nwhere $\\mathbb{E}[UV]$ is the expected product of a single jump-size pair, which is finite by assumption.\nSubstituting this back, we have:\n$$\n\\mathbb{E}\\left[ \\sum_{i=1}^{N_T} U_i V_i \\bigg| N_T \\right] = N_T \\, \\mathbb{E}[UV]\n$$\nNow, taking the outer expectation:\n$$\nB_T = \\mathbb{E}\\left[ N_T \\, \\mathbb{E}[UV] \\right] = \\mathbb{E}[N_T] \\, \\mathbb{E}[UV]\n$$\nThe process $N_t$ is a Poisson process with constant intensity $\\lambda$. The number of events $N_T$ in the interval $[0,T]$ follows a Poisson distribution with parameter $\\lambda T$. Its expectation is:\n$$\n\\mathbb{E}[N_T] = \\lambda T\n$$\nSubstituting this gives the closed-form expression for the bias:\n$$\nB_T = \\lambda T \\, \\mathbb{E}[UV]\n$$\nThis result shows that the bias $B_T$ is a linear function of the time horizon $T$, which confirms that it is \"first-order in the horizon $T$\". The bias is solely due to the omitted jump covariation.", "answer": "$$ \\boxed{\\lambda T \\, \\mathbb{E}[UV]} $$", "id": "2982652"}, {"introduction": "Mastery of the Itô product rule comes from applying it to general semimartingales that combine continuous diffusions, jumps, and finite variation drifts. This comprehensive exercise [@problem_id:2982661] requires you to synthesize your knowledge by analyzing the product of two distinct semimartingales. By meticulously identifying and computing each component of the general product formula—from the continuous covariation to the sum of jump products—you will practice the full power of this essential tool and reinforce your understanding of how different stochastic components interact.", "problem": "Fix a filtered probability space $\\left(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\ge 0},\\mathbb{P}\\right)$ satisfying the usual conditions and supporting a standard Brownian motion (BM) $W$ and an independent Poisson random measure $\\mu(\\mathrm{d}s,\\mathrm{d}z)$ on $(0,\\infty)\\times\\mathbb{R}$ with compensator $\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)$, where $\\lambda\\in(0,\\infty)$ is a constant intensity and $F$ is a probability distribution on $\\mathbb{R}$ with finite second moment $m_{2}:=\\int_{\\mathbb{R}} z^{2}\\,F(\\mathrm{d}z)\\in(0,\\infty)$. Let $T>0$ be fixed. Consider the pair of adapted càdlàg semimartingales $(X,Y)$ given by\n$$\nX_{t} \\;=\\; \\int_{0}^{t} \\sigma\\,\\mathrm{d}W_{s} \\;+\\; \\int_{0}^{t}\\int_{\\mathbb{R}} \\alpha\\,z\\big(\\mu(\\mathrm{d}s,\\mathrm{d}z)-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\big),\n\\qquad t\\in[0,T],\n$$\nand\n$$\nY_{t} \\;=\\; y_{0} \\;+\\; \\int_{0}^{t} b\\,\\mathrm{d}s \\;+\\; \\int_{0}^{t}\\int_{\\mathbb{R}} \\beta\\,z\\,\\mu(\\mathrm{d}s,\\mathrm{d}z),\n\\qquad t\\in[0,T],\n$$\nwhere $y_{0},\\sigma,\\alpha,\\beta,b\\in\\mathbb{R}$ are deterministic constants. Assume all stochastic integrals are well-defined and integrable under the stated moment conditions.\n\nTasks:\n1) Starting from the definitions of semimartingale decomposition, quadratic covariation, and the stochastic integral with predictable left limits, derive the full product decomposition for the process $t\\mapsto X_{t}Y_{t}$ on $[0,T]$, explicitly identifying the continuous covariation contribution, the integrals against $\\mathrm{d}W$, $\\mu-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)$, and $\\mu$, as well as the sum of jump products. Do not assume any pre-stated product formula; instead, justify each component from first principles of semimartingales and càdlàg jumps.\n\n2) Specialize your general decomposition to the concrete $X$ and $Y$ above by computing each identified component. In particular, determine the continuous covariation term and express the jump cross-term $\\sum_{0<s\\le t}\\Delta X_{s}\\,\\Delta Y_{s}$ in stochastic integral form with respect to $\\mu(\\mathrm{d}s,\\mathrm{d}z)$.\n\n3) Using your decomposition and integrability, compute the expectation $\\mathbb{E}[X_{T}Y_{T}]$ and present it as a closed-form analytic expression in the parameters $\\alpha,\\beta,\\lambda,m_{2},T$. Your final answer must be a single analytic expression with no units. If you choose to simplify, you may introduce the notation $m_{2}=\\int_{\\mathbb{R}} z^{2}\\,F(\\mathrm{d}z)$ in your final expression. No rounding is required.", "solution": "We begin from the foundational framework of semimartingales. A càdlàg semimartingale $Z$ admits a canonical decomposition $Z=Z_{0}+M+A$ into a local martingale $M$ and a predictable finite variation process $A$. If $Z$ has jumps, then at any time $s$ the jump is $\\Delta Z_{s}:=Z_{s}-Z_{s-}$. For two semimartingales $X$ and $Y$, the product process $XY$ is again a semimartingale. A fundamental route to its decomposition is to apply the two-dimensional Itô formula for $C^{2}$ functions to $f(x,y)=x\\,y$, together with the càdlàg jump structure and the definition of quadratic covariation. Specifically, for two semimartingales $(X,Y)$, the Itô formula with jumps yields\n$$\nX_{t}Y_{t}\n\\,=\\,\nX_{0}Y_{0}\n\\;+\\;\n\\int_{0}^{t} X_{s-}\\,\\mathrm{d}Y_{s}\n\\;+\\;\n\\int_{0}^{t} Y_{s-}\\,\\mathrm{d}X_{s}\n\\;+\\;\n[X^{c},Y^{c}]_{t}\n\\;+\\;\n\\sum_{0<s\\le t}\\Delta X_{s}\\,\\Delta Y_{s},\n$$\nwhere $X^{c}$ and $Y^{c}$ are the continuous local martingale parts of $X$ and $Y$, and $[X^{c},Y^{c}]$ is their quadratic covariation. This follows by writing the first-order terms from the semimartingale differentials $\\mathrm{d}X$ and $\\mathrm{d}Y$, adding the continuous quadratic covariation $[X^{c},Y^{c}]$ from the Itô correction, and then accounting for the jump correction\n$$\n\\sum_{0<s\\le t}\\big(f(X_{s},Y_{s})-f(X_{s-},Y_{s-})-\\nabla f(X_{s-},Y_{s-})\\cdot(\\Delta X_{s},\\Delta Y_{s})\\big)\n\\,=\\,\n\\sum_{0<s\\le t}\\Delta X_{s}\\,\\Delta Y_{s}\n$$\nfor $f(x,y)=x\\,y$. This identity is the rigorous product decomposition, with each term arising from first principles in Itô calculus for semimartingales.\n\nWe now specialize to the given $X$ and $Y$:\n$$\nX_{t} \\;=\\; \\underbrace{\\int_{0}^{t} \\sigma\\,\\mathrm{d}W_{s}}_{=:X^{c}_{t}} \\;+\\; \\underbrace{\\int_{0}^{t}\\int_{\\mathbb{R}} \\alpha\\,z\\big(\\mu(\\mathrm{d}s,\\mathrm{d}z)-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\big)}_{=:X^{d}_{t}},\n$$\nso $X$ is a local martingale with a continuous local martingale part $X^{c}$ and a purely discontinuous local martingale part $X^{d}$. For $Y$,\n$$\nY_{t}\n\\;=\\;\ny_{0}\n\\;+\\;\n\\underbrace{\\int_{0}^{t} b\\,\\mathrm{d}s}_{\\text{finite variation}}\n\\;+\\;\n\\underbrace{\\int_{0}^{t}\\int_{\\mathbb{R}} \\beta\\,z\\,\\mu(\\mathrm{d}s,\\mathrm{d}z)}_{\\text{pure jump process}},\n$$\nwhich is a special semimartingale. Its canonical decomposition is $Y=Y_{0}+M^{Y}+A^{Y}$ with\n$$\nM^{Y}_{t}=\\int_{0}^{t}\\int_{\\mathbb{R}}\\beta\\,z\\big(\\mu(\\mathrm{d}s,\\mathrm{d}z)-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\big),\n\\qquad\nA^{Y}_{t}=\\int_{0}^{t} b\\,\\mathrm{d}s+\\int_{0}^{t}\\int_{\\mathbb{R}}\\beta\\,z\\,\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z),\n$$\nso $Y$ has no continuous local martingale part, i.e., $Y^{c}\\equiv 0$.\n\nItemization of the product decomposition components:\n\n1) Continuous covariation: Since $Y^{c}\\equiv 0$, we have $[X^{c},Y^{c}]_{t}=0$ for all $t\\in[0,T]$.\n\n2) Jump cross-term: Jumps of $X$ come only from the Poisson random measure $\\mu$ and at a jump $(s,z)$ are $\\Delta X_{s}=\\alpha\\,z$; jumps of $Y$ at $(s,z)$ are $\\Delta Y_{s}=\\beta\\,z$. Therefore,\n$$\n\\sum_{0<s\\le t}\\Delta X_{s}\\,\\Delta Y_{s}\n\\;=\\;\n\\sum_{0<s\\le t}\\alpha\\,\\beta\\,z_{s}^{2}\n\\;=\\;\n\\int_{0}^{t}\\int_{\\mathbb{R}}\\alpha\\,\\beta\\,z^{2}\\,\\mu(\\mathrm{d}s,\\mathrm{d}z).\n$$\n\n3) Drift and martingale integrals in $\\int X_{s-}\\,\\mathrm{d}Y_{s}$: By the given $Y$,\n$$\n\\int_{0}^{t} X_{s-}\\,\\mathrm{d}Y_{s}\n\\;=\\;\n\\int_{0}^{t} X_{s-}\\,b\\,\\mathrm{d}s \\;+\\; \\int_{0}^{t}\\int_{\\mathbb{R}} X_{s-}\\,\\beta\\,z\\,\\mu(\\mathrm{d}s,\\mathrm{d}z).\n$$\n\n4) Martingale integrals in $\\int Y_{s-}\\,\\mathrm{d}X_{s}$: By the given $X$,\n$$\n\\int_{0}^{t} Y_{s-}\\,\\mathrm{d}X_{s}\n\\;=\\;\n\\int_{0}^{t} Y_{s-}\\,\\sigma\\,\\mathrm{d}W_{s}\n\\;+\\;\n\\int_{0}^{t}\\int_{\\mathbb{R}} Y_{s-}\\,\\alpha\\,z\\big(\\mu(\\mathrm{d}s,\\mathrm{d}z)-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\big).\n$$\n\nCollecting all terms, using $X_{0}=0$ and $Y_{0}=y_{0}$,\n$$\nX_{t}Y_{t}\n=\nX_{0}Y_{0}\n+\n\\int_{0}^{t} X_{s-}\\,b\\,\\mathrm{d}s\n+\n\\int_{0}^{t}\\int_{\\mathbb{R}} X_{s-}\\,\\beta\\,z\\,\\mu(\\mathrm{d}s,\\mathrm{d}z)\n+\n\\int_{0}^{t} Y_{s-}\\,\\sigma\\,\\mathrm{d}W_{s}\n$$\n$$\n\\quad\n+\n\\int_{0}^{t}\\int_{\\mathbb{R}} Y_{s-}\\,\\alpha\\,z\\big(\\mu(\\mathrm{d}s,\\mathrm{d}z)-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\big)\n+\n0\n+\n\\int_{0}^{t}\\int_{\\mathbb{R}}\\alpha\\,\\beta\\,z^{2}\\,\\mu(\\mathrm{d}s,\\mathrm{d}z).\n$$\n\nWe now compute $\\mathbb{E}[X_{T}Y_{T}]$ under integrability. Each stochastic integral with respect to a local martingale has mean zero:\n- $\\mathbb{E}\\left[\\int_{0}^{T} Y_{s-}\\,\\sigma\\,\\mathrm{d}W_{s}\\right]=0$.\n- $\\mathbb{E}\\left[\\int_{0}^{T}\\int_{\\mathbb{R}} Y_{s-}\\,\\alpha\\,z\\big(\\mu-\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\big)\\right]=0$.\n\nNext, the two terms involving $X_{s-}$:\n- $\\mathbb{E}\\left[\\int_{0}^{T} X_{s-}\\,b\\,\\mathrm{d}s\\right] = b\\int_{0}^{T}\\mathbb{E}[X_{s-}]\\,\\mathrm{d}s = 0$ because $X$ is a mean-zero local martingale with $X_{0}=0$ and is integrable by the given square-integrability conditions.\n- For the measure integral, using the compensation formula for predictable integrands,\n$$\n\\mathbb{E}\\left[\\int_{0}^{T}\\int_{\\mathbb{R}} X_{s-}\\,\\beta\\,z\\,\\mu(\\mathrm{d}s,\\mathrm{d}z)\\right]\n=\n\\mathbb{E}\\left[\\int_{0}^{T}\\int_{\\mathbb{R}} X_{s-}\\,\\beta\\,z\\,\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\\right]\n=\n\\beta\\,\\lambda\\left(\\int_{\\mathbb{R}} z\\,F(\\mathrm{d}z)\\right)\\int_{0}^{T}\\mathbb{E}[X_{s-}]\\,\\mathrm{d}s\n=0.\n$$\n\nFinally, for the jump cross-term,\n$$\n\\mathbb{E}\\left[\\int_{0}^{T}\\int_{\\mathbb{R}}\\alpha\\,\\beta\\,z^{2}\\,\\mu(\\mathrm{d}s,\\mathrm{d}z)\\right]\n=\n\\int_{0}^{T}\\int_{\\mathbb{R}}\\alpha\\,\\beta\\,z^{2}\\,\\lambda\\,\\mathrm{d}s\\,F(\\mathrm{d}z)\n=\n\\alpha\\,\\beta\\,\\lambda\\,T\\,\\int_{\\mathbb{R}} z^{2}\\,F(\\mathrm{d}z)\n=\n\\alpha\\,\\beta\\,\\lambda\\,m_{2}\\,T.\n$$\n\nTherefore,\n$$\n\\mathbb{E}[X_{T}Y_{T}]\n=\n\\alpha\\,\\beta\\,\\lambda\\,m_{2}\\,T.\n$$\n\nThis expression is finite and well-defined by the assumption $m_{2}<\\infty$ and the boundedness of $\\lambda,T$, and it cleanly exhibits the sole non-vanishing contribution in expectation: the predictable compensator of the jump cross-variation.", "answer": "$$\\boxed{\\alpha\\,\\beta\\,\\lambda\\,m_{2}\\,T}$$", "id": "2982661"}]}