{"hands_on_practices": [{"introduction": "This first practice provides a hands-on derivation of the Doléans-Dade exponential for the most fundamental case: a process driven by a scaled Brownian motion. By solving the defining SDE from first principles, you will solidify your understanding of Itô's lemma and its connection to the explicit form of the stochastic exponential. This calculation is a foundational building block for nearly all applications of Girsanov's theorem and measure change. [@problem_id:2975532]", "problem": "Let $\\left(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\geq 0},\\mathbb{P}\\right)$ be a filtered probability space satisfying the usual conditions and supporting a standard Brownian motion $W=(W_{t})_{t\\geq 0}$. Fix a constant $\\theta\\in\\mathbb{R}$ and a time $t>0$. Consider the continuous semimartingale $X=(X_{s})_{0\\leq s\\leq t}$ defined by $X_{s}=\\theta W_{s}$, and its Doléans-Dade exponential $\\mathcal{E}(X)=(\\mathcal{E}(X)_{s})_{0\\leq s\\leq t}$, also written $\\mathcal{E}(\\theta W)$. \n\nStarting from fundamental properties of Brownian motion and quadratic variation, and using only first principles of stochastic calculus, derive:\n- an explicit expression for $\\mathcal{E}(\\theta W)_{t}$ in terms of $\\theta$, $W_{t}$, and $t$,\n- the value of $\\mathbb{E}\\!\\left[\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p}\\right]$ for a given $p>0$,\n- the value of $\\mathrm{Var}^{\\mathbb{P}}\\!\\left(\\mathcal{E}(\\theta W)_{t}\\right)$.\n\nExpress your final answer as a single closed-form analytic expression. No rounding is required, and no physical units are involved. Your derivations must be scientifically sound and self-consistent, and should rely on well-tested facts such as the distributional properties of Brownian motion and the definition of quadratic variation.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is a standard problem in stochastic calculus that can be solved using first principles. We proceed with the derivation.\n\nThe problem requires the derivation of three quantities related to the Doléans-Dade exponential of the process $X_{s}=\\theta W_{s}$. We will address each in sequence.\n\nFirst, we derive an explicit expression for the Doléans-Dade exponential, denoted $Z_{t} = \\mathcal{E}(X)_{t}$. By definition, $Z=(Z_{s})_{s\\geq 0}$ is the unique strong solution to the stochastic differential equation (SDE):\n$$dZ_{s} = Z_{s} dX_{s}, \\quad Z_{0} = 1$$\nGiven that $X_{s} = \\theta W_{s}$, where $W$ is a standard Brownian motion and $\\theta$ is a real constant, the differential is $dX_{s} = \\theta dW_{s}$. The SDE for $Z_{s}$ becomes:\n$$dZ_{s} = \\theta Z_{s} dW_{s}$$\nThis is the SDE for a geometric Brownian motion with zero drift. To solve this, we apply Itô's lemma to a function of the form $f(s, w) = \\exp(\\theta w - \\frac{1}{2}\\theta^{2}s)$. We wish to show that $Z_{s} = f(s, W_{s})$ solves the SDE with the correct initial condition.\n\nLet $Z_{s} = f(s, W_{s}) = \\exp(\\theta W_{s} - \\frac{1}{2}\\theta^{2}s)$. We compute the necessary partial derivatives of $f(s, w)$:\n$$\\frac{\\partial f}{\\partial s} = -\\frac{1}{2}\\theta^{2} \\exp\\left(\\theta w - \\frac{1}{2}\\theta^{2}s\\right) = -\\frac{1}{2}\\theta^{2} f(s,w)$$\n$$\\frac{\\partial f}{\\partial w} = \\theta \\exp\\left(\\theta w - \\frac{1}{2}\\theta^{2}s\\right) = \\theta f(s,w)$$\n$$\\frac{\\partial^{2} f}{\\partial w^{2}} = \\theta^{2} \\exp\\left(\\theta w - \\frac{1}{2}\\theta^{2}s\\right) = \\theta^{2} f(s,w)$$\nAccording to Itô's lemma, the differential $dZ_{s} = df(s, W_{s})$ is given by:\n$$dZ_{s} = \\frac{\\partial f}{\\partial s}(s, W_{s}) ds + \\frac{\\partial f}{\\partial w}(s, W_{s}) dW_{s} + \\frac{1}{2} \\frac{\\partial^{2} f}{\\partial w^{2}}(s, W_{s}) d\\langle W \\rangle_{s}$$\nA fundamental property of standard Brownian motion is that its quadratic variation is $\\langle W \\rangle_{s} = s$, which implies $d\\langle W \\rangle_{s} = ds$. Substituting the derivatives and $d\\langle W \\rangle_{s}$ into the Itô formula:\n$$dZ_{s} = \\left(-\\frac{1}{2}\\theta^{2} Z_{s}\\right) ds + \\left(\\theta Z_{s}\\right) dW_{s} + \\frac{1}{2} \\left(\\theta^{2} Z_{s}\\right) ds$$\nThe terms involving $ds$ cancel out:\n$$dZ_{s} = \\left(-\\frac{1}{2}\\theta^{2} Z_{s} + \\frac{1}{2}\\theta^{2} Z_{s}\\right) ds + \\theta Z_{s} dW_{s} = \\theta Z_{s} dW_{s}$$\nThis matches the SDE we aimed to solve. We must also check the initial condition. At $s=0$, we have $W_{0}=0$, so:\n$$Z_{0} = \\exp\\left(\\theta W_{0} - \\frac{1}{2}\\theta^{2}(0)\\right) = \\exp(0) = 1$$\nThe initial condition is satisfied. Thus, the explicit expression for the Doléans-Dade exponential at time $t$ is:\n$$\\mathcal{E}(\\theta W)_{t} = \\exp\\left(\\theta W_{t} - \\frac{1}{2}\\theta^{2}t\\right)$$\n\nSecond, we compute the expected value of the $p$-th power of $\\mathcal{E}(\\theta W)_{t}$ for a given $p>0$. We are interested in the quantity $\\mathbb{E}\\!\\left[\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p}\\right]$.\nUsing the expression derived above:\n$$\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p} = \\left(\\exp\\left(\\theta W_{t} - \\frac{1}{2}\\theta^{2}t\\right)\\right)^{p} = \\exp\\left(p\\theta W_{t} - \\frac{p}{2}\\theta^{2}t\\right)$$\nThe expectation is:\n$$\\mathbb{E}\\!\\left[\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p}\\right] = \\mathbb{E}\\!\\left[\\exp\\left(p\\theta W_{t} - \\frac{p}{2}\\theta^{2}t\\right)\\right]$$\nWe can factor out the non-random term from the expectation:\n$$\\mathbb{E}\\!\\left[\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p}\\right] = \\exp\\left(-\\frac{p}{2}\\theta^{2}t\\right) \\mathbb{E}\\!\\left[\\exp(p\\theta W_{t})\\right]$$\nA cornerstone property of standard Brownian motion is that the random variable $W_{t}$ is normally distributed with mean $0$ and variance $t$, denoted $W_{t} \\sim \\mathcal{N}(0, t)$. The term $\\mathbb{E}[\\exp(p\\theta W_{t})]$ is the moment-generating function (MGF) of $W_{t}$ evaluated at the point $k=p\\theta$. The MGF of a general normal random variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ is $M_{Y}(k) = \\mathbb{E}[\\exp(kY)] = \\exp(k\\mu + \\frac{1}{2}k^{2}\\sigma^{2})$.\nFor $W_{t}$, we have $\\mu=0$ and $\\sigma^{2}=t$. Evaluating its MGF at $k=p\\theta$:\n$$\\mathbb{E}\\!\\left[\\exp(p\\theta W_{t})\\right] = M_{W_{t}}(p\\theta) = \\exp\\left((p\\theta)(0) + \\frac{1}{2}(p\\theta)^{2}t\\right) = \\exp\\left(\\frac{1}{2}p^{2}\\theta^{2}t\\right)$$\nSubstituting this result back into the expression for the $p$-th moment:\n$$\\mathbb{E}\\!\\left[\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p}\\right] = \\exp\\left(-\\frac{p}{2}\\theta^{2}t\\right) \\exp\\left(\\frac{1}{2}p^{2}\\theta^{2}t\\right) = \\exp\\left(\\frac{1}{2}p^{2}\\theta^{2}t - \\frac{p}{2}\\theta^{2}t\\right)$$\n$$\\mathbb{E}\\!\\left[\\left(\\mathcal{E}(\\theta W)_{t}\\right)^{p}\\right] = \\exp\\left(\\frac{1}{2}(p^{2}-p)\\theta^{2}t\\right)$$\n\nThird, we compute the variance, $\\mathrm{Var}^{\\mathbb{P}}\\!\\left(\\mathcal{E}(\\theta W)_{t}\\right)$. The variance of a random variable $Z$ is given by the formula $\\mathrm{Var}(Z) = \\mathbb{E}[Z^{2}] - (\\mathbb{E}[Z])^{2}$. We can use the general formula for the $p$-th moment derived above to find the first and second moments of $Z_t = \\mathcal{E}(\\theta W)_{t}$.\n\nFor the first moment (the mean), we set $p=1$:\n$$\\mathbb{E}[\\mathcal{E}(\\theta W)_{t}] = \\exp\\left(\\frac{1}{2}(1^{2}-1)\\theta^{2}t\\right) = \\exp(0) = 1$$\nThis result is expected, as $\\mathcal{E}(\\theta W)$ is a martingale under the Novikov condition $\\mathbb{E}[\\exp(\\frac{1}{2}\\int_{0}^{t}\\theta^{2}ds)] = \\exp(\\frac{1}{2}\\theta^{2}t) < \\infty$, which holds for any finite $t$.\n\nFor the second moment, we set $p=2$:\n$$\\mathbb{E}\\!\\left[(\\mathcal{E}(\\theta W)_{t})^{2}\\right] = \\exp\\left(\\frac{1}{2}(2^{2}-2)\\theta^{2}t\\right) = \\exp\\left(\\frac{1}{2}(2)\\theta^{2}t\\right) = \\exp(\\theta^{2}t)$$\nNow, we can compute the variance:\n$$\\mathrm{Var}(\\mathcal{E}(\\theta W)_{t}) = \\mathbb{E}\\!\\left[(\\mathcal{E}(\\theta W)_{t})^{2}\\right] - \\left(\\mathbb{E}[\\mathcal{E}(\\theta W)_{t}]\\right)^{2} = \\exp(\\theta^{2}t) - 1^{2}$$\n$$\\mathrm{Var}(\\mathcal{E}(\\theta W)_{t}) = \\exp(\\theta^{2}t) - 1$$\n\nThe three required quantities have been derived from first principles.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\exp\\left(\\theta W_t - \\frac{1}{2}\\theta^2 t\\right) & \\exp\\left(\\frac{1}{2}(p^2 - p)\\theta^2 t\\right) & \\exp(\\theta^2 t) - 1\n\\end{pmatrix}\n}\n$$", "id": "2975532"}, {"introduction": "This exercise moves beyond the standard Novikov condition to explore the more general Kazamaki criterion, highlighting a crucial subtlety in the theory of exponential martingales. You will construct and analyze a scenario where the simpler condition fails, yet the process $\\mathcal{E}(M)$ is still a uniformly integrable martingale, securing its role as a valid Radon-Nikodym density. This practice is invaluable for understanding the precise boundaries of when a change of measure is well-defined. [@problem_id:2989061]", "problem": "Let $\\left(\\Omega, \\mathcal{F}, (\\mathcal{F}_{t})_{t \\in [0,T]}, \\mathbb{P}\\right)$ be a filtered probability space supporting a standard one-dimensional Brownian motion $B = (B_{t})_{t \\in [0,T]}$ with the usual augmentation. Fix a deterministic horizon $T \\in (0,\\infty)$ and a parameter $\\alpha$ satisfying $\\frac{\\pi}{2} < \\alpha < 2$, and set the constant $c := \\alpha/T$. For each $n \\in \\mathbb{N}$ define the progressively measurable process\n$$\n\\theta^{(n)}_{t} := c\\, B_{t}\\, \\mathbf{1}_{\\{|B_{t}| \\le n\\}}, \\quad t \\in [0,T],\n$$\nand the associated Doléans–Dade exponential at time $T$,\n$$\nZ_{T}^{(n)} := \\exp\\!\\left( \\int_{0}^{T} \\theta^{(n)}_{t} \\, dB_{t} \\;-\\; \\frac{1}{2} \\int_{0}^{T} \\big(\\theta^{(n)}_{t}\\big)^{2} \\, dt \\right).\n$$\nLet $\\theta_{t} := c B_{t}$ and $Z_{T} := \\exp\\!\\left( \\int_{0}^{T} \\theta_{t} \\, dB_{t} \\;-\\; \\frac{1}{2} \\int_{0}^{T} \\theta_{t}^{2} \\, dt \\right)$ denote the limiting integrand and exponential, respectively.\n\nUsing only foundational facts and core definitions, including the Karhunen–Loève (KL) expansion for Brownian motion, the Itô formula, and the definitions of Novikov’s condition and Kazamaki’s condition for exponential local martingales, carry out the following tasks:\n\n1. Prove that Novikov’s condition holds for each truncated integrand $\\theta^{(n)}$, but Novikov’s condition fails for the limiting integrand $\\theta$. In your argument for failure, appeal to the sharp moment generating function bound for $\\int_{0}^{T} B_{t}^{2} \\, dt$ implied by the KL expansion.\n\n2. Prove that Kazamaki’s condition holds for the limiting integrand $\\theta$, i.e., verify that $\\sup_{t \\in [0,T]} \\mathbb{E}\\!\\left[\\exp\\!\\left(\\frac{1}{2} \\int_{0}^{t} \\theta_{s} \\, dB_{s}\\right)\\right] < \\infty$, and conclude that $(Z_{t})_{t \\in [0,T]}$ is a uniformly integrable martingale.\n\n3. Justify that $Z_{T}^{(n)} \\to Z_{T}$ in $\\mathbb{L}^{1}(\\mathbb{P})$ as $n \\to \\infty$ by combining convergence techniques such as the dominated convergence theorem (for the drift term) and either a Skorokhod-type representation or a Vitali/Uniform Integrability argument (leveraging Kazamaki’s condition) for the exponentials.\n\n4. Determine the explicit analytic expression for $Z_{T}$ in terms of $B_{T}$ and $\\int_{0}^{T} B_{t}^{2} \\, dt$, and compute the value of $\\mathbb{E}[Z_{T}]$.\n\nYour final answer must be a two-entry row matrix whose first entry is the closed-form expression for $Z_{T}$ and whose second entry is the value of $\\mathbb{E}[Z_{T}]$. No numerical approximation is required.", "solution": "The problem asks for a multi-part analysis of a specific family of exponential local martingales, testing the understanding of the conditions under which they are true martingales and uniformly integrable martingales. We will address each of the four requested tasks in sequence.\n\nThe setup involves a standard one-dimensional Brownian motion $(B_t)_{t \\in [0,T]}$ on a filtered probability space, a constant $c = \\alpha/T$ with $\\alpha \\in (\\frac{\\pi}{2}, 2)$, and the integrands $\\theta_t = c B_t$ and its truncated versions $\\theta_t^{(n)} = c B_t \\mathbf{1}_{\\{|B_t| \\le n\\}}$. The corresponding Doléans-Dade exponentials are $Z_t = \\mathcal{E}(\\int \\theta_s dB_s)_t$ and $Z_t^{(n)} = \\mathcal{E}(\\int \\theta_s^{(n)} dB_s)_t$.\n\n### 1. Analysis of Novikov’s Condition\n\nNovikov's condition provides a sufficient criterion for an exponential local martingale to be a true martingale. For a process $M_t = \\int_0^t \\eta_s dB_s$, its stochastic exponential $\\mathcal{E}(M)_t$ is a martingale if $\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2} \\langle M \\rangle_t\\right)\\right] < \\infty$. Here, $\\langle M \\rangle_t = \\int_0^t \\eta_s^2 ds$.\n\n**For the truncated integrand $\\theta^{(n)}$:**\nThe integrand is $\\theta_t^{(n)} = c B_t \\mathbf{1}_{\\{|B_t| \\le n\\}}$. By its definition, this process is bounded: $|\\theta_t^{(n)}| \\le c n$ for all $t \\in [0,T]$. The quadratic variation process is\n$$\n\\langle \\textstyle{\\int} \\theta_s^{(n)} dB_s \\rangle_T = \\int_0^T (\\theta_s^{(n)})^2 ds = c^2 \\int_0^T B_s^2 \\mathbf{1}_{\\{|B_s| \\le n\\}} ds.\n$$\nWe can establish an upper bound on this integral:\n$$\n\\int_0^T (\\theta_s^{(n)})^2 ds \\le \\int_0^T (cn)^2 ds = c^2 n^2 T.\n$$\nNow, we check Novikov's condition:\n$$\n\\mathbb{E}\\left[ \\exp\\left(\\frac{1}{2} \\int_0^T (\\theta_s^{(n)})^2 ds\\right) \\right] \\le \\mathbb{E}\\left[ \\exp\\left(\\frac{1}{2} c^2 n^2 T\\right) \\right] = \\exp\\left(\\frac{1}{2} c^2 n^2 T\\right).\n$$\nSince $c$, $n$, and $T$ are finite constants, this exponential is finite. Thus, Novikov's condition holds for each truncated integrand $\\theta^{(n)}$. This implies that for each $n \\in \\mathbb{N}$, the process $(Z_t^{(n)})_{t \\in [0,T]}$ is a true martingale, and in particular $\\mathbb{E}[Z_T^{(n)}] = Z_0^{(n)} = 1$.\n\n**For the limiting integrand $\\theta$:**\nThe integrand is $\\theta_t = c B_t$. Novikov's condition requires checking if $\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2} \\int_0^T \\theta_t^2 dt\\right)\\right] < \\infty$. Let's analyze the argument of the expectation:\n$$\n\\frac{1}{2} \\int_0^T \\theta_t^2 dt = \\frac{c^2}{2} \\int_0^T B_t^2 dt = \\frac{\\alpha^2}{2T^2} \\int_0^T B_t^2 dt.\n$$\nWe use the Karhunen-Loève (KL) expansion of the Brownian motion $B_t$ on $[0,T]$, which is $B_t = \\sum_{k=0}^{\\infty} \\xi_k \\sqrt{\\lambda_k} \\phi_k(t)$, where $\\{\\xi_k\\}_{k=0}^\\infty$ is a sequence of i.i.d. $N(0,1)$ random variables, and $\\phi_k(t) = \\sqrt{2/T}\\sin((k+1/2)\\pi t/T)$ are the eigenfunctions of the covariance operator of $B_t$ with corresponding eigenvalues $\\lambda_k = \\frac{T^2}{(k+1/2)^2\\pi^2}$. By Parseval's theorem, we can express the integral of the squared process as:\n$$\n\\int_0^T B_t^2 dt = \\sum_{k=0}^{\\infty} \\xi_k^2 \\lambda_k.\n$$\nThe expectation in Novikov's condition becomes:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{\\alpha^2}{2T^2} \\sum_{k=0}^{\\infty} \\xi_k^2 \\lambda_k\\right)\\right] = \\mathbb{E}\\left[\\prod_{k=0}^{\\infty} \\exp\\left(\\frac{\\alpha^2 \\lambda_k}{2T^2} \\xi_k^2\\right)\\right].\n$$\nDue to the independence of the $\\xi_k$, this is equal to the product of the individual expectations:\n$$\n\\prod_{k=0}^{\\infty} \\mathbb{E}\\left[\\exp\\left(\\frac{\\alpha^2 \\lambda_k}{2T^2} \\xi_k^2\\right)\\right].\n$$\nFor a standard normal variable $\\xi \\sim N(0,1)$, the expectation $\\mathbb{E}[\\exp(a \\xi^2)]$ is finite if and only if $a < 1/2$, in which case its value is $(1-2a)^{-1/2}$. Here, $a_k = \\frac{\\alpha^2 \\lambda_k}{2T^2}$. The condition for finiteness for each term is $\\frac{\\alpha^2 \\lambda_k}{2T^2} < \\frac{1}{2}$, which simplifies to $\\alpha^2 \\lambda_k/T^2 < 1$. Substituting the expression for $\\lambda_k$:\n$$\n\\frac{\\alpha^2}{T^2} \\frac{T^2}{(k+1/2)^2\\pi^2} < 1 \\iff \\frac{\\alpha^2}{(k+1/2)^2\\pi^2} < 1.\n$$\nThis condition must hold for all $k \\ge 0$. Let's check it for $k=0$:\n$$\n\\frac{\\alpha^2}{(\\pi/2)^2} < 1 \\iff \\frac{2\\alpha}{\\pi} < 1 \\iff \\alpha < \\frac{\\pi}{2}.\n$$\nHowever, the problem specifies that $\\alpha > \\frac{\\pi}{2}$. Therefore, for $k=0$, the condition is violated. The term $\\mathbb{E}\\left[\\exp\\left(\\frac{\\alpha^2 \\lambda_0}{2T^2} \\xi_0^2\\right)\\right]$ is infinite. Since all terms in the infinite product are greater than or equal to $1$, the entire product diverges to infinity.\nConsequently, Novikov's condition fails for the limiting integrand $\\theta$.\n\n### 2. Analysis of Kazamaki’s Condition\n\nKazamaki's condition is a weaker, but still sufficient, condition for an exponential local martingale to be a uniformly integrable martingale. For $M_t = \\int_0^t \\eta_s dB_s$, Kazamaki's condition is $\\sup_{t \\in [0,T]} \\mathbb{E}\\left[\\exp\\left(\\frac{1}{2} M_t\\right)\\right] < \\infty$.\n\nFor the limiting integrand $\\theta_t = c B_t$, the required stochastic integral is $M_t = \\int_0^t \\theta_s dB_s = c \\int_0^t B_s dB_s$. Using Itô's formula on $f(x) = x^2$ for the process $B_t$, we have $d(B_t^2) = 2B_t dB_t + dt$, which gives $\\int_0^t B_s dB_s = \\frac{1}{2}(B_t^2 - t)$. Therefore:\n$$\nM_t = \\frac{c}{2}(B_t^2 - t).\n$$\nWe must now verify the finiteness of $\\sup_{t \\in [0,T]} \\mathbb{E}\\left[\\exp\\left(\\frac{1}{2} M_t\\right)\\right]$:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2} M_t\\right)\\right] = \\mathbb{E}\\left[\\exp\\left(\\frac{c}{4}(B_t^2 - t)\\right)\\right] = \\exp\\left(-\\frac{ct}{4}\\right) \\mathbb{E}\\left[\\exp\\left(\\frac{c}{4}B_t^2\\right)\\right].\n$$\nSince $B_t \\sim N(0,t)$, we can write $B_t = \\sqrt{t} \\xi$ where $\\xi \\sim N(0,1)$. The expectation becomes:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{c}{4}B_t^2\\right)\\right] = \\mathbb{E}\\left[\\exp\\left(\\frac{ct}{4}\\xi^2\\right)\\right].\n$$\nThis expectation is finite if and only if the coefficient of $\\xi^2$ is less than $1/2$, i.e., $\\frac{ct}{4} < \\frac{1}{2}$, which is equivalent to $ct < 2$. Substituting $c = \\alpha/T$, we need $\\frac{\\alpha t}{T} < 2$. Since $t \\in [0,T]$, the most restrictive case is $t=T$, which requires $\\alpha < 2$. The problem states $\\frac{\\pi}{2} < \\alpha < 2$, so this condition is satisfied for all $t \\in [0,T]$.\nThe expectation evaluates to:\n$$\n\\mathbb{E}\\left[\\exp\\left(\\frac{1}{2} M_t\\right)\\right] = \\exp\\left(-\\frac{\\alpha t}{4T}\\right) \\left(1 - 2\\frac{\\alpha t}{4T}\\right)^{-1/2} = \\exp\\left(-\\frac{\\alpha t}{4T}\\right) \\left(1 - \\frac{\\alpha t}{2T}\\right)^{-1/2}.\n$$\nLet this expression be $f(t)$. The function $f(t)$ is continuous on the compact interval $[0,T]$, since the term inside the square root is always positive ($1 - \\frac{\\alpha t}{2T} > 1 - \\frac{2t}{2T} = 1 - \\frac{t}{T} \\ge 0$). A continuous function on a compact set is bounded. Therefore, $\\sup_{t \\in [0,T]} f(t) < \\infty$.\nKazamaki's condition holds for the integrand $\\theta$. This implies that the exponential local martingale $(Z_t)_{t\\in[0,T]}$ is a uniformly integrable martingale.\n\n### 3. $L^1$ Convergence of $Z_T^{(n)}$ to $Z_T$\n\nWe aim to prove that $\\mathbb{E}[|Z_T^{(n)} - Z_T|] \\to 0$ as $n \\to \\infty$. A standard approach is to show almost sure convergence combined with uniform integrability. A more direct method, fitting the context, is to use a powerful convergence theorem for stochastic exponentials.\n\nFirst, we establish that $Z_T^{(n)} \\to Z_T$ almost surely (a.s.). The argument of the exponential for $Z_T^{(n)}$ is $\\int_0^T \\theta_t^{(n)} dB_t - \\frac{1}{2}\\int_0^T (\\theta_t^{(n)})^2 dt$. For almost every sample path $\\omega$, the continuous function $t \\mapsto B_t(\\omega)$ is bounded on $[0,T]$. Let $K(\\omega) = \\sup_{t \\in [0,T]} |B_t(\\omega)| < \\infty$. For any $n > K(\\omega)$, we have $|B_t(\\omega)| < n$ for all $t \\in [0,T]$, which implies $\\theta_t^{(n)}(\\omega) = \\theta_t(\\omega)$ for all $t \\in [0,T]$. Consequently, the integrals for $Z_T^{(n)}$ become identical to those for $Z_T$. Thus, $Z_T^{(n)}(\\omega) \\to Z_T(\\omega)$ a.s.\n\nFor $L^1$ convergence, we appeal to the following theorem: If $(H_n)_{n \\in \\mathbb{N}}$ is a sequence of predictable integrands converging to $H$ in the space $L^2(\\Omega \\times [0,T])$, and the stochastic exponential $\\mathcal{E}(H)$ is a uniformly integrable martingale, then $\\mathcal{E}(H_n)_T \\to \\mathcal{E}(H)_T$ in $L^1(\\mathbb{P})$.\n\nLet's verify the conditions of this theorem for $H_n = \\theta^{(n)}$ and $H = \\theta$.\n1.  **UI Martingale property for $\\mathcal{E}(H)$**: We proved in Part 2, using Kazamaki's condition, that $Z = \\mathcal{E}(\\theta)$ is a uniformly integrable martingale. This condition is met.\n2.  **$L^2$ convergence of integrands**: We need to show $\\mathbb{E}\\left[\\int_0^T (\\theta_t - \\theta_t^{(n)})^2 dt\\right] \\to 0$ as $n \\to \\infty$.\n    $$\n    \\mathbb{E}\\left[\\int_0^T (\\theta_t - \\theta_t^{(n)})^2 dt\\right] = \\mathbb{E}\\left[\\int_0^T (c B_t - c B_t \\mathbf{1}_{\\{|B_t| \\le n\\}})^2 dt\\right] = c^2 \\mathbb{E}\\left[\\int_0^T B_t^2 \\mathbf{1}_{\\{|B_t| > n\\}} dt\\right].\n    $$\n    By the Fubini-Tonelli theorem, we can swap the expectation and time integral:\n    $$\n    c^2 \\int_0^T \\mathbb{E}\\left[B_t^2 \\mathbf{1}_{\\{|B_t| > n\\}}\\right] dt.\n    $$\n    Let $g_n(t) = \\mathbb{E}[B_t^2 \\mathbf{1}_{\\{|B_t| > n\\}}]$. Since $B_t^2$ is integrable, for each fixed $t$, $g_n(t) \\to 0$ as $n \\to \\infty$ by the Dominated Convergence Theorem. Furthermore, $g_n(t) \\le \\mathbb{E}[B_t^2] = t$. The function $f(t) = t$ is integrable on $[0,T]$. We can therefore apply the Dominated Convergence Theorem to the integral over $[0,T]$:\n    $$\n    \\lim_{n\\to\\infty} c^2 \\int_0^T g_n(t) dt = c^2 \\int_0^T \\lim_{n\\to\\infty} g_n(t) dt = c^2 \\int_0^T 0 \\, dt = 0.\n    $$\n    Thus, $\\theta^{(n)} \\to \\theta$ in $L^2(\\Omega \\times [0,T])$.\n\nSince both conditions of the theorem are satisfied, we conclude that $Z_T^{(n)} \\to Z_T$ in $L^1(\\mathbb{P})$.\n\n### 4. Explicit Expression for $Z_T$ and its Expectation\n\nThe Doléans-Dade exponential is given by\n$$\nZ_T = \\exp\\left( \\int_{0}^{T} \\theta_{t} \\, dB_{t} - \\frac{1}{2} \\int_{0}^{T} \\theta_{t}^{2} \\, dt \\right).\n$$\nWe substitute the expressions for the integrals calculated previously:\n- $\\int_0^T \\theta_t dB_t = c \\int_0^T B_t dB_t = \\frac{c}{2}(B_T^2 - T)$.\n- $\\int_0^T \\theta_t^2 dt = c^2 \\int_0^T B_t^2 dt$.\n\nSubstituting these and $c = \\alpha/T$ into the formula for $Z_T$ yields the explicit expression:\n$$\nZ_T = \\exp\\left( \\frac{c}{2}(B_T^2 - T) - \\frac{c^2}{2} \\int_0^T B_t^2 dt \\right) = \\exp\\left( \\frac{\\alpha}{2T}(B_T^2 - T) - \\frac{\\alpha^2}{2T^2} \\int_0^T B_t^2 dt \\right).\n$$\nTo compute the expectation $\\mathbb{E}[Z_T]$, we recall the result from Part 2. The validity of Kazamaki's condition implies that the process $(Z_t)_{t \\in [0,T]}$ is a uniformly integrable martingale. For any martingale, $\\mathbb{E}[Z_t] = \\mathbb{E}[Z_0]$ for all $t \\in [0,T]$. At time $t=0$, the integrals are zero:\n$$\nZ_0 = \\exp(0 - 0) = 1.\n$$\nTherefore, for any $t \\in [0,T]$, including $t=T$, we have:\n$$\n\\mathbb{E}[Z_T] = Z_0 = 1.\n$$\nThe uniform integrability is crucial, as it ensures that the martingale property (constant expectation) holds up to the fixed, deterministic time $T$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\exp\\left( \\frac{\\alpha}{2T}(B_T^2 - T) - \\frac{\\alpha^2}{2T^2} \\int_0^T B_t^2 dt \\right) & 1 \\end{pmatrix}}\n$$", "id": "2989061"}, {"introduction": "Our final practice presents a critical counterexample that illuminates the importance of uniform integrability. You will investigate a local martingale that is a true martingale on any interval $[0, T_n]$ for $T_n \\lt T$, but fails to be a martingale on the closed interval $[0, T]$ due to a singularity in the integrand at the terminal time. This exercise demonstrates how the absence of uniform integrability can lead to a breakdown in desired properties, providing a powerful lesson on the prerequisites for robust measure change applications. [@problem_id:2992601]", "problem": "Let $\\left(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\in[0,T]},\\mathbb{P}\\right)$ be a filtered probability space supporting a standard one-dimensional Brownian motion $W=(W_t)_{t\\in[0,T]}$ with the usual augmentation, where $T\\in(0,\\infty)$ is fixed. For a constant $a>0$, define the predictable process $\\theta=(\\theta_t)_{t\\in[0,T)}$ by $\\theta_t=\\frac{a}{\\sqrt{T-t}}\\mathbf{1}_{\\{t<T\\}}$. For $t\\in[0,T)$, define the process $Z=(Z_t)_{t\\in[0,T)}$ by the Doléans-Dade exponential\n$$\nZ_t=\\exp\\!\\Bigg(\\int_0^t \\theta_s\\,\\mathrm{d}W_s-\\frac{1}{2}\\int_0^t \\theta_s^2\\,\\mathrm{d}s\\Bigg),\n$$\nand define $Z_T:=\\lim_{t\\uparrow T}Z_t$ whenever the limit exists. Let $T_n:=T-\\frac{1}{n}$ so that $T_n\\uparrow T$ as $n\\to\\infty$.\n\nTasks:\n1. Starting from the definitions of Radon-Nikodym derivatives and the Doléans-Dade exponential, justify that for each $n\\in\\mathbb{N}$, the process $(Z_{t\\wedge T_n})_{t\\in[0,T]}$ is a true $\\mathbb{P}$-martingale on $[0,T]$ with $\\mathbb{E}_{\\mathbb{P}}[Z_{T_n}]=1$, and so $Z_{T_n}$ defines a Radon-Nikodym derivative of a probability measure $\\mathbb{Q}^{(n)}$ on $\\mathcal{F}_{T_n}$ via $\\frac{\\mathrm{d}\\mathbb{Q}^{(n)}}{\\mathrm{d}\\mathbb{P}}\\big|_{\\mathcal{F}_{T_n}}=Z_{T_n}$.\n2. Prove that $Z_t$ converges $\\mathbb{P}$-almost surely as $t\\uparrow T$ and compute the value of $Z_T$.\n3. Conclude from (1) and (2) whether the family $\\{Z_{T_n}\\}_{n\\in\\mathbb{N}}$ is uniformly integrable in $L^1(\\mathbb{P})$.\n\nYour final answer should be the computed closed-form value of $Z_T$ (a single number). No rounding is required and there are no physical units.", "solution": "We begin from the standard construction of Radon-Nikodym derivatives for measure changes in continuous-time Brownian settings. Let $W=(W_t)_{t\\in[0,T]}$ be a standard Brownian motion. For a predictable process $\\theta$ such that $\\int_0^t \\theta_s^2\\,\\mathrm{d}s<\\infty$ for each $t<T$, the Doléans-Dade exponential\n$$\nZ_t=\\exp\\!\\Bigg(M_t-\\frac{1}{2}\\langle M\\rangle_t\\Bigg),\\quad\\text{where }M_t:=\\int_0^t \\theta_s\\,\\mathrm{d}W_s,\\;\\langle M\\rangle_t:=\\int_0^t \\theta_s^2\\,\\mathrm{d}s,\n$$\nis a nonnegative local martingale on $[0,T)$. If, moreover, Novikov's condition holds on a finite horizon $[0,t]$, namely\n$$\n\\mathbb{E}_{\\mathbb{P}}\\Big[\\exp\\!\\Big(\\frac{1}{2}\\int_0^t \\theta_s^2\\,\\mathrm{d}s\\Big)\\Big]<\\infty,\n$$\nthen $(Z_s)_{s\\in[0,t]}$ is a true martingale with $\\mathbb{E}_{\\mathbb{P}}[Z_t]=1$.\n\nStep 1: Martingale property on $[0,T_n]$. For our choice $\\theta_t=\\frac{a}{\\sqrt{T-t}}\\mathbf{1}_{\\{t<T\\}}$ with $a>0$, compute for $t<T$ the quadratic variation\n$$\n\\langle M\\rangle_t=\\int_0^t \\theta_s^2\\,\\mathrm{d}s=\\int_0^t \\frac{a^2}{T-s}\\,\\mathrm{d}s\n=a^2\\int_0^t \\frac{1}{T-s}\\,\\mathrm{d}s\n=a^2\\big(-\\ln(T-t)+\\ln T\\big)=a^2\\ln\\!\\Big(\\frac{T}{T-t}\\Big).\n$$\nFor each fixed $n\\in\\mathbb{N}$, $T_n=T-\\frac{1}{n}<T$, hence\n$$\n\\int_0^{T_n}\\theta_s^2\\,\\mathrm{d}s=a^2\\ln\\!\\Big(\\frac{T}{T-T_n}\\Big)=a^2\\ln\\!\\Big(\\frac{T}{1/n}\\Big)=a^2\\ln(nT)<\\infty.\n$$\nThen Novikov's condition on $[0,T_n]$ reads\n$$\n\\mathbb{E}_{\\mathbb{P}}\\Big[\\exp\\!\\Big(\\frac{1}{2}\\int_0^{T_n}\\theta_s^2\\,\\mathrm{d}s\\Big)\\Big]\n=\\exp\\!\\Big(\\frac{1}{2}a^2\\ln(nT)\\Big)=(nT)^{a^2/2}<\\infty,\n$$\nwhich is finite and deterministic. Therefore $Z$ is a true martingale on $[0,T_n]$ with $\\mathbb{E}_{\\mathbb{P}}[Z_{T_n}]=1$. It follows that $Z_{T_n}$ is a Radon-Nikodym derivative for a probability measure $\\mathbb{Q}^{(n)}$ on $\\mathcal{F}_{T_n}$, i.e., $\\frac{\\mathrm{d}\\mathbb{Q}^{(n)}}{\\mathrm{d}\\mathbb{P}}\\big|_{\\mathcal{F}_{T_n}}=Z_{T_n}$.\n\nStep 2: Almost sure limit as $t\\uparrow T$ and computation of $Z_T$. Since $Z$ is a nonnegative local martingale, it is a supermartingale on $[0,T)$, and by the supermartingale convergence theorem, the limit $Z_T:=\\lim_{t\\uparrow T}Z_t$ exists $\\mathbb{P}$-almost surely (in $[0,\\infty]$).\n\nTo compute $Z_T$, we use a time-change argument. Define $A_t:=\\langle M\\rangle_t=a^2\\ln\\!\\big(\\frac{T}{T-t}\\big)$, which is continuous, strictly increasing in $t$, and satisfies $A_t\\uparrow\\infty$ as $t\\uparrow T$. By the Dambis-Dubins-Schwarz theorem, there exists a standard Brownian motion $B=(B_u)_{u\\ge 0}$ on an extension of the probability space such that\n$$\nM_t=B_{A_t}\\quad\\text{for all }t\\in[0,T).\n$$\nHence\n$$\nZ_t=\\exp\\!\\Big(B_{A_t}-\\frac{1}{2}A_t\\Big).\n$$\nLet $u:=A_t$. As $t\\uparrow T$ we have $u\\to\\infty$. Consider the process $X_u:=B_u-\\frac{1}{2}u$. By the strong law of large numbers for Brownian motion, $\\lim_{u\\to\\infty}\\frac{B_u}{u}=0$ almost surely. Consequently,\n$$\n\\lim_{u\\to\\infty}\\frac{X_u}{u}=\\lim_{u\\to\\infty}\\Big(\\frac{B_u}{u}-\\frac{1}{2}\\Big)=-\\frac{1}{2}\\quad\\text{almost surely,}\n$$\nwhich implies $X_u\\to -\\infty$ almost surely as $u\\to\\infty$. Therefore\n$$\n\\lim_{t\\uparrow T}Z_t=\\lim_{u\\to\\infty}\\exp(X_u)=0\\quad\\text{almost surely,}\n$$\nand thus $Z_T=0$ almost surely.\n\nStep 3: Failure of uniform integrability at $T$. From Step 1, $\\mathbb{E}_{\\mathbb{P}}[Z_{T_n}]=1$ for all $n\\in\\mathbb{N}$. From Step 2, $Z_T=0$ almost surely, so $\\mathbb{E}_{\\mathbb{P}}[Z_T]=0$. If the family $\\{Z_{T_n}\\}_{n\\in\\mathbb{N}}$ were uniformly integrable in $L^1(\\mathbb{P})$, then by a standard convergence theorem, the almost sure convergence $Z_{T_n} \\to Z_T$ would imply $\\lim_{n\\to\\infty}\\mathbb{E}_{\\mathbb{P}}[Z_{T_n}]=\\mathbb{E}_{\\mathbb{P}}[Z_T]$, which would force $1=0$, a contradiction. Therefore, the family $\\{Z_{T_n}\\}$ is not uniformly integrable in $L^1(\\mathbb{P})$ as $n\\to\\infty$.\n\nThe requested computed value is the almost sure limit $Z_T$, which equals $0$.", "answer": "$$\\boxed{0}$$", "id": "2992601"}]}