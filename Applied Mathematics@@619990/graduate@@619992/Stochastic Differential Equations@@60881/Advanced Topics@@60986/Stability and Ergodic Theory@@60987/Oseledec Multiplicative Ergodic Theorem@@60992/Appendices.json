{"hands_on_practices": [{"introduction": "To build intuition for Lyapunov exponents, we first turn to the familiar territory of deterministic linear systems. This exercise demonstrates how the general framework of Oseledec's theorem elegantly recovers a well-known result from linear algebra. By analyzing a cocycle generated by a constant, diagonalizable matrix [@problem_id:2989417], you will derive that the Lyapunov exponents are precisely the logarithms of the absolute values of the matrix's eigenvalues, reinforcing their role as generalized growth rates.", "problem": "Consider a deterministic linear cocycle generated by a constant matrix on a probability space with a trivial measure-preserving base. Let the matrix be\n$$\nA \\;=\\; \\begin{pmatrix}\n5 & 1 & 0 \\\\\n0 & -2 & 0 \\\\\n0 & 0 & \\tfrac{1}{3}\n\\end{pmatrix},\n$$\nand define the cocycle by $A(n) \\coloneqq A^{n}$ for all integers $n \\geq 1$. Assume the norm on $\\mathbb{R}^{3}$ is the Euclidean norm. The matrix $A$ is upper triangular with distinct diagonal entries, and hence is diagonalizable over $\\mathbb{R}$. The diagonal entries of $A$ are the eigenvalues.\n\nUsing the definition of Lyapunov exponents from Oseledec's multiplicative ergodic theorem (MET), namely that for a nonzero vector $v \\in \\mathbb{R}^{3}$ the Lyapunov exponent along $v$ is given by\n$$\n\\lambda(v) \\;=\\; \\lim_{n \\to \\infty} \\frac{1}{n} \\,\\ln \\bigl\\| A^{n} v \\bigr\\|,\n$$\nderive the full Lyapunov spectrum of the cocycle generated by $A$, starting from the existence and definition of Lyapunov exponents guaranteed by MET and basic linear algebra facts about diagonalizable matrices. Provide the Lyapunov exponents in nonincreasing order as a single row matrix. Do not round your answer; leave it in exact closed form. No units are required.", "solution": "The problem is valid. It is a well-posed and scientifically grounded application of Oseledec's multiplicative ergodic theorem (MET) to a deterministic linear system. All necessary information is provided, and the problem is free of contradictions or ambiguities.\n\nThe problem asks for the Lyapunov spectrum of a deterministic linear cocycle on $\\mathbb{R}^{3}$ generated by the constant matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n5 & 1 & 0 \\\\\n0 & -2 & 0 \\\\\n0 & 0 & \\tfrac{1}{3}\n\\end{pmatrix}.\n$$\nThe cocycle map is $\\Phi(n, \\omega) = A^n$, where the base dynamics are trivial. The Lyapunov exponent for a nonzero vector $v \\in \\mathbb{R}^{3}$ is defined as\n$$\n\\lambda(v) \\;=\\; \\lim_{n \\to \\infty} \\frac{1}{n} \\,\\ln \\bigl\\| A^{n} v \\bigr\\|.\n$$\nOseledec's theorem guarantees that for any ergodic measure on the base space (here, a trivial one), this limit exists for almost every starting point, and the set of possible values for $\\lambda(v)$ forms a discrete spectrum of at most $3$ distinct values, the Lyapunov exponents. For a deterministic system $x_{k+1} = Ax_k$, the Lyapunov exponents are given by the natural logarithms of the absolute values of the eigenvalues of $A$. We will derive this result from the given definition of $\\lambda(v)$.\n\nFirst, we find the eigenvalues and eigenvectors of the matrix $A$. Since $A$ is an upper triangular matrix, its eigenvalues are its diagonal entries:\n$$ \\lambda_1 = 5, \\quad \\lambda_2 = -2, \\quad \\lambda_3 = \\frac{1}{3}. $$\nThe problem states that $A$ is diagonalizable. Let the corresponding eigenvectors be $v_1, v_2, v_3$. These eigenvectors form a basis for $\\mathbb{R}^{3}$. Any nonzero vector $v \\in \\mathbb{R}^{3}$ can be expressed as a unique linear combination of these eigenvectors:\n$$ v = c_1 v_1 + c_2 v_2 + c_3 v_3, $$\nwhere $c_1, c_2, c_3$ are real coefficients, not all zero.\n\nApplying the matrix $A^n$ to the vector $v$, and using the property that $A^n v_i = \\lambda_i^n v_i$, we get:\n$$ A^n v = A^n(c_1 v_1 + c_2 v_2 + c_3 v_3) = c_1 A^n v_1 + c_2 A^n v_2 + c_3 A^n v_3 = c_1 \\lambda_1^n v_1 + c_2 \\lambda_2^n v_2 + c_3 \\lambda_3^n v_3. $$\nSubstituting the eigenvalues:\n$$ A^n v = c_1 (5)^n v_1 + c_2 (-2)^n v_2 + c_3 \\left(\\frac{1}{3}\\right)^n v_3. $$\nTo find the Lyapunov exponent, we must analyze the norm $\\|A^n v\\|$ as $n \\to \\infty$. The behavior is determined by the eigenvalue with the largest magnitude. The magnitudes are $|\\lambda_1|=5$, $|\\lambda_2|=2$, and $|\\lambda_3|=\\frac{1}{3}$. We have the ordering $|\\lambda_1| > |\\lambda_2| > |\\lambda_3|$.\n\nAccording to Oseledec's theorem, there exists a filtration of subspaces $E_3 \\subset E_2 \\subset E_1 = \\mathbb{R}^3$ such that the Lyapunov exponent is constant for all vectors within a given layer of the filtration.\nLet's analyze the generic case first, which corresponds to the largest exponent.\n\nCase 1: The vector $v$ has a non-zero component along the eigenvector $v_1$ (i.e., $c_1 \\neq 0$).\nWe factor out the term with the largest growth rate, $(5)^n$:\n$$ A^n v = 5^n \\left( c_1 v_1 + c_2 \\left(\\frac{-2}{5}\\right)^n v_2 + c_3 \\left(\\frac{1/3}{5}\\right)^n v_3 \\right) = 5^n \\left( c_1 v_1 + c_2 \\left(-\\frac{2}{5}\\right)^n v_2 + c_3 \\left(\\frac{1}{15}\\right)^n v_3 \\right). $$\nAs $n \\to \\infty$, the terms $\\left(-\\frac{2}{5}\\right)^n$ and $\\left(\\frac{1}{15}\\right)^n$ both approach $0$. Therefore, the vector inside the parenthesis approaches $c_1 v_1$.\nTaking the norm:\n$$ \\|A^n v\\| = |5^n| \\left\\| c_1 v_1 + c_2 \\left(-\\frac{2}{5}\\right)^n v_2 + c_3 \\left(\\frac{1}{15}\\right)^n v_3 \\right\\| = 5^n \\left\\| \\dots \\right\\|. $$\nThe Lyapunov exponent is:\n$$ \\lambda(v) = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\left( 5^n \\left\\| c_1 v_1 + \\dots \\right\\| \\right) = \\lim_{n \\to \\infty} \\frac{1}{n} \\left( n \\ln 5 + \\ln \\left\\| c_1 v_1 + \\dots \\right\\| \\right) $$\n$$ = \\ln 5 + \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\left\\| c_1 v_1 + \\dots \\right\\|. $$\nSince $\\lim_{n\\to\\infty} \\left\\| c_1 v_1 + \\dots \\right\\| = \\|c_1 v_1\\| = |c_1|\\|v_1\\|$, which is a non-zero constant, the second term vanishes.\n$$ \\lambda(v) = \\ln 5. $$\nThis is the largest Lyapunov exponent, $\\chi_1 = \\ln 5$. It applies to any vector not in the subspace spanned by $\\{v_2, v_3\\}$.\n\nCase 2: The vector $v$ is in the subspace spanned by $\\{v_2, v_3\\}$, so $c_1 = 0$, but has a non-zero component along $v_2$ (i.e., $c_2 \\neq 0$).\nThen $v = c_2 v_2 + c_3 v_3$, and\n$$ A^n v = c_2 (-2)^n v_2 + c_3 \\left(\\frac{1}{3}\\right)^n v_3. $$\nThe dominant eigenvalue magnitude is now $|-2|=2$. Factoring out $(-2)^n$:\n$$ A^n v = (-2)^n \\left(c_2 v_2 + c_3 \\left(\\frac{1/3}{-2}\\right)^n v_3 \\right) = (-2)^n \\left(c_2 v_2 + c_3 \\left(-\\frac{1}{6}\\right)^n v_3 \\right). $$\nFollowing the same logic as before:\n$$ \\|A^n v\\| = |(-2)^n| \\left\\| c_2 v_2 + \\dots \\right\\| = 2^n \\left\\| c_2 v_2 + \\dots \\right\\|. $$\n$$ \\lambda(v) = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln (2^n \\| \\dots \\|) = \\ln 2. $$\nThis is the second Lyapunov exponent, $\\chi_2 = \\ln 2$.\n\nCase 3: The vector $v$ is in the subspace spanned by $v_3$, so $c_1=c_2=0$ and $c_3 \\neq 0$.\nThen $v=c_3 v_3$, and\n$$ A^n v = c_3 \\left(\\frac{1}{3}\\right)^n v_3. $$\n$$ \\|A^n v\\| = \\left| c_3 \\left(\\frac{1}{3}\\right)^n \\right| \\|v_3\\| = |c_3| \\left(\\frac{1}{3}\\right)^n \\|v_3\\|. $$\n$$ \\lambda(v) = \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\left( |c_3| \\left(\\frac{1}{3}\\right)^n \\|v_3\\| \\right) = \\ln\\left(\\frac{1}{3}\\right) = -\\ln 3. $$\nThis is the third Lyapunov exponent, $\\chi_3 = -\\ln 3$.\n\nThe full Lyapunov spectrum is the set of these exponents: $\\{\\ln 5, \\ln 2, -\\ln 3\\}$. We are asked to provide them in nonincreasing order. Since $5 > 2 > 1 > 1/3$, we have $\\ln 5 > \\ln 2 > 0 > \\ln(1/3) = -\\ln 3$. Thus, the ordered exponents are $\\chi_1 = \\ln 5$, $\\chi_2 = \\ln 2$, and $\\chi_3 = -\\ln 3$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\ln 5 & \\ln 2 & -\\ln 3\n\\end{pmatrix}\n}\n$$", "id": "2989417"}, {"introduction": "Having explored the deterministic case, we now introduce randomness in its simplest form: a scalar (one-dimensional) cocycle. This fundamental exercise [@problem_id:2989412] provides a first-hand look at the core mechanism of the multiplicative ergodic theorem, where the Law of Large Numbers connects the long-term growth rate to an expected value. You will compute the Lyapunov exponent through direct integration and, just as importantly, verify the theorem's essential integrability condition, highlighting the rigorous foundation upon which these results are built.", "problem": "Consider a discrete-time scalar random linear cocycle generated by independent and identically distributed multipliers $\\{A_{n}\\}_{n \\geq 1}$ acting on $\\mathbb{R}$ via the recurrence $x_{n} = A_{n} x_{n-1}$, with $x_{0} \\neq 0$. Assume that the multipliers are given by $A_{n} = a Z_{n}$, where $a > 0$ is a fixed constant and $\\{Z_{n}\\}_{n \\geq 1}$ are independent and identically distributed standard normal random variables $Z_{n} \\sim \\mathcal{N}(0,1)$. Define the top Lyapunov exponent in dimension $d=1$ by the almost sure limit (when it exists)\n$$\n\\lambda \\equiv \\lim_{n \\to \\infty} \\frac{1}{n} \\ln \\left| A_{n} A_{n-1} \\cdots A_{1} \\right|.\n$$\nStarting from the definition of $\\lambda$ and classical limit theorems in probability, derive the expression for the almost sure growth rate and compute the value of\n$$\n\\lambda = \\mathbb{E}\\!\\left[ \\ln |A_{1}| \\right]\n$$\nin closed form, in terms of $a$ and fundamental constants. Additionally, verify the integrability condition required by Oseledecâ€™s multiplicative ergodic theorem, namely\n$$\n\\mathbb{E}\\!\\left[ \\ln^{+} |A_{1}| \\right] < \\infty,\n$$\nwhere $\\ln^{+}(x) \\equiv \\max\\{\\ln(x), 0\\}$ for $x > 0$, by providing a rigorous bound that demonstrates finiteness based on well-tested inequalities and properties of the standard normal distribution. Your final answer must be a single closed-form analytic expression for $\\lambda$; do not round your answer.", "solution": "The problem requires us to analyze the top Lyapunov exponent for a scalar discrete-time random linear cocycle. The derivation and calculation will proceed in three stages: first, justifying the expression for the Lyapunov exponent $\\lambda$ as an expectation; second, verifying the integrability condition required by the governing ergodic theorem; and third, computing the explicit value of $\\lambda$.\n\nThe top Lyapunov exponent for the sequence $x_{n} = A_{n}A_{n-1} \\cdots A_{1} x_0$ is defined by the almost sure limit:\n$$\n\\lambda \\equiv \\lim_{n \\to \\infty} \\frac{1}{n} \\ln |A_{n} A_{n-1} \\cdots A_{1}|.\n$$\nSince the multipliers $A_i$ are scalars, we can use the property of absolute values and logarithms to rewrite the term inside the limit. The logarithm of the product becomes a sum of logarithms:\n$$\n\\frac{1}{n} \\ln |A_{n} A_{n-1} \\cdots A_{1}| = \\frac{1}{n} \\ln \\left(\\prod_{i=1}^{n} |A_i|\\right) = \\frac{1}{n} \\sum_{i=1}^{n} \\ln|A_i|.\n$$\nThe problem states that the multipliers $\\{A_n\\}_{n \\ge 1}$ are independent and identically distributed (i.i.d.). Consequently, the random variables $Y_i \\equiv \\ln|A_i|$ are also i.i.d. The expression for $\\lambda$ is thus the limit of the sample mean of the sequence $\\{Y_i\\}_{i \\ge 1}$. By Kolmogorov's Strong Law of Large Numbers, if the expectation $\\mathbb{E}[Y_1]$ exists and is finite (i.e., $\\mathbb{E}[|Y_1|] < \\infty$), this limit converges almost surely to the expectation:\n$$\n\\lambda = \\lim_{n \\to \\infty} \\frac{1}{n} \\sum_{i=1}^{n} Y_i = \\mathbb{E}[Y_1] \\quad \\text{a.s.}\n$$\nThis establishes the formula provided in the question, $\\lambda = \\mathbb{E}[\\ln|A_1|]$. This result is a special case of Oseledec's multiplicative ergodic theorem for i.i.d. scalar systems. The theorem's applicability is contingent upon an integrability condition, which we now verify.\n\nThe integrability condition required by Oseledec's theorem is $\\mathbb{E}[\\ln^{+}\\|A_1\\|] < \\infty$. For the scalar case on $\\mathbb{R}$, the norm $\\|A_1\\|$ is simply $|A_1|$. We must verify that $\\mathbb{E}[\\ln^{+}|A_1|] < \\infty$, where $\\ln^{+}(x) \\equiv \\max\\{\\ln(x), 0\\}$. We are given $A_1 = a Z_1$, where $a > 0$ and $Z_1$ is a standard normal random variable, $Z_1 \\sim \\mathcal{N}(0,1)$, with probability density function (PDF) $p(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$. The expectation is\n$$\n\\mathbb{E}[\\ln^{+}|A_1|] = \\int_{-\\infty}^{\\infty} \\max\\{\\ln|az|, 0\\} p(z) dz.\n$$\nThe condition $\\ln|az| > 0$ is equivalent to $|az| > 1$, or $|z| > 1/a$. The integral is non-zero only over this region:\n$$\n\\mathbb{E}[\\ln^{+}|A_1|] = \\int_{|z| > 1/a} \\ln|az| \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz.\n$$\nThe integrand is an even function of $z$, so we can simplify the integral:\n$$\n\\mathbb{E}[\\ln^{+}|A_1|] = 2 \\int_{1/a}^{\\infty} \\ln(az) \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz = \\sqrt{\\frac{2}{\\pi}} \\int_{1/a}^{\\infty} (\\ln a + \\ln z) \\exp\\left(-\\frac{z^2}{2}\\right) dz.\n$$\nTo demonstrate finiteness, we can bound the integrand. For $z>0$, the inequality $\\ln z < z$ holds. Therefore, for the domain of integration $z \\ge 1/a > 0$:\n$$\n\\int_{1/a}^{\\infty} \\ln(z) \\exp\\left(-\\frac{z^2}{2}\\right) dz < \\int_{1/a}^{\\infty} z \\exp\\left(-\\frac{z^2}{2}\\right) dz.\n$$\nThe bounding integral on the right can be computed exactly:\n$$\n\\int_{1/a}^{\\infty} z \\exp\\left(-\\frac{z^2}{2}\\right) dz = \\left[-\\exp\\left(-\\frac{z^2}{2}\\right)\\right]_{1/a}^{\\infty} = 0 - \\left(-\\exp\\left(-\\frac{1}{2a^2}\\right)\\right) = \\exp\\left(-\\frac{1}{2a^2}\\right).\n$$\nSince this value is finite, the integral involving $\\ln z$ is also finite. The other term, involving $\\ln a$, is a constant multiplied by a Gaussian tail probability, which is also finite. Thus, the sum of these terms is finite, and we conclude that $\\mathbb{E}[\\ln^{+}|A_1|] < \\infty$, satisfying the condition.\n\nFinally, we compute the explicit value of $\\lambda$. From the established formula:\n$$\n\\lambda = \\mathbb{E}[\\ln|A_1|] = \\mathbb{E}[\\ln|aZ_1|] = \\mathbb{E}[\\ln a + \\ln|Z_1|].\n$$\nBy the linearity of expectation, since $a$ is a positive constant:\n$$\n\\lambda = \\ln a + \\mathbb{E}[\\ln|Z_1|].\n$$\nThe remaining task is to calculate $ \\mathbb{E}[\\ln|Z_1|] $:\n$$\n\\mathbb{E}[\\ln|Z_1|] = \\int_{-\\infty}^{\\infty} \\ln|z| \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz = 2 \\int_{0}^{\\infty} \\ln(z) \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) dz.\n$$\nWe perform a change of variables with $u = z^2/2$. This gives $z = \\sqrt{2u}$ and $dz = (1/\\sqrt{2u})du$. The integration limits remain $0$ to $\\infty$. The logarithm term becomes $\\ln(z) = \\ln(\\sqrt{2u}) = \\frac{1}{2}(\\ln 2 + \\ln u)$.\n$$\n\\mathbb{E}[\\ln|Z_1|] = \\sqrt{\\frac{2}{\\pi}} \\int_{0}^{\\infty} \\frac{1}{2}(\\ln 2 + \\ln u) \\exp(-u) \\frac{1}{\\sqrt{2u}} du = \\frac{1}{2\\sqrt{\\pi}} \\int_{0}^{\\infty} (\\ln 2 + \\ln u) u^{-1/2} \\exp(-u) du.\n$$\nWe separate the integral into two parts:\n$$\n\\mathbb{E}[\\ln|Z_1|] = \\frac{1}{2\\sqrt{\\pi}} \\left( \\ln 2 \\int_{0}^{\\infty} u^{-1/2} \\exp(-u) du + \\int_{0}^{\\infty} u^{-1/2} \\ln(u) \\exp(-u) du \\right).\n$$\nThe first integral is the Gamma function $\\Gamma(s) = \\int_0^\\infty t^{s-1} e^{-t} dt$ evaluated at $s=1/2$:\n$$\n\\int_{0}^{\\infty} u^{(1/2)-1} \\exp(-u) du = \\Gamma\\left(\\frac{1}{2}\\right) = \\sqrt{\\pi}.\n$$\nThe second integral corresponds to the derivative of the Gamma function, $\\Gamma'(s) = \\int_0^\\infty t^{s-1}\\ln(t)e^{-t}dt$, evaluated at $s=1/2$:\n$$\n\\int_{0}^{\\infty} u^{(1/2)-1} \\ln(u) \\exp(-u) du = \\Gamma'\\left(\\frac{1}{2}\\right).\n$$\nThe derivative $\\Gamma'(s)$ is related to the Digamma function $\\psi(s) = \\Gamma'(s)/\\Gamma(s)$. Thus, $\\Gamma'(1/2) = \\Gamma(1/2)\\psi(1/2) = \\sqrt{\\pi}\\psi(1/2)$. A standard value of the Digamma function is $\\psi(1/2) = -\\gamma - 2\\ln 2$, where $\\gamma$ is the Euler-Mascheroni constant.\nSubstituting these results back:\n$$\n\\mathbb{E}[\\ln|Z_1|] = \\frac{1}{2\\sqrt{\\pi}} \\left( (\\ln 2)(\\sqrt{\\pi}) + \\sqrt{\\pi}\\psi\\left(\\frac{1}{2}\\right) \\right) = \\frac{1}{2} \\left( \\ln 2 + \\psi\\left(\\frac{1}{2}\\right) \\right).\n$$\n$$\n\\mathbb{E}[\\ln|Z_1|] = \\frac{1}{2} (\\ln 2 - \\gamma - 2\\ln 2) = \\frac{1}{2}(-\\gamma - \\ln 2) = -\\frac{1}{2}(\\gamma + \\ln 2).\n$$\nThe final expression for the Lyapunov exponent $\\lambda$ is:\n$$\n\\lambda = \\ln a + \\mathbb{E}[\\ln|Z_1|] = \\ln a - \\frac{1}{2}(\\gamma + \\ln 2).\n$$\nThis can be written as:\n$$\n\\lambda = \\ln a - \\frac{1}{2}\\gamma - \\frac{1}{2}\\ln 2.\n$$\nThis is the closed-form analytic expression for the almost sure growth rate $\\lambda$.", "answer": "$$\n\\boxed{\\ln(a) - \\frac{1}{2}\\gamma - \\frac{1}{2}\\ln(2)}\n$$", "id": "2989412"}, {"introduction": "While analytical calculations are invaluable for building understanding, most real-world systems are too complex for such methods. This hands-on programming exercise [@problem_id:2989411] guides you through implementing a standard and robust numerical algorithm for estimating Lyapunov exponents from stochastic differential equation (SDE) trajectories. By repeatedly applying the system's linearized dynamics to an orthonormal basis and using QR decomposition to track its growth and rotation, you will learn how to compute the entire Lyapunov spectrum for systems of any dimension, turning abstract theory into a practical tool for a scientific inquiry.", "problem": "Consider a random dynamical system generated by a stochastic differential equation (SDE) in the ItÃ´ sense on $\\mathbb{R}^d$ of the form\n$$\ndX_t = A X_t \\, dt + \\sum_{k=1}^m B_k X_t \\, dW_t^{(k)},\n$$\nwhere $A \\in \\mathbb{R}^{d \\times d}$ is a constant drift matrix, $B_k \\in \\mathbb{R}^{d \\times d}$ are constant diffusion matrices, and $W_t^{(k)}$ are independent standard Wiener processes. Under the integrability assumptions of Oseledec's multiplicative ergodic theorem, the derivative cocycle $D\\varphi_{t,\\omega}$ associated with the flow $\\varphi_{t,\\omega}$ admits Lyapunov exponents defined as the almost sure limits of the long-time growth rates of singular values of $D\\varphi_{t,\\omega}$.\n\nStarting from core definitions and the fundamental ItÃ´ calculus framework, derive and implement a numerical procedure to estimate the Lyapunov exponents by:\n- Approximating the discrete-time Jacobian increment of the derivative cocycle over a small time step $\\Delta t$ by\n$$\nM_n = I_d + A \\, \\Delta t + \\sum_{k=1}^m B_k \\, \\Delta W_n^{(k)}, \\quad \\Delta W_n^{(k)} \\sim \\mathcal{N}(0, \\Delta t),\n$$\nwhich is the Eulerâ€“Maruyama approximation for the linear tangent SDE.\n- Propagating an orthonormal basis $Q_n \\in \\mathbb{R}^{d \\times d}$ via $Y_n = M_n Q_n$ and performing a reorthonormalization at each step using the Gramâ€“Schmidt method via a $QR$ decomposition $Y_n = Q_{n+1} R_n$, accumulating $\\log |(R_n)_{ii}|$ along each direction. The estimate of the Lyapunov exponents after $N$ steps (total horizon $T = N \\Delta t$) is given by\n$$\n\\hat{\\lambda}_i \\approx \\frac{1}{T} \\sum_{n=0}^{N-1} \\log |(R_n)_{ii}|, \\quad i = 1, \\dots, d.\n$$\nAlternatively, one may use singular value decomposition ($SVD$) reorthonormalization $Y_n = U_n \\Sigma_n V_n^\\top$ and accumulate $\\log(\\Sigma_{n,ii})$ with $Q_{n+1} = U_n$.\n\nYour program must:\n- Implement the above procedure using the $QR$-based reorthonormalization (you may optionally implement the $SVD$ variant, but the required output must be produced using the $QR$ method).\n- Use a fixed random seed per test case for reproducibility.\n- For each test case, simulate the product $M_{N-1} \\cdots M_0$ via iterative propagation and reorthonormalization, and report the estimated Lyapunov exponents.\n\nDesign a test suite with the following parameter sets, each ensuring scientific realism and covering a range of behaviors:\n1. One-dimensional geometric Brownian motion (happy path):\n   - Dimension $d = 1$,\n   - Drift $A = [0.2]$,\n   - Diffusions $B_1 = [0.3]$ (so $m = 1$),\n   - Time step $\\Delta t = 10^{-3}$,\n   - Total time $T = 50$,\n   - Random seed $123$.\n   The output for this case is a single float representing the top Lyapunov exponent estimate.\n\n2. Two-dimensional diagonal linear SDE with two independent noise channels (mixed exponents):\n   - Dimension $d = 2$,\n   - Drift $A = \\mathrm{diag}(0.1,-0.05)$,\n   - Diffusions $B_1 = \\mathrm{diag}(0.4,0.1)$, $B_2 = \\mathrm{diag}(0.0,0.3)$,\n   - Time step $\\Delta t = 10^{-3}$,\n   - Total time $T = 50$,\n   - Random seed $1234$.\n   The output for this case is a list of two floats $[\\hat{\\lambda}_1,\\hat{\\lambda}_2]$ corresponding to the estimated Lyapunov exponents.\n\n3. Two-dimensional deterministic system with no drift and no noise (boundary case of neutral dynamics):\n   - Dimension $d = 2$,\n   - Drift $A = \\mathrm{diag}(0.0, 0.0)$,\n   - No diffusion matrices (so $m = 0$),\n   - Time step $\\Delta t = 10^{-3}$,\n   - Total time $T = 10$,\n   - Random seed $42$ (unused but included for uniformity).\n   The output for this case is a list of two floats $[\\hat{\\lambda}_1,\\hat{\\lambda}_2]$.\n\nFinal output requirements:\n- Express all numerical answers as decimal numbers rounded to three decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases listed above. The formatting must have no spaces anywhere. For example, if the three results were $0.123$, $[0.456,-0.789]$, and $[0.000,0.000]$, the program should print:\n[0.123,[0.456,-0.789],[0.000,0.000]]\nNo physical units are involved in this problem, so none should be printed.", "solution": "The user has submitted a problem for solution. The first step is to perform a rigorous validation of the problem statement.\n\n### Step 1: Extract Givens\n\nThe problem statement provides the following information:\n- A linear stochastic differential equation (SDE) in ItÃ´ form on $\\mathbb{R}^d$:\n$$\ndX_t = A X_t \\, dt + \\sum_{k=1}^m B_k X_t \\, dW_t^{(k)}\n$$\nwhere $A, B_k \\in \\mathbb{R}^{d \\times d}$ are constant matrices and $W_t^{(k)}$ are independent standard Wiener processes.\n- A numerical procedure to estimate the Lyapunov exponents:\n  1. Approximate the discrete-time Jacobian increment using the Eulerâ€“Maruyama scheme:\n     $$\n     M_n = I_d + A \\, \\Delta t + \\sum_{k=1}^m B_k \\, \\Delta W_n^{(k)}, \\quad \\Delta W_n^{(k)} \\sim \\mathcal{N}(0, \\Delta t)\n     $$\n  2. Propagate an orthonormal basis $Q_n \\in \\mathbb{R}^{d \\times d}$ via $Y_n = M_n Q_n$.\n  3. Reorthonormalize using QR decomposition: $Y_n = Q_{n+1} R_n$.\n  4. Estimate the Lyapunov exponents after $N$ steps (total time $T = N \\Delta t$):\n     $$\n     \\hat{\\lambda}_i \\approx \\frac{1}{T} \\sum_{n=0}^{N-1} \\log |(R_n)_{ii}|, \\quad i = 1, \\dots, d\n     $$\n- A set of three test cases with specific parameters:\n  - **Case 1**: $d = 1$, $A = [0.2]$, $B_1 = [0.3]$, $m=1$, $\\Delta t = 10^{-3}$, $T = 50$, Random seed $= 123$.\n  - **Case 2**: $d = 2$, $A = \\mathrm{diag}(0.1,-0.05)$, $B_1 = \\mathrm{diag}(0.4,0.1)$, $B_2 = \\mathrm{diag}(0.0,0.3)$, $\\Delta t = 10^{-3}$, $T = 50$, Random seed $= 1234$.\n  - **Case 3**: $d = 2$, $A = \\mathrm{diag}(0.0, 0.0)$, $m=0$, $\\Delta t = 10^{-3}$, $T = 10$, Random seed $= 42$.\n- Output formatting requirements: Numerical answers rounded to three decimal places, presented in a single-line, comma-separated list enclosed in brackets, with no spaces. Example format: `[0.123,[0.456,-0.789],[0.000,0.000]]`.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is subjected to the validation criteria:\n\n- **Scientifically Grounded**: The problem is firmly rooted in the theory of random dynamical systems and stochastic analysis. Oseledec's multiplicative ergodic theorem is a cornerstone of this field, and the described numerical method (Euler-Maruyama discretization of the tangent flow combined with QR reorthonormalization) is a standard, well-established algorithm for computing Lyapunov exponents of SDEs. The mathematical setup is correct and standard.\n- **Well-Posed**: The problem is entirely self-contained. For each test case, all necessary parameters ($A, B_k, d, \\Delta t, T$) and conditions (random seed) are unambiguously provided. The objectiveâ€”to implement a specific algorithm and report its output for given inputsâ€”is clear. A unique, stable, and meaningful numerical solution is expected for each case given the fixed random seed.\n- **Objective**: The problem is stated in precise, formal mathematical and computational language, free from any subjective or biased phrasing.\n\nThe problem does not exhibit any flaws:\n1.  **Scientific/Factual Unsoundness**: No violations of mathematical logic or scientific principles are present.\n2.  **Non-Formalizable/Irrelevant**: The problem is a formal request to implement a specific algorithm directly related to the topic of Oseledec's theorem and SDEs.\n3.  **Incomplete/Contradictory Setup**: All required information is provided and is internally consistent.\n4.  **Unrealistic/Infeasible**: The parameters are chosen for numerical demonstration and are perfectly feasible.\n5.  **Ill-Posed/Poorly Structured**: The problem is well-structured and leads to a unique solution.\n6.  **Trivial/Tautological**: The problem requires a non-trivial implementation of a numerical algorithm and an understanding of the underlying theory. Case 3 is a boundary case that serves as a valuable sanity check, not a triviality that undermines the problem's integrity.\n7.  **Outside Scientific Verifiability**: The results are numerically verifiable by re-running the specified algorithm with the given seeds.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A complete, reasoned solution will be provided.\n\n### Solution\n\nThe stated problem requires the implementation of a numerical algorithm to estimate the Lyapunov exponents of a linear stochastic differential equation (SDE). This solution first details the theoretical principles and then describes the algorithmic implementation.\n\n**Theoretical Framework**\n\nThe dynamics of the system are described by the linear ItÃ´ SDE:\n$$\ndX_t = A X_t \\, dt + \\sum_{k=1}^m B_k X_t \\, dW_t^{(k)}\n$$\nwhere $X_t \\in \\mathbb{R}^d$ is the state vector. Since the equation is linear, its solution can be expressed by a linear flow map, or fundamental matrix solution, $\\varphi_{t,\\omega}: \\mathbb{R}^d \\to \\mathbb{R}^d$, such that $X_t(\\omega) = \\varphi_{t,\\omega}(X_0)$. This flow $\\varphi_{t,\\omega}$ itself satisfies the SDE in matrix form.\n\nOseledec's multiplicative ergodic theorem concerns the long-term asymptotic behavior of this flow. It guarantees the existence of a set of deterministic numbers $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_d$, called Lyapunov exponents, and a filtration of subspaces $V_1 \\supset V_2 \\supset \\dots \\supset V_d \\supset \\{0\\}$, such that for any initial vector $v \\in V_i \\setminus V_{i+1}$, the exponential growth rate of its transported norm is almost surely given by $\\lambda_i$:\n$$\n\\lim_{t \\to \\infty} \\frac{1}{t} \\log \\|\\varphi_{t,\\omega}(v)\\| = \\lambda_i\n$$\nThe Lyapunov exponents quantify the average exponential rates of expansion and contraction in the state space. The top exponent, $\\lambda_1$, determines the overall stability of the system: if $\\lambda_1 < 0$, the system is almost surely stable.\n\nDirectly computing the flow matrix $\\varphi_T$ over a long time horizon $T$ by multiplying discrete-time approximations $M_{N-1} \\cdots M_1 M_0$ is numerically intractable. The columns of the resulting matrix product tend to align with the direction corresponding to the largest Lyapunov exponent, leading to ill-conditioning and the loss of information about the smaller exponents.\n\n**Numerical Algorithm: QR Reorthonormalization**\n\nThe prescribed QR-based method circumvents this numerical instability. It tracks the evolution of a full $d$-dimensional volume element, represented by an orthonormal basis of vectors, and continuously reorthonormalizes the basis to prevent its collapse.\n\nThe algorithm proceeds as follows:\n1.  **Initialization**: Begin with an orthonormal basis for $\\mathbb{R}^d$, typically represented by the columns of the identity matrix $Q_0 = I_d$. Initialize an accumulator for the logarithmic growth rates, $\\Lambda = (0, \\dots, 0) \\in \\mathbb{R}^d$.\n2.  **Iteration**: For each time step $n = 0, 1, \\dots, N-1$:\n    a.  **Construct the Jacobian Increment**: Generate $m$ independent random variates $\\Delta W_n^{(k)}$ from a normal distribution $\\mathcal{N}(0, \\Delta t)$. Construct the discrete-time propagator matrix $M_n$ based on the Euler-Maruyama approximation of the tangent SDE:\n        $$\n        M_n = I_d + A \\, \\Delta t + \\sum_{k=1}^m B_k \\, \\Delta W_n^{(k)}\n        $$\n    b.  **Propagate the Basis**: Apply the operator $M_n$ to the current orthonormal basis $Q_n$ to find the evolved basis:\n        $$\n        Y_n = M_n Q_n\n        $$\n        The columns of $Y_n$ are the images of the basis vectors after one time step; they are generally neither orthogonal nor of unit length.\n    c.  **Reorthonormalize**: Use the QR decomposition to factorize $Y_n$ into an orthogonal matrix $Q_{n+1}$ and an upper-triangular matrix $R_n$:\n        $$\n        Y_n = Q_{n+1} R_n\n        $$\n        $Q_{n+1}$ represents the new orthonormal basis for the next step. The matrix $R_n$ contains the information about the stretching and shearing of the basis vectors during this step.\n    d.  **Accumulate Growth Rates**: The diagonal elements of $R_n$, denoted $(R_n)_{ii}$, represent the component-wise scaling factors of the basis vectors at this step. The logarithms of their absolute values are the instantaneous growth rates. These are added to the accumulator:\n        $$\n        \\Lambda \\leftarrow \\Lambda + \\log(|\\text{diag}(R_n)|)\n        $$\n        The absolute value is essential because standard QR algorithms may produce negative diagonal entries in $R_n$ to satisfy canonical properties of the decomposition, whereas the theory of Lyapunov exponents is concerned with the magnitude of the growth.\n3.  **Final Estimation**: After $N$ steps, the total time elapsed is $T = N \\Delta t$. The average logarithmic growth rates give the estimates for the Lyapunov exponents:\n    $$\n    \\hat{\\lambda}_i = \\frac{1}{T} \\Lambda_i = \\frac{1}{N \\Delta t} \\sum_{n=0}^{N-1} \\log |(R_n)_{ii}|\n    $$\nThe algorithm naturally sorts the exponents such that $\\hat{\\lambda}_1 \\ge \\hat{\\lambda}_2 \\ge \\dots \\ge \\hat{\\lambda}_d$.\n\n**Implementation for Test Cases**\n\nThis general procedure is applied to the three specified test cases. \n- For the one-dimensional Case 1, the QR decomposition is trivial. A $1 \\times 1$ matrix $Y_n = [y]$ is decomposed into $Q_{n+1} = [\\text{sign}(y)]$ and $R_n = [|y|]$. This simplifies to accumulating $\\log|M_n|$. The theoretical exponent is $\\lambda = A_{00} - B_{1,00}^2/2 = 0.2 - 0.3^2/2 = 0.155$.\n- For the two-dimensional Case 2, the system matrices $A$ and $B_k$ are diagonal, meaning the two state components evolve independently. The theoretical exponents correspond to each component: $\\lambda_1 = A_{00} - B_{1,00}^2/2 = 0.1 - 0.4^2/2 = 0.02$ and $\\lambda_2 = A_{11} - (B_{1,11}^2 + B_{2,11}^2)/2 = -0.05 - (0.1^2 + 0.3^2)/2 = -0.1$. The numerical result should be close to $[0.02, -0.1]$.\n- For Case 3, with no drift ($A=0$) and no noise ($B_k=0$), the propagator is always the identity matrix, $M_n=I_d$. Consequently, $Y_n=Q_n$, and its QR decomposition is $Y_n=Q_n \\cdot I_d$. Thus, $R_n=I_d$, and $\\log|\\text{diag}(R_n)| = (0,0)$. The estimated exponents will be exactly zero, matching the trivial deterministic dynamics.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import qr\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for Lyapunov exponent estimation.\n    \"\"\"\n\n    def estimate_lyapunov_exponents(d, A, B_list, delta_t, T, seed):\n        \"\"\"\n        Estimates the Lyapunov exponents of a linear SDE using QR reorthonormalization.\n\n        Args:\n            d (int): Dimension of the system.\n            A (np.ndarray): The drift matrix (d x d).\n            B_list (list): A list of diffusion matrices (each d x d).\n            delta_t (float): Time step for the simulation.\n            T (float): Total simulation time.\n            seed (int): Seed for the random number generator for reproducibility.\n\n        Returns:\n            np.ndarray: An array of estimated Lyapunov exponents, sorted in descending order.\n        \"\"\"\n        # Set a specific random seed for this simulation run for reproducibility\n        rng = np.random.default_rng(seed)\n\n        N = int(T / delta_t)\n        m = len(B_list)\n\n        # Initialize an orthonormal basis Q_0 (the identity matrix)\n        Q = np.identity(d)\n        \n        # Accumulator for the sum of log of diagonal elements of R\n        log_r_diags_sum = np.zeros(d)\n\n        # Main simulation loop\n        for _ in range(N):\n            # Generate m Wiener process increments, dW ~ N(0, dt)\n            delta_W = rng.normal(0.0, np.sqrt(delta_t), m)\n\n            # Construct the discrete-time propagator matrix M_n\n            # M_n = I + A*dt + sum(B_k * dW_k)\n            M = np.identity(d) + A * delta_t\n            if m > 0:\n                # Sum over all diffusion terms\n                M += np.sum([B_k * dW_k for B_k, dW_k in zip(B_list, delta_W)], axis=0)\n\n            # Propagate the orthonormal basis: Y_n = M_n * Q_n\n            Y = M @ Q\n\n            # Perform QR decomposition for reorthonormalization: Y_n = Q_{n+1} * R_n\n            # It's important to use a version of QR that handles potential rank deficiencies,\n            # though not expected here. Scipy's is robust.\n            Q, R = qr(Y, mode='economic')\n\n            # Accumulate the logarithm of the absolute values of the diagonal elements of R.\n            # The absolute value is crucial as the theory concerns growth rates (magnitudes),\n            # and some QR implementations may yield negative diagonal entries in R.\n            log_r_diags_sum += np.log(np.abs(np.diag(R)))\n\n        # Calculate the Lyapunov exponents by averaging over the total time T\n        lyapunov_exponents = log_r_diags_sum / T\n        \n        return lyapunov_exponents\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: 1D geometric Brownian motion\n        {\n            \"d\": 1,\n            \"A\": np.array([[0.2]]),\n            \"B\": [np.array([[0.3]])],\n            \"delta_t\": 1e-3,\n            \"T\": 50,\n            \"seed\": 123\n        },\n        # Case 2: 2D diagonal SDE\n        {\n            \"d\": 2,\n            \"A\": np.diag([0.1, -0.05]),\n            \"B\": [np.diag([0.4, 0.1]), np.diag([0.0, 0.3])],\n            \"delta_t\": 1e-3,\n            \"T\": 50,\n            \"seed\": 1234\n        },\n        # Case 3: 2D deterministic system (zero dynamics)\n        {\n            \"d\": 2,\n            \"A\": np.diag([0.0, 0.0]),\n            \"B\": [],  # m = 0\n            \"delta_t\": 1e-3,\n            \"T\": 10,\n            \"seed\": 42\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Calculate the result for one case.\n        exponents = estimate_lyapunov_exponents(\n            case[\"d\"], case[\"A\"], case[\"B\"], case[\"delta_t\"], case[\"T\"], case[\"seed\"]\n        )\n        results.append(exponents)\n\n    def format_result(res_array):\n        \"\"\"Formats the result array into the required string representation.\"\"\"\n        if res_array.size == 1:\n            # Single float for d=1 case\n            return f\"{res_array.item():.3f}\"\n        else:\n            # List of floats for d>1 cases\n            formatted_list = [f\"{x:.3f}\" for x in res_array]\n            return f\"[{','.join(formatted_list)}]\"\n\n    # Generate the final output string with no spaces as required.\n    formatted_results = [format_result(res) for res in results]\n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "2989411"}]}