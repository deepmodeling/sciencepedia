{"hands_on_practices": [{"introduction": "This exercise provides a foundational experience in proving the existence of an invariant measure. We will employ the powerful technique of Lyapunov functions to establish a drift condition for the Ornstein-Uhlenbeck process, one of the most fundamental SDEs. This practice [@problem_id:2974640] demonstrates how a carefully chosen function can reveal the long-term stability of a system, guaranteeing that the process does not escape to infinity and eventually settles into a statistical equilibrium.", "problem": "Consider the $d$-dimensional Ornstein–Uhlenbeck (OU) process defined by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t=-A X_t\\,\\mathrm{d}t+\\sigma\\,\\mathrm{d}W_t,\n$$\nwhere $A\\in\\mathbb{R}^{d\\times d}$, the symmetric part $S=\\frac{1}{2}(A+A^{\\top})$ satisfies $S\\succeq m I$ for some $m>0$, $\\sigma\\in\\mathbb{R}^{d\\times d}$ is a constant matrix that is invertible, and $W_t$ is a standard $d$-dimensional Brownian motion. Let $V:\\mathbb{R}^d\\to\\mathbb{R}$ be given by $V(x)=1+\\|x\\|^2$. Starting only from the fundamental definitions of the infinitesimal generator of a diffusion and the Lyapunov drift criterion for tightness and existence of an invariant measure, do the following:\n\n1. Compute the action of the generator $\\mathcal{L}$ of the OU process on the function $V$, expressing $\\mathcal{L}V(x)$ in terms of $A$, $\\sigma$, and $x$.\n2. Use the coercivity condition on the symmetric part $S$ to derive a drift inequality of the form\n$$\n\\mathcal{L}V(x)\\leq -\\alpha\\,V(x)+\\beta,\n$$\nvalid for all $x\\in\\mathbb{R}^d$, for explicit constants $\\alpha>0$ and $\\beta\\geq 0$ depending only on $m$ and $\\operatorname{tr}(\\sigma\\sigma^{\\top})$.\n3. Explain why this drift inequality ensures tightness of the family of empirical measures and existence of at least one invariant probability measure, and why the nondegeneracy of $\\sigma$ together with the linear structure of the OU dynamics yields uniqueness of the invariant measure.\n\nYour final answer must be the explicit pair of constants $(\\alpha,\\beta)$ as a single analytical expression. No rounding is required, and do not include any units. Express your final answer as a row matrix.", "solution": "The problem is well-posed and scientifically sound, representing a standard application of Lyapunov function techniques to establish the ergodic properties of a linear stochastic differential equation. We proceed with the solution.\n\nThe Ornstein-Uhlenbeck (OU) process is described by the $d$-dimensional stochastic differential equation (SDE):\n$$\n\\mathrm{d}X_t = b(X_t)\\,\\mathrm{d}t + \\Sigma(X_t)\\,\\mathrm{d}W_t\n$$\nwhere the drift vector is $b(x) = -A x$ and the diffusion matrix is the constant matrix $\\Sigma(x) = \\sigma$.\n\n**1. Computation of the generator's action on $V(x)$**\n\nThe fundamental definition of the infinitesimal generator $\\mathcal{L}$ of a diffusion process, acting on a twice continuously differentiable function $f: \\mathbb{R}^d \\to \\mathbb{R}$, is given by:\n$$\n\\mathcal{L}f(x) = \\sum_{i=1}^{d} b_i(x) \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i,j=1}^{d} \\left(\\Sigma(x)\\Sigma(x)^{\\top}\\right)_{ij} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x)\n$$\nIn more compact notation, this is $\\mathcal{L}f(x) = \\langle b(x), \\nabla f(x) \\rangle + \\frac{1}{2} \\operatorname{tr}\\left(\\Sigma(x)\\Sigma(x)^{\\top} H_f(x)\\right)$, where $\\nabla f$ is the gradient and $H_f$ is the Hessian matrix of $f$.\n\nThe given Lyapunov function is $V(x) = 1 + \\|x\\|^2 = 1 + \\sum_{k=1}^{d} x_k^2$. We compute its first and second partial derivatives:\n- The gradient vector $\\nabla V(x)$ has components $\\frac{\\partial V}{\\partial x_i} = 2x_i$, so $\\nabla V(x) = 2x$.\n- The Hessian matrix $H_V(x)$ has components $\\frac{\\partial^2 V}{\\partial x_i \\partial x_j} = 2\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. Thus, $H_V(x) = 2I$, where $I$ is the $d \\times d$ identity matrix.\n\nWe now substitute these into the definition of the generator $\\mathcal{L}$ with $b(x)=-Ax$ and $\\Sigma(x)=\\sigma$:\n$$\n\\mathcal{L}V(x) = \\langle -Ax, 2x \\rangle + \\frac{1}{2} \\operatorname{tr}\\left(\\sigma\\sigma^{\\top} (2I)\\right)\n$$\nThe first term is the inner product $-2\\langle Ax, x \\rangle$. The second term simplifies to $\\operatorname{tr}(\\sigma\\sigma^{\\top})$.\nTherefore, the action of the generator on $V(x)$ is:\n$$\n\\mathcal{L}V(x) = -2\\langle Ax, x \\rangle + \\operatorname{tr}(\\sigma\\sigma^{\\top})\n$$\n\n**2. Derivation of the drift inequality**\n\nThe next step is to use the given condition on the symmetric part of $A$, denoted $S = \\frac{1}{2}(A+A^{\\top})$. The quadratic form $\\langle Ax, x \\rangle$ can be related to $S$. Any square matrix can be written as the sum of a symmetric and a skew-symmetric matrix. For any vector $x \\in \\mathbb{R}^d$ and any skew-symmetric matrix $K$, the quadratic form $x^\\top Kx$ is zero. Since $A=S+\\frac{1}{2}(A-A^\\top)$ and $\\frac{1}{2}(A-A^\\top)$ is skew-symmetric, we have:\n$$\n\\langle Ax, x \\rangle = x^{\\top}Ax = x^{\\top}Sx = \\langle Sx, x \\rangle\n$$\nSubstituting this back into the expression for $\\mathcal{L}V(x)$, we get:\n$$\n\\mathcal{L}V(x) = -2\\langle Sx, x \\rangle + \\operatorname{tr}(\\sigma\\sigma^{\\top})\n$$\nThe problem states that $S \\succeq mI$ for some constant $m>0$. This is a positive definiteness condition, which implies that for any $x \\in \\mathbb{R}^d$:\n$$\n\\langle Sx, x \\rangle \\ge m \\|x\\|^2\n$$\nMultiplying by $-2$ reverses the inequality:\n$$\n-2\\langle Sx, x \\rangle \\le -2m \\|x\\|^2\n$$\nWe can now bound $\\mathcal{L}V(x)$ from above:\n$$\n\\mathcal{L}V(x) \\le -2m \\|x\\|^2 + \\operatorname{tr}(\\sigma\\sigma^{\\top})\n$$\nTo obtain the desired drift inequality involving $V(x)$, we use the definition $V(x) = 1 + \\|x\\|^2$, which implies $\\|x\\|^2 = V(x) - 1$. Substituting this into our inequality yields:\n$$\n\\mathcal{L}V(x) \\le -2m(V(x) - 1) + \\operatorname{tr}(\\sigma\\sigma^{\\top})\n$$\n$$\n\\mathcal{L}V(x) \\le -2m V(x) + 2m + \\operatorname{tr}(\\sigma\\sigma^{\\top})\n$$\nThis inequality is of the form $\\mathcal{L}V(x) \\le -\\alpha V(x) + \\beta$. By comparing the terms, we identify the constants $\\alpha$ and $\\beta$:\n- $\\alpha = 2m$\n- $\\beta = 2m + \\operatorname{tr}(\\sigma\\sigma^{\\top})$\nSince $m>0$, it is clear that $\\alpha>0$. As the trace of a positive semi-definite matrix $\\sigma\\sigma^\\top$ is non-negative, we also have $\\beta \\ge 0$. These constants depend only on $m$ and $\\operatorname{tr}(\\sigma\\sigma^{\\top})$ as required.\n\n**3. Implications for the invariant measure**\n\nThe inequality $\\mathcal{L}V(x) \\le -\\alpha V(x) + \\beta$ is a fundamental Lyapunov drift condition in the theory of Markov processes. Here, $V(x) = 1+\\|x\\|^2$ is a proper function, i.e., $V(x) \\to \\infty$ as $\\|x\\| \\to \\infty$.\n\n**Existence:** The drift condition implies that whenever $V(x)$ is large, its expected rate of change is negative, pulling the process back towards the region where $V(x)$ is small. Specifically, for any $x$ such that $V(x) > \\beta/\\alpha$, we have $\\mathcal{L}V(x) < 0$. This ensures the process is positive Harris recurrent and stochastically stable. A key result, often associated with Meyn and Tweedie or derived from Foster-Lyapunov theorems for diffusions, states that such a drift condition on a proper function implies that the family of time-averaged transition probabilities, $\\mu_T(x, \\cdot) = \\frac{1}{T}\\int_0^T P_t(x, \\cdot)\\,\\mathrm{d}t$, is tight for any starting point $x$. By the Krylov-Bogoliubov theorem, tightness of this family guarantees the existence of at least one weak*-limit point as $T \\to \\infty$. Any such limit point is an invariant probability measure for the process. Thus, the existence of at least one invariant measure is established.\n\n**Uniqueness:** The uniqueness of the invariant measure follows from a different property of the SDE: the non-degeneracy of the diffusion term. The problem states that the matrix $\\sigma$ is invertible. This implies that the diffusion covariance matrix $Q = \\sigma\\sigma^{\\top}$ is symmetric and positive definite. The generator $\\mathcal{L}$ is a second-order partial differential operator whose principal part is determined by $Q$. Since $Q$ is positive definite everywhere in $\\mathbb{R}^d$, the operator $\\mathcal{L}$ is elliptic. For SDEs with smooth coefficients (here, the drift is linear and the diffusion is constant), coercivity of the diffusion matrix is a sufficient condition (stronger than what is needed by Hörmander's theorem) for the transition semigroup $(P_t)_{t>0}$ to be strong Feller. That is, for any $t>0$, $P_t$ maps bounded measurable functions to continuous functions. Furthermore, a non-degenerate diffusion on $\\mathbb{R}^d$ implies that the process is irreducible: from any starting point $x$, the process can reach any open set with positive probability in finite time. A well-known theorem in Markov process theory states that a strong Feller and irreducible process admits at most one invariant probability measure.\n\nCombining the existence from the Lyapunov drift condition and the uniqueness from the non-degenerate diffusion, we conclude that the OU process under the given conditions possesses a unique invariant probability measure.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2m & 2m + \\operatorname{tr}(\\sigma\\sigma^{\\top})\n\\end{pmatrix}\n}\n$$", "id": "2974640"}, {"introduction": "Having established the existence of an invariant measure, we now turn to its explicit verification. This problem [@problem_id:2974612] asks you to directly compute the action of the Fokker-Planck operator on the known Gaussian stationary density of the Ornstein-Uhlenbeck process. By showing that the result is zero, you will confirm that this density indeed represents a stationary state, providing a concrete link between the abstract theory of generators and the explicit solutions of the governing equations.", "problem": "Consider the $d$-dimensional Ornstein–Uhlenbeck (OU) diffusion defined by the stochastic differential equation $dX_{t}=-B X_{t}\\,dt+\\Sigma\\,dW_{t}$, where $W_{t}$ is a standard $d$-dimensional Brownian motion, $B\\in\\mathbb{R}^{d\\times d}$ has eigenvalues with strictly positive real parts, and $a=\\Sigma\\Sigma^{\\top}\\in\\mathbb{R}^{d\\times d}$ is symmetric positive definite. Let $P\\in\\mathbb{R}^{d\\times d}$ be the unique symmetric positive definite solution to the continuous-time Lyapunov equation $B P+P B^{\\top}=a$. Define the Gaussian density $\\rho:\\mathbb{R}^{d}\\to(0,\\infty)$ by\n$$\n\\rho(x)=\\frac{1}{(2\\pi)^{d/2}(\\det P)^{1/2}}\\exp\\!\\left(-\\frac{1}{2}x^{\\top}P^{-1}x\\right).\n$$\nLet $L^{*}$ denote the Fokker–Planck (also called forward Kolmogorov) operator associated with the diffusion, namely $L^{*}g=-\\nabla\\cdot(b\\,g)+\\frac{1}{2}\\nabla\\cdot(a\\,\\nabla g)$ with drift $b(x)=-B x$ and diffusion matrix $a$. By direct computation of derivatives and using only the Lyapunov identity $B P+P B^{\\top}=a$, compute the expression $L^{*}\\rho(x)$ as a function of $x$, simplify it fully, and report the final simplified expression. Your final answer must be a single real number or a single closed-form analytic expression (with no units). If you obtain a constant, report that constant.", "solution": "The problem asks for the computation and simplification of the expression $L^{*}\\rho(x)$, where $L^{*}$ is the Fokker–Planck operator and $\\rho(x)$ is a given Gaussian density. The operator is defined as $L^{*}g=-\\nabla\\cdot(b\\,g)+\\frac{1}{2}\\nabla\\cdot(a\\,\\nabla g)$, with drift $b(x)=-B x$ and diffusion matrix $a=\\Sigma\\Sigma^\\top$. The density $\\rho(x)$ is given by\n$$\n\\rho(x)=\\frac{1}{(2\\pi)^{d/2}(\\det P)^{1/2}}\\exp\\!\\left(-\\frac{1}{2}x^{\\top}P^{-1}x\\right)\n$$\nwhere $P$ is the symmetric positive definite solution to the Lyapunov equation $B P+P B^{\\top}=a$. For brevity, let $C = \\frac{1}{(2\\pi)^{d/2}(\\det P)^{1/2}}$.\n\nWe must compute $L^{*}\\rho(x) = -\\nabla\\cdot(-Bx\\rho(x)) + \\frac{1}{2}\\nabla\\cdot(a\\nabla\\rho(x))$. We will compute each of the two terms separately.\n\nFirst, we compute the gradient of $\\rho(x)$. Let $f(x) = -\\frac{1}{2}x^{\\top}P^{-1}x$. Then $\\rho(x) = C \\exp(f(x))$. The gradient is given by the chain rule: $\\nabla\\rho(x) = C \\exp(f(x)) \\nabla f(x) = \\rho(x)\\nabla f(x)$.\nTo find $\\nabla f(x)$, we use the standard matrix calculus identity for the gradient of a quadratic form $\\nabla(x^{\\top}A x) = (A+A^{\\top})x$. Since $P$ is symmetric, its inverse $P^{-1}$ is also symmetric. Thus, $\\nabla(x^{\\top}P^{-1}x) = (P^{-1}+(P^{-1})^{\\top})x = 2P^{-1}x$.\nThe gradient of $f(x)$ is therefore:\n$$\n\\nabla f(x) = \\nabla\\left(-\\frac{1}{2}x^{\\top}P^{-1}x\\right) = -\\frac{1}{2}(2P^{-1}x) = -P^{-1}x\n$$\nThis gives the gradient of the density $\\rho(x)$:\n$$\n\\nabla\\rho(x) = -\\rho(x)P^{-1}x\n$$\n\nNow we compute the two terms of the Fokker-Planck operator.\n\nThe first term is $-\\nabla\\cdot(b(x)\\rho(x))$:\nSince $b(x)=-Bx$, this term is $-\\nabla\\cdot(-Bx\\rho(x)) = \\nabla\\cdot(Bx\\rho(x))$.\nWe use the product rule for divergence: $\\nabla\\cdot(\\mathbf{F}\\phi) = (\\nabla\\cdot\\mathbf{F})\\phi + \\mathbf{F}\\cdot(\\nabla\\phi)$. Let $\\mathbf{F} = Bx$ and $\\phi=\\rho(x)$.\nThe divergence of the linear map $x \\mapsto Bx$ is the trace of the matrix $B$, i.e., $\\nabla\\cdot(Bx) = \\operatorname{tr}(B)$.\nThe second part of the product rule is $\\mathbf{F}\\cdot(\\nabla\\phi) = (Bx)\\cdot(\\nabla\\rho(x))$. This dot product is equivalent to the matrix product $(Bx)^{\\top}\\nabla\\rho(x)$.\nUsing our expression for $\\nabla\\rho(x)$:\n$$\n(Bx)^{\\top}\\nabla\\rho(x) = (x^{\\top}B^{\\top})(-\\rho(x)P^{-1}x) = -\\rho(x) x^{\\top}B^{\\top}P^{-1}x\n$$\nCombining these, the first term becomes:\n$$\n-\\nabla\\cdot(b(x)\\rho(x)) = \\nabla\\cdot(Bx\\rho(x)) = (\\operatorname{tr}(B))\\rho(x) - \\rho(x) x^{\\top}B^{\\top}P^{-1}x = \\rho(x)[\\operatorname{tr}(B) - x^{\\top}B^{\\top}P^{-1}x]\n$$\n\nThe second term is $\\frac{1}{2}\\nabla\\cdot(a\\nabla\\rho(x))$:\nSubstitute $\\nabla\\rho(x) = -\\rho(x)P^{-1}x$:\n$$\n\\frac{1}{2}\\nabla\\cdot(a\\nabla\\rho(x)) = \\frac{1}{2}\\nabla\\cdot(a(-\\rho(x)P^{-1}x)) = -\\frac{1}{2}\\nabla\\cdot(\\rho(x)aP^{-1}x)\n$$\nWe again use the product rule for divergence, this time with $\\mathbf{F} = aP^{-1}x$ and $\\phi=\\rho(x)$.\nThe divergence of the linear map $x \\mapsto (aP^{-1})x$ is $\\nabla\\cdot(aP^{-1}x) = \\operatorname{tr}(aP^{-1})$.\nThe second part of the product rule is $(\\nabla\\phi)\\cdot\\mathbf{F} = (\\nabla\\rho(x))\\cdot(aP^{-1}x) = (\\nabla\\rho(x))^{\\top}(aP^{-1}x)$.\nUsing our expression for $\\nabla\\rho(x)$:\n$$\n(\\nabla\\rho(x))^{\\top}(aP^{-1}x) = (-\\rho(x)P^{-1}x)^{\\top}(aP^{-1}x) = -\\rho(x)x^{\\top}(P^{-1})^{\\top}aP^{-1}x\n$$\nSince $P^{-1}$ is symmetric, $(P^{-1})^{\\top} = P^{-1}$. So the expression is $-\\rho(x)x^{\\top}P^{-1}aP^{-1}x$.\nCombining these parts for the second term:\n$$\n\\frac{1}{2}\\nabla\\cdot(a\\nabla\\rho(x)) = -\\frac{1}{2}\\left[\\rho(x)\\operatorname{tr}(aP^{-1}) - \\rho(x)x^{\\top}P^{-1}aP^{-1}x\\right] = \\rho(x)\\left[-\\frac{1}{2}\\operatorname{tr}(aP^{-1}) + \\frac{1}{2}x^{\\top}P^{-1}aP^{-1}x\\right]\n$$\n\nNow we sum the two terms to find $L^{*}\\rho(x)$:\n$$\nL^{*}\\rho(x) = \\rho(x)\\left[\\operatorname{tr}(B) - x^{\\top}B^{\\top}P^{-1}x\\right] + \\rho(x)\\left[-\\frac{1}{2}\\operatorname{tr}(aP^{-1}) + \\frac{1}{2}x^{\\top}P^{-1}aP^{-1}x\\right]\n$$\nFactoring out $\\rho(x)$, we have:\n$$\nL^{*}\\rho(x) = \\rho(x)\\left[ \\left(\\operatorname{tr}(B) - \\frac{1}{2}\\operatorname{tr}(aP^{-1})\\right) + \\left(-x^{\\top}B^{\\top}P^{-1}x + \\frac{1}{2}x^{\\top}P^{-1}aP^{-1}x\\right) \\right]\n$$\nTo simplify this expression, we use the given Lyapunov identity: $a = BP + PB^{\\top}$.\n\nLet's simplify the scalar part first (the terms without $x$):\n$$\n\\operatorname{tr}(B) - \\frac{1}{2}\\operatorname{tr}(aP^{-1}) = \\operatorname{tr}(B) - \\frac{1}{2}\\operatorname{tr}((BP+PB^{\\top})P^{-1})\n$$\nUsing the linearity of the trace operator:\n$$\n= \\operatorname{tr}(B) - \\frac{1}{2}\\operatorname{tr}(BPP^{-1} + PB^{\\top}P^{-1}) = \\operatorname{tr}(B) - \\frac{1}{2}(\\operatorname{tr}(B) + \\operatorname{tr}(PB^{\\top}P^{-1}))\n$$\nUsing the cyclic property of the trace, $\\operatorname{tr}(XYZ) = \\operatorname{tr}(ZXY)$, we have $\\operatorname{tr}(PB^{\\top}P^{-1}) = \\operatorname{tr}(P^{-1}PB^{\\top}) = \\operatorname{tr}(B^{\\top})$. Since $\\operatorname{tr}(B^{\\top}) = \\operatorname{tr}(B)$, the expression becomes:\n$$\n= \\operatorname{tr}(B) - \\frac{1}{2}(\\operatorname{tr}(B) + \\operatorname{tr}(B)) = \\operatorname{tr}(B) - \\frac{1}{2}(2\\operatorname{tr}(B)) = \\operatorname{tr}(B) - \\operatorname{tr}(B) = 0\n$$\nThe scalar part of the expression in the brackets is zero.\n\nNext, we simplify the quadratic form part:\n$$\n-x^{\\top}B^{\\top}P^{-1}x + \\frac{1}{2}x^{\\top}P^{-1}aP^{-1}x = x^{\\top}\\left[-B^{\\top}P^{-1} + \\frac{1}{2}P^{-1}aP^{-1}\\right]x\n$$\nLet's analyze the matrix inside the brackets, $M = -B^{\\top}P^{-1} + \\frac{1}{2}P^{-1}aP^{-1}$. Substitute $a = BP+PB^{\\top}$:\n$$\nM = -B^{\\top}P^{-1} + \\frac{1}{2}P^{-1}(BP+PB^{\\top})P^{-1} = -B^{\\top}P^{-1} + \\frac{1}{2}(P^{-1}BPP^{-1} + P^{-1}PB^{\\top}P^{-1})\n$$\n$$\nM = -B^{\\top}P^{-1} + \\frac{1}{2}(P^{-1}B + B^{\\top}P^{-1}) = \\frac{1}{2}P^{-1}B - \\frac{1}{2}B^{\\top}P^{-1}\n$$\nNow, we check if this matrix is skew-symmetric. Its transpose is:\n$$\nM^{\\top} = \\left(\\frac{1}{2}P^{-1}B - \\frac{1}{2}B^{\\top}P^{-1}\\right)^{\\top} = \\frac{1}{2}(P^{-1}B)^{\\top} - \\frac{1}{2}(B^{\\top}P^{-1})^{\\top} = \\frac{1}{2}B^{\\top}(P^{-1})^{\\top} - \\frac{1}{2}(P^{-1})^{\\top}(B^{\\top})^{\\top}\n$$\nSince $P^{-1}$ is symmetric, $(P^{-1})^{\\top}=P^{-1}$. Also, $(B^{\\top})^{\\top}=B$.\n$$\nM^{\\top} = \\frac{1}{2}B^{\\top}P^{-1} - \\frac{1}{2}P^{-1}B = -\\left(\\frac{1}{2}P^{-1}B - \\frac{1}{2}B^{\\top}P^{-1}\\right) = -M\n$$\nThe matrix $M$ is skew-symmetric. For any skew-symmetric matrix $M$, the quadratic form $x^{\\top}Mx$ is always zero for any vector $x$. This is because $x^{\\top}Mx$ is a scalar, so it is equal to its transpose: $x^{\\top}Mx = (x^{\\top}Mx)^{\\top} = x^{\\top}M^{\\top}x = x^{\\top}(-M)x = -x^{\\top}Mx$. This equality implies $2x^{\\top}Mx=0$, and thus $x^{\\top}Mx=0$.\nTherefore, the entire quadratic form part is zero.\n\nBoth the scalar part and the quadratic form part of the expression inside the main brackets are zero. So, the expression for $L^{*}\\rho(x)$ simplifies to:\n$$\nL^{*}\\rho(x) = \\rho(x)[0 + 0] = 0\n$$\nThe final simplified expression is the constant $0$.", "answer": "$$\\boxed{0}$$", "id": "2974612"}, {"introduction": "We now advance to a more complex and physically relevant system: the kinetic Langevin equation, a model for a particle's motion under friction, potential forces, and random noise. A key feature of this system [@problem_id:2974613] is that the noise is degenerate—it only directly affects the velocity. This exercise will guide you through verifying Hörmander's condition using Lie brackets to establish the hypoellipticity required for uniqueness, and then deriving the famous Gibbs-Boltzmann distribution as the invariant measure.", "problem": "Consider the one-dimensional kinetic Langevin Stochastic Differential Equation (SDE), a system of coupled SDEs for position and velocity, given by\n$$\n\\begin{cases}\ndX_t = V_t\\,dt, \\\\\ndV_t = -\\gamma V_t\\,dt - U'(X_t)\\,dt + \\sigma\\,dW_t,\n\\end{cases}\n$$\nwhere $X_t \\in \\mathbb{R}$ is the position, $V_t \\in \\mathbb{R}$ is the velocity, $\\gamma > 0$ is a friction coefficient, $\\sigma > 0$ is a noise amplitude, $W_t$ is a standard one-dimensional Brownian motion, and $U:\\mathbb{R}\\to\\mathbb{R}$ is a twice continuously differentiable confining potential. Let the potential be quadratic, $U(x) = \\frac{k}{2}x^2$ with $k>0$.\n\nStarting from core definitions and well-tested facts, your tasks are:\n- Identify the drift and diffusion vector fields associated with the above SDE and compute their Lie brackets. Use these computations to verify Hörmander’s bracket condition at each point in $\\mathbb{R}^2$, thereby establishing hypoellipticity and the smoothing of marginal distributions.\n- Explain why the smoothing property and a suitable Lyapunov function together imply existence and uniqueness of an invariant probability measure for this kinetic system.\n- Using the stationary Fokker–Planck equation (forward Kolmogorov equation) and the fluctuation–dissipation relation that ensures detailed balance, derive the invariant density of the form\n$$\np^{\\star}(x,v) = Z^{-1}\\exp\\!\\left(-\\frac{H(x,v)}{T}\\right),\n$$\nwhere $H(x,v)$ is the Hamiltonian and $T>0$ is an effective temperature determined by $\\gamma$ and $\\sigma$. Then compute the exact analytic expression for the normalization constant $Z$ in terms of $\\gamma$, $\\sigma$, and $k$. Express the final answer as a closed-form analytic expression. Do not include any physical units. No rounding is required.", "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and complete. It is a standard problem in the theory of stochastic differential equations and statistical physics, and all provided data and conditions are consistent and sufficient for a unique solution. The problem is valid.\n\nThe system of stochastic differential equations (SDEs) for the state vector $Y_t = (X_t, V_t)^T$ can be written in the general Itô form $dY_t = F_0(Y_t)dt + F_1(Y_t)dW_t$. With $Y_t = (x,v)^T$, the drift vector field $F_0$ and the diffusion vector field $F_1$ are identified as:\n$$\nF_0(x,v) = \\begin{pmatrix} v \\\\ -\\gamma v - U'(x) \\end{pmatrix}, \\quad F_1(x,v) = \\begin{pmatrix} 0 \\\\ \\sigma \\end{pmatrix}\n$$\nGiven the potential $U(x) = \\frac{k}{2}x^2$, its derivative is $U'(x) = kx$. Thus, the drift vector field is:\n$$\nF_0(x,v) = \\begin{pmatrix} v \\\\ -kx - \\gamma v \\end{pmatrix}\n$$\n\n**Part 1: Hörmander's Bracket Condition**\n\nTo verify Hörmander's condition, we compute the Lie brackets of the vector fields. The Lie bracket of two vector fields $A$ and $B$ is defined as $[A, B](y) = (\\nabla B)(y) A(y) - (\\nabla A)(y) B(y)$, where $\\nabla A$ is the Jacobian matrix of the vector field $A$.\n\nFor our system, $F_1$ is a constant vector, so its Jacobian $\\nabla F_1$ is the zero matrix. The Jacobian of $F_0$ is:\n$$\n\\nabla F_0(x,v) = \\begin{pmatrix} \\frac{\\partial}{\\partial x}(v) & \\frac{\\partial}{\\partial v}(v) \\\\ \\frac{\\partial}{\\partial x}(-kx - \\gamma v) & \\frac{\\partial}{\\partial v}(-kx - \\gamma v) \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ -k & -\\gamma \\end{pmatrix}\n$$\nThe first-order Lie bracket is $[F_0, F_1]$:\n$$\n[F_0, F_1] = (\\nabla F_1) F_0 - (\\nabla F_0) F_1 = \\mathbf{0} \\cdot F_0 - \\begin{pmatrix} 0 & 1 \\\\ -k & -\\gamma \\end{pmatrix} \\begin{pmatrix} 0 \\\\ \\sigma \\end{pmatrix} = - \\begin{pmatrix} \\sigma \\\\ -\\gamma \\sigma \\end{pmatrix} = \\begin{pmatrix} -\\sigma \\\\ \\gamma \\sigma \\end{pmatrix}\n$$\nHörmander's condition requires that the set of vector fields generated by the Lie algebra, $\\{F_1, [F_0, F_1], [F_0, [F_0, F_1]], \\ldots\\}$, spans the tangent space $\\mathbb{R}^2$ at every point $(x,v)$. We only need to check the span of the first few vectors. Let's consider the set $\\{F_1, [F_0, F_1]\\}$:\n$$\nF_1 = \\begin{pmatrix} 0 \\\\ \\sigma \\end{pmatrix}, \\quad [F_0, F_1] = \\begin{pmatrix} -\\sigma \\\\ \\gamma \\sigma \\end{pmatrix}\n$$\nTo check if these two vectors span $\\mathbb{R}^2$, we can form a matrix with these vectors as columns and compute its determinant:\n$$\n\\det\\begin{pmatrix} 0 & -\\sigma \\\\ \\sigma & \\gamma \\sigma \\end{pmatrix} = (0)(\\gamma \\sigma) - (-\\sigma)(\\sigma) = \\sigma^2\n$$\nSince $\\sigma > 0$ is given, $\\sigma^2 > 0$. The determinant is non-zero, which implies that the vectors $F_1$ and $[F_0, F_1]$ are linearly independent for all $(x,v) \\in \\mathbb{R}^2$. Therefore, they form a basis for $\\mathbb{R}^2$, and Hörmander's bracket condition is satisfied at every point.\n\nThis result implies that the generator of the process, $\\mathcal{L} = v \\frac{\\partial}{\\partial x} + (-kx - \\gamma v) \\frac{\\partial}{\\partial v} + \\frac{\\sigma^2}{2} \\frac{\\partial^2}{\\partial v^2}$, is hypoelliptic. A key consequence of hypoellipticity is the smoothing property of the associated transition semigroup: for any initial condition, the probability density function $p(t,x,v)$ of the process at time $t>0$ is a smooth (infinitely differentiable) function.\n\n**Part 2: Existence and Uniqueness of an Invariant Measure**\n\nThe existence and uniqueness of an invariant probability measure for this process can be established by combining two key properties:\n1.  **Irreducibility and the Strong Feller Property:** The hypoellipticity established via Hörmander's condition implies that the transition semigroup is strong Feller and that the process is irreducible (any open set can be reached from any other open set). This ensures that if an invariant measure exists, it is unique and must have a smooth density with respect to the Lebesgue measure.\n2.  **Existence of a Lyapunov Function:** We need to show that the process is recurrent, meaning it tends to return to a central region of the state space. This is demonstrated by finding a Lyapunov function $W(x,v)$ such that $W(x,v) \\to \\infty$ as $|x|+|v| \\to \\infty$ and $\\mathcal{L}W(x,v) \\le -c W(x,v) + C$ for some positive constants $c, C$ outside a compact set. A standard choice for the Lyapunov function is the total energy (Hamiltonian): $H(x,v) = U(x) + \\frac{1}{2}v^2 = \\frac{k}{2}x^2 + \\frac{1}{2}v^2$. Let's compute $\\mathcal{L}H$:\n    $$\n    \\mathcal{L}H = v \\frac{\\partial H}{\\partial x} + (-kx - \\gamma v) \\frac{\\partial H}{\\partial v} + \\frac{\\sigma^2}{2} \\frac{\\partial^2 H}{\\partial v^2}\n    $$\n    $$\n    \\mathcal{L}H = v(kx) + (-kx - \\gamma v)(v) + \\frac{\\sigma^2}{2}(1) = kxv - kxv - \\gamma v^2 + \\frac{\\sigma^2}{2} = -\\gamma v^2 + \\frac{\\sigma^2}{2}\n    $$\n    This expression shows dissipation in velocity but not in position. The condition $\\mathcal{L}H \\le -c H + C$ is not satisfied for large $|x|$ and bounded $|v|$. A more sophisticated Lyapunov function, standard for kinetic Langevin equations, of the form $W(x,v) = H(x,v) + \\epsilon xv$ for a small $\\epsilon>0$, resolves this. This choice leads to a coercive drift towards the origin in both $x$ and $v$ for sufficiently small $\\epsilon$, satisfying the Lyapunov condition for existence of an invariant measure.\n\nThe combination of the strong Feller property (implying uniqueness) and the existence of a Lyapunov function (implying existence) is a classic result in the theory of Markov processes that guarantees the existence of a unique stationary distribution (invariant probability measure) to which the process converges from any initial condition.\n\n**Part 3: Invariant Density and Normalization Constant**\n\nThe invariant density $p^{\\star}(x,v)$ is the stationary solution to the Fokker-Planck equation, $\\mathcal{L}^* p = 0$. The drift is $F_0(x,v) = (v, -kx-\\gamma v)^T$, so the operator $\\mathcal{L}^*$ is:\n$$\n\\mathcal{L}^* p = -\\nabla \\cdot (F_0 p) + \\frac{1}{2} \\frac{\\partial^2}{\\partial v^2}(\\sigma^2 p) = -\\frac{\\partial}{\\partial x}(v p) - \\frac{\\partial}{\\partial v}((-kx - \\gamma v)p) + \\frac{\\sigma^2}{2} \\frac{\\partial^2 p}{\\partial v^2}\n$$\nExpanding the divergence terms gives:\n$$\n\\mathcal{L}^* p = -v\\frac{\\partial p}{\\partial x} + (kx + \\gamma v)\\frac{\\partial p}{\\partial v} + \\gamma p + \\frac{\\sigma^2}{2}\\frac{\\partial^2 p}{\\partial v^2}\n$$\nWe test the proposed Gibbs-Boltzmann form $p(x,v) = Z^{-1}\\exp(-\\beta H(x,v))$, where $\\beta=1/T$ and $H(x,v) = \\frac{k}{2}x^2 + \\frac{1}{2}v^2$. The required partial derivatives (omitting the constant $Z^{-1}$) are:\n$$\n\\frac{\\partial p}{\\partial x} = -k\\beta x p, \\quad \\frac{\\partial p}{\\partial v} = -\\beta v p, \\quad \\frac{\\partial^2 p}{\\partial v^2} = (-\\beta + \\beta^2 v^2)p\n$$\nSubstituting these into the expanded Fokker-Planck equation and setting it to zero:\n$$\n-v(-k\\beta x p) + (kx + \\gamma v)(-\\beta v p) + \\gamma p + \\frac{\\sigma^2}{2}(-\\beta + \\beta^2 v^2)p = 0\n$$\nDividing by $p$ (which is non-zero):\n$$\nk\\beta xv - k\\beta xv - \\gamma\\beta v^2 + \\gamma - \\frac{\\sigma^2\\beta}{2} + \\frac{\\sigma^2\\beta^2}{2}v^2 = 0\n$$\nThe terms $k\\beta xv$ and $-k\\beta xv$ cancel. We can group the remaining terms by powers of $v$:\n$$\n\\left(\\gamma - \\frac{\\sigma^2\\beta}{2}\\right) + v^2\\left(-\\gamma\\beta + \\frac{\\sigma^2\\beta^2}{2}\\right) = 0\n$$\nThis equation must hold for all values of $v$. This is only possible if the coefficients of the constant term and the $v^2$ term are both zero:\n1.  Constant term: $\\gamma - \\frac{\\sigma^2\\beta}{2} = 0$\n2.  $v^2$ coefficient: $-\\gamma\\beta + \\frac{\\sigma^2\\beta^2}{2} = 0$\n\nFrom equation (1), we solve for the inverse temperature $\\beta$:\n$$\n\\beta = \\frac{2\\gamma}{\\sigma^2}\n$$\nSince $\\gamma>0$ and $\\sigma>0$, we have $\\beta>0$. We verify this value in equation (2):\n$$\n-\\gamma\\left(\\frac{2\\gamma}{\\sigma^2}\\right) + \\frac{\\sigma^2}{2}\\left(\\frac{2\\gamma}{\\sigma^2}\\right)^2 = -\\frac{2\\gamma^2}{\\sigma^2} + \\frac{\\sigma^2}{2}\\left(\\frac{4\\gamma^2}{\\sigma^4}\\right) = -\\frac{2\\gamma^2}{\\sigma^2} + \\frac{2\\gamma^2}{\\sigma^2} = 0\n$$\nBoth conditions are satisfied. Thus, the Gibbs-Boltzmann distribution is the stationary solution with an effective temperature $T=1/\\beta = \\frac{\\sigma^2}{2\\gamma}$. The invariant density is:\n$$\np^{\\star}(x,v) = Z^{-1}\\exp\\left(-\\frac{2\\gamma}{\\sigma^2}\\left(\\frac{k}{2}x^2+\\frac{1}{2}v^2\\right)\\right) = Z^{-1}\\exp\\left(-\\frac{\\gamma k}{\\sigma^2}x^2 - \\frac{\\gamma}{\\sigma^2}v^2\\right)\n$$\nThe normalization constant $Z$ is found by integrating $Z p^{\\star}(x,v)$ over $\\mathbb{R}^2$:\n$$\nZ = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\gamma k}{\\sigma^2}x^2 - \\frac{\\gamma}{\\sigma^2}v^2\\right) dx\\,dv\n$$\nThis is a separable integral of two Gaussian functions:\n$$\nZ = \\left(\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\gamma k}{\\sigma^2}x^2\\right)dx\\right) \\left(\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\gamma}{\\sigma^2}v^2\\right)dv\\right)\n$$\nUsing the Gaussian integral formula $\\int_{-\\infty}^{\\infty}\\exp(-ax^2)dx = \\sqrt{\\frac{\\pi}{a}}$:\n- The integral over $x$ has $a_x = \\frac{\\gamma k}{\\sigma^2}$, yielding $\\sqrt{\\frac{\\pi \\sigma^2}{\\gamma k}}$.\n- The integral over $v$ has $a_v = \\frac{\\gamma}{\\sigma^2}$, yielding $\\sqrt{\\frac{\\pi \\sigma^2}{\\gamma}}$.\n\nMultiplying these results gives the normalization constant $Z$:\n$$\nZ = \\sqrt{\\frac{\\pi \\sigma^2}{\\gamma k}} \\cdot \\sqrt{\\frac{\\pi \\sigma^2}{\\gamma}} = \\sqrt{\\frac{\\pi^2 \\sigma^4}{\\gamma^2 k}} = \\frac{\\pi \\sigma^2}{\\gamma\\sqrt{k}}\n$$\nThis is the closed-form analytic expression for the normalization constant.", "answer": "$$ \\boxed{\\frac{\\pi \\sigma^2}{\\gamma \\sqrt{k}}} $$", "id": "2974613"}]}