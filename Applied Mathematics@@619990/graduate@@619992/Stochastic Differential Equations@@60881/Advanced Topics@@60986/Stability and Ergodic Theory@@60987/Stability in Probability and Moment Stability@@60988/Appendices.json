{"hands_on_practices": [{"introduction": "The Lyapunov method provides a powerful framework for analyzing the stability of stochastic systems without needing to find an explicit solution. This practice focuses on a core skill: applying the infinitesimal generator $\\mathcal{L}$ to a candidate function $V(x)$ to determine local stability. By analyzing a nonlinear SDE [@problem_id:2996128], you will see how the sign of $\\mathcal{L}V(x)$ in the vicinity of an equilibrium reveals whether the system is stable in the mean-square sense.", "problem": "Consider the one-dimensional stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t=-\\alpha X_t^{3}\\,\\mathrm{d}t+\\beta X_t^{2}\\,\\mathrm{d}W_t,\n$$\non $\\mathbb{R}$ with parameters $\\alpha0$ and $\\beta0$, where $W_t$ is a standard Brownian motion (Wiener process). Let the candidate Lyapunov function be $V(x)=|x|^{2}$. Using the infinitesimal generator associated with the SDE and the Lyapunov approach grounded in Itô calculus, compute $\\mathcal{L}V(x)$ and use its sign to assess local mean-square stability in a neighborhood of the equilibrium $x=0$. Report your final answer as the explicit closed-form expression for $\\mathcal{L}V(x)$ in terms of $x$, $\\alpha$, and $\\beta$.", "solution": "The problem is validated as scientifically sound, well-posed, objective, and self-contained. It is a standard exercise in applying Lyapunov stability theory to stochastic differential equations (SDEs).\n\nThe given one-dimensional SDE is of the form $\\mathrm{d}X_t = f(X_t) \\, \\mathrm{d}t + g(X_t) \\, \\mathrm{d}W_t$, where $W_t$ is a standard Wiener process. By comparing the given equation\n$$\n\\mathrm{d}X_t = -\\alpha X_t^3 \\, \\mathrm{d}t + \\beta X_t^2 \\, \\mathrm{d}W_t\n$$\nwith the general form, we identify the drift coefficient $f(x)$ and the diffusion coefficient $g(x)$ as:\n$$\nf(x) = -\\alpha x^3\n$$\n$$\ng(x) = \\beta x^2\n$$\nThe problem asks to use the candidate Lyapunov function $V(x) = |x|^2$. For $x \\in \\mathbb{R}$, this simplifies to $V(x) = x^2$. This function is twice continuously differentiable, i.e., $V(x) \\in C^2(\\mathbb{R})$, which is a necessary condition for applying Itô's lemma.\n\nThe infinitesimal generator of the SDE, denoted by $\\mathcal{L}$, when applied to a time-independent, twice-differentiable function $V(x)$, is defined by\n$$\n\\mathcal{L}V(x) = f(x) \\frac{\\mathrm{d}V(x)}{\\mathrm{d}x} + \\frac{1}{2} [g(x)]^2 \\frac{\\mathrm{d}^2V(x)}{\\mathrm{d}x^2}\n$$\nThis formula is a direct consequence of Itô's lemma applied to $V(X_t)$.\n\nFirst, we compute the necessary derivatives of the Lyapunov function $V(x) = x^2$:\nThe first derivative is:\n$$\n\\frac{\\mathrm{d}V}{\\mathrm{d}x} = \\frac{\\mathrm{d}}{\\mathrm{d}x}(x^2) = 2x\n$$\nThe second derivative is:\n$$\n\\frac{\\mathrm{d}^2V}{\\mathrm{d}x^2} = \\frac{\\mathrm{d}}{\\mathrm{d}x}(2x) = 2\n$$\nNext, we substitute the expressions for $f(x)$, $g(x)$, $\\frac{\\mathrm{d}V}{\\mathrm{d}x}$, and $\\frac{\\mathrm{d}^2V}{\\mathrm{d}x^2}$ into the formula for the infinitesimal generator $\\mathcal{L}V(x)$:\n$$\n\\mathcal{L}V(x) = (-\\alpha x^3)(2x) + \\frac{1}{2} (\\beta x^2)^2 (2)\n$$\nWe simplify the terms. The first term becomes:\n$$\n(-\\alpha x^3)(2x) = -2\\alpha x^4\n$$\nThe second term becomes:\n$$\n\\frac{1}{2} (\\beta x^2)^2 (2) = (\\beta^2 x^4)(1) = \\beta^2 x^4\n$$\nCombining these terms, we obtain the expression for $\\mathcal{L}V(x)$:\n$$\n\\mathcal{L}V(x) = -2\\alpha x^4 + \\beta^2 x^4\n$$\nFactoring out the common term $x^4$, we arrive at the final closed-form expression:\n$$\n\\mathcal{L}V(x) = (\\beta^2 - 2\\alpha)x^4\n$$\nTo assess local mean-square stability at the equilibrium point $x=0$, we examine the sign of $\\mathcal{L}V(x)$ in a neighborhood of $x=0$. The point $x=0$ is indeed an equilibrium because $f(0) = -\\alpha(0)^3 = 0$ and $g(0) = \\beta(0)^2 = 0$. The Lyapunov function $V(x) = x^2$ is positive definite, as $V(0) = 0$ and $V(x)  0$ for all $x \\neq 0$.\n\nAccording to the Lyapunov stability criterion for SDEs, the equilibrium $x=0$ is asymptotically stable in the mean-square sense if $\\mathcal{L}V(x)$ is negative definite, i.e., $\\mathcal{L}V(x)  0$ for all $x \\neq 0$ in a neighborhood of the origin.\nIn our expression $\\mathcal{L}V(x) = (\\beta^2 - 2\\alpha)x^4$, the term $x^4$ is strictly positive for any $x \\neq 0$. Therefore, the sign of $\\mathcal{L}V(x)$ is determined entirely by the sign of the constant factor $(\\beta^2 - 2\\alpha)$.\n\nFor the system to be locally mean-square stable, we require:\n$$\n\\beta^2 - 2\\alpha  0 \\implies \\beta^2  2\\alpha\n$$\nIf this condition holds, $\\mathcal{L}V(x)  0$ for all $x \\neq 0$, and the origin is asymptotically stable in the mean-square sense. Conversely, if $\\beta^2 - 2\\alpha  0$, then $\\mathcal{L}V(x)  0$ for $x \\neq 0$, indicating instability. If $\\beta^2 - 2\\alpha = 0$, then $\\mathcal{L}V(x) = 0$, and this Lyapunov function provides no conclusive information about stability.\n\nThe problem asks for the explicit closed-form expression for $\\mathcal{L}V(x)$, which we have computed.", "answer": "$$\n\\boxed{(\\beta^2 - 2\\alpha)x^4}\n$$", "id": "2996128"}, {"introduction": "In stochastic calculus, the notion of \"stability\" is multifaceted, and different definitions can lead to different conclusions. This exercise [@problem_id:2996127] presents a classic linear SDE that demonstrates a crucial distinction: a system can be stable in probability, with trajectories almost surely converging to zero, yet fail to be asymptotically stable in the mean-square sense. By deriving the exact solution and computing its second moment, you will gain firsthand insight into why these two fundamental types of stability are not equivalent.", "problem": "Consider the one-dimensional stochastic differential equation (SDE) $$\\mathrm{d}X_{t}=-X_{t}\\,\\mathrm{d}t+\\sqrt{2}\\,X_{t}\\,\\mathrm{d}W_{t},$$ where $W_{t}$ is a standard Brownian motion and $X_{0}=x_{0}\\in\\mathbb{R}$ is deterministic. Use the fundamental definitions of stability in probability and mean-square stability, and derive results from first principles using Itô calculus. Specifically:\n- Starting from Itô’s formula applied to suitable functions of $X_{t}$, obtain a closed-form expression for the second moment $$\\mathbb{E}\\big[|X_{t}|^{2}\\big]$$ for all $t\\geq 0$.\n- Using the exact solution representation obtained via Itô calculus for $\\ln|X_{t}|$, determine the asymptotic behavior of $X_{t}$ as $t\\to\\infty$ and justify whether the zero equilibrium is stable in probability.\n- Compare the moment behavior to the definition of mean-square stability and explain whether mean-square stability holds for this SDE.\n\nYour final answer must be the exact analytic expression for $$\\mathbb{E}\\big[|X_{t}|^{2}\\big]$$ in terms of $x_{0}$ and $t$. No rounding is required and no units are involved.", "solution": "The one-dimensional stochastic differential equation (SDE) under consideration is\n$$\\mathrm{d}X_{t}=-X_{t}\\,\\mathrm{d}t+\\sqrt{2}\\,X_{t}\\,\\mathrm{d}W_{t},$$\nwith a deterministic initial condition $X_{0}=x_{0}\\in\\mathbb{R}$. This is a linear SDE of the form $\\mathrm{d}X_t = b(X_t) \\mathrm{d}t + \\sigma(X_t) \\mathrm{d}W_t$, with drift coefficient $b(x) = -x$ and diffusion coefficient $\\sigma(x) = \\sqrt{2}x$. The zero solution, $X_t \\equiv 0$, is an equilibrium point of this SDE. We will analyze the stability of this equilibrium.\n\nFirst, we determine the second moment, $\\mathbb{E}[|X_{t}|^{2}]$, using Itô's formula. Let $f(x) = x^2$. The derivatives of this function are $f'(x) = 2x$ and $f''(x) = 2$. Itô's formula for a function $f(X_t)$ is given by\n$$\\mathrm{d}f(X_t) = \\left( b(X_t) f'(X_t) + \\frac{1}{2} \\sigma(X_t)^2 f''(X_t) \\right) \\mathrm{d}t + \\sigma(X_t) f'(X_t) \\mathrm{d}W_t.$$\nSubstituting the specific forms of $b(x)$, $\\sigma(x)$, and the derivatives of $f(x)$, we obtain the differential for $X_t^2$:\n$$\\mathrm{d}(X_t^2) = \\left( (-X_t)(2X_t) + \\frac{1}{2} (\\sqrt{2}X_t)^2 (2) \\right) \\mathrm{d}t + (\\sqrt{2}X_t)(2X_t) \\mathrm{d}W_t$$\n$$\\mathrm{d}(X_t^2) = \\left( -2X_t^2 + \\frac{1}{2} (2X_t^2) (2) \\right) \\mathrm{d}t + 2\\sqrt{2}X_t^2 \\mathrm{d}W_t$$\n$$\\mathrm{d}(X_t^2) = \\left( -2X_t^2 + 2X_t^2 \\right) \\mathrm{d}t + 2\\sqrt{2}X_t^2 \\mathrm{d}W_t$$\n$$\\mathrm{d}(X_t^2) = 0 \\cdot \\mathrm{d}t + 2\\sqrt{2}X_t^2 \\mathrm{d}W_t = 2\\sqrt{2}X_t^2 \\mathrm{d}W_t.$$\nTo find $X_t^2$, we integrate from $0$ to $t$:\n$$X_t^2 - X_0^2 = \\int_0^t 2\\sqrt{2}X_s^2 \\mathrm{d}W_s.$$\nNow, we take the expectation of both sides. The initial condition $X_0 = x_0$ is deterministic, so $\\mathbb{E}[X_0^2] = x_0^2$. The expectation of the Itô integral on the right-hand side is zero, as the integrand is a sufficiently regular process.\n$$\\mathbb{E}[X_t^2] - \\mathbb{E}[X_0^2] = \\mathbb{E}\\left[\\int_0^t 2\\sqrt{2}X_s^2 \\mathrm{d}W_s\\right]$$\n$$\\mathbb{E}[X_t^2] - x_0^2 = 0.$$\nThus, we arrive at the expression for the second moment:\n$$\\mathbb{E}[|X_{t}|^{2}] = \\mathbb{E}[X_t^2] = x_0^2.$$\n\nSecond, we determine the asymptotic behavior of $X_t$ and assess the stability in probability of the zero equilibrium. We apply Itô's formula to the function $g(x) = \\ln|x|$. For $x \\neq 0$, the derivatives are $g'(x) = 1/x$ and $g''(x) = -1/x^2$. The SDE for $Y_t = \\ln|X_t|$ is:\n$$\\mathrm{d}Y_t = \\left( b(X_t) g'(X_t) + \\frac{1}{2} \\sigma(X_t)^2 g''(X_t) \\right) \\mathrm{d}t + \\sigma(X_t) g'(X_t) \\mathrm{d}W_t$$\n$$\\mathrm{d}Y_t = \\left( (-X_t)\\left(\\frac{1}{X_t}\\right) + \\frac{1}{2} (\\sqrt{2}X_t)^2 \\left(-\\frac{1}{X_t^2}\\right) \\right) \\mathrm{d}t + (\\sqrt{2}X_t)\\left(\\frac{1}{X_t}\\right) \\mathrm{d}W_t$$\n$$\\mathrm{d}Y_t = \\left( -1 + \\frac{1}{2} (2X_t^2) \\left(-\\frac{1}{X_t^2}\\right) \\right) \\mathrm{d}t + \\sqrt{2} \\mathrm{d}W_t$$\n$$\\mathrm{d}Y_t = (-1 - 1) \\mathrm{d}t + \\sqrt{2} \\mathrm{d}W_t = -2 \\mathrm{d}t + \\sqrt{2} \\mathrm{d}W_t.$$\nIntegrating from $0$ to $t$ gives:\n$$Y_t - Y_0 = \\int_0^t (-2) \\mathrm{d}s + \\int_0^t \\sqrt{2} \\mathrm{d}W_s$$\n$$\\ln|X_t| - \\ln|x_0| = -2t + \\sqrt{2}W_t.$$\nThe explicit solution for $|X_t|$ is:\n$$|X_t| = |x_0| \\exp(-2t + \\sqrt{2}W_t).$$\nTo determine the asymptotic behavior as $t \\to \\infty$, we examine the exponent. By the Strong Law of Large Numbers for Brownian motion, $\\frac{W_t}{t} \\to 0$ almost surely as $t \\to \\infty$. Therefore, the term $-2t$ dominates the exponent:\n$$\\lim_{t\\to\\infty} (-2t + \\sqrt{2}W_t) = \\lim_{t\\to\\infty} t \\left(-2 + \\frac{\\sqrt{2}W_t}{t}\\right) = -\\infty \\quad \\text{almost surely}.$$\nThis implies that $\\lim_{t\\to\\infty} |X_t| = 0$ almost surely for any initial condition $x_0$. Almost sure convergence implies convergence in probability. This means that for any $\\epsilon  0$, $\\lim_{t\\to\\infty} \\mathbb{P}(|X_t|  \\epsilon) = 0$. This property is known as attractivity of the zero solution.\nFor stability in probability (in the sense of Lyapunov), we must show that for any $\\epsilon0, \\eta0$, there exists a $\\delta0$ such that $|x_0|\\delta$ implies $\\mathbb{P}(\\sup_{t\\geq 0} |X_t|  \\epsilon)  \\eta$.\nThe probability in question is\n$$\\mathbb{P}(\\sup_{t\\geq 0} |x_0|\\exp(-2t + \\sqrt{2}W_t)  \\epsilon) = \\mathbb{P}(\\sup_{t\\geq 0} (-2t + \\sqrt{2}W_t)  \\ln(\\epsilon/|x_0|)).$$\nLet $Z_t = -2t + \\sqrt{2}W_t$. This is a Brownian motion with drift. For a process $B_t = \\mu t + \\sigma W_t$ starting at $0$, the maximum value probability is given by $\\mathbb{P}(\\sup_{t\\geq 0} B_t \\geq a) = \\exp(2\\mu a / \\sigma^2)$ for $\\mu0, a0$.\nIn our case, $Z_t$ is a process where the drift coefficient is $\\mu=-2$ and the Brownian motion part has coefficient $\\sqrt{2}$. The equivalent standard form would be based on $W_t$. Let $Z_t = \\sqrt{2}(-\\sqrt{2}t+W_t)$. For the process $B_t' = -\\sqrt{2}t+W_t$, with drift $\\mu'=-\\sqrt{2}0$, we have $\\mathbb{P}(\\sup_{t\\ge 0} B_t' \\ge a') = \\exp(2(-\\sqrt{2})a')$.\nSo, $\\mathbb{P}(\\sup_{t\\geq 0} Z_t  a) = \\mathbb{P}(\\sup_{t\\geq 0} \\sqrt{2}B_t'  a) = \\mathbb{P}(\\sup_{t\\geq 0} B_t'  a/\\sqrt{2}) = \\exp(2(-\\sqrt{2})(a/\\sqrt{2})) = \\exp(-2a)$.\nLet $a = \\ln(\\epsilon/|x_0|)$. For the probability to be well-defined with this formula, we need $a0$, so we select $x_0$ such that $|x_0|\\epsilon$.\nThen, $\\mathbb{P}(\\sup_{t\\geq 0} |X_t|  \\epsilon) = \\exp(-2 \\ln(\\epsilon/|x_0|)) = (\\epsilon/|x_0|)^{-2} = (|x_0|/\\epsilon)^2$.\nTo satisfy the stability condition, we need $(|x_0|/\\epsilon)^2  \\eta$, which gives $|x_0|  \\epsilon\\sqrt{\\eta}$. We can choose $\\delta = \\epsilon\\sqrt{\\eta}$. If $|x_0|  \\delta$, the condition is fulfilled.\nThus, the zero equilibrium is stable in probability. Since it is also attractive, it is asymptotically stable in probability.\n\nThird, we analyze mean-square stability. A system is mean-square stable if for any $\\epsilon  0$, there exists a $\\delta  0$ such that $|x_0|^2  \\delta$ implies $\\mathbb{E}[|X_t|^2]  \\epsilon$ for all $t \\geq 0$. From our first result, we have $\\mathbb{E}[|X_t|^2] = x_0^2$. This is constant for all $t \\geq 0$. For a given $\\epsilon0$, we need to find $\\delta0$ such that $|x_0|^2  \\delta$ implies $x_0^2  \\epsilon$. We can simply choose $\\delta = \\epsilon$. This satisfies the definition of mean-square stability in the Lyapunov sense.\nA system is asymptotically mean-square stable if it is mean-square stable and $\\lim_{t\\to\\infty} \\mathbb{E}[|X_t|^2] = 0$. In our case:\n$$\\lim_{t\\to\\infty} \\mathbb{E}[|X_t|^2] = \\lim_{t\\to\\infty} x_0^2 = x_0^2.$$\nThis limit is not zero for any non-zero initial condition $x_0 \\neq 0$. Therefore, the zero equilibrium is not asymptotically mean-square stable.\n\nIn conclusion, this SDE provides a classic example where different notions of stability diverge. The zero solution is asymptotically stable in probability (and almost surely), meaning that trajectories converge to zero. However, it is not asymptotically mean-square stable, as the second moment does not decay to zero. This is due to the noise term being large enough ($2a+b^2=0$) to prevent the decay of moments, even though the sample paths themselves decay ($a-b^2/2  0$).\n\nThe specific question for the final answer is the exact analytic expression for $\\mathbb{E}[|X_{t}|^{2}]$.\nBased on the derivation using Itô's formula, this expression is $x_0^2$.", "answer": "$$\n\\boxed{x_{0}^{2}}\n$$", "id": "2996127"}, {"introduction": "Theoretical stability analysis has vital practical implications, especially when simulating SDEs numerically. This exercise [@problem_id:2996148] investigates the stability of the widely used Euler–Maruyama scheme. You will discover that a numerical approximation of a stable SDE can itself be unstable if the time step $h$ is too large, leading to divergent simulations. By deriving the explicit condition for the scheme's $p$-th moment stability, this practice connects the abstract concept of moment growth to the concrete task of choosing a valid step-size for computation.", "problem": "Consider the scalar linear Stochastic Differential Equation (SDE) $$\\mathrm{d}X(t) = \\lambda X(t)\\,\\mathrm{d}t + \\mu X(t)\\,\\mathrm{d}W(t),$$ where $W(t)$ is a standard Wiener process, and $\\lambda,\\mu \\in \\mathbb{R}$. Let $(t_n)_{n \\ge 0}$ be a uniform grid with step-size $h0$, and define the Euler–Maruyama discretization by $$X_{n+1} = X_n + \\lambda h X_n + \\mu X_n \\Delta W_n,$$ where $\\Delta W_n := W(t_{n+1}) - W(t_n)$. Write $\\Delta W_n = \\sqrt{h}\\,\\xi_n$ with $(\\xi_n)_{n\\ge 0}$ an independent and identically distributed sequence of standard normal random variables, $\\xi_n \\sim \\mathcal{N}(0,1)$, independent of $X_0$.\n\nYour tasks are:\n1) For an even integer $p \\ge 2$, derive the $p$-th moment amplification factor $$G_p(h) := \\mathbb{E}\\!\\left(|1 + \\lambda h + \\mu \\sqrt{h}\\,\\xi|^{p}\\right),$$ where $\\xi \\sim \\mathcal{N}(0,1)$ is independent of $X_n$. Express $G_p(h)$ in closed form using only fundamental properties of the normal distribution and basic combinatorics, starting from first principles (do not use or quote pre-derived stability region formulas).\n2) Using the definition of $p$-th moment stability, deduce from first principles a necessary and sufficient condition on the step-size $h$ (in terms of $G_p(h)$) that ensures $\\mathbb{E}(|X_n|^{p}) \\to 0$ as $n \\to \\infty$ for the Euler–Maruyama scheme applied to the given SDE.\n3) Assume that $2\\lambda + \\mu^{2}  0$ so that second-moment stability of the exact SDE is possible. Under this assumption, compute the largest admissible step-size $h^{\\star}$ guaranteeing second-moment ($p=2$) stability of the Euler–Maruyama scheme, as a single closed-form analytic expression in $\\lambda$ and $\\mu$. The final answer must be this expression.", "solution": "The problem statement is evaluated to be **valid**. It is scientifically grounded in the theory of numerical analysis for stochastic differential equations, specifically concerning the moment stability of the Euler–Maruyama method. The problem is well-posed, objective, and self-contained, providing all necessary definitions and conditions to derive a unique solution through rigorous mathematical reasoning.\n\nWe will address the three parts of the problem sequentially.\n\n**1) Derivation of the $p$-th moment amplification factor $G_p(h)$**\n\nThe Euler–Maruyama discretization is given by\n$$X_{n+1} = X_n + \\lambda h X_n + \\mu X_n \\Delta W_n = X_n(1 + \\lambda h + \\mu \\sqrt{h} \\xi_n),$$\nwhere $\\xi_n \\sim \\mathcal{N}(0,1)$ are independent and identically distributed standard normal random variables. The problem defines the $p$-th moment amplification factor as\n$$G_p(h) = \\mathbb{E}\\!\\left[|1 + \\lambda h + \\mu \\sqrt{h}\\,\\xi|^{p}\\right],$$\nwhere $\\xi \\sim \\mathcal{N}(0,1)$. Since the problem states that $p \\ge 2$ is an even integer, the absolute value is redundant, i.e., $|z|^p = z^p$ for any real $z$. Thus, we need to compute\n$$G_p(h) = \\mathbb{E}\\!\\left[(1 + \\lambda h + \\mu \\sqrt{h}\\,\\xi)^{p}\\right].$$\nLet $A = 1 + \\lambda h$ and $B = \\mu \\sqrt{h}$. We need to compute $\\mathbb{E}[(A + B\\xi)^p]$. Using the binomial theorem, we expand the term inside the expectation:\n$$(A + B\\xi)^p = \\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} (B\\xi)^k = \\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} B^k \\xi^k.$$\nBy the linearity of the expectation operator, we have\n$$G_p(h) = \\mathbb{E}\\!\\left[\\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} B^k \\xi^k\\right] = \\sum_{k=0}^{p} \\binom{p}{k} A^{p-k} B^k \\mathbb{E}[\\xi^k].$$\nWe now need the moments of a standard normal random variable $\\xi \\sim \\mathcal{N}(0,1)$. The probability density function of $\\xi$ is symmetric about $0$, which implies that all odd moments are zero:\n$$\\mathbb{E}[\\xi^k] = 0, \\quad \\text{for odd } k.$$\nFor even moments, where $k=2j$ for $j \\in \\{0, 1, 2, \\dots, p/2\\}$, the moments are given by the double factorial of $k-1$:\n$$\\mathbb{E}[\\xi^{2j}] = (2j-1)!! = (2j-1)(2j-3)\\cdots 3 \\cdot 1.$$\nBy convention, for $j=0$, we have $k=0$, and $\\mathbb{E}[\\xi^0] = 1$, which is consistent with the definition $(-1)!!=1$.\n\nSubstituting the moments back into the expression for $G_p(h)$, the sum is restricted to even values of $k$. Let $k=2j$:\n$$G_p(h) = \\sum_{j=0}^{p/2} \\binom{p}{2j} A^{p-2j} B^{2j} \\mathbb{E}[\\xi^{2j}].$$\nSubstituting the expressions for $A$, $B$, and the even moments of $\\xi$:\n$$G_p(h) = \\sum_{j=0}^{p/2} \\binom{p}{2j} (1+\\lambda h)^{p-2j} (\\mu\\sqrt{h})^{2j} (2j-1)!!.$$\nSimplifying the term $(\\mu\\sqrt{h})^{2j} = \\mu^{2j}h^j$, we obtain the final closed-form expression for the amplification factor:\n$$G_p(h) = \\sum_{j=0}^{p/2} \\binom{p}{2j} (1+\\lambda h)^{p-2j} \\mu^{2j} h^j (2j-1)!!.$$\n\n**2) Condition for $p$-th moment stability**\n\nThe $p$-th moment stability of the numerical scheme is defined by the condition $\\mathbb{E}(|X_n|^p) \\to 0$ as $n \\to \\infty$. We analyze the evolution of $\\mathbb{E}(|X_n|^p)$. From the recurrence relation $X_{n+1} = X_n(1 + \\lambda h + \\mu \\sqrt{h} \\xi_n)$, we take the $p$-th power of the absolute value:\n$$|X_{n+1}|^p = |X_n|^p |1 + \\lambda h + \\mu \\sqrt{h} \\xi_n|^p.$$\nNow we take the expectation of both sides.\n$$\\mathbb{E}[|X_{n+1}|^p] = \\mathbb{E}\\big[|X_n|^p |1 + \\lambda h + \\mu \\sqrt{h} \\xi_n|^p\\big].$$\nThe random variable $\\xi_n$ is associated with the time interval $[t_n, t_{n+1}]$ and is independent of all previous history of the Wiener process up to time $t_n$. Since $X_n$ is $\\mathcal{F}_{t_n}$-measurable (i.e., it depends only on the history of $W(t)$ up to time $t_n$), $X_n$ is independent of $\\xi_n$. Therefore, the expectation of the product is the product of the expectations:\n$$\\mathbb{E}[|X_{n+1}|^p] = \\mathbb{E}[|X_n|^p] \\cdot \\mathbb{E}\\big[|1 + \\lambda h + \\mu \\sqrt{h} \\xi_n|^p\\big].$$\nThe second factor on the right-hand side is precisely the definition of the amplification factor $G_p(h)$, noting that $\\xi_n$ has the same distribution as $\\xi$. So, we have the recurrence relation:\n$$\\mathbb{E}[|X_{n+1}|^p] = G_p(h) \\cdot \\mathbb{E}[|X_n|^p].$$\nThis is a geometric progression for the sequence $m_n = \\mathbb{E}[|X_n|^p]$. Its solution is\n$$m_n = (G_p(h))^n m_0,$$\nwhere $m_0 = \\mathbb{E}[|X_0|^p]$. For the sequence $m_n$ to converge to $0$ as $n \\to \\infty$ (assuming $m_0 \\neq 0$), the common ratio $G_p(h)$ must have a magnitude less than $1$. As $G_p(h)$ is the expectation of a non-negative quantity $|...|^p$, it is non-negative, i.e., $G_p(h) \\ge 0$.\nTherefore, the necessary and sufficient condition for $p$-th moment stability is\n$$G_p(h)  1.$$\n\n**3) Largest admissible step-size $h^{\\star}$ for second-moment ($p=2$) stability**\n\nWe specialize the results from the previous parts to the case $p=2$. First, we compute $G_2(h)$ using the formula derived in part 1:\n$$G_2(h) = \\sum_{j=0}^{1} \\binom{2}{2j} (1+\\lambda h)^{2-2j} \\mu^{2j} h^j (2j-1)!!.$$\nFor $j=0$: $\\binom{2}{0}(1+\\lambda h)^2 \\mu^0 h^0 (-1)!! = 1 \\cdot (1+\\lambda h)^2 \\cdot 1 \\cdot 1 = (1+\\lambda h)^2$.\nFor $j=1$: $\\binom{2}{2}(1+\\lambda h)^0 \\mu^2 h^1 (1)!! = 1 \\cdot 1 \\cdot \\mu^2 h \\cdot 1 = \\mu^2 h$.\nSumming these terms gives:\n$$G_2(h) = (1+\\lambda h)^2 + \\mu^2 h.$$\nExpanding this expression, we get:\n$$G_2(h) = 1 + 2\\lambda h + \\lambda^2 h^2 + \\mu^2 h = 1 + (2\\lambda + \\mu^2)h + \\lambda^2 h^2.$$\nThe condition for second-moment stability, from part 2, is $G_2(h)  1$.\n$$1 + (2\\lambda + \\mu^2)h + \\lambda^2 h^2  1.$$\nSubtracting $1$ from both sides yields:\n$$(2\\lambda + \\mu^2)h + \\lambda^2 h^2  0.$$\nSince the step-size $h$ must be positive ($h0$), we can divide the inequality by $h$ without changing its direction:\n$$2\\lambda + \\mu^2 + \\lambda^2 h  0.$$\nWe rearrange to solve for $h$:\n$$\\lambda^2 h  -(2\\lambda + \\mu^2).$$\nThe problem gives the assumption that $2\\lambda + \\mu^2  0$, which ensures that the corresponding continuous SDE is second-moment stable. This assumption implies that the right-hand side, $-(2\\lambda + \\mu^2)$, is a positive quantity.\nIf $\\lambda=0$, the inequality becomes $0  -(\\mu^2)$, which is $0  -\\mu^2$. This is impossible for any real $\\mu$. Furthermore, the assumption $2\\lambda+\\mu^20$ would become $\\mu^2  0$, also impossible. Thus, we must have $\\lambda \\neq 0$.\nSince $\\lambda \\neq 0$, its square $\\lambda^2$ is strictly positive. We can divide the inequality by $\\lambda^2$ without changing its direction:\n$$h  -\\frac{2\\lambda + \\mu^2}{\\lambda^2}.$$\nThe stability of the Euler–Maruyama scheme is guaranteed for all step-sizes $h$ that satisfy $0  h  -\\frac{2\\lambda + \\mu^2}{\\lambda^2}$. The largest admissible step-size, denoted $h^{\\star}$, is the supremum of this interval.\n$$h^{\\star} = -\\frac{2\\lambda + \\mu^2}{\\lambda^2}.$$\nThis is the maximum step-size that ensures second-moment stability for the numerical scheme under the given condition.", "answer": "$$\n\\boxed{-\\frac{2\\lambda + \\mu^2}{\\lambda^2}}\n$$", "id": "2996148"}]}