{"hands_on_practices": [{"introduction": "Langevin equations are a cornerstone of statistical physics, modeling the motion of particles in a thermal environment. This exercise explores the fundamental principle ensuring that such a system reaches thermal equilibrium. By analyzing the stationary Fokker–Planck equation, you will derive the fluctuation–dissipation relation, which dictates the precise balance between random noise and dissipative drift required for the system to relax to the physically correct Gibbs-Boltzmann distribution [@problem_id:2996786].", "problem": "Consider the overdamped Langevin stochastic differential equation (SDE) in $\\mathbb{R}^{d}$ given in Itô form by\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\, a\\, \\nabla V\\!\\left(X_{t}\\right)\\,\\mathrm{d}t \\;+\\; \\sigma\\, \\mathrm{d}W_{t},\n$$\nwhere $a>0$ is a constant dissipation (mobility) parameter, $V:\\mathbb{R}^{d}\\to\\mathbb{R}$ is a twice continuously differentiable confining potential, $\\sigma>0$ is an unknown constant noise intensity, and $W_{t}$ is a standard $d$-dimensional Wiener process. Assume $V$ is such that the Gibbs measure\n$$\n\\mu(\\mathrm{d}x) \\;=\\; Z^{-1}\\exp\\!\\bigl(-\\beta\\, V(x)\\bigr)\\,\\mathrm{d}x,\n$$\nwith inverse temperature $\\beta>0$ and normalization constant $Z=\\int_{\\mathbb{R}^{d}}\\exp\\!\\bigl(-\\beta\\, V(x)\\bigr)\\,\\mathrm{d}x$, is well-defined (finite $Z$). Derive, from first principles of the Kolmogorov forward equation (also known as the Fokker–Planck equation) and the definition of invariant measure, the fluctuation–dissipation relation that links $a$ and $\\sigma$ required for $\\mu$ to be an invariant measure of the SDE.\n\nProvide the noise intensity $\\sigma$ explicitly as a symbolic expression in terms of $a$ and $\\beta$. No rounding is needed.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard derivation in statistical physics and the theory of stochastic processes. All required information is provided and is internally consistent.\n\nThe stochastic differential equation (SDE) is given in Itô form as:\n$$\n\\mathrm{d}X_{t} = -a \\nabla V(X_{t}) \\mathrm{d}t + \\sigma \\mathrm{d}W_{t}\n$$\nThis is a multidimensional SDE in $\\mathbb{R}^{d}$. We can identify the drift vector $b(x)$ and the diffusion matrix $D(x)$ by comparing the given equation to the general form $\\mathrm{d}X_t = b(X_t)\\mathrm{d}t + D(X_t)\\mathrm{d}W_t$.\nThe drift vector is $b(x) = -a \\nabla V(x)$.\nThe diffusion term $\\sigma \\mathrm{d}W_t$ corresponds to a diffusion matrix $D(x) = \\sigma I_{d}$, where $I_{d}$ is the $d \\times d$ identity matrix and $\\sigma$ is a constant.\n\nThe time evolution of the probability density function $p(x, t)$ of the process $X_t$ is described by the Kolmogorov forward equation, also known as the Fokker–Planck equation. For a general SDE, this equation is:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\nabla \\cdot \\bigl(b(x) p(x,t)\\bigr) + \\frac{1}{2} \\sum_{i,j=1}^{d} \\frac{\\partial^2}{\\partial x_i \\partial x_j} \\left[ (D(x)D(x)^T)_{ij} p(x,t) \\right]\n$$\nFirst, we compute the matrix product $D(x)D(x)^T$:\n$$\nD(x)D(x)^T = (\\sigma I_d)(\\sigma I_d)^T = \\sigma^2 I_d\n$$\nThe components of this matrix are $(\\sigma^2 I_d)_{ij} = \\sigma^2 \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\nSubstituting the drift $b(x)$ and the diffusion matrix product into the Fokker–Planck equation:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\nabla \\cdot \\bigl(-a \\nabla V(x) p(x,t)\\bigr) + \\frac{1}{2} \\sum_{i,j=1}^{d} \\frac{\\partial^2}{\\partial x_i \\partial x_j} \\left[ \\sigma^2 \\delta_{ij} p(x,t) \\right]\n$$\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = \\nabla \\cdot \\bigl(a \\nabla V(x) p(x,t)\\bigr) + \\frac{1}{2} \\sigma^2 \\sum_{i=1}^{d} \\frac{\\partial^2}{\\partial x_i^2} p(x,t)\n$$\nThis simplifies to:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = \\nabla \\cdot \\bigl(a \\nabla V(x) p(x,t)\\bigr) + \\frac{\\sigma^2}{2} \\Delta p(x,t)\n$$\nwhere $\\Delta = \\nabla \\cdot \\nabla$ is the Laplacian operator.\n\nAn invariant measure, or stationary distribution, is characterized by a time-independent probability density function, which we denote by $p_{ss}(x)$. For a stationary distribution, $\\frac{\\partial p_{ss}(x)}{\\partial t} = 0$. Setting the time derivative to zero in the Fokker–Planck equation gives the condition for the stationary density:\n$$\n0 = \\nabla \\cdot \\bigl(a \\nabla V(x) p_{ss}(x)\\bigr) + \\frac{\\sigma^2}{2} \\Delta p_{ss}(x)\n$$\nThis equation can be written in the form of a continuity equation, $\\nabla \\cdot J(x) = 0$, where $J(x)$ is the probability current density. By distributing the divergence operator, we can identify the current:\n$$\n\\nabla \\cdot \\left[ a (\\nabla V(x)) p_{ss}(x) + \\frac{\\sigma^2}{2} \\nabla p_{ss}(x) \\right] = 0\n$$\nThus, the probability current is:\n$$\nJ(x) = a (\\nabla V(x)) p_{ss}(x) + \\frac{\\sigma^2}{2} \\nabla p_{ss}(x)\n$$\nThe condition $\\nabla \\cdot J(x) = 0$ is a statement of conservation of probability. For a system in thermal equilibrium, a stronger condition known as detailed balance must hold, which asserts that the net probability current is zero everywhere, i.e., $J(x) = 0$ for all $x \\in \\mathbb{R}^d$. This ensures that for any two states, the rate of transitions between them is equal in both directions. Setting the current to zero yields:\n$$\na (\\nabla V(x)) p_{ss}(x) + \\frac{\\sigma^2}{2} \\nabla p_{ss}(x) = 0\n$$\n\nThe problem states that the invariant measure is the Gibbs measure $\\mu(\\mathrm{d}x) = Z^{-1}\\exp(-\\beta V(x))\\mathrm{d}x$. The corresponding stationary probability density is $p_{ss}(x) = Z^{-1}\\exp(-\\beta V(x))$. We now compute the gradient of this density:\n$$\n\\nabla p_{ss}(x) = \\nabla \\left( Z^{-1}\\exp(-\\beta V(x)) \\right) = Z^{-1} \\exp(-\\beta V(x)) \\cdot (-\\beta \\nabla V(x))\n$$\nRecognizing that $Z^{-1}\\exp(-\\beta V(x))$ is simply $p_{ss}(x)$, we have:\n$$\n\\nabla p_{ss}(x) = -\\beta p_{ss}(x) \\nabla V(x)\n$$\nSubstituting this expression for $\\nabla p_{ss}(x)$ into the detailed balance equation ($J(x)=0$):\n$$\na (\\nabla V(x)) p_{ss}(x) + \\frac{\\sigma^2}{2} \\bigl(-\\beta p_{ss}(x) \\nabla V(x)\\bigr) = 0\n$$\nWe can factor out the common terms $p_{ss}(x)$ and $\\nabla V(x)$:\n$$\n\\left( a - \\frac{\\sigma^2 \\beta}{2} \\right) p_{ss}(x) \\nabla V(x) = 0\n$$\nThis equation must hold for all $x \\in \\mathbb{R}^d$. As $p_{ss}(x) = Z^{-1}\\exp(-\\beta V(x))$ is strictly positive and we assume $V(x)$ is not constant everywhere (i.e., $\\nabla V(x)$ is not identically zero), the scalar coefficient in the parentheses must be zero:\n$$\na - \\frac{\\sigma^2 \\beta}{2} = 0\n$$\nThis is the fluctuation-dissipation relation for this system. It connects the dissipation parameter $a$ with the fluctuation (noise) intensity $\\sigma$ and the inverse temperature $\\beta$.\n\nThe problem requires an explicit expression for $\\sigma$ in terms of $a$ and $\\beta$. Solving the relation for $\\sigma^2$:\n$$\n\\sigma^2 = \\frac{2a}{\\beta}\n$$\nSince the noise intensity $\\sigma$ is given as a positive constant ($\\sigma > 0$), we take the positive square root:\n$$\n\\sigma = \\sqrt{\\frac{2a}{\\beta}}\n$$\nThis result is a specific instance of the Einstein relation, connecting the diffusion coefficient ($D_{\\text{eff}} = \\sigma^2/2$) to the mobility ($a$) and temperature ($T = 1/(k_B \\beta)$, in physics contexts). Here, we have derived it from the Fokker-Planck equation as requested.", "answer": "$$\\boxed{\\sqrt{\\frac{2a}{\\beta}}}$$", "id": "2996786"}, {"introduction": "While many systems relax to thermal equilibrium, a vast class of interesting phenomena in physics and biology are characterized by non-equilibrium stationary states. This practice problem moves beyond the constraint of detailed balance by introducing a non-gradient drift term, which prevents the system from reaching equilibrium. You will find the stationary distribution for this system and, crucially, compute the non-zero stationary probability current and the associated entropy production rate, key signatures of a system actively being kept out of equilibrium [@problem_id:2996767].", "problem": "Consider the two-dimensional Itô stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t = -K X_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t,\n$$\nwhere $X_t \\in \\mathbb{R}^2$, $W_t$ is a standard two-dimensional Wiener process, and the constant matrices satisfy $K = S + R$, with\n$$\nS = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & \\beta \\end{pmatrix}, \\quad \\alpha > 0, \\ \\beta > 0, \\qquad R = \\omega \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}, \\ \\omega \\neq 0,\n$$\nand the diffusion matrix $a$ is defined by $a = \\sigma \\sigma^{\\top} = 2 S$. The drift $b(x)$ is $b(x) = -K x$ and the diffusion matrix $a$ is constant and positive-definite.\n\nStarting only from the Fokker–Planck equation (FPE) for the probability density $\\rho(x,t)$,\n$$\n\\partial_t \\rho(x,t) = -\\nabla \\cdot \\big(b(x)\\,\\rho(x,t)\\big) + \\tfrac{1}{2}\\,\\nabla \\cdot \\big(a\\,\\nabla \\rho(x,t)\\big),\n$$\nand the core definitions of (i) stationary distribution, (ii) detailed balance, and (iii) probability current, do the following:\n\n1. Establish conditions under which a stationary density exists for the above SDE and find the stationary density explicitly.\n\n2. Determine whether detailed balance holds under the given specification. State precisely the condition on $R$ under which detailed balance would hold, and conclude whether it holds here.\n\n3. Derive the stationary probability current $j(x)$ and show that in the stationary regime it is divergence-free.\n\n4. Define the stationary entropy production rate\n$$\nI := \\int_{\\mathbb{R}^2} \\rho(x)^{-1}\\, j(x)^{\\top} a^{-1} j(x)\\,\\mathrm{d}x,\n$$\nand compute $I$ in closed form in terms of $\\alpha$, $\\beta$, and $\\omega$.\n\nExpress your final answer as a single closed-form analytic expression in terms of $\\alpha$, $\\beta$, and $\\omega$. No rounding is required. No physical units are needed.", "solution": "The problem provides a two-dimensional linear Itô stochastic differential equation (SDE) and asks for an analysis of its stationary properties. The SDE is given by $\\mathrm{d}X_t = b(X_t)\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t$, with drift vector $b(x) = -Kx$ and diffusion matrix $a = \\sigma\\sigma^\\top$. The problem statement is validated as scientifically sound, well-posed, and self-contained. The matrices are given as $K = S + R$, where $S = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & \\beta \\end{pmatrix}$ with $\\alpha > 0, \\beta > 0$, $R = \\omega \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}$ with $\\omega \\neq 0$, and $a = 2S$.\n\n### 1. Stationary Density Existence and Calculation\n\nA stationary probability density $\\rho(x)$ is a time-independent solution to the Fokker-Planck equation (FPE), meaning $\\partial_t \\rho(x,t) = 0$. The stationary FPE is:\n$$\n0 = -\\nabla \\cdot \\big(b(x)\\,\\rho(x)\\big) + \\tfrac{1}{2}\\,\\nabla \\cdot \\big(a\\,\\nabla \\rho(x)\\big)\n$$\nFor a linear SDE of the form $\\mathrm{d}X_t = -KX_t\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_t$, a unique, normalizable stationary distribution exists if and only if all eigenvalues of the matrix $K$ have positive real parts. Let's verify this condition. The matrix $K$ is:\n$$\nK = S + R = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & \\beta \\end{pmatrix} + \\omega \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} \\alpha & -\\omega \\\\ \\omega & \\beta \\end{pmatrix}\n$$\nThe characteristic equation is $\\det(K - \\lambda I) = 0$, which is $(\\alpha - \\lambda)(\\beta - \\lambda) - (-\\omega)(\\omega) = 0$, leading to $\\lambda^2 - (\\alpha + \\beta)\\lambda + (\\alpha\\beta + \\omega^2) = 0$. The eigenvalues are given by the quadratic formula:\n$$\n\\lambda_{\\pm} = \\frac{(\\alpha+\\beta) \\pm \\sqrt{(\\alpha+\\beta)^2 - 4(\\alpha\\beta+\\omega^2)}}{2} = \\frac{(\\alpha+\\beta) \\pm \\sqrt{(\\alpha-\\beta)^2 - 4\\omega^2}}{2}\n$$\nThe real part of both eigenvalues is $\\mathrm{Re}(\\lambda_{\\pm}) = \\frac{\\alpha+\\beta}{2}$. Since the problem specifies $\\alpha > 0$ and $\\beta > 0$, we have $\\mathrm{Re}(\\lambda_{\\pm}) > 0$. Therefore, a unique stationary distribution exists.\n\nFor linear SDEs, the stationary distribution is a Gaussian, $\\rho(x) = C \\exp(-\\frac{1}{2} x^\\top \\Sigma^{-1} x)$, where $\\Sigma$ is the stationary covariance matrix. The matrix $\\Sigma$ is the unique positive-definite solution to the continuous-time Lyapunov equation:\n$$\nK\\Sigma + \\Sigma K^\\top = a\n$$\nWe are given $K=S+R$ and $a=2S$. Substituting these into the Lyapunov equation:\n$$\n(S+R)\\Sigma + \\Sigma(S+R)^\\top = 2S\n$$\nLet's test the hypothesis that $\\Sigma$ is the identity matrix, $\\Sigma = I_2$.\n$$\n(S+R)I_2 + I_2(S+R)^\\top = (S+R) + (S+R)^\\top = S+R+S^\\top+R^\\top\n$$\nThe matrix $S$ is symmetric, so $S^\\top=S$. The matrix $R$ is antisymmetric, so $R^\\top = -R$.\n$$\nS+R+S-R = 2S\n$$\nThis matches the given diffusion matrix $a=2S$. Thus, the covariance matrix of the stationary distribution is $\\Sigma = I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$.\nThe inverse is $\\Sigma^{-1} = I_2$. The stationary probability density is then of the form $\\rho(x) = C \\exp(-\\frac{1}{2} x^\\top I_2 x) = C \\exp(-\\frac{1}{2} |x|^2)$. Writing $x = (x_1, x_2)^\\top$, this is $\\rho(x_1, x_2) = C \\exp(-\\frac{1}{2}(x_1^2 + x_2^2))$. The normalization constant $C$ is found by requiring $\\int_{\\mathbb{R}^2} \\rho(x) \\mathrm{d}x = 1$.\n$$\n\\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} C e^{-x_1^2/2} e^{-x_2^2/2} \\mathrm{d}x_1 \\mathrm{d}x_2 = C (\\sqrt{2\\pi}) (\\sqrt{2\\pi}) = 2\\pi C = 1\n$$\nSo, $C = \\frac{1}{2\\pi}$. The stationary density is:\n$$\n\\rho(x) = \\frac{1}{2\\pi} \\exp\\left(-\\frac{1}{2} |x|^2\\right)\n$$\n\n### 2. Detailed Balance\nThe stationary state satisfies detailed balance if the stationary probability current is zero everywhere. The probability current is defined as $j(x) = b(x)\\rho(x) - \\frac{1}{2}a\\nabla\\rho(x)$.\nFor $\\rho(x) = \\frac{1}{2\\pi}\\exp(-\\frac{1}{2}x^\\top x)$, the gradient is $\\nabla \\rho(x) = -x \\rho(x)$.\nSubstituting this into the expression for the current:\n$$\nj(x) = (-Kx)\\rho(x) - \\frac{1}{2}a(-x\\rho(x)) = (-Kx + \\frac{1}{2}ax)\\rho(x) = (\\frac{1}{2}a - K)x\\rho(x)\n$$\nThe condition for detailed balance is $j(x) = 0$ for all $x$. Since $\\rho(x) \\neq 0$, this requires $(\\frac{1}{2}a - K)x = 0$ for all $x$, which in turn implies the matrix condition $\\frac{1}{2}a - K = 0$, or $K = \\frac{1}{2}a$.\nWe are given $a = 2S$, so the condition becomes $K=S$.\nThe problem defines $K=S+R$. Thus, the condition for detailed balance is $S+R=S$, which implies $R=0$.\nThe given matrix $R$ is $R = \\omega \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}$. This matrix is zero only if $\\omega=0$. However, the problem specifies $\\omega \\neq 0$.\nTherefore, $R \\neq 0$, and the condition for detailed balance is not met. The system is not in detailed balance.\n\n### 3. Stationary Probability Current\nWe calculate the stationary probability current $j(x)$ using the expression derived above:\n$$\nj(x) = (\\frac{1}{2}a - K)x\\rho(x)\n$$\nWith $a=2S$ and $K=S+R$, this becomes:\n$$\nj(x) = (\\frac{1}{2}(2S) - (S+R))x\\rho(x) = (S - S - R)x\\rho(x) = -Rx\\rho(x)\n$$\nLet's write this out in components, with $x=(x_1, x_2)^\\top$:\n$$\nj(x) = - \\omega \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} \\rho(x) = - \\omega \\begin{pmatrix} -x_2 \\\\ x_1 \\end{pmatrix} \\rho(x) = \\omega \\begin{pmatrix} x_2 \\\\ -x_1 \\end{pmatrix} \\rho(x)\n$$\nThe stationary FPE is $\\partial_t \\rho = -\\nabla \\cdot j(x) = 0$. This means the stationary current must be divergence-free. We verify this by direct computation: $\\nabla \\cdot j(x) = \\frac{\\partial j_1}{\\partial x_1} + \\frac{\\partial j_2}{\\partial x_2}$.\nThe components of the current are $j_1(x) = \\omega x_2 \\rho(x)$ and $j_2(x) = -\\omega x_1 \\rho(x)$.\nWe have $\\frac{\\partial \\rho}{\\partial x_1} = -x_1 \\rho(x)$ and $\\frac{\\partial \\rho}{\\partial x_2} = -x_2 \\rho(x)$.\nThe partial derivatives of the current components are:\n$$\n\\frac{\\partial j_1}{\\partial x_1} = \\frac{\\partial}{\\partial x_1}(\\omega x_2 \\rho(x)) = \\omega x_2 \\frac{\\partial \\rho}{\\partial x_1} = \\omega x_2 (-x_1 \\rho(x)) = -\\omega x_1 x_2 \\rho(x)\n$$\n$$\n\\frac{\\partial j_2}{\\partial x_2} = \\frac{\\partial}{\\partial x_2}(-\\omega x_1 \\rho(x)) = -\\omega x_1 \\frac{\\partial \\rho}{\\partial x_2} = -\\omega x_1 (-x_2 \\rho(x)) = \\omega x_1 x_2 \\rho(x)\n$$\nThe divergence is the sum of these two terms:\n$$\n\\nabla \\cdot j(x) = -\\omega x_1 x_2 \\rho(x) + \\omega x_1 x_2 \\rho(x) = 0\n$$\nAs expected, the stationary current is divergence-free.\n\n### 4. Stationary Entropy Production Rate\nThe stationary entropy production rate $I$ is defined as:\n$$\nI := \\int_{\\mathbb{R}^2} \\rho(x)^{-1}\\, j(x)^{\\top} a^{-1} j(x)\\,\\mathrm{d}x\n$$\nWe have $j(x) = -Rx\\rho(x)$, so $j(x)^\\top = (-Rx\\rho(x))^\\top = -\\rho(x)x^\\top R^\\top$.\nThe integrand is $\\rho(x)^{-1} (-\\rho(x)x^\\top R^\\top) a^{-1} (-Rx\\rho(x)) = \\rho(x) x^\\top R^\\top a^{-1} R x$.\nLet's compute the matrix $M = R^\\top a^{-1} R$.\nGiven $a=2S = \\begin{pmatrix} 2\\alpha & 0 \\\\ 0 & 2\\beta \\end{pmatrix}$, its inverse is $a^{-1} = \\begin{pmatrix} 1/(2\\alpha) & 0 \\\\ 0 & 1/(2\\beta) \\end{pmatrix}$.\nThe transpose of $R$ is $R^\\top = \\omega \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}$.\n$$\nR^\\top a^{-1} = \\omega \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix} \\begin{pmatrix} 1/(2\\alpha) & 0 \\\\ 0 & 1/(2\\beta) \\end{pmatrix} = \\omega \\begin{pmatrix} 0 & 1/(2\\beta) \\\\ -1/(2\\alpha) & 0 \\end{pmatrix}\n$$\n$$\nM = R^\\top a^{-1} R = \\left( \\omega \\begin{pmatrix} 0 & 1/(2\\beta) \\\\ -1/(2\\alpha) & 0 \\end{pmatrix} \\right) \\left( \\omega \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix} \\right) = \\omega^2 \\begin{pmatrix} 1/(2\\beta) & 0 \\\\ 0 & 1/(2\\alpha) \\end{pmatrix}\n$$\nThe integral for $I$ becomes:\n$$\nI = \\int_{\\mathbb{R}^2} \\rho(x) (x^\\top M x) \\,\\mathrm{d}x\n$$\nThis integral is the expectation of the quadratic form $x^\\top M x$ with respect to the density $\\rho(x)$.\n$$\nI = \\mathbb{E}_\\rho[x^\\top M x] = \\mathbb{E}_\\rho[\\text{Tr}(x^\\top M x)] = \\mathbb{E}_\\rho[\\text{Tr}(M x x^\\top)]\n$$\nBy linearity of expectation and trace, $I = \\text{Tr}(M\\, \\mathbb{E}_\\rho[x x^\\top])$. The term $\\mathbb{E}_\\rho[x x^\\top]$ is the covariance matrix $\\Sigma$ of the stationary distribution, which we found to be the identity matrix, $\\Sigma = I_2$.\n$$\nI = \\text{Tr}(M I_2) = \\text{Tr}(M)\n$$\nThe trace of $M$ is:\n$$\n\\text{Tr}(M) = \\text{Tr}\\left(\\omega^2 \\begin{pmatrix} 1/(2\\beta) & 0 \\\\ 0 & 1/(2\\alpha) \\end{pmatrix}\\right) = \\omega^2 \\left(\\frac{1}{2\\beta} + \\frac{1}{2\\alpha}\\right)\n$$\n$$\nI = \\frac{\\omega^2}{2} \\left(\\frac{1}{\\alpha} + \\frac{1}{\\beta}\\right) = \\frac{\\omega^2}{2} \\frac{\\alpha+\\beta}{\\alpha\\beta}\n$$\nThis is the closed-form expression for the stationary entropy production rate.", "answer": "$$\\boxed{\\frac{\\omega^{2} (\\alpha + \\beta)}{2 \\alpha \\beta}}$$", "id": "2996767"}, {"introduction": "Stochastic models in science and finance often require the state variables to remain within a specific domain, such as positive concentrations or prices. This hands-on practice demonstrates how to enforce such constraints using a reflecting boundary. By solving the Fokker–Planck equation for an Ornstein–Uhlenbeck process with a no-flux condition at the origin, you will derive the exact stationary density and see precisely how the reflection quantitatively shifts the mean and reduces the variance compared to the unconstrained process [@problem_id:2996774].", "problem": "Consider the one-dimensional Ornstein–Uhlenbeck process with reflection at the origin, defined as the solution $X_{t}$ on $[0,\\infty)$ to the stochastic differential equation (SDE) with reflection\n$$\n\\mathrm{d}X_{t} \\;=\\; \\kappa \\bigl(\\mu - X_{t}\\bigr)\\,\\mathrm{d}t \\;+\\; \\sigma \\,\\mathrm{d}W_{t} \\;+\\; \\mathrm{d}L_{t},\n$$\nwhere $\\kappa>0$, $\\mu\\in\\mathbb{R}$, $\\sigma>0$, $W_{t}$ is a standard Brownian motion, and $L_{t}$ is the boundary local time at $0$ that is nondecreasing, adapted, with $L_{0}=0$ and satisfying $\\int_{0}^{t}\\mathbf{1}_{\\{X_{s}>0\\}}\\,\\mathrm{d}L_{s}=0$ almost surely, so that reflection at $0$ is enforced. Let $p(x,t)$ denote the probability density of $X_{t}$ on $(0,\\infty)$.\n\nStarting from the Kolmogorov forward equation (also called the Fokker–Planck equation) for $p(x,t)$ and the no-flux (reflecting) boundary condition at $x=0$, derive the stationary density $p_{*}(x)$ on $[0,\\infty)$ and determine the stationary mean $\\mathbb{E}[X_{\\infty}]$ and variance $\\operatorname{Var}(X_{\\infty})$. Express your final formulas in closed form in terms of the parameters $\\kappa$, $\\mu$, and $\\sigma$, and the standard normal cumulative distribution function $\\Phi(\\cdot)$ and probability density function $\\varphi(\\cdot)$ if needed. Clearly explain how the reflection at $0$ modifies the stationary mean and variance relative to the unconstrained Ornstein–Uhlenbeck process on $\\mathbb{R}$.\n\nYour final boxed answer must be a single row matrix containing, in order, the invariant density $p_{*}(x)$, the stationary mean $\\mathbb{E}[X_{\\infty}]$, and the stationary variance $\\operatorname{Var}(X_{\\infty})$. No numerical approximation is required.", "solution": "The problem asks for the stationary density, mean, and variance of a one-dimensional Ornstein–Uhlenbeck (OU) process with reflection at the origin. The process $X_{t}$ evolves on a state space of $[0, \\infty)$ according to the stochastic differential equation (SDE):\n$$\n\\mathrm{d}X_{t} \\;=\\; \\kappa \\bigl(\\mu - X_{t}\\bigr)\\,\\mathrm{d}t \\;+\\; \\sigma \\,\\mathrm{d}W_{t} \\;+\\; \\mathrm{d}L_{t}\n$$\nwhere $\\kappa>0$, $\\sigma>0$, $\\mu\\in\\mathbb{R}$, $W_t$ is a standard Brownian motion, and $L_t$ is the local time at $x=0$ ensuring $X_t \\geq 0$.\n\nFirst, we validate the problem.\n**Step 1: Extract Givens**\n- SDE: $\\mathrm{d}X_{t} = \\kappa(\\mu - X_{t})\\,\\mathrm{d}t + \\sigma \\,\\mathrm{d}W_{t} + \\mathrm{d}L_{t}$\n- State space: $X_t \\in [0, \\infty)$\n- Parameters: $\\kappa > 0$, $\\mu \\in \\mathbb{R}$, $\\sigma > 0$\n- $W_t$: Standard Brownian motion\n- $L_t$: Boundary local time at $0$, nondecreasing, adapted, $L_{0}=0$, and $\\int_{0}^{t}\\mathbf{1}_{\\{X_{s}>0\\}}\\,\\mathrm{d}L_{s}=0$ a.s.\n- Task: Find the stationary density $p_*(x)$, stationary mean $\\mathbb{E}[X_{\\infty}]$, and stationary variance $\\operatorname{Var}(X_{\\infty})$.\n\n**Step 2: Validate Using Extracted Givens**\n- The problem is **scientifically grounded**. The reflected Ornstein-Uhlenbeck process is a standard, well-studied model in stochastic processes.\n- The problem is **well-posed**. It provides a complete SDE with clearly defined boundary behavior and asks for derivable quantities (stationary density and its moments).\n- The problem is **objective**. It is stated using formal mathematical language and is free of subjective claims.\n- The setup is complete and consistent, and the problem is formalizable and relevant to the study of stationary distributions for SDEs.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. We proceed to the solution.\n\nThe probability density $p(x,t)$ of the process on $(0,\\infty)$ is governed by the Kolmogorov forward equation, also known as the Fokker–Planck equation. For a general SDE $\\mathrm{d}X_t = a(X_t)\\mathrm{d}t + b(X_t)\\mathrm{d}W_t$, the equation is $\\frac{\\partial p}{\\partial t} = -\\frac{\\partial}{\\partial x}[a(x)p] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}[b(x)^2 p]$.\nFor the given process, the drift is $a(x) = \\kappa(\\mu - x)$ and the diffusion coefficient is $b(x) = \\sigma$. The Fokker–Planck equation on $(0, \\infty)$ is:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x} \\left[\\kappa(\\mu - x) p(x,t)\\right] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2} \\left[\\sigma^2 p(x,t)\\right]\n$$\nThe stationary density $p_*(x)$ is the time-independent solution, satisfying $\\frac{\\partial p_*(x)}{\\partial t} = 0$. This leads to:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}x} \\left( -\\kappa(\\mu - x) p_*(x) + \\frac{\\sigma^2}{2} \\frac{\\mathrm{d}p_*(x)}{\\mathrm{d}x} \\right) = 0\n$$\nThe term in the parenthesis is the probability flux, $J(x)$. The equation implies that the flux $J(x)$ must be constant. The reflection at $x=0$ imposes a no-flux boundary condition, $J(0)=0$. Therefore, the flux must be zero for all $x \\geq 0$:\n$$\n-\\kappa(\\mu - x) p_*(x) + \\frac{\\sigma^2}{2} \\frac{\\mathrm{d}p_*(x)}{\\mathrm{d}x} = 0\n$$\nThis is a separable first-order ordinary differential equation:\n$$\n\\frac{\\mathrm{d}p_*}{p_*} = \\frac{2\\kappa}{\\sigma^2}(\\mu - x) \\mathrm{d}x\n$$\nIntegrating both sides gives:\n$$\n\\ln(p_*(x)) = \\frac{2\\kappa}{\\sigma^2}\\left(\\mu x - \\frac{x^2}{2}\\right) + C_1 = -\\frac{\\kappa}{\\sigma^2}(x^2 - 2\\mu x) + C_1\n$$\nCompleting the square in the exponent, $x^2 - 2\\mu x = (x-\\mu)^2 - \\mu^2$, we get:\n$$\np_*(x) = C \\exp\\left(-\\frac{\\kappa}{\\sigma^2} (x-\\mu)^2\\right)\n$$\nThis is the functional form of a normal distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{2\\kappa}$. For the reflected process, this density is defined on $[0, \\infty)$ and must be normalized. The normalization constant $C$ is found by enforcing $\\int_0^\\infty p_*(x)\\mathrm{d}x = 1$.\nLet $\\sigma_{\\text{OU}}^2 = \\frac{\\sigma^2}{2\\kappa}$. The unnormalized density is proportional to the density of a $N(\\mu, \\sigma_{\\text{OU}}^2)$ distribution.\nThe normalization integral is:\n$$\n\\frac{1}{C} = \\int_0^{\\infty} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma_{\\text{OU}}^2}\\right) \\mathrm{d}x\n$$\nLet $z = \\frac{x-\\mu}{\\sigma_{\\text{OU}}}$. Then $x = z\\sigma_{\\text{OU}} + \\mu$ and $\\mathrm{d}x = \\sigma_{\\text{OU}}\\mathrm{d}z$. The lower integration limit becomes $x=0 \\implies z = -\\frac{\\mu}{\\sigma_{\\text{OU}}}$.\n$$\n\\frac{1}{C} = \\sigma_{\\text{OU}} \\int_{-\\mu/\\sigma_{\\text{OU}}}^{\\infty} \\exp\\left(-\\frac{z^2}{2}\\right) \\mathrm{d}z = \\sigma_{\\text{OU}}\\sqrt{2\\pi} \\int_{-\\mu/\\sigma_{\\text{OU}}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{z^2}{2}\\right) \\mathrm{d}z\n$$\nUsing the standard normal probability density function $\\varphi(z)$ and cumulative distribution function $\\Phi(z)$, the integral is $1 - \\Phi(-\\frac{\\mu}{\\sigma_{\\text{OU}}}) = \\Phi(\\frac{\\mu}{\\sigma_{\\text{OU}}})$.\nThus, $\\frac{1}{C} = \\sigma_{\\text{OU}}\\sqrt{2\\pi} \\Phi(\\frac{\\mu}{\\sigma_{\\text{OU}}})$, so $C = \\frac{1}{\\sigma_{\\text{OU}}\\sqrt{2\\pi} \\Phi(\\mu/\\sigma_{\\text{OU}})}$.\nThe stationary density is:\n$$\np_*(x) = \\frac{1}{\\sigma_{\\text{OU}}\\sqrt{2\\pi}\\,\\Phi(\\mu/\\sigma_{\\text{OU}})} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma_{\\text{OU}}^2}\\right) = \\frac{\\varphi((x-\\mu)/\\sigma_{\\text{OU}})}{\\sigma_{\\text{OU}}\\Phi(\\mu/\\sigma_{\\text{OU}})} \\quad \\text{for } x \\ge 0\n$$\nSubstituting $\\sigma_{\\text{OU}} = \\frac{\\sigma}{\\sqrt{2\\kappa}}$:\n$$\np_*(x) = \\frac{\\sqrt{\\kappa}}{\\sigma\\sqrt{\\pi} \\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(x-\\mu)^2\\right)\n$$\n\nThe stationary mean $\\mathbb{E}[X_{\\infty}]$ is the mean of a normal distribution $N(\\mu, \\sigma_{\\text{OU}}^2)$ truncated to $[0, \\infty)$.\n$$\n\\mathbb{E}[X_{\\infty}] = \\int_0^{\\infty} x p_*(x) \\mathrm{d}x\n$$\nThe mean of a normal variable $Y \\sim N(\\mu, \\sigma^2)$ truncated to $[a, \\infty)$ is $\\mu + \\sigma \\frac{\\varphi((a-\\mu)/\\sigma)}{1-\\Phi((a-\\mu)/\\sigma)}$.\nHere, the untruncated distribution has mean $\\mu$ and standard deviation $\\sigma_{\\text{OU}}=\\frac{\\sigma}{\\sqrt{2\\kappa}}$, and the truncation is at $a=0$.\n$$\n\\mathbb{E}[X_{\\infty}] = \\mu + \\sigma_{\\text{OU}} \\frac{\\varphi(-\\mu/\\sigma_{\\text{OU}})}{1-\\Phi(-\\mu/\\sigma_{\\text{OU}})} = \\mu + \\sigma_{\\text{OU}} \\frac{\\varphi(\\mu/\\sigma_{\\text{OU}})}{\\Phi(\\mu/\\sigma_{\\text{OU}})}\n$$\nSubstituting $\\sigma_{\\text{OU}}=\\frac{\\sigma}{\\sqrt{2\\kappa}}$, we get:\n$$\n\\mathbb{E}[X_{\\infty}] = \\mu + \\frac{\\sigma}{\\sqrt{2\\kappa}} \\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}\n$$\n\nThe stationary variance $\\operatorname{Var}(X_{\\infty})$ is the variance of this truncated normal distribution. The variance of a normal variable $Y \\sim N(\\mu, \\sigma^2)$ truncated to $[a, \\infty)$ is $\\sigma^2 \\left[1 + \\frac{\\alpha\\varphi(\\alpha)}{1-\\Phi(\\alpha)} - \\left(\\frac{\\varphi(\\alpha)}{1-\\Phi(\\alpha)}\\right)^2\\right]$, where $\\alpha = \\frac{a-\\mu}{\\sigma}$.\nWith our parameters, $\\alpha = \\frac{0-\\mu}{\\sigma_{\\text{OU}}} = -\\frac{\\mu}{\\sigma_{\\text{OU}}}$. Let $z_{\\mu} = \\frac{\\mu}{\\sigma_{\\text{OU}}} = \\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}$. Then $\\alpha = -z_{\\mu}$. The ratio becomes $\\frac{\\varphi(\\alpha)}{1-\\Phi(\\alpha)} = \\frac{\\varphi(-z_\\mu)}{1-\\Phi(-z_\\mu)} = \\frac{\\varphi(z_\\mu)}{\\Phi(z_\\mu)}$. Let's call this ratio $h(z_\\mu)$.\nThe variance is:\n$$\n\\operatorname{Var}(X_{\\infty}) = \\sigma_{\\text{OU}}^2 \\left[1 + (-z_{\\mu})h(z_{\\mu}) - (h(z_{\\mu}))^2\\right] = \\sigma_{\\text{OU}}^2 \\left[1 - z_{\\mu}h(z_{\\mu}) - h(z_{\\mu})^2\\right]\n$$\nSubstituting the expressions for $\\sigma_{\\text{OU}}$, $z_{\\mu}$, and $h(z_{\\mu})$:\n$$\n\\operatorname{Var}(X_{\\infty}) = \\frac{\\sigma^2}{2\\kappa} \\left[1 - \\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right) \\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} - \\left(\\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}\\right)^2\\right]\n$$\n\n**Comparison with the unconstrained Ornstein-Uhlenbeck process:**\nThe unconstrained OU process on $\\mathbb{R}$ has a stationary distribution $N(\\mu, \\sigma_{\\text{OU}}^2)$, with mean $\\mathbb{E}[X_\\infty]_{\\text{OU}} = \\mu$ and variance $\\operatorname{Var}(X_\\infty)_{\\text{OU}} = \\sigma_{\\text{OU}}^2 = \\frac{\\sigma^2}{2\\kappa}$.\n\n- **Mean:** The correction term to the mean, $\\frac{\\sigma}{\\sqrt{2\\kappa}} \\frac{\\varphi(\\cdot)}{\\Phi(\\cdot)}$, is strictly positive. Thus, $\\mathbb{E}[X_{\\infty}] > \\mu$. The reflection at $0$ prevents the process from taking negative values, effectively \"pushing\" the mass of the distribution to the right and increasing the mean.\n\n- **Variance:** The correction factor for the variance, $[1 - z_{\\mu}h(z_{\\mu}) - h(z_{\\mu})^2]$, is always less than $1$ for any finite $\\mu$. Thus, $\\operatorname{Var}(X_{\\infty}) < \\frac{\\sigma^2}{2\\kappa}$. The reflection truncates the left tail of the distribution, which reduces the overall spread of probability mass and decreases the variance. As $\\mu \\to \\infty$, the reflection becomes increasingly rare, and the mean and variance of the reflected process converge to those of the unconstrained process.\n\nFinal expressions:\n1.  Stationary density: $p_*(x) = \\frac{\\sqrt{\\kappa}}{\\sigma\\sqrt{\\pi} \\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(x-\\mu)^2\\right)$ for $x \\ge 0$.\n2.  Stationary mean: $\\mathbb{E}[X_{\\infty}] = \\mu + \\frac{\\sigma}{\\sqrt{2\\kappa}} \\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}$.\n3.  Stationary variance: $\\operatorname{Var}(X_{\\infty}) = \\frac{\\sigma^2}{2\\kappa} \\left[1 - \\mu\\frac{\\sqrt{2\\kappa}}{\\sigma} \\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} - \\left(\\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}\\right)^2\\right]$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\sqrt{\\kappa}}{\\sigma\\sqrt{\\pi} \\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(x-\\mu)^2\\right) & \\mu + \\frac{\\sigma}{\\sqrt{2\\kappa}} \\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} & \\frac{\\sigma^2}{2\\kappa} \\left[1 - \\mu\\frac{\\sqrt{2\\kappa}}{\\sigma} \\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)} - \\left(\\frac{\\varphi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}{\\Phi\\left(\\mu\\frac{\\sqrt{2\\kappa}}{\\sigma}\\right)}\\right)^2\\right]\n\\end{pmatrix}\n}\n$$", "id": "2996774"}]}