{"hands_on_practices": [{"introduction": "Our first practice explores the fundamental principle of local stability analysis using Lyapunov's second method. We will investigate how the stability of an equilibrium point is determined by a delicate balance between the deterministic drift pulling the system towards equilibrium and the stochastic noise pushing it away. This exercise [@problem_id:2969116] challenges you to determine a critical threshold for the scaling of state-dependent noise, revealing the precise point at which the stabilizing effect of the drift is overwhelmed.", "problem": "Consider the $n$-dimensional stochastic differential equation (SDE) in Itô form\n$$\ndX_{t}=-a\\,X_{t}\\,dt+b\\,\\|X_{t}\\|^{\\alpha}\\,dW_{t},\n$$\nwhere $a0$ and $b0$ are constants, $\\alpha\\in\\mathbb{R}$ is an exponent, $X_{t}\\in\\mathbb{R}^{n}$, and $W_{t}$ is an $n$-dimensional standard Brownian motion. Assume the diffusion coefficient is realized as the isotropic matrix field $G(x)=b\\,\\|x\\|^{\\alpha}I_{n}$ in a neighborhood of the origin, and that outside a small ball around the origin all coefficients are smoothly truncated to ensure global Lipschitz and linear growth conditions. The origin $x=0$ is an equilibrium for the drift. Using only the quadratic Lyapunov function $V(x)=\\|x\\|^{2}$, the definition of the infinitesimal generator, and Itô’s formula, analyze the sign of the Lyapunov drift near the origin to determine the threshold exponent $\\alpha_{c}$ that separates the regimes in which there exists a neighborhood of the origin where the Lyapunov drift is strictly negative definite (implying almost sure asymptotic stability via standard Lyapunov criteria) from the regimes in which such a neighborhood cannot exist due to dominance of the diffusion term. Your answer must be the exact value of the critical exponent $\\alpha_{c}$ as a single real number. Do not provide conditions in terms of inequalities; provide only the value of $\\alpha_{c}$.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- The $n$-dimensional stochastic differential equation (SDE) is given by $dX_{t}=-a\\,X_{t}\\,dt+b\\,\\|X_{t}\\|^{\\alpha}\\,dW_{t}$.\n- The constants are $a0$ and $b0$.\n- The exponent is $\\alpha\\in\\mathbb{R}$.\n- The state variable is $X_{t}\\in\\mathbb{R}^{n}$.\n- $W_{t}$ is an $n$-dimensional standard Brownian motion.\n- The diffusion matrix near the origin is $G(x)=b\\,\\|x\\|^{\\alpha}I_{n}$, where $I_n$ is the $n \\times n$ identity matrix.\n- The origin $x=0$ is an equilibrium point.\n- The analysis must use the quadratic Lyapunov function $V(x)=\\|x\\|^{2}$.\n- The methodology is restricted to using the infinitesimal generator and Itô's formula to analyze the Lyapunov drift, $\\mathcal{L}V(x)$, near the origin.\n- The objective is to find the critical exponent $\\alpha_{c}$ that separates regimes of stability from instability based on the sign of $\\mathcal{L}V(x)$ near the origin.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It poses a standard question in the field of stochastic stability theory, concerning the application of Lyapunov's second method to SDEs. The SDE structure is a common model for systems with state-dependent noise. All terms are well-defined, and the necessary data and constraints ($a0$, $b0$, specification of the Lyapunov function) are provided. The technical assumption of coefficient truncation ensures the global well-posedness of the SDE, allowing the analysis to focus on the local behavior near the equilibrium, which is the core of the problem. The problem is objective and free of ambiguity. It requests a specific, derivable quantity, $\\alpha_c$. No flaws listed in the validation criteria are present.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nThe given SDE is of the form $dX_t = f(X_t)dt + g(X_t)dW_t$, where the drift vector is $f(x) = -a x$ and the diffusion matrix is $g(x) = b \\|x\\|^{\\alpha} I_n$. We are asked to analyze the stability of the equilibrium point at the origin, $x=0$.\n\nWe use the specified Lyapunov function $V(x) = \\|x\\|^2 = x \\cdot x = \\sum_{i=1}^{n} x_i^2$. To analyze the stability, we must compute the infinitesimal generator $\\mathcal{L}$ applied to $V(x)$. The infinitesimal generator is defined as:\n$$\n\\mathcal{L}V(x) = \\nabla V(x) \\cdot f(x) + \\frac{1}{2} \\text{Tr}\\left[g(x) g(x)^T D^2V(x)\\right]\n$$\nwhere $\\nabla V(x)$ is the gradient of $V(x)$ and $D^2V(x)$ is its Hessian matrix.\n\nFirst, we compute the derivatives of $V(x)$:\n- The gradient of $V(x) = \\sum_{i=1}^{n} x_i^2$ is $\\nabla V(x) = \\left(\\frac{\\partial V}{\\partial x_1}, \\dots, \\frac{\\partial V}{\\partial x_n}\\right) = (2x_1, \\dots, 2x_n) = 2x$.\n- The Hessian matrix of $V(x)$ has components $(D^2V(x))_{ij} = \\frac{\\partial^2 V}{\\partial x_i \\partial x_j} = \\frac{\\partial}{\\partial x_i}(2x_j) = 2\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. Thus, the Hessian matrix is $D^2V(x) = 2I_n$.\n\nNext, we compute the two terms of the infinitesimal generator.\n\nThe first term, the drift contribution, is:\n$$\n\\nabla V(x) \\cdot f(x) = (2x) \\cdot (-ax) = -2a (x \\cdot x) = -2a \\|x\\|^2\n$$\n\nThe second term, the diffusion contribution, requires us to first find the matrix product $g(x)g(x)^T$:\n$$\ng(x) = b \\|x\\|^{\\alpha} I_n\n$$\n$$\ng(x)^T = \\left(b \\|x\\|^{\\alpha} I_n\\right)^T = b \\|x\\|^{\\alpha} I_n\n$$\n$$\ng(x) g(x)^T = \\left(b \\|x\\|^{\\alpha} I_n\\right) \\left(b \\|x\\|^{\\alpha} I_n\\right) = b^2 \\|x\\|^{2\\alpha} I_n^2 = b^2 \\|x\\|^{2\\alpha} I_n\n$$\nNow we can compute the trace for the diffusion contribution:\n$$\n\\frac{1}{2} \\text{Tr}\\left[g(x) g(x)^T D^2V(x)\\right] = \\frac{1}{2} \\text{Tr}\\left[\\left(b^2 \\|x\\|^{2\\alpha} I_n\\right) (2I_n)\\right] = \\frac{1}{2} \\text{Tr}\\left[2b^2 \\|x\\|^{2\\alpha} I_n\\right]\n$$\nUsing the property that $\\text{Tr}(c A) = c \\text{Tr}(A)$ for a scalar $c$, we have:\n$$\n\\frac{1}{2} \\left(2b^2 \\|x\\|^{2\\alpha}\\right) \\text{Tr}[I_n] = b^2 \\|x\\|^{2\\alpha} \\cdot n = nb^2 \\|x\\|^{2\\alpha}\n$$\n\nCombining the drift and diffusion terms, we obtain the expression for the Lyapunov drift, $\\mathcal{L}V(x)$:\n$$\n\\mathcal{L}V(x) = -2a \\|x\\|^2 + nb^2 \\|x\\|^{2\\alpha}\n$$\n\nThe problem requires us to determine the condition for which there exists a neighborhood of the origin where the Lyapunov drift is strictly negative definite, i.e., $\\mathcal{L}V(x)  0$ for all $x \\neq 0$ in that neighborhood. Let's analyze the sign of $\\mathcal{L}V(x)$ as $x \\to 0$ (which is equivalent to $\\|x\\| \\to 0$).\n\nWe can factor the expression for $\\mathcal{L}V(x)$:\n$$\n\\mathcal{L}V(x) = \\|x\\|^2 \\left(-2a + nb^2 \\|x\\|^{2\\alpha-2}\\right)\n$$\nFor $x \\neq 0$, the term $\\|x\\|^2$ is strictly positive. Therefore, the sign of $\\mathcal{L}V(x)$ is determined by the sign of the expression in the parenthesis: $-2a + nb^2 \\|x\\|^{2\\alpha-2}$.\n\nWe analyze this expression in the limit $\\|x\\| \\to 0$. The behavior depends on the sign of the exponent $2\\alpha-2$.\n\n- Case 1: $2\\alpha-2  0$, which means $\\alpha  1$.\nIn this case, as $\\|x\\| \\to 0$, the term $\\|x\\|^{2\\alpha-2} \\to 0$. The expression approaches:\n$$\n\\lim_{\\|x\\| \\to 0} \\left(-2a + nb^2 \\|x\\|^{2\\alpha-2}\\right) = -2a\n$$\nSince $a  0$, $-2a$ is strictly negative. By the properties of limits, for any sufficiently small neighborhood of the origin (excluding the origin itself), the expression $-2a + nb^2 \\|x\\|^{2\\alpha-2}$ will be negative. This implies $\\mathcal{L}V(x)  0$ in that neighborhood. The drift term (order $\\|x\\|^2$) dominates the diffusion term (order $\\|x\\|^{2\\alpha}$) because $2  2\\alpha$.\n\n- Case 2: $2\\alpha-2  0$, which means $\\alpha  1$.\nIn this case, as $\\|x\\| \\to 0$, the term $\\|x\\|^{2\\alpha-2} \\to +\\infty$ since the exponent is negative. The expression approaches:\n$$\n\\lim_{\\|x\\| \\to 0} \\left(-2a + nb^2 \\|x\\|^{2\\alpha-2}\\right) = +\\infty\n$$\nThis means that for any neighborhood of the origin, we can find $x$ close enough to $0$ such that the expression is positive. Consequently, $\\mathcal{L}V(x)  0$ for $x$ sufficiently close to the origin. A neighborhood where the Lyapunov drift is strictly negative definite cannot exist. The diffusion term (order $\\|x\\|^{2\\alpha}$) dominates the drift term (order $\\|x\\|^2$) because $2\\alpha  2$.\n\n- Case 3: $2\\alpha-2 = 0$, which means $\\alpha = 1$.\nIn this case, $\\|x\\|^{2\\alpha-2} = \\|x\\|^0 = 1$ for all $x \\neq 0$. The expression becomes constant:\n$$\n-2a + nb^2\n$$\nThe sign of $\\mathcal{L}V(x)$ is independent of $\\|x\\|$ and is determined by the specific values of the parameters $a$, $b$, and $n$. A neighborhood with strictly negative definite drift can exist only if $-2a + nb^2  0$. This condition is not guaranteed to hold for all valid parameters.\n\nThe problem asks for the threshold $\\alpha_c$ that separates the regime where a neighborhood with negative definite drift is guaranteed to exist (for any choice of $a0$, $b0$) from the regime where it cannot exist. This transition occurs precisely when the dominance between the drift and diffusion terms shifts. This shift corresponds to the exponents of $\\|x\\|$ being equal:\n$$\n2 = 2\\alpha\n$$\nSolving for $\\alpha$ gives the critical value:\n$$\n\\alpha_c = 1\n$$\nFor $\\alpha  \\alpha_c=1$, the stabilizing drift term always dominates near the origin. For $\\alpha  \\alpha_c=1$, the destabilizing diffusion term always dominates near the origin. Therefore, $\\alpha_c=1$ is the threshold exponent.", "answer": "$$\n\\boxed{1}\n$$", "id": "2969116"}, {"introduction": "Having established the basics of Lyapunov analysis, we now turn to a more subtle aspect of stochastic dynamics. A system can be recurrent, revisiting a neighborhood of an equilibrium infinitely often, without actually converging to it. This practice [@problem_id:2969157] presents a compelling one-dimensional example where a restoring drift competes with persistent noise, leading to ergodic behavior on a bounded interval rather than almost sure asymptotic stability. By analyzing this system, you will gain a deeper appreciation for the crucial differences between recurrence, ergodicity, and convergence to an equilibrium.", "problem": "Consider the one-dimensional stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t \\;=\\; -\\,X_t\\,\\mathrm{d}t \\;+\\; \\sqrt{2\\bigl(1 - X_t^2\\bigr)}\\,\\mathrm{d}W_t,\n\\qquad X_0 \\in (-1,1),\n$$\nwhere $W_t$ is a standard Brownian motion. Select all statements that are correct, and justify your choice based on first principles such as Itô calculus, the generator and its adjoint, boundary classification for one-dimensional diffusions, and precise definitions of almost sure (a.s.) asymptotic stability, recurrence, and ergodicity.\n\nA. The equilibrium $x=0$ is almost surely asymptotically stable: for every initial condition $X_0$ in a neighborhood of $0$, one has $\\lim_{t\\to\\infty} X_t = 0$ almost surely.\n\nB. For any $X_0 \\in (-1,1)$, the trajectory is almost surely bounded and recurrent in any neighborhood of $0$, but it does not converge to $0$; persistent noise prevents a.s. convergence.\n\nC. The process admits a unique invariant distribution on $(-1,1)$ with density\n$$\np(x) \\;=\\; \\frac{1}{\\pi}\\,\\frac{1}{\\sqrt{1 - x^2}},\n\\qquad x \\in (-1,1),\n$$\nand is ergodic with respect to this invariant distribution.\n\nD. Starting from any $X_0 \\in (-1,1)$, the boundary points $\\pm 1$ are never hit.\n\nE. The Lyapunov function $V(x) = x^2$ has negative drift under the generator on $(-1,1)$, which implies that $x=0$ is almost surely asymptotically stable.", "solution": "The given one-dimensional stochastic differential equation (SDE) is\n$$\n\\mathrm{d}X_t = -X_t\\,\\mathrm{d}t + \\sqrt{2(1 - X_t^2)}\\,\\mathrm{d}W_t, \\qquad X_0 \\in (-1,1).\n$$\nThis is an Itô diffusion of the form $\\mathrm{d}X_t = b(X_t)\\,\\mathrm{d}t + \\sigma(X_t)\\,\\mathrm{d}W_t$, with drift coefficient $b(x) = -x$ and diffusion coefficient $\\sigma(x) = \\sqrt{2(1-x^2)}$. The process is defined on the state space $I = (-1,1)$. The squared diffusion coefficient is $a(x) = \\sigma(x)^2 = 2(1-x^2)$.\n\nA powerful method to analyze this specific SDE is to find a transformation that simplifies it. Consider the function $F(x) = \\arcsin(x)$. Its derivatives are $F'(x) = (1-x^2)^{-1/2}$ and $F''(x) = x(1-x^2)^{-3/2}$. Let $Y_t = F(X_t) = \\arcsin(X_t)$. By Itô's formula, the dynamics of $Y_t$ are given by:\n$$\n\\mathrm{d}Y_t = F'(X_t)\\,\\mathrm{d}X_t + \\frac{1}{2}F''(X_t)(\\mathrm{d}X_t)^2.\n$$\nSubstituting $\\mathrm{d}X_t$ and $(\\mathrm{d}X_t)^2 = \\sigma(X_t)^2\\,\\mathrm{d}t = 2(1-X_t^2)\\,\\mathrm{d}t$:\n$$\n\\mathrm{d}Y_t = \\frac{1}{\\sqrt{1-X_t^2}}\\left(-X_t\\,\\mathrm{d}t + \\sqrt{2(1-X_t^2)}\\,\\mathrm{d}W_t\\right) + \\frac{1}{2}\\frac{X_t}{(1-X_t^2)^{3/2}}\\left(2(1-X_t^2)\\,\\mathrm{d}t\\right)\n$$\n$$\n\\mathrm{d}Y_t = \\left(-\\frac{X_t}{\\sqrt{1-X_t^2}} + \\frac{X_t}{\\sqrt{1-X_t^2}}\\right)\\mathrm{d}t + \\frac{\\sqrt{2(1-X_t^2)}}{\\sqrt{1-X_t^2}}\\,\\mathrm{d}W_t\n$$\n$$\n\\mathrm{d}Y_t = \\sqrt{2}\\,\\mathrm{d}W_t.\n$$\nThis remarkably simple SDE can be integrated directly: $Y_t = Y_0 + \\sqrt{2}W_t$, where $Y_0 = \\arcsin(X_0)$. Since $X_0 \\in (-1,1)$, we have $Y_0 \\in (-\\pi/2, \\pi/2)$.\nThe solution for $X_t$ is therefore explicit:\n$$\nX_t = \\sin(Y_t) = \\sin(Y_0 + \\sqrt{2}W_t).\n$$\nThis explicit solution allows for a direct evaluation of the given options.\n\nAlternatively, we can use the general theory of one-dimensional diffusions. The infinitesimal generator of the process $X_t$ is:\n$$\n\\mathcal{L} = b(x)\\frac{\\mathrm{d}}{\\mathrm{d}x} + \\frac{1}{2}a(x)\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2} = -x\\frac{\\mathrm{d}}{\\mathrm{d}x} + (1-x^2)\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}.\n$$\n\nNow we evaluate each statement.\n\n**D. Starting from any $X_0 \\in (-1,1)$, the boundary points $\\pm 1$ are never hit.**\nThe boundary point $x=1$ is hit if and only if the process $Y_t = \\arcsin(X_t)$ hits the value $\\arcsin(1) = \\pi/2$. The process $Y_t = Y_0 + \\sqrt{2}W_t$ is a standard Brownian motion (scaled by $\\sqrt{2}$ and shifted by $Y_0$). A fundamental property of Brownian motion is that it is certain to hit any level. Therefore, for any $Y_0 \\in (-\\pi/2, \\pi/2)$, $Y_t$ will hit $\\pi/2$ in finite time with probability $1$. Consequently, $X_t$ will hit $1$ in finite time almost surely. The same argument applies to the boundary point $-1$.\nAlternatively, using boundary classification, we compute the scale density $s'(x) = \\exp\\left(-\\int \\frac{2b(y)}{a(y)}\\mathrm{d}y\\right)$ and speed density $m'(x) = \\frac{1}{a(x)s'(x)}$.\n$$\n\\frac{2b(y)}{a(y)} = \\frac{-2y}{2(1-y^2)} = \\frac{-y}{1-y^2} \\implies s'(x) = \\exp\\left(\\int \\frac{y}{1-y^2}\\mathrm{d}y\\right) \\propto \\frac{1}{\\sqrt{1-x^2}}.\n$$\nThe speed density is $m'(x) = \\frac{1}{2(1-x^2)} \\sqrt{1-x^2} = \\frac{1}{2\\sqrt{1-x^2}}$.\nTo classify a boundary, e.g., $c=1$, we check the integrability of $s'$ and $m'$ near it. Let's take a reference point $x_0=0$.\n$\\int_0^1 s'(x)\\,\\mathrm{d}x \\propto \\int_0^1 \\frac{1}{\\sqrt{1-x^2}}\\,\\mathrm{d}x = [\\arcsin(x)]_0^1 = \\pi/2  \\infty$.\n$\\int_0^1 m'(x)\\,\\mathrm{d}x = \\int_0^1 \\frac{1}{2\\sqrt{1-x^2}}\\,\\mathrm{d}x = \\frac{1}{2}[\\arcsin(x)]_0^1 = \\pi/4  \\infty$.\nSince both integrals are finite, the boundary $x=1$ is a **regular** boundary. A regular boundary is reachable in finite time. By symmetry, $x=-1$ is also a regular boundary.\nVerdict: **Incorrect**.\n\n**C. The process admits a unique invariant distribution on $(-1,1)$ with density $p(x) = \\frac{1}{\\pi}\\,\\frac{1}{\\sqrt{1 - x^2}}, \\qquad x \\in (-1,1)$, and is ergodic with respect to this invariant distribution.**\nThe existence of a unique invariant distribution and ergodicity for a 1D diffusion on $(l,r)$ is guaranteed if the boundaries are inaccessible or reflecting, and the total speed measure on $(l,r)$ is finite.\nThe total speed measure is $M(-1,1) = \\int_{-1}^1 m'(x)\\,\\mathrm{d}x = \\int_{-1}^1 \\frac{1}{2\\sqrt{1-x^2}}\\,\\mathrm{d}x = \\frac{1}{2}[\\arcsin(x)]_{-1}^1 = \\frac{1}{2}(\\pi/2 - (-\\pi/2)) = \\frac{\\pi}{2}  \\infty$.\nThe drift $b(x)=-x$ is directed inwards at the boundaries ($b(1)=-10$, $b(-1)=10$), and the diffusion $\\sigma(x)$ vanishes there. This creates a reflecting behavior, confining the process to $[-1,1]$. The conditions for ergodicity are met.\nThe invariant probability density $p(x)$ satisfies the stationary Fokker-Planck equation, which implies its logarithm's derivative is $\\frac{p'(x)}{p(x)} = \\frac{2b(x)-a'(x)}{a(x)}$.\nWith $a(x) = 2(1-x^2)$, we have $a'(x)=-4x$.\n$$\n\\frac{p'(x)}{p(x)} = \\frac{2(-x) - (-4x)}{2(1-x^2)} = \\frac{2x}{2(1-x^2)} = \\frac{x}{1-x^2}.\n$$\nIntegrating gives $\\ln p(x) = -\\frac{1}{2}\\ln(1-x^2) + K$, so $p(x) = C(1-x^2)^{-1/2}$. Normalizing this density:\n$$\n\\int_{-1}^1 C(1-x^2)^{-1/2} \\,\\mathrm{d}x = C[\\arcsin(x)]_{-1}^1 = C\\pi = 1 \\implies C = 1/\\pi.\n$$\nThe unique invariant density is $p(x) = \\frac{1}{\\pi\\sqrt{1-x^2}}$, which is the arcsin distribution. This matches the statement. The process is indeed ergodic.\nThis can also be seen from the explicit solution $X_t = \\sin(Y_t)$. As $t \\to \\infty$, $Y_t = Y_0 + \\sqrt{2}W_t$ becomes diffuse over $\\mathbb{R}$. The distribution of $Y_t \\pmod{2\\pi}$ approaches the uniform distribution on $[-\\pi, \\pi]$. The distribution of $X_t = \\sin(Y_t)$ thus approaches that of $\\sin(U)$ where $U \\sim \\mathrm{Uniform}[-\\pi, \\pi]$, which is precisely the arcsin distribution.\nVerdict: **Correct**.\n\n**A. The equilibrium $x=0$ is almost surely asymptotically stable: for every initial condition $X_0$ in a neighborhood of $0$, one has $\\lim_{t\\to\\infty} X_t = 0$ almost surely.**\nFrom the explicit solution $X_t = \\sin(Y_0 + \\sqrt{2}W_t)$, we see that the process does not converge to $0$. The argument of the sine function, $Y_t$, undergoes a Brownian motion and does not converge to a multiple of $\\pi$. Instead, it explores the entire real line. Consequently, $X_t$ oscillates continuously between $-1$ and $1$. The limit $\\lim_{t\\to\\infty} X_t$ does not exist almost surely. Therefore, the equilibrium $x=0$ is not a.s. asymptotically stable.\nVerdict: **Incorrect**.\n\n**B. For any $X_0 \\in (-1,1)$, the trajectory is almost surely bounded and recurrent in any neighborhood of $0$, but it does not converge to $0$; persistent noise prevents a.s. convergence.**\nLet's analyze the parts of this statement:\n1.  **Bounded:** The solution $X_t = \\sin(Y_0 + \\sqrt{2}W_t)$ is always in the interval $[-1,1]$, so it is almost surely bounded.\n2.  **Does not converge to $0$:** As established in the analysis of option A, this is true.\n3.  **Recurrent in any neighborhood of $0$:** This means that for any $\\epsilon  0$, the process $X_t$ enters the interval $(-\\epsilon, \\epsilon)$ infinitely often with probability $1$. This is equivalent to $Y_t = \\arcsin(X_t)$ entering the set $\\bigcup_{k \\in \\mathbb{Z}} (k\\pi - \\delta, k\\pi + \\delta)$ for some $\\delta  0$ infinitely often. Since $Y_t$ is a Brownian motion, which is point-recurrent in one dimension, it visits any interval $(a,b)$ on the real line infinitely often. Thus, it will visit neighborhoods of $k\\pi$ for every integer $k$ infinitely often. This implies $X_t$ is recurrent in any neighborhood of $0$.\nAll claims in this statement are correct.\nVerdict: **Correct**.\n\n**E. The Lyapunov function $V(x) = x^2$ has negative drift under the generator on $(-1,1)$, which implies that $x=0$ is almost surely asymptotically stable.**\nThe drift of a function $V(x)$ under the process is given by the action of the generator, $\\mathcal{L}V(x)$. Let's compute this for $V(x)=x^2$:\n$$\n\\mathcal{L}V(x) = \\mathcal{L}(x^2) = -x\\frac{\\mathrm{d}}{\\mathrm{d}x}(x^2) + (1-x^2)\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}(x^2)\n$$\n$$\n\\mathcal{L}(x^2) = -x(2x) + (1-x^2)(2) = -2x^2 + 2 - 2x^2 = 2 - 4x^2 = 2(1-2x^2).\n$$\nThe statement claims that $\\mathcal{L}(x^2)$ is negative on $(-1,1)$. However, $\\mathcal{L}(x^2)  0$ only if $1-2x^2  0$, which means $x^2  1/2$, or $|x|  1/\\sqrt{2}$. For $|x|  1/\\sqrt{2}$, the drift $\\mathcal{L}(x^2)$ is positive. This positive drift near the origin pushes the process away from $x=0$, which is the opposite of what is required for asymptotic stability. The premise of the statement is false.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{BC}$$", "id": "2969157"}, {"introduction": "While Lyapunov functions provide a powerful qualitative tool, a more quantitative measure of stability for linear systems is offered by Lyapunov exponents. These exponents measure the long-term average exponential rate of separation or convergence of trajectories. In this final practice [@problem_id:2969154], you will calculate the Lyapunov exponents for a two-dimensional linear SDE with both rotational and noisy components, providing a direct and unambiguous criterion for determining almost sure asymptotic stability.", "problem": "Consider the two-dimensional linear Itô Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_{t} = A X_{t} \\,\\mathrm{d}t + \\beta X_{t} \\,\\mathrm{d}W_{t},\n$$\nwhere $X_{t} \\in \\mathbb{R}^{2}$, $W_{t}$ is a one-dimensional standard Brownian motion, and the constant matrices and parameters are given by\n$$\nA = -\\alpha I + \\omega J,\\quad I = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix},\\quad J = \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix},\n$$\nwith $\\alpha = \\frac{3}{5}$, $\\beta = 1$, and $\\omega = \\sqrt{2}$. Assume $X_{0} \\in \\mathbb{R}^{2}\\setminus\\{0\\}$.\n\nStarting from the fundamental definitions of Itô calculus and the notion of Lyapunov exponents for random linear dynamical systems, derive the almost sure Lyapunov exponents of this SDE and use them to determine whether trajectories $X_{t}$ converge to the origin almost surely as $t \\to \\infty$ (almost sure asymptotic stability). Let $\\lambda_{1}$ and $\\lambda_{2}$ denote the two Lyapunov exponents, ordered so that $\\lambda_{1} \\ge \\lambda_{2}$. Let $\\chi$ be the indicator of almost sure asymptotic stability, defined by $\\chi=1$ if $X_{t}\\to 0$ almost surely and $\\chi=0$ otherwise. Express your final answer as a row matrix containing $\\lambda_{1}$, $\\lambda_{2}$, and $\\chi$. Use exact values; no rounding is required.", "solution": "The user wants me to solve the problem. I will now proceed with solving it.\nThe problem is valid as it is scientifically grounded, well-posed, and objective. It is a standard problem in the theory of stochastic differential equations (SDEs), with all necessary information provided and no internal contradictions.\n\nThe given SDE is a two-dimensional linear Itô equation:\n$$\n\\mathrm{d}X_{t} = A X_{t} \\,\\mathrm{d}t + \\beta X_{t} \\,\\mathrm{d}W_{t}\n$$\nwhere $X_{t} \\in \\mathbb{R}^{2}$ and $W_{t}$ is a one-dimensional standard Brownian motion. The coefficient matrices are given by $A = -\\alpha I + \\omega J$ and the diffusion is determined by the scalar $\\beta$. In matrix form, the SDE is:\n$$\n\\mathrm{d}X_{t} = A X_{t} \\,\\mathrm{d}t + B X_{t} \\,\\mathrm{d}W_{t}\n$$\nwhere $A = -\\alpha I + \\omega J = \\begin{pmatrix} -\\alpha  -\\omega \\\\ \\omega  -\\alpha \\end{pmatrix}$ and $B = \\beta I = \\begin{pmatrix} \\beta  0 \\\\ 0  \\beta \\end{pmatrix}$. The parameters are given as $\\alpha = \\frac{3}{5}$, $\\beta = 1$, and $\\omega = \\sqrt{2}$.\n\nThis is a linear SDE with constant coefficients. A significant simplification arises if the matrices $A$ and $B$ commute, i.e., if $[A, B] = AB - BA = 0$. Let us check this condition:\n$$\n[A, B] = [-\\alpha I + \\omega J, \\beta I]\n$$\nUsing the linearity of the commutator and the fact that any matrix commutes with the identity matrix $I$:\n$$\n[A, B] = -\\alpha\\beta [I, I] + \\omega\\beta [J, I] = -\\alpha\\beta(0) + \\omega\\beta(0) = 0\n$$\nSince the matrices commute, the solution to the SDE can be expressed in a form analogous to the deterministic case. The fundamental solution matrix $\\Phi_t$, which satisfies $\\mathrm{d}\\Phi_t = A \\Phi_t \\mathrm{d}t + B \\Phi_t \\mathrm{d}W_t$ with $\\Phi_0 = I$, is given by:\n$$\n\\Phi_t = \\exp\\left( \\left(A - \\frac{1}{2}B^2\\right)t + B W_t \\right)\n$$\nLet's compute the argument of the exponential:\nThe matrix $B^2$ is $(\\beta I)^2 = \\beta^2 I$.\nThe exponent matrix is:\n$$\n\\left(A - \\frac{1}{2}B^2\\right)t + B W_t = \\left( (-\\alpha I + \\omega J) - \\frac{1}{2}\\beta^2 I \\right)t + (\\beta I) W_t\n$$\n$$\n= \\left( \\left(-\\alpha - \\frac{\\beta^2}{2}\\right)I + \\omega J \\right)t + \\beta W_t I\n$$\n$$\n= \\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t I + \\omega t J + \\beta W_t I\n$$\nSince the identity matrix $I$ and the matrix $J$ commute ($[I, J]=0$), we can separate the matrix exponential:\n$$\n\\Phi_t = \\exp\\left( \\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t I \\right) \\exp(\\omega t J) \\exp(\\beta W_t I)\n$$\nThe exponential of a scaled identity matrix is a scaled identity matrix: $\\exp(cI) = e^c I$.\n$$\n\\exp\\left( \\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t I \\right) = \\exp\\left( \\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t \\right) I\n$$\n$$\n\\exp(\\beta W_t I) = \\exp(\\beta W_t) I\n$$\nThe exponential of the scaled matrix $J$ is a rotation matrix. Since $J^2 = -I$, we have:\n$$\n\\exp(\\omega t J) = \\sum_{k=0}^\\infty \\frac{(\\omega t)^k J^k}{k!} = I \\cos(\\omega t) + J \\sin(\\omega t) = \\begin{pmatrix} \\cos(\\omega t)  -\\sin(\\omega t) \\\\ \\sin(\\omega t)  \\cos(\\omega t) \\end{pmatrix}\n$$\nThis is a rotation matrix, which is orthogonal, i.e., it preserves norms. Let's call it $R(\\omega t)$.\nCombining these parts, the fundamental solution matrix is:\n$$\n\\Phi_t = \\exp\\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t \\cdot \\exp(\\beta W_t) \\cdot R(\\omega t)\n$$\nThe solution to the SDE for an initial condition $X_0 \\in \\mathbb{R}^2 \\setminus \\{0\\}$ is $X_t = \\Phi_t X_0$.\nThe Lyapunov exponents are defined by the growth rates of the norm of the solution:\n$$\n\\lambda = \\lim_{t\\to\\infty} \\frac{1}{t} \\ln \\|X_t\\|\n$$\nLet's compute the norm of $X_t$:\n$$\n\\|X_t\\| = \\|\\Phi_t X_0\\| = \\left\\| \\exp\\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t \\cdot \\exp(\\beta W_t) \\cdot R(\\omega t) X_0 \\right\\|\n$$\nThe terms $\\exp((-\\alpha - \\frac{\\beta^2}{2})t)$ and $\\exp(\\beta W_t)$ are scalars. The matrix $R(\\omega t)$ is orthogonal, so $\\|R(\\omega t) X_0\\| = \\|X_0\\|$.\n$$\n\\|X_t\\| = \\exp\\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t \\cdot \\exp(\\beta W_t) \\cdot \\|X_0\\|\n$$\nNow, we take the logarithm and divide by $t$:\n$$\n\\frac{1}{t} \\ln \\|X_t\\| = \\frac{1}{t} \\left[ \\left(-\\alpha - \\frac{\\beta^2}{2}\\right)t + \\beta W_t + \\ln \\|X_0\\| \\right]\n$$\n$$\n= -\\alpha - \\frac{\\beta^2}{2} + \\frac{\\beta W_t}{t} + \\frac{\\ln \\|X_0\\|}{t}\n$$\nTaking the limit as $t \\to \\infty$:\n$$\n\\lambda = \\lim_{t\\to\\infty} \\left(-\\alpha - \\frac{\\beta^2}{2} + \\frac{\\beta W_t}{t} + \\frac{\\ln \\|X_0\\|}{t}\\right)\n$$\nBy the Law of the Iterated Logarithm for Brownian motion, $\\lim_{t\\to\\infty} \\frac{W_t}{t} = 0$ almost surely. The term $\\frac{\\ln \\|X_0\\|}{t}$ also tends to $0$. Therefore, the limit is:\n$$\n\\lambda = -\\alpha - \\frac{\\beta^2}{2} \\quad \\text{a.s.}\n$$\nThis growth rate is independent of the initial vector $X_0$. For a two-dimensional system, there are two Lyapunov exponents, $\\lambda_1$ and $\\lambda_2$. Since the growth rate is the same for any direction in the state space, the two exponents must be equal.\n$$\n\\lambda_1 = \\lambda_2 = -\\alpha - \\frac{\\beta^2}{2}\n$$\nNow, we substitute the given values $\\alpha = \\frac{3}{5}$ and $\\beta = 1$:\n$$\n\\lambda_1 = \\lambda_2 = -\\frac{3}{5} - \\frac{1^2}{2} = -\\frac{3}{5} - \\frac{1}{2} = -\\frac{6}{10} - \\frac{5}{10} = -\\frac{11}{10}\n$$\nThe almost sure asymptotic stability of the trivial solution $X_t = 0$ is determined by the sign of the top Lyapunov exponent, $\\lambda_1$. The system is almost surely asymptotically stable if and only if $\\lambda_1  0$.\nIn our case, $\\lambda_1 = -\\frac{11}{10}  0$.\nThus, the trajectories converge to the origin almost surely, i.e., $\\lim_{t\\to\\infty} X_t = 0$ a.s.\nThe indicator variable for stability, $\\chi$, is defined as $\\chi=1$ if the system is almost surely asymptotically stable, and $\\chi=0$ otherwise. Based on our result, $\\chi = 1$.\n\nThe final answer is composed of the ordered Lyapunov exponents $\\lambda_1, \\lambda_2$ (where $\\lambda_1 \\ge \\lambda_2$) and the stability indicator $\\chi$.\n$\\lambda_1 = -\\frac{11}{10}$\n$\\lambda_2 = -\\frac{11}{10}$\n$\\chi = 1$\nThis is expressed as a row matrix.", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{11}{10}  -\\frac{11}{10}  1 \\end{pmatrix}}\n$$", "id": "2969154"}]}