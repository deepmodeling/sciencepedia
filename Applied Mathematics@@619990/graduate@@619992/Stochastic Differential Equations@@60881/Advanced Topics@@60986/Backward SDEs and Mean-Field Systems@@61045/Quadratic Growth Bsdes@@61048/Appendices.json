{"hands_on_practices": [{"introduction": "We begin with a cornerstone exercise involving a class of explicitly solvable quadratic BSDEs. This practice guides you through the application of the exponential transformation, a powerful technique that linearizes the equation and reveals its connection to martingale theory [@problem_id:2991941]. By mastering this method, you will gain fundamental skills for analyzing and solving these important stochastic equations.", "problem": "Let $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t\\in[0,T]},\\mathbb{P})$ be a filtered probability space supporting a one-dimensional standard Brownian motion $W=\\{W_t\\}_{t\\in[0,T]}$, with fixed horizon $T0$. Fix a constant $\\gamma0$ and a constant $\\theta\\in\\mathbb{R}$. Consider the backward stochastic differential equation (BSDE) with terminal condition $\\xi=\\theta W_T$ and generator $g(z)=\\frac{\\gamma}{2}z^2$, in the sense that the pair $(Y,Z)$ is adapted and satisfies, for all $t\\in[0,T]$,\n$$\nY_t=\\xi+\\int_t^T \\frac{\\gamma}{2}\\,Z_s^2\\,ds-\\int_t^T Z_s\\,dW_s,\n$$\nwith $Y_T=\\xi$ and $Z$ square-integrable. Assume existence and uniqueness of a solution $(Y,Z)$ in the usual spaces.\n\nStarting from the fundamental definitions of a backward stochastic differential equation, the martingale representation via the Clark–Ocone formula, the Gaussian moment generating function of Brownian motion, and the definition of the Doléans–Dade stochastic exponential for continuous martingales, derive the explicit closed-form expression for the integrand process $Z=\\{Z_t\\}_{t\\in[0,T]}$ associated with the unique solution $(Y,Z)$ to the BSDE above.\n\nYour final answer must be a single analytical expression. No rounding is required, and no units are involved.", "solution": "The problem asks for the explicit closed-form expression for the integrand process $Z=\\{Z_t\\}_{t\\in[0,T]}$ of the BSDE:\n$$\nY_t = \\theta W_T + \\int_t^T \\frac{\\gamma}{2} Z_s^2 ds - \\int_t^T Z_s dW_s\n$$\nwhere $\\gamma > 0$ and $\\theta \\in \\mathbb{R}$ are constants, and $W$ is a standard one-dimensional Brownian motion. The terminal time is $T>0$. In differential form, the BSDE is given by:\n$$\ndY_t = -\\frac{\\gamma}{2} Z_t^2 dt + Z_t dW_t\n$$\nwith the terminal condition $Y_T = \\xi = \\theta W_T$.\n\nWe will solve this by using a change of variable that linearizes the problem, a technique related to the Hopf-Cole transformation for the associated partial differential equation. This method elegantly incorporates the ideas of stochastic exponentials and martingale representations as suggested by the problem statement.\n\nLet us define a new process $V_t$ through the transformation $V_t = \\exp(\\gamma Y_t)$. We apply Itô's formula to find the dynamics of $V_t$.\nLet $f(y) = \\exp(\\gamma y)$. Then $f'(y) = \\gamma \\exp(\\gamma y)$ and $f''(y) = \\gamma^2 \\exp(\\gamma y)$.\nThus, $V_t = f(Y_t)$ and its differential is:\n$$\ndV_t = f'(Y_t) dY_t + \\frac{1}{2} f''(Y_t) d\\langle Y \\rangle_t\n$$\nSubstituting $f'(Y_t) = \\gamma V_t$ and $f''(Y_t) = \\gamma^2 V_t$:\n$$\ndV_t = \\gamma V_t dY_t + \\frac{1}{2} \\gamma^2 V_t d\\langle Y \\rangle_t\n$$\nFrom the BSDE dynamics, we have $dY_t = -\\frac{\\gamma}{2} Z_t^2 dt + Z_t dW_t$. The quadratic variation process of $Y$ is given by $d\\langle Y \\rangle_t = (Z_t)^2 dt = Z_t^2 dt$.\nSubstituting these into the expression for $dV_t$:\n$$\ndV_t = \\gamma V_t \\left(-\\frac{\\gamma}{2} Z_t^2 dt + Z_t dW_t\\right) + \\frac{1}{2} \\gamma^2 V_t (Z_t^2 dt)\n$$\n$$\ndV_t = -\\frac{\\gamma^2}{2} V_t Z_t^2 dt + \\gamma V_t Z_t dW_t + \\frac{\\gamma^2}{2} V_t Z_t^2 dt\n$$\nThe drift terms cancel out, leaving a pure stochastic integral:\n$$\ndV_t = \\gamma V_t Z_t dW_t\n$$\nThis equation shows that $V_t$ is a local martingale. Given the assumption of existence and uniqueness of the solution to the BSDE in the usual spaces (which implies certain integrability conditions), $V_t$ is a true martingale. The process $V_t$ is a specific type of stochastic exponential, a key concept hinted at in the problem.\n\nAs $V_t$ is a martingale, it satisfies the property $V_t = \\mathbb{E}[V_T|\\mathcal{F}_t]$. The terminal value $V_T$ is determined by the terminal condition $Y_T = \\xi = \\theta W_T$:\n$$\nV_T = \\exp(\\gamma Y_T) = \\exp(\\gamma \\theta W_T)\n$$\nTherefore, we can write $V_t$ as a conditional expectation:\n$$\nV_t = \\mathbb{E}[\\exp(\\gamma \\theta W_T) | \\mathcal{F}_t]\n$$\nTo evaluate this conditional expectation, we use the property that for $t \\leq T$, $W_T = W_t + (W_T - W_t)$, where the increment $(W_T - W_t)$ is independent of the filtration $\\mathcal{F}_t$ and has a normal distribution $\\mathcal{N}(0, T-t)$.\n$$\nV_t = \\mathbb{E}[\\exp(\\gamma \\theta (W_t + W_T - W_t)) | \\mathcal{F}_t]\n$$\nSince $W_t$ is $\\mathcal{F}_t$-measurable and $(W_T-W_t)$ is independent of $\\mathcal{F}_t$:\n$$\nV_t = \\exp(\\gamma \\theta W_t) \\mathbb{E}[\\exp(\\gamma \\theta (W_T - W_t)) | \\mathcal{F}_t] = \\exp(\\gamma \\theta W_t) \\mathbb{E}[\\exp(\\gamma \\theta (W_T - W_t))]\n$$\nThe expectation term is the moment-generating function (MGF) of a normal random variable. For a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, its MGF is $\\mathbb{E}[\\exp(kX)] = \\exp(k\\mu + \\frac{1}{2}k^2\\sigma^2)$.\nHere, the random variable is $(W_T - W_t) \\sim \\mathcal{N}(0, T-t)$, so $\\mu=0$ and $\\sigma^2 = T-t$. The parameter $k$ is $\\gamma\\theta$.\n$$\n\\mathbb{E}[\\exp(\\gamma \\theta (W_T - W_t))] = \\exp\\left(0 + \\frac{1}{2}(\\gamma \\theta)^2 (T-t)\\right) = \\exp\\left(\\frac{\\gamma^2 \\theta^2}{2}(T-t)\\right)\n$$\nSubstituting this back into the expression for $V_t$, we obtain the explicit closed-form for $V_t$:\n$$\nV_t = \\exp(\\gamma \\theta W_t) \\exp\\left(\\frac{\\gamma^2 \\theta^2}{2}(T-t)\\right) = \\exp\\left(\\gamma \\theta W_t + \\frac{\\gamma^2 \\theta^2}{2}(T-t)\\right)\n$$\nNow we have two expressions for the dynamics of $V_t$:\n1. From the Itô transformation of $Y_t$: $dV_t = \\gamma V_t Z_t dW_t$.\n2. From applying Itô's formula to the explicit expression for $V_t$.\n\nLet's do the second calculation. Let $f(t, x) = \\exp\\left(\\gamma \\theta x + \\frac{\\gamma^2 \\theta^2}{2}(T-t)\\right)$. Then $V_t = f(t, W_t)$. We compute the partial derivatives of $f$:\n$$ \\partial_t f(t,x) = f(t,x) \\cdot \\left(-\\frac{\\gamma^2 \\theta^2}{2}\\right) $$\n$$ \\partial_x f(t,x) = f(t,x) \\cdot (\\gamma \\theta) $$\n$$ \\partial_{xx} f(t,x) = f(t,x) \\cdot (\\gamma \\theta)^2 = f(t,x) \\cdot \\gamma^2\\theta^2 $$\nBy Itô's formula, the differential of $V_t = f(t, W_t)$ is:\n$$ dV_t = \\left(\\partial_t f(t,W_t) + \\frac{1}{2}\\partial_{xx} f(t,W_t)\\right)dt + \\partial_x f(t,W_t) dW_t $$\nSubstituting the derivatives:\n$$ dV_t = \\left(V_t \\cdot \\left(-\\frac{\\gamma^2 \\theta^2}{2}\\right) + \\frac{1}{2} V_t \\cdot (\\gamma^2\\theta^2)\\right)dt + (V_t \\cdot \\gamma\\theta) dW_t $$\nThe drift term simplifies to zero:\n$$ dV_t = 0 \\cdot dt + \\gamma \\theta V_t dW_t = \\gamma \\theta V_t dW_t $$\nThis result can also be obtained via the Clark-Ocone formula, which provides the integrand for the martingale representation of functionals of Brownian motion, thus satisfying the problem's hint.\n\nBy comparing the two expressions for $dV_t$, we have:\n$$\n\\gamma V_t Z_t dW_t = \\gamma \\theta V_t dW_t\n$$\nThis implies that the integrands must be equal almost surely:\n$$\n\\gamma V_t Z_t = \\gamma \\theta V_t\n$$\nSince $\\gamma > 0$ and $V_t = \\exp(\\gamma Y_t) > 0$, we can divide both sides by $\\gamma V_t$:\n$$\nZ_t = \\theta\n$$\nThus, the integrand process $Z$ is the constant process $Z_t = \\theta$ for all $t \\in [0,T]$.", "answer": "$$\\boxed{\\theta}$$", "id": "2991941"}, {"introduction": "While the previous practice demonstrated how a solution can be constructed, it is crucial to understand the conditions under which solutions exist at all. This exercise explores the boundary of solvability for quadratic BSDEs, focusing on the integrability of the terminal condition [@problem_id:2991948]. You will derive a necessary condition involving exponential moments and discover precisely how its violation leads to the non-existence of a bounded solution, highlighting a key theoretical requirement.", "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{0\\le t\\le T},\\mathbb{P})$ supporting a one-dimensional standard Brownian motion $W=(W_t)_{0\\le t\\le T}$, where $T0$ is fixed. For a parameter $a0$, define the terminal random variable $\\xi_a := a\\,W_T^2$. Study the quadratic growth backward stochastic differential equation (BSDE) in the pair of progressively measurable processes $(Y,Z)$:\n$$\nY_t \\;=\\; \\xi_a \\;+\\; \\int_t^T \\frac{1}{2}\\,|Z_s|^2\\,ds \\;-\\; \\int_t^T Z_s\\,dW_s,\\qquad 0\\le t\\le T.\n$$\nStarting only from the definition of a backward stochastic differential equation (BSDE), basic properties of Brownian motion, and Itô's formula, address the following.\n\n1. Derive a necessary integrability condition on $\\xi_a$ that must hold if there exists a bounded adapted solution $(Y,Z)$ to the above BSDE. Your derivation must start from the BSDE itself and proceed from first principles, without invoking any specialized representation theorems.\n\n2. Use your necessary condition to construct an explicit choice of $a0$ (as a function of $T$) for which no bounded adapted solution can exist. To this end, compute exactly the threshold value $a_c(T)$ such that $\\mathbb{E}[\\exp(a\\,W_T^2)]$ is finite if and only if $aa_c(T)$, and infinite if $a\\ge a_c(T)$.\n\n3. Conclude that when $a\\ge a_c(T)$, the terminal condition $\\xi_a$ lacks the exponential integrability required for bounded solutions of the quadratic BSDE, thereby demonstrating the necessity of exponential integrability for bounded solvability in this quadratic growth setting.\n\nAnswer specification:\n- Provide as your final answer the exact analytic expression for the threshold $a_c(T)$ as a function of $T$.\n- No rounding is required and no units are involved in the final answer.", "solution": "The problem asks for an analysis of a specific backward stochastic differential equation (BSDE) with quadratic growth in the $Z$ component. The analysis is to be performed in three steps: first, deriving a necessary integrability condition for the existence of a bounded solution; second, calculating a critical parameter value related to this condition; and third, synthesizing these results.\n\nThe BSDE is given by:\n$$\nY_t \\;=\\; \\xi_a \\;+\\; \\int_t^T \\frac{1}{2}\\,|Z_s|^2\\,ds \\;-\\; \\int_t^T Z_s\\,dW_s,\\qquad 0\\le t\\le T\n$$\nwhere the terminal condition is $\\xi_a = a\\,W_T^2$ for a parameter $a>0$. The processes $(Y,Z)$ are assumed to be progressively measurable with respect to the filtration $(\\mathcal{F}_t)_{0\\le t\\le T}$ generated by the standard Brownian motion $W$.\n\nIn differential form, the BSDE is written as:\n$$\ndY_t = - \\frac{1}{2}\\,|Z_t|^2\\,dt + Z_t\\,dW_t, \\quad \\text{with terminal condition } Y_T = a\\,W_T^2.\n$$\n\n**1. Derivation of the Necessary Integrability Condition**\n\nWe are asked to derive a necessary condition on $\\xi_a$ that must hold if there exists a bounded adapted solution $(Y,Z)$. A bounded solution is one for which there exists a constant $M>0$ such that $|Y_t(\\omega)| \\le M$ for almost every $(\\omega, t) \\in \\Omega \\times [0,T]$. For this derivation, we will assume a strong form of boundedness, where $|Z_t(\\omega)|$ is also uniformly bounded by a constant.\n\nLet us consider the process $X_t = \\exp(Y_t)$. We apply Itô's formula for a function $f(y) = \\exp(y)$ applied to the process $Y_t$. The derivatives are $f'(y)=\\exp(y)$ and $f''(y)=\\exp(y)$. The Itô-Lévy formula for a general semimartingale yields:\n$$\ndX_t = f'(Y_t)\\,dY_t + \\frac{1}{2}\\,f''(Y_t)\\,d\\langle Y \\rangle_t\n$$\nThe quadratic variation of $Y_t$ is given by $d\\langle Y \\rangle_t = |Z_t|^2\\,dt$. Substituting the expression for $dY_t$ and $d\\langle Y \\rangle_t$:\n$$\ndX_t = \\exp(Y_t)\\left( - \\frac{1}{2}\\,|Z_t|^2\\,dt + Z_t\\,dW_t \\right) + \\frac{1}{2}\\,\\exp(Y_t)\\,|Z_t|^2\\,dt\n$$\nThe $dt$ terms cancel out:\n$$\ndX_t = -\\frac{1}{2}\\,\\exp(Y_t)\\,|Z_t|^2\\,dt + \\exp(Y_t)\\,Z_t\\,dW_t + \\frac{1}{2}\\,\\exp(Y_t)\\,|Z_t|^2\\,dt\n$$\n$$\ndX_t = \\exp(Y_t)\\,Z_t\\,dW_t\n$$\nThis shows that the process $X_t = \\exp(Y_t)$ is a local martingale. Integrating from a time $t$ to the terminal time $T$ gives:\n$$\nX_T - X_t = \\int_t^T dX_s = \\int_t^T \\exp(Y_s)\\,Z_s\\,dW_s\n$$\nRearranging the terms, we get an expression for $\\exp(Y_t)$:\n$$\n\\exp(Y_t) = \\exp(Y_T) - \\int_t^T \\exp(Y_s)\\,Z_s\\,dW_s\n$$\nNow, we take the conditional expectation with respect to $\\mathcal{F}_t$ on both sides. Since $Y_t$ is $\\mathcal{F}_t$-measurable, $\\exp(Y_t)$ is also $\\mathcal{F}_t$-measurable, so $\\mathbb{E}[\\exp(Y_t) | \\mathcal{F}_t] = \\exp(Y_t)$.\n$$\n\\exp(Y_t) = \\mathbb{E}[\\exp(Y_T) | \\mathcal{F}_t] - \\mathbb{E}\\left[ \\int_t^T \\exp(Y_s)\\,Z_s\\,dW_s \\;\\Bigg|\\; \\mathcal{F}_t \\right]\n$$\nThe second term involves the expectation of a stochastic integral. If the stochastic integral is a true martingale (not just a local martingale), this expectation is zero. A sufficient condition for this is $\\mathbb{E}\\left[\\int_t^T |\\exp(Y_s) Z_s|^2\\,ds\\right]  \\infty$. Under our assumption that both $Y$ and $Z$ are bounded by a constant $M$, the integrand $\\exp(Y_s)Z_s$ is also bounded: $|\\exp(Y_s)\\,Z_s| \\le \\exp(M) M$. A stochastic integral with a bounded integrand is a true martingale. Hence,\n$$\n\\mathbb{E}\\left[ \\int_t^T \\exp(Y_s)\\,Z_s\\,dW_s \\;\\Bigg|\\; \\mathcal{F}_t \\right] = 0\n$$\nThis simplifies our expression to:\n$$\n\\exp(Y_t) = \\mathbb{E}[\\exp(Y_T) | \\mathcal{F}_t]\n$$\nThis relation must hold for all $t \\in [0,T]$. Let's consider $t=0$. The filtration $\\mathcal{F}_0$ is trivial (up to $\\mathbb{P}$-null sets), so the conditional expectation becomes an unconditional expectation:\n$$\n\\exp(Y_0) = \\mathbb{E}[\\exp(Y_T)]\n$$\nSubstituting the terminal condition $Y_T = \\xi_a = a\\,W_T^2$:\n$$\n\\exp(Y_0) = \\mathbb{E}[\\exp(a\\,W_T^2)]\n$$\nFrom the boundedness assumption, $|Y_0| \\le M$, which implies $\\exp(Y_0) \\le \\exp(M)  \\infty$. Therefore, we must have:\n$$\n\\mathbb{E}[\\exp(a\\,W_T^2)]  \\infty\n$$\nThis is the necessary integrability condition that the terminal condition $\\xi_a$ must satisfy for a bounded solution to exist.\n\n**2. Calculation of the Threshold $a_c(T)$**\n\nWe now compute the expectation $\\mathbb{E}[\\exp(a\\,W_T^2)]$ and determine for which values of $a>0$ it is finite. The random variable $W_T$ follows a normal distribution with mean $0$ and variance $T$, i.e., $W_T \\sim \\mathcal{N}(0, T)$. Its probability density function (PDF) is given by:\n$$\np(x) = \\frac{1}{\\sqrt{2\\pi T}}\\,\\exp\\left(-\\frac{x^2}{2T}\\right)\n$$\nThe expectation is calculated by integrating over all possible values of $W_T$:\n$$\n\\mathbb{E}[\\exp(a\\,W_T^2)] = \\int_{-\\infty}^{\\infty} \\exp(ax^2)\\,p(x)\\,dx = \\int_{-\\infty}^{\\infty} \\exp(ax^2)\\,\\frac{1}{\\sqrt{2\\pi T}}\\,\\exp\\left(-\\frac{x^2}{2T}\\right)\\,dx\n$$\nWe can combine the exponents:\n$$\n\\mathbb{E}[\\exp(a\\,W_T^2)] = \\frac{1}{\\sqrt{2\\pi T}} \\int_{-\\infty}^{\\infty} \\exp\\left(ax^2 - \\frac{x^2}{2T}\\right)\\,dx = \\frac{1}{\\sqrt{2\\pi T}} \\int_{-\\infty}^{\\infty} \\exp\\left(-\\left(\\frac{1}{2T} - a\\right)x^2\\right)\\,dx\n$$\nThis is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} \\exp(-cx^2)\\,dx$. This integral converges if and only if the coefficient $c$ is strictly positive. In our case, $c = \\frac{1}{2T} - a$. Thus, for the expectation to be finite, we require:\n$$\n\\frac{1}{2T} - a > 0 \\implies a  \\frac{1}{2T}\n$$\nIf this condition holds, the value of the integral is $\\sqrt{\\pi/c}$. The expectation is:\n$$\n\\mathbb{E}[\\exp(a\\,W_T^2)] = \\frac{1}{\\sqrt{2\\pi T}} \\sqrt{\\frac{\\pi}{\\frac{1}{2T} - a}} = \\frac{1}{\\sqrt{2T}} \\frac{1}{\\sqrt{\\frac{1-2aT}{2T}}} = \\frac{1}{\\sqrt{1-2aT}}\n$$\nThis expression is finite if and only if $1-2aT > 0$, i.e., $a  \\frac{1}{2T}$. If $a = \\frac{1}{2T}$, the exponent in the integrand becomes $0$, and the integral $\\int_{-\\infty}^{\\infty} 1\\,dx$ diverges. If $a > \\frac{1}{2T}$, the exponent is positive, and the integral also diverges.\n\nTherefore, the expectation $\\mathbb{E}[\\exp(a\\,W_T^2)]$ is finite if and only if $a  \\frac{1}{2T}$. The threshold value $a_c(T)$ is the supremum of the set of $a$ for which the expectation is finite. This gives:\n$$\na_c(T) = \\frac{1}{2T}\n$$\nFor any choice of $a \\ge a_c(T)$, the expectation is infinite. According to our finding in Part 1, the necessary condition for the existence of a bounded solution is violated. Thus, for any $a \\ge \\frac{1}{2T}$, no bounded solution $(Y,Z)$ to the BSDE can exist.\n\n**3. Conclusion**\n\nThe analysis demonstrates the necessity of exponential integrability for the existence of bounded solutions to this quadratic BSDE.\n- Step 1 established that if a bounded solution $(Y,Z)$ exists, it is necessary for the terminal condition $\\xi_a = a\\,W_T^2$ to have a finite exponential moment, i.e., $\\mathbb{E}[\\exp(\\xi_a)]  \\infty$. This is a direct consequence of the transformation $X_t = \\exp(Y_t)$ which linearizes the BSDE's driver, converting the process into a martingale under the boundedness assumption.\n- Step 2 provided an explicit calculation of this expectation, showing $\\mathbb{E}[\\exp(a\\,W_T^2)]$ is finite if and only if $a  a_c(T) = \\frac{1}{2T}$.\n- Combining these two results, we conclude that for any parameter value $a \\ge a_c(T) = \\frac{1}{2T}$, the terminal condition $\\xi_a$ fails to be sufficiently integrable. The necessary condition derived from first principles is not met, proving that for such values of $a$, no bounded solution to the specified quadratic BSDE can exist. This highlights a fundamental feature of quadratic BSDEs: the solvability (at least for bounded solutions) is intimately linked to the exponential moments of the terminal data.\n\nThe required analytic expression for the threshold $a_c(T)$ is $\\frac{1}{2T}$.", "answer": "$$\n\\boxed{\\frac{1}{2T}}\n$$", "id": "2991948"}, {"introduction": "The theory of quadratic BSDEs is deeply intertwined with the study of semilinear parabolic partial differential equations (PDEs). This practice illuminates this connection, often known as the nonlinear Feynman-Kac formula, by using a logarithmic transformation to relate a nonlinear PDE to the linear heat equation [@problem_id:2991921]. Through explicit computation, you will not only solve the PDE but also uncover how the quadratic nonlinearity can affect the regularity of the solution, providing a bridge between stochastic and deterministic analysis.", "problem": "Consider the one-dimensional semilinear parabolic partial differential equation with quadratic gradient growth\n$$\n\\partial_{t} u(t,x) + \\frac{1}{2}\\,\\partial_{xx} u(t,x) + \\frac{1}{2}\\,|\\partial_{x} u(t,x)|^{2} = 0,\n$$\nposed on the cylinder $[0,T)\\times(0,\\pi)$, where $T0$ is fixed. The coefficients of the second-order term are constant and smooth. Define $v(t,x)$ to be a classical solution to the linear heat equation\n$$\n\\partial_{t} v(t,x) + \\frac{1}{2}\\,\\partial_{xx} v(t,x) = 0\n$$\non $[0,T]\\times(0,\\pi)$ with homogeneous Dirichlet boundary conditions $v(t,0)=0$ and $v(t,\\pi)=0$ for all $t\\in[0,T]$, and terminal condition $v(T,x)=\\sin(x)$ for $x\\in(0,\\pi)$. Starting from the fundamental definitions of the heat equation and the chain rule for differentiating compositions, derive the nonlinear equation satisfied by $u(t,x):=\\ln(v(t,x))$ in the interior of the domain. Compute the explicit formula for $u(t,x)$ and its spatial derivative $\\partial_{x}u(t,x)$, and use these to determine whether $u$ possesses continuously differentiable ($C^{1}$) spatial regularity on the closed interval $[0,\\pi]$ for each fixed $t\\in[0,T)$. Provide the explicit analytic expression for $u(t,x)$ as your final answer.", "solution": "The solution involves three main steps. First, we use the transformation $u(t,x) = \\ln(v(t,x))$ to find the PDE that $u$ must satisfy if $v$ solves the linear heat equation. Second, we solve the heat equation for $v$ subject to the given boundary and terminal conditions. Finally, we use this solution to find the explicit form of $u$ and analyze its regularity.\n\n**1. Derivation of the PDE for $u(t,x)$**\n\nGiven the transformation $u = \\ln(v)$, we express the derivatives of $v$ in terms of $u$ and its derivatives using the chain rule.\n$$ \\partial_x v = v \\, \\partial_x u $$\n$$ \\partial_{xx} v = \\partial_x (v \\, \\partial_x u) = (\\partial_x v)(\\partial_x u) + v (\\partial_{xx} u) = (v \\, \\partial_x u)(\\partial_x u) + v (\\partial_{xx} u) = v \\left( (\\partial_x u)^2 + \\partial_{xx} u \\right) $$\n$$ \\partial_t v = v \\, \\partial_t u $$\nThe function $v$ solves the linear heat equation $\\partial_{t} v + \\frac{1}{2}\\,\\partial_{xx} v = 0$. Substituting the expressions above, we get:\n$$ v \\, \\partial_t u + \\frac{1}{2} v \\left( (\\partial_x u)^2 + \\partial_{xx} u \\right) = 0 $$\nSince $v > 0$ in the interior of the domain, we can divide by $v$ to obtain the PDE for $u$:\n$$ \\partial_t u + \\frac{1}{2} \\partial_{xx} u + \\frac{1}{2} (\\partial_x u)^2 = 0 $$\nSince the spatial dimension is one, $(\\partial_x u)^2 = |\\partial_x u|^2$, which matches the PDE given in the problem statement.\n\n**2. Explicit Solution for $u(t,x)$**\n\nTo find $u(t,x)$, we must first find $v(t,x)$. The function $v$ solves the backward-in-time heat equation on $[0,T] \\times (0, \\pi)$ with terminal condition $v(T,x) = \\sin(x)$ and homogeneous Dirichlet boundary conditions $v(t,0) = v(t,\\pi) = 0$.\nWe use the method of separation of variables. The eigenfunctions for the operator $\\frac{1}{2}\\partial_{xx}$ on $(0,\\pi)$ with Dirichlet boundary conditions are $\\sin(kx)$ for integers $k \\ge 1$, with corresponding eigenvalues $-\\frac{k^2}{2}$. The solution can be written as a Fourier series:\n$$ v(t,x) = \\sum_{k=1}^{\\infty} c_k e^{-\\frac{k^2}{2}(T-t)} \\sin(kx) $$\nTo satisfy the terminal condition at $t=T$, we must have:\n$$ v(T,x) = \\sin(x) = \\sum_{k=1}^{\\infty} c_k \\sin(kx) $$\nBy uniqueness of the Fourier series expansion, we find that $c_1=1$ and $c_k=0$ for all $k \\ge 2$. Thus, the solution for $v$ is:\n$$ v(t,x) = e^{-\\frac{1}{2}(T-t)} \\sin(x) $$\nNow, we find $u(t,x)$ using the given transformation. For $t \\in [0,T)$ and $x \\in (0,\\pi)$, $v(t,x) > 0$, so the logarithm is well-defined:\n$$ u(t,x) = \\ln(v(t,x)) = \\ln\\left(e^{-\\frac{1}{2}(T-t)} \\sin(x)\\right) = -\\frac{T-t}{2} + \\ln(\\sin(x)) $$\n\n**3. Analysis of Spatial Regularity**\n\nTo determine if $u$ possesses $C^1$ spatial regularity on the closed interval $[0,\\pi]$ for a fixed $t \\in [0,T)$, we must check if both $u(t,x)$ and its spatial derivative $\\partial_x u(t,x)$ can be continuously extended to the endpoints $x=0$ and $x=\\pi$.\n\nLet's examine the behavior of $u(t,x)$ at the boundaries:\nAs $x \\to 0^+$, $\\sin(x) \\to 0^+$, so $\\ln(\\sin(x)) \\to -\\infty$.\nAs $x \\to \\pi^-$, $\\sin(x) \\to 0^+$, so $\\ln(\\sin(x)) \\to -\\infty$.\nSince $u(t,x)$ diverges to $-\\infty$ at both endpoints, it cannot be extended to a continuous function on $[0,\\pi]$. A function that is not continuous cannot be $C^1$.\n\nFor completeness, we also check the spatial derivative:\n$$ \\partial_x u(t,x) = \\frac{\\cos(x)}{\\sin(x)} = \\cot(x) $$\nAs $x \\to 0^+$, $\\cot(x) \\to +\\infty$.\nAs $x \\to \\pi^-$, $\\cot(x) \\to -\\infty$.\nThe derivative also diverges at the boundaries. We conclude that for any fixed $t \\in [0,T)$, $u(t,x)$ is not $C^1$ on the closed interval $[0,\\pi]$.\n\nThe explicit analytic expression for $u(t,x)$ is $-\\frac{T-t}{2} + \\ln(\\sin(x))$.", "answer": "$$ \\boxed{-\\frac{T-t}{2} + \\ln(\\sin(x))} $$", "id": "2991921"}]}