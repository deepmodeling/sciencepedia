{"hands_on_practices": [{"introduction": "The Stroock-Varadhan theorem is most naturally stated for systems in Stratonovich form, as their corresponding skeleton equations are free of stochastic correction terms. This exercise [@problem_id:3004333] provides essential practice in converting a stochastic differential equation from the common Itô form to its Stratonovich equivalent. Mastering this conversion is a critical first step in applying the support theorem to a wide range of models.", "problem": "Consider the Itô Stochastic Differential Equation (SDE) on $\\mathbb{R}^{d}$ driven by a one-dimensional standard Brownian motion $W_{t}$:\n$$\n\\mathrm{d}X_{t} \\;=\\; b(X_{t})\\,\\mathrm{d}t \\;+\\; \\sigma(X_{t})\\,\\mathrm{d}W_{t},\n$$\nwhere $b:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ and $\\sigma:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ are sufficiently smooth functions with bounded derivatives to ensure the existence of a unique strong solution and the applicability of the Stroock–Varadhan support theorem. The Stratonovich formulation of the same dynamics is written as\n$$\n\\mathrm{d}X_{t} \\;=\\; b^{\\circ}(X_{t})\\,\\mathrm{d}t \\;+\\; \\sigma(X_{t}) \\circ \\mathrm{d}W_{t},\n$$\nwhere $\\circ \\mathrm{d}W_{t}$ denotes the Stratonovich integral and $b^{\\circ}$ is the Stratonovich drift. The Stroock–Varadhan support theorem characterizes the topological support of the law of $X_{t}$ via controlled ordinary differential equations driven by the Stratonovich coefficients, which makes the explicit Itô–Stratonovich correction term essential for identifying the correct skeleton dynamics.\n\nStarting only from the fundamental definitions of the Itô integral, the Stratonovich integral (as symmetric limits of Riemann sums), and the quadratic covariation, derive the explicit Itô–Stratonovich correction vector field $c:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ such that $b^{\\circ}(x)=b(x)-c(x)$. Express $c(x)$ in terms of $\\sigma$ and its first derivatives. Then compute $c(x)$ in the specific case where the diffusion coefficient is linear and multiplicative,\n$$\n\\sigma(x) \\;=\\; \\Sigma x,\n$$\nwith $\\Sigma\\in\\mathbb{R}^{d\\times d}$ a fixed constant matrix. Your final answer must be the closed-form analytic expression for $c(x)$ in this special case. No rounding is required, and no units apply.", "solution": "The problem is valid. It asks for a standard derivation in stochastic calculus—the conversion formula between Itô and Stratonovich stochastic differential equations—and its application to a specific case. The problem is scientifically grounded, well-posed, and objective.\n\nThe objective is to find the correction term $c(x)$ that relates the Itô drift $b(x)$ to the Stratonovich drift $b^\\circ(x)$ via the equation $b^\\circ(x) = b(x) - c(x)$.\n\nThe Itô SDE is given by:\n$$ \\mathrm{d}X_{t} = b(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t})\\,\\mathrm{d}W_{t} $$\nIn integral form, this is:\n$$ X_{T} - X_{0} = \\int_{0}^{T} b(X_{t})\\,\\mathrm{d}t + \\int_{0}^{T} \\sigma(X_{t})\\,\\mathrm{d}W_{t} $$\nThe Stratonovich SDE is written as:\n$$ \\mathrm{d}X_{t} = b^{\\circ}(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t}) \\circ \\mathrm{d}W_{t} $$\nThe key to relating these two forms is to establish the relationship between the Itô integral $\\int \\sigma(X_t)\\,\\mathrm{d}W_t$ and the Stratonovich integral $\\int \\sigma(X_t)\\circ \\mathrm{d}W_t$.\n\nThe Stratonovich integral is defined as the limit of sums where the integrand is evaluated at the midpoint of the time interval. For a partition $0=t_0 < t_1 < \\dots < t_N=T$, a discrete approximation over an interval $[t_i, t_{i+1}]$ is given by $\\sigma\\left(\\frac{X_{t_{i+1}}+X_{t_i}}{2}\\right)(W_{t_{i+1}}-W_{t_i})$. The Itô integral approximation uses the left endpoint: $\\sigma(X_{t_i})(W_{t_{i+1}}-W_{t_i})$.\n\nLet's analyze the difference over a small time interval $\\Delta t = t_{i+1}-t_i$. Let $t=t_i$, $\\Delta X_t = X_{t+\\Delta t} - X_t$, and $\\Delta W_t = W_{t+\\Delta t} - W_t$.\nThe midpoint evaluation point is $X_t + \\frac{1}{2}\\Delta X_t$. We perform a first-order Taylor expansion of $\\sigma$ (a vector-valued function) around $X_t$:\n$$ \\sigma\\left(X_t + \\frac{1}{2}\\Delta X_t\\right) \\approx \\sigma(X_t) + \\frac{1}{2} D\\sigma(X_t)[\\Delta X_t] $$\nwhere $D\\sigma(X_t)$ is the Jacobian matrix of $\\sigma$ at $X_t$, and $D\\sigma(X_t)[\\Delta X_t]$ is the action of this Jacobian on the vector $\\Delta X_t$. In component form, if $\\sigma = (\\sigma_1, \\dots, \\sigma_d)^T$, the $i$-th component of this expansion is:\n$$ \\sigma_i\\left(X_t + \\frac{1}{2}\\Delta X_t\\right) \\approx \\sigma_i(X_t) + \\frac{1}{2} \\sum_{j=1}^{d} \\frac{\\partial \\sigma_i}{\\partial x_j}(X_t) (\\Delta X_t)_j $$\nThe Stratonovich increment is thus:\n$$ \\sigma\\left(X_t + \\frac{1}{2}\\Delta X_t\\right) \\Delta W_t \\approx \\left(\\sigma(X_t) + \\frac{1}{2} D\\sigma(X_t)[\\Delta X_t]\\right) \\Delta W_t = \\sigma(X_t)\\Delta W_t + \\frac{1}{2} D\\sigma(X_t)[\\Delta X_t] \\Delta W_t $$\nTo the lowest order, the increment $\\Delta X_t$ is given by the Itô SDE:\n$$ \\Delta X_t \\approx b(X_t)\\Delta t + \\sigma(X_t)\\Delta W_t $$\nSubstituting this into the expression for the Stratonovich increment:\n$$ \\sigma\\left(X_t + \\frac{1}{2}\\Delta X_t\\right) \\Delta W_t \\approx \\sigma(X_t)\\Delta W_t + \\frac{1}{2} D\\sigma(X_t)[b(X_t)\\Delta t + \\sigma(X_t)\\Delta W_t] \\Delta W_t $$\n$$ \\approx \\sigma(X_t)\\Delta W_t + \\frac{1}{2} (D\\sigma\\cdot b)(X_t) \\Delta t \\Delta W_t + \\frac{1}{2} (D\\sigma\\cdot\\sigma)(X_t) (\\Delta W_t)^2 $$\nIn the limit as $\\Delta t \\to 0$, we use the rules of stochastic calculus: terms of order $\\Delta t \\Delta W_t$ vanish, while $(\\Delta W_t)^2$ becomes $\\mathrm{d}t$. This is a heuristic argument; a rigorous proof relies on Itô's Lemma. The result is:\n$$ \\sigma(X_t) \\circ \\mathrm{d}W_t = \\sigma(X_t)\\,\\mathrm{d}W_t + \\frac{1}{2} (D\\sigma)[\\sigma](X_t)\\,\\mathrm{d}t $$\nwhere we use the notation $(D\\sigma)[\\sigma](x)$ for the vector field whose $i$-th component is $\\sum_{j=1}^d \\frac{\\partial \\sigma_i}{\\partial x_j}(x) \\sigma_j(x)$.\n\nRearranging this gives the Itô integral in terms of the Stratonovich integral:\n$$ \\sigma(X_t)\\,\\mathrm{d}W_t = \\sigma(X_t) \\circ \\mathrm{d}W_t - \\frac{1}{2} (D\\sigma)[\\sigma](X_t)\\,\\mathrm{d}t $$\nNow, we substitute this back into the original Itô SDE:\n$$ \\mathrm{d}X_{t} = b(X_{t})\\,\\mathrm{d}t + \\left(\\sigma(X_{t}) \\circ \\mathrm{d}W_t - \\frac{1}{2} (D\\sigma)[\\sigma](X_t)\\,\\mathrm{d}t\\right) $$\n$$ \\mathrm{d}X_{t} = \\left(b(X_t) - \\frac{1}{2} (D\\sigma)[\\sigma](X_t)\\right)\\,\\mathrm{d}t + \\sigma(X_t) \\circ \\mathrm{d}W_t $$\nComparing this to the definition of the Stratonovich SDE, $\\mathrm{d}X_{t} = b^{\\circ}(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t}) \\circ \\mathrm{d}W_{t}$, we identify the Stratonovich drift:\n$$ b^{\\circ}(x) = b(x) - \\frac{1}{2} (D\\sigma)[\\sigma](x) $$\nThe problem defines the correction vector field $c(x)$ such that $b^{\\circ}(x) = b(x) - c(x)$. Therefore, we have derived the general expression for $c(x)$:\n$$ c(x) = \\frac{1}{2} (D\\sigma)[\\sigma](x) $$\nIn component form, the $i$-th component of $c(x)$ is:\n$$ c_i(x) = \\frac{1}{2} \\sum_{j=1}^{d} \\frac{\\partial \\sigma_i}{\\partial x_j}(x) \\sigma_j(x) $$\nThis expression depends only on $\\sigma$ and its first derivatives, as required.\n\nNow, we compute $c(x)$ for the specific case where $\\sigma(x) = \\Sigma x$, with $\\Sigma \\in \\mathbb{R}^{d\\times d}$ being a constant matrix.\nFirst, let's write out the components of $\\sigma(x)$. Let $x = (x_1, \\dots, x_d)^T$.\n$$ \\sigma_i(x) = \\sum_{k=1}^{d} \\Sigma_{ik} x_k $$\nNext, we compute the partial derivatives required for the Jacobian matrix $D\\sigma$:\n$$ \\frac{\\partial \\sigma_i}{\\partial x_j}(x) = \\frac{\\partial}{\\partial x_j} \\left(\\sum_{k=1}^{d} \\Sigma_{ik} x_k\\right) = \\sum_{k=1}^{d} \\Sigma_{ik} \\frac{\\partial x_k}{\\partial x_j} $$\nUsing the property $\\frac{\\partial x_k}{\\partial x_j} = \\delta_{kj}$ (the Kronecker delta), we get:\n$$ \\frac{\\partial \\sigma_i}{\\partial x_j}(x) = \\sum_{k=1}^{d} \\Sigma_{ik} \\delta_{kj} = \\Sigma_{ij} $$\nThis shows that the Jacobian matrix of the linear function $\\sigma(x) = \\Sigma x$ is the constant matrix $\\Sigma$ itself: $D\\sigma(x) = \\Sigma$.\n\nNow we substitute these results into the component-wise formula for $c_i(x)$:\n$$ c_i(x) = \\frac{1}{2} \\sum_{j=1}^{d} \\Sigma_{ij} \\sigma_j(x) $$\nWe substitute the expression for $\\sigma_j(x)$:\n$$ c_i(x) = \\frac{1}{2} \\sum_{j=1}^{d} \\Sigma_{ij} \\left(\\sum_{k=1}^{d} \\Sigma_{jk} x_k\\right) $$\nBy rearranging the order of summation, we get:\n$$ c_i(x) = \\frac{1}{2} \\sum_{k=1}^{d} \\left(\\sum_{j=1}^{d} \\Sigma_{ij} \\Sigma_{jk}\\right) x_k $$\nThe term in the parenthesis, $\\sum_{j=1}^{d} \\Sigma_{ij} \\Sigma_{jk}$, is precisely the $(i,k)$-th element of the matrix product $\\Sigma^2$. Thus:\n$$ (\\Sigma^2)_{ik} = \\sum_{j=1}^{d} \\Sigma_{ij} \\Sigma_{jk} $$\nSubstituting this back, we find the expression for the $i$-th component of $c(x)$:\n$$ c_i(x) = \\frac{1}{2} \\sum_{k=1}^{d} (\\Sigma^2)_{ik} x_k $$\nThis expression is the $i$-th component of the vector $\\frac{1}{2}\\Sigma^2 x$. Therefore, the correction vector field $c(x)$ is:\n$$ c(x) = \\frac{1}{2} \\Sigma^2 x $$\nThis is the required closed-form analytic expression for the correction term in the specified case.", "answer": "$$\\boxed{\\frac{1}{2} \\Sigma^2 x}$$", "id": "3004333"}, {"introduction": "Once the deterministic skeleton dynamics are identified, the core task is to determine the set of all possible states reachable by the control system. This practice [@problem_id:3004325] offers a concrete scenario of a one-dimensional system with reflection, challenging you to explicitly construct the controlled trajectory and find its terminal reachable set. This exercise makes the abstract concept of a support set tangible by computing its precise geometric boundaries.", "problem": "Consider the one-dimensional reflected stochastic differential equation (Stochastic Differential Equation, SDE) on the half-line with normal reflection at the boundary:\n$$\n\\mathrm{d}X_{t} \\;=\\; \\mathrm{d}W_{t} \\;+\\; \\mathrm{d}L_{t}, \n\\qquad X_{0} \\,=\\, 0, \n\\qquad X_{t} \\,\\geq\\, 0 \\text{ for all } t \\geq 0,\n$$\nwhere $W$ is a standard Brownian motion and $L$ is the boundary local time at $0$ enforcing $X_{t} \\geq 0$. The Stroock–Varadhan support theorem asserts that the topological support of the law of $X$ on path space is the closure of the set of controlled skeleton trajectories obtained by replacing the Brownian increment with an absolutely continuous Cameron–Martin control.\n\nConstruct explicitly the controlled reflected skeleton dynamics on $[0,\\infty)$ by replacing the Brownian term with a deterministic control input. Let the control $u$ be Lebesgue measurable with essential bound $|u(t)| \\leq U$ for all $t \\in [0,T]$, where $U>0$ and $T>0$ are fixed, and let the initial condition be $x(0)=0$. The reflection is normal at $0$, implemented by the minimal nondecreasing regulator that acts only when the state is at the boundary, so that the trajectory stays in $[0,\\infty)$.\n\nFrom first principles, derive the controlled reflected skeleton dynamics on $[0,T]$, and using only the control bound $|u(t)| \\leq U$ and the reflection properties, determine the exact reachable set of terminal positions $x(T)$ over all admissible controls. Report a single quantity that captures this set by giving its exact Lebesgue measure (that is, the length of the interval that forms the reachable set of $x(T)$). Your final answer must be a closed-form analytic expression in terms of $U$ and $T$ only. No rounding is required.", "solution": "The problem asks for the Lebesgue measure of the reachable set of terminal positions for a one-dimensional controlled process on the half-line $[0, \\infty)$, starting from $x(0)=0$ and with normal reflection at the boundary $x=0$.\n\nFirst, we formalize the controlled reflected skeleton dynamics. The problem is set in the context of the Stroock–Varadhan support theorem, which relates the support of the law of a stochastic differential equation (SDE) to the set of trajectories of a corresponding controlled deterministic system. The given SDE is:\n$$\n\\mathrm{d}X_{t} \\;=\\; \\mathrm{d}W_{t} \\;+\\; \\mathrm{d}L_{t}\n$$\nwhere $X_{t} \\geq 0$, $X_{0} = 0$, $W_t$ is a standard Brownian motion, and $L_t$ is the local time at the boundary. The skeleton equation is obtained by replacing the Brownian increment $\\mathrm{d}W_t$ with a controlled drift $u(t)\\mathrm{d}t$. The control $u(t)$ must belong to a suitable class of functions; here, it is specified as a Lebesgue measurable function satisfying the bound $|u(t)| \\leq U$ for all $t \\in [0,T]$.\n\nThe resulting controlled dynamics for the skeleton path $x(t)$ are given by the differential equation:\n$$\n\\mathrm{d}x(t) \\;=\\; u(t)\\mathrm{d}t \\;+\\; \\mathrm{d}l(t)\n$$\nsubject to the initial condition $x(0) = 0$ and the state constraint $x(t) \\geq 0$. The term $\\mathrm{d}l(t)$ represents the reflection at the boundary. It is described as a minimal nondecreasing regulator that acts only when the state is at the boundary. This is the standard Skorokhod problem. In integral form, the dynamics are:\n$$\nx(t) \\;=\\; \\int_{0}^{t} u(s)\\mathrm{d}s \\;+\\; l(t)\n$$\nThe properties of the regulator $l(t)$ are:\n$1$. $l(0) = 0$.\n$2$. $l(t)$ is a non-decreasing function of $t$.\n$3$. $l(t)$ increases only at times $t$ when $x(t)=0$. This can be stated formally as $\\int_0^T x(t) \\mathrm{d}l(t) = 0$.\n\nLet $Y(t) = \\int_0^t u(s)\\mathrm{d}s$. The equation becomes $x(t) = Y(t) + l(t)$. The condition $x(t) \\geq 0$ implies $l(t) \\geq -Y(t)$. Since $l(t)$ is also non-decreasing, it must satisfy $l(t) \\geq l(s)$ for $s \\leq t$. Combining these, for the regulator to be minimal, $l(t)$ must be the smallest value that satisfies these conditions up to time $t$. This means $l(t)$ must be greater than or equal to $-Y(s)$ for all $s \\in [0, t]$. The minimal such non-decreasing function is given by the running supremum:\n$$\nl(t) \\;=\\; \\sup_{0 \\leq s \\leq t} \\left(-Y(s)\\right) \\;=\\; \\sup_{0 \\leq s \\leq t} \\left(-\\int_{0}^{s} u(\\tau)\\mathrm{d}\\tau\\right)\n$$\nSubstituting this into the expression for $x(t)$, we obtain the explicit solution for the controlled path:\n$$\nx(t) \\;=\\; \\int_{0}^{t} u(s)\\mathrm{d}s \\;+\\; \\sup_{0 \\leq s \\leq t} \\left(-\\int_{0}^{s} u(\\tau)\\mathrm{d}\\tau\\right)\n$$\nOur goal is to find the reachable set for the terminal position $x(T)$ over all admissible controls $u$ such that $|u(t)| \\leq U$ for $t \\in [0,T]$. The terminal position is:\n$$\nx(T) \\;=\\; \\int_{0}^{T} u(s)\\mathrm{d}s \\;+\\; \\sup_{0 \\leq t \\leq T} \\left(-\\int_{0}^{t} u(s)\\mathrm{d}s\\right)\n$$\nLet's analyze this expression. Using the notation $Y(t) = \\int_0^t u(s)\\mathrm{d}s$, we have:\n$$\nx(T) \\;=\\; Y(T) \\;+\\; \\sup_{0 \\leq t \\leq T} (-Y(t)) \\;=\\; Y(T) \\;-\\; \\inf_{0 \\leq t \\leq T} (Y(t))\n$$\nSince the function $Y(t)$ is continuous on the compact interval $[0,T]$, the infimum is attained. Let $t_{\\min} \\in [0,T]$ be a time such that $Y(t_{\\min}) = \\inf_{0 \\leq t \\leq T} Y(t)$. Then we can write:\n$$\nx(T) \\;=\\; Y(T) - Y(t_{\\min}) \\;=\\; \\int_{0}^{T} u(s)\\mathrm{d}s - \\int_{0}^{t_{\\min}} u(s)\\mathrm{d}s \\;=\\; \\int_{t_{\\min}}^{T} u(s)\\mathrm{d}s\n$$\nWe now need to find the range of values that $x(T) = \\int_{t_{\\min}}^{T} u(s)\\mathrm{d}s$ can take, under the constraint $|u(s)| \\leq U$. Note that $t_{\\min}$ itself depends on the choice of control $u$.\n\nFirst, we establish the bounds on $x(T)$.\nThe state constraint $x(t) \\geq 0$ implies $x(T) \\geq 0$. Thus, the minimum possible value is at least $0$.\nFor the upper bound, we have:\n$$\nx(T) \\;=\\; \\int_{t_{\\min}}^{T} u(s)\\mathrm{d}s \\;\\leq\\; \\int_{t_{\\min}}^{T} |u(s)|\\mathrm{d}s \\;\\leq\\; \\int_{t_{\\min}}^{T} U \\mathrm{d}s \\;=\\; U(T - t_{\\min})\n$$\nSince $t_{\\min} \\in [0,T]$, the minimum value of $t_{\\min}$ is $0$. Therefore, the maximum possible value for $x(T)$ is bounded above by $U(T-0) = UT$.\nSo, the reachable set for $x(T)$ is a subset of the interval $[0, UT]$.\n\nNext, we show that this entire interval is reachable.\nTo achieve the maximum value $x(T)=UT$:\nChoose the control $u(t) = U$ for all $t \\in [0,T]$.\nFor this control, $Y(t) = \\int_0^t U \\mathrm{d}s = Ut$. Since $U > 0$ and $t \\geq 0$, $Y(t) \\geq 0$ for all $t$. The infimum of $Y(t)$ is at $t=0$, where $Y(0)=0$. So, $t_{\\min}=0$.\nThe terminal position is $x(T) = \\int_{0}^{T} U \\mathrm{d}s = UT$. Thus, the maximum value $UT$ is reachable.\n\nTo achieve the minimum value $x(T)=0$:\nChoose the control $u(t) = -U$ for all $t \\in [0,T]$.\nFor this control, $Y(t) = \\int_0^t (-U) \\mathrm{d}s = -Ut$. This function is monotonically decreasing on $[0,T]$. Its infimum is at $t=T$. So, $t_{\\min}=T$.\nThe terminal position is $x(T) = \\int_{T}^{T} (-U) \\mathrm{d}s = 0$. Thus, the minimum value $0$ is reachable.\n\nTo achieve any intermediate value $V \\in (0, UT)$:\nWe seek a control $u$ that yields $x(T) = V$. Let's try a \"bang-bang\" control strategy that switches once. Consider the control:\n$$\nu(t) = \\begin{cases} -U & \\text{if } 0 \\leq t < t_0 \\\\ U & \\text{if } t_0 \\leq t \\leq T \\end{cases}\n$$\nfor some switching time $t_0 \\in (0,T)$.\nFor this control, the function $Y(t)$ is:\n$$\nY(t) = \\begin{cases} -Ut & \\text{if } 0 \\leq t < t_0 \\\\ -Ut_0 + U(t-t_0) = U(t-2t_0) & \\text{if } t_0 \\leq t \\leq T \\end{cases}\n$$\nThe function $Y(t)$ decreases from $Y(0)=0$ to $Y(t_0)=-Ut_0$, and then increases. The global infimum of $Y(t)$ on $[0,T]$ is therefore at $t=t_0$, i.e., $t_{\\min}=t_0$.\nThe terminal position is then given by:\n$$\nx(T) \\;=\\; \\int_{t_{\\min}}^{T} u(s)\\mathrm{d}s \\;=\\; \\int_{t_0}^{T} U \\mathrm{d}s \\;=\\; U(T-t_0)\n$$\nWe want this to be equal to $V$. So, we require $V = U(T-t_0)$. We can solve for the switching time $t_0$:\n$$\nt_0 \\;=\\; T - \\frac{V}{U}\n$$\nSince $V \\in (0, UT)$, we have $0 < V/U < T$, which implies $0 < T - V/U < T$. Thus, $t_0$ is a valid switching time within the interval $(0,T)$.\nThis construction shows that any value $V$ in the open interval $(0, UT)$ is reachable.\n\nCombining these results, we have shown that the minimum reachable value is $0$, the maximum is $UT$, and every value in between is also reachable.\nThe reachable set of terminal positions $x(T)$ is therefore the closed interval $[0, UT]$.\n\nThe problem asks for the Lebesgue measure of this reachable set. The Lebesgue measure of an interval $[a,b]$ is its length, $b-a$. For the interval $[0, UT]$, the measure is:\n$$\n\\text{Measure} \\;=\\; UT - 0 \\;=\\; UT\n$$\nThis is a closed-form analytic expression in terms of $U$ and $T$.", "answer": "$$\\boxed{UT}$$", "id": "3004325"}, {"introduction": "A system may be able to explore more dimensions than are immediately apparent from its drift and diffusion vector fields. This exercise [@problem_id:3004326] introduces the Lie bracket, a fundamental tool for uncovering these 'hidden' directions of motion that arise from the interaction of the system's dynamics. By computing this bracket, you will gain insight into the small-time local accessibility of the system, a key property that determines whether the SDE's support can fill out regions of the state space.", "problem": "Consider the stochastic differential equation (SDE) in $\\mathbb{R}^{2}$ driven by a one-dimensional standard Brownian motion $W_{t}$,\n$$\n\\mathrm{d}X_{t} \\,=\\, b(X_{t}) \\,\\mathrm{d}t \\,+\\, \\sigma^{(1)}(X_{t}) \\,\\mathrm{d}W_{t},\n$$\nwith drift and diffusion vector fields\n$$\nb(x,y) \\,=\\, \\begin{pmatrix} 0 \\\\ x^{2} \\end{pmatrix}, \n\\qquad \n\\sigma^{(1)}(x,y) \\,=\\, \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\nLet the corresponding skeleton (controlled) system be given by\n$$\n\\dot{\\varphi}(t) \\,=\\, b(\\varphi(t)) \\,+\\, \\sigma^{(1)}(\\varphi(t)) \\, \\dot{h}(t),\n$$\nwhere $h$ is an absolutely continuous control with square-integrable derivative, that is, $h \\in H^{1}$, the Cameron–Martin space. The Stroock–Varadhan support theorem asserts that the support of the law of $X_{\\cdot}$ in the topology of uniform convergence on compact time intervals is the closure of the set of all such skeleton trajectories $\\varphi(\\cdot)$ driven by controls $h \\in H^{1}$.\n\nStarting from the fundamental definitions of Lie brackets of vector fields and the skeleton system, and using only standard properties of smooth vector fields on $\\mathbb{R}^{2}$, perform the following:\n\n1. Compute the Lie bracket $[b,\\sigma^{(1)}]$, defined for smooth vector fields $V,W$ on $\\mathbb{R}^{2}$ by\n$$\n[V,W](z) \\,=\\, D W(z)\\, V(z) \\,-\\, D V(z)\\, W(z).\n$$\n\n2. Explain, using first principles of accessibility for controlled ordinary differential equations and without invoking any unproved shortcut formulas, how the vector field $[b,\\sigma^{(1)}]$ contributes to small-time local accessibility of the skeleton system from points $(x,y)$ with $x \\neq 0$, and how this, together with the Stroock–Varadhan support theorem, informs the structure of the support of the SDE.\n\n3. Define the scalar function\n$$\n\\Delta(x,y) \\,=\\, \\det\\!\\big( \\sigma^{(1)}(x,y), \\, [b,\\sigma^{(1)}](x,y) \\big),\n$$\nwhere the determinant is taken with the two vector fields as columns in $\\mathbb{R}^{2}$. Compute the explicit analytic expression of $\\Delta(x,y)$.\n\nYour final answer should be the closed-form expression for $\\Delta(x,y)$ in terms of $x$ and $y$. Do not approximate or round; no units are required.", "solution": "The problem is assessed to be valid as it is scientifically grounded in the theory of stochastic differential equations and control theory, is well-posed with clear and precise definitions, and is objective. All necessary information is provided, and the tasks are mathematically formalizable and verifiable.\n\nThe problem is addressed in three parts as requested.\n\n### Part 1: Computation of the Lie Bracket\n\nThe drift and diffusion vector fields are given by:\n$$\nb(x,y) = \\begin{pmatrix} 0 \\\\ x^{2} \\end{pmatrix}, \\qquad \\sigma^{(1)}(x,y) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\nThe Lie bracket $[V,W]$ of two vector fields $V$ and $W$ at a point $z \\in \\mathbb{R}^{2}$ is defined as:\n$$\n[V,W](z) = DW(z)V(z) - DV(z)W(z)\n$$\nwhere $DV(z)$ and $DW(z)$ are the Jacobian matrices of the vector fields $V$ and $W$, respectively.\n\nLet $V = b$ and $W = \\sigma^{(1)}$. First, we compute the Jacobian matrices.\nThe components of $b(x,y)$ are $b_1(x,y) = 0$ and $b_2(x,y) = x^{2}$. The Jacobian matrix of $b$ is:\n$$\nDb(x,y) = \\begin{pmatrix} \\frac{\\partial b_1}{\\partial x} & \\frac{\\partial b_1}{\\partial y} \\\\ \\frac{\\partial b_2}{\\partial x} & \\frac{\\partial b_2}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 2x & 0 \\end{pmatrix}\n$$\nThe components of $\\sigma^{(1)}(x,y)$ are $\\sigma^{(1)}_1(x,y) = 1$ and $\\sigma^{(1)}_2(x,y) = 0$. Since these components are constant, the Jacobian matrix of $\\sigma^{(1)}$ is the zero matrix:\n$$\nD\\sigma^{(1)}(x,y) = \\begin{pmatrix} \\frac{\\partial \\sigma^{(1)}_1}{\\partial x} & \\frac{\\partial \\sigma^{(1)}_1}{\\partial y} \\\\ \\frac{\\partial \\sigma^{(1)}_2}{\\partial x} & \\frac{\\partial \\sigma^{(1)}_2}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nNow, we substitute these into the definition of the Lie bracket:\n$$\n[b, \\sigma^{(1)}](x,y) = D\\sigma^{(1)}(x,y) b(x,y) - Db(x,y) \\sigma^{(1)}(x,y)\n$$\n$$\n[b, \\sigma^{(1)}](x,y) = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ x^{2} \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 2x & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n[b, \\sigma^{(1)}](x,y) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} (0)(1) + (0)(0) \\\\ (2x)(1) + (0)(0) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 2x \\end{pmatrix}\n$$\n$$\n[b, \\sigma^{(1)}](x,y) = \\begin{pmatrix} 0 \\\\ -2x \\end{pmatrix}\n$$\n\n### Part 2: Role of the Lie Bracket in Accessibility and Connection to the Stroock-Varadhan Theorem\n\nThe skeleton system is the controlled ordinary differential equation (ODE):\n$$\n\\dot{\\varphi}(t) = b(\\varphi(t)) + \\sigma^{(1)}(\\varphi(t)) u(t)\n$$\nwhere $u(t) = \\dot{h}(t)$. Letting $\\varphi(t) = (x(t), y(t))$, the system is:\n$$\n\\begin{cases} \\dot{x}(t) = u(t) \\\\ \\dot{y}(t) = x(t)^{2} \\end{cases}\n$$\nSmall-time local accessibility from a point $\\varphi_0$ means that the set of reachable points from $\\varphi_0$ in any arbitrarily small time contains a neighborhood of $\\varphi_0$. According to the Chow-Rashevsky theorem, a sufficient condition for accessibility is that the Lie algebra generated by the system's vector fields spans the entire tangent space at the point in question. The Lie algebra is the set of all vector fields obtained by taking repeated Lie brackets of the base vector fields, here $b$ and $\\sigma^{(1)}$, and their linear combinations.\n\nThe Lie bracket $[b, \\sigma^{(1)}]$ represents the first \"new\" vector field direction generated by the interaction of the drift $b$ and the controlled diffusion $\\sigma^{(1)}$. It quantifies the non-commutativity of the flows associated with these vector fields. We can demonstrate this from first principles by considering the net displacement from an infinitesimal path.\n\nConsider two paths starting from $\\varphi_0 = (x,y)$ over a total time of $2\\delta$:\nPath A: First, flow with $u(t) = c$ for time $\\delta$. This prioritizes motion influenced by $\\sigma^{(1)}$. Second, flow with $u(t) = 0$ for time $\\delta$. This is a pure drift motion.\nPath B: First, flow with $u(t) = 0$ for time $\\delta$. Second, flow with $u(t) = c$ for time $\\delta$.\n\nFor sufficiently small $\\delta$, the endpoint of Path A is approximately $\\varphi_A \\approx \\varphi_0 + \\delta(b(\\varphi_0)+c\\sigma^{(1)}(\\varphi_0)) + \\delta b(\\varphi_0+\\delta(b(\\varphi_0)+c\\sigma^{(1)}(\\varphi_0)))$.\nSimilarly, the endpoint of Path B is approximately $\\varphi_B \\approx \\varphi_0 + \\delta b(\\varphi_0) + \\delta(b(\\varphi_0+\\delta b(\\varphi_0))+c\\sigma^{(1)}(\\varphi_0+\\delta b(\\varphi_0)))$.\nA more direct calculation using the ODEs: let $\\varphi_0=(x_0, y_0)$.\nPath A's endpoint: $(x_0+c\\delta, y_0 + 2x_0^2\\delta + (2x_0c)\\delta^2 + O(\\delta^3))$.\nPath B's endpoint: $(x_0+c\\delta, y_0 + 2x_0^2\\delta + (x_0c)\\delta^2 + O(\\delta^3))$.\nThe difference vector is $\\varphi_A - \\varphi_B = (0, x_0c\\delta^2) + O(\\delta^3)$. This is a displacement of order $\\delta^2$ in the direction $(0,1)$, i.e., the vertical direction. The Lie bracket $[b, \\sigma^{(1)}] = (0, -2x)$ is also in this direction. This non-zero second-order displacement demonstrates how interacting flows can generate motion in a direction that might not be available from a simple linear combination of the primary vector fields.\n\nFor accessibility at a point $(x,y)$ with $x \\neq 0$, we examine the rank of the set of vector fields. The primary fields are $\\sigma^{(1)}(x,y) = (1, 0)^\\top$ and $b(x,y) = (0, x^2)^\\top$. The matrix formed by these two vectors is $\\begin{pmatrix} 1 & 0 \\\\ 0 & x^2 \\end{pmatrix}$, which has determinant $x^2$. Since $x \\neq 0$, the determinant is non-zero, and the two vectors are linearly independent, spanning $\\mathbb{R}^2$. Thus, the system is small-time locally accessible from any point $(x,y)$ where $x \\neq 0$. In this case, the Lie bracket $[b, \\sigma^{(1)}] = (0, -2x)^\\top$ is linearly dependent on $b$ (since $[b,\\sigma^{(1)}] = (-2/x)b$ for $x \\neq 0$), so it does not introduce a new direction. However, its computation is the crucial first step in the general procedure (Hörmander's condition) for verifying accessibility. If the primary vector fields were not sufficient, this bracket and further ones would be essential.\n\nThe Stroock-Varadhan support theorem states that the support of the law of the SDE solution $X_t$ is the closure of the set of all skeleton trajectories $\\varphi(t)$. Since the skeleton system is accessible for any initial condition $(x_0, y_0)$ with $x_0 \\neq 0$, the SDE process $X_t$, starting from such a point, can stochastically follow paths that explore an entire open neighborhood of the starting point. The support of its distribution will therefore be a set with a non-empty interior in $\\mathbb{R}^2$. The accessibility analysis, which hinges on the properties of the Lie algebra, thus reveals the geometric structure of the support of the SDE's solution.\n\n### Part 3: Computation of $\\Delta(x,y)$\n\nThe scalar function $\\Delta(x,y)$ is defined as the determinant of the matrix whose columns are the vector fields $\\sigma^{(1)}(x,y)$ and $[b,\\sigma^{(1)}](x,y)$.\nFrom Part 1, we have:\n$$\n\\sigma^{(1)}(x,y) = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\n[b, \\sigma^{(1)}](x,y) = \\begin{pmatrix} 0 \\\\ -2x \\end{pmatrix}\n$$\nWe form the matrix and compute its determinant:\n$$\n\\Delta(x,y) = \\det\\!\\begin{pmatrix} 1 & 0 \\\\ 0 & -2x \\end{pmatrix}\n$$\nThe determinant of a $2 \\times 2$ matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ is $ad-bc$.\n$$\n\\Delta(x,y) = (1)(-2x) - (0)(0)\n$$\n$$\n\\Delta(x,y) = -2x\n$$\nThis function $\\Delta(x,y)$ is known as a basic component of the Hörmander condition check. The condition for accessibility at level one is that the matrix of vector fields and their first-order brackets has full rank. Here, $\\Delta(x,y) \\neq 0$ if and only if $x \\neq 0$, confirming our analysis that the system is fully accessible off the $y$-axis.", "answer": "$$\n\\boxed{-2x}\n$$", "id": "3004326"}]}