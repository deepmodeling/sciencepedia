{"hands_on_practices": [{"introduction": "The framework of random dynamical systems is surprisingly versatile, extending beyond purely stochastic phenomena to describe non-autonomous deterministic systems. This exercise provides a foundational bridge by re-interpreting a simple non-autonomous ODE as a cocycle over a deterministic 'shift' flow [@problem_id:2992721]. By explicitly deriving the solution and verifying the cocycle property, you will gain a concrete intuition for this central concept, grounding the abstract definition in the familiar context of ordinary differential equations.", "problem": "Consider the measurable space $(\\Omega, \\mathcal{F}) = (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$ and the shift flow $\\theta : \\mathbb{R} \\times \\Omega \\to \\Omega$ given by $\\theta_{t}(\\omega) = \\omega + t$. Interpret the nonautonomous Ordinary Differential Equation (ODE)\n$$\n\\dot{x}(t) = a(\\theta_{t}\\omega)\\,x(t), \\quad a(\\xi) = \\lambda + \\mu \\sin(\\xi),\n$$\nwith fixed parameters $\\lambda, \\mu \\in \\mathbb{R}$, as a Random Dynamical System (RDS) over the driving flow $(\\Omega, \\theta)$. Define the cocycle $\\varphi : [0,\\infty) \\times \\Omega \\times \\mathbb{R} \\to \\mathbb{R}$ by setting $\\varphi(t,\\omega,x)$ equal to the time-$t$ value of the unique solution to the ODE with initial condition $x(0)=x$ at base point $\\omega$. Starting from the definitions of a cocycle over $(\\Omega,\\theta)$ and the fundamental existence and uniqueness theorem for ODEs, derive the expression for $\\varphi(t,\\omega,x)$ and verify the cocycle property\n$$\n\\varphi(t+s,\\omega,x) = \\varphi\\bigl(t, \\theta_{s}\\omega, \\varphi(s,\\omega,x)\\bigr)\n$$\nfor all $t,s \\ge 0$, all $\\omega \\in \\Omega$, and all $x \\in \\mathbb{R}$.\n\nYour final answer should be the explicit closed-form analytic expression for $\\varphi(t,\\omega,x)$ in terms of $t$, $\\omega$, $x$, $\\lambda$, and $\\mu$. No numerical approximation is required.", "solution": "The problem asks for two things: first, to derive the explicit expression for the cocycle $\\varphi(t,\\omega,x)$ associated with a given nonautonomous ordinary differential equation (ODE), and second, to verify that this expression satisfies the cocycle property.\n\nThe given ODE is:\n$$\n\\dot{x}(t) = a(\\theta_{t}\\omega)\\,x(t)\n$$\nwhere the driving flow is a shift $\\theta_{t}(\\omega) = \\omega + t$ on $\\Omega = \\mathbb{R}$, and the coefficient function is $a(\\xi) = \\lambda + \\mu \\sin(\\xi)$ for parameters $\\lambda, \\mu \\in \\mathbb{R}$. Substituting these into the ODE yields:\n$$\n\\frac{dx}{dt} = (\\lambda + \\mu \\sin(\\omega + t)) x(t)\n$$\nThis is a first-order linear homogeneous ODE, which is also separable. We are seeking the solution $x(t)$ with the initial condition $x(0) = x$.\n\nFirst, we derive the expression for $\\varphi(t,\\omega,x)$.\nWe separate variables, assuming $x(t) \\neq 0$. If $x(0)=0$, the unique solution is $x(t)=0$ for all $t$, which is consistent with the derived formula. For $x \\neq 0$:\n$$\n\\frac{1}{x(t)} \\frac{dx}{dt} = \\lambda + \\mu \\sin(\\omega + t)\n$$\nWe integrate both sides with respect to time from an initial time $s=0$ to a final time $s=t$:\n$$\n\\int_{0}^{t} \\frac{1}{x(s)} \\frac{dx}{ds} ds = \\int_{0}^{t} (\\lambda + \\mu \\sin(\\omega + s)) ds\n$$\nThe left-hand side (LHS) can be evaluated by a change of variables to $y=x(s)$, so $dy = \\frac{dx}{ds}ds$:\n$$\n\\text{LHS} = \\int_{x(0)}^{x(t)} \\frac{1}{y} dy = \\Big[\\ln|y|\\Big]_{x(0)}^{x(t)} = \\ln|x(t)| - \\ln|x(0)| = \\ln\\left|\\frac{x(t)}{x(0)}\\right|\n$$\nSince this is a linear homogeneous ODE, the solution $x(t)$ will have the same sign as the initial condition $x(0)$. Therefore, the ratio $x(t)/x(0)$ is always positive, and the absolute value can be removed.\n$$\n\\text{LHS} = \\ln\\left(\\frac{x(t)}{x(0)}\\right)\n$$\nThe right-hand side (RHS) is a standard integral:\n$$\n\\text{RHS} = \\int_{0}^{t} (\\lambda + \\mu \\sin(\\omega + s)) ds = \\left[ \\lambda s - \\mu \\cos(\\omega + s) \\right]_{s=0}^{s=t}\n$$\nEvaluating the integral at the limits of integration:\n$$\n\\text{RHS} = \\left( \\lambda t - \\mu \\cos(\\omega + t) \\right) - \\left( \\lambda \\cdot 0 - \\mu \\cos(\\omega + 0) \\right) = \\lambda t - \\mu \\cos(\\omega + t) + \\mu \\cos(\\omega)\n$$\nThis can be rewritten as:\n$$\n\\text{RHS} = \\lambda t + \\mu(\\cos(\\omega) - \\cos(\\omega + t))\n$$\nEquating the LHS and RHS:\n$$\n\\ln\\left(\\frac{x(t)}{x(0)}\\right) = \\lambda t + \\mu(\\cos(\\omega) - \\cos(\\omega + t))\n$$\nTo solve for $x(t)$, we exponentiate both sides:\n$$\n\\frac{x(t)}{x(0)} = \\exp\\left( \\lambda t + \\mu(\\cos(\\omega) - \\cos(\\omega + t)) \\right)\n$$\nThe solution $x(t)$ with the initial condition $x(0)=x$ is:\n$$\nx(t) = x \\exp\\left( \\lambda t + \\mu(\\cos(\\omega) - \\cos(\\omega + t)) \\right)\n$$\nBy definition, the cocycle $\\varphi(t,\\omega,x)$ is this unique solution. Thus, we have the explicit expression:\n$$\n\\varphi(t,\\omega,x) = x \\exp\\left( \\lambda t + \\mu(\\cos(\\omega) - \\cos(\\omega + t)) \\right)\n$$\nThis completes the first part of the task.\n\nSecond, we verify the cocycle property for all $t,s \\ge 0$, $\\omega \\in \\mathbb{R}$, and $x \\in \\mathbb{R}$:\n$$\n\\varphi(t+s,\\omega,x) = \\varphi\\bigl(t, \\theta_{s}\\omega, \\varphi(s,\\omega,x)\\bigr)\n$$\nWe will compute the left-hand side (LHS) and right-hand side (RHS) of this equation independently and show they are equal.\n\nFor the LHS, we substitute $t+s$ for $t$ in the expression for $\\varphi(t,\\omega,x)$:\n$$\n\\text{LHS} = \\varphi(t+s,\\omega,x) = x \\exp\\left( \\lambda (t+s) + \\mu(\\cos(\\omega) - \\cos(\\omega + t + s)) \\right)\n$$\n\nFor the RHS, we proceed in steps. First, we evaluate the inner terms:\nThe new state at time $s$ is $x' = \\varphi(s,\\omega,x)$:\n$$\nx' = x \\exp\\left( \\lambda s + \\mu(\\cos(\\omega) - \\cos(\\omega+s)) \\right)\n$$\nThe new base point is $\\omega' = \\theta_{s}\\omega = \\omega+s$.\n\nNow, we compute the outer part of the RHS, which is $\\varphi(t, \\omega', x')$:\n$$\n\\text{RHS} = \\varphi(t, \\omega', x') = x' \\exp\\left( \\lambda t + \\mu(\\cos(\\omega') - \\cos(\\omega' + t)) \\right)\n$$\nSubstitute the expressions for $x'$ and $\\omega'$:\n$$\n\\text{RHS} = \\left( x \\exp\\left( \\lambda s + \\mu(\\cos(\\omega) - \\cos(\\omega+s)) \\right) \\right) \\cdot \\exp\\left( \\lambda t + \\mu(\\cos(\\omega+s) - \\cos(\\omega+s+t)) \\right)\n$$\nUsing the property $\\exp(A)\\exp(B) = \\exp(A+B)$, we can combine the exponents:\n$$\n\\text{RHS} = x \\exp\\left( \\left(\\lambda s + \\mu(\\cos(\\omega) - \\cos(\\omega+s))\\right) + \\left(\\lambda t + \\mu(\\cos(\\omega+s) - \\cos(\\omega+s+t))\\right) \\right)\n$$\nLet's simplify the total exponent:\n$$\n\\text{Exponent} = \\lambda s + \\lambda t + \\mu\\cos(\\omega) - \\mu\\cos(\\omega+s) + \\mu\\cos(\\omega+s) - \\mu\\cos(\\omega+s+t)\n$$\nThe terms $-\\mu\\cos(\\omega+s)$ and $+\\mu\\cos(\\omega+s)$ cancel each other out.\n$$\n\\text{Exponent} = \\lambda(s+t) + \\mu\\cos(\\omega) - \\mu\\cos(\\omega+s+t) = \\lambda(t+s) + \\mu(\\cos(\\omega) - \\cos(\\omega+t+s))\n$$\nSubstituting this simplified exponent back into the expression for the RHS gives:\n$$\n\\text{RHS} = x \\exp\\left( \\lambda(t+s) + \\mu(\\cos(\\omega) - \\cos(\\omega+t+s)) \\right)\n$$\nComparing the final expressions for the LHS and RHS:\n$$\n\\text{LHS} = x \\exp\\left( \\lambda(t+s) + \\mu(\\cos(\\omega) - \\cos(\\omega+t+s)) \\right)\n$$\n$$\n\\text{RHS} = x \\exp\\left( \\lambda(t+s) + \\mu(\\cos(\\omega) - \\cos(\\omega+t+s)) \\right)\n$$\nThe expressions are identical. This verifies that the derived function $\\varphi(t,\\omega,x)$ satisfies the cocycle property.", "answer": "$$ \\boxed{x \\exp\\left(\\lambda t + \\mu(\\cos(\\omega) - \\cos(\\omega + t))\\right)} $$", "id": "2992721"}, {"introduction": "A central goal in studying random dynamical systems is to quantify the long-term stability of solutions. The top Lyapunov exponent provides the key measure, indicating the average exponential rate of growth or decay. This practice focuses on explicitly calculating this exponent for geometric Brownian motion, a cornerstone model for systems with multiplicative noise [@problem_id:2992765]. Critically, you will discover how the choice between Itô and Stratonovich interpretations of the noise leads to different stability conclusions, a fundamental lesson in stochastic modeling.", "problem": "Consider the scalar stochastic differential equation (SDE) with multiplicative noise given by $dX_{t}=a\\,X_{t}\\,dt+\\sigma\\,X_{t}\\,dW_{t}$, where $a\\in\\mathbb{R}$, $\\sigma>0$, and $W_{t}$ is a standard one-dimensional Wiener process. Regard this SDE as generating a random dynamical system (RDS) over the canonical Wiener space $(\\Omega,\\mathcal{F},\\mathbb{P})$ equipped with the Wiener shift $(\\theta_{t})_{t\\in\\mathbb{R}}$, and the associated linear cocycle $\\varphi(t,\\omega):\\mathbb{R}\\to\\mathbb{R}$ defined by $\\varphi(t,\\omega)\\,x=X_{t}(\\omega;x)$ for initial condition $X_{0}=x\\neq 0$. The top Lyapunov exponent of this linear cocycle is defined (when it exists) by $\\lambda=\\lim_{t\\to\\infty}\\frac{1}{t}\\ln|\\varphi(t,\\omega)\\,x|$ for almost every $\\omega\\in\\Omega$ and any fixed $x\\neq 0$.\n\nStarting from the fundamental definitions of a random dynamical system and a linear cocycle, and using only the core rules of Itô calculus and Stratonovich calculus (including the Itô–Stratonovich conversion and the respective chain rules), derive the almost sure limit $\\lambda$ explicitly in terms of $a$ and $\\sigma$ for the Itô interpretation of the SDE. Then, reinterpret the same model in the Stratonovich sense, $dX_{t}=a\\,X_{t}\\,dt+\\sigma\\,X_{t}\\circ dW_{t}$, and derive the corresponding almost sure Lyapunov exponent.\n\nYour reasoning should make clear why the exponent exists almost surely and how the Wiener shift yields the cocycle property. Express your final answer as a closed-form analytic expression in terms of $a$ and $\\sigma$, reported as a row matrix with the Itô exponent first and the Stratonovich exponent second. No numerical approximation is required, and no units are involved.", "solution": "We will derive the Lyapunov exponent for the two interpretations of the SDE.\n\n**Part 1: Itô Interpretation**\n\nThe SDE is given in the Itô sense:\n$$dX_{t} = a\\,X_{t}\\,dt + \\sigma\\,X_{t}\\,dW_{t}$$\nwith initial condition $X_{0} = x \\in \\mathbb{R}$, $x \\neq 0$.\n\nTo solve this linear SDE, we seek a transformation that simplifies it. Let us consider the function $f(X_{t}) = \\ln(X_{t})$. Since $X_{0} = x \\neq 0$ and the solution to this SDE almost surely does not cross zero, $X_{t}$ maintains the sign of $x$, and $\\ln|X_{t}|$ is well-defined for all $t \\geq 0$. Without loss of generality, let us assume $x>0$ so that $X_t > 0$. The analysis for $x<0$ is identical for $|\\varphi(t, \\omega)x|$. Let $Y_{t} = \\ln(X_{t})$. We apply Itô's lemma to $f(x) = \\ln(x)$, which has derivatives $f'(x) = 1/x$ and $f''(x) = -1/x^{2}$.\n\nAccording to Itô's lemma, the differential for $Y_t$ is:\n$$dY_{t} = f'(X_{t})dX_{t} + \\frac{1}{2}f''(X_{t})(dX_{t})^{2}$$\nThe quadratic variation term $(dX_{t})^{2}$ is calculated using the Itô rules, where $dt \\cdot dt = 0$, $dt \\cdot dW_{t} = 0$, and $dW_{t} \\cdot dW_{t} = dt$:\n$$(dX_{t})^{2} = (a\\,X_{t}\\,dt + \\sigma\\,X_{t}\\,dW_{t})^{2} = (\\sigma\\,X_{t})^{2}(dW_{t})^{2} = \\sigma^{2}X_{t}^{2}\\,dt$$\nSubstituting $dX_t$ and $(dX_t)^2$ into the expression for $dY_t$:\n$$dY_{t} = \\frac{1}{X_{t}}(a\\,X_{t}\\,dt + \\sigma\\,X_{t}\\,dW_{t}) + \\frac{1}{2}\\left(-\\frac{1}{X_{t}^{2}}\\right)(\\sigma^{2}X_{t}^{2}\\,dt)$$\n$$dY_{t} = (a\\,dt + \\sigma\\,dW_{t}) - \\frac{1}{2}\\sigma^{2}\\,dt$$\n$$dY_{t} = \\left(a - \\frac{1}{2}\\sigma^{2}\\right)dt + \\sigma\\,dW_{t}$$\nThis is a linear SDE with constant coefficients, which can be integrated directly from $t=0$ to $t=T$:\n$$Y_{T} - Y_{0} = \\int_{0}^{T} \\left(a - \\frac{1}{2}\\sigma^{2}\\right)dt + \\int_{0}^{T} \\sigma\\,dW_{t}$$\n$$\\ln(X_{T}) - \\ln(X_{0}) = \\left(a - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma(W_{T}-W_{0})$$\nSince $X_0 = x$ and $W_0=0$ by convention, we have:\n$$\\ln(X_{T}) = \\ln(x) + \\left(a - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma\\,W_{T}$$\nExponentiating both sides yields the explicit solution for $X_{T}$:\n$$X_{T}(\\omega; x) = x \\exp\\left(\\left(a - \\frac{1}{2}\\sigma^{2}\\right)T + \\sigma\\,W_{T}(\\omega)\\right)$$\nThis defines the linear cocycle $\\varphi(T,\\omega)x = X_{T}(\\omega; x)$. This map satisfies the cocycle property $\\varphi(t+s, \\omega) = \\varphi(t, \\theta_s \\omega) \\circ \\varphi(s, \\omega)$ because of the property of the Wiener shift $\\theta_s$, which states $W_t(\\theta_s \\omega) = W_{t+s}(\\omega) - W_s(\\omega)$. The composition gives\n$\\varphi(t, \\theta_s \\omega)[\\varphi(s, \\omega)x] = [x \\exp((a-\\frac{1}{2}\\sigma^2)s + \\sigma W_s(\\omega))] \\exp((a-\\frac{1}{2}\\sigma^2)t + \\sigma W_t(\\theta_s\\omega)) = x \\exp((a-\\frac{1}{2}\\sigma^2)(s+t) + \\sigma W_s(\\omega) + \\sigma(W_{s+t}(\\omega)-W_s(\\omega))) = x \\exp((a-\\frac{1}{2}\\sigma^2)(t+s) + \\sigma W_{t+s}(\\omega)) = \\varphi(t+s, \\omega)x$.\n\nThe top Lyapunov exponent, which we denote $\\lambda_{I}$ for the Itô case, is defined as:\n$$\\lambda_{I} = \\lim_{t\\to\\infty} \\frac{1}{t}\\ln|\\varphi(t,\\omega)x|$$\nSubstituting the solution:\n$$\\lambda_{I} = \\lim_{t\\to\\infty} \\frac{1}{t}\\ln\\left|x \\exp\\left(\\left(a - \\frac{1}{2}\\sigma^{2}\\right)t + \\sigma\\,W_{t}(\\omega)\\right)\\right|$$\n$$\\lambda_{I} = \\lim_{t\\to\\infty} \\frac{1}{t}\\left[\\ln|x| + \\left(a - \\frac{1}{2}\\sigma^{2}\\right)t + \\sigma\\,W_{t}(\\omega)\\right]$$\n$$\\lambda_{I} = \\lim_{t\\to\\infty} \\left(\\frac{\\ln|x|}{t} + a - \\frac{1}{2}\\sigma^{2} + \\sigma\\frac{W_{t}(\\omega)}{t}\\right)$$\nThe limit exists almost surely. This is rigorously guaranteed by Oseledets' Multiplicative Ergodic Theorem for linear cocycles over an ergodic base flow (the Wiener shift). The direct calculation relies on two standard limits:\n1. $\\lim_{t\\to\\infty} \\frac{\\ln|x|}{t} = 0$ for any fixed $x \\neq 0$.\n2. The strong law of large numbers for the Wiener process states that $\\lim_{t\\to\\infty} \\frac{W_{t}(\\omega)}{t} = 0$ for almost every path $\\omega \\in \\Omega$.\n\nApplying these limits, we find the Lyapunov exponent:\n$$\\lambda_{I} = 0 + a - \\frac{1}{2}\\sigma^{2} + \\sigma \\cdot 0 = a - \\frac{1}{2}\\sigma^{2}$$\n\n**Part 2: Stratonovich Interpretation**\n\nThe SDE is given in the Stratonovich sense:\n$$dX_{t} = a\\,X_{t}\\,dt + \\sigma\\,X_{t}\\circ dW_{t}$$\nTo find the corresponding Lyapunov exponent, $\\lambda_{S}$, we can convert the Stratonovich SDE to its Itô equivalent. For a general Stratonovich SDE $dX_{t} = b(X_{t},t)\\,dt + g(X_{t},t)\\circ dW_{t}$, the equivalent Itô SDE is $dX_{t} = \\tilde{b}(X_{t},t)\\,dt + g(X_{t},t)\\,dW_{t}$, where the Itô drift $\\tilde{b}$ is related to the Stratonovich drift $b$ by the correction term:\n$$\\tilde{b}(x,t) = b(x,t) + \\frac{1}{2}\\frac{\\partial g}{\\partial x}(x,t)g(x,t)$$\nIn our case, $b(X_{t},t) = a\\,X_{t}$ and $g(X_{t},t) = \\sigma\\,X_{t}$. The partial derivative of $g$ with respect to its state variable is $\\frac{\\partial g}{\\partial x} = \\sigma$.\nThe Itô correction term is therefore:\n$$\\frac{1}{2}\\sigma \\cdot (\\sigma X_{t}) = \\frac{1}{2}\\sigma^{2}X_{t}$$\nThe drift of the equivalent Itô SDE is:\n$$\\tilde{b}(X_{t}) = a\\,X_{t} + \\frac{1}{2}\\sigma^{2}X_{t} = \\left(a + \\frac{1}{2}\\sigma^{2}\\right)X_{t}$$\nThus, the Stratonovich SDE $dX_{t} = a\\,X_{t}\\,dt + \\sigma\\,X_{t}\\circ dW_{t}$ corresponds to the Itô SDE:\n$$dX_{t} = \\left(a + \\frac{1}{2}\\sigma^{2}\\right)X_{t}\\,dt + \\sigma\\,X_{t}\\,dW_{t}$$\nThis Itô SDE is of the exact same form as the one analyzed in Part $1$, with the drift parameter $a$ replaced by an effective drift $a' = a + \\frac{1}{2}\\sigma^{2}$. We can therefore directly use the result from Part $1$ by substituting $a$ with $a'$.\nThe Lyapunov exponent for this system is:\n$$\\lambda_{S} = a' - \\frac{1}{2}\\sigma^{2} = \\left(a + \\frac{1}{2}\\sigma^{2}\\right) - \\frac{1}{2}\\sigma^{2} = a$$\nAlternatively, one could solve the Stratonovich SDE directly. The Stratonovich chain rule is identical to the ordinary chain rule. For $Y_{t} = \\ln(X_{t})$, we have $dY_{t} = \\frac{1}{X_{t}}\\circ dX_{t}$.\n$$d(\\ln X_{t}) = \\frac{1}{X_{t}}\\circ (aX_{t}\\,dt + \\sigma X_{t}\\circ dW_{t}) = a\\,dt + \\sigma\\circ dW_{t} = a\\,dt + \\sigma\\,dW_{t}$$\nIntegrating gives $\\ln(X_{t}) = \\ln(x) + at + \\sigma W_{t}$. The solution is $X_t = x\\exp(at + \\sigma W_t)$.\nThe Lyapunov exponent is then $\\lambda_S = \\lim_{t\\to\\infty} \\frac{1}{t}(\\ln|x| + at + \\sigma W_t) = a$, confirming the result.\n\n**Conclusion**\nThe Lyapunov exponent for the Itô SDE is $\\lambda_{I} = a - \\frac{1}{2}\\sigma^{2}$.\nThe Lyapunov exponent for the Stratonovich SDE is $\\lambda_{S} = a$.\nThe problem requests the result as a row matrix with the Itô exponent first.", "answer": "$$\n\\boxed{\\begin{pmatrix} a - \\frac{1}{2}\\sigma^{2} & a \\end{pmatrix}}\n$$", "id": "2992765"}, {"introduction": "The celebrated Multiplicative Ergodic Theorem of Oseledec connects the long-term behavior of a cocycle to the statistical properties of its driving random flow. This exercise delves into one of the theorem's core assumptions: ergodicity. You will construct a simple but insightful example of a non-ergodic driving system and demonstrate how this structural feature leads to the existence of multiple distinct Lyapunov exponents on different parts of the space [@problem_id:2992729]. This provides a powerful illustration of how the structure of the underlying randomness dictates the entire system's asymptotic dynamics.", "problem": "Consider the canonical two-sided Wiener space defined as follows. Let $\\Omega_{W} = C_{0}(\\mathbb{R}, \\mathbb{R})$ be the set of continuous functions $\\omega: \\mathbb{R} \\to \\mathbb{R}$ with $\\omega(0) = 0$, equipped with the canonical $\\sigma$-algebra $\\mathcal{F}_{W}$ generated by the coordinate process $W_{t}(\\omega) = \\omega(t)$ and the Wiener measure $\\mathbb{P}_{W}$ under which $\\{W_{t}\\}_{t \\in \\mathbb{R}}$ is a two-sided standard Brownian motion. Define the Wiener shift $\\{\\theta^{W}_{t}\\}_{t \\in \\mathbb{R}}$ by $(\\theta^{W}_{t} \\omega)(s) = \\omega(s+t) - \\omega(t)$.\n\nLet $E = \\{0,1\\}$ equipped with the discrete $\\sigma$-algebra, and let $\\nu$ be the probability measure with $\\nu(\\{0\\}) = \\alpha$ and $\\nu(\\{1\\}) = 1 - \\alpha$ for some fixed $\\alpha \\in (0,1)$. Define $\\Omega = \\Omega_{W} \\times E$, $\\mathcal{F} = \\mathcal{F}_{W} \\otimes 2^{E}$, and $\\mathbb{P} = \\mathbb{P}_{W} \\otimes \\nu$. Define the flow $\\{\\theta_{t}\\}_{t \\in \\mathbb{R}}$ on $\\Omega$ by $\\theta_{t}(\\omega,i) = (\\theta^{W}_{t}\\omega, i)$.\n\n1) Starting from the definition of a metric dynamical system, verify that $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\}_{t \\in \\mathbb{R}})$ is a metric dynamical system and prove that it is not ergodic.\n\n2) Fix constants $\\mu_{0}, \\mu_{1} \\in \\mathbb{R}$ and $\\sigma > 0$. For $(\\omega,i) \\in \\Omega$ and $x_{0} \\in \\mathbb{R} \\setminus \\{0\\}$, consider the scalar stochastic differential equation in the Itô sense\n$$\n\\mathrm{d}X_{t} = \\mu_{i}\\, X_{t}\\, \\mathrm{d}t + \\sigma\\, X_{t}\\, \\mathrm{d}W_{t}(\\omega), \\quad X_{0} = x_{0},\n$$\nwhere $W_{t}(\\omega)$ is the canonical Brownian motion on $\\Omega_{W}$. Let $\\varphi(t,\\omega,i)x_{0}$ denote the unique solution at time $t \\geq 0$ starting from $x_{0}$. Starting from the definition of a random dynamical system (RDS) cocycle over $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\})$, prove that $\\varphi$ is a measurable linear cocycle and derive an explicit expression for $\\varphi(t,\\omega,i)x_{0}$ in terms of $W_{t}(\\omega)$.\n\n3) Using only fundamental properties of Brownian motion and Itô calculus, compute the almost-sure top Lyapunov exponent on each invariant component $\\Omega_{W} \\times \\{0\\}$ and $\\Omega_{W} \\times \\{1\\}$ for the cocycle $\\varphi$. Conclude how the lack of ergodicity of $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\})$ obstructs uniqueness of the top Lyapunov exponent for the associated random dynamical system. Report the set of possible top Lyapunov exponents as a single row matrix in terms of $\\mu_{0}$, $\\mu_{1}$, and $\\sigma$.\n\nYour final answer must be that row matrix, as a closed-form analytic expression. Do not include any units and do not round.", "solution": "### Part 1: Metric Dynamical System and Ergodicity\n\nA metric dynamical system (MDS) is a quadruple $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\}_{t \\in \\mathbb{R}})$ where $(\\Omega, \\mathcal{F}, \\mathbb{P})$ is a probability space and $\\{\\theta_{t}\\}_{t \\in \\mathbb{R}}$ is a group of measure-preserving transformations of $\\Omega$. We verify each property for the given system.\n\n1.  **Probability Space**: By construction, $(\\Omega, \\mathcal{F}, \\mathbb{P}) = (\\Omega_{W} \\times E, \\mathcal{F}_{W} \\otimes 2^{E}, \\mathbb{P}_{W} \\otimes \\nu)$ is a product probability space, as $(\\Omega_W, \\mathcal{F}_W, \\mathbb{P}_W)$ is the canonical Wiener space and $(E, 2^E, \\nu)$ is a discrete probability space.\n\n2.  **Group Property**: The family of maps is $\\{\\theta_{t}\\}_{t \\in \\mathbb{R}}$ with $\\theta_{t}(\\omega,i) = (\\theta^{W}_{t}\\omega, i)$.\n    - For $t=0$, we have $\\theta_{0}(\\omega, i) = (\\theta^{W}_{0}\\omega, i)$. The action of $\\theta^{W}_{0}$ is $(\\theta^{W}_{0}\\omega)(s) = \\omega(s+0) - \\omega(0)$. Since $\\omega \\in \\Omega_W = C_0(\\mathbb{R}, \\mathbb{R})$, we have $\\omega(0) = 0$, so $(\\theta^{W}_{0}\\omega)(s) = \\omega(s)$. Thus, $\\theta^{W}_{0}$ is the identity map on $\\Omega_W$, and $\\theta_{0}$ is the identity map on $\\Omega$.\n    - For composition, let $s, t \\in \\mathbb{R}$. We examine $\\theta_{t} \\circ \\theta_{s}$.\n      $\\theta_{t}(\\theta_{s}(\\omega, i)) = \\theta_{t}(\\theta^{W}_{s}\\omega, i) = (\\theta^{W}_{t}(\\theta^{W}_{s}\\omega), i)$.\n      Let $\\tilde{\\omega} = \\theta^{W}_{s}\\omega$, so $\\tilde{\\omega}(u) = \\omega(u+s)-\\omega(s)$.\n      Then $(\\theta^{W}_{t}\\tilde{\\omega})(u) = \\tilde{\\omega}(u+t) - \\tilde{\\omega}(t) = [\\omega(u+t+s)-\\omega(s)] - [\\omega(t+s)-\\omega(s)] = \\omega(u+t+s) - \\omega(t+s)$.\n      On the other hand, $\\theta_{t+s}(\\omega, i) = (\\theta^{W}_{t+s}\\omega, i)$, where $(\\theta^{W}_{t+s}\\omega)(u) = \\omega(u+(t+s)) - \\omega(t+s)$.\n      These expressions match, so $\\theta_{t} \\circ \\theta_{s} = \\theta_{t+s}$. Thus, $\\{\\theta_{t}\\}_{t \\in \\mathbb{R}}$ forms a group.\n\n3.  **Measure Preservation**: We must show that for any $A \\in \\mathcal{F}$ and $t \\in \\mathbb{R}$, $\\mathbb{P}(\\theta_{t}^{-1}(A)) = \\mathbb{P}(A)$. It is sufficient to check this for generating sets of the form $A = A_W \\times A_E$, where $A_W \\in \\mathcal{F}_W$ and $A_E \\subseteq E$.\n    $\\theta_{t}^{-1}(A_W \\times A_E) = \\{(\\omega, i) \\in \\Omega \\mid \\theta_{t}(\\omega, i) \\in A_W \\times A_E\\} = \\{(\\omega, i) \\mid (\\theta^{W}_{t}\\omega, i) \\in A_W \\times A_E\\}$.\n    This requires $\\theta^{W}_{t}\\omega \\in A_W$ and $i \\in A_E$. So, $\\theta_{t}^{-1}(A_W \\times A_E) = (\\theta^{W}_{t})^{-1}(A_W) \\times A_E$.\n    The Wiener shift $\\theta^{W}_{t}$ is known to be a measure-preserving transformation on $(\\Omega_W, \\mathcal{F}_W, \\mathbb{P}_W)$ due to the stationary increments of the two-sided Brownian motion. Thus, $\\mathbb{P}_W((\\theta^{W}_{t})^{-1}(A_W)) = \\mathbb{P}_W(A_W)$.\n    Now we compute the measure:\n    $\\mathbb{P}(\\theta_{t}^{-1}(A_W \\times A_E)) = (\\mathbb{P}_W \\otimes \\nu)((\\theta^{W}_{t})^{-1}(A_W) \\times A_E) = \\mathbb{P}_W((\\theta^{W}_{t})^{-1}(A_W)) \\nu(A_E) = \\mathbb{P}_W(A_W) \\nu(A_E) = \\mathbb{P}(A_W \\times A_E)$.\n    By the $\\pi$-$\\lambda$ theorem, this extends to all sets in $\\mathcal{F} = \\mathcal{F}_W \\otimes 2^E$.\n    The joint measurability of the map $(t, \\xi) \\mapsto \\theta_t \\xi$ is a standard property of the Wiener shift.\n    Therefore, $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\}_{t \\in \\mathbb{R}})$ is a metric dynamical system.\n\n**Non-ergodicity**: An MDS is ergodic if every invariant set has measure $0$ or $1$. A set $A \\in \\mathcal{F}$ is invariant if $\\theta_{t}^{-1}(A) = A$ for all $t \\in \\mathbb{R}$ (up to a set of measure zero).\nConsider the set $A_0 = \\Omega_W \\times \\{0\\}$. For any $(\\omega, i) \\in A_0$, we have $i=0$. Then $\\theta_t(\\omega, i) = (\\theta_t^W \\omega, 0) \\in A_0$. Thus $\\theta_t(A_0) \\subseteq A_0$. Since $\\theta_t$ is invertible, we have $\\theta_t(A_0) = A_0$, which implies $\\theta_t^{-1}(A_0) = A_0$ for all $t \\in \\mathbb{R}$. So $A_0$ is an invariant set.\nThe measure of this set is $\\mathbb{P}(A_0) = \\mathbb{P}(\\Omega_W \\times \\{0\\}) = \\mathbb{P}_W(\\Omega_W) \\nu(\\{0\\}) = 1 \\cdot \\alpha = \\alpha$.\nSince it is given that $\\alpha \\in (0,1)$, we have found an invariant set $A_0$ with measure $\\mathbb{P}(A_0) = \\alpha \\notin \\{0, 1\\}$.\nTherefore, the metric dynamical system $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\})$ is not ergodic.\n\n### Part 2: Cocycle Property and Explicit Solution\n\nThe SDE is $dX_{t} = \\mu_{i}\\, X_{t}\\, \\mathrm{d}t + \\sigma\\, X_{t}\\, \\mathrm{d}W_{t}(\\omega)$ with $X_0 = x_0 \\neq 0$. This is the equation for geometric Brownian motion. To solve it, we use Itô's Lemma on the function $f(X_t) = \\ln(X_t)$. Since the solution to this SDE never crosses zero, we can assume without loss of generality that $x_0 > 0$, so $X_t > 0$ for all $t \\ge 0$.\nLet $Y_t = \\ln(X_t)$. By Itô's Lemma:\n$$ \\mathrm{d}Y_{t} = \\frac{1}{X_t} \\mathrm{d}X_{t} - \\frac{1}{2} \\frac{1}{X_t^2} (\\mathrm{d}X_{t})^2 $$\nUsing the SDE, we have $\\mathrm{d}X_{t} = \\mu_i X_t \\mathrm{d}t + \\sigma X_t \\mathrm{d}W_t$ and $(\\mathrm{d}X_{t})^2 = (\\sigma X_t \\mathrm{d}W_t)^2 = \\sigma^2 X_t^2 \\mathrm{d}t$.\nSubstituting these into the expression for $\\mathrm{d}Y_t$:\n$$ \\mathrm{d}Y_{t} = \\frac{1}{X_t}(\\mu_i X_t \\mathrm{d}t + \\sigma X_t \\mathrm{d}W_t) - \\frac{1}{2} \\frac{1}{X_t^2}(\\sigma^2 X_t^2 \\mathrm{d}t) = (\\mu_i - \\frac{\\sigma^2}{2})\\mathrm{d}t + \\sigma \\mathrm{d}W_t $$\nIntegrating from $0$ to $t$:\n$$ Y_t - Y_0 = \\int_0^t (\\mu_i - \\frac{\\sigma^2}{2})\\mathrm{d}s + \\int_0^t \\sigma \\mathrm{d}W_s(\\omega) $$\n$$ \\ln(X_t) - \\ln(x_0) = (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma (W_t(\\omega) - W_0(\\omega)) $$\nSince $W_0(\\omega) = \\omega(0) = 0$, we have $\\ln(X_t/x_0) = (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma W_t(\\omega)$.\nExponentiating gives the explicit solution:\n$$ X_t = x_0 \\exp\\left( \\left(\\mu_i - \\frac{\\sigma^2}{2}\\right)t + \\sigma W_t(\\omega) \\right) $$\nThis solution defines the map $\\varphi(t,\\omega,i)x_{0} = X_t$. The mapping $\\varphi(t,\\omega,i)$ can be identified with the scalar multiplication factor, which is clearly linear in $x_0$.\nNow we verify the cocycle properties for $\\varphi$ over $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_{t}\\})$. Let $\\xi = (\\omega, i)$.\n1.  **Identity Property**: For $t=0$,\n    $\\varphi(0,\\omega,i)x_{0} = x_{0} \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})\\cdot 0 + \\sigma W_0(\\omega) \\right) = x_{0} \\exp(0) = x_{0}$.\n    Thus, $\\varphi(0,\\xi)$ is the identity operator.\n\n2.  **Cocycle Property**: We must show $\\varphi(t+s, \\xi) = \\varphi(t, \\theta_{s}\\xi) \\circ \\varphi(s, \\xi)$.\n    LHS: $\\varphi(t+s, \\omega, i)x_0 = x_0 \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})(t+s) + \\sigma W_{t+s}(\\omega) \\right)$.\n    RHS: $\\varphi(t, \\theta_s(\\omega,i)) \\circ \\varphi(s, \\omega,i) x_0$.\n    First, $\\varphi(s, \\omega,i)x_0 = x_0 \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})s + \\sigma W_s(\\omega) \\right)$.\n    Next, we apply $\\varphi(t, \\theta_s\\xi) = \\varphi(t, \\theta_s^W\\omega, i)$ to this result:\n    $\\varphi(t, \\theta_s^W\\omega, i) \\left[ \\varphi(s, \\omega,i)x_0 \\right] = \\left[ \\varphi(s, \\omega,i)x_0 \\right] \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma W_t(\\theta_s^W\\omega) \\right)$.\n    The crucial step is to evaluate $W_t(\\theta_s^W\\omega)$. By definition, $(\\theta^W_s \\omega)(u) = \\omega(u+s)-\\omega(s)$. So, $W_t(\\theta^W_s \\omega) = (\\theta^W_s \\omega)(t) = \\omega(t+s)-\\omega(s) = W_{t+s}(\\omega) - W_s(\\omega)$.\n    Substituting this back:\n    RHS = $x_0 \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})s + \\sigma W_s(\\omega) \\right) \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma (W_{t+s}(\\omega) - W_s(\\omega)) \\right)$\n    RHS = $x_0 \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})(s+t) + \\sigma W_s(\\omega) + \\sigma W_{t+s}(\\omega) - \\sigma W_s(\\omega) \\right)$\n    RHS = $x_0 \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})(t+s) + \\sigma W_{t+s}(\\omega) \\right)$.\n    The LHS and RHS are identical.\n\n3.  **Measurability**: The map $(t,\\omega, i) \\mapsto \\varphi(t,\\omega,i)x_0$ is measurable because $W_t(\\omega)$ is jointly measurable in $(t, \\omega)$, the exponential function is continuous, and all other operations are elementary.\nTherefore, $\\varphi$ is a measurable linear cocycle.\n\n### Part 3: Lyapunov Exponents\n\nThe top Lyapunov exponent of the one-dimensional cocycle $\\varphi$ is given by the almost sure limit:\n$$ \\lambda(\\xi) = \\lim_{t \\to \\infty} \\frac{1}{t} \\ln |\\varphi(t, \\xi)| $$\nfor $\\xi = (\\omega, i)$, where $|\\varphi(t, \\xi)|$ is the operator norm of $\\varphi(t, \\xi)$, which for this scalar linear map is the absolute value of the multiplicative factor.\nFrom Part 2, $\\varphi(t, \\omega, i)x_0 = x_0 C(t,\\omega,i)$ where $C(t,\\omega,i) = \\exp\\left( (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma W_t(\\omega) \\right)$.\nThe norm is $|C(t,\\omega,i)|$, which is positive, so $|\\varphi(t, \\omega, i)| = C(t,\\omega,i)$.\nThen $\\ln |\\varphi(t, \\omega, i)| = (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma W_t(\\omega)$.\nThe Lyapunov exponent is:\n$$ \\lambda(\\omega, i) = \\lim_{t \\to \\infty} \\frac{1}{t} \\left[ (\\mu_i - \\frac{\\sigma^2}{2})t + \\sigma W_t(\\omega) \\right] = \\lim_{t \\to \\infty} \\left( \\mu_i - \\frac{\\sigma^2}{2} + \\sigma \\frac{W_t(\\omega)}{t} \\right) $$\nA fundamental property of Brownian motion is the Strong Law of Large Numbers, which states that $\\lim_{t \\to \\infty} \\frac{W_t}{t} = 0$ almost surely.\nUsing this property, we can compute the limit:\n$$ \\lambda(\\omega, i) = \\mu_i - \\frac{\\sigma^2}{2} + \\sigma \\cdot 0 = \\mu_i - \\frac{\\sigma^2}{2} $$\nThe Lyapunov exponent is constant for almost every $\\omega \\in \\Omega_W$, but it depends on the discrete component $i \\in \\{0, 1\\}$.\n\nOn the invariant component $\\Omega_W \\times \\{0\\}$ (where $i=0$), the top Lyapunov exponent is almost surely constant and equal to:\n$$ \\lambda_0 = \\mu_0 - \\frac{\\sigma^2}{2} $$\nOn the invariant component $\\Omega_W \\times \\{1\\}$ (where $i=1$), the top Lyapunov exponent is almost surely constant and equal to:\n$$ \\lambda_1 = \\mu_1 - \\frac{\\sigma^2}{2} $$\nOseledec's Multiplicative Ergodic Theorem guarantees that for an ergodic RDS, the Lyapunov exponents are constant almost surely over the entire phase space. In this case, the base dynamics $(\\Omega, \\mathcal{F}, \\mathbb{P}, \\{\\theta_t\\})$ is not ergodic. It decomposes into two ergodic components, $\\Omega_W \\times \\{0\\}$ and $\\Omega_W \\times \\{1\\}$. The theorem applies to each component individually, yielding a distinct Lyapunov exponent for each, provided $\\mu_0 \\neq \\mu_1$. The lack of ergodicity of the base system is what allows for multiple distinct Lyapunov exponents to exist on sets of positive measure, thereby obstructing the uniqueness of the top Lyapunov exponent for the system as a whole.\nThe set of possible top Lyapunov exponents for the RDS is $\\{\\lambda_0, \\lambda_1\\}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\mu_{0} - \\frac{\\sigma^{2}}{2} & \\mu_{1} - \\frac{\\sigma^{2}}{2}\n\\end{pmatrix}\n}\n$$", "id": "2992729"}]}