{"hands_on_practices": [{"introduction": "The Krylov-Röckner theory provides a powerful framework for handling stochastic differential equations with highly singular, non-classical drifts. Its applicability hinges on a crucial integrability condition on the drift coefficient $b$, namely that it belongs to a mixed Lebesgue space $L^q([0,T];L^p(\\mathbb{R}^d))$ for exponents satisfying the subcritical relation $\\frac{2}{q} + \\frac{d}{p} \\lt 1$. This hands-on calculation [@problem_id:2983489] grounds this abstract condition by having you compute the mixed-norm for a canonical example of a singular drift, revealing exactly how the dimension $d$ and the spatial integrability $p$ constrain the strength of the singularity at the origin.", "problem": "Let $d \\in \\mathbb{N}$ and $p,q \\in (1,\\infty)$ be fixed. Consider the drift candidate $b:[0,\\infty)\\times \\mathbb{R}^{d}\\to \\mathbb{R}$ given by\n$$\nb(t,x)=\\mathbf{1}_{[0,1]}(t)\\,\\mathbf{1}_{B(0,1)}(x)\\,|x|^{-\\gamma},\n$$\nwhere $B(0,1)=\\{x\\in\\mathbb{R}^{d}:|x|1\\}$ and $\\gamma0$. The mixed norm $L^{q}_{t}L^{p}_{x}$ of $b$ on $[0,1]\\times \\mathbb{R}^{d}$ is defined by\n$$\n\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))}:=\\left(\\int_{0}^{1}\\left(\\int_{\\mathbb{R}^{d}}|b(t,x)|^{p}\\,dx\\right)^{\\frac{q}{p}}\\,dt\\right)^{\\frac{1}{q}}.\n$$\nWorking from the fundamental definitions of mixed Lebesgue norms and spherical coordinates in $\\mathbb{R}^{d}$, derive a closed-form expression for $\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))}$ in terms of $d,p,q,\\gamma$. Then determine the largest value $\\gamma_{\\max}=\\gamma_{\\max}(d,p)$ such that $b\\in L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))$ holds. Express the final result using the Gamma function $\\Gamma(\\cdot)$ for geometric constants where appropriate.\n\nReport your final answer as a row matrix whose first entry is the closed-form value of $\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))}$ and whose second entry is the threshold $\\gamma_{\\max}$. No numerical approximation is required.", "solution": "The problem is well-posed and mathematically sound. We proceed with the derivation.\n\nThe objective is to compute the mixed Lebesgue norm of the function $b:[0,\\infty)\\times \\mathbb{R}^{d}\\to \\mathbb{R}$ defined by\n$$\nb(t,x)=\\mathbf{1}_{[0,1]}(t)\\,\\mathbf{1}_{B(0,1)}(x)\\,|x|^{-\\gamma}\n$$\nwhere $d \\in \\mathbb{N}$, $p,q \\in (1,\\infty)$, $\\gamma0$, and $B(0,1)$ is the open unit ball in $\\mathbb{R}^{d}$. The norm is given by\n$$\n\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))}:=\\left(\\int_{0}^{1}\\left(\\int_{\\mathbb{R}^{d}}|b(t,x)|^{p}\\,dx\\right)^{\\frac{q}{p}}\\,dt\\right)^{\\frac{1}{q}}.\n$$\nWe will compute the norm by evaluating the integrals from the inside out.\n\nFirst, consider the inner integral, which constitutes the $p$-th power of the $L^p$ norm of $b(t, \\cdot)$ for a fixed time $t$. Let us denote this by $I_p(t)$:\n$$\nI_p(t) := \\|b(t, \\cdot)\\|_{L^p(\\mathbb{R}^d)}^p = \\int_{\\mathbb{R}^{d}}|b(t,x)|^{p}\\,dx.\n$$\nFrom the definition of $b(t,x)$, we can see that if $t \\notin [0,1]$, then $b(t,x) = 0$ for all $x \\in \\mathbb{R}^d$, which implies $I_p(t) = 0$.\nIf $t \\in [0,1]$, the function simplifies to $b(t,x) = \\mathbf{1}_{B(0,1)}(x)\\,|x|^{-\\gamma}$. Since the indicator function and $|x|^{-\\gamma}$ are non-negative, we have $|b(t,x)| = b(t,x)$.\nThus, for $t \\in [0,1]$, the integral becomes:\n$$\nI_p(t) = \\int_{\\mathbb{R}^{d}} \\left| \\mathbf{1}_{B(0,1)}(x)\\,|x|^{-\\gamma} \\right|^{p}\\,dx = \\int_{\\mathbb{R}^{d}} \\mathbf{1}_{B(0,1)}(x)\\,|x|^{-p\\gamma}\\,dx.\n$$\nThe indicator function $\\mathbf{1}_{B(0,1)}(x)$ restricts the domain of integration to the unit ball $B(0,1)$. The integral is therefore:\n$$\nI_p(t) = \\int_{B(0,1)} |x|^{-p\\gamma}\\,dx.\n$$\nThe integrand $|x|^{-p\\gamma}$ is a radial function, so we convert the integral to spherical coordinates. In $\\mathbb{R}^d$, the differential volume element is $dx = r^{d-1} dr dS^{d-1}$, where $r = |x|$ is the radial coordinate and $dS^{d-1}$ is the surface element on the unit sphere $S^{d-1} \\subset \\mathbb{R}^d$. The integral becomes:\n$$\nI_p(t) = \\int_{S^{d-1}} \\int_{0}^{1} (r^{-p\\gamma}) r^{d-1} \\,dr \\,dS^{d-1}.\n$$\nSince the integrand does not depend on the angular variables, we can separate the integrals:\n$$\nI_p(t) = \\left( \\int_{S^{d-1}} dS^{d-1} \\right) \\left( \\int_{0}^{1} r^{d-1-p\\gamma} \\,dr \\right).\n$$\nThe first integral is the surface area of the $(d-1)$-dimensional unit sphere, denoted $A_d$. Its value is given by the formula $A_d = \\frac{2\\pi^{d/2}}{\\Gamma(d/2)}$, where $\\Gamma(\\cdot)$ is the Gamma function.\n\nThe second integral is the radial integral. For this integral to converge at the lower limit $r=0$, the exponent of $r$ must be greater than $-1$. That is:\n$$\nd - 1 - p\\gamma  -1 \\implies d - p\\gamma  0 \\implies p\\gamma  d \\implies \\gamma  \\frac{d}{p}.\n$$\nThis inequality gives the condition for the function $b$ to belong to the space $L^q([0,1];L^p(\\mathbb{R}^d))$, as its norm would otherwise be infinite.\n\nAssuming this condition holds, we can evaluate the radial integral:\n$$\n\\int_{0}^{1} r^{d-1-p\\gamma} \\,dr = \\left[ \\frac{r^{d-p\\gamma}}{d-p\\gamma} \\right]_{r=0}^{r=1} = \\frac{1^{d-p\\gamma}}{d-p\\gamma} - \\frac{0^{d-p\\gamma}}{d-p\\gamma} = \\frac{1}{d-p\\gamma}.\n$$\nCombining the results, for any $t \\in [0,1]$, we have:\n$$\nI_p(t) = A_d \\cdot \\frac{1}{d-p\\gamma} = \\frac{2\\pi^{d/2}}{\\Gamma(d/2)} \\frac{1}{d-p\\gamma}.\n$$\nNotice that this value is a constant for all $t$ in the interval $[0,1]$. Let's call this constant $C_{d,p,\\gamma}$.\n\nNow we proceed to the outer integral over time $t$:\n$$\n\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))}^q = \\int_{0}^{1}\\left( I_p(t) \\right)^{\\frac{q}{p}}\\,dt.\n$$\nSince $I_p(t) = C_{d,p,\\gamma}$ for $t \\in [0,1]$, the integrand is constant over the interval of integration:\n$$\n\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))}^q = \\int_{0}^{1} \\left( C_{d,p,\\gamma} \\right)^{\\frac{q}{p}}\\,dt = (C_{d,p,\\gamma})^{\\frac{q}{p}} \\int_{0}^{1} 1 \\,dt = (C_{d,p,\\gamma})^{\\frac{q}{p}}.\n$$\nTo find the norm, we take the $q$-th root of this expression:\n$$\n\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))} = \\left( (C_{d,p,\\gamma})^{\\frac{q}{p}} \\right)^{\\frac{1}{q}} = (C_{d,p,\\gamma})^{\\frac{1}{p}}.\n$$\nSubstituting the expression for $C_{d,p,\\gamma}$:\n$$\n\\|b\\|_{L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))} = \\left( \\frac{2\\pi^{d/2}}{\\Gamma(d/2)(d-p\\gamma)} \\right)^{\\frac{1}{p}}.\n$$\nThis is the closed-form expression for the norm. It is finite if and only if $\\gamma  d/p$. The problem statement also specifies $\\gamma0$. Therefore, the norm is finite for $\\gamma \\in (0, d/p)$.\n\nThe second task is to find the largest value $\\gamma_{\\max}=\\gamma_{\\max}(d,p)$ such that $b\\in L^{q}([0,1];L^{p}(\\mathbb{R}^{d}))$. This corresponds to the supremum of the set of all $\\gamma$ for which the norm is finite. The condition for finiteness is $\\gamma  d/p$. The largest value, or the supremum of the interval $(0, d/p)$, is:\n$$\n\\gamma_{\\max} = \\frac{d}{p}.\n$$\nNote that at $\\gamma = \\gamma_{\\max}$, the norm diverges, so the function is not in the space. The value $\\gamma_{\\max}$ represents the sharp upper bound.\n\nThe final answer consists of two parts: the expression for the norm and the value of $\\gamma_{\\max}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\left( \\frac{2\\pi^{\\frac{d}{2}}}{\\Gamma(\\frac{d}{2})(d-p\\gamma)} \\right)^{\\frac{1}{p}}  \\frac{d}{p} \\end{pmatrix}}\n$$", "id": "2983489"}, {"introduction": "The core idea of the Krylov-Röckner approach is to \"tame\" the singular drift by applying a Zvonkin-type transformation, $Y_t = \\Phi(X_t) = X_t + u(X_t)$. For this method to succeed, the transformed process $Y_t$ must inherit the good properties of the original diffusion, especially uniform ellipticity. This exercise [@problem_id:2983484] guides you through the application of Itô's formula to determine how the diffusion matrix transforms under $\\Phi$, demonstrating that ellipticity is indeed preserved as long as the gradient of the correction term, $\\|\\nabla u\\|_{\\infty}$, is sufficiently small.", "problem": "Consider a $d$-dimensional Stochastic Differential Equation (SDE) with distributional drift in the sense of Krylov-Röckner theory. Let $X_{t}$ solve\n$$\n\\mathrm{d}X_{t} = b(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t})\\,\\mathrm{d}W_{t},\n$$\nwhere $W_{t}$ is a $d$-dimensional standard Brownian motion, the diffusion matrix is $a(x) := \\sigma(x)\\sigma(x)^{\\top}$, and $a$ is uniformly elliptic in the sense that there exist constants $0\\lambda\\leq \\Lambda\\infty$ such that for every $x\\in\\mathbb{R}^{d}$ and every $v\\in\\mathbb{R}^{d}$,\n$$\n\\lambda\\,|v|^{2} \\le v^{\\top} a(x) v \\le \\Lambda\\,|v|^{2}.\n$$\nAssume $b$ is a distribution in a suitable negative Sobolev space controlled by Krylov-Röckner integrability conditions, and that the Zvonkin-type Partial Differential Equation (PDE) admits a solution $u:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ such that the map $\\Phi(x):=x+u(x)$ is a $C^{1}$-diffeomorphism with\n$$\n\\|\\nabla u\\|_{\\infty} \\le \\delta  \\tfrac{1}{2}.\n$$\nDefine $Y_{t}:=\\Phi(X_{t})$. Using Itô’s formula and first principles, derive the diffusion matrix $\\tilde{a}$ of $Y_{t}$ as a function of $a$ and $\\nabla\\Phi$, and then obtain explicit constants $\\lambda'$ and $\\Lambda'$ (in terms of $\\lambda$, $\\Lambda$, and $\\delta$ only) such that the transformed diffusion matrix $\\tilde{a}$ is uniformly elliptic with\n$$\n\\lambda'\\,|v|^{2} \\le v^{\\top} \\tilde{a}(y) v \\le \\Lambda'\\,|v|^{2}\n$$\nfor all $y\\in\\mathbb{R}^{d}$ and $v\\in\\mathbb{R}^{d}$. Express your final answer as closed-form analytic expressions for $\\lambda'$ and $\\Lambda'$ in terms of $\\lambda$, $\\Lambda$, and $\\delta$.", "solution": "The problem is subjected to validation and is deemed valid. It is a well-posed problem within the mathematical theory of stochastic differential equations, using standard assumptions and techniques that do not violate any scientific or logical principles.\n\nThe starting point is the $d$-dimensional stochastic differential equation (SDE) for the process $X_t$:\n$$\n\\mathrm{d}X_{t} = b(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t})\\,\\mathrm{d}W_{t},\n$$\nwhere $W_t$ is a $d$-dimensional standard Brownian motion. The diffusion matrix is $a(x) = \\sigma(x)\\sigma(x)^{\\top}$, which is assumed to be uniformly elliptic. This means there exist constants $0  \\lambda \\le \\Lambda  \\infty$ such that for all $x, v \\in \\mathbb{R}^d$:\n$$\n\\lambda|v|^2 \\le v^{\\top}a(x)v \\le \\Lambda|v|^2.\n$$\nWe consider a transformed process $Y_t = \\Phi(X_t)$, where the transformation is given by $\\Phi(x) = x + u(x)$. We are given that $\\Phi: \\mathbb{R}^d \\to \\mathbb{R}^d$ is a $C^1$-diffeomorphism and that the Jacobian matrix of $u$, denoted by $\\nabla u$, satisfies $\\|\\nabla u\\|_{\\infty} \\le \\delta  \\frac{1}{2}$, where $\\|\\cdot\\|_{\\infty}$ is the supremum operator norm over $\\mathbb{R}^d$.\n\nOur objective is to find the diffusion matrix $\\tilde{a}$ of the process $Y_t$ and to determine the new ellipticity constants $\\lambda'$ and $\\Lambda'$.\n\nFirst, we apply Itô's multidimensional formula to the function $\\Phi$ and the process $X_t$. Let $D\\Phi$ denote the Jacobian matrix of $\\Phi$, with entries $(D\\Phi)_{ij} = \\frac{\\partial \\Phi_i}{\\partial x_j}$. The SDE for $Y_t$ is given by:\n$$\n\\mathrm{d}Y_t = D\\Phi(X_t) \\mathrm{d}X_t + \\frac{1}{2} \\sum_{i=1}^d e_i \\left(\\text{Tr}\\left[ D^2\\Phi_i(X_t) a(X_t) \\right]\\right) \\mathrm{d}t,\n$$\nwhere $e_i$ is the $i$-th standard basis vector and $D^2\\Phi_i$ is the Hessian of the $i$-th component of $\\Phi$. Substituting the SDE for $X_t$:\n$$\n\\mathrm{d}Y_t = D\\Phi(X_t) \\left( b(X_t)\\,\\mathrm{d}t + \\sigma(X_t)\\,\\mathrm{d}W_{t} \\right) + \\text{drift term in }\\mathrm{d}t.\n$$\nWe are only concerned with the diffusion part of the SDE for $Y_t$. Grouping the terms, the SDE for $Y_t$ takes the form:\n$$\n\\mathrm{d}Y_t = \\tilde{b}(X_t) \\mathrm{d}t + D\\Phi(X_t) \\sigma(X_t) \\mathrm{d}W_t.\n$$\nThe new drift term $\\tilde{b}$ is of no concern for this problem. The transformed SDE is typically expressed in terms of $Y_t$. Since $\\Phi$ is a diffeomorphism, we can write $x = \\Phi^{-1}(y)$. Let $y=Y_t$. Then the diffusion coefficient of the SDE for $Y_t$ is $\\tilde{\\sigma}(y) = D\\Phi(\\Phi^{-1}(y))\\sigma(\\Phi^{-1}(y))$.\n\nThe corresponding diffusion matrix $\\tilde{a}(y)$ for the process $Y_t$ is given by $\\tilde{a}(y) = \\tilde{\\sigma}(y)\\tilde{\\sigma}(y)^{\\top}$. Substituting the expression for $\\tilde{\\sigma}(y)$:\n$$\n\\tilde{a}(y) = \\left(D\\Phi(x) \\sigma(x)\\right) \\left(D\\Phi(x) \\sigma(x)\\right)^{\\top} \\Big|_{x=\\Phi^{-1}(y)}\n$$\n$$\n\\tilde{a}(y) = \\left(D\\Phi(x) \\sigma(x) \\sigma(x)^{\\top} D\\Phi(x)^{\\top}\\right) \\Big|_{x=\\Phi^{-1}(y)}\n$$\n$$\n\\tilde{a}(y) = D\\Phi(x) a(x) D\\Phi(x)^{\\top} \\Big|_{x=\\Phi^{-1}(y)}.\n$$\nNow, we must find the bounds for the quadratic form $v^{\\top}\\tilde{a}(y)v$ for an arbitrary vector $v \\in \\mathbb{R}^d$. Let $x = \\Phi^{-1}(y)$.\n$$\nv^{\\top}\\tilde{a}(y)v = v^{\\top} \\left( D\\Phi(x) a(x) D\\Phi(x)^{\\top} \\right) v.\n$$\nLet us define a new vector $w = D\\Phi(x)^{\\top}v$. Then the quadratic form can be expressed as:\n$$\nv^{\\top}\\tilde{a}(y)v = w^{\\top}a(x)w.\n$$\nUsing the uniform ellipticity of $a(x)$, we have:\n$$\n\\lambda|w|^2 \\le w^{\\top}a(x)w \\le \\Lambda|w|^2.\n$$\nSubstituting back the expression for $w$:\n$$\n\\lambda|D\\Phi(x)^{\\top}v|^2 \\le v^{\\top}\\tilde{a}(y)v \\le \\Lambda|D\\Phi(x)^{\\top}v|^2.\n$$\nThe problem is now reduced to finding uniform lower and upper bounds for $|D\\Phi(x)^{\\top}v|^2$ in terms of $|v|^2$. The Jacobian of $\\Phi(x) = x+u(x)$ is $D\\Phi(x) = I + \\nabla u(x)$, where $I$ is the $d \\times d$ identity matrix and $\\nabla u(x)$ is the Jacobian of $u(x)$.\n\nLet us denote the matrix operator norm by $\\|\\cdot\\|_{op}$. For any matrix $M$, we have $|Mv|^2 \\le \\|M\\|_{op}^2 |v|^2$.\nFor the upper bound:\n$$\n|D\\Phi(x)^{\\top}v|^2 \\le \\|D\\Phi(x)^{\\top}\\|_{op}^2 |v|^2.\n$$\nSince $\\|M^{\\top}\\|_{op} = \\|M\\|_{op}$, we have $\\|D\\Phi(x)^{\\top}\\|_{op} = \\|D\\Phi(x)\\|_{op} = \\|I+\\nabla u(x)\\|_{op}$.\nUsing the triangle inequality for operator norms:\n$$\n\\|I+\\nabla u(x)\\|_{op} \\le \\|I\\|_{op} + \\|\\nabla u(x)\\|_{op}.\n$$\nWe know $\\|I\\|_{op}=1$ and from the problem statement, $\\|\\nabla u(x)\\|_{op} \\le \\|\\nabla u\\|_{\\infty} \\le \\delta$.\nThus, $\\|D\\Phi(x)\\|_{op} \\le 1+\\delta$. This bound is uniform in $x$.\nThis gives the upper bound on the quadratic form:\n$$\nv^{\\top}\\tilde{a}(y)v \\le \\Lambda |D\\Phi(x)^{\\top}v|^2 \\le \\Lambda (1+\\delta)^2 |v|^2.\n$$\nThis implies $\\Lambda' = \\Lambda(1+\\delta)^2$.\n\nFor the lower bound, we need a lower bound on $|D\\Phi(x)^{\\top}v|^2$. The squared norm is bounded below by the square of the smallest singular value of the matrix, $\\sigma_{\\min}$.\n$$\n|D\\Phi(x)^{\\top}v|^2 \\ge (\\sigma_{\\min}(D\\Phi(x)^{\\top}))^2 |v|^2.\n$$\nThe singular values of a matrix and its transpose are identical, so $\\sigma_{\\min}(D\\Phi(x)^{\\top}) = \\sigma_{\\min}(D\\Phi(x))$.\nThe smallest singular value of an invertible matrix $M$ is given by $\\sigma_{\\min}(M) = 1/\\|M^{-1}\\|_{op}$.\nThe matrix $D\\Phi(x) = I+\\nabla u(x)$ is invertible because $\\|\\nabla u(x)\\|_{op} \\le \\delta  1$. Its inverse can be expressed using a Neumann series:\n$$\n(I+\\nabla u(x))^{-1} = \\sum_{k=0}^{\\infty} (-\\nabla u(x))^k.\n$$\nThe norm of the inverse is bounded as follows:\n$$\n\\|(I+\\nabla u(x))^{-1}\\|_{op} \\le \\sum_{k=0}^{\\infty} \\|(-\\nabla u(x))^k\\|_{op} \\le \\sum_{k=0}^{\\infty} \\|\\nabla u(x)\\|_{op}^k = \\frac{1}{1-\\|\\nabla u(x)\\|_{op}}.\n$$\nSince $\\|\\nabla u(x)\\|_{op} \\le \\delta$, we have $1-\\|\\nabla u(x)\\|_{op} \\ge 1-\\delta$. Therefore,\n$$\n\\|(I+\\nabla u(x))^{-1}\\|_{op} \\le \\frac{1}{1-\\delta}.\n$$\nThis implies that the smallest singular value is bounded below:\n$$\n\\sigma_{\\min}(D\\Phi(x)) = \\frac{1}{\\|(D\\Phi(x))^{-1}\\|_{op}} \\ge 1-\\delta.\n$$\nAs $\\delta  1/2$, $1-\\delta  1/2  0$.\nSo, we have the lower bound for the norm:\n$$\n|D\\Phi(x)^{\\top}v|^2 \\ge (1-\\delta)^2 |v|^2.\n$$\nThis gives the lower bound on the quadratic form:\n$$\nv^{\\top}\\tilde{a}(y)v \\ge \\lambda |D\\Phi(x)^{\\top}v|^2 \\ge \\lambda (1-\\delta)^2 |v|^2.\n$$\nThis implies $\\lambda' = \\lambda(1-\\delta)^2$.\n\nThe new ellipticity constants for the transformed diffusion matrix $\\tilde{a}(y)$ are therefore $\\lambda' = \\lambda(1-\\delta)^2$ and $\\Lambda' = \\Lambda(1+\\delta)^2$. These expressions depend only on $\\lambda$, $\\Lambda$, and $\\delta$ as required.\nThe new uniform ellipticity condition is:\n$$\n\\lambda(1-\\delta)^2 |v|^2 \\le v^{\\top}\\tilde{a}(y)v \\le \\Lambda(1+\\delta)^2 |v|^2.\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\lambda(1-\\delta)^2  \\Lambda(1+\\delta)^2\n\\end{pmatrix}\n}\n$$", "id": "2983484"}, {"introduction": "Having established the admissibility conditions for the drift and the geometric properties required of the Zvonkin transform, we now turn to the central task: constructing the transform itself. The correction map $u(t,x)$ is the solution to a backward parabolic PDE carefully designed to absorb the singular drift term. This problem [@problem_id:2983499] provides a concrete, step-by-step roadmap for this construction in a one-dimensional setting, starting from Itô's formula to derive the PDE and culminating in its solution as a Neumann series involving the heat kernel.", "problem": "Consider the one-dimensional Itô stochastic differential equation on a finite horizon $[0,T]$,\n$$\ndX_{t} = b(t,X_{t})\\,dt + dW_{t}, \\quad X_{0}=x\\in\\mathbb{R},\n$$\nwhere $W_{t}$ is a standard Brownian motion, and the drift $b$ satisfies $b\\in L^{\\infty}\\big([0,T];L^{1}(\\mathbb{R})\\big)$ with compact spatial support uniformly in time. Let the one-dimensional heat kernel be\n$$\nG_{t}(x) = \\frac{1}{\\sqrt{2\\pi t}}\\exp\\!\\Big(-\\frac{x^{2}}{2t}\\Big), \\quad t0,\\; x\\in\\mathbb{R},\n$$\nand denote the associated heat semigroup by $(P_{t}f)(x) = (G_{t}*f)(x) = \\int_{\\mathbb{R}}G_{t}(x-y)f(y)\\,dy$.\n\nThe Zvonkin transform seeks a space-time map $\\Phi:[0,T]\\times\\mathbb{R}\\to\\mathbb{R}$ such that the process $Y_{t}=\\Phi(t,X_{t})$ has no drift. You will construct $\\Phi$ in the form $\\Phi(t,x)=x+u(t,x)$ by solving the corresponding linear backward parabolic problem via convolution with the heat kernel.\n\nTasks:\n- Starting from Itô's formula and the requirement that $Y_{t}=\\Phi(t,X_{t})$ has zero drift, derive the backward parabolic equation for $u$ with terminal condition at time $T$.\n- Write this equation in mild (integral) form using the heat semigroup $(P_{t})_{t\\ge 0}$.\n- Under the small-time condition that guarantees the corresponding integral operator is a contraction on the Banach space of bounded Lipschitz functions on $[0,T]\\times\\mathbb{R}$, iterate the mild equation to obtain the Neumann series for $u$ expressed solely in terms of $b$, spatial derivatives, and convolutions with $G_{t}$.\n- Combine these steps to obtain a single explicit analytic expression for the Zvonkin transform map $\\Phi(t,x)$ as a convergent series of nested heat-kernel convolutions and spatial derivatives.\n\nYour final answer must be the single series expression for $\\Phi(t,x)$ obtained above, written as a closed-form analytic expression in terms of $b$ and $G_{t}$ only. No numerical approximation is required; provide the exact series. Express your final result as a single formula (no inequalities or estimates).", "solution": "The problem is valid. It describes a standard procedure in stochastic analysis for constructing the Zvonkin transform to remove the drift from a stochastic differential equation. The givens are self-contained and scientifically sound.\n\nWe are tasked with finding the Zvonkin transform $\\Phi(t,x) = x + u(t,x)$ for the SDE\n$$\ndX_{t} = b(t,X_{t})\\,dt + dW_{t}, \\quad X_{0}=x.\n$$\nThe transformation should result in a process $Y_{t} = \\Phi(t,X_{t})$ with zero drift.\n\nFirst, we apply Itô's formula to $Y_t = \\Phi(t, X_t)$:\n$$\ndY_t = \\frac{\\partial \\Phi}{\\partial t}(t, X_t) dt + \\frac{\\partial \\Phi}{\\partial x}(t, X_t) dX_t + \\frac{1}{2} \\frac{\\partial^2 \\Phi}{\\partial x^2}(t, X_t) d[X]_t.\n$$\nThe quadratic variation of $X_t$ is $d[X]_t = dt$ since the volatility is $1$. Substituting $dX_t = b(t,X_t)dt + dW_t$, we get:\n$$\ndY_t = \\frac{\\partial \\Phi}{\\partial t}(t, X_t) dt + \\frac{\\partial \\Phi}{\\partial x}(t, X_t) (b(t,X_t)dt + dW_t) + \\frac{1}{2} \\frac{\\partial^2 \\Phi}{\\partial x^2}(t, X_t) dt.\n$$\nGrouping the $dt$ (drift) and $dW_t$ (diffusion) terms:\n$$\ndY_t = \\left( \\frac{\\partial \\Phi}{\\partial t} + b(t,X_t) \\frac{\\partial \\Phi}{\\partial x} + \\frac{1}{2} \\frac{\\partial^2 \\Phi}{\\partial x^2} \\right)(t,X_t) dt + \\frac{\\partial \\Phi}{\\partial x}(t,X_t) dW_t.\n$$\nFor $Y_t$ to have zero drift, the coefficient of the $dt$ term must be zero for all $(t,x) \\in [0,T] \\times \\mathbb{R}$:\n$$\n\\frac{\\partial \\Phi}{\\partial t} + b(t,x) \\frac{\\partial \\Phi}{\\partial x} + \\frac{1}{2} \\frac{\\partial^2 \\Phi}{\\partial x^2} = 0.\n$$\nNow we substitute the form $\\Phi(t,x) = x + u(t,x)$. The partial derivatives are:\n$\\frac{\\partial \\Phi}{\\partial t} = \\frac{\\partial u}{\\partial t}$,\n$\\frac{\\partial \\Phi}{\\partial x} = 1 + \\frac{\\partial u}{\\partial x}$,\n$\\frac{\\partial^2 \\Phi}{\\partial x^2} = \\frac{\\partial^2 u}{\\partial x^2}$.\nPlugging these into the equation gives:\n$$\n\\frac{\\partial u}{\\partial t} + b(t,x) \\left(1 + \\frac{\\partial u}{\\partial x}\\right) + \\frac{1}{2} \\frac{\\partial^2 u}{\\partial x^2} = 0.\n$$\nRearranging the terms, we obtain a linear backward parabolic partial differential equation for $u(t,x)$:\n$$\n\\frac{\\partial u}{\\partial t} + \\frac{1}{2} \\frac{\\partial^2 u}{\\partial x^2} = -b(t,x)\\left(1 + \\frac{\\partial u}{\\partial x}\\right).\n$$\nThis is often written as $(\\partial_t + \\frac{1}{2}\\Delta)u = -b(1+\\nabla u)$ in higher dimensions. We impose the terminal condition that the transform becomes the identity at the final time $T$, meaning $\\Phi(T,x) = x$, which implies $u(T,x) = 0$.\n\nThe solution to the backward heat equation with a source term, $(\\partial_t + \\frac{1}{2}\\partial_{xx})u = F(t,x)$ and $u(T,x)=0$, can be expressed in its mild (integral) form using Duhamel's principle. Let $(P_s)_{s \\ge 0}$ be the heat semigroup, where $(P_s f)(x) = (G_s * f)(x)$. The solution is given by:\n$$\nu(t,x) = \\int_t^T (P_{s-t} F(s,\\cdot))(x) \\, ds.\n$$\nIn our case, the source term is $F(s,x) = -b(s,x)(1 + \\partial_x u(s,x))$. Substituting this yields the integral equation:\n$$\nu(t,x) = \\int_t^T \\left(P_{s-t} \\left[ -b(s,\\cdot)\\left(1 + \\frac{\\partial u}{\\partial x}(s,\\cdot)\\right)\\right]\\right)(x) \\, ds.\n$$\nSince the semigroup operator $P_{s-t}$ is linear, we can write this as a fixed-point equation $u = \\mathcal{F}(u)$:\n$$\nu(t,x) = \\int_t^T (P_{s-t} [-b(s, \\cdot)])(x) \\, ds + \\int_t^T (P_{s-t} [-b(s, \\cdot) \\frac{\\partial u}{\\partial x}(s, \\cdot)])(x) \\, ds.\n$$\nWe solve this equation via iteration, which generates a Neumann series. Let $u^{(0)}(t,x) = 0$. The iteration scheme is $u^{(k+1)} = \\mathcal{F}(u^{(k)})$. The problem statement assumes conditions that guarantee convergence of $u^{(k)}$ to a solution $u$.\nLet's find the first few terms of the iteration sequence:\n$$\nu^{(1)}(t,x) = \\mathcal{F}(u^{(0)}) = \\int_t^T (P_{s-t} [-b(s,\\cdot)])(x) \\, ds = -\\int_t^T (G_{s-t} * b(s,\\cdot))(x) \\, ds.\n$$\n$$\nu^{(2)}(t,x) = \\mathcal{F}(u^{(1)}) = -\\int_t^T \\left(P_{s-t} \\left[ b(s,\\cdot)\\left(1 + \\frac{\\partial u^{(1)}}{\\partial x}(s,\\cdot)\\right)\\right]\\right)(x) \\, ds.\n$$\nLet's define a new function $v = -u$ to eliminate the negative signs. The PDE for $v$ is $(\\partial_t + \\frac{1}{2}\\partial_{xx})v = b(1 - \\partial_x v)$ with $v(T,x)=0$. The integral equation becomes:\n$$\nv(t,x) = \\int_t^T (G_{s-t} * [b(s,\\cdot)(1 - \\partial_x v(s,\\cdot))])(x) \\, ds.\n$$\nLet's define the Neumann series for $v$. Let $v = \\sum_{n=0}^{\\infty} v_n$.\nThe fixed-point iteration $v_{k+1} = \\mathcal{F}(v_k)$ with $v_0 = 0$ yields a sequence of partial sums $v_k = \\sum_{j=0}^{k-1} v_j$.\nThe terms $v_n$ of the series are determined as follows:\nThe zeroth order term corresponds to setting the $\\partial_x v$ term to zero:\n$$\nv_0(t,x) = \\int_t^T (G_{s-t}*b(s,\\cdot))(x)\\,ds.\n$$\nThe higher-order terms are generated recursively by substituting the previous term into the integral equation:\n$$\nv_n(t,x) = -\\int_t^T (G_{s-t}*[b(s,\\cdot)\\partial_x v_{n-1}(s,\\cdot)])(x)\\,ds \\quad \\text{for } n \\ge 1.\n$$\nThe solution for $v$ is the sum $v(t,x) = \\sum_{n=0}^\\infty v_n(t,x)$. Since we defined $v = -u$, we have $u=-v$.\nThe Zvonkin transform is $\\Phi(t,x) = x+u(t,x) = x - v(t,x) = x - \\sum_{n=0}^{\\infty} v_n(t,x)$.\nLet's rewrite the series using $u_n = -v_n$.\n$u_0 = -v_0 = -\\int_t^T (G_{s-t}*b(s,\\cdot))(x)\\,ds$.\n$u_n = -v_n = \\int_t^T (G_{s-t}*[b(s,\\cdot)\\partial_x v_{n-1}(s,\\cdot)])(x)\\,ds = \\int_t^T (G_{s-t}*[b(s,\\cdot)\\partial_x(-u_{n-1})(s,\\cdot)])(x)\\,ds$.\nThis results in $u_n(t,x) = -\\int_t^T (G_{s-t}*[b(s,\\cdot)\\partial_x u_{n-1}(s,\\cdot)])(x)\\,ds$.\nThis leads to alternating signs.\n\nLet's return to the original equation for $u$: $u(t,x) = \\int_t^T (P_{s-t} [-b(s, \\cdot)])(x) \\, ds + \\int_t^T (P_{s-t} [-b(s, \\cdot) \\frac{\\partial u}{\\partial x}(s, \\cdot)])(x) \\, ds$.\nThis is a fixed point equation $u=\\mathcal{A} + \\mathcal{K}u$. The solution is $u=\\sum_{n=0}^\\infty \\mathcal{K}^n \\mathcal{A}$.\nLet $u_n = \\mathcal{K}^n \\mathcal{A}$.\n$u_0(t,x) = \\mathcal{A}(t,x) = -\\int_t^T (G_{s-t}*b(s,\\cdot))(x)\\,ds$.\n$u_1(t,x) = \\mathcal{K}(u_0)(t,x) = \\int_t^T (G_{s-t}*[-b(s,\\cdot)\\partial_x u_0(s,\\cdot)])(x)\\,ds$.\nGenerally, for $n \\ge 1$:\n$u_n(t,x) = \\int_t^T (G_{s-t}*[-b(s,\\cdot)\\partial_x u_{n-1}(s,\\cdot)])(x)\\,ds$.\nThe total solution for $u$ is $u(t,x) = \\sum_{n=0}^{\\infty}u_n(t,x)$.\nFinally, the Zvonkin transform is $\\Phi(t,x)=x+u(t,x) = x+\\sum_{n=0}^\\infty u_n(t,x)$.\n\nWe can write out the convolution explicitly: $(G_s*f)(x) = \\int_\\mathbb{R} G_s(x-y)f(y)dy$.\nThe recursive definition of the series terms is:\n$u_0(t,x) = -\\int_t^T \\int_{\\mathbb{R}} G_{s-t}(x-y)b(s,y)\\,dy\\,ds$.\nAnd for $n\\geq 1$:\n$u_n(t,x) = -\\int_t^T \\int_{\\mathbb{R}} G_{s-t}(x-y) b(s,y) \\frac{\\partial u_{n-1}}{\\partial x}(s,y) \\,dy\\,ds$.\nCombining these gives the final expression for $\\Phi(t,x)$.", "answer": "$$\n\\boxed{\n\\Phi(t,x) = x + \\sum_{n=0}^{\\infty} u_n(t,x), \\quad \\text{where } u_n \\text{ is defined by:} \\quad u_{n}(t,x) = \n\\begin{cases}\n-\\int_t^T \\int_{\\mathbb{R}} G_{s-t}(x-y) b(s,y) \\,dy\\,ds  n=0 \\\\\n-\\int_t^T \\int_{\\mathbb{R}} G_{s-t}(x-y) b(s,y) \\frac{\\partial u_{n-1}}{\\partial x}(s,y) \\,dy\\,ds  n\\ge 1\n\\end{cases}\n}\n$$", "id": "2983499"}]}