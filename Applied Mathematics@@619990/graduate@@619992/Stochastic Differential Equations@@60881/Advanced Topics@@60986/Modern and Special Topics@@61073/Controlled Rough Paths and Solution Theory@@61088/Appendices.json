{"hands_on_practices": [{"introduction": "The signature of a path, a series of tensors formed from its iterated integrals, is the fundamental object in rough path theory. This exercise provides a concrete opportunity to move from abstract definitions to direct computation by calculating the second-level signature and the geometrically significant Lévy area for a canonical smooth path [@problem_id:2972285]. Mastering this foundational calculation is the first step toward understanding how rough paths capture the intricate geometry of a driver.", "problem": "Consider the smooth path $X : [0,1] \\to \\mathbb{R}^{2}$ defined by $X_{t} = (X^{1}_{t}, X^{2}_{t}) = (t^{2}, t^{3})$. This path is a canonical example of a smooth controlled path in the sense of controlled rough paths. The path signature of order $2$ for a smooth path is defined via iterated Riemann–Stieltjes integrals as follows: for $i,j \\in \\{1,2\\}$,\n$$\nS^{(2)}_{ij} := \\int_{0  s  t  1} \\dot{X}^{i}_{s} \\, \\dot{X}^{j}_{t} \\, ds \\, dt\n$$\nwhere $\\dot{X}^{i}_{t}$ denotes the usual derivative of $X^{i}_{t}$ with respect to $t$. The Lévy area $A_{12}$ is defined as the antisymmetric part of the level-$2$ signature,\n$$\nA_{12} := \\tfrac{1}{2} \\left( S^{(2)}_{12} - S^{(2)}_{21} \\right)\n$$\nStarting only from these fundamental definitions, compute all level-$2$ signature components $S^{(2)}_{11}$, $S^{(2)}_{12}$, $S^{(2)}_{21}$, and $S^{(2)}_{22}$ for the given path, and compute the Lévy area $A_{12}$. Express your final answer as a single row matrix in the order $S^{(2)}_{11}, S^{(2)}_{12}, S^{(2)}_{21}, S^{(2)}_{22}, A_{12}$. No rounding is required.", "solution": "The problem statement is evaluated and determined to be valid. It is self-contained, scientifically grounded in the mathematical theory of rough paths, and well-posed. We may proceed with the solution.\n\nThe problem requires the computation of the level-$2$ signature components and the Lévy area for the smooth path $X: [0,1] \\to \\mathbb{R}^{2}$ defined by $X_{t} = (X^{1}_{t}, X^{2}_{t}) = (t^{2}, t^{3})$.\n\nFirst, we compute the time derivatives of the path components, denoted by $\\dot{X}^{i}_{t}$.\nFor the first component, $X^{1}_{t} = t^{2}$, the derivative is:\n$$\n\\dot{X}^{1}_{t} = \\frac{d}{dt}(t^{2}) = 2t\n$$\nFor the second component, $X^{2}_{t} = t^{3}$, the derivative is:\n$$\n\\dot{X}^{2}_{t} = \\frac{d}{dt}(t^{3}) = 3t^{2}\n$$\nThe problem defines the level-$2$ signature components as the iterated Riemann-Stieltjes integrals:\n$$\nS^{(2)}_{ij} := \\int_{0  s  t  1} \\dot{X}^{i}_{s} \\, \\dot{X}^{j}_{t} \\, ds \\, dt = \\int_{0}^{1} \\left( \\int_{0}^{t} \\dot{X}^{i}_{s} \\, \\dot{X}^{j}_{t} \\, ds \\right) dt\n$$\nWe compute each of the four components $S^{(2)}_{11}$, $S^{(2)}_{12}$, $S^{(2)}_{21}$, and $S^{(2)}_{22}$ using this definition.\n\nComponent $S^{(2)}_{11}$:\n$$\nS^{(2)}_{11} = \\int_{0}^{1} \\left( \\int_{0}^{t} \\dot{X}^{1}_{s} \\, \\dot{X}^{1}_{t} \\, ds \\right) dt = \\int_{0}^{1} \\left( \\int_{0}^{t} (2s)(2t) \\, ds \\right) dt\n$$\n$$\nS^{(2)}_{11} = \\int_{0}^{1} 4t \\left( \\int_{0}^{t} s \\, ds \\right) dt = \\int_{0}^{1} 4t \\left[ \\frac{s^{2}}{2} \\right]_{s=0}^{s=t} dt = \\int_{0}^{1} 4t \\left( \\frac{t^{2}}{2} \\right) dt\n$$\n$$\nS^{(2)}_{11} = \\int_{0}^{1} 2t^{3} \\, dt = 2 \\left[ \\frac{t^{4}}{4} \\right]_{0}^{1} = 2 \\left( \\frac{1}{4} \\right) = \\frac{1}{2}\n$$\n\nComponent $S^{(2)}_{12}$:\n$$\nS^{(2)}_{12} = \\int_{0}^{1} \\left( \\int_{0}^{t} \\dot{X}^{1}_{s} \\, \\dot{X}^{2}_{t} \\, ds \\right) dt = \\int_{0}^{1} \\left( \\int_{0}^{t} (2s)(3t^{2}) \\, ds \\right) dt\n$$\n$$\nS^{(2)}_{12} = \\int_{0}^{1} 6t^{2} \\left( \\int_{0}^{t} s \\, ds \\right) dt = \\int_{0}^{1} 6t^{2} \\left[ \\frac{s^{2}}{2} \\right]_{s=0}^{s=t} dt = \\int_{0}^{1} 6t^{2} \\left( \\frac{t^{2}}{2} \\right) dt\n$$\n$$\nS^{(2)}_{12} = \\int_{0}^{1} 3t^{4} \\, dt = 3 \\left[ \\frac{t^{5}}{5} \\right]_{0}^{1} = 3 \\left( \\frac{1}{5} \\right) = \\frac{3}{5}\n$$\n\nComponent $S^{(2)}_{21}$:\n$$\nS^{(2)}_{21} = \\int_{0}^{1} \\left( \\int_{0}^{t} \\dot{X}^{2}_{s} \\, \\dot{X}^{1}_{t} \\, ds \\right) dt = \\int_{0}^{1} \\left( \\int_{0}^{t} (3s^{2})(2t) \\, ds \\right) dt\n$$\n$$\nS^{(2)}_{21} = \\int_{0}^{1} 6t \\left( \\int_{0}^{t} s^{2} \\, ds \\right) dt = \\int_{0}^{1} 6t \\left[ \\frac{s^{3}}{3} \\right]_{s=0}^{s=t} dt = \\int_{0}^{1} 6t \\left( \\frac{t^{3}}{3} \\right) dt\n$$\n$$\nS^{(2)}_{21} = \\int_{0}^{1} 2t^{4} \\, dt = 2 \\left[ \\frac{t^{5}}{5} \\right]_{0}^{1} = 2 \\left( \\frac{1}{5} \\right) = \\frac{2}{5}\n$$\n\nComponent $S^{(2)}_{22}$:\n$$\nS^{(2)}_{22} = \\int_{0}^{1} \\left( \\int_{0}^{t} \\dot{X}^{2}_{s} \\, \\dot{X}^{2}_{t} \\, ds \\right) dt = \\int_{0}^{1} \\left( \\int_{0}^{t} (3s^{2})(3t^{2}) \\, ds \\right) dt\n$$\n$$\nS^{(2)}_{22} = \\int_{0}^{1} 9t^{2} \\left( \\int_{0}^{t} s^{2} \\, ds \\right) dt = \\int_{0}^{1} 9t^{2} \\left[ \\frac{s^{3}}{3} \\right]_{s=0}^{s=t} dt = \\int_{0}^{1} 9t^{2} \\left( \\frac{t^{3}}{3} \\right) dt\n$$\n$$\nS^{(2)}_{22} = \\int_{0}^{1} 3t^{5} \\, dt = 3 \\left[ \\frac{t^{6}}{6} \\right]_{0}^{1} = 3 \\left( \\frac{1}{6} \\right) = \\frac{1}{2}\n$$\n\nFinally, we compute the Lévy area $A_{12}$, defined as the antisymmetric part of the level-$2$ signature:\n$$\nA_{12} := \\frac{1}{2} \\left( S^{(2)}_{12} - S^{(2)}_{21} \\right)\n$$\nSubstituting the computed values:\n$$\nA_{12} = \\frac{1}{2} \\left( \\frac{3}{5} - \\frac{2}{5} \\right) = \\frac{1}{2} \\left( \\frac{1}{5} \\right) = \\frac{1}{10}\n$$\n\nThe computed values are: $S^{(2)}_{11} = \\frac{1}{2}$, $S^{(2)}_{12} = \\frac{3}{5}$, $S^{(2)}_{21} = \\frac{2}{5}$, $S^{(2)}_{22} = \\frac{1}{2}$, and $A_{12} = \\frac{1}{10}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2}  \\frac{3}{5}  \\frac{2}{5}  \\frac{1}{2}  \\frac{1}{10} \\end{pmatrix}}\n$$", "id": "2972285"}, {"introduction": "What happens when a path encloses infinitesimal area but has no net displacement? This thought experiment gets to the heart of why rough path theory is necessary, as classical methods would predict no evolution at all. This practice [@problem_id:2972254] demonstrates how a \"naive\" Euler scheme fails dramatically and reveals that the true solution is governed by a non-trivial ODE involving the Lie bracket of the vector fields, driven entirely by the path's area term.", "problem": "Let $\\mathbf{X} = (X, \\mathbb{X})$ be a step-$2$ geometric rough path on $\\mathbb{R}^{2}$ with finite $p$-variation for some $2 \\leq p  3$, where $X : [0,1] \\to \\mathbb{R}^{2}$ is the first level path and $\\mathbb{X} : \\{(s,t) : 0 \\leq s \\leq t \\leq 1\\} \\to \\mathbb{R}^{2 \\times 2}$ is the second level iterated integral. Assume that the first level path is identically zero, $X_{t} \\equiv (0,0)$ for all $t \\in [0,1]$, while the second level is purely antisymmetric and accumulates area at a constant rate $\\alpha \\in \\mathbb{R}$:\n$$\n\\mathbb{X}^{1,2}_{s,t} \\;=\\; \\alpha (t-s), \n\\qquad \n\\mathbb{X}^{2,1}_{s,t} \\;=\\; -\\alpha (t-s),\n\\qquad \n\\mathbb{X}^{1,1}_{s,t} \\;=\\; \\mathbb{X}^{2,2}_{s,t} \\;=\\; 0,\n$$\nfor all $0 \\leq s \\leq t \\leq 1$. Verify that this definition is consistent with Chen’s relation and interpret $\\mathbf{X}$ as the rough path limit of rapidly oscillating loops with zero net increment and constant signed area rate.\n\nConsider the Rough Differential Equation (RDE)\n$$\n\\mathrm{d}y_{t} \n\\;=\\; V_{1}(y_{t})\\,\\mathrm{d}X^{1}_{t} \\;+\\; V_{2}(y_{t})\\,\\mathrm{d}X^{2}_{t},\n\\qquad y_{0} \\in \\mathbb{R}^{2},\n$$\ndriven by $\\mathbf{X}$, where the vector fields are linear,\n$$\nV_{1}(y) \\;=\\; A\\,y, \\qquad V_{2}(y) \\;=\\; B\\,y, \\qquad y \\in \\mathbb{R}^{2},\n$$\nwith\n$$\nA \\;=\\; \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix},\n\\qquad\nB \\;=\\; \\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix}.\n$$\nLet $\\{t_{k}\\}_{k=0}^{N}$ be any partition of $[0,1]$, and define the “naive Euler” scheme that ignores second level information by\n$$\ny^{E}_{t_{k+1}} \\;=\\; y^{E}_{t_{k}} \\;+\\; V_{1}\\!\\big(y^{E}_{t_{k}}\\big)\\,\\big(X^{1}_{t_{k+1}} - X^{1}_{t_{k}}\\big)\n\\;+\\; V_{2}\\!\\big(y^{E}_{t_{k}}\\big)\\,\\big(X^{2}_{t_{k+1}} - X^{2}_{t_{k}}\\big),\n\\qquad y^{E}_{0} = y_{0}.\n$$\nStarting from the foundational controlled rough path expansion and the definition of the Lie bracket of vector fields, derive the true $t \\mapsto y_{t}$ at time $t=1$ for the above driver and vector fields, and show that the naive Euler scheme produces a completely different limit as the mesh size $\\max_{k}(t_{k+1}-t_{k})$ goes to zero. This demonstrates that ignoring the area terms can lead to divergence of the Euler scheme.\n\nQuantify the bias induced by missing $\\mathbb{X}$ by computing the Euclidean norm of the difference at time $t=1$ when $y_{0} = (1,0)^{\\top}$. Your final answer must be a single closed-form analytic expression in $\\alpha$. No rounding is required. Express the final answer without units.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- A step-$2$ geometric rough path $\\mathbf{X} = (X, \\mathbb{X})$ on $\\mathbb{R}^{2}$ with finite $p$-variation for $2 \\leq p  3$.\n- First level path: $X_{t} \\equiv (0,0)$ for all $t \\in [0,1]$.\n- Second level path (area): For $0 \\leq s \\leq t \\leq 1$,\n$$\n\\mathbb{X}^{1,2}_{s,t} = \\alpha (t-s), \\quad \\mathbb{X}^{2,1}_{s,t} = -\\alpha (t-s), \\quad \\mathbb{X}^{1,1}_{s,t} = 0, \\quad \\mathbb{X}^{2,2}_{s,t} = 0.\n$$\n- Rough Differential Equation (RDE): $\\mathrm{d}y_{t} = V_{1}(y_{t})\\,\\mathrm{d}X^{1}_{t} + V_{2}(y_{t})\\,\\mathrm{d}X^{2}_{t}$, with initial condition $y_{0} \\in \\mathbb{R}^{2}$.\n- Vector fields: $V_{1}(y) = A\\,y$ and $V_{2}(y) = B\\,y$, where\n$$\nA = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}, \\qquad B = \\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix}.\n$$\n- Naive Euler scheme: $y^{E}_{t_{k+1}} = y^{E}_{t_{k}} + V_{1}(y^{E}_{t_{k}})\\,(X^{1}_{t_{k+1}} - X^{1}_{t_{k}}) + V_{2}(y^{E}_{t_{k}})\\,(X^{2}_{t_{k+1}} - X^{2}_{t_{k}})$, with $y^{E}_{0} = y_{0}$.\n- Initial condition for bias calculation: $y_{0} = (1,0)^{\\top}$.\n- Task: Derive the true solution $y_t$, show the naive Euler scheme diverges from it, and quantify the bias norm at $t=1$ as a function of $\\alpha$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a standard, illustrative example in the theory of rough paths. It demonstrates the necessity of including second-order (area) information when integrating against rough signals, a cornerstone of the theory. All terms are mathematically well-defined, and the setup is self-contained and consistent. The problem is scientifically grounded in established mathematical theory and is objectively stated. Therefore, the problem is valid.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\nFirst, we verify that the definition of $\\mathbf{X}$ is consistent with Chen's relation for a step-$2$ rough path. Chen's relation states that for any $0 \\leq s \\leq t \\leq u \\leq 1$,\n$$\n\\mathbb{X}_{s,u} = \\mathbb{X}_{s,t} + \\mathbb{X}_{t,u} + (X_t - X_s) \\otimes (X_u - X_t).\n$$\nGiven that $X_t \\equiv (0,0)$, the increment term $(X_t - X_s)$ is always zero. Thus, the tensor product term $(X_t - X_s) \\otimes (X_u - X_t)$ is the zero matrix. The relation simplifies to $\\mathbb{X}_{s,u} = \\mathbb{X}_{s,t} + \\mathbb{X}_{t,u}$. We check this component-wise:\nFor the $(1,2)$ component: $\\mathbb{X}^{1,2}_{s,u} = \\alpha(u-s)$. The right side is $\\mathbb{X}^{1,2}_{s,t} + \\mathbb{X}^{1,2}_{t,u} = \\alpha(t-s) + \\alpha(u-t) = \\alpha(u-s)$. This holds.\nThe same logic confirms the relation for $\\mathbb{X}^{2,1}$. For the diagonal components, $\\mathbb{X}^{1,1}_{s,u} = 0$ and $\\mathbb{X}^{1,1}_{s,t} + \\mathbb{X}^{1,1}_{t,u} = 0 + 0 = 0$. This also holds. Chen's relation is satisfied. The interpretation of $\\mathbf{X}$ is that of a path that creates infinitesimal loops, resulting in zero net displacement ($X_t=0$) but accumulating a signed area at a constant rate $\\alpha$.\n\nNext, we analyze the naive Euler scheme. The scheme is defined by\n$$\ny^{E}_{t_{k+1}} = y^{E}_{t_{k}} + V_{1}(y^{E}_{t_{k}})\\,\\delta X^{1}_{t_{k}, t_{k+1}} + V_{2}(y^{E}_{t_{k}})\\,\\delta X^{2}_{t_{k}, t_{k+1}},\n$$\nwhere $\\delta X_{s,t} = X_t - X_s$. Since $X_t\\equiv (0,0)$ for all $t$, the increments $\\delta X^{1}$ and $\\delta X^{2}$ are always zero. The scheme simplifies to $y^{E}_{t_{k+1}} = y^{E}_{t_{k}}$. By induction, for any partition $\\{t_k\\}$, the value of the numerical solution remains at the initial condition, $y^{E}_{t_k} = y_0$. Therefore, as the mesh size of the partition goes to zero, the limit of the naive Euler scheme is the constant function $y^{E}_{t} = y_0$ for all $t \\in [0,1]$. At $t=1$, the naive solution is $y^{E}_{1} = y_{0}$.\n\nNow we derive the true solution of the RDE. The solution to an RDE is given by a corrected version of the classical expansion, which includes second-order terms from the rough path. The local expansion of the solution $y$ over a small interval $[s, t]$ is given by:\n$$\ny_t - y_s \\approx V_1(y_s) (X^1_t - X^1_s) + V_2(y_s) (X^2_t - X^2_s) + \\sum_{i,j=1}^2 (\\mathcal{L}_{V_i}V_j)(y_s) \\mathbb{X}^{i,j}_{s,t},\n$$\nwhere $\\mathcal{L}_{V_i}V_j(y) = (DV_j)(y)V_i(y)$ is the Lie derivative of the vector field $V_j$ along $V_i$.\nGiven $X_t \\equiv (0,0)$, the first-order terms vanish. For the linear vector fields $V_1(y)=Ay$ and $V_2(y)=By$, their Jacobians are $DV_1=A$ and $DV_2=B$. The Lie derivative terms are:\n$\\mathcal{L}_{V_1}V_1(y) = A(Ay) = A^2 y$\n$\\mathcal{L}_{V_1}V_2(y) = B(Ay) = BA y$\n$\\mathcal{L}_{V_2}V_1(y) = A(By) = AB y$\n$\\mathcal{L}_{V_2}V_2(y) = B(By) = B^2 y$\n\nThe expansion for the increment becomes:\n$$\ny_t - y_s \\approx (A^2 \\mathbb{X}^{1,1}_{s,t} + BA \\mathbb{X}^{1,2}_{s,t} + AB \\mathbb{X}^{2,1}_{s,t} + B^2 \\mathbb{X}^{2,2}_{s,t}) y_s.\n$$\nSubstituting the given forms for $\\mathbb{X}^{i,j}_{s,t}$:\n$$\ny_t - y_s \\approx (BA (\\alpha(t-s)) + AB (-\\alpha(t-s))) y_s = \\alpha (BA - AB)(t-s) y_s.\n$$\nDividing by $t-s$ and taking the limit as $t \\to s$, we obtain an ordinary differential equation (ODE) for the true solution $y_t$:\n$$\n\\frac{dy_t}{dt} = \\alpha(BA - AB) y_t = \\alpha[B,A]y_t,\n$$\nwhere $[B,A] = BA-AB$ is the matrix commutator. Let us compute this commutator:\n$A = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$, $B = \\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix}$.\n$BA = \\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix}$.\n$AB = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} \\begin{pmatrix} 0  0 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}$.\n$[B,A] = BA - AB = \\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix} - \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} = \\begin{pmatrix} -1  0 \\\\ 0  1 \\end{pmatrix}$.\n\nThe ODE for $y_t$ is $\\frac{dy_t}{dt} = \\alpha \\begin{pmatrix} -1  0 \\\\ 0  1 \\end{pmatrix} y_t$.\nThe solution to this linear system with initial condition $y_0$ is given by matrix exponentiation:\n$$\ny_t = \\exp\\left(t \\alpha \\begin{pmatrix} -1  0 \\\\ 0  1 \\end{pmatrix}\\right) y_0.\n$$\nSince the matrix is diagonal, its exponential is the exponential of its diagonal entries:\n$$\ny_t = \\begin{pmatrix} \\exp(-t\\alpha)  0 \\\\ 0  \\exp(t\\alpha) \\end{pmatrix} y_0.\n$$\nAt time $t=1$, the true solution is $y_1 = \\begin{pmatrix} \\exp(-\\alpha)  0 \\\\ 0  \\exp(\\alpha) \\end{pmatrix} y_0$. This is clearly different from the naive Euler limit $y^E_1 = y_0$, unless $\\alpha=0$.\n\nFinally, we quantify the bias for the specific initial condition $y_0 = (1,0)^{\\top}$.\nThe true solution at $t=1$ is:\n$$\ny_1 = \\begin{pmatrix} \\exp(-\\alpha)  0 \\\\ 0  \\exp(\\alpha) \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\exp(-\\alpha) \\\\ 0 \\end{pmatrix}.\n$$\nThe naive Euler solution at $t=1$ is:\n$$\ny^{E}_1 = y_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\nThe difference vector is $\\Delta y = y_1 - y^{E}_1$:\n$$\n\\Delta y = \\begin{pmatrix} \\exp(-\\alpha) \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\exp(-\\alpha) - 1 \\\\ 0 \\end{pmatrix}.\n$$\nThe Euclidean norm of this difference is:\n$$\n\\|\\Delta y\\|_2 = \\sqrt{(\\exp(-\\alpha) - 1)^2 + 0^2} = \\sqrt{(\\exp(-\\alpha) - 1)^2} = |\\exp(-\\alpha) - 1|.\n$$\nThis quantity represents the error, or bias, incurred at $t=1$ by neglecting the second-level information of the rough path.", "answer": "$$\\boxed{|\\exp(-\\alpha) - 1|}$$", "id": "2972254"}, {"introduction": "A robust generalization must contain the theory it generalizes. This practice demonstrates that the rough path framework neatly encompasses classical stochastic analysis by showing how it recovers the infinitesimal generator of a Markov process driven by a Stratonovich Stochastic Differential Equation (SDE) [@problem_id:2972262]. By applying the Rough Differential Equation (RDE) solution theory to a system driven by a canonical Brownian rough path, you will bridge the gap between these two perspectives and confirm their profound consistency.", "problem": "Let $m \\in \\mathbb{N}$ and $d \\in \\mathbb{N}$. Let $\\mathbf{W} = (W,\\mathbb{W})$ be the canonical enhanced $\\mathbb{R}^{m}$-valued Brownian rough path built over a standard $m$-dimensional Brownian motion, so that the second level $\\mathbb{W}$ encodes Stratonovich iterated integrals. Consider the linear rough differential equation on $\\mathbb{R}^{d}$ driven by $\\mathbf{W}$,\n$$\ndX_{t} \\;=\\; A X_{t}\\,dt \\;+\\; \\sum_{k=1}^{m} B_{k} X_{t}\\,d\\mathbf{W}_{t}^{k}, \\quad X_{0}=x \\in \\mathbb{R}^{d},\n$$\nwhere $A \\in \\mathbb{R}^{d \\times d}$ and, for each $k \\in \\{1,\\dots,m\\}$, $B_{k} \\in \\mathbb{R}^{d \\times d}$, and the equation is understood in the sense of controlled rough paths with respect to the Brownian rough path $\\mathbf{W}$. Let $(P_{t})_{t \\ge 0}$ denote the associated Markov semigroup acting on bounded, three-times continuously differentiable functions with bounded derivatives, $C^{3}_{b}(\\mathbb{R}^{d})$, defined by $P_{t}\\varphi(x) := \\mathbb{E}\\big[\\varphi(X_{t}^{x})\\big]$. The generator $\\mathcal{L}$ of $(P_{t})_{t \\ge 0}$ is defined for $\\varphi \\in C^{3}_{b}(\\mathbb{R}^{d})$ by\n$$\n\\mathcal{L}\\varphi(x) \\;:=\\; \\lim_{t \\downarrow 0} \\frac{P_{t}\\varphi(x) - \\varphi(x)}{t},\n$$\nwhenever the limit exists.\n\nStarting from the controlled rough path change-of-variables formula and the characterization of a generator via infinitesimal increments of the Markov semigroup, derive the explicit form of the generator $\\mathcal{L}$ for this linear rough differential equation. Then, for a polynomial test function of degree two, $\\varphi(x) = x^{\\top} Q x$ with $Q \\in \\mathbb{R}^{d \\times d}$ symmetric, compute the explicit closed-form expression for $\\mathcal{L}\\varphi(x)$ in terms of $A$, $\\{B_{k}\\}_{k=1}^{m}$, $Q$, and $x$. Your final answer must be a single closed-form analytic expression for $\\mathcal{L}\\varphi(x)$.", "solution": "The solution proceeds in two stages: first, deriving the general form of the generator $\\mathcal{L}$, and second, applying it to the specific polynomial test function $\\varphi(x) = x^{\\top} Q x$.\n\nThe given rough differential equation (RDE) is\n$$\ndX_{t} \\;=\\; A X_{t}\\,dt \\;+\\; \\sum_{k=1}^{m} B_{k} X_{t}\\,d\\mathbf{W}_{t}^{k}, \\quad X_{0}=x \\in \\mathbb{R}^{d}.\n$$\nThe problem specifies that the driving signal $\\mathbf{W} = (W,\\mathbb{W})$ is the canonical enhanced Brownian rough path where the second level $\\mathbb{W}$ encodes Stratonovich iterated integrals. A central result in the theory of stochastic differential equations is that an RDE driven by an enhanced Brownian motion is equivalent to a stochastic differential equation (SDE). The nature of the second-level path determines the integration convention of the SDE. Since $\\mathbb{W}$ encodes Stratonovich integrals, the RDE is equivalent to the following Stratonovich SDE:\n$$\ndX_{t} \\;=\\; A X_{t}\\,dt \\;+\\; \\sum_{k=1}^{m} B_{k} X_{t} \\circ dW_{t}^{k}.\n$$\nHere, $ \\circ dW_{t}^{k} $ denotes the Stratonovich integral with respect to the $k$-th component of the standard $m$-dimensional Brownian motion $W$.\n\nTo find the generator $\\mathcal{L}$, it is advantageous to convert the Stratonovich SDE into its equivalent Itô form. For a general Stratonovich SDE $dX_{t} = b(X_{t})dt + \\sum_{k=1}^{m} \\sigma_{k}(X_{t})\\circ dW_{t}^{k}$, the equivalent Itô SDE is given by\n$$\ndX_{t} \\;=\\; \\left( b(X_{t}) + \\frac{1}{2}\\sum_{k=1}^{m} (D\\sigma_{k})(X_{t})[\\sigma_{k}(X_{t})] \\right) dt \\;+\\; \\sum_{k=1}^{m} \\sigma_{k}(X_{t})\\,dW_{t}^{k}.\n$$\nIn our case, the vector fields are $b(x) = Ax$ and $\\sigma_{k}(x) = B_{k}x$. The Jacobian matrix of $\\sigma_{k}$ is $D\\sigma_{k}(x) = B_{k}$. The Itô correction term (or Itô-Stratonovich drift correction) is therefore\n$$\n\\frac{1}{2}\\sum_{k=1}^{m} (D\\sigma_{k})(x)[\\sigma_{k}(x)] \\;=\\; \\frac{1}{2}\\sum_{k=1}^{m} B_{k} (B_{k}x) \\;=\\; \\frac{1}{2}\\left(\\sum_{k=1}^{m} B_{k}^{2}\\right)x.\n$$\nThus, the equivalent Itô SDE for $X_{t}$ is\n$$\ndX_{t} \\;=\\; \\left(A + \\frac{1}{2}\\sum_{k=1}^{m} B_{k}^{2}\\right)X_{t} \\,dt \\;+\\; \\sum_{k=1}^{m} B_{k}X_{t}\\,dW_{t}^{k}.\n$$\nLet's define the Itô drift $\\tilde{b}(x) = \\left(A + \\frac{1}{2}\\sum_{k=1}^{m} B_{k}^{2}\\right)x$ and diffusion coefficients $\\tilde{\\sigma}_{k}(x) = B_{k}x$.\n\nThe infinitesimal generator $\\mathcal{L}$ of the Markov process $(X_{t})_{t \\ge 0}$ is a second-order differential operator whose form is given by Itô's lemma. For a sufficiently smooth function $\\varphi$, Itô's formula states\n$$\nd\\varphi(X_{t}) = \\mathcal{L}\\varphi(X_{t})dt + \\sum_{k=1}^{m} \\langle \\nabla\\varphi(X_{t}), \\tilde{\\sigma}_{k}(X_{t}) \\rangle dW_{t}^{k},\n$$\nwhere\n$$\n\\mathcal{L}\\varphi(x) \\;=\\; \\langle \\nabla\\varphi(x), \\tilde{b}(x) \\rangle + \\frac{1}{2} \\sum_{k=1}^{m} \\text{Tr}\\left( \\tilde{\\sigma}_{k}(x) \\tilde{\\sigma}_{k}(x)^{\\top} D^{2}\\varphi(x) \\right).\n$$\nHere, $\\nabla\\varphi$ is the gradient of $\\varphi$ and $D^{2}\\varphi$ is its Hessian matrix. Substituting the expressions for $\\tilde{b}(x)$ and $\\tilde{\\sigma}_{k}(x)$, we obtain the general form of the generator:\n$$\n\\mathcal{L}\\varphi(x) \\;=\\; \\left\\langle \\nabla\\varphi(x), \\left(A + \\frac{1}{2} \\sum_{k=1}^{m} B_{k}^{2}\\right)x \\right\\rangle + \\frac{1}{2} \\sum_{k=1}^{m} \\text{Tr}\\left( (B_{k}x)(B_{k}x)^{\\top} D^{2}\\varphi(x) \\right).\n$$\nThis expression fulfills the first part of the problem.\n\nNow, we compute the action of $\\mathcal{L}$ on the specific test function $\\varphi(x) = x^{\\top} Q x$, where $Q \\in \\mathbb{R}^{d \\times d}$ is a symmetric matrix. We first compute the gradient and Hessian of $\\varphi$.\nThe gradient $\\nabla\\varphi(x)$ is given by:\n$$\n\\nabla\\varphi(x) = (Q+Q^{\\top})x = 2Qx,\n$$\nsince $Q$ is symmetric ($Q=Q^{\\top}$).\nThe Hessian matrix $D^{2}\\varphi(x)$ is the matrix of second partial derivatives, which is:\n$$\nD^{2}\\varphi(x) = 2Q.\n$$\nNow, we substitute these into the expression for $\\mathcal{L}\\varphi(x)$. The first term of $\\mathcal{L}\\varphi(x)$ is:\n$$\n\\left\\langle \\nabla\\varphi(x), \\tilde{b}(x) \\right\\rangle = \\left\\langle 2Qx, \\left(A + \\frac{1}{2} \\sum_{k=1}^{m} B_{k}^{2}\\right)x \\right\\rangle = (2Qx)^{\\top} \\left(A + \\frac{1}{2} \\sum_{k=1}^{m} B_{k}^{2}\\right)x\n$$\n$$\n= 2x^{\\top}Q^{\\top} \\left(A + \\frac{1}{2} \\sum_{k=1}^{m} B_{k}^{2}\\right)x = 2x^{\\top}Q A x + x^{\\top}Q \\left(\\sum_{k=1}^{m} B_{k}^{2}\\right)x.\n$$\nThe second term of $\\mathcal{L}\\varphi(x)$ uses the trace property $\\text{Tr}(uv^{\\top}) = v^{\\top}u$:\n$$\n\\frac{1}{2} \\sum_{k=1}^{m} \\text{Tr}\\left( (B_{k}x)(B_{k}x)^{\\top} (2Q) \\right) = \\sum_{k=1}^{m} \\text{Tr}\\left( (B_{k}x)^{\\top} Q (B_{k}x) \\right).\n$$\nSince $(B_{k}x)^{\\top} Q (B_{k}x)$ is a scalar (a $1 \\times 1$ matrix), its trace is the scalar itself. So, the second term is:\n$$\n\\sum_{k=1}^{m} (B_{k}x)^{\\top} Q (B_{k}x) = \\sum_{k=1}^{m} x^{\\top}B_{k}^{\\top} Q B_{k}x.\n$$\nCombining both terms, we obtain the expression for $\\mathcal{L}\\varphi(x)$:\n$$\n\\mathcal{L}\\varphi(x) = 2x^{\\top}Q A x + x^{\\top}Q \\left(\\sum_{k=1}^{m} B_{k}^{2}\\right)x + \\sum_{k=1}^{m} x^{\\top}B_{k}^{\\top} Q B_{k}x.\n$$\nThis expression is a sum of quadratic forms in $x$. We can combine them into a single quadratic form:\n$$\n\\mathcal{L}\\varphi(x) = x^{\\top} \\left( 2QA + \\sum_{k=1}^{m} QB_{k}^{2} + \\sum_{k=1}^{m} B_{k}^{\\top} Q B_{k} \\right) x.\n$$\nThis is the explicit closed-form expression for $\\mathcal{L}\\varphi(x)$ for the given polynomial test function.", "answer": "$$\n\\boxed{x^{\\top} \\left( 2QA + \\sum_{k=1}^{m} QB_{k}^{2} + \\sum_{k=1}^{m} B_{k}^{\\top} Q B_{k} \\right) x}\n$$", "id": "2972262"}]}