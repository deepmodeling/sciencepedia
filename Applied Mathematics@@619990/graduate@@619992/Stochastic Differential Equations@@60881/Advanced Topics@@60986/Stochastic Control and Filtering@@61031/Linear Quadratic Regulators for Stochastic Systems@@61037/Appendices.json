{"hands_on_practices": [{"introduction": "This first exercise provides a foundational workout in the mechanics of stochastic cost evaluation. You will apply Itô's lemma to derive and solve the differential equation for the second moment of a controlled state, allowing for the direct analytical calculation of a finite-horizon quadratic cost functional [@problem_id:2984737]. This practice is essential for building intuition about how noise propagates through a system and accumulates in the performance index.", "problem": "Consider a scalar linear stochastic differential equation (SDE) modeling a controlled plant under a linear quadratic regulator (LQR) state-feedback law:\n$$\ndx_t \\;=\\; a\\,x_t\\,dt \\;+\\; b\\,u_t\\,dt \\;+\\; \\sigma\\,dW_t,\n$$\nwhere $W_t$ is a standard Wiener process (standard Brownian motion). A constant state-feedback control $u_t \\;=\\; -k\\,x_t$ is applied, as delivered by a precomputed linear quadratic regulator (LQR). The initial condition is random with $x_0 \\sim \\mathcal{N}(m_0, v_0)$, so $x_0$ has mean $m_0$ and variance $v_0$. The finite-horizon quadratic state cost is\n$$\nJ_Q \\;=\\; \\mathbb{E}\\!\\left[\\int_{0}^{T} x_t^{\\top}\\,Q\\,x_t \\, dt\\right],\n$$\nand in the scalar case $Q = q > 0$, so $x_t^{\\top}Q x_t = q\\,x_t^2$.\n\nStarting from the fundamental definitions and properties of Itô calculus and the basic moments of linear SDEs, analytically derive and evaluate the expectation $J_Q$ for the following specific parameter values:\n$$\na \\;=\\; 0.75,\\quad b \\;=\\; 1.2,\\quad k \\;=\\; 1.5,\\quad \\sigma \\;=\\; 0.9,\\quad q \\;=\\; 2.5,\\quad T \\;=\\; 1.8,\n$$\nand\n$$\nm_0 \\;=\\; 0.6,\\quad v_0 \\;=\\; 0.4.\n$$\nYour answer must be a single real number equal to $J_Q$, rounded to four significant figures. No units are required.", "solution": "The problem statement is formally validated and found to be self-contained, scientifically grounded in the theory of stochastic differential equations and control, and well-posed. All required parameters are provided, and there are no contradictions or ambiguities. We may therefore proceed with the derivation of a solution.\n\nThe system dynamics are described by the scalar linear stochastic differential equation (SDE):\n$$\ndx_t = a\\,x_t\\,dt + b\\,u_t\\,dt + \\sigma\\,dW_t\n$$\nThe state-feedback control law is given by $u_t = -k\\,x_t$. Substituting this into the SDE yields the closed-loop system dynamics:\n$$\ndx_t = (a - bk)x_t\\,dt + \\sigma\\,dW_t\n$$\nThis is an Ornstein-Uhlenbeck process. Let us define the closed-loop drift coefficient as $\\alpha = a - bk$. The SDE becomes:\n$$\ndx_t = \\alpha\\,x_t\\,dt + \\sigma\\,dW_t\n$$\nThe cost functional to be evaluated is:\n$$\nJ_Q = \\mathbb{E}\\left[\\int_{0}^{T} q\\,x_t^2 \\, dt\\right]\n$$\nwhere $q$ is a positive constant. By the Fubini-Tonelli theorem for stochastic processes, we can interchange the expectation and the integral because the integrand is non-negative:\n$$\nJ_Q = q \\int_{0}^{T} \\mathbb{E}[x_t^2] \\, dt\n$$\nThe core of the problem is to determine the second moment of the state, $\\mathbb{E}[x_t^2]$, as a function of time $t$. Let us denote $S_t = \\mathbb{E}[x_t^2]$. We can derive an ordinary differential equation (ODE) for $S_t$ using Itô's lemma.\n\nLet $f(x) = x^2$. The required derivatives are $f'(x) = 2x$ and $f''(x) = 2$. According to Itô's lemma, the differential of $f(x_t)$ is:\n$$\ndf(x_t) = f'(x_t)\\,dx_t + \\frac{1}{2}f''(x_t)\\,(dx_t)^2\n$$\nSubstituting our function and its derivatives:\n$$\nd(x_t^2) = 2x_t\\,dx_t + \\frac{1}{2}(2)\\,(dx_t)^2 = 2x_t\\,dx_t + (dx_t)^2\n$$\nNow, substitute the SDE for $dx_t$:\n$$\nd(x_t^2) = 2x_t(\\alpha\\,x_t\\,dt + \\sigma\\,dW_t) + (\\alpha\\,x_t\\,dt + \\sigma\\,dW_t)^2\n$$\nThe quadratic variation term $(dx_t)^2$ is evaluated using the Itô calculus rules: $(dt)^2 = 0$, $dt\\,dW_t = 0$, and $(dW_t)^2 = dt$.\n$$\n(\\alpha\\,x_t\\,dt + \\sigma\\,dW_t)^2 = \\alpha^2 x_t^2 (dt)^2 + 2\\alpha\\sigma x_t dt\\,dW_t + \\sigma^2 (dW_t)^2 = \\sigma^2 dt\n$$\nSubstituting this back into the expression for $d(x_t^2)$:\n$$\nd(x_t^2) = (2\\alpha\\,x_t^2\\,dt + 2\\sigma\\,x_t\\,dW_t) + \\sigma^2\\,dt = (2\\alpha\\,x_t^2 + \\sigma^2)\\,dt + 2\\sigma\\,x_t\\,dW_t\n$$\nTo find the ODE for $S_t = \\mathbb{E}[x_t^2]$, we take the expectation of the integral form of this differential:\n$$\n\\mathbb{E}[x_t^2] - \\mathbb{E}[x_0^2] = \\mathbb{E}\\left[\\int_0^t (2\\alpha\\,x_s^2 + \\sigma^2)\\,ds + \\int_0^t 2\\sigma\\,x_s\\,dW_s\\right]\n$$\nUsing the linearity of expectation and interchanging expectation and the time integral:\n$$\nS_t - S_0 = \\int_0^t (2\\alpha\\,\\mathbb{E}[x_s^2] + \\sigma^2)\\,ds + \\mathbb{E}\\left[\\int_0^t 2\\sigma\\,x_s\\,dW_s\\right]\n$$\nThe final term is the expectation of a zero-mean Itô integral, which is zero. Thus:\n$$\nS_t - S_0 = \\int_0^t (2\\alpha\\,S_s + \\sigma^2)\\,ds\n$$\nDifferentiating with respect to $t$ gives the Lyapunov differential equation for the second moment:\n$$\n\\frac{dS_t}{dt} = 2\\alpha\\,S_t + \\sigma^2\n$$\nThe initial condition $S_0 = \\mathbb{E}[x_0^2]$ is derived from the properties of the initial distribution $x_0 \\sim \\mathcal{N}(m_0, v_0)$. We have $\\mathbb{E}[x_0] = m_0$ and $\\text{Var}(x_0) = v_0$. The second moment is $S_0 = \\mathbb{E}[x_0^2] = \\text{Var}(x_0) + (\\mathbb{E}[x_0])^2 = v_0 + m_0^2$.\n\nThis first-order linear ODE can be solved using an integrating factor or by recognizing it as a standard form. The solution is:\n$$\nS_t = S_0 e^{2\\alpha t} + \\frac{\\sigma^2}{2\\alpha}(e^{2\\alpha t} - 1)\n$$\nThis is valid for $\\alpha \\neq 0$.\n\nNow we integrate $S_t$ from $0$ to $T$ to find the total expected cost:\n$$\n\\int_0^T S_t\\,dt = \\int_0^T \\left(S_0 e^{2\\alpha t} + \\frac{\\sigma^2}{2\\alpha}(e^{2\\alpha t} - 1)\\right) dt\n$$\n$$\n\\int_0^T S_t\\,dt = \\int_0^T \\left( \\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)e^{2\\alpha t} - \\frac{\\sigma^2}{2\\alpha} \\right) dt\n$$\n$$\n= \\left[ \\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)\\frac{e^{2\\alpha t}}{2\\alpha} - \\frac{\\sigma^2}{2\\alpha}t \\right]_0^T\n$$\n$$\n= \\left( \\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)\\frac{e^{2\\alpha T}}{2\\alpha} - \\frac{\\sigma^2 T}{2\\alpha} \\right) - \\left( \\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)\\frac{1}{2\\alpha} - 0 \\right)\n$$\n$$\n= \\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)\\frac{e^{2\\alpha T} - 1}{2\\alpha} - \\frac{\\sigma^2 T}{2\\alpha}\n$$\nFinally, we multiply by $q$ to obtain $J_Q$:\n$$\nJ_Q = q \\left[ \\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)\\frac{e^{2\\alpha T} - 1}{2\\alpha} - \\frac{\\sigma^2 T}{2\\alpha} \\right]\n$$\nNow, substitute the given numerical values:\n$a = 0.75$, $b = 1.2$, $k = 1.5$, $\\sigma = 0.9$, $q = 2.5$, $T = 1.8$, $m_0 = 0.6$, $v_0 = 0.4$.\n\nFirst, we compute the intermediate constants:\nThe closed-loop drift coefficient:\n$$\n\\alpha = a - bk = 0.75 - (1.2)(1.5) = 0.75 - 1.8 = -1.05\n$$\nThe initial second moment:\n$$\nS_0 = v_0 + m_0^2 = 0.4 + (0.6)^2 = 0.4 + 0.36 = 0.76\n$$\nThe noise variance:\n$$\n\\sigma^2 = (0.9)^2 = 0.81\n$$\nLet's compute the components of the expression for $J_Q$.\n$$\n2\\alpha = 2(-1.05) = -2.1\n$$\n$$\n\\frac{\\sigma^2}{2\\alpha} = \\frac{0.81}{-2.1} \\approx -0.385714\n$$\n$$\nS_0 + \\frac{\\sigma^2}{2\\alpha} = 0.76 + (-0.385714) \\approx 0.374286\n$$\n$$\n2\\alpha T = -2.1 \\times 1.8 = -3.78\n$$\n$$\ne^{2\\alpha T} - 1 = \\exp(-3.78) - 1 \\approx 0.022822 - 1 = -0.977178\n$$\n$$\n\\frac{e^{2\\alpha T} - 1}{2\\alpha} = \\frac{-0.977178}{-2.1} \\approx 0.465323\n$$\nThe first term inside the brackets is:\n$$\n\\left(S_0 + \\frac{\\sigma^2}{2\\alpha}\\right)\\frac{e^{2\\alpha T} - 1}{2\\alpha} \\approx (0.374286)(0.465323) \\approx 0.174160\n$$\nThe second term inside the brackets is:\n$$\n-\\frac{\\sigma^2 T}{2\\alpha} = -\\frac{0.81 \\times 1.8}{-2.1} = \\frac{1.458}{2.1} \\approx 0.694286\n$$\nSumming the terms inside the brackets:\n$$\n\\approx 0.174160 + 0.694286 = 0.868446\n$$\nFinally, we multiply by $q$:\n$$\nJ_Q = q \\times 0.868446 = 2.5 \\times 0.868446 \\approx 2.171115\n$$\nRounding to four significant figures, the result is $2.171$.", "answer": "$$\n\\boxed{2.171}\n$$", "id": "2984737"}, {"introduction": "Moving beyond simple cost evaluation, this problem challenges you to synthesize an optimal controller for a system with multiplicative noise [@problem_id:2984771]. Starting from the dynamic programming principle, you will derive the relevant algebraic Riccati equation and uncover the crucial condition for mean-square stability, a concept distinct from deterministic stability. This exercise highlights how the type of stochastic disturbance fundamentally alters the control design problem.", "problem": "Consider the scalar stochastic differential equation (SDE)\n$$\n\\mathrm{d}x_t = \\left(a\\,x_t + b\\,u_t\\right)\\mathrm{d}t + \\sigma\\,x_t\\,\\mathrm{d}W_t,\n$$\nwhere $W_t$ is a standard Wiener process, with constants $a$, $b$, and $\\sigma$. The performance criterion is the infinite-horizon expected quadratic cost\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left(q\\,x_t^{2} + r\\,u_t^{2}\\right)\\mathrm{d}t\\right],\n$$\nwhere $q>0$ and $r>0$. Assume the control is restricted to state-feedbacks of the form $u_t = -K\\,x_t$, and seek the optimal linear quadratic regulator (LQR) for this stochastic system.\n\nUsing only the dynamic programming principle and Itô calculus as foundational starting points, derive the stationary Hamilton–Jacobi–Bellman (HJB) equation appropriate for this problem and justify a quadratic value function ansatz $V(x) = P\\,x^{2}$ with a constant $P>0$. For the specific parameter values $a = 1$, $b = 2$, $\\sigma = 1$, $q = 1$, and $r = 1$:\n\n- Derive the algebraic Riccati equation that $P$ must satisfy and solve it explicitly.\n- Compute the optimal feedback gain $K$ in terms of $P$ and provide its explicit value.\n- Explain the additional mean-square stabilizing requirement introduced by the multiplicative noise and verify whether the obtained optimal feedback meets this requirement.\n\nYour final answer must be the ordered pair containing the optimal feedback gain and the Riccati solution, written as a row matrix. No rounding is required. No units are involved.", "solution": "The problem requires the derivation of the optimal linear quadratic regulator for a scalar stochastic system with multiplicative noise. The solution will be developed from first principles using the dynamic programming principle and Itô calculus.\n\nThe stochastic differential equation (SDE) is given by:\n$$\n\\mathrm{d}x_t = (a x_t + b u_t) \\mathrm{d}t + \\sigma x_t \\mathrm{d}W_t\n$$\nThe infinite-horizon cost functional to be minimized is:\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} (q x_t^2 + r u_t^2) \\mathrm{d}t\\right]\n$$\nwith $q > 0$ and $r > 0$. The value function $V(x)$ is defined as the minimum possible cost starting from state $x_0 = x$:\n$$\nV(x) = \\min_{u} J(u | x_0 = x)\n$$\nThe dynamic programming principle for this continuous-time, infinite-horizon problem leads to the stationary Hamilton-Jacobi-Bellman (HJB) equation. The HJB equation states that the optimal cost rate must be zero at every point in time. It is given by:\n$$\n\\min_{u} \\left\\{ L(x, u) + \\mathcal{L}^u V(x) \\right\\} = 0\n$$\nwhere $L(x, u) = q x^2 + r u^2$ is the instantaneous cost, and $\\mathcal{L}^u$ is the infinitesimal generator of the stochastic process $x_t$ under control $u_t$. Using Itô's lemma for a function $V(x_t)$, the generator is:\n$$\n\\mathcal{L}^u V(x) = \\frac{\\mathrm{d}V}{\\mathrm{d}x} (a x + b u) + \\frac{1}{2} \\frac{\\mathrm{d}^2V}{\\mathrm{d}x^2} (\\sigma x)^2\n$$\nSubstituting the generator and the cost into the HJB equation, we obtain:\n$$\n0 = \\min_{u} \\left\\{ q x^2 + r u^2 + (a x + b u) V'(x) + \\frac{1}{2} \\sigma^2 x^2 V''(x) \\right\\}\n$$\nwhere $V'(x)$ and $V''(x)$ denote the first and second derivatives of $V(x)$ with respect to $x$.\n\nTo find the optimal control $u^*(x)$ that minimizes the expression in the braces, we differentiate with respect to $u$ and set the result to zero. The term to be minimized is a quadratic function of $u$, so the minimum is unique.\n$$\n\\frac{\\partial}{\\partial u} \\left[ q x^2 + r u^2 + (a x + b u) V'(x) + \\frac{1}{2} \\sigma^2 x^2 V''(x) \\right] = 2 r u + b V'(x) = 0\n$$\nSolving for $u$ gives the optimal control policy in feedback form:\n$$\nu^*(x) = -\\frac{b}{2r} V'(x)\n$$\nThe second derivative with respect to $u$ is $2r > 0$, confirming this is a minimum.\n\nNext, we substitute this optimal control $u^*(x)$ back into the HJB equation to obtain a partial differential equation for the value function $V(x)$:\n$$\n0 = q x^2 + r \\left(-\\frac{b}{2r} V'(x)\\right)^2 + \\left(a x + b \\left(-\\frac{b}{2r} V'(x)\\right)\\right) V'(x) + \\frac{1}{2}\\sigma^2 x^2 V''(x)\n$$\n$$\n0 = q x^2 + \\frac{b^2}{4r} [V'(x)]^2 + a x V'(x) - \\frac{b^2}{2r} [V'(x)]^2 + \\frac{1}{2}\\sigma^2 x^2 V''(x)\n$$\nSimplifying the terms involving $[V'(x)]^2$:\n$$\n0 = q x^2 + a x V'(x) - \\frac{b^2}{4r} [V'(x)]^2 + \\frac{1}{2}\\sigma^2 x^2 V''(x)\n$$\nThe problem specifies a cost functional that is quadratic in the state $x$ and control $u$. This suggests a quadratic value function. We make the ansatz $V(x) = P x^2$ for some constant $P > 0$. The condition $P>0$ is required because the cost is always non-negative, so the value function, representing the total expected cost, must also be non-negative.\nThe derivatives of the ansatz are $V'(x) = 2 P x$ and $V''(x) = 2 P$. Substituting these into the HJB equation:\n$$\n0 = q x^2 + a x (2 P x) - \\frac{b^2}{4r} (2 P x)^2 + \\frac{1}{2}\\sigma^2 x^2 (2 P)\n$$\n$$\n0 = q x^2 + 2aP x^2 - \\frac{b^2}{4r} (4 P^2 x^2) + \\sigma^2 P x^2\n$$\nWe can factor out $x^2$. For this equation to hold for any state $x$, the expression in the brackets must be zero.\n$$\n\\left( q + 2aP + \\sigma^2 P - \\frac{b^2}{r} P^2 \\right) x^2 = 0\n$$\nThis yields the Algebraic Riccati Equation (ARE) for $P$:\n$$\n(2a + \\sigma^2)P - \\frac{b^2}{r}P^2 + q = 0\n$$\nNow, we substitute the specific parameter values: $a = 1$, $b = 2$, $\\sigma = 1$, $q = 1$, and $r = 1$.\n$$\n(2(1) + 1^2)P - \\frac{2^2}{1}P^2 + 1 = 0\n$$\n$$\n3P - 4P^2 + 1 = 0\n$$\nRearranging into standard quadratic form:\n$$\n4P^2 - 3P - 1 = 0\n$$\nWe solve this quadratic equation for $P$ using the quadratic formula $P = \\frac{-B \\pm \\sqrt{B^2 - 4AC}}{2A}$, with $A=4$, $B=-3$, $C=-1$:\n$$\nP = \\frac{3 \\pm \\sqrt{(-3)^2 - 4(4)(-1)}}{2(4)} = \\frac{3 \\pm \\sqrt{9 + 16}}{8} = \\frac{3 \\pm \\sqrt{25}}{8} = \\frac{3 \\pm 5}{8}\n$$\nThe two possible solutions are $P_1 = \\frac{3+5}{8} = 1$ and $P_2 = \\frac{3-5}{8} = -\\frac{1}{4}$.\nSince the value function must be positive definite ($V(x) = Px^2 \\ge 0$), we must choose the positive solution. Therefore, $P = 1$.\n\nThe optimal feedback gain $K$ is derived from the control law $u_t = -K x_t$. Comparing this to our expression for $u^*(x)$:\n$$\nu^*(x_t) = -\\frac{b}{2r} V'(x_t) = -\\frac{b}{2r} (2 P x_t) = -\\frac{bP}{r} x_t\n$$\nThus, the optimal feedback gain is $K = \\frac{bP}{r}$. Substituting the given parameters and our solved value for $P$:\n$$\nK = \\frac{2 \\cdot 1}{1} = 2\n$$\n\nFinally, we must verify that this control law leads to a mean-square stable closed-loop system. The closed-loop dynamics are found by substituting $u_t = -Kx_t$ into the SDE:\n$$\n\\mathrm{d}x_t = (a x_t + b(-Kx_t)) \\mathrm{d}t + \\sigma x_t \\mathrm{d}W_t = (a - bK)x_t \\mathrm{d}t + \\sigma x_t \\mathrm{d}W_t\n$$\nTo check for mean-square stability, we analyze the dynamics of the second moment, $\\mathbb{E}[x_t^2]$. We apply Itô's lemma to the function $f(x) = x^2$:\n$$\n\\mathrm{d}(x_t^2) = 2x_t \\mathrm{d}x_t + \\frac{1}{2}(2)(\\mathrm{d}x_t)^2 = 2x_t \\mathrm{d}x_t + (\\mathrm{d}x_t)^2\n$$\nSubstituting $\\mathrm{d}x_t$ and using the rule $(\\mathrm{d}t)^2 = 0$, $(\\mathrm{d}t)(\\mathrm{d}W_t) = 0$, $(\\mathrm{d}W_t)^2 = \\mathrm{d}t$:\n$$\n\\mathrm{d}(x_t^2) = 2x_t((a-bK)x_t \\mathrm{d}t + \\sigma x_t \\mathrm{d}W_t) + (\\sigma x_t \\mathrm{d}W_t)^2\n$$\n$$\n\\mathrm{d}(x_t^2) = (2(a-bK)x_t^2 + \\sigma^2 x_t^2) \\mathrm{d}t + 2\\sigma x_t^2 \\mathrm{d}W_t\n$$\nTaking the expectation of both sides, and noting that the expectation of the stochastic integral term is zero, we get an ODE for the mean square value $m_2(t) = \\mathbb{E}[x_t^2]$:\n$$\n\\frac{\\mathrm{d}m_2(t)}{\\mathrm{d}t} = \\mathbb{E}[(2(a-bK) + \\sigma^2)x_t^2] = (2(a-bK) + \\sigma^2)m_2(t)\n$$\nFor $m_2(t)$ to converge to $0$ as $t \\to \\infty$, the coefficient must be negative. This gives the mean-square stability condition:\n$$\n2(a-bK) + \\sigma^2 < 0\n$$\nThe term $\\sigma^2$ is the additional requirement introduced by the multiplicative noise. In a deterministic system ($\\sigma=0$), stability just requires the closed-loop pole, $a-bK$, to be negative. The noise has a destabilizing effect on the second moment which must be counteracted by a sufficiently large negative value of the drift term.\n\nLet's verify this condition with our calculated values $a = 1$, $b = 2$, $\\sigma = 1$, and $K = 2$:\n$$\n2(1 - 2 \\cdot 2) + 1^2 = 2(1 - 4) + 1 = 2(-3) + 1 = -6 + 1 = -5\n$$\nSince $-5 < 0$, the condition for mean-square stability is satisfied. The derived optimal feedback gain $K=2$ is indeed stabilizing.\n\nThe required answer is the ordered pair of the optimal feedback gain $K$ and the Riccati solution $P$. This is $(K,P) = (2,1)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & 1 \\end{pmatrix}}\n$$", "id": "2984771"}, {"introduction": "This final practice explores the boundaries of the Linear Quadratic Regulator framework by presenting a problem with an indefinite state-weighting matrix $Q$ [@problem_id:2984739]. By using the technique of completing the square, you will investigate the well-posedness of the problem and discover how certain cost structures can lead to an infimum cost of negative infinity. This advanced example deepens your understanding of the theoretical assumptions that guarantee a meaningful solution to an optimal control problem.", "problem": "Consider the continuous-time stochastic linear system in $\\mathbb{R}^{2}$,\n$$\ndx(t) \\;=\\; A\\,x(t)\\,dt \\;+\\; B\\,u(t)\\,dt \\;+\\; \\Sigma\\,dW(t),\n$$\nwhere $x(t) \\in \\mathbb{R}^{2}$, $u(t) \\in \\mathbb{R}$, $W(t) \\in \\mathbb{R}^{2}$ is a standard two-dimensional Brownian motion with independent components, and\n$$\nA \\;=\\; \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix},\\qquad\nB \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\\qquad\n\\Sigma \\;=\\; \\begin{pmatrix} \\sigma & 0 \\\\ 0 & 0 \\end{pmatrix},\n$$\nwith a fixed constant $\\sigma \\in (0,\\infty)$. The initial condition is $x(0)=0$. The admissible controls are all progressively measurable processes $u$ such that, for every finite horizon $T>0$, $\\mathbb{E}\\!\\left[\\int_{0}^{T} u(t)^{2}\\,dt\\right] < \\infty$. Consider the infinite-horizon quadratic performance index\n$$\nJ(u) \\;=\\; \\mathbb{E}\\!\\left[\\int_{0}^{\\infty} \\Big( x(t)^{\\top} Q\\, x(t) \\;+\\; 2\\, x(t)^{\\top} N\\, u(t) \\;+\\; r\\, u(t)^{2} \\Big) dt \\right],\n$$\nwith\n$$\nQ \\;=\\; \\begin{pmatrix} -1 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\qquad\nN \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\qquad\nr \\;=\\; 1.\n$$\nNote that $Q$ is indefinite. Using only foundational tools (the algebraic completion-of-squares identity for quadratics and basic properties of Itô diffusion second moments), do the following:\n\n- Complete the square in $u$ to eliminate the cross term and rewrite the running integrand in terms of a new control $\\tilde{u}$ and an effective state-weight matrix $Q_{\\mathrm{eff}}$. Determine $Q_{\\mathrm{eff}}$ explicitly.\n\n- Derive the dynamics under the control reparameterization $u(t) = \\tilde{u}(t) - K\\,x(t)$ for the $K$ that arises from the completion of squares, and identify the resulting drift matrix for the state.\n\n- Based on your reformulation, determine whether the problem is well-posed (finite optimal value) or ill-posed (the infimum of $J$ is $-\\infty$). Justify your conclusion by constructing an admissible control and using second-moment growth for the corresponding Itô process.\n\nWhat is the value of $\\inf_{u} J(u)$? Provide your final answer as a single analytic expression. No rounding is required.", "solution": "The user has provided a stochastic linear quadratic control problem and has requested a step-by-step analysis to determine if the problem is well-posed and to find the infimum of the cost functional. The analysis will be performed using first principles as requested.\n\nThe problem is defined by the stochastic differential equation (SDE):\n$$\ndx(t) = A\\,x(t)\\,dt + B\\,u(t)\\,dt + \\Sigma\\,dW(t)\n$$\nwith matrices\n$$\nA = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix},\\quad B = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix},\\quad \\Sigma = \\begin{pmatrix} \\sigma & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nThe state is $x(t) \\in \\mathbb{R}^2$, control is $u(t) \\in \\mathbb{R}$, and $W(t) \\in \\mathbb{R}^2$ is a standard Brownian motion. The initial condition is $x(0)=0$. The cost functional to be minimized is:\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left( x(t)^{\\top} Q\\, x(t) + 2\\, x(t)^{\\top} N\\, u(t) + r\\, u(t)^{2} \\right) dt \\right]\n$$\nwith cost parameters\n$$\nQ = \\begin{pmatrix} -1 & 0 \\\\ 0 & 1 \\end{pmatrix}, \\quad N = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad r = 1\n$$\n\nThe analysis will proceed in three parts as specified by the problem statement.\n\n### Part 1: Completion of the Square and Effective State-Weighting Matrix\n\nThe running integrand in the cost functional $J(u)$ is a quadratic function of the control $u(t)$. We can complete the square with respect to $u(t)$ to simplify the expression. The integrand is:\n$$\nL(x(t), u(t)) = x(t)^{\\top} Q x(t) + 2 x(t)^{\\top} N u(t) + r u(t)^2\n$$\nWith scalar control $u$ and $r=1$, this is $L(x, u) = u^2 + 2(N^{\\top}x)u + x^{\\top}Qx$. Completing the square for the terms involving $u$:\n$$\nu^2 + 2(N^{\\top}x)u = (u + N^{\\top}x)^2 - (N^{\\top}x)^2\n$$\nSince $N^{\\top}x$ is a scalar, its square is $(N^{\\top}x)^2 = (N^{\\top}x)^{\\top}(N^{\\top}x) = x^{\\top}NN^{\\top}x$.\nSubstituting this back into the integrand expression gives:\n$$\nL(x, u) = (u + N^{\\top}x)^2 - x^{\\top}NN^{\\top}x + x^{\\top}Qx = (u + N^{\\top}x)^2 + x^{\\top}(Q - NN^{\\top})x\n$$\nWe define a new control variable $\\tilde{u}(t)$ and a feedback gain matrix $K$ as follows:\n$$\nK = r^{-1}N^{\\top} = 1^{-1} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}^{\\top} = \\begin{pmatrix} 1 & 0 \\end{pmatrix}\n$$\n$$\n\\tilde{u}(t) = u(t) + Kx(t) = u(t) + N^{\\top}x(t)\n$$\nThis implies the control reparameterization $u(t) = \\tilde{u}(t) - Kx(t)$.\nThe integrand can now be written in terms of $\\tilde{u}(t)$ and an effective state-weighting matrix $Q_{\\mathrm{eff}}$:\n$$\nL(x, u) = \\tilde{u}(t)^2 + x(t)^{\\top} Q_{\\mathrm{eff}} x(t)\n$$\nwhere\n$$\nQ_{\\mathrm{eff}} = Q - r^{-1}NN^{\\top} = Q - NN^{\\top}\n$$\nWe compute $NN^{\\top}$:\n$$\nNN^{\\top} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nTherefore, the effective state-weighting matrix is:\n$$\nQ_{\\mathrm{eff}} = \\begin{pmatrix} -1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\n\n### Part 2: Dynamics Under Control Reparameterization\n\nWe substitute the control reparameterization $u(t) = \\tilde{u}(t) - Kx(t)$ into the state dynamics SDE:\n$$\ndx(t) = (A x(t) + B(\\tilde{u}(t) - Kx(t))) dt + \\Sigma dW(t)\n$$\n$$\ndx(t) = ((A - BK)x(t) + B\\tilde{u}(t)) dt + \\Sigma dW(t)\n$$\nThe resulting drift matrix for the state process $x(t)$ is the closed-loop matrix $A_{CL} = A - BK$. Let's compute this matrix:\n$$\nBK = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n$$\nA_{CL} = A - BK = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & -1 \\end{pmatrix}\n$$\nSo, the dynamics expressed in terms of the new control $\\tilde{u}(t)$ are governed by the drift matrix $A_{CL} = \\begin{pmatrix} 0 & 0 \\\\ 0 & -1 \\end{pmatrix}$.\n\n### Part 3: Well-Posedness Analysis\n\nWith the transformations from the previous parts, the problem is equivalent to minimizing\n$$\nJ(\\tilde{u}) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left( \\tilde{u}(t)^2 + x(t)^{\\top} Q_{\\mathrm{eff}} x(t) \\right) dt \\right]\n$$\nsubject to the dynamics\n$$\ndx(t) = (A_{CL} x(t) + B\\tilde{u}(t)) dt + \\Sigma dW(t), \\quad x(0)=0.\n$$\nLet's write out the dynamics and cost in terms of the components of $x(t) = \\begin{pmatrix} x_1(t) & x_2(t) \\end{pmatrix}^{\\top}$.\nThe dynamics are:\n$$\nd\\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix} = \\left( \\begin{pmatrix} 0 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\tilde{u}(t) \\right) dt + \\begin{pmatrix} \\sigma & 0 \\\\ 0 & 0 \\end{pmatrix} dW(t)\n$$\nThis decouples into two separate scalar SDEs:\n$$\ndx_1(t) = \\tilde{u}(t) dt + \\sigma dW_1(t)\n$$\n$$\ndx_2(t) = -x_2(t) dt\n$$\nThe cost integrand is:\n$$\n\\tilde{u}(t)^2 + x(t)^{\\top} \\begin{pmatrix} -2 & 0 \\\\ 0 & 1 \\end{pmatrix} x(t) = \\tilde{u}(t)^2 - 2x_1(t)^2 + x_2(t)^2\n$$\nFrom the SDE for $x_2(t)$ with the initial condition $x_2(0)=0$, the unique solution is $x_2(t) = 0$ for all $t \\geq 0$. This means the term $x_2(t)^2$ in the cost functional is identically zero.\nThe problem simplifies to minimizing:\n$$\nJ(\\tilde{u}) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left( \\tilde{u}(t)^2 - 2x_1(t)^2 \\right) dt \\right]\n$$\nsubject to $dx_1(t) = \\tilde{u}(t) dt + \\sigma dW_1(t)$ with $x_1(0)=0$.\n\nTo determine if the problem is well-posed, we test if the infimum of $J(u)$ can be driven to $-\\infty$. We can investigate this by choosing a specific admissible control and evaluating its cost. The negative sign on the $x_1(t)^2$ term suggests that making $x_1(t)$ large in magnitude will decrease the cost.\n\nConsider the simplest possible choice for the new control: $\\tilde{u}(t) = 0$ for all $t \\geq 0$.\nThis corresponds to the original feedback control law $u(t) = -Kx(t) = -x_1(t)$.\nFirst, we verify that this control is admissible. The dynamics for $x_1(t)$ become:\n$$\ndx_1(t) = \\sigma dW_1(t), \\quad x_1(0)=0\n$$\nThe solution is $x_1(t) = \\sigma W_1(t)$.\nThe control is $u(t) = -x_1(t) = -\\sigma W_1(t)$. For admissibility, we must check if $\\mathbb{E}\\left[\\int_{0}^{T} u(t)^2 dt\\right] < \\infty$ for any finite $T>0$.\n$$\n\\mathbb{E}\\left[\\int_{0}^{T} u(t)^2 dt\\right] = \\mathbb{E}\\left[\\int_{0}^{T} (-\\sigma W_1(t))^2 dt\\right]\n$$\nBy Fubini's theorem for non-negative functions, we can swap expectation and integration:\n$$\n\\mathbb{E}\\left[\\int_{0}^{T} u(t)^2 dt\\right] = \\int_{0}^{T} \\sigma^2 \\mathbb{E}[W_1(t)^2] dt\n$$\nThe second moment of a standard one-dimensional Wiener process is $\\mathbb{E}[W_1(t)^2] = t$.\n$$\n\\int_{0}^{T} \\sigma^2 t\\, dt = \\sigma^2 \\left[\\frac{t^2}{2}\\right]_0^T = \\frac{1}{2}\\sigma^2 T^2\n$$\nSince this value is finite for any finite $T$, the control $u(t)=-x_1(t)$ (or equivalently $\\tilde{u}(t)=0$) is admissible.\n\nNow, we calculate the cost $J$ for this control:\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left( \\tilde{u}(t)^2 - 2x_1(t)^2 \\right) dt \\right] = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left( 0^2 - 2(\\sigma W_1(t))^2 \\right) dt \\right]\n$$\nAgain, by Fubini's theorem (as the expected integrand is non-positive):\n$$\nJ(u) = \\int_{0}^{\\infty} -2 \\sigma^2 \\mathbb{E}[W_1(t)^2] dt = \\int_{0}^{\\infty} -2 \\sigma^2 t\\, dt\n$$\nThis integral diverges:\n$$\n\\int_{0}^{\\infty} -2 \\sigma^2 t\\, dt = -2\\sigma^2 \\lim_{T \\to \\infty} \\left[\\frac{t^2}{2}\\right]_0^T = -2\\sigma^2 \\lim_{T \\to \\infty} \\frac{T^2}{2} = -\\infty\n$$\nSince we have constructed an admissible control for which the performance index $J(u)$ is $-\\infty$, the infimum of $J(u)$ over the set of all admissible controls must be $-\\infty$.\nTherefore, the problem is ill-posed.\n\n### Conclusion\n\nThe problem is ill-posed because the infimum of the cost functional is $-\\infty$. This occurs because the completion-of-squares procedure results in an effective state-weighting matrix $Q_{\\mathrm{eff}}$ which is not positive semidefinite. The negative eigenvalue of $Q_{\\mathrm{eff}}$ corresponds to a state component that is controllable, allowing the cost to be driven to $-\\infty$ by an admissible control policy that exploits this instability. The value of the infimum is thus $-\\infty$.", "answer": "$$\n\\boxed{-\\infty}\n$$", "id": "2984739"}]}