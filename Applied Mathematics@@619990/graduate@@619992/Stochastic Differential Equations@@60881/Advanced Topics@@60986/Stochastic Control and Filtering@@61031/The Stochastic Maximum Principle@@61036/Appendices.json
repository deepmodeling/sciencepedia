{"hands_on_practices": [{"introduction": "A powerful way to understand a new, general theory is to see how it recovers familiar, specific cases. This first exercise guides you through this process by connecting the Stochastic Maximum Principle (SMP) to the classical deterministic Pontryagin's Maximum Principle (PMP). By analyzing a system where the control does not influence the stochastic term, you will uncover the precise role of the adjoint martingale process $q_t$ and see why it must vanish in a deterministic setting. This practice solidifies your understanding of the fundamental structure of the SMP.", "problem": "Consider the scalar controlled system on the finite horizon $[0,T]$ given by the stochastic differential equation\n$$\ndX_t \\;=\\; \\big(a\\,X_t + b\\,u_t\\big)\\,dt \\;+\\; D\\,u_t\\,dW_t,\\qquad X_0 = x_0,\n$$\nwhere $a$, $b$, $D$, and $x_0$ are real constants, $u_t$ is an admissible control process taking values in $\\mathbb{R}$, and $W_t$ is a standard Brownian motion. The performance index is\n$$\nJ(u) \\;=\\; \\mathbb{E}\\!\\left[\\,\\frac{1}{2}\\,M\\,X_T^2 \\;+\\; \\int_0^T \\frac{1}{2}\\,\\big(Q\\,X_t^2 + R\\,u_t^2\\big)\\,dt \\right],\n$$\nwith $M>0$, $Q\\ge 0$, and $R>0$ constants. Define the Hamiltonian $H$ associated to the Stochastic Maximum Principle (SMP) as\n$$\nH(t,x,u,p,q) \\;=\\; p\\,\\big(a\\,x + b\\,u\\big) \\;+\\; q\\,\\big(D\\,u\\big) \\;-\\; \\frac{1}{2}\\,\\big(Q\\,x^2 + R\\,u^2\\big),\n$$\nwhere $p_t$ and $q_t$ are the adjoint (costate and martingale) processes entering the backward stochastic differential equation (BSDE) for the SMP. \n\nAnalyze the special case $D=0$ and rigorously recover, starting from the variational structure of the SMP and fundamental properties of Itô processes and quadratic variation, the classical Pontryagin Maximum Principle (PMP) structure: a deterministic adjoint ordinary differential equation (ODE) and a pointwise-in-time stationarity (maximum) condition for the Hamiltonian. In particular, identify the adjoint martingale term $q_t$ and explain its role, then determine its explicit expression when $D=0$.\n\nYour final answer must be the explicit analytic expression for the adjoint martingale term $q_t$ in the case $D=0$. No rounding is necessary. Express your final answer as a single closed-form analytic expression.", "solution": "The analysis begins by recalling the general formulation of the Stochastic Maximum Principle (SMP) for the given problem. The system is described by the state equation\n$$dX_t = f(t, X_t, u_t) dt + \\sigma(t, X_t, u_t) dW_t$$\nand the cost functional\n$$J(u) = \\mathbb{E}\\left[\\Phi(X_T) + \\int_0^T L(t, X_t, u_t) dt\\right]$$\nFor the specific problem statement, we identify the components:\n- Drift: $f(t,x,u) = a\\,x + b\\,u$\n- Diffusion: $\\sigma(t,x,u) = D\\,u$\n- Terminal cost: $\\Phi(x) = \\frac{1}{2}\\,M\\,x^2$\n- Running cost: $L(t,x,u) = \\frac{1}{2}\\,\\big(Q\\,x^2 + R\\,u^2\\big)$\n\nThe Hamiltonian given is $H(t,x,u,p,q) = p\\,(a\\,x + b\\,u) + q\\,(D\\,u) - \\frac{1}{2}\\,\\big(Q\\,x^2 + R\\,u^2\\big)$, which corresponds to the standard definition $H = p f + q \\sigma - L$.\n\nThe necessary conditions for an optimal control $u_t^*$ and corresponding state $X_t^*$ are given by the SMP. These conditions involve a pair of adjoint processes, the costate $p_t$ and the martingale term $q_t$, which satisfy the following backward stochastic differential equation (BSDE):\n$$-dp_t = H_x(t, X_t^*, u_t^*, p_t, q_t) dt - q_t dW_t, \\qquad p_T = \\Phi_x(X_T^*)$$\nwhere $H_x$ denotes the partial derivative of the Hamiltonian with respect to the state variable $x$. Moreover, the optimal control $u_t^*$ must satisfy the maximum condition:\n$$H(t, X_t^*, u_t^*, p_t, q_t) = \\sup_{v \\in \\mathbb{R}} H(t, X_t^*, v, p_t, q_t)$$\nFor our specific problem, the partial derivative of the Hamiltonian with respect to $x$ is:\n$$H_x = \\frac{\\partial}{\\partial x} \\left[ p(ax+bu) + q(Du) - \\frac{1}{2}(Qx^2+Ru^2) \\right] = a\\,p_t - Q\\,X_t^*$$\nThe terminal condition for $p_t$ is:\n$$p_T = \\frac{\\partial}{\\partial x} \\left( \\frac{1}{2} M x^2 \\right) \\bigg|_{x=X_T^*} = M\\,X_T^*$$\nThus, the adjoint BSDE is:\n$$-dp_t = (a\\,p_t - Q\\,X_t^*) dt - q_t dW_t$$\nor equivalently, in forward form:\n$$dp_t = (Q\\,X_t^* - a\\,p_t) dt + q_t dW_t$$\nSince the control set is $\\mathbb{R}$ and the Hamiltonian is strictly concave in $u$ (because $R>0$), the maximum condition is equivalent to the first-order stationarity condition $H_u = 0$:\n$$H_u = \\frac{\\partial}{\\partial u} \\left[ p(ax+bu) + q(Du) - \\frac{1}{2}(Qx^2+Ru^2) \\right] = b\\,p_t + D\\,q_t - R\\,u_t = 0$$\nThis gives the optimal control in terms of the adjoint processes:\n$$u_t^* = \\frac{1}{R}(b\\,p_t + D\\,q_t)$$\n\nNow, we analyze the special case where $D=0$.\nIn this case, the system dynamics become:\n$$dX_t = (a\\,X_t + b\\,u_t)\\,dt, \\qquad X_0 = x_0$$\nThis is a deterministic ordinary differential equation (ODE) for any given control function $u(t)$. The Brownian motion $W_t$ no longer drives the state dynamics. The cost functional remains:\n$$J(u) = \\mathbb{E}\\!\\left[\\,\\frac{1}{2}\\,M\\,X_T^2 \\;+\\; \\int_0^T \\frac{1}{2}\\,\\big(Q\\,X_t^2 + R\\,u_t^2\\big)\\,dt \\right]$$\nThe problem is to find the optimal control $u_t$ within the class of admissible controls, which are processes adapted to the filtration $\\mathcal{F}_t$ generated by $W_t$.\n\nThe crucial step is to demonstrate that the optimal control $u_t^*$ must be deterministic. Let $u_t$ be any admissible adapted control. We can decompose it into its deterministic mean and a stochastic part with zero mean:\n$$u_t = \\bar{u}_t + \\tilde{u}_t, \\quad \\text{where} \\quad \\bar{u}_t = \\mathbb{E}[u_t] \\quad \\text{and} \\quad \\mathbb{E}[\\tilde{u}_t] = 0$$\nDue to the linearity of the state equation, the state $X_t$ can be similarly decomposed as $X_t = \\bar{X}_t + \\tilde{X}_t$, where:\n$$\\frac{d\\bar{X}_t}{dt} = a\\,\\bar{X}_t + b\\,\\bar{u}_t, \\quad \\bar{X}_0 = x_0$$\n$$\\frac{d\\tilde{X}_t}{dt} = a\\,\\tilde{X}_t + b\\,\\tilde{u}_t, \\quad \\tilde{X}_0 = 0$$\nSince $\\bar{X}_t$ and $\\bar{u}_t$ are deterministic, and $\\mathbb{E}[\\tilde{X}_t] = \\mathbb{E}[\\int_0^t e^{a(t-s)}b\\,\\tilde{u}_s ds] = \\int_0^t e^{a(t-s)}b\\,\\mathbb{E}[\\tilde{u}_s] ds = 0$.\n\nLet's expand the cost functional:\n$$J(u) = \\frac{1}{2} \\mathbb{E} \\left[ M(\\bar{X}_T + \\tilde{X}_T)^2 + \\int_0^T \\left( Q(\\bar{X}_t + \\tilde{X}_t)^2 + R(\\bar{u}_t + \\tilde{u}_t)^2 \\right) dt \\right]$$\nExpanding the quadratic terms and using the linearity of expectation:\n$$J(u) = \\frac{1}{2} \\left( M\\bar{X}_T^2 + \\int_0^T (Q\\bar{X}_t^2 + R\\bar{u}_t^2) dt \\right) + \\frac{1}{2} \\mathbb{E}\\left[ M\\tilde{X}_T^2 + \\int_0^T (Q\\tilde{X}_t^2 + R\\tilde{u}_t^2) dt \\right]$$\nAll cross-terms vanish because, for example, $\\mathbb{E}[\\bar{X}_t \\tilde{X}_t] = \\bar{X}_t \\mathbb{E}[\\tilde{X}_t] = 0$. The first term is precisely the cost functional for the deterministic control $\\bar{u}_t$, i.e., $J(\\bar{u})$. The second term is a non-negative quantity, as $M>0$, $Q\\ge 0$, and $R>0$.\n$$J(u) = J(\\bar{u}) + \\frac{1}{2} \\mathbb{E}\\left[ M\\tilde{X}_T^2 + \\int_0^T (Q\\tilde{X}_t^2 + R\\tilde{u}_t^2) dt \\right]$$\nThis inequality shows that $J(u) \\ge J(\\bar{u})$. The minimum is achieved if and only if the second term is zero. Since $R>0$, this requires $\\mathbb{E}[\\int_0^T R\\tilde{u}_t^2 dt] = 0$, which implies $\\tilde{u}_t = 0$ for almost every $t \\in [0,T]$, almost surely. Therefore, any optimal control $u_t^*$ must be deterministic.\n\nNow we return to the SMP results for the case $D=0$. The optimal control is given by:\n$$u_t^* = \\frac{1}{R}(b\\,p_t + (0)\\,q_t) = \\frac{b}{R}p_t$$\nSince we have rigorously established that $u_t^*$ must be a deterministic function of time, and $b$ and $R$ are constants, the adjoint process $p_t$ must also be a deterministic function of time.\n\nThe process $p_t$ is the solution to the BSDE:\n$$dp_t = (Q\\,X_t^* - a\\,p_t) dt + q_t dW_t, \\qquad p_T = M\\,X_T^*$$\nAn Itô process is deterministic if and only if its stochastic integral component is identically zero. The stochastic differential of a deterministic, differentiable function $p(t)$ is simply $dp(t) = \\frac{dp}{dt} dt$. For the Itô process $p_t$ to be deterministic, its diffusion coefficient must be zero. The diffusion part of $dp_t$ is $q_t dW_t$. For this term to be zero, the coefficient process $q_t$ must be zero for almost every $t \\in [0,T]$, almost surely.\n\nThus, we must have $q_t = 0$.\n\nThe role of the adjoint martingale term $q_t$ in the general SMP is to model the effect of uncertainty propagation in the adjoint system. It captures how the \"shadow price\" $p_t$ must adjust in response to the same random shocks that affect the state system. When the state system's evolution becomes independent of the random shocks (i.e., $D=0$), there is no longer any stochastic information for the adjoint process to react to, and its martingale component $q_t$ must vanish.\n\nWith $q_t=0$, the SMP system reduces to:\n1. State ODE: $\\frac{dX_t}{dt} = a\\,X_t + b\\,u_t$\n2. Adjoint ODE: $\\frac{dp_t}{dt} = Q\\,X_t - a\\,p_t$\n3. Transversality condition: $p_T = M\\,X_T$\n4. Optimality condition: $u_t = \\frac{b}{R} p_t$\n\nThis is precisely the set of necessary conditions that constitutes the Pontryagin Maximum Principle (PMP) for the corresponding deterministic linear-quadratic optimal control problem. The analysis shows how the more general SMP gracefully degrades to the classical PMP when the stochastic elements are removed from the system dynamics. The explicit expression for the adjoint martingale term $q_t$ in this case is zero.", "answer": "$$\\boxed{0}$$", "id": "3003302"}, {"introduction": "The first-order conditions of the Stochastic Maximum Principle are powerful, but they can be inconclusive, particularly for so-called singular controls. This exercise explores such a scenario, where the Hamiltonian is linear in the control, leaving the first-order analysis unable to determine optimality. You will employ a second-order variational analysis to resolve this ambiguity, a vital technique for diagnosing the true nature of singular control candidates and a key skill for tackling control-affine systems.", "problem": "Consider a one-dimensional controlled stochastic differential equation driven by a standard Brownian motion $W$ on the time interval $[0,1]$,\n$$\ndx_t \\;=\\; u_t\\,dt \\;+\\; \\nu\\,u_t\\,dW_t,\\qquad x_0 \\;=\\; 0,\n$$\nwhere $\\nu\\in\\mathbb{R}$ is a given constant and the control $u$ is progressively measurable and takes values in a fixed compact interval $U=[-\\bar{u},\\bar{u}]$ with $\\bar{u}>0$. The performance functional to be maximized is\n$$\nJ(u) \\;=\\; \\mathbb{E}\\!\\left[\\tfrac{1}{2}\\,x_1^2\\right].\n$$\nWork within the framework of the stochastic maximum principle (SMP) and its second-order extension. Begin from the core definitions: the Hamiltonian $H(x,u,p,q)$ for a control-affine system with running cost equal to zero, and the first-order adjoint backward stochastic differential equation with terminal condition given by the gradient of the terminal cost. Show that the first-order SMP is inconclusive at the candidate control $u_t\\equiv 0$, in the sense that the stationarity condition for the Hamiltonian with respect to $u$ and the Legendre condition provide no information to distinguish optimality.\n\nThen analyze a small control perturbation $u^{\\varepsilon}_t=\\varepsilon\\,v_t$ around the singular candidate $u_t\\equiv 0$, where $v_t$ is a deterministic direction and $\\varepsilon$ is a small scalar satisfying $0<|\\varepsilon|\\leq \\varepsilon_0$ for some $\\varepsilon_0>0$ small enough to keep $u^{\\varepsilon}$ in $U$. For the specific choice $v_t\\equiv 1$ on $[0,1]$, derive the second-order variation coefficient $Q(\\nu)$ defined by the relation\n$$\nJ(u^{\\varepsilon}) - J(0) \\;=\\; \\varepsilon^2\\,Q(\\nu) \\;+\\; o(\\varepsilon^2)\\quad\\text{as }\\varepsilon\\to 0,\n$$\nusing only well-tested facts such as Itô’s isometry and basic properties of stochastic integrals. Your derivation must start from the controlled dynamics, construct $x_1$ under $u^{\\varepsilon}$, and compute the expectation in $J(u^{\\varepsilon})$ exactly. Conclude, in words, how the sign of $Q(\\nu)$ eliminates the non-optimal singular control $u\\equiv 0$ via second-order conditions for a maximization problem. Express your final answer for $Q(\\nu)$ as a closed-form analytic expression in terms of $\\nu$. No rounding is required and no units are involved.", "solution": "First, we analyze the candidate control $u_t \\equiv 0$ using the first-order stochastic maximum principle (SMP). The system is control-affine with dynamics $dx_t = b(u_t) dt + \\sigma(u_t) dW_t$, where $b(u) = u$ and $\\sigma(u) = \\nu u$. The running cost is $L(x,u) = 0$ and the terminal cost is $\\Phi(x) = \\frac{1}{2}x^2$.\n\nThe Hamiltonian for this system is defined as:\n$$\nH(x, u, p, q) = p\\,b(u) + q\\,\\sigma(u) - L(x,u) = p u + q (\\nu u) = (p + \\nu q) u\n$$\nThe adjoint processes $(p_t, q_t)$ satisfy the backward stochastic differential equation (BSDE):\n$$\ndp_t = -\\frac{\\partial H}{\\partial x}(x_t, u_t, p_t, q_t) dt + q_t dW_t, \\quad p_1 = \\frac{d\\Phi}{dx}(x_1)\n$$\nSince the Hamiltonian $H$ does not depend on the state $x$, we have $\\frac{\\partial H}{\\partial x} = 0$. The terminal condition is $p_1 = \\frac{d}{dx}(\\frac{1}{2}x^2)\\big|_{x=x_1} = x_1$.\nThus, the adjoint BSDE is $dp_t = q_t dW_t$ with $p_1 = x_1$.\n\nLet's evaluate this for the singular candidate control $u_t \\equiv 0$. For $u_t = 0$, the state dynamics become $dx_t = 0$ with $x_0 = 0$. This yields the deterministic state trajectory $x_t \\equiv 0$ for all $t \\in [0, 1]$. Consequently, the terminal state is $x_1 = 0$.\nThe terminal condition for the adjoint process $p_t$ becomes $p_1 = x_1 = 0$. The unique solution to the BSDE $dp_t = q_t dW_t$ with $p_1 = 0$ is $p_t \\equiv 0$ and $q_t \\equiv 0$ for all $t \\in [0, 1]$.\n\nThe first-order necessary condition of the SMP (Pontryagin's principle) states that an optimal control $u^*_t$ must satisfy for a.e. $t \\in [0, 1]$:\n$$\nH(x^*_t, u^*_t, p_t, q_t) = \\max_{v \\in U} H(x^*_t, v, p_t, q_t)\n$$\nFor our candidate $u_t \\equiv 0$, we have $p_t = 0$ and $q_t = 0$. The Hamiltonian becomes $H(x_t, u, p_t, q_t) = (0 + \\nu \\cdot 0) u = 0$ for any value of $u \\in U$. The optimality condition reduces to $0 = \\max_{v \\in [-\\bar{u}, \\bar{u}]} 0$, which is a tautology. It provides no information to determine the optimal control, as any $v \\in U$ is a maximizer. The stationarity condition $\\frac{\\partial H}{\\partial u} = p_t + \\nu q_t = 0$ is satisfied, and the second-derivative (Legendre-Clebsch) condition $\\frac{\\partial^2 H}{\\partial u^2} = 0$ is also uninformative. Thus, the first-order SMP is inconclusive.\n\nNext, we perform a second-order analysis. We consider the specified control perturbation around the singular control $u_t \\equiv 0$. The perturbed control is $u_t^\\varepsilon = \\varepsilon v_t$ where $v_t \\equiv 1$, so $u_t^\\varepsilon = \\varepsilon$ for $t \\in [0, 1]$. We assume $\\varepsilon$ is small enough such that $\\varepsilon \\in [-\\bar{u}, \\bar{u}]$.\n\nThe state SDE under $u^\\varepsilon$ is:\n$$\ndx_t^\\varepsilon = \\varepsilon dt + \\nu \\varepsilon dW_t, \\quad x_0^\\varepsilon = 0\n$$\nThis is a linear SDE which can be solved by direct integration:\n$$\nx_t^\\varepsilon = \\int_0^t \\varepsilon ds + \\int_0^t \\nu \\varepsilon dW_s = \\varepsilon t + \\nu \\varepsilon W_t\n$$\nAt the terminal time $t=1$, the state is:\n$$\nx_1^\\varepsilon = \\varepsilon (1) + \\nu \\varepsilon W_1 = \\varepsilon (1 + \\nu W_1)\n$$\nThe performance functional for this perturbed control is:\n$$\nJ(u^\\varepsilon) = \\mathbb{E}\\left[\\frac{1}{2} (x_1^\\varepsilon)^2\\right] = \\mathbb{E}\\left[\\frac{1}{2} \\left(\\varepsilon (1 + \\nu W_1)\\right)^2\\right] = \\frac{1}{2}\\varepsilon^2 \\mathbb{E}\\left[(1 + \\nu W_1)^2\\right]\n$$\nWe expand the term inside the expectation:\n$$\n\\mathbb{E}\\left[(1 + \\nu W_1)^2\\right] = \\mathbb{E}\\left[1 + 2\\nu W_1 + \\nu^2 W_1^2\\right]\n$$\nUsing the linearity of expectation, we get:\n$$\n\\mathbb{E}\\left[1\\right] + 2\\nu \\mathbb{E}\\left[W_1\\right] + \\nu^2 \\mathbb{E}\\left[W_1^2\\right]\n$$\nFor a standard Brownian motion $W_t$, we have the fundamental properties $\\mathbb{E}[W_t] = 0$ and $\\text{Var}(W_t) = \\mathbb{E}[W_t^2] - (\\mathbb{E}[W_t])^2 = t$. For $t=1$, this gives $\\mathbb{E}[W_1] = 0$ and $\\mathbb{E}[W_1^2] = 1$. Substituting these values:\n$$\n\\mathbb{E}\\left[(1 + \\nu W_1)^2\\right] = 1 + 2\\nu(0) + \\nu^2(1) = 1 + \\nu^2\n$$\nReturning to the expression for $J(u^\\varepsilon)$, we find:\n$$\nJ(u^\\varepsilon) = \\frac{1}{2}\\varepsilon^2 (1 + \\nu^2)\n$$\nThe cost corresponding to the singular control $u_t \\equiv 0$ is $J(0) = \\mathbb{E}[\\frac{1}{2} (0)^2] = 0$.\nThe variation in the cost functional is therefore:\n$$\nJ(u^\\varepsilon) - J(0) = \\frac{1}{2}\\varepsilon^2 (1 + \\nu^2) - 0 = \\frac{1}{2}\\varepsilon^2 (1 + \\nu^2)\n$$\nThe problem defines the second-order variation coefficient $Q(\\nu)$ through the expansion $J(u^\\varepsilon) - J(0) = \\varepsilon^2 Q(\\nu) + o(\\varepsilon^2)$. Comparing our exact expression with this definition, we identify:\n$$\nQ(\\nu) = \\frac{1}{2}(1 + \\nu^2)\n$$\nThere are no higher-order terms in $\\varepsilon$, so the $o(\\varepsilon^2)$ term is zero.\n\nFinally, we use the sign of $Q(\\nu)$ to draw a conclusion about the optimality of $u_t \\equiv 0$. The problem is a maximization problem. A necessary condition for $u_t \\equiv 0$ to be a local maximum is that for any admissible perturbation, the corresponding variation of the cost must be non-positive, i.e., $J(u^\\varepsilon) - J(0) \\le 0$ for all sufficiently small $\\varepsilon$. This translates to the second-order necessary condition $Q(\\nu) \\le 0$ for the given type of perturbation.\nHowever, we found $Q(\\nu) = \\frac{1}{2}(1 + \\nu^2)$. Since $\\nu \\in \\mathbb{R}$, $\\nu^2 \\ge 0$, which implies $1 + \\nu^2 \\ge 1$. Consequently, for any value of the parameter $\\nu$:\n$$\nQ(\\nu) = \\frac{1}{2}(1 + \\nu^2) \\ge \\frac{1}{2} > 0\n$$\nSince $Q(\\nu)$ is strictly positive, the variation $J(u^\\varepsilon) - J(0) = \\varepsilon^2 Q(\\nu)$ is strictly positive for any $\\varepsilon \\neq 0$. This means that any small constant perturbation away from zero strictly increases the value of the cost functional. Therefore, the singular control $u_t \\equiv 0$ is not a maximizer. The sign of $Q(\\nu)$ being positive definitively eliminates $u_t \\equiv 0$ as a candidate for the optimal control; in fact, it reveals it to be a strict local minimum with respect to such perturbations.", "answer": "$$\\boxed{\\frac{1}{2}(1+\\nu^2)}$$", "id": "3003273"}, {"introduction": "The principles of optimal control extend powerfully to systems involving large populations of interacting agents, a domain captured by mean-field theory. This practice problem introduces a canonical linear-quadratic mean-field control model, where each agent's dynamics and costs are influenced by the population average. Through a clever decomposition into a system for the mean and a system for the fluctuations, you will see how this complex problem elegantly breaks down into two standard, solvable Riccati equations, showcasing a powerful problem-solving paradigm.", "problem": "Consider a scalar mean-field linear-quadratic-Gaussian control system driven by a standard Brownian motion $W_{t}$ on a filtered probability space satisfying the usual conditions, with state dynamics\n$$\n\\mathrm{d}x_{t} = \\left(a\\,x_{t} + b\\,u_{t} + \\alpha\\,m_{t}\\right)\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad x_{0}\\in\\mathbb{R},\n$$\nwhere $m_{t} := \\mathbb{E}[x_{t}]$ is the population mean, $a, \\alpha \\in \\mathbb{R}$, $b \\in \\mathbb{R}\\setminus\\{0\\}$, and $\\sigma>0$. The admissible controls $u_{t}$ are progressively measurable and square-integrable. The performance index to be minimized over all admissible controls is\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left(q\\,(x_{t}-m_{t})^{2} + \\bar{q}\\,m_{t}^{2} + r\\,u_{t}^{2}\\right)\\mathrm{d}t\\right],\n$$\nwith $q>0$, $\\bar{q}>0$, and $r>0$. Assume the standard stabilizability and detectability conditions that guarantee the existence of a unique stabilizing solution to the relevant algebraic Riccati equations.\n\nUsing the stochastic maximum principle (SMP) as the fundamental base, decompose the problem into its mean and fluctuation components and derive the coupled algebraic Riccati equations characterizing the optimal control. Then compute in closed form the two state-feedback gains $(K,\\bar{K})$ entering the optimal control law\n$$\nu_{t}^{\\star} = -K\\,(x_{t}-m_{t}) - \\bar{K}\\,m_{t},\n$$\nexpressed solely in terms of the parameters $(a,\\alpha,b,q,\\bar{q},r)$. Your final answer must be a single closed-form analytic expression for the pair $(K,\\bar{K})$. If a branch choice is required for square roots, choose the stabilizing branch that yields nonnegative Riccati solutions.", "solution": "### Step 2: Problem Decomposition\nThe key to solving this mean-field control problem is to decompose the system into two separate, simpler problems: one governing the mean behavior and one governing the fluctuations around the mean.\n\nLet $m_t = \\mathbb{E}[x_t]$ be the mean of the state process and $\\hat{x}_t = x_t - m_t$ be the fluctuation. The state is decomposed as $x_t = m_t + \\hat{x}_t$.\nSimilarly, we decompose the control $u_t$ into its mean $\\bar{u}_t = \\mathbb{E}[u_t]$ and its fluctuation $\\hat{u}_t = u_t - \\bar{u}_t$.\nBy definition, $\\mathbb{E}[\\hat{x}_t] = 0$ and $\\mathbb{E}[\\hat{u}_t] = 0$.\n\nTaking the expectation of the state SDE yields the dynamics for the mean $m_t$:\n$$\n\\mathbb{E}[\\mathrm{d}x_t] = \\mathbb{E}[(a x_t + b u_t + \\alpha m_t)\\mathrm{d}t + \\sigma \\mathrm{d}W_t]\n$$\nSince $m_t$ is deterministic (as it's an expectation over the whole probability space, which is then averaged over initial conditions drawn from a distribution with mean $m_0$; or simply, starting from a deterministic $x_0$), $\\mathrm{d}m_t = \\mathbb{E}[\\mathrm{d}x_t]$ and $\\mathbb{E}[m_t]=m_t$. The expectation of the stochastic integral is zero.\n$$\n\\mathrm{d}m_t = (a \\mathbb{E}[x_t] + b \\mathbb{E}[u_t] + \\alpha \\mathbb{E}[m_t])\\mathrm{d}t\n$$\n$$\n\\dot{m}_t = (a m_t + b \\bar{u}_t + \\alpha m_t) = ((a+\\alpha)m_t + b\\bar{u}_t)\n$$\nThis is a deterministic linear ordinary differential equation for the mean state $m_t$.\n\nSubtracting the mean dynamics from the full state dynamics gives the dynamics for the fluctuation $\\hat{x}_t$:\n$$\n\\mathrm{d}\\hat{x}_t = \\mathrm{d}x_t - \\mathrm{d}m_t = [(a x_t + b u_t + \\alpha m_t) - ((a+\\alpha)m_t + b\\bar{u}_t)]\\mathrm{d}t + \\sigma \\mathrm{d}W_t\n$$\n$$\n\\mathrm{d}\\hat{x}_t = [a(x_t-m_t) + b(u_t-\\bar{u}_t)]\\mathrm{d}t + \\sigma \\mathrm{d}W_t\n$$\n$$\n\\mathrm{d}\\hat{x}_t = (a\\hat{x}_t + b\\hat{u}_t)\\mathrm{d}t + \\sigma \\mathrm{d}W_t\n$$\nThis is a standard linear SDE for the fluctuation process $\\hat{x}_t$.\n\nNext, we decompose the cost functional $J(u)$:\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left(q\\,(x_{t}-m_{t})^{2} + \\bar{q}\\,m_{t}^{2} + r\\,u_{t}^{2}\\right)\\mathrm{d}t\\right]\n$$\nUsing $\\hat{x}_t = x_t-m_t$ and $u_t = \\bar{u}_t + \\hat{u}_t$, we analyze the term $\\mathbb{E}[u_t^2]$:\n$$\n\\mathbb{E}[u_t^2] = \\mathbb{E}[(\\bar{u}_t + \\hat{u}_t)^2] = \\mathbb{E}[\\bar{u}_t^2 + 2\\bar{u}_t\\hat{u}_t + \\hat{u}_t^2]\n$$\nSince $\\bar{u}_t$ is deterministic and $\\mathbb{E}[\\hat{u}_t] = 0$, we have $\\mathbb{E}[2\\bar{u}_t\\hat{u}_t] = 2\\bar{u}_t\\mathbb{E}[\\hat{u}_t] = 0$.\nThus, $\\mathbb{E}[u_t^2] = \\bar{u}_t^2 + \\mathbb{E}[\\hat{u}_t^2]$.\nSubstituting this back into the cost functional:\n$$\nJ(u) = \\mathbb{E}\\left[\\int_{0}^{\\infty} \\left(q\\,\\hat{x}_{t}^{2} + \\bar{q}\\,m_{t}^{2} + r\\,(\\bar{u}_{t}^{2} + \\mathbb{E}[\\hat{u}_t^2])\\right)\\mathrm{d}t\\right]\n$$\nSince $\\bar{q}m_t^2$ and $r\\bar{u}_t^2$ are deterministic, the expectation operator only acts on the terms involving fluctuations.\n$$\nJ(u) = \\int_{0}^{\\infty} (\\bar{q}\\,m_{t}^{2} + r\\,\\bar{u}_{t}^{2})\\mathrm{d}t + \\mathbb{E}\\left[\\int_{0}^{\\infty} (q\\,\\hat{x}_{t}^{2} + r\\,\\hat{u}_{t}^{2})\\mathrm{d}t\\right]\n$$\nThe total problem has now been decomposed into two independent optimal control problems:\n\n1.  **Fluctuation Problem (Stochastic LQ):** Minimize $J_{fluct}(\\hat{u}) = \\mathbb{E}\\left[\\int_{0}^{\\infty} (q\\,\\hat{x}_{t}^{2} + r\\,\\hat{u}_{t}^{2})\\mathrm{d}t\\right]$ subject to $\\mathrm{d}\\hat{x}_t = (a\\hat{x}_t + b\\hat{u}_t)\\mathrm{d}t + \\sigma\\mathrm{d}W_t$.\n2.  **Mean Problem (Deterministic LQR):** Minimize $J_{mean}(\\bar{u}) = \\int_{0}^{\\infty} (\\bar{q}\\,m_t^2 + r\\,\\bar{u}_t^2)\\mathrm{d}t$ subject to $\\dot{m}_t = (a+\\alpha)m_t + b\\bar{u}_t$.\n\nThe structure of the optimal control, $u_{t}^{\\star} = -K\\,(x_{t}-m_{t}) - \\bar{K}\\,m_{t} = -K\\,\\hat{x}_{t} - \\bar{K}\\,m_{t}$, confirms this decomposition. We have $\\hat{u}_t^\\star = -K\\hat{x}_t$ and $\\bar{u}_t^\\star = -\\bar{K}m_t$.\n\n### Step 3: Solving the Fluctuation Problem\nThis is a standard infinite-horizon LQG problem with dynamics matrix $A_1 = a$, control matrix $B_1 = b$, state-weighting matrix $Q_1 = q$, and control-weighting matrix $R_1 = r$. The optimal control is given by $\\hat{u}_t = -K\\hat{x}_t$ where the gain $K$ is $K = R_1^{-1}B_1^T P_1$. Here, $P_1$ is the unique positive semi-definite stabilizing solution to the corresponding Algebraic Riccati Equation (ARE):\n$$\nA_1^T P_1 + P_1 A_1 - P_1 B_1 R_1^{-1} B_1^T P_1 + Q_1 = 0\n$$\nSubstituting the scalar parameters:\n$$\naP_1 + P_1 a - P_1 b r^{-1} b P_1 + q = 0\n$$\n$$\n2aP_1 - \\frac{b^2}{r}P_1^2 + q = 0\n$$\nRearranging gives a quadratic equation for $P_1$:\n$$\n\\frac{b^2}{r}P_1^2 - 2aP_1 - q = 0\n$$\nThe solutions are:\n$$\nP_1 = \\frac{2a \\pm \\sqrt{4a^2 - 4(\\frac{b^2}{r})(-q)}}{2(b^2/r)} = \\frac{r}{b^2}\\left(a \\pm \\sqrt{a^2 + \\frac{qb^2}{r}}\\right)\n$$\nThe problem requires the stabilizing solution, which corresponds to picking the unique positive semi-definite root. Since $q>0$, $r>0$, we have $\\sqrt{a^2 + qb^2/r} > \\sqrt{a^2}=|a|$. To ensure $P_1 \\ge 0$, we must choose the positive sign.\n$$\nP_1 = \\frac{r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{qb^2}{r}}\\right)\n$$\nThe feedback gain $K$ is then:\n$$\nK = R_1^{-1}B_1 P_1 = r^{-1}b P_1 = \\frac{b}{r}\\left[\\frac{r}{b^2}\\left(a + \\sqrt{a^2 + \\frac{qb^2}{r}}\\right)\\right] = \\frac{1}{b}\\left(a + \\sqrt{a^2 + \\frac{qb^2}{r}}\\right)\n$$\n\n### Step 4: Solving the Mean Problem\nThis is a standard infinite-horizon deterministic LQR problem with dynamics matrix $A_2 = a+\\alpha$, control matrix $B_2 = b$, state-weighting matrix $Q_2 = \\bar{q}$, and control-weighting matrix $R_2 = r$. The optimal control is $\\bar{u}_t = -\\bar{K}m_t$, where $\\bar{K} = R_2^{-1}B_2^T P_2$ and $P_2$ is the unique positive semi-definite stabilizing solution to the ARE:\n$$\nA_2^T P_2 + P_2 A_2 - P_2 B_2 R_2^{-1} B_2^T P_2 + Q_2 = 0\n$$\nSubstituting the parameters:\n$$\n(a+\\alpha)P_2 + P_2(a+\\alpha) - P_2 b r^{-1} b P_2 + \\bar{q} = 0\n$$\n$$\n2(a+\\alpha)P_2 - \\frac{b^2}{r}P_2^2 + \\bar{q} = 0\n$$\nThis gives a quadratic equation for $P_2$:\n$$\n\\frac{b^2}{r}P_2^2 - 2(a+\\alpha)P_2 - \\bar{q} = 0\n$$\nThe solutions are:\n$$\nP_2 = \\frac{2(a+\\alpha) \\pm \\sqrt{4(a+\\alpha)^2 - 4(\\frac{b^2}{r})(-\\bar{q})}}{2(b^2/r)} = \\frac{r}{b^2}\\left((a+\\alpha) \\pm \\sqrt{(a+\\alpha)^2 + \\frac{\\bar{q}b^2}{r}}\\right)\n$$\nAgain, choosing the positive sign for the positive semi-definite stabilizing solution:\n$$\nP_2 = \\frac{r}{b^2}\\left((a+\\alpha) + \\sqrt{(a+\\alpha)^2 + \\frac{\\bar{q}b^2}{r}}\\right)\n$$\nThe feedback gain $\\bar{K}$ is:\n$$\n\\bar{K} = R_2^{-1}B_2 P_2 = r^{-1}b P_2 = \\frac{b}{r}\\left[\\frac{r}{b^2}\\left((a+\\alpha) + \\sqrt{(a+\\alpha)^2 + \\frac{\\bar{q}b^2}{r}}\\right)\\right]\n$$\n$$\n\\bar{K} = \\frac{1}{b}\\left((a+\\alpha) + \\sqrt{(a+\\alpha)^2 + \\frac{\\bar{q}b^2}{r}}\\right)\n$$\n\n### Step 5: Final Result\nThe pair of state-feedback gains $(K, \\bar{K})$ is thus determined. The problem asks for the result as a single expression. We present this as a row matrix.\n\n$K = \\frac{1}{b}\\left(a + \\sqrt{a^2 + \\frac{qb^2}{r}}\\right)$\n$\\bar{K} = \\frac{1}{b}\\left(a+\\alpha + \\sqrt{(a+\\alpha)^2 + \\frac{\\bar{q}b^2}{r}}\\right)$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{b}\\left(a + \\sqrt{a^2 + \\frac{qb^2}{r}}\\right) & \\frac{1}{b}\\left(a+\\alpha + \\sqrt{(a+\\alpha)^2 + \\frac{\\bar{q}b^2}{r}}\\right) \\end{pmatrix}}\n$$", "id": "3003259"}]}