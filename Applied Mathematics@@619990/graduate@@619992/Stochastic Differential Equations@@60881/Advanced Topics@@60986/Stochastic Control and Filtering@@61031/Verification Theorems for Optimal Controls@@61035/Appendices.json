{"hands_on_practices": [{"introduction": "The Hamilton-Jacobi-Bellman (HJB) equation is central to optimal control, but its application hinges on a critical first step: the pointwise minimization of the Hamiltonian. This exercise guides you through the fundamental conditions that ensure this minimization is well-posed and an optimal control action can be found for any state and time. By analyzing the structure of the Hamiltonian, you will explore how topological properties of the control set $\\mathcal{U}$, such as compactness or coercivity, are essential for guaranteeing the existence of a minimizing control, which is the cornerstone of any verification theorem [@problem_id:3005364].", "problem": "Consider a controlled stochastic differential equation on the finite horizon $[0,T]$ of the form\n$$\n\\mathrm{d}X_t = b(t,X_t,u_t)\\,\\mathrm{d}t + \\sigma(t,X_t,u_t)\\,\\mathrm{d}W_t, \\quad X_0 = x \\in \\mathbb{R}^d,\n$$\nwhere $W_t$ is a standard $d$-dimensional Brownian motion, $u_t$ is a control process taking values in a set $\\mathcal{U} \\subset \\mathbb{R}^m$, and the functions $b$ and $\\sigma$ satisfy standard Lipschitz continuity and linear growth conditions in $(x,u)$ that ensure existence and uniqueness of strong solutions for progressively measurable controls. The performance functional is\n$$\nJ(x;u) = \\mathbb{E}\\left[\\int_0^T \\ell(t,X_t,u_t)\\,\\mathrm{d}t + \\phi(X_T)\\right],\n$$\nwhere $\\ell$ and $\\phi$ are bounded from below and satisfy suitable measurability and continuity properties. An admissible control is any progressively measurable process $u_t$ with $u_t \\in \\mathcal{U}$ almost surely for each $t \\in [0,T]$, and such that the resulting state process $X_t$ is well-defined and $J(x;u)$ is finite.\n\nA verification theorem for the Hamilton–Jacobi–Bellman (HJB) framework asserts, under appropriate conditions, that if a candidate value function $V \\in C^{1,2}([0,T]\\times\\mathbb{R}^d)$ satisfies the HJB equation in the classical sense together with terminal condition $V(T,x)=\\phi(x)$, and if one can construct a measurable minimizing selector $(t,x) \\mapsto u^*(t,x)\\in \\mathcal{U}$ that attains the pointwise infimum associated with the Hamiltonian $H$, then the feedback control $\\hat{u}_t := u^*(t,X_t)$ is optimal and the value function is $V(t,x)$.\n\nIn this setting, assumptions on the admissible control set $\\mathcal{U}$ (such as compactness) and on the dependence in $u$ of the data $(b,\\sigma,\\ell)$ (such as coercivity and lower semicontinuity in $u$) are often imposed to ensure the existence of minimizers for the Hamiltonian and the measurability of selectors.\n\nWhich of the following statements about admissible control sets $\\mathcal{U}$ and the role of compactness or coercivity in $u$ in verification theorems is/are correct?\n\nA. If $\\mathcal{U}$ is compact and, for each $(t,x)$, the mappings $u \\mapsto b(t,x,u)$, $u \\mapsto \\sigma(t,x,u)$, and $u \\mapsto \\ell(t,x,u)$ are continuous, then the pointwise infimum in the Hamiltonian $H$ is attained for every $(t,x)$, and measurable selection theorems can be invoked to produce a measurable minimizing selector $(t,x) \\mapsto u^*(t,x)$; hence compactness directly supports the construction needed in verification.\n\nB. If $\\mathcal{U}$ is closed (not necessarily compact) and the map $u \\mapsto \\ell(t,x,u) + p \\cdot b(t,x,u) + \\tfrac{1}{2}\\mathrm{Tr}\\big(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\big)$ is lower semicontinuous and coercive in $u$ uniformly in $(t,x,p,M)$, then the pointwise infimum in the Hamiltonian is attained in $\\mathcal{U}$, preventing minimizing sequences from escaping to infinity; thus coercivity can be used in lieu of compactness to verify existence of minimizers.\n\nC. When $\\sigma$ depends on $u$, compactness of $\\mathcal{U}$ is irrelevant to verification because the diffusion term does not influence the attainment of the infimum in the Hamiltonian; only the drift term matters for minimization.\n\nD. If the value function $V$ is twice continuously differentiable in $x$, then the pointwise infimum in the Hamiltonian is automatically attained even when $\\mathcal{U}$ is unbounded and there is no coercivity, because the second derivatives in $x$ regularize the optimization in $u$.\n\nE. Compactness of $\\mathcal{U}$ is needed solely for uniqueness of solutions to the HJB equation; it has no bearing on the existence of optimal controls or on the construction of measurable minimizing selectors.\n\nSelect all correct options. Your reasoning should begin from the core definitions of admissible controls and the verification framework and proceed through the implications for existence and measurability of minimizers without invoking shortcut formulas or unstated assumptions. Clearly justify why compactness or coercivity in $u$ is often assumed and how these properties interact with continuity or lower semicontinuity in $u$ to support verification theorems.", "solution": "The problem statement describes a standard stochastic optimal control problem in continuous time over a finite horizon $[0,T]$. The goal is to minimize a cost functional $J(x;u)$ by choosing an admissible control process $u_t$. The problem asks to evaluate statements regarding the assumptions on the control set $\\mathcal{U}$ and the data $(b, \\sigma, \\ell)$ that are used in verification theorems based on the Hamilton-Jacobi-Bellman (HJB) equation.\n\nThe HJB equation for the value function $V(t,x)$ is a partial differential equation given by:\n$$\n\\frac{\\partial V}{\\partial t}(t,x) + H(t, x, DV(t,x), D^2V(t,x)) = 0, \\quad \\text{for } (t,x) \\in [0,T) \\times \\mathbb{R}^d\n$$\nwith the terminal condition $V(T,x) = \\phi(x)$. The operator $DV$ denotes the gradient with respect to $x$, and $D^2V$ denotes the Hessian matrix. The Hamiltonian, $H$, is defined by a minimization over the control set $\\mathcal{U}$:\n$$\nH(t, x, p, M) = \\inf_{u \\in \\mathcal{U}} \\left\\{ \\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right) \\right\\}.\n$$\nA cornerstone of a verification theorem is the ability to construct an optimal feedback control $\\hat{u}_t = u^*(t, X_t)$ from a measurable function $(t,x) \\mapsto u^*(t,x)$ that attains the infimum in the Hamiltonian for each $(t,x)$. That is, $u^*(t,x)$ must be a minimizer of the expression in the curly braces, where $p=DV(t,x)$ and $M=D^2V(t,x)$. The existence and measurability of such a $u^*$ are therefore critical.\n\nWe now evaluate each option.\n\nA. If $\\mathcal{U}$ is compact and, for each $(t,x)$, the mappings $u \\mapsto b(t,x,u)$, $u \\mapsto \\sigma(t,x,u)$, and $u \\mapsto \\ell(t,x,u)$ are continuous, then the pointwise infimum in the Hamiltonian $H$ is attained for every $(t,x)$, and measurable selection theorems can be invoked to produce a measurable minimizing selector $(t,x) \\mapsto u^*(t,x)$; hence compactness directly supports the construction needed in verification.\n\nThis statement is **Correct**. For any fixed $(t,x)$ and for the corresponding gradient $p=DV(t,x)$ and Hessian $M=D^2V(t,x)$, we consider the function to be minimized over $u \\in \\mathcal{U}$:\n$$\nf(u) = \\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right).\n$$\nThe assumption that $b$, $\\sigma$, and $\\ell$ are continuous functions of $u$ implies that $f(u)$ is also a continuous function of $u$. The Weierstrass Extreme Value Theorem states that a continuous real-valued function on a non-empty compact set attains its infimum (i.e., a minimum exists). Since $\\mathcal{U}$ is assumed to be compact, for each $(t,x)$, there exists at least one $u^*(t,x) \\in \\mathcal{U}$ that minimizes $f(u)$. Furthermore, standard measurable selection theorems (e.g., the Kuratowski and Ryll-Nardzewski selection theorem) require certain topological properties of the control set (like being a Polish space, which any compact subset of $\\mathbb{R}^m$ is) and measurability/continuity properties of the function being optimized. The conditions stated (continuity in $u$ and implicit measurability in $(t,x)$) are the standard ingredients for applying such theorems to guarantee the existence of a *measurable* selector $(t,x) \\mapsto u^*(t,x)$. Thus, compactness of $\\mathcal{U}$ is a cornerstone assumption that ensures both the existence of a minimizer and the ability to construct a measurable one.\n\nB. If $\\mathcal{U}$ is closed (not necessarily compact) and the map $u \\mapsto \\ell(t,x,u) + p \\cdot b(t,x,u) + \\tfrac{1}{2}\\mathrm{Tr}\\big(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\big)$ is lower semicontinuous and coercive in $u$ uniformly in $(t,x,p,M)$, then the pointwise infimum in the Hamiltonian is attained in $\\mathcal{U}$, preventing minimizing sequences from escaping to infinity; thus coercivity can be used in lieu of compactness to verify existence of minimizers.\n\nThis statement is **Correct**. This describes a standard alternative to the compactness assumption. A function $f(u)$ is coercive on $\\mathcal{U} \\subseteq \\mathbb{R}^m$ if $f(u) \\to \\infty$ as $\\|u\\| \\to \\infty$ for $u \\in \\mathcal{U}$. A fundamental result in optimization theory states that a lower semicontinuous (LSC) and coercive function on a non-empty closed subset of $\\mathbb{R}^m$ attains its infimum. The reasoning is as follows: let $\\{u_n\\}_{n \\in \\mathbb{N}}$ be a minimizing sequence in $\\mathcal{U}$. Because the function is coercive, the sequence $\\{u_n\\}$ must be bounded, otherwise the function values would tend to infinity, contradicting that it is a minimizing sequence. By the Bolzano-Weierstrass theorem, this bounded sequence has a convergent subsequence, say $u_{n_k} \\to u_0$. Since $\\mathcal{U}$ is closed, the limit point $u_0$ is in $\\mathcal{U}$. By the definition of lower semicontinuity, the function value at the limit point is less than or equal to the limit inferior of the function values along the sequence, which is the infimum. Thus, the infimum is attained at $u_0$. This demonstrates that coercivity serves the same purpose as compactness in ensuring a minimizing sequence remains in a bounded region, thereby guaranteeing the existence of a limit point where the minimum is achieved.\n\nC. When $\\sigma$ depends on $u$, compactness of $\\mathcal{U}$ is irrelevant to verification because the diffusion term does not influence the attainment of the infimum in the Hamiltonian; only the drift term matters for minimization.\n\nThis statement is **Incorrect**. The Hamiltonian involves minimizing the entire expression $\\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right)$ over $u \\in \\mathcal{U}$. If the diffusion coefficient $\\sigma$ depends on the control $u$, then the term $\\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right)$ is generally a non-constant function of $u$. The minimization problem must account for how $u$ affects all three components: the running cost $\\ell$, the drift $b$, and the diffusion $\\sigma$. To claim that the diffusion term is irrelevant to the minimization is fundamentally wrong. For instance, in financial applications, controlling portfolio volatility (related to $\\sigma$) is a primary objective. The statement is false.\n\nD. If the value function $V$ is twice continuously differentiable in $x$, then the pointwise infimum in the Hamiltonian is automatically attained even when $\\mathcal{U}$ is unbounded and there is no coercivity, because the second derivatives in $x$ regularize the optimization in $u$.\n\nThis statement is **Incorrect**. The differentiability of the value function $V$ determines the coefficients $p = DV(t,x)$ and $M = D^2V(t,x)$ in the Hamiltonian optimization problem. However, the smoothness of $V$ does not alter the fundamental nature of the optimization with respect to $u$. If the function $f(u) = \\ell(t,x,u) + p \\cdot b(t,x,u) + \\frac{1}{2}\\mathrm{Tr}\\left(\\sigma(t,x,u)\\sigma(t,x,u)^\\top M\\right)$ does not possess properties that guarantee a minimum is attained on $\\mathcal{U}$ (e.g., continuous on a compact set, or LSC and coercive on a closed set), then a minimum may not exist. For a simple counterexample, let $\\ell=0$, $b(u)=-u^2$, $\\sigma=0$, and $\\mathcal{U}=\\mathbb{R}$. The expression to minimize is $-p u^2$. If $p>0$, this function is unbounded below on $\\mathbb{R}$, and its infimum of $-\\infty$ is never attained. The fact that $p$ might originate from a $C^2$ function $V$ is irrelevant to the non-existence of a minimizer for this sub-problem.\n\nE. Compactness of $\\mathcal{U}$ is needed solely for uniqueness of solutions to the HJB equation; it has no bearing on the existence of optimal controls or on the construction of measurable minimizing selectors.\n\nThis statement is **Incorrect**. It is incorrect on multiple counts. First, the uniqueness of solutions to the HJB equation is a complex topic, typically addressed in the framework of viscosity solutions, where comparison principles are the main tool. While properties of the Hamiltonian matter, compactness of $\\mathcal{U}$ is not the primary or sole condition for uniqueness. Second, as established in the analysis of option A, compactness of $\\mathcal{U}$ (combined with continuity of the data in $u$) is a standard and direct way to prove the existence of a pointwise minimizer for the Hamiltonian. This minimizer is the foundation for constructing an optimal control. Third, as also discussed for option A, the topological properties of a compact set are crucial for applying measurable selection theorems. Therefore, compactness has a direct and fundamental bearing on both the existence of optimal controls and the construction of measurable selectors. The statement is a complete misrepresentation of the role of compactness.\n\nFinal summary: statements A and B correctly describe the roles of compactness and coercivity, respectively, in ensuring the existence of a minimizer for the Hamiltonian, a critical step in verification theorems. Statements C, D, and E are fundamentally flawed.", "answer": "$$\\boxed{AB}$$", "id": "3005364"}, {"introduction": "While knowing an optimal control exists is crucial, being able to uniquely identify and characterize it is even more powerful. This practice delves into the important role of convexity, particularly in common settings like control-affine systems with quadratic costs, which renders the Hamiltonian a convex function of the control variable $u$. You will learn how the positive definiteness of the Hamiltonian's Hessian guarantees a unique minimizing control and how this unique control is characterized by a variational inequality, providing a concrete formula or condition for the optimal feedback law [@problem_id:3005407].", "problem": "Consider a controlled stochastic differential equation driven by a single standard Brownian motion on a finite horizon, with state dimension $n$ and control dimension $m$, of the form\n$$\n\\mathrm{d}X_t = \\big(b(t,X_t) + B(t,X_t) u_t\\big)\\,\\mathrm{d}t + \\big(\\sigma(t,X_t) + \\Sigma(t,X_t) u_t\\big)\\,\\mathrm{d}W_t,\n$$\nwhere $b:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}^n$, $B:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}^{n\\times m}$, $\\sigma:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}^n$, and $\\Sigma:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}^{n\\times m}$ are measurable, locally bounded, and sufficiently smooth to ensure existence of strong solutions. Let $V\\in C^{1,2}\\big([0,T]\\times\\mathbb{R}^n\\big)$ be a candidate value function for the associated optimal control problem with running cost\n$$\nf(t,x,u) = g(t,x) + \\ell(t,x)^\\top u + \\tfrac{1}{2}\\,u^\\top R(t,x)\\,u,\n$$\nwhere $g:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}$, $\\ell:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}^m$, and $R:\\,[0,T]\\times\\mathbb{R}^n\\to\\mathbb{R}^{m\\times m}$ is symmetric and positive semidefinite. Define the generator applied to $V$ under control $u$ by\n$$\n\\mathcal{L}^u V(t,x) = V_t(t,x) + \\big(b(t,x)+B(t,x)u\\big)^\\top \\nabla V(t,x) + \\tfrac{1}{2}\\,\\big(\\sigma(t,x)+\\Sigma(t,x)u\\big)^\\top \\nabla^2 V(t,x)\\,\\big(\\sigma(t,x)+\\Sigma(t,x)u\\big),\n$$\nand the Hamiltonian appearing in the Hamilton-Jacobi-Bellman (HJB) equation by\n$$\nH(t,x,u) = \\mathcal{L}^u V(t,x) + f(t,x,u).\n$$\nAssume the admissible control set $U\\subset\\mathbb{R}^m$ is nonempty, closed, and convex, and $V$ satisfies all regularity required by verification theorems. For each $(t,x)$, consider the minimizing selector $u^*(t,x)\\in U$ that attains the minimum of $H(t,x,u)$ over $u\\in U$.\n\nWhich statement correctly explains sufficient conditions under which the convexity of $f$ and the quadratic form induced by $\\mathcal{L}^u V$ in $u$ imply existence and uniqueness of the minimizing selector $u^*(t,x)$, together with its correct variational characterization?\n\nA. If $R(t,x)$ is positive definite and $U$ is convex and closed, then for any $\\Sigma(t,x)$ and $\\nabla^2 V(t,x)$ the Hamiltonian $H(t,x,u)$ is strictly convex in $u$ and admits a unique minimizer given by the unconstrained critical point $u^*(t,x) = -R(t,x)^{-1}\\big(B(t,x)^\\top \\nabla V(t,x) + \\ell(t,x)\\big)$.\n\nB. If the symmetric matrix\n$$\nS(t,x) \\coloneqq R(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\Sigma(t,x)\n$$\nis positive definite for each $(t,x)$, then $H(t,x,u)$ is strictly convex in $u$, and for any nonempty, closed, convex set $U$ there exists a unique minimizing selector $u^*(t,x)\\in U$ characterized by the variational inequality\n$$\n\\Big\\langle S(t,x)\\,u^*(t,x) + B(t,x)^\\top \\nabla V(t,x) + \\ell(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\sigma(t,x),\\, v - u^*(t,x)\\Big\\rangle \\ge 0,\\quad \\forall v\\in U.\n$$\n\nC. Convexity of $f(t,x,u)$ alone guarantees existence and uniqueness of a minimizer in any convex $U$, independently of the term $\\mathcal{L}^u V(t,x)$.\n\nD. Strict convexity of $H(t,x,u)$ is unnecessary; compactness of $U$ and continuity of $H(t,x,u)$ are sufficient to guarantee uniqueness of the minimizer in $U$ for each $(t,x)$.", "solution": "The user wants me to validate and solve a problem concerning the minimization of a Hamiltonian in the context of stochastic optimal control.\n\nFirst, I shall analyze the problem statement. The problem is set in the standard framework of stochastic optimal control using the Hamilton-Jacobi-Bellman (HJB) equation. All provided definitions—the controlled stochastic differential equation (SDE), the running cost functional, the generator $\\mathcal{L}^u$, and the Hamiltonian $H(t,x,u)$—are textbook formulations. The mathematical spaces and regularity assumptions ($C^{1,2}$, measurable, locally bounded, sufficiently smooth, nonempty closed convex set $U$) are appropriate for the application of verification theorems. The problem is well-posed, scientifically grounded in control theory and stochastic analysis, and contains sufficient information to proceed. The problem is therefore valid.\n\nThe core of the problem is to find the minimizer $u^*(t,x)$ of the Hamiltonian $H(t,x,u)$ over the admissible control set $U$ for a fixed state-time pair $(t,x)$. The Hamiltonian is given by:\n$$\nH(t,x,u) = \\mathcal{L}^u V(t,x) + f(t,x,u)\n$$\nTo analyze its dependence on the control variable $u \\in \\mathbb{R}^m$, we expand the expression. For notational simplicity, we will temporarily omit the arguments $(t,x)$.\nThe cost function is:\n$$\nf(u) = g + \\ell^\\top u + \\tfrac{1}{2}\\,u^\\top R u\n$$\nThe generator is:\n$$\n\\mathcal{L}^u V = V_t + (b+Bu)^\\top \\nabla V + \\tfrac{1}{2}\\,(\\sigma+\\Sigma u)^\\top \\nabla^2 V (\\sigma+\\Sigma u)\n$$\nLet us expand the terms in $\\mathcal{L}^u V$ that depend on $u$:\nThe linear term in $u$ from the drift is $(Bu)^\\top \\nabla V = u^\\top B^\\top \\nabla V$.\nThe diffusion term's expansion yields terms up to second order in $u$:\n$$\n\\tfrac{1}{2}\\,(\\sigma+\\Sigma u)^\\top \\nabla^2 V (\\sigma+\\Sigma u) = \\tfrac{1}{2}\\,(\\sigma^\\top + u^\\top \\Sigma^\\top) \\nabla^2 V (\\sigma + \\Sigma u)\n$$\n$$\n= \\tfrac{1}{2}\\,\\left(\\sigma^\\top\\nabla^2 V\\sigma + \\sigma^\\top\\nabla^2 V\\Sigma u + u^\\top\\Sigma^\\top\\nabla^2 V\\sigma + u^\\top\\Sigma^\\top\\nabla^2 V\\Sigma u\\right)\n$$\nSince $\\nabla^2 V$ is a symmetric matrix, the scalar quantity $u^\\top\\Sigma^\\top\\nabla^2 V\\sigma$ is equal to its transpose, $(\\sigma^\\top\\nabla^2 V\\Sigma u)^\\top = u^\\top(\\sigma^\\top\\nabla^2 V\\Sigma)^\\top = u^\\top\\Sigma^\\top(\\nabla^2 V)^\\top\\sigma = u^\\top\\Sigma^\\top\\nabla^2 V\\sigma$. Thus, the two cross-terms are equal. The expansion becomes:\n$$\n= \\tfrac{1}{2}\\,\\sigma^\\top\\nabla^2 V\\sigma + u^\\top\\Sigma^\\top\\nabla^2 V\\sigma + \\tfrac{1}{2}\\,u^\\top(\\Sigma^\\top\\nabla^2 V\\Sigma)u\n$$\nNow, we combine all terms to assemble the Hamiltonian $H(t,x,u)$ as a function of $u$:\n$$\nH(u) = (V_t + b^\\top \\nabla V + \\tfrac{1}{2}\\,\\sigma^\\top\\nabla^2 V\\sigma + g) + (u^\\top B^\\top \\nabla V + u^\\top\\Sigma^\\top\\nabla^2 V\\sigma + \\ell^\\top u) + (\\tfrac{1}{2}\\,u^\\top(\\Sigma^\\top\\nabla^2 V\\Sigma)u + \\tfrac{1}{2}\\,u^\\top R u)\n$$\nThis is a quadratic function in $u$. We can write it in the standard form $H(u) = C + L^\\top u + \\tfrac{1}{2}\\,u^\\top S u$, where:\n- The term independent of $u$ is $C(t,x) = V_t + b^\\top \\nabla V + \\tfrac{1}{2}\\,\\sigma^\\top\\nabla^2 V\\sigma + g$.\n- The linear term is $L(t,x)^\\top u$, where the coefficient vector is $L(t,x) = B(t,x)^\\top \\nabla V(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\sigma(t,x) + \\ell(t,x)$.\n- The quadratic term is $\\tfrac{1}{2}\\,u^\\top S(t,x) u$, where the matrix is $S(t,x) = R(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\Sigma(t,x)$. Since $R$ is symmetric and $\\nabla^2 V$ is symmetric, $S$ is also symmetric.\n\nThe problem of finding $u^*(t,x) = \\arg\\min_{u \\in U} H(t,x,u)$ is a quadratic programming problem.\nFor existence and uniqueness of the minimizer, we require the objective function $H(t,x,u)$ to be strictly convex in $u$ and the constraint set $U$ to be nonempty, closed, and convex. The problem states that $U$ has these properties.\nThe strict convexity of $H(t,x,u)$ with respect to $u$ is guaranteed if its Hessian matrix, $\\nabla_u^2 H = S(t,x)$, is positive definite.\n\nIf $H(t,x,u)$ is strictly convex in $u$, a unique minimizer $u^*(t,x) \\in U$ exists. This minimizer is characterized by the first-order necessary and sufficient condition for optimality for a convex function over a convex set, which is the variational inequality:\n$$\n\\langle \\nabla_u H(t,x,u^*), v - u^* \\rangle \\ge 0, \\quad \\forall v \\in U\n$$\nThe gradient of $H$ with respect to $u$ is:\n$$\n\\nabla_u H(t,x,u) = L(t,x) + S(t,x)u\n$$\nSubstituting the expressions for $L$ and $S$, we get:\n$$\n\\nabla_u H(t,x,u) = \\big(B^\\top \\nabla V + \\Sigma^\\top \\nabla^2 V \\sigma + \\ell\\big) + (R + \\Sigma^\\top\\nabla^2 V\\Sigma)u\n$$\nTherefore, the variational inequality characterizing $u^*$ is:\n$$\n\\Big\\langle \\big(R(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\Sigma(t,x)\\big)u^*(t,x) + B(t,x)^\\top \\nabla V(t,x) + \\ell(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\sigma(t,x),\\, v - u^*(t,x)\\Big\\rangle \\ge 0\n$$\nfor all $v \\in U$. This can be rewritten using the definition of $S(t,x)$:\n$$\n\\Big\\langle S(t,x)\\,u^*(t,x) + B(t,x)^\\top \\nabla V(t,x) + \\ell(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\sigma(t,x),\\, v - u^*(t,x)\\Big\\rangle \\ge 0\n$$\n\nNow we evaluate the given options.\n\nA. If $R(t,x)$ is positive definite and $U$ is convex and closed, then for any $\\Sigma(t,x)$ and $\\nabla^2 V(t,x)$ the Hamiltonian $H(t,x,u)$ is strictly convex in $u$ and admits a unique minimizer given by the unconstrained critical point $u^*(t,x) = -R(t,x)^{-1}\\big(B(t,x)^\\top \\nabla V(t,x) + \\ell(t,x)\\big)$.\nThis statement is incorrect for multiple reasons. First, the strict convexity of $H$ depends on the positive definiteness of $S(t,x) = R(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\Sigma(t,x)$. Even if $R(t,x)$ is positive definite, the second term can be negative if $\\nabla^2 V(t,x)$ is not positive semidefinite, potentially making $S(t,x)$ not positive definite. Second, the provided formula for $u^*(t,x)$ incorrectly omits all terms involving $\\Sigma$ and $\\nabla^2 V$. Third, it presents an unconstrained minimizer, which is only valid if it happens to lie within the constraint set $U$. The general solution must account for the constraints.\n**Incorrect**.\n\nB. If the symmetric matrix $S(t,x) \\coloneqq R(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\Sigma(t,x)$ is positive definite for each $(t,x)$, then $H(t,x,u)$ is strictly convex in $u$, and for any nonempty, closed, convex set $U$ there exists a unique minimizing selector $u^*(t,x)\\in U$ characterized by the variational inequality\n$$\n\\Big\\langle S(t,x)\\,u^*(t,x) + B(t,x)^\\top \\nabla V(t,x) + \\ell(t,x) + \\Sigma(t,x)^\\top \\nabla^2 V(t,x)\\,\\sigma(t,x),\\, v - u^*(t,x)\\Big\\rangle \\ge 0,\\quad \\forall v\\in U.\n$$\nThis statement is fully consistent with our derivation. The condition that $S(t,x)$ is positive definite is precisely the condition for strict convexity of the quadratic Hamiltonian $H(t,x,u)$ in $u$. For a strictly convex function on a nonempty, closed, convex set $U$, a unique minimizer exists. The provided variational inequality is the correct first-order condition that characterizes this minimizer, correctly identifying the gradient term $\\nabla_u H = S u + L$.\n**Correct**.\n\nC. Convexity of $f(t,x,u)$ alone guarantees existence and uniqueness of a minimizer in any convex $U$, independently of the term $\\mathcal{L}^u V(t,x)$.\nThis is incorrect. The function to be minimized is the total Hamiltonian $H = \\mathcal{L}^u V + f$. The convexity of $f$ (which is guaranteed by $R \\ge 0$) is not sufficient. The term $\\mathcal{L}^u V$ contributes a quadratic part $\\tfrac{1}{2}\\,u^\\top (\\Sigma^\\top \\nabla^2 V \\Sigma) u$, which can be non-convex if $\\nabla^2 V$ is not positive semidefinite. A sum of a convex function and a non-convex function is not generally convex, and thus uniqueness of the minimizer is not guaranteed.\n**Incorrect**.\n\nD. Strict convexity of $H(t,x,u)$ is unnecessary; compactness of $U$ and continuity of $H(t,x,u)$ are sufficient to guarantee uniqueness of the minimizer in $U$ for each $(t,x)$.\nThis is incorrect. By the Weierstrass Extreme Value Theorem, a continuous function (which $H$ is) on a compact set (which $U$ would be) is guaranteed to *attain* a minimum, thus guaranteeing *existence*. However, it does not guarantee *uniqueness*. For example, the non-convex function $h(u) = \\cos(u)$ on the compact set $U = [0, 4\\pi]$ has multiple minimizers. Strict convexity is the standard sufficient condition for uniqueness.\n**Incorrect**.", "answer": "$$\\boxed{B}$$", "id": "3005407"}, {"introduction": "Many practical control problems are set over an infinite time horizon, where costs and the value function may be unbounded. This practice addresses the technical challenges of applying a verification theorem in such a setting, where the standard arguments require careful justification. You will investigate how to use weight functions and impose a Foster-Lyapunov drift condition on the system's generator to rigorously establish the integrability of the cost and the vanishing of boundary terms at infinity, thereby making the verification argument sound [@problem_id:3005362].", "problem": "Consider the controlled Stochastic Differential Equation (SDE) on $\\mathbb{R}^d$ given by\n$$\n\\mathrm{d}X_t = b\\big(X_t,a_t\\big)\\,\\mathrm{d}t + \\sigma\\big(X_t,a_t\\big)\\,\\mathrm{d}W_t,\n$$\nwhere $W_t$ is a $d$-dimensional standard Brownian motion, $a_t$ is an admissible control process taking values in a compact metric action set $A$, and $b$ and $\\sigma$ satisfy standard conditions ensuring existence and uniqueness of strong solutions (global Lipschitz and linear growth are sufficient and may be assumed). Let $\\beta>0$ be a discount factor and consider the infinite-horizon discounted cost functional\n$$\nJ(x,a_\\cdot) := \\mathbb{E}_x\\left[\\int_0^\\infty e^{-\\beta t}\\,g\\big(X_t,a_t\\big)\\,\\mathrm{d}t\\right],\n$$\nwith running cost $g:\\mathbb{R}^d\\times A\\to [0,\\infty)$ that may be unbounded in the state variable. Let $V:\\mathbb{R}^d\\to\\mathbb{R}$ denote the value function defined by\n$$\nV(x):=\\inf_{a_\\cdot} J(x,a_\\cdot).\n$$\nSuppose $V$ is a sufficiently smooth candidate for the dynamic programming equation associated with this control problem. The verification theorem for optimal controls typically proceeds by applying Itô’s formula to $e^{-\\beta t}V(X_t)$, integrating, and passing to the limit $t\\to\\infty$. When $g$ is unbounded, one must ensure integrability of all terms and vanishing of boundary terms by working in appropriately weighted function spaces and by imposing suitable growth conditions on $V$, on the coefficients $b$ and $\\sigma$, and on the running cost $g$.\n\nWhich of the following options correctly describes a set of conditions and the associated argument that handle unbounded costs in this infinite-horizon verification setting via weighted norms and growth conditions on $V$ and the coefficients? Select the best answer.\n\nA. There exists a twice continuously differentiable weight function $w:\\mathbb{R}^d\\to [1,\\infty)$ such that for some constants $C_g,C_V,C_\\nabla,C_{D^2},K_b,K_\\sigma,k_0,k_1>0$ and all $(x,a)\\in\\mathbb{R}^d\\times A$,\n- $g(x,a)\\le C_g\\,w(x)$,\n- $|V(x)|\\le C_V\\,w(x)$, $\\|\\nabla V(x)\\|\\le C_\\nabla\\,w(x)$, and $\\|D^2V(x)\\|\\le C_{D^2}\\,w(x)$ (that is, $V\\in C_w^2$ in the sense of weighted norms),\n- $|b(x,a)|\\le K_b\\,(1+|x|)$ and $\\|\\sigma(x,a)\\|\\le K_\\sigma\\,(1+|x|)$,\n- a Foster–Lyapunov drift condition holds uniformly in $a$, namely $\\sup_{a\\in A}\\big(L^a w\\big)(x)\\le k_0 - k_1\\,w(x)$, where $L^a$ is the controlled generator $L^a\\phi(x):=b(x,a)\\cdot\\nabla\\phi(x)+\\tfrac{1}{2}\\mathrm{Tr}\\big(\\sigma(x,a)\\sigma(x,a)^\\top D^2\\phi(x)\\big)$.\nThen the drift condition and $\\beta>0$ imply $\\mathbb{E}_x\\!\\left[\\int_0^\\infty e^{-\\beta t}w(X_t)\\,\\mathrm{d}t\\right]<\\infty$ and $e^{-\\beta T}\\,\\mathbb{E}_x[w(X_T)]\\to 0$ as $T\\to\\infty$, which, together with the weighted bounds on $V$, $\\nabla V$, and $D^2V$, yield integrability of $L^{a_t}V(X_t)$ and vanishing of the boundary term $e^{-\\beta T}\\,\\mathbb{E}_x[V(X_T)]$. Applying Itô’s formula to $e^{-\\beta t}V(X_t)$, taking expectations, and using the dynamic programming inequality derived from the Hamilton–Jacobi–Bellman (HJB) structure, one obtains $V(x)\\le J(x,a_\\cdot)$ for any admissible control $a_\\cdot$, with equality and optimality for a measurable selector $a^*(x)$ achieving the pointwise infimum.\n\nB. The discount factor $\\beta>0$ alone ensures integrability and the vanishing of boundary terms for any measurable running cost $g$ and any measurable coefficients $b$ and $\\sigma$, so no growth or weight assumptions are needed; one may directly apply Itô’s formula to $e^{-\\beta t}V(X_t)$ and conclude verification without further conditions.\n\nC. If the coefficients $b$ and $\\sigma$ and the running cost $g$ are uniformly bounded, then standard verification arguments using Itô’s formula apply; therefore, to handle unbounded costs in general, it suffices to localize and treat the problem as if $g$ were bounded, without introducing weight functions or growth controls.\n\nD. Choose a positive weight function $w$ that decays to zero at infinity and rescale $V$ so that $\\sup_{x\\in\\mathbb{R}^d}|V(x)|/w(x)<\\infty$; with $\\beta>0$ this guarantees $e^{-\\beta T}\\mathbb{E}_x[V(X_T)]\\to 0$ and renders all terms integrable, so no conditions on $\\nabla V$, $D^2V$, or the generator applied to $w$ are required.\n\nE. Use an exponential weight $w(x)=\\exp(\\alpha|x|^2)$ for some $\\alpha>0$ and require a positive drift condition $\\inf_{a\\in A}(L^a w)(x)\\ge c\\,w(x)$ with $c>0$; since $w$ grows fast, this will dominate any polynomially growing $g$ and ensure that the boundary term and the generator terms vanish in the verification argument.", "solution": "The user wants me to validate and solve a problem concerning verification theorems in stochastic optimal control for infinite-horizon problems with unbounded costs.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   The controlled process is a Stochastic Differential Equation (SDE) on $\\mathbb{R}^d$:\n    $$ \\mathrm{d}X_t = b\\big(X_t,a_t\\big)\\,\\mathrm{d}t + \\sigma\\big(X_t,a_t\\big)\\,\\mathrm{d}W_t $$\n-   $W_t$ is a $d$-dimensional standard Brownian motion.\n-   $a_t$ is an admissible control process with values in a compact metric action set $A$.\n-   $b$ and $\\sigma$ satisfy standard conditions for existence and uniqueness of strong solutions (e.g., global Lipschitz continuity and linear growth are assumed).\n-   The cost functional is an infinite-horizon discounted cost, with discount factor $\\beta > 0$:\n    $$ J(x,a_\\cdot) := \\mathbb{E}_x\\left[\\int_0^\\infty e^{-\\beta t}\\,g\\big(X_t,a_t\\big)\\,\\mathrm{d}t\\right] $$\n-   The running cost function is $g:\\mathbb{R}^d\\times A\\to [0,\\infty)$, and it may be unbounded in the state variable $x$.\n-   The value function is defined as $V(x):=\\inf_{a_\\cdot} J(x,a_\\cdot)$.\n-   $V$ is assumed to be a sufficiently smooth candidate for the dynamic programming equation.\n-   The question is to identify the correct set of conditions and arguments, using weighted norms and growth conditions, to handle the unboundedness of the cost function $g$ in the verification theorem.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly rooted in the mathematical theory of stochastic optimal control. All concepts—SDEs, Itô's formula, value functions, Hamilton-Jacobi-Bellman (HJB) equations, verification theorems, and Foster-Lyapunov conditions—are standard and rigorously defined within this field. The specific issue of handling unbounded costs and coefficients is a classic and non-trivial technical challenge, and the use of weighted spaces is a primary method for addressing it. The problem is a sound mathematical question.\n-   **Well-Posed:** The problem asks to select the correct description of a mathematical argument from a set of options. It has a clear structure and a well-defined objective.\n-   **Objective:** The language is formal, precise, and technical, appropriate for the subject matter. There is no subjectivity or ambiguity in the core statement.\n-   **Completeness:** The problem provides sufficient context to understand the question being asked. It defines the mathematical setting and the specific technical challenge (unbounded costs). It correctly frames the solution strategy (verification theorem via Itô's formula) and the tools to be considered (weighted norms, growth conditions). No essential information is missing.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is a well-posed, scientifically sound question within the field of stochastic control theory. I will proceed with the solution.\n\n### Solution Derivation\n\nThe core of a verification theorem is to show that a candidate function $V(x)$, which is a sufficiently smooth solution to the Hamilton-Jacobi-Bellman (HJB) equation, is indeed the value function. The HJB equation for this problem is:\n$$ \\beta V(x) = \\inf_{a \\in A} \\left\\{ L^a V(x) + g(x,a) \\right\\} $$\nwhere $L^a$ is the generator of the process $X_t$ for a fixed control $a$:\n$$ L^a \\phi(x) := b(x,a)\\cdot\\nabla\\phi(x)+\\frac{1}{2}\\mathrm{Tr}\\big(\\sigma(x,a)\\sigma(x,a)^\\top D^2\\phi(x)\\big) $$\n\nA function $V$ that solves the HJB equation satisfies the dynamic programming inequality for any control $a \\in A$:\n$$ \\beta V(x) - L^a V(x) - g(x,a) \\le 0 $$\nwith equality holding for an optimal control policy $a^*(x)$ that achieves the infimum.\n\nThe verification proof proceeds by applying Itô's formula to the process $e^{-\\beta t}V(X_t)$:\n$$ \\mathrm{d}\\left(e^{-\\beta t} V(X_t)\\right) = e^{-\\beta t}\\left(L^{a_t}V(X_t) - \\beta V(X_t)\\right)\\mathrm{d}t + e^{-\\beta t}\\nabla V(X_t)^\\top\\sigma(X_t,a_t)\\,\\mathrm{d}W_t $$\nIntegrating from $t=0$ to $t=T$ and taking the expectation $\\mathbb{E}_x$ (starting at $X_0=x$):\n$$ \\mathbb{E}_x\\left[e^{-\\beta T}V(X_T)\\right] - V(x) = \\mathbb{E}_x\\left[\\int_0^T e^{-\\beta t}\\left(L^{a_t}V(X_t) - \\beta V(X_t)\\right)\\mathrm{d}t\\right] $$\nThe expectation of the stochastic integral term is zero, provided it is a true martingale, which requires integrability conditions on $\\nabla V$ and $\\sigma$. Rearranging gives:\n$$ V(x) = \\mathbb{E}_x\\left[\\int_0^T e^{-\\beta t}\\left(\\beta V(X_t) - L^{a_t}V(X_t)\\right)\\mathrm{d}t\\right] + \\mathbb{E}_x\\left[e^{-\\beta T}V(X_T)\\right] $$\nUsing the dynamic programming inequality $\\beta V(X_t) - L^{a_t}V(X_t) \\le g(X_t,a_t)$, we get:\n$$ V(x) \\le \\mathbb{E}_x\\left[\\int_0^T e^{-\\beta t}g(X_t,a_t)\\,\\mathrm{d}t\\right] + \\mathbb{E}_x\\left[e^{-\\beta T}V(X_T)\\right] $$\nThe key challenge when $g$ (and thus $V$) is unbounded is to justify taking the limit $T\\to\\infty$. We must ensure:\n1.  All integrals are well-defined and finite.\n2.  The boundary term vanishes: $\\lim_{T\\to\\infty}\\mathbb{E}_x\\left[e^{-\\beta T}V(X_T)\\right] = 0$.\n\nThis is precisely where weighted norms and Lyapunov conditions are essential. Let $w:\\mathbb{R}^d\\to [1,\\infty)$ be a weight function that grows sufficiently fast at infinity. The standard approach imposes the following conditions:\n\n-   **Growth control on problem data:** The running cost $g$ and the candidate value function $V$ (along with its derivatives) are controlled by the weight function $w$. For instance, for constants $C_g, C_V, C_\\nabla, C_{D^2}$, we require $|g(x,a)| \\le C_g w(x)$, $|V(x)| \\le C_V w(x)$, $\\|\\nabla V(x)\\| \\le C_\\nabla w(x)$, and $\\|D^2V(x)\\| \\le C_{D^2} w(x)$. These conditions ensure that the terms inside the integrals and the Itô formula are controlled by $w(X_t)$.\n\n-   **Control on the dynamics via a Lyapunov condition:** To ensure integrability of $w(X_t)$ and the vanishing of the boundary term, we need to control the evolution of $w$ along the process trajectories. The standard condition is a Foster-Lyapunov drift condition, which provides a form of stability. It states that the generator applied to the weight function must drift towards the origin in a weighted sense, uniformly over all controls:\n    $$ \\sup_{a\\in A}\\big(L^a w\\big)(x) \\le k_0 - k_1 w(x) $$\n    for some constants $k_0 \\ge 0$ and $k_1>0$.\n\nLet's analyze the consequences of this drift condition. Let $y(t) = \\mathbb{E}_x[w(X_t)]$. Using Itô's formula for $w(X_t)$, taking expectations, and differentiating with respect to $t$ gives $\\frac{\\mathrm{d}}{\\mathrm{d}t} \\mathbb{E}_x[w(X_t)] = \\mathbb{E}_x[L^{a_t} w(X_t)]$.\n$$ \\frac{\\mathrm{d}y(t)}{\\mathrm{d}t} = \\mathbb{E}_x[L^{a_t}w(X_t)] \\le \\mathbb{E}_x[k_0 - k_1 w(X_t)] = k_0 - k_1 y(t) $$\nThis is a differential inequality. By Gronwall's inequality (or comparison principle), $y(t) \\le y(0)e^{-k_1 t} + \\frac{k_0}{k_1}(1-e^{-k_1 t})$. Since $y(0)=w(x)$, we have:\n$$ \\mathbb{E}_x[w(X_t)] \\le w(x)e^{-k_1 t} + \\frac{k_0}{k_1} $$\nThis shows that the expected value of the weight function is bounded and decays exponentially towards a constant.\n\nNow we can check the two requirements:\n1.  **Vanishing Boundary Term:** We need $\\lim_{T\\to\\infty}\\mathbb{E}_x\\left[e^{-\\beta T}V(X_T)\\right] = 0$. Using the growth bounds $|V(x)| \\le C_V w(x)$:\n    $$ \\left|\\mathbb{E}_x\\left[e^{-\\beta T}V(X_T)\\right]\\right| \\le e^{-\\beta T}\\mathbb{E}_x\\left[|V(X_T)|\\right] \\le C_V e^{-\\beta T}\\mathbb{E}_x\\left[w(X_T)\\right] $$\n    $$ \\le C_V e^{-\\beta T}\\left(w(x)e^{-k_1 T} + \\frac{k_0}{k_1}\\right) = C_V w(x)e^{-(\\beta+k_1)T} + C_V\\frac{k_0}{k_1}e^{-\\beta T} $$\n    Since $\\beta>0$ and $k_1>0$, both terms approach $0$ as $T\\to\\infty$. The boundary term vanishes.\n\n2.  **Integrability:** We need to know that $\\mathbb{E}_x\\left[\\int_0^\\infty e^{-\\beta t}|g(X_t,a_t)|\\,\\mathrm{d}t\\right] < \\infty$. Using the growth bound on $g$:\n    $$ \\mathbb{E}_x\\left[\\int_0^\\infty e^{-\\beta t}|g(X_t,a_t)|\\,\\mathrm{d}t\\right] \\le C_g \\int_0^\\infty e^{-\\beta t}\\mathbb{E}_x[w(X_t)]\\,\\mathrm{d}t $$\n    $$ \\le C_g \\int_0^\\infty e^{-\\beta t}\\left(w(x)e^{-k_1 t} + \\frac{k_0}{k_1}\\right)\\mathrm{d}t = C_g \\left( w(x)\\int_0^\\infty e^{-(\\beta+k_1)t}\\mathrm{d}t + \\frac{k_0}{k_1}\\int_0^\\infty e^{-\\beta t}\\mathrm{d}t \\right) $$\n    $$ = C_g \\left( \\frac{w(x)}{\\beta+k_1} + \\frac{k_0}{k_1\\beta} \\right) < \\infty $$\nThe integral is finite. A similar argument guarantees the finiteness of the other terms, justifying the application of Itô's formula and Fubini's theorem.\n\nWith these conditions, we can take the limit $T\\to\\infty$ in the inequality to get $V(x) \\le J(x,a_\\cdot)$ for any admissible control. If we use an optimal control policy $a^*_t = a^*(X_t)$ which achieves equality in the HJB equation, the same argument yields $V(x) = J(x,a^*_\\cdot)$. This completes the verification.\n\n### Option-by-Option Analysis\n\n**A. This option presents a set of conditions and an argument that closely match the derivation above.** It requires:\n-   A weight function $w(x) \\ge 1$.\n-   Growth bounds on $g$, $V$, $\\nabla V$, and $D^2V$ in terms of $w$.\n-   A Foster-Lyapunov drift condition $\\sup_{a\\in A}(L^a w)(x) \\le k_0 - k_1 w(x)$ with $k_1>0$.\n-   It correctly concludes that these conditions imply the finiteness of the weighted integral $\\mathbb{E}_x[\\int_0^\\infty e^{-\\beta t}w(X_t)\\,\\mathrm{d}t]$ and the vanishing of the boundary term $\\lim_{T\\to\\infty} e^{-\\beta T}\\,\\mathbb{E}_x[w(X_T)]$, which in turn ensures the vanishing of $\\lim_{T\\to\\infty} e^{-\\beta T}\\,\\mathbb{E}_x[V(X_T)]$. This is the standard, correct argument. The linear growth condition on $b$ and $\\sigma$ is also mentioned, which is required for the generator $L^a$ to be well-defined on $w$ and for general well-posedness of the SDE.\n**Verdict: Correct.**\n\n**B. This option claims that the discount factor $\\beta>0$ is sufficient by itself.** This is false. A simple counterexample is a 1-dimensional process with unstable dynamics, e.g., $\\mathrm{d}X_t=X_t\\,\\mathrm{d}t$ with $X_0=x>0$, so $X_t=xe^t$. If we have a running cost $g(x)=|x|$ and a discount factor $\\beta \\in (0,1]$, the cost integral is $\\int_0^\\infty e^{-\\beta t} (xe^t)\\,\\mathrm{d}t = x \\int_0^\\infty e^{(1-\\beta)t}\\,\\mathrm{d}t$, which diverges. The dynamics of the process, controlled by $b$ and $\\sigma$, are crucial.\n**Verdict: Incorrect.**\n\n**C. This option suggests that localization is sufficient to handle unbounded costs without explicit growth controls.** Localization using stopping times is a valid mathematical tool, but it does not eliminate the need for growth conditions. To take the limit as the localization radius goes to infinity, one must control the behavior of the process far from the origin. This inevitably requires some form of growth condition on the coefficients and cost, and typically a Lyapunov condition to ensure the process does not escape to infinity \"too quickly.\" The claim that one can proceed \"without introducing weight functions or growth controls\" is misleading.\n**Verdict: Incorrect.**\n\n**D. This option proposes using a weight function $w$ that decays to zero at infinity.** This is fundamentally wrong. A weight function is used to bound an unbounded function from above (e.g., $|V(x)| \\le C w(x)$). If $w(x)\\to 0$ as $|x|\\to\\infty$, this would imply $V(x)\\to 0$, which contradicts the premise that the cost $g$ (and thus the value function $V$) is unbounded. We need a weight function that grows at infinity, not decays.\n**Verdict: Incorrect.**\n\n**E. This option suggests a positive drift condition, $\\inf_{a\\in A}(L^a w)(x)\\ge c\\,w(x)$ with $c>0$.** This describes an instability or transience condition. It implies that $\\mathbb{E}_x[w(X_t)]$ grows exponentially. This is the opposite of what is needed. For the verification argument to work, we need to control the growth of expectations and ensure terms vanish, which is achieved by a negative drift (stability) condition as described in option A. A positive drift would lead to diverging integrals and non-vanishing boundary terms.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3005362"}]}