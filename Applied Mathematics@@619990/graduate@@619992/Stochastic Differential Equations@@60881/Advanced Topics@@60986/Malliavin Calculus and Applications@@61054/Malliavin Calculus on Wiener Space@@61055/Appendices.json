{"hands_on_practices": [{"introduction": "Before applying the Malliavin derivative, it is essential to master the mechanics of its computation for non-trivial functionals. This practice focuses on computing both the first and second derivatives of an integral functional of Brownian motion, reinforcing the use of the product and chain rules in this new context [@problem_id:2986339]. By calculating the norm of the second derivative, you will also directly verify the functional's membership in a key Sobolev space of random variables, connecting the abstract definition of these spaces to a concrete calculation.", "problem": "Let $\\{B_{t}\\}_{t \\in [0,T]}$ be a standard Brownian motion on the classical Wiener space, and let $H=L^{2}([0,T])$ be the Cameron–Martin space. Consider the Wiener functional\n$$\nF \\;=\\; \\int_{0}^{T} B_{t}^{2}\\,dt.\n$$\nUsing only foundational results in Malliavin calculus on Wiener space, namely:\n- the definition of the Malliavin derivative $D$ on smooth cylindrical functionals generated by the isonormal Gaussian family $\\{B_{t}\\}_{t \\in [0,T]}$,\n- the chain rule and the product rule for Malliavin derivatives,\n- the identity $D_{r}B_{t}=\\mathbf{1}_{\\{r \\le t\\}}$,\nderive from first principles the first and second Malliavin derivatives $D F \\in L^{2}(\\Omega;H)$ and $D^{2}F \\in L^{2}(\\Omega;H^{\\otimes 2})$ as explicit kernels on $[0,T]$ and $[0,T]^{2}$, respectively. Compute the exact closed-form expression of the Hilbert–Schmidt norm $\\|D^{2}F\\|_{H^{\\otimes 2}}$ and use it, together with Gaussian moment bounds, to determine whether $F \\in \\mathbb{D}^{2,p}$ for every finite $p \\in [1,\\infty)$. Provide a rigorous justification of each step, starting from the definitions.\n\nYour final answer must be the exact closed-form expression for $\\|D^{2}F\\|_{H^{\\otimes 2}}$. No rounding is required.", "solution": "We work on the classical Wiener space with Brownian motion $\\{B_{t}\\}_{t \\in [0,T]}$ and Cameron–Martin space $H=L^{2}([0,T])$. For smooth cylindrical functionals of the form $G=g(B_{t_{1}},\\dots,B_{t_{n}})$ with $g$ smooth, the Malliavin derivative is defined by\n$$\nD_{r}G \\;=\\; \\sum_{i=1}^{n} \\partial_{i}g(B_{t_{1}},\\dots,B_{t_{n}})\\,D_{r}B_{t_{i}},\n$$\nand $D_{r}B_{t}=\\mathbf{1}_{\\{r \\le t\\}}$. The chain rule and product rule apply, and the operator extends by closure to the Sobolev space $\\mathbb{D}^{1,2}$ and higher orders.\n\nStep $1$: compute $D F$. We first write\n$$\nF \\;=\\; \\int_{0}^{T} B_{t}^{2}\\,dt.\n$$\nApproximating the integral by Riemann sums and using closability, or directly using the differentiation under the integral sign justified by Fubini–Tonelli and the product rule, we obtain\n$$\nD_{r}F \\;=\\; \\int_{0}^{T} D_{r}\\!\\left(B_{t}^{2}\\right)\\,dt \\;=\\; \\int_{0}^{T} 2 B_{t}\\,D_{r}B_{t}\\,dt \\;=\\; \\int_{0}^{T} 2 B_{t}\\,\\mathbf{1}_{\\{r \\le t\\}}\\,dt \\;=\\; 2\\int_{r}^{T} B_{t}\\,dt,\n$$\nfor every $r \\in [0,T]$. Thus $D F$ is the $H$-valued random element with kernel\n$$\nD_{r}F \\;=\\; 2\\int_{r}^{T} B_{t}\\,dt,\\qquad r \\in [0,T].\n$$\n\nStep $2$: compute $D^{2}F$. Differentiating once more and using linearity and the fact that $D_{s}B_{t}=\\mathbf{1}_{\\{s \\le t\\}}$, we have for $(r,s)\\in[0,T]^{2}$,\n$$\nD_{s}D_{r}F \\;=\\; 2\\int_{r}^{T} D_{s}B_{t}\\,dt \\;=\\; 2\\int_{r}^{T} \\mathbf{1}_{\\{s \\le t\\}}\\,dt \\;=\\; 2\\int_{\\max\\{r,s\\}}^{T} 1\\,dt \\;=\\; 2\\bigl(T-\\max\\{r,s\\}\\bigr).\n$$\nEquivalently,\n$$\nD^{2}F(r,s) \\;=\\; 2\\,\\bigl(T-\\max\\{r,s\\}\\bigr)\\,\\mathbf{1}_{[0,T]}(r)\\,\\mathbf{1}_{[0,T]}(s).\n$$\nIn particular, $D^{2}F$ is a deterministic symmetric kernel on $[0,T]^{2}$.\n\nStep $3$: compute $\\|D^{2}F\\|_{H^{\\otimes 2}}$. Since $H=L^{2}([0,T])$, the tensor space $H^{\\otimes 2}$ is isometrically isomorphic to $L^{2}([0,T]^{2})$ with the norm\n$$\n\\|D^{2}F\\|_{H^{\\otimes 2}}^{2} \\;=\\; \\int_{0}^{T}\\int_{0}^{T} \\bigl(D^{2}F(r,s)\\bigr)^{2}\\,dr\\,ds.\n$$\nHence\n$$\n\\|D^{2}F\\|_{H^{\\otimes 2}}^{2} \\;=\\; \\int_{0}^{T}\\int_{0}^{T} 4\\bigl(T-\\max\\{r,s\\}\\bigr)^{2}\\,dr\\,ds.\n$$\nUsing the symmetry of the integrand and the decomposition of $[0,T]^{2}$ into the regions $\\{r \\le s\\}$ and $\\{s \\le r\\}$, we obtain\n$$\n\\|D^{2}F\\|_{H^{\\otimes 2}}^{2} \\;=\\; 2 \\int_{0}^{T}\\int_{0}^{s} 4\\bigl(T-s\\bigr)^{2}\\,dr\\,ds \\;=\\; 8\\int_{0}^{T} s\\,\\bigl(T-s\\bigr)^{2}\\,ds.\n$$\nCompute the last integral:\n$$\n\\int_{0}^{T} s\\,(T-s)^{2}\\,ds \\;=\\; \\int_{0}^{T} \\bigl(T^{2}s - 2T s^{2} + s^{3}\\bigr)\\,ds \\;=\\; \\frac{T^{4}}{2} - \\frac{2T^{4}}{3} + \\frac{T^{4}}{4} \\;=\\; \\frac{T^{4}}{12}.\n$$\nTherefore,\n$$\n\\|D^{2}F\\|_{H^{\\otimes 2}}^{2} \\;=\\; 8 \\cdot \\frac{T^{4}}{12} \\;=\\; \\frac{2}{3}\\,T^{4},\n$$\nand hence\n$$\n\\|D^{2}F\\|_{H^{\\otimes 2}} \\;=\\; \\sqrt{\\frac{2}{3}}\\,T^{2}.\n$$\n\nStep $4$: determine membership of $F$ in $\\mathbb{D}^{2,p}$. By definition,\n$$\nF \\in \\mathbb{D}^{2,p} \\quad\\Longleftrightarrow\\quad \\mathbb{E}\\bigl[|F|^{p}\\bigr] < \\infty,\\ \\ \\mathbb{E}\\bigl[\\|D F\\|_{H}^{p}\\bigr] < \\infty,\\ \\ \\mathbb{E}\\bigl[\\|D^{2}F\\|_{H^{\\otimes 2}}^{p}\\bigr] < \\infty.\n$$\nWe verify each condition for every finite $p \\in [1,\\infty)$.\n\n- For $\\mathbb{E}[|F|^{p}]$: since $F=\\int_{0}^{T} B_{t}^{2}\\,dt$ and $t \\mapsto B_{t}^{2}$ is nonnegative, Hölder’s inequality yields\n$$\n\\left(\\int_{0}^{T} B_{t}^{2}\\,dt\\right)^{p} \\;\\le\\; T^{p-1}\\int_{0}^{T} |B_{t}|^{2p}\\,dt.\n$$\nTaking expectations and using that Gaussian moments are finite and satisfy $\\mathbb{E}[|B_{t}|^{2p}] = c_{p}\\,t^{p}$ for some constant $c_{p}\\in(0,\\infty)$, we get\n$$\n\\mathbb{E}[|F|^{p}] \\;\\le\\; T^{p-1}\\int_{0}^{T} c_{p}\\,t^{p}\\,dt \\;=\\; \\frac{c_{p}}{p+1}\\,T^{2p} \\;<\\; \\infty.\n$$\n\n- For $\\mathbb{E}[\\|D F\\|_{H}^{p}]$: first compute the second moment to see finiteness and structure. We have\n$$\n\\|D F\\|_{H}^{2} \\;=\\; \\int_{0}^{T} \\left(2\\int_{r}^{T} B_{t}\\,dt\\right)^{2} dr \\;=\\; 4\\int_{0}^{T}\\int_{r}^{T}\\int_{r}^{T} B_{t}B_{u}\\,dt\\,du\\,dr.\n$$\nBy Fubini–Tonelli and the identity $\\int_{0}^{T} \\mathbf{1}_{\\{r \\le t\\}}\\mathbf{1}_{\\{r \\le u\\}}\\,dr = t \\wedge u$, this equals\n$$\n\\|D F\\|_{H}^{2} \\;=\\; 4\\int_{0}^{T}\\int_{0}^{T} (t \\wedge u)\\,B_{t}B_{u}\\,dt\\,du.\n$$\nTaking expectations and using $\\mathbb{E}[B_{t}B_{u}] = t \\wedge u$,\n$$\n\\mathbb{E}\\bigl[\\|D F\\|_{H}^{2}\\bigr] \\;=\\; 4\\int_{0}^{T}\\int_{0}^{T} (t \\wedge u)^{2}\\,dt\\,du \\;=\\; \\frac{2}{3}\\,T^{4} \\;<\\; \\infty.\n$$\nMoreover, $\\|D F\\|_{H}^{2}$ is a finite linear combination of a constant and a double Wiener integral (it lies in the direct sum of the zeroth and second Wiener chaoses), hence it has finite moments of all orders by hypercontractivity on Wiener chaos and standard Gaussian moment bounds. Therefore $\\mathbb{E}[\\|D F\\|_{H}^{p}]<\\infty$ for every finite $p$.\n\n- For $\\mathbb{E}[\\|D^{2}F\\|_{H^{\\otimes 2}}^{p}]$: since $D^{2}F$ is deterministic with $\\|D^{2}F\\|_{H^{\\otimes 2}}=\\sqrt{\\frac{2}{3}}\\,T^{2}$, it follows that\n$$\n\\mathbb{E}\\bigl[\\|D^{2}F\\|_{H^{\\otimes 2}}^{p}\\bigr] \\;=\\; \\left(\\sqrt{\\frac{2}{3}}\\,T^{2}\\right)^{p} \\;<\\; \\infty.\n$$\n\nCombining the three bullets, we conclude that $F \\in \\mathbb{D}^{2,p}$ for every finite $p \\in [1,\\infty)$.\n\nTherefore, the requested explicit kernel and norm are\n$$\nD^{2}F(r,s) \\;=\\; 2\\,\\bigl(T-\\max\\{r,s\\}\\bigr)\\,\\mathbf{1}_{[0,T]}(r)\\,\\mathbf{1}_{[0,T]}(s),\\qquad\n\\|D^{2}F\\|_{H^{\\otimes 2}} \\;=\\; \\sqrt{\\frac{2}{3}}\\,T^{2}.\n$$\nThe final answer to provide is the exact value of the norm $\\|D^{2}F\\|_{H^{\\otimes 2}}$.", "answer": "$$\\boxed{\\sqrt{\\frac{2}{3}}\\,T^{2}}$$", "id": "2986339"}, {"introduction": "One of the most celebrated applications of Malliavin calculus is the Clark-Ocone formula, which provides an explicit expression for the integrand in the martingale representation of a random variable. This exercise guides you through deriving this integrand for a functional resembling a European call option payoff [@problem_id:3000571]. Because the target functional is not smooth, you will employ the crucial technique of smooth approximation, demonstrating how the theory can be robustly extended to handle a wide class of important, non-differentiable cases.", "problem": "Let $\\{W_{t}\\}_{t \\in [0,T]}$ be a standard Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\in [0,T]},\\mathbb{P})$ satisfying the usual conditions. Consider the terminal functional $F = \\max(W_{T},0)$.\n\n1. Construct a family $\\{f_{\\epsilon}\\}_{\\epsilon>0}$ of smooth functions $f_{\\epsilon}:\\mathbb{R}\\to\\mathbb{R}$ such that $f_{\\epsilon}(x) \\to x^{+}$ pointwise as $\\epsilon \\to 0$, and $f_{\\epsilon}$ has a bounded and continuous first derivative for each fixed $\\epsilon>0$. Justify that $f_{\\epsilon}(W_{T}) \\to F$ in $L^{2}(\\Omega)$ as $\\epsilon \\to 0$.\n\n2. Using foundational definitions from the Malliavin calculus on the Wiener space (specifically, the Malliavin derivative of functionals of $W_{T}$ and the chain rule), compute the Malliavin derivative $D_{t}\\big(f_{\\epsilon}(W_{T})\\big)$ for $t \\in [0,T]$.\n\n3. Use independence of Brownian increments and standard properties of conditional expectation to express $\\mathbb{E}\\big[D_{t}\\big(f_{\\epsilon}(W_{T})\\big)\\,|\\,\\mathcal{F}_{t}\\big]$ in terms of $W_{t}$ and the law of $W_{T}-W_{t}$. Then analyze the limit as $\\epsilon \\to 0$ to obtain the predictable integrand $g_{t}$ that appears in the martingale representation of $F$ with respect to $\\{W_{t}\\}$.\n\nYour final task is to report the limiting analytic expression for $g_{t}$ obtained in step 3 (valid for $t \\in [0,T)$). The final answer must be a single closed-form expression.", "solution": "The problem requires finding the predictable integrand $g_{t}$ in the Clark-Ocone martingale representation of the functional $F = \\max(W_{T},0) = W_{T}^{+}$. The Clark-Ocone formula states that for a suitable functional $F$, its Itô representation is given by $F = \\mathbb{E}[F] + \\int_{0}^{T} g_{t} dW_{t}$, where the integrand is $g_{t} = \\mathbb{E}[D_{t}F | \\mathcal{F}_{t}]$. The problem guides us through a three-step procedure involving a smooth approximation of $F$.\n\nThe function $x \\mapsto \\max(x,0)$ is not differentiable, so we cannot directly apply the chain rule of Malliavin calculus. We proceed as directed.\n\n1.  Construction of a smooth approximation and $L^{2}$ convergence.\nThe function to be approximated is $x^{+} = \\max(x,0)$. We can express this as $x^{+} = \\frac{1}{2}(x + |x|)$. The non-smoothness comes from the absolute value function $|x| = \\sqrt{x^{2}}$. A standard way to smoothen this is to introduce a small positive parameter $\\epsilon$.\nWe define the family of functions $\\{f_{\\epsilon}\\}_{\\epsilon>0}$ by\n$$f_{\\epsilon}(x) = \\frac{1}{2}(x + \\sqrt{x^{2} + \\epsilon^{2}})$$\nFor any fixed $\\epsilon > 0$, the term under the square root is strictly positive, so $f_{\\epsilon}$ is infinitely differentiable ($C^{\\infty}$) on $\\mathbb{R}$. As $\\epsilon \\to 0$, we have $\\sqrt{x^{2} + \\epsilon^{2}} \\to \\sqrt{x^{2}} = |x|$, so $f_{\\epsilon}(x) \\to \\frac{1}{2}(x + |x|) = x^{+}$ for every $x \\in \\mathbb{R}$. This shows pointwise convergence.\nThe first derivative of $f_{\\epsilon}$ is:\n$$f_{\\epsilon}'(x) = \\frac{d}{dx} \\left[ \\frac{1}{2}(x + \\sqrt{x^{2} + \\epsilon^{2}}) \\right] = \\frac{1}{2}\\left(1 + \\frac{2x}{2\\sqrt{x^{2} + \\epsilon^{2}}}\\right) = \\frac{1}{2}\\left(1 + \\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}\\right)$$\nFor $\\epsilon > 0$, $f_{\\epsilon}'(x)$ is a continuous function of $x$. To check if it is bounded, we analyze the term $\\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}$. Its absolute value is $\\left|\\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}\\right| = \\frac{|x|}{\\sqrt{x^{2} + \\epsilon^{2}}} \\le \\frac{|x|}{\\sqrt{x^{2}}} = 1$ for $x \\ne 0$. The inequality is strict for all $x$. Thus, $-1 < \\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}} < 1$, which implies $0 < 1 + \\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}} < 2$. Therefore, $0 < f_{\\epsilon}'(x) < 1$. The derivative is continuous and bounded for each $\\epsilon > 0$.\n\nTo show that $f_{\\epsilon}(W_{T}) \\to F$ in $L^{2}(\\Omega)$, we must show $\\mathbb{E}\\left[|f_{\\epsilon}(W_{T}) - W_{T}^{+}|^{2}\\right] \\to 0$ as $\\epsilon \\to 0$. Let's examine the difference $|f_{\\epsilon}(x) - x^{+}|$:\n$$|f_{\\epsilon}(x) - x^{+}| = \\left|\\frac{1}{2}(x + \\sqrt{x^{2} + \\epsilon^{2}}) - \\frac{1}{2}(x + |x|)\\right| = \\frac{1}{2}|\\sqrt{x^{2} + \\epsilon^{2}} - |x||$$\nMultiplying by the conjugate, we get:\n$$\\frac{1}{2} \\left| \\frac{(\\sqrt{x^{2} + \\epsilon^{2}} - |x|)(\\sqrt{x^{2} + \\epsilon^{2}} + |x|)}{\\sqrt{x^{2} + \\epsilon^{2}} + |x|} \\right| = \\frac{1}{2} \\frac{|x^{2} + \\epsilon^{2} - x^{2}|}{\\sqrt{x^{2} + \\epsilon^{2}} + |x|} = \\frac{\\epsilon^{2}}{2(\\sqrt{x^{2} + \\epsilon^{2}} + |x|)}$$\nSince $\\sqrt{x^{2} + \\epsilon^{2}} \\ge \\sqrt{\\epsilon^{2}} = \\epsilon$ and $|x| \\ge 0$, the denominator is at least $\\epsilon$.\n$$|f_{\\epsilon}(x) - x^{+}| \\le \\frac{\\epsilon^{2}}{2\\epsilon} = \\frac{\\epsilon}{2}$$\nThis bound is uniform in $x$. Thus, applied to $W_{T}$, we have $|f_{\\epsilon}(W_{T}) - W_{T}^{+}| \\le \\frac{\\epsilon}{2}$ for all $\\omega \\in \\Omega$.\nThe $L^{2}$ norm of the difference is then bounded by:\n$$\\mathbb{E}\\left[|f_{\\epsilon}(W_{T}) - W_{T}^{+}|^{2}\\right] \\le \\mathbb{E}\\left[\\left(\\frac{\\epsilon}{2}\\right)^{2}\\right] = \\frac{\\epsilon^{2}}{4}$$\nAs $\\epsilon \\to 0$, $\\frac{\\epsilon^{2}}{4} \\to 0$, which proves that $f_{\\epsilon}(W_{T}) \\to W_{T}^{+}$ in $L^{2}(\\Omega)$.\n\n2.  Computation of the Malliavin derivative.\nThe Malliavin derivative of a functional of the form $f(W_{T})$, where $f$ is continuously differentiable with a bounded derivative, is given by the chain rule: $D_{t}(f(W_{T})) = f'(W_{T}) D_{t}W_{T}$. The Malliavin derivative of $W_{T} = \\int_{0}^{T} 1 \\, dW_{s}$ is $D_{t}W_{T} = 1$ for $t \\in [0,T]$.\nApplying this to our approximation $F_{\\epsilon} = f_{\\epsilon}(W_{T})$, we get:\n$$D_{t}(f_{\\epsilon}(W_{T})) = f_{\\epsilon}'(W_{T})$$\nfor $t \\in [0,T]$. Substituting the expression for $f_{\\epsilon}'(x)$ from Step 1:\n$$D_{t}(f_{\\epsilon}(W_{T})) = \\frac{1}{2}\\left(1 + \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}}\\right)$$\n\n3.  Conditional expectation and limiting expression.\nThe integrand in the Clark-Ocone representation for $F$ is $g_{t} = \\lim_{\\epsilon \\to 0} \\mathbb{E}[D_{t}(f_{\\epsilon}(W_{T})) | \\mathcal{F}_{t}]$. Let's first compute the conditional expectation for fixed $\\epsilon$:\n$$g_{t}^{\\epsilon} = \\mathbb{E}[D_{t}(f_{\\epsilon}(W_{T})) | \\mathcal{F}_{t}] = \\mathbb{E}\\left[\\frac{1}{2}\\left(1 + \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}}\\right) \\bigg| \\mathcal{F}_{t}\\right]$$\nBy linearity of conditional expectation:\n$$g_{t}^{\\epsilon} = \\frac{1}{2} + \\frac{1}{2}\\mathbb{E}\\left[\\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}} \\bigg| \\mathcal{F}_{t}\\right]$$\nThe random variable inside the expectation, $h_{\\epsilon}(W_{T}) = \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}}$, is bounded in absolute value by $1$. As $\\epsilon \\to 0$, $h_{\\epsilon}(x) \\to \\text{sgn}(x)$ for $x \\ne 0$. Since $\\mathbb{P}(W_{T}=0)=0$, this convergence happens almost surely. By the bounded convergence theorem for conditional expectations, we can interchange the limit and the expectation:\n$$g_{t} = \\lim_{\\epsilon \\to 0} g_{t}^{\\epsilon} = \\frac{1}{2} + \\frac{1}{2}\\mathbb{E}\\left[\\lim_{\\epsilon \\to 0} \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}} \\bigg| \\mathcal{F}_{t}\\right] = \\frac{1}{2}\\left(1 + \\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}]\\right)$$\nNow we compute $\\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}]$. Note that $\\text{sgn}(x) = \\mathbf{1}_{x>0} - \\mathbf{1}_{x<0}$.\n$$\\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}] = \\mathbb{E}[\\mathbf{1}_{W_{T}>0} | \\mathcal{F}_{t}] - \\mathbb{E}[\\mathbf{1}_{W_{T}<0} | \\mathcal{F}_{t}] = \\mathbb{P}(W_{T}>0 | \\mathcal{F}_{t}) - \\mathbb{P}(W_{T}<0 | \\mathcal{F}_{t})$$\nWe decompose $W_{T}$ as $W_{T} = W_{t} + (W_{T} - W_{t})$. Given $\\mathcal{F}_{t}$, $W_{t}$ is a known value, and the increment $W_{T} - W_{t}$ is independent of $\\mathcal{F}_{t}$ and follows a normal distribution with mean $0$ and variance $T-t$. So, $W_{T} - W_{t} \\sim N(0, T-t)$.\nWe have, for $t < T$:\n$$\\mathbb{P}(W_{T} > 0 | \\mathcal{F}_{t}) = \\mathbb{P}(W_{t} + (W_{T} - W_{t}) > 0 | \\mathcal{F}_{t}) = \\mathbb{P}(W_{T} - W_{t} > -W_{t})$$\nLet $Z \\sim N(0,1)$ be a standard normal variable. Then $W_{T} - W_{t}$ has the same distribution as $\\sqrt{T-t} Z$.\n$$\\mathbb{P}(\\sqrt{T-t}Z > -W_{t}) = \\mathbb{P}\\left(Z > -\\frac{W_{t}}{\\sqrt{T-t}}\\right)$$\nLet $\\Phi(\\cdot)$ be the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{x} \\exp(-\\frac{y^{2}}{2}) dy$.\nThe probability is $1 - \\Phi\\left(-\\frac{W_{t}}{\\sqrt{T-t}}\\right)$. Using the symmetry property $\\Phi(-z) = 1 - \\Phi(z)$, we get:\n$$\\mathbb{P}(W_{T} > 0 | \\mathcal{F}_{t}) = \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)$$\nSimilarly, $\\mathbb{P}(W_{T} < 0 | \\mathcal{F}_{t}) = \\mathbb{P}(Z < -\\frac{W_{t}}{\\sqrt{T-t}}) = \\Phi(-\\frac{W_{t}}{\\sqrt{T-t}}) = 1 - \\Phi(\\frac{W_{t}}{\\sqrt{T-t}})$.\nTherefore,\n$$\\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}] = \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right) - \\left(1 - \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)\\right) = 2\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right) - 1$$\nSubstituting this back into the expression for $g_{t}$:\n$$g_{t} = \\frac{1}{2}\\left(1 + \\left(2\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right) - 1\\right)\\right) = \\frac{1}{2}\\left(2\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)\\right) = \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)$$\nThe expression is valid for $t \\in [0,T)$.\n\nThe final result for the predictable integrand is the CDF of the standard normal distribution evaluated at $\\frac{W_{t}}{\\sqrt{T-t}}$.", "answer": "$$\\boxed{\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)}$$", "id": "3000571"}, {"introduction": "The Malliavin derivative $D$ has a dual operator, the Skorokhod integral $\\delta$, which extends the concept of stochastic integration to non-adapted, or \"anticipating,\" integrands. This practice provides a quintessential example of such an integral, where the integrand at time $t$ depends on the future value of the Brownian motion [@problem_id:2986329]. By computing this integral directly from its definition and relating it to other types of stochastic integrals, you will gain a concrete understanding of this powerful generalization and its departure from the classical Itô theory.", "problem": "Fix a time horizon $T>0$ and consider the classical Wiener space $(\\Omega,\\mathcal{F},\\mathbb{P})$ endowed with the canonical filtration generated by a standard Brownian motion $(B_t)_{t\\in[0,T]}$ with $B_0=0$. Let $H:=L^2([0,T])$ be the Cameron–Martin space and write $W(h):=\\int_0^T h(t)\\,dB_t$ for the Wiener integral of a deterministic $h\\in H$. For a smooth cylindrical functional $F=f\\big(W(h_1),\\dots,W(h_n)\\big)$ with $f\\in C_b^\\infty(\\mathbb{R}^n)$ and $h_i\\in H$, the Malliavin derivative $D F$ is the $H$-valued random variable defined by $D_t F=\\sum_{i=1}^n \\partial_i f\\big(W(h_1),\\dots,W(h_n)\\big)\\,h_i(t)$. The Skorokhod integral $\\delta(u)$ of a process $u\\in L^2(\\Omega;H)$ is defined (when it exists) by the duality relation $\\mathbb{E}[F\\,\\delta(u)]=\\mathbb{E}[\\langle D F,u\\rangle_H]$ for all such $F$, where $\\langle \\cdot,\\cdot\\rangle_H$ denotes the inner product in $H$. It is a standard fact that for deterministic $h\\in H$, one has $\\delta(h)=W(h)$.\n  \nDefine the anticipating integrand $u=(u_t)_{t\\in[0,T]}$ by $u_t:=B_T$ for all $t\\in[0,T]$. Starting only from the definitions above and basic Gaussian moment identities for $B_T$, perform the following:\n  \n1. Prove that $u\\in\\mathrm{Dom}(\\delta)$, the domain of the Skorokhod integral.\n2. Compute $\\delta(u)$ explicitly as an element of $L^2(\\Omega)$.\n3. Compute $\\mathbb{E}[\\delta(u)]$ and $\\mathrm{Var}(\\delta(u))$.\n4. Using the definition of the Russo–Vallois forward integral $\\int_0^T u_t\\,d^{-}B_t$ as the limit in probability of forward Riemann sums $\\sum_{k} u_{t_k}\\big(B_{t_{k+1}}-B_{t_k}\\big)$ over partitions of $[0,T]$ with mesh going to $0$, compute $\\int_0^T u_t\\,d^{-}B_t$ for this $u$ and relate it to $\\delta(u)$ through the Malliavin derivative $D_t u_t$.\n  \nProvide your final answer by giving the closed-form analytic expression for $\\delta(u)$ in terms of $B_T$ and $T$. No rounding is required and no units are involved.", "solution": "The problem is well-posed and scientifically grounded within the framework of Malliavin calculus. We proceed with the solution.\n\nThe integrand process is defined as $u_t := B_T$ for all $t \\in [0,T]$. This can be written as $u = B_T \\cdot \\mathbf{1}$, where $\\mathbf{1}$ is the function identically equal to $1$ on $[0,T]$. Since $\\mathbf{1} \\in L^2([0,T]) = H$, $u$ is an $H$-valued random variable.\n\n1. Prove that $u \\in \\mathrm{Dom}(\\delta)$.\nTo show that $u$ is in the domain of the Skorokhod integral, $\\mathrm{Dom}(\\delta)$, we must verify two conditions:\n(a) $u \\in L^2(\\Omega; H)$.\n(b) The mapping $F \\mapsto \\mathbb{E}[\\langle DF, u \\rangle_H]$ is continuous on the space of smooth cylindrical functionals with respect to the $L^2(\\Omega)$ norm.\n\nFor condition (a), we compute the squared norm of $u$ in $L^2(\\Omega; H)$:\n$$ \\mathbb{E}\\left[ \\|u\\|_H^2 \\right] = \\mathbb{E}\\left[ \\int_0^T u_t^2 \\, dt \\right] = \\mathbb{E}\\left[ \\int_0^T B_T^2 \\, dt \\right] $$\nBy Fubini's theorem, we can switch the expectation and the integral:\n$$ \\int_0^T \\mathbb{E}\\left[ B_T^2 \\right] \\, dt = \\int_0^T T \\, dt = T^2 $$\nSince $T^2 < \\infty$, we have shown that $u \\in L^2(\\Omega; H)$.\n\nFor condition (b), we analyze the expression $\\mathbb{E}[\\langle DF, u \\rangle_H]$ for a smooth cylindrical functional $F$.\n$$ \\mathbb{E}[\\langle DF, u \\rangle_H] = \\mathbb{E}\\left[ \\int_0^T (D_t F) u_t \\, dt \\right] = \\mathbb{E}\\left[ B_T \\int_0^T D_t F \\, dt \\right] $$\nWe use an integration by parts argument. Consider the product $B_T F$. Its Malliavin derivative is given by the product rule:\n$$ D_t(B_T F) = F (D_t B_T) + B_T (D_t F) $$\nThe Brownian motion at time $T$ can be written as the Wiener integral $B_T = \\int_0^T 1 \\, dB_s$. The Malliavin derivative of such an integral is $D_t B_T = D_t \\left(\\int_0^T \\mathbf{1}(s) \\, dB_s\\right) = \\mathbf{1}(t) = 1$ for $t \\in [0,T]$. So,\n$$ D_t(B_T F) = F + B_T D_t F $$\nNow, consider the duality relation between the derivative $D$ and the Wiener integral $W(h) = \\int_0^T h(s) \\, dB_s$. For a general smooth functional $G$ and $h \\in H$, we have $\\mathbb{E}[\\langle DG, h \\rangle_H] = \\mathbb{E}[G W(h)]$. Let $G = B_T F$ and $h = \\mathbf{1}$. Then $W(\\mathbf{1}) = B_T$.\n$$ \\mathbb{E}[\\langle D(B_T F), \\mathbf{1} \\rangle_H] = \\mathbb{E}[(B_T F) W(\\mathbf{1})] = \\mathbb{E}[B_T^2 F] $$\nOn the other hand, we can compute the inner product directly:\n$$ \\mathbb{E}[\\langle D(B_T F), \\mathbf{1} \\rangle_H] = \\mathbb{E}\\left[ \\int_0^T D_t(B_T F) \\cdot 1 \\, dt \\right] = \\mathbb{E}\\left[ \\int_0^T (F + B_T D_t F) \\, dt \\right] $$\n$$ = \\mathbb{E}\\left[ F \\int_0^T 1 \\, dt + B_T \\int_0^T D_t F \\, dt \\right] = \\mathbb{E}[T F] + \\mathbb{E}\\left[ B_T \\int_0^T D_t F \\, dt \\right] $$\nEquating the two expressions for $\\mathbb{E}[\\langle D(B_T F), \\mathbf{1} \\rangle_H]$, we get:\n$$ \\mathbb{E}[B_T^2 F] = T \\mathbb{E}[F] + \\mathbb{E}\\left[ B_T \\int_0^T D_t F \\, dt \\right] $$\nRearranging gives the expression we seek:\n$$ \\mathbb{E}[\\langle DF, u \\rangle_H] = \\mathbb{E}\\left[ B_T \\int_0^T D_t F \\, dt \\right] = \\mathbb{E}[B_T^2 F] - T \\mathbb{E}[F] = \\mathbb{E}[(B_T^2 - T)F] $$\nThe continuity condition is now evident. By the Cauchy-Schwarz inequality:\n$$ |\\mathbb{E}[(B_T^2 - T)F]| \\le \\| B_T^2 - T \\|_{L^2(\\Omega)} \\| F \\|_{L^2(\\Omega)} $$\nSince $B_T \\sim N(0,T)$, all its moments are finite, which implies $\\| B_T^2 - T \\|_{L^2(\\Omega)}$ is a finite constant. Thus, the mapping $F \\mapsto \\mathbb{E}[\\langle DF, u \\rangle_H]$ is continuous, completing the proof that $u \\in \\mathrm{Dom}(\\delta)$.\n\n2. Compute $\\delta(u)$ explicitly.\nThe Skorokhod integral $\\delta(u)$ is defined as the unique element in $L^2(\\Omega)$ satisfying the duality relation:\n$$ \\mathbb{E}[F \\delta(u)] = \\mathbb{E}[\\langle DF, u \\rangle_H] $$\nfor all smooth cylindrical functionals $F$. From our work in part 1, we found:\n$$ \\mathbb{E}[\\langle DF, u \\rangle_H] = \\mathbb{E}[(B_T^2 - T)F] $$\nTherefore, we must have:\n$$ \\mathbb{E}[F \\delta(u)] = \\mathbb{E}[(B_T^2 - T)F] $$\nSince the space of smooth cylindrical functionals is dense in $L^2(\\Omega)$, this equality implies that the random variables themselves must be equal almost surely.\n$$ \\delta(u) = B_T^2 - T $$\n\n3. Compute $\\mathbb{E}[\\delta(u)]$ and $\\mathrm{Var}(\\delta(u))$.\nUsing the expression for $\\delta(u)$, we compute its expectation:\n$$ \\mathbb{E}[\\delta(u)] = \\mathbb{E}[B_T^2 - T] = \\mathbb{E}[B_T^2] - T $$\nSince $B_T$ is a centered normal random variable with variance $T$, its second moment is $\\mathbb{E}[B_T^2] = T$.\n$$ \\mathbb{E}[\\delta(u)] = T - T = 0 $$\nNext, we compute the variance:\n$$ \\mathrm{Var}(\\delta(u)) = \\mathrm{Var}(B_T^2 - T) = \\mathrm{Var}(B_T^2) $$\nThe variance is given by $\\mathrm{Var}(B_T^2) = \\mathbb{E}[(B_T^2)^2] - (\\mathbb{E}[B_T^2])^2 = \\mathbb{E}[B_T^4] - T^2$.\nFor a centered normal random variable $X \\sim N(0, \\sigma^2)$, the fourth moment is $\\mathbb{E}[X^4] = 3\\sigma^4$. For $B_T$, we have $\\sigma^2 = T$, so $\\mathbb{E}[B_T^4] = 3T^2$.\n$$ \\mathrm{Var}(\\delta(u)) = 3T^2 - T^2 = 2T^2 $$\n\n4. Compute the Russo-Vallois forward integral and relate it to $\\delta(u)$.\nThe Russo-Vallois forward integral is defined by the limit in probability of the forward Riemann sums:\n$$ \\int_0^T u_t \\, d^-B_t = \\lim_{\\|\\pi_n\\| \\to 0} \\sum_{k=0}^{n-1} u_{t_k} (B_{t_{k+1}} - B_{t_k}) $$\nwhere $\\pi_n = \\{0=t_0 < t_1 < \\dots < t_n = T\\}$ is a partition of $[0,T]$. For our integrand $u_t = B_T$, the sum for any partition $\\pi_n$ is:\n$$ \\sum_{k=0}^{n-1} B_T (B_{t_{k+1}} - B_{t_k}) = B_T \\sum_{k=0}^{n-1} (B_{t_{k+1}} - B_{t_k}) $$\nThis is a telescoping sum:\n$$ B_T ( (B_{t_1} - B_{t_0}) + (B_{t_2} - B_{t_1}) + \\dots + (B_{t_n} - B_{t_{n-1}}) ) = B_T (B_{t_n} - B_{t_0}) = B_T (B_T - B_0) $$\nSince $B_0=0$, the sum is exactly $B_T^2$, regardless of the partition. Therefore, the limit is trivial:\n$$ \\int_0^T u_t \\, d^-B_t = B_T^2 $$\nTo relate this to $\\delta(u)$, we use the general identity (the Hitsuda-Skorokhod identity) which connects the Skorokhod integral to this forward integral:\n$$ \\int_0^T u_t \\, d^-B_t = \\delta(u) + \\int_0^T D_t u_t \\, dt $$\nThe term $\\int_0^T D_t u_t \\, dt$ is the trace of the Malliavin derivative of the process $u$. Let's compute it. The process is $u_t = B_T$. Its Malliavin derivative at time $s$ is $D_s u_t = D_s B_T = 1$ for all $s,t \\in [0,T]$.\nThe trace requires evaluating the derivative at the same time index as the process, i.e., $s=t$. So, $D_t u_t = 1$.\nThe integral of the trace is then:\n$$ \\int_0^T D_t u_t \\, dt = \\int_0^T 1 \\, dt = T $$\nSubstituting our results back into the identity, we verify its correctness:\n$$ \\int_0^T u_t \\, d^-B_t = B_T^2 $$\n$$ \\delta(u) + \\int_0^T D_t u_t \\, dt = (B_T^2 - T) + T = B_T^2 $$\nThe identity holds, establishing the relationship between the Skorokhod integral of $u$ and its Russo-Vallois forward integral via the trace of its Malliavin derivative. The final answer requested is the expression for $\\delta(u)$.", "answer": "$$\n\\boxed{B_T^2 - T}\n$$", "id": "2986329"}]}