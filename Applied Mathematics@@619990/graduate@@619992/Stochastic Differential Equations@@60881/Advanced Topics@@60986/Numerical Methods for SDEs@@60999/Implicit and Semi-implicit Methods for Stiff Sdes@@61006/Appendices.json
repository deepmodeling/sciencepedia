{"hands_on_practices": [{"introduction": "Explicit numerical schemes like the Euler-Maruyama method are appealing for their simplicity, but their stability is often severely limited when dealing with stiff dynamics. This practice [@problem_id:2979927] provides a foundational look into a phenomenon known as 'noise-induced stiffness,' where a strong multiplicative noise term—not just a stiff drift—can force the time step to become impractically small. By analyzing the mean-square stability of an explicit scheme applied to a canonical model, you will quantify this restriction and build a strong intuition for why implicit methods are essential tools.", "problem": "Consider the scalar stochastic differential equation driven by a standard Wiener process $W_t$,\n$$\n\\mathrm{d}X_t \\;=\\; -\\,X_t\\,\\mathrm{d}t \\;+\\; b\\,X_t\\,\\mathrm{d}W_t,\\qquad X_0\\in L^2(\\Omega),\\quad b>0,\n$$\nwhich is a linear multiplicative-noise model with a mild stabilizing drift of magnitude $1$ and diffusion coefficient $g(x)=b\\,x$. This is a canonical instance where the diffusion can induce numerical stiffness. Work from first principles to analyze the exact mean-square dynamics and the mean-square stability of the explicit Euler–Maruyama discretization with uniform time step $\\Delta t>0$:\n$$\nX_{n+1} \\;=\\; X_n \\;-\\; X_n\\,\\Delta t \\;+\\; b\\,X_n\\,\\Delta W_n,\n$$\nwhere $\\Delta W_n:=W_{t_{n+1}}-W_{t_n}$ and $t_n:=n\\,\\Delta t$. In your derivations, use only the fundamental properties of Itô calculus and the Wiener increment, namely $E[\\Delta W_n]=0$ and $E[(\\Delta W_n)^2]=\\Delta t$, and the definition of mean-square stability as the requirement that $E[|X_t|^2]$ (for the exact solution) or $E[|X_n|^2]$ (for the discrete solution) decays to $0$ as $t\\to\\infty$ or $n\\to\\infty$.\n\nTasks:\n- Derive the exact evolution equation for $E[|X_t|^2]$ and state the condition on $b$ under which the exact solution is mean-square stable.\n- Derive the one-step mean-square amplification factor of the Euler–Maruyama method and the associated mean-square stability condition.\n- Interpreting the situation as noise-induced stiffness when the drift $-X_t$ is mild but $b$ is not negligible, determine the largest step size $\\Delta t_{\\max}$ (as a function of $b$) for which the explicit Euler–Maruyama method is mean-square stable whenever the exact solution is mean-square stable.\n\nProvide your final answer as the closed-form expression for $\\Delta t_{\\max}$ in terms of $b$. No numerical rounding is required.", "solution": "The problem requires an analysis of the mean-square stability for a scalar linear stochastic differential equation (SDE) and its discretization by the explicit Euler–Maruyama method. We will first derive the condition for the stability of the exact solution, then for the numerical method, and finally determine the maximum allowable time step for the numerical method under the condition that the exact solution is stable.\n\nThe given SDE is:\n$$\n\\mathrm{d}X_t = -X_t\\,\\mathrm{d}t + b\\,X_t\\,\\mathrm{d}W_t\n$$\nwith initial condition $X_0 \\in L^2(\\Omega)$ and parameter $b>0$.\n\n**Part 1: Mean-Square Stability of the Exact Solution**\n\nTo analyze the mean-square stability, we need to find the evolution of the second moment, $E[|X_t|^2]$. Since $X_t$ is a real-valued process, $|X_t|^2 = X_t^2$. We apply Itô's formula to the function $f(x) = x^2$. The derivatives are $f_x(x) = 2x$ and $f_{xx}(x) = 2$.\nThe general Itô's formula for a process $\\mathrm{d}X_t = a(X_t, t)\\mathrm{d}t + g(X_t, t)\\mathrm{d}W_t$ applied to $f(X_t)$ is:\n$$\n\\mathrm{d}f(X_t) = \\left( a(X_t, t) f_x(X_t) + \\frac{1}{2} g(X_t, t)^2 f_{xx}(X_t) \\right) \\mathrm{d}t + g(X_t, t) f_x(X_t) \\mathrm{d}W_t\n$$\nIn our case, the drift coefficient is $a(x,t) = -x$ and the diffusion coefficient is $g(x,t) = b\\,x$. Substituting these into Itô's formula with $f(x)=x^2$:\n$$\n\\mathrm{d}(X_t^2) = \\left( (-X_t)(2X_t) + \\frac{1}{2} (b X_t)^2 (2) \\right) \\mathrm{d}t + (b X_t)(2X_t) \\mathrm{d}W_t\n$$\n$$\n\\mathrm{d}(X_t^2) = \\left( -2X_t^2 + b^2 X_t^2 \\right) \\mathrm{d}t + 2b X_t^2 \\mathrm{d}W_t\n$$\n$$\n\\mathrm{d}(X_t^2) = (-2 + b^2) X_t^2 \\mathrm{d}t + 2b X_t^2 \\mathrm{d}W_t\n$$\nTo find the differential equation for the mean-square value, $E[X_t^2]$, we take the expectation of the integral form of the above SDE:\n$$\nE[X_t^2] - E[X_0^2] = E\\left[\\int_0^t (-2 + b^2) X_s^2 \\mathrm{d}s\\right] + E\\left[\\int_0^t 2b X_s^2 \\mathrm{d}W_s\\right]\n$$\nBy Fubini's theorem, we can swap expectation and the time integral. The expectation of the Itô integral term is zero, provided the integrand is a suitable process, which is true here.\n$$\nE[X_t^2] - E[X_0^2] = \\int_0^t (-2 + b^2) E[X_s^2] \\mathrm{d}s\n$$\nDifferentiating with respect to $t$, we obtain an ordinary differential equation (ODE) for $m(t) := E[X_t^2]$:\n$$\n\\frac{\\mathrm{d}m(t)}{\\mathrm{d}t} = (-2 + b^2) m(t)\n$$\nThe solution to this linear ODE is $m(t) = m(0) \\exp((-2 + b^2)t)$, where $m(0)=E[X_0^2]$.\nMean-square stability requires that $m(t) \\to 0$ as $t \\to \\infty$. This occurs if and only if the coefficient in the exponent is negative:\n$$\n-2 + b^2 < 0 \\implies b^2 < 2\n$$\nSince the problem states $b > 0$, the condition for mean-square stability of the exact solution is $0 < b < \\sqrt{2}$.\n\n**Part 2: Mean-Square Stability of the Euler–Maruyama Method**\n\nThe Euler–Maruyama discretization with time step $\\Delta t$ is given by:\n$$\nX_{n+1} = X_n - X_n\\,\\Delta t + b\\,X_n\\,\\Delta W_n = X_n(1 - \\Delta t + b\\,\\Delta W_n)\n$$\nWe analyze the evolution of the mean-square value, $E[X_n^2]$. We square the expression for $X_{n+1}$ and take the expectation:\n$$\nE[X_{n+1}^2] = E\\left[ \\left( X_n(1 - \\Delta t + b\\,\\Delta W_n) \\right)^2 \\right] = E\\left[ X_n^2 (1 - \\Delta t + b\\,\\Delta W_n)^2 \\right]\n$$\nUsing the law of total expectation, $E[Z] = E[E[Z|\\mathcal{F}]]$, we condition on the sigma-algebra $\\mathcal{F}_{t_n}$ generated by the Wiener process up to time $t_n = n \\Delta t$. $X_n$ is $\\mathcal{F}_{t_n}$-measurable.\n$$\nE[X_{n+1}^2] = E\\left[ E\\left[ X_n^2 (1 - \\Delta t + b\\,\\Delta W_n)^2 \\big| \\mathcal{F}_{t_n} \\right] \\right] = E\\left[ X_n^2 E\\left[ (1 - \\Delta t + b\\,\\Delta W_n)^2 \\big| \\mathcal{F}_{t_n} \\right] \\right]\n$$\nThe Wiener increment $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is independent of $\\mathcal{F}_{t_n}$. Thus, the inner conditional expectation is a simple expectation:\n$$\nE[(1 - \\Delta t + b\\,\\Delta W_n)^2] = E[ (1 - \\Delta t)^2 + 2b(1 - \\Delta t)\\Delta W_n + b^2(\\Delta W_n)^2 ]\n$$\nUsing the properties $E[\\Delta W_n]=0$ and $E[(\\Delta W_n)^2]=\\Delta t$:\n$$\n= (1 - \\Delta t)^2 + 2b(1 - \\Delta t)E[\\Delta W_n] + b^2 E[(\\Delta W_n)^2] = (1 - \\Delta t)^2 + b^2 \\Delta t\n$$\n$$\n= 1 - 2\\Delta t + (\\Delta t)^2 + b^2\\Delta t = 1 + (b^2 - 2)\\Delta t + (\\Delta t)^2\n$$\nThis expression is the one-step mean-square amplification factor, $R(\\Delta t)$. The recurrence relation for the mean-square value is:\n$$\nE[X_{n+1}^2] = R(\\Delta t) E[X_n^2] = \\left( 1 + (b^2 - 2)\\Delta t + (\\Delta t)^2 \\right) E[X_n^2]\n$$\nFor the numerical method to be mean-square stable, we require $E[X_n^2] \\to 0$ as $n \\to \\infty$, which holds if and only if the amplification factor $R(\\Delta t)$ has a magnitude less than $1$:\n$$\n|R(\\Delta t)| < 1 \\implies -1 < 1 + (b^2 - 2)\\Delta t + (\\Delta t)^2 < 1\n$$\nThis gives two conditions:\n1. $1 + (b^2 - 2)\\Delta t + (\\Delta t)^2 < 1 \\implies (b^2 - 2)\\Delta t + (\\Delta t)^2 < 0 \\implies \\Delta t (b^2 - 2 + \\Delta t) < 0$.\nSince $\\Delta t > 0$, we must have $b^2 - 2 + \\Delta t < 0$, which means $\\Delta t < 2 - b^2$. For a positive step size $\\Delta t$ to exist, we must have $2 - b^2 > 0$, i.e., $b^2 < 2$.\n\n2. $1 + (b^2 - 2)\\Delta t + (\\Delta t)^2 > -1 \\implies (\\Delta t)^2 + (b^2 - 2)\\Delta t + 2 > 0$.\nLet $q(\\Delta t) = (\\Delta t)^2 + (b^2 - 2)\\Delta t + 2$. This is a quadratic in $\\Delta t$ that opens upwards. Its vertex is at $\\Delta t_v = -(b^2 - 2)/2 = (2 - b^2)/2$.\nIf $b^2 \\ge 2$, then $\\Delta t_v \\le 0$. For $\\Delta t > 0$, $q(\\Delta t)$ is an increasing function and $q(0)=2$, so $q(\\Delta t) > 2$ for all $\\Delta t > 0$.\nIf $0 < b^2 < 2$, then $\\Delta t_v > 0$. The minimum value of $q(\\Delta t)$ for $\\Delta t > 0$ is at the vertex: $q(\\Delta t_v) = (\\frac{2-b^2}{2})^2 - (2-b^2)(\\frac{2-b^2}{2}) + 2 = 2 - \\frac{(2-b^2)^2}{4}$. Since $0 < b^2 < 2$, we have $0 < 2-b^2 < 2$, so $0 < (2-b^2)^2 < 4$. This gives $0 < \\frac{(2-b^2)^2}{4} < 1$, and thus $1 < q(\\Delta t_v) < 2$.\nIn both cases, $q(\\Delta t) > 0$ for all $\\Delta t > 0$ and $b > 0$.\nTherefore, the second condition is always satisfied.\n\nThe sole condition for mean-square stability of the Euler-Maruyama method is $\\Delta t < 2 - b^2$, which requires $b^2 < 2$.\n\n**Part 3: Determination of the Maximum Step Size $\\Delta t_{\\max}$**\n\nThe problem asks for the largest step size $\\Delta t_{\\max}$ for which the numerical method is stable, under the assumption that the exact solution is stable.\nFrom Part 1, the exact solution is stable if and only if $0 < b^2 < 2$.\nFrom Part 2, for a given $b$ satisfying $b^2 < 2$, the Euler-Maruyama method is stable if and only if the step size $\\Delta t$ satisfies $0 < \\Delta t < 2 - b^2$.\nThe largest step size for which this stability condition holds is the upper bound of the interval.\nTherefore, the maximum allowed step size is:\n$$\n\\Delta t_{\\max} = 2 - b^2\n$$\nThis result highlights the phenomenon of noise-induced stiffness. The drift term alone suggests a stability limit of $\\Delta t < 2$. However, the multiplicative noise term, controlled by $b$, imposes a stricter constraint $\\Delta t < 2 - b^2$. As $b$ approaches the continuous-time stability boundary, i.e., $b \\to \\sqrt{2}^{-}$, the maximum stable step size $\\Delta t_{\\max}$ for the explicit method tends to zero, requiring an increasingly small time step for a stable simulation.", "answer": "$$\\boxed{2 - b^2}$$", "id": "2979927"}, {"introduction": "Having established the need for methods that can handle stiffness, we now turn to analyzing a widely-used solution: the semi-implicit Euler-Maruyama method, which treats the drift implicitly. This practice [@problem_id:2980005] focuses on a core skill in numerical SDEs: deriving the mean-square stability properties of a scheme. You will calculate the method's discrete amplification factor for a linear test equation and see how it approximates the true dynamics, providing a quantitative basis for understanding its excellent stability performance when the drift is stiff.", "problem": "Consider the scalar linear stochastic differential equation (SDE) $$\\mathrm{d}X_{t}=\\lambda X_{t}\\,\\mathrm{d}t+\\mu X_{t}\\,\\mathrm{d}W_{t},$$ where $W_{t}$ is a standard Wiener process, $\\lambda\\in\\mathbb{R}$ models a stiff linear drift (with $\\lambda<0$), and $\\mu\\in\\mathbb{R}$ is the multiplicative noise strength. Let $h>0$ be a fixed time-step and denote by $X_{n}\\approx X_{t_{n}}$ the numerical approximation at $t_{n}=nh$ produced by a drift-implicit Euler–Maruyama method, which treats the drift term implicitly and the diffusion term explicitly.\n\nStarting from fundamental definitions of Itô calculus and the update rule of the drift-implicit Euler–Maruyama method applied to this SDE, derive the discrete per-step mean-square (MS) amplification factor $R_{\\text{MS}}(h,\\lambda,\\mu)$ defined by $$R_{\\text{MS}}(h,\\lambda,\\mu)=\\frac{\\mathbb{E}\\!\\left[|X_{n+1}|^{2}\\right]}{\\mathbb{E}\\!\\left[|X_{n}|^{2}\\right]}.$$ Then, compare the discrete MS amplification factor to the exact continuous-time MS decay/growth rate obtained from the evolution equation for the second moment of the SDE, and explain the leading-order relationship in $h$.\n\nYour final answer should be the closed-form analytical expression for $R_{\\text{MS}}(h,\\lambda,\\mu)$ in terms of $h$, $\\lambda$, and $\\mu$. No numerical evaluation or rounding is required.", "solution": "The general form of a drift-implicit Euler–Maruyama scheme for an SDE $\\mathrm{d}X_t = a(X_t, t)\\mathrm{d}t + b(X_t, t)\\mathrm{d}W_t$ is given by:\n$$X_{n+1} = X_n + a(X_{n+1}, t_{n+1})h + b(X_n, t_n)\\Delta W_n$$\nwhere $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is the increment of the Wiener process over the interval $[t_n, t_{n+1}]$.\n\nFor the given SDE, $\\mathrm{d}X_{t}=\\lambda X_{t}\\,\\mathrm{d}t+\\mu X_{t}\\,\\mathrm{d}W_{t}$, the drift term is $a(X_t) = \\lambda X_t$ and the diffusion term is $b(X_t) = \\mu X_t$. Applying the drift-implicit scheme gives:\n$$X_{n+1} = X_n + \\lambda X_{n+1} h + \\mu X_n \\Delta W_n$$\nThis is an implicit equation for $X_{n+1}$. We can solve for $X_{n+1}$ algebraically:\n$$X_{n+1} - \\lambda X_{n+1} h = X_n + \\mu X_n \\Delta W_n$$\n$$X_{n+1}(1 - \\lambda h) = X_n(1 + \\mu \\Delta W_n)$$\nAssuming $1 - \\lambda h \\neq 0$, which is true since $\\lambda < 0$ and $h > 0$, we have:\n$$X_{n+1} = \\frac{1 + \\mu \\Delta W_n}{1 - \\lambda h} X_n$$\nThis is the explicit one-step update rule for the numerical approximation.\n\nNow, we can compute the mean-square amplification factor $R_{\\text{MS}}(h,\\lambda,\\mu)$. We start by taking the squared magnitude of $X_{n+1}$:\n$$|X_{n+1}|^2 = \\left| \\frac{1 + \\mu \\Delta W_n}{1 - \\lambda h} X_n \\right|^2 = \\frac{(1 + \\mu \\Delta W_n)^2}{(1 - \\lambda h)^2} |X_n|^2$$\nNext, we take the expectation of this expression. We use the law of total expectation, conditioning on the information available at time $t_n$, which is represented by the filtration $\\mathcal{F}_{t_n}$. The approximation $X_n$ is $\\mathcal{F}_{t_n}$-measurable, while the increment $\\Delta W_n$ is independent of $\\mathcal{F}_{t_n}$.\n$$\\mathbb{E}[|X_{n+1}|^2] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\frac{(1 + \\mu \\Delta W_n)^2}{(1 - \\lambda h)^2} |X_n|^2 \\bigg| \\mathcal{F}_{t_n} \\right] \\right]$$\nSince $|X_n|^2$ and the denominator $(1 - \\lambda h)^2$ are $\\mathcal{F}_{t_n}$-measurable, they can be treated as constants within the inner expectation:\n$$\\mathbb{E}[|X_{n+1}|^2] = \\mathbb{E}\\left[ \\frac{|X_n|^2}{(1 - \\lambda h)^2} \\mathbb{E}\\left[ (1 + \\mu \\Delta W_n)^2 \\bigg| \\mathcal{F}_{t_n} \\right] \\right]$$\nDue to the independence of $\\Delta W_n$ from $\\mathcal{F}_{t_n}$, the conditional expectation becomes an unconditional expectation:\n$$\\mathbb{E}[|X_{n+1}|^2] = \\frac{1}{(1 - \\lambda h)^2} \\mathbb{E}[|X_n|^2] \\mathbb{E}[(1 + \\mu \\Delta W_n)^2]$$\nThe increment $\\Delta W_n$ is a normally distributed random variable with mean $0$ and variance $h$, i.e., $\\Delta W_n \\sim \\mathcal{N}(0, h)$. Therefore, $\\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2] = h$. We use this to evaluate the remaining expectation:\n$$\\mathbb{E}[(1 + \\mu \\Delta W_n)^2] = \\mathbb{E}[1 + 2\\mu\\Delta W_n + \\mu^2(\\Delta W_n)^2]$$\nBy linearity of expectation:\n$$\\mathbb{E}[(1 + \\mu \\Delta W_n)^2] = 1 + 2\\mu\\mathbb{E}[\\Delta W_n] + \\mu^2\\mathbb{E}[(\\Delta W_n)^2] = 1 + 2\\mu(0) + \\mu^2(h) = 1 + \\mu^2 h$$\nSubstituting this result back, we get the relationship between the second moments at successive time steps:\n$$\\mathbb{E}[|X_{n+1}|^2] = \\frac{1 + \\mu^2 h}{(1 - \\lambda h)^2} \\mathbb{E}[|X_n|^2]$$\nThe discrete per-step mean-square amplification factor is therefore:\n$$R_{\\text{MS}}(h,\\lambda,\\mu) = \\frac{\\mathbb{E}[|X_{n+1}|^2]}{\\mathbb{E}[|X_n|^2]} = \\frac{1 + \\mu^2 h}{(1 - \\lambda h)^2}$$\nThis is the first part of the required answer.\n\nFor the comparison, we must find the exact continuous-time MS decay/growth rate. Let $m_2(t) = \\mathbb{E}[X_t^2]$. We derive the ordinary differential equation (ODE) governing $m_2(t)$ using Itô's formula. For $f(x) = x^2$, we have $f'(x) = 2x$ and $f''(x) = 2$. Applying Itô's formula to $X_t^2$:\n$$\\mathrm{d}(X_t^2) = \\left( (2X_t)(\\lambda X_t) + \\frac{1}{2}(2)(\\mu X_t)^2 \\right)\\mathrm{d}t + (2X_t)(\\mu X_t)\\mathrm{d}W_t$$\n$$\\mathrm{d}(X_t^2) = (2\\lambda + \\mu^2)X_t^2\\,\\mathrm{d}t + 2\\mu X_t^2\\,\\mathrm{d}W_t$$\nTaking the expectation of both sides, and noting that the expectation of the Itô integral term is zero ($\\mathbb{E}[\\int_{0}^{t} 2\\mu X_s^2\\,\\mathrm{d}W_s] = 0$):\n$$\\mathrm{d}(\\mathbb{E}[X_t^2]) = (2\\lambda + \\mu^2)\\mathbb{E}[X_t^2]\\,\\mathrm{d}t$$\nThis gives the ODE for the second moment $m_2(t)$:\n$$\\frac{\\mathrm{d}m_2(t)}{\\mathrm{d}t} = (2\\lambda + \\mu^2)m_2(t)$$\nThe solution is $m_2(t) = m_2(0)\\exp((2\\lambda + \\mu^2)t)$. The exact amplification of the second moment over a time step of length $h$ is:\n$$R_{\\text{exact}}(h) = \\frac{m_2(t_n+h)}{m_2(t_n)} = \\exp((2\\lambda + \\mu^2)h)$$\nTo compare $R_{\\text{MS}}$ with $R_{\\text{exact}}$, we perform a Taylor expansion of both expressions in powers of $h$ around $h=0$.\nFor the exact factor:\n$$R_{\\text{exact}}(h) = 1 + (2\\lambda + \\mu^2)h + \\frac{1}{2}(2\\lambda + \\mu^2)^2 h^2 + O(h^3)$$\nFor the numerical factor, we use the geometric series expansion $(1-x)^{-2} = 1 + 2x + 3x^2 + \\dots$:\n$$R_{\\text{MS}}(h) = \\frac{1 + \\mu^2 h}{(1 - \\lambda h)^2} = (1 + \\mu^2 h)(1 - \\lambda h)^{-2}$$\n$$R_{\\text{MS}}(h) = (1 + \\mu^2 h)(1 + 2\\lambda h + 3\\lambda^2 h^2 + O(h^3))$$\n$$R_{\\text{MS}}(h) = 1 + 2\\lambda h + 3\\lambda^2 h^2 + \\mu^2 h + 2\\lambda\\mu^2 h^2 + O(h^3)$$\n$$R_{\\text{MS}}(h) = 1 + (2\\lambda + \\mu^2)h + (3\\lambda^2 + 2\\lambda\\mu^2)h^2 + O(h^3)$$\nComparing the two series expansions, we see that the coefficients of $h^0$ and $h^1$ are identical.\n$$R_{\\text{MS}}(h) - R_{\\text{exact}}(h) = O(h^2)$$\nThis means the drift-implicit Euler-Maruyama method reproduces the exact mean-square dynamics to first order in the step-size $h$. The leading-order relationship is that the numerical MS amplification factor is a first-order approximation to the exact one: $R_{\\text{MS}}(h) = R_{\\text{exact}}(h) + O(h^2)$.", "answer": "$$\\boxed{\\frac{1 + \\mu^{2} h}{(1 - \\lambda h)^{2}}}$$", "id": "2980005"}, {"introduction": "While implicit methods enhance stability, they are not a universal panacea, and a fully implicit treatment can introduce new challenges. This advanced exercise [@problem_id:2980034] delves into a critical limitation that can arise when applying a fully implicit scheme to SDEs with strong, superlinear diffusion. You will discover that for large random increments, the resulting algebraic equation for the next time step may have no real solution, causing the simulation to fail. Understanding this potential for ill-posedness is crucial for robustly applying implicit methods to complex, nonlinear problems.", "problem": "Consider the one-dimensional Stochastic Differential Equation (SDE) with stiff linear drift and superlinear multiplicative diffusion\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\lambda\\,X_{t}\\,\\mathrm{d}t \\;+\\; \\sigma\\,X_{t}^{3/2}\\,\\mathrm{d}W_{t},\n$$\nwhere $\\lambda>0$ is a stiffness parameter, $\\sigma>0$ is the noise amplitude, and $W_{t}$ is a standard Brownian motion. For a fixed time step $h>0$, consider the fully implicit Euler–Maruyama (EM) method that treats both drift and diffusion implicitly:\n$$\nX_{n+1} \\;=\\; X_{n} \\;+\\; h\\,\\big(-\\lambda\\,X_{n+1}\\big) \\;+\\; \\sigma\\,X_{n+1}^{3/2}\\,\\Delta W_{n},\n$$\nwhere $\\Delta W_{n} := W_{t_{n+1}} - W_{t_{n}}$.\n\nAssume $X_{n}>0$ is given. Starting only from the definitions of the SDE and the fully implicit EM step, derive the algebraic equation that must be solved for $X_{n+1}$ and reparametrize it in terms of $y := \\sqrt{X_{n+1}}$ to obtain a polynomial in $y$. Using first-principles calculus for polynomial extrema, determine the smallest positive threshold $\\Delta W_{*}$ (as an explicit, closed-form expression in $\\lambda$, $\\sigma$, $h$, and $X_{n}$) such that for any realization with $\\Delta W_{n} \\ge \\Delta W_{*}$, the implicit EM update has no nonnegative real solution for $X_{n+1}$.\n\nExplain, in terms of monotonicity and the geometry of the polynomial mapping, why the failure occurs. Your final answer must be the single analytic expression for $\\Delta W_{*}$. No rounding is required.", "solution": "The problem provides the stochastic differential equation (SDE):\n$$\n\\mathrm{d}X_{t} = -\\lambda\\,X_{t}\\,\\mathrm{d}t + \\sigma\\,X_{t}^{3/2}\\,\\mathrm{d}W_{t}\n$$\nwith parameters $\\lambda > 0$ and $\\sigma > 0$. The fully implicit Euler-Maruyama (EM) discretization with a time step $h > 0$ is given as:\n$$\nX_{n+1} = X_{n} + h\\,\\big(-\\lambda\\,X_{n+1}\\big) + \\sigma\\,\\Delta W_{n}\\,X_{n+1}^{3/2}\n$$\nHere, $\\Delta W_{n}$ is the Wiener increment $W_{t_{n+1}} - W_{t_{n}}$, and we are given a current state $X_{n} > 0$. We seek a non-negative real solution for the next state, $X_{n+1} \\ge 0$.\n\nTo analyze this implicit equation, we first rearrange it to isolate the known term $X_{n}$:\n$$\nX_{n} = X_{n+1} + h\\lambda\\,X_{n+1} - \\sigma\\,\\Delta W_{n}\\,X_{n+1}^{3/2}\n$$\n$$\nX_{n} = (1+h\\lambda)X_{n+1} - \\sigma\\,\\Delta W_{n}\\,X_{n+1}^{3/2}\n$$\nThis is the algebraic equation that must be solved for $X_{n+1}$ given $X_{n}$ and a realization of $\\Delta W_{n}$.\n\nThe problem requires a reparametrization in terms of $y := \\sqrt{X_{n+1}}$. Since we are searching for a non-negative solution $X_{n+1} \\ge 0$, this implies $y$ must be a non-negative real number, $y \\ge 0$. With this substitution, we have $X_{n+1} = y^2$ and $X_{n+1}^{3/2} = |y|^3$. Since $y \\ge 0$, this simplifies to $y^3$. Substituting these into the algebraic equation gives:\n$$\nX_{n} = (1+h\\lambda)y^2 - \\sigma\\,\\Delta W_{n}\\,y^3\n$$\nThis equation defines a relationship between the known value $X_{n}$ and the unknown $y$. To find a solution for $y$ is to find a root of the following cubic polynomial in $y$:\n$$\n\\sigma\\,\\Delta W_{n}\\,y^3 - (1+h\\lambda)y^2 + X_{n} = 0\n$$\n\nWe need to determine the conditions on $\\Delta W_{n}$ under which this polynomial has at least one non-negative real root for $y$. Let us define a function $g(y)$ for $y \\ge 0$:\n$$\ng(y) = (1+h\\lambda)y^2 - \\sigma\\,\\Delta W_{n}\\,y^3\n$$\nFinding a solution $y$ is equivalent to finding an intersection of the graph of $g(y)$ with the horizontal line $z = X_{n}$.\n\nThe problem is concerned with the failure to find a solution when the noise increment $\\Delta W_{n}$ is large and positive. We thus assume $\\Delta W_{n} > 0$. The case $\\Delta W_{n} \\le 0$ always yields a unique positive solution, as the function corresponding to the polynomial is monotonic for $y>0$. To understand the geometry of the function $g(y)$ for $y \\ge 0$, we analyze its extrema by finding its critical points. The first derivative of $g(y)$ is:\n$$\ng'(y) = \\frac{\\mathrm{d}g}{\\mathrm{d}y} = 2(1+h\\lambda)y - 3\\sigma\\,\\Delta W_{n}\\,y^2\n$$\nSetting $g'(y) = 0$ to find critical points:\n$$\ny \\left( 2(1+h\\lambda) - 3\\sigma\\,\\Delta W_{n}\\,y \\right) = 0\n$$\nThis yields two critical points: $y=0$ and a positive critical point $y_c$:\n$$\ny_{c} = \\frac{2(1+h\\lambda)}{3\\sigma\\,\\Delta W_{n}}\n$$\nTo determine the nature of these extrema, we examine the second derivative:\n$$\ng''(y) = \\frac{\\mathrm{d}^2g}{\\mathrm{d}y^2} = 2(1+h\\lambda) - 6\\sigma\\,\\Delta W_{n}\\,y\n$$\nAt $y=0$, $g''(0) = 2(1+h\\lambda) > 0$ (since $\\lambda>0, h>0$), so $y=0$ is a local minimum, with $g(0)=0$. At $y=y_c$,\n$$\ng''(y_c) = 2(1+h\\lambda) - 6\\sigma\\,\\Delta W_{n} \\left( \\frac{2(1+h\\lambda)}{3\\sigma\\,\\Delta W_{n}} \\right) = 2(1+h\\lambda) - 4(1+h\\lambda) = -2(1+h\\lambda) < 0\n$$\nThus, $y_c$ corresponds to a local maximum. The function $g(y)$ starts at $g(0)=0$, increases to a maximum value at $y_c$, and then decreases for $y>y_c$, tending to $-\\infty$ as $y \\to \\infty$ due to the $-y^3$ term.\n\nA non-negative solution $y$ to the equation $g(y) = X_{n}$ exists if and only if the value $X_{n}$ is less than or equal to the local maximum value of $g(y)$. Let's calculate this maximum value, $g_{\\max} = g(y_c)$:\n$$\ng_{\\max} = (1+h\\lambda)y_c^2 - \\sigma\\,\\Delta W_{n}\\,y_c^3 = y_c^2 \\left( (1+h\\lambda) - \\sigma\\,\\Delta W_{n}\\,y_c \\right)\n$$\nSubstituting the expression for $y_c$:\n$$\ng_{\\max} = y_c^2 \\left( (1+h\\lambda) - \\sigma\\,\\Delta W_{n}\\,\\frac{2(1+h\\lambda)}{3\\sigma\\,\\Delta W_{n}} \\right) = y_c^2 \\left( (1+h\\lambda) - \\frac{2}{3}(1+h\\lambda) \\right) = \\frac{1}{3}(1+h\\lambda)y_c^2\n$$\nNow, substituting the expression for $y_c$ again:\n$$\ng_{\\max} = \\frac{1}{3}(1+h\\lambda) \\left( \\frac{2(1+h\\lambda)}{3\\sigma\\,\\Delta W_{n}} \\right)^2 = \\frac{1}{3}(1+h\\lambda) \\frac{4(1+h\\lambda)^2}{9\\sigma^2(\\Delta W_{n})^2} = \\frac{4(1+h\\lambda)^3}{27\\sigma^2(\\Delta W_{n})^2}\n$$\nA solution exists if and only if $X_{n} \\le g_{\\max}$. Conversely, no non-negative solution exists if $X_{n} > g_{\\max}$. The condition for the non-existence of a non-negative real solution is $X_{n} > g_{\\max}$, which translates to:\n$$\nX_{n} > \\frac{4(1+h\\lambda)^3}{27\\sigma^2(\\Delta W_{n})^2}\n$$\nRearranging this inequality to solve for $\\Delta W_{n}$:\n$$\n(\\Delta W_{n})^2 > \\frac{4(1+h\\lambda)^3}{27\\sigma^2 X_{n}}\n$$\nSince we are seeking a positive threshold, we consider $\\Delta W_{n} > 0$ and take the positive square root:\n$$\n\\Delta W_{n} > \\sqrt{\\frac{4(1+h\\lambda)^3}{27\\sigma^2 X_{n}}}\n$$\nThe problem asks for the smallest positive threshold $\\Delta W_{*}$ such that for any $\\Delta W_{n} \\ge \\Delta W_{*}$, no solution exists. The set of $\\Delta W_n$ for which no solution exists is an open interval $(\\Delta W_{crit}, \\infty)$, where $\\Delta W_{crit} = \\sqrt{\\frac{4(1+h\\lambda)^3}{27\\sigma^2 X_{n}}}$. There is no smallest number in this open interval. A rigorous interpretation is that the question asks for the infimum of this set, which represents the boundary where solutions cease to exist. At this boundary value, exactly one solution exists ($X_n = g_{\\max}$). For any value greater than this boundary, no solution exists. We identify the threshold $\\Delta W_{*}$ with this infimum.\n$$\n\\Delta W_{*} = \\sqrt{\\frac{4(1+h\\lambda)^3}{27\\sigma^2 X_{n}}}\n$$\nSimplifying this expression, we get:\n$$\n\\Delta W_{*} = \\frac{2(1+h\\lambda)^{3/2}}{\\sigma\\sqrt{27}\\sqrt{X_n}} = \\frac{2(1+h\\lambda)^{3/2}}{3\\sqrt{3}\\sigma\\sqrt{X_n}}\n$$\n\nThe failure of the implicit method to produce a solution stems from the non-monotonic nature of the mapping from the future state to the present one. The equation $X_{n} = g(y)$ with $y=\\sqrt{X_{n+1}}$ can be interpreted as asking: \"For a given current state $X_n$, what possible future state $X_{n+1}$ could have led to it under the dynamics of the implicit scheme?\"\n\nThe function $g(y)$ represents this backward mapping. Geometrically, for a positive noise increment $\\Delta W_n > 0$, the graph of $g(y)$ for $y \\ge 0$ rises from the origin to a peak (the local maximum $g_{\\max}$) and then descends towards $-\\infty$. This means there is a maximum possible value of $X_n$ that can be a result of this mapping from any non-negative $y$.\n\nIf the given value of $X_n$ is greater than this peak value ($X_n > g_{\\max}$), the horizontal line $z=X_n$ lies entirely above the graph of $g(y)$. Consequently, there are no intersection points, which signifies that no real, non-negative value of $y$ (and thus $X_{n+1}$) can satisfy the implicit equation.\n\nThe maximum value $g_{\\max}$ is inversely proportional to $(\\Delta W_n)^2$. A large positive noise increment $\\Delta W_n$ drastically lowers the peak of the $g(y)$ curve. The threshold $\\Delta W_*$ is precisely the value of the noise increment for which this peak, $g_{\\max}$, drops to the level of the given state $X_n$. For any larger noise increment, $\\Delta W_n > \\Delta W_*$, the peak will be below $X_n$, and no solution will exist.", "answer": "$$\\boxed{\\frac{2(1+h\\lambda)^{3/2}}{3\\sqrt{3}\\sigma\\sqrt{X_{n}}}}$$", "id": "2980034"}]}