{"hands_on_practices": [{"introduction": "The Milstein method's primary advantage over the Euler-Maruyama scheme lies in its higher strong order of convergence, achieved through a specific correction term. This practice delves into the fundamental origin of this term by examining a scenario where it naturally disappears: the case of additive noise, where the diffusion coefficient is independent of the system's state. By demonstrating that the Milstein correction vanishes in this context, you will gain a deeper, first-principles insight into its role in handling multiplicative noise and its impact on strong versus weak convergence orders. [@problem_id:3002576]", "problem": "Consider the scalar stochastic differential equation (SDE) in Itô form\n$$\ndX_t = a(X_t,t)\\,dt + b(X_t,t)\\,dW_t,\n$$\nwhere $a$ and $b$ are sufficiently smooth to justify an Itô–Taylor expansion, and $W_t$ is a standard Wiener process. Assume the additive noise case $b(x,t)=\\sigma(t)$, where $\\sigma$ is a deterministic function with appropriate regularity. Using only fundamental results for Itô processes (namely Itô’s formula and the stochastic Taylor expansion up to terms that yield strong order one schemes), derive the one-step method obtained by matching all terms whose inclusion is necessary to achieve strong order one. In particular, rigorously show that the multiplicative-noise correction term that involves a spatial derivative of the diffusion coefficient vanishes when $b(x,t)=\\sigma(t)$, and conclude what discrete-time update results for a time step of size $h>0$ from $t_n$ to $t_{n+1}=t_n+h$.\n\nThen, discuss the implications of the additive-noise structure on the strong and weak convergence orders of the resulting method relative to the general multiplicative-noise case, explaining the mechanism by which the convergence order is affected in mean-square and distributional senses under standard Lipschitz and linear growth conditions.\n\nProvide as your final answer the closed-form analytic expression for the one-step update for $X_{n+1}$ in terms of $X_n$, $a$, $\\sigma$, $h$, and $\\Delta W_n:=W_{t_{n+1}}-W_{t_n}$. Do not include an equality sign or explanatory text in your final answer.", "solution": "The problem requires the derivation of a strong order $1.0$ numerical method for a scalar stochastic differential equation (SDE) with additive noise, starting from the general principles of Itô-Taylor expansions. The SDE is given by:\n$$\ndX_t = a(X_t,t)\\,dt + b(X_t,t)\\,dW_t\n$$\nwith the specific condition of additive noise, where the diffusion coefficient $b(x,t)$ is independent of the state variable $x$, i.e., $b(x,t) = \\sigma(t)$.\n\nFirst, we derive the general one-step scheme that achieves a strong order of convergence of $1.0$, which is known as the Milstein method. We begin with the exact integral representation of the solution over a time step $[t_n, t_{n+1}]$ of size $h = t_{n+1} - t_n$:\n$$\nX_{t_{n+1}} = X_{t_n} + \\int_{t_n}^{t_{n+1}} a(X_s, s)\\,ds + \\int_{t_n}^{t_{n+1}} b(X_s, s)\\,dW_s\n$$\nTo construct a numerical scheme, we approximate the integrals. The simplest approximation, leading to the Euler-Maruyama method, is to assume the integrands are constant over the interval, taking their values at the start of the interval, $t_n$.\nThe drift term integral is approximated as:\n$$\n\\int_{t_n}^{t_{n+1}} a(X_s, s)\\,ds \\approx a(X_{t_n}, t_n) \\int_{t_n}^{t_{n+1}} ds = a(X_{t_n}, t_n)h\n$$\nThe stochastic integral is approximated as:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s, s)\\,dW_s \\approx b(X_{t_n}, t_n) \\int_{t_n}^{t_{n+1}} dW_s = b(X_{t_n}, t_n)\\Delta W_n\n$$\nwhere $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$. The resulting Euler-Maruyama scheme is:\n$$\nX_{n+1} = X_n + a(X_n, t_n)h + b(X_n, t_n)\\Delta W_n\n$$\nHere, we use the notation $X_n = X_{t_n}$. This scheme has a strong order of convergence of $0.5$ in the general multiplicative noise case.\n\nTo achieve a strong order of $1.0$, a more accurate approximation of the stochastic integral is required. This is accomplished by applying an Itô-Taylor expansion to the integrand $b(X_s, s)$ around the point $(X_{t_n}, t_n)$. Using Itô's formula for $b(X_t, t)$, its differential is:\n$$\ndb(X_t, t) = \\left( \\frac{\\partial b}{\\partial t} + a \\frac{\\partial b}{\\partial x} + \\frac{1}{2} b^2 \\frac{\\partial^2 b}{\\partial x^2} \\right) dt + b \\frac{\\partial b}{\\partial x} dW_t\n$$\nFor $s \\in [t_n, t_{n+1}]$, we can write $b(X_s, s)$ in integral form:\n$$\nb(X_s, s) = b(X_{t_n}, t_n) + \\int_{t_n}^s \\dots du + \\int_{t_n}^s b(X_u, u) \\frac{\\partial b}{\\partial x}(X_u, u) dW_u\n$$\nSubstituting this into the stochastic integral for $X_{t_{n+1}}$ and retaining only the terms necessary for strong order $1.0$, we approximate the inner integrand $b(X_u, u) \\frac{\\partial b}{\\partial x}(X_u, u)$ by its value at $t_n$:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s, s)\\,dW_s \\approx \\int_{t_n}^{t_{n+1}} \\left( b(X_{t_n}, t_n) + b(X_{t_n}, t_n) \\frac{\\partial b}{\\partial x}(X_{t_n}, t_n) \\int_{t_n}^s dW_u \\right) dW_s\n$$\nThis gives:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s, s)\\,dW_s \\approx b(X_n, t_n)\\int_{t_n}^{t_{n+1}}dW_s + b(X_n, t_n)\\frac{\\partial b}{\\partial x}(X_n, t_n) \\int_{t_n}^{t_{n+1}}\\int_{t_n}^s dW_u dW_s\n$$\nThe first term is $b(X_n, t_n)\\Delta W_n$. The second term involves a double Itô integral, which can be evaluated as:\n$$\n\\int_{t_n}^{t_{n+1}}\\int_{t_n}^s dW_u dW_s = \\int_{t_n}^{t_{n+1}} (W_s - W_{t_n}) dW_s = \\frac{1}{2}((W_{t_{n+1}} - W_{t_n})^2 - (t_{n+1}-t_n)) = \\frac{1}{2}((\\Delta W_n)^2 - h)\n$$\nCombining these results, the one-step update, known as the Milstein method, is:\n$$\nX_{n+1} = X_n + a(X_n, t_n)h + b(X_n, t_n)\\Delta W_n + \\frac{1}{2}b(X_n, t_n)\\frac{\\partial b}{\\partial x}(X_n, t_n)((\\Delta W_n)^2 - h)\n$$\nThis scheme achieves a strong order of convergence of $1.0$ for general SDEs under sufficient smoothness and boundedness conditions on $a$ and $b$ and their derivatives.\n\nNow, we enforce the problem's condition of additive noise: $b(x,t) = \\sigma(t)$. Since $\\sigma(t)$ is a deterministic function of time, it has no dependence on the state variable $x$. Therefore, its partial derivative with respect to $x$ is zero:\n$$\n\\frac{\\partial b}{\\partial x}(x, t) = \\frac{\\partial \\sigma(t)}{\\partial x} = 0\n$$\nSubstituting this into the general Milstein scheme, the final term, which represents the correction over the Euler-Maruyama method, vanishes identically:\n$$\n\\frac{1}{2}b(X_n, t_n)\\frac{\\partial b}{\\partial x}(X_n, t_n)((\\Delta W_n)^2 - h) = \\frac{1}{2}\\sigma(t_n) \\cdot 0 \\cdot ((\\Delta W_n)^2 - h) = 0\n$$\nThus, for an SDE with additive noise, the Milstein method simplifies to:\n$$\nX_{n+1} = X_n + a(X_n, t_n)h + \\sigma(t_n)\\Delta W_n\n$$\nThis update formula is identical in form to the Euler-Maruyama method.\n\nFinally, we discuss the implications of the additive-noise structure on convergence orders.\nStrong convergence concerns the mean-square error of the pathwise approximation, $E[|X_T - X_N|]$. For a general SDE with multiplicative noise, the Euler-Maruyama scheme has strong order $0.5$. The Milstein scheme achieves strong order $1.0$ precisely by including the term proportional to $((\\Delta W_n)^2 - h)$. For an SDE with additive noise, this correction term is zero. This means that the scheme that is formally the Euler-Maruyama scheme already includes all terms necessary to achieve strong order $1.0$. The primary source of error that limits the Euler-Maruyama scheme to order $0.5$ in the general case is absent when the noise is additive. Hence, the method $X_{n+1} = X_n + a_n h + \\sigma_n \\Delta W_n$ has a strong convergence order of $1.0$ for additive noise SDEs, an improvement over the general case.\n\nWeak convergence concerns the error in the approximation of the moments of the solution, $|E[f(X_T)]-E[f(X_N)]|$. For general SDEs, the Euler-Maruyama scheme has a weak order of $1.0$. The Milstein correction term, $\\frac{1}{2}b b_x ((\\Delta W_n)^2 - h)$, has an expectation of zero, since $E[(\\Delta W_n)^2] = h$. As a result, adding this term to the Euler-Maruyama scheme does not improve its weak order, which remains $1.0$. To achieve a higher weak order (e.g., $2.0$), different terms from the Itô-Taylor expansion must be included. Since the additive noise structure ($b_x=0$) only affects a term that is irrelevant for the first-order weak error, the weak convergence order of the simplified method remains $1.0$, just as it is for the Euler-Maruyama method in the general multiplicative noise case. Therefore, unlike for strong convergence, the additive-noise structure provides no benefit to the weak convergence order of this particular scheme.\n\nIn summary, for SDEs with additive noise, the Milstein method, which is required for strong order $1.0$ convergence, simplifies to the much less computationally expensive Euler-Maruyama scheme.\n\nThe resulting one-step update for $X_{n+1}$ is:\n$X_{n+1} = X_n + a(X_n, t_n)h + \\sigma(t_n)\\Delta W_n$.", "answer": "$$\n\\boxed{X_n + a(X_n, t_n)h + \\sigma(t_n)\\Delta W_n}\n$$", "id": "3002576"}, {"introduction": "After understanding the mechanics of the Milstein method, a vital step is to assess its behavior on important models from finance and science. This exercise investigates whether the explicit Milstein method preserves essential qualitative properties of the true SDE solution, specifically non-negativity in the context of the Cox-Ingersoll-Ross (CIR) process. By combining analytical derivation with numerical simulation, you will confront a common challenge where a numerical scheme fails to respect a critical boundary of the underlying process, gaining valuable insight into the practical limitations of standard explicit methods. [@problem_id:3002529]", "problem": "Consider the Cox–Ingersoll–Ross process, a one-dimensional stochastic differential equation (SDE) modeling a nonnegative diffusion, defined by $dX_t = \\kappa(\\theta - X_t)\\,dt + \\sigma\\sqrt{X_t}\\,dW_t$ with parameters $\\kappa > 0$, $\\theta > 0$, and $\\sigma > 0$. The process admits a unique strong solution that remains nonnegative under conditions that are standard in the literature. Your task is to investigate whether the explicit Milstein method, when applied to this SDE, preserves the nonnegativity of the numerical solution.\n\nStarting from first principles of Itô calculus for SDEs and the Itô–Taylor expansion to strong order one, derive a one-step explicit discretization of the Milstein method for a general scalar SDE $dX_t = a(X_t)\\,dt + b(X_t)\\,dW_t$ and then specialize it to the Cox–Ingersoll–Ross model. Use the fundamental definitions and the Itô formula for expansions up to the required order, and state all assumptions clearly. Based on this derivation, analyze whether the method enforces $X_n \\ge 0$ for all discrete times $t_n$ and explain any violations of nonnegativity in terms of the structure of the drift and diffusion coefficients and the stochastic increments.\n\nImplement a program that simulates independent sample paths using the derived explicit Milstein method for specified parameter sets. For each test case, simulate $N_{\\text{paths}}$ independent paths over $[0,T]$ with uniform time step $h$, and compute the fraction of paths that ever attain a negative value (strictly less than $0$) at any time during the simulation. A path that first becomes negative should be counted as negative thereafter; do not apply any corrective modifications (such as projection, truncation, or reflection) to force nonnegativity.\n\nThe program must:\n- Use the explicit Milstein discretization derived from first principles, specialized to the Cox–Ingersoll–Ross model.\n- Use a fixed random number generator seed to ensure reproducibility. Initialize a single generator at program start with seed $2025$ and use it for all randomness.\n- Vectorize computations across paths for efficiency and handle the square root term carefully at the boundary: it is defined for $X_n \\ge 0$ and the scheme must not attempt to evaluate $\\sqrt{X_n}$ for $X_n < 0$.\n- For each path, once $X_n < 0$ occurs, mark the path as negative and cease further updates to that path; subsequent steps should leave its value unchanged and it should remain marked as negative.\n\nUse the following test suite of parameter values, designed to probe different facets of positivity:\n- Case A (general case with strong mean reversion and moderate volatility): $\\kappa = 3.0$, $\\theta = 1.0$, $\\sigma = 1.0$, $X_0 = 1.0$, $h = 0.005$, $T = 1.0$, $N_{\\text{paths}} = 5000$.\n- Case B (coarser time step to test discretization error impact): $\\kappa = 3.0$, $\\theta = 1.0$, $\\sigma = 1.0$, $X_0 = 1.0$, $h = 0.02$, $T = 1.0$, $N_{\\text{paths}} = 5000$.\n- Case C (boundary of the Feller condition $2\\kappa\\theta = \\sigma^2$): $\\kappa = 2.0$, $\\theta = 1.0$, $\\sigma = 2.0$, $X_0 = 1.0$, $h = 0.005$, $T = 1.0$, $N_{\\text{paths}} = 5000$.\n- Case D (near-zero initial state): $\\kappa = 3.0$, $\\theta = 1.0$, $\\sigma = 1.0$, $X_0 = 10^{-6}$, $h = 0.005$, $T = 1.0$, $N_{\\text{paths}} = 5000$.\n\nAll quantities are dimensionless, so no physical units are required. The output for each case must be a floating-point number equal to the fraction of paths that ever become negative, rounded to six decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[resultA,resultB,resultC,resultD]\"), where each entry corresponds respectively to Cases A, B, C, and D, rounded to six decimal places. For example, if the fractions are $0.012345$, $0.067890$, $0.000000$, and $0.123456$, the program must print \"[0.012345,0.067890,0.000000,0.123456]\".", "solution": "The problem is assessed to be valid. It is scientifically grounded in the theory of stochastic differential equations and numerical methods, is well-posed with a complete and consistent set of parameters, and uses objective, formal language. It represents a standard, non-trivial exercise in computational finance and stochastic analysis.\n\n### Derivation of the Explicit Milstein Method\n\nWe begin with a general one-dimensional Itô stochastic differential equation (SDE):\n$$\ndX_t = a(X_t) \\, dt + b(X_t) \\, dW_t\n$$\nwhere $a(X_t)$ is the drift coefficient, $b(X_t)$ is the diffusion coefficient, and $W_t$ is a standard Wiener process. The goal is to derive a numerical scheme for $X_{t_{n+1}}$ given $X_{t_n}$, where $t_{n+1} = t_n + h$ for a small time step $h > 0$.\n\nThe integral form of the SDE over the interval $[t_n, t_{n+1}]$ is:\n$$\nX_{t_{n+1}} = X_{t_n} + \\int_{t_n}^{t_{n+1}} a(X_s) \\, ds + \\int_{t_n}^{t_{n+1}} b(X_s) \\, dW_s\n$$\nThe Milstein method improves upon the Euler-Maruyama method by more accurately approximating the stochastic integral. The drift integral is approximated as in the Euler method:\n$$\n\\int_{t_n}^{t_{n+1}} a(X_s) \\, ds \\approx a(X_{t_n}) h\n$$\nFor the stochastic integral, we first apply an Itô-Taylor expansion to the integrand $b(X_s)$ around $t_n$. Using Itô's formula for the function $b(x)$, we have:\n$$\nb(X_s) = b(X_{t_n}) + \\int_{t_n}^s L^0 b(X_u) \\, du + \\int_{t_n}^s L^1 b(X_u) \\, dW_u\n$$\nwhere $L^0 = a(x)\\frac{\\partial}{\\partial x} + \\frac{1}{2}b(x)^2\\frac{\\partial^2}{\\partial x^2}$ and $L^1 = b(x)\\frac{\\partial}{\\partial x}$ are the generator operators. For a strong order $1.0$ scheme, we can approximate the integrands in the expansion of $b(X_s)$ by their values at $t_n$.\n$$\nb(X_s) \\approx b(X_{t_n}) + L^1 b(X_{t_n}) \\int_{t_n}^s dW_u = b(X_{t_n}) + b(X_{t_n}) b'(X_{t_n}) (W_s - W_{t_n})\n$$\nSubstituting this approximation into the stochastic integral:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s) \\, dW_s \\approx \\int_{t_n}^{t_{n+1}} \\left[ b(X_{t_n}) + b(X_{t_n}) b'(X_{t_n}) (W_s - W_{t_n}) \\right] \\, dW_s\n$$\n$$\n= b(X_{t_n}) \\int_{t_n}^{t_{n+1}} dW_s + b(X_{t_n}) b'(X_{t_n}) \\int_{t_n}^{t_{n+1}} (W_s - W_{t_n}) \\, dW_s\n$$\nThe first integral is the Wiener increment, $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$. The second is a standard double Itô integral, whose value is known:\n$$\n\\int_{t_n}^{t_{n+1}} (W_s - W_{t_n}) \\, dW_s = \\frac{1}{2} \\left[ (W_{t_{n+1}} - W_{t_n})^2 - (t_{n+1} - t_n) \\right] = \\frac{1}{2} \\left[ (\\Delta W_n)^2 - h \\right]\n$$\nCombining these terms, we obtain the one-step explicit Milstein discretization, using the notation $X_n = X_{t_n}$:\n$$\nX_{n+1} = X_n + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2} b(X_n) b'(X_n) \\left[ (\\Delta W_n)^2 - h \\right]\n$$\n\n### Specialization to the Cox–Ingersoll–Ross (CIR) Model\n\nThe CIR process is defined by the SDE:\n$$\ndX_t = \\kappa(\\theta - X_t) \\, dt + \\sigma\\sqrt{X_t} \\, dW_t\n$$\nComparing with the general SDE form, we identify the coefficients:\n$$\na(x) = \\kappa(\\theta - x)\n$$\n$$\nb(x) = \\sigma\\sqrt{x} = \\sigma x^{1/2}\n$$\nThe derivative of the diffusion coefficient is (for $x > 0$):\n$$\nb'(x) = \\frac{d}{dx}(\\sigma x^{1/2}) = \\frac{1}{2}\\sigma x^{-1/2} = \\frac{\\sigma}{2\\sqrt{x}}\n$$\nA key property for the CIR Milstein scheme is that the product $b(x)b'(x)$ is a constant:\n$$\nb(x)b'(x) = (\\sigma\\sqrt{x}) \\left(\\frac{\\sigma}{2\\sqrt{x}}\\right) = \\frac{\\sigma^2}{2}\n$$\nSubstituting these coefficients into the general Milstein formula, we get the scheme for the CIR model:\n$$\nX_{n+1} = X_n + \\kappa(\\theta - X_n)h + \\sigma\\sqrt{X_n}\\Delta W_n + \\frac{1}{2}\\left(\\frac{\\sigma^2}{2}\\right)\\left[ (\\Delta W_n)^2 - h \\right]\n$$\nTo implement this, we use the property that $\\Delta W_n \\sim \\mathcal{N}(0, h)$, so we can write $\\Delta W_n = \\sqrt{h}Z_n$, where $Z_n \\sim \\mathcal{N}(0, 1)$. This gives $(\\Delta W_n)^2 = h Z_n^2$. The final scheme is:\n$$\nX_{n+1} = X_n + \\kappa(\\theta - X_n)h + \\sigma\\sqrt{X_n h}Z_n + \\frac{\\sigma^2}{4}\\left[ h Z_n^2 - h \\right]\n$$\n$$\nX_{n+1} = X_n + \\kappa(\\theta - X_n)h + \\sigma\\sqrt{X_n h}Z_n + \\frac{\\sigma^2 h}{4}(Z_n^2 - 1)\n$$\nThis is the explicit Milstein discretization for the CIR process that will be implemented.\n\n### Analysis of Nonnegativity Preservation\n\nThe true solution to the CIR SDE is guaranteed to be nonnegative if the Feller condition $2\\kappa\\theta \\geq \\sigma^2$ is met. We now analyze if the numerical scheme preserves this property.\nWe can rearrange the expression for $X_{n+1}$ as a quadratic function of the standard normal random variable $Z_n$:\n$$\nX_{n+1} = \\left(\\frac{\\sigma^2 h}{4}\\right)Z_n^2 + \\left(\\sigma\\sqrt{X_n h}\\right)Z_n + \\left(X_n + \\kappa(\\theta - X_n)h - \\frac{\\sigma^2 h}{4}\\right)\n$$\nThis is a parabola in $Z_n$ of the form $AZ_n^2 + BZ_n + C$, with $A = \\frac{\\sigma^2 h}{4} > 0$. Since the parabola opens upwards, it can attain a negative value only if its minimum value is negative. The minimum of the parabola occurs at $Z_n^* = -B/(2A)$ and the minimum value is $X_{n+1}^{\\text{min}} = C - B^2/(4A)$.\n\nLet's compute this minimum value.\n- $B^2 = (\\sigma\\sqrt{X_n h})^2 = \\sigma^2 X_n h$\n- $4A = 4 \\left(\\frac{\\sigma^2 h}{4}\\right) = \\sigma^2 h$\n- $\\frac{B^2}{4A} = \\frac{\\sigma^2 X_n h}{\\sigma^2 h} = X_n$\n- $C = X_n(1 - \\kappa h) + \\kappa\\theta h - \\frac{\\sigma^2 h}{4}$\n\nThe minimum value is:\n$$\nX_{n+1}^{\\text{min}} = C - X_n = \\left(X_n(1 - \\kappa h) + \\kappa\\theta h - \\frac{\\sigma^2 h}{4}\\right) - X_n = -\\kappa h X_n + \\kappa\\theta h - \\frac{\\sigma^2 h}{4}\n$$\n$$\nX_{n+1}^{\\text{min}} = h \\left( \\kappa\\theta - \\frac{\\sigma^2}{4} - \\kappa X_n \\right)\n$$\nThe numerical solution $X_{n+1}$ can become negative if this minimum value is negative. Since $h > 0$, negativity is possible if:\n$$\n\\kappa\\theta - \\frac{\\sigma^2}{4} - \\kappa X_n < 0 \\quad \\iff \\quad X_n > \\theta - \\frac{\\sigma^2}{4\\kappa}\n$$\nThis condition reveals that for any set of parameters $(\\kappa, \\theta, \\sigma, h)$ and for a sufficiently large value of the current state $X_n$, there exists a non-zero probability (associated with the random variable $Z_n$ attaining a value close to $Z_n^*$) for the next state $X_{n+1}$ to be negative. For example, in Case A, this inequality becomes $X_n > 1 - 1/12 \\approx 0.9167$. Since the process starts at $X_0 = 1.0$, it is immediately in a region where negativity is possible.\n\nEven if $4\\kappa\\theta > \\sigma^2$, ensuring that the origin is repulsive for small $X_n$ (i.e., $X_{n+1}^{\\text{min}} > 0$ for small $X_n$), the mean-reverting nature of the process pushes $X_t$ towards $\\theta$. If $\\theta$ is in the \"negativity-possible\" region (i.e., $\\theta > \\theta - \\frac{\\sigma^2}{4\\kappa}$, which is always true), the process will spend time in this region, exposing it to the risk of becoming negative due to a large random shock.\n\nTherefore, the explicit Milstein method does not, in general, preserve the nonnegativity of the CIR process. The violation is a structural property of the scheme, where the quadratic correction term is not sufficient to counteract large negative values of the diffusion term for all possible states and random shocks.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the explicit Milstein method for the Cox-Ingersoll-Ross (CIR) process\n    to determine the fraction of paths that become negative.\n    \"\"\"\n    # Set the global seed for the random number generator for reproducibility.\n    # A single generator is initialized and used for all simulations.\n    rng = np.random.default_rng(seed=2025)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: General case with strong mean reversion and moderate volatility\n        {'label': 'A', 'kappa': 3.0, 'theta': 1.0, 'sigma': 1.0, 'X0': 1.0, 'h': 0.005, 'T': 1.0, 'N_paths': 5000},\n        # Case B: Coarser time step to test discretization error impact\n        {'label': 'B', 'kappa': 3.0, 'theta': 1.0, 'sigma': 1.0, 'X0': 1.0, 'h': 0.02, 'T': 1.0, 'N_paths': 5000},\n        # Case C: Boundary of the Feller condition 2*kappa*theta = sigma^2\n        {'label': 'C', 'kappa': 2.0, 'theta': 1.0, 'sigma': 2.0, 'X0': 1.0, 'h': 0.005, 'T': 1.0, 'N_paths': 5000},\n        # Case D: Near-zero initial state\n        {'label': 'D', 'kappa': 3.0, 'theta': 1.0, 'sigma': 1.0, 'X0': 1e-6, 'h': 0.005, 'T': 1.0, 'N_paths': 5000},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Extract parameters for the current simulation\n        kappa = case['kappa']\n        theta = case['theta']\n        sigma = case['sigma']\n        X0 = case['X0']\n        h = case['h']\n        T = case['T']\n        N_paths = case['N_paths']\n\n        num_steps = int(T / h)\n        \n        # Initialize all paths to the starting value X0\n        X = np.full(N_paths, X0, dtype=np.float64)\n        \n        # Boolean array to track paths that have ever become negative.\n        # Once a path is marked, it ceases to be updated.\n        is_negative = np.zeros(N_paths, dtype=bool)\n\n        # Pre-compute constants for efficiency\n        sqrt_h = np.sqrt(h)\n        sigma2_h_4 = 0.25 * sigma**2 * h\n        kappa_theta_h = kappa * theta * h\n        kappa_h = kappa * h\n\n        for _ in range(num_steps):\n            # A mask to select active paths (those that have not yet turned negative)\n            active_mask = ~is_negative\n            \n            # Optimization: if all paths have turned negative, we can exit the loop\n            if not np.any(active_mask):\n                break\n\n            num_active = np.sum(active_mask)\n            \n            # Current state values for only the active paths\n            X_n = X[active_mask]\n\n            # Generate standard normal random increments for active paths\n            Z = rng.standard_normal(size=num_active)\n\n            # Apply the explicit Milstein method for the CIR process:\n            # X_{n+1} = X_n + kappa*(theta - X_n)*h + sigma*sqrt(X_n)*sqrt(h)*Z + 0.25*sigma^2*h*(Z^2 - 1)\n            # The sqrt(X_n) is safe because X_n >= 0 for all active paths.\n            term_drift = kappa_theta_h - X_n * kappa_h\n            term_diffusion = sigma * np.sqrt(X_n) * sqrt_h * Z\n            term_milstein = sigma2_h_4 * (Z**2 - 1)\n            \n            X_next = X_n + term_drift + term_diffusion + term_milstein\n\n            # Update the state of the active paths in the main state array\n            X[active_mask] = X_next\n\n            # Identify any of the just-updated paths that have now become negative.\n            # Update the master 'is_negative' tracker accordingly for these paths.\n            is_negative[active_mask] = (X_next < 0)\n            \n        # After the simulation, compute the fraction of paths that ever became negative\n        fraction_negative = np.mean(is_negative)\n        results.append(fraction_negative)\n\n    # Format the final output string as a comma-separated list in brackets,\n    # with each result rounded to six decimal places.\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3002529"}, {"introduction": "In professional practice, employing a fixed time step for SDE simulations is often inefficient, as it fails to adapt to intervals where the solution is smooth or highly variable. This hands-on problem guides you through the design of a more sophisticated tool: an adaptive step-size controller. You will use an \"embedded\" pair of methods—the lower-order Euler-Maruyama and the higher-order Milstein schemes—to construct a local error estimate, which then governs the step-size selection, a cornerstone technique in modern numerical analysis. This practice bridges the gap between theoretical schemes and their implementation as robust, efficient computational algorithms. [@problem_id:3002532]", "problem": "Consider a scalar Itō Stochastic Differential Equation (SDE) of the form $\\,\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + b(X_t)\\,\\mathrm{d}W_t\\,$ where $\\,W_t\\,$ is a standard Brownian motion. Starting from the definition of an Itō SDE, the Itō–Taylor expansion, and the properties of Brownian motion increments $\\,\\Delta W \\sim \\mathcal{N}(0,h)\\,$ over a time step $\\,h>0\\,$, design a blueprint for an embedded error estimator that compares one-step Euler–Maruyama (EM) and Milstein updates to produce an acceptance decision and a proposed next time step.\n\nYour program must implement the following conceptual pipeline for a single trial step:\n- Given functions $\\,a(x)\\,$, $\\,b(x)\\,$, and the derivative $\\,b'(x)\\,$ with respect to $\\,x\\,$, construct the one-step Euler–Maruyama update and the one-step Milstein update from the Itō–Taylor expansion principles appropriate to each method.\n- Define an error estimator as the absolute difference between the two one-step updates at the same state $\\,x\\,$ and the same increment $\\,\\Delta W\\,$.\n- Scale the error by a mixed absolute–relative tolerance to form a dimensionless error metric $\\,\\varepsilon\\,$:\n$$\n\\varepsilon \\;=\\; \\frac{\\lvert y_{\\text{Milstein}} - y_{\\text{EM}} \\rvert}{a_{\\text{tol}} + r_{\\text{tol}}\\,\\lvert y_{\\text{Milstein}} \\rvert},\n$$\nwhere $\\,a_{\\text{tol}}>0\\,$ is an absolute tolerance and $\\,r_{\\text{tol}}\\ge 0\\,$ is a relative tolerance.\n- Acceptance criterion: declare the trial step accepted if $\\,\\varepsilon \\le 1\\,$ and rejected otherwise.\n- Step-size adaptation: let $\\,p\\,$ be the strong convergence order of the accepted method used to advance the solution (for the scalar commutative-noise Milstein method, take $\\,p=1\\,$). Propose a new step size\n$$\nh_{\\text{new}} \\;=\\; h \\,\\cdot\\, \\operatorname{clip}\\!\\left(\\gamma \\,\\varepsilon^{-1/p},\\, \\mathrm{fac}_{\\min},\\, \\mathrm{fac}_{\\max}\\right),\n$$\nwhere $\\,\\gamma\\in(0,1)\\,$ is a safety factor and $\\,\\operatorname{clip}(u, L, U) = \\min\\{\\max\\{u,L\\},U\\}\\,$ bounds multiplicative changes by $\\,\\mathrm{fac}_{\\min}\\,$ and $\\,\\mathrm{fac}_{\\max}\\,$.\n\nImplement the above for the specific family $\\,a(x) = \\alpha x\\,$ and $\\,b(x) = \\beta x\\,$ with constants $\\,\\alpha\\,$ and $\\,\\beta\\,$. Use the following test suite, where each case specifies $\\,(\\alpha, \\beta, x, h, a_{\\text{tol}}, r_{\\text{tol}}, \\gamma, \\mathrm{fac}_{\\min}, \\mathrm{fac}_{\\max}, z)\\,$ and the Brownian increment is prescribed deterministically by $\\,\\Delta W = \\sqrt{h}\\,z\\,$:\n\n- Case 1 (happy path, moderate noise): $\\,(0.5,\\,0.2,\\,1.0,\\,0.05,\\,10^{-3},\\,10^{-2},\\,0.9,\\,0.2,\\,5.0,\\,0.1)\\,$.\n- Case 2 (edge case, large diffusion and increment): $\\,(0.1,\\,2.5,\\,1.0,\\,0.05,\\,10^{-3},\\,10^{-2},\\,0.9,\\,0.2,\\,5.0,\\,3.0)\\,$.\n- Case 3 (boundary case, very small state and step): $\\,(0.1,\\,0.8,\\,10^{-6},\\,10^{-4},\\,10^{-8},\\,10^{-1},\\,0.9,\\,0.2,\\,5.0,\\,0.3)\\,$.\n- Case 4 (stress case, large step with negative increment): $\\,(0.1,\\,1.0,\\,1.0,\\,0.5,\\,10^{-4},\\,10^{-3},\\,0.8,\\,0.2,\\,5.0,\\,-1.0)\\,$.\n\nYour program should, for each case, compute:\n- the acceptance decision encoded as $\\,1\\,$ if accepted and $\\,0\\,$ if rejected,\n- the proposed next step size $\\,h_{\\text{new}}\\,$,\n- the dimensionless error metric $\\,\\varepsilon\\,$.\n\nFinal output format: Your program should produce a single line of output containing a comma-separated list of four lists, one per test case, each inner list in the format $[ \\text{accept}, h_{\\text{new}}, \\varepsilon ]$. For example, a line of the form $[[1,0.0623,0.54],[0,0.01,2.3],[\\dots],[\\dots]]$.", "solution": "The problem presented is valid. It is scientifically grounded in the established theory of numerical methods for stochastic differential equations (SDEs), specifically the Itō-Taylor expansion and the resultant Euler-Maruyama and Milstein schemes. The problem is well-posed, providing all necessary parameters, functions, and a deterministic setup for the Wiener increment, ensuring a unique and verifiable solution for each test case. The language is objective and precise.\n\nWe are tasked with designing and implementing an adaptive step-size control mechanism for a scalar Itō SDE of the form:\n$$\n\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + b(X_t)\\,\\mathrm{d}W_t\n$$\nwhere $W_t$ is a standard Wiener process (Brownian motion). The core of the adaptive strategy lies in comparing a lower-order numerical approximation with a higher-order one to estimate the local error of a single step.\n\nThe foundation for both the Euler-Maruyama and Milstein methods is the Itō-Taylor expansion of the process $X_t$ around time $t_n$, which gives the value at $t_{n+1} = t_n + h$:\n$$\nX_{n+1} = X_n + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2} b(X_n)b'(X_n) \\left( (\\Delta W_n)^2 - h \\right) + \\mathcal{O}(h^{3/2})\n$$\nHere, $X_n \\equiv X_{t_n}$, $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is the Wiener increment over the interval $[t_n, t_{n+1}]$, which is a random variable distributed as $\\mathcal{N}(0, h)$. The notation $b'(x)$ denotes the derivative of $b(x)$ with respect to its argument $x$.\n\nFrom this expansion, we derive two numerical schemes of different strong convergence orders:\n\n1.  **Euler-Maruyama (EM) Scheme**: This method is obtained by truncating the Itō-Taylor expansion after the stochastic integral term. It has a strong convergence order of $0.5$. The one-step update, which we denote $y_{\\text{EM}}$, from a state $x$ with step size $h$ and increment $\\Delta W$ is:\n    $$\n    y_{\\text{EM}}(x, h, \\Delta W) = x + a(x)h + b(x)\\Delta W\n    $$\n\n2.  **Milstein Scheme**: By including the next term in the expansion, we obtain the Milstein method. For scalar SDEs (where noise is always commutative), this method has a strong convergence order of $1.0$. The one-step update, $y_{\\text{Milstein}}$, is:\n    $$\n    y_{\\text{Milstein}}(x, h, \\Delta W) = x + a(x)h + b(x)\\Delta W + \\frac{1}{2}b(x)b'(x)\\left( (\\Delta W)^2 - h \\right)\n    $$\n    We can express this succinctly as $y_{\\text{Milstein}} = y_{\\text{EM}} + \\frac{1}{2}b(x)b'(x)\\left( (\\Delta W)^2 - h \\right)$.\n\nThe problem specifies the SDE for a Geometric Brownian Motion:\n$$\n\\mathrm{d}X_t = \\alpha X_t\\,\\mathrm{d}t + \\beta X_t\\,\\mathrm{d}W_t\n$$\nFrom this, we identify the drift and diffusion coefficients and the derivative of the diffusion coefficient:\n$$\na(x) = \\alpha x, \\quad b(x) = \\beta x, \\quad b'(x) = \\beta\n$$\n\nThe adaptive control mechanism employs an embedded method, where the difference between the higher-order (Milstein) and lower-order (EM) updates serves as an estimate of the local error of the lower-order method. This error estimator, $E$, is:\n$$\nE = \\lvert y_{\\text{Milstein}} - y_{\\text{EM}} \\rvert = \\left\\lvert \\frac{1}{2}b(x)b'(x)\\left( (\\Delta W)^2 - h \\right) \\right\\rvert\n$$\nFor the specific SDE, this becomes:\n$$\nE = \\left\\lvert \\frac{1}{2}(\\beta x)(\\beta)\\left( (\\Delta W)^2 - h \\right) \\right\\rvert = \\left\\lvert \\frac{1}{2}\\beta^2 x \\left( (\\Delta W)^2 - h \\right) \\right\\rvert\n$$\nThe problem deterministically prescribes the Wiener increment as $\\Delta W = \\sqrt{h}\\,z$, where $z$ is a given value. Substituting this into the error expression yields a more direct formula:\n$$\nE = \\left\\lvert \\frac{1}{2}\\beta^2 x \\left( (\\sqrt{h}z)^2 - h \\right) \\right\\rvert = \\left\\lvert \\frac{1}{2}\\beta^2 x \\left( h z^2 - h \\right) \\right\\rvert = \\left\\lvert \\frac{1}{2}\\beta^2 x h (z^2-1) \\right\\rvert\n$$\nTo make an acceptance decision, this absolute error $E$ is scaled by a mixed absolute-relative tolerance criterion, forming a dimensionless error metric $\\varepsilon$:\n$$\n\\varepsilon = \\frac{E}{a_{\\text{tol}} + r_{\\text{tol}}\\,\\lvert y_{\\text{Milstein}} \\rvert}\n$$\nwhere $a_{\\text{tol}}$ is the absolute tolerance and $r_{\\text{tol}}$ is the relative tolerance. The solution is advanced using the more accurate Milstein update, $y_{\\text{Milstein}}$. A trial step is accepted if $\\varepsilon \\le 1$ and rejected otherwise.\n\nFinally, a new step size $h_{\\text{new}}$ is proposed based on the computed error $\\varepsilon$. The formula is derived from the principle that for a method of order $p$, the error behaves as $E \\propto h^p$. To achieve a target error, the step size should be adjusted by a factor proportional to $\\varepsilon^{-1/p}$. The specified formula is:\n$$\nh_{\\text{new}} = h \\cdot \\operatorname{clip}\\!\\left(\\gamma \\,\\varepsilon^{-1/p},\\, \\mathrm{fac}_{\\min},\\, \\mathrm{fac}_{\\max}\\right)\n$$\nHere, $p$ is the strong order of the accepted method (Milstein), so $p=1$. The safety factor $\\gamma$ prevents overly optimistic step-size increases, and $\\mathrm{fac}_{\\min}, \\mathrm{fac}_{\\max}$ bound the change to maintain stability. The $\\operatorname{clip}(u, L, U)$ function constrains the value $u$ to the interval $[L, U]$. In the special case where $\\varepsilon=0$, the term $\\varepsilon^{-1/p}$ is formally infinite; the standard interpretation in this context is to increase the step size by the maximum allowed factor, $\\mathrm{fac}_{\\max}$.\n\nThe algorithm for a single trial step is as follows:\n1.  Given parameters $(\\alpha, \\beta, x, h, a_{\\text{tol}}, r_{\\text{tol}}, \\gamma, \\mathrm{fac}_{\\min}, \\mathrm{fac}_{\\max}, z)$.\n2.  Calculate the Wiener increment: $\\Delta W = \\sqrt{h}\\,z$.\n3.  Calculate the error estimate directly: $E = |\\frac{1}{2}\\beta^2 x h (z^2-1)|$.\n4.  Calculate the higher-order update: $y_{\\text{Milstein}} = x + \\alpha x h + \\beta x \\Delta W + \\frac{1}{2}\\beta^2 x h (z^2-1)$.\n5.  Calculate the dimensionless error: $\\varepsilon = E / (a_{\\text{tol}} + r_{\\text{tol}}\\,|y_{\\text{Milstein}}|)$.\n6.  Determine acceptance: `accept` is $1$ if $\\varepsilon \\le 1$, and $0$ otherwise.\n7.  Calculate the new step size $h_{\\text{new}}$ using the adaptation formula with $p=1$. If $\\varepsilon=0$, the multiplicative factor is $\\mathrm{fac}_{\\max}$.\n\nThis procedure is systematically applied to each test case provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements an adaptive step-size controller for a scalar SDE\n    based on an embedded Euler-Maruyama and Milstein method pair.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is (alpha, beta, x, h, a_tol, r_tol, gamma, fac_min, fac_max, z)\n    test_cases = [\n        (0.5, 0.2, 1.0, 0.05, 1e-3, 1e-2, 0.9, 0.2, 5.0, 0.1),\n        (0.1, 2.5, 1.0, 0.05, 1e-3, 1e-2, 0.9, 0.2, 5.0, 3.0),\n        (0.1, 0.8, 1e-6, 1e-4, 1e-8, 1e-1, 0.9, 0.2, 5.0, 0.3),\n        (0.1, 1.0, 1.0, 0.5, 1e-4, 1e-3, 0.8, 0.2, 5.0, -1.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        alpha, beta, x, h, a_tol, r_tol, gamma, fac_min, fac_max, z = case\n\n        # The strong convergence order of the Milstein method (scalar commutative case)\n        p = 1.0\n\n        # Calculate the deterministic Wiener increment\n        delta_W = np.sqrt(h) * z\n\n        # The term that differentiates Milstein from Euler-Maruyama\n        # This is also the local error estimate before taking the absolute value.\n        # E = |milstein_term|\n        milstein_correction = 0.5 * beta**2 * x * (delta_W**2 - h)\n        # Note: delta_W**2 - h = (sqrt(h)*z)**2 - h = h*z**2 - h = h * (z**2 - 1)\n        # So, milstein_correction = 0.5 * beta**2 * x * h * (z**2 - 1)\n        \n        # Absolute error estimator\n        error_est = np.abs(milstein_correction)\n\n        # Calculate the one-step Euler-Maruyama update\n        y_em = x + alpha * x * h + beta * x * delta_W\n        \n        # Calculate the one-step Milstein update by adding the correction term\n        y_milstein = y_em + milstein_correction\n        \n        # Calculate the dimensionless error metric epsilon\n        # Handle the case where the denominator could be zero, though unlikely with a_tol > 0\n        tolerance_scale = a_tol + r_tol * np.abs(y_milstein)\n        if tolerance_scale == 0:\n            # If both error and tolerance are zero, error is controlled.\n            # If error is non-zero and tolerance is zero, error is infinite.\n            epsilon = 0.0 if error_est == 0.0 else np.inf\n        else:\n            epsilon = error_est / tolerance_scale\n\n        # Acceptance criterion\n        accept = 1 if epsilon <= 1.0 else 0\n\n        # Step-size adaptation\n        if epsilon == 0.0:\n            # If error is zero, increase step size by the maximum factor\n            scaling_factor = fac_max\n        else:\n            # Standard PI controller-based step size adaptation\n            raw_scaling_factor = gamma * (epsilon**(-1.0 / p))\n            scaling_factor = np.clip(raw_scaling_factor, fac_min, fac_max)\n        \n        h_new = h * scaling_factor\n\n        results.append([accept, h_new, epsilon])\n\n    # Final print statement in the exact required format.\n    # Convert each inner list to its string representation and join with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3002532"}]}