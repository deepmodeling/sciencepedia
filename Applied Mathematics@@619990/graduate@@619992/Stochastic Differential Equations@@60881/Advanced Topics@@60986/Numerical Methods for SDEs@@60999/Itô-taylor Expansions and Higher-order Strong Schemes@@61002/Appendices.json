{"hands_on_practices": [{"introduction": "Before constructing higher-order schemes, it is essential to understand how their accuracy is formally measured. The concept of local strong error provides the theoretical foundation, quantifying the error made in a single step of a numerical method. This exercise challenges you to select the precise mathematical definition of local strong error, focusing on the roles of conditional expectation, dependence on the starting state, and the critical link between the truncation level of the Itô-Taylor series and the resulting order of accuracy [@problem_id:2982894].", "problem": "Consider a $d$-dimensional Itô stochastic differential equation (SDE) of the form\n$$\n\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + \\sum_{j=1}^m b^{(j)}(X_t)\\,\\mathrm{d}W_t^{(j)}, \\quad X_0 = x_0,\n$$\nwhere $a:\\mathbb{R}^d\\to\\mathbb{R}^d$ and $b^{(j)}:\\mathbb{R}^d\\to\\mathbb{R}^d$ are sufficiently smooth with polynomial growth bounds, and $\\{W_t^{(j)}\\}_{j=1}^m$ are independent components of a standard $m$-dimensional Brownian motion adapted to a filtration $\\{\\mathcal{F}_t\\}_{t\\ge 0}$. Let $\\widehat{X}_{t+h}$ denote a one-step numerical approximation computed from $X_t$ by truncating the Itô–Taylor expansion to include all terms up to a prescribed generalized order $r$, where the generalized order of a multiple integral is defined as the sum of $1$ for each $\\mathrm{d}t$ and $1/2$ for each $\\mathrm{d}W$ encountered in that integral.\n\nIn the context of strong convergence, the local strong error is often summarized informally as $\\|X_{t+h}-\\widehat{X}_{t+h}\\|_{L^p} = O(h^{p^\\ast})$. Choose the option that states a precise and correct version of this local strong error definition, including the correct quantifiers, the role of conditional moments with respect to $\\mathcal{F}_t$, the dependence on $X_t$, and the connection between the exponent $p^\\ast$ and the truncation of the Itô–Taylor series.\n\nA. For any fixed horizon $T>0$ and any $p\\ge 2$, there exist constants $h_0>0$, $C>0$, and a nonnegative integer $q$ such that for all $t\\in[0,T-h]$, all $h\\in(0,h_0]$, and almost surely,\n$$\n\\Big(\\mathbb{E}\\big[\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert^p \\,\\big|\\, \\mathcal{F}_t\\big]\\Big)^{1/p} \\le C\\big(1+\\lvert X_t\\rvert^q\\big)\\,h^{p^\\ast}.\n$$\nMoreover, if $\\widehat{X}_{t+h}$ is constructed by truncating the Itô–Taylor expansion at generalized order $r$, then $p^\\ast$ equals the minimal generalized order among the neglected terms; in particular, if all terms up to order $r$ are included, then $p^\\ast=r+\\tfrac{1}{2}$.\n\nB. For any fixed horizon $T>0$ and any $p\\ge 2$, there exists $C>0$ such that for all $t\\in[0,T-h]$ and all $h>0$ sufficiently small,\n$$\n\\|X_{t+h}-\\widehat{X}_{t+h}\\|_{L^p} \\le C\\,h^{p^\\ast},\n$$\nwhere $p^\\ast=r$ is the generalized order used in the truncation. The bound is uniform and independent of $X_t$ due to the Markov property of $X_t$.\n\nC. For any fixed horizon $T>0$, the local strong error is a pathwise quantity satisfying for all $t\\in[0,T-h]$ and all $h>0$ sufficiently small,\n$$\n\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert \\le C\\,h^{p^\\ast} \\quad \\text{almost surely},\n$$\nwith $p^\\ast$ equal to the number of $\\mathrm{d}t$ integrals in the first neglected term of the Itô–Taylor expansion.\n\nD. The correct notion of local strong error is the global-in-time bound\n$$\n\\sup_{0\\le n\\le N}\\|X_{t_n}-\\widehat{X}_{t_n}\\|_{L^p} \\le C\\,h^{p^\\ast},\n$$\nwith $t_n=nh$, which holds whenever the Itô–Taylor series is truncated at order $r=p^\\ast$. Conditional expectations are not needed because $\\Delta W$ is independent of $\\mathcal{F}_t$.\n\nE. The precise local strong error definition mirrors the deterministic ordinary differential equation case: for any $p\\ge 2$, there exists $C>0$ such that\n$$\n\\Big(\\mathbb{E}\\big[\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert^p\\big]\\Big)^{1/p} \\le C\\,h^{p^\\ast},\n$$\nwith $p^\\ast = r+1$. This follows because truncating at order $r$ leaves a remainder of order $h^{r+1}$, independent of stochastic integrals.", "solution": "The user wants me to act as a STEM professor and critically validate a problem concerning the definition of local strong error for numerical schemes for stochastic differential equations (SDEs), and then to solve it.\n\n### Problem Validation\n\nI will first perform a critical validation of the problem statement, excluding the options.\n\n#### Step 1: Extract Givens\n\n-   **SDE:** A $d$-dimensional Itô SDE is given by $\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + \\sum_{j=1}^m b^{(j)}(X_t)\\,\\mathrm{d}W_t^{(j)}$, with initial condition $X_0 = x_0$.\n-   **Coefficients:** The drift $a:\\mathbb{R}^d\\to\\mathbb{R}^d$ and diffusion coefficients $b^{(j)}:\\mathbb{R}^d\\to\\mathbb{R}^d$ are sufficiently smooth with polynomial growth bounds.\n-   **Wiener Process:** $\\{W_t^{(j)}\\}_{j=1}^m$ are independent components of a standard $m$-dimensional Brownian motion adapted to a filtration $\\{\\mathcal{F}_t\\}_{t\\ge 0}$.\n-   **Numerical Scheme:** $\\widehat{X}_{t+h}$ is a one-step numerical approximation computed from $X_t$, obtained by truncating the Itô–Taylor expansion.\n-   **Truncation Rule:** The truncation includes all terms up to a prescribed generalized order $r$.\n-   **Generalized Order Definition:** The generalized order of a multiple integral is the sum of $1$ for each $\\mathrm{d}t$ and $1/2$ for each $\\mathrm{d}W$ in the integral.\n-   **Objective:** The question asks to identify the precise and correct definition of the local strong error, often summarized as $\\|X_{t+h}-\\widehat{X}_{t+h}\\|_{L^p} = O(h^{p^\\ast})$, specifying the quantifiers, the role of conditional moments, the dependence on $X_t$, and the connection between the exponent $p^\\ast$ and the truncation order $r$.\n\n#### Step 2: Validate Using Extracted Givens\n\n-   **Scientifically Grounded:** The problem is firmly rooted in the established theory of numerical analysis for SDEs. The Itô process, Itô-Taylor expansions, strong convergence, and the definition of generalized order are standard and central concepts in this field (cf. Kloeden & Platen, \"Numerical Solution of Stochastic Differential Equations\"). The assumptions on the coefficients are standard to guarantee existence, uniqueness, and moment properties of the solution, which are prerequisite for error analysis.\n-   **Well-Posed:** The question is well-posed. It asks for the correct theoretical definition of a fundamental concept (local strong error), which is uniquely defined within the mathematical literature on the subject.\n-   **Objective:** The language is formal, precise, and objective, using standard mathematical terminology without ambiguity or subjective content.\n-   **Overall Assessment:** The problem statement is free from any of the invalidating flaws. It is scientifically sound, self-contained, and poses a clear, non-trivial question about a core concept in its specified domain.\n\n#### Step 3: Verdict and Action\n\nThe problem statement is **valid**. I will proceed with the derivation and solution.\n\n### Derivation and Solution\n\nThe primary task is to identify the correct, formal definition of the local strong error for a one-step numerical method applied to an SDE. The local strong error quantifies the error incurred in a single time step of size $h$, assuming the method starts from the exact solution $X_t$ at time $t$.\n\n**1. Form of the Error Bound: Conditional Moments**\n\nThe error in one step is the random variable $X_{t+h} - \\widehat{X}_{t+h}$. At time $t$, the state of the system, $X_t$, is known and belongs to the information set represented by the sigma-algebra $\\mathcal{F}_t$. The error over the interval $[t, t+h]$ is driven by the increments of the Wiener process, $\\{\\Delta W^{(j)} = W_{t+h}^{(j)} - W_t^{(j)}\\}_{j=1}^m$, which are independent of $\\mathcal{F}_t$.\n\nA complete characterization of the error's magnitude, given the starting state $X_t$, is achieved by taking the expectation conditional on $\\mathcal{F}_t$. Strong convergence concerns moments of the error, so we consider the $p$-th conditional moment, $\\mathbb{E}\\big[\\lvert X_{t+h} - \\widehat{X}_{t+h} \\rvert^p \\,\\big|\\, \\mathcal{F}_t\\big]$, for some $p \\ge 1$ (typically $p \\ge 2$). The local strong error is then expressed in terms of the $L^p(\\mathcal{F}_t)$-norm: $\\left(\\mathbb{E}\\big[\\lvert X_{t+h} - \\widehat{X}_{t+h} \\rvert^p \\,\\big|\\, \\mathcal{F}_t\\big]\\right)^{1/p}$.\n\nBecause the coefficients $a$ and $b^{(j)}$ depend on the state $X_t$, the magnitude of this conditional moment will naturally depend on $X_t$. The standard assumption of polynomial growth on the coefficients leads to a bound on the local error that also exhibits polynomial growth in $\\lvert X_t \\rvert$. This is typically expressed by a factor of the form $C(1+\\lvert X_t \\rvert^q)$ for some constants $C > 0$ and $q \\ge 0$.\n\nTherefore, the correct form of a local strong error bound is:\n$$\n\\Big(\\mathbb{E}\\big[\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert^p \\,\\big|\\, \\mathcal{F}_t\\big]\\Big)^{1/p} \\le C\\big(1+\\lvert X_t\\rvert^q\\big)\\,h^{p^\\ast}\n$$\nThis inequality must hold for all sufficiently small step sizes $h \\in (0, h_0]$ and for all $t$ in a compact time interval, e.g., $t \\in [0, T-h]$.\n\n**2. The Error Exponent $p^\\ast$ and Itô-Taylor Expansions**\n\nThe numerical scheme $\\widehat{X}_{t+h}$ is formed by truncating the Itô-Taylor expansion of the true solution $X_{t+h}$. The error, $X_{t+h} - \\widehat{X}_{t+h}$, is precisely the remainder of this expansion. The order of the error is determined by the leading terms in this remainder.\n\nThe problem states that the scheme includes all terms up to a generalized order $r$. The generalized order of a multiple stochastic integral is $n_0 + n_1/2$, where $n_0$ is the number of integrations with respect to time ($\\mathrm{d}s$) and $n_1$ is the number of integrations with respect to the Wiener process ($\\mathrm{d}W$).\n\nThe $p$-th moment of a multiple stochastic integral with generalized order $\\delta$ is of order $O(h^{p\\delta})$. Consequently, its $L^p$-norm is of order $O(h^\\delta)$.\n\nIf the Itô-Taylor expansion is truncated at generalized order $r$, the remainder consists of all multiple integrals with generalized order greater than $r$. The magnitude of the remainder is dominated by the terms with the smallest generalized order. The smallest possible increment in generalized order is $1/2$, which corresponds to adding an additional integration with respect to a Wiener process. Thus, the minimal generalized order of a neglected term is $r+1/2$.\n\nTherefore, the local error exponent $p^\\ast$ is equal to the minimal generalized order of the terms in the remainder, which is $p^\\ast = r + 1/2$.\nIt is a standard result that a scheme constructed by including all terms of generalized order up to $r$ has a *global* strong order of convergence of $\\gamma = r$. The relationship between the local error exponent $p^\\ast$ and the global strong order $\\gamma$ is thus $p^\\ast = \\gamma + 1/2$.\n\n### Option-by-Option Analysis\n\nBased on the above derivation, I will now evaluate each option.\n\n**A. For any fixed horizon $T>0$ and any $p\\ge 2$, there exist constants $h_0>0$, $C>0$, and a nonnegative integer $q$ such that for all $t\\in[0,T-h]$, all $h\\in(0,h_0]$, and almost surely,\n$$\n\\Big(\\mathbb{E}\\big[\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert^p \\,\\big|\\, \\mathcal{F}_t\\big]\\Big)^{1/p} \\le C\\big(1+\\lvert X_t\\rvert^q\\big)\\,h^{p^\\ast}.\n$$\nMoreover, if $\\widehat{X}_{t+h}$ is constructed by truncating the Itô–Taylor expansion at generalized order $r$, then $p^\\ast$ equals the minimal generalized order among the neglected terms; in particular, if all terms up to order $r$ are included, then $p^\\ast=r+\\tfrac{1}{2}$.**\n\n-   **Form of the Bound:** The expression is exactly the correct form for a local strong error bound. It correctly uses the conditional expectation w.r.t. $\\mathcal{F}_t$, includes the polynomial growth factor $C(1+\\lvert X_t\\rvert^q)$, and specifies the necessary quantifiers for the constants and time variables.\n-   **Exponent $p^\\ast$:** The explanation for $p^\\ast$ is flawless. It correctly identifies $p^\\ast$ as the minimal generalized order of the neglected terms and correctly deduces that for a truncation at order $r$, this minimal order is $r+1/2$.\n-   **Verdict:** **Correct**. This option provides a complete and precise statement of the local strong error definition and its relation to Itô-Taylor schemes.\n\n**B. For any fixed horizon $T>0$ and any $p\\ge 2$, there exists $C>0$ such that for all $t\\in[0,T-h]$ and all $h>0$ sufficiently small,\n$$\n\\|X_{t+h}-\\widehat{X}_{t+h}\\|_{L^p} \\le C\\,h^{p^\\ast},\n$$\nwhere $p^\\ast=r$ is the generalized order used in the truncation. The bound is uniform and independent of $X_t$ due to the Markov property of $X_t$.**\n\n-   **Form of the Bound:** It uses an unconditional expectation $\\| \\cdot \\|_{L^p} = (\\mathbb{E}[\\cdot])^{1/p}$. This is not the fundamental definition of local error, which is conditioned on the starting state. Furthermore, it incorrectly claims the bound is independent of $X_t$; the Markov property does not imply this.\n-   **Exponent $p^\\ast$:** It incorrectly states $p^\\ast = r$. This would imply Local Order = Global Order, which is false. As derived, $p^\\ast = r+1/2$.\n-   **Verdict:** **Incorrect**.\n\n**C. For any fixed horizon $T>0$, the local strong error is a pathwise quantity satisfying for all $t\\in[0,T-h]$ and all $h>0$ sufficiently small,\n$$\n\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert \\le C\\,h^{p^\\ast} \\quad \\text{almost surely},\n$$\nwith $p^\\ast$ equal to the number of $\\mathrm{d}t$ integrals in the first neglected term of the Itô–Taylor expansion.**\n\n-   **Form of the Bound:** This describes a pathwise (almost sure) error bound, not a strong (moment-based) error bound. Strong convergence is, by definition, convergence in $L^p$. Pathwise convergence rates are generally different and weaker due to the fractal nature of Brownian paths (e.g., law of the iterated logarithm).\n-   **Exponent $p^\\ast$:** The definition of $p^\\ast$ is wrong. It completely ignores the contribution from stochastic integrals ($\\mathrm{d}W$), which are often the dominant source of error.\n-   **Verdict:** **Incorrect**.\n\n**D. The correct notion of local strong error is the global-in-time bound\n$$\n\\sup_{0\\le n\\le N}\\|X_{t_n}-\\widehat{X}_{t_n}\\|_{L^p} \\le C\\,h^{p^\\ast},\n$$\nwith $t_n=nh$, which holds whenever the Itô–Taylor series is truncated at order $r=p^\\ast$. Conditional expectations are not needed because $\\Delta W$ is independent of $\\mathcal{F}_t$.**\n\n-   **Local vs. Global:** This expression defines a *global* strong error, not the *local* strong error requested in the problem.\n-   **Justification:** The justification for omitting conditional expectations is flawed. The independence of increments is precisely the reason why conditional expectation is the correct tool for analyzing a single step.\n-   **Exponent $p^\\ast$:** It incorrectly sets the local exponent $p^\\ast$ equal to the truncation order $r$.\n-   **Verdict:** **Incorrect**.\n\n**E. The precise local strong error definition mirrors the deterministic ordinary differential equation case: for any $p\\ge 2$, there exists $C>0$ such that\n$$\n\\Big(\\mathbb{E}\\big[\\lvert X_{t+h}-\\widehat{X}_{t+h}\\rvert^p\\big]\\Big)^{1/p} \\le C\\,h^{p^\\ast},\n$$\nwith $p^\\ast = r+1$. This follows because truncating at order $r$ leaves a remainder of order $h^{r+1}$, independent of stochastic integrals.**\n\n-   **Analogy and Form:** The analogy to ODEs is misleading. It incorrectly leads to an unconditional expectation and, more importantly, the wrong exponent. The claim that the remainder is independent of stochastic integrals is fundamentally false.\n-   **Exponent $p^\\ast$:** It incorrectly states $p^\\ast = r+1$. This is the rule for standard ODE solvers (Local Order = Global Order + 1). For SDEs, the relationship is $p^\\ast = r+1/2$ (Local Exponent = Global Order + 1/2) because of the different scaling of stochastic integrals.\n-   **Verdict:** **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "2982894"}, {"introduction": "The Itô-Taylor expansion provides a systematic way to represent the solution of an SDE through a series of increasingly complex terms. These terms are composed of multiple stochastic integrals multiplied by coefficient functions, which are generated by applying specific differential operators, denoted $L^0$ and $L^k$, to the drift and diffusion functions of the SDE. This practice provides direct, hands-on experience in calculating these essential operator applications for a concrete multi-dimensional SDE and determining their relevance for a strong order $1.5$ scheme [@problem_id:2982869].", "problem": "Consider the two-dimensional Itô stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + \\sum_{k=1}^{2} b^{(k)}(X_{t})\\,\\mathrm{d}W_{t}^{(k)},\n$$\nwhere $X_{t} \\in \\mathbb{R}^{2}$, $W^{(1)}$ and $W^{(2)}$ are independent standard Wiener processes (Brownian motions), and the coefficient functions are\n$$\na(x) = \\begin{pmatrix} a_{1}(x) \\\\ a_{2}(x) \\end{pmatrix} = \\begin{pmatrix} x_{1} + x_{2}^{2} \\\\ x_{1}x_{2} \\end{pmatrix},\\quad\nb^{(1)}(x) = \\begin{pmatrix} x_{1}^{2} \\\\ \\ln(1 + x_{2}^{2}) \\end{pmatrix},\\quad\nb^{(2)}(x) = \\begin{pmatrix} x_{1}x_{2} \\\\ \\exp(x_{1}) \\end{pmatrix}.\n$$\nHere $\\ln$ denotes the natural logarithm and $\\exp$ denotes the exponential function. Using the Itô-Taylor expansion framework for strong schemes, compute the operator applications $L^{0}b^{(1)}(x)$, $L^{0}b^{(2)}(x)$, $L^{1}a(x)$, and $L^{2}a(x)$ at a general point $x = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$. Then, based on the index-weight structure of multiple Itô integrals used in strong schemes, indicate for each of these four operator applications whether it contributes to strong order $1.5$ schemes.\n\nExpress your final answer as a single row matrix\n$$\n\\begin{pmatrix}\n(L^{0}b^{(1)}(x))_{1} & (L^{0}b^{(1)}(x))_{2} & (L^{0}b^{(2)}(x))_{1} & (L^{0}b^{(2)}(x))_{2} & (L^{1}a(x))_{1} & (L^{1}a(x))_{2} & (L^{2}a(x))_{1} & (L^{2}a(x))_{2} & I_{L^{0}b^{(1)}} & I_{L^{0}b^{(2)}} & I_{L^{1}a} & I_{L^{2}a}\n\\end{pmatrix},\n$$\nwhere each $I_{\\cdot}$ is an indicator taking value $1$ if the corresponding term contributes to strong order $1.5$ and $0$ otherwise. No numerical rounding is required; provide exact symbolic expressions. No physical units are involved.", "solution": "The user has provided a valid problem statement from the field of numerical analysis of stochastic differential equations. The task is to compute several operator applications within the Itô-Taylor expansion framework and to determine their relevance for strong schemes of order $1.5$.\n\n### Step 1: Definition of Itô-Taylor Operators\n\nFor a general $d$-dimensional Itô SDE with $m$ independent Wiener processes,\n$$\n\\mathrm{d}X_t = a(X_t) \\mathrm{d}t + \\sum_{k=1}^m b^{(k)}(X_t) \\mathrm{d}W_t^{(k)}\n$$\nthe Itô-Taylor expansion employs the operators $L^0, L^1, \\dots, L^m$. For a sufficiently smooth scalar function $f: \\mathbb{R}^d \\to \\mathbb{R}$, these operators are defined as:\n$$\nL^0 f(x) = \\sum_{i=1}^d a_i(x) \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i,j=1}^d \\left( \\sum_{k=1}^m b_i^{(k)}(x) b_j^{(k)}(x) \\right) \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x)\n$$\n$$\nL^k f(x) = \\sum_{i=1}^d b_i^{(k)}(x) \\frac{\\partial f}{\\partial x_i}(x), \\quad \\text{for } k=1, \\dots, m\n$$\nWhen applied to a vector-valued function, the operator is applied to each component of the function. For the operators $L^k$ with $k \\ge 1$, this can be written concisely using the Jacobian matrix. If $g(x)$ is a vector-valued function, its Jacobian is $(\\nabla g)_{ij} = \\frac{\\partial g_i}{\\partial x_j}$, and we have $L^k g(x) = (\\nabla g(x)) b^{(k)}(x)$.\n\nIn this problem, the dimension is $d=2$ and the number of Wiener processes is $m=2$. The point is $x = (x_1, x_2)^T$. The coefficients are:\n$$\na(x) = \\begin{pmatrix} x_{1} + x_{2}^{2} \\\\ x_{1}x_{2} \\end{pmatrix}, \\quad\nb^{(1)}(x) = \\begin{pmatrix} x_{1}^{2} \\\\ \\ln(1 + x_{2}^{2}) \\end{pmatrix}, \\quad\nb^{(2)}(x) = \\begin{pmatrix} x_{1}x_{2} \\\\ \\exp(x_{1}) \\end{pmatrix}\n$$\n\n### Step 2: Calculation of Operator Applications\n\nWe compute the required terms: $L^0 b^{(1)}(x)$, $L^0 b^{(2)}(x)$, $L^1 a(x)$, and $L^2 a(x)$.\n\n**Calculation of $L^1 a(x)$ and $L^2 a(x)$**\n\nFirst, we find the Jacobian of $a(x)$:\n$$\n\\nabla a(x) =\n\\begin{pmatrix}\n\\frac{\\partial a_1}{\\partial x_1} & \\frac{\\partial a_1}{\\partial x_2} \\\\\n\\frac{\\partial a_2}{\\partial x_1} & \\frac{\\partial a_2}{\\partial x_2}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 2x_2 \\\\\nx_2 & x_1\n\\end{pmatrix}\n$$\nNow we can compute $L^1 a(x)$ and $L^2 a(x)$:\n$$\nL^1 a(x) = (\\nabla a(x)) b^{(1)}(x) = \\begin{pmatrix} 1 & 2x_2 \\\\ x_2 & x_1 \\end{pmatrix} \\begin{pmatrix} x_1^2 \\\\ \\ln(1+x_2^2) \\end{pmatrix} = \\begin{pmatrix} x_1^2 + 2x_2 \\ln(1+x_2^2) \\\\ x_1^2 x_2 + x_1 \\ln(1+x_2^2) \\end{pmatrix}\n$$\n$$\nL^2 a(x) = (\\nabla a(x)) b^{(2)}(x) = \\begin{pmatrix} 1 & 2x_2 \\\\ x_2 & x_1 \\end{pmatrix} \\begin{pmatrix} x_1 x_2 \\\\ \\exp(x_1) \\end{pmatrix} = \\begin{pmatrix} x_1 x_2 + 2x_2 \\exp(x_1) \\\\ x_1 x_2^2 + x_1 \\exp(x_1) \\end{pmatrix}\n$$\n\n**Calculation of $L^0 b^{(1)}(x)$**\n\nWe apply the operator $L^0$ to each component of $b^{(1)}(x)$.\nFor the first component, $f(x) = b_1^{(1)}(x) = x_1^2$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = 2x_1$, $\\frac{\\partial f}{\\partial x_2} = 0$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_1^2} = 2$, all other second partials are zero.\nApplying the $L^0$ formula:\n$$\n(L^0 b^{(1)})_1 = a_1 \\frac{\\partial f}{\\partial x_1} + a_2 \\frac{\\partial f}{\\partial x_2} + \\frac{1}{2} \\left( (b_1^{(1)})^2 + (b_1^{(2)})^2 \\right) \\frac{\\partial^2 f}{\\partial x_1^2}\n$$\n$$\n(L^0 b^{(1)})_1 = (x_1+x_2^2)(2x_1) + (x_1 x_2)(0) + \\frac{1}{2} \\left( (x_1^2)^2 + (x_1 x_2)^2 \\right)(2)\n$$\n$$\n(L^0 b^{(1)})_1 = 2x_1^2 + 2x_1 x_2^2 + x_1^4 + x_1^2 x_2^2 = x_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2\n$$\nFor the second component, $f(x) = b_2^{(1)}(x) = \\ln(1+x_2^2)$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = 0$, $\\frac{\\partial f}{\\partial x_2} = \\frac{2x_2}{1+x_2^2}$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_2^2} = \\frac{2(1+x_2^2) - 2x_2(2x_2)}{(1+x_2^2)^2} = \\frac{2-2x_2^2}{(1+x_2^2)^2}$, all other second partials are zero.\nApplying the $L^0$ formula:\n$$\n(L^0 b^{(1)})_2 = a_1 \\frac{\\partial f}{\\partial x_1} + a_2 \\frac{\\partial f}{\\partial x_2} + \\frac{1}{2} \\left( (b_2^{(1)})^2 + (b_2^{(2)})^2 \\right) \\frac{\\partial^2 f}{\\partial x_2^2}\n$$\n$$\n(L^0 b^{(1)})_2 = (x_1+x_2^2)(0) + (x_1 x_2) \\left(\\frac{2x_2}{1+x_2^2}\\right) + \\frac{1}{2} \\left( (\\ln(1+x_2^2))^2 + (\\exp(x_1))^2 \\right) \\left(\\frac{2-2x_2^2}{(1+x_2^2)^2}\\right)\n$$\n$$\n(L^0 b^{(1)})_2 = \\frac{2x_1 x_2^2}{1+x_2^2} + \\frac{(1-x_2^2) \\left( (\\ln(1+x_2^2))^2 + \\exp(2x_1) \\right)}{(1+x_2^2)^2}\n$$\n\n**Calculation of $L^0 b^{(2)}(x)$**\n\nWe apply the operator $L^0$ to each component of $b^{(2)}(x)$.\nFor the first component, $f(x) = b_1^{(2)}(x) = x_1 x_2$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = x_2$, $\\frac{\\partial f}{\\partial x_2} = x_1$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} = 1$, all other second partials are zero.\nThe formula for $L^0$ with a non-zero mixed partial is:\n$$\nL^0 f = \\sum_i a_i \\frac{\\partial f}{\\partial x_i} + \\sum_{k=1}^m \\left( b_1^{(k)} b_2^{(k)} \\right) \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2}\n$$\n$$\n(L^0 b^{(2)})_1 = a_1(x_2) + a_2(x_1) + \\left( b_1^{(1)} b_2^{(1)} + b_1^{(2)} b_2^{(2)} \\right)(1)\n$$\n$$\n(L^0 b^{(2)})_1 = (x_1+x_2^2)x_2 + (x_1 x_2)x_1 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)\n$$\n$$\n(L^0 b^{(2)})_1 = x_1 x_2 + x_2^3 + x_1^2 x_2 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)\n$$\nFor the second component, $f(x) = b_2^{(2)}(x) = \\exp(x_1)$:\n- First derivatives: $\\frac{\\partial f}{\\partial x_1} = \\exp(x_1)$, $\\frac{\\partial f}{\\partial x_2} = 0$.\n- Second derivatives: $\\frac{\\partial^2 f}{\\partial x_1^2} = \\exp(x_1)$, all other second partials are zero.\nApplying the $L^0$ formula:\n$$\n(L^0 b^{(2)})_2 = a_1 \\frac{\\partial f}{\\partial x_1} + \\frac{1}{2} \\left( (b_1^{(1)})^2 + (b_1^{(2)})^2 \\right) \\frac{\\partial^2 f}{\\partial x_1^2}\n$$\n$$\n(L^0 b^{(2)})_2 = (x_1+x_2^2)\\exp(x_1) + \\frac{1}{2} \\left( (x_1^2)^2 + (x_1 x_2)^2 \\right) \\exp(x_1)\n$$\n$$\n(L^0 b^{(2)})_2 = \\left( x_1 + x_2^2 + \\frac{1}{2}x_1^4 + \\frac{1}{2}x_1^2 x_2^2 \\right)\\exp(x_1)\n$$\n\n### Step 3: Contribution to Strong Order 1.5 Schemes\n\nThe strong Itô-Taylor expansion expresses the solution $X_t$ as a sum of terms of the form $f_\\alpha(X_0) I_\\alpha$, where $I_\\alpha$ is a multiple Itô integral corresponding to a multi-index $\\alpha = (j_1, j_2, \\dots, j_\\ell)$ with $j_i \\in \\{0, 1, \\dots, m\\}$. The coefficient functions $f_\\alpha$ are generated by nested applications of the operators $L^j$. For a numerical scheme to achieve a strong order of convergence $\\gamma$, it must correctly approximate all terms in the expansion for which the order of the integral $I_\\alpha$ is less than or equal to $\\gamma$. The order of $I_\\alpha$ is given by $\\text{ord}(I_\\alpha) = \\frac{\\ell}{2} + \\frac{n_0}{2}$, where $\\ell$ is the length of the multi-index and $n_0$ is the number of zeros it contains.\n\nWe are interested in strong order $\\gamma = 1.5$. We need to identify which of the calculated operators correspond to integrals with order $\\le 1.5$.\nThe terms we have computed are coefficients of the following multiple integrals:\n- $L^0 b^{(k)}(x)$ is the coefficient of $I_{(0,k)}$ for $k \\in \\{1, 2\\}$. The multi-index is $\\alpha = (0,k)$, so $\\ell=2$ and $n_0=1$. The order is $\\frac{2}{2} + \\frac{1}{2} = 1.5$. Since $1.5 \\le 1.5$, these terms contribute. Thus, $I_{L^0 b^{(1)}} = 1$ and $I_{L^0 b^{(2)}} = 1$.\n- $L^k a(x)$ is the coefficient of $I_{(k,0)}$ for $k \\in \\{1, 2\\}$. The multi-index is $\\alpha = (k,0)$, so $\\ell=2$ and $n_0=1$. The order is $\\frac{2}{2} + \\frac{1}{2} = 1.5$. Since $1.5 \\le 1.5$, these terms contribute. Thus, $I_{L^1 a} = 1$ and $I_{L^2 a} = 1$.\n\nAll four computed operator applications are necessary for constructing a strong order $1.5$ scheme.\n\n### Step 4: Final Answer Assembly\n\nWe assemble the 12 required components into a single row matrix as specified.\n1.  $(L^{0}b^{(1)})_1 = x_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2$\n2.  $(L^{0}b^{(1)})_2 = \\frac{2x_1 x_2^2}{1+x_2^2} + \\frac{(1-x_2^2)(\\exp(2x_1) + (\\ln(1+x_2^2))^2)}{(1+x_2^2)^2}$\n3.  $(L^{0}b^{(2)})_1 = x_1 x_2 + x_2^3 + x_1^2 x_2 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1)$\n4.  $(L^{0}b^{(2)})_2 = \\left( x_1 + x_2^2 + \\frac{1}{2}x_1^4 + \\frac{1}{2}x_1^2 x_2^2 \\right)\\exp(x_1)$\n5.  $(L^{1}a)_1 = x_1^2 + 2x_2 \\ln(1+x_2^2)$\n6.  $(L^{1}a)_2 = x_1^2 x_2 + x_1 \\ln(1+x_2^2)$\n7.  $(L^{2}a)_1 = x_1 x_2 + 2x_2 \\exp(x_1)$\n8.  $(L^{2}a)_2 = x_1 x_2^2 + x_1 \\exp(x_1)$\n9.  $I_{L^{0}b^{(1)}} = 1$\n10. $I_{L^{0}b^{(2)}} = 1$\n11. $I_{L^{1}a} = 1$\n12. $I_{L^{2}a} = 1$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx_1^4 + 2x_1^2 + x_1^2 x_2^2 + 2x_1 x_2^2 & \\frac{2x_1 x_2^2}{1+x_2^2} + \\frac{(1-x_2^2)(\\exp(2x_1) + (\\ln(1+x_2^2))^2)}{(1+x_2^2)^2} & x_1 x_2 + x_2^3 + x_1^2 x_2 + x_1^2 \\ln(1+x_2^2) + x_1 x_2 \\exp(x_1) & \\left( x_1 + x_2^2 + \\frac{1}{2}x_1^4 + \\frac{1}{2}x_1^2 x_2^2 \\right)\\exp(x_1) & x_1^2 + 2x_2 \\ln(1+x_2^2) & x_1^2 x_2 + x_1 \\ln(1+x_2^2) & x_1 x_2 + 2x_2 \\exp(x_1) & x_1 x_2^2 + x_1 \\exp(x_1) & 1 & 1 & 1 & 1\n\\end{pmatrix}\n}\n$$", "id": "2982869"}, {"introduction": "A key challenge in implementing higher-order schemes is the simulation of the required multiple stochastic integrals. Fortunately, some of these integrals can be replaced by simpler, equivalent expressions derived from Itô's formula, which greatly simplifies the algorithm. This exercise focuses on a crucial identity that relates the double integral $I_{(j,j)}(h)$ to the squared Brownian increment $(\\Delta W^j)^2$, explaining why this substitution is exact for strong schemes but can be problematic for high-order weak schemes that use non-Gaussian surrogates [@problem_id:2982893].", "problem": "Consider a $d$-dimensional stochastic differential equation driven by standard $m$-dimensional Brownian motion, $dX_t = a(X_t)\\,dt + \\sum_{j=1}^m b^{(j)}(X_t)\\,dW_t^{(j)}$, where $a:\\mathbb{R}^d\\to\\mathbb{R}^d$ and $b^{(j)}:\\mathbb{R}^d\\to\\mathbb{R}^d$ are sufficiently smooth and satisfy standard growth and Lipschitz conditions ensuring existence of a strong solution. For a time step of size $h>0$, denote the Brownian increments by $\\Delta W^j = W_{t+h}^j - W_t^j$, and the iterated Itô integrals by $I_{(j,k)}(h) = \\int_t^{t+h}\\int_t^{s_1} dW_{s_2}^k\\,dW_{s_1}^j$. In Itô–Taylor schemes of strong order up to $1.5$, terms of the form $I_{(j,j)}(h)$ appear.\n\nA common implementation replaces $I_{(j,j)}(h)$ by $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ within a strong Itô–Taylor integrator. In contrast, weak schemes of order exceeding $1.5$ often employ moment-matching surrogates for the driving noise, where each $\\Delta W^j$ is replaced by a non-Gaussian random variable with a prescribed finite set of matched moments.\n\nUsing only the following foundational facts:\n- the definition of Itô integrals and multiple Itô integrals,\n- the quadratic variation of Brownian motion and Itô’s formula for $f(x)=x^2$,\n- the definitions of strong order (mean-square pathwise accuracy) and weak order (accuracy of expectations for smooth test functions),\n- and the moment requirements for weak Taylor expansions (that joint moments of the driving random variables up to a certain total order must match those of Brownian motion),\n\nselect all statements that correctly explain why the replacement $I_{(j,j)}(h)\\mapsto \\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ preserves strong order, yet may fail to preserve weak order beyond $1.5$ unless additional conditions are enforced.\n\nA. For true Gaussian Brownian increments, the identity linking $I_{(j,j)}(h)$ and $\\Delta W^j$ follows from Itô’s formula and quadratic variation, so substituting $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ leaves the pathwise local truncation error unchanged and therefore does not degrade the strong order of the Itô–Taylor scheme.\n\nB. In weak schemes that replace $\\Delta W^j$ by non-Gaussian surrogates matching only finitely many moments, defining $I_{(j,j)}(h)$ as $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ generally fails to reproduce all required joint moments of total order up to $4$ between $\\Delta W^j$ and $I_{(j,j)}(h)$, so the weak order can drop when targeting orders higher than $1.5$.\n\nC. The replacement is invalid because $I_{(j,j)}(h)$ is independent of $\\Delta W^j$ in Itô calculus; enforcing a quadratic relation introduces spurious dependence and destroys both strong and weak orders.\n\nD. Weak order depends only on matching $\\mathbb{E}[\\Delta W^j]$ and $\\mathbb{E}[I_{(j,j)}(h)]$; therefore any replacement that preserves these means guarantees arbitrary weak order.", "solution": "The problem asks for an explanation of why the replacement $I_{(j,j)}(h) \\mapsto \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ is valid for strong Itô-Taylor schemes but can be problematic for high-order weak schemes. We will analyze this using the foundational facts provided.\n\nFirst, let's establish the relationship between the iterated Itô integral $I_{(j,j)}(h)$ and the Brownian increment $\\Delta W^j$ for a standard one-dimensional Brownian motion $W_t$. For simplicity, we drop the index $j$. The SDE for $W_t$ is $dW_t = 0 \\cdot dt + 1 \\cdot dW_t$.\nWe apply Itô's formula for the function $f(x) = x^2$ to the process $X_t = W_t$. The formula is $df(X_t) = f'(X_t) dX_t + \\frac{1}{2} f''(X_t) d\\langle X \\rangle_t$.\nWith $f(x)=x^2$, we have $f'(x)=2x$ and $f''(x)=2$. The quadratic variation of Brownian motion is $d\\langle W \\rangle_t = dt$.\nSubstituting these into Itô's formula gives:\n$$d(W_t^2) = 2W_t dW_t + \\frac{1}{2}(2)dt = 2W_t dW_t + dt$$\nIntegrating this stochastic differential from $t$ to $t+h$:\n$$W_{t+h}^2 - W_t^2 = 2\\int_t^{t+h} W_s dW_s + \\int_t^{t+h} ds$$\n$$W_{t+h}^2 - W_t^2 = 2\\int_t^{t+h} W_s dW_s + h$$\nThe term $\\int_t^{t+h} W_s dW_s$ can be expanded using integration by parts for Itô integrals, or more directly by substituting $W_s = W_t + (W_s - W_t)$:\n$$ \\int_t^{t+h} W_s dW_s = \\int_t^{t+h} (W_t + (W_s - W_t)) dW_s = W_t \\int_t^{t+h} dW_s + \\int_t^{t+h} (W_s - W_t) dW_s $$\nRecognizing that $W_s - W_t = \\int_t^s dW_u$ and using the definition of a multiple Itô integral, the second term is $\\int_t^{t+h} \\int_t^s dW_u dW_s$, which is precisely $I_{(j,j)}(h)$ for the $j$-th component. So, for a single component:\n$$ \\int_t^{t+h} W_s dW_s = W_t (W_{t+h}-W_t) + \\int_t^{t+h} \\int_t^s dW_u dW_s = W_t \\Delta W + I_{(1,1)}(h) $$\nSubstituting this back into the integrated Itô's formula:\n$$W_{t+h}^2 - W_t^2 = 2(W_t \\Delta W + I_{(1,1)}(h)) + h$$\nOn the other hand, we can write $W_{t+h}^2 - W_t^2$ algebraically as:\n$$W_{t+h}^2 - W_t^2 = (W_t + \\Delta W)^2 - W_t^2 = W_t^2 + 2W_t \\Delta W + (\\Delta W)^2 - W_t^2 = 2W_t \\Delta W + (\\Delta W)^2$$\nEquating the two expressions for $W_{t+h}^2 - W_t^2$:\n$$2W_t \\Delta W + (\\Delta W)^2 = 2W_t \\Delta W + 2I_{(1,1)}(h) + h$$\n$$(\\Delta W)^2 = 2I_{(1,1)}(h) + h$$\nSolving for the iterated integral $I_{(j,j)}(h)$ (re-introducing the index $j$):\n$$I_{(j,j)}(h) = \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$$\nThis is an exact identity for true Brownian motion, not an approximation.\n\nNow we evaluate each option.\n\n**A. For true Gaussian Brownian increments, the identity linking $I_{(j,j)}(h)$ and $\\Delta W^j$ follows from Itô’s formula and quadratic variation, so substituting $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ leaves the pathwise local truncation error unchanged and therefore does not degrade the strong order of the Itô–Taylor scheme.**\n\nThis statement is correct. Our derivation above shows that $I_{(j,j)}(h) = \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ is an identity, a direct consequence of Itô's formula and the quadratic variation of Brownian motion. Strong convergence concerns the pathwise approximation of the solution. Since the replacement is an exact identity for any given path of the Brownian motion, substituting $\\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ for $I_{(j,j)}(h)$ in an Itô-Taylor expansion does not alter the value of the numerical scheme's increment for a given realization of the Brownian path. Consequently, the local truncation error of the scheme is not affected by this substitution. Since the strong order of convergence depends on the order of the local truncation error, the strong order is preserved. The statement accurately describes the situation for strong schemes. **Verdict: Correct.**\n\n**B. In weak schemes that replace $\\Delta W^j$ by non-Gaussian surrogates matching only finitely many moments, defining $I_{(j,j)}(h)$ as $\\tfrac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$ generally fails to reproduce all required joint moments of total order up to $4$ between $\\Delta W^j$ and $I_{(j,j)}(h)$, so the weak order can drop when targeting orders higher than $1.5$.**\n\nThis statement is correct. Weak schemes approximate expectations, and achieving a weak order of $p$ requires the numerical increments to match the joint moments of the true increments up to a total order of $2p$. For orders beyond $1.5$ (e.g., weak order $p=2.0$), moments of total order up to $2p=4$ must be matched. In weak schemes, $\\Delta W^j$ is often replaced by a computationally cheaper non-Gaussian random variable, let's call it $\\tilde{W}^j$. When one then *defines* the surrogate for the iterated integral as $\\tilde{I}_{(j,j)}(h) = \\frac{1}{2}\\big((\\tilde{W}^j)^2 - h\\big)$, the joint moments of the pair $(\\tilde{W}^j, \\tilde{I}_{(j,j)}(h))$ are completely determined by the moments of $\\tilde{W}^j$ alone.\nFor this to work, $\\tilde{W}^j$ must be chosen such that all the resulting joint moments match the true ones. While it is possible to construct a surrogate for $\\tilde{W}^j$ (e.g., a specific $3$-point distribution) that makes this work for weak order $2.0$ (i.e., moments of total order up to $4$), a simpler, more \"general\" surrogate that works for lower orders will fail. For instance, a two-point random variable $\\tilde{W}^j$ with $\\mathbb{P}(\\tilde{W}^j = \\pm\\sqrt{h})=1/2$ matches moments up to order $3$ (odd moments are $0$, $\\mathbb{E}[(\\tilde{W}^j)^2]=h$), but fails for the fourth moment: $\\mathbb{E}[(\\tilde{W}^j)^4]=h^2$, whereas the true Gaussian moment is $3h^2$. This discrepancy causes higher-order joint moments, such as $\\mathbb{E}[(\\tilde{I}_{(j,j)}(h))^2]$, to be incorrect, preventing the scheme from achieving weak order $2.0$. The wording \"generally fails\" accurately captures that this approach is not robust and requires specific, careful choices of surrogates. Furthermore, even with a surrogate that works for order $2.0$, this ad-hoc definition will fail for even higher orders (e.g., $3.0$, which requires matching moments up to total order $6$), because the functional dependency is too rigid to satisfy the expanding set of moment conditions. Thus, the statement correctly identifies the mechanism of failure for high-order weak schemes. **Verdict: Correct.**\n\n**C. The replacement is invalid because $I_{(j,j)}(h)$ is independent of $\\Delta W^j$ in Itô calculus; enforcing a quadratic relation introduces spurious dependence and destroys both strong and weak orders.**\n\nThis statement is incorrect. The premise that $I_{(j,j)}(h)$ and $\\Delta W^j$ are independent is false. As shown by the identity $I_{(j,j)}(h) = \\frac{1}{2}\\big((\\Delta W^j)^2 - h\\big)$, $I_{(j,j)}(h)$ is a deterministic function of $\\Delta W^j$, which represents a very strong form of dependence. While they are uncorrelated ($\\text{Cov}(\\Delta W^j, I_{(j,j)}(h)) = 0$), they are not independent. The conclusion that this replacement \"destroys both strong and weak orders\" is also false. As explained in the analysis of option A, it perfectly preserves strong order. **Verdict: Incorrect.**\n\n**D. Weak order depends only on matching $\\mathbb{E}[\\Delta W^j]$ and $\\mathbb{E}[I_{(j,j)}(h)]$; therefore any replacement that preserves these means guarantees arbitrary weak order.**\n\nThis statement is incorrect. The premise is a gross oversimplification of the requirements for weak convergence. Preserving the means $\\mathbb{E}[\\Delta W^j]=0$ and $\\mathbb{E}[I_{(j,j)}(h)]=0$ is a necessary condition, but it is far from sufficient. Achieving a weak order of $p$ requires matching a whole hierarchy of joint moments of the numerical increments (e.g., $\\Delta W^j$, $I_{(j,k)}(h)$, etc.) up to total order $2p$. For example, even weak order $1.0$ requires matching second-order moments like $\\mathbb{E}[(\\Delta W^j)^2]=h$. The claim that matching only the means \"guarantees arbitrary weak order\" is patently false. **Verdict: Incorrect.**", "answer": "$$\\boxed{AB}$$", "id": "2982893"}]}