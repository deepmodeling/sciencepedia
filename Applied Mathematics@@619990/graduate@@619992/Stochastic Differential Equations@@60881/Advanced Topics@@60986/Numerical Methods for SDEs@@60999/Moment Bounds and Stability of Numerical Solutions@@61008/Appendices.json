{"hands_on_practices": [{"introduction": "A crucial first step in understanding numerical stability is to compare the long-term behavior of a discretized SDE with its exact continuous-time counterpart. This exercise guides you through the fundamental analysis for two cornerstone models: the Ornstein-Uhlenbeck process with additive noise and the Geometric Brownian Motion with multiplicative noise. By deriving the exact second-moment dynamics and comparing them to those of the Milstein scheme, you will determine the critical step-size thresholds, often denoted $h_{\\star}$, for maintaining mean-square stability, a core skill in designing reliable simulations [@problem_id:2988113].", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard Brownian motion on a filtered probability space satisfying the usual conditions. Consider two It\\^{o} stochastic differential equations (SDEs) with globally Lipschitz and linearly growing coefficients:\n1) The Ornstein–Uhlenbeck (OU) process defined by\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\lambda X_{t}\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t},\n$$\nwith $\\lambda>0$, $\\sigma>0$, and initial condition $X_{0}$ satisfying $\\mathbb{E}[X_{0}^{2}]<\\infty$.\n2) The geometric Brownian motion (GBM) defined by\n$$\n\\mathrm{d}Y_{t} \\;=\\; \\mu Y_{t}\\,\\mathrm{d}t \\;+\\; \\sigma Y_{t}\\,\\mathrm{d}W_{t},\n$$\nwith $\\mu \\in \\mathbb{R}$, $\\sigma>0$, and initial condition $Y_{0}$ satisfying $\\mathbb{E}[Y_{0}^{2}]<\\infty$.\n\nLet $\\{t_{n}\\}_{n \\geq 0}$ denote a uniform grid with step size $h>0$, $t_{n}=nh$, and let $\\Delta W_{n}:=W_{t_{n+1}}-W_{t_{n}}$. Apply the one-step Milstein scheme to each SDE to obtain numerical approximations $\\{X_{n}\\}_{n \\geq 0}$ for the OU process and $\\{Y_{n}\\}_{n \\geq 0}$ for the GBM, with $X_{0}$ and $Y_{0}$ given.\n\nStarting from first principles of It\\^{o} calculus and the definition of the Milstein method, and using only well-tested facts about Gaussian increments (e.g., $\\mathbb{E}[\\Delta W_{n}]=0$, $\\mathbb{E}[(\\Delta W_{n})^{2}]=h$, $\\mathbb{E}[(\\Delta W_{n})^{3}]=0$, $\\mathbb{E}[(\\Delta W_{n})^{4}]=3h^{2}$), carry out the following:\n- Derive the exact second-moment evolution $\\mathbb{E}[X_{t}^{2}]$ for the OU process, and determine the stationary second-moment bound as $t \\to \\infty$. Derive the second-moment recursion for the Milstein discretization (which, for additive noise, coincides with the Euler–Maruyama scheme), establish the condition on $h$ under which $\\{\\mathbb{E}[X_{n}^{2}]\\}_{n \\geq 0}$ remains uniformly bounded, and determine the largest allowable step size $h_{\\star}^{\\mathrm{OU}}$ for which this uniform boundedness (mean-square dissipativity) holds.\n- Derive the exact second-moment evolution $\\mathbb{E}[Y_{t}^{2}]$ for the GBM and state the parameter regime in which the exact dynamics are mean-square dissipative. For the Milstein scheme applied to the GBM, derive the multiplicative second-moment amplification factor $r(h)$ defined by $\\mathbb{E}[Y_{n+1}^{2}]=r(h)\\,\\mathbb{E}[Y_{n}^{2}]$. From the mean-square dissipativity requirement $r(h)<1$, determine the largest allowable step size $h_{\\star}^{\\mathrm{GBM}}$ as an explicit function of $\\mu$ and $\\sigma$.\n\nExpress your final answer as a single closed-form analytical expression containing both thresholds $h_{\\star}^{\\mathrm{OU}}$ and $h_{\\star}^{\\mathrm{GBM}}$ arranged as a row matrix using the $\\mathrm{pmatrix}$ environment. No numerical approximation or rounding is required, and no units are to be included in the final answer.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the field of numerical analysis for stochastic differential equations. We proceed with the solution.\n\nThe solution is presented in two parts, one for the Ornstein–Uhlenbeck (OU) process and one for the geometric Brownian motion (GBM), as requested.\n\n### Part 1: Ornstein–Uhlenbeck Process\n\nThe SDE for the OU process is given by:\n$$\n\\mathrm{d}X_{t} = -\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}\n$$\nwhere $\\lambda > 0$, $\\sigma > 0$, and $\\mathbb{E}[X_{0}^{2}] < \\infty$.\n\n**Exact Second-Moment Evolution**\nTo find the evolution of the second moment, $\\mathbb{E}[X_{t}^{2}]$, we apply Itō's lemma to the function $f(x) = x^{2}$. The derivatives are $f'(x)=2x$ and $f''(x)=2$. Itō's lemma states that for a process $X_t$ and a twice-differentiable function $f$,\n$$\n\\mathrm{d}f(X_{t}) = f'(X_{t})\\,\\mathrm{d}X_{t} + \\frac{1}{2}f''(X_{t})\\,(\\mathrm{d}X_{t})^{2}.\n$$\nSubstituting the SDE for $\\mathrm{d}X_{t}$, we get:\n$$\n\\mathrm{d}(X_{t}^{2}) = 2X_{t}(-\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}) + \\frac{1}{2}(2)(-\\lambda X_{t}\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t})^{2}.\n$$\nAccording to Itō calculus rules, $(\\mathrm{d}t)^{2}=0$, $\\mathrm{d}t\\,\\mathrm{d}W_{t}=0$, and $(\\mathrm{d}W_{t})^{2}=\\mathrm{d}t$. Thus, the quadratic variation term is $(\\mathrm{d}X_{t})^{2} = \\sigma^{2}(\\mathrm{d}W_{t})^{2} = \\sigma^{2}\\mathrm{d}t$.\nThe expression for $\\mathrm{d}(X_{t}^{2})$ becomes:\n$$\n\\mathrm{d}(X_{t}^{2}) = -2\\lambda X_{t}^{2}\\,\\mathrm{d}t + 2\\sigma X_{t}\\,\\mathrm{d}W_{t} + \\sigma^{2}\\,\\mathrm{d}t.\n$$\nLet $m_{2}(t) = \\mathbb{E}[X_{t}^{2}]$. Taking the expectation of the integral form of the above equation, and noting that the expectation of the Itō integral term is zero (i.e., $\\mathbb{E}[\\int_{0}^{t} 2\\sigma X_{s}\\,\\mathrm{d}W_{s}]=0$ since $X_s$ is adapted), we obtain an ordinary differential equation (ODE) for $m_{2}(t)$:\n$$\n\\frac{\\mathrm{d}m_{2}(t)}{\\mathrm{d}t} = \\mathbb{E}[-2\\lambda X_{t}^{2} + \\sigma^{2}] = -2\\lambda m_{2}(t) + \\sigma^{2}.\n$$\nThis is a first-order linear ODE, $m'_{2}(t) + 2\\lambda m_{2}(t) = \\sigma^{2}$. The solution with initial condition $m_{2}(0) = \\mathbb{E}[X_{0}^{2}]$ is:\n$$\nm_{2}(t) = \\frac{\\sigma^{2}}{2\\lambda} + \\left(\\mathbb{E}[X_{0}^{2}] - \\frac{\\sigma^{2}}{2\\lambda}\\right)\\exp(-2\\lambda t).\n$$\nAs $t \\to \\infty$, since $\\lambda > 0$, the exponential term decays to zero. The stationary second-moment bound is:\n$$\n\\lim_{t \\to \\infty} \\mathbb{E}[X_{t}^{2}] = \\frac{\\sigma^{2}}{2\\lambda}.\n$$\n\n**Milstein Discretization and Mean-Square Stability**\nThe general one-step Milstein scheme for an SDE $\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t}$ is:\n$$\nX_{n+1} = X_{n} + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2}b(X_n)b'(X_n)((\\Delta W_n)^2 - h).\n$$\nFor the OU process, we have $a(x) = -\\lambda x$ and $b(x) = \\sigma$. Since $b(x)$ is a constant, its derivative $b'(x) = 0$. Therefore, the Milstein scheme simplifies to the Euler–Maruyama scheme:\n$$\nX_{n+1} = X_{n} - \\lambda X_{n} h + \\sigma \\Delta W_{n} = (1 - \\lambda h)X_{n} + \\sigma \\Delta W_{n}.\n$$\nTo find the second-moment recursion, we square both sides:\n$$\nX_{n+1}^{2} = ((1 - \\lambda h)X_{n} + \\sigma \\Delta W_{n})^{2} = (1 - \\lambda h)^{2}X_{n}^{2} + 2\\sigma(1 - \\lambda h)X_{n}\\Delta W_{n} + \\sigma^{2}(\\Delta W_{n})^{2}.\n$$\nLet $\\mathcal{M}_{n} = \\mathbb{E}[X_{n}^{2}]$. We take the expectation, conditional on the information at time $t_{n}$, denoted by $\\mathcal{F}_{t_{n}}$. Since $X_n$ is $\\mathcal{F}_{t_{n}}$-measurable and $\\Delta W_n$ is independent of $\\mathcal{F}_{t_{n}}$, we use the provided facts $\\mathbb{E}[\\Delta W_{n}] = 0$ and $\\mathbb{E}[(\\Delta W_{n})^{2}] = h$:\n$$\n\\mathbb{E}[X_{n+1}^{2} | \\mathcal{F}_{t_{n}}] = (1 - \\lambda h)^{2}X_{n}^{2} + 2\\sigma(1 - \\lambda h)X_{n}\\mathbb{E}[\\Delta W_{n}] + \\sigma^{2}\\mathbb{E}[(\\Delta W_{n})^{2}] = (1 - \\lambda h)^{2}X_{n}^{2} + \\sigma^{2}h.\n$$\nTaking the full expectation gives the recursion for $\\mathcal{M}_{n}$:\n$$\n\\mathcal{M}_{n+1} = (1 - \\lambda h)^{2}\\mathcal{M}_{n} + \\sigma^{2}h.\n$$\nFor the sequence $\\{\\mathcal{M}_{n}\\}_{n \\ge 0}$ to remain uniformly bounded for any finite initial second moment $\\mathcal{M}_{0}$, the recurrence must be stable. This requires the magnitude of the amplification factor of the homogeneous part to be strictly less than $1$. If the magnitude were equal to $1$, $\\mathcal{M}_{n}$ would grow arithmetically, and thus would not be uniformly bounded. The condition is:\n$$\n|1 - \\lambda h| < 1.\n$$\nThis inequality is equivalent to $-1 < 1 - \\lambda h < 1$.\nThe right-hand side, $1 - \\lambda h < 1$, implies $-\\lambda h < 0$. Since $\\lambda > 0$ and $h > 0$, this is always satisfied.\nThe left-hand side, $-1 < 1 - \\lambda h$, implies $\\lambda h < 2$.\nThus, the condition for uniform boundedness is $h < \\frac{2}{\\lambda}$. The largest allowable step size is the supremum of this set, which is:\n$$\nh_{\\star}^{\\mathrm{OU}} = \\frac{2}{\\lambda}.\n$$\n\n### Part 2: Geometric Brownian Motion\n\nThe SDE for GBM is given by:\n$$\n\\mathrm{d}Y_{t} = \\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t}\n$$\nwhere $\\mu \\in \\mathbb{R}$, $\\sigma > 0$, and $\\mathbb{E}[Y_{0}^{2}] < \\infty$.\n\n**Exact Second-Moment Evolution**\nWe again apply Itō's lemma to $f(y) = y^{2}$, so $f'(y)=2y$ and $f''(y)=2$.\n$$\n\\mathrm{d}(Y_{t}^{2}) = 2Y_{t}(\\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t}) + \\frac{1}{2}(2)(\\mu Y_{t}\\,\\mathrm{d}t + \\sigma Y_{t}\\,\\mathrm{d}W_{t})^{2}.\n$$\nThe quadratic variation term is $(\\mathrm{d}Y_{t})^{2} = \\sigma^{2}Y_{t}^{2}(\\mathrm{d}W_{t})^{2} = \\sigma^{2}Y_{t}^{2}\\mathrm{d}t$.\nSubstituting this, we get:\n$$\n\\mathrm{d}(Y_{t}^{2}) = 2\\mu Y_{t}^{2}\\,\\mathrm{d}t + 2\\sigma Y_{t}^{2}\\,\\mathrm{d}W_{t} + \\sigma^{2}Y_{t}^{2}\\mathrm{d}t = (2\\mu + \\sigma^{2})Y_{t}^{2}\\,\\mathrm{d}t + 2\\sigma Y_{t}^{2}\\,\\mathrm{d}W_{t}.\n$$\nLet $m_{2}(t) = \\mathbb{E}[Y_{t}^{2}]$. Taking the expectation, the Itō integral term vanishes, and we obtain the ODE:\n$$\n\\frac{\\mathrm{d}m_{2}(t)}{\\mathrm{d}t} = (2\\mu + \\sigma^{2})m_{2}(t).\n$$\nThe solution is $m_{2}(t) = m_{2}(0)\\exp((2\\mu + \\sigma^{2})t)$. For the exact dynamics to be mean-square dissipative, the second moment must decay to zero as $t \\to \\infty$. This requires the exponent to be negative. The parameter regime is:\n$$\n2\\mu + \\sigma^{2} < 0.\n$$\n\n**Milstein Discretization and Mean-Square Stability**\nFor GBM, we have $a(y) = \\mu y$ and $b(y) = \\sigma y$, so $b'(y) = \\sigma$. The Milstein scheme is:\n$$\n\\begin{aligned}\nY_{n+1} &= Y_{n} + \\mu Y_{n}h + \\sigma Y_{n}\\Delta W_{n} + \\frac{1}{2}(\\sigma Y_{n})(\\sigma)((\\Delta W_{n})^{2} - h) \\\\\n&= Y_{n}\\left[1 + \\mu h + \\sigma \\Delta W_{n} + \\frac{1}{2}\\sigma^{2}((\\Delta W_{n})^{2} - h)\\right].\n\\end{aligned}\n$$\nThe problem defines the multiplicative amplification factor $r(h)$ via $\\mathbb{E}[Y_{n+1}^{2}] = r(h)\\mathbb{E}[Y_{n}^{2}]$. By the tower property and independence of $\\Delta W_n$ from $\\mathcal{F}_{t_n}$, we have:\n$$\nr(h) = \\mathbb{E}\\left[\\left(1 + \\mu h - \\frac{1}{2}\\sigma^{2}h + \\sigma\\Delta W_{n} + \\frac{1}{2}\\sigma^{2}(\\Delta W_{n})^{2}\\right)^{2}\\right].\n$$\nLet $C = 1 + \\mu h - \\frac{1}{2}\\sigma^{2}h$ and $Z_{n} = \\Delta W_{n}$. We need to compute $\\mathbb{E}[(C + \\sigma Z_{n} + \\frac{1}{2}\\sigma^{2}Z_{n}^{2})^{2}]$.\nExpanding the square:\n$$\n(C + \\sigma Z_{n} + \\frac{1}{2}\\sigma^{2}Z_{n}^{2})^{2} = C^{2} + \\sigma^{2}Z_{n}^{2} + \\frac{1}{4}\\sigma^{4}Z_{n}^{4} + 2C\\sigma Z_{n} + C\\sigma^{2}Z_{n}^{2} + \\sigma^{3}Z_{n}^{3}.\n$$\nTaking the expectation and using the given moments $\\mathbb{E}[Z_n]=0$, $\\mathbb{E}[Z_n^2]=h$, $\\mathbb{E}[Z_n^3]=0$, $\\mathbb{E}[Z_n^4]=3h^2$:\n$$\n\\begin{aligned}\nr(h) &= \\mathbb{E}[C^{2}] + \\sigma^{2}\\mathbb{E}[Z_{n}^{2}] + \\frac{1}{4}\\sigma^{4}\\mathbb{E}[Z_{n}^{4}] + 2C\\sigma\\mathbb{E}[Z_{n}] + C\\sigma^{2}\\mathbb{E}[Z_{n}^{2}] + \\sigma^{3}\\mathbb{E}[Z_{n}^{3}] \\\\\n&= C^{2} + \\sigma^{2}h + \\frac{1}{4}\\sigma^{4}(3h^{2}) + 0 + C\\sigma^{2}h + 0 \\\\\n&= C^{2} + (1+C)\\sigma^{2}h + \\frac{3}{4}\\sigma^{4}h^{2}.\n\\end{aligned}\n$$\nSubstituting $C = 1 + (\\mu - \\frac{1}{2}\\sigma^{2})h$:\n$C^{2} = (1 + (\\mu - \\frac{1}{2}\\sigma^{2})h)^{2} = 1 + 2(\\mu - \\frac{1}{2}\\sigma^{2})h + (\\mu - \\frac{1}{2}\\sigma^{2})^{2}h^{2}$.\n$1+C = 2 + (\\mu - \\frac{1}{2}\\sigma^{2})h$.\nSo, $(1+C)\\sigma^{2}h = 2\\sigma^{2}h + (\\mu - \\frac{1}{2}\\sigma^{2})\\sigma^{2}h^{2}$.\nSumming all terms for $r(h)$:\n$$\n\\begin{aligned}\nr(h) &= \\left(1 + (2\\mu - \\sigma^{2})h + (\\mu^{2}-\\mu\\sigma^{2}+\\frac{1}{4}\\sigma^{4})h^{2}\\right) + \\left(2\\sigma^{2}h + (\\mu\\sigma^{2}-\\frac{1}{2}\\sigma^{4})h^{2}\\right) + \\frac{3}{4}\\sigma^{4}h^{2} \\\\\n&= 1 + (2\\mu - \\sigma^{2} + 2\\sigma^{2})h + (\\mu^{2}-\\mu\\sigma^{2}+\\frac{1}{4}\\sigma^{4} + \\mu\\sigma^{2}-\\frac{1}{2}\\sigma^{4} + \\frac{3}{4}\\sigma^{4})h^{2} \\\\\n&= 1 + (2\\mu + \\sigma^{2})h + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h^{2}.\n\\end{aligned}\n$$\nThe mean-square dissipativity requirement is $r(h) < 1$:\n$$\n1 + (2\\mu + \\sigma^{2})h + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h^{2} < 1.\n$$\nFor $h > 0$, this simplifies to:\n$$\n(2\\mu + \\sigma^{2}) + (\\mu^{2} + \\frac{1}{2}\\sigma^{4})h < 0.\n$$\nFor this inequality to have a solution for $h > 0$, we must have the constant term negative, since the term with $h$ has a positive coefficient $(\\mu^{2} + \\frac{1}{2}\\sigma^{4}) > 0$. This implies $2\\mu + \\sigma^{2} < 0$, which is exactly the dissipativity condition for the continuous SDE.\nUnder this condition, we solve for $h$:\n$$\n(\\mu^{2} + \\frac{1}{2}\\sigma^{4})h < -(2\\mu + \\sigma^{2}).\n$$\n$$\nh < \\frac{-(2\\mu + \\sigma^{2})}{\\mu^{2} + \\frac{1}{2}\\sigma^{4}}.\n$$\nThe largest allowable step size is the supremum of this interval:\n$$\nh_{\\star}^{\\mathrm{GBM}} = \\frac{-(2\\mu + \\sigma^{2})}{\\mu^{2} + \\frac{1}{2}\\sigma^{4}}.\n$$\nThis threshold is valid only in the parameter regime $2\\mu+\\sigma^2 < 0$. Otherwise, no step size $h>0$ can ensure mean-square dissipativity for the Milstein method.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{\\lambda} & \\frac{-(2\\mu + \\sigma^2)}{\\mu^2 + \\frac{1}{2}\\sigma^4}\n\\end{pmatrix}\n}\n$$", "id": "2988113"}, {"introduction": "While direct calculation is insightful for simple models, a more powerful and general approach is needed for complex systems. This is where Lyapunov's method becomes indispensable for analyzing the stability of numerical schemes. In this practice, you will apply this technique by constructing a discrete Lyapunov function for the Euler-Maruyama method and deriving a uniform moment bound, offering a glimpse into the formal stability proofs used throughout stochastic numerical analysis [@problem_id:2988098].", "problem": "Consider the scalar Ornstein–Uhlenbeck (OU) stochastic differential equation (SDE) $$\\mathrm{d}X_{t} \\,=\\, -\\lambda X_{t} \\,\\mathrm{d}t \\;+\\; \\sigma \\,\\mathrm{d}W_{t},$$ where $W_{t}$ is a standard Wiener process, $\\lambda>0$ is the mean-reversion rate, and $\\sigma>0$ is the diffusion magnitude. Let $X_{0}$ be independent of $W_{t}$. The explicit Euler–Maruyama time discretization with step size $h>0$ is given by $$X_{n+1} \\,=\\, X_{n} \\;-\\; \\lambda h\\, X_{n} \\;+\\; \\sigma \\sqrt{h}\\, \\xi_{n+1},$$ where $(\\xi_{n})_{n\\geq 1}$ are independent standard normal random variables and independent of $X_{0}$. Define the Lyapunov function $$V(x) \\,=\\, 1 \\;+\\; x^{2}.$$\n\nStarting from the fundamental definitions of conditional expectation and the properties of the Euler–Maruyama scheme and Gaussian noise, derive a discrete Lyapunov drift inequality of the form $$\\mathbb{E}\\!\\left[V\\!\\left(X_{n+1}\\right)\\,\\middle|\\,X_{n}\\right] \\,\\leq\\, \\rho\\, V\\!\\left(X_{n}\\right) \\;+\\; \\beta,$$ for explicit constants $\\rho\\in(0,1)$ and $\\beta>0$ that depend only on $\\lambda$, $\\sigma$, and $h$. Then use this inequality and iterated expectations to obtain a uniform (in $n$) bound on the moments $\\mathbb{E}\\!\\left[V\\!\\left(X_{n}\\right)\\right]$ and identify the smallest constant $$C \\;=\\; \\sup_{n\\geq 0} \\,\\mathbb{E}\\!\\left[V\\!\\left(X_{n}\\right)\\right]$$ that your argument guarantees, expressed solely in terms of $\\lambda$, $\\sigma$, $h$, and the law of $X_{0}$.\n\nFinally, compute this constant for the specific parameter values $$\\lambda \\,=\\, 1.7, \\quad \\sigma \\,=\\, 1.3, \\quad h \\,=\\, 0.4, \\quad X_{0} \\sim \\mathcal{N}(m,s^{2}) \\text{ with } m \\,=\\, -0.5 \\text{ and } s^{2} \\,=\\, 0.8.$$ Round your final answer for $C$ to four significant figures. No units are required.", "solution": "The problem statement is critically validated before proceeding to a solution.\n\n### Step 1: Extract Givens\n- The scalar Ornstein–Uhlenbeck (OU) stochastic differential equation (SDE) is given by $\\mathrm{d}X_{t} = -\\lambda X_{t} \\,\\mathrm{d}t + \\sigma \\,\\mathrm{d}W_{t}$.\n- Parameters are the mean-reversion rate $\\lambda>0$ and the diffusion magnitude $\\sigma>0$.\n- $W_{t}$ is a standard Wiener process.\n- The initial condition $X_{0}$ is independent of $W_{t}$.\n- The explicit Euler–Maruyama time discretization with step size $h>0$ is $X_{n+1} = X_{n} - \\lambda h\\, X_{n} + \\sigma \\sqrt{h}\\, \\xi_{n+1}$.\n- $(\\xi_{n})_{n\\geq 1}$ are independent standard normal random variables, $\\xi_n \\sim \\mathcal{N}(0,1)$, and are independent of $X_{0}$.\n- The Lyapunov function is defined as $V(x) = 1 + x^{2}$.\n- The task is to derive a discrete Lyapunov drift inequality $\\mathbb{E}[V(X_{n+1})|X_{n}] \\leq \\rho V(X_{n}) + \\beta$ for constants $\\rho\\in(0,1)$ and $\\beta>0$.\n- Subsequently, use this to find the smallest constant $C = \\sup_{n\\geq 0} \\mathbb{E}[V(X_{n})]$ guaranteed by the argument.\n- Finally, compute $C$ for the specific parameters $\\lambda = 1.7$, $\\sigma = 1.3$, $h = 0.4$, and $X_{0} \\sim \\mathcal{N}(m, s^2)$ with $m = -0.5$ and $s^2 = 0.8$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded. The Ornstein-Uhlenbeck process is a fundamental model in stochastic calculus. The Euler-Maruyama method is a standard numerical scheme for SDEs. The use of a Lyapunov function to analyze the stability of a numerical method is a well-established technique in stochastic numerical analysis. The problem is well-posed, objective, and internally consistent. It provides all necessary information to derive the inequality and compute the final constant. The problem asks for standard derivations and calculations within its field, with no scientific or factual unsoundness, ambiguity, or missing information. A meaningful, unique solution exists, provided the standard numerical stability condition on the step size $h$ is met.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A full solution will be provided.\n\n### Solution Derivation\n\nThe first step is to derive the discrete Lyapunov drift inequality. We start by computing the conditional expectation of $V(X_{n+1})$ given $X_{n}$.\nThe Lyapunov function is $V(x) = 1 + x^{2}$. Applying this to $X_{n+1}$ from the Euler-Maruyama scheme:\n$$V(X_{n+1}) = 1 + X_{n+1}^2 = 1 + \\left((1 - \\lambda h)X_{n} + \\sigma \\sqrt{h}\\, \\xi_{n+1}\\right)^{2}.$$\nWe expand the squared term:\n$$X_{n+1}^2 = (1 - \\lambda h)^{2}X_{n}^2 + 2(1 - \\lambda h)X_{n}\\sigma\\sqrt{h}\\,\\xi_{n+1} + \\sigma^{2}h\\,\\xi_{n+1}^2.$$\nNow, we take the conditional expectation with respect to the sigma-algebra generated by $X_n$. Since $X_n$ is known in this context and $\\xi_{n+1}$ is independent with $\\xi_{n+1} \\sim \\mathcal{N}(0,1)$, we have $\\mathbb{E}[\\xi_{n+1}|X_n]=\\mathbb{E}[\\xi_{n+1}]=0$ and $\\mathbb{E}[\\xi_{n+1}^2|X_n]=\\mathbb{E}[\\xi_{n+1}^2]=1$.\n\\begin{align*} \\mathbb{E}[V(X_{n+1})|X_{n}] &= \\mathbb{E}\\left[1 + (1 - \\lambda h)^{2}X_{n}^2 + 2(1 - \\lambda h)X_{n}\\sigma\\sqrt{h}\\,\\xi_{n+1} + \\sigma^{2}h\\,\\xi_{n+1}^2 \\,\\middle|\\, X_{n}\\right] \\\\ &= 1 + (1 - \\lambda h)^{2}X_{n}^2 + 2(1 - \\lambda h)X_{n}\\sigma\\sqrt{h}\\,\\mathbb{E}[\\xi_{n+1}] + \\sigma^{2}h\\,\\mathbb{E}[\\xi_{n+1}^2] \\\\ &= 1 + (1 - \\lambda h)^{2}X_{n}^2 + \\sigma^{2}h. \\end{align*}\nTo obtain the desired inequality form, we express the result in terms of $V(X_n) = 1 + X_n^2$.\n\\begin{align*} \\mathbb{E}[V(X_{n+1})|X_{n}] &= 1 + (1 - \\lambda h)^{2}(V(X_n) - 1) + \\sigma^{2}h \\\\ &= (1 - \\lambda h)^{2}V(X_n) + 1 - (1 - \\lambda h)^{2} + \\sigma^{2}h \\\\ &= (1 - \\lambda h)^{2}V(X_n) + 1 - (1 - 2\\lambda h + \\lambda^{2}h^{2}) + \\sigma^{2}h \\\\ &= (1 - \\lambda h)^{2}V(X_n) + 2\\lambda h - \\lambda^{2}h^{2} + \\sigma^{2}h. \\end{align*}\nThis is a discrete Lyapunov drift inequality of the form $\\mathbb{E}[V(X_{n+1})|X_{n}] \\leq \\rho V(X_{n}) + \\beta$, where the inequality is an equality in this case. The constants are:\n$$\\rho = (1 - \\lambda h)^{2}$$\n$$\\beta = 2\\lambda h - \\lambda^{2}h^{2} + \\sigma^{2}h.$$\nFor the analysis to proceed, we require $\\rho \\in (0,1)$, which implies $|1 - \\lambda h| < 1$. This yields $-1 < 1 - \\lambda h < 1$, which simplifies to $0 < \\lambda h < 2$. Given $\\lambda>0$ and $h>0$, the condition is $h < 2/\\lambda$. If this holds, $\\rho < 1$. Also, $\\beta = \\lambda h(2 - \\lambda h) + \\sigma^{2}h > 0$ since all terms are positive under this condition.\n\nNext, we derive the uniform moment bound. Taking the total expectation of the inequality and letting $v_n = \\mathbb{E}[V(X_n)]$:\n$$v_{n+1} = \\mathbb{E}[\\mathbb{E}[V(X_{n+1})|X_{n}]] \\leq \\mathbb{E}[\\rho V(X_n) + \\beta] = \\rho v_n + \\beta.$$\nThis is a linear recurrence relation. By iterating, we find:\n$$v_n \\leq \\rho^{n} v_0 + \\beta \\sum_{k=0}^{n-1} \\rho^k = \\rho^{n} v_0 + \\beta \\frac{1-\\rho^n}{1-\\rho}.$$\nLet $y^* = \\beta/(1-\\rho)$. The inequality can be rewritten as:\n$$v_n \\leq \\rho^n (v_0 - y^*) + y^*.$$\nWe seek $C = \\sup_{n\\geq 0} v_n$. We consider two cases for the initial value $v_0 = \\mathbb{E}[V(X_0)]$.\n1. If $v_0 \\leq y^*$: Then $v_0 - y^* \\leq 0$. Since $\\rho^n \\geq 0$, it follows that $\\rho^n(v_0 - y^*) \\leq 0$, so $v_n \\leq y^*$. The sequence is bounded above by $y^*$.\n2. If $v_0 > y^*$: Then $v_0 - y^* > 0$. Since $0 < \\rho < 1$, the function $\\rho^n$ is maximized at $n=0$ (where $\\rho^0=1$). Therefore, for any $n \\geq 0$, $v_n \\leq \\rho^n (v_0 - y^*) + y^* \\leq \\rho^0 (v_0 - y^*) + y^* = v_0$. The sequence is bounded above by its initial value $v_0$.\nCombining these cases, the uniform bound for all $n \\geq 0$ is the maximum of the two upper bounds:\n$$C = \\sup_{n\\geq 0} \\mathbb{E}[V(X_n)] = \\max(v_0, y^*) = \\max\\left(\\mathbb{E}[V(X_0)], \\frac{\\beta}{1-\\rho}\\right).$$\nLet's express the terms using the problem parameters.\nFirst, $v_0 = \\mathbb{E}[V(X_0)] = \\mathbb{E}[1 + X_0^2] = 1 + \\mathbb{E}[X_0^2]$. Since $X_0 \\sim \\mathcal{N}(m, s^2)$, its second moment is $\\mathbb{E}[X_0^2] = \\text{Var}(X_0) + (\\mathbb{E}[X_0])^2 = s^2 + m^2$. Thus, $v_0 = 1 + m^2 + s^2$.\n\nSecond, we calculate $y^* = \\beta / (1-\\rho)$:\n$$1-\\rho = 1 - (1 - \\lambda h)^2 = 1 - (1 - 2\\lambda h + \\lambda^{2}h^{2}) = 2\\lambda h - \\lambda^{2}h^{2} = \\lambda h(2 - \\lambda h).$$\n$$\\beta = 2\\lambda h - \\lambda^{2}h^{2} + \\sigma^{2}h = (1-\\rho) + \\sigma^{2}h.$$\n$$y^* = \\frac{\\beta}{1-\\rho} = \\frac{(1-\\rho) + \\sigma^{2}h}{1-\\rho} = 1 + \\frac{\\sigma^{2}h}{1-\\rho} = 1 + \\frac{\\sigma^{2}h}{\\lambda h(2 - \\lambda h)} = 1 + \\frac{\\sigma^{2}}{\\lambda(2 - \\lambda h)}.$$\nSo, the smallest constant guaranteed by this argument is:\n$$C = \\max\\left(1 + m^2 + s^2, \\; 1 + \\frac{\\sigma^2}{\\lambda(2 - \\lambda h)}\\right).$$\n\n### Final Calculation\nWe are given the parameter values:\n$\\lambda = 1.7$, $\\sigma = 1.3$, $h = 0.4$, $m = -0.5$, $s^2 = 0.8$.\n\nFirst, we verify the stability condition $0 < \\lambda h < 2$:\n$$\\lambda h = 1.7 \\times 0.4 = 0.68.$$\nSince $0 < 0.68 < 2$, the stability condition is satisfied, and our derivation is valid for these parameters.\n\nNow we compute the two terms in the maximum function.\nThe first term is the initial expected value:\n$$\\mathbb{E}[V(X_0)] = 1 + m^2 + s^2 = 1 + (-0.5)^2 + 0.8 = 1 + 0.25 + 0.8 = 2.05.$$\nThe second term is the asymptotic bound:\n$$1 + \\frac{\\sigma^2}{\\lambda(2 - \\lambda h)} = 1 + \\frac{1.3^2}{1.7(2 - 0.68)} = 1 + \\frac{1.69}{1.7(1.32)} = 1 + \\frac{1.69}{2.244}.$$\nCalculating the fraction:\n$$\\frac{1.69}{2.244} \\approx 0.75311943.$$\nSo, the second term is approximately $1 + 0.75311943 = 1.75311943$.\n\nFinally, we find the constant $C$:\n$$C = \\max(2.05, 1.75311943) = 2.05.$$\nRounding to four significant figures gives $2.050$.", "answer": "$$\\boxed{2.050}$$", "id": "2988098"}, {"introduction": "It is a common misconception that a numerical method that accurately converges to the true solution path will also be stable over long time horizons. This exercise challenges that notion by exploring the crucial distinction between strong convergence and moment stability. By analyzing the Euler-Maruyama scheme, you will demonstrate from first principles how a method can be convergent for any finite time interval as $h \\to 0$, yet fail to reproduce the long-term stability of the underlying system for a fixed step-size $h \\gt 0$, a key insight for any practitioner of numerical SDEs [@problem_id:2988101].", "problem": "Consider the scalar linear Itô stochastic differential equation (SDE) $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with initial condition $X(0)=x_{0}\\in\\mathbb{R}$, where $\\lambda\\in\\mathbb{R}$ and $\\mu\\in\\mathbb{R}$ are constants and $W$ is a standard Wiener process. Recall the following foundational definitions.\n\n- Strong convergence (at a terminal time) of a numerical method $X^{h}_{N}$ with time step $h=T/N$ to the exact solution $X(T)$ at time $T>0$ means that $\\lim_{h\\to 0}\\mathbb{E}\\!\\left[|X(T)-X^{h}_{N}|^{p}\\right]=0$ for some $p\\ge 1$.\n\n- Exponential mean-square stability of the exact solution for the SDE above is characterized by the condition $2\\lambda+\\mu^{2}<0$, which implies $\\mathbb{E}\\!\\left[|X(t)|^{2}\\right]\\to 0$ as $t\\to\\infty$.\n\n- A numerical method is called unconditionally mean-square stable (a moment stability property) for the linear test SDE if, whenever $2\\lambda+\\mu^{2}<0$, it holds that for every step size $h>0$, the numerical solution satisfies $\\mathbb{E}\\!\\left[|X^{h}_{n}|^{2}\\right]\\to 0$ as $n\\to\\infty$.\n\nYour goal is to assess the logical implication “strong convergence of a scheme” $\\Rightarrow$ “moment stability” in the absence of additional dissipativity assumptions on the method, by identifying a valid counterexample. You must start from the core definitions above and general properties of the Euler-Maruyama method and related linear recursions derived from independence and moments of Gaussian increments.\n\nWhich option correctly constructs such a counterexample and justifies it from first principles?\n\nA. Take the Euler-Maruyama (EM) method applied to $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with parameters $\\lambda<0$ and $2\\lambda+\\mu^{2}<0$. The scheme is strongly convergent on any finite interval for globally Lipschitz coefficients, yet its second-moment recursion yields an amplification factor $q(h)$ satisfying $q(h)>1$ for sufficiently large $h$, so the method is not unconditionally mean-square stable even though the exact solution is exponentially mean-square stable. This shows strong convergence does not imply moment stability without additional dissipativity.\n\nB. Take the implicit backward Euler-Maruyama method applied to $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with $\\lambda<0$ and $2\\lambda+\\mu^{2}<0$. Although the scheme is strongly convergent, it is not unconditionally mean-square stable, hence it provides the desired counterexample.\n\nC. Take the Euler-Maruyama method applied to $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with $\\lambda>0$. The scheme is strongly convergent, and because the numerical moments grow for large $t$, this demonstrates that strong convergence does not imply moment stability.\n\nD. Take a tamed Euler scheme for a superlinearly growing drift and globally Lipschitz diffusion. The method is known to be strongly convergent; nevertheless, its moments are unbounded on finite time intervals, showing that strong convergence does not imply moment stability.", "solution": "The central task is to find a valid counterexample to the logical implication that strong convergence of a numerical scheme for a stochastic differential equation (SDE) implies its moment stability. Moment stability, in this context, refers to unconditional mean-square stability as defined in the problem statement. The counterexample must be constructed from first principles for the provided scalar linear Itô SDE:\n$$dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t), \\quad X(0)=x_{0}$$\nwhere $\\lambda, \\mu \\in \\mathbb{R}$ are constants.\n\nA counterexample requires a numerical method and an SDE such that:\n1.  The method is strongly convergent for the SDE on any finite time interval $[0, T]$.\n2.  The exact solution of the SDE is exponentially mean-square stable.\n3.  The numerical method is *not* unconditionally mean-square stable.\n\nLet us analyze the Euler-Maruyama (EM) method applied to this SDE.\n\n**1. Strong Convergence of the Euler-Maruyama Method**\nThe SDE has a drift function $f(x) = \\lambda x$ and a diffusion function $g(x) = \\mu x$. Both functions are globally Lipschitz continuous because for any $x, y \\in \\mathbb{R}$:\n$$|f(x)-f(y)| = |\\lambda x - \\lambda y| = |\\lambda| |x-y|$$\n$$|g(x)-g(y)| = |\\mu x - \\mu y| = |\\mu| |x-y|$$\nIt is a standard result in the numerical analysis of SDEs that if the drift and diffusion coefficients are globally Lipschitz, the Euler-Maruyama method exhibits strong convergence of order $p=1$ with a rate of $1/2$. That is, for any finite time $T > 0$ and time step $h=T/N$:\n$$\\mathbb{E}\\left[|X(T)-X^{h}_{N}|\\right] \\leq C\\sqrt{h}$$\nfor some constant $C>0$ that is independent of $h$. This implies $\\lim_{h\\to 0}\\mathbb{E}\\left[|X(T)-X^{h}_{N}|\\right]=0$. Thus, the EM method is strongly convergent for this SDE, satisfying the first requirement for our counterexample.\n\n**2. Stability of the Exact Solution**\nThe problem states that exponential mean-square stability of the exact solution is characterized by the condition $2\\lambda+\\mu^{2}<0$. This condition implies $\\mathbb{E}\\left[|X(t)|^{2}\\right]\\to 0$ as $t\\to\\infty$. To construct our counterexample, we must assume parameters $\\lambda$ and $\\mu$ are chosen such that this condition holds. Note that this requires $\\lambda < 0$, since $2\\lambda < -\\mu^2 \\leq 0$. So, the exact solution is stable. This satisfies the second requirement.\n\n**3. Mean-Square Stability of the Euler-Maruyama Method**\nThe EM discretization of the SDE is given by the recurrence relation:\n$$X^{h}_{n+1} = X^{h}_{n} + \\lambda X^{h}_{n}h + \\mu X^{h}_{n}\\Delta W_{n}$$\nwhere $X^{h}_{n}$ is the numerical approximation at time $t_n = n h$ and $\\Delta W_{n} = W(t_{n+1})-W(t_n)$ are independent random variables with distribution $\\mathcal{N}(0, h)$. We can write the scheme as:\n$$X^{h}_{n+1} = \\left(1 + \\lambda h + \\mu \\Delta W_{n}\\right) X^{h}_{n}$$\nTo analyze the mean-square stability, we derive the recurrence for the second moment, $\\mathbb{E}\\left[|X^{h}_{n}|^{2}\\right]$.\n$$\\mathbb{E}\\left[|X^{h}_{n+1}|^{2}\\right] = \\mathbb{E}\\left[\\left|\\left(1 + \\lambda h + \\mu \\Delta W_{n}\\right) X^{h}_{n}\\right|^{2}\\right]$$\nSince $X^{h}_{n}$ depends on Wiener increments up to time $t_n$, it is independent of $\\Delta W_{n}$. We can separate the expectations:\n$$\\mathbb{E}\\left[|X^{h}_{n+1}|^{2}\\right] = \\mathbb{E}\\left[\\left|1 + \\lambda h + \\mu \\Delta W_{n}\\right|^{2}\\right] \\mathbb{E}\\left[|X^{h}_{n}|^{2}\\right]$$\nLet the amplification factor be $q(h) = \\mathbb{E}\\left[\\left|1 + \\lambda h + \\mu \\Delta W_{n}\\right|^{2}\\right]$. Using the properties $\\mathbb{E}[\\Delta W_n]=0$ and $\\mathbb{E}[(\\Delta W_n)^2]=h$, we calculate:\n$$q(h) = \\mathbb{E}\\left[ (1+\\lambda h)^2 + 2(1+\\lambda h)\\mu\\Delta W_n + \\mu^2 (\\Delta W_n)^2 \\right]$$\n$$q(h) = (1+\\lambda h)^2 + 2(1+\\lambda h)\\mu\\mathbb{E}[\\Delta W_n] + \\mu^2 \\mathbb{E}[(\\Delta W_n)^2]$$\n$$q(h) = 1 + 2\\lambda h + \\lambda^2 h^2 + \\mu^2 h = 1 + (2\\lambda + \\mu^2)h + \\lambda^2 h^2$$\nThe recurrence for the second moment becomes $\\mathbb{E}\\left[|X^{h}_{n+1}|^{2}\\right] = q(h) \\mathbb{E}\\left[|X^{h}_{n}|^{2}\\right]$. The numerical solution is mean-square stable if and only if $|q(h)| < 1$.\nUnconditional mean-square stability requires $|q(h)| < 1$ for all step sizes $h>0$, given that $2\\lambda+\\mu^2<0$.\n\nLet's test this condition. Since we assume $2\\lambda+\\mu^2<0$ and this implies $\\lambda<0$, the term $\\lambda^2$ is strictly positive. The function $q(h)$ is an upward-opening parabola in $h$ with $q(0)=1$.\nThe condition $q(h) < 1$ is:\n$$1 + (2\\lambda + \\mu^2)h + \\lambda^2 h^2 < 1$$\n$$(2\\lambda + \\mu^2)h + \\lambda^2 h^2 < 0$$\n$$h\\left((2\\lambda + \\mu^2) + \\lambda^2 h\\right) < 0$$\nSince we consider $h>0$, this simplifies to:\n$$(2\\lambda + \\mu^2) + \\lambda^2 h < 0 \\implies \\lambda^2 h < -(2\\lambda + \\mu^2)$$\n$$h < -\\frac{2\\lambda + \\mu^2}{\\lambda^2}$$\nThis shows that the stability condition $q(h)<1$ only holds for a bounded interval of step sizes $h$, specifically $0 < h < -(2\\lambda+\\mu^2)/\\lambda^2$. For any $h$ larger than this upper bound, $q(h) > 1$, and the second moments of the numerical solution will grow to infinity, i.e., $\\mathbb{E}\\left[|X^{h}_{n}|^{2}\\right] \\to \\infty$ as $n \\to \\infty$.\nTherefore, the Euler-Maruyama method is *not* unconditionally mean-square stable. This satisfies the third requirement for our counterexample.\n\nIn conclusion, the Euler-Maruyama method applied to the linear test SDE with $2\\lambda+\\mu^2<0$ is strongly convergent but not unconditionally mean-square stable. This serves as a perfect counterexample showing that strong convergence does not imply moment stability.\n\nNow, we evaluate each option.\n\n**A. Take the Euler-Maruyama (EM) method applied to $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with parameters $\\lambda<0$ and $2\\lambda+\\mu^{2}<0$. The scheme is strongly convergent on any finite interval for globally Lipschitz coefficients, yet its second-moment recursion yields an amplification factor $q(h)$ satisfying $q(h)>1$ for sufficiently large $h$, so the method is not unconditionally mean-square stable even though the exact solution is exponentially mean-square stable. This shows strong convergence does not imply moment stability without additional dissipativity.**\nThis option correctly identifies the Euler-Maruyama method as the subject. It correctly states the conditions for stability of the exact solution ($\\lambda < 0$ is a necessary consequence of $2\\lambda + \\mu^2 < 0$). It correctly asserts that EM is strongly convergent. Its analysis of the amplification factor $q(h)$ and the conclusion that $q(h)>1$ for large $h$ aligns perfectly with our derivation. The final conclusion that EM is not unconditionally mean-square stable and thus provides the desired counterexample is correct.\n**Verdict: Correct.**\n\n**B. Take the implicit backward Euler-Maruyama method applied to $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with $\\lambda<0$ and $2\\lambda+\\mu^{2}<0$. Although the scheme is strongly convergent, it is not unconditionally mean-square stable, hence it provides the desired counterexample.**\nLet us analyze the standard backward Euler-Maruyama method (implicit drift, explicit diffusion):\n$X^{h}_{n+1} = X^{h}_{n} + \\lambda X^{h}_{n+1} h + \\mu X^{h}_{n} \\Delta W_n$.\nSolving for $X^{h}_{n+1}$ yields $X^{h}_{n+1}(1-\\lambda h) = X^{h}_{n}(1+\\mu\\Delta W_n)$, so $X^{h}_{n+1} = \\frac{1+\\mu\\Delta W_n}{1-\\lambda h}X^{h}_{n}$.\nThe amplification factor for the second moment is $q_B(h) = \\mathbb{E}\\left[\\left|\\frac{1+\\mu\\Delta W_n}{1-\\lambda h}\\right|^2\\right] = \\frac{\\mathbb{E}[|1+\\mu\\Delta W_n|^2]}{(1-\\lambda h)^2} = \\frac{1+\\mu^2 h}{(1-\\lambda h)^2}$.\nFor stability, we need $q_B(h)<1$, which means $1+\\mu^2 h < (1-\\lambda h)^2 = 1 - 2\\lambda h + \\lambda^2 h^2$.\nThis simplifies to $\\mu^2 h < -2\\lambda h + \\lambda^2 h^2$. Since $h>0$, we divide by $h$ to get $\\mu^2 < -2\\lambda + \\lambda^2 h$, or $2\\lambda + \\mu^2 < \\lambda^2 h$.\nUnder the assumption that the exact solution is stable ($2\\lambda+\\mu^2 < 0$), the left side is a negative constant. The right side, $\\lambda^2 h$, is non-negative for all $h>0$. Thus, the inequality $2\\lambda+\\mu^2 < \\lambda^2 h$ is satisfied for all $h>0$. The backward Euler-Maruyama method is, in fact, unconditionally mean-square stable. The option's claim that it is *not* is false.\n**Verdict: Incorrect.**\n\n**C. Take the Euler-Maruyama method applied to $dX(t)=\\lambda X(t)\\,dt+\\mu X(t)\\,dW(t)$ with $\\lambda>0$. The scheme is strongly convergent, and because the numerical moments grow for large $t$, this demonstrates that strong convergence does not imply moment stability.**\nThis option considers a case where $\\lambda>0$. In this scenario, the exact solution is generally not mean-square stable, as $2\\lambda+\\mu^2$ will likely be positive. The concept of a numerical method's moment stability is about its ability to reproduce the stability of a system that is known to be stable. Using an unstable SDE as the test case is a logical flaw. One would expect the numerical moments to grow if the exact moments grow. This does not provide a counterexample to the implication in question.\n**Verdict: Incorrect.**\n\n**D. Take a tamed Euler scheme for a superlinearly growing drift and globally Lipschitz diffusion. The method is known to be strongly convergent; nevertheless, its moments are unbounded on finite time intervals, showing that strong convergence does not imply moment stability.**\nThis option deflects from the problem's specified context. The problem is set up around the linear test SDE. It asks for a justification \"from first principles\", implying the use of the provided definitions and SDE. This option introduces a different class of SDEs (superlinear drift) and a different numerical method (tamed Euler). While the statement might be technically correct in its own context, it is not the counterexample requested by the problem, which is focused on the fundamental relationship between convergence and stability for linear SDEs.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2988101"}]}