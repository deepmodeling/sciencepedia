{"hands_on_practices": [{"introduction": "Understanding infinite divisibility begins with its fundamental definition in terms of characteristic functions. This first practice provides a direct application of this principle using the exponential distribution, a classic example of an infinitely divisible law [@problem_id:1308917]. By working backward from the known characteristic function of an exponential random variable, you will derive the characteristic function of its constituent i.i.d. components, reinforcing the core algebraic property that underpins this concept.", "problem": "A random variable $Y$ is said to be infinitely divisible if for any positive integer $n$, it can be represented as the sum of $n$ independent and identically distributed (i.i.d.) random variables, i.e., $Y = X_1 + X_2 + \\dots + X_n$, where $X_1, X_2, \\dots, X_n$ are i.i.d.\n\nConsider a random variable $Y$ that follows an exponential distribution with rate parameter $\\lambda > 0$. Its characteristic function, denoted by $\\phi_Y(t)$, is given by:\n$$\n\\phi_Y(t) = \\frac{\\lambda}{\\lambda - it}\n$$\nwhere $i$ is the imaginary unit and $t$ is a real number.\n\nGiven that the exponential distribution is infinitely divisible, it can be expressed as $Y = X_1 + X_2 + \\dots + X_n$ for any integer $n \\ge 1$, where the $X_k$ are i.i.d. random variables. Determine the characteristic function, $\\phi_X(t)$, of one of these components, $X_k$.", "solution": "Let $Y$ be exponential with rate $\\lambda>0$, so its characteristic function is $\\phi_{Y}(t)=\\lambda/(\\lambda-it)$. By infinite divisibility, for any integer $n\\ge 1$ there exist i.i.d. $X_{1},\\dots,X_{n}$ such that $Y=X_{1}+\\dots+X_{n}$. For characteristic functions, independence and identical distribution imply\n$$\n\\phi_{Y}(t)=\\mathbb{E}\\!\\left[\\exp\\!\\left(i t\\sum_{k=1}^{n}X_{k}\\right)\\right]=\\prod_{k=1}^{n}\\mathbb{E}\\!\\left[\\exp(i t X_{k})\\right]=\\prod_{k=1}^{n}\\phi_{X}(t)=[\\phi_{X}(t)]^{n}.\n$$\nSolving for $\\phi_{X}(t)$ gives\n$$\n\\phi_{X}(t)=[\\phi_{Y}(t)]^{\\frac{1}{n}}.\n$$\nSubstituting the given $\\phi_{Y}(t)$ yields\n$$\n\\phi_{X}(t)=\\left(\\frac{\\lambda}{\\lambda-it}\\right)^{\\frac{1}{n}}.\n$$\nThis is the characteristic function of a Gamma distribution with shape parameter $1/n$ and rate $\\lambda$, consistent with the infinite divisibility of the exponential distribution.", "answer": "$$\\boxed{\\left(\\frac{\\lambda}{\\lambda-it}\\right)^{\\frac{1}{n}}}$$", "id": "1308917"}, {"introduction": "While some distributions can be infinitely decomposed, many cannot. A crucial diagnostic tool arises from the Lévy-Khintchine representation, which implies that the characteristic function of an infinitely divisible distribution can never be zero for real $t$. This exercise challenges you to apply this powerful criterion to the uniform distribution, demonstrating how a simple property of its characteristic function provides a definitive proof against infinite divisibility [@problem_id:1308908].", "problem": "A random variable $Y$ is said to be infinitely divisible if for any positive integer $n$, there exist $n$ independent and identically distributed (i.i.d.) random variables $Y_1, Y_2, \\ldots, Y_n$ such that $Y$ has the same distribution as the sum $\\sum_{i=1}^{n} Y_i$. This property implies that for any integer $n \\ge 1$, the function $[\\phi_Y(t)]^{1/n}$ must be a valid characteristic function, where $\\phi_Y(t)$ is the characteristic function of $Y$.\n\nConsider a random variable $X$ that is uniformly distributed on the interval $[-1, 1]$. Its characteristic function is given by\n$$\n\\phi_X(t) = \n\\begin{cases} \n\\frac{\\sin(t)}{t} & t \\neq 0 \\\\\n1 & t = 0 \n\\end{cases}\n$$\nBased on the properties of characteristic functions, select the correct argument that explains why the random variable $X$ is not infinitely divisible.\n\nA. The characteristic function $\\phi_X(t)$ has real zeros for $t \\neq 0$. If $X$ were infinitely divisible, its characteristic function could not have any real zeros.\n\nB. The random variable $X$ has a bounded support, $[-1, 1]$. An infinitely divisible random variable must have unbounded support, such as the entire real line.\n\nC. The characteristic function $\\phi_X(t)$ is not complex-valued for real $t$, whereas the characteristic function corresponding to a component of an infinitely divisible distribution, $[\\phi_X(t)]^{1/n}$, must be complex-valued for some $t$ if $n > 1$.\n\nD. The distribution of $X$ is symmetric around 0. Infinitely divisible distributions are fundamentally asymmetric, a property inherited by the sum of i.i.d. random variables.\n\nE. The variance of $X$ is finite. For $X$ to be infinitely divisible, the variance of the component random variables $Y_i$ would be $\\frac{\\text{Var}(X)}{n}$, which would tend to zero. A non-degenerate random variable cannot have zero variance.", "solution": "An infinitely divisible distribution has a characteristic function of Lévy–Khintchine form\n$$\n\\phi(t) = \\exp\\!\\Big(\\mathrm{i}\\mu t - \\tfrac{1}{2}\\sigma^{2} t^{2} + \\int_{\\mathbb{R}} \\big(e^{\\mathrm{i}tx} - 1 - \\mathrm{i}tx\\,\\mathbf{1}_{\\{|x|<1\\}}\\big)\\,\\nu(dx)\\Big),\n$$\nwhere $\\mu \\in \\mathbb{R}$, $\\sigma \\ge 0$, and $\\nu$ is a Lévy measure. Since the exponential function never vanishes, any infinitely divisible characteristic function satisfies\n$$\n\\phi(t) \\neq 0 \\quad \\text{for all real } t.\n$$\nFor $X \\sim \\mathrm{Unif}[-1,1]$, the characteristic function is\n$$\n\\phi_{X}(t) = \\frac{\\sin t}{t} \\quad (t \\neq 0), \\qquad \\phi_{X}(0)=1,\n$$\nwhich has real zeros at $t = k\\pi$ for all integers $k \\neq 0$. Hence $\\phi_{X}$ vanishes at nonzero real $t$, so $X$ cannot be infinitely divisible. This directly validates option A.\n\nBriefly, why the others are incorrect:\n- B: Although non-degenerate infinitely divisible laws on $\\mathbb{R}$ indeed cannot have bounded support, the statement “must have unbounded support, such as the entire real line” is misleading and not the characteristic-function-based argument requested; moreover, many infinitely divisible laws (e.g., Poisson) do not have support equal to the entire real line.\n- C: Characteristic functions of symmetric distributions can be real-valued on $\\mathbb{R}$; there is no requirement that $[\\phi(t)]^{1/n}$ be complex-valued.\n- D: Symmetry does not preclude infinite divisibility (e.g., Gaussian is both symmetric and infinitely divisible).\n- E: The variance argument is invalid; for each fixed $n$, the component variance $\\mathrm{Var}(Y_{i})=\\mathrm{Var}(X)/n$ is positive (unless degenerate), and there is no contradiction as $n$ varies.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1308908"}, {"introduction": "The centerpiece of the theory of infinitely divisible distributions is the Lévy-Khintchine formula, which provides a canonical representation for any such law. This advanced exercise moves beyond simple cases and engages directly with this powerful formula by asking you to analyze a characteristic function given in its general form [@problem_id:2980563]. Your task is to validate the given Lévy measure and evaluate the jump integral to identify the distribution as a specific member of the stable family, thereby connecting the abstract components of the formula to a concrete stochastic process.", "problem": "Consider a noise model for a Stochastic Differential Equation (SDE), where the one-step law at time $t$ has characteristic function\n$$\\phi(t)=\\exp\\left(i\\gamma t-\\frac{1}{2}\\sigma^{2} t^{2}+\\int_{\\mathbb{R}}\\left(\\exp(i t x)-1-i t x\\,\\mathbf{1}_{\\{|x|\\le 1\\}}\\right)\\,c\\,|x|^{-1-\\alpha}\\,dx\\right),$$\nwith parameters $\\gamma\\in\\mathbb{R}$, $\\sigma\\ge 0$, $c\\ge 0$, and $\\alpha\\in(0,2)$. The jump part is symmetric, with candidate Lévy measure $\\nu(dx)=c\\,|x|^{-1-\\alpha}\\,dx$ on $\\mathbb{R}\\setminus\\{0\\}$.\n\nUsing only the Lévy–Khintchine representation for infinitely divisible distributions, the definition of a valid Lévy measure, and standard Fourier integral identities, perform the following:\n\n- Determine the parameter constraints on $c$ and $\\alpha$ under which $\\nu$ is a valid Lévy measure (i.e., satisfies $\\int_{\\mathbb{R}}(1\\wedge x^{2})\\,\\nu(dx)<\\infty$).\n- Exploit the symmetry of $\\nu$ to simplify the integral term in the exponent, and evaluate it in closed form as a constant multiple of $|t|^{\\alpha}$. Then, identify the resulting law class for $\\phi(t)$ in terms of a Gaussian component and a symmetric $\\alpha$-stable jump component.\n\nYour final answer must be the fully simplified characteristic function $\\phi(t)$ expressed in terms of $|t|^{\\alpha}$ with the constant written in closed form using only $\\Gamma(\\cdot)$ and trigonometric functions. No rounding is required, and no units are involved. The final answer must be a single closed-form analytic expression.", "solution": "The solution proceeds in three parts: first, we validate that the given Lévy measure $\\nu(dx)$ is well-defined under the specified parameter constraints. Second, we simplify and evaluate the integral part of the characteristic exponent. Third, we assemble the final characteristic function and identify the law it represents.\n\n**Part 1: Validation of the Lévy Measure**\n\nA measure $\\nu$ on $\\mathbb{R}\\setminus\\{0\\}$ is a valid Lévy measure if it satisfies the condition $\\int_{\\mathbb{R}}(1\\wedge x^{2})\\,\\nu(dx)<\\infty$.\nThe problem provides the candidate Lévy measure $\\nu(dx)=c\\,|x|^{-1-\\alpha}\\,dx$, with parameters $c\\ge 0$ and $\\alpha\\in(0,2)$.\nWe must verify if this measure satisfies the condition for the given parameter range. The integral is:\n$$ \\int_{\\mathbb{R}}(1\\wedge x^{2})\\,c\\,|x|^{-1-\\alpha}\\,dx $$\nSince the integrand $(1\\wedge x^{2})\\,c\\,|x|^{-1-\\alpha}$ is an even function of $x$, we can write the integral as:\n$$ 2c \\int_{0}^{\\infty} (1\\wedge x^{2})\\,x^{-1-\\alpha}\\,dx $$\nWe split the integral into two parts, over the domains $(0, 1]$ and $(1, \\infty)$:\n$$ 2c \\left( \\int_{0}^{1} x^{2} \\cdot x^{-1-\\alpha}\\,dx + \\int_{1}^{\\infty} 1 \\cdot x^{-1-\\alpha}\\,dx \\right) $$\nThe first integral is:\n$$ \\int_{0}^{1} x^{1-\\alpha}\\,dx = \\left[ \\frac{x^{2-\\alpha}}{2-\\alpha} \\right]_{0}^{1} $$\nFor this integral to converge at the lower limit $x=0$, we require the exponent $2-\\alpha$ to be positive, i.e., $\\alpha < 2$. If this holds, the integral evaluates to $\\frac{1}{2-\\alpha}$.\n\nThe second integral is:\n$$ \\int_{1}^{\\infty} x^{-1-\\alpha}\\,dx = \\left[ \\frac{x^{-\\alpha}}{-\\alpha} \\right]_{1}^{\\infty} $$\nFor this integral to converge at the upper limit $x\\to\\infty$, we require the exponent $-\\alpha$ to be negative, i.e., $\\alpha > 0$. If this holds, the integral evaluates to $0 - \\frac{1}{-\\alpha} = \\frac{1}{\\alpha}$.\n\nCombining these results, the total integral is:\n$$ 2c \\left( \\frac{1}{2-\\alpha} + \\frac{1}{\\alpha} \\right) = 2c \\left( \\frac{\\alpha + 2 - \\alpha}{\\alpha(2-\\alpha)} \\right) = \\frac{4c}{\\alpha(2-\\alpha)} $$\nThis expression is finite if and only if $c \\ge 0$ and the denominator is non-zero, which means $\\alpha \\in (0,2)$. These are precisely the constraints given in the problem statement. Thus, $\\nu(dx)=c\\,|x|^{-1-\\alpha}\\,dx$ is a valid Lévy measure for $c \\ge 0$ and $\\alpha \\in (0,2)$.\n\n**Part 2: Simplification and Evaluation of the Jump Component**\n\nThe characteristic function is given by:\n$$ \\phi(t)=\\exp\\left(i\\gamma t-\\frac{1}{2}\\sigma^{2} t^{2}+\\int_{\\mathbb{R}}\\left(\\exp(i t x)-1-i t x\\,\\mathbf{1}_{\\{|x|\\le 1\\}}\\right)\\,\\nu(dx)\\right) $$\nLet's analyze the integral term, which we denote as $I(t)$:\n$$ I(t) = \\int_{\\mathbb{R}}\\left(\\exp(i t x)-1-i t x\\,\\mathbf{1}_{\\{|x|\\le 1\\}}\\right)\\,c\\,|x|^{-1-\\alpha}\\,dx $$\nWe can split the integrand into its real and imaginary parts:\n$$ \\exp(i t x)-1-i t x\\,\\mathbf{1}_{\\{|x|\\le 1\\}} = (\\cos(tx)-1) + i(\\sin(tx) - tx\\,\\mathbf{1}_{\\{|x|\\le 1\\}}) $$\nThe Lévy measure density $c\\,|x|^{-1-\\alpha}$ is an even function of $x$. The imaginary part of the integrand, $(\\sin(tx) - tx\\,\\mathbf{1}_{\\{|x|\\le 1\\}})$, is an odd function of $x$. The integral of an odd function multiplied by an even function over a symmetric domain ($\\mathbb{R}$) is zero. Therefore, the imaginary part of $I(t)$ vanishes due to the symmetry of the Lévy measure.\n\nThe integral $I(t)$ simplifies to its real part:\n$$ I(t) = \\int_{\\mathbb{R}} (\\cos(tx) - 1)\\,c\\,|x|^{-1-\\alpha}\\,dx $$\nThe integrand is now an even function of $x$, so we can write:\n$$ I(t) = 2c \\int_{0}^{\\infty} (\\cos(tx) - 1)\\,x^{-1-\\alpha}\\,dx $$\nTo evaluate this integral, we perform a change of variables. Let $u = tx$ (for $t > 0$), so $x = u/t$ and $dx = du/t$.\n$$ I(t) = 2c \\int_{0}^{\\infty} (\\cos(u) - 1)\\,(u/t)^{-1-\\alpha}\\,\\frac{du}{t} = 2c\\,t^{\\alpha} \\int_{0}^{\\infty} (\\cos(u) - 1)\\,u^{-1-\\alpha}\\,du $$\nIf $t < 0$, the substitution $u = -tx$ leads to the same expression with $t$ replaced by $-t$. Thus, for any $t \\in \\mathbb{R}$, the dependence is on $|t|^{\\alpha}$.\n$$ I(t) = 2c\\,|t|^{\\alpha} \\int_{0}^{\\infty} (\\cos(u) - 1)\\,u^{-1-\\alpha}\\,du $$\nThe definite integral is a known result related to the Gamma function. We use the standard identity:\n$$ \\int_{0}^{\\infty} x^{\\mu-1}(1-\\cos(ax))\\,dx = -a^{-\\mu}\\Gamma(\\mu)\\cos\\left(\\frac{\\pi\\mu}{2}\\right), \\quad \\text{for } a>0, -2 < \\Re(\\mu) < 0 $$\nOur integral is $\\int_{0}^{\\infty} u^{-1-\\alpha}(\\cos u - 1)du = -\\int_{0}^{\\infty} u^{-1-\\alpha}(1-\\cos u)du$.\nHere, $a=1$ and the exponent is $\\mu-1 = -1-\\alpha$, which implies $\\mu = -\\alpha$. The condition on $\\alpha \\in (0,2)$ ensures that $-2 < -\\alpha < 0$, so the identity is applicable.\nThe integral evaluates to:\n$$ - \\left( -1^{-\\alpha}\\Gamma(-\\alpha)\\cos\\left(\\frac{-\\pi\\alpha}{2}\\right) \\right) = \\Gamma(-\\alpha)\\cos\\left(\\frac{\\pi\\alpha}{2}\\right) $$\nSo, the jump component is $I(t) = 2c\\,|t|^{\\alpha} \\Gamma(-\\alpha)\\cos\\left(\\frac{\\pi\\alpha}{2}\\right)$.\nTo simplify the constant, we use the Gamma function reflection and recursion formulas: $\\Gamma(z)\\Gamma(1-z) = \\frac{\\pi}{\\sin(\\pi z)}$ and $\\Gamma(z+1)=z\\Gamma(z)$.\nThe constant is $K = 2c\\,\\Gamma(-\\alpha)\\cos\\left(\\frac{\\pi\\alpha}{2}\\right)$. Using $\\Gamma(-\\alpha) = \\frac{\\Gamma(1-\\alpha)}{-\\alpha}$, we get:\n$$ K = -\\frac{2c}{\\alpha}\\Gamma(1-\\alpha)\\cos\\left(\\frac{\\pi\\alpha}{2}\\right) $$\nUsing the reflection formula, $\\Gamma(1-\\alpha) = \\frac{\\pi}{\\Gamma(\\alpha)\\sin(\\pi\\alpha)}$.\n$$ K = -\\frac{2c}{\\alpha} \\frac{\\pi}{\\Gamma(\\alpha)\\sin(\\pi\\alpha)} \\cos\\left(\\frac{\\pi\\alpha}{2}\\right) $$\nUsing the double-angle identity $\\sin(\\pi\\alpha) = 2\\sin(\\frac{\\pi\\alpha}{2})\\cos(\\frac{\\pi\\alpha}{2})$:\n$$ K = -\\frac{2c}{\\alpha} \\frac{\\pi}{\\Gamma(\\alpha)2\\sin(\\frac{\\pi\\alpha}{2})\\cos(\\frac{\\pi\\alpha}{2})} \\cos\\left(\\frac{\\pi\\alpha}{2}\\right) = -\\frac{c\\pi}{\\alpha\\Gamma(\\alpha)\\sin(\\frac{\\pi\\alpha}{2})} $$\nUsing $\\Gamma(1+\\alpha) = \\alpha\\Gamma(\\alpha)$, we obtain the final form of the constant:\n$$ K = -\\frac{c\\pi}{\\Gamma(1+\\alpha)\\sin\\left(\\frac{\\pi\\alpha}{2}\\right)} $$\nThe jump component is thus $I(t) = -\\frac{c\\pi}{\\Gamma(1+\\alpha)\\sin\\left(\\frac{\\pi\\alpha}{2}\\right)}|t|^{\\alpha}$.\n\n**Part 3: Final Characteristic Function and Law Identification**\n\nSubstituting the evaluated integral back into the expression for $\\phi(t)$:\n$$ \\phi(t) = \\exp\\left(i\\gamma t - \\frac{1}{2}\\sigma^2 t^2 - \\frac{c\\pi}{\\Gamma(1+\\alpha)\\sin\\left(\\frac{\\pi\\alpha}{2}\\right)}|t|^{\\alpha}\\right) $$\nThis is the characteristic function of a general Lévy process. By the Lévy-Itô decomposition, the law is a convolution of three independent components:\n1.  A deterministic drift with rate $\\gamma$, represented by the term $i\\gamma t$.\n2.  A Gaussian component (Brownian motion) with variance $\\sigma^2$, represented by the term $-\\frac{1}{2}\\sigma^2 t^2$.\n3.  A pure jump symmetric $\\alpha$-stable process, represented by the term $-C_\\alpha|t|^{\\alpha}$ where the constant $C_\\alpha = \\frac{c\\pi}{\\Gamma(1+\\alpha)\\sin\\left(\\frac{\\pi\\alpha}{2}\\right)}$ is positive for $\\alpha \\in (0,2)$ and $c>0$.\n\nThe resulting law is that of a random variable $X = \\gamma + X_G + X_S$, where $X_G \\sim N(0, \\sigma^2)$ and $X_S$ is a symmetric $\\alpha$-stable random variable, and all three are independent.\nThe problem requests the final simplified characteristic function.", "answer": "$$\n\\boxed{\\exp\\left(i\\gamma t - \\frac{1}{2}\\sigma^2 t^2 - \\frac{c\\pi |t|^{\\alpha}}{\\Gamma(1+\\alpha)\\sin\\left(\\frac{\\pi\\alpha}{2}\\right)}\\right)}\n$$", "id": "2980563"}]}