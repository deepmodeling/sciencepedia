{"hands_on_practices": [{"introduction": "Understanding the long-term behavior of a dynamic system is a central goal in many scientific fields. This practice provides a concrete example of how to determine this equilibrium, known as the steady-state vector. By modeling a user's browsing habits as a Markov chain, you will apply the core definition of a steady-state vector $\\mathbf{q}$—that it remains unchanged by the transition matrix $P$, satisfying $P\\mathbf{q} = \\mathbf{q}$. This exercise [@problem_id:1382127] is a fundamental workout in setting up and solving the system of linear equations that defines the stable, long-run distribution of the system.", "problem": "A simplified model for a user's web browsing behavior tracks their state across three types of web pages: Home (H), Content (C), and Purchase (P). The probability of a user transitioning from one page type to another depends only on their current page type. The observed transition probabilities are as follows:\n\n- A user on a Home page (H) has a 50% chance of staying on a Home page, a 30% chance of moving to a Content page (C), and a 20% chance of moving to a Purchase page (P).\n- A user on a Content page (C) has a 20% chance of moving to a Home page (H), a 60% chance of staying on a Content page (C), and a 20% chance of moving to a Purchase page (P).\n- A user on a Purchase page (P) has a 10% chance of moving to a Home page (H), a 40% chance of moving to a Content page (C), and a 50% chance of staying on a Purchase page (P).\n\nA state vector $\\mathbf{x} = \\begin{pmatrix} x_H \\\\ x_C \\\\ x_P \\end{pmatrix}$ represents the probability that a user is on a page of type H, C, or P, respectively. A steady-state probability vector, denoted $\\mathbf{q}$, is a probability vector (i.e., its entries are non-negative and sum to 1) that remains unchanged after one transition. It thus satisfies the matrix equation $P\\mathbf{q} = \\mathbf{q}$, where $P$ is the transition matrix of the system.\n\nDetermine the unique steady-state probability vector $\\mathbf{q}$ for this system. Express your answer as a column vector containing fractions in their simplest form.", "solution": "We model this as a Markov chain with states $H,C,P$ and column-stochastic transition matrix $P$ defined so that $P_{ij}$ is the probability of transitioning to state $i$ from state $j$. From the given transitions:\n- From $H$: to $H$ with $\\frac{1}{2}$, to $C$ with $\\frac{3}{10}$, to $P$ with $\\frac{1}{5}$.\n- From $C$: to $H$ with $\\frac{1}{5}$, to $C$ with $\\frac{3}{5}$, to $P$ with $\\frac{1}{5}$.\n- From $P$: to $H$ with $\\frac{1}{10}$, to $C$ with $\\frac{2}{5}$, to $P$ with $\\frac{1}{2}$.\n\nThus\n$$\nP=\\begin{pmatrix}\n\\frac{1}{2} & \\frac{1}{5} & \\frac{1}{10}\\\n$$4pt]\n\\frac{3}{10} & \\frac{3}{5} & \\frac{2}{5}\\\n$$4pt]\n\\frac{1}{5} & \\frac{1}{5} & \\frac{1}{2}\n\\end{pmatrix},\n$$\nwhich has strictly positive entries, so by the Perron–Frobenius theorem there is a unique steady-state probability vector $\\mathbf{q}$ satisfying $P\\mathbf{q}=\\mathbf{q}$ and $q_{H}+q_{C}+q_{P}=1$.\n\nLet $\\mathbf{q}=\\begin{pmatrix}h\\\\c\\\\p\\end{pmatrix}$. From $P\\mathbf{q}=\\mathbf{q}$, componentwise we have\n$$\n\\frac{1}{2}h+\\frac{1}{5}c+\\frac{1}{10}p=h,\\quad\n\\frac{3}{10}h+\\frac{3}{5}c+\\frac{2}{5}p=c,\\quad\n\\frac{1}{5}h+\\frac{1}{5}c+\\frac{1}{2}p=p.\n$$\nMultiplying each equation by $10$ and rearranging gives\n$$\n-5h+2c+p=0,\\quad 3h-4c+4p=0,\\quad 2h+2c-5p=0.\n$$\nFrom $2h+2c-5p=0$ we get $p=\\frac{2}{5}(h+c)$. From $-5h+2c+p=0$ we get $p=5h-2c$. Equating these two expressions for $p$,\n$$\n\\frac{2}{5}(h+c)=5h-2c \\;\\;\\Longrightarrow\\;\\; 2(h+c)=25h-10c \\;\\;\\Longrightarrow\\;\\; 23h=12c \\;\\;\\Longrightarrow\\;\\; c=\\frac{23}{12}h.\n$$\nThen\n$$\np=5h-2c=5h-2\\cdot\\frac{23}{12}h=\\left(5-\\frac{23}{6}\\right)h=\\frac{7}{6}h.\n$$\nImposing $h+c+p=1$,\n$$\nh+\\frac{23}{12}h+\\frac{7}{6}h=\\left(1+\\frac{23}{12}+\\frac{14}{12}\\right)h=\\frac{49}{12}h=1 \\;\\;\\Longrightarrow\\;\\; h=\\frac{12}{49}.\n$$\nThus\n$$\nc=\\frac{23}{12}\\cdot\\frac{12}{49}=\\frac{23}{49},\\qquad p=\\frac{7}{6}\\cdot\\frac{12}{49}=\\frac{14}{49}=\\frac{2}{7}.\n$$\nTherefore the unique steady-state probability vector is\n$$\n\\begin{pmatrix}\n\\frac{12}{49}\\\n$$4pt]\n\\frac{23}{49}\\\n$$4pt]\n\\frac{2}{7}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{12}{49}\\\\ \\frac{23}{49}\\\\ \\frac{2}{7}\\end{pmatrix}}$$", "id": "1382127"}, {"introduction": "A numerical solution is only as useful as its interpretation. After learning to calculate a steady-state vector, the next step is to understand what its components tell us about the system's dynamics. This problem [@problem_id:1375572] presents a hypothetical polling scenario where the long-term proportion of 'Undecided' individuals settles at zero. Your task is to move beyond the numbers and deduce the physical reason for this outcome by analyzing the structure of the transition matrix, specifically how probability flows between states.", "problem": "A polling company is modeling the weekly shift in public opinion regarding a new municipal policy. The population is divided into three categories: For (F), Against (A), and Undecided (U). The company uses a Markov chain model where the state of the system in week $k$ is given by a vector $x_k = \\begin{pmatrix} f_k \\\\ a_k \\\\ u_k \\end{pmatrix}$, where $f_k, a_k, u_k$ are the proportions of the population in the For, Against, and Undecided categories, respectively.\n\nThe transition from one week to the next is described by the equation $x_{k+1} = P x_k$, where $P$ is the following right stochastic transition matrix:\n$$\nP = \\begin{pmatrix} 0.8 & 0.1 & 0.5 \\\\ 0.2 & 0.9 & 0.3 \\\\ 0.0 & 0.0 & 0.2 \\end{pmatrix}\n$$\nThe entry $P_{ij}$ represents the proportion of the population in state $j$ that moves to state $i$ in one week. For example, the entry $P_{12}=0.1$ means that 10% of those who were Against the policy in one week will be For the policy in the next week.\n\nOver a long period, the system is expected to approach a unique steady-state probability vector $q = \\begin{pmatrix} q_F \\\\ q_A \\\\ q_U \\end{pmatrix}$, which satisfies the equation $Pq=q$. In this model, the steady-state proportion of undecided individuals, $q_U$, is exactly zero.\n\nWhich of the following statements provides the correct physical interpretation of this result?\n\nA. The 'Undecided' state is an absorbing state, meaning once a person becomes undecided, they can never change their opinion.\n\nB. In the long run, the 'Undecided' category becomes effectively empty because individuals who form an opinion (either For or Against) never become undecided again, while undecided individuals consistently move to form an opinion.\n\nC. The model must be flawed, as it is impossible for a category of the population to have a proportion of zero in a real-world scenario.\n\nD. It implies that any initial polling must show zero undecided individuals for the model to be valid.\n\nE. After exactly one week, regardless of the initial opinions, the 'Undecided' category will be empty.", "solution": "We model weekly opinion dynamics with a Markov chain over states For (F), Against (A), and Undecided (U). The state vector is $x_{k}=\\begin{pmatrix} f_{k} \\\\ a_{k} \\\\ u_{k} \\end{pmatrix}$, and the evolution is $x_{k+1}=P x_{k}$, with the column-stochastic matrix\n$$\nP=\\begin{pmatrix}\n0.8 & 0.1 & 0.5 \\\\\n0.2 & 0.9 & 0.3 \\\\\n0.0 & 0.0 & 0.2\n\\end{pmatrix},\n$$\nwhere $P_{ij}$ is the fraction moving from state $j$ to state $i$ in one step. A steady-state probability vector $q=\\begin{pmatrix} q_{F} \\\\ q_{A} \\\\ q_{U} \\end{pmatrix}$ satisfies\n$$\nP q = q,\\quad q_{F}+q_{A}+q_{U}=1,\\quad q_{F},q_{A},q_{U}\\ge 0.\n$$\nWriting $P q = q$ componentwise yields\n$$\n\\begin{aligned}\nq_{F} &= 0.8\\, q_{F} + 0.1\\, q_{A} + 0.5\\, q_{U}, \\\\\nq_{A} &= 0.2\\, q_{F} + 0.9\\, q_{A} + 0.3\\, q_{U}, \\\\\nq_{U} &= 0.0\\, q_{F} + 0.0\\, q_{A} + 0.2\\, q_{U}.\n\\end{aligned}\n$$\nFrom the third equation,\n$$\nq_{U} = 0.2\\, q_{U} \\;\\;\\Longrightarrow\\;\\; (1-0.2)\\, q_{U} = 0 \\;\\;\\Longrightarrow\\;\\; q_{U}=0.\n$$\nThis algebraic consequence reflects the structural properties of the chain: there is no inflow to the Undecided state from For or Against, while there is positive outflow from Undecided to For and Against, with only a subunit self-loop $P_{UU}=0.2$. Therefore, Undecided is a transient state: probability mass starting in Undecided eventually leaves for For or Against and never returns. In the long run, the Undecided category becomes empty in the steady distribution, i.e., $q_{U}=0$.\n\nInterpreting the options:\n- A is incorrect: an absorbing state would require $P_{UU}=1$, which is not the case.\n- B is correct: once individuals form an opinion they never become undecided (zero inflow from For/Against), while undecided individuals tend to leave Undecided (positive outflows and $P_{UU}<1$), so the long-run proportion in Undecided is zero.\n- C is incorrect: zero steady-state probability for a transient state is a standard and valid outcome in Markov chains.\n- D is incorrect: the steady state does not require any particular initial distribution; it describes the long-run behavior irrespective of initial conditions.\n- E is incorrect: after one week $u_{1}=0.2\\, u_{0}$, which is generally nonzero unless $u_{0}=0$.\n\nHence, the correct interpretation is B.", "answer": "$$\\boxed{B}$$", "id": "1375572"}, {"introduction": "While solving the system $(P-I)\\mathbf{q} = \\mathbf{0}$ is a reliable method, it is not always the most insightful. For systems with special symmetries, we can often deduce the steady state by leveraging deeper principles of linear algebra. This problem [@problem_id:1390757] models a random walk on a circle, which results in a highly structured circulant transition matrix. Instead of performing a brute-force calculation, you will use the fundamental connection between the steady-state vector and the eigenvectors of the transition matrix to arrive at an elegant and general solution.", "problem": "Consider a discrete-time Markov chain modeling a random walk on a circular graph with $N$ vertices, which are labeled $v_0, v_1, \\dots, v_{N-1}$. The state of the system at any time is the vertex occupied by a particle.\n\nAt each time step, from any vertex $v_i$, the particle has a probability $p$ of moving to the next vertex in the clockwise direction, $v_{(i+1) \\pmod N}$. It has a probability $r$ of moving to the previous vertex in the counter-clockwise direction, $v_{(i-1) \\pmod N}$. The particle remains at its current vertex $v_i$ with a probability $s = 1 - p - r$. The probabilities $p$ and $r$ are positive constants such that $p+r \\le 1$.\n\nThe transition matrix $P$ for this Markov chain is an $N \\times N$ stochastic circulant matrix. It is a known result from linear algebra that the vectors $\\mathbf{u}_k$, with components $(\\mathbf{u}_k)_j = \\exp\\left(\\frac{2\\pi \\mathrm{i} k j}{N}\\right)$ for $j \\in \\{0, 1, \\dots, N-1\\}$, form a complete set of eigenvectors for any $N \\times N$ circulant matrix, where $k \\in \\{0, 1, \\dots, N-1\\}$.\n\nUsing this fact, determine the component of the unique steady-state vector $\\mathbf{q}$ corresponding to any arbitrary vertex $v_j$. Express your answer as a function of $N$.", "solution": "Let $P$ be the $N \\times N$ circulant transition matrix with entries determined by $p$, $r$, and $s=1-p-r$ so that from $v_{i}$ the walk moves to $v_{(i+1) \\bmod N}$ with probability $p$, to $v_{(i-1) \\bmod N}$ with probability $r$, and stays with probability $s$. For a circulant matrix, the vectors $\\mathbf{u}_{k}$ with components $(\\mathbf{u}_{k})_{j}=\\exp\\!\\left(\\frac{2\\pi \\mathrm{i} k j}{N}\\right)$ for $k\\in\\{0,\\dots,N-1\\}$ form a complete eigenbasis.\n\nDefine $\\omega_{k}=\\exp\\!\\left(\\frac{2\\pi \\mathrm{i} k}{N}\\right)$ so that $(\\mathbf{u}_{k})_{j}=\\omega_{k}^{j}$. Using the circulant structure and modulo-$N$ indexing,\n$$\n(P\\mathbf{u}_{k})_{j}\n= s(\\mathbf{u}_{k})_{j} + p(\\mathbf{u}_{k})_{j-1} + r(\\mathbf{u}_{k})_{j+1}\n= \\left(s + p\\omega_{k}^{-1} + r\\omega_{k}\\right)\\omega_{k}^{j}.\n$$\nEquivalently,\n$$\nP\\mathbf{u}_{k}=\\lambda_{k}\\mathbf{u}_{k}, \\quad \\lambda_{k}=s+p\\omega_{k}^{-1}+r\\omega_{k}.\n$$\nSince $s=1-p-r$, we have\n$$\n\\lambda_{k}=1 - p - r + p\\omega_{k}^{-1} + r\\omega_{k}.\n$$\nFor $k=0$, we have $\\omega_{0}=1$ and hence $\\lambda_{0}=1 - p - r + p + r=1$. Thus $\\mathbf{u}_{0}$ (the all-ones vector) is a right eigenvector with eigenvalue $1$. For $k\\neq 0$, to have $\\lambda_{k}=1$ would require\n$$\np(\\omega_{k}^{-1}-1)+r(\\omega_{k}-1)=0.\n$$\nMultiplying by $\\omega_{k}$ yields\n$$\n(\\omega_{k}-1)(p - r\\omega_{k})=0.\n$$\nSince $\\omega_{k}\\neq 1$ for $k\\neq 0$ and $p$ and $r$ are positive real constants while $\\omega_{k}$ lies on the unit circle with nonzero argument, the equation $p - r\\omega_{k}=0$ cannot hold. Therefore $\\lambda_{k}\\neq 1$ for all $k\\neq 0$, and the eigenspace corresponding to the eigenvalue $1$ is one-dimensional, spanned by $\\mathbf{u}_{0}$.\n\nThe steady-state vector $\\mathbf{q}$ satisfies $P\\mathbf{q}=\\mathbf{q}$ and is unique for this irreducible finite chain. Since the eigenspace for eigenvalue $1$ is spanned by $\\mathbf{u}_{0}$, $\\mathbf{q}$ must be proportional to $\\mathbf{u}_{0}$; hence $q_{j}=c$ for all $j$. The normalization condition $\\sum_{j=0}^{N-1}q_{j}=1$ gives $Nc=1$, so $c=\\frac{1}{N}$. Therefore, for any vertex $v_{j}$,\n$$\nq_{j}=\\frac{1}{N}.\n$$", "answer": "$$\\boxed{\\frac{1}{N}}$$", "id": "1390757"}]}