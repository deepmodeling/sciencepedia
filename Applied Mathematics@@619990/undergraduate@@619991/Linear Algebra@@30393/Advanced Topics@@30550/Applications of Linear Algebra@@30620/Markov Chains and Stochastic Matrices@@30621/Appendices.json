{"hands_on_practices": [{"introduction": "The first step in wielding the power of Markov chains is translating a real-world process into a mathematical model. This exercise [@problem_id:1375578] challenges you to build a transition matrix from a description of user behavior on a social media platform. By calculating the two-step transition probabilities, you'll discover how the system evolves over time, revealing paths between states that may not be possible in a single step.", "problem": "A simplified model for user navigation on a new social media platform considers three possible states a user can be in during any given minute:\n1.  **State 1: Browsing Feed**\n2.  **State 2: Creating a Post**\n3.  **State 3: Private Messaging**\n\nThe transitions between these states follow a Markov chain model. The one-step transition probabilities for a one-minute interval are given as follows:\n\n*   A user who is **Browsing Feed** has a 0.7 probability of continuing to browse, a 0.2 probability of starting to create a post, and a 0.1 probability of switching to private messaging.\n*   A user who is **Creating a Post** has a 0.4 probability of continuing to create and a 0.6 probability of returning to browse the feed. It is impossible for them to switch directly to private messaging in one minute.\n*   A user who is in **Private Messaging** has a 0.5 probability of remaining in messaging and a 0.5 probability of returning to browse the feed. It is impossible for them to switch directly to creating a post in one minute.\n\nSuppose a user is currently in the **'Creating a Post'** state. What is the probability that this user will be in the **'Private Messaging'** state after exactly two minutes? Express your answer as a decimal.", "solution": "Let the states be indexed as 1 for Browsing Feed, 2 for Creating a Post, and 3 for Private Messaging. Following the convention of this article, the one-step transition matrix $P$ has entries $P_{ij}$ equal to the probability of moving from state $j$ to state $i$ in one minute. From the problem description, the matrix is:\n$$\nP=\\begin{pmatrix}\n0.7 & 0.6 & 0.5 \\\\\n0.2 & 0.4 & 0 \\\\\n0.1 & 0 & 0.5\n\\end{pmatrix}.\n$$\nWe are asked for the probability that, starting in state 2, the user is in state 3 after exactly two minutes. This is the $(3,2)$ entry of $P^{2}$:\n$$\n(P^{2})_{32}=\\sum_{k=1}^{3} P_{3k}P_{k2}=P_{31}P_{12}+P_{32}P_{22}+P_{33}P_{32}.\n$$\nSubstituting the values from matrix $P$:\n$$\n(P^{2})_{32}= (0.1)(0.6) + (0)(0.4) + (0.5)(0) = 0.06.\n$$\nEquivalently, the only possible two-step path from state 2 to state 3 is $2 \\to 1 \\to 3$, which occurs with probability $P_{12} \\times P_{31} = 0.6 \\times 0.1=0.06$.", "answer": "$$\\boxed{0.06}$$", "id": "1375578"}, {"introduction": "After modeling the immediate future, a natural question arises: what happens in the long run? Many Markov chains eventually settle into an equilibrium, known as a steady-state distribution. This practice [@problem_id:1375543] guides you through the process of finding this stable state by solving for the eigenvector associated with the eigenvalue $\\lambda=1$, a cornerstone of Markov chain analysis.", "problem": "A particle moves on the four vertices of a square, which are labeled $V_1, V_2, V_3, V_4$ in counter-clockwise order. At each discrete time step, the particle must move from its current vertex to one of its two adjacent vertices. The movement rule is biased: from any vertex, the probability of moving to the adjacent vertex in the counter-clockwise direction is twice the probability of moving to the adjacent vertex in the clockwise direction. A particle cannot remain at its current vertex in a given step. Determine the long-term, steady-state probability distribution for the particle's location. Express your answer as a row vector $[p_1, p_2, p_3, p_4]$, where $p_i$ is the probability of finding the particle at vertex $V_i$.", "solution": "Let the state of the system be the location of the particle. The state space is $S = \\{V_1, V_2, V_3, V_4\\}$. We are looking for the steady-state probability distribution, which we can represent as a vector $\\pi = [p_1, p_2, p_3, p_4]^T$, where $p_i$ is the long-term probability of finding the particle at vertex $V_i$. The sum of these probabilities must be 1, i.e., $p_1 + p_2 + p_3 + p_4 = 1$.\n\nFirst, we determine the transition probabilities. From any vertex, the particle can move to its counter-clockwise (ccw) neighbor or its clockwise (cw) neighbor. Let $p_{ccw}$ and $p_{cw}$ be the probabilities for these moves, respectively. The problem states that $p_{ccw} = 2 p_{cw}$. Since the particle must move to an adjacent vertex, the probabilities must sum to one: $p_{ccw} + p_{cw} = 1$.\nSubstituting the first relation into the second gives $2 p_{cw} + p_{cw} = 1$, which simplifies to $3 p_{cw} = 1$, so $p_{cw} = \\frac{1}{3}$. Consequently, $p_{ccw} = 2 \\times \\frac{1}{3} = \\frac{2}{3}$.\nThe probability of staying at the same vertex is 0.\n\nNext, we construct the transition matrix $P$. We will use the convention where the state vector is a column vector $\\mathbf{x}$, and its evolution is described by $\\mathbf{x}_{k+1} = P \\mathbf{x}_k$. In this convention, the entry $P_{ij}$ of the matrix is the probability of transitioning from state $j$ to state $i$. The columns of the matrix must sum to 1.\n\nLet's determine the columns of $P$:\n- Column 1 (from $V_1$): The particle can move to $V_2$ (ccw, prob $\\frac{2}{3}$) or $V_4$ (cw, prob $\\frac{1}{3}$). So, $P_{21} = \\frac{2}{3}$ and $P_{41} = \\frac{1}{3}$.\n- Column 2 (from $V_2$): The particle can move to $V_3$ (ccw, prob $\\frac{2}{3}$) or $V_1$ (cw, prob $\\frac{1}{3}$). So, $P_{32} = \\frac{2}{3}$ and $P_{12} = \\frac{1}{3}$.\n- Column 3 (from $V_3$): The particle can move to $V_4$ (ccw, prob $\\frac{2}{3}$) or $V_2$ (cw, prob $\\frac{1}{3}$). So, $P_{43} = \\frac{2}{3}$ and $P_{23} = \\frac{1}{3}$.\n- Column 4 (from $V_4$): The particle can move to $V_1$ (ccw, prob $\\frac{2}{3}$) or $V_3$ (cw, prob $\\frac{1}{3}$). So, $P_{14} = \\frac{2}{3}$ and $P_{34} = \\frac{1}{3}$.\n\nAll other entries are zero. The transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n0 & \\frac{1}{3} & 0 & \\frac{2}{3} \\\\\n\\frac{2}{3} & 0 & \\frac{1}{3} & 0 \\\\\n0 & \\frac{2}{3} & 0 & \\frac{1}{3} \\\\\n\\frac{1}{3} & 0 & \\frac{2}{3} & 0\n\\end{pmatrix}\n$$\nThe steady-state distribution vector $\\pi$ is the eigenvector of $P$ corresponding to the eigenvalue $\\lambda=1$. Thus, it must satisfy the equation $P\\pi = \\pi$, which can be rewritten as $(P-I)\\pi = \\mathbf{0}$, where $I$ is the identity matrix and $\\mathbf{0}$ is the zero vector.\n$$\n\\begin{pmatrix}\n-1 & \\frac{1}{3} & 0 & \\frac{2}{3} \\\\\n\\frac{2}{3} & -1 & \\frac{1}{3} & 0 \\\\\n0 & \\frac{2}{3} & -1 & \\frac{1}{3} \\\\\n\\frac{1}{3} & 0 & \\frac{2}{3} & -1\n\\end{pmatrix}\n\\begin{pmatrix} p_1 \\\\ p_2 \\\\ p_3 \\\\ p_4 \\end{pmatrix}\n=\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives us a system of linear equations:\n1. $-p_1 + \\frac{1}{3}p_2 + \\frac{2}{3}p_4 = 0 \\implies 3p_1 = p_2 + 2p_4$\n2. $\\frac{2}{3}p_1 - p_2 + \\frac{1}{3}p_3 = 0 \\implies 3p_2 = 2p_1 + p_3$\n3. $\\frac{2}{3}p_2 - p_3 + \\frac{1}{3}p_4 = 0 \\implies 3p_3 = 2p_2 + p_4$\n4. $\\frac{1}{3}p_1 + \\frac{2}{3}p_3 - p_4 = 0 \\implies 3p_4 = p_1 + 2p_3$\n\nLet's solve this system. From equation (2), $p_3 = 3p_2 - 2p_1$. Substitute this into equation (4):\n$3p_4 = p_1 + 2(3p_2 - 2p_1) = p_1 + 6p_2 - 4p_1 = 6p_2 - 3p_1$.\nSo, $p_4 = 2p_2 - p_1$.\n\nNow, substitute the expressions for $p_3$ and $p_4$ into equation (3):\n$3(3p_2 - 2p_1) = 2p_2 + (2p_2 - p_1)$\n$9p_2 - 6p_1 = 4p_2 - p_1$\n$5p_2 = 5p_1 \\implies p_1 = p_2$.\n\nNow that we know $p_1 = p_2$, we can find the other probabilities in terms of $p_1$:\n$p_4 = 2p_2 - p_1 = 2p_1 - p_1 = p_1$.\n$p_3 = 3p_2 - 2p_1 = 3p_1 - 2p_1 = p_1$.\nThis shows that all four probabilities are equal: $p_1 = p_2 = p_3 = p_4$.\n\nFinally, we use the normalization condition: $p_1 + p_2 + p_3 + p_4 = 1$.\nSubstituting our finding: $p_1 + p_1 + p_1 + p_1 = 1 \\implies 4p_1 = 1 \\implies p_1 = \\frac{1}{4}$.\nTherefore, the steady-state probability distribution is $p_1=p_2=p_3=p_4=\\frac{1}{4}$.\n\nThe steady-state distribution is uniform. This might seem counter-intuitive given the biased movement. However, we can observe that the transition matrix $P$ is doubly stochastic (both its columns and its rows sum to 1). For any finite, irreducible Markov chain, if the transition matrix is doubly stochastic, the unique stationary distribution is the uniform distribution. Our chain is finite and irreducible, so this theorem applies and confirms our result.\n\nThe final answer, expressed as a row vector, is $[\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}]$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\end{pmatrix}}$$", "id": "1375543"}, {"introduction": "Now, let's move from analyzing existing systems to designing new ones. This advanced exercise [@problem_id:1375555] tasks you with reverse-engineering a transition matrix to meet specific design criteria for user engagement. You will determine the matrix parameters that produce a desired long-term state distribution and a specific rate of convergence, directly linking the matrix's eigenvalues to the system's dynamic behavior.", "problem": "A software development team is analyzing user engagement for a new app feature. They model a user's behavior as a Markov chain with two states: State 1 (\"Active\") and State 2 (\"Inactive\"). The transition from one week to the next is described by a $2 \\times 2$ transition matrix $P$, where the entry $P_{ij}$ is the probability of a user transitioning from state $j$ to state $i$.\n\nThe matrix $P$ has the form:\n$$\nP = \\begin{pmatrix} 1-a & b \\\\ a & 1-b \\end{pmatrix}\n$$\nHere, $a$ is the probability that an Active user becomes Inactive, and $b$ is the probability that an Inactive user becomes Active. The model requires that these probabilities are strictly between 0 and 1 (i.e., $0 < a < 1$ and $0 < b < 1$).\n\nThe team has two design criteria. First, the feature should be tuned such that in the long run, the probability of a user being in the \"Active\" state stabilizes at exactly $1/3$. Second, the rate of convergence to this long-term distribution is related to the matrix's second eigenvalue; this eigenvalue (the one not equal to 1) is required to be $5/8$.\n\nDetermine the specific transition matrix $P$ that satisfies both of these conditions. The answer should be a $2 \\times 2$ matrix with exact fractional entries.", "solution": "We are given a two-state Markov chain with column-stochastic transition matrix\n$$\nP=\\begin{pmatrix}1-a & b \\\\ a & 1-b\\end{pmatrix},\n$$\nwhere $P_{ij}$ is the probability of transitioning from state $j$ to state $i$, so each column sums to $1$. Let the stationary distribution be $\\pi=\\begin{pmatrix}\\pi_{1} \\\\ \\pi_{2}\\end{pmatrix}$, where $\\pi_{1}$ is the long-run probability of being Active and $\\pi_{2}$ of being Inactive. The stationary condition is $P\\pi=\\pi$ together with $\\pi_{1}+\\pi_{2}=1$.\n\nExpanding $P\\pi=\\pi$ gives\n$$\n\\begin{cases}\n(1-a)\\pi_{1}+b\\pi_{2}=\\pi_{1},\\\\\na\\pi_{1}+(1-b)\\pi_{2}=\\pi_{2}.\n\\end{cases}\n$$\nThe first equation simplifies to\n$$\n-a\\pi_{1}+b\\pi_{2}=0 \\quad\\Longrightarrow\\quad b\\pi_{2}=a\\pi_{1}\\quad\\Longrightarrow\\quad \\frac{\\pi_{1}}{\\pi_{2}}=\\frac{b}{a}.\n$$\nUsing $\\pi_{1}+\\pi_{2}=1$, we obtain\n$$\n\\pi_{1}=\\frac{b}{a+b},\\qquad \\pi_{2}=\\frac{a}{a+b}.\n$$\nThe design requirement that the long-run Active probability equals $\\frac{1}{3}$ imposes\n$$\n\\pi_{1}=\\frac{b}{a+b}=\\frac{1}{3}\\quad\\Longrightarrow\\quad 3b=a+b\\quad\\Longrightarrow\\quad a=2b.\n$$\n\nNext, we impose the eigenvalue condition. The eigenvalues of $P$ are roots of the characteristic polynomial\n$$\n\\det(P-\\lambda I)=\\det\\begin{pmatrix}1-a-\\lambda & b \\\\ a & 1-b-\\lambda\\end{pmatrix}\n=(1-a-\\lambda)(1-b-\\lambda)-ab.\n$$\nExpanding and simplifying,\n$$\n\\det(P-\\lambda I)=\\lambda^{2}-\\lambda\\big(2-(a+b)\\big)+(1-a-b).\n$$\nSince $P$ is stochastic, $\\lambda=1$ is an eigenvalue, and the other eigenvalue is\n$$\n\\lambda_{2}=1-(a+b).\n$$\nThe requirement that the second eigenvalue equals $\\frac{5}{8}$ gives\n$$\n1-(a+b)=\\frac{5}{8}\\quad\\Longrightarrow\\quad a+b=\\frac{3}{8}.\n$$\nCombining with $a=2b$, we solve\n$$\n2b+b=\\frac{3}{8}\\quad\\Longrightarrow\\quad b=\\frac{1}{8},\\qquad a=2b=\\frac{1}{4}.\n$$\n\nTherefore, the transition matrix is\n$$\nP=\\begin{pmatrix}1-a & b \\\\ a & 1-b\\end{pmatrix}\n=\\begin{pmatrix}\\frac{3}{4} & \\frac{1}{8} \\\\ \\frac{1}{4} & \\frac{7}{8}\\end{pmatrix},\n$$\nwhich satisfies $\\pi_{1}=\\frac{1}{3}$ and has second eigenvalue $1-a-b=\\frac{5}{8}$, with $0<a<1$ and $0<b<1$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3}{4} & \\frac{1}{8} \\\\ \\frac{1}{4} & \\frac{7}{8}\\end{pmatrix}}$$", "id": "1375555"}]}