{"hands_on_practices": [{"introduction": "The polar decomposition provides the powerful insight that any linear transformation can be viewed as a combination of a stretch and a rotation. To build a solid understanding of this concept, we will work through a series of hands-on examples, starting with the most intuitive case: a pure rotation, which involves no stretching at all. This first exercise [@problem_id:1383651] asks you to confirm that for a given rotation matrix, its 'stretch' component $P$ is simply the identity matrix $I$, and its 'rotation' component $U$ is the original matrix itself.", "problem": "A linear transformation in a two-dimensional real vector space, $\\mathbb{R}^2$, is given by a counter-clockwise rotation about the origin by an angle $\\theta$, where $0 < \\theta < \\pi$. This transformation is represented by the matrix:\n$$A = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$$\nAny invertible real matrix $A$ has a unique polar decomposition of the form $A = UP$, where $U$ is an orthogonal matrix (satisfying $U^T U = I$, where $I$ is the identity matrix) and $P$ is a symmetric positive-definite matrix (a symmetric matrix with all positive eigenvalues). The matrix $U$ represents a pure rotation or reflection, while $P$ represents a pure scaling (stretching/compression) along orthogonal axes.\n\nFor the given rotation matrix $A$, which of the following options correctly identifies the matrices $U$ and $P$ in its polar decomposition? Let $I$ be the $2 \\times 2$ identity matrix.\n\nA) $U=A$ and $P=I$.\n\nB) $U=I$ and $P=A$.\n\nC) $U=A^T$ and $P=I$.\n\nD) $U=\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$ and $P=\\begin{pmatrix} \\cos\\theta & \\sin\\theta \\\\ \\sin\\theta & -\\cos\\theta \\end{pmatrix}$.\n\nE) Such a decomposition does not exist for the matrix $A$.", "solution": "We use the polar decomposition theorem: for any invertible real matrix $A$, there is a unique factorization $A=UP$ with $U$ orthogonal and $P$ symmetric positive-definite, given explicitly by\n$$\nP=(A^{T}A)^{1/2}, \\qquad U=A\\, (A^{T}A)^{-1/2}.\n$$\nFor the given $2\\times 2$ rotation matrix\n$$\nA=\\begin{pmatrix}\n\\cos\\theta & -\\sin\\theta\\\\\n\\sin\\theta & \\cos\\theta\n\\end{pmatrix},\n$$\nwe first compute its transpose:\n$$\nA^{T}=\\begin{pmatrix}\n\\cos\\theta & \\sin\\theta\\\\\n-\\sin\\theta & \\cos\\theta\n\\end{pmatrix}.\n$$\nThen\n$$\nA^{T}A=\n\\begin{pmatrix}\n\\cos\\theta & \\sin\\theta\\\\\n-\\sin\\theta & \\cos\\theta\n\\end{pmatrix}\n\\begin{pmatrix}\n\\cos\\theta & -\\sin\\theta\\\\\n\\sin\\theta & \\cos\\theta\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\cos^{2}\\theta+\\sin^{2}\\theta & -\\cos\\theta\\sin\\theta+\\sin\\theta\\cos\\theta\\\\\n-\\sin\\theta\\cos\\theta+\\cos\\theta\\sin\\theta & \\sin^{2}\\theta+\\cos^{2}\\theta\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 0\\\\\n0 & 1\n\\end{pmatrix}\n=I.\n$$\nTherefore,\n$$\nP=(A^{T}A)^{1/2}=I^{1/2}=I, \\qquad U=A\\,(A^{T}A)^{-1/2}=A\\,I=A.\n$$\nThe matrix $I$ is symmetric positive-definite, and $A$ is orthogonal since $A^{T}A=I$; thus $A=UP$ with $U=A$ and $P=I$ is indeed the polar decomposition. By uniqueness of the polar decomposition, this is the only valid choice.\n\nTo confirm the exclusivity among the options: option B would set $P=A$, which is not symmetric for $0<\\theta<\\pi$ (since $A=A^{T}$ only if $\\sin\\theta=0$, excluded by the given range). Option C would imply $A=A^{T}$, again false in the given range. Option D produces a matrix $P$ with determinant $-1$, hence not positive-definite. Option E is false because the decomposition exists for all invertible matrices, including rotations.\n\nThus the correct identification is $U=A$ and $P=I$.", "answer": "$$\\boxed{A}$$", "id": "1383651"}, {"introduction": "Next, we examine a transformation that consists only of scaling along the coordinate axes. The matrix in this hypothetical scenario is diagonal, but a negative entry introduces a reflection across an axis. This practice [@problem_id:1383655] beautifully demonstrates how the polar decomposition cleanly separates the pure scaling magnitudes into the positive semi-definite matrix $P$, while concentrating the reflection (a type of rotation) into the orthogonal matrix $U$.", "problem": "A linear transformation in a 3-dimensional real vector space is represented by the matrix $A$ with respect to the standard basis, where:\n$$\nA = \\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & -7 & 0 \\\\ 0 & 0 & 2 \\end{pmatrix}\n$$\nAny square matrix $A$ can be expressed via a right polar decomposition as $A = UP$, where $U$ is an orthogonal matrix (unitary in the complex case) and $P$ is a positive semi-definite matrix. For the given matrix $A$, determine the trace of the matrix $P$.", "solution": "The right polar decomposition of a real square matrix $A$ is $A = UP$, where $U$ is orthogonal (unitary in the complex case) and $P$ is the unique symmetric positive semi-definite factor given by the positive square root of $A^{T}A$. The defining relation is:\n$$\nP = \\left(A^{T}A\\right)^{1/2}.\n$$\nFor the given matrix\n$$\nA = \\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & -7 & 0 \\\\ 0 & 0 & 2 \\end{pmatrix},\n$$\ncompute $A^{T}A$. Since $A$ is diagonal, $A^{T} = A$, and\n$$\nA^{T}A = A^{2} = \\begin{pmatrix} 4^{2} & 0 & 0 \\\\ 0 & (-7)^{2} & 0 \\\\ 0 & 0 & 2^{2} \\end{pmatrix} = \\begin{pmatrix} 16 & 0 & 0 \\\\ 0 & 49 & 0 \\\\ 0 & 0 & 4 \\end{pmatrix}.\n$$\nThe positive semi-definite square root of a diagonal matrix is obtained by taking the positive square roots of the diagonal entries. Therefore,\n$$\nP = \\left(A^{T}A\\right)^{1/2} = \\begin{pmatrix} \\sqrt{16} & 0 & 0 \\\\ 0 & \\sqrt{49} & 0 \\\\ 0 & 0 & \\sqrt{4} \\end{pmatrix} = \\begin{pmatrix} 4 & 0 & 0 \\\\ 0 & 7 & 0 \\\\ 0 & 0 & 2 \\end{pmatrix}.\n$$\nThe trace of $P$ is the sum of its diagonal entries:\n$$\n\\operatorname{tr}(P) = 4 + 7 + 2 = 13.\n$$", "answer": "$$\\boxed{13}$$", "id": "1383655"}, {"introduction": "In practice, most linear transformations are not simple rotations or axis-aligned scalings but rather a mixture of both. This final exercise [@problem_id:1383671] presents a transformation that both swaps and scales the axes, offering a perfect opportunity to apply the general computational method for finding the polar decomposition. By working through the calculation of the stretch matrix $P$ from the product $A^T A$, you will solidify the core technique and gain a deeper appreciation for how the fundamental scaling factors are extracted from any transformation.", "problem": "A linear transformation on the Euclidean plane $\\mathbb{R}^2$ is represented by the matrix $A = \\begin{pmatrix} 0 & 2 \\\\ 3 & 0 \\end{pmatrix}$. This transformation can be uniquely factored into a scaling operation followed by a rigid motion (a rotation or reflection). This factorization is known as the polar decomposition, written as $A = UP$, where $P$ is a positive semi-definite symmetric matrix representing the scaling, and $U$ is an orthogonal matrix representing the rigid motion. The eigenvalues of the scaling matrix $P$ represent the factors by which the space is stretched along a set of orthogonal principal axes.\n\nCalculate the sum of these scaling factors.", "solution": "We seek the polar decomposition $A = UP$ with $U$ orthogonal and $P$ symmetric positive semidefinite. The scaling matrix is $P = \\sqrt{A^{T}A}$, and its eigenvalues (the singular values of $A$) are the scaling factors. Their sum equals the trace of $P$.\n\nCompute $A^{T}A$:\n$$\nA^{T} = \\begin{pmatrix} 0 & 3 \\\\ 2 & 0 \\end{pmatrix}, \\quad\nA^{T}A = \\begin{pmatrix} 0 & 3 \\\\ 2 & 0 \\end{pmatrix}\\begin{pmatrix} 0 & 2 \\\\ 3 & 0 \\end{pmatrix}\n= \\begin{pmatrix} 9 & 0 \\\\ 0 & 4 \\end{pmatrix}.\n$$\nSince $A^{T}A$ is diagonal with positive entries, its unique positive semidefinite square root is\n$$\nP = \\sqrt{A^{T}A} = \\begin{pmatrix} 3 & 0 \\\\ 0 & 2 \\end{pmatrix}.\n$$\nThus the scaling factors (eigenvalues of $P$) are $3$ and $2$, and their sum is\n$$\n3 + 2 = 5.\n$$", "answer": "$$\\boxed{5}$$", "id": "1383671"}]}