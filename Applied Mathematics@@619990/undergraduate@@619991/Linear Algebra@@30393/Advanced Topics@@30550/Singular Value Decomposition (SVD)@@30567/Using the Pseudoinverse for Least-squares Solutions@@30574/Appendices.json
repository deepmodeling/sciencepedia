{"hands_on_practices": [{"introduction": "This practice grounds the abstract concept of the pseudoinverse in a real-world data fitting scenario. You will learn to translate a physical model and experimental data into a matrix equation, $A\\mathbf{x} = \\mathbf{b}$. The core task is to compute the Moore-Penrose pseudoinverse $A^{+}$ for the matrix $A$, which is the essential tool needed to solve the resulting overdetermined system. [@problem_id:1400691]", "problem": "An experimental physicist is studying a newly discovered electronic component. They hypothesize that the relationship between the applied voltage $V$ and the resulting current $I$ follows a model of the form $V = c_1 + c_2 I^2$, where $c_1$ and $c_2$ are unknown device-specific parameters. To determine these parameters, the physicist takes three measurements of voltage for three different currents. The measured currents are $I_1=1$, $I_2=2$, and $I_3=3$ (in some consistent units).\n\nThis set of measurements leads to an overdetermined linear system of equations of the form $A\\mathbf{x} = \\mathbf{b}$, where $\\mathbf{x} = \\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix}$ contains the unknown parameters and $A$ is the design matrix derived from the current values. The least-squares solution for the parameters can be found using the Moore-Penrose pseudoinverse $A^+$ of the matrix $A$.\n\nGiven the model and the current values used, determine the Moore-Penrose pseudoinverse $A^+$ of the design matrix $A$.", "solution": "The problem asks for the Moore-Penrose pseudoinverse of the design matrix $A$ associated with the model $V = c_1 + c_2 I^2$ and the measurements taken at currents $I=1, 2, 3$.\n\nFirst, we construct the system of linear equations. Each measurement $(I_i, V_i)$ gives one equation:\nFor $I_1=1$: $c_1 \\cdot 1 + c_2 \\cdot 1^2 = V_1 \\implies c_1 + c_2 = V_1$\nFor $I_2=2$: $c_1 \\cdot 1 + c_2 \\cdot 2^2 = V_2 \\implies c_1 + 4c_2 = V_2$\nFor $I_3=3$: $c_1 \\cdot 1 + c_2 \\cdot 3^2 = V_3 \\implies c_1 + 9c_2 = V_3$\n\nThis system can be written in matrix form $A\\mathbf{x} = \\mathbf{b}$ as:\n$$\n\\begin{pmatrix} 1 & 1 \\\\ 1 & 4 \\\\ 1 & 9 \\end{pmatrix}\n\\begin{pmatrix} c_1 \\\\ c_2 \\end{pmatrix}\n=\n\\begin{pmatrix} V_1 \\\\ V_2 \\\\ V_3 \\end{pmatrix}\n$$\nThe design matrix $A$ is therefore:\n$$\nA = \\begin{pmatrix} 1 & 1 \\\\ 1 & 4 \\\\ 1 & 9 \\end{pmatrix}\n$$\nThe matrix $A$ is a $3 \\times 2$ matrix. Its columns are linearly independent, so it has full column rank. For a matrix $A$ with full column rank, its Moore-Penrose pseudoinverse $A^+$ is given by the formula:\n$$\nA^+ = (A^T A)^{-1} A^T\n$$\nWe will compute this in steps.\n\nStep 1: Compute the transpose of $A$, which is $A^T$.\n$$\nA^T = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 4 & 9 \\end{pmatrix}\n$$\n\nStep 2: Compute the product $A^T A$.\n$$\nA^T A = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 4 & 9 \\end{pmatrix} \\begin{pmatrix} 1 & 1 \\\\ 1 & 4 \\\\ 1 & 9 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(1)(1)+(1)(1) & (1)(1)+(1)(4)+(1)(9) \\\\ (1)(1)+(4)(1)+(9)(1) & (1)(1)+(4)(4)+(9)(9) \\end{pmatrix}\n$$\n$$\nA^T A = \\begin{pmatrix} 1+1+1 & 1+4+9 \\\\ 1+4+9 & 1+16+81 \\end{pmatrix} = \\begin{pmatrix} 3 & 14 \\\\ 14 & 98 \\end{pmatrix}\n$$\n\nStep 3: Compute the inverse of $A^T A$. For a $2 \\times 2$ matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, the inverse is $\\frac{1}{ad-bc} \\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$.\nThe determinant of $A^T A$ is:\n$$\n\\det(A^T A) = (3)(98) - (14)(14) = 294 - 196 = 98\n$$\nThe inverse is:\n$$\n(A^T A)^{-1} = \\frac{1}{98} \\begin{pmatrix} 98 & -14 \\\\ -14 & 3 \\end{pmatrix} = \\begin{pmatrix} \\frac{98}{98} & -\\frac{14}{98} \\\\ -\\frac{14}{98} & \\frac{3}{98} \\end{pmatrix} = \\begin{pmatrix} 1 & -\\frac{1}{7} \\\\ -\\frac{1}{7} & \\frac{3}{98} \\end{pmatrix}\n$$\n\nStep 4: Compute the final product $A^+ = (A^T A)^{-1} A^T$.\n$$\nA^+ = \\begin{pmatrix} 1 & -\\frac{1}{7} \\\\ -\\frac{1}{7} & \\frac{3}{98} \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 4 & 9 \\end{pmatrix}\n$$\nWe perform the matrix multiplication entry by entry:\nEntry (1,1): $(1)(1) + (-\\frac{1}{7})(1) = 1 - \\frac{1}{7} = \\frac{6}{7}$\nEntry (1,2): $(1)(1) + (-\\frac{1}{7})(4) = 1 - \\frac{4}{7} = \\frac{3}{7}$\nEntry (1,3): $(1)(1) + (-\\frac{1}{7})(9) = 1 - \\frac{9}{7} = -\\frac{2}{7}$\n\nEntry (2,1): $(-\\frac{1}{7})(1) + (\\frac{3}{98})(1) = -\\frac{14}{98} + \\frac{3}{98} = -\\frac{11}{98}$\nEntry (2,2): $(-\\frac{1}{7})(1) + (\\frac{3}{98})(4) = -\\frac{14}{98} + \\frac{12}{98} = -\\frac{2}{98} = -\\frac{1}{49}$\nEntry (2,3): $(-\\frac{1}{7})(1) + (\\frac{3}{98})(9) = -\\frac{14}{98} + \\frac{27}{98} = \\frac{13}{98}$\n\nAssembling these entries into the matrix $A^+$ gives the final result.\n$$\nA^+ = \\begin{pmatrix} \\frac{6}{7} & \\frac{3}{7} & -\\frac{2}{7} \\\\ -\\frac{11}{98} & -\\frac{1}{49} & \\frac{13}{98} \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\frac{6}{7} & \\frac{3}{7} & -\\frac{2}{7} \\\\ -\\frac{11}{98} & -\\frac{1}{49} & \\frac{13}{98} \\end{pmatrix}\n}\n$$", "id": "1400691"}, {"introduction": "Building upon the previous exercise, we now focus on the ultimate goal: finding the best-fit parameters for our model. This problem demonstrates how to use the pseudoinverse to calculate the least-squares solution vector that minimizes the error $\\lVert A\\mathbf{x} - \\mathbf{b} \\rVert_2^2$. This is where the power of the pseudoinverse becomes apparent, providing a direct method to find the optimal solution to an inconsistent system. [@problem_id:1400693]", "problem": "An engineer is calibrating a novel sensor whose output, $S$, is modeled as a linear function of two adjustable input parameters, $p_1$ and $p_2$. The theoretical model is given by the equation $S = x_1 p_1 + x_2 p_2$, where $x_1$ and $x_2$ are the unknown calibration constants that need to be determined. To find these constants, a series of three experiments are conducted, yielding the following measurements:\n\n1.  With $(p_1, p_2) = (1, 0)$, the sensor output was $S=1$.\n2.  With $(p_1, p_2) = (0, 1)$, the sensor output was $S=2$.\n3.  With $(p_1, p_2) = (1, 1)$, the sensor output was $S=2$.\n\nDue to measurement noise, this set of observations forms an overdetermined and inconsistent system of linear equations for the constants $x_1$ and $x_2$. Determine the values of $x_1$ and $x_2$ that constitute the least-squares solution to this system.\n\nExpress your answer as a column vector $\\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$. The entries in your vector must be given as exact fractions.", "solution": "The model is $S = x_{1} p_{1} + x_{2} p_{2}$. Collecting the three experiments into matrix form yields\n$$\nA = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{pmatrix},\\quad\n\\mathbf{x} = \\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix},\\quad\n\\mathbf{b} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix},\n$$\nso the system is $A \\mathbf{x} = \\mathbf{b}$, which is overdetermined. The least-squares solution minimizes $\\lVert A \\mathbf{x} - \\mathbf{b} \\rVert_2^2$ and satisfies the normal equations\n$$\nA^{\\top} A \\mathbf{x} = A^{\\top} \\mathbf{b}.\n$$\nCompute\n$$\nA^{\\top} A = \\begin{pmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix},\n\\quad\nA^{\\top} \\mathbf{b} = \\begin{pmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}.\n$$\nThus, the normal equations are\n$$\n\\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} \\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix},\n$$\ni.e.,\n$$\n\\begin{cases}\n2 x_{1} + x_{2} = 3, \\\\\nx_{1} + 2 x_{2} = 4.\n\\end{cases}\n$$\nFrom the first equation, $x_{2} = 3 - 2 x_{1}$. Substitute into the second:\n$$\nx_{1} + 2(3 - 2 x_{1}) = 4 \\;\\Rightarrow\\; x_{1} + 6 - 4 x_{1} = 4 \\;\\Rightarrow\\; -3 x_{1} = -2 \\;\\Rightarrow\\; x_{1} = \\frac{2}{3}.\n$$\nThen\n$$\nx_{2} = 3 - 2 \\cdot \\frac{2}{3} = 3 - \\frac{4}{3} = \\frac{5}{3}.\n$$\nTherefore, the least-squares solution is\n$$\n\\begin{pmatrix} x_{1} \\\\ x_{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3} \\\\ \\frac{5}{3} \\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{2}{3} \\\\ \\frac{5}{3} \\end{pmatrix}}$$", "id": "1400693"}, {"introduction": "After learning how to apply the pseudoinverse, it's crucial to understand its specific algebraic properties, which can differ from those of a standard matrix inverse. This exercise challenges the assumption that the reverse-order law, $(AB)^{-1} = B^{-1}A^{-1}$, extends to pseudoinverses. By working through a concrete counterexample, you will develop a more nuanced understanding of this powerful tool and avoid common pitfalls in its application. [@problem_id:1400678]", "problem": "In linear algebra, for any pair of invertible square matrices $X$ and $Y$ of the same size, the inverse of their product follows the reverse-order law: $(XY)^{-1} = Y^{-1}X^{-1}$. A generalization of the matrix inverse for any matrix (not necessarily square or invertible) is the Moore-Penrose pseudoinverse, denoted by a superscript '+'. A natural question arises: does the reverse-order law hold for the pseudoinverse? That is, is the identity $(AB)^+ = B^+A^+$ true for any pair of matrices $A$ and $B$ for which the product $AB$ is defined?\n\nThis problem asks you to investigate this question with a specific pair of singular matrices. Consider the real $2 \\times 2$ matrices given by:\n$$A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 0 \\end{pmatrix} \\quad \\text{and} \\quad B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$$\n\nTo carry out your calculations, you may use the following properties of the Moore-Penrose pseudoinverse without proof:\n1. For a rank-1 matrix $M$ that can be written as an outer product of two non-zero column vectors $\\mathbf{u}$ and $\\mathbf{v}$ (i.e., $M=\\mathbf{u}\\mathbf{v}^T$), its pseudoinverse is given by $M^+ = \\frac{1}{\\lVert\\mathbf{u}\\rVert_2^2 \\lVert\\mathbf{v}\\rVert_2^2} \\mathbf{v} \\mathbf{u}^T$, where $\\lVert \\cdot \\rVert_2$ denotes the standard Euclidean norm.\n2. For a real matrix $M$ that is symmetric ($M^T = M$) and idempotent ($M^2 = M$), its pseudoinverse is the matrix itself, i.e., $M^+ = M$.\n\nCalculate the difference matrix $D = (AB)^+ - B^+A^+$. What is the sum of all the entries of $D$?", "solution": "The problem asks for the sum of the entries of the difference matrix $D = (AB)^+ - B^+A^+$. We need to compute the terms $(AB)^+$ and $B^+A^+$ separately. This involves finding the pseudoinverses of $A$ and $B$, and the product $AB$.\n\nFirst, let's find the pseudoinverse of matrix $A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 0 \\end{pmatrix}$.\nMatrix $A$ is a rank-1 matrix. We can express it as an outer product $\\mathbf{u}\\mathbf{v}^T$. We can see that the first row is $\\begin{pmatrix} 1 & 1 \\end{pmatrix}$ and the second row is all zeros. The columns are both multiples of $\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. Let's choose $\\mathbf{u} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$. Then we need a vector $\\mathbf{v}$ such that $\\mathbf{u}\\mathbf{v}^T = A$.\nLet $\\mathbf{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix}$. Then $\\mathbf{u}\\mathbf{v}^T = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} v_1 & v_2 \\end{pmatrix} = \\begin{pmatrix} v_1 & v_2 \\\\ 0 & 0 \\end{pmatrix}$.\nComparing this with $A$, we see that we must have $v_1=1$ and $v_2=1$. So, we can write $A = \\mathbf{u}\\mathbf{v}^T$ with $\\mathbf{u} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{v} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\nNow we use the given formula for the pseudoinverse of a rank-1 matrix: $A^+ = \\frac{1}{\\lVert\\mathbf{u}\\rVert_2^2 \\lVert\\mathbf{v}\\rVert_2^2} \\mathbf{v} \\mathbf{u}^T$.\nFirst, we compute the squared norms:\n$\\lVert\\mathbf{u}\\rVert_2^2 = 1^2 + 0^2 = 1$.\n$\\lVert\\mathbf{v}\\rVert_2^2 = 1^2 + 1^2 = 2$.\nNow, we can compute $A^+$:\n$$A^+ = \\frac{1}{1 \\cdot 2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1 \\cdot 1 & 1 \\cdot 0 \\\\ 1 \\cdot 1 & 1 \\cdot 0 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1/2 & 0 \\\\ 1/2 & 0 \\end{pmatrix}$$\n\nNext, let's find the pseudoinverse of matrix $B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$.\nWe can use the second property provided. Let's check if $B$ is symmetric and idempotent.\nSymmetry: $B^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} = B$. So, $B$ is symmetric.\nIdempotency: $B^2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 + 0 \\cdot 0 & 1 \\cdot 0 + 0 \\cdot 0 \\\\ 0 \\cdot 1 + 0 \\cdot 0 & 0 \\cdot 0 + 0 \\cdot 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} = B$. So, $B$ is idempotent.\nSince $B$ is both symmetric and idempotent, its pseudoinverse is itself:\n$$B^+ = B = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$$\n\nNow we can compute the product $B^+A^+$:\n$$B^+A^+ = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1/2 & 0 \\\\ 1/2 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot (1/2) + 0 \\cdot (1/2) & 1 \\cdot 0 + 0 \\cdot 0 \\\\ 0 \\cdot (1/2) + 0 \\cdot (1/2) & 0 \\cdot 0 + 0 \\cdot 0 \\end{pmatrix} = \\begin{pmatrix} 1/2 & 0 \\\\ 0 & 0 \\end{pmatrix}$$\n\nThe next step is to compute $(AB)^+$. First, we must find the product $AB$:\n$$AB = \\begin{pmatrix} 1 & 1 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 + 1 \\cdot 0 & 1 \\cdot 0 + 1 \\cdot 0 \\\\ 0 \\cdot 1 + 0 \\cdot 0 & 0 \\cdot 0 + 0 \\cdot 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$$\nWe see that the product $AB$ is equal to the matrix $B$. Therefore, the pseudoinverse of the product is the pseudoinverse of $B$:\n$$(AB)^+ = B^+ = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$$\n\nFinally, we compute the difference matrix $D = (AB)^+ - B^+A^+$:\n$$D = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} 1/2 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 - 1/2 & 0 - 0 \\\\ 0 - 0 & 0 - 0 \\end{pmatrix} = \\begin{pmatrix} 1/2 & 0 \\\\ 0 & 0 \\end{pmatrix}$$\nAs a side note, since $D$ is not the zero matrix, we have demonstrated that $(AB)^+ \\ne B^+A^+$ for this choice of $A$ and $B$.\n\nThe problem asks for the sum of all the entries of $D$.\nSum of entries = $\\frac{1}{2} + 0 + 0 + 0 = \\frac{1}{2}$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1400678"}]}