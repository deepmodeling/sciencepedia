{"hands_on_practices": [{"introduction": "The journey to orthogonal diagonalization begins with mastering its core component: finding eigenvectors. Given an eigenvalue, the corresponding eigenvectors form a subspace of vectors that are simply scaled by the matrix transformation. This exercise hones the essential skill of solving the system of linear equations $(A - \\lambda I)\\mathbf{v} = \\mathbf{0}$ to find an eigenvector and normalizing it to unit length. [@problem_id:1380436]", "problem": "Consider the 2x2 symmetric matrix $A$ given by\n$$ A = \\begin{pmatrix} 2 & 2\\sqrt{2} \\\\ 2\\sqrt{2} & 9 \\end{pmatrix} $$\nOne of the eigenvalues of this matrix is $\\lambda = 1$. Your task is to find a unit eigenvector $\\mathbf{v}$ corresponding to this eigenvalue. The eigenvector must be represented as a column vector, and its first component must be positive.", "solution": "Let $\\lambda=1$ and let $\\mathbf{v}=\\begin{pmatrix}x \\\\ y\\end{pmatrix}$ be an eigenvector. The eigenvalue equation is $(A-\\lambda I)\\mathbf{v}=\\mathbf{0}$. Compute\n$$\nA-I=\\begin{pmatrix}2-1 & 2\\sqrt{2} \\\\ 2\\sqrt{2} & 9-1\\end{pmatrix}=\\begin{pmatrix}1 & 2\\sqrt{2} \\\\ 2\\sqrt{2} & 8\\end{pmatrix}.\n$$\nThus we solve\n$$\n\\begin{pmatrix}1 & 2\\sqrt{2} \\\\ 2\\sqrt{2} & 8\\end{pmatrix}\\begin{pmatrix}x \\\\ y\\end{pmatrix}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix},\n$$\nwhich gives the equations\n$$\nx+2\\sqrt{2}\\,y=0,\\qquad 2\\sqrt{2}\\,x+8y=0.\n$$\nFrom the first equation, $x=-2\\sqrt{2}\\,y$. Substituting into the second yields $2\\sqrt{2}(-2\\sqrt{2}\\,y)+8y=-8y+8y=0$, confirming consistency. Therefore an eigenvector is proportional to $\\begin{pmatrix}-2\\sqrt{2} \\\\ 1\\end{pmatrix}$. To make the first component positive, take $\\begin{pmatrix}2\\sqrt{2} \\\\ -1\\end{pmatrix}$. Its norm is\n$$\n\\|\\begin{pmatrix}2\\sqrt{2} \\\\ -1\\end{pmatrix}\\|=\\sqrt{(2\\sqrt{2})^{2}+(-1)^{2}}=\\sqrt{8+1}=3.\n$$\nHence a unit eigenvector with positive first component is\n$$\n\\frac{1}{3}\\begin{pmatrix}2\\sqrt{2} \\\\ -1\\end{pmatrix}=\\begin{pmatrix}\\frac{2\\sqrt{2}}{3} \\\\ -\\frac{1}{3}\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{2\\sqrt{2}}{3} \\\\ -\\frac{1}{3}\\end{pmatrix}}$$", "id": "1380436"}, {"introduction": "Not all matrices require the full computational process to be diagonalized; some reveal their eigensystem through their structure. This problem explores the special case of a rank-one matrix $A = \\mathbf{v}\\mathbf{v}^T$, which appears frequently in data analysis and physics. By understanding its construction, you can determine its eigenvalues and eigenvectors conceptually, providing a deeper intuition for the diagonalization process. [@problem_id:1380451]", "problem": "In many signal processing and machine learning applications, one encounters matrices constructed from a single vector. These rank-one matrices have special properties that simplify their analysis.\n\nLet $\\mathbf{v}$ be a non-zero vector in $\\mathbb{R}^3$ given by $\\mathbf{v} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$. Consider the $3 \\times 3$ matrix $A$ defined as the outer product $A = \\mathbf{v}\\mathbf{v}^T$.\n\nAn orthogonal diagonalization of $A$ is an expression of the form $A = PDP^T$, where $P$ is an orthogonal matrix and $D$ is a diagonal matrix. The columns of $P$ are the orthonormal eigenvectors of $A$, and the diagonal entries of $D$ are the corresponding eigenvalues.\n\nWhich of the following pairs of matrices $(D, P)$ represents a valid orthogonal diagonalization of the matrix $A$?\n\nA. $D = \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$, $P = \\begin{pmatrix} \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{3}} & -\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{3}} & 0 & -\\frac{2}{\\sqrt{6}} \\end{pmatrix}$\n\nB. $D = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$, $P = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$\n\nC. $D = \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$, $P = \\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & -1 & 1 \\\\ 1 & 0 & -2 \\end{pmatrix}$\n\nD. $D = \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$, $P = \\begin{pmatrix} \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{3}} & -\\frac{1}{\\sqrt{2}} & 0 \\\\ \\frac{1}{\\sqrt{3}} & 0 & -\\frac{1}{\\sqrt{2}} \\end{pmatrix}$\n\nE. $D = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 3 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$, $P = \\begin{pmatrix} \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{3}} & -\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{3}} & 0 & -\\frac{2}{\\sqrt{6}} \\end{pmatrix}$", "solution": "Compute $A$ from $v$ by the outer product:\n$$\nA=\\mathbf{v}\\mathbf{v}^{T}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}\\begin{pmatrix}1&1&1\\end{pmatrix}=\\begin{pmatrix}1&1&1\\\\1&1&1\\\\1&1&1\\end{pmatrix}.\n$$\nFor any nonzero $\\mathbf{v}$, the rank-one matrix $A=\\mathbf{v}\\mathbf{v}^{T}$ satisfies\n$$\nA\\mathbf{v}=\\mathbf{v}(\\mathbf{v}^{T}\\mathbf{v})=(\\mathbf{v}^{T}\\mathbf{v})\\mathbf{v},\n$$\nso $\\mathbf{v}$ is an eigenvector with eigenvalue $\\mathbf{v}^{T}\\mathbf{v}$. Also, if $\\mathbf{w}$ satisfies $\\mathbf{v}^{T}\\mathbf{w}=0$, then\n$$\nA\\mathbf{w}=\\mathbf{v}(\\mathbf{v}^{T}\\mathbf{w})=\\mathbf{v}\\cdot 0=\\mathbf{0},\n$$\nso any vector orthogonal to $\\mathbf{v}$ is an eigenvector with eigenvalue $0$. Therefore, the spectrum is $\\{3,0,0\\}$ because $\\mathbf{v}^{T}\\mathbf{v}=1+1+1=3$, with a one-dimensional eigenspace spanned by $\\mathbf{v}$ and a two-dimensional eigenspace given by $\\mathbf{v}^{\\perp}$.\n\nAn orthogonal diagonalization $A=PDP^{T}$ requires:\n- $D$ to have the eigenvalues on the diagonal in some order, here a permutation of $(3,0,0)$.\n- $P$ to be orthogonal, with columns forming an orthonormal eigenbasis, i.e., one column equal to $\\mathbf{v}/\\|\\mathbf{v}\\|=(1,1,1)/\\sqrt{3}$, and the other two columns an orthonormal basis of $\\mathbf{v}^{\\perp}$.\n\nCheck each option:\n\nA. $D=\\operatorname{diag}(3,0,0)$ and $P$ has columns\n$$\n\\mathbf{c}_{1}=\\frac{1}{\\sqrt{3}}\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix},\\quad\n\\mathbf{c}_{2}=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1\\\\-1\\\\0\\end{pmatrix},\\quad\n\\mathbf{c}_{3}=\\frac{1}{\\sqrt{6}}\\begin{pmatrix}1\\\\1\\\\-2\\end{pmatrix}.\n$$\nThese are orthonormal, with $\\mathbf{c}_{1}=\\mathbf{v}/\\|\\mathbf{v}\\|$ and $\\mathbf{c}_{2},\\mathbf{c}_{3}\\in\\mathbf{v}^{\\perp}$. Hence\n$$\nPDP^{T}=3\\,\\mathbf{c}_{1}\\mathbf{c}_{1}^{T}=3\\left(\\frac{\\mathbf{v}}{\\sqrt{3}}\\right)\\left(\\frac{\\mathbf{v}}{\\sqrt{3}}\\right)^{T}=\\mathbf{v}\\mathbf{v}^{T}=A,\n$$\nso A is valid.\n\nB. $D=I$ would imply $A=I$, which is false for $A$ being all ones. Not valid.\n\nC. $D=\\operatorname{diag}(3,0,0)$, but $P$ has columns $(1,1,1)^{T}$, $(1,-1,0)^{T}$, $(1,1,-2)^{T}$, which are not unit vectors. Thus $P$ is not orthogonal. Not valid.\n\nD. Although $D=\\operatorname{diag}(3,0,0)$ and the first column equals $\\mathbf{v}/\\sqrt{3}$, the second and third columns are not orthogonal because their dot product equals $1/2$. Hence $P$ is not orthogonal. Not valid.\n\nE. $D$ places $3$ in the $(2,2)$ position, so $PDP^{T}=3\\,\\mathbf{c}_{2}\\mathbf{c}_{2}^{T}$. With the given $P$ (same as in A), $\\mathbf{c}_{2}=(1,-1,0)^{T}/\\sqrt{2}\\not\\parallel\\mathbf{v}$, so $PDP^{T}\\neq \\mathbf{v}\\mathbf{v}^{T}$. Not valid.\n\nTherefore, only option A provides a correct orthogonal diagonalization.", "answer": "$$\\boxed{A}$$", "id": "1380451"}, {"introduction": "Orthogonal diagonalization is a powerful tool for simplifying complex systems, and a classic example is in the study of conic sections. The presence of a cross-term $xy$ in a quadratic equation signifies that the conic's axes are rotated, and this exercise demonstrates how to find a new coordinate system that eliminates this term. This change of basis simplifies the equation to its standard form, making the geometry of the ellipse or hyperbola clear. [@problem_id:1380458]", "problem": "The equation of a conic section is given by $5x^2 - 6xy + 5y^2 = 8$. The presence of the cross-term, $-6xy$, indicates that the principal axes of this conic section are rotated with respect to the standard Cartesian coordinate axes.\n\nTo simplify this equation, we can perform a rotation of the coordinate system. A new coordinate system $(x', y')$ is related to the original system $(x, y)$ by the transformation $\\begin{pmatrix} x \\\\ y \\end{pmatrix} = P \\begin{pmatrix} x' \\\\ y' \\end{pmatrix}$, where $P$ is a $2 \\times 2$ orthogonal matrix. If $P$ is chosen correctly, the equation of the conic section in the new coordinates will have no cross-term, taking the form $\\lambda_1 (x')^2 + \\lambda_2 (y')^2 = 8$.\n\nDetermine the specific orthogonal matrix $P$ that accomplishes this transformation, subject to the following two conditions:\n1. The matrix $P$ must represent a pure rotation, which means its determinant must be $+1$.\n2. The coefficients of the transformed equation must appear in descending order, that is, $\\lambda_1 > \\lambda_2$.", "solution": "We represent the quadratic form by a symmetric matrix. Writing a general quadratic form as $ax^{2}+2bxy+cy^{2}$ corresponds to the symmetric matrix $\\begin{pmatrix} a & b \\\\ b & c \\end{pmatrix}$. For $5x^{2}-6xy+5y^{2}=8$, we have $a=5$, $2b=-6$ so $b=-3$, and $c=5$, hence\n$$\nA=\\begin{pmatrix}5 & -3 \\\\ -3 & 5\\end{pmatrix}.\n$$\nWe seek an orthogonal matrix $P$ such that, with the change of variables $\\begin{pmatrix} x \\\\ y \\end{pmatrix}=P\\begin{pmatrix} x' \\\\ y' \\end{pmatrix}$, the matrix $P^{T}AP$ is diagonal. By the spectral theorem, the columns of $P$ can be chosen as orthonormal eigenvectors of $A$, and then $P^{T}AP=\\operatorname{diag}(\\lambda_{1},\\lambda_{2})$, where $\\lambda_{1},\\lambda_{2}$ are the eigenvalues of $A$.\n\nCompute the eigenvalues from the characteristic polynomial:\n$$\n\\det(A-\\lambda I)=\\det\\begin{pmatrix}5-\\lambda & -3 \\\\ -3 & 5-\\lambda\\end{pmatrix}=(5-\\lambda)^{2}-9=\\lambda^{2}-10\\lambda+16=0,\n$$\nwhich yields $\\lambda_{1}=8$ and $\\lambda_{2}=2$ (ordered so that $\\lambda_{1}>\\lambda_{2}$).\n\nFind corresponding eigenvectors. For $\\lambda_{1}=8$,\n$$\n(A-8I)\\begin{pmatrix}u \\\\ v\\end{pmatrix}=\\begin{pmatrix}-3 & -3 \\\\ -3 & -3\\end{pmatrix}\\begin{pmatrix}u \\\\ v\\end{pmatrix}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\n\\quad\\Rightarrow\\quad u=-v,\n$$\nso an eigenvector is $\\begin{pmatrix}1 \\\\ -1\\end{pmatrix}$. For $\\lambda_{2}=2$,\n$$\n(A-2I)\\begin{pmatrix}u \\\\ v\\end{pmatrix}=\\begin{pmatrix}3 & -3 \\\\ -3 & 3\\end{pmatrix}\\begin{pmatrix}u \\\\ v\\end{pmatrix}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}\n\\quad\\Rightarrow\\quad u=v,\n$$\nso an eigenvector is $\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$. Normalize these to obtain orthonormal eigenvectors:\n$$\nv_{1}=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ -1\\end{pmatrix},\\qquad v_{2}=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}.\n$$\nChoose $P$ to have these as columns in the order corresponding to $\\lambda_{1}=8$ and $\\lambda_{2}=2$:\n$$\nP=\\begin{pmatrix} v_{1} & v_{2} \\end{pmatrix}\n=\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1 \\\\ -1 & 1 \\end{pmatrix}.\n$$\nThen $P^{T}AP=\\operatorname{diag}(8,2)$, which gives the transformed equation $8(x')^{2}+2(y')^{2}=8$, and the cross-term vanishes. The determinant of $P$ is\n$$\n\\det P=\\left(\\frac{1}{\\sqrt{2}}\\right)^{2}\\bigl(1\\cdot 1-1\\cdot(-1)\\bigr)=1,\n$$\nso $P$ is a pure rotation. The ordering $\\lambda_{1}>\\lambda_{2}$ is satisfied by construction.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\ -\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}}\\end{pmatrix}}$$", "id": "1380458"}]}