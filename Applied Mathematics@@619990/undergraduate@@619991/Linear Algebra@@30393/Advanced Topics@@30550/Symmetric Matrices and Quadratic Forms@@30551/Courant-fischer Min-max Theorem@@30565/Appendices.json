{"hands_on_practices": [{"introduction": "The Courant-Fischer theorem provides powerful tools for understanding eigenvalues without calculating them directly. Its most fundamental consequence is the Rayleigh principle for the smallest eigenvalue, $\\lambda_1$, stating that $\\lambda_1 \\leq \\frac{\\mathbf{x}^T A \\mathbf{x}}{\\mathbf{x}^T \\mathbf{x}}$ for any non-zero vector $\\mathbf{x}$. This exercise challenges you to use this principle to prove a general property of a symmetric matrix by making a clever choice of a single 'test vector' [@problem_id:1356315].", "problem": "Let $A$ be a real, symmetric $n \\times n$ matrix, where $n \\geq 2$. The eigenvalues of $A$ are real and can be ordered as $\\lambda_1 \\leq \\lambda_2 \\leq \\dots \\leq \\lambda_n$. Suppose it is known that at least one of the diagonal entries of $A$ is zero, i.e., there exists an integer $k$ with $1 \\leq k \\leq n$ such that the entry $A_{kk} = 0$.\n\nWhich one of the following statements about the smallest eigenvalue, $\\lambda_1$, is necessarily true for any such matrix $A$?\n\nA) $\\lambda_1 > 0$\n\nB) $\\lambda_1 = 0$\n\nC) $\\lambda_1 < 0$\n\nD) $\\lambda_1 \\leq 0$\n\nE) $\\lambda_1 \\geq 0$", "solution": "The problem asks for a property that the smallest eigenvalue $\\lambda_1$ of a specific type of symmetric matrix must satisfy. The key to solving this problem is to use the Courant-Fischer min-max theorem, which provides a characterization of the eigenvalues of a symmetric matrix.\n\nFor a real symmetric $n \\times n$ matrix $A$, the smallest eigenvalue $\\lambda_1$ is given by the minimum of the Rayleigh quotient over all non-zero vectors in $\\mathbb{R}^n$. The Rayleigh quotient for a non-zero vector $\\mathbf{x}$ is defined as $R_A(\\mathbf{x}) = \\frac{\\mathbf{x}^T A \\mathbf{x}}{\\mathbf{x}^T \\mathbf{x}}$.\n\nThe Courant-Fischer theorem states that:\n$$\n\\lambda_1 = \\min_{\\mathbf{x} \\in \\mathbb{R}^n, \\mathbf{x} \\neq \\mathbf{0}} \\frac{\\mathbf{x}^T A \\mathbf{x}}{\\mathbf{x}^T \\mathbf{x}}\n$$\nThis means that for any specific non-zero vector we choose, say $\\mathbf{v}$, the value of the Rayleigh quotient for that vector, $R_A(\\mathbf{v})$, provides an upper bound for the smallest eigenvalue $\\lambda_1$. That is, for any non-zero vector $\\mathbf{v}$:\n$$\n\\lambda_1 \\leq \\frac{\\mathbf{v}^T A \\mathbf{v}}{\\mathbf{v}^T \\mathbf{v}}\n$$\nWe are given that there is a zero on the diagonal of matrix $A$. Let's say this occurs at the $k$-th position, so $A_{kk} = 0$. We can strategically choose a vector $\\mathbf{v}$ to exploit this information. A natural choice is the $k$-th standard basis vector, $\\mathbf{e}_k$, which is a column vector with a $1$ in the $k$-th position and zeros everywhere else.\n$$\n\\mathbf{e}_k = \\begin{pmatrix} 0 \\\\ \\vdots \\\\ 1 \\\\ \\vdots \\\\ 0 \\end{pmatrix} \\leftarrow k\\text{-th row}\n$$\nThis vector is clearly non-zero, so we can use it to find an upper bound for $\\lambda_1$.\n\nFirst, let's compute the numerator of the Rayleigh quotient, $\\mathbf{e}_k^T A \\mathbf{e}_k$. The quadratic form $\\mathbf{x}^T A \\mathbf{x}$ can be written as $\\sum_{i=1}^n \\sum_{j=1}^n A_{ij} x_i x_j$. For our choice $\\mathbf{x} = \\mathbf{e}_k$, the components are $x_i = \\delta_{ik}$ where $\\delta_{ik}$ is the Kronecker delta.\nSubstituting this into the sum:\n$$\n\\mathbf{e}_k^T A \\mathbf{e}_k = \\sum_{i=1}^n \\sum_{j=1}^n A_{ij} \\delta_{ik} \\delta_{jk}\n$$\nThe product of Kronecker deltas is non-zero (equal to 1) only when both $i=k$ and $j=k$. Therefore, the double summation reduces to a single term:\n$$\n\\mathbf{e}_k^T A \\mathbf{e}_k = A_{kk}\n$$\nNext, we compute the denominator of the Rayleigh quotient, $\\mathbf{e}_k^T \\mathbf{e}_k$. This is the squared Euclidean norm of $\\mathbf{e}_k$.\n$$\n\\mathbf{e}_k^T \\mathbf{e}_k = \\|\\mathbf{e}_k\\|^2 = 0^2 + \\dots + 1^2 + \\dots + 0^2 = 1\n$$\nNow we can compute the Rayleigh quotient for $\\mathbf{v} = \\mathbf{e}_k$:\n$$\nR_A(\\mathbf{e}_k) = \\frac{\\mathbf{e}_k^T A \\mathbf{e}_k}{\\mathbf{e}_k^T \\mathbf{e}_k} = \\frac{A_{kk}}{1} = A_{kk}\n$$\nWe were given that $A_{kk} = 0$. Therefore, $R_A(\\mathbf{e}_k) = 0$.\n\nUsing the inequality $\\lambda_1 \\leq R_A(\\mathbf{v})$ with our chosen vector $\\mathbf{v} = \\mathbf{e}_k$, we find:\n$$\n\\lambda_1 \\leq 0\n$$\nThis shows that the smallest eigenvalue must be less than or equal to zero.\n\nTo confirm that this is the strongest possible statement, let's consider counterexamples for the other options.\n- For options B ($\\lambda_1=0$) and C ($\\lambda_1 < 0$): Consider the zero matrix, $A = \\mathbf{0}$. All its diagonal entries are 0, and all its eigenvalues are 0. So $\\lambda_1=0$. This case is consistent with $\\lambda_1 \\le 0$, but it shows that $\\lambda_1 < 0$ is not always true.\n- For option E ($\\lambda_1 \\geq 0$): Consider the matrix $A = \\begin{pmatrix} 0 & 1 \\\\ 1 & 1 \\end{pmatrix}$. We have $A_{11}=0$. The characteristic equation is $\\det(A-\\lambda I) = (0-\\lambda)(1-\\lambda) - 1 = \\lambda^2 - \\lambda - 1 = 0$. The roots are $\\lambda = \\frac{1 \\pm \\sqrt{1 - 4(-1)}}{2} = \\frac{1 \\pm \\sqrt{5}}{2}$. The smallest eigenvalue is $\\lambda_1 = \\frac{1 - \\sqrt{5}}{2} < 0$. This case is consistent with $\\lambda_1 \\le 0$, but it contradicts $\\lambda_1 \\ge 0$.\n\nCombining our derivation and the counterexamples, the only statement that is always true is $\\lambda_1 \\leq 0$.", "answer": "$$\\boxed{D}$$", "id": "1356315"}, {"introduction": "Building upon the Rayleigh principle, we can now apply eigenvalue bounds to a physical problem. In mechanics, the stability of an equilibrium is tied to the eigenvalues of a 'stiffness' matrix $K$, where instability corresponds to a negative eigenvalue. This practice demonstrates that even when a system appears stable (e.g., has positive diagonal entries in $K$), a strategically chosen displacement vector can reveal an underlying instability by yielding a negative potential energy [@problem_id:1356329].", "problem": "The stability of a mechanical system at an equilibrium point can be analyzed by examining its potential energy. For a system with three degrees of freedom represented by the displacement vector $\\mathbf{x} = \\begin{pmatrix} x_1 & x_2 & x_3 \\end{pmatrix}^T$, the potential energy relative to the equilibrium at $\\mathbf{x} = \\mathbf{0}$ is given by the quadratic form $U(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T K \\mathbf{x}$. The matrix $K$ is a symmetric matrix known as the stiffness matrix.\n\nThe equilibrium at $\\mathbf{x} = \\mathbf{0}$ is considered stable only if the potential energy $U(\\mathbf{x})$ is positive for all possible non-zero displacement vectors $\\mathbf{x}$. If a displacement vector can be found for which the potential energy is negative, the equilibrium is unstable.\n\nConsider a system whose stiffness matrix is given by:\n$$\nK = \\begin{pmatrix} 8 & 3 & 4 \\\\ 3 & 2 & 6 \\\\ 4 & 6 & 5 \\end{pmatrix}\n$$\nNote that all diagonal entries, which represent the energy cost of individual displacements, are positive. Which one of the following displacement vectors reveals that the equilibrium at $\\mathbf{x} = \\mathbf{0}$ is unstable?\n\nA. $\\mathbf{x} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$\n\nB. $\\mathbf{x} = \\begin{pmatrix} 1 \\\\ -1 \\\\ -1 \\end{pmatrix}$\n\nC. $\\mathbf{x} = \\begin{pmatrix} 0 \\\\ -3 \\\\ 1 \\end{pmatrix}$\n\nD. $\\mathbf{x} = \\begin{pmatrix} -1 \\\\ 0 \\\\ 1 \\end{pmatrix}$", "solution": "For a system with potential energy $U(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^{T}K\\mathbf{x}$, stability at $\\mathbf{x}=\\mathbf{0}$ requires $U(\\mathbf{x})>0$ for all nonzero $\\mathbf{x}$. Since the factor $\\frac{1}{2}$ is positive, the sign of $U(\\mathbf{x})$ matches the sign of $\\mathbf{x}^{T}K\\mathbf{x}$. Therefore, instability is revealed by any nonzero $\\mathbf{x}$ for which $\\mathbf{x}^{T}K\\mathbf{x}<0$.\n\nGiven\n$$\nK=\\begin{pmatrix}\n8 & 3 & 4\\\\\n3 & 2 & 6\\\\\n4 & 6 & 5\n\\end{pmatrix},\n$$\ncompute $\\mathbf{x}^{T}K\\mathbf{x}$ for each candidate.\n\nA. $\\mathbf{x}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}$.\nCompute $K\\mathbf{x}$:\n$$\nK\\mathbf{x}=\\begin{pmatrix}\n8\\cdot 1+3\\cdot 1+4\\cdot 1\\\\\n3\\cdot 1+2\\cdot 1+6\\cdot 1\\\\\n4\\cdot 1+6\\cdot 1+5\\cdot 1\n\\end{pmatrix}=\\begin{pmatrix}15\\\\11\\\\15\\end{pmatrix}.\n$$\nThen\n$$\n\\mathbf{x}^{T}K\\mathbf{x}=\\begin{pmatrix}1 & 1 & 1\\end{pmatrix}\\begin{pmatrix}15\\\\11\\\\15\\end{pmatrix}=15+11+15=41>0.\n$$\n\nB. $\\mathbf{x}=\\begin{pmatrix}1\\\\-1\\\\-1\\end{pmatrix}$.\nCompute $K\\mathbf{x}$:\n$$\nK\\mathbf{x}=\\begin{pmatrix}\n8\\cdot 1+3\\cdot(-1)+4\\cdot(-1)\\\\\n3\\cdot 1+2\\cdot(-1)+6\\cdot(-1)\\\\\n4\\cdot 1+6\\cdot(-1)+5\\cdot(-1)\n\\end{pmatrix}=\\begin{pmatrix}1\\\\-5\\\\-7\\end{pmatrix}.\n$$\nThen\n$$\n\\mathbf{x}^{T}K\\mathbf{x}=\\begin{pmatrix}1 & -1 & -1\\end{pmatrix}\\begin{pmatrix}1\\\\-5\\\\-7\\end{pmatrix}=1+5+7=13>0.\n$$\n\nC. $\\mathbf{x}=\\begin{pmatrix}0\\\\-3\\\\1\\end{pmatrix}$.\nCompute $K\\mathbf{x}$:\n$$\nK\\mathbf{x}=\\begin{pmatrix}\n8\\cdot 0+3\\cdot(-3)+4\\cdot 1\\\\\n3\\cdot 0+2\\cdot(-3)+6\\cdot 1\\\\\n4\\cdot 0+6\\cdot(-3)+5\\cdot 1\n\\end{pmatrix}=\\begin{pmatrix}-5\\\\0\\\\-13\\end{pmatrix}.\n$$\nThen\n$$\n\\mathbf{x}^{T}K\\mathbf{x}=\\begin{pmatrix}0 & -3 & 1\\end{pmatrix}\\begin{pmatrix}-5\\\\0\\\\-13\\end{pmatrix}=0+0-13=-13<0.\n$$\nThis yields negative potential energy, revealing instability.\n\nD. $\\mathbf{x}=\\begin{pmatrix}-1\\\\0\\\\1\\end{pmatrix}$.\nCompute $K\\mathbf{x}$:\n$$\nK\\mathbf{x}=\\begin{pmatrix}\n8\\cdot(-1)+3\\cdot 0+4\\cdot 1\\\\\n3\\cdot(-1)+2\\cdot 0+6\\cdot 1\\\\\n4\\cdot(-1)+6\\cdot 0+5\\cdot 1\n\\end{pmatrix}=\\begin{pmatrix}-4\\\\3\\\\1\\end{pmatrix}.\n$$\nThen\n$$\n\\mathbf{x}^{T}K\\mathbf{x}=\\begin{pmatrix}-1 & 0 & 1\\end{pmatrix}\\begin{pmatrix}-4\\\\3\\\\1\\end{pmatrix}=4+0+1=5>0.\n$$\n\nOnly option C gives $\\mathbf{x}^{T}K\\mathbf{x}<0$, so it reveals that the equilibrium is unstable.", "answer": "$$\\boxed{C}$$", "id": "1356329"}, {"introduction": "The power of the Courant-Fischer theorem extends to all eigenvalues, not just the smallest one. This practice introduces the method for bounding an intermediate eigenvalue, such as $\\lambda_2$, by examining the Rayleigh quotient over a chosen subspace. You will calculate an upper bound for $\\lambda_2$ by restricting the matrix to a two-dimensional subspace, demonstrating a technique that is fundamental to many numerical algorithms for approximating eigenvalues [@problem_id:1356352].", "problem": "Let $A$ be the real symmetric $3 \\times 3$ matrix given by:\n$$ A = \\begin{pmatrix} 5 & -1 & 2 \\\\ -1 & 3 & 0 \\\\ 2 & 0 & 9 \\end{pmatrix} $$\nLet the eigenvalues of $A$ be ordered as $\\lambda_1 \\le \\lambda_2 \\le \\lambda_3$.\n\nA principle derived from the Courant-Fischer theorem states that for any two-dimensional subspace $U \\subset \\mathbb{R}^3$, the second eigenvalue $\\lambda_2$ is bounded above by the maximum value of the Rayleigh quotient on that subspace. That is,\n$$ \\lambda_2 \\le \\max_{\\mathbf{x} \\in U, \\mathbf{x} \\neq \\mathbf{0}} \\frac{\\mathbf{x}^T A \\mathbf{x}}{\\mathbf{x}^T \\mathbf{x}} $$\nUsing this principle with the specific subspace $U_0 = \\text{span}\\{(1, 0, 0)^T, (0, 1, 0)^T\\}$, find a numerical upper bound for $\\lambda_2$. Report your answer rounded to three significant figures.", "solution": "We apply the stated Courant-Fischer/Rayleigh-Ritz principle: for a symmetric matrix, the maximum of the Rayleigh quotient on a subspace equals the largest eigenvalue of the restriction of the matrix to that subspace. For the specific subspace $U_{0}=\\text{span}\\{(1,0,0)^{T},(0,1,0)^{T}\\}$, any vector has the form $\\mathbf{x}=(a,b,0)^{T}$ with $(a,b)\\neq(0,0)$. The Rayleigh quotient on $U_{0}$ is\n$$\nR(\\mathbf{x})=\\frac{\\mathbf{x}^{T}A\\mathbf{x}}{\\mathbf{x}^{T}\\mathbf{x}}=\\frac{\\begin{pmatrix}a&b\\end{pmatrix}\\begin{pmatrix}5&-1\\\\-1&3\\end{pmatrix}\\begin{pmatrix}a\\\\b\\end{pmatrix}}{a^{2}+b^{2}}.\n$$\nThus the restriction of $A$ to $U_{0}$ corresponds to the $2\\times 2$ symmetric matrix\n$$\nB=\\begin{pmatrix}5&-1\\\\-1&3\\end{pmatrix}.\n$$\nBy the Rayleigh-Ritz characterization, \n$$\n\\max_{\\mathbf{x}\\in U_{0},\\,\\mathbf{x}\\neq\\mathbf{0}}R(\\mathbf{x})=\\lambda_{\\max}(B),\n$$\nthe largest eigenvalue of $B$. We compute the eigenvalues of $B$ from its characteristic polynomial:\n$$\n\\det(B-tI)=\\det\\begin{pmatrix}5-t&-1\\\\-1&3-t\\end{pmatrix}=(5-t)(3-t)-1=t^{2}-8t+14.\n$$\nSolving $t^{2}-8t+14=0$ gives\n$$\nt=\\frac{8\\pm\\sqrt{64-56}}{2}=\\frac{8\\pm\\sqrt{8}}{2}=4\\pm\\sqrt{2}.\n$$\nHence $\\lambda_{\\max}(B)=4+\\sqrt{2}$. By the given principle,\n$$\n\\lambda_{2}\\leq\\max_{\\mathbf{x}\\in U_{0},\\,\\mathbf{x}\\neq\\mathbf{0}}R(\\mathbf{x})=4+\\sqrt{2}.\n$$\nTherefore, a numerical upper bound for $\\lambda_{2}$ is $4+\\sqrt{2}\\approx 5.41421356$, which rounded to three significant figures is $5.41$.", "answer": "$$\\boxed{5.41}$$", "id": "1356352"}]}