{"hands_on_practices": [{"introduction": "To truly master the Kronecker product, it is essential to look beyond its forward computation and understand its inherent structure. This introductory exercise [@problem_id:1370645] challenges you to \"deconstruct\" a given matrix, identifying its constituent parts by recognizing the repeating, scaled block patterns. This reverse-engineering approach solidifies your grasp of the fundamental definition, $A \\otimes B = (a_{ij}B)$, and trains your eye to spot this important structure in practice.", "problem": "The Kronecker product of an $m \\times n$ matrix $A = (a_{ij})$ and a $p \\times q$ matrix $B$, denoted as $A \\otimes B$, is the $mp \\times nq$ block matrix defined as:\n$$\nA \\otimes B = \\begin{pmatrix}\na_{11}B & a_{12}B & \\cdots & a_{1n}B \\\\\na_{21}B & a_{22}B & \\cdots & a_{2n}B \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1}B & a_{m2}B & \\cdots & a_{mn}B\n\\end{pmatrix}\n$$\nConsider a $2 \\times 2$ matrix $A$ and a $2 \\times 2$ matrix $B$ given by\n$$\nB = \\begin{pmatrix} 1 & 2 \\\\ 0 & 1 \\end{pmatrix}\n$$\nTheir Kronecker product results in the $4 \\times 4$ matrix $C = A \\otimes B$, where\n$$\nC = \\begin{pmatrix}\n3 & 6 & 1 & 2 \\\\\n0 & 3 & 0 & 1 \\\\\n-1 & -2 & 2 & 4 \\\\\n0 & -1 & 0 & 2\n\\end{pmatrix}\n$$\nDetermine the value of the determinant of the matrix $A$.", "solution": "Let $A=\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ and $B=\\begin{pmatrix} 1 & 2 \\\\ 0 & 1 \\end{pmatrix}$. By the definition of the Kronecker product, for $2 \\times 2$ matrices,\n$$\nA \\otimes B=\\begin{pmatrix} aB & bB \\\\ cB & dB \\end{pmatrix}.\n$$\nThe given matrix $C$ is\n$$\nC=\\begin{pmatrix}\n3 & 6 & 1 & 2 \\\\\n0 & 3 & 0 & 1 \\\\\n-1 & -2 & 2 & 4 \\\\\n0 & -1 & 0 & 2\n\\end{pmatrix},\n$$\nwhich we view as four $2 \\times 2$ blocks:\n$$\nC=\\begin{pmatrix}\n\\begin{pmatrix} 3 & 6 \\\\ 0 & 3 \\end{pmatrix} & \\begin{pmatrix} 1 & 2 \\\\ 0 & 1 \\end{pmatrix} \\\\\n\\begin{pmatrix} -1 & -2 \\\\ 0 & -1 \\end{pmatrix} & \\begin{pmatrix} 2 & 4 \\\\ 0 & 2 \\end{pmatrix}\n\\end{pmatrix}.\n$$\nSince $B=\\begin{pmatrix} 1 & 2 \\\\ 0 & 1 \\end{pmatrix}$, any scalar multiple $xB$ equals $\\begin{pmatrix} x & 2x \\\\ 0 & x \\end{pmatrix}$. Matching each block with $xB$ gives:\n- Top-left block: $\\begin{pmatrix} 3 & 6 \\\\ 0 & 3 \\end{pmatrix}=3B \\implies a=3$.\n- Top-right block: $\\begin{pmatrix} 1 & 2 \\\\ 0 & 1 \\end{pmatrix}=1B \\implies b=1$.\n- Bottom-left block: $\\begin{pmatrix} -1 & -2 \\\\ 0 & -1 \\end{pmatrix}=-1B \\implies c=-1$.\n- Bottom-right block: $\\begin{pmatrix} 2 & 4 \\\\ 0 & 2 \\end{pmatrix}=2B \\implies d=2$.\n\nTherefore,\n$$\nA=\\begin{pmatrix} 3 & 1 \\\\ -1 & 2 \\end{pmatrix},\n$$\nand its determinant is\n$$\n\\det(A)=ad-bc=3\\cdot 2-1\\cdot(-1)=6+1=7.\n$$\nAs a consistency check using the determinant property of Kronecker products, for square matrices of size $2$, $\\det(A \\otimes B)=\\det(A)^{2}\\det(B)^{2}$. Here $\\det(B)=1$, so $\\det(C)=\\det(A)^{2}$, which agrees with $\\det(A)=7$ since $\\det(C)=49$.", "answer": "$$\\boxed{7}$$", "id": "1370645"}, {"introduction": "The power of the Kronecker product lies not just in its definition, but in how it elegantly interacts with other fundamental matrix operations. This practice [@problem_id:1370671] invites you to explore the relationship between the Kronecker product and matrix transposition, governed by the rule $(A \\otimes B)^T = A^T \\otimes B^T$. By investigating the symmetry of a composite matrix, you will learn to combine algebraic properties to prove general results about matrix structures, a key skill in theoretical linear algebra.", "problem": "In linear algebra, a square matrix $A$ is called **symmetric** if it is equal to its transpose, i.e., $A^T = A$. A square matrix $B$ is called **skew-symmetric** if it is equal to the negative of its transpose, i.e., $B^T = -B$.\n\nThe **Kronecker product** of an $m \\times n$ matrix $A$ and a $p \\times q$ matrix $B$, denoted as $A \\otimes B$, is an $mp \\times nq$ block matrix given by:\n$$\nA \\otimes B = \\begin{pmatrix}\na_{11}B & a_{12}B & \\dots & a_{1n}B \\\\\na_{21}B & a_{22}B & \\dots & a_{2n}B \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1}B & a_{m2}B & \\dots & a_{mn}B\n\\end{pmatrix}\n$$\n\nLet $S$ be a non-zero $n \\times n$ symmetric matrix and $K$ be a non-zero $n \\times n$ skew-symmetric matrix, where $n \\ge 2$. Consider the matrix $M$ defined as:\n$$\nM = S \\otimes K + K \\otimes S\n$$\n\nDetermine the classification of the matrix $M$.\n\nA. $M$ is always symmetric.\n\nB. $M$ is always skew-symmetric.\n\nC. $M$ is neither symmetric nor skew-symmetric in general.\n\nD. $M$ is both symmetric and skew-symmetric.\n\nE. The property of $M$ depends on the specific choice of $S$ and $K$.", "solution": "To determine the properties of the matrix $M$, we need to analyze its transpose, $M^T$. The matrix $M$ is defined as $M = S \\otimes K + K \\otimes S$.\n\nFirst, we use the property that the transpose of a sum of matrices is the sum of their transposes:\n$$\nM^T = (S \\otimes K + K \\otimes S)^T = (S \\otimes K)^T + (K \\otimes S)^T\n$$\n\nNext, we use a fundamental property of the Kronecker product concerning transposition, which states that $(A \\otimes B)^T = A^T \\otimes B^T$. Applying this property to each term gives:\n$$\nM^T = (S^T \\otimes K^T) + (K^T \\otimes S^T)\n$$\n\nWe are given that $S$ is a symmetric matrix and $K$ is a skew-symmetric matrix. By their definitions:\n- For the symmetric matrix $S$, we have $S^T = S$.\n- For the skew-symmetric matrix $K$, we have $K^T = -K$.\n\nNow, we substitute these properties back into the expression for $M^T$:\n$$\nM^T = (S) \\otimes (-K) + (-K) \\otimes (S)\n$$\n\nUsing the scalar multiplication property of the Kronecker product, which is $(\\lambda A) \\otimes B = A \\otimes (\\lambda B) = \\lambda(A \\otimes B)$ for any scalar $\\lambda$, we can factor out the $-1$:\n$$\nM^T = -(S \\otimes K) - (K \\otimes S)\n$$\n\nFactoring out the negative sign from the entire expression, we get:\n$$\nM^T = -(S \\otimes K + K \\otimes S)\n$$\n\nThe expression inside the parentheses is the definition of the original matrix $M$. Therefore, we have found that:\n$$\nM^T = -M\n$$\n\nBy definition, a matrix $A$ is skew-symmetric if $A^T = -A$. Since $M^T = -M$, the matrix $M$ is skew-symmetric.\n\nWe must also consider if $M$ could be the zero matrix. If $M=0$, it would be both symmetric and skew-symmetric. However, since $S$ and $K$ are non-zero, it is possible to construct examples where $M$ is not the zero matrix. For instance, if $n=2$, let $S = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$ and $K = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}$.\nThen $S \\otimes K = \\begin{pmatrix} K & 0 \\\\ 0 & K \\end{pmatrix}$ and $K \\otimes S = \\begin{pmatrix} 0 & S \\\\ -S & 0 \\end{pmatrix}$. Their sum $M$ is clearly non-zero. Since $M$ is not always the zero matrix, it is not \"both symmetric and skew-symmetric\" in general.\n\nThus, the matrix $M$ is always skew-symmetric. This corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1370671"}, {"introduction": "Beyond the realm of pure theory, the Kronecker product is a powerful tool in data science and physics for modeling and decomposing complex systems. This advanced practice [@problem_id:1370665] presents a realistic scenario: finding the best \"Kronecker-separable\" approximation to a matrix, akin to filtering noise to reveal an underlying structure. You will apply a sophisticated method involving matrix reshaping and the Singular Value Decomposition (SVD) to connect the abstract idea of separability to the concrete task of finding a best rank-1 approximation.", "problem": "In many areas of physics and data science, such as quantum computing and signal analysis, large matrices often exhibit a \"separable\" structure. A matrix $M$ is called Kronecker-separable if it can be expressed as the Kronecker product $M = A \\otimes B$ of two smaller matrices, $A$ and $B$. The Kronecker product of an $m \\times n$ matrix $A$ and a $p \\times q$ matrix $B$ is the $(mp) \\times (nq)$ block matrix:\n$$\nA \\otimes B = \\begin{pmatrix}\nA_{11}B & A_{12}B & \\cdots & A_{1n}B \\\\\nA_{21}B & A_{22}B & \\cdots & A_{2n}B \\\\\n\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\nA_{m1}B & A_{m2}B & \\cdots & A_{mn}B\n\\end{pmatrix}\n$$\nIn practice, measurements are noisy, so a measured matrix $M$ might only be an approximation of an ideal separable matrix. The goal is to find the best separable approximation, $M_{\\text{ideal}} = A \\otimes B$, which minimizes the Frobenius norm of the error, $\\|M - A \\otimes B\\|_F$.\n\nThis optimization problem is equivalent to finding the best rank-1 approximation of a specially \"reshaped\" matrix, $M_R$. The procedure is as follows:\n1.  The given $(mp) \\times (nq)$ matrix $M$ is partitioned into an $m \\times n$ grid of blocks, where each block $M_{ij}$ is a $p \\times q$ matrix.\n2.  A vectorization operator, `vec(X)`, transforms a matrix $X$ into a single column vector by stacking its columns sequentially.\n3.  The reshaped matrix $M_R$ is constructed as an $(mn) \\times (pq)$ matrix. Its $k$-th row is given by $(\\text{vec}(M_{ij}))^T$, where the index $k$ corresponds to the block index $(i,j)$ in row-major order, i.e., $k = (i-1)n + j$.\n4.  The best rank-1 approximation of $M_R$ is given by $M_R^{(1)} = \\sigma_1 u_1 v_1^T$, where $(\\sigma_1, u_1, v_1)$ are the components from the Singular Value Decomposition (SVD) of $M_R$ corresponding to the largest singular value $\\sigma_1$. Here, $u_1$ is the left singular vector and $v_1$ is the right singular vector.\n5.  The optimal matrices $A$ and $B$ are reconstructed from these components. To ensure a unique solution, a symmetric scaling is used:\n    $$ \\text{vec}(A) = \\sqrt{\\sigma_1} u_1 \\quad \\text{and} \\quad \\text{vec}(B) = \\sqrt{\\sigma_1} v_1 $$\n    The matrices $A$ and $B$ are then recovered by reshaping these vectors back into their original matrix dimensions.\n\n**Problem:**\nYou are given the following $4 \\times 2$ measured matrix $M$:\n$$\nM = \\begin{pmatrix}\n3 & 0 \\\\\n1 & 0 \\\\\n1 & 0 \\\\\n3 & 0\n\\end{pmatrix}\n$$\nFind the best Kronecker-separable approximation $M_{\\text{ideal}} = A \\otimes B$, where $A$ is a $2 \\times 1$ matrix and $B$ is a $2 \\times 2$ matrix, by following the procedure described above.\nYour task is to calculate the value of $\\det(B^T B + I)$, where $I$ is the $2 \\times 2$ identity matrix.", "solution": "We are given $M \\in \\mathbb{R}^{4 \\times 2}$, and we seek the best Kronecker-separable approximation $M_{\\text{ideal}} = A \\otimes B$ with $A \\in \\mathbb{R}^{2 \\times 1}$ and $B \\in \\mathbb{R}^{2 \\times 2}$. Here $m=2$, $n=1$, $p=2$, $q=2$, so $mp=4$ and $nq=2$ match the size of $M$.\n\nPartition $M$ into an $m \\times n$ grid of $p \\times q$ blocks. Since $n=1$, there are two blocks, each of size $2 \\times 2$:\n$$\nM = \\begin{pmatrix}\n3 & 0 \\\\\n1 & 0 \\\\\n1 & 0 \\\\\n3 & 0\n\\end{pmatrix}, \\quad\nM_{11} = \\begin{pmatrix} 3 & 0 \\\\ 1 & 0 \\end{pmatrix}, \\quad\nM_{21} = \\begin{pmatrix} 1 & 0 \\\\ 3 & 0 \\end{pmatrix}.\n$$\nForm the reshaped matrix $M_{R} \\in \\mathbb{R}^{(mn) \\times (pq)} = \\mathbb{R}^{2 \\times 4}$ by taking rows as $(\\operatorname{vec}(M_{i1}))^{T}$ in row-major order. Using $\\operatorname{vec}\\big(\\begin{pmatrix} x_{11} & x_{12} \\\\ x_{21} & x_{22} \\end{pmatrix}\\big) = \\begin{pmatrix} x_{11} \\\\ x_{21} \\\\ x_{12} \\\\ x_{22} \\end{pmatrix}$, we obtain\n$$\n\\operatorname{vec}(M_{11}) = \\begin{pmatrix} 3 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\operatorname{vec}(M_{21}) = \\begin{pmatrix} 1 \\\\ 3 \\\\ 0 \\\\ 0 \\end{pmatrix},\n$$\nhence\n$$\nM_{R} = \\begin{pmatrix}\n3 & 1 & 0 & 0 \\\\\n1 & 3 & 0 & 0\n\\end{pmatrix}.\n$$\n\nCompute the best rank-1 approximation $M_{R}^{(1)} = \\sigma_{1} u_{1} v_{1}^{T}$ from the SVD of $M_{R}$. Only the first two columns of $M_{R}$ are nonzero, so the nonzero singular values coincide with those of the $2 \\times 2$ matrix\n$$\nS = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix}.\n$$\nSince $S$ is symmetric, its singular values are the absolute values of its eigenvalues. The eigenvalues of $S$ are obtained by solving\n$$\n\\det\\!\\begin{pmatrix} 3-\\lambda & 1 \\\\ 1 & 3-\\lambda \\end{pmatrix} = (3-\\lambda)^{2} - 1 = 0 \\;\\Rightarrow\\; \\lambda \\in \\{4, 2\\}.\n$$\nThus the largest singular value is $\\sigma_{1} = 4$. A corresponding unit eigenvector for $\\lambda=4$ is\n$$\nw = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}.\n$$\nEmbedding into $\\mathbb{R}^{4}$ (with zeros in positions corresponding to the zero columns of $M_{R}$), a valid right singular vector is\n$$\nv_{1} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\nThe corresponding left singular vector satisfies $u_{1} = \\frac{1}{\\sigma_{1}} M_{R} v_{1}$, and since $M_{R} v_{1} = S w = 4 w$, we get\n$$\nu_{1} = w = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}.\n$$\n\nUsing the symmetric scaling prescribed,\n$$\n\\operatorname{vec}(A) = \\sqrt{\\sigma_{1}}\\, u_{1} = 2 \\cdot \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n= \\begin{pmatrix} \\sqrt{2} \\\\ \\sqrt{2} \\end{pmatrix},\n\\quad\n\\operatorname{vec}(B) = \\sqrt{\\sigma_{1}}\\, v_{1} = 2 \\cdot \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ 0 \\end{pmatrix}\n= \\begin{pmatrix} \\sqrt{2} \\\\ \\sqrt{2} \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\nReshaping $\\operatorname{vec}(B)$ into a $2 \\times 2$ matrix via $\\operatorname{vec}(B) = \\begin{pmatrix} B_{11} \\\\ B_{21} \\\\ B_{12} \\\\ B_{22} \\end{pmatrix}$ yields\n$$\nB = \\begin{pmatrix} \\sqrt{2} & 0 \\\\ \\sqrt{2} & 0 \\end{pmatrix}.\n$$\n\nNow compute $B^{T} B + I$, where $I$ is the $2 \\times 2$ identity matrix. First,\n$$\nB^{T} B = \\begin{pmatrix} \\sqrt{2} & \\sqrt{2} \\\\ 0 & 0 \\end{pmatrix}\n\\begin{pmatrix} \\sqrt{2} & 0 \\\\ \\sqrt{2} & 0 \\end{pmatrix}\n= \\begin{pmatrix} 4 & 0 \\\\ 0 & 0 \\end{pmatrix},\n$$\nhence\n$$\nB^{T} B + I = \\begin{pmatrix} 4 & 0 \\\\ 0 & 0 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n= \\begin{pmatrix} 5 & 0 \\\\ 0 & 1 \\end{pmatrix}.\n$$\nTherefore,\n$$\n\\det(B^{T} B + I) = 5 \\cdot 1 - 0 = 5.\n$$", "answer": "$$\\boxed{5}$$", "id": "1370665"}]}