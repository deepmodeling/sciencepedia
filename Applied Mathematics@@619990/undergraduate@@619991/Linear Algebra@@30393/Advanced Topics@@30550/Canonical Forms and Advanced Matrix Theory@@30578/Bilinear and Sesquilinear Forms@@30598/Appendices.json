{"hands_on_practices": [{"introduction": "To truly master bilinear forms, we must be able to move seamlessly between their abstract definition and their concrete matrix representation. This first exercise provides foundational practice in this essential skill. Given the matrix of a bilinear form with respect to a specific basis, you will derive its explicit algebraic formula, reinforcing the core relationship $f(\\mathbf{u}, \\mathbf{v}) = [\\mathbf{u}]_{\\mathcal{B}}^T A [\\mathbf{v}]_{\\mathcal{B}}$ and demonstrating how the choice of basis and the matrix $A$ determines the form's behavior on any pair of vectors [@problem_id:1350845].", "problem": "Consider the real vector space $P_1(\\mathbb{R})$, which consists of all polynomials of degree at most one with real coefficients. Let $f: P_1(\\mathbb{R}) \\times P_1(\\mathbb{R}) \\to \\mathbb{R}$ be a bilinear form on this space. The matrix representation of this bilinear form with respect to the ordered basis $\\mathcal{B} = \\{1, x\\}$ is given by\n$$A = \\begin{pmatrix} 1 & 2 \\\\ 0 & 3 \\end{pmatrix}$$\nLet $p(x) = a_0 + a_1 x$ and $q(x) = b_0 + b_1 x$ be two arbitrary polynomials in $P_1(\\mathbb{R})$, where $a_0, a_1, b_0, b_1$ are real numbers. Determine the explicit formula for $f(p(x), q(x))$ in terms of the coefficients $a_0, a_1, b_0, b_1$.", "solution": "A bilinear form $f$ on a finite-dimensional vector space has a matrix $A$ with respect to an ordered basis $\\mathcal{B}=\\{1,x\\}$ defined by $A_{ij}=f(b_{i},b_{j})$, where $b_{1}=1$ and $b_{2}=x$. For vectors $p(x)=a_{0}+a_{1}x$ and $q(x)=b_{0}+b_{1}x$, their coordinate column vectors in the basis $\\mathcal{B}$ are $[p]_{\\mathcal{B}}=\\begin{pmatrix} a_{0} \\\\ a_{1} \\end{pmatrix}$ and $[q]_{\\mathcal{B}}=\\begin{pmatrix} b_{0} \\\\ b_{1} \\end{pmatrix}$. The bilinear form evaluates via\n$$\nf(p,q) = [p]_{\\mathcal{B}}^{T} A [q]_{\\mathcal{B}}.\n$$\nWith $A=\\begin{pmatrix} 1 & 2 \\\\ 0 & 3 \\end{pmatrix}$, compute\n$$\nA [q]_{\\mathcal{B}} = \\begin{pmatrix} 1 & 2 \\\\ 0 & 3 \\end{pmatrix} \\begin{pmatrix} b_{0} \\\\ b_{1} \\end{pmatrix} = \\begin{pmatrix} b_{0}+2 b_{1} \\\\ 3 b_{1} \\end{pmatrix},\n$$\nand then\n$$\nf(p,q) = [p]_{\\mathcal{B}}^{T} \\begin{pmatrix} b_{0}+2 b_{1} \\\\ 3 b_{1} \\end{pmatrix} = a_{0}(b_{0}+2 b_{1}) + a_{1}(3 b_{1}) = a_{0} b_{0} + 2 a_{0} b_{1} + 3 a_{1} b_{1}.\n$$\nEquivalently, using $f(1,1)=1$, $f(1,x)=2$, $f(x,1)=0$, and $f(x,x)=3$, bilinearity gives\n$$\nf(p,q) = a_{0} b_{0} f(1,1) + a_{0} b_{1} f(1,x) + a_{1} b_{0} f(x,1) + a_{1} b_{1} f(x,x) = a_{0} b_{0} + 2 a_{0} b_{1} + 3 a_{1} b_{1}.\n$$", "answer": "$$\\boxed{a_{0} b_{0} + 2 a_{0} b_{1} + 3 a_{1} b_{1}}$$", "id": "1350845"}, {"introduction": "A key application of symmetric bilinear forms lies in the study of quadratic forms, which describe various geometric shapes like ellipses and hyperbolas. A powerful technique is to find a \"nicer\" coordinate system in which the quadratic form has a simpler, diagonal expression without any cross-product terms. This practice guides you through this process of diagonalization, connecting it to the fundamental concept of eigenvalues and introducing the signature, a numerical invariant that classifies the geometric nature of the form [@problem_id:1350853].", "problem": "Consider the vector space $V = \\mathbb{R}^2$ over the real numbers, with coordinates $(x_1, x_2)$ relative to the standard basis. A quadratic form $q: V \\to \\mathbb{R}$ is defined by the expression:\n$$q(x_1, x_2) = 3x_1^2 + 2x_1x_2 + 3x_2^2$$\nIt is a fundamental result in linear algebra that through a suitable change of coordinates from $(x_1, x_2)$ to a new coordinate system $(y_1, y_2)$, this quadratic form can be expressed in a diagonal representation, namely $q(y_1, y_2) = c_1 y_1^2 + c_2 y_2^2$, where $c_1$ and $c_2$ are real-valued coefficients.\n\nThe signature of the quadratic form, denoted by $\\sigma$, is defined as the number of positive coefficients minus the number of negative coefficients in any such diagonal representation. This value is an invariant of the quadratic form.\n\nDetermine the sum of the coefficients, $S = c_1 + c_2$, and the signature, $\\sigma$, of the quadratic form $q$. Your final answer should be a pair of numbers presented as a row matrix $\\begin{pmatrix} S & \\sigma \\end{pmatrix}$.", "solution": "We represent the quadratic form by its symmetric matrix $A$ with respect to the standard basis, defined via $q(x) = x^{T} A x$. Matching coefficients for $q(x_{1},x_{2}) = 3x_{1}^{2} + 2x_{1}x_{2} + 3x_{2}^{2}$ gives\n$$\nA = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix},\n$$\nsince $2a_{12}x_{1}x_{2} = 2x_{1}x_{2}$ implies $a_{12} = a_{21} = 1$ and the diagonal entries are $a_{11} = a_{22} = 3$.\n\nBecause $A$ is real symmetric, there exists an orthogonal matrix $Q$ such that $Q^{T} A Q = \\operatorname{diag}(\\lambda_{1},\\lambda_{2})$, where $\\lambda_{1},\\lambda_{2}$ are the eigenvalues of $A$. In the orthonormal coordinate system $y = Q^{T} x$, the quadratic form becomes\n$$\nq(y_{1},y_{2}) = \\lambda_{1} y_{1}^{2} + \\lambda_{2} y_{2}^{2},\n$$\nso the diagonal coefficients are precisely the eigenvalues of $A$.\n\nCompute the eigenvalues from the characteristic polynomial:\n$$\n\\det(A - \\lambda I) = \\det \\begin{pmatrix} 3 - \\lambda & 1 \\\\ 1 & 3 - \\lambda \\end{pmatrix} = (3 - \\lambda)^{2} - 1 = \\lambda^{2} - 6\\lambda + 8.\n$$\nSolving $\\lambda^{2} - 6\\lambda + 8 = 0$ gives\n$$\n(\\lambda - 2)(\\lambda - 4) = 0 \\quad \\Rightarrow \\quad \\lambda_{1} = 2,\\;\\; \\lambda_{2} = 4.\n$$\nThus the diagonal form has coefficients $c_{1} = 2$ and $c_{2} = 4$. The sum of the coefficients is\n$$\nS = c_{1} + c_{2} = 2 + 4 = 6,\n$$\nwhich also equals $\\operatorname{tr}(A)$, consistent with orthogonal diagonalization.\n\nBoth eigenvalues are positive, so there are two positive and zero negative coefficients in the diagonal representation. By the definition of signature,\n$$\n\\sigma = \\#\\{\\text{positive}\\} - \\#\\{\\text{negative}\\} = 2 - 0 = 2.\n$$\nTherefore, the requested pair is $\\begin{pmatrix} S & \\sigma \\end{pmatrix} = \\begin{pmatrix} 6 & 2 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} 6 & 2 \\end{pmatrix}}$$", "id": "1350853"}, {"introduction": "Not all bilinear forms are \"well-behaved\"; some are degenerate, meaning there exist non-zero vectors that are orthogonal to every vector in the space. This exercise explores a powerful method for handling degeneracy by constructing a new, non-degenerate bilinear form on a quotient space. You will first identify the form's radical—the subspace of \"problematic\" vectors—and then see how a well-defined and non-degenerate structure, $\\tilde{B}$, emerges on the quotient space $V/\\text{rad}(B)$, illustrating a fundamental principle for restoring non-degeneracy [@problem_id:1350830].", "problem": "Let $V = \\mathbb{R}^4$ be the vector space of 4-dimensional real column vectors. Consider the bilinear form $B: V \\times V \\to \\mathbb{R}$ defined for any two vectors $x = (x_1, x_2, x_3, x_4)^T$ and $y = (y_1, y_2, y_3, y_4)^T$ in $V$ by the expression:\n$$B(x, y) = (x_1 + x_3)(y_1 + y_3) + (x_2 + x_4)(y_2 + y_4)$$\nLet $\\text{rad}(B)$ be the radical of the bilinear form $B$. The radical is the subspace of $V$ consisting of all vectors $v$ such that $B(v, y) = 0$ for all $y \\in V$. On the quotient space $V/\\text{rad}(B)$, there is a naturally induced non-degenerate bilinear form $\\tilde{B}$.\nLet $\\{e_1, e_2, e_3, e_4\\}$ denote the standard basis of $\\mathbb{R}^4$, where $e_i$ is the vector with a 1 in the $i$-th position and 0s elsewhere.\n\nDetermine the matrix representation of the induced bilinear form $\\tilde{B}$ with respect to the ordered basis $\\mathcal{C} = \\{e_1 + \\text{rad}(B), e_2 + \\text{rad}(B)\\}$ for the quotient space $V/\\text{rad}(B)$.", "solution": "We first express the bilinear form $B$ by a symmetric matrix $M$ in the standard basis $\\{e_{1},e_{2},e_{3},e_{4}\\}$, defined by $B(x,y)=x^{T}My$. From\n$$B(x,y)=(x_{1}+x_{3})(y_{1}+y_{3})+(x_{2}+x_{4})(y_{2}+y_{4})$$\nwe expand to obtain\n$$B(x,y)=x_{1}y_{1}+x_{1}y_{3}+x_{3}y_{1}+x_{3}y_{3}+x_{2}y_{2}+x_{2}y_{4}+x_{4}y_{2}+x_{4}y_{4},$$\nhence\n$$M=\\begin{pmatrix}\n1 & 0 & 1 & 0\\\\\n0 & 1 & 0 & 1\\\\\n1 & 0 & 1 & 0\\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}.$$\n\nThe radical is $\\text{rad}(B)=\\{v\\in V:B(v,y)=0\\ \\forall y\\in V\\}$, which equals $\\ker M$ because $B(v,y)=(Mv)^{T}y$ for all $y$. Solving $Mv=0$ for $v=(v_{1},v_{2},v_{3},v_{4})^{T}$ gives the equations\n$$v_{1}+v_{3}=0,\\quad v_{2}+v_{4}=0,$$\nso\n$$\\text{rad}(B)=\\{(a,b,-a,-b)^{T}:a,b\\in\\mathbb{R}\\}=\\operatorname{span}\\{(1,0,-1,0)^{T},(0,1,0,-1)^{T}\\}.$$\nThus $V/\\text{rad}(B)$ has dimension $2$.\n\nThe induced bilinear form $\\tilde{B}$ on $V/\\text{rad}(B)$ is defined by $\\tilde{B}(x+\\text{rad}(B),y+\\text{rad}(B))=B(x,y)$, which is well defined because $\\text{rad}(B)$ is the set of all vectors orthogonal to every vector under $B$.\n\nWith respect to the ordered basis $\\mathcal{C}=\\{e_{1}+\\text{rad}(B),e_{2}+\\text{rad}(B)\\}$, the matrix entries are\n$$\\tilde{B}(e_{i}+\\text{rad}(B),e_{j}+\\text{rad}(B))=B(e_{i},e_{j}).$$\nCompute:\n- $B(e_{1},e_{1})=(1+0)(1+0)+(0+0)(0+0)=1$,\n- $B(e_{1},e_{2})=(1+0)(0+0)+(0+0)(1+0)=0$,\n- $B(e_{2},e_{1})=0$ by symmetry,\n- $B(e_{2},e_{2})=(0+0)(0+0)+(1+0)(1+0)=1$.\n\nTherefore, the matrix of $\\tilde{B}$ in the basis $\\mathcal{C}$ is\n$$\\begin{pmatrix}1 & 0\\\\ 0 & 1\\end{pmatrix}.$$", "answer": "$$\\boxed{\\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}}$$", "id": "1350830"}]}