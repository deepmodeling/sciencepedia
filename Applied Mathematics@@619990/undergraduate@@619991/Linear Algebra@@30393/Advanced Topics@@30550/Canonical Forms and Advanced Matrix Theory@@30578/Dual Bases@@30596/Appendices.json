{"hands_on_practices": [{"introduction": "The journey into understanding dual spaces begins with a foundational skill: constructing a dual basis from a given basis. This first exercise provides a direct, hands-on method for this calculation within the familiar context of $\\mathbb{R}^2$ [@problem_id:1359437]. By working through this problem, you will see how the abstract defining property of a dual basis, $f^i(v_j) = \\delta^i_j$, translates into a concrete matrix operation, providing a powerful tool for finding coordinate-extracting functionals.", "problem": "Consider the vector space $V = \\mathbb{R}^2$ over the field of real numbers $\\mathbb{R}$. A basis for this space is given by the set of vectors $\\mathcal{B} = \\{v_1, v_2\\}$, where $v_1 = (2, 1)$ and $v_2 = (1, 3)$. The dual space, denoted $V^*$, is the vector space of all linear functionals on $V$. Associated with the basis $\\mathcal{B}$ is a unique dual basis $\\mathcal{B}^* = \\{f^1, f^2\\}$, whose elements are linear functionals defined by the property $f^i(v_j) = \\delta^i_j$, where $\\delta^i_j$ is the Kronecker delta (i.e., $\\delta^i_j = 1$ if $i=j$ and $\\delta^i_j = 0$ if $i \\neq j$).\n\nDetermine the explicit formula for the first linear functional, $f^1$, of the dual basis. Your answer should be an expression for $f^1(u)$ for an arbitrary vector $u=(x, y)$ in $\\mathbb{R}^2$.", "solution": "We are given a basis $\\mathcal{B}=\\{v_{1},v_{2}\\}$ of $V=\\mathbb{R}^{2}$ with $v_{1}=(2,1)$ and $v_{2}=(1,3)$. The dual basis $\\mathcal{B}^{*}=\\{f^{1},f^{2}\\}$ satisfies $f^{i}(v_{j})=\\delta^{i}_{j}$. For any $u=(x,y)\\in\\mathbb{R}^{2}$, write $u$ in the basis $\\mathcal{B}$ as $u=a_{1}v_{1}+a_{2}v_{2}$. Then $f^{1}(u)=a_{1}$ and $f^{2}(u)=a_{2}$ by definition of the dual basis.\n\nLet $B$ be the matrix whose columns are $v_{1}$ and $v_{2}$ in the standard basis:\n$$\nB=\\begin{pmatrix}2 & 1\\\\ 1 & 3\\end{pmatrix}.\n$$\nThe coordinate vector of $u$ in the basis $\\mathcal{B}$ is given by\n$$\n\\begin{pmatrix}a_{1}\\\\ a_{2}\\end{pmatrix}=B^{-1}\\begin{pmatrix}x\\\\ y\\end{pmatrix}.\n$$\nThus $f^{1}(u)$ is the first component of $B^{-1}(x,y)^{T}$, i.e., the first row of $B^{-1}$ applied to $(x,y)^{T}$.\n\nCompute the inverse:\n$$\n\\det(B)=2\\cdot 3-1\\cdot 1=5,\\qquad\nB^{-1}=\\frac{1}{5}\\begin{pmatrix}3 & -1\\\\ -1 & 2\\end{pmatrix}.\n$$\nTherefore,\n$$\nf^{1}(u)=\\frac{1}{5}\\begin{pmatrix}3 & -1\\end{pmatrix}\\begin{pmatrix}x\\\\ y\\end{pmatrix}=\\frac{3x-y}{5}.\n$$\nWe can verify the defining property: $f^{1}(v_{1})=\\frac{3\\cdot 2-1}{5}=1$ and $f^{1}(v_{2})=\\frac{3\\cdot 1-3}{5}=0$, as required.", "answer": "$$\\boxed{\\frac{3x-y}{5}}$$", "id": "1359437"}, {"introduction": "Linear algebra extends far beyond geometric vectors; it provides the framework for studying function spaces. This exercise moves our exploration into the space of polynomials, a cornerstone of approximation theory and physics [@problem_id:1508600]. Here, we reverse the typical problem: given a set of linear functionals defined by integration and differentiation, we will construct the unique basis of polynomials that these functionals are dual to, deepening our appreciation for the symmetrical nature of duality.", "problem": "Consider the vector space $V$ of all polynomials in the variable $t$ with real coefficients and degree at most 1. In the dual space $V^*$, which consists of all linear functionals from $V$ to $\\mathbb{R}$, a basis is given by the two covectors, $\\omega^1$ and $\\omega^2$. Their actions on any polynomial $p(t) \\in V$ are defined as follows:\n$$ \\omega^1(p) = \\int_0^1 p(t) dt $$\n$$ \\omega^2(p) = p'(0) $$\nwhere $p'(0)$ denotes the derivative of $p(t)$ with respect to $t$, evaluated at $t=0$.\n\nFind the basis $\\{e_1, e_2\\}$ of the original vector space $V$ that is dual to the basis $\\{\\omega^1, \\omega^2\\}$. Present your answer as the ordered pair of polynomials $(e_1(t), e_2(t))$.", "solution": "We work in the 2-dimensional real vector space $V$ of polynomials of degree at most $1$. Any $p(t) \\in V$ can be written uniquely as $p(t) = a t + b$ with $a, b \\in \\mathbb{R}$. The given covectors are\n$$\n\\omega^{1}(p) = \\int_{0}^{1} p(t)\\, dt, \\quad \\omega^{2}(p) = p'(0).\n$$\nFor $p(t) = a t + b$, we compute\n$$\n\\omega^{1}(p) = \\int_{0}^{1} (a t + b)\\, dt = \\frac{a}{2} + b, \\quad \\omega^{2}(p) = a.\n$$\nWe seek a basis $\\{e_{1}, e_{2}\\}$ of $V$ dual to $\\{\\omega^{1}, \\omega^{2}\\}$, meaning it satisfies the duality conditions\n$$\n\\omega^{i}(e_{j}) = \\delta^{i}_{j} \\quad \\text{for } i,j \\in \\{1,2\\}.\n$$\nWrite $e_{1}(t) = a_{1} t + b_{1}$. The conditions are\n$$\n\\omega^{1}(e_{1}) = \\frac{a_{1}}{2} + b_{1} = 1, \\quad \\omega^{2}(e_{1}) = a_{1} = 0.\n$$\nFrom $a_{1} = 0$, we get $b_{1} = 1$. Hence $e_{1}(t) = 1$.\n\nNext write $e_{2}(t) = a_{2} t + b_{2}$. The conditions are\n$$\n\\omega^{1}(e_{2}) = \\frac{a_{2}}{2} + b_{2} = 0, \\quad \\omega^{2}(e_{2}) = a_{2} = 1.\n$$\nFrom $a_{2} = 1$, we solve $\\frac{1}{2} + b_{2} = 0$ to get $b_{2} = -\\frac{1}{2}$. Hence $e_{2}(t) = t - \\frac{1}{2}$.\n\nTherefore, the dual basis in $V$ is $(e_{1}(t), e_{2}(t)) = \\left(1,\\, t - \\frac{1}{2}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix}1 & t-\\frac{1}{2}\\end{pmatrix}}$$", "id": "1508600"}, {"introduction": "A deep understanding of dual bases involves not just their construction, but also their behavior under a change of basis. This practice tackles a crucial theoretical question: how does the dual basis transform when we express our original space in a new coordinate system [@problem_id:1359421]? Uncovering this relationship reveals a fundamental transformation law that is indispensable in advanced topics like tensor calculus and its applications in physics.", "problem": "Let $V$ be a 3-dimensional vector space over the field of real numbers, $\\mathbb{R}$. The space of all linear functionals on $V$, denoted by $V^*$, is called the dual space of $V$. Let $\\mathcal{B} = \\{v_1, v_2, v_3\\}$ be an ordered basis for $V$. Its corresponding dual basis is the ordered basis $\\mathcal{B}^* = \\{f^1, f^2, f^3\\}$ for $V^*$, which is defined by the property $f^i(v_j) = \\delta^i_j$ for all $i,j \\in \\{1, 2, 3\\}$, where $\\delta^i_j$ is the Kronecker delta.\n\nNow, consider a new ordered basis for $V$, denoted by $\\mathcal{C} = \\{w_1, w_2, w_3\\}$, whose vectors are related to the vectors of $\\mathcal{B}$ by the following equations:\n$$w_1 = v_1$$\n$$w_2 = v_1 + 2v_2$$\n$$w_3 = v_1 + 2v_2 + 3v_3$$\n\nLet $\\mathcal{C}^* = \\{g^1, g^2, g^3\\}$ be the ordered dual basis corresponding to $\\mathcal{C}$. Determine the vectors $g^1, g^2, g^3$ by expressing them as linear combinations of the vectors in the original dual basis $\\mathcal{B}^* = \\{f^1, f^2, f^3\\}$.", "solution": "We begin with the ordered basis $\\mathcal{B}=\\{v_{1},v_{2},v_{3}\\}$ of $V$ and its dual basis $\\mathcal{B}^{*}=\\{f^{1},f^{2},f^{3}\\}$ satisfying $f^{i}(v_{j})=\\delta^{i}_{j}$. The new ordered basis $\\mathcal{C}=\\{w_{1},w_{2},w_{3}\\}$ is given by\n$$\nw_{1}=v_{1},\\quad w_{2}=v_{1}+2v_{2},\\quad w_{3}=v_{1}+2v_{2}+3v_{3}.\n$$\nLet $M$ be the change-of-basis matrix whose $j$-th column is the coordinate vector of $w_{j}$ in the basis $\\mathcal{B}$. From the definitions above, we obtain\n$$\nM=\\begin{pmatrix}\n1 & 1 & 1\\\\\n0 & 2 & 2\\\\\n0 & 0 & 3\n\\end{pmatrix}.\n$$\nIf $A$ is the matrix whose $i$-th column contains the coefficients of $g^{i}$ in the basis $\\{f^{1},f^{2},f^{3}\\}$, i.e., $g^{i}=\\sum_{k=1}^{3}a_{k i}f^{k}$ with $A=(a_{k i})$, then the duality condition $g^{i}(w_{j})=\\delta^{i}_{j}$ implies\n$$\nA^{T}M=I \\quad \\Longrightarrow \\quad A=M^{-T}.\n$$\nWe therefore compute $M^{-1}$. Since $M$ is upper triangular, we solve $MN=I$ with\n$$\nN=\\begin{pmatrix}\n1 & -\\frac{1}{2} & 0\\\\\n0 & \\frac{1}{2} & -\\frac{1}{3}\\\\\n0 & 0 & \\frac{1}{3}\n\\end{pmatrix}\n\\quad\\text{so that}\\quad\nM^{-1}=N.\n$$\nTaking the transpose gives\n$$\nA=M^{-T}=N^{T}=\\begin{pmatrix}\n1 & 0 & 0\\\\\n-\\frac{1}{2} & \\frac{1}{2} & 0\\\\\n0 & -\\frac{1}{3} & \\frac{1}{3}\n\\end{pmatrix}.\n$$\nHence the columns of $A$ provide the desired expressions of $g^{1},g^{2},g^{3}$ in terms of $f^{1},f^{2},f^{3}$:\n$$\ng^{1}=f^{1}-\\frac{1}{2}f^{2},\\quad\ng^{2}=\\frac{1}{2}f^{2}-\\frac{1}{3}f^{3},\\quad\ng^{3}=\\frac{1}{3}f^{3}.\n$$\nIt is straightforward to verify that these satisfy $g^{i}(w_{j})=\\delta^{i}_{j}$ by direct evaluation.", "answer": "$$\\boxed{\\begin{pmatrix}\nf^{1}-\\frac{1}{2}f^{2} & \\frac{1}{2}f^{2}-\\frac{1}{3}f^{3} & \\frac{1}{3}f^{3}\n\\end{pmatrix}}$$", "id": "1359421"}]}