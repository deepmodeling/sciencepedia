{"hands_on_practices": [{"introduction": "The primary function of a Givens rotation in numerical methods is to selectively introduce a zero into a vector. This first exercise is your entry point to mastering that core skill. Here, we will construct the precise $2 \\times 2$ Givens matrix required to zero out one component of a vector, laying the foundation for all subsequent applications [@problem_id:2176490].", "problem": "In numerical linear algebra, a Givens rotation is an operation that rotates a vector in a two-dimensional plane and is often used to introduce zeros into vectors or matrices as part of algorithms like QR decomposition. A 2x2 Givens matrix is an orthogonal matrix of the form\n$$\nG = \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix}\n$$\nwhere $c$ and $s$ are real numbers that satisfy the condition $c^2 + s^2 = 1$.\n\nConsider the vector $x = \\begin{pmatrix} 7 \\\\ -4 \\end{pmatrix}$. Determine the specific Givens matrix $G$ that transforms this vector $x$ into a new vector $y = Gx$ which has the form $\\begin{pmatrix} r \\\\ 0 \\end{pmatrix}$, under the additional constraint that the resulting component $r$ must be positive.\n\nPresent your answer as a 2x2 matrix with exact numerical entries.", "solution": "Let $G=\\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix}$ with $c^{2}+s^{2}=1$ and $x=\\begin{pmatrix} a \\\\ b \\end{pmatrix}$. Then\n$$\nGx=\\begin{pmatrix} ca+sb \\\\ -sa+cb \\end{pmatrix}.\n$$\nTo obtain $Gx=\\begin{pmatrix} r \\\\ 0 \\end{pmatrix}$, enforce the second component to vanish:\n$$\n-sa+cb=0 \\quad \\Longleftrightarrow \\quad cb=sa.\n$$\nA standard choice satisfying this and $c^{2}+s^{2}=1$ is\n$$\nr=\\sqrt{a^{2}+b^{2}}, \\quad c=\\frac{a}{r}, \\quad s=\\frac{b}{r}.\n$$\nWith this choice,\n$$\n-sa+cb=-\\frac{b}{r}a+\\frac{a}{r}b=0, \\quad ca+sb=\\frac{a^{2}+b^{2}}{r}=r,\n$$\nand since $r=\\sqrt{a^{2}+b^{2}}$ is positive, the requirement $r>0$ is satisfied.\n\nFor $x=\\begin{pmatrix} 7 \\\\ -4 \\end{pmatrix}$ we have $a=7$, $b=-4$, hence\n$$\nr=\\sqrt{7^{2}+(-4)^{2}}=\\sqrt{65}, \\quad c=\\frac{7}{\\sqrt{65}}, \\quad s=\\frac{-4}{\\sqrt{65}}.\n$$\nTherefore,\n$$\nG=\\begin{pmatrix} \\frac{7}{\\sqrt{65}} & \\frac{-4}{\\sqrt{65}} \\\\ \\frac{4}{\\sqrt{65}} & \\frac{7}{\\sqrt{65}} \\end{pmatrix}.\n$$\nThis $G$ yields $Gx=\\begin{pmatrix} \\sqrt{65} \\\\ 0 \\end{pmatrix}$ with the positive first component as required.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{7}{\\sqrt{65}} & \\frac{-4}{\\sqrt{65}} \\\\ \\frac{4}{\\sqrt{65}} & \\frac{7}{\\sqrt{65}} \\end{pmatrix}}$$", "id": "2176490"}, {"introduction": "A robust algorithm must handle all possible inputs, including seemingly trivial ones. This practice moves beyond rote calculation to explore a crucial edge case: what happens when we apply the procedure to an element that is already zero? By analyzing this scenario [@problem_id:1365914], you will gain insight into the logic that underpins efficient and stable numerical implementations.", "problem": "In numerical linear algebra, a Givens rotation is used to introduce a zero into a vector. A Givens rotation matrix, denoted as $G(i, j, c, s)$, is an identity matrix except for four elements at the intersections of the $i$-th and $j$-th rows and columns. These elements form a $2 \\times 2$ rotation sub-matrix:\n$$\n\\begin{pmatrix} g_{ii} & g_{ij} \\\\ g_{ji} & g_{jj} \\end{pmatrix} = \\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix}\n$$\nwhere $c^2 + s^2 = 1$. The non-zero entries are $g_{ii}=g_{jj}=c$, $g_{ij}=s$, and $g_{ji}=-s$ for $i<j$.\n\nTo zero out the $j$-th component of a vector $x = (..., x_i, ..., x_j, ...)^T$ using the $i$-th component as a pivot (where $i < j$), one constructs a vector $y = G(i, j, c, s)x$. The values for $c$ and $s$ are typically calculated as:\n$$\n c = \\frac{x_i}{\\sqrt{x_i^2 + x_j^2}}, \\quad s = \\frac{x_j}{\\sqrt{x_i^2 + x_j^2}}\n$$\nThis transformation affects only the $i$-th and $j$-th components of the vector, resulting in $y_i = \\sqrt{x_i^2 + x_j^2}$ and $y_j = 0$.\n\nConsider a vector $v \\in \\mathbb{R}^n$ where, for some indices $i < j$, the pivot component $v_i$ is non-zero, but the target component $v_j$ is already zero. If we mechanically apply the procedure to construct the Givens rotation matrix $G(i, j, c, s)$ to \"zero out\" the already-zero $v_j$, what is the resulting matrix $G$?\n\nA. The matrix $G$ is the identity matrix.\n\nB. The matrix $G$ is a permutation matrix that swaps the $i$-th and $j$-th basis vectors, but is not the identity.\n\nC. The construction fails because the formulas for $c$ and $s$ would involve division by zero.\n\nD. The matrix $G$ becomes a reflection matrix across the hyperplane defined by the $i$-th coordinate.\n\nE. The matrix $G$ sets the $i$-th component of the transformed vector to zero instead of the $j$-th, i.e., $(Gv)_i = 0$.", "solution": "The problem asks to determine the form of a Givens rotation matrix $G$ when the procedure is applied to a vector $v$ where the target component, $v_j$, is already zero, and the pivot component, $v_i$, is non-zero.\n\nThe primary purpose of applying the Givens rotation $G$ is to produce a new vector $y=Gv$ such that its $j$-th component $y_j$ is zero. In the given scenario, the vector $v$ already has $v_j=0$. The simplest possible transformation that preserves this property is the identity transformation, where $G=I$, the identity matrix. If we set $G=I$, then $y=Iv=v$, and so $y_j = v_j = 0$. The goal is met with no actual rotation performed.\n\nLet's verify if the identity matrix is a valid Givens rotation matrix according to the problem's definition. The identity matrix has $g_{ii}=1$, $g_{jj}=1$, and $g_{ij}=g_{ji}=0$. Comparing this to the Givens sub-matrix form:\n$$\n\\begin{pmatrix} c & s \\\\ -s & c \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nThis implies $c=1$ and $s=0$. These values satisfy the condition $c^2 + s^2 = 1^2 + 0^2 = 1$. Thus, the identity matrix corresponds to a Givens rotation with a rotation angle of zero. In any practical numerical algorithm, if the target element is already zero, no operation is performed, which is equivalent to applying the identity matrix.\n\nAlternatively, we can analyze the behavior by substituting the given vector components into the formulas for $c$ and $s$. We have $v_i \\neq 0$ and $v_j = 0$.\nThe denominator is $\\sqrt{v_i^2 + v_j^2} = \\sqrt{v_i^2 + 0^2} = \\sqrt{v_i^2} = |v_i|$.\nSince $v_i \\neq 0$, the denominator is non-zero. Therefore, the construction does not fail due to division by zero, and option C is incorrect.\n\nNow, we compute $c$ and $s$:\n$$\ns = \\frac{v_j}{\\sqrt{v_i^2 + v_j^2}} = \\frac{0}{|v_i|} = 0\n$$\n$$\nc = \\frac{v_i}{\\sqrt{v_i^2 + v_j^2}} = \\frac{v_i}{|v_i|}\n$$\nIf $v_i > 0$, then $c = v_i/v_i = 1$.\nIf $v_i < 0$, then $c = v_i/(-v_i) = -1$.\n\nIn the case where $v_i>0$, we have $c=1$ and $s=0$. This yields the identity matrix, as shown before.\nIn the case where $v_i<0$, we would get $c=-1$ and $s=0$. The sub-matrix would be $\\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}$. While this is not the identity, standard, robust implementations of Givens rotations define the transformation to be the identity when the target element is already zero to ensure stability and consistency. The problem implicitly refers to this standard procedure. The most sensible interpretation, especially in an introductory context, is that the procedure results in a \"no-op\" or identity transformation because no action is required to meet the goal.\n\nBased on this reasoning, the resulting matrix $G$ is the identity matrix.\nLet's re-evaluate the options:\nA. The matrix $G$ is the identity matrix. - This is the correct outcome in a practical setting and for $v_i > 0$ even with blind formula application.\nB. A non-identity permutation matrix. - False. The sub-matrix is diagonal.\nD. A reflection matrix. - False. The determinant of $G$ is 1, not -1.\nE. $(Gv)_i=0$. - False. With the given formulas, $(Gv)_i = c v_i + s v_j = (v_i/|v_i|) v_i + 0 = |v_i| \\neq 0$.\n\nTherefore, the only option consistent with the purpose and standard implementation of a Givens rotation is that the matrix is the identity matrix.", "answer": "$$\\boxed{A}$$", "id": "1365914"}, {"introduction": "Having mastered the single Givens operation, it's time to think like an algorithm designer. This final practice challenges you to scale up your thinking from a two-dimensional plane to an n-dimensional space. You will devise an efficient, step-by-step strategy using a sequence of Givens rotations to transform an arbitrary vector and determine the minimum number of operations required [@problem_id:1365884]. This exercise directly mirrors the logic used in powerful algorithms like QR factorization.", "problem": "Let $x$ be a non-zero vector in $\\mathbb{R}^n$, where $n \\ge 2$ is an integer. We wish to transform $x$ into a vector $y$ that is a scalar multiple of the first standard basis vector $e_1 = (1, 0, \\dots, 0)^T$. This transformation is to be accomplished by applying a sequence of Givens rotations.\n\nA Givens rotation in $\\mathbb{R}^n$ is defined by a matrix $G(i, j, \\theta)$ with $1 \\le i < j \\le n$. This matrix is identical to the $n \\times n$ identity matrix, except for four entries:\n$G_{ii} = \\cos(\\theta)$\n$G_{jj} = \\cos(\\theta)$\n$G_{ij} = \\sin(\\theta)$\n$G_{ji} = -\\sin(\\theta)$\nfor some angle $\\theta \\in [0, 2\\pi)$. Applying this matrix to a vector corresponds to a rotation in the plane spanned by the basis vectors $e_i$ and $e_j$.\n\nA sequence of $k$ rotations transforms $x$ into $y$ as follows:\n$$y = G_k G_{k-1} \\cdots G_1 x$$\nwhere each $G_m$ is a Givens rotation matrix of the form $G(i_m, j_m, \\theta_m)$.\n\nConsidering an arbitrary non-zero vector $x \\in \\mathbb{R}^n$, what is the minimal number of Givens rotations required to guarantee that the resulting vector $y$ is parallel to $e_1$? The choice of which planes to rotate in and by what angles is yours to make for each step. Express your answer as a function of $n$.", "solution": "The problem asks for the minimum number of Givens rotations needed to transform any non-zero vector $x \\in \\mathbb{R}^n$ into a vector parallel to $e_1$. A vector parallel to $e_1$ must be of the form $(\\alpha, 0, 0, \\dots, 0)^T$ for some scalar $\\alpha$. This means we need to zero out the last $n-1$ components of the vector.\n\nThe solution consists of two parts: first, showing that the transformation can be achieved using a certain number of rotations (an upper bound on the minimum), and second, arguing that it is not possible to do so with fewer rotations (a lower bound).\n\n**Part 1: Constructive approach (Upper Bound)**\n\nLet the initial vector be $x = (x_1, x_2, \\dots, x_n)^T$. We want to apply a sequence of Givens rotations to make the components $x_2, x_3, \\dots, x_n$ equal to zero. We can do this systematically by eliminating one component at a time. A strategic way to do this is to zero out components from last to first (i.e., $x_n, x_{n-1}, \\dots, x_2$), using rotations in planes that involve the first component.\n\n1.  **Zeroing out the $n$-th component:**\n    Let's use a Givens rotation in the $(1, n)$-plane, $G_1 = G(1, n, \\theta_1)$. Let $x^{(1)} = G_1 x$. This rotation only affects the 1st and $n$-th components of $x$. The other components remain unchanged. The new 1st and $n$-th components are related to the old ones by:\n    $$\n    \\begin{pmatrix} x^{(1)}_1 \\\\ x^{(1)}_n \\end{pmatrix} = \\begin{pmatrix} \\cos\\theta_1 & \\sin\\theta_1 \\\\ -\\sin\\theta_1 & \\cos\\theta_1 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_n \\end{pmatrix}\n    $$\n    We want to choose $\\theta_1$ such that $x^{(1)}_n = 0$. This requires $-x_1 \\sin\\theta_1 + x_n \\cos\\theta_1 = 0$.\n    If $x_1$ and $x_n$ are not both zero, we can always find such a $\\theta_1$. For instance, we can set $\\cos\\theta_1 = \\frac{x_1}{r}$ and $\\sin\\theta_1 = \\frac{x_n}{r}$, where $r = \\sqrt{x_1^2 + x_n^2}$. If $r=0$, then $x_1=x_n=0$ and the $n$-th component is already zero, so no rotation is needed (or we can use $\\theta_1=0$). With this choice of $\\theta_1$, we get $x^{(1)}_n = 0$.\n    So, after one rotation, we have the vector $x^{(1)} = (x_1', x_2, x_3, \\dots, x_{n-1}, 0)^T$.\n\n2.  **Zeroing out the $(n-1)$-th component:**\n    Now, we apply a second Givens rotation, $G_2 = G(1, n-1, \\theta_2)$, to the vector $x^{(1)}$. Let $x^{(2)} = G_2 x^{(1)}$. This rotation affects only the 1st and $(n-1)$-th components of $x^{(1)}$. Critically, it does not affect the $n$-th component, which is already zero. We choose $\\theta_2$ to make the new $(n-1)$-th component of $x^{(2)}$ zero.\n    After this second rotation, the vector is of the form $x^{(2)} = (x_1'', x_2, \\dots, x_{n-2}, 0, 0)^T$.\n\n3.  **General Procedure:**\n    We continue this process. To zero out the $j$-th component (for $j = n, n-1, \\dots, 2$), we apply a Givens rotation $G(1, j, \\theta)$ to the current vector. Each such rotation is chosen to zero out the $j$-th component, and it only modifies the 1st and $j$-th components, leaving all others (including those already set to zero) unchanged.\n\nTo zero out the components from index $2$ to $n$, we need to perform this operation for $j = n, n-1, \\dots, 2$. This is a total of $n-1$ components. Therefore, a sequence of $n-1$ Givens rotations is sufficient to transform any vector $x$ into the desired form. This establishes that the minimal number is at most $n-1$.\n\n**Part 2: Minimality argument (Lower Bound)**\n\nNow we must argue that it is not possible to guarantee the transformation with fewer than $n-1$ rotations. Let's consider a generic vector $x \\in \\mathbb{R}^n$ where all components $x_i$ are non-zero. The target vector $y = (\\alpha, 0, \\dots, 0)^T$ has $n-1$ zero components. Our starting vector has zero zero-components. So we need to introduce $n-1$ zeros.\n\nLet's analyze the effect of a single Givens rotation, $G(i, j, \\theta)$, on a vector $v$. Let $w = G(i, j, \\theta)v$.\nThe components of $w$ are $w_k = v_k$ for $k \\notin \\{i, j\\}$. This means that if $v_k \\neq 0$ for such a $k$, then $w_k$ is also non-zero. No new zeros can be created in positions other than $i$ and $j$.\n\nThe components $w_i$ and $w_j$ are given by:\n$$\nw_i = v_i \\cos\\theta + v_j \\sin\\theta\n$$\n$$\nw_j = -v_i \\sin\\theta + v_j \\cos\\theta\n$$\nCan we create two zeros at once, i.e., can $w_i = w_j = 0$? In matrix form, this is $\\begin{pmatrix} \\cos\\theta & \\sin\\theta \\\\ -\\sin\\theta & \\cos\\theta \\end{pmatrix} \\begin{pmatrix} v_i \\\\ v_j \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$. Since the rotation matrix is invertible (its determinant is 1), this equation holds if and only if $v_i = 0$ and $v_j = 0$. However, we are considering the case where we start with non-zero components. Thus, if at least one of $v_i, v_j$ is non-zero, we cannot make both $w_i$ and $w_j$ zero.\n\nThis means that a single Givens rotation can increase the number of zero components in a vector by at most one.\nTo transform a generic vector with no zero components into a vector with $n-1$ zero components, we need to increase the count of zeros from 0 to $n-1$. Since each rotation can increase this count by at most one, we need at least $n-1$ rotations.\n\nThis lower bound applies to the \"worst-case\" scenario of a vector with no pre-existing zero components in the positions $2, \\dots, n$. Since the problem asks for the minimal number of rotations to *guarantee* the transformation for an *arbitrary* vector, we must prepare for this worst case.\n\n**Conclusion**\n\nWe have shown that $n-1$ rotations are sufficient (Part 1) and that for a general vector, at least $n-1$ rotations are necessary (Part 2). Therefore, the minimal number of Givens rotations required is exactly $n-1$.", "answer": "$$\\boxed{n-1}$$", "id": "1365884"}]}