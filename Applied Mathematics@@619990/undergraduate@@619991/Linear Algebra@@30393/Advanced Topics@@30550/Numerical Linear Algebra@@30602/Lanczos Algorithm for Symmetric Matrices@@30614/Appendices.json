{"hands_on_practices": [{"introduction": "The Lanczos algorithm is best understood by doing. This first exercise provides a direct, hands-on opportunity to apply the iterative process that lies at the heart of the method. By manually computing the first two iterations for a small $3 \\times 3$ matrix, you will see how the orthonormal basis vectors and the tridiagonal matrix $T$ are constructed step-by-step, solidifying your understanding of the core mechanics.", "problem": "The Lanczos algorithm is a powerful iterative method used in numerical linear algebra, particularly for finding eigenvalues of large symmetric matrices. When applied to an $n \\times n$ symmetric matrix $A$ with a starting vector $b$, the algorithm constructs a sequence of orthonormal vectors that form a basis for a Krylov subspace, and simultaneously builds a symmetric tridiagonal matrix $T$ whose eigenvalues approximate those of $A$.\n\nConsider the real symmetric $3 \\times 3$ matrix $A$ and the starting vector $b$ given below:\n$$ A = \\begin{pmatrix} 4  1  1 \\\\ 1  2  3 \\\\ 1  3  5 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nLet $T_2$ be the $2 \\times 2$ symmetric tridiagonal matrix generated after two full iterations of the Lanczos algorithm applied to matrix $A$ with the starting vector $b$. Your task is to compute the matrix $T_2$.", "solution": "We apply the standard Lanczos iteration for a real symmetric matrix with initial vector normalized to unit length. Let $v_{1} = \\frac{b}{\\|b\\|}$, $\\beta_{0} = 0$, and for $j \\geq 1$:\n$$\nw_{j} = A v_{j} - \\beta_{j-1} v_{j-1}, \\quad \\alpha_{j} = v_{j}^{T} w_{j}, \\quad w_{j} \\leftarrow w_{j} - \\alpha_{j} v_{j}, \\quad \\beta_{j} = \\|w_{j}\\|, \\quad v_{j+1} = \\frac{w_{j}}{\\beta_{j}}.\n$$\nThe $2 \\times 2$ tridiagonal matrix after two iterations is\n$$\nT_{2} = \\begin{pmatrix} \\alpha_{1}  \\beta_{1} \\\\ \\beta_{1}  \\alpha_{2} \\end{pmatrix}.\n$$\n\nGiven $b = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$, we have $\\|b\\| = 1$, hence\n$$\nv_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\nFirst iteration:\n$$\nw_{1} = A v_{1} = \\begin{pmatrix} 4 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad \\alpha_{1} = v_{1}^{T} w_{1} = 4,\n$$\n$$\nw_{1} \\leftarrow w_{1} - \\alpha_{1} v_{1} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad \\beta_{1} = \\|w_{1}\\| = \\sqrt{0^{2} + 1^{2} + 1^{2}} = \\sqrt{2},\n$$\n$$\nv_{2} = \\frac{w_{1}}{\\beta_{1}} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}.\n$$\n\nSecond iteration:\n$$\nA v_{2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2 \\\\ 5 \\\\ 8 \\end{pmatrix}, \\quad w_{2} = A v_{2} - \\beta_{1} v_{1} = \\begin{pmatrix} 0 \\\\ \\frac{5}{\\sqrt{2}} \\\\ \\frac{8}{\\sqrt{2}} \\end{pmatrix},\n$$\n$$\n\\alpha_{2} = v_{2}^{T} w_{2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 0  1  1 \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ \\frac{5}{\\sqrt{2}} \\\\ \\frac{8}{\\sqrt{2}} \\end{pmatrix} = \\frac{13}{2}.\n$$\n\nTherefore,\n$$\nT_{2} = \\begin{pmatrix} \\alpha_{1}  \\beta_{1} \\\\ \\beta_{1}  \\alpha_{2} \\end{pmatrix} = \\begin{pmatrix} 4  \\sqrt{2} \\\\ \\sqrt{2}  \\frac{13}{2} \\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 4  \\sqrt{2} \\\\ \\sqrt{2}  \\frac{13}{2} \\end{pmatrix}}$$", "id": "1371132"}, {"introduction": "Understanding the limiting cases of an algorithm provides deep insight into its behavior. This practice [@problem_id:1371167] explores a fundamental scenario: what happens when the Lanczos algorithm is initiated with an eigenvector of the matrix $A$? Analyzing this special case will clarify the meaning of the termination condition $\\beta_j = 0$ and reveal the direct connection between the algorithm's output and the matrix's spectral properties.", "problem": "Let $A$ be a real, symmetric $n \\times n$ matrix and let $b$ be a non-zero vector in $\\mathbb{R}^n$. It is given that $b$ is an eigenvector of $A$ corresponding to a real eigenvalue $\\lambda$. The Lanczos algorithm is applied to the matrix $A$ with the starting vector $b$. The algorithm proceeds as follows:\n\n1.  Initialize: Let $q_1 = b / \\|b\\|_2$, $\\beta_0 = 0$, and $q_0 = \\vec{0}$ (the zero vector).\n2.  For $j = 1, 2, \\dots$:\n    a. Compute $v_j = A q_j$.\n    b. Compute the diagonal element $\\alpha_j = q_j^T v_j$.\n    c. Compute the residual vector $w_j = v_j - \\alpha_j q_j - \\beta_{j-1} q_{j-1}$.\n    d. Compute the off-diagonal element $\\beta_j = \\|w_j\\|_2$.\n    e. If $\\beta_j = 0$, the algorithm terminates. Let $m=j$.\n    f. Otherwise, compute the next vector $q_{j+1} = w_j / \\beta_j$.\n\nThe algorithm produces an $m \\times m$ symmetric tridiagonal matrix $T_m$ with diagonal entries $\\alpha_1, \\dots, \\alpha_m$ and off-diagonal entries $\\beta_1, \\dots, \\beta_{m-1}$.\n\nWhich of the following statements correctly describes the outcome of this process?\n\nA. The algorithm runs for $m=n$ iterations because the dimension of the Krylov subspace is always $n$.\n\nB. The algorithm terminates after one iteration ($m=1$), and the produced matrix is the $1 \\times 1$ matrix $T_1 = [\\lambda]$.\n\nC. The algorithm terminates after one iteration ($m=1$), and the produced matrix is the $1 \\times 1$ matrix $T_1 = [1]$.\n\nD. The algorithm fails at the first step because computing $q_1$ involves division by zero.\n\nE. The algorithm runs indefinitely because using an eigenvector as the starting vector creates a cycle.", "solution": "The problem asks to determine the behavior of the Lanczos algorithm when the starting vector is an eigenvector of the matrix. Let's trace the steps of the algorithm with the given information.\n\nWe are given a symmetric matrix $A$, a non-zero vector $b$, and a scalar $\\lambda$ such that $A b = \\lambda b$.\n\n**Step 1: Initialization**\nThe algorithm starts by initializing the first vector $q_1$.\n$$q_1 = \\frac{b}{\\|b\\|_2}$$\nSince $b$ is a non-zero vector, $\\|b\\|_2 \\neq 0$, so $q_1$ is well-defined. $q_1$ is a unit vector parallel to $b$.\nWe also have $\\beta_0 = 0$ and $q_0 = \\vec{0}$.\n\n**Step 2: First Iteration ($j=1$)**\nNow we proceed with the first iteration of the loop.\n\na. Compute $v_1 = A q_1$.\nSince $q_1$ is a scalar multiple of the eigenvector $b$, $q_1$ is also an eigenvector of $A$ corresponding to the same eigenvalue $\\lambda$.\n$$A q_1 = A \\left(\\frac{b}{\\|b\\|_2}\\right) = \\frac{1}{\\|b\\|_2} (A b) = \\frac{1}{\\|b\\|_2} (\\lambda b) = \\lambda \\left(\\frac{b}{\\|b\\|_2}\\right) = \\lambda q_1$$\nSo, $v_1 = \\lambda q_1$.\n\nb. Compute $\\alpha_1 = q_1^T v_1$.\nSubstituting the expression for $v_1$:\n$$\\alpha_1 = q_1^T (\\lambda q_1) = \\lambda (q_1^T q_1)$$\nSince $q_1$ is a unit vector, $q_1^T q_1 = \\|q_1\\|_2^2 = 1$.\nTherefore, $\\alpha_1 = \\lambda$.\n\nc. Compute the residual vector $w_1 = v_1 - \\alpha_1 q_1 - \\beta_0 q_0$.\nUsing the values we've found:\n$$w_1 = (\\lambda q_1) - (\\lambda) q_1 - (0) \\vec{0} = \\lambda q_1 - \\lambda q_1 - \\vec{0} = \\vec{0}$$\nThe residual vector is the zero vector.\n\nd. Compute $\\beta_1 = \\|w_1\\|_2$.\n$$\\beta_1 = \\|\\vec{0}\\|_2 = 0$$\n\ne. Check for termination.\nThe termination condition is $\\beta_j = 0$. Since we found $\\beta_1 = 0$, the algorithm terminates at this step. The number of iterations is $m=1$.\n\nThe output of the algorithm is the $m \\times m$ tridiagonal matrix $T_m$. In this case, $m=1$, so we get a $1 \\times 1$ matrix $T_1$. The general form of $T_m$ has the $\\alpha_j$ values on the diagonal. For $m=1$, the matrix is simply:\n$$T_1 = [\\alpha_1]$$\nWe found that $\\alpha_1 = \\lambda$. Thus, the resulting matrix is $T_1 = [\\lambda]$.\n\nNow, let's evaluate the given options:\nA. The algorithm runs for $m=n$ iterations because the dimension of the Krylov subspace is always $n$. This is false. The algorithm terminated after $m=1$ iteration. The Krylov subspace $\\mathcal{K}_1(A, b) = \\text{span}\\{b\\}$ is one-dimensional.\nB. The algorithm terminates after one iteration ($m=1$), and the produced matrix is the $1 \\times 1$ matrix $T_1 = [\\lambda]$. This is exactly what we found.\nC. The algorithm terminates after one iteration ($m=1$), and the produced matrix is the $1 \\times 1$ matrix $T_1 = [1]$. This is false; the matrix element is the eigenvalue $\\lambda$, which is not necessarily 1.\nD. The algorithm fails at the first step because computing $q_1$ involves division by zero. This is false. The problem states that $b$ is a non-zero vector, so its norm $\\|b\\|_2$ is non-zero.\nE. The algorithm runs indefinitely because using an eigenvector as the starting vector creates a cycle. This is false. The Lanczos algorithm is guaranteed to terminate in at most $n$ steps. We have shown it terminates in one step in this case.\n\nTherefore, the only correct statement is B.", "answer": "$$\\boxed{B}$$", "id": "1371167"}, {"introduction": "Beyond basic execution, the true power of the Lanczos algorithm lies in its elegant mathematical properties. This problem [@problem_id:1371119] investigates how the algorithm behaves under a spectral shift, where we analyze the matrix $A - \\sigma I$ instead of $A$. Uncovering this relationship is not just a theoretical curiosity; it is the cornerstone of powerful techniques like the shift-and-invert method, used to accelerate convergence to eigenvalues near a specific value $\\sigma$.", "problem": "The Lanczos algorithm is an iterative method used to find eigenvalues and eigenvectors of a large symmetric matrix. For a given real symmetric $n \\times n$ matrix $A$ and a starting vector $v_1$ with $\\|v_1\\|_2 = 1$, the algorithm generates a sequence of orthonormal vectors $q_1, q_2, \\dots, q_k$ (where $q_1 = v_1$) that form a basis for a Krylov subspace. These vectors satisfy the three-term recurrence relation:\n$$A q_j = \\beta_{j-1} q_{j-1} + \\alpha_j q_j + \\beta_j q_{j+1}$$\nfor $j=1, \\dots, k$, with $q_0 = 0$ and $\\beta_0 = 0$. The coefficients $\\alpha_j = q_j^T A q_j$ form the diagonal entries and $\\beta_j = \\| A q_j - \\alpha_j q_j - \\beta_{j-1} q_{j-1} \\|_2$ form the off-diagonal entries of a $k \\times k$ symmetric tridiagonal matrix $T_k$.\n\nNow, consider a spectral transformation of the matrix $A$ by a real constant shift $\\sigma$, resulting in a new matrix $A' = A - \\sigma I_n$, where $I_n$ is the $n \\times n$ identity matrix. Suppose we apply the same Lanczos algorithm for $k$ steps to the matrix $A'$, using the exact same starting vector $v_1$. This new process generates a new $k \\times k$ symmetric tridiagonal matrix, which we will call $T'_k$.\n\nDetermine the relationship between $T'_k$ and $T_k$. Express your answer for $T'_k$ in terms of $T_k$, the shift $\\sigma$, and the $k \\times k$ identity matrix $I_k$.", "solution": "We are given a real symmetric matrix $A \\in \\mathbb{R}^{n \\times n}$ and the Lanczos process started from $q_{1}=v_{1}$ with $\\|v_{1}\\|_{2}=1$, generating orthonormal vectors $q_{j}$ satisfying the three-term recurrence\n$$\nA q_{j}=\\beta_{j-1} q_{j-1}+\\alpha_{j} q_{j}+\\beta_{j} q_{j+1}, \\quad j=1,\\dots,k,\n$$\nwith $q_{0}=0$ and $\\beta_{0}=0$. The tridiagonal matrix $T_{k}$ has diagonal entries $\\alpha_{j}=q_{j}^{T} A q_{j}$ and off-diagonal entries $\\beta_{j}=\\|A q_{j}-\\alpha_{j} q_{j}-\\beta_{j-1} q_{j-1}\\|_{2}$.\n\nConsider the shifted matrix $A'=A-\\sigma I_{n}$ with the same starting vector $v_{1}$. First, the Krylov subspaces coincide:\n$$\n\\mathcal{K}_{m}(A,v_{1})=\\operatorname{span}\\{v_{1},A v_{1},\\dots,A^{m-1} v_{1}\\}=\\mathcal{K}_{m}(A',v_{1}),\n$$\nbecause, for each $m \\in \\mathbb{N}$,\n$$\n(A-\\sigma I_{n})^{m} v_{1}=\\sum_{r=0}^{m} \\binom{m}{r} (-\\sigma)^{m-r} A^{r} v_{1},\n$$\nshowing each $(A')^{m} v_{1}$ lies in $\\mathcal{K}_{m+1}(A,v_{1})$, and conversely $A^{m} v_{1}$ is a linear combination of $\\{(A')^{r} v_{1}\\}_{r=0}^{m}$ by the same argument. Hence, applying Lanczos with $A'$ and $v_{1}$ produces an orthonormal basis that must lie in the same subspaces at each step.\n\nWe now show by induction that the Lanczos vectors and off-diagonal coefficients are unchanged, while the diagonal coefficients are shifted by $-\\sigma$.\n\nDefine for $A$ the residuals $r_{j}=A q_{j}-\\alpha_{j} q_{j}-\\beta_{j-1} q_{j-1}$ so that $\\beta_{j}=\\|r_{j}\\|_{2}$ and $q_{j+1}=r_{j}/\\beta_{j}$. For $A'$, define $\\alpha'_{j}=q_{j}^{T} A' q_{j}$, $\\beta'_{j}=\\|A' q_{j}-\\alpha'_{j} q_{j}-\\beta'_{j-1} q_{j-1}\\|_{2}$, and $r'_{j}=A' q_{j}-\\alpha'_{j} q_{j}-\\beta'_{j-1} q_{j-1}$.\n\nBase step $j=1$: Since $q_{1}$ is unit-norm, \n$$\n\\alpha'_{1}=q_{1}^{T} A' q_{1}=q_{1}^{T} (A-\\sigma I_{n}) q_{1}=q_{1}^{T} A q_{1}-\\sigma=\\alpha_{1}-\\sigma.\n$$\nAlso,\n$$\nr'_{1}=A' q_{1}-\\alpha'_{1} q_{1}=A q_{1}-\\sigma q_{1}-(\\alpha_{1}-\\sigma) q_{1}=A q_{1}-\\alpha_{1} q_{1}=r_{1},\n$$\nso $\\beta'_{1}=\\|r'_{1}\\|_{2}=\\|r_{1}\\|_{2}=\\beta_{1}$ and $q_{2}'=r'_{1}/\\beta'_{1}=r_{1}/\\beta_{1}=q_{2}$.\n\nInductive step: Assume for some $j \\geq 2$ that $q_{j-1}$ and $q_{j}$ are the same for $A$ and $A'$, and that $\\beta'_{j-1}=\\beta_{j-1}$. Then\n$$\n\\alpha'_{j}=q_{j}^{T} A' q_{j}=q_{j}^{T} (A-\\sigma I_{n}) q_{j}=q_{j}^{T} A q_{j}-\\sigma=\\alpha_{j}-\\sigma,\n$$\nand\n$$\n\\begin{aligned}\nr'_{j}=A' q_{j}-\\alpha'_{j} q_{j}-\\beta'_{j-1} q_{j-1}\\\\\n=(A-\\sigma I_{n}) q_{j}-(\\alpha_{j}-\\sigma) q_{j}-\\beta_{j-1} q_{j-1}\\\\\n=A q_{j}-\\alpha_{j} q_{j}-\\beta_{j-1} q_{j-1}=r_{j}.\n\\end{aligned}\n$$\nHence $\\beta'_{j}=\\|r'_{j}\\|_{2}=\\|r_{j}\\|_{2}=\\beta_{j}$ and $q'_{j+1}=r'_{j}/\\beta'_{j}=r_{j}/\\beta_{j}=q_{j+1}$. This completes the induction.\n\nTherefore, the Lanczos basis $q_{1},\\dots,q_{k}$ and off-diagonal entries $\\beta_{j}$ are unchanged, while the diagonal entries are shifted: $\\alpha'_{j}=\\alpha_{j}-\\sigma$. Consequently, the tridiagonal matrices satisfy\n$$\nT'_{k}=T_{k}-\\sigma I_{k}.\n$$\n\nAn equivalent compact derivation uses the Lanczos decomposition $A Q_{k}=Q_{k} T_{k}+\\beta_{k} q_{k+1} e_{k}^{T}$ where $Q_{k}=[q_{1} \\dots q_{k}]$. Then\n$$\nA' Q_{k}=(A-\\sigma I_{n}) Q_{k}=A Q_{k}-\\sigma Q_{k}=Q_{k} (T_{k}-\\sigma I_{k})+\\beta_{k} q_{k+1} e_{k}^{T}.\n$$\nBy uniqueness of the tridiagonal projection in the Lanczos relation for $A'$, this confirms $T'_{k}=T_{k}-\\sigma I_{k}$.", "answer": "$$\\boxed{T'_{k}=T_{k}-\\sigma I_{k}}$$", "id": "1371119"}]}