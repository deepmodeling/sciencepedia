{"hands_on_practices": [{"introduction": "This first exercise provides foundational practice in working with coordinate vectors. We will see how linear operations on abstract vectors, in this case, $2 \\times 2$ matrices, are simplified into straightforward arithmetic in the space of coordinate vectors. This practice [@problem_id:1393924] reinforces the fundamental principle that the coordinate mapping is a linear transformation, allowing us to compute the coordinates of $u-v$ simply by subtracting the coordinate vectors of $u$ and $v$.", "problem": "Let $M_{2 \\times 2}$ be the vector space of all $2 \\times 2$ matrices with real entries. Consider the ordered basis $B = \\{B_1, B_2, B_3, B_4\\}$ for $M_{2 \\times 2}$, where\n$$\nB_1 = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\quad B_2 = \\begin{pmatrix} 0  1 \\\\ 1  0 \\end{pmatrix}, \\quad B_3 = \\begin{pmatrix} 1  1 \\\\ 0  0 \\end{pmatrix}, \\quad B_4 = \\begin{pmatrix} 0  0 \\\\ 1  -1 \\end{pmatrix}\n$$\nTwo vectors, $u$ and $v$, in $M_{2 \\times 2}$ have coordinate vectors with respect to the basis $B$ given by\n$$\n[u]_B = \\begin{pmatrix} 2 \\\\ -1 \\\\ 3 \\\\ 1 \\end{pmatrix} \\quad \\text{and} \\quad [v]_B = \\begin{pmatrix} 1 \\\\ 4 \\\\ -1 \\\\ -2 \\end{pmatrix}\n$$\nFind the matrix $u - v$.", "solution": "In a finite-dimensional vector space with ordered basis $B=\\{B_{1},B_{2},B_{3},B_{4}\\}$, a vector $x$ with coordinate vector $[x]_{B}=\\begin{pmatrix}c_{1}\\\\c_{2}\\\\c_{3}\\\\c_{4}\\end{pmatrix}$ is expressed as\n$$\nx=c_{1}B_{1}+c_{2}B_{2}+c_{3}B_{3}+c_{4}B_{4}.\n$$\nGiven\n$$\n[u]_{B}=\\begin{pmatrix}2\\\\-1\\\\3\\\\1\\end{pmatrix},\\qquad [v]_{B}=\\begin{pmatrix}1\\\\4\\\\-1\\\\-2\\end{pmatrix},\n$$\nthe coordinate vector of $u-v$ with respect to $B$ is\n$$\n[u-v]_{B}=[u]_{B}-[v]_{B}=\\begin{pmatrix}2\\\\-1\\\\3\\\\1\\end{pmatrix}-\\begin{pmatrix}1\\\\4\\\\-1\\\\-2\\end{pmatrix}=\\begin{pmatrix}1\\\\-5\\\\4\\\\3\\end{pmatrix}.\n$$\nTherefore,\n$$\nu-v=1\\cdot B_{1}+(-5)\\cdot B_{2}+4\\cdot B_{3}+3\\cdot B_{4}.\n$$\nUsing\n$$\nB_{1}=\\begin{pmatrix}10\\\\01\\end{pmatrix},\\quad\nB_{2}=\\begin{pmatrix}01\\\\10\\end{pmatrix},\\quad\nB_{3}=\\begin{pmatrix}11\\\\00\\end{pmatrix},\\quad\nB_{4}=\\begin{pmatrix}00\\\\1-1\\end{pmatrix},\n$$\ncompute each scaled matrix:\n$$\n1\\cdot B_{1}=\\begin{pmatrix}10\\\\01\\end{pmatrix},\\quad\n-5\\cdot B_{2}=\\begin{pmatrix}0-5\\\\-50\\end{pmatrix},\\quad\n4\\cdot B_{3}=\\begin{pmatrix}44\\\\00\\end{pmatrix},\\quad\n3\\cdot B_{4}=\\begin{pmatrix}00\\\\3-3\\end{pmatrix}.\n$$\nSumming these gives\n$$\nu-v=\\begin{pmatrix}10\\\\01\\end{pmatrix}+\\begin{pmatrix}0-5\\\\-50\\end{pmatrix}+\\begin{pmatrix}44\\\\00\\end{pmatrix}+\\begin{pmatrix}00\\\\3-3\\end{pmatrix}\n=\\begin{pmatrix}5-1\\\\-2-2\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}5  -1 \\\\ -2  -2\\end{pmatrix}}$$", "id": "1393924"}, {"introduction": "A coordinate system relies on a basis, which must be a linearly independent set of vectors. This practice [@problem_id:1393933] explores what happens when we relax this requirement and use a spanning set that is linearly dependent. You will discover that the coordinate representation of a vector is no longer unique and instead forms a set of solutions, which you will describe parametrically, reinforcing the deep connection between coordinate mappings and the structure of solutions to linear systems.", "problem": "Consider the vector space $\\mathbb{R}^3$. Let $S$ be a set of four vectors given by\n$$S = \\{\\mathbf{s}_1, \\mathbf{s}_2, \\mathbf{s}_3, \\mathbf{s}_4\\}$$\nwhere\n$$ \\mathbf{s}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{s}_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}, \\quad \\mathbf{s}_3 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{s}_4 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$\nThis set $S$ is a spanning set for $\\mathbb{R}^3$. A coordinate vector of a vector $\\mathbf{x} \\in \\mathbb{R}^3$ relative to $S$, denoted $[\\mathbf{x}]_S$, is any vector of coefficients $\\mathbf{c} = \\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\end{pmatrix}$ in $\\mathbb{R}^4$ such that $\\mathbf{x} = c_1\\mathbf{s}_1 + c_2\\mathbf{s}_2 + c_3\\mathbf{s}_3 + c_4\\mathbf{s}_4$.\n\nLet the vector $\\mathbf{x}$ be given by $\\mathbf{x} = \\begin{pmatrix} 5 \\\\ 3 \\\\ 2 \\end{pmatrix}$. Since the spanning set $S$ is linearly dependent, there is more than one possible coordinate vector $[\\mathbf{x}]_S$.\n\nDetermine the complete set of all possible coordinate vectors $[\\mathbf{x}]_S$. Your answer should be a parametric vector expression representing this set, using a parameter $t$.", "solution": "The problem asks for the set of all coefficient vectors $\\mathbf{c} = \\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\end{pmatrix}$ that satisfy the vector equation $\\mathbf{x} = c_1\\mathbf{s}_1 + c_2\\mathbf{s}_2 + c_3\\mathbf{s}_3 + c_4\\mathbf{s}_4$.\n\nWe can write this vector equation as a system of linear equations. Substituting the given vectors:\n$$ \\begin{pmatrix} 5 \\\\ 3 \\\\ 2 \\end{pmatrix} = c_1 \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + c_2 \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} + c_3 \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} + c_4 \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} $$\nThis can be expressed in matrix form $A\\mathbf{c} = \\mathbf{x}$, where $A$ is the matrix whose columns are the vectors in $S$:\n$$ \\begin{pmatrix} 1  0  1  1 \\\\ 0  1  1  1 \\\\ 0  1  0  1 \\end{pmatrix} \\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\end{pmatrix} = \\begin{pmatrix} 5 \\\\ 3 \\\\ 2 \\end{pmatrix} $$\nTo find all possible solutions for $\\mathbf{c}$, we solve this system by row reducing the augmented matrix $[A|\\mathbf{x}]$:\n$$ \\left[ \\begin{array}{cccc|c} 1  0  1  1  5 \\\\ 0  1  1  1  3 \\\\ 0  1  0  1  2 \\end{array} \\right] $$\nFirst, we apply the row operation $R_3 \\leftarrow R_3 - R_2$:\n$$ \\left[ \\begin{array}{cccc|c} 1  0  1  1  5 \\\\ 0  1  1  1  3 \\\\ 0  0  -1  0  -1 \\end{array} \\right] $$\nNext, we multiply the third row by $-1$ ($R_3 \\leftarrow -R_3$) to make the pivot 1:\n$$ \\left[ \\begin{array}{cccc|c} 1  0  1  1  5 \\\\ 0  1  1  1  3 \\\\ 0  0  1  0  1 \\end{array} \\right] $$\nNow we eliminate the entries above the pivot in the third column. We perform $R_1 \\leftarrow R_1 - R_3$ and $R_2 \\leftarrow R_2 - R_3$:\n$$ \\left[ \\begin{array}{cccc|c} 1  0  0  1  4 \\\\ 0  1  0  1  2 \\\\ 0  0  1  0  1 \\end{array} \\right] $$\nThis is the reduced row echelon form (RREF) of the augmented matrix. The leading 1's (pivots) are in columns 1, 2, and 3, corresponding to variables $c_1, c_2, c_3$. Column 4 has no pivot, so $c_4$ is a free variable.\n\nWe can express the system of equations from the RREF:\n$$ c_1 + c_4 = 4 $$\n$$ c_2 + c_4 = 2 $$\n$$ c_3 = 1 $$\nLet the free variable $c_4$ be represented by the parameter $t$, so $c_4 = t$. We can now express the other variables in terms of $t$:\n$$ c_1 = 4 - c_4 = 4 - t $$\n$$ c_2 = 2 - c_4 = 2 - t $$\n$$ c_3 = 1 $$\n$$ c_4 = t $$\nThe solution set is the set of all vectors $\\mathbf{c}$ of the form:\n$$ \\mathbf{c} = \\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\\\ c_4 \\end{pmatrix} = \\begin{pmatrix} 4 - t \\\\ 2 - t \\\\ 1 \\\\ t \\end{pmatrix} $$\nThis can be written in parametric vector form by separating the constant terms and the terms involving $t$:\n$$ \\mathbf{c} = \\begin{pmatrix} 4 \\\\ 2 \\\\ 1 \\\\ 0 \\end{pmatrix} + t \\begin{pmatrix} -1 \\\\ -1 \\\\ 0 \\\\ 1 \\end{pmatrix} $$\nThis expression represents a line in $\\mathbb{R}^4$ and describes the complete set of all possible coordinate vectors $[\\mathbf{x}]_S$.", "answer": "$$\\boxed{\\begin{pmatrix} 4 \\\\ 2 \\\\ 1 \\\\ 0 \\end{pmatrix} + t \\begin{pmatrix} -1 \\\\ -1 \\\\ 0 \\\\ 1 \\end{pmatrix}}$$", "id": "1393933"}, {"introduction": "The true power of coordinate mappings is revealed when a clever choice of basis simplifies a complex problem. This problem [@problem_id:1393951] shifts our focus to the vector space of polynomials and introduces the Lagrange basis, a basis specifically constructed for polynomial interpolation. By working through this exercise, you will see how finding a polynomial that passes through a set of points becomes as simple as reading the coordinates, beautifully illustrating how an abstract change of perspective can lead to profound simplification.", "problem": "Let $P_2$ be the vector space of all polynomials of degree at most 2 with real coefficients. Consider three distinct real numbers $x_0$, $x_1$, and $x_2$. A unique polynomial $p(t) \\in P_2$ is defined by the property that it passes through three specific points: $p(x_0) = y_0$, $p(x_1) = y_1$, and $p(x_2) = y_2$, where $y_0, y_1, y_2$ are given real values.\n\nA special basis for $P_2$, known as the Lagrange basis associated with the points $x_0, x_1, x_2$, is given by the set $B = \\{L_0(t), L_1(t), L_2(t)\\}$, where the basis polynomials are defined as:\n$$L_0(t) = \\frac{(t-x_1)(t-x_2)}{(x_0-x_1)(x_0-x_2)}$$\n$$L_1(t) = \\frac{(t-x_0)(t-x_2)}{(x_1-x_0)(x_1-x_2)}$$\n$$L_2(t) = \\frac{(t-x_0)(t-x_1)}{(x_2-x_0)(x_2-x_1)}$$\n\nAny polynomial in $P_2$, including $p(t)$, can be uniquely written as a linear combination of these basis vectors. The coordinate vector of $p(t)$ relative to the basis $B$, denoted $[p(t)]_B$, is the vector of coefficients $(c_0, c_1, c_2)$ such that $p(t) = c_0 L_0(t) + c_1 L_1(t) + c_2 L_2(t)$.\n\nDetermine the coordinate vector $[p(t)]_B$. Express your answer as a $1 \\times 3$ row matrix in terms of $y_0, y_1$, and $y_2$.", "solution": "We are given the Lagrange basis $B=\\{L_{0}(t),L_{1}(t),L_{2}(t)\\}$ where, for distinct $x_{0},x_{1},x_{2}$,\n$$\nL_{0}(t)=\\frac{(t-x_{1})(t-x_{2})}{(x_{0}-x_{1})(x_{0}-x_{2})},\\quad\nL_{1}(t)=\\frac{(t-x_{0})(t-x_{2})}{(x_{1}-x_{0})(x_{1}-x_{2})},\\quad\nL_{2}(t)=\\frac{(t-x_{0})(t-x_{1})}{(x_{2}-x_{0})(x_{2}-x_{1})}.\n$$\nBy construction of the Lagrange polynomials, they satisfy the Kronecker delta property\n$$\nL_{i}(x_{j})=\\delta_{ij}=\\begin{cases}1, i=j,\\\\ 0, i\\neq j.\\end{cases}\n$$\nLet $p(t)\\in P_{2}$ be such that $p(x_{0})=y_{0}$, $p(x_{1})=y_{1}$, and $p(x_{2})=y_{2}$. Express $p(t)$ in the basis $B$ as\n$$\np(t)=c_{0}L_{0}(t)+c_{1}L_{1}(t)+c_{2}L_{2}(t).\n$$\nEvaluate at $t=x_{0}$ and use $L_{0}(x_{0})=1$, $L_{1}(x_{0})=0$, $L_{2}(x_{0})=0$ to obtain\n$$\np(x_{0})=c_{0}L_{0}(x_{0})+c_{1}L_{1}(x_{0})+c_{2}L_{2}(x_{0})=c_{0}=y_{0}.\n$$\nSimilarly, evaluate at $t=x_{1}$ and $t=x_{2}$ to get\n$$\np(x_{1})=c_{1}=y_{1},\\qquad p(x_{2})=c_{2}=y_{2}.\n$$\nTherefore the coordinate vector relative to $B$ is\n$$\n[p(t)]_{B}=(y_{0},y_{1},y_{2}),\n$$\nwhich as a $1\\times 3$ row matrix is\n$$\n\\begin{pmatrix}\ny_{0}  y_{1}  y_{2}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} y_{0}  y_{1}  y_{2} \\end{pmatrix}}$$", "id": "1393951"}]}