{"hands_on_practices": [{"introduction": "Understanding a concept from multiple angles is key to mastery. Instead of just finding the subspaces from a given matrix, this exercise challenges you to work in reverse: to construct a matrix based on specific requirements for its column space, $C(A)$, and null space, $N(A)$. This practice [@problem_id:1394599] solidifies the fundamental definitions by requiring you to translate abstract properties into concrete matrix entries. Engaging with this problem will build a stronger intuition for how these crucial subspaces dictate the very structure of a matrix.", "problem": "Let $A$ be a $3 \\times 2$ matrix with real entries. The column space of $A$, denoted $C(A)$, is the set of all vectors that can be written as a linear combination of the columns of $A$. The null space of $A$, denoted $N(A)$, is the set of all vectors $\\mathbf{x}$ such that $A\\mathbf{x} = \\mathbf{0}$.\n\nConsider a matrix $A$ that satisfies the following three conditions:\n1. The vector $\\mathbf{v} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$ is an element of the column space $C(A)$.\n2. The vector $\\mathbf{w} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$ is an element of the null space $N(A)$.\n3. The entry in the first row and first column of $A$ is equal to 3.\n\nWhich of the following matrices is the matrix $A$?\n\nA. $\\begin{pmatrix} 3 & 6 \\\\ 3 & 6 \\\\ 3 & 6 \\end{pmatrix}$\n\nB. $\\begin{pmatrix} 3 & 0 \\\\ 3 & 1 \\\\ 3 & 0 \\end{pmatrix}$\n\nC. $\\begin{pmatrix} 3 & 1.5 \\\\ 3 & 1.5 \\\\ 3 & 1.5 \\end{pmatrix}$\n\nD. $\\begin{pmatrix} 3 & -6 \\\\ 3 & -6 \\\\ 3 & -6 \\end{pmatrix}$\n\nE. $\\begin{pmatrix} 3 & 6 \\\\ 0 & 0 \\\\ 0 & 0 \\end{pmatrix}$", "solution": "Let the matrix $A$ be represented by its two columns, $\\mathbf{a}_1$ and $\\mathbf{a}_2$, which are vectors in $\\mathbb{R}^3$.\n$$ A = \\begin{pmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 \\end{pmatrix} = \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\\\ a_{31} & a_{32} \\end{pmatrix} $$\nWe are given three conditions to determine the entries of $A$.\n\nFirst, let's analyze the second condition: the vector $\\mathbf{w} = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$ is in the null space of $A$. By definition of the null space, this means that $A\\mathbf{w} = \\mathbf{0}$.\n$$ A\\mathbf{w} = \\begin{pmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix} = 2\\mathbf{a}_1 - 1\\mathbf{a}_2 = \\mathbf{0} $$\nThis equation gives us a relationship between the two columns of the matrix $A$:\n$$ \\mathbf{a}_2 = 2\\mathbf{a}_1 $$\nThis implies that the second column of $A$ is exactly twice the first column. Therefore, the matrix $A$ must have the form:\n$$ A = \\begin{pmatrix} a_{11} & 2a_{11} \\\\ a_{21} & 2a_{21} \\\\ a_{31} & 2a_{31} \\end{pmatrix} $$\n\nNext, let's use the first condition: the vector $\\mathbf{v} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$ is in the column space of $A$. The column space $C(A)$ is the span of the columns of $A$. Since $\\mathbf{a}_2 = 2\\mathbf{a}_1$, the columns are linearly dependent, and the column space is simply the span of the first column:\n$$ C(A) = \\text{span}(\\mathbf{a}_1, \\mathbf{a}_2) = \\text{span}(\\mathbf{a}_1, 2\\mathbf{a}_1) = \\text{span}(\\mathbf{a}_1) $$\nFor $\\mathbf{v}$ to be in $C(A)$, it must be a scalar multiple of $\\mathbf{a}_1$. So, there exists a non-zero scalar $k$ such that $\\mathbf{a}_1 = k\\mathbf{v}$.\n$$ \\mathbf{a}_1 = \\begin{pmatrix} a_{11} \\\\ a_{21} \\\\ a_{31} \\end{pmatrix} = k \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} k \\\\ k \\\\ k \\end{pmatrix} $$\n\nNow, let's apply the third condition: the entry in the first row and first column, $a_{11}$, is 3. From the previous step, we have $a_{11} = k$. Therefore, we must have $k=3$.\nThis completely determines the first column $\\mathbf{a}_1$:\n$$ \\mathbf{a}_1 = \\begin{pmatrix} 3 \\\\ 3 \\\\ 3 \\end{pmatrix} $$\n\nFinally, we can find the second column $\\mathbf{a}_2$ using the relationship derived from the null space condition, $\\mathbf{a}_2 = 2\\mathbf{a}_1$:\n$$ \\mathbf{a}_2 = 2 \\begin{pmatrix} 3 \\\\ 3 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 6 \\\\ 6 \\\\ 6 \\end{pmatrix} $$\n\nCombining the two columns gives the matrix $A$:\n$$ A = \\begin{pmatrix} \\mathbf{a}_1 & \\mathbf{a}_2 \\end{pmatrix} = \\begin{pmatrix} 3 & 6 \\\\ 3 & 6 \\\\ 3 & 6 \\end{pmatrix} $$\nComparing our result with the given choices, we find that it matches option A.", "answer": "$$\\boxed{A}$$", "id": "1394599"}, {"introduction": "After building a conceptual foundation, it is crucial to master the core computational techniques. This problem focuses on the fundamental algorithm for dissecting any matrix to reveal its underlying structure. You will apply the method of Gaussian elimination to a given matrix $A$ to systematically find explicit bases for all four fundamental subspaces: the column space $C(A)$, the null space $N(A)$, the row space $C(A^T)$, and the left null space $N(A^T)$ [@problem_id:2436007]. This procedure is a cornerstone of linear algebra, providing the essential toolkit for analyzing linear systems and understanding the properties of a linear transformation.", "problem": "Consider the matrix $A \\in \\mathbb{R}^{4 \\times 3}$ given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1 & 2 & 3 \\\\\n0 & 1 & 1 \\\\\n1 & 3 & 4 \\\\\n2 & 5 & 7\n\\end{pmatrix}.\n$$\nUsing only the definitions of span and solution sets of homogeneous linear systems, determine bases for each of the four fundamental subspaces of $A$: the column space $C(A)$, the null space $N(A)$, the row space $C(A^{T})$, and the left null space $N(A^{T})$. Finally, report the rank of $A$ as your final answer. Express the final answer as an integer with no units. No rounding is required.", "solution": "First, we validate the problem statement.\n\nThe givens are:\n1.  A matrix $A \\in \\mathbb{R}^{4 \\times 3}$:\n    $$\n    A \\;=\\;\n    \\begin{pmatrix}\n    1 & 2 & 3 \\\\\n    0 & 1 & 1 \\\\\n    1 & 3 & 4 \\\\\n    2 & 5 & 7\n    \\end{pmatrix}.\n    $$\n2.  A directive to find bases for the four fundamental subspaces: the column space $C(A)$, the null space $N(A)$, the row space $C(A^T)$, and the left null space $N(A^T)$.\n3.  A methodological constraint: \"Using only the definitions of span and solution sets of homogeneous linear systems\".\n4.  A requirement to report the rank of $A$ as the final answer.\n\nThe problem is scientifically grounded, well-posed, and objective. It is a standard exercise in linear algebra, with all required information provided and no contradictions. The methodological constraint is a directive on the reasoning process, not a flaw. The problem is valid. We proceed to the solution.\n\nThe four fundamental subspaces are defined as follows:\n-   The row space, $C(A^T)$, is the subspace of $\\mathbb{R}^3$ spanned by the rows of $A$.\n-   The null space, $N(A)$, is the set of all vectors $\\mathbf{x} \\in \\mathbb{R}^3$ that are solutions to the homogeneous linear system $A\\mathbf{x} = \\mathbf{0}$.\n-   The column space, $C(A)$, is the subspace of $\\mathbb{R}^4$ spanned by the columns of $A$.\n-   The left null space, $N(A^T)$, is the set of all vectors $\\mathbf{y} \\in \\mathbb{R}^4$ that are solutions to the homogeneous linear system $A^T\\mathbf{y} = \\mathbf{0}$.\n\nTo find these subspaces, we will perform row reduction on the matrix $A$. The fundamental theorem of linear algebra states that elementary row operations do not alter the row space or the null space. We will find the reduced row echelon form (RREF) of $A$. To simultaneously find a basis for the left null space, we augment $A$ with the $4 \\times 4$ identity matrix $I$ and perform row reduction on $[A | I]$ to obtain $[R | E]$, where $R$ is the RREF of $A$ and $E$ is the matrix that records the row operations, such that $EA = R$.\n\nThe augmented matrix is:\n$$\n[A|I] = \\left(\\begin{array}{ccc|cccc}\n1 & 2 & 3 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n1 & 3 & 4 & 0 & 0 & 1 & 0 \\\\\n2 & 5 & 7 & 0 & 0 & 0 & 1\n\\end{array}\\right)\n$$\nWe perform Gauss-Jordan elimination:\n1.  $R_3 \\leftarrow R_3 - R_1$\n2.  $R_4 \\leftarrow R_4 - 2R_1$\n$$\n\\left(\\begin{array}{ccc|cccc}\n1 & 2 & 3 & 1 & 0 & 0 & 0 \\\\\n0 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n0 & 1 & 1 & -1 & 0 & 1 & 0 \\\\\n0 & 1 & 1 & -2 & 0 & 0 & 1\n\\end{array}\\right)\n$$\n3.  $R_1 \\leftarrow R_1 - 2R_2$\n4.  $R_3 \\leftarrow R_3 - R_2$\n5.  $R_4 \\leftarrow R_4 - R_2$\n$$\n[R|E] = \\left(\\begin{array}{ccc|cccc}\n1 & 0 & 1 & 1 & -2 & 0 & 0 \\\\\n0 & 1 & 1 & 0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & -1 & -1 & 1 & 0 \\\\\n0 & 0 & 0 & -2 & -1 & 0 & 1\n\\end{array}\\right)\n$$\nThe reduced row echelon form of $A$ is\n$$\nR \\;=\\;\n\\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n0 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{pmatrix}.\n$$\n\n**1. Basis for the Row Space, $C(A^T)$**\nThe row space is defined as the span of the rows of $A$. Row operations consist of taking linear combinations of rows. Thus, the rows of $R$ are linear combinations of the rows of $A$, so $C(R^T) \\subseteq C(A^T)$. Since row operations are reversible, the rows of $A$ are also linear combinations of the rows of $R$, implying $C(A^T) \\subseteq C(R^T)$. Therefore, $C(A^T) = C(R^T)$.\nA basis for $C(R^T)$ is the set of its non-zero rows. These are linearly independent due to the echelon structure: each leading $1$ (pivot) is in a column where all other rows have a $0$.\nThe non-zero rows of $R$ are $(1, 0, 1)$ and $(0, 1, 1)$.\nThus, a basis for $C(A^T)$ is $\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} \\right\\}$.\nThe dimension of the row space, which is the rank of $A$, is $2$.\n\n**2. Basis for the Null Space, $N(A)$**\nThe null space is the solution set of $A\\mathbf{x} = \\mathbf{0}$. This system is equivalent to $R\\mathbf{x} = \\mathbf{0}$, which is:\n$$\n\\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1 \\\\\n0 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{pmatrix}\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}\n=\n\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis gives the equations $x_1 + x_3 = 0$ and $x_2 + x_3 = 0$. The pivot variables are $x_1$ and $x_2$. The free variable is $x_3$. Let $x_3 = t$ for any scalar $t$. Then $x_1 = -t$ and $x_2 = -t$.\nThe solution vector is $\\mathbf{x} = \\begin{pmatrix} -t \\\\ -t \\\\ t \\end{pmatrix} = t \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\end{pmatrix}$.\nBy definition, the null space is the span of the vector that multiplies the free parameter. Since there is only one such vector, it is linearly independent by itself.\nThus, a basis for $N(A)$ is $\\left\\{ \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\end{pmatrix} \\right\\}$.\n\n**3. Basis for the Column Space, $C(A)$**\nThe column space is the span of the columns of $A$. The dependency relations among the columns of $A$ are the same as those among the columns of $R$. The equation $A\\mathbf{x}=\\mathbf{0}$ describes these relations.\nFrom $R$, we see that the pivot columns are columns $1$ and $2$. The third column is a linear combination of the pivot columns: $R_{col3} = 1 \\cdot R_{col1} + 1 \\cdot R_{col2}$.\nThis implies the same relationship for the columns of $A$, $c_1, c_2, c_3$: $c_3 = 1 \\cdot c_1 + 1 \\cdot c_2$.\nThis means the set $\\{c_1, c_2, c_3\\}$ is linearly dependent and $\\text{span}\\{c_1, c_2, c_3\\} = \\text{span}\\{c_1, c_2\\}$.\nThe pivot columns of $A$, which are $c_1$ and $c_2$, are linearly independent because the corresponding columns in $R$ are linearly independent.\nThus, a basis for $C(A)$ is the set of pivot columns of $A$.\nA basis for $C(A)$ is $\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 2 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 1 \\\\ 3 \\\\ 5 \\end{pmatrix} \\right\\}$.\n\n**4. Basis for the Left Null Space, $N(A^T)$**\nThe left null space is the solution set of $A^T\\mathbf{y} = \\mathbf{0}$, which is equivalent to $\\mathbf{y}^T A = \\mathbf{0}^T$. We are looking for linear combinations of the rows of $A$ that produce the zero vector.\nThe matrix $E$ from our augmented reduction $[A|I] \\to [R|E]$ is such that $EA=R$. The rows of $E$, let's call them $e_i^T$, when multiplied by $A$, produce the rows of $R$.\nThe last two rows of $R$ are zero rows. This means that the last two rows of $E$, which are $e_3^T = \\begin{pmatrix} -1 & -1 & 1 & 0 \\end{pmatrix}$ and $e_4^T = \\begin{pmatrix} -2 & -1 & 0 & 1 \\end{pmatrix}$, satisfy $e_3^T A = \\mathbf{0}^T$ and $e_4^T A = \\mathbf{0}^T$.\nTherefore, the vectors $\\mathbf{y}_1 = \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{y}_2 = \\begin{pmatrix} -2 \\\\ -1 \\\\ 0 \\\\ 1 \\end{pmatrix}$ are in $N(A^T)$.\nThese vectors are linearly independent. To see this, suppose $k_1 \\mathbf{y}_1 + k_2 \\mathbf{y}_2 = \\mathbf{0}$. This gives $k_1=0$ from the third component and $k_2=0$ from the fourth component.\nThe dimension of the left null space must be $m - r = 4 - 2 = 2$. Since we have found two linearly independent vectors in $N(A^T)$, they form a basis.\nThus, a basis for $N(A^T)$ is $\\left\\{ \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} -2 \\\\ -1 \\\\ 0 \\\\ 1 \\end{pmatrix} \\right\\}$.\n\n**Rank of A**\nThe rank of a matrix is defined as the dimension of its column space, which is equal to the dimension of its row space. From our analysis of $C(A)$ and $C(A^T)$, we found the dimension of both spaces to be $2$.\nTherefore, the rank of $A$ is $2$.", "answer": "$$\\boxed{2}$$", "id": "2436007"}, {"introduction": "This final practice pushes beyond standard calculations to explore the deeper nature of the four fundamental subspaces. It poses a fascinating question: is the relationship between a matrix and its subspaces unique? You are tasked with constructing a new matrix $B$ that is not a simple scalar multiple of a given matrix $A$, yet shares the exact same four fundamental subspaces [@problem_id:1394588]. Successfully solving this problem reveals a profound insight—that these subspaces define an entire family of matrices, uncovering a more flexible and powerful structural relationship than might be initially apparent.", "problem": "Let a matrix $A \\in \\mathbb{R}^{3 \\times 3}$ be defined as:\n$$ A = \\begin{pmatrix} 1 & 0 & 2 \\\\ 0 & 1 & 3 \\\\ 1 & 1 & 5 \\end{pmatrix} $$\nYour task is to construct a matrix $B \\in \\mathbb{R}^{3 \\times 3}$ that satisfies all of the following conditions simultaneously:\n1.  $B$ has the same four fundamental subspaces as $A$ (column space, row space, null space, and left null space).\n2.  The first column of $B$ is the vector $\\begin{pmatrix} 3 \\\\ 1 \\\\ 4 \\end{pmatrix}$.\n3.  The entry in the second row and second column of $B$ is $5$.\n4.  The entry in the first row and third column of $B$ is $7$.\n\nProvide the complete matrix $B$ as your answer. The entries of the matrix must be in their exact form (e.g., as integers or fractions).", "solution": "Let $A$ have columns $c_{1}=(1,0,1)^{T}$, $c_{2}=(0,1,1)^{T}$, $c_{3}=(2,3,5)^{T}$ with $c_{3}=2c_{1}+3c_{2}$, so $\\operatorname{rank}(A)=2$ and $\\operatorname{Col}(A)=\\operatorname{span}\\{c_{1},c_{2}\\}$. Its rows are $r_{1}=(1,0,2)$, $r_{2}=(0,1,3)$, $r_{3}=(1,1,5)$ with $r_{3}=r_{1}+r_{2}$, so $\\operatorname{Row}(A)=\\operatorname{span}\\{r_{1},r_{2}\\}$.\n\nTo construct $B$ with the same column and row spaces (hence the same null space and left null space, since $\\operatorname{Null}(A)=\\operatorname{Row}(A)^{\\perp}$ and $\\operatorname{LeftNull}(A)=\\operatorname{Col}(A)^{\\perp}$), use the factorization\n$$\nB=U C V^{T},\n$$\nwhere $U=[c_{1}\\;c_{2}]=\\begin{pmatrix}1&0\\\\0&1\\\\1&1\\end{pmatrix}$, $V=[r_{1}^{T}\\;r_{2}^{T}]=\\begin{pmatrix}1&0\\\\0&1\\\\2&3\\end{pmatrix}$, and $C=\\begin{pmatrix}a&b\\\\c&d\\end{pmatrix}$ is any invertible $2\\times 2$ matrix. Then $V^{T}=\\begin{pmatrix}1&0&2\\\\0&1&3\\end{pmatrix}$ and\n$$\nC V^{T}\n=\n\\begin{pmatrix}\na & b & 2a+3b\\\\\nc & d & 2c+3d\n\\end{pmatrix}.\n$$\nMultiplying by $U$ gives\n$$\nB=U(CV^{T})\n=\n\\begin{pmatrix}\na & b & 2a+3b\\\\\nc & d & 2c+3d\\\\\na+c & b+d & 2(a+c)+3(b+d)\n\\end{pmatrix}.\n$$\nImpose the constraints:\n- First column $=(3,1,4)^{T}$ gives $a=3$, $c=1$, and $a+c=4$ (consistent).\n- Entry $(2,2)=5$ gives $d=5$.\n- Entry $(1,3)=7$ gives $2a+3b=7$, hence $2\\cdot 3+3b=7$, so $b=\\frac{1}{3}$.\n\nThus\n$$\nC=\\begin{pmatrix}3 & \\tfrac{1}{3}\\\\ 1 & 5\\end{pmatrix},\n\\quad\n\\det C=3\\cdot 5-1\\cdot \\tfrac{1}{3}=\\tfrac{44}{3}\\neq 0,\n$$\nso $C$ is invertible and $B$ has the same column and row spaces as $A$, hence the same null and left null spaces. The resulting matrix is\n$$\nB=\n\\begin{pmatrix}\n3 & \\tfrac{1}{3} & 7\\\\\n1 & 5 & 17\\\\\n4 & \\tfrac{16}{3} & 24\n\\end{pmatrix}.\n$$\nOne can verify the internal consistency: the third column equals $2$ times the first plus $3$ times the second, and the third row equals the sum of the first two rows, matching the rank-$2$ structure and spaces of $A$.", "answer": "$$\\boxed{\\begin{pmatrix}3 & \\tfrac{1}{3} & 7\\\\ 1 & 5 & 17\\\\ 4 & \\tfrac{16}{3} & 24\\end{pmatrix}}$$", "id": "1394588"}]}