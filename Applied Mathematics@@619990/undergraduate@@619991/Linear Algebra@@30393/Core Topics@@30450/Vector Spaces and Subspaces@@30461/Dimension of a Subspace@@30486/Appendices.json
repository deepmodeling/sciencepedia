{"hands_on_practices": [{"introduction": "The dimension of a subspace fundamentally quantifies its \"size\" or complexity. The most direct method for determining dimension is to find the maximum number of linearly independent vectors within a spanning set. This exercise [@problem_id:1358082] provides a practical scenario where you will apply this core technique, using the rank of a matrix to measure the diversity of a hypothetical 'recommendation subspace' in a music streaming service.", "problem": "In a simplified model for a music streaming service's recommender engine, a user's taste profile is represented as a vector in $\\mathbb{R}^4$. Each component of the vector corresponds to the user's affinity score for a particular music genre: (Classical, Jazz, Pop, Rock). To initialize its recommendation space, the system defines four 'archetype' user profiles, given by the vectors:\n$p_1 = (1, 2, 3, 4)$\n$p_2 = (2, 3, 4, 1)$\n$p_3 = (3, 4, 1, 2)$\n$p_4 = (4, 1, 2, 3)$\nThe set of all possible user profiles that can be generated by forming linear combinations of these four archetypes constitutes the 'initial recommendation subspace'. The diversity of tastes the system can represent is directly measured by the dimension of this subspace. A higher dimension allows for a more varied and nuanced set of recommendations.\nDetermine the dimension of this initial recommendation subspace.", "solution": "The dimension of the subspace spanned by a set of vectors is equal to the number of linearly independent vectors in that set. To find this number, we can form a matrix whose rows are the given vectors and then determine the rank of that matrix. The rank is the number of non-zero rows in the row echelon form of the matrix.\n\nLet the given vectors be $p_1, p_2, p_3, p_4$. We form the matrix $A$ with these vectors as its rows:\n$$ A = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 2 & 3 & 4 & 1 \\\\ 3 & 4 & 1 & 2 \\\\ 4 & 1 & 2 & 3 \\end{pmatrix} $$\nNow, we perform Gaussian elimination to reduce $A$ to its row echelon form.\n\nFirst, we create zeros in the first column below the first row.\nApply the row operations $R_2 \\to R_2 - 2R_1$, $R_3 \\to R_3 - 3R_1$, and $R_4 \\to R_4 - 4R_1$:\n$$ \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 2 - 2(1) & 3 - 2(2) & 4 - 2(3) & 1 - 2(4) \\\\ 3 - 3(1) & 4 - 3(2) & 1 - 3(3) & 2 - 3(4) \\\\ 4 - 4(1) & 1 - 4(2) & 2 - 4(3) & 3 - 4(4) \\end{pmatrix} = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & -1 & -2 & -7 \\\\ 0 & -2 & -8 & -10 \\\\ 0 & -7 & -10 & -13 \\end{pmatrix} $$\nNext, we can simplify the second row by multiplying it by $-1$ to make the pivot positive. Let's call this new matrix $A'$.\n$R_2 \\to -R_2$:\n$$ A' = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 7 \\\\ 0 & -2 & -8 & -10 \\\\ 0 & -7 & -10 & -13 \\end{pmatrix} $$\nNow, we create zeros in the second column below the second row.\nApply the row operations $R_3 \\to R_3 + 2R_2$ and $R_4 \\to R_4 + 7R_2$:\n$$ \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 7 \\\\ 0 & -2+2(1) & -8+2(2) & -10+2(7) \\\\ 0 & -7+7(1) & -10+7(2) & -13+7(7) \\end{pmatrix} = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 7 \\\\ 0 & 0 & -4 & 4 \\\\ 0 & 0 & 4 & 36 \\end{pmatrix} $$\nNext, we create a zero in the third column below the third row. Let's call the current matrix $A''$.\nApply the row operation $R_4 \\to R_4 + R_3$:\n$$ \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 7 \\\\ 0 & 0 & -4 & 4 \\\\ 0 & 0 & 4+(-4) & 36+4 \\end{pmatrix} = \\begin{pmatrix} 1 & 2 & 3 & 4 \\\\ 0 & 1 & 2 & 7 \\\\ 0 & 0 & -4 & 4 \\\\ 0 & 0 & 0 & 40 \\end{pmatrix} $$\nThis matrix is in row echelon form. The leading entries (pivots) are in columns 1, 2, 3, and 4. We can count the number of non-zero rows. There are four non-zero rows:\nRow 1: $(1, 2, 3, 4)$\nRow 2: $(0, 1, 2, 7)$\nRow 3: $(0, 0, -4, 4)$\nRow 4: $(0, 0, 0, 40)$\n\nSince there are four non-zero rows, the rank of the matrix $A$ is 4.\nThe dimension of the subspace spanned by the vectors $p_1, p_2, p_3, p_4$ is equal to the rank of the matrix $A$.\nTherefore, the dimension of the initial recommendation subspace is 4. This implies that the four archetype vectors are linearly independent and span the entire $\\mathbb{R}^4$ space.", "answer": "$$\\boxed{4}$$", "id": "1358082"}, {"introduction": "Subspaces are often defined not by a list of spanning vectors, but by a set of linear constraints that their elements must satisfy. This practice problem [@problem_id:1358129] introduces a subspace of 'balanced' data points in a high-dimensional space. Here, you will use the powerful Rank-Nullity Theorem, which offers an elegant way to find the subspace's dimension by relating it to the dimension of the ambient space and the number of independent constraints.", "problem": "In certain data analysis models, vectors are used to represent states or measurements. Consider a model where data points are represented by vectors in the 5-dimensional real vector space $\\mathbb{R}^5$. A data point is defined as being 'balanced' if the sum of all its components is equal to zero. The collection of all such balanced data points forms a vector subspace of $\\mathbb{R}^5$.\n\nWhat is the dimension of this subspace of balanced data points?", "solution": "Let $V=\\mathbb{R}^{5}$ and define the linear functional $L:V\\to\\mathbb{R}$ by\n$$\nL(x_{1},x_{2},x_{3},x_{4},x_{5})=x_{1}+x_{2}+x_{3}+x_{4}+x_{5}.\n$$\nThe subspace of balanced data points is\n$$\nS=\\{x\\in V:\\ L(x)=0\\}=\\ker L.\n$$\nSince $L$ is linear and not the zero map (for example, $L(e_{1})=1\\neq 0$, where $e_{1}$ is the first standard basis vector), its image is a one-dimensional subspace of $\\mathbb{R}$. Hence\n$$\n\\operatorname{rank}(L)=1.\n$$\nBy the rank-nullity theorem,\n$$\n\\dim(\\ker L)=\\dim(V)-\\operatorname{rank}(L)=5-1=4.\n$$\n\nEquivalently, solving the constraint $x_{1}+x_{2}+x_{3}+x_{4}+x_{5}=0$ for $x_{5}$ gives $x_{5}=-(x_{1}+x_{2}+x_{3}+x_{4})$, so $x_{1},x_{2},x_{3},x_{4}$ are free parameters. A basis is, for instance,\n$$\n\\{e_{1}-e_{5},\\ e_{2}-e_{5},\\ e_{3}-e_{5},\\ e_{4}-e_{5}\\},\n$$\nwhich confirms that the dimension is $4$.", "answer": "$$\\boxed{4}$$", "id": "1358129"}, {"introduction": "The concepts of linear algebra, including dimension, are not confined to the familiar Euclidean space $\\mathbb{R}^n$. This problem [@problem_id:1358123] challenges you to extend your understanding to a vector space of continuous functions. You'll learn that testing for linear dependence in such spaces may rely on tools like trigonometric identities rather than matrix row reduction, highlighting the true generality and power of abstract vector space theory.", "problem": "In the design of a specialized function generator for scientific research, an engineer considers building waveforms through the linear combination of a specific set of functions. The considered functions are elements of the vector space $V = C(\\mathbb{R})$, which consists of all continuous real-valued functions defined on the entire real line.\n\nThe engineer proposes to generate a class of signals that belong to the subspace $W$, which is spanned by the set of functions $S = \\{f_1(x), f_2(x), f_3(x)\\}$, where:\n$f_1(x) = \\sin^2(x)$\n$f_2(x) = \\cos^2(x)$\n$f_3(x) = \\cos(2x)$\n\nTo create the most efficient hardware implementation, the engineer needs to determine the minimum number of unique, fundamental signal generators required to produce any possible signal within the subspace $W$. This minimum number corresponds to the dimension of the subspace $W$.\n\nWhat is the dimension of the subspace $W$?", "solution": "Let $V=C(\\mathbb{R})$ and $W=\\operatorname{span}\\{f_{1},f_{2},f_{3}\\}$ with $f_{1}(x)=\\sin^{2}(x)$, $f_{2}(x)=\\cos^{2}(x)$, $f_{3}(x)=\\cos(2x)$. Use the trigonometric identities\n$$\n\\sin^{2}(x)+\\cos^{2}(x)=1,\\qquad \\cos(2x)=\\cos^{2}(x)-\\sin^{2}(x).\n$$\nFrom these, we obtain\n$$\nf_{1}+f_{2}=1,\\qquad f_{3}=f_{2}-f_{1}.\n$$\nHence $1\\in W$. Moreover, we can solve the linear system for $f_{1}$ and $f_{2}$ in terms of $1$ and $f_{3}$:\n$$\n\\begin{cases}\nf_{2}-f_{1}=f_{3},\\\\\nf_{1}+f_{2}=1,\n\\end{cases}\n\\quad\\Longrightarrow\\quad\n2f_{2}=1+f_{3},\\;\\;2f_{1}=1-f_{3},\n$$\nso\n$$\nf_{2}=\\frac{1+f_{3}}{2},\\qquad f_{1}=\\frac{1-f_{3}}{2}.\n$$\nTherefore $W=\\operatorname{span}\\{1,f_{3}\\}$. To determine linear independence, suppose $a\\cdot 1+b\\cdot f_{3}=0$ as a function. Evaluating at $x=0$ gives\n$$\na+b\\cos(0)=a+b=0,\n$$\nand evaluating at $x=\\frac{\\pi}{4}$ gives\n$$\na+b\\cos\\!\\left(\\frac{\\pi}{2}\\right)=a+0=a=0.\n$$\nSubstituting $a=0$ into $a+b=0$ yields $b=0$. Thus $\\{1,f_{3}\\}$ is linearly independent. Consequently, a basis for $W$ has two elements, and the dimension of $W$ is $2$.", "answer": "$$\\boxed{2}$$", "id": "1358123"}]}