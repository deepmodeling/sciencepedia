{"hands_on_practices": [{"introduction": "One of the most intuitive applications of composing linear maps is in computer graphics and geometry, where complex transformations are built by sequencing simpler ones. This exercise guides you through combining a reflection, a shear, and a rotation in $\\mathbb{R}^2$. By finding the standard matrix for this composite transformation, you'll practice the fundamental principle that the matrix of a composition is the product of the individual matrices in the reverse order of application. [@problem_id:1355080]", "problem": "Consider a sequence of three linear transformations applied to vectors in $\\mathbb{R}^2$. The transformations are applied in the following specific order:\n\n1.  First, a reflection $T_1$ through the line defined by the equation $y = -x$.\n2.  Second, a horizontal shear $T_2$ that maps a point $(x, y)$ to the point $(x+2y, y)$.\n3.  Third, a counter-clockwise rotation $T_3$ about the origin by an angle of $\\frac{\\pi}{6}$ radians.\n\nLet $T$ be the composite transformation $T = T_3 \\circ T_2 \\circ T_1$. Determine the standard matrix for the transformation $T$.", "solution": "We denote by $A_{1}$, $A_{2}$, and $A_{3}$ the standard matrices of $T_{1}$, $T_{2}$, and $T_{3}$, respectively. The composite transformation $T = T_{3} \\circ T_{2} \\circ T_{1}$ has standard matrix $A = A_{3}A_{2}A_{1}$.\n\nFirst, $T_{1}$ is reflection through the line $y=-x$. For a line through the origin with unit direction vector $u$, the reflection matrix is $R = 2uu^{T} - I$. The line $y=-x$ has direction vector $v = \\begin{pmatrix}1 \\\\ -1\\end{pmatrix}$ and unit vector $u = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ -1\\end{pmatrix}$. Thus\n$$\nA_{1} = 2uu^{T} - I \n= 2 \\cdot \\frac{1}{2} \\begin{pmatrix}1 & -1 \\\\ -1 & 1\\end{pmatrix} - \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}\n= \\begin{pmatrix}0 & -1 \\\\ -1 & 0\\end{pmatrix}.\n$$\n\nSecond, $T_{2}$ is the horizontal shear $(x,y) \\mapsto (x + 2y, y)$, so\n$$\nA_{2} = \\begin{pmatrix}1 & 2 \\\\ 0 & 1\\end{pmatrix}.\n$$\n\nThird, $T_{3}$ is the counter-clockwise rotation by angle $\\frac{\\pi}{6}$, whose matrix is\n$$\nA_{3} = \\begin{pmatrix}\\cos\\left(\\frac{\\pi}{6}\\right) & -\\sin\\left(\\frac{\\pi}{6}\\right) \\\\ \\sin\\left(\\frac{\\pi}{6}\\right) & \\cos\\left(\\frac{\\pi}{6}\\right)\\end{pmatrix}.\n$$\n\nCompute the product $A_{2}A_{1}$:\n$$\nA_{2}A_{1} = \\begin{pmatrix}1 & 2 \\\\ 0 & 1\\end{pmatrix} \\begin{pmatrix}0 & -1 \\\\ -1 & 0\\end{pmatrix}\n= \\begin{pmatrix}1 \\cdot 0 + 2 \\cdot (-1) & 1 \\cdot (-1) + 2 \\cdot 0 \\\\ 0 \\cdot 0 + 1 \\cdot (-1) & 0 \\cdot (-1) + 1 \\cdot 0\\end{pmatrix}\n= \\begin{pmatrix}-2 & -1 \\\\ -1 & 0\\end{pmatrix}.\n$$\n\nThen multiply by $A_{3}$ to obtain $A = A_{3}(A_{2}A_{1})$:\n$$\nA = \\begin{pmatrix}\\cos\\left(\\frac{\\pi}{6}\\right) & -\\sin\\left(\\frac{\\pi}{6}\\right) \\\\ \\sin\\left(\\frac{\\pi}{6}\\right) & \\cos\\left(\\frac{\\pi}{6}\\right)\\end{pmatrix}\n\\begin{pmatrix}-2 & -1 \\\\ -1 & 0\\end{pmatrix}\n= \\begin{pmatrix}\n-2\\cos\\left(\\frac{\\pi}{6}\\right) + \\sin\\left(\\frac{\\pi}{6}\\right) & -\\cos\\left(\\frac{\\pi}{6}\\right) \\\\\n-2\\sin\\left(\\frac{\\pi}{6}\\right) - \\cos\\left(\\frac{\\pi}{6}\\right) & -\\sin\\left(\\frac{\\pi}{6}\\right)\n\\end{pmatrix}.\n$$\n\nTherefore, the standard matrix for $T$ is the above $2 \\times 2$ matrix.", "answer": "$$\\boxed{\\begin{pmatrix}-2\\cos\\left(\\frac{\\pi}{6}\\right)+\\sin\\left(\\frac{\\pi}{6}\\right) & -\\cos\\left(\\frac{\\pi}{6}\\right) \\\\ -2\\sin\\left(\\frac{\\pi}{6}\\right)-\\cos\\left(\\frac{\\pi}{6}\\right) & -\\sin\\left(\\frac{\\pi}{6}\\right)\\end{pmatrix}}$$", "id": "1355080"}, {"introduction": "The power of linear algebra lies in its ability to describe transformations not just in geometric spaces like $\\mathbb{R}^n$, but also in abstract vector spaces such as those of functions. This problem challenges you to work with linear operators on a space of polynomials, involving familiar calculus operations. Finding the matrix representation for the composition of these operators will strengthen your understanding of how to apply these concepts beyond simple geometric vectors. [@problem_id:1355111]", "problem": "Let $P_2(\\mathbb{R})$ denote the vector space of all polynomials with real coefficients of degree at most 2. Consider the standard ordered basis for this space, $\\mathcal{B} = \\{1, x, x^2\\}$.\n\nTwo linear operators, $L_1: P_2(\\mathbb{R}) \\to P_2(\\mathbb{R})$ and $L_2: P_2(\\mathbb{R}) \\to P_2(\\mathbb{R})$, are defined as follows. For any polynomial $p(x) \\in P_2(\\mathbb{R})$:\n- $L_1(p(x)) = (x-1) \\frac{d}{dx}p(x)$\n- $L_2(p(x)) = p(x) - p(0) + \\left( \\int_0^1 p(t) dt \\right) x^2$\n\nDetermine the matrix representation of the composite linear operator $L_1 \\circ L_2$ with respect to the basis $\\mathcal{B}$.", "solution": "Let $p(x)=a+bx+cx^{2}\\in P_{2}(\\mathbb{R})$. Then\n$$\np(0)=a,\\quad \\int_{0}^{1}p(t)\\,dt=\\int_{0}^{1}\\left(a+bt+ct^{2}\\right)dt=a+\\frac{b}{2}+\\frac{c}{3}.\n$$\nBy definition,\n$$\nL_{2}(p)(x)=p(x)-p(0)+\\left(\\int_{0}^{1}p(t)\\,dt\\right)x^{2}=bx+\\left(a+\\frac{b}{2}+\\frac{c}{3}+c\\right)x^{2}=bx+\\left(a+\\frac{b}{2}+\\frac{4}{3}c\\right)x^{2}.\n$$\nSet $d=a+\\frac{b}{2}+\\frac{4}{3}c$, so $L_{2}(p)(x)=bx+dx^{2}$. Then\n$$\n\\frac{d}{dx}L_{2}(p)(x)=b+2dx,\\qquad L_{1}(L_{2}(p))(x)=(x-1)\\left(b+2dx\\right).\n$$\nExpanding gives\n$$\nL_{1}(L_{2}(p))(x)=-b+\\left(b-2d\\right)x+\\left(2d\\right)x^{2}.\n$$\nSubstituting $d=a+\\frac{b}{2}+\\frac{4}{3}c$ yields the coefficients with respect to $\\{1,x,x^{2}\\}$:\n$$\n\\text{constant}=-b,\\quad \\text{coeff. of }x=-2a-\\frac{8}{3}c,\\quad \\text{coeff. of }x^{2}=2a+b+\\frac{8}{3}c.\n$$\nThus, relative to the ordered basis $\\mathcal{B}=\\{1,x,x^{2}\\}$, the matrix of $L_{1}\\circ L_{2}$, whose columns are the images of $1,x,x^{2}$ respectively, is\n$$\n\\begin{pmatrix}\n0 & -1 & 0\\\\\n-2 & 0 & -\\frac{8}{3}\\\\\n2 & 1 & \\frac{8}{3}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0 & -1 & 0\\\\ -2 & 0 & -\\frac{8}{3}\\\\ 2 & 1 & \\frac{8}{3}\\end{pmatrix}}$$", "id": "1355111"}, {"introduction": "When we multiply two non-zero numbers, the result is always non-zero. However, this property does not hold for matrix multiplication or the composition of linear maps. This practice explores this crucial and non-intuitive concept by asking you to find non-zero transformations whose composition results in the zero map, which geometrically means that one map sends vectors into a subspace that the second map completely annihilates. [@problem_id:1355124]", "problem": "Let $S: \\mathbb{R}^2 \\to \\mathbb{R}^2$ and $T: \\mathbb{R}^2 \\to \\mathbb{R}^2$ be two linear transformations. Let the standard matrix representations for $S$ and $T$ be $A$ and $B$, respectively. The composition of these transformations, denoted by $T \\circ S$, is a linear transformation from $\\mathbb{R}^2$ to $\\mathbb{R}^2$ represented by the matrix product $BA$.\n\nIn general, the product of two non-zero matrices can result in a non-zero matrix. However, it is possible to find two non-zero matrices whose product is the zero matrix. This corresponds to a scenario where a non-trivial transformation $S$ maps vectors into a space that is then entirely mapped to the zero vector by a second non-trivial transformation $T$.\n\nConsider the task of finding a pair of non-zero $2 \\times 2$ matrices $(A, B)$ such that their composition $T \\circ S$ corresponds to the zero transformation, i.e., $BA = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}$.\n\nWhich of the following pairs of matrices $(A, B)$ satisfy this condition? Select all that apply.\n\nA. $A = \\begin{pmatrix} 1 & 1 \\\\ -1 & -1 \\end{pmatrix}$, $B = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}$\n\nB. $A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix}$, $B = \\begin{pmatrix} 1 & -1 \\\\ -1 & 1 \\end{pmatrix}$\n\nC. $A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$, $B = \\begin{pmatrix} 0 & 1 \\\\ 0 & 1 \\end{pmatrix}$\n\nD. $A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$, $B = \\begin{pmatrix} 0 & 0 \\\\ 1 & 1 \\end{pmatrix}$\n\nE. $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$, $B = \\begin{pmatrix} 4 & -2 \\\\ -3 & 1 \\end{pmatrix}$", "solution": "We require that the composition $T \\circ S$ be the zero transformation, which in matrix form is $BA = \\begin{pmatrix}0 & 0 \\\\ 0 & 0\\end{pmatrix}$. For each option, we compute $BA$ and check whether it equals the zero matrix while both $A$ and $B$ are non-zero.\n\nOption A:\n$$\nB = \\begin{pmatrix}1 & 1 \\\\ 1 & 1\\end{pmatrix},\\quad A = \\begin{pmatrix}1 & 1 \\\\ -1 & -1\\end{pmatrix}\n$$\n$$\nBA = \\begin{pmatrix}1 & 1 \\\\ 1 & 1\\end{pmatrix}\\begin{pmatrix}1 & 1 \\\\ -1 & -1\\end{pmatrix}\n= \\begin{pmatrix}1\\cdot 1 + 1\\cdot(-1) & 1\\cdot 1 + 1\\cdot(-1) \\\\ 1\\cdot 1 + 1\\cdot(-1) & 1\\cdot 1 + 1\\cdot(-1)\\end{pmatrix}\n= \\begin{pmatrix}0 & 0 \\\\ 0 & 0\\end{pmatrix}\n$$\nBoth $A$ and $B$ are non-zero, so A satisfies the condition.\n\nOption B:\n$$\nB = \\begin{pmatrix}1 & -1 \\\\ -1 & 1\\end{pmatrix},\\quad A = \\begin{pmatrix}2 & 1 \\\\ 1 & 1\\end{pmatrix}\n$$\n$$\nBA = \\begin{pmatrix}1 & -1 \\\\ -1 & 1\\end{pmatrix}\\begin{pmatrix}2 & 1 \\\\ 1 & 1\\end{pmatrix}\n= \\begin{pmatrix}1\\cdot 2 + (-1)\\cdot 1 & 1\\cdot 1 + (-1)\\cdot 1 \\\\ (-1)\\cdot 2 + 1\\cdot 1 & (-1)\\cdot 1 + 1\\cdot 1\\end{pmatrix}\n= \\begin{pmatrix}1 & 0 \\\\ -1 & 0\\end{pmatrix}\n$$\nThis is not the zero matrix, so B does not satisfy the condition.\n\nOption C:\n$$\nB = \\begin{pmatrix}0 & 1 \\\\ 0 & 1\\end{pmatrix},\\quad A = \\begin{pmatrix}1 & 0 \\\\ 0 & 0\\end{pmatrix}\n$$\n$$\nBA = \\begin{pmatrix}0 & 1 \\\\ 0 & 1\\end{pmatrix}\\begin{pmatrix}1 & 0 \\\\ 0 & 0\\end{pmatrix}\n= \\begin{pmatrix}0\\cdot 1 + 1\\cdot 0 & 0\\cdot 0 + 1\\cdot 0 \\\\ 0\\cdot 1 + 1\\cdot 0 & 0\\cdot 0 + 1\\cdot 0\\end{pmatrix}\n= \\begin{pmatrix}0 & 0 \\\\ 0 & 0\\end{pmatrix}\n$$\nBoth $A$ and $B$ are non-zero, so C satisfies the condition.\n\nOption D:\n$$\nB = \\begin{pmatrix}0 & 0 \\\\ 1 & 1\\end{pmatrix},\\quad A = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}\n$$\n$$\nBA = \\begin{pmatrix}0 & 0 \\\\ 1 & 1\\end{pmatrix}\\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}\n= \\begin{pmatrix}0 & 0 \\\\ 1 & 1\\end{pmatrix}\n$$\nThis is not the zero matrix, so D does not satisfy the condition.\n\nOption E:\n$$\nB = \\begin{pmatrix}4 & -2 \\\\ -3 & 1\\end{pmatrix},\\quad A = \\begin{pmatrix}1 & 2 \\\\ 3 & 4\\end{pmatrix}\n$$\n$$\nBA = \\begin{pmatrix}4 & -2 \\\\ -3 & 1\\end{pmatrix}\\begin{pmatrix}1 & 2 \\\\ 3 & 4\\end{pmatrix}\n= \\begin{pmatrix}4\\cdot 1 + (-2)\\cdot 3 & 4\\cdot 2 + (-2)\\cdot 4 \\\\ (-3)\\cdot 1 + 1\\cdot 3 & (-3)\\cdot 2 + 1\\cdot 4\\end{pmatrix}\n= \\begin{pmatrix}-2 & 0 \\\\ 0 & -2\\end{pmatrix}\n$$\nThis is not the zero matrix, so E does not satisfy the condition.\n\nTherefore, the pairs that satisfy $BA = \\begin{pmatrix}0 & 0 \\\\ 0 & 0\\end{pmatrix}$ are A and C.", "answer": "$$\\boxed{AC}$$", "id": "1355124"}]}