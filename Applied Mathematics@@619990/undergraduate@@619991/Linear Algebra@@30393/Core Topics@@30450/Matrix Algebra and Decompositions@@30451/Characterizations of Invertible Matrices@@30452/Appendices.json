{"hands_on_practices": [{"introduction": "One of the most crucial characterizations of an invertible matrix is that its determinant is non-zero. This practice explores a special case—nilpotent matrices where $A^k = O$ for some integer $k \\ge 1$—to provide a decisive proof of this connection. By applying the multiplicative property of determinants, you will see how a seemingly simple matrix equation leads to an inescapable conclusion about the matrix's singularity. This exercise is fundamental for cementing your understanding of how determinants govern the properties of linear transformations. [@problem_id:1352762]", "problem": "Let $A$ be an $n \\times n$ matrix with real entries, where $n \\ge 1$. Suppose there exists a positive integer $k \\ge 1$ such that $A^k$ is equal to the $n \\times n$ zero matrix, $O$. Which of the following statements provides a logically sound argument, based on the properties of determinants, to draw a conclusion about the invertibility of matrix $A$?\n\nA. Applying the determinant to the equation $A^k = O$ yields $(\\det(A))^k = \\det(O)$. Since $\\det(O) = 0$, we have $(\\det(A))^k = 0$, which implies $\\det(A) = 0$. A matrix is invertible if and only if its determinant is non-zero, so $A$ is not invertible.\n\nB. The fact that $A^k = O$ for a finite $k$ does not give enough information. For example, if $k$ is even, $\\det(A)$ could be positive or negative. Therefore, we cannot determine if $A$ is invertible.\n\nC. The determinant is a linear function, so $\\det(A^k) = k \\det(A)$. Since $A^k = O$, we have $\\det(A^k) = \\det(O) = 0$. Thus, $k \\det(A) = 0$. As $k \\ge 1$, this forces $\\det(A) = 0$, which means $A$ is not invertible.\n\nD. If $A^k = O$, then the matrix $A$ itself must be the zero matrix, $O$. The determinant of the zero matrix is $0$, so $A$ is not invertible.\n\nE. A matrix is invertible if and only if its determinant is $1$. The condition $(\\det(A))^k = 0$ implies $\\det(A)=0$. Since the determinant is not $1$, the matrix $A$ is not invertible.", "solution": "We are given an $n \\times n$ real matrix $A$ and a positive integer $k \\ge 1$ such that $A^{k} = O$, the zero matrix. Apply the determinant to both sides:\n$$\n\\det(A^{k}) = \\det(O).\n$$\nUsing the multiplicative property of the determinant, namely $\\det(BC) = \\det(B)\\det(C)$, extended by induction to powers, we obtain:\n$$\n\\det(A^{k}) = (\\det A)^{k}.\n$$\nThe determinant of the zero matrix is zero:\n$$\n\\det(O) = 0.\n$$\nTherefore,\n$$\n(\\det A)^{k} = 0.\n$$\nOver the real numbers, the only real number whose $k$th power is zero is zero itself, hence\n$$\n\\det A = 0.\n$$\nBy the invertibility criterion, a matrix is invertible if and only if its determinant is non-zero. Therefore $A$ is not invertible.\n\nEvaluating the options:\n- A states exactly the multiplicativity of the determinant, concludes $(\\det A)^{k} = 0$ and hence $\\det A = 0$, and thus $A$ is not invertible. This is correct.\n- B is incorrect because we have determined non-invertibility from $A^{k} = O$.\n- C is incorrect because the determinant is not linear as a function of matrices; $\\det(A^{k}) \\neq k \\det(A)$ in general.\n- D is false; there exist nonzero nilpotent matrices $A$ with $A^{k} = O$ but $A \\neq O$.\n- E is false; invertibility is equivalent to $\\det A \\neq 0$, not to $\\det A = 1$.\n\nThus the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1352762"}, {"introduction": "Knowing a matrix is invertible is one thing, but finding its inverse is another. This exercise demonstrates a powerful algebraic technique for constructing an inverse. When a matrix $A$ satisfies a polynomial equation, you can often rearrange the equation to express $A^{-1}$ as a polynomial in $A$ itself. This practice shifts the focus from computational methods like row reduction to a more abstract, algebraic understanding of matrix inverses, highlighting a beautiful result related to the Cayley-Hamilton theorem. [@problem_id:1352727]", "problem": "Let $A$ be an $n \\times n$ square matrix that satisfies the matrix equation\n$$A^3 - A^2 - 8A + 12I = \\mathbf{0}$$\nwhere $I$ is the $n \\times n$ identity matrix and $\\mathbf{0}$ is the $n \\times n$ zero matrix. It is given that $A$ is invertible. Find an expression for the inverse of $A$, denoted as $A^{-1}$, in terms of the matrix $A$ and the identity matrix $I$.", "solution": "We are given that $A$ satisfies the polynomial equation $A^{3} - A^{2} - 8A + 12I = \\mathbf{0}$ and that $A$ is invertible. Because $A$ is invertible, we can right-multiply the equation by $A^{-1}$ and use the facts that $A^{k}A^{-1} = A^{k-1}$ for $k \\geq 1$ and $IA^{-1} = A^{-1}$:\n$$\nA^{3}A^{-1} - A^{2}A^{-1} - 8AA^{-1} + 12IA^{-1} = \\mathbf{0}.\n$$\nThis simplifies to\n$$\nA^{2} - A - 8I + 12A^{-1} = \\mathbf{0}.\n$$\nRearranging to isolate $A^{-1}$ gives\n$$\n12A^{-1} = -A^{2} + A + 8I,\n$$\nand dividing both sides by $12$ yields\n$$\nA^{-1} = \\frac{1}{12}\\left(-A^{2} + A + 8I\\right).\n$$\nThis expresses $A^{-1}$ purely in terms of $A$ and $I$, as required.", "answer": "$$\\boxed{\\frac{1}{12}\\left(-A^{2}+A+8I\\right)}$$", "id": "1352727"}, {"introduction": "This problem elevates the concept of invertibility by connecting it to combinatorial reasoning within the abstract framework of finite fields. You are tasked with counting all possible invertible $2 \\times 2$ matrices with entries from a finite field $\\mathbb{Z}_p$. To succeed, you must think of invertibility in terms of its geometric equivalent: the matrix's column vectors must be linearly independent and form a basis for the vector space. Solving this problem will deepen your appreciation for the structural properties of invertible matrices and provide insight into their applications in modern cryptography and coding theory. [@problem_id:1352759]", "problem": "Let $p$ be a prime number. Consider the set of $2 \\times 2$ matrices whose entries are elements of the finite field $\\mathbb{Z}_p$. The field $\\mathbb{Z}_p$ consists of the integers $\\{0, 1, \\dots, p-1\\}$ with addition and multiplication performed modulo $p$. Determine the total number of such $2 \\times 2$ matrices that are invertible.\n\nExpress your answer as a polynomial in $p$.", "solution": "Let $\\mathbb{Z}_{p}$ be a field since $p$ is prime. A $2\\times 2$ matrix over $\\mathbb{Z}_{p}$ is invertible if and only if its columns form a linearly independent set in $\\mathbb{Z}_{p}^{2}$.\n\nCount invertible matrices by choosing columns:\n- Choose the first column as any nonzero vector in $\\mathbb{Z}_{p}^{2}$. There are $p^{2}-1$ choices.\n- Given a first column $v\\neq 0$, the second column must not lie in the $1$-dimensional subspace $\\operatorname{span}\\{v\\}$, which contains exactly $p$ vectors. Since there are $p^{2}$ total vectors in $\\mathbb{Z}_{p}^{2}$, there are $p^{2}-p$ valid choices for the second column.\n\nBy the multiplication principle, the total number of invertible $2\\times 2$ matrices over $\\mathbb{Z}_{p}$ is\n$$\n(p^{2}-1)(p^{2}-p).\n$$\nExpressed as a polynomial in $p$, this is\n$$\n(p^{2}-1)(p^{2}-p)=p^{4}-p^{3}-p^{2}+p.\n$$", "answer": "$$\\boxed{p^{4}-p^{3}-p^{2}+p}$$", "id": "1352759"}]}