{"hands_on_practices": [{"introduction": "The concept of matrix similarity is fundamentally about perspective. A single linear transformation can have different matrix representations depending on the basis you choose. This exercise provides a concrete scenario: a complex dynamical system that becomes simple when viewed in its \"natural\" basis. Your task is to use the similarity transformation $B = PDP^{-1}$ to translate the simple dynamics back into the standard basis, revealing the more complex matrix that governs the system's observable behavior [@problem_id:1388677].", "problem": "A two-dimensional linear dynamical system is described by the vector differential equation $\\frac{d\\vec{x}}{dt} = B\\vec{x}$, where $\\vec{x}(t)$ is a state vector in the standard basis and $B$ is a $2 \\times 2$ matrix. For this particular system, there exists a special \"natural mode\" basis in which the dynamics are decoupled. In this basis, the evolution of the system's state $\\vec{x}'$ is governed by the simpler diagonal matrix $D$, where $\\frac{d\\vec{x}'}{dt} = D\\vec{x}'$.\n\nThe diagonal matrix representing the uncoupled dynamics is given by:\n$$D = \\begin{pmatrix} 5 & 0 \\\\ 0 & -1 \\end{pmatrix}$$\n\nThe change-of-basis matrix $P$, which transforms coordinates from the natural mode basis to the standard basis (i.e., $\\vec{x} = P\\vec{x}'$), is given by:\n$$P = \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix}$$\n\nDetermine the matrix $B$ that governs the system's dynamics in the standard basis.", "solution": "Given $\\vec{x} = P\\vec{x}'$ and the dynamics $\\frac{d\\vec{x}}{dt} = B\\vec{x}$ and $\\frac{d\\vec{x}'}{dt} = D\\vec{x}'$, differentiate $\\vec{x} = P\\vec{x}'$ with respect to $t$ to obtain\n$$\n\\frac{d\\vec{x}}{dt} = P\\frac{d\\vec{x}'}{dt} = P D \\vec{x}'.\n$$\nOn the other hand,\n$$\n\\frac{d\\vec{x}}{dt} = B\\vec{x} = B P \\vec{x}'.\n$$\nSince this holds for all $\\vec{x}'$, it follows that\n$$\nB P = P D.\n$$\nRight-multiplying by $P^{-1}$ yields\n$$\nB = P D P^{-1}.\n$$\nFirst, verify that $P$ is invertible and compute $P^{-1}$. The determinant is\n$$\n\\det(P) = 2\\cdot 1 - 1\\cdot 1 = 1,\n$$\nso\n$$\nP^{-1} = \\begin{pmatrix} 1 & -1 \\\\ -1 & 2 \\end{pmatrix}.\n$$\nCompute $P D$:\n$$\nP D = \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} 5 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} 10 & -1 \\\\ 5 & -1 \\end{pmatrix}.\n$$\nThen compute\n$$\nB = (P D) P^{-1} = \\begin{pmatrix} 10 & -1 \\\\ 5 & -1 \\end{pmatrix} \\begin{pmatrix} 1 & -1 \\\\ -1 & 2 \\end{pmatrix} = \\begin{pmatrix} 11 & -12 \\\\ 6 & -7 \\end{pmatrix}.\n$$\nThus, the matrix governing the dynamics in the standard basis is $\\begin{pmatrix} 11 & -12 \\\\ 6 & -7 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} 11 & -12 \\\\ 6 & -7 \\end{pmatrix}}$$", "id": "1388677"}, {"introduction": "While the definition $B = P^{-1}AP$ tells us what similarity is, it doesn't offer a quick way to determine if two matrices are similar. A more practical approach is to check for properties that are preserved under similarity transformationsâ€”these are known as similarity invariants. This practice challenges you to use invariants like the trace, determinant, and characteristic polynomial as powerful and efficient tools to prove that two matrices are *not* similar, a crucial skill for quickly narrowing down possibilities and avoiding dead-end calculations [@problem_id:1388675].", "problem": "Two square matrices $X$ and $Y$ are said to be similar if there exists an invertible matrix $P$ such that $Y = P^{-1}XP$. Consider the following two real matrices:\n$$\nA = \\begin{pmatrix} 4 & -1 \\\\ 2 & 1 \\end{pmatrix}\n$$\nand\n$$\nB = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}\n$$\nAnalyze the properties of these matrices and select all the statements below that are true.\n\nA. Matrices $A$ and $B$ are similar because they have the same trace.\n\nB. Matrices $A$ and $B$ are not similar because they have different determinants.\n\nC. Matrices $A$ and $B$ are not similar because they have different characteristic polynomials.\n\nD. Matrices $A$ and $B$ are similar because they are both diagonalizable.\n\nE. Matrices $A$ and $B$ are row equivalent, and therefore they are similar.", "solution": "Two square matrices $X$ and $Y$ are similar if and only if there exists an invertible matrix $P$ such that $Y=P^{-1}XP$. Similarity preserves the characteristic polynomial, and hence preserves determinant and trace.\n\nCompute invariants for $A$ and $B$.\n\n1) Trace:\n$$\n\\operatorname{tr}(A)=4+1=5, \\quad \\operatorname{tr}(B)=2+3=5.\n$$\nThus the traces are equal. Since equal trace is necessary but not sufficient for similarity, statement A, which claims similarity solely from equal trace, is false.\n\n2) Determinant:\n$$\n\\det(A)=4\\cdot 1-(-1)\\cdot 2=4+2=6, \\quad \\det(B)=2\\cdot 3-1\\cdot 1=6-1=5.\n$$\nSince similar matrices must have the same determinant and these determinants differ, $A$ and $B$ are not similar. Therefore statement B is true.\n\n3) Characteristic polynomials:\nFor $A$,\n$$\np_{A}(t)=\\det\\begin{pmatrix} t-4 & 1 \\\\ -2 & t-1 \\end{pmatrix}=(t-4)(t-1)-1\\cdot(-2)=t^{2}-5t+6.\n$$\nFor $B$,\n$$\np_{B}(t)=\\det\\begin{pmatrix} t-2 & -1 \\\\ -1 & t-3 \\end{pmatrix}=(t-2)(t-3)-(-1)(-1)=t^{2}-5t+6-1=t^{2}-5t+5.\n$$\nSince similar matrices must have the same characteristic polynomial and these differ, $A$ and $B$ are not similar. Therefore statement C is true.\n\n4) Diagonalizability:\nThe polynomial $p_{A}(t)=t^{2}-5t+6=(t-2)(t-3)$ has distinct real roots, so $A$ is diagonalizable over $\\mathbb{R}$. The polynomial $p_{B}(t)=t^{2}-5t+5$ has discriminant $25-20=5>0$, so $B$ also has two distinct real eigenvalues and is diagonalizable over $\\mathbb{R}$. However, both being diagonalizable does not imply similarity; similarity would require the same eigenvalues (with multiplicities), which they do not have. Hence statement D is false.\n\n5) Row equivalence and similarity:\nSince both $A$ and $B$ are invertible, each is row equivalent to the identity matrix, hence they are row equivalent to each other. Row equivalence means there exists an invertible $E$ with $EA=B$, while similarity requires $B=P^{-1}AP$ for some invertible $P$. Row equivalence does not imply similarity, so the conclusion in statement E is invalid. Therefore statement E is false.\n\nThe true statements are B and C.", "answer": "$$\\boxed{BC}$$", "id": "1388675"}, {"introduction": "Having explored how to construct and test for similarity, we now probe its limits. Can *any* matrix be simplified into a diagonal form through a change of basis? This question leads us to the important concept of diagonalizability. This exercise focuses on a special class of matrices, non-zero nilpotent matrices, to demonstrate a fundamental barrier to diagonalizability. By proving that such a matrix can never be similar to a diagonal one [@problem_id:1388687], you will uncover a deeper truth about the necessary structure an operator must possess for its action to be viewed as simple scaling along axes.", "problem": "In linear algebra, we study various properties of matrices. Let $A$ be an $n \\times n$ matrix with entries from the set of complex numbers, where $n$ is a positive integer.\n\nA matrix $A$ is defined as **nilpotent** if there exists a positive integer $k$ such that $A^k$ is the zero matrix.\nA matrix $A$ is defined as **diagonalizable** if it is similar to a diagonal matrix, meaning there exists an invertible matrix $P$ and a diagonal matrix $D$ such that $A = PDP^{-1}$.\n\nConsider a matrix $A$ that is known to be both non-zero and nilpotent. Which of the following statements about the diagonalizability of $A$ is always true?\n\nA. $A$ is always diagonalizable.\n\nB. $A$ is never diagonalizable.\n\nC. $A$ is diagonalizable if and only if its trace is zero.\n\nD. $A$ is diagonalizable if and only if its dimension $n$ is an odd number.\n\nE. $A$ is diagonalizable if and only if $A^2$ is the zero matrix.", "solution": "Let $A$ be a non-zero nilpotent $n \\times n$ complex matrix. By definition, there exists a positive integer $k$ such that $A^{k}=0$.\n\nFirst, determine the eigenvalues of $A$. If $\\lambda$ is an eigenvalue with a corresponding non-zero eigenvector $v$, then\n$$\nA v = \\lambda v.\n$$\nApplying $A^{k}$ to $v$ gives\n$$\nA^{k} v = \\lambda^{k} v.\n$$\nSince $A^{k}=0$, we have $A^{k} v = 0$, hence\n$$\n\\lambda^{k} v = 0.\n$$\nBecause $v \\neq 0$, it follows that\n$$\n\\lambda^{k} = 0 \\quad \\Rightarrow \\quad \\lambda = 0.\n$$\nTherefore, the only eigenvalue of $A$ is $0$.\n\nSuppose $A$ were diagonalizable. Then there exists an invertible matrix $P$ and a diagonal matrix $D$ such that\n$$\nA = P D P^{-1}.\n$$\nThe diagonal entries of $D$ are precisely the eigenvalues of $A$, so all diagonal entries of $D$ are $0$, which implies\n$$\nD = 0 \\quad \\Rightarrow \\quad A = P 0 P^{-1} = 0,\n$$\ncontradicting that $A$ is non-zero. Hence a non-zero nilpotent matrix cannot be diagonalizable.\n\nEquivalently, using the minimal polynomial: for a nilpotent $A \\neq 0$, the minimal polynomial is $m_{A}(t) = t^{m}$ with $m \\geq 2$. A complex matrix is diagonalizable if and only if its minimal polynomial splits into distinct linear factors. Since $t^{m}$ has a repeated factor when $m \\geq 2$, $A$ is not diagonalizable.\n\nEvaluate the options:\n- A is false by the above.\n- B is true: a non-zero nilpotent matrix is never diagonalizable.\n- C is false: while $\\operatorname{tr}(A)=0$ for nilpotent $A$, this does not imply diagonalizability.\n- D is false: diagonalizability does not depend on the parity of $n$.\n- E is false: $A^{2}=0$ with $A \\neq 0$ still implies non-diagonalizable; only $A=0$ would be diagonalizable.\n\nTherefore, the always true statement is B.", "answer": "$$\\boxed{B}$$", "id": "1388687"}]}