{"hands_on_practices": [{"introduction": "The fundamental test for diagonalizability requires comparing the algebraic and geometric multiplicities of a matrix's eigenvalues. This exercise provides a direct application of this test by exploring how a parameter within a matrix affects its eigenvalue structure. By systematically analyzing the cases for distinct real eigenvalues, repeated eigenvalues, and complex eigenvalues, you will build a solid foundation for determining diagonalizability in any scenario [@problem_id:1355366].", "problem": "In the study of discrete-time linear dynamical systems, the evolution of a state vector $\\vec{x}$ can be modeled by the equation $\\vec{x}_{n+1} = A \\vec{x}_n$. The ability to diagonalize the matrix $A$ over the field of real numbers, i.e., to write $A = PDP^{-1}$ where $D$ is a real diagonal matrix, greatly simplifies the analysis of the system's long-term behavior.\n\nConsider a system governed by the matrix\n$$ A = \\begin{pmatrix} 1 & 0 & k \\\\ 0 & 3 & 0 \\\\ 1 & 0 & 1 \\end{pmatrix} $$\nwhere $k$ is a real parameter.\n\nDetermine the complete set of real values for the parameter $k$ for which the matrix $A$ is diagonalizable over the real numbers. Choose the correct description of this set from the options below.\n\nA. The set of all positive real numbers ($k>0$).\n\nB. The set of all non-negative real numbers ($k \\ge 0$).\n\nC. The set of all real numbers except zero ($k \\neq 0$).\n\nD. Only the single value $k=4$.\n\nE. The set of all real numbers.", "solution": "To determine when $A$ is diagonalizable over $\\mathbb{R}$, compute the characteristic polynomial and analyze eigenvalues and eigenspaces.\n\nCompute the characteristic polynomial:\n$$\np(\\lambda)=\\det(A-\\lambda I)=\\det\\begin{pmatrix}1-\\lambda & 0 & k\\\\ 0 & 3-\\lambda & 0\\\\ 1 & 0 & 1-\\lambda\\end{pmatrix}.\n$$\nExpanding along the second column (which has only the middle nonzero entry) gives\n$$\np(\\lambda)=(3-\\lambda)\\det\\begin{pmatrix}1-\\lambda & k\\\\ 1 & 1-\\lambda\\end{pmatrix}=(3-\\lambda)\\left((1-\\lambda)^{2}-k\\right).\n$$\nHence the eigenvalues are\n$$\n\\lambda=3,\\quad \\lambda=1\\pm \\sqrt{k}.\n$$\n\n- If $k<0$, then $1\\pm \\sqrt{k}$ are not real, so $A$ is not diagonalizable over $\\mathbb{R}$.\n\n- If $k=0$, then the eigenvalues are $\\lambda=3$ and $\\lambda=1$ with algebraic multiplicity $2$. For $\\lambda=1$, solve $(A-I)\\vec{x}=0$ with $A-I=\\begin{pmatrix}0&0&k\\\\ 0&2&0\\\\ 1&0&0\\end{pmatrix}$ at $k=0$, i.e.,\n$$\n\\begin{pmatrix}0&0&0\\\\ 0&2&0\\\\ 1&0&0\\end{pmatrix}\\begin{pmatrix}x_{1}\\\\ x_{2}\\\\ x_{3}\\end{pmatrix}=\\begin{pmatrix}0\\\\ 0\\\\ 0\\end{pmatrix}\n\\Rightarrow x_{2}=0,\\; x_{1}=0,\n$$\nso the eigenspace is one-dimensional. Since the algebraic multiplicity is $2$ but the geometric multiplicity is $1$, $A$ is not diagonalizable when $k=0$.\n\n- If $k>0$, then all eigenvalues are real. For $k\\neq 4$, the eigenvalues $3$, $1+\\sqrt{k}$, and $1-\\sqrt{k}$ are distinct, so $A$ is diagonalizable. For the special case $k=4$, the eigenvalues are $\\lambda=3$ (with algebraic multiplicity $2$) and $\\lambda=-1$. Check the geometric multiplicity of $\\lambda=3$ by solving $(A-3I)\\vec{x}=0$ with\n$$\nA-3I=\\begin{pmatrix}-2&0&k\\\\ 0&0&0\\\\ 1&0&-2\\end{pmatrix}.\n$$\nThe system is\n$$\n-2x_{1}+k x_{3}=0,\\quad x_{1}-2x_{3}=0.\n$$\nFrom $x_{1}=2x_{3}$, the first equation becomes $(-4+k)x_{3}=0$. Hence:\n- If $k\\neq 4$, then $x_{3}=0$ and $x_{1}=0$, leaving $x_{2}$ free, so the eigenspace for $\\lambda=3$ is one-dimensional.\n- If $k=4$, then the first equation is redundant, and with $x_{1}=2x_{3}$ and $x_{2}$ free, the eigenspace is two-dimensional.\n\nThus, for $k=4$, the eigenvalue $\\lambda=3$ has geometric multiplicity $2$ equal to its algebraic multiplicity, and together with the eigenspace for $\\lambda=-1$, $A$ is diagonalizable.\n\nCombining cases: $A$ is diagonalizable over $\\mathbb{R}$ if and only if $k>0$. This set corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1355366"}, {"introduction": "Moving beyond routine calculations, expert problem-solving often involves recognizing and exploiting underlying structural properties. This problem focuses on rank-1 matrices, where properties like rank, nullity, and trace provide elegant shortcuts to determine diagonalizability [@problem_id:1355313]. This practice will train you to identify and use a matrix's intrinsic structure for a more insightful and efficient analysis.", "problem": "Consider the $3 \\times 3$ matrix $A$ that depends on a real parameter $\\alpha$:\n$$\nA = \\begin{pmatrix}\n3 & -1 & 1 \\\\\n6 & -2 & 2 \\\\\n3\\alpha & -\\alpha & \\alpha\n\\end{pmatrix}\n$$\nA matrix is said to be diagonalizable if there exists an invertible matrix $P$ and a diagonal matrix $D$ such that $A = PDP^{-1}$. Determine the unique real value of $\\alpha$ for which the matrix $A$ is not diagonalizable.", "solution": "First observe that the three rows of $A$ are proportional to the first row. Indeed,\n$$\n(6,-2,2)=2\\cdot(3,-1,1), \\quad (3\\alpha,-\\alpha,\\alpha)=\\alpha\\cdot(3,-1,1).\n$$\nHence $\\operatorname{rank}(A)=1$. Write $A$ as an outer product\n$$\nA = u r, \\quad \\text{where } u=\\begin{pmatrix}1\\\\2\\\\ \\alpha\\end{pmatrix}, \\; r=\\begin{pmatrix}3 & -1 & 1\\end{pmatrix}.\n$$\nThen\n$$\nA^{2} = (u r)(u r) = u(r u) r = (r u)\\, u r = (r u)\\, A,\n$$\nwhere $r u$ is the scalar\n$$\nr u = 3\\cdot 1 + (-1)\\cdot 2 + 1\\cdot \\alpha = 1+\\alpha.\n$$\nTherefore\n$$\nA^{2} = (1+\\alpha)A,\n$$\nso $A$ satisfies the polynomial $x^{2} - (1+\\alpha)x = x\\bigl(x-(1+\\alpha)\\bigr)$. Thus the only possible eigenvalues are $0$ and $1+\\alpha$. Also, $\\operatorname{tr}(A)=3+(-2)+\\alpha=1+\\alpha$ and $\\det(A)=0$ (since $\\operatorname{rank}(A)=1$), which forces the multiset of eigenvalues to be $\\{0,0,1+\\alpha\\}$.\n\nFor diagonalizability, compare algebraic and geometric multiplicities. Since $\\operatorname{rank}(A)=1$, the nullity is\n$$\n\\dim\\ker(A) = 3 - \\operatorname{rank}(A) = 2,\n$$\nso the geometric multiplicity of the eigenvalue $0$ is $2$. If $1+\\alpha\\neq 0$, then the eigenvalues are $0$ (algebraic multiplicity $2$) and $1+\\alpha$ (algebraic multiplicity $1$). The geometric multiplicities are $2$ and $1$ respectively, summing to $3$, so $A$ is diagonalizable.\n\nIf $1+\\alpha=0$, i.e., $\\alpha=-1$, then $A^{2}=0$ but $A\\neq 0$, so the only eigenvalue is $0$ with algebraic multiplicity $3$, while $\\dim\\ker(A)=2$. Hence the geometric multiplicity is strictly less than the algebraic multiplicity, and $A$ is not diagonalizable.\n\nTherefore, the unique real value of $\\alpha$ for which $A$ is not diagonalizable is $\\alpha=-1$.", "answer": "$$\\boxed{-1}$$", "id": "1355313"}, {"introduction": "A deeper understanding of mathematical concepts includes knowing their limitations and how they interact under various operations. This exercise challenges the common but false assumption that the set of diagonalizable matrices is closed under addition. By finding a concrete counterexample, you will prove that the sum of two diagonalizable matrices is not always diagonalizable, thereby achieving a more nuanced view of their algebraic properties [@problem_id:1355342].", "problem": "A square matrix $M$ is called diagonalizable if there exists an invertible matrix $P$ such that $P^{-1}MP$ is a diagonal matrix. An equivalent condition for an $n \\times n$ matrix to be diagonalizable is that it must have $n$ linearly independent eigenvectors. For a given eigenvalue, its number of associated linearly independent eigenvectors is its geometric multiplicity, while the number of times it appears as a root of the characteristic polynomial is its algebraic multiplicity. A matrix is diagonalizable if and only if, for every eigenvalue, its geometric and algebraic multiplicities are equal.\n\nThe set of all $n \\times n$ diagonalizable matrices is not closed under addition. That is, the sum of two diagonalizable matrices is not always diagonalizable.\n\nWhich of the following pairs of $2 \\times 2$ matrices, $(A, B)$, provides a counterexample to closure by having the property that both $A$ and $B$ are diagonalizable, but their sum $A+B$ is not diagonalizable?\n\nA. $A = \\begin{pmatrix} 1 & 0 \\\\ 0 & 3 \\end{pmatrix}, B = \\begin{pmatrix} 2 & 0 \\\\ 0 & -1 \\end{pmatrix}$\n\nB. $A = \\begin{pmatrix} 1 & 1 \\\\ 0 & 0 \\end{pmatrix}, B = \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}$\n\nC. $A = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, B = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$\n\nD. $A = \\begin{pmatrix} 2 & 1 \\\\ 0 & 1 \\end{pmatrix}, B = \\begin{pmatrix} -1 & 0 \\\\ 0 & 0 \\end{pmatrix}$\n\nE. $A = \\begin{pmatrix} 1 & 0 \\\\ 1 & 2 \\end{pmatrix}, B = \\begin{pmatrix} 0 & 1 \\\\ 0 & -1 \\end{pmatrix}$", "solution": "We analyze each option to determine whether both matrices are diagonalizable while their sum is not.\n\nA. Both $A$ and $B$ are diagonal, hence diagonalizable. Their sum is\n$$\nA+B=\\begin{pmatrix} 3 & 0 \\\\ 0 & 2 \\end{pmatrix},\n$$\nwhich has distinct eigenvalues $3$ and $2$, so it is diagonalizable. Not a counterexample.\n\nB. For\n$$\nA=\\begin{pmatrix} 1 & 1 \\\\ 0 & 0 \\end{pmatrix},\\quad B=\\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix},\n$$\n$A$ has characteristic polynomial\n$$\n\\det(A-\\lambda I)=\\det\\begin{pmatrix} 1-\\lambda & 1 \\\\ 0 & -\\lambda \\end{pmatrix}=-(1-\\lambda)\\lambda=\\lambda(\\lambda-1),\n$$\nso it has distinct eigenvalues $0$ and $1$ and is diagonalizable. $B$ is diagonal, hence diagonalizable. Their sum is\n$$\nA+B=\\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}.\n$$\nIts characteristic polynomial is\n$$\n\\det((A+B)-\\lambda I)=\\det\\begin{pmatrix} 1-\\lambda & 1 \\\\ 0 & 1-\\lambda \\end{pmatrix}=(1-\\lambda)^{2},\n$$\nso the only eigenvalue is $\\lambda=1$ with algebraic multiplicity $2$. The eigenspace is\n$$\n\\ker((A+B)-I)=\\ker\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}=\\left\\{\\begin{pmatrix} x \\\\ 0 \\end{pmatrix}: x\\in\\mathbb{F}\\right\\},\n$$\nwhich is one-dimensional, so the geometric multiplicity is $1\\neq 2$. Therefore $A+B$ is not diagonalizable. This is a counterexample.\n\nC. $A=\\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$ is nilpotent with a single eigenvalue $0$ and is not diagonalizable. Not a valid pair.\n\nD. For\n$$\nA=\\begin{pmatrix} 2 & 1 \\\\ 0 & 1 \\end{pmatrix},\\quad B=\\begin{pmatrix} -1 & 0 \\\\ 0 & 0 \\end{pmatrix},\n$$\n$A$ has characteristic polynomial\n$$\n\\det(A-\\lambda I)=\\det\\begin{pmatrix} 2-\\lambda & 1 \\\\ 0 & 1-\\lambda \\end{pmatrix}=(2-\\lambda)(1-\\lambda),\n$$\nso it has distinct eigenvalues $2$ and $1$ and is diagonalizable. $B$ is diagonal, hence diagonalizable. Their sum is\n$$\nA+B=\\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix},\n$$\nwhich, as in option B, has characteristic polynomial $(1-\\lambda)^{2}$ and a one-dimensional eigenspace, hence is not diagonalizable. This is a counterexample.\n\nE. For\n$$\nA=\\begin{pmatrix} 1 & 0 \\\\ 1 & 2 \\end{pmatrix},\\quad B=\\begin{pmatrix} 0 & 1 \\\\ 0 & -1 \\end{pmatrix},\n$$\nboth $A$ and $B$ have distinct eigenvalues and are diagonalizable. Their sum is\n$$\nA+B=\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix},\n$$\nwith characteristic polynomial\n$$\n\\det\\begin{pmatrix} 1-\\lambda & 1 \\\\ 1 & 1-\\lambda \\end{pmatrix}=(1-\\lambda)^{2}-1=\\lambda^{2}-2\\lambda,\n$$\nwhich has distinct roots $\\lambda=0$ and $\\lambda=2$, so $A+B$ is diagonalizable. Not a counterexample.\n\nTherefore, the pairs that provide counterexamples are B and D.", "answer": "$$\\boxed{B}$$", "id": "1355342"}]}