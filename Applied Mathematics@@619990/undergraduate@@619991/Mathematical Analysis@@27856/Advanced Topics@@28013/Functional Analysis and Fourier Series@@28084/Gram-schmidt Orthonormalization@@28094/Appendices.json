{"hands_on_practices": [{"introduction": "We often first learn the Gram-Schmidt process using the standard dot product in Euclidean space. This first exercise challenges that familiar setting by asking you to apply the process in $\\mathbb{R}^2$ with a non-standard inner product defined by a matrix. Successfully completing this practice reinforces the crucial concept that the Gram-Schmidt algorithm is a general procedure whose outcome depends fundamentally on the definition of the inner product, not just on our visual intuition of perpendicularity [@problem_id:2300318].", "problem": "In the vector space $\\mathbb{R}^2$, a non-standard inner product is defined for any two vectors $\\mathbf{u} = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix}$ and $\\mathbf{v} = \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix}$ as $\\langle \\mathbf{u}, \\mathbf{v} \\rangle = \\mathbf{u}^T A \\mathbf{v}$, where the superscript $T$ denotes the transpose. The matrix $A$ is given by:\n$$A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}$$\nConsider the standard basis vectors of $\\mathbb{R}^2$ in their conventional order: $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{v}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nApply the Gram-Schmidt orthonormalization process to the ordered set $\\{\\mathbf{v}_1, \\mathbf{v}_2\\}$ to find an orthonormal basis $\\{\\mathbf{u}_1, \\mathbf{u}_2\\}$ with respect to this inner product. Present your final answer as a $2 \\times 2$ matrix whose columns are the resulting orthonormal vectors $\\mathbf{u}_1$ and $\\mathbf{u}_2$, in that order.", "solution": "We use the inner product $\\langle \\mathbf{u}, \\mathbf{v} \\rangle=\\mathbf{u}^{T}A\\mathbf{v}$ with $A=\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix}$. For any vector $\\mathbf{x}$, the induced norm is $\\|\\mathbf{x}\\|=\\sqrt{\\langle \\mathbf{x},\\mathbf{x}\\rangle}=\\sqrt{\\mathbf{x}^{T}A\\mathbf{x}}$.\n\nStart with $\\mathbf{v}_{1}=\\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$. Its norm is\n$$\n\\|\\mathbf{v}_{1}\\|=\\sqrt{\\mathbf{v}_{1}^{T}A\\mathbf{v}_{1}}=\\sqrt{\\begin{pmatrix}1 & 0\\end{pmatrix}\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix}\\begin{pmatrix}1 \\\\ 0\\end{pmatrix}}=\\sqrt{2}.\n$$\nNormalize to get\n$$\n\\mathbf{u}_{1}=\\frac{\\mathbf{v}_{1}}{\\|\\mathbf{v}_{1}\\|}=\\begin{pmatrix}\\frac{1}{\\sqrt{2}} \\\\ 0\\end{pmatrix},\n$$\nso that $\\langle \\mathbf{u}_{1},\\mathbf{u}_{1}\\rangle=1$.\n\nNext take $\\mathbf{v}_{2}=\\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$ and orthogonalize it against $\\mathbf{u}_{1}$ using the Gram-Schmidt step with the given inner product:\n$$\n\\mathbf{w}_{2}=\\mathbf{v}_{2}-\\frac{\\langle \\mathbf{v}_{2},\\mathbf{u}_{1}\\rangle}{\\langle \\mathbf{u}_{1},\\mathbf{u}_{1}\\rangle}\\,\\mathbf{u}_{1}.\n$$\nCompute $\\langle \\mathbf{v}_{2},\\mathbf{u}_{1}\\rangle=\\mathbf{v}_{2}^{T}A\\mathbf{u}_{1}$. First\n$$\nA\\mathbf{u}_{1}=\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix}\\begin{pmatrix}\\frac{1}{\\sqrt{2}} \\\\ 0\\end{pmatrix}=\\begin{pmatrix}\\frac{2}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\\end{pmatrix},\n$$\nso\n$$\n\\langle \\mathbf{v}_{2},\\mathbf{u}_{1}\\rangle=\\begin{pmatrix}0 & 1\\end{pmatrix}\\begin{pmatrix}\\frac{2}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}}\\end{pmatrix}=\\frac{1}{\\sqrt{2}}.\n$$\nSince $\\langle \\mathbf{u}_{1},\\mathbf{u}_{1}\\rangle=1$, this gives\n$$\n\\mathbf{w}_{2}=\\begin{pmatrix}0 \\\\ 1\\end{pmatrix}-\\frac{1}{\\sqrt{2}}\\begin{pmatrix}\\frac{1}{\\sqrt{2}} \\\\ 0\\end{pmatrix}=\\begin{pmatrix}-\\frac{1}{2} \\\\ 1\\end{pmatrix}.\n$$\nNow normalize $\\mathbf{w}_{2}$. Its norm is\n$$\n\\|\\mathbf{w}_{2}\\|=\\sqrt{\\mathbf{w}_{2}^{T}A\\mathbf{w}_{2}}=\\sqrt{\\begin{pmatrix}-\\frac{1}{2} & 1\\end{pmatrix}\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix}\\begin{pmatrix}-\\frac{1}{2} \\\\ 1\\end{pmatrix}}.\n$$\nCompute\n$$\nA\\mathbf{w}_{2}=\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix}\\begin{pmatrix}-\\frac{1}{2} \\\\ 1\\end{pmatrix}=\\begin{pmatrix}0 \\\\ \\frac{3}{2}\\end{pmatrix},\n$$\nhence\n$$\n\\mathbf{w}_{2}^{T}A\\mathbf{w}_{2}=\\begin{pmatrix}-\\frac{1}{2} & 1\\end{pmatrix}\\begin{pmatrix}0 \\\\ \\frac{3}{2}\\end{pmatrix}=\\frac{3}{2},\n$$\nso\n$$\n\\|\\mathbf{w}_{2}\\|=\\sqrt{\\frac{3}{2}}.\n$$\nTherefore\n$$\n\\mathbf{u}_{2}=\\frac{\\mathbf{w}_{2}}{\\|\\mathbf{w}_{2}\\|}=\\sqrt{\\frac{2}{3}}\\begin{pmatrix}-\\frac{1}{2} \\\\ 1\\end{pmatrix}=\\begin{pmatrix}-\\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{6}}{3}\\end{pmatrix}.\n$$\nThe ordered orthonormal basis $\\{\\mathbf{u}_{1},\\mathbf{u}_{2}\\}$ with respect to $\\langle \\cdot,\\cdot\\rangle$ is thus given by the columns of the matrix\n$$\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} & -\\frac{\\sqrt{6}}{6} \\\\\n0 & \\frac{\\sqrt{6}}{3}\n\\end{pmatrix}.\n$$\nIt is straightforward to check that $\\langle \\mathbf{u}_{i},\\mathbf{u}_{j}\\rangle=\\delta_{ij}$ for $i,j\\in\\{1,2\\}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{\\sqrt{2}} & -\\frac{\\sqrt{6}}{6} \\\\ 0 & \\frac{\\sqrt{6}}{3}\\end{pmatrix}}$$", "id": "2300318"}, {"introduction": "The power of the Gram-Schmidt process extends far beyond geometric vectors into the realm of abstract function spaces. In this exercise, we will treat simple polynomials as \"vectors\" and define an inner product using an integral. By applying the process to the basis $\\{1, x\\}$, you will construct the first two members of a family of orthogonal polynomials known as Legendre polynomials, a cornerstone in fields ranging from physics to numerical analysis [@problem_id:10262].", "problem": "In the vector space of real-valued, continuous functions on the interval $[-1, 1]$, the inner product of two functions $f(x)$ and $g(x)$ is defined as:\n$$\n\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) dx\n$$\nAn orthonormal set of functions $\\{u_1(x), u_2(x), \\dots\\}$ is one where the inner product of any two distinct functions is zero, and the inner product of any function with itself is one, i.e., $\\langle u_i, u_j \\rangle = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n\nThe Gram-Schmidt process is an algorithm used to construct an orthonormal set $\\{u_1, u_2, \\dots\\}$ from a set of linearly independent functions $\\{v_1, v_2, \\dots\\}$. The process for the first two functions is as follows:\n1. Start with the first vector $v_1$ to find the first orthogonal vector $w_1$:\n   $$\n   w_1(x) = v_1(x)\n   $$\n2. Normalize $w_1$ to get the first orthonormal vector $u_1$:\n   $$\n   u_1(x) = \\frac{w_1(x)}{\\|w_1(x)\\|}, \\quad \\text{where } \\|f(x)\\| = \\sqrt{\\langle f(x), f(x) \\rangle}\n   $$\n3. Construct the second orthogonal vector $w_2$ by subtracting the projection of $v_2$ onto $u_1$ from $v_2$:\n   $$\n   w_2(x) = v_2(x) - \\langle v_2(x), u_1(x) \\rangle u_1(x)\n   $$\n4. Normalize $w_2$ to get the second orthonormal vector $u_2$:\n   $$\n   u_2(x) = \\frac{w_2(x)}{\\|w_2(x)\\|}\n   $$\n\n**Problem:**\nGiven the set of linearly independent polynomials $\\{v_1(x) = 1, v_2(x) = x\\}$, apply the Gram-Schmidt process to find the second orthonormal polynomial, $u_2(x)$, on the interval $[-1, 1]$.", "solution": "Normalize the first vector $v_1(x)=1$:\n$$\\|v_1\\|=\\sqrt{\\langle1,1\\rangle}=\\sqrt{\\int_{-1}^1 1\\,dx}=\\sqrt{2},$$\n$$u_1(x)=\\frac{1}{\\sqrt{2}}.$$\n\nCompute the second orthogonal vector:\n$$\\langle v_2,u_1\\rangle=\\int_{-1}^1 x\\cdot\\frac{1}{\\sqrt{2}}\\,dx=\\frac{1}{\\sqrt{2}}\\Bigl[\\frac{x^2}{2}\\Bigr]_{-1}^{1}=0,$$\n$$w_2(x)=v_2(x)-\\langle v_2,u_1\\rangle u_1(x)=x.$$\n\nNormalize $w_2(x)=x$:\n$$\\|w_2\\|=\\sqrt{\\langle x,x\\rangle}=\\sqrt{\\int_{-1}^1 x^2\\,dx}=\\sqrt{\\frac{2}{3}},$$\n$$u_2(x)=\\frac{x}{\\sqrt{2/3}}=\\sqrt{\\frac{3}{2}}\\;x.$$", "answer": "$$\\boxed{\\sqrt{\\frac{3}{2}} x}$$", "id": "10262"}, {"introduction": "After mastering the mechanics of the Gram-Schmidt process, a deeper question arises: what is the geometric meaning of the vectors it produces? This final practice provides a bridge between the algebraic steps and a tangible geometric concept. You will discover a beautiful and simple relationship between the norms of the orthogonal vectors, $\\|u_i\\|$, and the volume of the multidimensional parallelepiped spanned by the original vectors, offering a profound insight into what the algorithm accomplishes [@problem_id:2300312].", "problem": "Consider a set of $k$ linearly independent vectors $\\{v_1, v_2, \\dots, v_k\\}$ in the Euclidean space $\\mathbb{R}^n$, where $k \\le n$. These vectors span a $k$-dimensional parallelepiped, $P_k$. The volume of this parallelepiped is defined by the formula $\\text{Vol}(P_k) = \\sqrt{\\det(V^T V)}$, where $V$ is the $n \\times k$ matrix whose columns are the vectors $v_1, v_2, \\dots, v_k$, and $V^T$ is its transpose.\n\nNow, consider the application of the Gram-Schmidt process to the ordered set of vectors $\\{v_1, v_2, \\dots, v_k\\}$. This process generates a set of mutually orthogonal vectors $\\{u_1, u_2, \\dots, u_k\\}$ defined as follows:\n$u_1 = v_1$\n$u_i = v_i - \\sum_{j=1}^{i-1} \\frac{\\langle v_i, u_j \\rangle}{\\|u_j\\|^2} u_j \\quad \\text{for } i = 2, 3, \\dots, k.$\n\nHere, $\\langle a, b \\rangle$ denotes the standard dot product in $\\mathbb{R}^n$, and $\\|a\\| = \\sqrt{\\langle a, a \\rangle}$ denotes the Euclidean norm.\n\nFind a general, simplified expression for the volume of the parallelepiped, $\\text{Vol}(P_k)$, purely in terms of the norms of the orthogonal vectors, $\\|u_1\\|, \\|u_2\\|, \\dots, \\|u_k\\|$.", "solution": "We are given $k$ linearly independent vectors assembled as the columns of $V \\in \\mathbb{R}^{n \\times k}$, and the volume of the parallelepiped they span is\n$$\n\\text{Vol}(P_k)=\\sqrt{\\det(V^{T}V)}.\n$$\nApply the Gram-Schmidt process to $\\{v_{1},\\dots,v_{k}\\}$ to obtain orthogonal vectors $\\{u_{1},\\dots,u_{k}\\}$ and define $q_{i}=u_{i}/\\|u_{i}\\|$ for each $i$. Let $Q\\in \\mathbb{R}^{n\\times k}$ have columns $q_{1},\\dots,q_{k}$, so $Q^{T}Q=I_{k}$, and let $R\\in \\mathbb{R}^{k\\times k}$ be the upper-triangular matrix with entries\n$$\nr_{ij}=\\langle v_{j},q_{i}\\rangle \\quad \\text{for } i\\leq j, \\quad r_{ij}=0 \\quad \\text{for } i>j.\n$$\nBy the standard Gram-Schmidt (QR) decomposition, each $v_{j}$ expands in the orthonormal basis $\\{q_{1},\\dots,q_{j}\\}$, hence\n$$\nV=QR.\n$$\nTherefore,\n$$\nV^{T}V=R^{T}Q^{T}QR=R^{T}R.\n$$\nTaking determinants and using $Q^{T}Q=I_{k}$ gives\n$$\n\\det(V^{T}V)=\\det(R^{T}R)=\\det(R^{T})\\det(R)=(\\det R)^{2}.\n$$\nSince $R$ is upper triangular, $\\det R=\\prod_{i=1}^{k}r_{ii}$. Its diagonal entries satisfy\n$$\nr_{ii}=\\langle v_{i},q_{i}\\rangle=\\left\\langle v_{i},\\frac{u_{i}}{\\|u_{i}\\|}\\right\\rangle=\\left\\langle u_{i}+\\sum_{j=1}^{i-1}\\frac{\\langle v_{i},u_{j}\\rangle}{\\|u_{j}\\|^{2}}u_{j},\\frac{u_{i}}{\\|u_{i}\\|}\\right\\rangle=\\left\\langle u_{i},\\frac{u_{i}}{\\|u_{i}\\|}\\right\\rangle=\\|u_{i}\\|.\n$$\nThus,\n$$\n\\det(V^{T}V)=(\\prod_{i=1}^{k}\\|u_{i}\\|)^{2},\n$$\nand, since each $\\|u_{i}\\|>0$ by linear independence, we obtain\n$$\n\\text{Vol}(P_k)=\\sqrt{\\det(V^{T}V)}=\\prod_{i=1}^{k}\\|u_{i}\\|.\n$$\nThis expresses the volume purely in terms of the norms of the orthogonal vectors produced by the Gram-Schmidt process.", "answer": "$$\\boxed{\\prod_{i=1}^{k}\\|u_{i}\\|}$$", "id": "2300312"}]}