{"hands_on_practices": [{"introduction": "The Inverse Function Theorem provides a powerful shortcut for finding the derivative of an inverse function, even when the inverse itself is impossible to write down explicitly. This first practice exercise [@problem_id:30441] is a fundamental application of the theorem in one dimension. It hones the core skill of applying the formula $(f^{-1})'(y_0) = \\frac{1}{f'(x_0)}$ by relating the slope of the function at a point $x_0$ to the slope of its inverse at the corresponding point $y_0 = f(x_0)$.", "problem": "Consider a real-valued function $f: \\mathbb{R} \\to \\mathbb{R}$ defined by the polynomial:\n$$\nf(x) = x^5 + 2x^3 + x\n$$\nThe derivative of this function is $f'(x) = 5x^4 + 6x^2 + 1$. Since $f'(x) > 0$ for all $x \\in \\mathbb{R}$, the function $f$ is strictly increasing and therefore possesses a differentiable inverse function, which we denote by $f^{-1}$.\n\nThe derivative of the inverse function at a point $y_0$ in the range of $f$ can be found using the formula from the Inverse Function Theorem:\n$$\n(f^{-1})'(y_0) = \\frac{1}{f'(x_0)}\n$$\nwhere $x_0$ is the unique value such that $f(x_0) = y_0$.\n\nUsing this information, calculate the exact value of the derivative of the inverse function $f^{-1}$ at the point $y_0 = 4$.", "solution": "We have \n$$f(x)=x^5+2x^3+x,$$\nso\n$$f'(x)=5x^4+6x^2+1.$$\nSince for all real $x$, $5x^4\\ge0$, $6x^2\\ge0$ and $1>0$, it follows that $f'(x)>0$.  Hence $f$ is strictly increasing and admits a differentiable inverse $f^{-1}$.  By the Inverse Function Theorem, for $y_0\\in \\mathrm{Range}(f)$ and the unique $x_0$ with $f(x_0)=y_0$,\n$$(f^{-1})'(y_0)=\\frac1{f'(x_0)}.$$\n\nWe wish to compute $(f^{-1})'(4)$.  First find $x_0$ such that\n$$f(x_0)=x_0^5+2x_0^3+x_0=4.$$\nBy inspection $x_0=1$ gives $1^5+2\\cdot1^3+1=1+2+1=4$.  Thus $x_0=1$.\n\nNext, evaluate $f'$ at $x_0=1$:\n$$f'(1)=5\\cdot1^4+6\\cdot1^2+1=5+6+1=12.$$\n\nTherefore,\n$$(f^{-1})'(4)=\\frac1{f'(1)}=\\frac1{12}.$$", "answer": "$$\\boxed{\\frac{1}{12}}$$", "id": "30441"}, {"introduction": "Moving from a single variable to multiple dimensions, the concept of a derivative generalizes to the Jacobian matrix, which represents the best linear approximation of a map near a point. This exercise [@problem_id:2325116] applies the Inverse Function Theorem to a map between two-dimensional spaces. Your task is to find the Jacobian of the inverse map, which the theorem states is simply the inverse of the original map's Jacobian matrix, reinforcing the deep connection between multivariable differentiation and linear algebra.", "problem": "Consider a continuously differentiable function $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$. It is known that the function maps the point $(1, 1)$ to $(2, -1)$, i.e., $f(1, 1) = (2, -1)$. The Jacobian matrix of $f$ at the point $(1, 1)$ is given by:\n$$ J_f(1, 1) = \\begin{pmatrix} 1 & -1 \\\\ 2 & 3 \\end{pmatrix} $$\nAssuming that an inverse function $f^{-1}$ exists and is differentiable in a neighborhood of the point $(2, -1)$, determine the Jacobian matrix of $f^{-1}$ at the point $(2, -1)$.", "solution": "Let the point in the domain be $\\mathbf{a} = (1, 1)$ and the corresponding point in the codomain be $\\mathbf{b} = f(\\mathbf{a}) = (2, -1)$. The problem asks for the Jacobian matrix of the inverse function, $J_{f^{-1}}$, evaluated at the point $\\mathbf{b}$.\n\nThe Inverse Function Theorem provides a relationship between the Jacobian of a function $f$ at a point $\\mathbf{a}$ and the Jacobian of its inverse $f^{-1}$ at the point $\\mathbf{b} = f(\\mathbf{a})$. The theorem states that if $f$ is continuously differentiable in a neighborhood of $\\mathbf{a}$ and its Jacobian matrix $J_f(\\mathbf{a})$ is invertible, then $f^{-1}$ is differentiable at $\\mathbf{b}$ and its Jacobian matrix is the inverse of the Jacobian matrix of $f$ at $\\mathbf{a}$.\nThe formula is:\n$$ J_{f^{-1}}(\\mathbf{b}) = [J_f(\\mathbf{a})]^{-1} $$\n\nIn this problem, we are given:\n- $\\mathbf{a} = (1, 1)$\n- $\\mathbf{b} = (2, -1)$\n- $J_f(\\mathbf{a}) = J_f(1, 1) = \\begin{pmatrix} 1 & -1 \\\\ 2 & 3 \\end{pmatrix}$\n\nOur goal is to compute $J_{f^{-1}}(2, -1)$. Using the formula from the Inverse Function Theorem, we need to find the inverse of the matrix $J_f(1, 1)$.\n\nFor a general 2x2 matrix $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, its inverse $A^{-1}$ is given by the formula:\n$$ A^{-1} = \\frac{1}{\\det(A)} \\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix} $$\nwhere the determinant is $\\det(A) = ad - bc$.\n\nFirst, we calculate the determinant of $J_f(1, 1)$:\n$$ \\det(J_f(1, 1)) = (1)(3) - (-1)(2) = 3 + 2 = 5 $$\nSince the determinant is non-zero, the matrix is invertible, which is a necessary condition for the Inverse Function Theorem to hold.\n\nNow, we can apply the matrix inversion formula to find $[J_f(1, 1)]^{-1}$:\n$$ [J_f(1, 1)]^{-1} = \\frac{1}{5} \\begin{pmatrix} 3 & -(-1) \\\\ -2 & 1 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 3 & 1 \\\\ -2 & 1 \\end{pmatrix} $$\nDistributing the scalar $\\frac{1}{5}$ into the matrix elements, we get:\n$$ [J_f(1, 1)]^{-1} = \\begin{pmatrix} \\frac{3}{5} & \\frac{1}{5} \\\\ -\\frac{2}{5} & \\frac{1}{5} \\end{pmatrix} $$\n\nTherefore, the Jacobian matrix of the inverse function $f^{-1}$ at the point $(2, -1)$ is this resulting matrix.\n$$ J_{f^{-1}}(2, -1) = \\begin{pmatrix} \\frac{3}{5} & \\frac{1}{5} \\\\ -\\frac{2}{5} & \\frac{1}{5} \\end{pmatrix} $$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{5} & \\frac{1}{5} \\\\ -\\frac{2}{5} & \\frac{1}{5} \\end{pmatrix}}$$", "id": "2325116"}, {"introduction": "Just as important as knowing when a function can be inverted is knowing when it cannot. The Inverse Function Theorem's power lies in its precise condition for local invertibility: the Jacobian determinant must be non-zero. This final practice [@problem_id:2325128] asks you to find the set of points where this condition fails, revealing the curve along which the function is not locally one-to-one. This type of analysis is crucial for understanding the geometric behavior of maps and identifying singularities.", "problem": "Consider the function $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$ defined by the transformation $f(x,y) = (u,v)$, where $u = x+y$ and $v = xy$. A function is said to be locally invertible at a point if there exists an open neighborhood of that point on which the function has a continuous inverse. There exists a set of points $(x,y)$ in the plane $\\mathbb{R}^2$ where the function $f$ is not locally invertible. This set forms a curve or a union of curves. Find a simplified expression $g(x,y)$ such that the equation $g(x,y) = 0$ defines this entire set of points.", "solution": "We are given the smooth map $f:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ defined by $f(x,y)=(u,v)$ with $u=x+y$ and $v=xy$. A point $(x_{0},y_{0})$ is a point of local invertibility if there exists an open neighborhood on which $f$ is bijective onto its image with a continuous inverse. For $C^{1}$ maps between equal-dimensional Euclidean spaces, the inverse function theorem provides a sufficient condition: if the Jacobian determinant at a point is nonzero, then $f$ is locally a $C^{1}$-diffeomorphism there, hence locally invertible with continuous inverse.\n\nCompute the Jacobian matrix $Df(x,y)$:\n$$\nDf(x,y)=\\begin{pmatrix}\n\\frac{\\partial u}{\\partial x} & \\frac{\\partial u}{\\partial y} \\\\\n\\frac{\\partial v}{\\partial x} & \\frac{\\partial v}{\\partial y}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 1 \\\\\ny & x\n\\end{pmatrix}.\n$$\nIts determinant is\n$$\n\\det Df(x,y)=(1)(x)-(1)(y)=x-y.\n$$\nThus, wherever $x\\neq y$, we have $\\det Df(x,y)\\neq 0$, and by the inverse function theorem $f$ is locally invertible (indeed, admits a $C^{1}$ inverse) at such points.\n\nIt remains to show that $f$ is not locally invertible when $x=y$. Fix $(a,a)$. For any sufficiently small $h\\neq 0$, the distinct points $(a+h,a-h)$ and $(a-h,a+h)$ lie arbitrarily close to $(a,a)$ and satisfy\n$$\nf(a+h,a-h)=(2a,\\,(a+h)(a-h))=(2a,\\,a^{2}-h^{2})=f(a-h,a+h).\n$$\nHence $f$ is not injective on any neighborhood of $(a,a)$, so no continuous inverse can exist there. Therefore the set of points where $f$ fails to be locally invertible is exactly the line $x=y$, which is defined by the single equation $x-y=0$.\n\nA simplified expression $g(x,y)$ whose zero set gives the entire locus of non-invertibility is $g(x,y)=x-y$.", "answer": "$$\\boxed{x-y}$$", "id": "2325128"}]}