{"hands_on_practices": [{"introduction": "When faced with a sequence, how can we determine if it is consistently increasing or decreasing? While direct comparison of terms is one approach, it can be algebraically cumbersome. This practice demonstrates a powerful and elegant method from calculus: by associating the sequence $a_n$ with a continuous function $f(x)$, we can use the function's derivative to rigorously establish the sequence's monotonic behavior. This exercise [@problem_id:2307414] will equip you with a fundamental technique for analyzing sequences that are not easily handled by simple algebraic manipulation.", "problem": "Consider the sequence $\\{a_n\\}_{n=1}^{\\infty}$ where the $n$-th term is given by the formula:\n$$ a_n = n \\sin\\left(\\frac{1}{n}\\right) $$\nWhich of the following statements provides the most accurate description of the monotonic behavior of this sequence?\n\nA. The sequence is strictly increasing.\n\nB. The sequence is strictly decreasing.\n\nC. The sequence is non-increasing but not strictly decreasing.\n\nD. The sequence is non-decreasing but not strictly increasing.\n\nE. The sequence is not monotonic.", "solution": "To determine the monotonic nature of the sequence $a_n = n \\sin(\\frac{1}{n})$, we need to compare the values of consecutive terms, $a_n$ and $a_{n+1}$. A powerful method to do this is to study the behavior of a corresponding continuous function.\n\nLet's define a function $f(x)$ such that $a_n = f(1/n)$. The natural choice for $f(x)$ is:\n$$ f(x) = \\frac{\\sin(x)}{x} $$\nWith this definition, $a_n = f(1/n)$. As the index $n$ ranges from $1$ to $\\infty$, the argument of the function, $x = 1/n$, ranges over the values $1, 1/2, 1/3, \\dots$, which are all contained within the interval $(0, 1]$. We will therefore analyze the monotonicity of $f(x)$ on the interval $(0, 1]$.\n\nTo determine if $f(x)$ is increasing or decreasing, we examine the sign of its first derivative, $f'(x)$. Using the quotient rule for differentiation:\n$$ f'(x) = \\frac{d}{dx}\\left(\\frac{\\sin(x)}{x}\\right) = \\frac{x \\cos(x) - \\sin(x)}{x^2} $$\nThe sign of $f'(x)$ is determined by the sign of its numerator, since the denominator $x^2$ is always positive for $x \\in (0, 1]$. Let us define a new function $g(x) = x \\cos(x) - \\sin(x)$ and analyze its sign on the interval $(0, 1]$.\n\nTo find the sign of $g(x)$, we can study its derivative, $g'(x)$:\n$$ g'(x) = \\frac{d}{dx}(x \\cos(x) - \\sin(x)) $$\nUsing the product rule for the first term:\n$$ g'(x) = (1 \\cdot \\cos(x) + x \\cdot (-\\sin(x))) - \\cos(x) = \\cos(x) - x \\sin(x) - \\cos(x) = -x \\sin(x) $$\nFor any $x$ in the interval $(0, 1]$, we have $x > 0$. Also, for $x \\in (0, 1]$, which is a subset of $(0, \\pi)$, we have $\\sin(x) > 0$. Therefore, the product $-x \\sin(x)$ is strictly negative for all $x \\in (0, 1]$.\nSo, $g'(x) < 0$ on $(0, 1]$.\n\nSince the derivative of $g(x)$ is negative on $(0, 1]$, the function $g(x)$ is strictly decreasing on the closed interval $[0, 1]$. We can evaluate $g(x)$ at the left endpoint of this interval:\n$$ g(0) = 0 \\cdot \\cos(0) - \\sin(0) = 0 \\cdot 1 - 0 = 0 $$\nBecause $g(x)$ is strictly decreasing on $[0, 1]$ and $g(0) = 0$, it must be that for any $x > 0$ in this interval, $g(x) < g(0)$. Thus, $g(x) < 0$ for all $x \\in (0, 1]$.\n\nNow we can return to the derivative of $f(x)$:\n$$ f'(x) = \\frac{g(x)}{x^2} $$\nSince we have established that $g(x) < 0$ and we know $x^2 > 0$ for $x \\in (0, 1]$, it follows that $f'(x) < 0$ on this interval. This means that the function $f(x) = \\frac{\\sin(x)}{x}$ is strictly decreasing on $(0, 1]$.\n\nFinally, we relate this finding back to our sequence $a_n = f(1/n)$. For any integer $n \\ge 1$, we have $n+1 > n$. Taking the reciprocal of this inequality reverses its direction:\n$$ 0 < \\frac{1}{n+1} < \\frac{1}{n} \\le 1 $$\nLet $x_1 = \\frac{1}{n+1}$ and $x_2 = \\frac{1}{n}$. We have $x_1 < x_2$, and both are in the interval $(0, 1]$. Since $f(x)$ is a strictly decreasing function, $x_1 < x_2$ implies $f(x_1) > f(x_2)$.\nSubstituting back the sequence definitions:\n$$ f\\left(\\frac{1}{n+1}\\right) > f\\left(\\frac{1}{n}\\right) $$\nThis is equivalent to:\n$$ a_{n+1} > a_n $$\nThis inequality holds for all integers $n \\ge 1$. Therefore, the sequence $\\{a_n\\}$ is strictly increasing.\n\nComparing this conclusion with the given options, the most accurate description is A.", "answer": "$$\\boxed{A}$$", "id": "2307414"}, {"introduction": "A sequence's behavior is not always uniform from its very first term; many sequences only settle into a predictable pattern after some initial fluctuations. This exercise [@problem_id:2307415] introduces the important concept of *eventual monotonicity* through the lens of the classic sequence $a_n = n^{1/n}$. By finding the smallest integer $N$ for which the sequence becomes consistently decreasing, you will learn to distinguish between a sequence's initial behavior and its ultimate, long-term trend, a critical insight for studying convergence.", "problem": "Consider the sequence $\\{a_n\\}$ for positive integers $n \\geq 1$ defined by the formula $a_n = n^{1/n}$.\n\nA sequence is said to be *eventually decreasing* if there exists a positive integer $N$ such that for all integers $n \\ge N$, the inequality $a_{n+1} < a_n$ holds.\n\nFind the smallest positive integer $N$ for which the sequence $\\{a_n\\}$ is eventually decreasing.", "solution": "We consider $a_{n} = n^{1/n}$ for integers $n \\ge 1$ and seek the smallest positive integer $N$ such that $a_{n+1} < a_{n}$ holds for all $n \\ge N$.\n\nFirst, for any integer $n \\ge 1$, since $a_{n} > 0$, the inequality $a_{n+1} < a_{n}$ is equivalent to the following chain of equivalences obtained by raising both sides to the positive power $n(n+1)$ and simplifying:\n$$\na_{n+1} < a_{n}\n\\;\\;\\Longleftrightarrow\\;\\;\n(n+1)^{\\frac{1}{n+1}} < n^{\\frac{1}{n}}\n\\;\\;\\Longleftrightarrow\\;\\;\n(n+1)^{n} < n^{n+1}\n\\;\\;\\Longleftrightarrow\\;\\;\n\\left(1 + \\frac{1}{n}\\right)^{n} < n.\n$$\nThus $a_{n+1} < a_{n}$ is equivalent to $\\left(1 + \\frac{1}{n}\\right)^{n} < n$.\n\nNext, we establish a sufficient bound for all $n \\ge 3$. For any $t > 0$, the concavity of $\\ln$ implies $\\ln(1+t) < t$. Exponentiating yields $1 + t < \\exp(t)$. Setting $t = \\frac{1}{n} > 0$ and using the fact that the function $x \\mapsto x^{n}$ is increasing on $(0,\\infty)$ for fixed positive integer $n$, we obtain\n$$\n1 + \\frac{1}{n} < \\exp\\!\\left(\\frac{1}{n}\\right)\n\\;\\;\\Longrightarrow\\;\\;\n\\left(1 + \\frac{1}{n}\\right)^{n} < \\exp(1).\n$$\nWe now show $\\exp(1) < 3$. Using the series $\\exp(1) = \\sum_{k=0}^{\\infty} \\frac{1}{k!}$ and, for $k \\ge 3$, the bound $k! = 2 \\cdot 3 \\cdot 4 \\cdots k \\ge 2 \\cdot 3^{k-2}$, we have\n$$\n\\sum_{k=3}^{\\infty} \\frac{1}{k!} \\le \\frac{1}{2} \\sum_{k=3}^{\\infty} \\frac{1}{3^{\\,k-2}}\n= \\frac{1}{2} \\sum_{j=1}^{\\infty} \\frac{1}{3^{\\,j}}\n= \\frac{1}{2} \\cdot \\frac{\\frac{1}{3}}{1 - \\frac{1}{3}}\n= \\frac{1}{4}.\n$$\nTherefore,\n$$\n\\exp(1) = 1 + 1 + \\frac{1}{2} + \\sum_{k=3}^{\\infty} \\frac{1}{k!}\n\\le 1 + 1 + \\frac{1}{2} + \\frac{1}{4}\n= \\frac{11}{4}\n< 3.\n$$\nHence, for all integers $n \\ge 3$,\n$$\n\\left(1 + \\frac{1}{n}\\right)^{n} < \\exp(1) < 3 \\le n,\n$$\nwhich yields $\\left(1 + \\frac{1}{n}\\right)^{n} < n$ and thus $a_{n+1} < a_{n}$. This proves that the sequence is decreasing for all $n \\ge 3$.\n\nIt remains to show minimality. For $n=2$, the required inequality would be $a_{3} < a_{2}$, i.e., $3^{1/3} < 2^{1/2}$. Raising both sides to the sixth power gives $3^{2} < 2^{3}$, i.e., $9 < 8$, which is false. Therefore $a_{3} > a_{2}$ and $N=2$ does not work. Consequently, the smallest such $N$ is $N=3$.", "answer": "$$\\boxed{3}$$", "id": "2307415"}, {"introduction": "The Monotone Convergence Theorem is a pillar of real analysis, providing a powerful guarantee: if a sequence is both bounded and monotone, it must converge. This practice [@problem_id:15801] showcases the theorem's practical application to a famous recursive formula, Newton's method for approximating square roots. You will walk through the complete analytical process: proving the sequence is bounded and monotone, invoking the theorem to guarantee a limit exists, and finally, solving for that limit. This problem beautifully connects abstract theory with a concrete and historically significant algorithm.", "problem": "A sequence $(x_n)_{n=1}^\\infty$ is defined by the recurrence relation\n$$x_{n+1} = \\frac{1}{2} \\left( x_n + \\frac{a}{x_n} \\right)$$\nfor $n \\ge 1$, where $a$ is a positive real constant. The initial term is chosen such that $x_1 > \\sqrt{a}$.\n\nUsing the Monotone Convergence Theorem, which states that a sequence that is both monotone (non-increasing or non-decreasing) and bounded must converge, determine the limit of this sequence as $n \\to \\infty$.", "solution": "We show by induction that $x_n>\\sqrt{a}$ for all $n$. Base case: by hypothesis $x_1>\\sqrt{a}$. Assume $x_n>\\sqrt{a}$. Then by the AMâ€“GM inequality\n$$\nx_{n+1}\n=\\frac{x_n+\\frac{a}{x_n}}{2}\n\\ge \\sqrt{x_n\\cdot\\frac{a}{x_n}}\n=\\sqrt{a},\n$$\nwith strict inequality since $x_n\\neq\\sqrt{a}$. Hence $x_{n+1}>\\sqrt{a}$.\n\nNext, compute\n$$\nx_{n+1}-x_n\n=\\frac{x_n+\\frac{a}{x_n}-2x_n}{2}\n=\\frac{\\frac{a}{x_n}-x_n}{2}.\n$$\nSince $x_n^2>a$, we have $\\frac{a}{x_n}<x_n$, so $x_{n+1}-x_n<0$. Thus $(x_n)$ is strictly decreasing while bounded below by $\\sqrt{a}$, and by the Monotone Convergence Theorem converges to a limit $L\\ge\\sqrt{a}$. Taking limits in the recurrence gives\n$$\nL=\\frac{L+\\frac{a}{L}}{2}\n\\quad\\Longrightarrow\\quad\n2L=L+\\frac{a}{L}\n\\quad\\Longrightarrow\\quad\nL^2=a\n\\quad\\Longrightarrow\\quad\nL=\\sqrt{a}.\n$$", "answer": "$$\\boxed{\\sqrt{a}}$$", "id": "15801"}]}