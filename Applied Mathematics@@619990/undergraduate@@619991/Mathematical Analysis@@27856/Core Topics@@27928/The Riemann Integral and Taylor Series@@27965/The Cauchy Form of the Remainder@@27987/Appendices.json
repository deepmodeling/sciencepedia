{"hands_on_practices": [{"introduction": "Taylor's theorem guarantees the existence of an intermediate point $c$ in the remainder formula, but it doesn't provide a way to find it in general. This practice problem lifts the veil for a special class of functions—polynomials—where $c$ can be determined exactly. By directly calculating the remainder for a general cubic polynomial and equating it with the Cauchy form, you will uncover a beautifully simple and universal relationship for the intermediate point $c$. [@problem_id:1328757]", "problem": "Consider a general cubic polynomial given by $P(x) = d_3 x^3 + d_2 x^2 + d_1 x + d_0$, where the coefficients $d_i$ are real numbers and the leading coefficient $d_3$ is non-zero.\n\nLet $T_2(x;a)$ be the second-order Taylor polynomial of $P(x)$ expanded around an arbitrary point $x=a$. The corresponding remainder term is defined as $R_2(x;a) = P(x) - T_2(x;a)$.\n\nFor $x \\neq a$, Taylor's theorem with the remainder in Cauchy form states that this remainder can be expressed as:\n$$R_2(x;a) = \\frac{P'''(c)}{2!}(x-c)^2(x-a)$$\nfor some value $c$ that lies strictly between $x$ and $a$.\n\nFor this specific case of a cubic polynomial, the intermediate point $c$ is uniquely determined. Find the expression for this point $c$ in terms of $x$ and $a$. Your final answer should be a simplified expression for $c$ which does not depend on the polynomial's coefficients $d_0, d_1, d_2,$ or $d_3$.", "solution": "The problem asks for the expression of the intermediate point $c$ from the Cauchy form of the remainder for a cubic polynomial. We will find this by first calculating the remainder term directly and then equating it to the given Cauchy form.\n\nLet the cubic polynomial be $P(x) = d_3 x^3 + d_2 x^2 + d_1 x + d_0$, with $d_3 \\neq 0$.\n\nFirst, we find the remainder $R_2(x;a) = P(x) - T_2(x;a)$ by finding the full Taylor expansion of $P(x)$ around $x=a$. A polynomial of degree $n$ is its own $n$-th degree Taylor polynomial. For our cubic polynomial, the expansion around $a$ is:\n$$P(x) = P(a) + P'(a)(x-a) + \\frac{P''(a)}{2!}(x-a)^2 + \\frac{P'''(a)}{3!}(x-a)^3$$\nThe second-order Taylor polynomial $T_2(x;a)$ consists of the terms up to the second degree in $(x-a)$:\n$$T_2(x;a) = P(a) + P'(a)(x-a) + \\frac{P''(a)}{2!}(x-a)^2$$\nThe remainder $R_2(x;a)$ is the difference $P(x) - T_2(x;a)$, which is simply the next term in the series:\n$$R_2(x;a) = \\frac{P'''(a)}{3!}(x-a)^3$$\nTo evaluate this, we need the third derivative of $P(x)$:\n$P'(x) = 3d_3 x^2 + 2d_2 x + d_1$\n$P''(x) = 6d_3 x + 2d_2$\n$P'''(x) = 6d_3$\nSince the third derivative is constant, $P'''(a) = 6d_3$. Substituting this into the expression for the remainder, we get:\n$$R_2(x;a) = \\frac{6d_3}{3!}(x-a)^3 = \\frac{6d_3}{6}(x-a)^3 = d_3(x-a)^3$$\nThis is our first expression for the remainder, derived directly.\n\nNext, we use the Cauchy form of the remainder given in the problem statement:\n$$R_2(x;a) = \\frac{P'''(c)}{2!}(x-c)^2(x-a)$$\nWe know that $P'''(x) = 6d_3$ for any $x$, so $P'''(c) = 6d_3$. Substituting this into the Cauchy form:\n$$R_2(x;a) = \\frac{6d_3}{2!}(x-c)^2(x-a) = \\frac{6d_3}{2}(x-c)^2(x-a) = 3d_3(x-c)^2(x-a)$$\nThis is our second expression for the remainder.\n\nNow we equate the two expressions for $R_2(x;a)$:\n$$d_3(x-a)^3 = 3d_3(x-c)^2(x-a)$$\nSince we are given that $d_3 \\neq 0$ and the formula is for $x \\neq a$, we can divide both sides by $d_3(x-a)$:\n$$(x-a)^2 = 3(x-c)^2$$\nTo solve for $c$, we take the square root of both sides:\n$$|x-a| = \\sqrt{3}|x-c|$$\nThe problem states that $c$ lies strictly between $x$ and $a$. This implies that $x-c$ and $c-a$ have the same sign. It also means that $x-c$ and $x-a$ have the same sign.\nLet's analyze this more formally. Let's assume $x > a$. Then $a<c<x$. This means $(x-a)>0$ and $(x-c)>0$. So we can drop the absolute value signs:\n$$x-a = \\sqrt{3}(x-c)$$\nNow, we solve for $c$:\n$$x-a = \\sqrt{3}x - \\sqrt{3}c$$\n$$\\sqrt{3}c = \\sqrt{3}x - x + a$$\n$$\\sqrt{3}c = (\\sqrt{3}-1)x + a$$\n$$c = \\frac{\\sqrt{3}-1}{\\sqrt{3}}x + \\frac{1}{\\sqrt{3}}a$$\n$$c = \\left(1 - \\frac{1}{\\sqrt{3}}\\right)x + \\frac{1}{\\sqrt{3}}a$$\nIf we had assumed $x < a$, then $x<c<a$. This means $(x-a)<0$ and $(x-c)<0$. Then $|x-a|=-(x-a)=a-x$ and $|x-c|=-(x-c)=c-x$. The equation becomes:\n$$a-x = \\sqrt{3}(c-x)$$\n$$a-x = \\sqrt{3}c - \\sqrt{3}x$$\n$$\\sqrt{3}c = a - x + \\sqrt{3}x = a + (\\sqrt{3}-1)x$$\n$$c = \\frac{1}{\\sqrt{3}}a + \\frac{\\sqrt{3}-1}{\\sqrt{3}}x$$\nThis is the same expression for $c$ as in the first case. Thus, the result is independent of whether $x > a$ or $x < a$.\n\nThe other possibility from taking the square root would be $x-a = -\\sqrt{3}(x-c)$, which would lead to $c= \\left(1 + \\frac{1}{\\sqrt{3}}\\right)x - \\frac{1}{\\sqrt{3}}a$. If $x>a$, this gives $c-x = \\frac{1}{\\sqrt{3}}x - \\frac{1}{\\sqrt{3}}a = \\frac{1}{\\sqrt{3}}(x-a) > 0$, so $c>x$. This violates the condition that $c$ is between $x$ and $a$. Therefore, this solution is extraneous.\n\nThe unique expression for $c$ is:\n$$c = \\left(1 - \\frac{1}{\\sqrt{3}}\\right)x + \\frac{1}{\\sqrt{3}}a$$\nTo rationalize the denominators, we multiply the numerator and denominator by $\\sqrt{3}$:\n$$\\frac{1}{\\sqrt{3}} = \\frac{\\sqrt{3}}{3}$$\n$$1 - \\frac{1}{\\sqrt{3}} = 1 - \\frac{\\sqrt{3}}{3} = \\frac{3-\\sqrt{3}}{3}$$\nSo the final expression is:\n$$c = \\left(1 - \\frac{\\sqrt{3}}{3}\\right)x + \\frac{\\sqrt{3}}{3}a$$\nAs required, this expression for $c$ is a linear combination of $x$ and $a$ and is independent of the coefficients $d_i$.", "answer": "$$\\boxed{\\left(1 - \\frac{\\sqrt{3}}{3}\\right)x + \\frac{\\sqrt{3}}{3}a}$$", "id": "1328757"}, {"introduction": "Beyond calculating specific values, the true power of analysis often lies in making qualitative predictions. This exercise shifts our focus from finding the exact value of $c$ to using the structure of the Cauchy remainder to determine the nature of an approximation error. By simply analyzing the signs of the components in the remainder formula for the cosine function, you will be able to conclude whether its quadratic Maclaurin polynomial consistently overestimates or underestimates the function on a given interval. [@problem_id:1328782]", "problem": "According to Taylor's theorem, a function $f(x)$ that is sufficiently differentiable can be approximated near a point $a$ by its Taylor polynomial $P_n(x)$. The error in this approximation is given by a remainder term $R_n(x)$, such that $f(x) = P_n(x) + R_n(x)$. One form of the remainder, for a function $f$ that is $(n+1)$ times differentiable on an open interval $I$ containing $a$, is the Cauchy form:\n$$R_n(x) = \\frac{f^{(n+1)}(c)}{n!}(x-a)(x-c)^n$$\nfor some number $c$ strictly between $a$ and $x$.\n\nLet $f(x) = \\cos(x)$ and let $P_2(x)$ be its quadratic Maclaurin polynomial (i.e., the Taylor polynomial of degree 2 centered at $a=0$). By analyzing the sign of the Cauchy remainder term $R_2(x)$, determine if $P_2(x)$ provides an overestimate or an underestimate of $f(x)$ on the open interval $(0, \\frac{\\pi}{2})$.\n\nChoose the correct statement from the options below.\n\nA. $P_2(x)$ is an overestimate of $f(x)$ on the entire interval $(0, \\frac{\\pi}{2})$.\n\nB. $P_2(x)$ is an underestimate of $f(x)$ on the entire interval $(0, \\frac{\\pi}{2})$.\n\nC. $P_2(x)$ is an overestimate on $(0, \\frac{\\pi}{4})$ and an underestimate on $(\\frac{\\pi}{4}, \\frac{\\pi}{2})$.\n\nD. $P_2(x)$ is an underestimate on $(0, \\frac{\\pi}{4})$ and an overestimate on $(\\frac{\\pi}{4}, \\frac{\\pi}{2})$.\n\nE. $P_2(x)$ is exactly equal to $f(x)$ on the entire interval $(0, \\frac{\\pi}{2})$.", "solution": "We take $f(x)=\\cos(x)$ and its quadratic Maclaurin polynomial $P_{2}(x)$ given by the Taylor expansion at $a=0$:\n$$\nP_{2}(x)=f(0)+f'(0)x+\\frac{f''(0)}{2!}x^{2}.\n$$\nSince $f(0)=1$, $f'(x)=-\\sin(x)$ so $f'(0)=0$, and $f''(x)=-\\cos(x)$ so $f''(0)=-1$, we obtain\n$$\nP_{2}(x)=1-\\frac{x^{2}}{2}.\n$$\nBy the Cauchy form of the remainder with $n=2$ and $a=0$,\n$$\nR_{2}(x)=\\frac{f^{(3)}(c)}{2!}\\,x\\,(x-c)^{2}\n$$\nfor some $c$ strictly between $0$ and $x$. For $f(x)=\\cos(x)$, we have $f^{(3)}(x)=\\sin(x)$, hence\n$$\nR_{2}(x)=\\frac{\\sin(c)}{2}\\,x\\,(x-c)^{2}.\n$$\nOn the interval $x\\in(0,\\frac{\\pi}{2})$, we have $x>0$ and $c\\in(0,x)\\subset(0,\\frac{\\pi}{2})$, which implies $\\sin(c)>0$ and $(x-c)^{2}>0$. Therefore $R_{2}(x)>0$ for all $x\\in(0,\\frac{\\pi}{2})$. Since $f(x)=P_{2}(x)+R_{2}(x)$, it follows that $f(x)>P_{2}(x)$ on $(0,\\frac{\\pi}{2})$, so $P_{2}(x)$ underestimates $f(x)$ on the entire interval.\n\nThus the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1328782"}, {"introduction": "Having explored how a function's properties determine the remainder, we now flip the script: what if we know a property of the remainder's intermediate point $c$? This advanced practice poses such an \"inverse problem,\" where a specific, simple behavior for $c$ is assumed. By translating this assumption into a functional-differential equation, you will characterize the entire family of functions satisfying this condition, revealing the profound connection between a function and its Taylor approximation error. [@problem_id:1328769]", "problem": "According to Taylor's theorem, for a sufficiently differentiable function $f(x)$, the first-order expansion around $a=0$ is given by $f(x) = f(0) + f'(0)x + R_1(x)$, where $R_1(x)$ is the remainder term. In its Cauchy form, the remainder is expressed as $R_1(x) = f''(c)(x-c)x$ for some number $c$ strictly between $0$ and $x$.\n\nConsider a function $f(x)$ that is three times continuously differentiable (i.e., $f \\in C^3(\\mathbb{R})$). This function has a special property: for any non-zero $x$ in the domain of $f$, the value of the intermediate point $c$ in the Cauchy form of its first-order remainder is always $c=x/2$.\n\nGiven that $f(0) = C_0$, $f'(0) = C_1$, and $f''(0) = C_2$, determine the expression for $f(x)$. Your answer should be in terms of $x$ and the constants $C_0, C_1, C_2$.", "solution": "The problem provides the first-order Taylor expansion of a function $f(x)$ around $a=0$:\n$$f(x) = f(0) + f'(0)x + R_1(x)$$\nThe remainder term, $R_1(x)$, is given in its Cauchy form as:\n$$R_1(x) = f''(c)(x-c)x$$\nwhere $c$ is a number between $0$ and $x$.\n\nThe problem states that for the specific function $f(x)$ in question, the intermediate point $c$ is always given by $c = x/2$. We can substitute this into the expression for the remainder:\n$$R_1(x) = f''(x/2)\\left(x-\\frac{x}{2}\\right)x = f''(x/2)\\left(\\frac{x}{2}\\right)x = \\frac{x^2}{2}f''(x/2)$$\n\nNow, we can substitute this specific form of $R_1(x)$ back into the Taylor expansion equation. We can also express $R_1(x)$ directly from the expansion as $R_1(x) = f(x) - f(0) - f'(0)x$. Equating the two expressions for $R_1(x)$ gives us a functional-differential equation for $f(x)$:\n$$f(x) - f(0) - f'(0)x = \\frac{x^2}{2} f''(x/2)$$\n\nTo solve for $f(x)$, we can assume that $f(x)$ has a Taylor series representation around $x=0$, which is justified by the smoothness condition ($f \\in C^3$). Let the Taylor series be:\n$$f(x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(0)}{k!} x^k$$\nLet's denote the derivatives at zero as $d_k = f^{(k)}(0)$. The series is $f(x) = \\sum_{k=0}^{\\infty} \\frac{d_k}{k!} x^k$.\nThe left-hand side (LHS) of our functional equation is:\n$$f(x) - f(0) - f'(0)x = \\left(\\sum_{k=0}^{\\infty} \\frac{d_k}{k!} x^k\\right) - d_0 - d_1 x = \\sum_{k=2}^{\\infty} \\frac{d_k}{k!} x^k$$\n\nFor the right-hand side (RHS), we first need the second derivative of $f(x)$:\n$$f''(x) = \\frac{d}{dx^2} \\left(\\sum_{k=0}^{\\infty} \\frac{d_k}{k!} x^k\\right) = \\sum_{k=2}^{\\infty} \\frac{d_k}{k!} k(k-1) x^{k-2} = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)!} x^{k-2}$$\nNow, we evaluate this at $x/2$:\n$$f''(x/2) = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)!} \\left(\\frac{x}{2}\\right)^{k-2} = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)! 2^{k-2}} x^{k-2}$$\nFinally, we multiply by $x^2/2$ to get the RHS:\n$$\\frac{x^2}{2} f''(x/2) = \\frac{x^2}{2} \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)! 2^{k-2}} x^{k-2} = \\sum_{k=2}^{\\infty} \\frac{d_k}{2 \\cdot (k-2)! 2^{k-2}} x^k = \\sum_{k=2}^{\\infty} \\frac{d_k}{(k-2)! 2^{k-1}} x^k$$\n\nNow we equate the coefficients of the power series for the LHS and RHS for each power of $x^k$ where $k \\ge 2$:\n$$\\frac{d_k}{k!} = \\frac{d_k}{(k-2)! 2^{k-1}}$$\nThis can be rewritten as:\n$$d_k \\left( \\frac{1}{k!} - \\frac{1}{(k-2)! 2^{k-1}} \\right) = 0$$\n$$d_k \\left( \\frac{1}{k(k-1)(k-2)!} - \\frac{1}{(k-2)! 2^{k-1}} \\right) = 0$$\nFor this equation to hold, for each $k \\ge 2$, either $d_k=0$ or the term in the parenthesis must be zero. Let's analyze the term in the parenthesis:\n$$\\frac{1}{k(k-1)} = \\frac{1}{2^{k-1}} \\quad \\implies \\quad k(k-1) = 2^{k-1}$$\n\nLet's test this equality for integer values of $k \\ge 2$:\n- For $k=2$: $2(2-1) = 2$. And $2^{2-1} = 2^1 = 2$. The equality holds.\n- For $k=3$: $3(3-1) = 6$. And $2^{3-1} = 2^2 = 4$. The equality does not hold ($6 \\neq 4$).\n- For $k=4$: $4(4-1) = 12$. And $2^{4-1} = 2^3 = 8$. The equality does not hold ($12 \\neq 8$).\n\nFor $k \\ge 4$, the exponential function $2^{k-1}$ grows much faster than the quadratic function $k(k-1)$. We can prove by induction that $2^{k-1} > k(k-1)$ for $k \\ge 6$ (and we can check $k=4,5$ manually). Thus, the equality $k(k-1) = 2^{k-1}$ only holds for $k=2$.\n\nSo, our coefficient equation $d_k \\left( \\frac{1}{k(k-1)} - \\frac{1}{2^{k-1}} \\right) = 0$ implies:\n- For $k=2$: $d_2 \\left( \\frac{1}{2} - \\frac{1}{2} \\right) = 0 \\implies d_2 \\cdot 0 = 0$. This gives no restriction on $d_2$; it can be any arbitrary value.\n- For $k \\ge 3$: Since $k(k-1) \\neq 2^{k-1}$, the term in the parenthesis is non-zero. Therefore, we must have $d_k = 0$.\n\nThis means that all derivatives of $f(x)$ at $x=0$ of order 3 and higher are zero: $f^{(k)}(0) = 0$ for $k \\ge 3$.\nConsequently, the Taylor series for $f(x)$ terminates, and the function must be a polynomial of degree at most 2:\n$$f(x) = \\frac{d_0}{0!}x^0 + \\frac{d_1}{1!}x^1 + \\frac{d_2}{2!}x^2 = d_0 + d_1 x + \\frac{d_2}{2} x^2$$\n\nThe problem provides the values for the first three derivatives at $x=0$:\n$d_0 = f(0) = C_0$\n$d_1 = f'(0) = C_1$\n$d_2 = f''(0) = C_2$\n\nSubstituting these constants into our expression for $f(x)$:\n$$f(x) = C_0 + C_1 x + \\frac{C_2}{2} x^2$$\nThis is the general form of any $C^3$ function satisfying the given condition.", "answer": "$$\n\\boxed{C_0 + C_1 x + \\frac{C_2}{2} x^{2}}\n$$", "id": "1328769"}]}