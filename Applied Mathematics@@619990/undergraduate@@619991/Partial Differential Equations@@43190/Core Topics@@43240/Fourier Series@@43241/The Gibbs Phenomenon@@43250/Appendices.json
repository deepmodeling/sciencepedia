{"hands_on_practices": [{"introduction": "Our exploration of the Gibbs phenomenon begins with a direct and concrete calculation. While the full theory involves limits and infinite series, we can observe the tell-tale overshoot even with a very low-order partial sum of a Fourier series. This exercise [@problem_id:2143534] asks you to compute the overshoot for a simple approximation of a square wave, making the abstract concept of approximation error tangible and setting the stage for a deeper analysis.", "id": "2143534", "problem": "Consider a square wave function $f(x)$ defined on the interval $[-\\pi, \\pi]$ as follows:\n$$\nf(x) = \\begin{cases}\n-1 & \\text{if } -\\pi < x < 0 \\\\\n0 & \\text{if } x = 0, \\pm\\pi \\\\\n1 & \\text{if } 0 < x < \\pi\n\\end{cases}\n$$\nThe function is extended periodically outside this interval. The Fourier series representation for this odd function is given by:\n$$\nf(x) \\sim \\frac{4}{\\pi} \\sum_{n=1,3,5,...}^{\\infty} \\frac{\\sin(nx)}{n} = \\frac{4}{\\pi} \\left( \\sin(x) + \\frac{1}{3}\\sin(3x) + \\frac{1}{5}\\sin(5x) + \\dots \\right)\n$$\nThe Gibbs phenomenon describes how the partial sums of the Fourier series overshoot the function's value at a jump discontinuity. Let us investigate this for a low-order partial sum.\n\nConsider the partial sum $S_3(x)$, which includes terms up to $n=3$:\n$$\nS_3(x) = \\frac{4}{\\pi} \\left( \\sin(x) + \\frac{1}{3}\\sin(3x) \\right)\n$$\nAt a point near the discontinuity at $x=0$, such as $x=\\frac{\\pi}{4}$, this partial sum will exceed the function's true value of $f(\\frac{\\pi}{4})=1$.\n\nCalculate the percentage overshoot of the partial sum $S_3(x)$ at the point $x=\\frac{\\pi}{4}$. The percentage overshoot is defined as the difference between the partial sum's value and the function's true value, divided by the function's true value. Express your answer as a decimal rounded to three significant figures. For example, a 15% overshoot should be written as 0.150.\n\n", "solution": "We are given the partial sum\n$$\nS_{3}(x)=\\frac{4}{\\pi}\\left(\\sin(x)+\\frac{1}{3}\\sin(3x)\\right),\n$$\nand we evaluate it at $x=\\frac{\\pi}{4}$. Using the trigonometric values $\\sin\\left(\\frac{\\pi}{4}\\right)=\\frac{\\sqrt{2}}{2}$ and the identity $\\sin\\left(3\\cdot\\frac{\\pi}{4}\\right)=\\sin\\left(\\pi-\\frac{\\pi}{4}\\right)=\\sin\\left(\\frac{\\pi}{4}\\right)=\\frac{\\sqrt{2}}{2}$, we obtain\n$$\nS_{3}\\left(\\frac{\\pi}{4}\\right)=\\frac{4}{\\pi}\\left(\\frac{\\sqrt{2}}{2}+\\frac{1}{3}\\cdot\\frac{\\sqrt{2}}{2}\\right)\n=\\frac{4}{\\pi}\\cdot\\frac{\\sqrt{2}}{2}\\left(1+\\frac{1}{3}\\right)\n=\\frac{4}{\\pi}\\cdot\\frac{\\sqrt{2}}{2}\\cdot\\frac{4}{3}\n=\\frac{8\\sqrt{2}}{3\\pi}.\n$$\nSince $f\\left(\\frac{\\pi}{4}\\right)=1$, the percentage overshoot (defined as $\\frac{S_{3}-f}{f}$) at $x=\\frac{\\pi}{4}$ is\n$$\n\\frac{S_{3}\\left(\\frac{\\pi}{4}\\right)-f\\left(\\frac{\\pi}{4}\\right)}{f\\left(\\frac{\\pi}{4}\\right)}\n=\\frac{\\frac{8\\sqrt{2}}{3\\pi}-1}{1}\n=\\frac{8\\sqrt{2}}{3\\pi}-1.\n$$\nTo express this as a decimal rounded to three significant figures, we evaluate numerically only at the end:\n$$\n\\frac{8\\sqrt{2}}{3\\pi}-1\\approx 0.200421754\\ldots\n$$\nRounding to three significant figures gives $0.200$.", "answer": "$$\\boxed{0.200}$$"}, {"introduction": "Having seen the Gibbs phenomenon in action, we now investigate its root cause. This overshoot is not a universal feature of Fourier series; it appears only under specific conditions related to the smoothness of the function being approximated. This practice [@problem_id:2143572] challenges you to determine which functions will produce this effect, shifting the focus from 'what' to 'why' and highlighting the critical role of jump discontinuities in the function's periodic extension.", "id": "2143572", "problem": "Consider the following functions, each defined on the interval $[0, \\pi]$:\nI. $f_1(x) = \\sin(x)$\nII. $f_2(x) = \\cos(x)$\nIII. $f_3(x) = x(\\pi - x)$\nIV. $f_4(x) = (\\pi - x)^2$\n\nFor each function, a corresponding Fourier sine series is constructed on the interval $[0, \\pi]$. Which of the above functions will have a Fourier sine series that exhibits the Gibbs phenomenon?\n\nA. I and III only\nB. II and IV only\nC. I and II only\nD. III and IV only\nE. II only\n\n", "solution": "A Fourier sine series on $[0,\\pi]$ corresponds to the odd $2\\pi$-periodic extension of the function $f$ defined on $[0,\\pi]$. Define the odd extension by\n$$\nf_{\\text{odd}}(x)=\n\\begin{cases}\nf(x), & x\\in [0,\\pi],\\\\\n-f(-x), & x\\in [-\\pi,0],\n\\end{cases}\n$$\nand then extend $2\\pi$-periodically to all $x\\in \\mathbb{R}$. The Gibbs phenomenon occurs precisely near points where the periodic extension has jump discontinuities. For a sine series, jumps occur at the endpoints if $f(0)\\neq 0$ or $f(\\pi)\\neq 0$; if $f(0)=f(\\pi)=0$ and $f$ is sufficiently smooth on $[0,\\pi]$, the odd periodic extension is continuous and the Gibbs phenomenon does not occur.\n\nApply this to each function:\n\nI. $f_{1}(x)=\\sin x$. Here $f_{1}(0)=0$ and $f_{1}(\\pi)=0$. Moreover, $\\sin x$ already equals its own odd $2\\pi$-periodic extension, so there are no jump discontinuities. Therefore, no Gibbs phenomenon.\n\nII. $f_{2}(x)=\\cos x$. Here $f_{2}(0)=1$ and $f_{2}(\\pi)=-1$. The odd extension near $x=0$ has right limit $1$ and left limit $-1$, so there is a jump of size $2$ at $x=0$. At $x=\\pi$, the left limit is $-1$ while the right limit, obtained from periodicity and oddness, is $1$, producing another jump. Therefore, the Fourier sine series exhibits the Gibbs phenomenon.\n\nIII. $f_{3}(x)=x(\\pi-x)$. Here $f_{3}(0)=0$ and $f_{3}(\\pi)=0$. The odd periodic extension is continuous at $x=0$ and $x=\\pi$ (and smooth on the interior), so there are no jump discontinuities. Therefore, no Gibbs phenomenon.\n\nIV. $f_{4}(x)=(\\pi-x)^{2}$. Here $f_{4}(0)=\\pi^{2}$ and $f_{4}(\\pi)=0$. The odd extension has a jump at $x=0$ since the right limit is $\\pi^{2}$ and the left limit is $-\\pi^{2}$, but it is continuous at $x=\\pi$ (both one-sided limits tend to $0$). Therefore, the Fourier sine series exhibits the Gibbs phenomenon.\n\nHence, only II and IV exhibit the Gibbs phenomenon, which corresponds to option B.", "answer": "$$\\boxed{B}$$"}, {"introduction": "We now arrive at the quantitative heart of the Gibbs phenomenon. A curious and initially counter-intuitive feature is that adding more terms to the Fourier series does not eliminate the overshoot but merely narrows it and pushes it closer to the discontinuity. This final exercise [@problem_id:1301521] guides you through the classic derivation to find the precise limiting value of this persistent overshoot, revealing one of the most elegant and surprising results in the study of Fourier analysis.", "id": "1301521", "problem": "Consider a $2\\pi$-periodic function $f(x)$, which for $x \\in (-\\pi, \\pi]$ is defined as:\n$$\nf(x) = \\begin{cases}\n-1 & \\text{if } -\\pi < x < 0 \\\\\n0 & \\text{if } x = 0 \\\\\n1 & \\text{if } 0 < x \\le \\pi\n\\end{cases}\n$$\nThe Fourier series for this function is given by the form $\\sum_{n=1}^\\infty b_n \\sin(nx)$. Let $S_N(x) = \\sum_{n=1}^N b_n \\sin(nx)$ denote the $N$-th partial sum of this series. For any given finite $N$, $S_N(x)$ is a differentiable function. Let $x_N^*$ be the smallest positive value of $x$ for which the derivative $S_N'(x)$ is zero.\n\nYour task is to find the limiting value of the partial sum at this extremum point as $N$ grows indefinitely. Specifically, compute the value of $L = \\lim_{N \\to \\infty} S_N(x_N^*)$.\n\nExpress your answer as a numerical value rounded to four significant figures.\n\n", "solution": "The problem asks for the limiting value of the first positive maximum of the partial Fourier sums for a given square wave function. The procedure involves first finding the Fourier coefficients, then identifying the location of the maximum for the $N$-th partial sum, and finally evaluating the sum at that point in the limit as $N \\to \\infty$.\n\n**Step 1: Calculate the Fourier coefficients $b_n$.**\nThe function $f(x)$ as defined is an odd function, since $f(-x) = -f(x)$. For an odd function, the Fourier cosine coefficients $a_n$ (including $a_0$) are all zero. The sine coefficients $b_n$ are given by:\n$$b_n = \\frac{1}{\\pi} \\int_{-\\pi}^{\\pi} f(x) \\sin(nx) dx$$\nSince $f(x)\\sin(nx)$ is a product of two odd functions, it is an even function. Therefore, the integral can be simplified:\n$$b_n = \\frac{2}{\\pi} \\int_{0}^{\\pi} f(x) \\sin(nx) dx$$\nFor $x \\in (0, \\pi]$, $f(x) = 1$. So we have:\n$$b_n = \\frac{2}{\\pi} \\int_{0}^{\\pi} (1) \\sin(nx) dx = \\frac{2}{\\pi} \\left[ -\\frac{\\cos(nx)}{n} \\right]_{0}^{\\pi}$$\n$$b_n = \\frac{2}{n\\pi} [-\\cos(n\\pi) - (-\\cos(0))] = \\frac{2}{n\\pi} [1 - \\cos(n\\pi)]$$\nThe value of $\\cos(n\\pi)$ is $1$ for even $n$ and $-1$ for odd $n$.\n- If $n$ is even (i.e., $n=2k$ for some integer $k \\ge 1$), $b_{2k} = \\frac{2}{2k\\pi}(1-1) = 0$.\n- If $n$ is odd (i.e., $n=2k-1$ for some integer $k \\ge 1$), $b_{2k-1} = \\frac{2}{(2k-1)\\pi}(1-(-1)) = \\frac{4}{(2k-1)\\pi}$.\n\n**Step 2: Find the location of the first positive extremum, $x_N^*$.**\nThe partial sum is $S_N(x) = \\sum_{n=1}^N b_n \\sin(nx)$. Since $b_n=0$ for even $n$, the sum only includes terms for odd $n$. Let $N$ be a large odd integer, $N = 2M-1$ for some large integer $M$.\n$$S_{2M-1}(x) = \\sum_{k=1}^{M} b_{2k-1} \\sin((2k-1)x) = \\sum_{k=1}^{M} \\frac{4}{(2k-1)\\pi} \\sin((2k-1)x)$$\nNote that if $N$ is even, $N=2M$, then $S_{2M}(x) = S_{2M-1}(x)$ because $b_{2M}=0$. Thus, analyzing the limit for odd $N$ is sufficient.\nTo find the extremum, we compute the derivative $S_N'(x)$ and set it to zero. Let's use $N=2M-1$.\n$$S_{2M-1}'(x) = \\frac{d}{dx} \\left( \\sum_{k=1}^{M} \\frac{4}{(2k-1)\\pi} \\sin((2k-1)x) \\right) = \\sum_{k=1}^{M} \\frac{4}{\\pi} \\cos((2k-1)x)$$\nThis is a sum of cosines. We can evaluate it using a known formula, or by considering the real part of a geometric series:\n$$ \\sum_{k=1}^{M} \\cos((2k-1)x) = \\text{Re} \\left( \\sum_{k=1}^{M} e^{i(2k-1)x} \\right) $$\nThe sum inside is a geometric series with first term $e^{ix}$, ratio $e^{i2x}$, and $M$ terms. The sum is:\n$$ e^{ix} \\frac{1 - (e^{i2x})^M}{1 - e^{i2x}} = e^{ix} \\frac{1 - e^{i2Mx}}{1 - e^{i2x}} = e^{ix} \\frac{e^{iMx}(e^{-iMx} - e^{iMx})}{e^{ix}(e^{-ix} - e^{ix})} = e^{iMx} \\frac{-2i\\sin(Mx)}{-2i\\sin(x)} = \\frac{\\sin(Mx)}{\\sin(x)} e^{iMx} $$\nThe real part is $\\frac{\\sin(Mx)\\cos(Mx)}{\\sin(x)} = \\frac{\\sin(2Mx)}{2\\sin(x)}$. So,\n$$S_{2M-1}'(x) = \\frac{4}{\\pi} \\frac{\\sin(2Mx)}{2\\sin(x)}$$\nWe set $S_{2M-1}'(x) = 0$ to find the extrema. This requires $\\sin(2Mx)=0$, for $x\\neq 0, \\pm \\pi, \\dots$.\nThe solutions are $2Mx = k\\pi$ for any integer $k$. So, $x = \\frac{k\\pi}{2M}$.\nThe smallest positive value $x_N^*$ (with $N=2M-1$) corresponds to $k=1$.\n$$x_{2M-1}^* = \\frac{\\pi}{2M}$$\nAs noted before, if $N=2M$, $S_{2M}'(x)=S_{2M-1}'(x)$, so the first extremum is at $x_{2M}^*=\\frac{\\pi}{2M}=\\frac{\\pi}{N}$. If $N=2M-1$, then $x_{2M-1}^*=\\frac{\\pi}{2M}=\\frac{\\pi}{N+1}$. For large $N$, these locations are very close. We proceed with $x_N^* = \\frac{\\pi}{N+1}$ where $N=2M-1$.\n\n**Step 3: Evaluate the limit of the partial sum at the extremum.**\nWe need to compute $L = \\lim_{N \\to \\infty} S_N(x_N^*)$. We take the limit as $M \\to \\infty$, with $N=2M-1$.\n$$ L = \\lim_{M\\to\\infty} S_{2M-1}\\left(\\frac{\\pi}{2M}\\right) = \\lim_{M\\to\\infty} \\sum_{k=1}^{M} \\frac{4}{(2k-1)\\pi} \\sin\\left((2k-1)\\frac{\\pi}{2M}\\right) $$\nLet's rearrange the sum to see it as a Riemann sum:\n$$ L = \\lim_{M\\to\\infty} \\frac{2}{\\pi} \\sum_{k=1}^{M} \\frac{\\sin\\left(\\frac{(2k-1)\\pi}{2M}\\right)}{\\frac{(2k-1)}{2M}} \\left(\\frac{1}{M}\\right) $$\nLet's define a function $g(t) = \\frac{\\sin(t)}{t}$. Let's partition the interval $[0, \\pi]$ into $M$ subintervals of equal width $\\Delta t = \\frac{\\pi}{M}$. The midpoints of these subintervals $[ (k-1)\\frac{\\pi}{M}, k\\frac{\\pi}{M} ]$ are $t_k = \\frac{(2k-1)\\pi}{2M}$.\nThe sum can be expressed as:\n$$ S_{2M-1}\\left(\\frac{\\pi}{2M}\\right) = \\frac{2}{\\pi} \\sum_{k=1}^{M} \\frac{\\sin(t_k)}{t_k} \\frac{\\pi}{M} = \\frac{2}{\\pi} \\sum_{k=1}^{M} g(t_k) \\Delta t $$\nThis is a midpoint Riemann sum for the function $g(t) = \\frac{2}{\\pi} \\frac{\\sin(t)}{t}$ over the interval $[0, \\pi]$. In the limit as $M \\to \\infty$, the Riemann sum converges to the definite integral:\n$$ L = \\int_0^\\pi \\frac{2}{\\pi} \\frac{\\sin(t)}{t} dt = \\frac{2}{\\pi} \\int_0^\\pi \\frac{\\sin(t)}{t} dt $$\nThis integral is related to the sine integral function, $\\text{Si}(x) = \\int_0^x \\frac{\\sin(t)}{t} dt$.\nSo, $L = \\frac{2}{\\pi} \\text{Si}(\\pi)$.\n\n**Step 4: Numerical Calculation.**\nThe value of the integral must be found numerically.\n$$ \\text{Si}(\\pi) = \\int_0^\\pi \\frac{\\sin(t)}{t} dt \\approx 1.85193705 $$\nTherefore, the limiting value is:\n$$ L = \\frac{2}{\\pi} \\text{Si}(\\pi) \\approx \\frac{2}{3.14159265...} \\times 1.85193705... \\approx 1.17897974... $$\nRounding to four significant figures, we get $1.179$.", "answer": "$$\\boxed{1.179}$$"}]}