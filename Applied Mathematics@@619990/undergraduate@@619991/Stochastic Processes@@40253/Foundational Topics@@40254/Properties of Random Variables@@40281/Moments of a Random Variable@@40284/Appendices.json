{"hands_on_practices": [{"introduction": "Understanding the moments of a random variable begins with the most fundamental measures: the mean and the variance. This first exercise provides a direct application of these concepts to a discrete system, modeling charge flow in a simplified biophysical scenario. By calculating the variance, you will practice the core computational skills for quantifying the spread or variability of a distribution using its probability mass function and the formula $\\operatorname{Var}(X) = E[X^2] - (E[X])^2$. [@problem_id:1937448]", "problem": "In a simplified biophysical model of a neuron's membrane, the net flow of charge through a specific ion channel during a short, fixed time interval is quantized. We can model this net flow using a discrete random variable $X$, which represents the number of elementary charge units crossing the membrane. A positive value for $X$ indicates a net outward flow, while a negative value indicates a net inward flow. Based on extensive experimental data, the probability distribution for $X$ over this time interval has been determined as follows:\n- The probability of one elementary charge moving inward, corresponding to $X = -1$, is $0.2$.\n- The probability of no net charge movement, corresponding to $X = 0$, is $0.5$.\n- The probability of one elementary charge moving outward, corresponding to $X = 1$, is $0.3$.\n\nCalculate the variance of the random variable $X$.", "solution": "We are given a discrete random variable $X$ with probabilities $P(X=-1)=0.2$, $P(X=0)=0.5$, and $P(X=1)=0.3$. The variance is defined by\n$$\n\\operatorname{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}.\n$$\nFirst compute the expectation using $\\mathbb{E}[X]=\\sum x\\,P(X=x)$:\n$$\n\\mathbb{E}[X]=(-1)(0.2)+0(0.5)+1(0.3)=-0.2+0+0.3=0.1.\n$$\nNext compute the second moment using $\\mathbb{E}[X^{2}]=\\sum x^{2}P(X=x)$:\n$$\n\\mathbb{E}[X^{2}]=(-1)^{2}(0.2)+0^{2}(0.5)+1^{2}(0.3)=0.2+0+0.3=0.5.\n$$\nTherefore,\n$$\n\\operatorname{Var}(X)=0.5-(0.1)^{2}=0.5-0.01=0.49.\n$$", "answer": "$$\\boxed{0.49}$$", "id": "1937448"}, {"introduction": "We now advance to a higher-order moment for one of the most important distributions in probability, the Binomial distribution. This problem guides you to find the third central moment, $E[(X - E[X])^3]$, which serves as a measure of a distribution's asymmetry or skewness. The approach taken here is particularly instructive, as it leverages the structure of a Binomial variable as a sum of independent and identically distributed Bernoulli trials to greatly simplify the calculation. [@problem_id:1319680]", "problem": "In a digital manufacturing process, a machine produces a large batch of $n$ identical components. Due to minute fluctuations in the fabrication environment, each component has an independent probability $p$ of failing a quality control test, and a probability $1-p$ of passing. Let the random variable $X$ denote the total number of components that fail the test within a single batch.\n\nThe third central moment of a random variable, defined as $E[(X - E[X])^3]$, is a measure of the skewness or asymmetry of its probability distribution.\n\nFind a closed-form analytic expression for the third central moment of the random variable $X$ in terms of the parameters $n$ and $p$.", "solution": "Let $X$ denote the total number of failures in a batch of $n$ independent components, each failing with probability $p$. Model $X$ as a sum of independent Bernoulli random variables: define $X_{i} \\in \\{0,1\\}$ with $\\Pr(X_{i}=1)=p$ and $\\Pr(X_{i}=0)=1-p$, and write $X=\\sum_{i=1}^{n} X_{i}$. Then $E[X_{i}]=p$ and $E[X]=\\sum_{i=1}^{n}E[X_{i}]=np$.\n\nDefine the centered variables $Y_{i}=X_{i}-p$, so that $E[Y_{i}]=0$. The third central moment of $X$ is\n$$\nE\\big[(X-E[X])^{3}\\big]=E\\bigg[\\bigg(\\sum_{i=1}^{n} Y_{i}\\bigg)^{3}\\bigg].\n$$\nUsing the multinomial expansion,\n$$\n\\bigg(\\sum_{i=1}^{n} Y_{i}\\bigg)^{3}=\\sum_{i=1}^{n} Y_{i}^{3}+3\\sum_{i\\neq j} Y_{i}^{2}Y_{j}+6\\sum_{1\\leq i<j<k\\leq n} Y_{i}Y_{j}Y_{k}.\n$$\nTaking expectations and using independence together with $E[Y_{i}]=0$ yields\n$$\nE\\left[\\sum_{i\\neq j} Y_{i}^{2}Y_{j}\\right]=\\sum_{i\\neq j} E[Y_{i}^{2}]E[Y_{j}]=0,\\quad\nE\\left[\\sum_{i<j<k} Y_{i}Y_{j}Y_{k}\\right]=\\sum_{i<j<k} E[Y_{i}]E[Y_{j}]E[Y_{k}]=0.\n$$\nTherefore,\n$$\nE\\big[(X-E[X])^{3}\\big]=\\sum_{i=1}^{n} E[Y_{i}^{3}]=n\\,E[(X_{1}-p)^{3}],\n$$\nsince the $Y_{i}$ are identically distributed.\n\nTo compute $E[(X_{1}-p)^{3}]$ for a Bernoulli$(p)$ variable $X_{1}$, note that $X_{1}-p$ equals $(1-p)$ with probability $p$ and $-p$ with probability $(1-p)$. Hence,\n$$\nE[(X_{1}-p)^{3}]=p(1-p)^{3}+(1-p)(-p)^{3}\n= p(1-3p+3p^{2}-p^{3})-(1-p)p^{3}\n= p-3p^{2}+2p^{3}\n= p(1-p)(1-2p).\n$$\nSubstituting back gives the third central moment of $X$:\n$$\nE\\big[(X-E[X])^{3}\\big]=n\\,p(1-p)(1-2p).\n$$\nThis is a closed-form expression in terms of $n$ and $p$.", "answer": "$$\\boxed{n\\,p(1-p)(1-2p)}$$", "id": "1319680"}, {"introduction": "This final practice problem challenges you to think in reverse: instead of calculating moments from a given distribution, you will construct a distribution based on a set of moment constraints. This exercise powerfully illustrates a crucial concept: that the mean and variance alone are not sufficient to uniquely define a distribution. By building a distribution that shares the same mean and variance as a symmetric one but possesses a non-zero third moment, you will gain a deeper appreciation for how moments collectively characterize the shape and properties of a random variable. [@problem_id:1937417]", "problem": "An analyst is studying two different stochastic processes, which generate integer-valued data. The outputs of these processes are modeled by two distinct discrete random variables, $X$ and $Y$. Both variables are known to have a distribution described by a Probability Mass Function (PMF) supported on exactly three distinct integer values.\n\nThrough preliminary analysis, it has been determined that both variables share the same mean, $\\mu = 0$, and the same variance, $\\sigma^2 = 2$. To distinguish the two processes, the analyst decides to compute their third central moments. Since the mean is zero, these are given by $\\mu_{3,X} = E[X^3]$ and $\\mu_{3,Y} = E[Y^3]$.\n\nIt is known that the distribution of $X$ is symmetric about its mean. The support set for $X$ is of the form $\\{-a, 0, a\\}$ for some positive integer $a$.\nThe distribution of $Y$ is not symmetric. The support set for $Y$ is of the form $\\{-b, 0, c\\}$ for some distinct positive integers $b$ and $c$.\n\nTo ensure a unique construction for $Y$, assume that $b$ and $c$ are chosen from the set of positive integers such that their sum $b+c$ is minimized. Additionally, assume $b < c$.\n\nCalculate the value of the third central moment of $Y$, which is $\\mu_{3,Y}$. Express your answer as an exact fraction or an integer.", "solution": "The problem asks for the third central moment of a random variable $Y$, whose distribution must be constructed based on a set of given conditions. Let's break down the problem into two parts: first, characterizing the distribution of $X$, and second, constructing the distribution of $Y$ to find its third central moment.\n\n**Part 1: Characterizing the distribution of X**\n\nThe random variable $X$ has a support set $S_X = \\{-a, 0, a\\}$, where $a$ is a positive integer. Let the probabilities be $P(X=-a) = p_{-a}$, $P(X=0) = p_0$, and $P(X=a) = p_a$.\n\nThe sum of probabilities must be 1:\n$p_{-a} + p_0 + p_a = 1$.\n\nThe mean is given as $\\mu = 0$:\n$E[X] = (-a)p_{-a} + (0)p_0 + (a)p_a = a(p_a - p_{-a}) = 0$.\nSince $a > 0$, this implies $p_a = p_{-a}$. This is also consistent with the given information that the distribution is symmetric.\n\nLet's call this common probability $p = p_a = p_{-a}$. The sum of probabilities becomes $2p + p_0 = 1$, so $p_0 = 1 - 2p$. For $p_0$ to be a valid probability, $1 - 2p \\ge 0$, which implies $p \\le 1/2$.\n\nThe variance is given as $\\sigma^2 = 2$. Since the mean is 0, the variance is equal to the second raw moment $E[X^2]$.\n$\\text{Var}(X) = E[X^2] = (-a)^2 p_{-a} + (0)^2 p_0 + (a)^2 p_a = a^2 p + a^2 p = 2pa^2$.\nWe are given $\\text{Var}(X) = 2$, so we have the equation:\n$2pa^2 = 2 \\implies pa^2 = 1$.\n\nSubstituting $p = 1/a^2$ into the constraint $p \\le 1/2$, we get $1/a^2 \\le 1/2$, which means $a^2 \\ge 2$.\nSince $a$ must be a positive integer, the smallest possible value for $a$ is $2$. Although any integer $a \\ge 2$ could define a valid distribution for $X$, the properties of $X$ are only used to establish the target mean and variance. We can proceed with the established values of $\\mu=0$ and $\\sigma^2=2$.\n\nThe third central moment of $X$ is $\\mu_{3,X} = E[X^3]$.\n$\\mu_{3,X} = (-a)^3 p + (0)^3 (1-2p) + (a)^3 p = -a^3 p + a^3 p = 0$.\nThis confirms that the symmetric distribution has a zero third central moment, as expected.\n\n**Part 2: Constructing the distribution of Y**\n\nThe random variable $Y$ has a support set $S_Y = \\{-b, 0, c\\}$, where $b$ and $c$ are distinct positive integers with $b < c$. Let the probabilities be $P(Y=-b) = q_{-b}$, $P(Y=0) = q_0$, and $P(Y=c) = q_c$.\n\nThe sum of probabilities is 1: $q_{-b} + q_0 + q_c = 1$.\n\nThe mean is $\\mu = 0$:\n$E[Y] = (-b)q_{-b} + (0)q_0 + (c)q_c = c q_c - b q_{-b} = 0 \\implies q_c = \\frac{b}{c} q_{-b}$.\n\nThe variance is $\\sigma^2 = 2$:\n$\\text{Var}(Y) = E[Y^2] = (-b)^2 q_{-b} + (0)^2 q_0 + (c)^2 q_c = b^2 q_{-b} + c^2 q_c = 2$.\n\nNow we solve for the probabilities in terms of $b$ and $c$. Substitute $q_c = \\frac{b}{c} q_{-b}$ into the variance equation:\n$b^2 q_{-b} + c^2 \\left(\\frac{b}{c} q_{-b}\\right) = 2$\n$b^2 q_{-b} + bc q_{-b} = 2$\n$q_{-b}(b^2 + bc) = 2 \\implies q_{-b}(b(b+c)) = 2$\n$q_{-b} = \\frac{2}{b(b+c)}$.\n\nUsing this, we find $q_c$:\n$q_c = \\frac{b}{c} q_{-b} = \\frac{b}{c} \\frac{2}{b(b+c)} = \\frac{2}{c(b+c)}$.\n\nFinally, we find $q_0$ from the sum of probabilities:\n$q_0 = 1 - q_{-b} - q_c = 1 - \\frac{2}{b(b+c)} - \\frac{2}{c(b+c)} = 1 - \\frac{2c + 2b}{bc(b+c)} = 1 - \\frac{2(b+c)}{bc(b+c)} = 1 - \\frac{2}{bc}$.\n\nFor $\\{q_{-b}, q_0, q_c\\}$ to be a valid PMF for a three-point distribution, all probabilities must be strictly positive. $q_{-b}$ and $q_c$ are positive since $b, c > 0$. For $q_0 > 0$, we require:\n$1 - \\frac{2}{bc} > 0 \\implies 1 > \\frac{2}{bc} \\implies bc > 2$.\n\nThe problem states that we must choose a pair of distinct positive integers $(b,c)$ with $b<c$ that minimizes the sum $b+c$, subject to the constraint $bc>2$. Let's test possible values for $b$:\n- If $b=1$: The constraint becomes $c > 2$. Since $c$ must be an integer, the smallest possible value for $c$ is $3$. This gives the pair $(1,3)$. Here, $b \\ne c$ and $b<c$ are satisfied. The sum is $b+c = 1+3=4$.\n- If $b=2$: The constraint becomes $2c > 2$, so $c > 1$. Since we require $b < c$, the smallest possible integer value for $c$ is $3$. This gives the pair $(2,3)$. The sum is $b+c = 2+3=5$.\n- If $b=3$: The constraint is $3c>2$, so $c>2/3$. Since $b<c$, smallest integer $c$ is 4. The sum is $b+c=3+4=7$.\n\nComparing the sums, the minimum sum is $4$, which corresponds to the unique pair $(b,c) = (1,3)$.\n\nNow we can determine the specific PMF for $Y$:\nSupport $S_Y = \\{-1, 0, 3\\}$.\n$q_{-1} = \\frac{2}{1(1+3)} = \\frac{2}{4} = \\frac{1}{2}$.\n$q_3 = \\frac{2}{3(1+3)} = \\frac{2}{12} = \\frac{1}{6}$.\n$q_0 = 1 - \\frac{2}{1 \\cdot 3} = 1 - \\frac{2}{3} = \\frac{1}{3}$.\nSo, the PMF for $Y$ is $P(Y=-1) = 1/2$, $P(Y=0) = 1/3$, and $P(Y=3) = 1/6$.\n\n**Part 3: Calculating the third central moment of Y**\n\nThe final step is to calculate $\\mu_{3,Y} = E[Y^3]$:\n$\\mu_{3,Y} = E[Y^3] = (-1)^3 P(Y=-1) + (0)^3 P(Y=0) + (3)^3 P(Y=3)$\n$\\mu_{3,Y} = (-1)\\left(\\frac{1}{2}\\right) + (0)\\left(\\frac{1}{3}\\right) + (27)\\left(\\frac{1}{6}\\right)$\n$\\mu_{3,Y} = -\\frac{1}{2} + \\frac{27}{6} = -\\frac{3}{6} + \\frac{27}{6} = \\frac{24}{6} = 4$.\n\nThe third central moment of $Y$ is 4.", "answer": "$$\\boxed{4}$$", "id": "1937417"}]}