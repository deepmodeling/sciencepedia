{"hands_on_practices": [{"introduction": "A fundamental skill in probability is translating a physical or geometric description of a random process into a precise mathematical model. This practice challenges you to define a joint probability density function for two variables chosen uniformly from a triangular region [@problem_id:1313752]. By calculating the covariance, you will not only practice integrating over non-rectangular domains but also gain a tangible understanding of how geometric constraints can induce statistical dependence between random variables.", "problem": "A point $(X, Y)$ is chosen uniformly at random from a two-dimensional region. This region is a triangle in the Cartesian plane defined by the vertices $(0,0)$, $(a,0)$, and $(0,b)$. The parameters $a$ and $b$ are positive real constants.\n\nYour task is to determine the covariance between the random variables $X$ and $Y$. Provide your answer as a closed-form analytic expression in terms of $a$ and $b$.", "solution": "Let $T$ denote the triangular region $\\{(x,y): x \\geq 0,\\ y \\geq 0,\\ \\frac{x}{a}+\\frac{y}{b} \\leq 1\\}$ with vertices $(0,0)$, $(a,0)$, and $(0,b)$. Its area is $\\frac{ab}{2}$. Since $(X,Y)$ is uniformly distributed on $T$, the joint density is\n$$\nf_{X,Y}(x,y) = \\frac{2}{ab} \\quad \\text{for } (x,y) \\in T,\\quad \\text{and } 0 \\text{ otherwise}.\n$$\nThe covariance is defined by\n$$\n\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y].\n$$\n\nFirst, compute $\\mathbb{E}[X]$ using $\\mathbb{E}[X] = \\iint_{T} x f_{X,Y}(x,y)\\,dx\\,dy$. For each $x \\in [0,a]$, $y$ ranges from $0$ to $b\\left(1-\\frac{x}{a}\\right)$, hence\n$$\n\\mathbb{E}[X] = \\frac{2}{ab} \\int_{0}^{a} \\int_{0}^{b\\left(1-\\frac{x}{a}\\right)} x \\, dy \\, dx\n= \\frac{2}{ab} \\int_{0}^{a} x \\cdot b\\left(1-\\frac{x}{a}\\right) dx\n= \\frac{2}{ab} \\, b \\int_{0}^{a} \\left(x - \\frac{x^{2}}{a}\\right) dx.\n$$\nEvaluate the integral:\n$$\n\\int_{0}^{a} \\left(x - \\frac{x^{2}}{a}\\right) dx\n= \\left[\\frac{x^{2}}{2} - \\frac{x^{3}}{3a}\\right]_{0}^{a}\n= \\frac{a^{2}}{2} - \\frac{a^{3}}{3a}\n= \\frac{a^{2}}{2} - \\frac{a^{2}}{3}\n= \\frac{a^{2}}{6}.\n$$\nTherefore,\n$$\n\\mathbb{E}[X] = \\frac{2}{ab} \\cdot b \\cdot \\frac{a^{2}}{6} = \\frac{a}{3}.\n$$\n\nSimilarly, compute $\\mathbb{E}[Y]$ using $\\mathbb{E}[Y] = \\iint_{T} y f_{X,Y}(x,y)\\,dx\\,dy$:\n$$\n\\mathbb{E}[Y] = \\frac{2}{ab} \\int_{0}^{a} \\int_{0}^{b\\left(1-\\frac{x}{a}\\right)} y \\, dy \\, dx\n= \\frac{2}{ab} \\int_{0}^{a} \\left[\\frac{y^{2}}{2}\\right]_{0}^{b\\left(1-\\frac{x}{a}\\right)} dx\n= \\frac{2}{ab} \\int_{0}^{a} \\frac{b^{2}}{2} \\left(1 - \\frac{x}{a}\\right)^{2} dx.\n$$\nExpand and integrate:\n$$\n\\int_{0}^{a} \\left(1 - \\frac{2x}{a} + \\frac{x^{2}}{a^{2}}\\right) dx\n= \\left[x\\right]_{0}^{a} - \\frac{2}{a}\\left[\\frac{x^{2}}{2}\\right]_{0}^{a} + \\frac{1}{a^{2}}\\left[\\frac{x^{3}}{3}\\right]_{0}^{a}\n= a - a + \\frac{a}{3}\n= \\frac{a}{3}.\n$$\nThus,\n$$\n\\mathbb{E}[Y] = \\frac{2}{ab} \\cdot \\frac{b^{2}}{2} \\cdot \\frac{a}{3} = \\frac{b}{3}.\n$$\n\nNext, compute $\\mathbb{E}[XY]$:\n$$\n\\mathbb{E}[XY] = \\frac{2}{ab} \\int_{0}^{a} \\int_{0}^{b\\left(1-\\frac{x}{a}\\right)} x y \\, dy \\, dx\n= \\frac{2}{ab} \\int_{0}^{a} x \\left[\\frac{y^{2}}{2}\\right]_{0}^{b\\left(1-\\frac{x}{a}\\right)} dx\n= \\frac{2}{ab} \\int_{0}^{a} x \\cdot \\frac{b^{2}}{2} \\left(1 - \\frac{x}{a}\\right)^{2} dx.\n$$\nSimplify and integrate:\n$$\n\\mathbb{E}[XY] = \\frac{b^{2}}{ab} \\int_{0}^{a} x \\left(1 - \\frac{2x}{a} + \\frac{x^{2}}{a^{2}}\\right) dx\n= \\frac{b}{a} \\int_{0}^{a} \\left(x - \\frac{2x^{2}}{a} + \\frac{x^{3}}{a^{2}}\\right) dx.\n$$\nCompute each term:\n$$\n\\int_{0}^{a} x \\, dx = \\frac{a^{2}}{2}, \\quad\n\\int_{0}^{a} \\frac{2x^{2}}{a} \\, dx = \\frac{2}{a} \\cdot \\frac{a^{3}}{3} = \\frac{2a^{2}}{3}, \\quad\n\\int_{0}^{a} \\frac{x^{3}}{a^{2}} \\, dx = \\frac{1}{a^{2}} \\cdot \\frac{a^{4}}{4} = \\frac{a^{2}}{4}.\n$$\nThus,\n$$\n\\int_{0}^{a} x \\left(1 - \\frac{2x}{a} + \\frac{x^{2}}{a^{2}}\\right) dx\n= \\frac{a^{2}}{2} - \\frac{2a^{2}}{3} + \\frac{a^{2}}{4}\n= a^{2} \\left(\\frac{1}{2} - \\frac{2}{3} + \\frac{1}{4}\\right)\n= a^{2} \\cdot \\frac{1}{12}\n= \\frac{a^{2}}{12}.\n$$\nTherefore,\n$$\n\\mathbb{E}[XY] = \\frac{b}{a} \\cdot \\frac{a^{2}}{12} = \\frac{ab}{12}.\n$$\n\nFinally, use the covariance formula:\n$$\n\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n= \\frac{ab}{12} - \\left(\\frac{a}{3}\\right)\\left(\\frac{b}{3}\\right)\n= \\frac{ab}{12} - \\frac{ab}{9}\n= ab \\left(\\frac{1}{12} - \\frac{1}{9}\\right)\n= -\\frac{ab}{36}.\n$$", "answer": "$$\\boxed{-\\frac{ab}{36}}$$", "id": "1313752"}, {"introduction": "Joint distributions are particularly powerful because they allow us to update our beliefs about one variable when we gain information about another. This exercise provides a direct application of this principle by asking for a conditional probability from a given joint density function [@problem_id:1313701]. Mastering this type of calculation is essential for understanding concepts from statistical inference to the behavior of stochastic systems, showcasing how knowing the value of one variable, $X$, influences the probabilities associated with another, $Y$.", "problem": "Two random variables, $X$ and $Y$, represent the coordinates of a point selected from the unit square defined by the region $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$. The selection process is governed by a joint probability density function (PDF) given by:\n$$\nf(x, y) = \n\\begin{cases} \nc(x^2 + y)  \\text{if } 0 \\leq x \\leq 1 \\text{ and } 0 \\leq y \\leq 1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nwhere $c$ is a normalization constant.\n\nCalculate the conditional probability $P(Y  1/2 \\mid X = 1/2)$. Express your answer as a fraction.", "solution": "We use the definition of conditional probability for continuous random variables via the joint PDF along the line where $X$ is fixed. For $x \\in [0,1]$, the conditional probability\n$$\nP(Y  a \\mid X = x) = \\frac{\\int_{a}^{1} f(x,y)\\,dy}{\\int_{0}^{1} f(x,y)\\,dy}.\n$$\nHere $a=\\frac{1}{2}$ and $x=\\frac{1}{2}$, and the joint PDF on the unit square is $f(x,y)=c(x^{2}+y)$. Therefore,\n$$\nP\\!\\left(Y  \\frac{1}{2} \\mid X = \\frac{1}{2}\\right)\n= \\frac{\\int_{\\frac{1}{2}}^{1} c\\left(\\left(\\frac{1}{2}\\right)^{2}+y\\right)\\,dy}{\\int_{0}^{1} c\\left(\\left(\\frac{1}{2}\\right)^{2}+y\\right)\\,dy}\n= \\frac{\\int_{\\frac{1}{2}}^{1} c\\left(\\frac{1}{4}+y\\right)\\,dy}{\\int_{0}^{1} c\\left(\\frac{1}{4}+y\\right)\\,dy}.\n$$\nCompute the numerator:\n$$\n\\int_{\\frac{1}{2}}^{1} c\\left(\\frac{1}{4}+y\\right)\\,dy\n= c\\left[\\frac{1}{4}y+\\frac{1}{2}y^{2}\\right]_{\\frac{1}{2}}^{1}\n= c\\left(\\left(\\frac{1}{4}+\\frac{1}{2}\\right)-\\left(\\frac{1}{8}+\\frac{1}{8}\\right)\\right)\n= c\\left(\\frac{3}{4}-\\frac{1}{4}\\right)\n= c\\cdot\\frac{1}{2}.\n$$\nCompute the denominator:\n$$\n\\int_{0}^{1} c\\left(\\frac{1}{4}+y\\right)\\,dy\n= c\\left[\\frac{1}{4}y+\\frac{1}{2}y^{2}\\right]_{0}^{1}\n= c\\left(\\frac{1}{4}+\\frac{1}{2}\\right)\n= c\\cdot\\frac{3}{4}.\n$$\nTaking the ratio, the constant $c$ cancels:\n$$\nP\\!\\left(Y  \\frac{1}{2} \\mid X = \\frac{1}{2}\\right)\n= \\frac{c\\cdot\\frac{1}{2}}{c\\cdot\\frac{3}{4}}\n= \\frac{1}{2}\\cdot\\frac{4}{3}\n= \\frac{2}{3}.\n$$", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "1313701"}, {"introduction": "In many scientific and engineering applications, the parameters of a model are not known with certainty but are themselves random variables. This exercise introduces a powerful hierarchical modeling approach where the probability of success in a series of trials is not a fixed constant but is drawn from a distribution [@problem_id:1313740]. By applying the law of total probability, you will learn how to integrate over this parameter uncertainty to find the overall probability of an outcome, a foundational technique in Bayesian statistics.", "problem": "In a novel semiconductor manufacturing process, the probability $P$ of a single dopant atom successfully implanting in a target region is not fixed. Due to quantum fluctuations in the substrate, $P$ behaves as a random variable that is uniformly distributed over the interval $[0, 1]$. For a single manufactured chip, three independent implantation attempts are made. The outcomes of the attempts are conditionally independent given the value of $P$. Let $S_3$ be the total number of successful implantations in these three attempts.\n\nCalculate the probability that exactly one implantation is successful, that is, $P(S_3=1)$.\n\nProvide your answer as a fraction in simplest form.", "solution": "Let $S_3$ be the random variable representing the total number of successful implantations in three attempts. We are asked to find the unconditional probability $P(S_3=1)$. The probability of success in any given attempt, $P$, is itself a random variable with a uniform distribution on $[0, 1]$. Let's denote the specific value of the random variable $P$ as $p$. The probability density function (PDF) of $P$ is given by:\n$$\nf_P(p) =\n\\begin{cases}\n1  \\text{for } 0 \\le p \\le 1 \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nTo find the unconditional probability $P(S_3=1)$, we must average the conditional probability $P(S_3=1 | P=p)$ over all possible values of $p$, weighted by the PDF of $P$. This is an application of the law of total probability for a continuous conditioning variable:\n$$P(S_3=1) = \\int_{-\\infty}^{\\infty} P(S_3=1 | P=p) f_P(p) dp$$\nGiven a fixed probability of success $p$, the three implantation attempts are independent Bernoulli trials. The total number of successes, $S_3$, therefore follows a binomial distribution with parameters $n=3$ and probability $p$. The probability mass function (PMF) for a binomial distribution is $P(S_n=k | P=p) = \\binom{n}{k} p^k (1-p)^{n-k}$.\n\nFor our case, with $n=3$ and $k=1$, the conditional probability is:\n$$P(S_3=1 | P=p) = \\binom{3}{1} p^1 (1-p)^{3-1} = 3p(1-p)^2$$\nNow, we can substitute this conditional probability and the PDF $f_P(p)$ into the integral. Since $f_P(p)$ is non-zero only for $p \\in [0, 1]$, the limits of integration become 0 to 1:\n$$P(S_3=1) = \\int_0^1 \\left(3p(1-p)^2\\right) \\cdot 1 \\, dp$$\nLet's evaluate this definite integral. First, expand the term $(1-p)^2$:\n$$(1-p)^2 = 1 - 2p + p^2$$\nSo the integrand is:\n$$3p(1 - 2p + p^2) = 3p - 6p^2 + 3p^3$$\nNow, integrate this polynomial with respect to $p$ from 0 to 1:\n$$P(S_3=1) = \\int_0^1 (3p - 6p^2 + 3p^3) dp$$\n$$P(S_3=1) = \\left[ 3\\frac{p^2}{2} - 6\\frac{p^3}{3} + 3\\frac{p^4}{4} \\right]_0^1$$\n$$P(S_3=1) = \\left[ \\frac{3}{2}p^2 - 2p^3 + \\frac{3}{4}p^4 \\right]_0^1$$\nEvaluate the expression at the upper limit $p=1$ and subtract the value at the lower limit $p=0$:\n$$P(S_3=1) = \\left( \\frac{3}{2}(1)^2 - 2(1)^3 + \\frac{3}{4}(1)^4 \\right) - \\left( \\frac{3}{2}(0)^2 - 2(0)^3 + \\frac{3}{4}(0)^4 \\right)$$\n$$P(S_3=1) = \\left( \\frac{3}{2} - 2 + \\frac{3}{4} \\right) - 0$$\nTo simplify the expression, we find a common denominator, which is 4:\n$$P(S_3=1) = \\frac{3 \\cdot 2}{2 \\cdot 2} - \\frac{2 \\cdot 4}{4} + \\frac{3}{4}$$\n$$P(S_3=1) = \\frac{6}{4} - \\frac{8}{4} + \\frac{3}{4}$$\n$$P(S_3=1) = \\frac{6 - 8 + 3}{4} = \\frac{1}{4}$$\nThus, the probability of exactly one successful implantation is $\\frac{1}{4}$.", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "1313740"}]}