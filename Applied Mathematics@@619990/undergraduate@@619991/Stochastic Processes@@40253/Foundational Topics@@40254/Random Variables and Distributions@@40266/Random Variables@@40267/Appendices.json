{"hands_on_practices": [{"introduction": "A foundational concept for any random variable is its expected value, which represents the long-term average outcome of a random process. This practice [@problem_id:1329530] provides a concrete scenario in system performance analysis, where you will calculate the average computational cost by weighting each possible cost by its probability of occurrence. Mastering this calculation is the first step toward summarizing and predicting the behavior of complex random systems.", "problem": "A systems administrator is analyzing the performance of a web server. Based on historical data, the server handles four types of requests: GET, POST, PUT, and DELETE. The processing cost for each request type, measured in a standardized unit of CPU cycles, and the probability of each request type occurring are given as follows:\n\n- A GET request consumes 50 CPU cycles and occurs with a probability of 0.65.\n- A POST request consumes 150 CPU cycles and occurs with a probability of 0.25.\n- A PUT request consumes 250 CPU cycles and occurs with a probability of 0.07.\n- A DELETE request consumes 200 CPU cycles and occurs with a probability of 0.03.\n\nAssuming each incoming request is an independent event, calculate the expected number of CPU cycles consumed per request. Express your answer in CPU cycles, rounded to three significant figures.", "solution": "Let $C$ be the random variable representing CPU cycles per request. The possible outcomes and their probabilities are:\n- GET: $c_{1}=50$ with $p_{1}=0.65$,\n- POST: $c_{2}=150$ with $p_{2}=0.25$,\n- PUT: $c_{3}=250$ with $p_{3}=0.07$,\n- DELETE: $c_{4}=200$ with $p_{4}=0.03$.\n\nFirst, verify that the probabilities form a valid distribution:\n$$p_{1}+p_{2}+p_{3}+p_{4}=0.65+0.25+0.07+0.03=1.$$\n\nUsing the definition and linearity of expectation for a discrete random variable,\n$$\\mathbb{E}[C]=\\sum_{i=1}^{4} p_{i}c_{i}.$$\n\nSubstitute the given values and compute step by step:\n$$\\mathbb{E}[C]=0.65\\cdot 50+0.25\\cdot 150+0.07\\cdot 250+0.03\\cdot 200,$$\n$$=32.5+37.5+17.5+6,$$\n$$=93.5.$$\n\nRounded to three significant figures, the expected CPU cycles per request is $93.5$.", "answer": "$$\\boxed{93.5}$$", "id": "1329530"}, {"introduction": "While discrete variables take on specific values, many real-world phenomena, like time, are best modeled as continuous. For these, we use a probability density function (PDF), and its integral, the cumulative distribution function (CDF), gives the probability that a variable falls at or below a certain value. In this exercise [@problem_id:1329537], you will derive the CDF for a qubit's lifetime, a process modeled by the ubiquitous exponential distribution, providing a fundamental tool for reliability and survival analysis.", "problem": "In a simplified model of a quantum computer, the lifetime of a quantum bit (qubit) is the time until it succumbs to environmental noise, a process known as decoherence. Let the random variable $T$ represent the lifetime of a single qubit, measured in some arbitrary unit of time. The behavior of $T$ is described by a probability density function (PDF) given by:\n$$p(t) = \\begin{cases} \\delta \\exp(-\\delta t)  \\text{for } t \\ge 0 \\\\ 0  \\text{for } t  0 \\end{cases}$$\nwhere $\\delta$ is a positive constant representing the decoherence rate.\n\nDetermine the cumulative distribution function (CDF), $F(t) = P(T \\le t)$, for the qubit's lifetime. Your answer should be the expression for $F(t)$ valid for $t \\ge 0$.", "solution": "The cumulative distribution function is defined by the integral of the probability density function up to the argument:\n$$F(t)=P(T\\le t)=\\int_{-\\infty}^{t}p(s)\\,ds.$$\nGiven the PDF\n$$p(t)=\\begin{cases}\\delta \\exp(-\\delta t)  \\text{for } t\\ge 0 \\\\ 0  \\text{for } t0 \\end{cases},$$\nfor $t0$ we have $F(t)=0$ because $p(s)=0$ for all $s\\le t0$. For $t\\ge 0$, the integral reduces to\n$$F(t)=\\int_{-\\infty}^{t}p(s)\\,ds=\\int_{0}^{t}\\delta \\exp(-\\delta s)\\,ds.$$\nCompute the integral using the antiderivative of $\\exp(-\\delta s)$:\n$$\\int_{0}^{t}\\delta \\exp(-\\delta s)\\,ds=\\left[-\\exp(-\\delta s)\\right]_{s=0}^{s=t}=1-\\exp(-\\delta t).$$\nThus, for $t\\ge 0$,\n$$F(t)=1-\\exp(-\\delta t).$$\nThis satisfies $F(0)=0$ and $\\lim_{t\\to\\infty}F(t)=1$, as required for a valid CDF.", "answer": "$$\\boxed{1-\\exp(-\\delta t)}$$", "id": "1329537"}, {"introduction": "When analyzing systems with multiple components, we must understand how random variables interact. A common measure of their linear relationship is covariance, but a frequent pitfall is assuming that zero covariance implies independence. This problem [@problem_id:1922916] is designed to directly challenge that misconception by presenting a carefully constructed scenario where two variables are uncorrelated yet clearly dependent. Working through this example will sharpen your understanding of the precise mathematical conditions for statistical independence.", "problem": "Consider a pair of discrete random variables $(X, Y)$ whose joint probability mass function (PMF), denoted by $p(x, y) = P(X=x, Y=y)$, has non-zero values only at four specific points. These probabilities are given as:\n- $p(-1, 0) = \\frac{1}{3}$\n- $p(1, 0) = \\frac{1}{6}$\n- $p(0, -1) = \\frac{1}{4}$\n- $p(0, 1) = \\frac{1}{4}$\n\nFor all other pairs $(x, y)$, the joint PMF is $p(x, y) = 0$.\n\nYour task is to compute two quantities based on this distribution. First, calculate the covariance between $X$ and $Y$, denoted as $\\text{Cov}(X,Y)$. Second, calculate the value of $\\delta = P(X=1)P(Y=0) - P(X=1, Y=0)$, which is a measure related to the independence of the events $\\{X=1\\}$ and $\\{Y=0\\}$.\n\nPresent your final answer as an ordered pair $(\\text{Cov}(X,Y), \\delta)$.", "solution": "We use the definitions of expectation and covariance for discrete random variables. The covariance is defined by $\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]$. The given joint PMF has support at $(-1,0)$ with probability $\\frac{1}{3}$, $(1,0)$ with probability $\\frac{1}{6}$, $(0,-1)$ with probability $\\frac{1}{4}$, and $(0,1)$ with probability $\\frac{1}{4}$, and zero elsewhere. The total probability is $\\frac{1}{3}+\\frac{1}{6}+\\frac{1}{4}+\\frac{1}{4}=1$, so it is a valid PMF.\n\nFirst, compute the marginals. For $X$:\n$$\nP(X=-1)=\\frac{1}{3},\\quad P(X=1)=\\frac{1}{6},\\quad P(X=0)=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}.\n$$\nFor $Y$:\n$$\nP(Y=0)=\\frac{1}{3}+\\frac{1}{6}=\\frac{1}{2},\\quad P(Y=-1)=\\frac{1}{4},\\quad P(Y=1)=\\frac{1}{4}.\n$$\n\nCompute expectations using $\\mathbb{E}[X]=\\sum_{x} x\\,P(X=x)$ and $\\mathbb{E}[Y]=\\sum_{y} y\\,P(Y=y)$:\n$$\n\\mathbb{E}[X]=(-1)\\cdot \\frac{1}{3}+1\\cdot \\frac{1}{6}+0\\cdot \\frac{1}{2}=-\\frac{1}{6},\n$$\n$$\n\\mathbb{E}[Y]=0\\cdot \\frac{1}{2}+(-1)\\cdot \\frac{1}{4}+1\\cdot \\frac{1}{4}=0.\n$$\n\nCompute $\\mathbb{E}[XY]$ using $\\mathbb{E}[XY]=\\sum_{x,y} xy\\,p(x,y)$ over the support:\n$$\n\\mathbb{E}[XY]=(-1\\cdot 0)\\cdot \\frac{1}{3}+(1\\cdot 0)\\cdot \\frac{1}{6}+(0\\cdot (-1))\\cdot \\frac{1}{4}+(0\\cdot 1)\\cdot \\frac{1}{4}=0.\n$$\n\nTherefore, by the covariance formula,\n$$\n\\operatorname{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y]=0-\\left(-\\frac{1}{6}\\right)\\cdot 0=0.\n$$\n\nNext, compute $\\delta=P(X=1)P(Y=0)-P(X=1,Y=0)$ from the marginals and joint probability:\n$$\n\\delta=\\left(\\frac{1}{6}\\right)\\left(\\frac{1}{2}\\right)-\\frac{1}{6}=\\frac{1}{12}-\\frac{1}{6}=-\\frac{1}{12}.\n$$\n\nThus, the ordered pair $(\\operatorname{Cov}(X,Y),\\delta)$ is $\\left(0,-\\frac{1}{12}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} 0  -\\frac{1}{12} \\end{pmatrix}}$$", "id": "1922916"}]}