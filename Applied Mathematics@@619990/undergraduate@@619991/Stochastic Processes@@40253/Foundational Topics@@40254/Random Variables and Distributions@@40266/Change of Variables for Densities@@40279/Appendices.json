{"hands_on_practices": [{"introduction": "We begin with the most fundamental type of transformation: a linear scaling and shifting of a random variable. This type of operation is ubiquitous in science and engineering, from converting units of measurement to amplifying a signal in a communication system. This exercise [@problem_id:1287712] provides essential practice in applying the basic change of variables rule for a simple, one-to-one function, demonstrating how the parameters of a distribution, like the mean and variance of a Gaussian, are predictably altered.", "problem": "A standard one-dimensional Brownian motion, denoted by $W_t$, is a fundamental stochastic process. At any fixed time $t > 0$, the value of the process, $W_t$, is a normally distributed random variable with a mean of 0 and a variance of $t$. The Probability Density Function (PDF) for $W_t$ is given by\n$$ f_{W_t}(x) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^2}{2t}\\right) $$\nfor $x \\in (-\\infty, \\infty)$.\n\nConsider a new stochastic process, $Y_t$, which models a signal that is an amplified and shifted version of the Brownian motion. It is defined by the transformation $Y_t = a W_t + b$, where $a$ and $b$ are non-zero real constants.\n\nDetermine the PDF of the random variable $Y_t$ for a fixed time $t > 0$.", "solution": "We start from the given fact that for fixed $t>0$, $W_{t}$ is normally distributed with mean $0$ and variance $t$, with PDF\n$$\nf_{W_{t}}(x)=\\frac{1}{\\sqrt{2\\pi t}}\\exp\\!\\left(-\\frac{x^{2}}{2t}\\right), \\quad x\\in\\mathbb{R}.\n$$\nDefine the transformed variable $Y_{t}=aW_{t}+b$ with $a\\neq 0$ and $b\\in\\mathbb{R}$. Since this is a linear, hence monotone, transformation, we apply the change-of-variables formula for PDFs. Let $g(w)=aw+b$ and $g^{-1}(y)=(y-b)/a$. Then\n$$\nf_{Y_{t}}(y)=f_{W_{t}}(g^{-1}(y))\\left|\\frac{d}{dy}g^{-1}(y)\\right|=f_{W_{t}}\\!\\left(\\frac{y-b}{a}\\right)\\cdot\\frac{1}{|a|}.\n$$\nSubstituting the explicit form of $f_{W_{t}}$ gives\n$$\nf_{Y_{t}}(y)=\\frac{1}{|a|}\\cdot\\frac{1}{\\sqrt{2\\pi t}}\\exp\\!\\left(-\\frac{\\left(\\frac{y-b}{a}\\right)^{2}}{2t}\\right)\n=\\frac{1}{|a|\\sqrt{2\\pi t}}\\exp\\!\\left(-\\frac{(y-b)^{2}}{2a^{2}t}\\right), \\quad y\\in\\mathbb{R}.\n$$\nEquivalently, this identifies $Y_{t}\\sim\\mathcal{N}(b,a^{2}t)$ for fixed $t>0$.", "answer": "$$\\boxed{f_{Y_{t}}(y)=\\frac{1}{|a|\\sqrt{2\\pi t}}\\,\\exp\\!\\left(-\\frac{(y-b)^{2}}{2a^{2}t}\\right)}$$", "id": "1287712"}, {"introduction": "Many physical processes and mathematical models involve functions that are not one-to-one, such as taking the magnitude of a signal where both positive and negative values map to the same positive output. This problem [@problem_id:1287723] challenges you to handle a classic \"many-to-one\" transformation, $Y = |X|$, which requires a more careful approach than the direct formula used for monotonic functions. It is an excellent opportunity to practice the robust and universally applicable cumulative distribution function (CDF) method for deriving a new density.", "problem": "A random variable $X$ is said to follow the standard Laplace distribution if its probability density function (PDF), $f_X(x)$, is given by:\n$$f_X(x) = \\frac{1}{2} \\exp(-|x|)$$\nfor all real numbers $x$.\nNow, consider a new random variable $Y$ which is derived from $X$ through the transformation $Y = |X|$. Determine the probability density function $f_Y(y)$ for the domain where $y \\geq 0$. Your answer should be a single analytic expression in terms of $y$.", "solution": "We are given a standard Laplace random variable $X$ with density $f_{X}(x) = \\frac{1}{2}\\exp(-|x|)$ for all real $x$, and the transformation $Y = |X|$. For $y \\geq 0$, we can derive the distribution of $Y$ via its cumulative distribution function:\n$$\nF_{Y}(y) = \\Pr(Y \\leq y) = \\Pr(|X| \\leq y) = \\Pr(-y \\leq X \\leq y) = \\int_{-y}^{y} \\frac{1}{2}\\exp(-|x|)\\,dx.\n$$\nUsing the symmetry of the integrand and the fact that for $x \\geq 0$, $|x| = x$, we obtain\n$$\n\\int_{-y}^{y} \\frac{1}{2}\\exp(-|x|)\\,dx = 2 \\int_{0}^{y} \\frac{1}{2}\\exp(-x)\\,dx = \\int_{0}^{y} \\exp(-x)\\,dx = 1 - \\exp(-y).\n$$\nDifferentiating $F_{Y}(y)$ with respect to $y$ yields the density of $Y$ for $y \\geq 0$:\n$$\nf_{Y}(y) = \\frac{d}{dy}F_{Y}(y) = \\exp(-y).\n$$\nThis matches the alternative many-to-one transformation formula $f_{Y}(y) = f_{X}(y) + f_{X}(-y)$ for $y > 0$, since $f_{X}(y) = \\frac{1}{2}\\exp(-y)$ and $f_{X}(-y) = \\frac{1}{2}\\exp(-y)$, giving $f_{Y}(y) = \\exp(-y)$, and continuity at $y=0$ preserves the same value.", "answer": "$$\\boxed{\\exp(-y)}$$", "id": "1287723"}, {"introduction": "Moving from one dimension to many is a critical step in modeling the real world, where phenomena are often described by the interplay of multiple random influences. This capstone practice extends our skills to the multivariate domain, asking us to find the distribution of a single quantity derived from two independent random variables. By working through this exercise [@problem_id:1287711], you will learn to use the Jacobian determinant for transformations in higher dimensions, a powerful technique for understanding complex systems and deriving important distributions like the Rayleigh distribution from more fundamental ones.", "problem": "Consider a simplified model for the diffusion of a particle on a two-dimensional plane. The particle starts at the origin $(0,0)$. After a certain time, its position is described by the coordinates $(X, Y)$, where $X$ and $Y$ are independent random variables. Both $X$ and $Y$ follow a standard normal distribution, for which the probability density function (PDF) is given by $f_Z(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{z^2}{2})$ for any real number $z$.\n\nLet $R$ be the random variable representing the final distance of the particle from the origin, defined as $R = \\sqrt{X^2 + Y^2}$.\n\nDetermine the probability density function, $f_R(r)$, for the distance $R$. Your answer should be an expression in terms of the variable $r$, valid for $r \\ge 0$.", "solution": "We are given $X$ and $Y$ as independent standard normal random variables with joint density\n$$\nf_{X,Y}(x,y)=\\frac{1}{2\\pi}\\exp\\!\\left(-\\frac{x^{2}+y^{2}}{2}\\right).\n$$\nDefine the transformation to polar coordinates by $x=r\\cos\\theta$ and $y=r\\sin\\theta$, with $r\\ge 0$ and $\\theta\\in[0,2\\pi)$. The Jacobian determinant of this transformation is\n$$\n\\left|\\frac{\\partial(x,y)}{\\partial(r,\\theta)}\\right|=\\left|\\begin{pmatrix}\\cos\\theta & -r\\sin\\theta\\\\ \\sin\\theta & r\\cos\\theta\\end{pmatrix}\\right|=r.\n$$\nTherefore, the joint density of $(R,\\Theta)$ is\n$$\nf_{R,\\Theta}(r,\\theta)=f_{X,Y}(r\\cos\\theta,r\\sin\\theta)\\,r=\\frac{1}{2\\pi}\\exp\\!\\left(-\\frac{r^{2}\\cos^{2}\\theta+r^{2}\\sin^{2}\\theta}{2}\\right)r=\\frac{r}{2\\pi}\\exp\\!\\left(-\\frac{r^{2}}{2}\\right),\n$$\nvalid for $r\\ge 0$ and $\\theta\\in[0,2\\pi)$. The marginal density of $R$ is obtained by integrating out $\\Theta$:\n$$\nf_{R}(r)=\\int_{0}^{2\\pi} f_{R,\\Theta}(r,\\theta)\\,d\\theta=\\int_{0}^{2\\pi}\\frac{r}{2\\pi}\\exp\\!\\left(-\\frac{r^{2}}{2}\\right)\\,d\\theta=r\\exp\\!\\left(-\\frac{r^{2}}{2}\\right),\n$$\nfor $r\\ge 0$. To verify normalization,\n$$\n\\int_{0}^{\\infty} r\\exp\\!\\left(-\\frac{r^{2}}{2}\\right)dr=\\int_{0}^{\\infty}\\exp(-u)\\,du=1,\n$$\nwhere the substitution $u=\\frac{r^{2}}{2}$, $du=r\\,dr$, was used. Hence, the probability density function of $R$ is $f_{R}(r)=r\\exp(-r^{2}/2)$ for $r\\ge 0$.", "answer": "$$\\boxed{r\\exp\\!\\left(-\\frac{r^{2}}{2}\\right)}$$", "id": "1287711"}]}