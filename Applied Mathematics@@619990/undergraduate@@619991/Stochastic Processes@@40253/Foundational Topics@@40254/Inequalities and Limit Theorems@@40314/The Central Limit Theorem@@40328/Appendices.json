{"hands_on_practices": [{"introduction": "The Central Limit Theorem is powerful because it allows us to make predictions about the average of a sample, even if we don't know the shape of the original data's distribution. This first exercise provides a concrete scenario to apply the CLT to a sample mean [@problem_id:1959556]. By working through it, you'll practice calculating the sampling distribution's parameters and using the normal distribution to find probabilities, a foundational skill in statistics.", "problem": "A company specializing in customer support wants to evaluate the efficiency of its dispatchers. The time it takes for a dispatcher to handle a single support call is a random variable. Based on extensive historical data, the mean handle time is $\\mu = 195$ seconds, with a standard deviation of $\\sigma = 42$ seconds. The distribution of handle times for individual calls is known to be non-normal and positively skewed due to a small number of very complex calls that take an unusually long time to resolve.\n\nAs part of a weekly performance review, a supervisor randomly selects a sample of $n = 36$ calls handled by a specific dispatcher. The supervisor is interested in the average handle time for this sample.\n\nAssuming the sample of calls is representative of the dispatcher's overall performance, calculate the probability that the average handle time for these 36 calls is less than 185 seconds. Report your answer as a decimal rounded to three significant figures.", "solution": "Let $X_{1},\\dots,X_{n}$ denote the handle times for $n=36$ independent calls from the dispatcher, with population mean $\\mu=195$ and standard deviation $\\sigma=42$. The sample mean is $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$.\n\nBy the Central Limit Theorem, for sufficiently large $n$, the sampling distribution of $\\bar{X}$ is approximately normal with mean $\\mu$ and variance $\\frac{\\sigma^{2}}{n}$, i.e., $\\bar{X}\\approx \\mathcal{N}\\!\\left(\\mu,\\frac{\\sigma^{2}}{n}\\right)$. Therefore, the standard error is\n$$\n\\frac{\\sigma}{\\sqrt{n}}=\\frac{42}{\\sqrt{36}}=7.\n$$\nTo find $\\mathbb{P}(\\bar{X}<185)$, standardize using $Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}}$:\n$$\n\\mathbb{P}(\\bar{X}<185)=\\mathbb{P}\\!\\left(Z<\\frac{185-195}{7}\\right)=\\mathbb{P}\\!\\left(Z<-\\frac{10}{7}\\right)=\\Phi\\!\\left(-\\frac{10}{7}\\right),\n$$\nwhere $\\Phi$ is the standard normal cumulative distribution function. Evaluating $\\Phi\\!\\left(-\\frac{10}{7}\\right)$ numerically gives approximately $0.0766$ when rounded to three significant figures.", "answer": "$$\\boxed{0.0766}$$", "id": "1959556"}, {"introduction": "Building on the sample mean, the CLT also applies to the sum of random variables. This practice explores the sum of discrete random variables and introduces the crucial technique of continuity correction, which improves the accuracy of the normal approximation in such cases [@problem_id:1959567]. Mastering this adjustment is essential for correctly applying the CLT to real-world data that is often counted in whole numbers.", "problem": "A traffic analyst is studying vehicle flow at a particular crossing. For any vehicle passing through, the probability it is a truck is $p = 0.1$. Assume the types of consecutive vehicles are independent events. The analyst defines an 'observation period' as the process of counting the number of consecutive cars that pass *before* the first truck is observed. This process is repeated for $N=40$ independent observation periods. Let $S_{40}$ be the total number of cars counted across all 40 periods. Using a normal approximation with a continuity correction, calculate the probability that the total number of cars, $S_{40}$, is strictly greater than 380. Round your final answer to four significant figures.", "solution": "Let $p$ denote the probability a passing vehicle is a truck and $q = 1 - p$ denote the probability it is a car. For one observation period, let $X$ be the number of cars before the first truck. Then $X$ has the geometric distribution on $\\{0,1,2,\\dots\\}$ with\n$$\n\\Pr(X = k) = q^{k} p, \\quad k = 0,1,2,\\dots,\n$$\nso\n$$\n\\mathbb{E}[X] = \\frac{q}{p}, \\quad \\operatorname{Var}(X) = \\frac{q}{p^{2}}.\n$$\nOver $N = 40$ independent periods, the total number of cars is\n$$\nS_{40} = \\sum_{i=1}^{40} X_{i},\n$$\nwith mean and variance\n$$\n\\mu_{S} = \\mathbb{E}[S_{40}] = 40 \\frac{q}{p}, \\quad \\sigma_{S}^{2} = \\operatorname{Var}(S_{40}) = 40 \\frac{q}{p^{2}}.\n$$\nWith $p = 0.1$ and $q = 0.9$,\n$$\n\\mu_{S} = 40 \\cdot \\frac{0.9}{0.1} = 360, \\quad \\sigma_{S}^{2} = 40 \\cdot \\frac{0.9}{0.1^{2}} = 3600, \\quad \\sigma_{S} = 60.\n$$\nUsing the normal approximation with continuity correction,\n$$\n\\Pr(S_{40} > 380) = \\Pr(S_{40} \\geq 381) \\approx \\Pr\\!\\left(Y \\geq 380.5\\right),\n$$\nwhere $Y \\sim N(\\mu_{S}, \\sigma_{S}^{2})$. Standardizing,\n$$\nz = \\frac{380.5 - 360}{60} = \\frac{41}{120} \\approx 0.341666\\ldots,\n$$\nso\n$$\n\\Pr(S_{40} > 380) \\approx 1 - \\Phi\\!\\left(\\frac{41}{120}\\right).\n$$\nNumerically, $\\Phi\\!\\left(\\frac{41}{120}\\right) \\approx 0.633704$, hence\n$$\n\\Pr(S_{40} > 380) \\approx 0.366296 \\approx 0.3663 \\text{ (to four significant figures)}.\n$$", "answer": "$$\\boxed{0.3663}$$", "id": "1959567"}, {"introduction": "Our final practice bridges the gap between the theoretical CLT and its widespread use in statistical inference. In most real-world applications, the true population standard deviation $\\sigma$ is unknown and must be estimated from the sample. This exercise demonstrates why we can confidently substitute the sample standard deviation $S_n$ for $\\sigma$ in large samples, thanks to a key result known as Slutsky's theorem [@problem_id:1336748]. Understanding this principle is crucial for justifying the methods behind confidence intervals and hypothesis testing.", "problem": "Consider a sequence of independent and identically distributed (i.i.d.) real-valued random variables $X_1, X_2, \\dots, X_n$. These variables are drawn from a distribution with a finite mean $\\mu$ and a finite, non-zero variance $\\sigma^2 > 0$.\n\nLet the sample mean be defined as $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$, and let the unbiased sample variance be defined as $S_n^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar{X}_n)^2$.\n\nA common statistic used in hypothesis testing and for constructing confidence intervals is the studentized sample mean, which is formed by normalizing the sample mean using the sample standard deviation, $S_n = \\sqrt{S_n^2}$, instead of the true (and often unknown) standard deviation $\\sigma$. This statistic is given by the sequence of random variables $T_n$:\n$$ T_n = \\sqrt{n} \\frac{\\bar{X}_n - \\mu}{S_n} $$\nIn the limit as the sample size $n$ approaches infinity, this sequence $T_n$ converges in distribution to a well-known, foundational probability distribution.\n\nDetermine the mean and the variance of this limiting distribution. Your answer should be a pair of numbers.", "solution": "We have i.i.d. real-valued random variables $X_{1},\\dots,X_{n}$ with finite mean $\\mu$ and finite, non-zero variance $\\sigma^{2}>0$. Define the sample mean $\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$ and unbiased sample variance $S_{n}^{2}=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i}-\\bar{X}_{n})^{2}$, with $S_{n}=\\sqrt{S_{n}^{2}}$. The statistic is\n$$\nT_{n}=\\sqrt{n}\\,\\frac{\\bar{X}_{n}-\\mu}{S_{n}}.\n$$\n\nFirst, by the classical Central Limit Theorem for i.i.d. variables with finite variance,\n$$\n\\sqrt{n}\\,\\frac{\\bar{X}_{n}-\\mu}{\\sigma}\\;\\xrightarrow{d}\\;N(0,1).\n$$\nNext, show $S_{n}\\xrightarrow{p}\\sigma$. Using the identity\n$$\nS_{n}^{2}=\\frac{n}{n-1}\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2}-\\bar{X}_{n}^{2}\\right),\n$$\nthe Weak Law of Large Numbers gives $\\frac{1}{n}\\sum_{i=1}^{n}X_{i}^{2}\\xrightarrow{p}\\mathbb{E}[X_{1}^{2}]$ (finite by assumption of finite variance) and $\\bar{X}_{n}\\xrightarrow{p}\\mu$. Hence,\n$$\nS_{n}^{2}\\xrightarrow{p}\\mathbb{E}[X_{1}^{2}]-\\mu^{2}=\\sigma^{2},\n$$\nand by the continuous mapping theorem,\n$$\n\\frac{S_{n}}{\\sigma}\\xrightarrow{p}1.\n$$\n\nNow apply Slutskyâ€™s theorem: if $Y_{n}\\xrightarrow{d}Y$ and $Z_{n}\\xrightarrow{p}1$, then $\\frac{Y_{n}}{Z_{n}}\\xrightarrow{d}Y$. With $Y_{n}=\\sqrt{n}\\,\\frac{\\bar{X}_{n}-\\mu}{\\sigma}$ and $Z_{n}=\\frac{S_{n}}{\\sigma}$, we obtain\n$$\nT_{n}=\\frac{\\sqrt{n}\\,(\\bar{X}_{n}-\\mu)/\\sigma}{S_{n}/\\sigma}\\;\\xrightarrow{d}\\;N(0,1).\n$$\n\nTherefore, the limiting distribution of $T_{n}$ is standard normal, whose mean and variance are $0$ and $1$, respectively.", "answer": "$$\\boxed{\\begin{pmatrix}0 & 1\\end{pmatrix}}$$", "id": "1336748"}]}