{"hands_on_practices": [{"introduction": "The best way to build intuition for an abstract principle like the Minkowski inequality is to see it in action. This first exercise provides a concrete opportunity to do just that, using familiar continuous functions and standard integration. By explicitly calculating the $L^2$-norms, you will directly verify that the triangle inequality holds in this functional space context. [@problem_id:1432578]", "problem": "Let $(X, \\mathcal{M}, \\mu)$ be a measure space. For a real number $p \\geq 1$, the space $L^p(X)$ consists of all measurable functions $f: X \\to \\mathbb{R}$ for which the $L^p$-norm, defined as\n$$ \\|f\\|_p = \\left( \\int_X |f|^p \\,d\\mu \\right)^{1/p} $$\nis finite. A fundamental property of these spaces is Minkowski's inequality, which is the triangle inequality for the $L^p$-norm. For any $f, g \\in L^p(X)$, this inequality states that $\\|f+g\\|_p \\le \\|f\\|_p + \\|g\\|_p$.\n\nConsider the measure space given by the interval $X=[0, 1]$, with the standard Borel sigma-algebra and the Lebesgue measure $\\mu$. Let the functions $f: [0, 1] \\to \\mathbb{R}$ and $g: [0, 1] \\to \\mathbb{R}$ be defined by $f(x) = x$ and $g(x) = 1$.\n\nFor the specific case of $p=2$, calculate the value of the quantity $\\Delta = (\\|f\\|_2 + \\|g\\|_2)^2 - \\|f+g\\|_2^2$.\n\nExpress your answer as a single closed-form analytic expression.", "solution": "The problem asks us to compute the value of $\\Delta = (\\|f\\|_2 + \\|g\\|_2)^2 - \\|f+g\\|_2^2$ for the functions $f(x)=x$ and $g(x)=1$ on the interval $[0, 1]$ with the Lebesgue measure. We need to compute the $L^2$-norm for each of the functions $f$, $g$, and $f+g$.\n\nThe $L^2$-norm of a function $h$ on the interval $[0, 1]$ is given by the formula:\n$$ \\|h\\|_2 = \\left( \\int_0^1 |h(x)|^2 \\,dx \\right)^{1/2} $$\n\nFirst, we calculate $\\|f\\|_2$ for $f(x)=x$. On $[0, 1]$, $f(x)=x$ is non-negative, so $|f(x)|=f(x)$.\n$$ \\|f\\|_2 = \\left( \\int_0^1 x^2 \\,dx \\right)^{1/2} $$\nThe integral is:\n$$ \\int_0^1 x^2 \\,dx = \\left[ \\frac{x^3}{3} \\right]_0^1 = \\frac{1^3}{3} - \\frac{0^3}{3} = \\frac{1}{3} $$\nSo, the norm is:\n$$ \\|f\\|_2 = \\left( \\frac{1}{3} \\right)^{1/2} = \\frac{1}{\\sqrt{3}} $$\n\nNext, we calculate $\\|g\\|_2$ for $g(x)=1$. The function is positive, so $|g(x)|=g(x)$.\n$$ \\|g\\|_2 = \\left( \\int_0^1 1^2 \\,dx \\right)^{1/2} $$\nThe integral is:\n$$ \\int_0^1 1 \\,dx = [x]_0^1 = 1 - 0 = 1 $$\nSo, the norm is:\n$$ \\|g\\|_2 = (1)^{1/2} = 1 $$\n\nNow, we calculate $\\|f+g\\|_2$. The sum function is $(f+g)(x) = f(x) + g(x) = x+1$. On the interval $[0, 1]$, $x+1$ is positive, so $|(f+g)(x)| = x+1$.\n$$ \\|f+g\\|_2 = \\left( \\int_0^1 (x+1)^2 \\,dx \\right)^{1/2} $$\nWe expand the integrand and integrate:\n$$ \\int_0^1 (x+1)^2 \\,dx = \\int_0^1 (x^2 + 2x + 1) \\,dx = \\left[ \\frac{x^3}{3} + x^2 + x \\right]_0^1 $$\nEvaluating the definite integral:\n$$ \\left( \\frac{1^3}{3} + 1^2 + 1 \\right) - (0) = \\frac{1}{3} + 1 + 1 = \\frac{7}{3} $$\nSo, the norm of the sum is:\n$$ \\|f+g\\|_2 = \\left( \\frac{7}{3} \\right)^{1/2} = \\sqrt{\\frac{7}{3}} $$\n\nFinally, we substitute these results into the expression for $\\Delta$.\nWe need $(\\|f\\|_2 + \\|g\\|_2)^2$ and $\\|f+g\\|_2^2$.\n$$ \\|f\\|_2 + \\|g\\|_2 = \\frac{1}{\\sqrt{3}} + 1 $$\nSquaring this sum:\n$$ (\\|f\\|_2 + \\|g\\|_2)^2 = \\left( \\frac{1}{\\sqrt{3}} + 1 \\right)^2 = \\left(\\frac{1}{\\sqrt{3}}\\right)^2 + 2 \\cdot \\frac{1}{\\sqrt{3}} \\cdot 1 + 1^2 = \\frac{1}{3} + \\frac{2}{\\sqrt{3}} + 1 = \\frac{4}{3} + \\frac{2}{\\sqrt{3}} $$\nAnd for the other term:\n$$ \\|f+g\\|_2^2 = \\left( \\sqrt{\\frac{7}{3}} \\right)^2 = \\frac{7}{3} $$\nNow we compute $\\Delta$:\n$$ \\Delta = (\\|f\\|_2 + \\|g\\|_2)^2 - \\|f+g\\|_2^2 = \\left( \\frac{4}{3} + \\frac{2}{\\sqrt{3}} \\right) - \\frac{7}{3} $$\n$$ \\Delta = \\frac{4-7}{3} + \\frac{2}{\\sqrt{3}} = -1 + \\frac{2}{\\sqrt{3}} $$\nTo write this in a standard form, we can rationalize the denominator:\n$$ \\frac{2}{\\sqrt{3}} = \\frac{2\\sqrt{3}}{\\sqrt{3}\\sqrt{3}} = \\frac{2\\sqrt{3}}{3} $$\nThus, the final expression for $\\Delta$ is:\n$$ \\Delta = \\frac{2\\sqrt{3}}{3} - 1 $$", "answer": "$$\\boxed{\\frac{2\\sqrt{3}}{3} - 1}$$", "id": "1432578"}, {"introduction": "The Minkowski inequality's true power is its application across different mathematical fields, not just calculus. This practice extends the concept to the world of probability and stochastic processes, where $L^p$ spaces are defined for random variables. You will verify the inequality for a combination of discrete random variables, solidifying your understanding of how it provides a measure of \"distance\" and \"magnitude\" in probabilistic settings. [@problem_id:1318877]", "problem": "Let $X$ be a Bernoulli random variable with a probability of success given by $P(X=1) = q$. Let $Y$ be a discrete random variable that is uniformly distributed on the set of integers $\\{-N, -N+1, \\dots, N-1, N\\}$ for some positive integer $N$. The random variables $X$ and $Y$ are independent.\n\nFor any random variable $Z$ with a finite second moment, its $L_2$-norm is defined as $\\|Z\\|_2 = \\sqrt{E[Z^2]}$, where $E[\\cdot]$ denotes the expectation operator.\n\nYou are given that $q = \\frac{1}{4}$ and $N = 2$. Calculate the value of the quantity $D = \\|X\\|_2 + \\|Y\\|_2 - \\|X+Y\\|_2$.\n\nRound your final answer to four significant figures.", "solution": "We use the definition $\\|Z\\|_{2}=\\sqrt{E[Z^{2}]}$ and properties of expectation.\n\nFor the Bernoulli random variable $X$ with $P(X=1)=q$ and $P(X=0)=1-q$, note that $X^{2}=X$. Therefore,\n$$\nE[X^{2}]=E[X]=q \\quad \\Rightarrow \\quad \\|X\\|_{2}=\\sqrt{q}.\n$$\nWith $q=\\frac{1}{4}$, this gives $\\|X\\|_{2}=\\sqrt{\\frac{1}{4}}=\\frac{1}{2}$.\n\nFor $Y$ uniformly distributed on $\\{-2,-1,0,1,2\\}$, each value has probability $\\frac{1}{5}$. By symmetry,\n$$\nE[Y]=\\frac{1}{5}\\sum_{y\\in\\{-2,-1,0,1,2\\}} y=0.\n$$\nCompute the second moment:\n$$\nE[Y^{2}]=\\frac{1}{5}\\sum_{y\\in\\{-2,-1,0,1,2\\}} y^{2}=\\frac{1}{5}\\left(4+1+0+1+4\\right)=\\frac{10}{5}=2,\n$$\nso\n$$\n\\|Y\\|_{2}=\\sqrt{E[Y^{2}]}=\\sqrt{2}.\n$$\n\nFor the sum, use $(X+Y)^{2}=X^{2}+2XY+Y^{2}$ and independence of $X$ and $Y$:\n$$\nE[(X+Y)^{2}]=E[X^{2}]+2E[XY]+E[Y^{2}]=E[X^{2}]+2E[X]E[Y]+E[Y^{2}]=q+0+2=q+2.\n$$\nWith $q = 1/4$, $E[(X+Y)^2] = 1/4 + 2 = 9/4$.\nHence,\n$$\n\\|X+Y\\|_{2}=\\sqrt{q+2} = \\sqrt{9/4} = 3/2.\n$$\n\nTherefore,\n$$\nD=\\|X\\|_{2}+\\|Y\\|_{2}-\\|X+Y\\|_{2}=\\sqrt{q}+\\sqrt{2}-\\sqrt{q+2}.\n$$\nWith $q=\\frac{1}{4}$, we get\n$$\nD=\\sqrt{\\frac{1}{4}}+\\sqrt{2}-\\sqrt{\\frac{9}{4}}=\\frac{1}{2}+\\sqrt{2}-\\frac{3}{2}=\\sqrt{2}-1.\n$$\nNumerically, $\\sqrt{2}-1\\approx 0.41421356$, which rounded to four significant figures is $0.4142$.", "answer": "$$\\boxed{0.4142}$$", "id": "1318877"}, {"introduction": "A crucial aspect of applying any mathematical theorem is ensuring its preconditions are met; misapplying a powerful tool can lead to nonsensical results. This problem challenges you to investigate the applicability of the Minkowski inequality itself by first determining if the given functions belong to the relevant $L^p$ spaces. This is a fundamental step in rigorous mathematical analysis that prevents meaningless conclusions. [@problem_id:1432524]", "problem": "In measure theory, for a measurable set $E \\subseteq \\mathbb{R}$, the space $L^p(E)$ for $p \\geq 1$ consists of all measurable functions $f: E \\to \\mathbb{R}$ for which the $L^p$-norm, defined as $\\|f\\|_p = \\left( \\int_E |f(x)|^p \\, dx \\right)^{1/p}$, is finite. A fundamental result for these spaces is Minkowski's inequality, which states that for any two functions $f, g \\in L^p(E)$, their sum $f+g$ is also in $L^p(E)$ and satisfies $\\|f+g\\|_p \\leq \\|f\\|_p + \\|g\\|_p$.\n\nConsider the interval $E = (0,1)$ and the two functions defined on this interval:\n$$ f(x) = \\frac{1}{\\sqrt{x}} $$\n$$ g(x) = \\frac{1}{\\sqrt{1-x}} $$\n\nWhich of the following statements accurately describes these functions and the applicability of Minkowski's inequality for the cases $p=1$ and $p=2$?\n\nA. Both $f$ and $g$ belong to $L^1((0,1))$ and $L^2((0,1))$; consequently, Minkowski's inequality can be applied to provide a finite bound for $\\|f+g\\|_p$ for both $p=1$ and $p=2$.\n\nB. Both $f$ and $g$ belong to $L^2((0,1))$ but not to $L^1((0,1))$; consequently, Minkowski's inequality is applicable for $p=2$ but not for $p=1$.\n\nC. Neither $f$ nor $g$ belongs to $L^1((0,1))$, which makes the application of Minkowski's inequality trivial for any $p \\ge 1$.\n\nD. Both $f$ and $g$ belong to $L^1((0,1))$, but they do not belong to $L^2((0,1))$. As a result, applying Minkowski's inequality for $p=2$ is not meaningful as it involves infinite quantities.\n\nE. Exactly one of the functions belongs to $L^1((0,1))$ and exactly one belongs to $L^2((0,1))$, so Minkowski's inequality cannot be applied for either $p=1$ or $p=2$.", "solution": "We analyze the $L^{p}$-integrability of $f(x)=x^{-1/2}$ and $g(x)=(1-x)^{-1/2}$ on $E=(0,1)$.\n\nFirst, for $p=1$:\nFor $f$,\n$$\n\\int_{0}^{1} |f(x)| \\, dx=\\int_{0}^{1} x^{-1/2} \\, dx=\\left[2 x^{1/2}\\right]_{0}^{1}=2<\\infty.\n$$\nFor $g$, use the substitution $u=1-x$, $du=-dx$:\n$$\n\\int_{0}^{1} |g(x)| \\, dx=\\int_{0}^{1} (1-x)^{-1/2} \\, dx=\\int_{1}^{0} u^{-1/2}(-du)=\\int_{0}^{1} u^{-1/2}\\,du=2<\\infty.\n$$\nThus $f,g\\in L^{1}((0,1))$.\n\nNext, for $p=2$:\nFor $f$,\n$$\n\\int_{0}^{1} |f(x)|^{2} \\, dx=\\int_{0}^{1} x^{-1} \\, dx=\\lim_{\\varepsilon\\to 0^{+}} \\int_{\\varepsilon}^{1} x^{-1}\\,dx=\\lim_{\\varepsilon\\to 0^{+}} \\left(\\ln 1-\\ln \\varepsilon\\right)=+\\infty,\n$$\nso $f\\notin L^{2}((0,1))$.\nFor $g$,\n$$\n\\int_{0}^{1} |g(x)|^{2} \\, dx=\\int_{0}^{1} (1-x)^{-1} \\, dx=\\lim_{\\delta\\to 0^{+}} \\int_{0}^{1-\\delta} (1-x)^{-1}\\,dx=\\lim_{\\delta\\to 0^{+}} \\left(-\\ln(1-(1-\\delta))+\\ln(1-0)\\right)=+\\infty,\n$$\nso $g\\notin L^{2}((0,1))$.\n\nTherefore, both $f$ and $g$ belong to $L^{1}((0,1))$ but neither belongs to $L^{2}((0,1))$. Consequently, for $p=1$, Minkowski’s inequality applies and yields a finite bound:\n$$\n\\|f+g\\|_{1}\\leq \\|f\\|_{1}+\\|g\\|_{1}<\\infty.\n$$\nFor $p=2$, since $f,g\\notin L^{2}$, the $L^{2}$-norms are infinite and Minkowski’s inequality in $L^{2}$ is not applicable to these functions, providing no meaningful finite bound.\n\nHence the correct choice is D.", "answer": "$$\\boxed{D}$$", "id": "1432524"}]}