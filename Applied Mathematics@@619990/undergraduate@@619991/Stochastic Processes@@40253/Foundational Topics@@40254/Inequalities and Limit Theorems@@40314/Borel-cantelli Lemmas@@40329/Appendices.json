{"hands_on_practices": [{"introduction": "This first exercise demonstrates a core application of the First Borel-Cantelli Lemma. We will analyze a hypothetical automated system where the probability of failure for each task decreases over time. By showing that the sum of these failure probabilities is finite, we can conclude that failures will, with certainty, only occur a finite number of times, establishing the system's long-term stability—a concept known as almost sure convergence [@problem_id:1394257].", "problem": "An advanced automated system is designed to perform a sequence of independent computational tasks, indexed by the natural numbers $n=1, 2, 3, \\ldots$. For each task $n$, the system's outcome is represented by a random variable $X_n$. If the task is completed successfully, the outcome is $X_n = 0$. If the system fails the task, it returns an error code equal to the task's index, so $X_n = n$.\n\nThrough a self-improvement mechanism, the probability of failure on task $n$ is given by $P(X_n = n) = n^{-p}$, where $p=1.5$. Consequently, the probability of success is $P(X_n = 0) = 1 - n^{-p}$. The outcomes of the tasks are mutually independent.\n\nWhich of the following statements correctly describes the long-term behavior of the sequence of outcomes $\\{X_n\\}$ as $n \\to \\infty$?\n\nA. The sequence $\\{X_n\\}$ converges to 0 almost surely.\n\nB. The sequence $\\{X_n\\}$ converges to 0 in probability, but not almost surely.\n\nC. The sequence $\\{X_n\\}$ converges to 0 in mean square.\n\nD. The sequence $\\{X_n\\}$ does not converge to 0 in probability.\n\nE. The sequence $\\{X_n\\}$ does not converge, but its expected value $E[X_n]$ converges to 0.", "solution": "Define events $E_{n}=\\{X_{n}=n\\}$. By hypothesis, $P(E_{n})=n^{-p}$ with $p=\\frac{3}{2}$, and the events are independent.\n\nAlmost sure convergence: Since\n$$\n\\sum_{n=1}^{\\infty}P(E_{n})=\\sum_{n=1}^{\\infty}n^{-\\frac{3}{2}}\\infty\n$$\nby the $p$-series test (since $\\frac{3}{2}1$), the first Borel–Cantelli lemma implies\n$$\nP(E_{n}\\ \\text{i.o.})=0.\n$$\nHence, with probability $1$, only finitely many $E_{n}$ occur, so there exists a (random) $N$ such that $X_{n}=0$ for all $n\\geq N$. Therefore, $X_{n}\\to 0$ almost surely. This establishes that option A is true.\n\nConvergence in probability: For any fixed $\\epsilon0$, for all $n\\epsilon$,\n$$\nP(|X_{n}-0|\\epsilon)=P(X_{n}=n)=n^{-\\frac{3}{2}}\\to 0,\n$$\nso $X_{n}\\to 0$ in probability. Hence option D is false, and option B (which asserts convergence in probability but not almost surely) is also false.\n\nMean square convergence: Compute\n$$\n\\mathbb{E}[X_{n}^{2}]=n^{2}\\cdot n^{-\\frac{3}{2}}=n^{\\frac{1}{2}}\\to \\infty,\n$$\nso\n$$\n\\mathbb{E}[(X_{n}-0)^{2}]=\\mathbb{E}[X_{n}^{2}]\\not\\to 0,\n$$\nand $X_{n}$ does not converge to $0$ in mean square. Thus option C is false.\n\nExpectation: \n$$\n\\mathbb{E}[X_{n}]=0\\cdot(1-n^{-\\frac{3}{2}})+n\\cdot n^{-\\frac{3}{2}}=n^{-\\frac{1}{2}}\\to 0.\n$$\nHowever, since $X_{n}$ does converge (almost surely and in probability) to $0$, the statement that it does not converge is false. Hence option E is false.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1394257"}, {"introduction": "Now, let's explore the counterpart to the first lemma. This problem models a cosmic ray detector whose efficiency slowly declines, yet we want to know if it will still make detections in the long run. By applying the Second Borel-Cantelli Lemma to this sequence of independent detection events, you will see how a diverging sum of probabilities guarantees that detections will occur infinitely often, even as the likelihood of any single detection diminishes [@problem_id:1285547].", "problem": "An astrophysicist is studying data from a remote cosmic ray detector. Due to a slow accumulation of cosmic dust on its primary sensor, the detector's efficiency decreases over time. The system is modeled as follows: for each second $n = 1, 2, 3, \\ldots$, the number of particles detected, denoted by the random variable $Y_n$, follows a Poisson distribution with an expected value (mean) of $\\lambda_n = \\frac{1}{n}$. The number of detections in any given second is independent of the number of detections in all other seconds. The Probability Mass Function for a Poisson random variable $Y$ with mean $\\lambda$ is given by $P(Y=k) = \\frac{\\lambda^k \\exp(-\\lambda)}{k!}$ for $k=0, 1, 2, \\ldots$.\n\nLet $A_n$ be the event that at least one particle is detected in the $n$-th second (i.e., $A_n = \\{Y_n  0\\}$). We are interested in the long-term behavior of the detector. Which of the following statements correctly describes the probability that the event $A_n$ occurs for infinitely many values of $n$?\n\nA. The event $A_n$ occurs for infinitely many $n$ with probability 1.\n\nB. The event $A_n$ occurs for infinitely many $n$ with probability 0.\n\nC. The probability that $A_n$ occurs for infinitely many $n$ is a value strictly between 0 and 1, which cannot be determined from the given information.\n\nD. There is a finite, but random, time $N$ after which no more particles are ever detected, with probability 1.\n\nE. Whether $A_n$ occurs infinitely often depends on the detection count in the first second, $Y_1$.", "solution": "For each $n \\in \\{1,2,3,\\ldots\\}$, $Y_{n} \\sim \\text{Poisson}(\\lambda_{n})$ with $\\lambda_{n}=\\frac{1}{n}$, and the $Y_{n}$ are independent across $n$. Define $A_{n}=\\{Y_{n}0\\}$. Since $A_{n}$ depends only on $Y_{n}$, the events $\\{A_{n}\\}$ are independent.\n\nCompute the probability of $A_{n}$:\n$$\n\\mathbb{P}(A_{n})=1-\\mathbb{P}(Y_{n}=0)=1-\\exp\\!\\left(-\\frac{1}{n}\\right).\n$$\nTo study $\\sum_{n=1}^{\\infty}\\mathbb{P}(A_{n})$, use the inequality $\\exp(x)\\geq 1+x$ for $x\\geq 0$, which implies\n$$\n\\exp(-x)\\leq \\frac{1}{1+x} \\quad \\Rightarrow \\quad 1-\\exp(-x)\\geq \\frac{x}{1+x}.\n$$\nWith $x=\\frac{1}{n}$, this yields\n$$\n\\mathbb{P}(A_{n})=1-\\exp\\!\\left(-\\frac{1}{n}\\right)\\geq \\frac{\\frac{1}{n}}{1+\\frac{1}{n}}=\\frac{1}{n+1}.\n$$\nTherefore,\n$$\n\\sum_{n=1}^{\\infty}\\mathbb{P}(A_{n}) \\;\\geq\\; \\sum_{n=1}^{\\infty}\\frac{1}{n+1} \\;=\\; \\infty.\n$$\nBy the second Borel–Cantelli lemma for independent events, if $\\sum_{n=1}^{\\infty}\\mathbb{P}(A_{n})=\\infty$, then\n$$\n\\mathbb{P}(A_{n} \\text{ i.o.})=1.\n$$\nHence the event $A_{n}$ occurs for infinitely many $n$ with probability $1$. This corresponds to option A; options B, C, D, and E are false under these conditions.", "answer": "$$\\boxed{A}$$", "id": "1285547"}, {"introduction": "This final practice synthesizes our understanding of both lemmas to analyze a system with a critical threshold. We will investigate a communication system where \"significant events\" are defined by noise pulses exceeding a tunable threshold, $T_n = c \\ln(n)$. You will determine how the value of the constant $c$ creates a sharp boundary: for certain values, events occur infinitely often, while for others, they cease, showcasing the predictive power of the Borel-Cantelli lemmas in identifying such \"phase transitions\" [@problem_id:1394209].", "problem": "In a communication system, a sequence of noise pulses $\\{X_n\\}_{n=1}^{\\infty}$ is observed at discrete time steps $n=1, 2, 3, \\dots$. The energy of each pulse is modeled as an independent random variable from a standard exponential distribution, meaning its probability density function is $f(x) = \\exp(-x)$ for $x \\ge 0$. A 'significant event' is declared at time $n$ if the pulse energy $X_n$ exceeds a time-varying threshold given by $T_n = c \\ln(n)$, where $\\ln$ denotes the natural logarithm and $c$ is a positive real constant.\n\nLet $E$ be the event that significant events are declared for infinitely many time steps $n$. The probability of this event, $P(E)$, depends on the choice of the constant $c$. Which of the following statements accurately describes this dependence?\n\nA. $P(E) = 1$ for all $c  0$.\n\nB. $P(E) = 0$ for all $c  0$.\n\nC. $P(E) = 1$ if $0  c \\le 1$, and $P(E) = 0$ if $c  1$.\n\nD. $P(E) = 1$ if $0  c  1$, and $P(E) = 0$ if $c \\ge 1$.\n\nE. $P(E)$ transitions smoothly from 1 to 0 as $c$ increases, taking the value $1/2$ at $c=1$.\n\nF. The value of $P(E)$ is indeterminate and cannot be found without more information.", "solution": "The problem asks for the probability of the event $E$, which is that significant events occur infinitely often. Let $A_n$ be the event that a significant event occurs at time step $n$. According to the problem description, this happens if the pulse energy $X_n$ exceeds the threshold $T_n = c \\ln(n)$. Therefore, we define the event $A_n$ as:\n$$A_n = \\{X_n  c \\ln(n)\\}$$\nThe event $E$ is that $A_n$ occurs for infinitely many $n$. In the language of set theory, this is the limit superior of the sequence of events $\\{A_n\\}$, denoted $E = \\limsup_{n \\to \\infty} A_n$ or $\\{A_n \\text{ i.o.}\\}$. The Borel-Cantelli lemmas relate the probability of this event to the sum of the probabilities of the individual events, $\\sum_{n=1}^\\infty P(A_n)$.\n\nFirst, we must calculate the probability of a single event $A_n$. The random variable $X_n$ follows a standard exponential distribution. The cumulative distribution function (CDF) for a standard exponential random variable $X$ is $F_X(x) = P(X \\le x) = 1 - \\exp(-x)$ for $x \\ge 0$. The probability of $A_n$ is the tail probability $P(X_n  c \\ln n)$.\n$$P(A_n) = P(X_n  c \\ln n) = 1 - F_{X_n}(c \\ln n) = 1 - (1 - \\exp(-c \\ln n)) = \\exp(-c \\ln n)$$\nUsing the property of logarithms that $k \\ln(a) = \\ln(a^k)$ and the fact that $\\exp(\\ln(x)) = x$, we can simplify this expression:\n$$P(A_n) = \\exp(\\ln(n^{-c})) = n^{-c} = \\frac{1}{n^c}$$\n\nNext, we analyze the sum of these probabilities over all $n$:\n$$\\sum_{n=1}^{\\infty} P(A_n) = \\sum_{n=1}^{\\infty} \\frac{1}{n^c}$$\nThis is a p-series. The convergence of a p-series depends on the value of the exponent $p$. In our case, $p=c$. The series converges if $p  1$ and diverges if $p \\le 1$. Therefore:\n- The series $\\sum_{n=1}^{\\infty} \\frac{1}{n^c}$ converges if $c  1$.\n- The series $\\sum_{n=1}^{\\infty} \\frac{1}{n^c}$ diverges if $c \\le 1$.\n\nNow we apply the Borel-Cantelli lemmas.\nThe **First Borel-Cantelli Lemma** states that if the sum of the probabilities of the events is finite, i.e., $\\sum_{n=1}^{\\infty} P(A_n)  \\infty$, then the probability of the events occurring infinitely often is zero.\nIn our case, for $c  1$, the sum converges. Thus, by the First Borel-Cantelli Lemma:\n$$P(E) = P(A_n \\text{ i.o.}) = 0 \\quad \\text{if } c  1.$$\n\nThe **Second Borel-Cantelli Lemma** states that if the events $A_n$ are independent and the sum of their probabilities is infinite, i.e., $\\sum_{n=1}^{\\infty} P(A_n) = \\infty$, then the probability of the events occurring infinitely often is one.\nThe problem states that the random variables $\\{X_n\\}$ are independent. Since each event $A_n$ depends only on the corresponding $X_n$, the events $\\{A_n\\}$ are also independent. For $0  c \\le 1$, the sum diverges. Thus, by the Second Borel-Cantelli Lemma:\n$$P(E) = P(A_n \\text{ i.o.}) = 1 \\quad \\text{if } 0  c \\le 1.$$\n\nCombining these two results, we find that $P(E) = 1$ if $0  c \\le 1$ and $P(E) = 0$ if $c  1$. This corresponds exactly to option C.", "answer": "$$\\boxed{C}$$", "id": "1394209"}]}