{"hands_on_practices": [{"introduction": "We begin with a question designed to build physical and probabilistic intuition. Imagine a process that creates circles of varying sizes: is the average area of these circles the same as the area of a circle that has the average radius? This seemingly simple question gets to the heart of Jensen's inequality. By applying the inequality to the convex function that defines area in terms of radius, $A(R) = \\pi R^2$, we can rigorously settle the question and understand a core principle: the expectation of a nonlinear function is generally not the same as the function of the expectation [@problem_id:1368171].", "problem": "A scientific instrument is designed to create and measure microscopic, perfectly circular oil slicks on a water surface. Due to inherent fluctuations in the dispensing mechanism, the radius of any given slick, denoted by the random variable $R$, varies from one experiment to another. The radius $R$ is always a positive value, and its probability distribution is such that it is not a deterministic constant (i.e., it has non-zero variance).\n\nLet $A$ be the random variable representing the area of a slick, which is related to its radius by the formula $A = \\pi R^2$. We are interested in comparing two quantities:\n1. The expected area of a slick, $E[A]$.\n2. The area of a hypothetical \"average\" slick whose radius is the expected radius, $E[R]$. This area is given by $\\pi (E[R])^2$.\n\nWhich of the following statements correctly describes the relationship between these two quantities?\n\nA. $E[A] > \\pi (E[R])^2$\n\nB. $E[A] = \\pi (E[R])^2$\n\nC. $E[A]  \\pi (E[R])^2$\n\nD. The relationship cannot be determined without knowing the specific probability distribution of the radius $R$.\n\nE. The relationship reverses depending on whether $E[R]$ is greater than or less than 1.", "solution": "Let $R$ be a positive random variable with non-zero variance and let $A = \\pi R^2$. By linearity of expectation,\n$$\nE[A]=E[\\pi R^2]=\\pi E[R^2].\n$$\nRecall the variance identity for any random variable with finite second moment:\n$$\n\\operatorname{Var}(R)=E\\big[(R-E[R])^2\\big]=E[R^2]-(E[R])^2.\n$$\nThe problem states that $R$ is not deterministic, so $\\operatorname{Var}(R)0$. Therefore,\n$$\nE[R^2]  (E[R])^2.\n$$\nMultiplying both sides by the positive constant $\\pi$ yields\n$$\n\\pi E[R^2]  \\pi (E[R])^2.\n$$\nUsing $E[A]=\\pi E[R^2]$, we conclude\n$$\nE[A]  \\pi (E[R])^2.\n$$\nEquivalently, since $r\\mapsto r^2$ is convex on $(0,\\infty)$, Jensen’s inequality gives $E[R^2] \\geq (E[R])^2$ with strict inequality when $R$ is non-degenerate, consistent with the above.", "answer": "$$\\boxed{A}$$", "id": "1368171"}, {"introduction": "Jensen's inequality provides deep insights into the properties of statistical estimators. A fundamental concept in statistics is that while the sample variance $S^2$ can be defined to be an unbiased estimator of the population variance $\\sigma^2$, the sample standard deviation $S$ is a *biased* estimator of the population standard deviation $\\sigma$. This practice problem demystifies this by guiding you through a direct calculation in a simple, controlled setting [@problem_id:1926161]. This exercise serves as a concrete demonstration of Jensen's inequality for concave functions—in this case, the square root function, $f(x) = \\sqrt{x}$.", "problem": "Consider a small, finite population consisting of just two numbers: $\\{0, L\\}$, where $L$ is a positive constant. From this population, we draw a random sample of size $n=2$ with replacement. Let the two observations in the sample be denoted by $X_1$ and $X_2$.\n\nThe sample mean is given by $\\bar{X} = \\frac{X_1 + X_2}{2}$. The unbiased sample variance is calculated using the formula $S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2$. The sample standard deviation is defined as $S = \\sqrt{S^2}$.\n\nThe population from which the samples are drawn has a true standard deviation, denoted by $\\sigma$.\n\nYour task is to calculate the exact value of the ratio of the expected value of the sample standard deviation, $E[S]$, to the true population standard deviation, $\\sigma$. Express your answer as a single closed-form analytic expression.", "solution": "The population is the two-point set $\\{0, L\\}$ sampled uniformly with replacement, so $P(X=0)=P(X=L)=\\frac{1}{2}$. The population mean is\n$$\n\\mu=\\frac{0+L}{2}=\\frac{L}{2},\n$$\nand the population variance is\n$$\n\\sigma^2=E[(X-\\mu)^2]=\\frac{1}{2}\\left(\\left(0-\\frac{L}{2}\\right)^2+\\left(L-\\frac{L}{2}\\right)^2\\right)=\\frac{L^2}{4},\n$$\nso the population standard deviation is\n$$\n\\sigma=\\frac{L}{2}.\n$$\nFor a sample of size $n=2$, the unbiased sample variance is\n$$\nS^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\bar{X})^2=\\sum_{i=1}^{2}(X_i-\\bar{X})^2,\n$$\nwith $\\bar{X}=\\frac{X_1+X_2}{2}$. Using $X_1-\\bar{X}=\\frac{X_1-X_2}{2}$ and $X_2-\\bar{X}=-\\frac{X_1-X_2}{2}$, we obtain\n$$\nS^2=\\left(\\frac{X_1-X_2}{2}\\right)^2+\\left(-\\frac{X_1-X_2}{2}\\right)^2=\\frac{(X_1-X_2)^2}{2},\n$$\nso\n$$\nS=\\sqrt{S^2}=\\frac{|X_1-X_2|}{\\sqrt{2}}.\n$$\nEnumerating the four equally likely sample pairs $(0,0)$, $(0,L)$, $(L,0)$, $(L,L)$, we have $S=0$ when the two draws are equal and $S=\\frac{L}{\\sqrt{2}}$ when they differ. Hence\n$$\nE[S]=P(X_1\\neq X_2)\\cdot\\frac{L}{\\sqrt{2}}=\\left(2\\cdot\\frac{1}{2}\\cdot\\frac{1}{2}\\right)\\frac{L}{\\sqrt{2}}=\\frac{L}{2\\sqrt{2}}.\n$$\nTherefore, the desired ratio is\n$$\n\\frac{E[S]}{\\sigma}=\\frac{\\frac{L}{2\\sqrt{2}}}{\\frac{L}{2}}=\\frac{1}{\\sqrt{2}}.\n$$\nThis expression is independent of $L$ and is the exact closed-form value.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{2}}}$$", "id": "1926161"}, {"introduction": "Beyond comparing expected values, Jensen's inequality is a formidable tool for solving optimization problems. This final exercise challenges you to find the most efficient allocation of resources within a distributed system to minimize its total operational cost [@problem_id:2304653]. By identifying the underlying cost expression as a convex function, you can leverage Jensen's inequality not only to establish the minimum possible cost but also to determine the precise condition for achieving this optimal state. This demonstrates the constructive power of the inequality in practical design and analysis.", "problem": "A distributed computing system consists of $n$ independent processing nodes. The total processing power allocated across all nodes is a fixed positive value, $S$. Let $p_i$ be the processing power allocated to the $i$-th node, where $p_i > 0$ for all $i=1, 2, \\ldots, n$. The allocations must satisfy the constraint $\\sum_{i=1}^n p_i = S$. The operational cost for the $i$-th node is found to be a function of its allocated power, given by the expression $C_i(p_i) = p_i + \\frac{\\alpha^2}{p_i}$, where $\\alpha$ is a positive real constant representing a system-specific inefficiency factor. Your task is to determine the minimum possible total operational cost for the entire system, which is the sum of the costs of all nodes, $\\sum_{i=1}^n C_i(p_i)$. Express your answer as a function of $n$, $S$, and $\\alpha$.", "solution": "We are to minimize the total cost\n$$\nF(p_1,\\ldots,p_n)=\\sum_{i=1}^{n}\\left(p_i+\\frac{\\alpha^2}{p_i}\\right)\n$$\nsubject to $p_i0$ for all $i$ and the linear constraint $\\sum_{i=1}^{n}p_i=S$, where $S0$ and $\\alpha0$ are fixed.\n\nFirst, define $f(p)=p+\\frac{\\alpha^2}{p}$ for $p0$. Its second derivative is\n$$\nf''(p)=\\frac{2\\alpha^2}{p^3}0 \\quad \\text{for all } p0,\n$$\nso $f$ is strictly convex on $(0,\\infty)$. Therefore, by Jensen’s inequality,\n$$\n\\frac{1}{n}\\sum_{i=1}^{n}f(p_i) \\geq f\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n}p_i\\right)=f\\!\\left(\\frac{S}{n}\\right),\n$$\nwith equality if and only if $p_1=\\cdots=p_n=\\frac{S}{n}$. Hence the unique minimizer under the constraint is\n$$\np_i^{\\star}=\\frac{S}{n} \\quad \\text{for all } i=1,\\ldots,n.\n$$\nEvaluating the total cost at this allocation gives\n$$\nF_{\\min}= \\sum_{i=1}^{n}\\left(\\frac{S}{n}+\\frac{\\alpha^2}{S/n}\\right)\n= n\\cdot \\frac{S}{n} + n\\cdot \\frac{\\alpha^2n}{S}\n= S + \\frac{n^2\\alpha^2}{S}.\n$$\nBecause $f$ is strictly convex and the feasible set defined by $\\sum_{i=1}^{n}p_i=S$, $p_i0$ is convex and nonempty, this value is the unique global minimum.", "answer": "$$\\boxed{S+\\frac{n^2\\alpha^2}{S}}$$", "id": "2304653"}]}