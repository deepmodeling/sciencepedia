{"hands_on_practices": [{"introduction": "This first practice is a fundamental exercise in probability theory that takes us \"under the hood\" of the Gamma distribution. The moment-generating function ($MGF$) is a powerful tool that encodes all the moments of a distribution. By learning to manipulate the $MGF$, we can derive essential properties like the mean and variance without performing complex integrations, providing a deeper understanding of the distribution's structure [@problem_id:8017].", "problem": "A continuous random variable $X$ is said to follow a Gamma distribution with shape parameter $\\alpha > 0$ and rate parameter $\\beta > 0$, denoted as $X \\sim \\text{Gamma}(\\alpha, \\beta)$, if its probability density function (PDF) is given by:\n$$f(x; \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x}$$\nfor $x > 0$, and $f(x) = 0$ for $x \\leq 0$. Here, $\\Gamma(\\alpha)$ is the Gamma function.\n\nThe moment generating function (MGF) of this distribution, for $t < \\beta$, is given by:\n$$M_X(t) = E[e^{tX}] = \\left(\\frac{\\beta}{\\beta - t}\\right)^\\alpha = (1 - t/\\beta)^{-\\alpha}$$\nThe moments of the random variable $X$ can be found by taking derivatives of the MGF and evaluating them at $t=0$. Specifically, the $k$-th moment is given by $E[X^k] = M_X^{(k)}(0)$, where $M_X^{(k)}(t)$ is the $k$-th derivative of $M_X(t)$ with respect to $t$.\n\nThe variance of a random variable $X$ is defined as:\n$$\\text{Var}(X) = E[X^2] - (E[X])^2$$\nUsing the provided moment generating function and the relationships above, derive the variance of the Gamma distribution, $\\text{Var}(X)$, in terms of the parameters $\\alpha$ and $\\beta$. For this derivation, you may find it more convenient to use the form $M_X(t) = \\beta^\\alpha (\\beta - t)^{-\\alpha}$.", "solution": "The goal is to derive the variance of a Gamma distributed random variable $X$ using its moment generating function (MGF), $M_X(t)$. The variance is given by $\\text{Var}(X) = E[X^2] - (E[X])^2$. We must first find the first two moments, $E[X]$ and $E[X^2]$.\n\nThe MGF of the Gamma($\\alpha, \\beta$) distribution is provided as:\n$$M_X(t) = \\beta^\\alpha (\\beta - t)^{-\\alpha}$$\nThe first moment, $E[X]$, is the first derivative of the MGF evaluated at $t=0$.\n$$E[X] = M_X'(0)$$\nFirst, we find the derivative of $M_X(t)$ with respect to $t$ using the chain rule:\n$$M_X'(t) = \\frac{d}{dt} \\left[ \\beta^\\alpha (\\beta - t)^{-\\alpha} \\right]$$\n$$M_X'(t) = \\beta^\\alpha \\cdot (-\\alpha)(\\beta - t)^{-\\alpha-1} \\cdot (-1)$$\n$$M_X'(t) = \\alpha \\beta^\\alpha (\\beta - t)^{-\\alpha-1}$$\nNow, we evaluate this derivative at $t=0$:\n$$M_X'(0) = \\alpha \\beta^\\alpha (\\beta - 0)^{-\\alpha-1} = \\alpha \\beta^\\alpha \\beta^{-\\alpha-1}$$\n$$M_X'(0) = \\alpha \\beta^{\\alpha - (\\alpha+1)} = \\alpha \\beta^{-1} = \\frac{\\alpha}{\\beta}$$\nThus, the first moment (the mean) is:\n$$E[X] = \\frac{\\alpha}{\\beta}$$\n\nNext, we find the second moment, $E[X^2]$, by taking the second derivative of the MGF and evaluating it at $t=0$.\n$$E[X^2] = M_X''(0)$$\nWe differentiate $M_X'(t)$ with respect to $t$:\n$$M_X''(t) = \\frac{d}{dt} \\left[ \\alpha \\beta^\\alpha (\\beta - t)^{-\\alpha-1} \\right]$$\n$$M_X''(t) = \\alpha \\beta^\\alpha \\cdot (-\\alpha-1)(\\beta - t)^{-\\alpha-2} \\cdot (-1)$$\n$$M_X''(t) = \\alpha(\\alpha+1) \\beta^\\alpha (\\beta - t)^{-\\alpha-2}$$\nNow, we evaluate this second derivative at $t=0$:\n$$M_X''(0) = \\alpha(\\alpha+1) \\beta^\\alpha (\\beta - 0)^{-\\alpha-2} = \\alpha(\\alpha+1) \\beta^\\alpha \\beta^{-\\alpha-2}$$\n$$M_X''(0) = \\alpha(\\alpha+1) \\beta^{\\alpha - (\\alpha+2)} = \\alpha(\\alpha+1) \\beta^{-2} = \\frac{\\alpha(\\alpha+1)}{\\beta^2}$$\nThus, the second moment is:\n$$E[X^2] = \\frac{\\alpha(\\alpha+1)}{\\beta^2}$$\n\nFinally, we use the formula for the variance, $\\text{Var}(X) = E[X^2] - (E[X])^2$, and substitute the moments we have calculated.\n$$\\text{Var}(X) = \\frac{\\alpha(\\alpha+1)}{\\beta^2} - \\left(\\frac{\\alpha}{\\beta}\\right)^2$$\n$$\\text{Var}(X) = \\frac{\\alpha^2 + \\alpha}{\\beta^2} - \\frac{\\alpha^2}{\\beta^2}$$\n$$\\text{Var}(X) = \\frac{(\\alpha^2 + \\alpha) - \\alpha^2}{\\beta^2}$$\n$$\\text{Var}(X) = \\frac{\\alpha}{\\beta^2}$$\nThis is the variance of the Gamma distribution.", "answer": "$$\\boxed{\\frac{\\alpha}{\\beta^2}}$$", "id": "8017"}, {"introduction": "Building on the theoretical properties of the Gamma distribution, this next exercise bridges the gap between abstract formulas and practical application. In real-world scenarios, we often have summary statistics from data—like a mean and variance—but we don't know the exact parameters of the underlying distribution. This practice demonstrates how to work backward from observed data to determine the shape and rate parameters that define the Gamma model, a common task in fields like reliability engineering [@problem_id:1398490].", "problem": "The lifetime of a particular model of electronic component is modeled as a random variable, $X$, where $X$ is measured in thousands of hours. The probability distribution of $X$ is known to be a Gamma distribution. A random variable $Y$ that follows a Gamma distribution with a shape parameter $\\alpha > 0$ and a rate parameter $\\beta > 0$, denoted as $Y \\sim \\Gamma(\\alpha, \\beta)$, has an expected value (mean) given by $E[Y] = \\frac{\\alpha}{\\beta}$ and a variance given by $\\text{Var}(Y) = \\frac{\\alpha}{\\beta^2}$.\n\nFrom extensive testing on a large sample of these components, the mean lifetime is determined to be 10,000 hours, and the variance of their lifetimes is 20,000,000 $\\text{hours}^2$.\n\nFind the shape parameter, $\\alpha$, and the rate parameter, $\\beta$, for the probability distribution of the component's lifetime $X$.", "solution": "Let $T$ denote the lifetime in hours and $X$ denote the lifetime in thousands of hours, so $X=\\frac{T}{10^{3}}$. Using linearity of expectation and the scaling rule for variance, we have\n$$E[X]=\\frac{E[T]}{10^{3}}, \\quad \\text{Var}(X)=\\frac{\\text{Var}(T)}{10^{6}}.$$\nGiven $E[T]=10{,}000$ hours and $\\text{Var}(T)=20{,}000{,}000 \\text{ hours}^2$, it follows that\n$$E[X]=\\frac{10{,}000}{10^{3}}=10, \\quad \\text{Var}(X)=\\frac{20{,}000{,}000}{10^{6}}=20.$$\n\nAssuming $X \\sim \\Gamma(\\alpha,\\beta)$ with rate parameter $\\beta$, the mean and variance are\n$$E[X]=\\frac{\\alpha}{\\beta}, \\quad \\text{Var}(X)=\\frac{\\alpha}{\\beta^{2}}.$$\nSet these equal to the empirical values:\n$$\\frac{\\alpha}{\\beta}=10, \\quad \\frac{\\alpha}{\\beta^{2}}=20.$$\nFrom $\\frac{\\alpha}{\\beta}=10$ we get $\\alpha=10\\beta$. Substitute into the variance equation:\n$$\\frac{10\\beta}{\\beta^{2}}=20 \\quad \\Longrightarrow \\quad \\frac{10}{\\beta}=20 \\quad \\Longrightarrow \\quad \\beta=\\frac{1}{2}.$$\nThen\n$$\\alpha=10\\left(\\frac{1}{2}\\right)=5.$$\n\nTherefore, the shape and rate parameters are $\\alpha=5$ and $\\beta=\\frac{1}{2}$.", "answer": "$$\\boxed{\\begin{pmatrix}5 & \\frac{1}{2}\\end{pmatrix}}$$", "id": "1398490"}, {"introduction": "Our final practice takes an important step from probability theory into the realm of statistical inference. While our previous exercise involved finding parameters from given summary statistics, this problem asks us to develop a general procedure, the Method of Moments, for *estimating* these parameters from a random sample. This technique provides a foundational approach for fitting theoretical models to empirical data, a cornerstone of data analysis and scientific modeling [@problem_id:1919300].", "problem": "The operational lifetime of a specialized communications satellite component is modeled as a random variable $T$ that follows a Gamma distribution. The probability density function (PDF) for $T$ is given by:\n$$ f(t; \\alpha, \\beta) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)} t^{\\alpha-1} \\exp(-\\beta t), \\quad \\text{for } t > 0 $$\nwhere $\\alpha > 0$ is the shape parameter and $\\beta > 0$ is the rate parameter. To estimate these parameters from experimental data, a standard statistical technique involves matching the theoretical moments of the distribution to the corresponding moments calculated from a data sample.\n\nSuppose a random sample of $n$ component lifetimes, $T_1, T_2, \\ldots, T_n$, is collected. Let the sample mean be denoted by $\\bar{T} = \\frac{1}{n}\\sum_{i=1}^n T_i$, and let the second raw sample moment (the sample mean of the squares) be denoted by $M_2 = \\frac{1}{n}\\sum_{i=1}^n T_i^2$.\n\nFind the expressions for the estimators of the parameters, $\\hat{\\alpha}$ and $\\hat{\\beta}$, that are obtained by setting the theoretical mean $E[T]$ equal to $\\bar{T}$ and the theoretical second moment $E[T^2]$ equal to $M_2$. You are given that for a Gamma distribution with parameters $\\alpha$ and $\\beta$, the theoretical mean is $E[T] = \\frac{\\alpha}{\\beta}$ and the theoretical variance is $\\text{Var}(T) = \\frac{\\alpha}{\\beta^2}$. The final answer should be a pair of expressions, one for $\\hat{\\alpha}$ and one for $\\hat{\\beta}$, in terms of $\\bar{T}$ and $M_2$.", "solution": "We are given that $T$ follows a Gamma distribution with parameters $\\alpha$ and $\\beta$, with theoretical mean $E[T]=\\frac{\\alpha}{\\beta}$ and variance $\\text{Var}(T)=\\frac{\\alpha}{\\beta^{2}}$. The second moment about the origin is related to the mean and variance by $E[T^{2}]=\\text{Var}(T)+\\left(E[T]\\right)^{2}$. Therefore,\n$$\nE[T^{2}] \\;=\\; \\frac{\\alpha}{\\beta^{2}} \\;+\\; \\left(\\frac{\\alpha}{\\beta}\\right)^{2}\n\\;=\\; \\frac{\\alpha(1+\\alpha)}{\\beta^{2}}.\n$$\n\nThe method of moments sets the theoretical moments equal to the corresponding sample moments. Let $\\bar{T}=\\frac{1}{n}\\sum_{i=1}^{n}T_{i}$ and $M_{2}=\\frac{1}{n}\\sum_{i=1}^{n}T_{i}^{2}$. Then we solve\n$$\n\\frac{\\alpha}{\\beta}=\\bar{T}, \\qquad \\frac{\\alpha(1+\\alpha)}{\\beta^{2}}=M_{2}.\n$$\nFrom $\\frac{\\alpha}{\\beta}=\\bar{T}$ we obtain $\\beta=\\frac{\\alpha}{\\bar{T}}$. Substituting this into the second equation gives\n$$\nM_{2} \\;=\\; \\frac{\\alpha(1+\\alpha)}{\\left(\\frac{\\alpha}{\\bar{T}}\\right)^{2}}\n\\;=\\; \\bar{T}^{2}\\,\\frac{1+\\alpha}{\\alpha}.\n$$\nRearranging,\n$$\nM_{2}\\alpha \\;=\\; \\bar{T}^{2}(1+\\alpha)\n\\;\\;\\Longrightarrow\\;\\; \\alpha(M_{2}-\\bar{T}^{2}) \\;=\\; \\bar{T}^{2}\n\\;\\;\\Longrightarrow\\;\\; \\hat{\\alpha} \\;=\\; \\frac{\\bar{T}^{2}}{M_{2}-\\bar{T}^{2}}.\n$$\nFinally, substitute into $\\beta=\\frac{\\alpha}{\\bar{T}}$ to obtain\n$$\n\\hat{\\beta} \\;=\\; \\frac{\\hat{\\alpha}}{\\bar{T}} \\;=\\; \\frac{\\bar{T}}{M_{2}-\\bar{T}^{2}}.\n$$\nThese are the method-of-moments estimators expressed in terms of $\\bar{T}$ and $M_{2}$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\bar{T}^{2}}{M_{2}-\\bar{T}^{2}} & \\frac{\\bar{T}}{M_{2}-\\bar{T}^{2}} \\end{pmatrix}}$$", "id": "1919300"}]}