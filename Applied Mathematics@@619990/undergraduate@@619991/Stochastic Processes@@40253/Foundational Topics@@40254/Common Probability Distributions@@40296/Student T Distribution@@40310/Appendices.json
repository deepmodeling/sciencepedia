{"hands_on_practices": [{"introduction": "A powerful way to master a statistical concept is to understand its fundamental building blocks. The Student's t-distribution can be constructed from more basic distributions that you may already be familiar with. This practice demystifies the t-distribution by challenging you to identify the correct computational algorithm to generate a random number from it, using only standard normal variates. Successfully solving this problem [@problem_id:1335741] solidifies your understanding of the mathematical definition that connects the t-distribution to the normal and chi-squared distributions.", "problem": "A computational scientist needs to write a function that generates random variates from a Student's t-distribution with a specified number of degrees of freedom, $\\nu$, where $\\nu$ is a positive integer. The only available tool is a generator that can produce independent random samples from the standard normal distribution, $N(0,1)$. The scientist proposes several algorithms.\n\nWhich of the following algorithms correctly generates a single random number, $T$, that follows a Student's t-distribution with $\\nu$ degrees of freedom?\n\nA. Generate $\\nu+1$ independent standard normal samples, which we label $Z_0, Z_1, \\ldots, Z_\\nu$. Compute the value $T = \\frac{Z_0}{\\sqrt{\\frac{1}{\\nu} \\sum_{i=1}^{\\nu} Z_i}}$.\n\nB. Generate $\\nu$ independent standard normal samples, which we label $Z_1, \\ldots, Z_\\nu$. Compute the sample mean $\\bar{Z} = \\frac{1}{\\nu}\\sum_{i=1}^{\\nu} Z_i$ and the sample standard deviation $s = \\sqrt{\\frac{1}{\\nu-1}\\sum_{i=1}^{\\nu} (Z_i - \\bar{Z})^2}$. Compute the value $T = \\frac{\\bar{Z}}{s / \\sqrt{\\nu}}$.\n\nC. Generate $\\nu+1$ independent standard normal samples, which we label $Z_0, Z_1, \\ldots, Z_\\nu$. Compute the value $T = \\frac{Z_0}{\\sqrt{\\frac{1}{\\nu} \\sum_{i=1}^{\\nu} Z_i^2}}$.\n\nD. Generate $\\nu$ independent standard normal samples, which we label $Z_1, \\ldots, Z_\\nu$. Compute the value $T = \\frac{Z_1}{\\sqrt{\\frac{1}{\\nu-1} \\sum_{i=2}^{\\nu} Z_i^2}}$.\n\nE. Generate $\\nu+1$ independent standard normal samples, which we label $Z_0, Z_1, \\ldots, Z_\\nu$. Compute the value $T = \\frac{Z_0}{\\frac{1}{\\nu} \\sum_{i=1}^{\\nu} Z_i^2}$.", "solution": "Goal: determine which algorithm returns a random variable with the Studentâ€™s $t$ distribution with $\\nu$ degrees of freedom. The defining construction is: if $Z \\sim N(0,1)$ and $V \\sim \\chi^{2}_{\\nu}$ are independent, then\n$$\nT \\equiv \\frac{Z}{\\sqrt{V/\\nu}} \\sim t_{\\nu}.\n$$\nMoreover, if $Z_{1},\\ldots,Z_{\\nu}$ are i.i.d. $N(0,1)$, then $V=\\sum_{i=1}^{\\nu} Z_{i}^{2} \\sim \\chi^{2}_{\\nu}$. Also, for a normal sample of size $n$, the statistic\n$$\n\\frac{\\bar{Z}-\\mu}{S/\\sqrt{n}} \\sim t_{n-1},\n$$\nwhere $S$ is the sample standard deviation, and $\\bar{Z}$ and $S^{2}$ are independent; additionally $(n-1)S^{2}/\\sigma^{2} \\sim \\chi^{2}_{n-1}$ when each observation has variance $\\sigma^{2}$.\n\nAnalyze each option:\n\nA. The denominator is $\\sqrt{\\frac{1}{\\nu}\\sum_{i=1}^{\\nu} Z_{i}}$. Since $\\sum_{i=1}^{\\nu} Z_{i} \\sim N(0,\\nu)$, the quantity inside the square root is not almost surely nonnegative, so the expression is not well-defined and certainly does not have the required $\\sqrt{V/\\nu}$ form with $V \\sim \\chi^{2}_{\\nu}$. This does not produce $t_{\\nu}$.\n\nB. Here $n=\\nu$ i.i.d. $N(0,1)$ samples are used. By the classical $t$-statistic result,\n$$\nT=\\frac{\\bar{Z}}{s/\\sqrt{\\nu}} \\sim t_{\\nu-1},\n$$\nbecause $(\\nu-1)s^{2} \\sim \\chi^{2}_{\\nu-1}$ and $\\sqrt{\\nu}\\,\\bar{Z} \\sim N(0,1)$, with independence. The degrees of freedom are $\\nu-1$, not $\\nu$, so this does not produce $t_{\\nu}$.\n\nC. Let $Z_{0},Z_{1},\\ldots,Z_{\\nu}$ be independent $N(0,1)$. Define $V=\\sum_{i=1}^{\\nu} Z_{i}^{2} \\sim \\chi^{2}_{\\nu}$ and note that $Z_{0}$ is independent of $V$. Then\n$$\nT=\\frac{Z_{0}}{\\sqrt{\\frac{1}{\\nu}\\sum_{i=1}^{\\nu} Z_{i}^{2}}}=\\frac{Z_{0}}{\\sqrt{V/\\nu}} \\sim t_{\\nu},\n$$\nby the defining relationship. This is correct.\n\nD. Let $V=\\sum_{i=2}^{\\nu} Z_{i}^{2} \\sim \\chi^{2}_{\\nu-1}$, independent of $Z_{1} \\sim N(0,1)$. Then\n$$\nT=\\frac{Z_{1}}{\\sqrt{\\frac{1}{\\nu-1}\\sum_{i=2}^{\\nu} Z_{i}^{2}}}=\\frac{Z_{1}}{\\sqrt{V/(\\nu-1)}} \\sim t_{\\nu-1}.\n$$\nThis has $\\nu-1$ degrees of freedom, not $\\nu$, so it is not correct for $t_{\\nu}$.\n\nE. Let $V=\\sum_{i=1}^{\\nu} Z_{i}^{2} \\sim \\chi^{2}_{\\nu}$, independent of $Z_{0} \\sim N(0,1)$. Then\n$$\nT=\\frac{Z_{0}}{\\frac{1}{\\nu}\\sum_{i=1}^{\\nu} Z_{i}^{2}}=\\frac{\\nu Z_{0}}{V}.\n$$\nThe $t$ distribution requires division by $\\sqrt{V/\\nu}$, not by $V/\\nu$. The ratio of a standard normal to a chi-square (without the square root) yields a different distribution and is not $t_{\\nu}$.\n\nConclusion: only algorithm C yields $t_{\\nu}$.", "answer": "$$\\boxed{C}$$", "id": "1335741"}, {"introduction": "The Student's t-distribution is a cornerstone of statistical inference, especially when dealing with small sample sizes where the population variance is unknown. This exercise places you in a realistic scenario of quality control, where a decision must be made based on limited data. By determining the critical value for a hypothesis test [@problem_id:1335684], you will engage in a fundamental procedure that allows statisticians to draw conclusions from sample data and manage the risk of making incorrect decisions.", "problem": "A small-batch specialty coffee company is experimenting with a new roasting profile to improve the quality of its beans, which are scored on a standardized 100-point scale. The company's traditional roasting method has a long-established average quality score. To test the new profile, they roast a sample of 16 independent batches and have their scores evaluated.\n\nThe company decides on a statistical decision rule. They will only switch to the new roasting profile if the sample provides strong evidence that the new average score is genuinely higher than the historical average. They formalize this by calculating a test statistic, $T$, from the sample data:\n\n$$\nT = \\frac{\\bar{X} - \\mu_0}{S / \\sqrt{n}}\n$$\n\nHere, $\\bar{X}$ is the average score of the 16 new batches, $\\mu_0$ is the historical average score, $S$ is the standard deviation of the scores of the 16 new batches, and $n$ is the sample size.\n\nTo minimize the risk of switching to a new process that isn't actually better, they set a significance level of $\\alpha = 0.05$. They will only adopt the new profile if their calculated $T$ value exceeds a specific positive threshold, let's call it $t_{crit}$. This threshold is determined from the Student's t-distribution, which is appropriate for small sample sizes where the population standard deviation is unknown.\n\nWhat is the value of this critical threshold, $t_{crit}$, that the company should use for its decision?\n\nA. 1.753\n\nB. 2.131\n\nC. 1.341\n\nD. 1.746\n\nE. 2.602", "solution": "The problem asks for the critical threshold value, $t_{crit}$, for a one-sided hypothesis test using the Student's t-distribution. The company wants to determine if the new roasting profile is better, which means they are testing for an increase in the mean score. This corresponds to an upper-tailed (or right-tailed) test.\n\nThe critical value is the point on the t-distribution that separates the \"rejection region\" from the \"non-rejection region\". For an upper-tailed test with a significance level $\\alpha$, the critical value $t_{crit}$ is the value $t_{\\alpha, df}$ such that the area in the tail to its right is equal to $\\alpha$. The degrees of freedom, denoted by $df$, are calculated based on the sample size $n$.\n\nFirst, we must determine the degrees of freedom. The formula for degrees of freedom in this context is:\n$$\ndf = n - 1\n$$\nGiven the sample size is $n=16$, the degrees of freedom are:\n$$\ndf = 16 - 1 = 15\n$$\n\nNext, we identify the significance level. The problem states that the company uses a significance level of $\\alpha = 0.05$.\n\nWe are looking for an upper-tailed critical value. Therefore, we need to find the value $t_{crit}$ from the Student's t-distribution with 15 degrees of freedom such that the probability of observing a t-statistic greater than or equal to $t_{crit}$ is 0.05. This is denoted as $t_{0.05, 15}$.\n\nWe can find this value using a standard t-distribution table or statistical software. Looking up the t-table for a one-tailed probability of 0.05 and 15 degrees of freedom, we find the value.\n\n- The row corresponds to $df = 15$.\n- The column corresponds to the upper-tail probability, $\\alpha = 0.05$.\n\nThe intersection of this row and column gives the critical t-value.\n$$\nt_{crit} = t_{0.05, 15} \\approx 1.753\n$$\n\nThis means that if the calculated test statistic $T$ from their sample is greater than 1.753, the company will have statistically significant evidence (at the 5% significance level) to conclude that the new roasting profile yields a higher average score.\n\nLet's examine the other options to understand why they are incorrect:\n- B. 2.131: This is $t_{0.025, 15}$. It would be the correct critical value for a two-tailed test with a total significance level of $\\alpha=0.05$ (with 0.025 in each tail).\n- C. 1.341: This is $t_{0.10, 15}$. It corresponds to a less stringent significance level of $\\alpha=0.10$.\n- D. 1.746: This is $t_{0.05, 16}$. This value results from the common error of using the sample size $n$ as the degrees of freedom instead of $n-1$.\n- E. 2.602: This is $t_{0.01, 15}$. It corresponds to a more stringent significance level of $\\alpha=0.01$.\n\nTherefore, the correct critical threshold for the company's decision rule is 1.753.", "answer": "$$\\boxed{A}$$", "id": "1335684"}, {"introduction": "A true expert not only knows how to use a tool but also understands its limitations. The t-test is powerful, but its validity rests on several key assumptions. This problem explores what happens when one of these assumptionsâ€”the independence of observationsâ€”is violated, a common situation in fields like finance and econometrics that deal with time-series data. By analyzing why the standard t-statistic fails for an MA(1) process [@problem_id:1335725], you will develop a deeper, more robust understanding of the theoretical underpinnings of statistical testing.", "problem": "Consider a time series model known as a first-order moving-average, or MA(1), process. This process is defined for discrete time points $t=1, 2, ..., n$ as:\n$$X_t = \\mu + \\epsilon_t + \\theta \\epsilon_{t-1}$$\nHere, $\\mu$ is the constant mean of the process, $\\theta$ is a constant parameter with $|\\theta| < 1$, and $\\epsilon_t$ represents a sequence of independent and identically distributed random variables drawn from a normal distribution with mean 0 and variance $\\sigma^2$, often called \"white noise\".\n\nA researcher collects a sample of $n$ observations $\\{X_1, X_2, ..., X_n\\}$ from this process. To test a hypothesis about the mean, $H_0: \\mu = \\mu_0$, they compute the sample mean $\\hat{\\mu} = \\frac{1}{n} \\sum_{t=1}^{n} X_t$ and the sample standard deviation $S = \\sqrt{\\frac{1}{n-1} \\sum_{t=1}^{n} (X_t - \\hat{\\mu})^2}$. They then form the standard test statistic:\n$$T = \\frac{\\hat{\\mu} - \\mu_0}{S / \\sqrt{n}}$$\nUnder the standard assumptions for a one-sample t-test, this statistic would follow a Student's t-distribution with $n-1$ degrees of freedom. However, for the MA(1) process with $\\theta \\neq 0$, this is not the case.\n\nWhich of the following statements provides the most accurate and fundamental reason why the statistic $T$ does not exactly follow a Student's t-distribution for an MA(1) process where $\\theta \\neq 0$?\n\nA. The sample mean $\\hat{\\mu}$ is a biased estimator of the true mean $\\mu$.\n\nB. The individual observations $X_t$ are not normally distributed due to the presence of the lagged term $\\theta \\epsilon_{t-1}$.\n\nC. The MA(1) process is not weakly stationary, meaning its variance changes over time, which invalidates the assumptions of the t-test.\n\nD. The observations $X_t$ are serially correlated, which violates the assumption of sample independence required for the scaled sample variance to follow a chi-squared distribution.\n\nE. The parameter $\\theta$ makes the model non-linear, and the t-test is only strictly valid for data from linear models.", "solution": "We recall the standard t-test result. If $X_{1},\\dots,X_{n}$ are independent and identically distributed as $N(\\mu,\\sigma^{2})$, then:\n- The sample mean satisfies $\\sqrt{n}\\,(\\hat{\\mu}-\\mu)/\\sigma \\sim N(0,1)$.\n- The scaled sample variance satisfies $(n-1)S^{2}/\\sigma^{2} \\sim \\chi^{2}_{n-1}$.\n- Moreover, $\\hat{\\mu}$ and $S^{2}$ are independent.\nFrom these three facts, it follows that\n$$\nT \\;=\\; \\frac{\\hat{\\mu}-\\mu_{0}}{S/\\sqrt{n}}\n$$\nhas a Studentâ€™s $t$ distribution with $n-1$ degrees of freedom under $H_{0}:\\mu=\\mu_{0}$.\n\nNow analyze the MA(1) process $X_{t}=\\mu+\\epsilon_{t}+\\theta\\epsilon_{t-1}$ with $|\\theta|<1$ and $\\epsilon_{t}\\stackrel{\\text{i.i.d.}}{\\sim}N(0,\\sigma^{2})$.\n\n1) Marginal normality and unbiasedness:\nBecause $X_{t}$ is an affine transformation of jointly normal innovations, each $X_{t}$ is normal. Specifically,\n$$\n\\mathbb{E}[X_{t}] \\;=\\; \\mu,\\qquad \\operatorname{Var}(X_{t}) \\;=\\; (1+\\theta^{2})\\sigma^{2}.\n$$\nHence $X_{t}$ is normal (so statement B is false), and the sample mean is unbiased:\n$$\n\\mathbb{E}[\\hat{\\mu}] \\;=\\; \\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}[X_{t}] \\;=\\; \\mu\n$$\n(so statement A is false).\n\n2) Stationarity:\nThe autocovariance function is\n$$\n\\gamma_{0} \\;=\\; (1+\\theta^{2})\\sigma^{2},\\qquad \\gamma_{1} \\;=\\; \\theta\\sigma^{2},\\qquad \\gamma_{h}\\;=\\;0\\quad \\text{for }|h|\\ge 2,\n$$\nwhich does not depend on $t$. Therefore the process is weakly stationary (so statement C is false).\n\n3) Serial correlation:\nFor $\\theta\\neq 0$, we have $\\gamma_{1}\\neq 0$, hence\n$$\n\\operatorname{Cov}(X_{t},X_{t-1}) \\;=\\; \\theta\\sigma^{2}\\neq 0,\n$$\nso the observations are serially correlated. The $n$-vector $X=(X_{1},\\dots,X_{n})^{\\top}$ is multivariate normal with mean $\\mu\\mathbf{1}$ and a non-diagonal covariance matrix $\\Sigma$ whose first off-diagonals are $\\gamma_{1}$.\n\n4) Consequences for the t-statistic:\n- The variance of the sample mean differs from the i.i.d. case. Using $\\operatorname{Var}(\\hat{\\mu})=\\frac{1}{n^{2}}\\sum_{t=1}^{n}\\sum_{s=1}^{n}\\gamma_{|t-s|}$ and the MA(1) autocovariances,\n$$\n\\operatorname{Var}(\\hat{\\mu}) \\;=\\; \\frac{1}{n^{2}}\\Big(n\\gamma_{0} + 2(n-1)\\gamma_{1}\\Big)\n\\;=\\; \\sigma^{2}\\,\\frac{n(1+\\theta^{2}) + 2(n-1)\\theta}{n^{2}},\n$$\nwhich is not $\\sigma^{2}/n$ unless $\\theta=0$.\n\n- More fundamentally, the exact $t$ law requires both that $(n-1)S^{2}/\\sigma^{2}\\sim \\chi^{2}_{n-1}$ and that $\\hat{\\mu}$ be independent of $S^{2}$. These properties hinge on independence of the $X_{t}$. With serial correlation, $(n-1)S^{2}/\\sigma^{2}$ is not $\\chi^{2}_{n-1}$ (it is a weighted sum of independent $\\chi^{2}_{1}$ terms determined by the eigenvalues of a transformed covariance matrix), and $\\hat{\\mu}$ and $S^{2}$ are not independent. Thus the ratio $T$ does not follow a Studentâ€™s $t$ distribution.\n\n5) Linearity:\nThe MA(1) model is linear in the innovations (so statement E is false).\n\nTherefore, the most accurate and fundamental reason is the violation of independence due to serial correlation among the $X_{t}$, which breaks the chi-squared and independence properties required for the $t$ result. Hence, statement D is correct.", "answer": "$$\\boxed{D}$$", "id": "1335725"}]}