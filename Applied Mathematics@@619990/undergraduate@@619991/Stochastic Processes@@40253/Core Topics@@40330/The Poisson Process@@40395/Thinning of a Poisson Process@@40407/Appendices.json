{"hands_on_practices": [{"introduction": "The act of 'thinning' or 'splitting' a Poisson process is a fundamental operation with wide-ranging applications. This first practice explores a core consequence of this operation: if we know the total number of events that occurred in an interval, what can we say about the number of events belonging to a specific sub-category? This exercise demonstrates the elegant link between the continuous-time Poisson process and the discrete binomial distribution, a cornerstone concept for analyzing categorized count data. [@problem_id:1346161]", "problem": "The arrivals of visitors to a news website's homepage are modeled as a Poisson process with a constant average rate of $\\lambda$ visitors per minute. The website employs a content personalization system that classifies each visitor, independently of all others, as a 'Tech Enthusiast' with probability $p$ or a 'Finance Buff' with probability $1-p$.\n\nConsider a specific time interval of $T$ minutes. During this interval, it was recorded that a total of $N$ visitors arrived at the homepage. Given this information, find the probability that exactly $k$ of these visitors were classified as 'Tech Enthusiasts'. Assume $0 \\le k \\le N$. Express your answer as a symbolic expression in terms of $N$, $k$, and $p$.", "solution": "Let $N(t)$ denote the total number of visitors arriving in an interval of length $t$. According to the problem statement, $N(t)$ follows a Poisson process with rate $\\lambda$. The number of arrivals in a time interval of $T$ minutes, $N(T)$, is therefore a Poisson random variable with parameter $\\lambda T$. The probability mass function (PMF) is given by:\n$$ P(N(T) = n) = \\frac{\\exp(-\\lambda T) (\\lambda T)^n}{n!} $$\n\nThe stream of visitors is split into two categories: 'Tech Enthusiasts' and 'Finance Buffs'. Let $N_T(t)$ be the number of 'Tech Enthusiasts' arriving in time $t$, and $N_F(t)$ be the number of 'Finance Buffs' arriving in time $t$.\n\nA fundamental property of Poisson processes, known as thinning or splitting, states that if a Poisson process with rate $\\lambda$ is split into two streams with probabilities $p$ and $1-p$ for each arrival, then the two resulting streams are independent Poisson processes.\nThe rate for 'Tech Enthusiasts' is $\\lambda_T = \\lambda p$.\nThe rate for 'Finance Buffs' is $\\lambda_F = \\lambda (1-p)$.\n\nThus, $N_T(T)$ is a Poisson random variable with parameter $\\lambda p T$, and $N_F(T)$ is a Poisson random variable with parameter $\\lambda (1-p) T$. Their respective PMFs are:\n$$ P(N_T(T) = k) = \\frac{\\exp(-\\lambda p T) (\\lambda p T)^k}{k!} $$\n$$ P(N_F(T) = j) = \\frac{\\exp(-\\lambda (1-p) T) (\\lambda (1-p) T)^j}{j!} $$\n\nWe are asked to find the conditional probability that there were $k$ 'Tech Enthusiasts', given that the total number of visitors was $N$. This can be written as $P(N_T(T) = k | N(T) = N)$.\n\nUsing the definition of conditional probability:\n$$ P(N_T(T) = k | N(T) = N) = \\frac{P(N_T(T) = k \\text{ and } N(T) = N)}{P(N(T) = N)} $$\n\nThe event $\\{N_T(T) = k \\text{ and } N(T) = N\\}$ is the same as the event that there are $k$ 'Tech Enthusiasts' and $N-k$ 'Finance Buffs'. That is, $\\{N_T(T) = k \\text{ and } N_F(T) = N-k\\}$.\nSince the two thinned processes are independent, we can write the joint probability as the product of their individual probabilities:\n$$ P(N_T(T) = k, N_F(T) = N-k) = P(N_T(T) = k) \\cdot P(N_F(T) = N-k) $$\nSubstituting the PMFs:\n$$ P(N_T(T) = k, N_F(T) = N-k) = \\left( \\frac{\\exp(-\\lambda p T) (\\lambda p T)^k}{k!} \\right) \\cdot \\left( \\frac{\\exp(-\\lambda (1-p) T) (\\lambda (1-p) T)^{N-k}}{(N-k)!} \\right) $$\nLet's simplify this expression for the numerator:\n$$ \\text{Numerator} = \\frac{\\exp(-\\lambda p T - \\lambda (1-p) T) (\\lambda T)^k p^k (\\lambda T)^{N-k} (1-p)^{N-k}}{k!(N-k)!} $$\n$$ \\text{Numerator} = \\frac{\\exp(-\\lambda T (p + 1 - p)) (\\lambda T)^{k + N - k} p^k (1-p)^{N-k}}{k!(N-k)!} $$\n$$ \\text{Numerator} = \\frac{\\exp(-\\lambda T) (\\lambda T)^N p^k (1-p)^{N-k}}{k!(N-k)!} $$\n\nThe denominator is $P(N(T) = N)$, which we know is:\n$$ \\text{Denominator} = P(N(T) = N) = \\frac{\\exp(-\\lambda T) (\\lambda T)^N}{N!} $$\n\nNow we compute the ratio:\n$$ P(N_T(T) = k | N(T) = N) = \\frac{\\frac{\\exp(-\\lambda T) (\\lambda T)^N p^k (1-p)^{N-k}}{k!(N-k)!}}{\\frac{\\exp(-\\lambda T) (\\lambda T)^N}{N!}} $$\nThe terms $\\exp(-\\lambda T)$ and $(\\lambda T)^N$ cancel out, leaving:\n$$ P(N_T(T) = k | N(T) = N) = \\frac{N! p^k (1-p)^{N-k}}{k!(N-k)!} $$\nThis expression is the probability mass function for a binomial distribution with $N$ trials and success probability $p$. Using the binomial coefficient notation $\\binom{N}{k} = \\frac{N!}{k!(N-k)!}$, the final expression is:\n$$ \\binom{N}{k} p^k (1-p)^{N-k} $$", "answer": "$$ \\boxed{\\binom{N}{k} p^{k} (1-p)^{N-k}} $$", "id": "1346161"}, {"introduction": "Having established the distribution of counts within a fixed interval, we now shift our perspective from a time-based frame to the sequence of event types themselves. This problem investigates the number of 'background' events that occur between two consecutive 'signal' events. [@problem_id:1407533] The solution reveals a fascinating insight: by focusing on the order of event types, the problem simplifies to analyzing a sequence of Bernoulli trials, leading to the geometric distribution, irrespective of the original process's rate.", "problem": "In a particle physics experiment, a beam of particles is directed towards a detector. The arrival times of these particles at the detector can be modeled as a Poisson process with a constant average rate of $\\lambda$ particles per second. Each arriving particle is, independently of all other particles, classified as a 'signal' particle with a probability $p$, or a 'background' particle with a probability $1-p$. A data acquisition system is configured to trigger and record an event only when a 'signal' particle is detected; 'background' particles do not trigger the system and are effectively ignored.\n\nLet $N$ be the discrete random variable representing the number of 'background' particles that arrive at the detector in the interval between two consecutive 'signal' particle arrivals. Determine the probability mass function, $P(N=k)$, for $k=0, 1, 2, \\dots$. Your final answer should be an expression in terms of $p$ and $k$.", "solution": "The problem asks for the probability distribution of the number of 'background' particles, $N$, that occur between two consecutive 'signal' particles.\n\nLet's consider the sequence of particle types as they arrive at the detector. Each particle arrival constitutes an independent trial. The outcome of each trial can be either 'signal' (S) with probability $p$, or 'background' (B) with probability $1-p$. This forms a sequence of independent Bernoulli trials.\n\nThe question is about the number of background particles *between* two consecutive signal particles. This means we are observing the system starting from the moment a signal particle has just arrived. We want to find the probability that the following sequence of events occurs: a certain number of background particles arrive, and then the next particle to arrive is a signal particle, which ends the interval.\n\nLet's denote the event of interest as $\\{N=k\\}$. This corresponds to observing exactly $k$ background particles followed immediately by one signal particle. The sequence of particle classifications would look like this:\n$$\n\\underbrace{\\text{B, B, ..., B}}_{k \\text{ times}}, \\text{S}\n$$\nThe probability of a single particle being a background particle is $P(\\text{B}) = 1-p$.\nThe probability of a single particle being a signal particle is $P(\\text{S}) = p$.\n\nSince the classification of each particle is an independent event, the probability of observing this specific sequence is the product of the probabilities of each individual outcome.\nThe probability of getting $k$ consecutive background particles is $(P(\\text{B}))^k = (1-p)^k$.\nThe probability of the next particle being a signal particle is $P(\\text{S})=p$.\n\nTherefore, the probability of the entire sequence, which corresponds to the event $\\{N=k\\}$, is:\n$$\nP(N=k) = P(\\underbrace{\\text{B, B, ..., B}}_{k \\text{ times}}, \\text{S}) = (P(\\text{B}))^{k} \\times P(\\text{S})\n$$\nSubstituting the probabilities, we get:\n$$\nP(N=k) = (1-p)^{k} p\n$$\nThis is the probability mass function (PMF) for a geometric distribution, where the \"success\" is observing a signal particle. The random variable $N=k$ counts the number of \"failures\" (background particles) before the first success. This holds for $k = 0, 1, 2, \\dots$.\n\nNote that the Poisson process rate $\\lambda$ does not appear in the final answer. The problem is concerned with the sequence of event *types*, not the *time* between them. The question can be entirely rephrased as analyzing a sequence of independent Bernoulli trials, making the arrival time information provided by $\\lambda$ irrelevant to the final probability calculation for the count of particles.", "answer": "$$\\boxed{(1-p)^{k} p}$$", "id": "1407533"}, {"introduction": "Our final practice moves into the realm of statistical inference, a common task in real-world scenarios where we only have partial information. This exercise asks you to deduce a property of the total process—the expected total number of arrivals—given an observation from just one of the thinned sub-processes. [@problem_id:1407530] Successfully solving this requires applying the crucial theorem that thinned Poisson processes are independent, a property that is key to many practical applications in fields like network engineering and operations research.", "problem": "Data packets arrive at a core network router according to a Poisson process with a mean rate of $\\lambda = 150$ packets per second. Each incoming packet is independently classified as 'high-priority' with a probability of $p = 0.20$, or as 'low-priority' with a probability of $1-p$. During a specific observation interval of duration $T = 2.0$ seconds, a network analyzer records that exactly $k = 50$ high-priority packets were received.\n\nGiven this observation, calculate the expected total number of packets (both high- and low-priority) that arrived at the router during this 2.0-second interval.", "solution": "Let $N(t)$ be the total number of packets arriving in an interval of length $t$. According to the problem statement, $N(t)$ follows a Poisson process with rate $\\lambda$. The number of arrivals in a time interval of duration $T$ is a Poisson random variable, $N(T)$, with parameter $\\lambda T$.\n$$N(T) \\sim \\text{Poisson}(\\lambda T)$$\n\nThe stream of total packets is split into two streams: high-priority and low-priority packets. This is a classic example of thinning a Poisson process.\nLet $N_H(T)$ be the number of high-priority packets and $N_L(T)$ be the number of low-priority packets arriving in the interval $T$.\nDue to the thinning property of Poisson processes, $N_H(T)$ and $N_L(T)$ are also Poisson random variables.\nThe rate of high-priority arrivals is $\\lambda_H = p \\lambda$. Thus, $N_H(T) \\sim \\text{Poisson}(p \\lambda T)$.\nThe rate of low-priority arrivals is $\\lambda_L = (1-p) \\lambda$. Thus, $N_L(T) \\sim \\text{Poisson}((1-p) \\lambda T)$.\nA crucial property of thinning is that the resulting processes are independent. Therefore, the random variables $N_H(T)$ and $N_L(T)$ are independent.\n\nThe total number of packets is the sum of the high-priority and low-priority packets:\n$$N(T) = N_H(T) + N_L(T)$$\n\nThe problem asks for the expected total number of packets given that exactly $k$ high-priority packets were observed. This is the conditional expectation $E[N(T) | N_H(T) = k]$.\n\nWe can write this as:\n$$E[N(T) | N_H(T) = k] = E[N_H(T) + N_L(T) | N_H(T) = k]$$\n\nBy the linearity of expectation, we can split this into two terms:\n$$E[N(T) | N_H(T) = k] = E[N_H(T) | N_H(T) = k] + E[N_L(T) | N_H(T) = k]$$\n\nLet's evaluate each term separately.\nThe first term, $E[N_H(T) | N_H(T) = k]$, is the expectation of the variable $N_H(T)$ given that its value is fixed at $k$. The expectation of a constant is just the constant itself.\n$$E[N_H(T) | N_H(T) = k] = k$$\n\nFor the second term, $E[N_L(T) | N_H(T) = k]$, we use the independence of $N_L(T)$ and $N_H(T)$. Since the two random variables are independent, conditioning on the value of $N_H(T)$ does not provide any information about $N_L(T)$. Therefore, the conditional expectation is equal to the unconditional expectation:\n$$E[N_L(T) | N_H(T) = k] = E[N_L(T)]$$\n\nThe random variable $N_L(T)$ follows a Poisson distribution with parameter $(1-p)\\lambda T$. The expectation of a Poisson random variable is its parameter.\n$$E[N_L(T)] = (1-p)\\lambda T$$\n\nCombining these results, we get the expression for the conditional expectation:\n$$E[N(T) | N_H(T) = k] = k + (1-p)\\lambda T$$\n\nNow, we substitute the given numerical values:\n$k = 50$\n$p = 0.20$\n$\\lambda = 150 \\text{ s}^{-1}$\n$T = 2.0 \\text{ s}$\n\n$$E[N(T) | N_H(T) = 50] = 50 + (1 - 0.20)(150)(2.0)$$\n$$E[N(T) | N_H(T) = 50] = 50 + (0.80)(300)$$\n$$E[N(T) | N_H(T) = 50] = 50 + 240$$\n$$E[N(T) | N_H(T) = 50] = 290$$\n\nSo, the expected total number of packets that arrived during the interval is 290.", "answer": "$$\\boxed{290}$$", "id": "1407530"}]}