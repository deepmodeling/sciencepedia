{"hands_on_practices": [{"introduction": "The generator matrix, or $Q$-matrix, is the heart of any continuous-time Markov chain, encoding all possible transitions and their rates in a single, compact structure. This exercise provides practice in the essential skill of constructing this matrix from a system's description, translating process rules into a formal mathematical object [@problem_id:1347534]. Mastering this step is crucial as the generator matrix forms the basis for nearly all further analysis of a process's behavior.", "problem": "A modern logistics company models the journey of a package using a continuous-time Markov chain. The state of a package can be one of four possibilities:\n- State 1: 'Processing' (at the initial warehouse)\n- State 2: 'In Transit' (on its way to the recipient)\n- State 3: 'Delivered' (successfully received by the customer)\n- State 4: 'Awaiting Return' (delivery failed, pending return to the warehouse)\n\nThe package transitions between these states according to the following rules and constant rates:\n- A package that is 'Processing' is sent out and becomes 'In Transit' at a rate of $\\alpha$.\n- A package that is 'In Transit' is successfully 'Delivered' at a rate of $\\beta$.\n- A package that is 'In Transit' can also fail delivery and become 'Awaiting Return' at a rate of $\\gamma$.\n- A package that is 'Awaiting Return' is sent back to the warehouse for reprocessing, re-entering the 'Processing' state at a rate of $\\delta$.\n- Once a package is 'Delivered', it is considered an absorbing state, meaning it remains 'Delivered' forever.\n- No other transitions are possible.\n\nGiven this model, identify the correct generator matrix $Q$ for this process, where the states are ordered as (1: 'Processing', 2: 'In Transit', 3: 'Delivered', 4: 'Awaiting Return').\n\nWhich of the following matrices represents $Q$?\n\nA.\n$$\n\\begin{pmatrix}\n-\\alpha & \\alpha & 0 & 0 \\\\\n0 & -(\\beta+\\gamma) & \\beta & \\gamma \\\\\n0 & 0 & 0 & 0 \\\\\n\\delta & 0 & 0 & -\\delta\n\\end{pmatrix}\n$$\n\nB.\n$$\n\\begin{pmatrix}\n-\\alpha & \\alpha & 0 & 0 \\\\\n0 & -\\beta & \\beta & \\gamma \\\\\n0 & 0 & 0 & 0 \\\\\n\\delta & 0 & 0 & -\\delta\n\\end{pmatrix}\n$$\n\nC.\n$$\n\\begin{pmatrix}\n1-\\alpha & \\alpha & 0 & 0 \\\\\n0 & 1-\\beta-\\gamma & \\beta & \\gamma \\\\\n0 & 0 & 1 & 0 \\\\\n\\delta & 0 & 0 & 1-\\delta\n\\end{pmatrix}\n$$\n\nD.\n$$\n\\begin{pmatrix}\n-\\alpha & \\alpha & 0 & \\delta \\\\\n0 & -(\\beta+\\gamma) & \\beta & 0 \\\\\n0 & \\gamma & 0 & 0 \\\\\n0 & 0 & 0 & -\\delta\n\\end{pmatrix}\n$$\n\nE.\n$$\n\\begin{pmatrix}\n-\\alpha & \\alpha & 0 & 0 \\\\\n\\delta & -(\\beta+\\gamma) & \\beta & \\gamma \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & -\\delta\n\\end{pmatrix}\n$$", "solution": "For a continuous-time Markov chain, the generator matrix $Q$ satisfies the following properties:\n- For $i \\neq j$, $q_{ij} \\geq 0$ represents the transition rate from state $i$ to state $j$.\n- For each state $i$, the diagonal entry is $q_{ii} = -\\sum_{j \\neq i} q_{ij}$ so that each row sums to zero.\n- If a state is absorbing, then its entire row is zero.\n\nFrom the problem description with states ordered as $(1,2,3,4)$ corresponding to (Processing, In Transit, Delivered, Awaiting Return), the allowed transitions and rates are:\n- From state $1$ to state $2$ at rate $\\alpha$, and no other transitions out of state $1$. Hence,\n$$\nq_{12}=\\alpha,\\quad q_{11}=-\\alpha,\\quad q_{13}=0,\\quad q_{14}=0.\n$$\n- From state $2$ to state $3$ at rate $\\beta$ and to state $4$ at rate $\\gamma$, and no other transitions out of state $2$. Hence,\n$$\nq_{23}=\\beta,\\quad q_{24}=\\gamma,\\quad q_{21}=0,\\quad q_{22}=-(\\beta+\\gamma).\n$$\n- State $3$ (Delivered) is absorbing. Hence,\n$$\nq_{3j}=0\\ \\text{for all } j,\\quad \\text{so } q_{33}=0.\n$$\n- From state $4$ to state $1$ at rate $\\delta$, and no other transitions out of state $4$. Hence,\n$$\nq_{41}=\\delta,\\quad q_{44}=-\\delta,\\quad q_{42}=0,\\quad q_{43}=0.\n$$\n\nCollecting these entries, the generator matrix is\n$$\nQ=\\begin{pmatrix}\n-\\alpha & \\alpha & 0 & 0 \\\\\n0 & -(\\beta+\\gamma) & \\beta & \\gamma \\\\\n0 & 0 & 0 & 0 \\\\\n\\delta & 0 & 0 & -\\delta\n\\end{pmatrix}.\n$$\nThis matches option A. Options B, C, D, and E violate generator matrix properties or include forbidden transitions: B has an incorrect diagonal in row $2$; C is a discrete-time transition matrix form; D and E include non-permitted transitions or omit required ones.", "answer": "$$\\boxed{A}$$", "id": "1347534"}, {"introduction": "Once a system is described by transition rates, a fundamental question is how long it will remain in its current state before a change occurs. This problem explores the concept of holding time, which is governed by an exponential distribution whose rate is the sum of all exit rates from a state [@problem_id:1347554]. By calculating the expected holding time in a practical ride-sharing scenario, you will connect the abstract transition rates to a tangible and predictable outcome.", "problem": "A driver for a ride-sharing service can be in one of three states: 'Available' ($S_1$), 'Driving to a passenger' ($S_2$), or 'On a trip' ($S_3$). The transitions between these states are modeled as a continuous-time Markov process with constant transition rates.\n\nWhen the driver is in the 'Available' state ($S_1$), they can receive two types of requests. A standard request transitions them to the 'Driving to a passenger' state ($S_2$) with a rate of $\\lambda_{12} = 2.4$ requests per hour. An immediate pickup request, for a passenger at their current location, transitions them directly to the 'On a trip' state ($S_3$) with a rate of $\\lambda_{13} = 0.8$ requests per hour.\n\nOther transitions in the system are as follows: From state $S_2$, a passenger cancellation can occur, returning the driver to state $S_1$ with a rate of $\\lambda_{21} = 0.7$ per hour. Alternatively, the driver can successfully pick up the passenger, transitioning to state $S_3$ with a rate of $\\lambda_{23} = 11.5$ per hour. Upon completing a trip in state $S_3$, the driver returns to the 'Available' state $S_1$ with a rate of $\\lambda_{31} = 2.9$ per hour.\n\nAssuming the driver has just become 'Available', what is the expected amount of time they will remain in this 'Available' state before transitioning to another state? Express your answer in minutes, rounded to three significant figures.", "solution": "Let $T_1$ be the random variable representing the time the driver spends in the 'Available' state ($S_1$) during a single visit. In a continuous-time Markov process, the holding time in any state $i$ follows an exponential distribution. The rate parameter of this distribution, let's call it $q_i$, is the sum of the rates of all possible transitions out of state $i$.\n\nIn this problem, we are interested in the expected holding time in state $S_1$. The total rate of leaving state $S_1$, denoted as $q_1$, is the sum of the rates of all transitions originating from $S_1$. Based on the problem description, there are two ways for the driver to leave the 'Available' state:\n1. Transition to state $S_2$ ('Driving to a passenger') with rate $\\lambda_{12}$.\n2. Transition to state $S_3$ ('On a trip') with rate $\\lambda_{13}$.\n\nThe rates for transitions out of other states (e.g., $\\lambda_{21}$, $\\lambda_{23}$, $\\lambda_{31}$) are not relevant for calculating the holding time in state $S_1$.\n\nThe total exit rate from state $S_1$ is the sum of the rates of these two transitions:\n$$q_1 = \\lambda_{12} + \\lambda_{13}$$\nSubstituting the given values:\n$$q_1 = 2.4 \\text{ hr}^{-1} + 0.8 \\text{ hr}^{-1} = 3.2 \\text{ hr}^{-1}$$\nThe holding time $T_1$ is thus exponentially distributed with rate parameter $q_1 = 3.2 \\text{ hr}^{-1}$.\n\nThe expected value (mean) of an exponential random variable with rate parameter $\\lambda$ is given by $E[T] = \\frac{1}{\\lambda}$.\nTherefore, the expected time the driver remains in the 'Available' state is:\n$$E[T_1] = \\frac{1}{q_1} = \\frac{1}{3.2 \\text{ hr}^{-1}} = \\frac{1}{3.2} \\text{ hours}$$\nThe problem asks for the answer in minutes. We must convert the units from hours to minutes:\n$$E[T_1] \\text{ in minutes} = \\left(\\frac{1}{3.2} \\text{ hours}\\right) \\times \\left(\\frac{60 \\text{ minutes}}{1 \\text{ hour}}\\right)$$\nNow we calculate the numerical value:\n$$E[T_1] = \\frac{60}{3.2} = \\frac{600}{32} = \\frac{300}{16} = \\frac{150}{8} = \\frac{75}{4} = 18.75 \\text{ minutes}$$\nFinally, we need to round the result to three significant figures as requested. The first three significant figures are 1, 8, and 7. The next digit is 5, which means we round up the last significant digit.\n$$18.75 \\approx 18.8$$\nSo, the expected time the driver remains in the 'Available' state is 18.8 minutes.", "answer": "$$\\boxed{18.8}$$", "id": "1347554"}, {"introduction": "Beyond short-term behavior, we are often interested in the long-term stability of a stochastic process. This exercise investigates the concept of positive recurrence, which determines whether a system has a stable equilibrium or will instead drift to infinity [@problem_id:1347523]. By analyzing a random walk with state-dependent rates, you will learn to identify the conditions that ensure a process is well-behaved and possesses a stationary distribution, a cornerstone of system stability analysis.", "problem": "Consider a continuous-time Markov chain $\\{X(t) : t \\ge 0\\}$ on the set of integers $\\mathbb{Z} = \\{..., -2, -1, 0, 1, 2, ...\\}$. This process can be visualized as a particle performing a random walk on the integer line. The particle can only jump to its nearest neighbors.\n\nThe transition rates are state-dependent and are defined as follows, where $\\lambda_1, \\lambda_2, \\mu_1, \\mu_2$ are all strictly positive real constants:\n- The rate of jumping from state $i$ to state $i+1$ is $\\lambda_1$ if $i \\ge 0$, and $\\lambda_2$ if $i < 0$.\n- The rate of jumping from state $i$ to state $i-1$ is $\\mu_1$ if $i > 0$, and $\\mu_2$ if $i \\le 0$.\n\nUnder which of the following conditions is the process positive recurrent?\n\nA. $\\lambda_1 > \\mu_1$ and $\\lambda_2 > \\mu_2$\nB. $\\lambda_1 < \\mu_1$ and $\\lambda_2 < \\mu_2$\nC. $\\lambda_1 > \\mu_1$ and $\\lambda_2 < \\mu_2$\nD. $\\lambda_1 < \\mu_1$ and $\\lambda_2 > \\mu_2$", "solution": "We model the chain as a birth–death process on $\\mathbb{Z}$ with nearest-neighbor rates:\n- For $i \\geq 0$, $q_{i,i+1}=\\lambda_{1}$ and for $i>0$, $q_{i,i-1}=\\mu_{1}$.\n- For $i<0$, $q_{i,i+1}=\\lambda_{2}$ and for $i \\leq 0$, $q_{i,i-1}=\\mu_{2}$.\nAll four rates are strictly positive, so the chain is irreducible. A continuous-time birth–death chain on $\\mathbb{Z}$ is positive recurrent if and only if it admits a stationary probability distribution $\\{\\pi_{i}\\}_{i\\in\\mathbb{Z}}$ with $\\sum_{i\\in\\mathbb{Z}}\\pi_{i}=1$. For birth–death processes, a reversible stationary distribution (hence stationary) is obtained by imposing the detailed balance relations\n$$\n\\pi_{i}q_{i,i+1}=\\pi_{i+1}q_{i+1,i},\\quad \\text{for all }i\\in\\mathbb{Z}.\n$$\nWe solve these recurrences separately on the positive and negative sides.\n\nFor $i \\geq 0$, one has $q_{i,i+1}=\\lambda_{1}$ and $q_{i+1,i}=\\mu_{1}$ (since $i+1>0$), hence\n$$\n\\pi_{i+1}=\\pi_{i}\\frac{\\lambda_{1}}{\\mu_{1}} \\quad \\Rightarrow \\quad \\pi_{n}=\\pi_{0}\\left(\\frac{\\lambda_{1}}{\\mu_{1}}\\right)^{n},\\quad n\\geq 0.\n$$\n\nAcross $0$ and on the negative side, first relate $\\pi_{-1}$ to $\\pi_{0}$. At $i=-1$, $q_{-1,0}=\\lambda_{2}$, and at $i=0$, $q_{0,-1}=\\mu_{2}$, so detailed balance gives\n$$\n\\pi_{-1}\\lambda_{2}=\\pi_{0}\\mu_{2}\\quad \\Rightarrow \\quad \\pi_{-1}=\\pi_{0}\\frac{\\mu_{2}}{\\lambda_{2}}.\n$$\nFor $i\\leq -1$, we have $q_{i,i-1}=\\mu_{2}$ and $q_{i-1,i}=\\lambda_{2}$ (since both indices are $\\leq 0$ or $<0$ as needed), so\n$$\n\\pi_{i-1}=\\pi_{i}\\frac{\\mu_{2}}{\\lambda_{2}}.\n$$\nIterating this gives, for $n\\geq 1$,\n$$\n\\pi_{-n}=\\pi_{0}\\left(\\frac{\\mu_{2}}{\\lambda_{2}}\\right)^{n}.\n$$\n\nTherefore, up to the normalizing constant $\\pi_{0}$, the candidate stationary measure is\n$$\n\\pi_{n}=\\pi_{0}\\left(\\frac{\\lambda_{1}}{\\mu_{1}}\\right)^{n}\\ \\text{for }n\\geq 0,\\qquad\n\\pi_{-n}=\\pi_{0}\\left(\\frac{\\mu_{2}}{\\lambda_{2}}\\right)^{n}\\ \\text{for }n\\geq 1.\n$$\nThis defines a stationary probability distribution if and only if the total mass is finite:\n$$\n\\sum_{n=0}^{\\infty}\\pi_{n}+\\sum_{n=1}^{\\infty}\\pi_{-n}\n=\\pi_{0}\\left(1+\\sum_{n=1}^{\\infty}\\left(\\frac{\\lambda_{1}}{\\mu_{1}}\\right)^{n}+\\sum_{n=1}^{\\infty}\\left(\\frac{\\mu_{2}}{\\lambda_{2}}\\right)^{n}\\right)<\\infty.\n$$\nEach geometric series converges if and only if its ratio has absolute value less than $1$. Since all rates are strictly positive, this requires\n$$\n\\frac{\\lambda_{1}}{\\mu_{1}}<1 \\quad \\text{and} \\quad \\frac{\\mu_{2}}{\\lambda_{2}}<1,\n$$\nequivalently,\n$$\n\\lambda_{1}<\\mu_{1}\\quad \\text{and} \\quad \\lambda_{2}>\\mu_{2}.\n$$\nBecause the chain is irreducible, the existence of a finite stationary distribution is equivalent to positive recurrence. Hence the process is positive recurrent exactly under $\\lambda_{1}<\\mu_{1}$ and $\\lambda_{2}>\\mu_{2}$, which corresponds to option D.", "answer": "$$\\boxed{D}$$", "id": "1347523"}]}