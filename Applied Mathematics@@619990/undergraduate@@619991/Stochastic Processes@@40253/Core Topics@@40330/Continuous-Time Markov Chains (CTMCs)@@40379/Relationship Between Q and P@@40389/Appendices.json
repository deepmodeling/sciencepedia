{"hands_on_practices": [{"introduction": "In many scientific and financial applications, we must decide which of two competing probabilistic models best explains our observations. This requires a way to \"translate\" between the two corresponding probability measures, $P$ and $Q$. The Radon-Nikodym derivative serves as this translation key, quantifying how much more likely an observation is under one model compared to the other. This exercise [@problem_id:1330409] provides hands-on practice in calculating this crucial derivative for a fundamental scenario: a change in the mean of a Normal distribution.", "problem": "In the field of statistical signal processing, a common task is to distinguish between different models for an observed signal. Consider a scenario where a single measurement, represented by a random variable $X$, is recorded. There are two competing hypotheses about the underlying data-generating process.\n\nUnder a baseline hypothesis, which we associate with a probability measure $P$, the measurement $X$ is assumed to follow a Normal distribution with mean $\\mu$ and variance $\\sigma^2$.\n\nUnder an alternative hypothesis, associated with a probability measure $Q$, the measurement $X$ is assumed to follow a different Normal distribution with a shifted mean $\\nu$ but the same variance $\\sigma^2$. The change in mean is attributed to a persistent, non-random effect influencing the signal.\n\nThe Radon-Nikodym derivative, denoted $\\frac{dQ}{dP}$, serves as the likelihood ratio and is a fundamental tool for constructing optimal decision rules between these two hypotheses. It quantifies how much more likely a given observation $x$ is under measure $Q$ compared to measure $P$.\n\nGiven that the Probability Density Function (PDF) for a Normal distribution with mean $m$ and variance $s^2$ is $f(x) = \\frac{1}{\\sqrt{2\\pi}s} \\exp\\left(-\\frac{(x - m)^2}{2s^2}\\right)$, determine the Radon-Nikodym derivative $\\frac{dQ}{dP}$ as a function of an observed value $x$ and the parameters $\\mu$, $\\nu$, and $\\sigma$.", "solution": "Under $P$, $X$ has density $f_{P}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right)$, and under $Q$, $X$ has density $f_{Q}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x-\\nu)^{2}}{2\\sigma^{2}}\\right)$. Since both distributions are absolutely continuous with respect to Lebesgue measure, the Radon-Nikodym derivative of $Q$ with respect to $P$ at $x$ is the likelihood ratio\n$$\n\\frac{dQ}{dP}(x)=\\frac{f_{Q}(x)}{f_{P}(x)}.\n$$\nSubstituting the given Gaussian densities,\n$$\n\\frac{dQ}{dP}(x)=\\frac{\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x-\\nu)^{2}}{2\\sigma^{2}}\\right)}{\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right)}=\\exp\\left(-\\frac{(x-\\nu)^{2}}{2\\sigma^{2}}+\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right).\n$$\nCombine the terms in the exponent:\n$$\n\\frac{(x-\\mu)^{2}-(x-\\nu)^{2}}{2\\sigma^{2}}=\\frac{\\left(x^{2}-2\\mu x+\\mu^{2}\\right)-\\left(x^{2}-2\\nu x+\\nu^{2}\\right)}{2\\sigma^{2}}=\\frac{2x(\\nu-\\mu)+(\\mu^{2}-\\nu^{2})}{2\\sigma^{2}}.\n$$\nRewrite $\\mu^{2}-\\nu^{2}=-(\\nu^{2}-\\mu^{2})=-(\\nu-\\mu)(\\nu+\\mu)$ to factor:\n$$\n\\frac{2x(\\nu-\\mu)-(\\nu-\\mu)(\\nu+\\mu)}{2\\sigma^{2}}=\\frac{(\\nu-\\mu)\\left(2x-(\\nu+\\mu)\\right)}{2\\sigma^{2}}=\\frac{\\nu-\\mu}{\\sigma^{2}}\\left(x-\\frac{\\nu+\\mu}{2}\\right).\n$$\nTherefore,\n$$\n\\frac{dQ}{dP}(x)=\\exp\\left(\\frac{(\\nu-\\mu)\\left(2x-\\nu-\\mu\\right)}{2\\sigma^{2}}\\right)=\\exp\\left(\\frac{\\nu-\\mu}{\\sigma^{2}}\\left(x-\\frac{\\nu+\\mu}{2}\\right)\\right).\n$$", "answer": "$$\\boxed{\\exp\\!\\left(\\frac{\\nu-\\mu}{\\sigma^{2}}\\left(x-\\frac{\\nu+\\mu}{2}\\right)\\right)}$$", "id": "1330409"}, {"introduction": "After learning to switch between two probability measures, it is natural to ask what properties are preserved during this transformation. Are statistical relationships, like a lack of correlation, intrinsic to the random variables, or are they dependent on the \"world\"—the measure—in which they are observed? This practice [@problem_id:1330402] uses a simple, discrete system to explore this question, revealing a critical and often counter-intuitive insight about the nature of correlation.", "problem": "Consider a simple stochastic system with a finite sample space $\\Omega = \\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\}$. Two real-valued random variables, $X$ and $Y$, are defined on this sample space with the following values:\n$X(\\omega_1) = 2$, $X(\\omega_2) = -2$, $X(\\omega_3) = 2$, $X(\\omega_4) = -2$.\n$Y(\\omega_1) = 3$, $Y(\\omega_2) = 3$, $Y(\\omega_3) = -3$, $Y(\\omega_4) = -3$.\n\nInitially, the system is described by a probability measure $P$, which is the uniform distribution on $\\Omega$, i.e., $P(\\omega_i) = 1/4$ for $i=1, 2, 3, 4$. Under this measure $P$, the random variables $X$ and $Y$ are uncorrelated.\n\nNow, consider a change of measure from $P$ to a new, equivalent measure $Q$. Two measures are equivalent if they assign zero probability to the same events. The new measure $Q$ is defined by the following probabilities:\n$Q(\\omega_1) = \\frac{1}{2}$\n$Q(\\omega_2) = \\frac{1}{4}$\n$Q(\\omega_3) = \\frac{1}{8}$\n$Q(\\omega_4) = \\frac{1}{8}$\n\nThe covariance between two random variables $X$ and $Y$ under a given probability measure $\\mathbb{M}$ is defined as $\\text{Cov}_{\\mathbb{M}}(X, Y) = E_{\\mathbb{M}}[XY] - E_{\\mathbb{M}}[X]E_{\\mathbb{M}}[Y]$, where $E_{\\mathbb{M}}[\\cdot]$ denotes the expectation with respect to the measure $\\mathbb{M}$.\n\nCalculate the covariance of $X$ and $Y$ under the new measure $Q$. Express your answer as a single fraction.", "solution": "We use the definition $\\text{Cov}_{Q}(X,Y) = E_{Q}[XY] - E_{Q}[X]E_{Q}[Y]$. First compute each expectation under $Q$.\n\nCompute $E_{Q}[X]$:\n$$\nE_{Q}[X] = \\sum_{i=1}^{4} Q(\\omega_{i}) X(\\omega_{i}) = \\frac{1}{2}\\cdot 2 + \\frac{1}{4}\\cdot(-2) + \\frac{1}{8}\\cdot 2 + \\frac{1}{8}\\cdot(-2) = 1 - \\frac{1}{2} + \\frac{1}{4} - \\frac{1}{4} = \\frac{1}{2}.\n$$\n\nCompute $E_{Q}[Y]$:\n$$\nE_{Q}[Y] = \\sum_{i=1}^{4} Q(\\omega_{i}) Y(\\omega_{i}) = \\frac{1}{2}\\cdot 3 + \\frac{1}{4}\\cdot 3 + \\frac{1}{8}\\cdot(-3) + \\frac{1}{8}\\cdot(-3) = \\frac{3}{2} + \\frac{3}{4} - \\frac{3}{8} - \\frac{3}{8} = \\frac{3}{2}.\n$$\n\nCompute $E_{Q}[XY]$. First note $XY(\\omega_{1}) = 6$, $XY(\\omega_{2}) = -6$, $XY(\\omega_{3}) = -6$, $XY(\\omega_{4}) = 6$. Thus\n$$\nE_{Q}[XY] = \\sum_{i=1}^{4} Q(\\omega_{i}) X(\\omega_{i}) Y(\\omega_{i}) = \\frac{1}{2}\\cdot 6 + \\frac{1}{4}\\cdot(-6) + \\frac{1}{8}\\cdot(-6) + \\frac{1}{8}\\cdot 6 = 3 - \\frac{3}{2} - \\frac{3}{4} + \\frac{3}{4} = \\frac{3}{2}.\n$$\n\nTherefore,\n$$\n\\text{Cov}_{Q}(X,Y) = E_{Q}[XY] - E_{Q}[X]E_{Q}[Y] = \\frac{3}{2} - \\left(\\frac{1}{2}\\right)\\left(\\frac{3}{2}\\right) = \\frac{3}{2} - \\frac{3}{4} = \\frac{3}{4}.\n$$", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1330402"}, {"introduction": "We now shift our focus to a different, but equally fundamental, relationship: the connection between a system's instantaneous transition rates, described by the generator matrix $Q$, and its probability evolution over time, captured by the transition matrix $P(t)$. While the formal relationship is given by the matrix exponential $P(t) = \\exp(tQ)$, calculating this directly can be difficult. This problem [@problem_id:1330447] demonstrates an elegant algebraic technique that leverages the structure of $Q$ to find a closed-form expression for $P(t)$, showcasing a powerful link between linear algebra and stochastic processes.", "problem": "Consider a system modeled by a finite-state Continuous-Time Markov Chain (CTMC). The dynamics of the state probabilities are governed by the generator matrix $Q$. The matrix of transition probabilities over a time interval $t \\ge 0$ is given by $P(t) = \\exp(tQ)$, where $\\exp(\\cdot)$ denotes the matrix exponential.\n\nSuppose the generator matrix $Q$ for this particular system is known to satisfy the matrix polynomial equation:\n$(Q - \\lambda_1 I)(Q - \\lambda_2 I) = 0$\nwhere $I$ is the identity matrix of the same dimension as $Q$, $0$ is the zero matrix, and $\\lambda_1$ and $\\lambda_2$ are distinct, negative, real constants.\n\nDerive a closed-form expression for the transition probability matrix $P(t)$ as a linear combination of the matrices $I$ and $Q$. Your final expression should be of the form $P(t) = a(t)I + b(t)Q$, where $a(t)$ and $b(t)$ are scalar functions of time $t$ expressed in terms of $\\lambda_1$ and $\\lambda_2$.", "solution": "We are given a finite-state CTMC with generator matrix $Q$ and $P(t)=\\exp(tQ)$. The matrix $Q$ satisfies the quadratic polynomial identity $(Q-\\lambda_{1}I)(Q-\\lambda_{2}I)=0$ with distinct real $\\lambda_{1}\\neq\\lambda_{2}$. Since the minimal polynomial of $Q$ divides $(x-\\lambda_{1})(x-\\lambda_{2})$ and has distinct linear factors, any analytic function of $Q$ can be expressed as a polynomial in $Q$ of degree at most one. Therefore there exist scalar functions $a(t)$ and $b(t)$ such that\n$$\nP(t)=\\exp(tQ)=a(t)I+b(t)Q.\n$$\n\nTo determine $a(t)$ and $b(t)$, use the functional calculus via interpolation on the spectrum. For any eigenvalue $\\lambda$ of $Q$, the action of $\\exp(tQ)$ on its corresponding eigenspace equals multiplication by $\\exp(t\\lambda)$. Hence $a(t)$ and $b(t)$ must satisfy, for $i=1,2$,\n$$\na(t)+b(t)\\lambda_{i}=\\exp(t\\lambda_{i}).\n$$\nThis is a $2\\times 2$ linear system in $a(t)$ and $b(t)$:\n$$\n\\begin{cases}\na(t)+b(t)\\lambda_{1}=\\exp(t\\lambda_{1}),\\\\\na(t)+b(t)\\lambda_{2}=\\exp(t\\lambda_{2}).\n\\end{cases}\n$$\nSubtracting the second equation from the first yields\n$$\nb(t)(\\lambda_{1}-\\lambda_{2})=\\exp(t\\lambda_{1})-\\exp(t\\lambda_{2}),\n$$\nso\n$$\nb(t)=\\frac{\\exp(t\\lambda_{1})-\\exp(t\\lambda_{2})}{\\lambda_{1}-\\lambda_{2}}.\n$$\nSubstituting back into $a(t)+b(t)\\lambda_{1}=\\exp(t\\lambda_{1})$ gives\n$$\na(t)=\\exp(t\\lambda_{1})-\\lambda_{1}\\frac{\\exp(t\\lambda_{1})-\\exp(t\\lambda_{2})}{\\lambda_{1}-\\lambda_{2}}\n=\\frac{\\lambda_{1}\\exp(t\\lambda_{2})-\\lambda_{2}\\exp(t\\lambda_{1})}{\\lambda_{1}-\\lambda_{2}}.\n$$\n\nTherefore,\n$$\nP(t)=\\frac{\\lambda_{1}\\exp(t\\lambda_{2})-\\lambda_{2}\\exp(t\\lambda_{1})}{\\lambda_{1}-\\lambda_{2}}\\,I\n+\\frac{\\exp(t\\lambda_{1})-\\exp(t\\lambda_{2})}{\\lambda_{1}-\\lambda_{2}}\\,Q.\n$$\nAs a consistency check, at $t=0$ we have $b(0)=0$ and $a(0)=1$, so $P(0)=I$, as required for a transition semigroup. This completes the derivation.", "answer": "$$\\boxed{\\frac{\\lambda_{1}\\exp(t\\lambda_{2})-\\lambda_{2}\\exp(t\\lambda_{1})}{\\lambda_{1}-\\lambda_{2}}\\,I+\\frac{\\exp(t\\lambda_{1})-\\exp(t\\lambda_{2})}{\\lambda_{1}-\\lambda_{2}}\\,Q}$$", "id": "1330447"}]}