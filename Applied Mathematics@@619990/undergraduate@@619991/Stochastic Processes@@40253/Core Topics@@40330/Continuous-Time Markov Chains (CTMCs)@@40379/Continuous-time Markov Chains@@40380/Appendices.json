{"hands_on_practices": [{"introduction": "The cornerstone of analyzing a continuous-time Markov chain is its generator matrix, $Q$. This practice is designed to build your proficiency in translating a qualitative description of a system's dynamics into this precise mathematical structure. By correctly identifying the transition rates between states, you will construct the matrix that governs the entire evolution of the process, a foundational skill for any further analysis [@problem_id:1352656].", "problem": "A simplified model for the lifecycle of a computer virus on an infected machine is described as a continuous-time Markov chain. The virus can be in one of three states: Dormant (State 1), Replicating (State 2), or Detected (State 3).\n\nThe transitions between states are governed by the following rates:\n- A dormant virus becomes active and starts replicating at a constant rate of $\\lambda$ per day.\n- A replicating virus may become dormant again to evade simple detection mechanisms at a constant rate of $\\mu$ per day.\n- An active antivirus scanner finds and flags a replicating virus at a constant rate of $\\sigma_R$ per day.\n- The scanner can also find a dormant virus, but at a lower constant rate of $\\sigma_D$ per day.\n- Once a virus is in the 'Detected' state, it is isolated and cannot change its state.\n\nYour task is to construct the generator matrix, denoted by $Q$, for this continuous-time Markov chain. The states should be ordered as (1: Dormant, 2: Replicating, 3: Detected). Present the matrix $Q$ as your final answer.", "solution": "We model the virus lifecycle as a continuous-time Markov chain with states ordered as follows: 1 for Dormant, 2 for Replicating, and 3 for Detected. For a generator matrix $Q=\\{q_{ij}\\}$ of a continuous-time Markov chain, the off-diagonal entries $q_{ij}$ for $i\\neq j$ are the transition rates from state $i$ to state $j$, and the diagonal entries satisfy $q_{ii}=-\\sum_{j\\neq i}q_{ij}$ so that each row sums to zero.\n\nFrom the problem statement, the nonzero transition rates are:\n- From Dormant (1) to Replicating (2): rate $\\lambda$, so $q_{12}=\\lambda$.\n- From Dormant (1) to Detected (3): rate $\\sigma_{D}$, so $q_{13}=\\sigma_{D}$.\n- From Replicating (2) to Dormant (1): rate $\\mu$, so $q_{21}=\\mu$.\n- From Replicating (2) to Detected (3): rate $\\sigma_{R}$, so $q_{23}=\\sigma_{R}$.\n- Detected (3) is an absorbing state, so there are no outgoing transitions from state 3, implying $q_{31}=0$ and $q_{32}=0$.\n\nUsing $q_{ii}=-\\sum_{j\\neq i}q_{ij}$ for each state:\n- For state 1: $q_{11}=-(\\lambda+\\sigma_{D})$.\n- For state 2: $q_{22}=-(\\mu+\\sigma_{R})$.\n- For state 3: $q_{33}=0$.\n\nTherefore, the generator matrix $Q$ in the specified state order is\n$$\nQ=\\begin{pmatrix}\n-(\\lambda+\\sigma_{D}) & \\lambda & \\sigma_{D} \\\\\n\\mu & -(\\mu+\\sigma_{R}) & \\sigma_{R} \\\\\n0 & 0 & 0\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\n-(\\lambda+\\sigma_{D}) & \\lambda & \\sigma_{D} \\\\\n\\mu & -(\\mu+\\sigma_{R}) & \\sigma_{R} \\\\\n0 & 0 & 0\n\\end{pmatrix}}$$", "id": "1352656"}, {"introduction": "Once a continuous-time Markov chain is defined, a powerful question we can answer is about its long-term behavior. This exercise introduces the concept of the stationary distribution, which describes the fraction of time the system spends in each state after it has been running for a long time. You will apply the principle of detailed balance to a simple yet illustrative two-state system to find this equilibrium, a fundamental technique in performance and reliability analysis [@problem_id:1352653].", "problem": "Consider a simplified model of a single computer server that can be in one of two states: 'Active' or 'Idle'.\n\nWhen the server is in the 'Active' state, it is processing a task. The time it remains Active before completing the task and transitioning to the 'Idle' state is an exponential random variable with rate $\\lambda$.\n\nWhen the server is in the 'Idle' state, it is waiting for a new task. The time it remains Idle before a new task arrives, causing it to transition to the 'Active' state, is an exponential random variable with rate $\\mu$.\n\nAssuming the server has been running for a very long time, determine the fraction of time it spends in the 'Active' state. Express your answer as a symbolic expression in terms of $\\lambda$ and $\\mu$.", "solution": "Model the server as a two-state continuous-time Markov chain with states Active (A) and Idle (I). The transition rates are $q_{A \\to I}=\\lambda$ and $q_{I \\to A}=\\mu$. Let $\\pi_{A}$ and $\\pi_{I}$ denote the long-run fractions of time spent in states Active and Idle, respectively.\n\nIn steady state, the global balance equation equates the average flow out of and into each state. For the two-state chain this reduces to\n$$\n\\pi_{A}\\lambda=\\pi_{I}\\mu,\n$$\ntogether with the normalization condition\n$$\n\\pi_{A}+\\pi_{I}=1.\n$$\nFrom the normalization, $\\pi_{I}=1-\\pi_{A}$. Substituting into the balance equation gives\n$$\n\\pi_{A}\\lambda=(1-\\pi_{A})\\mu \\;\\;\\Rightarrow\\;\\; \\pi_{A}\\lambda=\\mu-\\pi_{A}\\mu \\;\\;\\Rightarrow\\;\\; \\pi_{A}(\\lambda+\\mu)=\\mu,\n$$\nhence\n$$\n\\pi_{A}=\\frac{\\mu}{\\lambda+\\mu}.\n$$\nTherefore, the fraction of time the server spends in the Active state in the long run is $\\frac{\\mu}{\\lambda+\\mu}$.\n\nEquivalently, by renewal reasoning, the mean Active duration is $\\frac{1}{\\lambda}$ and the mean Idle duration is $\\frac{1}{\\mu}$, so the long-run Active fraction is\n$$\n\\frac{\\frac{1}{\\lambda}}{\\frac{1}{\\lambda}+\\frac{1}{\\mu}}=\\frac{\\mu}{\\lambda+\\mu},\n$$\nwhich matches the Markov chain result.", "answer": "$$\\boxed{\\frac{\\mu}{\\lambda+\\mu}}$$", "id": "1352653"}, {"introduction": "While analytical methods provide insights into long-term averages, simulation allows us to witness a single, concrete realization of the stochastic process as it unfolds in time. This hands-on exercise guides you through the core algorithm for simulating a continuous-time Markov chain path, using random numbers to determine both the waiting time in a state and the destination of the next jump. This practice provides a tangible understanding of how the abstract rates translate into dynamic system behavior [@problem_id:1292573].", "problem": "A small-scale, private cloud computing node is being monitored. Its state can be modeled as a continuous-time Markov chain. The system can be in one of four states: State 1 (`Idle`), State 2 (`Processing`), State 3 (`Overloaded`), or State 4 (`Failed`).\n\nThe dynamics of the system are governed by the following transition rates:\n- A new job arrives with a rate $\\lambda$, causing a transition from `Idle` to `Processing`. If a job arrives while the system is `Processing`, it transitions to `Overloaded`.\n- A running job is completed with a rate $\\mu$. This leads to a transition from `Processing` to `Idle` (if no jobs are in the queue) or from `Overloaded` to `Processing` (as the queued job begins).\n- The node can suffer a hardware failure from any operational state. The failure rate depends on the load: $\\delta_1$ from `Idle`, $\\delta_2$ from `Processing`, and $\\delta_3$ from `Overloaded`. All failures lead to the `Failed` state.\n- A `Failed` node can be repaired, transitioning back to the `Idle` state with a rate $\\rho$.\n\nTo simulate a sample path of this system, one uses pairs of random numbers, $(u_t, u_s)$, drawn from a uniform distribution on $(0,1)$. For a system in state $i$ with total exit rate $q_i$, the time to the next jump is calculated as $\\Delta t = -(1/q_i) \\ln(u_t)$. The next state is then determined based on the value of $u_s$.\n\nSuppose the system starts in the `Idle` state at time $t=0$. You are given the following rate parameters:\n- Job arrival rate, $\\lambda = 2.0 \\text{ s}^{-1}$\n- Job completion rate, $\\mu = 3.0 \\text{ s}^{-1}$\n- Failure rate from `Idle`, $\\delta_1 = 0.1 \\text{ s}^{-1}$\n- Failure rate from `Processing`, $\\delta_2 = 0.2 \\text{ s}^{-1}$\n- Failure rate from `Overloaded`, $\\delta_3 = 0.5 \\text{ s}^{-1}$\n- Repair rate, $\\rho = 0.4 \\text{ s}^{-1}$\n\nYou are also provided with the following pre-ordered sequence of uniform random numbers: $(0.35, 0.80, 0.62, 0.25, 0.18, 0.98)$. The first number is used to determine the time of the first jump, the second to determine the state of the first jump, the third for the time of the second jump, the fourth for the state of the second jump, and so on.\n\nCalculate the time at which the third jump occurs. Express your answer in seconds, rounded to three significant figures.", "solution": "We model the system as a continuous-time Markov chain with the given transition rates. For a state with total exit rate $q_{i}$, the time to the next jump is $\\Delta t=-(1/q_{i})\\ln(u_{t})$, and the next state is chosen using $u_{s}$ with probabilities proportional to the outgoing rates.\n\nFrom `Idle` (state 1): transitions are to `Processing` (state 2) with rate $\\lambda$ and to `Failed` (state 4) with rate $\\delta_{1}$. Thus\n$$\nq_{1}=\\lambda+\\delta_{1}=2.0+0.1=2.1,\n\\qquad\np_{1\\to 2}=\\frac{\\lambda}{q_{1}}=\\frac{2.0}{2.1}=\\frac{20}{21},\n\\qquad\np_{1\\to 4}=\\frac{\\delta_{1}}{q_{1}}=\\frac{0.1}{2.1}=\\frac{1}{21}.\n$$\nFirst jump time with $u_{1}=0.35$:\n$$\n\\Delta t_{1}=-\\frac{1}{q_{1}}\\ln(u_{1})=-\\frac{1}{2.1}\\ln(0.35)\\approx \\frac{1.049822124}{2.1}\\approx 0.499915297.\n$$\nState selection with $u_{2}=0.80$ gives $u_{2}\\leq 20/21$, so the next state is `Processing` (state 2). Thus $t_{1}=\\Delta t_{1}\\approx 0.499915297$.\n\nFrom `Processing` (state 2): transitions are to `Idle` (state 1) with rate $\\mu$, to `Overloaded` (state 3) with rate $\\lambda$, and to `Failed` (state 4) with rate $\\delta_{2}$. Thus\n$$\nq_{2}=\\mu+\\lambda+\\delta_{2}=3.0+2.0+0.2=5.2,\n$$\n$$\np_{2\\to 1}=\\frac{\\mu}{q_{2}}=\\frac{3.0}{5.2}=\\frac{15}{26},\\quad\np_{2\\to 3}=\\frac{\\lambda}{q_{2}}=\\frac{2.0}{5.2}=\\frac{5}{13},\\quad\np_{2\\to 4}=\\frac{\\delta_{2}}{q_{2}}=\\frac{0.2}{5.2}=\\frac{1}{26}.\n$$\nSecond jump waiting time with $u_{3}=0.62$:\n$$\n\\Delta t_{2}=-\\frac{1}{q_{2}}\\ln(u_{3})=-\\frac{1}{5.2}\\ln(0.62)\\approx \\frac{0.478035801}{5.2}\\approx 0.091929962.\n$$\nState selection with $u_{4}=0.25$ gives $u_{4}\\leq 15/26$, so the next state is `Idle` (state 1). Thus $t_{2}=t_{1}+\\Delta t_{2}\\approx 0.499915297+0.091929962\\approx 0.591845259$.\n\nBack in `Idle` (state 1), the total exit rate is again $q_{1}=2.1$. The third jump waiting time with $u_{5}=0.18$ is\n$$\n\\Delta t_{3}=-\\frac{1}{q_{1}}\\ln(u_{5})=-\\frac{1}{2.1}\\ln(0.18)\\approx \\frac{1.714798428}{2.1}\\approx 0.816570680.\n$$\nTherefore, the time of the third jump is\n$$\nt_{3}=t_{2}+\\Delta t_{3}\\approx 0.591845259+0.816570680\\approx 1.408415939.\n$$\nRounded to three significant figures, the third jump occurs at $1.41$ seconds.", "answer": "$$\\boxed{1.41}$$", "id": "1292573"}]}