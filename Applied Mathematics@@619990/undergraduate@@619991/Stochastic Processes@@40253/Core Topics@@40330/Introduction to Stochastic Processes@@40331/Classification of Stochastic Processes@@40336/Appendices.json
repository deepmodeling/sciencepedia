{"hands_on_practices": [{"introduction": "A cornerstone of classifying stochastic processes is understanding their stationarityâ€”whether their statistical character changes over time. Wide-Sense Stationarity (WSS) provides a practical criterion, focusing on the mean and autocorrelation. This practice [@problem_id:1289251] invites you to investigate a fundamental closure property: is the product of two independent WSS processes also WSS? Mastering this will deepen your understanding of how process properties behave under common transformations, a vital skill in fields like signal processing and communication systems.", "problem": "In the modeling of complex systems, such as in signal processing or financial analysis, a new process is often generated by the product of two or more existing processes. Consider two stochastic processes, $X(t)$ and $Y(t)$, which are statistically independent of each other. Both $X(t)$ and $Y(t)$ are known to be Wide-Sense Stationary (WSS).\n\nA stochastic process $U(t)$ is defined as Wide-Sense Stationary (WSS) if it satisfies two conditions:\n1. Its mean function, $\\mu_U(t) = E[U(t)]$, is a constant for all time $t$.\n2. Its autocorrelation function, $R_{UU}(t_1, t_2) = E[U(t_1)U(t_2)]$, depends only on the time lag $\\tau = t_1 - t_2$.\n\nA new product process, $Z(t)$, is formed such that $Z(t) = X(t)Y(t)$.\n\nWhich of the following statements correctly describes the condition under which the product process $Z(t)$ is guaranteed to be Wide-Sense Stationary?\n\nA. $Z(t)$ is always WSS under the given conditions.\n\nB. $Z(t)$ is only WSS if at least one of the processes, $X(t)$ or $Y(t)$, has a zero mean.\n\nC. $Z(t)$ is only WSS if both processes, $X(t)$ and $Y(t)$, have zero mean.\n\nD. $Z(t)$ is only WSS if both $X(t)$ and $Y(t)$ are also Gaussian processes.\n\nE. The stationarity of $Z(t)$ cannot be determined from the information provided.", "solution": "Let $X(t)$ and $Y(t)$ be independent WSS processes, and define $Z(t)=X(t)Y(t)$. To check whether $Z(t)$ is WSS, we verify the two WSS conditions.\n\nMean: Because $X(t)$ and $Y(t)$ are independent for each $t$, we have\n$$\n\\mu_{Z}(t)=E[Z(t)]=E[X(t)Y(t)]=E[X(t)]E[Y(t)].\n$$\nSince $X(t)$ and $Y(t)$ are WSS, their means are constants, say $E[X(t)]=\\mu_{X}$ and $E[Y(t)]=\\mu_{Y}$, hence\n$$\n\\mu_{Z}(t)=\\mu_{X}\\mu_{Y},\n$$\nwhich is a constant. Thus the mean condition holds without any further assumptions.\n\nAutocorrelation: For any $t_{1},t_{2}$,\n$$\nR_{ZZ}(t_{1},t_{2})=E[Z(t_{1})Z(t_{2})]=E[X(t_{1})Y(t_{1})X(t_{2})Y(t_{2})].\n$$\nIndependence of the processes implies that the vector $(X(t_{1}),X(t_{2}))$ is independent of the vector $(Y(t_{1}),Y(t_{2}))$. Therefore,\n$$\nE[X(t_{1})X(t_{2})Y(t_{1})Y(t_{2})]=E[X(t_{1})X(t_{2})]E[Y(t_{1})Y(t_{2})] =R_{XX}(t_{1},t_{2})R_{YY}(t_{1},t_{2}).\n$$\nSince $X(t)$ and $Y(t)$ are WSS, $R_{XX}(t_{1},t_{2})=R_{XX}(t_{1}-t_{2})$ and $R_{YY}(t_{1},t_{2})=R_{YY}(t_{1}-t_{2})$, hence\n$$\nR_{ZZ}(t_{1},t_{2})=R_{XX}(t_{1}-t_{2})R_{YY}(t_{1}-t_{2}),\n$$\nwhich depends only on the lag $\\tau=t_{1}-t_{2}$. Thus the autocorrelation condition holds. The required moments exist because WSS guarantees finite second moments, and the product above is finite.\n\nTherefore, under the given conditions (independent WSS processes), $Z(t)$ is WSS without requiring zero means or Gaussianity.", "answer": "$$\\boxed{A}$$", "id": "1289251"}, {"introduction": "Beyond stationarity, a process can be classified by its \"memory.\" A process with independent increments is memoryless in the sense that its future changes are statistically independent of its past. This exercise [@problem_id:1289207] challenges you to apply this concept to a real-world scenario: an infinite-server queue. By dissecting the arrivals and departures, you will determine whether the number of customers in the system evolves without memory, honing your ability to analyze the underlying dynamics of complex models.", "problem": "Consider an $M/G/\\infty$ queueing system, which models a scenario with an infinite number of servers. Customers arrive according to a Poisson process with a constant rate of $\\lambda > 0$. Upon arrival, a customer immediately enters service, as there is always a free server. The service times are independent and identically distributed random variables, drawn from a general probability distribution with a finite, non-zero mean $E[S]$. The service time distribution is independent of the arrival process.\n\nLet $X(t)$ for $t \\ge 0$ be the stochastic process representing the number of customers in the system at time $t$. Assume the system is empty at time $t=0$, i.e., $X(0) = 0$.\n\nWhich of the following statements correctly describes the property of independent increments for the process $X(t)$?\n\nA. The process $X(t)$ has independent increments because the underlying arrival process is a Poisson process, which has independent increments.\n\nB. The process $X(t)$ has independent increments, but only under the condition that the system is stable, which in this case means the mean service time is finite.\n\nC. The process $X(t)$ does not have independent increments because the number of departures in any time interval $(t_1, t_2)$ is dependent on the number of customers present at time $t_1$.\n\nD. The process $X(t)$ does not have independent increments because the process is not stationary, meaning the probability distribution of $X(t)$ changes as a function of $t$.\n\nE. The process $X(t)$ has independent increments only if the service times are exponentially distributed (i.e., the system is an $M/M/\\infty$ queue).", "solution": "Define the independent-increments property: a process $\\{X(t): t \\ge 0\\}$ has independent increments if for any disjoint intervals $(t_{0}, t_{1}], (t_{1}, t_{2}], \\ldots, (t_{k-1}, t_{k}]$, the random variables $X(t_{1}) - X(t_{0}), X(t_{2}) - X(t_{1}), \\ldots, X(t_{k}) - X(t_{k-1})$ are mutually independent.\n\nIn an $M/G/\\infty$ system, let arrivals be a Poisson process with rate $\\lambda$, and let $\\{S_{i}\\}$ be i.i.d. service times, independent of arrivals. Represent the system via a Poisson random measure of marked arrivals $\\{(A_{i}, S_{i})\\}$ on $\\mathbb{R}_{+} \\times \\mathbb{R}_{+}$ with intensity measure $\\lambda \\, da \\, F_{S}(ds)$. Then the number in system at time $t$ is\n$$\nX(t) \\;=\\; \\sum_{i} \\mathbf{1}\\{A_{i} \\le t  A_{i} + S_{i}\\} \\;=\\; \\sum_{i} \\mathbf{1}\\{A_{i} \\le t\\}\\,\\mathbf{1}\\{S_{i}  t - A_{i}\\}.\n$$\nFix $0  t_{1}  t_{2}$ and write the increment as\n$$\n\\Delta X(t_{1}, t_{2}) \\;:=\\; X(t_{2}) - X(t_{1}) \\;=\\; N_{\\text{arr}}(t_{1}, t_{2}) \\;-\\; D(t_{1}, t_{2}),\n$$\nwhere $N_{\\text{arr}}(t_{1}, t_{2})$ is the number of arrivals in $(t_{1}, t_{2}]$, and $D(t_{1}, t_{2})$ is the number of departures in $(t_{1}, t_{2}]$. Because arrivals form a Poisson process, $N_{\\text{arr}}(t_{1}, t_{2})$ is Poisson with mean $\\lambda (t_{2} - t_{1})$ and is independent of the history up to time $t_{1}$. However, $D(t_{1}, t_{2})$ has a component due to customers already present at $t_{1}$, which necessarily depends on the state at $t_{1}$.\n\nDecompose departures as\n$$\nD(t_{1}, t_{2}) \\;=\\; D_{\\text{pre}}(t_{1}, t_{2}) \\;+\\; D_{\\text{post}}(t_{1}, t_{2}),\n$$\nwhere $D_{\\text{pre}}(t_{1}, t_{2})$ counts the customers that were in service at $t_{1}$ and complete service by $t_{2}$, and $D_{\\text{post}}(t_{1}, t_{2})$ counts those that both arrive after $t_{1}$ and depart by $t_{2}$. The term $D_{\\text{post}}(t_{1}, t_{2})$ depends only on arrivals and service times after $t_{1}$ and is independent of the past. By contrast,\n$$\nD_{\\text{pre}}(t_{1}, t_{2}) \\;=\\; \\sum_{j=1}^{X(t_{1})} \\mathbf{1}\\{R_{j} \\le t_{2} - t_{1}\\},\n$$\nwhere $R_{j}$ is the residual service time at $t_{1}$ of the $j$th customer present then. Conditional on $X(t_{1}) = n$ and on the residuals $\\{R_{j}\\}_{j=1}^{n}$, this sum is a function of these $n$ residual times. In particular, conditional on $X(t_{1}) = n$, the distribution of $D_{\\text{pre}}(t_{1}, t_{2})$ stochastically increases with $n$, so the distribution of $\\Delta X(t_{1}, t_{2})$ depends on $X(t_{1})$.\n\nA concrete special case underscores the dependence. If service times are exponential with rate $\\mu$ (the $M/M/\\infty$ case), then given $X(t_{1}) = n$, each of the $n$ customers present at $t_{1}$ departs in $(t_{1}, t_{2}]$ independently with probability $1 - \\exp(-\\mu (t_{2} - t_{1}))$. Thus\n$$\nD_{\\text{pre}}(t_{1}, t_{2}) \\,\\big|\\, X(t_{1}) = n \\;\\sim\\; \\text{Binomial}\\!\\left(n,\\, 1 - \\exp(-\\mu (t_{2} - t_{1}))\\right),\n$$\nso the law of $\\Delta X(t_{1}, t_{2})$ depends on $n$. Therefore $\\Delta X(t_{1}, t_{2})$ is not independent of the sigma-field generated by the past up to $t_{1}$, and increments over disjoint intervals cannot be independent.\n\nThis directly contradicts options asserting independent increments. The failure has nothing to do with stability (the infinite-server system is always well-defined with finite $E[S]$, but independent increments would still fail) and nothing to do with stationarity (even if started in stationarity, increments remain dependent because departures in a future interval depend on the current population). Moreover, making service exponential does not fix this; it only makes $\\{X(t)\\}$ Markov, not a process with independent increments.\n\nHence, the correct statement is that $X(t)$ does not have independent increments because departures in an interval depend on the number in system at the beginning of that interval, which is option C.", "answer": "$$\\boxed{C}$$", "id": "1289207"}, {"introduction": "The martingale property offers a more subtle classification, formalizing the idea of a \"fair game\" where the expected future value is equal to the present value. This concept is central to modern probability theory and finance. This hands-on problem [@problem_id:1289210] provides a concrete entry point by using the simple symmetric random walk. You will discover how a predictable trend in a process can be removed with a \"compensator\" term to construct a martingale, providing a foundational insight into one of the most important classes of stochastic processes.", "problem": "Consider a simple symmetric random walk on the integers, $\\{S_n\\}_{n \\ge 0}$, starting at $S_0 = 0$. The position at time $n$ is given by $S_n = \\sum_{i=1}^{n} Z_i$ for $n \\ge 1$, where $\\{Z_i\\}_{i \\ge 1}$ is a sequence of independent and identically distributed random variables with $P(Z_i = 1) = P(Z_i = -1) = \\frac{1}{2}$. Let $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ be the natural filtration generated by this walk, i.e., $\\mathcal{F}_n = \\sigma(S_0, S_1, \\dots, S_n)$.\n\nA new stochastic process $\\{M_n\\}_{n \\ge 0}$ is defined as $M_n = S_n^2 - cn$, where $c$ is a real constant.\n\nDetermine the value of the constant $c$ for which the process $\\{M_n\\}_{n \\ge 0}$ is a martingale with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$.", "solution": "A process $\\{M_{n}\\}_{n \\ge 0}$ adapted to $\\{\\mathcal{F}_{n}\\}_{n \\ge 0}$ is a martingale if for all $n \\ge 0$ it satisfies $\\mathbb{E}[|M_{n}|]  \\infty$ and\n$$\n\\mathbb{E}[M_{n+1} \\mid \\mathcal{F}_{n}] = M_{n} \\quad \\text{a.s.}\n$$\nHere $S_{n+1} = S_{n} + Z_{n+1}$ with $Z_{n+1}$ independent of $\\mathcal{F}_{n}$, $\\mathbb{P}(Z_{n+1} = 1) = \\mathbb{P}(Z_{n+1} = -1) = \\frac{1}{2}$, hence $\\mathbb{E}[Z_{n+1}] = 0$ and $\\mathbb{E}[Z_{n+1}^{2}] = 1$. Define $M_{n} = S_{n}^{2} - c n$. Then\n$$\nM_{n+1} = S_{n+1}^{2} - c(n+1) = (S_{n} + Z_{n+1})^{2} - c n - c = S_{n}^{2} + 2 S_{n} Z_{n+1} + Z_{n+1}^{2} - c n - c.\n$$\nTaking conditional expectation given $\\mathcal{F}_{n}$ and using independence of $Z_{n+1}$ from $\\mathcal{F}_{n}$ gives\n$$\n\\mathbb{E}[M_{n+1} \\mid \\mathcal{F}_{n}] = S_{n}^{2} + 2 S_{n} \\mathbb{E}[Z_{n+1}] + \\mathbb{E}[Z_{n+1}^{2}] - c n - c = S_{n}^{2} + 0 + 1 - c n - c.\n$$\nThus\n$$\n\\mathbb{E}[M_{n+1} \\mid \\mathcal{F}_{n}] = (S_{n}^{2} - c n) + (1 - c) = M_{n} + (1 - c).\n$$\nFor the martingale property to hold, we require $1 - c = 0$, hence $c = 1$. Integrability holds since $S_{n}^{2}$ has finite expectation for each $n$, so $\\{M_{n}\\}_{n \\ge 0}$ is a martingale precisely when $c = 1$.", "answer": "$$\\boxed{1}$$", "id": "1289210"}]}