{"hands_on_practices": [{"introduction": "The first step in understanding any stochastic process is to get a feel for its individual realizations, or sample paths. This exercise provides a concrete opportunity to do just that by tracing the journey of a simple symmetric random walk. By calculating the final position $S_{n}$ and the all-time maximum $M_{n}$ for a given path, you will translate abstract definitions into tangible numerical values [@problem_id:1331521].", "problem": "Consider a simple symmetric random walk on the integers, denoted by $\\{S_n\\}_{n \\ge 0}$. The walk starts at the origin, so $S_0 = 0$. At each step $n \\ge 1$, the position changes according to $S_n = S_{n-1} + X_n$, where $X_n$ are independent and identically distributed random variables taking values $+1$ or $-1$ with equal probability.\n\nA specific realization of the first 30 steps of this random walk is observed. The sequence of steps, where 'U' denotes a step of $+1$ and 'D' denotes a step of $-1$, is given as follows:\n\nU, D, U, U, D, D, U, U, U, D, U, D, U, D, D, D, U, U, D, U, U, D, D, U, D, D, U, U, U, D\n\nFor this particular sample path, determine two quantities:\n1. The final position of the walk, $S_{30}$.\n2. The maximum position attained by the walk during these 30 steps, $M_{30} = \\max_{0 \\le k \\le 30} S_k$.\n\nYour final answer should be a pair of integers, corresponding to the values of $S_{30}$ and $M_{30}$ respectively.", "solution": "We model the path by random walk increments $X_{n}\\in\\{+1,-1\\}$ with $X_{n}=+1$ for a step U and $X_{n}=-1$ for a step D. The position after $n$ steps is\n$$\nS_{n}=\\sum_{i=1}^{n}X_{i},\\quad S_{0}=0,\n$$\nand the running maximum up to time $30$ is\n$$\nM_{30}=\\max_{0\\leq k\\leq 30}S_{k}.\n$$\n\nFirst, to find $S_{30}$, let $N_{U}$ be the number of U steps and $N_{D}$ the number of D steps in the given sequence. Then\n$$\nS_{30}=N_{U}-N_{D}.\n$$\nCounting from the provided sequence, there are $N_{U}=16$ U steps and $N_{D}=14$ D steps, hence\n$$\nS_{30}=16-14=2.\n$$\n\nNext, to find $M_{30}$, compute the partial sums along the given steps starting from $S_{0}=0$. Enumerating $S_{k}$ for $k=0,1,\\dots,30$ along the provided path yields\n$$\nS_{0}=0 \\to 1 \\to 0 \\to 1 \\to 2 \\to 1 \\to 0 \\to 1 \\to 2 \\to 3 \\to 2 \\to 3 \\to 2 \\to 3 \\to 2 \\to 1 \\to 0 \\to 1 \\to 2 \\to 1 \\to 2 \\to 3 \\to 2 \\to 1 \\to 2 \\to 1 \\to 0 \\to 1 \\to 2 \\to 3 \\to 2.\n$$\nThe largest value attained in this sequence is $3$, hence\n$$\nM_{30}=3.\n$$\n\nTherefore, the requested pair $(S_{30},M_{30})$ is $(2,3)$.", "answer": "$$\\boxed{\\begin{pmatrix} 2 & 3 \\end{pmatrix}}$$", "id": "1331521"}, {"introduction": "A random walk $S_n$ gives rise to other related processes, such as its running maximum, $M_n = \\max_{0 \\le k \\le n} S_k$. This exercise focuses on constructing the entire sample path of the maximum process, not just its final value. Visualizing the path of $M_n$ reveals its distinct characteristics, like its non-decreasing nature, and solidifies the concept of a derived process [@problem_id:1331515].", "problem": "A one-dimensional simple symmetric random walk, denoted by $S_n$, is a stochastic process that starts at $S_0 = 0$. At each subsequent step $n \\ge 1$, the position of the walk is updated according to the rule $S_n = S_{n-1} + X_n$, where $X_n$ is a random variable that takes the value $+1$ or $-1$ with equal probability.\n\nAssociated with this random walk is the running maximum process, $M_n$, which keeps track of the maximum position the walk has reached up to step $n$. This is formally defined as $M_n = \\max_{0 \\le k \\le n} S_k$ for $n \\ge 0$.\n\nConsider a specific realization, or sample path, of this random walk for $10$ steps. The sequence of outcomes for the steps $X_1, X_2, \\dots, X_{10}$ is given by:\n$$ (+1, -1, +1, +1, -1, -1, -1, +1, +1, +1) $$\nWhich of the following sequences represents the corresponding sample path of the running maximum process, $(M_0, M_1, M_2, \\dots, M_{10})$?\n\nA. $(0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2)$\n\nB. $(0, 1, 0, 1, 2, 1, 0, -1, 0, 1, 2)$\n\nC. $(0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1)$\n\nD. $(0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2)$", "solution": "We use the definitions of the simple symmetric random walk and its running maximum. The walk starts at $S_{0}=0$ and evolves by $S_{n}=S_{n-1}+X_{n}$. The running maximum is $M_{n}=\\max_{0\\leq k\\leq n}S_{k}$, which is equivalently updated by $M_{n}=\\max(M_{n-1},S_{n})$ with $M_{0}=S_{0}=0$.\n\nGiven the steps $(X_{1},\\dots,X_{10})=(+1,-1,+1,+1,-1,-1,-1,+1,+1,+1)$, compute the partial sums:\n- $S_{0}=0$.\n- $S_{1}=S_{0}+X_{1}=0+1=1$.\n- $S_{2}=S_{1}+X_{2}=1+(-1)=0$.\n- $S_{3}=S_{2}+X_{3}=0+1=1$.\n- $S_{4}=S_{3}+X_{4}=1+1=2$.\n- $S_{5}=S_{4}+X_{5}=2+(-1)=1$.\n- $S_{6}=S_{5}+X_{6}=1+(-1)=0$.\n- $S_{7}=S_{6}+X_{7}=0+(-1)=-1$.\n- $S_{8}=S_{7}+X_{8}=-1+1=0$.\n- $S_{9}=S_{8}+X_{9}=0+1=1$.\n- $S_{10}=S_{9}+X_{10}=1+1=2$.\n\nNow compute the running maximums using $M_{n}=\\max(M_{n-1},S_{n})$:\n- $M_{0}=0$.\n- $M_{1}=\\max(0,1)=1$.\n- $M_{2}=\\max(1,0)=1$.\n- $M_{3}=\\max(1,1)=1$.\n- $M_{4}=\\max(1,2)=2$.\n- $M_{5}=\\max(2,1)=2$.\n- $M_{6}=\\max(2,0)=2$.\n- $M_{7}=\\max(2,-1)=2$.\n- $M_{8}=\\max(2,0)=2$.\n- $M_{9}=\\max(2,1)=2$.\n- $M_{10}=\\max(2,2)=2$.\n\nThus the sequence $(M_{0},M_{1},\\dots,M_{10})$ is $(0,1,1,1,2,2,2,2,2,2,2)$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1331515"}, {"introduction": "Moving beyond simple calculations, this exercise delves into a deeper, more conceptual property of sample paths related to the flow of information over time. You will explore the crucial concept of a stopping time and use a thought experiment to understand why one cannot determine if a process has hit its global maximum on an interval without \"peeking\" into the future. This principle is fundamental to the modern theory of stochastic processes [@problem_id:1331493].", "problem": "Consider a continuous-time stochastic process, $\\{X_t\\}_{t \\ge 0}$, representing a fluctuating quantity over time. We observe this process over a fixed time interval $[0, T]$, where $T$ is a known positive constant. An experimenter has access to the history of the process as it unfolds.\n\nThe information available at any time $t$ is captured by the natural filtration, denoted by $\\mathcal{F}_t$. The natural filtration $\\mathcal{F}_t$ is the collection of all information about the trajectory of the process up to and including time $t$. A random time $\\tau$ is called a stopping time with respect to this filtration if the decision of whether the event $\\{\\tau \\le t\\}$ has occurred can be made for any $t$ using only the information available in $\\mathcal{F}_t$. In other words, one does not need to know the future evolution of the process to determine if the event has already happened.\n\nLet $\\tau_M$ be the random time at which the process $X_t$ first attains its global maximum value on the entire fixed interval $[0, T]$. Assume for any given sample path that this time is unique.\n\nTo understand why $\\tau_M$ is generally not a stopping time, imagine observing a single sample path of the process on a graph. At an arbitrary intermediate time $t_0$ (where $0 < t_0 < T$), you have observed the path from time $0$ to $t_0$. Your task is to decide if the global maximum for the whole interval $[0, T]$ has occurred on or before $t_0$ (i.e., whether $\\tau_M \\le t_0$).\n\nWhich of the following statements provides the correct reasoning for why $\\tau_M$ is not a stopping time with respect to the natural filtration $\\mathcal{F}_t$?\n\nA. To certify that the maximum value observed up to time $t_0$ is indeed the global maximum on $[0, T]$, one must know the path of the process for all subsequent times $s \\in (t_0, T]$ to ensure it never exceeds this value. This requires information not contained in $\\mathcal{F}_{t_0}$.\n\nB. The natural filtration $\\mathcal{F}_{t_0}$ only contains the value of the process at the single point in time $t_0$, i.e., $X_{t_0}$. It does not contain the history of the path needed to find the maximum up to $t_0$.\n\nC. The process $X_t$ might have multiple points where it attains the same maximum value on $[0, T]$, making it ambiguous whether the *first* such time is before or after $t_0$.\n\nD. The random value of the global maximum, $M = X_{\\tau_M}$, is not known at time $t_0$. Since this value is unknown, the time it occurs cannot be determined.\n\nE. The time of the running maximum on the interval $[0, t_0]$ is known at time $t_0$. Because this time is known, it must be the same as the global maximum time $\\tau_M$, which contradicts the claim that $\\tau_M$ is not a stopping time.", "solution": "The core of the problem is to determine if the time of the global maximum on a fixed interval $[0, T]$, denoted $\\tau_M$, qualifies as a stopping time. For $\\tau_M$ to be a stopping time with respect to the natural filtration $\\{\\mathcal{F}_t\\}_{t \\in [0, T]}$, the event $\\{\\tau_M \\le t\\}$ must be an element of the sigma-algebra $\\mathcal{F}_t$ for every $t \\in [0, T]$.\n\nIn simpler terms, at any given moment $t$, we must be able to decide whether the global maximum has already occurred, using only the history of the process up to that moment, $\\{X_s : 0 \\le s \\le t\\}$.\n\nLet's analyze this condition at an arbitrary intermediate time $t_0$, where $0 < t_0 < T$. The information we possess at this time is the set of values $\\{X_s : 0 \\le s \\le t_0\\}$, which constitutes the filtration $\\mathcal{F}_{t_0}$.\n\nUsing this information, we can certainly compute the maximum value of the process on the interval we have observed so far, which is $M_{t_0} = \\max_{s \\in [0, t_0]} X_s$. Let's say this maximum was achieved at time $t^* \\in [0, t_0]$.\n\nNow, we need to decide if the event $\\{\\tau_M \\le t_0\\}$ is true. This event means that the global maximum over the entire interval $[0, T]$ occurred at some time in $[0, t_0]$. This is equivalent to saying that for all future times $s$ in the interval $(t_0, T]$, the process value $X_s$ will not exceed the maximum we have seen so far, $M_{t_0}$. That is, the event $\\{\\tau_M \\le t_0\\}$ is true if and only if $X_s \\le M_{t_0}$ for all $s \\in (t_0, T]$.\n\nTo verify the condition \"$X_s \\le M_{t_0}$ for all $s \\in (t_0, T]$\", we inherently need to know the values of $X_s$ for $s > t_0$. This is information about the future evolution of the process relative to time $t_0$. By definition, the filtration $\\mathcal{F}_{t_0}$ contains information only up to time $t_0$. It does not contain any information about the path for times $s > t_0$.\n\nTherefore, at time $t_0$, we are unable to make a definitive decision about whether $\\{\\tau_M \\le t_0\\}$ has occurred. We might see a peak at $t^* \\le t_0$, but we cannot rule out the possibility that an even higher peak will occur at some time $s > t_0$. Because we cannot determine membership in the set $\\{\\tau_M \\le t_0\\}$ using only information in $\\mathcal{F}_{t_0}$, $\\tau_M$ is not a stopping time.\n\nNow let's evaluate the given options based on this reasoning:\n\nA. This statement accurately captures the core issue. To confirm that the maximum on $[0, t_0]$ is the global maximum on $[0, T]$, you must look into the future (the interval $(t_0, T]$) to ensure no larger value appears. This future information is, by definition, not in $\\mathcal{F}_{t_0}$. This statement is correct.\n\nB. This statement incorrectly defines the filtration. The natural filtration $\\mathcal{F}_{t_0}$ contains the information about the *entire path* up to time $t_0$, not just the value at $t_0$. This statement is incorrect.\n\nC. While uniqueness of the maximum can be a technical point in some contexts, it is not the fundamental reason why $\\tau_M$ fails to be a stopping time. Even if the maximum is guaranteed to be unique (as stated in the problem for simplicity), the \"peeking into the future\" problem remains. This statement is incorrect.\n\nD. This statement is related to the problem but misses the main point. The issue is not merely that the *value* of the maximum is unknown, but that the *event* $\\{\\tau_M \\le t_0\\}$ cannot be determined. The property of being a stopping time is about the measurability of the event $\\{\\tau \\le t\\}$, not about knowing the value of a random variable. Statement A is more precise.\n\nE. This statement describes a logical fallacy. It correctly notes that the time of the running maximum on $[0, t_0]$ is known at time $t_0$. However, it then falsely equates this with the time of the global maximum, $\\tau_M$. This confuses a property of the running maximum with the property of the global maximum on a fixed interval. This statement describes a common misconception but is itself an incorrect line of reasoning.\n\nThus, statement A provides the correct and most precise explanation.", "answer": "$$\\boxed{A}$$", "id": "1331493"}]}