{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with the most famous illustration of the inspection paradox: the bus waiting time problem. This exercise will challenge your intuition by applying the principles of the Poisson process to a common scenario. By calculating the expected waiting time for a commuter arriving at a random moment, you will uncover why random observation does not lead to an \"average\" outcome, and see the profound implications of the memoryless property in action [@problem_id:1293652].", "problem": "A city's public transit authority is testing a new dynamic dispatch system where buses are sent from the depot based on real-time passenger flow data, rather than adhering to a fixed schedule. Over a long period, observations at a particular downtown bus stop show that bus arrivals can be accurately modeled as a Poisson process. The average rate of arrivals at this stop is 6 buses per hour.\n\nA commuter, who is unaware of this new system, arrives at the stop at a random moment in time. What is this commuter's expected waiting time for the next bus to arrive?\n\nExpress your final answer in minutes.", "solution": "Let the arrival of buses at the stop be described by a Poisson process with a rate parameter $\\lambda$. The problem states that the average rate of arrivals is 6 buses per hour.\n\nFirst, we convert the rate $\\lambda$ into units consistent with the desired answer format (minutes).\n$$\n\\lambda = \\frac{6 \\text{ buses}}{1 \\text{ hour}} = \\frac{6 \\text{ buses}}{60 \\text{ minutes}} = \\frac{1}{10} \\text{ buses per minute}\n$$\n\nA defining characteristic of a Poisson process is that the time intervals between consecutive events are independent and identically distributed (i.i.d.) random variables following an exponential distribution with the same rate parameter $\\lambda$. Let $T$ represent the time between two consecutive bus arrivals. The probability density function (PDF) of $T$ is given by:\n$$\nf_T(t) = \\lambda \\exp(-\\lambda t), \\quad \\text{for } t \\ge 0\n$$\nThe expected value of this exponential distribution, which represents the average time between bus arrivals, is:\n$$\nE[T] = \\frac{1}{\\lambda}\n$$\nPlugging in our value for $\\lambda$:\n$$\nE[T] = \\frac{1}{1/10 \\text{ min}^{-1}} = 10 \\text{ minutes}\n$$\n\nThe question asks for the expected waiting time for a commuter who arrives at a random time. Let's call this waiting time $W$. A crucial property of the exponential distribution (and therefore of the inter-arrival times of a Poisson process) is the memoryless property. This property states that the probability of waiting an additional amount of time is independent of how long one has already waited. Formally, for an exponentially distributed random variable $T$, the property is expressed as $P(T > t + s | T > s) = P(T > t)$ for any non-negative $t$ and $s$.\n\nWhen the commuter arrives at a random time, they arrive at some point within an inter-arrival interval. Let's say the last bus arrived at time $t_{last}$ and the next bus is due at time $t_{next}$. The commuter arrives at time $t_{arrival}$ where $t_{last} < t_{arrival} < t_{next}$. The time that has already passed since the last bus, $t_{arrival} - t_{last}$, does not influence the remaining waiting time, $W = t_{next} - t_{arrival}$, due to the memoryless property.\n\nTherefore, the distribution of the remaining waiting time $W$ is identical to the original distribution of the inter-arrival time $T$. Consequently, their expected values are the same.\n$$\nE[W] = E[T]\n$$\nThis leads to the conclusion that the commuter's expected waiting time is equal to the average time between buses.\n$$\nE[W] = 10 \\text{ minutes}\n$$\nThis result is often referred to as the \"waiting time paradox\" or \"inspection paradox.\" While one might intuitively guess the answer is half the average interval (5 minutes), the fact that a random arrival is more likely to occur within a longer-than-average interval skews the result. For the specific case of a Poisson process, this effect exactly cancels the \"averaging-over-the-interval\" intuition, making the expected wait equal to the full average inter-arrival time.", "answer": "$$\\boxed{10}$$", "id": "1293652"}, {"introduction": "Having seen the paradox in the context of a Poisson process, we now generalize our understanding to other types of processes. This problem moves away from exponentially distributed intervals to a scenario with discrete lifetimes, modeling the replacement of data center cooling units. By calculating the expected lifetime of an inspected unit, you will use a fundamental result from renewal theory to prove that you are inherently more likely to observe a longer-lasting component than the simple average would suggest [@problem_id:1280769].", "problem": "A large data center relies on a series of identical, independent cooling units to maintain operational temperatures for its server racks. When a cooling unit fails, it is immediately replaced with a new one. The lifetime of any given cooling unit is a random variable. Specifically, a unit has a lifetime of exactly 1 month with a probability of $1/4$, and a lifetime of exactly 3 months with a probability of $3/4$.\n\nAfter the data center has been in operation for a very long time, a quality control engineer arrives at a randomly chosen moment to inspect a particular server rack. The engineer is interested in the total operational lifetime of the cooling unit that is currently in service at that rack.\n\nAssuming the system has reached a steady state, what is the expected total lifetime of the cooling unit that the engineer inspects? Express your answer in units of months.", "solution": "Model the sequence of cooling unit lifetimes as i.i.d. renewal intervals with lifetime random variable $X$ taking values $1$ with probability $\\frac{1}{4}$ and $3$ with probability $\\frac{3}{4}$. After a long time, an inspection at a random time observes the interval containing that time. In steady state, the observed interval length $X^{*}$ has the length-biased distribution given by\n$$\n\\mathbb{P}(X^{*}=x_{i})=\\frac{x_{i}\\,\\mathbb{P}(X=x_{i})}{\\mathbb{E}[X]},\n$$\nand therefore\n$$\n\\mathbb{E}[X^{*}]=\\frac{\\mathbb{E}[X^{2}]}{\\mathbb{E}[X]}.\n$$\n\nCompute $\\mathbb{E}[X]$ and $\\mathbb{E}[X^{2}]$:\n$$\n\\mathbb{E}[X]=1\\cdot \\frac{1}{4}+3\\cdot \\frac{3}{4}=\\frac{1}{4}+\\frac{9}{4}=\\frac{10}{4}=\\frac{5}{2},\n$$\n$$\n\\mathbb{E}[X^{2}]=1^{2}\\cdot \\frac{1}{4}+3^{2}\\cdot \\frac{3}{4}=\\frac{1}{4}+\\frac{27}{4}=\\frac{28}{4}=7.\n$$\nHence the expected total lifetime of the currently operating unit at a random inspection time is\n$$\n\\mathbb{E}[X^{*}]=\\frac{\\mathbb{E}[X^{2}]}{\\mathbb{E}[X]}=\\frac{7}{5/2}=\\frac{14}{5}.\n$$\nThis value is in months.", "answer": "$$\\boxed{\\frac{14}{5}}$$", "id": "1280769"}, {"introduction": "Our final practice problem takes us back to the Poisson process, but with a deeper analytical goal. Instead of just calculating the expected value, we will investigate the variability of the observed interval by finding its variance. Set in the context of detecting cosmic rays, this exercise requires you to model the inspected interval as the sum of two independent random variables—the age and the residual life—providing a more complete picture of the statistical properties that define the inspection paradox [@problem_id:1339061].", "problem": "A physicist is studying high-energy cosmic rays using a specialized particle detector. The arrival times of cosmic ray events at the detector are well-modeled by a Poisson process. The long-term average of the time interval between any two consecutive detections has been measured to be a constant value $\\tau$.\n\nTo perform a spot check, the physicist picks a random moment in time, say $t_{obs}$, and measures the length of the particular time interval that contains $t_{obs}$. This is the interval between the last detection before $t_{obs}$ and the first detection after $t_{obs}$. Let the random variable representing the length of this observed interval be denoted by $L$.\n\nAssuming the system has been running for a very long time before the observation is made, determine the variance of the observed interval length, $\\text{Var}(L)$. Express your answer as a closed-form analytic expression in terms of $\\tau$.", "solution": "Let the Poisson process have rate $\\lambda$, so the interarrival times are independent and identically distributed exponential random variables with mean $1/\\lambda$. The problem states that the long-term average interarrival time is $\\tau$, hence\n$$\n\\lambda=\\frac{1}{\\tau}.\n$$\n\nBy stationarity (the system has been running a long time), we can take the observation time as $t_{obs}=0$ without loss of generality. Let $S$ denote the backward recurrence time (time since the last detection before $0$) and $T$ the forward recurrence time (time until the next detection after $0$). The observed interval length is\n$$\nL=S+T.\n$$\n\nFor a Poisson process, disjoint increments are independent. Therefore, the events in $(-s,0]$ and $(0,t]$ are independent. For $s,t \\geq 0$,\n$$\n\\mathbb{P}(S>s,\\,T>t)=\\mathbb{P}(\\text{no events in }(-s,0])\\,\\mathbb{P}(\\text{no events in }(0,t])=\\exp(-\\lambda s)\\exp(-\\lambda t)=\\exp(-\\lambda(s+t)).\n$$\nFrom this, the marginals are\n$$\n\\mathbb{P}(S>s)=\\exp(-\\lambda s),\\qquad \\mathbb{P}(T>t)=\\exp(-\\lambda t),\n$$\nso $S$ and $T$ are independent and each is exponential with rate $\\lambda$.\n\nHence $L=S+T$ is the sum of two independent $\\operatorname{Exp}(\\lambda)$ random variables, i.e., $L$ has a gamma (Erlang) distribution with shape parameter $2$ and rate $\\lambda$. Using independence,\n$$\n\\operatorname{Var}(L)=\\operatorname{Var}(S)+\\operatorname{Var}(T)=\\frac{1}{\\lambda^{2}}+\\frac{1}{\\lambda^{2}}=\\frac{2}{\\lambda^{2}}.\n$$\nSubstituting $\\lambda=1/\\tau$ gives\n$$\n\\operatorname{Var}(L)=2\\tau^{2}.\n$$", "answer": "$$\\boxed{2\\tau^{2}}$$", "id": "1339061"}]}