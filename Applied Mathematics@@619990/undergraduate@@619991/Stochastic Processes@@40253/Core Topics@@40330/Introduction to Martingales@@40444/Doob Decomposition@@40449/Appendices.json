{"hands_on_practices": [{"introduction": "We begin our exploration with a direct application of the Doob Decomposition theorem to a cumulative sum process. This exercise [@problem_id:1397477] illustrates the fundamental technique of isolating a predictable trend from a series of random variables with time-varying means. It serves as an essential first step in mastering the decomposition by directly applying the definition to compute the predictable component and extract the underlying martingale.", "problem": "Let $\\{Y_k\\}_{k=1}^\\infty$ be a sequence of independent random variables. The mean of each random variable is dependent on its index, given by $E[Y_k] = \\frac{1}{k}$ for $k \\ge 1$. Furthermore, assume that $E[|Y_k|] < \\infty$ for all $k$.\n\nConsider the stochastic process $X_n$ defined by the cumulative sum $X_n = \\sum_{k=1}^n Y_k$ for $n \\ge 1$, with the initial condition $X_0 = 0$. Let $\\{\\mathcal{F}_n\\}_{n=0}^\\infty$ be the natural filtration generated by the sequence $\\{Y_k\\}$, where $\\mathcal{F}_0 = \\{\\emptyset, \\Omega\\}$ is the trivial sigma-algebra and $\\mathcal{F}_n = \\sigma(Y_1, \\dots, Y_n)$ for $n \\ge 1$.\n\nAccording to the Doob Decomposition Theorem, any adapted process $X_n$ with finite expectation can be uniquely expressed as the sum of a martingale $M_n$ and a predictable process $A_n$, such that $X_n = M_n + A_n$.\n\nFind the explicit expressions for the martingale component $M_n$ and the predictable process component $A_n$ for $n \\geq 1$, subject to the standard initial conditions $M_0 = 0$ and $A_0 = 0$.\n\nPresent your answer as a row matrix containing two expressions: the first for $M_n$ and the second for $A_n$.", "solution": "We first recall the discrete-time Doob decomposition for an adapted, integrable process. For an adapted process $\\{X_n\\}_{n \\geq 0}$ with $E[|X_n|] < \\infty$, the Doob decomposition writes $X_n = M_n + A_n$, where $M_n$ is a martingale with $M_0 = 0$ and $A_n$ is a predictable process with $A_0 = 0$. In discrete time, the predictable component is given by\n$$\nA_n = \\sum_{k=1}^{n} E[X_k - X_{k-1} \\mid \\mathcal{F}_{k-1}],\n$$\nand the martingale component is $M_n = X_n - A_n$.\n\nIn our case, $X_n = \\sum_{k=1}^{n} Y_k$ with $X_0 = 0$. Therefore, the one-step increment is\n$$\nX_n - X_{n-1} = Y_n.\n$$\nThus, the predictable increment is\n$$\nE[X_n - X_{n-1} \\mid \\mathcal{F}_{n-1}] = E[Y_n \\mid \\mathcal{F}_{n-1}].\n$$\nSince $Y_n$ is independent of $\\mathcal{F}_{n-1} = \\sigma(Y_1,\\dots,Y_{n-1})$ and $E[|Y_n|] < \\infty$, we have\n$$\nE[Y_n \\mid \\mathcal{F}_{n-1}] = E[Y_n] = \\frac{1}{n}.\n$$\nTherefore, the predictable process is\n$$\nA_n = \\sum_{k=1}^{n} E[Y_k \\mid \\mathcal{F}_{k-1}] = \\sum_{k=1}^{n} \\frac{1}{k}.\n$$\nConsequently, the martingale component is\n$$\nM_n = X_n - A_n = \\sum_{k=1}^{n} Y_k - \\sum_{k=1}^{n} \\frac{1}{k} = \\sum_{k=1}^{n} \\left(Y_k - \\frac{1}{k}\\right).\n$$\nBy construction, $A_n$ is predictable since $A_n - A_{n-1} = \\frac{1}{n}$ is $\\mathcal{F}_{n-1}$-measurable, $A_0 = 0$, and $M_n$ is a martingale since\n$$\nE\\left[M_n \\mid \\mathcal{F}_{n-1}\\right] = E\\left[\\sum_{k=1}^{n} \\left(Y_k - \\frac{1}{k}\\right) \\mid \\mathcal{F}_{n-1}\\right]\n= \\sum_{k=1}^{n-1} \\left(Y_k - \\frac{1}{k}\\right) + E\\left[Y_n - \\frac{1}{n} \\mid \\mathcal{F}_{n-1}\\right]\n= M_{n-1}.\n$$\nThus the Doob decomposition is uniquely identified as above.", "answer": "$$\\boxed{\\begin{pmatrix}\\sum_{k=1}^{n}\\left(Y_{k}-\\frac{1}{k}\\right) & \\sum_{k=1}^{n}\\frac{1}{k}\\end{pmatrix}}$$", "id": "1397477"}, {"introduction": "Next, we tackle a canonical example in stochastic processes: the squared simple symmetric random walk. This process, representing the squared distance of a walker from its origin, is a natural submartingale that tends to drift away from the start. Decomposing it [@problem_id:1298470] reveals a surprisingly elegant predictable component and introduces the famous martingale $S_n^2 - n$, providing a deeper intuition for the behavior of random walks.", "problem": "Consider a simple symmetric random walk $(S_n)_{n \\geq 0}$ on the integers $\\mathbb{Z}$. The walk starts at $S_0 = 0$ and evolves according to $S_n = \\sum_{i=1}^n Y_i$ for $n \\geq 1$, where the $(Y_i)_{i \\geq 1}$ are independent and identically distributed random variables with probability distribution $P(Y_i = 1) = P(Y_i = -1) = 1/2$. Let $(\\mathcal{F}_n)_{n \\geq 0}$ be the natural filtration generated by this walk, i.e., $\\mathcal{F}_n = \\sigma(S_0, S_1, \\ldots, S_n)$.\n\nNow, consider the stochastic process $X_n = S_n^2$. This process represents the squared distance of the walker from the origin. It is a submartingale with respect to the filtration $(\\mathcal{F}_n)$. According to the Doob decomposition theorem, any adapted submartingale $X_n$ can be uniquely written as the sum of a martingale and a predictable process:\n$$X_n = M_n + A_n$$\nwhere $(M_n)_{n \\geq 0}$ is a martingale with respect to $(\\mathcal{F}_n)$ and $(A_n)_{n \\geq 0}$ is a predictable, non-decreasing process with $A_0 = 0$.\n\nYour task is to find the explicit expressions for the martingale component $M_n$ and the predictable component $A_n$ for the process $X_n = S_n^2$. Present your answer as a row matrix containing the expression for $M_n$ followed by the expression for $A_n$.", "solution": "We apply the Doob decomposition to the adapted submartingale $X_{n}=S_{n}^{2}$. By definition, the decomposition is $X_{n}=M_{n}+A_{n}$ with $A_{0}=0$, where\n$$\nA_{n}=\\sum_{k=1}^{n}\\mathbb{E}\\!\\left[X_{k}-X_{k-1}\\mid \\mathcal{F}_{k-1}\\right], \\quad M_{n}=X_{n}-A_{n}.\n$$\nCompute the increment of $X_{n}$:\n$$\nX_{n}-X_{n-1}=S_{n}^{2}-S_{n-1}^{2}=(S_{n-1}+Y_{n})^{2}-S_{n-1}^{2}=2S_{n-1}Y_{n}+Y_{n}^{2}.\n$$\nUsing independence of $Y_{n}$ from $\\mathcal{F}_{n-1}$ and the symmetry, we have $\\mathbb{E}[Y_{n}\\mid \\mathcal{F}_{n-1}]=0$ and $Y_{n}^{2}=1$, hence $\\mathbb{E}[Y_{n}^{2}\\mid \\mathcal{F}_{n-1}]=1$. Therefore,\n$$\n\\mathbb{E}\\!\\left[X_{n}-X_{n-1}\\mid \\mathcal{F}_{n-1}\\right]=\\mathbb{E}\\!\\left[2S_{n-1}Y_{n}+1\\mid \\mathcal{F}_{n-1}\\right]=2S_{n-1}\\mathbb{E}[Y_{n}\\mid \\mathcal{F}_{n-1}]+1=1.\n$$\nThus,\n$$\nA_{n}=\\sum_{k=1}^{n}1=n,\n$$\nwhich is predictable and non-decreasing with $A_{0}=0$. Consequently,\n$$\nM_{n}=X_{n}-A_{n}=S_{n}^{2}-n.\n$$\nTo verify the martingale property,\n$$\n\\mathbb{E}[M_{n}\\mid \\mathcal{F}_{n-1}]=\\mathbb{E}[S_{n}^{2}-n\\mid \\mathcal{F}_{n-1}]=S_{n-1}^{2}+2S_{n-1}\\mathbb{E}[Y_{n}\\mid \\mathcal{F}_{n-1}]+\\mathbb{E}[Y_{n}^{2}\\mid \\mathcal{F}_{n-1}]-n=S_{n-1}^{2}+1-n=M_{n-1}.\n$$\nHence, $M_{n}=S_{n}^{2}-n$ is a martingale and $A_{n}=n$ is the predictable compensator. By uniqueness of the Doob decomposition, these are the desired components.", "answer": "$$\\boxed{\\begin{pmatrix} S_{n}^{2}-n & n \\end{pmatrix}}$$", "id": "1298470"}, {"introduction": "To complete our practice, we shift focus from submartingales to a supermartingale, a process that tends to decrease over time. By decomposing the running minimum of a sequence of random variables [@problem_id:1298493], we can precisely quantify its predictable downward drift. This problem highlights the versatility of the Doob Decomposition and introduces a state-dependent compensator, where the predictable change at each step depends on the current value of the process.", "problem": "Consider a sequence of independent, identically distributed (i.i.d.) random variables $X_1, X_2, \\dots$, where each $X_k$ is drawn from a uniform distribution on the set of integers $\\{1, 2, \\dots, M\\}$, for a fixed integer $M > 1$.\n\nLet $Y_n = \\min\\{X_1, \\dots, X_n\\}$ for $n \\ge 1$ be the running minimum process. This process is a supermartingale with respect to the natural filtration $\\mathcal{F}_n = \\sigma(X_1, \\dots, X_n)$, where $\\mathcal{F}_0$ is the trivial sigma-algebra. The Doob decomposition theorem states that $Y_n$ can be uniquely written as $Y_n = M_n - A_n$, where $(M_n)_{n \\ge 0}$ is a martingale and $(A_n)_{n \\ge 0}$ is a non-decreasing, predictable process with $A_0=0$.\n\nFind a closed-form analytic expression for the increment of the compensator process, $\\Delta A_n = A_n - A_{n-1}$, for any integer $n \\ge 2$. Your expression should be in terms of $Y_{n-1}$ and $M$.", "solution": "By the discrete-time Doob decomposition for a supermartingale $(Y_{n})$, the compensator increments are\n$$\n\\Delta A_{n}=A_{n}-A_{n-1}=\\mathbb{E}\\!\\left[Y_{n-1}-Y_{n}\\,\\middle|\\,\\mathcal{F}_{n-1}\\right], \\quad n\\ge 2.\n$$\nSince $Y_{n}=\\min\\{Y_{n-1},X_{n}\\}$, we have\n$$\nY_{n-1}-Y_{n}=Y_{n-1}-\\min\\{Y_{n-1},X_{n}\\}=\\max\\{Y_{n-1}-X_{n},0\\}.\n$$\nBecause $X_{n}$ is independent of $\\mathcal{F}_{n-1}$ and uniformly distributed on $\\{1,2,\\dots,M\\}$, conditioning on $\\mathcal{F}_{n-1}$ amounts to fixing $y:=Y_{n-1}$ and taking expectation over $X_{n}$. Therefore,\n$$\n\\Delta A_{n}=\\mathbb{E}\\!\\left[(Y_{n-1}-X_{n})^{+}\\,\\middle|\\,\\mathcal{F}_{n-1}\\right]\n=\\frac{1}{M}\\sum_{k=1}^{M}\\max\\{y-k,0\\}.\n$$\nOnly terms with $k\\le y-1$ contribute, so\n$$\n\\Delta A_{n}=\\frac{1}{M}\\sum_{k=1}^{y-1}(y-k)\n=\\frac{1}{M}\\left(\\sum_{k=1}^{y-1}y-\\sum_{k=1}^{y-1}k\\right)\n=\\frac{1}{M}\\left(y(y-1)-\\frac{(y-1)y}{2}\\right)\n=\\frac{y(y-1)}{2M},\n$$\nwhere $y=Y_{n-1}$. Hence,\n$$\n\\Delta A_{n}=\\frac{Y_{n-1}\\bigl(Y_{n-1}-1\\bigr)}{2M}, \\quad n\\ge 2.\n$$", "answer": "$$\\boxed{\\frac{Y_{n-1}\\left(Y_{n-1}-1\\right)}{2M}}$$", "id": "1298493"}]}