{"hands_on_practices": [{"introduction": "This first practice problem provides a foundational understanding of how to model a system's evolution over time. We will analyze a simple two-state Markov chain, deriving a recurrence relation to describe the probability of being in a specific state at any given time step $n$. This exercise is crucial for grasping the core mechanics of how marginal distributions evolve based on the transition probabilities. [@problem_id:1316056]", "problem": "In a behavioral neuroscience experiment, a rat is placed in a chamber with two levers, one red and one blue. The experiment investigates the rat's learning and choice patterns over a series of trials. The probability of the rat's choice on any given trial is modeled as depending only on its choice in the immediately preceding trial.\n\nThe experimental data suggests the following probabilistic model:\n- If the rat presses the red lever on a trial, the probability it will press the red lever again on the next trial is $p$.\n- If the rat presses the blue lever on a trial, the probability it will press the red lever on the next trial is $q$.\n\nAssume that on the first trial (trial 1), the rat presses the red lever with a probability of $r_1$.\n\nDerive a general expression for the probability, let's call it $P_n$, that the rat presses the red lever on the $n$-th trial, for $n \\geq 1$. Your answer should be a closed-form expression in terms of $n$, $p$, $q$, and $r_1$. To ensure the model is non-trivial and avoids certain degenerate cases, assume that $p \\neq q$ and $p-q \\neq 1$.", "solution": "Let $P_n$ be the probability that the rat presses the red lever on the $n$-th trial. Let $R_n$ and $B_n$ be the events that the rat presses the red and blue lever on the $n$-th trial, respectively. We are asked to find an expression for $P_n = P(R_n)$.\n\nWe can express $P_n$ in terms of the probabilities from the $(n-1)$-th trial using the law of total probability. The event $R_n$ can occur in two mutually exclusive ways: either the rat chose red on trial $n-1$ and then red on trial $n$, or it chose blue on trial $n-1$ and then red on trial $n$.\n$$P(R_n) = P(R_n | R_{n-1}) P(R_{n-1}) + P(R_n | B_{n-1}) P(B_{n-1})$$\n\nFrom the problem statement, we have the following conditional probabilities:\n1.  $P(R_n | R_{n-1}) = p$\n2.  $P(R_n | B_{n-1}) = q$\n\nAlso, the probability of choosing red on trial $n-1$ is $P(R_{n-1}) = P_{n-1}$. Since there are only two levers, the probability of choosing blue on trial $n-1$ is $P(B_{n-1}) = 1 - P(R_{n-1}) = 1 - P_{n-1}$.\n\nSubstituting these into the equation for $P(R_n)$:\n$$P_n = p \\cdot P_{n-1} + q \\cdot (1 - P_{n-1})$$\n$$P_n = p P_{n-1} + q - q P_{n-1}$$\n$$P_n = (p - q) P_{n-1} + q$$\nThis is a linear first-order non-homogeneous recurrence relation for $P_n$, valid for $n \\geq 2$.\n\nTo solve this recurrence relation, we first find the fixed point, or stationary probability, $P^*$. This is the value for which $P_n = P_{n-1} = P^*$.\n$$P^* = (p-q)P^* + q$$\n$$P^*(1 - (p-q)) = q$$\n$$P^* = \\frac{q}{1 - p + q}$$\nThis fixed point exists because the problem states $p-q \\neq 1$, which ensures the denominator $1-p+q$ is not zero.\n\nNow, let's define a new sequence $d_n = P_n - P^*$.\n$$d_n = P_n - \\frac{q}{1-p+q}$$\nLet's substitute the recurrence for $P_n$:\n$$d_n = ((p-q)P_{n-1} + q) - \\frac{q}{1-p+q}$$\nRecall that $P_{n-1} = d_{n-1} + P^* = d_{n-1} + \\frac{q}{1-p+q}$.\n$$d_n = (p-q)\\left(d_{n-1} + \\frac{q}{1-p+q}\\right) + q - \\frac{q}{1-p+q}$$\n$$d_n = (p-q)d_{n-1} + \\frac{(p-q)q}{1-p+q} + \\frac{q(1-p+q) - q}{1-p+q}$$\n$$d_n = (p-q)d_{n-1} + \\frac{pq - q^2}{1-p+q} + \\frac{q - pq + q^2 - q}{1-p+q}$$\n$$d_n = (p-q)d_{n-1} + \\frac{pq - q^2 - pq + q^2}{1-p+q}$$\n$$d_n = (p-q)d_{n-1}$$\nThis is a simple geometric progression. The solution is $d_n = (p-q)^{n-1} d_1$.\n\nNow we find $d_1$. The initial condition is given for trial 1: $P_1 = r_1$.\n$$d_1 = P_1 - P^* = r_1 - \\frac{q}{1-p+q}$$\nSubstituting this back into the expression for $d_n$:\n$$d_n = \\left(r_1 - \\frac{q}{1-p+q}\\right) (p-q)^{n-1}$$\n\nFinally, we find $P_n$ by substituting back $d_n = P_n - P^*$:\n$$P_n - \\frac{q}{1-p+q} = \\left(r_1 - \\frac{q}{1-p+q}\\right) (p-q)^{n-1}$$\n$$P_n = \\frac{q}{1-p+q} + \\left(r_1 - \\frac{q}{1-p+q}\\right) (p-q)^{n-1}$$\nThis is the general expression for the probability that the rat presses the red lever on the $n$-th trial. The constraint $p \\neq q$ ensures that the factor $(p-q)$ is not zero, which we have used implicitly.", "answer": "$$\\boxed{\\frac{q}{1-p+q} + \\left(r_1 - \\frac{q}{1-p+q}\\right)(p-q)^{n-1}}$$", "id": "1316056"}, {"introduction": "Building on the foundational concepts, this exercise demonstrates the practical computation of a marginal distribution for a system with more states. By using matrix multiplication, you will calculate the state probabilities at a specific future time, $n=3$, for a four-state Markov chain. This hands-on calculation solidifies the relationship between the initial distribution $\\pi_0$, the transition matrix $P$, and the distribution at time $n$, $\\pi_n = \\pi_0 P^n$, and illustrates how to extract meaningful information from the resulting distribution. [@problem_id:1316084]", "problem": "A simplified model for a computer's memory controller tracks the status of two critical, independent memory blocks. The system can be in one of four states, $\\mathcal{S} = \\{S_1, S_2, S_3, S_4\\}$, representing the conditions of the two blocks:\n- $S_1$: Both blocks are idle.\n- $S_2$: The first block is active, the second is idle.\n- $S_3$: The first block is idle, the second is active.\n- $S_4$: Both blocks are active.\n\nThe state of the system evolves over discrete time steps according to a homogeneous Markov chain, $X_n$. The one-step transition probability matrix, $P$, where $P_{ij}$ is the probability of transitioning from state $S_i$ to state $S_j$ in a single time step, is given by:\n$$\nP = \\begin{pmatrix}\n0.1  0.5  0.3  0.1 \\\\\n0.4  0.2  0.2  0.2 \\\\\n0.2  0.1  0.4  0.3 \\\\\n0.1  0.2  0.3  0.4\n\\end{pmatrix}\n$$\nAt time $n=0$, the system is initialized with both memory blocks idle, meaning the process starts in state $S_1$.\n\nCalculate the probability that exactly one memory block is active at time $n=3$. Round your final answer to four significant figures.", "solution": "We model the system as a homogeneous Markov chain with state space $\\mathcal{S}=\\{S_{1},S_{2},S_{3},S_{4}\\}$ and transition matrix $P$. Let $p_{n}$ be the row vector of state probabilities at time $n$. With initial state $S_{1}$, we have\n$$\np_{0}=\\begin{pmatrix}1  0  0  0\\end{pmatrix}, \\quad p_{n}=p_{0}P^{n}.\n$$\nCompute $p_{1}=p_{0}P$ as the first row of $P$:\n$$\np_{1}=\\begin{pmatrix}0.1  0.5  0.3  0.1\\end{pmatrix}.\n$$\nNext, compute $p_{2}=p_{1}P$. Its components are\n$$\np_{2}(1)=0.1\\cdot 0.1+0.5\\cdot 0.4+0.3\\cdot 0.2+0.1\\cdot 0.1=0.28,\n$$\n$$\np_{2}(2)=0.1\\cdot 0.5+0.5\\cdot 0.2+0.3\\cdot 0.1+0.1\\cdot 0.2=0.20,\n$$\n$$\np_{2}(3)=0.1\\cdot 0.3+0.5\\cdot 0.2+0.3\\cdot 0.4+0.1\\cdot 0.3=0.28,\n$$\n$$\np_{2}(4)=0.1\\cdot 0.1+0.5\\cdot 0.2+0.3\\cdot 0.3+0.1\\cdot 0.4=0.24,\n$$\nso\n$$\np_{2}=\\begin{pmatrix}0.28  0.20  0.28  0.24\\end{pmatrix}.\n$$\nThen compute $p_{3}=p_{2}P$. Its components are\n$$\np_{3}(1)=0.28\\cdot 0.1+0.20\\cdot 0.4+0.28\\cdot 0.2+0.24\\cdot 0.1=0.188,\n$$\n$$\np_{3}(2)=0.28\\cdot 0.5+0.20\\cdot 0.2+0.28\\cdot 0.1+0.24\\cdot 0.2=0.256,\n$$\n$$\np_{3}(3)=0.28\\cdot 0.3+0.20\\cdot 0.2+0.28\\cdot 0.4+0.24\\cdot 0.3=0.308,\n$$\n$$\np_{3}(4)=0.28\\cdot 0.1+0.20\\cdot 0.2+0.28\\cdot 0.3+0.24\\cdot 0.4=0.248,\n$$\nso\n$$\np_{3}=\\begin{pmatrix}0.188  0.256  0.308  0.248\\end{pmatrix}.\n$$\nExactly one memory block active corresponds to states $S_{2}$ or $S_{3}$, hence\n$$\n\\mathbb{P}(X_{3}\\in\\{S_{2},S_{3}\\}\\mid X_{0}=S_{1})=p_{3}(2)+p_{3}(3)=0.256+0.308=0.564.\n$$\nRounded to four significant figures, this is $0.5640$.", "answer": "$$\\boxed{0.5640}$$", "id": "1316084"}, {"introduction": "This final practice problem challenges you to find a general, closed-form expression for the marginal distribution at any time $n$ for a three-state system. Unlike the previous exercise, which focused on a single time step, here you will solve a system of linked recurrence relations to describe the system's long-term behavior. This reveals how Markov chains can exhibit interesting patterns, such as periodic or oscillating probabilities, over time. [@problem_id:1316110]", "problem": "A biologist is modeling the foraging behavior of a bee among three specific flower patches, labeled Patch 1, Patch 2, and Patch 3. The bee's movement between patches after each nectar-gathering stop is probabilistic and can be described by a simple set of rules:\n\n- If the bee is at Patch 1, its next flight will take it to Patch 2 with a probability of $1/2$ or to Patch 3 with a probability of $1/2$. It never stays at Patch 1 for two consecutive flights.\n- If the bee is at either Patch 2 or Patch 3, its next flight will always be to Patch 1.\n\nThe bee begins its journey at Patch 1 at time $n=0$. Determine the probability distribution of the bee's location after exactly $n$ flights, for any integer $n \\ge 1$. Express your answer as a row vector $[p_1(n), p_2(n), p_3(n)]$, where $p_i(n)$ is the probability that the bee is at Patch $i$ after $n$ flights. Your answer should consist of three closed-form expressions in terms of $n$.", "solution": "Model the beeâ€™s location as a discrete-time Markov chain on states 1, 2, 3 with transition probabilities given by the rules. Let $v_{n}=[p_{1}(n),p_{2}(n),p_{3}(n)]$ be the row vector of probabilities after $n$ flights. The Markov property gives the evolution\n$$\nv_{n+1}=v_{n}P,\n$$\nwith transition matrix\n$$\nP=\\begin{pmatrix}\n0  \\frac{1}{2}  \\frac{1}{2}\\\\\n1  0  0\\\\\n1  0  0\n\\end{pmatrix},\n$$\nsince from Patch 1 the bee goes to 2 or 3 with probability $\\frac{1}{2}$ each, and from Patch 2 or 3 it goes to 1 with probability $1$. The initial condition is $v_{0}=[1,0,0]$.\n\nWrite $v_{n}=[a_{n},b_{n},c_{n}]$. From $v_{n+1}=v_{n}P$,\n$$\na_{n+1}=b_{n}+c_{n},\\quad b_{n+1}=\\frac{1}{2}a_{n},\\quad c_{n+1}=\\frac{1}{2}a_{n}.\n$$\nBy symmetry $b_{n}=c_{n}$ for all $n$ (true at $n=0$ and preserved by the recursion). Let $b_{n}=c_{n}=x_{n}$. Then\n$$\na_{n+1}=2x_{n},\\qquad x_{n+1}=\\frac{1}{2}a_{n}.\n$$\nEliminating $x_{n}$ gives a second-order recurrence for $a_{n}$:\n$$\na_{n+1}=2x_{n}=2\\cdot\\frac{1}{2}a_{n-1}=a_{n-1}.\n$$\nWith $a_{0}=1$ and $a_{1}=b_{0}+c_{0}=0$, the solution is $a_{n}=1$ for even $n$ and $a_{n}=0$ for odd $n$. This admits the closed form\n$$\na_{n}=\\frac{1+(-1)^{n}}{2}.\n$$\nSince $b_{n}=c_{n}$ and $a_{n}+b_{n}+c_{n}=1$, we have\n$$\nb_{n}=c_{n}=\\frac{1-a_{n}}{2}=\\frac{1-(-1)^{n}}{4}.\n$$\nTherefore, for any integer $n\\ge 1$, the distribution after $n$ flights is\n$$\n[p_{1}(n),p_{2}(n),p_{3}(n)]=\\left[\\frac{1+(-1)^{n}}{2},\\,\\frac{1-(-1)^{n}}{4},\\,\\frac{1-(-1)^{n}}{4}\\right].\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1+(-1)^{n}}{2}  \\frac{1-(-1)^{n}}{4}  \\frac{1-(-1)^{n}}{4}\\end{pmatrix}}$$", "id": "1316110"}]}