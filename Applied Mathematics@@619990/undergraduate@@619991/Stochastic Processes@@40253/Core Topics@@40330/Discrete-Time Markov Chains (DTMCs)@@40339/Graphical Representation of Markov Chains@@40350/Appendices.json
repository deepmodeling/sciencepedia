{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we'll translate a simple physical scenario into the language of Markov chains. This exercise focuses on a fundamental skill: defining states and determining transition probabilities from a system's rules of movement. By modeling a robot's path in a grid [@problem_id:1305824], you will practice calculating multi-step probabilities, a cornerstone for predicting the short-term evolution of a stochastic process.", "problem": "A small autonomous cleaning robot operates in a square room that is partitioned into a 2x2 grid of four equal quadrants. The quadrants are labeled with coordinates: (1,1) for the top-left, (1,2) for the top-right, (2,1) for the bottom-left, and (2,2) for the bottom-right.\n\nThe robot's movement is modeled as a discrete-time process. At each time step, the robot moves from its current quadrant to one of its adjacent quadrants. Two quadrants are defined as \"adjacent\" if they share a common side (i.e., not just a corner). The robot is equally likely to move to any of its available adjacent quadrants. For instance, from quadrant (1,1), the robot can only move to (1,2) or (2,1).\n\nIf the robot starts in the top-left quadrant, (1,1), what is the probability that it will be back in the top-left quadrant after exactly two time steps? Express your answer as a decimal rounded to two significant figures.", "solution": "Let the state of the system be the quadrant the robot is in. The state space is $S = \\{(1,1), (1,2), (2,1), (2,2)\\}$. We can model the robot's movement as a Markov chain on this state space. Let's assign numerical labels to the states for notational convenience: $1 \\leftrightarrow (1,1)$, $2 \\leftrightarrow (1,2)$, $3 \\leftrightarrow (2,1)$, and $4 \\leftrightarrow (2,2)$.\n\nThe problem asks for the probability of being in state 1 after two steps, given the process starts in state 1. This is the entry $P^{(2)}_{11}$ of the two-step transition matrix, which is the square of the one-step transition matrix, $P$.\n\nFirst, we construct the one-step transition matrix $P$, where the entry $P_{ij}$ is the probability of moving from state $i$ to state $j$ in one step. The movement rule is a uniform random choice among adjacent quadrants.\n\nFrom state 1, (1,1): The adjacent quadrants are (1,2) and (2,1). So, the robot moves to state 2 or state 3, each with probability $1/2$. The first row of $P$ is $(0, 1/2, 1/2, 0)$.\n$P_{11}=0, P_{12}=1/2, P_{13}=1/2, P_{14}=0$.\n\nFrom state 2, (1,2): The adjacent quadrants are (1,1) and (2,2). So, the robot moves to state 1 or state 4, each with probability $1/2$. The second row of $P$ is $(1/2, 0, 0, 1/2)$.\n$P_{21}=1/2, P_{22}=0, P_{23}=0, P_{24}=1/2$.\n\nFrom state 3, (2,1): The adjacent quadrants are (1,1) and (2,2). So, the robot moves to state 1 or state 4, each with probability $1/2$. The third row of $P$ is $(1/2, 0, 0, 1/2)$.\n$P_{31}=1/2, P_{32}=0, P_{33}=0, P_{34}=1/2$.\n\nFrom state 4, (2,2): The adjacent quadrants are (1,2) and (2,1). So, the robot moves to state 2 or state 3, each with probability $1/2$. The fourth row of $P$ is $(0, 1/2, 1/2, 0)$.\n$P_{41}=0, P_{42}=1/2, P_{43}=1/2, P_{44}=0$.\n\nThe complete one-step transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n0 & \\frac{1}{2} & \\frac{1}{2} & 0 \\\\\n\\frac{1}{2} & 0 & 0 & \\frac{1}{2} \\\\\n\\frac{1}{2} & 0 & 0 & \\frac{1}{2} \\\\\n0 & \\frac{1}{2} & \\frac{1}{2} & 0\n\\end{pmatrix}\n$$\n\nThe two-step transition probabilities are the entries of the matrix $P^2 = P \\times P$. We are interested in the probability of returning to state 1 after two steps, starting from state 1. This is the element $P^2_{11}$. This can be calculated using the definition of matrix multiplication:\n$$\nP^2_{11} = \\sum_{k=1}^{4} P_{1k} P_{k1}\n$$\nUsing the values from the matrix $P$:\n$$\nP^2_{11} = P_{11} P_{11} + P_{12} P_{21} + P_{13} P_{31} + P_{14} P_{41}\n$$\nSubstituting the probabilities we found:\n$$\nP^2_{11} = (0)(0) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + (0)(0)\n$$\n$$\nP^2_{11} = 0 + \\frac{1}{4} + \\frac{1}{4} + 0 = \\frac{2}{4} = \\frac{1}{2}\n$$\nAlternatively, one can reason about the paths. To start at (1,1) and return to (1,1) in two steps, the robot must move to an adjacent quadrant and then immediately move back. The possible paths are:\n1. (1,1) $\\rightarrow$ (1,2) $\\rightarrow$ (1,1). The probability of this path is $P((1,1)\\rightarrow(1,2)) \\times P((1,2)\\rightarrow(1,1)) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\n2. (1,1) $\\rightarrow$ (2,1) $\\rightarrow$ (1,1). The probability of this path is $P((1,1)\\rightarrow(2,1)) \\times P((2,1)\\rightarrow(1,1)) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}$.\nThese two paths are mutually exclusive, so the total probability is the sum of their probabilities: $\\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}$.\n\nThe probability is $1/2 = 0.5$. The problem requires the answer to be rounded to two significant figures, which is $0.50$.", "answer": "$$\\boxed{0.50}$$", "id": "1305824"}, {"introduction": "Having practiced short-term predictions, we now shift our focus to the long-term structure of a Markov chain. This problem introduces the critical concepts of communicating classes, which partition the state space into distinct groups, and the classification of these states as either transient or recurrent. By analyzing the directed pathways on a hypothetical 'dumbbell' graph [@problem_id:1305826], you will learn to identify which parts of the system are temporary and which represent final destinations.", "problem": "A particle performs a random walk on a set of six states, labeled $S = \\{1, 2, 3, 4, 5, 6\\}$. The connections between the states define the possible transitions for the particle. The topology of these connections forms a \"directed dumbbell\" structure, described as follows:\n\n-   **First Cluster:** States $\\{1, 2, 3\\}$ form a triangle. Bidirectional connections exist along the edges, meaning a particle can move between state 1 and 2, between state 2 and 3, and between state 3 and 1, in either direction.\n-   **Second Cluster:** States $\\{4, 5, 6\\}$ form a second, separate triangle. Similar to the first cluster, bidirectional connections exist along the edges, allowing movement between state 4 and 5, between state 5 and 6, and between state 6 and 4, in either direction.\n-   **Bridge:** A single directed bridge connects the two clusters. A transition is possible from state 3 to state 4, but a transition from state 4 back to state 3 is not possible.\n\nAt each discrete time step, if a particle is at a state $i$, it will move to one of its accessible neighboring states with equal probability. A state $j$ is an accessible neighbor of $i$ if a directed path from $i$ to $j$ exists.\n\nBased on this system, identify all communicating classes and classify each class as either recurrent or transient. Choose the option that correctly describes the classes.\n\nA. One transient class $\\{1, 2, 3\\}$ and one recurrent class $\\{4, 5, 6\\}$.\n\nB. One recurrent class $\\{1, 2, 3\\}$ and one transient class $\\{4, 5, 6\\}$.\n\nC. One communicating class $\\{1, 2, 3, 4, 5, 6\\}$ which is recurrent.\n\nD. Two recurrent classes, $\\{1, 2, 3\\}$ and $\\{4, 5, 6\\}$.\n\nE. Two transient classes, $\\{1, 2, 3\\}$ and $\\{4, 5, 6\\}$.\n\nF. Six communicating classes, $\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}$, all of which are transient.", "solution": "We model the system as a discrete-time Markov chain on state space $S=\\{1,2,3,4,5,6\\}$. For states $i,j\\in S$, define $i\\to j$ if there exists $n\\in\\mathbb{N}$ such that $(P^{n})_{ij}>0$, where $P$ is the one-step transition matrix induced by the stated rule, and define $i\\leftrightarrow j$ (communication) if $i\\to j$ and $j\\to i$. A communicating class is an equivalence class under $\\leftrightarrow$. A class $C$ is closed if for all $i\\in C$ and $j\\notin C$ we have $P(i,j)=0$. In a finite Markov chain, every closed communicating class is positive recurrent, and any state not in a closed class is transient.\n\nStep 1: Identify communication structure.\n- Within $\\{1,2,3\\}$: the triangle has bidirectional edges along its sides, so for any $i,j\\in\\{1,2,3\\}$ there are directed paths both ways. Hence for all such $i,j$, $i\\leftrightarrow j$, so $\\{1,2,3\\}$ is a communicating class.\n- Within $\\{4,5,6\\}$: the second triangle is likewise bidirectionally connected along its sides, so for any $i,j\\in\\{4,5,6\\}$, $i\\leftrightarrow j$, making $\\{4,5,6\\}$ a communicating class.\n- Between clusters: there is a directed bridge from $3$ to $4$, and from $4$ one can move within $\\{4,5,6\\}$, so for any $i\\in\\{1,2,3\\}$ and any $j\\in\\{4,5,6\\}$ there is a directed path $i\\to j$. However, there is no directed path from any $k\\in\\{4,5,6\\}$ back to any $\\ell\\in\\{1,2,3\\}$ (no edge from $4$ to $3$ or otherwise), so $j\\not\\to i$. Therefore no state in $\\{4,5,6\\}$ communicates with a state in $\\{1,2,3\\}$, and the communicating classes are exactly $\\{1,2,3\\}$ and $\\{4,5,6\\}$.\n\nStep 2: Classify recurrence versus transience.\n- Closedness of $\\{4,5,6\\}$: For any $i\\in\\{4,5,6\\}$ and any $j\\in\\{1,2,3\\}$, there is no directed path from $i$ to $j$, so under the given one-step rule (which only allows moves to states reachable by a directed path), $P(i,j)=0$. Hence $\\{4,5,6\\}$ is closed. Being a closed communicating class in a finite chain, all its states are (positive) recurrent.\n- Non-closedness of $\\{1,2,3\\}$: There exists a state $i\\in\\{1,2,3\\}$ and a state $j\\in\\{4,5,6\\}$ with $P(i,j)>0$ because from $3$ there is a direct transition to $4$ (and under the stated rule, from $1$ or $2$ there are also one-step moves to $\\{4,5,6\\}$ since those are reachable by directed paths). Thus $\\{1,2,3\\}$ is not closed. In a finite Markov chain, states in a non-closed communicating class are transient because with positive probability the chain exits the class and, upon entering the closed class $\\{4,5,6\\}$, cannot return. Therefore all states in $\\{1,2,3\\}$ are transient.\n\nHence there are two communicating classes: $\\{1,2,3\\}$, which is transient, and $\\{4,5,6\\}$, which is recurrent. This corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1305826"}, {"introduction": "Our final practice moves from qualitative classification to quantitative prediction by introducing a powerful technique for calculating expected hitting times. First-step analysis allows us to determine the average number of steps required to reach a target state, a crucial metric in many applications. By working through a hypothetical distributed computing system with a 'star' topology [@problem_id:1305793], you will learn to leverage system symmetry and linear equations to find these expected values.", "problem": "Consider a distributed computing system modeled as a network of nodes. The system consists of one central router, labeled $R_0$, and $N$ identical peripheral compute nodes, labeled $C_1, C_2, \\ldots, C_N$, where $N \\ge 2$. A data packet, or \"token,\" moves between these nodes in discrete time steps according to a specific routing protocol, forming a discrete-time Markov chain.\n\nThe transition rules are defined as follows:\n- From the central router $R_0$, the token is forwarded to any of the $N$ compute nodes with equal probability.\n- From any compute node $C_i$ (for $i \\in \\{1, 2, \\ldots, N\\}$), the token is sent back to the central router $R_0$ with probability $p$, where $0 < p \\le 1$.\n- With the remaining probability, $1-p$, the token is forwarded from compute node $C_i$ to a different compute node $C_j$ (where $j \\neq i$). The destination node $C_j$ is chosen uniformly at random from the set of all other $N-1$ compute nodes.\n\nSuppose the token starts at compute node $C_1$. Determine the expected number of time steps until the token first arrives at compute node $C_2$. Provide your answer as a closed-form analytical expression in terms of $N$ and $p$.", "solution": "Let $E_1$ denote the expected number of steps to hit $C_2$ starting from $C_1$, $E_0$ from $R_0$, and $E_o$ from any other compute node $C_k$ with $k \\notin \\{1,2\\}$. By definition, $E_2=0$.\n\nUsing first-step analysis:\n\n- From $R_0$, the token goes to $C_2$ with probability $\\frac{1}{N}$, to $C_1$ with probability $\\frac{1}{N}$, and to one of the $N-2$ other leaves with total probability $\\frac{N-2}{N}$:\n$$\nE_0=1+\\frac{1}{N} \\cdot 0+\\frac{1}{N} E_1+\\frac{N-2}{N} E_o.\n$$\n\n- From $C_1$, it goes to $R_0$ with probability $p$, to $C_2$ with probability $\\frac{1-p}{N-1}$, and to other leaves with total probability $\\frac{N-2}{N-1}(1-p)$:\n$$\nE_1=1+p E_0+\\frac{1-p}{N-1} \\cdot 0+\\frac{N-2}{N-1}(1-p) E_o.\n$$\n\n- From an other leaf, it goes to $R_0$ with probability $p$, to $C_2$ with probability $\\frac{1-p}{N-1}$, to $C_1$ with probability $\\frac{1-p}{N-1}$, and remains among other leaves with total probability $\\frac{N-3}{N-1}(1-p)$:\n$$\nE_o=1+p E_0+\\frac{1-p}{N-1} \\cdot 0+\\frac{1-p}{N-1} E_1+\\frac{N-3}{N-1}(1-p) E_o.\n$$\n\nRewriting the three equations:\n$$\nE_0-\\frac{1}{N} E_1-\\frac{N-2}{N} E_o=1,\n$$\n$$\n-p E_0+E_1-\\frac{N-2}{N-1}(1-p) E_o=1,\n$$\n$$\n-p E_0-\\frac{1-p}{N-1} E_1+\\frac{2+(N-3) p}{N-1} E_o=1.\n$$\n\nFrom the first equation,\n$$\nE_0=1+\\frac{1}{N} E_1+\\frac{N-2}{N} E_o.\n$$\nSubstituting this into the second and third equations yields two linear equations in $E_1$ and $E_o$:\n$$\n\\left(1-\\frac{p}{N}\\right) E_1-\\left[p \\frac{N-2}{N}+\\frac{N-2}{N-1}(1-p)\\right] E_o=1+p,\n$$\n$$\n-\\left(\\frac{p}{N}+\\frac{1-p}{N-1}\\right) E_1+\\left[-p \\frac{N-2}{N}+\\frac{2+(N-3) p}{N-1}\\right] E_o=1+p.\n$$\nSubtracting the second from the first gives\n$$\n\\left[\\left(1-\\frac{p}{N}\\right)+\\left(\\frac{p}{N}+\\frac{1-p}{N-1}\\right)\\right] E_1+\\left\\{-\\left[p \\frac{N-2}{N}+\\frac{N-2}{N-1}(1-p)\\right]-\\left[-p \\frac{N-2}{N}+\\frac{2+(N-3) p}{N-1}\\right]\\right\\} E_o=0,\n$$\nwhich simplifies to\n$$\n\\frac{N-p}{N-1} E_1-\\frac{N-p}{N-1} E_o=0 \\quad \\Longrightarrow \\quad E_1=E_o.\n$$\n\nUsing $E_1=E_o$ in $E_0=1+\\frac{1}{N} E_1+\\frac{N-2}{N} E_o$ gives\n$$\nE_0=1+\\frac{N-1}{N} E_1.\n$$\nSubstitute $E_0$ and $E_o=E_1$ into the $C_1$ equation:\n$$\nE_1=1+p\\left(1+\\frac{N-1}{N} E_1\\right)+\\frac{N-2}{N-1}(1-p) E_1.\n$$\nCollecting terms of $E_1$ on the left,\n$$\nE_1\\left[1-p \\frac{N-1}{N}-\\frac{N-2}{N-1}(1-p)\\right]=1+p.\n$$\nThe bracket simplifies as\n$$\n1-p \\frac{N-1}{N}-\\frac{N-2}{N-1}(1-p)=\\frac{N-p}{N(N-1)}.\n$$\nTherefore,\n$$\nE_1 \\cdot \\frac{N-p}{N(N-1)}=1+p \\quad \\Longrightarrow \\quad E_1=\\frac{N(N-1)(1+p)}{N-p}.\n$$\n\nThus, the expected number of steps from $C_1$ to $C_2$ is $\\frac{N(N-1)(1+p)}{N-p}$.", "answer": "$$\\boxed{\\frac{N(N-1)(1+p)}{N-p}}$$", "id": "1305793"}]}