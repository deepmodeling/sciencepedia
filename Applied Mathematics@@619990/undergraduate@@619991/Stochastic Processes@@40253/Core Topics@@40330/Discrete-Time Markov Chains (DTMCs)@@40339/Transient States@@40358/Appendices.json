{"hands_on_practices": [{"introduction": "To build a solid foundation, we begin with a clear and practical example of a finite-state Markov chain. This problem models the life cycle of industrial equipment, where states like 'Operational' and 'Requires Maintenance' are temporary stops on the way to a 'Permanently Failed' state. By analyzing this hypothetical model of transition probabilities, you will learn to identify transient states by determining if there is a path from them to an absorbing state, from which escape is impossible [@problem_id:1347265].", "problem": "A simplified model for the operational status of a piece of industrial equipment is described by a discrete-time Markov chain with three states:\n- State 1: Operational\n- State 2: Requires Maintenance\n- State 3: Permanently Failed\n\nThe equipment's state is evaluated at the end of each day. The transition probabilities between states are as follows:\n- If the equipment is in State 1 (Operational) on a given day, there is a 0.7 probability it will remain in State 1 and a 0.3 probability it will move to State 2 on the next day.\n- If the equipment is in State 2 (Requires Maintenance), there is a 0.5 probability it will be repaired and move back to State 1, and a 0.5 probability it will fail and move to State 3 on the next day. It never remains in State 2 for a second consecutive day.\n- If the equipment reaches State 3 (Permanently Failed), it remains in that state forever.\n\nA state is defined as transient if, starting from this state, there is a non-zero probability that the process will never return to it. Based on the transition probabilities provided, identify the complete set of all transient states for this Markov chain.\n\nA. {2}\n\nB. {3}\n\nC. {1, 3}\n\nD. {1, 2}\n\nE. The set of transient states is empty.", "solution": "Let the states be labeled as $1$ (Operational), $2$ (Requires Maintenance), and $3$ (Permanently Failed). The one-step transition matrix is\n$$\nP=\\begin{pmatrix}\n0.7 & 0.3 & 0 \\\\\n0.5 & 0 & 0.5 \\\\\n0 & 0 & 1\n\\end{pmatrix}.\n$$\nA state $i$ is transient if, starting from $i$, there is a positive probability that the chain never returns to $i$. Formally, with $T_{i}^{+}=\\inf\\{n\\ge 1:X_{n}=i\\}$, state $i$ is transient if $\\mathbb{P}_{i}(T_{i}^{+}=\\infty)>0$.\n\nConsider state $1$. A return to $1$ occurs as soon as $X_{1}=1$. Hence, to have no return at any $n\\ge 1$, the chain must avoid $1$ at time $1$, which forces $X_{1}=2$, and then immediately move to $3$ at time $2$ so that it can never visit $1$ later (since $3$ is absorbing). Therefore,\n$$\n\\mathbb{P}_{1}(T_{1}^{+}=\\infty)=\\mathbb{P}(1\\to 2)\\,\\mathbb{P}(2\\to 3)=0.3\\times 0.5=0.15>0,\n$$\nso state $1$ is transient.\n\nConsider state $2$. From $2$ the chain moves to $3$ with probability $0.5$, and since $3$ is absorbing, this precludes any future return to $2$. Thus,\n$$\n\\mathbb{P}_{2}(T_{2}^{+}=\\infty)\\ge \\mathbb{P}(2\\to 3)=0.5>0,\n$$\nso state $2$ is transient.\n\nConsider state $3$. Since $3$ is absorbing, $X_{1}=3$ with probability $1$, hence the chain returns to $3$ at time $1$ with probability $1$, and\n$$\n\\mathbb{P}_{3}(T_{3}^{+}=\\infty)=0.\n$$\nTherefore, state $3$ is not transient (it is recurrent).\n\nThe complete set of transient states is $\\{1,2\\}$, corresponding to option D.", "answer": "$$\\boxed{D}$$", "id": "1347265"}, {"introduction": "Now, let's extend our understanding of transience to an infinite state space. We will consider a particle moving on a hypothetical two-dimensional grid, a scenario reminiscent of the classic random walk, but with an absorbing 'trap' at the origin. This exercise demonstrates the powerful principle that even a single absorbing state can make other communicating states transient, by creating a non-zero probability that the process will be trapped and never return [@problem_id:1347255].", "problem": "A particle performs a simple symmetric random walk on the two-dimensional integer lattice, $\\mathbb{Z}^2$. At each discrete time step, the particle, currently at position $(x, y)$, moves to one of its four nearest neighbors — $(x+1, y)$, $(x-1, y)$, $(x, y+1)$, or $(x, y-1)$ — each with an equal probability of $1/4$.\n\nA modification is introduced to this random walk: the origin, $(0,0)$, is designated as an absorbing \"trap\". If the particle ever lands on the state $(0,0)$, it remains there for all subsequent time steps. All other states $(x,y) \\neq (0,0)$ are non-absorbing.\n\nConsider a particle that starts its walk at the state $S = (1, 0)$. Let $P_{return}$ be the probability that this particle ever returns to the starting state $S$ at some future time step. Which one of the following statements about $P_{return}$ is correct?\n\nA. $P_{return} = 1$\n\nB. $P_{return} < 1$\n\nC. $P_{return} = 0$\n\nD. $P_{return}$ is undefined because the lattice is infinite.", "solution": "Let $\\{X_{t}\\}_{t \\geq 0}$ be the simple symmetric random walk on $\\mathbb{Z}^{2}$ with $X_{0}=S=(1,0)$, nearest-neighbor transitions each with probability $\\frac{1}{4}$, and an absorbing state at the origin: if $X_{t}=(0,0)$ for some $t$, then $X_{t'}=(0,0)$ for all $t' \\geq t$. Define the return time to $S$ by $T_{S}=\\inf\\{t \\geq 1 : X_{t}=S\\}$ and $P_{return}=\\mathbb{P}(T_{S}<\\infty)$.\n\nTo show $P_{return}>0$, consider the explicit path that moves from $(1,0)$ to $(2,0)$ at time $1$ and then back to $(1,0)$ at time $2$. Each step has probability $\\frac{1}{4}$ and the steps are independent, so\n$$\n\\mathbb{P}(X_{1}=(2,0),\\,X_{2}=S)=\\frac{1}{4}\\cdot\\frac{1}{4}=\\frac{1}{16}.\n$$\nOn this event, $T_{S}=2$, hence\n$$\nP_{return}=\\mathbb{P}(T_{S}<\\infty)\\geq \\frac{1}{16}>0.\n$$\n\nTo show $P_{return}<1$, consider the event $A=\\{X_{1}=(0,0)\\}$. Since $(0,0)$ is absorbing, on $A$ the walk can never return to $S$, so $A \\subseteq \\{T_{S}=\\infty\\}$. Therefore,\n$$\n\\mathbb{P}(T_{S}=\\infty)\\geq \\mathbb{P}(A)=\\frac{1}{4},\n$$\nwhich implies\n$$\nP_{return}=\\mathbb{P}(T_{S}<\\infty)\\leq 1-\\frac{1}{4}=\\frac{3}{4}<1.\n$$\n\nCombining these, we have $0<P_{return}<1$, so the correct statement is that $P_{return}<1$. The probability is well defined despite the lattice being infinite, so option D is incorrect, and it is not zero due to the exhibited path, so option C is incorrect.", "answer": "$$\\boxed{B}$$", "id": "1347255"}, {"introduction": "Can a state be transient even if there are no absorbing states to get trapped in? This final practice problem explores this fascinating question by examining a random walk on an infinite regular tree, a common structure in graph theory. You will discover how the geometric structure of the state space itself can cause a process to drift away, making a return to the origin unlikely and thus rendering the state transient. This exercise challenges you to calculate the expected number of returns, providing a quantitative method to confirm transience [@problem_id:1347267].", "problem": "An infinite $d$-regular tree is an infinite, connected, acyclic graph where every vertex has a degree (number of neighbors) equal to $d$. Consider a particle performing a simple symmetric random walk on such a tree, where $d$ is an integer and $d \\ge 3$. The particle starts at an arbitrary vertex, which we label as the origin $o$. At each discrete time step, the particle moves from its current vertex to one of its $d$ adjacent vertices, with each neighbor being chosen with equal probability $\\frac{1}{d}$.\n\nCalculate the expected total number of times the particle returns to its starting vertex $o$ throughout its entire trajectory. Note that the initial position at time $t=0$ does not count as a return. Your final answer should be a closed-form analytic expression in terms of $d$.", "solution": "Let $X_{t}$ be the simple symmetric random walk on the infinite $d$-regular tree, started at the origin $o$. Write $R$ for the total number of returns to $o$ (excluding $t=0$). We first compute the probability $f$ that, starting from $o$, the walk ever returns to $o$ at least once.\n\nProject the walk to its distance from $o$, $D_{t}=\\operatorname{dist}(X_{t},o)$. Then $D_{0}=0$, and the first step sends the walk to some neighbor so $D_{1}=1$. For $k\\geq 1$, from any vertex at distance $k$ from $o$, there is exactly one neighbor at distance $k-1$ and $d-1$ neighbors at distance $k+1$. Hence, for $k\\geq 1$,\n$$\n\\mathbb{P}(D_{t+1}=k-1\\,|\\,D_{t}=k)=\\frac{1}{d},\\qquad \\mathbb{P}(D_{t+1}=k+1\\,|\\,D_{t}=k)=\\frac{d-1}{d}.\n$$\nThus $(D_{t})_{t\\geq 1}$ is a biased random walk on $\\{0,1,2,\\dots\\}$ with downward step probability $q=\\frac{1}{d}$ and upward step probability $p=\\frac{d-1}{d}$, and $0$ is absorbing for the event of return to $o$.\n\nLet $h(k)$ be the probability that, starting from $D_{1}=k$, the chain ever hits $0$. Then\n$$\nh(0)=1,\\qquad h(k)=\\frac{1}{d}h(k-1)+\\frac{d-1}{d}h(k+1)\\quad\\text{for all }k\\geq 1.\n$$\nSeek solutions of the form $h(k)=r^{k}$. Substituting gives\n$$\nr=\\frac{1}{d}+\\frac{d-1}{d}r^{2}\\quad\\Longleftrightarrow\\quad (d-1)r^{2}-dr+1=0.\n$$\nThe roots are\n$$\nr=\\frac{d\\pm(d-2)}{2(d-1)}\\in\\left\\{1,\\ \\frac{1}{d-1}\\right\\}.\n$$\nTherefore the general solution is $h(k)=A\\cdot 1^{k}+B\\left(\\frac{1}{d-1}\\right)^{k}$. Since $p>q$ for $d\\geq 3$, the probability of ever hitting $0$ must satisfy $\\lim_{k\\to\\infty}h(k)=0$, which forces $A=0$. Using $h(0)=1$ gives $B=1$. Hence\n$$\nh(k)=\\left(\\frac{1}{d-1}\\right)^{k},\\qquad\\text{so}\\qquad f=\\mathbb{P}_{o}(\\text{return to }o)=h(1)=\\frac{1}{d-1}.\n$$\n\nTo compute $\\mathbb{E}[R]$, use the renewal property at $o$. Conditioned on being at $o$, the probability of at least one further return is $f$, and after a return the process restarts from $o$. Let $m=\\mathbb{E}[R]$. Then\n$$\nm=f\\left(1+m\\right),\n$$\nbecause with probability $f$ there is a first return contributing $1$, after which the expected additional number of returns is again $m$. Solving,\n$$\nm=\\frac{f}{1-f}=\\frac{\\frac{1}{d-1}}{1-\\frac{1}{d-1}}=\\frac{1}{d-2}.\n$$\n\nTherefore, the expected total number of returns to $o$ (excluding the initial time) is $\\frac{1}{d-2}$.", "answer": "$$\\boxed{\\frac{1}{d-2}}$$", "id": "1347267"}]}