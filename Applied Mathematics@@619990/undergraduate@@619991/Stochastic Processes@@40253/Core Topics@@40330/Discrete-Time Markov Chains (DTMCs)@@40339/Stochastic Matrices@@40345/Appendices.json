{"hands_on_practices": [{"introduction": "Before using a stochastic matrix to model a dynamic system, we must confirm that it adheres to the fundamental rules of probability. This initial practice focuses on the defining properties of a valid transition matrix, which forms the bedrock of any Markov chain model. This exercise [@problem_id:1334934] asks you to verify these properties in a concrete scenario, ensuring you understand that the sum of probabilities for all possible transitions from any given state must equal exactly one.", "problem": "A botanist is modeling the health of a specific type of perennial plant over discrete time steps of one week. The plant can be in one of three states: Healthy (State 1), Stressed (State 2), or Diseased (State 3). The transitions between these states are modeled by a Markov chain. The proposed transition matrix $T$ is given as:\n$$\nT = \\begin{pmatrix} 0.85  0.10  0.05 \\\\ 0.20  p  0.50 \\\\ 0.05  0.25  0.70 \\end{pmatrix}\n$$\nIn this matrix, the element $T_{ij}$ represents the probability of the plant transitioning from state $i$ to state $j$ in a single week. For this matrix to be a valid representation of the transition probabilities, it must be a right stochastic matrix. Determine the value of the parameter $p$ that satisfies this condition.", "solution": "A right stochastic matrix requires that each row sums to $1$ and all entries are in $[0,1]$. For the given matrix\n$$\nT=\\begin{pmatrix}\n0.85  0.10  0.05 \\\\\n0.20  p  0.50 \\\\\n0.05  0.25  0.70\n\\end{pmatrix},\n$$\nthe first and third rows already sum to $1$:\n$$\n0.85+0.10+0.05=1,\\quad 0.05+0.25+0.70=1.\n$$\nFor the second row, impose the row-sum condition:\n$$\n0.20+p+0.50=1.\n$$\nSolving for $p$,\n$$\np=1-(0.20+0.50)=1-0.70=0.3.\n$$\nThis value satisfies $0\\leq p\\leq 1$, so the nonnegativity condition also holds.", "answer": "$$\\boxed{0.3}$$", "id": "1334934"}, {"introduction": "Once we have a valid transition matrix, we can use it to predict how a system evolves over time. This practice demonstrates the fundamental operation of a discrete-time Markov chain: calculating the system's state distribution after a single time step. The core mechanism involves multiplying the initial state vector by the transition matrix, a straightforward but powerful application of linear algebra [@problem_id:1334949]. Working through this example will solidify your understanding of how these matrices model dynamic changes in real-world systems like population dynamics.", "problem": "A simplified model for the differentiation of a population of biological cells categorizes them into three distinct types: Type A (progenitor cells), Type B (intermediate cells), and Type C (terminally differentiated cells). The state of the population at any given generation is described by a row vector $\\pi = \\begin{pmatrix} p_A  p_B  p_C \\end{pmatrix}$, where $p_A, p_B,$ and $p_C$ are the proportions of cells of each type, respectively.\n\nAt an initial time, the population's distribution is given by the state vector $\\pi_0 = \\begin{pmatrix} 0.1  0.7  0.2 \\end{pmatrix}$.\n\nThe change in this population from one generation to the next is modeled by a discrete-time Markov chain. The transition probabilities are encapsulated in the following one-step transition matrix $P$, where the element $P_{ij}$ represents the probability of a cell of type $i$ transitioning to type $j$ in a single generation.\n$$\nP = \\begin{pmatrix}\n0.6  0.4  0.0 \\\\\n0.0  0.5  0.5 \\\\\n0.0  0.0  1.0\n\\end{pmatrix}\n$$\nThe rows and columns are ordered corresponding to Type A, Type B, and Type C.\n\nDetermine the distribution of cells across the three types after one generation. Present your answer as a row matrix $\\begin{pmatrix} p_A  p_B  p_C \\end{pmatrix}$.", "solution": "In a discrete-time Markov chain modeled with row vectors, the distribution updates by right-multiplication with the transition matrix: if the current distribution is $\\pi_{0}$ and the one-step transition matrix is $P$, then the next-generation distribution is $\\pi_{1}=\\pi_{0}P$.\n\nGiven $\\pi_{0}=\\begin{pmatrix} 0.1  0.7  0.2 \\end{pmatrix}$ and\n$$\nP=\\begin{pmatrix}\n0.6  0.4  0.0 \\\\\n0.0  0.5  0.5 \\\\\n0.0  0.0  1.0\n\\end{pmatrix},\n$$\ncompute each component of $\\pi_{1}$ via row-by-column products:\n$$\np_{A}'=0.1\\cdot 0.6+0.7\\cdot 0.0+0.2\\cdot 0.0=0.06,\n$$\n$$\np_{B}'=0.1\\cdot 0.4+0.7\\cdot 0.5+0.2\\cdot 0.0=0.04+0.35=0.39,\n$$\n$$\np_{C}'=0.1\\cdot 0.0+0.7\\cdot 0.5+0.2\\cdot 1.0=0.35+0.2=0.55.\n$$\nThus,\n$$\n\\pi_{1}=\\begin{pmatrix} 0.06  0.39  0.55 \\end{pmatrix}.\n$$\nThe entries sum to $1$, confirming a valid probability distribution.", "answer": "$$\\boxed{\\begin{pmatrix} 0.06  0.39  0.55 \\end{pmatrix}}$$", "id": "1334949"}, {"introduction": "While calculating the system's very next state is useful, the true power of this framework lies in its ability to forecast long-term behavior. This final practice challenges you to look far into the future by deriving a general formula for the system's state after an arbitrary number of steps, $n$. By analyzing the structure of the transition matrix, you can develop a closed-form predictive equation [@problem_id:1334922], bridging the gap from simple, one-step iteration to a comprehensive understanding of the system's long-run dynamics and its convergence toward a stable equilibrium.", "problem": "A simplified model is used to describe a user's navigation behavior on a website with two main sections: an \"Articles\" section and a \"Forums\" section. The user's location is observed at discrete one-minute intervals. The model is characterized by the following transition probabilities:\n\n- If a user is in the \"Articles\" section at a given minute, there is a probability $a$ that they will remain in the \"Articles\" section in the next minute, and a probability $1-a$ that they will move to the \"Forums\" section.\n- If a user is in the \"Forums\" section, there is a probability $b$ that they will remain in the \"Forums\" section in the next minute, and a probability $1-b$ that they will move to the \"Articles\" section.\n\nThe parameters $a$ and $b$ are constants such that $0  a  1$ and $0  b  1$.\n\nSuppose a user starts in the \"Articles\" section at time $t=0$. Find a closed-form expression for the probability that this user is in the \"Articles\" section after $n$ minutes, for any non-negative integer $n$. Your answer should be expressed as a function of $a$, $b$, and $n$.", "solution": "Model the navigation as a two-state Markov chain with states \"Articles\" (A) and \"Forums\" (F). Let $x_n$ denote the probability that the user is in A at time $n$. The one-step transition probabilities are:\n- From A to A: $a$, from A to F: $1-a$.\n- From F to F: $b$, from F to A: $1-b$.\n\nConditioning on the state at time $n-1$, the total probability gives the recurrence\n$$\nx_{n} = a x_{n-1} + (1-b)(1 - x_{n-1}).\n$$\nSimplify:\n$$\nx_{n} = a x_{n-1} + (1-b) - (1-b) x_{n-1} = (a + b - 1) x_{n-1} + (1-b).\n$$\nDefine $r \\equiv a + b - 1$. Then\n$$\nx_{n} = r x_{n-1} + (1-b).\n$$\nThis is a first-order linear difference equation. Its fixed point $x^*$ satisfies\n$$\nx^* = r x^* + (1-b) \\;\\;\\Rightarrow\\;\\; (1 - r) x^* = 1 - b \\;\\;\\Rightarrow\\;\\; x^* = \\frac{1 - b}{1 - r}.\n$$\nSince $r = a + b - 1$, we have $1 - r = 2 - a - b$, so\n$$\nx^* = \\frac{1 - b}{2 - a - b}.\n$$\nThe general solution is\n$$\nx_n = x^* + C r^n.\n$$\nUse the initial condition $x_0 = 1$ (starting in A) to find $C$:\n$$\n1 = x^* + C \\;\\;\\Rightarrow\\;\\; C = 1 - x^* = 1 - \\frac{1 - b}{2 - a - b} = \\frac{1 - a}{2 - a - b}.\n$$\nTherefore,\n$$\nx_n = \\frac{1 - b}{2 - a - b} + \\frac{1 - a}{2 - a - b}(a + b - 1)^n = \\frac{(1 - b) + (1 - a)(a + b - 1)^n}{2 - a - b}.\n$$\nSince $0  a  1$ and $0  b  1$, we have $-1  a + b - 1  1$, ensuring convergence to the stationary probability $\\frac{1 - b}{2 - a - b}$ as $n \\to \\infty$.", "answer": "$$\\boxed{\\frac{(1 - b) + (1 - a)(a + b - 1)^{n}}{2 - a - b}}$$", "id": "1334922"}]}