{"hands_on_practices": [{"introduction": "Understanding a Markov chain begins with its most direct application: calculating the probability of a specific sequence of events. This practice problem demonstrates how to use the transition matrix to determine the likelihood of a particular path through the state space. By applying the Markov property, you'll see how the probability of a multi-step journey is simply the product of the probabilities of its individual steps, a foundational skill for analyzing stochastic processes [@problem_id:1345202].", "problem": "A simplified model describes the state of a particle that can occupy one of three discrete energy wells, labeled as State 1, State 2, and State 3. The process is modeled as a discrete-time Markov chain. The transition from a state $i$ at time $t$ to a state $j$ at time $t+1$ is given by the probability $P_{ij}$, where the transition probability matrix $P$ is defined as:\n$$\nP = \\begin{pmatrix}\n0.2 & 0.5 & 0.3 \\\\\n0.4 & 0.1 & 0.5 \\\\\n0.7 & 0.2 & 0.1\n\\end{pmatrix}\n$$\nAssume that the particle is always in State 1 at the initial time, $t=0$.\nCalculate the probability that the particle is observed in State 3 at time $t=1$ and subsequently in State 2 at time $t=2$. Express your answer as a decimal.", "solution": "Let $X_{t}$ denote the state at time $t$. The initial condition is $X_{0}=1$ with probability $1$. We are asked for the probability of the event $\\{X_{1}=3, X_{2}=2\\}$ given $X_{0}=1$.\n\nBy the multiplication rule and the Markov property,\n$$\n\\Pr(X_{1}=3, X_{2}=2 \\mid X_{0}=1)\n= \\Pr(X_{1}=3 \\mid X_{0}=1)\\,\\Pr(X_{2}=2 \\mid X_{1}=3).\n$$\nFrom the transition matrix $P$, we read $P_{13}=0.3$ and $P_{32}=0.2$, so\n$$\n\\Pr(X_{1}=3, X_{2}=2 \\mid X_{0}=1) = 0.3 \\times 0.2 = 0.06.\n$$\nThus, the required probability is $0.06$.", "answer": "$$\\boxed{0.06}$$", "id": "1345202"}, {"introduction": "While knowing the probability of one specific path is useful, we often want to know the overall likelihood of being in a certain state after several time steps, regardless of the exact path taken. This exercise introduces the concept of multi-step transition probabilities, which requires summing over all possible intermediate paths. By learning to compute the $n$-step transition matrix, $P^n$, you can predict the system's state distribution in the near future [@problem_id:1345206].", "problem": "The behavior of an experimental self-driving car's control system is modeled as a discrete-time Markov chain. The system can be in one of three operational modes at any given time step: 'Aggressive', 'Normal', or 'Cautious'. The transition from one mode to another in a single time step is governed by a fixed probability matrix. Let the states be represented by numbers: 1 for 'Aggressive', 2 for 'Normal', and 3 for 'Cautious'. The one-step transition probability matrix $P$, where the entry $P_{ij}$ is the probability of transitioning from state $i$ to state $j$, is given by:\n\n$$\nP = \\begin{pmatrix} 0.5 & 0.4 & 0.1 \\\\ 0.2 & 0.5 & 0.3 \\\\ 0.1 & 0.6 & 0.3 \\end{pmatrix}\n$$\n\nThe car's system is initialized in the 'Normal' mode. We want to compare the likelihood of its operational mode after exactly two time steps. Which of the following statements is correct?\n\nA. The probability of the system being in 'Aggressive' mode is greater than the probability of it being in 'Cautious' mode.\n\nB. The probability of the system being in 'Cautious' mode is greater than the probability of it being in 'Aggressive' mode.\n\nC. The probabilities of the system being in 'Aggressive' mode and 'Cautious' mode are exactly equal.\n\nD. This cannot be determined from the information provided.", "solution": "Let the states be labeled as 1 = Aggressive, 2 = Normal, 3 = Cautious. The system starts in state 2, so the probability of being in state $j$ after two steps is the two-step transition probability $(P^{2})_{2j}$, where $P^{2} = P P$.\n\nWrite the given transition matrix with exact fractions:\n$$\nP = \\begin{pmatrix}\n\\frac{1}{2} & \\frac{2}{5} & \\frac{1}{10} \\\\\n\\frac{1}{5} & \\frac{1}{2} & \\frac{3}{10} \\\\\n\\frac{1}{10} & \\frac{3}{5} & \\frac{3}{10}\n\\end{pmatrix}.\n$$\nFor $j \\in \\{1,2,3\\}$,\n$$\n(P^{2})_{2j} = \\sum_{k=1}^{3} P_{2k} P_{kj}.\n$$\nCompute the probabilities to states 1 and 3 after two steps.\n\nFor state 1 (Aggressive):\n$$\n(P^{2})_{21} = P_{21}P_{11} + P_{22}P_{21} + P_{23}P_{31}\n= \\frac{1}{5}\\cdot\\frac{1}{2} + \\frac{1}{2}\\cdot\\frac{1}{5} + \\frac{3}{10}\\cdot\\frac{1}{10}\n= \\frac{1}{10} + \\frac{1}{10} + \\frac{3}{100}\n= \\frac{23}{100}.\n$$\nFor state 3 (Cautious):\n$$\n(P^{2})_{23} = P_{21}P_{13} + P_{22}P_{23} + P_{23}P_{33}\n= \\frac{1}{5}\\cdot\\frac{1}{10} + \\frac{1}{2}\\cdot\\frac{3}{10} + \\frac{3}{10}\\cdot\\frac{3}{10}\n= \\frac{1}{50} + \\frac{3}{20} + \\frac{9}{100}\n= \\frac{2}{100} + \\frac{15}{100} + \\frac{9}{100}\n= \\frac{26}{100}.\n$$\nComparison:\n$$\n\\frac{23}{100} < \\frac{26}{100},\n$$\nso the probability of being in Cautious mode after two steps is greater than that of being in Aggressive mode. Therefore, statement B is correct.", "answer": "$$\\boxed{B}$$", "id": "1345206"}, {"introduction": "Beyond calculating short-term probabilities, a deep understanding of a Markov chain involves analyzing its long-term structural properties. This practice focuses on identifying communicating classes, which are groups of states that are mutually accessible. By examining the zero and non-zero entries in the transition matrix, you can map out the fundamental structure of the system and reveal which parts of the state space are interconnected and which contain isolated, absorbing states [@problem_id:1345194].", "problem": "An economist develops a simplified Markov chain model to study generational wealth mobility within a country. The population is categorized into four distinct economic states: $S_1$ (Lower Class), $S_2$ (Middle Class), $S_3$ (Upper Class), and $S_4$ (Established Wealth). The state of a family is observed from one generation to the next, and the probabilities of transitioning between these states are given by the following one-step transition probability matrix $P$:\n\n$$\nP = \\begin{pmatrix}\n0.7 & 0.3 & 0 & 0 \\\\\n0.2 & 0.6 & 0.2 & 0 \\\\\n0 & 0.1 & 0.8 & 0.1 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\n\nHere, the entry $P_{ij}$ represents the probability that a family in state $S_i$ in one generation will have descendants in state $S_j$ in the next generation. The state space of the model is $S = \\{S_1, S_2, S_3, S_4\\}$.\n\nYour task is to partition the state space $S$ into its unique communicating classes. Choose the correct partition from the options provided below.\n\nA. $\\{S_1\\}, \\{S_2\\}, \\{S_3\\}, \\{S_4\\}$\n\nB. $\\{S_1, S_2\\}, \\{S_3, S_4\\}$\n\nC. $\\{S_1, S_2, S_3\\}, \\{S_4\\}$\n\nD. $\\{S_1\\}, \\{S_2, S_3\\}, \\{S_4\\}$\n\nE. $\\{S_1, S_2, S_3, S_4\\}$", "solution": "We use the standard definitions for discrete-time Markov chains. State $i$ is said to access state $j$ if there exists $n \\in \\mathbb{N}$ such that $(P^{n})_{ij} > 0$. Two states $i$ and $j$ communicate, written $i \\leftrightarrow j$, if each accesses the other. Communicating classes are the equivalence classes under this relation; a class $C$ is closed if $P_{ij} = 0$ for all $i \\in C$ and $j \\notin C$.\n\nFrom the given $P$, the entries $P_{12}$ and $P_{21}$ are strictly positive, hence $S_{1} \\to S_{2}$ and $S_{2} \\to S_{1}$ in one step, so $S_{1} \\leftrightarrow S_{2}$. Similarly, $P_{23} > 0$ and $P_{32} > 0$, so $S_{2} \\leftrightarrow S_{3}$. By transitivity of communication, $S_{1} \\leftrightarrow S_{3}$. Explicitly, $(P^{2})_{13} \\geq P_{12}P_{23} > 0$ gives $S_{1} \\to S_{3}$ and $(P^{2})_{31} \\geq P_{32}P_{21} > 0$ gives $S_{3} \\to S_{1}$. Therefore, $S_{1}, S_{2}, S_{3}$ all communicate, forming a single communicating class $\\{S_{1}, S_{2}, S_{3}\\}$.\n\nFor $S_{4}$, the fourth row of $P$ has $P_{44} = 1$ and $P_{4j} = 0$ for $j \\neq 4$. Hence for all $n \\in \\mathbb{N}$, $(P^{n})_{4j} = 0$ for $j \\neq 4$, so $S_{4}$ cannot access any other state, while every state can access $S_{4}$ via paths with positive probability (e.g., $S_{3} \\to S_{4}$ since $P_{34} > 0$, $S_{2} \\to S_{3} \\to S_{4}$ since $P_{23}P_{34} > 0$, and $S_{1} \\to S_{2} \\to S_{3} \\to S_{4}$ since $P_{12}P_{23}P_{34} > 0$). Therefore, $S_{4}$ only communicates with itself and forms its own closed communicating class $\\{S_{4}\\}$.\n\nThus, the unique partition of the state space into communicating classes is $\\{S_{1}, S_{2}, S_{3}\\}$ and $\\{S_{4}\\}$, which corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1345194"}]}