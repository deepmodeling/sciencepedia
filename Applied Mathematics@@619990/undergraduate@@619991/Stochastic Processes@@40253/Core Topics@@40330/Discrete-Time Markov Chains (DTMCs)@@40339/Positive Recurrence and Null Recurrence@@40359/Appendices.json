{"hands_on_practices": [{"introduction": "This first practice problem takes us back to the foundational definition of recurrence. By analyzing a simple model of a particle's energy level [@problem_id:1323959], you will directly calculate the expected time for the particle to return to its ground state. This hands-on calculation is crucial for building a solid intuition for what it means for a state to be positive recurrent: not only does the process eventually return, but the average time it takes to do so is finite.", "problem": "A particle's energy level is modeled as a discrete-time stochastic process on the set of non-negative integers $\\{0, 1, 2, \\dots\\}$. From any energy level $i \\ge 0$, the particle transitions to level $i+2$ with a fixed probability $p$. With the complementary probability $1-p$, it decays to the ground state (level 0). The probability $p$ is a constant in the range $0 < p < 1$.\n\nWhich of the following statements correctly classifies the ground state, level 0?\n\nA. Level 0 is a transient state.\n\nB. Level 0 is a null recurrent state.\n\nC. Level 0 is a positive recurrent state.\n\nD. The classification of level 0 depends on whether $p < 1/2$ or $p \\ge 1/2$.\n\nE. The classification of level 0 is only well-defined if $p$ is a rational number.", "solution": "Let $X_{n}$ be the energy level at time $n$, and consider the ground state $0$. From any level $i \\ge 0$, the transition is\n$$\n\\mathbb{P}(X_{n+1}=i+2 \\mid X_{n}=i)=p, \\quad \\mathbb{P}(X_{n+1}=0 \\mid X_{n}=i)=1-p,\n$$\nwith $0<p<1$. In particular, from $0$ we have $\\mathbb{P}(X_{1}=0)=1-p$ and $\\mathbb{P}(X_{1}=2)=p$.\n\nDefine the first return time to $0$ (starting from $X_{0}=0$) by\n$$\nT_{0}=\\min\\{n \\ge 1: X_{n}=0\\}.\n$$\nAt each step $n \\ge 1$, regardless of the current state, a decay to $0$ occurs with probability $1-p$ and an upward move occurs with probability $p$. Therefore,\n$$\n\\mathbb{P}(T_{0}>n)=\\mathbb{P}(\\text{no decay in steps }1,\\dots,n)=p^{n}.\n$$\nHence, for $n \\ge 1$,\n$$\n\\mathbb{P}(T_{0}=n)=\\mathbb{P}(T_{0}>n-1)-\\mathbb{P}(T_{0}>n)=p^{n-1}-p^{n}=p^{n-1}(1-p).\n$$\nThus the return probability is\n$$\nf_{00}=\\mathbb{P}(T_{0}<\\infty)=1-\\lim_{n \\to \\infty}\\mathbb{P}(T_{0}>n)=1-\\lim_{n \\to \\infty}p^{n}=1,\n$$\nso state $0$ is recurrent. Its expected return time is\n$$\n\\mathbb{E}[T_{0}]=\\sum_{n=1}^{\\infty} n\\,\\mathbb{P}(T_{0}=n)=\\sum_{n=1}^{\\infty} n\\,p^{n-1}(1-p)=\\frac{1}{1-p},\n$$\nwhich is finite for all $0<p<1$. By definition, a recurrent state with finite expected return time is positive recurrent.\n\nTherefore, level $0$ is positive recurrent, independent of whether $p<\\frac{1}{2}$ or $p \\ge \\frac{1}{2}$, and independent of whether $p$ is rational.", "answer": "$$\\boxed{C}$$", "id": "1323959"}, {"introduction": "Calculating expected return times directly can be difficult for more complex systems. This exercise introduces a more powerful technique by analyzing the 'drift' of a process using a relatable model of personal savings [@problem_id:1323998]. By examining the average one-step change in the system, you can determine its long-term stability and classify its states as positive recurrent, null recurrent, or transient, providing a crucial tool for analyzing chains where first-passage times are intractable.", "problem": "A person's financial savings can be modeled as a discrete-time Markov chain $\\{X_n, n \\ge 0\\}$, where $X_n$ represents the amount of savings in integer units at the end of month $n$. The state space is the set of non-negative integers $\\{0, 1, 2, \\dots\\}$. The rules for changing the savings from month to month are as follows:\n\n- Each month, the person decides to save one additional unit with a fixed probability $p$.\n- If the current savings are at least 2 units, the person may decide to spend 2 units, which occurs with a fixed probability $q$. This spending decision is independent of the saving decision.\n- If neither of these events occurs, the savings remain unchanged.\n\nLet's formalize the transition probabilities. From a state $i$:\n- For $i=0$ or $i=1$: The savings can only increase by 1 (to $i+1$) with probability $p$, or stay the same (at $i$) with probability $1-p$. The spending option is not available.\n- For $i \\ge 2$: The savings increase by 1 (to $i+1$) with probability $p$, decrease by 2 (to $i-2$) with probability $q$, or remain the same (at $i$) with probability $1-p-q$.\n\nAssume that $p \\in (0,1)$, $q \\in (0,1)$, and $p+q < 1$. The Markov chain described is irreducible and aperiodic.\n\nWhich of the following statements correctly specifies the conditions on $p$ and $q$ for the chain to be positive recurrent and null recurrent?\n\nA. Positive Recurrent: $p < 2q$. Null Recurrent: $p = 2q$.\n\nB. Positive Recurrent: $p > 2q$. Null Recurrent: $p = 2q$.\n\nC. Positive Recurrent: $p < q$. Null Recurrent: $p = q$.\n\nD. Positive Recurrent: $2p < q$. Null Recurrent: $2p = q$.\n\nE. Positive Recurrent: $p < q/2$. Null Recurrent: $p = q/2$.", "solution": "For $i \\ge 2$, the one-step increment $\\Delta X := X_{n+1}-X_{n}$ satisfies\n$$\n\\Delta X=\\begin{cases}\n+1 & \\text{with probability } p,\\\\\n-2 & \\text{with probability } q,\\\\\n0 & \\text{with probability } 1-p-q.\n\\end{cases}\n$$\nThus, for $i \\ge 2$,\n$$\n\\mathbb{E}[\\Delta X \\mid X_{n}=i]=p-2q.\n$$\nFor $i=0$ or $i=1$, there is no spending, so\n$$\n\\mathbb{E}[\\Delta X \\mid X_{n}=0]=p,\\qquad \\mathbb{E}[\\Delta X \\mid X_{n}=1]=p.\n$$\nConsider the Lyapunov function $V(i)=i$. Its drift is\n$$\n\\mathbb{E}[V(X_{n+1})-V(X_{n}) \\mid X_{n}=i]=\n\\begin{cases}\np & \\text{if } i\\in\\{0,1\\},\\\\\np-2q & \\text{if } i \\ge 2.\n\\end{cases}\n$$\nHence, outside the finite set $C=\\{0,1\\}$, the drift is the constant $p-2q$.\n\nBy the Foster-Lyapunov criterion:\n- If $p-2q<0$ (that is, $p<2q$), then there exists $\\epsilon>0$ with $\\mathbb{E}[V(X_{n+1})-V(X_{n}) \\mid X_{n}=i]\\le -\\epsilon$ for all $i \\ge 2$, implying the chain is positive recurrent.\n- If $p-2q>0$ (that is, $p>2q$), the drift is positive outside $C$, which implies transience (so not recurrent).\n- For the boundary case $p=2q$, the drift is $0$ for all $i \\ge 2$. To distinguish null recurrence from positive recurrence, compute the second moment of the increment for $i \\ge 2$:\n$$\n\\mathbb{E}[(\\Delta X)^{2} \\mid X_{n}=i]=p \\cdot 1^{2}+q \\cdot 2^{2}+(1-p-q)\\cdot 0=p+4q.\n$$\nThus, when $p=2q$, the variance is\n$$\n\\mathrm{Var}(\\Delta X \\mid X_{n}=i)=\\mathbb{E}[(\\Delta X)^{2} \\mid X_{n}=i] - \\left(\\mathbb{E}[\\Delta X \\mid X_{n}=i]\\right)^{2}=p+4q>0,\n$$\nso the increments have zero mean and positive variance for all $i \\ge 2$. This places the chain in the classical one-dimensional reflected random-walk regime with bounded jumps, zero drift, and nondegenerate variance, which is null recurrent. Equivalently, by Lamperti-type criteria for processes on $\\{0,1,2,\\dots\\}$ with bounded increments and asymptotically zero drift, zero drift with positive variance yields null recurrence.\n\nTherefore, the chain is positive recurrent if and only if $p<2q$, and null recurrent if and only if $p=2q$. This corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1323998"}, {"introduction": "A key consequence of positive recurrence is the existence of a unique stationary distribution, which describes the long-term proportion of time the process spends in each state. This problem challenges you to apply this concept to a random walk on an infinite binary tree [@problem_id:1323981]. You will use the principle of detailed balance to find this distribution, illustrating how to translate the abstract property of positive recurrence into concrete, quantifiable predictions about a system's behavior.", "problem": "A particle undergoes a random walk on the vertices of a countably infinite binary tree. The vertices are organized into levels, with the root being the single vertex at level 0. Any vertex at level $n \\ge 0$ has two 'child' vertices at level $n+1$, and any vertex at level $n>0$ has one 'parent' vertex at level $n-1$.\n\nThe transition probabilities for the particle's movement are defined as follows:\n- From any vertex at level $n > 0$, the particle moves to its parent with a probability of $p=2/3$, and to each of its two children with a probability of $q=1/6$.\n- From the root (level 0), the particle moves to either of its two children with equal probability.\n\nIt is given that this process defines an irreducible, positive recurrent Markov chain, and thus possesses a unique stationary distribution over the set of vertices.\n\nDetermine the stationary probability of finding the particle at the root of the tree. Express your answer as a fraction.", "solution": "Let $s_{n}$ denote the stationary probability assigned to a single vertex at level $n$. By symmetry, all vertices at the same level have equal stationary probability, so the total probability at level $n$ is $2^{n} s_{n}$. We will determine $s_{0}$ using detailed balance across edges.\n\nFor reversibility, enforce detailed balance on each parent-child edge.\n\nBetween the root (level $0$) and a level $1$ child:\n$$\ns_{0} \\cdot \\frac{1}{2} = s_{1} \\cdot \\frac{2}{3}\n\\quad\\Longrightarrow\\quad\ns_{1} = \\frac{3}{4}\\,s_{0}.\n$$\n\nBetween a parent at level $n-1>0$ and its child at level $n$ (so $n\\geq 2$):\n$$\ns_{n-1} \\cdot \\frac{1}{6} = s_{n} \\cdot \\frac{2}{3}\n\\quad\\Longrightarrow\\quad\ns_{n} = \\frac{1}{4}\\,s_{n-1}.\n$$\n\nThus, for $n\\geq 1$,\n$$\ns_{n} = \\frac{3}{4}\\left(\\frac{1}{4}\\right)^{n-1} s_{0} = 3 \\cdot 4^{-n} s_{0}.\n$$\n\nNormalize to ensure total probability $1$:\n$$\n1 = \\sum_{n=0}^{\\infty} 2^{n} s_{n}\n= s_{0} + \\sum_{n=1}^{\\infty} 2^{n} \\cdot 3 \\cdot 4^{-n} s_{0}\n= s_{0} + 3 s_{0} \\sum_{n=1}^{\\infty} \\left(\\frac{1}{2}\\right)^{n}\n= s_{0} + 3 s_{0} \\cdot 1\n= 4 s_{0}.\n$$\nHence $s_{0} = \\frac{1}{4}$, which is the stationary probability of the root.", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "1323981"}]}