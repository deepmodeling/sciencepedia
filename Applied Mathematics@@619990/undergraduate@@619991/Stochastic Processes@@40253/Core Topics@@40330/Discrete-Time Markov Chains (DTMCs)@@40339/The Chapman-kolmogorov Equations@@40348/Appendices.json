{"hands_on_practices": [{"introduction": "The most fundamental application of the Chapman-Kolmogorov framework is to predict the future state of a system given its present state. This exercise provides a tangible scenario involving a robotic vacuum cleaner to practice this core skill. By modeling the robot's movement as a Markov chain, we can calculate the likelihood of its location after several time steps, illustrating the forward-looking power of these equations. [@problem_id:1347922]", "problem": "A smart robotic vacuum cleaner operates in an apartment with two rooms, a Living Room (Room 1) and a Bedroom (Room 2). The robot's movement between the rooms is modeled as a discrete-time stochastic process. At the end of each cleaning cycle (a time step), the robot decides where to go next based on its current location.\n\nThe transition probabilities are as follows:\n- If the robot is in the Living Room (Room 1), there is a probability of $\\frac{1}{3}$ it will stay in the Living Room for the next cycle, and a probability of $\\frac{2}{3}$ it will move to the Bedroom (Room 2).\n- If the robot is in the Bedroom (Room 2), there is a probability of $\\frac{1}{2}$ it will move to the Living Room for the next cycle, and a probability of $\\frac{1}{2}$ it will stay in the Bedroom.\n\nSuppose the robot starts its cleaning process in the Living Room at time step $t=0$. What is the probability that the robot will be in the Living Room at time step $t=3$? Express your answer as a single fraction.", "solution": "Model the robot’s location as a two-state Markov chain with states $1$ (Living Room) and $2$ (Bedroom). Let $p_t = \\mathbb{P}(X_t=1)$ be the probability the robot is in the Living Room at time $t$. By the law of total probability and the given transition probabilities,\n$$\np_{t+1} = p_t \\cdot \\frac{1}{3} + (1-p_t) \\cdot \\frac{1}{2} = \\frac{1}{2} - \\frac{1}{6} p_t.\n$$\nThis is a linear difference equation. Its fixed point $p^*$ satisfies\n$$\np^* = \\frac{1}{2} - \\frac{1}{6} p^* \\quad\\Rightarrow\\quad p^* \\left(1+\\frac{1}{6}\\right) = \\frac{1}{2} \\quad\\Rightarrow\\quad p^* = \\frac{3}{7}.\n$$\nThus the general solution is\n$$\np_t - p^* = \\left(-\\frac{1}{6}\\right)^t (p_0 - p^*).\n$$\nWith the initial condition $p_0=1$, we get\n$$\np_3 = \\frac{3}{7} + \\left(1-\\frac{3}{7}\\right) \\left(-\\frac{1}{6}\\right)^3 = \\frac{3}{7} + \\frac{4}{7} \\left(-\\frac{1}{216}\\right) = \\frac{3}{7} - \\frac{1}{378} = \\frac{161}{378} = \\frac{23}{54}.\n$$\nTherefore, the probability that the robot is in the Living Room at time step $t=3$ is $\\frac{23}{54}$.", "answer": "$$\\boxed{\\frac{23}{54}}$$", "id": "1347922"}, {"introduction": "Many real-world processes evolve towards a terminal state—a project is completed, a patient recovers, or a component fails. This practice introduces the concept of \"absorbing states\" in a Markov chain, which represent these definitive outcomes. Using a hypothetical debugging process as our model, we will calculate the probability of the process concluding successfully within a given number of steps, a typical problem in reliability and project management. [@problem_id:1347992]", "problem": "A simplified model for a software developer's debugging process is described by four states:\n- State 1: Actively Debugging\n- State 2: Testing a Fix\n- State 3: Bug Fixed\n- State 4: Gave Up\n\nThe process is observed on an hourly basis, and the state of the system evolves as a stochastic process. The probabilities of transitioning between states in any given hour are as follows:\n\n- If the developer is in State 1 (Actively Debugging), in the next hour there is a 0.4 probability of remaining in State 1, a 0.5 probability of moving to State 2, and a 0.1 probability of moving to State 4. It is not possible to move directly from State 1 to State 3.\n- If the developer is in State 2 (Testing a Fix), the test resolves within the hour. There is a 0.65 probability that the fix is successful, moving the system to State 3. There is a 0.3 probability that the fix fails, causing a return to State 1. Finally, there is a 0.05 probability that the fix has catastrophic consequences, causing a move to State 4.\n- States 3 and 4 are absorbing states. Once the system enters either of these states, it remains there indefinitely.\n\nAssuming the developer starts in the 'Actively Debugging' state at time $t=0$, what is the probability that the bug is fixed on or before the end of the third hour (i.e., by time $t=3$)? Give your answer rounded to three significant figures.", "solution": "Let the states be indexed as $1,2,3,4$ with $3$ and $4$ absorbing. The one-step transition matrix $P$ is\n$$\nP=\\begin{pmatrix}\n0.4  0.5  0  0.1\\\\\n0.3  0  0.65  0.05\\\\\n0  0  1  0\\\\\n0  0  0  1\n\\end{pmatrix}.\n$$\nStarting in state $1$ at $t=0$, the initial distribution is\n$$\np_0 = \\begin{pmatrix}1  0  0  0\\end{pmatrix}.\n$$\nBy the Chapman–Kolmogorov equation, $p_{n+1}=p_{n}P$.\n\nFirst step:\n$$\np_1 = p_0 P = \\begin{pmatrix}0.4  0.5  0  0.1\\end{pmatrix}.\n$$\n\nSecond step: compute components via matrix multiplication,\n$$\np_{2,1} = 0.4 \\cdot 0.4 + 0.5 \\cdot 0.3 + 0 \\cdot 0 + 0.1 \\cdot 0 = 0.31,\n$$\n$$\np_{2,2} = 0.4 \\cdot 0.5 + 0.5 \\cdot 0 + 0 \\cdot 0 + 0.1 \\cdot 0 = 0.20,\n$$\n$$\np_{2,3} = 0.4 \\cdot 0 + 0.5 \\cdot 0.65 + 0 \\cdot 1 + 0.1 \\cdot 0 = 0.325,\n$$\n$$\np_{2,4} = 0.4 \\cdot 0.1 + 0.5 \\cdot 0.05 + 0 \\cdot 0 + 0.1 \\cdot 1 = 0.165,\n$$\nso\n$$\np_2 = \\begin{pmatrix}0.31  0.20  0.325  0.165\\end{pmatrix}.\n$$\n\nThird step:\n$$\np_{3,1} = 0.31 \\cdot 0.4 + 0.20 \\cdot 0.3 + 0.325 \\cdot 0 + 0.165 \\cdot 0 = 0.184,\n$$\n$$\np_{3,2} = 0.31 \\cdot 0.5 + 0.20 \\cdot 0 + 0.325 \\cdot 0 + 0.165 \\cdot 0 = 0.155,\n$$\n$$\np_{3,3} = 0.31 \\cdot 0 + 0.20 \\cdot 0.65 + 0.325 \\cdot 1 + 0.165 \\cdot 0 = 0.455,\n$$\n$$\np_{3,4} = 0.31 \\cdot 0.1 + 0.20 \\cdot 0.05 + 0.325 \\cdot 0 + 0.165 \\cdot 1 = 0.206,\n$$\nso\n$$\np_3 = \\begin{pmatrix}0.184  0.155  0.455  0.206\\end{pmatrix}.\n$$\n\nBecause state $3$ is absorbing, the probability that the bug is fixed on or before $t=3$ equals the probability of being in state $3$ at $t=3$, which is $p_{3,3}=0.455$. Rounding to three significant figures yields $0.455$.", "answer": "$$\\boxed{0.455}$$", "id": "1347992"}, {"introduction": "Beyond just predicting the future, the principles underlying the Chapman-Kolmogorov equations allow us to make inferences about the past. This fascinating practice flips our perspective: given a system's starting and ending states, what can we say about the path it took? You will calculate the probability of a system passing through a specific intermediate state, a type of analysis crucial for diagnostics and for reconstructing event sequences in fields like computational biology and finance. [@problem_id:1347986]", "problem": "A simplified biophysical model describes the state of a single ion channel in a neuron's membrane using a discrete-time Markov chain. The channel can exist in one of three distinct states at any given time step $n$: State 1 (Closed), State 2 (Open), and State 3 (Inactive). The transitions between these states from time step $n$ to $n+1$ are governed by the following one-step transition probability matrix $P$, where the element $P_{ij}$ represents the probability of transitioning from state $i$ to state $j$:\n\n$$\nP = \\begin{pmatrix} 0.6  0.3  0.1 \\\\ 0.2  0.6  0.2 \\\\ 0.1  0.4  0.5 \\end{pmatrix}\n$$\n\nLet $X_n$ denote the state of the ion channel at time step $n$. Suppose the channel is initially in the 'Closed' state (State 1) at time $n=0$. Later, at time $n=2$, an experiment reveals that the channel is in the 'Inactive' state (State 3). Given this information, what is the probability that the channel was in the 'Open' state (State 2) at the intermediate time step $n=1$?\n\nProvide your answer as a decimal rounded to four significant figures.", "solution": "We are given a time-homogeneous Markov chain with states 1 (Closed), 2 (Open), and 3 (Inactive), and transition matrix\n$$\nP=\\begin{pmatrix}\n0.6  0.3  0.1\\\\\n0.2  0.6  0.2\\\\\n0.1  0.4  0.5\n\\end{pmatrix}.\n$$\nWe seek the conditional probability $P(X_1=2 \\mid X_0=1, X_2=3)$.\n\nBy the definition of conditional probability,\n$$\nP(X_1=j \\mid X_0=1, X_2=3) = \\frac{P(X_0=1, X_1=j, X_2=3)}{\\sum_{s=1}^{3}P(X_0=1, X_1=s, X_2=3)}.\n$$\nUsing the Markov property and time-homogeneity,\n$$\nP(X_0=1, X_1=j, X_2=3) = P(X_0=1)\\,P(X_1=j \\mid X_0=1)\\,P(X_2=3 \\mid X_1=j) = P(X_0=1)\\,P_{1j}\\,P_{j3}.\n$$\nHence,\n$$\nP(X_1=j \\mid X_0=1, X_2=3) = \\frac{P_{1j}P_{j3}}{\\sum_{s=1}^{3}P_{1s}P_{s3}}.\n$$\nSetting $j=2$ gives\n$$\nP(X_1=2 \\mid X_0=1, X_2=3) = \\frac{P_{12}P_{23}}{P_{11}P_{13}+P_{12}P_{23}+P_{13}P_{33}}.\n$$\nFrom $P$, we have $P_{11}=0.6$, $P_{12}=0.3$, $P_{13}=0.1$, $P_{23}=0.2$, and $P_{33}=0.5$. Therefore,\n$$\n\\text{numerator} = P_{12}P_{23} = 0.3 \\times 0.2 = 0.06,\n$$\n$$\n\\text{denominator} = P_{11}P_{13} + P_{12}P_{23} + P_{13}P_{33} = 0.6 \\times 0.1 + 0.3 \\times 0.2 + 0.1 \\times 0.5 = 0.06 + 0.06 + 0.05 = 0.17.\n$$\nThus,\n$$\nP(X_1=2 \\mid X_0=1, X_2=3) = \\frac{0.06}{0.17} = \\frac{6}{17} \\approx 0.352941\\dots\n$$\nRounded to four significant figures, this is $0.3529$.", "answer": "$$\\boxed{0.3529}$$", "id": "1347986"}]}