{"hands_on_practices": [{"introduction": "Understanding stationary distributions begins with the simplest non-trivial case: a system with just two states. This exercise models a common scenario where an attribute, in this case, a token, is passed back and forth between two entities. By defining the states and transition probabilities, you will practice the fundamental skill of setting up and solving the core balance equations $\\pi P = \\pi$ to find the long-term behavior of the system.[@problem_id:1302643]", "problem": "In a turn-based digital game, two players, Alice and Bob, compete for control of a special token. The player who possesses the token at the beginning of a round is designated the \"active player\" for that round. The control of the token evolves according to the following probabilistic rules:\n\n- If Alice is the active player, she has a probability $p_A$ of retaining control of the token for the next round. If she fails to retain control, the token is passed to Bob.\n- If Bob is the active player, he has a probability $p_B$ of retaining control of the token for the next round. If he fails to retain control, the token is passed to Alice.\n\nThe outcomes of these events are independent from one round to the next. Assume the game has been running for an extremely large number of rounds and that the probabilities satisfy $0 < p_A < 1$ and $0 < p_B < 1$.\n\nDetermine the long-term fraction of rounds that Alice is the active player. Your answer should be a single closed-form analytic expression in terms of $p_A$ and $p_B$.", "solution": "Let the state of the system be determined by which player holds the token. We can define two states: State A, where Alice has the token, and State B, where Bob has the token. The long-term fraction of rounds that Alice is the active player corresponds to the stationary probability of being in State A in a Markov chain model of this game.\n\nLet $\\pi = (\\pi_A, \\pi_B)$ be the stationary distribution vector, where $\\pi_A$ is the long-term probability of being in State A and $\\pi_B$ is the long-term probability of being in State B. By definition, these probabilities must sum to one:\n$$ \\pi_A + \\pi_B = 1 $$\n\nNext, we construct the transition matrix $P$ for this two-state system. The entry $P_{ij}$ represents the probability of transitioning from state $i$ to state $j$ in one round.\n\nThe transitions from State A (Alice has the token) are:\n- The probability of staying in State A (Alice to Alice) is the probability that Alice retains control, so $P_{AA} = p_A$.\n- The probability of transitioning to State B (Alice to Bob) is the probability that Alice fails to retain control, so $P_{AB} = 1 - p_A$.\n\nThe transitions from State B (Bob has the token) are:\n- The probability of transitioning to State A (Bob to Alice) is the probability that Bob fails to retain control, so $P_{BA} = 1 - p_B$.\n- The probability of staying in State B (Bob to Bob) is the probability that Bob retains control, so $P_{BB} = p_B$.\n\nThe one-step transition matrix $P$ is therefore:\n$$ P = \\begin{pmatrix} P_{AA} & P_{AB} \\\\ P_{BA} & P_{BB} \\end{pmatrix} = \\begin{pmatrix} p_A & 1 - p_A \\\\ 1 - p_B & p_B \\end{pmatrix} $$\n\nThe stationary distribution $\\pi$ must satisfy the equation $\\pi P = \\pi$.\n$$ (\\pi_A, \\pi_B) \\begin{pmatrix} p_A & 1 - p_A \\\\ 1 - p_B & p_B \\end{pmatrix} = (\\pi_A, \\pi_B) $$\n\nThis matrix equation yields a system of two linear equations:\n1. $\\pi_A p_A + \\pi_B (1 - p_B) = \\pi_A$\n2. $\\pi_A (1 - p_A) + \\pi_B p_B = \\pi_B$\n\nThese two equations are linearly dependent. We can use either one, along with the normalization condition $\\pi_A + \\pi_B = 1$, to solve for $\\pi_A$ and $\\pi_B$. Let's use the first equation.\n\nFrom $\\pi_A p_A + \\pi_B (1 - p_B) = \\pi_A$, we can rearrange the terms:\n$$ \\pi_B (1 - p_B) = \\pi_A - \\pi_A p_A $$\n$$ \\pi_B (1 - p_B) = \\pi_A (1 - p_A) $$\n\nNow, substitute $\\pi_B = 1 - \\pi_A$ into this equation:\n$$ (1 - \\pi_A)(1 - p_B) = \\pi_A (1 - p_A) $$\n\nWe expand both sides to solve for $\\pi_A$:\n$$ 1 - p_B - \\pi_A + \\pi_A p_B = \\pi_A - \\pi_A p_A $$\n\nGather all terms involving $\\pi_A$ on one side and constant terms on the other:\n$$ 1 - p_B = \\pi_A - \\pi_A p_A + \\pi_A - \\pi_A p_B $$\n$$ 1 - p_B = \\pi_A (1 - p_A + 1 - p_B) $$\n$$ 1 - p_B = \\pi_A (2 - p_A - p_B) $$\n\nFinally, we isolate $\\pi_A$:\n$$ \\pi_A = \\frac{1 - p_B}{2 - p_A - p_B} $$\nThis expression gives the long-term fraction of rounds that Alice is the active player. The denominator $2-p_A-p_B = (1-p_A) + (1-p_B)$ is the sum of the off-diagonal elements, which is guaranteed to be non-zero since $0 < p_A < 1$ and $0 < p_B < 1$.", "answer": "$$\\boxed{\\frac{1 - p_B}{2 - p_A - p_B}}$$", "id": "1302643"}, {"introduction": "Moving from two states to a slightly larger system allows us to explore more intricate dynamics and uncover surprising structural properties. This problem involves a token on a circular board with four states, where the movement rules introduce a degree of asymmetry. Solving for the stationary distribution here not only reinforces your algebraic skills but also reveals how the underlying connectivity of a state space can lead to an elegant, uniform distribution, a common feature in regular, strongly connected structures.[@problem_id:1302614]", "problem": "A token moves on a circular board with four spaces, labeled 1, 2, 3, and 4 in clockwise order. The state of the system is the current space occupied by the token. From any given space, the token has two possible moves on each turn: it can move one space clockwise with probability $p = 1/3$, or it can move two spaces clockwise with probability $1-p = 2/3$. For instance, if the token is on space 1, it will move to space 2 with probability $1/3$ or to space 3 with probability $2/3$. This process defines a discrete-time Markov chain.\n\nAssuming the process has been running for a very long time and has reached a steady state, what is the probability that the token is located on an odd-numbered space (i.e., either space 1 or space 3)?\n\nExpress your answer as an exact fraction in simplest form.", "solution": "Let the state space of the Markov chain be $S = \\{1, 2, 3, 4\\}$, corresponding to the four spaces on the board. The problem describes the transition probabilities. We can represent these transitions with a transition matrix $P$, where the entry $P_{ij}$ is the probability of moving from state $i$ to state $j$.\n\nThe rules for movement are:\n- From state 1: move to 2 with probability $p$, or to 3 with probability $1-p$.\n- From state 2: move to 3 with probability $p$, or to 4 with probability $1-p$.\n- From state 3: move to 4 with probability $p$, or to 1 (wrapping around) with probability $1-p$.\n- From state 4: move to 1 with probability $p$, or to 2 with probability $1-p$.\n\nThe transition matrix $P$ is therefore:\n$$\nP = \\begin{pmatrix}\n0 & p & 1-p & 0 \\\\\n0 & 0 & p & 1-p \\\\\n1-p & 0 & 0 & p \\\\\np & 1-p & 0 & 0\n\\end{pmatrix}\n$$\n\nThe phrase \"after a very long time\" implies that we are looking for the stationary distribution of the Markov chain. The stationary distribution is a probability vector $\\pi = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$ that satisfies the equation $\\pi P = \\pi$, subject to the condition that the components sum to one: $\\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1$. The component $\\pi_i$ represents the long-run probability of being in state $i$.\n\nThe equation $\\pi P = \\pi$ gives the following system of linear equations:\n1. $\\pi_1 = (1-p) \\pi_3 + p \\pi_4$\n2. $\\pi_2 = p \\pi_1 + (1-p) \\pi_4$\n3. $\\pi_3 = (1-p) \\pi_1 + p \\pi_2$\n4. $\\pi_4 = (1-p) \\pi_2 + p \\pi_3$\n5. $\\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1$\n\nThis is a system of five equations for four unknowns. One of the first four equations is redundant. Let's solve this system. We can use algebraic substitution.\n\nFrom equation (3), we have $\\pi_3 = (1-p)\\pi_1 + p\\pi_2$.\nSubstitute this into equation (4):\n$\\pi_4 = (1-p)\\pi_2 + p((1-p)\\pi_1 + p\\pi_2) = p(1-p)\\pi_1 + (1-p+p^2)\\pi_2$.\n\nNow substitute the expressions for $\\pi_3$ and $\\pi_4$ into equation (1):\n$\\pi_1 = (1-p)((1-p)\\pi_1 + p\\pi_2) + p(p(1-p)\\pi_1 + (1-p+p^2)\\pi_2)$\n$\\pi_1 = (1-p)^2 \\pi_1 + p(1-p)\\pi_2 + p^2(1-p)\\pi_1 + p(1-p+p^2)\\pi_2$\nGroup terms with $\\pi_1$ and $\\pi_2$:\n$\\pi_1 (1 - (1-p)^2 - p^2(1-p)) = \\pi_2 (p(1-p) + p(1-p+p^2))$\n$\\pi_1 (1 - (1-2p+p^2) - p^2+p^3) = \\pi_2 (p-p^2 + p-p^2+p^3)$\n$\\pi_1 (2p - 2p^2 + p^3) = \\pi_2 (2p - 2p^2 + p^3)$\n$\\pi_1 p(2 - 2p + p^2) = \\pi_2 p(2 - 2p + p^2)$\n\nFor $p \\in (0,1)$, the term $p(2-2p+p^2)$ is non-zero (since $p^2-2p+2 = (p-1)^2+1 > 0$), so we can divide by it, which gives $\\pi_1 = \\pi_2$.\n\nNow that we know $\\pi_1 = \\pi_2$, let's re-examine the original equations.\nFrom eq (3): $\\pi_3 = (1-p)\\pi_1 + p\\pi_2 = (1-p)\\pi_1 + p\\pi_1 = \\pi_1$.\nSo, $\\pi_3 = \\pi_1$.\nFrom eq (4): $\\pi_4 = (1-p)\\pi_2 + p\\pi_3 = (1-p)\\pi_1 + p\\pi_1 = \\pi_1$.\nSo, $\\pi_4 = \\pi_1$.\n\nThis means all components of the stationary distribution are equal: $\\pi_1 = \\pi_2 = \\pi_3 = \\pi_4$.\nUsing the normalization condition (5):\n$\\pi_1 + \\pi_1 + \\pi_1 + \\pi_1 = 1$\n$4\\pi_1 = 1$\n$\\pi_1 = 1/4$.\n\nTherefore, the stationary distribution is $\\pi = (1/4, 1/4, 1/4, 1/4)$.\nThis result is independent of the value of $p$ (as long as $0 < p < 1$, which is true for $p=1/3$).\n\nThe problem asks for the probability that the token is on an odd-numbered space, which is the sum of the probabilities of being on space 1 or space 3.\n$P(\\text{odd space}) = \\pi_1 + \\pi_3$\n$P(\\text{odd space}) = 1/4 + 1/4 = 2/4 = 1/2$.\nThe specific value $p=1/3$ is not needed to find the final answer.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1302614"}, {"introduction": "What happens when a system has a vast number of states, making the direct solution of balance equations computationally impossible? This challenge moves us beyond brute-force calculation and into the realm of conceptual problem-solving. By analyzing a process on an $n$-dimensional hypercube, you will learn to exploit the system's structural properties to guess and verify a \"product-form\" stationary distribution using the principle of detailed balance, a powerful technique essential for analyzing complex, high-dimensional networks.[@problem_id:1302650]", "problem": "Consider a model for a dynamic network consisting of $n$ interconnected nodes. The state of the entire network is described by a binary string of length $n$, $(s_1, s_2, \\dots, s_n)$ where $s_i \\in \\{0, 1\\}$, which can be visualized as a vertex on an $n$-dimensional hypercube. The network evolves in discrete time steps according to the following stochastic rule: at each time step, one of the $n$ nodes is chosen uniformly at random. If the chosen node is in state 0, it transitions to state 1 with a probability $p$. If the chosen node is in state 1, it transitions to state 0 with a probability $q$. If a transition does not occur (for instance, a node in state 0 is chosen but the flip does not happen), the node's state remains unchanged for that step.\n\nSuppose the system has $n=8$ nodes, with transition probabilities $p = 2/3$ and $q = 1/2$. After a very long time, the system approaches an equilibrium probability distribution over the $2^8$ possible states. Determine the equilibrium probability of the specific network state described by the binary string $v = (1, 1, 0, 0, 1, 1, 0, 0)$.\n\nExpress your answer as a single simplified fraction of integers.", "solution": "Let $n$ be the number of nodes and let $s=(s_{1},\\dots,s_{n})\\in\\{0,1\\}^{n}$ denote a network state. For $i\\in\\{1,\\dots,n\\}$, let $s^{(i)}$ be the configuration obtained by flipping only the $i$th bit of $s$. The Markov chain on configurations updates by selecting one coordinate uniformly at random and possibly flipping it: if $s_{i}=0$ then $P(s\\to s^{(i)})=\\frac{1}{n}p$, and if $s_{i}=1$ then $P(s\\to s^{(i)})=\\frac{1}{n}q$. Otherwise the state remains unchanged.\n\nWe look for a stationary distribution $\\mu$ satisfying detailed balance on each edge of the hypercube. Consider the ansatz\n$$\n\\mu(s)=\\frac{1}{Z}\\,r^{k(s)},\\quad r=\\frac{p}{q},\\quad k(s)=\\sum_{i=1}^{n}s_{i},\n$$\nwhere $Z$ is the normalizing constant. If $s_{i}=0$, then $k(s^{(i)})=k(s)+1$ so that\n$$\n\\frac{\\mu(s^{(i)})}{\\mu(s)}=\\frac{p}{q}.\n$$\nDetailed balance for the pair $(s,s^{(i)})$ requires\n$$\n\\mu(s)P(s\\to s^{(i)})=\\mu(s^{(i)})P(s^{(i)}\\to s).\n$$\nUsing $P(s\\to s^{(i)})=\\frac{1}{n}p$ and $P(s^{(i)}\\to s)=\\frac{1}{n}q$ (since then $s^{(i)}_{i}=1$), we have\n$$\n\\mu(s)\\frac{1}{n}p=\\mu(s^{(i)})\\frac{1}{n}q,\n$$\nwhich holds exactly because $\\mu(s^{(i)})/\\mu(s)=p/q$. The case $s_{i}=1$ is symmetric. Hence $\\mu$ satisfies detailed balance and is stationary.\n\nTo normalize, note that\n$$\nZ=\\sum_{s\\in\\{0,1\\}^{n}}r^{k(s)}=\\sum_{k=0}^{n}\\binom{n}{k}r^{k}=(1+r)^{n}=\\left(1+\\frac{p}{q}\\right)^{n}=\\left(\\frac{p+q}{q}\\right)^{n}.\n$$\nTherefore,\n$$\n\\mu(s)=\\frac{\\left(\\frac{p}{q}\\right)^{k(s)}}{\\left(1+\\frac{p}{q}\\right)^{n}}=\\left(\\frac{p}{p+q}\\right)^{k(s)}\\left(\\frac{q}{p+q}\\right)^{n-k(s)}.\n$$\nThus the equilibrium distribution is a product of independent Bernoulli variables with $\\Pr\\{s_{i}=1\\}=\\frac{p}{p+q}$.\n\nFor the given data, $n=8$, $p=\\frac{2}{3}$, $q=\\frac{1}{2}$, and the specific state $v=(1,1,0,0,1,1,0,0)$ has $k(v)=4$ ones. Compute\n$$\n\\frac{p}{p+q}=\\frac{\\frac{2}{3}}{\\frac{2}{3}+\\frac{1}{2}}=\\frac{\\frac{2}{3}}{\\frac{7}{6}}=\\frac{4}{7},\\qquad \\frac{q}{p+q}=\\frac{\\frac{1}{2}}{\\frac{7}{6}}=\\frac{3}{7}.\n$$\nHence\n$$\n\\mu(v)=\\left(\\frac{4}{7}\\right)^{4}\\left(\\frac{3}{7}\\right)^{4}=\\frac{4^{4}\\cdot 3^{4}}{7^{8}}=\\frac{20736}{5764801}.\n$$\nThis fraction is already in lowest terms.", "answer": "$$\\boxed{\\frac{20736}{5764801}}$$", "id": "1302650"}]}