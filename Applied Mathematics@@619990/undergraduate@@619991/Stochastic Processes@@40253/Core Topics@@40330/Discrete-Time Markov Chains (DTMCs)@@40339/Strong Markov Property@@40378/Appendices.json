{"hands_on_practices": [{"introduction": "The Strong Markov Property extends the memoryless nature of Markov processes to certain random times, known as stopping times. This initial exercise provides a classic, intuitive demonstration within the context of a discrete random walk. By analyzing a particle's future path after it reaches a specific state for the second time, you will see how the process effectively \"restarts,\" making its complex past history irrelevant for future predictions [@problem_id:1335461].", "problem": "A particle performs a simple symmetric random walk on the integers. Starting from position $X_0 = 0$, at each discrete time step, the particle moves one unit to the right with probability $1/2$ or one unit to the left with probability $1/2$. We denote the position of the particle after $n$ steps as $X_n$.\n\nSuppose the walk has been running for some time, and we observe that the particle has just arrived at position $+2$ for the second time. That is, there was a first time step $n_1 > 0$ such that $X_{n_1} = 2$, and at a later time step $n_2 > n_1$, we have $X_{n_2} = 2$, with the particle not having been at $+2$ at any time between $n_1$ and $n_2$.\n\nGiven that the particle is at position $+2$ at this exact moment (time $n_2$), what is the probability that it will reach position $+3$ before it reaches position $0$? Express your answer as an exact fraction.", "solution": "We model the simple symmetric random walk $\\{X_{n}\\}_{n \\geq 0}$ on $\\mathbb{Z}$ with $X_{0}=0$ and step increments $\\pm 1$ equiprobably. We are told that the walk has just arrived at $+2$ for the second time; denote this time by $n_{2}$, so $X_{n_{2}}=2$, and there was a previous time $n_{1}<n_{2}$ with $X_{n_{1}}=2$, with no visits to $2$ in between.\n\nWe seek the probability, given the information up to time $n_{2}$ and $X_{n_{2}}=2$, that the walk hits $+3$ before it hits $0$. By the (strong) Markov property, the future evolution of the Markov chain after time $n_{2}$, conditional on the present state $X_{n_{2}}=2$, is independent of the past event that this is the second visit. Therefore,\n$$\n\\mathbb{P}\\left(\\text{hit }3\\text{ before }0 \\,\\middle|\\, X_{n_{2}}=2,\\ \\text{second visit to }2\\right)\n=\n\\mathbb{P}\\left(\\text{hit }3\\text{ before }0 \\,\\middle|\\, X_{n_{2}}=2\\right).\n$$\nThus it suffices to compute $h(2)$, where for $x \\in \\{0,1,2,3\\}$ we define\n$$\nh(x) = \\mathbb{P}_{x}\\left(\\tau_{3}<\\tau_{0}\\right),\n$$\nwith $\\tau_{a}=\\inf\\{n\\geq 0: X_{n}=a\\}$ the hitting time of $a$. For the simple symmetric random walk, $h$ satisfies the discrete harmonic equation on interior points with absorbing boundary conditions:\n$$\nh(0)=0,\\quad h(3)=1,\\quad h(x)=\\tfrac{1}{2}h(x-1)+\\tfrac{1}{2}h(x+1)\\ \\text{for }x=1,2.\n$$\nThe interior equation implies $h(x+1)-h(x)=h(x)-h(x-1)$, so $h$ is linear: $h(x)=ax+b$. Using the boundary conditions gives $b=h(0)=0$ and $h(3)=1$ implies $3a=1$, hence $a=\\frac{1}{3}$. Therefore,\n$$\nh(2)=\\frac{2}{3}.\n$$\nThis value is exactly the desired probability.", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "1335461"}, {"introduction": "Building on the discrete random walk, we now explore the Strong Markov Property in a continuous-time setting with a Poisson process. This problem introduces a more sophisticated stopping time, defined by the interval between consecutive events. This practice will reinforce your understanding of the \"restart\" principle, showing how it simplifies calculations by allowing us to treat the process from a random observation point as if it were a brand new process [@problem_id:1335460].", "problem": "Consider a stream of events that occur according to a Poisson process with a constant rate $\\lambda > 0$. Let the times of the events be denoted by $T_1, T_2, T_3, \\dots$, where $0 < T_1 < T_2 < \\dots$. We define a specific moment in time, which we'll call the \"trigger time\" $\\mathcal{T}$. The trigger time $\\mathcal{T}$ is defined as the time of the first event that occurs less than $\\delta$ seconds after its immediately preceding event, where $\\delta$ is a fixed positive constant.\n\nSpecifically, let $X_n = T_n - T_{n-1}$ for $n \\ge 1$ be the inter-arrival time between the $(n-1)$-th and $n$-th events (with $T_0=0$). The trigger time is then $\\mathcal{T} = T_k$, where $k$ is the smallest integer index such that $X_k < \\delta$.\n\nWhat is the expected value of the time duration from the trigger time $\\mathcal{T}$ until the very next event occurs? Express your answer in terms of the given parameters $\\lambda$ and $\\delta$, if necessary.", "solution": "Let $\\{X_{n}\\}_{n \\geq 1}$ be the inter-arrival times of the Poisson process with rate $\\lambda$, so $X_{n} \\sim \\text{Exp}(\\lambda)$ are independent and identically distributed with density $f_{X}(x) = \\lambda \\exp(-\\lambda x)$ for $x \\geq 0$. Define the stopping index $k = \\min\\{n \\geq 1 : X_{n} < \\delta\\}$, which is almost surely finite because $\\mathbb{P}(X_{1} < \\delta) = 1 - \\exp(-\\lambda \\delta) > 0$.\n\nThe trigger time is $\\mathcal{T} = T_{k}$, and the time from the trigger to the next event is\n$$\nW = T_{k+1} - T_{k} = X_{k+1}.\n$$\nLet $\\mathcal{F}_{k} = \\sigma(X_{1}, \\dots, X_{k})$. Since the $X_{n}$ are independent and $k$ is an $\\{\\mathcal{F}_{n}\\}$-stopping time, $X_{k+1}$ is independent of $\\mathcal{F}_{k}$ and has the same distribution as $X_{1}$; equivalently, by the strong Markov property of the Poisson process, the post-$\\mathcal{T}$ process is a fresh Poisson process of rate $\\lambda$, independent of the past. Therefore, for all $t \\geq 0$,\n$$\n\\mathbb{P}(W > t \\mid \\mathcal{F}_{k}) = \\exp(-\\lambda t),\n$$\nso $W \\mid \\mathcal{F}_{k} \\sim \\text{Exp}(\\lambda)$. Hence\n$$\n\\mathbb{E}[W \\mid \\mathcal{F}_{k}] = \\int_{0}^{\\infty} \\mathbb{P}(W > t \\mid \\mathcal{F}_{k}) \\, dt = \\int_{0}^{\\infty} \\exp(-\\lambda t) \\, dt = \\frac{1}{\\lambda}.\n$$\nTaking expectations gives\n$$\n\\mathbb{E}[W] = \\mathbb{E}\\big[\\mathbb{E}[W \\mid \\mathcal{F}_{k}]\\big] = \\frac{1}{\\lambda}.\n$$\nThus, the expected time from the trigger time to the next event is independent of $\\delta$ and equals $\\frac{1}{\\lambda}$.", "answer": "$$\\boxed{\\frac{1}{\\lambda}}$$", "id": "1335460"}, {"introduction": "Our previous practices demonstrated the power of the Strong Markov Property, but its use is conditional on the random time being a valid \"stopping time\". This final exercise shifts from calculation to a crucial conceptual check, asking you to determine if a complex, path-dependent time in a financial model qualifies as a stopping time. Mastering this concept is essential for correctly applying the Strong Markov Property in advanced, real-world scenarios, particularly in fields like quantitative finance [@problem_id:1335471].", "problem": "A financial analyst models the price of a non-dividend-paying stock, $S_t$ at time $t \\ge 0$, using a Geometric Brownian Motion (GBM). This model is described by the stochastic differential equation $dS_t = \\mu S_t dt + \\sigma S_t dW_t$, where $\\mu$ and $\\sigma$ are constants representing the drift and volatility, respectively, and $W_t$ is a standard Wiener process. The initial stock price is $S_0 > 0$.\n\nLet $M_t = \\max_{0 \\le u \\le t} S_u$ be the running maximum price of the stock and $m_t = \\min_{0 \\le u \\le t} S_u$ be the running minimum price up to time $t$. The analyst is interested in a specific random time $T$, defined as the first instant the stock price is exactly at the arithmetic mean of its running maximum and running minimum up to that point. Mathematically, this time is given by:\n$$T = \\inf\\left\\{t > 0 : S_t = \\frac{M_t + m_t}{2}\\right\\}$$\nAssuming that such a time $T$ exists and is finite with a positive probability, can the Strong Markov Property be used to analyze the future evolution of the stock price from time $T$?\n\nSelect the best explanation from the choices below.\n\nA. Yes, because any randomly defined time based on the process path is a stopping time for which the Strong Markov property holds.\n\nB. Yes, because the determination of whether $T$ has occurred by any specific time $t$ can be made solely by observing the stock's price history up to time $t$.\n\nC. No, because determining the running maximum $M_t$ and minimum $m_t$ requires knowledge of the stock's price path beyond time $t$, which violates the definition of a stopping time.\n\nD. No, because the condition $S_t = (M_t + m_t)/2$ depends on the entire past history of the process, which violates the memoryless property that is fundamental to all Markov processes.\n\nE. No, because the running maximum and minimum processes, $M_t$ and $m_t$, are not themselves Markovian, so properties related to them cannot be used to restart the process.", "solution": "Let $\\{\\mathcal{F}_{t}\\}_{t \\ge 0}$ be the natural filtration of $S$, that is, $\\mathcal{F}_{t} = \\sigma(S_{u}: 0 \\le u \\le t)$ augmented in the usual way. The processes $M_{t} = \\sup_{0 \\le u \\le t} S_{u}$ and $m_{t} = \\inf_{0 \\le u \\le t} S_{u}$ are $\\mathcal{F}_{t}$-measurable since they are measurable functionals of the path up to time $t$. Because $S$ has continuous sample paths (solutions to $dS_{t} = \\mu S_{t} dt + \\sigma S_{t} dW_{t}$ are continuous), both $M_{t}$ and $m_{t}$ are continuous adapted processes.\n\nDefine the adapted continuous process\n$$\nX_{t} := S_{t} - \\frac{M_{t} + m_{t}}{2}.\n$$\nThen the random time\n$$\nT := \\inf\\{t > 0 : X_{t} = 0\\}\n$$\nis the first hitting time of the closed set $\\{0\\}$ by the continuous adapted process $X$. By the standard hitting-time theorem, for a continuous adapted process, the first time it hits a closed set is a stopping time with respect to $\\{\\mathcal{F}_{t}\\}$.\n\nEquivalently, for each fixed $t \\ge 0$, the event $\\{T \\le t\\}$ is determined by the path $\\{S_{u}: 0 \\le u \\le t\\}$ alone, since $M_{u}$ and $m_{u}$ depend only on $\\{S_{v}: 0 \\le v \\le u\\}$ with $u \\le t$. Hence $\\{T \\le t\\} \\in \\mathcal{F}_{t}$, so $T$ is a stopping time.\n\nSince $S$ is the (strong) solution of an SDE with Lipschitz and linear-growth coefficients driven by Brownian motion, $S$ is a strong Markov process. Therefore, by the Strong Markov Property, for the stopping time $T$, on the event $\\{T < \\infty\\}$, the post-$T$ process $\\{S_{T+t}: t \\ge 0\\}$ has the same law as a GBM started at $S_{T}$ and driven by the Brownian increments $\\{W_{T+t} - W_{T}: t \\ge 0\\}$, which are independent of $\\mathcal{F}_{T}$. Thus the Strong Markov Property can be used to analyze the future evolution of $S$ from time $T$.\n\nAmong the choices, this corresponds to recognizing that one can decide whether $T$ has occurred by time $t$ using only the path up to $t$, which is the definition of a stopping time. Therefore the correct justification is that the criterion is observable from the past, not that every path-defined time is a stopping time.", "answer": "$$\\boxed{B}$$", "id": "1335471"}]}