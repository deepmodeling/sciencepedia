{"hands_on_practices": [{"introduction": "To truly understand what makes a system ergodic, it is often helpful to first study a system that is not. This first practice explores a random walk on a specially structured network known as a complete bipartite graph [@problem_id:1299368]. By analyzing the particle's movement, you will discover the property of periodicity, a key characteristic that prevents a state from being aperiodic and, consequently, from being ergodic.", "problem": "Consider a system with six locations, divided into two groups: Group A, containing locations $\\{A_1, A_2, A_3\\}$, and Group B, containing locations $\\{B_1, B_2, B_3\\}$. A particle performs a random walk on these locations. The connections are such that every location in Group A is connected to every location in Group B, and there are no connections between locations within the same group. This structure forms a complete bipartite graph, denoted $K_{3,3}$.\n\nAt each discrete time step, the particle, currently at a specific location, moves to one of its connected (adjacent) locations. The choice of the next location is uniformly random among all available connections. For example, from location $A_1$, the particle can move to $B_1$, $B_2$, or $B_3$, each with equal probability.\n\nLet the location of the particle be the state of a Markov chain. Consider the state corresponding to the particle being at location $A_1$. Which one of the following statements correctly describes this state?\n\nA. The state is ergodic.\n\nB. The state is transient.\n\nC. The state is periodic with period 2.\n\nD. The state is absorbing.\n\nE. The state is periodic with period 3.", "solution": "We model the random walk on the complete bipartite graph $K_{3,3}$ with vertex set partitioned into $A=\\{A_{1},A_{2},A_{3}\\}$ and $B=\\{B_{1},B_{2},B_{3}\\}$. From any $a\\in A$, the particle moves to any $b\\in B$ with probability $\\frac{1}{3}$, and similarly from any $b\\in B$ to any $a\\in A$ with probability $\\frac{1}{3}$. There are no transitions within $A$ or within $B$. Thus, for $a,a'\\in A$ and $b,b'\\in B$,\n$$\nP(a,b)=\\frac{1}{3},\\quad P(b,a)=\\frac{1}{3},\\quad P(a,a')=0,\\quad P(b,b')=0.\n$$\n\nFirst, the chain is irreducible because from any state one can reach any other in at most two steps; for example, from $A_{1}$ to any $A_{i}$ via some $B_{j}$. Since the state space is finite and the chain is irreducible, every state is positive recurrent. Therefore, the state $A_{1}$ is not transient, ruling out option B.\n\nNext, $A_{1}$ is not absorbing because $P(A_{1},A_{1})=0$, ruling out option D.\n\nTo determine periodicity, recall the period of a state $i$ is\n$$\nd(i)=\\gcd\\{n\\ge 1: P^{n}(i,i)>0\\}.\n$$\nBecause the graph is bipartite, each step alternates between $A$ and $B$. Starting at $A_{1}$, after an odd number of steps the chain is in $B$, and after an even number of steps it is in $A$. Hence for all odd $n$,\n$$\nP^{n}(A_{1},A_{1})=0.\n$$\nThere is a return in two steps:\n$$\nP^{2}(A_{1},A_{1})=\\sum_{j=1}^{3}P(A_{1},B_{j})P(B_{j},A_{1})=\\sum_{j=1}^{3}\\left(\\frac{1}{3}\\cdot\\frac{1}{3}\\right)=\\frac{1}{3}>0.\n$$\nThere is also a return in four steps, for example along the path $A_{1}\\to B_{1}\\to A_{2}\\to B_{2}\\to A_{1}$, giving\n$$\nP^{4}(A_{1},A_{1})\\ge \\left(\\frac{1}{3}\\right)^{4}>0.\n$$\nThus the set $\\{n\\ge 1: P^{n}(A_{1},A_{1})>0\\}$ contains $2$ and $4$ and no odd integers, so its greatest common divisor is $2$. Therefore, the period of $A_{1}$ is $2$. The chain being periodic implies the state is not aperiodic and hence not ergodic in the sense of positive recurrent and aperiodic. Option E (period $3$) is false.\n\nTherefore, the correct description is that the state is periodic with period $2$.", "answer": "$$\\boxed{C}$$", "id": "1299368"}, {"introduction": "Once a system is confirmed to be ergodic, we can unlock its most powerful feature: the ability to predict its long-term behavior through a unique stationary distribution. This exercise focuses on a random walk on a \"lollipop\" graph, a classic network structure that is indeed ergodic [@problem_id:1299394]. You will apply a fundamental theorem connecting a state's long-run probability, $\\pi_{i}$, to its number of connections (its degree, $\\deg(i)$), providing a surprisingly elegant method for solving what might seem like a complex problem.", "problem": "A particle performs a random walk on a small network of four locations, labeled 1, 2, 3, and 4. The network is structured as follows: locations 1, 2, and 3 are connected to form a triangle, meaning each is connected to the other two. Location 4 is connected only to location 3.\n\nAt each discrete time step, the particle, currently at one location, must move to one of its connected neighbors. The choice of neighbor is uniformly random. For example, if a location has $k$ neighbors, the probability of moving to any specific one of its neighbors is $1/k$.\n\nThis random walk can be modeled as a discrete-time Markov chain on the state space $S = \\{1, 2, 3, 4\\}$. Over a long period, the system settles into a steady state, characterized by a stationary distribution which gives the probability of finding the particle at each location.\n\nCalculate the stationary probability of finding the particle at location 3. Express your answer as an exact fraction.", "solution": "Let $S=\\{1,2,3,4\\}$. The random walk is a discrete-time Markov chain with transition probabilities given by\n$$\nP_{ij}=\\begin{cases}\n\\frac{1}{\\deg(i)}, & \\text{if } i\\text{ and }j\\text{ are connected by an edge},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\nA stationary distribution $\\pi=(\\pi_{1},\\pi_{2},\\pi_{3},\\pi_{4})$ satisfies the defining equations\n$$\n\\pi=\\pi P,\\qquad \\sum_{i\\in S}\\pi_{i}=1,\\qquad \\pi_{i}\\ge 0.\n$$\nFor a random walk on a finite, connected, undirected graph, a standard reversible measure is\n$$\n\\pi_{i}=\\frac{\\deg(i)}{\\sum_{k\\in S}\\deg(k)}.\n$$\nTo verify stationarity, check detailed balance for all $i,j\\in S$:\n$$\n\\pi_{i}P_{ij}=\\frac{\\deg(i)}{\\sum_{k}\\deg(k)}\\cdot\\frac{A_{ij}}{\\deg(i)}=\\frac{A_{ij}}{\\sum_{k}\\deg(k)}=\\frac{A_{ji}}{\\sum_{k}\\deg(k)}=\\pi_{j}P_{ji},\n$$\nwhere $A_{ij}$ is the adjacency indicator. Thus $\\pi$ is stationary.\n\nCompute the degrees from the graph:\n- Nodes 1 and 2 have degrees $\\deg(1)=2$ and $\\deg(2)=2$. Node 3 is connected to nodes 1, 2, and 4, so its degree is $\\deg(3)=3$.\n- Node 4 connects only to node 3, so $\\deg(4)=1$.\n\nTherefore,\n$$\n\\sum_{k\\in S}\\deg(k)=\\deg(1)+\\deg(2)+\\deg(3)+\\deg(4)=2+2+3+1=8.\n$$\nHence the stationary probability at location $3$ is\n$$\n\\pi_{3}=\\frac{\\deg(3)}{\\sum_{k}\\deg(k)}=\\frac{3}{8}.\n$$", "answer": "$$\\boxed{\\frac{3}{8}}$$", "id": "1299394"}, {"introduction": "The principles of ergodicity extend far beyond simple graph walks into fields like game theory and adaptive systems. This final practice challenges you to model a game of Rock-Paper-Scissors where one player uses a strategy with a built-in \"noise\" factor, represented by the parameter $\\epsilon$ [@problem_id:1299380]. Your task is to construct the transition matrix from these rules and solve for the long-run probabilities as an expression of $\\epsilon$, demonstrating how this small amount of randomness ensures the system is ergodic and how its steady state depends critically on the system's parameters.", "problem": "Consider a repeated game of Rock-Paper-Scissors between two players. Player 1 is predictable and always chooses 'Rock'. Player 2 employs a more complex, adaptive strategy influenced by random noise. Let Player 2's action on any turn be one of {Rock, Paper, Scissors}.\n\nPlayer 2's strategy is defined as follows:\nOn each turn, Player 2's action is determined by a probabilistic rule. With probability $1-\\epsilon$, Player 2 follows a \"base strategy\". With probability $\\epsilon$, Player 2 disregards the base strategy and instead chooses one of the three actions {Rock, Paper, Scissors} uniformly at random (i.e., with probability $1/3$ for each).\n\nThe base strategy is a \"win-stay, lose-or-draw-shift\" rule based on the outcome of the previous turn against Player 1's 'Rock':\n- **Win-stay**: If Player 2 won the previous turn, their base action is to play the same action again.\n- **Lose-or-draw-shift**: If Player 2 lost or drew on the previous turn, their base action is to randomly choose one of the other two actions, each with a probability of $1/2$.\n\nAssume the noise parameter $\\epsilon$ is a constant satisfying $0  \\epsilon  3/2$.\n\nDetermine the long-run proportion of time that Player 2 chooses the 'Paper' action. Express your answer as a symbolic expression in terms of $\\epsilon$.", "solution": "Label Player 2’s current action by the Markov state set $\\{R,P,S\\}$. Against Player 1’s fixed $R$, the base rule is:\n- From $P$ (win): stay at $P$ with probability $1$.\n- From $R$ (draw): switch uniformly to one of the other two actions, i.e., to $P$ or $S$ with probability $\\frac{1}{2}$ each.\n- From $S$ (loss): switch uniformly to one of the other two actions, i.e., to $R$ or $P$ with probability $\\frac{1}{2}$ each.\n\nThus the base transition matrix $T_{0}$ (rows are current state, columns are next state) is\n$$\nT_{0}=\\begin{pmatrix}\n0  \\frac{1}{2}  \\frac{1}{2}\\\\\n0  1  0\\\\\n\\frac{1}{2}  \\frac{1}{2}  0\n\\end{pmatrix}.\n$$\nWith probability $\\epsilon$, Player 2 ignores the base rule and plays uniformly at random; let $J$ be the $3\\times 3$ matrix with every row equal to $\\left(\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right)$. The overall transition matrix is\n$$\nT=(1-\\epsilon)T_{0}+\\epsilon J.\n$$\nLet the stationary distribution be $\\pi=(r,p,s)$ for $(R,P,S)$. Stationarity gives\n$$\n\\pi=\\pi T=(1-\\epsilon)\\,\\pi T_{0}+\\epsilon\\left(\\tfrac{1}{3},\\tfrac{1}{3},\\tfrac{1}{3}\\right),\n$$\nbecause $\\pi J=\\left(\\tfrac{1}{3},\\tfrac{1}{3},\\tfrac{1}{3}\\right)$. Compute $\\pi T_{0}$:\n$$\n\\pi T_{0}\n= r\\,(0,\\tfrac{1}{2},\\tfrac{1}{2})+p\\,(0,1,0)+s\\,(\\tfrac{1}{2},\\tfrac{1}{2},0)\n=\\left(\\tfrac{1}{2}s,\\ \\tfrac{1}{2}r+p+\\tfrac{1}{2}s,\\ \\tfrac{1}{2}r\\right).\n$$\nHence the component equations are\n$$\nr=(1-\\epsilon)\\tfrac{1}{2}s+\\tfrac{\\epsilon}{3},\\quad\np=(1-\\epsilon)\\left(\\tfrac{1}{2}r+p+\\tfrac{1}{2}s\\right)+\\tfrac{\\epsilon}{3},\\quad\ns=(1-\\epsilon)\\tfrac{1}{2}r+\\tfrac{\\epsilon}{3},\n$$\ntogether with $r+p+s=1$. Let $a=\\tfrac{1-\\epsilon}{2}$. Then\n$$\nr=a\\,s+\\tfrac{\\epsilon}{3},\\qquad s=a\\,r+\\tfrac{\\epsilon}{3}.\n$$\nSubstitute $r$ from the first into the second:\n$$\ns=a\\left(a\\,s+\\tfrac{\\epsilon}{3}\\right)+\\tfrac{\\epsilon}{3}\n=a^{2}s+\\tfrac{a\\epsilon}{3}+\\tfrac{\\epsilon}{3}.\n$$\nTherefore\n$$\ns-a^{2}s=\\tfrac{(a+1)\\epsilon}{3}\\ \\Longrightarrow\\ s(1-a^{2})=\\tfrac{(a+1)\\epsilon}{3}.\n$$\nSince $1-a^{2}=(1-a)(1+a)$ and $1+a=\\tfrac{3-\\epsilon}{2}\\neq 0$ for $0\\epsilon\\tfrac{3}{2}$, cancel $(1+a)$ to get\n$$\ns(1-a)=\\tfrac{\\epsilon}{3}.\n$$\nNow $1-a=1-\\tfrac{1-\\epsilon}{2}=\\tfrac{1+\\epsilon}{2}$, so\n$$\ns=\\frac{\\epsilon/3}{(1+\\epsilon)/2}=\\frac{2\\epsilon}{3(1+\\epsilon)}.\n$$\nBy symmetry the same algebra yields\n$$\nr=\\frac{2\\epsilon}{3(1+\\epsilon)}.\n$$\nFinally, use $r+p+s=1$ to obtain\n$$\np=1-r-s=1-\\frac{4\\epsilon}{3(1+\\epsilon)}=\\frac{3-\\epsilon}{3(1+\\epsilon)}.\n$$\nThis $p$ also satisfies the middle stationarity equation, confirming consistency. Therefore, the long-run proportion of time that Player 2 chooses Paper is $\\frac{3-\\epsilon}{3(1+\\epsilon)}$.", "answer": "$$\\boxed{\\frac{3-\\epsilon}{3\\left(1+\\epsilon\\right)}}$$", "id": "1299380"}]}