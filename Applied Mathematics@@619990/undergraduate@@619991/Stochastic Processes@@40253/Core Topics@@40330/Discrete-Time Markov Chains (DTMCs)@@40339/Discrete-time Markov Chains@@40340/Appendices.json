{"hands_on_practices": [{"introduction": "To begin our hands-on exploration of Markov chains, we start with the fundamentals: calculating probabilities over a finite number of steps. This exercise strips the process down to its core, focusing on how state-to-state transition probabilities combine to determine the likelihood of future outcomes. By a careful enumeration of all possible paths a system can take, you will practice applying the chain rule of probability in the context of a state-dependent random walk, a crucial first step before tackling more complex, long-term behaviors [@problem_id:1297450].", "problem": "A simplified model for the price fluctuation of a speculative digital asset describes its value as an integer number of credits, $n \\in \\mathbb{Z}$. The price is updated at discrete time steps according to a stochastic process. The rules for the price change depend on the current price $n$.\n\n1.  If the current price $n$ is positive ($n > 0$), the probability of it increasing by 1 credit in the next step is $p$, and the probability of it decreasing by 1 credit is $q$.\n2.  If the current price $n$ is negative ($n < 0$), the probability of it increasing by 1 credit is $q$, and the probability of it decreasing by 1 credit is $p$.\n3.  If the current price is exactly zero ($n = 0$), the probability of it increasing by 1 credit is $1/2$, and the probability of it decreasing by 1 credit is $1/2$.\n\nThe parameters $p$ and $q$ are constants such that $p+q=1$ and $p < 1/2$.\n\nSuppose an asset is initially valued at $n_0 = 1$ credit. What is the probability that its value will be exactly 0 credits after three time steps? Express your answer as a closed-form analytic expression in terms of the parameter $q$.", "solution": "Let $X_t$ denote the price of the asset in credits at time step $t$. The state space of this discrete-time Markov chain is the set of integers $\\mathbb{Z}$. We are given the initial state $X_0 = 1$. We want to find the probability $P(X_3 = 0)$.\n\nFor the asset's price to go from an initial state of $X_0 = 1$ to a final state of $X_3 = 0$ in three steps, the net change in price must be $X_3 - X_0 = 0 - 1 = -1$. Each step results in a change of either $+1$ (a step to the right, R) or $-1$ (a step to the left, L). Let $N_R$ be the number of right steps and $N_L$ be the number of left steps.\n\nThe total number of steps is three:\n$$N_R + N_L = 3$$\nThe total displacement is $-1$:\n$$N_R - N_L = -1$$\n\nWe can solve this system of linear equations. Adding the two equations gives:\n$$2N_R = 2 \\implies N_R = 1$$\nSubstituting $N_R=1$ into the first equation gives:\n$$1 + N_L = 3 \\implies N_L = 2$$\nSo, any path from state 1 to state 0 in three steps must consist of exactly one step to the right and two steps to the left. The possible sequences of steps are the permutations of {R, L, L}, which are: RLL, LRL, and LLR.\n\nWe must calculate the probability of each path, taking into account the state-dependent transition probabilities. The probabilities of moving right ($P_R$) and left ($P_L$) from a state $n$ are:\n- If $n > 0$: $P_R = p$, $P_L = q$\n- If $n < 0$: $P_R = q$, $P_L = p$\n- If $n = 0$: $P_R = 1/2$, $P_L = 1/2$\n\nLet's evaluate the probability of each path starting from $X_0=1$:\n\n1.  **Path 1: RLL**\n    The sequence of states is $1 \\xrightarrow{R} 2 \\xrightarrow{L} 1 \\xrightarrow{L} 0$.\n    - Step 1: $X_0=1 \\to X_1=2$. The current state is $1 > 0$. A step to the right (away from the origin) has probability $p$.\n    - Step 2: $X_1=2 \\to X_2=1$. The current state is $2 > 0$. A step to the left (towards the origin) has probability $q$.\n    - Step 3: $X_2=1 \\to X_3=0$. The current state is $1 > 0$. A step to the left (towards the origin) has probability $q$.\n    The probability of this path is $P(\\text{RLL}) = p \\cdot q \\cdot q = pq^2$.\n\n2.  **Path 2: LRL**\n    The sequence of states is $1 \\xrightarrow{L} 0 \\xrightarrow{R} 1 \\xrightarrow{L} 0$.\n    - Step 1: $X_0=1 \\to X_1=0$. The current state is $1 > 0$. A step to the left (towards the origin) has probability $q$.\n    - Step 2: $X_1=0 \\to X_2=1$. The current state is $0$. A step to the right has probability $1/2$.\n    - Step 3: $X_2=1 \\to X_3=0$. The current state is $1 > 0$. A step to the left (towards the origin) has probability $q$.\n    The probability of this path is $P(\\text{LRL}) = q \\cdot \\frac{1}{2} \\cdot q = \\frac{1}{2}q^2$.\n\n3.  **Path 3: LLR**\n    The sequence of states is $1 \\xrightarrow{L} 0 \\xrightarrow{L} -1 \\xrightarrow{R} 0$.\n    - Step 1: $X_0=1 \\to X_1=0$. The current state is $1 > 0$. A step to the left (towards the origin) has probability $q$.\n    - Step 2: $X_1=0 \\to X_2=-1$. The current state is $0$. A step to the left has probability $1/2$.\n    - Step 3: $X_2=-1 \\to X_3=0$. The current state is $-1 < 0$. A step to the right (towards the origin) has probability $q$.\n    The probability of this path is $P(\\text{LLR}) = q \\cdot \\frac{1}{2} \\cdot q = \\frac{1}{2}q^2$.\n\nThe total probability of reaching state 0 after three steps is the sum of the probabilities of these mutually exclusive paths:\n$$P(X_3=0) = P(\\text{RLL}) + P(\\text{LRL}) + P(\\text{LLR})$$\n$$P(X_3=0) = pq^2 + \\frac{1}{2}q^2 + \\frac{1}{2}q^2 = pq^2 + q^2 = q^2(p+1)$$\n\nThe problem asks for the answer in terms of $q$. We use the given relation $p+q=1$, which implies $p = 1-q$.\nSubstituting this into our expression:\n$$P(X_3=0) = q^2((1-q)+1) = q^2(2-q)$$\nThis is the final expression for the probability.", "answer": "$$\\boxed{q^{2}(2-q)}$$", "id": "1297450"}, {"introduction": "Many real-world systems modeled by Markov chains eventually settle into one of several terminal, or absorbing, states. A common question is to find the probability of ending up in one specific absorbing state before any other. This problem [@problem_id:1297439] introduces this exact scenario, using a model of machine operational status with \"Maintenance\" and \"Critical Failure\" as absorbing states. You will apply the powerful technique of first-step analysis, which involves setting up and solving a system of linear equations to find these crucial absorption probabilities.", "problem": "A simplified model for the operational status of a piece of industrial machinery is described by a discrete-time Markov chain on the state space $S = \\{1, 2, 3, 4\\}$. The states are defined as:\n- State 1: Under Maintenance\n- State 2: Idle\n- State 3: Active\n- State 4: Critical Failure\n\nThe state of the machinery is observed at the end of each hour. Once the machine enters State 1 or State 4, it remains in that state. For the other states, the one-step transition probabilities are as follows:\n\nFrom State 2 (Idle), the machine transitions to:\n- State 1 with probability $p_{21} = 0.1$\n- State 2 with probability $p_{22} = 0.5$\n- State 3 with probability $p_{23} = 0.3$\n- State 4 with probability $p_{24} = 0.1$\n\nFrom State 3 (Active), the machine transitions to:\n- State 1 with probability $p_{31} = 0.2$\n- State 2 with probability $p_{32} = 0.4$\n- State 3 with probability $p_{33} = 0.1$\n- State 4 with probability $p_{34} = 0.3$\n\nSuppose the machine is currently in the Idle state (State 2). Calculate the probability that it will enter Critical Failure (State 4) before it enters the Under Maintenance state (State 1). Express your answer as an exact fraction.", "solution": "We model the event of hitting State 4 (Critical Failure) before State 1 (Under Maintenance) using hitting probabilities in an absorbing Markov chain. Let $h_{i}$ denote the probability that, starting from state $i$, the chain reaches State $4$ before State $1$. Since States $1$ and $4$ are absorbing, the boundary conditions are $h_{1}=0$ and $h_{4}=1$. By first-step analysis for transient states $2$ and $3$, we have\n$$\nh_{2} = p_{22} h_{2} + p_{23} h_{3} + p_{24}\\cdot 1 + p_{21}\\cdot 0,\n\\quad\nh_{3} = p_{32} h_{2} + p_{33} h_{3} + p_{34}\\cdot 1 + p_{31}\\cdot 0.\n$$\nSubstituting the given transition probabilities, written as exact fractions,\n$$\nh_{2} = \\frac{1}{2} h_{2} + \\frac{3}{10} h_{3} + \\frac{1}{10}, \n\\quad\nh_{3} = \\frac{2}{5} h_{2} + \\frac{1}{10} h_{3} + \\frac{3}{10}.\n$$\nRearranging,\n$$\n\\left(1 - \\frac{1}{2}\\right) h_{2} - \\frac{3}{10} h_{3} = \\frac{1}{10},\n\\quad\n-\\frac{2}{5} h_{2} + \\left(1 - \\frac{1}{10}\\right) h_{3} = \\frac{3}{10},\n$$\nwhich simplifies to\n$$\n\\frac{1}{2} h_{2} - \\frac{3}{10} h_{3} = \\frac{1}{10},\n\\quad\n-\\frac{2}{5} h_{2} + \\frac{9}{10} h_{3} = \\frac{3}{10}.\n$$\nMultiplying both equations by $10$ gives\n$$\n5 h_{2} - 3 h_{3} = 1,\n\\quad\n-4 h_{2} + 9 h_{3} = 3.\n$$\nFrom the first equation, $h_{2} = \\frac{1 + 3 h_{3}}{5}$. Substituting into the second,\n$$\n-4 \\cdot \\frac{1 + 3 h_{3}}{5} + 9 h_{3} = 3\n\\;\\Rightarrow\\;\n-\\frac{4}{5} - \\frac{12}{5} h_{3} + 9 h_{3} = 3\n\\;\\Rightarrow\\;\n\\frac{33}{5} h_{3} - \\frac{4}{5} = 3.\n$$\nMultiplying by $5$,\n$$\n33 h_{3} - 4 = 15 \\;\\Rightarrow\\; 33 h_{3} = 19 \\;\\Rightarrow\\; h_{3} = \\frac{19}{33}.\n$$\nThen\n$$\nh_{2} = \\frac{1 + 3 \\cdot \\frac{19}{33}}{5} = \\frac{\\frac{33}{33} + \\frac{57}{33}}{5} = \\frac{\\frac{90}{33}}{5} = \\frac{90}{165} = \\frac{6}{11}.\n$$\nThus, starting from State $2$ (Idle), the probability of entering State $4$ (Critical Failure) before State $1$ (Under Maintenance) is $\\frac{6}{11}$.", "answer": "$$\\boxed{\\frac{6}{11}}$$", "id": "1297439"}, {"introduction": "The core assumption of a Markov chain is its \"memoryless\" property, where the next state depends only on the current one. However, what if a process has memory? This practice [@problem_id:1297471] demonstrates a key modeling technique to handle such situations by transforming a process with second-order dependency into a standard first-order Markov chain. By redefining the state space to include information about the previous state, you can analyze the system's long-term behavior and calculate its stationary distribution, a fundamental concept in understanding stochastic equilibrium.", "problem": "A data packet travels through a multi-stage processing pipeline. At each stage $n \\ge 0$, the packet is assigned a priority state, denoted by $X_n$. The state can be either Low-priority ($L$) or High-priority ($H$). The process adheres to a memory-dependent rule: the priority at stage $n+1$ depends on the priorities at stages $n$ and $n-1$.\n\nThe specific state transition probabilities for $n \\ge 1$ are defined as follows:\n- If the packet was in state $L$ at both stage $n-1$ and stage $n$, the probability it remains in state $L$ at stage $n+1$ is $P(X_{n+1}=L | X_n=L, X_{n-1}=L) = \\alpha$.\n- If the packet transitioned from $L$ at stage $n-1$ to $H$ at stage $n$, the probability it remains in state $H$ at stage $n+1$ is $P(X_{n+1}=H | X_n=H, X_{n-1}=L) = \\beta$.\n- If the packet transitioned from $H$ at stage $n-1$ to $L$ at stage $n$, the probability it switches back to state $H$ at stage $n+1$ is $P(X_{n+1}=H | X_n=L, X_{n-1}=H) = \\gamma$.\n- If the packet was in state $H$ at both stage $n-1$ and stage $n$, the probability it switches to state $L$ at stage $n+1$ is $P(X_{n+1}=L | X_n=H, X_{n-1}=H) = \\delta$.\n\nAssume the constants have the values $\\alpha = \\frac{3}{4}$, $\\beta = \\frac{2}{3}$, $\\gamma = \\frac{1}{2}$, and $\\delta = \\frac{1}{4}$. Assuming the process runs for a very large number of stages, what is the long-run probability that the packet is in the high-priority state at any given stage?\n\nExpress your answer as an exact fraction.", "solution": "We model the given second-order process as a first-order Markov chain on pairs. Define $Y_{n} = (X_{n-1}, X_{n})$ with state space $\\{LL, LH, HL, HH\\}$. Then, from the given transition rules:\n- From $LL$: $P(LL \\to LL) = \\frac{3}{4}$ and $P(LL \\to LH) = \\frac{1}{4}$.\n- From $LH$: $P(LH \\to HH) = \\frac{2}{3}$ and $P(LH \\to HL) = \\frac{1}{3}$.\n- From $HL$: $P(HL \\to LL) = \\frac{1}{2}$ and $P(HL \\to LH) = \\frac{1}{2}$.\n- From $HH$: $P(HH \\to HH) = \\frac{3}{4}$ and $P(HH \\to HL) = \\frac{1}{4}$.\n\nLet the stationary distribution of $Y_{n}$ be $\\pi = (a, b, c, d)$ corresponding to $(LL, LH, HL, HH)$, so $\\pi$ satisfies $\\pi = \\pi P$ and $a + b + c + d = 1$. Writing the component equations:\n$$\n\\begin{aligned}\na &= \\frac{3}{4} a + \\frac{1}{2} c, \\\\\nb &= \\frac{1}{4} a + \\frac{1}{2} c, \\\\\nc &= \\frac{1}{3} b + \\frac{1}{4} d, \\\\\nd &= \\frac{2}{3} b + \\frac{3}{4} d.\n\\end{aligned}\n$$\nFrom $a = \\frac{3}{4} a + \\frac{1}{2} c$ we get $a - \\frac{3}{4} a = \\frac{1}{2} c$, hence $\\frac{1}{4} a = \\frac{1}{2} c$, so $a = 2 c$.\nThen $b = \\frac{1}{4} a + \\frac{1}{2} c = \\frac{1}{4} (2 c) + \\frac{1}{2} c = c$.\nFrom $d = \\frac{2}{3} b + \\frac{3}{4} d$ we get $d - \\frac{3}{4} d = \\frac{2}{3} b$, so $\\frac{1}{4} d = \\frac{2}{3} b$, hence $d = \\frac{8}{3} b = \\frac{8}{3} c$.\nThe $c$-equation is consistent: $c = \\frac{1}{3} b + \\frac{1}{4} d = \\frac{1}{3} c + \\frac{1}{4} \\cdot \\frac{8}{3} c = \\left(\\frac{1}{3} + \\frac{2}{3}\\right) c = c$.\nNormalize: $a + b + c + d = 2 c + c + c + \\frac{8}{3} c = \\frac{20}{3} c = 1$, so $c = \\frac{3}{20}$. Therefore $b = \\frac{3}{20}$, $a = 2 c = \\frac{3}{10}$, and $d = \\frac{8}{3} c = \\frac{8}{20} = \\frac{2}{5}$.\n\nIn stationarity, the long-run probability that $X_{n} = H$ is the marginal over pairs with second component $H$, namely $P(X_{n} = H) = \\pi(LH) + \\pi(HH) = b + d = \\frac{3}{20} + \\frac{2}{5} = \\frac{3}{20} + \\frac{8}{20} = \\frac{11}{20}$.", "answer": "$$\\boxed{\\frac{11}{20}}$$", "id": "1297471"}]}