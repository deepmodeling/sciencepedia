{"hands_on_practices": [{"introduction": "The cornerstone of a well-posed Stochastic Differential Equation (SDE) is the guarantee of a unique, stable solution. This guarantee often rests on two key properties of the SDE's coefficients: the global Lipschitz condition and the linear growth condition. This first exercise provides a direct opportunity to practice verifying these conditions for an SDE with well-behaved coefficients, a fundamental skill for analyzing stochastic models. [@problem_id:1300191]", "problem": "Consider the one-dimensional autonomous Stochastic Differential Equation (SDE) given by:\n$$ dX_t = \\frac{1}{1+|X_t|} dt + \\frac{X_t}{1+X_t^2} dW_t $$\nwhere $X_t$ is a stochastic process and $W_t$ is a standard one-dimensional Wiener process. The existence and uniqueness of a strong solution to this SDE for any given initial condition $X_0$ is guaranteed by certain properties of its drift coefficient, $\\mu(x)$, and diffusion coefficient, $\\sigma(x)$. Here, the SDE is of the form $dX_t = \\mu(X_t) dt + \\sigma(X_t) dW_t$.\n\nLet the two standard conditions on the coefficients be:\n\n(I) **Global Lipschitz Condition:** There exists a constant $K > 0$ such that for all $x, y \\in \\mathbb{R}$:\n$$ |\\mu(x) - \\mu(y)| + |\\sigma(x) - \\sigma(y)| \\le K|x-y| $$\n\n(II) **Linear Growth Condition:** There exists a constant $C > 0$ such that for all $x \\in \\mathbb{R}$:\n$$ |\\mu(x)|^2 + |\\sigma(x)|^2 \\le C(1+x^2) $$\n\nWhich one of the following statements correctly describes the properties of the coefficients $\\mu(x)$ and $\\sigma(x)$ for the given SDE?\n\nA. Both coefficients individually satisfy a global Lipschitz condition and both are bounded (which implies they satisfy a linear growth condition).\nB. Only the drift coefficient $\\mu(x)$ satisfies a global Lipschitz condition, but both are bounded.\nC. Only the diffusion coefficient $\\sigma(x)$ satisfies a global Lipschitz condition, but both are bounded.\nD. Neither coefficient satisfies a global Lipschitz condition, but both are bounded.\nE. At least one of the coefficients is not bounded, and therefore does not satisfy the linear growth condition in the strongest sense.", "solution": "To determine which properties the coefficients of the given SDE satisfy, we first need to identify the drift and diffusion coefficients and then analyze them with respect to the Global Lipschitz and Linear Growth conditions.\n\nThe given SDE is $dX_t = \\frac{1}{1+|X_t|} dt + \\frac{X_t}{1+X_t^2} dW_t$.\nComparing this to the general form $dX_t = \\mu(X_t) dt + \\sigma(X_t) dW_t$, we identify the coefficients as:\nDrift coefficient: $\\mu(x) = \\frac{1}{1+|x|}$\nDiffusion coefficient: $\\sigma(x) = \\frac{x}{1+x^2}$\n\nWe will now check if each coefficient satisfies a global Lipschitz condition and a linear growth condition. A function $f(x)$ is globally Lipschitz if there exists a constant $L>0$ such that $|f(x) - f(y)| \\leq L|x-y|$ for all $x, y \\in \\mathbb{R}$.\n\n**Analysis of the drift coefficient $\\mu(x) = \\frac{1}{1+|x|}$:**\n\n1.  **Lipschitz Condition for $\\mu(x)$:**\n    We need to check if $|\\mu(x) - \\mu(y)| \\leq L_1 |x-y|$ for some constant $L_1$.\n    Let's compute the difference:\n    $$ |\\mu(x) - \\mu(y)| = \\left| \\frac{1}{1+|x|} - \\frac{1}{1+|y|} \\right| = \\left| \\frac{(1+|y|) - (1+|x|)}{(1+|x|)(1+|y|)} \\right| = \\frac{||y|-|x||}{(1+|x|)(1+|y|)} $$\n    By the reverse triangle inequality, we know that $||y|-|x|| \\leq |y-x|$.\n    The denominator is always greater than or equal to 1, since $(1+|x|) \\ge 1$ and $(1+|y|) \\ge 1$.\n    Therefore, we can write:\n    $$ \\frac{||y|-|x||}{(1+|x|)(1+|y|)} \\leq \\frac{|y-x|}{1} = |x-y| $$\n    So, $|\\mu(x) - \\mu(y)| \\leq 1 \\cdot |x-y|$. This shows that $\\mu(x)$ is globally Lipschitz with a Lipschitz constant $L_1 = 1$.\n\n2.  **Growth Condition for $\\mu(x)$:**\n    The function is $|\\mu(x)| = \\frac{1}{1+|x|}$. Since $|x| \\ge 0$, the denominator $1+|x| \\ge 1$. Thus, we have $0  |\\mu(x)| \\leq 1$ for all $x \\in \\mathbb{R}$.\n    Since $\\mu(x)$ is a bounded function, it automatically satisfies the linear growth condition. To be explicit, $|\\mu(x)|^2 \\le 1^2 = 1$. We need to find a constant $C_1$ such that $1 \\leq C_1(1+x^2)$. Choosing $C_1=1$ works, since $1 \\leq 1+x^2$ for all $x$.\n\n**Analysis of the diffusion coefficient $\\sigma(x) = \\frac{x}{1+x^2}$:**\n\n1.  **Lipschitz Condition for $\\sigma(x)$:**\n    A differentiable function is globally Lipschitz if its derivative is bounded. Let's find the derivative of $\\sigma(x)$:\n    $$ \\sigma'(x) = \\frac{d}{dx}\\left(\\frac{x}{1+x^2}\\right) = \\frac{(1)(1+x^2) - x(2x)}{(1+x^2)^2} = \\frac{1-x^2}{(1+x^2)^2} $$\n    To check if the derivative is bounded, we can find its maximum absolute value. Let's find an upper bound for $|\\sigma'(x)|$:\n    $$ |\\sigma'(x)| = \\frac{|1-x^2|}{(1+x^2)^2} \\leq \\frac{1+x^2}{(1+x^2)^2} = \\frac{1}{1+x^2} $$\n    Since $1+x^2 \\ge 1$, we have $\\frac{1}{1+x^2} \\le 1$.\n    So, we have shown that $|\\sigma'(x)| \\leq 1$ for all $x \\in \\mathbb{R}$.\n    By the Mean Value Theorem, for any $x, y \\in \\mathbb{R}$, there exists a $c$ between $x$ and $y$ such that $\\sigma(x) - \\sigma(y) = \\sigma'(c)(x-y)$.\n    Taking the absolute value, we get $|\\sigma(x) - \\sigma(y)| = |\\sigma'(c)||x-y| \\leq 1 \\cdot |x-y|$.\n    This shows that $\\sigma(x)$ is globally Lipschitz with a Lipschitz constant $L_2 = 1$.\n\n2.  **Growth Condition for $\\sigma(x)$:**\n    We analyze the magnitude of $\\sigma(x)$: $|\\sigma(x)| = \\frac{|x|}{1+x^2}$.\n    To find the maximum value, we can examine its derivative, which we already found to be zero at $x=\\pm 1$. At these points, $|\\sigma(\\pm 1)| = \\frac{1}{1+1} = \\frac{1}{2}$. As $|x|\\to\\infty$, $|\\sigma(x)|\\to 0$. At $x=0$, $\\sigma(0)=0$.\n    Thus, the function is bounded: $|\\sigma(x)| \\le \\frac{1}{2}$ for all $x \\in \\mathbb{R}$.\n    Since $\\sigma(x)$ is bounded, it satisfies the linear growth condition. Specifically, $|\\sigma(x)|^2 \\le (\\frac{1}{2})^2 = \\frac{1}{4}$. We need to find a constant $C_2$ such that $\\frac{1}{4} \\leq C_2(1+x^2)$. Choosing $C_2=1/4$ works, since $1/4 \\le (1/4)(1+x^2)$ for all $x$.\n\n**Conclusion:**\nBoth the drift coefficient $\\mu(x)$ and the diffusion coefficient $\\sigma(x)$ are globally Lipschitz.\nBoth coefficients are also bounded, which is a stronger condition than and implies the linear growth condition.\nTherefore, the statement that correctly describes the properties is that both coefficients individually satisfy a global Lipschitz condition and are bounded. This matches option A.\n\nThe conditions (I) and (II) for the theorem are also satisfied:\n(I) $|\\mu(x)-\\mu(y)| + |\\sigma(x)-\\sigma(y)| \\le 1 \\cdot |x-y| + 1 \\cdot |x-y| = 2|x-y|$. So $K=2$.\n(II) $|\\mu(x)|^2 + |\\sigma(x)|^2 \\le 1^2 + (1/2)^2 = 1.25$. We need $1.25 \\le C(1+x^2)$, which is satisfied for $C \\ge 1.25$.\nThus, the SDE is guaranteed to have a unique strong solution.", "answer": "$$\\boxed{A}$$", "id": "1300191"}, {"introduction": "While many common functions in SDEs are smooth and satisfy the required conditions, it is equally important to recognize when these conditions fail. This practice problem presents a thought-provoking scenario with a drift coefficient defined by the floor function, which is discontinuous at every integer. By analyzing this function, you will develop a sharper intuition for the strict requirements of Lipschitz continuity and understand why functions with \"jumps\" can pose a challenge for the standard existence and uniqueness theory. [@problem_id:1300180]", "problem": "In the study of stochastic processes, the existence and uniqueness of a strong solution to a one-dimensional Stochastic Differential Equation (SDE) of the form $dX_t = b(X_t) dt + \\sigma(X_t) dW_t$ are often guaranteed if the drift coefficient $b(x)$ and the diffusion coefficient $\\sigma(x)$ satisfy certain conditions. One such key condition is the global Lipschitz condition.\n\nA function $f: \\mathbb{R} \\to \\mathbb{R}$ is said to be globally Lipschitz continuous if there exists a finite constant $L > 0$ such that for all $x, y \\in \\mathbb{R}$, the inequality $|f(x) - f(y)| \\le L|x - y|$ holds.\n\nConsider the following SDE:\n$$dX_t = \\lfloor X_t \\rfloor dt + dW_t$$\nwhere $\\lfloor z \\rfloor$ is the floor function, which returns the greatest integer less than or equal to $z$, and $W_t$ is a standard one-dimensional Wiener process. The diffusion coefficient is constant, $\\sigma(x) = 1$, which is globally Lipschitz.\n\nWhich of the following statements correctly evaluates whether the drift coefficient, $b(x) = \\lfloor x \\rfloor$, satisfies the global Lipschitz condition?\n\nA. Yes, the drift coefficient is globally Lipschitz continuous with a Lipschitz constant of $L=1$.\nB. Yes, the drift coefficient is globally Lipschitz continuous because for any two points $x$ and $y$, the change in the function is at most the change in its argument.\nC. No, the drift coefficient is not globally Lipschitz continuous because it is not a differentiable function.\nD. No, the drift coefficient is not globally Lipschitz continuous because the ratio $\\frac{|\\lfloor x \\rfloor - \\lfloor y \\rfloor|}{|x-y|}$ can be made arbitrarily large near integer values.", "solution": "We recall the definition: a function $f:\\mathbb{R}\\to\\mathbb{R}$ is globally Lipschitz if there exists $L0$ such that for all $x,y\\in\\mathbb{R}$,\n$$\n|f(x)-f(y)|\\le L|x-y|.\n$$\nTake $b(x)=\\lfloor x\\rfloor$. To test the global Lipschitz condition, fix any $L0$ and consider any integer $n\\in\\mathbb{Z}$. For $\\delta0$ small, set $x=n+\\delta$ and $y=n-\\delta$. Then\n$$\n\\lfloor x\\rfloor=\\lfloor n+\\delta\\rfloor=n,\\qquad \\lfloor y\\rfloor=\\lfloor n-\\delta\\rfloor=n-1,\n$$\nso\n$$\n|\\lfloor x\\rfloor-\\lfloor y\\rfloor|=|n-(n-1)|=1,\\qquad |x-y|=|(n+\\delta)-(n-\\delta)|=2\\delta.\n$$\nTherefore,\n$$\n\\frac{|\\lfloor x\\rfloor-\\lfloor y\\rfloor|}{|x-y|}=\\frac{1}{2\\delta}.\n$$\nSince $\\delta0$ can be chosen arbitrarily small, the ratio $\\frac{1}{2\\delta}$ can be made arbitrarily large. Hence there is no finite $L$ such that $|\\lfloor x\\rfloor-\\lfloor y\\rfloor|\\le L|x-y|$ holds for all $x,y$, so $b(x)=\\lfloor x\\rfloor$ is not globally Lipschitz. This directly validates statement D.\n\nFor completeness regarding the other options: A and B assert global Lipschitzness, which is false by the argument above. C claims non-Lipschitzness because of non-differentiability, but non-differentiability alone does not preclude Lipschitz continuity (for example, $f(x)=|x|$ is globally Lipschitz). Thus D is the correct statement.\n\nThe diffusion coefficient $\\sigma(x)=1$ is globally Lipschitz, but this does not alter the conclusion for $b(x)$.", "answer": "$$\\boxed{D}$$", "id": "1300180"}, {"introduction": "The existence and uniqueness theorem relies not only on the properties of an SDE's coefficients but also on the nature of its starting point. This problem moves beyond analyzing coefficients to explore the role of the initial condition, $X_0$, within the context of the Picard iteration method used to prove the theorem. You will investigate what assumption is necessary on a random initial value to ensure the iterative approximation scheme is well-defined and converges, a concept with direct implications for numerical simulations and theoretical analysis. [@problem_id:1300213]", "problem": "A quantitative analyst is modeling a financial asset whose price $X_t$ is believed to follow a geometric Brownian motion, described by the linear Stochastic Differential Equation (SDE):\n$$dX_t = \\mu X_t dt + \\sigma X_t dW_t$$\nwhere $\\mu$ and $\\sigma$ are constant real numbers representing the drift and volatility, respectively, and $W_t$ is a standard one-dimensional Wiener process. The initial price of the asset at time $t=0$, denoted by $X_0$, is not a fixed value but is instead a random variable, assumed to be independent of the Wiener process $W_t$.\n\nTo approximate the solution path on a finite time interval $[0, T]$ for some $T  0$, the analyst uses the standard Picard iterative method. The sequence of approximate solutions $\\{X_t^{(n)}\\}_{n \\ge 0}$ is defined as:\n$$X_t^{(0)} = X_0$$\n$$X_t^{(n+1)} = X_0 + \\int_0^t \\mu X_s^{(n)} ds + \\int_0^t \\sigma X_s^{(n)} dW_s \\quad \\text{for } n \\ge 0$$\nA crucial step in proving that this sequence of approximations converges to a true solution in the mean-square sense is to first establish that each iterate has a finite second moment that is uniformly bounded on the interval $[0, T]$. That is, for each integer $n \\ge 0$, there must exist a constant $C_n$ (which may depend on $n$, $\\mu$, $\\sigma$, and $T$) such that $\\sup_{t \\in [0, T]} \\mathbb{E}[|X_t^{(n)}|^2]  C_n$.\n\nWhat is the least restrictive condition that must be imposed on the initial random state $X_0$ to guarantee that this uniform boundedness of the second moment holds for all iterates $n \\ge 0$?\n\nA. The second moment of $X_0$ must be finite, i.e., $\\mathbb{E}[X_0^2]  \\infty$.\nB. The first absolute moment of $X_0$ must be finite, i.e., $\\mathbb{E}[|X_0|]  \\infty$.\nC. The fourth moment of $X_0$ must be finite, i.e., $\\mathbb{E}[X_0^4]  \\infty$.\nD. The initial state $X_0$ must be almost surely bounded, i.e., there exists a finite constant $M$ such that $|X_0| \\le M$ almost surely.\nE. The mean of the initial state must be zero, i.e., $\\mathbb{E}[X_0] = 0$.", "solution": "We consider the Picard iterates defined by\n$$\nX_{t}^{(0)}=X_{0}, \\qquad\nX_{t}^{(n+1)} = X_{0} + \\int_{0}^{t} \\mu X_{s}^{(n)} ds + \\int_{0}^{t} \\sigma X_{s}^{(n)} dW_{s}.\n$$\nFirst, note that the stochastic integrals are well-defined if the integrands are adapted and square-integrable on any finite interval. For the base case, if $\\mathbb{E}[|X_{0}|^{2}]\\infty$, then $X^{(0)}$ is constant in time, adapted, and\n$$\n\\mathbb{E}\\left[\\int_{0}^{T} |X_{s}^{(0)}|^{2} ds\\right] = T \\mathbb{E}[|X_{0}|^{2}]  \\infty,\n$$\nso the stochastic integral in $X^{(1)}$ is well-defined.\n\nWe show uniform boundedness of the second moment by induction. Define\n$$\nf_{n}(t) := \\mathbb{E}\\left[|X_{t}^{(n)}|^{2}\\right], \\qquad K_{n} := \\sup_{t \\in [0,T]} f_{n}(t).\n$$\nBase step: for $n=0$,\n$$\nf_{0}(t) = \\mathbb{E}[|X_{0}|^{2}], \\qquad K_{0} = \\mathbb{E}[|X_{0}|^{2}]  \\infty\n$$\nprovided $\\mathbb{E}[|X_{0}|^{2}]\\infty$.\n\nInductive step: assume $K_{n}\\infty$. Using $X_{t}^{(n+1)} = A + B + C$ with $A:=X_{0}$, $B:=\\mu \\int_{0}^{t} X_{s}^{(n)} ds$, and $C:=\\sigma \\int_{0}^{t} X_{s}^{(n)} dW_{s}$, the inequality $(a+b+c)^{2} \\le 3a^{2}+3b^{2}+3c^{2}$ yields\n$$\nf_{n+1}(t) \\le 3 \\mathbb{E}[|X_{0}|^{2}] + 3 \\mu^{2} \\mathbb{E}\\left[\\left|\\int_{0}^{t} X_{s}^{(n)} ds\\right|^{2}\\right] + 3 \\sigma^{2} \\mathbb{E}\\left[\\left|\\int_{0}^{t} X_{s}^{(n)} dW_{s}\\right|^{2}\\right].\n$$\nBy the Cauchyâ€“Schwarz inequality,\n$$\n\\mathbb{E}\\left[\\left|\\int_{0}^{t} X_{s}^{(n)} ds\\right|^{2}\\right] \\le t \\int_{0}^{t} \\mathbb{E}\\left[|X_{s}^{(n)}|^{2}\\right] ds \\le t \\int_{0}^{t} K_{n} ds = t^{2} K_{n} \\le T^{2} K_{n}.\n$$\nBy the It\\^{o} isometry,\n$$\n\\mathbb{E}\\left[\\left|\\int_{0}^{t} X_{s}^{(n)} dW_{s}\\right|^{2}\\right] = \\int_{0}^{t} \\mathbb{E}\\left[|X_{s}^{(n)}|^{2}\\right] ds \\le t K_{n} \\le T K_{n}.\n$$\nTherefore,\n$$\nf_{n+1}(t) \\le 3 \\mathbb{E}[|X_{0}|^{2}] + 3\\left(\\mu^{2} T^{2} + \\sigma^{2} T\\right) K_{n},\n$$\nand taking the supremum in $t \\in [0,T]$,\n$$\nK_{n+1} \\le 3 \\mathbb{E}[|X_{0}|^{2}] + 3\\left(\\mu^{2} T^{2} + \\sigma^{2} T\\right) K_{n}.\n$$\nLet $c := 3\\left(\\mu^{2} T^{2} + \\sigma^{2} T\\right)$. With $K_{0}=\\mathbb{E}[|X_{0}|^{2}]$, this linear recursion gives\n$$\nK_{n} \\le 3 \\mathbb{E}[|X_{0}|^{2}] \\sum_{k=0}^{n-1} c^{k} + c^{n} \\mathbb{E}[|X_{0}|^{2}]  \\infty\n$$\nfor every $n \\ge 0$, provided $\\mathbb{E}[|X_{0}|^{2}]\\infty$. Hence, for each $n$, $\\sup_{t \\in [0,T]} \\mathbb{E}[|X_{t}^{(n)}|^{2}] \\le K_{n}  \\infty$.\n\nNecessity of $\\mathbb{E}[|X_{0}|^{2}]\\infty$ for the stated property follows from $X_{t}^{(0)}=X_{0}$, since otherwise $\\sup_{t \\in [0,T]} \\mathbb{E}[|X_{t}^{(0)}|^{2}] = \\mathbb{E}[|X_{0}|^{2}] = \\infty$. Therefore, the least restrictive condition is that the initial state has a finite second moment.\n\nOptions B, C, D, and E are either insufficient or stronger than necessary: B fails because there exist distributions with finite $\\mathbb{E}[|X_{0}|]$ but infinite $\\mathbb{E}[|X_{0}|^{2}]$, making the base iterate unbounded in second moment; C and D imply a finite second moment but are stricter than needed; E is irrelevant to second-moment boundedness.", "answer": "$$\\boxed{A}$$", "id": "1300213"}]}