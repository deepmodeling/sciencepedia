{"hands_on_practices": [{"introduction": "The cornerstone of a stable process is its self-similarity or scaling property, which is uniquely governed by the stability parameter, $\\alpha$. This first exercise provides a direct, hands-on opportunity to work with this fundamental definition. By working backward from an observed scaling relationship, you will determine the value of $\\alpha$, solidifying your understanding of how the sum of $n$ variables relates to the scaling factor $n^{1/\\alpha}$. [@problem_id:1332654]", "problem": "A stochastic process is modeled by a sequence of random variables $X_1, X_2, X_3, \\dots$. These variables are independent and identically distributed (i.i.d.) and are known to follow a strictly stable distribution. A defining characteristic of such distributions is the existence of a stability parameter $\\alpha \\in (0, 2]$. This parameter governs the scaling property of sums of these variables. For any integer $n \\ge 2$, the sum $S_n = X_1 + \\dots + X_n$ has the same probability distribution as a scaled version of a single variable, $c_n X_1$, for some constant $c_n  0$.\n\nFor the specific process under consideration, it is found that the sum of the first four variables, $S_4 = X_1 + X_2 + X_3 + X_4$, has the same probability distribution as the random variable $Y = 2^{1.5} X_1$.\n\nDetermine the stability parameter, $\\alpha$, for this process. Your final answer should be provided as a single real number in its exact form.", "solution": "For a strictly stable i.i.d. sequence with stability parameter $\\alpha \\in (0,2]$, the defining scaling property is that for every integer $n \\geq 2$,\n$$\nS_{n}=X_{1}+\\cdots+X_{n} \\;\\overset{d}{=}\\; c_{n}X_{1},\n$$\nwith $c_{n}=n^{1/\\alpha}$. This follows from the strict stability property (no location shift), so the scale of the sum grows as $n^{1/\\alpha}$ relative to a single summand.\n\nFor $n=4$, this gives\n$$\nS_{4} \\;\\overset{d}{=}\\; 4^{1/\\alpha} X_{1}.\n$$\nThe problem states that\n$$\nS_{4} \\;\\overset{d}{=}\\; 2^{1.5} X_{1} \\;=\\; 2^{3/2} X_{1}.\n$$\nEquating the scale factors,\n$$\n4^{1/\\alpha} \\;=\\; 2^{3/2}.\n$$\nSince $4=2^{2}$, we rewrite the left-hand side:\n$$\n(2^{2})^{1/\\alpha} \\;=\\; 2^{2/\\alpha}.\n$$\nThus,\n$$\n2^{2/\\alpha} \\;=\\; 2^{3/2},\n$$\nwhich implies equality of exponents:\n$$\n\\frac{2}{\\alpha} \\;=\\; \\frac{3}{2}.\n$$\nSolving for $\\alpha$ yields\n$$\n\\alpha \\;=\\; \\frac{4}{3}.\n$$", "answer": "$$\\boxed{\\frac{4}{3}}$$", "id": "1332654"}, {"introduction": "Building on the scaling property, this next practice explores the \"stability\" of these distributions under addition. Here, we investigate how the distribution's other key parameters—scale ($\\gamma$) and location ($\\delta$)—transform when we sum multiple independent and identically distributed stable variables. This exercise gets to the heart of why these processes are called \"stable\" and is a crucial step toward modeling cumulative effects. [@problem_id:1332664]", "problem": "A random variable $X$ is said to have a stable distribution if its distribution type is preserved under linear combinations. The four-parameter family of stable distributions is denoted by $S(\\alpha, \\beta, \\gamma, \\delta)$, where $\\alpha \\in (0, 2]$ is the stability index, $\\beta \\in [-1, 1]$ is the skewness parameter, $\\gamma  0$ is the scale parameter, and $\\delta \\in \\mathbb{R}$ is the location parameter.\n\nConsider a sequence of $n$ independent and identically distributed (i.i.d.) random variables $X_1, X_2, \\dots, X_n$. Each variable $X_i$ follows a symmetric $\\alpha$-stable distribution with a scale parameter $\\gamma$ and a location parameter $\\delta_0$. In the standard notation, this corresponds to $X_i \\sim S(\\alpha, 0, \\gamma, \\delta_0)$ for all $i=1, \\dots, n$.\n\nThe sum of these variables, defined as $S_n = \\sum_{i=1}^{n} X_i$, is known to also follow a symmetric $\\alpha$-stable distribution. This resulting distribution can be expressed in the form $S_n \\sim S(\\alpha, 0, \\gamma_n, \\delta_n)$.\n\nDetermine the new scale parameter $\\gamma_n$ and the new location parameter $\\delta_n$ in terms of $n$, $\\alpha$, $\\gamma$, and $\\delta_0$. Present your answer as a row matrix containing the expressions for $\\gamma_n$ and $\\delta_n$ in that order.", "solution": "For a symmetric stable random variable $X \\sim S(\\alpha, 0, \\gamma, \\delta_{0})$, the characteristic function is\n$$\n\\varphi_{X}(t)=\\exp\\!\\left(i\\delta_{0} t-\\gamma^{\\alpha}|t|^{\\alpha}\\right),\n$$\nwhich holds for all $\\alpha \\in (0,2]$; when $\\alpha=1$ the symmetry $\\beta=0$ removes any logarithmic correction.\n\nGiven $X_{1},\\dots,X_{n}$ i.i.d. with $X_{i} \\sim S(\\alpha,0,\\gamma,\\delta_{0})$, independence implies that the characteristic function of the sum $S_{n}=\\sum_{i=1}^{n}X_{i}$ is the product of the individual characteristic functions:\n$$\n\\varphi_{S_{n}}(t)=\\prod_{i=1}^{n}\\varphi_{X_{i}}(t)=\\left[\\exp\\!\\left(i\\delta_{0} t-\\gamma^{\\alpha}|t|^{\\alpha}\\right)\\right]^{n}\n=\\exp\\!\\left(i n\\delta_{0} t- n\\,\\gamma^{\\alpha}|t|^{\\alpha}\\right).\n$$\nA symmetric $\\alpha$-stable variable $Y \\sim S(\\alpha,0,\\gamma_{n},\\delta_{n})$ has characteristic function\n$$\n\\varphi_{Y}(t)=\\exp\\!\\left(i\\delta_{n} t-\\gamma_{n}^{\\alpha}|t|^{\\alpha}\\right).\n$$\nIdentifying terms with $\\varphi_{S_{n}}(t)$ yields\n$$\n\\delta_{n}=n\\,\\delta_{0},\\qquad \\gamma_{n}^{\\alpha}=n\\,\\gamma^{\\alpha}.\n$$\nSolving for $\\gamma_{n}$ gives\n$$\n\\gamma_{n}=n^{1/\\alpha}\\,\\gamma.\n$$\nTherefore,\n$$\n\\left[\\gamma_{n}\\ \\ \\delta_{n}\\right]=\\left[n^{1/\\alpha}\\gamma\\ \\ n\\delta_{0}\\right].\n$$", "answer": "$$\\boxed{\\begin{pmatrix} n^{1/\\alpha}\\gamma  n\\delta_{0} \\end{pmatrix}}$$", "id": "1332664"}, {"introduction": "We now turn to one of the most profound and practical consequences of stable processes: their \"heavy tails.\" The stability parameter $\\alpha$ does more than just control scaling; it acts as a sharp boundary determining which statistical moments, like the mean or variance, exist and are finite. This practice challenges you to apply this concept to determine the nature of a particle's displacement, illustrating why stable distributions are indispensable for modeling phenomena characterized by rare but extreme events. [@problem_id:1332660]", "problem": "In the field of plasma physics, the turbulent motion of charged particles is often modeled using stochastic processes. Consider a simplified one-dimensional model where the displacement of a particle over a single time step is a random variable. The total displacement, $X$, after a large number of such time steps is found to follow a symmetric $\\alpha$-stable distribution. This type of distribution is characterized by a stability index $\\alpha$, where $0  \\alpha \\le 2$. For a particular turbulent plasma environment, experimental data suggests that the particle displacement $X$ is well-described by a symmetric stable distribution with a stability index of $\\alpha = 1.7$.\n\nA researcher is interested in characterizing the statistical properties of this displacement. Which of the following statistical measures are guaranteed to be finite for the random variable $X$?\n\nA. The mean displacement, $E[X]$.\n\nB. The mean squared displacement, $E[X^2]$.\n\nC. The mean absolute displacement, $E[|X|]$.\n\nD. The mean cubed absolute displacement, $E[|X|^3]$.", "solution": "Let $X$ be a symmetric $\\alpha$-stable random variable with stability index $\\alpha \\in (0,2]$. A fundamental property of symmetric $\\alpha$-stable laws is that absolute moments exist if and only if the order is strictly less than $\\alpha$:\n$$\nE\\!\\left[|X|^{p}\\right]  \\infty \\quad \\text{if and only if} \\quad 0  p  \\alpha,\n$$\nand $E\\!\\left[|X|^{p}\\right] = \\infty$ for $p \\ge \\alpha$, with the special case $\\alpha=2$ (Gaussian) having all moments finite.\n\nThis can be seen using the tail behavior. For large $x$, symmetric $\\alpha$-stable distributions satisfy\n$$\n\\mathbb{P}(|X| > x) \\sim C x^{-\\alpha},\n$$\nfor some constant $C0$. Using the identity\n$$\nE\\!\\left[|X|^{p}\\right] = \\int_{0}^{\\infty} p x^{p-1} \\mathbb{P}(|X|x)\\,dx,\n$$\nthe integrand behaves as $x^{p-1-\\alpha}$ for large $x$, which is integrable at infinity if and only if $p-\\alpha0$, i.e., $p\\alpha$.\n\nRegarding the ordinary mean $E[X]$, for a symmetric $\\alpha$-stable $X$, the mean exists and is finite if $\\alpha1$. Moreover, since $E[X]$ exists whenever $E[|X|]$ is finite, and $E[|X|]$ is finite for $\\alpha1$, it follows that $E[X]$ is finite for $\\alpha1$.\n\nNow apply these facts to $\\alpha=1.7$:\n- For A (mean displacement $E[X]$): since $\\alpha=1.71$, $E[X]$ exists and is finite.\n- For B (mean squared displacement $E[X^{2}]$): this is the $p=2$ moment. Because $2 \\ge \\alpha=1.7$ and $\\alpha2$, $E[X^{2}]$ is not finite.\n- For C (mean absolute displacement $E[|X|]$): this is the $p=1$ moment. Since $1\\alpha=1.7$, $E[|X|]$ is finite.\n- For D (mean cubed absolute displacement $E[|X|^{3}]$): here $p=3\\alpha=1.7$, so it is not finite.\n\nTherefore, the guaranteed finite quantities are A and C.", "answer": "$$\\boxed{AC}$$", "id": "1332660"}]}