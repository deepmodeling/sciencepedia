{"hands_on_practices": [{"introduction": "To begin, letâ€™s ground our understanding of total variation distance with a clear, tangible example. This first exercise uses the intuitive scenario of a robot moving on a square track to introduce the fundamental computation. By comparing the robot's position distribution after just one step to the long-term uniform distribution, we can directly apply the definition of total variation distance and build a solid foundation for a concept that measures the largest possible difference in probability between two distributions for the same event [@problem_id:1346637].", "problem": "A small maintenance robot moves on a square-shaped track. The track has four service stations located at its vertices, which we label $V_1, V_2, V_3, V_4$ in a counter-clockwise manner. The robot's movement is governed by a simple random process. At each step, from its current station, the robot moves to one of its two adjacent stations with equal probability.\n\nThe robot begins at station $V_1$. Let $\\mu_1$ be the probability distribution of the robot's location after exactly one move, and let $\\pi$ be the uniform probability distribution over the four stations.\n\nCalculate the total variation distance between the distributions $\\mu_1$ and $\\pi$.", "solution": "Let the state space be $\\{V_{1},V_{2},V_{3},V_{4}\\}$. The robot starts at $V_{1}$. In one move, it goes to either adjacent vertex with equal probability, so\n$$\n\\mu_{1}(V_{2})=\\frac{1}{2},\\quad \\mu_{1}(V_{4})=\\frac{1}{2},\\quad \\mu_{1}(V_{1})=0,\\quad \\mu_{1}(V_{3})=0.\n$$\nThe uniform distribution $\\pi$ on the four vertices assigns\n$$\n\\pi(V_{i})=\\frac{1}{4}\\quad \\text{for }i\\in\\{1,2,3,4\\}.\n$$\nThe total variation distance between two distributions $P$ and $Q$ on a finite set is\n$$\nd_{\\mathrm{TV}}(P,Q)=\\frac{1}{2}\\sum_{x}|P(x)-Q(x)|.\n$$\nApplying this to $\\mu_{1}$ and $\\pi$, we compute the absolute differences:\n$$\n|\\mu_{1}(V_{1})-\\pi(V_{1})|=\\left|0-\\frac{1}{4}\\right|=\\frac{1}{4},\\quad\n|\\mu_{1}(V_{2})-\\pi(V_{2})|=\\left|\\frac{1}{2}-\\frac{1}{4}\\right|=\\frac{1}{4},\n$$\n$$\n|\\mu_{1}(V_{3})-\\pi(V_{3})|=\\left|0-\\frac{1}{4}\\right|=\\frac{1}{4},\\quad\n|\\mu_{1}(V_{4})-\\pi(V_{4})|=\\left|\\frac{1}{2}-\\frac{1}{4}\\right|=\\frac{1}{4}.\n$$\nSumming gives $\\sum_{i=1}^{4}|\\mu_{1}(V_{i})-\\pi(V_{i})|=1$, hence\n$$\nd_{\\mathrm{TV}}(\\mu_{1},\\pi)=\\frac{1}{2}\\cdot 1=\\frac{1}{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1346637"}, {"introduction": "Building on the basic calculation, we now move to a more general case where a system's behavior is defined not by simple geometry, but by a transition probability matrix. This practice problem requires using the matrix to determine the system's state after one step and then calculating its total variation distance from the stationary distribution. This exercise is valuable as it connects the abstract mechanics of matrix multiplication to the tangible outcome of a probability distribution and highlights how properties of the matrix, such as being doubly stochastic, can inform us about the stationary state of the system [@problem_id:1346634].", "problem": "A particle performs a random walk on a set of four sites, labeled $S = \\{1, 2, 3, 4\\}$. The movement is modeled as a discrete-time Markov chain. The transition probability matrix $P$, where the entry $P_{ij}$ is the probability of moving from site $i$ to site $j$ in one step, is given by:\n$$\nP = \\begin{pmatrix}\n0.4 & 0.3 & 0.2 & 0.1 \\\\\n0.1 & 0.4 & 0.3 & 0.2 \\\\\n0.2 & 0.1 & 0.4 & 0.3 \\\\\n0.3 & 0.2 & 0.1 & 0.4\n\\end{pmatrix}\n$$\nThe chain has a uniform stationary distribution $\\pi_{\\text{stat}}$, where the probability of being at any site is equal.\n\nSuppose the particle starts at site 1 at time $t=0$. Let $\\pi_1$ be the probability distribution of the particle's location at time $t=1$. Calculate the total variation distance between the distribution $\\pi_1$ and the stationary distribution $\\pi_{\\text{stat}}$.\n\nExpress your final answer as an exact decimal.", "solution": "We are given a discrete-time Markov chain on $S=\\{1,2,3,4\\}$ with transition matrix $P$ and an initial condition that the particle starts at site $1$ at time $t=0$. Denote the distribution at time $t$ by $\\pi_{t}$. Then the initial distribution is\n$$\n\\pi_{0} = (1,0,0,0).\n$$\nThe distribution after one step is obtained by multiplying the initial distribution by the transition matrix:\n$$\n\\pi_{1} = \\pi_{0} P.\n$$\nSince $\\pi_{0}$ is the unit vector at state $1$, $\\pi_{1}$ is equal to the first row of $P$:\n$$\n\\pi_{1} = (0.4, 0.3, 0.2, 0.1).\n$$\nBecause $P$ is doubly stochastic (each column sums to $1$), the uniform distribution is stationary. Therefore,\n$$\n\\pi_{\\text{stat}} = \\left(\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}\\right) = (0.25, 0.25, 0.25, 0.25).\n$$\nThe total variation distance between two distributions $p$ and $q$ on a finite set is\n$$\nd_{\\text{TV}}(p,q) = \\frac{1}{2} \\sum_{i} |p_{i} - q_{i}|.\n$$\nApplying this to $\\pi_{1}$ and $\\pi_{\\text{stat}}$ gives\n$$\nd_{\\text{TV}}(\\pi_{1}, \\pi_{\\text{stat}}) = \\frac{1}{2}\\left(|0.4 - 0.25| + |0.3 - 0.25| + |0.2 - 0.25| + |0.1 - 0.25|\\right).\n$$\nCompute each absolute difference:\n$$\n|0.4 - 0.25| = 0.15,\\quad |0.3 - 0.25| = 0.05,\\quad |0.2 - 0.25| = 0.05,\\quad |0.1 - 0.25| = 0.15.\n$$\nSumming,\n$$\n0.15 + 0.05 + 0.05 + 0.15 = 0.40.\n$$\nTherefore,\n$$\nd_{\\text{TV}}(\\pi_{1}, \\pi_{\\text{stat}}) = \\frac{1}{2} \\times 0.40 = 0.20.\n$$\nHence, the total variation distance is the exact decimal $0.2$.", "answer": "$$\\boxed{0.2}$$", "id": "1346634"}, {"introduction": "Beyond calculating distance at a single point in time, a key application of total variation distance is to understand how quickly a Markov chain converges to its equilibrium. This final exercise explores the dynamics of this convergence process, addressing the question: how fast does a system \"forget\" its initial state? By calculating the number of steps required for the distance to the stationary distribution to be halved, you will gain a hands-on feel for the concept of convergence rate, a crucial metric in analyzing the efficiency and long-term behavior of stochastic processes [@problem_id:1346612].", "problem": "Consider a simple model for the evolution of an opinion in a two-option system, for example, a voter choosing between party A and party B. We model the voter's choice as a state in a two-state system, with states labeled as $\\{A, B\\}$. Initially, at time $t=0$, the voter supports party A.\n\nAt each subsequent discrete time step, the voter reconsiders their position. The voter stays with their current party with a probability $p$, or switches to the other party with probability $1-p$. This process is a Markov chain. The specific probability of staying with the current party is given by $p = \\frac{1}{2} + \\frac{\\sqrt{2}}{4}$. Over a long period, this process approaches a stationary distribution $\\pi$, where the voter is equally likely to support either party.\n\nLet $\\mu_t$ be the probability distribution describing the voter's party preference at time step $t$. The dissimilarity between the distribution at time $t$ and the stationary distribution is measured by the total variation distance, denoted $d_t$.\n\nDetermine the exact integer number of time steps, $t$, required for the total variation distance $d_t$ to become precisely one-half of its initial value, $d_0$.", "solution": "Let the state space be $\\{A,B\\}$ and order coordinates as $(A,B)$. The transition matrix is\n$$\nP=\\begin{pmatrix}\np & 1-p\\\\\n1-p & p\n\\end{pmatrix},\n$$\nwith $p=\\frac{1}{2}+\\frac{\\sqrt{2}}{4}$. The stationary distribution is $\\pi=\\left(\\frac{1}{2},\\frac{1}{2}\\right)$ by symmetry. Let $x_{t}=\\Pr(\\text{state}=A\\text{ at time }t)$. Then $\\mu_{t}=(x_{t},1-x_{t})$ and the total variation distance is\n$$\nd_{t}=\\frac{1}{2}\\left(\\left|x_{t}-\\frac{1}{2}\\right|+\\left|1-x_{t}-\\frac{1}{2}\\right|\\right)=\\left|x_{t}-\\frac{1}{2}\\right|.\n$$\n\nThe one-step update for $x_{t}$ is\n$$\nx_{t+1}=p x_{t}+(1-p)(1-x_{t})=(2p-1)x_{t}+(1-p).\n$$\nSubtracting $\\frac{1}{2}$ gives\n$$\nx_{t+1}-\\frac{1}{2}=(2p-1)\\left(x_{t}-\\frac{1}{2}\\right),\n$$\nso by induction\n$$\nx_{t}-\\frac{1}{2}=(2p-1)^{t}\\left(x_{0}-\\frac{1}{2}\\right).\n$$\nWith the initial condition $x_{0}=1$, we have $x_{0}-\\frac{1}{2}=\\frac{1}{2}$, hence\n$$\nd_{t}=\\left|x_{t}-\\frac{1}{2}\\right|=\\frac{1}{2}\\left|2p-1\\right|^{t}.\n$$\nAlso $d_{0}=\\frac{1}{2}$, so\n$$\nd_{t}=d_{0}\\left|2p-1\\right|^{t}.\n$$\nCompute $2p-1$:\n$$\n2p-1=2\\left(\\frac{1}{2}+\\frac{\\sqrt{2}}{4}\\right)-1=\\frac{\\sqrt{2}}{2}.\n$$\nTherefore\n$$\nd_{t}=d_{0}\\left(\\frac{\\sqrt{2}}{2}\\right)^{t}.\n$$\nWe require $d_{t}=\\frac{1}{2}d_{0}$, so\n$$\n\\left(\\frac{\\sqrt{2}}{2}\\right)^{t}=\\frac{1}{2}.\n$$\nSince $\\frac{\\sqrt{2}}{2}=2^{-1/2}$, this is $2^{-t/2}=2^{-1}$, which yields $t=2$.", "answer": "$$\\boxed{2}$$", "id": "1346612"}]}