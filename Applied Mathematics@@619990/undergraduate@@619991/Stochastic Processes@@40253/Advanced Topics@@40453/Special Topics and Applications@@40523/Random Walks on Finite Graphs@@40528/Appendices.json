{"hands_on_practices": [{"introduction": "To begin our exploration of random walks, we start with the most fundamental question: where might the walker be after a few steps? This exercise [@problem_id:1329644] provides a simple three-state system, analogous to a particle moving on a short path, to calculate the probability of being at a specific location after a fixed number of transitions. By systematically tracing the possible paths and their associated probabilities, you will build a solid intuition for the core mechanics of a discrete-time Markov chain, the mathematical engine that drives random walks.", "problem": "A simplified one-dimensional model for the conformational dynamics of a small molecule considers three distinct states, labeled 1, 2, and 3. The molecule can transition between these states at discrete time steps. The states are arranged linearly, such that transitions are only possible between adjacent states (i.e., between state 1 and 2, and between state 2 and 3).\n\nThe transition rules are as follows:\n- At each time step, from any state $S$, the molecule has a probability of $1/2$ of remaining in state $S$.\n- With the remaining probability of $1/2$, the molecule attempts to transition to an adjacent state.\n- If the molecule is in state 2, which has two adjacent states (1 and 3), it will move to state 1 with probability $1/4$ and to state 3 with probability $1/4$.\n- If the molecule is in an end state (1 or 3), which has only one adjacent state, it will move to that adjacent state (state 2) with probability $1/2$.\n\nSuppose the molecule is in state 1 at time $t=0$. What is the probability that the molecule is in state 3 after exactly 3 time steps?", "solution": "We model the system as a discrete-time Markov chain on states $\\{1,2,3\\}$ with transition probabilities defined by the rules:\n- From state $1$: $\\Pr(1\\to 1)=\\frac{1}{2}$, $\\Pr(1\\to 2)=\\frac{1}{2}$, $\\Pr(1\\to 3)=0$.\n- From state $2$: $\\Pr(2\\to 1)=\\frac{1}{4}$, $\\Pr(2\\to 2)=\\frac{1}{2}$, $\\Pr(2\\to 3)=\\frac{1}{4}$.\n- From state $3$: $\\Pr(3\\to 2)=\\frac{1}{2}$, $\\Pr(3\\to 3)=\\frac{1}{2}$, $\\Pr(3\\to 1)=0$.\n\nLet $X_{t}$ denote the state at time $t$, with $X_{0}=1$. By the Markov property and the law of total probability applied to the last step,\n$$\n\\Pr(X_{3}=3 \\mid X_{0}=1)\n= \\Pr(X_{2}=3 \\mid X_{0}=1)\\Pr(3\\to 3) + \\Pr(X_{2}=2 \\mid X_{0}=1)\\Pr(2\\to 3).\n$$\nFrom the transition rules, $\\Pr(3\\to 3)=\\frac{1}{2}$ and $\\Pr(2\\to 3)=\\frac{1}{4}$. We now compute the two-step probabilities $\\Pr(X_{2}=3 \\mid X_{0}=1)$ and $\\Pr(X_{2}=2 \\mid X_{0}=1)$ by enumerating all two-step paths:\n\nFor $\\Pr(X_{2}=3 \\mid X_{0}=1)$, the only feasible two-step path from $1$ to $3$ is $1\\to 2\\to 3$, hence\n$$\n\\Pr(X_{2}=3 \\mid X_{0}=1) = \\Pr(1\\to 2)\\Pr(2\\to 3) = \\frac{1}{2}\\cdot \\frac{1}{4} = \\frac{1}{8}.\n$$\nFor $\\Pr(X_{2}=2 \\mid X_{0}=1)$, the feasible two-step paths from $1$ to $2$ are $1\\to 1\\to 2$ and $1\\to 2\\to 2$, hence\n$$\n\\Pr(X_{2}=2 \\mid X_{0}=1) = \\Pr(1\\to 1)\\Pr(1\\to 2) + \\Pr(1\\to 2)\\Pr(2\\to 2) = \\frac{1}{2}\\cdot \\frac{1}{2} + \\frac{1}{2}\\cdot \\frac{1}{2} = \\frac{1}{2}.\n$$\nSubstituting into the decomposition gives\n$$\n\\Pr(X_{3}=3 \\mid X_{0}=1) = \\frac{1}{8}\\cdot \\frac{1}{2} + \\frac{1}{2}\\cdot \\frac{1}{4} = \\frac{1}{16} + \\frac{1}{8} = \\frac{3}{16}.\n$$\nTherefore, the probability that the molecule is in state $3$ after exactly $3$ time steps, starting from state $1$, is $\\frac{3}{16}$.", "answer": "$$\\boxed{\\frac{3}{16}}$$", "id": "1329644"}, {"introduction": "Beyond knowing where a walk might be at a fixed time, we are often interested in how long it takes to reach a target. This problem [@problem_id:1329640] introduces the concept of the expected hitting time, a crucial metric in applications ranging from web search algorithms to the study of chemical reactions. You will use a powerful and elegant technique called first-step analysis, which involves setting up a system of linear equations to find the average time it takes to first reach a destination state.", "problem": "An automated cleaning robot moves along a narrow hallway connecting three rooms, which we can label as positions 1, 2, and 3, in a straight line. Position 2 is in the middle, adjacent to both 1 and 3. Positions 1 and 3 are at the ends of the hallway, each adjacent only to position 2.\n\nThe robot starts at position 1. At each time step, it moves from its current position to an adjacent position. The choice of which adjacent position to move to is made uniformly at random. For example, from position 2, it moves to position 1 with probability 1/2 and to position 3 with probability 1/2. From an end position (1 or 3), it has only one adjacent position, so it moves there with probability 1.\n\nThe robot's task is considered complete once it reaches position 3 for the first time. Calculate the expected number of steps required for the robot to complete its task.", "solution": "Define the Markov chain on positions $\\{1,2,3\\}$, with absorbing target at position $3$ (the task completes upon first hitting $3$). Let $T$ be the hitting time of state $3$, and let $E_{i}=\\mathbb{E}[T\\mid \\text{start at }i]$ for $i\\in\\{1,2,3\\}$.\n\nBy the Markov property and the law of total expectation (first-step analysis):\n- From position $3$, the task is complete, so $E_{3}=0$.\n- From position $1$, the robot deterministically moves to $2$ in one step, so\n$$\nE_{1}=1+E_{2}.\n$$\n- From position $2$, the robot moves to $1$ with probability $\\frac{1}{2}$ and to $3$ with probability $\\frac{1}{2}$, incurring one step plus the remaining expected time, hence\n$$\nE_{2}=1+\\frac{1}{2}E_{1}+\\frac{1}{2}E_{3}.\n$$\n\nUsing $E_{3}=0$, we have\n$$\nE_{2}=1+\\frac{1}{2}E_{1}.\n$$\nSubstitute this into $E_{1}=1+E_{2}$:\n$$\nE_{1}=1+\\left(1+\\frac{1}{2}E_{1}\\right)=2+\\frac{1}{2}E_{1}.\n$$\nRearrange to solve for $E_{1}$:\n$$\nE_{1}-\\frac{1}{2}E_{1}=2 \\quad \\Rightarrow \\quad \\frac{1}{2}E_{1}=2 \\quad \\Rightarrow \\quad E_{1}=4.\n$$\n\nTherefore, the expected number of steps required to reach position $3$ starting from position $1$ is $4$.", "answer": "$$\\boxed{4}$$", "id": "1329640"}, {"introduction": "Having explored the short-term and goal-oriented properties of random walks, we now turn to their ultimate fate. If a walk runs for a very long time, do the probabilities of being at each vertex settle down into a stable equilibrium? This question leads us to the concept of the stationary distribution, which describes the long-run fraction of time the process spends in each state. This exercise [@problem_id:1329662] reveals a powerful insight by comparing a simple random walk with a \"lazy\" variant, demonstrating how the long-term behavior is fundamentally connected to the structure of the underlying graph.", "problem": "Consider a system with three discrete states, labeled $\\{1, 2, 3\\}$. The states are arranged in a linear chain, such that state 1 is connected only to state 2, state 3 is connected only to state 2, and state 2 is connected to both 1 and 3. Two different random walk processes are defined on this set of states.\n\n**Process 1: Simple Random Walk**\nA particle evolves in discrete time steps. At each step, a particle at its current state moves to one of its connected neighboring states. The particle chooses each neighbor with equal probability.\n\n**Process 2: Lazy Random Walk**\nThis process also evolves in discrete time steps. At each step, the particle has a probability of $\\frac{1}{2}$ to remain in its current state. With the remaining probability of $\\frac{1}{2}$, it moves to one of its connected neighbors, choosing each neighbor with equal probability.\n\nLet $\\pi_S = (\\pi_1^S, \\pi_2^S, \\pi_3^S)$ denote the stationary probability distribution for the simple random walk, and let $\\pi_L = (\\pi_1^L, \\pi_2^L, \\pi_3^L)$ denote the stationary probability distribution for the lazy random walk. In this notation, $\\pi_i$ represents the long-term probability of finding the particle in state $i$.\n\nWhich of the following statements correctly describes the relationship between $\\pi_S$ and $\\pi_L$?\n\nA. $\\pi_S = \\pi_L$.\n\nB. The lazy walk increases the probability of being at the central state, i.e., $\\pi_2^L > \\pi_2^S$.\n\nC. The lazy walk increases the probability of being at the end states, i.e., $\\pi_1^L > \\pi_1^S$ and $\\pi_3^L > \\pi_3^S$.\n\nD. The stationary distribution for the lazy walk is a uniform distribution, i.e., $\\pi_L = (1/3, 1/3, 1/3)$.\n\nE. A stationary distribution for the simple random walk, $\\pi_S$, does not exist because the chain is periodic.", "solution": "We model the three states as the path graph with vertices $\\{1,2,3\\}$ and edges $\\{(1,2),(2,3)\\}$. The degrees are $d_{1}=1$, $d_{2}=2$, and $d_{3}=1$, with $\\sum_{i=1}^{3} d_{i}=4$.\n\nFor the simple random walk, the transition probabilities are $P_{ij}^{S}=\\frac{1}{d_{i}}$ if $i$ and $j$ are adjacent and $0$ otherwise. In the state order $(1,2,3)$ this gives\n$$\nP_{S}=\\begin{pmatrix}\n0 & 1 & 0\\\\\n\\frac{1}{2} & 0 & \\frac{1}{2}\\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nA standard sufficient condition for stationarity is detailed balance. Define $\\pi_{i}^{S}=\\frac{d_{i}}{\\sum_{k} d_{k}}$, i.e.,\n$$\n\\pi^{S}=\\left(\\frac{1}{4},\\frac{1}{2},\\frac{1}{4}\\right).\n$$\nThen for adjacent $i$ and $j$,\n$$\n\\pi_{i}^{S} P_{ij}^{S}=\\frac{d_{i}}{4}\\cdot\\frac{1}{d_{i}}=\\frac{1}{4}=\\frac{d_{j}}{4}\\cdot\\frac{1}{d_{j}}=\\pi_{j}^{S} P_{ji}^{S},\n$$\nand for non-adjacent pairs both sides are $0$. Hence detailed balance holds, so $\\pi^{S}$ is stationary for $P_{S}$. Although $P_{S}$ is periodic (period $2$) because the graph is bipartite, the chain is finite and irreducible, so a unique stationary distribution exists; periodicity affects convergence but not existence.\n\nFor the lazy random walk, the transition matrix is\n$$\nP_{L}=\\frac{1}{2} I+\\frac{1}{2} P_{S}=\\begin{pmatrix}\n\\frac{1}{2} & \\frac{1}{2} & 0\\\\\n\\frac{1}{4} & \\frac{1}{2} & \\frac{1}{4}\\\\\n0 & \\frac{1}{2} & \\frac{1}{2}\n\\end{pmatrix}.\n$$\nIf $\\pi$ is stationary for $P_{S}$, then\n$$\n\\pi P_{L}=\\pi\\left(\\frac{1}{2} I+\\frac{1}{2} P_{S}\\right)=\\frac{1}{2}\\pi+\\frac{1}{2}(\\pi P_{S})=\\frac{1}{2}\\pi+\\frac{1}{2}\\pi=\\pi.\n$$\nThus the same $\\pi$ is stationary for $P_{L}$, so $\\pi^{L}=\\pi^{S}=\\left(\\frac{1}{4},\\frac{1}{2},\\frac{1}{4}\\right)$. Consequently:\n- Statement A is true.\n- Statements B and C are false because the stationary distributions are equal.\n- Statement D is false because the stationary distribution is not uniform due to unequal degrees.\n- Statement E is false because a stationary distribution does exist even though the simple chain is periodic.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1329662"}]}