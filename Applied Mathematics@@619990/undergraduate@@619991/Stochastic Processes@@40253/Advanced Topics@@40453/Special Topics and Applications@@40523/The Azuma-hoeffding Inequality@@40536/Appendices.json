{"hands_on_practices": [{"introduction": "We begin our exploration with the most fundamental application of concentration inequalities. This exercise models a series of independent binary tasks, akin to flipping a fair coin many times [@problem_id:1336259]. By applying a core version of the Azuma-Hoeffding inequality (often known simply as Hoeffding's inequality in this context), you will derive a bound on how much the total number of successes can deviate from its expected value, providing a solid foundation for understanding the behavior of sums of random variables.", "problem": "An autonomous system is designed to perform a series of $n$ independent binary tasks. For each task, the system has two possible actions, and only one of them is correct. In its initial, untrained state, the system chooses an action for each task completely at random, with each of the two actions being equally likely. After each task, the system receives feedback indicating whether its chosen action was correct.\n\nLet $C_n$ denote the total number of correctly performed tasks out of the total $n$ tasks. The expected number of successes is $E[C_n]$. We are interested in the probability that the actual number of successes deviates significantly from this expectation.\n\nFor a given positive real number $t$, find a non-trivial upper bound for the probability $P(|C_n - E[C_n]| \\geq t)$. Your answer should be an analytical expression in terms of $n$ and $t$.", "solution": "Define indicator variables $X_{i}$ for $i \\in \\{1,\\dots,n\\}$ by $X_{i}=1$ if the system performs task $i$ correctly and $X_{i}=0$ otherwise. Since in the untrained state each task’s action is chosen uniformly at random from two equally likely options and tasks are independent, the variables $X_{i}$ are independent and identically distributed with $P(X_{i}=1)=\\frac{1}{2}$ and $P(X_{i}=0)=\\frac{1}{2}$. Thus $X_{i} \\in [0,1]$ almost surely and $E[X_{i}]=\\frac{1}{2}$ for all $i$.\n\nThe total number of correctly performed tasks is the sum\n$$\nC_{n}=\\sum_{i=1}^{n} X_{i},\n$$\nand its expectation is\n$$\nE[C_{n}]=\\sum_{i=1}^{n} E[X_{i}]=\\sum_{i=1}^{n} \\frac{1}{2}=\\frac{n}{2}.\n$$\n\nWe apply Hoeffding’s inequality for sums of independent bounded random variables. If $X_{i}$ are independent with $a_{i} \\leq X_{i} \\leq b_{i}$ almost surely, and $S_{n}=\\sum_{i=1}^{n} X_{i}$, then for any $t>0$,\n$$\nP\\big(|S_{n}-E[S_{n}]|\\geq t\\big) \\leq 2 \\exp\\!\\left(-\\frac{2 t^{2}}{\\sum_{i=1}^{n} (b_{i}-a_{i})^{2}}\\right).\n$$\nHere, $a_{i}=0$ and $b_{i}=1$ for all $i$, so $\\sum_{i=1}^{n} (b_{i}-a_{i})^{2}=n$. Substituting $S_{n}=C_{n}$ and this bound into Hoeffding’s inequality yields the non-trivial deviation bound\n$$\nP\\big(|C_{n}-E[C_{n}]|\\geq t\\big) \\leq 2 \\exp\\!\\left(-\\frac{2 t^{2}}{n}\\right).\n$$\nThis is an analytical expression in terms of $n$ and $t$ and applies for all $t>0$.", "answer": "$$\\boxed{2 \\exp\\!\\left(-\\frac{2 t^{2}}{n}\\right)}$$", "id": "1336259"}, {"introduction": "Many real-world processes are not memoryless; the past influences the future. This practice problem models such a scenario, where the probability of an event depends on the previous outcome [@problem_id:1336222]. You will learn to identify and formalize this structure as a martingale, a powerful concept for analyzing 'fair games,' and then apply the Azuma-Hoeffding inequality to bound the total winnings, showcasing the tool's utility beyond simple independent variables.", "problem": "A game of chance consists of a sequence of $n$ coin flips. The outcome of the $i$-th flip is denoted by a random variable $X_i$, with $X_i=1$ if the result is heads and $X_i=0$ if it is tails.\n\nThe probability of heads is not constant. For the first flip ($i=1$), the probability of heads is $p_1 = p$. For any subsequent flip $i > 1$, the probability of heads, $p_i$, is determined by the outcome of the preceding flip, $X_{i-1}$, as follows:\n- If flip $i-1$ was heads ($X_{i-1}=1$), then $p_i = p - \\delta$.\n- If flip $i-1$ was tails ($X_{i-1}=0$), then $p_i = p + \\delta$.\n\nThe parameters $p$ and $\\delta$ are constants satisfying $0 < \\delta < \\min(p, 1-p)$.\n\nA player participates in a betting game based on these flips. At the start of each round $i$ (from $1$ to $n$), the player pays a fee of $p_i$ dollars to play. If the coin flip results in heads ($X_i=1$), the player receives a payout of 1 dollar. If it results in tails ($X_i=0$), the player receives nothing. Let $W_n$ be the player's total net winnings after all $n$ rounds.\n\nFind a simple upper bound for the probability that the magnitude of the player's total net winnings is at least $t$, where $t$ is a positive constant. Express your answer in terms of $n$ and $t$.", "solution": "Let $X_{i}\\in\\{0,1\\}$ be the outcome of flip $i$, and let $p_{i}$ be the fee paid at the start of round $i$, with $p_{1}=p$ and, for $i>1$, $p_{i}=p-\\delta$ if $X_{i-1}=1$ and $p_{i}=p+\\delta$ if $X_{i-1}=0$. The net gain in round $i$ is $X_{i}-p_{i}$, so the total net winnings after $n$ rounds are\n$$\nW_{n}=\\sum_{i=1}^{n}\\left(X_{i}-p_{i}\\right).\n$$\nLet $\\mathcal{F}_{i}=\\sigma(X_{1},\\ldots,X_{i})$ be the natural filtration. By construction of the process, for each $i$,\n$$\n\\mathbb{E}\\!\\left[X_{i}\\mid\\mathcal{F}_{i-1}\\right]=p_{i},\n$$\nhence\n$$\n\\mathbb{E}\\!\\left[X_{i}-p_{i}\\mid\\mathcal{F}_{i-1}\\right]=0.\n$$\nTherefore $\\{W_{i}\\}_{i=0}^{n}$ with $W_{0}=0$ and $W_{i}=\\sum_{j=1}^{i}(X_{j}-p_{j})$ is a martingale.\n\nThe increments satisfy the almost-sure bounds\n$$\n-p_{i}\\leq X_{i}-p_{i}\\leq 1-p_{i},\n$$\nso their range length is\n$$\n(1-p_{i})-(-p_{i})=1\\quad\\text{for every }i.\n$$\nApplying the Azuma–Hoeffding inequality for martingales with differences bounded in intervals $[a_{i},b_{i}]$, which states that\n$$\n\\mathbb{P}\\!\\left(W_{n}\\geq t\\right)\\leq\\exp\\!\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{n}(b_{i}-a_{i})^{2}}\\right),\n$$\nand using $b_{i}-a_{i}=1$ for all $i$, we obtain the one-sided bound\n$$\n\\mathbb{P}\\!\\left(W_{n}\\geq t\\right)\\leq\\exp\\!\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nBy symmetry (or applying the same bound to $-W_{n}$), we get\n$$\n\\mathbb{P}\\!\\left(W_{n}\\leq -t\\right)\\leq\\exp\\!\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nCombining the two tails yields the desired two-sided bound\n$$\n\\mathbb{P}\\!\\left(|W_{n}|\\geq t\\right)\\leq 2\\,\\exp\\!\\left(-\\frac{2t^{2}}{n}\\right).\n$$\nThis bound depends only on $n$ and $t$, as required.", "answer": "$$\\boxed{2\\,\\exp\\!\\left(-\\frac{2t^{2}}{n}\\right)}$$", "id": "1336222"}, {"introduction": "Finally, we generalize our perspective from simple sums to complex functions of many random variables. This exercise explores a practical computer science problem: analyzing the performance of a web server's cache [@problem_id:1336195]. You will use a powerful consequence of the Azuma-Hoeffding inequality, often called the method of bounded differences, which relies on the insight that changing a single input has a limited impact on the overall output. This demonstrates how concentration inequalities provide robust performance guarantees for complex algorithms and systems.", "problem": "A web server utilizes a cache of size $k=50$ to speed up access to a large collection of $m=5000$ unique files. The server processes a sequence of $N=2 \\times 10^6$ file requests. This sequence of requests, denoted $R_1, R_2, \\dots, R_N$, can be accurately modeled as a series of independent random variables, where each $R_i$ is drawn uniformly from the set of $m$ available files.\n\nThe cache employs a Least-Recently-Used (LRU) replacement policy. When a requested file is found in the cache, it's a \"hit,\" and the file is marked as the most recently used. If the file is not in the cache, it's a \"miss.\" In the event of a miss, the file is fetched from storage and placed in the cache. If the cache is already full, the least recently used file is evicted to make room.\n\nLet $H$ be the total number of cache hits over the sequence of $N$ requests. The value of $H$ is a random variable that depends on the specific sequence of requests. A known, non-trivial result from computer science theory states that the function which maps a request sequence to the total number of hits has a \"bounded difference\" property: changing a single request $R_i$ in the sequence can change the final value of $H$ by at most 2.\n\nUsing this information, determine an upper bound on the probability that the total number of hits $H$ deviates from its expected value $\\mathbb{E}[H]$ by more than $0.25\\%$ of the total number of requests. Express your answer as a numerical value, rounded to two significant figures.", "solution": "We model $H$ as a function $f(R_{1},\\dots,R_{N})$ of independent requests. The given bounded-difference property states that changing a single coordinate $R_{i}$ can change $H$ by at most $2$, so for all $i$ we have a Lipschitz constant $c_{i}=2$.\n\nBy McDiarmid’s inequality (bounded differences), for any $t>0$,\n$$\n\\Pr\\!\\left(H-\\mathbb{E}[H]\\ge t\\right)\\le \\exp\\!\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{N} c_{i}^{2}}\\right),\n$$\nand by symmetry,\n$$\n\\Pr\\!\\left(|H-\\mathbb{E}[H]|\\ge t\\right)\\le 2\\exp\\!\\left(-\\frac{2t^{2}}{\\sum_{i=1}^{N} c_{i}^{2}}\\right).\n$$\nHere $\\sum_{i=1}^{N} c_{i}^{2}=N\\cdot 2^{2}=4N$, hence\n$$\n\\Pr\\!\\left(|H-\\mathbb{E}[H]|\\ge t\\right)\\le 2\\exp\\!\\left(-\\frac{t^{2}}{2N}\\right).\n$$\n\nWe seek the deviation threshold $t$ equal to $0.0025$ of the total number of requests, i.e., $t=0.0025\\,N$. Substituting gives\n$$\n\\Pr\\!\\left(|H-\\mathbb{E}[H]|\\ge 0.0025\\,N\\right)\\le 2\\exp\\!\\left(-\\frac{(0.0025\\,N)^{2}}{2N}\\right)\n=2\\exp\\!\\left(-\\frac{0.0025^{2}\\,N}{2}\\right).\n$$\nWith $N=2\\times 10^{6}$, compute the exponent:\n$$\n0.0025^{2}=6.25\\times 10^{-6},\\quad \\frac{0.0025^{2}\\,N}{2}=\\frac{6.25\\times 10^{-6}\\cdot 2\\times 10^{6}}{2}=6.25,\n$$\nso the bound is\n$$\n2\\exp(-6.25)\\approx 3.9\\times 10^{-3},\n$$\nrounded to two significant figures.", "answer": "$$\\boxed{3.9 \\times 10^{-3}}$$", "id": "1336195"}]}