{"hands_on_practices": [{"introduction": "The journey into applying Large Deviations Theory often begins with the Gaussian, or Normal, distribution, as its elegant mathematical properties provide the clearest possible illustration of the core machinery. In this first exercise, we will derive the rate function for the sample mean of standard Normal random variables. This practice is foundational; it not only introduces you to the essential steps of applying Cramér's theorem but also reveals a fundamental connection between the form of the Normal distribution and the quadratic nature of its rate function [@problem_id:1309800].", "id": "1309800", "problem": "Consider a sequence of random variables $X_1, X_2, \\dots, X_n$, which represent a series of measurements of a physical system subject to random noise. These measurements are assumed to be independent and identically distributed (i.i.d.). Each measurement $X_i$ is drawn from a standard Normal distribution, which has a mean of 0 and a variance of 1.\n\nThe sample mean of these measurements is defined as $S_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$. By the law of large numbers, as $n$ becomes very large, the sample mean $S_n$ is expected to converge to the true mean of the distribution, which is 0.\n\nHowever, there is a small but non-zero probability that the sample mean will deviate significantly from 0. The Large Deviation Principle provides a framework for quantifying the exponential decay of this probability. For large $n$, the probability that the sample mean is close to a value $x \\neq 0$ is approximated by the relationship:\n$$\nP(S_n \\approx x) \\approx \\exp(-n I(x))\n$$\nThe function $I(x)$ is known as the rate function. It is non-negative, with $I(0)=0$, and it measures how unlikely it is to observe the sample mean deviating to the value $x$. Your task is to determine the explicit functional form of this rate function $I(x)$ for the given sequence of i.i.d. standard Normal random variables.\n\nYour final answer should be an expression for $I(x)$ in terms of $x$.\n\n", "solution": "We are given i.i.d. $X_{i} \\sim \\mathcal{N}(0,1)$ and the sample mean $S_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$. By Cramér’s theorem (or the Gärtner–Ellis theorem under smoothness), the large deviations rate function for $S_{n}$ is the Legendre–Fenchel transform of the cumulant generating function of a single $X_{1}$.\n\nFirst compute the moment generating function of $X_{1}$:\n$$\nM_{X}(t)=\\mathbb{E}[\\exp(tX_{1})]=\\int_{-\\infty}^{\\infty}\\exp(tx)\\,\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{x^{2}}{2}\\right)\\,dx.\n$$\nCombine exponents by completing the square:\n$$\n-\\frac{x^{2}}{2}+tx=-\\frac{1}{2}\\left(x^{2}-2tx\\right)=-\\frac{1}{2}\\left[(x-t)^{2}-t^{2}\\right]=-\\frac{(x-t)^{2}}{2}+\\frac{t^{2}}{2}.\n$$\nHence\n$$\nM_{X}(t)=\\exp\\!\\left(\\frac{t^{2}}{2}\\right)\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{(x-t)^{2}}{2}\\right)\\,dx=\\exp\\!\\left(\\frac{t^{2}}{2}\\right).\n$$\nTherefore the cumulant generating function is\n$$\n\\Lambda(t)=\\ln M_{X}(t)=\\frac{t^{2}}{2}, \\quad t\\in\\mathbb{R}.\n$$\nBy Cramér’s theorem, the good rate function for $S_{n}$ is the Legendre–Fenchel transform of $\\Lambda$:\n$$\nI(x)=\\sup_{t\\in\\mathbb{R}}\\{tx-\\Lambda(t)\\}=\\sup_{t\\in\\mathbb{R}}\\left\\{tx-\\frac{t^{2}}{2}\\right\\}.\n$$\nTo maximize the concave quadratic in $t$, differentiate with respect to $t$ and set to zero:\n$$\n\\frac{d}{dt}\\left(tx-\\frac{t^{2}}{2}\\right)=x-t=0 \\quad \\Rightarrow \\quad t=x.\n$$\nEvaluating at $t=x$ gives\n$$\nI(x)=x\\cdot x-\\frac{x^{2}}{2}=\\frac{x^{2}}{2}.\n$$\nThis $I(x)$ is nonnegative and satisfies $I(0)=0$, as required.", "answer": "$$\\boxed{\\frac{x^{2}}{2}}$$"}, {"introduction": "Moving from the idealized world of the Normal distribution, we now tackle a problem with direct applications in engineering and reliability theory. Exponentially distributed random variables are a standard model for the lifetimes of components or the waiting times between events. This practice challenges you to use the large deviation framework to quantify the risk of a system-wide failure, defined as the average component lifetime being significantly shorter than expected, demonstrating how abstract rate functions translate into concrete risk assessment [@problem_id:1309802].", "id": "1309802", "problem": "A company manufactures a specialized type of electronic capacitor. The time-to-failure for each capacitor, measured in hours, is a random variable. A large number of these capacitors, $n$, are used in a new high-reliability server farm. The lifetimes of the capacitors, denoted by $X_1, X_2, \\ldots, X_n$, are modeled as Independent and Identically Distributed (IID) exponential random variables with a rate parameter $\\lambda > 0$. The probability density function for the lifetime $X_i$ of a single capacitor is given by $f(x) = \\lambda \\exp(-\\lambda x)$ for $x \\ge 0$.\n\nThe reliability of the server farm is assessed by observing the sample mean of the component lifetimes, $M_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$. The theory of large deviations states that for a very large $n$, the probability that the sample mean $M_n$ deviates from its expected value can be approximated as $P(M_n \\leq a) \\approx \\exp(-n \\cdot I(a))$ for values of $a$ less than the true mean. The function $I(a)$ is known as the large deviation rate function, which measures the exponential rate of decay of this probability.\n\nA major system-wide risk is declared if the observed sample mean lifetime of the capacitors is less than or equal to half of their theoretical expected lifetime. Calculate the value of the rate function $I(a)$ for this specific risk scenario. Your final answer should be a closed-form analytic expression that does not depend on the parameter $\\lambda$.\n\n", "solution": "Let $X$ be an exponential random variable with rate $\\lambda>0$, so $f(x)=\\lambda \\exp(-\\lambda x)$ for $x\\ge 0$. Its moment generating function for $t<\\lambda$ is\n$$\nM_{X}(t)=\\mathbb{E}[\\exp(tX)]=\\int_{0}^{\\infty}\\lambda \\exp\\big(-( \\lambda - t )x\\big)\\,dx=\\frac{\\lambda}{\\lambda - t},\n$$\nhence the cumulant generating function is\n$$\n\\Lambda(t)=\\ln M_{X}(t)=\\ln \\lambda - \\ln(\\lambda - t).\n$$\nBy Cramér’s theorem, the large deviation rate function for the sample mean is the Legendre-Fenchel transform\n$$\nI(a)=\\sup_{t<\\lambda}\\{t a - \\Lambda(t)\\}.\n$$\nTo find the maximizer, differentiate:\n$$\n\\frac{d}{dt}\\big[t a - \\Lambda(t)\\big]=a+\\frac{d}{dt}\\ln(\\lambda - t)=a-\\frac{1}{\\lambda - t}.\n$$\nSetting this to zero gives $a=\\frac{1}{\\lambda - t}$, so the maximizer is $t^{\\star}=\\lambda - \\frac{1}{a}$. Substituting $t^{\\star}$ back,\n$$\n\\Lambda(t^{\\star})=\\ln \\lambda - \\ln\\!\\big(\\lambda - t^{\\star}\\big)=\\ln \\lambda - \\ln\\!\\Big(\\frac{1}{a}\\Big)=\\ln(\\lambda a),\n$$\nand\n$$\nI(a)=t^{\\star}a-\\Lambda(t^{\\star})=\\Big(\\lambda - \\frac{1}{a}\\Big)a - \\ln(\\lambda a)=\\lambda a - 1 - \\ln(\\lambda a).\n$$\nIn the given risk scenario, $a$ is half the mean lifetime. Since $\\mathbb{E}[X]=\\frac{1}{\\lambda}$, we have\n$$\na=\\frac{1}{2}\\mathbb{E}[X]=\\frac{1}{2\\lambda},\n$$\nso $\\lambda a=\\frac{1}{2}$ and therefore\n$$\nI(a)=\\frac{1}{2}-1-\\ln\\!\\Big(\\frac{1}{2}\\Big)=-\\frac{1}{2}+\\ln 2.\n$$\nThis expression does not depend on $\\lambda$, as required.", "answer": "$$\\boxed{\\ln 2 - \\frac{1}{2}}$$"}, {"introduction": "Our final practice explores the realm of discrete random variables and demonstrates one of the most powerful applications of large deviation principles: calculating explicit probability bounds. Using the Poisson distribution, a cornerstone for modeling count data, you will employ the Chernoff bounding technique to estimate the probability of observing an anomalously high number of events. This exercise shifts the perspective from simply finding the asymptotic rate $I(x)$ to using it to compute a tangible, numerical upper limit on the probability of a specific rare event [@problem_id:1309801].", "id": "1309801", "problem": "A research facility operates a large array of $n$ independent and identical particle detectors to monitor background radiation. For a given time interval, the number of particles, $X_i$, detected by the $i$-th detector is well-modeled by a Poisson random variable with a mean of $\\lambda$. The sample mean of the detected particles across all detectors is given by $S_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$.\n\nThe research team is interested in the probability of observing a system-wide fluctuation where the average number of detected particles significantly exceeds the expected value. Using the Chernoff bound method, calculate an upper bound for the probability that the sample mean is at least twice the expected value for a single detector.\n\nAssume the array consists of $n=50$ detectors, the expected count for any single detector is $\\lambda=3$, and the specified threshold for the sample mean is $a = 2\\lambda$.\n\nCalculate the upper bound for the probability $P(S_n \\ge a)$. Express your answer as a numerical value rounded to three significant figures.\n\n", "solution": "We have independent and identically distributed $X_{i} \\sim \\text{Poisson}(\\lambda)$ and the sample mean $S_{n} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}$. We want an upper bound for $P(S_{n} \\ge a)$ with $a = 2\\lambda$.\n\nBy the Chernoff bound, for any $t > 0$,\n$$\nP\\!\\left(S_{n} \\ge a\\right) \\;=\\; P\\!\\left(\\sum_{i=1}^{n} X_{i} \\ge n a\\right) \\;\\le\\; \\exp(-t n a)\\, \\mathbb{E}\\!\\left[\\exp\\!\\left(t \\sum_{i=1}^{n} X_{i}\\right)\\right].\n$$\nUsing independence,\n$$\n\\mathbb{E}\\!\\left[\\exp\\!\\left(t \\sum_{i=1}^{n} X_{i}\\right)\\right] \\;=\\; \\prod_{i=1}^{n} \\mathbb{E}\\!\\left[\\exp(t X_{i})\\right] \\;=\\; \\left(M_{X}(t)\\right)^{n},\n$$\nwhere $M_{X}(t)$ is the moment generating function of $X_{i}$. For $X \\sim \\text{Poisson}(\\lambda)$,\n$$\nM_{X}(t) \\;=\\; \\exp\\!\\left(\\lambda\\left(\\exp(t) - 1\\right)\\right).\n$$\nTherefore,\n$$\nP\\!\\left(S_{n} \\ge a\\right) \\;\\le\\; \\exp\\!\\left(-t n a + n \\lambda \\left(\\exp(t) - 1\\right)\\right).\n$$\nTo tighten the bound, minimize the exponent over $t>0$. Define\n$$\n\\phi(t) \\;=\\; -t a + \\lambda \\left(\\exp(t) - 1\\right).\n$$\nThen\n$$\n\\phi'(t) \\;=\\; -a + \\lambda \\exp(t).\n$$\nSet $\\phi'(t)=0$ to get the optimal $t^{\\ast}$:\n$$\n\\lambda \\exp(t^{\\ast}) \\;=\\; a \\;\\;\\Rightarrow\\;\\; \\exp(t^{\\ast}) \\;=\\; \\frac{a}{\\lambda}, \\quad t^{\\ast} \\;=\\; \\ln\\!\\left(\\frac{a}{\\lambda}\\right).\n$$\nSubstituting $t^{\\ast}$ gives\n$$\nP\\!\\left(S_{n} \\ge a\\right) \\;\\le\\; \\exp\\!\\left(n\\left[-a \\ln\\!\\left(\\frac{a}{\\lambda}\\right) + \\lambda\\!\\left(\\frac{a}{\\lambda} - 1\\right)\\right]\\right)\n\\;=\\; \\exp\\!\\left(-n\\left[a \\ln\\!\\left(\\frac{a}{\\lambda}\\right) - a + \\lambda\\right]\\right).\n$$\nWith $a = 2\\lambda$, this simplifies to\n$$\nP\\!\\left(S_{n} \\ge 2\\lambda\\right) \\;\\le\\; \\exp\\!\\left(-n\\left[2\\lambda \\ln 2 - \\lambda\\right]\\right) \\;=\\; \\exp\\!\\left(n \\lambda \\left(1 - 2 \\ln 2\\right)\\right).\n$$\nNow substitute $n=50$ and $\\lambda=3$:\n$$\nP\\!\\left(S_{n} \\ge 2\\lambda\\right) \\;\\le\\; \\exp\\!\\left(150\\left(1 - 2 \\ln 2\\right)\\right).\n$$\nNumerically, $1 - 2 \\ln 2 \\approx -0.386294361$, hence the exponent is approximately $-57.944154$, and\n$$\nP\\!\\left(S_{n} \\ge 2\\lambda\\right) \\;\\lesssim\\; \\exp(-57.944154) \\;\\approx\\; 6.84 \\times 10^{-26}.\n$$\nRounded to three significant figures, the Chernoff upper bound is $6.84 \\times 10^{-26}$.", "answer": "$$\\boxed{6.84 \\times 10^{-26}}$$"}]}