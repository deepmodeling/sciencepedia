{"hands_on_practices": [{"introduction": "The abstract formulas of probability theory find their true power when applied to real-world decisions. This problem presents a classic dilemma: is it better to pursue a goal through small, incremental steps or with a single, decisive action? By applying the Gambler's Ruin framework, you will discover how the underlying probability of success in a single trial, $p$, dictates the optimal strategy, providing a quantitative answer to a strategic question. [@problem_id:1326619]", "problem": "A player enters a sequential betting game with an initial capital of $i=5$ units. The player's objective is to reach a total fortune of $N=10$ units. The game ends if the player's capital reaches either the target of 10 units (a win) or 0 units (ruin). In each independent round of the game, the player has a probability $p$ of winning their bet, where $p \\in (0, 1)$. The player is considering two distinct betting strategies:\n\n1.  **Patient Strategy**: In each round, the player bets a single unit. They win 1 unit with probability $p$ and lose 1 unit with probability $1-p$. This continues until the game ends.\n2.  **Bold Strategy**: The player bets their entire initial capital of 5 units in a single, all-or-nothing round. If they win, their capital becomes 10 units, and they achieve their objective. If they lose, their capital becomes 0 and they are ruined.\n\nAssuming the player's goal is to maximize the probability of reaching the target capital, which of the following statements correctly describes the optimal choice of strategy based on the win probability $p$?\n\nA. The Bold Strategy is strictly better than the Patient Strategy for all $p \\in (0, 1)$.\n\nB. The Patient Strategy is strictly better than the Bold Strategy for all $p \\in (0, 1)$.\n\nC. The Bold Strategy is the better or equivalent choice if $p \\le 0.5$, and the Patient Strategy is the better choice if $p > 0.5$.\n\nD. The Patient Strategy is the better or equivalent choice if $p \\le 0.5$, and the Bold Strategy is the better choice if $p > 0.5$.\n\nE. Both strategies always yield the exact same probability of success, regardless of the value of $p$.", "solution": "Let $q=1-p$. Under the Patient Strategy, the fortune performs a biased random walk on $\\{0,1,\\dots,10\\}$ with absorbing states at $0$ and $10$. Let $u_{i}$ denote the probability of hitting $10$ before $0$ starting from state $i$. The standard gambler’s ruin difference equation and boundary conditions are\n$$\nu_{i}=p\\,u_{i+1}+q\\,u_{i-1},\\quad u_{0}=0,\\quad u_{10}=1.\n$$\nFor $p\\neq \\frac{1}{2}$, the solution is\n$$\nu_{i}=\\frac{1-\\left(\\frac{q}{p}\\right)^{i}}{1-\\left(\\frac{q}{p}\\right)^{10}},\\quad\\text{and for }p=\\frac{1}{2},\\;u_{i}=\\frac{i}{10}.\n$$\nWith $i=5$, we obtain for $p\\neq \\frac{1}{2}$:\n$$\nP_{\\text{pat}}=\\frac{1-\\left(\\frac{q}{p}\\right)^{5}}{1-\\left(\\frac{q}{p}\\right)^{10}}=\\frac{1}{1+\\left(\\frac{q}{p}\\right)^{5}}=\\frac{p^{5}}{p^{5}+q^{5}},\n$$\nand for $p=\\frac{1}{2}$, $P_{\\text{pat}}=\\frac{1}{2}$, which agrees with the above expression by continuity.\n\nUnder the Bold Strategy, the player stakes $5$ at once and wins with probability $p$, reaching $10$ immediately, so\n$$\nP_{\\text{bold}}=p.\n$$\n\nTo compare, consider the inequality $P_{\\text{bold}}\\ge P_{\\text{pat}}$:\n$$\np\\ge \\frac{p^{5}}{p^{5}+q^{5}}\n\\;\\Longleftrightarrow\\;\np\\left(p^{5}+q^{5}\\right)\\ge p^{5}\n\\;\\Longleftrightarrow\\;\np q^{5}\\ge p^{5}(1-p)=p^{5}q.\n$$\nFor $p\\in(0,1)$, divide both sides by $pq0$ to get\n$$\nq^{4}\\ge p^{4}\\;\\Longleftrightarrow\\;q\\ge p\\;\\Longleftrightarrow\\;p\\le \\frac{1}{2}.\n$$\nThus:\n- If $p\\frac{1}{2}$, then $P_{\\text{bold}}P_{\\text{pat}}$.\n- If $p=\\frac{1}{2}$, then $P_{\\text{bold}}=P_{\\text{pat}}=\\frac{1}{2}$.\n- If $p\\frac{1}{2}$, then $P_{\\text{bold}}P_{\\text{pat}}$.\n\nTherefore, the Bold Strategy is better or equivalent if $p\\le \\frac{1}{2}$, and the Patient Strategy is better if $p\\frac{1}{2}$.", "answer": "$$\\boxed{C}$$", "id": "1326619"}, {"introduction": "Standard models provide a foundation, but the true art of a scientist is adapting them to specific, complex systems. This problem, framed in the context of biopolymer growth, introduces a fascinating twist to the classic random walk: a 'molecular chaperone' that can intervene to prevent ruin. You will learn how to modify the underlying difference equations to account for this special boundary condition, a key skill for modeling realistic stochastic processes in fields from biology to finance. [@problem_id:1326632]", "problem": "Consider a simplified model for the growth of a biopolymer chain. The length of the chain, an integer $i$, changes in discrete time steps. The chain's initial length is $j$. The goal is for the chain to reach a stable target length of $N$. The dynamics of the chain's length are governed by the following stochastic rules:\n\n- The initial length is $j$, where $j$ and $N$ are integers satisfying $1 \\le j  N$.\n- In each time step, for any length $i$ such that $2 \\le i \\le N-1$, the chain adds a monomer and its length increases to $i+1$ with probability $p$, or it loses a monomer and its length decreases to $i-1$ with probability $q = 1-p$. We assume $p \\in (0, 1)$ and $p \\ne 1/2$.\n- The state of length $N$ is a stable final configuration, meaning if the chain reaches length $N$, it stops growing (an absorbing state).\n- The monomer state (length 1) is unstable. If the chain has length 1, an addition event occurs with probability $p$, increasing the length to 2. A dissociation event occurs with probability $q$. In the case of dissociation from length 1, a molecular chaperone may intervene:\n    - With probability $\\alpha$, where $\\alpha \\in [0, 1]$, the chaperone successfully stabilizes the monomer, and the chain's length remains 1.\n    - With probability $1-\\alpha$, the chaperone fails, and the monomeric chain completely dissolves. This corresponds to a \"failure\" state of length 0, from which the chain cannot regrow (an absorbing state).\n\nDetermine a closed-form expression for the probability that the polymer chain eventually reaches the target length $N$, starting from the initial length $j$. Express your answer in terms of $p$, $q$, $j$, $N$, and $\\alpha$.", "solution": "Let $u_{i}$ denote the probability that the chain eventually reaches the absorbing target length $N$ before dissolving to the absorbing failure state $0$, starting from length $i$. We have $u_{N}=1$ and $u_{0}=0$ by definition.\n\nFor $2 \\le i \\le N-1$, the one-step dynamics yield the standard birth–death relation\n$$\nu_{i}=p\\,u_{i+1}+q\\,u_{i-1},\n$$\nwith $q=1-p$. At $i=1$, the special rule gives\n$$\nu_{1}=p\\,u_{2}+q\\,\\alpha\\,u_{1}+q\\,(1-\\alpha)\\,u_{0}.\n$$\nUsing $u_{0}=0$, this reduces to\n$$\n(1-q\\alpha)\\,u_{1}=p\\,u_{2}\\quad\\Longrightarrow\\quad u_{1}=\\frac{p}{1-q\\alpha}\\,u_{2}.\n$$\n\nTo solve the interior recurrence, write it as\n$$\np\\,u_{i+1}-u_{i}+q\\,u_{i-1}=0,\\quad 2\\le i\\le N-1.\n$$\nSeek solutions of the form $u_{i}=r^{i}$, leading to the characteristic equation\n$$\np\\,r^{2}-r+q=0.\n$$\nSince $p\\in(0,1)$ and $p\\ne \\tfrac{1}{2}$, the roots are distinct and given by $r=1$ and $r=\\frac{q}{p}$. Hence the general solution on $\\{i\\ge 1\\}$ is\n$$\nu_{i}=A+B\\left(\\frac{q}{p}\\right)^{i},\n$$\nfor constants $A,B$ determined by the boundary conditions.\n\nImpose $u_{N}=1$ to get\n$$\nA+B\\left(\\frac{q}{p}\\right)^{N}=1.\n$$\nUse the special boundary relation at $i=1$:\n$$\n(1-q\\alpha)\\,u_{1}=p\\,u_{2}\n\\quad\\Longrightarrow\\quad\n(1-q\\alpha)\\left(A+B\\frac{q}{p}\\right)=p\\left(A+B\\left(\\frac{q}{p}\\right)^{2}\\right).\n$$\nRearranging with $p+q=1$ gives\n$$\nq(1-\\alpha)\\,A+\\frac{q}{p}\\,(p-q\\alpha)\\,B=0\n\\quad\\Longrightarrow\\quad\np(1-\\alpha)\\,A+(p-q\\alpha)\\,B=0.\n$$\nThus\n$$\nB=-\\frac{p(1-\\alpha)}{p-q\\alpha}\\,A.\n$$\nSubstitute this in $u_{N}=1$:\n$$\n1=u_{N}=A+B\\left(\\frac{q}{p}\\right)^{N}\n=A\\left[1-\\frac{p(1-\\alpha)}{p-q\\alpha}\\left(\\frac{q}{p}\\right)^{N}\\right],\n$$\nso\n$$\nA=\\frac{1}{1-\\dfrac{p(1-\\alpha)}{p-q\\alpha}\\left(\\dfrac{q}{p}\\right)^{N}}.\n$$\nTherefore, for any $j\\in\\{1,\\dots,N-1\\}$,\n$$\nu_{j}=A+B\\left(\\frac{q}{p}\\right)^{j}\n=A\\left[1-\\frac{p(1-\\alpha)}{p-q\\alpha}\\left(\\frac{q}{p}\\right)^{j}\\right].\n$$\nThis yields the closed form\n$$\nu_{j}=\\frac{1-\\dfrac{p(1-\\alpha)}{p-q\\alpha}\\left(\\dfrac{q}{p}\\right)^{j}}{1-\\dfrac{p(1-\\alpha)}{p-q\\alpha}\\left(\\dfrac{q}{p}\\right)^{N}}.\n$$\n\nConsistency checks:\n- If $\\alpha=0$ (no rescue at $i=1$), then $u_{j}=\\dfrac{1-\\left(\\dfrac{q}{p}\\right)^{j}}{1-\\left(\\dfrac{q}{p}\\right)^{N}}$, the standard gambler’s ruin formula.\n- If $\\alpha=1$ (perfect rescue at $i=1$), the factor $\\dfrac{p(1-\\alpha)}{p-q\\alpha}$ vanishes and $u_{j}=1$, as expected since $0$ is then unattainable and $N$ is the only absorbing state.\n\nThus the required probability is as above.", "answer": "$$\\boxed{\\frac{1-\\dfrac{p(1-\\alpha)}{p-q\\alpha}\\left(\\dfrac{q}{p}\\right)^{j}}{1-\\dfrac{p(1-\\alpha)}{p-q\\alpha}\\left(\\dfrac{q}{p}\\right)^{N}}}$$", "id": "1326632"}, {"introduction": "An analytical solution provides a precise prediction, but how do we gain confidence in its correctness and build intuition for the process? This hands-on computational exercise guides you through one of the most powerful techniques in science: verifying theory with experiment. You will implement the Gambler's Ruin model as a Monte Carlo simulation and compare its empirical results against the exact formula, bridging the gap between abstract mathematics and concrete, observable outcomes. [@problem_id:2445753]", "problem": "Consider a one-dimensional random walk model of capital in the Gambler’s Ruin setting. A gambler’s capital after step $t$ is a discrete-time stochastic process $\\{X_t\\}_{t \\ge 0}$ on the finite state space $\\{0,1,2,\\dots,N\\}$ with absorbing boundaries at $0$ and $N$. At each time step, the capital changes by $+1$ with probability $p$ and by $-1$ with probability $q=1-p$, independently of the past, provided the capital is not already at a boundary. The initial capital is $X_0=i$. If the process hits $0$, the gambler is ruined; if it hits $N$, the gambler reaches the goal. All probabilities in this problem are dimensionless.\n\nYour task is to write a complete, runnable program that does the following:\n\n1) From first principles, derive and implement the analytical probability of ruin, denoted $r_i=\\mathbb{P}(\\text{ruin}\\mid X_0=i)$, using only the foundational definitions of the model and the law of total probability. The derivation must start from the boundary conditions $r_0=1$ and $r_N=0$ and the first-step relation for $0iN$. Do not use any pre-memorized end-formulas; instead, solve the resulting linear difference equation with the stated boundary conditions to obtain a closed-form expression that you then implement in code.\n\n2) Implement a Monte Carlo estimator of the ruin probability by simulating $M$ independent sample paths until absorption and computing the empirical frequency of ruin. Use a pseudorandom number generator with a fixed seed $s$ to ensure reproducibility.\n\n3) For each test case in the suite below, compute both the analytical ruin probability and the Monte Carlo estimate, and return a boolean indicating whether the absolute error between the two is within a tolerance $\\varepsilon$.\n\nFoundational base you must use:\n- The law of total probability applied to the first step of the random walk.\n- The boundary conditions of the absorbing states.\n- Standard algebra for solving linear constant-coefficient difference equations with boundary values.\n\nMonte Carlo estimator specification:\n- For each independent trial, start at $X_0=i$ and evolve $X_t$ with steps $+1$ with probability $p$ and $-1$ with probability $q=1-p$ until $X_t \\in \\{0,N\\}$. Record whether $X_t$ hits $0$ before $N$. The estimator is the fraction of trials that are ruined.\n\nReproducibility:\n- Use a single fixed seed $s=123456$ for the pseudorandom number generator for all simulations.\n\nAcceptance criterion:\n- Let $\\hat{r}_i$ be the Monte Carlo estimate and $r_i$ the analytical value. A test case passes if $|\\hat{r}_i - r_i| \\le \\varepsilon$ with $\\varepsilon=0.02$.\n\nTest suite:\nProvide results for the following parameter sets $(N,i,p,M)$:\n- Case A (general, fair game): $(N,i,p,M)=(10,3,0.5,20000)$.\n- Case B (boundary: immediate ruin): $(N,i,p,M)=(10,0,0.5,1000)$.\n- Case C (boundary: immediate success): $(N,i,p,M)=(10,10,0.5,1000)$.\n- Case D (biased toward success): $(N,i,p,M)=(50,10,0.7,20000)$.\n- Case E (biased toward ruin): $(N,i,p,M)=(50,10,0.3,20000)$.\n- Case F (larger state space, fair game): $(N,i,p,M)=(100,50,0.5,5000)$.\n\nOutput format:\n- Your program should produce a single line of output containing the results for the six cases as a comma-separated list of booleans enclosed in square brackets, with no spaces. For example: “[True,False,True,True,True,False]”.\n\nNote: All numerical parameters appearing above such as $0$, $1$, $0.5$, $10$, $50$, $100$, $20000$, $1000$, $5000$, $0.02$, and $123456$ are part of the test specification and must be used exactly as given. No angles or physical units are involved beyond dimensionless probabilities.", "solution": "The problem statement is a valid exercise in computational physics and probability theory. It describes the classic one-dimensional Gambler's Ruin problem, a well-posed model with a unique, analytical solution. The problem is self-contained, providing all necessary parameters and definitions, and its components—derivation of an analytical solution and its comparison with a Monte Carlo simulation—are standard and scientifically sound procedures. The problem is free from ambiguity, factual error, and subjective claims. We shall therefore proceed to its solution.\n\nThe solution is divided into three parts: first, the derivation of the analytical ruin probability; second, the specification of the Monte Carlo estimator; and third, the implementation logic for comparing the two for the given test suite.\n\n_1. Derivation of the Analytical Ruin Probability_\n\nLet $r_i$ be the probability of ruin given an initial capital of $X_0 = i$, where the state space for the capital is $\\{0, 1, 2, \\dots, N\\}$. The states $0$ and $N$ are absorbing.\n\nThe boundary conditions are defined by the nature of these absorbing states:\n- If the initial capital is $i=0$, the gambler is already ruined. Thus, the probability of ruin is $1$.\n  $$r_0 = 1$$\n- If the initial capital is $i=N$, the gambler has reached the goal and can no longer be ruined. Thus, the probability of ruin is $0$.\n  $$r_N = 0$$\n\nFor any non-boundary state $i \\in \\{1, 2, \\dots, N-1\\}$, we can formulate a recurrence relation for $r_i$ by applying the law of total probability, conditioning on the outcome of the first step. After one step from state $i$, the capital is either $i+1$ with probability $p$ or $i-1$ with probability $q=1-p$. The ruin probability from these new states are $r_{i+1}$ and $r_{i-1}$, respectively, due to the memoryless property of the process. This leads to the relation:\n$$r_i = p \\cdot r_{i+1} + q \\cdot r_{i-1}$$\nThis can be rewritten as a second-order linear homogeneous difference equation with constant coefficients:\n$$p r_{i+1} - r_i + q r_{i-1} = 0$$\nTo solve this equation, we seek a solution of the form $r_i = \\lambda^i$. Substituting this into the equation yields the characteristic equation:\n$$p \\lambda^2 - \\lambda + q = 0$$\nThe roots of this quadratic equation are given by $\\lambda = \\frac{1 \\pm \\sqrt{1 - 4pq}}{2p}$. Since $q=1-p$, the discriminant simplifies to $1 - 4p(1-p) = 1 - 4p + 4p^2 = (1-2p)^2$.\nThe roots are therefore:\n$$\\lambda_1 = \\frac{1 + (1-2p)}{2p} = \\frac{2 - 2p}{2p} = \\frac{1-p}{p} = \\frac{q}{p}$$\n$$\\lambda_2 = \\frac{1 - (1-2p)}{2p} = \\frac{2p}{2p} = 1$$\n\nWe must consider two cases based on whether these roots are distinct.\n\n_Case 1: Biased Game ($p \\neq 0.5$)_\nIf $p \\neq 0.5$, then $p \\neq q$, and the roots $\\lambda_1 = q/p$ and $\\lambda_2 = 1$ are distinct. The general solution to the difference equation is a linear combination of the fundamental solutions:\n$$r_i = A (\\frac{q}{p})^i + B (1)^i = A (\\frac{q}{p})^i + B$$\nThe constants $A$ and $B$ are determined by the boundary conditions $r_0=1$ and $r_N=0$.\nFor $i=0$: $r_0 = A(\\frac{q}{p})^0 + B = A+B = 1$.\nFor $i=N$: $r_N = A(\\frac{q}{p})^N + B = 0$.\nSolving this system of linear equations, we find $B = 1-A$, which gives $A(\\frac{q}{p})^N + (1-A) = 0$, so $A( (\\frac{q}{p})^N - 1 ) = -1$.\nThis yields $A = \\frac{1}{1-(q/p)^N}$ and $B = 1 - A = \\frac{-(q/p)^N}{1-(q/p)^N}$.\nSubstituting $A$ and $B$ back into the general solution, we obtain the ruin probability for $p \\neq 0.5$:\n$$r_i = \\frac{(q/p)^i - (q/p)^N}{1 - (q/p)^N}$$\n\n_Case 2: Fair Game ($p = 0.5$)_\nIf $p = 0.5$, then $q=0.5$ and $\\lambda_1 = \\lambda_2 = 1$. The characteristic equation has a repeated root. In this situation, the general solution is of the form:\n$$r_i = A(1)^i + B \\cdot i \\cdot (1)^i = A + Bi$$\nWe again use the boundary conditions $r_0=1$ and $r_N=0$ to find the constants $A$ and $B$.\nFor $i=0$: $r_0 = A + B(0) = A = 1$.\nFor $i=N$: $r_N = A + BN = 1 + BN = 0$, which implies $B = -1/N$.\nSubstituting $A$ and $B$ back, we obtain the ruin probability for $p=0.5$:\n$$r_i = 1 - \\frac{i}{N} = \\frac{N-i}{N}$$\n\nThese derived formulas provide the complete analytical solution for the ruin probability $r_i$.\n\n_2. Monte Carlo Estimator Design_\n\nThe Monte Carlo method provides a numerical estimate of the ruin probability, $\\hat{r}_i$, by simulating a large number of random walks. For each of the $M$ independent trials:\n1.  Initialize the gambler's capital to the starting value, $X_0 = i$.\n2.  If $i=0$ or $i=N$, the outcome is predetermined as ruin or success, respectively.\n3.  For $0  i  N$, simulate the walk step-by-step. At each time step $t$, generate a pseudorandom number $u$ from a uniform distribution $U(0,1)$.\n    - If $u  p$, the capital is updated: $X_{t+1} = X_t + 1$.\n    - If $u \\ge p$, the capital is updated: $X_{t+1} = X_t - 1$.\n4.  This process continues until the capital $X_t$ reaches either of the absorbing boundaries, $0$ or $N$.\n5.  If the walk terminates at state $0$, the trial is recorded as a \"ruin\". If it terminates at state $N$, it is a \"success\".\n\nAfter $M$ trials are completed, the estimator $\\hat{r}_i$ is the empirical frequency of ruin:\n$$\\hat{r}_i = \\frac{\\text{Number of trials ending in ruin}}{\\text{Total number of trials, } M}$$\nTo ensure reproducibility of the results, the pseudorandom number generator is initialized with a fixed seed $s=123456$ before running the simulations for each test case.\n\n_3. Implementation and Comparison_\n\nThe final program will implement two functions corresponding to the analytical solution and the Monte Carlo estimator. A main routine will iterate through the provided test suite. For each parameter set $(N, i, p, M)$:\n- The boundary cases $i=0$ and $i=N$ are handled directly. The analytical solution is $r_0=1, r_N=0$ by definition. The Monte Carlo estimator will also return these values without simulation.\n- For $0  i  N$, the analytical formula for $r_i$ (depending on whether $p=0.5$) is computed.\n- The Monte Carlo estimator $\\hat{r}_i$ is computed by running $M$ simulations with the specified parameters and the fixed seed $s=123456$.\n- The absolute error $|\\hat{r}_i - r_i|$ is calculated and compared to the tolerance $\\varepsilon=0.02$.\n- A boolean value, `True` if the error is within tolerance and `False` otherwise, is determined for each case.\n- The program's final output is a comma-separated list of these booleans, formatted as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Gambler's Ruin problem for a suite of test cases.\n    It calculates the analytical ruin probability and a Monte Carlo estimate,\n    then checks if the estimate is within a specified tolerance of the analytical value.\n    \"\"\"\n\n    def analytical_ruin_prob(N: int, i: int, p: float) - float:\n        \"\"\"\n        Calculates the analytical ruin probability r_i.\n\n        Args:\n            N: The goal capital.\n            i: The initial capital.\n            p: The probability of winning a single bet.\n\n        Returns:\n            The analytical probability of ruin.\n        \"\"\"\n        if i = 0:\n            return 1.0\n        if i = N:\n            return 0.0\n\n        # Using a small tolerance for floating point comparison of p with 0.5\n        if abs(p - 0.5)  1e-9:\n            # Case for a fair game (p = 0.5)\n            return (N - i) / N\n        else:\n            # Case for a biased game (p != 0.5)\n            q = 1.0 - p\n            rho = q / p\n            # The formula is robust and does not require special handling\n            # for rho  1 or rho  1, as long as rho != 1.\n            return (rho**i - rho**N) / (1 - rho**N)\n\n    def monte_carlo_estimator(N: int, i: int, p: float, M: int, seed: int) - float:\n        \"\"\"\n        Estimates the ruin probability using a Monte Carlo simulation.\n\n        Args:\n            N: The goal capital.\n            i: The initial capital.\n            p: The probability of winning a single bet.\n            M: The number of simulation trials.\n            seed: The seed for the random number generator.\n\n        Returns:\n            The estimated probability of ruin.\n        \"\"\"\n        if i = 0:\n            return 1.0\n        if i = N:\n            return 0.0\n\n        rng = np.random.default_rng(seed)\n        ruin_count = 0\n\n        for _ in range(M):\n            capital = i\n            while 0  capital  N:\n                if rng.random()  p:\n                    capital += 1\n                else:\n                    capital -= 1\n            if capital == 0:\n                ruin_count += 1\n        \n        return ruin_count / M\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, i, p, M)\n        (10, 3, 0.5, 20000),  # Case A\n        (10, 0, 0.5, 1000),   # Case B\n        (10, 10, 0.5, 1000),  # Case C\n        (50, 10, 0.7, 20000),  # Case D\n        (50, 10, 0.3, 20000),  # Case E\n        (100, 50, 0.5, 5000), # Case F\n    ]\n\n    # Parameters for the simulation and comparison\n    seed = 123456\n    tolerance = 0.02\n    \n    results = []\n    for case in test_cases:\n        N, i, p, M = case\n        \n        # Calculate analytical and estimated probabilities\n        analytical_val = analytical_ruin_prob(N, i, p)\n        mc_estimate = monte_carlo_estimator(N, i, p, M, seed)\n        \n        # Check if the estimate is within the tolerance\n        absolute_error = abs(analytical_val - mc_estimate)\n        is_within_tolerance = absolute_error = tolerance\n        results.append(is_within_tolerance)\n\n    # Final print statement in the exact required format.\n    # The str() of a boolean is 'True' or 'False' (capitalized).\n    # The requirement \"[True,False,...]\" matches Python's string conversion.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2445753"}]}