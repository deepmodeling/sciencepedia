{"hands_on_practices": [{"introduction": "The defining characteristic of a long-range dependent process is its \"memory,\" which causes the variance of the sample mean to decrease more slowly than for processes with no memory. This exercise focuses on a fundamental relationship: the variance of the sample mean, $Var(\\bar{X}_n)$, scales with the sample size $n$ as $Var(\\bar{X}_n) \\propto n^{2H-2}$, where $H$ is the Hurst exponent. By working through this problem [@problem_id:1315781], you will perform a direct calculation of $H$ from an empirically observed scaling law, solidifying your understanding of this core principle.", "problem": "A data scientist is analyzing a time series representing the number of transactions processed per second by a financial server. This time series is modeled as a stationary stochastic process $\\{X_i\\}_{i \\ge 1}$, where $X_i$ is the number of transactions in the $i$-th second.\n\nTo understand the memory properties of this process, the scientist examines the behavior of the sample mean, $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$, for various large sample sizes $n$. The persistence or long-range dependence in such a process is quantified by the Hurst exponent, $H$.\n\nFor a stationary stochastic process, the variance of the sample mean for large $n$ is known to be asymptotically proportional to a power of $n$. This relationship is given by:\n$$ \\text{Var}(\\bar{X}_n) \\propto n^{2H-2} $$\nwhere $H$ is the Hurst exponent. A value of $H = 0.5$ indicates a process with no long-term memory (like white noise), while a value in the range $0.5 < H < 1$ indicates the presence of long-range dependence.\n\nFrom empirical analysis of the transaction data, the scientist determines that for large $n$, the variance of the sample mean follows the scaling law:\n$$ \\text{Var}(\\bar{X}_n) \\propto n^{-0.5} $$\n\nBased on this empirical finding, calculate the value of the Hurst exponent $H$ for this transaction process.", "solution": "We are given the asymptotic variance scaling for the sample mean of a stationary process:\n$$\n\\operatorname{Var}(\\bar{X}_{n}) \\propto n^{2H-2}.\n$$\nFrom the empirical analysis, the scientist finds:\n$$\n\\operatorname{Var}(\\bar{X}_{n}) \\propto n^{-0.5} = n^{-\\frac{1}{2}}.\n$$\nEquating the exponents of $n$ in the two proportionality expressions gives:\n$$\n2H - 2 = -\\frac{1}{2}.\n$$\nSolving for $H$:\n$$\n2H = 2 - \\frac{1}{2} = \\frac{3}{2},\n$$\n$$\nH = \\frac{3}{4}.\n$$\nThis value lies in the interval $(0.5, 1)$, indicating long-range dependence, consistent with the interpretation of the Hurst exponent.", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1315781"}, {"introduction": "While the power-law relationship between variance and sample size is fundamental, a more practical tool for data analysis is often the log-log plot. This powerful graphical technique transforms power-law relationships into linear ones, making them easier to identify and quantify. In this practice [@problem_id:1315798], you will learn how to estimate the Hurst exponent $H$ from the slope of a variance-aggregation plot, a standard method used by engineers and scientists to diagnose long-range dependence in real-world data.", "problem": "A network engineer is analyzing a high-frequency time series representing the number of data packets arriving at a router in consecutive, non-overlapping 1-millisecond intervals. To study the traffic's long-term correlation structure, a property known as long-range dependence (LRD), the engineer performs an aggregation analysis.\n\nThe analysis involves creating a new, coarser time series by averaging the packet counts over non-overlapping blocks of size $m$ (where $m$ is an integer representing the number of 1-millisecond intervals in a block). Let $V(m)$ denote the sample variance of this new time series aggregated at level $m$.\n\nFor a process exhibiting LRD, theoretical models predict that for large aggregation levels $m$, the variance $V(m)$ scales according to the relation $V(m) \\propto m^{2H-2}$, where $H$ is a constant called the Hurst exponent. A key method for estimating $H$ is to plot $\\log(V(m))$ versus $\\log(m)$ and observe the slope of the resulting line.\n\nThe engineer's analysis reveals that this log-log plot is indeed linear for large $m$, with a measured slope of $-0.4$. Using this information, determine the value of the Hurst exponent $H$.", "solution": "We are given that for large aggregation level $m$, the variance scales as $V(m) \\propto m^{2H-2}$. Therefore, there exists a constant $C>0$ such that for large $m$,\n$$\nV(m) = C\\, m^{2H-2}.\n$$\nTaking natural logarithms on both sides yields\n$$\n\\ln(V(m)) = \\ln(C) + (2H - 2)\\,\\ln(m).\n$$\nIn a plot of $\\ln(V(m))$ versus $\\ln(m)$, the slope is the coefficient of $\\ln(m)$, which is $2H - 2$. The measured slope is given as $-0.4$, which we write exactly as $-\\frac{2}{5}$. Hence,\n$$\n2H - 2 = -\\frac{2}{5}.\n$$\nSolving for $H$,\n$$\n2H = 2 - \\frac{2}{5} = \\frac{10 - 2}{5} = \\frac{8}{5},\n$$\n$$\nH = \\frac{4}{5}.\n$$\nThus, the Hurst exponent is $H = \\frac{4}{5}$.", "answer": "$$\\boxed{\\frac{4}{5}}$$", "id": "1315798"}, {"introduction": "Moving from analyzing time series to creating them, this exercise introduces a method for simulating processes that exhibit long-range dependence. We will explore the Autoregressive Fractionally Integrated Moving Average (ARFIMA) model, a flexible and widely-used framework for modeling long memory. This hands-on simulation [@problem_id:1315789] demystifies the concept of fractional integration by guiding you through the calculation of a data point in an ARFIMA process, showing how complex memory structures can be built from simple white noise.", "problem": "A telecommunications engineer is modeling packet delay variation in a high-traffic network. Empirical data suggests that the delay process exhibits long-range dependence. To capture this characteristic, the engineer models the delay variation at time $t$, denoted by $X_t$, as a stationary Autoregressive Fractionally Integrated Moving Average (ARFIMA) process of order (0, d, 0).\n\nThe process is defined by the relation $(1-B)^d X_t = Z_t$, where $B$ is the backshift operator ($B X_t = X_{t-1}$), $d$ is the fractional differencing parameter, and $Z_t$ is a sequence of independent and identically distributed Gaussian white noise random variables with mean 0 and variance 1. For this model, the fractional differencing parameter is set to $d=0.4$.\n\nFor simulation purposes, the infinite moving-average representation of the process, $X_t = (1-B)^{-d} Z_t = \\sum_{k=0}^{\\infty} \\psi_k Z_{t-k}$, is approximated by a truncated sum with a maximum lag of $M=3$. The simulated process is thus given by:\n$$ \\tilde{X}_t = \\sum_{k=0}^{3} \\psi_k Z_{t-k} $$\nThe coefficients $\\psi_k$ are derived from the series expansion of $(1-x)^{-d}$.\n\nGiven the following recent values from the white noise sequence:\n$Z_1 = 0.50$, $Z_0 = -1.20$, $Z_{-1} = 0.80$, and $Z_{-2} = -0.30$.\n\nCalculate the simulated value of the process at time $t=1$, denoted as $\\tilde{X}_1$. Round your final answer to four significant figures.", "solution": "The problem asks for the value of a simulated time series $\\tilde{X}_1$ based on a truncated ARFIMA(0, d, 0) model. The model for the simulated process is given by\n$$ \\tilde{X}_t = \\sum_{k=0}^{3} \\psi_k Z_{t-k} $$\nWe need to calculate $\\tilde{X}_1$, which is:\n$$ \\tilde{X}_1 = \\psi_0 Z_1 + \\psi_1 Z_0 + \\psi_2 Z_{-1} + \\psi_3 Z_{-2} $$\nThe coefficients $\\psi_k$ are the coefficients of $B^k$ in the Maclaurin series expansion of the operator $(1-B)^{-d}$. The general formula for these coefficients comes from the generalized binomial theorem:\n$$ (1-x)^{-d} = \\sum_{k=0}^{\\infty} \\binom{-d}{k} (-x)^k $$\nThe binomial coefficient $\\binom{n}{k}$ can be written as $\\frac{n(n-1)\\dots(n-k+1)}{k!}$.\nSo, $\\binom{-d}{k} = \\frac{(-d)(-d-1)\\dots(-d-k+1)}{k!} = (-1)^k \\frac{d(d+1)\\dots(d+k-1)}{k!}$.\nSubstituting this into the series expansion for $x=B$:\n$$ (1-B)^{-d} = \\sum_{k=0}^{\\infty} \\left( (-1)^k \\frac{d(d+1)\\dots(d+k-1)}{k!} \\right) (-B)^k = \\sum_{k=0}^{\\infty} \\frac{d(d+1)\\dots(d+k-1)}{k!} B^k $$\nThe coefficients $\\psi_k$ are therefore $\\psi_k = \\frac{d(d+1)\\dots(d+k-1)}{k!}$. An alternative and more compact representation using the Gamma function is $\\psi_k = \\frac{\\Gamma(k+d)}{\\Gamma(k+1)\\Gamma(d)}$. We will use the product form as it is simpler for small integer $k$.\n\nWe need to calculate the first four coefficients, $\\psi_0, \\psi_1, \\psi_2, \\psi_3$, for $d=0.4$.\n\nFor $k=0$:\n$$ \\psi_0 = \\frac{1}{0!} = 1 $$\nThis is because the product in the numerator is empty, which is defined as 1.\n\nFor $k=1$:\n$$ \\psi_1 = \\frac{d}{1!} = d $$\n\nFor $k=2$:\n$$ \\psi_2 = \\frac{d(d+1)}{2!} = \\frac{d(d+1)}{2} $$\n\nFor $k=3$:\n$$ \\psi_3 = \\frac{d(d+1)(d+2)}{3!} = \\frac{d(d+1)(d+2)}{6} $$\n\nNow, we substitute the given value $d=0.4$ into these expressions:\n$$ \\psi_0 = 1 $$\n$$ \\psi_1 = 0.4 $$\n$$ \\psi_2 = \\frac{0.4(0.4+1)}{2} = \\frac{0.4 \\times 1.4}{2} = \\frac{0.56}{2} = 0.28 $$\n$$ \\psi_3 = \\frac{0.4(0.4+1)(0.4+2)}{6} = \\frac{0.4 \\times 1.4 \\times 2.4}{6} = \\frac{1.344}{6} = 0.224 $$\n\nNow we have the coefficients. We can substitute them and the given values of $Z_t$ into the expression for $\\tilde{X}_1$:\n$Z_1 = 0.50$, $Z_0 = -1.20$, $Z_{-1} = 0.80$, $Z_{-2} = -0.30$.\n\n$$ \\tilde{X}_1 = \\psi_0 Z_1 + \\psi_1 Z_0 + \\psi_2 Z_{-1} + \\psi_3 Z_{-2} $$\n$$ \\tilde{X}_1 = (1)(0.50) + (0.4)(-1.20) + (0.28)(0.80) + (0.224)(-0.30) $$\n\nLet's compute each term:\n$$ (1)(0.50) = 0.50 $$\n$$ (0.4)(-1.20) = -0.48 $$\n$$ (0.28)(0.80) = 0.224 $$\n$$ (0.224)(-0.30) = -0.0672 $$\n\nNow, sum these terms:\n$$ \\tilde{X}_1 = 0.50 - 0.48 + 0.224 - 0.0672 $$\n$$ \\tilde{X}_1 = 0.02 + 0.224 - 0.0672 $$\n$$ \\tilde{X}_1 = 0.244 - 0.0672 $$\n$$ \\tilde{X}_1 = 0.1768 $$\n\nThe problem asks for the answer to be rounded to four significant figures. The calculated value $0.1768$ already has four significant figures.\n\nThus, the simulated value of the process at time $t=1$ is $0.1768$.", "answer": "$$\\boxed{0.1768}$$", "id": "1315789"}]}