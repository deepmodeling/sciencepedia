{"hands_on_practices": [{"introduction": "Understanding the autocorrelation function (ACF) begins with its definition as a normalized version of the autocovariance function. This exercise provides a direct application of the core formula, which defines the ACF at a given lag $h$ as the ratio of the autocovariance $\\gamma(h)$ to the process variance $\\gamma(0)$. By working through this foundational calculation [@problem_id:1897241], you will reinforce your understanding of how the ACF provides a standardized, scale-free measure of temporal dependence in a stationary time series.", "problem": "An economist is studying a country's quarterly Gross Domestic Product (GDP) growth rate. The time series of these growth rates, after appropriate transformations, is modeled as a stationary stochastic process, $\\{X_t\\}$. The autocovariance function of this process, which measures the covariance between observations separated by a lag of $h$ quarters, is denoted by $\\gamma(h)$. Specifically, $\\gamma(h) = \\text{Cov}(X_t, X_{t+h})$.\n\nFrom the historical data, the variance of the process is calculated to be $\\gamma(0) = 0.0036$. The autocovariance between the growth rates of two consecutive quarters (a lag of $h=1$) is found to be $\\gamma(1) = -0.0012$. The Autocorrelation Function (ACF), denoted by $\\rho(h)$, provides a scale-free measure of the correlation between observations as a function of the time lag.\n\nCalculate the value of the ACF at lag 1, $\\rho(1)$, for this time series.", "solution": "For a weakly stationary process $\\{X_{t}\\}$, the autocorrelation function at lag $h$ is defined by\n$$\n\\rho(h) = \\frac{\\gamma(h)}{\\gamma(0)}.\n$$\nGiven $\\gamma(0) = 0.0036$ and $\\gamma(1) = -0.0012$, compute\n$$\n\\rho(1) = \\frac{\\gamma(1)}{\\gamma(0)} = \\frac{-0.0012}{0.0036}.\n$$\nMultiply numerator and denominator by $10^{4}$ to clear decimals:\n$$\n\\rho(1) = \\frac{-12}{36} = -\\frac{1}{3}.\n$$\nThus, the ACF at lag $1$ is $-\\frac{1}{3}$.", "answer": "$$\\boxed{-\\frac{1}{3}}$$", "id": "1897241"}, {"introduction": "While theoretical properties are essential, time series analysis is ultimately an empirical discipline where we work with observed data. This practice problem bridges the gap between theory and data by having you calculate the sample autocorrelation function (sample ACF) from a short sequence of observations [@problem_id:1897249]. Mastering this calculation is a crucial first step toward analyzing real-world data, where the true process and its parameters are unknown and must be estimated from the available information.", "problem": "Consider a discrete time series representing four sequential observations, given by the sequence $\\{X_t\\}_{t=1}^4 = \\{2, 8, 4, 10\\}$. For the purposes of this calculation, you are to assume that the true mean of the process generating this data is zero, and therefore, the sample mean $\\bar{X}$ should be taken as 0.\n\nThe sample Autocorrelation Function (ACF) at a given lag $h$ for a time series $\\{X_t\\}_{t=1}^n$ with a sample mean $\\bar{X}$ is defined as:\n$$r_h = \\frac{\\sum_{t=1}^{n-h} (X_t - \\bar{X})(X_{t+h} - \\bar{X})}{\\sum_{t=1}^{n} (X_t - \\bar{X})^2}$$\nYour task is to compute the value of the sample ACF at lag $h=1$ for the provided time series.\n\nExpress your final answer as a fraction in its simplest form.", "solution": "We are given the time series $\\{X_{t}\\}_{t=1}^{4}=\\{2,8,4,10\\}$ and instructed to take $\\bar{X}=0$. The sample ACF at lag $h=1$ is defined by\n$$\nr_{1}=\\frac{\\sum_{t=1}^{n-1}\\left(X_{t}-\\bar{X}\\right)\\left(X_{t+1}-\\bar{X}\\right)}{\\sum_{t=1}^{n}\\left(X_{t}-\\bar{X}\\right)^{2}}.\n$$\nWith $\\bar{X}=0$ and $n=4$, the numerator is\n$$\n\\sum_{t=1}^{3}X_{t}X_{t+1}=X_{1}X_{2}+X_{2}X_{3}+X_{3}X_{4}=2\\cdot 8+8\\cdot 4+4\\cdot 10=16+32+40=88.\n$$\nThe denominator is\n$$\n\\sum_{t=1}^{4}X_{t}^{2}=2^{2}+8^{2}+4^{2}+10^{2}=4+64+16+100=184.\n$$\nTherefore,\n$$\nr_{1}=\\frac{88}{184}.\n$$\nSimplifying the fraction by dividing numerator and denominator by $8$ gives\n$$\nr_{1}=\\frac{11}{23}.\n$$", "answer": "$$\\boxed{\\frac{11}{23}}$$", "id": "1897249"}, {"introduction": "A key skill in time series analysis is identifying a suitable model for a given dataset, and the ACF is one of our primary tools for this task. This exercise [@problem_id:1897209] challenges you to derive the theoretical ACF for a specific and widely-used model: the Moving Average of order 1, or MA(1), process. By doing so, you will see firsthand how the structure of a stochastic model directly determines its correlation properties, a concept that is fundamental to practical model selection and forecasting.", "problem": "A financial analyst is modeling the daily change in a particular commodity's price using a simple time series model. The model for the price change on day $t$, denoted by $X_t$, is given by a moving average process of order 1, MA(1):\n$$X_t = \\epsilon_t + 0.8 \\epsilon_{t-1}$$\nHere, $\\epsilon_t$ represents a \"shock\" or new information arriving on day $t$. The sequence of shocks $\\{\\epsilon_t\\}$ is assumed to be a white noise process with the following properties:\n1. The expected value of any shock is zero, i.e., $E[\\epsilon_t] = 0$ for all $t$.\n2. The variance of any shock is a constant, finite value $\\sigma^2$, i.e., $Var(\\epsilon_t) = \\sigma^2$ for all $t$.\n3. Shocks at different times are uncorrelated, i.e., $Cov(\\epsilon_t, \\epsilon_s) = 0$ for all $t \\neq s$.\n\nThe theoretical Autocorrelation Function (ACF) at lag $k$, denoted $\\rho(k)$, measures the correlation between the time series and its value $k$ periods ago. It is defined as:\n$$\\rho(k) = \\frac{\\gamma(k)}{\\gamma(0)}$$\nwhere $\\gamma(k) = Cov(X_t, X_{t-k})$ is the autocovariance function at lag $k$, and $\\gamma(0) = Var(X_t)$ is the variance of the process.\n\nCalculate the theoretical autocorrelation at lag 1, $\\rho(1)$, for this model. Express your answer as an exact fraction in its simplest form.", "solution": "We are given the MA(1) process $X_{t}=\\epsilon_{t}+\\theta\\,\\epsilon_{t-1}$ with $\\theta=\\frac{4}{5}$ and $\\{\\epsilon_{t}\\}$ white noise with $E[\\epsilon_{t}]=0$, $Var(\\epsilon_{t})=\\sigma^{2}$, and $Cov(\\epsilon_{t},\\epsilon_{s})=0$ for $t\\neq s$. The autocorrelation at lag $k$ is $\\rho(k)=\\frac{\\gamma(k)}{\\gamma(0)}$, where $\\gamma(k)=Cov(X_{t},X_{t-k})$.\n\nFirst compute the variance $\\gamma(0)=Var(X_{t})$. Using $Var(aY+bZ)=a^{2}Var(Y)+b^{2}Var(Z)+2ab\\,Cov(Y,Z)$ and the white noise properties,\n$$\n\\gamma(0)=Var(\\epsilon_{t}+\\theta\\,\\epsilon_{t-1})=Var(\\epsilon_{t})+\\theta^{2}Var(\\epsilon_{t-1})+2\\theta\\,Cov(\\epsilon_{t},\\epsilon_{t-1}).\n$$\nSince $Cov(\\epsilon_{t},\\epsilon_{t-1})=0$, this simplifies to\n$$\n\\gamma(0)=(1+\\theta^{2})\\sigma^{2}=\\left(1+\\left(\\frac{4}{5}\\right)^{2}\\right)\\sigma^{2}=\\left(1+\\frac{16}{25}\\right)\\sigma^{2}=\\frac{41}{25}\\sigma^{2}.\n$$\n\nNext compute the lag-1 autocovariance $\\gamma(1)=Cov(X_{t},X_{t-1})$. Using $X_{t-1}=\\epsilon_{t-1}+\\theta\\,\\epsilon_{t-2}$,\n$$\n\\gamma(1)=Cov(\\epsilon_{t}+\\theta\\,\\epsilon_{t-1},\\,\\epsilon_{t-1}+\\theta\\,\\epsilon_{t-2}).\n$$\nExpanding covariance bilinearly,\n$$\n\\gamma(1)=Cov(\\epsilon_{t},\\epsilon_{t-1})+\\theta\\,Cov(\\epsilon_{t},\\epsilon_{t-2})+\\theta\\,Cov(\\epsilon_{t-1},\\epsilon_{t-1})+\\theta^{2}Cov(\\epsilon_{t-1},\\epsilon_{t-2}).\n$$\nBy the white noise properties, $Cov(\\epsilon_{t},\\epsilon_{t-1})=0$, $Cov(\\epsilon_{t},\\epsilon_{t-2})=0$, and $Cov(\\epsilon_{t-1},\\epsilon_{t-2})=0$, while $Cov(\\epsilon_{t-1},\\epsilon_{t-1})=Var(\\epsilon_{t-1})=\\sigma^{2}$. Hence\n$$\n\\gamma(1)=\\theta\\,\\sigma^{2}=\\frac{4}{5}\\sigma^{2}.\n$$\n\nTherefore, the lag-1 autocorrelation is\n$$\n\\rho(1)=\\frac{\\gamma(1)}{\\gamma(0)}=\\frac{\\frac{4}{5}\\sigma^{2}}{\\frac{41}{25}\\sigma^{2}}=\\frac{4}{5}\\cdot\\frac{25}{41}=\\frac{20}{41}.\n$$\nThis fraction is already in simplest form.", "answer": "$$\\boxed{\\frac{20}{41}}$$", "id": "1897209"}]}