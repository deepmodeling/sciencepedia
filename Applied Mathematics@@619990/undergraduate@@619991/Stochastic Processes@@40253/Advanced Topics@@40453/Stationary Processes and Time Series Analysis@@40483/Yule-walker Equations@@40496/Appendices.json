{"hands_on_practices": [{"introduction": "The Yule-Walker equations provide a direct bridge between an observable property of a time series—its autocorrelation—and the parameters of an underlying autoregressive (AR) model. This exercise is a fundamental application of this powerful connection, essential for modeling time-dependent data. By working through this problem, you will practice the core skill of translating empirical autocorrelation values into the specific coefficients that define an AR model, a procedure central to fields from finance to signal processing. [@problem_id:1283002]", "problem": "An analyst is studying the daily price fluctuations of a particular financial asset. The fluctuations, represented by the time series $\\{X_t\\}$, are modeled as a stationary, mean-zero Autoregressive (AR) process of order 2. The model is described by the equation:\n$$X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + Z_t$$\nwhere $\\phi_1$ and $\\phi_2$ are the model parameters, and $\\{Z_t\\}$ is a white noise process with mean zero and constant variance, uncorrelated with past values of $X$.\n\nFrom empirical data, the analyst has estimated the first two values of the autocorrelation function (ACF) for this process to be $\\rho(1) = 0.5$ and $\\rho(2) = 0.2$.\n\nUsing the Yule-Walker equations, determine the values of the parameters $\\phi_1$ and $\\phi_2$. Present your final answer as a pair of analytic expressions for $(\\phi_1, \\phi_2)$.", "solution": "We model the stationary mean-zero AR(2) process by $X_{t}=\\phi_{1}X_{t-1}+\\phi_{2}X_{t-2}+Z_{t}$ with $\\{Z_{t}\\}$ white noise. Let $\\gamma(k)$ denote the autocovariance function and $\\rho(k)=\\gamma(k)/\\gamma(0)$ the autocorrelation function. The Yule-Walker equations for AR(2) are, for $k=1,2$,\n$$\n\\gamma(1)=\\phi_{1}\\gamma(0)+\\phi_{2}\\gamma(1),\\quad \\gamma(2)=\\phi_{1}\\gamma(1)+\\phi_{2}\\gamma(0).\n$$\nDividing each equation by $\\gamma(0)$ gives\n$$\n\\rho(1)=\\phi_{1}+\\phi_{2}\\rho(1),\\quad \\rho(2)=\\phi_{1}\\rho(1)+\\phi_{2}.\n$$\nFrom the first equation,\n$$\n\\phi_{1}=\\rho(1)\\bigl(1-\\phi_{2}\\bigr).\n$$\nSubstituting into the second equation yields\n$$\n\\rho(2)=\\rho(1)^{2}\\bigl(1-\\phi_{2}\\bigr)+\\phi_{2}=\\rho(1)^{2}+\\phi_{2}\\bigl(1-\\rho(1)^{2}\\bigr).\n$$\nSolving for $\\phi_{2}$ gives\n$$\n\\phi_{2}=\\frac{\\rho(2)-\\rho(1)^{2}}{1-\\rho(1)^{2}}.\n$$\nThen\n$$\n\\phi_{1}=\\rho(1)\\left(1-\\frac{\\rho(2)-\\rho(1)^{2}}{1-\\rho(1)^{2}}\\right)=\\rho(1)\\,\\frac{1-\\rho(2)}{1-\\rho(1)^{2}}.\n$$\nWith the given values $\\rho(1)=\\frac{1}{2}$ and $\\rho(2)=\\frac{1}{5}$, we compute\n$$\n\\phi_{2}=\\frac{\\frac{1}{5}-\\left(\\frac{1}{2}\\right)^{2}}{1-\\left(\\frac{1}{2}\\right)^{2}}=\\frac{\\frac{1}{5}-\\frac{1}{4}}{1-\\frac{1}{4}}=\\frac{-\\frac{1}{20}}{\\frac{3}{4}}=-\\frac{1}{15},\n$$\nand\n$$\n\\phi_{1}=\\frac{1}{2}\\left(1-(-\\frac{1}{15})\\right)=\\frac{1}{2}\\cdot\\frac{16}{15}=\\frac{8}{15}.\n$$\nThus the parameter values are $\\phi_{1}=\\frac{8}{15}$ and $\\phi_{2}=-\\frac{1}{15}$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{8}{15} & -\\frac{1}{15}\\end{pmatrix}}$$", "id": "1283002"}, {"introduction": "In any practical application, a single point estimate for a parameter is incomplete without a measure of its uncertainty. This practice advances from basic parameter estimation to the vital statistical concept of confidence intervals. You will explore how the large-sample properties of the Yule-Walker estimator allow us to quantify the precision of our estimate, providing a plausible range for the true parameter value—an essential step in rigorous scientific and engineering analysis. [@problem_id:1350569]", "problem": "In a high-precision materials science laboratory, the ambient temperature must be maintained with extreme stability. The hourly deviation of the room temperature from its target set-point, measured in degrees Celsius, is modeled by a stationary time series $\\{X_t\\}$. A detailed analysis suggests that this series can be well-described by an Autoregressive model of order 1 (AR(1)), given by the equation $X_t = \\phi_1 X_{t-1} + Z_t$, where $Z_t$ is a white noise process with zero mean and constant variance, and $|\\phi_1| < 1$ for stationarity. The parameter $\\phi_1$ quantifies the persistence of temperature shocks.\n\nA researcher collects a large dataset of $n = 400$ hourly temperature deviation measurements. Using the Yule-Walker method, they obtain an estimate for the autoregressive parameter, $\\hat{\\phi}_1 = 0.60$.\n\nFrom statistical theory, it is known that for a stationary AR(1) process, the Yule-Walker estimator $\\hat{\\phi}_1$ is asymptotically normal for large $n$. Specifically, its sampling distribution can be approximated by a normal distribution with mean equal to the true parameter $\\phi_1$ and variance equal to $\\frac{1-\\phi_1^2}{n}$. To construct a practical confidence interval, it is common to approximate the variance by substituting the estimate $\\hat{\\phi}_1$ for the unknown true parameter $\\phi_1$.\n\nBased on this information, construct an approximate 95% confidence interval for the true parameter $\\phi_1$. For your calculation, use the fact that for a standard normal random variable $Z$, the probability $P(-1.96 \\le Z \\le 1.96)$ is approximately $0.95$. Provide the lower and upper bounds of the confidence interval, respectively. Round your final answers to three significant figures.", "solution": "We are given a stationary AR(1) process $X_{t}=\\phi_{1}X_{t-1}+Z_{t}$ with $|\\phi_{1}|<1$ and a Yule-Walker estimate $\\hat{\\phi}_{1}=0.60$ based on $n=400$ observations. From asymptotic theory, for large $n$, the Yule-Walker estimator satisfies\n$$\n\\hat{\\phi}_{1}\\approx \\mathcal{N}\\!\\left(\\phi_{1},\\,\\frac{1-\\phi_{1}^{2}}{n}\\right).\n$$\nTo construct a practical confidence interval, we substitute $\\hat{\\phi}_{1}$ for $\\phi_{1}$ in the variance, giving the approximate standard error\n$$\n\\operatorname{SE}(\\hat{\\phi}_{1})\\approx \\sqrt{\\frac{1-\\hat{\\phi}_{1}^{2}}{n}}.\n$$\nA two-sided approximate 95 percent confidence interval for $\\phi_{1}$ is then\n$$\n\\hat{\\phi}_{1}\\pm z_{0.975}\\,\\operatorname{SE}(\\hat{\\phi}_{1}),\n$$\nwith $z_{0.975}=1.96$. Substituting the given values,\n$$\n\\operatorname{SE}(\\hat{\\phi}_{1})=\\sqrt{\\frac{1-0.60^{2}}{400}}=\\sqrt{\\frac{1-0.36}{400}}=\\sqrt{\\frac{0.64}{400}}=\\sqrt{0.0016}=0.04,\n$$\nso the margin of error is\n$$\n1.96\\times 0.04=0.0784.\n$$\nTherefore, the confidence interval bounds are\n$$\n\\text{lower}:\\;0.60-0.0784=0.5216,\\qquad \\text{upper}:\\;0.60+0.0784=0.6784.\n$$\nRounding each bound to three significant figures yields $0.522$ and $0.678$, respectively.", "answer": "$$\\boxed{\\begin{pmatrix}0.522 & 0.678\\end{pmatrix}}$$", "id": "1350569"}, {"introduction": "Powerful tools often have specific operating conditions, and understanding their limits is as important as knowing how to use them. The Yule-Walker equations are designed for stochastic processes, but what happens when they are applied to a signal that is perfectly predictable? This thought-provoking exercise investigates such a boundary case, revealing how the mathematical machinery responds to a deterministic, periodic signal and providing deeper insight into the assumptions that underpin autoregressive modeling. [@problem_id:1350531]", "problem": "In the analysis of deterministic signals, especially those arising from rotating machinery or digital oscillators, it is sometimes useful to employ a specialized definition of autocovariance that respects the signal's inherent periodicity.\n\nConsider a time series $X_1, X_2, \\ldots, X_n$ of length $n$. For a series that is known to be periodic with a period that divides $n$, we can define the Periodic Sample Autocovariance Function (PSACF), denoted $\\hat{\\gamma}_P(h)$, as:\n$$\n\\hat{\\gamma}_P(h) = \\frac{1}{n} \\sum_{t=1}^n (X_t - \\bar{X})(X_{t+h} - \\bar{X})\n$$\nwhere $\\bar{X}$ is the standard sample mean $\\bar{X} = \\frac{1}{n}\\sum_{t=1}^n X_t$. The indices are interpreted cyclically, meaning the index $t+h$ is taken modulo $n$, with the result mapped to the set $\\{1, 2, \\ldots, n\\}$. For example, $X_{n+1}$ is understood as $X_1$, and $X_{n+2}$ as $X_2$.\n\nThe sample Yule-Walker equations, used for fitting autoregressive models, involve an autocovariance matrix. Using the PSACF, we can construct the $2 \\times 2$ matrix $\\hat{\\Gamma}_{P,2}$ as follows:\n$$\n\\hat{\\Gamma}_{P,2} = \\begin{pmatrix}\n\\hat{\\gamma}_P(0) & \\hat{\\gamma}_P(1) \\\\\n\\hat{\\gamma}_P(1) & \\hat{\\gamma}_P(0)\n\\end{pmatrix}\n$$\nWhen this matrix is singular, it indicates that the signal has a perfectly predictable structure that can pose challenges for standard time series model fitting procedures.\n\nYour task is to identify the simplest non-constant signal of a specific form that causes this singularity. Find the pair of integers $(n, A)$ that satisfies all of the following conditions:\n1. The time series is given by $X_t = A(-1)^{t-1}$ for $t = 1, 2, \\ldots, n$.\n2. $A$ must be the smallest positive integer that can define such a non-constant series.\n3. $n$ must be the smallest even integer satisfying $n > 2$ for which the corresponding matrix $\\hat{\\Gamma}_{P,2}$ is singular.\n\nDetermine the pair $(n, A)$.", "solution": "We consider the series defined by $X_{t} = A(-1)^{t-1}$ for $t = 1, 2, \\ldots, n$. This sequence has period $2$, so for the PSACF setup that assumes a period dividing $n$, we must take $n$ even. The smallest even integer with $n > 2$ is to be determined after verifying singularity conditions.\n\nFirst, compute the sample mean. For $n$ even,\n$$\n\\sum_{t=1}^{n} X_{t} = \\sum_{t=1}^{n} A(-1)^{t-1} = A\\sum_{t=1}^{n} (-1)^{t-1} = 0,\n$$\nsince there are equally many $+A$ and $-A$ terms. Hence,\n$$\n\\bar{X} = \\frac{1}{n} \\sum_{t=1}^{n} X_{t} = 0.\n$$\n\nNext, compute the PSACF at lags $0$ and $1$ using cyclic indexing.\n\nFor $h=0$,\n$$\n\\hat{\\gamma}_{P}(0) = \\frac{1}{n} \\sum_{t=1}^{n} (X_{t} - \\bar{X})^{2} = \\frac{1}{n} \\sum_{t=1}^{n} X_{t}^{2} = \\frac{1}{n} \\sum_{t=1}^{n} A^{2} = A^{2}.\n$$\n\nFor $h=1$,\n$$\n\\hat{\\gamma}_{P}(1) = \\frac{1}{n} \\sum_{t=1}^{n} (X_{t} - \\bar{X})(X_{t+1} - \\bar{X}) = \\frac{1}{n} \\sum_{t=1}^{n} X_{t} X_{t+1}.\n$$\nSince $X_{t+1} = A(-1)^{t} = -A(-1)^{t-1} = -X_{t}$ for all $t$ (including $t=n$ because $X_{n+1} = X_{1}$ by cyclic indexing and $n$ is even), we have\n$$\nX_{t} X_{t+1} = -X_{t}^{2} = -A^{2} \\quad \\text{for all } t,\n$$\nhence\n$$\n\\hat{\\gamma}_{P}(1) = \\frac{1}{n} \\sum_{t=1}^{n} (-A^{2}) = -A^{2}.\n$$\n\nTherefore, the $2 \\times 2$ PSACF matrix is\n$$\n\\hat{\\Gamma}_{P,2} = \\begin{pmatrix}\n\\hat{\\gamma}_{P}(0) & \\hat{\\gamma}_{P}(1) \\\\\n\\hat{\\gamma}_{P}(1) & \\hat{\\gamma}_{P}(0)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nA^{2} & -A^{2} \\\\\n- A^{2} & A^{2}\n\\end{pmatrix}.\n$$\nIts determinant is\n$$\n\\det(\\hat{\\Gamma}_{P,2}) = \\hat{\\gamma}_{P}(0)^{2} - \\hat{\\gamma}_{P}(1)^{2} = A^{4} - A^{4} = 0,\n$$\nso the matrix is singular for any even $n$ and any $A \\neq 0$. To satisfy the requirements:\n- The series must be non-constant, so $A$ must be the smallest positive integer, namely $A=1$.\n- The smallest even integer $n$ with $n > 2$ is $n=4$.\n\nThus, the required pair is $(n, A) = (4, 1)$.", "answer": "$$\\boxed{\\begin{pmatrix} 4 & 1 \\end{pmatrix}}$$", "id": "1350531"}]}