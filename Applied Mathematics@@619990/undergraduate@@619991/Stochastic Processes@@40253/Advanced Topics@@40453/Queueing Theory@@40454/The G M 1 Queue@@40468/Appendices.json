{"hands_on_practices": [{"introduction": "A cornerstone result for the G/M/1 queue is that the number of customers an arriving patron observes follows a simple geometric distribution. This exercise [@problem_id:1338307] invites you to explore the implications of this property by deriving the variance of this distribution. This practice not only reinforces fundamental skills with probability distributions but also deepens your intuition for how the key parameter $\\sigma$ quantifies the system's variability and predictability.", "problem": "In a stable G/M/1 queuing system, customers arrive and are served by a single server. The service times are exponentially distributed. An important result for this system is that the number of customers an arriving customer finds in the system (including any customer currently being served) follows a specific probability distribution when the system is in steady state. Let this random variable be denoted by $N$. The probability mass function of $N$ is given by $P(N=k) = (1-\\sigma)\\sigma^k$ for $k=0, 1, 2, \\dots$, where $\\sigma$ is a constant between 0 and 1 that represents the unique root of the equation $z = A^*(\\mu(1-z))$ in the interval $(0, 1)$. Here, $A^*(s)$ is the Laplace-Stieltjes Transform (LST) of the inter-arrival time distribution and $1/\\mu$ is the mean service time. Given this information, derive a closed-form expression for the variance of the number of customers an arriving customer sees, $\\text{Var}(N)$. Your final answer should be expressed solely in terms of $\\sigma$.", "solution": "The problem asks for the variance of a random variable $N$ whose probability mass function (PMF) is given by $P(N=k) = (1-\\sigma)\\sigma^k$ for $k=0, 1, 2, \\dots$. This is a geometric distribution on the set of non-negative integers.\n\nThe variance of a random variable $N$ is defined as:\n$$ \\text{Var}(N) = E[N^2] - (E[N])^2 $$\nWe need to calculate the first moment (expected value) $E[N]$ and the second moment $E[N^2]$.\n\n**Step 1: Calculate the expected value $E[N]$**\nThe expected value is calculated by definition:\n$$ E[N] = \\sum_{k=0}^{\\infty} k P(N=k) = \\sum_{k=0}^{\\infty} k (1-\\sigma)\\sigma^k $$\nWe can factor out the constant $(1-\\sigma)$:\n$$ E[N] = (1-\\sigma) \\sum_{k=0}^{\\infty} k \\sigma^k $$\nThe $k=0$ term is zero, so the sum can start from $k=1$:\n$$ E[N] = (1-\\sigma) \\sum_{k=1}^{\\infty} k \\sigma^k $$\nTo evaluate this sum, we recall the formula for a geometric series for $|\\sigma| < 1$:\n$$ \\sum_{k=0}^{\\infty} \\sigma^k = \\frac{1}{1-\\sigma} $$\nDifferentiating both sides with respect to $\\sigma$ gives:\n$$ \\frac{d}{d\\sigma} \\left( \\sum_{k=0}^{\\infty} \\sigma^k \\right) = \\sum_{k=1}^{\\infty} k \\sigma^{k-1} = \\frac{d}{d\\sigma} \\left( \\frac{1}{1-\\sigma} \\right) = \\frac{1}{(1-\\sigma)^2} $$\nMultiplying by $\\sigma$:\n$$ \\sum_{k=1}^{\\infty} k \\sigma^k = \\frac{\\sigma}{(1-\\sigma)^2} $$\nSubstituting this back into the expression for $E[N]$:\n$$ E[N] = (1-\\sigma) \\left( \\frac{\\sigma}{(1-\\sigma)^2} \\right) = \\frac{\\sigma}{1-\\sigma} $$\n\n**Step 2: Calculate the second moment $E[N^2]$**\nThe second moment is calculated by definition:\n$$ E[N^2] = \\sum_{k=0}^{\\infty} k^2 P(N=k) = (1-\\sigma) \\sum_{k=0}^{\\infty} k^2 \\sigma^k $$\nAgain, the sum can start from $k=1$:\n$$ E[N^2] = (1-\\sigma) \\sum_{k=1}^{\\infty} k^2 \\sigma^k $$\nTo evaluate this sum, we can use a similar differentiation trick. We start from the result of the first differentiation:\n$$ \\sum_{k=1}^{\\infty} k \\sigma^{k-1} = \\frac{1}{(1-\\sigma)^2} $$\nDifferentiating again with respect to $\\sigma$:\n$$ \\frac{d}{d\\sigma} \\left( \\sum_{k=1}^{\\infty} k \\sigma^{k-1} \\right) = \\sum_{k=2}^{\\infty} k(k-1)\\sigma^{k-2} = \\frac{d}{d\\sigma} \\left( \\frac{1}{(1-\\sigma)^2} \\right) = \\frac{2}{(1-\\sigma)^3} $$\nMultiplying by $\\sigma^2$:\n$$ \\sum_{k=2}^{\\infty} k(k-1)\\sigma^k = \\frac{2\\sigma^2}{(1-\\sigma)^3} $$\nWe can write $k^2 = k(k-1) + k$. Thus, the sum for $E[N^2]$ becomes:\n$$ \\sum_{k=1}^{\\infty} k^2 \\sigma^k = \\sum_{k=1}^{\\infty} (k(k-1) + k) \\sigma^k = \\sum_{k=1}^{\\infty} k(k-1)\\sigma^k + \\sum_{k=1}^{\\infty} k\\sigma^k $$\nThe term for $k=1$ in the first sum is zero, so its index can start from $k=2$. We have already found both of these sums:\n$$ \\sum_{k=1}^{\\infty} k^2 \\sigma^k = \\frac{2\\sigma^2}{(1-\\sigma)^3} + \\frac{\\sigma}{(1-\\sigma)^2} $$\nNow we substitute this back into the expression for $E[N^2]$:\n$$ E[N^2] = (1-\\sigma) \\left( \\frac{2\\sigma^2}{(1-\\sigma)^3} + \\frac{\\sigma}{(1-\\sigma)^2} \\right) $$\n$$ E[N^2] = \\frac{2\\sigma^2}{(1-\\sigma)^2} + \\frac{\\sigma}{1-\\sigma} $$\nTo combine these terms, we find a common denominator:\n$$ E[N^2] = \\frac{2\\sigma^2}{(1-\\sigma)^2} + \\frac{\\sigma(1-\\sigma)}{(1-\\sigma)^2} = \\frac{2\\sigma^2 + \\sigma - \\sigma^2}{(1-\\sigma)^2} = \\frac{\\sigma^2 + \\sigma}{(1-\\sigma)^2} $$\n\n**Step 3: Calculate the variance $\\text{Var}(N)$**\nNow we use the variance formula with our calculated moments:\n$$ \\text{Var}(N) = E[N^2] - (E[N])^2 $$\n$$ \\text{Var}(N) = \\frac{\\sigma^2 + \\sigma}{(1-\\sigma)^2} - \\left( \\frac{\\sigma}{1-\\sigma} \\right)^2 $$\n$$ \\text{Var}(N) = \\frac{\\sigma^2 + \\sigma}{(1-\\sigma)^2} - \\frac{\\sigma^2}{(1-\\sigma)^2} $$\n$$ \\text{Var}(N) = \\frac{(\\sigma^2 + \\sigma) - \\sigma^2}{(1-\\sigma)^2} = \\frac{\\sigma}{(1-\\sigma)^2} $$\nThis is the final expression for the variance of $N$ in terms of $\\sigma$.", "answer": "$$\\boxed{\\frac{\\sigma}{(1-\\sigma)^{2}}}$$", "id": "1338307"}, {"introduction": "Having explored the theoretical properties tied to the parameter $\\sigma$, we now turn to its calculation in a practical scenario. This problem [@problem_id:1338336] presents a system with regular, deterministic arrivals—a special but important case of the G/M/1 model known as the D/M/1 queue. Your task is to apply the fundamental G/M/1 equation to find the probability that a new arrival must wait, thereby bridging abstract theory and concrete performance analysis.", "problem": "In an automated manufacturing facility, a specialized robotic arm is tasked with processing components. These components are delivered by a conveyor belt, arriving one at a time at precisely regular intervals of $T = 30$ seconds. The time required for the robotic arm to complete its task on a single component is a random variable that follows an exponential distribution with a mean processing time of $25$ seconds. If a component arrives while the robot is already busy, it is held in a queue with sufficient capacity.\n\nAssuming the system has been operating for a long time and has reached a statistical equilibrium, which of the following choices best represents the probability that a newly arriving component finds the robotic arm busy and therefore must wait in the queue?\n\nA. 0.582\n\nB. 0.691\n\nC. 0.833\n\nD. 0.500\n\nE. 0.167", "solution": "Let the interarrival time be deterministic with value $T$ and the service time be exponential with mean $1/\\mu$, where $\\mu$ is the service rate. Here $T=30$ and the service rate is $\\mu=1/25$. The arrival rate is $\\lambda = 1/T = 1/30$, so the traffic intensity is $\\rho=\\frac{\\lambda}{\\mu}=\\frac{1/30}{1/25}=\\frac{25}{30}=\\frac{5}{6}<1$, ensuring stability.\n\nFor a G/M/1 queue, the steady-state probability that an arrival finds the server busy (equivalently, that it must wait) equals $\\sigma$, where $\\sigma$ is the unique root in $[0,1)$ of the functional equation\n$$\n\\sigma=A^*(\\mu(1-\\sigma)),\n$$\nwith $A^*(s)$ the Laplace–Stieltjes transform of the interarrival-time distribution. For a deterministic interarrival time $T$, $A^*(s)=\\exp(-sT)$, hence\n$$\n\\sigma=\\exp\\big(-(\\mu-\\mu \\sigma)T\\big)=\\exp\\big(-\\mu T(1-\\sigma)\\big).\n$$\nThis can be solved explicitly using the Lambert $W$ function. Let $\\mu T = \\frac{1}{25} \\times 30 = \\frac{6}{5}$. The equation becomes $\\sigma=\\exp\\big(-\\frac{6}{5}(1-\\sigma)\\big)$. Rewrite as\n$$\n\\sigma\\,\\exp(-\\tfrac{6}{5} \\sigma)=\\exp(-\\tfrac{6}{5}),\n$$\nthen multiply both sides by $-\\frac{6}{5}$ to obtain\n$$\n(-\\tfrac{6}{5} \\sigma)\\,\\exp(-\\tfrac{6}{5} \\sigma)=-\\tfrac{6}{5}\\,\\exp(-\\tfrac{6}{5}).\n$$\nThus\n$$\n-\\tfrac{6}{5} \\sigma=W_{0}\\big(-\\tfrac{6}{5}\\,\\exp(-\\tfrac{6}{5})\\big),\n$$\nwhere the principal branch $W_{0}$ yields the solution in $(0,1)$, so\n$$\n\\sigma=-\\frac{5}{6}\\,W_{0}\\Big(-\\frac{6}{5}\\,\\exp\\big(-\\tfrac{6}{5}\\big)\\Big).\n$$\nNumerically, this evaluates to $\\sigma \\approx 0.6863$. Among the provided options, this is closest to $0.691$, i.e., option B.\n\nTherefore, the probability that a newly arriving component finds the robotic arm busy (and must wait) is best represented by option B.", "answer": "$$\\boxed{B}$$", "id": "1338336"}, {"introduction": "We now shift our focus from static snapshots of the queue to its dynamic evolution over time. This engaging problem [@problem_id:1338311] delves into the relationship between the waiting times of consecutive customers. By leveraging a key property of the waiting time process, you will discover an elegant expression for this correlation, revealing how the parameter $\\sigma$ also governs the system's \"memory\" between successive arrivals.", "problem": "A specialized data processing center operates as a single-server queue. Data packets arrive with interarrival times drawn from a general probability distribution with a finite mean. The processing time for each packet is exponentially distributed with a rate parameter $\\mu$. This system is modeled as a G/M/1 queue.\n\nFor a stable G/M/1 queue, the stationary probability that an arriving packet finds the system busy (and therefore must wait in the queue) is given by a parameter $\\sigma \\in (0, 1)$. This parameter is the unique root within the interval $(0, 1)$ of the equation $\\sigma = A^*(\\mu(1-\\sigma))$, where $A^*(s)$ is the Laplace-Stieltjes transform of the interarrival time distribution.\n\nThe stationary waiting time in the queue, denoted by the random variable $W$, has a mixed distribution: there is a probability mass at $W=0$, and for $W > 0$, the distribution is continuous. Specifically, $P(W=0) = 1-\\sigma$, and conditional on having to wait, the waiting time follows an exponential distribution with rate $\\mu(1-\\sigma)$.\n\nA key property of the waiting time process $\\{W_n\\}$ for consecutive packets $n$ and $n+1$ in this specific system is that the conditional expectation of the next waiting time given the current one is piecewise linear. For a customer who experiences a waiting time $W_n = w > 0$, the expected waiting time for the next customer is given by:\n$$E[W_{n+1} | W_n = w] = \\sigma^2 w + E[W_{n+1} | W_n = 0]$$\nThis relation holds for any $w > 0$.\n\nAssuming the queue is in its stationary state, derive a symbolic expression for the correlation coefficient, $\\text{Corr}(W_n, W_{n+1})$, between the waiting times of two consecutive packets. Express your final answer in terms of $\\sigma$.", "solution": "Let $W$ denote $W_{n}$ and $W'$ denote $W_{n+1}$ in the stationary regime. By the given property, for $w>0$,\n$$\n\\mathbb{E}[W' \\mid W=w]=\\sigma^{2} w+\\mathbb{E}[W' \\mid W=0].\n$$\nDefine $a \\equiv \\mathbb{E}[W' \\mid W=0]$ and $b \\equiv \\sigma^{2}$. Since the right-hand side equals $a$ when $w=0$, the same affine relation holds at $w=0$, hence\n$$\n\\mathbb{E}[W' \\mid W]=a+bW \\quad \\text{almost surely}.\n$$\n\nUse the law of total covariance:\n$$\n\\operatorname{Cov}(W,W')=\\operatorname{Cov}\\bigl(W,\\mathbb{E}[W' \\mid W]\\bigr).\n$$\nSubstituting the affine form of the regression,\n$$\n\\operatorname{Cov}(W,W')=\\operatorname{Cov}(W,a+bW)=b\\,\\operatorname{Var}(W)=\\sigma^{2}\\operatorname{Var}(W).\n$$\n\nBy stationarity, $\\operatorname{Var}(W')=\\operatorname{Var}(W)$. Therefore, the correlation coefficient is\n$$\n\\operatorname{Corr}(W,W')=\\frac{\\operatorname{Cov}(W,W')}{\\sqrt{\\operatorname{Var}(W)\\operatorname{Var}(W')}}=\\frac{\\sigma^{2}\\operatorname{Var}(W)}{\\operatorname{Var}(W)}=\\sigma^{2}.\n$$\nThus,\n$$\n\\operatorname{Corr}(W_{n},W_{n+1})=\\sigma^{2}.\n$$", "answer": "$$\\boxed{\\sigma^{2}}$$", "id": "1338311"}]}