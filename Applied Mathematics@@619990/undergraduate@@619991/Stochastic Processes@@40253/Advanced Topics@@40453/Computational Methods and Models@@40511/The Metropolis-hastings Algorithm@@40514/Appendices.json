{"hands_on_practices": [{"introduction": "Mastering the Metropolis-Hastings algorithm begins with understanding its core decision-making step: the calculation of the acceptance probability. This first exercise focuses on this fundamental calculation for a continuous target distribution and a symmetric proposal, where the acceptance probability $\\alpha$ simplifies to $\\alpha = \\min(1, \\pi(x')/\\pi(x))$. By working through this problem [@problem_id:1962632], you will gain direct experience with how the algorithm uses the ratio of target probabilities to decide whether to explore a new state or remain in the current one, forming the basis of its journey through the probability space.", "problem": "A statistician is implementing a Markov Chain Monte Carlo (MCMC) simulation to generate samples from a specific target probability distribution. The target distribution is a standard exponential distribution, which has a probability density function (PDF) defined as $\\pi(x) = \\exp(-x)$ for all non-negative values of $x$.\n\nThe simulation employs the Metropolis-Hastings algorithm. At each step, given a current state $x$, a candidate for the next state, $x'$, is generated from a proposal distribution $q(x'|x)$. For this particular implementation, the proposal distribution is a uniform distribution centered at the current state, drawing a value from the interval $[x - 1.5, x + 1.5]$.\n\nSuppose that at a certain step in the simulation, the current state of the chain is $x = 1.0$. A new candidate state $x' = 2.0$ is proposed. Calculate the acceptance probability for this specific move.\n\nExpress your answer as a numerical value, rounded to four significant figures.", "solution": "The Metropolis-Hastings acceptance probability for a proposed move from $x$ to $x'$ is\n$$\n\\alpha(x,x')=\\min\\left(1,\\frac{\\pi(x')\\,q(x\\mid x')}{\\pi(x)\\,q(x'\\mid x)}\\right),\n$$\nwhere $\\pi(x)$ is the target density and $q(x'\\mid x)$ is the proposal density.\n\nHere the target density is the standard exponential,\n$$\n\\pi(x)=\\exp(-x)\\quad \\text{for } x\\ge 0,\n$$\nand the proposal is uniform on $[x-1.5,x+1.5]$, so\n$$\nq(x'\\mid x)=\\begin{cases}\n\\frac{1}{3}, & x'\\in [x-1.5,x+1.5],\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\nGiven $x=1.0$ and $x'=2.0$:\n- Both $x$ and $x'$ are in the support of $\\pi$.\n- Since $2.0\\in[-0.5,2.5]$, we have $q(x'\\mid x)=\\frac{1}{3}$.\n- Since $1.0\\in[0.5,3.5]$, we have $q(x\\mid x')=\\frac{1}{3}$.\n\nTherefore,\n$$\n\\alpha(1.0,2.0)=\\min\\left(1,\\frac{\\exp(-2.0)\\cdot \\frac{1}{3}}{\\exp(-1.0)\\cdot \\frac{1}{3}}\\right)\n=\\min\\left(1,\\exp(-(2.0-1.0))\\right)\n=\\min\\left(1,\\exp(-1)\\right).\n$$\nSince $\\exp(-1)<1$, the acceptance probability equals $\\exp(-1)$. Numerically,\n$$\n\\exp(-1)\\approx 0.367879\\ldots\n$$\nRounded to four significant figures, this is $0.3679$.", "answer": "$$\\boxed{0.3679}$$", "id": "1962632"}, {"introduction": "The power of the Metropolis-Hastings algorithm lies in its generality, particularly its ability to handle asymmetric proposal distributions where $q(x'|x) \\ne q(x|x')$. This is enabled by the full acceptance probability formula, $\\alpha = \\min\\left(1, \\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)$, which ensures the process satisfies the detailed balance condition. This practice problem [@problem_id:1343405] critically examines the consequences of misapplying the algorithm, demonstrating how using a simplified (Metropolis) acceptance rule with an asymmetric proposal causes the sampler to converge to an incorrect stationary distribution, thus highlighting the theoretical necessity of the Hastings correction factor.", "problem": "An analyst is implementing a Markov Chain Monte Carlo (MCMC) algorithm to sample from a discrete target probability distribution $\\pi$ defined over three states: $S_1$, $S_2$, and $S_3$. The target distribution is given by:\n$$\n\\pi(S_1) = \\frac{1}{2}, \\quad \\pi(S_2) = \\frac{1}{3}, \\quad \\pi(S_3) = \\frac{1}{6}\n$$\nThe analyst designs a deterministic, cyclic proposal mechanism described by the proposal distribution $q(y|x)$. From a state $x$, it always proposes the next state $y$ in the cycle $S_1 \\to S_2 \\to S_3 \\to S_1$. Specifically, the non-zero proposal probabilities are $q(S_2|S_1) = 1$, $q(S_3|S_2) = 1$, and $q(S_1|S_3) = 1$.\n\nHowever, in setting up the acceptance probability $\\alpha(x,y)$, the analyst mistakenly uses the simplified Metropolis acceptance rule:\n$$\n\\alpha(x,y) = \\min\\left(1, \\frac{\\pi(y)}{\\pi(x)}\\right)\n$$\nwhich is generally only valid when the proposal distribution $q(y|x)$ is symmetric.\n\nThe resulting Markov chain converges to a stationary distribution, let's call it $\\pi'$, which is different from the intended target distribution $\\pi$. Calculate the long-run probability that the chain is in state $S_2$. Express your answer as a fraction in simplest form.", "solution": "We construct the Markov chain induced by the deterministic proposal and the mistaken Metropolis acceptance rule. For states $S_{1}, S_{2}, S_{3}$, the proposal is $S_{1}\\to S_{2}\\to S_{3}\\to S_{1}$, and the acceptance probability used is\n$$\n\\alpha(x,y)=\\min\\left(1,\\frac{\\pi(y)}{\\pi(x)}\\right).\n$$\nGiven $\\pi(S_{1})=\\frac{1}{2}$, $\\pi(S_{2})=\\frac{1}{3}$, and $\\pi(S_{3})=\\frac{1}{6}$, the acceptance probabilities for proposed moves are:\n$$\n\\alpha(S_{1},S_{2})=\\min\\left(1,\\frac{\\pi(S_{2})}{\\pi(S_{1})}\\right)=\\min\\left(1,\\frac{\\frac{1}{3}}{\\frac{1}{2}}\\right)=\\frac{2}{3},\n$$\n$$\n\\alpha(S_{2},S_{3})=\\min\\left(1,\\frac{\\pi(S_{3})}{\\pi(S_{2})}\\right)=\\min\\left(1,\\frac{\\frac{1}{6}}{\\frac{1}{3}}\\right)=\\frac{1}{2},\n$$\n$$\n\\alpha(S_{3},S_{1})=\\min\\left(1,\\frac{\\pi(S_{1})}{\\pi(S_{3})}\\right)=\\min\\left(1,\\frac{\\frac{1}{2}}{\\frac{1}{6}}\\right)=1.\n$$\nThus, the transition probabilities (accept or stay) are:\n- From $S_{1}$: $P(S_{1}\\to S_{2})=\\frac{2}{3}$, $P(S_{1}\\to S_{1})=\\frac{1}{3}$.\n- From $S_{2}$: $P(S_{2}\\to S_{3})=\\frac{1}{2}$, $P(S_{2}\\to S_{2})=\\frac{1}{2}$.\n- From $S_{3}$: $P(S_{3}\\to S_{1})=1$.\n\nHence the transition matrix $P$ in the order $(S_{1},S_{2},S_{3})$ is\n$$\nP=\\begin{pmatrix}\n\\frac{1}{3} & \\frac{2}{3} & 0 \\\\\n0 & \\frac{1}{2} & \\frac{1}{2} \\\\\n1 & 0 & 0\n\\end{pmatrix}.\n$$\nLet the stationary distribution be $\\pi'=(a,b,c)$ with $a+b+c=1$ and $\\pi'=\\pi'P$. The stationarity equations are:\n$$\na=a\\cdot\\frac{1}{3}+b\\cdot 0+c\\cdot 1,\\quad\nb=a\\cdot\\frac{2}{3}+b\\cdot\\frac{1}{2}+c\\cdot 0,\\quad\nc=a\\cdot 0+b\\cdot\\frac{1}{2}+c\\cdot 0.\n$$\nFrom the third equation, $c=\\frac{b}{2}$. From the first equation, $a=\\frac{a}{3}+c$, hence $c=a-\\frac{a}{3}=\\frac{2a}{3}$. Equating the two expressions for $c$ gives $\\frac{b}{2}=\\frac{2a}{3}$, so $b=\\frac{4a}{3}$. Using $a+b+c=1$ with $c=\\frac{2a}{3}$ yields\n$$\na+\\frac{4a}{3}+\\frac{2a}{3}=a+2a=3a=1\\quad\\Rightarrow\\quad a=\\frac{1}{3},\n$$\nand therefore\n$$\nb=\\frac{4}{9},\\qquad c=\\frac{2}{9}.\n$$\nThus the long-run probability of being in state $S_{2}$ is $b=\\frac{4}{9}$.", "answer": "$$\\boxed{\\frac{4}{9}}$$", "id": "1343405"}, {"introduction": "A theoretically correct sampler can still be practically ineffective if it fails to explore the entire target distribution efficiently, a property known as ergodicity. This final exercise delves into one of the most common practical challenges in MCMC: tuning the sampler to navigate complex, multi-modal landscapes [@problem_id:1962668]. It illuminates the crucial trade-off in selecting a proposal step size and reveals why a high acceptance rate, while seemingly desirable, is not a definitive indicator of a well-performing sampler, especially when the chain can become trapped in a local probability mode.", "problem": "A data scientist is analyzing the posterior probability distribution for a parameter $\\theta$ of a complex climate model. The analysis reveals that the posterior distribution, denoted as $p(\\theta)$, is bimodal, with two distinct peaks of high probability located at $\\theta_A$ and $\\theta_B$, separated by a wide region of very low probability. To explore this distribution and estimate properties like the posterior mean, the scientist employs the Metropolis-Hastings (M-H) algorithm.\n\nThe M-H sampler is initialized with a starting value $\\theta_0$ located within the high-probability region around the first peak, $\\theta_A$. A symmetric proposal distribution $q(\\theta' | \\theta) = \\mathcal{N}(\\theta' | \\theta, \\sigma^2)$ is used, where $\\mathcal{N}$ is a normal distribution centered at the current state $\\theta$ with a standard deviation $\\sigma$, which represents the proposal step size. The scientist, aiming for a high acceptance rate, chooses a very small value for $\\sigma$ relative to the distance between the two modes, $|\\theta_A - \\theta_B|$.\n\nAfter running the M-H sampler for a very large number of iterations, which of the following descriptions most accurately characterizes the expected outcome of this simulation?\n\nA. The sampler will efficiently find the global maximum of the posterior distribution $p(\\theta)$ and remain there, thus providing an excellent point estimate for the parameter.\n\nB. The acceptance rate for proposed states will be very low, causing the chain to remain near the initial state $\\theta_0$ and explore very little of the parameter space.\n\nC. The generated chain of samples will be highly autocorrelated, and its histogram will largely represent the shape of the mode around $\\theta_A$, while failing to discover the mode around $\\theta_B$.\n\nD. The samples will alternate between the two modes in a systematic fashion, jumping from the region of $\\theta_A$ to the region of $\\theta_B$ and back again with regular frequency.\n\nE. The states of the chain will be nearly independent of one another, indicating that the sampler has successfully converged to the true bimodal posterior distribution.", "solution": "We analyze the Metropolis-Hastings (M-H) sampler with a symmetric proposal and very small proposal scale relative to the distance between two separated modes of the posterior $p(\\theta)$ at $\\theta_{A}$ and $\\theta_{B}$.\n\nFor a symmetric proposal $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta' \\mid \\theta, \\sigma^{2})$, the Metropolis-Hastings acceptance probability is\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\}.\n$$\nThe chain is initialized at $\\theta_{0}$ in the high-probability region around $\\theta_{A}$. Because $\\sigma$ is chosen to be very small compared to the separation $|\\theta_{A} - \\theta_{B}|$, proposed moves satisfy $|\\theta' - \\theta| = O(\\sigma)$ and thus remain very close to the current state. In a high-probability region near a mode, $p(\\theta')$ is close to $p(\\theta)$ for small steps, so\n$$\n\\frac{p(\\theta')}{p(\\theta)} \\approx 1,\n$$\nimplying that $a(\\theta \\rightarrow \\theta') \\approx 1$ and the local acceptance rate is high. Hence, option B (very low acceptance rate) is contradicted by the small-step, within-mode behavior.\n\nNext, consider transitions between the modes. The probability to directly propose a state near $\\theta_{B}$ from a current state near $\\theta_{A}$ under the Gaussian proposal is\n$$\nq(\\theta_{B} \\mid \\theta) \\propto \\exp\\left(-\\frac{|\\theta_{B} - \\theta|^{2}}{2 \\sigma^{2}}\\right).\n$$\nSince $\\sigma \\ll |\\theta_{A} - \\theta_{B}|$, this proposal probability is exponentially small in $|\\theta_{A} - \\theta_{B}|^{2} / \\sigma^{2}$. Therefore, direct jumps across the low-probability valley are essentially never proposed on practical time scales. Alternatively, crossing the valley via many small steps requires repeatedly proposing moves into regions where $p(\\theta') \\ll p(\\theta)$, for which\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\} \\ll 1,\n$$\nso such steps are overwhelmingly rejected. Consequently, the chain becomes effectively trapped near $\\theta_{A}$ for a very long time, failing to discover $\\theta_{B}$ in practice.\n\nBecause moves are very local and the chain stays within the same mode, successive samples are highly autocorrelated. The empirical histogram thus reflects the local shape around $\\theta_{A}$ but does not capture the separated mode near $\\theta_{B}$. This rules out option E (independence and successful convergence) and option D (regular alternation between modes). Option A is incorrect because M-H is a sampler targeting $p(\\theta)$, not an optimizer; moreover, with small steps and bimodality, it neither efficiently finds nor remains at a global maximum.\n\nTherefore, the most accurate description is that the chain exhibits high autocorrelation, predominantly samples the neighborhood of $\\theta_{A}$, and fails to discover the second mode $\\theta_{B}$.\n\nThe correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1962668"}]}