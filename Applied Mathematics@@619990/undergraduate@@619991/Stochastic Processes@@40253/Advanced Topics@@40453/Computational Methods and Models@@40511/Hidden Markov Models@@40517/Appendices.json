{"hands_on_practices": [{"introduction": "The first fundamental challenge in working with Hidden Markov Models is the Evaluation Problem: calculating the probability of a given sequence of observations. This practice will allow you to master the Forward Algorithm, a cornerstone of HMMs that efficiently computes this probability by summing over all possible hidden state paths. By tackling this hands-on example of an industrial sensor [@problem_id:1306030], you will gain a concrete understanding of how to determine the likelihood of observed data given a known model, a critical skill for model validation and comparison.", "problem": "An industrial sensor is used to monitor the quality of components on an assembly line. The sensor's status, which is not directly observable, can be modeled as a system with two hidden states: 'Operational' and 'Malfunctioning'. At each time step, which corresponds to the inspection of one component, the sensor either remains in its current state or transitions to the other. The sensor outputs one of two signals for each component it inspects: 'Pass' or 'Defect'.\n\nThe behavior of this system can be described by a Hidden Markov Model (HMM) defined by the following parameters:\n\nLet the set of hidden states be $S = \\{S_{\\text{Op}}, S_{\\text{Mal}}\\}$, where $S_{\\text{Op}}$ represents the 'Operational' state and $S_{\\text{Mal}}$ represents the 'Malfunctioning' state.\n\n1.  **Initial State Probabilities ($\\pi$):** At the beginning of the observation period (time $t=1$), the probabilities of the sensor being in each state are:\n    *   $P(S_{\\text{Op}}) = 0.95$\n    *   $P(S_{\\text{Mal}}) = 0.05$\n\n2.  **State Transition Probability Matrix ($A$):** This matrix gives the probability of transitioning from one state to another between consecutive time steps.\n    $$\n    A = \n    \\begin{pmatrix}\n    P(S_{t+1}=S_{\\text{Op}} | S_t=S_{\\text{Op}}) & P(S_{t+1}=S_{\\text{Mal}} | S_t=S_{\\text{Op}}) \\\\\n    P(S_{t+1}=S_{\\text{Op}} | S_t=S_{\\text{Mal}}) & P(S_{t+1}=S_{\\text{Mal}} | S_t=S_{\\text{Mal}})\n    \\end{pmatrix}\n    =\n    \\begin{pmatrix}\n    0.98 & 0.02 \\\\\n    0.15 & 0.85\n    \\end{pmatrix}\n    $$\n\n3.  **Observation Emission Probability Matrix ($B$):** This matrix gives the probability of observing a particular signal given the sensor's current hidden state.\n    $$\n    B = \n    \\begin{pmatrix}\n    P(\\text{'Pass'} | S_{\\text{Op}}) & P(\\text{'Defect'} | S_{\\text{Op}}) \\\\\n    P(\\text{'Pass'} | S_{\\text{Mal}}) & P(\\text{'Defect'} | S_{\\text{Mal}})\n    \\end{pmatrix}\n    =\n    \\begin{pmatrix}\n    0.99 & 0.01 \\\\\n    0.20 & 0.80\n    \\end{pmatrix}\n    $$\n\nAn engineer observes the sequence of signals from the sensor for three consecutive components: ('Pass', 'Pass', 'Defect').\n\nCalculate the total probability of observing this specific sequence. Round your final answer to four significant figures.", "solution": "We model the observation sequence using the forward algorithm. Let $\\alpha_{t}(s) = P(o_{1:t}, S_{t}=s)$, where $o_{1:t}$ denotes the observations from time $1$ to $t$, and $S_{t}$ is the hidden state at time $t$. The recursions are:\n$$\n\\alpha_{1}(s) = \\pi(s)\\, b_{s}(o_{1}), \\quad\n\\alpha_{t+1}(s') = \\left[\\sum_{s \\in S} \\alpha_{t}(s)\\, a_{s \\to s'}\\right] b_{s'}(o_{t+1}),\n$$\nand the total probability of the observation sequence $o_{1:3} = (\\text{Pass}, \\text{Pass}, \\text{Defect})$ is\n$$\nP(o_{1:3}) = \\sum_{s \\in S} \\alpha_{3}(s).\n$$\n\nInitial step for $t=1$ with $o_1=\\text{Pass}$:\n$$\n\\alpha_{1}(S_{\\text{Op}}) = \\pi(S_{\\text{Op}})\\, b_{S_{\\text{Op}}}(\\text{Pass}) = 0.95 \\cdot 0.99 = 0.9405,\n$$\n$$\n\\alpha_{1}(S_{\\text{Mal}}) = \\pi(S_{\\text{Mal}})\\, b_{S_{\\text{Mal}}}(\\text{Pass}) = 0.05 \\cdot 0.20 = 0.01.\n$$\n\nInduction for $t=2$ with $o_2=\\text{Pass}$:\n$$\n\\alpha_{2}(S_{\\text{Op}}) = \\left[\\alpha_{1}(S_{\\text{Op}})\\, a_{\\text{Op}\\to\\text{Op}} + \\alpha_{1}(S_{\\text{Mal}})\\, a_{\\text{Mal}\\to\\text{Op}}\\right] b_{S_{\\text{Op}}}(\\text{Pass})\n= \\left[0.9405 \\cdot 0.98 + 0.01 \\cdot 0.15\\right] \\cdot 0.99\n= 0.92319 \\cdot 0.99 = 0.9139581,\n$$\n$$\n\\alpha_{2}(S_{\\text{Mal}}) = \\left[\\alpha_{1}(S_{\\text{Op}})\\, a_{\\text{Op}\\to\\text{Mal}} + \\alpha_{1}(S_{\\text{Mal}})\\, a_{\\text{Mal}\\to\\text{Mal}}\\right] b_{S_{\\text{Mal}}}(\\text{Pass})\n= \\left[0.9405 \\cdot 0.02 + 0.01 \\cdot 0.85\\right] \\cdot 0.20\n= 0.02731 \\cdot 0.20 = 0.005462.\n$$\n\nInduction for $t=3$ with $o_3=\\text{Defect}$:\n$$\n\\alpha_{3}(S_{\\text{Op}}) = \\left[\\alpha_{2}(S_{\\text{Op}})\\, a_{\\text{Op}\\to\\text{Op}} + \\alpha_{2}(S_{\\text{Mal}})\\, a_{\\text{Mal}\\to\\text{Op}}\\right] b_{S_{\\text{Op}}}(\\text{Defect})\n= \\left[0.9139581 \\cdot 0.98 + 0.005462 \\cdot 0.15\\right] \\cdot 0.01\n= 0.896498238 \\cdot 0.01 = 0.00896498238,\n$$\n$$\n\\alpha_{3}(S_{\\text{Mal}}) = \\left[\\alpha_{2}(S_{\\text{Op}})\\, a_{\\text{Op}\\to\\text{Mal}} + \\alpha_{2}(S_{\\text{Mal}})\\, a_{\\text{Mal}\\to\\text{Mal}}\\right] b_{S_{\\text{Mal}}}(\\text{Defect})\n= \\left[0.9139581 \\cdot 0.02 + 0.005462 \\cdot 0.85\\right] \\cdot 0.80\n= 0.022921862 \\cdot 0.80 = 0.0183374896.\n$$\n\nTotal probability of the sequence is\n$$\nP(\\text{Pass}, \\text{Pass}, \\text{Defect}) = \\alpha_{3}(S_{\\text{Op}}) + \\alpha_{3}(S_{\\text{Mal}}) = 0.00896498238 + 0.0183374896 = 0.02730247198.\n$$\n\nRounding to four significant figures gives $0.02730$.", "answer": "$$\\boxed{0.02730}$$", "id": "1306030"}, {"introduction": "Moving beyond simply evaluating an observation sequence, we often want to uncover the most likely sequence of hidden states that produced it. This is known as the Decoding Problem, and it is solved using the elegant Viterbi algorithm. In this exercise [@problem_id:1306022], you will step into the role of a wildlife biologist and apply the Viterbi algorithm to infer an animal's hidden behaviors from observable GPS data. This practice illuminates how HMMs can be used to reconstruct a hidden narrative from indirect evidence, a powerful technique used in fields from bioinformatics to speech recognition.", "problem": "A wildlife biologist is studying the behavior of a solitary predator using a GPS collar. The biologist models the animal's behavior as a simple stochastic process with two unobservable internal states: `Hunting` and `Resting`. At the beginning of each hour, the animal is in exactly one of these two states. The collar, however, can only provide an observable signal indicating whether the animal is `Moving` or `Stationary`.\n\nThe parameters of the biologist's model are as follows:\n\n**1. Initial State Probabilities:**\nAt the very beginning of the observation period (at hour 1), the probabilities of the animal's initial state are:\n- Probability of being in the `Hunting` state: $0.2$\n- Probability of being in the `Resting` state: $0.8$\n\n**2. State Transition Probabilities (per hour):**\nThese probabilities describe how the animal's internal state changes from one hour to the next.\n- If the animal is `Hunting`, the probability it will be `Hunting` in the next hour is $0.7$.\n- If the animal is `Hunting`, the probability it will switch to `Resting` in the next hour is $0.3$.\n- If the animal is `Resting`, the probability it will remain `Resting` in the next hour is $0.9$.\n- If the animal is `Resting`, the probability it will switch to `Hunting` in the next hour is $0.1$.\n\n**3. Emission Probabilities:**\nThese probabilities link the unobservable internal state to the observable GPS signal.\n- If the animal is `Hunting`, the probability the collar reports `Moving` is $0.8$, and `Stationary` is $0.2$.\n- If the animal is `Resting`, the probability the collar reports `Moving` is $0.1$, and `Stationary` is $0.9$.\n\nOver a period of three hours, the biologist observes the following sequence of signals from the collar: `(Moving, Stationary, Moving)`.\n\nGiven this sequence of observations, determine the single most probable sequence of the animal's internal states for these three hours. Choose from the options below.\n\nA. (`Hunting`, `Hunting`, `Hunting`)\n\nB. (`Hunting`, `Resting`, `Hunting`)\n\nC. (`Resting`, `Resting`, `Hunting`)\n\nD. (`Resting`, `Resting`, `Resting`)\n\nE. (`Hunting`, `Resting`, `Resting`)", "solution": "We have a hidden Markov model with hidden states Hunting (H) and Resting (R), observations Moving (M) and Stationary (St), initial probabilities $\\pi_{H}=0.2$, $\\pi_{R}=0.8$, transition probabilities $a_{HH}=0.7$, $a_{HR}=0.3$, $a_{RH}=0.1$, $a_{RR}=0.9$, and emission probabilities $b_{H}(\\text{M})=0.8$, $b_{H}(\\text{St})=0.2$, $b_{R}(\\text{M})=0.1$, $b_{R}(\\text{St})=0.9$. The observed sequence is $(M,\\text{St},M)$. We apply the Viterbi algorithm, which uses the recursion\n$$\n\\delta_{t}(i)=b_{i}(o_{t})\\max_{j}\\left[\\delta_{t-1}(j)a_{ji}\\right],\\quad\n\\psi_{t}(i)=\\arg\\max_{j}\\left[\\delta_{t-1}(j)a_{ji}\\right],\n$$\nwith initialization $\\delta_{1}(i)=\\pi_{i}b_{i}(o_{1})$.\n\nInitialization at $t=1$ for $o_1=\\text{M}$:\n$$\n\\delta_{1}(H)=\\pi_{H}b_{H}(\\text{M})=0.2\\cdot 0.8=0.16,\\quad\n\\delta_{1}(R)=\\pi_{R}b_{R}(\\text{M})=0.8\\cdot 0.1=0.08.\n$$\n\nRecursion at $t=2$ for $o_2=\\text{St}$:\n$$\n\\delta_{2}(H)=b_{H}(\\text{St})\\max\\{\\delta_{1}(H)a_{HH},\\ \\delta_{1}(R)a_{RH}\\}\n=0.2\\max\\{0.16\\cdot 0.7,\\ 0.08\\cdot 0.1\\}\n=0.2\\cdot 0.112=0.0224,\n$$\nwith backpointer $\\psi_{2}(H)=H$ since $0.112>0.008$.\n$$\n\\delta_{2}(R)=b_{R}(\\text{St})\\max\\{\\delta_{1}(H)a_{HR},\\ \\delta_{1}(R)a_{RR}\\}\n=0.9\\max\\{0.16\\cdot 0.3,\\ 0.08\\cdot 0.9\\}\n=0.9\\cdot 0.072=0.0648,\n$$\nwith backpointer $\\psi_{2}(R)=R$ since $0.072>0.048$.\n\nRecursion at $t=3$ for $o_3=\\text{M}$:\n$$\n\\delta_{3}(H)=b_{H}(\\text{M})\\max\\{\\delta_{2}(H)a_{HH},\\ \\delta_{2}(R)a_{RH}\\}\n=0.8\\max\\{0.0224\\cdot 0.7,\\ 0.0648\\cdot 0.1\\}\n=0.8\\cdot 0.01568=0.012544,\n$$\nwith backpointer $\\psi_{3}(H)=H$ since $0.01568>0.00648$.\n$$\n\\delta_{3}(R)=b_{R}(\\text{M})\\max\\{\\delta_{2}(H)a_{HR},\\ \\delta_{2}(R)a_{RR}\\}\n=0.1\\max\\{0.0224\\cdot 0.3,\\ 0.0648\\cdot 0.9\\}\n=0.1\\cdot 0.05832=0.005832,\n$$\nwith backpointer $\\psi_{3}(R)=R$ since $0.05832>0.00672$.\n\nTermination and backtracking: since $\\delta_{3}(H)=0.012544>\\delta_{3}(R)=0.005832$, the most probable final state is $H$. Tracing back through the pointers gives $\\psi_{3}(H)=H$ and $\\psi_{2}(H)=H$, so the most probable state sequence is $(H,H,H)$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1306022"}, {"introduction": "The previous exercises assumed the model parameters (transition and emission probabilities) were already known. But how do we determine these parameters in the first place? This brings us to the Learning Problem, often solved using the Baum-Welch algorithm. This advanced practice [@problem_id:765296] gives you a look under the hood of this algorithm, challenging you to derive the parameter update rule within a Bayesian framework. By incorporating a prior distribution, this approach allows for more robust parameter estimation, and mastering this derivation will deepen your understanding of the machine learning principles that make HMMs so adaptable.", "problem": "In the context of a Hidden Markov Model (HMM), the Baum-Welch algorithm is an Expectation-Maximization (EM) procedure used to find the maximum likelihood estimate of the model parameters. Let an HMM be defined by a set of $N$ states $\\{S_1, \\dots, S_N\\}$, a transition probability matrix $A = \\{a_{ij}\\}$, an emission probability distribution $B$, and an initial state distribution $\\pi$.\n\nThe M-step of the Baum-Welch algorithm updates the model parameters to maximize the expected complete-data log-likelihood. For the transition probabilities $a'_{ij}$ (the new estimates), this maximization is equivalent to maximizing the term $\\sum_{i=1}^N \\sum_{j=1}^N C_{ij} \\log a'_{ij}$, where $C_{ij}$ represents the expected number of transitions from state $S_i$ to state $S_j$ given the observation sequence and the old parameters. This maximization is performed under the constraint that $\\sum_{j=1}^N a'_{ij} = 1$ for each state $S_i$.\n\nConsider a Bayesian approach where we aim for a Maximum a Posteriori (MAP) estimate instead of a Maximum Likelihood (ML) estimate. We place a prior distribution over the transition probabilities. Specifically, for each state $S_i$, the corresponding row of the transition matrix, $A'_{i} = (a'_{i1}, a'_{i2}, \\dots, a'_{iN})$, is assumed to follow a Dirichlet distribution with hyperparameter vector $\\mathbf{\\upsilon}_i = (\\upsilon_{i1}, \\upsilon_{i2}, \\dots, \\upsilon_{iN})$, where all $\\upsilon_{ij} > 0$. The probability density function is given by:\n$$\nP(A'_{i} | \\mathbf{\\upsilon}_i) \\propto \\prod_{j=1}^{N} (a'_{ij})^{\\upsilon_{ij}-1}\n$$\nThe total prior on the transition matrix $A'$ is $P(A') = \\prod_{i=1}^{N} P(A'_{i} | \\mathbf{\\upsilon}_i)$.\n\nThe M-step objective is now to maximize the log-posterior probability, which is proportional to the sum of the expected complete-data log-likelihood term and the log-prior term:\n$$\nL(A') = \\left(\\sum_{i=1}^N \\sum_{j=1}^N C_{ij} \\log a'_{ij}\\right) + \\log P(A')\n$$\nThis maximization is subject to the constraints $\\sum_{j=1}^N a'_{ij} = 1$ for all $i=1, \\dots, N$.\n\nDerive the expression for the re-estimated transition probability $a'_{ij}$ in terms of the expected transition counts $C_{ik}$ and the Dirichlet hyperparameters $\\upsilon_{ik}$ for $k=1, \\dots, N$.", "solution": "We maximize the log-posterior under the constraints $\\sum_{j=1}^N a'_{ij}=1$.  Introduce Lagrange multipliers $\\lambda_i$ and form\n$$\n\\mathcal{L}\n=\\sum_{i=1}^N\\sum_{j=1}^N\\bigl(C_{ij}+(\\upsilon_{ij}-1)\\bigr)\\log a'_{ij}\n+\\sum_{i=1}^N\\lambda_i\\Bigl(1-\\sum_{j=1}^N a'_{ij}\\Bigr).\n$$\nDifferentiate with respect to $a'_{ij}$:\n$$\n\\frac{\\partial\\mathcal{L}}{\\partial a'_{ij}}\n=\\frac{C_{ij}+\\upsilon_{ij}-1}{a'_{ij}}-\\lambda_i\n\\stackrel{!}{=}0\n\\;\\;\\Longrightarrow\\;\\;\na'_{ij}\n=\\frac{C_{ij}+\\upsilon_{ij}-1}{\\lambda_i}.\n$$\nEnforce the normalization $\\sum_{j=1}^N a'_{ij}=1$:\n$$\n\\sum_{j=1}^N a'_{ij}\n=\\frac{\\sum_{j=1}^N\\bigl(C_{ij}+\\upsilon_{ij}-1\\bigr)}{\\lambda_i}=1\n\\;\\;\\Longrightarrow\\;\\;\n\\lambda_i=\\sum_{k=1}^N\\bigl(C_{ik}+\\upsilon_{ik}-1\\bigr).\n$$\nSubstitute back to obtain the MAP update:\n$$\na'_{ij}\n=\\frac{C_{ij}+\\upsilon_{ij}-1}\n{\\displaystyle\\sum_{k=1}^N\\bigl(C_{ik}+\\upsilon_{ik}-1\\bigr)}.\n$$", "answer": "$$\\boxed{\\frac{C_{ij} + \\upsilon_{ij} - 1}{\\sum_{k=1}^N \\bigl(C_{ik} + \\upsilon_{ik} - 1\\bigr)}}$$", "id": "765296"}]}