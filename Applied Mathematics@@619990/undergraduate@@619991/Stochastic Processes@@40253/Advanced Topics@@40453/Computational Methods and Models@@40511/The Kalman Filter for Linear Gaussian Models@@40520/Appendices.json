{"hands_on_practices": [{"introduction": "The essence of the Kalman filter lies in its measurement update step, where it optimally blends a prior prediction with a new, noisy measurement. This first exercise provides a concrete, hands-on calculation of this crucial step in a simple scalar context. By working through this problem, you will see how the Kalman gain is determined by the uncertainties of the prediction and the measurement, and how it is used to produce a new estimate that is more accurate than either the prediction or the measurement alone. [@problem_id:1339626]", "problem": "A technician is monitoring the internal temperature of a small, experimental bioreactor using a digital control system. The system employs a Kalman filter to estimate the true temperature, which is subject to fluctuations. Let the true temperature at a discrete time step $k$ be denoted by $x_k$.\n\nAt a particular time step $k$, the system's dynamic model, based on previous data, provides a predicted temperature (the *a priori* state estimate) of $\\hat{x}_{k|k-1} = 85.2~^{\\circ}\\text{C}$. The variance associated with this prediction (the *a priori* error covariance) is $P_{k|k-1} = 1.5~({}^{\\circ}\\text{C})^2$, indicating the model's uncertainty.\n\nA temperature sensor provides a measurement, $z_k$. The measurement model is given by $z_k = H x_k + v_k$, where $H=1$ (the sensor directly measures the temperature) and $v_k$ is a zero-mean Gaussian noise term representing sensor inaccuracy. The variance of this measurement noise is specified as $R = 0.6~({}^{\\circ}\\text{C})^2$.\n\nAt this time step $k$, the sensor returns a measurement of $z_k = 84.1~^{\\circ}\\text{C}$.\n\nUsing a single update step of a linear Kalman filter, calculate the updated temperature estimate (the *a posteriori* state estimate) $\\hat{x}_{k|k}$ after incorporating this new measurement. Express your final answer in degrees Celsius, rounded to four significant figures.", "solution": "We use the standard linear Kalman filter measurement update for a scalar system. The measurement model is $z_{k} = H x_{k} + v_{k}$ with $H=1$ and measurement noise variance $R$. Given the a priori estimate $\\hat{x}_{k|k-1}$ and covariance $P_{k|k-1}$, the Kalman gain is\n$$\nK_{k} = \\frac{P_{k|k-1} H^{\\top}}{H P_{k|k-1} H^{\\top} + R}.\n$$\nWith $H=1$, this simplifies to\n$$\nK_{k} = \\frac{P_{k|k-1}}{P_{k|k-1} + R}.\n$$\nSubstituting the given values $P_{k|k-1} = 1.5$ and $R = 0.6$,\n$$\nK_{k} = \\frac{1.5}{1.5 + 0.6} = \\frac{1.5}{2.1} = \\frac{5}{7}.\n$$\nThe innovation (measurement residual) is\n$$\ny_{k} = z_{k} - H \\hat{x}_{k|k-1} = 84.1 - 85.2 = -1.1.\n$$\nThe a posteriori state estimate is\n$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_{k} y_{k} = 85.2 + \\frac{5}{7}(-1.1) = 85.2 - \\frac{11}{14}.\n$$\nNumerically,\n$$\n85.2 - \\frac{11}{14} = 84.414285714\\ldots\n$$\nRounded to four significant figures, this is $84.41$.", "answer": "$$\\boxed{84.41}$$", "id": "1339626"}, {"introduction": "Understanding a model's behavior in extreme or idealized scenarios can provide deep insights into its fundamental logic. This thought experiment explores the Kalman filter's update equations under the hypothetical condition of a perfect, noise-free measurement device where the measurement noise covariance $R_k = 0$. By analyzing this limiting case, you can verify the filter's intuitive consistency: when a measurement is perfect, the filter should trust it completely, leading to a posterior uncertainty of zero. [@problem_id:1339614]", "problem": "Consider a standard linear discrete-time system used in state estimation, described by the following equations:\n\nState transition: $x_k = F_k x_{k-1} + w_k$\nMeasurement model: $z_k = H_k x_k + v_k$\n\nHere, $x_k$ is the state vector at time step $k$, $z_k$ is the measurement vector, $F_k$ is the state transition matrix, and $H_k$ is the measurement matrix. The process noise $w_k$ and measurement noise $v_k$ are assumed to be zero-mean, white, and Gaussian, with covariance matrices $Q_k$ and $R_k$ respectively.\n\nThe operation of a Kalman filter is typically divided into two steps: prediction and update. The update-step equations, which correct the state estimate and its covariance using the new measurement, are given by:\n\nKalman Gain: $K_k = P_{k|k-1} H_k^T (H_k P_{k|k-1} H_k^T + R_k)^{-1}$\nState Update: $\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k (z_k - H_k \\hat{x}_{k|k-1})$\nCovariance Update: $P_{k|k} = (I - K_k H_k) P_{k|k-1}$\n\nwhere $\\hat{x}_{k|k-1}$ and $P_{k|k-1}$ are the predicted state and covariance from the previous step, and $\\hat{x}_{k|k}$ and $P_{k|k}$ are the updated state and covariance. $I$ is the identity matrix.\n\nImagine a breakthrough in sensor technology has led to the creation of a \"perfect\" measurement device. For such a device, the measurement noise is effectively zero, meaning its covariance matrix $R_k$ is the zero matrix ($R_k=0$). For this scenario, assume that the measurement matrix $H_k$ is a square and invertible matrix for all time steps $k$.\n\nUnder these conditions, the update step of the Kalman filter simplifies significantly. Which of the following options correctly describes the updated state estimate $\\hat{x}_{k|k}$ and its associated error covariance $P_{k|k}$?\n\nA. $\\hat{x}_{k|k} = H_k^{-1} z_k$ and $P_{k|k} = 0$\n\nB. $\\hat{x}_{k|k} = \\hat{x}_{k|k-1}$ and $P_{k|k} = P_{k|k-1}$\n\nC. $\\hat{x}_{k|k} = \\hat{x}_{k|k-1}$ and $P_{k|k} = 0$\n\nD. $\\hat{x}_{k|k} = z_k$ and $P_{k|k} = 0$\n\nE. $\\hat{x}_{k|k} = F_k \\hat{x}_{k-1|k-1}$ and $P_{k|k} = Q_k$", "solution": "We start from the given Kalman filter update equations:\n$$\nK_{k} = P_{k|k-1} H_{k}^{T} \\left(H_{k} P_{k|k-1} H_{k}^{T} + R_{k}\\right)^{-1},\n$$\n$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_{k} \\left(z_{k} - H_{k} \\hat{x}_{k|k-1}\\right),\n$$\n$$\nP_{k|k} = \\left(I - K_{k} H_{k}\\right) P_{k|k-1}.\n$$\nUnder the stated conditions, the measurement noise covariance is zero, so $R_{k} = 0$, and $H_{k}$ is square and invertible. Therefore, the Kalman gain reduces to\n$$\nK_{k} = P_{k|k-1} H_{k}^{T} \\left(H_{k} P_{k|k-1} H_{k}^{T}\\right)^{-1}.\n$$\nSince $P_{k|k-1}$ is a covariance matrix, it is positive definite in the generic case and hence invertible, and $H_{k}$ is invertible by assumption. Using the identity for invertible matrices $A, B, C$,\n$$\n(ABC)^{-1} = C^{-1} B^{-1} A^{-1},\n$$\nwith $A = H_{k}$, $B = P_{k|k-1}$, and $C = H_{k}^{T}$, we obtain\n$$\n\\left(H_{k} P_{k|k-1} H_{k}^{T}\\right)^{-1} = H_{k}^{-T} P_{k|k-1}^{-1} H_{k}^{-1}.\n$$\nSubstituting this into the expression for $K_{k}$ gives\n$$\nK_{k} = P_{k|k-1} H_{k}^{T} \\left(H_{k}^{-T} P_{k|k-1}^{-1} H_{k}^{-1}\\right).\n$$\nUsing $H_{k}^{T} H_{k}^{-T} = I$, we simplify:\n$$\nK_{k} = P_{k|k-1} \\left(I\\right) P_{k|k-1}^{-1} H_{k}^{-1} = H_{k}^{-1}.\n$$\nTherefore, the state update becomes\n$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + H_{k}^{-1} \\left(z_{k} - H_{k} \\hat{x}_{k|k-1}\\right) = H_{k}^{-1} z_{k}.\n$$\nThe covariance update is\n$$\nP_{k|k} = \\left(I - K_{k} H_{k}\\right) P_{k|k-1} = \\left(I - H_{k}^{-1} H_{k}\\right) P_{k|k-1} = 0.\n$$\nThus, with a perfect measurement device and invertible $H_{k}$, the updated state is exactly the state implied by the measurement, and the posterior covariance collapses to zero. This corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1339614"}, {"introduction": "Most real-world applications involve tracking systems with multiple, interconnected state variables, such as an object's position and velocity. This requires applying the full, matrix-based version of the Kalman filter's predict-update cycle. This practice moves beyond the scalar case to a common two-dimensional system, challenging you to propagate not just the state estimate but also its associated error covariance matrix through a complete cycle of prediction and update. [@problem_id:2888322]", "problem": "A discrete-time linear time-invariant (LTI) state-space model for a constant-velocity motion in one spatial dimension is given by the stochastic difference equations\n$$\nx_{k+1} = A x_{k} + w_{k}, \\quad y_{k} = C x_{k} + v_{k},\n$$\nwhere $x_{k} \\in \\mathbb{R}^{2}$ is the state with components position and velocity, $y_{k} \\in \\mathbb{R}$ is the position measurement, $w_{k}$ is zero-mean process noise with covariance $Q$, and $v_{k}$ is zero-mean measurement noise with covariance $R$. Assume the sampling interval is $1$ time unit so that\n$$\nA = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 1 & 0 \\end{bmatrix}, \\quad Q = \\operatorname{diag}(0.01,\\,0.01), \\quad R = \\begin{bmatrix} 0.04 \\end{bmatrix}.\n$$\nSuppose the initial a posteriori error covariance at time $k=0$ is\n$$\nP_{0} = I_{2}.\n$$\nStarting from this prior, perform one full Kalman filter (KF) prediction-update cycle to obtain the a posteriori error covariance at time $k=1$. Compute all intermediate quantities necessary for the covariance update, but report only the a posteriori error covariance matrix at time $k=1$ as your final answer. Round each reported matrix entry to $4$ significant figures. No physical units are required.", "solution": "The objective is to compute the a posteriori error covariance matrix at time $k=1$, denoted $P_{1|1}$, given the a posteriori error covariance at time $k=0$, denoted $P_{0|0}$. The Kalman filter provides the optimal linear estimator for a linear system with Gaussian noise by propagating the state estimate and its error covariance through a two-step recursive cycle: a prediction (time update) step and an update (measurement update) step.\n\nThe covariance propagation equations are as follows.\nPrediction:\n$$\nP_{k|k-1} = A P_{k-1|k-1} A^T + Q\n$$\nUpdate:\n$$\nK_k = P_{k|k-1} C^T (C P_{k|k-1} C^T + R)^{-1}\n$$\n$$\nP_{k|k} = (I - K_k C) P_{k|k-1}\n$$\nHere, $P_{k|k-1}$ is the a priori error covariance at time $k$, and $P_{k|k}$ is the a posteriori error covariance at time $k$. $K_k$ is the Kalman gain.\n\nThe given parameters are:\nState transition matrix: $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$\nMeasurement matrix: $C = \\begin{bmatrix} 1 & 0 \\end{bmatrix}$\nProcess noise covariance: $Q = \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix}$\nMeasurement noise covariance: $R = [0.04]$\nInitial a posteriori error covariance at $k=0$: $P_{0|0} = I_2 = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n\nWe shall now perform one full cycle for $k=1$.\n\n**Step 1: Prediction (Time Update)**\n\nWe compute the a priori error covariance at $k=1$, $P_{1|0}$, using the state of the covariance at $k=0$.\n$$\nP_{1|0} = A P_{0|0} A^T + Q\n$$\nSubstituting the given values:\n$$\nA P_{0|0} A^T = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 + 1 \\cdot 1 & 1 \\cdot 0 + 1 \\cdot 1 \\\\ 0 \\cdot 1 + 1 \\cdot 1 & 0 \\cdot 0 + 1 \\cdot 1 \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\\\ 1 & 1 \\end{bmatrix}\n$$\nNow, we add the process noise covariance $Q$:\n$$\nP_{1|0} = \\begin{bmatrix} 2 & 1 \\\\ 1 & 1 \\end{bmatrix} + \\begin{bmatrix} 0.01 & 0 \\\\ 0 & 0.01 \\end{bmatrix} = \\begin{bmatrix} 2.01 & 1 \\\\ 1 & 1.01 \\end{bmatrix}\n$$\nThis is the predicted error covariance before incorporating the measurement at $k=1$.\n\n**Step 2: Update (Measurement Update)**\n\nFirst, we compute the innovation covariance, which we denote as $S_1$:\n$$\nS_1 = C P_{1|0} C^T + R\n$$\n$$\nC P_{1|0} C^T = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 2.01 & 1 \\\\ 1 & 1.01 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 2.01 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = [2.01]\n$$\n$$\nS_1 = [2.01] + [0.04] = [2.05]\n$$\nNext, we compute the Kalman gain $K_1$:\n$$\nK_1 = P_{1|0} C^T S_1^{-1}\n$$\n$$\nP_{1|0} C^T = \\begin{bmatrix} 2.01 & 1 \\\\ 1 & 1.01 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 2.01 \\\\ 1 \\end{bmatrix}\n$$\n$$\nK_1 = \\begin{bmatrix} 2.01 \\\\ 1 \\end{bmatrix} [2.05]^{-1} = \\begin{bmatrix} \\frac{2.01}{2.05} \\\\ \\frac{1}{2.05} \\end{bmatrix}\n$$\nFinally, we compute the a posteriori error covariance $P_{1|1}$:\n$$\nP_{1|1} = (I - K_1 C) P_{1|0}\n$$\nLet us compute the term $(I - K_1 C)$:\n$$\nK_1 C = \\begin{bmatrix} \\frac{2.01}{2.05} \\\\ \\frac{1}{2.05} \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\end{bmatrix} = \\begin{bmatrix} \\frac{2.01}{2.05} & 0 \\\\ \\frac{1}{2.05} & 0 \\end{bmatrix}\n$$\n$$\nI - K_1 C = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} \\frac{2.01}{2.05} & 0 \\\\ \\frac{1}{2.05} & 0 \\end{bmatrix} = \\begin{bmatrix} 1 - \\frac{2.01}{2.05} & 0 \\\\ -\\frac{1}{2.05} & 1 \\end{bmatrix} = \\begin{bmatrix} \\frac{0.04}{2.05} & 0 \\\\ -\\frac{1}{2.05} & 1 \\end{bmatrix}\n$$\nNow we perform the final matrix multiplication:\n$$\nP_{1|1} = \\begin{bmatrix} \\frac{0.04}{2.05} & 0 \\\\ -\\frac{1}{2.05} & 1 \\end{bmatrix} \\begin{bmatrix} 2.01 & 1 \\\\ 1 & 1.01 \\end{bmatrix}\n$$\n$$\nP_{1|1} = \\begin{bmatrix} (\\frac{0.04}{2.05})(2.01) + (0)(1) & (\\frac{0.04}{2.05})(1) + (0)(1.01) \\\\ (-\\frac{1}{2.05})(2.01) + (1)(1) & (-\\frac{1}{2.05})(1) + (1)(1.01) \\end{bmatrix}\n$$\n$$\nP_{1|1} = \\begin{bmatrix} \\frac{0.0804}{2.05} & \\frac{0.04}{2.05} \\\\ \\frac{-2.01 + 2.05}{2.05} & \\frac{-1 + 1.01 \\cdot 2.05}{2.05} \\end{bmatrix} = \\begin{bmatrix} \\frac{0.0804}{2.05} & \\frac{0.04}{2.05} \\\\ \\frac{0.04}{2.05} & \\frac{1.0705}{2.05} \\end{bmatrix}\n$$\nThe problem requires the matrix entries to be rounded to $4$ significant figures.\n$$\nP_{1|1}(1,1) = \\frac{0.0804}{2.05} \\approx 0.0392195... \\approx 0.03922\n$$\n$$\nP_{1|1}(1,2) = P_{1|1}(2,1) = \\frac{0.04}{2.05} \\approx 0.0195121... \\approx 0.01951\n$$\n$$\nP_{1|1}(2,2) = \\frac{1.0705}{2.05} \\approx 0.5221951... \\approx 0.5222\n$$\nThus, the a posteriori error covariance matrix at $k=1$ is:\n$$\nP_{1|1} \\approx \\begin{bmatrix} 0.03922 & 0.01951 \\\\ 0.01951 & 0.5222 \\end{bmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.03922 & 0.01951 \\\\ 0.01951 & 0.5222 \\end{pmatrix}}\n$$", "id": "2888322"}]}