{"hands_on_practices": [{"introduction": "The Picard-Lindelöf theorem doesn't just promise that a solution exists; its proof provides a concrete recipe for approximating it. This technique, known as Picard's method of successive approximations, builds a sequence of functions that converge to the actual solution, starting from an initial guess. This exercise [@problem_id:1675298] offers hands-on practice with this powerful iterative process, helping to demystify the constructive nature of existence proofs and build your computational fluency.", "problem": "In a simplified model for the dynamics of a driven, damped system, a quantity of interest $y(t)$ evolves according to the first-order Ordinary Differential Equation (ODE):\n$$ \\frac{dy}{dt} = \\sin(t) - k y(t) $$\nwhere $k$ is a positive real constant representing a damping factor and the $\\sin(t)$ term represents a periodic driving force. The system is known to be at its zero state initially, meaning $y(0) = 0$.\n\nPicard's method of successive approximations provides a way to construct a sequence of functions, $y_n(t)$, that converge to the true solution of this Initial Value Problem (IVP). The process begins with an initial approximation $y_0(t)$ based on the initial condition. Each subsequent approximation is generated by integrating the governing ODE with the previous approximation substituted into it.\n\nYour task is to determine the third Picard approximation, $y_3(t)$, which is the third function generated by the iterative process after the initial guess $y_0(t)$. Express your final answer as an analytic function of $t$ and $k$.", "solution": "We apply Picard’s successive approximations to the IVP $y^{\\prime}(t)=\\sin(t)-k y(t)$ with $y(0)=0$. The iterative scheme is\n$$\ny_{n+1}(t)=y(0)+\\int_{0}^{t}\\left[\\sin(s)-k\\,y_{n}(s)\\right]\\,ds,\n$$\nstarting from $y_{0}(t)=0$.\n\nFirst approximation:\n$$\ny_{1}(t)=\\int_{0}^{t}\\sin(s)\\,ds=1-\\cos(t).\n$$\n\nSecond approximation:\n$$\ny_{2}(t)=\\int_{0}^{t}\\left[\\sin(s)-k\\,y_{1}(s)\\right]ds\n=\\int_{0}^{t}\\sin(s)\\,ds-k\\int_{0}^{t}\\left[1-\\cos(s)\\right]ds,\n$$\n$$\ny_{2}(t)=\\left[1-\\cos(t)\\right]-k\\left[t-\\sin(t)\\right]=1-\\cos(t)-k t+k\\sin(t).\n$$\n\nThird approximation:\n$$\ny_{3}(t)=\\int_{0}^{t}\\left[\\sin(s)-k\\,y_{2}(s)\\right]ds\n=\\int_{0}^{t}\\sin(s)\\,ds-k\\int_{0}^{t}\\left[1-\\cos(s)-k s+k\\sin(s)\\right]ds.\n$$\nCompute the integrals term by term:\n$$\n\\int_{0}^{t}\\sin(s)\\,ds=1-\\cos(t),\\quad \\int_{0}^{t}1\\,ds=t,\\quad \\int_{0}^{t}-\\cos(s)\\,ds=-\\sin(t),\n$$\n$$\n\\int_{0}^{t}-k s\\,ds=-\\frac{k}{2}t^{2},\\quad \\int_{0}^{t}k\\sin(s)\\,ds=k\\left[1-\\cos(t)\\right].\n$$\nTherefore,\n$$\n\\int_{0}^{t}y_{2}(s)\\,ds=t-\\sin(t)-\\frac{k}{2}t^{2}+k\\left[1-\\cos(t)\\right],\n$$\nand\n$$\ny_{3}(t)=\\left[1-\\cos(t)\\right]-k\\left[t-\\sin(t)-\\frac{k}{2}t^{2}+k\\left(1-\\cos(t)\\right)\\right].\n$$\nSimplifying,\n$$\ny_{3}(t)=\\left(1-k^{2}\\right)+\\left(k^{2}-1\\right)\\cos(t)+k\\sin(t)-k t+\\frac{k^{2}}{2}t^{2}\n= k\\sin(t)+\\left(k^{2}-1\\right)\\left[\\cos(t)-1\\right]-k t+\\frac{k^{2}}{2}t^{2}.\n$$\nThis is the third Picard approximation.", "answer": "$$\\boxed{k\\sin(t)+\\left(k^{2}-1\\right)\\left(\\cos(t)-1\\right)-k t+\\frac{k^{2}}{2}t^{2}}$$", "id": "1675298"}, {"introduction": "While the existence of a solution is fundamental, its uniqueness is often just as critical for a differential equation to serve as a reliable predictive model. The key to guaranteeing uniqueness lies in a property called Lipschitz continuity, which is a stronger requirement than simple continuity. This problem [@problem_id:2172764] challenges you to explore the subtle yet crucial difference between the conditions of differentiability and Lipschitz continuity, clarifying why the latter provides a more general criterion for ensuring a one-of-a-kind solution passes through an initial point.", "problem": "Consider the following two theorems regarding the existence and uniqueness of solutions for a first-order Initial Value Problem (IVP) of the form $y' = f(t, y)$ with an initial condition $y(t_0) = y_0$.\n\n*   **Theorem 1 (Differentiability Condition):** If $f(t, y)$ and its partial derivative with respect to $y$, $\\frac{\\partial f}{\\partial y}$, are both continuous on an open rectangle $R$ in the $ty$-plane that contains the point $(t_0, y_0)$, then there exists an interval around $t_0$ on which the IVP has a unique solution.\n*   **Theorem 2 (Lipschitz Condition):** A function $f(t, y)$ is said to be Lipschitz continuous with respect to $y$ on a domain $D$ if there exists a positive constant $K$ (the Lipschitz constant) such that $|f(t, y_1) - f(t, y_2)| \\leq K|y_1 - y_2|$ for all $(t, y_1)$ and $(t, y_2)$ in $D$. If $f(t, y)$ is continuous and Lipschitz continuous with respect to $y$ on an open rectangle $R$ containing $(t_0, y_0)$, then there exists an interval around $t_0$ on which the IVP has a unique solution.\n\nNow, consider the specific IVP given by the differential equation $y' = |y|$ with the initial condition $y(0) = 0$.\n\nWhich of the following statements accurately describes the application of these theorems to this IVP?\n\nA. The IVP fails to have a unique solution because the conditions of Theorem 1 are not satisfied at the initial point $(0, 0)$.\n\nB. The IVP is guaranteed to have a unique solution by Theorem 1 because the function $f(t, y)=|y|$ and its partial derivative are continuous.\n\nC. The IVP has multiple distinct solutions passing through $(0,0)$ because the function $f(t,y)=|y|$ is not Lipschitz continuous with respect to $y$.\n\nD. The IVP is guaranteed to have a unique solution by Theorem 2, even though the conditions for Theorem 1 are not met.\n\nE. The IVP has a unique solution, and both Theorem 1 and Theorem 2 can be used to guarantee this uniqueness.", "solution": "We are given the IVP $y' = |y|$ with $y(0) = 0$ and asked which theorem(s) apply and what conclusion about uniqueness follows.\n\nFirst, set $f(t,y) = |y|$. Note that $f$ is continuous in $(t,y)$ on $\\mathbb{R}^{2}$ because the absolute value function is continuous.\n\nCheck Theorem 1 (Differentiability Condition): This requires both $f$ and $\\frac{\\partial f}{\\partial y}$ to be continuous on an open rectangle containing $(0,0)$. Compute the partial derivative with respect to $y$:\n$$\n\\frac{\\partial f}{\\partial y}(t,y) = \n\\begin{cases}\n1, & y>0,\\\\\n-1, & y<0.\n\\end{cases}\n$$\nAt $y=0$, the one-sided limits are $1$ and $-1$, so $\\frac{\\partial f}{\\partial y}(t,0)$ does not exist and, in particular, cannot be continuous at $y=0$. Therefore, the hypotheses of Theorem 1 are not satisfied at $(0,0)$, so Theorem 1 cannot be used to guarantee uniqueness.\n\nCheck Theorem 2 (Lipschitz Condition): We verify that $f$ is Lipschitz in $y$. For any fixed $t$ and any $y_{1},y_{2}$,\n$$\n|f(t,y_{1}) - f(t,y_{2})| = ||y_{1}| - |y_{2}|| \\leq |y_{1} - y_{2}|,\n$$\nby the reverse triangle inequality. Hence $f$ is Lipschitz in $y$ with Lipschitz constant $K=1$ on any domain. Since $f$ is also continuous, Theorem 2 applies on any open rectangle containing $(0,0)$ and guarantees existence and uniqueness of a solution through $(0,0)$.\n\nFor completeness, the unique solution through $(0,0)$ is $y(t)\\equiv 0$. Indeed, if $y(t_{0})=0$, then on any interval where $y\\geq 0$ one has $y' = y$, and the solution with zero initial value is $y\\equiv 0$; similarly, on any interval where $y\\leq 0$ one has $y' = -y$, and again the solution with zero initial value is $y\\equiv 0$. Uniqueness from Theorem 2 rules out any nontrivial branching from zero.\n\nTherefore:\n- Theorem 1 does not apply.\n- Theorem 2 applies and guarantees uniqueness.\n- The IVP does not have multiple distinct solutions through $(0,0)$.\n\nThe correct choice is D.", "answer": "$$\\boxed{D}$$", "id": "2172764"}, {"introduction": "What happens when the conditions for uniqueness, such as Lipschitz continuity, are not met at an initial point? This is not merely a theoretical curiosity; it might signify that the initial state of a system is not sufficient to determine its future uniquely. This exercise [@problem_id:1675288] provides a striking demonstration of non-uniqueness by guiding you to construct a non-trivial solution to an initial value problem, which alongside the obvious trivial solution, proves that the system's evolution from the starting condition is ambiguous.", "problem": "Consider the initial value problem defined by the differential equation\n$$ \\frac{dy}{dt} = 3|y|^{2/3} $$\nand the initial condition $y(0)=0$.\n\nWhile $y(t)=0$ for all $t$ is a solution, it is considered the trivial solution. A non-trivial solution to this problem for $t \\ge 0$ can be expressed in the form $y(t) = C t^k$, where $C$ is a real constant and $k$ is a positive real constant. Determine the value of this non-trivial solution evaluated at $t=8$.", "solution": "We seek a non-trivial solution of the form $y(t)=C t^{k}$ with $k>0$. Compute the derivative and the right-hand side:\n$$\n\\frac{dy}{dt} = C k t^{k-1}, \\qquad 3|y|^{2/3} = 3|C|^{2/3}|t^{k}|^{2/3}.\n$$\nSince $t \\ge 0$, we have $|t^{k}| = t^{k}$, hence\n$$\n3|y|^{2/3} = 3|C|^{2/3} t^{\\frac{2k}{3}}.\n$$\nEquating both sides of the differential equation for all $t>0$,\n$$\nC k t^{k-1} = 3|C|^{2/3} t^{\\frac{2k}{3}}.\n$$\nMatching exponents gives\n$$\nk - 1 = \\frac{2k}{3} \\quad \\Longrightarrow \\quad 3k - 3 = 2k \\quad \\Longrightarrow \\quad k = 3.\n$$\nMatching coefficients with $k=3$ gives\n$$\n3C = 3|C|^{\\frac{2}{3}} \\quad \\Longrightarrow \\quad C = |C|^{\\frac{2}{3}}.\n$$\nBecause the right-hand side of the ODE is nonnegative, for $t>0$ the left-hand side $C k t^{k-1}$ must be nonnegative, which forces $C \\ge 0$, hence $|C|=C$. Therefore\n$$\nC = C^{\\frac{2}{3}} \\quad \\Longrightarrow \\quad C = 0 \\text{ or } C^{\\frac{1}{3}} = 1 \\Longrightarrow C=1.\n$$\nThe trivial $C=0$ is excluded, so the non-trivial monomial solution is $y(t)=t^{3}$. Evaluating at $t=8$ yields\n$$\ny(8) = 8^{3} = 512.\n$$", "answer": "$$\\boxed{512}$$", "id": "1675288"}]}