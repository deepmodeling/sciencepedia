{"hands_on_practices": [{"introduction": "The concept of a Nash equilibrium is the cornerstone of game theory, representing a stable state where no participant can improve their outcome by changing their strategy alone. This first exercise [@problem_id:1377566] provides a classic business scenario to build your intuition for this fundamental concept. By analyzing a payoff matrix, you will learn to identify pure strategy Nash equilibria by systematically checking for mutual best responses.", "problem": "Two competing companies, \"Apex Books\" and \"Vertex Books\", are planning to open their first bookstores in a city. They must each independently and simultaneously choose one of three districts to open in: the Arts District (A), the Business Hub (B), or the Campus Town (C). The success of each bookstore depends on both its own location and the location of its competitor.\n\nMarket analysis has produced a payoff matrix representing the expected monthly profit, in thousands of dollars, for each combination of choices. The pair of numbers in each cell `(x, y)` represents the profit for Apex Books (`x`) and Vertex Books (`y`), respectively. Apex Books is the \"row player\" and Vertex Books is the \"column player\".\n\nThe payoff matrix is as follows:\n\nbr\n\n| Apex \\ Vertex | District A | District B | District C |\n| :--- | :--- | :--- | :--- |\n| **District A** | (10, 10)| (25, 15)| (35, 45)|\n| **District B** | (15, 25)| (8, 8) | (15, 40)|\n| **District C** | (45, 35)| (40, 15)| (20, 20)|\n\nbr\n\nLet a strategy profile be denoted by a pair `(Apex's Choice, Vertex's Choice)`. Identify all pure strategy Nash equilibria in this location game.\n\nA. The only equilibrium is (C, C).\n\nB. The equilibria are (A, C) and (C, A).\n\nC. The equilibria are (A, A), (B, B), and (C, C).\n\nD. There are no pure strategy Nash equilibria.\n\nE. The only equilibrium is (A, C).", "solution": "A pure strategy Nash equilibrium is a strategy profile in which each player’s chosen strategy is a best response to the other’s choice. Formally, a profile $(s_{R},s_{C})$ is a Nash equilibrium if $u_{R}(s_{R},s_{C}) \\geq u_{R}(s_{R}^{\\prime},s_{C})$ for all $s_{R}^{\\prime}$ and $u_{C}(s_{R},s_{C}) \\geq u_{C}(s_{R},s_{C}^{\\prime})$ for all $s_{C}^{\\prime}$.\n\nCompute Apex Books’ (row player’s) best responses to each Vertex Books’ (column player’s) choice by comparing Apex’s payoffs across rows for each fixed column:\n- If Vertex chooses District A, Apex’s payoffs are $u_{R}(A,A)=10$, $u_{R}(B,A)=15$, $u_{R}(C,A)=45$. The maximum is $45$ at $C$, so the best response set is $\\{C\\}$.\n- If Vertex chooses District B, Apex’s payoffs are $u_{R}(A,B)=25$, $u_{R}(B,B)=8$, $u_{R}(C,B)=40$. The maximum is $40$ at $C$, so the best response set is $\\{C\\}$.\n- If Vertex chooses District C, Apex’s payoffs are $u_{R}(A,C)=35$, $u_{R}(B,C)=15$, $u_{R}(C,C)=20$. The maximum is $35$ at $A$, so the best response set is $\\{A\\}$.\n\nThus Apex’s best responses are: to A $\\rightarrow C$, to B $\\rightarrow C$, to C $\\rightarrow A$.\n\nCompute Vertex Books’ best responses to each Apex choice by comparing Vertex’s payoffs across columns for each fixed row:\n- If Apex chooses District A, Vertex’s payoffs are $u_{C}(A,A)=10$, $u_{C}(A,B)=15$, $u_{C}(A,C)=45$. The maximum is $45$ at $C$, so the best response set is $\\{C\\}$.\n- If Apex chooses District B, Vertex’s payoffs are $u_{C}(B,A)=25$, $u_{C}(B,B)=8$, $u_{C}(B,C)=40$. The maximum is $40$ at $C$, so the best response set is $\\{C\\}$.\n- If Apex chooses District C, Vertex’s payoffs are $u_{C}(C,A)=35$, $u_{C}(C,B)=15$, $u_{C}(C,C)=20$. The maximum is $35$ at $A$, so the best response set is $\\{A\\}$.\n\nThus Vertex’s best responses are: to A $\\rightarrow C$, to B $\\rightarrow C$, to C $\\rightarrow A$.\n\nA pure strategy Nash equilibrium must be a mutual best response. The profiles where both players’ choices are best responses to each other are:\n- $(A,C)$: Apex’s best response to $C$ is $A$, and Vertex’s best response to $A$ is $C$.\n- $(C,A)$: Apex’s best response to $A$ is $C$, and Vertex’s best response to $C$ is $A$.\n\nNo other profile satisfies mutual best responses. Therefore, the pure strategy Nash equilibria are $(A,C)$ and $(C,A)$, which corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1377566"}, {"introduction": "Not all strategic interactions have a stable outcome where players choose a single, deterministic action. This exercise [@problem_id:1377571] introduces the crucial concept of mixed strategies, where players randomize their choices to remain unpredictable. You will explore a classic zero-sum game to learn how to calculate the optimal probabilities that form a mixed strategy Nash equilibrium and determine the game's expected value.", "problem": "In a simplified strategic engagement scenario, two opponents, Strategist Alpha and Strategist Beta, play a simultaneous, zero-sum game. Each strategist can choose to display one of two signals: Signal 1 or Signal 2. The outcome of each round is determined by the sum of the signal numbers displayed. The rules for awarding \"strategy points\" are as follows:\n\n1.  If the sum of the signal numbers is an odd number, Strategist Alpha wins a number of strategy points equal to that sum.\n2.  If the sum of the signal numbers is an even number, Strategist Beta wins a number of strategy points equal to that sum.\n\nSince the game is zero-sum, a win for one strategist is an equivalent loss for the other. For example, if Beta wins 4 points, Alpha's score changes by -4.\n\nAssuming both strategists are perfectly rational and play optimally to maximize their own long-term average outcome, what is the expected number of points Strategist Alpha will gain per round? Express your answer as a single closed-form analytic expression.", "solution": "Let Strategist Alpha choose Signal 1 with probability $p$ and Signal 2 with probability $1-p$, and let Strategist Beta choose Signal 1 with probability $q$ and Signal 2 with probability $1-q$. The payoff to Alpha (in a zero-sum sense) for each pure action profile is:\n- $(1,1)$ yields sum $2$ (even), so Alpha gets $-2$.\n- $(1,2)$ or $(2,1)$ yields sum $3$ (odd), so Alpha gets $+3$.\n- $(2,2)$ yields sum $4$ (even), so Alpha gets $-4$.\n\nThus the payoff matrix to Alpha is\n$$\n\\begin{pmatrix}\n-2  3 \\\\\n3  -4\n\\end{pmatrix}.\n$$\nIn a zero-sum game, by the minimax principle, in mixed-strategy equilibrium each player mixes to make the opponent indifferent between their pure actions. For Beta to be indifferent between choosing Signal 1 and Signal 2, the expected payoff to Alpha against Beta's Signal 1 must equal that against Beta's Signal 2, given Alpha's mixing probability $p$.\n\nThe expected payoff to Alpha if Beta chooses Signal 1 is\n$$\nE_{1} = (-2)p + 3(1-p) = 3 - 5p.\n$$\nThe expected payoff to Alpha if Beta chooses Signal 2 is\n$$\nE_{2} = 3p - 4(1-p) = 7p - 4.\n$$\nIndifference requires\n$$\n3 - 5p = 7p - 4,\n$$\nwhich implies\n$$\n7 = 12p \\quad \\Rightarrow \\quad p = \\frac{7}{12}.\n$$\nThe value of the game to Alpha is then $v = E_{1} = E_{2}$ at this $p$:\n$$\nv = 3 - 5\\left(\\frac{7}{12}\\right) = \\frac{36}{12} - \\frac{35}{12} = \\frac{1}{12}.\n$$\nTherefore, the expected number of points Strategist Alpha will gain per round under optimal play is $\\frac{1}{12}$.", "answer": "$$\\boxed{\\frac{1}{12}}$$", "id": "1377571"}, {"introduction": "The assumption of rationality in game theory has profound consequences, especially when it is common knowledge that all players are rational. This thought-provoking problem [@problem_id:1377586], a variant of a famous multi-player guessing game, illustrates the power of iterated reasoning. You will learn how repeatedly eliminating strategies that are never a best response can unravel a complex game, leading to a single and logically inevitable outcome.", "problem": "In a modern investment firm, a \"consensus game\" is played by $n$ analysts to forecast a key market indicator. The game is structured as follows:\nEach of the $n$ analysts simultaneously and independently chooses an integer $x_i$ from the set $\\{0, 1, 2, \\dots, 100\\}$. An analyst's success (and their annual bonus) is determined by how close their chosen number is to a target value $T$. The analyst whose number is closest to $T$ wins the largest prize.\n\nCrucially, the target value $T$ is not an external, fixed quantity. Instead, it is determined by the analysts' choices themselves. It is defined as $T = p \\times \\bar{x}$, where $\\bar{x}$ is the arithmetic mean of all $n$ numbers chosen by the analysts, and $p$ is a known constant satisfying $0  p  1$.\n\nAssume that all analysts are perfectly rational, they want to maximize their chances of winning, and all of the above information is common knowledge among them. A rational analyst will not play a strategy (i.e., choose a number) if it is a \"never-best-response\". A strategy is a never-best-response if there are no possible choices by the other analysts for which this strategy would yield the best possible outcome.\n\nThis common knowledge of rationality allows for a process of iterated elimination of never-best-response strategies. Identify the unique integer that each analyst must choose if it is the sole surviving strategy after this iterative elimination process is complete.", "solution": "Let $n \\ge 2$ be fixed and let each analyst $i$ choose an integer $x_{i} \\in \\{0,1,2,\\dots,100\\}$. Let $\\bar{x}$ denote the arithmetic mean of all $n$ chosen numbers, and define the target\n$$\nT \\equiv p \\,\\bar{x}, \\quad \\text{with } 0  p  1.\n$$\nAn analyst’s payoff is maximized by choosing an integer as close as possible to $T$, so a best response is any integer minimizing $|x_{i} - T|$.\n\nKey bounding principle. If all analysts’ choices are known to lie in the interval $\\{0,1,\\dots,U\\}$ for some integer $U$, then the mean $\\bar{x}$ satisfies $0 \\le \\bar{x} \\le U$. Hence the endogenous target satisfies\n$$\n0 \\le T \\le p U.\n$$\nTherefore, no integer $x_{i}$ strictly greater than $p U$ can ever be closest to any feasible $T$, because every feasible $T$ lies in $[0,pU]$. Thus, conditional on the others being restricted to $\\{0,1,\\dots,U\\}$, every integer strictly larger than $pU$ is a never-best-response and is eliminated at that stage.\n\nIterated elimination from the initial full set. Initially $U_{0}=100$. After one elimination round, any integer strictly larger than $p U_{0} = 100 p$ is a never-best-response and is eliminated, so the surviving choices lie in $\\{0,1,\\dots,\\lfloor 100 p \\rfloor\\}$. Denote the maximal surviving integer after $t$ rounds by $U_{t}$. By the same logic applied iteratively,\n$$\nU_{t+1} \\le p\\,U_{t}, \\quad \\text{so inductively } \\quad U_{t} \\le p^{t}\\,100.\n$$\nSince $0p1$, there exists a finite integer $t^{\\ast}$ such that $p^{t^{\\ast}}\\,100  1$. Because choices are restricted to integers, it follows that for all $t \\ge t^{\\ast}$ the only possible surviving integer is $0$.\n\nSurvival of $0$. If all analysts choose $0$, then $\\bar{x}=0$ and $T=p\\cdot 0=0$. Choosing $x_{i}=0$ gives distance $|0-0|=0$, which is minimal among all integers. Hence $0$ is a best response to everyone else choosing $0$, so $0$ is never eliminated.\n\nConclusion. The iterated elimination of never-best-responses removes every positive integer in finitely many rounds (because $p^{t} 100 \\to 0$), while $0$ remains a best response and survives. Therefore, if a unique integer survives the process, it must be $0$.", "answer": "$$\\boxed{0}$$", "id": "1377586"}]}