{"hands_on_practices": [{"introduction": "A linear code is fundamentally defined by its generator matrix, $G$, which maps short message vectors to longer, redundant codewords. The error-correcting capability of a code is determined by its minimum weight, which for a linear code is the smallest number of non-zero elements in any non-zero codeword. This hands-on exercise [@problem_id:1367884] will guide you through the process of generating all codewords from a given matrix and finding this crucial value, building your intuition for how a code's structure relates to its strength.", "problem": "In digital communication, linear block codes are used to detect and correct errors. A linear code $C$ is a set of binary strings of a fixed length, called codewords. A common way to define such a code is with a generator matrix.\n\nConsider a system that encodes 2-bit message words into 4-bit codewords. The encoding is performed using a $2 \\times 4$ generator matrix $G$. A message word $u$, represented as a row vector of length 2, is encoded into a codeword $c$, a row vector of length 4, by the matrix multiplication $c = uG$. All arithmetic operations are performed modulo 2 (i.e., $1+1=0$).\n\nThe generator matrix for this system is given by:\n$$G = \\begin{pmatrix} 1  1  0  1 \\\\ 0  1  1  0 \\end{pmatrix}$$\n\nThe Hamming weight of a codeword, denoted $w(c)$, is the number of 1s in the codeword. The minimum weight of the code $C$ is the smallest Hamming weight among all non-zero codewords in $C$.\n\nDetermine the minimum weight of the code generated by the matrix $G$.", "solution": "A binary linear code generated by a matrix $G$ consists of all codewords $c$ of the form $c = uG$ where $u$ is a binary row vector. For the given generator matrix\n$$\nG=\\begin{pmatrix}\n1  1  0  1\\\\\n0  1  1  0\n\\end{pmatrix},\n$$\nlet the two rows be denoted by $g_{1}$ and $g_{2}$, respectively:\n$$\ng_{1}=(1,1,0,1), \\quad g_{2}=(0,1,1,0).\n$$\nSince all operations are modulo $2$, the set of codewords is\n$$\nC=\\{u_{1}g_{1}+u_{2}g_{2} \\mid u_{1},u_{2}\\in\\{0,1\\}\\}.\n$$\nWe enumerate all possible non-zero message vectors $u=(u_{1},u_{2})$ and compute the corresponding codewords:\n- For $u=(1,0)$:\n$$\nc=g_{1}=(1,1,0,1), \\quad w(c)=3.\n$$\n- For $u=(0,1)$:\n$$\nc=g_{2}=(0,1,1,0), \\quad w(c)=2.\n$$\n- For $u=(1,1)$:\n$$\nc=g_{1}+g_{2}=(1,1,0,1)+(0,1,1,0)=(1,0,1,1), \\quad w(c)=3.\n$$\nThe zero message $u=(0,0)$ yields the zero codeword, which is excluded from the minimum weight definition. Therefore, the minimum Hamming weight among all non-zero codewords is\n$$\n\\min\\{3,2,3\\}=2.\n$$\nHence, the minimum weight of the code generated by $G$ is $2$.", "answer": "$$\\boxed{2}$$", "id": "1367884"}, {"introduction": "While a generator matrix creates a code, a parity-check matrix, $H$, is used to validate it. When a word is received, we compute its 'syndrome' by multiplying it with $H$; a non-zero result signals that a transmission error has occurred. This practice problem [@problem_id:1367894] allows you to master the fundamental calculation of the syndrome, a critical first step in any error detection and correction scheme.", "problem": "In the theory of linear block codes over the binary field $\\mathbb{F}_2 = \\{0, 1\\}$, the syndrome of a received word $y$ is a vector $s$ used for error detection. It is calculated as the matrix-vector product $s = H y^T$, where $H$ is the code's parity-check matrix and $y^T$ is the transpose of the word $y$. All arithmetic operations are performed modulo 2, where $1+1=0$.\n\nConsider a specific linear code defined by the following parity-check matrix:\n$$\nH = \\begin{pmatrix}\n1  1  0  1  0 \\\\\n0  1  1  0  1 \\\\\n1  0  1  1  0\n\\end{pmatrix}\n$$\nSuppose a word $y = (1, 0, 1, 1, 0)$ is received. Calculate the corresponding syndrome $s$. Express your answer as a row matrix.", "solution": "We compute the syndrome $s$ over $\\mathbb{F}_{2}$ using $s=H y^{T}$, where arithmetic is modulo $2$. The given parity-check matrix is\n$$\nH=\\begin{pmatrix}\n1  1  0  1  0 \\\\\n0  1  1  0  1 \\\\\n1  0  1  1  0\n\\end{pmatrix},\n$$\nand the received word as a column vector is\n$$\ny^{T}=\\begin{pmatrix}1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0\\end{pmatrix}.\n$$\nCompute each component of $s$ as the dot product of the corresponding row of $H$ with $y^{T}$, all modulo $2$:\n- First component: $(1)(1)+(1)(0)+(0)(1)+(1)(1)+(0)(0)=1+0+0+1+0=2\\equiv 0 \\pmod{2}$.\n- Second component: $(0)(1)+(1)(0)+(1)(1)+(0)(1)+(1)(0)=0+0+1+0+0=1\\equiv 1 \\pmod{2}$.\n- Third component: $(1)(1)+(0)(0)+(1)(1)+(1)(1)+(0)(0)=1+0+1+1+0=3\\equiv 1 \\pmod{2}$.\n\nThus $s=\\begin{pmatrix}0 \\\\ 1 \\\\ 1\\end{pmatrix}$ as a column vector, which as a row matrix is $\\begin{pmatrix}0  1  1\\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}0  1  1\\end{pmatrix}}$$", "id": "1367894"}, {"introduction": "After calculating a syndrome, interpreting its meaning is paramount. While a non-zero syndrome clearly signals an error, what can we conclude with certainty when the syndrome is a zero vector? This conceptual exercise [@problem_id:1367883] pushes you to think critically about the implications of a 'clean' check, deepening your understanding of a code's structure and the fundamental limits of error detection.", "problem": "In a digital communication system, a linear block code is used to handle transmission errors. The code, denoted by $C$, is a subspace of the vector space $\\mathbb{F}_2^n$, where $\\mathbb{F}_2 = \\{0, 1\\}$ and all vector arithmetic is performed modulo 2. The code is defined by its parity-check matrix, $H$, which is an $(n-k) \\times n$ matrix with entries in $\\mathbb{F}_2$. A vector $v \\in \\mathbb{F}_2^n$ is a valid codeword (i.e., $v \\in C$) if and only if its product with the parity-check matrix results in the zero vector: $Hv^T = 0$.\n\nWhen a codeword $x \\in C$ is transmitted over a noisy channel, a possibly different vector $y \\in \\mathbb{F}_2^n$ is received. The difference between the received word and the transmitted codeword is the error vector, $e = y - x$. Note that in $\\mathbb{F}_2$, subtraction is the same as addition, so $e = y + x$.\n\nTo check for errors, the receiver calculates the *syndrome* of the received word $y$, which is defined as $S(y) = Hy^T$.\n\nAn engineer monitoring the system observes a particular received word, $y_{obs}$, and after computing its syndrome, finds that the result is the zero vector, i.e., $S(y_{obs}) = 0$.\n\nBased *only* on this observation, which of the following statements can the engineer conclude with absolute certainty? Select all that apply.\n\nA. The received word $y_{obs}$ is identical to the codeword that was originally transmitted.\n\nB. No errors occurred during the transmission of the codeword.\n\nC. The received word $y_{obs}$ is an element of the set of valid codewords $C$.\n\nD. The error vector $e$, corresponding to the difference between the received word $y_{obs}$ and the transmitted codeword, is itself a valid codeword in $C$.", "solution": "We are given a linear block code $C \\subseteq \\mathbb{F}_{2}^{n}$ defined by the parity-check matrix $H$ with $C=\\{v \\in \\mathbb{F}_{2}^{n} : Hv^{T}=0\\}$, and the syndrome of any $y \\in \\mathbb{F}_{2}^{n}$ is $S(y)=Hy^{T}$. A codeword $x \\in C$ is transmitted, and $y$ is received with error vector $e=y-x$, noting that over $\\mathbb{F}_{2}$ we have $e=y+x$.\n\nFrom the observation $S(y_{obs})=0$, we have $Hy_{obs}^{T}=0$. By the definition of $C$ as the null space of $H$, this implies $y_{obs} \\in C$. Therefore, statement C holds with certainty.\n\nTo analyze A and B, consider that $x \\in C$ satisfies $Hx^{T}=0$ by definition. If $e \\in C$ is any (possibly nonzero) codeword, then $y=x+e$ also satisfies\n$$\nHy^{T}=H(x+e)^{T}=Hx^{T}+He^{T}=0+0=0,\n$$\nso $S(y)=0$ can occur even when $e \\neq 0$ and $y \\neq x$. Hence, from $S(y_{obs})=0$ alone, one cannot conclude that $y_{obs}=x$ (statement A) or that no errors occurred (statement B). Both A and B are therefore not guaranteed.\n\nFor D, define $e=y_{obs}-x=y_{obs}+x$ in $\\mathbb{F}_{2}^{n}$. Using linearity of $H$ and that $Hx^{T}=0$ (since $x \\in C$) and $Hy_{obs}^{T}=0$ (by observation), we get\n$$\nHe^{T}=H(y_{obs}+x)^{T}=Hy_{obs}^{T}+Hx^{T}=0+0=0.\n$$\nThus $e \\in C$. Therefore, statement D holds with certainty.\n\nIn conclusion, the only statements that can be concluded with absolute certainty from $S(y_{obs})=0$ are C and D.", "answer": "$$\\boxed{CD}$$", "id": "1367883"}]}