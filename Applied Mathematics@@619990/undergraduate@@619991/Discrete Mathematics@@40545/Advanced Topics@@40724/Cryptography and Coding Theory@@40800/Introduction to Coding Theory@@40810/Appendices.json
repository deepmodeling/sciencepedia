{"hands_on_practices": [{"introduction": "Before we can correct errors, we must first understand how to describe them mathematically. This initial exercise introduces the fundamental concept of the error vector, a binary string that precisely indicates which bits were flipped during transmission. By applying the properties of the exclusive-OR (XOR) operation, you will practice calculating this vector by comparing the transmitted codeword with the received word, providing a clear and essential map of the channel-induced corruption [@problem_id:1377089].", "problem": "In digital communication systems, error detection is a fundamental task. Consider a simplified model for signals sent from a Mars rover to Earth. Data is encoded into binary strings called codewords. A codeword $c$ is transmitted, but due to atmospheric interference and signal degradation over the vast distance, some bits may be flipped. The binary string that arrives at Earth is called the received word, $r$.\n\nThe errors are represented by an error vector, $e$, which is a binary string of the same length as the codeword. A '1' in the $i$-th position of $e$ signifies that the $i$-th bit of the codeword was flipped during transmission, while a '0' signifies that it was not. The relationship between the transmitted codeword $c$, the received word $r$, and the error vector $e$ is given by the bitwise exclusive-OR (XOR, denoted by $\\oplus$) operation:\n$$r = c \\oplus e$$\nSuppose the rover transmits the 12-bit codeword $c = 110101100011$. After traveling to Earth, the mission control center receives the word $r = 111101000111$.\n\nWhich of the following represents the error vector $e$ that describes the transmission errors?\n\nA. `001000100100`\n\nB. `110101000011`\n\nC. `111101100111`\n\nD. `001000100110`\n\nE. `000000000000`", "solution": "The problem defines the relationship between the transmitted codeword ($c$), the received word ($r$), and the error vector ($e$) using the bitwise exclusive-OR (XOR, $\\oplus$) operation as:\n$$r = c \\oplus e$$\nOur goal is to find the error vector $e$. To isolate $e$, we can use a property of the XOR operation: for any binary string $x$, $x \\oplus x$ results in an all-zero string, and $x \\oplus 0 = x$.\n\nWe can apply the XOR operation with $c$ to both sides of the given equation:\n$$r \\oplus c = (c \\oplus e) \\oplus c$$\nBy the associative and commutative properties of XOR, we can reorder the terms on the right side:\n$$r \\oplus c = (c \\oplus c) \\oplus e$$\nSince $c \\oplus c$ is a string of all zeros, let's call it $\\mathbf{0}$:\n$$r \\oplus c = \\mathbf{0} \\oplus e$$\nThe XOR of any string with an all-zero string is the string itself:\n$$r \\oplus c = e$$\nSo, the error vector $e$ can be found by performing a bitwise XOR operation between the received word $r$ and the transmitted codeword $c$.\n\nThe given values are:\n$c = 110101100011$\n$r = 111101000111$\n\nNow, we compute $e = r \\oplus c$ bit by bit. The XOR operation yields 1 if the bits are different and 0 if they are the same.\n\n```\n  r:  1 1 1 1 0 1 0 0 0 1 1 1\n  c:  1 1 0 1 0 1 1 0 0 0 1 1\n---------------------------------\ne=râŠ•c:  0 0 1 0 0 0 1 0 0 1 0 0\n```\n\nLet's do the calculation explicitly for each position:\n- Position 1: $1 \\oplus 1 = 0$\n- Position 2: $1 \\oplus 1 = 0$\n- Position 3: $1 \\oplus 0 = 1$\n- Position 4: $1 \\oplus 1 = 0$\n- Position 5: $0 \\oplus 0 = 0$\n- Position 6: $1 \\oplus 1 = 0$\n- Position 7: $0 \\oplus 1 = 1$\n- Position 8: $0 \\oplus 0 = 0$\n- Position 9: $0 \\oplus 0 = 0$\n- Position 10: $1 \\oplus 0 = 1$\n- Position 11: $1 \\oplus 1 = 0$\n- Position 12: $1 \\oplus 1 = 0$\n\nCombining these bits, we get the error vector:\n$$e = 001000100100$$\nThis result indicates that bits at positions 3, 7, and 10 (counting from the left, starting at 1) were flipped during transmission.\n\nComparing this result with the given options:\nA. `001000100100`\nB. `110101000011`\nC. `111101100111`\nD. `001000100110`\nE. `000000000000`\n\nThe calculated error vector matches option A.", "answer": "$$\\boxed{A}$$", "id": "1377089"}, {"introduction": "Moving beyond simply identifying errors, our next challenge is to correct them and recover the original information. This practice demonstrates the power of syndrome decoding, a cornerstone of linear codes, where a received word is checked against a parity-check matrix $H$ to produce a 'syndrome' [@problem_id:1377111]. You will see how this syndrome, $s = Hr^T$, acts like a diagnostic signal, allowing you to pinpoint the exact location of a single-bit error and restore the original message, a process vital for reliable deep-space communication and data storage.", "problem": "In a deep-space communication system, a linear block code is used to transmit 4-bit messages as 7-bit codewords to protect against errors. All arithmetic operations in this context are performed modulo 2. The code is defined by its parity-check matrix $H$:\n$$ H = \\begin{pmatrix} 0  1  1  1  1  0  0 \\\\ 1  0  1  1  0  1  0 \\\\ 1  1  0  1  0  0  1 \\end{pmatrix} $$\nA 7-bit word $c = (c_1, c_2, c_3, c_4, c_5, c_6, c_7)$ is a valid codeword if and only if its transpose $c^T$ satisfies the equation $Hc^T = \\vec{0}$, where $\\vec{0}$ is the zero vector. The code is systematic, meaning any codeword is of the form $(m_1, m_2, m_3, m_4, p_1, p_2, p_3)$, where $(m_1, m_2, m_3, m_4)$ is the original 4-bit message and $(p_1, p_2, p_3)$ are the parity bits.\n\nA ground station receives the 7-bit word $r = (1, 0, 1, 0, 0, 0, 1)$. It is known from the system's design specifications that at most one bit can be flipped during a single transmission. Your task is to determine the original 4-bit message $(m_1, m_2, m_3, m_4)$ that was sent. Present your answer as a single row matrix containing the four message bits.", "solution": "We work over the finite field with two elements, so all additions and multiplications are modulo 2. Let the received vector be $r=(1,0,1,0,0,0,1)$. The syndrome is defined as\n$$\ns = Hr^{T} \\pmod{2}.\n$$\nCompute $s$ explicitly:\n$$\ns = \\begin{pmatrix}\n0  1  1  1  1  0  0 \\\\\n1  0  1  1  0  1  0 \\\\\n1  1  0  1  0  0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0\\cdot 1+1\\cdot 0+1\\cdot 1+1\\cdot 0+1\\cdot 0+0\\cdot 0+0\\cdot 1 \\\\\n1\\cdot 1+0\\cdot 0+1\\cdot 1+1\\cdot 0+0\\cdot 0+1\\cdot 0+0\\cdot 1 \\\\\n1\\cdot 1+1\\cdot 0+0\\cdot 1+1\\cdot 0+0\\cdot 0+0\\cdot 0+1\\cdot 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ 0\n\\end{pmatrix}\n\\pmod{2}.\n$$\nAssuming at most one bit error, write $r=c+e$ with $c$ a valid codeword and $e$ an error vector having Hamming weight at most $1$. Then\n$$\ns=Hr^{T}=Hc^{T}+He^{T}=0+He^{T}=He^{T}.\n$$\nIf the single error is in position $i$, then $e=e_{i}$ and $He^{T}$ equals the $i$-th column $h_{i}$ of $H$. Therefore the syndrome $s$ must equal one of the columns of $H$. The columns of $H$ are\n$$\nh_{1}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix},\\quad\nh_{2}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix},\\quad\nh_{3}=\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix},\\quad\nh_{4}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix},\\quad\nh_{5}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix},\\quad\nh_{6}=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix},\\quad\nh_{7}=\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}.\n$$\nSince $s=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}=h_{5}$, the error is in position $5$. Correcting gives\n$$\nc=r+e_{5}=(1,0,1,0,0,0,1)+(0,0,0,0,1,0,0)=(1,0,1,0,1,0,1)\\pmod{2}.\n$$\nBecause the code is systematic, the original message is the first four bits of $c$, namely $(1,0,1,0)$.", "answer": "$$\\boxed{\\begin{pmatrix}1  0  1  0\\end{pmatrix}}$$", "id": "1377111"}, {"introduction": "While syndrome decoding is powerful, it is not foolproof, and its effectiveness depends on the code's structure and the number of errors. This final practice explores the crucial concept of the decoding radius, $t = \\lfloor (d-1)/2 \\rfloor$, and the limits of unique error correction [@problem_id:1377090]. By analyzing a received word that lies equidistant from multiple valid codewords, you will discover firsthand why nearest-neighbor decoding fails when the number of errors exceeds the code's correction capability, higlighting the importance of minimum distance in code design.", "problem": "Consider a binary linear code $C$ of length $n=6$ defined over the field $F_2 = \\{0, 1\\}$. A binary word $v = (v_1, v_2, v_3, v_4, v_5, v_6)$ is a codeword in $C$ if and only if it satisfies the parity check equation $vH^T = 0$, where $H$ is the parity-check matrix given by:\n$$\nH = \\begin{pmatrix}\n1  0  1  1  0  0 \\\\\n1  1  0  0  1  0 \\\\\n0  1  1  0  0  1\n\\end{pmatrix}\n$$\nThe operation is matrix multiplication over $F_2$. The distance between two words is the Hamming distance, which is the number of positions in which they differ.\n\nThe unique decoding radius of a code with minimum distance $d$ is given by $t = \\lfloor (d-1)/2 \\rfloor$. This is the maximum number of errors that the code can uniquely correct using nearest-neighbor decoding. When a received word has a number of errors greater than $t$, unique decoding is not guaranteed.\n\nYou are given the received word $y = (1, 0, 0, 0, 0, 1)$.\n\nYour task is to analyze the decoding ambiguity for this word $y$.\nFirst, determine the minimum Hamming distance from $y$ to any codeword in $C$. Let this distance be $k = \\min_{c \\in C} d(y, c)$.\nSecond, determine the number of distinct codewords, $N$, that are at this minimum distance $k$ from $y$.\n\nYour final answer should be the pair of integers $(k, N)$ presented as a row matrix.", "solution": "The code is defined by $C=\\{c\\in F_{2}^{6}: cH^{T}=0\\}$. For a received word $y$, any candidate codeword $c$ corresponds to an error vector $e=y-c$ (over $F_{2}$, $e=y+c$). The syndrome is\n$$\ns=yH^{T}=(c+e)H^{T}=cH^{T}+eH^{T}=eH^{T},\n$$\nso the minimum Hamming distance from $y$ to $C$ equals the minimum weight of any $e$ satisfying $He^{T}=s$. Moreover, each such minimum-weight $e$ yields a distinct nearest codeword $c=y+e$.\n\nCompute the syndrome. With\n$$\nH=\\begin{pmatrix}\n1  0  1  1  0  0\\\\\n1  1  0  0  1  0\\\\\n0  1  1  0  0  1\n\\end{pmatrix},\\quad y=(1,0,0,0,0,1),\n$$\nwe get\n$$\ns=yH^{T}=\\begin{pmatrix}\n1\\cdot 1+0\\cdot 0+0\\cdot 1+0\\cdot 1+0\\cdot 0+1\\cdot 0\\\\\n1\\cdot 1+0\\cdot 1+0\\cdot 0+0\\cdot 0+0\\cdot 1+1\\cdot 0\\\\\n1\\cdot 0+0\\cdot 1+0\\cdot 1+0\\cdot 0+0\\cdot 0+1\\cdot 1\n\\end{pmatrix}\n=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}.\n$$\n\nLet $h_{i}$ denote column $i$ of $H$:\n$$\nh_{1}=\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix},\\;\nh_{2}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix},\\;\nh_{3}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix},\\;\nh_{4}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix},\\;\nh_{5}=\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix},\\;\nh_{6}=\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}.\n$$\nA weight-$1$ error has syndrome equal to some $h_{i}$. Since $s\\neq h_{i}$ for all $i$, there is no weight-$1$ solution.\n\nFor weight-$2$ errors at positions $\\{i,j\\}$, the syndrome is $h_{i}+h_{j}$. We seek pairs with $h_{i}+h_{j}=s$. Checking all pairs,\n$$\nh_{1}+h_{6}=\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix}+\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}=s,\n$$\n$$\nh_{2}+h_{4}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix}+\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}=s,\n$$\n$$\nh_{3}+h_{5}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix}+\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}=s,\n$$\nand no other pair sums to $s$. Therefore the minimum possible weight is $k=2$, and there are exactly $N=3$ distinct weight-$2$ error vectors $e$ with $He^{T}=s$. Each yields a distinct nearest codeword $c=y+e$, so there are $N=3$ nearest codewords at distance $k=2$.\n\nThus, $(k,N)=\\left(2,3\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} 2  3 \\end{pmatrix}}$$", "id": "1377090"}]}