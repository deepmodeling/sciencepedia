{"hands_on_practices": [{"introduction": "The journey of a message from its source to its destination often involves encoding, a crucial step to protect it against errors during transmission. This first practice provides a direct, hands-on experience with the fundamental operation of a linear code: transforming a message into a longer, redundant codeword using a generator matrix. By working through this example, you will solidify your understanding of how matrix multiplication over a finite field forms the basis of linear encoding. [@problem_id:1381321]", "problem": "A miniature deep-space probe is designed to send back sensor readings from a distant asteroid. To ensure data integrity over the noisy communication channel, the probe uses a simple linear block code. The code operates over the finite field $F_3 = \\{0, 1, 2\\}$, where all arithmetic is performed modulo 3.\n\nA two-symbol message from the sensor, represented as a row vector $m = (m_1, m_2)$, is encoded into a four-symbol codeword, represented as a row vector $c = (c_1, c_2, c_3, c_4)$. The encoding is performed via matrix multiplication $c = mG$, using the following $2 \\times 4$ generator matrix $G$:\n$$\nG = \\begin{pmatrix} 1 & 2 & 0 & 1 \\\\ 2 & 1 & 1 & 0 \\end{pmatrix}\n$$\nSuppose the probe needs to transmit the specific sensor message $m = (1, 2)$. Determine the 4-symbol codeword $c$ that is generated for transmission. Your answer should be the sequence of the four symbols of the codeword.", "solution": "We encode over the finite field $F_{3}$, so all arithmetic is performed modulo $3$. The codeword is computed by matrix multiplication $c = mG$.\n\nGiven $m = (1, 2)$ and\n$$\nG = \\begin{pmatrix} 1 & 2 & 0 & 1 \\\\ 2 & 1 & 1 & 0 \\end{pmatrix},\n$$\nthe components of $c = (c_{1}, c_{2}, c_{3}, c_{4})$ are\n$$\nc_{j} = m_{1}G_{1j} + m_{2}G_{2j} \\pmod{3}.\n$$\n\nCompute each component:\n$$\nc_{1} = 1\\cdot 1 + 2\\cdot 2 = 1 + 4 = 5 \\equiv 2 \\pmod{3},\n$$\n$$\nc_{2} = 1\\cdot 2 + 2\\cdot 1 = 2 + 2 = 4 \\equiv 1 \\pmod{3},\n$$\n$$\nc_{3} = 1\\cdot 0 + 2\\cdot 1 = 0 + 2 = 2 \\equiv 2 \\pmod{3},\n$$\n$$\nc_{4} = 1\\cdot 1 + 2\\cdot 0 = 1 + 0 = 1 \\equiv 1 \\pmod{3}.\n$$\n\nTherefore, the codeword is $(2, 1, 2, 1)$.", "answer": "$$\\boxed{\\begin{pmatrix} 2 & 1 & 2 & 1 \\end{pmatrix}}$$", "id": "1381321"}, {"introduction": "A linear code is more than just a collection of individual codewords; it's a structured vector space with distinct properties. A key characteristic is its weight distribution, which describes the frequency of codewords of each possible Hamming weight and offers insights into the code's error-handling capabilities. This exercise challenges you to generate the complete set of codewords from a basis and then systematically classify them by weight, providing a full picture of the code's structure. [@problem_id:1381329]", "problem": "A binary linear code $C$ is a subspace of the vector space $\\mathbb{Z}_2^n$, where $n$ is the length of the code. The elements of $C$, called codewords, are binary strings of length $n$.\n\nConsider a binary linear code $C$ of length $n=4$. This code is generated by the two basis vectors $g_1 = 1101$ and $g_2 = 0110$. This means that any codeword in $C$ can be expressed as a linear combination of these two vectors, of the form $c = a_1 g_1 + a_2 g_2$, where the coefficients $a_1$ and $a_2$ are elements of $\\mathbb{Z}_2$ (i.e., they can be 0 or 1). The addition of vectors is performed component-wise modulo 2. For example, $1100 + 1010 = 0110$.\n\nThe Hamming weight (or simply weight) of a codeword is defined as the number of '1's in its binary representation. The weight distribution of the code $C$ is a sequence of integers $(A_0, A_1, \\dots, A_n)$, where $A_i$ represents the number of codewords in $C$ that have a weight of $i$.\n\nDetermine the complete weight distribution $(A_0, A_1, A_2, A_3, A_4)$ for the code $C$.\n\nA. (1, 0, 1, 2, 0)\n\nB. (1, 0, 2, 1, 0)\n\nC. (1, 1, 1, 1, 0)\n\nD. (0, 1, 2, 1, 0)\n\nE. (1, 2, 1, 0, 0)", "solution": "We work over the field $\\mathbb{Z}_{2}$ with length $n=4$. The code $C$ is generated by $g_{1}=1101$ and $g_{2}=0110$, so every codeword has the form $c=a_{1}g_{1}+a_{2}g_{2}$ with $a_{1},a_{2}\\in\\{0,1\\}$, and addition is component-wise modulo $2$.\n\nList all codewords by choosing $(a_{1},a_{2})$:\n- For $(a_{1},a_{2})=(0,0)$: $c=0000$, whose Hamming weight is $0$.\n- For $(a_{1},a_{2})=(1,0)$: $c=g_{1}=1101$, whose Hamming weight is $3$.\n- For $(a_{1},a_{2})=(0,1)$: $c=g_{2}=0110$, whose Hamming weight is $2$.\n- For $(a_{1},a_{2})=(1,1)$: $c=g_{1}+g_{2}=1101+0110=1011$, whose Hamming weight is $3$.\n\nCount the occurrences of each weight $i\\in\\{0,1,2,3,4\\}$ to form $(A_{0},A_{1},A_{2},A_{3},A_{4})$:\n- Weight $0$: one codeword ($0000$), so $A_{0}=1$.\n- Weight $1$: none, so $A_{1}=0$.\n- Weight $2$: one codeword ($0110$), so $A_{2}=1$.\n- Weight $3$: two codewords ($1101$ and $1011$), so $A_{3}=2$.\n- Weight $4$: none, so $A_{4}=0$.\n\nThus the weight distribution is $(1,0,1,2,0)$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1381329"}, {"introduction": "The primary purpose of an error-correcting code is to enable the recovery of the original message even when the transmission is corrupted by noise. This final practice puts you in the role of a receiver, applying the principle of maximum likelihood decoding to determine the most probable message that was sent. You will compare a received, possibly erroneous, vector to all valid codewords to find the \"closest\" match and thereby correct the error, completing the full cycle from encoding to decoding. [@problem_id:1381305]", "problem": "A binary linear code $C$ of length $n=4$ and dimension $k=2$ is defined by the generator matrix\n$$\nG = \\begin{pmatrix} 1 & 1 & 0 & 1 \\\\ 0 & 1 & 1 & 1 \\end{pmatrix}.\n$$\nA message word, represented by a binary vector $u = (u_1, u_2)$, is encoded into a codeword $c$ using the rule $c = uG$, where all arithmetic is performed in the field $\\mathbb{F}_2$. A codeword is transmitted through a noisy channel, and the vector $y = (0, 1, 1, 0)$ is received.\n\nAssuming that the error pattern introduced by the channel has the smallest possible Hamming weight, determine the most likely transmitted codeword $c$ and the corresponding original message word $u$. Present your answer as a single sequence of 6 binary digits, representing the concatenation of the decoded codeword $c$ followed by the original message word $u$ (i.e., $c_1c_2c_3c_4u_1u_2$).", "solution": "The encoding rule over $\\mathbb{F}_{2}$ is $c = uG$, where $u = (u_{1},u_{2})$ and\n$$\nG=\\begin{pmatrix}1 & 1 & 0 & 1\\\\ 0 & 1 & 1 & 1\\end{pmatrix}.\n$$\nThus,\n$$\nc=u_{1}(1,1,0,1)+u_{2}(0,1,1,1)=(u_{1},\\,u_{1}+u_{2},\\,u_{2},\\,u_{1}+u_{2}),\n$$\nwith all additions in $\\mathbb{F}_{2}$. Enumerating all messages $u\\in\\mathbb{F}_{2}^{2}$ gives the corresponding codewords:\n$$\nu=(0,0)\\Rightarrow c=(0,0,0,0),\\quad\nu=(1,0)\\Rightarrow c=(1,1,0,1),\\quad\nu=(0,1)\\Rightarrow c=(0,1,1,1),\\quad\nu=(1,1)\\Rightarrow c=(1,0,1,0).\n$$\nThe received vector is $y=(0,1,1,0)$. Under the assumption of the smallest possible Hamming weight error pattern, we choose the codeword $c$ minimizing the Hamming distance to $y$, equivalently minimizing the Hamming weight of the error $e=y+c$ (addition in $\\mathbb{F}_{2}$). Compute the error vectors and their weights:\n$$\n\\begin{aligned}\nc=(0,0,0,0)&:\\ e=y+c=(0,1,1,0),\\ \\mathrm{wt}(e)=2,\\\\\nc=(1,1,0,1)&:\\ e=(1,0,1,1),\\ \\mathrm{wt}(e)=3,\\\\\nc=(0,1,1,1)&:\\ e=(0,0,0,1),\\ \\mathrm{wt}(e)=1,\\\\\nc=(1,0,1,0)&:\\ e=(1,1,0,0),\\ \\mathrm{wt}(e)=2.\n\\end{aligned}\n$$\nThe minimum weight is $1$, achieved uniquely by $c=(0,1,1,1)$, which corresponds to $u=(0,1)$. Therefore, the most likely transmitted codeword is $c=(0,1,1,1)$ and the original message word is $u=(0,1)$. The requested concatenation $c_{1}c_{2}c_{3}c_{4}u_{1}u_{2}$ is $011101$.", "answer": "$$\\boxed{011101}$$", "id": "1381305"}]}