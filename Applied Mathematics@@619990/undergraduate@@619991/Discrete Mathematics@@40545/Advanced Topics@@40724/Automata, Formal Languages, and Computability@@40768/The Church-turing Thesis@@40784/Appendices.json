{"hands_on_practices": [{"introduction": "Before the Turing Machine was proposed, mathematicians sought to formalize the intuitive concept of an \"algorithm.\" This exercise takes us back to that time, examining an early attempt—the class of primitive recursive functions. By understanding why the computable yet non-primitive recursive Ackermann function doesn't fit into this class, we can appreciate why a more powerful and general definition of computation was necessary, paving the way for the Church-Turing thesis. [@problem_id:1405456]", "problem": "In the historical development of the theory of computation, mathematicians sought a precise, formal definition for the intuitive notion of an \"effectively computable\" function—a function whose value can be determined by a finite, mechanical procedure. One of the early, promising candidates for this definition was the class of **primitive recursive functions**. This class is built up from a set of basic initial functions (the zero function, the successor function, and projection functions) using two operations: composition and a restricted form of recursion known as primitive recursion.\n\nHowever, in the 1920s, the Ackermann function (or a similar function) was discovered. It was clear that the Ackermann function was computable in the intuitive sense; for any given non-negative integer inputs, a well-defined, terminating algorithm exists to compute its output. Yet, it was rigorously proven that the Ackermann function is **not** a primitive recursive function.\n\nWhat is the most significant implication of the existence of a function like the Ackermann function, which is intuitively computable but not primitive recursive, for the search for a formal definition of computability?\n\nA. The existence of the Ackermann function proves that the Church-Turing thesis is incorrect.\n\nB. It implies that any function that grows faster than a polynomial is not truly computable.\n\nC. It demonstrates that the class of primitive recursive functions is an incomplete definition and is a proper subset of the class of all computable functions.\n\nD. It proves that the concept of an \"effectively computable\" function is inherently paradoxical and cannot be formalized mathematically.\n\nE. It shows that while the Ackermann function is computable in theory, no algorithm can compute its values in practice, even for small inputs.", "solution": "We formalize the relevant classes and implications step by step.\n\n1) By definition, the class of primitive recursive functions, denoted $\\mathrm{PR}$, is built from initial functions (zero, successor, projections) using composition and primitive recursion. Every function in $\\mathrm{PR}$ is total and effectively computable by a finite mechanical procedure. Hence,\n$$\n\\mathrm{PR} \\subseteq \\mathrm{Comp}_{\\mathrm{total}},\n$$\nwhere $\\mathrm{Comp}_{\\mathrm{total}}$ denotes the class of all total computable (effectively computable) functions.\n\n2) The Ackermann function $A$ is a total function for which there exists an effective, terminating algorithm to compute $A(n,m)$ for any given nonnegative integers $n,m$. Therefore $A \\in \\mathrm{Comp}_{\\mathrm{total}}$.\n\n3) It is rigorously proven that $A \\notin \\mathrm{PR}$ (for example, by showing that $A$ eventually dominates every function in the Grzegorczyk hierarchy levels that cover all primitive recursive functions, or by a majorization argument showing no primitive recursive bound can capture $A$’s growth). Thus there exists a computable function not in $\\mathrm{PR}$.\n\n4) From steps (1)–(3) we conclude\n$$\n\\mathrm{PR} \\subsetneq \\mathrm{Comp}_{\\mathrm{total}}.\n$$\nTherefore, the primitive recursive class is strictly too narrow to serve as a complete formalization of “effectively computable.”\n\n5) Evaluating the options:\n- A is false: The Ackermann function is computable by Turing machines and $\\mu$-recursive definitions; this does not contradict the Church-Turing thesis, which equates the informal notion to Turing-computable (and equivalent) formalisms, not to $\\mathrm{PR}$.\n- B is false: Computability is not determined by growth rate; many extremely fast-growing functions are still computable.\n- C is true: $\\mathrm{PR}$ is a proper subset of the computable functions, so it is an incomplete definition of computability.\n- D is false: The concept can be formalized (e.g., as Turing-computable or partial recursive), and these robust formalisms agree.\n- E is false: There is an algorithm to compute the Ackermann function; though it is impractical for large inputs, it is computable for small inputs in practice.\n\nTherefore, the most significant implication is that primitive recursion does not capture all effectively computable functions; a broader formalism is required.", "answer": "$$\\boxed{C}$$", "id": "1405456"}, {"introduction": "The Church-Turing thesis claims that the Turing Machine model is powerful enough to compute anything that any reasonable computational device can. To test this bold claim, we can imagine a more advanced machine and see if a standard TM can simulate it. This practice explores a \"Self-Modifying Turing Machine\" that can alter its own programming during execution, a seemingly superior capability, and challenges you to understand the principle that proves it is no more powerful than a standard TM. [@problem_id:1405429]", "problem": "An engineer at a futuristic computing company proposes a new theoretical model of computation called a Self-Modifying Turing Machine (SMTM). An SMTM is similar to a standard Turing Machine (TM) but has an additional capability: it can alter its own transition function during its execution.\n\nSpecifically, an SMTM $M_{SM}$ is defined by a set of states $Q$, an input alphabet $\\Sigma$, and a tape alphabet $\\Gamma$. Its single infinite tape is conceptually divided into two regions: a data region and a program region. The program region contains a complete encoding of the machine's own transition function, $\\delta$. A transition of an SMTM is determined by its current state and the symbol read from the data region, and has the form:\n$$ \\delta(q, \\gamma) = (q', \\gamma', D, A) $$\nwhere $q, q' \\in Q$ are the current and next states, $\\gamma, \\gamma' \\in \\Gamma$ are the symbols read from and written to the data region, $D \\in \\{L, R\\}$ is the head movement direction on the data region, and $A$ is a special \"modification action\". The action $A$ can be one of two types:\n1.  **$\\text{NO-OP}$**: No modification occurs to the program region. The transition function remains unchanged.\n2.  **$\\operatorname{MODIFY}((q_s, \\gamma_s), (q_t, \\gamma_t, D_t))$**: The machine finds the encoding of the rule for the state-symbol pair $(q_s, \\gamma_s)$ in its program region and overwrites it. The new rule becomes a transition to state $q_t$, writing symbol $\\gamma_t$, and moving the head in direction $D_t$. For simplicity, this newly defined transition is assumed to have a $\\text{NO-OP}$ modification action.\n\nThe Church-Turing thesis posits that any function computable by an algorithmic process can be computed by a standard TM. To test if the SMTM model challenges this thesis, one must determine if it can compute functions that a standard TM cannot. This is typically done by demonstrating how a standard, fixed-program TM, let's call it $M_{standard}$, could simulate the behavior of any given SMTM.\n\nAssume you are tasked with describing such a simulation. The machine $M_{standard}$ will use its own tape to keep track of the SMTM's entire configuration, which includes the SMTM's data region, its program region, and its current state.\n\nWhich of the following statements best describes the core principle that allows a standard TM with a fixed transition function to successfully simulate a self-modifying one?\n\nA. The standard TM halts and is manually reprogrammed by an operator each time the SMTM modifies its transition function, effectively creating a sequence of different TMs to mirror the SMTM's evolution.\n\nB. The standard TM uses a non-deterministic \"guess\" for each of the SMTM's future transition functions, and a computation is considered successful if at least one of the guessed computation paths matches the SMTM's actual evolution.\n\nC. The standard TM treats the SMTM's transition function as data stored on its own tape. When the SMTM performs a `MODIFY` action, the standard TM performs a standard data-writing operation to update this representation on its tape before simulating the next step.\n\nD. The simulation is only possible if the SMTM is restricted to a finite, predetermined number of self-modifications. An SMTM capable of an infinite number of modifications throughout its execution cannot be simulated by a standard TM.\n\nE. The simulation requires the standard TM to have a special \"meta-tape\" that is physically separate from its data tape and is inaccessible to normal read/write operations, used exclusively to store the SMTM's program.", "solution": "We formalize the simulation by a standard Turing machine, denoted $M_{standard}$, of a self-modifying Turing machine $M_{SM}$ with transition relation $\\delta$. The key observation is that a universal Turing machine interprets descriptions of machines as data; therefore, any change to the program of $M_{SM}$ can be mirrored by a corresponding change in the data that $M_{standard}$ maintains on its own tape.\n\nFirst, we define a complete configuration of $M_{SM}$ at step $t$ as $C_{t}=(q_{t},T^{data}_{t},T^{prog}_{t},h^{data}_{t})$ where $q_{t}\\in Q$ is the current state, $T^{data}_{t}$ encodes the data region contents, $T^{prog}_{t}$ encodes the current transition table of $M_{SM}$, and $h^{data}_{t}$ encodes the head position in the data region. The machine $M_{standard}$ maintains an explicit encoding of $C_{t}$ on its own tape at each simulated step $t$.\n\nTo simulate one transition, $M_{standard}$ performs the following deterministic interpretation procedure:\n1. It reads the symbol $\\gamma$ under the encoded data head and the current state $q_{t}$.\n2. It searches within the encoded $T^{prog}_{t}$ for the rule corresponding to $(q_{t},\\gamma)$, obtaining $(q',\\gamma',D,A)=\\delta(q_{t},\\gamma)$.\n3. It updates the encoded data region by writing $\\gamma'$ at the encoded head position, shifts the encoded head position according to $D$, and sets the encoded state to $q'$.\n\nCrucially, the handling of the modification action $A$ is achieved by ordinary data manipulation on the tape of $M_{standard}$:\n- If $A$ is $\\text{NO-OP}$, then $T^{prog}_{t+1}=T^{prog}_{t}$, and $M_{standard}$ proceeds to the next simulated step with the updated configuration encoding.\n- If $A$ is $\\operatorname{MODIFY}\\big((q_{s},\\gamma_{s}),(q_{targ},\\gamma_{targ},D_{targ})\\big)$, then $M_{standard}$ searches within its tape’s encoding of $T^{prog}_{t}$ for the rule with key $(q_{s},\\gamma_{s})$ and overwrites that encoded rule with the new right-hand side $(q_{targ},\\gamma_{targ},D_{targ})$, setting its action to $\\text{NO-OP}$ in the encoding by convention. This is a standard write operation on the data that encodes the program. The result is a new program encoding $T^{prog}_{t+1}$.\n\nBecause each modification is a localized rewrite of a finite portion of the tape, $M_{standard}$ can carry out any finite or countably infinite sequence of such modifications over time as part of its computation. No nondeterminism is required, no external intervention or reprogramming of $M_{standard}$ is necessary, and no special meta-tape beyond the ordinary work tape is needed. This is precisely the universal-machine principle: programs are data, and interpreting and updating them is within the capabilities of a standard Turing machine with a fixed transition function.\n\nHence, the core principle that enables the simulation is that $M_{standard}$ treats the SMTM’s transition function as data on its tape and updates that data whenever the SMTM performs a modification, before continuing the step-by-step simulation deterministically. Therefore, the correct choice is the statement that explicitly captures this principle.", "answer": "$$\\boxed{C}$$", "id": "1405429"}, {"introduction": "A profound consequence of formalizing computability is the realization that some well-defined functions are fundamentally uncomputable. This exercise introduces one of the most famous examples, the Busy Beaver function, $\\Sigma(n)$, which grows faster than any computable function. Working through the logic of a proof by contradiction will provide a concrete look at the absolute limits of what algorithms can ever achieve. [@problem_id:1405440]", "problem": "The Church-Turing thesis posits that any function that can be computed by an effective procedure can be computed by a Turing Machine. A key implication of this thesis is the existence of well-defined but uncomputable functions. One of the most famous examples is the Busy Beaver function, $\\Sigma(n)$, defined as the maximum number of '1's that a halting $n$-state, 2-symbol (one of which is blank) Turing Machine can write on an initially blank tape before it halts. The uncomputability of $\\Sigma(n)$ is demonstrable through a proof by contradiction.\n\nConsider the following hypothetical construction of a Turing Machine, which we will call $M_{paradox}$:\n\nFirst, assume the existence of a hypothetical Turing Machine, $M_{\\Sigma}$, that can compute the Busy Beaver function $\\Sigma(n)$. This machine, $M_{\\Sigma}$, takes an integer $n$ from the tape as input, and after it finishes its computation, it halts with the integer value $\\Sigma(n)$ written on the tape. Let the number of states in this machine $M_{\\Sigma}$ be a fixed constant, $c$.\n\nNow, we construct the machine $M_{paradox}$ by combining the functionality of $M_{\\Sigma}$ with other components. The machine $M_{paradox}$ is designed to operate on a value, $N$, that is hard-coded into its structure. The full sequence of operations for $M_{paradox}$ is as follows:\n1.  A sub-machine, $M_{write}$, writes the integer $N$ onto the tape. This component requires a fixed number of states, $c_{write}$.\n2.  The machine $M_{\\Sigma}$ (with its $c$ states) is then executed, using the value $N$ on the tape as its input to compute $\\Sigma(N)$.\n3.  A final sub-machine, $M_{increment}$, reads the value $\\Sigma(N)$ from the tape, and then proceeds to write a total of $\\Sigma(N) + 1$ ones onto a clear section of the tape before halting. This component requires a fixed number of states, $c_{inc}$.\n\nThe total number of states for the entire machine $M_{paradox}$ is the sum of the states of its constituent parts, so its state count is $N_{total} = c_{write} + c + c_{inc}$. To create the paradox, the hard-coded integer $N$ used in the operational steps is set to be equal to the total number of states of $M_{paradox}$ itself. That is, we set $N = N_{total}$. You are given that the overhead states from the non-oracle components sum to $c_{write} + c_{inc} = 38$.\n\nThis construction—a machine with $N_{total}$ states that is designed to write $\\Sigma(N_{total}) + 1$ ones—leads to a fundamental contradiction when compared with the very definition of the Busy Beaver function, thereby proving that the initial assumption (the existence of $M_{\\Sigma}$) must be false.\n\nWhich of the following mathematical statements correctly represents the contradiction derived from this hypothetical construction?\n\nA. $\\Sigma(c+38) + 1 = \\Sigma(c) + \\Sigma(38)$\n\nB. $\\Sigma(c+38) \\le \\Sigma(c) + 38$\n\nC. $c+38 \\le \\Sigma(c+38)$\n\nD. $\\Sigma(c+38) + 1 \\le \\Sigma(c+38)$\n\nE. $\\Sigma(c) + 1 \\le \\Sigma(c)$", "solution": "By definition of the Busy Beaver function, for every halting $n$-state, $2$-symbol Turing machine $M$ that starts on a blank tape and writes $t$ ones before halting, one has the fundamental bound\n$$\nt \\le \\Sigma(n).\n$$\nAssume there exists a Turing machine $M_{\\Sigma}$ with $c$ states that, given input $n$ on the tape, halts with $\\Sigma(n)$ written on the tape. Construct $M_{paradox}$ by composing:\n- a writer $M_{write}$ that writes a hard-coded integer $N$ on the tape using $c_{write}$ states,\n- the oracle $M_{\\Sigma}$ with $c$ states to compute $\\Sigma(N)$,\n- an incrementer $M_{increment}$ with $c_{inc}$ states that writes exactly $\\Sigma(N)+1$ ones on a clear section of tape and then halts.\n\nThe total number of states of $M_{paradox}$ is\n$$\nN_{total} = c_{write} + c + c_{inc}.\n$$\nWe are given $c_{write} + c_{inc} = 38$, hence\n$$\nN_{total} = c + 38.\n$$\nSet the hard-coded input to be $N = N_{total}$. Then $M_{paradox}$ is an $N$-state, $2$-symbol Turing machine that starts on a blank tape, halts, and writes exactly $\\Sigma(N) + 1$ ones. Applying the defining bound of the Busy Beaver function to this specific $N$-state halting machine yields\n$$\n\\Sigma(N) + 1 \\le \\Sigma(N),\n$$\nwhich is a contradiction. Substituting $N = c + 38$ gives the explicit contradictory inequality\n$$\n\\Sigma(c+38) + 1 \\le \\Sigma(c+38).\n$$\nAmong the given options, this is exactly statement D.", "answer": "$$\\boxed{D}$$", "id": "1405440"}]}