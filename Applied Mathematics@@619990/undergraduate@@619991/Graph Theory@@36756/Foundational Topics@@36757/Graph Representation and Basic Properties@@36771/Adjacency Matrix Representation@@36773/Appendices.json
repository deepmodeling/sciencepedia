{"hands_on_practices": [{"introduction": "The adjacency matrix is a powerful tool for representing a graph's structure in a way that computers can process. This first practice explores the most direct relationship between the matrix and the graph: how to identify a vertex's properties, such as being isolated, simply by inspecting the matrix's entries. Mastering this foundational skill is essential for translating between the visual language of graphs and the algebraic language of matrices. [@problem_id:1479331]", "problem": "In network analysis, a graph is a common way to represent connections between entities. Consider a computer network with $n$ nodes, which can be modeled as a simple, undirected graph $G = (V, E)$, where $V$ is the set of $n$ nodes (vertices) and $E$ is the set of connections (edges). A graph is \"simple\" meaning it has no self-loops (a node is not connected to itself) and no multiple edges between the same two nodes.\n\nThe connectivity of this network is represented by an $n \\times n$ adjacency matrix $A$, where the entry $A_{ij}$ is defined as:\n- $A_{ij} = 1$ if there is a direct connection (an edge) between node $i$ and node $j$.\n- $A_{ij} = 0$ if there is no direct connection between node $i$ and node $j$.\n\nA node is considered \"isolated\" if it has no connections to any other node in the network. Which of the following conditions on the adjacency matrix $A$ uniquely identifies that a node $k$ (where $1 \\leq k \\leq n$) is an isolated node?\n\nA. The $k$-th row and the $k$-th column consist entirely of zeros.\n\nB. The $k$-th row consists entirely of zeros, but the $k$-th column may contain non-zero entries.\n\nC. The diagonal entry $A_{kk}$ is 1, and all other entries in the $k$-th row and $k$-th column are 0.\n\nD. The sum of the entries in the $k$-th row is equal to 1.\n\nE. The $k$-th row is identical to the $k$-th column.", "solution": "Let $G=(V,E)$ be a simple, undirected graph with adjacency matrix $A\\in\\{0,1\\}^{n\\times n}$. For such a graph, by definition of undirectedness and simplicity, the adjacency matrix satisfies\n$$\nA_{ij}=A_{ji}\\quad\\text{for all }i,j,\\quad\\text{and}\\quad A_{ii}=0\\quad\\text{for all }i.\n$$\nThe degree of node $k$ is\n$$\nd_{k}=\\sum_{j=1}^{n}A_{kj}=\\sum_{j=1}^{n}A_{jk},\n$$\nand node $k$ is isolated if and only if $d_{k}=0$. This is equivalent to\n$$\nA_{kj}=0\\ \\text{for all }j\\quad\\text{and}\\quad A_{jk}=0\\ \\text{for all }j,\n$$\ni.e., the $k$-th row and the $k$-th column are entirely zeros.\n\nEvaluate each option:\n\nA. \"The $k$-th row and the $k$-th column consist entirely of zeros.\" This states $A_{kj}=0$ and $A_{jk}=0$ for all $j$, which is exactly equivalent to $d_{k}=0$. This condition is both necessary and sufficient for isolation.\n\nB. \"The $k$-th row consists entirely of zeros, but the $k$-th column may contain non-zero entries.\" If some $A_{jk}=1$ then symmetry forces $A_{kj}=A_{jk}=1$, contradicting that the $k$-th row is all zeros. Hence this cannot occur in a valid simple undirected graph and does not characterize isolation.\n\nC. \"The diagonal entry $A_{kk}$ is 1, and all other entries in the $k$-th row and $k$-th column are 0.\" This violates $A_{kk}=0$ required by simplicity (no self-loops). Thus it cannot identify an isolated node.\n\nD. \"The sum of the entries in the $k$-th row is equal to 1.\" This says $d_{k}=\\sum_{j=1}^{n}A_{kj}=1$, which indicates degree one, not isolation (which requires $d_{k}=0$).\n\nE. \"The $k$-th row is identical to the $k$-th column.\" This holds for all $k$ in any undirected graph due to $A_{ij}=A_{ji}$, so it provides no information about isolation.\n\nTherefore, the correct and uniquely identifying condition is option A.", "answer": "$$\\boxed{A}$$", "id": "1479331"}, {"introduction": "Beyond encoding direct connections, the adjacency matrix unlocks deeper insights through algebraic operations. This exercise reveals a fascinating connection between matrix powers and a graph's fundamental structure, specifically its bipartiteness. You will explore how properties of walks in a graph manifest in the entries of $A^k$, demonstrating how algebra can test for properties that are not immediately obvious from the graph's drawing. [@problem_id:1479330]", "problem": "Let $G = (V, E)$ be a simple, undirected graph with a set of vertices $V$ and a set of edges $E$. The graph $G$ is defined as **bipartite** if its vertex set $V$ can be partitioned into two disjoint and independent sets, $U$ and $W$, such that every edge in $E$ connects a vertex in $U$ to one in $W$.\n\nThe **adjacency matrix** $A$ of the graph $G$ with $n = |V|$ vertices is an $n \\times n$ matrix where the entry $A_{ij}$ is 1 if there is an edge connecting vertex $v_i$ and vertex $v_j$, and 0 otherwise.\n\nConsider any arbitrary bipartite graph $G$. Let $A$ be its adjacency matrix. Let $A^k$ denote the matrix $A$ raised to the power of $k$, where $k$ is any positive odd integer (e.g., $k=1, 3, 5, \\dots$). What value must all diagonal entries of the matrix $A^k$ always have, regardless of the specific structure of the bipartite graph?\n\nA. 0\n\nB. 1\n\nC. The degree of the corresponding vertex.\n\nD. The value depends on the specific choice of the odd integer $k$.\n\nE. The value depends on the number of non-zero entries in the matrix $A$.", "solution": "A fundamental theorem in graph theory states that the entry in the $i$-th row and $j$-th column of the matrix $A^k$, denoted as $(A^k)_{ij}$, is equal to the number of distinct walks of length $k$ from vertex $v_i$ to vertex $v_j$.\n\nThe problem asks for the value of the diagonal entries of $A^k$, which are the entries $(A^k)_{ii}$. According to the theorem, $(A^k)_{ii}$ represents the number of closed walks of length $k$ that start at vertex $v_i$ and end at the same vertex $v_i$.\n\nThe graph in question is bipartite. By definition, its vertex set $V$ is partitioned into two disjoint sets, $U$ and $W$, such that every edge connects a vertex in $U$ to a vertex in $W$. There are no edges connecting two vertices within the same set (i.e., no edges within $U$ and no edges within $W$).\n\nLet's analyze the nature of a walk in a bipartite graph. Consider a walk starting from an arbitrary vertex $v_i$. Without loss of generality, let's assume $v_i$ is in partition $U$.\n- A walk of length 1 (one step) must move from $v_i \\in U$ to a neighboring vertex, which, by the definition of a bipartite graph, must be in partition $W$. So, after one step, the walk is at a vertex in $W$.\n- A walk of length 2 (two steps) must move from the current vertex in $W$ to one of its neighbors. All neighbors of a vertex in $W$ must be in partition $U$. So, after two steps, the walk is at a vertex in $U$.\n- A walk of length 3 (three steps) must move from the current vertex in $U$ to a neighbor in $W$.\n\nWe can observe a pattern. If a walk starts in a vertex of partition $U$, its position after $m$ steps will be in partition $W$ if $m$ is odd, and in partition $U$ if $m$ is even. The same logic applies if the walk starts from a vertex in partition $W$: after an odd number of steps it will be in $U$, and after an even number of steps it will be back in $W$.\n\nA closed walk is a walk that starts and ends at the same vertex. For a walk starting at $v_i$ to be closed, it must end in the same partition where it began. Based on our observation, this can only happen if the length of the walk is an even number.\n\nThe problem specifies that we are looking at the matrix $A^k$, where $k$ is any positive odd integer. This corresponds to finding the number of closed walks of odd length $k$. Since any closed walk in a bipartite graph must have an even length, it is impossible to have a closed walk of an odd length.\n\nTherefore, the number of closed walks of any odd length $k$ from any vertex $v_i$ to itself is always zero. This means that for any odd integer $k$, all diagonal entries $(A^k)_{ii}$ must be 0 for all $i$. This holds true for any bipartite graph.", "answer": "$$\\boxed{A}$$", "id": "1479330"}, {"introduction": "Adjacency matrices are more than just static descriptions; they are dynamic data structures at the heart of many graph algorithms. This final practice challenges you to think algorithmically by determining the correct sequence of matrix operations that corresponds to contracting an edge. This process is fundamental to graph coarsening and simplification algorithms used to analyze massive networks in fields like network science and computer graphics. [@problem_id:1479332]", "problem": "In the field of network science, a common technique for simplifying large, complex networks is graph coarsening, where groups of vertices are merged into single \"super-vertices\". One of the fundamental operations used in this process is edge contraction.\n\nConsider a simple, undirected graph $G$ with $n$ vertices, labeled $V = \\{v_1, v_2, \\dots, v_n\\}$. A graph is \"simple\" if it has no self-loops (edges from a vertex to itself) and no more than one edge between any pair of vertices. The structure of this graph is represented by its $n \\times n$ adjacency matrix $A$, where $A_{kl} = 1$ if an edge exists between vertex $v_k$ and vertex $v_l$, and $A_{kl} = 0$ otherwise.\n\nThe operation of contracting an edge $(v_i, v_j)$ merges the two vertices $v_i$ and $v_j$ into a new super-vertex, which we will call $v_{new}$. The resulting graph, $G'$, contains $n-1$ vertices. The vertex set of $G'$ is $V' = (V \\setminus \\{v_i, v_j\\}) \\cup \\{v_{new}\\}$. The edge set of $G'$ is defined such that $G'$ is also a simple graph:\n1. For any two vertices $v_k, v_l$ that were not involved in the contraction (i.e., $k,l \\notin \\{i,j\\}$), an edge $(v_k, v_l)$ exists in $G'$ if and only if it existed in $G$.\n2. For any other vertex $v_k$ (with $k \\notin \\{i,j\\}$), an edge $(v_{new}, v_k)$ exists in $G'$ if and only if an edge $(v_i, v_k)$ existed in $G$ OR an edge $(v_j, v_k)$ existed in $G$.\n\nTo update the adjacency matrix, we will let the new super-vertex $v_{new}$ inherit the index $i$, and we will remove the row and column corresponding to index $j$. Your task is to identify the correct sequence of operations on the matrix $A$ that produces the $(n-1) \\times (n-1)$ adjacency matrix $A'$ for the new graph $G'$.\n\nLet $R_k$ and $C_k$ denote the $k$-th row and $k$-th column of matrix $A$, respectively. The symbol $\\lor$ denotes the element-wise logical OR operation (e.g., $[1, 0, 1] \\lor [0, 0, 1] = [1, 0, 1]$), and $+$ denotes element-wise addition.\n\nWhich of the following sequences of operations correctly transforms matrix $A$ into matrix $A'$?\n\nA.\n1. Update row $i$: $R_i \\leftarrow R_i \\lor R_j$.\n2. Update column $i$: $C_i \\leftarrow C_i \\lor C_j$.\n3. Enforce no self-loops: $A_{ii} \\leftarrow 0$.\n4. Remove vertex $j$: Delete $R_j$ and $C_j$.\n\nB.\n1. Update row $i$: $R_i \\leftarrow R_i + R_j$.\n2. Update column $i$: $C_i \\leftarrow C_i + C_j$.\n3. Enforce no self-loops: $A_{ii} \\leftarrow 0$.\n4. Remove vertex $j$: Delete $R_j$ and $C_j$.\n\nC.\n1. Update row $i$: $R_i \\leftarrow R_i \\lor R_j$.\n2. Update column $i$: $C_i \\leftarrow C_i \\lor C_j$.\n3. Remove vertex $j$: Delete $R_j$ and $C_j$.\n\nD.\n1. Remove vertex $j$: Delete $R_j$ and $C_j$.\n2. Update row $i$: $R_i \\leftarrow R_i \\lor R_j$.\n3. Update column $i$: $C_i \\leftarrow C_i \\lor C_j$.\n4. Enforce no self-loops: $A_{ii} \\leftarrow 0$.\n\nE.\n1. Update row $i$: For each $k$, set $A_{ik} \\leftarrow A_{ik} \\times A_{jk}$.\n2. Update column $i$: For each $k$, set $A_{ki} \\leftarrow A_{ki} \\times A_{kj}$.\n3. Enforce no self-loops: $A_{ii} \\leftarrow 0$.\n4. Remove vertex $j$: Delete $R_j$ and $C_j$.", "solution": "We need an operation on the adjacency matrix that implements the union of the neighborhoods of vertices $v_{i}$ and $v_{j}$ into the new super-vertex that inherits index $i$, preserves all other adjacencies unchanged, maintains a simple graph (binary entries, no self-loops), and then removes index $j$.\n\nBy definition of edge contraction as described, for any $k \\notin \\{i,j\\}$, the new adjacency to the super-vertex must satisfy\n$$\nA'_{ik} = A_{ik} \\lor A_{jk}, \\quad A'_{ki} = A_{ki} \\lor A_{kj},\n$$\nwhich is exactly realized by updating the $i$-th row and column via element-wise logical OR with those of $j$:\n$$\nR_{i} \\leftarrow R_{i} \\lor R_{j}, \\quad C_{i} \\leftarrow C_{i} \\lor C_{j}.\n$$\nAll entries $A'_{kl}$ with $k,l \\notin \\{i,j\\}$ must remain unchanged, which these operations do not alter.\n\nBecause we are contracting the edge $(v_{i},v_{j})$, we have $A_{ij} = A_{ji} = 1$. After the row update, the diagonal entry becomes\n$$\nA^{\\text{temp}}_{ii} = A_{ii} \\lor A_{ji} = 0 \\lor 1 = 1,\n$$\ncreating a self-loop. A simple graph forbids self-loops, so we must enforce\n$$\nA_{ii} \\leftarrow 0.\n$$\nFinally, to form the $(n-1) \\times (n-1)$ matrix of the contracted graph, we delete the $j$-th row and column.\n\nEvaluating the options:\n- A performs $R_{i} \\leftarrow R_{i} \\lor R_{j}$ and $C_{i} \\leftarrow C_{i} \\lor C_{j}$ (correct union), explicitly resets $A_{ii} \\leftarrow 0$ (removes the self-loop induced by contraction), and then deletes $R_{j},C_{j}$ (producing the correct reduced matrix). This matches the required transformation.\n- B uses addition instead of logical OR, which yields entries equal to $2$ when both $A_{ik}$ and $A_{jk}$ are $1$, violating the binary nature of a simple graph even after zeroing $A_{ii}$.\n- C omits resetting $A_{ii}$, leaving a self-loop since $A_{ii}$ becomes $1$ when contracting an existing edge.\n- D deletes $R_{j},C_{j}$ before attempting to OR with them, which is undefined and loses necessary information.\n- E uses element-wise multiplication (logical AND), which computes the intersection of neighborhoods rather than the required union.\n\nTherefore, the correct sequence is A.", "answer": "$$\\boxed{A}$$", "id": "1479332"}]}