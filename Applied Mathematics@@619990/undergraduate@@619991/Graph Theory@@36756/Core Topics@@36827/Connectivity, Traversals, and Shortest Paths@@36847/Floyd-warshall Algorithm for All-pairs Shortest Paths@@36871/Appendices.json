{"hands_on_practices": [{"introduction": "The foundation of mastering any algorithm is to understand its core iterative process. This first exercise provides a direct, hands-on opportunity to trace the Floyd-Warshall algorithm's update rule, $D^{(k)}_{ij} = \\min(D^{(k-1)}_{ij}, D^{(k-1)}_{ik} + D^{(k-1)}_{kj})$, on a small, weighted graph. By manually calculating the distance matrix for the first two iterations, you will build a concrete understanding of how the algorithm systematically considers intermediate vertices to find shorter paths. [@problem_id:1504965]", "problem": "Consider a weighted directed graph with 4 vertices, labeled 1, 2, 3, and 4. The costs of the direct paths between any two vertices are given by an initial distance matrix $D^{(0)}$. In this matrix, the element $D^{(0)}_{ij}$ represents the weight of the directed edge from vertex $i$ to vertex $j$. If no direct edge exists from $i$ to $j$, the weight is considered infinite ($\\infty$). The self-distance $D^{(0)}_{ii}$ is 0 for all vertices.\n\nThe initial distance matrix $D^{(0)}$ is given as:\n$$ D^{(0)} = \\begin{pmatrix} 0 & 4 & \\infty & 7 \\\\ \\infty & 0 & 1 & \\infty \\\\ 6 & \\infty & 0 & 2 \\\\ 3 & -2 & \\infty & 0 \\end{pmatrix} $$\n\nThe Floyd-Warshall algorithm computes the all-pairs shortest paths by iteratively updating this matrix. In the $k$-th iteration (for $k=1, 2, \\dots, 4$), the algorithm considers paths that use vertex $k$ as an intermediate vertex to potentially find a shorter path between any two vertices $i$ and $j$.\n\nStarting with the given matrix $D^{(0)}$, perform the first two iterations of the Floyd-Warshall algorithm to compute the matrices $D^{(1)}$ (using $k=1$) and $D^{(2)}$ (using $k=2$). Your task is to determine the final state of the distance matrix after the second iteration, $D^{(2)}$.", "solution": "We use the Floyd-Warshall update rule: for each iteration $k$ and for all $i,j$,\n$$\nD^{(k)}_{ij}=\\min\\left(D^{(k-1)}_{ij},\\,D^{(k-1)}_{ik}+D^{(k-1)}_{kj}\\right).\n$$\nGiven\n$$\nD^{(0)}=\\begin{pmatrix}\n0 & 4 & \\infty & 7\\\\\n\\infty & 0 & 1 & \\infty\\\\\n6 & \\infty & 0 & 2\\\\\n3 & -2 & \\infty & 0\n\\end{pmatrix},\n$$\nwe perform the first iteration with $k=1$, using $D^{(1)}_{ij}=\\min\\left(D^{(0)}_{ij},\\,D^{(0)}_{i1}+D^{(0)}_{1j}\\right)$.\n\nFor $i=1$:\n- $j=1$: $\\min(0,\\,0+0)=0$.\n- $j=2$: $\\min(4,\\,0+4)=4$.\n- $j=3$: $\\min(\\infty,\\,0+\\infty)=\\infty$.\n- $j=4$: $\\min(7,\\,0+7)=7$.\n\nFor $i=2$ (since $D^{(0)}_{21}=\\infty$, all via $1$ are $\\infty$):\n- $j=1$: $\\min(\\infty,\\,\\infty)=\\infty$.\n- $j=2$: $\\min(0,\\,\\infty)=0$.\n- $j=3$: $\\min(1,\\,\\infty)=1$.\n- $j=4$: $\\min(\\infty,\\,\\infty)=\\infty$.\n\nFor $i=3$ (with $D^{(0)}_{31}=6$):\n- $j=1$: $\\min(6,\\,6+0)=6$.\n- $j=2$: $\\min(\\infty,\\,6+4)=10$.\n- $j=3$: $\\min(0,\\,6+\\infty)=0$.\n- $j=4$: $\\min(2,\\,6+7)=2$.\n\nFor $i=4$ (with $D^{(0)}_{41}=3$):\n- $j=1$: $\\min(3,\\,3+0)=3$.\n- $j=2$: $\\min(-2,\\,3+4)=-2$.\n- $j=3$: $\\min(\\infty,\\,3+\\infty)=\\infty$.\n- $j=4$: $\\min(0,\\,3+7)=0$.\n\nThus\n$$\nD^{(1)}=\\begin{pmatrix}\n0 & 4 & \\infty & 7\\\\\n\\infty & 0 & 1 & \\infty\\\\\n6 & 10 & 0 & 2\\\\\n3 & -2 & \\infty & 0\n\\end{pmatrix}.\n$$\n\nNext, perform the second iteration with $k=2$, using $D^{(2)}_{ij}=\\min\\left(D^{(1)}_{ij},\\,D^{(1)}_{i2}+D^{(1)}_{2j}\\right)$.\n\nFor $i=1$ (with $D^{(1)}_{12}=4$):\n- $j=1$: $\\min(0,\\,4+\\infty)=0$.\n- $j=2$: $\\min(4,\\,4+0)=4$.\n- $j=3$: $\\min(\\infty,\\,4+1)=5$.\n- $j=4$: $\\min(7,\\,4+\\infty)=7$.\n\nFor $i=2$ (with $D^{(1)}_{22}=0$):\n- $j=1$: $\\min(\\infty,\\,0+\\infty)=\\infty$.\n- $j=2$: $\\min(0,\\,0+0)=0$.\n- $j=3$: $\\min(1,\\,0+1)=1$.\n- $j=4$: $\\min(\\infty,\\,0+\\infty)=\\infty$.\n\nFor $i=3$ (with $D^{(1)}_{32}=10$):\n- $j=1$: $\\min(6,\\,10+\\infty)=6$.\n- $j=2$: $\\min(10,\\,10+0)=10$.\n- $j=3$: $\\min(0,\\,10+1)=0$.\n- $j=4$: $\\min(2,\\,10+\\infty)=2$.\n\nFor $i=4$ (with $D^{(1)}_{42}=-2$):\n- $j=1$: $\\min(3,\\, -2+\\infty)=3$.\n- $j=2$: $\\min(-2,\\, -2+0)=-2$.\n- $j=3$: $\\min(\\infty,\\, -2+1)=-1$.\n- $j=4$: $\\min(0,\\, -2+\\infty)=0$.\n\nTherefore, the matrix after the second iteration is\n$$\nD^{(2)}=\\begin{pmatrix}\n0 & 4 & 5 & 7\\\\\n\\infty & 0 & 1 & \\infty\\\\\n6 & 10 & 0 & 2\\\\\n3 & -2 & -1 & 0\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0 & 4 & 5 & 7 \\\\ \\infty & 0 & 1 & \\infty \\\\ 6 & 10 & 0 & 2 \\\\ 3 & -2 & -1 & 0\\end{pmatrix}}$$", "id": "1504965"}, {"introduction": "The power of the Floyd-Warshall algorithm lies not just in finding paths, but also in correctly handling their absence. This problem presents a thought experiment concerning a vertex that is completely disconnected from the rest of the graph. By analyzing the final distance matrix for an isolated vertex, you will reinforce your understanding of how the algorithm uses the concept of infinity ($\\infty$) to represent non-existent paths and correctly interprets the graph's structure. [@problem_id:1504983]", "problem": "Consider a weighted, directed graph $G = (V, E)$ with a set of $n$ vertices $V = \\{v_1, v_2, \\dots, v_n\\}$ and edge weights that may be positive or negative, but with no negative-weight cycles. A vertex $v_i$ is defined as being **isolated** if there are no incoming edges to $v_i$ from any other vertex and no outgoing edges from $v_i$ to any other vertex in the graph.\n\nThe Floyd-Warshall algorithm is used to compute the all-pairs shortest paths. The algorithm initializes a distance matrix $D^{(0)}$ as follows:\n-   $D^{(0)}_{j,k} = 0$ for all $j = k$.\n-   $D^{(0)}_{j,k} = w(v_j, v_k)$ if a directed edge from $v_j$ to $v_k$ exists with weight $w(v_j, v_k)$.\n-   $D^{(0)}_{j,k} = \\infty$ if $j \\neq k$ and no direct edge exists from $v_j$ to $v_k$.\n\nThe algorithm then iteratively refines this matrix, producing a final distance matrix $D^{(n)}$ where $D^{(n)}_{j,k}$ is the length of the shortest path from vertex $v_j$ to vertex $v_k$.\n\nSuppose that a specific vertex $v_i$ in the graph is isolated. Which of the following statements accurately describes the $i$-th row and the $i$-th column of the final distance matrix $D^{(n)}$?\n\nA. The $i$-th row and the $i$-th column will both be filled with $\\infty$ for all entries, except for the diagonal element $D^{(n)}_{i,i}$, which will be 0.\n\nB. The $i$-th row and the $i$-th column will both be filled entirely with 0s.\n\nC. The $i$-th row and the $i$-th column will both be filled entirely with $\\infty$, including the diagonal element $D^{(n)}_{i,i}$.\n\nD. The $i$-th row will be filled with $\\infty$ (except for $D^{(n)}_{i,i} = 0$), but the $i$-th column could contain finite values if paths from other vertices can be routed through $v_i$.\n\nE. The contents of the $i$-th row and column depend on the specific processing order of the vertices in the main loop of the algorithm.", "solution": "Let $G=(V,E)$ be a weighted directed graph with no negative-weight cycles, and let $v_{i}$ be isolated, meaning there are no edges $(v_{i},v_{j})$ and no edges $(v_{j},v_{i})$ for all $j \\neq i$.\n\nThe Floyd-Warshall algorithm maintains matrices $D^{(r)}$ for $r=0,1,\\dots,n$, where $D^{(0)}$ is initialized by\n- $D^{(0)}_{j,k}=0$ if $j=k$,\n- $D^{(0)}_{j,k}=w(v_{j},v_{k})$ if $(v_{j},v_{k}) \\in E$,\n- $D^{(0)}_{j,k}=\\infty$ otherwise.\n\nThe update rule for $r=1,2,\\dots,n$ is\n$$\nD^{(r)}_{p,q}=\\min\\!\\big(D^{(r-1)}_{p,q},\\,D^{(r-1)}_{p,r}+D^{(r-1)}_{r,q}\\big).\n$$\n\nBecause $v_{i}$ is isolated, the initialization for the $i$-th row and column of $D^{(0)}$ is\n$$\nD^{(0)}_{i,i}=0,\\quad D^{(0)}_{i,j}=\\infty\\ \\text{for}\\ j\\neq i,\\quad D^{(0)}_{j,i}=\\infty\\ \\text{for}\\ j\\neq i.\n$$\n\nWe prove by induction on $r$ that, for all $r=0,1,\\dots,n$,\n$$\nD^{(r)}_{i,i}=0,\\qquad D^{(r)}_{i,j}=\\infty\\ \\text{for all}\\ j\\neq i,\\qquad D^{(r)}_{j,i}=\\infty\\ \\text{for all}\\ j\\neq i.\n$$\n\nBase case $r=0$ holds by initialization. Assume the statement holds for some $r-1\\geq 0$. Fix $j\\neq i$. Then\n$$\nD^{(r)}_{i,j}=\\min\\!\\big(D^{(r-1)}_{i,j},\\,D^{(r-1)}_{i,r}+D^{(r-1)}_{r,j}\\big).\n$$\nBy the induction hypothesis, $D^{(r-1)}_{i,j}=\\infty$. If $r\\neq i$, then $D^{(r-1)}_{i,r}=\\infty$, so $D^{(r-1)}_{i,r}+D^{(r-1)}_{r,j}=\\infty$. If $r=i$, then $D^{(r-1)}_{i,i}=0$ and $D^{(r-1)}_{i,j}=\\infty$, hence $D^{(r-1)}_{i,i}+D^{(r-1)}_{i,j}=\\infty$. In both cases, $D^{(r)}_{i,j}=\\min(\\infty,\\infty)=\\infty$.\n\nSimilarly,\n$$\nD^{(r)}_{j,i}=\\min\\!\\big(D^{(r-1)}_{j,i},\\,D^{(r-1)}_{j,r}+D^{(r-1)}_{r,i}\\big).\n$$\nBy the induction hypothesis, $D^{(r-1)}_{j,i}=\\infty$. If $r\\neq i$, then $D^{(r-1)}_{r,i}=\\infty$, so the sum is $\\infty$. If $r=i$, then $D^{(r-1)}_{i,i}=0$ and $D^{(r-1)}_{j,i}=\\infty$, so the sum is $\\infty$. Thus $D^{(r)}_{j,i}=\\infty$.\n\nFor the diagonal entry,\n$$\nD^{(r)}_{i,i}=\\min\\!\\big(D^{(r-1)}_{i,i},\\,D^{(r-1)}_{i,r}+D^{(r-1)}_{r,i}\\big).\n$$\nIf $r\\neq i$, then $D^{(r-1)}_{i,r}=\\infty$ or $D^{(r-1)}_{r,i}=\\infty$ by the induction hypothesis, so the sum is $\\infty$ and $D^{(r)}_{i,i}=\\min(D^{(r-1)}_{i,i},\\infty)=D^{(r-1)}_{i,i}$. If $r=i$, then $D^{(r-1)}_{i,i}=0$, so $D^{(r)}_{i,i}=\\min(0,0+0)=0$. Hence $D^{(r)}_{i,i}=0$ for all $r$.\n\nTherefore, in the final matrix $D^{(n)}$, the $i$-th row and $i$-th column have $\\infty$ in all off-diagonal positions and $0$ on the diagonal, which matches option A. No processing order dependence arises, and no finite value can appear via paths through $v_{i}$ because no such paths exist without incident edges.", "answer": "$$\\boxed{A}$$", "id": "1504983"}, {"introduction": "Do shortest paths remain the \"shortest\" if we uniformly change all edge weights? This final practice challenges our intuition by exploring the effect of adding a positive constant $c$ to every edge in a graph. This exercise moves beyond simple execution to a deeper analysis, revealing that the optimal path is not always invariant and that adding weight systemically favors paths with fewer edges. [@problem_id:1504949]", "problem": "Consider a weighted, directed graph $G = (V, E)$ with a weight function $w: E \\to \\mathbb{R}$ for its edges. The graph has no negative-weight cycles. The all-pairs shortest path distance matrix for this graph contains entries $d(u, v)$ for all pairs of vertices $(u, v) \\in V \\times V$, representing the minimum possible sum of edge weights along a path from $u$ to $v$.\n\nNow, let's construct a new graph $G'$ on the same set of vertices and edges, but with a new weight function $w'$. For a given positive constant $c > 0$, the new weight of every edge is defined as $w'(u, v) = w(u, v) + c$. Let $d'(u, v)$ be the shortest path distance from $u$ to $v$ in this new graph $G'$.\n\nFurthermore, let's define $d_k(u, v)$ as the weight of the shortest path from vertex $u$ to vertex $v$ in the original graph $G$ that contains *exactly* $k$ edges. If no path with exactly $k$ edges exists between $u$ and $v$, we consider $d_k(u, v)$ to be infinite.\n\nWhich of the following expressions correctly relates the new shortest path distance $d'(u, v)$ to the properties of the original graph $G$?\n\nA. $d'(u, v) = d(u, v) + c$\n\nB. $d'(u, v) = d(u, v) \\cdot (1 + c)$\n\nC. $d'(u, v) = d(u, v) + k_{uv} \\cdot c$, where $k_{uv}$ is the number of edges on a shortest path from $u$ to $v$ in the original graph $G$.\n\nD. The shortest paths in $G'$ are the same set of paths as in $G$, just with their total weights increased.\n\nE. $d'(u, v) = \\min_{k \\ge 1} \\{ d_k(u,v) + k \\cdot c \\}$", "solution": "Let $P$ be any directed path from $u$ to $v$ in $G$ using exactly $k$ edges $e_{1},\\dots,e_{k}$. Its total weight in $G$ is\n$$\nw(P)=\\sum_{i=1}^{k} w(e_{i}).\n$$\nIn $G'$ each edge weight is shifted by $c>0$, so the total weight of the same path $P$ in $G'$ is\n$$\nw'(P)=\\sum_{i=1}^{k} \\big(w(e_{i})+c\\big)=\\sum_{i=1}^{k} w(e_{i})+kc=w(P)+kc.\n$$\n\nBy definition, the shortest path distance in $G'$ is\n$$\nd'(u,v)=\\min_{P:u\\to v} w'(P)=\\min_{P:u\\to v} \\big(w(P)+k(P)\\,c\\big),\n$$\nwhere $k(P)$ denotes the number of edges on $P$. Grouping paths by their edge count $k$ and using the definition of $d_{k}(u,v)$ as the minimum weight among $k$-edge $u\\to v$ paths (with $d_{k}(u,v)=\\infty$ if none exists), we obtain\n$$\nd'(u,v)=\\min_{k\\ge 1}\\left(\\min_{P:u\\to v,\\ |P|=k} w(P)+k\\,c\\right)=\\min_{k\\ge 1}\\big(d_{k}(u,v)+k\\,c\\big).\n$$\nThis establishes option E.\n\nWe now assess the other options:\n\n- A: $d'(u,v)=d(u,v)+c$ would ignore the dependence on the number of edges; since each edge incurs an additional $c$, the increment depends on $k$, so A is false in general.\n\n- B: $d'(u,v)=d(u,v)\\cdot(1+c)$ is a multiplicative scaling, whereas the transformation is additive per edge; thus B is false.\n\n- C: $d'(u,v)=d(u,v)+k_{uv}\\,c$, where $k_{uv}$ is the edge count of a shortest $u\\to v$ path in $G$, can fail because after adding $c$ per edge a different path with a different number of edges may become optimal; thus C is false in general.\n\n- D: The set of shortest paths need not remain the same, because adding $c$ per edge favors paths with fewer edges; thus D is false in general.\n\nTherefore, only E correctly characterizes $d'(u,v)$.", "answer": "$$\\boxed{E}$$", "id": "1504949"}]}