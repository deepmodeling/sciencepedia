{"hands_on_practices": [{"introduction": "The spectral theorem guarantees that any real symmetric matrix can be diagonalized by an orthogonal matrix, a process that simplifies its structure to its fundamental componentsâ€”the eigenvalues. This exercise provides essential hands-on practice in the complete orthogonal diagonalization procedure for a simple $2 \\times 2$ matrix. Mastering this algorithm [@problem_id:1380447], from calculating eigenvalues and eigenvectors to constructing the final orthonormal transformation matrix, is the foundational skill for applying matrix diagonalization in science and engineering.", "problem": "In linear algebra, a real symmetric matrix $A$ can be factored as $A = PDP^T$, where $P$ is an orthogonal matrix whose columns are the orthonormal eigenvectors of $A$, and $D$ is a diagonal matrix containing the corresponding eigenvalues. This is known as the orthogonal diagonalization of $A$. An equivalent formulation is $P^T A P = D$.\n\nConsider the symmetric matrix $A$ given by:\n$$\nA = \\begin{pmatrix} 1 & 1 \\\\ 1 & 2 \\end{pmatrix}\n$$\nFind the unique orthogonal matrix $P$ that diagonalizes $A$, subject to two conditions:\n1. The diagonal entries of the resulting diagonal matrix $D = P^T A P$ must be in decreasing order.\n2. The first entry of each column vector of $P$ must be positive.\n\nPresent your answer as a single matrix.", "solution": "The problem asks for a specific orthogonal matrix $P$ that diagonalizes the matrix $A = \\begin{pmatrix} 1 & 1 \\\\ 1 & 2 \\end{pmatrix}$ such that $D = P^T A P$ is a diagonal matrix with its entries in decreasing order. The columns of $P$ must also have a positive first entry.\n\nThe procedure involves finding the eigenvalues and corresponding orthonormal eigenvectors of $A$.\n\n**Step 1: Find the eigenvalues of A.**\nThe eigenvalues $\\lambda$ are the roots of the characteristic equation $\\det(A - \\lambda I) = 0$.\n$$\n\\det\\left(\\begin{pmatrix} 1 & 1 \\\\ 1 & 2 \\end{pmatrix} - \\lambda \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\right) = 0\n$$\n$$\n\\det\\begin{pmatrix} 1-\\lambda & 1 \\\\ 1 & 2-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(1-\\lambda)(2-\\lambda) - (1)(1) = 0\n$$\n$$\n2 - 3\\lambda + \\lambda^2 - 1 = 0\n$$\n$$\n\\lambda^2 - 3\\lambda + 1 = 0\n$$\nUsing the quadratic formula, $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\n\\lambda = \\frac{3 \\pm \\sqrt{(-3)^2 - 4(1)(1)}}{2} = \\frac{3 \\pm \\sqrt{9 - 4}}{2} = \\frac{3 \\pm \\sqrt{5}}{2}\n$$\nThe problem requires the diagonal entries of $D$ to be in decreasing order. So, we order the eigenvalues as:\n$$\n\\lambda_1 = \\frac{3 + \\sqrt{5}}{2}\n$$\n$$\n\\lambda_2 = \\frac{3 - \\sqrt{5}}{2}\n$$\n\n**Step 2: Find the eigenvectors for each eigenvalue.**\nThe first column of $P$ will be the normalized eigenvector corresponding to $\\lambda_1$, and the second column will correspond to $\\lambda_2$.\n\nFor $\\lambda_1 = \\frac{3 + \\sqrt{5}}{2}$:\nWe solve the system $(A - \\lambda_1 I)\\mathbf{v} = \\mathbf{0}$ for the eigenvector $\\mathbf{v}_1 = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$.\n$$\n\\begin{pmatrix} 1 - \\frac{3 + \\sqrt{5}}{2} & 1 \\\\ 1 & 2 - \\frac{3 + \\sqrt{5}}{2} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} \\frac{-1 - \\sqrt{5}}{2} & 1 \\\\ 1 & \\frac{1 - \\sqrt{5}}{2} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nFrom the first row, we get the equation $\\frac{-1 - \\sqrt{5}}{2} x_1 + x_2 = 0$, which implies $x_2 = \\frac{1 + \\sqrt{5}}{2} x_1$.\nLet's choose $x_1 = 1$. Then $x_2 = \\frac{1 + \\sqrt{5}}{2}$. An eigenvector is $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ \\frac{1 + \\sqrt{5}}{2} \\end{pmatrix}$. The first entry is positive, as required.\n\nFor $\\lambda_2 = \\frac{3 - \\sqrt{5}}{2}$:\nWe solve $(A - \\lambda_2 I)\\mathbf{v} = \\mathbf{0}$ for $\\mathbf{v}_2 = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$.\n$$\n\\begin{pmatrix} 1 - \\frac{3 - \\sqrt{5}}{2} & 1 \\\\ 1 & 2 - \\frac{3 - \\sqrt{5}}{2} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\begin{pmatrix} \\frac{-1 + \\sqrt{5}}{2} & 1 \\\\ 1 & \\frac{1 + \\sqrt{5}}{2} \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}\n$$\nFrom the first row, we have $\\frac{-1 + \\sqrt{5}}{2} x_1 + x_2 = 0$, which implies $x_2 = \\frac{1 - \\sqrt{5}}{2} x_1$.\nChoosing $x_1 = 1$, we get $x_2 = \\frac{1 - \\sqrt{5}}{2}$. An eigenvector is $\\mathbf{v}_2 = \\begin{pmatrix} 1 \\\\ \\frac{1 - \\sqrt{5}}{2} \\end{pmatrix}$. The first entry is positive, as required.\n\n**Step 3: Normalize the eigenvectors.**\nTo form the orthogonal matrix $P$, we need to normalize $\\mathbf{v}_1$ and $\\mathbf{v}_2$ to unit vectors $\\mathbf{u}_1$ and $\\mathbf{u}_2$.\n\nFor $\\mathbf{v}_1$:\n$$\n||\\mathbf{v}_1||^2 = 1^2 + \\left(\\frac{1 + \\sqrt{5}}{2}\\right)^2 = 1 + \\frac{1 + 2\\sqrt{5} + 5}{4} = 1 + \\frac{6 + 2\\sqrt{5}}{4} = 1 + \\frac{3 + \\sqrt{5}}{2} = \\frac{5 + \\sqrt{5}}{2}\n$$\n$$\n||\\mathbf{v}_1|| = \\sqrt{\\frac{5 + \\sqrt{5}}{2}}\n$$\nSo, $\\mathbf{u}_1 = \\frac{\\mathbf{v}_1}{||\\mathbf{v}_1||} = \\frac{1}{\\sqrt{\\frac{5 + \\sqrt{5}}{2}}} \\begin{pmatrix} 1 \\\\ \\frac{1 + \\sqrt{5}}{2} \\end{pmatrix}$.\n\nFor $\\mathbf{v}_2$:\n$$\n||\\mathbf{v}_2||^2 = 1^2 + \\left(\\frac{1 - \\sqrt{5}}{2}\\right)^2 = 1 + \\frac{1 - 2\\sqrt{5} + 5}{4} = 1 + \\frac{6 - 2\\sqrt{5}}{4} = 1 + \\frac{3 - \\sqrt{5}}{2} = \\frac{5 - \\sqrt{5}}{2}\n$$\n$$\n||\\mathbf{v}_2|| = \\sqrt{\\frac{5 - \\sqrt{5}}{2}}\n$$\nSo, $\\mathbf{u}_2 = \\frac{\\mathbf{v}_2}{||\\mathbf{v}_2||} = \\frac{1}{\\sqrt{\\frac{5 - \\sqrt{5}}{2}}} \\begin{pmatrix} 1 \\\\ \\frac{1 - \\sqrt{5}}{2} \\end{pmatrix}$.\n\n**Step 4: Construct the matrix P.**\nThe matrix $P$ has $\\mathbf{u}_1$ and $\\mathbf{u}_2$ as its columns. Let's simplify the entries of the vectors.\n\nFor $\\mathbf{u}_1 = \\begin{pmatrix} p_{11} \\\\ p_{21} \\end{pmatrix}$:\n$$\np_{11} = \\frac{1}{\\sqrt{\\frac{5 + \\sqrt{5}}{2}}} = \\sqrt{\\frac{2}{5 + \\sqrt{5}}} = \\sqrt{\\frac{2(5 - \\sqrt{5})}{(5 + \\sqrt{5})(5 - \\sqrt{5})}} = \\sqrt{\\frac{10 - 2\\sqrt{5}}{20}} = \\sqrt{\\frac{5 - \\sqrt{5}}{10}}\n$$\n$$\np_{21} = \\frac{\\frac{1 + \\sqrt{5}}{2}}{\\sqrt{\\frac{5 + \\sqrt{5}}{2}}} = \\left(\\frac{1 + \\sqrt{5}}{2}\\right)\\sqrt{\\frac{2}{5 + \\sqrt{5}}} = \\sqrt{\\left(\\frac{1 + \\sqrt{5}}{2}\\right)^2 \\frac{2}{5 + \\sqrt{5}}} = \\sqrt{\\frac{6+2\\sqrt{5}}{4} \\frac{2}{5 + \\sqrt{5}}} = \\sqrt{\\frac{3+\\sqrt{5}}{2} \\frac{2}{5 + \\sqrt{5}}} = \\sqrt{\\frac{3+\\sqrt{5}}{5 + \\sqrt{5}}} = \\sqrt{\\frac{(3+\\sqrt{5})(5-\\sqrt{5})}{(5+\\sqrt{5})(5-\\sqrt{5})}} = \\sqrt{\\frac{10+2\\sqrt{5}}{20}} = \\sqrt{\\frac{5 + \\sqrt{5}}{10}}\n$$\nSo, $\\mathbf{u}_1 = \\begin{pmatrix} \\sqrt{\\frac{5 - \\sqrt{5}}{10}} \\\\ \\sqrt{\\frac{5 + \\sqrt{5}}{10}} \\end{pmatrix}$.\n\nFor $\\mathbf{u}_2 = \\begin{pmatrix} p_{12} \\\\ p_{22} \\end{pmatrix}$:\n$$\np_{12} = \\frac{1}{\\sqrt{\\frac{5 - \\sqrt{5}}{2}}} = \\sqrt{\\frac{2}{5 - \\sqrt{5}}} = \\sqrt{\\frac{2(5 + \\sqrt{5})}{(5 - \\sqrt{5})(5 + \\sqrt{5})}} = \\sqrt{\\frac{10 + 2\\sqrt{5}}{20}} = \\sqrt{\\frac{5 + \\sqrt{5}}{10}}\n$$\n$$\np_{22} = \\frac{\\frac{1 - \\sqrt{5}}{2}}{\\sqrt{\\frac{5 - \\sqrt{5}}{2}}} = \\left(\\frac{1 - \\sqrt{5}}{2}\\right)\\sqrt{\\frac{2}{5 - \\sqrt{5}}} = -\\sqrt{\\left(\\frac{\\sqrt{5}-1}{2}\\right)^2 \\frac{2}{5 - \\sqrt{5}}} = -\\sqrt{\\frac{6-2\\sqrt{5}}{4} \\frac{2}{5 - \\sqrt{5}}} = -\\sqrt{\\frac{3-\\sqrt{5}}{2} \\frac{2}{5 - \\sqrt{5}}} = -\\sqrt{\\frac{3-\\sqrt{5}}{5 - \\sqrt{5}}} = -\\sqrt{\\frac{(3-\\sqrt{5})(5+\\sqrt{5})}{(5-\\sqrt{5})(5+\\sqrt{5})}} = -\\sqrt{\\frac{10-2\\sqrt{5}}{20}} = -\\sqrt{\\frac{5 - \\sqrt{5}}{10}}\n$$\nSo, $\\mathbf{u}_2 = \\begin{pmatrix} \\sqrt{\\frac{5 + \\sqrt{5}}{10}} \\\\ -\\sqrt{\\frac{5 - \\sqrt{5}}{10}} \\end{pmatrix}$.\n\nFinally, we construct $P$ with columns $\\mathbf{u}_1$ and $\\mathbf{u}_2$:\n$$\nP = \\begin{pmatrix} \\mathbf{u}_1 & \\mathbf{u}_2 \\end{pmatrix} = \\begin{pmatrix} \\sqrt{\\frac{5 - \\sqrt{5}}{10}} & \\sqrt{\\frac{5 + \\sqrt{5}}{10}} \\\\ \\sqrt{\\frac{5 + \\sqrt{5}}{10}} & -\\sqrt{\\frac{5 - \\sqrt{5}}{10}} \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\sqrt{\\frac{5 - \\sqrt{5}}{10}} & \\sqrt{\\frac{5 + \\sqrt{5}}{10}} \\\\ \\sqrt{\\frac{5 + \\sqrt{5}}{10}} & -\\sqrt{\\frac{5 - \\sqrt{5}}{10}} \\end{pmatrix}}\n$$", "id": "1380447"}, {"introduction": "Building on the diagonalization of a single matrix, we now explore a more profound property: the simultaneous diagonalization of commuting matrices. When two symmetric operators commute, they share a common basis of eigenvectors, a principle that is a cornerstone of quantum mechanics and materials science, where it defines the principal axes of a system. This exercise [@problem_id:1506266] challenges you to find such a common basis for two $3 \\times 3$ matrices, a task that requires careful navigation of degenerate eigenspaces to uncover the shared underlying structure.", "problem": "In the study of anisotropic crystalline materials, different physical properties, such as the electric susceptibility and the thermoelastic stress response, can be described by symmetric second-rank tensors. In a particular orthonormal coordinate system, two such property tensors, $T_A$ and $T_B$, are represented by the matrices $A$ and $B$, respectively. It is known from underlying physical principles that these two matrices commute, i.e., $AB = BA$. The matrices are given by:\n\n$$\nA = \\frac{1}{3} \\begin{pmatrix} 13 & -2 & -2 \\\\ -2 & 13 & -2 \\\\ -2 & -2 & 13 \\end{pmatrix}\n$$\n\n$$\nB = \\begin{pmatrix} 2 & 0 & -1 \\\\ 0 & 2 & -1 \\\\ -1 & -1 & 3 \\end{pmatrix}\n$$\n\nA common orthonormal basis of eigenvectors for both $A$ and $B$ corresponds to the principal axes of the crystal, along which these physical properties are decoupled. Your task is to find this common basis.\n\nDetermine the $3 \\times 3$ matrix $P$ whose columns are the common orthonormal eigenvectors, denoted $\\{\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3\\}$. The columns of $P$ must be ordered such that their corresponding eigenvalues with respect to matrix $B$ are in ascending order. Additionally, for each eigenvector, its first non-zero component must be positive. Present your final answer as the matrix $P$.", "solution": "The problem asks for a common orthonormal basis of eigenvectors for two commuting symmetric matrices $A$ and $B$. The existence of such a basis is guaranteed by the fact that $A$ and $B$ are symmetric and commute. The procedure is to find the eigenspaces of one matrix and then use the other matrix to find specific eigenvectors within any degenerate eigenspaces.\n\nLet's start by finding the eigenvalues and eigenvectors of matrix $A$.\n$A = \\frac{1}{3} \\begin{pmatrix} 13 & -2 & -2 \\\\ -2 & 13 & -2 \\\\ -2 & -2 & 13 \\end{pmatrix}$.\nTo simplify calculations, we can work with the matrix $A' = 3A = \\begin{pmatrix} 13 & -2 & -2 \\\\ -2 & 13 & -2 \\\\ -2 & -2 & 13 \\end{pmatrix}$. The eigenvalues of $A$ will be $\\frac{1}{3}$ of the eigenvalues of $A'$.\n\nTo find the eigenvalues of $A'$, we solve the characteristic equation $\\det(A' - \\lambda' I) = 0$.\nA shortcut can be observed by summing the elements in each row of $A'$: $13 - 2 - 2 = 9$. This indicates that the vector $\\mathbf{u}_1 = [1, 1, 1]^T$ is an eigenvector of $A'$, and its corresponding eigenvalue is $\\lambda'_1 = 9$.\nLet's verify:\n$A'\\mathbf{u}_1 = \\begin{pmatrix} 13 & -2 & -2 \\\\ -2 & 13 & -2 \\\\ -2 & -2 & 13 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 13-2-2 \\\\ -2+13-2 \\\\ -2-2+13 \\end{pmatrix} = \\begin{pmatrix} 9 \\\\ 9 \\\\ 9 \\end{pmatrix} = 9 \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\nSo, $\\lambda'_1 = 9$ is an eigenvalue of $A'$. The corresponding eigenvalue for $A$ is $\\lambda_1 = \\frac{9}{3} = 3$.\n\nThe sum of the eigenvalues of $A'$ is equal to its trace: $\\text{Tr}(A') = 13 + 13 + 13 = 39$.\nSo, $\\lambda'_1 + \\lambda'_2 + \\lambda'_3 = 39$.\n$9 + \\lambda'_2 + \\lambda'_3 = 39 \\implies \\lambda'_2 + \\lambda'_3 = 30$.\n\nSince $A'$ is symmetric, its eigenvectors are orthogonal. The other two eigenvectors must be orthogonal to $\\mathbf{u}_1 = [1, 1, 1]^T$. Let's test a simple vector orthogonal to $\\mathbf{u}_1$, for example $\\mathbf{u}_2 = [1, -1, 0]^T$ (since $1(1) + 1(-1) + 1(0) = 0$).\n$A' \\mathbf{u}_2 = \\begin{pmatrix} 13 & -2 & -2 \\\\ -2 & 13 & -2 \\\\ -2 & -2 & 13 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 13+2 \\\\ -2-13 \\\\ -2+2 \\end{pmatrix} = \\begin{pmatrix} 15 \\\\ -15 \\\\ 0 \\end{pmatrix} = 15 \\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$.\nThis shows that $\\mathbf{u}_2=[1, -1, 0]^T$ is an eigenvector of $A'$ with eigenvalue $\\lambda'_2 = 15$.\nFrom $\\lambda'_2 + \\lambda'_3 = 30$, we find $\\lambda'_3 = 30 - 15 = 15$.\nSo, the eigenvalues of $A'$ are $\\{9, 15, 15\\}$, and the eigenvalues of $A$ are $\\{3, 5, 5\\}$.\n\nMatrix $A$ has a non-degenerate eigenvalue $\\lambda_1 = 3$ with eigenvector $\\mathbf{u}_1 = [1, 1, 1]^T$.\nIt also has a degenerate eigenvalue $\\lambda=5$ with a two-dimensional eigenspace $E_5(A)$, which is the plane of vectors orthogonal to $\\mathbf{u}_1$. This plane is defined by the equation $x+y+z=0$.\n\nNow, we use matrix $B$ to find a specific basis for this degenerate eigenspace. The eigenvectors of $B$ must lie within the eigenspaces of $A$. Since $\\mathbf{u}_1$ spans a 1D eigenspace of $A$, it must also be an eigenvector of $B$. Let's find its corresponding eigenvalue, $\\mu_1$:\n$B \\mathbf{u}_1 = \\begin{pmatrix} 2 & 0 & -1 \\\\ 0 & 2 & -1 \\\\ -1 & -1 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2-1 \\\\ 2-1 \\\\ -1-1+3 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = 1 \\cdot \\mathbf{u}_1$.\nSo, for $B$, the eigenvector $\\mathbf{u}_1=[1,1,1]^T$ corresponds to the eigenvalue $\\mu_1=1$.\n\nThe other two eigenvectors of $B$, let's call them $\\mathbf{u}_2$ and $\\mathbf{u}_3$, must lie in the degenerate eigenspace $E_5(A)$, i.e., they must satisfy $x+y+z=0$. Let $\\mathbf{v}=[x,y,z]^T$ be a vector in this plane, where $z=-x-y$. We seek $\\mathbf{v}$ such that $B\\mathbf{v} = \\mu \\mathbf{v}$.\n$B\\mathbf{v} = \\begin{pmatrix} 2 & 0 & -1 \\\\ 0 & 2 & -1 \\\\ -1 & -1 & 3 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ -x-y \\end{pmatrix} = \\begin{pmatrix} 2x - (-x-y) \\\\ 2y - (-x-y) \\\\ -x-y + 3(-x-y) \\end{pmatrix} = \\begin{pmatrix} 3x+y \\\\ x+3y \\\\ -4x-4y \\end{pmatrix}$.\nFor this to be $\\mu \\mathbf{v} = \\mu [x, y, -x-y]^T$, we must have:\n1) $3x+y = \\mu x$\n2) $x+3y = \\mu y$\n3) $-4x-4y = \\mu(-x-y) \\implies 4(x+y)=\\mu(x+y)$.\n\nFrom equation (3), we have two possibilities:\nCase 1: $x+y \\neq 0$. Then we can divide by $(x+y)$ to get $\\mu=4$.\nSubstituting $\\mu=4$ into equation (1): $3x+y = 4x \\implies y=x$.\nThis is consistent with equation (2): $x+3y = 4y \\implies x=y$.\nIf $y=x$, then $z=-x-y=-2x$. The eigenvector is proportional to $[x, x, -2x]^T$, or more simply, $\\mathbf{u}_3 = [1, 1, -2]^T$. The eigenvalue is $\\mu_3=4$.\n\nCase 2: $x+y = 0 \\implies y=-x$.\nIn this case, $z=-x-y=0$. The eigenvector is proportional to $[x, -x, 0]^T$, or more simply, $\\mathbf{u}_2 = [1, -1, 0]^T$.\nWe can find its eigenvalue $\\mu_2$ from equation (1): $3x+(-x)=\\mu_2 x \\implies 2x=\\mu_2 x$. Since $\\mathbf{u}_2$ is non-zero, $x\\neq 0$, so $\\mu_2=2$.\n\nSo we have found the three common unnormalized eigenvectors and their corresponding eigenvalues for matrix $B$:\n$\\mu_1 = 1 \\implies \\mathbf{u}_1 = [1, 1, 1]^T$\n$\\mu_2 = 2 \\implies \\mathbf{u}_2 = [1, -1, 0]^T$\n$\\mu_3 = 4 \\implies \\mathbf{u}_3 = [1, 1, -2]^T$\n\nThe problem requires the final matrix $P=[\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3]$ to have orthonormal columns, ordered by ascending eigenvalues of $B$. The current order $\\{1, 2, 4\\}$ is already ascending. We also need to normalize the vectors and ensure the first non-zero component is positive.\n\nFor $\\mu_1 = 1$: $\\mathbf{u}_1=[1,1,1]^T$. First component is positive.\n$||\\mathbf{u}_1|| = \\sqrt{1^2+1^2+1^2} = \\sqrt{3}$.\n$\\mathbf{v}_1 = \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\n\nFor $\\mu_2 = 2$: $\\mathbf{u}_2=[1,-1,0]^T$. First component is positive.\n$||\\mathbf{u}_2|| = \\sqrt{1^2+(-1)^2+0^2} = \\sqrt{2}$.\n$\\mathbf{v}_2 = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix}$.\n\nFor $\\mu_3 = 4$: $\\mathbf{u}_3=[1,1,-2]^T$. First component is positive.\n$||\\mathbf{u}_3|| = \\sqrt{1^2+1^2+(-2)^2} = \\sqrt{6}$.\n$\\mathbf{v}_3 = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1 \\\\ 1 \\\\ -2 \\end{pmatrix}$.\n\nCombining these column vectors to form the matrix $P$:\n$P = \\begin{pmatrix} \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{3}} & -\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{3}} & 0 & -\\frac{2}{\\sqrt{6}} \\end{pmatrix}$.\n\nRationalizing the denominators yields:\n$P = \\begin{pmatrix} \\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{3}}{3} & -\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{3}}{3} & 0 & -\\frac{2\\sqrt{6}}{6} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{3}}{3} & -\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{3}}{3} & 0 & -\\frac{\\sqrt{6}}{3} \\end{pmatrix}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{\\sqrt{3}}{3} & \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{3}}{3} & -\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{6}}{6} \\\\ \\frac{\\sqrt{3}}{3} & 0 & -\\frac{\\sqrt{6}}{3} \\end{pmatrix}}\n$$", "id": "1506266"}, {"introduction": "Diagonalization is not just a computational shortcut; it is a powerful analytical tool for diagnosing a system's intrinsic properties, such as stability or admissibility. This practice problem [@problem_id:1506229] connects the eigenvalues of a symmetric tensor to the crucial concept of positive definiteness, a condition required for physical stability in continuum mechanics and for finding minima in optimization problems. Here, you will use the properties of the matrix to determine the parameter range for which a hypothetical stability tensor remains positive definite, ensuring all its principal responses are positive.", "problem": "In the study of continuum mechanics, the stability of an anisotropic elastic material under certain loading conditions can be analyzed by examining a symmetric \"stability tensor,\" which can be represented by a 3x3 matrix. A fundamental requirement for material stability is that this matrix must be positive definite.\n\nConsider a simplified model where the stability matrix, denoted by $S$, is dependent on a single dimensionless real parameter $\\alpha$ and is given in a Cartesian basis by the following representation:\n$$\nS(\\alpha) = \\begin{pmatrix}\n2 & \\alpha & 0 \\\\\n\\alpha & 2 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix}\n$$\nA real symmetric matrix is defined as positive definite if and only if all of its eigenvalues are strictly positive. The set of all values of $\\alpha$ for which $S(\\alpha)$ is positive definite forms an open interval, which can be expressed as $(\\alpha_{\\text{min}}, \\alpha_{\\text{max}})$.\n\nDetermine the exact value of the upper bound of this interval, $\\alpha_{\\text{max}}$.", "solution": "We seek the set of real $\\alpha$ such that the symmetric matrix\n$$\nS(\\alpha)=\\begin{pmatrix}\n2 & \\alpha & 0 \\\\\n\\alpha & 2 & 1 \\\\\n0 & 1 & 2\n\\end{pmatrix}\n$$\nis positive definite. For a real symmetric matrix, Sylvester's criterion states that positive definiteness is equivalent to all leading principal minors being strictly positive.\n\nCompute the leading principal minors:\n1) The $1\\times 1$ leading principal minor is\n$$\n\\Delta_{1} = 2 > 0,\n$$\nwhich holds for all $\\alpha$.\n\n2) The $2\\times 2$ leading principal minor is\n$$\n\\Delta_{2} = \\det\\begin{pmatrix}2 & \\alpha \\\\ \\alpha & 2\\end{pmatrix} = 4 - \\alpha^{2}.\n$$\nThe condition $\\Delta_{2} > 0$ gives\n$$\n4 - \\alpha^{2} > 0 \\quad \\Longleftrightarrow \\quad |\\alpha| < 2.\n$$\n\n3) The $3\\times 3$ leading principal minor is the determinant of $S(\\alpha)$:\nExpand along the first row:\n$$\n\\det S(\\alpha) = 2\\det\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix} - \\alpha \\det\\begin{pmatrix}\\alpha & 1 \\\\ 0 & 2\\end{pmatrix} + 0\\cdot(\\cdots).\n$$\nCompute the $2\\times 2$ determinants:\n$$\n\\det\\begin{pmatrix}2 & 1 \\\\ 1 & 2\\end{pmatrix} = 4 - 1 = 3, \\qquad \\det\\begin{pmatrix}\\alpha & 1 \\\\ 0 & 2\\end{pmatrix} = 2\\alpha.\n$$\nHence\n$$\n\\Delta_{3} = \\det S(\\alpha) = 2\\cdot 3 - \\alpha \\cdot 2\\alpha = 6 - 2\\alpha^{2} = 2\\left(3 - \\alpha^{2}\\right).\n$$\nThe condition $\\Delta_{3} > 0$ gives\n$$\n3 - \\alpha^{2} > 0 \\quad \\Longleftrightarrow \\quad |\\alpha| < \\sqrt{3}.\n$$\n\nBy Sylvester's criterion, $S(\\alpha)$ is positive definite if and only if all three inequalities hold simultaneously. Therefore the admissible set is\n$$\n|\\alpha| < 2 \\quad \\text{and} \\quad |\\alpha| < \\sqrt{3} \\quad \\Longleftrightarrow \\quad |\\alpha| < \\sqrt{3}.\n$$\nThus the interval is $\\left(-\\sqrt{3}, \\sqrt{3}\\right)$, and the upper bound is $\\alpha_{\\text{max}} = \\sqrt{3}$.", "answer": "$$\\boxed{\\sqrt{3}}$$", "id": "1506229"}]}