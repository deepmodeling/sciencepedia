{"hands_on_practices": [{"introduction": "The most direct way to understand the Lie derivative is by seeing how it acts on a scalar function. In this case, the operator measures the rate of change of the function along the flow of the vector field, which is conceptually identical to the directional derivative. This foundational exercise [@problem_id:1679297] solidifies this core concept by having you compute the change of a quadratic function along a constant vector field, providing a concrete intuition for this powerful tool.", "problem": "Consider the two-dimensional Euclidean space $\\mathbb{R}^2$ with standard Cartesian coordinates $(x, y)$. Let $f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}$ be a scalar function defined by the quadratic form $f(x, y) = a x^2 + bxy + c y^2$, where $a, b, c$ are arbitrary real constants. Let $V$ be a constant vector field on $\\mathbb{R}^2$ given in component form by $V = v_x \\frac{\\partial}{\\partial x} + v_y \\frac{\\partial}{\\partial y}$, where $v_x$ and $v_y$ are also real constants.\n\nYour task is to compute the Lie derivative of the function $f$ along the vector field $V$, which we denote by $\\mathcal{L}_V f$. Express your final answer as a function of $x$ and $y$, in terms of the constants $a, b, c, v_x,$ and $v_y$.", "solution": "The Lie derivative of a scalar function $f$ along a vector field $V$ is the directional derivative of $f$ in the direction of $V$, given by\n$$\n\\mathcal{L}_{V} f = V(f).\n$$\nFor $V = v_{x} \\frac{\\partial}{\\partial x} + v_{y} \\frac{\\partial}{\\partial y}$ and $f(x,y) = a x^{2} + b x y + c y^{2}$, this becomes\n$$\n\\mathcal{L}_{V} f = v_{x} \\frac{\\partial f}{\\partial x} + v_{y} \\frac{\\partial f}{\\partial y}.\n$$\nCompute the partial derivatives:\n$$\n\\frac{\\partial f}{\\partial x} = 2 a x + b y, \\qquad \\frac{\\partial f}{\\partial y} = b x + 2 c y.\n$$\nSubstitute into the expression for the Lie derivative:\n$$\n\\mathcal{L}_{V} f = v_{x} (2 a x + b y) + v_{y} (b x + 2 c y).\n$$\nOptionally expanding yields\n$$\n\\mathcal{L}_{V} f = (2 a v_{x} + b v_{y}) x + (b v_{x} + 2 c v_{y}) y.\n$$\nThis is the desired expression as a function of $x$ and $y$ in terms of $a, b, c, v_{x}, v_{y}$.", "answer": "$$\\boxed{(2 a v_{x} + b v_{y}) x + (b v_{x} + 2 c v_{y}) y}$$", "id": "1679297"}, {"introduction": "A crucial application of the Lie derivative is in defining the Lie bracket of two vector fields, $\\mathcal{L}_X Y = [X, Y]$, which measures the failure of their flows to commute. This practice [@problem_id:1553890] asks you to verify a fundamental geometric principle: that the basis vectors derived from any valid coordinate system must commute. By explicitly calculating the Lie bracket for the basis vectors of a parabolic coordinate system and confirming it is zero, you will connect the abstract algebraic definition to the tangible geometry of a coordinate grid.", "problem": "In the Euclidean plane $\\mathbb{R}^2$ with standard Cartesian coordinates $(x,y)$, a system of parabolic coordinates $(u,v)$ is defined by the transformation equations $x = uv$ and $y = \\frac{1}{2}(v^2 - u^2)$, valid for $u \\ge 0$ and $v \\in \\mathbb{R}$. The coordinate basis vectors for this system, $\\partial_u$ and $\\partial_v$, are vector fields on the plane. The Lie bracket of these two vector fields defines a new vector field, $Z = [\\partial_u, \\partial_v]$.\n\nDetermine the component functions $(Z_x, Z_y)$ of the vector field $Z$ in the standard Cartesian basis $\\{\\partial_x, \\partial_y\\}$, such that $Z = Z_x \\partial_x + Z_y \\partial_y$. Your answer should be a pair of analytic expressions in terms of the parabolic coordinates $u$ and $v$.", "solution": "We are given the smooth coordinate transformation\n$$\nx(u,v)=uv, \\qquad y(u,v)=\\frac{1}{2}\\left(v^{2}-u^{2}\\right),\n$$\nso the coordinate basis vectors pushed forward to the plane are\n$$\n\\partial_{u}=x_{u}\\,\\partial_{x}+y_{u}\\,\\partial_{y}=v\\,\\partial_{x}-u\\,\\partial_{y}, \\qquad\n\\partial_{v}=x_{v}\\,\\partial_{x}+y_{v}\\,\\partial_{y}=u\\,\\partial_{x}+v\\,\\partial_{y}.\n$$\nLet $A=\\partial_{u}$ and $B=\\partial_{v}$, with components in the Cartesian basis\n$$\nA=a^{x}\\partial_{x}+a^{y}\\partial_{y}, \\quad a^{x}=v,\\ a^{y}=-u; \\qquad\nB=b^{x}\\partial_{x}+b^{y}\\partial_{y}, \\quad b^{x}=u,\\ b^{y}=v.\n$$\nThe Lie bracket in coordinates $x,y$ is\n$$\n[A,B]=\\left(A(b^{x})-B(a^{x})\\right)\\partial_{x}+\\left(A(b^{y})-B(a^{y})\\right)\\partial_{y}.\n$$\nTo evaluate $A(\\cdot)$ and $B(\\cdot)$ on the component functions $u$ and $v$, we need the derivatives of $u$ and $v$ with respect to $x$ and $y$. These are obtained by inverting the Jacobian matrix\n$$\nJ=\\begin{pmatrix} x_{u} & x_{v} \\\\ y_{u} & y_{v} \\end{pmatrix}\n=\\begin{pmatrix} v & u \\\\ -u & v \\end{pmatrix}, \\qquad \\det J=u^{2}+v^{2}.\n$$\nThus\n$$\n\\begin{pmatrix} u_{x} & u_{y} \\\\ v_{x} & v_{y} \\end{pmatrix}\n=J^{-1}\n=\\frac{1}{u^{2}+v^{2}}\\begin{pmatrix} v & -u \\\\ u & v \\end{pmatrix},\n$$\nso\n$$\nu_{x}=\\frac{v}{u^{2}+v^{2}}, \\quad u_{y}=-\\frac{u}{u^{2}+v^{2}}, \\quad\nv_{x}=\\frac{u}{u^{2}+v^{2}}, \\quad v_{y}=\\frac{v}{u^{2}+v^{2}}.\n$$\nNow compute the needed derivatives:\n$$\nA(u)=v\\,u_{x}-u\\,u_{y}\n=v\\left(\\frac{v}{u^{2}+v^{2}}\\right)-u\\left(-\\frac{u}{u^{2}+v^{2}}\\right)\n=\\frac{v^{2}+u^{2}}{u^{2}+v^{2}}=1,\n$$\n$$\nB(v)=u\\,v_{x}+v\\,v_{y}\n=u\\left(\\frac{u}{u^{2}+v^{2}}\\right)+v\\left(\\frac{v}{u^{2}+v^{2}}\\right)\n=\\frac{u^{2}+v^{2}}{u^{2}+v^{2}}=1,\n$$\n$$\nA(v)=v\\,v_{x}-u\\,v_{y}\n=v\\left(\\frac{u}{u^{2}+v^{2}}\\right)-u\\left(\\frac{v}{u^{2}+v^{2}}\\right)=0,\n$$\n$$\nB(u)=u\\,u_{x}+v\\,u_{y}\n=u\\left(\\frac{v}{u^{2}+v^{2}}\\right)+v\\left(-\\frac{u}{u^{2}+v^{2}}\\right)=0.\n$$\nTherefore the Lie bracket components are\n$$\nZ_{x}=A(b^{x})-B(a^{x})=A(u)-B(v)=1-1=0, \\qquad\nZ_{y}=A(b^{y})-B(a^{y})=A(v)-B(-u)=A(v)+B(u)=0.\n$$\nEquivalently, since $\\partial_{u}$ and $\\partial_{v}$ are coordinate vector fields, they commute, so $[\\partial_{u},\\partial_{v}]=0$; the explicit computation above confirms $Z_{x}=0$ and $Z_{y}=0$.", "answer": "$$\\boxed{\\begin{pmatrix}0 & 0\\end{pmatrix}}$$", "id": "1553890"}, {"introduction": "This advanced problem challenges you to work backward by finding a vector field that induces a specific change in a given differential 1-form. Such inverse problems [@problem_id:1679322] are excellent for developing a deeper mastery of the interplay between vector fields, forms, and the geometric operators that connect them. To solve it, you will need to skillfully apply Cartan's formula, $\\mathcal{L}_X \\alpha = i_X d\\alpha + d(i_X \\alpha)$, which is an indispensable tool in differential geometry.", "problem": "Consider the flat plane $\\mathbb{R}^2$ endowed with standard Cartesian coordinates $(x,y)$. Let $\\alpha$ be a differential 1-form given by $\\alpha = \\exp(x) dy$, and let $f$ be a smooth scalar function defined as $f(x,y) = y^2$.\n\nA smooth vector field $X$ on $\\mathbb{R}^2$ is sought that satisfies the condition $\\mathcal{L}_X \\alpha = df$, where $\\mathcal{L}_X \\alpha$ is the Lie derivative of the 1-form $\\alpha$ with respect to the vector field $X$, and $df$ is the exterior derivative of the function $f$.\n\nDetermine the general functional form for the components of such a vector field $X = X^1(x,y) \\frac{\\partial}{\\partial x} + X^2(x,y) \\frac{\\partial}{\\partial y}$. Your final answer for the components $(X^1, X^2)$ may involve an arbitrary differentiable function of a single variable. Let this arbitrary function be denoted by $g(y)$, and its derivative with respect to $y$ by $g'(y)$.", "solution": "We are given $\\alpha=\\exp(x)\\,dy$ and $f=y^{2}$ on $\\mathbb{R}^{2}$ with coordinates $(x,y)$. We seek a vector field $X=X^{1}(x,y)\\,\\frac{\\partial}{\\partial x}+X^{2}(x,y)\\,\\frac{\\partial}{\\partial y}$ such that $\\mathcal{L}_{X}\\alpha=df$. Since $f=y^{2}$, its exterior derivative is\n$$\ndf=d(y^{2})=2y\\,dy.\n$$\nUsing Cartanâ€™s formula for the Lie derivative of a 1-form, \n$$\n\\mathcal{L}_{X}\\alpha=i_{X}d\\alpha+d(i_{X}\\alpha).\n$$\nFirst compute $d\\alpha$. Using $d(\\exp(x))=\\exp(x)\\,dx$ and $d(dy)=0$, we have\n$$\nd\\alpha=d(\\exp(x)\\,dy)=d(\\exp(x))\\wedge dy+\\exp(x)\\,d(dy)=\\exp(x)\\,dx\\wedge dy.\n$$\nNext compute the interior product $i_{X}d\\alpha$. Using $i_{\\frac{\\partial}{\\partial x}}(dx\\wedge dy)=dy$ and $i_{\\frac{\\partial}{\\partial y}}(dx\\wedge dy)=-dx$, we get\n$$\ni_{X}d\\alpha=\\exp(x)\\big(X^{1}\\,dy-X^{2}\\,dx\\big).\n$$\nNow compute $i_{X}\\alpha=\\alpha(X)=\\exp(x)\\,dy(X)=\\exp(x)\\,X^{2}$, hence\n$$\nd(i_{X}\\alpha)=d\\big(\\exp(x)\\,X^{2}\\big)=\\partial_{x}\\big(\\exp(x)\\,X^{2}\\big)\\,dx+\\partial_{y}\\big(\\exp(x)\\,X^{2}\\big)\\,dy.\n$$\nTherefore,\n$$\n\\mathcal{L}_{X}\\alpha=\\big[\\partial_{x}\\big(\\exp(x)\\,X^{2}\\big)-\\exp(x)\\,X^{2}\\big]\\;dx+\\big[\\exp(x)\\,X^{1}+\\partial_{y}\\big(\\exp(x)\\,X^{2}\\big)\\big]\\;dy.\n$$\nImposing $\\mathcal{L}_{X}\\alpha=df=2y\\,dy$ yields the system\n$$\n\\partial_{x}\\big(\\exp(x)\\,X^{2}\\big)-\\exp(x)\\,X^{2}=0,\\qquad \\exp(x)\\,X^{1}+\\partial_{y}\\big(\\exp(x)\\,X^{2}\\big)=2y.\n$$\nFor the first equation, apply the product rule:\n$$\n\\partial_{x}\\big(\\exp(x)\\,X^{2}\\big)=\\exp(x)\\,X^{2}+\\exp(x)\\,\\partial_{x}X^{2},\n$$\nso the equation becomes $\\exp(x)\\,\\partial_{x}X^{2}=0$, hence\n$$\n\\partial_{x}X^{2}=0\\quad\\Longrightarrow\\quad X^{2}=g(y),\n$$\nwith $g$ an arbitrary differentiable function of $y$. Substitute this into the second equation:\n$$\n\\exp(x)\\,X^{1}+\\partial_{y}\\big(\\exp(x)\\,g(y)\\big)=2y\\quad\\Longrightarrow\\quad \\exp(x)\\,X^{1}+\\exp(x)\\,g'(y)=2y,\n$$\nso\n$$\nX^{1}=2y\\,\\exp(-x)-g'(y).\n$$\nThus the general vector field satisfying $\\mathcal{L}_{X}\\alpha=df$ has components\n$$\n\\big(X^{1}(x,y),X^{2}(x,y)\\big)=\\big(2y\\,\\exp(-x)-g'(y),\\;g(y)\\big),\n$$\nwhere $g$ is an arbitrary differentiable function of $y$.", "answer": "$$\\boxed{\\begin{pmatrix}2y\\,\\exp(-x)-g'(y) & g(y)\\end{pmatrix}}$$", "id": "1679322"}]}