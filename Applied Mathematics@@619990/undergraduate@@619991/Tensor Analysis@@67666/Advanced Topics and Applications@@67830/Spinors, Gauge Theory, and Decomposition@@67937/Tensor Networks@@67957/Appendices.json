{"hands_on_practices": [{"introduction": "The power of tensor networks lies in their intuitive graphical language, where tensors are nodes and contractions are links. This exercise challenges you to translate between the traditional algebraic notation of a tensor contraction and its visual diagram. Mastering this fundamental skill is the first step toward building, interpreting, and simplifying complex networks.", "problem": "In the formalism of tensor networks, a tensor is represented as a node, and its indices are represented as lines (or \"legs\") connected to that node. The rank of the tensor determines the number of its legs. A contraction between two tensors over a common index is depicted by connecting the corresponding legs. The un-connected legs represent the free indices of the resulting tensor.\n\nConsider a rank-3 tensor, denoted as $A_{ijk}$. In a diagram, this tensor is a node with three legs, where the first leg corresponds to index $i$, the second to index $j$, and the third to index $k$.\n\nTwo identical copies of this tensor $A$ are contracted to form a rank-2 tensor $M$ according to the following equation:\n$$M_{ac} = \\sum_{b,d} A_{abd} A_{cbd}$$\nWhich of the following descriptions accurately represents the tensor network diagram for this contraction?\n\nA. Two nodes for $A$. The first leg of the first node is connected to the first leg of the second node. The second leg of the first node is connected to the second leg of the second node. The third legs of both nodes remain open.\n\nB. Two nodes for $A$. The second leg of the first node is connected to the third leg of the second node. The third leg of the first node is connected to the second leg of the second node. The first legs of both nodes remain open.\n\nC. Two nodes for $A$. Only the second leg of the first node is connected to the second leg of the second node. The first and third legs of both nodes remain open, resulting in four free indices.\n\nD. Two nodes for $A$. The second leg of the first node is connected to the second leg of the second node. The third leg of the first node is connected to the third leg of the second node. The first legs of both nodes remain open.", "solution": "A rank-3 tensor $A_{ijk}$ is represented as a node with three legs corresponding to indices $i$ (first leg), $j$ (second leg), and $k$ (third leg). For two copies of $A$, the contraction\n$$M_{ac} = \\sum_{b,d} A_{abd} A_{cbd}$$\nspecifies which indices are summed and which remain free.\n\nIdentify the leg-to-index mapping for each copy:\n- For the first tensor $A_{abd}$: first leg $\\to a$, second leg $\\to b$, third leg $\\to d$.\n- For the second tensor $A_{cbd}$: first leg $\\to c$, second leg $\\to b$, third leg $\\to d$.\n\nThe summation over $b$ and $d$ means these indices are contracted between the two tensors. Diagrammatically, this corresponds to connecting the legs that carry the same contracted indices across the two nodes:\n- Connect the second leg of the first node (index $b$) to the second leg of the second node (index $b$).\n- Connect the third leg of the first node (index $d$) to the third leg of the second node (index $d$).\n\nThe remaining free indices are $a$ and $c$, which correspond to the first leg of the first node and the first leg of the second node, respectively. Therefore, the resulting tensor $M_{ac}$ is rank-2 with its two open legs being precisely those first legs.\n\nThis description matches option D. Option A would incorrectly contract the first legs (contracting $a$), option B cross-connects $b$ with $d$ and $d$ with $b$, and option C would leave four free legs, yielding a rank-4 tensor, which contradicts $M_{ac}$ being rank-2.", "answer": "$$\\boxed{D}$$", "id": "1543550"}, {"introduction": "One of the most successful applications of tensor networks is the Matrix Product State (MPS), used to efficiently represent quantum states of one-dimensional systems. This practice problem demystifies the structure of an MPS by having you calculate its total number of parameters. This calculation will help you understand how the physical and internal \"bond\" dimensions, represented by $\\chi$, directly determine the representational capacity and memory cost of the tensor network.", "problem": "A computational physicist is modeling a small one-dimensional quantum spin chain using a tensor network approach. The state of the system is represented by a Matrix Product State (MPS) with open boundary conditions. The chain consists of $N=3$ sites.\n\nAt each site, there is a \"physical index\" of dimension $d=2$, representing the local state of a spin-1/2 particle. The tensors in the MPS are connected by \"internal\" or \"bond\" indices. For this particular model, the maximum bond dimension is chosen to be $\\chi=4$.\n\nIn an open boundary condition MPS, the tensors at the two ends of the chain are rank-2 (having one physical index and one bond index), while any tensors in the bulk (middle) of the chain are rank-3 (having one physical index and two bond indices).\n\nCalculate the total number of scalar parameters required to completely specify all the tensor elements in this three-site MPS representation.", "solution": "In an open-boundary MPS with $N=3$, there are two end tensors (sites $1$ and $3$) of rank $2$ and one bulk tensor (site $2$) of rank $3$. The number of scalar parameters in a tensor equals the product of the dimensions of all its indices.\n\nLet the physical dimension be $d$ and the (maximum) bond dimension be $\\chi$.\n\n- Site $1$ tensor: one physical index of dimension $d$ and one bond index of dimension $\\chi$, giving $d\\chi$ parameters.\n- Site $2$ tensor: one physical index of dimension $d$ and two bond indices each of dimension $\\chi$, giving $d\\chi^{2}$ parameters.\n- Site $3$ tensor: one bond index of dimension $\\chi$ and one physical index of dimension $d$, giving $d\\chi$ parameters.\n\nTherefore, the total number of scalar parameters is\n$$\nP=d\\chi+d\\chi^{2}+d\\chi=d\\left(2\\chi+\\chi^{2}\\right)=d\\chi\\left(\\chi+2\\right).\n$$\nSubstituting $d=2$ and $\\chi=4$,\n$$\nP=2\\cdot 4\\cdot(4+2)=8\\cdot 6=48.\n$$", "answer": "$$\\boxed{48}$$", "id": "1543545"}, {"introduction": "Beyond just representing complex objects, the structure of a tensor network can guide us toward the most efficient way to compute quantities of interest. This problem explores the critical concept of contraction order, demonstrating how different evaluation paths can lead to vastly different computational costs. This principle is a cornerstone of practical tensor network algorithms and highlights their power in tackling large-scale numerical problems.", "problem": "In many fields of computational science, evaluating complex tensor networks is a common task. The efficiency of such a calculation critically depends on the order in which tensors are contracted. Consider a network composed of a central rank-5 tensor, $C_{ijklm}$, and five vectors, $v_i$, $w_j$, $x_k$, $y_l$, and $z_m$. The goal is to compute the scalar value $S$ given by the full contraction of this network:\n$$S = \\sum_{i,j,k,l,m} C_{ijklm} v_i w_j x_k y_l z_m$$\nThe dimensions of the indices are given as follows: $d_i = 5$, $d_j = 7$, $d_k = 11$, $d_l = 13$, and $d_m = 17$.\n\nThe computational cost of a single contraction of a tensor with a vector over one index is defined by the number of multiplication operations required. This is equal to the total number of elements in the higher-rank tensor involved in that step. For example, computing an intermediate tensor $T_{jklm} = \\sum_{i} C_{ijklm} v_i$ requires $d_i \\times d_j \\times d_k \\times d_l \\times d_m$ multiplications.\n\nTwo distinct sequences for computing the scalar $S$ are proposed:\n\n**Sequence A**: The scalar $S$ is computed by first contracting the tensor $C$ with the vector $v$, then contracting the resulting rank-4 tensor with $w$, and so on, following the sequential order of vectors $(v, w, x, y, z)$.\n\n**Sequence B**: The scalar $S$ is computed similarly, but by contracting with the vectors in the reverse order, $(z, y, x, w, v)$.\n\nCalculate the ratio of the total computational cost of the more expensive sequence to that of the less expensive sequence. Round your final answer to four significant figures.", "solution": "We are given a rank-5 tensor $C_{ijklm}$ with index dimensions $d_i=5$, $d_j=7$, $d_k=11$, $d_l=13$, $d_m=17$, and vectors $v_i, w_j, x_k, y_l, z_m$. The scalar is\n$$\nS=\\sum_{i,j,k,l,m} C_{ijklm} v_{i} w_{j} x_{k} y_{l} z_{m}.\n$$\nThe cost of contracting a tensor with a vector over one index equals the number of elements in the higher-rank tensor before the contraction.\n\nFor Sequence A (order $(v,w,x,y,z)$), the costs at each step are:\n- First contract $C$ with $v$ over $i$: cost $d_i d_j d_k d_l d_m$; result has size $d_j d_k d_l d_m$.\n- Then with $w$ over $j$: cost $d_j d_k d_l d_m$; result has size $d_k d_l d_m$.\n- Then with $x$ over $k$: cost $d_k d_l d_m$; result has size $d_l d_m$.\n- Then with $y$ over $l$: cost $d_l d_m$; result has size $d_m$.\n- Finally with $z$ over $m$: cost $d_m$; result is a scalar.\n\nThus the total cost is\n$$\n\\text{Cost}_{A}=d_{i} d_{j} d_{k} d_{l} d_{m}+d_{j} d_{k} d_{l} d_{m}+d_{k} d_{l} d_{m}+d_{l} d_{m}+d_{m}.\n$$\nSubstituting the given dimensions,\n$$\n\\text{Cost}_{A}=5\\cdot 7\\cdot 11\\cdot 13\\cdot 17+7\\cdot 11\\cdot 13\\cdot 17+11\\cdot 13\\cdot 17+13\\cdot 17+17.\n$$\nCompute each product:\n$$\n5\\cdot 7\\cdot 11\\cdot 13\\cdot 17=85085,\\quad 7\\cdot 11\\cdot 13\\cdot 17=17017,\\quad 11\\cdot 13\\cdot 17=2431,\\quad 13\\cdot 17=221,\\quad 17=17,\n$$\nso\n$$\n\\text{Cost}_{A}=85085+17017+2431+221+17=104771.\n$$\n\nFor Sequence B (order $(z,y,x,w,v)$), the costs at each step are:\n- First contract $C$ with $z$ over $m$: cost $d_i d_j d_k d_l d_m$; result has size $d_i d_j d_k d_l$.\n- Then with $y$ over $l$: cost $d_i d_j d_k d_l$; result has size $d_i d_j d_k$.\n- Then with $x$ over $k$: cost $d_i d_j d_k$; result has size $d_i d_j$.\n- Then with $w$ over $j$: cost $d_i d_j$; result has size $d_i$.\n- Finally with $v$ over $i$: cost $d_i$; result is a scalar.\n\nThus the total cost is\n$$\n\\text{Cost}_{B}=d_{i} d_{j} d_{k} d_{l} d_{m}+d_{i} d_{j} d_{k} d_{l}+d_{i} d_{j} d_{k}+d_{i} d_{j}+d_{i}.\n$$\nSubstituting the given dimensions,\n$$\n\\text{Cost}_{B}=5\\cdot 7\\cdot 11\\cdot 13\\cdot 17+5\\cdot 7\\cdot 11\\cdot 13+5\\cdot 7\\cdot 11+5\\cdot 7+5.\n$$\nCompute each product:\n$$\n5\\cdot 7\\cdot 11\\cdot 13\\cdot 17=85085,\\quad 5\\cdot 7\\cdot 11\\cdot 13=5005,\\quad 5\\cdot 7\\cdot 11=385,\\quad 5\\cdot 7=35,\\quad 5=5,\n$$\nso\n$$\n\\text{Cost}_{B}=85085+5005+385+35+5=90515.\n$$\n\nThe more expensive sequence is Sequence A since $104771 > 90515$. The requested ratio is\n$$\nR=\\frac{\\text{Cost}_{\\text{more}}}{\\text{Cost}_{\\text{less}}}=\\frac{104771}{90515}\\approx 1.15749877\\ldots\n$$\nRounded to four significant figures, this is $1.157$.", "answer": "$$\\boxed{1.157}$$", "id": "1543555"}]}