{"hands_on_practices": [{"introduction": "To build any application on an interest rate model, we must first understand its fundamental dynamics. The Vasicek model describes a mean-reverting process, and by solving its governing stochastic differential equation (SDE), we can find the exact distribution of the future interest rate, conditional on its current value. This exercise ([@problem_id:3074350]) will solidify your Itô calculus skills and provide you with the explicit formulas for the conditional mean and variance, which are the foundational building blocks for pricing derivatives and managing risk.", "problem": "Consider a short-rate model where the instantaneous interest rate process $\\{r_{t}\\}_{t \\geq 0}$ evolves under a fixed probability measure according to the stochastic differential equation (SDE),\n$$\n\\mathrm{d}r_{t} = \\kappa \\left(\\theta - r_{t}\\right)\\mathrm{d}t + \\sigma \\,\\mathrm{d}W_{t}, \\quad r_{0} \\in \\mathbb{R},\n$$\nwhere $\\kappa  0$, $\\theta \\in \\mathbb{R}$, and $\\sigma  0$ are constants, and $\\{W_{t}\\}_{t \\geq 0}$ is a standard one-dimensional Brownian motion (Wiener process). This specification is the classical Vasicek short-rate model, whose solution is known to be an Ornstein-Uhlenbeck (OU) process. For fixed times $0 \\leq s  t$, derive the explicit pathwise solution $r_{t}$ starting from fundamental definitions and principles of Itô calculus, and from your explicit solution compute the conditional expectation $\\mathbb{E}\\!\\left[r_{t}\\mid r_{s}\\right]$ and the conditional variance $\\operatorname{Var}\\!\\left(r_{t}\\mid r_{s}\\right)$ as closed-form analytic expressions in terms of $\\kappa$, $\\theta$, $\\sigma$, $s$, $t$, and $r_{s}$. Express your final answer as a pair of closed-form expressions and do not include any units. No rounding is required.", "solution": "The problem statement is validated as being scientifically grounded, well-posed, objective, and internally consistent. It poses a standard, non-trivial question within the field of stochastic calculus as applied to mathematical finance. We may therefore proceed with the derivation.\n\nThe stochastic differential equation (SDE) for the Vasicek model is given by:\n$$\n\\mathrm{d}r_{t} = \\kappa \\left(\\theta - r_{t}\\right)\\mathrm{d}t + \\sigma \\,\\mathrm{d}W_{t}\n$$\nwhere $\\kappa  0$, $\\theta \\in \\mathbb{R}$, and $\\sigma  0$ are constants, and $\\{W_{t}\\}_{t \\geq 0}$ is a standard Wiener process. This is a linear SDE, which can be solved using an integrating factor. First, we rearrange the SDE as:\n$$\n\\mathrm{d}r_{t} + \\kappa r_{t} \\mathrm{d}t = \\kappa \\theta \\mathrm{d}t + \\sigma \\mathrm{d}W_{t}\n$$\nThe integrating factor for the left-hand side is $I(t) = \\exp(\\kappa t)$. We define a new process $Y_{t} = r_{t} I(t) = r_{t} \\exp(\\kappa t)$. We find its differential using Itô's product rule. For two processes $X_t$ and $Z_t$, $\\mathrm{d}(X_t Z_t) = X_t \\mathrm{d}Z_t + Z_t \\mathrm{d}X_t + \\mathrm{d}\\langle X, Z \\rangle_t$. Here, $X_t = \\exp(\\kappa t)$ is a deterministic process, so its differential is $\\mathrm{d}X_t = \\kappa \\exp(\\kappa t) \\mathrm{d}t$ and its quadratic variation is zero, making the quadratic covariation term $\\mathrm{d}\\langle X, r \\rangle_t$ equal to zero.\nThus, we have:\n$$\n\\mathrm{d}Y_{t} = \\mathrm{d}\\left(r_{t} \\exp(\\kappa t)\\right) = r_{t} \\, \\mathrm{d}(\\exp(\\kappa t)) + \\exp(\\kappa t) \\, \\mathrm{d}r_{t}\n$$\n$$\n\\mathrm{d}Y_{t} = r_{t} (\\kappa \\exp(\\kappa t) \\mathrm{d}t) + \\exp(\\kappa t) \\, \\mathrm{d}r_{t}\n$$\nSubstituting the SDE for $\\mathrm{d}r_{t}$:\n$$\n\\mathrm{d}Y_{t} = \\kappa r_{t} \\exp(\\kappa t) \\mathrm{d}t + \\exp(\\kappa t) \\left( \\kappa \\theta \\mathrm{d}t - \\kappa r_{t} \\mathrm{d}t + \\sigma \\mathrm{d}W_{t} \\right)\n$$\nSimplifying the expression by cancelling terms:\n$$\n\\mathrm{d}Y_{t} = \\kappa r_{t} \\exp(\\kappa t) \\mathrm{d}t + \\kappa \\theta \\exp(\\kappa t) \\mathrm{d}t - \\kappa r_{t} \\exp(\\kappa t) \\mathrm{d}t + \\sigma \\exp(\\kappa t) \\mathrm{d}W_{t}\n$$\n$$\n\\mathrm{d}Y_{t} = \\kappa \\theta \\exp(\\kappa t) \\mathrm{d}t + \\sigma \\exp(\\kappa t) \\mathrm{d}W_{t}\n$$\nNow, we integrate this expression from a starting time $s$ to a future time $t$, where $0 \\leq s  t$:\n$$\n\\int_{s}^{t} \\mathrm{d}Y_{u} = \\int_{s}^{t} \\kappa \\theta \\exp(\\kappa u) \\mathrm{d}u + \\int_{s}^{t} \\sigma \\exp(\\kappa u) \\mathrm{d}W_{u}\n$$\n$$\nY_{t} - Y_{s} = \\kappa \\theta \\left[ \\frac{1}{\\kappa} \\exp(\\kappa u) \\right]_{s}^{t} + \\sigma \\int_{s}^{t} \\exp(\\kappa u) \\mathrm{d}W_{u}\n$$\nSubstituting back $Y_{u} = r_{u}\\exp(\\kappa u)$:\n$$\nr_{t}\\exp(\\kappa t) - r_{s}\\exp(\\kappa s) = \\theta \\left( \\exp(\\kappa t) - \\exp(\\kappa s) \\right) + \\sigma \\int_{s}^{t} \\exp(\\kappa u) \\mathrm{d}W_{u}\n$$\nTo find the explicit solution for $r_{t}$, we isolate it by multiplying the entire equation by $\\exp(-\\kappa t)$:\n$$\nr_{t} = r_{s} \\exp(-\\kappa(t-s)) + \\theta \\left( 1 - \\exp(-\\kappa(t-s)) \\right) + \\sigma \\int_{s}^{t} \\exp(-\\kappa(t-u)) \\mathrm{d}W_{u}\n$$\nThis is the explicit pathwise solution for $r_t$ conditional on its value $r_s$ at time $s$.\n\nNext, we compute the conditional expectation $\\mathbb{E}[r_{t}\\mid r_{s}]$. Since $r_s$ is known at time $s$, it is $\\mathcal{F}_{s}$-measurable, where $\\{\\mathcal{F}_{t}\\}_{t \\geq 0}$ is the filtration generated by the Wiener process. We condition on the sigma-algebra $\\mathcal{F}_{s}$.\n$$\n\\mathbb{E}[r_{t}\\mid \\mathcal{F}_{s}] = \\mathbb{E}\\left[ r_{s} \\exp(-\\kappa(t-s)) + \\theta \\left( 1 - \\exp(-\\kappa(t-s)) \\right) + \\sigma \\int_{s}^{t} \\exp(-\\kappa(t-u)) \\mathrm{d}W_{u} \\mid \\mathcal{F}_{s} \\right]\n$$\nBy the linearity of conditional expectation:\n$$\n\\mathbb{E}[r_{t}\\mid \\mathcal{F}_{s}] = \\mathbb{E}[r_{s} \\exp(-\\kappa(t-s)) \\mid \\mathcal{F}_{s}] + \\mathbb{E}[\\theta (1 - \\exp(-\\kappa(t-s))) \\mid \\mathcal{F}_{s}] + \\mathbb{E}\\left[\\sigma \\int_{s}^{t} \\exp(-\\kappa(t-u)) \\mathrm{d}W_{u} \\mid \\mathcal{F}_{s}\\right]\n$$\nThe first two terms are functions of $r_s$ and constants, which are $\\mathcal{F}_{s}$-measurable, so they are fixed under the conditional expectation. The third term involves an Itô integral with a deterministic integrand over the interval $[s, t]$. A fundamental property of Itô integrals is that their conditional expectation is zero: $\\mathbb{E}\\left[\\int_{s}^{t} f(u) \\mathrm{d}W_u \\mid \\mathcal{F}_{s}\\right] = 0$.\nTherefore, the conditional expectation is:\n$$\n\\mathbb{E}[r_{t}\\mid r_{s}] = r_{s} \\exp(-\\kappa(t-s)) + \\theta \\left( 1 - \\exp(-\\kappa(t-s)) \\right)\n$$\nFinally, we compute the conditional variance $\\operatorname{Var}(r_{t}\\mid r_{s}) = \\mathbb{E}\\left[ (r_{t} - \\mathbb{E}[r_{t}\\mid r_{s}])^2 \\mid r_{s} \\right]$. From our previous results:\n$$\nr_{t} - \\mathbb{E}[r_{t}\\mid r_{s}] = \\sigma \\int_{s}^{t} \\exp(-\\kappa(t-u)) \\mathrm{d}W_{u}\n$$\nSo, the conditional variance is:\n$$\n\\operatorname{Var}(r_{t}\\mid r_{s}) = \\mathbb{E}\\left[ \\left( \\sigma \\int_{s}^{t} \\exp(-\\kappa(t-u)) \\mathrm{d}W_{u} \\right)^2 \\mid \\mathcal{F}_{s} \\right]\n$$\nSince the increments of the Wiener process $W_u - W_s$ for $u  s$ are independent of $\\mathcal{F}_{s}$, the conditional expectation is equal to the unconditional expectation.\n$$\n\\operatorname{Var}(r_{t}\\mid r_{s}) = \\sigma^2 \\mathbb{E}\\left[ \\left( \\int_{s}^{t} \\exp(-\\kappa(t-u)) \\mathrm{d}W_{u} \\right)^2 \\right]\n$$\nUsing the Itô isometry property, which states that $\\mathbb{E}\\left[ \\left(\\int_{s}^{t} f(u) \\mathrm{d}W_u\\right)^2 \\right] = \\int_{s}^{t} \\mathbb{E}[f(u)^2] \\mathrm{d}u$, and noting that our integrand $f(u) = \\exp(-\\kappa(t-u))$ is deterministic:\n$$\n\\operatorname{Var}(r_{t}\\mid r_{s}) = \\sigma^2 \\int_{s}^{t} \\left( \\exp(-\\kappa(t-u)) \\right)^2 \\mathrm{d}u = \\sigma^2 \\int_{s}^{t} \\exp(-2\\kappa(t-u)) \\mathrm{d}u\n$$\nWe evaluate the integral:\n$$\n\\int_{s}^{t} \\exp(-2\\kappa(t-u)) \\mathrm{d}u = \\left[ \\frac{1}{2\\kappa} \\exp(-2\\kappa(t-u)) \\right]_{u=s}^{u=t} = \\frac{1}{2\\kappa} \\left( \\exp(0) - \\exp(-2\\kappa(t-s)) \\right) = \\frac{1 - \\exp(-2\\kappa(t-s))}{2\\kappa}\n$$\nThus, the conditional variance is:\n$$\n\\operatorname{Var}(r_{t}\\mid r_{s}) = \\frac{\\sigma^2}{2\\kappa} \\left(1 - \\exp(-2\\kappa(t-s))\\right)\n$$\nThis completes the derivation of the conditional expectation and variance.", "answer": "$$\n\\boxed{\\begin{pmatrix} r_{s} \\exp(-\\kappa (t - s)) + \\theta \\left(1 - \\exp(-\\kappa (t - s))\\right)  \\frac{\\sigma^{2}}{2 \\kappa} \\left(1 - \\exp(-2 \\kappa (t - s))\\right) \\end{pmatrix}}\n$$", "id": "3074350"}, {"introduction": "While knowing the short-term evolution of interest rates is crucial, understanding their long-run behavior provides insight into the stability and economic implications of a model. For a mean-reverting process like the one defined by the Vasicek model, the interest rate does not wander off to infinity but instead fluctuates around a long-term average, a behavior described by a stationary distribution. In this practice ([@problem_id:3074338]), you will derive this equilibrium distribution using the Fokker-Planck equation, revealing the long-term mean and variance that the interest rate process tends toward over time.", "problem": "Consider the time-homogeneous Vasicek short-rate model, where the short rate $r_t$ satisfies the linear Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d} r_t = \\kappa \\left( \\theta - r_t \\right) \\mathrm{d} t + \\sigma \\,\\mathrm{d} W_t,\n$$\nwith constants $\\kappa  0$, $\\theta \\in \\mathbb{R}$, $\\sigma  0$, and $\\{W_t\\}_{t \\ge 0}$ a standard Brownian motion (also called a Wiener process). Assume the model is defined on a filtered probability space that supports a unique strong solution and that natural boundary conditions hold at $\\pm \\infty$ for the associated Kolmogorov forward equation. Using only well-established principles of Itô calculus and Markov diffusion theory, determine the stationary distribution of $\\{r_t\\}_{t \\ge 0}$, explicitly provide the stationary probability density function $\\pi(r)$, and compute its mean and variance. Express your final answer as a single analytical expression listing the stationary density, its mean, and its variance in that order. Do not use or quote any shortcut formulas; derive your result from first principles appropriate to stochastic differential equations and time-homogeneous diffusions. No numerical rounding is required.", "solution": "The problem requires the derivation of the stationary probability density function $\\pi(r)$, its mean, and its variance for the Vasicek short-rate model. The model is described by the stochastic differential equation (SDE):\n$$\n\\mathrm{d} r_t = \\kappa \\left( \\theta - r_t \\right) \\mathrm{d} t + \\sigma \\,\\mathrm{d} W_t\n$$\nwhere $\\kappa  0$, $\\theta \\in \\mathbb{R}$, and $\\sigma  0$ are constants, and $\\{W_t\\}_{t \\ge 0}$ is a standard Wiener process. This SDE describes a time-homogeneous Itô diffusion process, specifically an Ornstein-Uhlenbeck process. The condition $\\kappa  0$ ensures the process is mean-reverting, which is necessary for the existence of a stationary distribution.\n\nThe derivation will proceed from first principles by solving the stationary form of the Kolmogorov forward equation (also known as the Fokker-Planck equation).\n\nFor a general time-homogeneous SDE $\\mathrm{d}X_t = \\mu(X_t)\\mathrm{d}t + b(X_t)\\mathrm{d}W_t$, the Kolmogorov forward equation for the probability density function $p(x,t)$ is:\n$$\n\\frac{\\partial p(x, t)}{\\partial t} = -\\frac{\\partial}{\\partial x} [\\mu(x) p(x, t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial x^2} [b(x)^2 p(x, t)]\n$$\nFor the Vasicek model, the process is $r_t$, the drift coefficient is $\\mu(r) = \\kappa(\\theta - r)$, and the diffusion coefficient is $b(r) = \\sigma$. Substituting these into the general equation gives:\n$$\n\\frac{\\partial p(r, t)}{\\partial t} = -\\frac{\\partial}{\\partial r} [\\kappa(\\theta - r) p(r, t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial r^2} [\\sigma^2 p(r, t)]\n$$\nThe stationary distribution is characterized by a time-independent probability density function, $\\pi(r)$, which is the solution to the above equation when $\\frac{\\partial p(r, t)}{\\partial t} = 0$. Thus, $\\pi(r)$ must satisfy the following ordinary differential equation (ODE):\n$$\n0 = -\\frac{\\mathrm{d}}{\\mathrm{d} r} [\\kappa(\\theta - r) \\pi(r)] + \\frac{1}{2} \\frac{\\mathrm{d}}{\\mathrm{d} r} \\left( \\frac{\\mathrm{d}}{\\mathrm{d} r} [\\sigma^2 \\pi(r)] \\right)\n$$\nSince $\\sigma$ is a constant, this simplifies to:\n$$\n0 = \\frac{\\mathrm{d}}{\\mathrm{d} r} \\left( -\\kappa(\\theta - r) \\pi(r) + \\frac{\\sigma^2}{2} \\frac{\\mathrm{d}\\pi(r)}{\\mathrm{d}r} \\right)\n$$\nIntegrating this equation once with respect to $r$ yields:\n$$\nC = -\\kappa(\\theta - r) \\pi(r) + \\frac{\\sigma^2}{2} \\frac{\\mathrm{d}\\pi(r)}{\\mathrm{d}r}\n$$\nThe expression on the right-hand side represents the negative of the probability flux. The problem specifies natural boundary conditions at $\\pm \\infty$, which implies that the probability density and its derivative vanish at infinity (i.e., $\\pi(r) \\to 0$ and $\\frac{\\mathrm{d}\\pi(r)}{\\mathrm{d}r} \\to 0$ as $r \\to \\pm\\infty$). This forces the constant of integration $C$ to be zero. Setting $C=0$, we obtain a first-order separable ODE for $\\pi(r)$:\n$$\n\\kappa(\\theta - r) \\pi(r) = \\frac{\\sigma^2}{2} \\frac{\\mathrm{d}\\pi(r)}{\\mathrm{d}r}\n$$\nWe can separate variables to solve for $\\pi(r)$:\n$$\n\\frac{\\mathrm{d}\\pi(r)}{\\pi(r)} = \\frac{2\\kappa}{\\sigma^2}(\\theta-r)\\mathrm{d}r\n$$\nIntegrating both sides:\n$$\n\\int \\frac{1}{\\pi(r)}\\mathrm{d}\\pi(r) = \\int \\frac{2\\kappa}{\\sigma^2}(\\theta-r)\\mathrm{d}r\n$$\n$$\n\\ln(\\pi(r)) = \\frac{2\\kappa}{\\sigma^2} \\left( \\theta r - \\frac{r^2}{2} \\right) + K\n$$\nwhere $K$ is the constant of integration. We can rewrite the expression in the exponent by completing the square:\n$$\n\\ln(\\pi(r)) = -\\frac{\\kappa}{\\sigma^2} (r^2 - 2\\theta r) + K = -\\frac{\\kappa}{\\sigma^2} ((r - \\theta)^2 - \\theta^2) + K = -\\frac{\\kappa}{\\sigma^2} (r - \\theta)^2 + \\frac{\\kappa\\theta^2}{\\sigma^2} + K\n$$\nExponentiating both sides gives the unnormalized density function:\n$$\n\\pi(r) = \\exp\\left(-\\frac{\\kappa}{\\sigma^2} (r - \\theta)^2 + \\frac{\\kappa\\theta^2}{\\sigma^2} + K\\right) = C \\exp\\left(-\\frac{\\kappa}{\\sigma^2} (r - \\theta)^2\\right)\n$$\nwhere $C$ is a normalization constant. This functional form is that of a Gaussian (Normal) distribution. The standard probability density function for a Normal distribution $\\mathcal{N}(\\mu_{dist}, \\sigma_{dist}^2)$ is:\n$$\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_{dist}^2}} \\exp\\left(-\\frac{(x - \\mu_{dist})^2}{2\\sigma_{dist}^2}\\right)\n$$\nBy comparing the exponent of our derived $\\pi(r)$ with the standard form, we can identify the mean and variance of the stationary distribution.\nThe mean is immediately identified by inspection as $\\mu_{dist} = \\theta$.\nTo find the variance, we equate the coefficients of the quadratic term in the exponent:\n$$\n\\frac{1}{2\\sigma_{dist}^2} = \\frac{\\kappa}{\\sigma^2} \\implies \\sigma_{dist}^2 = \\frac{\\sigma^2}{2\\kappa}\n$$\nTherefore, the stationary distribution of the Vasicek process is a Normal distribution with mean $\\theta$ and variance $\\frac{\\sigma^2}{2\\kappa}$:\n$$\nr_t \\xrightarrow{d} \\mathcal{N}\\left(\\theta, \\frac{\\sigma^2}{2\\kappa}\\right) \\quad \\text{as } t \\to \\infty\n$$\nThe stationary probability density function $\\pi(r)$ is the PDF of this Normal distribution. By substituting the derived mean and variance into the standard Normal PDF formula, we obtain the normalized density:\n$$\n\\pi(r) = \\frac{1}{\\sqrt{2\\pi \\left(\\frac{\\sigma^2}{2\\kappa}\\right)}} \\exp\\left(-\\frac{(r - \\theta)^2}{2\\left(\\frac{\\sigma^2}{2\\kappa}\\right)}\\right) = \\frac{1}{\\sqrt{\\frac{\\pi\\sigma^2}{\\kappa}}} \\exp\\left(-\\frac{\\kappa(r - \\theta)^2}{\\sigma^2}\\right) = \\sqrt{\\frac{\\kappa}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\kappa(r - \\theta)^2}{\\sigma^2}\\right)\n$$\nThe problem asks for the stationary probability density function $\\pi(r)$, its mean, and its variance. Based on the rigorous derivation from the Kolmogorov forward equation, these are:\n1.  Stationary PDF: $\\pi(r) = \\sqrt{\\frac{\\kappa}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\kappa(r - \\theta)^2}{\\sigma^2}\\right)$\n2.  Mean of the stationary distribution: $\\mathbb{E}[r_\\infty] = \\theta$\n3.  Variance of the stationary distribution: $\\mathrm{Var}(r_\\infty) = \\frac{\\sigma^2}{2\\kappa}$\nThese results are now compiled into the required final answer format.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sqrt{\\frac{\\kappa}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\kappa(r - \\theta)^2}{\\sigma^2}\\right)  \\theta  \\frac{\\sigma^2}{2\\kappa}\n\\end{pmatrix}\n}\n$$", "id": "3074338"}, {"introduction": "Analytical solutions are powerful, but many real-world financial problems require numerical methods for valuation. This advanced practice ([@problem_id:3074299]) bridges theory and computational finance, challenging you to price a zero-coupon bond using the Euler-Maruyama scheme, a fundamental algorithm for simulating SDEs. A key insight of this problem is that for Gaussian models like Vasicek, expectations of discretized paths can often be computed deterministically, allowing for a precise analysis of numerical error without Monte Carlo simulation. By implementing a program to calculate the bond price and analyze its error, you will gain hands-on experience in assessing the accuracy of a numerical scheme and controlling its discretization bias, a critical skill in quantitative finance.", "problem": "Consider a risk-neutral short-rate model where the instantaneous short rate $r_t$ follows the Vasicek stochastic differential equation (SDE): \n$$\ndr_t = \\kappa \\left(\\theta - r_t\\right)\\,dt + \\sigma\\, dW_t,\n$$\nwhere $\\kappa  0$ is the mean-reversion speed, $\\theta$ is the long-run level, $\\sigma \\ge 0$ is the volatility, and $W_t$ is a standard Brownian motion. The time-$0$ price of a zero-coupon bond maturing at time $T$ is by definition\n$$\nP(0,T) \\equiv \\mathbb{E}\\left[\\exp\\left(-\\int_0^T r_s\\,ds\\right)\\right],\n$$\nwith the expectation taken under the risk-neutral measure. \n\nA common numerical approach approximates the integral by a left Riemann sum on an equispaced grid of $N$ steps of width $\\Delta \\equiv T/N$. The Euler-Maruyama discretization for $r_t$ on the grid points $t_n = n\\Delta$ is\n$$\nr_{n+1} = r_n + \\kappa\\left(\\theta - r_n\\right)\\Delta + \\sigma \\sqrt{\\Delta}\\, Z_n,\\quad n=0,1,\\dots,N-1,\n$$\nwith $r_0$ given and $\\{Z_n\\}$ independent standard normal random variables. Define the discrete-time approximation of the time integral by\n$$\nS_\\Delta \\equiv \\Delta \\sum_{n=0}^{N-1} r_n,\n$$\nand the corresponding Euler-based bond price approximation by\n$$\nP_\\Delta(0,T) \\equiv \\mathbb{E}\\left[\\exp\\left(-S_\\Delta\\right)\\right].\n$$\nThe discretization bias at step size $\\Delta$ is the difference \n$$\n\\mathrm{bias}_\\Delta \\equiv P_\\Delta(0,T) - P(0,T).\n$$\n\nYour task is to write a deterministic program (no Monte Carlo sampling) that:\n- Computes the absolute discretization bias $\\left|\\mathrm{bias}_\\Delta\\right|$ for a given $\\Delta$,\n- Estimates the weak convergence order $p$ and leading constant $C$ from two step sizes $\\Delta$ and $\\Delta/2$ using only logically justified, fundamental properties of the model and Gaussian processes, and\n- Proposes the largest time step $h$ of the form $h = T/N$ with integer $N \\ge 1$ such that the predicted absolute bias at step size $h$ is guaranteed to be less than or equal to a given absolute tolerance $\\varepsilon$, under the standard power-law assumption for the weak error, i.e., $\\left|P_h(0,T) - P(0,T)\\right| \\approx C\\, h^p$.\n\nScientific and algorithmic requirements:\n- Work from first principles that are appropriate for linear Gaussian systems. Your program must be fully deterministic: do not use any random sampling.\n- You may assume that $P(0,T)$ is available in closed form for the Vasicek model, but the problem statement does not provide any such formula. Your derivation should be grounded in core definitions and well-tested facts about affine term structures and normal distributions.\n- Ensure that $\\Delta$ divides $T$, i.e., $N = T/\\Delta$ is an integer. Use both $\\Delta$ and $\\Delta/2$ (which also divides $T$) to estimate the observed convergence order $p$ and a conservative leading constant $C$. Then pick \n$$\nh_{\\max} \\equiv \\left(\\frac{\\varepsilon}{C}\\right)^{1/p},\n$$\nand return the largest grid step of the form $T/N$ not exceeding $h_{\\max}$, i.e., with $N = \\lceil T/h_{\\max} \\rceil$ and $h = T/N$.\n- If the estimation yields $C=0$ (within machine precision), you may return $h = T$.\n\nTest suite:\nFor each tuple $(\\kappa,\\theta,\\sigma,r_0,T,\\Delta,\\varepsilon)$ below, compute and return two numbers: the absolute discretization bias at $\\Delta$, i.e., $\\left|P_\\Delta(0,T) - P(0,T)\\right|$, and the recommended step size $h$ described above.\n\nUse the following parameter sets, each tuple in the order $(\\kappa,\\theta,\\sigma,r_0,T,\\Delta,\\varepsilon)$:\n- Test $1$: $(0.5,\\,0.04,\\,0.01,\\,0.03,\\,5.0,\\,0.25,\\,10^{-5})$\n- Test $2$: $(1.2,\\,0.03,\\,0.02,\\,0.02,\\,1.0,\\,0.2,\\,5\\times 10^{-5})$\n- Test $3$: $(0.1,\\,0.05,\\,0.015,\\,0.08,\\,10.0,\\,1.0,\\,10^{-4})$\n- Test $4$: $(0.7,\\,0.05,\\,0.03,\\,0.05,\\,0.25,\\,0.25,\\,10^{-5})$\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s output must be a two-element list in the order $[\\left|\\mathrm{bias}_\\Delta\\right|, h]$. For example, a valid output line with two hypothetical cases would be \n$[[0.00123,0.05],[0.00001,0.1]]$.", "solution": "The problem requires a deterministic computation of the discretization bias for the Euler-Maruyama approximation of a Vasicek bond price, and then using this to estimate convergence parameters and a suitable time step for a given error tolerance. This task is to be completed without using any Monte Carlo simulations. The approach must be based on the analytical properties of the Vasicek model, which, being a linear Gaussian process, allows for exact calculation of expectations involving its states.\n\nThe analysis proceeds in four main steps:\n1.  Derive the closed-form expression for the exact zero-coupon bond price, $P(0,T)$.\n2.  Derive the closed-form expression for the bond price under the Euler-Maruyama approximation, $P_\\Delta(0,T)$.\n3.  Use the derived expressions to calculate the discretization bias for two different step sizes, $\\Delta$ and $\\Delta/2$, and estimate the weak convergence order $p$ and constant $C$.\n4.  Use the estimated convergence parameters to recommend a maximum step size $h$ that meets the error tolerance $\\varepsilon$.\n\n### Step 1: Analytical Bond Price $P(0,T)$\n\nThe Vasicek short-rate model is an affine term-structure model. This means the time-$t$ price of a zero-coupon bond maturing at $T$, $P(t,T)$, is an exponential-affine function of the short rate $r_t$:\n$$\nP(t,T) = \\exp\\left(A(t,T) - B(t,T)r_t\\right)\n$$\nThe functions $A(t,T)$ and $B(t,T)$ are deterministic and can be found by solving a system of ordinary differential equations (ODEs) derived from the no-arbitrage condition that the bond's expected return equals the short rate. The solutions to these ODEs with boundary conditions $A(T,T)=0$ and $B(T,T)=0$ are well-known:\n$$\nB(t,T) = \\frac{1}{\\kappa}\\left(1 - e^{-\\kappa(T-t)}\\right)\n$$\n$$\nA(t,T) = \\left(\\theta - \\frac{\\sigma^2}{2\\kappa^2}\\right)\\left(B(t,T) - (T-t)\\right) - \\frac{\\sigma^2}{4\\kappa}B(t,T)^2\n$$\nFor the time-$0$ price, we set $t=0$:\n$$\nP(0,T) = \\exp\\left(A(0,T) - B(0,T)r_0\\right)\n$$\nwhere\n$$\nB(0,T) = \\frac{1}{\\kappa}\\left(1 - e^{-\\kappa T}\\right)\n$$\n$$\nA(0,T) = \\left(\\theta - \\frac{\\sigma^2}{2\\kappa^2}\\right)\\left(B(0,T) - T\\right) - \\frac{\\sigma^2}{4\\kappa}B(0,T)^2\n$$\nThese formulas allow for the direct, deterministic computation of the true bond price.\n\n### Step 2: Approximate Bond Price $P_\\Delta(0,T)$\n\nThe approximate bond price is defined as $P_\\Delta(0,T) \\equiv \\mathbb{E}\\left[\\exp\\left(-S_\\Delta\\right)\\right]$, where $S_\\Delta = \\Delta \\sum_{n=0}^{N-1} r_n$ and $r_n$ follows the Euler-Maruyama discretization:\n$$\nr_{n+1} = (1-\\kappa\\Delta)r_n + \\kappa\\theta\\Delta + \\sigma\\sqrt{\\Delta}Z_n, \\quad Z_n \\sim \\mathcal{N}(0,1)\n$$\nSince this is a linear recurrence driven by Gaussian noise, the vector of rates $[r_0, r_1, \\dots, r_{N-1}]$ is a multivariate Gaussian process. Their sum, $S_\\Delta$, is therefore a Gaussian random variable. The expectation $\\mathbb{E}\\left[\\exp(-S_\\Delta)\\right]$ can be calculated using the moment-generating function of a normal distribution. If $S_\\Delta \\sim \\mathcal{N}(\\mu_{S_\\Delta}, \\sigma^2_{S_\\Delta})$, then:\n$$\nP_\\Delta(0,T) = \\exp\\left(-\\mu_{S_\\Delta} + \\frac{1}{2}\\sigma^2_{S_\\Delta}\\right)\n$$\nOur task reduces to finding the mean $\\mu_{S_\\Delta}$ and variance $\\sigma^2_{S_\\Delta}$ of $S_\\Delta$.\n\n**Mean of $S_\\Delta$**:\nThe expectation $\\mu_n = \\mathbb{E}[r_n]$ follows the recurrence $\\mu_{n+1} = (1-\\kappa\\Delta)\\mu_n + \\kappa\\theta\\Delta$, with $\\mu_0=r_0$. The solution is $\\mu_n = (r_0 - \\theta)(1-\\kappa\\Delta)^n + \\theta$.\nThe mean of $S_\\Delta$ is $\\mu_{S_\\Delta} = \\mathbb{E}\\left[\\Delta \\sum_{n=0}^{N-1} r_n\\right] = \\Delta \\sum_{n=0}^{N-1} \\mu_n$. Summing the geometric series yields:\n$$\n\\mu_{S_\\Delta} = (r_0 - \\theta)\\frac{1-(1-\\kappa\\Delta)^N}{\\kappa} + T\\theta \\quad (\\text{since } N\\Delta=T)\n$$\n\n**Variance of $S_\\Delta$**:\nLet $r'_n = r_n - \\mu_n$. The variance of $S_\\Delta$ is $\\sigma^2_{S_\\Delta} = \\mathrm{Var}\\left(\\Delta \\sum_{n=0}^{N-1} r_n\\right) = \\Delta^2 \\mathrm{Var}\\left(\\sum_{n=0}^{N-1} r'_n\\right)$.\nThe centered process follows $r'_{n+1} = (1-\\kappa\\Delta)r'_n + \\sigma\\sqrt{\\Delta}Z_n$, with $r'_0=0$.\nBy unrolling the recurrence, we can express $\\sum r'_n$ as a linear combination of the i.i.d. standard normal variables $\\{Z_k\\}_{k=0}^{N-2}$.\n$$\n\\sum_{n=0}^{N-1} r'_n = \\sum_{n=1}^{N-1} \\sum_{k=0}^{n-1} \\sigma\\sqrt{\\Delta}(1-\\kappa\\Delta)^{n-1-k} Z_k\n$$\nBy changing the order of summation, this becomes $\\sum_{k=0}^{N-2} c_k Z_k$ for some coefficients $c_k$. The variance is $\\sum c_k^2$. After algebraic simplification, the variance of $S_\\Delta$ is found to be:\n$$\n\\sigma^2_{S_\\Delta} = \\frac{\\Delta\\sigma^2}{\\kappa^2}\\left( (N-1) - 2S_1 + S_2 \\right)\n$$\nwhere $a = 1-\\kappa\\Delta$ and $S_1, S_2$ are sums of geometric series:\n$$\nS_1 = \\sum_{j=1}^{N-1} a^j = a \\frac{1-a^{N-1}}{1-a}\n$$\n$$\nS_2 = \\sum_{j=1}^{N-1} (a^2)^j = a^2 \\frac{1-a^{2(N-1)}}{1-a^2}\n$$\nWith these closed-form expressions for $\\mu_{S_\\Delta}$ and $\\sigma^2_{S_\\Delta}$, $P_\\Delta(0,T)$ can be computed deterministically.\n\n### Step 3: Estimating Convergence Parameters\n\nThe weak error is assumed to follow a power law: $|\\mathrm{bias}_h| = |P_h(0,T) - P(0,T)| \\approx C h^p$.\nGiven two step sizes, $\\Delta$ and $\\Delta/2$, we can write:\n$$\n\\mathrm{bias}_{\\Delta} \\approx C \\Delta^p\n$$\n$$\n\\mathrm{bias}_{\\Delta/2} \\approx C (\\Delta/2)^p\n$$\nTaking the ratio gives an estimate for the convergence order $p$:\n$$\n\\frac{\\mathrm{bias}_{\\Delta}}{\\mathrm{bias}_{\\Delta/2}} \\approx 2^p \\implies p \\approx \\log_2\\left(\\frac{\\mathrm{bias}_{\\Delta}}{\\mathrm{bias}_{\\Delta/2}}\\right)\n$$\nFor robustness, especially if the error term oscillates, it is safer to use absolute values: $p \\approx \\log_2\\left(|\\mathrm{bias}_{\\Delta}| / |\\mathrm{bias}_{\\Delta/2}|\\right)$. For the Euler-Maruyama scheme applied to this SDE, we expect $p \\approx 1$.\nOnce $p$ is estimated, the constant $C$ can be found using the more accurate result from the smaller step size:\n$$\nC \\approx \\frac{|\\mathrm{bias}_{\\Delta/2}|}{(\\Delta/2)^p}\n$$\n\n### Step 4: Recommending a Step Size\n\nWe seek the largest step size $h$ of the form $h=T/N$ (for integer $N \\ge 1$) such that the predicted absolute bias is at most $\\varepsilon$.\n$$\nC h^p \\le \\varepsilon \\implies h \\le \\left(\\frac{\\varepsilon}{C}\\right)^{1/p}\n$$\nLet $h_{\\max} = (\\varepsilon/C)^{1/p}$. We need to find the largest $h = T/N$ that does not exceed $h_{\\max}$.\n$$\n\\frac{T}{N} \\le h_{\\max} \\implies N \\ge \\frac{T}{h_{\\max}}\n$$\nSince $N$ must be an integer, the minimal integer $N$ satisfying this is $N = \\lceil T/h_{\\max} \\rceil$. The required step size is then $h = T/N$. If the estimated constant $C$ is zero (or numerically indistinguishable from it), the bias is considered negligible for any step size, and we can take $h=T$ (i.e., $N=1$).\n\nThe implementation will utilize numerically stable functions like `numpy.expm1` and `numpy.log1p` to handle potential cancellation errors when arguments to exponentials or logarithms are close to $0$ or $1$, respectively. This is particularly relevant for expressions like $1-e^{-x}$ or $1-a^k$ when $x$ or $k\\ln(a)$ are small.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    For each test case, it computes the absolute discretization bias and a recommended step size.\n    \"\"\"\n    \n    test_cases = [\n        (0.5, 0.04, 0.01, 0.03, 5.0, 0.25, 1e-5),\n        (1.2, 0.03, 0.02, 0.02, 1.0, 0.2, 5e-5),\n        (0.1, 0.05, 0.015, 0.08, 10.0, 1.0, 1e-4),\n        (0.7, 0.05, 0.03, 0.05, 0.25, 0.25, 1e-5),\n    ]\n\n    results = []\n    for case in test_cases:\n        kappa, theta, sigma, r0, T, delta, eps = case\n        \n        # --- Analytical Bond Price P(0,T) ---\n        # Using numerically stable expm1(x) = exp(x) - 1\n        B_0T = -np.expm1(-kappa * T) / kappa\n        A_0T = (theta - sigma**2 / (2 * kappa**2)) * (B_0T - T) - \\\n               (sigma**2 / (4 * kappa)) * B_0T**2\n        P_exact = np.exp(A_0T - B_0T * r0)\n        \n        # --- Helper function for Approximate Bond Price P_h(0,T) ---\n        def get_approx_price(h):\n            \"\"\"\n            Calculates the approximate bond price for a given step size h\n            using the derived deterministic formula.\n            \"\"\"\n            N = int(round(T / h))\n            if N == 0: return 1.0 # T=0 case\n            \n            # Use numerically stable log1p(x) = log(1+x) and expm1(x)\n            a = 1.0 - kappa * h\n            log_a = np.log1p(-kappa * h)\n            \n            # Mean of S_h\n            # The term (1-a^N) / kappa can be simplified\n            term = -np.expm1(N * log_a) / kappa\n            mu_Sh = (r0 - theta) * term + T * theta\n\n            # Variance of S_h\n            if N == 1:\n                # Sum from j=1 to 0 is empty. S1=0, S2=0.\n                sigma2_Sh = 0.0\n            else:\n                one_minus_a_inv = 1.0 / (kappa * h)\n                \n                sum1_term = -np.expm1((N - 1) * log_a)\n                S1 = a * sum1_term * one_minus_a_inv\n\n                one_minus_a2_inv = 1.0 / (h * (2 * kappa - kappa**2 * h))\n                sum2_term = -np.expm1(2 * (N-1) * log_a)\n                S2 = a**2 * sum2_term * one_minus_a2_inv\n                \n                sigma2_Sh = (h * sigma**2 / kappa**2) * ((N-1) - 2 * S1 + S2)\n\n            return np.exp(-mu_Sh + 0.5 * sigma2_Sh)\n\n        # --- Calculate biases for delta and delta/2 ---\n        P_delta = get_approx_price(delta)\n        P_delta_half = get_approx_price(delta / 2.0)\n\n        bias_delta = P_delta - P_exact\n        bias_delta_half = P_delta_half - P_exact\n\n        abs_bias_delta = np.abs(bias_delta)\n        \n        # --- Estimate convergence parameters p and C ---\n        if np.abs(bias_delta_half)  1e-16 or np.abs(bias_delta)  1e-16:\n             # If bias is already tiny, C is effectively zero.\n            C = 0.0\n            p = 1.0 # Assume default order\n        else:\n            # Use absolute values for robustness in case of sign change\n            ratio = np.abs(bias_delta) / np.abs(bias_delta_half)\n            # If ratio is = 1, the convergence assumption is failing.\n            # Fallback to p=1, the theoretical order.\n            if ratio = 1.0:\n                p = 1.0\n            else:\n                p = np.log2(ratio)\n            \n            C = np.abs(bias_delta_half) / ((delta / 2.0)**p)\n            \n        # --- Calculate recommended step size h ---\n        if C  1e-15:\n            # If C is negligible, error is always below tolerance.\n            # Largest allowed step size is T (N=1).\n            h = T\n        else:\n            h_max = (eps / C)**(1.0 / p)\n            if h_max  T:\n                # If required h is larger than T, N would be  1. Smallest N is 1.\n                N_new = 1\n            else:\n                N_new = np.ceil(T / h_max)\n            \n            h = T / N_new\n\n        results.append([abs_bias_delta, h])\n\n    # Final print statement in the exact required format.\n    # str().replace(\" \", \"\") produces the required compact format.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3074299"}]}