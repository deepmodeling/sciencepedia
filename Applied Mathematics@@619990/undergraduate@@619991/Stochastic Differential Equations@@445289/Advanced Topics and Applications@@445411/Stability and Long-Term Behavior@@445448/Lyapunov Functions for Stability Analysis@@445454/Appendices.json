{"hands_on_practices": [{"introduction": "This first exercise provides a foundational entry point into stochastic stability analysis. We begin with the simplest non-trivial stochastic differential equation, the geometric Brownian motion, which models countless phenomena from stock prices to population dynamics. By analyzing a system that is stable in the absence of noise ($a \\lt 0$), you will use a quadratic Lyapunov function to determine the precise threshold of noise intensity the system can withstand before becoming unstable in the mean-square sense. This practice directly connects the abstract Lyapunov method to a tangible and critical question about system robustness [@problem_id:3064628].", "problem": "Consider the scalar linear stochastic differential equation (SDE), in the sense of Itô, given by\n$$\ndX_{t} = a\\,X_{t}\\,dt + b\\,X_{t}\\,dW_{t},\n$$\nwhere $a \\in \\mathbb{R}$ is a constant drift coefficient, $b \\in \\mathbb{R}$ is a constant diffusion (noise) coefficient, and $W_{t}$ is a standard Wiener process (Brownian motion). Assume $a<0$ and interpret the equilibrium at $x=0$ as the origin. Using the Lyapunov function method and fundamental definitions from stochastic stability theory, determine the largest allowable noise intensity $\\|B\\|$, where in this scalar setting $\\|B\\|=|b|$, such that the origin is mean-square stable, meaning $\\mathbb{E}[|X_{t}|^{2}] \\to 0$ as $t \\to \\infty$ for any square-integrable initial condition $X_{0}$. Express your final answer as a closed-form analytic expression in terms of $a$. Do not approximate.", "solution": "We begin from the definition of mean-square stability for the equilibrium at $x=0$: the equilibrium is mean-square stable if for any square-integrable initial condition $X_{0}$, one has $\\mathbb{E}[|X_{t}|^{2}] \\to 0$ as $t \\to \\infty$. A standard approach is to use a Lyapunov function. For a scalar linear system, a natural choice is the quadratic Lyapunov function\n$$\nV(x) = x^{2}.\n$$\nWe use Itô's formula for the function $V$ applied to the process $X_{t}$ satisfying $dX_{t} = a X_{t} dt + b X_{t} dW_{t}$. The derivatives of $V$ are $V'(x) = 2x$ and $V''(x) = 2$. Itô's formula yields\n$$\ndV(X_{t}) = V'(X_{t})\\,dX_{t} + \\frac{1}{2} V''(X_{t})\\,(dX_{t})^{2}.\n$$\nSubstituting $dX_{t} = a X_{t} dt + b X_{t} dW_{t}$ and using $(dW_{t})^{2} = dt$, we obtain\n\\begin{align*}\nd(X_{t}^{2})\n&= 2 X_{t} \\left( a X_{t} dt + b X_{t} dW_{t} \\right) + \\frac{1}{2} \\cdot 2 \\cdot \\left( b^{2} X_{t}^{2} dt \\right) \\\\\n&= \\left( 2 a X_{t}^{2} + b^{2} X_{t}^{2} \\right) dt + 2 b X_{t}^{2} dW_{t} \\\\\n&= \\left( 2 a + b^{2} \\right) X_{t}^{2} dt + 2 b X_{t}^{2} dW_{t}.\n\\end{align*}\nTaking expectations and using that the stochastic integral has zero mean, we find\n$$\n\\frac{d}{dt} \\mathbb{E}\\left[ X_{t}^{2} \\right] = \\left( 2 a + b^{2} \\right) \\mathbb{E}\\left[ X_{t}^{2} \\right].\n$$\nThis is a linear ordinary differential equation for $\\mathbb{E}[X_{t}^{2}]$ with solution\n$$\n\\mathbb{E}\\left[ X_{t}^{2} \\right] = \\mathbb{E}\\left[ X_{0}^{2} \\right] \\exp\\!\\left( \\left( 2 a + b^{2} \\right) t \\right).\n$$\nThe condition for mean-square stability, namely $\\mathbb{E}[X_{t}^{2}] \\to 0$ as $t \\to \\infty$, is therefore\n$$\n2 a + b^{2} < 0.\n$$\nGiven the assumption $a<0$, this inequality is equivalent to\n$$\nb^{2} < - 2 a \\quad \\Longleftrightarrow \\quad |b| < \\sqrt{ - 2 a }.\n$$\nThus, the largest allowable noise intensity norm in the scalar setting, where $\\|B\\| = |b|$, is the threshold value\n$$\n\\sqrt{ - 2 a }.\n$$\nThis value is sharp: if $|b| = \\sqrt{ - 2 a }$, then $\\mathbb{E}[X_{t}^{2}]$ remains constant in time and does not decay to zero, and if $|b| > \\sqrt{ - 2 a }$, the second moment grows exponentially. Therefore, the maximal allowable noise intensity ensuring mean-square stability is $\\sqrt{ - 2 a }$.", "answer": "$$\\boxed{\\sqrt{-2a}}$$", "id": "3064628"}, {"introduction": "Building upon the concept of mean-square stability, this problem explores a deeper and more subtle aspect of stochastic systems. It is possible for almost every trajectory of a system to converge to zero, while its statistical moments, like the mean square, diverge to infinity. This practice guides you to uncover this fascinating distinction by using two different Lyapunov functions to probe two different modes of stability for the very same SDE we analyzed before. By deriving and comparing the conditions for almost sure stability and mean-square stability, you will gain a crucial insight into the nuanced nature of stability in a stochastic world [@problem_id:3064647].", "problem": "Consider the scalar Itô Stochastic Differential Equation (SDE) $$dX_{t}=a\\,X_{t}\\,dt+b\\,X_{t}\\,dW_{t}, \\qquad X_{0}\\neq 0,$$ where $a\\in\\mathbb{R}$ and $b\\in\\mathbb{R}$ are constants, and $(W_{t})_{t\\ge 0}$ is a standard Brownian motion. Using Lyapunov functions and starting only from the definitions of the infinitesimal generator and Itô’s formula, do the following:\n- Using the Lyapunov function $V_{1}(x)=\\ln(x^{2})$, derive the almost sure (a.s.) Lyapunov exponent $$\\lambda_{\\mathrm{as}}:=\\lim_{t\\to\\infty}\\frac{1}{t}\\ln|X_{t}| \\quad \\text{a.s.}$$\n- Using the Lyapunov function $V_{2}(x)=x^{2}$, derive the exponential rate $$\\kappa_{2}:=\\lim_{t\\to\\infty}\\frac{1}{t}\\ln\\mathbb{E}[X_{t}^{2}].$$\nThen, compare the sign conditions on $a$ and $b$ under which $|X_{t}|$ decays to zero almost surely and under which $\\mathbb{E}[X_{t}^{2}]$ decays exponentially. For grading, report only the pair $(\\lambda_{\\mathrm{as}},\\kappa_{2})$ as a single row matrix. No numerical rounding is required, and no units are involved. Express your final answer in closed form in terms of $a$ and $b$.", "solution": "We are given the scalar Itô Stochastic Differential Equation (SDE) for a process $(X_{t})_{t\\ge 0}$:\n$$dX_{t}=a\\,X_{t}\\,dt+b\\,X_{t}\\,dW_{t}, \\qquad X_{0}\\neq 0$$\nwhere $a$ and $b$ are real constants and $W_{t}$ is a standard Brownian motion. This is a linear SDE, often referred to as geometric Brownian motion. The drift coefficient is $f(x)=ax$ and the diffusion coefficient is $g(x)=bx$.\n\nThe infinitesimal generator $\\mathcal{L}$ of the Itô process $X_{t}$, when applied to a twice-differentiable function $V(x)$, is defined as:\n$$\\mathcal{L}V(x) = f(x)\\frac{dV}{dx} + \\frac{1}{2}g(x)^{2}\\frac{d^{2}V}{dx^{2}}$$\nFor our specific SDE, this becomes:\n$$\\mathcal{L}V(x) = (ax)\\frac{dV}{dx} + \\frac{1}{2}(bx)^{2}\\frac{d^{2}V}{dx^{2}}$$\nItô's formula for a function $V(X_{t})$ states that:\n$$dV(X_{t}) = \\mathcal{L}V(X_{t})\\,dt + \\frac{dV}{dx}(X_{t})g(X_{t})\\,dW_{t}$$\n\nWe will now apply this framework to the two specified Lyapunov functions.\n\n**Part 1: Derivation of the Almost Sure Lyapunov Exponent $\\lambda_{\\mathrm{as}}$**\n\nWe use the Lyapunov function $V_{1}(x) = \\ln(x^{2})$. Note that since $X_{0} \\neq 0$, the solution $X_{t}$ almost surely never reaches $0$, so $V_{1}(X_{t})$ is well-defined for all $t > 0$. The derivatives of $V_{1}(x)$ are:\n$$\\frac{dV_{1}}{dx} = \\frac{d}{dx}(\\ln(x^{2})) = \\frac{1}{x^{2}}(2x) = \\frac{2}{x}$$\n$$\\frac{d^{2}V_{1}}{dx^{2}} = \\frac{d}{dx}\\left(\\frac{2}{x}\\right) = -\\frac{2}{x^{2}}$$\nNow, we compute the action of the infinitesimal generator $\\mathcal{L}$ on $V_{1}(x)$:\n$$\\mathcal{L}V_{1}(x) = (ax)\\left(\\frac{2}{x}\\right) + \\frac{1}{2}(bx)^{2}\\left(-\\frac{2}{x^{2}}\\right)$$\n$$\\mathcal{L}V_{1}(x) = 2a + \\frac{1}{2}b^{2}x^{2}\\left(-\\frac{2}{x^{2}}\\right) = 2a - b^{2}$$\nThe result is a constant. We now apply Itô's formula to $V_{1}(X_{t})$:\n$$dV_{1}(X_{t}) = \\mathcal{L}V_{1}(X_{t})\\,dt + \\frac{dV_{1}}{dx}(X_{t})g(X_{t})\\,dW_{t}$$\n$$d(\\ln(X_{t}^{2})) = (2a - b^{2})\\,dt + \\left(\\frac{2}{X_{t}}\\right)(bX_{t})\\,dW_{t}$$\n$$d(\\ln(X_{t}^{2})) = (2a - b^{2})\\,dt + 2b\\,dW_{t}$$\nIntegrating both sides from $t=0$ to an arbitrary $t > 0$:\n$$\\int_{0}^{t} d(\\ln(X_{s}^{2})) = \\int_{0}^{t} (2a - b^{2})\\,ds + \\int_{0}^{t} 2b\\,dW_{s}$$\n$$\\ln(X_{t}^{2}) - \\ln(X_{0}^{2}) = (2a - b^{2})t + 2bW_{t}$$\n$$\\ln(X_{t}^{2}) = \\ln(X_{0}^{2}) + (2a - b^{2})t + 2bW_{t}$$\nUsing the property $\\ln(x^{2})=2\\ln|x|$, we get:\n$$2\\ln|X_{t}| = 2\\ln|X_{0}| + (2a - b^{2})t + 2bW_{t}$$\nTo find the Lyapunov exponent, we divide by $t$ and take the limit as $t \\to \\infty$:\n$$\\frac{1}{t}\\ln|X_{t}| = \\frac{1}{t}\\ln|X_{0}| + \\frac{1}{2}(2a - b^{2}) + \\frac{bW_{t}}{t}$$\nBy the Law of the Iterated Logarithm for Brownian motion, we know that $\\lim_{t\\to\\infty} \\frac{W_{t}}{t} = 0$ almost surely (a.s.). The first term also vanishes: $\\lim_{t\\to\\infty} \\frac{\\ln|X_{0}|}{t} = 0$.\nTherefore, taking the limit yields the almost sure Lyapunov exponent:\n$$\\lambda_{\\mathrm{as}} := \\lim_{t\\to\\infty}\\frac{1}{t}\\ln|X_{t}| = \\frac{1}{2}(2a - b^{2}) = a - \\frac{b^{2}}{2} \\quad \\text{a.s.}$$\n\n**Part 2: Derivation of the Exponential Rate $\\kappa_{2}$**\n\nWe use the Lyapunov function $V_{2}(x) = x^{2}$. The derivatives are:\n$$\\frac{dV_{2}}{dx} = 2x$$\n$$\\frac{d^{2}V_{2}}{dx^{2}} = 2$$\nWe compute the action of $\\mathcal{L}$ on $V_{2}(x)$:\n$$\\mathcal{L}V_{2}(x) = (ax)(2x) + \\frac{1}{2}(bx)^{2}(2) = 2ax^{2} + b^{2}x^{2} = (2a + b^{2})x^{2}$$\nApplying Itô's formula to $V_{2}(X_{t})$:\n$$dV_{2}(X_{t}) = \\mathcal{L}V_{2}(X_{t})\\,dt + \\frac{dV_{2}}{dx}(X_{t})g(X_{t})\\,dW_{t}$$\n$$dX_{t}^{2} = (2a + b^{2})X_{t}^{2}\\,dt + (2X_{t})(bX_{t})\\,dW_{t}$$\n$$dX_{t}^{2} = (2a + b^{2})X_{t}^{2}\\,dt + 2bX_{t}^{2}\\,dW_{t}$$\nTo find the evolution of the second moment, $\\mathbb{E}[X_{t}^{2}]$, we take the expectation of the integral form of the above SDE:\n$$\\mathbb{E}[X_{t}^{2}] - \\mathbb{E}[X_{0}^{2}] = \\mathbb{E}\\left[\\int_{0}^{t} (2a + b^{2})X_{s}^{2}\\,ds\\right] + \\mathbb{E}\\left[\\int_{0}^{t} 2bX_{s}^{2}\\,dW_{s}\\right]$$\nThe expectation of the stochastic integral term is zero, i.e., $\\mathbb{E}\\left[\\int_{0}^{t} 2bX_{s}^{2}\\,dW_{s}\\right] = 0$. By Fubini's theorem, we can swap expectation and integration for the drift term. Let $m_{2}(t) = \\mathbb{E}[X_{t}^{2}]$. The equation becomes:\n$$m_{2}(t) - m_{2}(0) = \\int_{0}^{t} (2a + b^{2})m_{2}(s)\\,ds$$\nDifferentiating with respect to $t$ gives the ordinary differential equation (ODE):\n$$\\frac{d m_{2}(t)}{dt} = (2a + b^{2})m_{2}(t)$$\nThe solution to this ODE is:\n$$m_{2}(t) = m_{2}(0) \\exp((2a + b^{2})t)$$\n$$\\mathbb{E}[X_{t}^{2}] = \\mathbb{E}[X_{0}^{2}] \\exp((2a + b^{2})t)$$\nAssuming $X_{0}$ is a deterministic initial condition, $\\mathbb{E}[X_{0}^{2}] = X_{0}^{2}$. Then:\n$$\\ln(\\mathbb{E}[X_{t}^{2}]) = \\ln(X_{0}^{2}) + (2a + b^{2})t$$\nDividing by $t$ and taking the limit gives the exponential rate $\\kappa_{2}$:\n$$\\kappa_{2} := \\lim_{t\\to\\infty}\\frac{1}{t}\\ln\\mathbb{E}[X_{t}^{2}] = \\lim_{t\\to\\infty}\\left(\\frac{\\ln(X_{0}^{2})}{t} + 2a + b^{2}\\right) = 2a + b^{2}$$\n\n**Comparison of Stability Conditions**\n\n- The system is almost surely exponentially stable if $|X_{t}| \\to 0$ as $t \\to \\infty$ a.s. This requires the Lyapunov exponent to be negative:\n  $$\\lambda_{\\mathrm{as}} < 0 \\iff a - \\frac{b^{2}}{2} < 0 \\iff a < \\frac{b^{2}}{2}$$\n- The system is mean-square exponentially stable if $\\mathbb{E}[X_{t}^{2}] \\to 0$ as $t \\to \\infty$. This requires the second moment rate to be negative:\n  $$\\kappa_{2} < 0 \\iff 2a + b^{2} < 0 \\iff a < -\\frac{b^{2}}{2}$$\n\nNotice that the condition for mean-square stability ($a < -b^{2}/2$) is strictly stronger than the condition for almost sure stability ($a < b^{2}/2$), since $-b^{2}/2 \\le b^{2}/2$ for any $b\\in\\mathbb{R}$. This highlights a fundamental distinction in stochastic systems: it is possible for almost all sample paths to converge to zero while the moments (like the mean square) diverge to infinity. This occurs in the parameter region $-b^{2}/2 \\le a < b^{2}/2$. The diffusive term has a stabilizing effect on individual paths (via the Itô correction term $-b^2/2$) but a destabilizing effect on the moments.\n\nThe required output is the pair $(\\lambda_{\\mathrm{as}}, \\kappa_{2})$.\n$$\\lambda_{\\mathrm{as}} = a - \\frac{b^{2}}{2}$$\n$$\\kappa_{2} = 2a + b^{2}$$", "answer": "$$\\boxed{\\begin{pmatrix} a - \\frac{b^{2}}{2} & 2a + b^{2} \\end{pmatrix}}$$", "id": "3064647"}, {"introduction": "Our final practice demonstrates the versatility of Lyapunov functions beyond analyzing stability at an equilibrium point. Here, we confront a nonlinear system whose deterministic counterpart exhibits \"finite-time blow-up,\" meaning its solution shoots to infinity in a finite amount of time. The challenge is to show how a sufficiently strong stochastic component can tame this explosive behavior and ensure the solution exists for all time. By carefully selecting a Lyapunov function of the form $V(x)=1+|x|^p$, you will determine the precise condition under which the stabilizing effect of the Itô diffusion term dominates the destabilizing drift, thereby preventing explosion and showcasing a powerful application of the theory [@problem_id:3064635].", "problem": "Consider the one-dimensional stochastic differential equation (SDE) $$\\mathrm{d}X_{t}=\\mu X_{t}^{3}\\,\\mathrm{d}t+\\sigma X_{t}^{2}\\,\\mathrm{d}W_{t},$$ where $\\mu>0$, $\\sigma>0$, and $W_{t}$ is a standard Brownian motion. Use the infinitesimal generator of this SDE together with the concept of a Lyapunov function to rule out finite-time blow-up by ensuring that the diffusion contribution in the generator dominates the drift contribution for large $|x|$. Assume $\\sigma^{2}>2\\mu$ so that such a dominance is achievable.\n\nLet $V:\\mathbb{R}\\to\\mathbb{R}$ be given by $$V(x)=1+|x|^{p},$$ where $p>0$. Starting from the definition of the infinitesimal generator for an SDE and the basic properties of Lyapunov functions (positivity and radial unboundedness), determine the largest exponent $$p^{*}>0$$ (as a function of $\\mu$ and $\\sigma$) such that there exists $R>0$ for which $$\\mathcal{L}V(x)\\leq 0\\quad\\text{for all}\\quad |x|\\geq R.$$ Your final answer must be the closed-form expression for $p^{*}$ in terms of $\\mu$ and $\\sigma$.", "solution": "The problem requires us to determine the largest exponent $p^{*}>0$ for a Lyapunov function candidate $V(x)=1+|x|^{p}$ such that its application through the infinitesimal generator indicates non-explosive behavior for a given stochastic differential equation (SDE) for large values of the state.\n\nThe SDE is given by:\n$$ \\mathrm{d}X_{t}=\\mu X_{t}^{3}\\,\\mathrm{d}t+\\sigma X_{t}^{2}\\,\\mathrm{d}W_{t} $$\nThis is a one-dimensional Itô process of the form $\\mathrm{d}X_{t} = b(X_{t},\\,t)\\,\\mathrm{d}t + a(X_{t},\\,t)\\,\\mathrm{d}W_{t}$. By comparing the given SDE with this general form, we identify the drift coefficient $b(x)$ and the diffusion coefficient $a(x)$ as:\n$$ b(x) = \\mu x^{3} $$\n$$ a(x) = \\sigma x^{2} $$\nwhere $\\mu>0$ and $\\sigma>0$ are constants.\n\nThe infinitesimal generator $\\mathcal{L}$ of this Itô process, when applied to a twice continuously differentiable function $f:\\mathbb{R}\\to\\mathbb{R}$, is defined by:\n$$ \\mathcal{L}f(x) = b(x)\\frac{\\mathrm{d}f}{\\mathrm{d}x} + \\frac{1}{2}a(x)^{2}\\frac{\\mathrm{d}^{2}f}{\\mathrm{d}x^{2}} $$\nSubstituting the expressions for $b(x)$ and $a(x)$, we get:\n$$ \\mathcal{L}f(x) = (\\mu x^{3})\\frac{\\mathrm{d}f}{\\mathrm{d}x} + \\frac{1}{2}(\\sigma x^{2})^{2}\\frac{\\mathrm{d}^{2}f}{\\mathrm{d}x^{2}} = \\mu x^{3}f'(x) + \\frac{1}{2}\\sigma^{2}x^{4}f''(x) $$\n\nWe are given the Lyapunov function candidate $V(x) = 1 + |x|^{p}$, where $p > 0$. We need to find the largest $p^* > 0$ such that there exists a constant $R>0$ for which $\\mathcal{L}V(x) \\leq 0$ for all $|x| \\geq R$.\nThe function $V(x)$ is not twice differentiable at $x=0$ for all $p > 0$. Specifically, if $p \\in (0, 2)$, the second derivative does not exist at $x=0$. However, the condition on $\\mathcal{L}V(x)$ is required only for large $|x|$, i.e., for $|x| \\geq R$ where $R>0$. In this region, $V(x)$ is infinitely differentiable, so the application of the generator is well-defined.\n\nLet us compute the first and second derivatives of $V(x)$ for $x \\neq 0$.\nFor $x > 0$, $V(x) = 1 + x^{p}$. The derivatives are:\n$$ V'(x) = px^{p-1} $$\n$$ V''(x) = p(p-1)x^{p-2} $$\nFor $x < 0$, $V(x) = 1 + (-x)^{p}$. The derivatives are:\n$$ V'(x) = p(-x)^{p-1}(-1) = -p(-x)^{p-1} $$\n$$ V''(x) = -p(p-1)(-x)^{p-2}(-1) = p(p-1)(-x)^{p-2} $$\nWe can write these derivatives for any $x \\neq 0$ using the absolute value and the sign function $\\mathrm{sgn}(x)$:\n$$ V'(x) = p|x|^{p-1}\\mathrm{sgn}(x) $$\n$$ V''(x) = p(p-1)|x|^{p-2} $$\n\nNow, we apply the infinitesimal generator $\\mathcal{L}$ to $V(x)$ for $x \\neq 0$:\n$$ \\mathcal{L}V(x) = \\mu x^{3}V'(x) + \\frac{1}{2}\\sigma^{2}x^{4}V''(x) $$\nSubstituting the derivatives of $V(x)$:\n$$ \\mathcal{L}V(x) = \\mu x^{3}(p|x|^{p-1}\\mathrm{sgn}(x)) + \\frac{1}{2}\\sigma^{2}x^{4}(p(p-1)|x|^{p-2}) $$\nWe use the identities $x^{3}\\mathrm{sgn}(x) = |x|^{2}x\\mathrm{sgn}(x) = |x|^{2}|x| = |x|^{3}$ and $x^{4} = |x|^{4}$:\n$$ \\mathcal{L}V(x) = \\mu p |x|^{3}|x|^{p-1} + \\frac{1}{2}\\sigma^{2}p(p-1)|x|^{4}|x|^{p-2} $$\n$$ \\mathcal{L}V(x) = \\mu p |x|^{p+2} + \\frac{1}{2}\\sigma^{2}p(p-1)|x|^{p+2} $$\nFactoring out the common terms, we obtain:\n$$ \\mathcal{L}V(x) = \\left( \\mu p + \\frac{1}{2}\\sigma^{2}p(p-1) \\right) |x|^{p+2} $$\n\nThe problem requires that there exists an $R>0$ such that $\\mathcal{L}V(x) \\leq 0$ for all $|x| \\geq R$.\nSince $p>0$ and for $|x| \\geq R > 0$, the term $|x|^{p+2}$ is strictly positive, the sign of $\\mathcal{L}V(x)$ is determined by the sign of the coefficient in the parentheses. Thus, the condition $\\mathcal{L}V(x) \\leq 0$ is equivalent to:\n$$ \\mu p + \\frac{1}{2}\\sigma^{2}p(p-1) \\leq 0 $$\nGiven that $p>0$, we can divide the inequality by $p$ without changing the direction of the inequality:\n$$ \\mu + \\frac{1}{2}\\sigma^{2}(p-1) \\leq 0 $$\nNow, we solve for $p$:\n$$ \\frac{1}{2}\\sigma^{2}(p-1) \\leq -\\mu $$\n$$ p-1 \\leq -\\frac{2\\mu}{\\sigma^{2}} $$\n$$ p \\leq 1 - \\frac{2\\mu}{\\sigma^{2}} $$\n\nThis inequality defines the range of values for $p$ that satisfy the condition. We are seeking the largest possible value of $p$, which we denote by $p^{*}$. This corresponds to the upper bound of the permissible range for $p$:\n$$ p^{*} = 1 - \\frac{2\\mu}{\\sigma^{2}} $$\nThe problem states that we should assume $\\sigma^{2} > 2\\mu$. This condition is crucial, as it ensures that $p^{*}$ is positive:\n$$ \\sigma^{2} > 2\\mu \\implies \\frac{2\\mu}{\\sigma^{2}} < 1 \\implies 1 - \\frac{2\\mu}{\\sigma^{2}} > 0 $$\nSo, $p^{*} > 0$, which is consistent with the requirement for the exponent of the Lyapunov function. If this inequality holds for $p=p^*$, the coefficient becomes zero, so $\\mathcal{L}V(x)=0$. For any $p < p^*$, the coefficient is negative, so $\\mathcal{L}V(x)<0$ for $x \\neq 0$. The question asks for the largest exponent $p^*$ for which the condition $\\mathcal{L}V(x)\\leq 0$ can be satisfied for large $|x|$. This is precisely the value that makes the coefficient non-positive.\n\nThe physical interpretation is that a negative drift in the value of the Lyapunov function for large $|x|$ pulls the process back from infinity, preventing blow-up. The term proportional to $\\mu$ comes from the SDE's drift and is destabilizing (pushes $V(x)$ up), while the term proportional to $\\sigma^2$ is a contribution from the Itô correction which, for $p<1$, is stabilizing (pushes $V(x)$ down). The condition on $p$ ensures that the stabilizing effect of the diffusion dominates the destabilizing effect of the drift for large $|x|$.", "answer": "$$\\boxed{1 - \\frac{2\\mu}{\\sigma^{2}}}$$", "id": "3064635"}]}