{"hands_on_practices": [{"introduction": "Proving stability in distribution often relies on the powerful technique of Lyapunov functions. The central idea is to find a function $V(x)$ that grows towards infinity but whose expected change along the process trajectories, quantified by the infinitesimal generator $\\mathcal{L}V$, is negative outside a certain region. This practice provides a direct, hands-on calculation to make these concepts concrete, guiding you through the verification of a key drift inequality for a fundamental linear system [@problem_id:3075105].", "problem": "Consider the linear stochastic differential equation in dimension $2$ driven by two-dimensional standard Brownian motion,\n$$\n\\mathrm{d}X_{t} = A\\,X_{t}\\,\\mathrm{d}t + \\Sigma\\,\\mathrm{d}W_{t}, \\quad X_{t} \\in \\mathbb{R}^{2},\n$$\nwhere $A = -I_{2}$ and $\\Sigma = \\mathrm{diag}(1,2)$. Let $V:\\mathbb{R}^{2}\\to\\mathbb{R}$ be the Lyapunov candidate $V(x) = 1 + |x|^{2}$, where $|x|$ denotes the Euclidean norm. Starting from the definition of the infinitesimal generator and using Itô’s formula, compute the generator $\\mathcal{L}V(x)$ and verify a linear drift inequality of the form\n$$\n\\mathcal{L}V(x) \\leq -\\alpha\\,V(x) + \\beta \\quad \\text{for all } x \\in \\mathbb{R}^{2},\n$$\nwith explicit constants $\\alpha > 0$ and $\\beta \\ge 0$. Determine the largest admissible $\\alpha$ for which such an inequality holds, and, for that choice of $\\alpha$, determine the smallest $\\beta$ that makes the inequality valid for all $x \\in \\mathbb{R}^{2}$. Provide your final answer as the row matrix $(\\alpha,\\beta)$. No rounding is required, and no physical units are involved.", "solution": "The problem requires us to compute the infinitesimal generator $\\mathcal{L}V(x)$ for a given stochastic differential equation (SDE) and a Lyapunov candidate function $V(x)$, and then to determine a pair of optimal constants $(\\alpha, \\beta)$ satisfying a certain inequality.\n\nThe SDE is given in $\\mathbb{R}^{2}$ as:\n$$\n\\mathrm{d}X_{t} = A\\,X_{t}\\,\\mathrm{d}t + \\Sigma\\,\\mathrm{d}W_{t}\n$$\nwhere $X_{t} = \\begin{pmatrix} X_{t,1} \\\\ X_{t,2} \\end{pmatrix}$, $A = -I_{2} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, and $\\Sigma = \\mathrm{diag}(1,2) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}$.\nThe process $W_{t}$ is a $2$-dimensional standard Brownian motion. This SDE is of the general form $\\mathrm{d}X_{t} = b(X_t)\\mathrm{d}t + \\sigma(X_t)\\mathrm{d}W_{t}$, where the drift vector is $b(x) = Ax = -x$ and the diffusion matrix is $\\sigma(x) = \\Sigma$.\n\nThe infinitesimal generator $\\mathcal{L}$ of the process $X_t$, when applied to a twice continuously differentiable function $f:\\mathbb{R}^{2}\\to\\mathbb{R}$, is defined as:\n$$\n\\mathcal{L}f(x) = \\sum_{i=1}^{2} b_i(x) \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i,j=1}^{2} (\\sigma(x)\\sigma(x)^T)_{ij} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x)\n$$\nIn our case, $b(x) = (-x_1, -x_2)^T$. The diffusion matrix $\\sigma$ is constant, so we compute the covariance matrix $\\sigma\\sigma^T$:\n$$\n\\Sigma\\Sigma^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix}\n$$\nThe Lyapunov candidate function is $V(x) = 1 + |x|^{2} = 1 + x_1^2 + x_2^2$. We need to compute its first and second partial derivatives:\nFirst derivatives:\n$$\n\\frac{\\partial V}{\\partial x_1} = 2x_1, \\quad \\frac{\\partial V}{\\partial x_2} = 2x_2\n$$\nThe gradient is $\\nabla V(x) = (2x_1, 2x_2)^T = 2x$.\nSecond derivatives:\n$$\n\\frac{\\partial^2 V}{\\partial x_1^2} = 2, \\quad \\frac{\\partial^2 V}{\\partial x_2^2} = 2, \\quad \\frac{\\partial^2 V}{\\partial x_1 \\partial x_2} = 0\n$$\n\nNow we compute the two parts of $\\mathcal{L}V(x)$.\nThe drift part is:\n$$\n\\sum_{i=1}^{2} b_i(x) \\frac{\\partial V}{\\partial x_i}(x) = b(x) \\cdot \\nabla V(x) = (-x_1, -x_2) \\cdot (2x_1, 2x_2) = -2x_1^2 - 2x_2^2 = -2|x|^2\n$$\nThe diffusion part is:\n$$\n\\frac{1}{2} \\sum_{i,j=1}^{2} (\\Sigma\\Sigma^T)_{ij} \\frac{\\partial^2 V}{\\partial x_i \\partial x_j}(x)\n= \\frac{1}{2} \\left[ (\\Sigma\\Sigma^T)_{11}\\frac{\\partial^2 V}{\\partial x_1^2} + (\\Sigma\\Sigma^T)_{12}\\frac{\\partial^2 V}{\\partial x_1 \\partial x_2} + (\\Sigma\\Sigma^T)_{21}\\frac{\\partial^2 V}{\\partial x_2 \\partial x_1} + (\\Sigma\\Sigma^T)_{22}\\frac{\\partial^2 V}{\\partial x_2^2} \\right]\n$$\nSubstituting the values:\n$$\n= \\frac{1}{2} \\left[ (1)(2) + (0)(0) + (0)(0) + (4)(2) \\right] = \\frac{1}{2}(2 + 8) = 5\n$$\nCombining both parts, we obtain the expression for the generator applied to $V(x)$:\n$$\n\\mathcal{L}V(x) = -2|x|^2 + 5\n$$\nNext, we need to find the largest $\\alpha > 0$ and the corresponding smallest $\\beta \\ge 0$ that satisfy the inequality for all $x \\in \\mathbb{R}^2$:\n$$\n\\mathcal{L}V(x) \\leq -\\alpha\\,V(x) + \\beta\n$$\nSubstituting the expressions for $\\mathcal{L}V(x)$ and $V(x)$:\n$$\n-2|x|^2 + 5 \\leq -\\alpha(1 + |x|^2) + \\beta\n$$\n$$\n-2|x|^2 + 5 \\leq -\\alpha - \\alpha|x|^2 + \\beta\n$$\nTo analyze this inequality, we rearrange it by grouping terms involving $|x|^2$ and constant terms:\n$$\n\\alpha|x|^2 - 2|x|^2 + 5 + \\alpha - \\beta \\leq 0\n$$\n$$\n(\\alpha - 2)|x|^2 + (5 + \\alpha - \\beta) \\leq 0\n$$\nThis inequality must hold for all $x \\in \\mathbb{R}^2$, which is equivalent to it holding for all possible values of $|x|^2 \\ge 0$. Let $u = |x|^2$. The inequality is:\n$$\n(\\alpha - 2)u + (5 + \\alpha - \\beta) \\leq 0 \\quad \\text{for all } u \\ge 0\n$$\nThis is a linear function of $u$. For this inequality to hold for all $u \\ge 0$, two conditions must be satisfied:\n1. The coefficient of $u$, which is the slope of the function, must be non-positive. If $(\\alpha - 2) > 0$, the left side would become arbitrarily large and positive as $u \\to \\infty$, violating the inequality. Thus, we must have:\n$$\n\\alpha - 2 \\leq 0 \\implies \\alpha \\leq 2\n$$\n2. The value of the linear function at $u=0$ must be non-positive. Since the slope is non-positive, the function's maximum value on the interval $[0, \\infty)$ is attained at $u=0$. Therefore, we need:\n$$\n(\\alpha - 2)(0) + (5 + \\alpha - \\beta) \\leq 0 \\implies 5 + \\alpha - \\beta \\leq 0 \\implies \\beta \\ge 5 + \\alpha\n$$\nThe problem asks for the largest admissible $\\alpha > 0$. From the first condition, the maximum possible value is $\\alpha = 2$. This value satisfies $\\alpha > 0$.\n\nFor this choice of $\\alpha = 2$, we must find the smallest $\\beta$ that makes the inequality valid. From the second condition, we have:\n$$\n\\beta \\ge 5 + \\alpha\n$$\nSubstituting $\\alpha = 2$, we get:\n$$\n\\beta \\ge 5 + 2 \\implies \\beta \\ge 7\n$$\nThe smallest value of $\\beta$ is therefore $7$. This value satisfies the requirement $\\beta \\ge 0$.\nWith $\\alpha = 2$ and $\\beta = 7$, the inequality becomes:\n$$\n(2 - 2)|x|^2 + (5 + 2 - 7) \\leq 0 \\implies 0 \\cdot |x|^2 + 0 \\leq 0 \\implies 0 \\leq 0\n$$\nThis is true for all $x \\in \\mathbb{R}^2$.\nThus, the largest admissible $\\alpha$ is $2$, and for this $\\alpha$, the smallest $\\beta$ is $7$. The requested answer is the row matrix $(\\alpha, \\beta)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 7\n\\end{pmatrix}\n}\n$$", "id": "3075105"}, {"introduction": "Moving from specific examples to broader classes of models, this problem explores the stability of the overdamped Langevin equation, a cornerstone model in statistical physics for describing particle motion in a potential field. Here, you will connect the abstract mathematical drift condition to the tangible physical property of a confining potential. This exercise [@problem_id:3075164] demonstrates how the shape of the potential $U(x)$ dictates the long-term stability of the system, providing a deep intuition for why many physical systems tend towards an equilibrium.", "problem": "Consider the diffusion process on $\\mathbb{R}^{d}$ with infinitesimal generator $\\mathcal{L}$ defined by $\\mathcal{L} f(x) = -\\nabla U(x) \\cdot \\nabla f(x) + \\Delta f(x)$, where $U:\\mathbb{R}^{d} \\to \\mathbb{R}$ is twice continuously differentiable. This generator corresponds to the overdamped Langevin stochastic differential equation (SDE), a standard model in stochastic differential equations used to study stability in distribution via Lyapunov methods. Assume that $U$ satisfies a quadratic growth (coercivity) condition: there exist constants $\\alpha > 0$ and $\\beta \\ge 0$ such that for all $x \\in \\mathbb{R}^{d}$,\n$$\nx \\cdot \\nabla U(x) \\ge \\alpha |x|^{2} - \\beta.\n$$\nUsing the Lyapunov function $V(x) = 1 + |x|^{2}$, derive a drift inequality of the form\n$$\n\\mathcal{L} V(x) \\le -\\lambda \\, V(x) + K \\quad \\text{for all } x \\in \\mathbb{R}^{d},\n$$\nstarting only from the definition of the generator and basic differential identities. Express explicitly the constants $\\lambda$ and $K$ in terms of $\\alpha$, $\\beta$, and $d$. Your final answer must be the pair $(\\lambda, K)$ written as a row matrix. No rounding is required and no units are involved.", "solution": "The objective is to compute $\\mathcal{L} V(x)$ for the Lyapunov function $V(x) = 1 + |x|^2$ and then apply the given coercivity condition to derive the target inequality.\n\nFirst, we need to compute the gradient, $\\nabla V(x)$, and the Laplacian, $\\Delta V(x)$, of the function $V$. Let $x = (x_1, x_2, \\dots, x_d) \\in \\mathbb{R}^{d}$. Then $|x|^2 = \\sum_{i=1}^{d} x_i^2$, and $V(x) = 1 + \\sum_{i=1}^{d} x_i^2$.\n\nThe gradient of $V(x)$ is a vector whose $j$-th component is $\\frac{\\partial V}{\\partial x_j}$:\n$$\n\\frac{\\partial V}{\\partial x_j} = \\frac{\\partial}{\\partial x_j} \\left(1 + \\sum_{i=1}^{d} x_i^2\\right) = 2x_j.\n$$\nTherefore, the gradient vector is:\n$$\n\\nabla V(x) = 2x.\n$$\nNext, we compute the Laplacian of $V(x)$, which is the sum of the second partial derivatives, $\\Delta V(x) = \\sum_{j=1}^{d} \\frac{\\partial^2 V}{\\partial x_j^2}$:\n$$\n\\frac{\\partial^2 V}{\\partial x_j^2} = \\frac{\\partial}{\\partial x_j} (2x_j) = 2.\n$$\nSumming over all components from $j=1$ to $d$:\n$$\n\\Delta V(x) = \\sum_{j=1}^{d} 2 = 2d.\n$$\nNow we substitute these results into the definition of the generator $\\mathcal{L}$ applied to $V(x)$:\n$$\n\\mathcal{L} V(x) = -\\nabla U(x) \\cdot \\nabla V(x) + \\Delta V(x).\n$$\nSubstituting $\\nabla V(x) = 2x$ and $\\Delta V(x) = 2d$:\n$$\n\\mathcal{L} V(x) = -\\nabla U(x) \\cdot (2x) + 2d = -2 (x \\cdot \\nabla U(x)) + 2d.\n$$\nWe are given the coercivity condition on $U(x)$:\n$$\nx \\cdot \\nabla U(x) \\ge \\alpha |x|^{2} - \\beta.\n$$\nTo use this condition in our expression for $\\mathcal{L} V(x)$, we multiply the inequality by $-2$. This reverses the inequality sign:\n$$\n-2 (x \\cdot \\nabla U(x)) \\le -2 (\\alpha |x|^{2} - \\beta) = -2\\alpha |x|^{2} + 2\\beta.\n$$\nNow we can bound $\\mathcal{L} V(x)$ from above:\n$$\n\\mathcal{L} V(x) = -2 (x \\cdot \\nabla U(x)) + 2d \\le (-2\\alpha |x|^{2} + 2\\beta) + 2d.\n$$\nSo we have the inequality:\n$$\n\\mathcal{L} V(x) \\le -2\\alpha |x|^{2} + 2\\beta + 2d.\n$$\nThe final step is to express this inequality in the target form $\\mathcal{L} V(x) \\le -\\lambda V(x) + K$. We use the definition of $V(x)$ to relate $|x|^2$ back to $V(x)$:\n$$\nV(x) = 1 + |x|^{2} \\implies |x|^{2} = V(x) - 1.\n$$\nSubstituting this expression for $|x|^2$ into our inequality:\n$$\n\\mathcal{L} V(x) \\le -2\\alpha (V(x) - 1) + 2\\beta + 2d.\n$$\nDistributing the $-2\\alpha$ term:\n$$\n\\mathcal{L} V(x) \\le -2\\alpha V(x) + 2\\alpha + 2\\beta + 2d.\n$$\nThis inequality is now in the desired form $\\mathcal{L} V(x) \\le -\\lambda V(x) + K$. By comparing the terms, we can identify the constants $\\lambda$ and $K$.\nThe term proportional to $V(x)$ gives us $\\lambda$:\n$$\n-\\lambda V(x) = -2\\alpha V(x) \\implies \\lambda = 2\\alpha.\n$$\nThe constant term gives us $K$:\n$$\nK = 2\\alpha + 2\\beta + 2d.\n$$\nThe pair of constants $(\\lambda, K)$ is therefore $(2\\alpha, 2\\alpha + 2\\beta + 2d)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 2\\alpha & 2\\alpha + 2\\beta + 2d \\end{pmatrix}}\n$$", "id": "3075164"}, {"introduction": "The theoretical stability of a continuous-time model does not automatically guarantee the stability of its numerical simulation, a crucial consideration for anyone implementing SDE models. This exercise investigates the widely-used Euler–Maruyama scheme and reveals how the choice of the discrete time step $\\Delta t$ can dramatically affect the long-term behavior of the simulation, even for an inherently stable process. You will use a discrete-time version of the drift criterion to find a critical step size, highlighting a common and important pitfall in computational stochastic modeling [@problem_id:3075162].", "problem": "Consider the scalar Ornstein–Uhlenbeck stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\alpha\\,X_{t}\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t},\n$$\nwhere $\\alpha>0$, $\\sigma>0$, and $W_{t}$ is a standard Brownian motion. It is known that in continuous time this SDE admits a unique stationary distribution and is stable in distribution. Now discretize this SDE by the explicit Euler–Maruyama scheme with fixed step size $\\Delta t>0$:\n$$\nX_{n+1} \\;=\\; X_{n} \\;-\\; \\alpha\\,\\Delta t\\,X_{n} \\;+\\; \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_{n},\n$$\nwhere $(\\xi_{n})_{n\\ge 0}$ are independent and identically distributed standard normal random variables with $\\mathbb{E}[\\xi_{n}]=0$ and $\\mathbb{E}[\\xi_{n}^{2}]=1$.\n\nUsing the quadratic Lyapunov function $V(x)=x^{2}$ and the Foster–Lyapunov drift criterion for Markov chains, derive from first principles a one-step drift inequality of the form\n$$\n\\mathbb{E}\\!\\left[V(X_{n+1})\\mid X_{n}=x\\right] - V(x) \\;\\le\\; -\\lambda(\\Delta t)\\,V(x) \\;+\\; \\beta(\\Delta t),\n$$\nwith explicit expressions for $\\lambda(\\Delta t)$ and $\\beta(\\Delta t)$ in terms of $\\alpha$, $\\sigma$, and $\\Delta t$. Then use your inequality to determine the largest step size $\\Delta t_{\\mathrm{max}}(\\alpha)$ such that there exists a positive constant $\\lambda(\\Delta t)>0$ making the drift negative for all sufficiently large $|x|$, thereby ensuring stability in distribution of the Euler–Maruyama chain. Your final answer must be the closed-form analytic expression for $\\Delta t_{\\mathrm{max}}(\\alpha)$.\n\nFinally, explain, using the derived expressions, how and why the scheme becomes unstable in distribution when $\\Delta t>\\Delta t_{\\mathrm{max}}(\\alpha)$, diagnosing the failure through the sign of the drift bound.\n\nExpress the final answer as an analytic expression. No rounding is required.", "solution": "The problem asks for an analysis of the stability in distribution for the Euler-Maruyama discretization of the scalar Ornstein-Uhlenbeck process. The analysis is to be performed using a quadratic Lyapunov function and the Foster-Lyapunov drift criterion.\n\nThe discrete-time process is given by the stochastic recurrence relation:\n$$\nX_{n+1} \\;=\\; X_{n} \\;-\\; \\alpha\\,\\Delta t\\,X_{n} \\;+\\; \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_{n} \\;=\\; (1 - \\alpha\\,\\Delta t)\\,X_{n} \\;+\\; \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_{n}\n$$\nwhere $\\alpha>0$, $\\sigma>0$, $\\Delta t>0$, and $\\xi_n$ are independent and identically distributed standard normal random variables, i.e., $\\xi_n \\sim \\mathcal{N}(0, 1)$, which implies $\\mathbb{E}[\\xi_n] = 0$ and $\\mathbb{E}[\\xi_n^2] = 1$.\n\nWe are given the quadratic Lyapunov function $V(x) = x^2$. Our first goal is to derive the one-step drift inequality. The one-step drift of the Lyapunov function, conditioned on the current state $X_n=x$, is defined as $\\Delta V(x) = \\mathbb{E}[V(X_{n+1}) \\mid X_n=x] - V(x)$.\n\nLet's compute the conditional expectation $\\mathbb{E}[V(X_{n+1}) \\mid X_n=x] = \\mathbb{E}[X_{n+1}^2 \\mid X_n=x]$.\nSubstituting the expression for $X_{n+1}$ with $X_n=x$:\n$$\n\\mathbb{E}[X_{n+1}^2 \\mid X_n=x] \\;=\\; \\mathbb{E}\\!\\left[\\left( (1 - \\alpha\\,\\Delta t)\\,x + \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_n \\right)^2\\right]\n$$\nExpanding the square inside the expectation gives:\n$$\n\\mathbb{E}\\!\\left[ (1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; 2\\,(1 - \\alpha\\,\\Delta t)\\,x\\,\\sigma\\,\\sqrt{\\Delta t}\\,\\xi_n \\;+\\; (\\sigma\\,\\sqrt{\\Delta t}\\,\\xi_n)^2 \\right]\n$$\nBy the linearity of expectation, we can write:\n$$\n(1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; 2\\,(1 - \\alpha\\,\\Delta t)\\,x\\,\\sigma\\,\\sqrt{\\Delta t}\\,\\mathbb{E}[\\xi_n] \\;+\\; \\sigma^2\\,\\Delta t\\,\\mathbb{E}[\\xi_n^2]\n$$\nUsing the properties of the standard normal random variable $\\xi_n$, where $\\mathbb{E}[\\xi_n]=0$ and $\\mathbb{E}[\\xi_n^2]=1$, the expression simplifies to:\n$$\n(1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; 2\\,(1 - \\alpha\\,\\Delta t)\\,x\\,\\sigma\\,\\sqrt{\\Delta t}\\,(0) \\;+\\; \\sigma^2\\,\\Delta t\\,(1)\n$$\n$$\n\\mathbb{E}[X_{n+1}^2 \\mid X_n=x] \\;=\\; (1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\nNow, we compute the drift $\\Delta V(x)$:\n$$\n\\Delta V(x) \\;=\\; \\mathbb{E}[X_{n+1}^2 \\mid X_n=x] - x^2 \\;=\\; \\left[ (1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t \\right] - x^2\n$$\nGrouping the terms with $x^2$:\n$$\n\\Delta V(x) \\;=\\; \\left( (1 - \\alpha\\,\\Delta t)^2 - 1 \\right)\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\nExpanding the squared term $(1 - \\alpha\\,\\Delta t)^2 = 1 - 2\\alpha\\,\\Delta t + (\\alpha\\,\\Delta t)^2$:\n$$\n\\Delta V(x) \\;=\\; \\left( 1 - 2\\alpha\\,\\Delta t + \\alpha^2\\,(\\Delta t)^2 - 1 \\right)\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\n$$\n\\Delta V(x) \\;=\\; \\left( \\alpha^2\\,(\\Delta t)^2 - 2\\alpha\\,\\Delta t \\right)\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\nThis expression is the exact one-step drift. We need to match it to the form $\\Delta V(x) \\le -\\lambda(\\Delta t)\\,V(x) + \\beta(\\Delta t)$, where $V(x)=x^2$. Since we have an exact equality, it satisfies the inequality trivially.\nBy comparing our derived expression for the drift with the target form:\n$$\n\\left( \\alpha^2\\,(\\Delta t)^2 - 2\\alpha\\,\\Delta t \\right)\\,V(x) \\;+\\; \\sigma^2\\,\\Delta t \\;=\\; -\\lambda(\\Delta t)\\,V(x) \\;+\\; \\beta(\\Delta t)\n$$\nWe can identify the functions $\\lambda(\\Delta t)$ and $\\beta(\\Delta t)$ by equating the coefficients of $V(x)$ and the constant terms:\n$$\n-\\lambda(\\Delta t) \\;=\\; \\alpha^2\\,(\\Delta t)^2 - 2\\alpha\\,\\Delta t \\quad \\implies \\quad \\lambda(\\Delta t) \\;=\\; 2\\alpha\\,\\Delta t - \\alpha^2\\,(\\Delta t)^2\n$$\n$$\n\\beta(\\Delta t) \\;=\\; \\sigma^2\\,\\Delta t\n$$\nThis completes the first part of the problem.\n\nThe second part is to determine the largest step size $\\Delta t_{\\mathrm{max}}(\\alpha)$ that ensures stability in distribution. The Foster-Lyapunov drift criterion for the existence of a stationary distribution (and ergodicity) requires that the drift is negative for all states $x$ outside some compact set. That is, for sufficiently large $|x|$, we must have $\\Delta V(x) < 0$. This is guaranteed if the coefficient of $V(x)$ is strictly negative. In our notation, this corresponds to requiring $\\lambda(\\Delta t) > 0$.\nSo, the condition for numerical stability in distribution is:\n$$\n\\lambda(\\Delta t) \\;>\\; 0\n$$\nSubstituting our expression for $\\lambda(\\Delta t)$:\n$$\n2\\alpha\\,\\Delta t - \\alpha^2\\,(\\Delta t)^2 \\;>\\; 0\n$$\nWe can factor out $\\alpha\\,\\Delta t$. Since both $\\alpha > 0$ and $\\Delta t > 0$, the term $\\alpha\\,\\Delta t$ is strictly positive, so we can divide the inequality by it without changing the direction:\n$$\n\\alpha\\,\\Delta t \\,(2 - \\alpha\\,\\Delta t) \\;>\\; 0 \\quad \\implies \\quad 2 - \\alpha\\,\\Delta t \\;>\\; 0\n$$\nThis inequality can be solved for $\\Delta t$:\n$$\n2 \\;>\\; \\alpha\\,\\Delta t \\quad \\implies \\quad \\Delta t \\;<\\; \\frac{2}{\\alpha}\n$$\nThe scheme is stable in distribution for any step size $\\Delta t$ in the interval $(0, 2/\\alpha)$. The problem asks for the largest step size $\\Delta t_{\\mathrm{max}}(\\alpha)$ such that $\\lambda(\\Delta t) > 0$. This corresponds to the supremum of the set of allowed step sizes.\nTherefore, the maximum step size is:\n$$\n\\Delta t_{\\mathrm{max}}(\\alpha) \\;=\\; \\frac{2}{\\alpha}\n$$\n\nFinally, we explain the instability when $\\Delta t > \\Delta t_{\\mathrm{max}}(\\alpha)$.\nIf we choose a step size $\\Delta t > \\frac{2}{\\alpha}$, then it follows that $\\alpha\\,\\Delta t > 2$, or $2-\\alpha\\,\\Delta t < 0$.\nLet us examine the drift coefficient $-\\lambda(\\Delta t) = \\alpha^2 (\\Delta t)^2 - 2\\alpha \\Delta t$:\n$$\n-\\lambda(\\Delta t) \\;=\\; \\alpha\\,\\Delta t\\,(\\alpha\\,\\Delta t - 2)\n$$\nSince $\\alpha\\,\\Delta t > 2$, the term $(\\alpha\\,\\Delta t - 2)$ is positive. As $\\alpha\\,\\Delta t$ is also positive, the entire coefficient $-\\lambda(\\Delta t)$ is positive.\nThe drift is then:\n$$\n\\Delta V(x) \\;=\\; -\\lambda(\\Delta t)\\,V(x) + \\beta(\\Delta t) \\;=\\; (\\text{positive coefficient}) \\cdot x^2 + (\\text{positive constant})\n$$\nSince $-\\lambda(\\Delta t) > 0$ and $\\beta(\\Delta t) = \\sigma^2 \\Delta t > 0$, the drift $\\Delta V(x)$ is strictly positive for all $x$. Furthermore, as $|x| \\to \\infty$, the drift grows quadratically, $\\Delta V(x) \\to +\\infty$.\nThis means that, on average, the squared value of the process, $V(X_{n+1})$, is always greater than its current value, $V(X_n)$. Instead of being pulled back towards the origin (which is what a negative drift for large $|x|$ accomplishes), the process is actively pushed away from the origin at every step, regardless of its current state. The variance of the process, $\\mathbb{E}[X_n^2]$, will grow without bound as $n \\to \\infty$. This explosive behavior demonstrates that the discrete Markov chain does not possess a stationary distribution and is therefore unstable in distribution.\nAt the critical boundary, $\\Delta t = \\Delta t_{\\mathrm{max}}(\\alpha) = 2/\\alpha$, we have $\\lambda(\\Delta t)=0$, and the drift becomes $\\Delta V(x) = \\beta(\\Delta t) = \\sigma^2 (2/\\alpha) > 0$. The expected variance increases by a constant amount at each step, $\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}[X_n^2] + 2\\sigma^2/\\alpha$, leading to linear growth in variance, which is also an unstable regime.", "answer": "$$\n\\boxed{\\frac{2}{\\alpha}}\n$$", "id": "3075162"}]}