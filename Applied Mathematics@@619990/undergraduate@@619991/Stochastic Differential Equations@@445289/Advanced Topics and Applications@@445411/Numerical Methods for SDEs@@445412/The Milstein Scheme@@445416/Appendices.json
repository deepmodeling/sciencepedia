{"hands_on_practices": [{"introduction": "To truly master a numerical method, it is essential to understand its derivation. This practice guides you through the Itô-Taylor expansion that gives rise to the Milstein scheme, revealing the origin of its higher-order correction term [@problem_id:3081404]. By working through the derivation, you will also discover the precise conditions under which the Milstein scheme elegantly reduces to the simpler Euler-Maruyama method, clarifying its role in solving SDEs with multiplicative noise.", "problem": "Consider the scalar stochastic differential equation (SDE) in the Itô sense,\n$$\n\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t},\n$$\nwhere $a$ and $b$ are globally Lipschitz functions with continuous first derivatives, and $W_{t}$ is a standard Brownian motion. Let a uniform time discretization be given by $t_{n+1} = t_{n} + \\Delta t$ with Brownian increment $\\Delta W_{n} = W_{t_{n+1}} - W_{t_{n}}$.\n\nStarting from the integral form of the SDE and using Itô's formula for twice continuously differentiable functions together with the fundamental moment identities of Brownian motion increments, derive a one-step method that attains strong order one by retaining terms up to order $\\Delta t$ in mean-square. Then specialize to the case in which the diffusion coefficient is constant, $b(x) \\equiv \\sigma$, with $\\sigma \\neq 0$, and justify algebraically why the additional correction term in the strong order one method vanishes.\n\nProvide, as your final answer, the resulting one-step update as a single closed-form analytic expression written solely in terms of $X_{n}$, $a(X_{n})$, $\\Delta t$, $\\sigma$, and $\\Delta W_{n}$, without an equality sign. No rounding is required, and no physical units are involved. Define all acronyms on first use; for example, Euler–Maruyama (EM).", "solution": "The problem requires the derivation of a one-step numerical method for a scalar stochastic differential equation (SDE) that achieves strong order one. We will then specialize this method to the case of a constant diffusion coefficient and provide the resulting simplified update rule.\n\nThe given SDE is in the Itô sense:\n$$\n\\mathrm{d}X_{t} = a(X_{t})\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t}\n$$\nwith a uniform time discretization $t_{n+1} = t_{n} + \\Delta t$. The solution to this SDE can be expressed in integral form over a single time step $[t_n, t_{n+1}]$:\n$$\nX_{t_{n+1}} = X_{t_n} + \\int_{t_n}^{t_{n+1}} a(X_s)\\,\\mathrm{d}s + \\int_{t_n}^{t_{n+1}} b(X_s)\\,\\mathrm{d}W_s\n$$\nLet $X_n$ be the numerical approximation to $X_{t_n}$. To construct a numerical scheme, we must approximate the two integrals on the right-hand side.\n\nThe first integral, involving $\\mathrm{d}t$, is a standard Riemann integral. The simplest and most common approximation is the left-endpoint rule:\n$$\n\\int_{t_n}^{t_{n+1}} a(X_s)\\,\\mathrm{d}s \\approx a(X_n) (t_{n+1} - t_n) = a(X_n) \\Delta t\n$$\nThis approximation has a local error of order $O((\\Delta t)^2)$.\n\nThe second integral is an Itô stochastic integral. The simplest approximation evaluates the integrand at the left endpoint:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s)\\,\\mathrm{d}W_s \\approx b(X_n) \\int_{t_n}^{t_{n+1}} \\mathrm{d}W_s = b(X_n) (W_{t_{n+1}} - W_{t_n}) = b(X_n) \\Delta W_n\n$$\nCombining these two simple approximations yields the Euler–Maruyama (EM) scheme:\n$$\nX_{n+1} = X_n + a(X_n)\\Delta t + b(X_n)\\Delta W_n\n$$\nThe EM scheme has a strong order of convergence of $0.5$. To achieve the required strong order of $1$, we must improve the approximation of the stochastic integral, as it is the dominant source of error. This requires retaining terms of a higher order in the expansion of $b(X_s)$.\n\nWe apply an Itô-Taylor expansion to the term $b(X_s)$ around $t_n$. However, a more direct approach, as suggested by the problem, is to expand $b(X_s)$ and then use Itô's formula to handle the resulting integrals. For $s \\in [t_n, t_{n+1}]$, we approximate $b(X_s)$ using a one-term Taylor series expansion around $X_n$:\n$$\nb(X_s) \\approx b(X_n) + b'(X_n) (X_s - X_n)\n$$\nSubstituting this into the stochastic integral:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s)\\,\\mathrm{d}W_s \\approx \\int_{t_n}^{t_{n+1}} [b(X_n) + b'(X_n)(X_s - X_n)]\\,\\mathrm{d}W_s = b(X_n)\\Delta W_n + b'(X_n) \\int_{t_n}^{t_{n+1}} (X_s - X_n)\\,\\mathrm{d}W_s\n$$\nTo evaluate the remaining integral, we need an approximation for $(X_s - X_n)$. For this purpose, the lowest-order approximation (the EM scheme itself) is sufficient:\n$$\nX_s - X_n \\approx a(X_n)(s - t_n) + b(X_n)(W_s - W_{t_n})\n$$\nSubstituting this into the integral gives:\n$$\n\\int_{t_n}^{t_{n+1}} (X_s - X_n)\\,\\mathrm{d}W_s \\approx \\int_{t_n}^{t_{n+1}} [a(X_n)(s - t_n) + b(X_n)(W_s - W_{t_n})]\\,\\mathrm{d}W_s\n$$\n$$\n= a(X_n) \\int_{t_n}^{t_{n+1}} (s - t_n)\\,\\mathrm{d}W_s + b(X_n) \\int_{t_n}^{t_{n+1}} (W_s - W_{t_n})\\,\\mathrm{d}W_s\n$$\nThe first term, involving $\\int (s-t_n)\\,\\mathrm{d}W_s$, contributes a mean-square error of order $O((\\Delta t)^3)$, which is of a higher order than required for a strong order $1$ scheme, so it can be neglected. We focus on the second term containing the iterated Itô integral $\\int (W_s - W_{t_n})\\,\\mathrm{d}W_s$.\n\nWe evaluate this integral using Itô's formula for the function $f(y) = y^2$ applied to the process $Y_s = W_s - W_{t_n}$. We have $\\mathrm{d}Y_s = \\mathrm{d}W_s$. Itô's formula states $\\mathrm{d}f(Y_s) = f'(Y_s)\\mathrm{d}Y_s + \\frac{1}{2}f''(Y_s)(\\mathrm{d}Y_s)^2$.\nWith $f(y)=y^2$, we have $f'(y)=2y$ and $f''(y)=2$. Thus:\n$$\n\\mathrm{d}(Y_s^2) = 2 Y_s \\mathrm{d}Y_s + \\frac{1}{2}(2)(\\mathrm{d}Y_s)^2 = 2 Y_s \\mathrm{d}W_s + \\mathrm{d}s\n$$\nRearranging for the term $Y_s \\mathrm{d}W_s$ and integrating from $t_n$ to $t_{n+1}$:\n$$\n\\int_{t_n}^{t_{n+1}} Y_s \\mathrm{d}W_s = \\frac{1}{2}\\int_{t_n}^{t_{n+1}}\\mathrm{d}(Y_s^2) - \\frac{1}{2}\\int_{t_n}^{t_{n+1}}\\mathrm{d}s = \\frac{1}{2}[Y_{t_{n+1}}^2 - Y_{t_n}^2] - \\frac{1}{2}[t_{n+1} - t_n]\n$$\nSince $Y_{t_n} = W_{t_n} - W_{t_n} = 0$ and $Y_{t_{n+1}} = W_{t_{n+1}} - W_{t_n} = \\Delta W_n$, the integral evaluates to:\n$$\n\\int_{t_n}^{t_{n+1}} (W_s - W_{t_n})\\,\\mathrm{d}W_s = \\frac{1}{2}[(\\Delta W_n)^2 - 0] - \\frac{1}{2}\\Delta t = \\frac{1}{2}((\\Delta W_n)^2 - \\Delta t)\n$$\nSubstituting this result back into the approximation for the stochastic integral:\n$$\n\\int_{t_n}^{t_{n+1}} b(X_s)\\,\\mathrm{d}W_s \\approx b(X_n)\\Delta W_n + b(X_n)b'(X_n) \\frac{1}{2}((\\Delta W_n)^2 - \\Delta t)\n$$\nCombining this with the drift term approximation, we obtain the one-step method:\n$$\nX_{n+1} = X_n + a(X_n)\\Delta t + b(X_n)\\Delta W_n + \\frac{1}{2}b(X_n)b'(X_n)((\\Delta W_n)^2 - \\Delta t)\n$$\nThis is the Milstein method, which has a strong order of convergence of $1$. The additional term involving $(\\Delta W_n)^2$ is the Milstein correction term. It uses the second moment identity of Brownian increments, $E[(\\Delta W_n)^2] = \\Delta t$, as the correction term has a mean of zero.\n\nNow, we specialize to the case where the diffusion coefficient is constant, $b(x) \\equiv \\sigma$, with $\\sigma \\neq 0$.\nTo apply the derived scheme, we need the function $b(x)$ and its derivative $b'(x)$.\nFor $b(x) = \\sigma$, the derivative with respect to $x$ is:\n$$\nb'(x) = \\frac{\\mathrm{d}}{\\mathrm{d}x}(\\sigma) = 0\n$$\nWe now substitute $b(X_n) = \\sigma$ and $b'(X_n) = 0$ into the Milstein scheme. The correction term is:\n$$\n\\frac{1}{2}b(X_n)b'(X_n)((\\Delta W_n)^2 - \\Delta t) = \\frac{1}{2}(\\sigma)(0)((\\Delta W_n)^2 - \\Delta t)\n$$\nSince multiplication by $0$ results in $0$, the entire correction term vanishes. This is the algebraic justification for the simplification. The Milstein scheme reduces to:\n$$\nX_{n+1} = X_n + a(X_n)\\Delta t + \\sigma \\Delta W_n + 0 = X_n + a(X_n)\\Delta t + \\sigma \\Delta W_n\n$$\nFor SDEs with additive noise (i.e., a constant diffusion coefficient), the Milstein scheme is identical to the Euler-Maruyama scheme. In this specific case, the Euler-Maruyama scheme itself achieves strong order $1.0$.\n\nThe final answer requested is the resulting one-step update expression, which is the right-hand side of the simplified scheme.", "answer": "$$\n\\boxed{X_{n} + a(X_{n}) \\Delta t + \\sigma \\Delta W_{n}}\n$$", "id": "3081404"}, {"introduction": "The primary motivation for adopting the Milstein scheme over the Euler-Maruyama method is its higher order of strong convergence. This practice challenges you to design a computational experiment to empirically verify this theoretical advantage for a Geometric Brownian Motion process [@problem_id:3081428]. By analyzing the slope of the mean-square error on a log-log plot against the step size, you will gain a concrete, visual understanding of how the accuracy of each scheme scales and why the Milstein method is superior for pathwise simulations.", "problem": "Consider the Geometric Brownian Motion (GBM) governed by the Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_t = \\mu X_t\\,\\mathrm{d}t + \\sigma X_t\\,\\mathrm{d}W_t,\\quad X_0>0,\n$$\nwhere $W_t$ is a standard Wiener process. You wish to estimate the strong mean-square error $\\mathbb{E}\\!\\left[|X_T - X_N|^2\\right]$ for two time-discretization methods with uniform step size $h=T/N$: the Euler–Maruyama (EM) method and the Milstein method. Design a computational experiment to empirically estimate $\\mathbb{E}\\!\\left[|X_T - X_N|^2\\right]$ for each method and interpret the observed slopes as functions of the step size.\n\nYour design should be scientifically sound and must use only foundational principles of stochastic calculus and numerical approximation. You will simulate independent Brownian paths and approximate the terminal value $X_T$ using each method with several step sizes. To remove bias from not knowing the exact terminal value, use the availability of the exact solution of GBM derived from Itô calculus (without writing it down here) to compute a reference $X_T$ for each path. For concreteness, take $T=1$, $X_0=1$, $\\mu=0.3$, $\\sigma=0.5$, and a set of step sizes $h\\in\\{T/16, T/32, T/64, T/128, T/256\\}$. For each $h$, simulate $M=10000$ independent paths via normal increments $\\Delta W_n\\sim\\mathcal{N}(0,h)$, compute the terminal approximations $X_N^{\\text{EM}}$ and $X_N^{\\text{Milstein}}$ along the same paths, and estimate\n$$\n\\widehat{\\mathrm{MSE}}_{\\text{scheme}}(h)=\\frac{1}{M}\\sum_{m=1}^{M}\\left|X_T^{(m)}-X_N^{\\text{scheme},(m)}\\right|^2.\n$$\nThen plot $\\log\\big(\\widehat{\\mathrm{MSE}}_{\\text{scheme}}(h)\\big)$ against $\\log(h)$ for each scheme and fit a line to estimate the slope.\n\nWhich interpretation of the observed slopes is correct in the asymptotic regime $h\\to 0$?\n\nA. On the log–log plot of $\\mathbb{E}\\!\\left[|X_T - X_N|^2\\right]$ versus $h$, the Euler–Maruyama method yields a slope approximately equal to $1$, and the Milstein method yields a slope approximately equal to $2$. This corresponds to root-mean-square strong errors scaling like $h^{1/2}$ and $h^{1}$, respectively.\n\nB. The Euler–Maruyama method yields a slope approximately equal to $1/2$, and the Milstein method yields a slope approximately equal to $1$, because the mean-square errors themselves scale like $h^{1/2}$ and $h^{1}$.\n\nC. Both methods yield slopes approximately equal to $1$ for GBM, since multiplicative noise causes both to have the same strong convergence order.\n\nD. The Euler–Maruyama method yields a slope approximately equal to $2$, while the Milstein method yields a slope approximately equal to $1$, due to instability of Milstein under multiplicative noise.\n\nE. The slopes depend nontrivially on $\\mu$ and $\\sigma$ and are not asymptotically constant; increasing $\\sigma$ decreases the slope for both methods.", "solution": "### Problem Validation\n\n#### Step 1: Extract Givens\n\nThe problem statement provides the following information:\n-   **Stochastic Differential Equation (SDE)**: Geometric Brownian Motion (GBM) given by $\\mathrm{d}X_t = \\mu X_t\\,\\mathrm{d}t + \\sigma X_t\\,\\mathrm{d}W_t$, with initial condition $X_0 > 0$.\n-   **Process**: $W_t$ is a standard Wiener process.\n-   **Objective**: To interpret the observed slopes from a computational experiment designed to estimate the strong mean-square error, $\\mathbb{E}\\!\\left[|X_T - X_N|^2\\right]$.\n-   **Numerical Methods**: Euler–Maruyama (EM) and Milstein methods.\n-   **Discretization**: Uniform step size $h=T/N$.\n-   **Computational Experiment Setup**:\n    -   A reference solution $X_T$ is computed using the known exact solution of the GBM SDE for each path.\n    -   Simulation parameters: $T=1$, $X_0=1$, $\\mu=0.3$, $\\sigma=0.5$.\n    -   Set of step sizes: $h\\in\\{T/16, T/32, T/64, T/128, T/256\\}$.\n    -   Number of Monte Carlo simulations: $M=10000$ independent paths for each $h$.\n    -   Wiener increments: $\\Delta W_n \\sim \\mathcal{N}(0,h)$.\n    -   Error estimator: The sample mean-square error is calculated as $\\widehat{\\mathrm{MSE}}_{\\text{scheme}}(h)=\\frac{1}{M}\\sum_{m=1}^{M}\\left|X_T^{(m)}-X_N^{\\text{scheme},(m)}\\right|^2$.\n    -   Analysis method: Plot $\\log\\big(\\widehat{\\mathrm{MSE}}_{\\text{scheme}}(h)\\big)$ against $\\log(h)$ and fit a line to estimate the slope for each scheme.\n-   **Question**: What is the correct interpretation of the observed slopes in the asymptotic regime $h\\to 0$?\n\n#### Step 2: Validate Using Extracted Givens\n\nThe problem statement is a well-defined exercise in the numerical analysis of stochastic differential equations.\n-   **Scientifically Grounded**: The problem is based on the standard theory of SDEs and their numerical approximation. The GBM is a fundamental model, and the Euler-Maruyama and Milstein schemes are canonical numerical methods. The concept of strong convergence and its numerical verification via log-log plots of mean-square error is a standard procedure in the field. The setup is scientifically and mathematically sound.\n-   **Well-Posed**: The question asks for the theoretical strong convergence rates of two standard schemes applied to a standard SDE. These rates are well-established in the literature, leading to a unique and correct interpretation of the experimental outcome.\n-   **Objective**: The problem is specified with precise numerical values and mathematical definitions, leaving no room for subjective interpretation.\n-   **Completeness and Consistency**: The problem is self-contained. All necessary parameters ($T, X_0, \\mu, \\sigma$), methods, and the analysis procedure are explicitly defined. There are no contradictions. The use of the exact solution to compute the error is a standard technique to isolate the discretization error of the numerical scheme.\n\n#### Step 3: Verdict and Action\n\nThe problem statement is valid. It is a standard and well-posed question about the convergence properties of numerical methods for SDEs. I will proceed with the derivation of the solution.\n\n### Solution Derivation\n\nThe problem asks for the theoretical interpretation of the slope of a log-log plot of the mean-square error versus the step size $h$ for the Euler-Maruyama and Milstein schemes applied to a given SDE.\n\nThe SDE is of the general form $\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + b(X_t)\\,\\mathrm{d}W_t$. For the given Geometric Brownian Motion, the drift and diffusion coefficients are $a(x) = \\mu x$ and $b(x) = \\sigma x$.\n\nThe strong order of convergence of a numerical scheme is defined as the largest value $\\gamma > 0$ such that for any final time $T$, there exists a constant $C$ (independent of the step size $h$) such that the global error at time $T$ satisfies:\n$$\n\\mathbb{E}\\left[|X_T - X_N|\\right] \\le C h^\\gamma\n$$\nwhere $X_N$ is the numerical approximation at time $T=Nh$.\n\nThe mean-square error (MSE), which is the quantity being estimated in the problem, is $\\mathbb{E}\\left[|X_T - X_N|^2\\right]$. The order of the mean-square error is related to the strong order of convergence. It can be shown that the MSE has a convergence order of $2\\gamma$:\n$$\n\\text{MSE}(h) = \\mathbb{E}\\left[|X_T - X_N|^2\\right] \\le K h^{2\\gamma}\n$$\nfor some constant $K$. In the asymptotic limit $h \\to 0$, we can write $\\text{MSE}(h) \\approx K h^{p}$, where $p=2\\gamma$ is the order of mean-square convergence.\n\nThe problem describes plotting $\\log(\\text{MSE})$ against $\\log(h)$. Taking the logarithm of the asymptotic relationship gives:\n$$\n\\log(\\text{MSE}(h)) \\approx \\log(K) + p \\log(h)\n$$\nThis is the equation of a line with dependent variable $\\log(\\text{MSE}(h))$ and independent variable $\\log(h)$. The slope of this line is $p$, which is equal to $2\\gamma$.\n\nWe now analyze each scheme.\n\n**1. Euler-Maruyama (EM) Method**\nThe discretization scheme is given by:\n$$\nX_{n+1} = X_n + a(X_n)h + b(X_n)\\Delta W_n\n$$\nFor the given GBM, this becomes:\n$$\nX_{n+1}^{\\text{EM}} = X_n + \\mu X_n h + \\sigma X_n \\Delta W_n = X_n (1 + \\mu h + \\sigma \\Delta W_n)\n$$\nThe Euler-Maruyama method is known to have a strong order of convergence $\\gamma = 0.5$ for general SDEs with globally Lipschitz coefficients, and this holds for GBM.\nTherefore, the exponent for the mean-square error is $p = 2\\gamma = 2 \\times 0.5 = 1$.\nThe slope of the log-log plot of MSE vs. $h$ for the Euler-Maruyama method is expected to be $1$.\n\n**2. Milstein Method**\nThe Milstein scheme is derived from a higher-order Itô-Taylor expansion. The scheme is:\n$$\nX_{n+1} = X_n + a(X_n)h + b(X_n)\\Delta W_n + \\frac{1}{2} b(X_n) b'(X_n) \\left((\\Delta W_n)^2 - h\\right)\n$$\nwhere $b'(x)$ is the derivative of $b(x)$ with respect to $x$. For the GBM, $b(x) = \\sigma x$, so its derivative is $b'(x) = \\sigma$. The term $b(x)b'(x) = (\\sigma x)(\\sigma) = \\sigma^2 x$.\nSubstituting this into the Milstein scheme gives:\n$$\nX_{n+1}^{\\text{Milstein}} = X_n + \\mu X_n h + \\sigma X_n \\Delta W_n + \\frac{1}{2} \\sigma^2 X_n \\left((\\Delta W_n)^2 - h\\right)\n$$\nThe Milstein method is specifically designed to improve the strong order of convergence for SDEs with non-constant diffusion coefficients (multiplicative noise). For this class of SDEs, including GBM, it has a strong order of convergence $\\gamma = 1.0$.\nTherefore, the exponent for the mean-square error is $p = 2\\gamma = 2 \\times 1.0 = 2$.\nThe slope of the log-log plot of MSE vs. $h$ for the Milstein method is expected to be $2$.\n\n**Summary of Expected Slopes:**\n-   Euler-Maruyama: slope $p=1$.\n-   Milstein: slope $p=2$.\n\n### Evaluation of Options\n\n**A. On the log–log plot of $\\mathbb{E}\\!\\left[|X_T - X_N|^2\\right]$ versus $h$, the Euler–Maruyama method yields a slope approximately equal to $1$, and the Milstein method yields a slope approximately equal to $2$. This corresponds to root-mean-square strong errors scaling like $h^{1/2}$ and $h^{1}$, respectively.**\nThis statement is fully consistent with our derivation. A slope of $p=1$ for the MSE of the EM method implies an MSE scaling of $\\mathcal{O}(h^1)$. The root-mean-square (RMS) error, $\\sqrt{\\text{MSE}}$, would then scale as $\\sqrt{h^1} = h^{0.5}$, which corresponds to the strong convergence order $\\gamma=0.5$. A slope of $p=2$ for the MSE of the Milstein method implies an MSE scaling of $\\mathcal{O}(h^2)$. The RMS error would then scale as $\\sqrt{h^2} = h^1$, which corresponds to the strong convergence order $\\gamma=1.0$. This option is correct in its entirety.\n**Verdict: Correct.**\n\n**B. The Euler–Maruyama method yields a slope approximately equal to $1/2$, and the Milstein method yields a slope approximately equal to $1$, because the mean-square errors themselves scale like $h^{1/2}$ and $h^{1}$.**\nThis is incorrect. The values $1/2$ and $1$ are the strong convergence orders ($\\gamma$), not the slopes of the log-log plot of the MSE. The slope of the log-log plot of MSE is $p=2\\gamma$. Furthermore, the statement that the MSEs \"scale like $h^{1/2}$ and $h^1$\" is inconsistent; the first part is wrong, as the MSE for EM scales with $h^1$.\n**Verdict: Incorrect.**\n\n**C. Both methods yield slopes approximately equal to $1$ for GBM, since multiplicative noise causes both to have the same strong convergence order.**\nThis is incorrect. The Milstein method is specifically designed to achieve a higher order of strong convergence than Euler-Maruyama for SDEs with multiplicative noise, like GBM. If the noise were additive (i.e., $b(x)$ were a constant), then $b'(x)=0$, the Milstein scheme would reduce to the Euler-Maruyama scheme, and they would have the same convergence order ($\\gamma=0.5$). But for multiplicative noise, Milstein is superior.\n**Verdict: Incorrect.**\n\n**D. The Euler–Maruyama method yields a slope approximately equal to $2$, while the Milstein method yields a slope approximately equal to $1$, due to instability of Milstein under multiplicative noise.**\nThis is incorrect. The convergence orders are reversed. The Milstein method is not unstable; it is more accurate for strong convergence than Euler-Maruyama in this context.\n**Verdict: Incorrect.**\n\n**E. The slopes depend nontrivially on $\\mu$ and $\\sigma$ and are not asymptotically constant; increasing $\\sigma$ decreases the slope for both methods.**\nThis is incorrect. The *order* of convergence, and thus the asymptotic slope of the log-log error plot, is a structural property of the numerical method and the class of SDE. While the constant $K$ in the error bound $\\text{MSE} \\le K h^{2\\gamma}$ depends on $\\mu$, $\\sigma$, and $T$, the exponent $2\\gamma$ (the slope) does not. It is an asymptotic feature for $h \\to 0$.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3081428"}, {"introduction": "While the Milstein scheme offers superior accuracy, this advantage does not come without trade-offs. This hands-on coding exercise explores the critical concept of mean-square stability, revealing a scenario where the higher-order Milstein scheme imposes a stricter constraint on the timestep $\\Delta t$ than the Euler-Maruyama scheme [@problem_id:2443132]. By analyzing the stability regions for a specific linear SDE, you will learn the important lesson that accuracy and stability must be considered in tandem when implementing numerical solutions.", "problem": "You are tasked with constructing and analyzing a scalar stochastic differential equation in which the sensitivity of numerical stability to the timestep choice is stricter for the Milstein scheme than for the Euler–Maruyama scheme. Consider the scalar stochastic differential equation with multiplicative noise given by\n$$\n\\mathrm{d}X_t = a\\,X_t\\,\\mathrm{d}t + b\\,X_t\\,\\mathrm{d}W_t,\n$$\nwhere $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are constants, $X_0 \\in \\mathbb{R}$ is a given initial value with finite second moment, and $W_t$ is a standard Wiener process. For this task, you must use the specific parameter values $a=-2$ and $b=1$. The zero solution of the continuous-time system is an equilibrium, and mean-square stability of a discrete-time approximation refers to whether the second moment $\\,\\mathbb{E}[X_n^2]\\,$ tends to decrease geometrically as the step index $n$ increases.\n\nYour program must determine, for each prescribed timestep $\\,\\Delta t\\,$, whether each of the following two discretization schemes applied to the equation above is mean-square stable in the sense that the one-step mean-square amplification factor is strictly less than $\\,1$:\n- The Euler–Maruyama scheme.\n- The Milstein scheme.\n\nThe test suite of timesteps is\n$$\n\\{\\Delta t_1, \\Delta t_2, \\Delta t_3\\} = \\{\\,0.1,\\,0.7,\\,1.0\\,\\}.\n$$\nFor each $\\,\\Delta t\\,$ in this set, evaluate two booleans: the mean-square stability of the Euler–Maruyama scheme at that $\\,\\Delta t\\,$, followed by the mean-square stability of the Milstein scheme at that $\\,\\Delta t\\,$. Declare a scheme “stable” if and only if its one-step mean-square amplification factor is strictly less than $\\,1$, and “unstable” otherwise.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[\\text{EM}(\\Delta t_1),\\ \\text{Mil}(\\Delta t_1),\\ \\text{EM}(\\Delta t_2),\\ \\text{Mil}(\\Delta t_2),\\ \\text{EM}(\\Delta t_3),\\ \\text{Mil}(\\Delta t_3)],\n$$\nwhere $\\,\\text{EM}(\\Delta t)\\,$ and $\\,\\text{Mil}(\\Delta t)\\,$ are booleans indicating mean-square stability at timestep $\\,\\Delta t\\,$ for the Euler–Maruyama and Milstein schemes, respectively. The required output is a list of six boolean values formatted on a single line, with no additional text or characters.", "solution": "The problem as stated is valid. It is scientifically grounded, well-posed, and objective. It presents a standard inquiry into the numerical stability of common discretization schemes for stochastic differential equations, using established definitions and a concrete example. All necessary data and conditions are provided, and there are no contradictions or ambiguities. We shall proceed with the derivation and solution.\n\nThe problem requires an analysis of the mean-square stability of two numerical schemes for the scalar stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t = a X_t\\,\\mathrm{d}t + b X_t\\,\\mathrm{d}W_t,\n$$\nwith parameters $a = -2$ and $b = 1$. $W_t$ is a standard Wiener process. A numerical approximation $X_n$ of $X(t_n)$ at discrete times $t_n = n \\Delta t$ is considered mean-square stable if its one-step mean-square amplification factor, $R$, is strictly less than one. The amplification factor is defined as $R = \\mathbb{E}[X_{n+1}^2 | \\mathcal{F}_{t_n}] / X_n^2$, where $\\mathbb{E}[ \\cdot | \\mathcal{F}_{t_n}]$ denotes expectation conditional on the information available at time $t_n$. Since $X_n$ is known at step $n$, this simplifies to $R = \\mathbb{E}[(X_{n+1}/X_n)^2]$. The condition for stability is $R < 1$.\n\nWe will analyze the Euler–Maruyama and Milstein schemes separately. For these derivations, we use the moments of the Wiener increment $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$, which is a normally distributed random variable with mean zero and variance $\\Delta t$. Specifically, $\\mathbb{E}[\\Delta W_n] = 0$ and $\\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$. For the Milstein scheme, we will also need higher-order moments: $\\mathbb{E}[(\\Delta W_n)^3] = 0$ and $\\mathbb{E}[(\\Delta W_n)^4] = 3(\\Delta t)^2$.\n\n**1. Euler–Maruyama (EM) Scheme**\n\nThe Euler–Maruyama scheme for the given SDE is\n$$\nX_{n+1} = X_n + a X_n \\Delta t + b X_n \\Delta W_n = X_n (1 + a \\Delta t + b \\Delta W_n).\n$$\nThe one-step mean-square amplification factor $R_{EM}$ is\n$$\nR_{EM} = \\mathbb{E}\\left[ \\left(\\frac{X_{n+1}}{X_n}\\right)^2 \\right] = \\mathbb{E}[ (1 + a \\Delta t + b \\Delta W_n)^2 ].\n$$\nExpanding the square and taking the expectation yields:\n$$\nR_{EM} = \\mathbb{E}[ 1 + (a \\Delta t)^2 + b^2 (\\Delta W_n)^2 + 2a \\Delta t + 2b \\Delta W_n + 2ab \\Delta t \\Delta W_n ]\n$$\n$$\nR_{EM} = 1 + (a \\Delta t)^2 + b^2 \\mathbb{E}[(\\Delta W_n)^2] + 2a \\Delta t + 2b \\mathbb{E}[\\Delta W_n] + 2ab \\Delta t \\mathbb{E}[\\Delta W_n].\n$$\nSubstituting the moments of $\\Delta W_n$:\n$$\nR_{EM} = 1 + a^2 (\\Delta t)^2 + b^2 \\Delta t + 2a \\Delta t = (1 + a \\Delta t)^2 + b^2 \\Delta t.\n$$\nFor mean-square stability, we require $R_{EM} < 1$. With $a = -2$ and $b = 1$:\n$$\n(1 - 2 \\Delta t)^2 + (1)^2 \\Delta t < 1\n$$\n$$\n1 - 4 \\Delta t + 4(\\Delta t)^2 + \\Delta t < 1\n$$\n$$\n4(\\Delta t)^2 - 3 \\Delta t < 0.\n$$\nSince $\\Delta t > 0$, we can divide by $\\Delta t$ to obtain the stability condition:\n$$\n4 \\Delta t - 3 < 0 \\implies \\Delta t < \\frac{3}{4} = 0.75.\n$$\n\n**2. Milstein Scheme**\n\nThe general Milstein scheme is $X_{n+1} = X_n + f(X_n)\\Delta t + g(X_n)\\Delta W_n + \\frac{1}{2}g(X_n)g'(X_n)((\\Delta W_n)^2 - \\Delta t)$. For our SDE, $f(x) = ax$ and $g(x) = bx$, so $g'(x) = b$. The scheme becomes:\n$$\nX_{n+1} = X_n + a X_n \\Delta t + b X_n \\Delta W_n + \\frac{1}{2}(b X_n)(b)((\\Delta W_n)^2 - \\Delta t)\n$$\n$$\nX_{n+1} = X_n \\left( 1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t + b \\Delta W_n + \\frac{1}{2}b^2 (\\Delta W_n)^2 \\right).\n$$\nThe amplification factor $R_{Mil}$ is the expectation of the square of the term in the parentheses. Let $C = 1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t$.\n$$\nR_{Mil} = \\mathbb{E}\\left[ \\left( C + b \\Delta W_n + \\frac{1}{2}b^2 (\\Delta W_n)^2 \\right)^2 \\right]\n$$\n$$\nR_{Mil} = \\mathbb{E}\\left[ C^2 + b^2(\\Delta W_n)^2 + \\frac{1}{4}b^4(\\Delta W_n)^4 + 2C b \\Delta W_n + C b^2 (\\Delta W_n)^2 + b^3 (\\Delta W_n)^3 \\right].\n$$\nTaking the expectation term-by-term using the moments of $\\Delta W_n$:\n$$\nR_{Mil} = C^2 + b^2\\Delta t + \\frac{1}{4}b^4(3(\\Delta t)^2) + 2C b(0) + C b^2 \\Delta t + b^3(0)\n$$\n$$\nR_{Mil} = C^2 + C b^2 \\Delta t + b^2 \\Delta t + \\frac{3}{4} b^4 (\\Delta t)^2.\n$$\nSubstitute $C = 1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t$ back into the expression:\n$$\nR_{Mil} = \\left(1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t\\right)^2 + \\left(1 + a \\Delta t - \\frac{1}{2}b^2 \\Delta t\\right)b^2 \\Delta t + b^2 \\Delta t + \\frac{3}{4}b^4 (\\Delta t)^2\n$$\n$$\nR_{Mil} = \\left((1+a\\Delta t) - \\frac{1}{2}b^2\\Delta t\\right) \\left((1+a\\Delta t) + \\frac{1}{2}b^2\\Delta t\\right) + b^2\\Delta t + \\frac{3}{4}b^4 (\\Delta t)^2\n$$\n$$\nR_{Mil} = (1+a\\Delta t)^2 - \\frac{1}{4}b^4(\\Delta t)^2 + b^2\\Delta t + \\frac{3}{4}b^4(\\Delta t)^2 = (1+a\\Delta t)^2 + b^2\\Delta t + \\frac{1}{2}b^4(\\Delta t)^2.\n$$\nFor mean-square stability, we require $R_{Mil} < 1$. With $a = -2$ and $b = 1$:\n$$\n(1 - 2 \\Delta t)^2 + \\Delta t + \\frac{1}{2}(1)^4 (\\Delta t)^2 < 1\n$$\n$$\n1 - 4 \\Delta t + 4(\\Delta t)^2 + \\Delta t + \\frac{1}{2}(\\Delta t)^2 < 1\n$$\n$$\n\\frac{9}{2}(\\Delta t)^2 - 3 \\Delta t < 0.\n$$\nDividing by $\\Delta t > 0$:\n$$\n\\frac{9}{2} \\Delta t - 3 < 0 \\implies \\Delta t < \\frac{3}{9/2} = \\frac{6}{9} = \\frac{2}{3}.\n$$\n\n**3. Evaluation for Test Cases**\n\nWe have the stability regions:\n- Euler–Maruyama: $\\Delta t < 0.75$\n- Milstein: $\\Delta t < 2/3 \\approx 0.667$\n\nNow we test the prescribed timesteps $\\{\\Delta t_1, \\Delta t_2, \\Delta t_3\\} = \\{0.1, 0.7, 1.0\\}$. A scheme is stable if its $\\Delta t$ is within its stability region.\n\n- For $\\Delta t_1 = 0.1$:\n  - EM: $0.1 < 0.75 \\implies \\text{Stable (True)}$\n  - Milstein: $0.1 < 2/3 \\implies \\text{Stable (True)}$\n\n- For $\\Delta t_2 = 0.7$:\n  - EM: $0.7 < 0.75 \\implies \\text{Stable (True)}$\n  - Milstein: $0.7 > 2/3 \\implies \\text{Unstable (False)}$\n\n- For $\\Delta t_3 = 1.0$:\n  - EM: $1.0 > 0.75 \\implies \\text{Unstable (False)}$\n  - Milstein: $1.0 > 2/3 \\implies \\text{Unstable (False)}$\n\nThe resulting sequence of booleans is [True, True, True, False, False, False].", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Determines the mean-square stability of the Euler-Maruyama and Milstein schemes\n    for a specific SDE at given timesteps.\n    \"\"\"\n    # Parameters for the SDE: dX = a*X*dt + b*X*dW\n    a = -2.0\n    b = 1.0\n\n    # Test suite of timesteps\n    test_cases = [0.1, 0.7, 1.0]\n\n    results = []\n    \n    # The mean-square stability condition for a scheme is that its one-step\n    # amplification factor R must be strictly less than 1.\n\n    for dt in test_cases:\n        # Euler-Maruyama stability analysis:\n        # The amplification factor is R_EM = (1 + a*dt)^2 + b^2*dt.\n        # The stability condition R_EM < 1 simplifies to:\n        # (1 - 2*dt)^2 + dt < 1\n        # 1 - 4*dt + 4*dt^2 + dt < 1\n        # 4*dt^2 - 3*dt < 0\n        # dt * (4*dt - 3) < 0\n        # Since dt > 0, the condition is 4*dt - 3 < 0.\n        em_stable = (4.0 * dt - 3.0) < 0\n        results.append(em_stable)\n\n        # Milstein stability analysis:\n        # The amplification factor is R_Mil = (1 + a*dt)^2 + b^2*dt + 0.5*b^4*dt^2.\n        # The stability condition R_Mil < 1 simplifies to:\n        # (1 - 2*dt)^2 + dt + 0.5*dt^2 < 1\n        # 1 - 4*dt + 4*dt^2 + dt + 0.5*dt^2 < 1\n        # 4.5*dt^2 - 3*dt < 0\n        # dt * (4.5*dt - 3) < 0\n        # Since dt > 0, the condition is 4.5*dt - 3 < 0.\n        mil_stable = (4.5 * dt - 3.0) < 0\n        results.append(mil_stable)\n\n    # Final print statement in the exact required format.\n    # The str() of a boolean is 'True' or 'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2443132"}]}