{"hands_on_practices": [{"introduction": "The journey into simulating stochastic processes begins with understanding the fundamental building block of any simulation: the single time step. The Euler-Maruyama method provides the most direct numerical translation of a stochastic differential equation into a step-by-step algorithm. This exercise [@problem_id:3067105] invites you to perform one such step for the geometric Brownian motion model, solidifying your grasp of how the drift and diffusion components, along with a random shock, combine to advance the process in time.", "problem": "Consider the geometric Brownian motion, a Stochastic Differential Equation (SDE), given by $dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$, where $W_t$ is a standard Brownian motion. In a Monte Carlo (MC) simulation, time is discretized on a uniform grid $t_n$ with step size $\\Delta t = t_{n+1} - t_n$. At each step, the Brownian increment $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is sampled from a normal distribution with mean $0$ and variance $\\Delta t$, that is $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$. \n\nYou are given the parameter values $\\mu = 0.05$, $\\sigma = 0.2$, the current state $X_n = 50$, and the time step $\\Delta t = 0.01$. Suppose a MC draw yields a standard normal variate $Z_n = 0.32$, and we set $\\Delta W_n = \\sqrt{\\Delta t}\\,Z_n$. Using a first-principles discretization of the SDE over one time step from $t_n$ to $t_{n+1}$, compute the updated value $X_{n+1}$ produced by one Euler–Maruyama step starting from $X_n$. \n\nRound your final result to four significant figures.", "solution": "The geometric Brownian motion SDE is given by $dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$. Over a small time interval $[t_n, t_{n+1}]$ with $\\Delta t = t_{n+1} - t_n$, the integral form is\n$$\nX_{t_{n+1}} - X_{t_n} = \\int_{t_n}^{t_{n+1}} \\mu X_s\\,ds + \\int_{t_n}^{t_{n+1}} \\sigma X_s\\,dW_s.\n$$\nA first-order explicit time discretization, known as the Euler–Maruyama method, approximates the drift integral by evaluating the integrand at the left endpoint and multiplying by the step size, and approximates the Itô integral by evaluating the integrand at the left endpoint and multiplying by the Brownian increment. Thus,\n$$\nX_{n+1} \\approx X_n + \\mu X_n \\Delta t + \\sigma X_n \\Delta W_n.\n$$\nIn a Monte Carlo implementation, the Brownian increment $\\Delta W_n$ is sampled according to $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$. A convenient construction uses a standard normal variate $Z_n \\sim \\mathcal{N}(0,1)$ and sets\n$$\n\\Delta W_n = \\sqrt{\\Delta t}\\, Z_n.\n$$\nWith the given values $\\Delta t = 0.01$ and $Z_n = 0.32$, we compute\n$$\n\\sqrt{\\Delta t} = \\sqrt{0.01} = 0.1,\n$$\nso\n$$\n\\Delta W_n = 0.1 \\times 0.32 = 0.032.\n$$\nNow substitute $\\mu = 0.05$, $\\sigma = 0.2$, $X_n = 50$, and $\\Delta t = 0.01$, $\\Delta W_n = 0.032$ into the Euler–Maruyama update:\n$$\nX_{n+1} = 50 + (0.05)(50)(0.01) + (0.2)(50)(0.032).\n$$\nCompute the contributions term by term:\n- Drift term: $(0.05)(50)(0.01) = 0.05 \\times 0.5 = 0.025$.\n- Diffusion term: $(0.2)(50)(0.032) = 0.2 \\times 1.6 = 0.32$.\nTherefore,\n$$\nX_{n+1} = 50 + 0.025 + 0.32 = 50.345.\n$$\nRounding to four significant figures gives $50.35$.", "answer": "$$\\boxed{50.35}$$", "id": "3067105"}, {"introduction": "While the Euler-Maruyama method is foundational, its accuracy can be limited. To achieve better approximations without excessively shrinking the time step, we can turn to higher-order numerical schemes. The Milstein method is a cornerstone of this next level of sophistication, introducing a correction term that accounts for the interaction between the process and its own volatility. This practice [@problem_id:3067093] challenges you to apply the Milstein update, revealing how a deeper application of Itô calculus leads to more accurate and efficient simulations.", "problem": "A scalar Stochastic Differential Equation (SDE) driven by Brownian motion (Wiener process) models geometric Brownian motion as $dX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t}$, where $\\mu$ and $\\sigma$ are real constants and $W_{t}$ is standard Brownian motion. In Monte Carlo (MC) simulation of SDEs, one constructs a discrete-time strong approximation to sample paths by advancing the state $X_{t}$ over a small time step $\\Delta t$ using a Brownian increment $\\Delta W_{n}$ that is generated as $\\Delta W_{n}=\\sqrt{\\Delta t}\\,Z_{n}$ for a standard normal variate $Z_{n}\\sim\\mathcal{N}(0,1)$.\n\nUsing the Itô calculus and the Itô–Taylor expansion truncated at terms that yield a strong order one scheme, derive the one-step Milstein update for the above SDE over a step of size $\\Delta t$ in terms of $X_{n}$, $\\Delta W_{n}$, and the coefficients $\\mu$ and $\\sigma$. Then evaluate this update for the specific inputs $\\mu=0.12$, $\\sigma=0.5$, $X_{n}=0.8$, $\\Delta t=0.01$, and $\\Delta W_{n}=0.09$ (consistent with the Monte Carlo construction $\\Delta W_{n}=\\sqrt{\\Delta t}\\,Z_{n}$ when $Z_{n}=0.9$). Round your numerical answer to $5$ significant figures. Provide your final answer as a single number with no units.", "solution": "The Milstein scheme is a higher-order method for approximating solutions to Stochastic Differential Equations (SDEs), offering improved strong convergence over the Euler-Maruyama method. For a general scalar SDE of the form $dX_t = a(X_t, t)\\,dt + b(X_t, t)\\,dW_t$, the Milstein update rule is derived from an Itô-Taylor expansion:\n$$\nX_{n+1} = X_n + a(X_n, t_n)\\Delta t + b(X_n, t_n)\\Delta W_n + \\frac{1}{2} b(X_n, t_n) \\frac{\\partial b}{\\partial x}(X_n, t_n) \\left( (\\Delta W_n)^2 - \\Delta t \\right)\n$$\n\n**1. Derivation for Geometric Brownian Motion**\n\nThe SDE for geometric Brownian motion (GBM) is:\n$$\ndX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t}\n$$\nHere, the drift and diffusion coefficients are:\n- Drift: $a(X_t) = \\mu X_t$\n- Diffusion: $b(X_t) = \\sigma X_t$\n\nTo apply the Milstein scheme, we need the derivative of the diffusion coefficient with respect to the state variable $X$:\n$$\n\\frac{\\partial b}{\\partial X_t} = \\frac{\\partial}{\\partial X_t}(\\sigma X_t) = \\sigma\n$$\nSubstituting these components into the general Milstein formula gives the specific update rule for GBM:\n$$\nX_{n+1} = X_n + (\\mu X_n) \\Delta t + (\\sigma X_n) \\Delta W_n + \\frac{1}{2} (\\sigma X_n) (\\sigma) ((\\Delta W_n)^2 - \\Delta t)\n$$\nSimplifying, we obtain:\n$$\nX_{n+1} = X_n + \\mu X_n \\Delta t + \\sigma X_n \\Delta W_n + \\frac{1}{2} \\sigma^2 X_n ((\\Delta W_n)^2 - \\Delta t)\n$$\n\n**2. Numerical Evaluation**\n\nWe are given the following parameter values:\n- $\\mu = 0.12$\n- $\\sigma = 0.5$\n- $X_n = 0.8$\n- $\\Delta t = 0.01$\n- $\\Delta W_n = 0.09$\n\nWe substitute these values into the derived Milstein update equation. Let's compute each term's contribution:\n- **Initial Value**: $X_n = 0.8$\n- **Drift Term**: $\\mu X_n \\Delta t = (0.12)(0.8)(0.01) = 0.00096$\n- **Diffusion Term**: $\\sigma X_n \\Delta W_n = (0.5)(0.8)(0.09) = 0.036$\n- **Milstein Correction Term**: $\\frac{1}{2} \\sigma^2 X_n ((\\Delta W_n)^2 - \\Delta t)$\n  - First, calculate the components inside the correction term:\n    - $(\\Delta W_n)^2 = (0.09)^2 = 0.0081$\n    - $(\\Delta W_n)^2 - \\Delta t = 0.0081 - 0.01 = -0.0019$\n  - The full correction term is:\n    - $\\frac{1}{2}(0.5)^2(0.8)(-0.0019) = \\frac{1}{2}(0.25)(0.8)(-0.0019) = (0.1)(-0.0019) = -0.00019$\n\nNow, sum all the parts to find $X_{n+1}$:\n$$\nX_{n+1} = 0.8 + 0.00096 + 0.036 - 0.00019 = 0.83677\n$$\nThe problem requires rounding to 5 significant figures. The calculated value $0.83677$ already has exactly 5 significant figures.", "answer": "$$\n\\boxed{0.83677}\n$$", "id": "3067093"}, {"introduction": "Mastering single-step updates is essential, but the true power of simulation lies in using them to conduct meaningful numerical experiments. A critical task in computational science is to verify that a numerical method behaves as theory predicts. This comprehensive exercise [@problem_id:3067097] guides you through the process of empirically measuring the convergence rates of the Euler-Maruyama method. You will learn to distinguish between strong and weak convergence and implement a full-scale Monte Carlo experiment, a capstone skill for anyone working with numerical solutions to SDEs.", "problem": "Design and implement a self-contained numerical experiment to empirically estimate strong and weak convergence rates for a time-discretization method applied to a stochastic differential equation (SDE), by refining the time step and comparing pathwise and expectation errors.\n\nYou must base your work on the following fundamental setup and definitions.\n\n1. Stochastic differential equation model. Consider the Geometric Brownian Motion (GBM) SDE\n$$\ndX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t,\\quad X_0>0,\n$$\nwhere $W_t$ is a standard Brownian motion, and $\\mu,\\sigma \\in \\mathbb{R}$ are constants. For time discretization, use the Euler–Maruyama (EM) method, which is the most basic scheme derived from the Itô integral definition and the increment approximation $dW_t \\approx \\Delta W$ with $\\Delta W \\sim \\mathcal{N}(0,\\Delta t)$.\n\n2. Error notions. For a fixed final time $T>0$, let $X_T^{\\Delta t}$ denote the EM approximation at time $T$ with time step $\\Delta t$. Define:\n- The strong error at time $T$ as\n$$\ne_{\\text{strong}}(\\Delta t) = \\left(\\mathbb{E}\\left[\\,|X_T^{\\Delta t}-X_T|^2\\,\\right]\\right)^{1/2}.\n$$\n- The weak error at time $T$ for a test function $\\varphi$ as\n$$\ne_{\\text{weak}}(\\Delta t) = \\left|\\,\\mathbb{E}\\left[\\varphi\\left(X_T^{\\Delta t}\\right)\\right] - \\mathbb{E}\\left[\\varphi\\left(X_T\\right)\\right]\\right|.\n$$\n\n3. Monte Carlo (MC) experiment design. Use Monte Carlo to estimate these errors for a sequence of refined time steps $\\Delta t$. For the strong error, couple the Brownian paths across refinements by reusing a single fine Brownian grid whose increments are summed to form coarser-grid increments. For the weak error, evaluate $\\varphi$ on the EM terminal values and compare to the exact value of $\\mathbb{E}[\\varphi(X_T)]$ obtained from first principles. Use the following test functions to ensure closed-form targets:\n- Case $\\varphi(x)=x^k$ with $k \\in \\{1,2\\}$.\n\n4. Convergence rates. For each sequence of decreasing time steps $\\{\\Delta t_\\ell\\}$ and corresponding error estimates $\\{e(\\Delta t_\\ell)\\}$, estimate the empirical convergence rate $p$ by a linear least-squares fit of $\\log e(\\Delta t_\\ell)$ versus $\\log \\Delta t_\\ell$, i.e., fit\n$$\n\\log e(\\Delta t_\\ell) \\approx a + p \\,\\log \\Delta t_\\ell,\n$$\nand take the slope $p$ as the estimated rate.\n\nProgram requirements and test suite.\n\nA. Implement a program that:\n- Simulates the EM approximation of GBM to time $T$ for a sequence of time steps formed by $M \\in \\{4,8,16,32,64\\}$ uniform subintervals, i.e., $\\Delta t = T/M$.\n- Uses a single finest grid with $M_{\\max}=64$ to generate Brownian increments $\\Delta W$; obtain coarser-level increments by summing disjoint consecutive blocks of fine increments to enforce pathwise coupling across refinements.\n- Estimates the strong error by a Monte Carlo root-mean-square (RMS) over coupled paths using the exact solution $X_T$ evaluated on the same Brownian terminal values to define $X_T$ pathwise.\n- Estimates the weak error using the Monte Carlo average of $\\varphi(X_T^{\\Delta t})$ and the exact value of $\\mathbb{E}[\\varphi(X_T)]$ derived from the GBM law.\n- Uses $N$ Monte Carlo paths with a fixed random seed for reproducibility.\n\nB. Use the following test suite of parameter sets, covering typical, boundary, and edge-like regimes. For each test case, report two floats: the estimated strong convergence rate and the estimated weak convergence rate, in this order.\n\n- Test case $1$ (happy path): $X_0=1.0$, $\\mu=0.3$, $\\sigma=0.5$, $T=1.0$, $\\varphi(x)=x$ (i.e., $k=1$), $N=20000$, seed $=12345$.\n- Test case $2$ (boundary: zero drift, nonlinear moment): $X_0=2.0$, $\\mu=0.0$, $\\sigma=0.8$, $T=2.0$, $\\varphi(x)=x^2$ (i.e., $k=2$), $N=20000$, seed $=12346$.\n- Test case $3$ (edge-like: negative drift, large volatility, short horizon): $X_0=1.5$, $\\mu=-0.2$, $\\sigma=1.2$, $T=0.5$, $\\varphi(x)=x$ (i.e., $k=1$), $N=20000$, seed $=12347$.\n\nC. Final output format. Your program should produce a single line of output containing the results as a list of lists of floats, one inner list per test case in the order given above:\n- The format must be\n$$\n\\big[ [p_{\\text{strong},1},\\, p_{\\text{weak},1}],\\; [p_{\\text{strong},2},\\, p_{\\text{weak},2}],\\; [p_{\\text{strong},3},\\, p_{\\text{weak},3}] \\big],\n$$\nwith each float rounded to three decimal places.\n\nNo external inputs or files are allowed. The program must run as is and follow the specified random seeds. No physical units or angle units are involved. The output must be exactly one line in the specified format.", "solution": "The objective is to empirically determine the strong and weak convergence rates of the Euler-Maruyama (EM) method for the Geometric Brownian Motion (GBM) stochastic differential equation (SDE). This will be accomplished through a Monte Carlo simulation experiment where the time step is refined, and the resulting errors are analyzed.\n\n### 1. Theoretical Framework\n\n#### 1.1. The Geometric Brownian Motion SDE and its Solution\nThe problem is based on the Geometric Brownian Motion SDE:\n$$\ndX_t = \\mu X_t \\,dt + \\sigma X_t \\,dW_t, \\quad X(0) = X_0 > 0\n$$\nwhere $\\mu$ is the drift rate, $\\sigma$ is the volatility, and $W_t$ is a standard Wiener process (Brownian motion). This SDE possesses a known strong solution, which can be found using Itô's lemma on $f(x) = \\log(x)$. The solution for the process at time $T$ is:\n$$\nX_T = X_0 \\exp\\left( \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T + \\sigma W_T \\right)\n$$\nHere, $W_T$ is a normally distributed random variable, $W_T \\sim \\mathcal{N}(0, T)$. This exact solution is fundamental for calculating the pathwise error required for the strong convergence analysis.\n\n#### 1.2. The Euler-Maruyama Discretization\nThe Euler-Maruyama method is a numerical scheme for approximating the solution of an SDE. For a time interval $[0, T]$ discretized into $M$ steps of size $\\Delta t = T/M$, the scheme for the GBM SDE is given by the iterative formula:\n$$\nX_{n+1} = X_n + \\mu X_n \\Delta t + \\sigma X_n \\Delta W_{n+1}\n$$\nwhere $X_n$ is the approximation of $X_{t_n}$ at time $t_n = n\\Delta t$. The term $\\Delta W_{n+1} = W_{t_{n+1}} - W_{t_n}$ is an increment of the Wiener process, which is simulated as an independent random variable drawn from a normal distribution $\\mathcal{N}(0, \\Delta t)$. The terminal value of this approximation at time $T$ is denoted as $X_T^{\\Delta t}$.\n\n#### 1.3. Error Definitions and Convergence Rates\nThe analysis relies on two types of error metrics.\n-   The **strong error** measures the pathwise-average deviation between the numerical approximation and the exact solution. It is defined as the root-mean-square error:\n    $$\n    e_{\\text{strong}}(\\Delta t) = \\left( \\mathbb{E}\\left[ |X_T^{\\Delta t} - X_T|^2 \\right] \\right)^{1/2}\n    $$\n    The strong convergence rate $p_{\\text{strong}}$ is such that $e_{\\text{strong}}(\\Delta t) = \\mathcal{O}((\\Delta t)^{p_{\\text{strong}}})$. For the Euler-Maruyama method, the theoretical strong rate is $p_{\\text{strong}} = 0.5$.\n\n-   The **weak error** measures the error in the expectation of functions of the solution. For a given test function $\\varphi$, it is defined as:\n    $$\n    e_{\\text{weak}}(\\Delta t) = \\left| \\mathbb{E}\\left[\\varphi\\left(X_T^{\\Delta t}\\right)\\right] - \\mathbb{E}\\left[\\varphi\\left(X_T\\right)\\right] \\right|\n    $$\n    The weak convergence rate $p_{\\text{weak}}$ is such that $e_{\\text{weak}}(\\Delta t) = \\mathcal{O}((\\Delta t)^{p_{\\text{weak}}})$. For the Euler-Maruyama method, the theoretical weak rate is $p_{\\text{weak}} = 1.0$.\n\nFor this problem, the test functions are monomials $\\varphi(x) = x^k$. The exact expectation $\\mathbb{E}[\\varphi(X_T)] = \\mathbb{E}[X_T^k]$ can be calculated from the log-normal distribution of $X_T$. Since $\\ln(X_T) \\sim \\mathcal{N}\\left(\\ln(X_0) + (\\mu - \\frac{1}{2}\\sigma^2)T, \\sigma^2 T\\right)$, the $k$-th moment is:\n$$\n\\mathbb{E}[X_T^k] = X_0^k \\exp\\left( k\\mu T + \\frac{1}{2}k(k-1)\\sigma^2 T \\right)\n$$\nThis formula provides the exact value against which the numerical average $\\mathbb{E}[\\varphi(X_T^{\\Delta t})]$ is compared.\n\n### 2. Numerical Experiment Design\n\nThe convergence rates are estimated empirically from a numerical experiment.\n\n#### 2.1. Monte Carlo Simulation and Path Coupling\nWe generate $N$ independent sample paths to estimate the expectations. A crucial element for strong error estimation is **path coupling**. To ensure that the difference $|X_T^{\\Delta t} - X_T|$ is meaningful, both the approximate and exact solutions must be driven by the same realization of the underlying Brownian path $W_t$. We achieve this by generating a single set of Brownian increments on the finest grid, with $M_{\\max}$ steps. Let these fine increments be $\\{\\Delta W_i^{\\text{fine}}\\}_{i=1}^{M_{\\max}}$. A coarser grid with $M < M_{\\max}$ steps (where $M$ divides $M_{\\max}$) uses increments $\\Delta W_j^{\\text{coarse}}$ formed by summing blocks of fine increments:\n$$\n\\Delta W_j^{\\text{coarse}} = \\sum_{i=(j-1)S+1}^{jS} \\Delta W_i^{\\text{fine}}, \\quad \\text{where } S = M_{\\max} / M\n$$\nThe total Brownian motion at the final time, $W_T = \\sum_i \\Delta W_i$, is therefore identical for all discretization levels, enabling a valid path-by-path comparison.\n\n#### 2.2. Error Estimation\nThe expectations in the error definitions are approximated by Monte Carlo averages over the $N$ sample paths.\n-   The strong error is estimated by:\n    $$\n    \\hat{e}_{\\text{strong}}(\\Delta t) = \\left( \\frac{1}{N} \\sum_{j=1}^{N} \\left| X_{T, j}^{\\Delta t} - X_{T, j} \\right|^2 \\right)^{1/2}\n    $$\n    where $j$ indexes the Monte Carlo path.\n-   The weak error is estimated by:\n    $$\n    \\hat{e}_{\\text{weak}}(\\Delta t) = \\left| \\left( \\frac{1}{N} \\sum_{j=1}^{N} \\varphi(X_{T, j}^{\\Delta t}) \\right) - \\mathbb{E}[\\varphi(X_T)] \\right|\n    $$\n\n#### 2.3. Convergence Rate Calculation\nWe generate a sequence of time steps $\\{\\Delta t_\\ell = T/M_\\ell\\}$ for $M_\\ell \\in \\{4, 8, 16, 32, 64\\}$ and compute the corresponding error estimates $\\{\\hat{e}(\\Delta t_\\ell)\\}$. The convergence rate $p$ is determined by fitting the model $\\log \\hat{e}(\\Delta t_\\ell) \\approx a + p \\log \\Delta t_\\ell$. This is a linear regression problem for $(\\log \\Delta t_\\ell, \\log \\hat{e}(\\Delta t_\\ell))$. The slope $p$ of the best-fit line is the estimated convergence rate. This can be calculated using standard methods, such as a polynomial fit of degree $1$.\n\n### 3. Implementation\nThe implementation will follow these steps for each test case:\n1.  Set the parameters $X_0, \\mu, \\sigma, T, k, N$ and the random seed.\n2.  Generate $N \\times M_{\\max}$ standard normal random variables, scaled to represent the fine-grid Brownian increments $\\Delta W_i^{\\text{fine}}$.\n3.  For each of the $N$ paths, calculate the exact terminal value $X_T$ using the sum of all fine increments for $W_T$.\n4.  Calculate the exact moment $\\mathbb{E}[\\varphi(X_T)]$.\n5.  Iterate through the specified refinement levels $M \\in \\{4, 8, 16, 32, 64\\}$:\n    a. Construct the coarser Brownian increments by summing blocks of the fine increments.\n    b. Simulate the EM paths to time $T$ to get $X_T^{\\Delta t}$.\n    c. Compute and store the strong and weak error estimates for this $\\Delta t$.\n6.  Perform a linear regression on the log-log plot of errors versus time steps to find the slopes, which are the estimated strong and weak convergence rates.\n7.  The results from all test cases are collected and formatted into the required output string.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs and implements a numerical experiment to estimate strong and weak\n    convergence rates for the Euler-Maruyama method applied to the Geometric\n    Brownian Motion SDE.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (X0, mu, sigma, T, k, N, seed)\n        (1.0, 0.3, 0.5, 1.0, 1, 20000, 12345),\n        (2.0, 0.0, 0.8, 2.0, 2, 20000, 12346),\n        (1.5, -0.2, 1.2, 0.5, 1, 20000, 12347)\n    ]\n\n    # Levels of discretization (number of steps)\n    M_levels = [4, 8, 16, 32, 64]\n    M_max = 64\n\n    results = []\n    for case in test_cases:\n        X0, mu, sigma, T, k, N, seed = case\n        \n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # --- Monte Carlo Simulation Setup ---\n        \n        # Generate all Brownian increments for the finest grid (M_max)\n        # These are used to build increments for all coarser grids\n        dt_fine = T / M_max\n        fine_shocks = rng.normal(loc=0.0, scale=np.sqrt(dt_fine), size=(N, M_max))\n\n        # Calculate the exact solution X_T for each path\n        # W_T is the sum of all fine increments\n        W_T = fine_shocks.sum(axis=1)\n        X_T_exact = X0 * np.exp((mu - 0.5 * sigma**2) * T + sigma * W_T)\n\n        # Calculate the exact expectation for the weak error component\n        # E[X_T^k] = X0^k * exp(k*mu*T + 0.5*k*(k-1)*sigma^2*T)\n        exact_moment = (X0**k) * np.exp(k * mu * T + 0.5 * k * (k - 1) * (sigma**2) * T)\n\n        # Store errors and step sizes for regression\n        dts = []\n        strong_errors = []\n        weak_errors = []\n\n        # --- Loop over refinement levels ---\n        for M in M_levels:\n            dt = T / M\n            dts.append(dt)\n\n            # --- Path Generation (Euler-Maruyama) ---\n            \n            # Construct coarse Brownian increments from fine ones (path coupling)\n            # Sum blocks of fine_shocks to get shocks for the current grid size M\n            step_size = M_max // M\n            coarse_shocks = fine_shocks.reshape(N, M, step_size).sum(axis=2)\n\n            # Simulate paths using Euler-Maruyama\n            X_em = np.full(N, X0)\n            for i in range(M):\n                # The formula is X_{n+1} = X_n * (1 + mu*dt + sigma*dW)\n                X_em += mu * X_em * dt + sigma * X_em * coarse_shocks[:, i]\n            \n            X_T_em = X_em\n\n            # --- Error Calculation ---\n\n            # Strong error: (E[|X_T^EM - X_T_exact|^2])^0.5\n            strong_error = np.sqrt(np.mean((X_T_em - X_T_exact)**2))\n            strong_errors.append(strong_error)\n\n            # Weak error: |E[phi(X_T^EM)] - E[phi(X_T_exact)]|\n            # where phi(x) = x^k\n            em_moment = np.mean(X_T_em**k)\n            weak_error = np.abs(em_moment - exact_moment)\n            weak_errors.append(weak_error)\n\n        # --- Convergence Rate Estimation ---\n        \n        # Use linear regression on log-log data to find the slope (rate)\n        # log(error) = a + p * log(dt)\n        # np.polyfit(x, y, 1) returns [p, a]\n        \n        log_dts = np.log(dts)\n        \n        # Strong rate\n        log_strong_errors = np.log(strong_errors)\n        p_strong = np.polyfit(log_dts, log_strong_errors, 1)[0]\n        \n        # Weak rate\n        log_weak_errors = np.log(weak_errors)\n        p_weak = np.polyfit(log_dts, log_weak_errors, 1)[0]\n        \n        results.append([p_strong, p_weak])\n\n    # --- Final Output Formatting ---\n    # The format must be [[p_strong,1, p_weak,1], [p_strong,2, p_weak,2], [p_strong,3, p_weak,3]]\n    # Each float is rounded to three decimal places.\n    output_str = f\"[{', '.join([f'[{s:.3f}, {w:.3f}]' for s, w in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3067097"}]}