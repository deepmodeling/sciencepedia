{"hands_on_practices": [{"introduction": "A powerful way to build intuition for an abstract mathematical concept is to see it yield the same result as a more direct, concrete calculation. This exercise demonstrates the core principle of the Cameron-Martin theorem by computing the expectation of a functional of a shifted Brownian path in two distinct ways. By confirming that the sophisticated change-of-measure approach agrees with a straightforward computation using the properties of Gaussian distributions, you will gain a deeper appreciation for how the theorem elegantly captures the effect of deterministic shifts [@problem_id:3043120].", "problem": "Consider the classical Wiener space $C([0,T],\\mathbb{R})$ equipped with the Wiener measure, and let $W=(W_s)_{0\\leq s\\leq T}$ be a standard Brownian motion with $W_0=0$. Fix $T0$ and $t\\in(0,T]$. Let $h\\in\\mathcal{H}$ belong to the Cameron–Martin space, meaning that $h$ is absolutely continuous on $[0,T]$, satisfies $h(0)=0$, and has derivative $\\dot{h}\\in L^2([0,T])$. Define the functional $F:C([0,T],\\mathbb{R})\\to\\mathbb{R}$ by $F(x)=\\exp(\\lambda x(t))$ for a fixed $\\lambda\\in\\mathbb{R}$.\n\nUsing the Cameron–Martin theorem, express $\\mathbb{E}[F(W+h)]$ as an expectation under the Wiener measure weighted by the appropriate density involving $\\dot{h}$, and evaluate it explicitly. Independently, compute $\\mathbb{E}[F(W+h)]$ directly by recognizing the finite-dimensional marginal of $W$ under a deterministic shift $h$ and evaluating the resulting Gaussian integral. Confirm that both methods produce the same value and provide the final closed-form expression for $\\mathbb{E}[F(W+h)]$ in terms of $\\lambda$, $t$, and $h(t)$.\n\nYour final answer must be a single closed-form analytic expression.", "solution": "The user wants me to solve a problem on the Cameron-Martin theorem. I'll start by validating the user's problem statement.\n\n### Step 1: Extract Givens\n- **Space and Measure**: The classical Wiener space $C([0,T],\\mathbb{R})$ with the Wiener measure.\n- **Stochastic Process**: $W = (W_s)_{0\\leq s\\leq T}$ is a standard Brownian motion with $W_0=0$.\n- **Constants**: $T0$, $t \\in (0,T]$, $\\lambda \\in \\mathbb{R}$.\n- **Shift Function**: $h \\in \\mathcal{H}$, where $\\mathcal{H}$ is the Cameron-Martin space. This implies $h$ is absolutely continuous on $[0,T]$, $h(0)=0$, and its weak derivative $\\dot{h}$ is in $L^2([0,T])$. The norm is $\\|\\dot{h}\\|^2_{L^2} = \\int_0^T |\\dot{h}(s)|^2 ds  \\infty$.\n- **Functional**: $F:C([0,T],\\mathbb{R})\\to\\mathbb{R}$ is defined by $F(x) = \\exp(\\lambda x(t))$.\n- **Tasks**:\n    1. Compute $\\mathbb{E}[F(W+h)]$ using the Cameron-Martin theorem, by expressing it as an expectation weighted by a density.\n    2. Compute $\\mathbb{E}[F(W+h)]$ directly by evaluating the resulting Gaussian integral.\n    3. Confirm that both methods yield the same result.\n    4. Provide the final closed-form expression in terms of $\\lambda$, $t$, and $h(t)$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is set within the rigorous mathematical framework of stochastic calculus and the theory of Gaussian measures. All concepts—Wiener space, Brownian motion, the Cameron-Martin space, and Girsanov's theorem—are fundamental and well-established. The problem is scientifically and mathematically sound.\n- **Well-Posed**: The problem is clearly stated with all necessary definitions and conditions. The functional is well-defined, the shift $h$ belongs to the appropriate space $\\mathcal{H}$, and the goal is to compute a specific expectation. A unique, stable, and meaningful solution exists.\n- **Objective**: The problem is stated in precise, formal mathematical language, free from any subjectivity or ambiguity.\n- **Other criteria**: The problem is not metaphorical, incomplete, contradictory, unrealistic, or trivial. It is a standard, yet substantive, exercise in applying the Cameron-Martin/Girsanov theorem.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will now proceed with the solution.\n\nThe problem asks for the computation of $\\mathbb{E}[F(W+h)] = \\mathbb{E}[\\exp(\\lambda (W_t+h(t)))]$ using two different methods. Let $\\mu_W$ denote the Wiener measure, so that $\\mathbb{E}[\\cdot]$ denotes expectation with respect to $\\mu_W$.\n\n### Method 1: Using the Cameron-Martin Theorem\n\nThe Cameron-Martin theorem provides a relationship between the Wiener measure $\\mu_W$ and the measure of a deterministically shifted Brownian motion. Let $h \\in \\mathcal{H}$ be a function in the Cameron-Martin space. The law of the process $W+h$, denoted $\\mu_{W+h}$, is absolutely continuous with respect to the law of $W$, $\\mu_W$. The Radon-Nikodym derivative is given by:\n$$\n\\frac{d\\mu_{W+h}}{d\\mu_W}(W) = \\exp\\left( \\int_0^T \\dot{h}(s) dW_s - \\frac{1}{2} \\int_0^T |\\dot{h}(s)|^2 ds \\right)\n$$\nWe want to compute $\\mathbb{E}[F(W+h)]$. By definition, this is an expectation under the measure $\\mu_W$:\n$$\n\\mathbb{E}[F(W+h)] = \\int_{C([0,T])} F(\\omega+h) d\\mu_W(\\omega)\n$$\nWe can perform a change of variables in this pathspace integral. Let $\\phi = \\omega+h$. Then $\\omega = \\phi-h$. The integral becomes:\n$$\n\\int_{C([0,T])} F(\\phi) d\\mu_W(\\phi-h)\n$$\nThe measure defined by $\\nu(A) = \\mu_W(A-h)$ is precisely the law of the process $W+h$, which we denote $\\mu_{W+h}$. Thus, the integral is equivalent to an expectation of $F(\\phi)$ under the measure $\\mu_{W+h}$:\n$$\n\\int_{C([0,T])} F(\\phi) d\\mu_{W+h}(\\phi) = \\mathbb{E}_{\\mu_{W+h}}[F(W)]\n$$\nNow, we can relate this expectation back to an expectation under the Wiener measure $\\mu_W$ using the Radon-Nikodym derivative:\n$$\n\\mathbb{E}_{\\mu_{W+h}}[F(W)] = \\mathbb{E}_{\\mu_W}\\left[ F(W) \\frac{d\\mu_{W+h}}{d\\mu_W}(W) \\right]\n$$\nThis gives us the identity:\n$$\n\\mathbb{E}[F(W+h)] = \\mathbb{E}\\left[ F(W) \\exp\\left( \\int_0^T \\dot{h}(s) dW_s - \\frac{1}{2} \\int_0^T |\\dot{h}(s)|^2 ds \\right) \\right]\n$$\nThis expression conforms to the problem's request to write the expectation as one under the Wiener measure weighted by a density. Now we evaluate it. Substituting $F(W) = \\exp(\\lambda W_t)$:\n$$\n\\mathbb{E}[F(W+h)] = \\mathbb{E}\\left[ \\exp(\\lambda W_t) \\exp\\left( \\int_0^T \\dot{h}(s) dW_s - \\frac{1}{2} \\int_0^T |\\dot{h}(s)|^2 ds \\right) \\right]\n$$\nWe can factor out the deterministic term from the expectation:\n$$\n\\mathbb{E}[F(W+h)] = \\exp\\left( - \\frac{1}{2} \\int_0^T |\\dot{h}(s)|^2 ds \\right) \\mathbb{E}\\left[ \\exp\\left( \\lambda W_t + \\int_0^T \\dot{h}(s) dW_s \\right) \\right]\n$$\nThe term in the exponent of the expectation is a Gaussian random variable. We can write $W_t = \\int_0^t 1 \\, dW_s = \\int_0^T 1_{[0,t]}(s) dW_s$. Let the random variable be $X$:\n$$\nX = \\lambda W_t + \\int_0^T \\dot{h}(s) dW_s = \\int_0^T (\\lambda 1_{[0,t]}(s) + \\dot{h}(s)) dW_s\n$$\nSince $X$ is an Itô integral of a deterministic square-integrable function, it is a zero-mean Gaussian random variable, $X \\sim N(0,\\sigma_X^2)$. Its variance is given by the Itô isometry:\n$$\n\\sigma_X^2 = \\mathbb{E}[X^2] = \\int_0^T (\\lambda 1_{[0,t]}(s) + \\dot{h}(s))^2 ds\n$$\nExpanding the square:\n$$\n\\sigma_X^2 = \\int_0^T \\left( \\lambda^2 1_{[0,t]}(s)^2 + 2\\lambda 1_{[0,t]}(s)\\dot{h}(s) + |\\dot{h}(s)|^2 \\right) ds\n$$\n$$\n\\sigma_X^2 = \\lambda^2 \\int_0^t ds + 2\\lambda \\int_0^t \\dot{h}(s) ds + \\int_0^T |\\dot{h}(s)|^2 ds\n$$\nSince $h$ is absolutely continuous and $h(0)=0$, we have $\\int_0^t \\dot{h}(s) ds = h(t) - h(0) = h(t)$.\n$$\n\\sigma_X^2 = \\lambda^2 t + 2\\lambda h(t) + \\int_0^T |\\dot{h}(s)|^2 ds\n$$\nFor a Gaussian random variable $X \\sim N(0, \\sigma_X^2)$, the expectation of its exponential is $\\mathbb{E}[\\exp(X)] = \\exp(\\frac{1}{2}\\sigma_X^2)$.\n$$\n\\mathbb{E}[\\exp(X)] = \\exp\\left( \\frac{1}{2} \\left( \\lambda^2 t + 2\\lambda h(t) + \\int_0^T |\\dot{h}(s)|^2 ds \\right) \\right) = \\exp\\left( \\frac{1}{2}\\lambda^2 t + \\lambda h(t) + \\frac{1}{2}\\int_0^T |\\dot{h}(s)|^2 ds \\right)\n$$\nSubstituting this back into the expression for $\\mathbb{E}[F(W+h)]$:\n$$\n\\mathbb{E}[F(W+h)] = \\exp\\left( - \\frac{1}{2} \\int_0^T |\\dot{h}(s)|^2 ds \\right) \\times \\exp\\left( \\frac{1}{2}\\lambda^2 t + \\lambda h(t) + \\frac{1}{2}\\int_0^T |\\dot{h}(s)|^2 ds \\right)\n$$\nThe integral terms cancel, yielding the final result for the first method:\n$$\n\\mathbb{E}[F(W+h)] = \\exp\\left( \\lambda h(t) + \\frac{1}{2}\\lambda^2 t \\right)\n$$\n\n### Method 2: Direct Computation\n\nThis method involves a direct evaluation of the expectation $\\mathbb{E}[F(W+h)]$.\n$$\n\\mathbb{E}[F(W+h)] = \\mathbb{E}[\\exp(\\lambda (W_t+h(t)))]\n$$\nWe can separate the exponential term:\n$$\n\\mathbb{E}[F(W+h)] = \\mathbb{E}[\\exp(\\lambda W_t) \\exp(\\lambda h(t))]\n$$\nSince $h$ is a deterministic function, for a fixed $t$, $h(t)$ is a constant. Thus, $\\exp(\\lambda h(t))$ is a deterministic constant and can be factored out of the expectation:\n$$\n\\mathbb{E}[F(W+h)] = \\exp(\\lambda h(t)) \\mathbb{E}[\\exp(\\lambda W_t)]\n$$\nThe problem states that $W$ is a standard Brownian motion. For any fixed time $t  0$, the random variable $W_t$ follows a normal distribution with mean $0$ and variance $t$, i.e., $W_t \\sim N(0,t)$.\nThe term $\\mathbb{E}[\\exp(\\lambda W_t)]$ is the moment-generating function (MGF) of the random variable $W_t$ evaluated at $\\lambda$. The MGF for a general Gaussian random variable $Y \\sim N(\\mu, \\sigma^2)$ is $M_Y(k) = \\mathbb{E}[\\exp(kY)] = \\exp(k\\mu + \\frac{1}{2}k^2\\sigma^2)$.\nFor $W_t$, we have $\\mu=0$ and $\\sigma^2=t$. Applying the MGF formula with $k=\\lambda$:\n$$\n\\mathbb{E}[\\exp(\\lambda W_t)] = \\exp\\left(\\lambda \\cdot 0 + \\frac{1}{2}\\lambda^2 t\\right) = \\exp\\left(\\frac{1}{2}\\lambda^2 t\\right)\n$$\nSubstituting this back into our expression for $\\mathbb{E}[F(W+h)]$:\n$$\n\\mathbb{E}[F(W+h)] = \\exp(\\lambda h(t)) \\cdot \\exp\\left(\\frac{1}{2}\\lambda^2 t\\right)\n$$\nCombining the exponents gives the final result for the second method:\n$$\n\\mathbb{E}[F(W+h)] = \\exp\\left( \\lambda h(t) + \\frac{1}{2}\\lambda^2 t \\right)\n$$\n\n### Confirmation\nBoth Method 1 (using the Cameron-Martin theorem) and Method 2 (direct computation) yield the identical result:\n$$\n\\mathbb{E}[F(W+h)] = \\exp\\left( \\lambda h(t) + \\frac{1}{2}\\lambda^2 t \\right)\n$$\nThis confirms the correctness of the derivation. The final closed-form expression depends only on $\\lambda$, $t$, and the value of the shift function $h$ at time $t$.", "answer": "$$\\boxed{\\exp\\left(\\lambda h(t) + \\frac{1}{2}t\\lambda^{2}\\right)}$$", "id": "3043120"}, {"introduction": "At the heart of the Cameron-Martin theorem lies the Radon-Nikodym derivative, a density that quantifies how the probability measure changes when a Brownian path is shifted. This practice guides you through the explicit calculation of this density for a simple linear shift, $h(t) = at$. By computing the new expectation of the process under the modified measure, you will directly verify the central result of Girsanov's theorem: the original Brownian motion, under the new measure, behaves like a Brownian motion with a constant drift [@problem_id:3043135].", "problem": "Let $\\left(\\Omega,\\mathcal{F},\\left(\\mathcal{F}_{t}\\right)_{t\\in[0,T]},\\mathbb{P}\\right)$ be a filtered probability space supporting a standard Brownian motion $W=\\left(W_{t}\\right)_{t\\in[0,T]}$, where $T0$ is fixed. The Cameron-Martin space $\\mathsf{H}$ over $[0,T]$ is the set of absolutely continuous functions $h:[0,T]\\to\\mathbb{R}$ with square-integrable derivative, equipped with the inner product $\\langle h,g\\rangle_{\\mathsf{H}}=\\int_{0}^{T}\\dot{h}(s)\\dot{g}(s)\\,\\mathrm{d}s$. For $h\\in\\mathsf{H}$, define the exponential functional\n$$\nZ_{h}=\\exp\\!\\left(\\int_{0}^{T}\\dot{h}(s)\\,\\mathrm{d}W_{s}-\\frac{1}{2}\\int_{0}^{T}\\left|\\dot{h}(s)\\right|^{2}\\,\\mathrm{d}s\\right),\n$$\nand the tilted probability measure $\\mathbb{P}^{h}$ on $\\left(\\Omega,\\mathcal{F}\\right)$ by the Radon-Nikodym derivative $\\frac{\\mathrm{d}\\mathbb{P}^{h}}{\\mathrm{d}\\mathbb{P}}=Z_{h}$. Consider the specific element $h(t)=a\\,t$ with $a\\in\\mathbb{R}$ and $t\\in[0,T]$.\n\nStarting from the above definitions and standard properties of Brownian motion and jointly Gaussian random variables, compute $Z_{h}$ explicitly and evaluate $\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right]$. Then use the relationship $\\mathbb{E}^{\\mathbb{P}^{h}}\\!\\left[W_{t}\\right]=\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right]$ to confirm that, under the tilted measure $\\mathbb{P}^{h}$, the process $W_{t}$ has mean $a\\,t$ for $t\\in[0,T]$.\n\nProvide your final answer as a single row matrix whose first entry is your expression for $Z_{h}$ and whose second entry is the value of $\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right]$. No rounding is required.", "solution": "The user wants me to solve a problem related to Cameron-Martin theory and Girsanov's theorem.\n\nHere's a plan:\n1.  **Validate the problem statement.**\n    *   **Step 1: Extract Givens.**\n        *   Filtered probability space: $\\left(\\Omega,\\mathcal{F},\\left(\\mathcal{F}_{t}\\right)_{t\\in[0,T]},\\mathbb{P}\\right)$\n        *   Standard Brownian motion: $W=\\left(W_{t}\\right)_{t\\in[0,T]}$\n        *   Time horizon: $T0$\n        *   Cameron-Martin space $\\mathsf{H}$: set of $h:[0,T]\\to\\mathbb{R}$ such that $h$ is absolutely continuous and $\\dot{h} \\in L^2([0,T])$.\n        *   Inner product on $\\mathsf{H}$: $\\langle h,g\\rangle_{\\mathsf{H}}=\\int_{0}^{T}\\dot{h}(s)\\dot{g}(s)\\,\\mathrm{d}s$.\n        *   Exponential functional for $h \\in \\mathsf{H}$: $Z_{h}=\\exp\\!\\left(\\int_{0}^{T}\\dot{h}(s)\\,\\mathrm{d}W_{s}-\\frac{1}{2}\\int_{0}^{T}\\left|\\dot{h}(s)\\right|^{2}\\,\\mathrm{d}s\\right)$.\n        *   Tilted probability measure: $\\mathbb{P}^{h}$ with Radon-Nikodym derivative $\\frac{\\mathrm{d}\\mathbb{P}^{h}}{\\mathrm{d}\\mathbb{P}}=Z_{h}$.\n        *   Specific element: $h(t)=a\\,t$ for $a\\in\\mathbb{R}$ and $t\\in[0,T]$.\n        *   Task 1: Compute $Z_h$ explicitly for $h(t)=at$.\n        *   Task 2: Evaluate $\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right]$.\n        *   Task 3: Use the relationship $\\mathbb{E}^{\\mathbb{P}^{h}}\\!\\left[W_{t}\\right]=\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right]$ to confirm that under $\\mathbb{P}^h$, the process $W_t$ has mean $at$.\n\n    *   **Step 2: Validate Using Extracted Givens.**\n        *   **Scientifically Grounded?** Yes, this is a standard setup for Girsanov's theorem and the Cameron-Martin theorem in stochastic calculus. The definitions are correct.\n        *   **Well-Posed?** Yes, the problem asks for specific computations based on well-defined mathematical objects. The steps are logical and lead to a unique solution.\n        *   **Objective?** Yes, the language is formal and precise.\n        *   **Flaw Check:**\n            1.  **Scientific/Factual Unsoundness?** No. All definitions are standard in stochastic calculus.\n            2.  **Non-Formalizable/Irrelevant?** No. The problem is directly an application of Cameron-Martin space and shifts.\n            3.  **Incomplete/Contradictory?** No. All necessary information is provided. $h(t)=at$ is in $\\mathsf{H}$ since it's absolutely continuous and its derivative $\\dot{h}(t)=a$ is constant, so it's square-integrable on a finite interval $[0,T]$.\n            4.  **Unrealistic/Infeasible?** No. This is a purely mathematical problem.\n            5.  **Ill-Posed?** No. The tasks are well-defined.\n            6.  **Pseudo-Profound/Trivial?** No. It's a standard but non-trivial exercise that tests understanding of Girsanov's theorem.\n            7.  **Outside Scientific Verifiability?** No. The calculations can be verified.\n\n    *   **Step 3: Verdict and Action.**\n        *   The problem is **valid**. I will proceed to the solution.\n\n2.  **Solve the problem.**\n    *   **Part 1: Compute $Z_h$ explicitly for $h(t)=at$.**\n        *   First, find the derivative of $h(t)$.\n            *   $h(t) = at$.\n            *   $\\dot{h}(t) = a$.\n        *   Now, substitute this into the definition of $Z_h$.\n            *   $Z_{h}=\\exp\\!\\left(\\int_{0}^{T}a\\,\\mathrm{d}W_{s}-\\frac{1}{2}\\int_{0}^{T}a^{2}\\,\\mathrm{d}s\\right)$.\n        *   Evaluate the integrals.\n            *   The stochastic integral is $\\int_{0}^{T}a\\,\\mathrm{d}W_{s} = a \\int_{0}^{T}\\mathrm{d}W_{s} = a (W_T - W_0) = a W_T$ (since $W_0=0$ a.s.).\n            *   The ordinary integral is $\\int_{0}^{T}a^{2}\\,\\mathrm{d}s = a^2 \\int_{0}^{T} \\mathrm{d}s = a^2 T$.\n        *   Combine these to get the expression for $Z_h$.\n            *   $Z_h = \\exp(a W_T - \\frac{1}{2} a^2 T)$.\n            *   This is a Doléans-Dade exponential, which is a martingale. Specifically, $Z_h = \\mathcal{E}(aW)_T$.\n\n    *   **Part 2: Evaluate $\\mathbb{E}[W_t Z_h]$.**\n        *   We need to compute $\\mathbb{E}[W_t \\exp(a W_T - \\frac{1}{2} a^2 T)]$.\n        *   Let's pull out the constant term: $\\exp(-\\frac{1}{2} a^2 T) \\mathbb{E}[W_t \\exp(a W_T)]$.\n        *   The random variables are $W_t$ and $W_T$. They are jointly Gaussian.\n            *   $\\mathbb{E}[W_t] = 0$.\n            *   $\\mathbb{E}[W_T] = 0$.\n            *   $\\text{Var}(W_t) = t$.\n            *   $\\text{Var}(W_T) = T$.\n            *   $\\text{Cov}(W_t, W_T) = \\mathbb{E}[W_t W_T] = \\min(t,T) = t$ since $t \\in [0,T]$.\n        *   So the vector $(W_t, W_T)$ is a bivariate normal distribution with mean vector $(0,0)$ and covariance matrix $\\Sigma = \\begin{pmatrix} t  t \\\\ t  T \\end{pmatrix}$.\n        *   We need to calculate $\\mathbb{E}[W_t \\exp(a W_T)]$.\n        *   Let $X = W_t$ and $Y = W_T$. We want to find $\\mathbb{E}[X \\exp(a Y)]$.\n        *   A general property of jointly Gaussian variables $(X,Y)$ is that $\\mathbb{E}[X \\exp(sY)] = (\\mathbb{E}[X] + s \\text{Cov}(X,Y)) \\exp(s \\mathbb{E}[Y] + \\frac{1}{2} s^2 \\text{Var}(Y))$.\n        *   Let's apply this formula.\n            *   $X = W_t$, $Y = W_T$, $s=a$.\n            *   $\\mathbb{E}[W_t] = 0$.\n            *   $\\mathbb{E}[W_T] = 0$.\n            *   $\\text{Cov}(W_t, W_T) = t$.\n            *   $\\text{Var}(W_T) = T$.\n        *   Substituting these values into the formula:\n            *   $\\mathbb{E}[W_t \\exp(a W_T)] = (0 + a \\cdot t) \\exp(a \\cdot 0 + \\frac{1}{2} a^2 T) = at \\exp(\\frac{1}{2} a^2 T)$.\n        *   Now, let's put it all together for $\\mathbb{E}[W_t Z_h]$.\n            *   $\\mathbb{E}[W_t Z_h] = \\mathbb{E}[W_t \\exp(a W_T - \\frac{1}{2} a^2 T)] = \\exp(-\\frac{1}{2} a^2 T) \\mathbb{E}[W_t \\exp(a W_T)]$.\n            *   $\\mathbb{E}[W_t Z_h] = \\exp(-\\frac{1}{2} a^2 T) \\left( at \\exp(\\frac{1}{2} a^2 T) \\right)$.\n            *   $\\mathbb{E}[W_t Z_h] = at$.\n\n    *   **Part 3: Confirm the mean under $\\mathbb{P}^h$.**\n        *   The problem states $\\mathbb{E}^{\\mathbb{P}^{h}}\\!\\left[W_{t}\\right]=\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right]$.\n        *   From Part 2, we found $\\mathbb{E}\\!\\left[W_{t}\\,Z_{h}\\right] = at$.\n        *   Therefore, $\\mathbb{E}^{\\mathbb{P}^{h}}\\!\\left[W_{t}\\right] = at$.\n        *   This confirms that under the tilted measure $\\mathbb{P}^h$, the process $W_t$ has mean $at$ for $t \\in [0,T]$.\n        *   This is consistent with Girsanov's theorem, which states that the process $\\tilde{W}_t = W_t - \\int_0^t \\dot{h}(s) ds$ is a Brownian motion under $\\mathbb{P}^h$.\n            *   In our case, $\\dot{h}(s) = a$, so $\\int_0^t \\dot{h}(s) ds = \\int_0^t a ds = at$.\n            *   So, $\\tilde{W}_t = W_t - at$ is a $\\mathbb{P}^h$-Brownian motion.\n            *   This means $\\mathbb{E}^{\\mathbb{P}^h}[\\tilde{W}_t] = 0$.\n            *   $\\mathbb{E}^{\\mathbb{P}^h}[W_t - at] = 0$.\n            *   $\\mathbb{E}^{\\mathbb{P}^h}[W_t] - at = 0$.\n            *   $\\mathbb{E}^{\\mathbb{P}^h}[W_t] = at$.\n        *   The calculation confirms the theorem. The problem asks me to show this, so the calculation is the core part of the answer.\n\n3.  **Finalize the output.**\n    *   The solution part will contain the detailed derivation.\n        *   First, calculate $Z_h$.\n        *   Second, calculate $\\mathbb{E}[W_t Z_h]$ using the joint normality of $(W_t, W_T)$.\n        *   Third, use the result to find $\\mathbb{E}^{\\mathbb{P}^h}[W_t]$ and comment on its meaning.\n    *   The final answer will be a row matrix with two entries:\n        *   Entry 1: $Z_h = \\exp(aW_T - \\frac{1}{2}a^2T)$.\n        *   Entry 2: $\\mathbb{E}[W_t Z_h] = at$.\n    *   I need to be very careful with the mandatory LaTeX formatting. Every symbol, number, variable must be in LaTeX.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\exp(aW_{T} - \\frac{1}{2}a^{2}T)  at\n\\end{pmatrix}\n}\n$$", "id": "3043135"}, {"introduction": "The true power of Cameron-Martin shifts is revealed when they are applied not just to Brownian motion itself, but to processes defined by stochastic differential equations (SDEs). This exercise explores the effect of a shift on the solution to the Ornstein-Uhlenbeck SDE, a fundamental model for mean-reverting processes. By solving the SDE with a shifted driver, you will discover that the deterministic shift only alters the mean of the solution, leaving its variance unchanged, a principle with significant implications for control theory and financial modeling [@problem_id:3043093].", "problem": "Let $\\{W_t\\}_{t \\geq 0}$ be a standard Brownian motion and consider the Ornstein–Uhlenbeck stochastic differential equation (SDE), defined as\n$$\ndX_t=-\\theta X_t\\,dt+dW_t,\\qquad X_0=x_0,\n$$\nwhere $\\theta0$ and $x_0 \\in \\mathbb{R}$ are deterministic constants. On the time interval $[0,t]$, the Cameron–Martin space (CM) consists of all absolutely continuous functions $h:[0,t]\\to\\mathbb{R}$ with $h(0)=0$ and derivative $\\dot{h}\\in L^2([0,t])$. Consider the Cameron–Martin shift $h(s)=a s$ with $a\\in\\mathbb{R}$, which belongs to this space. Define the shifted driver $W_s^{(h)}=W_s+h(s)$, and let $X_s^{(h)}$ be the solution to the SDE driven by $W^{(h)}$:\n$$\ndX_s^{(h)}=-\\theta X_s^{(h)}\\,ds+dW_s^{(h)},\\qquad X_0^{(h)}=x_0.\n$$\nStarting from fundamental properties of Itô integrals (zero mean and Itô isometry) and the integrating factor method for linear SDEs, derive closed-form expressions for the expectation $\\mathbb{E}[X_t^{(h)}]$ and the variance $\\mathrm{Var}(X_t^{(h)})$ in terms of $\\theta$, $a$, $t$, and $x_0$. Express your final answer as a row matrix with the first entry equal to $\\mathbb{E}[X_t^{(h)}]$ and the second entry equal to $\\mathrm{Var}(X_t^{(h)})$.", "solution": "The problem statement is a valid exercise in stochastic calculus. It is scientifically grounded, well-posed, objective, and contains all necessary information to derive a unique solution without any contradictions. We may therefore proceed with the derivation.\n\nThe problem asks for the expectation $\\mathbb{E}[X_t^{(h)}]$ and variance $\\mathrm{Var}(X_t^{(h)})$ of a process $X_t^{(h)}$ governed by a stochastic differential equation (SDE) with a shifted driver. Let $\\{W_t\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion.\n\nThe SDE for the shifted process $X_s^{(h)}$ is given by:\n$$\ndX_s^{(h)} = -\\theta X_s^{(h)}\\,ds + dW_s^{(h)}, \\quad X_0^{(h)} = x_0\n$$\nwhere $\\theta  0$, $x_0 \\in \\mathbb{R}$, and the shifted driver is $W_s^{(h)} = W_s + h(s)$. The Cameron-Martin shift is specified as $h(s) = a s$ for some constant $a \\in \\mathbb{R}$.\n\nFirst, we express the differential $dW_s^{(h)}$ in terms of the original Brownian motion $W_s$. Since $h(s)$ is a differentiable function of time, its differential is $dh(s) = \\dot{h}(s)ds$. For $h(s) = as$, the derivative is $\\dot{h}(s) = a$.\nThus, we have:\n$$\ndW_s^{(h)} = d(W_s + as) = dW_s + a\\,ds\n$$\nSubstituting this into the SDE for $X_s^{(h)}$ yields:\n$$\ndX_s^{(h)} = -\\theta X_s^{(h)}\\,ds + (dW_s + a\\,ds)\n$$\nRearranging the terms, we obtain a linear SDE in standard form:\n$$\ndX_s^{(h)} + \\theta X_s^{(h)}\\,ds = a\\,ds + dW_s\n$$\nThis is a linear first-order differential equation, which can be solved using an integrating factor. Let the integrating factor be $I_s = \\exp(\\int_0^s \\theta \\,du) = \\exp(\\theta s)$. Multiplying the SDE by $I_s = \\exp(\\theta s)$:\n$$\n\\exp(\\theta s)dX_s^{(h)} + \\theta \\exp(\\theta s) X_s^{(h)}\\,ds = a \\exp(\\theta s)\\,ds + \\exp(\\theta s)dW_s\n$$\nThe left-hand side is, by the product rule for Itô processes (applied to the deterministic function $\\exp(\\theta s)$ and the process $X_s^{(h)}$), the differential of the product $\\exp(\\theta s)X_s^{(h)}$:\n$$\nd(\\exp(\\theta s)X_s^{(h)}) = \\exp(\\theta s)dX_s^{(h)} + \\theta \\exp(\\theta s) X_s^{(h)}\\,ds\n$$\nTherefore, our equation simplifies to:\n$$\nd(\\exp(\\theta s)X_s^{(h)}) = a \\exp(\\theta s)\\,ds + \\exp(\\theta s)dW_s\n$$\nWe integrate both sides from $s=0$ to $s=t$:\n$$\n\\int_0^t d(\\exp(\\theta s)X_s^{(h)}) = \\int_0^t a \\exp(\\theta s)\\,ds + \\int_0^t \\exp(\\theta s)dW_s\n$$\nEvaluating the integrals gives:\n$$\n\\exp(\\theta t)X_t^{(h)} - \\exp(0)X_0^{(h)} = a \\left[\\frac{\\exp(\\theta s)}{\\theta}\\right]_0^t + \\int_0^t \\exp(\\theta s)dW_s\n$$\nUsing the initial condition $X_0^{(h)} = x_0$ and evaluating the definite integral:\n$$\n\\exp(\\theta t)X_t^{(h)} - x_0 = \\frac{a}{\\theta}(\\exp(\\theta t) - 1) + \\int_0^t \\exp(\\theta s)dW_s\n$$\nTo obtain the explicit solution for $X_t^{(h)}$, we multiply by $\\exp(-\\theta t)$:\n$$\nX_t^{(h)} = x_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t)) + \\int_0^t \\exp(-\\theta(t-s))dW_s\n$$\nThis expression provides the closed-form solution for the process $X_t^{(h)}$. We now proceed to compute its expectation and variance.\n\n**Expectation $\\mathbb{E}[X_t^{(h)}]$**\nWe take the expectation of the solution for $X_t^{(h)}$. By linearity of expectation:\n$$\n\\mathbb{E}[X_t^{(h)}] = \\mathbb{E}\\left[x_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t)) + \\int_0^t \\exp(-\\theta(t-s))dW_s\\right]\n$$\nThe terms $x_0 \\exp(-\\theta t)$ and $\\frac{a}{\\theta}(1 - \\exp(-\\theta t))$ are deterministic. The expectation of a constant is the constant itself. The third term is an Itô integral with a deterministic integrand, $f(s,t) = \\exp(-\\theta(t-s))$. A fundamental property of Itô integrals is that they have zero mean:\n$$\n\\mathbb{E}\\left[\\int_0^t f(s)dW_s\\right] = 0\n$$\nApplying these facts, we get:\n$$\n\\mathbb{E}[X_t^{(h)}] = x_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t)) + 0\n$$\nThus, the expectation is:\n$$\n\\mathbb{E}[X_t^{(h)}] = x_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t))\n$$\n\n**Variance $\\mathrm{Var}(X_t^{(h)}]$**\nThe variance of a random variable $Y$ is defined as $\\mathrm{Var}(Y) = \\mathbb{E}[(Y - \\mathbb{E}[Y])^2]$.\nFrom our previous results, we can write:\n$$\nX_t^{(h)} - \\mathbb{E}[X_t^{(h)}] = \\int_0^t \\exp(-\\theta(t-s))dW_s\n$$\nTherefore, the variance is:\n$$\n\\mathrm{Var}(X_t^{(h)}) = \\mathrm{Var}\\left(x_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t)) + \\int_0^t \\exp(-\\theta(t-s))dW_s\\right)\n$$\nSince the first two terms are deterministic, they do not contribute to the variance. Hence:\n$$\n\\mathrm{Var}(X_t^{(h)}) = \\mathrm{Var}\\left(\\int_0^t \\exp(-\\theta(t-s))dW_s\\right)\n$$\nThe variance of a zero-mean random variable is the expectation of its square. So we need to compute:\n$$\n\\mathbb{E}\\left[\\left(\\int_0^t \\exp(-\\theta(t-s))dW_s\\right)^2\\right]\n$$\nWe now apply the Itô isometry property, which states that for a deterministic square-integrable function $f(s)$:\n$$\n\\mathbb{E}\\left[\\left(\\int_0^t f(s)dW_s\\right)^2\\right] = \\int_0^t f(s)^2 ds\n$$\nIn our case, the integrand is $f(s) = \\exp(-\\theta(t-s))$. Squaring it gives:\n$$\nf(s)^2 = (\\exp(-\\theta(t-s)))^2 = \\exp(-2\\theta(t-s))\n$$\nNow we integrate this squared function from $0$ to $t$:\n$$\n\\mathrm{Var}(X_t^{(h)}) = \\int_0^t \\exp(-2\\theta(t-s))\\,ds = \\int_0^t \\exp(-2\\theta t)\\exp(2\\theta s)\\,ds\n$$\nThe term $\\exp(-2\\theta t)$ is constant with respect to the integration variable $s$:\n$$\n\\mathrm{Var}(X_t^{(h)}) = \\exp(-2\\theta t) \\int_0^t \\exp(2\\theta s)\\,ds\n$$\nEvaluating the integral:\n$$\n\\int_0^t \\exp(2\\theta s)\\,ds = \\left[\\frac{\\exp(2\\theta s)}{2\\theta}\\right]_0^t = \\frac{\\exp(2\\theta t) - \\exp(0)}{2\\theta} = \\frac{\\exp(2\\theta t) - 1}{2\\theta}\n$$\nSubstituting this back into the expression for the variance:\n$$\n\\mathrm{Var}(X_t^{(h)}) = \\exp(-2\\theta t) \\left( \\frac{\\exp(2\\theta t) - 1}{2\\theta} \\right) = \\frac{\\exp(-2\\theta t)\\exp(2\\theta t) - \\exp(-2\\theta t)}{2\\theta} = \\frac{1 - \\exp(-2\\theta t)}{2\\theta}\n$$\nThe variance is independent of the shift parameter $a$ and the initial condition $x_0$, which is expected as these deterministic components only affect the mean of the process.\n\nThe final expressions are:\nExpectation: $\\mathbb{E}[X_t^{(h)}] = x_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t))$\nVariance: $\\mathrm{Var}(X_t^{(h)}) = \\frac{1 - \\exp(-2\\theta t)}{2\\theta}$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx_0 \\exp(-\\theta t) + \\frac{a}{\\theta}(1 - \\exp(-\\theta t))  \\frac{1 - \\exp(-2\\theta t)}{2\\theta}\n\\end{pmatrix}\n}\n$$", "id": "3043093"}]}