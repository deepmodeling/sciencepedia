{"hands_on_practices": [{"introduction": "To bridge the gap between abstract theory and practical application, we begin with a foundational exercise. This practice focuses on one of the simplest non-trivial functionals of Brownian motion, $F = W_T^2$. By explicitly calculating the Malliavin derivative and the resulting Clark-Ocone integrand, you will not only apply the core mechanics of the formula but also verify the crucial isometry that links the variance of $F$ to the expected norm of its integrand. This exercise provides a concrete check of your understanding and builds a solid base for more complex problems [@problem_id:3079912].", "problem": "Let $\\{W_t\\}_{t \\in [0,T]}$ be a standard Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t \\in [0,T]},\\mathbb{P})$ satisfying the usual conditions, and let $F := W_T^2 \\in L^2(\\Omega,\\mathcal{F}_T,\\mathbb{P})$. Consider the Malliavin derivative process $\\{D_t F\\}_{t \\in [0,T]}$, defined so that $D_t W_T = \\mathbf{1}_{\\{t \\leq T\\}}$ and the chain rule holds, and define the predictable process $\\{\\varphi_t\\}_{t \\in [0,T]}$ by $\\varphi_t := \\mathbb{E}[D_t F \\mid \\mathcal{F}_t]$.\n\nUsing only foundational properties of Brownian motion, Gaussian moments, the chain rule for the Malliavin derivative, and the Itô isometry for stochastic integrals, do the following:\n\n- Compute $\\varphi_t$ explicitly.\n- Compute the quantity $A := \\mathbb{E}\\big[(F - \\mathbb{E}[F])^2\\big]$.\n- Compute the quantity $B := \\mathbb{E}\\!\\left[\\int_0^T \\varphi_t^2 \\, dt\\right]$.\n\nFinally, report the common value of $A$ and $B$ as a single closed-form expression in terms of $T$. Express your final answer as a symbolic expression. Do not include units. Do not round.", "solution": "We proceed step by step, starting from the standard properties of Brownian motion and associated tools in stochastic analysis.\n\nFirst, we identify the Malliavin derivative of $F = W_T^2$. The Malliavin derivative satisfies $D_t W_T = \\mathbf{1}_{\\{t \\leq T\\}}$ and obeys the chain rule. Therefore,\n$$\nD_t F \\;=\\; D_t\\big(W_T^2\\big) \\;=\\; 2 W_T \\, D_t W_T \\;=\\; 2 W_T \\, \\mathbf{1}_{\\{t \\leq T\\}}.\n$$\nBy definition, the predictable process $\\varphi_t$ is given by the conditional expectation\n$$\n\\varphi_t \\;=\\; \\mathbb{E}\\!\\left[D_t F \\,\\middle|\\, \\mathcal{F}_t\\right] \\;=\\; \\mathbb{E}\\!\\left[2 W_T \\mathbf{1}_{\\{t \\leq T\\}} \\,\\middle|\\, \\mathcal{F}_t\\right] \\;=\\; 2\\,\\mathbf{1}_{\\{t \\leq T\\}}\\, \\mathbb{E}\\!\\left[W_T \\,\\middle|\\, \\mathcal{F}_t\\right].\n$$\nUsing the independent increments of Brownian motion, write $W_T = W_t + (W_T - W_t)$, where $W_T - W_t$ is independent of $\\mathcal{F}_t$ and has mean $0$. Hence,\n$$\n\\mathbb{E}\\!\\left[W_T \\,\\middle|\\, \\mathcal{F}_t\\right] \\;=\\; W_t,\n$$\nand therefore\n$$\n\\varphi_t \\;=\\; 2 W_t \\quad \\text{for } t \\in [0,T].\n$$\n\nNext, compute $A := \\mathbb{E}\\big[(F - \\mathbb{E}[F])^2\\big]$, which is the variance of $F$. Since $W_T \\sim \\mathcal{N}(0,T)$, we have $\\mathbb{E}[W_T^2] = T$ and $\\mathbb{E}[W_T^4] = 3 T^2$ (fourth moment of a centered Gaussian). Thus,\n$$\nA \\;=\\; \\mathrm{Var}(W_T^2) \\;=\\; \\mathbb{E}[W_T^4] - \\big(\\mathbb{E}[W_T^2]\\big)^2 \\;=\\; 3 T^2 - T^2 \\;=\\; 2 T^2.\n$$\n\nNow compute $B := \\mathbb{E}\\!\\left[\\int_0^T \\varphi_t^2 \\, dt\\right]$. Substituting $\\varphi_t = 2 W_t$ gives\n$$\nB \\;=\\; \\mathbb{E}\\!\\left[\\int_0^T (2 W_t)^2 \\, dt\\right] \\;=\\; 4 \\int_0^T \\mathbb{E}[W_t^2] \\, dt.\n$$\nFor Brownian motion, $\\mathbb{E}[W_t^2] = t$. Therefore,\n$$\nB \\;=\\; 4 \\int_0^T t \\, dt \\;=\\; 4 \\cdot \\frac{T^2}{2} \\;=\\; 2 T^2.\n$$\n\nWe have obtained $A = 2 T^2$ and $B = 2 T^2$, which verifies by explicit computation that the two norms coincide for $F = W_T^2$, consistent with the norm identity associated with the Clark-Ocone representation and the Itô isometry.\n\nHence, the common value to report is\n$$\n2 T^2.\n$$", "answer": "$$\\boxed{2 T^{2}}$$", "id": "3079912"}, {"introduction": "Building on the skills developed in the previous practice, we now tackle a slightly more complex functional, $F = W_T^3$. This exercise reinforces the computational procedure for finding the Clark-Ocone integrand, requiring careful application of the chain rule for the Malliavin derivative and properties of conditional expectation. Working through this problem will solidify your command of the essential steps and deepen your intuition for how the integrand process reflects the structure of the underlying random variable [@problem_id:428234].", "problem": "Let $(W_t)_{t \\ge 0}$ be a standard one-dimensional Wiener process (or Brownian motion) on a probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$, and let $(\\mathcal{F}_t)_{t \\ge 0}$ be the natural filtration generated by $W$. The Malliavin derivative, denoted by $D$, is a generalization of the ordinary directional derivative to the space of random variables. For a random variable $F$ that is a functional of the Wiener path, its Malliavin derivative $D_t F$ for $t \\ge 0$ is a stochastic process that measures the sensitivity of $F$ to an infinitesimal perturbation of the path of $W$ at time $t$. A key property of this derivative is that for any $s \\ge 0$, $D_t W_s = \\mathbf{1}_{[0, s]}(t)$, where $\\mathbf{1}$ is the indicator function. The Malliavin derivative satisfies a chain rule: for a differentiable function $g: \\mathbb{R} \\to \\mathbb{R}$ and a suitable random variable $F$, $D_t g(F) = g'(F) D_t F$.\n\nThe Clark-Ocone formula provides a fundamental representation for any square-integrable, $\\mathcal{F}_T$-measurable random variable $F$ (that lies in the domain of the Malliavin derivative) in terms of a stochastic integral:\n$$F = \\mathbb{E}[F] + \\int_0^T \\Phi_s dW_s$$\nwhere the integrand process $(\\Phi_s)_{s \\in [0,T]}$ is the projection of the Malliavin derivative of $F$ onto the adapted processes, given by\n$$\\Phi_s = \\mathbb{E}[D_s F | \\mathcal{F}_s]$$\n\nConsider the random variable $F = W_T^3$ for a fixed time $T  0$. Your task is to compute the integrand process $(\\Phi_t)_{t \\in [0, T]}$ in the Clark-Ocone representation of $W_T^3$. Your answer should be an explicit expression for $\\Phi_t$ in terms of $t$, $T$, and the process $(W_t)_{t \\ge 0}$.", "solution": "1. We have the Malliavin derivative of the Wiener process:  \n   $$D_tW_s = \\mathbf{1}_{[0,s]}(t)\\,. $$  \n2. For $F = W_T^3$, the chain rule gives  \n   $$D_tF = D_t\\bigl(W_T^3\\bigr) = 3W_T^2\\,D_tW_T = 3W_T^2\\mathbf{1}_{[0,T]}(t) = 3W_T^2\\,,\\quad t\\in[0,T].$$  \n3. By the Clark–Ocone formula, the integrand is  \n   $$\\Phi_t = \\mathbb{E}[D_tF \\mid \\mathcal{F}_t] = 3\\,\\mathbb{E}\\bigl[W_T^2 \\mid \\mathcal{F}_t\\bigr]\\,. $$  \n4. Decompose $W_T = W_t + (W_T - W_t)$. Since $W_T - W_t$ is independent of $\\mathcal{F}_t$ with mean 0 and variance $T-t$,  \n   $$\\mathbb{E}\\bigl[W_T^2 \\mid \\mathcal{F}_t\\bigr]\n     = \\mathbb{E}\\bigl[(W_t + (W_T - W_t))^2 \\mid \\mathcal{F}_t\\bigr]\n     = W_t^2 + 2W_t\\mathbb{E}[W_T - W_t]+\\mathbb{E}[(W_T - W_t)^2]\n     = W_t^2 + (T-t)\\,. $$\n5. Hence  \n   $$\\Phi_t = 3\\bigl(W_t^2 + T - t\\bigr)\\,. $$", "answer": "$$\\boxed{3\\bigl(W_t^2 + T - t\\bigr)}$$", "id": "428234"}, {"introduction": "This final practice moves into a more advanced and highly relevant application of the Clark-Ocone formula, connecting it to the world of financial mathematics. We consider the functional $F = \\max(W_T, 0)$, which represents the payoff of a European call option. Since this function is not differentiable, a direct application of the Malliavin chain rule is not possible. This exercise guides you through the powerful technique of smooth approximation, demonstrating how to handle such cases and revealing that the resulting integrand is a fundamental quantity used in financial hedging [@problem_id:3000571].", "problem": "Let $\\{W_{t}\\}_{t \\in [0,T]}$ be a standard Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\in [0,T]},\\mathbb{P})$ satisfying the usual conditions. Consider the terminal functional $F = \\max(W_{T},0)$.\n\n1. Construct a family $\\{f_{\\epsilon}\\}_{\\epsilon0}$ of smooth functions $f_{\\epsilon}:\\mathbb{R}\\to\\mathbb{R}$ such that $f_{\\epsilon}(x) \\to x^{+}$ pointwise as $\\epsilon \\to 0$, and $f_{\\epsilon}$ has a bounded and continuous first derivative for each fixed $\\epsilon0$. Justify that $f_{\\epsilon}(W_{T}) \\to F$ in $L^{2}(\\Omega)$ as $\\epsilon \\to 0$.\n\n2. Using foundational definitions from the Malliavin calculus on the Wiener space (specifically, the Malliavin derivative of functionals of $W_{T}$ and the chain rule), compute the Malliavin derivative $D_{t}\\big(f_{\\epsilon}(W_{T})\\big)$ for $t \\in [0,T]$.\n\n3. Use independence of Brownian increments and standard properties of conditional expectation to express $\\mathbb{E}\\big[D_{t}\\big(f_{\\epsilon}(W_{T})\\big)\\,|\\,\\mathcal{F}_{t}\\big]$ in terms of $W_{t}$ and the law of $W_{T}-W_{t}$. Then analyze the limit as $\\epsilon \\to 0$ to obtain the predictable integrand $g_{t}$ that appears in the martingale representation of $F$ with respect to $\\{W_{t}\\}$.\n\nYour final task is to report the limiting analytic expression for $g_{t}$ obtained in step 3 (valid for $t \\in [0,T)$). The final answer must be a single closed-form expression.", "solution": "The problem requires finding the predictable integrand $g_{t}$ in the Clark-Ocone martingale representation of the functional $F = \\max(W_{T},0) = W_{T}^{+}$. The Clark-Ocone formula states that for a suitable functional $F$, its Itô representation is given by $F = \\mathbb{E}[F] + \\int_{0}^{T} g_{t} dW_{t}$, where the integrand is $g_{t} = \\mathbb{E}[D_{t}F | \\mathcal{F}_{t}]$. The problem guides us through a three-step procedure involving a smooth approximation of $F$.\n\nThe function $x \\mapsto \\max(x,0)$ is not differentiable, so we cannot directly apply the chain rule of Malliavin calculus. We proceed as directed.\n\n1.  Construction of a smooth approximation and $L^{2}$ convergence.\nThe function to be approximated is $x^{+} = \\max(x,0)$. We can express this as $x^{+} = \\frac{1}{2}(x + |x|)$. The non-smoothness comes from the absolute value function $|x| = \\sqrt{x^{2}}$. A standard way to smoothen this is to introduce a small positive parameter $\\epsilon$.\nWe define the family of functions $\\{f_{\\epsilon}\\}_{\\epsilon0}$ by\n$$f_{\\epsilon}(x) = \\frac{1}{2}(x + \\sqrt{x^{2} + \\epsilon^{2}})$$\nFor any fixed $\\epsilon  0$, the term under the square root is strictly positive, so $f_{\\epsilon}$ is infinitely differentiable ($C^{\\infty}$) on $\\mathbb{R}$. As $\\epsilon \\to 0$, we have $\\sqrt{x^{2} + \\epsilon^{2}} \\to \\sqrt{x^{2}} = |x|$, so $f_{\\epsilon}(x) \\to \\frac{1}{2}(x + |x|) = x^{+}$ for every $x \\in \\mathbb{R}$. This shows pointwise convergence.\nThe first derivative of $f_{\\epsilon}$ is:\n$$f_{\\epsilon}'(x) = \\frac{d}{dx} \\left[ \\frac{1}{2}(x + \\sqrt{x^{2} + \\epsilon^{2}}) \\right] = \\frac{1}{2}\\left(1 + \\frac{2x}{2\\sqrt{x^{2} + \\epsilon^{2}}}\\right) = \\frac{1}{2}\\left(1 + \\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}\\right)$$\nFor $\\epsilon  0$, $f_{\\epsilon}'(x)$ is a continuous function of $x$. To check if it is bounded, we analyze the term $\\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}$. Its absolute value is $\\left|\\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}\\right| = \\frac{|x|}{\\sqrt{x^{2} + \\epsilon^{2}}} \\le \\frac{|x|}{\\sqrt{x^{2}}} = 1$ for $x \\ne 0$. The inequality is strict for all $x$. Thus, $-1  \\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}  1$, which implies $0  1 + \\frac{x}{\\sqrt{x^{2} + \\epsilon^{2}}}  2$. Therefore, $0  f_{\\epsilon}'(x)  1$. The derivative is continuous and bounded for each $\\epsilon  0$.\n\nTo show that $f_{\\epsilon}(W_{T}) \\to F$ in $L^{2}(\\Omega)$, we must show $\\mathbb{E}\\left[|f_{\\epsilon}(W_{T}) - W_{T}^{+}|^{2}\\right] \\to 0$ as $\\epsilon \\to 0$. Let's examine the difference $|f_{\\epsilon}(x) - x^{+}|$:\n$$|f_{\\epsilon}(x) - x^{+}| = \\left|\\frac{1}{2}(x + \\sqrt{x^{2} + \\epsilon^{2}}) - \\frac{1}{2}(x + |x|)\\right| = \\frac{1}{2}|\\sqrt{x^{2} + \\epsilon^{2}} - |x||$$\nMultiplying by the conjugate, we get:\n$$\\frac{1}{2} \\left| \\frac{(\\sqrt{x^{2} + \\epsilon^{2}} - |x|)(\\sqrt{x^{2} + \\epsilon^{2}} + |x|)}{\\sqrt{x^{2} + \\epsilon^{2}} + |x|} \\right| = \\frac{1}{2} \\frac{|x^{2} + \\epsilon^{2} - x^{2}|}{\\sqrt{x^{2} + \\epsilon^{2}} + |x|} = \\frac{\\epsilon^{2}}{2(\\sqrt{x^{2} + \\epsilon^{2}} + |x|)}$$\nSince $\\sqrt{x^{2} + \\epsilon^{2}} \\ge \\sqrt{\\epsilon^{2}} = \\epsilon$ and $|x| \\ge 0$, the denominator is at least $\\epsilon$.\n$$|f_{\\epsilon}(x) - x^{+}| \\le \\frac{\\epsilon^{2}}{2\\epsilon} = \\frac{\\epsilon}{2}$$\nThis bound is uniform in $x$. Thus, applied to $W_{T}$, we have $|f_{\\epsilon}(W_{T}) - W_{T}^{+}| \\le \\frac{\\epsilon}{2}$ for all $\\omega \\in \\Omega$.\nThe $L^{2}$ norm of the difference is then bounded by:\n$$\\mathbb{E}\\left[|f_{\\epsilon}(W_{T}) - W_{T}^{+}|^{2}\\right] \\le \\mathbb{E}\\left[\\left(\\frac{\\epsilon}{2}\\right)^{2}\\right] = \\frac{\\epsilon^{2}}{4}$$\nAs $\\epsilon \\to 0$, $\\frac{\\epsilon^{2}}{4} \\to 0$, which proves that $f_{\\epsilon}(W_{T}) \\to W_{T}^{+}$ in $L^{2}(\\Omega)$.\n\n2.  Computation of the Malliavin derivative.\nThe Malliavin derivative of a functional of the form $f(W_{T})$, where $f$ is continuously differentiable with a bounded derivative, is given by the chain rule: $D_{t}(f(W_{T})) = f'(W_{T}) D_{t}W_{T}$. The Malliavin derivative of $W_{T} = \\int_{0}^{T} 1 \\, dW_{s}$ is $D_{t}W_{T} = 1$ for $t \\in [0,T]$.\nApplying this to our approximation $F_{\\epsilon} = f_{\\epsilon}(W_{T})$, we get:\n$$D_{t}(f_{\\epsilon}(W_{T})) = f_{\\epsilon}'(W_{T})$$\nfor $t \\in [0,T]$. Substituting the expression for $f_{\\epsilon}'(x)$ from Step 1:\n$$D_{t}(f_{\\epsilon}(W_{T})) = \\frac{1}{2}\\left(1 + \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}}\\right)$$\n\n3.  Conditional expectation and limiting expression.\nThe integrand in the Clark-Ocone representation for $F$ is $g_{t} = \\lim_{\\epsilon \\to 0} \\mathbb{E}[D_{t}(f_{\\epsilon}(W_{T})) | \\mathcal{F}_{t}]$. Let's first compute the conditional expectation for fixed $\\epsilon$:\n$$g_{t}^{\\epsilon} = \\mathbb{E}[D_{t}(f_{\\epsilon}(W_{T})) | \\mathcal{F}_{t}] = \\mathbb{E}\\left[\\frac{1}{2}\\left(1 + \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}}\\right) \\bigg| \\mathcal{F}_{t}\\right]$$\nBy linearity of conditional expectation:\n$$g_{t}^{\\epsilon} = \\frac{1}{2} + \\frac{1}{2}\\mathbb{E}\\left[\\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}} \\bigg| \\mathcal{F}_{t}\\right]$$\nThe random variable inside the expectation, $h_{\\epsilon}(W_{T}) = \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}}$, is bounded in absolute value by $1$. As $\\epsilon \\to 0$, $h_{\\epsilon}(x) \\to \\text{sgn}(x)$ for $x \\ne 0$. Since $\\mathbb{P}(W_{T}=0)=0$, this convergence happens almost surely. By the bounded convergence theorem for conditional expectations, we can interchange the limit and the expectation:\n$$g_{t} = \\lim_{\\epsilon \\to 0} g_{t}^{\\epsilon} = \\frac{1}{2} + \\frac{1}{2}\\mathbb{E}\\left[\\lim_{\\epsilon \\to 0} \\frac{W_{T}}{\\sqrt{W_{T}^{2} + \\epsilon^{2}}} \\bigg| \\mathcal{F}_{t}\\right] = \\frac{1}{2}\\left(1 + \\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}]\\right)$$\nNow we compute $\\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}]$. Note that $\\text{sgn}(x) = \\mathbf{1}_{x0} - \\mathbf{1}_{x0}$.\n$$\\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}] = \\mathbb{E}[\\mathbf{1}_{W_{T}0} | \\mathcal{F}_{t}] - \\mathbb{E}[\\mathbf{1}_{W_{T}0} | \\mathcal{F}_{t}] = \\mathbb{P}(W_{T}0 | \\mathcal{F}_{t}) - \\mathbb{P}(W_{T}0 | \\mathcal{F}_{t})$$\nWe decompose $W_{T}$ as $W_{T} = W_{t} + (W_{T} - W_{t})$. Given $\\mathcal{F}_{t}$, $W_{t}$ is a known value, and the increment $W_{T} - W_{t}$ is independent of $\\mathcal{F}_{t}$ and follows a normal distribution with mean $0$ and variance $T-t$. So, $W_{T} - W_{t} \\sim N(0, T-t)$.\nWe have, for $t  T$:\n$$\\mathbb{P}(W_{T}  0 | \\mathcal{F}_{t}) = \\mathbb{P}(W_{t} + (W_{T} - W_{t})  0 | \\mathcal{F}_{t}) = \\mathbb{P}(W_{T} - W_{t}  -W_{t})$$\nLet $Z \\sim N(0,1)$ be a standard normal variable. Then $W_{T} - W_{t}$ has the same distribution as $\\sqrt{T-t} Z$.\n$$\\mathbb{P}(\\sqrt{T-t}Z  -W_{t}) = \\mathbb{P}\\left(Z  -\\frac{W_{t}}{\\sqrt{T-t}}\\right)$$\nLet $\\Phi(\\cdot)$ be the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{x} \\exp(-\\frac{y^{2}}{2}) dy$.\nThe probability is $1 - \\Phi\\left(-\\frac{W_{t}}{\\sqrt{T-t}}\\right)$. Using the symmetry property $\\Phi(-z) = 1 - \\Phi(z)$, we get:\n$$\\mathbb{P}(W_{T}  0 | \\mathcal{F}_{t}) = \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)$$\nSimilarly, $\\mathbb{P}(W_{T}  0 | \\mathcal{F}_{t}) = \\mathbb{P}(Z  -\\frac{W_{t}}{\\sqrt{T-t}}) = \\Phi(-\\frac{W_{t}}{\\sqrt{T-t}}) = 1 - \\Phi(\\frac{W_{t}}{\\sqrt{T-t}})$.\nTherefore,\n$$\\mathbb{E}[\\text{sgn}(W_{T}) | \\mathcal{F}_{t}] = \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right) - \\left(1 - \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)\\right) = 2\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right) - 1$$\nSubstituting this back into the expression for $g_{t}$:\n$$g_{t} = \\frac{1}{2}\\left(1 + \\left(2\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right) - 1\\right)\\right) = \\frac{1}{2}\\left(2\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)\\right) = \\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)$$\nThe expression is valid for $t \\in [0,T)$.\n\nThe final result for the predictable integrand is the CDF of the standard normal distribution evaluated at $\\frac{W_{t}}{\\sqrt{T-t}}$.", "answer": "$$\\boxed{\\Phi\\left(\\frac{W_{t}}{\\sqrt{T-t}}\\right)}$$", "id": "3000571"}]}