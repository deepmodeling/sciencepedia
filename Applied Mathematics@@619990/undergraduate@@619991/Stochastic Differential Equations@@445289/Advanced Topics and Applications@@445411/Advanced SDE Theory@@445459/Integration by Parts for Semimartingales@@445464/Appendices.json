{"hands_on_practices": [{"introduction": "The foundation of stochastic calculus for continuous processes lies in understanding the behavior of Brownian motion. This first exercise [@problem_id:3060281] is fundamental, guiding you to derive the quadratic variation of a standard Brownian motion, $\\langle B \\rangle_t = t$, directly from its definition as a limit of squared increments. You will then apply the integration by parts formula to the process $B_t^2$ to solidify the connection between quadratic variation and the martingale property, a cornerstone result in the theory of stochastic integration.", "problem": "Let $\\{B_t\\}_{t \\geq 0}$ be a standard Brownian motion with $B_0 = 0$ on a filtered probability space satisfying the usual conditions. For a continuous semimartingale $X$, its quadratic variation $\\langle X \\rangle_t$ is defined as the limit in probability of the sequence of random variables $\\sum_{i=0}^{n-1} \\left(X_{t_{i+1}} - X_{t_i}\\right)^{2}$ along any sequence of partitions $\\pi_n = \\{0 = t_0 < t_1 < \\cdots < t_n = t\\}$ whose mesh tends to $0$. \n\n- Using only the defining properties of standard Brownian motion (namely, independent and stationary Gaussian increments with $\\mathbb{E}[B_t] = 0$ and $\\operatorname{Var}(B_t) = t$, and continuity of sample paths), compute the quadratic variation process $\\langle B \\rangle_t$.\n\n- Then, using the product (integration by parts) rule for semimartingales, demonstrate that the process $M_t := B_t^{2} - \\langle B \\rangle_t$ is a martingale with respect to the natural filtration of $B$. Your argument should begin from core definitions and well-tested facts about stochastic integrals and semimartingales, and it should explicitly identify each step where independence, moment computations, or properties of stochastic integrals are invoked.\n\nProvide your final answer as the closed-form analytic expression for $\\langle B \\rangle_t$. No rounding is required. Do not include units.", "solution": "The problem is divided into two parts. The first part is to compute the quadratic variation process of a standard Brownian motion, $\\langle B \\rangle_t$, using its fundamental definition. The second part is to use this result and the product rule for semimartingales to demonstrate that the process $M_t = B_t^2 - \\langle B \\rangle_t$ is a martingale.\n\n**Part 1: Computation of the Quadratic Variation $\\langle B \\rangle_t$**\n\nWe are tasked with computing the quadratic variation $\\langle B \\rangle_t$. By definition, for a continuous semimartingale $X$, this is the limit in probability of the sum of squared increments over a partition of the interval $[0, t]$. Let $\\pi_n = \\{0 = t_0 < t_1 < \\dots < t_n = t\\}$ be a sequence of partitions of the interval $[0, t]$ such that its mesh, $|\\pi_n| = \\max_{i} (t_{i+1} - t_i)$, tends to $0$ as $n \\to \\infty$. For the standard Brownian motion $B_t$, we consider the corresponding sum of squared increments:\n$$\nV_n(t) = \\sum_{i=0}^{n-1} (B_{t_{i+1}} - B_{t_i})^2\n$$\nWe need to find the limit of $V_n(t)$ in probability as $|\\pi_n| \\to 0$. We will show this limit is $t$ by demonstrating convergence in $L^2$, which is a stronger mode of convergence and implies convergence in probability. This requires showing that $\\mathbb{E}[(V_n(t) - t)^2] \\to 0$.\n\nFirst, we compute the expectation of $V_n(t)$. Let $\\Delta t_i = t_{i+1} - t_i$ and $\\Delta B_i = B_{t_{i+1}} - B_{t_i}$. From the properties of standard Brownian motion:\n1.  The increments $\\Delta B_i$ are independent random variables.\n2.  Each increment $\\Delta B_i$ follows a normal distribution with mean $0$ and variance $\\Delta t_i$. That is, $\\Delta B_i \\sim \\mathcal{N}(0, \\Delta t_i)$.\n\nThe expectation of the square of an increment is its variance:\n$$\n\\mathbb{E}[(\\Delta B_i)^2] = \\operatorname{Var}(\\Delta B_i) + (\\mathbb{E}[\\Delta B_i])^2 = \\Delta t_i + 0^2 = \\Delta t_i\n$$\nUsing the linearity of expectation, we find the expectation of $V_n(t)$:\n$$\n\\mathbb{E}[V_n(t)] = \\mathbb{E}\\left[\\sum_{i=0}^{n-1} (\\Delta B_i)^2\\right] = \\sum_{i=0}^{n-1} \\mathbb{E}[(\\Delta B_i)^2] = \\sum_{i=0}^{n-1} \\Delta t_i = t - 0 = t\n$$\nSo, $V_n(t)$ is an unbiased estimator of $t$.\n\nNext, we compute the variance of $V_n(t)$. Since the increments $\\Delta B_i$ are independent, the random variables $(\\Delta B_i)^2$ are also independent. Therefore, the variance of the sum is the sum of the variances:\n$$\n\\operatorname{Var}(V_n(t)) = \\operatorname{Var}\\left(\\sum_{i=0}^{n-1} (\\Delta B_i)^2\\right) = \\sum_{i=0}^{n-1} \\operatorname{Var}((\\Delta B_i)^2)\n$$\nTo compute $\\operatorname{Var}((\\Delta B_i)^2)$, we need the fourth moment of a centered normal distribution. If a random variable $Y \\sim \\mathcal{N}(0, \\sigma^2)$, then $\\mathbb{E}[Y^4] = 3\\sigma^4$. For the increment $\\Delta B_i$, its distribution is $\\mathcal{N}(0, \\Delta t_i)$, so $\\sigma^2 = \\Delta t_i$. The fourth moment is:\n$$\n\\mathbb{E}[(\\Delta B_i)^4] = 3(\\Delta t_i)^2\n$$\nThe variance of $(\\Delta B_i)^2$ is then:\n$$\n\\operatorname{Var}((\\Delta B_i)^2) = \\mathbb{E}[((\\Delta B_i)^2)^2] - (\\mathbb{E}[(\\Delta B_i)^2])^2 = \\mathbb{E}[(\\Delta B_i)^4] - (\\Delta t_i)^2 = 3(\\Delta t_i)^2 - (\\Delta t_i)^2 = 2(\\Delta t_i)^2\n$$\nSubstituting this into the expression for the variance of $V_n(t)$:\n$$\n\\operatorname{Var}(V_n(t)) = \\sum_{i=0}^{n-1} 2(\\Delta t_i)^2 = 2 \\sum_{i=0}^{n-1} (\\Delta t_i)^2\n$$\nAs the mesh of the partition $|\\pi_n| = \\max_i(\\Delta t_i)$ goes to $0$:\n$$\n\\sum_{i=0}^{n-1} (\\Delta t_i)^2 = \\sum_{i=0}^{n-1} (\\Delta t_i) (\\Delta t_i) \\leq \\sum_{i=0}^{n-1} |\\pi_n| (\\Delta t_i) = |\\pi_n| \\sum_{i=0}^{n-1} \\Delta t_i = |\\pi_n| t\n$$\nThus, we have the inequality:\n$$\n\\operatorname{Var}(V_n(t)) \\leq 2t |\\pi_n|\n$$\nAs $|\\pi_n| \\to 0$, it follows that $\\operatorname{Var}(V_n(t)) \\to 0$. Since $\\mathbb{E}[V_n(t)] = t$, the mean squared error $\\mathbb{E}[(V_n(t) - t)^2] = \\operatorname{Var}(V_n(t))$ converges to $0$. This implies that $V_n(t)$ converges to $t$ in $L^2$, and therefore also in probability.\nBy the definition provided in the problem, the quadratic variation is the limit in probability of these sums. Therefore, we conclude:\n$$\n\\langle B \\rangle_t = t\n$$\n\n**Part 2: Proving $M_t = B_t^2 - \\langle B \\rangle_t$ is a Martingale**\n\nFrom Part 1, we have $\\langle B \\rangle_t = t$. The process in question is thus $M_t = B_t^2 - t$. We are asked to demonstrate that $M_t$ is a martingale with respect to the natural filtration $\\mathcal{F}_t = \\sigma(B_s : s \\leq t)$, using the product rule for semimartingales.\n\nThe product rule (a specific case of Itô's formula) for two continuous semimartingales $X$ and $Y$ states that their product $X_t Y_t$ is also a semimartingale, with its differential given by:\n$$\nd(X_t Y_t) = X_t dY_t + Y_t dX_t + d\\langle X, Y \\rangle_t\n$$\nWe apply this rule by setting $X_t = B_t$ and $Y_t = B_t$. The process $B_t$ is a continuous semimartingale (it is a local martingale, and in fact a true martingale). The cross-variation $\\langle B, B \\rangle_t$ is by definition the same as the quadratic variation $\\langle B \\rangle_t$.\nSubstituting into the product rule:\n$$\nd(B_t B_t) = B_t dB_t + B_t dB_t + d\\langle B, B \\rangle_t\n$$\n$$\nd(B_t^2) = 2B_t dB_t + d\\langle B \\rangle_t\n$$\nThis is a stochastic differential equation. We can express it in integral form by integrating from $0$ to $t$:\n$$\n\\int_0^t d(B_s^2) = \\int_0^t 2B_s dB_s + \\int_0^t d\\langle B \\rangle_s\n$$\n$$\nB_t^2 - B_0^2 = 2\\int_0^t B_s dB_s + \\langle B \\rangle_t\n$$\nGiven the initial condition $B_0 = 0$ and the result from Part 1, $\\langle B \\rangle_t = t$, the equation simplifies to:\n$$\nB_t^2 = 2\\int_0^t B_s dB_s + t\n$$\nRearranging this equation gives an expression for the process $M_t = B_t^2 - t$:\n$$\nM_t = B_t^2 - t = 2\\int_0^t B_s dB_s\n$$\nThis shows that the process $M_t$ is equal to an Itô stochastic integral. We now verify that $M_t$ satisfies the three defining properties of a martingale with respect to the filtration $\\mathcal{F}_t$:\n\n1.  **Adaptedness**: $M_t = B_t^2 - t$. Since $B_t$ is $\\mathcal{F}_t$-adapted, its square $B_t^2$ is also $\\mathcal{F}_t$-adapted. The term $t$ is deterministic. Thus, $M_t$ is $\\mathcal{F}_t$-adapted for all $t \\ge 0$.\n\n2.  **Integrability**: We must have $\\mathbb{E}[|M_t|] < \\infty$ for all $t$.\n    $$\n    \\mathbb{E}[|M_t|] = \\mathbb{E}[|B_t^2 - t|] \\leq \\mathbb{E}[|B_t^2|] + |t| = \\mathbb{E}[B_t^2] + t\n    $$\n    We know $\\mathbb{E}[B_t^2] = \\operatorname{Var}(B_t) = t$. Thus:\n    $$\n    \\mathbb{E}[|M_t|] \\leq t + t = 2t\n    $$\n    For any finite $t$, $2t < \\infty$, so the integrability condition is satisfied.\n\n3.  **Martingale Property**: For any $s < t$, we must show $\\mathbb{E}[M_t | \\mathcal{F}_s] = M_s$.\n    Using the representation $M_t = 2\\int_0^t B_u dB_u$, we can write:\n    $$\n    M_t = 2\\int_0^s B_u dB_u + 2\\int_s^t B_u dB_u = M_s + 2\\int_s^t B_u dB_u\n    $$\n    Taking the conditional expectation with respect to $\\mathcal{F}_s$:\n    $$\n    \\mathbb{E}[M_t | \\mathcal{F}_s] = \\mathbb{E}\\left[M_s + 2\\int_s^t B_u dB_u \\bigg| \\mathcal{F}_s\\right]\n    $$\n    By linearity of conditional expectation:\n    $$\n    \\mathbb{E}[M_t | \\mathcal{F}_s] = \\mathbb{E}[M_s | \\mathcal{F}_s] + 2\\mathbb{E}\\left[\\int_s^t B_u dB_u \\bigg| \\mathcal{F}_s\\right]\n    $$\n    Since $M_s$ is $\\mathcal{F}_s$-measurable, $\\mathbb{E}[M_s | \\mathcal{F}_s] = M_s$.\n    The second term involves the Itô integral $\\int_s^t B_u dB_u$. A fundamental property of the Itô integral is that for any suitable (predictable and square-integrable) integrand $H_u$, the conditional expectation of its future integral is zero: $\\mathbb{E}[\\int_s^t H_u dB_u | \\mathcal{F}_s] = 0$. The integrand $H_u = B_u$ is continuous and adapted, hence predictable. Its square-integrability was confirmed when verifying that the Itô integral $\\int_0^t 2B_s dB_s$ is well-defined: $\\mathbb{E}[\\int_0^t (2B_s)^2 ds] = 2t^2 < \\infty$. The same holds for the interval $[s, t]$. Therefore:\n    $$\n    \\mathbb{E}\\left[\\int_s^t B_u dB_u \\bigg| \\mathcal{F}_s\\right] = 0\n    $$\n    Substituting these results back, we obtain:\n    $$\n    \\mathbb{E}[M_t | \\mathcal{F}_s] = M_s + 2 \\cdot 0 = M_s\n    $$\n    This confirms the martingale property. All three conditions are satisfied, proving that $M_t = B_t^2 - t$ is a martingale.\n\nThe final answer required is the closed-form expression for $\\langle B \\rangle_t$, which we found in the first part of the derivation.", "answer": "$$\n\\boxed{t}\n$$", "id": "3060281"}, {"introduction": "Unlike in standard calculus, the integration by parts formula for semimartingales must elegantly handle discontinuities. This practice [@problem_id:3060261] zooms in on the mechanics of a jump using a clear, illustrative scenario involving a continuous process and a process with a single jump. By calculating the change in the product of these processes at the exact moment of the jump, you will gain a concrete intuition for how the left-limit $X_{t-}$ and the jump size $\\Delta Y_t$ contribute to the overall formula.", "problem": "Consider a filtered probability space that supports standard semimartingales. Define two real-valued, adapted processes as follows:\n- A continuous, deterministic semimartingale $X$ given by $X_t = 2^{t}$ for all $t \\ge 0$.\n- A càdlàg, finite-variation semimartingale $Y$ that has a single jump at time $t_0 = 2$ with jump size $3$, given by $Y_t = 3 \\mathbf{1}_{\\{t \\ge 2\\}}$, where $\\mathbf{1}_{\\{t \\ge 2\\}}$ is the indicator function.\n\nUsing only the definitions of left limit and jump for a càdlàg process, compute the product increment of $XY$ at the jump time $t_0 = 2$, that is,\n$$\\Delta(XY)_2 := (XY)_2 - (XY)_{2-},$$\nby expressing it in terms of $X_{2-}$ and $\\Delta Y_2$ and then evaluating it explicitly.\n\nYour final answer must be a single real number. No rounding is required; give the exact value.", "solution": "The problem asks for the computation of the product increment $\\Delta(XY)_2$ at the time of jump $t_0 = 2$. The increment is defined as the difference between the value of the process at time $t_0=2$ and its left limit at that time.\n$$\n\\Delta(XY)_2 := (XY)_2 - (XY)_{2-}\n$$\nHere, $(XY)_2$ denotes the value of the product process $Z_t = X_t Y_t$ at $t=2$, which is $X_2 Y_2$. The term $(XY)_{2-}$ denotes the left limit of the process $Z_t$ as $t$ approaches $2$, which is defined as $\\lim_{t \\uparrow 2} (X_t Y_t)$. Since the left limits of $X_t$ and $Y_t$ exist (as they are semimartingales and thus càdlàg processes), the limit of the product is the product of the limits:\n$$\n(XY)_{2-} = \\left(\\lim_{t \\uparrow 2} X_t\\right) \\left(\\lim_{t \\uparrow 2} Y_t\\right) = X_{2-} Y_{2-}\n$$\nSo we can write the increment as:\n$$\n\\Delta(XY)_2 = X_2 Y_2 - X_{2-} Y_{2-}\n$$\nThe problem specifies that the process $X_t = 2^t$ is continuous. For a continuous process, the value at any time $t$ is equal to its left limit at $t$. Therefore, for the process $X_t$ at $t=2$:\n$$\nX_{2-} = \\lim_{t \\uparrow 2} X_t = X_2\n$$\nThe jump of $X_t$ at $t=2$ is $\\Delta X_2 = X_2 - X_{2-} = 0$.\n\nLet's substitute $X_2 = X_{2-}$ into the expression for the product increment:\n$$\n\\Delta(XY)_2 = X_{2-} Y_2 - X_{2-} Y_{2-}\n$$\nFactoring out the term $X_{2-}$, we get:\n$$\n\\Delta(XY)_2 = X_{2-} (Y_2 - Y_{2-})\n$$\nThe term $(Y_2 - Y_{2-})$ is, by definition, the jump of the process $Y_t$ at $t=2$, denoted by $\\Delta Y_2$. This gives the expression for the product increment in terms of $X_{2-}$ and $\\Delta Y_2$, as requested by the problem:\n$$\n\\Delta(XY)_2 = X_{2-} \\Delta Y_2\n$$\nThis simplified formula is a specific case of the general rule for the jump of a product of two semimartingales, $\\Delta(XY)_t = X_{t-} \\Delta Y_t + Y_{t-} \\Delta X_t + \\Delta X_t \\Delta Y_t$, where the terms involving $\\Delta X_t$ vanish because $X_t$ is continuous.\n\nNow, we must evaluate this expression explicitly by calculating $X_{2-}$ and $\\Delta Y_2$.\n\nFirst, we calculate $X_{2-}$. The process $X_t$ is given by $X_t = 2^t$. Its left limit at $t=2$ is:\n$$\nX_{2-} = \\lim_{t \\uparrow 2} 2^t = 2^2 = 4\n$$\n\nNext, we calculate $\\Delta Y_2$. The process $Y_t$ is given by $Y_t = 3 \\mathbf{1}_{\\{t \\ge 2\\}}$.\nThe value at $t=2$ is:\n$$\nY_2 = 3 \\mathbf{1}_{\\{2 \\ge 2\\}} = 3 \\times 1 = 3\n$$\nThe left limit at $t=2$ is found by considering values of $t$ strictly less than $2$:\n$$\nY_{2-} = \\lim_{t \\uparrow 2} Y_t = \\lim_{t \\uparrow 2, t<2} 3 \\mathbf{1}_{\\{t \\ge 2\\}} = \\lim_{t \\uparrow 2, t<2} 3 \\times 0 = 0\n$$\nThe jump $\\Delta Y_2$ is the difference between the value at $t=2$ and the left limit at $t=2$:\n$$\n\\Delta Y_2 = Y_2 - Y_{2-} = 3 - 0 = 3\n$$\nThis confirms the given information that the jump size is $3$.\n\nFinally, we substitute the calculated values of $X_{2-}$ and $\\Delta Y_2$ into our derived formula:\n$$\n\\Delta(XY)_2 = X_{2-} \\Delta Y_2 = 4 \\times 3 = 12\n$$\nThe product increment of $XY$ at the jump time $t_0 = 2$ is $12$.", "answer": "$$\n\\boxed{12}\n$$", "id": "3060261"}, {"introduction": "Many stochastic models combine smooth, random drift with sudden shocks, requiring us to handle processes that are part continuous and part jump. This exercise [@problem_id:3060270] synthesizes the concepts from the previous practices by analyzing semimartingales built from both Brownian motion and a Poisson process. You will employ the powerful polarization identity, a direct consequence of bilinearity, to compute the quadratic covariation $[X,Y]_t$ and then verify your result by decomposing it into its continuous and jump components, sharpening your computational toolkit for mixed processes.", "problem": "Consider a filtered probability space supporting a standard Brownian motion $W = (W_{t})_{t \\geq 0}$ and an independent Poisson process $N = (N_{t})_{t \\geq 0}$ with rate $\\lambda > 0$. Define two semimartingales by $X_{t} = W_{t} + N_{t}$ and $Y_{t} = 2 W_{t} + 3 N_{t}$. The quadratic covariation $[X,Y]$ is defined via the integration by parts identity for semimartingales: for all $t \\geq 0$,\n$$\nX_{t} Y_{t} = X_{0} Y_{0} + \\int_{0}^{t} X_{s-} \\, dY_{s} + \\int_{0}^{t} Y_{s-} \\, dX_{s} + [X,Y]_{t}.\n$$\nUsing only fundamental properties of quadratic covariation for semimartingales—including bilinearity, symmetry, the decomposition into continuous and jump parts, and well-tested facts such as $[W]_{t} = t$ for a standard Brownian motion and $[N]_{t} = \\sum_{0 < s \\leq t} (\\Delta N_{s})^{2} = N_{t}$ for a unit-jump Poisson process—first compute $[X]_{t}$, $[Y]_{t}$, $[X+Y]_{t}$, and $[X-Y]_{t}$. Then, by deriving an appropriate polarization relation from bilinearity, express $[X,Y]_{t}$ in terms of $[X+Y]_{t}$ and $[X-Y]_{t}$. Finally, verify your expression by separately identifying the continuous covariation contribution and the jump contribution using the canonical decomposition $[X,Y]_{t} = [X^{c},Y^{c}]_{t} + \\sum_{0 < s \\leq t} \\Delta X_{s} \\Delta Y_{s}$, where $X^{c}$ and $Y^{c}$ denote the continuous parts of $X$ and $Y$.\n\nProvide the exact closed-form analytic expression for $[X,Y]_{t}$; do not round.", "solution": "We are asked to find the quadratic covariation $[X,Y]_{t}$ for the semimartingales $X_{t} = W_{t} + N_{t}$ and $Y_{t} = 2 W_{t} + 3 N_{t}$. We will follow the steps prescribed in the problem statement.\n\nThe quadratic covariation process $[\\cdot,\\cdot]_{t}$ is a symmetric, bilinear form. This means for semimartingales $U$, $V$, $Z$ and real numbers $a$, $b$, we have:\nSymmetry: $[U,V]_{t} = [V,U]_{t}$\nBilinearity: $[aU+bV, Z]_{t} = a[U,Z]_{t} + b[V,Z]_{t}$ and $[Z, aU+bV]_{t} = a[Z,U]_{t} + b[Z,V]_{t}$.\nThe quadratic variation of a process $U$ is $[U]_{t} \\equiv [U,U]_{t}$.\n\nA critical property for this problem is the quadratic covariation of a continuous semimartingale and a pure jump semimartingale. The Brownian motion $W_{t}$ is a continuous process, while the Poisson process $N_{t}$ has paths of finite variation and is a pure jump process. Because $W_t$ and $N_t$ are independent, their quadratic covariation is zero. More generally, the quadratic covariation of any continuous local martingale and any local martingale with finite variation paths is zero. Thus, we have $[W,N]_{t} = 0$.\n\nFirst, we compute $[X]_{t}$, $[Y]_{t}$, $[X+Y]_{t}$, and $[X-Y]_{t}$ using bilinearity and the given facts.\n\nFor $X_{t} = W_{t} + N_{t}$:\n$$\n[X]_{t} = [W+N, W+N]_{t} = [W,W]_{t} + [W,N]_{t} + [N,W]_{t} + [N,N]_{t}\n$$\nUsing symmetry $[N,W]_{t}=[W,N]_{t}$, this becomes:\n$$\n[X]_{t} = [W]_{t} + 2[W,N]_{t} + [N]_{t}\n$$\nSubstituting $[W]_{t} = t$, $[N]_{t} = N_{t}$, and $[W,N]_{t} = 0$:\n$$\n[X]_{t} = t + 2(0) + N_{t} = t + N_{t}\n$$\n\nFor $Y_{t} = 2W_{t} + 3N_{t}$:\n$$\n[Y]_{t} = [2W+3N, 2W+3N]_{t} = [2W,2W]_{t} + 2[2W,3N]_{t} + [3N,3N]_{t}\n$$\nUsing the property $[aU, bV]_{t} = ab[U,V]_{t}$:\n$$\n[Y]_{t} = 4[W,W]_{t} + 12[W,N]_{t} + 9[N,N]_{t}\n$$\nSubstituting the known values:\n$$\n[Y]_{t} = 4t + 12(0) + 9N_{t} = 4t + 9N_{t}\n$$\n\nNext, we form the sum $X_{t}+Y_{t}$ and difference $X_{t}-Y_{t}$:\n$X_{t} + Y_{t} = (W_{t} + N_{t}) + (2W_{t} + 3N_{t}) = 3W_{t} + 4N_{t}$.\n$X_{t} - Y_{t} = (W_{t} + N_{t}) - (2W_{t} + 3N_{t}) = -W_{t} - 2N_{t}$.\n\nFor $[X+Y]_{t}$:\n$$\n[X+Y]_{t} = [3W+4N, 3W+4N]_{t} = 9[W,W]_{t} + 24[W,N]_{t} + 16[N,N]_{t}\n$$\nSubstituting the known values:\n$$\n[X+Y]_{t} = 9t + 24(0) + 16N_{t} = 9t + 16N_{t}\n$$\n\nFor $[X-Y]_{t}$:\n$$\n[X-Y]_{t} = [-W-2N, -W-2N]_{t} = (-1)^2[W,W]_{t} + 2(-1)(-2)[W,N]_{t} + (-2)^2[N,N]_{t}\n$$\n$$\n[X-Y]_{t} = 1[W,W]_{t} + 4[W,N]_{t} + 4[N,N]_{t}\n$$\nSubstituting the known values:\n$$\n[X-Y]_{t} = t + 4(0) + 4N_{t} = t + 4N_{t}\n$$\n\nThe second step is to derive a polarization relation. From bilinearity and symmetry:\n$$\n[X+Y]_{t} = [X+Y, X+Y]_{t} = [X,X]_{t} + 2[X,Y]_{t} + [Y,Y]_{t} = [X]_{t} + 2[X,Y]_{t} + [Y]_{t}\n$$\n$$\n[X-Y]_{t} = [X-Y, X-Y]_{t} = [X,X]_{t} - 2[X,Y]_{t} + [Y,Y]_{t} = [X]_{t} - 2[X,Y]_{t} + [Y]_{t}\n$$\nSubtracting the second equation from the first gives:\n$$\n[X+Y]_{t} - [X-Y]_{t} = ( [X]_{t} + 2[X,Y]_{t} + [Y]_{t} ) - ( [X]_{t} - 2[X,Y]_{t} + [Y]_{t} ) = 4[X,Y]_{t}\n$$\nThis yields the polarization identity:\n$$\n[X,Y]_{t} = \\frac{1}{4} \\left( [X+Y]_{t} - [X-Y]_{t} \\right)\n$$\n\nNow, we use this identity with the expressions we calculated:\n$$\n[X,Y]_{t} = \\frac{1}{4} \\left( (9t + 16N_{t}) - (t + 4N_{t}) \\right) = \\frac{1}{4} (8t + 12N_{t})\n$$\n$$\n[X,Y]_{t} = 2t + 3N_{t}\n$$\n\nFinally, we verify this result using the canonical decomposition $[X,Y]_{t} = [X^{c},Y^{c}]_{t} + \\sum_{0 < s \\leq t} \\Delta X_{s} \\Delta Y_{s}$.\nThe semimartingale $X_t = W_t + N_t$ has a continuous part $X^{c}_{t} = W_{t}$ and a jump part driven by $N_t$.\nThe semimartingale $Y_t = 2W_t + 3N_t$ has a continuous part $Y^{c}_{t} = 2W_{t}$ and a jump part driven by $3N_t$.\n\nThe continuous part of the covariation is:\n$$\n[X^{c},Y^{c}]_{t} = [W, 2W]_{t} = 2[W,W]_{t} = 2t\n$$\n\nThe jump part of the covariation is the sum over the product of jumps. The jumps of $X_t$ and $Y_t$ occur only at the jump times of $N_t$.\nThe jump of $X_t$ at time $s$ is $\\Delta X_{s} = \\Delta(W_{s} + N_{s})$. Since $W_t$ is continuous, $\\Delta W_s = 0$, so $\\Delta X_{s} = \\Delta N_{s}$.\nThe jump of $Y_t$ at time $s$ is $\\Delta Y_{s} = \\Delta(2W_{s} + 3N_{s})$. Since $W_t$ is continuous, $\\Delta(2W_s) = 0$, so $\\Delta Y_{s} = 3\\Delta N_{s}$.\nThe sum of the products of jumps is:\n$$\n\\sum_{0 < s \\leq t} \\Delta X_{s} \\Delta Y_{s} = \\sum_{0 < s \\leq t} (\\Delta N_{s}) (3\\Delta N_{s}) = 3 \\sum_{0 < s \\leq t} (\\Delta N_{s})^{2}\n$$\nFrom the problem statement, we know that for a unit-jump Poisson process, $\\sum_{0 < s \\leq t} (\\Delta N_{s})^{2} = N_{t}$. Therefore, the jump part is:\n$$\n\\sum_{0 < s \\leq t} \\Delta X_{s} \\Delta Y_{s} = 3N_{t}\n$$\n\nCombining the continuous and jump parts:\n$$\n[X,Y]_{t} = [X^{c},Y^{c}]_{t} + \\sum_{0 < s \\leq t} \\Delta X_{s} \\Delta Y_{s} = 2t + 3N_{t}\n$$\nThis confirms the result obtained using the polarization identity.", "answer": "$$\n\\boxed{2t + 3N_{t}}\n$$", "id": "3060270"}]}