{"hands_on_practices": [{"introduction": "The Lévy-Khintchine formula provides a powerful decomposition of any Lévy process into a drift, a Brownian motion, and a pure jump component. For $\\alpha$-stable processes with $\\alpha \\in (0,2)$, the behavior is dominated by jumps described by the Lévy measure. This exercise guides you to derive the explicit form of this measure directly from the process's defining self-similarity property, revealing the characteristic power-law distribution of its jumps [@problem_id:3081258].", "problem": "Consider a one-dimensional symmetric $\\alpha$-stable Lévy process, with $0\\alpha2$, whose law at time $t$ satisfies the scaling relation $X_{t} \\overset{d}{=} t^{1/\\alpha} X_{1}$, where $\\overset{d}{=}$ denotes equality in distribution. Let the characteristic triplet of this Lévy process be $(b, A, \\nu)$, where $b \\in \\mathbb{R}$ is the drift, $A \\ge 0$ is the Gaussian (diffusion) coefficient, and $\\nu$ is the Lévy measure on $\\mathbb{R} \\setminus \\{0\\}$.\n\nUsing only the definitions of a Lévy process, the definition of an $\\alpha$-stable law, and the Lévy measure integrability condition, determine the functional form of the Lévy measure $\\nu$ for this symmetric $\\alpha$-stable process and verify the Lévy measure integrability condition near zero. Specifically:\n\n- Identify the functional form of the Lévy measure density $x \\mapsto \\nu(\\mathrm{d}x)$ for the symmetric $\\alpha$-stable process, expressing it in terms of a positive constant $q_{\\alpha}0$ and $\\alpha$.\n- Compute the exact value of the integral\n$$\nI(\\alpha) \\;=\\; \\int_{|x|\\le 1} |x|^{2} \\,\\nu(\\mathrm{d}x)\n$$\nin closed form as a function of $q_{\\alpha}$ and $\\alpha$, and use it to verify the Lévy measure integrability condition near zero for $0\\alpha2$.\n\nYour final answer must consist of:\n- An analytical expression for the Lévy measure density in terms of $q_{\\alpha}$ and $\\alpha$.\n- An analytical expression for $I(\\alpha)$ in terms of $q_{\\alpha}$ and $\\alpha$.\n\nWrite the final answer entries together as a single row matrix. No numerical approximation is required.", "solution": "Let $X_t$ be a one-dimensional symmetric $\\alpha$-stable Lévy process with $0  \\alpha  2$. The characteristic function of $X_t$ is given by $\\mathbb{E}[\\exp(i u X_t)] = \\exp(t \\Psi(u))$, where $\\Psi(u)$ is the characteristic exponent. The Lévy-Khintchine formula provides the general form for $\\Psi(u)$:\n$$\n\\Psi(u) = i b u - \\frac{1}{2} A u^2 + \\int_{\\mathbb{R} \\setminus \\{0\\}} \\left( e^{i u x} - 1 - i u x \\mathbf{1}_{|x|\\le 1}(x) \\right) \\nu(\\mathrm{d}x)\n$$\nwhere $(b, A, \\nu)$ is the Lévy triplet, with $b \\in \\mathbb{R}$ being the drift, $A \\ge 0$ the Gaussian coefficient, and $\\nu$ the Lévy measure.\n\nThe process $X_t$ is symmetric, which means $X_t$ and $-X_t$ have the same distribution. This implies that the characteristic function $\\mathbb{E}[\\exp(i u X_t)]$ is a real and even function of $u$. Consequently, the characteristic exponent $\\Psi(u)$ must also be real and even.\n\nFor $\\Psi(u)$ to be real, its imaginary part must be zero for all $u \\in \\mathbb{R}$:\n$$\n\\mathrm{Im}(\\Psi(u)) = b u + \\int_{\\mathbb{R} \\setminus \\{0\\}} \\left( \\sin(u x) - u x \\mathbf{1}_{|x|\\le 1}(x) \\right) \\nu(\\mathrm{d}x) = 0\n$$\nThe symmetry of the process distribution implies that the Lévy measure $\\nu$ is also symmetric, i.e., for any Borel set $B \\subset \\mathbb{R} \\setminus \\{0\\}$, $\\nu(B) = \\nu(-B)$. Since the functions $x \\mapsto \\sin(ux)$ and $x \\mapsto x \\mathbf{1}_{|x|\\le 1}(x)$ are odd functions of $x$, their integrals with respect to the symmetric measure $\\nu$ are zero. Thus, the integral term vanishes. This leaves $b u = 0$ for all $u$, which implies the drift $b=0$.\n\nWith $b=0$ and a symmetric measure $\\nu$, the characteristic exponent simplifies to:\n$$\n\\Psi(u) = - \\frac{1}{2} A u^2 + \\int_{\\mathbb{R} \\setminus \\{0\\}} (\\cos(u x) - 1) \\nu(\\mathrm{d}x)\n$$\nThis form is manifestly real and an even function of $u$.\n\nNext, we use the $\\alpha$-stable scaling property, $X_t \\overset{d}{=} t^{1/\\alpha} X_1$. In terms of characteristic functions, this means:\n$$\n\\mathbb{E}[e^{i u X_t}] = \\mathbb{E}[e^{i u t^{1/\\alpha} X_1}]\n$$\nIn terms of the characteristic exponent, this yields the scaling relation:\n$$\nt \\Psi(u) = \\Psi(u t^{1/\\alpha})\n$$\nSubstituting our simplified form of $\\Psi(u)$:\n$$\nt \\left[ - \\frac{1}{2} A u^2 + \\int_{\\mathbb{R} \\setminus \\{0\\}} (\\cos(ux) - 1) \\nu(\\mathrm{d}x) \\right] = - \\frac{1}{2} A (u t^{1/\\alpha})^2 + \\int_{\\mathbb{R} \\setminus \\{0\\}} (\\cos(u t^{1/\\alpha} x) - 1) \\nu(\\mathrm{d}x)\n$$\nThis equation must hold for all $u \\in \\mathbb{R}$ and $t > 0$. We can equate terms with the same functional dependence on $u$.\nComparing the terms quadratic in $u$:\n$$\n- \\frac{1}{2} A t u^2 = - \\frac{1}{2} A u^2 t^{2/\\alpha}\n$$\nIf $A > 0$, this implies $t = t^{2/\\alpha}$, which gives $2/\\alpha = 1$, or $\\alpha=2$. However, the problem specifies $0  \\alpha  2$. Therefore, for this range of $\\alpha$, the Gaussian coefficient must be zero, $A=0$.\n\nWith $A=0$, the scaling relation for the integral part becomes:\n$$\nt \\int_{\\mathbb{R} \\setminus \\{0\\}} (\\cos(ux) - 1) \\nu(\\mathrm{d}x) = \\int_{\\mathbb{R} \\setminus \\{0\\}} (\\cos(u t^{1/\\alpha} x) - 1) \\nu(\\mathrm{d}x)\n$$\nThis is a functional equation for the measure $\\nu$. It implies that for any Borel set $B \\subset \\mathbb{R} \\setminus \\{0\\}$, the measure must satisfy $t \\nu(B) = \\nu(t^{-1/\\alpha}B)$. Let the Lévy measure have a density, $\\nu(\\mathrm{d}x) = f(x) \\mathrm{d}x$. The relation becomes:\n$$\nt \\int_B f(x) \\mathrm{d}x = \\int_{t^{-1/\\alpha}B} f(x) \\mathrm{d}x\n$$\nPerforming a change of variable $y = t^{1/\\alpha}x$ on the right-hand side integral gives $x = t^{-1/\\alpha}y$ and $\\mathrm{d}x = t^{-1/\\alpha}\\mathrm{d}y$. The integration domain becomes $B$.\n$$\n\\int_B f(t^{-1/\\alpha}y) t^{-1/\\alpha} \\mathrm{d}y\n$$\nComparing the integrands, we must have $t f(x) = f(x t^{-1/\\alpha}) t^{-1/\\alpha}$ for almost every $x$.\nRearranging gives $t^{1+1/\\alpha} f(x) = f(x t^{-1/\\alpha})$. Let $s=t^{-1/\\alpha}$, then $t=s^{-\\alpha}$. Substituting this into the equation yields $s^{-\\alpha(1+1/\\alpha)} f(x) = f(sx)$, which simplifies to $s^{-(\\alpha+1)} f(x) = f(sx)$. This is the defining equation for a homogeneous function of degree $-(\\alpha+1)$. The general solution is $f(x) = C|x|^{-(\\alpha+1)}$ for some constant $C$. Since the measure is symmetric, we do not need separate constants for $x>0$ and $x0$. The problem specifies the constant as $q_\\alpha > 0$.\nThus, the density of the Lévy measure is:\n$$\nx \\mapsto \\frac{q_{\\alpha}}{|x|^{1+\\alpha}}\n$$\n\nNow, we compute the integral $I(\\alpha)$ and verify the integrability condition for the Lévy measure. The general condition is $\\int_{\\mathbb{R} \\setminus \\{0\\}} \\min(1, |x|^2) \\nu(\\mathrm{d}x)  \\infty$. This is equivalent to checking two separate conditions: $\\int_{|x|>1} \\nu(\\mathrm{d}x)  \\infty$ and $\\int_{|x|\\le 1} |x|^2 \\nu(\\mathrm{d}x)  \\infty$.\n\nThe second condition corresponds to the integral $I(\\alpha)$:\n$$\nI(\\alpha) = \\int_{|x|\\le 1} |x|^2 \\nu(\\mathrm{d}x) = \\int_{|x|\\le 1} |x|^2 \\frac{q_{\\alpha}}{|x|^{1+\\alpha}} \\mathrm{d}x = q_{\\alpha} \\int_{|x|\\le 1} |x|^{1-\\alpha} \\mathrm{d}x\n$$\nThe integrand is an even function, so we can write the integral over $[-1, 1]$ as twice the integral over $[0, 1]$:\n$$\nI(\\alpha) = 2 q_{\\alpha} \\int_{0}^{1} x^{1-\\alpha} \\mathrm{d}x\n$$\nFor the integral to converge at $x=0$, we require the exponent to be greater than $-1$, i.e., $1-\\alpha > -1$, which means $\\alpha  2$. This condition is satisfied.\nWe can now evaluate the integral:\n$$\nI(\\alpha) = 2 q_{\\alpha} \\left[ \\frac{x^{1-\\alpha+1}}{1-\\alpha+1} \\right]_0^1 = 2 q_{\\alpha} \\left[ \\frac{x^{2-\\alpha}}{2-\\alpha} \\right]_0^1\n$$\nSince $0  \\alpha  2$, the exponent $2-\\alpha$ is positive, so $0^{2-\\alpha}=0$.\n$$\nI(\\alpha) = 2 q_{\\alpha} \\left( \\frac{1^{2-\\alpha}}{2-\\alpha} - \\frac{0^{2-\\alpha}}{2-\\alpha} \\right) = \\frac{2 q_{\\alpha}}{2-\\alpha}\n$$\nSince $q_\\alpha > 0$ and $0  \\alpha  2$, the value of $I(\\alpha)$ is finite and positive. This verifies the Lévy measure integrability condition near zero. For completeness, we can check the condition away from zero:\n$$\n\\int_{|x|>1} \\nu(\\mathrm{d}x) = \\int_{|x|>1} \\frac{q_{\\alpha}}{|x|^{1+\\alpha}} \\mathrm{d}x = 2 q_{\\alpha} \\int_1^{\\infty} x^{-1-\\alpha} \\mathrm{d}x = 2 q_{\\alpha} \\left[ \\frac{x^{-\\alpha}}{-\\alpha} \\right]_1^{\\infty} = \\frac{2 q_{\\alpha}}{\\alpha}\n$$\nThis is also finite since $\\alpha > 0$. Thus, the Lévy measure is valid for the given range of $\\alpha$.\n\nThe two required expressions are the Lévy measure density and the value of the integral $I(\\alpha)$.\nLévy measure density: $\\frac{q_{\\alpha}}{|x|^{1+\\alpha}}$\nIntegral $I(\\alpha)$: $\\frac{2 q_{\\alpha}}{2-\\alpha}$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{q_{\\alpha}}{|x|^{1+\\alpha}}  \\frac{2 q_{\\alpha}}{2-\\alpha} \\end{pmatrix}}\n$$", "id": "3081258"}, {"introduction": "The name \"stable\" refers to a crucial closure property: the sum of independent stable variables is itself stable with the same stability index $\\alpha$. This exercise asks you to generalize this idea by finding the distribution of a weighted sum of increments of an $\\alpha$-stable process [@problem_id:3083612]. Successfully solving this problem is a key step toward understanding how to construct stochastic integrals with respect to jump processes, a cornerstone of modern financial and physical modeling.", "problem": "Let $\\{L_{t}^{(\\alpha)}\\}_{t \\geq 0}$ be a real-valued $\\alpha$-stable Lévy process with $L_{0}^{(\\alpha)}=0$, where $\\alpha \\in (0,2)$ and $\\alpha \\neq 1$. Assume the following fundamental properties: (i) $L_{t}^{(\\alpha)}$ has stationary and independent increments; (ii) for each $t0$, the random variable $L_{t}^{(\\alpha)}$ is strictly $\\alpha$-stable with characteristic function given in Zolotarev parameterization $1$ by\n$$\n\\mathbb{E}\\big[\\exp(i u L_{t}^{(\\alpha)})\\big]\n=\n\\exp\\Big(\n- t\\,|u|^{\\alpha}\\big(1 - i\\,\\beta\\,\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u)\\big)\n\\Big),\n$$\nwhere $\\beta \\in [-1,1]$ is the skewness parameter and the scale at time $t=1$ is normalized to $1$.\n\nLet $0=t_{0}t_{1}\\cdotst_{n}=T$ be a fixed time grid and let $(c_{k})_{k=0}^{n-1}$ be a given sequence of real constants. Define the random sum\n$$\nS \\;=\\; \\sum_{k=0}^{n-1} c_{k}\\big(L_{t_{k+1}}^{(\\alpha)}-L_{t_{k}}^{(\\alpha)}\\big).\n$$\nUsing only the fundamental properties specified above, derive the characteristic function of $S$ and determine the $\\alpha$-stable parameters of $S$ (stability index, skewness, scale, location) in Zolotarev parameterization $1$. Express your final answer as a single parameter vector $\\big(\\alpha,\\beta_{S},\\sigma_{S},\\mu_{S}\\big)$ written in terms of $(\\alpha,\\beta)$, the coefficients $(c_{k})$, and the time increments $(t_{k+1}-t_{k})$. The final answer must be a single analytic expression. If any special cases arise from the data, justify them in the derivation, but the final answer must remain in closed form.", "solution": "The problem asks for the characteristic function of the random sum $S$ and its corresponding stable distribution parameters. We are to use only the fundamental properties provided.\n\nLet the random sum be defined as\n$$\nS = \\sum_{k=0}^{n-1} c_{k} \\Delta L_{k}^{(\\alpha)},\n$$\nwhere $\\Delta L_{k}^{(\\alpha)} = L_{t_{k+1}}^{(\\alpha)} - L_{t_{k}}^{(\\alpha)}$ is the increment of the Lévy process over the time interval $[t_{k}, t_{k+1}]$.\n\nThe characteristic function of $S$, denoted by $\\phi_{S}(u)$, is defined as $\\mathbb{E}[\\exp(i u S)]$. Substituting the expression for $S$:\n$$\n\\phi_{S}(u) = \\mathbb{E}\\left[\\exp\\left(i u \\sum_{k=0}^{n-1} c_{k} \\Delta L_{k}^{(\\alpha)}\\right)\\right] = \\mathbb{E}\\left[\\exp\\left(\\sum_{k=0}^{n-1} i u c_{k} \\Delta L_{k}^{(\\alpha)}\\right)\\right].\n$$\nThis can be written as the expectation of a product:\n$$\n\\phi_{S}(u) = \\mathbb{E}\\left[\\prod_{k=0}^{n-1} \\exp\\left(i (u c_{k}) \\Delta L_{k}^{(\\alpha)}\\right)\\right].\n$$\nFrom property (i), the Lévy process has independent increments. The time intervals $[t_{k}, t_{k+1}]$ for $k=0, 1, \\dots, n-1$ are disjoint (except at endpoints), so the increments $\\Delta L_{0}^{(\\alpha)}, \\Delta L_{1}^{(\\alpha)}, \\dots, \\Delta L_{n-1}^{(\\alpha)}$ are mutually independent random variables. The expectation of the product of independent random variables is the product of their expectations:\n$$\n\\phi_{S}(u) = \\prod_{k=0}^{n-1} \\mathbb{E}\\left[\\exp\\left(i (u c_{k}) \\Delta L_{k}^{(\\alpha)}\\right)\\right].\n$$\nEach term in the product is the characteristic function of the increment $\\Delta L_{k}^{(\\alpha)}$, evaluated at the point $u c_{k}$. Let $\\phi_{\\Delta L_{k}^{(\\alpha)}}(v) = \\mathbb{E}[\\exp(iv \\Delta L_{k}^{(\\alpha)})]$. Then,\n$$\n\\phi_{S}(u) = \\prod_{k=0}^{n-1} \\phi_{\\Delta L_{k}^{(\\alpha)}}(u c_{k}).\n$$\nFrom property (i), the process also has stationary increments. This means the distribution of an increment $\\Delta L_{k}^{(\\alpha)} = L_{t_{k+1}}^{(\\alpha)} - L_{t_{k}}^{(\\alpha)}$ depends only on the duration of the time interval, $\\Delta t_{k} = t_{k+1} - t_{k}$. Specifically, the distribution of $\\Delta L_{k}^{(\\alpha)}$ is the same as the distribution of $L_{\\Delta t_{k}}^{(\\alpha)}$.\n\nUsing property (ii), the characteristic function of $L_{t}^{(\\alpha)}$ is given. Therefore, the characteristic function of the increment $\\Delta L_{k}^{(\\alpha)}$ is:\n$$\n\\phi_{\\Delta L_{k}^{(\\alpha)}}(v) = \\mathbb{E}\\big[\\exp(iv L_{\\Delta t_k}^{(\\alpha)})\\big] = \\exp\\Big(-\\Delta t_{k}\\,|v|^{\\alpha}\\big(1 - i\\,\\beta\\,\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(v)\\big)\\Big).\n$$\nWe need to evaluate this at $v = u c_k$:\n$$\n\\phi_{\\Delta L_{k}^{(\\alpha)}}(u c_{k}) = \\exp\\Big(-\\Delta t_{k}\\,|u c_{k}|^{\\alpha}\\big(1 - i\\,\\beta\\,\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u c_{k})\\big)\\Big).\n$$\nUsing the properties $|uc_k|^\\alpha = |u|^\\alpha |c_k|^\\alpha$ and $\\operatorname{sign}(uc_k) = \\operatorname{sign}(u)\\operatorname{sign}(c_k)$ (for $c_k \\neq 0$; if $c_k=0$, the expression is zero and the identity holds trivially), we have:\n$$\n\\phi_{\\Delta L_{k}^{(\\alpha)}}(u c_{k}) = \\exp\\Big(-\\Delta t_{k}\\,|c_{k}|^{\\alpha}|u|^{\\alpha}\\big(1 - i\\,\\beta\\,\\operatorname{sign}(c_k)\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u)\\big)\\Big).\n$$\nNow, we substitute this back into the product for $\\phi_{S}(u)$:\n$$\n\\phi_{S}(u) = \\prod_{k=0}^{n-1} \\exp\\Big(-\\Delta t_{k}\\,|c_{k}|^{\\alpha}|u|^{\\alpha}\\big(1 - i\\,\\beta\\,\\operatorname{sign}(c_k)\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u)\\big)\\Big).\n$$\nThe product of exponentials is the exponential of the sum of their arguments:\n$$\n\\phi_{S}(u) = \\exp\\left( \\sum_{k=0}^{n-1} \\left[ -\\Delta t_{k}\\,|c_{k}|^{\\alpha}|u|^{\\alpha}\\big(1 - i\\,\\beta\\,\\operatorname{sign}(c_k)\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u)\\big) \\right] \\right).\n$$\nWe can factor out $-|u|^\\alpha$ from the summation:\n$$\n\\phi_{S}(u) = \\exp\\left( -|u|^{\\alpha} \\sum_{k=0}^{n-1} \\Delta t_{k}\\,|c_{k}|^{\\alpha}\\big(1 - i\\,\\beta\\,\\operatorname{sign}(c_k)\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u)\\big) \\right).\n$$\nTo identify the parameters, we must match this expression to the general form of the characteristic function for an $\\alpha$-stable variable $X \\sim S_{\\alpha}(\\sigma, \\beta, \\mu)$ in Zolotarev parameterization $1$, which for $\\alpha \\neq 1$ is:\n$$\n\\phi_{X}(u) = \\exp\\Big(i u \\mu - \\sigma^{\\alpha} |u|^{\\alpha} \\big(1 - i \\beta \\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big) \\operatorname{sign}(u)\\big)\\Big).\n$$\nLet's rearrange our derived expression for $\\phi_S(u)$. We distribute the sum:\n$$\n\\phi_{S}(u) = \\exp\\left( -|u|^{\\alpha} \\left[ \\sum_{k=0}^{n-1} \\Delta t_{k}\\,|c_{k}|^{\\alpha} - i\\,\\beta\\,\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u) \\sum_{k=0}^{n-1} \\Delta t_{k}\\,|c_{k}|^{\\alpha}\\operatorname{sign}(c_k) \\right] \\right).\n$$\nThis expression has no term of the form $i u \\mu_S$, which implies that the location parameter $\\mu_S = 0$.\nThe remainder of the expression must match $-\\sigma_S^{\\alpha} |u|^{\\alpha} (1 - i \\beta_S \\tan(\\frac{\\pi \\alpha}{2}) \\operatorname{sign}(u))$.\nLet's define two quantities for clarity:\n$$\n\\Sigma_{\\alpha} = \\sum_{k=0}^{n-1} (t_{k+1}-t_k) |c_k|^{\\alpha}\n$$\n$$\n\\Gamma_{\\alpha} = \\sum_{k=0}^{n-1} (t_{k+1}-t_k) |c_k|^{\\alpha} \\operatorname{sign}(c_k).\n$$\nWith these, the characteristic function of $S$ is:\n$$\n\\phi_{S}(u) = \\exp\\left( -|u|^{\\alpha} \\left[ \\Sigma_{\\alpha} - i\\,\\beta\\,\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u) \\Gamma_{\\alpha} \\right] \\right).\n$$\nTo match the standard form, we factor out $\\Sigma_{\\alpha}$:\n$$\n\\phi_{S}(u) = \\exp\\left( -\\Sigma_{\\alpha} |u|^{\\alpha} \\left[ 1 - i\\,\\beta\\,\\frac{\\Gamma_{\\alpha}}{\\Sigma_{\\alpha}}\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u) \\right] \\right).\n$$\nThis is valid provided $\\Sigma_{\\alpha} \\neq 0$. If all $c_k=0$, then $S=0$, $\\Sigma_{\\alpha}=0$, and the distribution is degenerate. In this case, $\\sigma_S=0$ and $\\beta_S$ is undefined (or conventionally set to $0$). Our formula must cover the general case where at least one $c_k$ is non-zero, making $\\Sigma_{\\alpha} > 0$.\n\nBy comparing our derived form\n$$\n\\phi_{S}(u) = \\exp\\left( -\\Sigma_{\\alpha} |u|^{\\alpha} \\left[ 1 - i\\,\\left(\\beta\\,\\frac{\\Gamma_{\\alpha}}{\\Sigma_{\\alpha}}\\right)\\tan\\big(\\tfrac{\\pi \\alpha}{2}\\big)\\operatorname{sign}(u) \\right] \\right)\n$$\nwith the canonical form for $S \\sim S_{\\alpha_S}(\\sigma_S, \\beta_S, \\mu_S)$:\n$$\n\\phi_{S}(u) = \\exp\\Big(i u \\mu_S - \\sigma_S^{\\alpha_S} |u|^{\\alpha_S} \\big(1 - i \\beta_S \\tan\\big(\\tfrac{\\pi \\alpha_S}{2}\\big) \\operatorname{sign}(u)\\big)\\Big),\n$$\nwe can identify the parameters of the distribution of $S$:\n1.  **Stability Index**: The exponent of $|u|$ is $\\alpha$. Thus, $\\alpha_S = \\alpha$. This is expected as linear combinations of $\\alpha$-stable variables are themselves $\\alpha$-stable.\n2.  **Location Parameter**: There is no $i u \\mu$ term, so $\\mu_S = 0$.\n3.  **Scale Parameter**: The term multiplying $|u|^{\\alpha}$ is $\\sigma_S^{\\alpha}$. By comparison, $\\sigma_S^{\\alpha} = \\Sigma_{\\alpha}$. Therefore, the scale parameter is\n    $$\n    \\sigma_S = (\\Sigma_{\\alpha})^{1/\\alpha} = \\left(\\sum_{k=0}^{n-1} |c_k|^{\\alpha} (t_{k+1}-t_k)\\right)^{1/\\alpha}.\n    $$\n4.  **Skewness Parameter**: The coefficient of the imaginary part in the parentheses is $\\beta_S$. By comparison,\n    $$\n    \\beta_S = \\beta\\,\\frac{\\Gamma_{\\alpha}}{\\Sigma_{\\alpha}} = \\beta \\frac{\\sum_{k=0}^{n-1} (t_{k+1}-t_k) |c_k|^{\\alpha} \\operatorname{sign}(c_k)}{\\sum_{k=0}^{n-1} (t_{k+1}-t_k) |c_k|^{\\alpha}}.\n    $$\nThe derived characteristic function of $S$ is\n$$\n\\phi_S(u) = \\exp\\left( -\\left(\\sum_{k=0}^{n-1} |c_k|^{\\alpha} (t_{k+1}-t_k)\\right)|u|^{\\alpha}\\left(1 - i \\left(\\beta \\frac{\\sum_{j=0}^{n-1} (t_{j+1}-t_j) |c_j|^{\\alpha} \\operatorname{sign}(c_j)}{\\sum_{j=0}^{n-1} (t_{j+1}-t_j) |c_j|^{\\alpha}}\\right) \\tan\\left(\\frac{\\pi\\alpha}{2}\\right)\\operatorname{sign}(u)\\right) \\right).\n$$\nThe parameters for the distribution of $S$ in the Zolotarev parameterization $1$ are $(\\alpha, \\beta_S, \\sigma_S, \\mu_S)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix} \\alpha  \\beta \\frac{\\sum_{k=0}^{n-1} (t_{k+1}-t_k) |c_k|^{\\alpha} \\operatorname{sign}(c_k)}{\\sum_{k=0}^{n-1} (t_{k+1}-t_k) |c_k|^{\\alpha}}  \\left(\\sum_{k=0}^{n-1} |c_k|^{\\alpha} (t_{k+1}-t_k)\\right)^{\\frac{1}{\\alpha}}  0 \\end{pmatrix}\n}\n$$", "id": "3083612"}, {"introduction": "Theoretical understanding comes to life through simulation, which allows us to visualize processes and validate their properties numerically. This practice challenges you to implement the famous Chambers-Mallows-Stuck algorithm, a cornerstone for simulating $\\alpha$-stable random variables [@problem_id:3083663]. By building and testing a simulator, you will gain a practical grasp of concepts like self-similarity and heavy tails and develop essential computational skills for stochastic modeling.", "problem": "A one-dimensional $\\alpha$-stable Lévy process $L_t^{(\\alpha)}$ is a stochastic process with stationary and independent increments whose characteristic function has the Lévy–Khintchine form. In the symmetric case (zero skewness and zero drift), the characteristic exponent is a power law in the frequency, and the increment distribution over a time horizon $t$ exhibits a scaling property tied to the stability index $\\alpha \\in (0,2]$. The Chambers–Mallows–Stuck algorithm (a constructive simulation scheme based on foundational properties of stable laws) provides a practical way to draw samples from a symmetric $\\alpha$-stable distribution without resorting to numerical inversion. Your task is to derive, implement, and validate a simulator for the increments of $L_t^{(\\alpha)}$.\n\nStarting from the following fundamental base:\n- The Lévy–Khintchine representation of infinitely divisible distributions and Lévy processes, ensuring that increments are independent and stationary.\n- The symmetric $\\alpha$-stable law’s scaling property: for $X \\sim S\\alpha S$ (symmetric $\\alpha$-stable), the characteristic function is of the form $\\mathbb{E}[e^{i u X}] = \\exp\\!\\big(-\\sigma^{\\alpha} |u|^{\\alpha}\\big)$ for scale parameter $\\sigma  0$, and scalar multiplication preserves $\\alpha$-stability.\n\nProceed to:\n1. Derive why, for a symmetric $\\alpha$-stable Lévy process with unit scale normalization, the increment $L_t^{(\\alpha)} - L_0^{(\\alpha)}$ over time $t$ has characteristic function $\\mathbb{E}[e^{i u (L_t^{(\\alpha)} - L_0^{(\\alpha)})}] = \\exp\\!\\big(-t |u|^{\\alpha}\\big)$, and hence is distributed as a symmetric $\\alpha$-stable random variable with scale $\\sigma_t = t^{1/\\alpha}$.\n2. Describe the algorithmic steps of the Chambers–Mallows–Stuck construction for simulating a symmetric $\\alpha$-stable random variable (angles measured in radians), explaining the special cases $\\alpha = 1$ and $\\alpha = 2$.\n3. Implement a program that:\n   - Generates samples of symmetric $\\alpha$-stable random variables using the Chambers–Mallows–Stuck algorithm in the symmetric case (zero skewness), with special handling for $\\alpha = 1$ (Cauchy) and $\\alpha = 2$ (Gaussian).\n   - Generates increments of $L_t^{(\\alpha)}$ by sampling from the symmetric $\\alpha$-stable distribution with scale $\\sigma_t = t^{1/\\alpha}$.\n   - Validates the simulator by computing empirical characteristic function values and a scaling check based on interquartile ranges (IQR).\n\nAngles must be treated in the unit of radians.\n\nYour program must use the following test suite with a fixed random seed $1337$, and produce a single summary error per test case:\n- Test case $1$ (general case, $\\alpha \\in (1,2)$): $\\alpha = 1.5$, times $t \\in \\{0.5, 1.0, 2.0\\}$, frequencies $u \\in \\{0.2, 0.7\\}$, sample size $N = 30000$. Compute, over all combinations of $t$ and $u$, the maximum of the two absolute errors: $\\left| \\mathbb{E}[\\cos(u X_t)] - \\exp(-t |u|^{\\alpha}) \\right|$ and $\\left| \\mathbb{E}[\\sin(u X_t)] - 0 \\right|$, where $X_t$ are simulated increments of $L_t^{(\\alpha)}$.\n- Test case $2$ (Cauchy, $\\alpha = 1$): $\\alpha = 1.0$, times $t \\in \\{0.25, 1.0, 4.0\\}$, frequencies $u \\in \\{0.3, 0.9\\}$, sample size $N = 30000$. Compute the same maximum error metric as in test case $1$.\n- Test case $3$ (Gaussian boundary, $\\alpha = 2$): $\\alpha = 2.0$, times $t \\in \\{0.25, 1.0, 4.0\\}$, frequencies $u \\in \\{0.5, 1.5, 2.0\\}$, sample size $N = 30000$. Compute the same maximum error metric as in test case $1$.\n- Test case $4$ (self-similarity scaling check): $\\alpha = 1.2$, times $t_1 = 1.0$, $t_2 = 3.0$, sample size $N = 60000$. Compute the interquartile range $\\mathrm{IQR}(t)$ for samples at $t_1$ and $t_2$, then the absolute relative error of the predicted scaling $\\left| \\frac{\\mathrm{IQR}(t_2)}{\\mathrm{IQR}(t_1)} - \\left(\\frac{t_2}{t_1}\\right)^{1/\\alpha} \\right| \\Big/ \\left(\\frac{t_2}{t_1}\\right)^{1/\\alpha}$.\n- Test case $5$ (heavy-tail edge, $\\alpha \\in (0,1)$): $\\alpha = 0.6$, times $t \\in \\{0.2, 0.8\\}$, frequencies $u \\in \\{0.4\\}$, sample size $N = 40000$. Compute the same maximum error metric as in test case $1$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $\\left[\\! \\text{result}_1, \\text{result}_2, \\ldots, \\text{result}_5 \\!\\right]$), where each $\\text{result}_k$ is a floating-point number computed exactly as specified above. No other text should be printed.", "solution": "The problem is assessed to be scientifically grounded, well-posed, objective, and complete. It is based on established principles of stochastic processes and stable distributions, providing all necessary parameters and specifications for a unique numerical solution. The problem is valid and a solution will be provided.\n\nThe problem requires a three-part response: a derivation of the increment properties of a symmetric $\\alpha$-stable Lévy process, a description of the Chambers–Mallows–Stuck simulation algorithm, and finally, the implementation and validation of a numerical simulator.\n\n### 1. Derivation of Increment Properties\n\nA Lévy process $\\{L_t\\}_{t \\ge 0}$ is characterized by increments that are independent and stationary. This means that for any $s  t$, the distribution of the increment $L_t - L_s$ depends only on the time difference $t-s$ and is independent of the process history $\\{L_u\\}_{u \\le s}$.\n\nThe characteristic function of a random variable $X$, denoted $\\phi_X(u) = \\mathbb{E}[e^{i u X}]$, uniquely determines its distribution. For a Lévy process, a fundamental property is that the characteristic function of the process at time $t$ is related to the characteristic function at time $t=1$ by the relation:\n$$ \\phi_{L_t}(u) = [\\phi_{L_1}(u)]^t $$\nThis stems from the fact that $L_t$ can be expressed as the sum of $t$ independent and identically distributed increments over unit time intervals (for integer $t$, and generalized to real $t > 0$ by the theory of infinitely divisible distributions).\n\nThe problem specifies a symmetric $\\alpha$-stable Lévy process, $L_t^{(\\alpha)}$, with unit scale normalization. This implies that the increment over a unit time interval, $L_1^{(\\alpha)} - L_0^{(\\alpha)}$, which has the same distribution as $L_1^{(\\alpha)}$ (conventionally starting at $L_0^{(\\alpha)}=0$), follows a standard symmetric $\\alpha$-stable distribution. Let us denote this random variable as $X_1$. Its distribution is $S(\\alpha, \\beta=0, \\sigma=1, \\mu=0)$, where $\\alpha \\in (0, 2]$ is the stability index, $\\beta=0$ indicates symmetry, $\\sigma=1$ is the unit scale, and $\\mu=0$ is the zero location parameter.\n\nThe characteristic function for a symmetric $\\alpha$-stable variable with scale $\\sigma$ is given as $\\mathbb{E}[e^{i u X}] = \\exp(-\\sigma^\\alpha |u|^\\alpha)$. For our standard variable $X_1$ with $\\sigma=1$, this becomes:\n$$ \\phi_{L_1^{(\\alpha)}}(u) = \\exp(-|u|^\\alpha) $$\nNow, we can find the characteristic function of the increment over a time horizon $t$, which we denote $X_t = L_t^{(\\alpha)} - L_0^{(\\alpha)}$. Due to the stationarity of increments, $X_t$ has the same distribution as $L_t^{(\\alpha)}$. Using the Lévy process property:\n$$ \\phi_{X_t}(u) = \\phi_{L_t^{(\\alpha)}}(u) = [\\phi_{L_1^{(\\alpha)}}(u)]^t = \\left(\\exp(-|u|^\\alpha)\\right)^t = \\exp(-t |u|^\\alpha) $$\nThis completes the first part of the derivation.\n\nNext, we identify the scale parameter $\\sigma_t$ of this increment $X_t$. By comparing its characteristic function $\\exp(-t |u|^\\alpha)$ with the general form $\\exp(-\\sigma_t^\\alpha |u|^\\alpha)$, we can equate the exponents:\n$$ \\sigma_t^\\alpha |u|^\\alpha = t |u|^\\alpha $$\nThis immediately yields $\\sigma_t^\\alpha = t$, and therefore the scale parameter for the increment over time $t$ is:\n$$ \\sigma_t = t^{1/\\alpha} $$\nThus, the increment $L_t^{(\\alpha)} - L_0^{(\\alpha)}$ is a symmetric $\\alpha$-stable random variable with scale $\\sigma_t = t^{1/\\alpha}$. This self-similarity property, where the distribution at time $t$ is a scaled version of the distribution at time $1$, is a hallmark of stable processes.\n\n### 2. The Chambers–Mallows–Stuck (CMS) Algorithm\n\nThe Chambers–Mallows–Stuck (CMS) algorithm provides a method for generating a random variate $X$ from a standard symmetric $\\alpha$-stable distribution, $S(\\alpha, 0, 1, 0)$, without requiring numerical inversion of the characteristic function.\n\nThe algorithm requires two independent random inputs:\n1.  A random variable $V$ drawn from a uniform distribution on the interval $(-\\pi/2, \\pi/2)$.\n2.  A random variable $W$ drawn from a standard exponential distribution with mean $1$ (i.e., rate $\\lambda=1$).\n\n**General Case ($0  \\alpha  2$, $\\alpha \\neq 1$)**:\nFor a given stability index $\\alpha$, the sample $X$ is constructed as follows:\n$$ X = \\frac{\\sin(\\alpha V)}{(\\cos V)^{1/\\alpha}} \\cdot \\left( \\frac{\\cos((1-\\alpha)V)}{W} \\right)^{(1-\\alpha)/\\alpha} $$\nAll angles are in radians.\n\n**Special Case ($\\alpha = 1$, Cauchy Distribution)**:\nWhen $\\alpha = 1$, the expression simplifies significantly. The second term's exponent becomes $(1-1)/1 = 0$, making the term equal to $1$:\n$$ X = \\frac{\\sin(V)}{(\\cos V)^1} \\cdot \\left( \\frac{\\cos(0)}{W} \\right)^0 = \\frac{\\sin V}{\\cos V} \\cdot 1 = \\tan V $$\nSince $V \\sim \\mathrm{Uniform}(-\\pi/2, \\pi/2)$, $X = \\tan V$ is the standard method for generating a random variate from the standard Cauchy distribution $C(0, 1)$.\n\n**Special Case ($\\alpha = 2$, Gaussian Distribution)**:\nWhen $\\alpha = 2$, the process $L_t^{(2)}$ becomes a scaled Brownian motion. The characteristic function of the increment $X_t = L_t^{(2)} - L_0^{(2)}$ is $\\exp(-t |u|^2)$. A Gaussian random variable with mean $0$ and variance $\\sigma_G^2$ has a characteristic function $\\exp(-\\frac{1}{2}\\sigma_G^2 u^2)$. Comparing the two forms gives $\\frac{1}{2}\\sigma_G^2 = t$, which implies the variance is $\\sigma_G^2 = 2t$.\nTherefore, the increment is distributed as a Gaussian random variable with mean $0$ and variance $2t$, i.e., $X_t \\sim N(0, 2t)$. While one could derive a form from the general CMS formula, it is numerically more robust and conventional to handle this case directly by generating a standard normal variate $Z \\sim N(0, 1)$ and scaling it: $X_t = \\sqrt{2t} \\cdot Z$.\n\n### 3. Implementation and Validation Plan\n\nThe implementation follows the principles derived above. A core function generates samples of the increment $X_t = L_t^{(\\alpha)} - L_0^{(\\alpha)}$ for a given set of parameters $(\\alpha, t)$.\n\n**Simulation Function**:\nA function `generate_sas(alpha, t, N, rng)` will be implemented to generate $N$ samples.\n- It will take `alpha` ($\\alpha$), `t` ($t$), `N` (sample size), and a `numpy.random.Generator` instance `rng` as input.\n- It will have branches for the three cases identified:\n    1.  If $\\alpha = 2.0$: Generate samples from $N(0, 2t)$. This is achieved by `rng.normal(loc=0, scale=np.sqrt(2 * t), size=N)`.\n    2.  If $\\alpha = 1.0$: Generate samples from a Cauchy distribution with scale $t$. This is done by computing $t \\cdot \\tan(V)$, where $V$ are $N$ samples from $\\mathrm{Uniform}(-\\pi/2, \\pi/2)$.\n    3.  For any other valid $\\alpha$: Generate $N$ samples using the general CMS formula to obtain standard $S\\alpha S$ variates, and then multiply them by the time-dependent scale factor $\\sigma_t = t^{1/\\alpha}$.\n\n**Validation Logic**:\nThe program will execute the five test cases specified, using a fixed random seed of $1337$ for reproducibility.\n\n- **Test Cases 1, 2, 3, 5 (Characteristic Function Validation)**:\n  For each combination of time $t$ and frequency $u$, a large number of samples $X_t$ are generated. The empirical characteristic function is computed as:\n  $$ \\hat{\\phi}_{X_t}(u) = \\frac{1}{N} \\sum_{j=1}^N e^{i u X_{t,j}} = \\frac{1}{N} \\sum_{j=1}^N \\cos(u X_{t,j}) + i \\frac{1}{N} \\sum_{j=1}^N \\sin(u X_{t,j}) $$\n  The theoretical characteristic function for a symmetric process is purely real: $\\phi_{X_t}(u) = \\exp(-t |u|^\\alpha)$.\n  The validation metric is the maximum absolute error found across all $(t, u)$ pairs within a test case, considering both the real and imaginary parts:\n  $$ \\text{error} = \\max_{(t,u)} \\left\\{ \\left| \\mathbb{E}[\\cos(u X_t)] - \\exp(-t |u|^{\\alpha}) \\right|, \\left| \\mathbb{E}[\\sin(u X_t)] - 0 \\right| \\right\\} $$\n  where the expectations are estimated by the sample means.\n\n- **Test Case 4 (Scaling Validation)**:\n  This test verifies the self-similarity property $\\sigma_t = t^{1/\\alpha}$. Since quantiles (and thus the interquartile range, IQR) scale linearly with the scale parameter, we expect the ratio of IQRs to follow the scaling law:\n  $$ \\frac{\\mathrm{IQR}(X_{t_2})}{\\mathrm{IQR}(X_{t_1})} = \\frac{\\sigma_{t_2}}{\\sigma_{t_1}} = \\frac{t_2^{1/\\alpha}}{t_1^{1/\\alpha}} = \\left(\\frac{t_2}{t_1}\\right)^{1/\\alpha} $$\n  The program will compute the empirical IQRs for samples generated at $t_1$ and $t_2$, calculate their ratio, and report the absolute relative error compared to the theoretical ratio. IQRs will be computed using NumPy's percentile functions: $\\mathrm{IQR}(X) = \\text{percentile}(X, 75) - \\text{percentile}(X, 25)$.\n\nThe final output will be a list of these computed error metrics, one for each test case, formatted as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Derives, implements, and validates a simulator for symmetric α-stable Lévy process increments.\n    \"\"\"\n    \n    # Initialize a random number generator with a fixed seed for reproducibility.\n    RNG = np.random.default_rng(1337)\n\n    def generate_sas_increments(alpha: float, t: float, n_samples: int, rng: np.random.Generator):\n        \"\"\"\n        Generates samples of increments for a symmetric α-stable Lévy process.\n\n        Args:\n            alpha: The stability index, 0  alpha = 2.\n            t: The time horizon.\n            n_samples: The number of samples to generate.\n            rng: The NumPy random number generator instance.\n\n        Returns:\n            An array of n_samples from the SαS distribution with scale t^(1/alpha).\n        \"\"\"\n        if alpha == 2.0:\n            # Gaussian case: N(0, 2t) distribution.\n            # Variance is 2t, so scale (std dev) is sqrt(2t).\n            scale = np.sqrt(2 * t)\n            return rng.normal(loc=0, scale=scale, size=n_samples)\n        \n        if alpha == 1.0:\n            # Cauchy case: C(0, t) distribution.\n            # Scale is t.\n            v = np.pi * (rng.uniform(size=n_samples) - 0.5)\n            return t * np.tan(v)\n\n        # General case for 0  alpha  2, alpha != 1\n        # Generate inputs for the CMS algorithm\n        v = np.pi * (rng.uniform(size=n_samples) - 0.5)\n        w = rng.exponential(scale=1.0, size=n_samples)\n\n        # Handle cos(v) - 0, although with uniform v it's a zero-probability event\n        cos_v = np.cos(v)\n        \n        # CMS formula for a standard SαS variable (scale=1)\n        term1 = np.sin(alpha * v) / (cos_v**(1/alpha))\n        term2_base = np.cos((1 - alpha) * v) / w\n        term2 = term2_base**((1 - alpha) / alpha)\n        \n        samples_std = term1 * term2\n        \n        # Scale the standard variable by t^(1/alpha)\n        scale = t**(1/alpha)\n        return scale * samples_std\n\n    def run_char_func_test(alpha, ts, us, n_samples):\n        \"\"\"\n        Runs validation by comparing empirical and theoretical characteristic functions.\n        \"\"\"\n        max_err = 0.0\n        for t in ts:\n            samples = generate_sas_increments(alpha, t, n_samples, RNG)\n            for u in us:\n                arg = u * samples\n                \n                # Empirical characteristic function parts\n                emp_real = np.mean(np.cos(arg))\n                emp_imag = np.mean(np.sin(arg))\n                \n                # Theoretical characteristic function parts (symmetric case)\n                th_real = np.exp(-t * (np.abs(u)**alpha))\n                th_imag = 0.0\n                \n                err_real = np.abs(emp_real - th_real)\n                err_imag = np.abs(emp_imag - th_imag)\n                \n                max_err = max(max_err, err_real, err_imag)\n        return max_err\n\n    def run_scaling_test(alpha, t1, t2, n_samples):\n        \"\"\"\n        Runs validation by checking the scaling property of the interquartile range (IQR).\n        \"\"\"\n        samples_t1 = generate_sas_increments(alpha, t1, n_samples, RNG)\n        samples_t2 = generate_sas_increments(alpha, t2, n_samples, RNG)\n        \n        iqr_t1 = np.percentile(samples_t1, 75) - np.percentile(samples_t1, 25)\n        iqr_t2 = np.percentile(samples_t2, 75) - np.percentile(samples_t2, 25)\n        \n        # Avoid division by zero if IQR is 0 (highly unlikely for these distributions)\n        if iqr_t1 == 0:\n            return np.inf\n\n        empirical_ratio = iqr_t2 / iqr_t1\n        theoretical_ratio = (t2 / t1)**(1 / alpha)\n        \n        relative_error = np.abs(empirical_ratio - theoretical_ratio) / theoretical_ratio\n        return relative_error\n\n    results = []\n\n    # Test case 1: general case, α ∈ (1,2)\n    alpha1 = 1.5\n    ts1 = [0.5, 1.0, 2.0]\n    us1 = [0.2, 0.7]\n    N1 = 30000\n    results.append(run_char_func_test(alpha1, ts1, us1, N1))\n\n    # Test case 2: Cauchy, α = 1\n    alpha2 = 1.0\n    ts2 = [0.25, 1.0, 4.0]\n    us2 = [0.3, 0.9]\n    N2 = 30000\n    results.append(run_char_func_test(alpha2, ts2, us2, N2))\n    \n    # Test case 3: Gaussian boundary, α = 2\n    alpha3 = 2.0\n    ts3 = [0.25, 1.0, 4.0]\n    us3 = [0.5, 1.5, 2.0]\n    N3 = 30000\n    results.append(run_char_func_test(alpha3, ts3, us3, N3))\n\n    # Test case 4: self-similarity scaling check\n    alpha4 = 1.2\n    t1_4, t2_4 = 1.0, 3.0\n    N4 = 60000\n    results.append(run_scaling_test(alpha4, t1_4, t2_4, N4))\n\n    # Test case 5: heavy-tail edge, α ∈ (0,1)\n    alpha5 = 0.6\n    ts5 = [0.2, 0.8]\n    us5 = [0.4]\n    N5 = 40000\n    results.append(run_char_func_test(alpha5, ts5, us5, N5))\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3083663"}]}