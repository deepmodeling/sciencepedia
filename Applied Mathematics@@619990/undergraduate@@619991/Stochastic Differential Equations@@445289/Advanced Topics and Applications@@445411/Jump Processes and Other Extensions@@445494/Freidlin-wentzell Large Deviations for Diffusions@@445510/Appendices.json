{"hands_on_practices": [{"introduction": "We begin our hands-on practice by returning to first principles. This exercise asks you to derive the large deviation principle for the simplest non-trivial stochastic process, a scaled Brownian motion, using the Gärtner–Ellis theorem. By directly computing the limiting cumulant generating function and its Legendre transform, you will obtain the fundamental quadratic rate function that underpins many applications of the theory [@problem_id:3055629]. This practice solidifies the connection between the general LDP framework and the specific context of small-noise diffusions.", "problem": "Consider the family of random variables $\\{X_{\\varepsilon}\\}_{\\varepsilon0}$ defined by $X_{\\varepsilon}=\\sqrt{\\varepsilon}\\,Z$, where $Z$ is a standard normal random variable, $Z\\sim \\mathcal{N}(0,1)$. This family arises as the one-time marginal of a small-noise linear diffusion $dX_{t}^{\\varepsilon}=\\sqrt{\\varepsilon}\\,dW_{t}$ at time $t=1$, which is a canonical setting in the theory of Freidlin-Wentzell large deviations for diffusions.\n\nStarting from the definition of the Large Deviation Principle (LDP) and using only fundamental facts about Gaussian moment generating functions and the Gärtner–Ellis theorem, derive the LDP for $\\{X_{\\varepsilon}\\}$ with a precise speed and identify the associated good rate function. Here, the Large Deviation Principle (LDP) for a family $\\{X_{\\varepsilon}\\}$ on $\\mathbb{R}$ with speed $v(\\varepsilon)$ and good rate function $I:\\mathbb{R}\\to[0,\\infty]$ means that for every Borel set $B\\subset\\mathbb{R}$,\n$$\n-\\inf_{x\\in B^{\\circ}}I(x)\\leq \\liminf_{\\varepsilon\\to 0} v(\\varepsilon)\\,\\ln \\mathbb{P}(X_{\\varepsilon}\\in B)\\leq \\limsup_{\\varepsilon\\to 0} v(\\varepsilon)\\,\\ln \\mathbb{P}(X_{\\varepsilon}\\in B)\\leq -\\inf_{x\\in \\overline{B}}I(x),\n$$\nwhere $B^{\\circ}$ denotes the interior and $\\overline{B}$ the closure of $B$.\n\nYour derivation must begin from first principles by:\n- Computing the scaled logarithmic moment generating function and its limit.\n- Applying the Gärtner–Ellis theorem (stated in words as needed) to identify the rate function via a Legendre–Fenchel transform.\n\nProvide the explicit closed-form expression for the good rate function $I(x)$. Your final answer must be a single analytic expression in terms of $x$. No numerical approximation or rounding is required.", "solution": "The user wants to derive the Large Deviation Principle (LDP) for the family of random variables $\\{X_{\\varepsilon}\\}_{\\varepsilon0}$ defined by $X_{\\varepsilon}=\\sqrt{\\varepsilon}\\,Z$, where $Z\\sim \\mathcal{N}(0,1)$. The derivation must be based on the Gärtner–Ellis theorem. This involves identifying the correct speed $v(\\varepsilon)$ and computing the associated good rate function $I(x)$.\n\nThe Gärtner–Ellis theorem provides a mechanism to establish an LDP for a family of random variables $\\{Y_{\\varepsilon}\\}_{\\varepsilon0}$ by examining the limiting behavior of their moment generating functions. Let us define a scaling parameter $a(\\varepsilon)$ such that $a(\\varepsilon) \\to 0$ as $\\varepsilon \\to 0$. The scaled cumulant generating function (SCGF) is defined as the limit:\n$$\n\\Lambda(k) = \\lim_{\\varepsilon \\to 0} a(\\varepsilon) \\ln \\mathbb{E}\\left[\\exp\\left(\\frac{k Y_{\\varepsilon}}{a(\\varepsilon)}\\right)\\right]\n$$\nThe Gärtner–Ellis theorem states that if this limit $\\Lambda(k)$ exists for all $k \\in \\mathbb{R}$, is finite, and is a differentiable function, then the family $\\{Y_{\\varepsilon}\\}$ satisfies an LDP on $\\mathbb{R}$ with speed $v(\\varepsilon) = 1/a(\\varepsilon)$ and a good rate function $I(x)$ given by the Legendre–Fenchel transform of $\\Lambda(k)$:\n$$\nI(x) = \\sup_{k \\in \\mathbb{R}} \\{kx - \\Lambda(k)\\}\n$$\nA rate function is called \"good\" if its level sets, $\\{x \\in \\mathbb{R} : I(x) \\le C\\}$ for any $C \\ge 0$, are compact.\n\nIn this problem, the random variables are $X_{\\varepsilon} = \\sqrt{\\varepsilon}\\,Z$. We begin by computing the moment generating function (MGF) of $X_{\\varepsilon}$. Let $M_{X_{\\varepsilon}}(t) = \\mathbb{E}[\\exp(t X_{\\varepsilon})]$.\nThe MGF of a standard normal random variable $Z \\sim \\mathcal{N}(0,1)$ is $M_Z(s) = \\mathbb{E}[\\exp(sZ)] = \\exp(s^2/2)$.\nUsing this, the MGF of $X_{\\varepsilon}$ is:\n$$\nM_{X_{\\varepsilon}}(t) = \\mathbb{E}[\\exp(t(\\sqrt{\\varepsilon}Z))] = \\mathbb{E}[\\exp((t\\sqrt{\\varepsilon})Z)] = M_Z(t\\sqrt{\\varepsilon})\n$$\nSubstituting $s = t\\sqrt{\\varepsilon}$ into the formula for $M_Z(s)$, we get:\n$$\nM_{X_{\\varepsilon}}(t) = \\exp\\left(\\frac{(t\\sqrt{\\varepsilon})^2}{2}\\right) = \\exp\\left(\\frac{t^2 \\varepsilon}{2}\\right)\n$$\nNow, we must identify the appropriate scaling $a(\\varepsilon)$ to define the SCGF. The choice of $a(\\varepsilon)$ is crucial; it must be chosen so that the limit $\\Lambda(k)$ is non-trivial (i.e., not always $0$ or $\\infty$). We substitute $Y_\\varepsilon = X_\\varepsilon$ into the definition of the SCGF:\n$$\n\\Lambda(k) = \\lim_{\\varepsilon \\to 0} a(\\varepsilon) \\ln M_{X_{\\varepsilon}}\\left(\\frac{k}{a(\\varepsilon)}\\right)\n$$\nUsing our expression for $M_{X_{\\varepsilon}}(t)$ with $t = k/a(\\varepsilon)$:\n$$\n\\Lambda(k) = \\lim_{\\varepsilon \\to 0} a(\\varepsilon) \\ln \\left[\\exp\\left(\\frac{(k/a(\\varepsilon))^2 \\varepsilon}{2}\\right)\\right] = \\lim_{\\varepsilon \\to 0} a(\\varepsilon) \\left(\\frac{k^2 \\varepsilon}{2a(\\varepsilon)^2}\\right) = \\lim_{\\varepsilon \\to 0} \\frac{k^2 \\varepsilon}{2a(\\varepsilon)}\n$$\nFor this limit to be finite and not identically zero for $k \\ne 0$, the scaling factor $a(\\varepsilon)$ must have the same order of magnitude as $\\varepsilon$. The canonical choice that yields a well-defined, non-trivial limit is $a(\\varepsilon) = \\varepsilon$.\n\nWith the choice $a(\\varepsilon) = \\varepsilon$, the SCGF becomes:\n$$\n\\Lambda(k) = \\lim_{\\varepsilon \\to 0} \\frac{k^2 \\varepsilon}{2\\varepsilon} = \\frac{k^2}{2}\n$$\nThe function $\\Lambda(k) = \\frac{k^2}{2}$ is well-defined, finite, and infinitely differentiable for all $k \\in \\mathbb{R}$. Therefore, the conditions of the Gärtner–Ellis theorem are satisfied.\n\nThe speed of the LDP is given by $v(\\varepsilon) = 1/a(\\varepsilon) = 1/\\varepsilon$.\n\nThe rate function $I(x)$ is the Legendre–Fenchel transform of $\\Lambda(k)$:\n$$\nI(x) = \\sup_{k \\in \\mathbb{R}} \\{kx - \\Lambda(k)\\} = \\sup_{k \\in \\mathbb{R}} \\left\\{kx - \\frac{k^2}{2}\\right\\}\n$$\nTo find the supremum, we consider the function $f(k) = kx - \\frac{k^2}{2}$ for a fixed $x$. This is a quadratic function of $k$ representing a downward-opening parabola. Its maximum occurs at the vertex, which can be found by setting its derivative with respect to $k$ to zero:\n$$\n\\frac{d}{dk}f(k) = \\frac{d}{dk}\\left(kx - \\frac{k^2}{2}\\right) = x - k\n$$\nSetting the derivative to zero gives $x - k = 0$, which implies that the supremum is attained at $k = x$.\n\nSubstituting this value of $k$ back into the expression for $f(k)$:\n$$\nI(x) = x(x) - \\frac{x^2}{2} = x^2 - \\frac{x^2}{2} = \\frac{x^2}{2}\n$$\nThis is the rate function. To confirm it is a \"good\" rate function, we check its level sets. The level set $\\{x \\in \\mathbb{R} : I(x) \\le C\\}$ is $\\{x \\in \\mathbb{R} : \\frac{x^2}{2} \\le C\\}$, which is equivalent to $\\{x \\in \\mathbb{R} : x^2 \\le 2C\\}$. This set is the closed interval $[-\\sqrt{2C}, \\sqrt{2C}]$, which is a compact subset of $\\mathbb{R}$ for any $C \\ge 0$. Thus, $I(x)$ is a good rate function.\n\nIn summary, the LDP for the family $\\{X_{\\varepsilon}\\}$ is established with speed $1/\\varepsilon$ and the good rate function $I(x) = \\frac{x^2}{2}$. The problem asks for the explicit closed-form expression for this rate function.", "answer": "$$\n\\boxed{\\frac{x^2}{2}}\n$$", "id": "3055629"}, {"introduction": "Having seen how a rate function emerges, we now develop the general mechanical framework for finding the 'most probable path' a diffusion takes during a rare event. This problem guides you through the calculus of variations to derive the Hamiltonian system that governs this optimal path [@problem_id:3055600]. This formulation is not just elegant; it is a powerful computational tool for solving for the dynamics of transitions in complex systems, connecting large deviation theory to the principles of classical mechanics.", "problem": "Consider the one-dimensional Stochastic Differential Equation (SDE) $$dX^{\\varepsilon}_{t} = b\\!\\left(X^{\\varepsilon}_{t}\\right)\\,dt + \\sqrt{\\varepsilon}\\,\\sigma\\,dW_{t},$$ where $b:\\mathbb{R}\\to\\mathbb{R}$ is continuously differentiable, $\\sigma0$ is a constant diffusion coefficient, $W_{t}$ is a standard Brownian motion, and $\\varepsilon0$ is a small parameter. The Freidlin–Wentzell Large Deviation Principle (LDP) for diffusions asserts that, as $\\varepsilon \\to 0$, the probability of observing an absolutely continuous path $x:[0,T]\\to\\mathbb{R}$ with $x(0)=x_{0}$ and $x(T)=x_{T}$ is exponentially small with rate governed by a variational principle over the action functional built from a Lagrangian. Using this well-tested framework, take as fundamental base the standard Freidlin–Wentzell rate functional for constant diffusion coefficient and derive, from first principles in the calculus of variations, the boundary value problem that characterizes the action-minimizing path $x^{\\ast}(t)$ between the fixed endpoints $x_{0}$ and $x_{T}$ over a fixed time horizon $T0$. Reformulate the necessary conditions as a Hamiltonian two-point boundary value system by introducing the conjugate momentum $p(t)$ associated with the Lagrangian.\n\nYour task:\n- Starting from the standard Freidlin–Wentzell rate functional for constant diffusion coefficient, derive the Euler–Lagrange equation satisfied by the minimizer $x^{\\ast}(t)$ together with the appropriate boundary conditions for fixed endpoints $x(0)=x_{0}$ and $x(T)=x_{T}$.\n- Introduce the conjugate momentum $p(t)$ and formulate the equivalent first-order Hamiltonian system that characterizes the minimizer, including the endpoint constraints.\n- As your final answer, provide the explicit analytic expression for the Hamiltonian $H(x,p)$ that generates this Hamiltonian system. Express your final answer as a single closed-form expression in terms of $x$, $p$, $b(x)$, and $\\sigma$. No rounding is required and no units should be included in your final expression.", "solution": "The problem asks for the derivation of the boundary value problem for the optimal path in a Freidlin-Wentzell large deviation context, followed by its Hamiltonian formulation, and finally for the expression of the Hamiltonian itself. The problem is well-posed and scientifically grounded in the theory of stochastic processes and calculus of variations.\n\nThe starting point is the one-dimensional stochastic differential equation (SDE):\n$$dX^{\\varepsilon}_{t} = b(X^{\\varepsilon}_{t})\\,dt + \\sqrt{\\varepsilon}\\,\\sigma\\,dW_{t}$$\nwhere $t \\in [0, T]$, $X^{\\varepsilon}_{0} = x_0$. According to the Freidlin-Wentzell theory for diffusions with a constant diffusion matrix, the probability of observing a trajectory close to a given path $\\phi(t)$ behaves as $\\exp(-\\frac{1}{\\varepsilon}I(\\phi))$. The rate function, or action functional, $I(\\phi)$ is given by the variational problem:\n$$S[x] = \\inf_{\\phi : \\phi(0)=x_0, \\phi(t) = x(t)} \\left\\{ \\frac{1}{2} \\int_{0}^{t} \\left\\| \\dot{\\phi}_s - b(\\phi_s) \\right\\|_{(\\sigma^2)^{-1}}^2 ds \\right\\}$$\nFor a path $x(t)$ on the fixed time interval $[0, T]$ connecting $x(0) = x_0$ to $x(T) = x_T$, the action functional to be minimized is:\n$$S[x] = \\int_{0}^{T} L(x(t), \\dot{x}(t))\\,dt$$\nwhere the Lagrangian $L(x, \\dot{x})$ is given by:\n$$L(x, \\dot{x}) = \\frac{1}{2\\sigma^2} (\\dot{x} - b(x))^2$$\nThe path $x^{\\ast}(t)$ that minimizes this functional is known as the instanton or the most probable path. It satisfies the Euler-Lagrange equation, which provides the necessary condition for a minimum.\n\nFirst, we derive the Euler-Lagrange equation:\n$$\\frac{d}{dt} \\left( \\frac{\\partial L}{\\partial \\dot{x}} \\right) - \\frac{\\partial L}{\\partial x} = 0$$\nWe compute the required partial derivatives of the Lagrangian $L(x, \\dot{x}) = \\frac{1}{2\\sigma^2} (\\dot{x} - b(x))^2$:\n1.  The derivative with respect to $\\dot{x}$:\n    $$\\frac{\\partial L}{\\partial \\dot{x}} = \\frac{1}{2\\sigma^2} \\cdot 2 (\\dot{x} - b(x)) \\cdot 1 = \\frac{\\dot{x} - b(x)}{\\sigma^2}$$\n2.  The derivative with respect to $x$, where $b'(x) = \\frac{db}{dx}$:\n    $$\\frac{\\partial L}{\\partial x} = \\frac{1}{2\\sigma^2} \\cdot 2 (\\dot{x} - b(x)) \\cdot (-\\frac{d}{dx}b(x)) = -\\frac{(\\dot{x} - b(x))b'(x)}{\\sigma^2}$$\n\nSubstituting these into the Euler-Lagrange equation yields:\n$$\\frac{d}{dt} \\left( \\frac{\\dot{x} - b(x)}{\\sigma^2} \\right) - \\left( -\\frac{(\\dot{x} - b(x))b'(x)}{\\sigma^2} \\right) = 0$$\nSince $\\sigma^2$ is a positive constant, we can multiply the entire equation by $\\sigma^2$:\n$$\\frac{d}{dt} (\\dot{x} - b(x)) + (\\dot{x} - b(x))b'(x) = 0$$\nApplying the chain rule, $\\frac{d}{dt}b(x(t)) = b'(x(t))\\dot{x}(t)$, we expand the first term:\n$$\\ddot{x} - \\frac{d}{dt}b(x) + \\dot{x}b'(x) - b(x)b'(x) = 0$$\n$$\\ddot{x} - \\dot{x}b'(x) + \\dot{x}b'(x) - b(x)b'(x) = 0$$\nThis simplifies to the second-order ordinary differential equation for the minimizing path $x^{\\ast}(t)$:\n$$\\ddot{x} - b(x)b'(x) = 0$$\nThis equation, together with the fixed endpoint conditions $x(0) = x_0$ and $x(T) = x_T$, constitutes the boundary value problem that characterizes the optimal path.\n\nNext, we reformulate this problem as a Hamiltonian system. We introduce the conjugate momentum $p(t)$ by its definition in classical mechanics:\n$$p(t) = \\frac{\\partial L}{\\partial \\dot{x}} = \\frac{\\dot{x}(t) - b(x(t))}{\\sigma^2}$$\nFrom this definition, we can express the velocity $\\dot{x}$ in terms of the state $x$ and momentum $p$:\n$$\\sigma^2 p = \\dot{x} - b(x) \\implies \\dot{x} = b(x) + \\sigma^2 p$$\nThe Hamiltonian $H(x,p)$ is obtained via the Legendre transformation of the Lagrangian:\n$$H(x, p) = p\\dot{x} - L(x, \\dot{x})$$\nWe substitute the expression for $\\dot{x}$ in terms of $p$ into the definition of $H$. The term $\\dot{x} - b(x)$ in the Lagrangian becomes $(b(x) + \\sigma^2 p) - b(x) = \\sigma^2 p$.\n$$H(x, p) = p(b(x) + \\sigma^2 p) - \\frac{1}{2\\sigma^2}(\\sigma^2 p)^2$$\n$$H(x, p) = b(x)p + \\sigma^2 p^2 - \\frac{1}{2\\sigma^2}(\\sigma^4 p^2)$$\n$$H(x, p) = b(x)p + \\sigma^2 p^2 - \\frac{1}{2}\\sigma^2 p^2$$\nSimplifying this expression gives the Hamiltonian:\n$$H(x, p) = b(x)p + \\frac{1}{2}\\sigma^2 p^2$$\nThe dynamics of the minimizing path are then described by Hamilton's equations:\n$$\\dot{x} = \\frac{\\partial H}{\\partial p}, \\quad \\dot{p} = -\\frac{\\partial H}{\\partial x}$$\nLet's compute these partial derivatives:\n$$\\frac{\\partial H}{\\partial p} = \\frac{\\partial}{\\partial p} \\left( b(x)p + \\frac{1}{2}\\sigma^2 p^2 \\right) = b(x) + \\sigma^2 p$$\n$$\\frac{\\partial H}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( b(x)p + \\frac{1}{2}\\sigma^2 p^2 \\right) = b'(x)p$$\nThus, the Hamiltonian system is the following system of two first-order differential equations:\n$$\\dot{x}(t) = b(x(t)) + \\sigma^2 p(t)$$\n$$\\dot{p}(t) = -b'(x(t)) p(t)$$\nThis system, subject to the two-point boundary conditions $x(0) = x_0$ and $x(T) = x_T$, provides the full characterization of the optimal path $x^{\\ast}(t)$ and its associated conjugate momentum $p(t)$. The first equation correctly recovers our expression for $\\dot{x}$ in terms of $p$. The problem asks for the final expression for the Hamiltonian $H(x, p)$, which we have derived.", "answer": "$$\\boxed{b(x)p + \\frac{1}{2}\\sigma^2 p^2}$$", "id": "3055600"}, {"introduction": "We now apply the theoretical machinery to a classic and physically significant problem: noise-induced transitions in a double-well potential. You will calculate the 'quasipotential', which quantifies the energetic barrier for transitioning between the two stable states of the system [@problem_id:3055569]. This concept is central to understanding phenomena ranging from chemical reaction rates and protein folding to the stability of ecological and climate systems.", "problem": "Consider the one-dimensional gradient diffusion in a double-well potential governed by the Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_{t} = -U'(X_{t})\\,\\mathrm{d}t + \\sqrt{\\varepsilon}\\,\\mathrm{d}W_{t},\n$$\nwhere $U(x) = \\frac{(x^{2}-1)^{2}}{4}$, $\\varepsilon  0$ is small, and $W_{t}$ is a standard Wiener process. Assume the diffusion matrix $a(x) = \\sigma(x)\\sigma(x)^{\\top} \\equiv 1$ is the identity (that is, unit diffusivity). The drift is $b(x) = -U'(x)$.\n\nIn the Freidlin–Wentzell large-deviation framework, the action associated with an absolutely continuous path $\\varphi:[0,T]\\to\\mathbb{R}$ is\n$$\nS_{0}^{T}(\\varphi) = \\frac{1}{2}\\int_{0}^{T}\\big|\\dot{\\varphi}(t) - b(\\varphi(t))\\big|^{2}\\,\\mathrm{d}t,\n$$\nand the quasipotential from a stable equilibrium point $x_{-}$ to a point $y$ is defined as the infimum of $S_{0}^{T}(\\varphi)$ over all times $T0$ and all such paths $\\varphi$ with $\\varphi(0)=x_{-}$ and $\\varphi(T)=y$.\n\nIdentify the minima and the saddle point of $U(x)$, and use only the fundamental definitions above to determine the Freidlin–Wentzell quasipotential for the transition from the left minimum at $x=-1$ to the right minimum at $x=+1$ via the saddle at $x=0$. Provide the final answer as a single exact real number. No rounding is required.", "solution": "The user wants me to solve the problem. I will first perform validation.\n\n### Step 1: Extract Givens\n-   The Stochastic Differential Equation (SDE) is: $\\mathrm{d}X_{t} = -U'(X_{t})\\,\\mathrm{d}t + \\sqrt{\\varepsilon}\\,\\mathrm{d}W_{t}$.\n-   The potential function is: $U(x) = \\frac{(x^{2}-1)^{2}}{4}$.\n-   The drift is: $b(x) = -U'(x)$.\n-   The diffusion matrix is: $a(x) = 1$.\n-   The noise strength is: $\\varepsilon  0$ and small.\n-   $W_{t}$ is a standard Wiener process.\n-   The action functional for a path $\\varphi:[0,T]\\to\\mathbb{R}$ is: $S_{0}^{T}(\\varphi) = \\frac{1}{2}\\int_{0}^{T}\\big|\\dot{\\varphi}(t) - b(\\varphi(t))\\big|^{2}\\,\\mathrm{d}t$.\n-   The quasipotential from a stable equilibrium point $x_{-}$ to a point $y$ is: $V(x_{-}, y) = \\inf_{T0, \\varphi: \\varphi(0)=x_{-}, \\varphi(T)=y} S_{0}^{T}(\\varphi)$.\n-   The task is to determine the quasipotential for the transition from the left minimum ($x=-1$) to the right minimum ($x=+1$).\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is a canonical example in the Freidlin-Wentzell theory of large deviations for stochastic differential equations. It describes the noise-induced transition of a particle in a double-well potential, a fundamental topic in statistical physics and applied mathematics. The formulation is standard and scientifically sound.\n2.  **Well-Posed**: The problem is well-posed. The potential function and SDE are clearly specified. The definitions of the action functional and quasipotential are standard. The objective—to calculate the quasipotential between two specific points—is unambiguous and leads to a unique solution.\n3.  **Objective**: The language is precise and mathematical, free of any subjectivity.\n4.  **Completeness**: All necessary information is provided. The potential $U(x)$ defines the drift $b(x)$. The action functional is explicitly given. The start and end points of the transition are specified.\n5.  **Consistency**: There are no contradictions in the given information.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nTo determine the quasipotential for the transition from the left minimum to the right minimum, we must first identify the equilibrium points of the system and characterize their stability. The deterministic dynamics associated with the SDE are given by $\\frac{\\mathrm{d}x}{\\mathrm{d}t} = b(x) = -U'(x)$. The equilibrium points are the solutions to $U'(x) = 0$.\n\nThe potential is given by $U(x) = \\frac{(x^{2}-1)^{2}}{4}$. Its derivative, $U'(x)$, is:\n$$\nU'(x) = \\frac{d}{dx}\\left[\\frac{1}{4}(x^{4} - 2x^{2} + 1)\\right] = \\frac{1}{4}(4x^{3} - 4x) = x^{3} - x = x(x^{2}-1)\n$$\nSetting $U'(x) = 0$ yields the critical points $x=0$, $x=-1$, and $x=+1$.\n\nTo classify these points, we compute the second derivative, $U''(x)$:\n$$\nU''(x) = \\frac{d}{dx}(x^{3}-x) = 3x^{2} - 1\n$$\nWe evaluate $U''(x)$ at each critical point:\n-   At $x=-1$: $U''(-1) = 3(-1)^{2} - 1 = 2  0$. This indicates a local minimum of the potential $U(x)$.\n-   At $x=+1$: $U''(+1) = 3(1)^{2} - 1 = 2  0$. This also indicates a local minimum.\n-   At $x=0$: $U''(0) = 3(0)^{2} - 1 = -1  0$. This indicates a local maximum of the potential, which acts as a saddle point for the dynamics on the real line.\n\nThe two minima at $x=-1$ and $x=+1$ are the stable equilibrium points of the deterministic system. The problem asks for the quasipotential for the transition from the left minimum, $x_{-} = -1$, to the right minimum, $x_{+} = +1$. Let's denote this by $V(-1, +1)$.\n\nAccording to the provided definition, the quasipotential is given by:\n$$\nV(-1, +1) = \\inf_{T0, \\varphi} S_{0}^{T}(\\varphi)\n$$\nwhere the infimum is taken over all absolutely continuous paths $\\varphi$ such that $\\varphi(0)=-1$ and $\\varphi(T)=+1$. The action functional is:\n$$\nS_{0}^{T}(\\varphi) = \\frac{1}{2}\\int_{0}^{T}\\big|\\dot{\\varphi}(t) - b(\\varphi(t))\\big|^{2}\\,\\mathrm{d}t = \\frac{1}{2}\\int_{0}^{T}\\big(\\dot{\\varphi}(t) + U'(\\varphi(t))\\big)^{2}\\,\\mathrm{d}t\n$$\nFor a gradient system of this type, the infimum of the action for a transition between two stable equilibria, $x_a$ and $x_b$, separated by a saddle point $x_s$, is achieved by a specific path known as the \"most probable escape path\" or instanton. This path consists of two segments:\n1.  An \"uphill\" segment from the initial minimum $x_a$ to the saddle point $x_s$, which is the time-reversal of the deterministic trajectory. This path $\\varphi_1$ satisfies the equation $\\dot{\\varphi}_1(t) = -b(\\varphi_1(t)) = +U'(\\varphi_1(t))$.\n2.  A \"downhill\" segment from the saddle point $x_s$ to the final minimum $x_b$, which follows the deterministic dynamics. This path $\\varphi_2$ satisfies $\\dot{\\varphi}_2(t) = b(\\varphi_2(t)) = -U'(\\varphi_2(t))$.\n\nThe total action is the sum of the actions over these two segments. Let us calculate each contribution.\n\nFor the second segment, from the saddle $x_s=0$ to the minimum $x_b=+1$, the path $\\varphi_2$ satisfies $\\dot{\\varphi}_2(t) = b(\\varphi_2(t))$. The action for this segment is:\n$$\nS(\\varphi_2) = \\frac{1}{2}\\int_{t_s}^{t_b} \\big|\\dot{\\varphi}_2(t) - b(\\varphi_2(t))\\big|^{2}\\,\\mathrm{d}t = \\frac{1}{2}\\int_{t_s}^{t_b} \\big|b(\\varphi_2(t)) - b(\\varphi_2(t))\\big|^{2}\\,\\mathrm{d}t = 0\n$$\n\nFor the first segment, from the minimum $x_a=-1$ to the saddle $x_s=0$, the path $\\varphi_1$ satisfies $\\dot{\\varphi}_1(t) = -b(\\varphi_1(t)) = +U'(\\varphi_1(t))$. The action is:\n$$\nS(\\varphi_1) = \\frac{1}{2}\\int_{t_a}^{t_s} \\big|\\dot{\\varphi}_1(t) - b(\\varphi_1(t))\\big|^{2}\\,\\mathrm{d}t = \\frac{1}{2}\\int_{t_a}^{t_s} \\big|-b(\\varphi_1(t)) - b(\\varphi_1(t))\\big|^{2}\\,\\mathrm{d}t = \\frac{1}{2}\\int_{t_a}^{t_s} \\big|-2b(\\varphi_1(t))\\big|^{2}\\,\\mathrm{d}t\n$$\nSubstituting $b(\\varphi_1) = -U'(\\varphi_1)$, this becomes:\n$$\nS(\\varphi_1) = \\frac{1}{2}\\int_{t_a}^{t_s} \\big|2U'(\\varphi_1(t))\\big|^{2}\\,\\mathrm{d}t = 2\\int_{t_a}^{t_s} \\left(U'(\\varphi_1(t))\\right)^{2}\\,\\mathrm{d}t\n$$\nWe can re-express the integrand using the equation for the path $\\dot{\\varphi}_1(t) = U'(\\varphi_1(t))$ and the chain rule for the potential $U(\\varphi_1(t))$:\n$$\n\\frac{d}{dt}U(\\varphi_1(t)) = U'(\\varphi_1(t)) \\cdot \\dot{\\varphi}_1(t) = U'(\\varphi_1(t)) \\cdot U'(\\varphi_1(t)) = \\left(U'(\\varphi_1(t))\\right)^{2}\n$$\nSubstituting this into the integral for the action:\n$$\nS(\\varphi_1) = 2\\int_{t_a}^{t_s} \\frac{d}{dt}U(\\varphi_1(t))\\,\\mathrm{d}t = 2\\Big[U(\\varphi_1(t))\\Big]_{t_a}^{t_s} = 2\\big(U(\\varphi_1(t_s)) - U(\\varphi_1(t_a))\\big)\n$$\nWith $\\varphi_1(t_a) = x_a = -1$ and $\\varphi_1(t_s) = x_s = 0$, the action for the uphill segment is:\n$$\nS(\\varphi_1) = 2\\big(U(0) - U(-1)\\big)\n$$\nThe total quasipotential is the sum of the actions for the two segments:\n$$\nV(-1, +1) = S(\\varphi_1) + S(\\varphi_2) = 2\\big(U(0) - U(-1)\\big) + 0 = 2\\big(U(0) - U(-1)\\big)\n$$\nThis confirms the general result that for a gradient system, the quasipotential to transition between two minima equals twice the potential energy difference between the separating saddle point and the initial minimum.\n\nNow, we compute the values of the potential at $x=-1$ and $x=0$:\n$$\nU(-1) = \\frac{((-1)^{2}-1)^{2}}{4} = \\frac{(1-1)^{2}}{4} = 0\n$$\n$$\nU(0) = \\frac{((0)^{2}-1)^{2}}{4} = \\frac{(-1)^{2}}{4} = \\frac{1}{4}\n$$\nTherefore, the quasipotential is:\n$$\nV(-1, +1) = 2\\left(\\frac{1}{4} - 0\\right) = 2\\left(\\frac{1}{4}\\right) = \\frac{1}{2}\n$$\nThe quasipotential for the transition from the left minimum at $x=-1$ to the right minimum at $x=+1$ is $\\frac{1}{2}$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "3055569"}]}