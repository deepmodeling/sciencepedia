{"hands_on_practices": [{"introduction": "The first step in understanding any stochastic process is to analyze its average behavior. For a standard Ornstein-Uhlenbeck process, the expectation predictably reverts to a constant long-term mean $\\mu$. This exercise challenges you to generalize this analysis to a more dynamic scenario where the target mean itself, $\\mu(t)$, changes over time. By solving for the expected value $\\mathbb{E}[X_t]$, you will practice a fundamental technique and gain intuition on how a mean-reverting process tracks a moving target, a concept widely applicable in areas like interest rate modeling with shifting economic conditions. [@problem_id:859261]", "problem": "The standard Ornstein-Uhlenbeck (OU) process is a stochastic process that describes the velocity of a massive Brownian particle under the influence of friction. It is characterized by a tendency to revert towards a long-term mean. A generalized version of this process can be constructed where the mean-reversion level is not constant but changes over time.\n\nConsider a modified Ornstein-Uhlenbeck process $X_t$ described by the following stochastic differential equation (SDE):\n$$\ndX_t = \\theta (\\mu(t) - X_t) dt + \\sigma dW_t\n$$\nwhere $t \\geq 0$. In this equation:\n- $X_t$ is the value of the process at time $t$.\n- $\\theta > 0$ is the rate of reversion to the mean.\n- $\\sigma > 0$ is the volatility.\n- $W_t$ is a standard Wiener process.\n- $\\mu(t)$ is the time-dependent mean-reversion level, which is given by a linear function of time:\n$$\n\\mu(t) = a + bt\n$$\nfor some real constants $a$ and $b$.\n\nThe process starts from a known deterministic value $X(0) = X_0$.\n\nDerive the expected value of the process, $\\mathbb{E}[X_t]$, for any time $t \\geq 0$.", "solution": "We denote $m(t) = \\mathbb{E}[X_t]$. Taking expectations in the SDE\n$$dX_t=\\theta\\bigl(a+bt -X_t\\bigr)\\,dt+\\sigma\\,dW_t$$\ngives the ODE\n$$\\frac{dm}{dt}=\\theta\\bigl(a+bt -m(t)\\bigr)\\,. $$\n\n1. Rewrite in standard form:\n$$\\frac{dm}{dt}+\\theta\\,m(t)=\\theta\\bigl(a+bt\\bigr)\\,. $$\n\n2. Integrating factor: $I(t)=e^{\\theta t}$. Multiply both sides:\n$$\\frac{d}{dt}\\bigl(e^{\\theta t}m(t)\\bigr)\n=\\theta\\,e^{\\theta t}(a+bt)\\,. $$\n\n3. Integrate from $0$ to $t$:\n$$e^{\\theta t}m(t)-m(0)\n=\\theta\\int_0^t e^{\\theta s}(a+bs)\\,ds\n=\\theta\\Bigl[a\\int_0^te^{\\theta s}ds+b\\int_0^ts\\,e^{\\theta s}ds\\Bigr].$$\n\n4. Compute the integrals symbolically:\n$$\\int_0^te^{\\theta s}ds=\\frac{e^{\\theta t}-1}{\\theta},\\qquad\n\\int_0^ts\\,e^{\\theta s}ds\n=\\frac{t\\,e^{\\theta t}}{\\theta}-\\frac{e^{\\theta t}-1}{\\theta^2}.$$\n\n5. Substitute back and divide by $e^{\\theta t}$:\n\n$$\nm(t)=X_0e^{-\\theta t}\n+a\\bigl(1-e^{-\\theta t}\\bigr)\n+b\\Bigl(t-\\frac{1-e^{-\\theta t}}{\\theta}\\Bigr).\n$$", "answer": "$$\\boxed{X_0e^{-\\theta t}+a\\bigl(1-e^{-\\theta t}\\bigr)+b\\Bigl(t-\\frac{1-e^{-\\theta t}}{\\theta}\\Bigr)}$$", "id": "859261"}, {"introduction": "While the mean describes the central tendency, many applications in finance and engineering require understanding the risk or variability of a process, which is related to its second moment. This practice introduces Itô's Lemma, the cornerstone of stochastic calculus, for finding the dynamics of a function of a process. By deriving the stochastic differential equation for $Y_t = X_t^2$, you will gain essential hands-on experience with the unique rules of Itô calculus and see how the volatility and mean-reversion of $X_t$ together drive the evolution of its squared value. [@problem_id:1282629]", "problem": "In quantitative finance, the Ornstein-Uhlenbeck (OU) process is a popular model for mean-reverting quantities like interest rates. Let the dynamics of a short-term interest rate, $X_t$, be described by the following Stochastic Differential Equation (SDE):\n$$dX_t = \\theta(\\mu - X_t)dt + \\sigma dW_t$$\nHere, $X_t$ represents the interest rate at time $t$. The parameter $\\theta > 0$ is the speed of reversion to the mean, $\\mu$ is the long-term mean interest rate, and $\\sigma > 0$ is the volatility. $W_t$ is a standard Wiener process (also known as Brownian motion).\n\nA financial analyst is interested in studying a simple measure of risk associated with this interest rate, defined as its squared value, $Y_t = X_t^2$. The evolution of this risk measure, $Y_t$, can also be described by an SDE. It can be shown that this new SDE has the general form:\n$$dY_t = \\alpha(X_t) dt + \\beta(X_t) dW_t$$\nwhere $\\alpha(X_t)$ is the drift coefficient and $\\beta(X_t)$ is the diffusion coefficient, both being functions of the original process $X_t$.\n\nDetermine the expressions for the drift coefficient $\\alpha(X_t)$ and the diffusion coefficient $\\beta(X_t)$ for the process $Y_t$. Your answer should be two expressions, presented in a row matrix format corresponding to $(\\alpha(X_t), \\beta(X_t))$.", "solution": "Let $X_t$ satisfy the Ornstein-Uhlenbeck SDE $dX_t = \\theta(\\mu - X_t)dt + \\sigma dW_t$ with $\\theta > 0$ and $\\sigma > 0$. Define $Y_t = X_t^2$. Apply Itô's lemma to the function $f(x) = x^2$:\n$$\ndf(X_t) = f'(X_t)\\,dX_t + \\frac{1}{2} f''(X_t)\\,(dX_t)^2\n$$\nwith derivatives $f'(x) = 2x$ and $f''(x) = 2$. Using Itô calculus rules $(dW_t)^2 = dt$, $dt\\,dW_t = 0$, and $(dt)^2 = 0$, compute\n$$\n(dX_t)^2 = \\left(\\theta(\\mu - X_t)dt + \\sigma dW_t\\right)^2 = \\sigma^2(dW_t)^2 = \\sigma^2 dt.\n$$\nTherefore,\n$$\ndY_t = 2 X_t\\,dX_t + \\frac{1}{2}\\cdot 2\\cdot (dX_t)^2 = 2X_t\\left[\\theta(\\mu - X_t)dt + \\sigma dW_t\\right] + \\sigma^2 dt.\n$$\nCollecting drift and diffusion terms yields\n$$\ndY_t = \\left(2\\theta X_t(\\mu - X_t) + \\sigma^2\\right) dt + \\left(2\\sigma X_t\\right) dW_t.\n$$\nHence the drift and diffusion coefficients are\n$$\n\\alpha(X_t) = 2\\theta X_t(\\mu - X_t) + \\sigma^2, \\qquad \\beta(X_t) = 2\\sigma X_t.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}2\\theta X_t(\\mu - X_t) + \\sigma^{2} & 2\\sigma X_t\\end{pmatrix}}$$", "id": "1282629"}, {"introduction": "Continuous-time models like the Ornstein-Uhlenbeck SDE are powerful theoretically, but for simulation, estimation, and data analysis, we need a discrete-time representation. This exercise provides a crucial bridge between continuous theory and discrete practice. You will derive the exact solution to the OU equation over a finite time step, revealing its deep connection to the autoregressive AR(1) models used in time series analysis, and then translate this analytical result into a working computer program. [@problem_id:3069482]", "problem": "Consider the Ornstein-Uhlenbeck process defined by the stochastic differential equation\n$$\ndX_t = \\kappa \\left(\\mu - X_t\\right)\\,dt + \\sigma\\,dW_t,\n$$\nwhere $X_t$ is a real-valued process, $\\kappa \\ge 0$ is the mean-reversion rate, $\\mu \\in \\mathbb{R}$ is the long-run mean, $\\sigma > 0$ is the diffusion coefficient, and $W_t$ is a standard Wiener process. Use only the following fundamental base: the definition of the Itô integral, the linearity of the Itô integral, the integrating factor method for linear stochastic differential equations, and the Itô isometry for computing variances of Itô integrals.\n\nTask A (derivation): Starting from the given stochastic differential equation and the stated fundamental base, derive the exact discrete-time transition for a fixed step size $\\Delta > 0$. Specifically, express $X_{t+\\Delta}$ as an affine function of $X_t$ plus a mean-zero Gaussian innovation that is independent of $X_t$. Then, by sampling at times $t_n = n\\Delta$, show that the sampled process $\\{X_{t_n}\\}_{n \\in \\mathbb{N}}$ satisfies an autoregressive recursion of order one with independent Gaussian innovations, and identify the autoregressive coefficient and the innovation variance as explicit functions of $\\kappa$, $\\mu$, $\\sigma$, and $\\Delta$. Your derivation must also identify the correct continuous limits for the boundary cases $\\kappa = 0$ and $\\Delta = 0$.\n\nTask B (program): Implement a program that, for each parameter quadruple $(\\kappa,\\mu,\\sigma,\\Delta)$ in the test suite below, computes:\n- the autoregressive coefficient $\\phi$ associated with the sampled process at interval $\\Delta$,\n- the innovation standard deviation $s_{\\varepsilon}$,\n- a boolean diagnostic $b$ defined as follows:\n  - If $\\Delta = 0$, set $b$ to true.\n  - Else if $\\kappa > 0$, compute both the stationary variance implied by the discrete-time recursion, $s_{\\varepsilon}^2/(1-\\phi^2)$, and the continuous-time stationary variance, $\\sigma^2/(2\\kappa)$, and set $b$ to true if these two quantities are equal within absolute tolerance $10^{-12}$ or relative tolerance $10^{-10}$; otherwise set $b$ to false.\n  - Else (i.e., $\\kappa = 0$ and $\\Delta > 0$), set $b$ to true if $s_{\\varepsilon}^2$ equals $\\sigma^2 \\Delta$ within absolute tolerance $10^{-12}$ or relative tolerance $10^{-10}$; otherwise set $b$ to false.\n\nEdge-case handling and continuity requirements:\n- For $\\kappa = 0$, your program must use the continuous limit of the innovation variance in place of any formula that involves division by $\\kappa$.\n- For $\\Delta = 0$, your program must return $\\phi = 1$ and $s_{\\varepsilon} = 0$.\n\nTest suite:\nUse exactly the following five parameter sets (with the order preserved) to form the test suite:\n1. $(\\kappa,\\mu,\\sigma,\\Delta) = (0.7,\\,1.2,\\,0.5,\\,0.1)$\n2. $(\\kappa,\\mu,\\sigma,\\Delta) = (0,\\,0.0,\\,1.0,\\,0.25)$\n3. $(\\kappa,\\mu,\\sigma,\\Delta) = (2.0,\\,-0.5,\\,0.3,\\,1.0)$\n4. $(\\kappa,\\mu,\\sigma,\\Delta) = (1.1,\\,2.0,\\,0.8,\\,0)$\n5. $(\\kappa,\\mu,\\sigma,\\Delta) = (5.0,\\,0.0,\\,2.0,\\,10^{-8})$\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element of this list corresponds to one test case and must itself be a list $[\\phi, s_{\\varepsilon}, b]$, where $\\phi$ and $s_{\\varepsilon}$ are real numbers and $b$ is a boolean. For example, a valid output structure is\n$$\n[[\\phi_1, s_{\\varepsilon,1}, b_1],[\\phi_2, s_{\\varepsilon,2}, b_2],\\dots]\n$$\nwith no additional text before or after the line.", "solution": "The problem requires the derivation of the exact discrete-time transition for the Ornstein-Uhlenbeck (OU) process and its implementation in a program. The validation of the problem statement is the first step.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **SDE**: $dX_t = \\kappa (\\mu - X_t) dt + \\sigma dW_t$\n-   **Parameters**: $\\kappa \\ge 0$ (mean-reversion rate), $\\mu \\in \\mathbb{R}$ (long-run mean), $\\sigma > 0$ (diffusion coefficient), $W_t$ (standard Wiener process).\n-   **Methodological Constraints**: Use only the definition of the Itô integral, its linearity, the integrating factor method for linear SDEs, and the Itô isometry.\n-   **Task A (Derivation)**: Derive the exact discrete-time transition $X_{t+\\Delta} = f(X_t, \\text{innovation})$, show it is an AR(1) process for sampled times, identify the autoregressive coefficient $\\phi$ and innovation variance $\\sigma_\\varepsilon^2$, and find the limits for $\\kappa = 0$ and $\\Delta = 0$.\n-   **Task B (Program)**: Compute $[\\phi, s_{\\varepsilon}, b]$ for given test cases, where $s_\\varepsilon$ is the innovation standard deviation and $b$ is a boolean diagnostic checking the consistency of stationary variances or limiting behavior.\n-   **Edge Cases**: Specific handling for $\\Delta=0$ ($\\phi=1, s_\\varepsilon=0, b=\\text{true}$) and $\\kappa=0$ (use limit for innovation variance).\n-   **Test Suite**: Five quadruples of $(\\kappa, \\mu, \\sigma, \\Delta)$ are provided.\n-   **Output Format**: A single line representing a list of lists: $[[\\phi_1, s_{\\varepsilon,1}, b_1], \\dots, [\\phi_5, s_{\\varepsilon,5}, b_5]]$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The Ornstein-Uhlenbeck process is a fundamental concept in stochastic processes, with well-established theory. The problem is scientifically and mathematically sound.\n-   **Well-Posedness**: The problem is well-posed. It asks for a standard derivation and a direct implementation of the derived formulas. All parameters, constraints, and objectives are clearly defined, leading to a unique solution.\n-   **Objectivity**: The language is formal and mathematical, free from subjectivity or ambiguity.\n-   **Overall Assessment**: The problem does not violate any of the invalidity criteria. It is a standard, self-contained, and non-trivial problem in applied stochastic calculus.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A solution will be provided.\n\n### Task A: Derivation\n\nThe Ornstein-Uhlenbeck process is described by the stochastic differential equation (SDE):\n$$\ndX_t = \\kappa (\\mu - X_t) dt + \\sigma dW_t\n$$\nThis SDE is a linear first-order equation. We can rewrite it as:\n$$\ndX_t + \\kappa X_t dt = \\kappa \\mu dt + \\sigma dW_t\n$$\nTo solve this, we use the integrating factor method. The integrating factor is $I(t) = e^{\\int \\kappa ds} = e^{\\kappa t}$. We consider the process $Y_t = e^{\\kappa t} X_t$.\nUsing Itô's lemma for $f(t, X_t) = e^{\\kappa t} X_t$, with $\\frac{\\partial f}{\\partial t} = \\kappa e^{\\kappa t} X_t$, $\\frac{\\partial f}{\\partial x} = e^{\\kappa t}$, and $\\frac{\\partial^2 f}{\\partial x^2} = 0$, we find the differential of $Y_t$:\n$$\nd(e^{\\kappa t} X_t) = (\\kappa e^{\\kappa t} X_t) dt + e^{\\kappa t} dX_t\n$$\nSubstituting the expression for $dX_t$:\n$$\nd(e^{\\kappa t} X_t) = \\kappa e^{\\kappa t} X_t dt + e^{\\kappa t} (\\kappa \\mu dt - \\kappa X_t dt + \\sigma dW_t)\n$$\nThe terms involving $X_t$ cancel out:\n$$\nd(e^{\\kappa t} X_t) = \\kappa \\mu e^{\\kappa t} dt + \\sigma e^{\\kappa t} dW_t\n$$\nIntegrating both sides from a starting time $t$ to a future time $t+\\Delta$ (where $\\Delta > 0$):\n$$\n\\int_t^{t+\\Delta} d(e^{\\kappa s} X_s) = \\int_t^{t+\\Delta} \\kappa \\mu e^{\\kappa s} ds + \\int_t^{t+\\Delta} \\sigma e^{\\kappa s} dW_s\n$$\n$$\ne^{\\kappa (t+\\Delta)} X_{t+\\Delta} - e^{\\kappa t} X_t = \\kappa \\mu \\int_t^{t+\\Delta} e^{\\kappa s} ds + \\sigma \\int_t^{t+\\Delta} e^{\\kappa s} dW_s\n$$\nFor the case $\\kappa > 0$, the first integral on the right-hand side is:\n$$\n\\kappa \\mu \\left[ \\frac{1}{\\kappa} e^{\\kappa s} \\right]_t^{t+\\Delta} = \\mu (e^{\\kappa(t+\\Delta)} - e^{\\kappa t})\n$$\nSubstituting this back and solving for $X_{t+\\Delta}$:\n$$\ne^{\\kappa (t+\\Delta)} X_{t+\\Delta} = e^{\\kappa t} X_t + \\mu (e^{\\kappa(t+\\Delta)} - e^{\\kappa t}) + \\sigma \\int_t^{t+\\Delta} e^{\\kappa s} dW_s\n$$\nMultiplying by $e^{-\\kappa(t+\\Delta)}$ isolates $X_{t+\\Delta}$:\n$$\nX_{t+\\Delta} = e^{-\\kappa\\Delta} X_t + \\mu (1 - e^{-\\kappa\\Delta}) + \\sigma e^{-\\kappa(t+\\Delta)} \\int_t^{t+\\Delta} e^{\\kappa s} dW_s\n$$\nThe last term can be rewritten by changing the integration variable in the stochastic integral:\n$$\nX_{t+\\Delta} = (1 - e^{-\\kappa\\Delta})\\mu + e^{-\\kappa\\Delta} X_t + \\sigma \\int_t^{t+\\Delta} e^{-\\kappa(t+\\Delta-s)} dW_s\n$$\nThis equation expresses $X_{t+\\Delta}$ as an affine function of $X_t$ plus an innovation term. For a process sampled at discrete times $t_n = n\\Delta$, we have the recursion:\n$$\nX_{t_{n+1}} = c + \\phi X_{t_n} + \\varepsilon_{n+1}\n$$\nThis is an autoregressive process of order one, AR(1). The coefficients are:\n-   Autoregressive coefficient: $\\phi = e^{-\\kappa\\Delta}$\n-   Constant term: $c = (1 - e^{-\\kappa\\Delta})\\mu$\n-   Innovation term: $\\varepsilon_{n+1} = \\sigma \\int_{t_n}^{t_{n+1}} e^{-\\kappa(t_{n+1}-s)} dW_s$\n\nThe innovation $\\varepsilon_{n+1}$ is an Itô integral of a deterministic function against a Wiener process. Thus, it is a Gaussian random variable with mean zero. Because the increments of the Wiener process are independent, the innovations $\\{\\varepsilon_n\\}$ form an independent and identically distributed sequence, and each $\\varepsilon_{n+1}$ is independent of $X_{t_n}$ (which depends on $W_s$ for $s \\le t_n$).\n\nTo find the variance of the innovation, $\\sigma_\\varepsilon^2 = E[\\varepsilon_{n+1}^2]$, we use the Itô isometry:\n$$\n\\sigma_\\varepsilon^2 = E\\left[ \\left( \\sigma \\int_{t_n}^{t_{n+1}} e^{-\\kappa(t_{n+1}-s)} dW_s \\right)^2 \\right] = \\sigma^2 \\int_{t_n}^{t_{n+1}} \\left( e^{-\\kappa(t_{n+1}-s)} \\right)^2 ds = \\sigma^2 \\int_{t_n}^{t_{n+1}} e^{-2\\kappa(t_{n+1}-s)} ds\n$$\nLet $u = t_n - s$. The integral becomes: $\\int_{-\\Delta}^0 e^{-2\\kappa(-\\Delta-u)} (-du) = \\int_0^{\\Delta} e^{-2\\kappa(\\Delta-v)} dv$ by changing variables. A simpler substitution $u = s-t_n$ gives:\n$$\n\\sigma_\\varepsilon^2 = \\sigma^2 \\int_{0}^{\\Delta} e^{-2\\kappa(\\Delta-u)} du = \\sigma^2 e^{-2\\kappa\\Delta} \\int_{0}^{\\Delta} e^{2\\kappa u} du = \\sigma^2 e^{-2\\kappa\\Delta} \\left[ \\frac{e^{2\\kappa u}}{2\\kappa} \\right]_0^{\\Delta} = \\frac{\\sigma^2 e^{-2\\kappa\\Delta}}{2\\kappa}(e^{2\\kappa\\Delta}-1)\n$$\nThus, for $\\kappa > 0$, the innovation variance is:\n$$\n\\sigma_\\varepsilon^2 = \\frac{\\sigma^2}{2\\kappa} (1-e^{-2\\kappa\\Delta})\n$$\n\n**Continuous Limits:**\n\n1.  **Case $\\Delta \\to 0$**:\n    -   $\\phi = e^{-\\kappa\\Delta} \\to e^0 = 1$.\n    -   Using the Taylor expansion $e^{-x} \\approx 1-x$ for small $x$, the innovation variance becomes $\\sigma_\\varepsilon^2 \\approx \\frac{\\sigma^2}{2\\kappa}(1-(1-2\\kappa\\Delta)) = \\sigma^2\\Delta$. As $\\Delta \\to 0$, $\\sigma_\\varepsilon^2 \\to 0$. This gives $s_\\varepsilon=\\sqrt{\\sigma_\\varepsilon^2} \\to 0$. The problem specifies that for $\\Delta=0$, we must use $\\phi=1$ and $s_\\varepsilon=0$, which is consistent with this limit.\n\n2.  **Case $\\kappa = 0$**:\n    The SDE simplifies to $dX_t = \\sigma dW_t$. The exact solution is $X_{t+\\Delta} = X_t + \\sigma(W_{t+\\Delta}-W_t)$. This is an AR(1) process with $\\phi=1$ and an innovation $\\varepsilon = \\sigma(W_{t+\\Delta}-W_t)$ which has variance $\\sigma^2 \\Delta$.\n    We can confirm this by taking the limit of our general formulas as $\\kappa \\to 0$.\n    -   $\\phi = e^{-\\kappa\\Delta} \\to e^0 = 1$.\n    -   For the variance, we have a $\\frac{0}{0}$ indeterminacy. Using L'Hôpital's rule on the ratio $f(\\kappa)/g(\\kappa) = (1-e^{-2\\kappa\\Delta})/(2\\kappa)$:\n        $$\n        \\lim_{\\kappa \\to 0} \\sigma_\\varepsilon^2 = \\sigma^2 \\lim_{\\kappa \\to 0} \\frac{\\frac{d}{d\\kappa}(1-e^{-2\\kappa\\Delta})}{\\frac{d}{d\\kappa}(2\\kappa)} = \\sigma^2 \\lim_{\\kappa \\to 0} \\frac{-e^{-2\\kappa\\Delta}(-2\\Delta)}{2} = \\sigma^2 \\Delta\n        $$\n    These results provide the formulas for the $\\kappa=0$ edge case.\n\n**Stationary Variance Consistency Check**\nFor the AR(1) process to be stationary, we require $|\\phi| < 1$, which holds for $\\kappa>0, \\Delta>0$. The stationary variance of the discrete process is $V = \\frac{\\sigma_\\varepsilon^2}{1-\\phi^2}$. Substituting our derived expressions:\n$$\nV = \\frac{\\frac{\\sigma^2}{2\\kappa}(1-e^{-2\\kappa\\Delta})}{1-(e^{-\\kappa\\Delta})^2} = \\frac{\\frac{\\sigma^2}{2\\kappa}(1-e^{-2\\kappa\\Delta})}{1-e^{-2\\kappa\\Delta}} = \\frac{\\sigma^2}{2\\kappa}\n$$\nThis is identical to the stationary variance of the continuous-time OU process. This analytical identity justifies the boolean diagnostic `b`, which checks if this equality holds numerically.\n\n**Summary of Formulas for Implementation:**\n-   If $\\Delta=0$: $\\phi=1$, $s_\\varepsilon=0$.\n-   If $\\Delta>0$ and $\\kappa=0$: $\\phi=1$, $s_\\varepsilon = \\sigma\\sqrt{\\Delta}$.\n-   If $\\Delta>0$ and $\\kappa>0$: $\\phi=e^{-\\kappa\\Delta}$, $s_\\varepsilon = \\sqrt{\\frac{\\sigma^2}{2\\kappa}(1-e^{-2\\kappa\\Delta})}$.\nThe boolean $b$ will be computed by checking the appropriate variance identities as specified in the problem statement.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes autoregressive parameters and a diagnostic for the discretized\n    Ornstein-Uhlenbeck process for a given set of test cases.\n    \"\"\"\n    \n    # Test suite: (kappa, mu, sigma, delta)\n    test_cases = [\n        (0.7, 1.2, 0.5, 0.1),\n        (0.0, 0.0, 1.0, 0.25),\n        (2.0, -0.5, 0.3, 1.0),\n        (1.1, 2.0, 0.8, 0.0),\n        (5.0, 0.0, 2.0, 1e-8),\n    ]\n\n    results = []\n\n    def is_close(a, b, rtol, atol):\n        \"\"\"\n        Checks if two floats are close, with an 'or' condition for\n        absolute and relative tolerances, as specified in the problem.\n        \"\"\"\n        if abs(a - b) <= atol:\n            return True\n        # The relative tolerance check is only meaningful if the reference value is non-zero\n        if b != 0:\n            if abs(a - b) / abs(b) <= rtol:\n                return True\n        # If b is zero, the absolute tolerance check is the only one that applies.\n        return False\n\n    for case in test_cases:\n        kappa, mu, sigma, delta = case\n        \n        phi = 0.0\n        s_varepsilon = 0.0\n        b = False\n        \n        # Absolute and relative tolerances for the diagnostic check\n        atol = 1e-12\n        rtol = 1e-10\n\n        # Handle edge cases and main logic based on problem statement\n        if delta == 0:\n            phi = 1.0\n            s_varepsilon = 0.0\n            b = True\n        elif kappa == 0: # and delta > 0\n            phi = 1.0\n            s_varepsilon_sq = sigma**2 * delta\n            s_varepsilon = np.sqrt(s_varepsilon_sq)\n            \n            # Diagnostic check for kappa = 0 case\n            variance_limit = sigma**2 * delta\n            b = is_close(s_varepsilon_sq, variance_limit, rtol, atol)\n        else: # kappa > 0 and delta > 0\n            phi = np.exp(-kappa * delta)\n            \n            # Use a numerically stable way to compute (1 - exp(-x)) for small x\n            # This is equivalent to sigma**2/(2*kappa) * (1 - np.exp(-2*kappa*delta))\n            # Or sigma**2/(2*kappa) * -np.expm1(-2*kappa*delta)\n            s_varepsilon_sq = (sigma**2 / (2 * kappa)) * (1 - phi**2)\n            s_varepsilon = np.sqrt(s_varepsilon_sq)\n            \n            # Diagnostic check for kappa > 0 case.\n            # The denominator (1 - phi**2) can be close to zero if kappa*delta is small,\n            # but it is non-zero for kappa > 0 and delta > 0.\n            if 1 - phi**2 == 0:\n                # This case should not be reached given kappa>0, delta>0, but as a safeguard:\n                # if 1-phi^2 is numerically zero, the discrete variance is infinite.\n                # The continuous variance is finite. So they are not equal.\n                b = False\n            else:\n                discrete_stationary_var = s_varepsilon_sq / (1 - phi**2)\n                continuous_stationary_var = sigma**2 / (2 * kappa)\n                b = is_close(discrete_stationary_var, continuous_stationary_var, rtol, atol)\n\n        results.append([phi, s_varepsilon, b])\n\n    # Format the final output string to match the required format exactly,\n    # without spaces inside the inner lists.\n    # str() of a list adds spaces, so we remove them.\n    final_output = str(results).replace(\" \", \"\")\n    print(final_output)\n\nsolve()\n```", "id": "3069482"}]}