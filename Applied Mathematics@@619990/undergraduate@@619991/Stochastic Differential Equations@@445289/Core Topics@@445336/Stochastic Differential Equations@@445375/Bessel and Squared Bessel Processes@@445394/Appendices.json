{"hands_on_practices": [{"introduction": "One of the first steps in understanding any new stochastic process is to determine its average behavior. This practice guides you through a fundamental calculation to find the expected value of a squared Bessel process directly from its defining stochastic differential equation (SDE). By solving this, you will uncover the precise role of the dimension parameter $\\delta$ as the constant drift of the mean squared radius, providing a crucial piece of intuition for the process's long-term evolution [@problem_id:3040417].", "problem": "Let $\\{X_t\\}_{t \\geq 0}$ be a squared Bessel process of dimension $\\delta \\geq 0$, defined as the unique nonnegative strong solution to the stochastic differential equation (SDE)\n$$\ndX_t \\;=\\; \\delta \\, dt \\;+\\; 2 \\sqrt{X_t}\\, dW_t, \\qquad X_0 = x \\geq 0,\n$$\nwhere $\\{W_t\\}_{t \\geq 0}$ is a standard one-dimensional Brownian motion and $t \\mapsto \\sqrt{X_t}$ is interpreted as $0$ when $X_t=0$. Starting from the SDE and using only standard properties of Itô integrals and conditional expectation (do not assume any ready-made formula for the expectation of $X_t$), derive a closed-form expression for the conditional expectation $\\,\\mathbb{E}[X_t \\mid X_0 = x]\\,$ as a function of $t$, $x$, and $\\delta$. Then, briefly interpret the role of $\\delta$ in terms of the average evolution of the squared radius.\n\nProvide your final result as a single symbolic expression in terms of $x$, $\\delta$, and $t$. No numerical approximation is required.", "solution": "The problem asks for the derivation of the conditional expectation $\\,\\mathbb{E}[X_t \\mid X_0 = x]\\,$ for a squared Bessel process $\\{X_t\\}_{t \\geq 0}$ of dimension $\\delta \\geq 0$. The process is defined by the stochastic differential equation (SDE):\n$$\ndX_t \\;=\\; \\delta \\, dt \\;+\\; 2 \\sqrt{X_t}\\, dW_t, \\qquad X_0 = x \\geq 0\n$$\nwhere $\\{W_t\\}_{t \\geq 0}$ is a standard one-dimensional Brownian motion.\n\nThe derivation must proceed from this SDE using only standard properties of Itô integrals and conditional expectation.\n\nFirst, we write the SDE in its integral form by integrating both sides from time $0$ to time $t$:\n$$\n\\int_0^t dX_s \\;=\\; \\int_0^t \\delta \\, ds \\;+\\; \\int_0^t 2 \\sqrt{X_s}\\, dW_s\n$$\nThis yields:\n$$\nX_t - X_0 \\;=\\; \\delta t \\;+\\; 2 \\int_0^t \\sqrt{X_s}\\, dW_s\n$$\nGiven the initial condition $X_0 = x$, we can write:\n$$\nX_t \\;=\\; x \\;+\\; \\delta t \\;+\\; 2 \\int_0^t \\sqrt{X_s}\\, dW_s\n$$\nNow, we compute the conditional expectation $\\,\\mathbb{E}[X_t \\mid X_0 = x]\\,$. We apply the conditional expectation operator to both sides of the equation. Note that conditioning on the event $\\{X_0 = x\\}$ means we treat $X_0$ as the deterministic starting value $x$.\n$$\n\\mathbb{E}[X_t \\mid X_0 = x] \\;=\\; \\mathbb{E}\\left[x \\;+\\; \\delta t \\;+\\; 2 \\int_0^t \\sqrt{X_s}\\, dW_s \\mid X_0 = x\\right]\n$$\nBy the linearity of expectation, we can separate the terms:\n$$\n\\mathbb{E}[X_t \\mid X_0 = x] \\;=\\; \\mathbb{E}[x \\mid X_0 = x] \\;+\\; \\mathbb{E}[\\delta t \\mid X_0 = x] \\;+\\; \\mathbb{E}\\left[2 \\int_0^t \\sqrt{X_s}\\, dW_s \\mid X_0 = x\\right]\n$$\nLet us evaluate each term on the right-hand side:\n1.  The term $x$ is a constant determined by the initial condition. Therefore, its expectation is $x$:\n    $$\n    \\mathbb{E}[x \\mid X_0 = x] \\;=\\; x\n    $$\n2.  The term $\\delta t$ is also deterministic, being a product of two constants for a fixed time $t$. Thus:\n    $$\n    \\mathbb{E}[\\delta t \\mid X_0 = x] \\;=\\; \\delta t\n    $$\n3.  The third term involves an Itô stochastic integral. We can pull the constant $2$ out of the expectation:\n    $$\n    \\mathbb{E}\\left[2 \\int_0^t \\sqrt{X_s}\\, dW_s \\mid X_0 = x\\right] \\;=\\; 2 \\, \\mathbb{E}\\left[\\int_0^t \\sqrt{X_s}\\, dW_s \\mid X_0 = x\\right]\n    $$\n    A fundamental property of the Itô integral is that for a suitable integrand process $\\{H_s\\}_{s \\geq 0}$, the stochastic integral process $M_t = \\int_0^t H_s dW_s$ is a martingale, provided that the process is adapted and $\\mathbb{E}\\left[\\int_0^t H_s^2 \\, ds\\right]  \\infty$. A key property of a martingale starting at $M_0=0$ is that its expectation at any future time is zero, i.e., $\\mathbb{E}[M_t] = 0$.\n\n    In our case, the integrand is $H_s = \\sqrt{X_s}$. Since $\\{X_t\\}$ is a solution to the SDE driven by $\\{W_t\\}$, it is adapted to the filtration generated by $\\{W_t\\}$. Consequently, $\\{H_s = \\sqrt{X_s}\\}$ is also an adapted process. The Itô integral $\\int_0^t \\sqrt{X_s}\\, dW_s$ is a local martingale. For it to be a true martingale, we must verify the integrability condition:\n    $$\n    \\mathbb{E}\\left[\\int_0^t \\left(\\sqrt{X_s}\\right)^2 ds\\right] \\;=\\; \\mathbb{E}\\left[\\int_0^t X_s \\, ds\\right]  \\infty\n    $$\n    Using Fubini's theorem, this is equivalent to $\\int_0^t \\mathbb{E}[X_s] \\, ds  \\infty$. For solutions to SDEs of this type, it is a standard result that the expectation $\\mathbb{E}[|X_s|]$ is finite for finite $s$, and thus the integral is finite for finite $t$. Therefore, the process $M_t = \\int_0^t \\sqrt{X_s} \\, dW_s$ is a true martingale.\n    Since $M_0 = \\int_0^0 \\sqrt{X_s} \\, dW_s = 0$, the martingale property implies that its conditional expectation (given information at time $0$) is equal to its initial value:\n    $$\n    \\mathbb{E}\\left[\\int_0^t \\sqrt{X_s}\\, dW_s \\mid X_0 = x\\right] \\;=\\; 0\n    $$\nSubstituting these results back into the equation for $\\mathbb{E}[X_t \\mid X_0 = x]$, we get:\n$$\n\\mathbb{E}[X_t \\mid X_0 = x] \\;=\\; x \\;+\\; \\delta t \\;+\\; 2 \\cdot 0\n$$\n$$\n\\mathbb{E}[X_t \\mid X_0 = x] \\;=\\; x \\;+\\; \\delta t\n$$\nThis is the closed-form expression for the conditional expectation.\n\n**Interpretation of $\\delta$:**\nThe result $\\mathbb{E}[X_t \\mid X_0 = x] = x + \\delta t$ shows that the expected value of the squared Bessel process evolves linearly in time. The parameter $\\delta$, which is the dimension of the process, acts as the constant drift coefficient for the mean squared radius.\n- If $\\delta  0$, the average squared radius increases linearly with time, indicating an overall drift away from the origin.\n- If $\\delta = 0$, the average squared radius remains constant at its initial value $x$. The process is a martingale in this case.\n- The quantity $X_t$ can be interpreted as the squared Euclidean distance from the origin of a particle undergoing stochastic motion in $\\mathbb{R}^k$ for integer $k=\\delta$. The formula shows that the average squared distance from the origin grows linearly with time, and the rate of this growth is precisely the dimension $\\delta$. This generalizes to non-integer $\\delta \\geq 0$. In essence, $\\delta$ quantifies the strength of the outward \"push\" on the average squared radius of the process.", "answer": "$$\\boxed{x + \\delta t}$$", "id": "3040417"}, {"introduction": "While the mean describes the average trajectory, the quadratic variation quantifies the magnitude of the random fluctuations around that average. This exercise uses Itô’s formula to derive the quadratic variation for both the Bessel process $R_t$ and its square $X_t$. This hands-on calculation is essential for cementing your understanding of how the diffusion coefficients in the SDEs translate into the realized volatility of the process paths [@problem_id:3040481].", "problem": "Let $\\{W_t\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion, and fix parameters $\\delta \\in (0,\\infty)$ and $r \\in (0,\\infty)$. Consider the $\\delta$-dimensional Bessel process $\\{R_t\\}_{t \\geq 0}$, defined as the strong solution of the stochastic differential equation (SDE)\n$$\ndR_t \\;=\\; dW_t \\;+\\; \\frac{\\delta - 1}{2\\,R_t}\\,dt, \\qquad R_0 \\;=\\; r,\n$$\nand define its squared Bessel process $\\{X_t\\}_{t \\geq 0}$ by $X_t := R_t^2$. Using only the foundational definitions from stochastic calculus, including the definition of quadratic variation and Itô’s formula, derive the quadratic variations of $R_t$ and $X_t$ and verify that they have the canonical forms associated with their diffusion coefficients. Your final answer must be a single closed-form analytic expression that simultaneously gives the quadratic variations $[R]_t$ and $[X]_t$ up to time $t$ in terms of $t$ and the path $\\{X_s\\}_{0 \\leq s \\leq t}$. No numerical evaluation is required.", "solution": "We begin from the given stochastic differential equation (SDE) for the $\\delta$-dimensional Bessel process $\\{R_t\\}_{t \\geq 0}$:\n$$\ndR_t \\;=\\; dW_t \\;+\\; \\frac{\\delta - 1}{2\\,R_t}\\,dt, \\qquad R_0 \\;=\\; r,\n$$\nwhere $\\{W_t\\}_{t \\geq 0}$ is a standard one-dimensional Brownian motion. The squared Bessel process is defined by $X_t := R_t^2$.\n\nWe recall the fundamental definition of quadratic variation for a continuous semimartingale. If a continuous semimartingale $Y_t$ admits the decomposition $Y_t = Y_0 + M_t + A_t$, where $M_t$ is a continuous local martingale and $A_t$ is of finite variation, then the quadratic variation $[Y]_t$ is defined by $[Y]_t = [M]_t$, and for an Itô integral of the form $M_t = \\int_0^t \\sigma_s\\,dW_s$ we have\n$$\n[M]_t \\;=\\; \\int_0^t \\sigma_s^2\\,ds.\n$$\nThis follows from the Itô isometry and the characterization of quadratic variation for continuous local martingales.\n\nStep $1$: Quadratic variation of $R_t$. The SDE for $R_t$ shows that $R_t$ is a continuous semimartingale with the decomposition\n$$\nR_t \\;=\\; r \\;+\\; \\underbrace{\\int_0^t \\frac{\\delta - 1}{2\\,R_s}\\,ds}_{\\text{finite variation}} \\;+\\; \\underbrace{\\int_0^t 1 \\cdot dW_s}_{\\text{continuous local martingale}}.\n$$\nHence, the continuous local martingale part of $R_t$ is $M_t^{(R)} = \\int_0^t 1 \\cdot dW_s$. Therefore, by the definition of quadratic variation for a continuous local martingale,\n$$\n[R]_t \\;=\\; [M^{(R)}]_t \\;=\\; \\int_0^t 1^2\\,ds \\;=\\; t.\n$$\n\nStep $2$: Derive the SDE for $X_t = R_t^2$ and its quadratic variation. By Itô’s formula applied to the function $f(x) = x^2$, we have for $X_t = f(R_t)$,\n$$\ndX_t \\;=\\; f'(R_t)\\,dR_t \\;+\\; \\frac{1}{2} f''(R_t)\\,d[R]_t.\n$$\nSince $f'(x) = 2x$ and $f''(x) = 2$, and we already computed $d[R]_t = dt$, we obtain\n$$\ndX_t \\;=\\; 2R_t\\,dR_t \\;+\\; 1 \\cdot dt.\n$$\nSubstituting $dR_t = dW_t + \\frac{\\delta - 1}{2\\,R_t}\\,dt$ into the above,\n$$\ndX_t \\;=\\; 2R_t\\left(dW_t + \\frac{\\delta - 1}{2\\,R_t}\\,dt\\right) \\;+\\; dt \\;=\\; 2R_t\\,dW_t \\;+\\; (\\delta - 1)\\,dt \\;+\\; dt \\;=\\; 2R_t\\,dW_t \\;+\\; \\delta\\,dt.\n$$\nSince $X_t = R_t^2$ and $R_t \\geq 0$ for a Bessel process, we have $R_t = \\sqrt{X_t}$, hence the SDE can be written as\n$$\ndX_t \\;=\\; 2\\sqrt{X_t}\\,dW_t \\;+\\; \\delta\\,dt.\n$$\nThis displays $X_t$ as a continuous semimartingale with continuous local martingale part $M_t^{(X)} = \\int_0^t 2\\sqrt{X_s}\\,dW_s$. Therefore, using the definition of quadratic variation for a continuous local martingale,\n$$\n[X]_t \\;=\\; [M^{(X)}]_t \\;=\\; \\int_0^t \\left(2\\sqrt{X_s}\\right)^2 ds \\;=\\; \\int_0^t 4 X_s\\,ds.\n$$\n\nThus, starting from the SDE for the Bessel process, applying Itô’s formula, and using the definition of quadratic variation for continuous local martingales, we have verified the canonical forms\n$$\n[R]_t \\;=\\; t, \\qquad [X]_t \\;=\\; \\int_0^t 4 X_s\\,ds.\n$$\nThese forms are consistent with the diffusion coefficients $1$ for $R_t$ and $2\\sqrt{X_t}$ for $X_t$, respectively.", "answer": "$$\\boxed{\\begin{pmatrix} t  \\int_{0}^{t} 4\\,X_{s}\\,ds \\end{pmatrix}}$$", "id": "3040481"}, {"introduction": "Bridging the gap between theory and practice is a vital skill in quantitative fields. This exercise moves from analytical derivations to computational implementation, tasking you with building an exact sampler for the squared Bessel process at a fixed point in time [@problem_id:3040473]. By leveraging the known connection between the process and the noncentral chi-square distribution, you will not only create a powerful simulation tool but also validate your code against the theoretical mean and variance, closing the loop between analytical results and computational practice.", "problem": "Consider the squared Bessel process of dimension $\\delta$, denoted $\\mathrm{BESQ}(\\delta)$, defined as the unique strong solution to the Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_t = \\delta\\,\\mathrm{d}t + 2\\sqrt{X_t}\\,\\mathrm{d}W_t,\\quad X_0 = x_0 \\ge 0,\n$$\nwhere $W_t$ is a standard Brownian motion. A fundamental characterization of $\\mathrm{BESQ}(\\delta)$ is that its Laplace transform admits the explicit form\n$$\n\\mathbb{E}\\big[\\exp(-\\lambda X_t)\\big] = \\exp\\!\\left(-\\frac{x_0 \\lambda}{1+2t\\lambda}\\right)\\,(1+2t\\lambda)^{-\\delta/2},\\quad \\lambda \\ge 0.\n$$\nThis implies that the scaled variable $Y_t := X_t/t$ has the noncentral chi-square distribution with degrees of freedom $\\delta$ and noncentrality parameter $\\kappa := x_0/t$, equivalently the noncentral gamma distribution with shape $\\delta/2$, scale $2$, and noncentrality parameter $\\kappa$. Therefore, an exact sampling scheme for $X_t$ at any fixed $t0$ can be constructed by using a Poisson-gamma mixture: if $K \\sim \\mathrm{Poisson}(\\kappa/2)$ and, conditionally on $K$, $G \\sim \\mathrm{Gamma}(\\delta/2 + K, 2)$, then $Y_t \\overset{d}{=} G$ and $X_t \\overset{d}{=} t\\,G$. The theoretical mean and variance for $\\mathrm{BESQ}(\\delta)$ at time $t$ are given by\n$$\n\\mathbb{E}[X_t] = x_0 + \\delta t,\\qquad \\mathrm{Var}(X_t) = 2\\delta t^2 + 4 x_0 t.\n$$\n\nYour task is to implement an exact sampler for $\\mathrm{BESQ}(\\delta)$ at a fixed time $t$ using the noncentral gamma distribution via the Poisson-gamma mixture described above, and to analyze parameter regimes for numerical stability. Specifically:\n\n- Implement the Poisson-gamma mixture sampler for $X_t$ based on the representation $X_t \\overset{d}{=} t\\,G$ where $G$ is as above, using a reproducible random number generator with a fixed seed.\n- Identify a regime where the Poisson mean $\\mu := x_0/(2t)$ is large, which can cause numerical instability or inefficiency for direct Poisson-gamma sampling due to very large shape parameters for the gamma distribution. In such regimes, switch to an alternative exact sampler for the noncentral chi-square distribution and then scale by $t$.\n- Use the theoretical mean and variance to validate your sampler by computing empirical mean and variance from independent samples and checking their relative errors against specified tolerances.\n\nFundamental base to be used:\n- The SDE definition of $\\mathrm{BESQ}(\\delta)$ and the Laplace transform identity for $X_t$.\n- The equivalence between the scaled law $Y_t := X_t/t$ and a noncentral chi-square (noncentral gamma) distribution characterized by degrees of freedom $\\delta$, scale parameter $2$, and noncentrality parameter $\\kappa = x_0/t$.\n- The Poisson-gamma mixture representation for noncentral chi-square variables: if $K \\sim \\mathrm{Poisson}(\\kappa/2)$, then conditionally $Y \\mid K \\sim \\mathrm{Gamma}(\\delta/2 + K, 2)$ yields $Y \\sim \\chi'^2(\\delta, \\kappa)$.\n- The theoretical formulas $\\mathbb{E}[X_t] = x_0 + \\delta t$ and $\\mathrm{Var}(X_t) = 2\\delta t^2 + 4 x_0 t$.\n\nAlgorithmic requirements:\n- Use a fixed random seed $123456789$ for reproducibility.\n- Implement regime switching with a threshold $\\mu_{\\mathrm{thr}}$ on $\\mu = x_0/(2t)$: if $\\mu \\le \\mu_{\\mathrm{thr}}$, use the Poisson-gamma mixture; if $\\mu  \\mu_{\\mathrm{thr}}$, use an exact noncentral chi-square sampler and scale by $t$.\n- For each test case, generate $N$ independent samples of $X_t$, compute empirical mean and variance, and compare to the theoretical mean and variance. Report whether the relative error of the mean is at most $0.02$ and whether the relative error of the variance is at most $0.05$.\n\nTest suite:\n- Case A (general): $\\delta = 3.0$, $x_0 = 1.5$, $t = 0.7$, $N = 50000$.\n- Case B (boundary $x_0=0$): $\\delta = 5.0$, $x_0 = 0.0$, $t = 2.0$, $N = 50000$.\n- Case C (large noncentrality, small $t$): $\\delta = 3.0$, $x_0 = 10.0$, $t = 10^{-3}$, $N = 50000$.\n- Case D (large $t$): $\\delta = 2.0$, $x_0 = 0.5$, $t = 100.0$, $N = 50000$.\n- Case E (subcritical dimension): $\\delta = 0.5$, $x_0 = 0.0$, $t = 1.0$, $N = 50000$.\n\nNumerical stability regime:\n- Use $\\mu_{\\mathrm{thr}} = 200$ as the threshold for switching. This tests both the Poisson-gamma mixture in stable regimes and a direct exact noncentral chi-square sampler in regimes where $\\mu$ is very large.\n\nFinal output specification:\n- For each case in the test suite, output three values in order: a boolean indicating whether the mean relative error is at most $0.02$, a boolean indicating whether the variance relative error is at most $0.05$, and an integer method flag where $0$ denotes the Poisson-gamma mixture and $1$ denotes the exact noncentral chi-square sampler.\n- Aggregate all results into a single line as a comma-separated list enclosed in square brackets.\n- No physical units are involved in this task.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,\\dots,r_{15}]$ where the three outputs per case are concatenated for five cases).", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the theory of stochastic processes, specifically squared Bessel processes. All provided mathematical formulas and characterizations, including the stochastic differential equation (SDE), Laplace transform, connection to the noncentral chi-square distribution, and theoretical moments, are standard and correct results from the field. The problem is well-posed, self-contained, and presents a clear, objective, and non-trivial computational task. There are no contradictions, ambiguities, or factual errors.\n\nThe solution implements an exact sampler for the state of a squared Bessel process, $X_t$, at a fixed time $t  0$, starting from $X_0 = x_0$. The implementation adheres to the specified algorithmic requirements, including a regime-switching mechanism for numerical stability and a validation procedure against theoretical moments.\n\nThe core of the algorithm is based on the distributional identity $X_t \\overset{d}{=} t \\cdot Y_t$, where $Y_t$ follows a noncentral chi-square distribution, $\\chi'^2(\\delta, \\kappa)$, with $\\delta$ degrees of freedom and noncentrality parameter $\\kappa = x_0/t$.\n\nThe sampling procedure is divided into two regimes based on the parameter $\\mu = x_0 / (2t)$, which is half the noncentrality parameter of the corresponding Poisson distribution in the mixture representation. The threshold for switching is given as $\\mu_{\\mathrm{thr}} = 200$.\n\nFirst, for each test case defined by parameters $(\\delta, x_0, t)$ and sample size $N$, the value of $\\mu$ is calculated.\n\n**Regime 1: Low Noncentrality ($\\mu \\le \\mu_{\\mathrm{thr}} = 200$)**\n\nIf $\\mu$ is below or at the threshold, the Poisson-gamma mixture representation is used. This corresponds to `method_flag = 0`. This method constructs a noncentral gamma (and thus noncentral chi-square) variable from a mixture of central gamma distributions.\n1. A random integer $K$ is drawn from a Poisson distribution with mean $\\mu$: $K \\sim \\mathrm{Poisson}(\\mu)$. This is performed for each of the $N$ samples to generate a vector of counts $K_i$.\n2. For each $K_i$, a random variable $G_i$ is drawn from a Gamma distribution whose shape parameter depends on $K_i$. The shape is $\\alpha_i = \\delta/2 + K_i$, and the scale is fixed at $\\beta = 2$. So, $G_i \\sim \\mathrm{Gamma}(\\delta/2 + K_i, 2)$.\n3. The sample of the squared Bessel process is then obtained by scaling: $X_{t,i} = t \\cdot G_i$.\n\nVectorized implementation in `numpy` is used for efficiency. A vector of $N$ Poisson samples `k_samples` is generated. This vector is used to create a vector of shape parameters `gamma_shape = delta/2.0 + k_samples`. Then, a vector of $N$ Gamma samples `g_samples` is generated using this shape vector and a scale of $2$. Finally, the samples for $X_t$ are computed as `samples = t * g_samples`.\n\n**Regime 2: High Noncentrality ($\\mu  \\mu_{\\mathrm{thr}} = 200$)**\n\nIf $\\mu$ is large, the Poisson-gamma mixture method can become inefficient, as it may require generating Poisson variates with a very large mean, leading to large shape parameters for the gamma distribution. In this case, the algorithm switches to a direct sampler for the noncentral chi-square distribution. This corresponds to `method_flag = 1`.\n1. The degrees of freedom are $d = \\delta$ and the noncentrality parameter is $\\kappa = x_0/t$.\n2. A vector of $N$ samples, `y_samples`, is drawn directly from the $\\chi'^2(\\delta, \\kappa)$ distribution.\n3. The samples for $X_t$ are obtained by scaling: `samples = t * y_samples`.\n\nThis is implemented using `numpy.random.noncentral_chisquare`.\n\n**Validation Procedure**\n\nFor each test case, after generating $N = 50000$ independent samples of $X_t$, their empirical mean and variance are computed.\n- Empirical mean: $\\hat{\\mathbb{E}}[X_t] = \\frac{1}{N} \\sum_{i=1}^N X_{t,i}$.\n- Empirical variance: $\\widehat{\\mathrm{Var}}(X_t) = \\frac{1}{N-1} \\sum_{i=1}^N (X_{t,i} - \\hat{\\mathbb{E}}[X_t])^2$. We use the sample variance with `ddof=1` for an unbiased estimate of the population variance.\n\nThese empirical moments are compared to the theoretical moments:\n- Theoretical mean: $\\mathbb{E}[X_t] = x_0 + \\delta t$.\n- Theoretical variance: $\\mathrm{Var}(X_t) = 2\\delta t^2 + 4 x_0 t$.\n\nThe relative error is calculated for both mean and variance:\n- $\\text{err}_{\\text{mean}} = \\frac{|\\hat{\\mathbb{E}}[X_t] - \\mathbb{E}[X_t]|}{|\\mathbb{E}[X_t]|}$\n- $\\text{err}_{\\text{var}} = \\frac{|\\widehat{\\mathrm{Var}}(X_t) - \\mathrm{Var}(X_t)|}{|\\mathrm{Var}(X_t)|}$\n\nThe validation passes if $\\text{err}_{\\text{mean}} \\le 0.02$ and $\\text{err}_{\\text{var}} \\le 0.05$. The results for each test case—a boolean for the mean check, a boolean for the variance check, and the integer `method_flag`—are collected.\n\nA fixed random seed of $123456789$ is used to ensure reproducibility of the results. The final output aggregates the results from all test cases into a single list as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements an exact sampler for the squared Bessel process (BESQ) at a fixed time t,\n    validates the sampler against theoretical moments, and reports the results.\n    \"\"\"\n    # Define constants from the problem statement.\n    SEED = 123456789\n    MU_THR = 200.0\n    MEAN_TOL = 0.02\n    VAR_TOL = 0.05\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (delta, x0, t, N)\n        (3.0, 1.5, 0.7, 50000),      # Case A\n        (5.0, 0.0, 2.0, 50000),      # Case B\n        (3.0, 10.0, 1e-3, 50000),   # Case C\n        (2.0, 0.5, 100.0, 50000),    # Case D\n        (0.5, 0.0, 1.0, 50000)       # Case E\n    ]\n\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(SEED)\n\n    all_results = []\n\n    for delta, x0, t, N in test_cases:\n        # 1. Determine the sampling method based on the regime.\n        #    mu is the parameter for the Poisson distribution in the mixture.\n        mu = x0 / (2.0 * t) if t > 0 else float('inf')\n\n        if mu > MU_THR:\n            method_flag = 1\n            # 2a. Generate samples using direct noncentral chi-square (Method 1).\n            #     The scaled process Y_t = X_t/t ~ chi'^2(delta, kappa).\n            kappa = x0 / t\n            y_samples = rng.noncentral_chisquare(delta, kappa, size=N)\n            samples = t * y_samples\n        else:\n            method_flag = 0\n            # 2b. Generate samples using Poisson-gamma mixture (Method 0).\n            #     K ~ Poisson(mu), G | K ~ Gamma(delta/2 + K, 2).\n            #     X_t = t * G.\n            k_samples = rng.poisson(mu, size=N)\n            gamma_shape = delta / 2.0 + k_samples\n            g_samples = rng.gamma(gamma_shape, 2.0)\n            samples = t * g_samples\n\n        # 3. Validate the samples against theoretical moments.\n        emp_mean = np.mean(samples)\n        emp_var = np.var(samples, ddof=1) # Use sample variance (ddof=1).\n\n        theo_mean = x0 + delta * t\n        theo_var = 2 * delta * t**2 + 4 * x0 * t\n\n        # Calculate relative errors. Handle potential division by zero.\n        if theo_mean != 0:\n            rel_err_mean = abs(emp_mean - theo_mean) / abs(theo_mean)\n        else:\n            rel_err_mean = abs(emp_mean)\n\n        if theo_var != 0:\n            rel_err_var = abs(emp_var - theo_var) / abs(theo_var)\n        else:\n            rel_err_var = abs(emp_var)\n        \n        mean_ok = rel_err_mean = MEAN_TOL\n        var_ok = rel_err_var = VAR_TOL\n\n        all_results.extend([mean_ok, var_ok, method_flag])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3040473"}]}