{"hands_on_practices": [{"introduction": "We begin with a foundational exercise to solidify your understanding of what the strong Markov property means in practice. This problem asks you to use the property to determine the distribution of a Brownian motion increment starting from a random stopping time, directly testing the idea that the process \"restarts\" with no memory of the past [@problem_id:3079174]. This confirms that the increment's behavior depends only on the elapsed time, not on the random moment from which it is measured.", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard Brownian motion (also known as a Wiener process) on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$ satisfying the usual conditions. Recall the strong Markov property: for any stopping time $\\tau$ with respect to $\\{\\mathcal{F}_{t}\\}$, the process $\\{B_{\\tau + s} - B_{\\tau}\\}_{s \\geq 0}$ is independent of $\\mathcal{F}_{\\tau}$ and has the same distribution as $\\{B_{s}\\}_{s \\geq 0}$. Assume $\\tau$ is a bounded stopping time (that is, there exists a deterministic constant $M>0$ such that $\\tau \\leq M$ almost surely). Fix a deterministic $a>0$.\n\nUsing only the defining properties of standard Brownian motion (independent and stationary increments, Gaussian increments with mean $0$ and variance proportional to elapsed time) together with the strong Markov property, determine the probability density function of the increment $B_{\\tau + a} - B_{\\tau}$ as an explicit function of a real variable $x$ and the parameter $a$.\n\nYour final answer must be a single closed-form analytic expression for this density in terms of $x$ and $a$. No rounding is required.", "solution": "The problem requires the determination of the probability density function (PDF) of the random variable $X = B_{\\tau + a} - B_{\\tau}$, where $\\{B_t\\}_{t \\geq 0}$ is a standard Brownian motion, $\\tau$ is a bounded stopping time, and $a>0$ is a deterministic constant. We are instructed to use the defining properties of Brownian motion and the strong Markov property.\n\nLet the given filtered probability space be $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t \\geq 0}, \\mathbb{P})$, satisfying the usual conditions. The process $\\{B_t\\}_{t \\geq 0}$ is a standard Brownian motion adapted to this filtration. A stopping time $\\tau$ is a random variable $\\tau: \\Omega \\to [0, \\infty)$ such that for every $t \\geq 0$, the event $\\{\\omega \\in \\Omega : \\tau(\\omega) \\leq t\\}$ is in $\\mathcal{F}_t$. The problem states that $\\tau$ is a bounded stopping time, which means there exists a constant $M > 0$ such that $\\mathbb{P}(\\tau \\leq M) = 1$. This implies that $\\tau$ is an almost surely finite stopping time.\n\nThe problem explicitly provides the statement of the strong Markov property for Brownian motion: for any stopping time $\\tau$, the process defined by $W_s = B_{\\tau+s} - B_{\\tau}$ for $s \\geq 0$ is a standard Brownian motion, and this new process $\\{W_s\\}_{s \\geq 0}$ is independent of the pre-$\\tau$ sigma-algebra $\\mathcal{F}_{\\tau}$. The notation $\\mathcal{F}_{\\tau}$ represents the collection of events that are determined by the history of the process up to the random time $\\tau$, defined as $\\mathcal{F}_{\\tau} = \\{A \\in \\mathcal{F} : A \\cap \\{\\tau \\leq t\\} \\in \\mathcal{F}_t \\text{ for all } t \\geq 0 \\}$.\n\nOur objective is to find the PDF of the random variable $X = B_{\\tau + a} - B_{\\tau}$. Following the definition provided, this random variable is precisely the value of the process $\\{W_s\\}_{s \\geq 0}$ at the specific time $s=a$. That is, $X = W_a$.\n\nAccording to the strong Markov property, the stochastic process $\\{W_s\\}_{s \\geq 0}$ is a standard Brownian motion. This means that $\\{W_s\\}_{s \\geq 0}$ has the same distributional properties as the original Brownian motion $\\{B_s\\}_{s \\geq 0}$.\n\nOne of the defining properties of a standard Brownian motion $\\{B_t\\}_{t \\geq 0}$ is that for any fixed time $t > 0$, the random variable $B_t$ follows a normal distribution with mean $0$ and variance $t$. We denote this as $B_t \\sim \\mathcal{N}(0, t)$.\n\nSince the process $\\{W_s\\}_{s \\geq 0}$ is a standard Brownian motion, the random variable $W_a$ (for a fixed $a>0$) must also follow a normal distribution with mean $0$ and variance $a$. Therefore,\n$$\nW_a \\sim \\mathcal{N}(0, a)\n$$\nAs we have established that $X = B_{\\tau + a} - B_{\\tau} = W_a$, it follows directly that the random variable $X$ also has this distribution:\n$$\nX \\sim \\mathcal{N}(0, a)\n$$\nIt is crucial to note that this result is independent of the specific characteristics of the stopping time $\\tau$, as long as it is a valid (a.s. finite) stopping time. The boundedness of $\\tau$ as given in the problem statement guarantees this condition.\n\nThe probability density function for a general normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is given by the formula:\n$$\nf(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n$$\nFor our random variable $X \\sim \\mathcal{N}(0, a)$, the parameters are the mean $\\mu = 0$ and the variance $\\sigma^2 = a$. Substituting these values into the general formula, we obtain the PDF for $X = B_{\\tau + a} - B_{\\tau}$ as a function of the real variable $x$ and the parameter $a$:\n$$\nf_X(x) = \\frac{1}{\\sqrt{2\\pi a}} \\exp\\left(-\\frac{(x - 0)^2}{2a}\\right)\n$$\n$$\nf_X(x) = \\frac{1}{\\sqrt{2\\pi a}} \\exp\\left(-\\frac{x^2}{2a}\\right)\n$$\nThis is the required probability density function.", "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{2\\pi a}} \\exp\\left(-\\frac{x^2}{2a}\\right)}\n$$", "id": "3079174"}, {"introduction": "Building on the basic definition, we now explore a celebrated application: the reflection principle. This powerful technique, which relies critically on the strong Markov property at a hitting time, allows us to compute the distribution of the maximum value a Brownian motion achieves over a given interval [@problem_id:3079166]. Solving this problem will not only deepen your grasp of the strong Markov property but also introduce a clever symmetry argument that is a cornerstone of stochastic calculus.", "problem": "Let $\\{B_t\\}_{t \\ge 0}$ be a one-dimensional standard Brownian motion (BM) started at $B_0 = 0$, defined on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t \\ge 0},\\mathbb{P})$ satisfying the usual conditions, where $\\{\\mathcal{F}_t\\}_{t \\ge 0}$ is the augmented natural filtration. For a fixed level $a > 0$, define the first hitting time of level $a$ by\n$$\n\\tau_a := \\inf\\{t \\ge 0 : B_t = a\\}.\n$$\nUsing only fundamental properties of Brownian motion (stationary and independent increments, Gaussian increments with variance proportional to elapsed time, path continuity, and the strong Markov property), answer the following.\n\n1) Prove from first principles that $\\tau_a$ is a stopping time with respect to $\\{\\mathcal{F}_t\\}_{t \\ge 0}$. In particular, justify carefully why the event $\\{\\tau_a \\le t\\}$ is in $\\mathcal{F}_t$ for each $t \\ge 0$.\n\n2) Let $M_t := \\sup_{0 \\le s \\le t} B_s$. Using the strong Markov property of Brownian motion at the stopping time $\\tau_a$, compute the probability\n$$\n\\mathbb{P}_0\\!\\left(M_t \\ge a\\right),\n$$\nfor fixed $a > 0$ and $t > 0$, in closed form in terms of the standard normal cumulative distribution function $\\Phi(x) := \\int_{-\\infty}^{x} \\frac{1}{\\sqrt{2\\pi}} \\exp\\!\\left(-\\frac{u^2}{2}\\right) \\, du$. Express your final answer as a single analytic expression in $a$ and $t$ using $\\Phi$.", "solution": "This is a two-part problem concerning the fundamental properties of a standard one-dimensional Brownian motion $\\{B_t\\}_{t \\ge 0}$ with $B_0=0$. We first prove that the first hitting time of a level $a > 0$ is a stopping time, and then we compute the probability that the running maximum of the process exceeds this level by a time $t$.\n\nFirst, we address the proof that $\\tau_a := \\inf\\{t \\ge 0 : B_t = a\\}$ is a stopping time with respect to the augmented natural filtration $\\{\\mathcal{F}_t\\}_{t \\ge 0}$. By definition, a random time $\\tau$ is a stopping time if the event $\\{\\tau \\le t\\}$ is in the sigma-algebra $\\mathcal{F}_t$ for every $t \\ge 0$.\n\nLet $t \\ge 0$ be a fixed time. We must show that the set $\\{\\omega \\in \\Omega : \\tau_a(\\omega) \\le t\\}$ is an element of $\\mathcal{F}_t$. We can rewrite this event by considering the running maximum of the Brownian motion, $M_t := \\sup_{0 \\le s \\le t} B_s$. The event $\\{\\tau_a \\le t\\}$ is equivalent to the event $\\{M_t \\ge a\\}$. To see this equivalence, consider two implications:\n1. If $\\tau_a(\\omega) \\le t$, then there exists some time $s_0 = \\tau_a(\\omega) \\in [0, t]$ such that $B_{s_0}(\\omega) = a$. Consequently, the supremum of the process over $[0, t]$, $M_t(\\omega) = \\sup_{0 \\le s \\le t} B_s(\\omega)$, must be at least $a$. Thus, $\\{\\tau_a \\le t\\} \\subseteq \\{M_t \\ge a\\}$.\n2. If $M_t(\\omega) \\ge a$, then $\\sup_{0 \\le s \\le t} B_s(\\omega) \\ge a$. Since $B_0 = 0$ and $a > 0$, and the sample paths $s \\mapsto B_s(\\omega)$ are almost surely continuous, the Intermediate Value Theorem implies that for any such path, there must be at least one time $s_1 \\in [0, t]$ where $B_{s_1}(\\omega) = a$. The infimum of all such times, $\\tau_a(\\omega)$, must therefore be less than or equal to $t$. Thus, $\\{M_t \\ge a\\} \\subseteq \\{\\tau_a \\le t\\}$.\nCombining these inclusions, we have the equality of events: $\\{\\tau_a \\le t\\} = \\{M_t \\ge a\\}$.\n\nThe problem now reduces to showing that the event $\\{M_t \\ge a\\}$ is in $\\mathcal{F}_t$. This requires demonstrating that the random variable $M_t$ is $\\mathcal{F}_t$-measurable. The filtration $\\mathcal{F}_t$ is the augmented sigma-algebra generated by the process up to time $t$, i.e., $\\mathcal{F}_t = \\sigma(B_s : 0 \\le s \\le t)$ completed with all $\\mathbb{P}$-null sets.\nDue to the almost sure continuity of Brownian paths, the supremum over the continuous interval $[0, t]$ can be found as the limit of suprema over an increasingly dense discrete set of points. For each integer $n \\ge 1$, let us consider a discrete set of time points $D_n = \\{k t 2^{-n} : k=0, 1, \\dots, 2^n\\}$. Let $M_t^{(n)} = \\max_{s \\in D_n, s \\le t} B_s$. For each $s \\in D_n$ with $s \\le t$, the random variable $B_s$ is by definition $\\mathcal{F}_t$-measurable. Since the maximum of a finite collection of $\\mathcal{F}_t$-measurable random variables is also $\\mathcal{F}_t$-measurable, $M_t^{(n)}$ is $\\mathcal{F}_t$-measurable for each $n$.\nBecause the paths of Brownian motion are continuous, as $n \\to \\infty$, the union of the sets $D_n$ becomes dense in $[0, t]$, and therefore the sequence of random variables $M_t^{(n)}$ converges almost surely to $M_t = \\sup_{0 \\le s \\le t} B_s$. The limit of a sequence of $\\mathcal{F}_t$-measurable functions is $\\mathcal{F}_t$-measurable (here the completeness of the filtration, part of the \"usual conditions,\" ensures any almost sure limit of measurable functions is measurable). Thus, $M_t$ is an $\\mathcal{F}_t$-measurable random variable.\nSince $M_t$ is $\\mathcal{F}_t$-measurable, the level set $\\{M_t \\ge a\\}$ is an event in $\\mathcal{F}_t$. This completes the proof that $\\{\\tau_a \\le t\\} \\in \\mathcal{F}_t$ for all $t \\ge 0$, establishing that $\\tau_a$ is a stopping time.\n\nNext, we compute the probability $\\mathbb{P}_0(M_t \\ge a)$ for $a > 0$ and $t > 0$, using the strong Markov property at the stopping time $\\tau_a$. As established, this is equivalent to computing $\\mathbb{P}(\\tau_a \\le t)$. We decompose this probability based on the value of the process at time $t$:\n$$ \\mathbb{P}(\\tau_a \\le t) = \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t \\ge a) + \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t < a) $$\nSince the distribution of $B_t$ is continuous, $\\mathbb{P}(B_t = a) = 0$, so we can use strict inequalities without loss of generality. As argued before, if $B_t \\ge a$, then by path continuity from $B_0=0$, the level $a$ must have been crossed at or before time $t$, which implies $\\tau_a \\le t$. Therefore, the event $\\{\\tau_a \\le t \\text{ and } B_t \\ge a\\}$ is identical to the event $\\{B_t \\ge a\\}$. Our decomposition becomes:\n$$ \\mathbb{P}(\\tau_a \\le t) = \\mathbb{P}(B_t \\ge a) + \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t < a) $$\nThis relation is often called the reflection principle. To evaluate the second term on the right-hand side, we invoke the strong Markov property at the stopping time $\\tau_a$. This property states that, conditional on the information available up to time $\\tau_a$ (i.e., conditional on $\\mathcal{F}_{\\tau_a}$), the process $W_s := B_{\\tau_a+s} - B_{\\tau_a}$ is a standard Brownian motion independent of $\\mathcal{F}_{\\tau_a}$.\nOn the event $\\{\\tau_a \\le t\\}$, we have $B_t = B_{\\tau_a} + (B_t - B_{\\tau_a})$. Since $B_{\\tau_a} = a$ on this event, the condition $B_t < a$ is equivalent to $B_t - B_{\\tau_a} < 0$. Symmetrically, the condition $B_t > a$ is equivalent to $B_t - B_{\\tau_a} > 0$.\nBy the law of total expectation and the strong Markov property:\n$$ \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t < a) = \\mathbb{E}\\left[ \\mathbb{I}_{\\{\\tau_a \\le t\\}} \\mathbb{I}_{\\{B_t < a\\}} \\right] = \\mathbb{E}\\left[ \\mathbb{E}\\left[ \\mathbb{I}_{\\{\\tau_a \\le t\\}} \\mathbb{I}_{\\{B_t < a\\}} \\middle| \\mathcal{F}_{\\tau_a} \\right] \\right] $$\nSince $\\mathbb{I}_{\\{\\tau_a \\le t\\}}$ is $\\mathcal{F}_{\\tau_a}$-measurable, we can pull it out of the inner expectation:\n$$ = \\mathbb{E}\\left[ \\mathbb{I}_{\\{\\tau_a \\le t\\}} \\mathbb{P}(B_t < a \\mid \\mathcal{F}_{\\tau_a}) \\right] = \\mathbb{E}\\left[ \\mathbb{I}_{\\{\\tau_a \\le t\\}} \\mathbb{P}(B_t - B_{\\tau_a} < 0 \\mid \\mathcal{F}_{\\tau_a}) \\right] $$\nThe increment $B_t - B_{\\tau_a}$ is a value of the new Brownian motion $W$ at time $t-\\tau_a$, which is a positive, $\\mathcal{F}_{\\tau_a}$-measurable random time. Due to the independence and symmetry of the new Brownian motion $W$, for any $s' = t-\\tau_a > 0$, $\\mathbb{P}(W_{s'} < 0 \\mid \\mathcal{F}_{\\tau_a}) = 1/2$.\nTherefore,\n$$ \\mathbb{P}(\\tau_a \\le t \\text{ and } B_t < a) = \\mathbb{E}\\left[ \\mathbb{I}_{\\{\\tau_a \\le t\\}} \\cdot \\frac{1}{2} \\right] = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t) $$\nBy the same argument, $\\mathbb{P}(\\tau_a \\le t \\text{ and } B_t > a) = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t)$. As we noted earlier, this event is identical to $\\{B_t > a\\}$. So, we have the key relationship:\n$$ \\mathbb{P}(B_t > a) = \\frac{1}{2} \\mathbb{P}(\\tau_a \\le t) $$\nThis implies that $\\mathbb{P}(\\tau_a \\le t) = 2\\mathbb{P}(B_t > a)$.\nThe random variable $B_t$ follows a normal distribution with mean $0$ and variance $t$, i.e., $B_t \\sim \\mathcal{N}(0, t)$. Let $Z = B_t/\\sqrt{t}$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$. We can compute the probability:\n$$ \\mathbb{P}(B_t > a) = \\mathbb{P}\\left(\\frac{B_t}{\\sqrt{t}} > \\frac{a}{\\sqrt{t}}\\right) = \\mathbb{P}\\left(Z > \\frac{a}{\\sqrt{t}}\\right) $$\nIn terms of the standard normal cumulative distribution function $\\Phi(x) = \\mathbb{P}(Z \\le x)$, this probability is:\n$$ \\mathbb{P}\\left(Z > \\frac{a}{\\sqrt{t}}\\right) = 1 - \\mathbb{P}\\left(Z \\le \\frac{a}{\\sqrt{t}}\\right) = 1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right) $$\nFinally, we substitute this back into our expression for the desired probability:\n$$ \\mathbb{P}_0(M_t \\ge a) = \\mathbb{P}(\\tau_a \\le t) = 2\\mathbb{P}(B_t > a) = 2\\left(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\right) $$\nThis is the closed-form solution for the probability that the maximum of a standard Brownian motion reaches level $a$ by time $t$.", "answer": "$$\n\\boxed{2\\left(1 - \\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)\\right)}\n$$", "id": "3079166"}, {"introduction": "Our final practice problem generalizes the concept from simple Brownian motion to a more complex Itô process, the Ornstein-Uhlenbeck process. Here, you will use the strong Markov property to derive a differential equation for the expected time it takes the process to hit a certain level, a quantity known as the mean first passage time [@problem_id:3079176]. This exercise illuminates the profound connection between stochastic processes and partial differential equations, showing how the strong Markov property is the key to formulating and solving such boundary value problems via the infinitesimal generator.", "problem": "Let $\\{X_{t}\\}_{t \\geq 0}$ be the unique strong solution to the Ornstein–Uhlenbeck stochastic differential equation (SDE)\n$$\ndX_{t} \\;=\\; \\kappa \\big(\\theta - X_{t}\\big)\\, dt \\;+\\; \\sigma \\, dW_{t}, \\qquad X_{0}=x,\n$$\nwhere $\\kappa>0$, $\\theta \\in \\mathbb{R}$, $\\sigma>0$, and $\\{W_{t}\\}_{t \\geq 0}$ is a standard Brownian motion. Let $a \\in \\mathbb{R}$ with $x<a$, and define the first hitting time\n$$\n\\tau_{a} \\;=\\; \\inf\\{t \\geq 0 : X_{t}=a\\}.\n$$\nUsing only fundamental facts about Markov processes and generators for diffusion processes, derive from first principles a boundary value problem for the function $u(x)=\\mathbb{E}_{x}[\\tau_{a}]$ that relies on the strong Markov property and the infinitesimal generator $\\mathcal{L}$ of $\\{X_{t}\\}_{t \\geq 0}$. Then solve this boundary value problem explicitly to obtain a closed-form analytic expression for $u(x)$ in terms of $\\kappa,\\theta,\\sigma,a$, and $x$. Your final answer must be a single closed-form expression. Do not approximate or round any constant, and do not include units.", "solution": "The problem asks for a boundary value problem (BVP) for the expected first hitting time $u(x) = \\mathbb{E}_{x}[\\tau_{a}]$ of the level $a$ by an Ornstein-Uhlenbeck (OU) process, and for the explicit solution of this BVP. The OU process $\\{X_{t}\\}_{t \\geq 0}$ starts at $X_{0}=x$ and follows the stochastic differential equation (SDE):\n$$\ndX_{t} \\;=\\; \\kappa \\big(\\theta - X_{t}\\big)\\, dt \\;+\\; \\sigma \\, dW_{t}\n$$\nwhere $x < a$, $\\kappa>0$, $\\theta \\in \\mathbb{R}$, $\\sigma>0$.\n\nFirst, we derive the boundary value problem from first principles using the infinitesimal generator of the process and the strong Markov property. An Itô diffusion of the form $dX_t = b(X_t)dt + \\sigma(X_t)dW_t$ has an infinitesimal generator $\\mathcal{L}$ that acts on a twice continuously differentiable function $f(y)$ as:\n$$\n\\mathcal{L}f(y) = b(y)f'(y) + \\frac{1}{2}\\sigma(y)^2 f''(y)\n$$\nFor the given OU process, the drift coefficient is $b(y) = \\kappa(\\theta - y)$ and the diffusion coefficient is $\\sigma(y) = \\sigma$. The generator is therefore:\n$$\n\\mathcal{L}f(y) = \\kappa(\\theta - y)f'(y) + \\frac{1}{2}\\sigma^2 f''(y)\n$$\nLet $u(x) = \\mathbb{E}_{x}[\\tau_{a}]$. A fundamental result from the theory of stochastic processes, often known as Dynkin's formula or derived using a martingale approach based on the strong Markov property, states that the expected exit time from a domain satisfies the differential equation $\\mathcal{L}u(x) = -1$ within that domain.\n\nTo show this from first principles, consider the process $Y_t = u(X_t) + t$. Applying Itô's lemma to $f(t,x) = u(x)+t$ (here, time is an explicit variable in our new function, not in $u$ itself), we get:\n$$\ndY_t = \\left(\\frac{\\partial f}{\\partial t} + \\mathcal{L}f\\right) dt + \\sigma(X_t)\\frac{\\partial f}{\\partial x} dW_t\n$$\nWith $f(t,X_t) = u(X_t)+t$, we have $\\frac{\\partial f}{\\partial t}=1$, $\\frac{\\partial f}{\\partial x}=u'(X_t)$, and $\\mathcal{L}f = \\mathcal{L}u(X_t)$. The stochastic differential for $Y_t$ is:\n$$\ndY_t = (1 + \\mathcal{L}u(X_t)) dt + \\sigma u'(X_t) dW_t\n$$\nIf we postulate that $u(x)$ satisfies $\\mathcal{L}u(x) = -1$, then the drift term in $dY_t$ vanishes, making $Y_t$ a local martingale. For the OU process, appropriate conditions hold such that $Y_t$ is a martingale. By the Optional Stopping Theorem applied to the stopping time $\\tau_a$, we have $\\mathbb{E}_x[Y_{\\tau_a}] = Y_0$.\nThe initial value is $Y_0 = u(X_0) + 0 = u(x)$.\nThe value at the stopping time is $Y_{\\tau_a} = u(X_{\\tau_a}) + \\tau_a = u(a) + \\tau_a$.\nEquating the expectations gives $u(x) = \\mathbb{E}_x[u(a) + \\tau_a] = u(a) + \\mathbb{E}_x[\\tau_a]$.\nTo find $u(x) = \\mathbb{E}_x[\\tau_a]$, we must impose the boundary condition $u(a)=0$. This is logical, as the time to hit $a$ when starting at $a$ is zero.\n\nThus, the function $u(x)$ must solve the following BVP for $x \\in (-\\infty, a)$:\n$$\n\\frac{1}{2}\\sigma^2 u''(x) + \\kappa(\\theta - x) u'(x) = -1, \\qquad u(a)=0\n$$\nThis is a second-order linear ordinary differential equation. Let $v(x) = u'(x)$. The equation becomes a first-order ODE for $v(x)$:\n$$\nv'(x) + \\frac{2\\kappa}{\\sigma^2}(\\theta - x)v(x) = -\\frac{2}{\\sigma^2}\n$$\nWe solve this using an integrating factor $I(x)$:\n$$\nI(x) = \\exp\\left(\\int \\frac{2\\kappa}{\\sigma^2}(\\theta - x) dx\\right) = \\exp\\left(\\frac{2\\kappa}{\\sigma^2}\\left(\\theta x - \\frac{x^2}{2}\\right)\\right) = \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(x-\\theta)^2\\right)\n$$\nMultiplying the ODE by $I(x)$ gives:\n$$\n\\frac{d}{dx}\\left(v(x)I(x)\\right) = -\\frac{2}{\\sigma^2}I(x)\n$$\nIntegrating both sides yields:\n$$\nv(x)I(x) = C - \\frac{2}{\\sigma^2} \\int^x I(y) dy \\implies v(x) = \\frac{1}{I(x)}\\left(C - \\frac{2}{\\sigma^2} \\int^x I(y) dy\\right)\n$$\n$$\nu'(x) = \\exp\\left(\\frac{\\kappa}{\\sigma^2}(x-\\theta)^2\\right) \\left[C - \\frac{2}{\\sigma^2} \\int^x \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(y-\\theta)^2\\right) dy \\right]\n$$\nA second boundary condition is needed to determine the constant $C$. This condition comes from the behavior of the solution as $x \\to -\\infty$. The OU process is mean-reverting, so for $x \\ll \\theta$, the drift $\\kappa(\\theta-x)$ is large and positive, pushing the process towards $\\theta$. We expect the hitting time $u(x)$ to be finite and to not grow excessively fast as $x \\to -\\infty$. In particular, we require that $u'(x)$ does not grow exponentially as $x \\to -\\infty$.\nAs $x \\to -\\infty$, the term $\\exp\\left(\\frac{\\kappa}{\\sigma^2}(x-\\theta)^2\\right)$ grows unboundedly. To prevent $u'(x)$ from also growing unboundedly, the term in the square brackets must go to zero. This can be achieved by choosing the lower limit of integration to be $-\\infty$ and setting the constant $C$ to $0$. Let's formalize this:\n$$\nu'(x) = \\exp\\left(\\frac{\\kappa}{\\sigma^2}(x-\\theta)^2\\right) C - \\frac{2}{\\sigma^2} \\frac{\\int_{-\\infty}^x \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(y-\\theta)^2\\right) dy}{\\exp\\left(-\\frac{\\kappa}{\\sigma^2}(x-\\theta)^2\\right)}\n$$\nThe second term tends to $0$ as $x \\to -\\infty$ (by L'Hôpital's rule). For $u'(x)$ to not diverge exponentially, we must have $C=0$.\nSo, the physically relevant solution for $u'(x)$ is:\n$$\nu'(x) = -\\frac{2}{\\sigma^2} \\exp\\left(\\frac{\\kappa}{\\sigma^2}(x-\\theta)^2\\right) \\int_{-\\infty}^x \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(y-\\theta)^2\\right) dy\n$$\nNow, we find $u(x)$ by integrating $u'(x)$ and applying the boundary condition $u(a)=0$:\n$$\nu(x) - u(a) = \\int_a^x u'(y) dy\n$$\nSince $u(a)=0$, we have:\n$$\nu(x) = \\int_a^x u'(y) dy = -\\int_x^a u'(y) dy\n$$\nSubstituting the expression for $u'(y)$:\n$$\nu(x) = \\int_x^a \\left[ \\frac{2}{\\sigma^2} \\exp\\left(\\frac{\\kappa}{\\sigma^2}(y-\\theta)^2\\right) \\left( \\int_{-\\infty}^y \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(z-\\theta)^2\\right) dz \\right) \\right] dy\n$$\nThis is the explicit, closed-form analytic solution for $u(x)$. It is expressed as an iterated integral of elementary functions and depends only on the given parameters.\nFinal Answer:\n$$\nu(x) = \\frac{2}{\\sigma^2} \\int_x^a \\exp\\left(\\frac{\\kappa}{\\sigma^2}(y-\\theta)^2\\right) \\left( \\int_{-\\infty}^y \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(z-\\theta)^2\\right) dz \\right) dy\n$$", "answer": "$$\n\\boxed{\\frac{2}{\\sigma^2} \\int_x^a \\exp\\left(\\frac{\\kappa}{\\sigma^2}(y-\\theta)^2\\right) \\left( \\int_{-\\infty}^y \\exp\\left(-\\frac{\\kappa}{\\sigma^2}(z-\\theta)^2\\right) dz \\right) dy}\n$$", "id": "3079176"}]}