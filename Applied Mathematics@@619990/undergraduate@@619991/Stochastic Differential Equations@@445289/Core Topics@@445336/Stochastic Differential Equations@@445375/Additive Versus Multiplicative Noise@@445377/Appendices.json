{"hands_on_practices": [{"introduction": "Multiplicative noise, where the magnitude of random fluctuations depends on the system's current state, often makes stochastic differential equations challenging to solve directly. A powerful strategy is to find a transformation that simplifies the noise structure. This first exercise guides you through a cornerstone technique: using the logarithmic transform to convert the geometric Brownian motion SDE into a much simpler process with constant, additive noise.", "problem": "Consider the geometric Brownian motion defined by the Itô stochastic differential equation (SDE)\n$$\ndX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t,\n$$\nwhere $W_t$ is a standard Brownian motion, $\\mu$ and $\\sigma$ are real constants with $\\sigma \\ge 0$, and $X_0 > 0$. Define the logarithmic transform $Y_t = \\ln X_t$. Starting only from the definition of Itô SDEs and Itô's lemma, derive the SDE satisfied by $Y_t$ and identify its drift and diffusion coefficients. Express your final answer as the ordered pair consisting of the drift and diffusion coefficients of $Y_t$ in terms of $\\mu$ and $\\sigma$. Your final answer should be a single analytic expression. Do not include any units.", "solution": "The user has asked for a critical validation and, if valid, a solution to the following problem:\n\"Consider the geometric Brownian motion defined by the Itô stochastic differential equation (SDE)\n$$\ndX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t,\n$$\nwhere $W_t$ is a standard Brownian motion, $\\mu$ and $\\sigma$ are real constants with $\\sigma \\ge 0$, and $X_00$. Define the logarithmic transform $Y_t = \\ln X_t$. Starting only from the definition of Itô SDEs and Itô's lemma, derive the SDE satisfied by $Y_t$ and identify its drift and diffusion coefficients. Express your final answer as the ordered pair consisting of the drift and diffusion coefficients of $Y_t$ in terms of $\\mu$ and $\\sigma$.\"\n\n### Step 1: Extract Givens\n- The stochastic process $X_t$ follows the SDE: $dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$.\n- $W_t$ is a standard Brownian motion.\n- $\\mu$ and $\\sigma$ are real constants.\n- $\\sigma \\ge 0$.\n- The initial condition is $X_0  0$.\n- A new process $Y_t$ is defined by the transformation: $Y_t = \\ln X_t$.\n- The task is to find the SDE for $Y_t$ and identify its drift and diffusion coefficients.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem statement involves geometric Brownian motion and Itô's lemma, which are canonical and rigorously defined concepts within the field of stochastic calculus. The problem is scientifically sound.\n2.  **Well-Posed:** The problem is well-posed. The given SDE for $X_t$ is a standard model. The transformation $Y_t = \\ln X_t$ is well-defined because the solution to the geometric Brownian motion SDE with a positive initial condition ($X_0  0$) remains strictly positive for all $t \\ge 0$. Itô's lemma provides a direct and unique procedure to derive the SDE for the transformed process $Y_t$.\n3.  **Objective:** The problem is stated using precise mathematical language, free of any subjectivity or ambiguity.\n4.  **Completeness and Consistency:** The problem provides all necessary information. The SDE, the transformation, and the properties of the constants are clearly stated. There are no contradictions.\n5.  **Conclusion:** The problem is valid as it is mathematically sound, well-posed, objective, and self-contained.\n\n### Step 3: Derivation of the Solution\nThe problem is to find the SDE for the process $Y_t = \\ln X_t$, given the SDE for $X_t$. This requires an application of Itô's lemma.\n\nThe given SDE for $X_t$ is of the general form $dX_t = a(t, X_t) dt + b(t, X_t) dW_t$. By comparing this with the provided equation,\n$$dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t,$$\nwe identify the drift coefficient $a(t, X_t)$ and the diffusion coefficient $b(t, X_t)$ for the process $X_t$:\n$$a(t, X_t) = \\mu X_t$$\n$$b(t, X_t) = \\sigma X_t$$\n\nThe transformation is given by $Y_t = f(X_t)$, where the function $f(x)$ is the natural logarithm, $f(x) = \\ln(x)$. Note that this function does not have explicit time dependence, so $\\frac{\\partial f}{\\partial t} = 0$.\n\nItô's lemma for a process $Y_t = f(t, X_t)$ states that its differential $dY_t$ is given by:\n$$dY_t = \\left(\\frac{\\partial f}{\\partial t} + a(t, X_t)\\frac{\\partial f}{\\partial x} + \\frac{1}{2}b(t, X_t)^2\\frac{\\partial^2 f}{\\partial x^2}\\right) dt + b(t, X_t)\\frac{\\partial f}{\\partial x} dW_t$$\n\nTo apply the lemma, we need the first and second partial derivatives of $f(x) = \\ln(x)$ with respect to $x$:\n$$\\frac{\\partial f}{\\partial x} = \\frac{d}{dx}(\\ln x) = \\frac{1}{x}$$\n$$\\frac{\\partial^2 f}{\\partial x^2} = \\frac{d^2}{dx^2}(\\ln x) = \\frac{d}{dx}\\left(\\frac{1}{x}\\right) = -\\frac{1}{x^2}$$\n\nNow, we substitute these derivatives and the coefficients $a(t, X_t)$ and $b(t, X_t)$ into Itô's formula.\n\nThe drift term for $dY_t$ is the coefficient of $dt$:\n$$\\text{Drift}(Y_t) = \\frac{\\partial f}{\\partial t} + a(t, X_t)\\frac{\\partial f}{\\partial x}\\bigg|_{x=X_t} + \\frac{1}{2}b(t, X_t)^2\\frac{\\partial^2 f}{\\partial x^2}\\bigg|_{x=X_t}$$\nSubstituting the respective expressions:\n$$\\text{Drift}(Y_t) = 0 + (\\mu X_t)\\left(\\frac{1}{X_t}\\right) + \\frac{1}{2}(\\sigma X_t)^2\\left(-\\frac{1}{X_t^2}\\right)$$\nSimplifying the terms:\n$$\\text{Drift}(Y_t) = \\mu - \\frac{1}{2}\\sigma^2 X_t^2 \\frac{1}{X_t^2}$$\n$$\\text{Drift}(Y_t) = \\mu - \\frac{1}{2}\\sigma^2$$\nThe drift coefficient for $Y_t$ is a constant, independent of $Y_t$ or $t$.\n\nThe diffusion term for $dY_t$ is the coefficient of $dW_t$:\n$$\\text{Diffusion}(Y_t) = b(t, X_t)\\frac{\\partial f}{\\partial x}\\bigg|_{x=X_t}$$\nSubstituting the respective expressions:\n$$\\text{Diffusion}(Y_t) = (\\sigma X_t)\\left(\\frac{1}{X_t}\\right)$$\nSimplifying the expression:\n$$\\text{Diffusion}(Y_t) = \\sigma$$\nThe diffusion coefficient for $Y_t$ is also a constant.\n\nCombining these results, the SDE for $Y_t$ is:\n$$dY_t = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) dt + \\sigma dW_t$$\nThis is the SDE for an arithmetic Brownian motion. The drift coefficient is $\\mu - \\frac{1}{2}\\sigma^2$ and the diffusion coefficient is $\\sigma$.\n\nThe problem asks for the ordered pair consisting of the drift and diffusion coefficients of $Y_t$.\nDrift coefficient: $\\mu - \\frac{1}{2}\\sigma^2$\nDiffusion coefficient: $\\sigma$\nThe ordered pair is $\\left(\\mu - \\frac{1}{2}\\sigma^2, \\sigma\\right)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\mu - \\frac{1}{2}\\sigma^2  \\sigma\n\\end{pmatrix}\n}\n$$", "id": "3038828"}, {"introduction": "Once we can solve an SDE, the next step is to understand the behavior of its solution. This practice builds on the transformation technique to find the explicit solution for geometric Brownian motion and compute its key statistical moments, the mean $\\mathbb{E}[X_t]$ and variance $\\mathrm{Var}(X_t)$. By analyzing how these moments evolve, you will uncover the non-stationary nature typical of models with multiplicative noise and contrast it with the stability of mean-reverting processes.", "problem": "Consider the stochastic differential equation (SDE) for geometric Brownian motion with multiplicative noise given by $$dX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t},$$ where $W_{t}$ is a standard Wiener process (Brownian motion), $\\mu\\in\\mathbb{R}$ and $\\sigma0$ are constants, and $X_{0}0$ is a deterministic initial condition. Starting from foundational facts of Itô calculus and the definition of Brownian motion, derive an explicit closed-form expression for $X_{t}$, then compute the expectation $\\mathbb{E}[X_{t}]$ and the variance $\\mathrm{Var}(X_{t})$ in terms of $X_{0}$, $\\mu$, $\\sigma$, and $t$. Finally, assess whether the distribution of $X_{t}$ is stationary in time and contrast this with the Ornstein–Uhlenbeck (OU) process with additive noise defined by $$dY_{t}=-\\theta\\,(Y_{t}-m)\\,dt+\\sigma\\,dW_{t},$$ where $\\theta0$, $m\\in\\mathbb{R}$, and $Y_{0}\\in\\mathbb{R}$ is deterministic. Express your final answer as a single row matrix containing, in order, the explicit solution for $X_{t}$, $\\mathbb{E}[X_{t}]$, and $\\mathrm{Var}(X_{t})$. No numerical rounding is required and no physical units are involved.", "solution": "The problem is well-posed and scientifically grounded within the framework of stochastic calculus. It requests the derivation of the solution, expectation, and variance for a geometric Brownian motion (GBM) process, followed by an analysis of its stationarity in contrast with an Ornstein–Uhlenbeck (OU) process.\n\nFirst, we validate the problem statement.\n**Step 1: Extract Givens**\n-   The stochastic differential equation (SDE) for geometric Brownian motion is given as $dX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t}$.\n-   $W_{t}$ is a standard Wiener process.\n-   $\\mu \\in \\mathbb{R}$ is a constant.\n-   $\\sigma  0$ is a constant.\n-   The initial condition $X_{0}  0$ is deterministic.\n-   The SDE for the Ornstein–Uhlenbeck process is given as $dY_{t}=-\\theta\\,(Y_{t}-m)\\,dt+\\sigma\\,dW_{t}$.\n-   $\\theta  0$, $m \\in \\mathbb{R}$ are constants.\n-   The initial condition $Y_{0} \\in \\mathbb{R}$ is deterministic.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem uses standard, foundational models in stochastic processes: the geometric Brownian motion and the Ornstein–Uhlenbeck process. All concepts, including the Wiener process and Itô calculus, are mathematically rigorous and well-established.\n-   **Well-Posed:** The problem provides all necessary information (SDEs, parameter constraints, initial conditions) to derive a unique solution for $X_{t}$ and its statistical moments. The question is clearly structured and asks for specific, derivable quantities.\n-   **Objective:** The problem is stated using precise mathematical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We will proceed with the detailed solution.\n\n**Derivation of the Explicit Solution for $X_{t}$**\n\nThe given SDE for geometric Brownian motion is:\n$$dX_{t} = \\mu X_{t} dt + \\sigma X_{t} dW_{t}$$\nThis SDE has a state-dependent diffusion coefficient, $\\sigma X_{t}$, which is characteristic of multiplicative noise. To find a closed-form solution, we use a transformation via Itô's lemma. Let us consider the function $f(x) = \\ln(x)$. The derivatives of $f(x)$ are $f'(x) = 1/x$ and $f''(x) = -1/x^2$. Let $Z_{t} = f(X_{t}) = \\ln(X_{t})$.\n\nAccording to Itô's lemma for a function $f(X_t)$, the differential $df(X_t)$ is given by:\n$$df(X_t) = f'(X_t) dX_t + \\frac{1}{2} f''(X_t) (dX_t)^2$$\nWe first compute the quadratic variation term $(dX_t)^2$. Using the rules of Itô calculus where $(dt)^2=0$, $dt dW_t=0$, and $(dW_t)^2=dt$:\n$$(dX_t)^2 = (\\mu X_{t} dt + \\sigma X_{t} dW_{t})^2 = \\mu^2 X_t^2 (dt)^2 + 2\\mu\\sigma X_t^2 dt dW_t + \\sigma^2 X_t^2 (dW_t)^2 = \\sigma^2 X_t^2 dt$$\nSubstituting $f'(X_t)$, $f''(X_t)$, $dX_t$, and $(dX_t)^2$ into the Itô's lemma formula for $dZ_t = d(\\ln(X_t))$:\n$$d(\\ln(X_t)) = \\frac{1}{X_t} (\\mu X_{t} dt + \\sigma X_{t} dW_{t}) + \\frac{1}{2} \\left(-\\frac{1}{X_t^2}\\right) (\\sigma^2 X_t^2 dt)$$\n$$d(\\ln(X_t)) = (\\mu dt + \\sigma dW_t) - \\frac{1}{2}\\sigma^2 dt$$\n$$d(\\ln(X_t)) = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) dt + \\sigma dW_t$$\nThis new SDE for $\\ln(X_t)$ has constant coefficients. We can integrate it from $t=0$ to $t$:\n$$\\int_{0}^{t} d(\\ln(X_s)) = \\int_{0}^{t} \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) ds + \\int_{0}^{t} \\sigma dW_s$$\n$$\\ln(X_t) - \\ln(X_0) = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma (W_t - W_0)$$\nSince $W_t$ is a standard Wiener process, $W_0=0$. Thus:\n$$\\ln(X_t) = \\ln(X_0) + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t$$\nExponentiating both sides gives the explicit closed-form solution for $X_t$:\n$$X_t = \\exp\\left(\\ln(X_0) + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t\\right)$$\n$$X_t = X_0 \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t\\right)$$\n\n**Calculation of Expectation $\\mathbb{E}[X_{t}]$**\n\nThe expectation of $X_t$ is:\n$$\\mathbb{E}[X_t] = \\mathbb{E}\\left[X_0 \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t\\right)\\right]$$\nSince $X_0$ and the terms in $t$ are deterministic, they can be factored out of the expectation:\n$$\\mathbb{E}[X_t] = X_0 \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t\\right) \\mathbb{E}[\\exp(\\sigma W_t)]$$\nThe random variable $W_t$ follows a normal distribution with mean $0$ and variance $t$, i.e., $W_t \\sim N(0, t)$. We use the property of the moment-generating function of a normal random variable $Y \\sim N(\\nu, \\tau^2)$, which is $M_Y(k) = \\mathbb{E}[\\exp(kY)] = \\exp(k\\nu + \\frac{1}{2}k^2\\tau^2)$. For $W_t$, we have $\\nu=0$, $\\tau^2=t$, and we evaluate at $k=\\sigma$:\n$$\\mathbb{E}[\\exp(\\sigma W_t)] = \\exp\\left(\\sigma \\cdot 0 + \\frac{1}{2}\\sigma^2 t\\right) = \\exp\\left(\\frac{1}{2}\\sigma^2 t\\right)$$\nSubstituting this back into the expression for $\\mathbb{E}[X_t]$:\n$$\\mathbb{E}[X_t] = X_0 \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t\\right) \\exp\\left(\\frac{1}{2}\\sigma^2 t\\right) = X_0 \\exp\\left(\\mu t - \\frac{1}{2}\\sigma^2 t + \\frac{1}{2}\\sigma^2 t\\right)$$\n$$\\mathbb{E}[X_t] = X_0 \\exp(\\mu t)$$\n\n**Calculation of Variance $\\mathrm{Var}(X_{t})$**\n\nThe variance is defined as $\\mathrm{Var}(X_t) = \\mathbb{E}[X_t^2] - (\\mathbb{E}[X_t])^2$. We first compute the second moment, $\\mathbb{E}[X_t^2]$.\n$$X_t^2 = \\left(X_0 \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + \\sigma W_t\\right)\\right)^2 = X_0^2 \\exp\\left(2\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)t + 2\\sigma W_t\\right)$$\n$$X_t^2 = X_0^2 \\exp\\left((2\\mu - \\sigma^2)t + 2\\sigma W_t\\right)$$\nTaking the expectation:\n$$\\mathbb{E}[X_t^2] = X_0^2 \\exp((2\\mu - \\sigma^2)t) \\mathbb{E}[\\exp(2\\sigma W_t)]$$\nUsing the moment-generating function for $W_t \\sim N(0, t)$ with $k=2\\sigma$:\n$$\\mathbb{E}[\\exp(2\\sigma W_t)] = \\exp\\left(2\\sigma \\cdot 0 + \\frac{1}{2}(2\\sigma)^2 t\\right) = \\exp\\left(2\\sigma^2 t\\right)$$\nSubstituting this back:\n$$\\mathbb{E}[X_t^2] = X_0^2 \\exp((2\\mu - \\sigma^2)t) \\exp(2\\sigma^2 t) = X_0^2 \\exp((2\\mu + \\sigma^2)t)$$\nNow, we compute the variance:\n$$\\mathrm{Var}(X_t) = \\mathbb{E}[X_t^2] - (\\mathbb{E}[X_t])^2 = X_0^2 \\exp((2\\mu + \\sigma^2)t) - (X_0 \\exp(\\mu t))^2$$\n$$\\mathrm{Var}(X_t) = X_0^2 \\exp(2\\mu t + \\sigma^2 t) - X_0^2 \\exp(2\\mu t)$$\nFactoring out the common term $X_0^2 \\exp(2\\mu t)$:\n$$\\mathrm{Var}(X_t) = X_0^2 \\exp(2\\mu t) \\left(\\exp(\\sigma^2 t) - 1\\right)$$\n\n**Stationarity Analysis and Contrast with the Ornstein–Uhlenbeck Process**\n\nA stochastic process is (weak-sense) stationary if its mean is constant and its autocovariance function depends only on the time lag. For the GBM process $X_t$:\n-   The mean is $\\mathbb{E}[X_t] = X_0 \\exp(\\mu t)$. This is time-dependent for any $\\mu \\neq 0$.\n-   The variance is $\\mathrm{Var}(X_t) = X_0^2 \\exp(2\\mu t)(\\exp(\\sigma^2 t) - 1)$. This is time-dependent for any $\\sigma  0$.\nSince both the mean and variance depend on time $t$, the distribution of $X_t$ is not constant. Therefore, the geometric Brownian motion process $X_t$ is non-stationary. The multiplicative noise term $\\sigma X_t dW_t$ causes the process volatility to grow with the level of the process, leading to exponential growth in variance and preventing the process from converging to a stationary distribution.\n\nIn contrast, consider the Ornstein–Uhlenbeck (OU) process:\n$$dY_t = -\\theta(Y_t - m)dt + \\sigma dW_t$$\nThis process features additive noise ($\\sigma dW_t$) and a mean-reverting drift term. The solution to this SDE is:\n$$Y_t = m + (Y_0 - m)\\exp(-\\theta t) + \\sigma \\int_0^t \\exp(-\\theta(t-s))dW_s$$\nThe moments are:\n-   $\\mathbb{E}[Y_t] = m + (Y_0 - m)\\exp(-\\theta t)$\n-   $\\mathrm{Var}(Y_t) = \\frac{\\sigma^2}{2\\theta}(1 - \\exp(-2\\theta t))$\nAs $t \\to \\infty$, since $\\theta  0$, the exponential terms decay to zero. The moments approach constant values:\n$$\\lim_{t\\to\\infty} \\mathbb{E}[Y_t] = m$$\n$$\\lim_{t\\to\\infty} \\mathrm{Var}(Y_t) = \\frac{\\sigma^2}{2\\theta}$$\nThe OU process is asymptotically stationary. For large $t$, it \"forgets\" its initial condition $Y_0$ and fluctuates around its stationary mean $m$ with a constant variance. This demonstrates the fundamental difference: the additive noise and mean-reverting drift of the OU process lead to long-term stability and a stationary distribution, whereas the multiplicative noise of the GBM process leads to unbounded growth and non-stationarity.", "answer": "$$ \\boxed{ \\begin{pmatrix} X_{0} \\exp\\left(\\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right) t + \\sigma W_{t}\\right)  X_{0} \\exp(\\mu t)  X_{0}^{2} \\exp(2\\mu t) \\left(\\exp(\\sigma^{2} t) - 1\\right) \\end{pmatrix} } $$", "id": "3038789"}, {"introduction": "A central question in the study of stochastic systems is whether they settle into a long-term equilibrium, described by a stationary probability distribution. This final practice explores this concept by tasking you with deriving the stationary distribution for the Ornstein-Uhlenbeck process, a canonical model with additive noise. This exercise highlights the interplay between a confining drift and constant noise that creates stability, providing a crucial point of comparison for understanding why such a stable density may not exist for systems with multiplicative noise.", "problem": "Consider the one-dimensional stochastic differential equation (SDE) for an Ornstein–Uhlenbeck process with additive noise\n$$\ndX_t=-\\lambda X_t\\,dt+\\sigma\\,dW_t,\n$$\nwhere $\\lambda0$ and $\\sigma0$ are constants, and $W_t$ is a standard Wiener process. Starting from established principles for Markov diffusion processes, derive the stationary probability density $p_{\\ast}(x)$ on $\\mathbb{R}$ and ensure it is properly normalized. Then, using the definition of ergodicity for a time-homogeneous Markov diffusion, determine for which values of $\\lambda$ the process is ergodic and briefly justify your conclusion. Finally, discuss qualitatively how the existence of a normalizable stationary density on $\\mathbb{R}$ changes if the additive noise $\\sigma\\,dW_t$ is replaced by multiplicative noise $\\sigma X_t\\,dW_t$ in the drift $-\\lambda X_t$ setting, with $\\sigma\\neq 0$.\n\nAnswer specification:\n- Provide the fully normalized stationary density $p_{\\ast}(x)$ as a closed-form analytic expression in terms of $x$, $\\lambda$, and $\\sigma$.\n- No numerical rounding is required.\n- For grading, report only $p_{\\ast}(x)$ in your final answer.", "solution": "The problem statement is first validated against the required criteria.\n\n### Step 1: Extract Givens\n- The one-dimensional stochastic differential equation (SDE) is given as: $dX_t=-\\lambda X_t\\,dt+\\sigma\\,dW_t$.\n- The parameters are constants: $\\lambda0$ and $\\sigma0$.\n- $W_t$ is a standard Wiener process.\n- The first task is to derive the stationary probability density $p_{\\ast}(x)$ on $\\mathbb{R}$ and normalize it.\n- The second task is to determine for which values of $\\lambda$ the process is ergodic.\n- The third task is to discuss qualitatively how the existence of a normalizable stationary density changes if the noise term is multiplicative, $\\sigma X_t\\,dW_t$, instead of additive.\n- The final answer should be the closed-form expression for $p_{\\ast}(x)$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is centered on the Ornstein–Uhlenbeck process, a cornerstone of stochastic calculus with wide applications in physics and finance. The SDE, the concept of a stationary density, ergodicity, and the comparison between additive and multiplicative noise are all standard, well-established topics in this field. The problem is factually and scientifically sound.\n- **Well-Posed**: The problem is clearly defined. Given the SDE and the constraints on its parameters ($\\lambda  0$), a unique, stable, and meaningful stationary solution is known to exist. The questions posed are precise and admit rigorous mathematical treatment.\n- **Objective**: The problem is stated in precise mathematical language, free of ambiguity, subjectivity, or opinion.\n- **Flaw Checklist**:\n    1.  **Scientific or Factual Unsoundness**: None. The setup is a canonical example in the study of SDEs.\n    2.  **Non-Formalizable or Irrelevant**: None. The problem is directly formalizable and is a core topic concerning additive versus multiplicative noise.\n    3.  **Incomplete or Contradictory Setup**: None. All necessary information ($\\lambda0$, $\\sigma0$) is provided.\n    4.  **Unrealistic or Infeasible**: None. The model is a standard theoretical model.\n    5.  **Ill-Posed or Poorly Structured**: None. The problem is a classic, well-posed problem.\n    6.  **Pseudo-Profound, Trivial, or Tautological**: None. The derivation requires a standard but non-trivial application of the Fokker-Planck equation.\n    7.  **Outside Scientific Verifiability**: None. All claims and results can be proven mathematically.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A reasoned solution will be provided.\n\n### Solution Derivation\n\nThe analysis begins from the Fokker-Planck equation, which describes the time evolution of the probability density function $p(x,t)$ of a process governed by a general one-dimensional SDE of the form $dX_t = a(X_t)\\,dt + b(X_t)\\,dW_t$. The Fokker-Planck equation is:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x} [a(x) p(x,t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial x^2} [b(x)^2 p(x,t)]\n$$\nFor the given Ornstein–Uhlenbeck process, $dX_t = -\\lambda X_t dt + \\sigma dW_t$, the drift and diffusion coefficients are:\n- Drift coefficient: $a(x) = -\\lambda x$\n- Diffusion coefficient: $b(x) = \\sigma$\n\nSubstituting these into the Fokker-Planck equation yields:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x} [(-\\lambda x) p(x,t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial x^2} [\\sigma^2 p(x,t)]\n$$\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = \\lambda \\frac{\\partial}{\\partial x} [x p(x,t)] + \\frac{\\sigma^2}{2} \\frac{\\partial^2 p(x,t)}{\\partial x^2}\n$$\nThe stationary probability density $p_{\\ast}(x)$ is defined by the condition that it does not change in time, i.e., $\\frac{\\partial p_{\\ast}(x)}{\\partial t} = 0$. This leads to the ordinary differential equation:\n$$\n0 = \\lambda \\frac{d}{dx} [x p_{\\ast}(x)] + \\frac{\\sigma^2}{2} \\frac{d^2 p_{\\ast}(x)}{dx^2}\n$$\nThis equation can be written as the divergence of the probability current $J(x)$ being zero:\n$$\n\\frac{d}{dx} \\left( \\lambda x p_{\\ast}(x) + \\frac{\\sigma^2}{2} \\frac{d p_{\\ast}(x)}{dx} \\right) = 0\n$$\nIntegrating once with respect to $x$ gives:\n$$\n\\lambda x p_{\\ast}(x) + \\frac{\\sigma^2}{2} \\frac{d p_{\\ast}(x)}{dx} = C_1\n$$\nwhere $C_1$ is a constant of integration. For a stationary distribution on the unbounded domain $\\mathbb{R}$, the probability current must vanish at infinity, i.e., $\\lim_{x\\to\\pm\\infty} J(x) = 0$. This implies that the net flow of probability is zero everywhere, so the constant $C_1$ must be zero. This gives the first-order linear ODE:\n$$\n\\frac{\\sigma^2}{2} \\frac{d p_{\\ast}(x)}{dx} = -\\lambda x p_{\\ast}(x)\n$$\nThis equation is separable:\n$$\n\\frac{dp_{\\ast}}{p_{\\ast}} = -\\frac{2\\lambda}{\\sigma^2} x \\,dx\n$$\nIntegrating both sides yields:\n$$\n\\ln(p_{\\ast}(x)) = -\\frac{2\\lambda}{\\sigma^2} \\frac{x^2}{2} + C_2 = -\\frac{\\lambda x^2}{\\sigma^2} + C_2\n$$\nwhere $C_2$ is another integration constant. Exponentiating both sides gives the unnormalized density:\n$$\np_{\\ast}(x) = A \\exp\\left(-\\frac{\\lambda x^2}{\\sigma^2}\\right)\n$$\nwhere $A = \\exp(C_2)$ is the normalization constant. To find $A$, we enforce the normalization condition $\\int_{-\\infty}^{\\infty} p_{\\ast}(x) \\,dx = 1$:\n$$\nA \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\lambda x^2}{\\sigma^2}\\right) \\,dx = 1\n$$\nThis is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} \\exp(-\\alpha u^2) \\,du = \\sqrt{\\frac{\\pi}{\\alpha}}$. Here, $\\alpha = \\frac{\\lambda}{\\sigma^2}$. Since $\\lambda0$ and $\\sigma0$ by definition, $\\alpha0$ and the integral converges.\n$$\n\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\lambda x^2}{\\sigma^2}\\right) \\,dx = \\sqrt{\\frac{\\pi}{\\lambda/\\sigma^2}} = \\sqrt{\\frac{\\pi \\sigma^2}{\\lambda}}\n$$\nThus, the normalization condition becomes $A \\sqrt{\\frac{\\pi \\sigma^2}{\\lambda}} = 1$, which gives the constant:\n$$\nA = \\frac{1}{\\sqrt{\\frac{\\pi \\sigma^2}{\\lambda}}} = \\sqrt{\\frac{\\lambda}{\\pi \\sigma^2}}\n$$\nThe fully normalized stationary probability density is therefore:\n$$\np_{\\ast}(x) = \\sqrt{\\frac{\\lambda}{\\pi \\sigma^2}} \\exp\\left(-\\frac{\\lambda x^2}{\\sigma^2}\\right)\n$$\nThis is a Gaussian distribution with mean $\\mu=0$ and variance $\\Sigma^2 = \\frac{\\sigma^2}{2\\lambda}$.\n\n### Ergodicity\nA time-homogeneous Markov diffusion process is ergodic if the time average of any suitable observable converges to the statistical average over the stationary distribution. A sufficient condition for ergodicity on $\\mathbb{R}$ is the existence of a unique, normalizable stationary probability distribution towards which the system evolves from any initial state.\nAs derived above, such a normalizable stationary distribution exists if and only if the normalization integral $\\int_{-\\infty}^{\\infty} \\exp(-\\frac{\\lambda x^2}{\\sigma^2}) \\,dx$ is finite. This is true if the coefficient of $x^2$ in the exponent is positive, i.e., $\\frac{\\lambda}{\\sigma^2}  0$. Since the problem specifies $\\sigma  0$, this condition reduces to $\\lambda  0$.\nThe problem statement gives $\\lambda  0$ as a condition. For these values, the drift term $-\\lambda x$ acts as a restoring force, pulling the process towards the origin and creating a \"confining potential\" $U(x) = \\frac{1}{2}\\lambda x^2$. This confinement prevents the process from escaping to infinity and ensures it explores the state space in a manner that eventually settles into the unique stationary distribution $p_{\\ast}(x)$. Therefore, the process is ergodic for all $\\lambda  0$.\n\n### Multiplicative Noise Case\nIf the additive noise $\\sigma\\,dW_t$ is replaced by multiplicative noise $\\sigma X_t\\,dW_t$, the SDE becomes:\n$$\ndX_t = -\\lambda X_t\\,dt + \\sigma X_t\\,dW_t\n$$\nThe drift and diffusion coefficients are now $a(x) = -\\lambda x$ and $b(x) = \\sigma x$. The stationary Fokker-Planck equation with zero-flux condition becomes:\n$$\n\\lambda x p_{\\ast}(x) + \\frac{1}{2} \\frac{d}{dx} [(\\sigma x)^2 p_{\\ast}(x)] = 0\n$$\nFor $x \\neq 0$, this leads to the ODE:\n$$\n\\frac{dp_{\\ast}}{p_{\\ast}} = -\\frac{2(\\lambda + \\sigma^2)}{\\sigma^2} \\frac{dx}{x}\n$$\nThe solution is of the form $p_{\\ast}(x) \\propto |x|^{-\\alpha}$ where $\\alpha = 2 + \\frac{2\\lambda}{\\sigma^2}$. Since $\\lambda0$, we have $\\alpha  2$.\nTo check for normalizability, we examine the integral $\\int_{-\\infty}^{\\infty} |x|^{-\\alpha}\\,dx$. This integral diverges at the origin $x=0$, since $\\int_{0}^{\\epsilon} x^{-\\alpha}\\,dx$ diverges for $\\alpha  1$. Thus, no normalizable stationary probability density function (in the usual sense of a regular function) exists on $\\mathbb{R}$.\n\nQualitatively, the fundamental change is that the state $X_t=0$ becomes an absorbing state or a \"trap\". At $x=0$, both the drift term $(-\\lambda x)$ and the diffusion term $(\\sigma x)$ are zero. Once the process reaches the origin, it remains there forever. For any initial condition $X_0 \\neq 0$, the drift term $-\\lambda x$ consistently pulls the process towards the origin. The stochastic fluctuations, governed by $\\sigma x$, also vanish as $x \\to 0$, so they cannot \"kick\" the process away from the origin as the additive noise could. The criterion for stability at the origin, $-\\lambda - \\frac{1}{2}\\sigma^2  0$, is always satisfied for $\\lambda  0$. Consequently, all probability mass eventually accumulates at $x=0$. The stationary distribution is no longer a smooth density spread over $\\mathbb{R}$ (like the Gaussian for additive noise), but rather a singular distribution, the Dirac delta function $p_{\\ast}(x) = \\delta(x)$. While this is a normalizable distribution ($\\int \\delta(x)\\,dx = 1$), it is fundamentally different from a non-degenerate density function, as its support is a single point.", "answer": "$$\n\\boxed{\\sqrt{\\frac{\\lambda}{\\pi \\sigma^{2}}} \\exp\\left(-\\frac{\\lambda x^{2}}{\\sigma^{2}}\\right)}\n$$", "id": "3038829"}]}