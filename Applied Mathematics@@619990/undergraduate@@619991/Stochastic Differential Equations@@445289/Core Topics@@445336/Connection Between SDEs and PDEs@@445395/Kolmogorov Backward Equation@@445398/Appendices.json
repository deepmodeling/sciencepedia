{"hands_on_practices": [{"introduction": "The infinitesimal generator, denoted $\\mathcal{L}$, is the core engine of the Kolmogorov Backward Equation, describing the expected rate of change of a function of a stochastic process. Before we can use the full power of the backward equation, we must first understand how to construct its main component. This practice guides you through a first-principles derivation of the generator for a common process, grounding the abstract operator in the concrete dynamics of a stochastic differential equation (SDE). [@problem_id:3062743]", "problem": "Consider the one-dimensional stochastic differential equation (SDE) in $\\mathbb{R}$ given by\n$$\ndX_t = b X_t \\, dt + \\sigma \\, dW_t,\n$$\nwhere $b \\in \\mathbb{R}$ and $\\sigma  0$ are constants, and $W_t$ is a standard Brownian motion. Let a function $f:\\mathbb{R}\\to\\mathbb{R}$ be defined by $f(x)=|x|^2$. Using only foundational tools of stochastic calculus and the definition of the infinitesimal generator arising in the Kolmogorov backward equation (KBE), derive from first principles the explicit form of the infinitesimal generator $\\mathcal{L}$ applied to $f$, that is, compute $\\mathcal{L}f(x)$.\n\nExpress your final answer as a single simplified analytic expression in terms of $x$, $b$, and $\\sigma$. No numerical evaluation or rounding is required.", "solution": "The problem requires the derivation of the explicit form of the infinitesimal generator $\\mathcal{L}$ applied to the function $f(x) = |x|^2$ for the stochastic differential equation (SDE) $dX_t = b X_t \\, dt + \\sigma \\, dW_t$. The derivation must be from first principles, using the definition of the generator.\n\nThe infinitesimal generator $\\mathcal{L}$ of a time-homogeneous Markov process $X_t$ is defined by its action on a suitable function $f$. For a process starting at $X_0 = x$, the definition is:\n$$\n\\mathcal{L}f(x) = \\lim_{h \\to 0^+} \\frac{\\mathbb{E}[f(X_h) | X_0=x] - f(x)}{h}\n$$\nprovided this limit exists. The notation $\\mathbb{E}[ \\cdot | X_0=x]$ denotes the expectation conditioned on the process starting at the point $x \\in \\mathbb{R}$.\n\nThe given SDE is a one-dimensional Itô process:\n$$\ndX_t = b X_t \\, dt + \\sigma \\, dW_t\n$$\nThis has a drift coefficient $\\mu(X_t) = bX_t$ and a constant diffusion coefficient $\\nu(X_t) = \\sigma$.\n\nThe function under consideration is $f(x) = |x|^2$. Since $x$ is a real variable, this is equivalent to $f(x) = x^2$. This function is in $C^2(\\mathbb{R})$, the space of twice continuously differentiable functions, which is typically the domain of the infinitesimal generator for diffusion processes. The derivatives of $f(x)$ are $f'(x) = 2x$ and $f''(x) = 2$.\n\nTo compute the expectation $\\mathbb{E}[f(X_h) | X_0=x]$, we can analyze the dynamics of the process $f(X_t)$ using Itô's lemma, which is a foundational tool in stochastic calculus. For a function $f(x)$ and an Itô process $X_t$ with drift $\\mu(X_t)$ and diffusion $\\nu(X_t)$, Itô's lemma states:\n$$\ndf(X_t) = \\left( \\mu(X_t) f'(X_t) + \\frac{1}{2} \\nu(X_t)^2 f''(X_t) \\right) dt + \\nu(X_t) f'(X_t) dW_t\n$$\nSubstituting our specific drift $\\mu(X_t) = bX_t$, diffusion $\\nu(X_t) = \\sigma$, and the function derivatives $f'(X_t) = 2X_t$ and $f''(X_t) = 2$, we get:\n$$\nd(f(X_t)) = \\left( (bX_t)(2X_t) + \\frac{1}{2} \\sigma^2 (2) \\right) dt + \\sigma(2X_t) dW_t\n$$\nSimplifying the expression gives the SDE for $f(X_t)$:\n$$\nd(f(X_t)) = (2bX_t^2 + \\sigma^2) dt + 2\\sigma X_t dW_t\n$$\nThis equation describes the infinitesimal change in $f(X_t)$. To relate this to the definition of the generator, we can write it in integral form from time $0$ to $h$:\n$$\nf(X_h) - f(X_0) = \\int_0^h (2bX_s^2 + \\sigma^2) ds + \\int_0^h 2\\sigma X_s dW_s\n$$\nNow, we take the expectation of both sides, conditioned on $X_0 = x$. This gives:\n$$\n\\mathbb{E}[f(X_h) | X_0=x] - \\mathbb{E}[f(X_0) | X_0=x] = \\mathbb{E}\\left[\\int_0^h (2bX_s^2 + \\sigma^2) ds \\bigg| X_0=x\\right] + \\mathbb{E}\\left[\\int_0^h 2\\sigma X_s dW_s \\bigg| X_0=x\\right]\n$$\nGiven the condition $X_0=x$, $f(X_0) = f(x)$ is a deterministic constant. A fundamental property of Itô integrals is that the expectation of an Itô integral with a suitable integrand (such as $2\\sigma X_s$, which is adapted to the filtration of $W_s$) is zero. Therefore, the last term vanishes:\n$$\n\\mathbb{E}\\left[\\int_0^h 2\\sigma X_s dW_s \\bigg| X_0=x\\right] = 0\n$$\nThe equation simplifies to:\n$$\n\\mathbb{E}[f(X_h) | X_0=x] - f(x) = \\mathbb{E}\\left[\\int_0^h (2bX_s^2 + \\sigma^2) ds \\bigg| X_0=x\\right]\n$$\nNow, we substitute this into the definition of the generator:\n$$\n\\mathcal{L}f(x) = \\lim_{h \\to 0^+} \\frac{1}{h} \\mathbb{E}\\left[\\int_0^h (2bX_s^2 + \\sigma^2) ds \\bigg| X_0=x\\right]\n$$\nBy Fubini's theorem, we can interchange the expectation and the time integral:\n$$\n\\mathcal{L}f(x) = \\lim_{h \\to 0^+} \\frac{1}{h} \\int_0^h \\mathbb{E}[2bX_s^2 + \\sigma^2 | X_0=x] ds\n$$\nThe function $g(s) = \\mathbb{E}[2bX_s^2 + \\sigma^2 | X_0=x]$ is continuous with respect to $s$, because the moments of the solution to the SDE are continuous in time. By the Fundamental Theorem of Calculus (specifically, the Leibniz integral rule for differentiation under the integral sign), the limit is the value of the integrand at $s=0$:\n$$\n\\mathcal{L}f(x) = g(0) = \\mathbb{E}[2bX_0^2 + \\sigma^2 | X_0=x]\n$$\nSince $X_0=x$ is a given deterministic value, the expectation evaluates directly:\n$$\n\\mathcal{L}f(x) = 2bx^2 + \\sigma^2\n$$\nThis derivation from first principles, using Itô's lemma to analyze the expected evolution of $f(X_t)$ over an infinitesimal time interval, yields the explicit form of the generator applied to $f(x)=|x|^2=x^2$. The result is consistent with the general formula for the generator of an Itô diffusion, $\\mathcal{L} = \\mu(x)\\frac{\\partial}{\\partial x} + \\frac{1}{2}\\nu(x)^2\\frac{\\partial^2}{\\partial x^2}$, which for this problem is $\\mathcal{L} = (bx)\\frac{d}{dx} + \\frac{1}{2}\\sigma^2\\frac{d^2}{dx^2}$, yielding $(bx)(2x) + \\frac{1}{2}\\sigma^2(2) = 2bx^2 + \\sigma^2$.", "answer": "$$\\boxed{2bx^{2} + \\sigma^{2}}$$", "id": "3062743"}, {"introduction": "Having defined the generator, we can now assemble the full Kolmogorov Backward Equation, which provides a powerful link between stochastic processes and partial differential equations (PDEs). To build confidence in this connection, this exercise takes a two-pronged approach. You will first calculate a conditional expectation directly using probabilistic methods and then verify that your result indeed solves the associated backward equation, confirming the celebrated Feynman-Kac formula in a tangible example. [@problem_id:3062785]", "problem": "Consider the one-dimensional Itô stochastic differential equation (SDE) for a process $X_{s}$, defined for $s \\in [t,T]$, given by \n$$dX_{s}=\\mu\\,ds+\\sigma\\,dW_{s},$$\nwhere $\\mu \\in \\mathbb{R}$ and $\\sigma0$ are constants, and $W_{s}$ is a standard Brownian motion. Assume the initial condition $X_{t}=x$. Let the terminal payoff be $\\varphi(x)=x^2$, and define the function $u(t,x)=\\mathbb{E}\\!\\left[\\varphi\\!\\left(X_{T}\\right)\\mid X_{t}=x\\right]$.\n\nUsing only the fundamental properties of Itô integrals, Brownian motion increments, and expectations, compute the explicit analytical expression for $u(t,x)$ as a function of $x$, $t$, $T$, $\\mu$, and $\\sigma$. Then, verify directly by differentiation that the resulting function $u$ satisfies the Kolmogorov backward equation (KBE) with constant-coefficient generator $L f=\\mu\\,\\partial_{x} f+\\frac{\\sigma^{2}}{2}\\,\\partial_{xx} f$, that is,\n$$\n\\partial_{t}u(t,x)+\\mu\\,\\partial_{x}u(t,x)+\\frac{\\sigma^{2}}{2}\\,\\partial_{xx}u(t,x)=0,\n$$\nwith terminal condition $u(T,x)=x^2$. In particular, show that your $u(t,x)$ is a quadratic polynomial in $x$ and $T-t$ and that it solves the above partial differential equation.\n\nYour final answer must be a single closed-form analytical expression for $u(t,x)$.", "solution": "We start from the fundamental definition of an Itô stochastic differential equation (SDE) and the properties of Brownian motion. The SDE is\n$$\ndX_{s}=\\mu\\,ds+\\sigma\\,dW_{s},\\qquad s\\in[t,T],\\quad X_{t}=x,\n$$\nwhere $W_{s}$ is a standard Brownian motion. Integrating from $t$ to $T$, we obtain\n$$\nX_{T}-X_{t}=\\int_{t}^{T}\\mu\\,ds+\\int_{t}^{T}\\sigma\\,dW_{s}=\\mu\\,(T-t)+\\sigma\\,(W_{T}-W_{t}).\n$$\nUsing $X_{t}=x$, this gives the explicit representation\n$$\nX_{T}=x+\\mu\\,(T-t)+\\sigma\\,(W_{T}-W_{t}).\n$$\nDefine $\\Delta W:=W_{T}-W_{t}$. By the basic properties of Brownian motion, $\\Delta W$ is a Gaussian random variable with mean $0$ and variance $T-t$, and it is independent of $\\mathcal{F}_{t}$. Therefore,\n$$\nu(t,x)=\\mathbb{E}\\!\\left[X_{T}^{2}\\mid X_{t}=x\\right]=\\mathbb{E}\\!\\left[\\left(x+\\mu\\,(T-t)+\\sigma\\,\\Delta W\\right)^{2}\\right].\n$$\nLet $A:=x+\\mu\\,(T-t)$. Then\n$$\nu(t,x)=\\mathbb{E}\\!\\left[(A+\\sigma\\,\\Delta W)^{2}\\right]=\\mathbb{E}\\!\\left[A^{2}+2A\\sigma\\,\\Delta W+\\sigma^{2}\\,(\\Delta W)^{2}\\right].\n$$\nUsing linearity of expectation and $\\mathbb{E}[\\Delta W]=0$, $\\mathbb{E}[(\\Delta W)^{2}]=\\mathrm{Var}(\\Delta W)=T-t$, we obtain\n$$\nu(t,x)=A^{2}+\\sigma^{2}\\,(T-t)=\\left(x+\\mu\\,(T-t)\\right)^{2}+\\sigma^{2}\\,(T-t).\n$$\nThus,\n$$\nu(t,x)=x^{2}+2\\mu\\,x\\,(T-t)+\\mu^{2}\\,(T-t)^{2}+\\sigma^{2}\\,(T-t),\n$$\nwhich is manifestly a quadratic polynomial in $x$ and $T-t$.\n\nNext, we verify that $u$ solves the Kolmogorov backward equation (KBE) with terminal condition. Introduce $\\tau:=T-t$ so that $u$ can be written as\n$$\nu(t,x)=\\left(x+\\mu\\,\\tau\\right)^{2}+\\sigma^{2}\\,\\tau.\n$$\nDifferentiate $u$ with respect to $x$ and $t$. First compute spatial derivatives. Let $A:=x+\\mu\\,\\tau$. Then\n$$\n\\partial_{x}u(t,x)=\\partial_{x}\\left(A^{2}+\\sigma^{2}\\,\\tau\\right)=2A\\cdot\\partial_{x}A=2A,\n$$\nand\n$$\n\\partial_{xx}u(t,x)=\\partial_{x}(2A)=2.\n$$\nFor the time derivative, note that $\\tau=T-t$ so $\\partial_{t}\\tau=-1$. Compute\n$$\n\\partial_{\\tau}u(t,x)=\\partial_{\\tau}\\left(A^{2}+\\sigma^{2}\\,\\tau\\right)=2A\\cdot\\partial_{\\tau}A+\\sigma^{2}=2A\\mu+\\sigma^{2},\n$$\nhence\n$$\n\\partial_{t}u(t,x)=\\partial_{\\tau}u(t,x)\\cdot\\partial_{t}\\tau=-(2\\mu\\,A+\\sigma^{2}).\n$$\nNow substitute into the KBE:\n$$\n\\partial_{t}u+\\mu\\,\\partial_{x}u+\\frac{\\sigma^{2}}{2}\\,\\partial_{xx}u=-(2\\mu\\,A+\\sigma^{2})+\\mu\\,(2A)+\\frac{\\sigma^{2}}{2}\\,(2)=-(2\\mu\\,A+\\sigma^{2})+2\\mu\\,A+\\sigma^{2}=0.\n$$\nThus $u$ satisfies the Kolmogorov backward equation. For the terminal condition,\n$$\nu(T,x)=\\left(x+\\mu\\,(T-T)\\right)^{2}+\\sigma^{2}\\,(T-T)=x^{2},\n$$\nwhich matches $\\varphi(x)=x^{2}$. Therefore, the computed quadratic polynomial $u(t,x)$ both solves the KBE and satisfies the terminal condition.", "answer": "$$\\boxed{\\left(x+\\mu\\,(T-t)\\right)^{2}+\\sigma^{2}\\,(T-t)}$$", "id": "3062785"}, {"introduction": "Now that we have verified the validity of the Kolmogorov Backward Equation, we can wield it as a primary problem-solving tool. For many problems, solving the PDE is far more straightforward than tackling the probabilistic expectation directly, especially in higher dimensions. This final practice demonstrates this utility by setting up and solving the KBE to find a key quantity—the mean-squared displacement of a multidimensional Brownian motion. [@problem_id:3062740]", "problem": "Consider a standard $d$-dimensional Brownian motion $\\{X_{s}\\}_{s \\ge 0}$ solving the stochastic differential equation (SDE) $dX_{s} = dW_{s}$, where $W_{s}$ is a standard $d$-dimensional Brownian motion and $X_{t} = x \\in \\mathbb{R}^{d}$ at time $t$. Let $T  t$ be fixed. Define the function $u(t,x)$ by\n$$\nu(t,x) := \\mathbb{E}\\!\\left[\\,|X_{T}|^2 \\,\\big|\\, X_{t} = x \\right].\n$$\nUsing the Kolmogorov backward equation (KBE) and the generator of Brownian motion, compute $u(t,x)$ in closed form, starting from fundamental definitions (such as the infinitesimal generator and Dynkin's formula) and without assuming any explicit formula for transition densities. Then use your expression to confirm the variance growth property of Brownian motion increments by identifying $\\mathbb{E}\\!\\left[\\,|X_{T} - x|^2 \\,\\big|\\, X_{t} = x \\right]$.\n\nYour final answer must be a single closed-form analytic expression for $u(t,x)$; do not include any intermediate results in the final answer. No rounding is required.", "solution": "The problem asks for the computation of $u(t,x) = \\mathbb{E}[|X_T|^2 \\,|\\, X_t = x]$ for a process governed by the SDE $dX_s = dW_s$ with $X_t = x$, using the Kolmogorov backward equation (KBE).\n\nFirst, we identify the infinitesimal generator $\\mathcal{A}$ for a standard $d$-dimensional Brownian motion $X_s$. The SDE has zero drift ($\\mu(x) = 0$) and the diffusion matrix is the identity ($\\sigma(x) = I_d$). The generator acting on a sufficiently smooth function $f(x)$ is given by:\n$$\n\\mathcal{A}f(x) = \\sum_{i=1}^{d} \\mu_i(x) \\frac{\\partial f}{\\partial x_i} + \\frac{1}{2} \\sum_{i=1}^{d} \\sum_{j=1}^{d} (\\sigma\\sigma^T)_{ij} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} = \\frac{1}{2} \\sum_{i=1}^{d} \\frac{\\partial^2 f}{\\partial x_i^2} = \\frac{1}{2}\\Delta f(x)\n$$\nwhere $\\Delta$ is the Laplacian operator.\n\nThe function $u(t,x)$ must satisfy the KBE, which is $\\frac{\\partial u}{\\partial t} + \\mathcal{A}u = 0$, with the terminal condition $u(T,x) = \\psi(x) = |x|^2$. The specific PDE problem is therefore:\n$$\n\\frac{\\partial u}{\\partial t} + \\frac{1}{2}\\Delta u = 0, \\quad \\text{for } t \\in [0, T)\n$$\n$$\nu(T,x) = |x|^2 = \\sum_{i=1}^{d} x_i^2\n$$\nGiven the quadratic terminal condition and the symmetry of the Laplacian, we propose an ansatz of the form $u(t,x) = A(t)|x|^2 + B(t)$. We compute the derivatives:\n$$\n\\frac{\\partial u}{\\partial t} = A'(t)|x|^2 + B'(t) \\quad \\text{and} \\quad \\Delta u = \\sum_{i=1}^d \\frac{\\partial^2}{\\partial x_i^2}(A(t)|x|^2 + B(t)) = \\sum_{i=1}^d 2A(t) = 2dA(t)\n$$\nSubstituting these into the PDE gives:\n$$\nA'(t)|x|^2 + B'(t) + \\frac{1}{2}(2dA(t)) = 0 \\implies A'(t)|x|^2 + (B'(t) + dA(t)) = 0\n$$\nSince this must hold for all $x$, we equate coefficients of powers of $|x|^2$ to zero, yielding a system of ODEs:\n1.  $A'(t) = 0$\n2.  $B'(t) + dA(t) = 0$\n\nThe terminal condition $u(T,x) = |x|^2$ implies $A(T)|x|^2 + B(T) = |x|^2$, which gives terminal conditions for the ODEs: $A(T) = 1$ and $B(T) = 0$.\n\nSolving the first ODE, $A'(t)=0$ with $A(T)=1$, gives $A(t)=1$ for all $t$.\nSubstituting this into the second ODE gives $B'(t) + d = 0$, or $B'(t) = -d$. Integrating gives $B(t) = -dt + C$. Using $B(T)=0$, we find $0 = -dT + C$, so $C=dT$. Therefore, $B(t) = d(T-t)$.\n\nThe solution is $u(t,x) = A(t)|x|^2 + B(t) = |x|^2 + d(T-t)$.\n\nTo confirm the variance growth, we compute $\\mathbb{E}[|X_T - x|^2 \\,|\\, X_t = x]$.\n$$\n\\mathbb{E}[|X_T - x|^2] = \\mathbb{E}[|X_T|^2 - 2X_T \\cdot x + |x|^2] = \\mathbb{E}[|X_T|^2] - 2\\mathbb{E}[X_T] \\cdot x + |x|^2\n$$\nWe found $\\mathbb{E}[|X_T|^2 | X_t = x] = u(t,x) = |x|^2 + d(T-t)$. Since $X_s$ is a martingale, $\\mathbb{E}[X_T | X_t=x] = x$.\n$$\n\\mathbb{E}[|X_T - x|^2 | X_t = x] = (|x|^2 + d(T-t)) - 2x \\cdot x + |x|^2 = d(T-t)\n$$\nThis correctly identifies the mean-squared displacement as $d(T-t)$.", "answer": "$$\n\\boxed{|x|^{2} + d(T-t)}\n$$", "id": "3062740"}]}