{"hands_on_practices": [{"introduction": "The cornerstone of our topic is the remarkable connection between stochastic processes and partial differential equations. This first practice invites you to verify this connection directly for a general Itô diffusion with constant coefficients [@problem_id:3070563]. By explicitly calculating the expected value of a function of the process and then separately applying the infinitesimal generator, you will confirm firsthand that the probabilistic representation indeed satisfies the associated Kolmogorov backward equation.", "problem": "Let $W_{t}$ be a standard Brownian motion (BM), and consider the one-dimensional Itô diffusion given by the Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_{t} \\;=\\; \\mu\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t}, \\qquad X_{0}=x,\n$$\nwhere $\\mu \\in \\mathbb{R}$ and $\\sigma0$ are constants. Let the infinitesimal generator $\\mathcal{L}$ of this diffusion act on twice continuously differentiable functions $\\varphi$ by\n$$\n\\mathcal{L}\\varphi(x) \\;=\\; \\mu\\,\\varphi'(x) \\;+\\; \\frac{1}{2}\\,\\sigma^{2}\\,\\varphi''(x).\n$$\nFix $\\alpha \\in \\mathbb{R}$ and define $f(y)=\\exp(\\alpha y)$. For $t\\geq 0$ and $x\\in\\mathbb{R}$, define\n$$\nu(t,x) \\;=\\; \\mathbb{E}^{x}\\!\\left[f\\!\\left(X_{t}\\right)\\right],\n$$\nwhere $\\mathbb{E}^{x}$ denotes expectation for the process started at $X_{0}=x$.\n\nUsing only foundational tools appropriate to this setting (notably, the definition of the generator for Itô diffusions, the distributional properties of Brownian motion, Itô's formula, and standard differentiation rules under the expectation justified by dominated convergence for this choice of $f$), perform the following:\n\n- Compute $u(t,x)$ explicitly.\n- Compute $u_{t}(t,x)$ and $\\mathcal{L}u(t,x)$.\n- Verify directly that $u_{t}(t,x)=\\mathcal{L}u(t,x)$ for all $t0$ and $x\\in\\mathbb{R}$, and that $u(0,x)=f(x)$.\n\nYour final answer must be the closed-form expression you obtain for $u(t,x)$. No numerical rounding is required.", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- The stochastic process $X_t$ is an Itô diffusion described by the stochastic differential equation (SDE):\n$$\n\\mathrm{d}X_{t} \\;=\\; \\mu\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t}\n$$\n- The initial condition is $X_{0}=x$.\n- $W_{t}$ is a standard one-dimensional Brownian motion.\n- $\\mu \\in \\mathbb{R}$ and $\\sigma0$ are constant parameters.\n- The infinitesimal generator $\\mathcal{L}$ for a function $\\varphi \\in C^2(\\mathbb{R})$ is defined as:\n$$\n\\mathcal{L}\\varphi(x) \\;=\\; \\mu\\,\\varphi'(x) \\;+\\; \\frac{1}{2}\\,\\sigma^{2}\\,\\varphi''(x)\n$$\n- A function $f: \\mathbb{R} \\to \\mathbb{R}$ is defined by $f(y)=\\exp(\\alpha y)$ for a fixed constant $\\alpha \\in \\mathbb{R}$.\n- A function $u(t,x)$ is defined as the expectation of $f(X_t)$ conditional on the process starting at $x$:\n$$\nu(t,x) \\;=\\; \\mathbb{E}^{x}\\!\\left[f\\!\\left(X_{t}\\right)\\right]\n$$\n- The tasks are:\n    1. Compute $u(t,x)$ explicitly.\n    2. Compute the partial derivative $u_{t}(t,x)$ and the action of the generator $\\mathcal{L}u(t,x)$.\n    3. Verify that the partial differential equation (PDE) $u_{t}(t,x)=\\mathcal{L}u(t,x)$ and the initial condition $u(0,x)=f(x)$ are satisfied.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in stochastic calculus, illustrating the connection between SDEs and parabolic PDEs, a concept formalized by the Feynman-Kac formula. All definitions (SDE, generator, expectation) are standard and mathematically rigorous.\n- **Well-Posed:** The problem provides all necessary information and asks for a specific function and a verification. A unique, stable, and meaningful solution exists.\n- **Objective:** The problem is stated in precise mathematical language, free from any subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution will be provided.\n\n### Solution\n\nThe solution proceeds by first explicitly solving the SDE, then computing the expectation to find $u(t,x)$, and finally verifying the PDE and initial condition through direct differentiation.\n\n**1. Compute $u(t,x)$ explicitly.**\n\nThe SDE for $X_t$ is given by\n$$\n\\mathrm{d}X_{t} = \\mu\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}W_{t}, \\quad X_{0}=x.\n$$\nThis is a linear SDE with constant coefficients. We can integrate it directly from $0$ to $t$:\n$$\n\\int_{0}^{t} \\mathrm{d}X_{s} = \\int_{0}^{t} \\mu\\,\\mathrm{d}s + \\int_{0}^{t} \\sigma\\,\\mathrm{d}W_{s}\n$$\n$$\nX_{t} - X_{0} = \\mu t + \\sigma (W_{t} - W_{0})\n$$\nGiven that $X_{0}=x$ and $W_{0}=0$ almost surely for a standard Brownian motion, the explicit solution for the process $X_t$ is:\n$$\nX_{t} = x + \\mu t + \\sigma W_{t}\n$$\nA standard Brownian motion $W_t$ is a Gaussian process. For any fixed $t0$, the random variable $W_t$ is normally distributed with mean $0$ and variance $t$, i.e., $W_t \\sim \\mathcal{N}(0, t)$. Since $X_t$ is a linear transformation of the normally distributed random variable $W_t$, $X_t$ is also normally distributed. We compute its mean and variance:\nThe mean of $X_t$ is\n$$\n\\mathbb{E}^{x}[X_t] = \\mathbb{E}[x + \\mu t + \\sigma W_{t}] = x + \\mu t + \\sigma\\mathbb{E}[W_t] = x + \\mu t + \\sigma \\cdot 0 = x + \\mu t.\n$$\nThe variance of $X_t$ is\n$$\n\\mathrm{Var}^{x}(X_t) = \\mathrm{Var}(x + \\mu t + \\sigma W_{t}) = \\mathrm{Var}(\\sigma W_{t}) = \\sigma^2 \\mathrm{Var}(W_{t}) = \\sigma^2 t.\n$$\nThus, for a given starting point $x$, the random variable $X_t$ follows a normal distribution $X_t \\sim \\mathcal{N}(x + \\mu t, \\sigma^2 t)$.\n\nNow, we compute $u(t,x)$:\n$$\nu(t,x) = \\mathbb{E}^{x}[f(X_t)] = \\mathbb{E}^{x}[\\exp(\\alpha X_t)].\n$$\nThis is precisely the moment-generating function (MGF) of the normal random variable $X_t$, evaluated at $\\alpha$. The MGF of a random variable $Y \\sim \\mathcal{N}(m, s^2)$ is given by $M_Y(a) = \\mathbb{E}[\\exp(a Y)] = \\exp(am + \\frac{1}{2}a^2s^2)$.\nIn our case, $Y=X_t$, $a=\\alpha$, the mean is $m = x + \\mu t$, and the variance is $s^2 = \\sigma^2 t$. Substituting these into the MGF formula, we obtain the explicit form of $u(t,x)$:\n$$\nu(t,x) = \\exp\\left(\\alpha(x + \\mu t) + \\frac{1}{2}\\alpha^2(\\sigma^2 t)\\right) = \\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right).\n$$\n\n**2. Compute $u_t(t,x)$ and $\\mathcal{L}u(t,x)$.**\n\nWe first compute the partial derivative of $u(t,x)$ with respect to $t$. For clarity, we can write $u(t,x)$ as:\n$$\nu(t,x) = \\exp(\\alpha x) \\exp\\left(\\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)t\\right).\n$$\nDifferentiating with respect to $t$:\n$$\nu_{t}(t,x) = \\frac{\\partial}{\\partial t}u(t,x) = \\exp(\\alpha x) \\cdot \\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\exp\\left(\\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)t\\right)\\right]\n$$\n$$\nu_{t}(t,x) = \\exp(\\alpha x) \\cdot \\exp\\left(\\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)t\\right) \\cdot \\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right)\n$$\n$$\nu_{t}(t,x) = \\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right) u(t,x).\n$$\n\nNext, we compute $\\mathcal{L}u(t,x)$. The operator $\\mathcal{L}$ acts on the spatial variable $x$. We need the first and second partial derivatives of $u(t,x)$ with respect to $x$:\n$$\nu(t,x) = \\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right).\n$$\nThe first derivative with respect to $x$ is:\n$$\n\\frac{\\partial}{\\partial x}u(t,x) = u_x(t,x) = \\alpha \\cdot \\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right) = \\alpha u(t,x).\n$$\nThe second derivative with respect to $x$ is:\n$$\n\\frac{\\partial^2}{\\partial x^2}u(t,x) = u_{xx}(t,x) = \\alpha \\cdot \\frac{\\partial}{\\partial x}u(t,x) = \\alpha (\\alpha u(t,x)) = \\alpha^2 u(t,x).\n$$\nNow we apply the infinitesimal generator $\\mathcal{L}$:\n$$\n\\mathcal{L}u(t,x) = \\mu u_x(t,x) + \\frac{1}{2}\\sigma^2 u_{xx}(t,x)\n$$\nSubstituting the derivatives we found:\n$$\n\\mathcal{L}u(t,x) = \\mu (\\alpha u(t,x)) + \\frac{1}{2}\\sigma^2 (\\alpha^2 u(t,x))\n$$\n$$\n\\mathcal{L}u(t,x) = \\left(\\mu \\alpha + \\frac{1}{2}\\sigma^2 \\alpha^2\\right) u(t,x).\n$$\nThe differentiation under the expectation sign required for these calculations is justified by the dominated convergence theorem, as the resulting integrands are suitably bounded for any finite time interval.\n\n**3. Verify the PDE and Initial Condition.**\n\nBy comparing the expressions derived in step 2, we can directly verify the PDE:\n$$\nu_{t}(t,x) = \\left(\\alpha \\mu + \\frac{1}{2}\\alpha^2 \\sigma^2\\right) u(t,x)\n$$\n$$\n\\mathcal{L}u(t,x) = \\left(\\mu \\alpha + \\frac{1}{2}\\sigma^2 \\alpha^2\\right) u(t,x)\n$$\nIt is clear that for all $t0$ and $x\\in\\mathbb{R}$,\n$$\nu_{t}(t,x) = \\mathcal{L}u(t,x).\n$$\nThis equation is the Kolmogorov backward equation for this diffusion process.\n\nFinally, we verify the initial condition at $t=0$:\n$$\nu(0,x) = \\exp\\left(\\alpha x + \\alpha \\mu (0) + \\frac{1}{2}\\alpha^2 \\sigma^2 (0)\\right) = \\exp(\\alpha x).\n$$\nBy definition, $f(x) = \\exp(\\alpha x)$. Therefore, we have verified that\n$$\nu(0,x) = f(x).\n$$\nThe function $u(t,x)$ is thus the solution to the Cauchy problem for the PDE $\\frac{\\partial u}{\\partial t} = \\mathcal{L}u$ with initial condition $u(0,x)=f(x)$.\n\nThe final answer is the explicit form of $u(t,x)$.", "answer": "$$\\boxed{\\exp\\left(\\alpha x + \\alpha \\mu t + \\frac{1}{2}\\alpha^2 \\sigma^2 t\\right)}$$", "id": "3070563"}, {"introduction": "Having established the validity of the probabilistic approach, we now explore its deeper connections to other areas of mathematics. This exercise [@problem_id:3070549] uses a complex exponential, a fundamental building block in Fourier analysis, as the initial condition for the heat equation. Your task is to show how the probabilistic solution naturally reveals that the characteristic function of Brownian motion acts as the Fourier multiplier for the PDE, elegantly unifying concepts from probability, PDEs, and harmonic analysis.", "problem": "Let $d \\in \\mathbb{N}$ and let $\\{W_{t}\\}_{t \\geq 0}$ be a standard $d$-dimensional Brownian motion with $W_{0} = 0$, whose increments are independent and stationary, and for each $t \\geq 0$, $W_{t}$ is Gaussian with mean $0$ and covariance $t I_{d}$, where $I_{d}$ is the $d \\times d$ identity matrix. Consider the Cauchy problem for the heat Partial Differential Equation (PDE)\n$$\n\\partial_{t} u(t,x) = \\frac{1}{2} \\Delta u(t,x), \\quad t  0, \\; x \\in \\mathbb{R}^{d},\n$$\nwith initial condition\n$$\nu(0,x) = f(x) = \\exp(i\\, k \\cdot x),\n$$\nwhere $k \\in \\mathbb{R}^{d}$ is fixed, $k \\cdot x$ denotes the Euclidean inner product, and $|k|$ is the Euclidean norm of $k$. Starting from the fundamental facts that the infinitesimal generator of Brownian motion is $\\frac{1}{2}\\Delta$ and that its associated Markov semigroup arises from the distributional properties of $W_{t}$, derive the probabilistic representation of the solution $u(t,x)$ and compute $u(t,x)$ explicitly. In your reasoning, identify how the action of this semigroup on the Fourier mode $\\exp(i\\, k \\cdot x)$ corresponds to a Fourier multiplier and relate this multiplier to the characteristic function of $W_{t}$. Express your final answer as a single closed-form analytic expression for $u(t,x)$. No rounding is required.", "solution": "The user has asked for the validation and solution of a mathematical problem.\n\n### Step 1: Extract Givens\n-   The dimension is a natural number, $d \\in \\mathbb{N}$.\n-   $\\{W_{t}\\}_{t \\geq 0}$ is a standard $d$-dimensional Brownian motion with $W_{0} = 0$. Its increments are independent and stationary. For any $t \\geq 0$, the random variable $W_{t}$ follows a Gaussian distribution with mean $0$ and covariance matrix $t I_{d}$, where $I_{d}$ is the $d \\times d$ identity matrix.\n-   The Partial Differential Equation (PDE) is the heat equation: $\\partial_{t} u(t,x) = \\frac{1}{2} \\Delta u(t,x)$, for $t  0$ and $x \\in \\mathbb{R}^{d}$. Here, $\\Delta$ is the Laplacian operator.\n-   The initial condition is $u(0,x) = f(x) = \\exp(i\\, k \\cdot x)$, where $k \\in \\mathbb{R}^{d}$ is a fixed vector. The notation $k \\cdot x$ represents the Euclidean inner product.\n-   The problem requires using the fact that the infinitesimal generator of the Brownian motion $\\{W_t\\}_{t \\geq 0}$ is the operator $\\frac{1}{2}\\Delta$.\n-   The task is to derive the probabilistic representation of the solution $u(t,x)$, compute it explicitly, and relate the result to Fourier multipliers and the characteristic function of $W_t$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is examined for validity.\n\n-   **Scientific Groundedness**: The problem is firmly rooted in the mathematical theory of stochastic differential equations and partial differential equations. The link between Brownian motion, its generator, and the heat equation is a fundamental and rigorously established result known as the Feynman-Kac formula. All premises are standard and mathematically correct.\n-   **Well-Posedness**: The Cauchy problem for the heat equation with a bounded, smooth initial condition such as $f(x) = \\exp(i\\, k \\cdot x)$ is a classic example of a well-posed problem. It admits a unique, stable solution.\n-   **Objectivity**: The problem is stated in precise, unambiguous mathematical language.\n-   **Completeness and Consistency**: The problem provides all necessary information: the PDE, the initial condition, and the properties of the underlying stochastic process. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a standard exercise in connecting stochastic processes to PDEs. We may proceed with the solution.\n\n### Solution Derivation\n\nThe problem concerns the heat equation $\\partial_{t} u(t,x) = \\frac{1}{2} \\Delta u(t,x)$ with an initial condition $u(0,x) = f(x)$. This PDE can be rewritten as $\\partial_{t} u(t,x) - \\mathcal{L} u(t,x) = 0$, where $\\mathcal{L} = \\frac{1}{2}\\Delta$ is the specified infinitesimal generator of the standard $d$-dimensional Brownian motion $\\{W_t\\}_{t \\geq 0}$.\n\nThe connection between this PDE and the stochastic process is given by the Feynman-Kac formula. For a stochastic process $X_s$ starting at $x$ (i.e., $X_0 = x$) whose generator is $\\mathcal{L}$, the solution to the backward Kolmogorov equation $\\partial_t u + \\mathcal{L}u = 0$ with terminal condition $u(T,x) = f(x)$ is $u(t,x) = \\mathbb{E}[f(X_{T-t}^x)]$. By a change of variables, the solution to the forward equation (the heat equation) $\\partial_t u - \\mathcal{L}u = 0$ with initial condition $u(0,x) = f(x)$ is given by considering the process $X_s = x + W_s$. The solution $u(t,x)$ is then the expectation of the initial function $f$ evaluated at the position of this process at time $t$. This gives the probabilistic representation of the solution:\n$$\nu(t,x) = \\mathbb{E}[f(x + W_t)]\n$$\nHere, the expectation $\\mathbb{E}[\\cdot]$ is taken with respect to the probability measure of the Brownian motion.\n\nThe initial condition is given as the Fourier mode $f(x) = \\exp(i\\, k \\cdot x)$. Substituting this into the probabilistic representation, we obtain:\n$$\nu(t,x) = \\mathbb{E}[\\exp(i\\, k \\cdot (x + W_t))]\n$$\nUsing the property of the exponential function, $\\exp(a+b) = \\exp(a)\\exp(b)$, we can separate the terms inside the expectation:\n$$\nu(t,x) = \\mathbb{E}[\\exp(i\\, k \\cdot x) \\exp(i\\, k \\cdot W_t)]\n$$\nThe term $\\exp(i\\, k \\cdot x)$ is deterministic with respect to the expectation over the paths of the Brownian motion $W_t$. Therefore, it can be factored out of the expectation:\n$$\nu(t,x) = \\exp(i\\, k \\cdot x) \\, \\mathbb{E}[\\exp(i\\, k \\cdot W_t)]\n$$\nThe remaining term, $\\mathbb{E}[\\exp(i\\, k \\cdot W_t)]$, is by definition the characteristic function of the random variable $W_t$, evaluated at the vector $k \\in \\mathbb{R}^d$. Let us denote this by $\\phi_{W_t}(k)$.\n\nWe are given that $W_t$ is a $d$-dimensional Gaussian random variable with mean vector $\\mu = 0$ and covariance matrix $\\Sigma = t I_d$. The characteristic function of a general multivariate normal random variable $Y \\sim \\mathcal{N}(\\mu, \\Sigma)$ is given by the formula $\\phi_Y(v) = \\exp(i\\, v \\cdot \\mu - \\frac{1}{2} v^T \\Sigma v)$.\nFor our specific case, $Y = W_t$, $\\mu = 0$, $\\Sigma = tI_d$, and the vector is $k$. Substituting these into the formula yields:\n$$\n\\phi_{W_t}(k) = \\exp\\left(i\\, k \\cdot 0 - \\frac{1}{2} k^{T} (tI_d) k\\right)\n$$\nThe first term in the exponent is $0$. The second term is:\n$$\n-\\frac{1}{2} k^{T} (tI_d) k = -\\frac{t}{2} (k^{T} k) = -\\frac{t}{2} |k|^2\n$$\nwhere $|k|^2 = k \\cdot k$ is the squared Euclidean norm of the vector $k$.\nThus, the characteristic function of $W_t$ is:\n$$\n\\phi_{W_t}(k) = \\exp\\left(-\\frac{t}{2} |k|^2\\right)\n$$\nSubstituting this result back into our expression for $u(t,x)$:\n$$\nu(t,x) = \\exp(i\\, k \\cdot x) \\exp\\left(-\\frac{t}{2} |k|^2\\right)\n$$\nCombining the exponents gives the final explicit solution:\n$$\nu(t,x) = \\exp\\left(i\\, k \\cdot x - \\frac{t}{2} |k|^2\\right)\n$$\nThis expression is the solution to the heat equation for the given initial condition.\n\nThe problem also requires us to analyze this result in the context of the associated Markov semigroup. The solution operator $P_t$, which maps the initial data $f$ to the solution $u(t, \\cdot)$, is a semigroup defined by $(P_t f)(x) = \\mathbb{E}[f(x+W_t)]$. Our calculation shows that the action of this semigroup on the Fourier mode $f(x) = \\exp(i\\, k \\cdot x)$ is:\n$$\n(P_t \\exp(i k \\cdot x))(x) = \\exp\\left(-\\frac{t}{2} |k|^2\\right) \\exp(i\\, k \\cdot x)\n$$\nThis demonstrates that the Fourier modes $\\exp(i\\, k \\cdot x)$ are eigenfunctions of the heat semigroup operators $P_t$. The corresponding eigenvalue for the mode with wavevector $k$ is $\\lambda_k(t) = \\exp(-\\frac{t}{2} |k|^2)$.\n\nThis eigenvalue is precisely the Fourier multiplier associated with the heat equation. If one were to solve the PDE using Fourier transforms, one would find that the Fourier transform of the solution $\\hat{u}(t,\\xi)$ is related to the Fourier transform of the initial data $\\hat{f}(\\xi)$ by $\\hat{u}(t,\\xi) = \\hat{f}(\\xi) \\exp(-\\frac{t}{2}|\\xi|^2)$. The factor $\\exp(-\\frac{t}{2}|\\xi|^2)$ is the Fourier multiplier.\n\nOur probabilistic derivation shows that this Fourier multiplier is identical to the characteristic function of the underlying Brownian motion increment $W_t$, evaluated at the frequency vector $\\xi=k$. This establishes the deep connection requested: the semigroup's action on a Fourier mode is multiplication by a scalar, and this scalar (the Fourier multiplier) is the characteristic function of the random increment of the associated stochastic process.", "answer": "$$\n\\boxed{\\exp\\left(i k \\cdot x - \\frac{t|k|^2}{2}\\right)}\n$$", "id": "3070549"}, {"introduction": "The power of the probabilistic representation extends beyond simple homogeneous equations. This final practice tackles an inhomogeneous parabolic PDE, where a source term continuously influences the system [@problem_id:3070555]. By applying a probabilistic version of Duhamel's principle, you will construct the solution by combining the effects of the initial condition and the integrated source term, demonstrating the framework's robustness and broad applicability.", "problem": "Let $X_{s}$ be the one-dimensional solution to the stochastic differential equation (SDE) $dX_{s} = dW_{s}$ with $X_{0} = x$, where $W_{s}$ is a standard Brownian motion. Let $\\{P_{t}\\}_{t \\geq 0}$ denote the associated Markov semigroup acting on bounded measurable functions $\\varphi$ by $P_{t}\\varphi(x) = \\mathbb{E}^{x}[\\varphi(X_{t})]$. Consider the parabolic partial differential equation (PDE)\n$$\n\\partial_{t} u(t,x) = \\frac{1}{2}\\,\\partial_{xx} u(t,x) + g_{0}(x), \\qquad u(0,x) = f(x),\n$$\non $\\mathbb{R}$, where $V \\equiv 0$ (no potential term). Using the probabilistic representation of solutions based on the Markov semigroup and the Feynman–Kac formula (FK) for $V \\equiv 0$, derive $u(t,x)$ from first principles and compute it explicitly for the choice $f(x) = \\exp(a x)$ and $g_{0}(x) = \\exp(b x)$, where $a$ and $b$ are fixed real constants with $b \\neq 0$. Express your final answer as a single closed-form analytic expression in terms of $a$, $b$, $x$, and $t$. No rounding is required, and no units are involved.", "solution": "The problem statement is parsed and validated as follows.\n\n### Step 1: Extract Givens\n- Stochastic Differential Equation (SDE): $dX_{s} = dW_{s}$\n- Initial condition for the SDE: $X_{0} = x$\n- $W_{s}$ is a standard one-dimensional Brownian motion.\n- Markov semigroup definition: $P_{t}\\varphi(x) = \\mathbb{E}^{x}[\\varphi(X_{t})]$ for a bounded measurable function $\\varphi$.\n- Parabolic Partial Differential Equation (PDE): $\\partial_{t} u(t,x) = \\frac{1}{2}\\,\\partial_{xx} u(t,x) + g_{0}(x)$\n- Initial condition for the PDE: $u(0,x) = f(x)$\n- Domain: $(t,x) \\in [0, \\infty) \\times \\mathbb{R}$\n- Potential term: $V \\equiv 0$\n- Specific initial condition function: $f(x) = \\exp(ax)$\n- Specific source term function: $g_{0}(x) = \\exp(bx)$\n- Constants: $a, b \\in \\mathbb{R}$ with the constraint $b \\neq 0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It poses a standard question in the theory of stochastic differential equations and their connection to partial differential equations. The Feynman–Kac formula provides a well-established bridge between the solution of a parabolic PDE and the expectation of a functional of a stochastic process. The given SDE describes a standard Brownian motion, and the PDE is the inhomogeneous heat equation. The functions $f(x)$ and $g_{0}(x)$ are exponential functions, which are smooth and well-behaved, ensuring that the necessary expectations are well-defined (provided any growth conditions are met, which is implicitly handled by the probabilistic framework). All components of the problem are precisely defined, self-contained, and consistent. The problem is a standard exercise in applying the Feynman-Kac theorem and is neither trivial nor ill-posed.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Derivation of the Solution\n\nThe problem asks for the solution $u(t,x)$ to the parabolic PDE:\n$$\n\\partial_{t} u(t,x) = \\frac{1}{2}\\,\\partial_{xx} u(t,x) + g_{0}(x), \\quad u(0,x) = f(x)\n$$\nThe generator of the stochastic process $X_s$ defined by $dX_s = dW_s$ is the operator $\\mathcal{L} = \\frac{1}{2}\\partial_{xx}$. The PDE can thus be written as $\\partial_t u = \\mathcal{L} u + g_0$.\n\nThe probabilistic representation of the solution to this initial value problem, which is a direct consequence of the Feynman-Kac formula (or can be seen as an application of Duhamel's principle for the semigroup $P_t$), is given by:\n$$\nu(t,x) = P_t f(x) + \\int_0^t P_s g_0(x) ds\n$$\nwhere $P_t$ is the Markov semigroup associated with the process $X_s$. Using the definition of the semigroup, $P_t \\varphi(x) = \\mathbb{E}^x[\\varphi(X_t)]$, we can write the solution as:\n$$\nu(t,x) = \\mathbb{E}^{x}[f(X_{t})] + \\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds\n$$\nHere, $\\mathbb{E}^{x}[\\cdot]$ denotes the expectation conditional on the process starting at $X_0 = x$.\n\nFirst, we must characterize the process $X_s$. The SDE is $dX_s = dW_s$ with $X_0 = x$. Integrating from $0$ to $s$ yields:\n$$\nX_s - X_0 = \\int_0^s dW_u = W_s - W_0\n$$\nSince $W_s$ is a standard Brownian motion, $W_0=0$. Therefore, the solution to the SDE is $X_s = x + W_s$. The random variable $W_s$ is normally distributed with mean $0$ and variance $s$, i.e., $W_s \\sim \\mathcal{N}(0, s)$. Consequently, $X_s$ follows a normal distribution $X_s \\sim \\mathcal{N}(x, s)$.\n\nWe will now compute the two terms of the solution $u(t,x)$ separately.\n\n**Term 1: The homogeneous part**\n\nThe first term is $\\mathbb{E}^x[f(X_t)]$. With $f(x) = \\exp(ax)$ and $X_t = x + W_t$, this term becomes:\n$$\n\\mathbb{E}^{x}[f(X_{t})] = \\mathbb{E}[\\exp(a(x+W_t)) | X_0=x] = \\mathbb{E}[\\exp(ax)\\exp(aW_t)] = \\exp(ax) \\mathbb{E}[\\exp(aW_t)]\n$$\nThe expectation $\\mathbb{E}[\\exp(aW_t)]$ is the moment-generating function (MGF) of the random variable $W_t \\sim \\mathcal{N}(0, t)$, evaluated at $a$. The MGF of a general normal random variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is $M_Y(k) = \\mathbb{E}[\\exp(kY)] = \\exp(k\\mu + \\frac{1}{2}k^2\\sigma^2)$.\nFor $W_t$, we have $\\mu=0$ and $\\sigma^2=t$. Applying this formula with $k=a$:\n$$\n\\mathbb{E}[\\exp(aW_t)] = \\exp(a \\cdot 0 + \\frac{1}{2}a^2t) = \\exp(\\frac{1}{2}a^2t)\n$$\nSubstituting this back, the first term is:\n$$\n\\mathbb{E}^{x}[f(X_{t})] = \\exp(ax) \\exp(\\frac{1}{2}a^2t) = \\exp(ax + \\frac{1}{2}a^2t)\n$$\n\n**Term 2: The inhomogeneous part**\n\nThe second term is $\\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds$. With $g_0(x) = \\exp(bx)$, the integrand is $\\mathbb{E}^{x}[\\exp(bX_s)]$.\nThe calculation is analogous to the one for Term 1, with the variable $s$ replacing the fixed time $t$ and the constant $b$ replacing $a$.\n$$\n\\mathbb{E}^{x}[g_{0}(X_{s})] = \\mathbb{E}^{x}[\\exp(bX_s)] = \\mathbb{E}[\\exp(b(x+W_s)) | X_0=x] = \\exp(bx)\\mathbb{E}[\\exp(bW_s)]\n$$\nUsing the MGF of $W_s \\sim \\mathcal{N}(0, s)$ evaluated at $b$:\n$$\n\\mathbb{E}[\\exp(bW_s)] = \\exp(b \\cdot 0 + \\frac{1}{2}b^2s) = \\exp(\\frac{1}{2}b^2s)\n$$\nThus, the integrand is:\n$$\n\\mathbb{E}^{x}[g_{0}(X_{s})] = \\exp(bx)\\exp(\\frac{1}{2}b^2s) = \\exp(bx + \\frac{1}{2}b^2s)\n$$\nNow, we integrate this expression with respect to $s$ from $0$ to $t$:\n$$\n\\int_{0}^{t} \\exp(bx + \\frac{1}{2}b^2s) ds = \\exp(bx) \\int_{0}^{t} \\exp(\\frac{1}{2}b^2s) ds\n$$\nThe problem specifies that $b \\neq 0$, so $\\frac{1}{2}b^2 \\neq 0$. The integral is elementary:\n$$\n\\int_{0}^{t} \\exp(\\frac{1}{2}b^2s) ds = \\left[ \\frac{1}{\\frac{1}{2}b^2} \\exp(\\frac{1}{2}b^2s) \\right]_{s=0}^{s=t} = \\frac{2}{b^2} \\left( \\exp(\\frac{1}{2}b^2t) - \\exp(0) \\right) = \\frac{2}{b^2} \\left( \\exp(\\frac{1}{2}b^2t) - 1 \\right)\n$$\nTherefore, the second term is:\n$$\n\\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds = \\exp(bx) \\cdot \\frac{2}{b^2} \\left( \\exp(\\frac{1}{2}b^2t) - 1 \\right) = \\frac{2}{b^2} \\left( \\exp(bx + \\frac{1}{2}b^2t) - \\exp(bx) \\right)\n$$\n\n**Final Solution**\n\nCombining the two terms gives the complete solution $u(t,x)$:\n$$\nu(t,x) = \\mathbb{E}^{x}[f(X_t)] + \\int_{0}^{t} \\mathbb{E}^{x}[g_{0}(X_{s})] ds\n$$\n$$\nu(t,x) = \\exp(ax + \\frac{1}{2}a^2t) + \\frac{2}{b^2} \\left( \\exp(bx + \\frac{1}{2}b^2t) - \\exp(bx) \\right)\n$$\nThis expression is the closed-form analytical solution for $u(t,x)$ in terms of the given parameters $a$, $b$, $x$, and $t$.", "answer": "$$\\boxed{\\exp(ax + \\frac{1}{2}a^2t) + \\frac{2}{b^2} \\left( \\exp(bx + \\frac{1}{2}b^2t) - \\exp(bx) \\right)}$$", "id": "3070555"}]}