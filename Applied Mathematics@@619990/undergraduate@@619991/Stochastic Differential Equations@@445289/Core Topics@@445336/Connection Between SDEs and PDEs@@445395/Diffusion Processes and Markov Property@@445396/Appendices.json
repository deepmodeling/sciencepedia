{"hands_on_practices": [{"introduction": "Understanding the long-term behavior of a diffusion process is a fundamental task. A key question is whether the process settles into a statistical equilibrium, which is mathematically described by an invariant probability measure. This practice will guide you through deriving the famous Gaussian invariant measure for the Ornstein-Uhlenbeck (OU) process by solving the stationary Fokker-Planck equation. You will also explore the process's generator and verify the detailed balance condition, a crucial property related to time-reversibility, by showing the generator is symmetric in the weighted space $L^2(\\pi)$ [@problem_id:3048996].", "problem": "Consider the one-dimensional Ornstein–Uhlenbeck (OU) process defined by the Itô stochastic differential equation\n$$\ndX_t \\;=\\; -\\theta\\big(X_t - \\mu\\big)\\,dt \\;+\\; \\sigma\\,dW_t, \\quad t \\geq 0,\n$$\nwhere $W_t$ is a standard one-dimensional Brownian motion (BM), $\\theta>0$ is the mean-reversion rate, $\\mu \\in \\mathbb{R}$ is the long-run mean, and $\\sigma>0$ is the noise intensity. Let $\\pi(x)$ denote an invariant probability density (if it exists), and let $\\mathcal{L}$ denote the infinitesimal generator of this Markov diffusion acting on twice continuously differentiable functions $f:\\mathbb{R}\\to\\mathbb{R}$.\n\nStarting from the Kolmogorov forward equation (also called the Fokker–Planck equation) for Itô diffusions and the definition of invariance under the Markov semigroup, derive the invariant density $\\pi(x)$ for the OU process, including its normalization constant, by solving the appropriate stationary equation. Then, using the definition of the generator $\\mathcal{L}$ and the weighted inner product\n$$\n\\langle f, g\\rangle_{L^{2}(\\pi)} \\;=\\; \\int_{\\mathbb{R}} f(x)\\,g(x)\\,\\pi(x)\\,dx,\n$$\nverify the detailed balance condition by showing that $\\mathcal{L}$ is symmetric in $L^{2}(\\pi)$ on a core of smooth, compactly supported test functions. In your verification, justify any integration by parts and boundary term evaluations using the decay of $\\pi(x)$ and the support properties of the test functions.\n\nProvide the closed-form expression for the invariant density $\\pi(x)$ as your final answer. No numerical approximation is required.", "solution": "The Ornstein-Uhlenbeck (OU) process is described by the stochastic differential equation (SDE):\n$$\ndX_t = -\\theta(X_t - \\mu) dt + \\sigma dW_t\n$$\nThis is a one-dimensional Itô diffusion of the form $dX_t = a(X_t) dt + b(X_t) dW_t$, with drift coefficient $a(x) = -\\theta(x - \\mu)$ and diffusion coefficient $b(x) = \\sigma$. The parameters are given as $\\theta > 0$, $\\mu \\in \\mathbb{R}$, and $\\sigma > 0$.\n\n### Part 1: Derivation of the Invariant Density $\\pi(x)$\n\nThe evolution of the probability density function $p(x,t)$ of a one-dimensional Itô diffusion is governed by the Kolmogorov forward equation, also known as the Fokker-Planck equation:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x} [a(x) p(x,t)] + \\frac{1}{2} \\frac{\\partial^2}{\\partial x^2} [b(x)^2 p(x,t)]\n$$\nAn invariant (or stationary) density $\\pi(x)$ is a solution that does not change with time, i.e., $\\frac{\\partial \\pi(x)}{\\partial t} = 0$. For such a density, the Fokker-Planck equation becomes:\n$$\n0 = -\\frac{d}{dx} [a(x) \\pi(x)] + \\frac{1}{2} \\frac{d^2}{dx^2} [b(x)^2 \\pi(x)]\n$$\nThis can be written as $\\frac{d}{dx} J(x) = 0$, where $J(x)$ is the probability current:\n$$\nJ(x) = a(x) \\pi(x) - \\frac{1}{2} \\frac{d}{dx} [b(x)^2 \\pi(x)]\n$$\nThe condition $\\frac{d}{dx}J(x) = 0$ implies that $J(x)$ is a constant. For a process on the entire real line $\\mathbb{R}$, a normalizable probability density requires that $\\pi(x)$ and its derivatives vanish as $|x| \\to \\infty$. This implies the constant probability current must be zero, so $J(x) = 0$ for all $x \\in \\mathbb{R}$.\n\nSubstituting the expressions for $a(x)$ and $b(x)$ for the OU process, we get:\n$$\n-\\theta(x-\\mu)\\pi(x) - \\frac{1}{2} \\frac{d}{dx} [\\sigma^2 \\pi(x)] = 0\n$$\nSince $\\sigma$ is a constant, this simplifies to a first-order ordinary differential equation (ODE) for $\\pi(x)$:\n$$\n-\\theta(x-\\mu)\\pi(x) - \\frac{\\sigma^2}{2} \\frac{d\\pi(x)}{dx} = 0\n$$\nThis is a separable ODE:\n$$\n\\frac{d\\pi}{\\pi} = -\\frac{2\\theta}{\\sigma^2}(x-\\mu) dx\n$$\nIntegrating both sides yields:\n$$\n\\int \\frac{d\\pi}{\\pi} = \\int -\\frac{2\\theta}{\\sigma^2}(x-\\mu) dx\n$$\n$$\n\\ln(\\pi(x)) = -\\frac{2\\theta}{\\sigma^2} \\frac{(x-\\mu)^2}{2} + C'\n$$\n$$\n\\ln(\\pi(x)) = -\\frac{\\theta}{\\sigma^2}(x-\\mu)^2 + C'\n$$\nExponentiating both sides gives the form of the invariant density:\n$$\n\\pi(x) = C \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)\n$$\nwhere $C = \\exp(C')$ is a normalization constant. To find $C$, we use the condition that $\\pi(x)$ must be a probability density, so its integral over $\\mathbb{R}$ must be $1$:\n$$\n\\int_{-\\infty}^{\\infty} \\pi(x) dx = C \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right) dx = 1\n$$\nLet $y = x - \\mu$, so $dy = dx$. The integral becomes:\n$$\nC \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\theta}{\\sigma^2}y^2\\right) dy = 1\n$$\nWe use the standard Gaussian integral formula $\\int_{-\\infty}^{\\infty} \\exp(-k y^2) dy = \\sqrt{\\frac{\\pi}{k}}$. Here, $k = \\frac{\\theta}{\\sigma^2}$.\n$$\nC \\sqrt{\\frac{\\pi}{\\theta/\\sigma^2}} = C \\sqrt{\\frac{\\pi\\sigma^2}{\\theta}} = 1\n$$\nSolving for $C$:\n$$\nC = \\sqrt{\\frac{\\theta}{\\pi\\sigma^2}}\n$$\nThus, the invariant density for the OU process is:\n$$\n\\pi(x) = \\sqrt{\\frac{\\theta}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)\n$$\nThis is the probability density function of a Gaussian distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{2\\theta}$.\n\n### Part 2: Verification of the Detailed Balance Condition\n\nThe detailed balance condition is equivalent to showing that the infinitesimal generator $\\mathcal{L}$ of the process is a self-adjoint (symmetric) operator in the Hilbert space $L^2(\\pi)$ with the weighted inner product $\\langle f, g\\rangle_{L^{2}(\\pi)} = \\int_{\\mathbb{R}} f(x)\\,g(x)\\,\\pi(x)\\,dx$. We need to verify that for any two smooth, compactly supported test functions $f$ and $g$:\n$$\n\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\langle f, \\mathcal{L}g\\rangle_{L^{2}(\\pi)}\n$$\nThe generator for a one-dimensional Itô diffusion is $\\mathcal{L} = a(x) \\frac{d}{dx} + \\frac{1}{2}b(x)^2 \\frac{d^2}{dx^2}$. For the OU process, this is:\n$$\n\\mathcal{L}f(x) = -\\theta(x-\\mu) \\frac{df}{dx} + \\frac{\\sigma^2}{2} \\frac{d^2f}{dx^2}\n$$\nWe evaluate the left-hand side of the symmetry condition:\n$$\n\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\int_{-\\infty}^{\\infty} \\left( -\\theta(x-\\mu) f'(x) + \\frac{\\sigma^2}{2} f''(x) \\right) g(x) \\pi(x) dx\n$$\nWe split the integral into two parts and use integration by parts on the second term involving $f''(x)$:\n$$\nI_1 = \\int_{-\\infty}^{\\infty} -\\theta(x-\\mu) f'(x) g(x) \\pi(x) dx\n$$\n$$\nI_2 = \\int_{-\\infty}^{\\infty} \\frac{\\sigma^2}{2} f''(x) g(x) \\pi(x) dx\n$$\nFor $I_2$, let $u = \\frac{\\sigma^2}{2} g(x) \\pi(x)$ and $dv = f''(x) dx$. Then $du = \\frac{\\sigma^2}{2} (g'(x)\\pi(x) + g(x)\\pi'(x)) dx$ and $v = f'(x)$.\n$$\nI_2 = \\left[ \\frac{\\sigma^2}{2} g(x) \\pi(x) f'(x) \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} f'(x) \\frac{\\sigma^2}{2} (g'(x)\\pi(x) + g(x)\\pi'(x)) dx\n$$\nThe boundary term vanishes because $f$ and $g$ (and thus their derivatives) have compact support, meaning they are zero outside a finite interval.\nSo, $\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = I_1 + I_2$ becomes:\n$$\n\\int_{-\\infty}^{\\infty} \\left[ -\\theta(x-\\mu)f'g\\pi - \\frac{\\sigma^2}{2} f'g'\\pi - \\frac{\\sigma^2}{2} f'g\\pi' \\right] dx\n$$\nWe can factor out $f'(x)$:\n$$\n\\int_{-\\infty}^{\\infty} f'(x) \\left\\{ g(x) \\left[-\\theta(x-\\mu)\\pi(x) - \\frac{\\sigma^2}{2}\\pi'(x)\\right] - g'(x)\\frac{\\sigma^2}{2}\\pi(x) \\right\\} dx\n$$\nFrom the stationary Fokker-Planck equation derived in Part 1, we found that:\n$$\n-\\theta(x-\\mu)\\pi(x) - \\frac{\\sigma^2}{2}\\pi'(x) = 0\n$$\nSubstituting this into the expression, the term multiplying $g(x)$ becomes zero. We are left with:\n$$\n\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\int_{-\\infty}^{\\infty} f'(x) \\left\\{ -g'(x)\\frac{\\sigma^2}{2}\\pi(x) \\right\\} dx = -\\frac{\\sigma^2}{2} \\int_{-\\infty}^{\\infty} f'(x)g'(x)\\pi(x) dx\n$$\nThis final expression is symmetric with respect to an interchange of $f$ and $g$. If we had started with $\\langle \\mathcal{L}g, f\\rangle_{L^{2}(\\pi)}$, we would have followed the same steps with the roles of $f$ and $g$ swapped, leading to the same result:\n$$\n\\langle f, \\mathcal{L}g\\rangle_{L^{2}(\\pi)} = \\langle \\mathcal{L}g, f\\rangle_{L^{2}(\\pi)} = -\\frac{\\sigma^2}{2} \\int_{-\\infty}^{\\infty} g'(x)f'(x)\\pi(x) dx\n$$\nTherefore, $\\langle \\mathcal{L}f, g\\rangle_{L^{2}(\\pi)} = \\langle f, \\mathcal{L}g\\rangle_{L^{2}(\\pi)}$, which confirms that the generator $\\mathcal{L}$ is symmetric in $L^2(\\pi)$ for the OU process. This verifies the detailed balance condition.", "answer": "$$\n\\boxed{\\sqrt{\\frac{\\theta}{\\pi\\sigma^2}} \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)}\n$$", "id": "3048996"}, {"introduction": "Having established the stationary distribution of the OU process, we can ask a deeper question about its behavior in equilibrium: if we were to film the process, could we tell if the movie is being played forwards or backwards? For time-reversible processes, the statistical properties are identical in both directions, a concept central to statistical physics. This exercise connects the stationary density and the probability current to the drift of the time-reversed diffusion, allowing you to prove that the stationary OU process is indeed time-reversible [@problem_id:3049015].", "problem": "Consider a one-dimensional Ornstein–Uhlenbeck (OU) diffusion process defined by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{t}=-\\theta\\left(X_{t}-\\mu\\right)\\,\\mathrm{d}t+\\sigma\\,\\mathrm{d}W_{t},\n$$\nwhere $X_{t}\\in\\mathbb{R}$, $t\\geq 0$, $\\theta>0$, $\\mu\\in\\mathbb{R}$, $\\sigma>0$ are constants, and $W_{t}$ is a standard Brownian motion. Assume the process is in its stationary regime so that the probability density of $X_{t}$ is time-independent and equal to a stationary density $\\pi(x)$. Let $p(x,t)$ denote the time-dependent density of $X_{t}$, and recall that for an Itô diffusion with drift $b(x)$ and constant diffusion coefficient $a=\\sigma^{2}$, the forward density $p(x,t)$ evolves according to the Fokker–Planck partial differential equation (PDE)\n$$\n\\partial_{t}p(x,t)=-\\partial_{x}\\big(b(x)\\,p(x,t)\\big)+\\frac{1}{2}\\,\\partial_{xx}\\big(a\\,p(x,t)\\big),\n$$\nand the associated probability current is\n$$\nJ(x,t)=b(x)\\,p(x,t)-\\frac{1}{2}\\,\\partial_{x}\\big(a\\,p(x,t)\\big).\n$$\n\nStarting from these fundamental definitions and equations, do the following:\n\n1. Derive the stationary density $\\pi(x)$ for the OU process by solving the stationary Fokker–Planck equation, and identify it up to normalization.\n\n2. Consider the time-reversed process $\\widetilde{X}_{t}:=X_{T-t}$ for a fixed $T>0$. Using only the continuity equation for probability mass and the requirement that under time reversal the probability current reverses sign, derive from first principles the drift $b^{\\ast}(x)$ of the time-reversed diffusion with the same constant diffusion coefficient $a=\\sigma^{2}$. That is, find the $b^{\\ast}(x)$ such that the reversed process satisfies an SDE of the form\n$$\n\\mathrm{d}\\widetilde{X}_{t}=b^{\\ast}\\!\\left(\\widetilde{X}_{t}\\right)\\,\\mathrm{d}t+\\sigma\\,\\mathrm{d}\\widetilde{W}_{t},\n$$\nwhere $\\widetilde{W}_{t}$ is a standard Brownian motion adapted to the reversed filtration.\n\n3. Specialize your general expression for $b^{\\ast}(x)$ to the stationary OU process above and verify that the time-reversed SDE has the same functional form as the forward SDE. Provide the explicit analytical expression for $b^{\\ast}(x)$ as your final answer.\n\nYour final answer must be a single closed-form analytic expression for $b^{\\ast}(x)$ with no units.", "solution": "The Ornstein–Uhlenbeck (OU) process is described by the stochastic differential equation (SDE):\n$$\n\\mathrm{d}X_{t}=-\\theta\\left(X_{t}-\\mu\\right)\\,\\mathrm{d}t+\\sigma\\,\\mathrm{d}W_{t}\n$$\nThe drift function is $b(x) = -\\theta(x-\\mu)$, and the diffusion coefficient is a constant $a = \\sigma^2$.\n\n**Part 1: Derivation of the stationary density $\\pi(x)$**\n\nThe evolution of the probability density $p(x,t)$ is governed by the Fokker–Planck equation (FPE):\n$$\n\\partial_{t}p(x,t)=-\\partial_{x}\\big(b(x)\\,p(x,t)\\big)+\\frac{1}{2}\\,\\partial_{xx}\\big(a\\,p(x,t)\\big)\n$$\nIn the stationary regime, the density is time-independent, so $p(x,t) = \\pi(x)$ and $\\partial_{t}\\pi(x) = 0$. The stationary FPE is thus:\n$$\n0 = -\\partial_{x}\\big(b(x)\\,\\pi(x)\\big)+\\frac{1}{2}\\,\\partial_{xx}\\big(a\\,\\pi(x)\\big)\n$$\nSince the diffusion coefficient $a$ is constant, we can write this as:\n$$\n0 = -\\partial_{x}\\left(b(x)\\,\\pi(x)-\\frac{1}{2}\\,a\\,\\partial_{x}\\pi(x)\\right)\n$$\nThe term in the parentheses is the probability current, $J(x,t)$, which in the stationary state becomes $J_{st}(x)$. The equation $\\partial_{x}J_{st}(x) = 0$ implies that the stationary current $J_{st}(x)$ is a constant. For a process on the real line $\\mathbb{R}$, a normalizable probability density $\\pi(x)$ must vanish at infinity, i.e., $\\lim_{|x|\\to\\infty} \\pi(x) = 0$ and $\\lim_{|x|\\to\\infty} \\partial_x \\pi(x) = 0$. This requires the constant stationary current to be zero, $J_{st}(x) = 0$.\nTherefore, we must solve the first-order ordinary differential equation:\n$$\nb(x)\\,\\pi(x)-\\frac{1}{2}\\,a\\,\\partial_{x}\\pi(x) = 0\n$$\nRearranging the terms gives a separable equation for $\\pi(x)$:\n$$\n\\frac{\\partial_{x}\\pi(x)}{\\pi(x)} = \\frac{2b(x)}{a}\n$$\nSubstituting the specific forms for the OU process, $b(x) = -\\theta(x-\\mu)$ and $a = \\sigma^2$:\n$$\n\\frac{\\partial_{x}\\pi(x)}{\\pi(x)} = \\frac{2(-\\theta(x-\\mu))}{\\sigma^2} = -\\frac{2\\theta}{\\sigma^2}(x-\\mu)\n$$\nIntegrating both sides with respect to $x$:\n$$\n\\int \\frac{1}{\\pi(x)}\\,\\mathrm{d}\\pi(x) = -\\frac{2\\theta}{\\sigma^2} \\int (x-\\mu)\\,\\mathrm{d}x\n$$\n$$\n\\ln(\\pi(x)) = -\\frac{2\\theta}{\\sigma^2} \\frac{(x-\\mu)^2}{2} + C'\n$$\nwhere $C'$ is an integration constant. Exponentiating both sides yields the stationary density $\\pi(x)$ up to a normalization constant $C = \\exp(C')$:\n$$\n\\pi(x) = C \\exp\\left(-\\frac{\\theta}{\\sigma^2}(x-\\mu)^2\\right)\n$$\nThis is the functional form of a Gaussian density with mean $\\mu$ and variance $\\frac{\\sigma^2}{2\\theta}$.\n\n**Part 2: Derivation of the time-reversed drift $b^{\\ast}(x)$**\n\nThe FPE is a continuity equation for probability, $\\partial_{t}p(x,t) = -\\partial_{x}J(x,t)$, where the forward current is $J(x,t) = b(x)p(x,t) - \\frac{1}{2}a\\partial_{x}p(x,t)$, since $a=\\sigma^2$ is constant.\n\nLet $\\widetilde{X}_{t} = X_{T-t}$ be the time-reversed process. Its probability density $\\widetilde{p}(x,t)$ is related to the forward process density $p(x,t)$ by $\\widetilde{p}(x,t) = p(x,T-t)$.\nWe find the time evolution of $\\widetilde{p}(x,t)$ by using the chain rule. Let $s=T-t$, so $\\frac{\\mathrm{d}s}{\\mathrm{d}t} = -1$.\n$$\n\\partial_{t}\\widetilde{p}(x,t) = \\partial_{t}p(x,T-t) = \\frac{\\partial p(x,s)}{\\partial s}\\frac{\\mathrm{d}s}{\\mathrm{d}t}\\bigg|_{s=T-t} = -\\partial_{s}p(x,s)\\bigg|_{s=T-t}\n$$\nFrom the forward FPE, we have $\\partial_{s}p(x,s) = -\\partial_{x}J(x,s)$. Substituting this in, we get:\n$$\n\\partial_{t}\\widetilde{p}(x,t) = -(-\\partial_{x}J(x,s))\\big|_{s=T-t} = \\partial_{x}J(x,T-t)\n$$\nThe FPE for the time-reversed process is $\\partial_{t}\\widetilde{p}(x,t) = -\\partial_{x}\\widetilde{J}(x,t)$, where $\\widetilde{J}(x,t)$ is the current of the reversed process. Comparing these two equations, we see that the currents are related by:\n$$\n\\widetilde{J}(x,t) = -J(x,T-t)\n$$\nThis matches the condition given in the problem statement. The reversed process is assumed to have drift $b^{\\ast}(x)$ and the same diffusion coefficient $a$. Its current is therefore defined as:\n$$\n\\widetilde{J}(x,t) = b^{\\ast}(x)\\widetilde{p}(x,t) - \\frac{1}{2}a\\partial_{x}\\widetilde{p}(x,t)\n$$\nEquating the two expressions for $\\widetilde{J}(x,t)$ and substituting the definitions of the currents and densities:\n$$\nb^{\\ast}(x)p(x,T-t) - \\frac{1}{2}a\\partial_{x}p(x,T-t) = -\\left(b(x)p(x,T-t) - \\frac{1}{2}a\\partial_{x}p(x,T-t)\\right)\n$$\n$$\nb^{\\ast}(x)p(x,T-t) - \\frac{1}{2}a\\partial_{x}p(x,T-t) = -b(x)p(x,T-t) + \\frac{1}{2}a\\partial_{x}p(x,T-t)\n$$\nSolving for $b^{\\ast}(x)$:\n$$\nb^{\\ast}(x)p(x,T-t) = -b(x)p(x,T-t) + a\\partial_{x}p(x,T-t)\n$$\nDividing by $p(x,T-t)$ gives the general expression for the time-reversed drift:\n$$\nb^{\\ast}(x) = -b(x) + a\\frac{\\partial_{x}p(x,T-t)}{p(x,T-t)} = -b(x) + a\\partial_{x}\\ln\\big(p(x,T-t)\\big)\n$$\n\n**Part 3: Specialization to the stationary OU process**\n\nFor a process in its stationary regime, the probability density is time-independent: $p(x,t) = \\pi(x)$ for all $t$. Therefore, $p(x,T-t) = \\pi(x)$. The general expression for the reversed drift simplifies to:\n$$\nb^{\\ast}(x) = -b(x) + a\\frac{\\partial_{x}\\pi(x)}{\\pi(x)}\n$$\nFrom Part 1, we established that for a stationary process with zero current, the following relation holds:\n$$\nb(x)\\pi(x) - \\frac{1}{2}a\\partial_{x}\\pi(x) = 0\n$$\nThis implies:\n$$\na\\frac{\\partial_{x}\\pi(x)}{\\pi(x)} = 2b(x)\n$$\nSubstituting this result into the expression for $b^{\\ast}(x)$:\n$$\nb^{\\ast}(x) = -b(x) + 2b(x) = b(x)\n$$\nThis demonstrates that for any one-dimensional stationary diffusion process with zero stationary current, the drift of the time-reversed process is identical to the drift of the forward process. Such processes are said to be time-reversible.\n\nFor the specific case of the stationary OU process, the forward drift is $b(x) = -\\theta(x-\\mu)$. Therefore, the time-reversed drift is:\n$$\nb^{\\ast}(x) = -\\theta(x-\\mu)\n$$\nThe SDE for the time-reversed process $\\widetilde{X}_t$ is:\n$$\n\\mathrm{d}\\widetilde{X}_{t} = b^{\\ast}(\\widetilde{X}_{t})\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}\\widetilde{W}_{t} = -\\theta(\\widetilde{X}_{t}-\\mu)\\,\\mathrm{d}t + \\sigma\\,\\mathrm{d}\\widetilde{W}_{t}\n$$\nThis equation has the exact same functional form as the forward SDE for $X_t$, verifying that the stationary OU process is time-reversible.", "answer": "$$\n\\boxed{-\\theta(x-\\mu)}\n$$", "id": "3049015"}, {"introduction": "While the Ornstein-Uhlenbeck process can be solved analytically, most stochastic differential equations cannot, making numerical methods essential. A critical aspect of using such methods is understanding their accuracy. This practice bridges theory and computation by comparing the exact solution of the OU process to its Euler-Maruyama approximation. By analyzing the local weak and strong errors, you will determine the global convergence rates of the simulation, providing a foundational understanding of how to assess the quality of stochastic numerical schemes [@problem_id:3049010].", "problem": "Consider the Ornstein–Uhlenbeck (OU) process defined by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{s} = -\\theta X_{s}\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}, \\quad s \\in [t,t+h],\n$$\nwhere $\\theta > 0$ and $\\sigma > 0$ are constants, $W_{s}$ is a Wiener process (Brownian motion), and the initial condition $X_{t} = x$ is deterministic. The process is a time-homogeneous Markov diffusion with linear drift and constant diffusion. Using only fundamental definitions and properties of It\\^o stochastic calculus, the Markov property, and the Gaussianity of linear functionals of Brownian motion, perform the following tasks:\n\n1. Derive the exact one-step transition density of $X_{t+h}$ conditional on $X_{t} = x$, and identify its mean and variance as functions of $\\theta$, $\\sigma$, $h$, and $x$.\n\n2. Derive the one-step Euler–Maruyama (EM) approximation $\\bar{X}_{t+h}$ started from $x$ and its transition density conditional on $X_{t} = x$, and identify its mean and variance.\n\n3. Compare the two transition densities by expanding their means and variances in powers of $h$ and use this to determine the order of the local weak error, defined through expectations of bounded sufficiently smooth test functions, and the local strong error in root-mean-square, defined by $\\left(\\mathbb{E}\\!\\left[|X_{t+h} - \\bar{X}_{t+h}|^{2} \\mid X_{t} = x\\right]\\right)^{1/2}$.\n\n4. Using standard stability and accumulation arguments based on the Markov property and independence of Wiener increments, infer the corresponding global weak and strong convergence rates of the Euler–Maruyama method for the OU process over a fixed time interval partitioned into steps of size $h$.\n\nExpress the final answer as a row matrix containing, in order, the global weak convergence rate and the global strong convergence rate. No numerical approximation is required.", "solution": "The Ornstein-Uhlenbeck SDE is given by:\n$$\n\\mathrm{d}X_{s} = -\\theta X_{s}\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}, \\quad s \\in [t,t+h]\n$$\nwith parameters $\\theta > 0$, $\\sigma > 0$, and a deterministic initial condition $X_{t} = x$.\n\n**1. Exact One-Step Transition Density**\n\nThe SDE is a linear first-order equation. We can solve it using an integrating factor, $e^{\\theta s}$. Let $Y_{s} = e^{\\theta s}X_{s}$. Using Itô's product rule, we find the differential of $Y_s$:\n$$\n\\mathrm{d}Y_{s} = \\mathrm{d}(e^{\\theta s} X_{s}) = (\\theta e^{\\theta s} X_{s})\\,\\mathrm{d}s + e^{\\theta s}\\,\\mathrm{d}X_{s}\n$$\nSubstituting the SDE for $\\mathrm{d}X_{s}$:\n$$\n\\mathrm{d}Y_{s} = \\theta e^{\\theta s} X_{s}\\,\\mathrm{d}s + e^{\\theta s}(-\\theta X_{s}\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}) = \\sigma e^{\\theta s}\\,\\mathrm{d}W_{s}\n$$\nIntegrating from $s=t$ to $s=t+h$:\n$$\nY_{t+h} - Y_{t} = \\int_{t}^{t+h} \\sigma e^{\\theta s}\\,\\mathrm{d}W_{s}\n$$\nSubstituting back $Y_s = e^{\\theta s}X_s$ and using the initial condition $X_t=x$:\n$$\ne^{\\theta(t+h)}X_{t+h} - e^{\\theta t}x = \\sigma \\int_{t}^{t+h} e^{\\theta s}\\,\\mathrm{d}W_{s}\n$$\nSolving for $X_{t+h}$:\n$$\nX_{t+h} = x e^{-\\theta h} + \\sigma \\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s}\n$$\nThe solution $X_{t+h}$ is the sum of a deterministic term and an Itô integral. An Itô integral of a deterministic function is a Gaussian random variable. Thus, $X_{t+h}$ conditional on $X_t=x$ is normally distributed.\n\nThe mean of $X_{t+h}$ is found by taking the expectation. The Itô integral has zero mean:\n$$\n\\mathbb{E}[X_{t+h} \\mid X_{t}=x] = \\mathbb{E}[x e^{-\\theta h}] + \\sigma \\mathbb{E}\\left[\\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s}\\right] = x e^{-\\theta h}\n$$\nThe variance of $X_{t+h}$ is found using the Itô isometry property for the stochastic integral part:\n$$\n\\mathrm{Var}(X_{t+h} \\mid X_{t}=x) = \\mathrm{Var}\\left(\\sigma \\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s}\\right) = \\sigma^2 \\int_{t}^{t+h} \\left(e^{-\\theta(t+h-s)}\\right)^2\\,\\mathrm{d}s\n$$\nLet $u = t+h-s$, so $\\mathrm{d}u = -\\mathrm{d}s$. The limits change from $s=t \\Rightarrow u=h$ to $s=t+h \\Rightarrow u=0$.\n$$\n\\mathrm{Var}(X_{t+h} \\mid X_{t}=x) = \\sigma^2 \\int_{h}^{0} e^{-2\\theta u}(-\\mathrm{d}u) = \\sigma^2 \\int_{0}^{h} e^{-2\\theta u}\\,\\mathrm{d}u = \\sigma^2 \\left[-\\frac{1}{2\\theta}e^{-2\\theta u}\\right]_{0}^{h} = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta h})\n$$\nSo, the transition is Gaussian: $X_{t+h} \\mid X_{t}=x \\sim \\mathcal{N}(\\mu, v)$, where:\n- Mean: $\\mu(h) = x e^{-\\theta h}$\n- Variance: $v(h) = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta h})$\nThe transition density is the probability density function of this normal distribution.\n\n**2. Euler–Maruyama Approximation and its Transition Density**\n\nThe Euler–Maruyama (EM) discretization of the SDE over a time step $h$ is:\n$$\n\\bar{X}_{t+h} = \\bar{X}_{t} + (-\\theta \\bar{X}_{t})h + \\sigma(W_{t+h} - W_{t})\n$$\nStarting from $\\bar{X}_{t} = x$, we get:\n$$\n\\bar{X}_{t+h} = x - \\theta x h + \\sigma \\Delta W_{t} = x(1-\\theta h) + \\sigma \\Delta W_{t}\n$$\nwhere $\\Delta W_{t} = W_{t+h} - W_{t}$ is a Wiener increment, which is a Gaussian random variable with mean $0$ and variance $h$, i.e., $\\Delta W_{t} \\sim \\mathcal{N}(0, h)$.\nSince $\\bar{X}_{t+h}$ is a linear transformation of a Gaussian variable, it is also Gaussian.\n\nThe mean of the EM approximation is:\n$$\n\\mathbb{E}[\\bar{X}_{t+h} \\mid X_{t}=x] = \\mathbb{E}[x(1-\\theta h) + \\sigma \\Delta W_{t}] = x(1-\\theta h) + \\sigma \\mathbb{E}[\\Delta W_{t}] = x(1-\\theta h)\n$$\nThe variance of the EM approximation is:\n$$\n\\mathrm{Var}(\\bar{X}_{t+h} \\mid X_{t}=x) = \\mathrm{Var}(x(1-\\theta h) + \\sigma \\Delta W_{t}) = \\sigma^2 \\mathrm{Var}(\\Delta W_{t}) = \\sigma^2 h\n$$\nSo, the EM transition is also Gaussian: $\\bar{X}_{t+h} \\mid X_{t}=x \\sim \\mathcal{N}(\\bar{\\mu}, \\bar{v})$, where:\n- Mean: $\\bar{\\mu}(h) = x(1-\\theta h)$\n- Variance: $\\bar{v}(h) = \\sigma^2 h$\n\n**3. Comparison and Local Errors**\n\nWe expand the exact mean and variance in powers of $h$ to compare with the EM moments.\n- **Means:** Using the Taylor series $e^{-z} = 1 - z + \\frac{z^2}{2!} - \\dots$:\n  $$\n  \\mu(h) = x e^{-\\theta h} = x\\left(1 - \\theta h + \\frac{\\theta^2 h^2}{2} + O(h^3)\\right)\n  $$\n  The difference between the exact and EM means is:\n  $$\n  \\mu(h) - \\bar{\\mu}(h) = x\\left(1 - \\theta h + \\frac{\\theta^2 h^2}{2} + O(h^3)\\right) - x(1-\\theta h) = \\frac{x\\theta^2}{2}h^2 + O(h^3) = O(h^2)\n  $$\n- **Variances:** Using the Taylor series $e^{-z} = 1 - z + \\frac{z^2}{2!} - \\dots$:\n  $$\n  v(h) = \\frac{\\sigma^2}{2\\theta}(1 - e^{-2\\theta h}) = \\frac{\\sigma^2}{2\\theta}\\left(1 - \\left(1 - 2\\theta h + \\frac{(2\\theta h)^2}{2} + O(h^3)\\right)\\right) = \\frac{\\sigma^2}{2\\theta}(2\\theta h - 2\\theta^2 h^2 + O(h^3)) = \\sigma^2 h - \\sigma^2\\theta h^2 + O(h^3)\n  $$\n  The difference between the exact and EM variances is:\n  $$\n  v(h) - \\bar{v}(h) = (\\sigma^2 h - \\sigma^2\\theta h^2 + O(h^3)) - \\sigma^2 h = -\\sigma^2\\theta h^2 + O(h^3) = O(h^2)\n  $$\n\nThe **local weak error** is of order $p$ if $|\\mathbb{E}[f(X_{t+h})] - \\mathbb{E}[f(\\bar{X}_{t+h})]| = O(h^{p+1})$ for smooth test functions $f$. Since the means and variances both match to order $h$ and differ at order $h^2$, the expectation of any sufficiently smooth function $f$ will also differ at order $h^2$. This implies the local weak error is $O(h^2)$. The local weak order is therefore $p=1$.\n\nThe **local strong error** is given by $(\\mathbb{E}[|X_{t+h} - \\bar{X}_{t+h}|^2 \\mid X_t=x])^{1/2}$. We compute the mean squared error (MSE):\n$$\nX_{t+h} - \\bar{X}_{t+h} = \\left(x e^{-\\theta h} - x(1-\\theta h)\\right) + \\sigma\\left(\\int_{t}^{t+h} e^{-\\theta(t+h-s)}\\,\\mathrm{d}W_{s} - \\int_{t}^{t+h} 1\\,\\mathrm{d}W_{s}\\right)\n$$\nLet the first term be $A$ and the second term be $B$. The terms are uncorrelated since $A$ is deterministic and $B$ is a zero-mean Itô integral. Thus, $\\mathbb{E}[(A+B)^2] = A^2 + \\mathbb{E}[B^2]$.\n- The deterministic part $A$:\n  $A = x(e^{-\\theta h} - 1 + \\theta h) = x\\left(\\left(1-\\theta h + \\frac{\\theta^2h^2}{2} + O(h^3)\\right) - 1 + \\theta h\\right) = \\frac{x\\theta^2}{2}h^2 + O(h^3) = O(h^2)$. Thus, $A^2 = O(h^4)$.\n- The stochastic part $B$: Using Itô isometry for $\\mathbb{E}[B^2]$:\n  $$\n  \\mathbb{E}[B^2] = \\sigma^2 \\int_{t}^{t+h} (e^{-\\theta(t+h-s)} - 1)^2\\,\\mathrm{d}s = \\sigma^2 \\int_{0}^{h} (e^{-\\theta u} - 1)^2\\,\\mathrm{d}u\n  $$\n  For small $u$, $(e^{-\\theta u} - 1)^2 = (-\\theta u + O(u^2))^2 = \\theta^2 u^2 + O(u^3)$.\n  $$\n  \\mathbb{E}[B^2] = \\sigma^2 \\int_{0}^{h} (\\theta^2 u^2 + O(u^3))\\,\\mathrm{d}u = \\sigma^2\\left(\\frac{\\theta^2 h^3}{3} + O(h^4)\\right) = O(h^3)\n  $$\nThe total MSE is $\\mathbb{E}[|X_{t+h} - \\bar{X}_{t+h}|^2] = A^2 + \\mathbb{E}[B^2] = O(h^4) + O(h^3) = O(h^3)$.\nThe local strong error is the root-mean-square, so it is $(O(h^3))^{1/2} = O(h^{1.5})$. The local strong order is $1.5$.\n\n**4. Global Convergence Rates**\n\nThe global rates of convergence can be inferred from the local error orders using standard accumulation arguments for stable numerical methods.\n- **Global Weak Convergence Rate:** A method with local weak order $p$ (i.e., one-step error of $O(h^{p+1})$) has a global weak convergence rate of $p$. Here, the local weak error is $O(h^2)$, so the local order is $p=1$. Thus, the global weak convergence rate is $1$.\n\n- **Global Strong Convergence Rate:** A method with local strong order $\\gamma$ (i.e., one-step RMSE of $O(h^{\\gamma})$) typically has a global strong convergence rate of $\\gamma - 0.5$. The factor $0.5$ arises from the accumulation of stochastic errors, which scales with the square root of the number of steps, $\\sqrt{N} = \\sqrt{T/h}$.\nIn our case, the local strong order is $\\gamma = 1.5$. Therefore, the global strong convergence rate is $1.5 - 0.5 = 1.0$.\n\nThis improved strong convergence rate (from the general EM rate of $0.5$ to $1.0$) is a known special case for SDEs with additive noise, where the diffusion coefficient $\\sigma(t,x)$ does not depend on the state $x$. The OU process SDE fits this case, as $\\sigma$ is a constant. For such SDEs, the Euler-Maruyama scheme is equivalent to the higher-order Milstein scheme, which generally has a strong convergence rate of $1.0$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & 1 \\end{pmatrix}}\n$$", "id": "3049010"}]}