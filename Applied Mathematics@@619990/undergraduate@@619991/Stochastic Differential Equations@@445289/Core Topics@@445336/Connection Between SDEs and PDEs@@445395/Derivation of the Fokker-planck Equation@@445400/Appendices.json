{"hands_on_practices": [{"introduction": "We begin with a foundational exercise involving the Ornstein-Uhlenbeck process, a cornerstone model for mean-reverting systems. This practice guides you through the derivation of its Fokker-Planck equation from the underlying SDE, solidifying the link between microscopic fluctuations and macroscopic probability dynamics [@problem_id:3048627]. By solving the resulting PDE, you will obtain the explicit transition probability density, offering a clear view of how the system's mean and variance evolve over time.", "problem": "Consider the Ornstein–Uhlenbeck process defined by the stochastic differential equation $dX_{t} = -\\kappa \\left(X_{t} - \\mu \\right) dt + \\sigma \\, dW_{t}$, where $\\kappa > 0$ is the mean-reversion rate, $\\mu \\in \\mathbb{R}$ is the long-run mean, $\\sigma > 0$ is the volatility parameter, and $W_{t}$ is a standard Wiener process (standard Brownian motion). Let $p(x,t \\mid x_{0})$ denote the transition probability density (the fundamental solution) of the process, i.e., the solution to the forward evolution for the density starting from the initial condition $X_{0} = x_{0}$ almost surely.\n\nUsing only the foundational elements of Itô calculus (Itô’s lemma for smooth test functions), the definition of the probability density via expectations, and standard integration by parts under appropriate decay at spatial infinity, perform the following:\n\n1) Derive the partial differential equation that governs the time evolution of the transition density $p(x,t \\mid x_{0})$ for this process together with the initial condition corresponding to $X_{0} = x_{0}$.\n\n2) Solve this initial value problem to obtain the fundamental solution $p(x,t \\mid x_{0})$ in closed form, explicitly exhibiting its mean-reverting behavior and time-dependent variance.\n\nProvide your final answer as a single analytic expression for $p(x,t \\mid x_{0})$ in terms of $x$, $t$, $x_{0}$, $\\kappa$, $\\mu$, and $\\sigma$. No numerical evaluation or rounding is required. Do not include units in your final expression.", "solution": "The problem is to derive the forward Kolmogorov equation (Fokker-Planck equation) for the Ornstein–Uhlenbeck process and then solve it to find the transition probability density $p(x,t \\mid x_{0})$. The process is defined by the stochastic differential equation (SDE):\n$$dX_{t} = -\\kappa (X_{t} - \\mu) dt + \\sigma dW_{t}$$\nwith initial condition $X_{0} = x_{0}$ almost surely. The parameters $\\kappa>0$, $\\sigma>0$, and $\\mu \\in \\mathbb{R}$ are constants.\n\n### Part 1: Derivation of the Fokker-Planck Equation\n\nLet $f(x)$ be a smooth test function that, along with its derivatives, decays sufficiently fast as $|x| \\to \\infty$. The expectation of $f(X_{t})$ can be expressed in terms of the probability density function $p(x,t) \\equiv p(x,t \\mid x_{0})$ as:\n$$\\mathbb{E}[f(X_{t})] = \\int_{-\\infty}^{\\infty} f(x) p(x,t) dx$$\nWe compute the time derivative of this expectation in two ways. First, by differentiating under the integral sign:\n$$\\frac{d}{dt} \\mathbb{E}[f(X_{t})] = \\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial p(x,t)}{\\partial t} dx$$\nSecond, we use Itô's lemma. For a function $f(X_t)$, Itô's lemma states that:\n$$df(X_{t}) = f'(X_{t}) dX_{t} + \\frac{1}{2} f''(X_{t}) (dX_{t})^2$$\nThe drift and diffusion coefficients for the Ornstein–Uhlenbeck process are $a(x,t) = -\\kappa(x-\\mu)$ and $b(x,t) = \\sigma$, respectively. The quadratic variation term $(dX_t)^2$ is calculated using Itô's rules ($dt^2 = 0$, $dt dW_t = 0$, $(dW_t)^2 = dt$):\n$$(dX_{t})^2 = \\left(-\\kappa (X_{t} - \\mu) dt + \\sigma dW_{t}\\right)^2 = \\sigma^2 (dW_t)^2 = \\sigma^2 dt$$\nSubstituting $dX_t$ and $(dX_t)^2$ into the Itô formula gives:\n$$df(X_t) = f'(X_{t})[-\\kappa(X_{t}-\\mu) dt + \\sigma dW_{t}] + \\frac{1}{2} f''(X_{t})[\\sigma^2 dt]$$\n$$df(X_t) = \\left[-\\kappa(X_{t}-\\mu)f'(X_{t}) + \\frac{1}{2}\\sigma^2 f''(X_{t})\\right] dt + \\sigma f'(X_{t}) dW_{t}$$\nTaking the expectation of the differential $df(X_t)$, we get $\\mathbb{E}[df(X_t)] = d\\mathbb{E}[f(X_t)]$. The expectation of the stochastic integral term is zero, $\\mathbb{E}[\\sigma f'(X_{t}) dW_{t}] = 0$. Thus:\n$$d\\mathbb{E}[f(X_t)] = \\mathbb{E}\\left[-\\kappa(X_{t}-\\mu)f'(X_{t}) + \\frac{1}{2}\\sigma^2 f''(X_{t})\\right] dt$$\nDividing by $dt$, we obtain the time derivative:\n$$\\frac{d}{dt}\\mathbb{E}[f(X_t)] = \\mathbb{E}\\left[-\\kappa(X_{t}-\\mu)f'(X_{t}) + \\frac{1}{2}\\sigma^2 f''(X_{t})\\right]$$\nWriting the expectation as an integral over the probability density:\n$$\\frac{d}{dt}\\mathbb{E}[f(X_t)] = \\int_{-\\infty}^{\\infty} \\left[-\\kappa(x-\\mu)f'(x) + \\frac{1}{2}\\sigma^2 f''(x)\\right] p(x,t) dx$$\nNow, we equate the two expressions for $\\frac{d}{dt}\\mathbb{E}[f(X_t)]$:\n$$\\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial p}{\\partial t} dx = \\int_{-\\infty}^{\\infty} \\left[-\\kappa(x-\\mu)f'(x)p(x,t) + \\frac{1}{2}\\sigma^2 f''(x)p(x,t)\\right] dx$$\nWe use integration by parts on the right-hand side to transfer the derivatives from $f(x)$ to the other terms. The boundary terms vanish due to the decay assumption on $f(x)$ and its derivatives at infinity.\nFor the first term (drift):\n$$\\int_{-\\infty}^{\\infty} [-\\kappa(x-\\mu)p(x,t)] f'(x) dx = \\left[-\\kappa(x-\\mu)p(x,t)f(x)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial}{\\partial x}[-\\kappa(x-\\mu)p(x,t)] dx$$\n$$= \\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial}{\\partial x}[\\kappa(x-\\mu)p(x,t)] dx$$\nFor the second term (diffusion), integrating by parts twice:\n$$\\int_{-\\infty}^{\\infty} \\left[\\frac{1}{2}\\sigma^2 p(x,t)\\right] f''(x) dx = \\left[\\frac{1}{2}\\sigma^2 p(x,t) f'(x)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} f'(x) \\frac{\\partial}{\\partial x}\\left[\\frac{1}{2}\\sigma^2 p(x,t)\\right] dx$$\n$$= -\\left[f(x)\\frac{\\partial}{\\partial x}\\left(\\frac{1}{2}\\sigma^2 p(x,t)\\right)\\right]_{-\\infty}^{\\infty} + \\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial^2}{\\partial x^2}\\left[\\frac{1}{2}\\sigma^2 p(x,t)\\right] dx$$\n$$= \\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial^2}{\\partial x^2}\\left[\\frac{1}{2}\\sigma^2 p(x,t)\\right] dx$$\nSubstituting these back into the main equation:\n$$\\int_{-\\infty}^{\\infty} f(x) \\frac{\\partial p}{\\partial t} dx = \\int_{-\\infty}^{\\infty} f(x) \\left( \\frac{\\partial}{\\partial x}[\\kappa(x-\\mu)p] + \\frac{\\partial^2}{\\partial x^2}\\left[\\frac{1}{2}\\sigma^2 p\\right] \\right) dx$$\nSince this equality must hold for any arbitrary smooth test function $f(x)$, the integrands must be identical. This gives the Fokker-Planck equation:\n$$\\frac{\\partial p(x,t)}{\\partial t} = \\frac{\\partial}{\\partial x}[\\kappa(x-\\mu)p(x,t)] + \\frac{\\sigma^2}{2} \\frac{\\partial^2 p(x,t)}{\\partial x^2}$$\nThe initial condition is that the process starts at $x_0$ at time $t=0$, which is represented by a Dirac delta function:\n$$p(x,0 \\mid x_0) = \\delta(x-x_0)$$\n\n### Part 2: Solution of the Initial Value Problem\n\nTo solve this PDE, we first solve the SDE for $X_t$. The law of $X_t$ will be the solution $p(x,t \\mid x_0)$.\nThe SDE is $dX_{t} + \\kappa X_{t} dt = \\kappa \\mu dt + \\sigma dW_{t}$.\nWe use an integrating factor $e^{\\kappa t}$. Consider $d(e^{\\kappa t} X_t)$:\n$$d(e^{\\kappa t} X_t) = \\kappa e^{\\kappa t} X_t dt + e^{\\kappa t} dX_t = e^{\\kappa t}(\\kappa X_t dt + dX_t) = e^{\\kappa t}(\\kappa \\mu dt + \\sigma dW_t)$$\nIntegrating from $s=0$ to $s=t$:\n$$e^{\\kappa t} X_t - e^{\\kappa \\cdot 0} X_0 = \\int_0^t \\kappa \\mu e^{\\kappa s} ds + \\int_0^t \\sigma e^{\\kappa s} dW_s$$\n$$e^{\\kappa t} X_t = x_0 + \\kappa \\mu \\left[\\frac{e^{\\kappa s}}{\\kappa}\\right]_0^t + \\sigma \\int_0^t e^{\\kappa s} dW_s$$\n$$e^{\\kappa t} X_t = x_0 + \\mu(e^{\\kappa t} - 1) + \\sigma \\int_0^t e^{\\kappa s} dW_s$$\nSolving for $X_t$:\n$$X_t = x_0 e^{-\\kappa t} + \\mu(1 - e^{-\\kappa t}) + \\sigma \\int_0^t e^{-\\kappa(t-s)} dW_s$$\n$$X_t = \\mu + (x_0 - \\mu)e^{-\\kappa t} + \\sigma \\int_0^t e^{-\\kappa(t-s)} dW_s$$\nSince $X_t$ is a sum of a deterministic term and an Itô integral with a deterministic integrand, $X_t$ follows a normal distribution for $t>0$. We need to find its mean $M(t)$ and variance $V(t)$.\n\nThe mean $M(t) = \\mathbb{E}[X_t]$:\n$$M(t) = \\mathbb{E}\\left[\\mu + (x_0 - \\mu)e^{-\\kappa t} + \\sigma \\int_0^t e^{-\\kappa(t-s)} dW_s\\right]$$\nUsing the linearity of expectation and the fact that the expectation of an Itô integral is zero:\n$$M(t) = \\mu + (x_0 - \\mu)e^{-\\kappa t}$$\nThe variance $V(t) = \\text{Var}(X_t) = \\mathbb{E}[(X_t - M(t))^2]$:\n$$X_t - M(t) = \\sigma \\int_0^t e^{-\\kappa(t-s)} dW_s$$\n$$V(t) = \\mathbb{E}\\left[\\left(\\sigma \\int_0^t e^{-\\kappa(t-s)} dW_s\\right)^2\\right]$$\nUsing the Itô isometry property $\\mathbb{E}[(\\int_0^t G_s dW_s)^2] = \\int_0^t \\mathbb{E}[G_s^2] ds$:\n$$V(t) = \\sigma^2 \\int_0^t \\left(e^{-\\kappa(t-s)}\\right)^2 ds = \\sigma^2 e^{-2\\kappa t} \\int_0^t e^{2\\kappa s} ds$$\n$$V(t) = \\sigma^2 e^{-2\\kappa t} \\left[\\frac{e^{2\\kappa s}}{2\\kappa}\\right]_0^t = \\frac{\\sigma^2}{2\\kappa} e^{-2\\kappa t} (e^{2\\kappa t} - 1)$$\n$$V(t) = \\frac{\\sigma^2}{2\\kappa} (1 - e^{-2\\kappa t})$$\nThe probability density of a normally distributed random variable $X_t \\sim \\mathcal{N}(M(t), V(t))$ is given by:\n$$p(x,t \\mid x_0) = \\frac{1}{\\sqrt{2\\pi V(t)}} \\exp\\left(-\\frac{(x - M(t))^2}{2V(t)}\\right)$$\nSubstituting the expressions for $M(t)$ and $V(t)$:\n$$p(x,t \\mid x_0) = \\frac{1}{\\sqrt{2\\pi \\frac{\\sigma^2}{2\\kappa}(1-e^{-2\\kappa t})}} \\exp\\left(-\\frac{(x - (\\mu + (x_0 - \\mu)e^{-\\kappa t}))^2}{2 \\frac{\\sigma^2}{2\\kappa}(1-e^{-2\\kappa t})}\\right)$$\nSimplifying the expression yields the final result for the transition probability density:\n$$p(x,t \\mid x_0) = \\sqrt{\\frac{\\kappa}{\\pi\\sigma^2(1 - \\exp(-2\\kappa t))}} \\exp\\left(-\\frac{\\kappa(x - \\mu - (x_0 - \\mu)e^{-\\kappa t})^2}{\\sigma^2(1 - \\exp(-2\\kappa t))}\\right)$$", "answer": "$$\\boxed{\\sqrt{\\frac{\\kappa}{\\pi\\sigma^{2}(1 - \\exp(-2\\kappa t))}} \\exp\\left(-\\frac{\\kappa(x - \\mu - (x_{0} - \\mu)\\exp(-\\kappa t))^{2}}{\\sigma^{2}(1 - \\exp(-2\\kappa t))}\\right)}$$", "id": "3048627"}, {"introduction": "After understanding the time-evolution of a probability density, a natural question is about its long-term behavior. This practice explores the concept of a stationary solution to the Fokker-Planck equation, which describes the equilibrium state of a stochastic system [@problem_id:3048649]. You will use the principle of zero probability flux to derive the stationary distribution, revealing its deep connection to the Boltzmann distribution of statistical mechanics.", "problem": "Consider a one-dimensional Itô Stochastic Differential Equation (SDE) of the form $dX_{t} = a(X_{t})\\,dt + \\sqrt{2D}\\,dW_{t}$, where $D>0$ is constant, $W_{t}$ is a standard Wiener process, and the drift is given by $a(x) = -D\\,\\beta\\,U'(x)$ for a differentiable potential $U:\\mathbb{R}\\to\\mathbb{R}$ and a constant $\\beta>0$. Starting from the conservation of probability and the definition of the probability current, derive the stationary solution of the associated Fokker–Planck Equation (FPE) up to a normalization constant, under natural boundary conditions at $x\\to\\pm\\infty$.\n\nThen, for the specific potential $U(x) = \\frac{1}{2}\\,\\kappa\\,x^{2}$ with $\\kappa>0$, compute the fully normalized stationary probability density $p_{\\text{st}}(x)$ over $x\\in\\mathbb{R}$, expressing your final answer in terms of $x$, $\\beta$, and $\\kappa$. No numerical approximation is required.", "solution": "### Derivation of the Stationary Fokker-Planck Solution\n\nThe general form of the Fokker-Planck equation for the probability density $p(x,t)$ of a process described by the SDE $dX_t = A(X_t)dt + B(X_t)dW_t$ is:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x}\\left[A(x)p(x,t)\\right] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\left[B(x)^2 p(x,t)\\right]\n$$\nFrom the given SDE, $dX_{t} = a(X_{t})\\,dt + \\sqrt{2D}\\,dW_{t}$, we identify the drift and diffusion coefficients:\n$A(x) = a(x) = -D\\,\\beta\\,U'(x)$\n$B(x) = \\sqrt{2D}$ (a constant)\n\nSubstituting these into the general FPE gives:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x}\\left[(-D\\,\\beta\\,U'(x))p(x,t)\\right] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\left[(\\sqrt{2D})^2 p(x,t)\\right]\n$$\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = \\frac{\\partial}{\\partial x}\\left[D\\,\\beta\\,U'(x)p(x,t)\\right] + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\left[2D p(x,t)\\right]\n$$\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = \\frac{\\partial}{\\partial x}\\left[D\\,\\beta\\,U'(x)p(x,t) + D\\frac{\\partial p(x,t)}{\\partial x}\\right]\n$$\nThis equation is in the form of a continuity equation, $\\frac{\\partial p}{\\partial t} + \\frac{\\partial J}{\\partial x} = 0$, where $J(x,t)$ is the probability current. By comparison, we identify the current as:\n$$\nJ(x,t) = -D\\,\\beta\\,U'(x)p(x,t) - D\\frac{\\partial p(x,t)}{\\partial x}\n$$\nWe seek the stationary solution, $p_{\\text{st}}(x)$, for which the probability density is time-independent, i.e., $\\frac{\\partial p_{\\text{st}}}{\\partial t} = 0$. The continuity equation for the stationary state becomes:\n$$\n\\frac{d J_{\\text{st}}(x)}{dx} = 0\n$$\nThis implies that the stationary current $J_{\\text{st}}(x)$ must be a constant, say $J_{\\text{st}}(x) = C$. The natural boundary conditions at $x \\to \\pm\\infty$ require that the probability density and its gradient vanish, $p_{\\text{st}}(x) \\to 0$ and $\\frac{dp_{\\text{st}}}{dx} \\to 0$, to ensure the solution is normalizable over $\\mathbb{R}$. This is physically required for a particle confined by a potential. Applying these conditions to the expression for $J_{\\text{st}}(x)$ implies that $C$ must be zero. Therefore, we have $J_{\\text{st}}(x) = 0$ for all $x$.\n$$\n-D\\,\\beta\\,U'(x)p_{\\text{st}}(x) - D\\frac{d p_{\\text{st}}(x)}{dx} = 0\n$$\nSince $D > 0$, we can divide by $-D$:\n$$\n\\beta\\,U'(x)p_{\\text{st}}(x) + \\frac{d p_{\\text st}(x)}{dx} = 0\n$$\nThis is a first-order linear ordinary differential equation. It is separable:\n$$\n\\frac{1}{p_{\\text{st}}(x)}\\frac{d p_{\\text{st}}(x)}{dx} = -\\beta\\,U'(x)\n$$\nIntegrating both sides with respect to $x$:\n$$\n\\int \\frac{1}{p_{\\text{st}}(x)}\\,d p_{\\text{st}}(x) = -\\beta \\int U'(x)\\,dx\n$$\n$$\n\\ln(p_{\\text{st}}(x)) = -\\beta\\,U(x) + C_1\n$$\nwhere $C_1$ is the constant of integration. Exponentiating both sides yields the stationary solution up to a normalization constant $\\mathcal{N} = \\exp(C_1)$:\n$$\np_{\\text{st}}(x) = \\mathcal{N} \\exp(-\\beta\\,U(x))\n$$\nThis is the general form of the stationary solution, which corresponds to the Boltzmann distribution.\n\n### Normalization for the Specific Potential\n\nNow, we consider the specific harmonic potential $U(x) = \\frac{1}{2}\\,\\kappa\\,x^{2}$. Substituting this into the general solution gives:\n$$\np_{\\text{st}}(x) = \\mathcal{N} \\exp\\left(-\\beta\\,\\frac{1}{2}\\,\\kappa\\,x^{2}\\right) = \\mathcal{N} \\exp\\left(-\\frac{\\beta\\kappa}{2}x^{2}\\right)\n$$\nTo find the normalization constant $\\mathcal{N}$, we impose the condition that the total probability is equal to $1$:\n$$\n\\int_{-\\infty}^{\\infty} p_{\\text{st}}(x)\\,dx = 1\n$$\n$$\n\\mathcal{N} \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\beta\\kappa}{2}x^{2}\\right)\\,dx = 1\n$$\nThe integral is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} \\exp(-ax^2)\\,dx = \\sqrt{\\frac{\\pi}{a}}$. In our case, the parameter $a = \\frac{\\beta\\kappa}{2}$. Thus, the value of the integral is:\n$$\n\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\beta\\kappa}{2}x^{2}\\right)\\,dx = \\sqrt{\\frac{\\pi}{\\beta\\kappa/2}} = \\sqrt{\\frac{2\\pi}{\\beta\\kappa}}\n$$\nSubstituting this back into the normalization condition:\n$$\n\\mathcal{N} \\sqrt{\\frac{2pi}{\\beta\\kappa}} = 1\n$$\nSolving for $\\mathcal{N}$ gives:\n$$\n\\mathcal{N} = \\frac{1}{\\sqrt{\\frac{2\\pi}{\\beta\\kappa}}} = \\sqrt{\\frac{\\beta\\kappa}{2\\pi}}\n$$\nFinally, the fully normalized stationary probability density is:\n$$\np_{\\text{st}}(x) = \\sqrt{\\frac{\\beta\\kappa}{2\\pi}} \\exp\\left(-\\frac{\\beta\\kappa x^{2}}{2}\\right)\n$$\nThis is a Gaussian distribution with mean $0$ and variance $\\sigma^{2} = (\\beta\\kappa)^{-1}$. The result is expressed solely in terms of the specified variables $x$, $\\beta$, and $\\kappa$.", "answer": "$$\n\\boxed{\\sqrt{\\frac{\\beta\\kappa}{2\\pi}} \\exp\\left(-\\frac{\\beta\\kappa x^{2}}{2}\\right)}\n$$", "id": "3048649"}, {"introduction": "While analytical solutions offer deep insight, most real-world problems demand numerical approaches to solve the Fokker-Planck equation. This comprehensive practice challenges you to bridge theory and computation by discretizing the FPE and implementing different time-stepping schemes [@problem_id:3048611]. By comparing their performance, you will gain hands-on experience with the critical trade-offs between stability, accuracy, and efficiency in scientific computing.", "problem": "You are given a one-dimensional Itô stochastic differential equation (SDE) for a state variable $X_t$ of the form $dX_t = a(X_t)\\,dt + b\\,dW_t$, where $a(x)$ is a deterministic drift, $b \\gt 0$ is a constant diffusion intensity, and $W_t$ is a standard Wiener process. Let $p(x,t)$ denote the probability density function of $X_t$ on a finite domain $x \\in [-L,L]$ with reflecting boundaries. Your tasks are as follows.\n\n1) Starting from the conservation of probability and Itô's lemma, derive the one-dimensional Fokker–Planck equation (also called the forward Kolmogorov equation) governing $p(x,t)$ for the given SDE with constant diffusion intensity. State clearly the boundary condition corresponding to reflecting boundaries in terms of probability flux.\n\n2) Consider the special case where the drift is a gradient flow $a(x) = -U'(x)$ with a smooth potential $U(x)$ and constant diffusion $D = b^2/2$. Show from first principles what the steady-state density $p_{\\mathrm{eq}}(x)$ must be under reflecting boundaries and express it as a normalized function of $U(x)$ and $D$.\n\n3) Discretize the Fokker–Planck equation on a uniform grid of $N$ nodes on $[-L,L]$ with spacing $h = 2L/(N-1)$ using a conservative finite-volume style semi-discretization in space that is mass-conservative and monotone:\n   - Use a first-order upwind numerical flux for the advective flux $- \\partial_x(a(x)\\,p)$ at cell interfaces with interface velocity obtained by arithmetic averaging of $a(x)$ at neighboring nodes.\n   - Use a centered difference for the diffusive flux $D\\,\\partial_{xx} p$ at cell interfaces.\n   - Enforce reflecting (no-flux) boundary conditions by setting the boundary interface fluxes to zero.\n\n   This yields a linear system $\\partial_t \\mathbf{p} = \\mathbf{L}\\,\\mathbf{p}$ for the vector of nodal probabilities $\\mathbf{p}(t) \\in \\mathbb{R}^N$ with a tridiagonal generator matrix $\\mathbf{L}$. Construct $\\mathbf{L}$ explicitly as a tridiagonal operator.\n\n4) For time discretization, compare the following schemes:\n   - Explicit forward Euler: $\\mathbf{p}^{n+1} = \\mathbf{p}^n + \\Delta t\\,\\mathbf{L}\\,\\mathbf{p}^n$.\n   - Implicit backward Euler: $(\\mathbf{I} - \\Delta t\\,\\mathbf{L})\\,\\mathbf{p}^{n+1} = \\mathbf{p}^n$.\n\n   For the explicit method, use the absolute stability region of forward Euler to compute the maximal stable time step $\\Delta t_{\\max}$ as the largest $\\Delta t$ for which $|1 + \\Delta t\\,\\lambda| \\le 1$ holds for all eigenvalues $\\lambda$ of $\\mathbf{L}$. For a general complex eigenvalue $\\lambda = \\lambda_r + i \\lambda_i$ with $\\lambda_r \\lt 0$, the largest stable step associated with that mode is $\\Delta t_{\\lambda} = -2\\,\\lambda_r / (\\lambda_r^2 + \\lambda_i^2)$. Define $\\Delta t_{\\max}$ as the minimum of $\\Delta t_{\\lambda}$ over all eigenvalues with $\\lambda_r \\lt 0$.\n\n5) Implement both time-stepping schemes to evolve from an initial condition $p(x,0)$ up to a given final time $T$. Use a normalized Gaussian initial density $p(x,0) \\propto \\exp\\left(-(x-x_0)^2/(2\\sigma_0^2)\\right)$ truncated to the domain and normalized with respect to the grid spacing. At each step, renormalize the numerical density to ensure its grid integral is exactly $1$.\n\n6) For each test case below, do the following:\n   - Define $U(x) = \\frac{k}{4} x^4 + \\frac{\\alpha}{2} x^2$, so that $a(x) = -U'(x) = -(k x^3 + \\alpha x)$ and $D$ is given. Compute the steady-state target $p_{\\mathrm{eq}}(x) \\propto \\exp(-U(x)/D)$ and normalize it on the grid.\n   - Construct $\\mathbf{L}$ as in item $3)$ and compute $\\Delta t_{\\max}$ from the eigenvalues of $\\mathbf{L}$.\n   - Choose $\\Delta t_{\\mathrm{exp}} = 0.9\\,\\Delta t_{\\max}$ and take $n_{\\mathrm{exp}} = \\lceil T / \\Delta t_{\\mathrm{exp}} \\rceil$ explicit steps with uniform step size adjusted to hit $T$ exactly.\n   - Choose a multiplier $m$ and set $\\Delta t_{\\mathrm{imp}} = \\min(T, m\\,\\Delta t_{\\max})$ and $n_{\\mathrm{imp}} = \\lceil T / \\Delta t_{\\mathrm{imp}} \\rceil$. March $n_{\\mathrm{imp}}$ implicit steps with uniform step size adjusted to hit $T$ exactly.\n   - Compute the grid $L^1$ errors at time $T$ relative to $p_{\\mathrm{eq}}$: $E_{\\mathrm{exp}} = \\sum_i h\\,|p^{\\mathrm{exp}}_i(T) - p_{\\mathrm{eq},i}|$ and $E_{\\mathrm{imp}} = \\sum_i h\\,|p^{\\mathrm{imp}}_i(T) - p_{\\mathrm{eq},i}|$.\n   - Report two floats per test: the step-count ratio $R_{\\mathrm{steps}} = n_{\\mathrm{exp}} / n_{\\mathrm{imp}}$ and the error ratio $R_{\\mathrm{err}} = E_{\\mathrm{imp}} / E_{\\mathrm{exp}}$.\n\n7) Your program must aggregate the results for all tests into one single line: a comma-separated list enclosed in square brackets in the order $[R_{\\mathrm{steps}}^{(1)}, R_{\\mathrm{err}}^{(1)}, R_{\\mathrm{steps}}^{(2)}, R_{\\mathrm{err}}^{(2)}, R_{\\mathrm{steps}}^{(3)}, R_{\\mathrm{err}}^{(3)}]$.\n\nUse the following test suite with all parameters dimensionless:\n- Domain size: $L = 1$, grid size $N = 121$, multiplier $m = 20$.\n- Initial condition parameters: $x_0 = 0.5$, $\\sigma_0 = 0.1$.\n- Test $1$ (moderately stiff drift): $k = 50$, $\\alpha = 4$, $D = 0.05$, $T = 0.2$.\n- Test $2$ (highly stiff drift): $k = 200$, $\\alpha = 2$, $D = 0.02$, $T = 0.1$.\n- Test $3$ (diffusion-dominated edge case): $k = 0$, $\\alpha = 0$, $D = 0.1$, $T = 0.1$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[0.5,1.2,0.3,0.9,1.0,1.0]$). All numbers in the output must be plain decimal numbers.", "solution": "The problem requires the derivation, discretization, and numerical solution of the one-dimensional Fokker-Planck equation for a stochastic process with a constant diffusion coefficient. The solution is presented in several parts, following the structure of the problem statement.\n\n### 1. Derivation of the Fokker-Planck Equation\n\nWe consider the Itô stochastic differential equation (SDE) for a state variable $X_t$:\n$$\ndX_t = a(X_t)\\,dt + b\\,dW_t\n$$\nwhere $a(x)$ is the drift, $b>0$ is a constant diffusion intensity, and $W_t$ is a standard Wiener process. Let $p(x,t)$ be the probability density function (PDF) of $X_t$. The evolution of $p(x,t)$ can be derived using the principle of conservation of probability and Itô's lemma.\n\nLet $f(x)$ be an arbitrary, twice-differentiable test function with compact support within the domain $(-L, L)$. The expectation of $f(X_t)$ is given by $\\mathbb{E}[f(X_t)] = \\int_{-L}^{L} f(x) p(x,t) dx$. Differentiating with respect to time gives:\n$$\n\\frac{d}{dt}\\mathbb{E}[f(X_t)] = \\int_{-L}^{L} f(x) \\frac{\\partial p(x,t)}{\\partial t} dx\n$$\nBy Itô's lemma, the differential of $f(X_t)$ is:\n$$\ndf(X_t) = f'(X_t) dX_t + \\frac{1}{2} f''(X_t) (dX_t)^2\n$$\nThe quadratic variation of the process is $(dX_t)^2 = (a(X_t)dt + b dW_t)^2 = b^2 (dW_t)^2 = b^2 dt$, as terms with $dt^2$ and $dt\\,dW_t$ are of lower order. Substituting $dX_t$ and $(dX_t)^2$ into the expression for $df(X_t)$:\n$$\ndf(X_t) = f'(X_t) [a(X_t)dt + b dW_t] + \\frac{1}{2} f''(X_t) b^2 dt = \\left[ a(X_t)f'(X_t) + \\frac{b^2}{2}f''(X_t) \\right] dt + b f'(X_t) dW_t\n$$\nTaking the expectation of the integral form $f(X_t) - f(X_0) = \\int_0^t df(X_s)$, and noting that the expectation of the Itô integral term (the stochastic part) is zero, we get:\n$$\n\\frac{d}{dt}\\mathbb{E}[f(X_t)] = \\mathbb{E}\\left[ a(X_t)f'(X_t) + \\frac{b^2}{2}f''(X_t) \\right] = \\int_{-L}^{L} \\left[ a(x)f'(x) + \\frac{b^2}{2}f''(x) \\right] p(x,t) dx\n$$\nEquating the two expressions for $\\frac{d}{dt}\\mathbb{E}[f(X_t)]$:\n$$\n\\int_{-L}^{L} f(x) \\frac{\\partial p}{\\partial t} dx = \\int_{-L}^{L} \\left[ a(x)f'(x) + \\frac{b^2}{2}f''(x) \\right] p(x,t) dx\n$$\nWe perform integration by parts on the right-hand side. For the first term:\n$$\n\\int_{-L}^{L} a(x)p(x,t) f'(x) dx = \\left[ a(x)p(x,t)f(x) \\right]_{-L}^{L} - \\int_{-L}^{L} \\frac{\\partial}{\\partial x}[a(x)p(x,t)] f(x) dx\n$$\nFor the second term, letting $D = b^2/2$, we integrate by parts twice:\n$$\n\\int_{-L}^{L} D p(x,t) f''(x) dx = \\left[ Dp(x,t)f'(x) \\right]_{-L}^{L} - \\left[ \\frac{\\partial}{\\partial x}(Dp(x,t))f(x) \\right]_{-L}^{L} + \\int_{-L}^{L} \\frac{\\partial^2}{\\partial x^2}[Dp(x,t)] f(x) dx\n$$\nSince the test function $f(x)$ has compact support in $(-L,L)$, $f(x)$ and its derivatives are zero at the boundaries $x=\\pm L$. All boundary terms from integration by parts vanish. The equation becomes:\n$$\n\\int_{-L}^{L} f(x) \\frac{\\partial p}{\\partial t} dx = \\int_{-L}^{L} f(x) \\left( -\\frac{\\partial}{\\partial x}[a(x)p] + \\frac{\\partial^2}{\\partial x^2}[Dp] \\right) dx\n$$\nAs this must hold for any arbitrary test function $f(x)$, the integrands must be equal. This gives the Fokker-Planck equation:\n$$\n\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x}[a(x)p(x,t)] + D\\frac{\\partial^2 p(x,t)}{\\partial x^2}\n$$\nThis equation can be expressed as a conservation law $\\frac{\\partial p}{\\partial t} + \\frac{\\partial J}{\\partial x} = 0$, where $J(x,t)$ is the probability flux:\n$$\nJ(x,t) = a(x)p(x,t) - D\\frac{\\partial p(x,t)}{\\partial x}\n$$\nReflecting boundaries at $x = \\pm L$ imply that no probability can flow across the boundaries. This corresponds to a zero-flux boundary condition:\n$$\nJ(-L, t) = 0 \\quad \\text{and} \\quad J(L, t) = 0\n$$\n\n### 2. Steady-State Solution\n\nAt steady state, the probability density is time-independent, so $\\frac{\\partial p}{\\partial t} = 0$. The Fokker-Planck equation reduces to $\\frac{\\partial J}{\\partial x} = 0$, which implies that the flux $J$ must be constant across the domain. The reflecting boundary conditions $J(\\pm L) = 0$ then force the flux to be zero everywhere: $J(x) = 0$ for all $x \\in [-L, L]$.\nFor the special case $a(x) = -U'(x)$ and constant diffusion $D=b^2/2$, the zero-flux condition on the steady-state density $p_{\\mathrm{eq}}(x)$ is:\n$$\n-U'(x)p_{\\mathrm{eq}}(x) - D \\frac{d p_{\\mathrm{eq}}(x)}{dx} = 0\n$$\nThis is a first-order linear ordinary differential equation that is separable:\n$$\n\\frac{d p_{\\mathrm{eq}}}{p_{\\mathrm{eq}}} = -\\frac{U'(x)}{D} dx\n$$\nIntegrating both sides yields $\\ln p_{\\mathrm{eq}}(x) = -U(x)/D + C_0$, where $C_0$ is an integration constant. Exponentiating gives the unnormalized steady-state solution:\n$$\np_{\\mathrm{eq}}(x) = C \\exp\\left(-\\frac{U(x)}{D}\\right)\n$$\nThe constant $C$ is determined by the normalization condition $\\int_{-L}^{L} p_{\\mathrm{eq}}(x) dx = 1$. This gives:\n$$\nC = \\frac{1}{\\int_{-L}^{L} \\exp\\left(-\\frac{U(y)}{D}\\right) dy}\n$$\nThe final normalized steady-state density is the Boltzmann-Gibbs distribution:\n$$\np_{\\mathrm{eq}}(x) = \\frac{\\exp\\left(-U(x)/D\\right)}{\\int_{-L}^{L} \\exp\\left(-U(y)/D\\right) dy}\n$$\n\n### 3. Spatial Discretization\n\nThe Fokker-Planck equation is discretized on a uniform grid of $N$ nodes $x_i = -L + i \\cdot h$ for $i=0, \\ldots, N-1$, with spacing $h=2L/(N-1)$. We use a conservative finite-volume approach where the time evolution of the probability $p_i(t) \\approx p(x_i, t)$ is governed by the fluxes at the interfaces between cells. The semi-discrete equation for node $i$ is:\n$$\n\\frac{d p_i}{dt} = \\frac{1}{h}(F_{i-1/2} - F_{i+1/2})\n$$\nwhere $F_{i+1/2}$ is the numerical flux at the interface $x_{i+1/2} = (x_i + x_{i+1})/2$. The total flux is $J=J_{\\text{adv}} + J_{\\text{diff}}$, where $J_{\\text{adv}} = a(x)p$ and $J_{\\text{diff}} = -D \\partial_x p$.\n\nThe numerical flux $F_{i+1/2}$ is constructed as follows:\n- The diffusive flux is approximated using a second-order centered difference: $F_{\\text{diff}, i+1/2} = -D \\frac{p_{i+1} - p_i}{h}$.\n- The advective flux is approximated using a first-order upwind scheme. The velocity at the interface is the arithmetic mean $a_{i+1/2} = (a(x_i) + a(x_{i+1}))/2$. The upwind flux is then $F_{\\text{adv}, i+1/2} = a_{i+1/2}^+ p_i + a_{i+1/2}^- p_{i+1}$, where $v^+ = \\max(v,0)$ and $v^- = \\min(v,0)$.\n\nThe total numerical flux is $F_{i+1/2} = (a_{i+1/2}^+ p_i + a_{i+1/2}^- p_{i+1}) - D \\frac{p_{i+1} - p_i}{h}$. Reflecting boundary conditions are enforced by setting the fluxes at the domain boundaries to zero. This implies $F_{-1/2} = 0$ (left of node $0$) and $F_{N-1/2} = 0$ (right of node $N-1$).\n\nThis leads to the linear system $\\frac{d\\mathbf{p}}{dt} = \\mathbf{L}\\mathbf{p}$, where $\\mathbf{p} = [p_0, \\dots, p_{N-1}]^T$ and $\\mathbf{L}$ is a tridiagonal matrix. The non-zero elements of $\\mathbf{L}$ are:\n\nFor an interior node $i \\in \\{1, \\dots, N-2\\}$:\n- $L_{i, i-1} = \\frac{D}{h^2} + \\frac{a_{i-1/2}^+}{h}$\n- $L_{i, i} = -\\frac{2D}{h^2} + \\frac{a_{i-1/2}^- - a_{i+1/2}^+}{h}$\n- $L_{i, i+1} = \\frac{D}{h^2} - \\frac{a_{i+1/2}^-}{h}$\n\nFor the left boundary node $i=0$:\n- $L_{0, 0} = -\\frac{D}{h^2} - \\frac{a_{1/2}^+}{h}$\n- $L_{0, 1} = \\frac{D}{h^2} - \\frac{a_{1/2}^-}{h}$\n\nFor the right boundary node $i=N-1$:\n- $L_{N-1, N-2} = \\frac{D}{h^2} + \\frac{a_{N-3/2}^+}{h}$\n- $L_{N-1, N-1} = -\\frac{D}{h^2} + \\frac{a_{N-3/2}^-}{h}$\n\n### 4. Numerical Simulation & Analysis\n\nTo solve the system $\\frac{d\\mathbf{p}}{dt} = \\mathbf{L}\\mathbf{p}$, we compare two first-order time-stepping methods:\n- **Explicit Forward Euler**: $\\mathbf{p}^{n+1} = (\\mathbf{I} + \\Delta t\\,\\mathbf{L})\\,\\mathbf{p}^n$. This method is simple but only conditionally stable. The maximum stable time step $\\Delta t_{\\max}$ is determined by the eigenvalues $\\lambda$ of $\\mathbf{L}$ through the condition $|1+\\Delta t \\lambda| \\le 1$. The problem specifies computing $\\Delta t_{\\max}$ as the minimum of $\\Delta t_{\\lambda} = -2\\lambda_r/(\\lambda_r^2+\\lambda_i^2)$ over all eigenvalues with negative real part $\\lambda_r < 0$. We use a safe step size $\\Delta t_{\\mathrm{exp}} = 0.9\\,\\Delta t_{\\max}$.\n- **Implicit Backward Euler**: $(\\mathbf{I} - \\Delta t\\,\\mathbf{L})\\,\\mathbf{p}^{n+1} = \\mathbf{p}^n$. This method is unconditionally stable, allowing for much larger time steps than the explicit method, which is particularly advantageous for stiff problems (where $\\Delta t_{\\max}$ is very small). At each step, a linear system must be solved.\n\nThe numerical experiment compares these two methods by evolving an initial Gaussian density to a final time $T$. The goal is to reach a numerical approximation of the steady-state solution $p_{\\mathrm{eq}}(x)$. We compute the ratio of the number of steps required by each method, $R_{\\mathrm{steps}} = n_{\\mathrm{exp}}/n_{\\mathrm{imp}}$, and the ratio of their final $L^1$ errors with respect to the true steady state, $R_{\\mathrm{err}} = E_{\\mathrm{imp}}/E_{\\mathrm{exp}}$. This analysis highlights the trade-off between computational cost (related to step count) and accuracy for explicit and implicit schemes. For stiff problems, we expect $R_{\\mathrm{steps}} \\gg 1$ and $R_{\\mathrm{err}} > 1$, showing that the implicit method is much faster but less accurate for a given large time step.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Fokker-Planck equation numerically for given test cases and\n    reports the comparison between explicit and implicit Euler methods.\n    \"\"\"\n    \n    # Define test cases from the problem statement\n    test_cases = [\n        # k, alpha, D, T\n        (50.0, 4.0, 0.05, 0.2),   # Test 1: Moderately stiff drift\n        (200.0, 2.0, 0.02, 0.1),  # Test 2: Highly stiff drift\n        (0.0, 0.0, 0.1, 0.1)     # Test 3: Diffusion-dominated\n    ]\n    \n    # Global parameters\n    L = 1.0\n    N = 121\n    m = 20.0\n    x0 = 0.5\n    sigma0 = 0.1\n    \n    # Grid setup\n    x = np.linspace(-L, L, N)\n    h = 2.0 * L / (N - 1)\n    \n    final_results = []\n    \n    for k, alpha, D, T in test_cases:\n        \n        # --- PART 6: Numerical Calculation for a Test Case ---\n\n        # Define potential U(x) and drift a(x)\n        U = lambda x_coords: (k / 4.0) * x_coords**4 + (alpha / 2.0) * x_coords**2\n        a_func = lambda x_coords: -(k * x_coords**3 + alpha * x_coords)\n        \n        # Compute and normalize the steady-state density p_eq(x)\n        p_eq_unnormalized = np.exp(-U(x) / D)\n        norm_const_eq = np.sum(p_eq_unnormalized) * h\n        p_eq = p_eq_unnormalized / norm_const_eq\n        \n        # Construct the generator matrix L\n        a_vals = a_func(x)\n        L_matrix = np.zeros((N, N))\n        \n        # Calculate velocities at cell interfaces\n        a_interface = 0.5 * (a_vals[:-1] + a_vals[1:])\n        a_plus = np.maximum(a_interface, 0)\n        a_minus = np.minimum(a_interface, 0)\n        \n        # Fill interior rows of L (i = 1 to N-2)\n        for i in range(1, N - 1):\n            L_matrix[i, i - 1] = D / h**2 + a_plus[i - 1] / h\n            L_matrix[i, i + 1] = D / h**2 - a_minus[i] / h\n            L_matrix[i, i] = -2 * D / h**2 + (a_minus[i - 1] - a_plus[i]) / h\n            \n        # Fill boundary row i=0 (left boundary)\n        L_matrix[0, 0] = -D / h**2 - a_plus[0] / h\n        L_matrix[0, 1] = D / h**2 - a_minus[0] / h\n        \n        # Fill boundary row i=N-1 (right boundary)\n        L_matrix[N - 1, N - 1] = -D / h**2 + a_minus[N - 2] / h\n        L_matrix[N - 1, N - 2] = D / h**2 + a_plus[N - 2] / h\n\n        # Compute maximal stable time step dt_max from eigenvalues of L\n        eigenvalues = np.linalg.eigvals(L_matrix)\n        \n        stable_dt_candidates = []\n        for lam in eigenvalues:\n            lr = lam.real\n            li = lam.imag\n            if lr < -1e-9:  # Filter for eigenvalues with negative real part\n                dt_lam = -2.0 * lr / (lr**2 + li**2)\n                stable_dt_candidates.append(dt_lam)\n        \n        dt_max = min(stable_dt_candidates) if stable_dt_candidates else float('inf')\n\n        # Define and normalize the initial density p(x,0)\n        p0_unnormalized = np.exp(-(x - x0)**2 / (2 * sigma0**2))\n        norm_const_0 = np.sum(p0_unnormalized) * h\n        p0 = p0_unnormalized / norm_const_0\n\n        # --- EXPLICIT FORWARD EULER ---\n        dt_exp = 0.9 * dt_max\n        n_exp = int(np.ceil(T / dt_exp))\n        dt_exp_actual = T / n_exp\n        \n        p_exp = np.copy(p0)\n        for _ in range(n_exp):\n            p_exp += dt_exp_actual * (L_matrix @ p_exp)\n            # Renormalize to conserve total probability\n            norm_c = np.sum(p_exp) * h\n            p_exp /= norm_c\n            \n        # --- IMPLICIT BACKWARD EULER ---\n        dt_imp = min(T, m * dt_max)\n        n_imp = int(np.ceil(T / dt_imp))\n        dt_imp_actual = T / n_imp\n        \n        p_imp = np.copy(p0)\n        # Pre-compute the matrix for the linear system in the implicit step\n        A_imp = np.identity(N) - dt_imp_actual * L_matrix\n        for _ in range(n_imp):\n            p_imp = np.linalg.solve(A_imp, p_imp)\n            # Renormalize to conserve total probability\n            norm_c = np.sum(p_imp) * h\n            p_imp /= norm_c\n            \n        # Compute grid L1 errors relative to p_eq\n        E_exp = np.sum(h * np.abs(p_exp - p_eq))\n        E_imp = np.sum(h * np.abs(p_imp - p_eq))\n        \n        # Compute final ratios\n        R_steps = n_exp / n_imp\n        if E_exp == 0:\n            R_err = 1.0 if E_imp == 0 else float('inf')\n        else:\n            R_err = E_imp / E_exp\n            \n        final_results.append((R_steps, R_err))\n        \n    # Format and print the final results in the specified single-line format\n    flat_list = [item for sublist in final_results for item in sublist]\n    print(f\"[{','.join(f'{x:.7f}' for x in flat_list)}]\")\n\nsolve()\n```", "id": "3048611"}]}