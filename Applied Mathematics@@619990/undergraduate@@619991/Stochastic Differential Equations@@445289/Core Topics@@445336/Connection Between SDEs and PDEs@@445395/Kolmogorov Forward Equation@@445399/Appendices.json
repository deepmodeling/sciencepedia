{"hands_on_practices": [{"introduction": "The Ornstein-Uhlenbeck process is a cornerstone of stochastic modeling, describing systems that return to a stable equilibrium, such as a particle in a harmonic potential subject to thermal fluctuations. This practice provides an opportunity to solve the associated Kolmogorov forward equation analytically using the powerful method of Fourier transforms. By working through this problem [@problem_id:3063158], you will derive the exact probability distribution and see precisely how the drift and diffusion terms govern the evolution of the system's mean and variance.", "problem": "Consider the Ornstein–Uhlenbeck (OU) process defined by the Itô stochastic differential equation $dX_{t} = -\\gamma X_{t}\\,dt + \\sqrt{2D}\\,dW_{t}$ with constants $\\gamma  0$ and $D  0$, where $W_{t}$ is a standard Wiener process and the initial condition is $X_{0} = x_{0}$. Let $p(x,t)$ denote the transition probability density of $X_{t}$, so that $p(x,t)\\,dx = \\mathbb{P}\\{X_{t} \\in dx\\}$, and define the characteristic function (equivalently, the spatial Fourier transform of $p$) by $\\hat{p}(k,t) = \\int_{-\\infty}^{\\infty} \\exp(i k x)\\,p(x,t)\\,dx$.\n\nStarting from the Itô stochastic differential equation and using the definition of the infinitesimal generator and conservation of probability, derive the Kolmogorov forward (Fokker–Planck) equation satisfied by $p(x,t)$. Then, apply the spatial Fourier transform to this partial differential equation to obtain an evolution equation for $\\hat{p}(k,t)$ and solve it using the method of characteristics under the initial condition $p(x,0) = \\delta(x - x_{0})$, where $\\delta$ is the Dirac delta distribution. Interpret how the drift and diffusion terms govern the evolution of the characteristic function in wave number space.\n\nYour final task is to provide a single, closed-form analytical expression for the characteristic function $\\hat{p}(k,t)$ at arbitrary $t \\geq 0$. No numerical approximation is required, and no units are involved in the final expression.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the theory of stochastic differential equations, specifically concerning the Ornstein–Uhlenbeck process and its associated Kolmogorov forward (Fokker–Planck) equation. The problem is well-posed, with a clear objective and sufficient initial conditions to determine a unique solution. The terminology is precise and the requested steps form a standard, logical procedure in this field.\n\nThe problem asks for several steps: first, to derive the Fokker–Planck equation; second, to Fourier transform it; third, to solve the resulting equation for the characteristic function $\\hat{p}(k,t)$; and finally, to interpret the roles of the drift and diffusion terms.\n\n**1. Derivation of the Fokker–Planck Equation**\n\nThe Ornstein–Uhlenbeck process is described by the Itô stochastic differential equation (SDE):\n$$dX_{t} = -\\gamma X_{t}\\,dt + \\sqrt{2D}\\,dW_{t}$$\nThis SDE is of the general form $dX_{t} = a(X_{t},t)\\,dt + b(X_{t},t)\\,dW_{t}$, with a drift coefficient $a(x) = -\\gamma x$ and a diffusion coefficient $b(x) = \\sqrt{2D}$. The evolution of the probability density function $p(x,t)$ of the process $X_t$ is governed by the Kolmogorov forward equation, also known as the Fokker–Planck equation.\n\nA general derivation starts from the conservation of probability, expressed as a continuity equation:\n$$\\frac{\\partial p(x,t)}{\\partial t} + \\frac{\\partial J(x,t)}{\\partial x} = 0$$\nwhere $J(x,t)$ is the probability current. For a stochastic process described by the SDE above, the current is given by:\n$$J(x,t) = A_{1}(x) p(x,t) - \\frac{1}{2} \\frac{\\partial}{\\partial x} [A_{2}(x) p(x,t)]$$\nThe coefficients $A_{1}(x)$ and $A_{2}(x)$ are the first and second Kramers–Moyal coefficients, defined as the infinitesimal mean and variance of the process increments:\n$$A_{1}(x) = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} \\mathbb{E}[\\Delta X_{t} | X_{t}=x]$$\n$$A_{2}(x) = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} \\mathbb{E}[(\\Delta X_{t})^{2} | X_{t}=x]$$\nwhere $\\Delta X_{t} = X_{t+\\Delta t} - X_{t}$. From the SDE, for a small time step $\\Delta t$, the increment is $\\Delta X_t \\approx -\\gamma x \\Delta t + \\sqrt{2D} \\Delta W_t$, where $\\Delta W_t = W_{t+\\Delta t} - W_t$. The increments of the Wiener process have properties $\\mathbb{E}[\\Delta W_{t}] = 0$ and $\\mathbb{E}[(\\Delta W_{t})^{2}] = \\Delta t$.\n\nCalculating $A_{1}(x)$:\n$$A_{1}(x) = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} \\mathbb{E}[-\\gamma x \\Delta t + \\sqrt{2D} \\Delta W_{t}] = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} (-\\gamma x \\Delta t) = -\\gamma x$$\nCalculating $A_{2}(x)$:\n$$A_{2}(x) = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} \\mathbb{E}[(-\\gamma x \\Delta t + \\sqrt{2D} \\Delta W_{t})^{2}]$$\n$$A_{2}(x) = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} \\mathbb{E}[(\\gamma x)^{2}(\\Delta t)^{2} - 2\\gamma x \\sqrt{2D} \\Delta t \\Delta W_{t} + 2D (\\Delta W_{t})^{2}]$$\nUsing linearity of expectation and neglecting terms of order higher than $\\Delta t$:\n$$A_{2}(x) = \\lim_{\\Delta t \\to 0} \\frac{1}{\\Delta t} [(\\gamma x)^{2}(\\Delta t)^{2} - 0 + 2D \\Delta t] = \\lim_{\\Delta t \\to 0} [(\\gamma x)^{2}\\Delta t + 2D] = 2D$$\nSo, the drift coefficient is $a(x) = A_{1}(x) = -\\gamma x$ and the diffusion term is $b(x)^2 = A_2(x) = 2D$.\n\nSubstituting these coefficients back into the expression for the current $J(x,t)$:\n$$J(x,t) = (-\\gamma x) p(x,t) - \\frac{1}{2} \\frac{\\partial}{\\partial x} [2D p(x,t)] = -\\gamma x p(x,t) - D \\frac{\\partial p(x,t)}{\\partial x}$$\nThe Fokker–Planck equation is then $\\frac{\\partial p}{\\partial t} = -\\frac{\\partial J}{\\partial x}$:\n$$\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x} \\left(-\\gamma x p(x,t) - D \\frac{\\partial p(x,t)}{\\partial x}\\right)$$\n$$\\frac{\\partial p(x,t)}{\\partial t} = \\gamma \\frac{\\partial}{\\partial x}[x p(x,t)] + D \\frac{\\partial^{2}p(x,t)}{\\partial x^{2}}$$\nThis is the required Fokker–Planck equation for the Ornstein–Uhlenbeck process.\n\n**2. Fourier Transform of the Fokker–Planck Equation**\n\nThe characteristic function $\\hat{p}(k,t)$ is the spatial Fourier transform of $p(x,t)$, defined as:\n$$\\hat{p}(k,t) = \\mathcal{F}[p(x,t)] = \\int_{-\\infty}^{\\infty} \\exp(ikx) p(x,t) dx$$\nWe apply this transform to the Fokker–Planck equation. The necessary transform properties for the given definition are:\n$$\\mathcal{F}\\left[\\frac{\\partial^{n} f}{\\partial x^{n}}\\right] = (-ik)^{n} \\hat{f}(k)$$\n$$\\mathcal{F}[x f(x)] = i \\frac{d\\hat{f}(k)}{dk}$$\nUsing these, we can find the transform of the term $\\frac{\\partial}{\\partial x}[x p(x,t)]$:\n$$\\mathcal{F}\\left[\\frac{\\partial}{\\partial x}(x p)\\right] = (-ik)\\mathcal{F}[x p] = (-ik)\\left(i \\frac{\\partial \\hat{p}}{\\partial k}\\right) = k \\frac{\\partial \\hat{p}}{\\partial k}$$\nThere is a subtle point about the transform convention. The problem states $\\exp(ikx)$. Let's verify the rule for $\\mathcal{F}[xf(x)]$.\n$\\frac{d\\hat{p}}{dk} = \\frac{d}{dk}\\int \\exp(ikx)p(x,t)dx = \\int ix \\exp(ikx)p(x,t) dx = i\\mathcal{F}[xp]$. So $\\mathcal{F}[xp] = \\frac{1}{i}\\frac{d\\hat{p}}{dk} = -i\\frac{d\\hat{p}}{dk}$.\nThen, $\\mathcal{F}\\left[\\frac{\\partial}{\\partial x}(x p)\\right] = (-ik)\\mathcal{F}[x p] = (-ik)\\left(-i \\frac{\\partial \\hat{p}}{\\partial k}\\right) = -k \\frac{\\partial \\hat{p}}{\\partial k}$.\n\nTransforming the Fokker–Planck equation term by term:\n$$\\mathcal{F}\\left[\\frac{\\partial p}{\\partial t}\\right] = \\frac{\\partial \\hat{p}}{\\partial t}$$\n$$\\mathcal{F}\\left[\\gamma \\frac{\\partial}{\\partial x}(x p)\\right] = \\gamma \\left(-k \\frac{\\partial \\hat{p}}{\\partial k}\\right)$$\n$$\\mathcal{F}\\left[D \\frac{\\partial^{2}p}{\\partial x^{2}}\\right] = D(-ik)^{2}\\hat{p} = -Dk^{2}\\hat{p}$$\nCombining these results yields the evolution equation for the characteristic function:\n$$\\frac{\\partial \\hat{p}(k,t)}{\\partial t} = -\\gamma k \\frac{\\partial \\hat{p}(k,t)}{\\partial k} - Dk^{2}\\hat{p}(k,t)$$\n\n**3. Solution for the Characteristic Function**\n\nWe solve this first-order linear partial differential equation using the method of characteristics. The equation is:\n$$\\frac{\\partial \\hat{p}}{\\partial t} + \\gamma k \\frac{\\partial \\hat{p}}{\\partial k} = -Dk^{2}\\hat{p}$$\nThe characteristic equations are:\n$$\\frac{dt}{1} = \\frac{dk}{\\gamma k} = \\frac{d\\hat{p}}{-Dk^{2}\\hat{p}}$$\nFrom the first equality, $\\frac{dk}{dt} = \\gamma k$. Integrating gives the characteristic curves $k(t) = k_{0} \\exp(\\gamma t)$, where $k_{0}$ is the value of $k$ at $t=0$.\nAlong these curves, the evolution of $\\hat{p}$ is given by $\\frac{d\\hat{p}}{dt} = -Dk^{2}\\hat{p}$. Substituting $k(t)$:\n$$\\frac{d\\hat{p}}{dt} = -D(k_{0}\\exp(\\gamma t))^{2}\\hat{p} = -Dk_{0}^{2}\\exp(2\\gamma t)\\hat{p}$$\nThis is a separable ordinary differential equation for $\\hat{p}(t) = \\hat{p}(k(t),t)$:\n$$\\int_{\\hat{p}(k_0,0)}^{\\hat{p}(k(t),t)} \\frac{d\\hat{p}'}{\\hat{p}'} = \\int_{0}^{t} -Dk_{0}^{2}\\exp(2\\gamma \\tau) d\\tau$$\n$$\\ln\\left(\\frac{\\hat{p}(k(t),t)}{\\hat{p}(k_{0},0)}\\right) = -Dk_{0}^{2} \\left[\\frac{\\exp(2\\gamma \\tau)}{2\\gamma}\\right]_{0}^{t} = -\\frac{Dk_{0}^{2}}{2\\gamma}(\\exp(2\\gamma t)-1)$$\n$$\\hat{p}(k(t),t) = \\hat{p}(k_{0},0) \\exp\\left(-\\frac{Dk_{0}^{2}}{2\\gamma}(\\exp(2\\gamma t)-1)\\right)$$\nTo get the solution in terms of $(k,t)$, we express $k_0$ in terms of $k$ and $t$ using the characteristic curve equation: $k_{0} = k \\exp(-\\gamma t)$.\nSubstituting this into the solution gives:\n$$\\hat{p}(k,t) = \\hat{p}(k\\exp(-\\gamma t),0) \\exp\\left(-\\frac{D(k\\exp(-\\gamma t))^{2}}{2\\gamma}(\\exp(2\\gamma t)-1)\\right)$$\nSimplifying the argument of the exponential:\n$$-\\frac{Dk^{2}\\exp(-2\\gamma t)}{2\\gamma}(\\exp(2\\gamma t)-1) = -\\frac{Dk^{2}}{2\\gamma}(\\exp(0) - \\exp(-2\\gamma t)) = -\\frac{Dk^{2}}{2\\gamma}(1 - \\exp(-2\\gamma t))$$\nSo, the general solution is:\n$$\\hat{p}(k,t) = \\hat{p}(k\\exp(-\\gamma t), 0) \\exp\\left(-\\frac{Dk^{2}}{2\\gamma}(1 - \\exp(-2\\gamma t))\\right)$$\nThe initial condition is $p(x,0) = \\delta(x - x_{0})$. Its Fourier transform is:\n$$\\hat{p}(k,0) = \\int_{-\\infty}^{\\infty} \\exp(ikx) \\delta(x - x_{0}) dx = \\exp(ikx_{0})$$\nWe need $\\hat{p}(k',0)$ where $k' = k\\exp(-\\gamma t)$:\n$$\\hat{p}(k\\exp(-\\gamma t), 0) = \\exp(i(k\\exp(-\\gamma t))x_{0}) = \\exp(ikx_{0}\\exp(-\\gamma t))$$\nSubstituting this into the general solution gives the final expression for the characteristic function:\n$$\\hat{p}(k,t) = \\exp(ikx_{0}\\exp(-\\gamma t)) \\exp\\left(-\\frac{Dk^{2}}{2\\gamma}(1 - \\exp(-2\\gamma t))\\right)$$\nThis can be written as a single exponential:\n$$\\hat{p}(k,t) = \\exp\\left(ikx_{0}\\exp(-\\gamma t) - \\frac{Dk^{2}}{2\\gamma}(1 - \\exp(-2\\gamma t))\\right)$$\n\n**4. Interpretation**\n\nThe characteristic function of a Gaussian distribution with mean $\\mu$ and variance $\\sigma^{2}$ is $\\exp(ik\\mu - \\frac{1}{2}k^{2}\\sigma^{2})$. By comparing our result for $\\hat{p}(k,t)$ with this canonical form, we can identify the time-dependent mean and variance of the Ornstein-Uhlenbeck process:\n$$\\mu(t) = x_{0}\\exp(-\\gamma t)$$\n$$\\sigma^{2}(t) = \\frac{D}{\\gamma}(1 - \\exp(-2\\gamma t))$$\nThe evolution equation $\\frac{\\partial \\hat{p}}{\\partial t} = -\\gamma k \\frac{\\partial \\hat{p}}{\\partial k} - Dk^{2}\\hat{p}$ reveals the roles of drift and diffusion in Fourier (wave number) space.\n- The **drift term** in the SDE, $-\\gamma X_t dt$, gives rise to the term $-\\gamma k \\frac{\\partial \\hat{p}}{\\partial k}$ in the evolution equation. This is an advection term in $k$-space, causing a \"flow\" of wave numbers. It primarily affects the phase of $\\hat{p}(k,t)$, which corresponds to the mean of $p(x,t)$. The solution shows the mean $\\mu(t)$ decays exponentially to $0$ with a rate $\\gamma$, representing the particle being pulled towards the origin.\n- The **diffusion term** in the SDE, $\\sqrt{2D} dW_t$, gives rise to the term $-Dk^{2}\\hat{p}$. This is a damping term in $k$-space that is stronger for larger $|k|$ (higher frequencies). This damping corresponds to the smoothing of the probability distribution $p(x,t)$ in real space, i.e., its diffusive spreading. This term governs the magnitude $|\\hat{p}(k,t)|$, which is determined by the variance $\\sigma^2(t)$. The variance grows from $0$ and asymptotically approaches the steady-state value $D/\\gamma$, representing a balance between diffusive spreading and the confining drift.", "answer": "$$\\boxed{\\exp\\left(ikx_{0}\\exp(-\\gamma t) - \\frac{Dk^{2}}{2\\gamma}\\left(1 - \\exp(-2\\gamma t)\\right)\\right)}$$", "id": "3063158"}, {"introduction": "While many systems relax to an equilibrium state with no net flows, others settle into non-equilibrium steady states characterized by persistent currents. This exercise [@problem_id:3063143] explores such a system, where a non-conservative force drives circulating probability currents even in the stationary state. This practice offers a fascinating window into the physics of systems that violate detailed balance and equips you with the skills to analyze more complex, realistic stochastic dynamics.", "problem": "Consider the two-dimensional stochastic differential equation (SDE)\n$$\nd\\mathbf{X}_t=\\left(-k\\,\\mathbf{X}_t+\\Omega\\,R\\,\\mathbf{X}_t\\right)dt+\\sqrt{2D}\\,d\\mathbf{W}_t,\n$$\nwhere $\\mathbf{X}_t\\in\\mathbb{R}^2$, $k0$ and $D0$ are constants, $\\Omega\\in\\mathbb{R}$, $\\mathbf{W}_t$ is a standard two-dimensional Wiener process, and $R$ is the constant antisymmetric matrix\n$$\nR=\\begin{pmatrix}\n0  -1\\\\\n1  \\phantom{-}0\n\\end{pmatrix}.\n$$\nThe drift field is $\\mathbf{a}(\\mathbf{x})=-k\\,\\mathbf{x}+\\Omega\\,R\\,\\mathbf{x}$ and the diffusion is isotropic with coefficient $D$.\n\nStarting from the Kolmogorov forward equation (also known as the Fokker–Planck equation) for the probability density $p(\\mathbf{x},t)$ associated with the SDE above, do the following:\n\n1. Derive the stationary (time-independent) density $p_{\\infty}(\\mathbf{x})$ and determine its covariance matrix. You may assume the stationary density, if it exists, is centered at the origin and is normalizable.\n\n2. State the condition for detailed balance in terms of the stationary probability current $\\mathbf{J}_{\\infty}(\\mathbf{x})$ and explain, based on the form of $\\mathbf{a}(\\mathbf{x})$, why detailed balance holds when $\\Omega=0$ and is violated when $\\Omega\\neq 0$.\n\n3. Compute the stationary probability current $\\mathbf{J}_{\\infty}(\\mathbf{x})$ and show that its streamlines are circles centered at the origin when $\\Omega\\neq 0$.\n\n4. Define the scalar measure of circulating probability current\n$$\nJ_{\\infty}:=\\int_{\\mathbb{R}^2}\\left(x_1\\,J_{\\infty,y}(\\mathbf{x})-x_2\\,J_{\\infty,x}(\\mathbf{x})\\right)\\,d^2\\mathbf{x},\n$$\nwhere $J_{\\infty,x}$ and $J_{\\infty,y}$ are the Cartesian components of $\\mathbf{J}_{\\infty}(\\mathbf{x})$ and $d^2\\mathbf{x}$ denotes the Lebesgue measure on $\\mathbb{R}^2$. Compute $J_{\\infty}$ in closed form as a function of $k$, $\\Omega$, and $D$.\n\nExpress your final answer as a single analytic expression. No rounding is required.", "solution": "The user wants me to analyze a two-dimensional stochastic differential equation (SDE), derive properties of its stationary state from the corresponding Kolmogorov forward (Fokker-Planck) equation, and compute a measure of the stationary probability current.\n\nThe SDE is given by:\n$$\nd\\mathbf{X}_t=\\left(-k\\,\\mathbf{X}_t+\\Omega\\,R\\,\\mathbf{X}_t\\right)dt+\\sqrt{2D}\\,d\\mathbf{W}_t\n$$\nThis is a linear SDE of the form $d\\mathbf{X}_t = A\\mathbf{X}_t dt + B d\\mathbf{W}_t$, where the state is $\\mathbf{X}_t = (x_1, x_2)^T \\in \\mathbb{R}^2$, the drift matrix is $A = -kI + \\Omega R$, and the diffusion matrix is specified by $B = \\sqrt{2D}I$. The matrix $R = \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix}$ effects a counter-clockwise rotation by $\\pi/2$. Explicitly, the drift matrix is:\n$$\nA = \\begin{pmatrix} -k  -\\Omega \\\\ \\Omega  -k \\end{pmatrix}\n$$\nThe diffusion tensor for the Fokker-Planck equation is given by $D_{ij} = \\frac{1}{2}(BB^T)_{ij}$, which in this case is $D \\delta_{ij}$. The diffusion is isotropic with coefficient $D$.\n\nThe Kolmogorov forward equation (Fokker-Planck equation) for the probability density $p(\\mathbf{x}, t)$ is:\n$$\n\\frac{\\partial p(\\mathbf{x}, t)}{\\partial t} = -\\nabla \\cdot \\mathbf{J}(\\mathbf{x}, t)\n$$\nwhere $\\mathbf{J}(\\mathbf{x}, t)$ is the probability current, defined as:\n$$\n\\mathbf{J}(\\mathbf{x}, t) = \\mathbf{a}(\\mathbf{x})p(\\mathbf{x}, t) - D\\nabla p(\\mathbf{x}, t)\n$$\nand $\\mathbf{a}(\\mathbf{x}) = A\\mathbf{x}$ is the drift field.\n\n**1. Stationary Density and Covariance Matrix**\n\nThe stationary density $p_{\\infty}(\\mathbf{x})$ is the time-independent solution to the Fokker-Planck equation, which satisfies $\\frac{\\partial p}{\\partial t} = 0$. This implies that the stationary probability current $\\mathbf{J}_{\\infty}(\\mathbf{x})$ must have zero divergence:\n$$\n\\nabla \\cdot \\mathbf{J}_{\\infty}(\\mathbf{x}) = \\nabla \\cdot (\\mathbf{a}(\\mathbf{x}) p_{\\infty}(\\mathbf{x}) - D \\nabla p_{\\infty}(\\mathbf{x})) = 0\n$$\nFor a linear SDE with constant diffusion, the stationary distribution (if it exists) is a multivariate Gaussian. The problem statement assumes it is centered at the origin, which is consistent with the drift being zero only at $\\mathbf{x}=\\mathbf{0}$. We can find its covariance matrix $C = \\langle \\mathbf{X}_t \\mathbf{X}_t^T \\rangle_{\\infty}$ by solving the continuous-time Lyapunov equation:\n$$\nAC + CA^T + 2D I = 0\n$$\nHere, $A = \\begin{pmatrix} -k  -\\Omega \\\\ \\Omega  -k \\end{pmatrix}$, $A^T = \\begin{pmatrix} -k  \\Omega \\\\ -\\Omega  -k \\end{pmatrix}$, and $I$ is the $2 \\times 2$ identity matrix. Let $C = \\begin{pmatrix} c_{11}  c_{12} \\\\ c_{21}  c_{22} \\end{pmatrix}$ be the symmetric covariance matrix ($c_{12}=c_{21}$).\n\nThe Lyapunov equation expands to:\n$$\n\\begin{pmatrix} -k  -\\Omega \\\\ \\Omega  -k \\end{pmatrix}\\begin{pmatrix} c_{11}  c_{12} \\\\ c_{12}  c_{22} \\end{pmatrix} + \\begin{pmatrix} c_{11}  c_{12} \\\\ c_{12}  c_{22} \\end{pmatrix}\\begin{pmatrix} -k  \\Omega \\\\ -\\Omega  -k \\end{pmatrix} + \\begin{pmatrix} 2D  0 \\\\ 0  2D \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\nPerforming the matrix multiplications yields a system of linear equations for the components of $C$:\n$$\n\\begin{pmatrix} -2kc_{11}-2\\Omega c_{12}  -kc_{12}-\\Omega c_{22} -kc_{12}+\\Omega c_{11} \\\\ \\Omega c_{11}-k c_{12} -kc_{12}-\\Omega c_{22}  2\\Omega c_{12}-2k c_{22} \\end{pmatrix} + \\begin{pmatrix} 2D  0 \\\\ 0  2D \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}\n$$\nThis gives the equations:\n1.  $-2kc_{11} - 2\\Omega c_{12} + 2D = 0 \\implies -kc_{11} - \\Omega c_{12} + D = 0$\n2.  $-2kc_{22} + 2\\Omega c_{12} + 2D = 0 \\implies -kc_{22} + \\Omega c_{12} + D = 0$\n3.  $\\Omega(c_{11}-c_{22}) - 2k c_{12} = 0$\n\nFrom (1) and (2), we express $c_{11}$ and $c_{22}$:\n$c_{11} = \\frac{D-\\Omega c_{12}}{k}$ and $c_{22} = \\frac{D+\\Omega c_{12}}{k}$.\nSubstituting these into (3):\n$$\n\\Omega\\left(\\frac{D-\\Omega c_{12}}{k} - \\frac{D+\\Omega c_{12}}{k}\\right) - 2k c_{12} = 0\n$$\n$$\n\\Omega\\left(-\\frac{2\\Omega c_{12}}{k}\\right) - 2k c_{12} = 0\n$$\n$$\n-2\\left(\\frac{\\Omega^2}{k} + k\\right)c_{12} = -2\\left(\\frac{\\Omega^2+k^2}{k}\\right)c_{12} = 0\n$$\nSince $k0$, the term $\\frac{\\Omega^2+k^2}{k}$ is strictly positive. Therefore, we must have $c_{12} = 0$.\nWith $c_{12}=0$, we find $c_{11}=D/k$ and $c_{22}=D/k$.\nThe covariance matrix is diagonal and isotropic:\n$$\nC = \\begin{pmatrix} D/k  0 \\\\ 0  D/k \\end{pmatrix} = \\frac{D}{k}I\n$$\nThe stationary probability density $p_{\\infty}(\\mathbf{x})$ is a zero-mean Gaussian with this covariance. The inverse covariance is $C^{-1} = \\frac{k}{D}I$.\n$$\np_{\\infty}(\\mathbf{x}) = \\frac{1}{\\sqrt{(2\\pi)^2 \\det(C)}} \\exp\\left(-\\frac{1}{2}\\mathbf{x}^T C^{-1} \\mathbf{x}\\right) = \\frac{1}{2\\pi (D/k)} \\exp\\left(-\\frac{k}{2D}\\mathbf{x}^T\\mathbf{x}\\right)\n$$\n$$\np_{\\infty}(\\mathbf{x}) = \\frac{k}{2\\pi D} \\exp\\left(-\\frac{k(x_1^2+x_2^2)}{2D}\\right)\n$$\n\n**2. Detailed Balance**\n\nDetailed balance is a condition on a stationary system where, for every pair of states, the rate of transitioning from state A to B is equal to the rate of transitioning from B to A. In the context of continuous stochastic processes described by a Fokker-Planck equation, detailed balance holds if the stationary probability current $\\mathbf{J}_{\\infty}(\\mathbf{x})$ is identically zero for all $\\mathbf{x}$.\n$$\n\\mathbf{J}_{\\infty}(\\mathbf{x}) = \\mathbf{0}\n$$\nLet us compute $\\mathbf{J}_{\\infty}(\\mathbf{x})$. First, we compute the gradient of $p_{\\infty}(\\mathbf{x})$:\n$$\n\\nabla p_{\\infty}(\\mathbf{x}) = \\nabla \\left( \\frac{k}{2\\pi D} \\exp\\left(-\\frac{k|\\mathbf{x}|^2}{2D}\\right) \\right) = p_{\\infty}(\\mathbf{x}) \\left(-\\frac{k}{2D} \\nabla(|\\mathbf{x}|^2)\\right) = p_{\\infty}(\\mathbf{x}) \\left(-\\frac{k}{D} \\mathbf{x}\\right)\n$$\nThe stationary current is:\n$$\n\\mathbf{J}_{\\infty}(\\mathbf{x}) = \\mathbf{a}(\\mathbf{x})p_{\\infty}(\\mathbf{x}) - D\\nabla p_{\\infty}(\\mathbf{x}) = \\mathbf{a}(\\mathbf{x})p_{\\infty}(\\mathbf{x}) - D\\left(-\\frac{k}{D}\\mathbf{x}\\, p_{\\infty}(\\mathbf{x})\\right)\n$$\n$$\n\\mathbf{J}_{\\infty}(\\mathbf{x}) = (\\mathbf{a}(\\mathbf{x}) + k\\mathbf{x}) p_{\\infty}(\\mathbf{x})\n$$\nSubstituting $\\mathbf{a}(\\mathbf{x}) = -k\\mathbf{x} + \\Omega R \\mathbf{x}$:\n$$\n\\mathbf{J}_{\\infty}(\\mathbf{x}) = (-k\\mathbf{x} + \\Omega R \\mathbf{x} + k\\mathbf{x}) p_{\\infty}(\\mathbf{x}) = \\Omega R \\mathbf{x}\\,p_{\\infty}(\\mathbf{x})\n$$\n-   When $\\Omega=0$, $\\mathbf{J}_{\\infty}(\\mathbf{x}) = 0$ for all $\\mathbf{x}$. Thus, the system satisfies detailed balance. This is because the drift field $\\mathbf{a}(\\mathbf{x})=-k\\mathbf{x}$ is a gradient field, $\\mathbf{a}(\\mathbf{x}) = -\\nabla U(\\mathbf{x})$ with potential $U(\\mathbf{x})=\\frac{1}{2}k|\\mathbf{x}|^2$. Systems with gradient drift and constant isotropic diffusion satisfy detailed balance.\n-   When $\\Omega \\neq 0$, $\\mathbf{J}_{\\infty}(\\mathbf{x}) = \\Omega R \\mathbf{x}\\,p_{\\infty}(\\mathbf{x})$. Since $R\\mathbf{x} = (-x_2, x_1)^T \\neq \\mathbf{0}$ for $\\mathbf{x}\\neq\\mathbf{0}$ and $p_{\\infty}(\\mathbf{x})0$ everywhere, the current $\\mathbf{J}_{\\infty}(\\mathbf{x})$ is non-zero (except at the origin). Thus, detailed balance is violated. The part of the drift $\\Omega R \\mathbf{x}$ is non-conservative (has non-zero curl), which drives persistent probability currents in the stationary state.\n\n**3. Stationary Current Streamlines**\n\nThe stationary probability current for $\\Omega \\neq 0$ is:\n$$\n\\mathbf{J}_{\\infty}(\\mathbf{x}) = \\Omega R \\mathbf{x}\\,p_{\\infty}(\\mathbf{x}) = \\Omega \\begin{pmatrix} -x_2 \\\\ x_1 \\end{pmatrix} \\frac{k}{2\\pi D} \\exp\\left(-\\frac{k(x_1^2+x_2^2)}{2D}\\right)\n$$\nA streamline is a curve $\\mathbf{r}(s)=(x_1(s), x_2(s))^T$ that is everywhere tangent to the vector field $\\mathbf{J}_{\\infty}(\\mathbf{x})$. The direction of the current at $\\mathbf{x}$ is given by the vector $R\\mathbf{x} = (-x_2, x_1)^T$. Let's examine the relationship between the position vector $\\mathbf{x}=(x_1, x_2)^T$ and the current direction. Their dot product is:\n$$\n\\mathbf{x} \\cdot (R\\mathbf{x}) = (x_1, x_2) \\cdot (-x_2, x_1) = -x_1 x_2 + x_2 x_1 = 0\n$$\nSince the current vector is always orthogonal to the position vector, the streamlines must be curves along which the distance from the origin is constant. These are circles centered at the origin.\nMore formally, a streamline $\\mathbf{r}(s)$ satisfies $\\frac{d\\mathbf{r}}{ds} \\propto \\mathbf{J}_\\infty(\\mathbf{r}(s))$, which means $\\frac{d\\mathbf{r}}{ds}$ is parallel to $R\\mathbf{r}(s)$.\nConsider the squared radius $|\\mathbf{r}(s)|^2 = x_1^2(s)+x_2^2(s)$:\n$$\n\\frac{d}{ds}|\\mathbf{r}(s)|^2 = 2\\mathbf{r}(s) \\cdot \\frac{d\\mathbf{r}}{ds}\n$$\nSince $\\frac{d\\mathbf{r}}{ds}$ is parallel to $R\\mathbf{r}(s)$, and we showed $\\mathbf{r}(s) \\cdot (R\\mathbf{r}(s)) = 0$, it follows that $\\frac{d}{ds}|\\mathbf{r}(s)|^2 = 0$. This implies $|\\mathbf{r}(s)|^2$ is constant along any streamline. The streamlines are therefore circles $x_1^2+x_2^2=\\text{constant}$ centered at the origin.\n\n**4. Computation of the Scalar Current Measure $J_{\\infty}$**\n\nThe scalar measure is defined as:\n$$\nJ_{\\infty} := \\int_{\\mathbb{R}^2}\\left(x_1\\,J_{\\infty,y}(\\mathbf{x})-x_2\\,J_{\\infty,x}(\\mathbf{x})\\right)\\,d^2\\mathbf{x}\n$$\nThe components of the current are $J_{\\infty,x}(\\mathbf{x}) = -\\Omega x_2 p_{\\infty}(\\mathbf{x})$ and $J_{\\infty,y}(\\mathbf{x}) = \\Omega x_1 p_{\\infty}(\\mathbf{x})$. Substituting these into the integrand:\n$$\nx_1(\\Omega x_1 p_{\\infty}(\\mathbf{x})) - x_2(-\\Omega x_2 p_{\\infty}(\\mathbf{x})) = \\Omega x_1^2 p_{\\infty}(\\mathbf{x}) + \\Omega x_2^2 p_{\\infty}(\\mathbf{x}) = \\Omega(x_1^2+x_2^2)p_{\\infty}(\\mathbf{x})\n$$\nSo the integral becomes:\n$$\nJ_{\\infty} = \\int_{\\mathbb{R}^2} \\Omega(x_1^2+x_2^2) p_{\\infty}(\\mathbf{x})\\, d^2\\mathbf{x} = \\Omega \\int_{\\mathbb{R}^2} |\\mathbf{x}|^2 p_{\\infty}(\\mathbf{x})\\, d^2\\mathbf{x}\n$$\nThe integral $\\int_{\\mathbb{R}^2} |\\mathbf{x}|^2 p_{\\infty}(\\mathbf{x})\\, d^2\\mathbf{x}$ is the expectation of the squared norm $|\\mathbf{X}|^2$ in the stationary state, $\\mathbb{E}[|\\mathbf{X}|^2]$. This is equal to the trace of the covariance matrix $C$.\n$$\n\\mathbb{E}[|\\mathbf{X}|^2] = \\mathbb{E}[X_1^2 + X_2^2] = \\mathbb{E}[X_1^2] + \\mathbb{E}[X_2^2] = c_{11} + c_{22} = \\mathrm{Tr}(C)\n$$\nFrom Part 1, we found $C = \\frac{D}{k}I$, so $\\mathrm{Tr}(C) = \\frac{D}{k} + \\frac{D}{k} = \\frac{2D}{k}$.\nTherefore, the scalar measure of the current is:\n$$\nJ_{\\infty} = \\Omega \\cdot \\mathrm{Tr}(C) = \\Omega \\left(\\frac{2D}{k}\\right) = \\frac{2\\Omega D}{k}\n$$\nThis expression provides the final answer.", "answer": "$$\\boxed{\\frac{2\\Omega D}{k}}$$", "id": "3063143"}, {"introduction": "Analytical solutions to the Kolmogorov forward equation are often intractable, making numerical methods essential for practical applications. This hands-on coding exercise [@problem_id:3063184] guides you through implementing a finite-volume solver to simulate the evolution of the probability density. By testing different boundary conditions, you will gain a tangible understanding of how these mathematical rules determine whether total probability is conserved or lost from the domain, directly connecting abstract theory to concrete computational results.", "problem": "Consider the one-dimensional Kolmogorov forward equation (also called the Fokker–Planck equation) on a bounded interval domain $\\Omega = [0,L]$ with a nonnegative probability density $p(x,t)$, drift coefficient $a(x)$, and constant diffusion coefficient $bgt;0$:\n$$\n\\partial_t p(x,t) = -\\partial_x\\big(a(x)\\,p(x,t)\\big) + \\tfrac{1}{2}\\,\\partial_x^2\\big(b\\,p(x,t)\\big), \\quad x\\in (0,L),\\ t\\in (0,T].\n$$\nAssume an initial condition $p(x,0)=p_0(x)$ with unit mass $\\int_0^L p_0(x)\\,dx = 1$. Mass conservation means that the total mass\n$$\nM(t) = \\int_0^L p(x,t)\\,dx\n$$\nremains equal to $1$ for all $t\\in[0,T]$ under appropriate boundary conditions.\n\nYour task is to verify conservation (or lack thereof) of total mass numerically by discretizing the equation in space and time, integrating $p$ over $\\Omega$, and comparing $M(T)$ to $M(0)$ for several boundary-condition and coefficient scenarios.\n\nRequirements for modeling, discretization, and implementation:\n- Start from the core equation stated above and recast it in conservative (flux) form by identifying a flux $J(x,t)$ such that $\\partial_t p + \\partial_x J = 0$. Justify your expression for $J(x,t)$ using the given differential equation and the fact that $b$ is constant.\n- Use a uniform partition of $\\Omega$ into $N$ cells of width $\\Delta x = L/N$, and approximate cell averages of $p$ by piecewise constants. Use a finite-volume method that updates cell averages by numerical fluxes across cell interfaces. Your numerical flux at each interior face should be consistent with the continuum flux, with the spatial derivative inside the diffusion contribution approximated by a centered difference. Use explicit Euler in time with step size $\\Delta t$.\n- Implement three types of boundary conditions at $x=0$ and $x=L$:\n  1. Periodic: flux leaving at $x=L$ re-enters at $x=0$ consistently.\n  2. Reflecting (no-flux): the net flux through each boundary is zero.\n  3. Absorbing (Dirichlet): $p=0$ is enforced at the boundary when evaluating the flux.\n- Use an initial condition $p_0(x)$ of the form $p_0(x) = \\exp\\!\\big(-\\frac{(x-x_c)^2}{2 s^2}\\big)$, where $x_c=L/2$ and $s$ is prescribed. Normalize $p_0$ so that the discrete mass is exactly $1$ at $t=0$.\n- For each test case, compute a discrete approximation to the mass $M(t)$ at $t=0$ and $t=T$ by summing cell averages times $\\Delta x$. Return a boolean that is true if $|M(T)-M(0)| \\le \\varepsilon$ and false otherwise, where $\\varepsilon$ is a given tolerance.\n- All quantities are pure numbers; no physical units are required.\n\nTest suite and parameters:\n- Use the parameters below for four distinct test cases. In each case, let $x_c = L/2$ and discretize with $N$ cells of width $\\Delta x = L/N$. Use a common time step $\\Delta t = 5\\times 10^{-6}$ (chosen to satisfy standard explicit stability constraints for the given $b$ and $\\Delta x$). Define tolerance $\\varepsilon = 10^{-3}$. For each case, the drift $a(x)$, diffusion $b$, boundary condition, total time $T$, and initial width $s$ are specified:\n  1. Case A (periodic, pure diffusion): $L=1$, $N=400$, $a(x)=0$, $b=1$, $T=0.05$, $s=0.05$.\n  2. Case B (reflecting, advection–diffusion): $L=1$, $N=400$, $a(x)=0.5$ (constant), $b=0.1$, $T=0.05$, $s=0.05$.\n  3. Case C (absorbing, pure diffusion): $L=1$, $N=400$, $a(x)=0$, $b=1$, $T=0.2$, $s=0.05$.\n  4. Case D (reflecting, Ornstein–Uhlenbeck-type drift): $L=1$, $N=400$, $a(x)=-k\\,(x-L/2)$ with $k=1$, $b=0.05$, $T=0.05$, $s=0.05$.\n\nAlgorithmic expectations:\n- Your implementation must follow from the finite-volume interpretation of the conservation law $\\partial_t p + \\partial_x J = 0$, in which the cell-average update uses the difference of numerical fluxes across the two faces of each cell divided by $\\Delta x$.\n- For periodic boundaries, ensure the face between the last and first cell is included and indices wrap.\n- For reflecting boundaries, set the flux at the physical boundaries to zero.\n- For absorbing boundaries, enforce $p=0$ at the physical boundary when forming the boundary-face fluxes.\n\nFinal output specification:\n- Your program should produce a single line of output containing a comma-separated list enclosed in square brackets, in the order of the cases A, B, C, D. For each case, the entry must be a boolean that is true if $|M(T)-M(0)| \\le \\varepsilon$ and false otherwise. For example, a valid output looks like \"[True,True,False,True]\".", "solution": "The user has provided a valid problem statement concerning the numerical verification of mass conservation for the one-dimensional Kolmogorov forward equation (Fokker-Planck equation). The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. I will proceed with a full derivation and solution.\n\nThe problem revolves around the Fokker-Planck equation for a probability density $p(x,t)$ on a domain $\\Omega = [0,L]$:\n$$\n\\partial_t p(x,t) = -\\partial_x\\big(a(x)\\,p(x,t)\\big) + \\tfrac{1}{2}\\,\\partial_x^2\\big(b\\,p(x,t)\\big)\n$$\nwhere $a(x)$ is the drift coefficient and $b0$ is a constant diffusion coefficient. The task is to numerically investigate the conservation of total mass $M(t) = \\int_0^L p(x,t)\\,dx$ under different boundary conditions.\n\nFirst, we recast the equation into a conservation law form, $\\partial_t p + \\partial_x J = 0$. Since the diffusion coefficient $b$ is constant, the second derivative term can be simplified:\n$$\n\\tfrac{1}{2}\\,\\partial_x^2\\big(b\\,p(x,t)\\big) = \\tfrac{b}{2}\\,\\partial_x^2 p(x,t) = \\partial_x \\left( \\tfrac{b}{2}\\,\\partial_x p(x,t) \\right)\n$$\nSubstituting this back into the original equation gives:\n$$\n\\partial_t p(x,t) = -\\partial_x\\big(a(x)\\,p(x,t)\\big) + \\partial_x \\left( \\tfrac{b}{2}\\,\\partial_x p(x,t) \\right)\n$$\n$$\n\\partial_t p(x,t) + \\partial_x \\left( a(x)\\,p(x,t) - \\tfrac{b}{2}\\,\\partial_x p(x,t) \\right) = 0\n$$\nThis is the desired conservation law form, $\\partial_t p + \\partial_x J = 0$, where the probability flux $J(x,t)$ is identified as:\n$$\nJ(x,t) = a(x)\\,p(x,t) - \\tfrac{b}{2}\\,\\partial_x p(x,t)\n$$\nThe flux consists of an advective part, $a(x)p(x,t)$, due to drift, and a diffusive part, $-\\frac{b}{2}\\partial_x p(x,t)$, which is a form of Fick's law.\n\nThe rate of change of the total mass $M(t)$ is found by integrating the conservation law over the domain $\\Omega$:\n$$\n\\frac{dM}{dt} = \\frac{d}{dt}\\int_0^L p(x,t)\\,dx = \\int_0^L \\partial_t p(x,t)\\,dx = -\\int_0^L \\partial_x J(x,t)\\,dx\n$$\nBy the Fundamental Theorem of Calculus, this becomes:\n$$\n\\frac{dM}{dt} = -[J(x,t)]_{x=0}^{x=L} = J(0,t) - J(L,t)\n$$\nThis crucial relation shows that the total mass $M(t)$ is conserved ($dM/dt = 0$) if and only if the flux entering at $x=0$ equals the flux exiting at $x=L$.\n1.  **Periodic boundary conditions**: $J(0,t) = J(L,t)$, implying $dM/dt = 0$. Mass is conserved.\n2.  **Reflecting (no-flux) boundary conditions**: $J(0,t)=0$ and $J(L,t)=0$, implying $dM/dt = 0$. Mass is conserved.\n3.  **Absorbing boundary conditions**: $p(0,t)=0$ and $p(L,t)=0$. The flux $J = ap - \\frac{b}{2}\\partial_x p$ is not generally zero at the boundaries. Mass can \"leak\" out of the domain, so we expect $dM/dt \\le 0$ and non-conservation.\n\nTo verify this numerically, we employ a finite-volume method. The domain $[0,L]$ is partitioned into $N$ cells $C_i = [x_{i-1/2}, x_{i+1/2}]$ of equal width $\\Delta x = L/N$. The cell centers are $x_i = (i+1/2)\\Delta x$ for $i=0,\\dots,N-1$, and interfaces are at $x_{i+1/2} = (i+1)\\Delta x$. Let $p_i(t)$ be the average of $p(x,t)$ over cell $C_i$. Integrating the conservation law over $C_i$ yields an exact relation for the cell average:\n$$\n\\frac{dp_i}{dt} = -\\frac{1}{\\Delta x} \\left( J(x_{i+1/2}, t) - J(x_{i-1/2}, t) \\right)\n$$\nWe discretize this in time using explicit Euler with step $\\Delta t$, and approximate the interface fluxes $J_{i\\pm1/2}$ using the cell averages $p_i^n \\approx p_i(n\\Delta t)$. The update rule is:\n$$\np_i^{n+1} = p_i^n - \\frac{\\Delta t}{\\Delta x} \\left( J_{i+1/2}^n - J_{i-1/2}^n \\right)\n$$\nFollowing the problem's prescription, the numerical flux $J_{i+1/2}^n$ at the interface between cells $i$ and $i+1$ is approximated using a centered scheme:\n$$\nJ_{i+1/2}^n = a(x_{i+1/2}) \\frac{p_i^n + p_{i+1}^n}{2} - \\frac{b}{2} \\frac{p_{i+1}^n - p_i^n}{\\Delta x}\n$$\nThe boundary conditions determine the fluxes at the domain boundaries, $J_{1/2}$ (at $x=0$) and $J_{N-1/2}$ (at $x=L$). In implementation, it is convenient to define an array of $N+1$ fluxes at all interfaces $x_{i+1/2}$ for $i=-1, \\dots, N-1$.\n\n-   **Periodic BC**: The flux at $x=L$ re-enters at $x=0$. We compute the flux between cell $N-1$ and cell $0$ and assign it to both $J_{-1/2}$ and $J_{N-1/2}$.\n-   **Reflecting BC**: The fluxes are zero: $J_{-1/2} = 0$ and $J_{N-1/2} = 0$.\n-   **Absorbing BC**: We enforce $p=0$ at the boundary. For a cell-centered scheme, this is typically done using ghost cells. A ghost cell value $p_{-1}$ is chosen such that linear interpolation between $p_{-1}$ and $p_0$ gives zero at the boundary $x=0$. This implies $p_{-1}=-p_0$. The flux at $x=0$ is then $J_{-1/2} = a(0)\\frac{p_{-1}+p_0}{2} - \\frac{b}{2}\\frac{p_0-p_{-1}}{\\Delta x} = -b\\frac{p_0}{\\Delta x}$. Similarly, at $x=L$, we find $J_{N-1/2} = b\\frac{p_{N-1}}{\\Delta x}$.\n\nThe initial condition is a Gaussian $p_0(x) = \\exp\\big({-\\frac{(x-x_c)^2}{2s^2}}\\big)$ evaluated at cell centers. This discrete distribution $p_i^0$ is normalized such that the initial discrete mass, $M(0) = \\sum_{i=0}^{N-1} p_i^0 \\Delta x$, is exactly $1$. After evolving the system to time $T$, the final mass $M(T) = \\sum_{i=0}^{N-1} p_i^T \\Delta x$ is computed. The conservation check is then $|M(T) - M(0)| \\le \\varepsilon$. We expect cases A, B, and D to pass (True) and case C to fail (False).", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Fokker-Planck equation numerically for four test cases\n    and verifies mass conservation.\n    \"\"\"\n    \n    # Common parameters across all cases\n    N_val = 400\n    dt_val = 5e-6\n    epsilon_val = 1e-3\n\n    # Definition of the four test cases\n    test_cases = [\n        {'L': 1.0, 'a_func': lambda x: 0.0, 'b': 1.0, 'T': 0.05, 's': 0.05, 'bc_type': 'periodic', 'case_name': 'A'},\n        {'L': 1.0, 'a_func': lambda x: 0.5, 'b': 0.1, 'T': 0.05, 's': 0.05, 'bc_type': 'reflecting', 'case_name': 'B'},\n        {'L': 1.0, 'a_func': lambda x: 0.0, 'b': 1.0, 'T': 0.2, 's': 0.05, 'bc_type': 'absorbing', 'case_name': 'C'},\n        {'L': 1.0, 'a_func': lambda x: -1.0 * (x - 0.5), 'b': 0.05, 'T': 0.05, 's': 0.05, 'bc_type': 'reflecting', 'case_name': 'D'}\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        L = case['L']\n        a_func = case['a_func']\n        b = case['b']\n        T = case['T']\n        s = case['s']\n        bc_type = case['bc_type']\n        \n        # Spatial discretization\n        dx = L / N_val\n        # Cell centers\n        x_centers = np.linspace(dx / 2.0, L - dx / 2.0, N_val)\n        # Cell interfaces\n        x_interfaces = np.linspace(0, L, N_val + 1)\n        \n        # Initial condition: normalized Gaussian\n        xc = L / 2.0\n        p = np.exp(-(x_centers - xc)**2 / (2.0 * s**2))\n        M0 = np.sum(p) * dx\n        p = p / M0 # Ensures initial discrete mass is exactly 1.0\n\n        # Time stepping\n        num_steps = int(round(T / dt_val))\n        \n        for _ in range(num_steps):\n            p_old = np.copy(p)\n            \n            # Flux array for N+1 interfaces\n            J_faces = np.zeros(N_val + 1)\n            \n            # Interior fluxes (from interface 1 to N-1)\n            # J_faces[i] is the flux at x_interfaces[i]\n            for i in range(1, N_val):\n                p_left = p_old[i - 1]\n                p_right = p_old[i]\n                a_val = a_func(x_interfaces[i])\n                advective_flux = a_val * (p_left + p_right) / 2.0\n                diffusive_flux = (b / 2.0) * (p_right - p_left) / dx\n                J_faces[i] = advective_flux - diffusive_flux\n                \n            # Boundary fluxes (interface 0 and N)\n            if bc_type == 'periodic':\n                # Flux at the interface between cell N-1 and cell 0\n                p_left = p_old[N_val - 1]\n                p_right = p_old[0]\n                a_val = a_func(x_interfaces[0]) \n                advective_flux = a_val * (p_left + p_right) / 2.0\n                diffusive_flux = (b / 2.0) * (p_right - p_left) / dx\n                J_faces[0] = advective_flux - diffusive_flux\n                J_faces[N_val] = J_faces[0]\n            elif bc_type == 'reflecting':\n                J_faces[0] = 0.0\n                J_faces[N_val] = 0.0\n            elif bc_type == 'absorbing':\n                # Flux at x=0\n                J_faces[0] = -b * p_old[0] / dx\n                # Flux at x=L\n                J_faces[N_val] = b * p_old[N_val - 1] / dx\n                \n            # Update cell averages using the calculated fluxes\n            for i in range(N_val):\n                p[i] = p_old[i] - (dt_val / dx) * (J_faces[i + 1] - J_faces[i])\n                \n        # Final mass calculation\n        M_T = np.sum(p) * dx\n        \n        # Check for conservation against the initial mass of 1.0\n        is_conserved = abs(M_T - 1.0) = epsilon_val\n        results.append(is_conserved)\n\n    # Format the final output as a comma-separated list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3063184"}]}