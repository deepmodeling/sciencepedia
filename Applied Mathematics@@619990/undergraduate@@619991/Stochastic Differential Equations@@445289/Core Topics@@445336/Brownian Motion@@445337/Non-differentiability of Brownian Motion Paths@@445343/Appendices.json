{"hands_on_practices": [{"introduction": "We begin by directly investigating the behavior of the slope of a Brownian motion path. By approximating the derivative with a difference quotient over small time intervals of size $h$, we can analyze its statistical properties. This exercise [@problem_id:3068303] asks you to calculate the variance of this approximate slope, revealing a fundamental reason why the limit as $h \\to 0$, which would define the derivative, cannot exist.", "problem": "Let $\\{B_{t}\\}_{t \\ge 0}$ be a standard Brownian motion. Fix a mesh size $h>0$ and define grid times $t_{k} = k h$ for integers $k \\ge 0$. Define the piecewise linear interpolation $B^{(h)}_{t}$ by $B^{(h)}_{t_{k}} = B_{t_{k}}$ for all $k$, and by linearity on each interval $[t_{k}, t_{k+1}]$. For any $t \\in [t_{k}, t_{k+1})$, define the slope process by\n$$\nS_{h}(t) \\coloneqq \\frac{B_{t_{k+1}} - B_{t_{k}}}{h}.\n$$\nUsing only the defining properties of standard Brownian motion (stationary independent increments that are normally distributed with mean $0$ and variance equal to the length of the time increment), determine the exact expression for the variance $\\operatorname{Var}(S_{h}(t))$ as a function of $h$. Provide your final answer as a single closed-form analytic expression in $h$.", "solution": "The problem is valid as it is well-posed, scientifically grounded, and formulated using standard, unambiguous definitions from the theory of stochastic processes. We proceed to find the variance of the slope process $S_{h}(t)$.\n\nLet $\\{B_{t}\\}_{t \\ge 0}$ be a standard Brownian motion. The problem defines a slope process $S_{h}(t)$ for a given mesh size $h > 0$. For any time $t \\ge 0$, there exists a unique non-negative integer $k$ such that $t \\in [t_{k}, t_{k+1})$, where $t_{k} = k h$. For such a $t$, the slope process is defined as\n$$\nS_{h}(t) = \\frac{B_{t_{k+1}} - B_{t_{k}}}{h}.\n$$\nWe are asked to compute the variance, $\\operatorname{Var}(S_{h}(t))$. The variance of a random variable $X$ is given by the formula $\\operatorname{Var}(X) = E[X^2] - (E[X])^2$. We will first compute the expectation $E[S_{h}(t)]$ and then its second moment $E[(S_{h}(t))^2]$.\n\nFirst, let's compute the expectation of $S_{h}(t)$. Using the linearity of the expectation operator, we have:\n$$\nE[S_{h}(t)] = E\\left[\\frac{B_{t_{k+1}} - B_{t_{k}}}{h}\\right] = \\frac{1}{h} E[B_{t_{k+1}} - B_{t_{k}}].\n$$\nOne of the defining properties of a standard Brownian motion is that its increments have a mean of $0$. Specifically, for any $s < t$, the increment $B_{t} - B_{s}$ is a random variable with mean $E[B_{t} - B_{s}] = 0$. In our case, the increment is over the time interval $[t_k, t_{k+1})$. The starting time is $s = t_k$ and the ending time is $t = t_{k+1}$. Therefore,\n$$\nE[B_{t_{k+1}} - B_{t_{k}}] = 0.\n$$\nSubstituting this result back into the expression for the expectation of the slope process gives:\n$$\nE[S_{h}(t)] = \\frac{1}{h} \\times 0 = 0.\n$$\nThe mean of the slope process is $0$. Note that due to the stationary increments property of Brownian motion, this result does not depend on the specific interval index $k$.\n\nNow we can compute the variance of $S_{h}(t)$. Since the mean is $0$, the variance simplifies to the second moment:\n$$\n\\operatorname{Var}(S_{h}(t)) = E[(S_{h}(t))^2] - (E[S_{h}(t)])^2 = E[(S_{h}(t))^2] - 0^2 = E[(S_{h}(t))^2].\n$$\nWe now compute this second moment. Substituting the definition of $S_{h}(t)$:\n$$\n\\operatorname{Var}(S_{h}(t)) = E\\left[\\left(\\frac{B_{t_{k+1}} - B_{t_{k}}}{h}\\right)^2\\right].\n$$\nUsing the property of expectation $E[c Y^2] = c E[Y^2]$ for a constant $c$, we can pull the constant factor $1/h^2$ out of the expectation:\n$$\n\\operatorname{Var}(S_{h}(t)) = \\frac{1}{h^2} E[(B_{t_{k+1}} - B_{t_{k}})^2].\n$$\nThe term $E[(B_{t_{k+1}} - B_{t_{k}})^2]$ is the second moment of the Brownian increment $B_{t_{k+1}} - B_{t_{k}}$. Since we have already established that the mean of this increment is $0$, its variance is equal to its second moment:\n$$\n\\operatorname{Var}(B_{t_{k+1}} - B_{t_{k}}) = E[(B_{t_{k+1}} - B_{t_{k}})^2] - (E[B_{t_{k+1}} - B_{t_{k}}])^2 = E[(B_{t_{k+1}} - B_{t_{k}})^2].\n$$\nAnother defining property of standard Brownian motion is that the variance of an increment $B_t - B_s$ for $s<t$ is equal to the length of the time interval, $t-s$. For our increment, the time interval is $[t_k, t_{k+1}]$, and its length is $t_{k+1} - t_k = (k+1)h - kh = h$. Thus,\n$$\n\\operatorname{Var}(B_{t_{k+1}} - B_{t_{k}}) = h.\n$$\nCombining the last two equations, we find the second moment of the increment:\n$$\nE[(B_{t_{k+1}} - B_{t_{k}})^2] = h.\n$$\nFinally, we substitute this result back into our expression for the variance of the slope process:\n$$\n\\operatorname{Var}(S_{h}(t)) = \\frac{1}{h^2} \\times h = \\frac{1}{h}.\n$$\nThis is the exact expression for the variance of the slope process $S_{h}(t)$ as a function of the mesh size $h$. The result is independent of the specific time $t$, as long as $h$ is fixed. This is a consequence of the stationary increments property of Brownian motion.\nAs a conceptual check, this result demonstrates why the path of a Brownian motion is almost surely nowhere differentiable. If a derivative existed at time $t$, we would expect the limit of the slope process $S_h(t)$ as $h \\to 0$ to converge. However, the variance of $S_h(t)$, which is $1/h$, diverges to infinity as $h \\to 0$. A sequence of random variables whose variance diverges cannot converge in the mean-square sense, which is a strong indication of non-differentiability.", "answer": "$$\n\\boxed{\\frac{1}{h}}\n$$", "id": "3068303"}, {"introduction": "While the first-order changes of a Brownian path are too erratic to define a derivative, its second-order properties are remarkably stable. This exercise [@problem_id:1321428] introduces the concept of quadratic variation by having you calculate the expected value of the sum of squared increments. The non-zero result is a hallmark of stochastic processes and a key feature distinguishing them from the smooth functions of classical calculus, which have zero quadratic variation.", "problem": "An engineer is studying the statistical properties of a noise signal $V(t)$ that contaminates a sensitive high-precision measurement. The noise is modeled as a standard one-dimensional Brownian motion, denoted by $B_t$, where $t$ represents time. A standard Brownian motion is a stochastic process characterized by the following properties:\n1.  $B_0 = 0$.\n2.  For any sequence of times $0 \\le s_1 < t_1 \\le s_2 < t_2$, the increments $B_{t_1} - B_{s_1}$ and $B_{t_2} - B_{s_2}$ are independent random variables.\n3.  For any $t > s \\ge 0$, the increment $B_t - B_s$ follows a normal distribution with a mean of 0 and a variance of $t-s$.\n\nTo analyze the signal's volatility over a time interval $[0, T]$, the engineer considers a partition of the interval into $n$ equal subintervals, where $n$ is a positive integer. The endpoints of these subintervals are given by $t_i = i \\frac{T}{n}$ for $i = 0, 1, 2, \\ldots, n$. The engineer then computes a quantity $Q_n$, which is the sum of the squared changes in the noise signal over each subinterval:\n$$Q_n = \\sum_{i=1}^{n} (B_{t_i} - B_{t_{i-1}})^2$$\n\nDetermine the expected value of this quantity, $\\mathbb{E}[Q_n]$. Express your final answer as a symbolic expression in terms of the total time $T$.", "solution": "Let the partition points be $t_{i} = i \\frac{T}{n}$ for $i=0,1,\\ldots,n$, and define the increments $\\Delta B_{i} = B_{t_{i}} - B_{t_{i-1}}$. By property 3 of standard Brownian motion, for each $i$,\n$$\n\\Delta B_{i} \\sim \\mathcal{N}\\!\\left(0,\\, t_{i} - t_{i-1}\\right) = \\mathcal{N}\\!\\left(0,\\, \\frac{T}{n}\\right).\n$$\nThe quantity of interest is\n$$\nQ_{n} = \\sum_{i=1}^{n} \\left(\\Delta B_{i}\\right)^{2}.\n$$\nUsing linearity of expectation,\n$$\n\\mathbb{E}[Q_{n}] = \\sum_{i=1}^{n} \\mathbb{E}\\left[\\left(\\Delta B_{i}\\right)^{2}\\right].\n$$\nFor any random variable $X$ with mean $0$, $\\mathbb{E}[X^{2}] = \\operatorname{Var}(X)$. Since $\\Delta B_{i} \\sim \\mathcal{N}\\!\\left(0, \\frac{T}{n}\\right)$, we have\n$$\n\\mathbb{E}\\left[\\left(\\Delta B_{i}\\right)^{2}\\right] = \\operatorname{Var}(\\Delta B_{i}) = \\frac{T}{n}.\n$$\nTherefore,\n$$\n\\mathbb{E}[Q_{n}] = \\sum_{i=1}^{n} \\frac{T}{n} = n \\cdot \\frac{T}{n} = T.\n$$", "answer": "$$\\boxed{T}$$", "id": "1321428"}, {"introduction": "Finally, we will use one of the most elegant features of Brownian motion—its self-similarity or scaling property—to prove non-differentiability by contradiction. This thought experiment [@problem_id:1321465] asks you to temporarily assume that a derivative does exist and see where that assumption leads when combined with the scaling property. You will discover this leads to a logical inconsistency, providing a rigorous confirmation of our earlier findings.", "problem": "An analyst proposes a model where the path of a standard one-dimensional Brownian motion, $\\{B_t\\}_{t \\geq 0}$, is, contrary to established theory, assumed to be a mean-square differentiable function of time. Let the derivative at time $t$ be the random variable $B'(t)$. The analysis further relies on the property of stationary increments, which implies that the statistical distribution of the derivative $B'(t)$ is the same for all $t > 0$. We denote the variance of the derivative at an arbitrary time $t>0$ as $\\sigma^2 = \\text{Var}(B'(t))$, which is assumed to be a finite, non-zero constant.\n\nThe analyst then examines the scaled process $W_t = \\frac{1}{\\sqrt{c}} B_{ct}$ for a constant $c > 0$. It is a well-known property of Brownian motion that this scaled process $\\{W_t\\}_{t \\geq 0}$ is also a standard one-dimensional Brownian motion. By applying the chain rule to the definition of $W_t$, the analyst finds a relationship between the derivative of the scaled process, $W'(t)$, and the derivative of the original process.\n\nSince $W_t$ and $B_t$ are statistically identical processes, it must be that $\\text{Var}(W'(1)) = \\text{Var}(B'(1)) = \\sigma^2$. This constraint, combined with the derived relationship between the derivatives, leads to an equation of the form $\\sigma^2 = g(c) \\sigma^2$.\n\nBased on this hypothetical framework, determine the function $g(c)$. Your answer should be an expression in terms of $c$.", "solution": "We assume, contrary to the established theory, that a standard one-dimensional Brownian motion $\\{B_{t}\\}_{t \\geq 0}$ is mean-square differentiable, so that its time derivative $B'(t)$ exists in mean square for each $t>0$. By the given stationarity of increments and the assumed differentiability, the distribution of $B'(t)$ is the same for all $t>0$, hence $\\operatorname{Var}(B'(t))=\\sigma^{2}$ for a finite, non-zero constant $\\sigma^{2}$.\n\nDefine the scaled process $W_{t}=\\frac{1}{\\sqrt{c}} B_{c t}$ for a constant $c>0$. By the Brownian scaling property, $\\{W_{t}\\}_{t \\geq 0}$ is also a standard Brownian motion. Under the differentiability assumption, we apply the chain rule to obtain\n$$\nW'(t)=\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left(c^{-1/2} B_{c t}\\right)=c^{-1/2}\\cdot B'(c t)\\cdot c=c^{1/2} B'(c t).\n$$\nTaking variances and using $\\operatorname{Var}(aX)=a^{2}\\operatorname{Var}(X)$ gives\n$$\n\\operatorname{Var}(W'(1))=\\operatorname{Var}\\left(c^{1/2} B'(c)\\right)=c\\,\\operatorname{Var}(B'(c)).\n$$\nBy the assumed stationarity of the derivative’s distribution, $\\operatorname{Var}(B'(c))=\\operatorname{Var}(B'(1))=\\sigma^{2}$. Since $W$ is standard Brownian motion, $\\operatorname{Var}(W'(1))=\\operatorname{Var}(B'(1))=\\sigma^{2}$. Therefore,\n$$\n\\sigma^{2}=\\operatorname{Var}(W'(1))=c\\,\\operatorname{Var}(B'(c))=c\\,\\sigma^{2}.\n$$\nThis is of the form $\\sigma^{2}=g(c)\\,\\sigma^{2}$ with\n$$\ng(c)=c.\n$$", "answer": "$$\\boxed{c}$$", "id": "1321465"}]}