{"hands_on_practices": [{"introduction": "The first step in mastering any stochastic quantity is to understand its probability distribution. This exercise guides you through the fundamental derivation of the distribution for the maximum of a Brownian motion, $M_t$, using the celebrated reflection principle. By working through this problem [@problem_id:3049950], you will not only compute the probability density function but also calculate its expected value, a key measure of its typical size.", "problem": "Let $\\{B_{s}\\}_{s \\geq 0}$ be a standard Brownian motion, meaning a continuous-time stochastic process with $B_{0}=0$, independent and stationary increments, and $B_{t} \\sim \\mathcal{N}(0,t)$ for each $t0$, where $\\mathcal{N}(0,t)$ denotes the normal distribution with mean $0$ and variance $t$. For a fixed $t0$, define the running maximum\n$$\nM_{t} := \\sup_{0 \\leq s \\leq t} B_{s}.\n$$\nUsing only the core properties of standard Brownian motion (including symmetry of increments, the normal distribution of $B_{t}$, and pathwise arguments available from the reflection principle), derive the cumulative distribution function and the probability density function of $M_{t}$ for $m \\geq 0$. Then compute the expectation\n$$\nE[M_{t}] = \\int_{0}^{\\infty} m \\, f_{M_{t}}(m) \\, dm,\n$$\nwhere $f_{M_{t}}$ is the probability density function of $M_{t}$. Finally, use the Brownian scaling property to justify the relation $M_{t} \\stackrel{d}{=} \\sqrt{t}\\,M_{1}$ and deduce $E[M_{t}]$ from $E[M_{1}]$. Express your final answer as a single closed-form expression in terms of $t$. No numerical approximation is required.", "solution": "The problem statement is a standard, well-posed problem in the theory of stochastic processes. It is scientifically grounded, self-contained, and free of any flaws. We may proceed with the solution.\n\nLet $\\{B_s\\}_{s \\geq 0}$ be a standard one-dimensional Brownian motion with $B_0=0$. The running maximum up to time $t > 0$ is defined as $M_t := \\sup_{0 \\leq s \\leq t} B_s$. We are tasked with finding the cumulative distribution function (CDF) and probability density function (PDF) of $M_t$, and then computing its expectation $E[M_t]$.\n\nFirst, we derive the CDF of $M_t$, which is $F_{M_t}(m) = P(M_t \\leq m)$ for any real number $m$. Since $B_0 = 0$ and the paths of Brownian motion are continuous, the maximum $M_t$ must be non-negative, i.e., $M_t \\geq B_0 = 0$. Therefore, for any $m  0$, $P(M_t \\leq m) = 0$. We now consider the case where $m \\geq 0$.\n\nThe core tool for this derivation is the reflection principle for Brownian motion. The principle states that for any level $m>0$, the probability that the maximum $M_t$ has exceeded $m$ is twice the probability that the process value $B_t$ is greater than $m$.\nLet's analyze the event $\\{M_t \\geq m\\}$. This is equivalent to saying that the Brownian path hits or crosses the level $m$ at some time $s \\in [0, t]$. Let $\\tau_m = \\inf\\{s \\geq 0 : B_s = m\\}$ be the first hitting time of the level $m$. Then the event $\\{M_t \\geq m\\}$ is identical to the event $\\{\\tau_m \\leq t\\}$.\nWe can decompose this event based on the final position $B_t$:\n$$\nP(M_t \\geq m) = P(M_t \\geq m, B_t \\geq m) + P(M_t \\geq m, B_t  m)\n$$\nIf $B_t \\geq m$, then it is certain that the maximum $M_t$ is also at least $m$, so $M_t \\geq B_t \\geq m$. Thus, the event $\\{M_t \\geq m, B_t \\geq m\\}$ is simply the event $\\{B_t \\geq m\\}$.\nSo, the equation becomes:\n$$\nP(M_t \\geq m) = P(B_t \\geq m) + P(M_t \\geq m, B_t  m)\n$$\nThe reflection principle states that $P(M_t \\geq m, B_t  m) = P(B_t > m)$. Briefly, this is because any path that hits $m$ and ends up below $m$ can be \"reflected\" about the line $y=m$ after its first hitting time $\\tau_m$. The reflected path from $\\tau_m$ onwards corresponds to a path that hits $m$ and ends up above $m$. By the strong Markov property of Brownian motion, these two sets of paths have equal probability.\nSince the distribution of $B_t$ is continuous (normal distribution), we have $P(B_t \\geq m) = P(B_t > m)$.\nSubstituting this into the equation for $P(M_t \\geq m)$, we get:\n$$\nP(M_t \\geq m) = P(B_t > m) + P(B_t > m) = 2 P(B_t > m)\n$$\nThe random variable $B_t$ is normally distributed with mean $0$ and variance $t$, i.e., $B_t \\sim \\mathcal{N}(0, t)$. We can express this in terms of the standard normal variable $Z \\sim \\mathcal{N}(0, 1)$ as $B_t \\stackrel{d}{=} \\sqrt{t}Z$.\n$$\nP(B_t > m) = P(\\sqrt{t}Z > m) = P(Z > \\frac{m}{\\sqrt{t}}) = 1 - \\Phi\\left(\\frac{m}{\\sqrt{t}}\\right)\n$$\nwhere $\\Phi(\\cdot)$ is the CDF of the standard normal distribution.\nTherefore, for $m \\geq 0$:\n$$\nP(M_t \\geq m) = 2 \\left(1 - \\Phi\\left(\\frac{m}{\\sqrt{t}}\\right)\\right)\n$$\nThe CDF of $M_t$ is $F_{M_t}(m) = P(M_t \\leq m) = 1 - P(M_t > m)$. Since $M_t$ has a continuous distribution, $P(M_t > m) = P(M_t \\geq m)$.\n$$\nF_{M_t}(m) = 1 - 2 \\left(1 - \\Phi\\left(\\frac{m}{\\sqrt{t}}\\right)\\right) = 2\\Phi\\left(\\frac{m}{\\sqrt{t}}\\right) - 1, \\quad \\text{for } m \\geq 0\n$$\nAnd $F_{M_t}(m) = 0$ for $m0$.\n\nNext, we find the probability density function (PDF) of $M_t$, $f_{M_t}(m)$, by differentiating the CDF for $m \\geq 0$:\n$$\nf_{M_t}(m) = \\frac{d}{dm} F_{M_t}(m) = \\frac{d}{dm} \\left(2\\Phi\\left(\\frac{m}{\\sqrt{t}}\\right) - 1\\right)\n$$\nLet $\\phi(x) = \\frac{d}{dx}\\Phi(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$ be the PDF of the standard normal distribution. Using the chain rule:\n$$\nf_{M_t}(m) = 2 \\phi\\left(\\frac{m}{\\sqrt{t}}\\right) \\cdot \\frac{d}{dm}\\left(\\frac{m}{\\sqrt{t}}\\right) = 2 \\phi\\left(\\frac{m}{\\sqrt{t}}\\right) \\cdot \\frac{1}{\\sqrt{t}}\n$$\nSubstituting the expression for $\\phi(\\cdot)$:\n$$\nf_{M_t}(m) = \\frac{2}{\\sqrt{t}} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{m}{\\sqrt{t}}\\right)^2\\right) = \\frac{2}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{m^2}{2t}\\right) = \\sqrt{\\frac{2}{\\pi t}} \\exp\\left(-\\frac{m^2}{2t}\\right)\n$$\nThis is the PDF for $m \\geq 0$. For $m  0$, $f_{M_t}(m) = 0$. This distribution is known as a folded normal distribution. It is noteworthy that $M_t$ has the same distribution as $|B_t|$.\n\nNow we compute the expectation $E[M_t]$:\n$$\nE[M_t] = \\int_{-\\infty}^{\\infty} m f_{M_t}(m) dm = \\int_{0}^{\\infty} m f_{M_t}(m) dm\n$$\n$$\nE[M_t] = \\int_{0}^{\\infty} m \\left(\\sqrt{\\frac{2}{\\pi t}} \\exp\\left(-\\frac{m^2}{2t}\\right)\\right) dm = \\sqrt{\\frac{2}{\\pi t}} \\int_{0}^{\\infty} m \\exp\\left(-\\frac{m^2}{2t}\\right) dm\n$$\nTo evaluate the integral, we use the substitution $u = \\frac{m^2}{2t}$. This gives $du = \\frac{2m}{2t} dm = \\frac{m}{t} dm$, so $m \\, dm = t \\, du$. The limits of integration remain from $0$ to $\\infty$.\n$$\nE[M_t] = \\sqrt{\\frac{2}{\\pi t}} \\int_{0}^{\\infty} \\exp(-u) (t \\, du) = t \\sqrt{\\frac{2}{\\pi t}} \\int_{0}^{\\infty} e^{-u} du\n$$\nThe integral $\\int_{0}^{\\infty} e^{-u} du = [-e^{-u}]_0^\\infty = 0 - (-1) = 1$.\n$$\nE[M_t] = t \\sqrt{\\frac{2}{\\pi t}} \\cdot 1 = \\sqrt{t^2 \\cdot \\frac{2}{\\pi t}} = \\sqrt{\\frac{2t}{\\pi}}\n$$\n\nFinally, we use the Brownian scaling property to justify this result. The scaling property states that for any constant $c>0$, the process $W_s = \\frac{1}{\\sqrt{c}}B_{cs}$ is also a standard Brownian motion. Let us choose $c=t$. Then the process $W_s = \\frac{1}{\\sqrt{t}} B_{ts}$ defined for $s \\geq 0$ is a standard Brownian motion.\nWe can express $M_t$ in terms of this new process $W_s$. Note that $B_{ts} = \\sqrt{t} W_s$.\n$$\nM_t = \\sup_{0 \\leq u \\leq t} B_u\n$$\nLet's change the variable of the supremum to $s = u/t$. As $u$ ranges from $0$ to $t$, $s$ ranges from $0$ to $1$.\n$$\nM_t = \\sup_{0 \\leq s \\leq 1} B_{ts} = \\sup_{0 \\leq s \\leq 1} (\\sqrt{t} W_s) = \\sqrt{t} \\sup_{0 \\leq s \\leq 1} W_s\n$$\nThe term $\\sup_{0 \\leq s \\leq 1} W_s$ is the maximum of the standard Brownian motion $W$ over the time interval $[0,1]$. Let's denote this as $M_{W,1}$. Since $W$ is a standard Brownian motion, the distribution of its maximum over $[0,1]$ is identical to the distribution of the maximum of the original Brownian motion $B$ over $[0,1]$, which is $M_1$. Thus, $M_{W,1} \\stackrel{d}{=} M_1$.\nThis leads to the equality in distribution:\n$$\nM_t \\stackrel{d}{=} \\sqrt{t} M_1\n$$\nTaking the expectation of both sides:\n$$\nE[M_t] = E[\\sqrt{t} M_1] = \\sqrt{t} E[M_1]\n$$\nWe can find $E[M_1]$ from our previous general calculation by setting $t=1$:\n$$\nE[M_1] = \\sqrt{\\frac{2(1)}{\\pi}} = \\sqrt{\\frac{2}{\\pi}}\n$$\nSubstituting this value back, we get:\n$$\nE[M_t] = \\sqrt{t} \\cdot \\sqrt{\\frac{2}{\\pi}} = \\sqrt{\\frac{2t}{\\pi}}\n$$\nThis confirms our direct calculation and demonstrates the utility of the scaling property.", "answer": "$$\\boxed{\\sqrt{\\frac{2t}{\\pi}}}$$", "id": "3049950"}, {"introduction": "Brownian motion exhibits a remarkable self-similarity across different time scales, a property known as Brownian scaling. This practice [@problem_id:3049947] invites you to formally prove this scaling relationship and explore its consequences for the distribution of the maximum. Understanding this principle is crucial, as it allows us to relate the behavior of the process over long periods to its behavior over short ones, simplifying many calculations.", "problem": "Let $\\{B_t\\}_{t \\geq 0}$ be a standard Brownian motion (SBM), defined as a mean-zero Gaussian process with continuous sample paths and covariance $\\mathbb{E}[B_s B_t] = \\min\\{s,t\\}$. For a fixed $t0$, define the running maximum $M_t := \\sup_{0 \\leq s \\leq t} B_s$. Let $c0$ be a fixed constant.\n\n(a) Starting from the Gaussian process characterization of Brownian motion and its covariance structure, establish the scaling-in-law relationship for the maximum by proving that $M_{c t}$ is equal in distribution to $\\sqrt{c}\\, M_t$.\n\n(b) Using only first principles about how probability density functions (PDFs) transform under positive scalar multiplication of a random variable, express the PDF of $M_{c t}$, denoted $f_{M_{c t}}(m)$ for $m \\in \\mathbb{R}$, in terms of the PDF of $M_t$, denoted $f_{M_t}(m)$.\n\nYour final answer should be a single closed-form analytic expression for $f_{M_{c t}}(m)$ written in terms of $f_{M_t}$ only. No numerical approximation is required.", "solution": "The problem is deemed valid as it is scientifically grounded in the theory of stochastic processes, well-posed, objective, and contains no discernible flaws.\n\nThe problem is divided into two parts. Part (a) requires proving a scaling property for the maximum of a standard Brownian motion, and part (b) requires using this property to relate the probability density functions (PDFs) of the maxima at different time scales.\n\n(a) Proving the scaling-in-law relationship $M_{c t} \\stackrel{d}{=} \\sqrt{c}\\, M_t$.\n\nLet $\\{B_t\\}_{t \\geq 0}$ be a standard Brownian motion (SBM). By definition, it is a stochastic process satisfying:\n1.  $B_0 = 0$ almost surely.\n2.  The sample paths $t \\mapsto B_t$ are continuous almost surely.\n3.  It is a Gaussian process with mean $\\mathbb{E}[B_t] = 0$ for all $t \\geq 0$.\n4.  It has covariance $\\mathbb{E}[B_s B_t] = \\min\\{s, t\\}$ for all $s, t \\geq 0$.\n\nWe are given a constant $c > 0$. We define a new stochastic process $\\{X_s\\}_{s \\geq 0}$ by scaling the process $\\{B_t\\}$ in both time and space:\n$$ X_s = \\frac{1}{\\sqrt{c}} B_{c s} \\quad \\text{for } s \\geq 0 $$\nTo prove the scaling property of the maximum, we first demonstrate that $\\{X_s\\}_{s \\geq 0}$ is also a standard Brownian motion by verifying the four defining properties.\n\n1.  **Initial value:** At $s=0$, we have $X_0 = \\frac{1}{\\sqrt{c}} B_{c \\cdot 0} = \\frac{1}{\\sqrt{c}} B_0$. Since $B_0 = 0$, it follows that $X_0 = 0$.\n\n2.  **Continuity of paths:** The mapping $s \\mapsto cs$ is a continuous function. The process $\\{B_t\\}$ has continuous sample paths, meaning $u \\mapsto B_u$ is continuous. The composition of continuous functions is continuous, so $s \\mapsto B_{cs}$ is continuous. Scaling by the constant $\\frac{1}{\\sqrt{c}}$ preserves continuity. Therefore, the sample paths of $\\{X_s\\}$ are continuous.\n\n3.  **Gaussian process and mean:** Since $\\{B_t\\}$ is a Gaussian process, any finite linear combination of its random variables is normally distributed. For any set of times $s_1, s_2, \\dots, s_n$, the vector $(X_{s_1}, \\dots, X_{s_n}) = (\\frac{1}{\\sqrt{c}} B_{cs_1}, \\dots, \\frac{1}{\\sqrt{c}} B_{cs_n})$ is a linear transformation of the Gaussian vector $(B_{cs_1}, \\dots, B_{cs_n})$, and is therefore also a Gaussian vector. This establishes that $\\{X_s\\}$ is a Gaussian process.\nThe mean of $X_s$ is:\n$$ \\mathbb{E}[X_s] = \\mathbb{E}\\left[\\frac{1}{\\sqrt{c}} B_{cs}\\right] = \\frac{1}{\\sqrt{c}} \\mathbb{E}[B_{cs}] $$\nSince $\\mathbb{E}[B_t] = 0$ for all $t$, we have $\\mathbb{E}[B_{cs}] = 0$. Thus, $\\mathbb{E}[X_s] = 0$ for all $s \\geq 0$.\n\n4.  **Covariance structure:** We compute the covariance of $X_s$ and $X_u$ for any $s, u \\geq 0$.\n$$ \\mathbb{E}[X_s X_u] = \\mathbb{E}\\left[ \\left(\\frac{1}{\\sqrt{c}} B_{cs}\\right) \\left(\\frac{1}{\\sqrt{c}} B_{cu}\\right) \\right] = \\frac{1}{c} \\mathbb{E}[B_{cs} B_{cu}] $$\nUsing the covariance property of SBM, $\\mathbb{E}[B_a B_b] = \\min\\{a, b\\}$, we have:\n$$ \\mathbb{E}[B_{cs} B_{cu}] = \\min\\{cs, cu\\} $$\nSince $c > 0$, we can factor it out of the minimum operator: $\\min\\{cs, cu\\} = c \\min\\{s, u\\}$.\nSubstituting this back into the covariance calculation for $X$:\n$$ \\mathbb{E}[X_s X_u] = \\frac{1}{c} (c \\min\\{s, u\\}) = \\min\\{s, u\\} $$\nThis is precisely the covariance structure of a standard Brownian motion.\n\nSince the process $\\{X_s\\}_{s \\geq 0}$ satisfies all four defining properties of a standard Brownian motion, it has the same probability law as the process $\\{B_s\\}_{s \\geq 0}$. This is denoted as $\\{X_s\\}_{s \\geq 0} \\stackrel{d}{=} \\{B_s\\}_{s \\geq 0}$, where $\\stackrel{d}{=}$ means equality in distribution.\n\nThis equality in distribution of the entire processes implies that any functional applied to the paths of these processes will also result in random variables that are equal in distribution. The running maximum is such a functional.\nLet $M_t = \\sup_{0 \\leq s \\leq t} B_s$. The running maximum of the process $\\{X_s\\}$ over the interval $[0, t]$ is $\\sup_{0 \\leq s \\leq t} X_s$. Due to the equality in law of the processes:\n$$ \\sup_{0 \\leq s \\leq t} X_s \\stackrel{d}{=} \\sup_{0 \\leq s \\leq t} B_s = M_t $$\nNow, we express $\\sup_{0 \\leq s \\leq t} X_s$ in terms of the original process $\\{B_t\\}$:\n$$ \\sup_{0 \\leq s \\leq t} X_s = \\sup_{0 \\leq s \\leq t} \\left(\\frac{1}{\\sqrt{c}} B_{cs}\\right) $$\nSince $\\sqrt{c}$ is a positive constant, we can move the scaling factor outside the supremum:\n$$ \\sup_{0 \\leq s \\leq t} X_s = \\frac{1}{\\sqrt{c}} \\sup_{0 \\leq s \\leq t} B_{cs} $$\nLet's perform a change of variable in the supremum. Let $u = cs$. As $s$ varies from $0$ to $t$, the variable $u$ varies from $0$ to $ct$. The expression becomes:\n$$ \\frac{1}{\\sqrt{c}} \\sup_{0 \\leq u \\leq ct} B_u $$\nBy definition, $\\sup_{0 \\leq u \\leq ct} B_u = M_{ct}$. Therefore, we have established:\n$$ \\frac{1}{\\sqrt{c}} M_{ct} \\stackrel{d}{=} M_t $$\nMultiplying by $\\sqrt{c}$ (which is a deterministic, positive constant), we arrive at the desired scaling relationship:\n$$ M_{ct} \\stackrel{d}{=} \\sqrt{c} M_t $$\nThis completes the proof for part (a).\n\n(b) Relating the PDFs of $M_{c t}$ and $M_t$.\n\nFrom part (a), we have the distributional equality $M_{ct} \\stackrel{d}{=} \\sqrt{c} M_t$. Let $Y = M_{ct}$ and $X = M_t$. Let the scaling factor be $a = \\sqrt{c}$. We have $Y \\stackrel{d}{=} aX$, with $a > 0$. We need to find the PDF of $Y$, $f_Y(m)$, in terms of the PDF of $X$, $f_X(m)$. The problem asks us to use first principles.\n\nWe begin with the cumulative distribution function (CDF). Let $F_Y(m)$ be the CDF of $Y$ and $F_X(m)$ be the CDF of $X$.\n$$ F_Y(m) = P(Y \\leq m) $$\nDue to the equality in distribution, $P(Y \\leq m) = P(aX \\leq m)$.\nSince $a = \\sqrt{c} > 0$, we can divide the inequality by $a$ without changing its direction:\n$$ P(aX \\leq m) = P\\left(X \\leq \\frac{m}{a}\\right) $$\nThe right-hand side is, by definition, the CDF of $X$ evaluated at the point $\\frac{m}{a}$:\n$$ F_Y(m) = F_X\\left(\\frac{m}{a}\\right) $$\nThe probability density function (PDF) is the derivative of the CDF with respect to its argument. So, $f_Y(m) = \\frac{d}{dm} F_Y(m)$. Applying this to our relationship:\n$$ f_Y(m) = \\frac{d}{dm} F_X\\left(\\frac{m}{a}\\right) $$\nUsing the chain rule for differentiation, with $u = \\frac{m}{a}$ so that $\\frac{du}{dm} = \\frac{1}{a}$:\n$$ f_Y(m) = \\frac{dF_X(u)}{du} \\cdot \\frac{du}{dm} = f_X(u) \\cdot \\frac{1}{a} $$\nSubstituting $u = \\frac{m}{a}$ back into the expression:\n$$ f_Y(m) = \\frac{1}{a} f_X\\left(\\frac{m}{a}\\right) $$\nFinally, we replace $Y$, $X$, and $a$ with their definitions in the context of the problem: $Y=M_{ct}$, $X=M_t$, and $a=\\sqrt{c}$. The PDFs are denoted $f_{M_{ct}}(m)$ and $f_{M_t}(m)$.\nThis yields the relationship between the two PDFs:\n$$ f_{M_{ct}}(m) = \\frac{1}{\\sqrt{c}} f_{M_t}\\left(\\frac{m}{\\sqrt{c}}\\right) $$\nThis expression gives the PDF of the maximum at time $ct$ in terms of the PDF of the maximum at time $t$. For any given value $m$, the probability density is scaled by $\\frac{1}{\\sqrt{c}}$, and the function is evaluated at the correspondingly scaled point $\\frac{m}{\\sqrt{c}}$.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{c}} f_{M_t}\\left(\\frac{m}{\\sqrt{c}}\\right)}$$", "id": "3049947"}, {"introduction": "The theory of the Brownian maximum has powerful applications, one of the most important being the analysis of first hitting times. This problem [@problem_id:3049951] builds a bridge between the maximum process, $M_t$, and the time $\\tau_a$ it takes for Brownian motion to first reach a level $a$. By solving it, you will uncover a fascinating and counter-intuitive feature of random walks: an event that is certain to happen can still have an infinite expected waiting time.", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion with $B_{0} = 0$. For a fixed level $a  0$, define the first hitting time $\\tau_{a} := \\inf\\{t \\geq 0 : B_{t} = a\\}$ and the running maximum $M_{t} := \\sup_{0 \\leq s \\leq t} B_{s}$. Assume the fundamental properties of Brownian motion: for each $t  0$, $B_{t}$ is Gaussian with mean $0$ and variance $t$, the process has stationary and independent increments, and paths are continuous. Using only these foundations and the reflection principle, proceed as follows:\n- Establish the relationship between the running maximum and the marginal distribution of $B_{t}$ by showing, for each $t  0$ and $a  0$, that $\\mathbb{P}(M_{t} \\geq a)$ can be expressed in terms of $\\mathbb{P}(B_{t} \\geq a)$.\n- Deduce from this relationship the cumulative distribution function (CDF) $F_{\\tau_{a}}(t) := \\mathbb{P}(\\tau_{a} \\leq t)$ of the hitting time $\\tau_{a}$ for $t  0$, and then differentiate to obtain its probability density function (PDF) $f_{\\tau_{a}}(t)$.\n- Evaluate the integral $\\int_{0}^{\\infty} t \\, f_{\\tau_{a}}(t) \\, dt$ and determine whether it converges or diverges, justifying your conclusion from first principles without appealing to any pre-stated shortcut formulas. Conclude the value of $\\mathbb{E}[\\tau_{a}]$.\n\nYour final answer must be the value of $\\mathbb{E}[\\tau_{a}]$ expressed as a single closed-form mathematical expression. No rounding is required, and no physical units are involved.", "solution": "The problem asks for a multi-step derivation concerning a standard one-dimensional Brownian motion $\\{B_t\\}_{t \\geq 0}$ starting at $B_0=0$. We are asked to first relate the probability of the running maximum $M_t = \\sup_{0 \\leq s \\leq t} B_s$ exceeding a level $a > 0$ to the marginal probability of $B_t$ exceeding that level. Then, we are to find the distribution of the first hitting time $\\tau_a = \\inf\\{t \\geq 0: B_t = a\\}$ and finally compute its expectation $\\mathbb{E}[\\tau_a]$. The solution will proceed in three parts as requested.\n\n### Part 1: Distribution of the Running Maximum\n\nWe aim to find a relationship between $\\mathbb{P}(M_t \\geq a)$ and $\\mathbb{P}(B_t \\geq a)$ for any fixed $t>0$ and $a>0$. The event $\\{M_t \\geq a\\}$ means that the Brownian path has reached or exceeded the level $a$ at some time $s \\in [0, t]$.\n\nWe can partition the sample space based on the value of $B_t$. By the law of total probability, we can write:\n$$\n\\mathbb{P}(M_t \\geq a) = \\mathbb{P}(M_t \\geq a \\text{ and } B_t \\geq a) + \\mathbb{P}(M_t \\geq a \\text{ and } B_t  a)\n$$\nLet's analyze the first term. If the process is at or above level $a$ at time $t$, i.e., $B_t \\geq a$, then its maximum over the interval $[0, t]$ must also be at or above $a$, i.e., $M_t \\geq B_t$. This is because $M_t = \\sup_{0 \\leq s \\leq t} B_s \\geq B_t$. Therefore, the event $\\{B_t \\geq a\\}$ is a subset of the event $\\{M_t \\geq a\\}$. This implies that the intersection of these two events is simply the event $\\{B_t \\geq a\\}$ itself. So,\n$$\n\\mathbb{P}(M_t \\geq a \\text{ and } B_t \\geq a) = \\mathbb{P}(B_t \\geq a)\n$$\nNow we analyze the second term, $\\mathbb{P}(M_t \\geq a \\text{ and } B_t  a)$. This is the probability that the path reaches or exceeds level $a$ at some point but ends up below $a$ at time $t$. For this to happen, the path must have crossed level $a$ at some time $\\tau_a \\leq t$. This is where the reflection principle for Brownian motion is applied.\n\nThe reflection principle states that for any $a > 0$, the probability of a path starting at $0$ reaching level $a$ before time $t$ and ending at $B_t  a$ is equal to the probability of a path starting at $0$ and ending at $B_t > a$. To see this, consider a path $\\omega$ for which $M_t(\\omega) \\geq a$ and $B_t(\\omega)  a$. Let $\\tau_a(\\omega)$ be the first time this path hits $a$. We define a new path $\\tilde{\\omega}$ by reflecting the original path after time $\\tau_a(\\omega)$:\n$$\n\\tilde{B}_s(\\omega) = \\begin{cases} B_s(\\omega)  \\text{if } s \\leq \\tau_a(\\omega) \\\\ a - (B_s(\\omega) - a) = 2a - B_s(\\omega)  \\text{if } s > \\tau_a(\\omega) \\end{cases}\n$$\nBy construction, since $B_t(\\omega)  a$, the reflected path's value at time $t$ is $\\tilde{B}_t(\\omega) = 2a - B_t(\\omega) > 2a - a = a$. The map from $\\omega$ to $\\tilde{\\omega}$ is a bijection between the set of paths where $\\{M_t \\geq a, B_t  a\\}$ and the set of paths where $\\{B_t > a\\}$. The strong Markov property of Brownian motion and the symmetry of its increments imply that this map preserves probabilities. Therefore,\n$$\n\\mathbb{P}(M_t \\geq a \\text{ and } B_t  a) = \\mathbb{P}(B_t > a)\n$$\nSince $B_t$ follows a normal distribution, which is continuous, the probability of it being exactly equal to any value is $0$. Thus, $\\mathbb{P}(B_t > a) = \\mathbb{P}(B_t \\geq a)$.\n\nSubstituting these results back into our original equation:\n$$\n\\mathbb{P}(M_t \\geq a) = \\mathbb{P}(B_t \\geq a) + \\mathbb{P}(B_t > a) = \\mathbb{P}(B_t \\geq a) + \\mathbb{P}(B_t \\geq a)\n$$\nThis yields the fundamental relationship:\n$$\n\\mathbb{P}(M_t \\geq a) = 2 \\, \\mathbb{P}(B_t \\geq a)\n$$\n\n### Part 2: CDF and PDF of the First Hitting Time $\\tau_a$\n\nThe cumulative distribution function (CDF) of $\\tau_a$ is defined as $F_{\\tau_a}(t) = \\mathbb{P}(\\tau_a \\leq t)$. The event that the first hitting time $\\tau_a$ is less than or equal to $t$ is equivalent to the event that the running maximum $M_t$ is greater than or equal to $a$. This is because $B_0=0$ and the paths of a Brownian motion are continuous. If $M_t \\geq a$, the path must have visited $a$ at or before time $t$. Conversely, if $\\tau_a \\leq t$, then $B_{\\tau_a} = a$, so $M_t \\geq a$. Thus, $\\{\\tau_a \\leq t\\} = \\{M_t \\geq a\\}$.\n\nUsing the result from Part 1, we can write the CDF of $\\tau_a$ as:\n$$\nF_{\\tau_a}(t) = \\mathbb{P}(\\tau_a \\leq t) = \\mathbb{P}(M_t \\geq a) = 2 \\, \\mathbb{P}(B_t \\geq a)\n$$\nA standard Brownian motion $B_t$ at a fixed time $t$ is a normally distributed random variable with mean $0$ and variance $t$, i.e., $B_t \\sim \\mathcal{N}(0, t)$. We can express this in terms of a standard normal variable $Z \\sim \\mathcal{N}(0, 1)$ as $B_t = \\sqrt{t} Z$.\n$$\n\\mathbb{P}(B_t \\geq a) = \\mathbb{P}(\\sqrt{t} Z \\geq a) = \\mathbb{P}\\left(Z \\geq \\frac{a}{\\sqrt{t}}\\right)\n$$\nThe probability $\\mathbb{P}(Z \\geq z)$ can be written as an integral of the standard normal PDF, $\\phi(u) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{u^2}{2}\\right)$:\n$$\n\\mathbb{P}\\left(Z \\geq \\frac{a}{\\sqrt{t}}\\right) = \\int_{a/\\sqrt{t}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du\n$$\nSo, the CDF of $\\tau_a$ is:\n$$\nF_{\\tau_a}(t) = 2 \\int_{a/\\sqrt{t}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du\n$$\nTo find the probability density function (PDF), $f_{\\tau_a}(t)$, we differentiate the CDF with respect to $t$. Using the Leibniz integral rule ($\\frac{d}{dx} \\int_{g(x)}^{h(x)} f(u) du = f(h(x))h'(x) - f(g(x))g'(x)$), we have:\n$$\nf_{\\tau_a}(t) = \\frac{d}{dt} F_{\\tau_a}(t) = \\frac{d}{dt} \\left( 2 \\int_{a/\\sqrt{t}}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{u^2}{2}\\right) du \\right)\n$$\nThe upper limit is a constant, so its derivative is $0$. The lower limit is $g(t) = a t^{-1/2}$, and its derivative is $g'(t) = a(-\\frac{1}{2})t^{-3/2} = -\\frac{a}{2t^{3/2}}$.\n$$\nf_{\\tau_a}(t) = 2 \\left( 0 - \\left[ \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{a}{\\sqrt{t}}\\right)^2\\right) \\right] \\cdot \\left( -\\frac{a}{2t^{3/2}} \\right) \\right)\n$$\n$$\nf_{\\tau_a}(t) = 2 \\left( \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{a^2}{2t}\\right) \\frac{a}{2t^{3/2}} \\right)\n$$\nSimplifying this expression gives the PDF of the first hitting time $\\tau_a$:\n$$\nf_{\\tau_a}(t) = \\frac{a}{\\sqrt{2\\pi} t^{3/2}} \\exp\\left(-\\frac{a^2}{2t}\\right) \\quad \\text{for } t > 0\n$$\n\n### Part 3: Expectation of the First Hitting Time $\\mathbb{E}[\\tau_a]$\n\nThe expectation of $\\tau_a$ is given by the integral of $t$ times its PDF over its support $(0, \\infty)$:\n$$\n\\mathbb{E}[\\tau_a] = \\int_{0}^{\\infty} t \\, f_{\\tau_a}(t) \\, dt\n$$\nSubstituting the derived PDF:\n$$\n\\mathbb{E}[\\tau_a] = \\int_{0}^{\\infty} t \\left( \\frac{a}{\\sqrt{2\\pi} t^{3/2}} \\exp\\left(-\\frac{a^2}{2t}\\right) \\right) dt\n$$\nWe can simplify the integrand:\n$$\n\\mathbb{E}[\\tau_a] = \\frac{a}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} t \\cdot t^{-3/2} \\exp\\left(-\\frac{a^2}{2t}\\right) dt = \\frac{a}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} t^{-1/2} \\exp\\left(-\\frac{a^2}{2t}\\right) dt\n$$\nWe must now evaluate this improper integral and determine if it converges. The integral must be analyzed at its limits $t \\to 0^+$ and $t \\to \\infty$.\n\n1.  Behavior as $t \\to 0^+$: Let $y = 1/t$. As $t \\to 0^+$, $y \\to \\infty$. The integrand becomes $y^{1/2} \\exp(-a^2 y/2)$. Using L'HÃ´pital's rule multiple times shows that $\\lim_{y\\to\\infty} y^{1/2} \\exp(-a^2 y/2) = 0$. The integrand approaches $0$ at the lower limit of integration, so the integral converges on any interval of the form $[0, K]$ for finite $K > 0$.\n\n2.  Behavior as $t \\to \\infty$: As $t \\to \\infty$, the term $a^2/(2t) \\to 0$, and therefore $\\exp(-a^2/(2t)) \\to \\exp(0) = 1$.\n    For large $t$, the integrand behaves asymptotically like $t^{-1/2}$:\n    $$\n    t^{-1/2} \\exp\\left(-\\frac{a^2}{2t}\\right) \\sim t^{-1/2} \\quad \\text{as } t \\to \\infty\n    $$\n    We can use the limit comparison test for improper integrals. Consider the integral $\\int_{1}^{\\infty} t^{-p} dt$. This integral converges if and only if $p > 1$. In our case, the power is $p = 1/2$. Since $p = 1/2 \\leq 1$, the integral $\\int_{1}^{\\infty} t^{-1/2} dt$ diverges.\n    Formally, let $g(t) = t^{-1/2} \\exp(-a^2/(2t))$ and $h(t) = t^{-1/2}$.\n    $$\n    \\lim_{t\\to\\infty} \\frac{g(t)}{h(t)} = \\lim_{t\\to\\infty} \\frac{t^{-1/2} \\exp(-a^2/(2t))}{t^{-1/2}} = \\lim_{t\\to\\infty} \\exp\\left(-\\frac{a^2}{2t}\\right) = 1\n    $$\n    Since this limit is a finite positive number and the integral $\\int_{1}^{\\infty} h(t) dt = \\int_{1}^{\\infty} t^{-1/2} dt$ diverges, the integral $\\int_{1}^{\\infty} g(t) dt$ must also diverge. The integral for the expectation can be split as $\\int_{0}^{1} g(t) dt + \\int_{1}^{\\infty} g(t) dt$. The first part is finite, but the second part diverges to infinity.\n\nTherefore, the integral for $\\mathbb{E}[\\tau_a]$ diverges to $+\\infty$.\n\nConclusion: The expected time for a standard Brownian motion to first hit any level $a > 0$ is infinite.\n$$\n\\mathbb{E}[\\tau_a] = \\infty\n$$", "answer": "$$\\boxed{\\infty}$$", "id": "3049951"}]}