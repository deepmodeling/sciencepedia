{"hands_on_practices": [{"introduction": "The journey into Brownian motion begins with its foundational axioms. This first practice invites you to use these axioms—specifically the properties of its increments—to derive two of its most fundamental statistical characteristics: its mean and its covariance function. Mastering this calculation is the first step toward building a solid intuition for how this fascinating random process behaves over time [@problem_id:3048018].", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$, defined by the following properties:\n- $B_{0}=0$ almost surely (a.s.),\n- $t \\mapsto B_{t}$ has continuous sample paths,\n- for all $0 \\leq s  t$, the increment $B_{t}-B_{s}$ is independent of $\\mathcal{F}_{s}$ and is Gaussian (normal) with mean $0$ and variance $t-s$.\n\nUsing only the above defining properties, do the following:\n1. Prove that the process is centered, i.e., for every $t \\geq 0$, $\\mathbb{E}[B_{t}]=0$.\n2. Compute the second mixed moment $\\mathbb{E}[B_{s} B_{t}]$ as an explicit function of $(s,t) \\in [0,\\infty)^{2}$.\n\nYour final answer must be a single closed-form analytic expression for $\\mathbb{E}[B_{s} B_{t}]$ in terms of $s$ and $t$ (no units). No rounding is required.", "solution": "The problem is well-defined and requires proving two fundamental properties of a standard one-dimensional Brownian motion $\\{B_t\\}_{t \\geq 0}$ using its axiomatic definition. We will address each part of the problem sequentially. The properties given are:\n1. $B_{0}=0$ almost surely (a.s.).\n2. The sample paths $t \\mapsto B_{t}$ are continuous a.s.\n3. For any $0 \\leq s  t$, the increment $B_{t}-B_{s}$ is a Gaussian random variable with mean $0$ and variance $t-s$.\n4. For any $0 \\leq s  t$, the increment $B_{t}-B_{s}$ is independent of the filtration $\\mathcal{F}_{s}$, which contains the history of the process up to time $s$.\n\nPart 1: Prove that the process is centered, i.e., $\\mathbb{E}[B_{t}]=0$ for every $t \\geq 0$.\n\nWe consider two cases for the time $t$.\n\nCase (i): $t=0$.\nThe definition states that $B_{0}=0$ a.s. The expectation of a random variable that is equal to a constant almost surely is that constant. Therefore,\n$$ \\mathbb{E}[B_{0}] = \\mathbb{E}[0] = 0 $$\n\nCase (ii): $t  0$.\nWe can express the random variable $B_{t}$ as the sum of its initial value $B_{0}$ and the increment from time $0$ to $t$:\n$$ B_{t} = B_{0} + (B_{t} - B_{0}) $$\nBy the linearity of the expectation operator, we have:\n$$ \\mathbb{E}[B_{t}] = \\mathbb{E}[B_{0} + (B_{t} - B_{0})] = \\mathbb{E}[B_{0}] + \\mathbb{E}[B_{t} - B_{0}] $$\nFrom Case (i), we know that $\\mathbb{E}[B_{0}] = 0$.\nFor the second term, we use the third defining property with $s=0$. For $t0$, the increment $B_{t}-B_{0}$ is a Gaussian random variable with mean $0$ and variance $t-0=t$. The expectation of this random variable is its mean.\n$$ \\mathbb{E}[B_{t} - B_{0}] = 0 $$\nSubstituting these results back into the equation for $\\mathbb{E}[B_t]$, we get:\n$$ \\mathbb{E}[B_{t}] = 0 + 0 = 0 $$\nCombining both cases, we have proven that $\\mathbb{E}[B_{t}]=0$ for all $t \\geq 0$.\n\nPart 2: Compute the second mixed moment $\\mathbb{E}[B_{s} B_{t}]$ as an explicit function of $(s,t) \\in [0,\\infty)^{2}$.\n\nThe value of this expectation depends on the relative order of $s$ and $t$. We consider three cases.\n\nCase (i): $s = t$.\nThe expectation becomes:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[B_{t} B_{t}] = \\mathbb{E}[B_{t}^{2}] $$\nFor any random variable $X$, its variance is given by $\\text{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$. Rearranging, we have $\\mathbb{E}[X^2] = \\text{Var}(X) + (\\mathbb{E}[X])^2$.\nLetting $X=B_t$, and using the result from Part 1 that $\\mathbb{E}[B_t]=0$, we get:\n$$ \\mathbb{E}[B_{t}^{2}] = \\text{Var}(B_{t}) + (\\mathbb{E}[B_{t}])^{2} = \\text{Var}(B_{t}) + 0^{2} = \\text{Var}(B_{t}) $$\nTo find the variance of $B_t$, we consider the increment $B_t - B_0$. Since $B_0=0$ a.s., $\\text{Var}(B_t) = \\text{Var}(B_t - B_0)$.\nFrom the third property, for $s=0$ and $t0$, the increment $B_t - B_0$ has variance $t-0=t$. If $t=0$, $\\text{Var}(B_0)=\\text{Var}(0)=0$. Thus, for all $t \\geq 0$, $\\text{Var}(B_t) = t$.\nTherefore, for $s=t$, we have:\n$$ \\mathbb{E}[B_{t}^{2}] = t $$\n\nCase (ii): $0 \\leq s  t$.\nWe can write $B_t$ as the sum of $B_s$ and the subsequent increment $B_t - B_s$:\n$$ B_t = B_s + (B_t - B_s) $$\nSubstituting this into the expectation:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[B_{s}(B_{s} + (B_{t} - B_{s}))] $$\nBy linearity of expectation:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[B_{s}^{2}] + \\mathbb{E}[B_{s}(B_{t} - B_{s})] $$\nFrom Case (i) with $t$ replaced by $s$, we know that $\\mathbb{E}[B_{s}^{2}] = s$.\nFor the second term, $\\mathbb{E}[B_{s}(B_{t} - B_{s})]$, we use the independence property. The process $\\{B_t\\}$ is adapted to the filtration $\\{\\mathcal{F}_t\\}$, meaning $B_s$ is an $\\mathcal{F}_s$-measurable random variable. The fourth property states that the increment $B_t - B_s$ is independent of $\\mathcal{F}_s$. Consequently, $B_s$ and $B_t - B_s$ are independent random variables.\nThe expectation of the product of two independent random variables is the product of their expectations:\n$$ \\mathbb{E}[B_{s}(B_{t} - B_{s})] = \\mathbb{E}[B_{s}]\\mathbb{E}[B_{t} - B_{s}] $$\nFrom Part 1, we have $\\mathbb{E}[B_{s}]=0$. From the third property, the increment $B_t - B_s$ has mean $0$, so $\\mathbb{E}[B_{t} - B_{s}]=0$.\n$$ \\mathbb{E}[B_{s}(B_{t} - B_{s})] = 0 \\cdot 0 = 0 $$\nCombining the terms, for $0 \\leq s  t$:\n$$ \\mathbb{E}[B_{s} B_{t}] = s + 0 = s $$\n\nCase (iii): $0 \\leq t  s$.\nThis case is symmetric to Case (ii). By interchanging the roles of $s$ and $t$, the same logic applies. We expect the result to be $t$. Let's verify this explicitly.\nWe write $B_s = B_t + (B_s - B_t)$.\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[(B_{t} + (B_{s} - B_{t}))B_{t}] = \\mathbb{E}[B_{t}^{2}] + \\mathbb{E}[(B_{s} - B_{t})B_{t}] $$\nAs before, $\\mathbb{E}[B_{t}^{2}] = t$.\nThe increment $B_s - B_t$ is independent of $\\mathcal{F}_t$, and $B_t$ is $\\mathcal{F}_t$-measurable. Thus, they are independent.\n$$ \\mathbb{E}[(B_{s} - B_{t})B_{t}] = \\mathbb{E}[B_{s} - B_{t}] \\mathbb{E}[B_{t}] = 0 \\cdot 0 = 0 $$\nTherefore, for $0 \\leq t  s$:\n$$ \\mathbb{E}[B_{s} B_{t}] = t + 0 = t $$\n\nSummary:\n- If $s  t$, then $\\mathbb{E}[B_s B_t] = s$.\n- If $t  s$, then $\\mathbb{E}[B_s B_t] = t$.\n- If $s = t$, then $\\mathbb{E}[B_s B_t] = s = t$.\n\nAll three cases can be written concisely using the minimum function:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\min(s, t) $$\nThis expression gives the second mixed moment for all $(s,t) \\in [0,\\infty)^2$. Since the mean of the process is zero, this is also the covariance function, $\\text{Cov}(B_s, B_t) = \\min(s, t)$.", "answer": "$$ \\boxed{\\min(s, t)} $$", "id": "3048018"}, {"introduction": "While the mean and covariance provide a crucial summary, they don't tell the whole story. This exercise takes you a step further, asking you to derive the characteristic function of Brownian motion, which uniquely determines its entire probability distribution. By showing that the process's moments and Gaussian nature lead to the characteristic function of a normal distribution, you will build a more complete and rigorous understanding of why it serves as the canonical example of a Gaussian process [@problem_id:3048085].", "problem": "Let $\\{B_{t}\\}_{t \\ge 0}$ be a Brownian motion, defined as a centered Gaussian process (GP) with $B_{0} = 0$ almost surely, continuous sample paths, and covariance function $\\operatorname{Cov}(B_{s}, B_{t}) = \\min\\{s, t\\}$. The characteristic function (CF) of a real-valued random variable $X$ is $\\varphi_{X}(u) = \\mathbb{E}[\\exp(i u X)]$. Using only the defining properties of Brownian motion and standard facts about Gaussian distributions that follow from them, derive the CFs $\\varphi_{B_{t}}(u)$ and $\\varphi_{B_{t} - B_{s}}(u)$ for $0 \\le s  t$, and show they coincide with the CFs of the normal distributions $\\mathcal{N}(0, t)$ and $\\mathcal{N}(0, t - s)$, respectively. Provide your final answer as closed-form expressions in the variable $u$. No rounding is required.", "solution": "The problem requires the derivation of the characteristic functions (CFs) for the random variables $B_t$ and $B_t - B_s$, where $\\{B_{t}\\}_{t \\ge 0}$ is a standard Brownian motion. The derivation must be based on the provided definition of Brownian motion as a centered Gaussian process (GP) with $B_0 = 0$ almost surely and covariance function $\\operatorname{Cov}(B_s, B_t) = \\min\\{s, t\\}$.\n\nFirst, we derive the characteristic function of $B_t$, denoted $\\varphi_{B_t}(u)$, for a fixed $t  0$.\nBy definition, a Brownian motion is a Gaussian process. This implies that for any fixed time $t$, the random variable $B_t$ is a Gaussian (or normal) random variable. A Gaussian random variable is completely specified by its mean and variance.\nThe process is defined as \"centered,\" which signifies that the mean is zero for all time. Thus, the mean of $B_t$ is:\n$$\n\\mathbb{E}[B_t] = 0\n$$\nThe variance of $B_t$, denoted $\\operatorname{Var}(B_t)$, can be computed from the given covariance function:\n$$\n\\operatorname{Var}(B_t) = \\operatorname{Cov}(B_t, B_t) = \\min\\{t, t\\} = t\n$$\nTherefore, for any $t  0$, $B_t$ follows a normal distribution with mean $0$ and variance $t$, which is written as $B_t \\sim \\mathcal{N}(0, t)$.\n\nThe characteristic function of a general normal random variable $X$ with distribution $\\mathcal{N}(\\mu, \\sigma^2)$ is given by the formula $\\varphi_X(u) = \\mathbb{E}[\\exp(iuX)] = \\exp(i\\mu u - \\frac{1}{2}\\sigma^2 u^2)$.\nFor the random variable $B_t$, we have $\\mu = 0$ and $\\sigma^2 = t$. Substituting these into the general formula yields its characteristic function:\n$$\n\\varphi_{B_t}(u) = \\exp\\left(i(0)u - \\frac{1}{2}tu^2\\right) = \\exp\\left(-\\frac{1}{2}tu^2\\right)\n$$\nThis confirms that the characteristic function of $B_t$ is that of a $\\mathcal{N}(0, t)$ distribution.\n\nNext, we derive the characteristic function of the increment $B_t - B_s$ for $0 \\le s  t$.\nSince $\\{B_t\\}_{t \\ge 0}$ is a Gaussian process, any finite set of its random variables, such as $\\{B_s, B_t\\}$, forms a multivariate Gaussian random vector. A key property of multivariate Gaussian distributions is that any linear combination of its components is also a Gaussian random variable. The increment $B_t - B_s$ is a linear combination of $B_s$ and $B_t$ (specifically, $1 \\cdot B_t + (-1) \\cdot B_s$). Consequently, $B_t - B_s$ must be a Gaussian random variable.\nWe proceed to find its mean and variance. The mean, by linearity of expectation, is:\n$$\n\\mathbb{E}[B_t - B_s] = \\mathbb{E}[B_t] - \\mathbb{E}[B_s]\n$$\nSince the process is centered, $\\mathbb{E}[B_t] = 0$ and $\\mathbb{E}[B_s] = 0$, so:\n$$\n\\mathbb{E}[B_t - B_s] = 0 - 0 = 0\n$$\nThe variance of the increment is given by the formula:\n$$\n\\operatorname{Var}(B_t - B_s) = \\operatorname{Var}(B_t) + \\operatorname{Var}(B_s) - 2\\operatorname{Cov}(B_t, B_s)\n$$\nWe have already established that $\\operatorname{Var}(B_t) = t$ and $\\operatorname{Var}(B_s) = s$. The covariance term is given by $\\operatorname{Cov}(B_t, B_s) = \\min\\{s, t\\}$. Because the problem specifies $s  t$, we have $\\min\\{s, t\\} = s$. Substituting these values:\n$$\n\\operatorname{Var}(B_t - B_s) = t + s - 2s = t - s\n$$\nThus, the increment $B_t - B_s$ follows a normal distribution with mean $0$ and variance $t-s$, i.e., $B_t - B_s \\sim \\mathcal{N}(0, t-s)$.\n\nUsing the general formula for the characteristic function of a normal random variable $\\mathcal{N}(\\mu, \\sigma^2)$ with $\\mu=0$ and $\\sigma^2 = t-s$, we find the characteristic function of the increment:\n$$\n\\varphi_{B_t - B_s}(u) = \\exp\\left(i(0)u - \\frac{1}{2}(t-s)u^2\\right) = \\exp\\left(-\\frac{1}{2}(t-s)u^2\\right)\n$$\nThis confirms that the characteristic function of the increment $B_t - B_s$ is that of a $\\mathcal{N}(0, t-s)$ distribution.\n\nThe derived characteristic functions for $B_t$ and $B_t - B_s$ are $\\exp(-\\frac{1}{2}tu^2)$ and $\\exp(-\\frac{1}{2}(t-s)u^2)$, respectively.", "answer": "$$\\boxed{\\begin{pmatrix} \\exp\\left(-\\frac{1}{2}tu^{2}\\right)  \\exp\\left(-\\frac{1}{2}(t-s)u^{2}\\right) \\end{pmatrix}}$$", "id": "3048085"}, {"introduction": "One of the most remarkable and defining features of Brownian motion is the continuity of its sample paths, a property we often take as an axiom. This advanced practice allows you to rigorously justify this property by connecting the moments of the increments to the path's smoothness. By calculating the $p$-th absolute moment of an increment and applying the powerful Kolmogorov continuity criterion, you will see how moment estimates can guarantee the existence of a continuous version of the process, bridging the gap between statistical definitions and geometric reality [@problem_id:3048021].", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard Brownian motion, defined as a real-valued stochastic process with $B_{0} = 0$, stationary and independent increments, and for $0 \\leq s  t$, the increment $B_{t} - B_{s}$ is Gaussian with mean $0$ and variance $t - s$. Starting from these core properties and the definition of the Gaussian distribution, derive an exact formula for the moment $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$ for a fixed $p  0$. As a second task, use your derived expression to verify a continuity criterion of the Kolmogorov type by exhibiting constants $\\alpha  0$, $\\beta  0$, and $C  0$ (as functions of $p$) such that $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{\\alpha}\\right] \\leq C\\,|t - s|^{1 + \\beta}$ for all $s,t$ in a bounded interval, and deduce the largest Hölder continuity exponent guaranteed by this criterion in terms of $p$. Your final reported answer must be the exact closed-form expression for $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$ in terms of $p$, $t$, and $s$. No rounding is required.", "solution": "The problem is evaluated to be scientifically grounded, well-posed, objective, and formally solvable. All necessary information is provided, and there are no contradictions. The problem requires a standard derivation from the definition of Brownian motion and an application of the Kolmogorov continuity criterion.\n\nWe begin by calculating the moment $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$ for a fixed $p  0$. Let $X = B_{t} - B_{s}$. According to the problem statement, for any $t, s \\geq 0$, the increment $X$ is a Gaussian random variable with mean $0$ and variance $\\sigma^2 = |t-s|$. The probability density function (PDF) of $X$ is given by:\n$$f_{X}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\nThe $p$-th absolute moment of $X$ is defined as the expectation of $|X|^{p}$, which can be computed by integrating over the entire real line:\n$$\\mathbb{E}\\!\\left[|X|^{p}\\right] = \\int_{-\\infty}^{\\infty} |x|^{p} f_{X}(x) \\,dx = \\int_{-\\infty}^{\\infty} |x|^{p} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\,dx$$\nThe integrand $|x|^{p} \\exp(-x^2/(2\\sigma^2))$ is an even function of $x$. Thus, we can simplify the integral by considering only the positive real axis and multiplying by $2$:\n$$\\mathbb{E}\\!\\left[|X|^{p}\\right] = 2 \\int_{0}^{\\infty} x^{p} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\,dx = \\frac{2}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} x^{p} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\,dx$$\nTo evaluate this integral, we perform a change of variables. Let $u = \\frac{x^2}{2\\sigma^2}$. This implies $x^2 = 2\\sigma^2 u$, so $x = \\sqrt{2\\sigma^2 u} = \\sigma\\sqrt{2u}$. The differential is $dx = \\frac{\\sigma\\sqrt{2}}{2\\sqrt{u}} du = \\frac{\\sigma}{\\sqrt{2u}} du$. The limits of integration remain from $0$ to $\\infty$. Substituting these into the integral:\n\\begin{align*} \\mathbb{E}\\!\\left[|X|^{p}\\right] = \\frac{2}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\left(\\sigma\\sqrt{2u}\\right)^{p} \\exp(-u) \\frac{\\sigma}{\\sqrt{2u}} \\,du \\\\ = \\frac{2}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\sigma^{p} (2u)^{p/2} \\exp(-u) \\frac{\\sigma}{\\sqrt{2u}} \\,du \\\\ = \\frac{2 \\sigma^{p+1}}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} 2^{p/2} u^{p/2} \\exp(-u) \\frac{1}{\\sqrt{2} u^{1/2}} \\,du \\\\ = \\frac{2 \\sigma^{p}}{\\sqrt{2\\pi}} \\frac{2^{p/2}}{\\sqrt{2}} \\int_{0}^{\\infty} u^{p/2 - 1/2} \\exp(-u) \\,du \\\\ = \\frac{2^{1/2} \\sigma^{p}}{\\sqrt{\\pi}} 2^{p/2-1/2} \\int_{0}^{\\infty} u^{(p-1)/2} \\exp(-u) \\,du \\\\ = \\frac{2^{p/2} \\sigma^{p}}{\\sqrt{\\pi}} \\int_{0}^{\\infty} u^{\\frac{p+1}{2} - 1} \\exp(-u) \\,du \\end{align*}\nThe integral is the definition of the Gamma function, $\\Gamma(z) = \\int_{0}^{\\infty} t^{z-1}\\exp(-t)dt$, with $z = \\frac{p+1}{2}$.\nTherefore, the integral evaluates to $\\Gamma\\left(\\frac{p+1}{2}\\right)$.\nSubstituting this back, we get:\n$$\\mathbb{E}\\!\\left[|X|^{p}\\right] = \\frac{2^{p/2} \\sigma^{p}}{\\sqrt{\\pi}} \\Gamma\\left(\\frac{p+1}{2}\\right)$$\nRecalling that $\\sigma^2 = |t-s|$, we have $\\sigma^{p} = (\\sqrt{|t-s|})^{p} = |t-s|^{p/2}$. Thus, the final expression for the moment is:\n$$\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right] = \\frac{2^{p/2} \\Gamma\\left(\\frac{p+1}{2}\\right)}{\\sqrt{\\pi}} |t-s|^{p/2}$$\n\nNext, we address the second task concerning the Kolmogorov continuity criterion. The criterion states that if a stochastic process $\\{X_t\\}_{t \\geq 0}$ satisfies the condition $\\mathbb{E}\\!\\left[|X_{t} - X_{s}|^{\\alpha}\\right] \\leq C\\,|t - s|^{1 + \\beta}$ for some constants $\\alpha  0$, $\\beta  0$, and $C  0$, and for all $s,t$ in a bounded interval, then there exists a modification of the process whose sample paths are almost surely Hölder continuous with any exponent $\\gamma \\in (0, \\beta/\\alpha)$.\n\nWe use our derived expression for the moments of Brownian motion. Let us choose $\\alpha = p$ for some $p  0$. Our derived formula is an equality:\n$$\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right] = C_{p} |t-s|^{p/2}$$\nwhere $C_{p} = \\frac{2^{p/2} \\Gamma\\left(\\frac{p+1}{2}\\right)}{\\sqrt{\\pi}}$ is a positive constant depending only on $p$.\nTo satisfy the Kolmogorov criterion, we need to find $p$ such that the exponent of $|t-s|$ is greater than $1$. That is, we require $\\frac{p}{2}  1$, which implies $p  2$.\nFor any such fixed $p  2$, we can set $\\alpha = p$. The condition becomes:\n$$C_{p} |t-s|^{p/2} \\leq C |t-s|^{1+\\beta}$$\nWe can write the exponent $\\frac{p}{2}$ as $1 + \\left(\\frac{p}{2} - 1\\right)$. Let $\\beta = \\frac{p}{2} - 1$. Since $p  2$, we have $\\beta  0$.\nNow we can set $\\alpha = p  0$, $\\beta = \\frac{p}{2} - 1  0$, and $C = C_{p}  0$. With these choices, we have the equality:\n$$\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{\\alpha}\\right] = C |t-s|^{1+\\beta}$$\nThis satisfies the condition of the Kolmogorov continuity criterion. The theorem then guarantees that Brownian motion has a modification that is a.s. Hölder continuous for any exponent $\\gamma$ such that:\n$$0  \\gamma  \\frac{\\beta}{\\alpha} = \\frac{\\frac{p}{2} - 1}{p} = \\frac{1}{2} - \\frac{1}{p}$$\nThis result holds for any choice of $p  2$. To find the best possible guarantee on the Hölder exponent from this method, we can consider the limit as $p \\to \\infty$:\n$$\\lim_{p \\to \\infty} \\left(\\frac{1}{2} - \\frac{1}{p}\\right) = \\frac{1}{2}$$\nThis means that for any exponent $\\gamma  1/2$, we can choose a sufficiently large $p$ (specifically, $p  1/(1/2 - \\gamma)$) such that the Kolmogorov criterion guarantees $\\gamma$-Hölder continuity. Therefore, the criterion ensures that Brownian motion sample paths have a modification that is Hölder continuous for any exponent strictly less than $1/2$. The largest such exponent is the supremum over all possible $\\gamma$, which is $1/2$. It is a classical result that the paths are not Hölder continuous for exponent $1/2$.\n\nThe problem asks for the single, final expression for $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$, which we derived first.", "answer": "$$\n\\boxed{\\frac{2^{p/2} \\Gamma\\left(\\frac{p+1}{2}\\right)}{\\sqrt{\\pi}} |t-s|^{p/2}}\n$$", "id": "3048021"}]}