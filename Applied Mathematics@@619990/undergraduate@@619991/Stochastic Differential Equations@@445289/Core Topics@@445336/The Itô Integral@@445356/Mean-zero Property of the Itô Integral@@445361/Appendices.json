{"hands_on_practices": [{"introduction": "The mean-zero property of the Itô integral is most clearly understood by starting with the simplest case: a non-random, deterministic integrand. This foundational exercise [@problem_id:3066033] guides you through a proof from first principles, demonstrating how the property arises directly from the zero-mean nature of Brownian motion increments. By building the integral from simple step functions, you will see why the result holds regardless of the integrand's specific shape or size.", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard Brownian motion (also called a Wiener process) on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$ satisfying the usual conditions, with $W_{0}=0$, independent and stationary increments, and for $0 \\leq s < t$, the increment $W_{t}-W_{s}$ is normally distributed with mean $0$ and variance $t-s$. Let $g:[0,T]\\to\\mathbb{R}$ be a deterministic function such that $\\int_{0}^{T} |g(u)|^{2}\\,du < \\infty$. For fixed $0 \\leq s < t \\leq T$, the Itô integral $\\int_{s}^{t} g(u)\\,dW_{u}$ is defined as the $L^{2}(\\Omega)$-limit of stochastic Riemann sums built from deterministic step-function approximations to $g$ on partitions of $[s,t]$.\n\nStarting from the core properties of Brownian motion increments and the construction of the Itô integral via $L^{2}$ limits of sums with deterministic coefficients, compute the expectation $E\\!\\left[\\int_{s}^{t} g(u)\\,dW_{u}\\right]$ and justify each step of your reasoning. Your derivation must not invoke any unproven shortcut identities; it should proceed from the defining properties of the Itô integral and Brownian motion. Explicitly address why the sign and magnitude of $g$ play no role in the value of this expectation. Express your final answer as a single real number. No rounding is required and no units are involved.", "solution": "The problem is to compute the expectation $E\\!\\left[\\int_{s}^{t} g(u)\\,dW_{u}\\right]$, where $g(u)$ is a deterministic, square-integrable function and $\\{W_t\\}_{t \\geq 0}$ is a standard Brownian motion. The derivation must proceed from the fundamental definitions.\n\nThe construction of the Itô integral for a general deterministic function $g \\in L^{2}([s,t])$ proceeds in two stages. First, the integral is defined for simple functions (step functions), and then it is extended to general functions in $L^{2}([s,t])$ via a limit process. We will follow this structure to compute the expectation.\n\n**Step 1: The Itô integral for simple functions**\n\nLet $\\phi:[s,t] \\to \\mathbb{R}$ be a simple function. This means that we can find a partition of the interval $[s, t]$, denoted by $s = \\tau_0 < \\tau_1 < \\dots < \\tau_n = t$, such that $\\phi(u)$ is constant on each subinterval $[\\tau_j, \\tau_{j+1})$. Let the value of $\\phi(u)$ on $[\\tau_j, \\tau_{j+1})$ be the constant $c_j$. We can write $\\phi(u)$ as:\n$$\n\\phi(u) = \\sum_{j=0}^{n-1} c_j \\mathbb{I}_{[\\tau_j, \\tau_{j+1})}(u)\n$$\nwhere $\\mathbb{I}_{A}(u)$ is the indicator function for the set $A$.\n\nBy definition, the Itô integral of this simple function $\\phi(u)$ with respect to the Brownian motion $W_u$ is given by the sum:\n$$\n\\int_{s}^{t} \\phi(u)\\,dW_{u} = \\sum_{j=0}^{n-1} c_j (W_{\\tau_{j+1}} - W_{\\tau_j})\n$$\nThis expression is a finite sum of random variables. We can now compute its expectation. Using the linearity of the expectation operator, we have:\n$$\nE\\left[\\int_{s}^{t} \\phi(u)\\,dW_{u}\\right] = E\\left[\\sum_{j=0}^{n-1} c_j (W_{\\tau_{j+1}} - W_{\\tau_j})\\right] = \\sum_{j=0}^{n-1} E\\left[c_j (W_{\\tau_{j+1}} - W_{\\tau_j})\\right]\n$$\nSince each $c_j$ is a deterministic constant, we can pull it out of the expectation:\n$$\nE\\left[\\int_{s}^{t} \\phi(u)\\,dW_{u}\\right] = \\sum_{j=0}^{n-1} c_j E\\left[W_{\\tau_{j+1}} - W_{\\tau_j}\\right]\n$$\nA fundamental property of standard Brownian motion, as stated in the problem, is that its increments have a mean of zero. For any $s_1 < s_2$, the increment $W_{s_2} - W_{s_1}$ is a normally distributed random variable with mean $E[W_{s_2} - W_{s_1}] = 0$. Applying this property to each term in the sum, with $s_1 = \\tau_j$ and $s_2 = \\tau_{j+1}$, we get:\n$$\nE\\left[W_{\\tau_{j+1}} - W_{\\tau_j}\\right] = 0 \\quad \\text{for all } j = 0, 1, \\dots, n-1\n$$\nSubstituting this into the expression for the expectation of the integral gives:\n$$\nE\\left[\\int_{s}^{t} \\phi(u)\\,dW_{u}\\right] = \\sum_{j=0}^{n-1} c_j \\cdot 0 = 0\n$$\nThus, for any simple function $\\phi(u)$, the expectation of its Itô integral is zero.\n\n**Step 2: Extension to general $L^2$ functions**\n\nThe problem states that $g:[0,T] \\to \\mathbb{R}$ is a deterministic function such that $\\int_0^T |g(u)|^2 du < \\infty$. This implies that $g$ belongs to the Hilbert space $L^2([s,t])$. A key result in measure theory is that the set of simple functions is dense in $L^2([s,t])$. This means there exists a sequence of simple functions, $\\{\\phi_k(u)\\}_{k=1}^\\infty$, that converges to $g(u)$ in the $L^2$ norm:\n$$\n\\lim_{k \\to \\infty} \\int_{s}^{t} |g(u) - \\phi_k(u)|^2 \\,du = 0\n$$\nThe Itô integral for $g(u)$ is then defined as the limit in $L^2(\\Omega)$ of the integrals of the approximating simple functions $\\phi_k(u)$:\n$$\n\\int_{s}^{t} g(u)\\,dW_{u} = L^2(\\Omega)\\text{-}\\lim_{k \\to \\infty} \\int_{s}^{t} \\phi_k(u)\\,dW_{u}\n$$\nLet $I(f) = \\int_s^t f(u) dW_u$. The convergence in $L^2(\\Omega)$ means that $E\\left[|I(g) - I(\\phi_k)|^2\\right] \\to 0$ as $k \\to \\infty$.\n\nWe want to compute $E[I(g)]$. To do this, we need to show that we can interchange the expectation and the limit:\n$$\nE[I(g)] = E\\left[L^2(\\Omega)\\text{-}\\lim_{k \\to \\infty} I(\\phi_k)\\right] = \\lim_{k \\to \\infty} E[I(\\phi_k)]\n$$\nThis interchange is justified because convergence in $L^2(\\Omega)$ implies convergence in $L^1(\\Omega)$. This can be seen using the Cauchy-Schwarz inequality or Jensen's inequality for the expectation operator: for any random variable $X$, $(E[|X|])^2 \\leq E[X^2]$.\nLet $X_k = I(g) - I(\\phi_k)$. We have:\n$$\n\\left(E\\left[|I(g) - I(\\phi_k)|\\right]\\right)^2 \\leq E\\left[|I(g) - I(\\phi_k)|^2\\right]\n$$\nSince $I(\\phi_k) \\to I(g)$ in $L^2(\\Omega)$, the right-hand side converges to $0$ as $k \\to \\infty$. This implies that the left-hand side must also converge to $0$, so $E[|I(g) - I(\\phi_k)|] \\to 0$. This is the definition of convergence in $L^1(\\Omega)$.\n\nThe continuity of the expectation operator with respect to $L^1$ convergence gives us:\n$$\n|E[I(g)] - E[I(\\phi_k)]| = |E[I(g) - I(\\phi_k)]| \\leq E[|I(g) - I(\\phi_k)|]\n$$\nAs $k \\to \\infty$, the right-hand side goes to $0$, which implies $\\lim_{k \\to \\infty} E[I(\\phi_k)] = E[I(g)]$.\n\nFrom Step 1, we established that for every simple function $\\phi_k(u)$ in the sequence, its Itô integral has an expectation of zero:\n$$\nE[I(\\phi_k)] = E\\left[\\int_{s}^{t} \\phi_k(u)\\,dW_{u}\\right] = 0 \\quad \\text{for all } k\n$$\nTherefore, we can conclude:\n$$\nE\\left[\\int_{s}^{t} g(u)\\,dW_{u}\\right] = \\lim_{k \\to \\infty} E[I(\\phi_k)] = \\lim_{k \\to \\infty} 0 = 0\n$$\n\n**Justification regarding the sign and magnitude of $g(u)$**\n\nThe final result, $0$, is independent of the specific functional form of $g(u)$, including its sign and magnitude, as long as it satisfies the square-integrability condition $g \\in L^2([s,t])$. The reason for this is rooted in the fundamental structure of the Itô integral with a deterministic integrand.\n\nIn the simple function case, the expectation is a sum of terms $c_j E[W_{\\tau_{j+1}} - W_{\\tau_j}]$. Each term is a product of a deterministic coefficient $c_j$ (representing the magnitude and sign of the function $\\phi(u)$ on a subinterval) and the expectation of a Brownian increment, which is always zero. The product $c_j \\times 0$ is always $0$, irrespective of the value of $c_j$. So, for simple functions, the sign and magnitude have no effect on the expectation.\n\nSince the integral for a general function $g(u)$ is constructed as a limit of integrals of simple functions, this property is inherited in the limit. The core mechanism is the pairing of a deterministic function with the increments of a zero-mean process. This structure ensures that, upon taking the expectation, the zero-mean property of the Brownian motion increments dominates, rendering the expectation of the entire integral zero. The role of the $L^2$ condition on $g(u)$ is solely to ensure that the integral is well-defined as a limit in $L^2(\\Omega)$, not to influence the value of its mean. The magnitude of $g(u)$ does affect the variance of the integral, as shown by the Itô isometry ($E[|I(g)|^2] = \\int_s^t |g(u)|^2 du$), but not its expectation.\n\nThe final answer is the real number $0$.", "answer": "$$\n\\boxed{0}\n$$", "id": "3066033"}, {"introduction": "Moving beyond deterministic functions, we can ask if the mean-zero property holds when the integrand is itself a stochastic process. This practice [@problem_id:3066040] addresses this question by tackling the classic integral of Brownian motion $W_t$ with respect to itself. You will use the celebrated Itô's formula to find a surprising closed-form expression for this integral and confirm that its expectation is indeed zero, illustrating how the property extends to adapted stochastic processes.", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion with $W_{0}=0$, and let $T>0$ be a fixed deterministic time. Using only the fundamental properties of Brownian motion and the Itô formula for twice continuously differentiable functions, first derive an explicit expression for the stochastic integral $\\int_{0}^{T} W_{t}\\,dW_{t}$ in terms of $W_{T}$ and $T$. Then compute the expectation $\\mathbb{E}\\!\\left[\\int_{0}^{T} W_{t}\\,dW_{t}\\right]$. Express your final answer as an exact real number.", "solution": "The problem asks for two results concerning the Itô stochastic integral $\\int_{0}^{T} W_{t}\\,dW_{t}$. First, we must derive an explicit expression for this integral in terms of the Brownian motion $W_T$ at the terminal time $T$ and $T$ itself. Second, we must compute the expectation of this integral. The derivation is constrained to use only the fundamental properties of Brownian motion and the Itô formula.\n\nLet $\\{W_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion starting at $W_{0}=0$. Let $f(x)$ be a twice continuously differentiable function. Itô's formula for the process $X_t = f(W_t)$ states that its differential is given by:\n$$df(W_t) = f'(W_t)\\,dW_t + \\frac{1}{2}f''(W_t)\\,(dW_t)^2$$\nIn the context of Itô calculus, the quadratic variation of Brownian motion is $(dW_t)^2 = dt$. Therefore, the formula becomes:\n$$df(W_t) = f'(W_t)\\,dW_t + \\frac{1}{2}f''(W_t)\\,dt$$\nTo find an expression for the integral $\\int_{0}^{T} W_{t}\\,dW_{t}$, we need to select a function $f(x)$ such that the term $W_{t}\\,dW_{t}$ appears in the expression for $df(W_t)$. Let us choose the function $f(x) = \\frac{1}{2}x^2$. This function is twice continuously differentiable with respect to $x$. Its derivatives are:\n$$f'(x) = \\frac{d}{dx}\\left(\\frac{1}{2}x^2\\right) = x$$\n$$f''(x) = \\frac{d}{dx}(x) = 1$$\nSubstituting these derivatives into Itô's formula for $f(W_t) = \\frac{1}{2}W_t^2$:\n$$d\\left(\\frac{1}{2}W_t^2\\right) = W_t\\,dW_t + \\frac{1}{2}(1)\\,dt$$\nRearranging this equation to isolate the term $W_t\\,dW_t$, we obtain:\n$$W_t\\,dW_t = d\\left(\\frac{1}{2}W_t^2\\right) - \\frac{1}{2}\\,dt$$\nNow, we integrate both sides of this equation from the initial time $t=0$ to the terminal time $t=T$:\n$$\\int_{0}^{T} W_{t}\\,dW_{t} = \\int_{0}^{T} d\\left(\\frac{1}{2}W_t^2\\right) - \\int_{0}^{T} \\frac{1}{2}\\,dt$$\nThe first integral on the right-hand side is the integral of an exact differential, which evaluates to the change in the function between the endpoints:\n$$\\int_{0}^{T} d\\left(\\frac{1}{2}W_t^2\\right) = \\frac{1}{2}W_T^2 - \\frac{1}{2}W_0^2$$\nThe second integral is a standard Riemann integral of a constant:\n$$\\int_{0}^{T} \\frac{1}{2}\\,dt = \\frac{1}{2}(T-0) = \\frac{1}{2}T$$\nCombining these results, we get:\n$$\\int_{0}^{T} W_{t}\\,dW_{t} = \\left(\\frac{1}{2}W_T^2 - \\frac{1}{2}W_0^2\\right) - \\frac{1}{2}T$$\nThe problem specifies that the Brownian motion starts at zero, so $W_0=0$. Substituting this initial condition yields the explicit expression for the integral:\n$$\\int_{0}^{T} W_{t}\\,dW_{t} = \\frac{1}{2}W_T^2 - \\frac{1}{2}T$$\nThis completes the first part of the problem.\n\nFor the second part, we must compute the expectation of this integral. Using the expression derived above and the linearity of the expectation operator $\\mathbb{E}$:\n$$\\mathbb{E}\\!\\left[\\int_{0}^{T} W_{t}\\,dW_{t}\\right] = \\mathbb{E}\\!\\left[\\frac{1}{2}W_T^2 - \\frac{1}{2}T\\right] = \\frac{1}{2}\\mathbb{E}[W_T^2] - \\mathbb{E}\\!\\left[\\frac{1}{2}T\\right]$$\nSince $T$ is a fixed deterministic time, it is a constant. The expectation of a constant is the constant itself:\n$$\\mathbb{E}\\!\\left[\\frac{1}{2}T\\right] = \\frac{1}{2}T$$\nNext, we need to evaluate $\\mathbb{E}[W_T^2]$. By the definition of a standard Brownian motion, for any time $t \\geq 0$, the random variable $W_t$ is normally distributed with mean $0$ and variance $t$. Thus, $W_T \\sim \\mathcal{N}(0, T)$.\nThe mean and variance are given by:\n$$\\mathbb{E}[W_T] = 0$$\n$$\\text{Var}(W_T) = T$$\nThe variance is defined as $\\text{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$. Applying this to $W_T$:\n$$\\text{Var}(W_T) = \\mathbb{E}[W_T^2] - (\\mathbb{E}[W_T])^2$$\nSubstituting the known values for the mean and variance:\n$$T = \\mathbb{E}[W_T^2] - (0)^2$$\nThis implies that the second moment of $W_T$ is equal to its variance:\n$$\\mathbb{E}[W_T^2] = T$$\nNow we can substitute this result back into the expression for the expectation of the integral:\n$$\\mathbb{E}\\!\\left[\\int_{0}^{T} W_{t}\\,dW_{t}\\right] = \\frac{1}{2}(T) - \\frac{1}{2}T = 0$$\nThus, the expectation of the stochastic integral is $0$. This result is an instance of the general property that Itô integrals of a suitable class of integrands with respect to Brownian motion are martingales, and martingales starting at $0$ have an expectation of $0$.", "answer": "$$\\boxed{0}$$", "id": "3066040"}, {"introduction": "The non-anticipating nature of the integrand is a cornerstone of Itô's calculus, but why is it so essential for the mean-zero property? This final exercise [@problem_id:3066037] provides a crucial counterexample by constructing an integrand that \"looks into the future\" of the Brownian path. By directly computing the expectation, you will discover that it is non-zero, revealing the breakdown that occurs when the assumption of non-anticipation is violated.", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a standard Brownian motion (also called a Wiener process) with $W_{0} = 0$. Fix times $t_{k}$ and $t_{k+1}$ with $0 \\leq t_{k} < t_{k+1}$. Define the random variable $H_{k} := W_{t_{k+1}}$. Compute the expectation\n$$\\mathbb{E}\\!\\left[H_{k}\\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right]$$\nusing only the defining properties of Brownian motion: Gaussian increments with mean $0$, variance equal to the time increment, independence of increments over disjoint intervals, and the covariance structure $\\operatorname{Cov}(W_{s}, W_{t}) = \\min\\{s, t\\}$. Express your final answer as a closed-form analytic expression in terms of $t_{k}$ and $t_{k+1}$.", "solution": "We are asked to compute the expectation $\\mathbb{E}\\!\\left[H_{k}\\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right]$.\nThe givens are:\n1.  $\\{W_{t}\\}_{t \\geq 0}$ is a standard Brownian motion with $W_{0} = 0$.\n2.  The times $t_{k}$ and $t_{k+1}$ are fixed, satisfying $0 \\leq t_{k} < t_{k+1}$.\n3.  The random variable $H_{k}$ is defined as $H_{k} := W_{t_{k+1}}$.\n\nFirst, we substitute the definition of $H_{k}$ into the expression for the expectation:\n$$\n\\mathbb{E}\\!\\left[H_{k}\\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right] = \\mathbb{E}\\!\\left[W_{t_{k+1}}\\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right]\n$$\nBy applying the linearity of the expectation operator, we can expand the product inside the expectation:\n$$\n\\mathbb{E}\\!\\left[W_{t_{k+1}} \\cdot W_{t_{k+1}} - W_{t_{k+1}} \\cdot W_{t_{k}}\\right] = \\mathbb{E}\\!\\left[W_{t_{k+1}}^{2}\\right] - \\mathbb{E}\\!\\left[W_{t_{k+1}}W_{t_{k}}\\right]\n$$\nTo evaluate the two terms on the right-hand side, we use the defining properties of a standard Brownian motion as specified in the problem statement. Specifically, for any times $s, t \\geq 0$:\n- The mean of the process at time $t$ is $\\mathbb{E}[W_t] = 0$.\n- The variance of the process at time $t$ is $\\operatorname{Var}(W_t) = t$. Since the mean is $0$, the variance is equal to the second moment: $\\operatorname{Var}(W_t) = \\mathbb{E}[W_t^2] - (\\mathbb{E}[W_t])^2 = \\mathbb{E}[W_t^2] = t$.\n- The covariance of the process at two times $s$ and $t$ is given by $\\operatorname{Cov}(W_s, W_t) = \\min\\{s, t\\}$. Since the means are zero, the covariance is equal to the cross-moment: $\\operatorname{Cov}(W_s, W_t) = \\mathbb{E}[W_s W_t] - \\mathbb{E}[W_s]\\mathbb{E}[W_t] = \\mathbb{E}[W_s W_t]$.\n\nNow we can compute each term separately.\n\nFor the first term, $\\mathbb{E}\\!\\left[W_{t_{k+1}}^{2}\\right]$, we use the property that the second moment of a standard Brownian motion at time $t$ is equal to $t$. Here, the time is $t_{k+1}$, so:\n$$\n\\mathbb{E}\\!\\left[W_{t_{k+1}}^{2}\\right] = t_{k+1}\n$$\nFor the second term, $\\mathbb{E}\\!\\left[W_{t_{k+1}}W_{t_{k}}\\right]$, we use the covariance property. This expectation is precisely the covariance between $W_{t_{k+1}}$ and $W_{t_{k}}$:\n$$\n\\mathbb{E}\\!\\left[W_{t_{k+1}}W_{t_{k}}\\right] = \\operatorname{Cov}(W_{t_{k+1}}, W_{t_{k}})\n$$\nThe covariance is given by the minimum of the two time indices. Since we are given that $t_{k} < t_{k+1}$, we have:\n$$\n\\operatorname{Cov}(W_{t_{k+1}}, W_{t_{k}}) = \\min\\{t_{k+1}, t_{k}\\} = t_{k}\n$$\nTherefore,\n$$\n\\mathbb{E}\\!\\left[W_{t_{k+1}}W_{t_{k}}\\right] = t_{k}\n$$\nFinally, we substitute these two results back into our expanded expression for the expectation:\n$$\n\\mathbb{E}\\!\\left[W_{t_{k+1}}^{2}\\right] - \\mathbb{E}\\!\\left[W_{t_{k+1}}W_{t_{k}}\\right] = t_{k+1} - t_{k}\n$$\nThis provides the final answer as a closed-form analytic expression in terms of $t_k$ and $t_{k+1}$.\n\nAlternatively, one may use the property of independent increments. We write $W_{t_{k+1}}$ as the sum of $W_{t_k}$ and the increment from $t_k$ to $t_{k+1}$: $W_{t_{k+1}} = W_{t_k} + (W_{t_{k+1}}-W_{t_k})$. Substituting this into the original expression:\n$$\n\\mathbb{E}\\!\\left[\\left(W_{t_{k}} + (W_{t_{k+1}}-W_{t_k})\\right) \\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right] = \\mathbb{E}\\!\\left[W_{t_{k}}\\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right] + \\mathbb{E}\\!\\left[\\left(W_{t_{k+1}} - W_{t_{k}}\\right)^{2}\\right]\n$$\nThe random variable $W_{t_k}$ depends on the path of the Brownian motion up to time $t_k$, while the increment $W_{t_{k+1}} - W_{t_{k}}$ depends on the path over the disjoint interval $(t_k, t_{k+1}]$. Therefore, $W_{t_k}$ and $(W_{t_{k+1}} - W_{t_{k}})$ are independent. For independent random variables, the expectation of their product is the product of their expectations:\n$$\n\\mathbb{E}\\!\\left[W_{t_{k}}\\left(W_{t_{k+1}} - W_{t_{k}}\\right)\\right] = \\mathbb{E}\\!\\left[W_{t_{k}}\\right] \\mathbb{E}\\!\\left[W_{t_{k+1}} - W_{t_{k}}\\right] = 0 \\cdot 0 = 0\n$$\nThe second term is the second moment of the increment $W_{t_{k+1}} - W_{t_{k}}$. This increment is a random variable with mean $0$ and variance $t_{k+1} - t_k$. Its second moment is therefore equal to its variance:\n$$\n\\mathbb{E}\\!\\left[\\left(W_{t_{k+1}} - W_{t_{k}}\\right)^{2}\\right] = \\operatorname{Var}(W_{t_{k+1}} - W_{t_{k}}) = t_{k+1} - t_k\n$$\nSumming the two terms gives $0 + (t_{k+1} - t_k) = t_{k+1} - t_k$, which confirms the result obtained using the covariance formula.", "answer": "$$\n\\boxed{t_{k+1} - t_{k}}\n$$", "id": "3066037"}]}