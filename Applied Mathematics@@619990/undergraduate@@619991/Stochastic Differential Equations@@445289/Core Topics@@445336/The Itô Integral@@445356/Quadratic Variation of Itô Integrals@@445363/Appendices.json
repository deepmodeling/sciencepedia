{"hands_on_practices": [{"introduction": "A central concept in stochastic calculus is the decomposition of a semimartingale into a \"rough\" local martingale part and a \"smooth\" finite variation part (the drift). This first exercise establishes a foundational principle: that the quadratic variation of a process, which quantifies its total squared volatility, is entirely determined by its local martingale component. By working through this problem [@problem_id:3071350], you will prove from first principles that adding a smooth drift does not alter the quadratic variation, a key insight for simplifying many calculations.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\geq 0},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions, and let $W=(W_t)_{t\\geq 0}$ be a standard Brownian motion adapted to $(\\mathcal{F}_t)_{t\\geq 0}$. Fix $t>0$. Let $\\sigma=(\\sigma_s)_{0\\leq s\\leq t}$ and $\\mu=(\\mu_s)_{0\\leq s\\leq t}$ be bounded, $(\\mathcal{F}_s)_{s\\geq 0}$-predictable processes such that $\\int_{0}^{t}\\sigma_s^{2}\\,ds<\\infty$ almost surely. Define the continuous local martingale $M=(M_s)_{0\\leq s\\leq t}$ by\n$$\nM_s=\\int_{0}^{s}\\sigma_u\\,dW_u,\n$$\nand the finite variation process $A=(A_s)_{0\\leq s\\leq t}$ by\n$$\nA_s=\\int_{0}^{s}\\mu_u\\,du.\n$$\nConsider the continuous semimartingale $X=(X_s)_{0\\leq s\\leq t}$ given by $X_s=M_s+A_s$. Using the definition of Quadratic Variation (QV) as the limit of sums of squared increments along refining time partitions and only foundational properties of stochastic integrals (such as Itô isometry), compute the quadratic variation $[X]_t$. Express your final answer as a closed-form symbolic expression in terms of $\\sigma$. This computation should make clear that adding a finite variation process can change drift but does not change quadratic variation. No numerical approximation is required.", "solution": "The problem requires the computation of the quadratic variation $[X]_t$ for the continuous semimartingale $X_s = M_s + A_s$, where $M_s = \\int_{0}^{s} \\sigma_u \\, dW_u$ is a continuous local martingale and $A_s = \\int_{0}^{s} \\mu_u \\, du$ is a continuous finite variation process. The computation must be based on the definition of quadratic variation as the limit of sums of squared increments.\n\nLet $\\Pi_n = \\{0 = t_0^{(n)} < t_1^{(n)} < \\dots < t_{k_n}^{(n)} = t\\}$ be a sequence of partitions of the interval $[0, t]$ such that the mesh of the partition, $\\|\\Pi_n\\| = \\max_{j} (t_{j+1}^{(n)} - t_j^{(n)})$, converges to $0$ as $n \\to \\infty$. The quadratic variation of the process $X$ at time $t$, denoted $[X]_t$, is defined as the limit in probability of the sum of squared increments over this sequence of partitions:\n$$\n[X]_t = \\operatorname{p-lim}_{n \\to \\infty} \\sum_{j=0}^{k_n-1} (X_{t_{j+1}^{(n)}} - X_{t_j^{(n)}})^2\n$$\n\nLet's denote the increment of a process $Y$ over the interval $[t_j^{(n)}, t_{j+1}^{(n)}]$ as $\\Delta Y_j^{(n)} = Y_{t_{j+1}^{(n)}} - Y_{t_j^{(n)}}$. For simplicity, we will drop the superscript $(n)$ in the notation for the partition points and increments, writing $t_j$ and $\\Delta Y_j$. The increment of $X$ is given by:\n$$\n\\Delta X_j = X_{t_{j+1}} - X_{t_j} = (M_{t_{j+1}} + A_{t_{j+1}}) - (M_{t_j} + A_{t_j}) = (M_{t_{j+1}} - M_{t_j}) + (A_{t_{j+1}} - A_{t_j}) = \\Delta M_j + \\Delta A_j\n$$\nThe sum of squared increments can be expanded as:\n$$\n\\sum_{j=0}^{k_n-1} (\\Delta X_j)^2 = \\sum_{j=0}^{k_n-1} (\\Delta M_j + \\Delta A_j)^2 = \\sum_{j=0}^{k_n-1} (\\Delta M_j)^2 + 2\\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) + \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2\n$$\nBy the properties of limits in probability, the quadratic variation $[X]_t$ is the sum of the limits of these three terms, provided they exist:\n$$\n[X]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta M_j)^2 + 2 \\cdot \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) + \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2\n$$\nThese three limits correspond to the quadratic variations $[M]_t$, $[A]_t$, and the covariation $[M, A]_t$, respectively. We will analyze each term individually.\n\nFirst, consider the term involving the finite variation process $A_s = \\int_{0}^{s} \\mu_u \\, du$. The process $\\mu = (\\mu_s)_{0 \\le s \\le t}$ is given as bounded. This means there exists a constant $K > 0$ such that $|\\mu_s(\\omega)| \\le K$ for almost all $(\\omega, s) \\in \\Omega \\times [0, t]$. The increment $\\Delta A_j$ is:\n$$\n\\Delta A_j = A_{t_{j+1}} - A_{t_j} = \\int_{t_j}^{t_{j+1}} \\mu_u \\, du\n$$\nWe can bound its absolute value:\n$$\n|\\Delta A_j| = \\left| \\int_{t_j}^{t_{j+1}} \\mu_u \\, du \\right| \\le \\int_{t_j}^{t_{j+1}} |\\mu_u| \\, du \\le K (t_{j+1} - t_j) = K \\Delta t_j\n$$\nNow, consider the sum of squared increments of $A$:\n$$\n0 \\le \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 \\le \\sum_{j=0}^{k_n-1} (K \\Delta t_j)^2 = K^2 \\sum_{j=0}^{k_n-1} (\\Delta t_j)^2\n$$\nWe can further bound this sum:\n$$\n\\sum_{j=0}^{k_n-1} (\\Delta t_j)^2 \\le \\left( \\max_{0 \\le j \\le k_n-1} \\Delta t_j \\right) \\left( \\sum_{j=0}^{k_n-1} \\Delta t_j \\right) = \\|\\Pi_n\\| \\cdot t\n$$\nCombining these inequalities, we have:\n$$\n0 \\le \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 \\le K^2 t \\|\\Pi_n\\|\n$$\nAs $\\|\\Pi_n\\| \\to 0$, the right-hand side converges to $0$. By the Squeeze Theorem, the sum of squared increments for $A$ also converges to $0$. Thus, the quadratic variation of the finite variation process $A$ is zero:\n$$\n[A]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 = 0\n$$\n\nNext, we analyze the cross term, which defines the covariation $[M, A]_t$. We use the Cauchy-Schwarz inequality for sums:\n$$\n\\left| \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) \\right| \\le \\left( \\sum_{j=0}^{k_n-1} (\\Delta M_j)^2 \\right)^{1/2} \\left( \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 \\right)^{1/2}\n$$\nTaking the limit as $\\|\\Pi_n\\| \\to 0$, we have already shown that the second term on the right-hand side converges to $\\sqrt{[A]_t} = \\sqrt{0} = 0$. The first term on the right-hand side converges in probability to $\\sqrt{[M]_t}$. Since $\\int_0^t \\sigma_s^2 ds < \\infty$ almost surely, $[M]_t$ is an almost surely finite random variable. Therefore, the product converges in probability to $0$:\n$$\n\\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\left| \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) \\right| = 0\n$$\nThis implies that the covariation is zero:\n$$\n[M, A]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) = 0\n$$\n\nFinally, we consider the first term, $\\sum_{j=0}^{k_n-1} (\\Delta M_j)^2$. The process $M$ is defined as the Itô integral $M_s = \\int_{0}^{s} \\sigma_u \\, dW_u$. A foundational result in the theory of stochastic integration is that the quadratic variation of such a process is given by the integral of the square of the integrand. That is:\n$$\n[M]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} \\left( \\int_{t_j}^{t_{j+1}} \\sigma_u \\, dW_u \\right)^2 = \\int_0^t \\sigma_s^2 \\, ds\n$$\nThe problem statement allows the use of such foundational properties.\n\nCombining the results for the three terms, we find the quadratic variation of $X_t$:\n$$\n[X]_t = [M]_t + 2[M, A]_t + [A]_t = \\int_0^t \\sigma_s^2 \\, ds + 2(0) + 0 = \\int_0^t \\sigma_s^2 \\, ds\n$$\nThis derivation makes it clear that the addition of a continuous process of finite variation, $A_s$, which alters the drift of the process $X_s$, does not affect its quadratic variation. The quadratic variation is determined solely by the local martingale part, $M_s$.", "answer": "$$\n\\boxed{\\int_{0}^{t}\\sigma_s^{2}\\,ds}\n$$", "id": "3071350"}, {"introduction": "Building on the principle that quadratic variation ignores drift, we now explore how to compute it for a concrete semimartingale. This practice [@problem_id:3071180] examines the process $X_t = B_t^2$, which Itô's formula decomposes into an Itô integral (its martingale part) and a time integral (its finite variation part). By deriving its quadratic variation from the fundamental definition and comparing it with the result from its Itô decomposition, you will gain a deeper, hands-on understanding of the crucial formula $[\\int H_s dW_s]_t = \\int H_s^2 ds$.", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion starting at $B_{0}=0$. Define the process $X_{t} = B_{t}^{2}$ for $t \\geq 0$. Using only fundamental properties of Brownian motion and the definition of quadratic variation for continuous semimartingales, derive an explicit expression for the quadratic variation $[X]_{t}$ as a functional of the Brownian path $\\{B_{s}\\}_{0 \\leq s \\leq t}$. Then, explain how your expression is consistent with the decomposition $X_{t} = 2 \\int_{0}^{t} B_{s} \\, dB_{s} + [B]_{t}$ obtained from Itô's formula, where $[B]_{t}$ denotes the quadratic variation of Brownian motion. Provide your final answer for $[X]_{t}$ as a single closed-form expression. No rounding is required.", "solution": "The solution proceeds in two parts as requested. First, we derive the quadratic variation $[X]_t$ from its definition. Second, we demonstrate consistency with the result obtained via Itô's formula.\n\n**Part 1: Derivation of $[X]_t$ from the Definition**\n\nLet $X_t$ be a continuous semimartingale. Its quadratic variation over the interval $[0, t]$, denoted $[X]_t$, is defined as the limit in probability of the sum of squared increments over a sequence of partitions of the interval. Let $\\Pi_n = \\{0 = t_0^{(n)} < t_1^{(n)} < \\dots < t_{k_n}^{(n)} = t\\}$ be a sequence of partitions of $[0, t]$ such that the mesh $||\\Pi_n|| = \\max_{i} (t_{i+1}^{(n)} - t_i^{(n)})$ approaches $0$ as $n \\to \\infty$. The quadratic variation is given by:\n$$ [X]_t = \\operatorname*{plim}_{n \\to \\infty} \\sum_{i=0}^{k_n-1} (X_{t_{i+1}^{(n)}} - X_{t_i^{(n)}})^2 $$\nFor simplicity, we will drop the superscript $(n)$ and let $||\\Pi|| \\to 0$. The process is $X_t = B_t^2$. The increment of $X_t$ over a subinterval $[t_i, t_{i+1}]$ is:\n$$ X_{t_{i+1}} - X_{t_i} = B_{t_{i+1}}^2 - B_{t_i}^2 $$\nLet $\\Delta B_i = B_{t_{i+1}} - B_{t_i}$. We can write $B_{t_{i+1}} = B_{t_i} + \\Delta B_i$. The increment of $X_t$ can be expanded as:\n$$ X_{t_{i+1}} - X_{t_i} = (B_{t_{i+1}} - B_{t_i})(B_{t_{i+1}} + B_{t_i}) = (\\Delta B_i)(B_{t_i} + \\Delta B_i + B_{t_i}) = 2B_{t_i}\\Delta B_i + (\\Delta B_i)^2 $$\nNow, we must square this increment and sum over the partition:\n$$ \\sum_{i=0}^{k-1} (X_{t_{i+1}} - X_{t_i})^2 = \\sum_{i=0}^{k-1} (2B_{t_i}\\Delta B_i + (\\Delta B_i)^2)^2 $$\nExpanding the squared term:\n$$ (2B_{t_i}\\Delta B_i + (\\Delta B_i)^2)^2 = 4B_{t_i}^2 (\\Delta B_i)^2 + 4B_{t_i} (\\Delta B_i)^3 + (\\Delta B_i)^4 $$\nWe analyze the limit of the sum of each of these three terms as $||\\Pi|| \\to 0$.\n\n1.  **First term:** $\\sum_{i=0}^{k-1} 4B_{t_i}^2 (\\Delta B_i)^2$.\n    This sum is a stochastic integral in disguise. For a continuous process $Y_s$, the integral $\\int_0^t Y_s d[B]_s$ can be defined as the limit in probability of sums of the form $\\sum_i Y_{t_i} ([B]_{t_{i+1}} - [B]_{t_i})$. Since for standard Brownian motion, $[B]_t = t$, this is $\\int_0^t Y_s ds$. The sum $\\sum_i Y_{t_i} (\\Delta B_i)^2$ is a discrete approximation to this integral. The process $Y_s = 4B_s^2$ is continuous. It is a standard result in stochastic calculus that\n    $$ \\operatorname*{plim}_{||\\Pi|| \\to 0} \\sum_{i=0}^{k-1} 4B_{t_i}^2 (\\Delta B_i)^2 = \\int_0^t 4B_s^2 d[B]_s $$\n    Since $d[B]_s = ds$ for standard Brownian motion, the limit is:\n    $$ \\int_0^t 4B_s^2 ds $$\n\n2.  **Second term:** $\\sum_{i=0}^{k-1} 4B_{t_i} (\\Delta B_i)^3$.\n    We show that this term converges to $0$ in $L^1$, which implies convergence in probability. The increment $\\Delta B_i = B_{t_{i+1}} - B_{t_i}$ is independent of the sigma-algebra $\\mathcal{F}_{t_i}$, to which $B_{t_i}$ is adapted. Let $\\Delta t_i = t_{i+1} - t_i$. The moments of $\\Delta B_i \\sim N(0, \\Delta t_i)$ are $E[\\Delta B_i] = 0$, $E[(\\Delta B_i)^2] = \\Delta t_i$, $E[|\\Delta B_i|^3] = E[|Z|^3](\\Delta t_i)^{3/2}$ where $Z \\sim N(0,1)$, and $E[(\\Delta B_i)^3] = 0$.\n    The expectation of the absolute value of the sum is:\n    $$ E\\left[ \\left| \\sum_{i=0}^{k-1} 4B_{t_i} (\\Delta B_i)^3 \\right| \\right] \\leq \\sum_{i=0}^{k-1} 4 E\\left[ |B_{t_i} (\\Delta B_i)^3| \\right] = \\sum_{i=0}^{k-1} 4 E[|B_{t_i}|] E[|(\\Delta B_i)^3|] $$\n    $E[|B_{t_i}|] = \\sqrt{2/\\pi}\\sqrt{t_i} \\leq \\sqrt{2t/\\pi}$ for $t_i \\in [0, t]$. Let $C_3 = E[|Z|^3]$, a constant.\n    $$ \\leq \\sum_{i=0}^{k-1} 4 \\sqrt{\\frac{2t}{\\pi}} C_3 (\\Delta t_i)^{3/2} \\leq 4 \\sqrt{\\frac{2t}{\\pi}} C_3 \\sqrt{||\\Pi||} \\sum_{i=0}^{k-1} \\Delta t_i = 4 t \\sqrt{\\frac{2t}{\\pi}} C_3 \\sqrt{||\\Pi||} $$\n    As $||\\Pi|| \\to 0$, this upper bound goes to $0$. Thus, the sum converges to $0$ in $L^1$.\n\n3.  **Third term:** $\\sum_{i=0}^{k-1} (\\Delta B_i)^4$.\n    We again show this term converges to $0$ in $L^1$.\n    $$ E\\left[ \\sum_{i=0}^{k-1} (\\Delta B_i)^4 \\right] = \\sum_{i=0}^{k-1} E[(\\Delta B_i)^4] $$\n    For a normal random variable $Y \\sim N(0, \\sigma^2)$, $E[Y^4] = 3\\sigma^4$. Here, $\\sigma^2 = \\Delta t_i$.\n    $$ E\\left[ \\sum_{i=0}^{k-1} (\\Delta B_i)^4 \\right] = \\sum_{i=0}^{k-1} 3(\\Delta t_i)^2 \\leq 3 ||\\Pi|| \\sum_{i=0}^{k-1} \\Delta t_i = 3t||\\Pi|| $$\n    As $||\\Pi|| \\to 0$, the expectation goes to $0$. Thus, the sum converges to $0$ in $L^1$.\n\nCombining the limits of the three terms, we find:\n$$ [X]_t = \\int_0^t 4B_s^2 ds + 0 + 0 = 4\\int_0^t B_s^2 ds $$\nThis expression is a functional of the Brownian path $\\{B_s\\}_{0 \\leq s \\leq t}$.\n\n**Part 2: Consistency with Itô's Formula**\n\nThe problem provides the decomposition of $X_t$ from Itô's formula: $X_{t} = 2 \\int_{0}^{t} B_{s} \\, dB_{s} + [B]_{t}$.\nLet's first verify this decomposition. Let $f(x) = x^2$. Then $f'(x) = 2x$ and $f''(x) = 2$. By Itô's formula for a function of a Brownian motion,\n$$ dX_t = df(B_t) = f'(B_t)dB_t + \\frac{1}{2}f''(B_t)d[B]_t $$\n$$ d(B_t^2) = 2B_t dB_t + \\frac{1}{2}(2)d[B]_t = 2B_t dB_t + d[B]_t $$\nIntegrating from $0$ to $t$ and using $X_0=B_0^2=0$ and $[B]_0=0$:\n$$ X_t - X_0 = \\int_0^t 2B_s dB_s + \\int_0^t d[B]_s \\implies X_t = 2\\int_0^t B_s dB_s + [B]_t $$\nThis confirms the given decomposition.\n\nNow, we compute the quadratic variation of $X_t$ from this semimartingale representation.\nLet $M_t = 2\\int_0^t B_s dB_s$ be the local martingale part and $A_t = [B]_t = t$ be the finite variation part.\nThe quadratic variation of a semimartingale $X_t = M_t + A_t$ is given by the polarization identity:\n$$ [X]_t = [M+A, M+A]_t = [M,M]_t + 2[M,A]_t + [A,A]_t $$\nWe evaluate each term:\n-   $[A,A]_t = [t,t]_t$. Since $A_t=t$ is a process of bounded (and hence finite) variation, its quadratic variation is zero. The sum of squared increments is $\\sum_i (t_{i+1}-t_i)^2 \\leq ||\\Pi|| \\sum_i (t_{i+1}-t_i) = t||\\Pi|| \\to 0$. So, $[A,A]_t = 0$.\n-   $[M,A]_t$. The cross-variation of a continuous local martingale and a continuous process of finite variation is zero. Thus, $[M,A]_t = 0$.\n-   $[M,M]_t = [2\\int_0^\\cdot B_s dB_s, 2\\int_0^\\cdot B_s dB_s]_t$. For an Itô integral of the form $I_t = \\int_0^t H_s dB_s$, its quadratic variation is given by $[I]_t = \\int_0^t H_s^2 d[B]_s$. In our case, the integrand is $H_s = 2B_s$.\n    Therefore,\n    $$ [M]_t = \\int_0^t (2B_s)^2 d[B]_s = \\int_0^t 4B_s^2 ds $$\n\nSubstituting these back into the expression for $[X]_t$:\n$$ [X]_t = \\int_0^t 4B_s^2 ds + 2(0) + 0 = 4\\int_0^t B_s^2 ds $$\nThis result is identical to the one derived from the fundamental definition. This demonstrates the internal consistency of the theory of stochastic calculus, showing that the definitional approach and the more powerful Itô calculus yield the same result. The final expression for the quadratic variation of $X_t=B_t^2$ is an integral functional of the Brownian path.", "answer": "$$\n\\boxed{4 \\int_{0}^{t} B_{s}^{2} \\, ds}\n$$", "id": "3071180"}, {"introduction": "With the foundational principles in place, we can now apply them to calculate the quadratic variation for a specific and important Itô integral. This exercise [@problem_id:2992283] focuses on the process $X_t = \\int_0^t \\exp(-s) dB_s$, which appears in the Ornstein-Uhlenbeck model for mean reversion. This problem will guide you through a powerful and widely used technique—employing an auxiliary process and the Itô product rule—to derive an explicit, closed-form solution for $[X]_t$, solidifying your practical problem-solving skills in stochastic calculus.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\ge 0},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions and carrying a standard one-dimensional Brownian motion $B=(B_{t})_{t\\ge 0}$. Define the continuous local martingale $X=(X_{t})_{t\\ge 0}$ by\n$$\nX_{t}=\\int_{0}^{t}\\exp(-s)\\,dB_{s}.\n$$\nStarting only from the foundational definitions of the Itô integral and quadratic variation for continuous semimartingales, together with the Itô formula for twice continuously differentiable functions, compute the quadratic variation $[X]_{t}$ as an explicit function of $t$. Then prove, by identifying its derivative with respect to Lebesgue measure on $\\mathbb{R}_{+}$, that $[X]_{t}$ is increasing and absolutely continuous in $t$, and determine its Radon–Nikodym derivative. Your final answer must be a single closed-form analytic expression for $[X]_{t$}.", "solution": "The problem is to compute the quadratic variation $[X]_{t}$ of the continuous local martingale a.k.a. Itô process $X_t$ defined by\n$$\nX_{t}=\\int_{0}^{t}\\exp(-s)\\,dB_{s}\n$$\nwhere $B_t$ is a standard one-dimensional Brownian motion. The computation must be based on the Itô formula and foundational definitions. We are also asked to prove certain properties of $[X]_t$.\n\nThe differential of the process $X_t$ is given by\n$$\ndX_t = \\exp(-t)\\,dB_t.\n$$\nThis is an Itô process with zero drift and a volatility term of $\\exp(-t)$. According to the problem statement, we must derive its quadratic variation $[X]_t$ using the Itô formula, rather than directly applying the standard result for Itô integrals.\n\nA standard method to achieve this is to define an auxiliary process and compute its differential in two different ways, then equate the results. Let us define the process $Y_t$ as\n$$\nY_t = \\exp(t) X_t.\n$$\nWe can compute the differential $dY_t$ using the Itô product rule, which is a specific application of the Itô formula for a function $f(u,v)=uv$. Let $u(t) = \\exp(t)$. Then $dY_t = d(u(t)X_t)$ is given by\n$$\ndY_t = (du(t))X_t + u(t)dX_t + d[u, X]_t.\n$$\nSince $u(t) = \\exp(t)$ is a deterministic, continuously differentiable function, its differential is $du(t) = \\exp(t)dt$. As a process of finite variation, its quadratic variation is zero, and its covariation with any continuous local martingale $X_t$ is also zero. Thus, $d[u, X]_t = 0$.\nSubstituting the known terms, we get\n$$\ndY_t = (\\exp(t)dt)X_t + \\exp(t)(\\exp(-t)dB_t) = \\exp(t)X_t dt + dB_t.\n$$\nThis expression gives the stochastic differential equation (SDE) for $Y_t$. It shows that $Y_t$ is an Itô process with drift coefficient $a_t = \\exp(t)X_t$ and diffusion coefficient $b_t = 1$. The quadratic variation of such a process is given by $d[Y]_t = b_t^2 d[B]_t$. Since $B_t$ is a standard Brownian motion, $[B]_t = t$, so $d[B]_t = dt$. Therefore,\n$$\nd[Y]_t = 1^2 dt = dt.\n$$\nIntegrating from $0$ to $t$ and noting that $Y_0 = \\exp(0)X_0 = 0$, we find that the quadratic variation of $Y_t$ is simply\n$$\n[Y]_t = t.\n$$\nNow, we will compute the differential of $Y_t^2$ in two ways.\n\nFirst, applying Itô's formula for the function $f(y) = y^2$ to the process $Y_t$:\n$$\nd(Y_t^2) = 2Y_t dY_t + d[Y]_t.\n$$\nSubstituting the expressions for $dY_t$ and $d[Y]_t$:\n$$\nd(Y_t^2) = 2Y_t(\\exp(t)X_t dt + dB_t) + dt.\n$$\nSubstitute $Y_t = \\exp(t)X_t$:\n$$\nd(Y_t^2) = 2\\exp(t)X_t(\\exp(t)X_t dt + dB_t) + dt = 2\\exp(2t)X_t^2 dt + 2\\exp(t)X_t dB_t + dt.\n$$\nThis gives us our first expression for $d(Y_t^2)$. It is a semimartingale with a martingale part $2\\exp(t)X_t dB_t$ and a finite variation part $(2\\exp(2t)X_t^2 + 1)dt$. Both integrands are predictable processes since $X_t$ is continuous and adapted.\n\nSecond, we express $Y_t^2$ in terms of $X_t$ directly: $Y_t^2 = (\\exp(t)X_t)^2 = \\exp(2t)X_t^2$. We apply Itô's formula for a time-dependent function $f(t,x) = \\exp(2t)x^2$ to the process $X_t$. The general formula is\n$$\nd f(t, X_t) = \\frac{\\partial f}{\\partial t}dt + \\frac{\\partial f}{\\partial x}dX_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}d[X]_t.\n$$\nThe partial derivatives are:\n$$\n\\frac{\\partial f}{\\partial t}(t,x) = 2\\exp(2t)x^2, \\quad \\frac{\\partial f}{\\partial x}(t,x) = 2\\exp(2t)x, \\quad \\frac{\\partial^2 f}{\\partial x^2}(t,x) = 2\\exp(2t).\n$$\nSubstituting these into the formula, with $x=X_t$ and $dX_t = \\exp(-t)dB_t$:\n$$\nd(Y_t^2) = d(\\exp(2t)X_t^2) = 2\\exp(2t)X_t^2 dt + 2\\exp(2t)X_t dX_t + \\frac{1}{2}(2\\exp(2t))d[X]_t\n$$\n$$\nd(Y_t^2) = 2\\exp(2t)X_t^2 dt + 2\\exp(2t)X_t (\\exp(-t)dB_t) + \\exp(2t)d[X]_t\n$$\n$$\nd(Y_t^2) = 2\\exp(2t)X_t^2 dt + 2\\exp(t)X_t dB_t + \\exp(2t)d[X]_t.\n$$\nThis gives our second expression for $d(Y_t^2)$.\n\nBy the uniqueness of the decomposition of a semimartingale into a local martingale and a predictable finite-variation process, the two expressions for $d(Y_t^2)$ must be equal.\n$$\n(2\\exp(2t)X_t^2 + 1)dt + 2\\exp(t)X_t dB_t = (2\\exp(2t)X_t^2 dt + \\exp(2t)d[X]_t) + 2\\exp(t)X_t dB_t.\n$$\nThe local martingale parts are identical. Equating the finite variation parts:\n$$\n(2\\exp(2t)X_t^2 + 1)dt = 2\\exp(2t)X_t^2 dt + \\exp(2t)d[X]_t.\n$$\nSubtracting the common term $2\\exp(2t)X_t^2 dt$ from both sides, we get:\n$$\ndt = \\exp(2t)d[X]_t.\n$$\nSolving for $d[X]_t$, we find:\n$$\nd[X]_t = \\exp(-2t)dt.\n$$\nTo find $[X]_t$, we integrate from $0$ to $t$. Since $X_0=0$, we have $[X]_0=0$.\n$$\n[X]_t = \\int_0^t d[X]_s = \\int_0^t \\exp(-2s) ds.\n$$\nEvaluating the integral:\n$$\n[X]_t = \\left[ -\\frac{1}{2}\\exp(-2s) \\right]_0^t = -\\frac{1}{2}\\exp(-2t) - \\left(-\\frac{1}{2}\\exp(0)\\right) = \\frac{1}{2}(1 - \\exp(-2t)).\n$$\nThis is the explicit closed-form expression for $[X]_t$.\n\nNext, we prove that $[X]_t$ is increasing and absolutely continuous.\nThe derivative of $[X]_t$ with respect to $t$ is given by the Fundamental Theorem of Calculus:\n$$\n\\frac{d}{dt}[X]_t = \\frac{d}{dt}\\int_0^t \\exp(-2s) ds = \\exp(-2t).\n$$\nSince $\\exp(-2t) > 0$ for all $t \\ge 0$, the derivative is strictly positive, which implies that $[X]_t$ is a strictly increasing function of $t$.\n\nA function $F(t) = \\int_0^t f(s)ds$ is absolutely continuous on an interval if the integrand $f$ is Lebesgue integrable on that interval. The integrand here is $f(t) = \\exp(-2t)$, which is a continuous function on $\\mathbb{R}_+$. Any continuous function on a compact interval $[0, T]$ is integrable. Thus, $[X]_t$ is absolutely continuous on any interval $[0, T]$ for $T>0$, and therefore on $\\mathbb{R}_+$.\n\nFinally, we determine the Radon–Nikodym derivative of the measure induced by $[X]_t$ with respect to the Lebesgue measure on $\\mathbb{R}_+$. The relation $d[X]_t = \\exp(-2t)dt$ states precisely that the measure induced by $[X]_t$ is absolutely continuous with respect to the Lebesgue measure $dt$, and that its Radon–Nikodym derivative is the function $\\exp(-2t)$.\n$$\n\\frac{d[X]}{d\\lambda}(t) = \\exp(-2t),\n$$\nwhere $\\lambda$ denotes the Lebesgue measure.\n\nThe problem requires a single closed-form analytic expression for $[X]_t$ as the final answer.\n$$\n[X]_t = \\frac{1}{2}(1 - \\exp(-2t)).\n$$", "answer": "$$\n\\boxed{\\frac{1}{2}(1 - \\exp(-2t))}\n$$", "id": "2992283"}]}