{"hands_on_practices": [{"introduction": "The multidimensional Itô formula is fundamentally a tool from stochastic calculus, but its essential ingredients—the gradient and the Hessian matrix—come directly from multivariable calculus. This first exercise provides crucial practice in computing these objects for simple, yet common, functions. Mastering these foundational calculations [@problem_id:3067820] is the first step toward confidently applying the Itô formula in more complex stochastic settings.", "problem": "Let $d \\in \\mathbb{N}$ with $d \\geq 2$ and let $x=(x_{1},\\dots,x_{d})^{\\top} \\in \\mathbb{R}^{d}$. Consider the functions $f:\\mathbb{R}^{d}\\to\\mathbb{R}$ given by $f(x)=\\|x\\|^{2}$, $f(x)=x_{i}x_{j}$ for fixed indices $i,j \\in \\{1,\\dots,d\\}$, and $f(x)=x_{k}$ for a fixed index $k \\in \\{1,\\dots,d\\}$. In the context of the multidimensional Itô formula, one needs the gradient $\\nabla f$ and the Hessian $D^{2}f$ of $f$. Starting from the fundamental definitions of the gradient as the column vector of first-order partial derivatives and the Hessian as the matrix of second-order partial derivatives, compute $\\nabla f(x)$ and $D^{2}f(x)$ for each of the three functions listed, and verify the symmetry of the Hessian in each case by appealing to the equality of mixed partial derivatives for twice continuously differentiable functions.\n\nUse the following notations: for $m,n \\in \\{1,\\dots,d\\}$, the Kronecker delta $\\delta_{mn}$ is defined by $\\delta_{mn}=1$ if $m=n$ and $\\delta_{mn}=0$ otherwise; $e_{\\ell} \\in \\mathbb{R}^{d}$ denotes the $\\ell$-th standard basis vector; and $E_{mn} \\in \\mathbb{R}^{d \\times d}$ denotes the matrix with a $1$ in the $(m,n)$ entry and $0$ elsewhere.\n\nProvide your final answer as a single row matrix with three entries, in order corresponding to $f(x)=\\|x\\|^{2}$, $f(x)=x_{i}x_{j}$, and $f(x)=x_{k}$, where each entry is the ordered pair $\\big(\\nabla f(x), D^{2}f(x)\\big)$. The final answer must be a single closed-form analytic expression. No rounding is required.", "solution": "The problem is evaluated as valid, as it is a well-posed, scientifically grounded problem in multivariable calculus with direct relevance to stochastic differential equations. All definitions are standard and the problem is self-contained. We proceed with the solution.\n\nThe gradient of a scalar function $f: \\mathbb{R}^d \\to \\mathbb{R}$ is the column vector of its first-order partial derivatives, $(\\nabla f(x))_m = \\frac{\\partial f}{\\partial x_m}$ for $m \\in \\{1, \\dots, d\\}$. The Hessian is the $d \\times d$ matrix of its second-order partial derivatives, $(D^2 f(x))_{mn} = \\frac{\\partial^2 f}{\\partial x_m \\partial x_n}$ for $m, n \\in \\{1, \\dots, d\\}$. We compute these quantities for each of the three given functions.\n\nFirst, consider the function $f(x) = \\|x\\|^2$.\nThe squared Euclidean norm is defined as $\\|x\\|^2 = \\sum_{l=1}^d x_l^2$.\nTo find the gradient, we compute the partial derivative with respect to each component $x_m$:\n$$\n\\frac{\\partial f}{\\partial x_m} = \\frac{\\partial}{\\partial x_m} \\left( \\sum_{l=1}^d x_l^2 \\right) = \\sum_{l=1}^d \\frac{\\partial}{\\partial x_m}(x_l^2)\n$$\nThe derivative $\\frac{\\partial}{\\partial x_m}(x_l^2)$ equals $2x_l$ if $l=m$ and $0$ if $l \\neq m$. Using the Kronecker delta, this is $2x_l \\delta_{lm}$.\n$$\n\\frac{\\partial f}{\\partial x_m} = \\sum_{l=1}^d 2x_l \\delta_{lm} = 2x_m\n$$\nThe gradient is the column vector of these components: $\\nabla f(x) = (2x_1, 2x_2, \\dots, 2x_d)^\\top = 2x$.\n\nTo find the Hessian, we compute the second-order partial derivatives:\n$$\n(D^2 f(x))_{mn} = \\frac{\\partial^2 f}{\\partial x_m \\partial x_n} = \\frac{\\partial}{\\partial x_m} \\left( \\frac{\\partial f}{\\partial x_n} \\right) = \\frac{\\partial}{\\partial x_m} (2x_n) = 2 \\delta_{mn}\n$$\nThe Hessian matrix is therefore the diagonal matrix with all diagonal entries equal to $2$, which is $2I_d$, where $I_d$ is the $d \\times d$ identity matrix.\nThe function $f(x)=\\|x\\|^2$ is a polynomial and thus is infinitely differentiable ($C^\\infty$). By Clairaut's theorem, its mixed partial derivatives must be equal. We verify this: $(D^2 f(x))_{mn} = 2\\delta_{mn}$ and $(D^2 f(x))_{nm} = 2\\delta_{nm}$. Since $\\delta_{mn} = \\delta_{nm}$, the Hessian matrix is symmetric, as expected.\nFor this function, the ordered pair is $\\big(\\nabla f(x), D^2 f(x)\\big) = \\left( 2x, 2I_d \\right)$.\n\nSecond, consider the function $f(x) = x_i x_j$ for fixed indices $i,j \\in \\{1,\\dots,d\\}$.\nWe compute the partial derivative with respect to $x_m$ using the product rule:\n$$\n\\frac{\\partial f}{\\partial x_m} = \\frac{\\partial}{\\partial x_m} (x_i x_j) = \\left(\\frac{\\partial x_i}{\\partial x_m}\\right) x_j + x_i \\left(\\frac{\\partial x_j}{\\partial x_m}\\right) = \\delta_{im}x_j + x_i\\delta_{jm}\n$$\nThe gradient vector $\\nabla f(x)$ is the vector whose $m$-th component is $\\delta_{im}x_j + x_i\\delta_{jm}$. This can be expressed using the standard basis vectors $e_\\ell$ as $\\nabla f(x) = x_j e_i + x_i e_j$. This compact form is valid for both $i=j$ (where it yields $2x_i e_i$) and $i \\neq j$.\n\nTo find the Hessian, we differentiate again with respect to $x_n$:\n$$\n(D^2 f(x))_{mn} = \\frac{\\partial^2 f}{\\partial x_m \\partial x_n} = \\frac{\\partial}{\\partial x_m} \\left( \\delta_{in}x_j + x_i\\delta_{jn} \\right) = \\delta_{in}\\left(\\frac{\\partial x_j}{\\partial x_m}\\right) + \\left(\\frac{\\partial x_i}{\\partial x_m}\\right)\\delta_{jn} = \\delta_{in}\\delta_{jm} + \\delta_{im}\\delta_{jn}\n$$\nThis expression gives the entry in the $m$-th row and $n$-th column. The resulting matrix has a $1$ in the $(j,i)$ position and a $1$ in the $(i,j)$ position, and zeros elsewhere if $i \\neq j$. If $i=j$, it has a $2$ in the $(i,i)$ position. This matrix can be written compactly as $E_{ji} + E_{ij}$. Or, using the result for the $(m,n)$ entry: $D^2 f(x) = E_{ij} + E_{ji}$. If $i=j$, this becomes $E_{ii} + E_{ii} = 2E_{ii}$.\nThis function is also a polynomial and thus $C^\\infty$. We verify the symmetry of the Hessian from our derived components: $(D^2 f(x))_{mn} = \\delta_{in}\\delta_{jm} + \\delta_{im}\\delta_{jn}$. Swapping the indices $m$ and $n$ gives $(D^2 f(x))_{nm} = \\delta_{im}\\delta_{jn} + \\delta_{in}\\delta_{jm}$, which is identical. The Hessian is symmetric, as required by Clairaut's theorem.\nFor this function, the ordered pair is $\\big(\\nabla f(x), D^2 f(x)\\big) = \\left( x_j e_i + x_i e_j, E_{ij} + E_{ji} \\right)$.\n\nThird, consider the function $f(x) = x_k$ for a fixed index $k \\in \\{1,\\dots,d\\}$.\nThis is a linear function. The partial derivative with respect to $x_m$ is:\n$$\n\\frac{\\partial f}{\\partial x_m} = \\frac{\\partial x_k}{\\partial x_m} = \\delta_{km}\n$$\nThe gradient vector $\\nabla f(x)$ has a $1$ in the $k$-th position and zeros elsewhere. This is precisely the $k$-th standard basis vector, so $\\nabla f(x) = e_k$.\n\nTo find the Hessian, we differentiate again:\n$$\n(D^2 f(x))_{mn} = \\frac{\\partial^2 f}{\\partial x_m \\partial x_n} = \\frac{\\partial}{\\partial x_m} \\left(\\frac{\\partial f}{\\partial x_n}\\right) = \\frac{\\partial}{\\partial x_m}(\\delta_{kn}) = 0\n$$\nsince $\\delta_{kn}$ is a constant for fixed $k$ and $n$. The Hessian is the $d \\times d$ zero matrix, which we denote by $0_{d \\times d}$.\nThe zero matrix is trivially symmetric, $(0_{d \\times d})_{mn} = (0_{d \\times d})_{nm} = 0$, which is consistent with Clairaut's theorem for this $C^\\infty$ function.\nFor this function, the ordered pair is $\\big(\\nabla f(x), D^2 f(x)\\big) = \\left( e_k, 0_{d \\times d} \\right)$.\n\nCombining these results into a single row matrix as requested provides the final answer.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\left( 2x, 2I_d \\right) & \\left( x_j e_i + x_i e_j, E_{ij} + E_{ji} \\right) & \\left( e_k, 0_{d \\times d} \\right) \\end{pmatrix}}\n$$", "id": "3067820"}, {"introduction": "With the calculus prerequisites refreshed, we can now engage with the Itô formula directly. This practice problem [@problem_id:3067846] guides you through applying the formula to find the dynamics of a new process, $(X_t^i)^3$, derived from a general Itô process $X_t$. This is a classic exercise that clearly illustrates how the formula combines the original process's drift and diffusion with the function's first and second derivatives to produce the new stochastic differential.", "problem": "Consider a $d$-dimensional Itô process $\\{X_{t}\\}_{t \\ge 0}$ satisfying the stochastic differential equation (SDE)\n$$\ndX_{t} = b(t,X_{t})\\,dt + \\sigma(t,X_{t})\\,dW_{t},\n$$\nwhere $W_{t}$ is an $m$-dimensional standard Brownian motion with independent components, $b : [0,\\infty) \\times \\mathbb{R}^{d} \\to \\mathbb{R}^{d}$ is measurable, and $\\sigma : [0,\\infty) \\times \\mathbb{R}^{d} \\to \\mathbb{R}^{d \\times m}$ is measurable. For $i \\in \\{1,\\dots,d\\}$, denote by $X_{t}^{i}$ the $i$-th component of $X_{t}$, by $b^{i}(t,X_{t})$ the $i$-th component of $b(t,X_{t})$, and by $\\sigma_{i\\cdot}(t,X_{t})$ the $i$-th row of the matrix $\\sigma(t,X_{t})$, whose $k$-th entry is $\\sigma_{ik}(t,X_{t})$ for $k \\in \\{1,\\dots,m\\}$. Let $f : \\mathbb{R}^{d} \\to \\mathbb{R}$ be defined by $f(x) = x_{i}^{3}$.\n\nUsing only the definition of an Itô process, the properties of quadratic variation and covariation of semimartingales, and the multidimensional Itô formula as a foundational tool, derive the stochastic differential for $f(X_{t}) = (X_{t}^{i})^{3}$ and express the result explicitly in terms of $b^{i}(t,X_{t})$ and the entries of $\\sigma_{i\\cdot}(t,X_{t})$. Your final answer must be a single closed-form analytic expression for $d(X_{t}^{i})^{3}$ involving $dt$ and $dW_{t}^{k}$ terms.", "solution": "We start from the structure of the given Itô process. The $d$-dimensional process $\\{X_{t}\\}_{t \\ge 0}$ is defined by\n$$\ndX_{t} = b(t,X_{t})\\,dt + \\sigma(t,X_{t})\\,dW_{t},\n$$\nwhere $W_{t}$ is an $m$-dimensional Brownian motion. Writing components, for each $i \\in \\{1,\\dots,d\\}$,\n$$\ndX_{t}^{i} = b^{i}(t,X_{t})\\,dt + \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})\\,dW_{t}^{k}.\n$$\nThe quadratic covariation of the components $X^{i}$ and $X^{j}$ satisfies, by the well-known property of Itô integrals,\n$$\nd[X^{i},X^{j}]_{t} = \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})\\,\\sigma_{jk}(t,X_{t})\\,dt,\n$$\nand in particular the quadratic variation of $X^{i}$ is\n$$\nd[X^{i}]_{t} = d[X^{i},X^{i}]_{t} = \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})^{2}\\,dt.\n$$\n\nNext, consider the function $f : \\mathbb{R}^{d} \\to \\mathbb{R}$ defined by $f(x) = x_{i}^{3}$. Its gradient and Hessian are computed as follows. For the gradient,\n$$\n\\partial_{j} f(x) =\n\\begin{cases}\n3 x_{i}^{2}, & \\text{if } j=i, \\\\\n0, & \\text{if } j \\neq i,\n\\end{cases}\n$$\nand for the Hessian,\n$$\n\\partial_{j\\ell} f(x) =\n\\begin{cases}\n6 x_{i}, & \\text{if } j=\\ell=i, \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\nBy the multidimensional Itô formula, for $f \\in C^{2}(\\mathbb{R}^{d})$ and an Itô process $X_{t}$,\n$$\ndf(X_{t}) = \\sum_{j=1}^{d} \\partial_{j} f(X_{t})\\,dX_{t}^{j} + \\frac{1}{2} \\sum_{j=1}^{d} \\sum_{\\ell=1}^{d} \\partial_{j\\ell} f(X_{t})\\,d[X^{j},X^{\\ell}]_{t}.\n$$\nApplying this to $f(x) = x_{i}^{3}$ and using the above derivatives,\n$$\nd\\big((X_{t}^{i})^{3}\\big) = 3 (X_{t}^{i})^{2}\\,dX_{t}^{i} + \\frac{1}{2} \\cdot 6 X_{t}^{i} \\, d[X^{i},X^{i}]_{t}.\n$$\nSimplifying,\n$$\nd\\big((X_{t}^{i})^{3}\\big) = 3 (X_{t}^{i})^{2}\\,dX_{t}^{i} + 3 X_{t}^{i}\\,d[X^{i}]_{t}.\n$$\n\nWe now substitute the expressions for $dX_{t}^{i}$ and $d[X^{i}]_{t}$ in terms of $b^{i}(t,X_{t})$ and $\\sigma_{ik}(t,X_{t})$. First,\n$$\ndX_{t}^{i} = b^{i}(t,X_{t})\\,dt + \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})\\,dW_{t}^{k},\n$$\nand second,\n$$\nd[X^{i}]_{t} = \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})^{2}\\,dt.\n$$\nTherefore,\n$$\nd\\big((X_{t}^{i})^{3}\\big)\n= 3 (X_{t}^{i})^{2} \\left( b^{i}(t,X_{t})\\,dt + \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})\\,dW_{t}^{k} \\right)\n+ 3 X_{t}^{i} \\left( \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})^{2}\\,dt \\right).\n$$\n\nCollecting the $dt$ and $dW_{t}^{k}$ terms explicitly, we obtain\n$$\nd\\big( (X_{t}^{i})^{3} \\big)\n= \\left[ 3 (X_{t}^{i})^{2} b^{i}(t,X_{t}) + 3 X_{t}^{i} \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})^{2} \\right] dt\n+ 3 (X_{t}^{i})^{2} \\sum_{k=1}^{m} \\sigma_{ik}(t,X_{t})\\,dW_{t}^{k}.\n$$\n\nThis is the desired closed-form analytic expression for $d(X_{t}^{i})^{3}$ in terms of $b^{i}(t,X_{t})$ and the entries of the $i$-th row $\\sigma_{i\\cdot}(t,X_{t})$.", "answer": "$$\\boxed{d\\big((X_{t}^{i})^{3}\\big)=\\left[3\\,(X_{t}^{i})^{2}\\,b^{i}(t,X_{t})+3\\,X_{t}^{i}\\sum_{k=1}^{m}\\sigma_{ik}(t,X_{t})^{2}\\right]dt+3\\,(X_{t}^{i})^{2}\\sum_{k=1}^{m}\\sigma_{ik}(t,X_{t})\\,dW_{t}^{k}}$$", "id": "3067846"}, {"introduction": "This final practice moves beyond mechanical application to reveal a profound connection between stochastic analysis and partial differential equations. By applying Itô's formula to a special class of functions known as harmonic functions, we can show that the resulting process is a local martingale—a process with no predictable drift [@problem_id:3067881]. This elegant result is not just a theoretical curiosity; it forms the basis of powerful techniques for solving boundary value problems and for pricing financial derivatives.", "problem": "Let $f:\\mathbb{R}^{d}\\to\\mathbb{R}$ be twice continuously differentiable and let $D^{2}f(x)$ denote its Hessian matrix at $x\\in\\mathbb{R}^{d}$, whose $(i,j)$ entry is $\\partial_{ij}f(x)=\\frac{\\partial^{2}f}{\\partial x_{i}\\partial x_{j}}(x)$. The Laplacian of $f$ is defined by $\\Delta f(x)=\\sum_{i=1}^{d}\\partial_{ii}f(x)$. Suppose $f$ is harmonic, meaning $\\Delta f(x)=0$ for all $x\\in\\mathbb{R}^{d}$. Let $\\{W_{t}\\}_{t\\ge 0}$ be a $d$-dimensional standard Brownian motion with $W_{0}=x_{0}\\in\\mathbb{R}^{d}$, where Brownian motion is understood in the sense of a continuous-time stochastic process with independent, stationary Gaussian increments and continuous paths, and whose components have quadratic variation $[W^{(i)}]_{t}=t$ and zero cross-variation for $i\\neq j$. \n\n(a) Starting from the definitions above, show that the trace of the Hessian matrix $D^{2}f(x)$ equals the Laplacian $\\Delta f(x)$, and conclude that $\\operatorname{tr}(D^{2}f(x))=0$ for all $x\\in\\mathbb{R}^{d}$.\n\n(b) Using only foundational properties of Brownian motion and twice continuously differentiable functions, derive the stochastic differential for the process $f(W_{t})$, identify its drift term, and explain why the harmonicity condition $\\Delta f=0$ implies that $f(W_{t})$ is a local martingale.\n\n(c) Now specialize to $d=2$ and the concrete harmonic function $f(x,y)=x^{3}-3xy^{2}$. Assume $W_{0}=(a,b)\\in\\mathbb{R}^{2}$ and that all necessary integrability conditions hold to justify taking expectations. Provide a closed-form analytic expression for $\\mathbb{E}\\big[f(W_{t})\\big]$ in terms of $a$ and $b$ that holds for all $t\\ge 0$. Express your final answer as a single closed-form analytic expression in $a$ and $b$.", "solution": "This problem comprises three parts, concerning the properties of harmonic functions in the context of multidimensional Brownian motion. We shall address each part sequentially after validating the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- $f:\\mathbb{R}^{d}\\to\\mathbb{R}$ is a twice continuously differentiable function.\n- $D^{2}f(x)$ denotes the Hessian matrix of $f$ at $x\\in\\mathbb{R}^{d}$, with entries $\\partial_{ij}f(x)=\\frac{\\partial^{2}f}{\\partial x_{i}\\partial x_{j}}(x)$.\n- The Laplacian is defined as $\\Delta f(x)=\\sum_{i=1}^{d}\\partial_{ii}f(x)$.\n- $f$ is harmonic, meaning $\\Delta f(x)=0$ for all $x\\in\\mathbb{R}^{d}$.\n- $\\{W_{t}\\}_{t\\ge 0}$ is a $d$-dimensional standard Brownian motion with $W_{0}=x_{0}\\in\\mathbb{R}^{d}$.\n- The quadratic variation of the components is $[W^{(i)}]_{t}=t$.\n- The quadratic cross-variation of distinct components is zero.\n- Part (a): Show $\\operatorname{tr}(D^{2}f(x)) = \\Delta f(x)$ and conclude $\\operatorname{tr}(D^{2}f(x))=0$.\n- Part (b): Derive the stochastic differential for $f(W_{t})$, identify its drift, and show it is a local martingale if $f$ is harmonic.\n- Part (c): For $d=2$, $f(x,y)=x^{3}-3xy^{2}$, and $W_{0}=(a,b)$, find $\\mathbb{E}\\big[f(W_{t})\\big]$ assuming necessary integrability conditions hold.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined within the mathematical framework of stochastic calculus.\n1.  **Scientific or Factual Soundness**: The problem is factually sound. All definitions provided (Hessian, Laplacian, Brownian motion) are standard. The connection between harmonic functions and martingales via Brownian motion is a classical result (Dynkin's formula). The specific function $f(x,y)=x^{3}-3xy^{2}$ is the real part of the complex analytic function $z^3 = (x+iy)^3$, and as such, it is known to be harmonic. Let's verify this explicitly:\n    $\\frac{\\partial f}{\\partial x} = 3x^2 - 3y^2 \\implies \\frac{\\partial^2 f}{\\partial x^2} = 6x$.\n    $\\frac{\\partial f}{\\partial y} = -6xy \\implies \\frac{\\partial^2 f}{\\partial y^2} = -6x$.\n    $\\Delta f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2} = 6x - 6x = 0$.\n    The function is indeed harmonic, making the premise of part (c) consistent.\n2.  **Well-Posedness and Completeness**: The problem is well-posed and self-contained. Each part requests a specific, derivable result based on the givens. The assumption of integrability in part (c) is a standard device to ensure that a local martingale is a true martingale, simplifying the calculation of the expectation.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We proceed with the solution.\n\n### Solution\n\n**(a) Trace of the Hessian and the Laplacian**\n\nBy definition, the Hessian matrix $D^{2}f(x)$ is a $d \\times d$ matrix whose entries are the second-order partial derivatives of $f$. The entry in the $i$-th row and $j$-th column is given by $(D^{2}f(x))_{ij} = \\partial_{ij}f(x) = \\frac{\\partial^{2}f}{\\partial x_{i}\\partial x_{j}}(x)$.\n\nThe trace of a square matrix is the sum of the elements on its main diagonal. For the Hessian matrix $D^{2}f(x)$, the trace is:\n$$\n\\operatorname{tr}(D^{2}f(x)) = \\sum_{i=1}^{d} (D^{2}f(x))_{ii}\n$$\nSubstituting the definition of the Hessian entries, we have:\n$$\n\\operatorname{tr}(D^{2}f(x)) = \\sum_{i=1}^{d} \\partial_{ii}f(x) = \\sum_{i=1}^{d} \\frac{\\partial^{2}f}{\\partial x_{i}^{2}}(x)\n$$\nThis sum is, by the definition provided in the problem statement, the Laplacian of $f$ at $x$:\n$$\n\\operatorname{tr}(D^{2}f(x)) = \\Delta f(x)\n$$\nWe are given that the function $f$ is harmonic, which means $\\Delta f(x) = 0$ for all $x \\in \\mathbb{R}^d$. Therefore, we can immediately conclude that:\n$$\n\\operatorname{tr}(D^{2}f(x)) = 0\n$$\n\n**(b) Stochastic Differential of $f(W_t)$ and the Martingale Property**\n\nTo find the stochastic differential of the process $Y_t = f(W_t)$, where $W_t = (W^{(1)}_t, \\dots, W^{(d)}_t)$ is a $d$-dimensional standard Brownian motion, we apply the multidimensional Itô's formula. For a twice continuously differentiable function $f:\\mathbb{R}^d \\to \\mathbb{R}$ and a stochastic process $X_t$ given by $dX_t = \\mu_t dt + \\sigma_t dW_t$, Itô's formula states:\n$$\ndf(X_t) = (\\nabla f(X_t))^T \\mu_t dt + \\frac{1}{2} \\operatorname{tr}\\left( \\sigma_t^T D^2 f(X_t) \\sigma_t \\right) dt + (\\nabla f(X_t))^T \\sigma_t dW_t\n$$\nIn our case, the process is $X_t = W_t$. A standard $d$-dimensional Brownian motion has the stochastic differential $dW_t = \\mu dt + \\sigma dW_t$ with drift vector $\\mu = \\mathbf{0}$ and diffusion matrix $\\sigma = I_d$, where $I_d$ is the $d \\times d$ identity matrix.\n\nApplying Itô's formula with $X_t=W_t$, $\\mu_t = \\mathbf{0}$, and $\\sigma_t = I_d$, we obtain:\n$$\ndf(W_t) = (\\nabla f(W_t))^T \\mathbf{0} \\, dt + \\frac{1}{2} \\operatorname{tr}\\left( I_d^T D^2 f(W_t) I_d \\right) dt + (\\nabla f(W_t))^T I_d dW_t\n$$\nSimplifying this expression:\n$$\ndf(W_t) = \\frac{1}{2} \\operatorname{tr}\\left( D^2 f(W_t) \\right) dt + (\\nabla f(W_t))^T dW_t\n$$\nFrom part (a), we know that $\\operatorname{tr}(D^2 f(x)) = \\Delta f(x)$. Substituting this into the equation gives:\n$$\ndf(W_t) = \\frac{1}{2} \\Delta f(W_t) dt + \\sum_{i=1}^{d} \\frac{\\partial f}{\\partial x_i}(W_t) dW^{(i)}_t\n$$\nThe drift term of a stochastic differential is the coefficient of the $dt$ term. Thus, the drift of the process $f(W_t)$ is $\\frac{1}{2}\\Delta f(W_t)$.\n\nA stochastic process is a local martingale if its stochastic differential has a zero drift term. The harmonicity condition states that $\\Delta f(x) = 0$ for all $x \\in \\mathbb{R}^d$. This implies that for the process $W_t$, the evaluation $\\Delta f(W_t)$ is also zero for all $t \\ge 0$.\nConsequently, the drift term vanishes:\n$$\n\\frac{1}{2}\\Delta f(W_t) = \\frac{1}{2} \\cdot 0 = 0\n$$\nThe stochastic differential for $f(W_t)$ thus reduces to:\n$$\ndf(W_t) = \\sum_{i=1}^{d} \\frac{\\partial f}{\\partial x_i}(W_t) dW^{(i)}_t\n$$\nThis expression represents a stochastic integral with respect to a Brownian motion. Since the integrand, involving the first derivatives of the $C^2$ function $f$, is a sufficiently well-behaved adapted process, the resulting process $f(W_t)$ is a continuous local martingale.\n\n**(c) Expectation of $f(W_t)$ for a Specific Harmonic Function**\n\nWe are given $d=2$, the harmonic function $f(x,y)=x^{3}-3xy^{2}$, and the initial condition $W_{0}=(a,b)$. We need to calculate $\\mathbb{E}\\big[f(W_{t})\\big]$.\n\nFrom part (b), we have established that because $f$ is harmonic, the process $Y_t = f(W_t)$ is a local martingale. The problem statement includes the assumption that \"all necessary integrability conditions hold\". This is a crucial piece of information which allows us to conclude that $Y_t$ is not just a local martingale, but a true martingale.\n\nA key property of a martingale $\\{M_t\\}_{t \\ge 0}$ is that its expectation is constant over time. Specifically, for any $t \\ge 0$:\n$$\n\\mathbb{E}[M_t] = \\mathbb{E}[M_0]\n$$\nApplying this property to our process $Y_t = f(W_t)$:\n$$\n\\mathbb{E}\\big[f(W_t)\\big] = \\mathbb{E}\\big[f(W_0)\\big]\n$$\nThe initial condition is given as a deterministic point $W_0 = (a, b)$. Therefore, $f(W_0)$ is a non-random constant value:\n$$\nf(W_0) = f(a,b) = a^3 - 3ab^2\n$$\nThe expectation of a constant is the constant itself:\n$$\n\\mathbb{E}\\big[f(W_0)\\big] = f(a,b) = a^3 - 3ab^2\n$$\nTherefore, for all $t \\ge 0$, the expectation is:\n$$\n\\mathbb{E}\\big[f(W_{t})\\big] = a^3 - 3ab^2\n$$\nThis provides the required closed-form analytic expression for the expectation in terms of $a$ and $b$.", "answer": "$$\\boxed{a^{3}-3ab^{2}}$$", "id": "3067881"}]}