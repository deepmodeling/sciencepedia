{"hands_on_practices": [{"introduction": "Before we can understand Itô's Lemma, we must first grasp the foundational property of Brownian motion that makes it so unique: its non-zero quadratic variation. This exercise guides you through a heuristic proof that the quadratic variation of a standard Wiener process, $[W]_t$, is simply equal to time $t$ itself [@problem_id:3057918]. Mastering this concept is the key to understanding why classical calculus rules fail and a new set of rules is required for stochastic processes.", "problem": "Let $\\{W_{t}\\}_{t \\ge 0}$ be a standard Brownian motion (also called a Wiener process), meaning a continuous stochastic process with $W_{0}=0$, independent increments, and for $0 \\le s < t$ the increment $W_{t}-W_{s}$ is Gaussian with mean $0$ and variance $t-s$. \n\n(a) Provide a precise definition of the quadratic variation $[X]_{t}$ of a real-valued continuous process $\\{X_{t}\\}_{t \\ge 0}$ on the interval $[0,t]$ in terms of limits in probability of partition sums of squared increments. Your definition must be based on an arbitrary sequence of partitions $\\pi^{(n)}$ of $[0,t]$ whose mesh size tends to $0$.\n\n(b) Using only the defining properties of Brownian motion listed above and basic facts about moments of Gaussian random variables, evaluate the quadratic variation $[W]_{t}$ heuristically by analyzing the partition sums $\\sum_{i=0}^{n-1} \\big(W_{t_{i+1}} - W_{t_{i}}\\big)^{2}$ along the uniform partition $\\pi^{(n)}=\\{0=t_{0}<t_{1}<\\cdots<t_{n}=t\\}$ with $t_{i}=i\\,t/n$. Your reasoning should compute the expectation and variance of these sums and conclude their limit in probability as $n \\to \\infty$, thereby identifying $[W]_{t}$.\n\nGive your final answer as a single closed-form expression in terms of $t$; no rounding is required.", "solution": "The problem is valid as it is a standard, well-posed question in stochastic calculus with a clear and mathematically sound basis.\n\n(a)\nLet $\\{X_{t}\\}_{t \\ge 0}$ be a real-valued continuous process. Let $t > 0$ be a fixed time. A partition of the interval $[0,t]$ is a finite set of points $\\pi = \\{0 = \\tau_0 < \\tau_1 < \\cdots < \\tau_m = t\\}$. The mesh of the partition is defined as $\\|\\pi\\| = \\max_{0 \\le i \\le m-1} (\\tau_{i+1} - \\tau_i)$.\n\nConsider an arbitrary sequence of partitions $\\pi^{(n)}$ of $[0,t]$ such that the mesh of the partitions tends to zero, i.e., $\\lim_{n \\to \\infty} \\|\\pi^{(n)}\\| = 0$. For each partition $\\pi^{(n)} = \\{0=\\tau_{0}^{(n)} < \\tau_{1}^{(n)} < \\cdots < \\tau_{m_n}^{(n)}=t\\}$, we form the sum of the squared increments of the process $X_t$:\n$$\nS_{\\pi^{(n)}}(X) = \\sum_{i=0}^{m_n-1} \\left(X_{\\tau_{i+1}^{(n)}} - X_{\\tau_{i}^{(n)}}\\right)^{2}\n$$\nThe quadratic variation of the process $X_t$ over the interval $[0,t]$, denoted by $[X]_t$, is a stochastic process defined as the limit in probability of these sums. That is, $[X]_t$ is the unique random variable such that for any sequence of partitions $\\pi^{(n)}$ with $\\|\\pi^{(n)}\\| \\to 0$, the sequence of random variables $S_{\\pi^{(n)}}(X)$ converges in probability to $[X]_t$. Formally, for any $\\epsilon > 0$,\n$$\n\\lim_{n \\to \\infty} P\\left( \\left| S_{\\pi^{(n)}}(X) - [X]_t \\right| > \\epsilon \\right) = 0\n$$\n\n(b)\nWe are asked to evaluate the quadratic variation $[W]_t$ of a standard Brownian motion $\\{W_t\\}_{t \\geq 0}$. We use the specific sequence of uniform partitions $\\pi^{(n)} = \\{t_0, t_1, \\dots, t_n\\}$ where $t_i = i \\frac{t}{n}$ for $i=0, 1, \\dots, n$. The mesh of this partition is $\\|\\pi^{(n)}\\| = t/n$, which tends to $0$ as $n \\to \\infty$.\n\nThe corresponding sum of squared increments is\n$$\nS_n = \\sum_{i=0}^{n-1} (W_{t_{i+1}} - W_{t_i})^2\n$$\nLet us denote the increment over the $i$-th subinterval as $\\Delta W_i = W_{t_{i+1}} - W_{t_i}$. The duration of each subinterval is $\\Delta t_i = t_{i+1} - t_i = \\frac{t}{n}$. From the definition of Brownian motion, the increments $\\Delta W_i$ are independent and identically distributed Gaussian random variables. Specifically, for each $i$, $\\Delta W_i \\sim N(0, t_{i+1}-t_i)$, which means $\\Delta W_i \\sim N(0, t/n)$.\n\nFirst, we compute the expectation of $S_n$. By the linearity of expectation,\n$$\nE[S_n] = E\\left[\\sum_{i=0}^{n-1} (\\Delta W_i)^2\\right] = \\sum_{i=0}^{n-1} E[(\\Delta W_i)^2]\n$$\nThe second moment $E[Z^2]$ of a random variable $Z$ is related to its variance and mean by $E[Z^2] = \\text{Var}(Z) + (E[Z])^2$. For the increment $\\Delta W_i$, we have $E[\\Delta W_i] = 0$ and $\\text{Var}(\\Delta W_i) = t/n$. Therefore,\n$$\nE[(\\Delta W_i)^2] = \\frac{t}{n} + 0^2 = \\frac{t}{n}\n$$\nSubstituting this back into the expression for $E[S_n]$:\n$$\nE[S_n] = \\sum_{i=0}^{n-1} \\frac{t}{n} = n \\cdot \\frac{t}{n} = t\n$$\nThe expectation of the sum $S_n$ is exactly $t$, for any $n$. This suggests that the limit of $S_n$ will be $t$.\n\nNext, to provide a heuristic argument for convergence in probability, we compute the variance of $S_n$. Since the increments $\\Delta W_i$ are independent, the random variables $(\\Delta W_i)^2$ are also independent. For a sum of independent random variables, the variance of the sum is the sum of the variances:\n$$\n\\text{Var}(S_n) = \\text{Var}\\left(\\sum_{i=0}^{n-1} (\\Delta W_i)^2\\right) = \\sum_{i=0}^{n-1} \\text{Var}((\\Delta W_i)^2)\n$$\nThe variance of a random variable $Y$ is given by $\\text{Var}(Y) = E[Y^2] - (E[Y])^2$. Here, $Y = (\\Delta W_i)^2$. We have already found $E[Y] = E[(\\Delta W_i)^2] = t/n$. We now need $E[Y^2] = E[(\\Delta W_i)^4]$, which is the fourth moment of $\\Delta W_i$.\nFor a centered Gaussian random variable $Z \\sim N(0, \\sigma^2)$, the fourth moment is $E[Z^4] = 3(\\sigma^2)^2$. In our case, $Z = \\Delta W_i$ and $\\sigma^2 = t/n$. Thus,\n$$\nE[(\\Delta W_i)^4] = 3 \\left(\\frac{t}{n}\\right)^2 = \\frac{3t^2}{n^2}\n$$\nNow we can compute the variance of $(\\Delta W_i)^2$:\n$$\n\\text{Var}((\\Delta W_i)^2) = E[(\\Delta W_i)^4] - (E[(\\Delta W_i)^2])^2 = \\frac{3t^2}{n^2} - \\left(\\frac{t}{n}\\right)^2 = \\frac{2t^2}{n^2}\n$$\nSince the distributions of $(\\Delta W_i)^2$ are identical for all $i$, we can find the variance of $S_n$:\n$$\n\\text{Var}(S_n) = \\sum_{i=0}^{n-1} \\frac{2t^2}{n^2} = n \\cdot \\frac{2t^2}{n^2} = \\frac{2t^2}{n}\n$$\nAs $n \\to \\infty$, we have $\\text{Var}(S_n) = \\frac{2t^2}{n} \\to 0$.\n\nIn summary, we have a sequence of random variables $\\{S_n\\}_{n \\ge 1}$ such that $E[S_n] = t$ for all $n$ and $\\lim_{n \\to \\infty} \\text{Var}(S_n) = 0$. A sequence of random variables whose variance converges to zero converges in probability to the limit of its expectation (if that limit exists). In our case, the expectation is constant. This means that $S_n$ converges in probability to $t$.\nTherefore, by definition of the quadratic variation,\n$$\n[W]_t = \\underset{n\\to\\infty}{\\text{p-lim}} \\sum_{i=0}^{n-1} (W_{t_{i+1}} - W_{t_i})^2 = t\n$$", "answer": "$$\n\\boxed{t}\n$$", "id": "3057918"}, {"introduction": "With the concept of quadratic variation in hand, we can now explore how it gives rise to the famous Itô's Lemma. This practice asks you to perform a Taylor expansion on a function of a stochastic process and, by carefully analyzing the orders of magnitude of the terms, to isolate the \"correction term\" that distinguishes the stochastic chain rule from its deterministic counterpart [@problem_id:3057961]. This exercise provides a direct, hands-on look at the heart of the lemma.", "problem": "Consider the stochastic differential equation (SDE) $$\\mathrm{d}X_{t}=\\mu X_{t}\\,\\mathrm{d}t+\\sigma X_{t}\\,\\mathrm{d}W_{t},$$ where $W_{t}$ is a Standard Brownian Motion (SBM), $X_{t}>0$, and $\\mu$ and $\\sigma$ are real constants. Let $f:\\mathbb{R}_{+}\\to\\mathbb{R}$ be given by $f(x)=x^{p}$ with $p\\in\\mathbb{R}$ such that $f$ is twice continuously differentiable on $(0,\\infty)$. Over a small time increment $\\Delta t>0$, write $\\Delta W=W_{t+\\Delta t}-W_{t}$ and $\\Delta X=X_{t+\\Delta t}-X_{t}$. Using only the following foundational facts:\n\n- The increment $\\Delta W$ is Gaussian with mean $0$ and variance $\\Delta t$.\n- The typical magnitude of $\\Delta W$ scales as $|\\Delta W|=\\mathcal{O}(\\sqrt{\\Delta t})$.\n- A second-order Taylor expansion for a twice continuously differentiable function $f$ around a point $x$ has the form $f(x+\\Delta X)=f(x)+f_{x}(x)\\,\\Delta X+\\frac{1}{2}f_{xx}(x)\\,(\\Delta X)^{2}+\\text{higher-order terms}$.\n\nPerform a Taylor expansion of $f(X_{t+\\Delta t})$ around $X_{t}$, and then use the scaling of $\\Delta W$ to classify the orders (in $\\Delta t$) of each term that appears. Explicitly show how keeping the contribution from $(\\Delta W)^{2}$ while dropping all terms that are of order higher than $\\Delta t$ (including $(\\Delta W)^{3}$ and beyond) generates a deterministic correction term in the drift of $f(X_{t})$ over $\\Delta t$. Your final task is to extract and present the analytic expression for this correction term, expressed as a function of $p$, $\\sigma$, and $X_{t}$.\n\nProvide only the correction term; do not include any equality signs or additional context in your final answer. No numerical approximation or rounding is required.", "solution": "The problem is valid as it is scientifically grounded in the principles of stochastic calculus, is well-posed with a clear objective, and is free of any factual or logical inconsistencies. We shall proceed with the derivation.\n\nThe objective is to find the deterministic correction term that appears in the drift of the process $Y_t = f(X_t)$ when $X_t$ follows the stochastic differential equation (SDE) for Geometric Brownian Motion. The function is given as $f(x) = x^p$.\n\nWe begin with the second-order Taylor expansion of $f(X_{t+\\Delta t})$ around the point $X_t$:\n$$f(X_{t+\\Delta t}) = f(X_t) + f_x(X_t)\\,\\Delta X_t + \\frac{1}{2}f_{xx}(X_t)\\,(\\Delta X_t)^2 + \\mathcal{O}((\\Delta X_t)^3)$$\nwhere $\\Delta X_t = X_{t+\\Delta t} - X_t$ and $f_x$ and $f_{xx}$ denote the first and second partial derivatives of $f$ with respect to its spatial variable, evaluated at $X_t$. The change in $f(X_t)$ over the interval $\\Delta t$ is thus:\n$$\\Delta f(X_t) = f(X_{t+\\Delta t}) - f(X_t) = f_x(X_t)\\,\\Delta X_t + \\frac{1}{2}f_{xx}(X_t)\\,(\\Delta X_t)^2 + \\text{h.o.t.}$$\nThe given SDE is $\\mathrm{d}X_t = \\mu X_t \\,\\mathrm{d}t + \\sigma X_t \\,\\mathrm{d}W_t$. We can write its discrete-time approximation over a small interval $\\Delta t > 0$ as:\n$$\\Delta X_t \\approx \\mu X_t \\,\\Delta t + \\sigma X_t \\,\\Delta W_t$$\nwhere $\\Delta W_t = W_{t+\\Delta t} - W_t$.\n\nNow, we substitute this expression for $\\Delta X_t$ into the Taylor expansion for $\\Delta f(X_t)$:\n$$\\Delta f(X_t) \\approx f_x(X_t) (\\mu X_t \\,\\Delta t + \\sigma X_t \\,\\Delta W_t) + \\frac{1}{2}f_{xx}(X_t) (\\mu X_t \\,\\Delta t + \\sigma X_t \\,\\Delta W_t)^2$$\nLet's expand the squared term:\n$$(\\mu X_t \\,\\Delta t + \\sigma X_t \\,\\Delta W_t)^2 = (\\mu X_t)^2 (\\Delta t)^2 + 2\\mu\\sigma X_t^2 \\Delta t \\Delta W_t + (\\sigma X_t)^2 (\\Delta W_t)^2$$\nSubstituting this back into the expansion for $\\Delta f(X_t)$:\n$$\\Delta f(X_t) \\approx f_x(X_t) \\mu X_t \\Delta t + f_x(X_t) \\sigma X_t \\Delta W_t + \\frac{1}{2}f_{xx}(X_t) \\left[ (\\mu X_t)^2 (\\Delta t)^2 + 2\\mu\\sigma X_t^2 \\Delta t \\Delta W_t + (\\sigma X_t)^2 (\\Delta W_t)^2 \\right]$$\nThe next step is to analyze the order of magnitude of each term as $\\Delta t \\to 0$, using the provided fact that the typical magnitude of the Brownian increment is $|\\Delta W_t| = \\mathcal{O}(\\sqrt{\\Delta t})$.\n\\begin{itemize}\n    \\item Term 1: $f_x(X_t) \\mu X_t \\Delta t$. This is of order $\\mathcal{O}(\\Delta t)$.\n    \\item Term 2: $f_x(X_t) \\sigma X_t \\Delta W_t$. This is of order $\\mathcal{O}(\\sqrt{\\Delta t})$.\n    \\item Term 3: $\\frac{1}{2}f_{xx}(X_t) (\\mu X_t)^2 (\\Delta t)^2$. This is of order $\\mathcal{O}((\\Delta t)^2)$.\n    \\item Term 4: $\\frac{1}{2}f_{xx}(X_t) 2\\mu\\sigma X_t^2 \\Delta t \\Delta W_t = f_{xx}(X_t)\\mu\\sigma X_t^2 \\Delta t \\Delta W_t$. This is of order $\\mathcal{O}((\\Delta t)^{3/2})$.\n    \\item Term 5: $\\frac{1}{2}f_{xx}(X_t) (\\sigma X_t)^2 (\\Delta W_t)^2$. This is the critical term. While $\\Delta W_t$ is a random variable of order $\\mathcal{O}(\\sqrt{\\Delta t})$, its quadratic variation is non-random in the limit. Specifically, $\\mathbb{E}[(\\Delta W_t)^2] = \\Delta t$. In the heuristic derivation of Itô's lemma, we make the replacement $(\\Delta W_t)^2 \\to \\Delta t$. Therefore, this term is of order $\\mathcal{O}(\\Delta t)$.\n\\end{itemize}\nThe problem states that we should drop all terms of order higher than $\\Delta t$. This means we discard terms of order $\\mathcal{O}((\\Delta t)^{3/2})$ and $\\mathcal{O}((\\Delta t)^2)$. We retain terms of order $\\mathcal{O}(\\Delta t)$ and the leading stochastic term of order $\\mathcal{O}(\\sqrt{\\Delta t})$.\n\nThe simplified expansion becomes:\n$$\\Delta f(X_t) \\approx \\underbrace{f_x(X_t) \\mu X_t \\Delta t + \\frac{1}{2}f_{xx}(X_t) (\\sigma X_t)^2 \\Delta t}_{\\text{Drift terms, }\\mathcal{O}(\\Delta t)} + \\underbrace{f_x(X_t) \\sigma X_t \\Delta W_t}_{\\text{Stochastic term, }\\mathcal{O}(\\sqrt{\\Delta t})}$$\nIn differential form, this corresponds to the Itô-Doeblin formula:\n$$\\mathrm{d}f(X_t) = \\left( f_x(X_t) \\mu X_t + \\frac{1}{2}f_{xx}(X_t) \\sigma^2 X_t^2 \\right) \\mathrm{d}t + f_x(X_t) \\sigma X_t \\mathrm{d}W_t$$\nThe drift part of this expression is the coefficient of the $\\mathrm{d}t$ term:\n$$\\text{Drift of } f(X_t) = f_x(X_t) \\mu X_t + \\frac{1}{2}f_{xx}(X_t) \\sigma^2 X_t^2$$\nA naive application of the chain rule would only yield the first term, $f_x(X_t) \\mu X_t$. The second term, $\\frac{1}{2}f_{xx}(X_t) \\sigma^2 X_t^2$, is the deterministic correction term that arises from the non-zero quadratic variation of the Brownian motion. This correction term is the object of our inquiry.\n\nTo find the specific expression for this term, we must compute the derivatives for the given function $f(x) = x^p$, which is twice continuously differentiable on $(0, \\infty)$ for any $p \\in \\mathbb{R}$.\nThe first derivative is:\n$$f_x(x) = \\frac{\\mathrm{d}}{\\mathrm{d}x}(x^p) = p x^{p-1}$$\nThe second derivative is:\n$$f_{xx}(x) = \\frac{\\mathrm{d}}{\\mathrm{d}x}(p x^{p-1}) = p(p-1) x^{p-2}$$\nNow, we substitute the second derivative $f_{xx}(X_t) = p(p-1) X_t^{p-2}$ into the general form of the correction term:\n$$\n\\text{Correction Term} = \\frac{1}{2} f_{xx}(X_t) \\sigma^2 X_t^2\n$$\n$$\n\\text{Correction Term} = \\frac{1}{2} \\left( p(p-1) X_t^{p-2} \\right) \\sigma^2 X_t^2\n$$\nBy combining the terms involving $X_t$:\n$$\n\\text{Correction Term} = \\frac{1}{2} p(p-1) \\sigma^2 X_t^{p-2} X_t^2 = \\frac{1}{2} p(p-1) \\sigma^2 X_t^{p-2+2}\n$$\nThis simplifies to the final expression for the correction term in the drift:\n$$\n\\text{Correction Term} = \\frac{1}{2} p(p-1) \\sigma^2 X_t^p\n$$\nThis term is deterministic, as required, and is expressed as a function of $p$, $\\sigma$, and $X_t$.", "answer": "$$\\boxed{\\frac{1}{2}p(p-1)\\sigma^2 X_t^p}$$", "id": "3057961"}, {"introduction": "Now we will put everything together by applying our heuristic derivation to a function that depends explicitly on both time $t$ and the stochastic process $X_t$. This exercise requires you to use the same Taylor expansion and scaling arguments to derive the full stochastic differential for the transformed process [@problem_id:3057970]. By working through this example, you will consolidate your understanding of the complete, time-dependent version of Itô's Lemma.", "problem": "Consider a scalar stochastic process $X_t$ defined on a filtered probability space supporting a standard Wiener process (Brownian motion) $W_t$, with dynamics given in the Itô sense by the stochastic differential equation $dX_t = \\mu\\,dt + \\sigma\\,dW_t$, where $\\mu$ and $\\sigma$ are real constants. Define a time-dependent transformation $Y_t = f(t, X_t)$ with $f(t,x) = \\exp(\\alpha t)\\,x$, where $\\alpha$ is a real constant. Using only a second-order Taylor expansion in the increments of $t$ and $X_t$, and the scaling properties of Brownian motion increments, derive heuristically the stochastic differential $dY_t$ up to terms of order $dt$ by:\n- Expanding $df(t, X_t)$ to include terms involving $f_t$, $f_x$, $f_{xx}$, and the product rules for differentials.\n- Retaining only terms that contribute at order $dt$, using the facts $E[dW_t] = 0$, $E[(dW_t)^2] = dt$, $(dW_t)^2$ is of order $dt$, $dt\\,dW_t$ is of order $dt^{3/2}$, and $(dt)^2$ is negligible at order $dt$.\n- Substituting $dX_t = \\mu\\,dt + \\sigma\\,dW_t$ and simplifying, without invoking any pre-stated stochastic chain rule.\n\nFrom your derivation, identify the drift and diffusion coefficients $a_Y(t, X_t)$ and $b_Y(t, X_t)$ such that $dY_t = a_Y(t, X_t)\\,dt + b_Y(t, X_t)\\,dW_t$. Report your final answer as the row matrix containing the pair $a_Y(t, X_t)$ and $b_Y(t, X_t)$, written as $\\begin{pmatrix} a_Y(t, X_t) & b_Y(t, X_t) \\end{pmatrix}$, in closed form in terms of $t$, $X_t$, $\\alpha$, $\\mu$, and $\\sigma$. No numerical approximation or rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard derivation in the theory of stochastic differential equations without any logical contradictions or missing information. We may therefore proceed with a formal solution.\n\nThe objective is to derive the stochastic differential for the process $Y_t = f(t, X_t)$, where $f(t,x) = \\exp(\\alpha t)x$ and $X_t$ follows the Itô process $dX_t = \\mu\\,dt + \\sigma\\,dW_t$. This will be accomplished through a second-order Taylor expansion of $f(t, X_t)$.\n\nLet $dY_t = Y_{t+dt} - Y_t = f(t+dt, X_{t+dt}) - f(t, X_t)$. The increment $dX_t$ is defined as $X_{t+dt} - X_t$. The Taylor series expansion of $f$ around the point $(t, X_t)$ is:\n$$\ndY_t = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x} dX_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial t^2} (dt)^2 + \\frac{\\partial^2 f}{\\partial t \\partial x} dt\\,dX_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2} (dX_t)^2 + \\dots\n$$\nwhere all partial derivatives are evaluated at $(t, X_t)$.\n\nWe now analyze the order of magnitude of the terms based on the heuristic rules of Itô calculus, where we retain terms up to order $dt$. The infinitesimal increments $dt$ and $dW_t$ have a non-trivial quadratic variation relationship, $(dW_t)^2 = dt$.\nThe terms are analyzed as follows:\n- The terms $\\frac{\\partial f}{\\partial t} dt$ and $\\frac{\\partial f}{\\partial x} dX_t$ are kept as they contain terms of order $dt$ and $dW_t \\sim (dt)^{1/2}$.\n- The term $\\frac{1}{2} \\frac{\\partial^2 f}{\\partial t^2} (dt)^2$ is of order $(dt)^2$ and is negligible compared to $dt$.\n- The term $\\frac{\\partial^2 f}{\\partial t \\partial x} dt\\,dX_t$: We substitute $dX_t = \\mu\\,dt + \\sigma\\,dW_t$. This gives $dt\\,dX_t = dt(\\mu\\,dt + \\sigma\\,dW_t) = \\mu(dt)^2 + \\sigma\\,dt\\,dW_t$. The term $\\mu(dt)^2$ is of order $O(dt^2)$, and the term $\\sigma\\,dt\\,dW_t$ is of order $O(dt^{3/2})$. Both are higher order than $dt$ and are therefore neglected.\n- The term $\\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2} (dX_t)^2$: We expand $(dX_t)^2$.\n$$\n(dX_t)^2 = (\\mu\\,dt + \\sigma\\,dW_t)^2 = \\mu^2(dt)^2 + 2\\mu\\sigma\\,dt\\,dW_t + \\sigma^2(dW_t)^2\n$$\nAgain, we analyze the orders: $\\mu^2(dt)^2$ is $O(dt^2)$, $2\\mu\\sigma\\,dt\\,dW_t$ is $O(dt^{3/2})$. These are negligible. The term $\\sigma^2(dW_t)^2$ is of order $\\sigma^2 dt$ because $(dW_t)^2 = dt$. This is the only part of $(dX_t)^2$ that contributes at order $dt$. Thus, $(dX_t)^2 = \\sigma^2 dt$.\n\nRetaining only the terms of order $dt$ or lower, the Taylor expansion simplifies to:\n$$\ndY_t = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x} dX_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2} (\\sigma^2 dt)\n$$\nNow, we substitute the expression for $dX_t = \\mu\\,dt + \\sigma\\,dW_t$:\n$$\ndY_t = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial x} (\\mu\\,dt + \\sigma\\,dW_t) + \\frac{1}{2} \\sigma^2 \\frac{\\partial^2 f}{\\partial x^2} dt\n$$\nWe group the $dt$ and $dW_t$ terms to identify the drift and diffusion coefficients of the SDE for $Y_t$:\n$$\ndY_t = \\left( \\frac{\\partial f}{\\partial t} + \\mu \\frac{\\partial f}{\\partial x} + \\frac{1}{2} \\sigma^2 \\frac{\\partial^2 f}{\\partial x^2} \\right) dt + \\left( \\sigma \\frac{\\partial f}{\\partial x} \\right) dW_t\n$$\nThis is the general form of Itô's lemma for a function of time and one stochastic process.\n\nThe problem specifies the function $f(t,x) = \\exp(\\alpha t)x$. We compute its partial derivatives:\n1. First partial derivative with respect to time $t$:\n$$\n\\frac{\\partial f}{\\partial t} = \\frac{\\partial}{\\partial t}(\\exp(\\alpha t)x) = \\alpha \\exp(\\alpha t)x\n$$\n2. First partial derivative with respect to state $x$:\n$$\n\\frac{\\partial f}{\\partial x} = \\frac{\\partial}{\\partial x}(\\exp(\\alpha t)x) = \\exp(\\alpha t)\n$$\n3. Second partial derivative with respect to state $x$:\n$$\n\\frac{\\partial^2 f}{\\partial x^2} = \\frac{\\partial}{\\partial x}(\\exp(\\alpha t)) = 0\n$$\nNow we substitute these derivatives evaluated at $(t, X_t)$ into the general SDE for $dY_t$.\nThe drift coefficient, $a_Y(t, X_t)$, is:\n$$\na_Y(t, X_t) = \\frac{\\partial f}{\\partial t}(t, X_t) + \\mu \\frac{\\partial f}{\\partial x}(t, X_t) + \\frac{1}{2} \\sigma^2 \\frac{\\partial^2 f}{\\partial x^2}(t, X_t)\n$$\n$$\na_Y(t, X_t) = \\alpha \\exp(\\alpha t) X_t + \\mu (\\exp(\\alpha t)) + \\frac{1}{2} \\sigma^2 (0)\n$$\n$$\na_Y(t, X_t) = (\\alpha X_t + \\mu) \\exp(\\alpha t)\n$$\nThe diffusion coefficient, $b_Y(t, X_t)$, is:\n$$\nb_Y(t, X_t) = \\sigma \\frac{\\partial f}{\\partial x}(t, X_t)\n$$\n$$\nb_Y(t, X_t) = \\sigma \\exp(\\alpha t)\n$$\nTherefore, the stochastic differential for $Y_t$ is:\n$$\ndY_t = (\\alpha X_t + \\mu)\\exp(\\alpha t)\\,dt + \\sigma \\exp(\\alpha t)\\,dW_t\n$$\nThe problem asks for the pair of coefficients $(a_Y(t, X_t), b_Y(t, X_t))$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n(\\alpha X_t + \\mu) \\exp(\\alpha t) & \\sigma \\exp(\\alpha t)\n\\end{pmatrix}\n}\n$$", "id": "3057970"}]}