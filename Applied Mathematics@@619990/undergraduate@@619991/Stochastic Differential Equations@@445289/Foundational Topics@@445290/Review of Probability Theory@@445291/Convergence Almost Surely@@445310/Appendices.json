{"hands_on_practices": [{"introduction": "Understanding almost sure convergence often begins with connecting the abstract definition to a concrete scenario. This first practice problem does exactly that by exploring a simple, non-linear dynamical system whose evolution is deterministic but whose starting point is random. By analyzing how the system evolves from an initial value drawn from a uniform distribution, you will derive the precise condition required for the sequence to converge to zero for, quite literally, almost all possible starting points. This exercise provides a foundational intuition for how the support of a distribution dictates long-term, almost sure behavior [@problem_id:1352864].", "problem": "Consider a sequence of random variables $\\{X_n\\}_{n=1}^{\\infty}$. The initial term, $X_1$, is drawn from a continuous uniform distribution on the interval $[-B, B]$, where $B$ is a positive constant. For $n \\ge 1$, the subsequent terms of the sequence are generated by the recurrence relation $X_{n+1} = A (X_n)^2$, where $A$ is also a positive constant.\n\nA sequence of random variables $\\{X_n\\}$ is said to converge almost surely to a limit $L$ if the probability of the set of outcomes for which the sequence $\\lim_{n \\to \\infty} X_n = L$ is equal to 1.\n\nWhich of the following choices represents the necessary and sufficient condition on the product of the constants, $AB$, for the sequence $\\{X_n\\}$ to converge almost surely to 0?\n\nA. $AB < 1$\n\nB. $AB \\le 1$\n\nC. $AB > 1$\n\nD. $AB \\ge 1$\n\nE. $AB = 1$", "solution": "We analyze the deterministic recurrence generated by the random initial condition. For $A>0$ and any realization of $X_1 \\in [-B,B]$, define $X_{n+1} = A(X_n)^{2}$.\n\nFirst, we obtain a closed-form expression for $X_n$ in terms of $X_1$. We claim, for all $n \\ge 1$,\n$$\nX_n = A^{-1} (A X_1)^{2^{\\,n-1}}.\n$$\nProof by induction:\n- Base case $n=1$: $A^{-1}(A X_1)^{2^{0}} = A^{-1}(A X_1) = X_1$.\n- Inductive step: assume $X_n = A^{-1}(A X_1)^{2^{n-1}}$. Then\n$$\nX_{n+1} = A (X_n)^{2} = A \\left(A^{-1}\\right)^{2} (A X_1)^{2^{n}} = A^{-1} (A X_1)^{2^{n}},\n$$\nwhich matches the claimed form with $n$ replaced by $n+1$. This completes the induction.\n\nFrom this form, for any realization with $X_1 \\neq 0$ (the event $X_1=0$ has probability zero under a continuous distribution and leads to the constant zero sequence anyway), the asymptotic behavior is determined by $|A X_1|$:\n- If $|A X_1| < 1$, then $\\lim_{n \\to \\infty} |A X_1|^{2^{n-1}} = 0$, hence $\\lim_{n \\to \\infty} X_n = 0$.\n- If $|A X_1| > 1$, then $|A X_1|^{2^{n-1}} \\to \\infty$, so $X_n \\to \\infty$.\n- If $|A X_1| = 1$, then $X_n = A^{-1}$ for all $n \\ge 2$, so the limit is not $0$.\n\nTherefore, the sequence converges to $0$ for a given realization if and only if $|A X_1| < 1$. With $X_1 \\sim \\mathrm{Unif}([-B,B])$, almost sure convergence to $0$ requires\n$$\n\\mathbb{P}(|A X_1| < 1) = 1.\n$$\nBecause the distribution is continuous and supported on $[-B,B]$, this is equivalent to having the entire support (up to endpoints, which have probability zero) contained in $(-1/A, 1/A)$. Hence the necessary and sufficient condition is\n$$\nB \\le \\frac{1}{A} \\quad \\Longleftrightarrow \\quad AB \\le 1.\n$$\nAt the boundary $AB = 1$, the only points failing $|A X_1| < 1$ are $X_1 = \\pm B = \\pm A^{-1}$, which occur with probability zero, so almost sure convergence still holds.\n\nThus, the correct choice is $AB \\le 1$.", "answer": "$$\\boxed{B}$$", "id": "1352864"}, {"introduction": "How can we be certain that a sequence of events will eventually stop occurring? This question lies at the heart of the first Borel-Cantelli Lemma, a cornerstone of probability theory. Through the engaging, hypothetical scenario of a carnival game with diminishing probabilities of success, this problem challenges you to prove that the total number of wins will be finite [@problem_id:1352851]. This practice is a classic illustration of how summing the probabilities of an infinite sequence of events can tell us whether those events will cease almost surely.", "problem": "A new carnival game, known as the \"Diminishing Returns Challenge,\" involves a sequence of independent trials, indexed by the positive integers $n = 1, 2, 3, \\ldots$. The probability of winning the $n$-th trial is given by $p_n = \\frac{1}{n^2}$. A player attempts every trial in the sequence.\n\nAssuming the player continues to play indefinitely, what is the probability that the total number of wins they accumulate is finite?\n\nThe final answer should be a single real number.", "solution": "Let $A_{n}$ be the event that the player wins on trial $n$. By the problem, $\\Pr(A_{n})=p_{n}=\\frac{1}{n^{2}}$, and the $A_{n}$ are independent. Consider the series\n$$\n\\sum_{n=1}^{\\infty}\\Pr(A_{n})=\\sum_{n=1}^{\\infty}\\frac{1}{n^{2}}=\\frac{\\pi^{2}}{6}<\\infty.\n$$\nBy the first Borel-Cantelli lemma, if $\\sum_{n=1}^{\\infty}\\Pr(A_{n})<\\infty$, then\n$$\n\\Pr(A_{n}\\ \\text{i.o.})=0,\n$$\nwhere $A_{n}$ i.o. denotes that infinitely many of the events $A_{n}$ occur. Therefore, with probability $1$, only finitely many $A_{n}$ occur, which is exactly the event that the total number of wins is finite. Hence\n$$\n\\Pr(\\text{total number of wins is finite})=1-\\Pr(A_{n}\\ \\text{i.o.})=1-0=1.\n$$", "answer": "$$\\boxed{1}$$", "id": "1352851"}, {"introduction": "In contrast to the previous problem, sometimes we want to prove that something will continue to happen forever. This exercise explores the concept of almost sure divergence by examining the maximum value in a growing sequence of standard normal random variables. Common intuition might suggest that the maximum could settle down, but this problem demonstrates that it almost surely grows without bound [@problem_id:1352847]. This is a key application of the second Borel-Cantelli Lemma, which provides the conditions under which events are guaranteed to occur infinitely often, a powerful tool for analyzing phenomena like record-breaking values and the long-term behavior of random walks.", "problem": "Let $\\{X_n\\}_{n=1}^{\\infty}$ be a sequence of independent and identically distributed (i.i.d.) random variables. Each $X_n$ follows a standard Normal distribution, denoted by $N(0, 1)$, which has a mean of 0 and a variance of 1.\n\nDefine a new sequence of random variables $\\{M_n\\}_{n=1}^{\\infty}$ where $M_n$ is the maximum of the first $n$ variables in the sequence:\n$$M_n = \\max(X_1, X_2, \\dots, X_n)$$\nWe are interested in the long-term behavior of this maximum value as $n$ approaches infinity. Which of the following statements correctly describes the almost sure convergence of the sequence $M_n$?\n\nA. $M_n$ converges almost surely to 0.\n\nB. $M_n$ converges almost surely to a finite, non-zero constant.\n\nC. $M_n$ converges almost surely to a non-degenerate random variable (i.e., a random variable that is not a constant).\n\nD. $M_n$ does not converge almost surely to any finite limit; instead, it almost surely diverges to infinity.\n\nE. The sequence $M_n$ fails to converge, with its limit superior being a finite constant and its limit inferior being $-\\infty$ almost surely.", "solution": "The problem asks for the almost sure limiting behavior of the sequence $M_n = \\max(X_1, X_2, \\dots, X_n)$, where $X_i$ are i.i.d. standard normal random variables.\n\nWe want to determine if $M_n$ converges to a finite limit almost surely. A sequence of random variables $Y_n$ converges almost surely to a limit $Y$ if $P(\\lim_{n \\to \\infty} Y_n = Y) = 1$. If $M_n$ were to converge to a finite limit $L$ almost surely, it would imply that for almost every outcome $\\omega$ in the sample space, the sequence of real numbers $M_n(\\omega)$ converges to $L$. A necessary condition for a real sequence to converge is that it must be bounded. We will show that the sequence $M_n$ is almost surely unbounded, which will rule out convergence to any finite limit.\n\nTo do this, we can use the second Borel-Cantelli Lemma. This lemma states that for a sequence of independent events $\\{A_n\\}_{n=1}^{\\infty}$, if the sum of their probabilities diverges, i.e., $\\sum_{n=1}^{\\infty} P(A_n) = \\infty$, then the probability that infinitely many of these events occur is 1.\n\nLet's fix an arbitrary, large positive number $K$. Define the event $A_n$ as $A_n = \\{X_n > K\\}$. This event corresponds to the $n$-th observation exceeding the threshold $K$.\n\nWe check the conditions of the second Borel-Cantelli Lemma for the sequence of events $\\{A_n\\}$:\n1.  **Independence**: The random variables $X_n$ are independent by definition. Therefore, the events $A_n = \\{X_n > K\\}$, which depend only on $X_n$, are also independent.\n2.  **Sum of Probabilities**: The random variables are identically distributed, so $P(A_n) = P(X_n > K)$ is a constant for all $n$. Let this probability be $p = P(X_1 > K)$. The standard normal distribution $N(0,1)$ has a probability density function $f(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$, which is positive for all real $x$. This means that for any finite value $K$, the probability of observing a value greater than $K$ is strictly positive. So, $p = P(X_1 > K) = \\int_K^\\infty f(x) dx > 0$.\n\nNow we consider the sum of the probabilities:\n$$ \\sum_{n=1}^{\\infty} P(A_n) = \\sum_{n=1}^{\\infty} p $$\nSince $p$ is a positive constant, this sum is a sum of infinitely many identical positive numbers, which diverges to infinity: $\\sum_{n=1}^{\\infty} p = \\infty$.\n\nSince the events $\\{A_n\\}$ are independent and the sum of their probabilities diverges, the second Borel-Cantelli Lemma applies. It tells us that the probability of $A_n$ occurring infinitely often is 1.\n$$ P(A_n \\text{ i.o.}) = 1 $$\nThis means that, with probability 1, the event $\\{X_n > K\\}$ happens for infinitely many values of $n$.\n\nNow we relate this back to the maximum, $M_n$. If, for a given outcome, $X_n > K$ for infinitely many $n$, then the sequence of maximums $M_n = \\max(X_1, \\dots, X_n)$ must eventually exceed $K$. More strongly, the sequence $M_n$ cannot be bounded by $K$. Every time an $X_m > K$ occurs, $M_m$ will be at least $K$. As this happens infinitely often, the sequence $M_n$ cannot converge to any value less than or equal to $K$.\n\nThis argument holds for any choice of a finite number $K$, no matter how large. We can choose $K=100$, $K=1000$, or any other large number. For each such $K$, it is almost certain that $M_n$ will eventually exceed it. This implies that the sequence $M_n$ is almost surely unbounded.\n\nA sequence that is unbounded cannot converge to a finite limit. Therefore, options A and B are incorrect.\nThe sequence $M_n$ is a non-decreasing sequence, because $M_{n+1} = \\max(M_n, X_{n+1}) \\ge M_n$. A non-decreasing sequence of real numbers always has a limit, which is either a finite number or $+\\infty$. Since we have shown that $M_n$ is almost surely unbounded, it cannot converge to a finite limit. Therefore, it must diverge to $+\\infty$ almost surely.\nSo, $\\lim_{n \\to \\infty} M_n = \\infty$ almost surely.\n\nThis means that $M_n$ does not converge to a non-degenerate random variable (Option C) or have a finite limit superior (Option E). The correct statement is that $M_n$ almost surely diverges to infinity.\n\nThus, option D is the correct description.", "answer": "$$\\boxed{D}$$", "id": "1352847"}]}