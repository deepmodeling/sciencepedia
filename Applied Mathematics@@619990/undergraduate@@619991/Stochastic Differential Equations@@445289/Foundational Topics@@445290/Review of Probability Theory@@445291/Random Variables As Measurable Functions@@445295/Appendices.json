{"hands_on_practices": [{"introduction": "To truly grasp the concept of a random variable as a measurable function, we must move beyond our intuition about continuous or \"well-behaved\" functions. This first practice [@problem_id:1440291] introduces the Dirichlet function, a classic example that is discontinuous everywhere but is still a perfectly valid random variable. By directly applying the definition of measurability, this exercise demonstrates that the structure of the preimages, not the function's continuity, is the defining characteristic of a random variable.", "problem": "In probability theory, a random variable is formally defined as a measurable function. Let the sample space be the set of real numbers, $\\Omega = \\mathbb{R}$, equipped with the Borel $\\sigma$-algebra, $\\mathcal{F} = \\mathcal{B}(\\mathbb{R})$. The Borel $\\sigma$-algebra $\\mathcal{B}(\\mathbb{R})$ is the smallest $\\sigma$-algebra on $\\mathbb{R}$ that contains all open sets.\n\nA function $X: (\\Omega, \\mathcal{F}) \\to (\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$ is called a random variable (or is said to be $\\mathcal{F}$-measurable) if for every set $B$ in the Borel $\\sigma$-algebra of the codomain, its preimage $X^{-1}(B) = \\{\\omega \\in \\Omega \\mid X(\\omega) \\in B\\}$ is an element of the $\\sigma$-algebra of the domain, $\\mathcal{F}$.\n\nConsider the Dirichlet function, $D: \\mathbb{R} \\to \\mathbb{R}$, defined as:\n$$\nD(x) = \\begin{cases} \n1  \\text{if } x \\in \\mathbb{Q} \\\\\n0  \\text{if } x \\in \\mathbb{R} \\setminus \\mathbb{Q} \n\\end{cases}\n$$\nwhere $\\mathbb{Q}$ is the set of rational numbers and $\\mathbb{R} \\setminus \\mathbb{Q}$ is the set of irrational numbers.\n\nIs the Dirichlet function $D(x)$ a random variable on the measurable space $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$? Select the correct statement and justification from the options below.\n\nA. Yes, because the preimages of all possible Borel sets in the codomain under $D$ are one of the four sets: $\\emptyset$, $\\mathbb{Q}$, $\\mathbb{R} \\setminus \\mathbb{Q}$, or $\\mathbb{R}$, all of which are members of the Borel $\\sigma$-algebra $\\mathcal{B}(\\mathbb{R})$.\n\nB. No, because the function is discontinuous at every point in its domain, and a function must be at least piecewise continuous to be a random variable.\n\nC. No, because the preimage of the Borel set $\\{1\\}$, which is the set of rational numbers $\\mathbb{Q}$, is not a Borel set itself.\n\nD. Yes, because all simple functions (functions with a finite range) are always random variables, and the Dirichlet function is a simple function with range $\\{0, 1\\}$.", "solution": "To determine if the Dirichlet function $D(x)$ is a random variable on the measurable space $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$, we must check if it is a measurable function. According to the definition provided, this means we must verify that for any Borel set $B \\in \\mathcal{B}(\\mathbb{R})$, its preimage $D^{-1}(B)$ is also a Borel set, i.e., $D^{-1}(B) \\in \\mathcal{B}(\\mathbb{R})$.\n\nThe Dirichlet function $D(x)$ maps any rational number to $1$ and any irrational number to $0$. The range of the function is the set $\\{0, 1\\}$. Let's analyze the structure of the preimage $D^{-1}(B)$ for an arbitrary Borel set $B \\subseteq \\mathbb{R}$.\n\nThere are four distinct cases based on whether $0$ and $1$ are elements of the set $B$:\n\n1.  **Case 1: $0 \\notin B$ and $1 \\notin B$**\n    In this case, for any $x \\in \\mathbb{R}$, the value $D(x)$ (which is either $0$ or $1$) cannot be in $B$. Therefore, there are no elements in the domain that map into $B$.\n    $$D^{-1}(B) = \\emptyset$$\n    The empty set $\\emptyset$ is, by definition, an element of every $\\sigma$-algebra, so $\\emptyset \\in \\mathcal{B}(\\mathbb{R})$.\n\n2.  **Case 2: $0 \\in B$ and $1 \\notin B$**\n    In this case, an element $x \\in \\mathbb{R}$ maps into $B$ if and only if $D(x) = 0$. This is true for all irrational numbers.\n    $$D^{-1}(B) = \\{x \\in \\mathbb{R} \\mid D(x) = 0\\} = \\mathbb{R} \\setminus \\mathbb{Q}$$\n\n3.  **Case 3: $0 \\notin B$ and $1 \\in B$**\n    In this case, an element $x \\in \\mathbb{R}$ maps into $B$ if and only if $D(x) = 1$. This is true for all rational numbers.\n    $$D^{-1}(B) = \\{x \\in \\mathbb{R} \\mid D(x) = 1\\} = \\mathbb{Q}$$\n\n4.  **Case 4: $0 \\in B$ and $1 \\in B$**\n    In this case, an element $x \\in \\mathbb{R}$ maps into $B$ regardless of whether it is rational or irrational, since $D(x)$ will be either $0$ or $1$, both of which are in $B$.\n    $$D^{-1}(B) = \\mathbb{R}$$\n    The entire space $\\mathbb{R}$ is, by definition, an element of any $\\sigma$-algebra on $\\mathbb{R}$, so $\\mathbb{R} \\in \\mathcal{B}(\\mathbb{R})$.\n\nSo, for any Borel set $B$, the preimage $D^{-1}(B)$ must be one of the four sets: $\\emptyset$, $\\mathbb{R}$, $\\mathbb{Q}$, or $\\mathbb{R} \\setminus \\mathbb{Q}$. For $D(x)$ to be a random variable, all four of these sets must belong to the Borel $\\sigma$-algebra $\\mathcal{B}(\\mathbb{R})$. We already know $\\emptyset \\in \\mathcal{B}(\\mathbb{R})$ and $\\mathbb{R} \\in \\mathcal{B}(\\mathbb{R})$. We need to check $\\mathbb{Q}$ and $\\mathbb{R} \\setminus \\mathbb{Q}$.\n\nFirst, consider the set of rational numbers, $\\mathbb{Q}$. The set $\\mathbb{Q}$ is countable. We can write it as a sequence of its elements, $\\mathbb{Q} = \\{q_1, q_2, q_3, \\dots\\}$. Each singleton set $\\{q_i\\}$ is a closed set in the standard topology of $\\mathbb{R}$. All closed sets are, by definition, members of the Borel $\\sigma-algebra$. A $\\sigma$-algebra is closed under countable unions. Therefore, the set $\\mathbb{Q}$ can be expressed as a countable union of Borel sets:\n$$\\mathbb{Q} = \\bigcup_{i=1}^{\\infty} \\{q_i\\}$$\nSince each $\\{q_i\\} \\in \\mathcal{B}(\\mathbb{R})$, their countable union $\\mathbb{Q}$ is also in $\\mathcal{B}(\\mathbb{R})$.\n\nNext, consider the set of irrational numbers, $\\mathbb{R} \\setminus \\mathbb{Q}$. Since we have shown that $\\mathbb{Q} \\in \\mathcal{B}(\\mathbb{R})$ and we know $\\mathbb{R} \\in \\mathcal{B}(\\mathbb{R})$, we can use the property that a $\\sigma$-algebra is closed under complements. The set of irrationals is the complement of the set of rationals in $\\mathbb{R}$. Therefore,\n$$\\mathbb{R} \\setminus \\mathbb{Q} \\in \\mathcal{B}(\\mathbb{R})$$\nSince all four possible preimages ($\\emptyset$, $\\mathbb{Q}$, $\\mathbb{R} \\setminus \\mathbb{Q}$, and $\\mathbb{R}$) are in $\\mathcal{B}(\\mathbb{R})$, the Dirichlet function satisfies the condition for measurability. Thus, $D(x)$ is a random variable on $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$.\n\nNow let's evaluate the given options:\n- **A:** This statement correctly summarizes our findings. The preimages are restricted to a specific collection of four sets, and all of these sets are indeed Borel sets. This makes the function measurable. This option is correct.\n- **B:** This is false. A function does not need to be continuous to be measurable. The Dirichlet function is a classic counterexample, as it is nowhere continuous but is measurable.\n- **C:** This is false. As shown above, the set $\\mathbb{Q}$ is a Borel set because it is a countable union of closed sets (the singletons).\n- **D:** This statement contains a subtle error. While the Dirichlet function is a simple function, the statement \"all simple functions are always random variables\" is not universally true. A simple function of the form $\\sum_{i=1}^n a_i \\mathbb{1}_{A_i}$ is measurable with respect to a $\\sigma$-algebra $\\mathcal{F}$ if and only if each set $A_i$ is in $\\mathcal{F}$. In this case, $D = 1 \\cdot \\mathbb{1}_{\\mathbb{Q}} + 0 \\cdot \\mathbb{1}_{\\mathbb{R}\\setminus\\mathbb{Q}}$. It is measurable because the sets $\\mathbb{Q}$ and $\\mathbb{R}\\setminus\\mathbb{Q}$ are in $\\mathcal{B}(\\mathbb{R})$. The option is incorrect because it presents a blanket statement that is not always true without the necessary condition on the partitioning sets.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1440291"}, {"introduction": "The abstract definition of a random variable is not merely a theoretical exercise; it is the foundation upon which we solve concrete problems in science and engineering. This next practice [@problem_id:1440309] places the concept in a simplified signal processing context, where an electronic circuit modifies a voltage signal. You will see how a function of a random variable—in this case, the output of a rectifier—is itself a random variable, and you will use this property to calculate a specific probability, bridging the gap between formal theory and practical application.", "problem": "In a simplified model of a phase-sensitive detector, an internal oscillator generates a random phase $\\Theta$. This phase is assumed to be a random variable uniformly distributed on the interval $[0, 2\\pi)$. The detector produces a voltage signal $V$ that is a function of this phase, given by the relationship $V(\\Theta) = K \\cos(\\Theta)$, where $K$ is a known positive voltage constant. It is given that $V$ is a random variable on the underlying probability space.\n\nThis signal is then processed by a half-wave rectifier, an electronic circuit that clips all negative voltages to zero. The output of the rectifier is a new signal, which we can define as a function $V_{\\text{rect}} = \\max(V, 0)$. This rectified voltage is also a random variable.\n\nCalculate the probability that the rectified voltage $V_{\\text{rect}}$ is greater than $\\frac{K}{2}$. Express your final answer as a single fraction in its simplest form.", "solution": "Let $\\Theta$ be uniformly distributed on $[0, 2\\pi)$, so for any measurable set $A \\subset [0, 2\\pi)$ the probability is $P(\\Theta \\in A) = \\frac{|A|}{2\\pi}$, where $|A|$ denotes Lebesgue measure (length).\n\nThe voltage is $V(\\Theta) = K \\cos(\\Theta)$ with $K0$. The rectified voltage is $V_{\\text{rect}} = \\max(V, 0) = \\max(K \\cos(\\Theta), 0)$. We seek\n$$\nP\\left(V_{\\text{rect}}  \\frac{K}{2}\\right).\n$$\nSince $K0$, the inequality $V_{\\text{rect}}  \\frac{K}{2}$ is equivalent to\n$$\n\\max\\left(\\cos(\\Theta), 0\\right)  \\frac{1}{2}.\n$$\nIf $\\cos(\\Theta) \\leq 0$, then $\\max(\\cos(\\Theta), 0) = 0$, which cannot exceed $\\frac{1}{2}$. Thus the event reduces to\n$$\n\\cos(\\Theta)  \\frac{1}{2}.\n$$\nSolving $\\cos(\\Theta)  \\frac{1}{2}$ over one period gives\n$$\n\\Theta \\in \\left(-\\arccos\\left(\\frac{1}{2}\\right), \\arccos\\left(\\frac{1}{2}\\right)\\right) \\pmod{2\\pi}.\n$$\nUsing $\\arccos\\left(\\frac{1}{2}\\right) = \\frac{\\pi}{3}$, the subset of $[0, 2\\pi)$ where this holds is\n$$\n(0, \\frac{\\pi}{3}) \\cup \\left(2\\pi - \\frac{\\pi}{3}, 2\\pi\\right),\n$$\nwhose total length is $\\frac{2\\pi}{3}$. Therefore,\n$$\nP\\left(V_{\\text{rect}}  \\frac{K}{2}\\right) = \\frac{\\frac{2\\pi}{3}}{2\\pi} = \\frac{1}{3}.\n$$\nThe strict inequality does not alter the result since $P(\\cos(\\Theta) = \\frac{1}{2}) = 0$ for a continuous distribution.", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1440309"}, {"introduction": "One of the most powerful techniques in mathematics is approximating complex objects with simpler ones. This principle is central to the theory of integration and stochastic processes. This final exercise [@problem_id:3072019] guides you through the fundamental construction of approximating a general bounded random variable with a sequence of simple random variables. By building this approximation and calculating the precise error bound, you will gain insight into the theoretical machinery that underpins much of modern probability theory and its applications in fields like quantitative finance.", "problem": "Let $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a probability space with a filtration $(\\mathcal{F}_{t})_{t \\ge 0}$. Fix a time $t0$. Consider a bounded $\\mathcal{F}_{t}$-measurable random variable $X:\\Omega \\to \\mathbb{R}$ that represents the state at time $t$ of a solution to a stochastic differential equation (SDE), and suppose there exist real constants $\\alpha\\beta$ such that $\\alpha \\le X(\\omega) \\le \\beta$ for all $\\omega \\in \\Omega$. For each $n \\in \\mathbb{N}$, partition the interval $[\\alpha,\\beta]$ into $2^{n}$ equal subintervals of length $\\Delta_{n} = (\\beta-\\alpha)/2^{n}$, and define a simple random variable $S_{n}$ by assigning to each $\\omega$ the midpoint of the subinterval of $[\\alpha,\\beta]$ that contains $X(\\omega)$. \n\nUsing only the definition of a random variable as a measurable function (that is, the preimage under $X$ of every Borel set is in $\\mathcal{F}_{t}$), the definition of a simple random variable as a finite-valued measurable function, and basic properties of partitions of the real line, rigorously construct $S_{n}$ as a simple $\\mathcal{F}_{t}$-measurable random variable and show that $S_{n} \\to X$ uniformly as $n \\to \\infty$. Then determine the smallest constant $E_{n}$, depending only on $n$, $\\alpha$, and $\\beta$, such that\n$$\n\\sup_{\\omega \\in \\Omega} |X(\\omega)-S_{n}(\\omega)| \\le E_{n}\n$$\nholds for every such $X$ with $\\alpha \\le X \\le \\beta$ pointwise. Your final answer must be a single closed-form analytic expression in terms of $n$, $\\alpha$, and $\\beta$.", "solution": "The problem is valid as it is a well-posed, scientifically grounded, and objective question within the domain of measure-theoretic probability theory. It asks for the construction and analysis of a standard approximation scheme for a bounded measurable function.\n\nLet $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a probability space, $(\\mathcal{F}_{t})_{t \\ge 0}$ a filtration, and $X$ a bounded $\\mathcal{F}_{t}$-measurable random variable for a fixed $t0$. We are given that there exist constants $\\alpha, \\beta \\in \\mathbb{R}$ with $\\alpha  \\beta$ such that the range of $X$ is contained in the interval $[\\alpha, \\beta]$.\n\nFirst, we rigorously construct the simple random variable $S_{n}$. For each $n \\in \\mathbb{N}$, we are given the length of the subintervals $\\Delta_{n} = (\\beta-\\alpha)/2^{n}$. We partition the interval $[\\alpha, \\beta]$ into $2^{n}$ disjoint subintervals whose union is $[\\alpha, \\beta]$. Let the partition points be $x_{k}^{(n)} = \\alpha + k\\Delta_{n}$ for $k \\in \\{0, 1, \\dots, 2^{n}\\}$. Note that $x_{0}^{(n)} = \\alpha$ and $x_{2^{n}}^{(n)} = \\beta$. We define the subintervals as:\nFor $k = 1, 2, \\dots, 2^{n}-1$, let $I_{k}^{(n)} = [x_{k-1}^{(n)}, x_{k}^{(n)})$.\nFor $k = 2^{n}$, let $I_{2^{n}}^{(n)} = [x_{2^{n}-1}^{(n)}, x_{2^{n}}^{(n)}] = [\\beta - \\Delta_{n}, \\beta]$.\nThese intervals $\\{I_{k}^{(n)}\\}_{k=1}^{2^n}$ form a partition of $[\\alpha, \\beta]$. Each $I_{k}^{(n)}$ is a Borel set in $\\mathbb{R}$.\n\nThe midpoint of the $k$-th interval, $I_{k}^{(n)}$, is given by\n$$ m_{k}^{(n)} = x_{k-1}^{(n)} + \\frac{\\Delta_{n}}{2} = \\alpha + (k-1)\\Delta_{n} + \\frac{\\Delta_{n}}{2} = \\alpha + \\left(k - \\frac{1}{2}\\right)\\Delta_{n} $$\nThe problem defines $S_{n}(\\omega)$ as the midpoint of the subinterval containing $X(\\omega)$. We can express this formally as a function:\n$$ S_{n}(\\omega) = \\sum_{k=1}^{2^{n}} m_{k}^{(n)} \\mathbf{1}_{A_{k}^{(n)}}(\\omega) $$\nwhere $\\mathbf{1}_{A}$ is the indicator function of a set $A$, and the sets $A_{k}^{(n)}$ are defined as:\n$$ A_{k}^{(n)} = \\{\\omega \\in \\Omega \\mid X(\\omega) \\in I_{k}^{(n)}\\} = X^{-1}(I_{k}^{(n)}) $$\nSince the intervals $I_{k}^{(n)}$ partition the range of $X$, for any given $\\omega \\in \\Omega$, $X(\\omega)$ falls into exactly one interval $I_{k}^{(n)}$, so $S_{n}(\\omega)$ is well-defined and takes exactly one value $m_{k}^{(n)}$.\n\nTo show that $S_{n}$ is a simple $\\mathcal{F}_{t}$-measurable random variable, we must verify two conditions:\n1.  $S_{n}$ takes only a finite number of values. This is true by construction, as the set of possible values for $S_{n}$ is $\\{m_{1}^{(n)}, m_{2}^{(n)}, \\dots, m_{2^{n}}^{(n)}\\}$, which has $2^{n}$ elements.\n2.  $S_{n}$ is $\\mathcal{F}_{t}$-measurable. A function is measurable with respect to a $\\sigma$-algebra if the preimage of every Borel set is in the $\\sigma$-algebra. For a simple function like $S_n$, it is sufficient to show that the sets on which it takes its constant values are measurable. These sets are the $A_{k}^{(n)}$.\nBy definition, $A_{k}^{(n)} = X^{-1}(I_{k}^{(n)})$. We are given that $X$ is an $\\mathcal{F}_{t}$-measurable random variable. By the definition of a random variable, this means that for any Borel set $B \\subset \\mathbb{R}$, its preimage $X^{-1}(B)$ is an element of the $\\sigma$-algebra $\\mathcal{F}_{t}$. Since each interval $I_{k}^{(n)}$ is a Borel set, its preimage $A_{k}^{(n)} = X^{-1}(I_{k}^{(n)})$ must belong to $\\mathcal{F}_{t}$.\nThus, $S_{n}$ is a finite linear combination of indicator functions of sets in $\\mathcal{F}_{t}$, which proves that $S_{n}$ is a simple $\\mathcal{F}_{t}$-measurable random variable.\n\nNext, we show that $S_{n} \\to X$ uniformly as $n \\to \\infty$ and find the requested error bound.\nFor any $\\omega \\in \\Omega$, let $k$ be the unique index such that $X(\\omega) \\in I_{k}^{(n)}$. By definition, $S_{n}(\\omega) = m_{k}^{(n)}$.\nThe value $X(\\omega)$ and the midpoint $m_{k}^{(n)}$ are both in the interval $I_{k}^{(n)}$ or its closure. The length of this interval is $\\text{length}(I_k^{(n)}) = \\Delta_n$. The maximum possible distance between any point in an interval and its midpoint is half the length of the interval.\nTherefore, for any $\\omega \\in \\Omega$:\n$$ |X(\\omega) - S_{n}(\\omega)| = |X(\\omega) - m_{k}^{(n)}| \\le \\frac{1}{2} \\text{length}(I_{k}^{(n)}) = \\frac{\\Delta_{n}}{2} $$\nSubstituting the expression for $\\Delta_{n}$:\n$$ |X(\\omega) - S_{n}(\\omega)| \\le \\frac{1}{2} \\left(\\frac{\\beta-\\alpha}{2^{n}}\\right) = \\frac{\\beta-\\alpha}{2^{n+1}} $$\nThis inequality holds for all $\\omega \\in \\Omega$. The right-hand side is a constant that depends only on $n$, $\\alpha$, and $\\beta$, not on $\\omega$ or the specific choice of $X$. Taking the supremum over all $\\omega \\in \\Omega$, we get the uniform error bound for a specific $X$:\n$$ \\sup_{\\omega \\in \\Omega} |X(\\omega) - S_{n}(\\omega)| \\le \\frac{\\beta-\\alpha}{2^{n+1}} $$\nAs $n \\to \\infty$, the term $2^{n+1} \\to \\infty$, so the bound $(\\beta-\\alpha)/2^{n+1} \\to 0$. By the Squeeze Theorem, $\\sup_{\\omega \\in \\Omega} |X(\\omega) - S_{n}(\\omega)| \\to 0$, which is the definition of uniform convergence, $S_{n} \\to X$.\n\nFinally, we must determine the smallest constant $E_{n}$ such that $\\sup_{\\omega \\in \\Omega} |X(\\omega)-S_{n}(\\omega)| \\le E_{n}$ holds for *every* such random variable $X$. This smallest constant is the supremum of the uniform error over all possible choices of $X$ that satisfy the given conditions:\n$$ E_{n} = \\sup_{\\substack{X: \\Omega \\to [\\alpha, \\beta] \\\\ X \\text{ is } \\mathcal{F}_t\\text{-measurable}}} \\left( \\sup_{\\omega \\in \\Omega} |X(\\omega) - S_{n}(\\omega)| \\right) $$\nFrom our previous derivation, we know that for any valid $X$, the uniform error is bounded above by $(\\beta-\\alpha)/2^{n+1}$. This implies that $E_{n} \\le (\\beta-\\alpha)/2^{n+1}$.\n\nTo show that this bound is the smallest possible, we must demonstrate that it is attainable. We need to find at least one valid random variable $X$ for which the uniform error is exactly $(\\beta-\\alpha)/2^{n+1}$.\nLet us choose a simple probability space where $\\Omega = \\{\\omega_0\\}$ and $\\mathcal{F}=\\mathcal{F}_t=\\{\\emptyset, \\Omega\\}$. Consider the constant random variable $X(\\omega) = \\alpha$ for all $\\omega \\in \\Omega$.\nThis $X$ is $\\mathcal{F}_t$-measurable because for any Borel set $B$, $X^{-1}(B)$ is $\\Omega$ if $\\alpha \\in B$ and $\\emptyset$ otherwise; both are in $\\mathcal{F}_t$. The range of $X$ is $\\{\\alpha\\}$, which is contained in $[\\alpha, \\beta]$. So, this $X$ is a valid choice.\nFor this $X$, for any $\\omega$, $X(\\omega)=\\alpha$. The value $\\alpha$ lies in the first subinterval, $I_{1}^{(n)} = [\\alpha, \\alpha+\\Delta_{n})$.\nBy definition, $S_n(\\omega)$ is the midpoint of this interval:\n$$ S_{n}(\\omega) = m_{1}^{(n)} = \\alpha + \\frac{\\Delta_{n}}{2} $$\nThe error for this choice of $X$ is:\n$$ |X(\\omega) - S_{n}(\\omega)| = \\left| \\alpha - \\left(\\alpha + \\frac{\\Delta_{n}}{2}\\right) \\right| = \\left| -\\frac{\\Delta_{n}}{2} \\right| = \\frac{\\Delta_{n}}{2} = \\frac{\\beta-\\alpha}{2^{n+1}} $$\nSince this error is constant for all $\\omega$, the supremum over $\\omega$ is also this value:\n$$ \\sup_{\\omega \\in \\Omega} |X(\\omega) - S_{n}(\\omega)| = \\frac{\\beta-\\alpha}{2^{n+1}} $$\nWe have found a specific $X$ for which the uniform error achieves the value $(\\beta-\\alpha)/2^{n+1}$. Therefore, the supremum of these errors over all possible $X$ cannot be smaller than this value. This gives us the lower bound:\n$$ E_{n} \\ge \\frac{\\beta-\\alpha}{2^{n+1}} $$\nCombining our two inequalities, $E_{n} \\le \\frac{\\beta-\\alpha}{2^{n+1}}$ and $E_{n} \\ge \\frac{\\beta-\\alpha}{2^{n+1}}$, we conclude that the smallest constant $E_n$ is exactly this value.\n\n$$ E_{n} = \\frac{\\beta-\\alpha}{2^{n+1}} $$\nThis expression depends only on $n$, $\\alpha$, and $\\beta$, as required.", "answer": "$$\n\\boxed{\\frac{\\beta - \\alpha}{2^{n+1}}}\n$$", "id": "3072019"}]}