{"hands_on_practices": [{"introduction": "Calculating the mean and variance is the first step in characterizing any stochastic process. This exercise goes back to basics, asking you to derive the variance of an Arithmetic Brownian Motion from first principles [@problem_id:3052666]. By working through this fundamental problem, you will see exactly how the properties of the underlying Brownian motion, like $\\mathbb{E}[W_t] = 0$ and $\\text{Var}(W_t) = t$, directly shape the uncertainty in the SDE's solution over time.", "problem": "Consider the one-dimensional stochastic differential equation (SDE) driven by standard Brownian motion on a filtered probability space satisfying the usual conditions: \n$$\n\\mathrm{d}X_{t}=\\lambda\\,\\mathrm{d}t+\\sigma\\,\\mathrm{d}W_{t},\\quad t\\ge 0,\n$$\nwith deterministic initial condition $X_{0}=x_{0}$, where $\\lambda\\in\\mathbb{R}$ and $\\sigma>0$ are constants, and $\\{W_{t}\\}_{t\\ge 0}$ is standard Brownian motion. Using only fundamental properties of Brownian motion and the Itô integral with constant integrand, derive from first principles a closed-form expression for the variance of $X_{t}$ as a function of $t$, $\\lambda$, $\\sigma$, and $x_{0}$. Express your final answer as a single simplified analytic expression. No numerical rounding is required.", "solution": "The problem statement is validated as scientifically grounded, well-posed, objective, and self-contained. It describes a standard arithmetic Brownian motion, which is a fundamental model in the theory of stochastic processes. All necessary parameters ($\\lambda$, $\\sigma$), the initial condition ($x_{0}$), and the nature of the driving process ($\\{W_{t}\\}_{t\\ge 0}$ as standard Brownian motion) are clearly and consistently defined. The task is to derive a standard result from first principles, which is a legitimate and well-defined mathematical exercise. There are no contradictions, ambiguities, or factual unsoundness present.\n\nThe variance of a random variable $Y$ is defined by the formula $\\text{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$. To find the variance of the process $X_{t}$, we must first compute its expectation, $\\mathbb{E}[X_{t}]$, and its second moment, $\\mathbb{E}[X_{t}^2]$.\n\nFirst, we find the explicit solution to the given stochastic differential equation (SDE). The SDE is:\n$$\n\\mathrm{d}X_{s} = \\lambda\\,\\mathrm{d}s + \\sigma\\,\\mathrm{d}W_{s}\n$$\nWe integrate this equation from time $s=0$ to $s=t$:\n$$\n\\int_{0}^{t} \\mathrm{d}X_s = \\int_{0}^{t} \\lambda\\,\\mathrm{d}s + \\int_{0}^{t} \\sigma\\,\\mathrm{d}W_s\n$$\nThe integral on the left side is $X_t - X_0$. The first integral on the right side is a standard Riemann integral of a constant, which evaluates to $\\lambda t$. The second integral is an Itô integral with a constant integrand, $\\sigma$. This is defined as $\\sigma$ multiplied by the Itô integral of the function $f(s)=1$, which is $\\sigma(W_t - W_0)$.\n$$X_t - X_0 = \\lambda t + \\sigma(W_t - W_0)$$\nGiven the deterministic initial condition $X_{0}=x_{0}$ and the property of standard Brownian motion that $W_{0}=0$ almost surely, the explicit solution for $X_{t}$ is:\n$$X_t = x_{0} + \\lambda t + \\sigma W_t$$\nWith this closed-form solution, we can compute the required moments.\n\nWe begin with the expectation of $X_t$. Using the linearity of the expectation operator:\n$$\\mathbb{E}[X_t] = \\mathbb{E}[x_{0} + \\lambda t + \\sigma W_t] = \\mathbb{E}[x_{0}] + \\mathbb{E}[\\lambda t] + \\mathbb{E}[\\sigma W_t]$$\nSince $x_{0}$, $\\lambda$, and $t$ are deterministic quantities, their expectations are themselves, so $\\mathbb{E}[x_{0}] = x_{0}$ and $\\mathbb{E}[\\lambda t] = \\lambda t$. The expectation of the stochastic component is $\\mathbb{E}[\\sigma W_t] = \\sigma \\mathbb{E}[W_t]$. A fundamental property of standard Brownian motion is that its mean is zero for all $t \\ge 0$, i.e., $\\mathbb{E}[W_t] = 0$.\nTherefore, the expectation of $X_t$ is:\n$$\\mathbb{E}[X_t] = x_{0} + \\lambda t + \\sigma(0) = x_{0} + \\lambda t$$\n\nNext, we compute the second moment of $X_t$, which is $\\mathbb{E}[X_t^2]$.\n$$\\mathbb{E}[X_t^2] = \\mathbb{E}[(x_{0} + \\lambda t + \\sigma W_t)^2]$$\nFor clarity, let the deterministic mean be denoted by $\\mu_t = \\mathbb{E}[X_t] = x_{0} + \\lambda t$. Then $X_t = \\mu_t + \\sigma W_t$.\n$$\\mathbb{E}[X_t^2] = \\mathbb{E}[(\\mu_t + \\sigma W_t)^2] = \\mathbb{E}[\\mu_t^2 + 2\\mu_t \\sigma W_t + \\sigma^2 W_t^2]$$\nAgain, applying the linearity of expectation:\n$$\\mathbb{E}[X_t^2] = \\mathbb{E}[\\mu_t^2] + \\mathbb{E}[2\\mu_t \\sigma W_t] + \\mathbb{E}[\\sigma^2 W_t^2]$$\nAs $\\mu_t$ and $\\sigma$ are deterministic:\n$$\\mathbb{E}[X_t^2] = \\mu_t^2 + 2\\mu_t \\sigma \\mathbb{E}[W_t] + \\sigma^2 \\mathbb{E}[W_t^2]$$\nWe have already used $\\mathbb{E}[W_t] = 0$. For the term $\\mathbb{E}[W_t^2]$, we use another fundamental property of standard Brownian motion: its variance is equal to time, $\\text{Var}(W_t) = t$. From the definition of variance, $\\text{Var}(W_t) = \\mathbb{E}[W_t^2] - (\\mathbb{E}[W_t])^2$.\nSubstituting the known values gives $t = \\mathbb{E}[W_t^2] - (0)^2$, which implies that the second moment of a standard Brownian motion is $\\mathbb{E}[W_t^2] = t$.\nSubstituting these results back into the expression for $\\mathbb{E}[X_t^2]$ yields:\n$$\\mathbb{E}[X_t^2] = \\mu_t^2 + 2\\mu_t \\sigma (0) + \\sigma^2 t = \\mu_t^2 + \\sigma^2 t$$\nSubstituting back the expression for $\\mu_t = x_{0} + \\lambda t$:\n$$\\mathbb{E}[X_t^2] = (x_{0} + \\lambda t)^2 + \\sigma^2 t$$\n\nFinally, we compute the variance of $X_t$ using its definition:\n$$\\text{Var}(X_t) = \\mathbb{E}[X_t^2] - (\\mathbb{E}[X_t])^2$$\nSubstituting the expressions we have derived for the first and second moments:\n$$\\text{Var}(X_t) = \\left((x_{0} + \\lambda t)^2 + \\sigma^2 t\\right) - (x_{0} + \\lambda t)^2$$\nThe terms involving the mean, $(x_{0} + \\lambda t)^2$, cancel out:\n$$\\text{Var}(X_t) = \\sigma^2 t$$\nThis expression provides the variance of $X_t$ as a function of the model parameters. Notably, the variance increases linearly with time $t$ and is proportional to the square of the volatility parameter $\\sigma$. It is independent of the initial condition $x_{0}$ and the drift coefficient $\\lambda$, as these parameters only shift the mean of the process, not its dispersion.", "answer": "$$\\boxed{\\sigma^{2}t}$$", "id": "3052666"}, {"introduction": "While variance measures the spread of a distribution, higher moments like skewness and kurtosis provide a more complete picture of its shape. This practice explores these higher-order statistics for a very important class of processes: those whose solutions follow a Gaussian (normal) distribution [@problem_id:3052718]. Your task is to show how the third and fourth moments of a Gaussian variable are completely determined by its mean and variance, a unique and powerful simplifying property of this distribution.", "problem": "Consider the linear stochastic differential equation $\\mathrm{d}X_t = a(t)\\,X_t\\,\\mathrm{d}t + b(t)\\,\\mathrm{d}t + \\sigma(t)\\,\\mathrm{d}W_t$ driven by a standard Brownian motion, where $a(t)$, $b(t)$, and $\\sigma(t)$ are deterministic functions of time and the initial condition $X_0$ is Gaussian. It is a well-known result that for each fixed time $t$, the solution $X_t$ is Gaussian with mean $m_t$ and variance $v_t$, that is, $X_t \\sim \\mathcal{N}(m_t, v_t)$. Without computing $m_t$ or $v_t$, and starting from core definitions and well-known properties of Gaussian random variables, express the third and fourth raw moments $\\mathbb{E}[X_t^3]$ and $\\mathbb{E}[X_t^4]$ purely in terms of $m_t$ and $v_t$. Provide your answers as closed-form expressions in $m_t$ and $v_t$. The final answer should contain no units and no numerical approximations.", "solution": "The problem requires expressing the third and fourth raw moments, $\\mathbb{E}[X_t^3]$ and $\\mathbb{E}[X_t^4]$, of a Gaussian random variable $X_t \\sim \\mathcal{N}(m_t, v_t)$ in terms of its mean $m_t$ and variance $v_t$. For notational simplicity during the derivation, let's consider a generic Gaussian random variable $X \\sim \\mathcal{N}(m, v)$, and we will reintroduce the subscript $t$ in the final expressions.\n\nThe mean is $\\mathbb{E}[X] = m$ and the variance is $\\text{Var}(X) = v$. The relationship between variance and the first two raw moments is $v = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = \\mathbb{E}[X^2] - m^2$.\n\nA standard method to relate raw moments to the parameters of a distribution is through its central moments. A central moment of order $k$ is defined as $\\mu_k = \\mathbb{E}[(X - m)^k]$. Let us define a centered random variable $Z = X - m$. Since $X$ is Gaussian, $Z$ is also Gaussian. The mean of $Z$ is $\\mathbb{E}[Z] = \\mathbb{E}[X - m] = \\mathbb{E}[X] - m = m - m = 0$. The variance of $Z$ is $\\text{Var}(Z) = \\text{Var}(X - m) = \\text{Var}(X) = v$. Thus, $Z \\sim \\mathcal{N}(0, v)$.\n\nThe central moments of a Gaussian distribution are a well-established property. For $Z \\sim \\mathcal{N}(0, v)$, the $k$-th moment $\\mathbb{E}[Z^k]$ is given by:\n$$\n\\mathbb{E}[Z^k] =\n\\begin{cases}\n0 & \\text{if } k \\text{ is odd} \\\\\n(k-1)!! \\, v^{k/2} & \\text{if } k \\text{ is even}\n\\end{cases}\n$$\nwhere $(k-1)!! = (k-1)(k-3)\\cdots(3)(1)$ is the double factorial.\n\nUsing this property, we can find the first four central moments of $X$ (which are the moments of $Z$):\nThe first central moment is $\\mu_1 = \\mathbb{E}[Z] = 0$.\nThe second central moment is $\\mu_2 = \\mathbb{E}[Z^2] = (2-1)!! \\, v^{2/2} = 1!! \\cdot v = v$. This is consistent with the definition of variance.\nThe third central moment is $\\mu_3 = \\mathbb{E}[Z^3] = 0$, since $3$ is odd.\nThe fourth central moment is $\\mu_4 = \\mathbb{E}[Z^4] = (4-1)!! \\, v^{4/2} = 3!! \\, v^2 = (3)(1)v^2 = 3v^2$.\n\nNow, we can express the raw moments of $X$ in terms of its central moments and its mean $m$. We use the relation $X = Z + m$.\n\nTo find the third raw moment, $\\mathbb{E}[X^3]$, we expand $(Z+m)^3$ using the binomial theorem:\n$$ X^3 = (Z+m)^3 = Z^3 + 3Z^2m + 3Zm^2 + m^3 $$\nBy the linearity of the expectation operator:\n$$ \\mathbb{E}[X^3] = \\mathbb{E}[Z^3 + 3mZ^2 + 3m^2Z + m^3] = \\mathbb{E}[Z^3] + 3m\\mathbb{E}[Z^2] + 3m^2\\mathbb{E}[Z] + \\mathbb{E}[m^3] $$\nSubstituting the central moments $\\mu_k = \\mathbb{E}[Z^k]$:\n$$ \\mathbb{E}[X^3] = \\mu_3 + 3m\\mu_2 + 3m^2\\mu_1 + m^3 $$\nNow, we substitute the values we found for the central moments of a Gaussian distribution:\n$$ \\mathbb{E}[X^3] = 0 + 3m(v) + 3m^2(0) + m^3 = m^3 + 3mv $$\n\nTo find the fourth raw moment, $\\mathbb{E}[X^4]$, we follow the same procedure, expanding $(Z+m)^4$:\n$$ X^4 = (Z+m)^4 = Z^4 + 4Z^3m + 6Z^2m^2 + 4Zm^3 + m^4 $$\nTaking the expectation:\n$$ \\mathbb{E}[X^4] = \\mathbb{E}[Z^4] + 4m\\mathbb{E}[Z^3] + 6m^2\\mathbb{E}[Z^2] + 4m^3\\mathbb{E}[Z] + \\mathbb{E}[m^4] $$\nSubstituting the central moments:\n$$ \\mathbb{E}[X^4] = \\mu_4 + 4m\\mu_3 + 6m^2\\mu_2 + 4m^3\\mu_1 + m^4 $$\nSubstituting the values for the Gaussian central moments:\n$$ \\mathbb{E}[X^4] = 3v^2 + 4m(0) + 6m^2(v) + 4m^3(0) + m^4 = m^4 + 6m^2v + 3v^2 $$\n\nReintroducing the time subscript $t$ to match the problem statement, we have $m=m_t$ and $v=v_t$.\nThe third raw moment of $X_t$ is:\n$$ \\mathbb{E}[X_t^3] = m_t^3 + 3m_t v_t $$\nThe fourth raw moment of $X_t$ is:\n$$ \\mathbb{E}[X_t^4] = m_t^4 + 6m_t^2 v_t + 3v_t^2 $$\nThese are the required expressions for the third and fourth raw moments in terms of the mean $m_t$ and variance $v_t$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nm_t^3 + 3m_t v_t & m_t^4 + 6m_t^2 v_t + 3v_t^2\n\\end{pmatrix}\n}\n$$", "id": "3052718"}, {"introduction": "A crucial question in mathematical modeling is whether a model's predictions remain physically sensible over time. For SDEs, this often translates to asking if the moments remain finite. This exercise presents a thought experiment using a simplified SDE with a superlinear drift term to demonstrate the concept of moment explosion [@problem_id:3052681]. By solving this equation, you will discover how certain types of drift can cause the solution to become infinite in a finite amount of time, providing a clear counterexample for why model stability cannot be taken for granted.", "problem": "Consider the degenerate stochastic differential equation (SDE with zero diffusion)\n$$\n\\mathrm{d}X_t \\,=\\, X_t^{\\,1+\\alpha}\\,\\mathrm{d}t,\\qquad X_0 \\,=\\, x_0 \\,>\\, 0,\n$$\nwhere $\\alpha \\,>\\, 0$ is a given constant. This SDE has superlinear drift and no confining term. Let $p \\,>\\, 0$ be fixed. Using only foundational tools such as separation of variables for ordinary differential equations, the definition of explosion time, and the definition of the $p$-th moment $M_p(t) \\,=\\, \\mathbb{E}[X_t^{\\,p}]$, do the following:\n\n- Solve for $X_t$ up to the maximal time of existence and determine the explosion time in terms of $\\alpha$ and $x_0$.\n- Derive the explicit expression for the $p$-th moment $M_p(t)$ on the interval where it is finite, and explain why this furnishes a counterexample showing that superlinear drift without confining terms can lead to moment explosion in finite time.\n\nGive your final answer as the single analytic expression for $M_p(t)$ on its interval of finiteness. No rounding is required.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard mathematical problem concerning the solution of an ordinary differential equation (ODE) and the behavior of its moments, framed within the context of stochastic differential equations (SDEs). All parameters and conditions are clearly defined.\n\nThe given stochastic differential equation is:\n$$ \\mathrm{d}X_t = X_t^{1+\\alpha} \\mathrm{d}t, \\quad X_0 = x_0 > 0 $$\nwhere $\\alpha > 0$ is a constant. This is a degenerate SDE because the diffusion coefficient is zero. Consequently, the process $X_t$ is deterministic, and its evolution is described by the ordinary differential equation:\n$$ \\frac{\\mathrm{d}X_t}{\\mathrm{d}t} = X_t^{1+\\alpha} $$\nwith the initial condition $X(0) = x_0$. The problem asks to solve this equation using separation of variables.\n\nFirst, we solve for $X_t$. Since $x_0 > 0$ and the derivative is positive, $X_t$ will remain positive for all $t$ where it is defined. We can separate the variables:\n$$ \\frac{\\mathrm{d}X_t}{X_t^{1+\\alpha}} = \\mathrm{d}t $$\nIntegrating both sides from the initial time $t=0$ to a later time $t$, and from the initial state $X_0=x_0$ to the state $X_t$, we get:\n$$ \\int_{x_0}^{X_t} x^{-(1+\\alpha)} \\mathrm{d}x = \\int_0^t \\mathrm{d}s $$\nThe integral of $x^{-(1+\\alpha)}$ with respect to $x$ is $\\frac{x^{-(1+\\alpha)+1}}{-(1+\\alpha)+1} = \\frac{x^{-\\alpha}}{-\\alpha}$. Evaluating the definite integral on the left-hand side:\n$$ \\left[ -\\frac{1}{\\alpha} x^{-\\alpha} \\right]_{x_0}^{X_t} = t $$\n$$ -\\frac{1}{\\alpha} \\left( X_t^{-\\alpha} - x_0^{-\\alpha} \\right) = t $$\nNow, we solve for $X_t^{-\\alpha}$:\n$$ X_t^{-\\alpha} - x_0^{-\\alpha} = -\\alpha t $$\n$$ X_t^{-\\alpha} = x_0^{-\\alpha} - \\alpha t $$\nFinally, raising both sides to the power of $-1/\\alpha$:\n$$ X_t = \\left( x_0^{-\\alpha} - \\alpha t \\right)^{-\\frac{1}{\\alpha}} $$\nThis is the solution for $X_t$.\n\nNext, we determine the maximal time of existence, also known as the explosion time, $T_{\\text{expl}}$. The solution $X_t$ is real and positive as long as the term inside the parentheses is positive.\n$$ x_0^{-\\alpha} - \\alpha t > 0 $$\n$$ x_0^{-\\alpha} > \\alpha t $$\n$$ t < \\frac{x_0^{-\\alpha}}{\\alpha} $$\nAs $t$ approaches this critical value from below, the term $(x_0^{-\\alpha} - \\alpha t)$ approaches $0$ from the positive side. Since the exponent $-1/\\alpha$ is negative (as $\\alpha > 0$), $X_t$ will tend to $+\\infty$. This phenomenon is known as finite-time blow-up or explosion. The explosion time is therefore:\n$$ T_{\\text{expl}} = \\frac{x_0^{-\\alpha}}{\\alpha} = \\frac{1}{\\alpha x_0^{\\alpha}} $$\nThe solution $X_t$ exists and is finite for $t \\in [0, T_{\\text{expl}})$.\n\nNow, we derive the explicit expression for the $p$-th moment, $M_p(t) = \\mathbb{E}[X_t^p]$, for a fixed constant $p > 0$. The expectation $\\mathbb{E}[\\cdot]$ is taken with respect to the underlying probability measure. However, since the SDE has zero diffusion and a deterministic initial condition $X_0 = x_0$, the solution path $X_t$ is a deterministic function of time. There is no randomness in the process. Therefore, the expectation of any function of $X_t$ is simply the function evaluated at the deterministic value of $X_t$.\n$$ M_p(t) = \\mathbb{E}[X_t^p] = (X_t)^p $$\nSubstituting the expression we found for $X_t$:\n$$ M_p(t) = \\left[ \\left( x_0^{-\\alpha} - \\alpha t \\right)^{-\\frac{1}{\\alpha}} \\right]^p = \\left( x_0^{-\\alpha} - \\alpha t \\right)^{-\\frac{p}{\\alpha}} $$\nThis expression for the $p$-th moment $M_p(t)$ is finite precisely when $X_t$ is finite, which is for $t \\in [0, T_{\\text{expl}})$.\n\nFinally, we explain why this serves as a counterexample. The drift term in the SDE is $b(x) = x^{1+\\alpha}$. Since $\\alpha > 0$, the exponent $1+\\alpha$ is greater than $1$, which means the drift is superlinear. Furthermore, for $X_t > 0$, the drift is always positive, pushing the process towards larger values. There is no \"confining\" part of the drift that would pull the process back towards the origin or some other finite value. Our calculation shows that for any $p > 0$, the $p$-th moment $M_p(t)$ becomes infinite as $t \\to T_{\\text{expl}}^-$, where $T_{\\text{expl}}$ is a finite time. This explicitly demonstrates that a process with superlinear drift and no confining term can experience a moment explosion in finite time. This simple, deterministic example isolates the effect of the drift's growth rate on the moments of the solution.", "answer": "$$\\boxed{\\left(x_0^{-\\alpha} - \\alpha t\\right)^{-\\frac{p}{\\alpha}}}$$", "id": "3052681"}]}