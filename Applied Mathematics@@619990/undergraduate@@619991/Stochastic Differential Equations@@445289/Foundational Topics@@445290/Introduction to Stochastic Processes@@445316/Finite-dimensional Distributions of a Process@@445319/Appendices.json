{"hands_on_practices": [{"introduction": "We begin with one of the most fundamental stochastic models: the simple random walk. Understanding its finite-dimensional distributions is crucial for grasping the path-dependent nature of such processes. This first practice [@problem_id:1302889] offers a concrete, hands-on calculation of a joint probability mass function for a normalized random walk at times $n=1$ and $n=2$, directly illustrating how the process's state at a later time depends on its earlier state.", "problem": "Consider a sequence of independent and identically distributed (i.i.d.) random variables $\\{Z_i\\}_{i \\ge 1}$, which represent the steps of a random walk. Each step is either forward or backward with equal probability, such that the probability mass function for each $Z_i$ is given by $P(Z_i = 1) = 1/2$ and $P(Z_i = -1) = 1/2$.\n\nThe position of the random walk at time $n$ is given by the sum of the steps, $S_n = \\sum_{i=1}^n Z_i$, with the starting position being $S_0=0$. A normalized stochastic process $\\{X_n\\}_{n \\ge 1}$ is constructed from this random walk, where $X_n = S_n / n$.\n\nDetermine the two-dimensional finite-dimensional distribution for this process at times $n=1$ and $n=2$. That is, find the joint probability mass function $P(X_1=x_1, X_2=x_2)$. Which of the following tables correctly represents this joint distribution?\n\nA.\n$$\n\\begin{array}{c|ccc}\n P(X_1, X_2) & x_2 = -1 & x_2 = 0 & x_2 = 1 \\\\\n\\hline\nx_1 = -1 & 1/4 & 1/4 & 0 \\\\\nx_1 = 1 & 0 & 1/4 & 1/4 \\\\\n\\end{array}\n$$\n\nB.\n$$\n\\begin{array}{c|ccc}\n P(X_1, X_2) & x_2 = -1 & x_2 = 0 & x_2 = 1 \\\\\n\\hline\nx_1 = -1 & 1/8 & 1/4 & 1/8 \\\\\nx_1 = 1 & 1/8 & 1/4 & 1/8 \\\\\n\\end{array}\n$$\n\nC.\n$$\n\\begin{array}{c|ccc}\n P(X_1, X_2) & x_2 = -1 & x_2 = 0 & x_2 = 1 \\\\\n\\hline\nx_1 = -1 & 1/4 & 0 & 1/4 \\\\\nx_1 = 1 & 1/4 & 1/4 & 0 \\\\\n\\end{array}\n$$\n\nD.\n$$\n\\begin{array}{c|ccc}\n P(X_1, X_2) & x_2 = -1 & x_2 = 0 & x_2 = 1 \\\\\n\\hline\nx_1 = -1 & 1/2 & 0 & 0 \\\\\nx_1 = 1 & 0 & 0 & 1/2 \\\\\n\\end{array}\n$$", "solution": "We are given i.i.d. steps with $P(Z_{i}=1)=\\frac{1}{2}$ and $P(Z_{i}=-1)=\\frac{1}{2}$. The random walk positions are $S_{n}=\\sum_{i=1}^{n}Z_{i}$ with $S_{0}=0$, and the normalized process is $X_{n}=S_{n}/n$.\n\nAt the specified times,\n$$\nX_{1}=\\frac{S_{1}}{1}=Z_{1}, \\qquad X_{2}=\\frac{S_{2}}{2}=\\frac{Z_{1}+Z_{2}}{2}.\n$$\nBy independence and identical distribution, for each pair $(z_{1},z_{2})\\in\\{-1,1\\}^{2}$,\n$$\nP(Z_{1}=z_{1},Z_{2}=z_{2})=P(Z_{1}=z_{1})P(Z_{2}=z_{2})=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4}.\n$$\n\nEnumerate the four possible outcomes and map them to $(X_{1},X_{2})$:\n- If $(Z_{1},Z_{2})=(1,1)$, then $X_{1}=1$ and $X_{2}=\\frac{1+1}{2}=1$, giving $(X_{1},X_{2})=(1,1)$ with probability $\\frac{1}{4}$.\n- If $(Z_{1},Z_{2})=(1,-1)$, then $X_{1}=1$ and $X_{2}=\\frac{1+(-1)}{2}=0$, giving $(X_{1},X_{2})=(1,0)$ with probability $\\frac{1}{4}$.\n- If $(Z_{1},Z_{2})=(-1,1)$, then $X_{1}=-1$ and $X_{2}=\\frac{-1+1}{2}=0$, giving $(X_{1},X_{2})=(-1,0)$ with probability $\\frac{1}{4}$.\n- If $(Z_{1},Z_{2})=(-1,-1)$, then $X_{1}=-1$ and $X_{2}=\\frac{-1+(-1)}{2}=-1$, giving $(X_{1},X_{2})=(-1,-1)$ with probability $\\frac{1}{4}$.\n\nTherefore, the joint pmf has nonzero entries only at $(-1,-1)$, $(-1,0)$, $(1,0)$, and $(1,1)$ with probabilities $\\frac{1}{4}$ each, and zeros elsewhere. Comparing with the provided tables, this matches option A.", "answer": "$$\\boxed{A}$$", "id": "1302889"}, {"introduction": "Moving from discrete steps to a continuous range of values, we now explore a process defined by extreme events. Many real-world phenomena, from financial market peaks to the failure time of a system component, are modeled by the maximum or minimum of a set of random variables. This exercise [@problem_id:1302878] challenges you to derive the one-dimensional cumulative distribution function (CDF) for a process constructed from the maximum of scaled random variables, a core skill for analyzing such processes.", "problem": "Consider a sequence of independent and identically distributed (i.i.d.) random variables $Z_1, Z_2, Z_3, \\dots$, where each $Z_i$ follows a continuous uniform distribution on the interval $[0, 1]$. A stochastic process $\\{X_n\\}_{n=1}^{\\infty}$ is constructed from this sequence as follows:\n$$\nX_n = \\max\\left(\\frac{Z_1}{1}, \\frac{Z_2}{2}, \\frac{Z_3}{3}, \\dots, \\frac{Z_n}{n}\\right)\n$$\nfor each integer $n \\ge 1$.\n\nYour task is to determine the one-dimensional cumulative distribution function (CDF) of the process, denoted by $F_{X_n}(x) = P(X_n \\le x)$. Provide a single, closed-form analytic expression for $F_{X_n}(x)$ that is valid for all real numbers $x$.", "solution": "Define $Y_{i} \\equiv Z_{i}/i$ for $i=1,\\dots,n$. Since the $Z_{i}$ are independent and each $Y_{i}$ is a deterministic function of $Z_{i}$, the $Y_{i}$ are independent. For any real $x$,\n$$\nF_{X_{n}}(x)=\\mathbb{P}\\!\\left(X_{n}\\le x\\right)=\\mathbb{P}\\!\\left(\\max_{1\\le i\\le n}Y_{i}\\le x\\right)=\\mathbb{P}\\!\\left(Y_{i}\\le x\\ \\text{for all }i=1,\\dots,n\\right)=\\prod_{i=1}^{n}\\mathbb{P}\\!\\left(Y_{i}\\le x\\right).\n$$\nFor each $i$, we have\n$$\n\\mathbb{P}\\!\\left(Y_{i}\\le x\\right)=\\mathbb{P}\\!\\left(\\frac{Z_{i}}{i}\\le x\\right)=\\mathbb{P}\\!\\left(Z_{i}\\le i x\\right).\n$$\nBecause $Z_{i}\\sim \\text{Uniform}[0,1]$, its CDF satisfies\n$$\nF_{Z}(t)=\\mathbb{P}(Z_{i}\\le t)=\n\\begin{cases}\n0, & t\\le 0,\\\\\nt, & 0\\le t\\le 1,\\\\\n1, & t\\ge 1,\n\\end{cases}\n$$\nwhich can be written compactly as $F_{Z}(t)=\\min\\!\\left(1,\\max\\!\\left(0,t\\right)\\right)$. Therefore,\n$$\n\\mathbb{P}\\!\\left(Y_{i}\\le x\\right)=F_{Z}(i x)=\\min\\!\\left(1,\\max\\!\\left(0,i x\\right)\\right),\n$$\nand by independence,\n$$\nF_{X_{n}}(x)=\\prod_{i=1}^{n}\\min\\!\\left(1,\\max\\!\\left(0,i x\\right)\\right).\n$$\nThis single expression is valid for all real $x$ and automatically yields the correct boundary behaviors $F_{X_{n}}(x)=0$ for $x\\le 0$ and $F_{X_{n}}(x)=1$ for $x\\ge 1$.", "answer": "$$\\boxed{\\prod_{i=1}^{n}\\min\\!\\left(1,\\max\\!\\left(0,i x\\right)\\right)}$$", "id": "1302878"}, {"introduction": "Our final practice demonstrates that describing a finite-dimensional distribution does not always require deriving a full probability density or mass function. Often, significant insight comes from understanding the geometric structure and constraints on the process's possible values. In this problem [@problem_id:1302861], you will analyze a 'random phase' process, discovering that the joint values at any two time points are not arbitrary but are confined to an elegant elliptical curve, providing a powerful link between stochastic analysis and geometry.", "problem": "Consider the stochastic process defined by $X_t = \\cos(t + \\Theta)$, where $\\Theta$ is a random variable uniformly distributed over the interval $[0, 2\\pi]$. For any two time points $t_1$ and $t_2$, let $x_1$ and $x_2$ be the values of the process, such that $x_1 = X_{t_1}$ and $x_2 = X_{t_2}$. The set of all possible pairs $(x_1, x_2)$, known as the support of the joint distribution of $(X_{t_1}, X_{t_2})$, is constrained to a specific curve in the $x_1x_2$-plane. This curve's equation can be expressed in the quadratic form $x_1^2 + A x_1 x_2 + x_2^2 = B$, where the coefficients $A$ and $B$ are functions of the time difference $\\Delta t = t_2 - t_1$. Determine the expression for the coefficient $B$ as a function of $\\Delta t$.", "solution": "Let $\\Delta t = t_{2} - t_{1}$ and define $\\phi = t_{1} + \\Theta$. Then\n$$\nx_{1} = \\cos\\phi, \\quad x_{2} = \\cos(\\phi + \\Delta t) = \\cos\\phi\\cos\\Delta t - \\sin\\phi\\sin\\Delta t.\n$$\nSet $c = \\cos\\phi = x_{1}$ and $s = \\sin\\phi$. Then $c^{2} + s^{2} = 1$ and\n$$\nx_{2} = c\\cos\\Delta t - s\\sin\\Delta t.\n$$\nConsider the quadratic combination\n$$\nx_{1}^{2} - 2\\cos\\Delta t\\, x_{1}x_{2} + x_{2}^{2}.\n$$\nSubstituting $x_{1} = c$ and $x_{2} = c\\cos\\Delta t - s\\sin\\Delta t$,\n$$\n\\begin{aligned}\nx_{1}^{2} - 2\\cos\\Delta t\\, x_{1}x_{2} + x_{2}^{2}\n&= c^{2} - 2\\cos\\Delta t\\, c(c\\cos\\Delta t - s\\sin\\Delta t) + (c\\cos\\Delta t - s\\sin\\Delta t)^{2} \\\\\n&= c^{2} - 2c^{2}\\cos^{2}\\Delta t + 2cs\\cos\\Delta t \\sin\\Delta t + c^{2}\\cos^{2}\\Delta t - 2cs\\cos\\Delta t \\sin\\Delta t + s^{2}\\sin^{2}\\Delta t \\\\\n&= c^{2}(1 - \\cos^{2}\\Delta t) + s^{2}\\sin^{2}\\Delta t \\\\\n&= (c^{2} + s^{2})\\sin^{2}\\Delta t \\\\\n&= \\sin^{2}\\Delta t.\n\\end{aligned}\n$$\nThus the support lies on the curve\n$$\nx_{1}^{2} - 2\\cos\\Delta t\\, x_{1}x_{2} + x_{2}^{2} = \\sin^{2}\\Delta t,\n$$\nwhich matches the given quadratic form with $A = -2\\cos\\Delta t$ and\n$$\nB = \\sin^{2}\\Delta t.\n$$", "answer": "$$\\boxed{\\sin^{2}(\\Delta t)}$$", "id": "1302861"}]}