{"hands_on_practices": [{"introduction": "The first step in analyzing a stochastic process is often to understand its average behavior over time. This practice problem provides a concrete scenario to calculate the expected value, or mean, of a compound Poisson process. By working through this exercise [@problem_id:1290809], you will apply a fundamental property that elegantly separates the randomness of the event timings from the randomness of the event sizes, showing that the total expected value is simply the expected number of events multiplied by the average size of each event.", "problem": "A cybersecurity firm monitors a corporate network for security threats. The occurrences of significant security breaches follow a Poisson process with an average rate of $\\lambda = 5$ breaches per hour. When a breach occurs, a risk score is assigned to it. The value of this score is a random variable, independent of the time of occurrence and of all other breaches. The probability distribution for the score of a single breach is as follows: a score of 10 is assigned with a probability of 0.6, a score of 50 is assigned with a probability of 0.3, and a score of 100 is assigned with a probability of 0.1.\n\nIf the total risk score for the network is initially zero at the beginning of a workday, what is the expected total risk score after an 8-hour period?", "solution": "Let $N(t)$ denote the number of breaches in time $t$, modeled as a Poisson process with rate $\\lambda$, and let $\\{X_{i}\\}$ be independent and identically distributed breach scores, independent of $N(t)$. The total risk score accumulated by time $t$ is the compound Poisson sum\n$$\nS(t)=\\sum_{i=1}^{N(t)} X_{i}.\n$$\nBy the law of total expectation and independence,\n$$\n\\mathbb{E}[S(t)]=\\mathbb{E}\\big[\\mathbb{E}[S(t)\\mid N(t)]\\big]=\\mathbb{E}\\big[N(t)\\mathbb{E}[X]\\big]=\\mathbb{E}[N(t)]\\,\\mathbb{E}[X].\n$$\nFor a Poisson process, $\\mathbb{E}[N(t)]=\\lambda t$. With $\\lambda=5$ per hour and $t=8$ hours,\n$$\n\\mathbb{E}[N(8)]=5\\cdot 8=40.\n$$\nThe breach score $X$ has distribution $P(X=10)=0.6$, $P(X=50)=0.3$, and $P(X=100)=0.1$, so\n$$\n\\mathbb{E}[X]=10\\cdot 0.6+50\\cdot 0.3+100\\cdot 0.1=6+15+10=31.\n$$\nTherefore,\n$$\n\\mathbb{E}[S(8)]=\\lambda\\cdot 8\\cdot \\mathbb{E}[X]=5\\cdot 8\\cdot 31=40\\cdot 31=1240.\n$$", "answer": "$$\\boxed{1240}$$", "id": "1290809"}, {"introduction": "Beyond the average outcome, it is crucial to quantify the uncertainty or variability of a process. This exercise [@problem_id:1349670] guides you through calculating the variance of a compound Poisson process, a measure of its spread around the mean. You will discover how the total variance arises from two distinct sources—the randomness in the number of events and the randomness in the magnitude of each event—and apply a key result known as the law of total variance to combine these effects.", "problem": "At a remote arctic research station, the number of major blizzards occurring during the winter season is modeled as a Poisson random variable with a mean of 5 blizzards per season. The snowfall from each blizzard is an independent, identically distributed random variable, uniformly distributed between 0.5 meters and 2.5 meters. Let the total snowfall for one winter season be the sum of the snowfalls from all the blizzards that occur in that season. If no blizzards occur, the total snowfall is zero. Calculate the variance of the total seasonal snowfall. Express your answer in units of meters squared, rounded to three significant figures.", "solution": "Let $N$ be the random variable representing the number of blizzards in a season. We are given that $N$ follows a Poisson distribution with a mean of 5. The parameter of the Poisson distribution, $\\lambda$, is equal to its mean.\n$$N \\sim \\text{Poisson}(\\lambda=5)$$\nFor a Poisson distribution, the expectation and variance are both equal to the parameter $\\lambda$.\n$$E[N] = \\lambda = 5$$\n$$\\text{Var}(N) = \\lambda = 5$$\n\nLet $S_i$ be the random variable for the snowfall from the $i$-th blizzard. The variables $S_i$ are independent and identically distributed (i.i.d.). We are given that the snowfall for each blizzard follows a uniform distribution on the interval $[a, b]$, where $a = 0.5$ meters and $b = 2.5$ meters.\n$$S_i \\sim U(0.5, 2.5)$$\nThe expectation (mean) of a uniform random variable on $[a, b]$ is given by $E[S_i] = \\frac{a+b}{2}$.\n$$E[S] = \\frac{0.5 + 2.5}{2} = \\frac{3}{2} = 1.5 \\text{ meters}$$\nThe variance of a uniform random variable on $[a, b]$ is given by $\\text{Var}(S_i) = \\frac{(b-a)^2}{12}$.\n$$\\text{Var}(S) = \\frac{(2.5 - 0.5)^2}{12} = \\frac{2^2}{12} = \\frac{4}{12} = \\frac{1}{3} \\text{ meters}^2$$\nHere, $E[S]$ and $\\text{Var}(S)$ are common to all $S_i$, so we drop the subscript.\n\nThe total seasonal snowfall, $X$, is the sum of the snowfalls from each blizzard. This can be written as a random sum:\n$$X = \\sum_{i=1}^{N} S_i$$\nWe need to find the variance of $X$, which is $\\text{Var}(X)$. This is a compound random variable. We can compute its variance using the law of total variance, also known as the conditional variance formula:\n$$\\text{Var}(X) = E[\\text{Var}(X|N)] + \\text{Var}(E[X|N])$$\n\nFirst, we find the conditional expectation of $X$ given $N=n$:\n$$E[X|N=n] = E\\left[\\sum_{i=1}^{n} S_i\\right]$$\nBy the linearity of expectation, this becomes:\n$$E[X|N=n] = \\sum_{i=1}^{n} E[S_i] = n E[S]$$\nThus, $E[X|N]$ is a random variable given by $N \\cdot E[S]$.\n\nNext, we find the conditional variance of $X$ given $N=n$. Since the $S_i$ are independent:\n$$\\text{Var}(X|N=n) = \\text{Var}\\left(\\sum_{i=1}^{n} S_i\\right) = \\sum_{i=1}^{n} \\text{Var}(S_i) = n \\text{Var}(S)$$\nThus, $\\text{Var}(X|N)$ is a random variable given by $N \\cdot \\text{Var}(S)$.\n\nNow we substitute these expressions back into the law of total variance formula.\nFor the first term:\n$$E[\\text{Var}(X|N)] = E[N \\cdot \\text{Var}(S)]$$\nSince $\\text{Var}(S)$ is a constant, we can pull it out of the expectation:\n$$E[\\text{Var}(X|N)] = \\text{Var}(S) E[N]$$\n\nFor the second term:\n$$\\text{Var}(E[X|N]) = \\text{Var}(N \\cdot E[S])$$\nUsing the property $\\text{Var}(c Y) = c^2 \\text{Var}(Y)$ for a constant $c$ and random variable $Y$, and noting that $E[S]$ is a constant:\n$$\\text{Var}(E[X|N]) = (E[S])^2 \\text{Var}(N)$$\n\nCombining the two terms, we get the formula for the variance of a compound Poisson process, sometimes called Wald's identity for variance:\n$$\\text{Var}(X) = E[N] \\text{Var}(S) + \\text{Var}(N) (E[S])^2$$\nNow, we substitute the numerical values we calculated earlier:\n$$E[N] = 5, \\quad \\text{Var}(N) = 5$$\n$$E[S] = 1.5, \\quad \\text{Var}(S) = \\frac{1}{3}$$\n\n$$\\text{Var}(X) = (5) \\left(\\frac{1}{3}\\right) + (5) (1.5)^2$$\n$$\\text{Var}(X) = \\frac{5}{3} + 5 \\cdot (2.25)$$\n$$\\text{Var}(X) = \\frac{5}{3} + 11.25$$\nTo add these, we can use decimals:\n$$\\text{Var}(X) \\approx 1.6666... + 11.25 = 12.91666... \\text{ meters}^2$$\n\nThe problem asks for the answer rounded to three significant figures. The first three significant figures are 1, 2, and 9. The fourth digit is 1, so we round down.\n$$\\text{Var}(X) \\approx 12.9 \\text{ meters}^2$$", "answer": "$$\\boxed{12.9}$$", "id": "1349670"}, {"introduction": "While calculating moments like the mean and variance one by one is useful, a more powerful approach is to find a single function that characterizes the entire distribution of the process. This advanced practice introduces the Laplace transform, a versatile tool in probability theory. By deriving the Laplace transform for a compound Poisson process [@problem_id:3044840], you will obtain a compact formula from which all moments can be derived, offering a much deeper and more comprehensive understanding of the process's structure.", "problem": "Let $\\{N_t\\}_{t \\geq 0}$ be a Poisson process with rate $\\lambda  0$. Let $\\{Y_i\\}_{i \\geq 1}$ be independent and identically distributed (i.i.d.) jump sizes with distribution $\\mathrm{Exp}(\\mu)$, where $\\mu  0$, and assume that $\\{Y_i\\}_{i \\geq 1}$ is independent of $\\{N_t\\}_{t \\geq 0}$. Define the compound Poisson process $X_t = \\sum_{i=1}^{N_t} Y_i$ for $t \\geq 0$, with the convention that an empty sum equals $0$. For a fixed $t  0$ and Laplace parameter $q \\geq 0$, compute the Laplace transform $E[\\exp(-q X_t)]$ in closed form as a function of $\\lambda$, $\\mu$, $t$, and $q$. Your final answer must be a single analytic expression. Do not provide an inequality or an equation involving an unspecified constant. No rounding is required.", "solution": "The problem requires the computation of the Laplace transform of a compound Poisson process $X_t$, defined as $X_t = \\sum_{i=1}^{N_t} Y_i$. We are given that $\\{N_t\\}_{t \\geq 0}$ is a Poisson process with a constant rate $\\lambda  0$, and $\\{Y_i\\}_{i \\geq 1}$ represents a sequence of independent and identically distributed (i.i.d.) random variables, corresponding to the jump sizes. Each $Y_i$ follows an exponential distribution with rate parameter $\\mu  0$, denoted as $Y_i \\sim \\mathrm{Exp}(\\mu)$. The set of jump sizes $\\{Y_i\\}_{i \\geq 1}$ is independent of the Poisson process $\\{N_t\\}_{t \\geq 0}$. The objective is to find a closed-form expression for $E[\\exp(-q X_t)]$ for a fixed time $t  0$ and a Laplace parameter $q \\geq 0$.\n\nThe structure of $X_t$ involves a sum where the number of terms, $N_t$, is itself a random variable. A standard technique to evaluate the expectation of such a quantity is to use the law of total expectation (also known as the tower property). We condition on the number of jumps that have occurred up to time $t$, which is given by the random variable $N_t$.\nThe Laplace transform of $X_t$ is thus:\n$$ E[\\exp(-q X_t)] = E \\left[ E[\\exp(-q X_t) | N_t] \\right] $$\nFirst, we compute the inner conditional expectation, $E[\\exp(-q X_t) | N_t = n]$, for a non-negative integer $n$. When we condition on $N_t=n$, the sum becomes a sum of a fixed number of terms:\n$$ E[\\exp(-q X_t) | N_t = n] = E\\left[\\exp\\left(-q \\sum_{i=1}^{n} Y_i\\right) | N_t = n\\right] $$\nAccording to the problem statement, the jump sizes $\\{Y_i\\}$ are independent of the process $\\{N_t\\}$. Therefore, the conditional distribution of the $Y_i$ given $N_t=n$ is the same as their unconditional distribution. This allows us to remove the conditioning on $N_t=n$ from the expectation involving the $Y_i$:\n$$ E[\\exp(-q X_t) | N_t = n] = E\\left[\\exp\\left(-q \\sum_{i=1}^{n} Y_i\\right)\\right] $$\nFor $n=0$, the sum is empty and, by convention, equals $0$. So, $X_t=0$, and $E[\\exp(-q \\cdot 0) | N_t = 0] = E[1] = 1$.\nFor $n  0$, since the random variables $Y_i$ are i.i.d., the exponential of the sum becomes a product of exponentials. The expectation of this product is the product of the individual expectations:\n$$ E\\left[\\exp\\left(-q \\sum_{i=1}^{n} Y_i\\right)\\right] = E\\left[\\prod_{i=1}^{n} \\exp(-q Y_i)\\right] = \\prod_{i=1}^{n} E[\\exp(-q Y_i)] $$\nSince all $Y_i$ have the same distribution, this simplifies to:\n$$ \\left(E[\\exp(-q Y_1)]\\right)^n $$\nThe term $E[\\exp(-q Y_1)]$ is the Laplace transform of a single jump size $Y_1$. Since $Y_1 \\sim \\mathrm{Exp}(\\mu)$, its probability density function is $f_{Y_1}(y) = \\mu e^{-\\mu y}$ for $y \\geq 0$. We compute its Laplace transform, $\\mathcal{L}_{Y_1}(q)$, as follows:\n$$ \\mathcal{L}_{Y_1}(q) = E[\\exp(-q Y_1)] = \\int_0^\\infty e^{-qy} (\\mu e^{-\\mu y}) dy = \\mu \\int_0^\\infty e^{-(\\mu+q)y} dy $$\nGiven that $\\mu  0$ and $q \\geq 0$, the sum $\\mu+q$ is strictly positive, ensuring the convergence of the integral.\n$$ \\mathcal{L}_{Y_1}(q) = \\mu \\left[ -\\frac{1}{\\mu+q} e^{-(\\mu+q)y} \\right]_{y=0}^{y=\\infty} = \\mu \\left( 0 - \\left(-\\frac{1}{\\mu+q} e^0\\right) \\right) = \\frac{\\mu}{\\mu+q} $$\nSubstituting this result back, the conditional expectation is:\n$$ E[\\exp(-q X_t) | N_t = n] = \\left(\\frac{\\mu}{\\mu+q}\\right)^n $$\nThis formula correctly gives $1$ for $n=0$, consistent with our earlier observation.\n\nNow, we perform the outer expectation with respect to the distribution of $N_t$.\n$$ E[\\exp(-q X_t)] = E\\left[ \\left(\\frac{\\mu}{\\mu+q}\\right)^{N_t} \\right] $$\nThe random variable $N_t$ follows a Poisson distribution with parameter (mean) $\\lambda t$. Its probability mass function (PMF) is given by $P(N_t=n) = \\frac{e^{-\\lambda t}(\\lambda t)^n}{n!}$ for $n \\in \\{0, 1, 2, \\dots\\}$. The expectation is thus a sum over all possible values of $n$:\n$$ E\\left[ \\left(\\frac{\\mu}{\\mu+q}\\right)^{N_t} \\right] = \\sum_{n=0}^{\\infty} \\left(\\frac{\\mu}{\\mu+q}\\right)^n P(N_t=n) = \\sum_{n=0}^{\\infty} \\left(\\frac{\\mu}{\\mu+q}\\right)^n \\frac{e^{-\\lambda t}(\\lambda t)^n}{n!} $$\nWe can rearrange the terms in the sum:\n$$ = e^{-\\lambda t} \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left( \\lambda t \\frac{\\mu}{\\mu+q} \\right)^n $$\nThe summation is the Taylor series expansion of the exponential function, $\\sum_{n=0}^{\\infty} \\frac{z^n}{n!} = e^z$, with $z = \\lambda t \\frac{\\mu}{\\mu+q}$.\n$$ E[\\exp(-q X_t)] = e^{-\\lambda t} \\exp\\left(\\lambda t \\frac{\\mu}{\\mu+q}\\right) $$\nCombining the exponents, we get:\n$$ = \\exp\\left(-\\lambda t + \\lambda t \\frac{\\mu}{\\mu+q}\\right) = \\exp\\left(\\lambda t \\left(-1 + \\frac{\\mu}{\\mu+q}\\right)\\right) $$\nSimplifying the term in the parenthesis:\n$$ -1 + \\frac{\\mu}{\\mu+q} = \\frac{-(\\mu+q) + \\mu}{\\mu+q} = \\frac{-\\mu-q+\\mu}{\\mu+q} = \\frac{-q}{\\mu+q} $$\nSubstituting this back into the expression for the expectation gives the final result:\n$$ E[\\exp(-q X_t)] = \\exp\\left(\\lambda t \\left(\\frac{-q}{\\mu+q}\\right)\\right) = \\exp\\left(-\\frac{\\lambda t q}{\\mu+q}\\right) $$\nThis expression represents the Laplace transform of the compound Poisson process $X_t$ evaluated at $q$.", "answer": "$$\\boxed{\\exp\\left(-\\frac{\\lambda t q}{\\mu+q}\\right)}$$", "id": "3044840"}]}