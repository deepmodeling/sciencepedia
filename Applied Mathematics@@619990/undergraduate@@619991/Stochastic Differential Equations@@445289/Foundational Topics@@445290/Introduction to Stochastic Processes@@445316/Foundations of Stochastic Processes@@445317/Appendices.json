{"hands_on_practices": [{"introduction": "Before modeling complex random systems, one must master the fundamentals of manipulating individual random variables. This exercise provides practice with a core skill: determining the probability distribution of a variable after it undergoes a simple linear transformation. By working from the definition of the cumulative distribution function, you will solidify your understanding of how scaling and shifting a random variable affects its underlying probabilistic description. [@problem_id:3055425]", "problem": "Let $(\\Omega,\\mathcal{F},\\mathbb{P})$ be a probability space and let $X$ be a real-valued random variable with cumulative distribution function $F_{X}(x) = \\mathbb{P}(X \\leq x)$, and suppose $X$ admits a probability density function (pdf) $f_{X}(x)$ with respect to Lebesgue measure. For fixed constants $a \\neq 0$ and $b \\in \\mathbb{R}$, define the transformed random variable $Y = a X + b$. Using only the foundational definitions of a distribution function and the change-of-variables principle for monotone transformations, derive the cumulative distribution function $F_{Y}(y)$ in terms of $F_{X}$ and, under the assumption that $f_{X}$ exists, derive the pdf $f_{Y}(y)$ in terms of $f_{X}$. Then illustrate your result by taking $X \\sim \\mathcal{N}(0,1)$, the standard normal distribution, and explicitly determining $f_{Y}(y)$. Provide your reasoning starting from first principles, and present your final reported answer as a single closed-form analytic expression for $f_{Y}(y)$ in terms of $f_{X}(x)$, $a$, and $b$.", "solution": "The problem requires the derivation of the cumulative distribution function (CDF) and the probability density function (PDF) for a linear transformation $Y = aX+b$ of a random variable $X$. The derivation must proceed from first principles, specifically the definition of the CDF.\n\nLet $X$ be a real-valued random variable with CDF $F_{X}(x) = \\mathbb{P}(X \\leq x)$ and PDF $f_{X}(x) = \\frac{d}{dx}F_{X}(x)$. Let $Y$ be the transformed random variable defined as $Y = aX+b$, where $a \\in \\mathbb{R}$, $a \\neq 0$, and $b \\in \\mathbb{R}$. We seek to find the CDF $F_{Y}(y)$ and PDF $f_{Y}(y)$ of $Y$.\n\nThe derivation begins with the definition of the CDF of $Y$:\n$$F_{Y}(y) = \\mathbb{P}(Y \\leq y)$$\nSubstituting the expression for $Y$, we get:\n$$F_{Y}(y) = \\mathbb{P}(aX + b \\leq y)$$\nTo express this probability in terms of the CDF of $X$, we must isolate $X$.\n$$F_{Y}(y) = \\mathbb{P}(aX \\leq y-b)$$\nThe next step depends on the sign of the constant $a$. We must consider two separate cases.\n\nCase 1: $a > 0$.\nIf $a$ is positive, we can divide the inequality by $a$ without changing its direction:\n$$\\mathbb{P}\\left(X \\leq \\frac{y-b}{a}\\right)$$\nBy the definition of the CDF of $X$, this is:\n$$F_{Y}(y) = F_{X}\\left(\\frac{y-b}{a}\\right)$$\n\nCase 2: $a < 0$.\nIf $a$ is negative, dividing the inequality by $a$ reverses the direction of the inequality:\n$$\\mathbb{P}\\left(X \\geq \\frac{y-b}{a}\\right)$$\nThe probability of $X$ being greater than or equal to a value can be expressed in terms of its CDF.\n$$\\mathbb{P}\\left(X \\geq \\frac{y-b}{a}\\right) = 1 - \\mathbb{P}\\left(X < \\frac{y-b}{a}\\right)$$\nSince we have assumed that $X$ admits a PDF $f_X(x)$, the random variable $X$ is continuous. For any continuous random variable, the probability of it taking on any single specific value is zero. That is, for any $z \\in \\mathbb{R}$, $\\mathbb{P}(X=z) = 0$. Therefore, $\\mathbb{P}(X < z) = \\mathbb{P}(X \\leq z) = F_X(z)$. Applying this, we get:\n$$F_{Y}(y) = 1 - F_{X}\\left(\\frac{y-b}{a}\\right)$$\n\nHaving derived the CDF $F_Y(y)$ for both cases, we now derive the PDF $f_Y(y)$ by differentiating $F_Y(y)$ with respect to $y$, i.e., $f_{Y}(y) = \\frac{d}{dy}F_{Y}(y)$. We again proceed by cases.\n\nCase 1: $a > 0$.\nWe have $F_{Y}(y) = F_{X}\\left(\\frac{y-b}{a}\\right)$. Applying the chain rule for differentiation:\n$$f_{Y}(y) = \\frac{d}{dy} F_{X}\\left(\\frac{y-b}{a}\\right) = F_{X}'\\left(\\frac{y-b}{a}\\right) \\cdot \\frac{d}{dy}\\left(\\frac{y-b}{a}\\right)$$\nSince $F_{X}'(x) = f_{X}(x)$ and $\\frac{d}{dy}\\left(\\frac{y-b}{a}\\right) = \\frac{1}{a}$, this becomes:\n$$f_{Y}(y) = f_{X}\\left(\\frac{y-b}{a}\\right) \\cdot \\frac{1}{a}$$\n\nCase 2: $a < 0$.\nWe have $F_{Y}(y) = 1 - F_{X}\\left(\\frac{y-b}{a}\\right)$. Differentiating with respect to $y$:\n$$f_{Y}(y) = \\frac{d}{dy} \\left[1 - F_{X}\\left(\\frac{y-b}{a}\\right)\\right] = 0 - F_{X}'\\left(\\frac{y-b}{a}\\right) \\cdot \\frac{d}{dy}\\left(\\frac{y-b}{a}\\right)$$\n$$f_{Y}(y) = -f_{X}\\left(\\frac{y-b}{a}\\right) \\cdot \\frac{1}{a}$$\n\nWe can unify these two results into a single expression. Note that if $a > 0$, then $|a| = a$, so $\\frac{1}{a} = \\frac{1}{|a|}$. If $a < 0$, then $|a| = -a$, so $-\\frac{1}{a} = \\frac{1}{-a} = \\frac{1}{|a|}$. In both cases, the multiplicative factor is $\\frac{1}{|a|}$.\nTherefore, the general expression for the PDF of $Y$ is:\n$$f_{Y}(y) = \\frac{1}{|a|} f_{X}\\left(\\frac{y-b}{a}\\right)$$\nThis is a standard result known as the change-of-variables formula for probability densities, here derived from first principles.\n\nTo illustrate this result, let us consider the case where $X$ follows a standard normal distribution, $X \\sim \\mathcal{N}(0,1)$. The PDF of $X$ is given by:\n$$f_{X}(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right)$$\nUsing the derived formula, the PDF of $Y = aX+b$ is:\n$$f_{Y}(y) = \\frac{1}{|a|} f_{X}\\left(\\frac{y-b}{a}\\right) = \\frac{1}{|a|} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{y-b}{a}\\right)^2\\right)$$\n$$f_{Y}(y) = \\frac{1}{\\sqrt{2\\pi}|a|} \\exp\\left(-\\frac{(y-b)^2}{2a^2}\\right)$$\nWe can write $|a| = \\sqrt{a^2}$. So, the expression becomes:\n$$f_{Y}(y) = \\frac{1}{\\sqrt{2\\pi a^2}} \\exp\\left(-\\frac{(y-b)^2}{2a^2}\\right)$$\nThis is the PDF of a normal distribution with mean $\\mu = b$ and variance $\\sigma^2 = a^2$. Thus, we have shown that if $X \\sim \\mathcal{N}(0,1)$, then $Y = aX+b \\sim \\mathcal{N}(b, a^2)$, which is a well-established property of the normal distribution and confirms our general derivation.\n\nThe final answer requested is the single closed-form analytic expression for $f_Y(y)$ in terms of the function $f_X$ and the constants $a$ and $b$. Based on our derivation, this expression is the unified formula that holds for any $a \\neq 0$.", "answer": "$$\n\\boxed{\\frac{1}{|a|} f_{X}\\left(\\frac{y-b}{a}\\right)}\n$$", "id": "3055425"}, {"introduction": "The behavior of stochastic processes over time is formalized through the concept of convergence for sequences of random variables. However, 'convergence' can mean different things, and the distinction is crucial for correct analysis. This problem challenges you to explore a classic example that distinguishes convergence in probability from the stronger condition of almost sure convergence, a subtlety that is fundamental to the rigorous study of stochastic systems. [@problem_id:3055424]", "problem": "Consider the probability space $([0,1],\\mathcal{B}([0,1]),\\lambda)$, where $\\mathcal{B}([0,1])$ is the Borel $\\sigma$-algebra on $[0,1]$ and $\\lambda$ is the Lebesgue measure. A random variable is a measurable function from $[0,1]$ to $\\mathbb{R}$. A sequence of random variables $\\{X_n\\}_{n\\ge 1}$ converges in probability to $0$ if for every $\\varepsilon>0$, $\\lambda\\big(\\{\\omega\\in[0,1]: |X_n(\\omega)|>\\varepsilon\\}\\big)\\to 0$ as $n\\to\\infty$. It converges almost surely to $0$ if $\\lambda\\big(\\{\\omega\\in[0,1]: \\lim_{n\\to\\infty} X_n(\\omega)=0\\}\\big)=1$.\n\nSelect the option that correctly constructs, using a diagonal array, a sequence $\\{X_n\\}_{n\\ge 1}$ that converges in probability to $0$ but does not converge almost surely to $0$ on $([0,1],\\mathcal{B}([0,1]),\\lambda)$. Justify the convergence behavior of the sequence within the option.\n\nA. For each $m\\in\\mathbb{N}$, partition $[0,1]$ into $m$ half-open intervals $I_{m,k} := \\big((k-1)/m,\\,k/m\\big]$ for $k=1,2,\\dots,m$. Enumerate the pairs $(m,k)$ by increasing $m$ and, within each $m$, increasing $k$. Define $X_n(\\omega):=\\mathbf{1}_{I_{m,k}}(\\omega)$ when $n$ corresponds to $(m,k)$ in this enumeration. Claim: $X_n\\to 0$ in probability but $X_n$ does not converge almost surely.\n\nB. Define $X_n(\\omega):=\\mathbf{1}_{[0,1/n]}(\\omega)$ for $n\\in\\mathbb{N}$. Claim: $X_n\\to 0$ in probability and $X_n\\to 0$ almost surely.\n\nC. Define $X_n(\\omega):=\\mathbf{1}_{[0,1/2]}(\\omega)$ for all $n\\in\\mathbb{N}$. Claim: $X_n\\not\\to 0$ in probability and $X_n$ does not converge almost surely.\n\nD. For each $n\\in\\mathbb{N}$, let $X_n(\\omega):=\\mathbf{1}_{[0,1]}(\\omega)\\cdot \\mathbf{1}_{\\{n \\text{ is a perfect square}\\}}$, that is, $X_n(\\omega)=1$ when $n$ is a perfect square and $X_n(\\omega)=0$ otherwise. Claim: $X_n\\to 0$ in probability but $X_n$ does not converge almost surely.", "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n- **Probability Space**: $([0,1],\\mathcal{B}([0,1]),\\lambda)$, where $\\mathcal{B}([0,1])$ is the Borel $\\sigma$-algebra on $[0,1]$ and $\\lambda$ is the Lebesgue measure.\n- **Random Variable Definition**: A measurable function from $[0,1]$ to $\\mathbb{R}$.\n- **Convergence in Probability**: A sequence of random variables $\\{X_n\\}_{n\\ge 1}$ converges in probability to $0$ if for every $\\varepsilon>0$, $\\lambda\\big(\\{\\omega\\in[0,1]: |X_n(\\omega)|>\\varepsilon\\}\\big)\\to 0$ as $n\\to\\infty$.\n- **Almost Sure Convergence**: A sequence of random variables $\\{X_n\\}_{n\\ge 1}$ converges almost surely to $0$ if $\\lambda\\big(\\{\\omega\\in[0,1]: \\lim_{n\\to\\infty} X_n(\\omega)=0\\}\\big)=1$.\n- **Objective**: Select the option that constructs a sequence $\\{X_n\\}_{n\\ge 1}$ that converges in probability to $0$ but does not converge almost surely to $0$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem provides standard, correct definitions from measure-theoretic probability theory. The concepts of convergence in probability and almost sure convergence are fundamental. The task is to identify a classic example, often called the \"typewriter\" or \"running bump\" sequence, which illustrates the distinction between these two modes of convergence. The problem is scientifically grounded, well-posed, objective, and contains no internal contradictions or ambiguities.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A full solution will be derived by analyzing each option.\n\n---\n\n### Analysis of a Generic Sequence of Indicator Functions\nLet $\\{E_n\\}_{n\\ge 1}$ be a sequence of measurable sets in $[0,1]$ and let $X_n = \\mathbf{1}_{E_n}$ be the corresponding sequence of indicator random variables. According to the provided definitions:\n- **Convergence in Probability to $0$**: For any $\\varepsilon \\in (0,1)$, we must have $\\lambda(\\{\\omega: |X_n(\\omega)| > \\varepsilon\\}) = \\lambda(\\{\\omega: X_n(\\omega) = 1\\}) = \\lambda(E_n) \\to 0$ as $n\\to\\infty$.\n- **Almost Sure Convergence to $0$**: We must have $\\lambda(\\{\\omega: \\lim_{n\\to\\infty} X_n(\\omega) = 0\\}) = 1$. The limit $\\lim_{n\\to\\infty} X_n(\\omega) = 0$ if and only if for a given $\\omega$, $X_n(\\omega) = 1$ for only a finite number of indices $n$. This is equivalent to saying $\\omega$ belongs to at most a finite number of the sets $E_n$. The set of points that belong to infinitely many sets $E_n$ is the limit superior of the sequence of sets, denoted $\\limsup_{n\\to\\infty} E_n$. Therefore, almost sure convergence to $0$ is equivalent to the condition $\\lambda(\\limsup_{n\\to\\infty} E_n) = 0$.\n\nThe problem asks for a sequence $\\{X_n\\}$ such that $\\lambda(E_n)\\to 0$ but $\\lambda(\\limsup_{n\\to\\infty} E_n) \\ne 0$ (specifically, we will see it is $1$, so the convergence to $0$ fails for almost every $\\omega$).\n\n### Option-by-Option Analysis\n\n**Option A**\n\n- **Construction**: For each $m \\in \\mathbb{N}$, the interval $[0,1]$ is partitioned (except for the point $0$) into $m$ intervals $I_{m,k} := ((k-1)/m, k/m]$ for $k=1,2,\\dots,m$. Let $E_n$ be the interval $I_{m,k}$ where $n$ is the index corresponding to the pair $(m,k)$ enumerated by increasing $m$, then increasing $k$. The random variable is $X_n := \\mathbf{1}_{E_n}$. This construction is what is meant by a \"diagonal array\".\n- **Analysis of Convergence in Probability**: The sequence of sets $E_n$ is $I_{1,1}, I_{2,1}, I_{2,2}, I_{3,1}, I_{3,2}, I_{3,3}, \\dots$. The Lebesgue measure of a generic set $E_n=I_{m,k}$ in this sequence is $\\lambda(I_{m,k}) = k/m - (k-1)/m = 1/m$. The enumeration maps $n$ to $(m,k)$ such that as $n \\to \\infty$, the block index $m$ must also go to infinity ($m\\to\\infty$). Therefore, $\\lambda(E_n) = 1/m \\to 0$ as $n \\to \\infty$. The sequence $\\{X_n\\}$ converges to $0$ in probability.\n- **Analysis of Almost Sure Convergence**: We examine the set $\\limsup_{n\\to\\infty} E_n$. A point $\\omega$ is in this set if it is in infinitely many of the $E_n$. Consider any $\\omega \\in (0,1]$. For any integer $m \\ge 1$, there exists a unique integer $k_m \\in \\{1, 2, \\dots, m\\}$ such that $\\omega \\in I_{m, k_m}$. This means that for each $m$, $\\omega$ belongs to one of the sets from the $m$-th block of our sequence. Since $m$ can be any natural number, $\\omega$ belongs to an infinite number of sets $E_n$ (one for each $m$). Thus, for any $\\omega \\in (0,1]$, $\\limsup_{n\\to\\infty} X_n(\\omega) = 1$, which implies the limit does not exist and is not $0$. The set of points where the limit is $0$ is at most $\\{0\\}$, which has measure $0$. The condition $\\lambda(\\{\\omega: \\lim_{n\\to\\infty} X_n(\\omega) = 0\\}) = 1$ is not met. Therefore, $\\{X_n\\}$ does not converge almost surely to $0$. This conclusion is supported by the Borel-Cantelli lemma, as $\\sum_{n=1}^\\infty \\lambda(E_n) = \\sum_{m=1}^\\infty \\sum_{k=1}^m \\lambda(I_{m,k}) = \\sum_{m=1}^\\infty \\sum_{k=1}^m \\frac{1}{m} = \\sum_{m=1}^\\infty 1 = \\infty$. While the sets are not independent, the fact that $\\lambda(\\limsup E_n) = \\lambda((0,1]) = 1$ directly shows the lack of almost sure convergence.\n- **Verdict**: The claim within the option is correct. The sequence converges in probability to $0$ but does not converge almost surely to $0$. This option correctly provides the required construction.\n\n**Option B**\n\n- **Construction**: $X_n(\\omega) := \\mathbf{1}_{[0,1/n]}(\\omega)$. Let $E_n = [0, 1/n]$.\n- **Analysis of Convergence in Probability**: We have $\\lambda(E_n) = \\lambda([0, 1/n]) = 1/n$. As $n\\to\\infty$, $\\lambda(E_n) \\to 0$. So, $\\{X_n\\}$ converges to $0$ in probability.\n- **Analysis of Almost Sure Convergence**: Consider a point $\\omega \\in (0,1]$. By the Archimedean property, there exists an integer $N$ such that $N > 1/\\omega$, which implies $1/N < \\omega$. For all $n \\ge N$, we have $1/n \\le 1/N < \\omega$, so $\\omega \\notin [0, 1/n]$. This means $X_n(\\omega) = 0$ for all $n \\ge N$. Thus, $\\lim_{n\\to\\infty} X_n(\\omega) = 0$. This holds for all $\\omega \\in (0,1]$. The set of points where the limit is not $0$ is just $\\{0\\}$, which has Lebesgue measure $0$. Therefore, $\\lambda(\\{\\omega: \\lim_{n\\to\\infty} X_n(\\omega)=0\\}) = \\lambda((0,1]) = 1$. The sequence converges almost surely to $0$.\n- **Verdict**: The claim \"$X_n\\to 0$ in probability and $X_n\\to 0$ almost surely\" is correct. However, this is not the example sought by the problem, which requires almost sure convergence to fail. Thus, this option is **Incorrect** as an answer to the main question.\n\n**Option C**\n\n- **Construction**: $X_n(\\omega) := \\mathbf{1}_{[0,1/2]}(\\omega)$ for all $n \\in \\mathbb{N}$. Let $E_n = [0, 1/2]$ for all $n$.\n- **Analysis of Convergence in Probability**: We have $\\lambda(E_n) = \\lambda([0, 1/2]) = 1/2$ for all $n$. The sequence of measures $\\lambda(E_n)$ is constant at $1/2$ and does not converge to $0$. Thus, $\\{X_n\\}$ does not converge to $0$ in probability.\n- **Analysis of Almost Sure Convergence**: For $\\omega \\in [0, 1/2]$, $X_n(\\omega) = 1$ for all $n$, so $\\lim_{n\\to\\infty} X_n(\\omega) = 1$. For $\\omega \\in (1/2, 1]$, $X_n(\\omega) = 0$ for all $n$, so $\\lim_{n\\to\\infty} X_n(\\omega) = 0$. The set of points where the limit is $0$ is $(1/2, 1]$, which has measure $1/2$. Since this measure is not $1$, the sequence does not converge almost surely to $0$.\n- **Verdict**: The claim \"$X_n\\not\\to 0$ in probability and $X_n$ does not converge almost surely\" is correct. This option is **Incorrect** as it does not describe a sequence that converges in probability to $0$.\n\n**Option D**\n\n- **Construction**: $X_n(\\omega) = 1$ if $n$ is a perfect square and $X_n(\\omega) = 0$ otherwise, for all $\\omega \\in [0,1]$. This defines a sequence of random variables that are constant on the sample space $[0,1]$. Let $c_n=1$ if $n=k^2$ for some $k \\in \\mathbb{N}$ and $c_n=0$ otherwise. Then $X_n(\\omega)=c_n$.\n- **Analysis of Convergence in Probability**: Let $\\varepsilon \\in (0,1)$. The set $\\{\\omega: |X_n(\\omega)| > \\varepsilon\\}$ is $[0,1]$ if $X_n(\\omega)=1$ and $\\emptyset$ if $X_n(\\omega)=0$. So, $\\lambda(\\{\\omega: |X_n(\\omega)| > \\varepsilon\\})$ is $1$ if $n$ is a perfect square and $0$ otherwise. The sequence of measures is $1,0,0,1,0,0,0,0,1, \\dots$. This sequence does not converge to $0$, as it has a subsequence that is identically $1$. Thus, $\\{X_n\\}$ does not converge to $0$ in probability.\n- **Analysis of Almost Sure Convergence**: For any $\\omega \\in [0,1]$, the sequence of values $X_n(\\omega)$ is $1,0,0,1,0,0,0,0,1, \\dots$. This numerical sequence does not converge, as its limit superior is $1$ and its limit inferior is $0$. Therefore, the set $\\{\\omega: \\lim_{n\\to\\infty} X_n(\\omega) = 0\\}$ is the empty set, which has measure $0$. The sequence does not converge almost surely to $0$.\n- **Verdict**: The claim \"$X_n\\to 0$ in probability\" is false. Therefore, the entire claim made in the option is false. This option is **Incorrect**.\n\n### Conclusion\nOnly option A presents a sequence of random variables that converges in probability to $0$ but fails to converge almost surely to $0$. The justification provided in the option is also correct.", "answer": "$$\\boxed{A}$$", "id": "3055424"}, {"introduction": "At the heart of stochastic differential equations lies the Itô integral, which generalizes the concept of integration to a random, erratic path like Brownian motion. This practice provides a concrete entry point into this essential tool by having you analyze a simple yet non-trivial stochastic integral, $I(t)=\\int_{0}^{t}s\\,dW_{s}$. By applying the Itô isometry, you will directly connect the integral's properties, such as its mean and variance, back to the foundational definition of Brownian motion. [@problem_id:3055415]", "problem": "Let $W=\\{W_{s}:s\\geq 0\\}$ be a standard Brownian motion (also called a Wiener process) on a filtered probability space satisfying the usual conditions. For a fixed $t>0$, consider the It\\^{o} stochastic integral\n$$\nI(t)=\\int_{0}^{t}s\\,dW_{s},\n$$\ndefined via the $L^{2}$ limit of adapted step processes. Starting from the foundational definitions of standard Brownian motion, its independent and stationary increments, and the construction of the It\\^{o} integral from simple processes, justify why $I(t)$ is a Gaussian random variable and determine its mean. Then, using the It\\^{o} isometry, compute the variance of $I(t)$ as a function of $t$. Provide your final answer as a single closed-form analytic expression in $t$ for the variance of $I(t)$. Do not quote any pre-derived shortcut formulas without justification from the above foundations, and ensure that each step in your reasoning is made explicit. No rounding is required.", "solution": "The problem statement is found to be valid as it is scientifically grounded, well-posed, objective, self-contained, and consistent. It represents a standard exercise in the theory of stochastic calculus. We proceed with the solution.\n\nThe stochastic integral $I(t) = \\int_{0}^{t}s\\,dW_{s}$ is defined for the deterministic integrand $f(s) = s$ with respect to a standard $1$-dimensional Brownian motion $\\{W_s\\}_{s \\ge 0}$ on a filtered probability space $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_s\\}_{s \\geq 0}, P)$ satisfying the usual conditions. We are tasked to demonstrate that $I(t)$ is a Gaussian random variable, and to compute its mean and variance based on foundational principles.\n\nFirst, we justify the Gaussian nature of $I(t)$. The Itô integral is constructed as a limit in $L^2(\\Omega, \\mathcal{F}, P)$ of integrals of simple processes. A simple process $\\phi(s)$ on $[0, t]$ is a process of the form $\\phi(s) = \\sum_{i=0}^{n-1} \\xi_i \\mathbb{I}_{(t_i, t_{i+1}]}(s)$, where $0 = t_0 < t_1 < \\dots < t_n = t$ is a partition of $[0, t]$ and each $\\xi_i$ is an $\\mathcal{F}_{t_i}$-measurable random variable. The integral of such a simple process is defined as $\\int_0^t \\phi(s) dW_s = \\sum_{i=0}^{n-1} \\xi_i (W_{t_{i+1}} - W_{t_i})$.\n\nThe integrand in our problem is the deterministic function $f(s) = s$, which is continuous and therefore belongs to the space $L^2([0, t])$ since $\\int_0^t s^2 ds = t^3/3 < \\infty$. We can approximate $f(s) = s$ by a sequence of simple processes. Let's consider a sequence of partitions of $[0, t]$ with mesh size tending to zero. For a given $n \\in \\mathbb{N}$, let the partition points be $t_i = \\frac{i t}{n}$ for $i=0, 1, \\dots, n$. We define a sequence of simple processes $\\phi_n(s)$ by taking the value of the function at the left endpoint of each subinterval:\n$$\n\\phi_n(s) = \\sum_{i=0}^{n-1} f(t_i) \\mathbb{I}_{(t_i, t_{i+1}]}(s) = \\sum_{i=0}^{n-1} t_i \\mathbb{I}_{(t_i, t_{i+1}]}(s).\n$$\nSince $f(s)=s$ is deterministic, the coefficients $\\xi_i$ are constants, $\\xi_i = f(t_i) = t_i$. The Itô integral for this simple process $\\phi_n(s)$ is the random variable $I_n(t)$:\n$$\nI_n(t) = \\int_0^t \\phi_n(s) dW_s = \\sum_{i=0}^{n-1} t_i (W_{t_{i+1}} - W_{t_i}).\n$$\nBy definition, a standard Brownian motion has independent increments. The random variables $\\Delta W_i = W_{t_{i+1}} - W_{t_i}$ are independent for different indices $i$. Furthermore, each increment is a Gaussian random variable with distribution $\\Delta W_i \\sim N(0, t_{i+1} - t_i)$.\nThe random variable $I_n(t)$ is a linear combination of independent Gaussian random variables. A fundamental property of the Gaussian distribution is that any linear combination of independent Gaussian random variables is itself a Gaussian random variable. Thus, for each $n$, $I_n(t)$ is a Gaussian random variable.\n\nThe Itô integral $I(t)$ is defined as the $L^2$-limit of the sequence of random variables $\\{I_n(t)\\}_{n \\in \\mathbb{N}}$ as $n \\to \\infty$. A key theorem in probability theory states that if a sequence of Gaussian random variables converges in $L^2$ to a random variable $X$, then $X$ must also be a Gaussian random variable. This is because convergence in $L^2$ implies convergence in distribution. The characteristic function of $I_n(t)$ is of Gaussian form, and the limit of these characteristic functions must be the characteristic function of the limit random variable $I(t)$, which must therefore also be Gaussian. Hence, we conclude that $I(t) = \\int_{0}^{t}s\\,dW_{s}$ is a Gaussian random variable.\n\nNext, we determine the mean of $I(t)$. Since convergence in $L^2$ implies convergence in $L^1$, we can interchange the expectation and the limit:\n$$\n\\mathbb{E}[I(t)] = \\mathbb{E}[\\lim_{n \\to \\infty} I_n(t)] = \\lim_{n \\to \\infty} \\mathbb{E}[I_n(t)].\n$$\nWe compute the expectation of $I_n(t)$ using its definition and the linearity of expectation:\n$$\n\\mathbb{E}[I_n(t)] = \\mathbb{E}\\left[\\sum_{i=0}^{n-1} t_i (W_{t_{i+1}} - W_{t_i})\\right] = \\sum_{i=0}^{n-1} \\mathbb{E}[t_i (W_{t_{i+1}} - W_{t_i})].\n$$\nSince the $t_i$ values are deterministic constants, we have:\n$$\n\\mathbb{E}[I_n(t)] = \\sum_{i=0}^{n-1} t_i \\mathbb{E}[W_{t_{i+1}} - W_{t_i}].\n$$\nFor a standard Brownian motion, the increments have mean zero: $\\mathbb{E}[W_{t_{i+1}} - W_{t_i}] = 0$. Therefore, for every $n$:\n$$\n\\mathbb{E}[I_n(t)] = \\sum_{i=0}^{n-1} t_i \\cdot 0 = 0.\n$$\nConsequently, the mean of $I(t)$ is:\n$$\n\\mathbb{E}[I(t)] = \\lim_{n \\to \\infty} 0 = 0.\n$$\n\nFinally, we compute the variance of $I(t)$. The variance is given by $\\text{Var}(I(t)) = \\mathbb{E}[I(t)^2] - (\\mathbb{E}[I(t)])^2$. Since we have shown that $\\mathbb{E}[I(t)]=0$, the variance simplifies to the second moment:\n$$\n\\text{Var}(I(t)) = \\mathbb{E}[I(t)^2].\n$$\nTo compute this, we use the Itô isometry property. The Itô isometry states that for any adapted process $\\phi_s$ belonging to the space of processes with finite expected integrated square, i.e., $\\mathbb{E}[\\int_0^t \\phi_s^2 ds] < \\infty$, the following equality holds:\n$$\n\\mathbb{E}\\left[\\left(\\int_0^t \\phi_s dW_s\\right)^2\\right] = \\mathbb{E}\\left[\\int_0^t \\phi_s^2 ds\\right].\n$$\nThis property is foundational to the construction of the Itô integral. It is first established for simple processes. For a simple process $\\phi_s = \\sum_{i=0}^{n-1} \\xi_i \\mathbb{I}_{(t_i, t_{i+1}]}(s)$, its integral is $I_\\phi(t) = \\sum_{i=0}^{n-1} \\xi_i \\Delta W_i$. The second moment is $\\mathbb{E}[I_\\phi(t)^2] = \\mathbb{E}[(\\sum_i \\xi_i \\Delta W_i)(\\sum_j \\xi_j \\Delta W_j)] = \\sum_{i,j} \\mathbb{E}[\\xi_i \\xi_j \\Delta W_i \\Delta W_j]$. Due to the independent increments property of Brownian motion, the expectation of cross-terms, e.g., for $i < j$, is $\\mathbb{E}[\\xi_i \\xi_j \\Delta W_i \\Delta W_j] = \\mathbb{E}[\\mathbb{E}[\\xi_i \\xi_j \\Delta W_i \\Delta W_j | \\mathcal{F}_{t_j}]] = \\mathbb{E}[\\xi_i \\xi_j \\Delta W_i \\mathbb{E}[\\Delta W_j | \\mathcal{F}_{t_j}]] = 0$. So all cross-terms ($i \\neq j$) vanish. The sum reduces to the diagonal terms: $\\sum_i \\mathbb{E}[\\xi_i^2 (\\Delta W_i)^2]$. Using the tower property and independence of $\\Delta W_i$ from $\\mathcal{F}_{t_i}$, this becomes $\\mathbb{E}[\\xi_i^2 (\\Delta W_i)^2] = \\mathbb{E}[\\xi_i^2 \\mathbb{E}[(\\Delta W_i)^2|\\mathcal{F}_{t_i}]] = \\mathbb{E}[\\xi_i^2]\\text{Var}(\\Delta W_i) = \\mathbb{E}[\\xi_i^2](t_{i+1}-t_i)$. Thus, $\\mathbb{E}[I_\\phi(t)^2] = \\sum_i \\mathbb{E}[\\xi_i^2](t_{i+1}-t_i) = \\mathbb{E}[\\int_0^t \\phi_s^2 ds]$. The property is extended to general integrands via the $L^2$ limiting procedure that defines the Itô integral.\n\nIn our problem, the integrand is the deterministic function $\\phi_s = s$. A deterministic function is trivially adapted. Applying the Itô isometry:\n$$\n\\text{Var}(I(t)) = \\mathbb{E}\\left[\\left(\\int_0^t s dW_s\\right)^2\\right] = \\mathbb{E}\\left[\\int_0^t s^2 ds\\right].\n$$\nSince the integrand $s^2$ in the right-hand side integral is deterministic, the expectation operator has no effect. The expression simplifies to a standard definite integral:\n$$\n\\text{Var}(I(t)) = \\int_0^t s^2 ds.\n$$\nWe evaluate this integral:\n$$\n\\int_0^t s^2 ds = \\left[ \\frac{s^3}{3} \\right]_0^t = \\frac{t^3}{3} - \\frac{0^3}{3} = \\frac{t^3}{3}.\n$$\nTherefore, the variance of the stochastic integral $I(t) = \\int_0^t s dW_s$ is $\\frac{t^3}{3}$. The distribution of $I(t)$ is fully characterized as $I(t) \\sim N(0, \\frac{t^3}{3})$. The problem asks for the variance of $I(t)$ as the final answer.", "answer": "$$\\boxed{\\frac{t^3}{3}}$$", "id": "3055415"}]}