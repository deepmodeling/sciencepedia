{"hands_on_practices": [{"introduction": "Before analyzing specific stochastic processes, it is valuable to establish a general property of their increments. This exercise challenges you to prove a fundamental result: if a process is wide-sense stationary, then the process formed by its increments is also wide-sense stationary. Mastering this derivation [@problem_id:3075817] provides a powerful, general tool for analyzing time series models and develops essential skills in manipulating covariance functions.", "problem": "Let $\\{X_{t}: t \\in \\mathbb{R}\\}$ be a real-valued stochastic process that is covariance stationary in the wide-sense (also called second-order stationary): it has a constant mean $\\mu$ and autocovariance function $C(\\tau) = \\operatorname{Cov}(X_{t+\\tau}, X_{t})$ that depends only on the lag $\\tau$ and is finite for all $\\tau \\in \\mathbb{R}$. Fix a lag $h0$ and define the increment process $Y_{t} = X_{t+h} - X_{t}$ for all $t \\in \\mathbb{R}$. Using only the definition of covariance and covariance stationarity, compute the autocovariance of the increment process, $\\gamma_{Y}(u) = \\operatorname{Cov}(Y_{t}, Y_{t+u})$, and express your answer solely in terms of $C(\\cdot)$, $h$, and $u$. Provide your final result as a single closed-form analytic expression.", "solution": "The problem as stated is valid. It is a well-posed, scientifically grounded problem within the field of stochastic processes, with a clear and objective formulation. All necessary definitions and conditions are provided, and there are no internal contradictions or ambiguities.\n\nOur objective is to compute the autocovariance function of the increment process $\\{Y_t\\}$, denoted by $\\gamma_Y(u)$, where $Y_t = X_{t+h} - X_t$. The process $\\{X_t\\}$ is given to be wide-sense stationary, which means it has a constant mean $\\mathbb{E}[X_t] = \\mu$ and an autocovariance function $\\operatorname{Cov}(X_s, X_t) = C(t-s)$ that depends only on the time lag $t-s$.\n\nThe autocovariance function of $Y_t$ is defined as $\\gamma_Y(u) = \\operatorname{Cov}(Y_t, Y_{t+u})$.\nFirst, we express $Y_t$ and $Y_{t+u}$ in terms of the original process $X_t$:\n$$Y_t = X_{t+h} - X_t$$\n$$Y_{t+u} = X_{t+u+h} - X_{t+u}$$\nSubstituting these definitions into the expression for $\\gamma_Y(u)$:\n$$\\gamma_Y(u) = \\operatorname{Cov}(X_{t+h} - X_t, X_{t+u+h} - X_{t+u})$$\nThe covariance operator is bilinear. For any four random variables $A$, $B$, $C$, and $D$ with finite second moments, we have:\n$$\\operatorname{Cov}(A - B, C - D) = \\operatorname{Cov}(A, C) - \\operatorname{Cov}(A, D) - \\operatorname{Cov}(B, C) + \\operatorname{Cov}(B, D)$$\nWe apply this property by setting $A = X_{t+h}$, $B = X_t$, $C = X_{t+u+h}$, and $D = X_{t+u}$. This yields:\n$$\\gamma_Y(u) = \\operatorname{Cov}(X_{t+h}, X_{t+u+h}) - \\operatorname{Cov}(X_{t+h}, X_{t+u}) - \\operatorname{Cov}(X_t, X_{t+u+h}) + \\operatorname{Cov}(X_t, X_{t+u})$$\nNow, we use the property of wide-sense stationarity of $X_t$, which states that $\\operatorname{Cov}(X_s, X_{s'}) = C(s' - s)$. We evaluate each of the four covariance terms in the expression above:\n1. The first term is $\\operatorname{Cov}(X_{t+h}, X_{t+u+h})$. The time indices are $s = t+h$ and $s' = t+u+h$. The time lag is $s' - s = (t+u+h) - (t+h) = u$. Therefore, this term is equal to $C(u)$.\n2. The second term is $\\operatorname{Cov}(X_{t+h}, X_{t+u})$. The time indices are $s = t+h$ and $s' = t+u$. The time lag is $s' - s = (t+u) - (t+h) = u-h$. Therefore, this term is equal to $C(u-h)$.\n3. The third term is $\\operatorname{Cov}(X_t, X_{t+u+h})$. The time indices are $s = t$ and $s' = t+u+h$. The time lag is $s' - s = (t+u+h) - t = u+h$. Therefore, this term is equal to $C(u+h)$.\n4. The fourth term is $\\operatorname{Cov}(X_t, X_{t+u})$. The time indices are $s = t$ and $s' = t+u$. The time lag is $s' - s = (t+u) - t = u$. Therefore, this term is equal to $C(u)$.\n\nSubstituting these expressions back into the equation for $\\gamma_Y(u)$:\n$$\\gamma_Y(u) = C(u) - C(u-h) - C(u+h) + C(u)$$\nFinally, combining the like terms, we arrive at the closed-form expression for the autocovariance of the increment process:\n$$\\gamma_Y(u) = 2C(u) - C(u+h) - C(u-h)$$\nThis result is expressed solely in terms of the autocovariance function $C(\\cdot)$ of the original process and the parameters $u$ and $h$, as required. The expression is independent of $t$, which confirms that the increment process $Y_t$ is also wide-sense stationary.", "answer": "$$\\boxed{2C(u) - C(u+h) - C(u-h)}$$", "id": "3075817"}, {"introduction": "The Ornstein-Uhlenbeck (OU) process is a cornerstone model for systems exhibiting mean-reversion, from particle velocities to interest rates. This practice [@problem_id:3075863] asks you to connect the process's SDE representation, its time-domain autocovariance function, and its frequency-domain spectral density. By relating these perspectives and analyzing the structure of its increments, you will build a robust, multi-faceted understanding of this fundamental stationary process.", "problem": "Let $\\alpha0$ and $\\sigma0$ be fixed constants, and consider the function $C:\\mathbb{R}\\to\\mathbb{R}$ defined by $C(\\tau)=\\sigma^{2}\\exp(-\\alpha|\\tau|)$. Suppose $C(\\tau)$ is proposed as the autocovariance function of a real-valued, zero-mean, wide-sense stationary stochastic process $\\{X_{t}\\}_{t\\in\\mathbb{R}}$. \n\n(a) Using the definition of positive semidefiniteness of a covariance kernel together with the spectral representation of stationary processes, verify that $C(\\tau)$ is a valid autocovariance by explicitly computing the spectral density $S(\\omega)$ as the Fourier transform $S(\\omega)=\\int_{-\\infty}^{\\infty}C(\\tau)\\exp(-\\mathrm{i}\\omega\\tau)\\,\\mathrm{d}\\tau$ and showing $S(\\omega)\\ge 0$ for all real $\\omega$.\n\n(b) Identify the linear Ornstein–Uhlenbeck (OU) process, defined as the unique strictly stationary solution to the linear Stochastic Differential Equation (SDE) of the form $\\mathrm{d}X_{t}=-a X_{t}\\mathrm{d}t+b\\mathrm{d}W_{t}$ driven by a standard Wiener process $\\{W_{t}\\}_{t\\in\\mathbb{R}}$, whose autocovariance equals $C(\\tau)$. Determine the drift coefficient $a$ and diffusion coefficient $b$ in terms of $\\alpha$ and $\\sigma$.\n\n(c) Briefly justify, from the covariance structure alone, whether the increments $\\Delta_{h}X_{t}=X_{t+h}-X_{t}$ are stationary in the second-order sense, and compute $\\mathrm{Var}(\\Delta_{h}X_{t})$ as a function of $h0$.\n\nProvide your final answer as a single row matrix in the order $(S(\\omega),a,b)$. No numerical rounding is required, and no physical units are involved.", "solution": "The problem statement is subjected to validation prior to any attempt at a solution.\n\n### Step 1: Extract Givens\n-   Constants: $\\alpha  0$, $\\sigma  0$.\n-   Function: $C(\\tau) = \\sigma^2 \\exp(-\\alpha|\\tau|)$, for $\\tau \\in \\mathbb{R}$.\n-   Context: $C(\\tau)$ is proposed as the autocovariance function of a zero-mean, real-valued, wide-sense stationary (WSS) stochastic process $\\{X_t\\}_{t \\in \\mathbb{R}}$.\n-   Part (a): Verify $C(\\tau)$ is a valid autocovariance by computing the spectral density $S(\\omega) = \\int_{-\\infty}^{\\infty} C(\\tau) \\exp(-i\\omega\\tau) d\\tau$ and showing $S(\\omega) \\ge 0$.\n-   Part (b): Identify the parameters $a$ and $b$ of the Ornstein–Uhlenbeck (OU) process, described by the SDE $dX_t = -a X_t dt + b dW_t$, that has $C(\\tau)$ as its autocovariance function.\n-   Part (c): Justify if the increment process $\\Delta_h X_t = X_{t+h} - X_t$ is second-order stationary and compute its variance, $\\text{Var}(\\Delta_h X_t)$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientific Grounding**: The problem is well-grounded in the theory of stochastic processes. It involves standard concepts such as wide-sense stationarity, autocovariance functions, Bochner's theorem, spectral density, the Ornstein-Uhlenbeck process, and stochastic differential equations. The function $C(\\tau)$ is the canonical autocovariance for the OU process.\n-   **Well-Posedness**: The problem is well-posed. Each part requests a specific, calculable quantity or a justification based on established theory. The necessary information is provided.\n-   **Objectivity**: The problem is stated in precise, objective mathematical language.\n-   **Flaw Analysis**: The problem is free from scientific unsoundness, ambiguity, contradictions, or any other listed flaws. It is a standard, non-trivial exercise in its field.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n---\n\n### Solution\n\n**(a) Verification of the Autocovariance Function**\n\nAccording to Bochner's theorem, a continuous function $C(\\tau)$ is the autocovariance function of a mean-square continuous, wide-sense stationary (WSS) stochastic process if and only if it is positive semidefinite. For a continuous WSS process, this is equivalent to the condition that its Fourier transform, the power spectral density $S(\\omega)$, is non-negative for all $\\omega \\in \\mathbb{R}$.\n\nWe compute the spectral density $S(\\omega)$ by taking the Fourier transform of $C(\\tau)$:\n$$S(\\omega) = \\int_{-\\infty}^{\\infty} C(\\tau) \\exp(-i\\omega\\tau) d\\tau = \\int_{-\\infty}^{\\infty} \\sigma^2 \\exp(-\\alpha|\\tau|) \\exp(-i\\omega\\tau) d\\tau$$\nDue to the absolute value in the exponent, we split the integral:\n$$S(\\omega) = \\sigma^2 \\left( \\int_{-\\infty}^{0} \\exp(\\alpha\\tau) \\exp(-i\\omega\\tau) d\\tau + \\int_{0}^{\\infty} \\exp(-\\alpha\\tau) \\exp(-i\\omega\\tau) d\\tau \\right)$$\n$$S(\\omega) = \\sigma^2 \\left( \\int_{-\\infty}^{0} \\exp((\\alpha - i\\omega)\\tau) d\\tau + \\int_{0}^{\\infty} \\exp(-(\\alpha + i\\omega)\\tau) d\\tau \\right)$$\nSince $\\alpha  0$, the integrals converge. Evaluating the integrals:\n$$S(\\omega) = \\sigma^2 \\left( \\left[ \\frac{\\exp((\\alpha - i\\omega)\\tau)}{\\alpha - i\\omega} \\right]_{-\\infty}^{0} + \\left[ \\frac{\\exp(-(\\alpha + i\\omega)\\tau)}{-(\\alpha + i\\omega)} \\right]_{0}^{\\infty} \\right)$$\n$$S(\\omega) = \\sigma^2 \\left( \\left( \\frac{1}{\\alpha - i\\omega} - 0 \\right) + \\left( 0 - \\frac{-1}{\\alpha + i\\omega} \\right) \\right)$$\n$$S(\\omega) = \\sigma^2 \\left( \\frac{1}{\\alpha - i\\omega} + \\frac{1}{\\alpha + i\\omega} \\right)$$\nCombining the terms over a common denominator:\n$$S(\\omega) = \\sigma^2 \\left( \\frac{(\\alpha + i\\omega) + (\\alpha - i\\omega)}{(\\alpha - i\\omega)(\\alpha + i\\omega)} \\right) = \\sigma^2 \\left( \\frac{2\\alpha}{\\alpha^2 - (i\\omega)^2} \\right) = \\frac{2\\alpha\\sigma^2}{\\alpha^2 + \\omega^2}$$\nFor this spectral density to be valid, we must verify $S(\\omega) \\ge 0$ for all $\\omega \\in \\mathbb{R}$. Given that $\\alpha  0$ and $\\sigma  0$, the numerator $2\\alpha\\sigma^2$ is strictly positive. The denominator $\\alpha^2 + \\omega^2$ is always positive for any real $\\omega$ (and strictly positive since $\\alpha \\neq 0$). Thus, $S(\\omega)  0$ for all $\\omega \\in \\mathbb{R}$.\nSince $S(\\omega) \\ge 0$, $C(\\tau)$ is a valid autocovariance function.\n\n**(b) Identification of the Ornstein–Uhlenbeck Process Parameters**\n\nThe Ornstein-Uhlenbeck (OU) process is the stationary solution to the linear SDE:\n$$dX_t = -a X_t dt + b dW_t$$\nwhere $a  0$ and $b  0$ are constants and $\\{W_t\\}$ is a standard Wiener process. The stationary solution for $t \\in \\mathbb{R}$ can be expressed as:\n$$X_t = b \\int_{-\\infty}^t \\exp(-a(t-s)) dW_s$$\nThe process is zero-mean, $\\mathbb{E}[X_t] = 0$, as required. Its autocovariance function is $\\mathbb{E}[X_{t}X_{t+\\tau}]$. For $\\tau \\ge 0$:\n$$\\mathbb{E}[X_t X_{t+\\tau}] = \\mathbb{E}\\left[ \\left(b \\int_{-\\infty}^t \\exp(-a(t-s)) dW_s \\right) \\left(b \\int_{-\\infty}^{t+\\tau} \\exp(-a(t+\\tau-u)) dW_u \\right) \\right]$$\nBy applying the Itô isometry:\n$$\\mathbb{E}[X_t X_{t+\\tau}] = b^2 \\int_{-\\infty}^{\\min(t, t+\\tau)} \\exp(-a(t-s)) \\exp(-a(t+\\tau-s)) ds$$\nSince $\\tau \\ge 0$, the upper limit is $t$.\n$$\\mathbb{E}[X_t X_{t+\\tau}] = b^2 \\int_{-\\infty}^t \\exp(-2at - a\\tau + 2as) ds = b^2 \\exp(-a\\tau) \\int_{-\\infty}^t \\exp(-2a(t-s)) ds$$\nLet $v = 2a(t-s)$, then $dv = -2a ds$. The integral becomes:\n$$b^2 \\exp(-a\\tau) \\int_{\\infty}^0 \\exp(-v) \\left(-\\frac{dv}{2a}\\right) = \\frac{b^2}{2a} \\exp(-a\\tau) \\int_0^{\\infty} \\exp(-v) dv = \\frac{b^2}{2a} \\exp(-a\\tau)$$\nSince the autocovariance function must be even, for any $\\tau \\in \\mathbb{R}$, we have:\n$$\\text{Cov}(X_t, X_{t+\\tau}) = \\frac{b^2}{2a} \\exp(-a|\\tau|)$$\nWe are given that this autocovariance is equal to $C(\\tau) = \\sigma^2 \\exp(-\\alpha|\\tau|)$. By comparing the two expressions, we can identify the parameters:\n$$ \\sigma^2 \\exp(-\\alpha|\\tau|) = \\frac{b^2}{2a} \\exp(-a|\\tau|) $$\nBy matching the exponential decay rate, we find:\n$$a = \\alpha$$\nBy matching the pre-exponential factor:\n$$\\sigma^2 = \\frac{b^2}{2a}$$\nSubstituting $a=\\alpha$:\n$$b^2 = 2a\\sigma^2 = 2\\alpha\\sigma^2$$\nSince $b$ is a coefficient that can be taken as positive (the sign can be absorbed into the Wiener process), we have:\n$$b = \\sqrt{2\\alpha\\sigma^2} = \\sigma\\sqrt{2\\alpha}$$\n\n**(c) Stationarity of Increments**\n\nLet the increment process be $Y_t = \\Delta_h X_t = X_{t+h} - X_t$ for a fixed $h0$. For $\\{Y_t\\}$ to be second-order stationary (or WSS), its mean must be constant and its autocovariance function $\\text{Cov}(Y_t, Y_{t+\\tau})$ must depend only on the time lag $\\tau$, not on $t$.\n\nFirst, the mean of $Y_t$:\n$$\\mathbb{E}[Y_t] = \\mathbb{E}[X_{t+h} - X_t] = \\mathbb{E}[X_{t+h}] - \\mathbb{E}[X_t]$$\nSince $\\{X_t\\}$ is a zero-mean process, $\\mathbb{E}[X_s]=0$ for any $s$. Thus, $\\mathbb{E}[Y_t] = 0 - 0 = 0$, which is constant.\n\nSecond, the autocovariance of $Y_t$:\n$$\\text{Cov}(Y_t, Y_{t+\\tau}) = \\mathbb{E}[Y_t Y_{t+\\tau}] - \\mathbb{E}[Y_t]\\mathbb{E}[Y_{t+\\tau}] = \\mathbb{E}[(X_{t+h} - X_t)(X_{t+\\tau+h} - X_{t+\\tau})]$$\nExpanding the product:\n$$\\text{Cov}(Y_t, Y_{t+\\tau}) = \\mathbb{E}[X_{t+h}X_{t+\\tau+h}] - \\mathbb{E}[X_{t+h}X_{t+\\tau}] - \\mathbb{E}[X_t X_{t+\\tau+h}] + \\mathbb{E}[X_t X_{t+\\tau}]$$\nSince $\\{X_t\\}$ is WSS with autocovariance $C(\\cdot)$, we have $\\mathbb{E}[X_u X_v] = C(v-u)$.\n$$\\begin{align*} \\mathbb{E}[X_{t+h}X_{t+\\tau+h}] = C((t+\\tau+h) - (t+h)) = C(\\tau) \\\\ \\mathbb{E}[X_{t+h}X_{t+\\tau}] = C((t+\\tau) - (t+h)) = C(\\tau-h) \\\\ \\mathbb{E}[X_t X_{t+\\tau+h}] = C((t+\\tau+h) - t) = C(\\tau+h) \\\\ \\mathbb{E}[X_t X_{t+\\tau}] = C((t+\\tau)-t) = C(\\tau)\\end{align*}$$\nSubstituting these into the covariance expression:\n$$\\text{Cov}(Y_t, Y_{t+\\tau}) = C(\\tau) - C(\\tau-h) - C(\\tau+h) + C(\\tau) = 2C(\\tau) - C(\\tau-h) - C(\\tau+h)$$\nThis expression depends only on the lag $\\tau$ and the fixed increment duration $h$, and not on the absolute time $t$. Therefore, the increment process $\\{\\Delta_h X_t\\}$ is WSS (second-order stationary).\n\nThe variance of the increment is the autocovariance at lag $\\tau=0$:\n$$\\text{Var}(\\Delta_h X_t) = \\text{Cov}(Y_t, Y_{t}) = 2C(0) - C(-h) - C(h)$$\nSince $C(\\tau)$ is an autocovariance function, it is an even function, i.e., $C(-h) = C(h)$.\n$$\\text{Var}(\\Delta_h X_t) = 2C(0) - 2C(h) = 2(C(0) - C(h))$$\nSubstituting the given function $C(\\tau) = \\sigma^2 \\exp(-\\alpha|\\tau|)$:\n$$C(0) = \\sigma^2 \\exp(0) = \\sigma^2$$\n$$C(h) = \\sigma^2 \\exp(-\\alpha|h|) = \\sigma^2 \\exp(-\\alpha h) \\quad (\\text{since } h0)$$\nThus, the variance is:\n$$\\text{Var}(\\Delta_h X_t) = 2(\\sigma^2 - \\sigma^2 \\exp(-\\alpha h)) = 2\\sigma^2(1 - \\exp(-\\alpha h))$$", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{2\\alpha\\sigma^2}{\\alpha^2 + \\omega^2}  \\alpha  \\sigma\\sqrt{2\\alpha} \\end{pmatrix} } $$", "id": "3075863"}, {"introduction": "How do the elegant properties of continuous-time processes translate to the discrete world of numerical simulations? This practice [@problem_id:3075856] investigates the stationary behavior of the Euler-Maruyama scheme when applied to the Ornstein-Uhlenbeck SDE, revealing its connection to the discrete-time AR(1) model. By comparing the scheme's stationary variance to the true continuous variance, you will gain insight into numerical convergence and the crucial role played by the stationary increments of the underlying Wiener process.", "problem": "Consider the Ornstein–Uhlenbeck stochastic differential equation (SDE) $$dX_{t}=-a\\,X_{t}\\,dt+\\sigma\\,dW_{t},$$ where $a0$, $\\sigma0$, and $(W_{t})_{t\\geq 0}$ is a standard Wiener process (Brownian motion). The continuous-time process $(X_{t})_{t\\geq 0}$ is known to admit a unique stationary distribution.\n\nUsing the Euler–Maruyama (EM) time discretization with constant step size $h0$ applied to this SDE, define the discrete-time process $(X_{n})_{n\\in\\mathbb{N}}$ by sampling at times $t_{n}=nh$. This discretization yields an autoregressive model of order one, commonly denoted autoregressive (AR(1)). Assume the EM recursion produces a strictly stationary sequence whenever its autoregressive coefficient has magnitude less than one, and that the Wiener increments have stationary and independent increments with variance proportional to the step size. Your task is to compute, from first principles, the exact stationary variance of the EM AR(1) scheme as a function of $a$, $\\sigma$, and $h$.\n\nThen, starting from core definitions and Itô calculus, show how the continuous-time stationary variance of the Ornstein–Uhlenbeck process arises, and compare the two variances in the limit as $h\\to 0$, commenting on the role of increment stationarity in the discrete innovations.\n\nProvide as your final answer the exact closed-form expression for the stationary variance of the EM AR(1) scheme in terms of $a$, $\\sigma$, and $h$. No numerical evaluation is required.", "solution": "The problem requires the calculation and comparison of the stationary variance for both the continuous-time Ornstein–Uhlenbeck (OU) process and its discrete-time approximation via the Euler–Maruyama (EM) method.\n\nFirst, we analyze the discrete-time process generated by the Euler–Maruyama scheme. The stochastic differential equation (SDE) is given by\n$$dX_{t} = -a X_{t} dt + \\sigma dW_{t}$$\nwhere $a0$ and $\\sigma0$. The EM discretization with a constant time step $h0$ approximates the continuous process at times $t_{n} = nh$ for $n \\in \\{0, 1, 2, \\dots\\}$. The recursive formula is obtained by approximating the differentials $dt$ and $dW_t$ with their discrete counterparts $\\Delta t = h$ and $\\Delta W_{n} = W_{t_{n+1}} - W_{t_{n}}$, respectively. This yields\n$$X_{n+1} = X_{n} - a X_{n} h + \\sigma (W_{t_{n+1}} - W_{t_{n}})$$\nwhere $X_{n}$ is the approximation of $X_{t_{n}}$. We can rewrite this as\n$$X_{n+1} = (1 - ah) X_{n} + \\sigma \\Delta W_{n}$$\nThis is an autoregressive model of order one, AR(1), of the form $X_{n+1} = \\phi X_{n} + \\epsilon_{n+1}$, with autoregressive coefficient $\\phi = 1-ah$ and innovation term $\\epsilon_{n+1} = \\sigma \\Delta W_{n}$.\n\nThe increments of a standard Wiener process, $\\Delta W_{n} = W_{(n+1)h} - W_{nh}$, are independent and identically distributed normal random variables with mean $0$ and variance $h$. That is, $\\Delta W_{n} \\sim N(0, h)$. The problem states that the Wiener increments have stationary and independent increments, which is a key property. This implies that the innovation sequence $(\\epsilon_{n})$ is a sequence of independent and identically distributed random variables with mean $\\mathbb{E}[\\epsilon_{n}] = \\mathbb{E}[\\sigma \\Delta W_{n}] = \\sigma \\mathbb{E}[\\Delta W_{n}] = 0$ and variance $\\text{Var}(\\epsilon_{n}) = \\text{Var}(\\sigma \\Delta W_{n}) = \\sigma^2 \\text{Var}(\\Delta W_{n}) = \\sigma^2 h$.\n\nThe problem states that the process $(X_{n})$ is strictly stationary if the magnitude of the autoregressive coefficient is less than one, i.e., $|\\phi|  1$. This condition is $|1-ah|  1$, which expands to $-1  1-ah  1$. Since $a0$ and $h0$, the inequality $1-ah  1$ is always satisfied. The other inequality, $1-ah  -1$, implies $2  ah$, or $h  2/a$. Thus, the EM scheme produces a stationary process for $0  h  2/a$.\n\nAssuming stationarity, the mean $\\mathbb{E}[X_{n}] = \\mu$ and variance $\\text{Var}(X_{n}) = \\gamma_{EM}$ are constant for all $n$. Taking the expectation of the AR(1) equation:\n$$\\mathbb{E}[X_{n+1}] = (1-ah)\\mathbb{E}[X_{n}] + \\mathbb{E}[\\epsilon_{n+1}]$$\n$$\\mu = (1-ah)\\mu + 0 \\implies ah\\mu = 0$$\nSince $a0$ and $h0$, we must have $\\mu=0$. The stationary mean is zero.\n\nTo find the stationary variance, we compute the variance of the AR(1) equation. Since $X_{n}$ is constructed from Wiener increments up to time $t_{n}$, it is independent of the future increment $\\Delta W_{n}$ (and thus of $\\epsilon_{n+1}$).\n$$\\text{Var}(X_{n+1}) = \\text{Var}((1-ah)X_{n} + \\epsilon_{n+1})$$\n$$\\text{Var}(X_{n+1}) = (1-ah)^2 \\text{Var}(X_{n}) + \\text{Var}(\\epsilon_{n+1})$$\nIn the stationary state, $\\text{Var}(X_{n+1}) = \\text{Var}(X_{n}) = \\gamma_{EM}$.\n$$\\gamma_{EM} = (1-ah)^2 \\gamma_{EM} + \\sigma^2 h$$\nRearranging to solve for $\\gamma_{EM}$:\n$$\\gamma_{EM} (1 - (1-ah)^2) = \\sigma^2 h$$\n$$\\gamma_{EM} (1 - (1 - 2ah + a^2 h^2)) = \\sigma^2 h$$\n$$\\gamma_{EM} (2ah - a^2 h^2) = \\sigma^2 h$$\nSince $h0$, we can divide by $h$:\n$$\\gamma_{EM} (2a - a^2 h) = \\sigma^2$$\n$$\\gamma_{EM} = \\frac{\\sigma^2}{2a - a^2h}$$\nThis is the exact stationary variance of the Euler–Maruyama AR(1) scheme.\n\nNext, we derive the stationary variance of the continuous-time OU process. Let $Y_t = X_t^2$. We apply Itô's lemma to the function $f(x) = x^2$. The derivatives are $f'(x) = 2x$ and $f''(x) = 2$.\nThe differential $d(X_t^2)$ is:\n$$d(X_t^2) = \\frac{\\partial f}{\\partial x} dX_t + \\frac{1}{2} \\frac{\\partial^2 f}{\\partial x^2} (dX_t)^2$$\n$$d(X_t^2) = 2X_t dX_t + \\frac{1}{2}(2)(dX_t)^2$$\nSubstituting $dX_t = -a X_t dt + \\sigma dW_t$ and using the rule $(dX_t)^2 = \\sigma^2 dt$:\n$$d(X_t^2) = 2X_t(-aX_t dt + \\sigma dW_t) + \\sigma^2 dt$$\n$$d(X_t^2) = (-2aX_t^2 + \\sigma^2)dt + 2\\sigma X_t dW_t$$\nTaking the expectation of this equation:\n$$\\mathbb{E}[d(X_t^2)] = \\mathbb{E}[(-2aX_t^2 + \\sigma^2)dt] + \\mathbb{E}[2\\sigma X_t dW_t]$$\nThe expectation of the Itô integral term is zero, $\\mathbb{E}[2\\sigma X_t dW_t] = 0$. Using the linearity of expectation and Fubini's theorem:\n$$\\frac{d}{dt}\\mathbb{E}[X_t^2] = -2a\\mathbb{E}[X_t^2] + \\sigma^2$$\nThe OU process admits a unique stationary distribution. In this stationary state, the moments are time-invariant, so $\\frac{d}{dt}\\mathbb{E}[X_t^2] = 0$. Let $\\gamma_{OU} = \\mathbb{E}[X_t^2]$ be the stationary second moment. As the stationary mean is also zero, this is the stationary variance.\n$$0 = -2a\\gamma_{OU} + \\sigma^2$$\nSolving for $\\gamma_{OU}$:\n$$\\gamma_{OU} = \\frac{\\sigma^2}{2a}$$\n\nFinally, we compare the discrete-time variance $\\gamma_{EM}$ with the continuous-time variance $\\gamma_{OU}$ in the limit as the step size $h \\to 0$:\n$$\\lim_{h\\to 0} \\gamma_{EM} = \\lim_{h\\to 0} \\frac{\\sigma^2}{2a - a^2h} = \\frac{\\sigma^2}{2a - 0} = \\frac{\\sigma^2}{2a}$$\nThe limit of the stationary variance of the EM scheme converges to the true stationary variance of the continuous OU process. This demonstrates the consistency of the scheme's stationary distribution moments. For any finite step size $h0$ within the stability region ($h  2/a$), the denominator $2a - a^2h$ is smaller than $2a$, which implies that $\\gamma_{EM}  \\gamma_{OU}$. The numerical scheme systematically overestimates the true variance.\n\nThe role of increment stationarity is fundamental. The property that the Wiener increments $\\Delta W_n$ are stationary (i.e., the distribution of $W_{t+s} - W_t$ depends only on $s$, not on $t$) ensures that the discrete noise terms $\\epsilon_{n+1} = \\sigma \\Delta W_n$ form an independent and identically distributed sequence. This i.i.d. property of the innovations is crucial for the existence of a time-invariant stationary variance $\\gamma_{EM}$ in the resulting AR(1) model. Without stationary increments in the underlying continuous noise process, the discrete noise process would be non-stationary, and the concept of a single stationary variance for the AR(1) model would not apply.", "answer": "$$\n\\boxed{\\frac{\\sigma^2}{2a - a^2h}}\n$$", "id": "3075856"}]}