{"hands_on_practices": [{"introduction": "To truly understand a powerful result like the Optional Stopping Theorem, it's essential to see how it arises from fundamental principles. This first exercise guides you through a direct proof of a core result for a discrete-time martingale transform, using only the definitions of conditional expectation and predictable processes. By manually demonstrating that the expected value of a stopped martingale transform is zero [@problem_id:3065398], you will build a foundational intuition for why the theorem holds and appreciate the interplay between predictability and the martingale property.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{n})_{n\\geq 0},\\mathbb{P})$ be a filtered probability space carrying a simple symmetric random walk $(S_{n})_{n\\geq 0}$ defined by $S_{0}=0$ and $S_{n}=\\sum_{k=1}^{n}X_{k}$, where $(X_{k})_{k\\geq 1}$ are independent and identically distributed random variables with $\\mathbb{P}(X_{k}=1)=\\mathbb{P}(X_{k}=-1)=\\tfrac{1}{2}$ and $X_{k}$ is $\\mathcal{F}_{k}$-measurable for each $k$. Let $(H_{n})_{n\\geq 1}$ be a bounded predictable process with respect to $(\\mathcal{F}_{n})_{n\\geq 0}$, meaning $H_{n}$ is $\\mathcal{F}_{n-1}$-measurable for each $n$ and there exists a finite constant $C>0$ such that $|H_{n}|\\leq C$ almost surely for all $n$. Define the discrete-time stochastic integral (martingale transform) by\n$$(H\\cdot S)_{n}\\;=\\;\\sum_{k=1}^{n}H_{k}\\,(S_{k}-S_{k-1})\\;=\\;\\sum_{k=1}^{n}H_{k}\\,X_{k}.$$\nLet $\\tau$ be a bounded stopping time with respect to $(\\mathcal{F}_{n})_{n\\geq 0}$, that is, there exists a finite deterministic $T\\in\\mathbb{N}$ such that $\\tau\\leq T$ almost surely. For a fixed $n\\in\\mathbb{N}$, compute the quantity $\\mathbb{E}\\big[(H\\cdot S)_{\\tau\\wedge n}\\big]$ using only fundamental properties of conditional expectation and the definitions above, and explain how your computation is consistent with the optional stopping theorem (OST) for martingales under bounded stopping times. Your final answer must be a single closed-form expression.", "solution": "The problem asks for the computation of the quantity $\\mathbb{E}\\big[(H\\cdot S)_{\\tau\\wedge n}\\big]$ for a fixed $n\\in\\mathbb{N}$. We are to use fundamental properties of conditional expectation and relate the result to the optional stopping theorem (OST).\n\nLet us denote the discrete-time stochastic integral, or martingale transform, by $M_n = (H\\cdot S)_n$. The problem defines this as\n$$M_n = \\sum_{k=1}^{n}H_{k}\\,(S_{k}-S_{k-1}) = \\sum_{k=1}^{n}H_{k}\\,X_{k}.$$\nBy definition, the sum is empty for $n=0$, so $M_0 = 0$. We wish to compute $\\mathbb{E}[M_{\\tau \\wedge n}]$.\n\nFirst, we perform the computation directly using fundamental properties. The term $M_{\\tau \\wedge n}$ is the value of the process $M$ at the stopped time $\\tau \\wedge n$. The sum can be written as:\n$$M_{\\tau \\wedge n} = \\sum_{k=1}^{\\tau \\wedge n} H_k X_k.$$\nTo handle the random upper limit of the summation, we can rewrite the sum using indicator functions up to the deterministic time $n$. An equivalent expression for the stopped sum is:\n$$M_{\\tau \\wedge n} = \\sum_{k=1}^{n} H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}}.$$\nTo verify this identity, consider any sample path $\\omega \\in \\Omega$. Let $t = \\tau(\\omega)$.\nCase 1: $t \\ge n$. Then $\\tau(\\omega) \\wedge n = n$. The left side is $\\sum_{k=1}^{n} H_k(\\omega) X_k(\\omega)$. On the right side, for $k \\in \\{1, \\dots, n\\}$, we have $k \\le n \\le t = \\tau(\\omega)$, so $\\mathbb{I}_{\\{k \\le \\tau(\\omega)\\}} = 1$. The right side becomes $\\sum_{k=1}^{n} H_k(\\omega) X_k(\\omega)$, matching the left side.\nCase 2: $t < n$. Then $\\tau(\\omega) \\wedge n = t$. The left side is $\\sum_{k=1}^{t} H_k(\\omega) X_k(\\omega)$. On the right side, for $k \\le t$, $\\mathbb{I}_{\\{k \\le \\tau(\\omega)\\}} = 1$. For $k > t$, $\\mathbb{I}_{\\{k \\le \\tau(\\omega)\\}} = 0$. So the sum on the right side effectively stops at $t$, becoming $\\sum_{k=1}^{t} H_k(\\omega) X_k(\\omega)$, which again matches the left side.\nThe identity is thus established.\n\nNow we can compute the expectation:\n$$\\mathbb{E}[M_{\\tau \\wedge n}] = \\mathbb{E}\\left[\\sum_{k=1}^{n} H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}}\\right].$$\nBy linearity of expectation, which applies since the sum is finite, we can write:\n$$\\mathbb{E}[M_{\\tau \\wedge n}] = \\sum_{k=1}^{n} \\mathbb{E}\\left[H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}}\\right].$$\nWe analyze each term in the summation using the tower property of conditional expectation:\n$$\\mathbb{E}\\left[H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}}\\right] = \\mathbb{E}\\left[\\mathbb{E}\\left[H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}} \\mid \\mathcal{F}_{k-1}\\right]\\right].$$\nThe process $(H_n)_{n \\ge 1}$ is predictable, which means by definition that $H_k$ is $\\mathcal{F}_{k-1}$-measurable for each $k \\ge 1$.\nThe indicator function $\\mathbb{I}_{\\{k \\le \\tau\\}}$ is also $\\mathcal{F}_{k-1}$-measurable. This is because the event $\\{k \\le \\tau\\}$ is the complement of the event $\\{\\tau < k\\}$. The event $\\{\\tau < k\\}$ is equivalent to $\\bigcup_{j=0}^{k-1} \\{\\tau=j\\}$. Since $\\tau$ is a stopping time, the event $\\{\\tau=j\\}$ is in $\\mathcal{F}_j$ for each $j$. As $\\mathcal{F}_j \\subseteq \\mathcal{F}_{k-1}$ for $j < k$, the union $\\bigcup_{j=0}^{k-1} \\{\\tau=j\\}$ is an element of $\\mathcal{F}_{k-1}$. Therefore, $\\{\\tau < k\\} \\in \\mathcal{F}_{k-1}$, and so is its complement $\\{k \\le \\tau\\}$.\n\nSince both $H_k$ and $\\mathbb{I}_{\\{k \\le \\tau\\}}$ are $\\mathcal{F}_{k-1}$-measurable, we can pull them out of the inner conditional expectation:\n$$\\mathbb{E}\\left[\\mathbb{E}\\left[H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}} \\mid \\mathcal{F}_{k-1}\\right]\\right] = \\mathbb{E}\\left[H_k \\mathbb{I}_{\\{k \\le \\tau\\}} \\mathbb{E}\\left[X_k \\mid \\mathcal{F}_{k-1}\\right]\\right].$$\nThe random variables $(X_k)_{k \\ge 1}$ are independent. Thus, $X_k$ is independent of the filtration $\\mathcal{F}_{k-1}$, which is generated by $X_1, \\ldots, X_{k-1}$. This implies that the conditional expectation of $X_k$ given $\\mathcal{F}_{k-1}$ is simply its unconditional expectation:\n$$\\mathbb{E}[X_k \\mid \\mathcal{F}_{k-1}] = \\mathbb{E}[X_k].$$\nThe distribution of $X_k$ is given as $\\mathbb{P}(X_k=1) = \\mathbb{P}(X_k=-1) = \\frac{1}{2}$. Thus, its expectation is:\n$$\\mathbb{E}[X_k] = 1 \\cdot \\mathbb{P}(X_k=1) + (-1) \\cdot \\mathbb{P}(X_k=-1) = 1 \\cdot \\frac{1}{2} - 1 \\cdot \\frac{1}{2} = 0.$$\nSubstituting this back, we get for each term in the sum:\n$$\\mathbb{E}\\left[H_k X_k \\mathbb{I}_{\\{k \\le \\tau\\}}\\right] = \\mathbb{E}\\left[H_k \\mathbb{I}_{\\{k \\le \\tau\\}} \\cdot 0\\right] = \\mathbb{E}[0] = 0.$$\nSince every term in the summation is zero, the total sum is zero:\n$$\\mathbb{E}[M_{\\tau \\wedge n}] = \\sum_{k=1}^{n} 0 = 0.$$\n\nThis result is consistent with the optional stopping theorem. To see this, we first establish that the process $(M_n)_{n \\geq 0}$ is a martingale with respect to the filtration $(\\mathcal{F}_n)_{n \\geq 0}$.\n1.  **Adaptedness**: For each $n$, $M_n = \\sum_{k=1}^{n} H_k X_k$. $H_k$ is $\\mathcal{F}_{k-1}$-measurable and $X_k$ is $\\mathcal{F}_k$-measurable. Thus, their product $H_k X_k$ is $\\mathcal{F}_k$-measurable. Since $\\mathcal{F}_k \\subseteq \\mathcal{F}_n$ for $k \\le n$, each term in the sum is $\\mathcal{F}_n$-measurable, and so is $M_n$.\n2.  **Integrability**: Since $|H_k| \\le C$ and $|X_k|=1$ almost surely, we have $|M_n| = |\\sum_{k=1}^n H_k X_k| \\le \\sum_{k=1}^n |H_k||X_k| \\le \\sum_{k=1}^n C = nC$. Thus, $\\mathbb{E}[|M_n|] \\le nC < \\infty$.\n3.  **Martingale property**: We must show $\\mathbb{E}[M_n \\mid \\mathcal{F}_{n-1}] = M_{n-1}$ for $n \\ge 1$.\n    $$\\mathbb{E}[M_n \\mid \\mathcal{F}_{n-1}] = \\mathbb{E}[M_{n-1} + H_n X_n \\mid \\mathcal{F}_{n-1}].$$\n    By linearity and since $M_{n-1}$ is $\\mathcal{F}_{n-1}$-measurable:\n    $$\\mathbb{E}[M_n \\mid \\mathcal{F}_{n-1}] = M_{n-1} + \\mathbb{E}[H_n X_n \\mid \\mathcal{F}_{n-1}].$$\n    As $H_n$ is $\\mathcal{F}_{n-1}$-measurable and $X_n$ is independent of $\\mathcal{F}_{n-1}$ with $\\mathbb{E}[X_n]=0$:\n    $$\\mathbb{E}[H_n X_n \\mid \\mathcal{F}_{n-1}] = H_n \\mathbb{E}[X_n \\mid \\mathcal{F}_{n-1}] = H_n \\mathbb{E}[X_n] = H_n \\cdot 0 = 0.$$\n    Therefore, $\\mathbb{E}[M_n \\mid \\mathcal{F}_{n-1}] = M_{n-1}$, confirming that $(M_n)_{n \\ge 0}$ is a martingale.\n\nThe optional stopping theorem for bounded stopping times states that if $(M_n)_{n \\ge 0}$ is a martingale and $\\sigma$ is a bounded stopping time, then $\\mathbb{E}[M_\\sigma] = \\mathbb{E}[M_0]$.\nIn our problem, the stopping time is $\\sigma = \\tau \\wedge n$. Since $\\tau$ is a stopping time and $n$ is a constant, $\\sigma$ is also a stopping time. We are given that $\\tau \\le T$ for a deterministic constant $T$, so $\\sigma = \\tau \\wedge n \\le n$. This means $\\sigma$ is a bounded stopping time.\nApplying the OST, we get:\n$$\\mathbb{E}[M_{\\tau \\wedge n}] = \\mathbb{E}[M_0].$$\nThe process starts at $M_0 = (H \\cdot S)_0 = \\sum_{k=1}^0 H_k X_k = 0$.\nSo, the OST gives:\n$$\\mathbb{E}[M_{\\tau \\wedge n}] = 0.$$\nThis confirms that our direct calculation, which also yielded $0$, is consistent with the optional stopping theorem.", "answer": "$$\\boxed{0}$$", "id": "3065398"}, {"introduction": "The Optional Stopping Theorem is a cornerstone of martingale theory, but its power comes with important caveats. Applying it without verifying its conditions can lead to incorrect conclusions, a common pitfall for newcomers. This practice problem uses the familiar setting of a simple random walk to explore the boundaries of the theorem [@problem_id:3065401]. You will analyze why optional stopping works for a certain hitting time but fails for another that, while almost surely finite, has an infinite expectation, providing a crucial lesson in mathematical rigor.", "problem": "Consider a discrete-time Symmetric Simple Random Walk (SSRW) defined by $S_0=0$ and $S_n=\\sum_{k=1}^n X_k$, where $(X_k)_{k\\ge 1}$ are independent and identically distributed random variables with $\\mathbb{P}(X_k=1)=\\mathbb{P}(X_k=-1)=\\tfrac{1}{2}$. Let $(\\mathcal{F}_n)_{n\\ge 0}$ be the natural filtration generated by $(X_k)_{1\\le k\\le n}$. Define the stopping times\n- $T_a=\\inf\\{n\\ge 0:\\lvert S_n\\rvert=a\\}$ for a fixed integer $a\\ge 1$, and\n- $T_1=\\inf\\{n\\ge 1:S_n=1\\}$.\n\nLet the predictable process $(H_k)_{k\\ge 1}$ be given by $H_k=2S_{k-1}$, and consider the martingale transform\n$$M_n=\\sum_{k=1}^n H_k X_k=2\\sum_{k=1}^n S_{k-1}X_k=S_n^2-n.$$\n\nUse the fundamental definitions of martingale and predictable process, and a valid form of the Optional Stopping Theorem (OST) for bounded stopping times, to reason about the expectations $\\mathbb{E}[S_{T_a}]$, $\\mathbb{E}[T_a]$, and what happens when one replaces $T_a$ by the recurrence-based $T_1$. Select all statements that are true.\n\nA. $(S_n)_{n\\ge 0}$ is a martingale, and applying the Optional Stopping Theorem (OST) to $T_a$ yields $\\mathbb{E}[S_{T_a}]=0$.\n\nB. $(M_n)_{n\\ge 0}$ is a martingale transform of $(S_n)_{n\\ge 0}$, and applying OST to $T_a$ gives $\\mathbb{E}[T_a]=a^2$.\n\nC. $T_1$ is almost surely finite; therefore, applying OST to $(S_n)_{n\\ge 0}$ at $T_1$ gives $\\mathbb{E}[S_{T_1}]=0$.\n\nD. $T_1$ is almost surely finite but satisfies $\\mathbb{E}[T_1]=\\infty$, so OST may fail; in fact, $\\mathbb{E}[S_{T_1}]=1\\ne 0$.\n\nE. Applying OST to $(M_n)_{n\\ge 0}$ at $T_1$ yields $\\mathbb{E}[T_1]=1$, since $S_{T_1}^2=1$.", "solution": "The problem statement is analyzed for validity as a mandatory first step.\n\n**Step 1: Extract Givens**\n- **Process**: A discrete-time Symmetric Simple Random Walk (SSRW) is defined by $S_0=0$ and $S_n=\\sum_{k=1}^n X_k$ for $n \\ge 1$.\n- **Increments**: $(X_k)_{k\\ge 1}$ are independent and identically distributed (i.i.d.) random variables with $\\mathbb{P}(X_k=1)=\\mathbb{P}(X_k=-1)=\\tfrac{1}{2}$.\n- **Filtration**: $(\\mathcal{F}_n)_{n\\ge 0}$ is the natural filtration generated by $(X_k)_{1\\le k\\le n}$.\n- **Stopping Times**:\n    - $T_a=\\inf\\{n\\ge 0:\\lvert S_n\\rvert=a\\}$ for a fixed integer $a\\ge 1$.\n    - $T_1=\\inf\\{n\\ge 1:S_n=1\\}$.\n- **Predictable Process**: $(H_k)_{k\\ge 1}$ is given by $H_k=2S_{k-1}$.\n- **Martingale Transform**: $M_n=\\sum_{k=1}^n H_k X_k=2\\sum_{k=1}^n S_{k-1}X_k$.\n- **Identity**: $M_n=S_n^2-n$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined within the standard mathematical framework of stochastic processes. All terms are standard.\n- The processes $(S_n)_{n\\ge0}$ and $(M_n)_{n\\ge0}$ are well-known martingales. For $(S_n)$, we have $\\mathbb{E}[X_k]=0$, so $\\mathbb{E}[S_{n+1}|\\mathcal{F}_n] = S_n + \\mathbb{E}[X_{n+1}|\\mathcal{F}_n] = S_n$. For $(M_n=S_n^2-n)$, $\\mathbb{E}[M_{n+1}|\\mathcal{F}_n] = \\mathbb{E}[S_{n+1}^2-(n+1)|\\mathcal{F}_n] = \\mathbb{E}[(S_n+X_{n+1})^2-n-1|\\mathcal{F}_n] = S_n^2 + 2S_n\\mathbb{E}[X_{n+1}] + \\mathbb{E}[X_{n+1}^2]-n-1 = S_n^2+0+1-n-1=S_n^2-n=M_n$.\n- The stopping times $T_a$ and $T_1$ are standard first passage times.\n- The identity $M_n=S_n^2-n$ is correct, as shown by the martingale calculation above or by direct summation: $S_k^2-S_{k-1}^2 = (S_{k-1}+X_k)^2-S_{k-1}^2=2S_{k-1}X_k+X_k^2=2S_{k-1}X_k+1$. Summing from $k=1$ to $n$ gives $S_n^2-S_0^2 = \\sum_{k=1}^n(2S_{k-1}X_k+1)$, which simplifies to $S_n^2 = 2\\sum_{k=1}^n S_{k-1}X_k + n$, confirming the identity.\n- The problem is scientifically grounded, well-posed, and objective.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The solution proceeds by analyzing each option.\n\n**Analysis of Option A**\nStatement: $(S_n)_{n\\ge 0}$ is a martingale, and applying the Optional Stopping Theorem (OST) to $T_a$ yields $\\mathbb{E}[S_{T_a}]=0$.\n- The process $(S_n)_{n\\ge 0}$ is a martingale with respect to its natural filtration $(\\mathcal{F}_n)_{n\\ge 0}$ because the increments have zero mean: $\\mathbb{E}[S_{n+1}|\\mathcal{F}_n] = \\mathbb{E}[S_n+X_{n+1}|\\mathcal{F}_n] = S_n + \\mathbb{E}[X_{n+1}] = S_n+0 = S_n$.\n- To apply the Optional Stopping Theorem (OST), we must verify its conditions for the stopping time $T_a$. While $T_a$ is not bounded, it is a well-known result for a $1$-dimensional SSRW that the first passage time to any level has a finite expectation. So, $\\mathbb{E}[T_a]<\\infty$.\n- One form of OST states that if $(Y_n)$ is a martingale, $T$ is a stopping time with $\\mathbb{E}[T]<\\infty$, and the increments of the martingale are uniformly bounded (i.e., $|Y_n-Y_{n-1}| \\le C$ for some constant C), then $\\mathbb{E}[Y_T]=\\mathbb{E}[Y_0]$.\n- For our martingale $(S_n)$, the increments are $|S_n-S_{n-1}|=|X_n|=1$, which are uniformly bounded by $C=1$. Since $\\mathbb{E}[T_a]<\\infty$, the conditions of this version of OST are met.\n- Therefore, we can conclude that $\\mathbb{E}[S_{T_a}] = \\mathbb{E}[S_0]$. Since $S_0=0$, we get $\\mathbb{E}[S_{T_a}]=0$.\n- By definition of $T_a$, $S_{T_a}$ can only take values $a$ or $-a$. The result $\\mathbb{E}[S_{T_a}]=0$ implies that $\\mathbb{P}(S_{T_a}=a)=\\mathbb{P}(S_{T_a}=-a)=\\tfrac{1}{2}$, which is expected from the symmetry of the walk.\n- The statement is therefore correct.\n\nVerdict for A: **Correct**.\n\n**Analysis of Option B**\nStatement: $(M_n)_{n\\ge 0}$ is a martingale transform of $(S_n)_{n\\ge 0}$, and applying OST to $T_a$ gives $\\mathbb{E}[T_a]=a^2$.\n- The process $(M_n=S_n^2-n)$ is a martingale, as verified during validation. It is also a martingale transform as stated.\n- To apply OST to $(M_n)$ and $T_a$, we check the conditions. The increments $|M_n-M_{n-1}| = |2S_{n-1}X_n| = 2|S_{n-1}|$ are not uniformly bounded, so the previous version of OST does not apply.\n- A more general approach is required, as hinted by the problem's reference to bounded stopping times. We use OST for the bounded stopping time $T_a \\wedge n = \\min(T_a, n)$ for any $n \\ge 1$. For any bounded stopping time $\\tau$, $\\mathbb{E}[M_{\\tau}]=\\mathbb{E}[M_0]=0$.\n- Applying this, $\\mathbb{E}[M_{T_a \\wedge n}] = 0$. Substituting the definition of $M_n$, we have $\\mathbb{E}[S_{T_a \\wedge n}^2 - (T_a \\wedge n)] = 0$, which implies $\\mathbb{E}[S_{T_a \\wedge n}^2] = \\mathbb{E}[T_a \\wedge n]$.\n- We can now take the limit as $n \\to \\infty$.\n  - For the right-hand side, since $T_a \\wedge n$ is a non-decreasing sequence of non-negative random variables converging to $T_a$, the Monotone Convergence Theorem gives $\\lim_{n\\to\\infty} \\mathbb{E}[T_a \\wedge n] = \\mathbb{E}[\\lim_{n\\to\\infty} (T_a \\wedge n)] = \\mathbb{E}[T_a]$.\n  - For the left-hand side, for any $k \\le T_a$, we have $|S_k|<a$, and at $k=T_a$, $|S_{T_a}|=a$. Thus, for all $n$, $|S_{T_a \\wedge n}| \\le a$. This means that the sequence of random variables $(S_{T_a \\wedge n}^2)_{n\\ge 1}$ is uniformly bounded by $a^2$. Since $T_a$ is almost surely finite for a $1$D SSRW, $S_{T_a \\wedge n} \\to S_{T_a}$ almost surely. By the Bounded Convergence Theorem, we can interchange limit and expectation: $\\lim_{n\\to\\infty} \\mathbb{E}[S_{T_a \\wedge n}^2] = \\mathbb{E}[\\lim_{n\\to\\infty} S_{T_a \\wedge n}^2] = \\mathbb{E}[S_{T_a}^2]$.\n- By definition of $T_a$, $|S_{T_a}|=a$, so $S_{T_a}^2 = a^2$. Thus, $\\mathbb{E}[S_{T_a}^2] = \\mathbb{E}[a^2] = a^2$.\n- Equating the limits of both sides gives $\\mathbb{E}[T_a] = a^2$. This result is known as Wald's second identity. The reasoning is sound.\n- The statement is therefore correct.\n\nVerdict for B: **Correct**.\n\n**Analysis of Option C**\nStatement: $T_1$ is almost surely finite; therefore, applying OST to $(S_n)_{n\\ge 0}$ at $T_1$ gives $\\mathbb{E}[S_{T_1}]=0$.\n- For a $1$D SSRW, it is a classical result that the walk is recurrent, meaning it visits every integer with probability $1$. Thus, $T_1 = \\inf\\{n\\ge 1:S_n=1\\}$ is almost surely finite, i.e., $\\mathbb{P}(T_1<\\infty)=1$. The premise is correct.\n- However, the logical connective \"therefore\" implies that $\\mathbb{P}(T_1<\\infty)=1$ is a sufficient condition to apply OST. This is false.\n- As discussed for option A, sufficient conditions for $\\mathbb{E}[S_T]=\\mathbb{E}[S_0]$ include $T$ being bounded, or $\\mathbb{E}[T]<\\infty$ (given bounded increments), or uniform integrability of the stopped process.\n- For $T_1$, none of these conditions are met. In particular, it is another classical result that for a $1$D SSRW, the expected time to reach any state $k\\neq 0$ is infinite. Thus, $\\mathbb{E}[T_1]=\\infty$.\n- Since the conditions for OST are not met, its conclusion is not guaranteed. In fact, by the very definition of $T_1$, we have $S_{T_1}=1$. Therefore, $\\mathbb{E}[S_{T_1}] = \\mathbb{E}[1]=1$. This contradicts the statement's conclusion that $\\mathbb{E}[S_{T_1}]=0$.\n- The statement contains a fallacious implication and a false conclusion.\n\nVerdict for C: **Incorrect**.\n\n**Analysis of Option D**\nStatement: $T_1$ is almost surely finite but satisfies $\\mathbb{E}[T_1]=\\infty$, so OST may fail; in fact, $\\mathbb{E}[S_{T_1}]=1\\ne 0$.\n- This statement accurately summarizes the situation with the martingale $(S_n)$ and the stopping time $T_1$.\n- As established in the analysis of C, $T_1$ is almost surely finite.\n- As established in the analysis of C, $\\mathbb{E}[T_1]=\\infty$ for a $1$D SSRW.\n- The fact that $\\mathbb{E}[T_1]=\\infty$ violates a key condition for the simplest non-trivial version of OST, so the conclusion of OST is not guaranteed to hold (\"OST may fail\").\n- As a matter of fact, $\\mathbb{E}[S_{T_1}]=1$, since $S_{T_1}=1$ with probability $1$.\n- Since $\\mathbb{E}[S_0]=0$, we have $\\mathbb{E}[S_{T_1}]=1 \\ne 0 = \\mathbb{E}[S_0]$, which explicitly demonstrates that OST does fail in this case.\n- Every part of this statement is correct.\n\nVerdict for D: **Correct**.\n\n**Analysis of Option E**\nStatement: Applying OST to $(M_n)_{n\\ge 0}$ at $T_1$ yields $\\mathbb{E}[T_1]=1$, since $S_{T_1}^2=1$.\n- This statement describes the result of a formal, but invalid, application of OST to the martingale $M_n = S_n^2-n$ with stopping time $T_1$.\n- If OST were applicable, we would have $\\mathbb{E}[M_{T_1}] = \\mathbb{E}[M_0] = 0$.\n- This would mean $\\mathbb{E}[S_{T_1}^2 - T_1] = 0$, or $\\mathbb{E}[S_{T_1}^2] - \\mathbb{E}[T_1] = 0$.\n- Since $S_{T_1}=1$, we have $S_{T_1}^2=1$, and $\\mathbb{E}[S_{T_1}^2]=1$.\n- The equation would become $1 - \\mathbb{E}[T_1] = 0$, yielding the result $\\mathbb{E}[T_1]=1$.\n- However, we know from fundamental theory (and as stated in option D) that $\\mathbb{E}[T_1]=\\infty$.\n- The conclusion $\\mathbb{E}[T_1]=1$ is false. This contradiction proves that the initial assumption—that OST is applicable to $(M_n)$ and $T_1$—must be false.\n- A theorem cannot be \"applied\" if its hypotheses are not satisfied. Stating that an invalid application \"yields\" a certain result is a mathematically incorrect statement.\n\nVerdict for E: **Incorrect**.\n\n**Summary of Conclusions**\n- A: Correct.\n- B: Correct.\n- C: Incorrect.\n- D: Correct.\n- E: Incorrect.\n\nThe correct options are A, B, and D.", "answer": "$$\\boxed{ABD}$$", "id": "3065401"}, {"introduction": "Moving from discrete random walks to continuous-time Brownian motion introduces new subtleties in applying martingale theory. This exercise examines a classic scenario where the Optional Stopping Theorem fails for a standard Brownian motion and an unbounded hitting time, leading to a famous paradox if applied naively [@problem_id:3064202]. By diagnosing the failure through the lens of uniform integrability and exploring the powerful technique of localization, you will learn the standard, rigorous approach for handling such situations in modern stochastic calculus.", "problem": "Let $\\left(B_t\\right)_{t \\ge 0}$ be a standard Brownian motion with $B_0=0$ on a filtered probability space satisfying the usual conditions, and fix a level $a \\in \\mathbb{R} \\setminus \\{0\\}$. Define the hitting time $\\tau_a = \\inf\\{ t \\ge 0 : B_t = a \\}$, which is a stopping time. Consider the question of evaluating $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right]$ by appealing to the Optional Stopping Theorem for martingales.\n\nFrom the foundational definitions, recall that a process $\\left(M_t\\right)_{t \\ge 0}$ is a martingale if $\\mathbb{E}\\!\\left[|M_t|\\right] < \\infty$ for all $t$, $\\mathbb{E}\\!\\left[M_t \\mid \\mathcal{F}_s\\right] = M_s$ for $s \\le t$, and the stopping time version of the Optional Stopping Theorem typically requires additional conditions such as boundedness of the stopping time or uniform integrability of the stopped martingale. It is known that $\\tau_a$ is almost surely finite and has the classical Lévy distribution with density $f_{\\tau_a}(t) = \\dfrac{|a|}{\\sqrt{2\\pi}}\\,t^{-3/2}\\exp\\!\\left(-\\dfrac{a^2}{2t}\\right)$ on $(0,\\infty)$, a well-tested fact in the theory of Brownian motion first-passage times.\n\nWhich option best explains why the Optional Stopping Theorem cannot be directly applied to compute $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right]$ when $\\tau_a$ is unbounded, and proposes a scientifically sound localization-based remedy?\n\nA. Optional stopping in the form $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$ fails because $\\tau_a$ is unbounded and the stopped Brownian motion $\\left(B_{t \\wedge \\tau_a}\\right)_{t \\ge 0}$ is not uniformly integrable. A valid localization remedy is to introduce the bounded stopping times $\\tau_a^{(n)} = \\tau_a \\wedge n$ and apply optional stopping to get $\\mathbb{E}\\!\\left[B_{\\tau_a^{(n)}}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$ for each $n$. One may then only pass to the limit $n \\to \\infty$ if one establishes uniform integrability of $\\left(B_{\\tau_a^{(n)}}\\right)_{n \\ge 1}$ or instead works with a uniformly integrable martingale (for example, the exponential martingale $\\exp\\!\\left(\\lambda B_t - \\tfrac{1}{2}\\lambda^2 t\\right)$) to deduce properties of $\\tau_a$ via bounded localizations.\n\nB. Since $\\tau_a$ is almost surely finite, optional stopping automatically applies and yields $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$. No localization is needed because finiteness of $\\tau_a$ suffices.\n\nC. Optional stopping fails because $\\mathbb{E}\\!\\left[\\tau_a\\right] = \\infty$, but this can be remedied by applying optional stopping to the martingale $M_t = B_t^2 - t$ at $\\tau_a$ to conclude $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$.\n\nD. The failure arises from the unbounded variation of Brownian motion; the remedy is to approximate $B$ by a simple random walk, apply optional stopping in discrete time, and then conclude $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = 0$ by taking limits.\n\nE. Define $\\sigma_n = \\inf\\{ t \\ge 0 : |B_t| \\ge n \\}$ and apply optional stopping to $B$ at the bounded stopping time $\\tau_a \\wedge \\sigma_n$. Then use dominated convergence to pass to the limit $n \\to \\infty$ and conclude $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$.", "solution": "The user wants a critical validation of the problem statement, followed by a detailed solution and evaluation of the options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   $\\left(B_t\\right)_{t \\ge 0}$ is a standard Brownian motion.\n-   $B_0 = 0$.\n-   The process is defined on a filtered probability space satisfying the usual conditions.\n-   $a \\in \\mathbb{R} \\setminus \\{0\\}$ is a fixed level.\n-   $\\tau_a = \\inf\\{ t \\ge 0 : B_t = a \\}$ is the first hitting time of level $a$.\n-   It is stated that $\\tau_a$ is a stopping time.\n-   It is stated that $\\tau_a$ is almost surely finite.\n-   It is stated that the probability density function of $\\tau_a$ is $f_{\\tau_a}(t) = \\dfrac{|a|}{\\sqrt{2\\pi}}\\,t^{-3/2}\\exp\\!\\left(-\\dfrac{a^2}{2t}\\right)$ for $t \\in (0,\\infty)$.\n-   The question is to explain why the Optional Stopping Theorem (OST) cannot be directly applied to compute $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right]$ and to identify a sound localization-based remedy.\n\n**Step 2: Validate Using Extracted Givens**\n1.  **Scientifically Grounded:** The problem is set within the rigorous mathematical framework of stochastic differential equations and martingale theory. All concepts—Brownian motion, stopping times, martingales, the Optional Stopping Theorem, and localization—are standard and well-defined. The provided density for the first passage time is correct. The question addresses a classic and important subtlety in the application of the OST. The problem is scientifically and mathematically sound.\n2.  **Well-Posed:** The problem is clearly stated. It asks for an explanation of a known theoretical difficulty and the corresponding standard resolution. It is structured to have a unique and meaningful answer.\n3.  **Objective:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n4.  **Incomplete or Contradictory Setup:** The problem provides all necessary information. The properties of standard Brownian motion are assumed as standard knowledge in the field. There are no contradictions.\n5.  **Unrealistic or Infeasible:** Not applicable, as this is a theoretical mathematics problem.\n6.  **Ill-Posed or Poorly Structured:** The problem is well-structured and not ill-posed.\n7.  **Pseudo-Profound, Trivial, or Tautological:** The problem is not trivial. Understanding the conditions for the OST and the concept of uniform integrability is a non-trivial aspect of stochastic calculus.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the solution.\n\n### Solution Derivation\n\nThe core issue is the potential application of the Optional Stopping Theorem (OST) to the martingale $M_t = B_t$ and the stopping time $T = \\tau_a$. A naive application of the theorem would suggest $\\mathbb{E}\\!\\left[M_T\\right] = \\mathbb{E}\\!\\left[M_0\\right]$, which translates to $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$.\n\nGiven $B_0=0$, this would imply $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = 0$.\nHowever, by the definition of the stopping time $\\tau_a$ and the continuity of Brownian paths, we have $B_{\\tau_a} = a$ almost surely.\nTherefore, $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}[a] = a$.\nSince the problem specifies $a \\ne 0$, we have a contradiction: $a = 0$. This proves that the Optional Stopping Theorem, in its simple form, cannot be applied to the martingale $B_t$ and the stopping time $\\tau_a$.\n\nWe must now diagnose why the theorem fails. The common sufficient conditions for the OST to hold, i.e., for $\\mathbb{E}[M_T] = \\mathbb{E}[M_0]$, are:\n1.  The stopping time $T$ is bounded.\n2.  $\\mathbb{E}[T] < \\infty$ and the martingale has bounded increments (a condition that needs careful formulation in continuous time but is related to this).\n3.  The stopped process $(M_{t \\wedge T})_{t \\ge 0}$ is uniformly integrable (UI).\n\nLet's check these conditions for $M_t = B_t$ and $T = \\tau_a$:\n1.  Is $\\tau_a$ bounded? No. The provided density function has support on $(0, \\infty)$, so $\\tau_a$ is an unbounded random variable.\n2.  Is $\\mathbb{E}[\\tau_a] < \\infty$? We can compute the expectation from the density:\n    $$ \\mathbb{E}[\\tau_a] = \\int_0^\\infty t f_{\\tau_a}(t) dt = \\frac{|a|}{\\sqrt{2\\pi}} \\int_0^\\infty t \\cdot t^{-3/2} e^{-a^2/(2t)} dt = \\frac{|a|}{\\sqrt{2\\pi}} \\int_0^\\infty t^{-1/2} e^{-a^2/(2t)} dt $$\n    The integrand behaves as $t^{-1/2}$ for large $t$, and the integral $\\int_1^\\infty t^{-1/2} dt$ diverges. Thus, $\\mathbb{E}[\\tau_a] = \\infty$. This condition fails.\n3.  Is the stopped process $(B_{t \\wedge \\tau_a})_{t \\ge 0}$ uniformly integrable? A family of random variables $\\{X_i\\}$ is UI if they are $L^1$-bounded and $\\sup_i \\mathbb{E}[|X_i| \\mathbf{1}_{\\{|X_i|>K\\}}] \\to 0$ as $K \\to \\infty$. The process $(B_{t \\wedge \\tau_a})_{t \\ge 0}$ is a martingale that converges almost surely to $B_{\\tau_a}$ as $t \\to \\infty$. If this martingale were UI, then the convergence would also be in $L^1$, implying $\\mathbb{E}[B_{\\tau_a}] = \\lim_{t\\to\\infty} \\mathbb{E}[B_{t \\wedge \\tau_a}]$. Since $(B_{t \\wedge \\tau_a})$ is a martingale starting at $0$, we have $\\mathbb{E}[B_{t \\wedge \\tau_a}] = \\mathbb{E}[B_0] = 0$ for all $t$. This would lead to $\\mathbb{E}[B_{\\tau_a}] = 0$, which we already know is false. Therefore, the stopped process $(B_{t \\wedge \\tau_a})_{t \\ge 0}$ is **not** uniformly integrable. This is the most direct and crucial reason for the failure of the OST.\n\nA **remedy** for situations where a martingale is not UI is **localization**. A process $M$ is a local martingale if there exists a sequence of stopping times $T_n \\uparrow \\infty$ a.s. (a localizing sequence) such that each stopped process $(M_{t \\wedge T_n})_{t \\ge 0}$ is a UI martingale. Standard Brownian motion is a local martingale.\n\nOne can apply the localization procedure by introducing a sequence of bounded stopping times. A common choice is $\\tau_a^{(n)} = \\tau_a \\wedge n$. For each fixed $n$, $\\tau_a^{(n)}$ is a bounded stopping time (bounded by $n$). Thus, the OST applies to $B_t$ and $\\tau_a^{(n)}$:\n$$ \\mathbb{E}[B_{\\tau_a^{(n)}}] = \\mathbb{E}[B_0] = 0 $$\nThis equation is valid for every $n \\in \\mathbb{N}$. To find anything about $\\tau_a$, we would need to take the limit as $n \\to \\infty$. As $n \\to \\infty$, $\\tau_a^{(n)} \\to \\tau_a$ a.s. and thus $B_{\\tau_a^{(n)}} \\to B_{\\tau_a}$ a.s. by path continuity. To interchange the limit and expectation, i.e., to claim $\\lim_{n\\to\\infty} \\mathbb{E}[B_{\\tau_a^{(n)}}] = \\mathbb{E}[\\lim_{n\\to\\infty} B_{\\tau_a^{(n)}}]$, we need the sequence of random variables $(B_{\\tau_a^{(n)}})_{n \\ge 1}$ to be uniformly integrable.\nBut this interchange leads to $0 = a$, a contradiction. So, the sequence $(B_{\\tau_a^{(n)}})_{n \\ge 1}$ is not UI, and this localization approach, when applied directly to $B_t$, does not yield a useful result but rather confirms the lack of uniform integrability.\n\nA scientifically sound remedy involves applying this localization procedure to a *different* martingale for which the resulting sequence of stopped random variables *is* UI. A canonical example is the exponential martingale $X_t(\\lambda) = \\exp(\\lambda B_t - \\frac{1}{2}\\lambda^2 t)$.\nApplying the OST with the bounded stopping times $\\tau_a^{(n)}$ gives $\\mathbb{E}[X_{\\tau_a^{(n)}}(\\lambda)] = \\mathbb{E}[X_0(\\lambda)] = 1$.\nOne can then show that for certain choices of $\\lambda$ (e.g., $\\lambda > 0$ if $a > 0$), the sequence $(X_{\\tau_a^{(n)}}(\\lambda))_{n \\ge 1}$ is uniformly bounded and therefore UI, which allows passing to the limit. This correctly yields properties of $\\tau_a$, such as its Laplace transform.\n\n### Option-by-Option Analysis\n\n**A. Optional stopping in the form $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$ fails because $\\tau_a$ is unbounded and the stopped Brownian motion $\\left(B_{t \\wedge \\tau_a}\\right)_{t \\ge 0}$ is not uniformly integrable. A valid localization remedy is to introduce the bounded stopping times $\\tau_a^{(n)} = \\tau_a \\wedge n$ and apply optional stopping to get $\\mathbb{E}\\!\\left[B_{\\tau_a^{(n)}}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$ for each $n$. One may then only pass to the limit $n \\to \\infty$ if one establishes uniform integrability of $\\left(B_{\\tau_a^{(n)}}\\right)_{n \\ge 1}$ or instead works with a uniformly integrable martingale (for example, the exponential martingale $\\exp\\!\\left(\\lambda B_t - \\tfrac{1}{2}\\lambda^2 t\\right)$) to deduce properties of $\\tau_a$ via bounded localizations.**\nThis option is entirely correct. It correctly identifies the failure mechanism (non-UI of the stopped process). It correctly describes the localization procedure ($\\tau_a^{(n)} = \\tau_a \\wedge n$). It correctly explains why this procedure fails for $B_t$ itself (the resulting sequence $(B_{\\tau_a^{(n)}})$ is not UI). Finally, it proposes the correct, standard remedy: use the same localization procedure on a different, well-behaved martingale (the exponential martingale) for which the argument goes through.\n**Verdict: Correct.**\n\n**B. Since $\\tau_a$ is almost surely finite, optional stopping automatically applies and yields $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$. No localization is needed because finiteness of $\\tau_a$ suffices.**\nThis is incorrect. As demonstrated, a.s. finiteness of the stopping time is not a sufficient condition for the OST. The contradiction $a=0$ explicitly shows the theorem cannot apply.\n**Verdict: Incorrect.**\n\n**C. Optional stopping fails because $\\mathbb{E}\\!\\left[\\tau_a\\right] = \\infty$, but this can be remedied by applying optional stopping to the martingale $M_t = B_t^2 - t$ at $\\tau_a$ to conclude $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$.**\nThis option contains multiple errors. While $\\mathbb{E}[\\tau_a] = \\infty$ is true and violates one of the common sufficient conditions for the OST, the more direct reason for failure is the lack of UI. The proposed remedy is flawed: applying OST to $M_t = B_t^2 - t$ and $\\tau_a$ is also invalid, as it leads to the false conclusion $\\mathbb{E}[\\tau_a] = a^2$. Furthermore, even if it were valid, it would concern $\\mathbb{E}[\\tau_a]$, not $\\mathbb{E}[B_{\\tau_a}]$. The final conclusion is a non-sequitur.\n**Verdict: Incorrect.**\n\n**D. The failure arises from the unbounded variation of Brownian motion; the remedy is to approximate $B$ by a simple random walk, apply optional stopping in discrete time, and then conclude $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = 0$ by taking limits.**\nThe unbounded variation is a fundamental property of BM, but it is not the proximate reason for the OST failure in this context. The lack of uniform integrability is the correct technical reason. While random walk approximations are a cornerstone of theory (Donsker's theorem), simply taking limits is not justified without uniform integrability conditions, which is the same problem in a different guise. The conclusion $\\mathbb{E}[B_{\\tau_a}] = 0$ is false.\n**Verdict: Incorrect.**\n\n**E. Define $\\sigma_n = \\inf\\{ t \\ge 0 : |B_t| \\ge n \\}$ and apply optional stopping to $B$ at the bounded stopping time $\\tau_a \\wedge \\sigma_n$. Then use dominated convergence to pass to the limit $n \\to \\infty$ and conclude $\\mathbb{E}\\!\\left[B_{\\tau_a}\\right] = \\mathbb{E}\\!\\left[B_0\\right]$.**\nThis option is flawed. First, the stopping time $T_n = \\tau_a \\wedge \\sigma_n$ is not bounded. However, the stopped martingale $B_{t \\wedge T_n}$ is bounded (by $n$, if $n>|a|$), and thus is a UI martingale. So OST does apply to yield $\\mathbb{E}[B_{T_n}] = \\mathbb{E}[B_0] = 0$. The crucial error is the next step: it claims one can use dominated convergence to pass to the limit. As with the localization in option A, the sequence $(B_{T_n})_{n \\ge 1}$ is not UI, so DCT does not apply. The conclusion $\\mathbb{E}[B_{\\tau_a}] = \\mathbb{E}[B_0]$ is false, and this procedure cannot be used to prove it.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3064202"}]}