{"hands_on_practices": [{"introduction": "我们从参数估计的理论基石开始。这个练习将通过一个简单的零级反应模型，从最大似然估计（Maximum Likelihood Estimation, MLE）的第一性原理出发，推导出线性最小二乘法（Linear Least Squares）的解析解。通过完成这个推导，您将深刻理解为何在高斯噪声假设下，最小二乘法是估计模型参数的统计最优方法，从而为更复杂的非线性问题打下坚实的理论基础。", "problem": "考虑一个在等温、恒容条件下进行的批量反应，其中物种 $[A]$ 的浓度遵循零级消耗模型 $[A](t) = [A]_{0} - k t$。您收集了 $n$ 组独立测量值 $\\{(t_{i}, y_{i})\\}_{i=1}^{n}$，其中 $t_{i}$ 表示已知的观测时间，$y_{i}$ 表示观测到的浓度。假设测量误差是独立同分布的，服从均值为 $0$、已知方差为 $\\sigma^{2}$ 的高斯分布，并且设计时间存在非零变异性，即 $\\sum_{i=1}^{n} (t_{i} - \\bar{t})^{2} \\neq 0$，其中 $\\bar{t} = \\frac{1}{n}\\sum_{i=1}^{n} t_{i}$。\n\n从独立高斯误差下的似然定义和模型 $y_{i} = [A]_{0} - k t_{i} + \\varepsilon_{i}$（其中 $\\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma^{2})$）出发，推导 $[A]_{0}$ 和 $k$ 的闭式最大似然估计。您的最终结果必须明确地用和式 $\\sum_{i=1}^{n} y_{i}$、$\\sum_{i=1}^{n} t_{i}$、$\\sum_{i=1}^{n} t_{i}^{2}$、$\\sum_{i=1}^{n} t_{i} y_{i}$ 以及样本量 $n$ 来表示。\n\n您的最终答案必须是一个单一的解析表达式，以行矩阵的形式按 $(\\widehat{[A]}_{0}, \\widehat{k})$ 的顺序列出两个估计值。不需要进行数值计算或四舍五入，最终表达式中不应包含任何单位。", "solution": "在尝试求解之前，我们首先严格审查问题陈述的有效性。\n\n**第一步：提取已知条件**\n- **反应模型：** 零级消耗，$[A](t) = [A]_{0} - k t$。\n- **系统条件：** 等温、恒容的批量反应器。\n- **数据：** $n$ 组独立测量值 $\\{(t_{i}, y_{i})\\}_{i=1}^{n}$。\n- **测量误差：** 误差是独立同分布的(i.i.d.)，服从均值为 $0$、已知方差为 $\\sigma^{2}$ 的高斯分布。\n- **统计模型：** $y_{i} = [A]_{0} - k t_{i} + \\varepsilon_{i}$，其中 $\\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma^{2})$。\n- **约束条件：** 观测时间存在非零变异性，$\\sum_{i=1}^{n} (t_{i} - \\bar{t})^{2} \\neq 0$，其中 $\\bar{t} = \\frac{1}{n}\\sum_{i=1}^{n} t_{i}$。\n- **目标：** 推导参数 $[A]_{0}$ 和 $k$ 的闭式最大似然估计(MLE)。结果需要用和式 $\\sum_{i=1}^{n} y_{i}$、 $\\sum_{i=1}^{n} t_{i}$、 $\\sum_{i=1}^{n} t_{i}^{2}$、 $\\sum_{i=1}^{n} t_{i} y_{i}$ 以及样本量 $n$ 表示。\n\n**第二步：使用提取的已知条件进行验证**\n根据所需标准对问题进行评估。\n- **有科学依据：** 该问题使用标准的零级动力学模型和经典的统计框架（带有高斯误差的线性回归）。这些是物理化学和统计学中的基本概念。该问题是科学合理的。\n- **适定性：** 该问题是适定的。模型对于参数 $[A]_{0}$ 和 $k$ 是线性的。独立同分布高斯误差的假设是标准的。明确的约束条件 $\\sum_{i=1}^{n} (t_{i} - \\bar{t})^{2} \\neq 0$ 确保了设计矩阵是满秩的，从而保证了参数存在唯一解。\n- **目标：** 语言精确、量化，没有任何主观或模糊的术语。\n\n**第三步：结论与行动**\n该问题被判定为 **有效**。这是一个统计参数估计中的标准、定义明确的问题。下面将进行求解。\n\n**最大似然估计的推导**\n\n观测值 $y_i$ 的统计模型由 $y_{i} = [A]_{0} - k t_{i} + \\varepsilon_{i}$ 给出。由于 $\\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma^{2})$，因此观测值 $y_i$ 是一个服从高斯分布的随机变量，其均值为 $\\mu_i = E[y_i] = [A]_{0} - k t_{i}$，方差为 $\\sigma^{2}$。单个观测值 $y_i$ 的概率密度函数 (PDF) 为：\n$$p(y_i \\mid [A]_0, k) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - ([A]_0 - k t_i))^2}{2\\sigma^2}\\right)$$\n由于测量是独立的，整个数据集 $\\{(t_i, y_i)\\}_{i=1}^n$ 的似然函数 $L([A]_0, k)$ 是各个独立概率密度函数的乘积：\n$$L([A]_0, k) = \\prod_{i=1}^{n} p(y_i \\mid [A]_0, k) = \\left(\\frac{1}{2\\pi\\sigma^2}\\right)^{n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - [A]_0 + k t_i)^2\\right)$$\n为了找到最大似然估计值 (MLE)，我们需要最大化 $L$，这等价于最大化其自然对数，即对数似然函数 $\\ln L$：\n$$\\ln L([A]_0, k) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{n} (y_i - [A]_0 + k t_i)^2$$\n相对于 $[A]_0$ 和 $k$ 最大化 $\\ln L([A]_0, k)$ 等价于最小化残差平方和项 $S([A]_0, k)$，因为所有其他项相对于这些参数都是常数：\n$$S([A]_0, k) = \\sum_{i=1}^{n} (y_i - [A]_0 + k t_i)^2$$\n注意，模型 $E[y_i] = [A]_0 - k t_i$ 意味着残差为 $y_i - E[y_i] = y_i - ([A]_0 - k t_i) = y_i - [A]_0 + k t_i$。\n\n为了最小化 $S$，我们分别对 $[A]_0$ 和 $k$ 求偏导数，并令其等于零。得到的估计值将表示为 $\\widehat{[A]}_0$ 和 $\\widehat{k}$。\n\n首先，对 $[A]_0$ 求偏导数：\n$$\\frac{\\partial S}{\\partial [A]_0} = \\sum_{i=1}^{n} 2(y_i - [A]_0 + k t_i)(-1) = -2 \\left( \\sum_{i=1}^{n} y_i - n[A]_0 + k \\sum_{i=1}^{n} t_i \\right)$$\n令该导数为零，得到第一个正规方程：\n$$n \\widehat{[A]}_0 - \\widehat{k} \\sum_{i=1}^{n} t_i = \\sum_{i=1}^{n} y_i \\quad (1)$$\n\n其次，对 $k$ 求偏导数：\n$$\\frac{\\partial S}{\\partial k} = \\sum_{i=1}^{n} 2(y_i - [A]_0 + k t_i)(t_i) = 2 \\left( \\sum_{i=1}^{n} y_i t_i - [A]_0 \\sum_{i=1}^{n} t_i + k \\sum_{i=1}^{n} t_i^2 \\right)$$\n令该导数为零，得到第二个正规方程：\n$$\\widehat{[A]}_0 \\sum_{i=1}^{n} t_i - \\widehat{k} \\sum_{i=1}^{n} t_i^2 = \\sum_{i=1}^{n} y_i t_i \\quad (2)$$\n\n我们现在得到一个关于两个未知数 $\\widehat{[A]}_0$ 和 $\\widehat{k}$ 的二元一次方程组：\n$$\n\\begin{cases}\n    n \\widehat{[A]}_0 - \\left(\\sum_{i=1}^{n} t_i\\right) \\widehat{k} = \\sum_{i=1}^{n} y_i \\\\\n    \\left(\\sum_{i=1}^{n} t_i\\right) \\widehat{[A]}_0 - \\left(\\sum_{i=1}^{n} t_i^2\\right) \\widehat{k} = \\sum_{i=1}^{n} y_i t_i\n\\end{cases}\n$$\n该方程组可以使用多种方法求解，例如代入法或 Cramer's rule。使用 Cramer's rule，系数矩阵的行列式为：\n$$\\Delta = (n)\\left(-\\sum_{i=1}^{n} t_i^2\\right) - \\left(-\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} t_i\\right) = -\\left(n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2\\right)$$\n估计值 $\\widehat{[A]}_0$ 由下式给出：\n$$\\widehat{[A]}_0 = \\frac{\\begin{vmatrix} \\sum_{i=1}^{n} y_i & -\\sum_{i=1}^{n} t_i \\\\ \\sum_{i=1}^{n} y_i t_i & -\\sum_{i=1}^{n} t_i^2 \\end{vmatrix}}{\\Delta} = \\frac{\\left(\\sum_{i=1}^{n} y_i\\right)\\left(-\\sum_{i=1}^{n} t_i^2\\right) - \\left(-\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} y_i t_i\\right)}{-\\left(n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2\\right)}$$\n$$\\widehat{[A]}_0 = \\frac{-\\left(\\sum_{i=1}^{n} y_i\\right)\\left(\\sum_{i=1}^{n} t_i^2\\right) + \\left(\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} y_i t_i\\right)}{-\\left(n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2\\right)} = \\frac{\\left(\\sum_{i=1}^{n} y_i\\right)\\left(\\sum_{i=1}^{n} t_i^2\\right) - \\left(\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} y_i t_i\\right)}{n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2}$$\n估计值 $\\widehat{k}$ 由下式给出：\n$$\\widehat{k} = \\frac{\\begin{vmatrix} n & \\sum_{i=1}^{n} y_i \\\\ \\sum_{i=1}^{n} t_i & \\sum_{i=1}^{n} y_i t_i \\end{vmatrix}}{\\Delta} = \\frac{n\\left(\\sum_{i=1}^{n} y_i t_i\\right) - \\left(\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} y_i\\right)}{-\\left(n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2\\right)}$$\n$$\\widehat{k} = \\frac{\\left(\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} y_i\\right) - n \\sum_{i=1}^{n} y_i t_i}{n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2}$$\n这些就是 $[A]_0$ 和 $k$ 的最大似然估计的闭式解。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\left(\\sum_{i=1}^{n} y_i\\right)\\left(\\sum_{i=1}^{n} t_i^2\\right) - \\left(\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} t_i y_i\\right)}{n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2} & \\frac{\\left(\\sum_{i=1}^{n} t_i\\right)\\left(\\sum_{i=1}^{n} y_i\\right) - n \\sum_{i=1}^{n} t_i y_i}{n \\sum_{i=1}^{n} t_i^2 - \\left(\\sum_{i=1}^{n} t_i\\right)^2}\n\\end{pmatrix}\n}\n$$", "id": "2660590"}, {"introduction": "在掌握了线性模型的理论后，我们将转向更真实、更普遍的场景：非线性模型的参数估计。大多数化学动力学模型，如一级反应，本质上都是非线性的，需要通过数值优化方法求解。这个实践练习要求您编写代码，对一级衰减反应的模拟数据进行加权非线性最小二乘拟合，不仅要估算出速率常数 $k$ 和初始浓度 $[A]_0$，还要计算它们的不确定性与协方差，这是评估参数可靠性的关键一步。", "problem": "给定一个单步、不可逆、一级衰变反应的动态模型，其中物种 $A$ 的浓度遵循常微分方程 $d[A]/dt = -k[A]$，初始条件为 $[A](0) = [A]_0$。浓度的测量在离散时间点进行，并受到独立加性噪声的干扰。目标是在高斯噪声模型下，使用加权最小二乘法（WLS）将积分速率方程与数据进行拟合，以估计参数矢量 $\\boldsymbol{\\theta} = ([A]_0, k)$，并计算该估计量的近似协方差矩阵。\n\n基本依据与假设：\n- 确定性动力学由一级过程的质量作用定律支配。测量模型为 $y_i = [A](t_i) + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma_i^2)$ 且对于不同的 $i$ 相互独立。\n- 自变量是时间 $t$，单位为秒；可观测浓度 $[A]$ 的单位为摩尔/升。\n- 在所述假设下，最大似然估计量与WLS估计量一致，其中权重为 $w_i = 1/\\sigma_i^2$。\n\n你的程序必须为每个测试用例执行以下任务：\n1. 从基本速率方程和初始条件出发，推导出 $[A](t)$ 作为 $[A]_0$ 和 $k$ 的函数表达式。\n2. 构建由已知方差 $\\sigma_i^2$ 的高斯噪声模型所蕴含的 WLS 目标函数。通过最小化此目标函数（约束条件为 $[A]_0 > 0$ 和 $k > 0$）来估计 $\\boldsymbol{\\theta} = ([A]_0, k)$。\n3. 使用与 WLS 公式一致的一阶（Gauss–Newton）近似，在最优点计算近似协方差矩阵 $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$。报告 $\\mathrm{Var}([A]_0)$、$\\mathrm{Var}(k)$ 和 $\\mathrm{Cov}([A]_0,k)$ 这些项。\n4. 实现一个数值稳定的求解器，该求解器强制 $[A]_0$ 和 $k$ 为正，并在形成近似时使用模型相对于参数的解析正确的灵敏度（雅可比矩阵）。\n5. 使用下述精确测试套件，包括指定的伪随机种子来生成合成观测值 $y_i$，并使用给定的已知标准差 $\\sigma_i$ 来定义 WLS 权重。\n\n使用的物理和数值单位：\n- 报告 $[A]_0$ 的单位为 $\\mathrm{mol\\,L^{-1}}$，$k$ 的单位为 $\\mathrm{s^{-1}}$。方差和协方差必须使用相应的平方单位和混合单位。\n- 最终程序输出必须是不带单位符号的数值；但是，所有计算都必须以所述单位进行。\n\n测试套件（三个数据集）。对每个数据集 $j \\in \\{1,2,3\\}$：\n- 使用 $y_i^{(j)} = [A]_0^{\\mathrm{true}(j)} \\exp(-k^{\\mathrm{true}(j)} t_i^{(j)}) + \\varepsilon_i^{(j)}$ 生成合成观测值，其中 $\\varepsilon_i^{(j)} \\sim \\mathcal{N}(0, (\\sigma_i^{(j)})^2)$ 且相互独立。对每个数据集使用指定的种子初始化伪随机数生成器，以使生成的 $y_i^{(j)}$ 是确定性和可复现的。\n\n数据集 1 （理想情况，同方差）：\n- 真实参数：$[A]_0^{\\mathrm{true}(1)} = 1.25\\,\\mathrm{mol\\,L^{-1}}$，$k^{\\mathrm{true}(1)} = 0.0075\\,\\mathrm{s^{-1}}$。\n- 时间点（单位：秒）：$t^{(1)} = (0, 50, 100, 150, 200, 250, 300)$。\n- 已知标准差（单位：$\\mathrm{mol\\,L^{-1}}$）：对于所有 $i$，$\\sigma_i^{(1)} \\equiv 0.02$。\n- 种子：$314159$。\n\n数据集 2 （异方差噪声随时间增加）：\n- 真实参数：$[A]_0^{\\mathrm{true}(2)} = 0.8\\,\\mathrm{mol\\,L^{-1}}$，$k^{\\mathrm{true}(2)} = 0.01\\,\\mathrm{s^{-1}}$。\n- 时间点（单位：秒）：$t^{(2)} = (0, 40, 80, 120, 160, 200, 240, 280, 320)$。\n- 已知标准差（单位：$\\mathrm{mol\\,L^{-1}}$）：$\\sigma_i^{(2)} = 0.01 + 0.00005\\, t_i^{(2)}$。\n- 种子：$271828$。\n\n数据集 3 （边界情况，在短时间窗口内关于 $k$ 的信息较弱）：\n- 真实参数：$[A]_0^{\\mathrm{true}(3)} = 1.0\\,\\mathrm{mol\\,L^{-1}}$，$k^{\\mathrm{true}(3)} = 0.001\\,\\mathrm{s^{-1}}$。\n- 时间点（单位：秒）：$t^{(3)} = (0, 5, 10, 15, 20, 25, 30)$。\n- 已知标准差（单位：$\\mathrm{mol\\,L^{-1}}$）：对于所有 $i$，$\\sigma_i^{(3)} \\equiv 0.005$。\n- 种子：$161803$。\n\n算法要求：\n- 使用带有 WLS 残差的非线性最小二乘求解器。向求解器提供模型关于 $[A]_0$ 和 $k$ 的解析雅可比矩阵。强制执行边界条件 $[A]_0 > 0$ 和 $k > 0$。\n- 使用与 WLS 权重和已知 $\\sigma_i$ 的高斯假设相符的一阶信息近似，在最优点计算近似协方差矩阵。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含三个数据集拼接起来的结果，严格按照\n$[\\hat{[A]}_0^{(1)}$, $\\hat{k}^{(1)}$, $\\mathrm{Var}^{(1)}([A]_0)$, $\\mathrm{Var}^{(1)}(k)$, $\\mathrm{Cov}^{(1)}([A]_0,k)$, $\\hat{[A]}_0^{(2)}$, $\\hat{k}^{(2)}$, $\\mathrm{Var}^{(2)}([A]_0)$, $\\mathrm{Var}^{(2)}(k)$, $\\mathrm{Cov}^{(2)}([A]_0,k)$, $\\hat{[A]}_0^{(3)}$, $\\hat{k}^{(3)}$, $\\mathrm{Var}^{(3)}([A]_0)$, $\\mathrm{Var}^{(3)}(k)$, $\\mathrm{Cov}^{(3)}([A]_0,k)]$ 的顺序，不含空格。\n- 每个数值必须四舍五入到小数点后恰好 6 位。\n- 不涉及角度。所有量均为实值浮点数。\n\n你的程序必须是完整且可直接运行的，无需任何外部输入，并且必须严格遵守指定的输出格式。唯一允许使用的库是 Python 标准库、NumPy 和 SciPy。", "solution": "所提出的问题是化学动力学中动态系统参数估计的一个标准练习。该问题具有科学依据、是良构的，并且包含了获得确定性且可验证解所需的所有信息。因此，该问题被认为是有效的。\n\n解决方案按以下四个主要步骤进行：\n1.  从控制微分方程推导解析模型。\n2.  构建用于参数估计的加权最小二乘法（WLS）目标函数。\n3.  为优化算法推导解析雅可比矩阵。\n4.  构建参数协方差矩阵的近似公式。\n\n**1. 积分速率方程**\n\n问题从一级不可逆衰变过程的基本速率方程开始：\n$$\n\\frac{d[A]}{dt} = -k[A]\n$$\n这是一个一阶线性常微分方程。我们使用分离变量法，在初始条件 $[A](t=0) = [A]_0$ 下求解它。\n$$\n\\frac{d[A]}{[A]} = -k \\, dt\n$$\n将两边从初始状态 $([A]_0, 0)$ 积分到状态 $([A], t)$，得到：\n$$\n\\int_{[A]_0}^{[A]} \\frac{1}{[A]'} \\, d[A]' = \\int_0^t -k \\, dt'\n$$\n$$\n\\ln([A]) - \\ln([A]_0) = -k(t - 0)\n$$\n$$\n\\ln\\left(\\frac{[A]}{[A]_0}\\right) = -kt\n$$\n对两边取指数，即可得到积分速率方程，这就是我们用于描述物种 $A$ 在时间 $t$ 浓度的模型函数：\n$$\n[A](t) = [A]_0 e^{-kt}\n$$\n该函数我们记为 $f(t; \\boldsymbol{\\theta})$，它依赖于参数矢量 $\\boldsymbol{\\theta} = ([A]_0, k)^T$。\n\n**2. 加权最小二乘（WLS）公式构建**\n\n在时间 $t_i$ 的测量值 $y_i$ 被建模为 $y_i = f(t_i; \\boldsymbol{\\theta}) + \\varepsilon_i$，其中误差 $\\varepsilon_i$ 是独立且服从正态分布的，即 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_i^2)$，其方差 $\\sigma_i^2$ 已知。在这些假设下，$\\boldsymbol{\\theta}$ 的最大似然估计量就是使加权残差平方和最小化的估计量。这即是加权最小二乘（WLS）估计量。\n\nWLS 目标函数 $S(\\boldsymbol{\\theta})$ 由下式给出：\n$$\nS(\\boldsymbol{\\theta}) = \\sum_{i=1}^{N} \\left( \\frac{y_i - f(t_i; \\boldsymbol{\\theta})}{\\sigma_i} \\right)^2 = \\sum_{i=1}^{N} \\left( \\frac{y_i - [A]_0 e^{-kt_i}}{\\sigma_i} \\right)^2\n$$\n其中 $N$ 是观测点的数量。我们寻求能最小化此函数的参数值 $\\hat{\\boldsymbol{\\theta}} = (\\hat{[A]}_0, \\hat{k})^T$，并满足物理约束条件 $[A]_0 > 0$ 和 $k > 0$。\n\n**3. 非线性优化与解析雅可比矩阵**\n\n最小化 $S(\\boldsymbol{\\theta})$ 是一个非线性最小二乘问题。我们采用一个数值求解器，具体是 `scipy.optimize.least_squares`，它非常适合这项任务。通过提供残差矢量关于参数的解析雅可比矩阵，可以极大地提升求解器的效率和可靠性。\n\n该求解器最小化一个矢量函数的平方和。设此矢量函数为 $\\mathbf{r}_w(\\boldsymbol{\\theta})$，即加权残差矢量，其第 $i$ 个分量为：\n$$\nr_{w,i}(\\boldsymbol{\\theta}) = \\frac{f(t_i; \\boldsymbol{\\theta}) - y_i}{\\sigma_i} = \\frac{[A]_0 e^{-kt_i} - y_i}{\\sigma_i}\n$$\n雅可比矩阵 $J_w$ 是一个 $N \\times 2$ 的矩阵，其中 $(J_w)_{ij} = \\frac{\\partial r_{w,i}}{\\partial \\theta_j}$。其两列分别对应于关于 $[A]_0$ 和 $k$ 的偏导数。\n\n对于第一个参数 $[A]_0$：\n$$\n\\frac{\\partial r_{w,i}}{\\partial [A]_0} = \\frac{1}{\\sigma_i} \\frac{\\partial}{\\partial [A]_0} \\left( [A]_0 e^{-kt_i} - y_i \\right) = \\frac{e^{-kt_i}}{\\sigma_i}\n$$\n对于第二个参数 $k$：\n$$\n\\frac{\\partial r_{w,i}}{\\partial k} = \\frac{1}{\\sigma_i} \\frac{\\partial}{\\partial k} \\left( [A]_0 e^{-kt_i} - y_i \\right) = \\frac{[A]_0}{\\sigma_i} \\frac{\\partial}{\\partial k} \\left( e^{-kt_i} \\right) = \\frac{[A]_0}{\\sigma_i} \\left( -t_i e^{-kt_i} \\right) = -\\frac{[A]_0 t_i e^{-kt_i}}{\\sigma_i}\n$$\n这些偏导数的表达式构成了提供给优化程序的雅可比矩阵的各列。\n\n**4. 估计量的协方差矩阵**\n\n估计参数 $\\hat{\\boldsymbol{\\theta}}$ 的不确定性由其协方差矩阵 $\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}})$ 来表征。对于非线性最小二乘问题，一个常用且有效的近似源自 Gauss-Newton 方法。该近似将协方差矩阵与费雪信息矩阵的逆联系起来，而费雪信息矩阵本身则通过在解 $\\hat{\\boldsymbol{\\theta}}$ 处求值的 $J_w^T J_w$ 来近似。\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) \\approx \\left( J_w(\\hat{\\boldsymbol{\\theta}})^T J_w(\\hat{\\boldsymbol{\\theta}}) \\right)^{-1}\n$$\n这个 $2 \\times 2$ 矩阵的对角线元素是估计量的方差，非对角线元素是它们之间的协方差：\n$$\n\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = \\begin{pmatrix} \\mathrm{Var}(\\hat{[A]}_0) & \\mathrm{Cov}(\\hat{[A]}_0, \\hat{k}) \\\\ \\mathrm{Cov}(\\hat{[A]}_0, \\hat{k}) & \\mathrm{Var}(\\hat{k}) \\end{pmatrix}\n$$\n`scipy.optimize.least_squares` 函数会方便地返回在最终参数估计值处计算的雅可比矩阵 $J_w$，从而可以直接计算该协方差矩阵。\n\n实现将精确遵循这些推导。对于每个数据集，使用提供的真实参数和带种子的随机数生成器来生成合成数据，以确保可复现性。然后执行 WLS 优化以找到 $\\hat{[A]}_0$ 和 $\\hat{k}$，接着计算所需的方差和协方差项。", "answer": "```python\n# Final runnable Python code for the specified environment.\nimport numpy as np\nfrom scipy.optimize import least_squares\n\ndef solve():\n    \"\"\"\n    Solves for the parameters of a first-order decay model for three\n    different datasets using Weighted Least Squares and computes the\n    covariance matrix of the estimators.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Dataset 1\",\n            \"true_params\": [1.25, 0.0075], # [A0_true, k_true]\n            \"times\": np.array([0., 50., 100., 150., 200., 250., 300.]),\n            \"sigma\": lambda t: np.full_like(t, 0.02),\n            \"seed\": 314159\n        },\n        {\n            \"name\": \"Dataset 2\",\n            \"true_params\": [0.8, 0.01],\n            \"times\": np.array([0., 40., 80., 120., 160., 200., 240., 280., 320.]),\n            \"sigma\": lambda t: 0.01 + 0.00005 * t,\n            \"seed\": 271828\n        },\n        {\n            \"name\": \"Dataset 3\",\n            \"true_params\": [1.0, 0.001],\n            \"times\": np.array([0., 5., 10., 15., 20., 25., 30.]),\n            \"sigma\": lambda t: np.full_like(t, 0.005),\n            \"seed\": 161803\n        }\n    ]\n\n    # --- Model and Objective Function Definitions ---\n\n    def model(params, t_vals):\n        \"\"\"\n        Calculates concentration based on first-order decay model.\n        params: [A0, k]\n        \"\"\"\n        A0, k = params\n        return A0 * np.exp(-k * t_vals)\n\n    def residuals_wls(params, t_vals, y_obs, sigma_vals):\n        \"\"\"\n        Calculates weighted residuals for WLS fitting.\n        (model - y) / sigma\n        \"\"\"\n        return (model(params, t_vals) - y_obs) / sigma_vals\n\n    def jacobian_wls(params, t_vals, y_obs, sigma_vals):\n        \"\"\"\n        Calculates the analytical Jacobian of the weighted residuals.\n        \"\"\"\n        A0, k = params\n        jac = np.zeros((len(t_vals), 2))\n        exp_term = np.exp(-k * t_vals)\n        \n        # d(residual)/d(A0) = (1/sigma) * d(model)/d(A0)\n        jac[:, 0] = exp_term / sigma_vals\n        \n        # d(residual)/d(k) = (1/sigma) * d(model)/d(k)\n        jac[:, 1] = -A0 * t_vals * exp_term / sigma_vals\n        \n        return jac\n\n    all_results = []\n    \n    for case in test_cases:\n        A0_true, k_true = case[\"true_params\"]\n        t = case[\"times\"]\n        seed = case[\"seed\"]\n        sigma = case[\"sigma\"](t)\n        \n        # 1. Generate synthetic data\n        rng = np.random.default_rng(seed)\n        noise = rng.normal(0, sigma)\n        y_obs = model([A0_true, k_true], t) + noise\n        \n        # 2. Perform nonlinear least-squares optimization\n        # Use true parameters as initial guess for robust convergence in this test setup\n        initial_guess = case[\"true_params\"]\n        # Enforce positivity constraints [A0 > 0, k > 0]\n        bounds = ([1e-9, 1e-9], [np.inf, np.inf])\n        \n        lsq_result = least_squares(\n            residuals_wls,\n            x0=initial_guess,\n            jac=jacobian_wls,\n            bounds=bounds,\n            method='trf',\n            args=(t, y_obs, sigma)\n        )\n        \n        A0_est, k_est = lsq_result.x\n        \n        # 3. Compute the approximate covariance matrix\n        # Cov(theta) approx (J^T J)^-1, where J is Jacobian of weighted residuals\n        J = lsq_result.jac\n        try:\n            cov_matrix = np.linalg.inv(J.T @ J)\n            var_A0 = cov_matrix[0, 0]\n            var_k = cov_matrix[1, 1]\n            cov_A0_k = cov_matrix[0, 1]\n        except np.linalg.LinAlgError:\n            # Handle cases where the matrix is singular (e.g., poor data)\n            var_A0, var_k, cov_A0_k = (np.inf, np.inf, np.inf)\n\n        # 4. Store the results in the required order\n        all_results.extend([A0_est, k_est, var_A0, var_k, cov_A0_k])\n\n    # 5. Format and print the final output string\n    # E.g. [1.249123,0.007505,...]\n    output_str = \",\".join([f\"{val:.6f}\" for val in all_results])\n    print(f\"[{output_str}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2660532"}, {"introduction": "为了获得最精确、最可靠的动力学参数，我们应充分利用所有可用的实验信息。这个高级实践将向您展示“全局分析”（Global Analysis）的强大威力。在一个简单的 $A \\to B$ 反应中，您将不再孤立地分析物种 $[A]$ 或 $[B]$ 的浓度数据，而是将它们进行联合拟合。通过在拟合过程中强制执行质量守恒等物理约束，并共享同一个速率常数 $k$，您将亲身体会到这种整体性方法如何显著提高参数估计的精度和稳健性。", "problem": "考虑一个由质量作用动力学控制的不可逆单分子反应，其中物种 $A$ 以一级速率常数 $k$ 转化为物种 $B$：\n$$ A \\xrightarrow{k} B $$\n令 $[A](t)$ 和 $[B](t)$ 分别表示在时间 $t$ 时 $A$ 和 $B$ 的浓度。在充分混合和恒定体积的条件下，其控制性常微分方程（ODE）为\n$$ \\frac{d[A]}{dt} = -k [A], \\quad \\frac{d[B]}{dt} = k [A], $$\n以及守恒定律（质量平衡）\n$$ [A](t) + [B](t) = M, $$\n其中 $M$ 是一个常数，等于 $[A](0) + [B](0)$。\n\n您将通过在指定时间点评估由常微分方程所蕴含的精确轨迹，然后添加具有指定标准差的独立高斯测量噪声，来生成 $[A](t)$ 和 $[B](t)$ 的合成测量数据。然后，您将通过三种方式估算动力学参数 $k$：\n- 仅对 $[A](t)$ 进行单独拟合：通过最小化测量的 $[A](t_i)$ 与相应模型预测值之间的加权残差平方和，来估算 $k_A$。将 $[A](0)$ 视为一个待估算的未知参数。对所有浓度参数和 $k_A$ 强制施加非负约束。\n- 仅对 $[B](t)$ 进行单独拟合：通过最小化测量的 $[B](t_i)$ 与相应模型预测值之间的加权残差平方和，来估算 $k_B$。将 $[B](0)$、$[A](0)$ 和 $k_B$ 视为待估算的未知参数。对所有浓度参数和 $k_B$ 强制施加非负约束。\n- 对 $[A](t)$ 和 $[B](t)$ 进行联合拟合，强制使用共同的速率常数和质量平衡：通过同时最小化两个序列的总加权残差平方和，来估算一个单一的 $k_{\\mathrm{joint}}$。使用一个与常微分方程一致并在所有时间 $t$ 上都满足守恒定律的模型，其未知参数为 $[A](0)$、$[B](0)$ 和 $k_{\\mathrm{joint}}$。对所有浓度参数和 $k_{\\mathrm{joint}}$ 强制施加非负约束。\n\n在所有三个估算任务中，假定测量误差是独立的、服从高斯分布的，且其已知标准差分别为 $[A](t)$ 的 $\\sigma_A$ 和 $[B](t)$ 的 $\\sigma_B$。使用的权重等于方差的倒数，即在平方和求和之前，将残差除以相应的标准差。使用具有指定种子的确定性伪随机数生成，以确保可复现性。\n\n单位和报告要求：\n- 时间 $t$ 必须以秒为单位。\n- 浓度 $[A]$ 和 $[B]$ 必须以摩尔/升为单位。\n- 速率常数 $k_A$、$k_B$ 和 $k_{\\mathrm{joint}}$ 必须以逆秒（即 $\\mathrm{s}^{-1}$）为单位报告。\n- 所有报告的速率常数以 $\\mathrm{s}^{-1}$ 为单位，表示为十进制浮点数，四舍五入到小数点后恰好六位。\n\n测试套件规范。对于下方的每个测试案例，生成时间网格，计算与常微分方程和守恒定律一致的无噪声轨迹，添加具有给定标准差和种子的的高斯噪声，然后执行上述三种估算程序。使用以下测试案例：\n\n- 案例1（通用，良态）：\n  - 真实参数：$k_{\\text{true}} = 0.35 \\ \\mathrm{s}^{-1}$，$[A](0) = 1.1 \\ \\mathrm{mol \\cdot L^{-1}}$，$[B](0) = 0.3 \\ \\mathrm{mol \\cdot L^{-1}}$。\n  - 时间网格：从 $t=0$ 到 $t_\\max = 8.0 \\ \\mathrm{s}$（含）的 $N = 41$ 个等距点。\n  - 噪声水平：$\\sigma_A = 0.01 \\ \\mathrm{mol \\cdot L^{-1}}$，$\\sigma_B = 0.01 \\ \\mathrm{mol \\cdot L^{-1}}$。\n  - 随机种子：$13579$。\n\n- 案例2（慢动力学，长观测窗口）：\n  - 真实参数：$k_{\\text{true}} = 0.02 \\ \\mathrm{s}^{-1}$，$[A](0) = 2.0 \\ \\mathrm{mol \\cdot L^{-1}}$，$[B](0) = 0.4 \\ \\mathrm{mol \\cdot L^{-1}}$。\n  - 时间网格：从 $t=0$ 到 $t_\\max = 200.0 \\ \\mathrm{s}$（含）的 $N = 51$ 个等距点。\n  - 噪声水平：$\\sigma_A = 0.01 \\ \\mathrm{mol \\cdot L^{-1}}$，$\\sigma_B = 0.015 \\ \\mathrm{mol \\cdot L^{-1}}$。\n  - 随机种子：$24680$。\n\n- 案例3（稀疏采样，快动力学）：\n  - 真实参数：$k_{\\text{true}} = 1.5 \\ \\mathrm{s}^{-1}$，$[A](0) = 0.5 \\ \\mathrm{mol \\cdot L^{-1}}$，$[B](0) = 0.0 \\ \\mathrm{mol \\cdot L^{-1}}$。\n  - 时间网格：明确指定为 $t \\in \\{0.0, 0.2, 0.5, 1.0, 1.5\\} \\ \\mathrm{s}$。\n  - 噪声水平：$\\sigma_A = 0.02 \\ \\mathrm{mol \\cdot L^{-1}}$，$\\sigma_B = 0.02 \\ \\mathrm{mol \\cdot L^{-1}}$。\n  - 随机种子：$97531$。\n\n您的程序必须对每个案例执行以下步骤：\n- 使用真实参数，根据常微分方程和守恒定律生成 $[A](t)$ 和 $[B](t)$ 轨迹。\n- 添加具有指定标准差和种子的独立高斯噪声，以获得带噪声的测量数据。\n- 拟合单独的 $[A](t)$ 模型以估算 $k_A$；拟合单独的 $[B](t)$ 模型以估算 $k_B$；拟合强制使用共同速率常数和质量平衡的联合模型以估算 $k_{\\mathrm{joint}}$。\n- 将三个估算出的速率常数四舍五入到小数点后恰好六位，以 $\\mathrm{s}^{-1}$ 为单位表示。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个以逗号分隔的列表的列表形式的结果，每个内部列表对应一个测试案例，并按上述案例顺序排列。每个内部列表必须包含该案例的三个四舍五入后的浮点数 $[k_A, k_B, k_{\\mathrm{joint}}]$，单位为 $\\mathrm{s}^{-1}$。例如，含一个案例的输出将类似于 $[[0.123456,0.123457,0.123450]]$。对于本问题中的三个案例，要求的输出必须具有 $[[k_{A,1},k_{B,1},k_{\\mathrm{joint},1}],[k_{A,2},k_{B,2},k_{\\mathrm{joint},2}],[k_{A,3},k_{B,3},k_{\\mathrm{joint},3}]]$ 的形式，该行中任何地方都不能有空格。", "solution": "所述问题在逻辑上是一致的，科学上是合理的，并为获得唯一且可验证的解提供了所有必要信息。这是一个化学动力学中标准的、适定的问题，具体来说是根据时间序列数据进行参数估计。因此，我们将着手提供一个完整的解。\n\n问题的核心是使用三种不同的统计模型从合成数据中估计一个动力学参数，并对结果进行比较。该反应是物种 $A$ 到物种 $B$ 的单分子、不可逆转化，表示为 $A \\xrightarrow{k} B$。\n\n首先，我们建立物种浓度的解析模型。$A$ 的消失速率由一级速率定律给出：\n$$ \\frac{d[A]}{dt} = -k [A] $$\n这是一个线性一阶常微分方程。在初始条件 $[A](t=0) = [A]_0$ 下，对该方程积分，得到 $A$ 浓度的指数衰减函数：\n$$ [A](t) = [A]_0 e^{-kt} $$\n物种 $A$ 和 $B$ 的总浓度是守恒的。质量平衡方程为：\n$$ [A](t) + [B](t) = M = \\text{constant} $$\n常数 $M$ 是总初始浓度， $M = [A]_0 + [B]_0$。利用这个守恒定律，我们推导出物种 $B$ 浓度随时间变化的函数：\n$$ [B](t) = M - [A](t) = ([A]_0 + [B]_0) - [A]_0 e^{-kt} $$\n这可以重新整理成一个更常见的形式：\n$$ [B](t) = [B]_0 + [A]_0 (1 - e^{-kt}) $$\n这两个方程，分别用于 $[A](t)$ 和 $[B](t)$，构成了我们模型的确定性部分。它们将用于生成合成数据和拟合参数。\n\n合成数据生成分两步进行。首先，对于每个测试案例，使用提供的真实参数（$k_{\\text{true}}$、$[A]_{0, \\text{true}}$、$[B]_{0, \\text{true}}$）在一组离散时间点 $\\{t_i\\}$ 上计算“真实”的无噪声轨迹 $[A]_{\\text{true}}(t_i)$ 和 $[B]_{\\text{true}}(t_i)$。其次，将独立的、零均值的高斯测量噪声添加到这些真实浓度中：\n$$ [A]_{\\text{meas}}(t_i) = [A]_{\\text{true}}(t_i) + \\epsilon_{A,i}, \\quad \\text{其中} \\quad \\epsilon_{A,i} \\sim \\mathcal{N}(0, \\sigma_A^2) $$\n$$ [B]_{\\text{meas}}(t_i) = [B]_{\\text{true}}(t_i) + \\epsilon_{B,i}, \\quad \\text{其中} \\quad \\epsilon_{B,i} \\sim \\mathcal{N}(0, \\sigma_B^2) $$\n噪声的标准差 $\\sigma_A$ 和 $\\sigma_B$ 在每个案例中都已指定。为确保可复现性，每个案例都使用特定的种子初始化一个伪随机数生成器。\n\n参数估计通过最小化加权残差平方和（WSSR）来进行，该方法也称为卡方（$\\chi^2$）目标函数。给定一组测量数据点 $(t_i, y_i)$、它们的不确定度 $\\sigma_i$ 以及一个依赖于参数 $\\boldsymbol{\\theta}$ 的模型函数 $y_{\\text{model}}(t; \\boldsymbol{\\theta})$，目标是找到使 $\\chi^2$ 最小化的参数 $\\boldsymbol{\\theta}^*$：\n$$ \\boldsymbol{\\theta}^* = \\arg\\min_{\\boldsymbol{\\theta}} \\chi^2(\\boldsymbol{\\theta}) = \\arg\\min_{\\boldsymbol{\\theta}} \\sum_{i} \\left( \\frac{y_i - y_{\\text{model}}(t_i; \\boldsymbol{\\theta})}{\\sigma_i} \\right)^2 $$\n这个最小化过程将使用 `scipy.optimize.minimize` 函数进行数值计算，并设置边界以强制所有参数（浓度和速率常数）满足物理上的非负约束。\n\n我们将这个框架应用于三种不同的估计情景：\n\n1.  **仅对 $[A](t)$ 进行单独拟合**：\n    模型是 $[A]_{\\text{model}}(t) = [A]_0 e^{-k_A t}$。未知参数的向量是 $\\boldsymbol{\\theta}_A = ([A]_0, k_A)$。要最小化的目标函数是：\n    $$ \\chi^2_A([A]_0, k_A) = \\sum_{i} \\left( \\frac{[A]_{\\text{meas}}(t_i) - [A]_0 e^{-k_A t_i}}{\\sigma_A} \\right)^2 $$\n    参数 $[A]_0$ 和 $k_A$ 在约束条件 $[A]_0 \\ge 0$ 和 $k_A \\ge 0$ 下进行估计。得到的速率常数估计值记为 $k_A$。\n\n2.  **仅对 $[B](t)$ 进行单独拟合**：\n    模型是 $[B]_{\\text{model}}(t) = [B]_0 + [A]_0(1 - e^{-k_B t})$。这里，未知参数的向量是 $\\boldsymbol{\\theta}_B = ([B]_0, [A]_0, k_B)$。目标函数是：\n    $$ \\chi^2_B([B]_0, [A]_0, k_B) = \\sum_{i} \\left( \\frac{[B]_{\\text{meas}}(t_i) - \\left( [B]_0 + [A]_0(1 - e^{-k_B t_i}) \\right)}{\\sigma_B} \\right)^2 $$\n    所有三个参数都是从 $[B]$ 的单一时间序列中估计出来的，并受约束条件 $[B]_0 \\ge 0$、$[A]_0 \\ge 0$ 和 $k_B \\ge 0$ 的限制。速率常数的估计值是 $k_B$。\n\n3.  **对 $[A](t)$ 和 $[B](t)$ 进行联合拟合**：\n    这种方法同时使用所有可用信息，并在两个数据集中一致地执行物理模型。未知参数的向量是 $\\boldsymbol{\\theta}_{\\text{joint}} = ([A]_0, [B]_0, k_{\\text{joint}})$。$[A](t)$ 和 $[B](t)$ 的模型通过这些共享参数耦合在一起：\n    $$ [A]_{\\text{model}}(t) = [A]_0 e^{-k_{\\text{joint}} t} $$\n    $$ [B]_{\\text{model}}(t) = [B]_0 + [A]_0(1 - e^{-k_{\\text{joint}} t}) $$\n    目标函数是每个序列的 $\\chi^2$ 值的总和：\n    $$ \\chi^2_{\\text{joint}}(\\boldsymbol{\\theta}_{\\text{joint}}) = \\sum_{i} \\left( \\frac{[A]_{\\text{meas}}(t_i) - [A]_0 e^{-k_{\\text{joint}} t_i}}{\\sigma_A} \\right)^2 + \\sum_{i} \\left( \\frac{[B]_{\\text{meas}}(t_i) - \\left( [B]_0 + [A]_0(1 - e^{-k_{\\text{joint}} t_i}) \\right)}{\\sigma_B} \\right)^2 $$\n    参数在约束条件 $[A]_0 \\ge 0$、$[B]_0 \\ge 0$ 和 $k_{\\text{joint}} \\ge 0$ 下进行估计。得到的估计值是 $k_{\\text{joint}}$。由于这种联合拟合整合了所有数据并强制执行了所有已知的物理约束，预期它将产生统计上最稳健的估计。\n\n对于每个测试案例，我们将执行这三个拟合程序，提取估计出的速率常数 $k_A$、$k_B$ 和 $k_{\\text{joint}}$，并在四舍五入到指定精度后报告它们。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases for parameter estimation.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general, well-conditioned)\n        {\n            \"k_true\": 0.35, \"A0_true\": 1.1, \"B0_true\": 0.3,\n            \"t_grid\": np.linspace(0, 8.0, 41),\n            \"sigma_A\": 0.01, \"sigma_B\": 0.01,\n            \"seed\": 13579\n        },\n        # Case 2 (slow kinetics, long observation window)\n        {\n            \"k_true\": 0.02, \"A0_true\": 2.0, \"B0_true\": 0.4,\n            \"t_grid\": np.linspace(0, 200.0, 51),\n            \"sigma_A\": 0.01, \"sigma_B\": 0.015,\n            \"seed\": 24680\n        },\n        # Case 3 (sparse sampling, fast kinetics)\n        {\n            \"k_true\": 1.5, \"A0_true\": 0.5, \"B0_true\": 0.0,\n            \"t_grid\": np.array([0.0, 0.2, 0.5, 1.0, 1.5]),\n            \"sigma_A\": 0.02, \"sigma_B\": 0.02,\n            \"seed\": 97531\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # Step 1: Generate synthetic data\n        k_true, A0_true, B0_true = case[\"k_true\"], case[\"A0_true\"], case[\"B0_true\"]\n        t = case[\"t_grid\"]\n        sigma_A, sigma_B = case[\"sigma_A\"], case[\"sigma_B\"]\n        seed = case[\"seed\"]\n\n        A_true = A0_true * np.exp(-k_true * t)\n        B_true = B0_true + A0_true * (1 - np.exp(-k_true * t))\n        \n        rng = np.random.default_rng(seed)\n        noise_A = rng.normal(0, sigma_A, size=t.shape)\n        noise_B = rng.normal(0, sigma_B, size=t.shape)\n        \n        A_meas = A_true + noise_A\n        B_meas = B_true + noise_B\n\n        # --- Fitting Procedure A ---\n        def model_A(params, t):\n            A0, k = params\n            return A0 * np.exp(-k * t)\n\n        def objective_A(params, t, A_meas, sigma_A):\n            residuals = (A_meas - model_A(params, t)) / sigma_A\n            return np.sum(residuals**2)\n\n        # Initial guesses and bounds\n        A0_guess_A = A_meas[0] if A_meas[0] > 1e-6 else 1e-6\n        k_guess_A = 0.1 \n        initial_guess_A = [A0_guess_A, k_guess_A]\n        bounds_A = [(0, None), (0, None)]\n\n        res_A = minimize(objective_A, initial_guess_A, args=(t, A_meas, sigma_A),\n                         method='L-BFGS-B', bounds=bounds_A)\n        k_A = res_A.x[1]\n\n        # --- Fitting Procedure B ---\n        def model_B(params, t):\n            B0, A0, k = params\n            return B0 + A0 * (1 - np.exp(-k * t))\n\n        def objective_B(params, t, B_meas, sigma_B):\n            residuals = (B_meas - model_B(params, t)) / sigma_B\n            return np.sum(residuals**2)\n\n        # Initial guesses and bounds\n        B0_guess_B = B_meas[0] if B_meas[0] > 1e-6 else 1e-6\n        A0_guess_B = (B_meas[-1] - B_meas[0]) if (B_meas[-1] - B_meas[0]) > 1e-6 else 1e-6\n        k_guess_B = 0.1\n        initial_guess_B = [B0_guess_B, A0_guess_B, k_guess_B]\n        bounds_B = [(0, None), (0, None), (0, None)]\n        \n        res_B = minimize(objective_B, initial_guess_B, args=(t, B_meas, sigma_B),\n                         method='L-BFGS-B', bounds=bounds_B)\n        k_B = res_B.x[2]\n\n        # --- Fitting Procedure Joint ---\n        def model_joint_A(params, t):\n            A0, _, k = params # A0, B0, k\n            return A0 * np.exp(-k * t)\n\n        def model_joint_B(params, t):\n            A0, B0, k = params\n            return B0 + A0 * (1 - np.exp(-k * t))\n\n        def objective_joint(params, t, A_meas, B_meas, sigma_A, sigma_B):\n            res_A = (A_meas - model_joint_A(params, t)) / sigma_A\n            res_B = (B_meas - model_joint_B(params, t)) / sigma_B\n            return np.sum(res_A**2) + np.sum(res_B**2)\n\n        # Initial guesses and bounds\n        A0_guess_joint = A_meas[0] if A_meas[0] > 1e-6 else 1e-6\n        B0_guess_joint = B_meas[0] if B_meas[0] > 1e-6 else 1e-6\n        k_guess_joint = 0.1\n        initial_guess_joint = [A0_guess_joint, B0_guess_joint, k_guess_joint]\n        bounds_joint = [(0, None), (0, None), (0, None)]\n\n        res_joint = minimize(objective_joint, initial_guess_joint, \n                             args=(t, A_meas, B_meas, sigma_A, sigma_B),\n                             method='L-BFGS-B', bounds=bounds_joint)\n        k_joint = res_joint.x[2]\n\n        # Format and store results\n        k_A_rounded = round(k_A, 6)\n        k_B_rounded = round(k_B, 6)\n        k_joint_rounded = round(k_joint, 6)\n        \n        all_results.append([k_A_rounded, k_B_rounded, k_joint_rounded])\n\n    # Final print statement in the exact required format.\n    # Convert each inner list to a string without spaces, then join them\n    inner_lists_str = [f\"[{','.join(f'{x:.6f}' for x in res)}]\" for res in all_results]\n    print(f\"[{','.join(inner_lists_str)}]\")\n\nsolve()\n```", "id": "2660601"}]}