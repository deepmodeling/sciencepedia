{"hands_on_practices": [{"introduction": "本练习将理论与实践相结合，引导你通过分析浓度随时间变化的实验数据来确定反应级数。你将学习如何通过积分速率方程的线性化形式，将一级和二级反应动力学数据转换为线性图，并应用线性回归进行分析。此过程不仅可以估算速率常数，更重要的是，它引入了赤池信息量准则 (Akaike Information Criterion, $AIC$) 这一强大的统计工具，使你能够客观地在不同动力学模型之间做出选择 [@problem_id:2665160]。", "problem": "考虑物种 A 在一个封闭、充分搅拌、恒温且体积不变的系统中的不可逆衰变。模拟浓度 $[\\mathrm{A}]$ 随时间演变的基本依据是确定性速率定律的定义，即速率 $-\\dfrac{d[\\mathrm{A}]}{dt}$ 等于一个速率常数与一个浓度依赖项的乘积，该浓度依赖项的幂次（反应级数）必须由数据推断。假设为一级定律，其中 $-\\dfrac{d[\\mathrm{A}]}{dt}$ 与 $[\\mathrm{A}]$ 成正比；或为二级定律，其中 $-\\dfrac{d[\\mathrm{A}]}{dt}$ 与 $[\\mathrm{A}]^2$ 成正比。严格地从此基础出发，推导适当的积分关系式，以允许使用 $[\\mathrm{A}]$ 和 $t$ 的变换进行线性回归，并论证对这些线性化变量使用普通最小二乘法的合理性。\n\n您的任务是编写一个程序，对每个提供的数据集，在一个模型比较框架内，并且仅使用您推导出的线性化积分形式，执行以下步骤：\n\n- 构建两个线性回归：一个适用于一级反应假设，另一个适用于二级反应假设。\n- 对每个线性拟合，计算残差向量、残差平方和 $RSS$ 以及决定系数（决定系数记为 $R^2$）。\n- 在线性化变量上，根据一个高斯、独立、同分布的误差模型，计算赤池信息准则（Akaike Information Criterion (AIC)），其中参数个数 $p$ 等于 $2$（斜率和截距）：$AIC = n \\ln(RSS/n) + 2p$，其中 $n$ 是数据点数，$RSS$ 是线性化变量的残差平方和。\n- 根据最低的 $AIC$ 选择反应级数。如果两个模型间的 $AIC$ 绝对差值小于 $10^{-8}$，则通过选择具有更高 $R^2$ 的模型来打破平局。如果仍然平局，则选择一级反应。\n- 从选定的模型中，从回归斜率提取速率常数 $k$，并使用您推导中隐含的适当公式计算半衰期。在需要时，使用在 $t=0$ 时的首次浓度测量值作为初始浓度 $[\\mathrm{A}]_0$。所有时间输入单位为秒，所有浓度输入单位为 $\\mathrm{mol \\ L^{-1}}$，您必须以秒为单位报告半衰期。$k$ 的单位必须与所选级数一致：一级反应为 $\\mathrm{s}^{-1}$，二级反应为 $\\mathrm{L \\ mol^{-1} \\ s^{-1}}$。\n- 对于包含两个不同温度 $T$ 下实验的数据集，首先在每个温度下分别执行上述模型选择和参数估计。然后，使用两个估计的速率常数 $k(T_1)$ 和 $k(T_2)$ 以及温度 $T_1$ 和 $T_2$（单位为开尔文），计算由您从第一性原理推导的阿伦尼乌斯关系所隐含的活化能 $E_\\mathrm{a}$。以 $\\mathrm{J \\ mol^{-1}}$ 为单位报告 $E_\\mathrm{a}$。\n\n重要的数学和实现要求：\n\n- 所有回归、残差和信息准则的计算都必须在从您的积分形式得出的线性化变量空间中进行，而不是在原始变量中进行非线性回归。\n- 程序必须将所有报告的浮点输出四舍五入到六位有效数字。\n- 在任何温度依赖性计算中使用的气体常数为 $R = 8.314462618 \\ \\mathrm{J \\ mol^{-1} \\ K^{-1}}$。\n\n测试套件（每个数据集由时间 $t$（秒）和浓度 $[\\mathrm{A}]$（$\\mathrm{mol \\ L^{-1}}$）组成；以下所有数字均为精确值，必须按原样使用）：\n\n- 数据集 1（单温度实验）： \n  - $t = [0, 5, 10, 15, 20, 25, 30]$\n  - $[\\mathrm{A}] = [0.820, 0.401, 0.189, 0.095, 0.045, 0.021, 0.011]$\n- 数据集 2（单温度实验）：\n  - $t = [0, 20, 40, 60, 80, 100, 120]$\n  - $[\\mathrm{A}] = [0.500, 0.386, 0.310, 0.266, 0.226, 0.200, 0.179]$\n- 数据集 3（单温度实验；短时间、低曲率边缘情况）：\n  - $t = [0, 30, 60, 90, 120]$\n  - $[\\mathrm{A}] = [1.200, 0.889, 0.661, 0.491, 0.362]$\n- 数据集 4（用于阿伦尼乌斯分析的配对温度实验；两个独立实验）：\n  - 实验 $4\\mathrm{a}$，温度 $T_1 = 295 \\ \\mathrm{K}$：\n    - $t = [0, 300, 600, 900, 1200]$\n    - $[\\mathrm{A}] = [1.000, 0.497, 0.240, 0.121, 0.058]$\n  - 实验 $4\\mathrm{b}$，温度 $T_2 = 325 \\ \\mathrm{K}$：\n    - $t = [0, 60, 120, 180, 240]$\n    - $[\\mathrm{A}] = [1.000, 0.262, 0.069, 0.017, 0.005]$\n\n最终输出格式：\n\n- 对于数据集 1-3，输出一个列表，其中包含按此确切顺序排列的以下七个条目：\n  - 所选级数，为整数（$1$ 或 $2$），\n  - 估计的 $k$（浮点数，四舍五入到六位有效数字），\n  - 估计的半衰期（秒）（浮点数，四舍五入到六位有效数字），\n  - 一级线性化拟合的 $R^2$（浮点数，四舍五入到六位有效数字），\n  - 二级线性化拟合的 $R^2$（浮点数，四舍五入到六位有效数字），\n  - 一级线性化拟合的 $AIC$（浮点数，四舍五入到六位有效数字），\n  - 二级线性化拟合的 $AIC$（浮点数，四舍五入到六位有效数字）。\n- 对于数据集 4，输出一个列表，其中包含按此确切顺序排列的以下十五个条目：\n  - 在 $T_1$ 下所选级数，为整数，\n  - 估计的 $k(T_1)$（浮点数），\n  - 在 $T_1$ 下的估计半衰期（秒）（浮点数），\n  - 在 $T_1$ 下一级线性化拟合的 $R^2$（浮点数），\n  - 在 $T_1$ 下二级线性化拟合的 $R^2$（浮点数），\n  - 在 $T_1$ 下一级线性化拟合的 $AIC$（浮点数），\n  - 在 $T_1$ 下二级线性化拟合的 $AIC$（浮点数），\n  - 在 $T_2$ 下所选级数，为整数，\n  - 估计的 $k(T_2)$（浮点数），\n  - 在 $T_2$ 下的估计半衰期（秒）（浮点数），\n  - 在 $T_2$ 下一级线性化拟合的 $R^2$（浮点数），\n  - 在 $T_2$ 下二级线性化拟合的 $R^2$（浮点数），\n  - 在 $T_2$ 下一级线性化拟合的 $AIC$（浮点数），\n  - 在 $T_2$ 下二级线性化拟合的 $AIC$（浮点数），\n  - 估计的活化能 $E_\\mathrm{a}$，单位为 $\\mathrm{J \\ mol^{-1}}$（浮点数）。\n- 您的程序应生成单行输出，其中包含所有四个数据集的结果，格式为由逗号分隔的各数据集列表，并用一对单独的方括号括起来，不含多余的空格或文本，例如：$[[\\cdots],[\\cdots],[\\cdots],[\\cdots]]$，但没有空格。\n\n所有数值输出必须四舍五入到六位有效数字。所有时间的单位为秒，所有浓度的单位为 $\\mathrm{mol \\ L^{-1}}$，$k$ 的单位必须根据情况为一级反应的 $\\mathrm{s}^{-1}$ 或二级反应的 $\\mathrm{L \\ mol^{-1} \\ s^{-1}}$，而 $E_\\mathrm{a}$ 的单位必须为 $\\mathrm{J \\ mol^{-1}}$。", "solution": "所提出的问题是化学动力学中一个表述清晰且具有科学依据的练习，要求从实验数据中确定反应级数及相关参数。该问题内部一致，提供了所有必要信息，并遵循物理化学的基本原理。因此，该问题被认为是有效的，并将提供完整的解决方案。\n\n此问题的核心在于一级和二级反应的积分速率定律的推导和应用。我们的任务是使用基于线性回归的统计框架，对多个数据集比较这两种模型。\n\n### 积分速率定律和线性形式的推导\n\n我们从物种 $\\mathrm{A}$ 不可逆衰变的基本确定性速率定律开始：\n$$-\\frac{d[\\mathrm{A}]}{dt} = k [\\mathrm{A}]^n$$\n其中 $[\\mathrm{A}]$ 是物种 $\\mathrm{A}$ 的浓度，$t$ 是时间，$k$ 是速率常数，$n$ 是反应级数。我们将考虑 $n=1$ 和 $n=2$ 的情况。\n\n#### 一级动力学（$n=1$）\n一级反应的微分速率定律为：\n$$-\\frac{d[\\mathrm{A}]}{dt} = k_1 [\\mathrm{A}]$$\n为了求出积分速率定律，我们分离变量，并从初始条件 $(t=0, [\\mathrm{A}]=[\\mathrm{A}]_0)$ 到后来的状态 $(t, [\\mathrm{A}])$进行积分：\n$$\\int_{[\\mathrm{A}]_0}^{[\\mathrm{A}]} \\frac{d[\\mathrm{A}]'}{[\\mathrm{A}]'} = -\\int_0^t k_1 dt'$$\n求解积分得到：\n$$\\ln[\\mathrm{A}] - \\ln[\\mathrm{A}]_0 = -k_1 t$$\n该方程可以重排为线性形式 $y = mx + c$：\n$$\\ln[\\mathrm{A}] = -k_1 t + \\ln[\\mathrm{A}]_0$$\n这里，因变量是 $y = \\ln[\\mathrm{A}]$，自变量是 $x = t$，斜率是 $m = -k_1$，截距是 $c = \\ln[\\mathrm{A}]_0$。对于一级反应，$\\ln[\\mathrm{A}]$ 对 $t$ 的图将是一条直线，速率常数 $k_1$ 可由斜率的负值确定。\n\n半衰期 $t_{1/2}$ 是 $[\\mathrm{A}] = \\frac{1}{2}[\\mathrm{A}]_0$ 时的时间。将此代入积分速率定律：\n$$\\ln\\left(\\frac{1}{2}[\\mathrm{A}]_0\\right) - \\ln[\\mathrm{A}]_0 = -k_1 t_{1/2}$$\n$$\\ln\\left(\\frac{1}{2}\\right) = -k_1 t_{1/2}$$\n$$-\\ln(2) = -k_1 t_{1/2}$$\n$$t_{1/2} = \\frac{\\ln(2)}{k_1}$$\n一级反应的半衰期与初始浓度无关。\n\n#### 二级动力学（$n=2$）\n二级反应的微分速率定律为：\n$$-\\frac{d[\\mathrm{A}]}{dt} = k_2 [\\mathrm{A}]^2$$\n分离变量并积分得到：\n$$\\int_{[\\mathrm{A}]_0}^{[\\mathrm{A}]} \\frac{d[\\mathrm{A}]'}{[\\mathrm{A}]'^2} = -\\int_0^t k_2 dt'$$\n$$\\left[ -\\frac{1}{[\\mathrm{A}]'} \\right]_{[\\mathrm{A}]_0}^{[\\mathrm{A}]} = -k_2 [t']_0^t$$\n$$-\\frac{1}{[\\mathrm{A}]} - \\left(-\\frac{1}{[\\mathrm{A}]_0}\\right) = -k_2 t$$\n$$\\frac{1}{[\\mathrm{A}]} - \\frac{1}{[\\mathrm{A}]_0} = k_2 t$$\n重排为线性形式 $y = mx + c$：\n$$\\frac{1}{[\\mathrm{A}]} = k_2 t + \\frac{1}{[\\mathrm{A}]_0}$$\n这里，因变量是 $y = 1/[\\mathrm{A}]$，自变量是 $x = t$，斜率是 $m = k_2$，截距是 $c = 1/[\\mathrm{A}]_0$。对于二级反应，$1/[\\mathrm{A}]$ 对 $t$ 的图将是线性的，速率常数 $k_2$ 等于斜率。\n\n半衰期 $t_{1/2}$ 可通过设置 $[\\mathrm{A}] = \\frac{1}{2}[\\mathrm{A}]_0$ 求得：\n$$\\frac{1}{\\frac{1}{2}[\\mathrm{A}]_0} - \\frac{1}{[\\mathrm{A}]_0} = k_2 t_{1/2}$$\n$$\\frac{2}{[\\mathrm{A}]_0} - \\frac{1}{[\\mathrm{A}]_0} = k_2 t_{1/2}$$\n$$t_{1/2} = \\frac{1}{k_2 [\\mathrm{A}]_0}$$\n二级反应的半衰期依赖于初始浓度。\n\n### 普通最小二乘法（OLS）的合理性论证\n在线性回归模型满足高斯-马尔可夫假设时，普通最小二乘法回归为模型参数（斜率和截距）提供最佳线性无偏估计。这些假设要求因变量中的误差（残差）是不相关的，均值为零，并具有恒定方差（同方差性）。问题陈述明确要求在线性化变量上假设一个“高斯、独立、同分布的误差模型”。这一前提直接满足了对变换后变量（$y = \\ln[\\mathrm{A}]$ 或 $y = 1/[\\mathrm{A}]$）应用 OLS 的有效性条件。因此，对这些线性化形式使用 OLS 的合理性是由问题本身的约束所保证的。\n\n### 模型选择与阿伦尼乌斯关系\n\n#### 模型选择框架\n对于每个数据集，我们将执行两次线性回归：一次用于一级反应假设（$\\ln[\\mathrm{A}]$ 对 $t$），一次用于二级反应假设（$1/[\\mathrm{A}]$ 对 $t$）。对于每次拟合，我们计算决定系数 $R^2$ 和残差平方和 $RSS = \\sum(y_i - \\hat{y}_i)^2$，其中 $y_i$ 是观测到的变换后浓度，$\\hat{y}_i$ 是线性拟合预测的值。\n\n模型选择基于赤池信息准则（AIC），该准则在模型拟合度（$RSS$）和模型复杂性之间取得平衡。对于一个拟合了 $n$ 个数据点且有 $p$ 个参数的模型，AIC 由下式给出：\n$$AIC = n \\ln\\left(\\frac{RSS}{n}\\right) + 2p$$\n在我们的情况中，两个线性模型都有 $p=2$ 个参数（斜率和截距）。AIC 值较低的模型更优。对于 $AIC$ 绝对差值可忽略不计（$ 10^{-8}$）的情况，指定了基于 $R^2$ 的平局打破规则。\n\n#### 用于计算活化能的阿伦尼乌斯方程\n速率常数 $k$ 的温度依赖性由阿伦尼乌斯方程描述：\n$$k(T) = A e^{-E_a / (RT)}$$\n其中 $E_a$ 是活化能，$R$ 是通用气体常数，$T$ 是绝对温度，$A$ 是指前因子。\n为了从在两个不同温度 $T_1$ 和 $T_2$ 下测得的速率常数 $k_1$ 和 $k_2$ 确定 $E_a$，我们对每个温度的方程取自然对数：\n$$\\ln(k_1) = \\ln(A) - \\frac{E_a}{RT_1}$$\n$$\\ln(k_2) = \\ln(A) - \\frac{E_a}{RT_2}$$\n将第二个方程减去第一个方程以消除 $\\ln(A)$：\n$$\\ln(k_2) - \\ln(k_1) = \\left( -\\frac{E_a}{RT_2} \\right) - \\left( -\\frac{E_a}{RT_1} \\right)$$\n$$\\ln\\left(\\frac{k_2}{k_1}\\right) = \\frac{E_a}{R} \\left( \\frac{1}{T_1} - \\frac{1}{T_2} \\right)$$\n求解活化能 $E_a$ 得到两点形式：\n$$E_a = R \\frac{\\ln(k_2/k_1)}{\\frac{1}{T_1} - \\frac{1}{T_2}}$$\n该公式将用于数据集 4 实验中估计的速率常数。此计算的有效性依赖于一个假设，即在两个温度下反应级数相同，因此 $k$ 的单位也相同。对于在适度温度范围内的基元反应来说，这是一个合理的预期。\n\n下面的程序实现了这一完整的方法论。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import linregress\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the chemical kinetics problem by performing model selection and parameter estimation.\n    \"\"\"\n\n    # Define a helper function for rounding to six significant figures.\n    sf_round = lambda num: float(f\"{num:.5e}\") if num != 0 else 0.0\n\n    def analyze_dataset(t_data, conc_data):\n        \"\"\"\n        Analyzes a single concentration vs. time dataset to determine reaction order and parameters.\n        \"\"\"\n        t = np.array(t_data)\n        conc_A = np.array(conc_data)\n        n = len(t)\n        p = 2  # Number of parameters (slope, intercept)\n        conc_A0 = conc_A[0]\n\n        # --- First-Order Analysis ---\n        y1 = np.log(conc_A)\n        slope1, intercept1, r_val1, _, _ = linregress(t, y1)\n        \n        k1 = -slope1\n        r2_1 = r_val1**2\n        \n        y1_pred = slope1 * t + intercept1\n        rss1 = np.sum((y1 - y1_pred)**2)\n        # Avoid math.log(0) if the fit is perfect (rss1=0)\n        aic1 = n * math.log(rss1 / n) + 2 * p if rss1 > 0 else -np.inf\n        \n        t_half_1 = math.log(2) / k1 if k1 > 0 else float('inf')\n\n        # --- Second-Order Analysis ---\n        y2 = 1.0 / conc_A\n        slope2, intercept2, r_val2, _, _ = linregress(t, y2)\n        \n        k2 = slope2\n        r2_2 = r_val2**2\n        \n        y2_pred = slope2 * t + intercept2\n        rss2 = np.sum((y2 - y2_pred)**2)\n        aic2 = n * math.log(rss2 / n) + 2 * p if rss2 > 0 else -np.inf\n\n        t_half_2 = 1.0 / (k2 * conc_A0) if k2 > 0 else float('inf')\n\n        # --- Model Selection ---\n        selected_order = 0\n        k = 0.0\n        t_half = 0.0\n\n        if abs(aic1 - aic2)  1e-8:\n            if r2_1 >= r2_2:  # Tie-break with R^2, and if still tied, pick order 1\n                selected_order = 1\n                k = k1\n                t_half = t_half_1\n            else:\n                selected_order = 2\n                k = k2\n                t_half = t_half_2\n        elif aic1  aic2:\n            selected_order = 1\n            k = k1\n            t_half = t_half_1\n        else:\n            selected_order = 2\n            k = k2\n            t_half = t_half_2\n        \n        # Format results to six significant figures\n        k_out = sf_round(k)\n        t_half_out = sf_round(t_half)\n        r2_1_out = sf_round(r2_1)\n        r2_2_out = sf_round(r2_2)\n        aic1_out = sf_round(aic1)\n        aic2_out = sf_round(aic2)\n\n        return [selected_order, k_out, t_half_out, r2_1_out, r2_2_out, aic1_out, aic2_out], (k, selected_order)\n\n    # Test suite datasets\n    test_cases = [\n        # Dataset 1\n        {'t': [0, 5, 10, 15, 20, 25, 30], 'A': [0.820, 0.401, 0.189, 0.095, 0.045, 0.021, 0.011]},\n        # Dataset 2\n        {'t': [0, 20, 40, 60, 80, 100, 120], 'A': [0.500, 0.386, 0.310, 0.266, 0.226, 0.200, 0.179]},\n        # Dataset 3\n        {'t': [0, 30, 60, 90, 120], 'A': [1.200, 0.889, 0.661, 0.491, 0.362]},\n        # Dataset 4\n        {\n            'exp_a': {'T': 295, 't': [0, 300, 600, 900, 1200], 'A': [1.000, 0.497, 0.240, 0.121, 0.058]},\n            'exp_b': {'T': 325, 't': [0, 60, 120, 180, 240], 'A': [1.000, 0.262, 0.069, 0.017, 0.005]}\n        }\n    ]\n\n    gas_constant_R = 8.314462618\n    all_results = []\n\n    # Process datasets 1-3\n    for i in range(3):\n        case = test_cases[i]\n        results, _ = analyze_dataset(case['t'], case['A'])\n        all_results.append(results)\n\n    # Process dataset 4\n    case4 = test_cases[3]\n    T1 = case4['exp_a']['T']\n    t1_data = case4['exp_a']['t']\n    A1_data = case4['exp_a']['A']\n    \n    T2 = case4['exp_b']['T']\n    t2_data = case4['exp_b']['t']\n    A2_data = case4['exp_b']['A']\n\n    results_a, (k1_raw, order1) = analyze_dataset(t1_data, A1_data)\n    results_b, (k2_raw, order2) = analyze_dataset(t2_data, A2_data)\n\n    # Calculate activation energy Ea, assuming orders are consistent\n    Ea = 0.0\n    if order1 == order2 and k1_raw > 0 and k2_raw > 0:\n        Ea = gas_constant_R * math.log(k2_raw / k1_raw) / (1.0/T1 - 1.0/T2)\n    \n    results_4 = results_a + results_b + [sf_round(Ea)]\n    all_results.append(results_4)\n\n    # Format final output string\n    str_results = []\n    for res_list in all_results:\n        str_results.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    final_output = f\"[{','.join(str_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2665160"}, {"introduction": "当反应涉及多种反应物时，确定每种物质对总速率的贡献至关重要。本实践聚焦于初速率法，这是一种经典的动力学分析技术，通过系统地改变初始浓度并测量初始反应速率来解析复杂的速率方程。你将通过对数变换将幂律形式的速率方程线性化，并应用多元线性回归来估算各个反应级数，同时还将学习如何计算这些估算参数的统计不确定性，这是严谨科学分析不可或缺的一环 [@problem_id:2665183]。", "problem": "给你一个在固定温度下，物种A和B之间双分子反应的初始速率测量值，并假设体系在足够低的转化率下遵循经验幂律速率方程。目标是估计反应对A和B的偏反应级数，并从第一性原理出发，量化其统计不确定性。仅使用基本定义和经过充分检验的规则作为基础，包括恒温下的经验幂律形式速率方程和经典线性回归框架。\n\n你的程序必须：\n- 从基本假设出发，即在恒定温度下，初始速率 $r_0$ 与一个常数乘以 $[\\mathrm{A}]_0^{\\alpha}[\\mathrm{B}]_0^{\\beta}$ 成正比，其中 $\\alpha$ 和 $\\beta$ 是待从数据中推断的未知、无量纲的反应级数，该常数包含了速率系数和任何与单位相关的依赖性。\n- 对数据进行适当变换，以将推断 $\\alpha$ 和 $\\beta$ 的问题转化为一个线性回归问题，该变换由其代数性质所保证。\n- 使用普通最小二乘法（OLS, ordinary least squares）进行参数估计，并基于经典假设下OLS估计量的协方差来计算 $\\alpha$ 和 $\\beta$ 的标准误差。\n- 所有对数变换均使用自然对数。\n- 对于每个数据集，报告一个包含四个值的列表 $[\\hat{\\alpha}, \\hat{\\beta}, \\sigma_{\\hat{\\alpha}}, \\sigma_{\\hat{\\beta}}]$，其中 $\\hat{\\alpha}$ 和 $\\hat{\\beta}$ 是反应级数的OLS估计值，$\\sigma_{\\hat{\\alpha}}$ 和 $\\sigma_{\\hat{\\beta}}$ 是它们的单标准差不确定性（标准误差）。所有报告的值都是无量纲的。将每个报告值四舍五入到小数点后四位。\n\n科学真实性说明：\n- 恒定温度意味着对于给定的数据集，速率系数是固定的；这里只分析浓度效应。\n- 取对数以一种将指数分离为线性系数的方式重新调整了模型，而截距项则包含了常数和单位依赖性。对 $\\alpha$ 和 $\\beta$ 的估计值对于 $r_0$、$[\\mathrm{A}]_0$ 和 $[\\mathrm{B}]_0$ 的单位的一致选择是不变的；但截距项并非如此。\n- 不确定性必须源于从数据中估计的残差方差；一个完全一致的数据集可能会产生有效为零的残差方差，因此在有限精度算法中标准误差为零。\n\n物理单位：\n- 初始速率 $r_0$ 的单位为 $\\mathrm{mol \\ L^{-1} \\ s^{-1}}$。\n- 浓度的单位为 $\\mathrm{mol \\ L^{-1}}$。\n- 在取对数时，使用所提供量在其给定单位下的数值。\n- 所需输出是无量纲的，因此不需要单位转换。\n\n测试套件：\n对于下面的每个数据集，实验以有序三元组 $\\left([\\mathrm{A}]_0, [\\mathrm{B}]_0, r_0\\right)$ 的形式列出，其中 $[\\mathrm{A}]_0$ 的单位为 $\\mathrm{mol \\ L^{-1}}$，$[\\mathrm{B}]_0$ 的单位为 $\\mathrm{mol \\ L^{-1}}$，$r_0$ 的单位为 $\\mathrm{mol \\ L^{-1} \\ s^{-1}}$。你的程序必须联合处理一个数据集中的所有实验，以生成一个结果列表 $[\\hat{\\alpha}, \\hat{\\beta}, \\sigma_{\\hat{\\alpha}}, \\sigma_{\\hat{\\beta}}]$。\n\n- 数据集 D1（理想情况；内部一致的幂律，动态范围宽）：\n  1. (0.10, 0.05, $1.767766953 \\times 10^{-5}$)\n  2. (0.10, 0.10, $2.500000000 \\times 10^{-5}$)\n  3. (0.10, 0.20, $3.535533906 \\times 10^{-5}$)\n  4. (0.20, 0.05, $5.000000000 \\times 10^{-5}$)\n  5. (0.20, 0.10, $7.071067810 \\times 10^{-5}$)\n  6. (0.20, 0.20, $1.000000000 \\times 10^{-4}$)\n  7. (0.50, 0.05, $1.976423538 \\times 10^{-4}$)\n  8. (0.50, 0.10, $2.795084972 \\times 10^{-4}$)\n  9. (0.50, 0.20, $3.952847075 \\times 10^{-4}$)\n\n- 数据集 D2（中等乘性噪声；检验稳健性和不确定性量化）：\n  1. (0.02, 0.02, $6.72 \\times 10^{-7}$)\n  2. (0.02, 0.10, $3.136 \\times 10^{-6}$)\n  3. (0.02, 0.30, $9.696 \\times 10^{-6}$)\n  4. (0.05, 0.02, $3.88 \\times 10^{-6}$)\n  5. (0.05, 0.10, $2.04 \\times 10^{-5}$)\n  6. (0.05, 0.30, $5.76 \\times 10^{-5}$)\n  7. (0.10, 0.02, $1.648 \\times 10^{-5}$)\n  8. (0.10, 0.10, $8.32 \\times 10^{-5}$)\n  9. (0.10, 0.30, $2.28 \\times 10^{-4}$)\n\n- 数据集 D3（$[\\mathrm{B}]_0$ 变化中存在近似共线性；评估 $\\beta$ 估计中的方差膨胀）：\n  1. (0.050, 0.095, $7.125 \\times 10^{-5}$)\n  2. (0.050, 0.100, $7.575 \\times 10^{-5}$)\n  3. (0.050, 0.105, $7.79625 \\times 10^{-5}$)\n  4. (0.100, 0.095, $1.4535 \\times 10^{-4}$)\n  5. (0.100, 0.100, $1.5000 \\times 10^{-4}$)\n  6. (0.100, 0.105, $1.5435 \\times 10^{-4}$)\n  7. (0.200, 0.095, $2.8785 \\times 10^{-4}$)\n  8. (0.200, 0.100, $2.9700 \\times 10^{-4}$)\n  9. (0.200, 0.105, $3.2445 \\times 10^{-4}$)\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个顶级列表，该列表内含三个内部列表，按 $\\mathrm{D1}, \\mathrm{D2}, \\mathrm{D3}$ 的顺序分别对应每个数据集。每个内部列表必须是 $[\\hat{\\alpha}, \\hat{\\beta}, \\sigma_{\\hat{\\alpha}}, \\sigma_{\\hat{\\beta}}]$，其中每个值都四舍五入到小数点后四位。例如，输出必须如下所示：\n- $[[a_1,b_1,s_{a1},s_{b1}],[a_2,b_2,s_{a2},s_{b2}],[a_3,b_3,s_{a3},s_{b3}]]$\n- 只输出这一行，不含任何附加文本。", "solution": "问题陈述已经过严格评估，并被确定为有效。它构成了一个在化学动力学领域中提法恰当的问题，该问题具有科学依据、客观且内部一致。我们将基于第一性原理进行求解。\n\n出发点是恒定温度 $T$ 下双分子反应的经验幂律速率表达式：\n$$r_0 = k_{\\text{eff}} [\\mathrm{A}]_0^{\\alpha} [\\mathrm{B}]_0^{\\beta}$$\n此处，$r_0$ 是初始反应速率，$[\\mathrm{A}]_0$ 和 $[\\mathrm{B}]_0$ 分别是反应物 $\\mathrm{A}$ 和 $\\mathrm{B}$ 的初始浓度。参数 $\\alpha$ 和 $\\beta$ 是反应对 $\\mathrm{A}$ 和 $\\mathrm{B}$ 的偏反应级数。$k_{\\text{eff}}$ 项是一个有效速率常数，它包含了真实的速率系数以及与单位选择相关的任何依赖性。目标是根据实验数据确定 $\\alpha$ 和 $\\beta$ 的值及其统计不确定性。\n\n这个模型在其参数 $\\alpha$ 和 $\\beta$ 上是非线性的。为了应用强大而简洁的线性回归框架，我们必须首先将该方程线性化。这可以通过对等式两边取自然对数来实现：\n$$\\ln(r_0) = \\ln(k_{\\text{eff}} [\\mathrm{A}]_0^{\\alpha} [\\mathrm{B}]_0^{\\beta})$$\n利用对数的性质，该表达式可展开为线性形式：\n$$\\ln(r_0) = \\ln(k_{\\text{eff}}) + \\alpha \\ln([\\mathrm{A}]_0) + \\beta \\ln([\\mathrm{B}]_0)$$\n该方程具有多元线性回归模型的结构。对于一组 $n$ 个实验测量值，我们可以将第 $i$ 个测量值（$i=1, \\dots, n$）写为：\n$$y_i = \\theta_0 + \\theta_1 x_{i,1} + \\theta_2 x_{i,2} + \\epsilon_i$$\n其中我们做了如下对应：\n- 因变量是 $y_i = \\ln(r_{0,i})$。\n- 自变量（预测变量）是 $x_{i,1} = \\ln([\\mathrm{A}]_{0,i})$ 和 $x_{i,2} = \\ln([\\mathrm{B}]_{0,i})$。\n- 待估参数是截距 $\\theta_0 = \\ln(k_{\\text{eff}})$，以及斜率 $\\theta_1 = \\alpha$ 和 $\\theta_2 = \\beta$。\n- $\\epsilon_i$ 项代表随机实验误差，假设在对数尺度上是加性的。\n\n这个包含 $n$ 个线性方程的系统可以用矩阵简洁地表示为 $\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\theta} + \\boldsymbol{\\epsilon}$，其中：\n- $\\mathbf{Y}$ 是观测响应的 $n \\times 1$ 列向量：$\\mathbf{Y} = [\\ln(r_{0,1}), \\dots, \\ln(r_{0,n})]^T$。\n- $\\mathbf{X}$ 是 $n \\times p$ 的设计矩阵，有 $p=3$ 个参数。每一行对应一个实验，每一列对应一个预测变量，包括一个代表截距的常数项：\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  \\ln([\\mathrm{A}]_{0,1})  \\ln([\\mathrm{B}]_{0,1}) \\\\\n1  \\ln([\\mathrm{A}]_{0,2})  \\ln([\\mathrm{B}]_{0,2}) \\\\\n\\vdots  \\vdots  \\vdots \\\\\n1  \\ln([\\mathrm{A}]_{0,n})  \\ln([\\mathrm{B}]_{0,n})\n\\end{pmatrix}\n$$\n- $\\boldsymbol{\\theta}$ 是未知参数的 $p \\times 1$ 向量：$\\boldsymbol{\\theta} = [\\theta_0, \\theta_1, \\theta_2]^T = [\\ln(k_{\\text{eff}}), \\alpha, \\beta]^T$。\n- $\\boldsymbol{\\epsilon}$ 是误差的 $n \\times 1$ 向量。\n\n参数使用普通最小二乘法（OLS）估计，该方法找到使残差平方和 $\\mathrm{RSS} = \\sum_{i=1}^n \\epsilon_i^2 = \\boldsymbol{\\epsilon}^T\\boldsymbol{\\epsilon}$ 最小化的向量 $\\hat{\\boldsymbol{\\theta}}$。这个最小化问题的解析解由正规方程给出：\n$$\\hat{\\boldsymbol{\\theta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{Y}$$\n反应级数的估计值是该向量的第二个和第三个元素：$\\hat{\\alpha} = \\hat{\\theta}_1$ 和 $\\hat{\\beta} = \\hat{\\theta}_2$。\n\n这些估计值的不确定性由其标准误差来量化。在OLS的标准假设下（包括误差的同方差性），估计量 $\\hat{\\boldsymbol{\\theta}}$ 的协方差矩阵是：\n$$\\mathrm{Cov}(\\hat{\\boldsymbol{\\theta}}) = \\sigma^2 (\\mathbf{X}^T \\mathbf{X})^{-1}$$\n误差的方差 $\\sigma^2$ 通常是未知的，必须从数据中估计。$\\sigma^2$ 的一个无偏估计量是均方误差：\n$$\\hat{\\sigma}^2 = \\frac{\\mathrm{RSS}}{n-p}$$\n其中 $\\mathrm{RSS} = (\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\theta}})^T(\\mathbf{Y} - \\mathbf{X}\\hat{\\boldsymbol{\\theta}})$ 是使用估计参数 $\\hat{\\boldsymbol{\\theta}}$ 计算的残差平方和。分母 $n-p$ 代表误差项的自由度。对于这个问题，每个数据集有 $n=9$ 个实验，我们要估计 $p=3$ 个参数，所以自由度是 $9-3=6$。\n\n估计的协方差矩阵则为 $\\widehat{\\mathrm{Cov}}(\\hat{\\boldsymbol{\\theta}}) = \\hat{\\sigma}^2 (\\mathbf{X}^T \\mathbf{X})^{-1}$。单个参数估计值的标准误差是该矩阵对角线元素的平方根。具体来说，对于 $\\hat{\\alpha}$ 和 $\\hat{\\beta}$：\n$$\\sigma_{\\hat{\\alpha}} = \\sqrt{\\widehat{\\mathrm{Cov}}(\\hat{\\boldsymbol{\\theta}})_{2,2}}$$\n$$\\sigma_{\\hat{\\beta}} = \\sqrt{\\widehat{\\mathrm{Cov}}(\\hat{\\boldsymbol{\\theta}})_{3,3}}$$\n这些标准误差量化了参数估计的精度。对于数据集 D1，其构造与幂律模型完全一致，因此残差以及 $\\hat{\\sigma}^2$ 将有效为零，导致不确定性为零。对于数据集 D2，其包含噪声，$\\hat{\\sigma}^2$ 将不为零，从而产生非零的不确定性。对于数据集 D3，$\\mathbf{X}$ 中截距列与 $\\ln([\\mathrm{B}]_0)$ 列之间的近似共线性预计会使矩阵 $(\\mathbf{X}^T \\mathbf{X})$ 成为病态的，这将表现为较大的方差，从而导致较大的标准误差 $\\sigma_{\\hat{\\beta}}$，这正确地反映了从给定数据中精确估计 $\\beta$ 的困难。\n\n每个数据集的计算过程如下：\n1. 从所提供数据的自然对数值构造向量 $\\mathbf{Y}$ 和矩阵 $\\mathbf{X}$。\n2. 使用OLS公式计算参数估计值 $\\hat{\\boldsymbol{\\theta}}$。\n3. 计算残差和RSS，然后估计误差方差 $\\hat{\\sigma}^2$。\n4. 计算协方差矩阵 $\\widehat{\\mathrm{Cov}}(\\hat{\\boldsymbol{\\theta}})$。\n5. 提取第二个和第三个对角线元素的平方根，以求得 $\\sigma_{\\hat{\\alpha}}$ 和 $\\sigma_{\\hat{\\beta}}$。\n6. 报告所需的值 $[\\hat{\\alpha}, \\hat{\\beta}, \\sigma_{\\hat{\\alpha}}, \\sigma_{\\hat{\\beta}}]$，并四舍五入到指定的精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process all datasets and print the final result.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    d1 = [\n        (0.10, 0.05, 1.767766953e-5),\n        (0.10, 0.10, 2.500000000e-5),\n        (0.10, 0.20, 3.535533906e-5),\n        (0.20, 0.05, 5.000000000e-5),\n        (0.20, 0.10, 7.071067810e-5),\n        (0.20, 0.20, 1.000000000e-4),\n        (0.50, 0.05, 1.976423538e-4),\n        (0.50, 0.10, 2.795084972e-4),\n        (0.50, 0.20, 3.952847075e-4),\n    ]\n\n    d2 = [\n        (0.02, 0.02, 6.72e-7),\n        (0.02, 0.10, 3.136e-6),\n        (0.02, 0.30, 9.696e-6),\n        (0.05, 0.02, 3.88e-6),\n        (0.05, 0.10, 2.04e-5),\n        (0.05, 0.30, 5.76e-5),\n        (0.10, 0.02, 1.648e-5),\n        (0.10, 0.10, 8.32e-5),\n        (0.10, 0.30, 2.28e-4),\n    ]\n\n    d3 = [\n        (0.050, 0.095, 7.125e-5),\n        (0.050, 0.100, 7.575e-5),\n        (0.050, 0.105, 7.79625e-5),\n        (0.100, 0.095, 1.4535e-4),\n        (0.100, 0.100, 1.5000e-4),\n        (0.100, 0.105, 1.5435e-4),\n        (0.200, 0.095, 2.8785e-4),\n        (0.200, 0.100, 2.9700e-4),\n        (0.200, 0.105, 3.2445e-4),\n    ]\n\n    test_cases = [d1, d2, d3]\n\n    results = []\n    for case in test_cases:\n        result = analyze_kinetics_data(case)\n        results.append(result)\n\n    # Format the final output string to match [[...],[...],[...]]\n    # using list comprehensions and string formatting\n    formatted_results = [\n        \"[\" + \",\".join([f\"{val:.4f}\" for val in res]) + \"]\"\n        for res in results\n    ]\n    final_output_string = \"[\" + \",\".join(formatted_results) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\ndef analyze_kinetics_data(data):\n    \"\"\"\n    Performs Ordinary Least Squares regression to find reaction orders and their standard errors.\n    \n    Args:\n        data (list): A list of tuples, where each tuple is ([A]0, [B]0, r0).\n        \n    Returns:\n        list: A list containing [alpha_hat, beta_hat, sigma_alpha, sigma_beta].\n    \"\"\"\n    # 1. Extract data and perform natural log transformation.\n    # The data is structured as (concentration_A, concentration_B, rate).\n    conc_a = np.array([d[0] for d in data])\n    conc_b = np.array([d[1] for d in data])\n    rates = np.array([d[2] for d in data])\n\n    log_a = np.log(conc_a)\n    log_b = np.log(conc_b)\n    log_rates = np.log(rates)\n\n    # 2. Construct the design matrix X and the response vector Y.\n    # The linear model is ln(r) = ln(k_eff) + alpha*ln([A]) + beta*ln([B]).\n    # The parameters are [ln(k_eff), alpha, beta].\n    n = len(data)\n    X = np.column_stack([np.ones(n), log_a, log_b])\n    Y = log_rates\n    \n    # The number of parameters (p) is the number of columns in X.\n    p = X.shape[1]\n\n    # 3. Estimate parameters using the OLS normal equation: beta = (X^T * X)^-1 * X^T * Y.\n    # Using np.linalg.solve is more numerically stable than direct inversion.\n    XTX = X.T @ X\n    XTY = X.T @ Y\n    # beta_hat will be a vector [intercept, alpha_hat, beta_hat]\n    beta_hat = np.linalg.solve(XTX, XTY)\n    \n    alpha_hat = beta_hat[1]\n    beta_hat_val = beta_hat[2]\n\n    # 4. Compute the standard errors of the parameter estimates.\n    # Calculate residuals.\n    Y_hat = X @ beta_hat\n    residuals = Y - Y_hat\n    \n    # Calculate Residual Sum of Squares (RSS).\n    RSS = np.sum(residuals**2)\n    \n    # Degrees of freedom for error term.\n    dof = n - p\n    \n    # Estimate the error variance (sigma^2).\n    # If dof = 0, we cannot estimate variance. Not an issue for this problem's data.\n    if dof > 0:\n        sigma_sq_hat = RSS / dof\n    else:\n        # This case is not expected to be reached.\n        sigma_sq_hat = 0\n        \n    # Handle the perfect fit case (RSS is zero or very close to it).\n    if sigma_sq_hat  1e-20: # A small tolerance for floating point inaccuracies.\n        sigma_alpha = 0.0\n        sigma_beta = 0.0\n    else:\n        # Compute the covariance matrix of parameters: sigma^2 * (X^T * X)^-1.\n        cov_beta = sigma_sq_hat * np.linalg.inv(XTX)\n        \n        # Standard errors are the square root of the diagonal elements of the covariance matrix.\n        std_errors = np.sqrt(np.diag(cov_beta))\n        \n        sigma_alpha = std_errors[1]\n        sigma_beta = std_errors[2]\n\n    # 5. Return the results. The problem asks for values, not rounded strings yet.\n    # Rounding will be handled in the final print statement.\n    return [alpha_hat, beta_hat_val, sigma_alpha, sigma_beta]\n\nsolve()\n```", "id": "2665183"}, {"introduction": "经典的阿伦尼乌斯 (Arrhenius) 方程是描述速率常数与温度关系的基础，但在某些情况下，实验数据在阿伦尼乌斯图上会表现出轻微的曲率。本高级练习将指导你探索这种情况，比较经典阿伦尼乌斯模型与包含温度依赖性指前因子的修正模型。你将应用最小二乘法拟合这两个模型，并使用修正的赤池信息量准则 ($AICc$) 来评估增加模型复杂性是否合理，从而掌握在简约性与拟合优度之间进行权衡的宝贵技能 [@problem_id:2665169]。", "problem": "您的任务是构建一个程序，该程序针对几个在半对数温度图上表现出轻微曲率的、与温度相关的速率常数的合成数据集，执行以下操作：从第一性原理推导并拟合两种备选的动力学模型，使用基于似然理论的信息准则评估它们的相对支持度，并在证据不确定时选择更简约的表示。\n\n您的解决方案中需要使用并论证的起点和建模假设：\n- 从基元反应速率由活化能垒和分子能量分布控制的物理图像出发。利用此图像推导速率常数的经典温度依赖关系，以及一个有原则的扩展形式，其中指前因子包含一个弱的温度依赖性，以捕捉态密度或碰撞频率效应。\n- 假设速率常数的自然对数存在独立同分布的高斯测量误差，即，如果真实速率常数表示为 $k(T)$，则观测值满足 $\\ln k_{\\text{obs}}(T) = \\ln k(T) + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 在不同温度下是独立的。\n- 在这些假设下，推导出适用于每个模型的参数线性回归表示，并从高斯对数似然推导出有限样本校正的赤池信息准则 (AICc)，以比较具有不同参数数量的模型。\n- 明确陈述并使用一个决胜规则：如果两个模型之间的 AICc 差异的绝对值小于一个指定的阈值，则选择更简单的模型。\n\n科学和数值规范：\n- 使用以开尔文为单位的绝对温度，表示为 $T$，单位为 $\\mathrm{K}$。\n- 使用摩尔气体常数 $R = 8.314462618 \\ \\mathrm{J \\ mol^{-1} \\ K^{-1}}$。\n- 使用活化能单位为 $\\mathrm{J \\ mol^{-1}}$，速率常数单位为 $\\mathrm{s}^{-1}$。\n- 经典形式是直接从一个活化能垒推导出来的形式，其指前因子由碰撞理论或过渡态理论在弱温度依赖性假设下获得，且与温度无关。扩展形式则引入一个弱的温度指数乘以指前因子。\n- 因为误差被假设在 $\\ln k$ 上呈高斯分布，所以在对数空间中进行拟合（即，将 $\\ln k$ 对适当的预测变量进行回归）。\n- 对于模型选择，使用适用于高斯残差的、从第一性原理推导出的有限样本校正的赤池信息准则 (AICc)。将观测数量表示为 $n$，每个模型的自由参数数量表示为 $p$。\n- 使用以下决胜规则：如果模型间的 AICc 差异绝对值小于 $2$，则选择更简单的模型（参数较少的那个）。\n\n测试套件的合成数据生成：\n- 对于每个数据集，使用等差数列生成一个温度网格。然后，从选定的真实模型生成 $\\ln k$ 值，并在 $\\ln k$ 上添加指定标准差的独立高斯噪声（等效于在 $k$ 上添加乘性对数正态噪声）。最后，取指数以获得单位为 $\\mathrm{s}^{-1}$ 的 $k$。\n- 使用固定的伪随机数生成器种子 $20240601$ 以确保确定性。\n- 为清晰起见，在生成数据时，您可以假设合成真值使用以下参数化：指前因子参数 $A$（单位 $\\mathrm{s}^{-1}$），活化能 $E_{\\mathrm{a}}$（单位 $\\mathrm{J \\ mol^{-1}}$），以及温度指数 $n$（无量纲）。经典情况对应于扩展模型中 $n=0$ 的特例。在选择模型时不要使用此知识；它仅用于数据生成。\n\n测试套件（五个数据集），每个由 $7$ 元组 $\\left(A, E_{\\mathrm{a}}, n, T_{\\min}, T_{\\max}, N, \\sigma_{\\ln}\\right)$ 指定：\n- 数据集 $1$：$\\left(1.0\\times 10^{12}, 75{,}000.0, 0.0, 550.0, 900.0, 10, 0.05\\right)$\n- 数据集 $2$：$\\left(2.5\\times 10^{11}, 80{,}000.0, 0.6, 500.0, 1000.0, 12, 0.03\\right)$\n- 数据集 $3$：$\\left(1.0\\times 10^{12}, 70{,}000.0, 0.05, 500.0, 900.0, 15, 0.02\\right)$\n- 数据集 $4$：$\\left(5.0\\times 10^{10}, 65{,}000.0, 0.9, 700.0, 900.0, 6, 0.04\\right)$\n- 数据集 $5$：$\\left(3.0\\times 10^{12}, 90{,}000.0, 0.0, 500.0, 1000.0, 25, 0.12\\right)$\n\n对于每个数据集：\n- 在 $T_{\\min}$ 和 $T_{\\max}$（含）之间均匀生成 $N$ 个温度点，单位为 $\\mathrm{K}$。\n- 使用选定的生成参数计算真实的 $\\ln k(T)$，并添加标准差为 $\\sigma_{\\ln}$ 的独立高斯噪声，然后通过取指数返回 $k(T)$ 以确保其为正值。\n- 在 $\\ln$-空间中，通过对适当的预测变量进行线性最小二乘法，将经典模型和扩展模型都拟合到带噪声的 $(T, k(T))$ 数据上，计算残差平方和，并为每个模型评估 AICc。\n- 实施上述阈值为 $2$ 的决胜规则。\n\n输出规范：\n- 使用模型代码 $0$ 表示经典模型（较简单的模型），模型代码 $1$ 表示扩展模型（带有额外温度指数的模型）。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的整数列表，按数据集 $1$ 到 $5$ 的顺序排列结果（例如，$\\left[\\dots\\right]$）。\n- 输出中不应出现任何物理单位；结果为纯整数。\n\n您的程序必须是完全自包含的：硬编码上述测试套件，将伪随机数生成器种子固定为 $20240601$，并以所描述的格式精确打印一行。算法必须根据此处陈述的假设和定律推导得出，并且不得依赖任何外部文件或用户输入。", "solution": "该问题要求对描述反应速率常数 $k(T)$ 温度依赖性的两种动力学模型进行严格比较。我们必须首先从基本原理推导这些模型，然后建立一个统计框架来将它们拟合到数据并进行模型选择，最后将此框架应用于一系列合成数据集。\n\n**动力学模型的推导**\n\n基元反应速率的温度依赖性从根本上由分子的能量分布决定。要发生反应，碰撞的分子必须拥有足够的能量来克服一个活化能垒，记为 $E_{\\mathrm{a}}$。根据玻尔兹曼分布，拥有至少这么多能量的分子分数正比于玻尔兹曼因子 $\\exp\\left(-\\frac{E_{\\mathrm{a}}}{RT}\\right)$，其中 $R$ 是摩尔气体常数， $T$ 是绝对温度。因此，速率常数与此项成正比。\n\n**模型 0：经典 Arrhenius 方程**\n\n由 Arrhenius 提出的最简单模型假设所有温度依赖性都包含在指数项中。比例常数，称为指前因子 $A$，被认为是与温度无关的。该因子包含了与碰撞频率和空间位阻因子相关的项。由此得到的方程是：\n$$k(T) = A \\exp\\left(-\\frac{E_{\\mathrm{a}}}{RT}\\right)$$\n该模型有两个参数：$A$ 和 $E_{\\mathrm{a}}$。为了便于进行线性回归（根据问题的误差模型规范要求），我们取自然对数：\n$$\\ln k(T) = \\ln A - \\frac{E_{\\mathrm{a}}}{R} \\left(\\frac{1}{T}\\right)$$\n该方程形式为 $y = \\beta_0 + \\beta_1 x$，其中响应变量是 $y = \\ln k$，预测变量是 $x = 1/T$，截距是 $\\beta_0 = \\ln A$，斜率是 $\\beta_1 = -E_{\\mathrm{a}}/R$。这是一个具有两个系数的简单线性回归模型。\n\n**模型 1：扩展（修正的 Arrhenius）方程**\n\n更复杂的理论，如碰撞理论或过渡态理论，预测指前因子 $A$ 本身对温度有微弱的依赖性。这种依赖性通常是幂律关系 $T^n$。将其纳入后，得到扩展的或修正的 Arrhenius 方程：\n$$k(T) = A T^n \\exp\\left(-\\frac{E_{\\mathrm{a}}}{RT}\\right)$$\n这里，$A$ 是一个与温度无关的常数，$n$ 是一个值很小的指数。该模型有三个参数：$A$、$n$ 和 $E_{\\mathrm{a}}$。同样，我们通过取自然对数来线性化模型：\n$$\\ln k(T) = \\ln A + n \\ln T - \\frac{E_{\\mathrm{a}}}{R} \\left(\\frac{1}{T}\\right)$$\n该方程形式为 $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$，其中响应是 $y = \\ln k$，预测变量是 $x_1 = \\ln T$ 和 $x_2 = 1/T$。回归系数为 $\\beta_0 = \\ln A$、$\\beta_1 = n$ 和 $\\beta_2 = -E_{\\mathrm{a}}/R$。这是一个具有三个系数的多元线性回归模型。\n\n**统计框架和模型选择**\n\n问题规定，观测误差在速率常数的对数上是独立同分布的高斯误差：$\\ln k_{\\text{obs}} = \\ln k_{\\text{true}} + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。在此假设下，使用最小二乘法拟合线性化方程等同于最大似然估计。\n\n为了比较这两个模型，其中一个（模型 1）是另一个（模型 0）的更复杂扩展，我们必须使用一个能在拟合优度和模型复杂度之间取得平衡的标准。赤池信息准则（AIC）就是为此目的设计的。对于小样本量，有限样本校正（AICc）是必要的，其公式为：\n$$\\text{AICc} = N \\ln\\left(\\frac{\\text{RSS}}{N}\\right) + 2p + \\frac{2p(p+1)}{N-p-1}$$\n这里，$N$ 是数据点的数量，$\\text{RSS}$ 是最小二乘拟合的残差平方和，$p$ 是模型中估计参数的总数。参数数量 $p$ 必须包括残差的方差 $\\sigma^2$ 以及回归系数。\n\n对于模型 0（经典模型），有两个系数（$\\beta_0, \\beta_1$），因此参数总数为 $p_0 = 2 + 1 = 3$。\n对于模型 1（扩展模型），有三个系数（$\\beta_0, \\beta_1, \\beta_2$），因此参数总数为 $p_1 = 3 + 1 = 4$。\n\nAICc 值较低的模型被认为能更好地表示数据。然而，简约性原则指示，只有当更复杂的模型能提供实质上更好的拟合时，才应选择它。问题为此决策指定了一个量化阈值。\n\n**决策规则**\n\n设 $\\text{AICc}_0$ 和 $\\text{AICc}_1$ 分别为经典模型和扩展模型的 AICc 值。\n1. 如果 $|\\text{AICc}_1 - \\text{AICc}_0|  2$，则支持更复杂模型的证据不足。根据简约性原则，我们选择更简单的模型（模型 0）。\n2. 如果 $|\\text{AICc}_1 - \\text{AICc}_0| \\geq 2$，我们选择 AICc 值较低的模型。\n\n这个逻辑可以合并为一个条件：我们选择更复杂的模型 1 当且仅当它实质上更好，即其 AICc 值至少低 $2$。数学上表示为：\n- 如果 $\\text{AICc}_0 - \\text{AICc}_1 \\geq 2$，选择模型 1（代码 1）。\n- 否则，选择模型 0（代码 0）。\n\n**计算算法**\n\n对于每个提供的数据集，我们执行以下步骤：\n1.  为保证可复现性，将伪随机数生成器种子设置为 `20240601`。\n2.  生成 $N$ 个温度 $T_i$，作为从 $T_{\\min}$ 到 $T_{\\max}$ 的等差数列。\n3.  对于这些温度，使用为测试用例提供的生成参数 $(A, E_{\\mathrm{a}}, n)$ 计算 $\\ln k_{\\text{true}, i}$ 的“真实”值。\n4.  添加标准差为 $\\sigma_{\\ln}$ 的高斯噪声，以获得合成观测值 $\\ln k_{\\text{obs}, i}$。\n5.  **拟合模型 0：**\n    a. 构建 $N \\times 2$ 的设计矩阵 $\\mathbf{X}_0$，第一列全为 1（用于截距），第二列为 $1/T_i$。\n    b. 对 $\\ln k_{\\text{obs}, i}$ 关于 $\\mathbf{X}_0$ 进行线性最小二乘回归，以获得系数和残差平方和 $\\text{RSS}_0$。\n    c. 使用 $N$、$\\text{RSS}_0$ 和 $p_0=3$ 计算 $\\text{AICc}_0$。\n6.  **拟合模型 1：**\n    a. 构建 $N \\times 3$ 的设计矩阵 $\\mathbf{X}_1$，列分别为 1、$\\ln T_i$ 和 $1/T_i$。\n    b. 对 $\\ln k_{\\text{obs}, i}$ 关于 $\\mathbf{X}_1$ 进行多元线性最小二乘回归，以获得 $\\text{RSS}_1$。\n    c. 使用 $N$、$\\text{RSS}_1$ 和 $p_1=4$ 计算 $\\text{AICc}_1$。\n7.  应用决策规则：如果 $\\text{AICc}_0 - \\text{AICc}_1 \\geq 2$，则选择的模型是 $1$。否则，是 $0$。\n8.  存储整数结果，并对所有数据集重复此过程。最终输出是这些整数的列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and fits two kinetic models to synthetic data, and selects the\n    best model using the Akaike Information Criterion (AICc).\n    \"\"\"\n    # Fixed pseudorandom number generator seed for determinism.\n    RNG_SEED = 20240601\n    np.random.seed(RNG_SEED)\n\n    # Molar gas constant in J mol^-1 K^-1.\n    R_CONST = 8.314462618\n\n    # Test suite: (A, E_a, n, T_min, T_max, N, sigma_ln)\n    test_cases = [\n        # Dataset 1: True model is classical (n=0)\n        (1.0e12, 75000.0, 0.0, 550.0, 900.0, 10, 0.05),\n        # Dataset 2: True model is extended (n=0.6)\n        (2.5e11, 80000.0, 0.6, 500.0, 1000.0, 12, 0.03),\n        # Dataset 3: True model is extended but with very small n\n        (1.0e12, 70000.0, 0.05, 500.0, 900.0, 15, 0.02),\n        # Dataset 4: True model is extended, very small sample size N\n        (5.0e10, 65000.0, 0.9, 700.0, 900.0, 6, 0.04),\n        # Dataset 5: True model is classical, high noise and large N\n        (3.0e12, 90000.0, 0.0, 500.0, 1000.0, 25, 0.12),\n    ]\n\n    results = []\n    for case in test_cases:\n        A, E_a, n_gen, T_min, T_max, N, sigma_ln = case\n\n        # 1. Generate synthetic data\n        T = np.linspace(T_min, T_max, N)\n        ln_k_true = np.log(A) + n_gen * np.log(T) - E_a / (R_CONST * T)\n        noise = np.random.normal(0, sigma_ln, N)\n        ln_k_obs = ln_k_true + noise\n        \n        y = ln_k_obs\n\n        # 2. Fit Classical Model (Model 0)\n        # Model: ln(k) = b0 + b1 * (1/T)\n        # p0 = 2 coefficients + 1 variance = 3 parameters\n        p0 = 3\n        X0 = np.vstack([np.ones(N), 1.0 / T]).T\n        _, rss0_array, _, _ = np.linalg.lstsq(X0, y, rcond=None)\n        \n        # Check if regression was underdetermined which shouldn't happen here\n        if rss0_array.size == 0 or N - p0 - 1 = 0:\n            # Assign a very high AICc if model is invalid (e.g. N = p)\n            aicc0 = np.inf\n        else:\n            rss0 = rss0_array[0]\n            # AICc formula for Gaussian residuals\n            aicc0 = N * np.log(rss0 / N) + 2 * p0 + (2 * p0 * (p0 + 1)) / (N - p0 - 1)\n\n        # 3. Fit Extended Model (Model 1)\n        # Model: ln(k) = b0 + b1*ln(T) + b2*(1/T)\n        # p1 = 3 coefficients + 1 variance = 4 parameters\n        p1 = 4\n        X1 = np.vstack([np.ones(N), np.log(T), 1.0 / T]).T\n        _, rss1_array, _, _ = np.linalg.lstsq(X1, y, rcond=None)\n        \n        if rss1_array.size == 0 or N - p1 - 1 = 0:\n            # Assign a very high AICc if model is invalid\n            aicc1 = np.inf\n        else:\n            rss1 = rss1_array[0]\n            # AICc formula for Gaussian residuals\n            aicc1 = N * np.log(rss1 / N) + 2 * p1 + (2 * p1 * (p1 + 1)) / (N - p1 - 1)\n\n        # 4. Model Selection\n        # Select model 1 only if it is substantially better (AICc drops by >= 2).\n        # Otherwise, select the simpler model 0 due to parsimony.\n        delta_aicc_threshold = 2.0\n        if aicc0 - aicc1 >= delta_aicc_threshold:\n            selected_model = 1\n        else:\n            selected_model = 0\n            \n        results.append(selected_model)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2665169"}]}