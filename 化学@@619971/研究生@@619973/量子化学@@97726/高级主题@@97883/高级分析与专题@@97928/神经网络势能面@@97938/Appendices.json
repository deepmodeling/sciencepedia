{"hands_on_practices": [{"introduction": "量子力学的一个基石是全同粒子的不可区分性。一个精确的神经网络势能面（NN-PES）必须遵守这种置换不变性。本练习通过展示一个违反此基本对称性的模型如何导致非物理性的后果——例如，为同一分子构型预测不同能量——来阐明这一概念，从而强调了构建不变性架构的必要性。[@problem_id:2908410]", "problem": "在针对氢分子阳离子 $\\mathrm{H}_3^+$ 的玻恩–奥本海默 (BO) 近似中，其精确势能面 (PES) $E_{\\mathrm{BO}}(\\{\\mathbf{R}_i\\})$ 在三个相同的氢原子核的位置 $\\{\\mathbf{R}_1,\\mathbf{R}_2,\\mathbf{R}_3\\}$ 的任何置换下都保持不变。现在考虑一个学习得到的神经网络势 (NNP)，它通过在平移不变但索引有序的描述符上使用原子索引的线性贡献，从而违反了置换不变性。具体来说，对于核位置 $\\{\\mathbf{R}_i\\}_{i=1}^3 \\subset \\mathbb{R}^3$，定义中心化坐标 $\\mathbf{s}_i = \\mathbf{R}_i - \\frac{1}{3}\\sum_{j=1}^3 \\mathbf{R}_j$，并令预测能量为\n$$\nE_{\\boldsymbol{\\theta}}(\\mathbf{R}_1,\\mathbf{R}_2,\\mathbf{R}_3) = b + \\sum_{i=1}^{3} \\mathbf{u}_i \\cdot \\mathbf{s}_i,\n$$\n其中 $b \\in \\mathbb{R}$ 是一个标量偏置，$\\mathbf{u}_i \\in \\mathbb{R}^3$ 是独立的、按原子索引的权重向量，$\\mathbf{u}_i = (u_{ix},u_{iy},u_{iz})$。该模型根据其构造是平移不变的，但除非 $\\mathbf{u}_1=\\mathbf{u}_2=\\mathbf{u}_3$，否则它不是置换不变的。\n\n考虑在 $z=0$ 平面内边长为 $R>0$ 的等边三角形几何构型，其实验室坐标系坐标如下：\n$$\n\\mathbf{R}_1 = (0,0,0),\\quad \\mathbf{R}_2 = (R,0,0),\\quad \\mathbf{R}_3 = \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{2}, 0\\right).\n$$\n定义两个物理上相同但标记不同的输入：几何构型 $\\mathcal{G}_A$ 使用给定的标记 $(1,2,3)$，而几何构型 $\\mathcal{G}_B$ 通过置换标记 $1 \\leftrightarrow 2$ 得到，即 $(2,1,3)$。由于 $\\mathrm{H}_3^+$ 有三个相同的原子核，$E_{\\mathrm{BO}}$ 必须满足 $E_{\\mathrm{BO}}(\\mathcal{G}_A)=E_{\\mathrm{BO}}(\\mathcal{G}_B)$。然而，模型 $E_{\\boldsymbol{\\theta}}$ 无需满足此条件。\n\n从 BO 哈密顿量的置换对称性以及上述 $E_{\\boldsymbol{\\theta}}$ 的定义出发，推导预测的简并分裂\n$$\n\\Delta E \\equiv E_{\\boldsymbol{\\theta}}(\\mathcal{G}_A) - E_{\\boldsymbol{\\theta}}(\\mathcal{G}_B)\n$$\n的闭式解析表达式，用 $R$ 和权重分量 $u_{ix},u_{iy},u_{iz}$ 表示。将您的最终答案表示为单个简化的解析表达式。不要对结果进行数值计算或四舍五入。最终表达式不需要单位。", "solution": "在继续之前，对问题进行验证。\n\n步骤1：提取已知条件。\n- 系统是氢分子阳离子 $\\mathrm{H}_3^+$。\n- 玻恩-奥本海默 (BO) 势能面 (PES) 是 $E_{\\mathrm{BO}}(\\{\\mathbf{R}_i\\})$。\n- $E_{\\mathrm{BO}}$ 在三个相同氢原子核的位置 $\\{\\mathbf{R}_1,\\mathbf{R}_2,\\mathbf{R}_3\\}$ 的任何置换下保持不变。\n- 一个学习得到的神经网络势 (NNP) 定义为 $E_{\\boldsymbol{\\theta}}(\\mathbf{R}_1,\\mathbf{R}_2,\\mathbf{R}_3) = b + \\sum_{i=1}^{3} \\mathbf{u}_i \\cdot \\mathbf{s}_i$。\n- $b \\in \\mathbb{R}$ 是一个标量偏置。\n- $\\mathbf{u}_i \\in \\mathbb{R}^3$ 是独立的、按原子索引的权重向量，$\\mathbf{u}_i = (u_{ix},u_{iy},u_{iz})$。\n- 中心化坐标为 $\\mathbf{s}_i = \\mathbf{R}_i - \\frac{1}{3}\\sum_{j=1}^3 \\mathbf{R}_j$。\n- 该模型是平移不变的，但不必是置换不变的。\n- 在 $z=0$ 平面内给出了一个边长为 $R>0$ 的等边三角形几何构型，其坐标为：$\\mathbf{R}_1 = (0,0,0)$、$\\mathbf{R}_2 = (R,0,0)$、$\\mathbf{R}_3 = \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{2}, 0\\right)$。\n- 几何构型 $\\mathcal{G}_A$ 对应于给定的标记 $(1,2,3)$。\n- 几何构型 $\\mathcal{G}_B$ 对应于标记 $(2,1,3)$，通过置换标记 $1 \\leftrightarrow 2$ 得到。\n- 目标是推导简并分裂 $\\Delta E \\equiv E_{\\boldsymbol{\\theta}}(\\mathcal{G}_A) - E_{\\boldsymbol{\\theta}}(\\mathcal{G}_B)$ 的表达式。\n\n步骤2：验证。\n该问题具有科学依据，提法明确且客观。它利用了量子化学（玻恩-奥本海默近似、势能面、置换对称性）和机器学习（神经网络势、输入特征）中的标准概念。所提出的模型虽然简单，但它是一个有效的数学构造，用于演示对称性破缺的后果，这是该领域的一个关键课题。所有术语的定义都没有歧义，所需信息是完整的，并且前提是一致的。该问题是一个可形式化和可验证的数学练习，不是一个微不足道或提法不当的问题。\n\n步骤3：结论。\n问题有效。将提供解答。\n\n目标是计算简并分裂 $\\Delta E$，其定义为：\n$$\n\\Delta E \\equiv E_{\\boldsymbol{\\theta}}(\\mathcal{G}_A) - E_{\\boldsymbol{\\theta}}(\\mathcal{G}_B)\n$$\n对于给定的原子位置集合 $\\{\\mathbf{R}_1, \\mathbf{R}_2, \\mathbf{R}_3\\}$，模型预测的能量是：\n$$\nE_{\\boldsymbol{\\theta}}(\\mathbf{R}_1,\\mathbf{R}_2,\\mathbf{R}_3) = b + \\sum_{i=1}^{3} \\mathbf{u}_i \\cdot \\mathbf{s}_i\n$$\n其中 $\\mathbf{s}_i = \\mathbf{R}_i - \\mathbf{R}_{\\text{COM}}$ 是中心化坐标，而 $\\mathbf{R}_{\\text{COM}} = \\frac{1}{3}\\sum_{j=1}^3 \\mathbf{R}_j$ 是原子核的中心。权重向量 $\\mathbf{u}_i$ 由原子标签索引。\n\n首先，我们计算几何构型 $\\mathcal{G}_A$ 的能量。坐标为 $\\mathbf{R}_1^{(A)} = (0,0,0)$、$\\mathbf{R}_2^{(A)} = (R,0,0)$ 和 $\\mathbf{R}_3^{(A)} = \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{2}, 0\\right)$。\n位置中心是：\n$$\n\\mathbf{R}_{\\text{COM}} = \\frac{1}{3}\\left[ (0,0,0) + (R,0,0) + \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{2}, 0\\right) \\right] = \\frac{1}{3}\\left(\\frac{3R}{2}, \\frac{\\sqrt{3}R}{2}, 0\\right) = \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{6}, 0\\right)\n$$\n$\\mathcal{G}_A$ 的中心化坐标是：\n$$\n\\mathbf{s}_1^{(A)} = \\mathbf{R}_1^{(A)} - \\mathbf{R}_{\\text{COM}} = (0,0,0) - \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{6}, 0\\right) = \\left(-\\frac{R}{2}, -\\frac{\\sqrt{3}R}{6}, 0\\right)\n$$\n$$\n\\mathbf{s}_2^{(A)} = \\mathbf{R}_2^{(A)} - \\mathbf{R}_{\\text{COM}} = (R,0,0) - \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{6}, 0\\right) = \\left(\\frac{R}{2}, -\\frac{\\sqrt{3}R}{6}, 0\\right)\n$$\n$$\n\\mathbf{s}_3^{(A)} = \\mathbf{R}_3^{(A)} - \\mathbf{R}_{\\text{COM}} = \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{2}, 0\\right) - \\left(\\frac{R}{2}, \\frac{\\sqrt{3}R}{6}, 0\\right) = \\left(0, \\frac{\\sqrt{3}R}{2} - \\frac{\\sqrt{3}R}{6}, 0\\right) = \\left(0, \\frac{\\sqrt{3}R}{3}, 0\\right)\n$$\n因此，$\\mathcal{G}_A$ 的能量是：\n$$\nE_{\\boldsymbol{\\theta}}(\\mathcal{G}_A) = b + \\mathbf{u}_1 \\cdot \\mathbf{s}_1^{(A)} + \\mathbf{u}_2 \\cdot \\mathbf{s}_2^{(A)} + \\mathbf{u}_3 \\cdot \\mathbf{s}_3^{(A)}\n$$\n接下来，我们考虑几何构型 $\\mathcal{G}_B$，它是通过置换 $\\mathcal{G}_A$ 的标签 $1 \\leftrightarrow 2$ 得到的。$\\mathcal{G}_B$ 的坐标是 $\\mathbf{R}_1^{(B)} = \\mathbf{R}_2^{(A)}$, $\\mathbf{R}_2^{(B)} = \\mathbf{R}_1^{(A)}$ 和 $\\mathbf{R}_3^{(B)} = \\mathbf{R}_3^{(A)}$。位置向量的集合是相同的，因此中心 $\\mathbf{R}_{\\text{COM}}$ 保持不变。中心化坐标计算为 $\\mathbf{s}_i^{(B)} = \\mathbf{R}_i^{(B)} - \\mathbf{R}_{\\text{COM}}$。\n$$\n\\mathbf{s}_1^{(B)} = \\mathbf{R}_1^{(B)} - \\mathbf{R}_{\\text{COM}} = \\mathbf{R}_2^{(A)} - \\mathbf{R}_{\\text{COM}} = \\mathbf{s}_2^{(A)}\n$$\n$$\n\\mathbf{s}_2^{(B)} = \\mathbf{R}_2^{(B)} - \\mathbf{R}_{\\text{COM}} = \\mathbf{R}_1^{(A)} - \\mathbf{R}_{\\text{COM}} = \\mathbf{s}_1^{(A)}\n$$\n$$\n\\mathbf{s}_3^{(B)} = \\mathbf{R}_3^{(B)} - \\mathbf{R}_{\\text{COM}} = \\mathbf{R}_3^{(A)} - \\mathbf{R}_{\\text{COM}} = \\mathbf{s}_3^{(A)}\n$$\n模型的权重 $\\mathbf{u}_i$ 与原子索引绑定，而不是它们的位置。因此，$\\mathcal{G}_B$ 的能量是：\n$$\nE_{\\boldsymbol{\\theta}}(\\mathcal{G}_B) = b + \\mathbf{u}_1 \\cdot \\mathbf{s}_1^{(B)} + \\mathbf{u}_2 \\cdot \\mathbf{s}_2^{(B)} + \\mathbf{u}_3 \\cdot \\mathbf{s}_3^{(B)}\n$$\n代入上面找到的关系：\n$$\nE_{\\boldsymbol{\\theta}}(\\mathcal{G}_B) = b + \\mathbf{u}_1 \\cdot \\mathbf{s}_2^{(A)} + \\mathbf{u}_2 \\cdot \\mathbf{s}_1^{(A)} + \\mathbf{u}_3 \\cdot \\mathbf{s}_3^{(A)}\n$$\n现在我们计算分裂 $\\Delta E$：\n$$\n\\Delta E = E_{\\boldsymbol{\\theta}}(\\mathcal{G}_A) - E_{\\boldsymbol{\\theta}}(\\mathcal{G}_B) = \\left(b + \\mathbf{u}_1 \\cdot \\mathbf{s}_1^{(A)} + \\mathbf{u}_2 \\cdot \\mathbf{s}_2^{(A)} + \\mathbf{u}_3 \\cdot \\mathbf{s}_3^{(A)}\\right) - \\left(b + \\mathbf{u}_1 \\cdot \\mathbf{s}_2^{(A)} + \\mathbf{u}_2 \\cdot \\mathbf{s}_1^{(A)} + \\mathbf{u}_3 \\cdot \\mathbf{s}_3^{(A)}\\right)\n$$\n偏置 $b$ 和原子 3 的项相消，剩下：\n$$\n\\Delta E = \\mathbf{u}_1 \\cdot \\mathbf{s}_1^{(A)} + \\mathbf{u}_2 \\cdot \\mathbf{s}_2^{(A)} - \\mathbf{u}_1 \\cdot \\mathbf{s}_2^{(A)} - \\mathbf{u}_2 \\cdot \\mathbf{s}_1^{(A)}\n$$\n该表达式可以通过对权重向量分组来重新排列：\n$$\n\\Delta E = (\\mathbf{u}_1 - \\mathbf{u}_2) \\cdot \\mathbf{s}_1^{(A)} - (\\mathbf{u}_1 - \\mathbf{u}_2) \\cdot \\mathbf{s}_2^{(A)}\n$$\n$$\n\\Delta E = (\\mathbf{u}_1 - \\mathbf{u}_2) \\cdot (\\mathbf{s}_1^{(A)} - \\mathbf{s}_2^{(A)})\n$$\n现在我们计算向量差 $(\\mathbf{s}_1^{(A)} - \\mathbf{s}_2^{(A)})$：\n$$\n\\mathbf{s}_1^{(A)} - \\mathbf{s}_2^{(A)} = \\left(-\\frac{R}{2}, -\\frac{\\sqrt{3}R}{6}, 0\\right) - \\left(\\frac{R}{2}, -\\frac{\\sqrt{3}R}{6}, 0\\right) = \\left(-\\frac{R}{2} - \\frac{R}{2}, -\\frac{\\sqrt{3}R}{6} + \\frac{\\sqrt{3}R}{6}, 0 - 0\\right) = (-R, 0, 0)\n$$\n最后，我们计算点积：\n$$\n\\Delta E = (u_{1x}-u_{2x}, u_{1y}-u_{2y}, u_{1z}-u_{2z}) \\cdot (-R, 0, 0)\n$$\n$$\n\\Delta E = (u_{1x}-u_{2x})(-R) + (u_{1y}-u_{2y})(0) + (u_{1z}-u_{2z})(0)\n$$\n$$\n\\Delta E = -R(u_{1x}-u_{2x}) = R(u_{2x}-u_{1x})\n$$\n这就是预测的简并分裂的最终闭式表达式。它表明，对于此特定置换和几何构型，置换不变性的违反仅取决于边长 $R$ 以及与被置换原子相关联的权重向量的 $x$ 分量之差。对于一个置换不变的势，$\\mathbf{u}_1 = \\mathbf{u}_2$，这正确地意味着 $\\Delta E = 0$。", "answer": "$$\n\\boxed{R(u_{2x} - u_{1x})}\n$$", "id": "2908410"}, {"introduction": "确立了置换不变性的必要性之后，我们转向消息传递神经网络（MPNNs），这是一种能够自然地编码这种对称性的强大架构。MPNNs通过在原子间迭代传递信息来运作，从而为每个原子构建其局部化学环境的表示。这个动手练习将引导你实现一次完整的前向传播，让你对现代NN-PES内部的计算流程获得具体理解，从而揭开其神秘面纱。[@problem_id:2908437]", "problem": "要求您实现一个单层消息传递网络的确定性前向传播过程，以在玻恩-奥本海默近似下近似原子级势能面。该模型应为一个简单的平移和旋转不变性架构，通过汇集每个原子的贡献，将原子核几何结构映射到标量总能量。其数学设计受以下基本原则约束：(1) 在玻恩-奥本海默近似下，势能面仅取决于原子核的坐标和电荷；(2) 通过仅使用原子间的成对距离来强制实现全局平移和旋转的不变性；(3) 总能量是每个原子贡献的总和。您必须使用规定的标量和张量运算以及提供的数值参数来实现完整的计算，并为每个测试用例返回包含所有中间消息、更新后的特征和汇集能量的单行输出。\n\n需要实现的模型和计算：\n- 原子类型由一个嵌入映射表示，该映射将原子序数映射到一个维度为 $d_h = 2$ 的初始隐藏特征向量。\n- 对于每个有序的、不同的原子对，使用基于距离的滤波器和逐元素的非线性函数来计算消息。\n- 传入消息的聚合通过对当前隐藏特征和消息总和的拼接向量进行门控变换，来更新每个原子的隐藏状态。\n- 原子级能量贡献从更新后的特征中线性读出，总能量是所有原子的能量贡献之和。\n\n下文使用的所有数学实体均以 LaTeX 定义，必须严格遵守。\n\n定义和参数：\n- 隐藏特征维度：$d_h = 2$。\n- 初始嵌入（无量纲）：\n  - 氢 $\\left(Z = 1\\right)$: $\\mathbf{h}_{\\mathrm{H}} = \\begin{bmatrix} 0.40 \\\\ -0.10 \\end{bmatrix}$。\n  - 碳 $\\left(Z = 6\\right)$: $\\mathbf{h}_{\\mathrm{C}} = \\begin{bmatrix} 0.00 \\\\ 0.50 \\end{bmatrix}$。\n  - 氧 $\\left(Z = 8\\right)$: $\\mathbf{h}_{\\mathrm{O}} = \\begin{bmatrix} 0.80 \\\\ 0.20 \\end{bmatrix}$。\n- 从原子 $j$ 到原子 $i$ 的有向消息：\n  - 设 $\\mathbf{h}_j \\in \\mathbb{R}^{2}$ 为原子 $j$ 的当前隐藏特征。\n  - 线性消息预激活：$\\mathbf{z}_{j} = \\mathbf{W}_m \\mathbf{h}_j + \\mathbf{b}_m$，其中\n    $$\\mathbf{W}_m = \\begin{bmatrix} 0.60 & -0.20 \\\\ 0.15 & 0.30 \\end{bmatrix}, \\quad \\mathbf{b}_m = \\begin{bmatrix} 0.05 \\\\ -0.05 \\end{bmatrix}。$$\n  - 非线性函数：$\\phi(\\cdot) = \\tanh(\\cdot)$ 逐元素应用，因此 $\\tilde{\\mathbf{m}}_{j} = \\phi(\\mathbf{z}_{j})$。\n  - 原子 $i$ 和 $j$ 的位置分别为 $\\mathbf{r}_i, \\mathbf{r}_j \\in \\mathbb{R}^{3}$（单位为埃），它们之间的距离为 $r_{ij} = \\lVert \\mathbf{r}_i - \\mathbf{r}_j \\rVert_2$。\n  - 径向滤波器（高斯函数）：$f(r) = \\exp\\!\\left(-\\dfrac{(r - \\mu)^2}{2 \\sigma^2}\\right)$，其中 $\\mu = 1.00$ 埃，$\\sigma = 0.50$ 埃。\n  - 有向消息：$\\mathbf{m}_{i \\leftarrow j} = f(r_{ij}) \\cdot \\tilde{\\mathbf{m}}_{j}$。\n- 原子 $i$ 的消息聚合：$\\mathbf{m}_i = \\sum_{j \\neq i} \\mathbf{m}_{i \\leftarrow j}$。\n- 原子 $i$ 的更新规则：\n  - 拼接 $\\mathbf{h}_i$ 和 $\\mathbf{m}_i$ 形成 $\\mathbf{u}_i = \\begin{bmatrix} \\mathbf{h}_i \\\\ \\mathbf{m}_i \\end{bmatrix} \\in \\mathbb{R}^{4}$。\n  - 线性更新：$\\mathbf{q}_i = \\mathbf{W}_u \\mathbf{u}_i + \\mathbf{b}_u$，其中\n    $$\\mathbf{W}_u = \\begin{bmatrix} 0.50 & 0.10 & 0.20 & -0.30 \\\\ -0.40 & 0.25 & 0.10 & 0.15 \\end{bmatrix}, \\quad \\mathbf{b}_u = \\begin{bmatrix} 0.00 \\\\ 0.10 \\end{bmatrix}。$$\n  - 非线性更新特征：$\\mathbf{h}_i' = \\phi(\\mathbf{q}_i)$，其中 $\\phi = \\tanh$ 逐元素应用。\n- 原子级能量读出与汇集：\n  - 读出权重和偏置：$\\mathbf{v} = \\begin{bmatrix} 1.50 \\\\ -0.50 \\end{bmatrix}$ 和 $c = -0.20$。\n  - 原子级能量：$e_i = \\mathbf{v}^\\top \\mathbf{h}_i' + c$，单位为电子伏特。\n  - 总能量：$E = \\sum_i e_i$，单位为电子伏特。\n\n约束条件：\n- 包括所有 $i \\neq j$ 的有向消息（无自消息）。\n- 严格使用所提供的参数。\n- 对所有 $\\tanh$ 运算使用双曲正切函数。\n- 所有距离必须以埃为单位计算，总能量必须以电子伏特为单位报告。\n\n每个测试用例所需的输出：\n- 一个扁平化的列表，包含所有有向消息分量，顺序固定：按升序索引遍历原子 $i$，对每个 $i$ 按升序索引遍历发送者 $j$（其中 $j \\neq i$）；在每个有向消息向量内部，按升序分量索引列出分量。\n- 一个扁平化的列表，包含更新后的特征 $\\mathbf{h}_i'$，按升序原子索引和升序分量索引排列。\n- 标量总能量 $E$。\n- 将所有浮点输出四舍五入到 $6$ 位小数。\n\n最终输出格式：\n- 您的程序必须生成单行输出，包含一个类JSON表示（无空格）的列表，其中包含每个案例的结果。\n- 每个案例的结果是一个包含三个元素的列表：扁平化的有向消息列表、扁平化的更新后特征列表和标量能量。\n- 例如，一个有效的输出行格式为：`[[[m_1,...],[h_1,...],E_1],[[m_2,...],[h_2,...],E_2]]`，其中所有数字均按规定四舍五入。\n\n测试套件：\n- 案例1（线性三原子）：原子 $\\left[ Z_1, Z_2, Z_3 \\right] = \\left[ 1, 6, 8 \\right]$，位置（单位为埃）\n  $$\\mathbf{r}_1 = \\begin{bmatrix} 0.00 \\\\ 0.00 \\\\ 0.00 \\end{bmatrix}, \\quad \\mathbf{r}_2 = \\begin{bmatrix} 1.10 \\\\ 0.00 \\\\ 0.00 \\end{bmatrix}, \\quad \\mathbf{r}_3 = \\begin{bmatrix} 2.30 \\\\ 0.00 \\\\ 0.00 \\end{bmatrix}。$$\n- 案例2（双原子氢）：原子 $\\left[ Z_1, Z_2 \\right] = \\left[ 1, 1 \\right]$，位置\n  $$\\mathbf{r}_1 = \\begin{bmatrix} 0.00 \\\\ 0.00 \\\\ 0.00 \\end{bmatrix}, \\quad \\mathbf{r}_2 = \\begin{bmatrix} 0.74 \\\\ 0.00 \\\\ 0.00 \\end{bmatrix}。$$\n- 案例3（单原子氧）：原子 $\\left[ Z_1 \\right] = \\left[ 8 \\right]$，位置\n  $$\\mathbf{r}_1 = \\begin{bmatrix} 0.00 \\\\ 0.00 \\\\ 0.00 \\end{bmatrix}。$$\n\n不涉及角度单位。能量必须以电子伏特表示。您的程序应生成单行输出，包含一个无空格的类JSON列表形式的结果，其中每个元素对应上述顺序的一个测试用例，每个测试用例由一个列表表示，该列表包含：扁平化的有向消息、扁平化的更新后特征和标量总能量，所有数值都四舍五入到 $6$ 位小数。", "solution": "该问题陈述是有效的。它提出了一个定义明确、自成体系的计算任务，该任务基于计算化学领域的既定原则，特别是神经网络势能面的构建。所有必要的参数、初始条件和数学运算都得到了明确的规定。任务是为三个给定的分子系统实现一个简单消息传递神经网络的单次前向传播。\n\n该解决方案是通过对每个测试用例系统地实现规定的操作序列来制定的。对于一个给定的含 $N$ 个原子的系统，其总体流程如下：\n1.  根据每个原子 $i$ 的原子序数 $Z_i$，初始化其隐藏特征向量 $\\mathbf{h}_i \\in \\mathbb{R}^{d_h}$。\n2.  计算所有 $i, j \\in \\{1,\\dots,N\\}$，$i \\neq j$ 的有向消息 $\\mathbf{m}_{i \\leftarrow j}$。\n3.  聚合每个原子 $i$ 的传入消息，得到 $\\mathbf{m}_i$。\n4.  将每个原子的隐藏特征向量从 $\\mathbf{h}_i$ 更新为 $\\mathbf{h}_i'$。\n5.  从每个更新后的特征向量 $\\mathbf{h}_i'$ 中读出原子能量贡献 $e_i$。\n6.  将原子能量相加，得到总势能 $E = \\sum_i e_i$。\n\n所提供的参数为：\n- 隐藏特征维度：$d_h = 2$。\n- 初始嵌入：$\\mathbf{h}_{\\mathrm{H}} = \\begin{bmatrix} 0.40 \\\\ -0.10 \\end{bmatrix}$，$\\mathbf{h}_{\\mathrm{C}} = \\begin{bmatrix} 0.00 \\\\ 0.50 \\end{bmatrix}$，$\\mathbf{h}_{\\mathrm{O}} = \\begin{bmatrix} 0.80 \\\\ 0.20 \\end{bmatrix}$。\n- 消息线性层：$\\mathbf{W}_m = \\begin{bmatrix} 0.60 & -0.20 \\\\ 0.15 & 0.30 \\end{bmatrix}$，$\\mathbf{b}_m = \\begin{bmatrix} 0.05 \\\\ -0.05 \\end{bmatrix}$。\n- 更新线性层：$\\mathbf{W}_u = \\begin{bmatrix} 0.50 & 0.10 & 0.20 & -0.30 \\\\ -0.40 & 0.25 & 0.10 & 0.15 \\end{bmatrix}$，$\\mathbf{b}_u = \\begin{bmatrix} 0.00 \\\\ 0.10 \\end{bmatrix}$。\n- 能量读出：$\\mathbf{v} = \\begin{bmatrix} 1.50 \\\\ -0.50 \\end{bmatrix}$，$c = -0.20$。\n- 径向滤波器：$\\mu = 1.00$ 埃，$\\sigma = 0.50$ 埃。\n- 非线性函数：$\\phi(x) = \\tanh(x)$。\n\n计算按以下详细步骤进行。\n\n**步骤1：消息生成**\n对于每对有序的不同原子 $(i, j)$，都会计算一个有向消息 $\\mathbf{m}_{i \\leftarrow j}$。此消息取决于发送原子 $j$ 的特征向量 $\\mathbf{h}_j$ 和原子间的距离 $r_{ij}$。\n\n首先，根据发送者的当前特征 $\\mathbf{h}_j$ 创建一个“基础”消息 $\\tilde{\\mathbf{m}}_j$。这涉及一个线性变换，后跟一个逐元素的双曲正切非线性函数 $\\phi(\\cdot) = \\tanh(\\cdot)$。\n$$\n\\mathbf{z}_{j} = \\mathbf{W}_m \\mathbf{h}_j + \\mathbf{b}_m\n$$\n$$\n\\tilde{\\mathbf{m}}_{j} = \\phi(\\mathbf{z}_{j})\n$$\n然后，此基础消息由一个径向滤波器函数 $f(r_{ij})$ 进行调制，该函数取决于原子间距 $r_{ij} = \\lVert \\mathbf{r}_i - \\mathbf{r}_j \\rVert_2$。该滤波器是一个以 $\\mu$ 为中心、标准差为 $\\sigma$ 的高斯函数。\n$$\nf(r_{ij}) = \\exp\\!\\left(-\\frac{(r_{ij} - \\mu)^2}{2 \\sigma^2}\\right)\n$$\n从原子 $j$ 到原子 $i$ 的最终有向消息是滤波器值与基础消息的乘积。\n$$\n\\mathbf{m}_{i \\leftarrow j} = f(r_{ij}) \\cdot \\tilde{\\mathbf{m}}_{j}\n$$\n所有计算出的有向消息 $\\mathbf{m}_{i \\leftarrow j}$ 都将按照输出格式的要求被收集并扁平化为一个列表。\n\n**步骤2：消息聚合**\n对于每个原子 $i$，将来自所有其他原子 $j$ 的传入消息相加，形成一个聚合消息向量 $\\mathbf{m}_i \\in \\mathbb{R}^{d_h}$。\n$$\n\\mathbf{m}_i = \\sum_{j \\neq i} \\mathbf{m}_{i \\leftarrow j}\n$$\n如果一个原子没有邻居（例如，单原子系统），则此和为空，其值为零向量，即 $\\mathbf{m}_i = \\mathbf{0}$。\n\n**步骤3：特征更新**\n每个原子的隐藏特征向量 $\\mathbf{h}_i$ 使用其当前特征和聚合消息 $\\mathbf{m}_i$ 更新为 $\\mathbf{h}_i'$。首先，将 $\\mathbf{h}_i$ 和 $\\mathbf{m}_i$ 拼接起来形成一个向量 $\\mathbf{u}_i \\in \\mathbb{R}^{2 d_h}$。\n$$\n\\mathbf{u}_i = \\begin{bmatrix} \\mathbf{h}_i \\\\ \\mathbf{m}_i \\end{bmatrix}\n$$\n然后，这个拼接后的向量通过另一次线性变换和逐元素的非线性函数，生成更新后的特征向量 $\\mathbf{h}_i'$。\n$$\n\\mathbf{q}_i = \\mathbf{W}_u \\mathbf{u}_i + \\mathbf{b}_u\n$$\n$$\n\\mathbf{h}_i' = \\phi(\\mathbf{q}_i)\n$$\n所有更新后的特征向量 $\\mathbf{h}_i'$ 的分量都将被收集并扁平化为第二个列表。\n\n**步骤4：能量读出与汇集**\n最后一步是计算总势能 $E$。这首先通过基于每个原子的更新特征向量 $\\mathbf{h}_i'$ 为其分配一个标量能量贡献 $e_i$ 来完成。一个线性读出层将 $\\mathbf{h}_i'$ 映射到 $e_i$。\n$$\ne_i = \\mathbf{v}^\\top \\mathbf{h}_i' + c\n$$\n系统的总势能是所有原子能量贡献的总和。\n$$\nE = \\sum_i e_i\n$$\n总能量 $E$ 是给定原子构型的最终输出值。\n\n对提供的三个测试用例分别执行这些步骤。对于单原子情况（案例3），消息生成和聚合步骤的结果是零消息，更新仅基于初始原子特征，这是所定义模型的正确且一致的结果。所有数值结果在格式化为最终输出字符串之前，都四舍五入到6位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a single forward pass of a message-passing neural network for potential energy.\n    \"\"\"\n    # Define model parameters\n    params = {\n        'h_dim': 2,\n        'embeddings': {\n            1: np.array([0.40, -0.10]),  # Hydrogen (Z=1)\n            6: np.array([0.00, 0.50]),  # Carbon (Z=6)\n            8: np.array([0.80, 0.20]),  # Oxygen (Z=8)\n        },\n        'W_m': np.array([[0.60, -0.20], [0.15, 0.30]]),\n        'b_m': np.array([0.05, -0.05]),\n        'mu': 1.00,\n        'sigma': 0.50,\n        'W_u': np.array([[0.50, 0.10, 0.20, -0.30], [-0.40, 0.25, 0.10, 0.15]]),\n        'b_u': np.array([0.00, 0.10]),\n        'v': np.array([1.50, -0.50]),\n        'c': -0.20,\n    }\n\n    # Define test cases\n    test_cases = [\n        {\n            'Z': [1, 6, 8],\n            'R': np.array([\n                [0.00, 0.00, 0.00],\n                [1.10, 0.00, 0.00],\n                [2.30, 0.00, 0.00]\n            ])\n        },\n        {\n            'Z': [1, 1],\n            'R': np.array([\n                [0.00, 0.00, 0.00],\n                [0.74, 0.00, 0.00]\n            ])\n        },\n        {\n            'Z': [8],\n            'R': np.array([\n                [0.00, 0.00, 0.00]\n            ])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        Zs = case['Z']\n        Rs = case['R']\n        num_atoms = len(Zs)\n\n        # 1. Initialize features\n        h_initial = np.array([params['embeddings'][Z] for Z in Zs])\n\n        # 2. Message Generation and Aggregation\n        all_messages_flat = []\n        aggregated_messages = np.zeros_like(h_initial)\n        \n        # Pre-compute base messages for all atoms\n        base_messages = {}\n        for j in range(num_atoms):\n            z_j = params['W_m'] @ h_initial[j] + params['b_m']\n            m_tilde_j = np.tanh(z_j)\n            base_messages[j] = m_tilde_j\n\n        for i in range(num_atoms):\n            for j in range(num_atoms):\n                if i == j:\n                    continue\n                \n                # Distance\n                r_ij = np.linalg.norm(Rs[i] - Rs[j])\n                \n                # Radial filter\n                f_r = np.exp(-((r_ij - params['mu'])**2) / (2 * params['sigma']**2))\n\n                # Directed message\n                m_i_j = f_r * base_messages[j]\n                \n                # Collect for output\n                all_messages_flat.extend(m_i_j.tolist())\n\n                # Aggregate\n                aggregated_messages[i] += m_i_j\n\n        # 3. Feature Update\n        h_updated = np.zeros_like(h_initial)\n        all_updated_features_flat = []\n        \n        for i in range(num_atoms):\n            u_i = np.concatenate([h_initial[i], aggregated_messages[i]])\n            q_i = params['W_u'] @ u_i + params['b_u']\n            h_prime_i = np.tanh(q_i)\n            h_updated[i] = h_prime_i\n            all_updated_features_flat.extend(h_prime_i.tolist())\n\n        # 4. Energy Readout\n        total_energy = 0.0\n        if num_atoms > 0:\n            atomic_energies = h_updated @ params['v'] + params['c']\n            total_energy = np.sum(atomic_energies)\n\n        results.append([all_messages_flat, all_updated_features_flat, total_energy])\n\n    # Format output as specified\n    def format_case(case_result):\n        msg_list_str = f\"[{','.join([f'{m:.6f}' for m in case_result[0]])}]\"\n        feat_list_str = f\"[{','.join([f'{h:.6f}' for h in case_result[1]])}]\"\n        energy_str = f'{case_result[2]:.6f}'\n        return f\"[{msg_list_str},{feat_list_str},{energy_str}]\"\n    \n    all_cases_str = [format_case(case) for case in results]\n    final_output = f\"[{','.join(all_cases_str)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2908437"}, {"introduction": "为了将NN-PES用于分子动力学模拟，我们必须计算力，即势能的负梯度。对于一个复杂的深度学习模型，这需要谨慎地应用链式法则，其中原子描述符相对于坐标的导数（即雅可比矩阵，$Jacobian$）是一个关键组成部分。这个高级练习不仅专注于推导这些解析雅可比矩阵，还介绍了通过与数值有限差分近似进行比较来验证它们的关键技能，以确保所计算力的准确性。[@problem_id:2908378]", "problem": "给定三维分子构型和一个固定的径向截断半径。对于每种构型，在固定截断半径下构建邻居列表，并通过计算一个在神经网络势能面中使用的平滑、局域、径向描述符相对于原子坐标的雅可比矩阵，来评估其敏感性。您必须从第一性原理计算解析雅可比，并用中心有限差分法计算数值雅可比，然后报告每种构型的无向邻居对总数，以及在所有原子、所有描述符分量和所有坐标方向上，解析雅可比与数值雅可比之间的最大绝对偏差。\n\n基本原理和定义：\n- 设有 $N$ 个原子，其位置为 $\\{\\mathbf{R}_i\\}_{i=1}^N$，其中 $\\mathbf{R}_i \\in \\mathbb{R}^3$ 以埃格斯特朗（$\\mathrm{\\AA}$）为单位。\n- 对于一个固定的截断半径 $R_{\\mathrm{c}}$，定义对距离 $R_{ij} = \\lVert \\mathbf{R}_i - \\mathbf{R}_j \\rVert_2$。当且仅当 $R_{ij} \\le R_{\\mathrm{c}}$ 时，存在一个无向邻居对 $\\{i,j\\}$。\n- 定义平滑截断函数 $f_{\\mathrm{c}}(R)$ 如下：\n$$\nf_{\\mathrm{c}}(R) = \n\\begin{cases}\n\\frac{1}{2}\\left(\\cos\\left(\\pi R / R_{\\mathrm{c}}\\right) + 1\\right), & \\text{若 } R \\le R_{\\mathrm{c}}, \\\\\n0, & \\text{若 } R > R_{\\mathrm{c}}.\n\\end{cases}\n$$\n角度应以弧度为单位，$\\pi$ 表示以弧度为单位的圆周率。\n- 定义原子 $I$ 的类径向密度原子描述符为一个向量 $\\mathcal{D}_I \\in \\mathbb{R}^{M}$，其分量为：\n$$\n\\mathcal{D}_{I,k} = \\sum_{\\substack{J=1\\\\ J \\ne I}}^{N} g_k(R_{IJ}) \\, f_{\\mathrm{c}}(R_{IJ}),\n$$\n其中 $g_k$ 是平滑径向函数。在本问题中，取 $M=3$ 且\n$$\ng_k(R) = \\exp\\!\\left(-\\eta_k \\left(R - R_{s,k}\\right)^2\\right),\n$$\n参数为：\n$$\n(\\eta_1, R_{s,1}) = (1.0, 0.0), \\quad\n(\\eta_2, R_{s,2}) = (0.5, 1.0), \\quad\n(\\eta_3, R_{s,3}) = (0.2, 2.0).\n$$\n\n待推导和计算的解析雅可比：\n- 对于每个有序原子对 $(I,J)$ 和每个笛卡尔分量 $\\alpha \\in \\{x,y,z\\}$，定义雅可比项\n$$\n\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}},\n$$\n并将它们组合成一个矩阵，其中描述符索引 $k \\in \\{1,2,3\\}$ 对应行，坐标索引 $\\alpha$ 对应列。您必须仅使用基本向量微积分和链式法则，以 $R_{IJ}$、单位向量 $\\hat{\\mathbf{r}}_{IJ} = (\\mathbf{R}_I - \\mathbf{R}_J)/R_{IJ}$ 以及关于 $R$ 的导数来获得精确表达式。\n\n通过中心有限差分计算数值雅可比：\n- 对于步长 $\\varepsilon$，近似计算\n$$\n\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}}\n\\approx \\frac{\\mathcal{D}_{I,k}\\left(\\mathbf{R}_{J,\\alpha} + \\varepsilon\\right) - \\mathcal{D}_{I,k}\\left(\\mathbf{R}_{J,\\alpha} - \\varepsilon\\right)}{2\\varepsilon}.\n$$\n使用 $\\varepsilon = 10^{-6}\\ \\mathrm{\\AA}$。\n\n测试套件：\n使用单一固定截断半径 $R_{\\mathrm{c}} = 1.5\\ \\mathrm{\\AA}$ 和以下三种构型，每种构型均以 $\\mathrm{\\AA}$ 为单位的位置数组形式给出：\n1. 构型 A ($N=3$)：$\\left[(0,0,0),\\ (1.0,0,0),\\ (0,1.4,0)\\right]$。\n2. 构型 B ($N=2$)：$\\left[(0,0,0),\\ (1.5,0,0)\\right]$。\n3. 构型 C ($N=1$)：$\\left[(0,0,0)\\right]$。\n\n每种构型需要计算的内容：\n1. 根据规则 $R_{ij} \\le R_{\\mathrm{c}}$ 构建邻居列表，并计算无向邻居对的总数（每对不分方向只计数一次）。\n2. 仅使用第一性原理和所述定义，计算所有 $I,J$ 的解析雅可比 $\\partial \\mathcal{D}_I / \\partial \\mathbf{R}_J$。\n3. 使用指定的 $\\varepsilon$ 通过中心有限差分计算数值雅可比。\n4. 对于该构型，计算最大绝对偏差\n$$\nE_{\\max} = \\max_{I,J,k,\\alpha} \\left| \\left( \\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}} \\right)_{\\mathrm{analytic}} - \\left( \\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}} \\right)_{\\mathrm{numeric}} \\right|.\n$$\n\n要求的最终输出：\n您的程序必须生成单行输出，其中包含按 A、B、C 顺序排列的所有构型的结果，并聚合为一个用方括号括起来的逗号分隔列表。对于每种构型，首先输出无向邻居对的整数数量，然后输出浮点数 $E_{\\max}$ 值。因此，输出必须总共包含 6 个条目，格式如下：\n$[N_A, E_{\\max,A}, N_B, E_{\\max,B}, N_C, E_{\\max,C}]$,\n其中 $N_A$、$N_B$、$N_C$ 是整数，三个浮点数值必须格式化为包含六位有效数字的科学记数法。角度必须以弧度为单位，距离以埃格斯特朗（$\\mathrm{\\AA}$）为单位。不应打印任何其他文本。每种构型的答案都可以分别量化为一个整数和一个浮点数。", "solution": "该问题陈述已经过严格验证，并被证实是有效的。它在科学上植根于计算化学的原理，特别是在机器学习原子间势的领域。该问题是适定的（well-posed），所有必要的参数、函数和数据都已明确定义，确保可以计算出唯一且有意义的解。其语言客观、数学上精确，没有歧义或主观论断。\n\n我们继续求解，这包括推导给定原子描述符的解析雅可比，实现其计算，通过有限差分实现数值雅可比以进行验证，并将这些方法应用于指定的测试用例。\n\n**1. 解析雅可比推导**\n\n中心原子 $I$ 的原子描述符由一个向量 $\\mathcal{D}_I \\in \\mathbb{R}^{M}$ 给出，其分量为：\n$$\n\\mathcal{D}_{I,k} = \\sum_{\\substack{J'=1\\\\ J' \\ne I}}^{N} g_k(R_{IJ'}) \\, f_{\\mathrm{c}}(R_{IJ'})\n$$\n其中 $k \\in \\{1, 2, 3\\}$。为方便起见，我们定义复合函数 $G_k(R) = g_k(R) f_{\\mathrm{c}}(R)$。描述符分量则为 $\\mathcal{D}_{I,k} = \\sum_{J' \\ne I} G_k(R_{IJ'})$。我们的任务是计算雅可比矩阵元素 $\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}}$，其中 $I$ 和 $J$ 为原子索引，$\\alpha \\in \\{x, y, z\\}$ 为笛卡尔坐标索引。\n\n我们应用链式法则：\n$$\n\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}} = \\sum_{\\substack{J'=1\\\\ J' \\ne I}}^{N} \\frac{\\partial G_k(R_{IJ'})}{\\partial R_{J,\\alpha}} = \\sum_{\\substack{J'=1\\\\ J' \\ne I}}^{N} \\frac{dG_k(R)}{dR}\\bigg|_{R=R_{IJ'}} \\frac{\\partial R_{IJ'}}{\\partial R_{J,\\alpha}}\n$$\n原子间距离 $R_{IJ'} = \\lVert \\mathbf{R}_I - \\mathbf{R}_{J'} \\rVert_2$ 相对于坐标 $R_{J,\\alpha}$ 的导数取决于索引 $J$。\n令 $\\mathbf{r}_{IJ'} = \\mathbf{R}_I - \\mathbf{R}_{J'}$。那么 $R_{IJ'} = \\sqrt{\\mathbf{r}_{IJ'} \\cdot \\mathbf{r}_{IJ'}}$。其导数为 $\\frac{\\partial R_{IJ'}}{\\partial R_{J,\\alpha}} = \\frac{1}{R_{IJ'}} \\sum_{\\beta} (R_{I,\\beta} - R_{J',\\beta}) \\frac{\\partial(R_{I,\\beta} - R_{J',\\beta})}{\\partial R_{J,\\alpha}}$。\n\n我们区分索引 $J$ 的两种情况：\n\n**情况1：$J = I$（关于中心原子坐标的导数）**\n在这种情况下，$\\frac{\\partial(R_{I,\\beta} - R_{J',\\beta})}{\\partial R_{I,\\alpha}} = \\delta_{\\alpha\\beta}$。\n距离的导数变为：\n$$\n\\frac{\\partial R_{IJ'}}{\\partial R_{I,\\alpha}} = \\frac{R_{I,\\alpha} - R_{J',\\alpha}}{R_{IJ'}} = \\hat{r}_{IJ',\\alpha}\n$$\n其中 $\\hat{\\mathbf{r}}_{IJ'} = (\\mathbf{R}_I - \\mathbf{R}_{J'})/R_{IJ'}$ 是单位向量。雅可比元素为：\n$$\n\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{I,\\alpha}} = \\sum_{\\substack{J' = 1 \\\\ J' \\ne I}}^{N} \\frac{dG_k(R)}{dR}\\bigg|_{R=R_{IJ'}} \\hat{r}_{IJ',\\alpha}\n$$\n\n**情况2：$J \\neq I$（关于另一原子坐标的导数）**\n只有当 $J' = J$ 时，项 $\\frac{\\partial R_{IJ'}}{\\partial R_{J,\\alpha}}$ 才非零。对于 $J' \\neq J$ 的其他项，该导数为零。因此，求和简化为单项：\n$$\n\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}} = \\frac{dG_k(R)}{dR}\\bigg|_{R=R_{IJ}} \\frac{\\partial R_{IJ}}{\\partial R_{J,\\alpha}}\n$$\n此处，$\\frac{\\partial(R_{I,\\beta} - R_{J,\\beta})}{\\partial R_{J,\\alpha}} = -\\delta_{\\alpha\\beta}$，这得出：\n$$\n\\frac{\\partial R_{IJ}}{\\partial R_{J,\\alpha}} = -\\frac{R_{I,\\alpha} - R_{J,\\alpha}}{R_{IJ}} = -\\hat{r}_{IJ,\\alpha}\n$$\n所以，对于 $J \\neq I$，雅可比元素为：\n$$\n\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}} = - \\frac{dG_k(R)}{dR}\\bigg|_{R=R_{IJ}} \\hat{r}_{IJ,\\alpha}\n$$\n如果 $R > R_{\\mathrm{c}}$，导数 $\\frac{dG_k(R)}{dR}$ 为零。如果 $R \\le R_{\\mathrm{c}}$，我们使用乘法法则：\n$$\n\\frac{dG_k(R)}{dR} = \\frac{dg_k(R)}{dR} f_{\\mathrm{c}}(R) + g_k(R) \\frac{df_{\\mathrm{c}}(R)}{dR}\n$$\n分量函数的导数是：\n$$\n\\frac{dg_k(R)}{dR} = -2\\eta_k(R - R_{s,k}) \\exp\\!\\left(-\\eta_k(R - R_{s,k})^2\\right) = -2\\eta_k(R - R_{s,k}) g_k(R)\n$$\n$$\n\\frac{df_{\\mathrm{c}}(R)}{dR} = -\\frac{\\pi}{2 R_{\\mathrm{c}}} \\sin\\left(\\frac{\\pi R}{R_{\\mathrm{c}}}\\right)\n$$\n将这些结合起来，得到 $R \\le R_{\\mathrm{c}}$ 时导数的最终表达式：\n$$\n\\frac{dG_k(R)}{dR} = g_k(R) \\left[ -2\\eta_k(R - R_{s,k}) f_{\\mathrm{c}}(R) - \\frac{\\pi}{2 R_{\\mathrm{c}}} \\sin\\left(\\frac{\\pi R}{R_{\\mathrm{c}}}\\right) \\right]\n$$\n\n**2. 数值雅可比计算**\n\n数值雅可比使用中心有限差分公式，并以一个小的步长 $\\varepsilon = 10^{-6}\\ \\mathrm{\\AA}$ 进行近似：\n$$\n\\left(\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}}\\right)_{\\text{numeric}} \\approx \\frac{\\mathcal{D}_{I,k}(\\mathbf{R}_{J,\\alpha} + \\varepsilon) - \\mathcal{D}_{I,k}(\\mathbf{R}_{J,\\alpha} - \\varepsilon)}{2\\varepsilon}\n$$\n这里，$\\mathcal{D}_{I,k}(\\mathbf{R}_{J,\\alpha} \\pm \\varepsilon)$ 表示在将原子 $J$ 的 $\\alpha$ 坐标扰动 $\\pm\\varepsilon$ 后，重新评估原子 $I$ 的描述符。这需要对每个雅可比元素 $(I,J,k,\\alpha)$ 进行两次完整的描述符评估。\n\n**3. 算法策略**\n\n对于所提供的每种构型，执行以下步骤：\n1.  **构建邻居列表**：计算所有原子对 $\\{i,j\\}$ 的距离矩阵。统计满足 $R_{ij} \\le R_{\\mathrm{c}}$ 的无向对的数量。\n2.  **解析雅可比计算**：分配一个形状为 $(N, N, M, 3)$ 的 4 维张量来存储解析雅可比 $\\frac{\\partial \\mathcal{D}_{I,k}}{\\partial R_{J,\\alpha}}$。通过遍历所有索引 $I, J, k, \\alpha$ 并应用上述推导的表达式来填充它。\n    -   实现一个辅助函数来计算 $\\frac{dG_k(R)}{dR}$，该函数通过返回 0 来处理 $R > R_{\\mathrm{c}}$ 的情况。\n3.  **数值雅可比计算**：为数值雅可比分配第二个相同形状的张量。通过遍历 $I, J, \\alpha$ 并应用有限差分公式来填充它。这需要一个辅助函数，该函数接收一套完整的原子坐标，并计算描述符向量 $\\mathcal{D}_I$。\n4.  **偏差计算**：找出解析和数值雅可比张量之间元素级的最大绝对差。该值为 $E_{\\max}$。\n5.  **结果聚合**：存储计算出的邻居对数量和 $E_{\\max}$。\n\n**4. 测试用例分析**\n\n- **构型 A ($N=3$)：** 包含两个邻居对 $\\{ (0,1), (0,2) \\}$，因为 $R_{01}=1.0\\ \\mathrm{\\AA} \\le 1.5\\ \\mathrm{\\AA}$ 和 $R_{02}=1.4\\ \\mathrm{\\AA} \\le 1.5\\ \\mathrm{\\AA}$，而 $R_{12} \\approx 1.72\\ \\mathrm{\\AA} > 1.5\\ \\mathrm{\\AA}$。预计会有一个小的非零偏差 $E_{\\max, A}$，这是由有限差分法的近似误差引起的，该误差通常为 $O(\\varepsilon^2)$ 阶。\n- **构型 B ($N=2$)：** 包含一个邻居对 $\\{ (0,1) \\}$，其距离为 $R_{01}=1.5\\ \\mathrm{\\AA} = R_{\\mathrm{c}}$。这是一个特殊的边界情况。截断函数 $f_{\\mathrm{c}}(R)$ 及其一阶导数 $f'_{\\mathrm{c}}(R)$ 在 $R=R_{\\mathrm{c}}$ 处均为零。这使得解析雅可比为零。然而，该函数的二阶导数在 $R=R_{\\mathrm{c}}$ 处不连续。数值有限差分法探测了边界两侧的点，导致了非零的估计值。由此产生的误差预计为 $O(\\varepsilon)$ 阶，明显大于构型 A 中的误差。\n- **构型 C ($N=1$)：**只有一个原子，不存在原子对，因此邻居数量为 0。描述符定义中的求和为空，使得描述符 $\\mathcal{D}_I$ 及其所有导数恒为零。解析和数值雅可比都将为零，导致 $E_{\\max, C} = 0.0$。\n\n这种全面的方法确保了正确性，并根据已知的数值分析原理验证了实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of computing descriptor Jacobians for given molecular configurations.\n    \"\"\"\n    \n    # --- Define parameters and constants ---\n    RC = 1.5  # Cutoff radius in Angstrom\n    EPSILON = 1e-6  # Step size for finite differences in Angstrom\n    PARAMS = [\n        # (eta_k, R_s_k) for k=1,2,3\n        (1.0, 0.0),\n        (0.5, 1.0),\n        (0.2, 2.0),\n    ]\n    M = len(PARAMS) # Number of descriptor components\n\n    # --- Define base functions and their derivatives ---\n\n    def fc(R, Rc):\n        \"\"\"Smooth cutoff function.\"\"\"\n        if R > Rc:\n            return 0.0\n        return 0.5 * (np.cos(np.pi * R / Rc) + 1.0)\n\n    def dfc_dR(R, Rc):\n        \"\"\"Derivative of the smooth cutoff function.\"\"\"\n        if R > Rc:\n            return 0.0\n        return -0.5 * (np.pi / Rc) * np.sin(np.pi * R / Rc)\n\n    def gk(R, eta, Rs):\n        \"\"\"Gaussian radial basis function.\"\"\"\n        return np.exp(-eta * (R - Rs)**2)\n\n    def dgk_dR(R, eta, Rs):\n        \"\"\"Derivative of the Gaussian radial basis function.\"\"\"\n        return -2.0 * eta * (R - Rs) * gk(R, eta, Rs)\n\n    def Gk(R, Rc, eta, Rs):\n        \"\"\"Combined descriptor function G_k(R) = g_k(R) * f_c(R).\"\"\"\n        if R > Rc:\n            return 0.0\n        return gk(R, eta, Rs) * fc(R, Rc)\n\n    def dGk_dR(R, Rc, eta, Rs):\n        \"\"\"Derivative of the combined descriptor function G_k(R).\"\"\"\n        if R > Rc:\n            return 0.0\n        val_fc = fc(R, Rc)\n        val_dfc = dfc_dR(R, Rc)\n        val_gk = gk(R, eta, Rs)\n        val_dgk = dgk_dR(R, eta, Rs)\n        return val_dgk * val_fc + val_gk * val_dfc\n\n    def compute_descriptor(coords, i_atom, Rc, params):\n        \"\"\"Computes the descriptor vector D_I for atom i_atom.\"\"\"\n        desc = np.zeros(len(params))\n        pos_i = coords[i_atom]\n        for j_atom in range(len(coords)):\n            if i_atom == j_atom:\n                continue\n            \n            pos_j = coords[j_atom]\n            dist_vec = pos_i - pos_j\n            dist = np.linalg.norm(dist_vec)\n            \n            if dist = Rc:\n                for k in range(len(params)):\n                    eta_k, Rs_k = params[k]\n                    desc[k] += Gk(dist, Rc, eta_k, Rs_k)\n        return desc\n\n    # --- Test case configurations ---\n    test_cases = [\n        np.array([[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 1.4, 0.0]]),\n        np.array([[0.0, 0.0, 0.0], [1.5, 0.0, 0.0]]),\n        np.array([[0.0, 0.0, 0.0]]),\n    ]\n    \n    results = []\n\n    for coords in test_cases:\n        N = coords.shape[0]\n        \n        # --- 1. Compute number of neighbor pairs ---\n        num_neighbor_pairs = 0\n        if N > 1:\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dist = np.linalg.norm(coords[i] - coords[j])\n                    if dist = RC:\n                        num_neighbor_pairs += 1\n        \n        if N = 1:\n            results.extend([0, 0.0])\n            continue\n            \n        # --- 2. Compute analytic and numerical Jacobians ---\n        analytic_jac = np.zeros((N, N, M, 3))\n        numeric_jac = np.zeros((N, N, M, 3))\n\n        # Analytic Jacobian\n        for I in range(N):\n            for J_neighbor in range(N):\n                if I == J_neighbor:\n                    continue\n                \n                R_vec = coords[I] - coords[J_neighbor]\n                R_norm = np.linalg.norm(R_vec)\n                \n                if R_norm > RC:\n                    continue\n\n                R_hat = R_vec / R_norm\n                \n                dG_dR_vec = np.zeros(M)\n                for k in range(M):\n                    eta_k, Rs_k = PARAMS[k]\n                    dG_dR_vec[k] = dGk_dR(R_norm, RC, eta_k, Rs_k)\n                \n                # Contribution to dD_I / dR_J for J != I\n                analytic_jac[I, J_neighbor, :, :] = -np.outer(dG_dR_vec, R_hat)\n                \n                # Contribution to dD_I / dR_I\n                analytic_jac[I, I, :, :] += np.outer(dG_dR_vec, R_hat)\n\n        # Numerical Jacobian\n        for I in range(N):\n            for J in range(N):\n                for alpha in range(3):\n                    coords_plus = coords.copy()\n                    coords_plus[J, alpha] += EPSILON\n                    desc_plus = compute_descriptor(coords_plus, I, RC, PARAMS)\n                    \n                    coords_minus = coords.copy()\n                    coords_minus[J, alpha] -= EPSILON\n                    desc_minus = compute_descriptor(coords_minus, I, RC, PARAMS)\n                    \n                    numeric_jac[I, J, :, alpha] = (desc_plus - desc_minus) / (2 * EPSILON)\n\n        # --- 3. Compute maximum discrepancy ---\n        max_discrepancy = np.max(np.abs(analytic_jac - numeric_jac))\n        \n        results.extend([num_neighbor_pairs, max_discrepancy])\n\n    # --- 4. Format and print the final output ---\n    formatted_results = []\n    for i, res in enumerate(results):\n        if i % 2 == 0: # Integer number of pairs\n            formatted_results.append(str(res))\n        else: # Float E_max\n            formatted_results.append(f\"{res:.5e}\")\n            \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2908378"}]}