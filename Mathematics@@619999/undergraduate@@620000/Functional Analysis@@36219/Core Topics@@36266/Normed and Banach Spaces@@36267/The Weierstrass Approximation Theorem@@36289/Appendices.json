{"hands_on_practices": [{"introduction": "The Weierstrass Approximation Theorem is a cornerstone of analysis, and Bernstein polynomials offer a beautiful, constructive proof. This first exercise invites you to explore the very foundation of this construction by calculating the first-degree Bernstein polynomial. By working through the simplest case, you will uncover the intuitive geometric meaning behind the approximation, connecting an abstract formula to a familiar concept. [@problem_id:2330457]", "problem": "The Bernstein polynomials provide a constructive way to approximate continuous functions with polynomials, forming the basis for a proof of the Weierstrass Approximation Theorem. For a function $f(x)$ that is continuous on the interval $[0, 1]$, the $n$-th degree Bernstein polynomial is defined as:\n$$B_n(f; x) = \\sum_{k=0}^{n} f\\left(\\frac{k}{n}\\right) \\binom{n}{k} x^k (1-x)^{n-k}$$\nwhere $\\binom{n}{k}$ is the binomial coefficient \"n choose k\".\n\nDetermine the explicit form of the first-degree Bernstein polynomial, $B_1(f; x)$, for a generic continuous function $f$. Express your answer as a polynomial in the variable $x$, with coefficients that depend on the values of the function $f$ at the endpoints of the interval $[0, 1]$.", "solution": "We use the definition of the Bernstein polynomial of degree $n$:\n$$B_{n}(f;x)=\\sum_{k=0}^{n} f\\left(\\frac{k}{n}\\right)\\binom{n}{k} x^{k} (1-x)^{n-k}.$$\nSetting $n=1$ gives\n$$B_{1}(f;x)=\\sum_{k=0}^{1} f\\left(\\frac{k}{1}\\right)\\binom{1}{k} x^{k} (1-x)^{1-k}.$$\nEvaluating term by term:\n- For $k=0$, $\\binom{1}{0}=1$, $x^{0}=1$, $(1-x)^{1}=1-x$, so the term is $f(0)\\,(1-x)$.\n- For $k=1$, $\\binom{1}{1}=1$, $x^{1}=x$, $(1-x)^{0}=1$, so the term is $f(1)\\,x$.\nSumming,\n$$B_{1}(f;x)=f(0)\\,(1-x)+f(1)\\,x.$$\nExpanding to exhibit it explicitly as a polynomial in $x$,\n$$B_{1}(f;x)=f(0)+\\bigl(f(1)-f(0)\\bigr)x.$$\nThis expresses the first-degree Bernstein polynomial with coefficients depending only on $f(0)$ and $f(1)$.", "answer": "$$\\boxed{f(0)+\\bigl(f(1)-f(0)\\bigr)x}$$", "id": "2330457"}, {"introduction": "This practice challenges you to probe the boundaries of the Weierstrass theorem, which guarantees approximation by polynomials with real coefficients. By restricting the approximating polynomials to have only integer coefficients, you will discover that the ability to approximate any continuous function can be lost. This exercise highlights the crucial role that the set of real numbers plays as coefficients, deepening your understanding of the theorem's precise conditions. [@problem_id:1904669]", "problem": "Let $C[0,2]$ be the space of all real-valued continuous functions on the interval $[0,2]$, equipped with the uniform norm, defined as $\\|f\\|_\\infty = \\max_{x \\in [0,2]} |f(x)|$. Let $\\mathcal{P}_{\\mathbb{Z}}$ denote the set of all polynomials with only integer coefficients (e.g., $P(x) = a_n x^n + \\dots + a_1 x + a_0$ where all $a_i$ are integers).\n\nWhile the Weierstrass Approximation Theorem guarantees that any continuous function on a closed interval can be uniformly approximated by polynomials with *real* coefficients, the situation changes when coefficients are restricted to be integers.\n\nConsider the linear function $f(x) = \\frac{x}{2}$ defined on the interval $[0,2]$. Find the smallest possible value for the maximum approximation error. That is, calculate the value of $\\delta = \\inf_{P \\in \\mathcal{P}_{\\mathbb{Z}}} \\|f(x) - P(x)\\|_\\infty$. Express your final answer as a single real number.", "solution": "Let $f(x)=\\frac{x}{2}$ on $[0,2]$ and define \n$$\n\\delta=\\inf_{P\\in\\mathcal{P}_{\\mathbb{Z}}}\\|f-P\\|_{\\infty}.\n$$\nFor any $P(x)=\\sum_{k=0}^{n}a_{k}x^{k}$ with all $a_{k}\\in\\mathbb{Z}$, we have\n$$\nP(0)=a_{0}\\in\\mathbb{Z},\\qquad P(2)=\\sum_{k=0}^{n}a_{k}2^{k}\\in\\mathbb{Z}.\n$$\nMoreover, reducing modulo $2$ gives\n$$\nP(2)\\equiv a_{0}\\equiv P(0)\\pmod{2},\n$$\nso $P(0)$ and $P(2)$ have the same parity.\n\nAssume, for contradiction, that there exists $P\\in\\mathcal{P}_{\\mathbb{Z}}$ with\n$$\n\\|f-P\\|_{\\infty}1.\n$$\nThen, evaluating at the endpoints,\n$$\n|P(0)-f(0)|=|P(0)|1\\quad\\Rightarrow\\quad P(0)=0,\n$$\nand\n$$\n|P(2)-f(2)|=|P(2)-1|1\\quad\\Rightarrow\\quad P(2)=1.\n$$\nBut this contradicts the parity condition $P(2)\\equiv P(0)\\pmod{2}$, since $1\\not\\equiv 0\\pmod{2}$. Therefore no such $P$ exists, and we conclude\n$$\n\\delta\\geq 1.\n$$\n\nTo show this bound is sharp, take the constant polynomial $P(x)\\equiv 0\\in\\mathcal{P}_{\\mathbb{Z}}$. Then\n$$\n\\|f-P\\|_{\\infty}=\\max_{x\\in[0,2]}\\left|\\frac{x}{2}-0\\right|=\\max_{x\\in[0,2]}\\frac{x}{2}=1,\n$$\nso\n$$\n\\delta\\leq 1.\n$$\nCombining both inequalities yields\n$$\n\\delta=1.\n$$", "answer": "$$\\boxed{1}$$", "id": "1904669"}, {"introduction": "The power of the Weierstrass theorem is best appreciated by understanding what fails and why. This problem asks you to quantify the minimum possible uniform error when approximating a continuous function with a simple step function, a fundamentally discontinuous approximant. This exercise vividly illustrates the nature of uniform convergence and clarifies why the continuity of polynomials is essential for their universal approximating power. [@problem_id:2330442]", "problem": "While the Weierstrass approximation theorem guarantees that any continuous function on a closed interval can be uniformly approximated by polynomials, the situation with other families of functions, like step functions, reveals important structural properties of function spaces.\n\nConsider the continuous function $f(x) = \\cos\\left(\\frac{\\pi x}{2}\\right)$ on the closed interval $[0, 1]$. We wish to approximate this function using a simple type of step function. Let $S$ be the set of all step functions $s(x)$ on $[0, 1]$ that are constant on each of the two subintervals partitioned by $x=1/2$. Specifically, any function $s \\in S$ has the form:\n$$\ns(x) = \\begin{cases} c_1  \\text{for } 0 \\le x  1/2 \\\\ c_2  \\text{for } 1/2 \\le x \\le 1 \\end{cases}\n$$\nwhere $c_1$ and $c_2$ are arbitrary real constants.\n\nYour task is to determine the smallest possible value of the uniform error when approximating $f(x)$ with a function from the set $S$. This error is defined by the quantity $E = \\inf_{s \\in S} \\left( \\sup_{x \\in [0, 1]} |f(x) - s(x)| \\right)$.\n\nExpress your final answer as an exact analytic expression.", "solution": "We consider $f(x)=\\cos\\left(\\frac{\\pi x}{2}\\right)$ on $[0,1]$ and step functions $s \\in S$ of the form $s(x)=c_{1}$ on $[0,\\frac{1}{2})$ and $s(x)=c_{2}$ on $[\\frac{1}{2},1]$. For any fixed $(c_{1},c_{2})$, the uniform error equals\n$$\n\\sup_{x \\in [0,1]}|f(x)-s(x)|=\\max\\left\\{\\sup_{x \\in [0,\\frac{1}{2}]}|f(x)-c_{1}|,\\ \\sup_{x \\in [\\frac{1}{2},1]}|f(x)-c_{2}|\\right\\}.\n$$\nBecause $c_{1}$ and $c_{2}$ are independent, we have\n$$\n\\inf_{c_{1},c_{2}}\\max\\left\\{\\sup_{[0,\\frac{1}{2}]}|f-c_{1}|,\\ \\sup_{[\\frac{1}{2},1]}|f-c_{2}|\\right\\}\n=\n\\max\\left\\{\\inf_{c_{1}}\\sup_{[0,\\frac{1}{2}]}|f-c_{1}|,\\ \\inf_{c_{2}}\\sup_{[\\frac{1}{2},1]}|f-c_{2}|\\right\\}.\n$$\nIndeed, for any $c_{1},c_{2}$, the left-hand side is at least the right-hand side; conversely, choosing $c_{1}$ and $c_{2}$ to approximate their respective infima within any $\\varepsilon0$ yields the reverse inequality in the limit.\n\nFor a continuous function on a compact interval $I$, the best uniform approximation by a constant $c$ is obtained by taking the midpoint of the range. Writing $M=\\max_{x \\in I} f(x)$ and $m=\\min_{x \\in I} f(x)$, for any $c \\in \\mathbb{R}$ one has\n$$\n\\sup_{x \\in I}|f(x)-c| \\geq \\max\\{M-c,\\ c-m\\},\n$$\nwith equality for $c \\in [m,M]$. The quantity $\\max\\{M-c,\\ c-m\\}$ is minimized when $M-c=c-m$, i.e., $c=\\frac{M+m}{2}$, and the minimal error is\n$$\n\\frac{M-m}{2}.\n$$\n\nNow analyze $f$ on each subinterval. The derivative is\n$$\nf'(x)=-\\frac{\\pi}{2}\\sin\\left(\\frac{\\pi x}{2}\\right),\n$$\nwhich is strictly negative on $(0,1]$ since $\\sin\\left(\\frac{\\pi x}{2}\\right)0$ for $x \\in (0,1]$. Hence $f$ is strictly decreasing on $[0,1]$, so on any subinterval $[a,b] \\subset [0,1]$ we have $\\max f=f(a)$ and $\\min f=f(b)$.\n\nOn $I_{1}=[0,\\frac{1}{2}]$:\n$$\nM_{1}=f(0)=\\cos(0)=1,\\quad m_{1}=f\\!\\left(\\frac{1}{2}\\right)=\\cos\\!\\left(\\frac{\\pi}{4}\\right)=\\frac{\\sqrt{2}}{2}.\n$$\nThus the minimal uniform error on $I_{1}$ is\n$$\nE_{1}=\\frac{M_{1}-m_{1}}{2}=\\frac{1-\\cos\\!\\left(\\frac{\\pi}{4}\\right)}{2}=\\frac{1-\\frac{\\sqrt{2}}{2}}{2}=\\frac{2-\\sqrt{2}}{4}.\n$$\n\nOn $I_{2}=\\left[\\frac{1}{2},1\\right]$:\n$$\nM_{2}=f\\!\\left(\\frac{1}{2}\\right)=\\cos\\!\\left(\\frac{\\pi}{4}\\right)=\\frac{\\sqrt{2}}{2},\\quad m_{2}=f(1)=\\cos\\!\\left(\\frac{\\pi}{2}\\right)=0.\n$$\nThus the minimal uniform error on $I_{2}$ is\n$$\nE_{2}=\\frac{M_{2}-m_{2}}{2}=\\frac{\\cos\\!\\left(\\frac{\\pi}{4}\\right)-0}{2}=\\frac{\\frac{\\sqrt{2}}{2}}{2}=\\frac{\\sqrt{2}}{4}.\n$$\n\nTherefore the best possible uniform error over $[0,1]$ using functions in $S$ is\n$$\nE=\\max\\{E_{1},E_{2}\\}=\\max\\left\\{\\frac{2-\\sqrt{2}}{4},\\ \\frac{\\sqrt{2}}{4}\\right\\}=\\frac{\\sqrt{2}}{4},\n$$\nsince $\\sqrt{2}2-\\sqrt{2}$.", "answer": "$$\\boxed{\\frac{\\sqrt{2}}{4}}$$", "id": "2330442"}]}