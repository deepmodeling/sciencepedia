{"hands_on_practices": [{"introduction": "The concept of separability hinges on the ability to approximate any element in a space with elements from a simpler, countable set. This first exercise provides a hands-on feel for this approximation process within the space $c_0$ of sequences converging to zero. By explicitly calculating the error between a sequence and its truncated approximations, you will gain a concrete understanding of how a sequence with finite support can be \"close\" to an infinite sequence under the supremum norm, a foundational idea behind the separability of $c_0$ [@problem_id:1879313].", "problem": "Let $c_0$ be the vector space of all real-valued sequences $(a_n)_{n=1}^\\infty$ that converge to zero, i.e., $\\lim_{n \\to \\infty} a_n = 0$. This space is equipped with the supremum norm, defined as $\\|a\\|_\\infty = \\sup_{n \\ge 1} |a_n|$.\n\nAn important property of $c_0$ is its separability, which can be demonstrated by approximating any sequence in $c_0$ with sequences that have a finite number of non-zero rational terms.\n\nConsider the sequence $x = (x_n)_{n=1}^\\infty$ in $c_0$, where $x_n = \\frac{(-1)^n}{n}$.\nLet us construct an approximating sequence of sequences, $(y^{(k)})_{k=1}^\\infty$, where for each integer $k \\ge 1$, the sequence $y^{(k)} = (y^{(k)}_n)_{n=1}^\\infty$ is defined as the truncation of $x$ after the $k$-th term. Specifically, its components are:\n$$\ny^{(k)}_n =\n\\begin{cases}\nx_n & \\text{if } n \\le k \\\\\n0 & \\text{if } n > k\n\\end{cases}\n$$\nThis sequence of sequences $(y^{(k)})_{k=1}^\\infty$ converges to $x$ in the supremum norm.\n\nDetermine a closed-form expression for the distance $\\|y^{(k)} - x\\|_\\infty$ as a function of the integer $k$, for $k \\ge 1$.", "solution": "We are given $x=(x_{n})_{n=1}^{\\infty}$ with $x_{n}=\\frac{(-1)^{n}}{n}$ and, for each integer $k\\ge 1$, $y^{(k)}=(y^{(k)}_{n})_{n=1}^{\\infty}$ defined by $y^{(k)}_{n}=x_{n}$ if $n\\le k$ and $y^{(k)}_{n}=0$ if $n>k$. Consider the difference sequence $d^{(k)}=(d^{(k)}_{n})_{n=1}^{\\infty}$ given by\n$$\nd^{(k)}_{n}=y^{(k)}_{n}-x_{n}.\n$$\nBy the definition of $y^{(k)}$, for $n\\le k$ we have $d^{(k)}_{n}=x_{n}-x_{n}=0$, and for $n>k$ we have $d^{(k)}_{n}=0-x_{n}=-\\frac{(-1)^{n}}{n}$. Therefore,\n$$\n|d^{(k)}_{n}|=\\begin{cases}\n0 & \\text{if } n\\le k,\\\\\n\\frac{1}{n} & \\text{if } n>k.\n\\end{cases}\n$$\nThe supremum norm of the difference is\n$$\n\\|y^{(k)}-x\\|_{\\infty}=\\sup_{n\\ge 1}|d^{(k)}_{n}|=\\sup_{n>k}\\frac{1}{n}.\n$$\nThe function $n\\mapsto \\frac{1}{n}$ is strictly decreasing on the positive integers, hence for $n>k$ we have $\\frac{1}{n}\\le \\frac{1}{k+1}$ with equality at $n=k+1$. Therefore,\n$$\n\\|y^{(k)}-x\\|_{\\infty}=\\frac{1}{k+1}.\n$$\nThis gives the desired closed-form expression as a function of $k\\ge 1$.", "answer": "$$\\boxed{\\frac{1}{k+1}}$$", "id": "1879313"}, {"introduction": "Building on the idea of approximation, this practice moves from merely calculating error to actively constructing an approximating element within the $\\ell_1$ space. This problem challenges you to find a specific element from a proposed dense set (rational sequences with finite support) that lies within a given distance of a target sequence. This task makes the abstract definition of a dense set tangible and demonstrates a practical method for proving separability using the $\\ell_1$ norm, $d(x,y) = \\sum_{n=1}^\\infty |x_n - y_n|$ [@problem_id:1879301].", "problem": "The space of all sequences $x=(x_n)_{n=1}^\\infty$ of real numbers for which the series $\\sum_{n=1}^\\infty |x_n|$ converges is denoted by $\\ell_1$. The distance between two sequences $x, y \\in \\ell_1$ is defined by the metric $d(x,y) = \\sum_{n=1}^\\infty |x_n - y_n|$.\n\nConsider the sequence $x \\in \\ell_1$ where its terms are given by $x_n = \\frac{1}{n^2}$ for each positive integer $n$.\n\nA sequence $y = (y_n)_{n=1}^\\infty$ is called a rational sequence with finite support if all its terms $y_n$ are rational numbers and there exists a positive integer $N$ such that $y_n=0$ for all $n > N$.\n\nFind one specific example of a rational sequence with finite support, $y$, such that the distance $d(x, y)$ is less than $0.1$. Provide your answer as the finite sequence of its non-zero rational terms $(y_1, y_2, \\dots, y_N)$ written as exact fractions.", "solution": "Let the given sequence be $x = (x_n)_{n=1}^\\infty$ with $x_n = \\frac{1}{n^2}$. We are looking for a sequence $y = (y_n)_{n=1}^\\infty$ that has rational terms and finite support, such that the distance $d(x,y) = \\sum_{n=1}^\\infty |x_n - y_n|$ is less than $0.1$.\n\nA sequence $y$ having finite support means there exists a positive integer $N$ such that $y_n=0$ for all $n > N$. The distance metric can be split based on this integer $N$:\n$$ d(x,y) = \\sum_{n=1}^N |x_n - y_n| + \\sum_{n=N+1}^\\infty |x_n - y_n| $$\nSince $y_n = 0$ for $n > N$, the expression becomes:\n$$ d(x,y) = \\sum_{n=1}^N \\left|\\frac{1}{n^2} - y_n\\right| + \\sum_{n=N+1}^\\infty \\left|\\frac{1}{n^2} - 0\\right| $$\n$$ d(x,y) = \\sum_{n=1}^N \\left|\\frac{1}{n^2} - y_n\\right| + \\sum_{n=N+1}^\\infty \\frac{1}{n^2} $$\nOur goal is to find a suitable integer $N$ and rational numbers $y_1, y_2, \\dots, y_N$ such that this sum is less than $0.1$.\n\nA straightforward strategy is to make the first sum equal to zero. We can achieve this by choosing $y_n$ to be exactly equal to $x_n$ for $n=1, \\dots, N$. The terms $x_n = \\frac{1}{n^2}$ are all rational numbers, so this choice satisfies the condition that $y_n$ must be rational.\n\nLet's set $y_n = \\frac{1}{n^2}$ for $1 \\le n \\le N$, and $y_n = 0$ for $n > N$.\nWith this choice, the first sum becomes:\n$$ \\sum_{n=1}^N \\left|\\frac{1}{n^2} - \\frac{1}{n^2}\\right| = \\sum_{n=1}^N 0 = 0 $$\nThe distance then simplifies to the tail of the series for $x$:\n$$ d(x,y) = \\sum_{n=N+1}^\\infty \\frac{1}{n^2} $$\nNow, we need to find an integer $N$ such that this tail sum is less than $0.1$:\n$$ \\sum_{n=N+1}^\\infty \\frac{1}{n^2} < 0.1 $$\nTo find such an $N$, we can bound the sum using an integral. For a positive, decreasing function $f(t)$, we have the inequality $\\sum_{n=k}^\\infty f(n) < \\int_{k-1}^\\infty f(t) dt$. A tighter and more direct bound for this tail sum is $\\sum_{n=N+1}^\\infty f(n) < \\int_{N}^\\infty f(t) dt$. Let's use this bound with $f(t) = \\frac{1}{t^2}$.\n$$ \\sum_{n=N+1}^\\infty \\frac{1}{n^2} < \\int_N^\\infty \\frac{1}{t^2} dt $$\nWe compute the integral:\n$$ \\int_N^\\infty \\frac{1}{t^2} dt = \\left[ -\\frac{1}{t} \\right]_N^\\infty = \\lim_{b \\to \\infty} \\left(-\\frac{1}{b}\\right) - \\left(-\\frac{1}{N}\\right) = 0 + \\frac{1}{N} = \\frac{1}{N} $$\nSo, we need to find an $N$ that satisfies the condition:\n$$ \\frac{1}{N} < 0.1 $$\n$$ \\frac{1}{N} < \\frac{1}{10} $$\nThis implies $N > 10$. The smallest integer value for $N$ that satisfies this condition is $N=11$.\n\nLet's choose $N=11$. We define our sequence $y$ as:\n$$ y_n = \\begin{cases} \\frac{1}{n^2} & \\text{for } 1 \\le n \\le 11 \\\\ 0 & \\text{for } n > 11 \\end{cases} $$\nThis sequence $y$ consists of rational numbers and has finite support. The distance is $d(x,y) = \\sum_{n=12}^\\infty \\frac{1}{n^2}$. Based on our calculation, this distance is bounded by $\\int_{11}^\\infty \\frac{1}{t^2} dt = \\frac{1}{11}$.\nSince $\\frac{1}{11} \\approx 0.0909$, which is less than $0.1$, our choice of $y$ is a valid solution.\n\nThe non-zero terms of this sequence $y$ are $(y_1, y_2, \\dots, y_{11})$, where $y_n = \\frac{1}{n^2}$.\nExplicitly, these terms are:\n$y_1 = \\frac{1}{1^2} = 1$\n$y_2 = \\frac{1}{2^2} = \\frac{1}{4}$\n$y_3 = \\frac{1}{3^2} = \\frac{1}{9}$\n$y_4 = \\frac{1}{4^2} = \\frac{1}{16}$\n$y_5 = \\frac{1}{5^2} = \\frac{1}{25}$\n$y_6 = \\frac{1}{6^2} = \\frac{1}{36}$\n$y_7 = \\frac{1}{7^2} = \\frac{1}{49}$\n$y_8 = \\frac{1}{8^2} = \\frac{1}{64}$\n$y_9 = \\frac{1}{9^2} = \\frac{1}{81}$\n$y_{10} = \\frac{1}{10^2} = \\frac{1}{100}$\n$y_{11} = \\frac{1}{11^2} = \\frac{1}{121}$", "answer": "$$\\boxed{\\begin{pmatrix} 1 & \\frac{1}{4} & \\frac{1}{9} & \\frac{1}{16} & \\frac{1}{25} & \\frac{1}{36} & \\frac{1}{49} & \\frac{1}{64} & \\frac{1}{81} & \\frac{1}{100} & \\frac{1}{121} \\end{pmatrix}}$$", "id": "1879301"}, {"introduction": "The concept of separability extends beyond sequence spaces to spaces of functions, such as the space of continuously differentiable functions on an interval, $C^1([0,1])$. In these spaces, the notion of \"closeness\" or approximation can be more demanding, as the norm may need to account for both the function's values and its derivatives. This problem applies the celebrated Weierstrass Approximation Theorem in a more sophisticated context, requiring you to reason about how to construct polynomial approximations that converge in the stronger $C^1$ norm, which deepens your understanding of how the choice of norm critically influences the dense subsets of a function space [@problem_id:1879352].", "problem": "Let $C^1([0,1])$ be the vector space of real-valued functions defined on the closed interval $[0,1]$ that have a continuous first derivative. We equip this space with the norm $\\|f\\|_{C^1}$ defined as:\n$$\n\\|f\\|_{C^1} = \\sup_{x \\in [0,1]}|f(x)| + \\sup_{x \\in [0,1]}|f'(x)|\n$$\nLet $\\mathcal{P}$ denote the set of all polynomials with real coefficients, viewed as functions on $[0,1]$. A set $A$ is said to be dense in a normed space $X$ if for every element $x \\in X$ and for every real number $\\epsilon > 0$, there exists an element $a \\in A$ such that $\\|x-a\\| < \\epsilon$.\n\nEvaluate the following statement: \"The set of polynomials $\\mathcal{P}$ is dense in the space $(C^1([0,1]), \\|\\cdot\\|_{C^1})$.\"\n\nWhich of the following options provides the correct conclusion and reasoning?\n\nA. The statement is true. For any $f \\in C^1([0,1])$, its derivative $f'$ is continuous on $[0,1]$. By the Weierstrass Approximation Theorem, there exists a sequence of polynomials $\\{q_n\\}$ converging uniformly to $f'$. The sequence of polynomials defined by $p_n(x) = f(0) + \\int_{0}^{x} q_n(t) \\,dt$ then converges to $f$ in the $C^1$ norm.\n\nB. The statement is false. The Weierstrass Approximation Theorem guarantees that for any $f \\in C^1([0,1])$, there is a sequence of polynomials $\\{p_n\\}$ that converges uniformly to $f$. However, this does not imply that the sequence of derivatives $\\{p'_n\\}$ converges to $f'$.\n\nC. The statement is false. As a counterexample, consider the function $f(x) = \\exp(x)$. While it belongs to $C^1([0,1])$, its Taylor series, which is a sequence of polynomials, only converges on a specific interval, preventing approximation over the entire $[0,1]$ interval to arbitrary precision.\n\nD. The statement is true. Since any function in $C^1([0,1])$ is infinitely differentiable, its Taylor series expansion at $x=0$ provides a sequence of polynomials that converges to the function in the $C^1$ norm on the interval $[0,1]$.", "solution": "Let $f \\in C^{1}([0,1])$. Then $f'$ is continuous on $[0,1]$, so by the Weierstrass Approximation Theorem there exists a sequence of polynomials $\\{q_{n}\\}$ such that\n$$\n\\sup_{x \\in [0,1]} |q_{n}(x) - f'(x)| \\to 0 \\quad \\text{as } n \\to \\infty.\n$$\nDefine a sequence of polynomials $\\{p_{n}\\}$ by\n$$\np_{n}(x) = f(0) + \\int_{0}^{x} q_{n}(t)\\, dt.\n$$\nEach $p_{n}$ is a polynomial because it is a constant plus the integral of a polynomial. By the Fundamental Theorem of Calculus,\n$$\np_{n}'(x) = q_{n}(x),\n$$\nso\n$$\n\\sup_{x \\in [0,1]} |p_{n}'(x) - f'(x)| = \\sup_{x \\in [0,1]} |q_{n}(x) - f'(x)| \\to 0.\n$$\nFor the functions themselves, for each $x \\in [0,1]$,\n$$\n|p_{n}(x) - f(x)| = \\left| f(0) + \\int_{0}^{x} q_{n}(t)\\, dt - \\left(f(0) + \\int_{0}^{x} f'(t)\\, dt\\right) \\right|\n= \\left| \\int_{0}^{x} \\left(q_{n}(t) - f'(t)\\right) dt \\right|.\n$$\nHence,\n$$\n|p_{n}(x) - f(x)| \\le \\int_{0}^{x} |q_{n}(t) - f'(t)|\\, dt \\le x \\sup_{t \\in [0,1]} |q_{n}(t) - f'(t)| \\le \\sup_{t \\in [0,1]} |q_{n}(t) - f'(t)|.\n$$\nTaking the supremum over $x \\in [0,1]$ gives\n$$\n\\sup_{x \\in [0,1]} |p_{n}(x) - f(x)| \\le \\sup_{t \\in [0,1]} |q_{n}(t) - f'(t)| \\to 0.\n$$\nTherefore,\n$$\n\\|p_{n} - f\\|_{C^{1}} = \\sup_{x \\in [0,1]} |p_{n}(x) - f(x)| + \\sup_{x \\in [0,1]} |p_{n}'(x) - f'(x)|\n\\le 2 \\sup_{x \\in [0,1]} |q_{n}(x) - f'(x)| \\to 0.\n$$\nSince for every $f \\in C^{1}([0,1])$ we have constructed polynomials $p_{n}$ with $\\|p_{n} - f\\|_{C^{1}} \\to 0$, the set of polynomials is dense in $(C^{1}([0,1]), \\|\\cdot\\|_{C^{1}})$. This matches the reasoning in option A. Option B notes that uniform convergence of $p_{n}$ to $f$ does not imply convergence of derivatives, which is true but irrelevant here because the construction specifically approximates $f'$ and then integrates. Option C is incorrect because the Weierstrass theorem applies on $[0,1]$ regardless of Taylor series radius of convergence. Option D is false because $C^{1}$ functions need not be infinitely differentiable.", "answer": "$$\\boxed{A}$$", "id": "1879352"}]}