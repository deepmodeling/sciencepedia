{"hands_on_practices": [{"introduction": "We begin with a foundational exercise that explores the relationship between two of the most common norms on the vector space $\\mathbb{R}^n$: the 1-norm, $\\|x\\|_1$, and the infinity-norm, $\\|x\\|_\\infty$. This practice serves as a cornerstone for understanding norm equivalence. By finding the sharpest possible constants for the inequality $C_1 \\|x\\|_\\infty \\le \\|x\\|_1 \\le C_2 \\|x\\|_\\infty$, you will not only master the technique of bounding one norm by another but also discover how these \"exchange rates\" critically depend on the dimension $n$ of the space [@problem_id:1859231].", "problem": "In the field of functional analysis, a fundamental result states that all norms on a finite-dimensional vector space are equivalent. Consider the real vector space $\\mathbb{R}^n$. For any vector $x = (x_1, x_2, \\ldots, x_n) \\in \\mathbb{R}^n$, two of the most commonly used norms are the 1-norm (or Manhattan norm) and the infinity-norm (or maximum norm), defined as:\n$$ \\|x\\|_1 = \\sum_{i=1}^n |x_i| $$\n$$ \\|x\\|_\\infty = \\max_{1 \\le i \\le n} |x_i| $$\nThe equivalence of these norms implies that there exist positive constants $C_1$ and $C_2$, which may depend on the dimension $n$, such that the following inequality holds for all vectors $x \\in \\mathbb{R}^n$:\n$$ C_1 \\|x\\|_\\infty \\leq \\|x\\|_1 \\leq C_2 \\|x\\|_\\infty $$\nYour task is to find the *sharpest* possible constants for this relationship. This means determining the largest possible value for $C_1$ and the smallest possible value for $C_2$ for which the inequality is universally true.\n\nCalculate the product of these two sharpest constants, $C_1 C_2$, and express your answer as an analytic expression in terms of $n$.", "solution": "We want the largest $C_{1}$ and smallest $C_{2}$ such that for all $x=(x_{1},\\dots,x_{n})\\in\\mathbb{R}^{n}$,\n$$\nC_{1}\\|x\\|_{\\infty}\\le \\|x\\|_{1}\\le C_{2}\\|x\\|_{\\infty},\n$$\nwhere $\\|x\\|_{1}=\\sum_{i=1}^{n}|x_{i}|$ and $\\|x\\|_{\\infty}=\\max_{1\\le i\\le n}|x_{i}|$.\n\nFirst, since the maximum of the absolute values is one of the summands, we have\n$$\n\\|x\\|_{1}=\\sum_{i=1}^{n}|x_{i}|\\ge \\max_{1\\le i\\le n}|x_{i}|=\\|x\\|_{\\infty}.\n$$\nTherefore $\\|x\\|_{1}\\ge \\|x\\|_{\\infty}$ for all $x$, which shows the inequality holds with $C_{1}=1$. To see sharpness, consider the ratio $r(x)=\\|x\\|_{1}/\\|x\\|_{\\infty}$ for $x\\neq 0$. We have $r(x)\\ge 1$ by the above inequality, and for $x=t e_{j}$ with $t\\neq 0$ and $e_{j}$ a standard basis vector, $\\|x\\|_{1}=|t|$ and $\\|x\\|_{\\infty}=|t|$, so $r(x)=1$. Hence $\\inf_{x\\neq 0}r(x)=1$, and the largest possible $C_{1}$ is $C_{1}=1$.\n\nSecond, let $M=\\|x\\|_{\\infty}$. Then $|x_{i}|\\le M$ for each $i$, so\n$$\n\\|x\\|_{1}=\\sum_{i=1}^{n}|x_{i}|\\le \\sum_{i=1}^{n}M=nM=n\\|x\\|_{\\infty}.\n$$\nThus $r(x)\\le n$ for all $x\\neq 0$, so any admissible $C_{2}$ must satisfy $C_{2}\\ge \\sup_{x\\neq 0}r(x)$. Taking $x=(t,\\dots,t)$ with $t\\neq 0$ gives $\\|x\\|_{1}=n|t|$ and $\\|x\\|_{\\infty}=|t|$, so $r(x)=n$. Therefore $\\sup_{x\\neq 0}r(x)=n$, and the smallest possible $C_{2}$ is $C_{2}=n$.\n\nThe sharp constants are $C_{1}=1$ and $C_{2}=n$, so their product is $C_{1}C_{2}=n$.", "answer": "$$\\boxed{n}$$", "id": "1859231"}, {"introduction": "The powerful principle of norm equivalence in finite dimensions applies universally, not just to the familiar space $\\mathbb{R}^n$. This exercise challenges you to apply the same\n    reasoning to the vector space of $2 \\times 2$ matrices, a common object in linear algebra [@problem_id:2308369]. By calculating the equivalence constants between the Frobenius norm, $\\|A\\|_F$, and the maximum absolute entry norm, $\\|A\\|_{\\max}$, you will gain hands-on experience confirming that the geometric structure induced by different norms is fundamentally the same, regardless of the specific finite-dimensional setting.", "problem": "Consider the vector space $V = M_2(\\mathbb{R})$ of all $2 \\times 2$ matrices with real entries. For any matrix $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ in $V$, we define two different ways to measure its size, known as norms:\n\n1.  The **maximum absolute entry norm**, denoted by $\\|A\\|_{\\max}$, is given by $\\|A\\|_{\\max} = \\max\\{|a|, |b|, |c|, |d|\\}$.\n2.  The **Frobenius norm**, denoted by $\\|A\\|_{F}$, is given by $\\|A\\|_{F} = \\sqrt{a^2 + b^2 + c^2 + d^2}$.\n\nIt is a known result that for this space, there exist positive constants $C_1$ and $C_2$ such that for every non-zero matrix $A \\in V$, the following inequality holds:\n$$\nC_1 \\|A\\|_{\\max} \\leq \\|A\\|_{F} \\leq C_2 \\|A\\|_{\\max}\n$$\nDetermine the values of the constants $C_1$ and $C_2$ that make this inequality as tight as possible. Specifically, find the largest possible value for $C_1$ and the smallest possible value for $C_2$.\n\nPresent your answer for the constants $C_1$ and $C_2$, in that order.", "solution": "Identify $V$ with $\\mathbb{R}^{4}$ via the entries of $A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$. Let $m = \\|A\\|_{\\max} = \\max\\{|a|,|b|,|c|,|d|\\}$. Then, by definition of the Frobenius norm,\n$$\n\\|A\\|_{F} = \\sqrt{a^{2} + b^{2} + c^{2} + d^{2}}.\n$$\n\nFor the lower bound, note that at least one of $|a|,|b|,|c|,|d|$ equals $m$, hence $a^{2} + b^{2} + c^{2} + d^{2} \\geq m^{2}$. Therefore,\n$$\n\\|A\\|_{F} \\geq m = \\|A\\|_{\\max}.\n$$\nThis shows the inequality holds with $C_{1} = 1$. To see this is optimal, take $A$ with exactly one nonzero entry, say $A = \\begin{pmatrix} t & 0 \\\\ 0 & 0 \\end{pmatrix}$ with $t \\neq 0$. Then $\\|A\\|_{F} = |t| = \\|A\\|_{\\max}$, so any $C_{1} > 1$ would violate $C_{1}\\|A\\|_{\\max} \\leq \\|A\\|_{F}$.\n\nFor the upper bound, since each of $|a|,|b|,|c|,|d|$ is at most $m$, we have\n$$\na^{2} + b^{2} + c^{2} + d^{2} \\leq 4 m^{2},\n$$\nhence\n$$\n\\|A\\|_{F} \\leq 2 m = 2 \\|A\\|_{\\max}.\n$$\nThus the inequality holds with $C_{2} = 2$. To see minimality, take all entries equal to a common nonzero value $t$, i.e., $A = \\begin{pmatrix} t & t \\\\ t & t \\end{pmatrix}$ with $t \\neq 0$. Then $\\|A\\|_{\\max} = |t|$ and $\\|A\\|_{F} = \\sqrt{4 t^{2}} = 2|t|$, so any $C_{2}  2$ would fail.\n\nTherefore, the largest possible $C_{1}$ is $1$, and the smallest possible $C_{2}$ is $2$.", "answer": "$$\\boxed{\\begin{pmatrix} 1  2 \\end{pmatrix}}$$", "id": "2308369"}, {"introduction": "This final practice uncovers a profound link between the abstract theory of norm equivalence and a crucial concept from numerical linear algebra: the matrix condition number. Here, we investigate a norm defined by the coefficients of a vector in an arbitrary, non-orthogonal basis [@problem_id:1859204]. You will demonstrate that the optimal constants relating this custom norm to the standard Euclidean norm are determined by the operator norms of the basis-change matrix and its inverse. This reveals that equivalence constants are more than just theoretical bounds; they quantify the geometric distortion introduced by a change of basis and are directly related to the numerical stability of solving linear systems.", "problem": "Consider the vector space $V = \\mathbb{R}^n$ equipped with the standard Euclidean norm, denoted by $\\|\\cdot\\|_2$. Let $B = \\{b_1, b_2, \\dots, b_n\\}$ be a basis for $V$, where the basis vectors are not necessarily orthogonal. Any vector $x \\in V$ can be uniquely expressed as a linear combination of the basis vectors: $x = \\sum_{i=1}^n c_i b_i$. The vector of coefficients, $c = (c_1, c_2, \\dots, c_n)^T$, is the coordinate vector of $x$ with respect to the basis $B$.\n\nWe can define a new norm on $V$, called the *coefficient norm* with respect to $B$, as the Euclidean norm of the coordinate vector:\n$$ \\|x\\|_B = \\|c\\|_2 $$\nSince all norms on a finite-dimensional vector space are equivalent, there exist positive constants $m$ and $M$ such that for all $x \\in V$, the following inequality holds:\n$$ m \\|x\\|_B \\le \\|x\\|_2 \\le M \\|x\\|_B $$\nLet $P$ be the $n \\times n$ matrix whose columns are the basis vectors $\\{b_1, b_2, \\dots, b_n\\}$. Since $B$ is a basis, $P$ is an invertible matrix. Let the condition number of $P$ with respect to the 2-norm be denoted by $\\kappa_2(P)$. This is defined as $\\kappa_2(P) = \\|P\\|_{op} \\|P^{-1}\\|_{op}$, where $\\|A\\|_{op}$ is the operator norm of a matrix $A$ induced by the vector 2-norm.\n\nDetermine the value of the ratio $\\frac{M_{opt}}{m_{opt}}$, where $M_{opt}$ and $m_{opt}$ are the tightest possible constants (supremum and infimum of the ratio of norms) satisfying the equivalence inequality. Express your answer in terms of $\\kappa_2(P)$.", "solution": "Let $x \\in V$ and write $x = P c$ where $c$ is the coordinate vector in basis $B$. By definition, $\\|x\\|_{B} = \\|c\\|_{2}$. The ratio of norms for a given $x$ is\n$$\n\\frac{\\|x\\|_{2}}{\\|x\\|_{B}} = \\frac{\\|P c\\|_{2}}{\\|c\\|_{2}}.\n$$\nDefine\n$$\nM_{\\mathrm{opt}} = \\sup_{c \\neq 0} \\frac{\\|P c\\|_{2}}{\\|c\\|_{2}}, \\quad m_{\\mathrm{opt}} = \\inf_{c \\neq 0} \\frac{\\|P c\\|_{2}}{\\|c\\|_{2}}.\n$$\nBy the definition of the operator norm induced by the vector $2$-norm,\n$$\nM_{\\mathrm{opt}} = \\|P\\|_{op}.\n$$\nFor the lower extremum, use invertibility of $P$:\n$$\n\\|c\\|_{2} = \\|P^{-1} P c\\|_{2} \\le \\|P^{-1}\\|_{op} \\|P c\\|_{2},\n$$\nwhich implies\n$$\n\\|P c\\|_{2} \\ge \\frac{1}{\\|P^{-1}\\|_{op}} \\|c\\|_{2}.\n$$\nTaking the infimum over $c \\neq 0$ gives\n$$\nm_{\\mathrm{opt}} = \\frac{1}{\\|P^{-1}\\|_{op}}.\n$$\nTherefore, the ratio of the tightest constants is\n$$\n\\frac{M_{\\mathrm{opt}}}{m_{\\mathrm{opt}}} = \\|P\\|_{op} \\|P^{-1}\\|_{op} = \\kappa_{2}(P).\n$$\nBecause the operator $2$-norm equals the largest singular value and $\\|P^{-1}\\|_{op}$ equals the reciprocal of the smallest singular value, these extrema are attained (e.g., at the corresponding singular vectors), so the constants are tight.", "answer": "$$\\boxed{\\kappa_{2}(P)}$$", "id": "1859204"}]}