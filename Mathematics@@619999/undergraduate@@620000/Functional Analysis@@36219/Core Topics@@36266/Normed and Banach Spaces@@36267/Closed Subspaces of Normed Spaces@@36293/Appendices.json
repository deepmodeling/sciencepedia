{"hands_on_practices": [{"introduction": "A powerful method for proving a subspace is closed is to demonstrate that it is the kernel of a continuous linear functional. This exercise provides a concrete opportunity to apply this technique within the important Hilbert space $\\ell^2$ of square-summable sequences. To successfully solve it, you will need to verify the functional's continuity, a task that neatly combines the definition of boundedness with the Cauchy-Schwarz inequality [@problem_id:1848988].", "problem": "Let $\\ell^2$ be the Hilbert space of all sequences of complex numbers $x = (x_n)_{n=1}^{\\infty}$ such that the series $\\sum_{n=1}^\\infty |x_n|^2$ converges. The norm on this space is defined as $\\|x\\|_{\\ell^2} = \\left( \\sum_{n=1}^\\infty |x_n|^2 \\right)^{1/2}$.\n\nConsider the subset $M$ of $\\ell^2$ defined by the condition that the weighted sum of its elements is zero:\n$$M = \\left\\{ x = (x_n)_{n=1}^\\infty \\in \\ell^2 \\;\\middle|\\; \\sum_{n=1}^\\infty \\frac{x_n}{n} = 0 \\right\\}$$\n\nWhich of the following statements accurately describes the set $M$ with respect to the topology induced by the $\\ell^2$-norm?\n\nA. $M$ is a subspace of $\\ell^2$ but is not closed.\n\nB. $M$ is a closed subset of $\\ell^2$ but is not a subspace.\n\nC. $M$ is a closed subspace of $\\ell^2$.\n\nD. $M$ is an open subset of $\\ell^2$.\n\nE. $M$ is a dense subspace of $\\ell^2$.", "solution": "We define a linear functional $f:\\ell^{2}\\to \\mathbb{C}$ by\n$$\nf(x)=\\sum_{n=1}^{\\infty}\\frac{x_{n}}{n}.\n$$\nFirst, $f$ is well defined on all of $\\ell^{2}$. Indeed, for any $x\\in \\ell^{2}$, the Cauchyâ€“Schwarz inequality gives\n$$\n\\sum_{n=1}^{\\infty}\\left|\\frac{x_{n}}{n}\\right|\\leq \\left(\\sum_{n=1}^{\\infty}|x_{n}|^{2}\\right)^{1/2}\\left(\\sum_{n=1}^{\\infty}\\frac{1}{n^{2}}\\right)^{1/2}=\\|x\\|_{\\ell^{2}}\\left(\\sum_{n=1}^{\\infty}\\frac{1}{n^{2}}\\right)^{1/2}<\\infty,\n$$\nso the series defining $f(x)$ converges absolutely. Linearity follows from linearity of series:\n$$\nf(ax+by)=\\sum_{n=1}^{\\infty}\\frac{ax_{n}+by_{n}}{n}=a\\sum_{n=1}^{\\infty}\\frac{x_{n}}{n}+b\\sum_{n=1}^{\\infty}\\frac{y_{n}}{n}=af(x)+bf(y).\n$$\nMoreover, $f$ is continuous (bounded), since\n$$\n|f(x)|=\\left|\\sum_{n=1}^{\\infty}\\frac{x_{n}}{n}\\right|\\leq \\|x\\|_{\\ell^{2}}\\left(\\sum_{n=1}^{\\infty}\\frac{1}{n^{2}}\\right)^{1/2}.\n$$\nHence $M=\\ker f$ is a subspace of $\\ell^{2}$. To see that $M$ is closed, note that the kernel of any continuous linear functional is closed. Equivalently, if $(x^{(k)})_{k\\in\\mathbb{N}}\\subset M$ with $x^{(k)}\\to x$ in $\\ell^{2}$, then by continuity $f(x)=\\lim_{k\\to\\infty}f(x^{(k)})=0$, hence $x\\in M$.\n\nThe functional $f$ is nonzero, for example with $y=(1,0,0,\\dots)$ we have $f(y)=1\\neq 0$. Therefore $M=\\ker f$ is a proper subspace of $\\ell^{2}$, so it is not open (the only open subspace of a normed linear space is the whole space). Since $M$ is closed and proper, it is not dense in $\\ell^{2}$.\n\nThus $M$ is a closed subspace of $\\ell^{2}$.", "answer": "$$\\boxed{C}$$", "id": "1848988"}, {"introduction": "Not all subspaces are closed, and understanding these \"dense\" subspaces is crucial for the theory of approximation. This problem explores this concept through the fundamental example of sequences with finite support, $c_{00}$, within the space of sequences converging to zero, $c_0$ [@problem_id:1849001]. You will practice the essential technique of approximation by constructing a sequence of simpler elements to show how any element in $c_0$ can be reached as a limit.", "problem": "In the study of sequence spaces in functional analysis, we often consider various collections of real-valued sequences and the relationships between them. Let $c_{00}$ be the set of all real-valued sequences that have only a finite number of non-zero terms. Let $c_0$ be the set of all real-valued sequences that converge to zero. Both $c_{00}$ and $c_0$ are vector spaces over the real numbers.\n\nWe equip the space $c_0$ with the supremum norm, denoted by $\\|\\cdot\\|_{\\infty}$, which is defined for any sequence $x = (x_n)_{n=1}^{\\infty}$ in $c_0$ as:\n$$ \\|x\\|_{\\infty} = \\sup_{n \\geq 1} |x_n| $$\nWith this norm, $(c_0, \\|\\cdot\\|_{\\infty})$ becomes a normed vector space. It is clear that $c_{00}$ is a subspace of $c_0$.\n\nYour task is to determine the closure of the subspace $c_{00}$ within the normed space $(c_0, \\|\\cdot\\|_{\\infty})$.\n\nFor context, we also define the following sequence spaces:\n- $\\ell^1$: the space of absolutely summable sequences, i.e., sequences $x=(x_n)_{n=1}^{\\infty}$ for which $\\sum_{n=1}^{\\infty} |x_n| < \\infty$.\n- $\\ell^2$: the space of square-summable sequences, i.e., sequences $x=(x_n)_{n=1}^{\\infty}$ for which $\\sum_{n=1}^{\\infty} |x_n|^2 < \\infty$.\n- $\\ell^{\\infty}$: the space of all bounded sequences.\n\nWhich of the following sets represents the closure of $c_{00}$ in $c_0$?\n\nA. $c_{00}$\n\nB. $c_0$\n\nC. $\\ell^1$\n\nD. $\\ell^2$\n\nE. $\\ell^{\\infty}$", "solution": "We work in the normed space $(c_{0},\\|\\cdot\\|_{\\infty})$, where $\\|x\\|_{\\infty}=\\sup_{n\\geq 1}|x_{n}|$. The closure of $c_{00}$ in this norm is the set of all $x\\in c_{0}$ such that for every $\\varepsilon>0$ there exists $y\\in c_{00}$ with $\\|x-y\\|_{\\infty}<\\varepsilon$.\n\nFix any $x=(x_{n})\\in c_{0}$. Define its $N$-th truncation $x^{(N)}=(x^{(N)}_{n})$ by\n$$\nx^{(N)}_{n}=\n\\begin{cases}\nx_{n}, & n\\leq N,\\\\\n0, & n>N.\n\\end{cases}\n$$\nThen $x^{(N)}\\in c_{00}$ for every $N$. Compute the sup-norm distance:\n$$\n\\|x-x^{(N)}\\|_{\\infty}=\\sup_{n\\geq 1}|x_{n}-x^{(N)}_{n}|=\\sup_{n>N}|x_{n}|.\n$$\nSince $x\\in c_{0}$, we have $x_{n}\\to 0$ as $n\\to\\infty$. Define $s_{N}=\\sup_{n\\geq N}|x_{n}|$. The sequence $(s_{N})$ is monotonically decreasing and, by the definition of convergence to zero, for every $\\varepsilon>0$ there exists $N_{0}$ such that $|x_{n}|<\\varepsilon$ for all $n\\geq N_{0}$, hence $s_{N_{0}}\\leq\\varepsilon$. Therefore $s_{N}\\to 0$, which implies\n$$\n\\|x-x^{(N)}\\|_{\\infty}=\\sup_{n>N}|x_{n}|\\xrightarrow[N\\to\\infty]{}0.\n$$\nThus, for every $\\varepsilon>0$, there exists $N$ such that $\\|x-x^{(N)}\\|_{\\infty}<\\varepsilon$ with $x^{(N)}\\in c_{00}$. Hence every $x\\in c_{0}$ lies in the closure of $c_{00}$ in $(c_{0},\\|\\cdot\\|_{\\infty})$.\n\nBecause the closure is taken inside $c_{0}$, it is a subset of $c_{0}$. Combining both inclusions yields that the closure of $c_{00}$ in $(c_{0},\\|\\cdot\\|_{\\infty})$ is exactly $c_{0}$.\n\nAmong the options, this corresponds to $c_{0}$, i.e., choice B. For completeness: it cannot be $c_{00}$ since $c_{00}$ is not closed (e.g., $x_{n}=1/\\sqrt{n}\\in c_{0}\\setminus c_{00}$ is a uniform limit of its truncations in $c_{00}$); it cannot be $\\ell^{1}$ or $\\ell^{2}$ because the closure contains all of $c_{0}$, which strictly contains sequences not in $\\ell^{1}$ or $\\ell^{2}$; it cannot be $\\ell^{\\infty}$ because the closure is taken in $c_{0}$ and thus is contained in $c_{0}\\subsetneq \\ell^{\\infty}$.", "answer": "$$\\boxed{B}$$", "id": "1849001"}, {"introduction": "The property of being a closed subspace has profound geometric consequences, especially in Hilbert spaces, as it guarantees the existence of a unique best approximation. This problem shifts the focus from proving a subspace is closed to using this property to solve a tangible problem: finding the shortest distance from a given matrix to the subspace of anti-symmetric matrices [@problem_id:1848991]. This exercise guides you through a practical calculation involving orthogonal projection, connecting abstract theory with a concrete application in linear algebra.", "problem": "Consider the vector space $M_3(\\mathbb{R})$ of all $3 \\times 3$ matrices with real entries. This space is equipped with the Frobenius norm, defined for any matrix $A \\in M_3(\\mathbb{R})$ as $\\|A\\|_F = \\sqrt{\\sum_{i=1}^{3} \\sum_{j=1}^{3} (A_{ij})^2}$.\n\nLet $\\mathcal{K}_3$ be the subspace of $M_3(\\mathbb{R})$ consisting of all anti-symmetric matrices. A matrix $X$ is anti-symmetric if its transpose is equal to its negative, i.e., $X^T = -X$.\n\nThe distance from a matrix $M \\in M_3(\\mathbb{R})$ to the subspace $\\mathcal{K}_3$ is defined as $d(M, \\mathcal{K}_3) = \\inf_{X \\in \\mathcal{K}_3} \\|M - X\\|_F$.\n\nGiven the matrix\n$$\nM = \\begin{pmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{pmatrix}\n$$\ncalculate the distance $d(M, \\mathcal{K}_3)$. Express your answer as an exact value.", "solution": "We work in the inner product space of real matrices with the Frobenius inner product $\\langle A,B\\rangle=\\operatorname{tr}(A^{T}B)$ and norm $\\|A\\|_{F}=\\sqrt{\\langle A,A\\rangle}$. The space $M_{3}(\\mathbb{R})$ decomposes orthogonally as the direct sum of the symmetric and the anti-symmetric (skew-symmetric) subspaces:\n$$\nM = S + K,\\quad S = \\frac{M+M^{T}}{2}\\ \\text{(symmetric)},\\quad K = \\frac{M-M^{T}}{2}\\ \\text{(skew-symmetric)},\n$$\nwith $\\langle S, K\\rangle = 0$. The orthogonal projection of $M$ onto the skew-symmetric subspace $\\mathcal{K}_{3}$ is $K$, hence the closest point in $\\mathcal{K}_{3}$ to $M$ is $K$, and the distance from $M$ to $\\mathcal{K}_{3}$ equals the norm of the orthogonal component $S$:\n$$\nd(M,\\mathcal{K}_{3}) = \\|M - K\\|_{F} = \\|S\\|_{F} = \\left\\|\\frac{M+M^{T}}{2}\\right\\|_{F}.\n$$\n\nFor the given matrix\n$$\nM = \\begin{pmatrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{pmatrix},\n\\quad\nM^{T} = \\begin{pmatrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{pmatrix},\n$$\nwe compute the symmetric part\n$$\nS = \\frac{M+M^{T}}{2}\n= \\frac{1}{2}\\begin{pmatrix}\n2 & 6 & 10 \\\\\n6 & 10 & 14 \\\\\n10 & 14 & 18\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1 & 3 & 5 \\\\\n3 & 5 & 7 \\\\\n5 & 7 & 9\n\\end{pmatrix}.\n$$\nTherefore,\n$$\n\\|S\\|_{F}^{2} = 1^{2}+3^{2}+5^{2}+3^{2}+5^{2}+7^{2}+5^{2}+7^{2}+9^{2}\n= 35+83+155 = 273,\n$$\nso\n$$\nd(M,\\mathcal{K}_{3}) = \\|S\\|_{F} = \\sqrt{273}.\n$$", "answer": "$$\\boxed{\\sqrt{273}}$$", "id": "1848991"}]}