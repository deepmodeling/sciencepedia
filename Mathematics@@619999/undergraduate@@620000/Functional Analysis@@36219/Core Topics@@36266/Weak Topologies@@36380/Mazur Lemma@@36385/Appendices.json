{"hands_on_practices": [{"introduction": "To build intuition for Mazur's Lemma, we begin with the most fundamental example: the standard orthonormal basis $\\{e_n\\}$ in the Hilbert space $\\ell^2$. While this sequence converges weakly to the zero vector, it fails to converge in norm. This exercise [@problem_id:1869444] invites you to see the magic of averaging in action by calculating the norm of the simplest possible sequence of convex combinations, the arithmetic means. This hands-on calculation provides a concrete verification of how convex combinations can transform a weakly convergent sequence into a strongly convergent one.", "problem": "Consider the Hilbert space $\\ell^2$, which consists of all square-summable real sequences $x = (x_1, x_2, x_3, \\dots)$ such that the series $\\sum_{k=1}^\\infty x_k^2$ converges. The norm on this space is defined as $\\|x\\|_{\\ell^2} = \\left(\\sum_{k=1}^\\infty x_k^2\\right)^{1/2}$.\n\nLet $\\{e_n\\}_{n=1}^\\infty$ be the standard orthonormal basis for $\\ell^2$, where the vector $e_n$ is a sequence with a $1$ in the $n$-th position and zeros in all other positions.\n\nFor any positive integer $N$, we can construct a new vector, $y_N$, by taking the arithmetic mean of the first $N$ basis vectors:\n$$y_N = \\frac{1}{N} \\sum_{n=1}^N e_n$$\nThis vector represents a simple averaging process within the space. To understand the properties of this averaging, we are interested in the magnitude of the resulting vector.\n\nDetermine a closed-form expression for the squared norm, $\\|y_N\\|_{\\ell^2}^2$, as a function of $N$.", "solution": "The problem asks for the squared norm of the vector $y_N = \\frac{1}{N} \\sum_{n=1}^N e_n$ in the Hilbert space $\\ell^2$.\n\nThe squared norm of a vector $v$ in a Hilbert space is given by the inner product of the vector with itself: $\\|v\\|^2 = \\langle v, v \\rangle$. Applying this to our vector $y_N$:\n$$ \\|y_N\\|_{\\ell^2}^2 = \\left\\langle y_N, y_N \\right\\rangle $$\n\nSubstitute the definition of $y_N$ into the inner product:\n$$ \\|y_N\\|_{\\ell^2}^2 = \\left\\langle \\frac{1}{N} \\sum_{n=1}^N e_n, \\frac{1}{N} \\sum_{m=1}^N e_m \\right\\rangle $$\n\nUsing the properties of the inner product, we can pull the constant factors out. The scalar $\\frac{1}{N}$ from the first argument comes out as $\\frac{1}{N}$, and the scalar $\\frac{1}{N}$ from the second argument comes out as its complex conjugate, which is also $\\frac{1}{N}$ since it is a real number.\n$$ \\|y_N\\|_{\\ell^2}^2 = \\frac{1}{N^2} \\left\\langle \\sum_{n=1}^N e_n, \\sum_{m=1}^N e_m \\right\\rangle $$\n\nNext, we use the linearity of the inner product to expand the sums:\n$$ \\|y_N\\|_{\\ell^2}^2 = \\frac{1}{N^2} \\sum_{n=1}^N \\sum_{m=1}^N \\langle e_n, e_m \\rangle $$\n\nThe problem states that $\\{e_n\\}_{n=1}^\\infty$ is an orthonormal basis. By the definition of an orthonormal set, the inner product of any two basis vectors is given by the Kronecker delta:\n$$ \\langle e_n, e_m \\rangle = \\delta_{nm} = \\begin{cases} 1  \\text{if } n=m \\\\ 0  \\text{if } n \\neq m \\end{cases} $$\n\nSubstituting this into our expression, the inner sum over $m$ simplifies. For a fixed $n$, the term $\\langle e_n, e_m \\rangle$ is non-zero only when $m=n$.\n$$ \\|y_N\\|_{\\ell^2}^2 = \\frac{1}{N^2} \\sum_{n=1}^N \\left( \\sum_{m=1}^N \\delta_{nm} \\right) $$\nThe inner sum $\\sum_{m=1}^N \\delta_{nm}$ evaluates to $1$, because for each $n \\in \\{1, \\dots, N\\}$, there is exactly one value of $m$ in the same range such that $m=n$.\n\nSo the expression simplifies to:\n$$ \\|y_N\\|_{\\ell^2}^2 = \\frac{1}{N^2} \\sum_{n=1}^N 1 $$\n\nThe sum $\\sum_{n=1}^N 1$ is simply $N$.\n$$ \\|y_N\\|_{\\ell^2}^2 = \\frac{1}{N^2} \\cdot N = \\frac{1}{N} $$\n\nThus, the squared norm of $y_N$ is $\\frac{1}{N}$.\n\nAlternatively, one can use the Pythagorean theorem for orthogonal vectors. Since the vectors $\\{e_n\\}$ are mutually orthogonal, the squared norm of their sum is the sum of their squared norms.\nFirst, pull out the constant:\n$$ \\|y_N\\|_{\\ell^2}^2 = \\left\\| \\frac{1}{N} \\sum_{n=1}^N e_n \\right\\|^2 = \\frac{1}{N^2} \\left\\| \\sum_{n=1}^N e_n \\right\\|^2 $$\nBy the generalized Pythagorean theorem:\n$$ \\left\\| \\sum_{n=1}^N e_n \\right\\|^2 = \\sum_{n=1}^N \\|e_n\\|^2 $$\nSince the basis is orthonormal, $\\|e_n\\| = 1$ for all $n$. Therefore, $\\|e_n\\|^2 = 1^2 = 1$.\n$$ \\sum_{n=1}^N \\|e_n\\|^2 = \\sum_{n=1}^N 1 = N $$\nSubstituting this back, we get:\n$$ \\|y_N\\|_{\\ell^2}^2 = \\frac{1}{N^2} \\cdot N = \\frac{1}{N} $$\nBoth methods yield the same result.", "answer": "$$\\boxed{\\frac{1}{N}}$$", "id": "1869444"}, {"introduction": "Having explored the discrete sequence space $\\ell^2$, we now turn our attention to the continuous function space $L^1[0,1]$. This practice [@problem_id:1869418] presents a sequence of \"shrinking\" indicator functions and asks you to analyze their convergence. You will discover that this sequence already converges strongly to its weak limit, offering a different perspective on Mazur's Lemma and reinforcing that its conclusion holds universally, even in cases where it might seem trivial.", "problem": "Consider the Banach space $X = L^1[0,1]$, which consists of all Lebesgue integrable functions on the interval $[0,1]$, equipped with the norm $\\|f\\|_1 = \\int_0^1 |f(x)| dx$. Let a sequence of functions $\\{f_n\\}_{n=1}^{\\infty}$ in this space be defined by $f_n(x) = \\chi_{[1/n, 2/n]}(x)$, where $\\chi_S$ is the indicator function of a set $S$.\n\nThis problem consists of two parts: first, identifying the weak limit of the sequence $\\{f_n\\}$, and second, correctly stating the conclusion of Mazur's lemma as it applies to this sequence. Recall that a sequence $\\{f_n\\}$ converges weakly to $f$ in $L^1[0,1]$ if for every function $g$ in the dual space $(L^1[0,1])^* = L^\\infty[0,1]$, the following holds:\n$$ \\lim_{n \\to \\infty} \\int_0^1 f_n(x)g(x)dx = \\int_0^1 f(x)g(x)dx $$\nMazur's lemma relates weak convergence to strong (norm) convergence via convex combinations.\n\nBased on your analysis of the sequence $\\{f_n\\}$, select the option that correctly identifies both the weak limit and the conclusion of Mazur's lemma.\n\n- A: The weak limit is the zero function $f(x)=0$. Mazur's lemma concludes that there exists a sequence $\\{g_N\\}$, where each $g_N$ is a convex combination of $\\{f_1, \\dots, f_N\\}$, such that $\\{g_N\\}$ converges strongly (in norm) to the zero function.\n\n- B: The sequence converges strongly but not weakly to the zero function. Mazur's lemma is not applicable.\n\n- C: The weak limit is the zero function $f(x)=0$. Mazur's lemma concludes that the sequence $\\{f_n\\}$ must be bounded in $L^1[0,1]$.\n\n- D: The weak limit of $\\{f_n\\}$ does not exist in $L^1[0,1]$. Therefore, Mazur's lemma cannot be applied.", "solution": "We work in $X=L^{1}[0,1]$ with norm $\\|f\\|_{1}=\\int_{0}^{1}|f(x)|\\,dx$, and define $f_{n}(x)=\\chi_{[1/n,\\,2/n]}(x)$.\n\nFirst, compute the $L^{1}$-norms to assess strong convergence. Since $f_{n}$ is an indicator function of an interval of length $\\lambda([1/n,2/n])=2/n-1/n=1/n$, we have\n$$\n\\|f_{n}\\|_{1}=\\int_{0}^{1}|f_{n}(x)|\\,dx=\\int_{1/n}^{2/n}1\\,dx=\\frac{1}{n}\\to 0 \\quad \\text{as } n\\to\\infty.\n$$\nTherefore $f_{n}\\to 0$ strongly in $L^{1}[0,1]$.\n\nSecond, verify weak convergence to $0$. The dual of $L^{1}[0,1]$ is $L^{\\infty}[0,1]$ with the pairing $\\langle f,g\\rangle=\\int_{0}^{1} f(x)g(x)\\,dx$. For arbitrary $g\\in L^{\\infty}[0,1]$, we estimate\n$$\n\\left|\\int_{0}^{1} f_{n}(x)g(x)\\,dx\\right|=\\left|\\int_{1/n}^{2/n} g(x)\\,dx\\right|\\leq \\|g\\|_{\\infty}\\,\\lambda([1/n,2/n])=\\|g\\|_{\\infty}\\cdot \\frac{1}{n}\\to 0.\n$$\nHence, for every $g\\in L^{\\infty}[0,1]$,\n$$\n\\lim_{n\\to\\infty}\\int_{0}^{1} f_{n}(x)g(x)\\,dx=0=\\int_{0}^{1} 0\\cdot g(x)\\,dx,\n$$\nwhich shows $f_{n}\\rightharpoonup 0$ weakly in $L^{1}[0,1]$. Thus the weak limit is the zero function.\n\nThird, recall Mazur’s lemma: If $x_{n}\\rightharpoonup x$ in a normed space, then there exists a sequence $y_{N}$, where each $y_{N}$ is a finite convex combination of the $x_{n}$’s (and one can take $y_{N}\\in\\operatorname{conv}\\{x_{n}:n\\geq N\\}$), such that $y_{N}\\to x$ in norm. Applying this to $f_{n}\\rightharpoonup 0$ in $L^{1}[0,1]$, there exists a sequence $g_{N}$ of convex combinations of $\\{f_{n}\\}$ converging strongly to $0$. In the present case, since $f_{n}\\to 0$ already in norm, we may choose the specific convex combinations $g_{N}=f_{N}$, which are convex combinations of $\\{f_{1},\\dots,f_{N}\\}$, and these satisfy $\\|g_{N}-0\\|_{1}=\\|f_{N}\\|_{1}=1/N\\to 0$.\n\nTherefore, the correct option is that the weak limit is $0$, and Mazur’s lemma provides convex combinations (indeed, we can take $g_{N}=f_{N}$) that converge strongly to $0$. This matches option A.", "answer": "$$\\boxed{A}$$", "id": "1869418"}, {"introduction": "The final practice shifts our focus from direct computation to logical deduction, highlighting Mazur's Lemma as a powerful theoretical tool. Instead of constructing a convergent sequence, this thought experiment [@problem_id:1869440] asks what can be concluded if we know that *no* sequence of convex combinations can converge to zero. By applying the contrapositive of the lemma, you will develop a deeper appreciation for its role in proving fundamental results about the relationship between weak and strong convergence.", "problem": "Let $X$ be a real normed linear space. Consider a sequence of elements $\\{x_n\\}_{n=1}^{\\infty}$ in $X$. A finite convex combination of elements from this sequence is any vector $y$ of the form $y = \\sum_{i=1}^{N} \\alpha_i x_{m_i}$, where $N$ is a positive integer, $\\{m_i\\}_{i=1}^N$ are positive integers, each coefficient $\\alpha_i \\ge 0$, and $\\sum_{i=1}^{N} \\alpha_i = 1$.\n\nSuppose that for this particular sequence $\\{x_n\\}$, there exists a positive real number $\\delta  0$ such that for any finite convex combination $y$ of elements from $\\{x_n\\}$, the inequality $\\|y\\|  \\delta$ holds.\n\nBased on this information, what can be definitively concluded about the weak convergence of the sequence $\\{x_n\\}$ to the zero vector $0$?\n\nA. The sequence $\\{x_n\\}$ must converge weakly to the zero vector.\n\nB. The sequence $\\{x_n\\}$ cannot converge weakly to the zero vector.\n\nC. The sequence $\\{x_n\\}$ may or may not converge weakly to the zero vector; the given information is insufficient to decide.\n\nD. The sequence $\\{x_n\\}$ must converge strongly to a non-zero vector.\n\nE. The sequence $\\{x_n\\}$ is not a Cauchy sequence.", "solution": "We are given a real normed linear space $X$ and a sequence $\\{x_{n}\\}_{n=1}^{\\infty}\\subset X$. A finite convex combination of elements of the sequence is any $y$ of the form\n$$\ny=\\sum_{i=1}^{N}\\alpha_{i}x_{m_{i}},\n$$\nwith $N\\in\\mathbb{N}$, $m_{i}\\in\\mathbb{N}$, $\\alpha_{i}\\ge 0$, and $\\sum_{i=1}^{N}\\alpha_{i}=1$. The assumption is that there exists $\\delta0$ such that for every such $y$ one has\n$$\n\\|y\\|\\delta.\n$$\n\nWe analyze the possibility that $\\{x_{n}\\}$ converges weakly to $0$. Recall the definition: $\\{x_{n}\\}$ converges weakly to $0$ if and only if for every $f\\in X^*$,\n$$\nf(x_{n})\\to 0.\n$$\nWe will use the following standard result (Mazur's lemma/Mazur's theorem): If $x_{n}\\to x$ weakly in a normed linear space $X$, then there exists a sequence of finite convex combinations $y_{k}$ of elements from suitable tails of $\\{x_{n}\\}$ such that\n$$\n\\|y_{k}-x\\|\\to 0 \\quad \\text{as } k\\to\\infty.\n$$\nApply this with $x=0$. If $\\{x_{n}\\}$ converges weakly to $0$, then there exist finite convex combinations\n$$\ny_{k}=\\sum_{i=1}^{N_{k}}\\alpha_{i}^{(k)}x_{m_{i}^{(k)}}, \\quad \\alpha_{i}^{(k)}\\ge 0,\\quad \\sum_{i=1}^{N_{k}}\\alpha_{i}^{(k)}=1,\n$$\nsuch that\n$$\n\\|y_{k}\\|\\to 0 \\quad \\text{as } k\\to\\infty.\n$$\nBy the definition of limit in a normed space, this implies that for some $k_{0}\\in\\mathbb{N}$,\n$$\n\\|y_{k}\\|\\frac{\\delta}{2}\\quad \\text{for all } k\\ge k_{0}.\n$$\nHowever, each $y_{k}$ is a finite convex combination of elements of $\\{x_{n}\\}$, so the given assumption enforces\n$$\n\\|y_{k}\\|\\delta \\quad \\text{for all } k,\n$$\nwhich contradicts $\\|y_{k}\\|\\frac{\\delta}{2}$ for $k\\ge k_{0}$. Therefore, the hypothesis that $\\{x_{n}\\}$ converges weakly to $0$ is impossible.\n\nIt follows definitively that the sequence $\\{x_{n}\\}$ cannot converge weakly to the zero vector. Hence the correct choice is B, while none of the other options are entailed by the hypothesis.", "answer": "$$\\boxed{B}$$", "id": "1869440"}]}