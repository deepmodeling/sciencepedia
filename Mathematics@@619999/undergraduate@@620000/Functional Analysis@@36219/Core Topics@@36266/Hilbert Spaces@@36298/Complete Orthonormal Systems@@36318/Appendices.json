{"hands_on_practices": [{"introduction": "A foundational skill in functional analysis is the ability to construct an orthonormal set from a given set of linearly independent vectors. This exercise provides direct, hands-on practice with the Gram-Schmidt process, the fundamental algorithm for this task. By applying it to simple polynomials within the function space $L^2([0, 1])$, you will translate an abstract procedure into concrete calculations involving inner products defined by integrals.", "problem": "Consider the real Hilbert space $L^2([0, 1])$ of square-integrable functions on the interval $[0, 1]$, equipped with the inner product defined as $\\langle f, g \\rangle = \\int_0^1 f(t)g(t) dt$. Let $S = \\{v_1(t), v_2(t), v_3(t)\\}$ be an ordered set of linearly independent functions, where $v_1(t) = 1$, $v_2(t) = t$, and $v_3(t) = t^2$.\n\nBy applying the Gram-Schmidt orthonormalization process to the set $S$ in the given order, a set of orthonormal polynomials $\\{p_0(t), p_1(t), p_2(t)\\}$ is generated.\n\nDetermine the expression for the third polynomial, $p_2(t)$.", "solution": "We work in $L^{2}([0,1])$ with inner product $\\langle f,g\\rangle=\\int_{0}^{1}f(t)g(t)\\,dt$ and apply Gramâ€“Schmidt to $v_{1}(t)=1$, $v_{2}(t)=t$, $v_{3}(t)=t^{2}$.\n\nFirst, set $w_{1}=v_{1}$. Then $\\langle w_{1},w_{1}\\rangle=\\int_{0}^{1}1\\,dt=1$, hence $p_{0}=w_{1}/\\|w_{1}\\|=1$.\n\nNext, compute\n$$\nw_{2}=v_{2}-\\frac{\\langle v_{2},w_{1}\\rangle}{\\langle w_{1},w_{1}\\rangle}w_{1}=t-\\left(\\int_{0}^{1}t\\,dt\\right)\\cdot 1=t-\\frac{1}{2}.\n$$\nIts norm is\n$$\n\\|w_{2}\\|^{2}=\\int_{0}^{1}\\left(t-\\frac{1}{2}\\right)^{2}dt=\\int_{0}^{1}\\left(t^{2}-t+\\frac{1}{4}\\right)dt=\\frac{1}{3}-\\frac{1}{2}+\\frac{1}{4}=\\frac{1}{12},\n$$\nso $p_{1}=w_{2}/\\|w_{2}\\|=2\\sqrt{3}\\left(t-\\frac{1}{2}\\right)$.\n\nFor the third vector,\n$$\nw_{3}=v_{3}-\\frac{\\langle v_{3},w_{1}\\rangle}{\\langle w_{1},w_{1}\\rangle}w_{1}-\\frac{\\langle v_{3},w_{2}\\rangle}{\\langle w_{2},w_{2}\\rangle}w_{2}.\n$$\nCompute the inner products:\n$$\n\\langle v_{3},w_{1}\\rangle=\\int_{0}^{1}t^{2}\\,dt=\\frac{1}{3},\\qquad\n\\langle v_{3},w_{2}\\rangle=\\int_{0}^{1}t^{2}\\left(t-\\frac{1}{2}\\right)dt=\\int_{0}^{1}\\left(t^{3}-\\frac{1}{2}t^{2}\\right)dt=\\frac{1}{4}-\\frac{1}{6}=\\frac{1}{12}.\n$$\nSince $\\langle w_{2},w_{2}\\rangle=\\frac{1}{12}$, it follows that\n$$\nw_{3}=t^{2}-\\frac{1}{3}\\cdot 1-\\frac{\\frac{1}{12}}{\\frac{1}{12}}\\left(t-\\frac{1}{2}\\right)=t^{2}-\\frac{1}{3}-\\left(t-\\frac{1}{2}\\right)=t^{2}-t+\\frac{1}{6}.\n$$\nNow normalize $w_{3}$. Its norm squared is\n$$\n\\|w_{3}\\|^{2}=\\int_{0}^{1}\\left(t^{2}-t+\\frac{1}{6}\\right)^{2}dt\n=\\int_{0}^{1}\\left(t^{4}-2t^{3}+\\frac{4}{3}t^{2}-\\frac{1}{3}t+\\frac{1}{36}\\right)dt\n=\\frac{1}{5}-\\frac{1}{2}+\\frac{4}{9}-\\frac{1}{6}+\\frac{1}{36}=\\frac{1}{180}.\n$$\nThus $\\|w_{3}\\|=\\sqrt{\\frac{1}{180}}=\\frac{1}{6\\sqrt{5}}$, and the normalized polynomial is\n$$\np_{2}(t)=\\frac{w_{3}(t)}{\\|w_{3}\\|}=6\\sqrt{5}\\left(t^{2}-t+\\frac{1}{6}\\right)=\\sqrt{5}\\left(6t^{2}-6t+1\\right).\n$$", "answer": "$$\\boxed{\\sqrt{5}\\left(6t^{2}-6t+1\\right)}$$", "id": "1850529"}, {"introduction": "After constructing an orthonormal system [@problem_id:1850529], it is crucial to understand the property of 'completeness'. An orthonormal system is complete if it is not a proper subset of any other orthonormal system in the space. This exercise offers a powerful way to make this abstract concept concrete: by finding a specific non-zero vector that is orthogonal to an entire subsystem, you will decisively prove that the subsystem is not complete.", "problem": "Let $\\ell^2$ be the Hilbert space consisting of all infinite sequences of complex numbers $x = (x_1, x_2, x_3, \\ldots)$ for which the series $\\sum_{n=1}^{\\infty} |x_n|^2$ converges. The inner product for two vectors $x = (x_1, x_2, \\ldots)$ and $y = (y_1, y_2, \\ldots)$ in $\\ell^2$ is defined as $\\langle x, y \\rangle = \\sum_{n=1}^{\\infty} x_n \\overline{y_n}$, where $\\overline{y_n}$ is the complex conjugate of $y_n$.\n\nThe standard basis for $\\ell^2$ is the set of vectors $\\{e_n\\}_{n=1}^{\\infty}$, where for each $n$, the vector $e_n$ is the sequence that has a $1$ in the $n$-th position and $0$s in all other positions. This set is known to be a Complete Orthonormal System (C.O.N.S.) for $\\ell^2$. An orthonormal system is defined as 'complete' if the only vector in the space that is orthogonal to every vector in the system is the zero vector.\n\nNow, consider the subsystem $S_{odd} = \\{e_{2k-1}\\}_{k=1}^{\\infty}$, which is formed by taking only the basis vectors with odd indices (i.e., $e_1, e_3, e_5, \\ldots$).\n\nWhich one of the following non-zero vectors in $\\ell^2$ is orthogonal to every vector in the subsystem $S_{odd}$?\n\nA. $v_A = e_1$\n\nB. $v_B = e_2$\n\nC. $v_C = e_1 + e_3$\n\nD. $v_D = e_1 - e_2$\n\nE. $v_E = \\sum_{n=1}^{\\infty} \\frac{1}{n} e_n$", "solution": "The problem asks us to identify which of the given non-zero vectors is orthogonal to every vector in the set $S_{odd} = \\{e_{2k-1}\\}_{k=1}^{\\infty}$. A vector $v$ is orthogonal to every vector in $S_{odd}$ if its inner product with every vector in $S_{odd}$ is zero. That is, we must have $\\langle v, e_{2k-1} \\rangle = 0$ for all positive integers $k$.\n\nThe standard basis $\\{e_n\\}_{n=1}^{\\infty}$ is an orthonormal system, which means that the inner product of any two basis vectors is given by the Kronecker delta: $\\langle e_m, e_n \\rangle = \\delta_{mn}$, where $\\delta_{mn} = 1$ if $m=n$ and $\\delta_{mn} = 0$ if $m \\neq n$. This property is key to solving the problem.\n\nLet's test each of the given options:\n\n**Option A: $v_A = e_1$**\nWe need to check if $\\langle e_1, e_{2k-1} \\rangle = 0$ for all $k \\ge 1$. Let's test the case where $k=1$. The corresponding vector in $S_{odd}$ is $e_{2(1)-1} = e_1$. The inner product is $\\langle e_1, e_1 \\rangle = 1$. Since this is not equal to zero, $v_A$ is not orthogonal to all vectors in $S_{odd}$.\n\n**Option B: $v_B = e_2$**\nWe need to check if $\\langle e_2, e_{2k-1} \\rangle = 0$ for all $k \\ge 1$. Using the orthonormality property, this inner product is equal to $\\delta_{2, 2k-1}$. For any positive integer $k$, the number $2k-1$ is always an odd number (1, 3, 5, ...). The number 2 is an even number. Therefore, $2 \\neq 2k-1$ for any integer $k \\ge 1$. This implies that the Kronecker delta $\\delta_{2, 2k-1}$ is always 0. So, $\\langle e_2, e_{2k-1} \\rangle = 0$ for all $k \\ge 1$. This means the vector $e_2$ is orthogonal to every vector in the subsystem $S_{odd}$. Since $e_2$ is a non-zero vector, its existence demonstrates that $S_{odd}$ is not a complete system.\n\n**Option C: $v_C = e_1 + e_3$**\nWe check the orthogonality condition. Let's take the first vector in $S_{odd}$, which is $e_1$ (for $k=1$).\n$$ \\langle v_C, e_1 \\rangle = \\langle e_1 + e_3, e_1 \\rangle $$\nUsing the linearity of the inner product in the first argument:\n$$ \\langle e_1, e_1 \\rangle + \\langle e_3, e_1 \\rangle = 1 + 0 = 1 $$\nSince the result is not zero, $v_C$ is not orthogonal to all vectors in $S_{odd}$.\n\n**Option D: $v_D = e_1 - e_2$**\nAgain, let's test against the vector $e_1$ from $S_{odd}$.\n$$ \\langle v_D, e_1 \\rangle = \\langle e_1 - e_2, e_1 \\rangle = \\langle e_1, e_1 \\rangle - \\langle e_2, e_1 \\rangle = 1 - 0 = 1 $$\nThe result is not zero, so $v_D$ is not the correct choice.\n\n**Option E: $v_E = \\sum_{n=1}^{\\infty} \\frac{1}{n} e_n$**\nThis vector is in $\\ell^2$ because the series of squared coefficients $\\sum_{n=1}^{\\infty} |\\frac{1}{n}|^2 = \\sum_{n=1}^{\\infty} \\frac{1}{n^2} = \\frac{\\pi^2}{6}$ converges. We test for orthogonality against $e_1$ (for $k=1$).\n$$ \\langle v_E, e_1 \\rangle = \\left\\langle \\sum_{n=1}^{\\infty} \\frac{1}{n} e_n, e_1 \\right\\rangle $$\nDue to the continuity of the inner product, we can write:\n$$ \\sum_{n=1}^{\\infty} \\frac{1}{n} \\langle e_n, e_1 \\rangle = \\sum_{n=1}^{\\infty} \\frac{1}{n} \\delta_{n1} $$\nThis sum has only one non-zero term, which occurs when $n=1$. The value is $\\frac{1}{1} \\delta_{11} = 1$. Since the inner product is not zero, $v_E$ is not orthogonal to all vectors in $S_{odd}$.\n\nBased on the analysis of all options, only $v_B = e_2$ is orthogonal to every vector in the subsystem $S_{odd}$.", "answer": "$$\\boxed{B}$$", "id": "1850501"}, {"introduction": "Parseval's identity, $\\|x\\|^2 = \\sum_{n=1}^{\\infty} |\\langle x, e_n \\rangle|^2$, is a cornerstone result for complete orthonormal systems, acting as an infinite-dimensional Pythagorean theorem. But what happens if the system is merely orthogonal and not normalized to have unit length? This problem challenges you to derive the generalized form of this identity, revealing how the norms of the basis vectors are essential and deepening your understanding of the geometric principles at play.", "problem": "Let $H$ be a complex Hilbert space with an inner product denoted by $\\langle \\cdot, \\cdot \\rangle$ and its induced norm by $\\|x\\| = \\sqrt{\\langle x, x \\rangle}$. Consider a set of non-zero vectors $\\{v_n\\}_{n=1}^{\\infty}$ that forms a complete orthogonal system in $H$. This means that for any two distinct indices $n$ and $m$, $\\langle v_n, v_m \\rangle = 0$, and for any vector $x \\in H$, the vector $x$ can be represented as the series $x = \\sum_{n=1}^{\\infty} c_n v_n$ for some complex coefficients $c_n$. Note that the system is not necessarily orthonormal, so $\\|v_n\\|$ is not necessarily equal to 1.\n\nFor an arbitrary vector $x \\in H$, which of the following expressions correctly represents the squared norm, $\\|x\\|^2$?\n\nA. $\\sum_{n=1}^{\\infty} \\frac{|\\langle x, v_n \\rangle|^2}{\\|v_n\\|^2}$\n\nB. $\\sum_{n=1}^{\\infty} \\frac{|\\langle x, v_n \\rangle|^2}{\\|v_n\\|^4}$\n\nC. $\\sum_{n=1}^{\\infty} |\\langle x, v_n \\rangle|^2$\n\nD. $\\sum_{n=1}^{\\infty} |\\langle x, v_n \\rangle|^2 \\|v_n\\|^2$\n\nE. $\\sum_{n=1}^{\\infty} \\frac{\\langle x, v_n \\rangle^2}{\\|v_n\\|^2}$", "solution": "Let $\\{v_{n}\\}_{n=1}^{\\infty}$ be an orthogonal and complete system of nonzero vectors in a complex Hilbert space $H$, and let $x \\in H$. By completeness, there exist coefficients $c_{n} \\in \\mathbb{C}$ such that the series converges in $H$:\n$$\nx=\\sum_{n=1}^{\\infty} c_{n} v_{n}.\n$$\nFor the partial sums $s_{N}=\\sum_{n=1}^{N} c_{n} v_{n}$, orthogonality gives\n$$\n\\|s_{N}\\|^{2}=\\left\\langle \\sum_{n=1}^{N} c_{n} v_{n}, \\sum_{m=1}^{N} c_{m} v_{m}\\right\\rangle=\\sum_{n=1}^{N}\\sum_{m=1}^{N} c_{n}\\overline{c_{m}}\\langle v_{n},v_{m}\\rangle=\\sum_{n=1}^{N} |c_{n}|^{2}\\|v_{n}\\|^{2}.\n$$\nSince $s_{N} \\to x$ in norm, the continuity of the norm implies\n$$\n\\|x\\|^{2}=\\lim_{N\\to\\infty}\\|s_{N}\\|^{2}=\\sum_{n=1}^{\\infty} |c_{n}|^{2}\\|v_{n}\\|^{2}.\n$$\nNext, we relate $c_{n}$ to inner products. Using orthogonality,\n- if the inner product is linear in the second argument, then $\\langle v_{k},x\\rangle=\\sum_{n} c_{n}\\langle v_{k},v_{n}\\rangle=c_{k}\\langle v_{k},v_{k}\\rangle$, hence $c_{k}=\\langle v_{k},x\\rangle/\\|v_{k}\\|^{2}$;\n- if the inner product is linear in the first argument, then $\\langle x,v_{k}\\rangle=\\sum_{n} c_{n}\\langle v_{n},v_{k}\\rangle=c_{k}\\langle v_{k},v_{k}\\rangle$, hence $c_{k}=\\langle x,v_{k}\\rangle/\\|v_{k}\\|^{2}$.\n\nIn either convention,\n$$\n|c_{k}|=\\frac{|\\langle x,v_{k}\\rangle|}{\\|v_{k}\\|^{2}}.\n$$\nSubstituting into the norm identity gives\n$$\n\\|x\\|^{2}=\\sum_{n=1}^{\\infty} |c_{n}|^{2}\\|v_{n}\\|^{2}=\\sum_{n=1}^{\\infty} \\frac{|\\langle x,v_{n}\\rangle|^{2}}{\\|v_{n}\\|^{2}}.\n$$\nTherefore the correct choice is A. Options C and D correspond to the orthonormal case (C) or incorrect scaling (D), B has an extra factor of $\\|v_{n}\\|^{2}$ in the denominator, and E omits the modulus, which is invalid in the complex setting.", "answer": "$$\\boxed{A}$$", "id": "1850519"}]}