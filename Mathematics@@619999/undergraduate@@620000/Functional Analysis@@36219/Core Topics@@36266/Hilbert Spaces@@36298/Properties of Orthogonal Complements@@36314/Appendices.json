{"hands_on_practices": [{"introduction": "We begin our exploration with a foundational exercise set in a familiar context: the two-dimensional Euclidean plane, $\\mathbb{R}^2$. This practice is designed to connect the abstract definition of an orthogonal complement to its concrete geometric intuition. By finding the orthogonal complement to a line through the origin, you will translate the algebraic condition for orthogonality, $\\langle v, w \\rangle = 0$, into the tangible concept of perpendicular lines, reinforcing your understanding from the ground up. [@problem_id:1876382]", "problem": "Consider the Hilbert space $H = \\mathbb{R}^2$ equipped with the standard Euclidean inner product, which is the dot product. Let $M$ be the one-dimensional subspace of $H$ defined by the set of all points $(x, y)$ that satisfy the linear equation $y = 3x$. The orthogonal complement of $M$, denoted by $M^\\perp$, is the set of all vectors in $H$ that are orthogonal to every vector in $M$.\n\nFind a non-zero column vector $\\mathbf{v}$ such that its span, $\\text{span}(\\mathbf{v})$, is equal to the orthogonal complement $M^\\perp$.", "solution": "We work in $H=\\mathbb{R}^{2}$ with the standard dot product. The subspace $M$ is the line $y=3x$, which is $\\text{span}\\{(1,3)\\}$. By definition, the orthogonal complement $M^{\\perp}$ consists of all vectors $\\mathbf{v}=(a,b)$ such that $\\mathbf{v}\\cdot(1,3)=0$. The dot product condition gives\n$$\na\\cdot 1 + b\\cdot 3 = a + 3b = 0.\n$$\nSolving, we obtain $a=-3b$, so every vector in $M^{\\perp}$ has the form $b(-3,1)$ for some scalar $b$. Since $M$ is one-dimensional in $\\mathbb{R}^{2}$, the dimension formula implies $\\dim(M^{\\perp})=1$, hence $M^{\\perp}=\\text{span}\\{(-3,1)\\}$. Therefore any non-zero multiple of $(-3,1)$ is a valid column vector whose span equals $M^{\\perp}$.", "answer": "$$\\boxed{\\begin{pmatrix}-3\\\\1\\end{pmatrix}}$$", "id": "1876382"}, {"introduction": "Having mastered the concept in Euclidean space, we now generalize to a more abstract setting: a vector space of polynomials. This problem challenges you to apply the ideas of orthogonality and projection within a function space, where the inner product is defined by an integral rather than a simple dot product. Here, you will calculate the orthogonal projection of a polynomial onto a subspace, a fundamental technique for finding the \"best approximation\" of a vector within a given subspace, which is a cornerstone of approximation theory and signal analysis. [@problem_id:1876416]", "problem": "Consider the vector space $V$ of all real-valued polynomials of degree at most 2, defined on the interval $[-1, 1]$. An inner product is defined on this space for any two polynomials $f(x)$ and $g(x)$ by the integral:\n$$\n\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) \\, dx\n$$\nLet $U$ be the one-dimensional subspace of $V$ spanned by the polynomial $p(x) = x$. Let $U^{\\perp}$ denote the orthogonal complement of $U$ in $V$.\n\nYour task is to find the orthogonal projection of the polynomial $q(x) = x^2 + x + 1$ onto the subspace $U^{\\perp}$.", "solution": "We work in the inner product space with $\\langle f,g\\rangle=\\int_{-1}^{1}f(x)g(x)\\,dx$ and $U=\\operatorname{span}\\{x\\}$. For any $q\\in V$, the orthogonal decomposition is $q=q_{U}+q_{U^{\\perp}}$ with $q_{U}=\\operatorname{proj}_{U}(q)$ and $q_{U^{\\perp}}=q-q_{U}$. Since $U$ is one-dimensional spanned by $x$, the projection onto $U$ is\n$$\n\\operatorname{proj}_{U}(q)=\\frac{\\langle q,x\\rangle}{\\langle x,x\\rangle}\\,x.\n$$\nFor $q(x)=x^{2}+x+1$, compute the necessary inner products. First,\n$$\n\\langle x,x\\rangle=\\int_{-1}^{1}x^{2}\\,dx=\\left[\\frac{x^{3}}{3}\\right]_{-1}^{1}=\\frac{1}{3}-\\left(-\\frac{1}{3}\\right)=\\frac{2}{3}.\n$$\nNext,\n$$\n\\langle q,x\\rangle=\\int_{-1}^{1}(x^{2}+x+1)x\\,dx=\\int_{-1}^{1}\\bigl(x^{3}+x^{2}+x\\bigr)\\,dx.\n$$\nUsing the parity of integrands, $\\int_{-1}^{1}x^{3}\\,dx=0$ and $\\int_{-1}^{1}x\\,dx=0$ (odd functions), while\n$$\n\\int_{-1}^{1}x^{2}\\,dx=\\frac{2}{3}.\n$$\nThus,\n$$\n\\langle q,x\\rangle=\\frac{2}{3}.\n$$\nTherefore,\n$$\n\\operatorname{proj}_{U}(q)=\\frac{\\langle q,x\\rangle}{\\langle x,x\\rangle}x=\\frac{\\frac{2}{3}}{\\frac{2}{3}}\\,x=x.\n$$\nThe projection of $q$ onto $U^{\\perp}$ is then\n$$\nq_{U^{\\perp}}=q-\\operatorname{proj}_{U}(q)=(x^{2}+x+1)-x=x^{2}+1.\n$$\nA quick check of orthogonality: $\\langle x^{2}+1,x\\rangle=\\int_{-1}^{1}(x^{3}+x)\\,dx=0$, confirming $x^{2}+1\\in U^{\\perp}$.", "answer": "$$\\boxed{x^{2}+1}$$", "id": "1876416"}, {"introduction": "Our final practice takes you into the realm of infinite-dimensional Hilbert spaces, specifically the sequence space $\\ell^2(\\mathbb{N})$. This advanced exercise explores how to characterize the orthogonal complement of a subspace defined by a set of linear constraints. This problem bridges the concept of orthogonality with the structure of linear functionals, providing a powerful method for analyzing subspaces in infinite dimensions, a skill essential for applications in functional analysis, quantum mechanics, and advanced signal processing. [@problem_id:1876388]", "problem": "Let $\\ell^2(\\mathbb{N})$ be the Hilbert space of all complex-valued sequences $x = (x_n)_{n=1}^\\infty$ such that $\\sum_{n=1}^\\infty |x_n|^2 < \\infty$, equipped with the inner product $\\langle x, y \\rangle = \\sum_{n=1}^\\infty x_n \\overline{y_n}$.\n\nConsider the subspace $M$ of $\\ell^2(\\mathbb{N})$ defined as:\n$$\nM = \\left\\{ x = (x_n)_{n=1}^\\infty \\in \\ell^2(\\mathbb{N}) \\mid x_1 - x_2 = 0 \\text{ and } x_3 = 0 \\right\\}\n$$\n\nWhich of the following options correctly characterizes the orthogonal complement of $M$, denoted by $M^\\perp$? In the options below, $\\text{span}\\{v_1, v_2, \\dots\\}$ denotes the set of all finite linear combinations of the vectors $v_1, v_2, \\dots$. The vectors are written with only their non-zero initial components shown explicitly.\n\nA. $M^\\perp = \\text{span}\\{ (1, 1, 0, \\dots) \\}$\n\nB. $M^\\perp = \\text{span}\\{ (1, -1, 0, \\dots) \\}$\n\nC. $M^\\perp = \\text{span}\\{ (0, 0, 1, \\dots) \\}$\n\nD. $M^\\perp = \\text{span}\\{ (1, -1, 0, \\dots), (0, 0, 1, \\dots) \\}$\n\nE. $M^\\perp = \\text{span}\\{ (1, 1, 0, \\dots), (0, 0, 1, \\dots) \\}$", "solution": "Let $e_{n}$ denote the standard orthonormal basis of $\\ell^{2}(\\mathbb{N})$. The subspace $M$ is\n$$\nM=\\{x\\in \\ell^{2}(\\mathbb{N}) : x_{1}-x_{2}=0,\\ x_{3}=0\\}.\n$$\nEquivalently, $M=\\ker f_{1}\\cap \\ker f_{2}$ where\n$$\nf_{1}(x)=x_{1}-x_{2}=\\langle x, e_{1}-e_{2}\\rangle,\\qquad f_{2}(x)=x_{3}=\\langle x, e_{3}\\rangle.\n$$\nBy the Riesz representation theorem, $\\ker f_{1}$ and $\\ker f_{2}$ are orthogonal to $e_{1}-e_{2}$ and $e_{3}$ respectively, hence\n$$\n(\\ker f_{1})^{\\perp}=\\text{span}\\{e_{1}-e_{2}\\},\\qquad (\\ker f_{2})^{\\perp}=\\text{span}\\{e_{3}\\}.\n$$\nUsing $(A\\cap B)^{\\perp}=\\overline{A^{\\perp}+B^{\\perp}}$ and the fact that finite-dimensional subspaces are closed, we get\n$$\nM^{\\perp}=\\text{span}\\{e_{1}-e_{2},\\, e_{3}\\}=\\text{span}\\{(1,-1,0,\\dots),(0,0,1,\\dots)\\}.\n$$\n\nFor a direct verification, let $y=(y_{n})\\in M^{\\perp}$. Then $\\langle x,y\\rangle=0$ for all $x\\in M$. Choosing $x$ with $x_{k}\\neq 0$ and all other components zero for $k\\geq 4$ (which satisfies $x_{1}-x_{2}=0$ and $x_{3}=0$), we get $0=\\langle x,y\\rangle=x_{k}\\overline{y_{k}}$ for all $x_{k}$, hence $y_{k}=0$ for all $k\\geq 4$. Next, choosing $x$ with $x_{1}=t$, $x_{2}=t$, $x_{3}=0$, all others zero, we obtain $0=\\langle x,y\\rangle=t(\\overline{y_{1}}+\\overline{y_{2}})$ for all $t\\in \\mathbb{C}$, hence $y_{1}+y_{2}=0$. No condition of $M$ varies $x_{3}$, so $y_{3}$ is free. Therefore every $y\\in M^{\\perp}$ has the form\n$$\ny=(y_{1},-y_{1},y_{3},0,0,\\dots)=y_{1}(1,-1,0,\\dots)+y_{3}(0,0,1,\\dots),\n$$\nwhich equals $\\text{span}\\{(1,-1,0,\\dots),(0,0,1,\\dots)\\}$.\n\nComparing with the options, this is option D.", "answer": "$$\\boxed{D}$$", "id": "1876388"}]}