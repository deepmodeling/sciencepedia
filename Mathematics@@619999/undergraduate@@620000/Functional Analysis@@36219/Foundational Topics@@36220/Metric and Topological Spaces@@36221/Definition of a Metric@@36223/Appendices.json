{"hands_on_practices": [{"introduction": "How do we measure distance between points in a space? Our intuition often links it to length, but this can be misleading. This first practice [@problem_id:1856575] challenges you to vet a seemingly simple distance function based on the difference in vector norms, $d(u,v) = | \\|u\\| - \\|v\\| |$. This exercise reveals why the \"identity of indiscernibles\" axiom is a crucial guardrail in our definition of distance, ensuring that zero distance implies true identity.", "problem": "In machine learning, data points are often represented as vectors in a high-dimensional feature space, which can be modeled as $\\mathbb{R}^n$. Let $\\|\\cdot\\|$ be any valid norm on this space (for example, the standard Euclidean norm). A data scientist proposes a function $d: \\mathbb{R}^n \\times \\mathbb{R}^n \\to \\mathbb{R}$ to quantify a specific type of dissimilarity between two feature vectors $u$ and $v$ as follows:\n$$d(u, v) = | \\|u\\| - \\|v\\| |$$\nwhere $|x|$ denotes the absolute value of a real number $x$.\n\nFor $d(u,v)$ to be a valid metric on the space $\\mathbb{R}^n$, it must satisfy four standard properties for all $u, v, w \\in \\mathbb{R}^n$:\n1.  **Non-negativity:** $d(u,v) \\ge 0$.\n2.  **Identity of Indiscernibles:** $d(u,v) = 0$ if and only if $u = v$.\n3.  **Symmetry:** $d(u,v) = d(v,u)$.\n4.  **Triangle Inequality:** $d(u,w) \\le d(u,v) + d(v,w)$.\n\nWhich of the following statements about the function $d(u,v)$ is correct?\n\nA. $d(u,v)$ is a valid metric as it satisfies all four properties.\n\nB. $d(u,v)$ is not a metric because it fails the non-negativity property.\n\nC. $d(u,v)$ is not a metric because it fails the identity of indiscernibles.\n\nD. $d(u,v)$ is not a metric because it fails the symmetry property.\n\nE. $d(u,v)$ is not a metric because it fails the triangle inequality.", "solution": "We analyze the four metric properties for $d(u,v)=|\\|u\\|-\\|v\\||$ on $\\mathbb{R}^{n}$ with any norm $\\|\\cdot\\|$.\n\nNon-negativity: For any $u,v$, norms satisfy $\\|u\\|\\ge 0$ and $\\|v\\|\\ge 0$ by definition. Therefore $d(u,v)=|\\|u\\|-\\|v\\||\\ge 0$, so non-negativity holds.\n\nIdentity of indiscernibles: We have $d(u,v)=0$ if and only if $|\\|u\\|-\\|v\\||=0$, which is equivalent to $\\|u\\|=\\|v\\|$. This does not imply $u=v$ in general: for any nonzero $u$, take $v=-u$, then $\\|v\\|=\\|u\\|$ while $v\\ne u$, hence $d(u,v)=0$ but $u\\ne v$. Thus the identity of indiscernibles fails.\n\nSymmetry: For any real numbers $a,b$, $|a-b|=|b-a|$. Taking $a=\\|u\\|$ and $b=\\|v\\|$ gives $d(u,v)=|\\|u\\|-\\|v\\||=|\\|v\\|-\\|u\\||=d(v,u)$, so symmetry holds.\n\nTriangle inequality: Let $a=\\|u\\|$, $b=\\|v\\|$, and $c=\\|w\\|$. The triangle inequality in $\\mathbb{R}$ yields\n$$\n|a-c|\\le |a-b|+|b-c|.\n$$\nTranslating back gives\n$$\nd(u,w)=|\\|u\\|-\\|w\\||\\le |\\|u\\|-\\|v\\||+|\\|v\\|-\\|w\\||=d(u,v)+d(v,w),\n$$\nso the triangle inequality holds.\n\nConclusion: The only failed property is the identity of indiscernibles. Therefore $d$ is not a metric, and the correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1856575"}, {"introduction": "We now extend our thinking from simple vectors in $\\mathbb{R}^n$ to the infinite-dimensional world of function spaces. This practice explores a candidate metric for continuous functions, defined by the absolute value of the integral of their difference, $d(f, g) = \\left| \\int_{0}^{1} (f(t) - g(t)) dt \\right|$ [@problem_id:1856614]. This problem critically examines whether a \"net difference\" of zero is enough to declare two functions identical, reinforcing the strict requirements of a metric in more abstract settings.", "problem": "In mathematics, a metric space is a set $X$ equipped with a function $d: X \\times X \\to \\mathbb{R}$, called a metric or distance function, that satisfies four specific properties for all $f, g, h \\in X$:\n1.  **Non-negativity**: $d(f, g) \\ge 0$\n2.  **Identity of indiscernibles**: $d(f, g) = 0$ if and only if $f = g$\n3.  **Symmetry**: $d(f, g) = d(g, f)$\n4.  **Triangle inequality**: $d(f, h) \\le d(f, g) + d(g, h)$\n\nLet $C[0,1]$ be the set of all continuous real-valued functions defined on the closed interval $[0,1]$. A candidate for a metric on this set is proposed as:\n$$d(f, g) = \\left| \\int_{0}^{1} (f(t) - g(t)) dt \\right|$$\nDetermine if this function $d(f,g)$ is a valid metric on the set $C[0,1]$. If it is not, identify the single property that fails.\n\nA. Non-negativity\n\nB. Identity of indiscernibles\n\nC. Symmetry\n\nD. Triangle inequality\n\nE. It is a valid metric; no property fails.", "solution": "We are given $d(f,g) = \\left| \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt \\right|$ on $C[0,1]$. We verify each metric property:\n\nNon-negativity: For any $f,g \\in C[0,1]$, the integral $\\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt$ is a real number. The absolute value satisfies $|a| \\ge 0$ for all real $a$. Therefore,\n$$\nd(f,g) = \\left| \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt \\right| \\ge 0,\n$$\nso non-negativity holds.\n\nIdentity of indiscernibles: If $f=g$, then $f(t)-g(t)=0$ for all $t$, hence\n$$\nd(f,g) = \\left| \\int_{0}^{1} 0 \\, dt \\right| = 0.\n$$\nConversely, if $d(f,g)=0$, then\n$$\n\\left| \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt \\right| = 0 \\implies \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt = 0.\n$$\nThis does not imply $f=g$ as functions. For a counterexample, let $f(t) = t - \\frac{1}{2}$ and $g(t) \\equiv 0$. Both are continuous on $[0,1]$, and\n$$\n\\int_{0}^{1} f(t) \\, dt = \\int_{0}^{1} \\left(t - \\frac{1}{2}\\right) \\, dt = \\left[\\frac{t^{2}}{2} - \\frac{t}{2}\\right]_{0}^{1} = \\frac{1}{2} - \\frac{1}{2} = 0, \\quad \\int_{0}^{1} g(t) \\, dt = 0,\n$$\nso\n$$\nd(f,g) = \\left| \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt \\right| = \\left| \\int_{0}^{1} f(t) \\, dt - \\int_{0}^{1} g(t) \\, dt \\right| = |0 - 0| = 0,\n$$\nyet $f \\ne g$. Therefore, the identity of indiscernibles fails.\n\nSymmetry: By linearity of the integral and properties of absolute value,\n$$\nd(f,g) = \\left| \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt \\right| = \\left| - \\int_{0}^{1} \\left(g(t) - f(t)\\right) \\, dt \\right| = \\left| \\int_{0}^{1} \\left(g(t) - f(t)\\right) \\, dt \\right| = d(g,f),\n$$\nso symmetry holds.\n\nTriangle inequality: For any $f,g,h \\in C[0,1]$, by linearity of the integral,\n$$\n\\int_{0}^{1} \\left(f(t) - h(t)\\right) \\, dt = \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt + \\int_{0}^{1} \\left(g(t) - h(t)\\right) \\, dt.\n$$\nLet $A = \\int_{0}^{1} \\left(f(t) - g(t)\\right) \\, dt$ and $B = \\int_{0}^{1} \\left(g(t) - h(t)\\right) \\, dt$. Then $d(f,h) = |A + B| \\le |A| + |B| = d(f,g) + d(g,h)$ by the triangle inequality for real numbers. Hence the triangle inequality holds.\n\nConclusion: The only failing property is the identity of indiscernibles.", "answer": "$$\\boxed{B}$$", "id": "1856614"}, {"introduction": "Having seen what can go wrong, let's analyze an unconventional function that, perhaps surprisingly, does satisfy all the axioms of a metric. This practice introduces the \"French Railway\" or \"SNCF\" metric, defined piecewise based on whether points are collinear with the origin [@problem_id:1856591]. Verifying the triangle inequality for this metric is a fantastic exercise in rigorous, case-by-case logical deduction and deepens your appreciation for the robustness of the metric axioms.", "problem": "Let $\\mathbb{R}^2$ be the two-dimensional real vector space. For any two vectors $x = (x_1, x_2)$ and $y = (y_1, y_2)$ in $\\mathbb{R}^2$, let $\\|x\\|_2$ denote the standard Euclidean norm, defined as $\\|x\\|_2 = \\sqrt{x_1^2 + x_2^2}$. The origin is denoted by $O = (0,0)$.\n\nConsider the function $d: \\mathbb{R}^2 \\times \\mathbb{R}^2 \\to \\mathbb{R}$ defined by the following rule:\n$$\nd(x, y) = \\begin{cases} \\|x - y\\|_2 & \\text{if } x, y, \\text{ and the origin } O \\text{ are collinear} \\\\ \\|x\\|_2 + \\|y\\|_2 & \\text{otherwise} \\end{cases}\n$$\nThe condition that $x, y,$ and the origin $O$ are collinear means that the three points lie on a single straight line in the plane.\n\nA function $f: X \\times X \\to \\mathbb{R}$ is a metric on a set $X$ if for all $x, y, z \\in X$, it satisfies the following four axioms:\n1.  **Non-negativity**: $f(x, y) \\ge 0$\n2.  **Identity of indiscernibles**: $f(x, y) = 0 \\iff x = y$\n3.  **Symmetry**: $f(x, y) = f(y, x)$\n4.  **Triangle inequality**: $f(x, z) \\le f(x, y) + f(y, z)$\n\nWhich of the following statements about the function $d$ is true?\n\nA) $d$ is not a metric because it fails the non-negativity axiom.\n\nB) $d$ is not a metric because it fails the identity of indiscernibles axiom.\n\nC) $d$ is not a metric because it fails the symmetry axiom.\n\nD) $d$ is not a metric because it fails the triangle inequality axiom.\n\nE) $d$ is a metric.", "solution": "We analyze the function $d$ defined on $\\mathbb{R}^{2}$ by\n$$\nd(x,y)=\\begin{cases}\n\\|x-y\\|_{2}, & \\text{if } x,y,O \\text{ are collinear},\\\\\n\\|x\\|_{2}+\\|y\\|_{2}, & \\text{otherwise}.\n\\end{cases}\n$$\nWe verify the metric axioms one by one.\n\nNon-negativity: In both cases the value is a norm or a sum of norms, hence non-negative:\n$$\nd(x,y)\\ge 0.\n$$\n\nIdentity of indiscernibles: If $x=y$, then $x,y,O$ are collinear and $d(x,x)=\\|x-x\\|_{2}=0$. Conversely, if $d(x,y)=0$, consider two cases.\n\n- If $x,y,O$ are collinear, then $\\|x-y\\|_{2}=0$ implies $x=y$.\n- Otherwise, $d(x,y)=\\|x\\|_{2}+\\|y\\|_{2}=0$ implies $\\|x\\|_{2}=0$ and $\\|y\\|_{2}=0$, so $x=y=O$.\n\nThus $d(x,y)=0$ if and only if $x=y$.\n\nSymmetry: For all $x,y$,\n$$\nd(x,y)=\\begin{cases}\n\\|x-y\\|_{2}=\\|y-x\\|_{2}=d(y,x), & \\text{if collinear},\\\\\n\\|x\\|_{2}+\\|y\\|_{2}=\\|y\\|_{2}+\\|x\\|_{2}=d(y,x), & \\text{otherwise}.\n\\end{cases}\n$$\n\nTriangle inequality: We must show $d(x,z)\\le d(x,y)+d(y,z)$ for all $x,y,z$.\n\nWe first record two general bounds, valid for all $a,b\\in\\mathbb{R}^{2}$:\n$$\n|\\|a\\|_{2}-\\|b\\|_{2}|\\le d(a,b)\\le \\|a\\|_{2}+\\|b\\|_{2}.\n$$\nIndeed, if $a,b,O$ are collinear, then by the reverse triangle inequality $|\\|a\\|_{2}-\\|b\\|_{2}|\\le \\|a-b\\|_{2}=d(a,b)$, and by the triangle inequality $\\|a-b\\|_{2}\\le \\|a\\|_{2}+\\|b\\|_{2}$. If they are not collinear, then $d(a,b)=\\|a\\|_{2}+\\|b\\|_{2}\\ge |\\|a\\|_{2}-\\|b\\|_{2}|$ and also $d(a,b)=\\|a\\|_{2}+\\|b\\|_{2}$.\n\nNow fix $x,y,z$ and consider two cases.\n\nCase I: At least one of $(x,y)$ or $(y,z)$ is not collinear with $O$. Without loss of generality, assume $x,y,O$ are not collinear. Then\n$$\nd(x,y)=\\|x\\|_{2}+\\|y\\|_{2}, \\quad d(y,z)\\ge \\|z\\|_{2}-\\|y\\|_{2}, \\quad d(x,z)\\le \\|x\\|_{2}+\\|z\\|_{2}.\n$$\nTherefore,\n$$\nd(x,y)+d(y,z)\\ge (\\|x\\|_{2}+\\|y\\|_{2})+(\\|z\\|_{2}-\\|y\\|_{2})=\\|x\\|_{2}+\\|z\\|_{2}\\ge d(x,z).\n$$\n\nCase II: Both pairs $(x,y)$ and $(y,z)$ are collinear with $O$. If $y\\neq O$, then $x,y,z$ all lie on the unique line through $O$ and $y$, hence\n$$\nd(x,z)=\\|x-z\\|_{2}\\le \\|x-y\\|_{2}+\\|y-z\\|_{2}=d(x,y)+d(y,z),\n$$\nby the Euclidean triangle inequality. If $y=O$, then $d(x,y)+d(y,z)=\\|x\\|_{2}+\\|z\\|_{2}\\ge d(x,z)$ by the general upper bound.\n\nIn all cases, the triangle inequality holds.\n\nSince all four axioms are satisfied, $d$ is a metric. Hence the correct choice is E.", "answer": "$$\\boxed{E}$$", "id": "1856591"}]}