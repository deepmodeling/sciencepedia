{"hands_on_practices": [{"introduction": "To begin our exploration, we'll ground the abstract idea of convergence in a familiar setting: the space of polynomials. This first practice [@problem_id:1854083] challenges you to determine the limit of a sequence of polynomials using a metric defined by an integral, a common tool in analysis for measuring the \"total difference\" between functions. Successfully solving this will build your intuition for how convergence works in function spaces, moving beyond simple pointwise convergence to a more robust, metric-based understanding.", "problem": "Consider the vector space $P_3$, which consists of all real-valued polynomials of degree at most 3. This space is equipped with a metric $d$ defined for any two polynomials $p(t)$ and $q(t)$ in $P_3$ by the integral:\n$$d(p, q) = \\int_{0}^{1} |p(t) - q(t)| dt$$\nA sequence of polynomials $\\{p_n\\}_{n=1}^{\\infty}$ is defined within this space as:\n$$p_n(t) = t^2 + \\frac{1}{n}t^3$$\nDetermine the polynomial $p(t) \\in P_3$ to which this sequence converges with respect to the given metric. Express your answer as a polynomial in the variable $t$.", "solution": "To determine the limit of the sequence $\\{p_n(t)\\}$ in the metric space $(P_3, d)$, we need to find a polynomial $p(t) \\in P_3$ such that the distance $d(p_n, p)$ approaches 0 as $n \\to \\infty$. The definition of convergence for a sequence $\\{p_n\\}$ to a limit $p$ in a metric space is:\n$$ \\lim_{n \\to \\infty} d(p_n, p) = 0 $$\n\nFirst, let's form an intuitive guess for the limit polynomial $p(t)$. Looking at the expression for $p_n(t) = t^2 + \\frac{1}{n}t^3$, as the index $n$ becomes very large ($n \\to \\infty$), the term $\\frac{1}{n}$ approaches 0. This suggests that the term $\\frac{1}{n}t^3$ vanishes in the limit. Therefore, a plausible candidate for the limit is the polynomial $p(t) = t^2$. We must verify that this candidate function $p(t)$ is an element of the space $P_3$. Since $p(t)=t^2$ is a polynomial of degree 2, and $2 \\leq 3$, it is indeed in $P_3$.\n\nNow, let's verify if the sequence converges to $p(t) = t^2$ by computing the limit of the distance $d(p_n, p)$.\nThe distance is given by the integral:\n$$ d(p_n, p) = \\int_{0}^{1} |p_n(t) - p(t)| dt $$\nSubstitute the expressions for $p_n(t)$ and our candidate limit $p(t)$:\n$$ p_n(t) - p(t) = \\left(t^2 + \\frac{1}{n}t^3\\right) - t^2 = \\frac{1}{n}t^3 $$\nSo, the integral for the distance becomes:\n$$ d(p_n, p) = \\int_{0}^{1} \\left| \\frac{1}{n}t^3 \\right| dt $$\nThe integration is over the interval $t \\in [0, 1]$. In this interval, $t^3 \\ge 0$. Also, since $n$ is a positive integer, $\\frac{1}{n}  0$. Therefore, the term $\\frac{1}{n}t^3$ is always non-negative on the interval of integration. This means we can remove the absolute value bars:\n$$ d(p_n, p) = \\int_{0}^{1} \\frac{1}{n}t^3 dt $$\nSince $\\frac{1}{n}$ is a constant with respect to the integration variable $t$, we can factor it out of the integral:\n$$ d(p_n, p) = \\frac{1}{n} \\int_{0}^{1} t^3 dt $$\nNow, we evaluate the definite integral using the power rule for integration, $\\int t^k dt = \\frac{t^{k+1}}{k+1}$:\n$$ \\int_{0}^{1} t^3 dt = \\left[ \\frac{t^4}{4} \\right]_{0}^{1} = \\frac{1^4}{4} - \\frac{0^4}{4} = \\frac{1}{4} $$\nSubstituting this result back into the expression for the distance, we get:\n$$ d(p_n, p) = \\frac{1}{n} \\cdot \\frac{1}{4} = \\frac{1}{4n} $$\nFinally, we take the limit as $n \\to \\infty$:\n$$ \\lim_{n \\to \\infty} d(p_n, p) = \\lim_{n \\to \\infty} \\frac{1}{4n} $$\nAs $n$ approaches infinity, the denominator $4n$ also approaches infinity, so the fraction approaches 0.\n$$ \\lim_{n \\to \\infty} \\frac{1}{4n} = 0 $$\nSince we have shown that $\\lim_{n \\to \\infty} d(p_n, p) = 0$ for $p(t)=t^2$, we can conclude that the sequence of polynomials $\\{p_n(t)\\}$ converges to the polynomial $p(t)=t^2$ in the given metric space.", "answer": "$$\\boxed{t^{2}}$$", "id": "1854083"}, {"introduction": "Having explored a continuous-style metric, we now turn to a fascinating and extreme counterexample: the discrete metric space. In this space, every two distinct points are considered equally \"far apart,\" which this exercise [@problem_id:1854130] uses to force a reliance purely on the formal $\\epsilon-N$ definition of convergence, stripping away any geometric intuition you may have from standard spaces like $\\mathbb{R}^n$. By characterizing exactly which sequences can converge here, you will develop a much deeper and more precise understanding of the fundamental mechanics of convergence.", "problem": "Let $X$ be a non-empty set. The discrete metric $d$ on $X$ is defined as follows: for any two points $x, y \\in X$,\n$$\nd(x, y) = \\begin{cases} 1  \\text{if } x \\neq y \\\\ 0  \\text{if } x = y \\end{cases}\n$$\nA sequence $(x_n)_{n=1}^{\\infty}$ of points in $X$ is said to be *eventually constant* if there exists a point $L \\in X$ and a positive integer $N$ such that for all integers $n \\ge N$, we have $x_n = L$.\n\nWhich one of the following statements provides a complete characterization of all convergent sequences in the metric space $(X, d)$?\n\nA. A sequence converges if and only if it is constant (i.e., $x_n = c$ for all $n \\ge 1$).\n\nB. A sequence converges if and only if it is eventually constant.\n\nC. A sequence converges if and only if the set of its values, $\\{x_n \\mid n \\in \\mathbb{Z}^+\\}$, is a finite set.\n\nD. Any sequence in $(X, d)$ is convergent, regardless of its terms.\n\nE. A sequence converges only if the underlying set $X$ is finite; otherwise, no sequence can converge.", "solution": "Let $(X,d)$ be a metric space with the discrete metric $d$, so $d(x,y)=0$ if $x=y$ and $d(x,y)=1$ if $x\\neq y$. By the definition of convergence in a metric space, a sequence $(x_{n})$ converges to a point $L\\in X$ if and only if for every $\\varepsilon0$ there exists $N\\in\\mathbb{Z}^{+}$ such that for all $n\\geq N$ we have $d(x_{n},L)\\varepsilon$.\n\nNecessity: Assume $(x_{n})$ converges to $L\\in X$. Choose $\\varepsilon=\\frac{1}{2}$. Then there exists $N$ such that for all $n\\geq N$, $d(x_{n},L)\\frac{1}{2}$. Since $d$ only takes the values $0$ and $1$, the inequality $d(x_{n},L)\\frac{1}{2}$ forces $d(x_{n},L)=0$, hence $x_{n}=L$ for all $n\\geq N$. Therefore, any convergent sequence in $(X,d)$ is eventually constant.\n\nSufficiency: Conversely, if $(x_{n})$ is eventually constant with eventual value $L\\in X$, i.e., there exists $N$ such that $x_{n}=L$ for all $n\\geq N$, then for every $\\varepsilon0$ and for all $n\\geq N$ we have $d(x_{n},L)=0\\varepsilon$. Hence $(x_{n})$ converges to $L$.\n\nThus, a sequence in $(X,d)$ converges if and only if it is eventually constant.\n\nWe now compare with the options:\n- A is too restrictive: sequences that are eventually constant but not constant from the start still converge.\n- B matches the established characterization.\n- C is false: for instance, an alternating sequence between two distinct points $a,b\\in X$ has finite range $\\{a,b\\}$ but does not converge, since taking $\\varepsilon=\\frac{1}{2}$ fails for any candidate limit.\n- D is false: non-eventually-constant sequences (e.g., the alternating example) do not converge.\n- E is false: even when $X$ is infinite, eventually constant sequences exist and converge.\n\nTherefore, the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1854130"}, {"introduction": "Our final practice demonstrates one of the most important lessons in functional analysis: the choice of metric matters. Here, you will investigate a single sequence of points (where each point is itself an infinite sequence) but test for convergence in three different, widely-used metric spaces: $\\ell^1$, $\\ell^2$, and $\\ell^\\infty$. This comparative analysis [@problem_id:1854126] reveals that convergence is not an intrinsic property of a sequence but a relationship between the sequence and the metric used to measure distance, a profound concept that underlies much of advanced analysis.", "problem": "Let $S$ be the vector space of all infinite sequences of real numbers, $x = (x_1, x_2, x_3, \\dots)$. For a real number $p \\ge 1$, the space $\\ell^p$ is the subspace of $S$ consisting of all sequences $x$ for which the $p$-norm, defined as $\\|x\\|_p = \\left( \\sum_{k=1}^\\infty |x_k|^p \\right)^{1/p}$, is finite. The space $\\ell^\\infty$ is the subspace of $S$ consisting of all bounded sequences, for which the infinity-norm, given by $\\|x\\|_\\infty = \\sup_{k \\ge 1} |x_k|$, is finite. A sequence of sequences $(x^{(n)})_{n=1}^\\infty$ is said to converge to a limit sequence $L$ in a given norm if the sequence of real numbers $d_n = \\|x^{(n)} - L\\|$ converges to $0$ as $n \\to \\infty$.\n\nConsider the sequence of sequences $(x^{(n)})_{n=1}^\\infty$, where each element $x^{(n)} \\in S$ is defined by its components $x_k^{(n)}$ as:\n$$\nx_k^{(n)} =\n\\begin{cases}\n\\frac{1}{n+k}  \\text{for } 1 \\le k \\le n \\\\\n0  \\text{for } k  n\n\\end{cases}\n$$\nIn which of the following spaces does the sequence $(x^{(n)})_{n=1}^\\infty$ converge to the zero sequence $0 = (0, 0, 0, \\dots)$?\n\nA. In $\\ell^1$ only\n\nB. In $\\ell^2$ only\n\nC. In $\\ell^\\infty$ only\n\nD. In $\\ell^2$ and $\\ell^\\infty$, but not in $\\ell^1$\n\nE. In $\\ell^1$, $\\ell^2$, and $\\ell^\\infty$", "solution": "We must determine, for each norm, whether $\\|x^{(n)}\\|$ tends to $0$ as $n \\to \\infty$, where\n$$\nx^{(n)} = \\bigg(\\frac{1}{n+1}, \\frac{1}{n+2}, \\dots, \\frac{1}{2n}, 0, 0, \\dots\\bigg).\n$$\n\nConvergence in $\\ell^{\\infty}$: Since the function $k \\mapsto \\frac{1}{n+k}$ is decreasing in $k$ for fixed $n$, we have\n$$\n\\|x^{(n)}\\|_{\\infty}=\\sup_{k \\ge 1} |x_{k}^{(n)}|=\\max_{1 \\le k \\le n} \\frac{1}{n+k}=\\frac{1}{n+1}.\n$$\nHence $\\|x^{(n)}\\|_{\\infty}=\\frac{1}{n+1} \\to 0$ as $n \\to \\infty$. Therefore, $x^{(n)} \\to 0$ in $\\ell^{\\infty}$.\n\nConvergence in $\\ell^{2}$: We compute\n$$\n\\|x^{(n)}\\|_{2}^{2}=\\sum_{k=1}^{n} \\left(\\frac{1}{n+k}\\right)^{2}=\\sum_{j=n+1}^{2n} \\frac{1}{j^{2}}.\n$$\nUsing the simple bound $\\frac{1}{j^{2}} \\le \\frac{1}{(n+1)^{2}}$ for $j \\in \\{n+1,\\dots,2n\\}$ and that there are $n$ terms, we obtain\n$$\n\\|x^{(n)}\\|_{2}^{2} \\le n \\cdot \\frac{1}{(n+1)^{2}}=\\frac{n}{(n+1)^{2}} \\to 0,\n$$\nso\n$$\n\\|x^{(n)}\\|_{2} \\le \\frac{\\sqrt{n}}{n+1} \\to 0.\n$$\nTherefore, $x^{(n)} \\to 0$ in $\\ell^{2}$.\n\nConvergence in $\\ell^{1}$: We have\n$$\n\\|x^{(n)}\\|_{1}=\\sum_{k=1}^{n} \\frac{1}{n+k}=\\sum_{j=n+1}^{2n} \\frac{1}{j}.\n$$\nUsing the integral test bounds for the decreasing function $f(x)=\\frac{1}{x}$,\n$$\n\\int_{n+1}^{2n+1} \\frac{1}{x}\\,dx \\le \\sum_{j=n+1}^{2n} \\frac{1}{j} \\le \\int_{n}^{2n} \\frac{1}{x}\\,dx,\n$$\nwhich yields\n$$\n\\ln\\!\\left(\\frac{2n+1}{n+1}\\right) \\le \\|x^{(n)}\\|_{1} \\le \\ln\\!\\left(\\frac{2n}{n}\\right)=\\ln(2).\n$$\nTaking limits as $n \\to \\infty$ gives\n$$\n\\|x^{(n)}\\|_{1} \\to \\ln(2) \\neq 0.\n$$\nHence $x^{(n)}$ does not converge to $0$ in $\\ell^{1}$.\n\nCombining these, the sequence converges to $0$ in $\\ell^{2}$ and $\\ell^{\\infty}$, but not in $\\ell^{1}$.", "answer": "$$\\boxed{D}$$", "id": "1854126"}]}