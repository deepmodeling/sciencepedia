{"hands_on_practices": [{"introduction": "Mastery of linear algebra begins with a firm grasp of its foundational definitions. This practice problem focuses on the concept of linear dependence, presenting a scenario that tests your understanding of a fundamental and non-negotiable rule. By analyzing a set of vectors that includes the zero vector, you will reinforce a critical property that simplifies the analysis of vector sets in any vector space [@problem_id:1868566].", "problem": "In a vector space $V$, a set of vectors $S = \\{\\mathbf{v}_1, \\mathbf{v}_2, \\dots, \\mathbf{v}_n\\}$ is defined as being **linearly dependent** if there exist scalars $c_1, c_2, \\dots, c_n$, which are not all zero, such that the equation $c_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2 + \\dots + c_n \\mathbf{v}_n = \\mathbf{0}$ is satisfied. A set that is not linearly dependent is called **linearly independent**.\n\nConsider the following statements about a set of vectors $S$ taken from an arbitrary non-trivial vector space $V$ (meaning $V$ contains vectors other than the zero vector $\\mathbf{0}$). Which of the following statements is necessarily true?\n\nA. If $S$ contains more vectors than the dimension of $V$, then $S$ must be linearly independent.\n\nB. If $S$ consists of exactly two non-zero vectors, then $S$ is always linearly independent.\n\nC. If the zero vector $\\mathbf{0}$ is an element of the set $S$, then $S$ must be linearly dependent.\n\nD. Any subset of a linearly dependent set $S$ is also linearly dependent.\n\nE. If $S$ is a linearly independent set, then any vector in $V$ can be written as a linear combination of the vectors in $S$.", "solution": "We analyze each statement using the definition: a set $S=\\{\\mathbf{v}_{1},\\dots,\\mathbf{v}_{n}\\}$ is linearly dependent if there exist scalars $c_{1},\\dots,c_{n}$, not all zero, such that $c_{1}\\mathbf{v}_{1}+\\cdots+c_{n}\\mathbf{v}_{n}=\\mathbf{0}$; otherwise it is linearly independent.\n\nFor A: If $S$ contains more vectors than $\\dim V$, then $S$ must be linearly independent. This contradicts the fundamental fact that in any vector space (finite- or infinite-dimensional), the cardinality of any linearly independent set is at most the dimension of the space. If $|S| > \\dim V$, then $S$ cannot be linearly independent; it must be linearly dependent. Therefore A is false.\n\nFor B: If $S$ consists of exactly two non-zero vectors, then $S$ is always linearly independent. This is false: take any non-zero $\\mathbf{v}\\in V$ and set $S=\\{\\mathbf{v},2\\mathbf{v}\\}$. Then $2\\mathbf{v}+(-1)(2\\mathbf{v})=\\mathbf{0}$ with coefficients not all zero, so $S$ is linearly dependent even though both vectors are non-zero.\n\nFor C: If $\\mathbf{0}\\in S$, then $S$ must be linearly dependent. This is true: if $S=\\{\\mathbf{0},\\mathbf{v}_{2},\\dots,\\mathbf{v}_{n}\\}$, choose $c_{1}=1$ for the coefficient of $\\mathbf{0}$ and $c_{2}=\\cdots=c_{n}=0$. Then $c_{1}\\mathbf{0}+\\cdots+c_{n}\\mathbf{v}_{n}=\\mathbf{0}$ with not all coefficients zero, so $S$ is linearly dependent.\n\nFor D: Any subset of a linearly dependent set $S$ is also linearly dependent. This is false: consider $S=\\{\\mathbf{e}_{1},\\mathbf{e}_{2},\\mathbf{e}_{1}+\\mathbf{e}_{2}\\}$ in a vector space containing two independent vectors (for instance $V=\\mathbb{R}^{2}$). We have $\\mathbf{e}_{1}+\\mathbf{e}_{2}-\\left(\\mathbf{e}_{1}+\\mathbf{e}_{2}\\right)=\\mathbf{0}$ with nontrivial coefficients, so $S$ is dependent. But the subset $\\{\\mathbf{e}_{1},\\mathbf{e}_{2}\\}$ is linearly independent because $c_{1}\\mathbf{e}_{1}+c_{2}\\mathbf{e}_{2}=\\mathbf{0}$ implies $c_{1}=c_{2}=0$.\n\nFor E: If $S$ is linearly independent, then any vector in $V$ can be written as a linear combination of vectors in $S$. This is false in general; linear independence does not imply spanning. For example, in $V=\\mathbb{R}^{3}$, $S=\\{\\mathbf{e}_{1},\\mathbf{e}_{2}\\}$ is linearly independent but does not span $V$, since $\\mathbf{e}_{3}$ cannot be expressed as a linear combination of $\\mathbf{e}_{1}$ and $\\mathbf{e}_{2}$.\n\nTherefore, the only statement that is necessarily true is C.", "answer": "$$\\boxed{C}$$", "id": "1868566"}, {"introduction": "Moving from abstract vectors to function spaces requires a shift in perspective. Linear dependence between functions is not always immediately apparent and can be concealed by familiar mathematical identities. This exercise challenges you to investigate a set of trigonometric functions and determine the true dimension of the space they span, highlighting how underlying relationships can reveal \"hidden\" dependencies [@problem_id:1868616].", "problem": "Consider the vector space $V = C(\\mathbb{R})$, which consists of all continuous real-valued functions defined on the entire real line. Let $W$ be the subspace of $V$ spanned by the set of functions $S = \\{f_1(x), f_2(x), f_3(x), f_4(x)\\}$, where:\n$f_1(x) = 1$\n$f_2(x) = \\sin^{2}(x)$\n$f_3(x) = \\cos^{2}(x)$\n$f_4(x) = \\cos(2x)$\n\nWhat is the dimension of the subspace $W$?\n\nA. 1\n\nB. 2\n\nC. 3\n\nD. 4", "solution": "We work in $V=C(\\mathbb{R})$ and consider $W=\\operatorname{span}\\{f_{1},f_{2},f_{3},f_{4}\\}$ with $f_{1}(x)=1$, $f_{2}(x)=\\sin^{2}(x)$, $f_{3}(x)=\\cos^{2}(x)$, and $f_{4}(x)=\\cos(2x)$.\n\nUse the trigonometric identities\n$$\n\\sin^{2}(x)+\\cos^{2}(x)=1, \\qquad \\cos(2x)=\\cos^{2}(x)-\\sin^{2}(x).\n$$\nFrom these, we obtain\n$$\nf_{1}=f_{2}+f_{3}, \\qquad f_{4}=f_{3}-f_{2}.\n$$\nAdding and subtracting the identities yield\n$$\n\\cos^{2}(x)=\\frac{1+\\cos(2x)}{2}, \\qquad \\sin^{2}(x)=\\frac{1-\\cos(2x)}{2}.\n$$\nHence $f_{2}$ and $f_{3}$ are linear combinations of $f_{1}$ and $f_{4}$. Since $f_{1}$ and $f_4$ are in the original set, we have\n$$\nW=\\operatorname{span}\\{1,\\cos(2x)\\}.\n$$\nTo determine the dimension, we show that $\\{1,\\cos(2x)\\}$ is a linearly independent set. Suppose $a\\cdot 1+b\\cos(2x)=0$ for all $x\\in\\mathbb{R}$. Evaluating at $x=0$ and $x=\\frac{\\pi}{2}$ gives\n$$\na+b=0, \\qquad a-b=0,\n$$\nwhich implies $a=0$ and $b=0$. Therefore $\\{1,\\cos(2x)\\}$ is linearly independent, so\n$$\n\\dim W=2.\n$$\nThus the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1868616"}, {"introduction": "A true test of understanding is the ability to not just analyze a vector space, but to construct its essential components, like a basis. This problem asks you to find a basis for a specific subspace of polynomials defined by an integral constraint, a common scenario in applied mathematics and physics. Successfully solving it requires you to translate a functional condition into a linear algebraic one and build a set of vectors that is both linearly independent and spans the entire subspace [@problem_id:1868605].", "problem": "Let $P_3(\\mathbb{R})$ denote the vector space of polynomials with real coefficients having a degree of at most 3. Consider the subspace $W$ of $P_3(\\mathbb{R})$ which is defined as the set of all polynomials $p(t)$ that satisfy the following integral condition:\n$$ \\int_{-1}^{1} p(t) dt = 0 $$\nWhich of the following sets of polynomials constitutes a basis for the subspace $W$?\n\nA. $\\{1, t, t^2\\}$\n\nB. $\\{t, t^3, 3t^2 - 1\\}$\n\nC. $\\{t, t^3\\}$\n\nD. $\\{t^2 - \\frac{1}{3}, t^3 - t, 1\\}$\n\nE. $\\{t, t^2, t^3\\}$", "solution": "To solve this problem, we first need to understand the structure of the subspace $W$ and determine its dimension. Then, we will evaluate each of the given options to see which one forms a basis for $W$.\n\nFirst, let's characterize the polynomials in $W$. The vector space $P_3(\\mathbb{R})$ consists of polynomials of the form $p(t) = a_3 t^3 + a_2 t^2 + a_1 t + a_0$, where $a_0, a_1, a_2, a_3$ are real coefficients. The condition for a polynomial $p(t)$ to be in the subspace $W$ is $\\int_{-1}^{1} p(t) dt = 0$.\n\nLet's compute the integral for a general polynomial in $P_3(\\mathbb{R})$:\n$$ \\int_{-1}^{1} (a_3 t^3 + a_2 t^2 + a_1 t + a_0) dt $$\nWe can integrate term by term:\n$$ \\left[ a_3 \\frac{t^4}{4} + a_2 \\frac{t^3}{3} + a_1 \\frac{t^2}{2} + a_0 t \\right]_{-1}^{1} $$\nEvaluating at the limits of integration:\n$$ \\left( a_3 \\frac{1^4}{4} + a_2 \\frac{1^3}{3} + a_1 \\frac{1^2}{2} + a_0 (1) \\right) - \\left( a_3 \\frac{(-1)^4}{4} + a_2 \\frac{(-1)^3}{3} + a_1 \\frac{(-1)^2}{2} + a_0 (-1) \\right) $$\n$$ \\left( \\frac{a_3}{4} + \\frac{a_2}{3} + \\frac{a_1}{2} + a_0 \\right) - \\left( \\frac{a_3}{4} - \\frac{a_2}{3} + \\frac{a_1}{2} - a_0 \\right) $$\n$$ \\frac{2a_2}{3} + 2a_0 $$\nThe condition for $p(t)$ to be in $W$ is thus $\\frac{2a_2}{3} + 2a_0 = 0$, which simplifies to $a_0 = -\\frac{a_2}{3}$.\n\nThis single linear constraint on the four coefficients $(a_0, a_1, a_2, a_3)$ reduces the dimension of the subspace by one. The dimension of $P_3(\\mathbb{R})$ is 4. Therefore, the dimension of the subspace $W$ is $\\dim(W) = \\dim(P_3(\\mathbb{R})) - 1 = 4 - 1 = 3$.\n\nA basis for a 3-dimensional vector space must contain exactly three linearly independent vectors that all belong to the space. With this knowledge, we can analyze the given options.\n\nA. $\\{1, t, t^2\\}$: Let's check if the polynomial $p(t)=1$ is in $W$. For this polynomial, $a_0=1, a_1=a_2=a_3=0$. The integral is $\\int_{-1}^{1} 1 dt = [t]_{-1}^{1} = 1 - (-1) = 2$. Since $2 \\neq 0$, the polynomial $p(t)=1$ is not in $W$. Thus, this set cannot be a basis for $W$.\n\nB. $\\{t, t^3, 3t^2 - 1\\}$: This set contains three polynomials. We need to check if all three are in $W$ and if they are linearly independent.\n- For $p_1(t) = t$: $\\int_{-1}^{1} t dt = \\left[\\frac{t^2}{2}\\right]_{-1}^{1} = \\frac{1}{2} - \\frac{1}{2} = 0$. So, $t \\in W$.\n- For $p_2(t) = t^3$: $\\int_{-1}^{1} t^3 dt = \\left[\\frac{t^4}{4}\\right]_{-1}^{1} = \\frac{1}{4} - \\frac{1}{4} = 0$. So, $t^3 \\in W$.\n- For $p_3(t) = 3t^2 - 1$: $\\int_{-1}^{1} (3t^2 - 1) dt = \\left[t^3 - t\\right]_{-1}^{1} = (1-1) - (-1 - (-1)) = 0$. So, $3t^2-1 \\in W$.\nAll three polynomials are in $W$. Since the dimension of $W$ is 3, we just need to confirm they are linearly independent. The polynomials in the set have degrees 1, 3, and 2. A set of polynomials of distinct degrees is always linearly independent. Therefore, this set forms a basis for $W$.\n\nC. $\\{t, t^3\\}$: This set contains only two vectors. Since the dimension of $W$ is 3, this set cannot span $W$ and therefore cannot be a basis.\n\nD. $\\{t^2 - \\frac{1}{3}, t^3 - t, 1\\}$: As established in the analysis of option A, the polynomial $p(t)=1$ is not in $W$. Therefore, this set cannot be a basis for $W$.\n\nE. $\\{t, t^2, t^3\\}$: Let's check the polynomial $p(t) = t^2$. The integral is $\\int_{-1}^{1} t^2 dt = \\left[\\frac{t^3}{3}\\right]_{-1}^{1} = \\frac{1}{3} - (-\\frac{1}{3}) = \\frac{2}{3}$. Since this is not zero, $t^2$ is not in $W$. Therefore, this set cannot be a basis for $W$.\n\nBased on the analysis, only the set in option B meets all the requirements for a basis of the subspace $W$.", "answer": "$$\\boxed{B}$$", "id": "1868605"}]}