{"hands_on_practices": [{"introduction": "The journey into self-adjoint operators begins with a firm grasp of their definition in the most concrete setting: finite-dimensional vector spaces. In this context, the abstract condition of an operator being its own adjoint translates to the tangible property of its matrix representation being Hermitian—equal to its own conjugate transpose. This exercise provides foundational practice in applying this definition to determine the properties of a composite operator, a crucial first step before tackling more abstract spaces [@problem_id:1879058].", "problem": "In the study of functional analysis, constructing operators with specific properties is a fundamental task. Consider the complex vector space $V = \\mathbb{C}^2$, equipped with the standard inner product. Let $A$ and $B$ be two linear operators on $V$. Their matrix representations with respect to the standard basis $\\{ (1,0), (0,1) \\}$ are given by:\n$$\nM_A = \\begin{pmatrix} 1 & 1+i \\\\ 1 & 2 \\end{pmatrix}\n\\quad \\text{and} \\quad\nM_B = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n$$\nA new operator, $L_{\\alpha}$, is defined as a linear combination of these operators: $L_{\\alpha} = A + \\alpha B$, where $\\alpha$ is a complex number.\n\nFind the complex number $\\alpha$ for which the operator $L_{\\alpha}$ is self-adjoint.", "solution": "On a complex inner product space with the standard inner product, a linear operator is self-adjoint if and only if its matrix in the standard basis is equal to its conjugate transpose. Denote the conjugate transpose by $^{*}$. For $L_{\\alpha} = A + \\alpha B$, its matrix is\n$$\nM_{L_{\\alpha}} = M_{A} + \\alpha M_{B}\n= \\begin{pmatrix} 1 & 1+i \\\\ 1 & 2 \\end{pmatrix} + \\alpha \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n= \\begin{pmatrix} 1 & 1+i+\\alpha \\\\ 1 & 2 \\end{pmatrix}.\n$$\nSelf-adjointness requires $M_{L_{\\alpha}} = M_{L_{\\alpha}}^{*}$. Compute the conjugate transpose:\n$$\nM_{L_{\\alpha}}^{*} = \\begin{pmatrix} 1 & 1 \\\\ 1 - i + \\overline{\\alpha} & 2 \\end{pmatrix}.\n$$\nEquating entries gives the conditions\n$$\n1+i+\\alpha = 1, \\quad 1 = 1 - i + \\overline{\\alpha}.\n$$\nFrom the first equation, $\\alpha = -i$. Substituting into the second,\n$$\n1 - i + \\overline{\\alpha} = 1 - i + i = 1,\n$$\nwhich holds, so the choice is consistent. Therefore, the unique value ensuring self-adjointness is $\\alpha = -i$.", "answer": "$$\\boxed{-i}$$", "id": "1879058"}, {"introduction": "After mastering the definition in finite dimensions, we can explore the general algebraic properties that self-adjoint operators possess in any Hilbert space. This practice problem investigates a fundamental question: does self-adjointness persist under inversion? Answering this requires moving from direct computation to a more abstract proof, reinforcing your understanding of how the adjoint operation interacts with other operator functions and highlighting why this property is essential for physical observables in quantum mechanics [@problem_id:1879002].", "problem": "In the mathematical formulation of quantum mechanics, physical observables (like position, momentum, or energy) are represented by self-adjoint operators on a complex Hilbert space $H$. Let $T: H \\to H$ be a bounded linear operator. The adjoint of $T$, denoted $T^*$, is the unique operator satisfying $\\langle Tx, y \\rangle = \\langle x, T^*y \\rangle$ for all vectors $x, y \\in H$. An operator $T$ is called self-adjoint if $T = T^*$. An operator $T$ is called invertible if there exists an operator $T^{-1}$ such that $T T^{-1} = T^{-1} T = I$, where $I$ is the identity operator.\n\nConsider a physical system whose energy is described by an observable represented by an invertible, self-adjoint, and bounded linear operator $T$. One might be interested in a related quantity represented by the operator $T^{-1}$. For this new operator to also represent a valid physical observable, it must also be self-adjoint.\n\nGiven these definitions, which one of the following statements about the inverse operator $T^{-1}$ is always true for any invertible, self-adjoint, bounded linear operator $T$ on a complex Hilbert space $H$?\n\nA. $T^{-1}$ is always self-adjoint.\n\nB. $T^{-1}$ is never self-adjoint.\n\nC. $T^{-1}$ is self-adjoint if and only if $T$ is also a unitary operator (i.e., $T^{-1} = T^*$).\n\nD. $T^{-1}$ is self-adjoint if and only if the Hilbert space $H$ is finite-dimensional.\n\nE. $T^{-1}$ is self-adjoint if and only if $T$ is a scalar multiple of the identity operator (i.e., $T = \\lambda I$ for some scalar $\\lambda \\neq 0$).", "solution": "We are given a bounded, invertible, self-adjoint operator $T$ on a complex Hilbert space $H$. We need to determine which statement about $T^{-1}$ is always true.\n\nFirst, recall the adjoint identities for bounded operators:\n1) $(AB)^{*} = B^{*} A^{*}$ for bounded operators $A,B$.\n2) $I^{*} = I$.\n3) If $T$ is invertible and bounded, then its inverse $T^{-1}$ is also bounded, and the inverse is unique.\n\nStart from the defining identities of the inverse:\n$$\nT T^{-1} = I \\quad \\text{and} \\quad T^{-1} T = I.\n$$\nTake adjoints of both equations and use $(AB)^{*} = B^{*} A^{*}$:\n$$\n(T T^{-1})^{*} = I \\implies (T^{-1})^{*} T^{*} = I,\n$$\n$$\n(T^{-1} T)^{*} = I \\implies T^{*} (T^{-1})^{*} = I.\n$$\nThese show that $(T^{-1})^{*}$ is both a left and right inverse of $T^{*}$. By uniqueness of inverses, it follows that\n$$\n(T^{-1})^{*} = (T^{*})^{-1}.\n$$\nNow use the self-adjointness of $T$, namely $T^{*} = T$, to obtain\n$$\n(T^{-1})^{*} = (T^{*})^{-1} = T^{-1}.\n$$\nTherefore $T^{-1}$ is self-adjoint.\n\nThis proves that for any bounded, invertible, self-adjoint operator $T$, the inverse $T^{-1}$ is also self-adjoint. Hence statement A is always true.\n\nTo see that the other statements are not valid:\n- C is false because unitarity is not required. For example, $T = \\lambda I$ with $\\lambda \\in \\mathbb{R}\\setminus\\{0\\}$ is self-adjoint and invertible; $T^{-1} = \\lambda^{-1} I$ is self-adjoint, but $T$ is unitary only when $|\\lambda| = 1$.\n- D is false because the argument above does not depend on the dimension of $H$; it holds equally in infinite-dimensional Hilbert spaces.\n- E is false because there are many non-scalar self-adjoint invertible operators whose inverses are self-adjoint; the identity $(T^{-1})^{*} = T^{-1}$ holds without $T$ being a scalar multiple of $I$.\n\nTherefore, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1879002"}, {"introduction": "The true power of functional analysis is in its application to infinite-dimensional spaces, such as spaces of functions. This problem introduces the Volterra integral operator, a classic example that appears in the study of differential and integral equations. By calculating its adjoint on the space $L^2([0,1])$, you will practice a key analytical technique—changing the order of integration—and see firsthand how the concept of the adjoint extends far beyond the simple conjugate transpose of a matrix [@problem_id:1879028].", "problem": "Consider the Hilbert space $L^2([0,1])$, which consists of complex-valued, square-integrable functions on the interval $[0,1]$. The inner product on this space is defined as $\\langle f, g \\rangle = \\int_0^1 f(x) \\overline{g(x)} dx$ for any functions $f, g \\in L^2([0,1])$.\n\nLet $V$ be the Volterra integral operator, which maps a function $f \\in L^2([0,1])$ to another function $(Vf)$ according to the rule:\n$$ (Vf)(x) = \\int_0^x f(t) dt $$\nAn operator $A$ is self-adjoint if it is equal to its adjoint operator $A^*$, where the adjoint is defined by the relation $\\langle Af, g \\rangle = \\langle f, A^*g \\rangle$ for all $f, g$ in the space.\n\nAnalyze the Volterra operator $V$ and determine which of the following statements is correct.\n\nA. $V$ is self-adjoint.\n\nB. $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = -\\int_0^x g(t) dt$.\n\nC. $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = \\int_x^1 g(t) dt$.\n\nD. $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = \\int_0^1 g(t) dt$.\n\nE. The adjoint operator $V^*$ does not exist for the Volterra operator on $L^2([0,1])$.", "solution": "To determine if the Volterra operator $V$ is self-adjoint, we must first find its adjoint operator, $V^*$. The adjoint operator is defined by the relation $\\langle Vf, g \\rangle = \\langle f, V^*g \\rangle$ for all functions $f, g \\in L^2([0,1])$.\n\nLet's start by calculating the left-hand side of the defining relation, $\\langle Vf, g \\rangle$. Using the definition of the inner product and the operator $V$:\n$$ \\langle Vf, g \\rangle = \\int_0^1 (Vf)(x) \\overline{g(x)} dx $$\nSubstituting the definition of $(Vf)(x)$:\n$$ \\langle Vf, g \\rangle = \\int_0^1 \\left( \\int_0^x f(t) dt \\right) \\overline{g(x)} dx $$\nThis is a double integral over a triangular region in the $tx$-plane. The region of integration is defined by the inequalities $0 \\le x \\le 1$ and $0 \\le t \\le x$. To proceed, we can change the order of integration. The current order is $dt$ then $dx$. We want to switch to $dx$ then $dt$.\n\nThe region can also be described by the inequalities $0 \\le t \\le 1$ and $t \\le x \\le 1$. This allows us to rewrite the integral as:\n$$ \\langle Vf, g \\rangle = \\int_0^1 \\int_t^1 \\left( f(t) \\overline{g(x)} \\right) dx dt $$\nSince $f(t)$ does not depend on $x$, we can move it outside the inner integral:\n$$ \\langle Vf, g \\rangle = \\int_0^1 f(t) \\left( \\int_t^1 \\overline{g(x)} dx \\right) dt $$\nWe want to express this in the form $\\langle f, V^*g \\rangle = \\int_0^1 f(t) \\overline{(V^*g)(t)} dt$. By comparing the two expressions, we can identify the term that corresponds to $\\overline{(V^*g)(t)}$:\n$$ \\overline{(V^*g)(t)} = \\int_t^1 \\overline{g(x)} dx $$\nTo find $(V^*g)(t)$, we take the complex conjugate of both sides.\n$$ (V^*g)(t) = \\overline{\\int_t^1 \\overline{g(x)} dx} $$\nThe conjugate of an integral is the integral of the conjugate:\n$$ (V^*g)(t) = \\int_t^1 \\overline{\\overline{g(x)}} dx = \\int_t^1 g(x) dx $$\nFor notational consistency, we can replace the integration variable $x$ with $t$ and the function variable $t$ with $x$:\n$$ (V^*g)(x) = \\int_x^1 g(t) dt $$\nNow we have found the adjoint operator $V^*$. We can compare it to the original operator $V$:\n$$ (Vf)(x) = \\int_0^x f(t) dt \\quad \\text{and} \\quad (V^*f)(x) = \\int_x^1 f(t) dt $$\nSince $(Vf)(x) \\neq (V^*f)(x)$ in general (for example, take $f(x)=1$, then $(Vf)(x)=x$ while $(V^*f)(x)=1-x$), the operator $V$ is not self-adjoint.\n\nThe correct statement is that $V$ is not self-adjoint, and its adjoint is given by $(V^*g)(x) = \\int_x^1 g(t) dt$. This corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1879028"}]}