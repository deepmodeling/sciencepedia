{"hands_on_practices": [{"introduction": "When first encountering spectra, it's tempting to assume they follow simple algebraic rules, such as additivity. This practice directly confronts that intuition by asking you to explore the spectrum of a sum of two operators in the familiar setting of $2 \\times 2$ matrices [@problem_id:1902879]. By working through this concrete counterexample, you will discover that $\\sigma(S+T)$ is not generally equal to $\\sigma(S) + \\sigma(T)$, a foundational insight into the non-trivial nature of spectral theory.", "problem": "In linear algebra and functional analysis, the spectrum of an operator is a generalization of the set of eigenvalues. For a finite-dimensional operator represented by a square matrix, the spectrum is precisely the set of its eigenvalues. Let $S$ and $T$ be two linear operators on a vector space. A natural question is how the spectrum of their sum, $\\sigma(S+T)$, relates to their individual spectra, $\\sigma(S)$ and $\\sigma(T)$.\n\nConsider the specific linear operators $S$ and $T$ acting on the vector space $\\mathbb{R}^2$, represented by the matrices:\n$$\nS = \\begin{pmatrix} 0 & 2 \\\\ 0 & 0 \\end{pmatrix}\n\\quad \\text{and} \\quad\nT = \\begin{pmatrix} 0 & 0 \\\\ 3 & 0 \\end{pmatrix}\n$$\nThe sum of two spectra, $\\sigma(S) + \\sigma(T)$, is defined as the set of all possible sums of an element from $\\sigma(S)$ and an element from $\\sigma(T)$. That is, $\\sigma(S) + \\sigma(T) = \\{s + t \\mid s \\in \\sigma(S), t \\in \\sigma(T)\\}$.\n\nThis problem demonstrates that the equality $\\sigma(S+T) = \\sigma(S) + \\sigma(T)$ does not hold in general. Find the positive real number $\\lambda$ which is an element of $\\sigma(S+T)$ but is not an element of $\\sigma(S) + \\sigma(T)$.", "solution": "For finite-dimensional operators represented by matrices over a field, the spectrum is the set of scalars $\\lambda$ for which the operator is not invertible, equivalently the set of roots of the characteristic polynomial, i.e., $\\sigma(A)=\\{\\lambda:\\det(A-\\lambda I)=0\\}$.\n\nCompute $\\sigma(S)$. The characteristic polynomial of $S$ is\n$$\n\\det(S-\\lambda I)=\\det\\begin{pmatrix}-\\lambda & 2 \\\\ 0 & -\\lambda\\end{pmatrix}=\\lambda^{2}.\n$$\nThus $\\sigma(S)=\\{0\\}$.\n\nCompute $\\sigma(T)$. The characteristic polynomial of $T$ is\n$$\n\\det(T-\\lambda I)=\\det\\begin{pmatrix}-\\lambda & 0 \\\\ 3 & -\\lambda\\end{pmatrix}=\\lambda^{2}.\n$$\nThus $\\sigma(T)=\\{0\\}$, and hence $\\sigma(S)+\\sigma(T)=\\{0\\}$.\n\nCompute $\\sigma(S+T)$. The sum is\n$$\nS+T=\\begin{pmatrix}0 & 2 \\\\ 3 & 0\\end{pmatrix}.\n$$\nIts characteristic polynomial is\n$$\n\\det(S+T-\\lambda I)=\\det\\begin{pmatrix}-\\lambda & 2 \\\\ 3 & -\\lambda\\end{pmatrix}=\\lambda^{2}-6.\n$$\nTherefore $\\sigma(S+T)=\\{-\\sqrt{6},\\sqrt{6}\\}$. The positive real element of $\\sigma(S+T)$ that is not in $\\sigma(S)+\\sigma(T)=\\{0\\}$ is $\\sqrt{6}$.", "answer": "$$\\boxed{\\sqrt{6}}$$", "id": "1902879"}, {"introduction": "Having established that spectra can behave unexpectedly, we now turn to a class of operators where their behavior is wonderfully predictable: multiplication operators. This exercise demonstrates how the spectrum of a multiplication operator on a space of continuous functions is directly determined by the range of the multiplying function [@problem_id:1902883]. You will apply the spectral mapping theorem for a simple shift, $\\sigma(T + cI) = \\sigma(T) + c$, providing a tangible way to visualize the spectrum as a geometric set in the complex plane.", "problem": "Let $X$ be the Banach space $C([0, 1])$ of all continuous complex-valued functions on the interval $[0, 1]$, equipped with the supremum norm $\\|f\\|_{\\infty} = \\sup_{t \\in [0, 1]} |f(t)|$.\n\nConsider a linear operator $T: X \\to X$ defined for any function $f \\in X$ by\n$$\n(Tf)(t) = (t^2 - 2it) f(t),\n$$\nwhere $t \\in [0, 1]$ and $i$ is the imaginary unit.\n\nA new operator $S: X \\to X$ is constructed from $T$ as $S = T + cI$, where $c = 3 - i$ is a complex constant and $I$ is the identity operator on $X$.\n\nThe spectrum of $S$, denoted $\\sigma(S)$, is a set of complex numbers. Determine the maximum value of the real part and the minimum value of the imaginary part over all complex numbers in $\\sigma(S)$. Present your result as an ordered pair $(\\max(\\text{Re}(z)), \\min(\\text{Im}(z)))$ for $z \\in \\sigma(S)$.", "solution": "We consider the multiplication operator $T$ on $X=C([0,1])$ given by $(Tf)(t)=m(t)f(t)$ with $m(t)=t^{2}-2it$. The operator $S=T+cI$ with $c=3-i$ is itself a multiplication operator by\n$$\ns(t)=m(t)+c=t^{2}-2it+3-i=(3+t^{2})+i(-2t-1).\n$$\nOn $C(K)$ with $K$ compact Hausdorff and $g\\in C(K)$, the spectrum of the multiplication operator $M_{g}$ equals the range $g(K)$ because:\n- If $\\lambda\\notin g(K)$, then $g-\\lambda$ has no zeros, so $1/(g-\\lambda)\\in C(K)$ and $(M_{g}-\\lambda I)^{-1}=M_{1/(g-\\lambda)}$ exists and is bounded; hence $\\lambda$ lies in the resolvent set.\n- If $\\lambda\\in g(K)$, then $g-\\lambda$ vanishes at some point, so $M_{g}-\\lambda I$ is not invertible; hence $\\lambda\\in\\sigma(M_{g})$.\nTherefore, $\\sigma(S)=s([0,1])$.\n\nWrite $s(t)$ in terms of its real and imaginary parts:\n$$\n\\operatorname{Re}(s(t))=3+t^{2}, \\qquad \\operatorname{Im}(s(t))=-2t-1, \\quad t\\in[0,1].\n$$\nTo find $\\max_{z\\in\\sigma(S)}\\operatorname{Re}(z)$, maximize $3+t^{2}$ over $[0,1]$. Since $\\frac{d}{dt}(3+t^{2})=2t\\geq 0$ on $[0,1]$, the maximum occurs at $t=1$, giving\n$$\n\\max_{z\\in\\sigma(S)}\\operatorname{Re}(z)=3+1=4.\n$$\nTo find $\\min_{z\\in\\sigma(S)}\\operatorname{Im}(z)$, minimize $-2t-1$ over $[0,1]$. This function is strictly decreasing since its derivative is $-2<0$, so the minimum occurs at $t=1$, giving\n$$\n\\min_{z\\in\\sigma(S)}\\operatorname{Im}(z)=-2\\cdot 1-1=-3.\n$$\nThus the ordered pair is $(4,-3)$.", "answer": "$$\\boxed{\\begin{pmatrix} 4 & -3 \\end{pmatrix}}$$", "id": "1902883"}, {"introduction": "The spectrum of an operator in an infinite-dimensional space is often richer than just its set of eigenvalues. This hands-on problem delves into this complexity by introducing the approximate point spectrum, which consists of 'almost' eigenvalues [@problem_id:1902919]. Your task is to explicitly construct a sequence of vectors in the Hilbert space $\\ell^2$ to show that a specific value belongs to this part of the spectrum, offering a deep, constructive understanding of a concept central to infinite-dimensional analysis.", "problem": "Consider the Hilbert space $\\ell^2$, which consists of all infinite sequences of complex numbers $x = (c_1, c_2, c_3, \\dots)$ such that the series $\\sum_{k=1}^{\\infty} |c_k|^2$ converges. The norm on this space is given by $\\|x\\|_{\\ell^2} = \\left(\\sum_{k=1}^{\\infty} |c_k|^2\\right)^{1/2}$. Let $\\{e_k\\}_{k=1}^{\\infty}$ be the standard orthonormal basis for $\\ell^2$, where $e_k$ is the sequence with a $1$ in the $k$-th position and zeros elsewhere.\n\nThe left shift operator, $L$, is a bounded linear operator on $\\ell^2$ defined by $L(c_1, c_2, c_3, \\dots) = (c_2, c_3, c_4, \\dots)$.\n\nA complex number $\\lambda$ is said to be in the approximate point spectrum of $L$, denoted $\\sigma_{ap}(L)$, if there exists a sequence of vectors $\\{x_n\\}_{n=1}^{\\infty}$ in $\\ell^2$ that satisfies two conditions:\n1.  $\\|x_n\\|_{\\ell^2} = 1$ for all $n \\ge 1$.\n2.  $\\lim_{n \\to \\infty} \\|(L - \\lambda I)x_n\\|_{\\ell^2} = 0$, where $I$ is the identity operator.\n\nYour task is to demonstrate that the value $\\lambda = 1$ belongs to the approximate point spectrum of the left shift operator $L$. You must do this by explicitly constructing a sequence $\\{x_n\\}$ that fulfills both of the conditions above.\n\nWhat is the general form of the vector $x_n$ in your constructed sequence? Express your answer as a single symbolic expression in terms of the standard basis vectors $e_k$ and the index $n$.", "solution": "Our goal is to find a sequence of vectors $\\{x_n\\}_{n=1}^{\\infty}$ in $\\ell^2$ that satisfies the following two conditions for $\\lambda=1$:\n1.  $\\|x_n\\|_{\\ell^2} = 1$ for all $n \\ge 1$.\n2.  $\\lim_{n \\to \\infty} \\|(L - I)x_n\\|_{\\ell^2} = 0$.\n\nLet's try to construct a sequence of vectors $x_n$ that are \"spread out\" over an increasing number of basis vectors. We propose a candidate sequence of the form $x_n = C_n \\sum_{k=1}^{n} e_k$, where $C_n$ is a normalization constant that we will determine.\n\nFirst, we enforce the unit norm condition, $\\|x_n\\|_{\\ell^2} = 1$. The vectors $\\{e_k\\}$ form an orthonormal basis, so the norm squared of a linear combination is the sum of the squares of the absolute values of the coefficients.\n$$\n\\|x_n\\|^2 = \\left\\| C_n \\sum_{k=1}^{n} e_k \\right\\|^2 = |C_n|^2 \\left\\| \\sum_{k=1}^{n} e_k \\right\\|^2\n$$\nThe vector $\\sum_{k=1}^{n} e_k$ is $(1, 1, \\dots, 1, 0, \\dots)$, with $n$ ones. Its norm squared is:\n$$\n\\left\\| \\sum_{k=1}^{n} e_k \\right\\|^2 = \\sum_{k=1}^{n} 1^2 = n\n$$\nSo, for the norm of $x_n$ to be 1, we must have:\n$$\n\\|x_n\\|^2 = |C_n|^2 n = 1\n$$\nThis gives $|C_n| = \\frac{1}{\\sqrt{n}}$. We can choose the positive real constant $C_n = \\frac{1}{\\sqrt{n}}$.\nThus, our candidate sequence of unit vectors is:\n$$\nx_n = \\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n} e_k\n$$\n\nNext, we must verify the second condition, that $\\|(L - I)x_n\\|_{\\ell^2}$ converges to 0 as $n \\to \\infty$. Let's first compute the vector $(L-I)x_n$.\nWe apply the operator $L$ to $x_n$:\n$$\nL x_n = L \\left( \\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n} e_k \\right) = \\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n} L e_k\n$$\nBy definition of the left shift operator, $L e_1 = 0$ (the zero vector) and $L e_k = e_{k-1}$ for $k > 1$. Applying this to the sum:\n$$\nL x_n = \\frac{1}{\\sqrt{n}} \\left( L e_1 + \\sum_{k=2}^{n} L e_k \\right) = \\frac{1}{\\sqrt{n}} \\left( 0 + \\sum_{k=2}^{n} e_{k-1} \\right)\n$$\nBy re-indexing the sum (let $j = k-1$), we get:\n$$\nL x_n = \\frac{1}{\\sqrt{n}} \\sum_{j=1}^{n-1} e_j\n$$\nNow we can compute $(L-I)x_n$:\n$$\n(L-I)x_n = L x_n - I x_n = \\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n-1} e_k - \\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n} e_k\n$$\n$$\n(L-I)x_n = \\frac{1}{\\sqrt{n}} \\left( \\left(\\sum_{k=1}^{n-1} e_k\\right) - \\left(\\left(\\sum_{k=1}^{n-1} e_k\\right) + e_n\\right) \\right)\n$$\n$$\n(L-I)x_n = - \\frac{1}{\\sqrt{n}} e_n\n$$\nFinally, we compute the norm of this resulting vector and evaluate its limit:\n$$\n\\|(L - I)x_n\\|_{\\ell^2} = \\left\\| - \\frac{1}{\\sqrt{n}} e_n \\right\\| = \\left| - \\frac{1}{\\sqrt{n}} \\right| \\|e_n\\|_{\\ell^2}\n$$\nSince $\\|e_n\\|_{\\ell^2} = 1$, we have:\n$$\n\\|(L - I)x_n\\|_{\\ell^2} = \\frac{1}{\\sqrt{n}}\n$$\nTaking the limit as $n \\to \\infty$:\n$$\n\\lim_{n \\to \\infty} \\|(L - I)x_n\\|_{\\ell^2} = \\lim_{n \\to \\infty} \\frac{1}{\\sqrt{n}} = 0\n$$\nBoth conditions are satisfied. The constructed sequence is indeed $x_n = \\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n} e_k$, which demonstrates that $\\lambda=1$ is in the approximate point spectrum of $L$.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{n}} \\sum_{k=1}^{n} e_k}$$", "id": "1902919"}]}