{"hands_on_practices": [{"introduction": "The Neumann series is a cornerstone of operator theory, providing a powerful method to construct the inverse of an operator, much like how the geometric series $1 + x + x^2 + \\dots$ gives us $(1-x)^{-1}$ for numbers. This series, $\\sum_{k=0}^{\\infty} T^k$, converges to $(I-T)^{-1}$ when the operator $T$ is \"small\" enough (specifically, when its norm is less than 1). This exercise provides a concrete, computational entry point into this fundamental concept by asking you to calculate the first few terms of the series for a simple $2 \\times 2$ matrix, building a tangible understanding of how the resolvent can be approximated [@problem_id:1899241].", "problem": "Consider a linear operator $T$ acting on the two-dimensional real vector space $\\mathbb{R}^2$. With respect to the standard basis, this operator is represented by the matrix:\n$$\nT = \\begin{pmatrix} 0 & \\frac{1}{2} \\\\ -\\frac{1}{3} & 0 \\end{pmatrix}\n$$\nLet $I$ be the identity operator, represented by the $2 \\times 2$ identity matrix. The Neumann series is often used to approximate the resolvent operator $(I-T)^{-1}$. The third partial sum of this series is defined as $S_3 = \\sum_{k=0}^{2} T^k = T^0 + T^1 + T^2$. By convention, $T^0 = I$.\n\nCalculate the matrix representation of this third partial sum, $S_3$. Express your answer as a single $2 \\times 2$ matrix with rational entries.", "solution": "We are given the linear operator $T$ on $\\mathbb{R}^{2}$ with matrix\n$$\nT=\\begin{pmatrix} 0 & \\frac{1}{2} \\\\ -\\frac{1}{3} & 0 \\end{pmatrix}.\n$$\nThe third partial sum of the Neumann series is $S_{3}=T^{0}+T^{1}+T^{2}=I+T+T^{2}$, where $I$ is the identity matrix. We first compute $T^{2}$ by matrix multiplication:\n$$\nT^{2}=T\\,T=\\begin{pmatrix} 0 & \\frac{1}{2} \\\\ -\\frac{1}{3} & 0 \\end{pmatrix}\\begin{pmatrix} 0 & \\frac{1}{2} \\\\ -\\frac{1}{3} & 0 \\end{pmatrix}\n=\\begin{pmatrix}\n0\\cdot 0+\\frac{1}{2}\\left(-\\frac{1}{3}\\right) & 0\\cdot \\frac{1}{2}+\\frac{1}{2}\\cdot 0 \\\\\n-\\frac{1}{3}\\cdot 0+0\\left(-\\frac{1}{3}\\right) & -\\frac{1}{3}\\cdot \\frac{1}{2}+0\\cdot 0\n\\end{pmatrix}\n=\\begin{pmatrix}\n-\\frac{1}{6} & 0 \\\\\n0 & -\\frac{1}{6}\n\\end{pmatrix}.\n$$\nThus $T^{2}=-\\frac{1}{6}I$. Therefore,\n$$\nS_{3}=I+T+T^{2}=I+T-\\frac{1}{6}I=\\left(1-\\frac{1}{6}\\right)I+T=\\frac{5}{6}I+T,\n$$\nwhich yields\n$$\nS_{3}=\\begin{pmatrix} \\frac{5}{6} & 0 \\\\ 0 & \\frac{5}{6} \\end{pmatrix}+\\begin{pmatrix} 0 & \\frac{1}{2} \\\\ -\\frac{1}{3} & 0 \\end{pmatrix}\n=\\begin{pmatrix} \\frac{5}{6} & \\frac{1}{2} \\\\ -\\frac{1}{3} & \\frac{5}{6} \\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{5}{6} & \\frac{1}{2} \\\\ -\\frac{1}{3} & \\frac{5}{6} \\end{pmatrix}}$$", "id": "1899241"}, {"introduction": "Moving from the clarity of finite-dimensional matrices to the abstraction of infinite-dimensional function spaces is a key step in functional analysis. This practice guides you through that transition by focusing on one of the most intuitive examples: the multiplication operator on the space of continuous functions, $C[0,1]$. You will explore how to determine the inverse of $(\\lambda I - T)$ and, crucially, how to calculate its operator norm, connecting this abstract concept to the familiar task of finding the maximum value of a function over an interval [@problem_id:1899220]. This hands-on calculation demystifies resolvents in function spaces and builds a bridge between operator theory and calculus.", "problem": "Consider the Banach space $X = C[0,1]$, which consists of all continuous real-valued functions on the interval $[0,1]$, equipped with the supremum norm defined as $\\|f\\|_{\\infty} = \\sup_{x \\in [0,1]} |f(x)|$. Let $T: X \\to X$ be a linear operator defined by the rule $(Tf)(x) = x^2 f(x)$ for any function $f \\in X$. Let $I$ be the identity operator on $X$. For the specific scalar value $\\lambda = 4$, the operator $(\\lambda I - T)$ is invertible. Your task is to compute the operator norm of its inverse, $\\|(\\lambda I - T)^{-1}\\|$.", "solution": "We work on $X=C[0,1]$ with the supremum norm $\\|f\\|_{\\infty}=\\sup_{x\\in[0,1]}|f(x)|$. The operator $T$ is multiplication by $x^{2}$, so for any $f\\in X$,\n$$\n(Tf)(x)=x^{2}f(x).\n$$\nFor $\\lambda=4$, the operator $(\\lambda I-T)$ acts as multiplication by $4-x^{2}$:\n$$\n\\bigl((4I-T)f\\bigr)(x)=(4-x^{2})f(x).\n$$\nSince $x^{2}\\in[0,1]$ for $x\\in[0,1]$, we have $4-x^{2}\\in[3,4]$, hence $4-x^{2}\\geq 3>0$ on $[0,1]$. Therefore $(4I-T)$ is invertible and its inverse is the multiplication operator by $(4-x^{2})^{-1}$:\n$$\n\\bigl((4I-T)^{-1}g\\bigr)(x)=\\frac{g(x)}{4-x^{2}}.\n$$\n\nOn $C[0,1]$, a multiplication operator $M_{m}$ given by $(M_{m}f)(x)=m(x)f(x)$ has operator norm\n$$\n\\|M_{m}\\|=\\sup_{x\\in[0,1]}|m(x)|.\n$$\nIndeed, for any $f$ with $\\|f\\|_{\\infty}=1$,\n$$\n\\|M_{m}f\\|_{\\infty}=\\sup_{x}|m(x)||f(x)|\\leq\\sup_{x}|m(x)|,\n$$\nand taking $f$ to be the constant function with value $\\operatorname{sgn}(m(x_{0}))$ at a point $x_{0}$ where $|m(x_{0})|=\\sup_{x}|m(x)|$ yields equality.\n\nApplying this to $m(x)=(4-x^{2})^{-1}$, we obtain\n$$\n\\|(4I-T)^{-1}\\|=\\sup_{x\\in[0,1]}\\left|\\frac{1}{4-x^{2}}\\right|=\\frac{1}{\\inf_{x\\in[0,1]}(4-x^{2})}=\\frac{1}{3}.\n$$\nThe infimum $\\inf_{x\\in[0,1]}(4-x^{2})$ equals $3$ because $x^{2}$ attains its maximum $1$ at $x=1$.", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1899220"}, {"introduction": "The sequence space $\\ell^2(\\mathbb{N})$ provides another essential playground for exploring the properties of operators, with the shift operators serving as canonical examples that model processes from digital signal processing to quantum mechanics. Determining the eigenvalues of an operator on a sequence space often translates the abstract equation $Ax = \\lambda x$ into a concrete recurrence relation for the components of the vector $x$. This exercise challenges you to find the point spectrum of a self-adjoint combination of shift operators, revealing a surprising and purely infinite-dimensional phenomenon: the complete absence of eigenvalues [@problem_id:1899244]. By working through the analysis, you will gain insight into why a non-zero solution may exist for the recurrence but fail to belong to the required Hilbert space.", "problem": "In the study of quantum walks on a line, one encounters operators acting on the Hilbert space $\\ell^2(\\mathbb{N})$, which consists of all infinite sequences of complex numbers $x = (x_1, x_2, x_3, \\dots)$ such that the series $\\sum_{k=1}^{\\infty} |x_k|^2$ converges. The inner product on this space is given by $\\langle x, y \\rangle = \\sum_{k=1}^{\\infty} x_k \\overline{y_k}$.\n\nLet $S$ be the right shift operator defined on $\\ell^2(\\mathbb{N})$ by $S(x_1, x_2, x_3, \\dots) = (0, x_1, x_2, \\dots)$. Its adjoint operator, the left shift operator, is given by $S^*(x_1, x_2, x_3, \\dots) = (x_2, x_3, x_4, \\dots)$.\n\nConsider the operator $A = S + S^*$. This operator serves as a simplified model for the hopping of a particle on a semi-infinite discrete chain. A complex number $\\lambda$ is an eigenvalue of $A$ if there exists a non-zero sequence $x \\in \\ell^2(\\mathbb{N})$, called an eigenvector, such that $Ax = \\lambda x$. The set of all such eigenvalues is known as the point spectrum of $A$, denoted $\\sigma_p(A)$.\n\nWhich of the following sets correctly describes the point spectrum of the operator $A = S + S^*$?\n\nA. $\\sigma_p(A) = [-2, 2]$\n\nB. $\\sigma_p(A) = (-2, 2)$\n\nC. $\\sigma_p(A) = \\{0\\}$\n\nD. $\\sigma_p(A) = \\emptyset$ (the empty set)\n\nE. $\\sigma_p(A) = \\mathbb{C}$", "solution": "We seek all $\\lambda \\in \\mathbb{C}$ for which there exists a nonzero $x \\in \\ell^{2}(\\mathbb{N})$ satisfying $Ax=\\lambda x$ with $A=S+S^{*}$. Writing $x=(x_{1},x_{2},\\dots)$, the eigenvalue equation gives the coordinate relations\n$$\n(Ax)_{1}=x_{2}=\\lambda x_{1},\n$$\nand for all $k\\geq 2$,\n$$\n(Ax)_{k}=x_{k-1}+x_{k+1}=\\lambda x_{k}.\n$$\nEquivalently, for $k\\geq 2$,\n$$\nx_{k+1}=\\lambda x_{k}-x_{k-1},\n$$\nand the boundary condition at $k=1$ is $x_{2}=\\lambda x_{1}$, which is consistent with extending the recurrence to $k=1$ by setting $x_{0}=0$.\n\nTo solve the recurrence, consider the characteristic equation\n$$\nr^{2}-\\lambda r+1=0,\n$$\nwith roots\n$$\nr_{\\pm}=\\frac{\\lambda \\pm \\sqrt{\\lambda^{2}-4}}{2}.\n$$\nFor $k\\geq 1$, the general solution of the recurrence has the form\n$$\nx_{k}=c_{+}r_{+}^{k-1}+c_{-}r_{-}^{k-1}.\n$$\nImposing the boundary condition $x_{2}=\\lambda x_{1}$ yields\n$$\nc_{+}r_{+}+c_{-}r_{-}=\\lambda(c_{+}+c_{-}).\n$$\nUsing $r_{+}+r_{-}=\\lambda$, this simplifies to\n$$\n(r_{+}-\\lambda)c_{+}+(r_{-}-\\lambda)c_{-}=0 \\quad \\Longleftrightarrow \\quad -r_{-}c_{+}-r_{+}c_{-}=0 \\quad \\Longleftrightarrow \\quad r_{-}c_{+}+r_{+}c_{-}=0.\n$$\nThus $c_{-}=-(r_{-}/r_{+})c_{+}$, and any solution satisfying the boundary condition is (up to scale)\n$$\nx_{k}=C\\left(r_{+}^{\\,k-1}-\\frac{r_{-}}{r_{+}}\\,r_{-}^{\\,k-1}\\right).\n$$\nUsing $r_{+}r_{-}=1$, we rewrite this as\n$$\nx_{k}=C\\left(r^{\\,k-1}-r^{-(k+1)}\\right), \\quad \\text{where } r:=r_{+}.\n$$\nWe now analyze when such a sequence is in $\\ell^{2}(\\mathbb{N})$.\n\n1) If $|r|>1$, then $|r|^{k-1}$ grows exponentially while $|r|^{-(k+1)}$ decays; hence $x_{k}$ grows exponentially in $k$ unless $C=0$, so no nontrivial $\\ell^{2}$ solution exists.\n\n2) If $|r|<1$, then $|r|^{-(k+1)}$ grows exponentially while $|r|^{k-1}$ decays; again $x_{k}$ is not in $\\ell^{2}$ unless $C=0$.\n\n3) If $|r|=1$, which occurs exactly when $\\lambda \\in [-2,2]$ (including the double-root cases $\\lambda=\\pm 2$), then both terms have modulus $1$ and do not decay. Specifically:\n- For $\\lambda \\in (-2,2)$, write $r=\\exp(i\\theta)$, so $x_{k}$ is a bounded oscillatory sequence and not square-summable unless $C=0$.\n- For $\\lambda=\\pm 2$, the characteristic root is repeated $r=\\pm 1$, and the general solution is $x_{k}=(a+bk)(\\pm 1)^{k-1}$. The boundary condition forces $a=0$, leaving $x_{k}=bk(\\pm 1)^{k-1}$, which grows linearly and is not in $\\ell^{2}$ unless $b=0$.\n\nTherefore, for all $\\lambda \\in \\mathbb{C}$, the only $\\ell^{2}$ solution is the trivial one, so $A$ has no eigenvalues. Hence the point spectrum is empty.\n\nConsequently, among the given options, the correct description is the empty set.", "answer": "$$\\boxed{D}$$", "id": "1899244"}]}