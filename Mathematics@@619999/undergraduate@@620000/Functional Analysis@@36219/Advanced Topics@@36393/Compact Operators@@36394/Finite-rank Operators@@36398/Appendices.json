{"hands_on_practices": [{"introduction": "Understanding a new class of objects in mathematics often begins with a direct, hands-on computation. This first practice invites you to do just that by calculating the rank of a linear operator defined on an infinite-dimensional space. By working through this example [@problem_id:1863147], you will solidify your understanding of the core definition of a finite-rank operator—the dimension of its range—and see how it applies beyond the familiar context of finite-dimensional matrices.", "problem": "Let $c_0$ be the vector space of all real-valued sequences $\\{x_n\\}_{n=1}^{\\infty}$ that converge to zero, i.e., $\\lim_{n \\to \\infty} x_n = 0$. Consider the linear operator $T: c_0 \\to c_0$ defined by\n$$T(\\{x_n\\}_{n=1}^{\\infty}) = (x_1+x_2, x_1+x_2, 0, 0, 0, \\dots)$$\nfor any sequence $\\{x_n\\}_{n=1}^{\\infty}$ in $c_0$.\n\nThe rank of a linear operator is defined as the dimension of its range. Determine the rank of the operator $T$.", "solution": "We consider the vector space $c_{0}$ of all real sequences $\\{x_{n}\\}_{n=1}^{\\infty}$ with $\\lim_{n \\to \\infty} x_{n} = 0$. Define the linear operator $T: c_{0} \\to c_{0}$ by\n$$\nT(\\{x_{n}\\}_{n=1}^{\\infty}) = (x_{1} + x_{2},\\, x_{1} + x_{2},\\, 0,\\, 0,\\, 0, \\dots).\n$$\nFirst, for any $\\{x_{n}\\} \\in c_{0}$, set $s = x_{1} + x_{2} \\in \\mathbb{R}$. Then\n$$\nT(\\{x_{n}\\}) = (s, s, 0, 0, \\dots),\n$$\nwhich shows that every image lies in the one-dimensional subspace\n$$\n\\operatorname{span}\\{(1, 1, 0, 0, \\dots)\\}.\n$$\nHence,\n$$\n\\operatorname{ran}(T) \\subseteq \\operatorname{span}\\{(1, 1, 0, 0, \\dots)\\}.\n$$\nTo prove the reverse inclusion, let $a \\in \\mathbb{R}$ be arbitrary. Consider the sequence $y = (a, 0, 0, 0, \\dots) \\in c_{0}$. Then\n$$\nT(y) = (a + 0, a + 0, 0, 0, \\dots) = (a, a, 0, 0, \\dots),\n$$\nshowing that every vector of the form $(a, a, 0, 0, \\dots)$ is in the range. Therefore,\n$$\n\\operatorname{ran}(T) = \\operatorname{span}\\{(1, 1, 0, 0, \\dots)\\}.\n$$\nThe spanning vector $(1, 1, 0, 0, \\dots)$ is nonzero, hence the range is a one-dimensional subspace of $c_{0}$. By definition, the rank of $T$ is the dimension of its range, so\n$$\n\\operatorname{rank}(T) = 1.\n$$", "answer": "$$\\boxed{1}$$", "id": "1863147"}, {"introduction": "Linear operators can exhibit a rich variety of behaviors that go beyond simple scaling or rotation. This exercise [@problem_id:1863144] challenges you to construct a non-trivial, rank-one operator whose square is the zero operator, a property known as nilpotency. This hands-on task reveals a crucial structural concept: an operator's range can be a subspace of its null space, leading to powerful applications in both pure mathematics and physics.", "problem": "Consider the vector space $\\mathbb{R}^2$ over the field of real numbers. A linear operator on this space is a linear transformation $T: \\mathbb{R}^2 \\to \\mathbb{R}^2$. The rank of an operator is defined as the dimension of its image (or range).\n\nYour task is to find an example of a linear operator $T$ on $\\mathbb{R}^2$ that satisfies all of the following conditions simultaneously:\n1. $T$ is not the zero operator (i.e., there exists at least one vector $x$ such that $T(x) \\neq 0$).\n2. The rank of $T$ is exactly one.\n3. The composition of the operator with itself, denoted $T^2 = T \\circ T$, is the zero operator (i.e., $T^2(x) = 0$ for all $x \\in \\mathbb{R}^2$).\n\nProvide the matrix representation of one such operator $T$ with respect to the standard basis of $\\mathbb{R}^2$.", "solution": "Let $T$ be the linear operator represented in the standard basis by the matrix\n$$\nA=\\begin{pmatrix}\n0 & 1\\\\\n0 & 0\n\\end{pmatrix}.\n$$\nA matrix defines a linear operator via $T(x)=Ax$, so $T$ is linear. To verify that $T$ is not the zero operator, evaluate $T$ on $e_{2}=\\begin{pmatrix}0\\\\1\\end{pmatrix}$:\n$$\nT(e_{2})=A\\begin{pmatrix}0\\\\1\\end{pmatrix}=\\begin{pmatrix}1\\\\0\\end{pmatrix}\\neq\\begin{pmatrix}0\\\\0\\end{pmatrix}.\n$$\nTo compute the rank, note that the columns of $A$ are $v_{1}=\\begin{pmatrix}0\\\\0\\end{pmatrix}$ and $v_{2}=\\begin{pmatrix}1\\\\0\\end{pmatrix}$. Hence the column space is $\\operatorname{span}\\{v_{2}\\}$, which has dimension $1$, so $\\operatorname{rank}(T)=1$.\n\nFinally, compute $T^{2}$ by matrix multiplication:\n$$\nA^{2}=A\\,A=\\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix}\\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix}\n=\\begin{pmatrix}0\\cdot 0+1\\cdot 0 & 0\\cdot 1+1\\cdot 0\\\\ 0\\cdot 0+0\\cdot 0 & 0\\cdot 1+0\\cdot 0\\end{pmatrix}\n=\\begin{pmatrix}0 & 0\\\\ 0 & 0\\end{pmatrix}.\n$$\nTherefore $T^{2}$ is the zero operator. This $T$ satisfies all three required conditions.", "answer": "$$\\boxed{\\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix}}$$", "id": "1863144"}, {"introduction": "Finite-rank operators form an algebra, meaning we can add them and compose them. This practice [@problem_id:1863149] explores the fundamental arithmetic of these operators by examining the sum of two rank-one \"building blocks.\" Determining the condition under which their sum remains a simple rank-one operator is key to understanding how more complex operators are constructed and is a foundational step toward the theory of approximating compact operators.", "problem": "In many areas of applied mathematics, such as signal compression and machine learning, complex systems are often approximated by simpler, low-rank operators. A rank-one operator is the most fundamental building block in this context.\n\nLet $H$ be a complex Hilbert space with an inner product $\\langle \\cdot, \\cdot \\rangle$ that is linear in the first argument and conjugate-linear in the second. Consider two non-zero, rank-one operators, $T_1: H \\to H$ and $T_2: H \\to H$, defined by\n$$\nT_1(x) = \\langle x, v_1 \\rangle u_1\n$$\n$$\nT_2(x) = \\langle x, v_2 \\rangle u_2\n$$\nfor some non-zero vectors $u_1, u_2, v_1, v_2$ in $H$. Let $S = T_1 + T_2$ be their sum. Assume that $S$ is not the zero operator.\n\nWhich of the following is the necessary and sufficient condition for the operator $S$ to have a rank of one?\n\nA. The set $\\{u_1, u_2\\}$ is linearly dependent and the set $\\{v_1, v_2\\}$ is linearly dependent.\n\nB. At least one of the sets $\\{u_1, u_2\\}$ or $\\{v_1, v_2\\}$ is linearly dependent.\n\nC. The vectors are orthogonal, i.e., $\\langle u_1, u_2 \\rangle = 0$ and $\\langle v_1, v_2 \\rangle = 0$.\n\nD. The set $\\{u_1, u_2\\}$ is linearly dependent or the set $\\{v_1, v_2\\}$ is linearly dependent, but not both.\n\nE. The set $\\{u_1, u_2\\}$ is linearly independent and the set $\\{v_1, v_2\\}$ is linearly independent.", "solution": "We consider $T_{1}(x) = \\langle x, v_{1} \\rangle u_{1}$ and $T_{2}(x) = \\langle x, v_{2} \\rangle u_{2}$ with nonzero $u_{1},u_{2},v_{1},v_{2} \\in H$, and their sum $S = T_{1} + T_{2}$ given by\n$$\nSx = \\langle x, v_{1} \\rangle u_{1} + \\langle x, v_{2} \\rangle u_{2}.\n$$\nThe range of $S$ is contained in $\\operatorname{span}\\{u_{1},u_{2}\\}$, so $\\operatorname{rank}(S) \\leq 2$. We assume $S$ is not the zero operator and seek necessary and sufficient conditions for $\\operatorname{rank}(S) = 1$.\n\nSufficiency when at least one of $\\{u_{1},u_{2}\\}$ or $\\{v_{1},v_{2}\\}$ is linearly dependent:\n- If $u_{2}$ is a scalar multiple of $u_{1}$, say $u_{2} = \\alpha u_{1}$ with $\\alpha \\in \\mathbb{C}$, then using the conjugate-linearity in the second argument,\n$$\nSx = \\langle x, v_{1} \\rangle u_{1} + \\alpha \\langle x, v_{2} \\rangle u_{1}\n= \\big( \\langle x, v_{1} \\rangle + \\langle x, \\overline{\\alpha} v_{2} \\rangle \\big) u_{1}\n= \\langle x, v_{1} + \\overline{\\alpha} v_{2} \\rangle\\, u_{1}.\n$$\nThus $S$ is rank one (and nonzero precisely when $v_{1} + \\overline{\\alpha} v_{2} \\neq 0$).\n\n- If $v_{2}$ is a scalar multiple of $v_{1}$, say $v_{2} = \\beta v_{1}$, then\n$$\nSx = \\langle x, v_{1} \\rangle u_{1} + \\langle x, \\beta v_{1} \\rangle u_{2}\n= \\langle x, v_{1} \\rangle \\big( u_{1} + \\overline{\\beta}\\, u_{2} \\big),\n$$\nso $S$ is again rank one (and nonzero precisely when $u_{1} + \\overline{\\beta} u_{2} \\neq 0$).\n\nHence, if at least one of the sets $\\{u_{1},u_{2}\\}$ or $\\{v_{1},v_{2}\\}$ is linearly dependent, then $S$ has rank one (unless there is complete cancellation yielding the zero operator, which is excluded by assumption).\n\nNecessity: if both $\\{u_{1},u_{2}\\}$ and $\\{v_{1},v_{2}\\}$ are linearly independent, then $\\operatorname{rank}(S) = 2$.\nSince $v_{1}, v_{2}$ are linearly independent, the Gram matrix\n$$\nG = \\begin{pmatrix}\n\\langle v_{1}, v_{1} \\rangle & \\langle v_{1}, v_{2} \\rangle \\\\\n\\langle v_{2}, v_{1} \\rangle & \\langle v_{2}, v_{2} \\rangle\n\\end{pmatrix}\n$$\nis invertible. Therefore there exist $x_{1}, x_{2} \\in \\operatorname{span}\\{v_{1}, v_{2}\\}$ such that\n$$\n\\langle x_{1}, v_{1} \\rangle = 1,\\quad \\langle x_{1}, v_{2} \\rangle = 0,\\qquad\n\\langle x_{2}, v_{1} \\rangle = 0,\\quad \\langle x_{2}, v_{2} \\rangle = 1.\n$$\nThen\n$$\nSx_{1} = u_{1}, \\qquad Sx_{2} = u_{2}.\n$$\nIf $u_{1},u_{2}$ are linearly independent, the range of $S$ contains two independent vectors, so $\\operatorname{rank}(S) \\geq 2$. Since $\\operatorname{rank}(S) \\leq 2$, we have $\\operatorname{rank}(S) = 2$, which rules out rank one. Hence, for $\\operatorname{rank}(S) = 1$, it is necessary that at least one of $\\{u_{1},u_{2}\\}$ or $\\{v_{1},v_{2}\\}$ be linearly dependent.\n\nCombining both directions and recalling the assumption that $S \\neq 0$ (which excludes the special cancellation when both pairs are dependent and the sum vanishes), the necessary and sufficient condition for $\\operatorname{rank}(S) = 1$ is: at least one of the sets $\\{u_{1},u_{2}\\}$ or $\\{v_{1},v_{2}\\}$ is linearly dependent.\n\nTherefore, the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1863149"}]}