{"hands_on_practices": [{"introduction": "To ground the theory of score tests in a familiar context, we begin with one of the most fundamental problems in statistics: testing a hypothesis about a population proportion. This exercise demonstrates how to apply the general \"recipe\" for a score test—involving the score function and Fisher information—to a simple Bernoulli model. By working through this example, you will see how the abstract framework leads to a well-known and intuitive test statistic for analyzing binary outcomes.", "problem": "Consider a simplified model for a digital communication channel where individual bits are transmitted. The transmission of each bit is subject to a potential bit-flip error (a 0 becomes a 1, or a 1 becomes a 0) with a constant probability $p$. We can model the occurrence of an error for each bit as an independent Bernoulli trial. Let $X_i$ be a random variable for the $i$-th bit transmission, where $X_i=1$ if an error occurs and $X_i=0$ if the transmission is successful.\n\nAn engineer collects a random sample of $n$ transmissions to test if the error rate equals a specific design value, $p_0$. The total number of observed bit-flip errors in the sample is denoted by $T = \\sum_{i=1}^{n} X_i$.\n\nYour task is to construct the Rao's score test statistic for the null hypothesis $H_0: p = p_0$ against the alternative hypothesis $H_a: p \\neq p_0$. Express the statistic as a function of the sample size $n$, the total number of observed errors $T$, and the hypothesized error rate $p_0$.", "solution": "We model $X_{i} \\sim \\text{Bernoulli}(p)$ independently, so $T=\\sum_{i=1}^{n}X_{i} \\sim \\text{Binomial}(n,p)$. The likelihood for $p$ given $T$ is\n$$\nL(p;T)=\\binom{n}{T}p^{T}(1-p)^{n-T},\n$$\nand the log-likelihood is\n$$\n\\ell(p)=\\ln L(p;T)=\\ln\\binom{n}{T}+T\\ln p+(n-T)\\ln(1-p).\n$$\nThe score function is the first derivative with respect to $p$:\n$$\nU(p)=\\frac{\\partial \\ell}{\\partial p}=\\frac{T}{p}-\\frac{n-T}{1-p}.\n$$\nThe Fisher information is\n$$\nI(p)=-\\mathbb{E}\\!\\left[\\frac{\\partial^{2}\\ell}{\\partial p^{2}}\\right]\n=-\\mathbb{E}\\!\\left[-\\frac{T}{p^{2}}-\\frac{n-T}{(1-p)^{2}}\\right]\n=\\frac{n}{p(1-p)},\n$$\nusing $\\mathbb{E}[T]=np$. Under the null hypothesis $H_{0}:p=p_{0}$ with $0<p_{0}<1$, evaluate the score and information at $p_{0}$:\n$$\nU(p_{0})=\\frac{T}{p_{0}}-\\frac{n-T}{1-p_{0}}=\\frac{T-np_{0}}{p_{0}(1-p_{0})},\\qquad I(p_{0})=\\frac{n}{p_{0}(1-p_{0})}.\n$$\nRao’s score test statistic is\n$$\nS=\\frac{U(p_{0})^{2}}{I(p_{0})}\n=\\frac{\\left(\\dfrac{T-np_{0}}{p_{0}(1-p_{0})}\\right)^{2}}{\\dfrac{n}{p_{0}(1-p_{0})}}\n=\\frac{(T-np_{0})^{2}}{n\\,p_{0}(1-p_{0})}.\n$$\nEquivalently, the standardized score is $Z=(T-np_{0})/\\sqrt{n\\,p_{0}(1-p_{0})}$ and $S=Z^{2}$.", "answer": "$$\\boxed{\\frac{(T-np_{0})^{2}}{n\\,p_{0}(1-p_{0})}}$$", "id": "1953755"}, {"introduction": "Building on the foundational skill of deriving a test statistic, this next practice shifts our focus to concrete application. We will work with the Pareto distribution, a model frequently used in economics to describe wealth or income inequality. This exercise takes you a step further by moving from symbolic derivation to a numerical calculation, using a summary statistic from a hypothetical dataset to evaluate an economic theory.", "problem": "Economists are studying a model of wealth distribution in a particular country. They model the wealth $X$ of an individual, measured in millions of dollars, using a Pareto Type I distribution. The probability density function (PDF) is given by $f(x; \\alpha, x_m) = \\frac{\\alpha x_m^\\alpha}{x^{\\alpha+1}}$ for $x \\ge x_m > 0$. The minimum wealth parameter $x_m$ is known to be fixed at $x_m = 1$ million dollars. The shape parameter $\\alpha$, which determines the degree of wealth inequality, is unknown.\n\nA dominant economic theory proposes that the shape parameter is $\\alpha = 1.5$. To test this theory, a random sample of $n=100$ individuals is collected. The data from this sample yields the summary statistic $\\sum_{i=1}^{100} \\ln(x_i) = 75$, where $x_i$ is the wealth of the $i$-th individual in the sample.\n\nCalculate the value of the Rao's score test statistic for testing the null hypothesis $H_0: \\alpha = 1.5$. Round your final answer to four significant figures.", "solution": "For a Pareto Type I distribution with known $x_{m}=1$, the density is $f(x;\\alpha)=\\alpha x^{-(\\alpha+1)}$ for $x\\geq 1$. For an i.i.d. sample $\\{x_{i}\\}_{i=1}^{n}$, the log-likelihood is\n$$\n\\ell(\\alpha)=\\sum_{i=1}^{n}\\left[\\ln(\\alpha)-(\\alpha+1)\\ln(x_{i})\\right]\n= n\\ln(\\alpha)-(\\alpha+1)\\sum_{i=1}^{n}\\ln(x_{i}).\n$$\nThe score function is\n$$\nU(\\alpha)=\\frac{\\partial \\ell}{\\partial \\alpha}=\\frac{n}{\\alpha}-\\sum_{i=1}^{n}\\ln(x_{i}),\n$$\nand the Fisher information is\n$$\nI(\\alpha)=-\\mathbb{E}\\left[\\frac{\\partial^{2}\\ell}{\\partial \\alpha^{2}}\\right]\n=-\\mathbb{E}\\left[-\\frac{n}{\\alpha^{2}}\\right]=\\frac{n}{\\alpha^{2}}.\n$$\nRao’s score test statistic for testing $H_{0}:\\alpha=\\alpha_{0}$ is\n$$\nS=\\frac{U(\\alpha_{0})^{2}}{I(\\alpha_{0})}.\n$$\nWith $n=100$, $\\sum_{i=1}^{100}\\ln(x_{i})=75$, and $\\alpha_{0}=1.5$, compute\n$$\nU(\\alpha_{0})=\\frac{100}{1.5}-75=\\frac{200}{3}-75=\\frac{200}{3}-\\frac{225}{3}=-\\frac{25}{3},\n$$\nand\n$$\nI(\\alpha_{0})=\\frac{100}{(1.5)^{2}}=\\frac{100}{\\frac{9}{4}}=\\frac{400}{9}.\n$$\nTherefore,\n$$\nS=\\frac{\\left(-\\frac{25}{3}\\right)^{2}}{\\frac{400}{9}}=\\frac{\\frac{625}{9}}{\\frac{400}{9}}=\\frac{625}{400}=1.5625.\n$$\nRounded to four significant figures, the test statistic is $1.563$.", "answer": "$$\\boxed{1.563}$$", "id": "1953913"}, {"introduction": "After mastering the construction and computation of a score test, a critical question remains: how effective is the test at detecting small, but real, deviations from the null hypothesis? This final practice delves into the theoretical power of the score test by analyzing its behavior under a sequence of \"local\" alternatives. By deriving the non-centrality parameter of the test's asymptotic distribution, we can quantify its ability to find an effect, providing a deeper understanding of its performance as a statistical tool.", "problem": "Consider a sample of independent and identically distributed random variables $X_1, X_2, \\dots, X_n$. These observations are drawn from a location family model with a probability density function (PDF) given by the standard logistic distribution shifted by a parameter $\\theta$. The PDF is defined as:\n$$\nf(x; \\theta) = \\frac{\\exp(-(x-\\theta))}{\\left(1 + \\exp(-(x-\\theta))\\right)^2}\n$$\nfor $x \\in (-\\infty, \\infty)$ and $\\theta \\in (-\\infty, \\infty)$.\n\nWe are interested in testing the null hypothesis $H_0: \\theta = 0$. To analyze the performance of the score test for this hypothesis, we consider a sequence of local alternatives, $H_{1,n}$, defined by $\\theta_n = \\delta / \\sqrt{n}$, where $\\delta$ is a non-zero real constant.\n\nUnder standard regularity conditions, the score test statistic, $W$, for $H_0: \\theta = 0$ converges in distribution under the sequence of alternatives $H_{1,n}$ to a non-central chi-squared distribution with one degree of freedom, denoted $\\chi^2_1(\\lambda)$.\n\nYour task is to derive the non-centrality parameter $\\lambda$ for this asymptotic distribution. The final answer should be a closed-form analytic expression in terms of the constant $\\delta$.", "solution": "We have a location family with density $f(x;\\theta)=g(x-\\theta)$ where $g(y)=\\exp(-y)\\left(1+\\exp(-y)\\right)^{-2}$ is the standard logistic density and $F(y)=\\left(1+\\exp(-y)\\right)^{-1}$ its cumulative distribution function. For one observation, the log-likelihood is $\\ell(\\theta;x)=\\ln g(x-\\theta)$. The score for $\\theta$ is\n$$\nU(\\theta;x)=\\frac{\\partial}{\\partial \\theta}\\ell(\\theta;x)=1-\\frac{2}{1+\\exp(x-\\theta)}=\\frac{\\exp(x-\\theta)-1}{\\exp(x-\\theta)+1}=2F(x-\\theta)-1=\\tanh\\!\\left(\\frac{x-\\theta}{2}\\right).\n$$\nThe Fisher information per observation is\n$$\nI(\\theta)=\\operatorname{E}_{\\theta}\\!\\left[U(\\theta;X)^{2}\\right],\n$$\nsince $\\operatorname{E}_{\\theta}[U(\\theta;X)]=0$ by standard regularity for scores. Set $Y=X-\\theta\\sim g$. Then $U(\\theta;X)=2F(Y)-1$. By the probability integral transform, $T=F(Y)\\sim \\operatorname{Uniform}(0,1)$, hence $U=2T-1\\sim \\operatorname{Uniform}(-1,1)$. Therefore\n$$\nI(\\theta)=\\operatorname{E}[U^{2}]=\\int_{-1}^{1}u^{2}\\cdot\\frac{1}{2}\\,du=\\frac{1}{3},\n$$\nwhich is constant in $\\theta$, so in particular $I(0)=\\frac{1}{3}$.\n\nLet $S_{n}(0)=\\sum_{i=1}^{n}U(0;X_{i})$ and $I_{n}(0)=nI(0)$. The score test statistic is $W=\\frac{S_{n}(0)^{2}}{I_{n}(0)}$. Under the local alternatives $\\theta_{n}=\\delta/\\sqrt{n}$, by local asymptotic normality and Le Cam’s third lemma,\n$$\n\\frac{S_{n}(0)}{\\sqrt{n}}\\;\\xrightarrow{d}\\; \\mathcal{N}\\!\\left(\\delta I(0),\\,I(0)\\right).\n$$\nHence\n$$\nW=\\frac{S_{n}(0)^{2}}{n I(0)}=\\left(\\frac{S_{n}(0)/\\sqrt{n}-\\delta I(0)}{\\sqrt{I(0)}}+\\delta\\sqrt{I(0)}\\right)^{2}\\;\\xrightarrow{d}\\;\\chi^{2}_{1}\\!\\left(\\lambda\\right),\n$$\nwith non-centrality parameter\n$$\n\\lambda=\\left(\\delta\\sqrt{I(0)}\\right)^{2}=\\delta^{2}I(0)=\\frac{\\delta^{2}}{3}.\n$$\nTherefore, the required non-centrality parameter is $\\lambda=\\delta^{2}/3$.", "answer": "$$\\boxed{\\frac{\\delta^{2}}{3}}$$", "id": "1953925"}]}