{"hands_on_practices": [{"introduction": "The core of Gibbs sampling is the process of iteratively drawing from conditional distributions to approximate a complex joint distribution. This first exercise provides a concrete, step-by-step walkthrough of one full iteration of the sampler. By manually generating random variates using the inverse transform sampling method, you will gain a fundamental, hands-on understanding of the algorithm's underlying mechanics [@problem_id:1920320].", "problem": "Consider a two-dimensional random vector $(X, Y)$ whose joint probability distribution is defined by the following full conditional distributions:\n- The conditional distribution of $X$ given $Y=y$ is an Exponential distribution with a rate parameter of $y$. The probability density function is given by $p(x|y) = y \\exp(-yx)$ for $x > 0$.\n- The conditional distribution of $Y$ given $X=x$ is a Poisson distribution with a mean parameter of $x$. The probability mass function is given by $p(y=k|x) = \\frac{x^k \\exp(-x)}{k!}$ for $k \\in \\{0, 1, 2, \\dots\\}$.\n\nYou are tasked with performing one full iteration of a Gibbs sampler. Starting from the initial state $(x^{(0)}, y^{(0)}) = (2, 3)$, you will generate a new state $(x^{(1)}, y^{(1)})$. The procedure for the iteration is as follows: first, draw a sample for $x^{(1)}$ from the distribution $p(x|y^{(0)})$, and then, using this new value $x^{(1)}$, draw a sample for $y^{(1)}$ from the distribution $p(y|x^{(1)})$.\n\nTo generate the necessary random variates, you must use the inverse transform sampling method. Use the following random numbers, which are drawn from a Uniform(0,1) distribution:\n- For generating $x^{(1)}$, use the uniform random number $u_x = 0.600$.\n- For generating $y^{(1)}$, use the uniform random number $u_y = 0.750$.\n\nWhat are the numerical values for the new state $(x^{(1)}, y^{(1)})$? The value for $x^{(1)}$ must be rounded to four significant figures.", "solution": "We perform one Gibbs update using inverse transform sampling.\n\n1) Sample $x^{(1)}$ from $p(x \\mid y^{(0)}=3)$.\nFor an Exponential rate $y$, the conditional CDF is\n$$\nF(x \\mid y)=1-\\exp(-yx), \\quad x>0.\n$$\nInverse transform uses $u_{x}=F(x \\mid y)$, hence\n$$\nx^{(1)}=F^{-1}(u_{x})=-\\frac{1}{y^{(0)}}\\ln\\!\\bigl(1-u_{x}\\bigr).\n$$\nWith $y^{(0)}=3$ and $u_{x}=0.600$,\n$$\nx^{(1)}=-\\frac{1}{3}\\ln(1-0.600)=-\\frac{1}{3}\\ln(0.4)=\\frac{1}{3}\\ln(2.5)\\approx 0.3054302439.\n$$\nRounded to four significant figures: $x^{(1)}=0.3054$.\n\n2) Sample $y^{(1)}$ from $p(y \\mid x^{(1)})$ using $u_{y}=0.750$.\nFor a Poisson mean $x$, the pmf is\n$$\np(y=k \\mid x)=\\frac{x^{k}\\exp(-x)}{k!}, \\quad k\\in\\{0,1,2,\\dots\\}.\n$$\nInverse transform for a discrete distribution selects the smallest $k$ such that $F(k \\mid x)=\\sum_{j=0}^{k}p(j \\mid x)\\ge u_{y}$.\n\nWith $x=x^{(1)}=\\frac{1}{3}\\ln(2.5)$, compute\n$$\np(0 \\mid x)=\\exp(-x)=\\exp\\!\\Bigl(-\\tfrac{1}{3}\\ln(2.5)\\Bigr)=2.5^{-1/3}\\approx 0.7368.\n$$\nSince $p(0 \\mid x)=0.7368<0.750$, continue to $k=1$:\n$$\np(1 \\mid x)=x\\exp(-x)=x\\,2.5^{-1/3}\\approx 0.30543\\times 0.7368\\approx 0.2250.\n$$\nThen\n$$\nF(1 \\mid x)=p(0 \\mid x)+p(1 \\mid x)\\approx 0.7368+0.2250=0.9618>0.750,\n$$\nso the smallest $k$ with $F(k \\mid x)\\ge 0.750$ is $k=1$. Therefore $y^{(1)}=1$.\n\nThus, the new state is $(x^{(1)},y^{(1)})=(0.3054,1)$ with $x^{(1)}$ rounded to four significant figures.", "answer": "$$\\boxed{\\begin{pmatrix}0.3054 & 1\\end{pmatrix}}$$", "id": "1920320"}, {"introduction": "Once you have generated samples from a Markov chain, the most critical step is to assess whether the sampler has converged to its target stationary distribution. This practice introduces the essential diagnostic technique of trace plot analysis, a common first step in any MCMC workflow. You will learn to interpret a scenario where multiple chains fail to mix, a classic symptom of non-convergence indicating that the sampler has not successfully explored the entire parameter space [@problem_id:1920355].", "problem": "A data scientist is using a Gibbs sampler, a type of Markov Chain Monte Carlo (MCMC) algorithm, to draw samples from a complex, one-dimensional posterior probability distribution for a parameter $\\theta$. To diagnose the convergence of the sampler to the target distribution, they initialize two independent MCMC chains from very different starting points.\n\nAfter running both chains for 20,000 iterations, the data scientist examines the trace plots, which show the value of $\\theta$ at each iteration. The visual inspection of these plots is described as follows:\n\n- **Chain 1:** Initialized with $\\theta_0 = -15.0$. For all 20,000 iterations, the sampled values of $\\theta$ quickly moved to and then fluctuated within the approximate interval $[-8.5, -6.5]$, exhibiting behavior consistent with a stationary time series centered around -7.5.\n- **Chain 2:** Initialized with $\\theta_0 = 15.0$. For all 20,000 iterations, the sampled values of $\\theta$ quickly moved to and then fluctuated within the approximate interval $[6.5, 8.5]$, exhibiting behavior consistent with a stationary time series centered around 7.5.\n\nBased on this textual description of the trace plots, what is the most appropriate conclusion regarding the performance of the Gibbs sampler?\n\nA. The sampler has converged successfully. The posterior distribution for $\\theta$ is clearly bimodal with modes near -7.5 and 7.5.\n\nB. The two chains have not mixed. This is a strong indication that the sampler has failed to converge and explore the full parameter space.\n\nC. The sampler is working correctly, but the \"burn-in\" period is too short. Discarding the first 10,000 samples from each chain will ensure the remaining samples are from the true posterior.\n\nD. The posterior distribution for $\\theta$ is unimodal with a mean of 0, which is the average of the means of the two chains. The chains simply show the range of the distribution.\n\nE. The starting values were not far enough apart. A re-run with starting values of -100 and 100 is necessary to make any valid conclusion about convergence.", "solution": "We consider the definition of Markov chain Monte Carlo convergence to a target posterior distribution $\\pi(\\theta)$: for a Markov chain with transition kernel invariant under $\\pi(\\theta)$, convergence requires that the marginal distribution of $\\theta_{t}$ approaches $\\pi(\\theta)$ as $t \\to \\infty$, regardless of the initial state. In practice, a standard diagnostic is to run multiple overdispersed chains and check whether their trace plots overlap and whether the chains mix across the same regions of the parameter space.\n\nFrom the description, Chain 1 rapidly moves to and then remains within approximately $[-8.5,-6.5]$ with apparent stationarity centered near $-7.5$, while Chain 2 rapidly moves to and then remains within approximately $[6.5,8.5]$ with apparent stationarity centered near $7.5$. There is no crossing between these disjoint regions over $20{,}000$ iterations for either chain. This indicates that each chain is trapped in a different region of the parameter space and does not mix across regions.\n\nA standard quantitative check is the Gelmanâ€“Rubin potential scale reduction factor. With $m$ chains of length $n$, denote the chain means by $\\bar{\\theta}_{i\\cdot}$ and the overall mean by $\\bar{\\theta}_{\\cdot\\cdot}$. The between-chain variance is\n$$\nB=\\frac{n}{m-1}\\sum_{i=1}^{m}\\left(\\bar{\\theta}_{i\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2},\n$$\nand the within-chain variance is\n$$\nW=\\frac{1}{m}\\sum_{i=1}^{m}s_{i}^{2},\n$$\nwhere $s_{i}^{2}$ is the sample variance within chain $i$. The marginal variance estimate is\n$$\n\\hat{V}=\\frac{n-1}{n}W+\\frac{1}{n}B,\n$$\nand the potential scale reduction factor is\n$$\n\\hat{R}=\\sqrt{\\frac{\\hat{V}}{W}}.\n$$\nGiven that the two chains have means far apart with little within-chain overlap, $B$ is large relative to $W$, implying $\\hat{R}>1$, which indicates lack of convergence.\n\nRegarding the options:\n- Option A is not justified: although the target posterior might be bimodal, convergence requires that each chain explores the full support according to $\\pi(\\theta)$. Persistent separation without mode switching shows non-mixing and failure to explore both modes; one cannot claim successful convergence from disjoint occupancy.\n- Option C is incorrect: discarding early iterations (burn-in) does not solve the lack of transitions between regions when no transitions occur at any time.\n- Option D is incorrect: the assertion of a unimodal posterior with mean $0$ contradicts the disjoint, stationary behavior in separated regions; averaging chain means does not validate posterior characteristics.\n- Option E is incorrect: the starting values were already far apart; increasing that distance does not remedy non-mixing across modes.\n\nTherefore, the correct conclusion is that the two chains have not mixed, indicating failure of the sampler to converge and explore the full parameter space.", "answer": "$$\\boxed{B}$$", "id": "1920355"}, {"introduction": "While visual inspection of trace plots is invaluable, a quantitative measure of convergence provides a more objective and formal diagnostic. The Gelman-Rubin statistic, often denoted as the potential scale reduction factor $\\hat{R}$, serves this exact purpose by comparing the variability within chains to the variability between chains. This final exercise challenges you to move from visual intuition to formal calculation by deriving the $\\hat{R}$ statistic, solidifying your understanding of how this powerful diagnostic tool works in practice [@problem_id:764139].", "problem": "In Bayesian statistics, Markov Chain Monte Carlo (MCMC) methods, such as Gibbs sampling, are fundamental for approximating complex posterior distributions. A critical aspect of applying MCMC is assessing the convergence of the sampler to its target stationary distribution. The Gelman-Rubin diagnostic provides a formal method for this by calculating the potential scale reduction factor, $\\hat{R}$. This factor compares the variance within multiple parallel MCMC chains to the variance between them. A value of $\\hat{R}$ close to 1 suggests that the chains have converged.\n\nFor a scalar parameter of interest, $\\psi$, suppose we run $m$ parallel MCMC chains, each of length $n$ (after an initial burn-in period). Let $\\bar{\\psi}_{i}$ and $s_i^2$ be the sample mean and variance of the $i$-th chain, for $i=1, \\dots, m$. The key quantities for the Gelman-Rubin diagnostic are:\n\n1.  The mean within-chain variance, $W$:\n    $$W = \\frac{1}{m} \\sum_{i=1}^{m} s_i^2$$\n2.  The between-chain variance, $B$:\n    $$B = \\frac{n}{m-1} \\sum_{i=1}^{m} (\\bar{\\psi}_{i} - \\bar{\\psi}_{..})^2$$\n    where $\\bar{\\psi}_{..} = \\frac{1}{m} \\sum_{i=1}^{m} \\bar{\\psi}_{i}$ is the grand mean over all samples from all chains.\n3.  The estimated marginal posterior variance of $\\psi$, $\\hat{V}$:\n    $$\\hat{V} = \\frac{n-1}{n}W + \\frac{1}{n}B$$\n4.  The potential scale reduction factor, $\\hat{R}$:\n    $$\\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}}$$\n\nConsider a scenario where two parallel Gibbs sampling chains ($m=2$) are run for $N$ iterations each to estimate a scalar parameter. After the runs, the summary statistics for the two chains are defined as follows:\n-   The sample means are $\\bar{\\psi}_{1} = \\mu - \\delta$ and $\\bar{\\psi}_{2} = \\mu + \\delta$.\n-   The sample variances are $s_1^2 = \\sigma^2(1 - \\epsilon)$ and $s_2^2 = \\sigma^2(1 + \\epsilon)$.\n\nThe parameters $N, \\mu, \\delta, \\sigma^2, \\epsilon$ are real constants, with $N>1$ being an integer, $\\sigma^2 > 0$, $\\delta \\ge 0$, and $|\\epsilon| < 1$.\n\nDerive a simplified expression for the potential scale reduction factor $\\hat{R}$ in terms of $N$, $\\delta$, and $\\sigma^2$.", "solution": "1. Within-chain variance:\n$$W = \\frac{1}{2}\\bigl(s_1^2 + s_2^2\\bigr)\n= \\frac{1}{2}\\bigl(\\sigma^2(1-\\epsilon)+\\sigma^2(1+\\epsilon)\\bigr)\n= \\sigma^2.$$\n\n2. Grand mean:\n$$\\bar\\psi_{..} = \\frac{1}{2}\\bigl((\\mu-\\delta)+(\\mu+\\delta)\\bigr)=\\mu.$$\n\n3. Between-chain variance ($m-1=1$, $n=N$):\n$$B = \\frac{N}{1}\\Bigl[(\\bar\\psi_1-\\bar\\psi_{..})^2+(\\bar\\psi_2-\\bar\\psi_{..})^2\\Bigr]\n= N\\bigl[(-\\delta)^2+(\\delta)^2\\bigr]\n= 2N\\delta^2.$$\n\n4. Marginal posterior variance estimate:\n$$\\hat V = \\frac{N-1}{N}W + \\frac{1}{N}B\n= \\frac{N-1}{N}\\sigma^2 + \\frac{1}{N}(2N\\delta^2)\n= \\frac{N-1}{N}\\sigma^2 + 2\\delta^2.$$\n\n5. Potential scale reduction factor:\n$$\\hat R = \\sqrt{\\frac{\\hat V}{W}}\n= \\sqrt{\\frac{\\tfrac{N-1}{N}\\sigma^2 + 2\\delta^2}{\\sigma^2}}\n= \\sqrt{\\frac{N-1}{N} + \\frac{2\\delta^2}{\\sigma^2}}.$$", "answer": "$$\\boxed{\\sqrt{\\frac{N-1}{N} + \\frac{2\\delta^2}{\\sigma^2}}}$$", "id": "764139"}]}