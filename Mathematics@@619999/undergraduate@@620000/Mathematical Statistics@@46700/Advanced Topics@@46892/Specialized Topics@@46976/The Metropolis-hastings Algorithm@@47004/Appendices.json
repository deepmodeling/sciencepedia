{"hands_on_practices": [{"introduction": "The core of the Metropolis-Hastings algorithm is the probabilistic decision to accept or reject a proposed new state. This practice will solidify your understanding of this fundamental mechanism by having you calculate the acceptance probability, $\\alpha$. In this scenario [@problem_id:1962612], we will work with a discrete target distribution, the Poisson distribution, and see how the ratio of target probabilities directly determines the chance of moving to a new state.", "problem": "A statistician is implementing a Markov Chain Monte Carlo (MCMC) simulation to generate samples from a target probability distribution. The chosen target distribution is a Poisson distribution, which models the number of events, $k$, occurring in a fixed interval of time or space. The probability mass function for a Poisson distribution is given by:\n$$ P(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\nwhere $\\lambda$ is the average rate of events. For this specific simulation, the parameter is set to $\\lambda = 5$.\n\nThe simulation uses the Metropolis-Hastings algorithm with a symmetric proposal distribution, meaning the probability of proposing a move from state $k_1$ to state $k_2$ is the same as proposing a move from $k_2$ to $k_1$.\n\nSuppose the current state of the chain is $k=5$. The algorithm then proposes a move to a new state, $k'=6$.\n\nCalculate the acceptance probability for this proposed move from $k=5$ to $k'=6$. Express your answer as a decimal rounded to three significant figures.", "solution": "In the Metropolis-Hastings algorithm with a symmetric proposal distribution, the acceptance probability for a proposed move from state $k$ to $k'$ is\n$$\n\\alpha = \\min\\left(1, \\frac{\\pi(k')}{\\pi(k)}\\right),\n$$\nwhere $\\pi(\\cdot)$ is the target probability mass function. For a Poisson distribution with parameter $\\lambda$, the PMF is\n$$\n\\pi(k) = \\frac{\\lambda^{k} \\exp(-\\lambda)}{k!}.\n$$\nTherefore, the ratio simplifies as\n$$\n\\frac{\\pi(k')}{\\pi(k)} = \\frac{\\lambda^{k'} \\exp(-\\lambda) / k'!}{\\lambda^{k} \\exp(-\\lambda) / k!} = \\lambda^{k'-k} \\frac{k!}{k'!}.\n$$\nWith $k=5$, $k'=6$, and $\\lambda=5$, we have $k'-k=1$ and $6! = 6 \\cdot 5!$, so\n$$\n\\frac{\\pi(6)}{\\pi(5)} = \\lambda \\cdot \\frac{5!}{6!} = \\lambda \\cdot \\frac{1}{6} = \\frac{5}{6}.\n$$\nHence, the acceptance probability is\n$$\n\\alpha = \\min\\left(1, \\frac{5}{6}\\right) = \\frac{5}{6}.\n$$\nExpressed as a decimal rounded to three significant figures, this is $0.833$.", "answer": "$$\\boxed{0.833}$$", "id": "1962612"}, {"introduction": "Beyond sampling from named distributions, the Metropolis algorithm is a powerful tool for exploring complex geometric regions. This exercise [@problem_id:1962636] casts the algorithm as a method for generating points uniformly from a constrained two-dimensional area. You will manually trace the sampler's path, applying the accept/reject rule to see how the algorithm \"learns\" the boundaries of the target space, providing a tangible feel for the Markov chain's movement.", "problem": "A data scientist is modeling a system whose state can be described by a point $(x, y)$ in a two-dimensional space. The valid states of the system are constrained to a specific region $\\mathcal{S} \\subset \\mathbb{R}^2$. The region $\\mathcal{S}$ is defined by the following system of inequalities:\n1. $y \\ge x^2$\n2. $x^2 + y^2 \\le 4$\n3. $x \\ge 0$\n\nTo explore this state space, the scientist uses the Metropolis algorithm, which is a specific case of the Metropolis-Hastings algorithm where the proposal distribution is symmetric. The goal is to generate a sequence of points that are uniformly distributed within the region $\\mathcal{S}$.\n\nThe algorithm proceeds in discrete time steps. Let the state of the system at step $t$ be $P_t = (x_t, y_t)$. To generate the state at step $t+1$, a new candidate state $P'_{t+1}$ is proposed. The candidate is then accepted or rejected based on the Metropolis acceptance rule. If accepted, $P_{t+1} = P'_{t+1}$. If rejected, the state does not change, i.e., $P_{t+1} = P_t$.\n\nThe initial state of the system is $P_0 = (1.0, 1.5)$. A sequence of five candidate states is proposed in order:\n- $P'_1 = (1.1, 1.8)$\n- $P'_2 = (0.8, 1.7)$\n- $P'_3 = (0.6, 0.2)$\n- $P'_4 = (0.9, 1.9)$\n- $P'_5 = (0.7, 1.1)$\n\nDetermine the coordinates of the system's state after all five proposals have been considered, denoted as $P_5 = (x_5, y_5)$.", "solution": "We target the uniform distribution on the region $\\mathcal{S}=\\{(x,y)\\in\\mathbb{R}^{2}: y\\ge x^{2},\\ x^{2}+y^{2}\\le 4,\\ x\\ge 0\\}$. With a symmetric proposal, the Metropolis acceptance probability is\n$$\n\\alpha\\big(P_{t}\\to P'\\big)=\\min\\left(1,\\frac{\\pi(P')}{\\pi(P_{t})}\\right),\n$$\nwhere $\\pi$ is the target density. For a uniform target on $\\mathcal{S}$, $\\pi(P)=c0$ if $P\\in\\mathcal{S}$ and $\\pi(P)=0$ otherwise. Hence,\n- if $P'\\in\\mathcal{S}$, then $\\alpha=1$ (accept),\n- if $P'\\notin\\mathcal{S}$, then $\\alpha=0$ (reject).\n\nWe first verify the initial state $P_{0}=(1.0,1.5)$ is in $\\mathcal{S}$:\n$$\nx_{0}=1.0\\ge 0,\\quad y_{0}=1.5\\ge x_{0}^{2}=1.0,\\quad x_{0}^{2}+y_{0}^{2}=1.0+2.25=3.25\\le 4,\n$$\nso $P_{0}\\in\\mathcal{S}$.\n\nWe now check each proposal:\n\n1) $P'_{1}=(1.1,1.8)$:\n$$\nx=1.1\\ge 0,\\quad y=1.8\\ge x^{2}=1.21,\\quad x^{2}+y^{2}=1.21+3.24=4.454,\n$$\nso $P'_{1}\\notin\\mathcal{S}$, reject. Thus $P_{1}=P_{0}=(1.0,1.5)$.\n\n2) $P'_{2}=(0.8,1.7)$:\n$$\nx=0.8\\ge 0,\\quad y=1.7\\ge x^{2}=0.64,\\quad x^{2}+y^{2}=0.64+2.89=3.53\\le 4,\n$$\nso $P'_{2}\\in\\mathcal{S}$, accept. Thus $P_{2}=(0.8,1.7)$.\n\n3) $P'_{3}=(0.6,0.2)$:\n$$\nx=0.6\\ge 0,\\quad y=0.2\\ge x^{2}=0.36\\ \\text{is false},\n$$\nso $P'_{3}\\notin\\mathcal{S}$, reject. Thus $P_{3}=P_{2}=(0.8,1.7)$.\n\n4) $P'_{4}=(0.9,1.9)$:\n$$\nx=0.9\\ge 0,\\quad y=1.9\\ge x^{2}=0.81,\\quad x^{2}+y^{2}=0.81+3.61=4.424,\n$$\nso $P'_{4}\\notin\\mathcal{S}$, reject. Thus $P_{4}=(0.8,1.7)$.\n\n5) $P'_{5}=(0.7,1.1)$:\n$$\nx=0.7\\ge 0,\\quad y=1.1\\ge x^{2}=0.49,\\quad x^{2}+y^{2}=0.49+1.21=1.70\\le 4,\n$$\nso $P'_{5}\\in\\mathcal{S}$, accept. Thus $P_{5}=(0.7,1.1)$.\n\nTherefore, after five proposals, the state is $P_{5}=(0.7,1.1)$.", "answer": "$$\\boxed{\\begin{pmatrix}0.7  1.1\\end{pmatrix}}$$", "id": "1962636"}, {"introduction": "Implementing a sampler is only half the battle; knowing if it's working efficiently is crucial for practical applications. The acceptance rate is a primary diagnostic, but its meaning can be subtle. This problem [@problem_id:1962675] presents a common yet counterintuitive situation—an extremely high acceptance rate—and asks you to diagnose what it implies about the sampler's performance and its exploration of the target distribution.", "problem": "A data scientist is using the Metropolis algorithm, a specific case of the Metropolis-Hastings algorithm, to generate samples from a one-dimensional, continuous, and unimodal target probability density function $\\pi(x)$. The algorithm works as follows: at each step $t$, given the current state $x_t$, a new candidate state $x'$ is proposed from a symmetric proposal distribution $q(x'|x_t) = q(x_t|x')$. In this case, the proposal distribution is a Normal distribution centered at the current state, $x' \\sim N(x_t, \\sigma^2)$, where the standard deviation $\\sigma$ is a tuning parameter that controls the step size.\n\nThe new state $x'$ is accepted with probability $\\alpha = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x_t)}\\right)$. If accepted, the next state is $x_{t+1} = x'$; otherwise, the chain remains in the same state, $x_{t+1} = x_t$.\n\nAfter running the sampler for a large number of iterations, the data scientist observes that the acceptance rate is consistently around 99.5%. Which of the following statements provides the most accurate and likely interpretation of this observation in the context of Markov Chain Monte Carlo (MCMC) diagnostics?\n\nA. The sampler is performing optimally, as a high acceptance rate ensures that the generated samples are a perfect representation of the target distribution.\n\nB. The proposal step size $\\sigma$ is likely too large, causing the sampler to propose states in the tails of the target distribution which are almost always rejected.\n\nC. The sampler has successfully converged to the stationary distribution, and subsequent samples can be treated as independent draws from $\\pi(x)$.\n\nD. The proposal step size $\\sigma$ is likely too small, causing the sampler to explore the state space very slowly and inefficiently, even though most steps are accepted.\n\nE. The target distribution $\\pi(x)$ must be nearly uniform, which is why almost every proposed state is accepted.", "solution": "Given a symmetric proposal $q(x'|x_{t})=q(x_{t}|x')$, the Metropolis acceptance probability reduces to\n$$\n\\alpha(x_{t},x')=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x_{t})}\\right)=\\min\\left(1,\\exp\\left(\\ln\\pi(x')-\\ln\\pi(x_{t})\\right)\\right).\n$$\nLet $x'=x_{t}+\\epsilon$ with $\\epsilon\\sim N(0,\\sigma^{2})$. Define the log-density $\\ell(x)=\\ln\\pi(x)$. For differentiable unimodal $\\pi$, a Taylor expansion around $x_{t}$ gives\n$$\n\\ell(x_{t}+\\epsilon)-\\ell(x_{t})=\\ell'(x_{t})\\,\\epsilon+\\frac{1}{2}\\ell''(x_{t})\\,\\epsilon^{2}+o(\\epsilon^{2}).\n$$\nWhen $\\sigma$ is small, $\\epsilon$ is typically of order $\\sigma$, so the change in log-density is small:\n$$\n\\ell(x_{t}+\\epsilon)-\\ell(x_{t})=\\mathcal{O}(\\sigma)+\\mathcal{O}(\\sigma^{2}).\n$$\nTherefore $\\exp\\left(\\ell(x_{t}+\\epsilon)-\\ell(x_{t})\\right)\\approx 1$, implying that $\\alpha(x_{t},x')\\approx 1$. Hence, an acceptance rate near $0.995$ is a hallmark of very small step sizes $\\sigma$: most proposed moves produce negligible changes in $\\pi$, so they are almost always accepted. However, the chain then moves by increments of size $\\epsilon=\\mathcal{O}(\\sigma)$, so per iteration the exploration of the state space is slow, and the Markov chain exhibits high autocorrelation and poor mixing efficiency.\n\nConsider each option in light of this:\n- A is incorrect because a very high acceptance rate does not imply optimal performance or a perfect representation; excessively high acceptance typically indicates tiny steps and inefficient exploration.\n- B is incorrect because a too-large $\\sigma$ would generally drive proposals into low-density regions, causing low, not high, acceptance.\n- C is incorrect because acceptance rate alone does not establish convergence, and even at stationarity, random-walk Metropolis samples are not independent; with tiny steps they are strongly autocorrelated.\n- D is correct: a very high acceptance rate strongly suggests that $\\sigma$ is too small, leading to slow exploration despite most proposals being accepted.\n- E is incorrect because near-unity acceptance does not require $\\pi$ to be nearly uniform; it can arise simply from very small $\\sigma$. A truly uniform target would yield acceptance exactly $1$ for any proposal, which is not implied here.\n\nTherefore, the most accurate interpretation is that the proposal step size is too small, yielding inefficient exploration despite high acceptance.", "answer": "$$\\boxed{D}$$", "id": "1962675"}]}