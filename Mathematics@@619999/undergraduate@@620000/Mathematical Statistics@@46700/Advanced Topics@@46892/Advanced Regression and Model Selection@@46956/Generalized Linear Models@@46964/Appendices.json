{"hands_on_practices": [{"introduction": "Parameter estimation in Generalized Linear Models (GLMs) relies on the principle of maximum likelihood. To apply this principle, one must first construct the log-likelihood function, which mathematically describes the plausibility of the model parameters given the observed data. This fundamental exercise [@problem_id:1919840] guides you through deriving the log-likelihood for a binomial regression model, explicitly connecting the random component (binomial distribution), the link function (logit), and the systematic component (linear predictor). Mastering this derivation is the first step toward understanding the mechanics of model fitting in the GLM framework.", "problem": "In the context of a Generalized Linear Model (GLM), consider a binomial regression model used to analyze count data. For each observation unit $i$, we observe a count $y_i$ of \"successes\" out of a known total number of trials $n_i$. The model assumes that the random variable $Y_i$ follows a binomial distribution, $Y_i \\sim \\text{Binomial}(n_i, p_i)$, where $p_i$ is the probability of success for a single trial in unit $i$.\n\nThe model connects the success probability $p_i$ to a set of explanatory variables (covariates) $\\mathbf{x}_i$ through a logit link function. Specifically, the relationship is given by:\n$$ \\text{logit}(p_i) = \\ln\\left(\\frac{p_i}{1-p_i}\\right) = \\eta_i $$\nwhere $\\eta_i = \\mathbf{x}_i^T \\boldsymbol{\\beta}$ is the linear predictor, with $\\boldsymbol{\\beta}$ being the vector of regression coefficients.\n\nYour task is to derive the log-likelihood function for a single observation $y_i$ from unit $i$. Express your final answer, denoted as $\\ell(\\boldsymbol{\\beta}; y_i)$, in terms of the observed count $y_i$, the total trials $n_i$, and the linear predictor $\\eta_i$.", "solution": "For a single observation $y_i$ with $Y_i \\sim \\text{Binomial}(n_i, p_i)$, the probability mass function is\n$$\n\\Pr(Y_i = y_i) = \\binom{n_i}{y_i} p_i^{y_i} (1 - p_i)^{n_i - y_i}.\n$$\nThe log-likelihood for this observation is\n$$\n\\ell(\\boldsymbol{\\beta}; y_i) = \\ln \\binom{n_i}{y_i} + y_i \\ln p_i + (n_i - y_i)\\ln(1 - p_i).\n$$\nWith the logit link, $\\eta_i = \\ln\\!\\left(\\frac{p_i}{1 - p_i}\\right)$, so the inverse link gives\n$$\np_i = \\frac{\\exp(\\eta_i)}{1 + \\exp(\\eta_i)}, \\qquad 1 - p_i = \\frac{1}{1 + \\exp(\\eta_i)}.\n$$\nTherefore,\n$$\n\\ln p_i = \\eta_i - \\ln\\!\\left(1 + \\exp(\\eta_i)\\right), \\qquad \\ln(1 - p_i) = -\\ln\\!\\left(1 + \\exp(\\eta_i)\\right).\n$$\nSubstituting into the log-likelihood,\n$$\n\\ell(\\boldsymbol{\\beta}; y_i) = \\ln \\binom{n_i}{y_i} + y_i\\left[\\eta_i - \\ln\\!\\left(1 + \\exp(\\eta_i)\\right)\\right] + (n_i - y_i)\\left[-\\ln\\!\\left(1 + \\exp(\\eta_i)\\right)\\right].\n$$\nCollecting terms,\n$$\n\\ell(\\boldsymbol{\\beta}; y_i) = \\ln \\binom{n_i}{y_i} + y_i \\eta_i - n_i \\ln\\!\\left(1 + \\exp(\\eta_i)\\right).\n$$\nThis is the desired log-likelihood expressed in terms of $y_i$, $n_i$, and $\\eta_i$.", "answer": "$$\\boxed{\\ln\\binom{n_i}{y_i} + y_i \\eta_i - n_i \\ln\\!\\left(1 + \\exp(\\eta_i)\\right)}$$", "id": "1919840"}, {"introduction": "A critical phase in statistical modeling is diagnostic checking, which ensures that the model's underlying assumptions align with the data. A key assumption of the Poisson model for count data is equidispersion, where the variance of the response is equal to its mean. This practical exercise [@problem_id:1919857] addresses the common issue of overdispersion—where the observed variance exceeds the theoretical mean—by demonstrating how to calculate an estimated dispersion parameter, $\\hat{\\phi}$, from the residual deviance. This simple calculation provides a vital first check on model adequacy and helps determine if a more flexible model is warranted.", "problem": "A biostatistician is analyzing data on the number of non-healing ulcers observed in a cohort of patients over a one-year period. Since the data are counts, a Poisson regression model, which is a type of Generalized Linear Model (GLM), is employed to understand the relationship between the ulcer count and several patient-specific covariates.\n\nThe study includes a total of $n = 120$ patients. The fitted model contains an intercept term plus $k=7$ distinct predictor variables. After running the regression analysis, the statistical software reports a residual deviance of $208.5$.\n\nIn a standard Poisson model, the variance of the response is assumed to be equal to its mean. Overdispersion occurs when the observed variance is larger than the mean. A simple way to check for overdispersion is to compute an estimate of the dispersion parameter, $\\phi$. In an ideal Poisson model without overdispersion, this parameter is equal to 1. Using the information provided, calculate the estimated dispersion parameter, $\\hat{\\phi}$, for this model. Report the result as a numerical value, rounded to three significant figures.", "solution": "In a Poisson GLM, under the equidispersion assumption, the residual deviance $D$ is approximately $\\chi^{2}$-distributed with residual degrees of freedom $\\text{df} = n - p$, where $p$ is the number of estimated parameters (including the intercept). When assessing overdispersion, an estimator of the dispersion parameter is\n$$\n\\hat{\\phi} = \\frac{D}{\\text{df}} = \\frac{D}{n - p}.\n$$\nHere, $n = 120$, the model has an intercept plus $k = 7$ predictors, so\n$$\np = 1 + k = 1 + 7 = 8, \\quad \\text{df} = n - p = 120 - 8 = 112.\n$$\nGiven the residual deviance $D = 208.5$, we compute\n$$\n\\hat{\\phi} = \\frac{208.5}{112} = 1.861607142857\\ldots\n$$\nRounded to three significant figures, this is\n$$\n\\hat{\\phi} \\approx 1.86.\n$$", "answer": "$$\\boxed{1.86}$$", "id": "1919857"}, {"introduction": "Effective model building is an iterative process of specification and refinement. After checking distributional assumptions, it is crucial to assess whether the model's systematic component correctly captures the relationship between the predictors and the response. This exercise [@problem_id:1919838] presents a hypothetical scenario involving the interpretation of a diagnostic plot, a core skill in applied statistics. By analyzing a distinct pattern in the deviance residuals, you will learn to diagnose a specific form of model misspecification, highlighting how graphical tools guide the improvement of a model's structure.", "problem": "An ecologist is studying the factors that determine the presence or absence of a rare alpine flower, *Florus calculus*, in a mountain range. For a set of $n$ randomly selected square-meter plots, she records whether the flower is present ($y_i=1$) or absent ($y_i=0$) and measures the soil acidity, quantified by its pH value ($x_i$).\n\nShe hypothesizes that the probability of the flower's presence, $\\mu_i = P(y_i=1)$, is related to the soil pH. To model this, she fits a Generalized Linear Model (GLM) assuming a Bernoulli distribution for the response variable $y_i$. The systematic component of her model is linear in the predictor, and she uses a standard logit link function. The fitted model is therefore:\n$$\n\\ln\\left(\\frac{\\mu_i}{1-\\mu_i}\\right) = \\beta_0 + \\beta_1 x_i\n$$\nAfter fitting the model and obtaining estimates for the parameters, she produces a diagnostic plot of the deviance residuals versus the corresponding fitted linear predictors, $\\hat{\\eta}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_i$. She observes a distinct and symmetric U-shaped pattern in this plot, where the residuals are predominantly positive for very low and very high values of $\\hat{\\eta}_i$, and predominantly negative for intermediate values of $\\hat{\\eta}_i$.\n\nBased on this specific diagnostic finding, which of the following is the most likely misspecification in her initial model?\n\nA. The variance of the response is larger than what is assumed by the Bernoulli model (overdispersion).\n\nB. The assumption of independence among the observations $y_i$ is violated.\n\nC. The true relationship between the linear predictor and the soil pH is non-linear and would be better captured by including a quadratic term.\n\nD. The logit link function is inappropriate, and a different link function, such as the probit or complementary log-log, should have been used.\n\nE. The dataset contains one or more highly influential outlier observations that are skewing the results.", "solution": "The GLM assumes $y_i \\sim \\text{Bernoulli}(\\mu_i)$ with the logit link and linear predictor\n$$\n\\eta_i=\\ln\\left(\\frac{\\mu_i}{1-\\mu_i}\\right)=\\beta_0+\\beta_1 x_i.\n$$\nThe fitted model yields deviance residuals $r_i$ plotted against $\\hat{\\eta}_i=\\hat{\\beta}_0+\\hat{\\beta}_1 x_i$. For a correctly specified GLM (correct link and correct linear predictor form), the residuals should show no systematic dependence on $\\hat{\\eta}_i$; they should be approximately centered around zero with roughly constant spread as a function of $\\hat{\\eta}_i$.\n\nFor Bernoulli responses, the deviance residual for observation $i$ is\n$$\nr_i=\\operatorname{sign}(y_i-\\hat{\\mu}_i)\\sqrt{2\\left[y_i\\ln\\left(\\frac{y_i}{\\hat{\\mu}_i}\\right)+(1-y_i)\\ln\\left(\\frac{1-y_i}{1-\\hat{\\mu}_i}\\right)\\right]},\n$$\nwhere $\\hat{\\mu}_i=\\exp(\\hat{\\eta}_i)\\big/\\left(1+\\exp(\\hat{\\eta}_i)\\right)$ and the convention $0\\ln(0/\\cdot)=0$ is used.\n\nThe observed diagnostic pattern is a symmetric U-shape: residuals predominantly positive for very low and very high $\\hat{\\eta}_i$, and predominantly negative for intermediate $\\hat{\\eta}_i$. This indicates a systematic dependence of the residuals on $\\hat{\\eta}_i$ that is symmetric about some center, which is characteristic of a missing even-order term (most simply a quadratic) in the systematic component. Specifically, if the true relationship on the link scale were\n$$\n\\eta_i^{\\ast}=\\beta_0^{\\ast}+\\beta_1^{\\ast}x_i+\\beta_2^{\\ast}x_i^{2},\n$$\nwith $\\beta_2^{\\ast}>0$ (convex curvature), then a misspecified linear model $\\eta_i=\\beta_0+\\beta_1 x_i$ would tend to underfit at the extremes of $x_i$ (and hence extremes of $\\hat{\\eta}_i$) and overfit near the center. Underfitting at the extremes leads to $\\hat{\\mu}_i$ being too close to $1/2$ when the true $\\mu_i$ is closer to $0$ or $1$, which produces predominantly positive deviance residuals at both low and high $\\hat{\\eta}_i$. Overfitting in the middle yields predominantly negative residuals there. The resulting residual-versus-$\\hat{\\eta}_i$ plot shows the described symmetric U-shape.\n\nNow consider and eliminate the alternatives:\n- Overdispersion (A) inflates the variance of residuals but does not induce a systematic, symmetric U-shaped dependence on $\\hat{\\eta}_i$; the mean residual given $\\hat{\\eta}_i$ would still be approximately zero if the mean structure is correct.\n- Dependence among observations (B) can produce clustering or runs in residuals but does not typically create a symmetric U-shaped pattern as a function of the fitted linear predictor.\n- An inappropriate link (D) generally produces a systematic, often monotone or S-shaped pattern of residuals versus the predictor or fitted values, not a symmetric U-shape centered in the predictor domain. Moreover, logit versus probit or complementary log-log differences rarely yield the specific symmetric U-shape seen here.\n- Influential outliers (E) manifest as isolated large-magnitude residuals rather than a smooth, symmetric U-shaped pattern across the range of $\\hat{\\eta}_i$.\n\nTherefore, the most likely misspecification indicated by a symmetric U-shaped residual pattern versus $\\hat{\\eta}_i$ is a non-linear effect of $x_i$ on the link scale that is better captured by including a quadratic term in the linear predictor.\n\nHence, the correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1919838"}]}