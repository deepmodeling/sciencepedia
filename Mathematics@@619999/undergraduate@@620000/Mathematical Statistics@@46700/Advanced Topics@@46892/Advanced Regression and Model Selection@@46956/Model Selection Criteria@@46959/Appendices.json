{"hands_on_practices": [{"introduction": "When building a statistical model, adding more parameters can improve the fit to the observed data, but at the risk of overfitting and poor predictive performance on new data. The Akaike Information Criterion (AIC) provides a principled way to navigate this trade-off. This exercise demonstrates the fundamental application of AIC, allowing you to compare two competing models by balancing their goodness-of-fit, measured by the log-likelihood, against their complexity, measured by the number of parameters [@problem_id:1936627].", "problem": "An ecologist is developing statistical models to understand the population dynamics of a particular bird species in a protected wetland. They have collected data over a period of many years. Two competing models are proposed to explain the yearly population fluctuations.\n\nModel A is a simpler model that relates the bird population in a given year to climatic variables such as average temperature and rainfall. After fitting this model to the data, it is found to have $k_A = 4$ estimated parameters, and the maximized value of its log-likelihood function is $\\ln(\\mathcal{L}_A) = -85.2$.\n\nModel B is a more complex model that includes the same climatic variables as Model A but also incorporates the population size of a key predator species. This more comprehensive model has $k_B = 6$ estimated parameters and achieves a higher maximized log-likelihood of $\\ln(\\mathcal{L}_B) = -83.5$.\n\nTo decide which model provides a better balance between goodness-of-fit and complexity, the ecologist uses the Akaike Information Criterion (AIC). The AIC for a model is defined as $AIC = -2\\ln(\\mathcal{L}) + 2k$, where $k$ is the number of estimated parameters in the model and $\\ln(\\mathcal{L})$ is the maximized value of the log-likelihood function. The model with the lower AIC value is considered to be the better model.\n\nBased on the AIC, which model is preferred, and what are their respective AIC values?\n\nA. Model A is preferred, with $AIC_A = 178.4$ and $AIC_B = 179.0$.\n\nB. Model B is preferred, with $AIC_A = 178.4$ and $AIC_B = 179.0$.\n\nC. Model A is preferred, with $AIC_A = -162.4$ and $AIC_B = -155.0$.\n\nD. Model B is preferred, with $AIC_A = 178.4$ and $AIC_B = 171.0$.\n\nE. Model B is preferred, with $AIC_A = 178.4$ and $AIC_B = 173.0$.", "solution": "The Akaike Information Criterion is defined by\n$$\nAIC = -2\\ln(\\mathcal{L}) + 2k.\n$$\nFor Model A, with $k_{A} = 4$ and $\\ln(\\mathcal{L}_{A}) = -85.2$,\n$$\nAIC_{A} = -2\\cdot(-85.2) + 2\\cdot 4 = 170.4 + 8 = 178.4.\n$$\nFor Model B, with $k_{B} = 6$ and $\\ln(\\mathcal{L}_{B}) = -83.5$,\n$$\nAIC_{B} = -2\\cdot(-83.5) + 2\\cdot 6 = 167.0 + 12 = 179.0.\n$$\nSince $AIC_{A} = 178.4 < AIC_{B} = 179.0$, Model A is preferred. These values correspond to option A.", "answer": "$$\\boxed{A}$$", "id": "1936627"}, {"introduction": "While AIC is a widely used tool, it is not the only information criterion available. The Bayesian Information Criterion (BIC) offers an alternative, differing from AIC primarily in how it penalizes model complexity. This practice focuses on the crucial distinction between the two criteria: their penalty terms [@problem_id:1936657]. By calculating the difference directly, you will gain a concrete understanding of how BIC's penalty incorporates the sample size $n$, often leading to the selection of more parsimonious models compared to AIC.", "problem": "An ecologist is analyzing a dataset of species abundance over time, which consists of $n=50$ distinct observations. They are considering a particular population dynamics model that requires estimating $k=5$ free parameters from the data. To evaluate the model's quality while penalizing complexity, they use two common information criteria.\n\nThe Akaike Information Criterion (AIC) is defined as $\\text{AIC} = -2\\ln(\\mathcal{L}) + 2k$, and the Bayesian Information Criterion (BIC) is defined as $\\text{BIC} = -2\\ln(\\mathcal{L}) + k\\ln(n)$. In these formulas, $\\mathcal{L}$ is the maximized value of the likelihood function for the model, $k$ is the number of estimated parameters, and $n$ is the number of observations.\n\nThe terms $2k$ (for AIC) and $k\\ln(n)$ (for BIC) are known as the \"penalty terms\" because they increase the value of the criterion as the model complexity (i.e., the number of parameters $k$) increases.\n\nCalculate the difference between the penalty term of the BIC and the penalty term of the AIC for this specific model and dataset. Express your answer as a numerical value rounded to three significant figures.", "solution": "The AIC penalty term is $2k$ and the BIC penalty term is $k\\ln(n)$. The difference (BIC penalty minus AIC penalty) is\n$$\nk\\ln(n) - 2k = k\\left(\\ln(n) - 2\\right).\n$$\nSubstituting $k=5$ and $n=50$ gives\n$$\n5\\left(\\ln(50) - 2\\right).\n$$\nUsing the numerical value $\\ln(50) \\approx 3.912023$, we obtain\n$$\n5\\left(3.912023 - 2\\right) = 5 \\times 1.912023 = 9.560115.\n$$\nRounded to three significant figures, the result is $9.56$.", "answer": "$$\\boxed{9.56}$$", "id": "1936657"}, {"introduction": "Manually comparing every possible model is often infeasible, leading statisticians to use automated stepwise selection algorithms like Forward Selection and Backward Elimination. These methods use criteria like AIC to greedily add or remove predictors one at a time. This exercise reveals the path-dependent nature of these procedures, showing that the 'best' model they find can depend on the direction of the search [@problem_id:1936615]. By working through both algorithms, you will see why these useful tools must be applied with caution and critical thinking.", "problem": "An agricultural scientist is studying the yield of a new crop variety. They have collected data from $n=100$ experimental plots. The scientist wants to build a linear regression model to predict crop yield ($Y$) using three potential predictor variables:\n- $X_1$: amount of a specific nitrogen-based fertilizer.\n- $X_2$: soil pH level.\n- $X_3$: average daily water supply.\n\nTo find the best model, the scientist has calculated the Residual Sum of Squares (RSS) for all possible linear models involving these three predictors. The intercept is included in all models. The results are summarized in the table below:\n\n| Model Predictors | Number of Predictors ($p$) | Residual Sum of Squares (RSS) |\n|------------------|----------------------------|-------------------------------|\n| None (Intercept Only) | 0 | 200 |\n| {$X_1$} | 1 | 150 |\n| {$X_2$} | 1 | 160 |\n| {$X_3$} | 1 | 165 |\n| {$X_1, X_2$} | 2 | 110 |\n| {$X_1, X_3$} | 2 | 120 |\n| {$X_2, X_3$} | 2 | 100 |\n| {$X_1, X_2, X_3$} | 3 | 108 |\n\nThe scientist decides to use two common automated model selection procedures, Forward Selection and Backward Elimination, based on the Akaike Information Criterion (AIC). The AIC is a statistical measure used for model selection, and for a linear model under the assumption of normally distributed errors, it is given by:\n$$AIC = n \\ln\\left(\\frac{RSS}{n}\\right) + 2k$$\nwhere $n$ is the number of observations, $RSS$ is the residual sum of squares, and $k$ is the total number of parameters in the model, including the intercept (i.e., $k = p+1$, where $p$ is the number of predictors). At each step of the selection procedures, the change that results in the model with the lowest AIC is chosen. The process stops when no single step can further decrease the AIC.\n\nLet $M_F$ be the set of predictors in the final model chosen by Forward Selection, and $M_B$ be the set of predictors in the final model chosen by Backward Elimination. Which of the following options correctly identifies both final models?\n\nA. $M_F = \\{X_1, X_2\\}$, $M_B = \\{X_1, X_2\\}$\n\nB. $M_F = \\{X_1, X_2\\}$, $M_B = \\{X_2, X_3\\}$\n\nC. $M_F = \\{X_2, X_3\\}$, $M_B = \\{X_1, X_2\\}$\n\nD. $M_F = \\{X_2, X_3\\}$, $M_B = \\{X_2, X_3\\}$\n\nE. $M_F = \\{X_1, X_2, X_3\\}$, $M_B = \\{X_2, X_3\\}$\n\nF. $M_F = \\{X_1\\}$, $M_B = \\{X_1, X_2, X_3\\}$", "solution": "We use the Akaike Information Criterion for linear models with normally distributed errors:\n$$AIC = n \\ln\\left(\\frac{RSS}{n}\\right) + 2k,$$\nwhere $n=100$, $RSS$ is the residual sum of squares for the model, and $k=p+1$ with $p$ the number of predictors (the intercept is always included).\n\nForward Selection starts from the intercept-only model. Its AIC is\n$$AIC_{\\emptyset} = 100 \\ln\\left(\\frac{200}{100}\\right) + 2(1) = 100 \\ln(2) + 2.$$\nFor single-predictor models ($k=2$):\n- For $\\{X_{1}\\}$: $AIC_{1} = 100 \\ln\\left(\\frac{150}{100}\\right) + 4 = 100 \\ln(1.5) + 4.$\n- For $\\{X_{2}\\}$: $AIC_{2} = 100 \\ln(1.6) + 4.$\n- For $\\{X_{3}\\}$: $AIC_{3} = 100 \\ln(1.65) + 4.$\nCompare to the intercept-only model:\n$$AIC_{1} - AIC_{\\emptyset} = 100 \\ln\\left(\\frac{1.5}{2}\\right) + 2 = 100 \\ln(0.75) + 2 < 0,$$\nso $\\{X_{1}\\}$ reduces AIC; similarly, $AIC_{2}$ and $AIC_{3}$ also reduce AIC, but among singletons\n$$AIC_{2} - AIC_{1} = 100 \\ln\\left(\\frac{1.6}{1.5}\\right) > 0,\\quad AIC_{3} - AIC_{1} = 100 \\ln\\left(\\frac{1.65}{1.5}\\right) > 0,$$\nso the best is $\\{X_{1}\\}$. Forward step 1 selects $X_{1}$.\n\nFrom $\\{X_{1}\\}$, consider adding one more predictor ($k=3$):\n- For $\\{X_{1},X_{2}\\}$: $AIC_{12} = 100 \\ln\\left(\\frac{110}{100}\\right) + 6 = 100 \\ln(1.1) + 6.$\n- For $\\{X_{1},X_{3}\\}$: $AIC_{13} = 100 \\ln(1.2) + 6.$\nRelative to $\\{X_{1}\\}$:\n$$AIC_{12} - AIC_{1} = 100 \\ln\\left(\\frac{1.1}{1.5}\\right) + 2 = 100 \\ln(0.733\\ldots) + 2 < 0,$$\n$$AIC_{13} - AIC_{1} = 100 \\ln\\left(\\frac{1.2}{1.5}\\right) + 2 = 100 \\ln(0.8) + 2 < 0,$$\nand $AIC_{12} < AIC_{13}$ since $\\ln(1.1) < \\ln(1.2)$. Thus the best addition is $X_{2}$, giving $\\{X_{1},X_{2}\\}$.\n\nFrom $\\{X_{1},X_{2}\\}$, consider adding $X_{3}$ to get the full model ($k=4$):\n$$AIC_{123} = 100 \\ln\\left(\\frac{108}{100}\\right) + 8 = 100 \\ln(1.08) + 8.$$\nCompare to $\\{X_{1},X_{2}\\}$:\n$$AIC_{123} - AIC_{12} = 100 \\ln\\left(\\frac{1.08}{1.1}\\right) + 2 = 100 \\ln(0.9818\\ldots) + 2 > 0,$$\nso adding $X_{3}$ increases AIC. Forward Selection stops with $M_{F} = \\{X_{1},X_{2}\\}$.\n\nBackward Elimination starts from the full model $\\{X_{1},X_{2},X_{3}\\}$ with\n$$AIC_{123} = 100 \\ln(1.08) + 8.$$\nConsider removing one predictor to get two-predictor models ($k=3$):\n- Removing $X_{3}$: $AIC_{12} = 100 \\ln(1.1) + 6.$\n- Removing $X_{2}$: $AIC_{13} = 100 \\ln(1.2) + 6.$\n- Removing $X_{1}$: $AIC_{23} = 100 \\ln\\left(\\frac{100}{100}\\right) + 6 = 6.$\nAmong these, $AIC_{23}$ is smallest since $\\ln(1.1) > 0$ and $\\ln(1.2) > 0$. Also,\n$$AIC_{23} - AIC_{123} = 6 - \\left(100 \\ln(1.08) + 8\\right) = -100 \\ln(1.08) - 2 < 0,$$\nso removing $X_{1}$ decreases AIC. Move to $\\{X_{2},X_{3}\\}$.\n\nFrom $\\{X_{2},X_{3}\\}$, consider removing one more predictor to get singletons ($k=2$):\n- $\\{X_{2}\\}$: $AIC_{2} = 100 \\ln(1.6) + 4.$\n- $\\{X_{3}\\}$: $AIC_{3} = 100 \\ln(1.65) + 4.$\nBoth satisfy $AIC_{2} > 6$ and $AIC_{3} > 6$ since $\\ln(1.6) > 0$ and $\\ln(1.65) > 0$, so any removal increases AIC. Backward Elimination stops with $M_{B} = \\{X_{2},X_{3}\\}$.\n\nMapping to the provided options, this corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "1936615"}]}