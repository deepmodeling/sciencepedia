{"hands_on_practices": [{"introduction": "Making predictions under uncertainty is a central task in statistics. This first exercise [@problem_id:1946862] explores the fundamental mechanics of the posterior predictive distribution in a simple, intuitive scenario involving a die with an unknown number of sides. By working through this problem, you will see how to combine prior beliefs with observed data to form a posterior distribution, which is then used to make probabilistic forecasts about future events.", "problem": "An archivist at a museum of games is cataloging a collection of unusual polyhedral dice from a historical society. These dice are known to be fair (i.e., for a die with $N$ sides, the probability of any given outcome is $1/N$). The dice in this collection have either 4, 6, or 8 sides, with faces numbered consecutively starting from 1. Based on the society's acquisition records, the archivist establishes a prior probability distribution for the number of sides, $N$, of a randomly selected die. The prior probabilities are as follows:\n- The probability that a die has 4 sides is $P(N=4) = \\frac{1}{2}$.\n- The probability that a die has 6 sides is $P(N=6) = \\frac{1}{3}$.\n- The probability that a die has 8 sides is $P(N=8) = \\frac{1}{6}$.\n\nThe archivist randomly selects one die from the collection and rolls it once, observing the outcome. The result of this first roll, let's call it $D_1$, is a 3. The archivist plans to roll the same die a second time. Let the outcome of the second roll be $D_2$.\n\nCalculate the probability that the second roll results in a 7, given the outcome of the first roll. In other words, find $P(D_2=7 | D_1=3)$. Express your answer as a single fraction in simplest form.", "solution": "Let $N\\in\\{4,6,8\\}$ denote the number of sides. The prior probabilities are $P(N=4)=\\frac{1}{2}$, $P(N=6)=\\frac{1}{3}$, and $P(N=8)=\\frac{1}{6}$. Given a fair $N$-sided die, for any $k\\in\\{1,\\dots,N\\}$ we have $P(D=k\\mid N)=\\frac{1}{N}$. Since $3\\leq 4,6,8$, the likelihoods are $P(D_{1}=3\\mid N=n)=\\frac{1}{n}$ for $n\\in\\{4,6,8\\}$.\n\nBy Bayesâ€™ theorem,\n$$\nP(N=n\\mid D_{1}=3)=\\frac{P(D_{1}=3\\mid N=n)P(N=n)}{\\sum_{m\\in\\{4,6,8\\}}P(D_{1}=3\\mid N=m)P(N=m)}=\\frac{\\frac{1}{n}P(N=n)}{\\frac{1}{4}\\cdot\\frac{1}{2}+\\frac{1}{6}\\cdot\\frac{1}{3}+\\frac{1}{8}\\cdot\\frac{1}{6}}.\n$$\nCompute the normalizing denominator:\n$$\n\\frac{1}{4}\\cdot\\frac{1}{2}+\\frac{1}{6}\\cdot\\frac{1}{3}+\\frac{1}{8}\\cdot\\frac{1}{6}=\\frac{1}{8}+\\frac{1}{18}+\\frac{1}{48}=\\frac{29}{144}.\n$$\nThus,\n$$\nP(N=4\\mid D_{1}=3)=\\frac{\\frac{1}{8}}{\\frac{29}{144}}=\\frac{18}{29},\\quad\nP(N=6\\mid D_{1}=3)=\\frac{\\frac{1}{18}}{\\frac{29}{144}}=\\frac{8}{29},\\quad\nP(N=8\\mid D_{1}=3)=\\frac{\\frac{1}{48}}{\\frac{29}{144}}=\\frac{3}{29}.\n$$\n\nGiven $N$, the rolls are independent and $P(D_{2}=7\\mid N=n)$ equals $\\frac{1}{n}$ if $7\\leq n$ and $0$ otherwise. Therefore,\n$$\nP(D_{2}=7\\mid D_{1}=3)=\\sum_{n\\in\\{4,6,8\\}}P(D_{2}=7\\mid N=n)\\,P(N=n\\mid D_{1}=3)=\\frac{1}{8}\\cdot\\frac{3}{29}=\\frac{3}{232}.\n$$", "answer": "$$\\boxed{\\frac{3}{232}}$$", "id": "1946862"}, {"introduction": "Many scientific problems involve estimating and predicting continuous quantities. This practice [@problem_id:1946911] moves from discrete parameters to the continuous domain, demonstrating the power of conjugate priors with the ubiquitous Normal distribution model. You will learn how to update your belief about a parameter after taking measurements and then calculate the probability of a future observation falling within a desired range.", "problem": "A materials scientist is studying a dimensionless parameter, $\\mu$, related to the piezoelectric response of a newly fabricated crystal. The measurement instrument is known to produce readings that follow a Normal distribution with the true mean being $\\mu$ and a known variance of 1.\n\nBased on prior theoretical calculations for similar materials, the scientist models their belief about $\\mu$ using a Normal distribution with a mean of 0.5 and a variance of 0.25.\n\nThe scientist then performs four independent measurements, obtaining the following values: 1.2, 1.8, 2.0, and 1.0.\n\nAfter updating their belief about $\\mu$ using this data, what is the probability that the next single measurement will fall in the interval $(-1, 1)$?\n\nRound your final answer to three significant figures.", "solution": "Let the measurement model be $y_{i} \\mid \\mu \\sim \\text{Normal}(\\mu, \\sigma^{2})$ with $\\sigma^{2}=1$, and the prior be $\\mu \\sim \\text{Normal}(m_{0}, v_{0})$ with $m_{0}=0.5$ and $v_{0}=\\frac{1}{4}$. Define precisions $\\tau_{0}=\\frac{1}{v_{0}}$ and $\\tau=\\frac{1}{\\sigma^{2}}$.\n\nFor $n$ independent observations $y_{1},\\dots,y_{n}$, the conjugate Normal posterior is\n$$\nv_{n}=\\frac{1}{\\tau_{0}+n\\tau}, \\qquad m_{n}=v_{n}\\left(\\tau_{0}m_{0}+\\tau\\sum_{i=1}^{n}y_{i}\\right).\n$$\nHere $n=4$ and the data sum is $\\sum_{i=1}^{4}y_{i}=1.2+1.8+2.0+1.0=6.0$. With $v_{0}=\\frac{1}{4}$ we have $\\tau_{0}=4$, and with $\\sigma^{2}=1$ we have $\\tau=1$. Thus\n$$\nv_{n}=\\frac{1}{4+4}=\\frac{1}{8}, \\qquad m_{n}=\\frac{1}{8}\\left(4\\cdot 0.5+1\\cdot 6\\right)=\\frac{1}{8}(2+6)=1.\n$$\n\nThe posterior predictive distribution for a new measurement $Y_{\\text{new}}$ marginalizing over $\\mu$ is Normal with mean $m_{n}$ and variance $\\sigma^{2}+v_{n}$:\n$$\nY_{\\text{new}} \\mid \\text{data} \\sim \\text{Normal}\\left(m_{n},\\,\\sigma^{2}+v_{n}\\right)=\\text{Normal}\\left(1,\\,1+\\frac{1}{8}\\right)=\\text{Normal}\\left(1,\\,\\frac{9}{8}\\right).\n$$\n\nWe seek $P(-1<Y_{\\text{new}}<1\\mid \\text{data})$. Let $Z\\sim \\text{Normal}(0,1)$ and write this probability using the standard normal cumulative distribution function $\\Phi$:\n$$\nP(-1<Y_{\\text{new}}<1)=\\Phi\\!\\left(\\frac{1-m_{n}}{\\sqrt{\\sigma^{2}+v_{n}}}\\right)-\\Phi\\!\\left(\\frac{-1-m_{n}}{\\sqrt{\\sigma^{2}+v_{n}}}\\right).\n$$\nSubstituting $m_{n}=1$ and $\\sigma^{2}+v_{n}=\\frac{9}{8}$ gives\n$$\n\\frac{1-m_{n}}{\\sqrt{\\sigma^{2}+v_{n}}}=0, \\qquad \\frac{-1-m_{n}}{\\sqrt{\\sigma^{2}+v_{n}}}=\\frac{-2}{\\sqrt{9/8}}=-\\frac{4\\sqrt{2}}{3}.\n$$\nHence\n$$\nP(-1<Y_{\\text{new}}<1)=\\Phi(0)-\\Phi\\!\\left(-\\frac{4\\sqrt{2}}{3}\\right)=\\Phi\\!\\left(\\frac{4\\sqrt{2}}{3}\\right)-\\frac{1}{2}.\n$$\nUsing $\\Phi(x)=\\frac{1}{2}\\left[1+\\operatorname{erf}\\!\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]$ and $\\frac{1}{\\sqrt{2}}\\cdot \\frac{4\\sqrt{2}}{3}=\\frac{4}{3}$,\n$$\nP(-1<Y_{\\text{new}}<1)=\\frac{1}{2}\\operatorname{erf}\\!\\left(\\frac{4}{3}\\right).\n$$\nNumerically, $\\operatorname{erf}\\!\\left(\\frac{4}{3}\\right)\\approx 0.940836$, so\n$$\nP(-1<Y_{\\text{new}}<1)\\approx \\frac{1}{2}\\times 0.940836 \\approx 0.470418.\n$$\nRounded to three significant figures, this is $0.470$.", "answer": "$$\\boxed{0.470}$$", "id": "1946911"}, {"introduction": "A key feature of Bayesian inference is the explicit role of prior beliefs, but how much does the choice of prior really matter? This hands-on practice [@problem_id:1946883] investigates this question by comparing predictions from two analysts with different priors for a defect rate. By calculating and comparing the variance of their respective posterior predictive distributions, you will gain insight into how prior information shapes predictive uncertainty.", "problem": "In a semiconductor manufacturing plant, the quality of a batch of integrated circuits is assessed by the probability, $\\theta$, that a single randomly selected circuit is defective. The number of defective circuits in a sample of size $N$ is assumed to follow a binomial distribution with parameter $\\theta$.\n\nTwo statisticians, a junior analyst and a senior analyst, are tasked with predicting the number of defects in a future production run. They approach the problem from a Bayesian perspective.\n\nThe junior analyst, lacking specific historical data for this new process, adopts an uninformative prior for $\\theta$. They model their belief using a Beta distribution with parameters $\\alpha_J = 1$ and $\\beta_J = 1$.\n\nThe senior analyst, drawing on experience from similar manufacturing processes, believes the defect rate is likely close to 0.5. They use a more informative prior, a Beta distribution with parameters $\\alpha_S = 10$ and $\\beta_S = 10$.\n\nBoth analysts then observe the same initial data from a test batch: a sample of $n=20$ circuits is inspected, and $k=15$ are found to be defective. After updating their beliefs with this data, they are asked to make a prediction for a future production run of $m=50$ circuits.\n\nLet $V_J$ be the variance of the junior analyst's posterior predictive distribution for the number of defects in the new run, and let $V_S$ be the variance of the senior analyst's posterior predictive distribution.\n\nCalculate the ratio $\\frac{V_J}{V_S}$. Round your final answer to four significant figures.", "solution": "Let the defect probability be $\\theta$ and the test-batch data be $k$ defects out of $n$ items. With a $\\mathrm{Beta}(\\alpha,\\beta)$ prior and binomial likelihood, the posterior is $\\mathrm{Beta}(\\alpha',\\beta')$ with $\\alpha'=\\alpha+k$ and $\\beta'=\\beta+n-k$. For a future production run of size $m$, the posterior predictive distribution for the number of defects $X$ is $\\mathrm{Beta\\text{-}Binomial}(m,\\alpha',\\beta')$, whose variance is\n$$\n\\operatorname{Var}(X)=m\\,\\frac{\\alpha'\\beta'}{(\\alpha'+\\beta')^{2}}\\cdot\\frac{\\alpha'+\\beta'+m}{\\alpha'+\\beta'+1}\n= m\\,\\frac{\\alpha'\\beta'(\\alpha'+\\beta'+m)}{(\\alpha'+\\beta')^{2}(\\alpha'+\\beta'+1)}.\n$$\n\nJunior analyst: prior $\\mathrm{Beta}(1,1)$, so with $n=20$ and $k=15$,\n$$\n\\alpha'_{J}=1+15=16,\\quad \\beta'_{J}=1+5=6.\n$$\nThus\n$$\nV_{J}=m\\,\\frac{16\\cdot 6\\,(16+6+m)}{(16+6)^{2}(16+6+1)}\n=50\\,\\frac{96\\cdot(22+50)}{22^{2}\\cdot 23}\n=50\\,\\frac{96\\cdot 72}{484\\cdot 23}\n=\\frac{345600}{11132}.\n$$\n\nSenior analyst: prior $\\mathrm{Beta}(10,10)$, so\n$$\n\\alpha'_{S}=10+15=25,\\quad \\beta'_{S}=10+5=15.\n$$\nThus\n$$\nV_{S}=m\\,\\frac{25\\cdot 15\\,(25+15+m)}{(25+15)^{2}(25+15+1)}\n=50\\,\\frac{375\\cdot(40+50)}{40^{2}\\cdot 41}\n=50\\,\\frac{375\\cdot 90}{1600\\cdot 41}\n=\\frac{1687500}{65600}.\n$$\n\nThe ratio is\n$$\n\\frac{V_{J}}{V_{S}}=\\frac{345600}{11132}\\cdot\\frac{65600}{1687500}\n=\\frac{345600\\cdot 65600}{11132\\cdot 1687500}.\n$$\nCancel common factors: $\\gcd(65600,1687500)=100$, giving\n$$\n=\\frac{345600\\cdot 656}{11132\\cdot 16875}.\n$$\nFactor $345600=2^{9}\\cdot 3^{3}\\cdot 5^{2}$ and $16875=3^{3}\\cdot 5^{4}$, so\n$$\n\\frac{345600}{16875}=\\frac{2^{9}}{5^{2}}=\\frac{512}{25},\n$$\nhence\n$$\n\\frac{V_{J}}{V_{S}}=\\frac{512\\cdot 656}{25\\cdot 11132}.\n$$\nAlso $\\gcd(656,11132)=4$, so\n$$\n\\frac{V_{J}}{V_{S}}=\\frac{512\\cdot 164}{25\\cdot 2783}=\\frac{83968}{69575}.\n$$\nNumerically,\n$$\n\\frac{83968}{69575}\\approx 1.20687\\ldots,\n$$\nwhich to four significant figures is $1.207$.", "answer": "$$\\boxed{1.207}$$", "id": "1946883"}]}