{"hands_on_practices": [{"introduction": "Empirical Bayes methods gain their power by \"borrowing strength\" across related groups to learn about an underlying prior distribution. This first exercise demonstrates a foundational application: estimating the parameters of a Beta prior for a set of Binomial observations. By analyzing click-through rates from several distinct groups, you will learn how to use the method of moments to transform observed data into estimates for the hyperparameters that govern the variability across all groups [@problem_id:1915175].", "problem": "A digital marketing firm is analyzing the performance of a new advertisement across several distinct metropolitan areas. In each of $k$ areas, the ad was shown to $n$ randomly selected individuals. Let $x_i$ be the number of individuals who clicked the ad in area $i$.\n\nThe firm models this situation using a Beta-Binomial model. For each area $i$, the number of clicks $X_i$ is assumed to follow a Binomial distribution, $X_i \\sim \\text{Bin}(n, p_i)$, where $p_i$ is the true Click-Through Rate (CTR) for that area. The CTRs $p_i$ are themselves assumed to be drawn from a common Beta distribution, $p_i \\sim \\text{Beta}(\\alpha, \\beta)$, which describes the variation in the ad's effectiveness across different areas.\n\nThe firm wants to estimate the parameters $\\alpha$ and $\\beta$ of the Beta prior distribution using the method of moments. This involves first estimating the mean, $\\mu_p$, and variance, $\\sigma_p^2$, of the prior distribution from the observed data. A standard procedure relates the moments of the Beta prior to the sample statistics of the observed proportions $\\hat{p}_i = x_i/n$. Let $\\bar{p}$ be the mean of the sample proportions and $s_p^2$ be their unbiased sample variance. The moment-based estimates for the prior's mean and variance are:\n$$ \\hat{\\mu}_p = \\bar{p} $$\n$$ \\hat{\\sigma}_p^2 = \\frac{n}{n-1}\\left( s_p^2 - \\frac{\\bar{p}(1-\\bar{p})}{n} \\right) $$\nOnce $\\hat{\\mu}_p$ and $\\hat{\\sigma}_p^2$ are computed, the parameters of the Beta distribution are found by solving the moment equations:\n$$ \\hat{\\mu}_p = \\frac{\\hat{\\alpha}}{\\hat{\\alpha}+\\hat{\\beta}} \\quad \\text{and} \\quad \\hat{\\sigma}_p^2 = \\frac{\\hat{\\mu}_p(1-\\hat{\\mu}_p)}{\\hat{\\alpha}+\\hat{\\beta}+1} $$\n\nSuppose the experiment was conducted in $k=4$ areas with $n=50$ impressions each. The observed number of clicks were:\n$$ x_1 = 5, \\quad x_2 = 10, \\quad x_3 = 15, \\quad x_4 = 20 $$\n\nCalculate the method of moments estimates $(\\hat{\\alpha}, \\hat{\\beta})$. Express your final answer as a pair of fractions in their simplest form.", "solution": "The goal is to find the method of moments estimates for the parameters $\\alpha$ and $\\beta$ of the Beta prior distribution. The process involves three main steps:\n1.  Calculate descriptive statistics from the data.\n2.  Use these statistics to estimate the mean $\\mu_p$ and variance $\\sigma_p^2$ of the prior.\n3.  Solve for the Beta parameters $\\hat{\\alpha}$ and $\\hat{\\beta}$ using the moment equations.\n\n**Step 1: Calculate sample statistics**\n\nThe observed number of clicks are $x_1 = 5, x_2 = 10, x_3 = 15, x_4 = 20$. The number of trials in each area is $n=50$.\nFirst, we compute the sample proportions $\\hat{p}_i = x_i/n$ for each of the $k=4$ areas:\n$$ \\hat{p}_1 = \\frac{5}{50} = 0.1 $$\n$$ \\hat{p}_2 = \\frac{10}{50} = 0.2 $$\n$$ \\hat{p}_3 = \\frac{15}{50} = 0.3 $$\n$$ \\hat{p}_4 = \\frac{20}{50} = 0.4 $$\n\nNext, we calculate the mean of these sample proportions, $\\bar{p}$:\n$$ \\bar{p} = \\frac{1}{k} \\sum_{i=1}^{k} \\hat{p}_i = \\frac{0.1 + 0.2 + 0.3 + 0.4}{4} = \\frac{1.0}{4} = 0.25 $$\n\nThen, we calculate the unbiased sample variance of the proportions, $s_p^2$:\n$$ s_p^2 = \\frac{1}{k-1} \\sum_{i=1}^{k} (\\hat{p}_i - \\bar{p})^2 $$\n$$ s_p^2 = \\frac{1}{3} \\left( (0.1 - 0.25)^2 + (0.2 - 0.25)^2 + (0.3 - 0.25)^2 + (0.4 - 0.25)^2 \\right) $$\n$$ s_p^2 = \\frac{1}{3} \\left( (-0.15)^2 + (-0.05)^2 + (0.05)^2 + (0.15)^2 \\right) $$\n$$ s_p^2 = \\frac{1}{3} \\left( 0.0225 + 0.0025 + 0.0025 + 0.0225 \\right) $$\n$$ s_p^2 = \\frac{1}{3} (0.05) = \\frac{0.05}{3} = \\frac{1}{20 \\times 3} = \\frac{1}{60} $$\n\n**Step 2: Estimate the moments of the prior distribution**\n\nUsing the formulas provided in the problem statement, we estimate the mean $\\mu_p$ and variance $\\sigma_p^2$ of the Beta prior.\nThe estimate for the mean is simply the sample mean of the proportions:\n$$ \\hat{\\mu}_p = \\bar{p} = 0.25 = \\frac{1}{4} $$\n\nThe estimate for the variance is:\n$$ \\hat{\\sigma}_p^2 = \\frac{n}{n-1}\\left( s_p^2 - \\frac{\\bar{p}(1-\\bar{p})}{n} \\right) $$\nWe substitute the values we have: $n=50$, $\\bar{p}=0.25$, and $s_p^2 = 1/60$.\n$$ \\hat{\\sigma}_p^2 = \\frac{50}{50-1}\\left( \\frac{1}{60} - \\frac{0.25 \\times (1-0.25)}{50} \\right) $$\n$$ \\hat{\\sigma}_p^2 = \\frac{50}{49}\\left( \\frac{1}{60} - \\frac{0.25 \\times 0.75}{50} \\right) = \\frac{50}{49}\\left( \\frac{1}{60} - \\frac{0.1875}{50} \\right) $$\nTo work with fractions: $0.1875 = \\frac{3}{16}$.\n$$ \\hat{\\sigma}_p^2 = \\frac{50}{49}\\left( \\frac{1}{60} - \\frac{3/16}{50} \\right) = \\frac{50}{49}\\left( \\frac{1}{60} - \\frac{3}{800} \\right) $$\nFind a common denominator for the terms in the parenthesis, which is 2400.\n$$ \\hat{\\sigma}_p^2 = \\frac{50}{49}\\left( \\frac{40}{2400} - \\frac{9}{2400} \\right) = \\frac{50}{49}\\left( \\frac{31}{2400} \\right) $$\n$$ \\hat{\\sigma}_p^2 = \\frac{1}{49}\\left( \\frac{31}{48} \\right) = \\frac{31}{2352} $$\n\n**Step 3: Solve for the Beta parameters $\\hat{\\alpha}$ and $\\hat{\\beta}$**\n\nWe now use the moment equations for the Beta distribution with our estimates $\\hat{\\mu}_p$ and $\\hat{\\sigma}_p^2$.\n$$ \\hat{\\mu}_p = \\frac{\\hat{\\alpha}}{\\hat{\\alpha}+\\hat{\\beta}} \\quad \\text{and} \\quad \\hat{\\sigma}_p^2 = \\frac{\\hat{\\mu}_p(1-\\hat{\\mu}_p)}{\\hat{\\alpha}+\\hat{\\beta}+1} $$\nFrom the second equation, we can solve for the sum $\\hat{\\alpha}+\\hat{\\beta}$:\n$$ \\hat{\\alpha}+\\hat{\\beta}+1 = \\frac{\\hat{\\mu}_p(1-\\hat{\\mu}_p)}{\\hat{\\sigma}_p^2} $$\n$$ \\hat{\\alpha}+\\hat{\\beta} = \\frac{\\hat{\\mu}_p(1-\\hat{\\mu}_p)}{\\hat{\\sigma}_p^2} - 1 $$\nLet's calculate $\\hat{\\mu}_p(1-\\hat{\\mu}_p)$:\n$$ \\hat{\\mu}_p(1-\\hat{\\mu}_p) = \\frac{1}{4} \\left(1-\\frac{1}{4}\\right) = \\frac{1}{4} \\times \\frac{3}{4} = \\frac{3}{16} $$\nNow substitute this and $\\hat{\\sigma}_p^2 = \\frac{31}{2352}$ into the equation for the sum:\n$$ \\hat{\\alpha}+\\hat{\\beta} = \\frac{3/16}{31/2352} - 1 = \\frac{3}{16} \\times \\frac{2352}{31} - 1 $$\nWe simplify the fraction: $2352 \\div 16 = 147$.\n$$ \\hat{\\alpha}+\\hat{\\beta} = \\frac{3 \\times 147}{31} - 1 = \\frac{441}{31} - \\frac{31}{31} = \\frac{410}{31} $$\nNow we use the first moment equation to find $\\hat{\\alpha}$ and $\\hat{\\beta}$ individually. Let $S = \\hat{\\alpha}+\\hat{\\beta} = \\frac{410}{31}$.\n$$ \\hat{\\alpha} = S \\times \\hat{\\mu}_p = \\frac{410}{31} \\times \\frac{1}{4} = \\frac{205}{62} $$\n$$ \\hat{\\beta} = S \\times (1-\\hat{\\mu}_p) = \\frac{410}{31} \\times \\frac{3}{4} = \\frac{205 \\times 3}{31 \\times 2} = \\frac{615}{62} $$\nThe estimates are $(\\hat{\\alpha}, \\hat{\\beta}) = \\left(\\frac{205}{62}, \\frac{615}{62}\\right)$. These are fractions in their simplest form.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{205}{62} & \\frac{615}{62} \\end{pmatrix}}$$", "id": "1915175"}, {"introduction": "While the method of moments is a powerful tool, it can sometimes lead to surprising results that require careful interpretation. This practice explores the Normal-Normal hierarchical model, a cornerstone for analyzing continuous data, and confronts a common practical issue: obtaining a negative estimate for a variance parameter. By working through this scenario, you will gain crucial insight into the relationship between sampling variance and true between-group variance, and learn the standard procedure for handling such outcomes [@problem_id:1915166].", "problem": "A team of education researchers is evaluating a new teaching method across $J=4$ different school districts. For each district $j$, they obtain an estimate of the average student score improvement, denoted by $Y_j$. This estimate is known to have a specific sampling variance $\\sigma_j^2$ which depends on the number of students in that district's study. The researchers adopt an empirical Bayes approach, modeling the score improvements with a Normal-Normal hierarchical model.\n\nThe model is specified as follows:\n1.  The observed improvement in each district, $Y_j$, is an estimate of the true but unknown effectiveness $\\theta_j$ for that district. The sampling distribution is $Y_j | \\theta_j \\sim N(\\theta_j, \\sigma_j^2)$.\n2.  The true effectiveness levels $\\theta_j$ for the different districts are assumed to be drawn from a common population distribution, which is modeled by a normal prior: $\\theta_j \\sim N(\\mu, \\tau^2)$. Here, $\\mu$ represents the overall average effectiveness of the method, and $\\tau^2$ represents the true variance in effectiveness between districts.\n\nThe collected data are:\n-   Observed score improvements: $Y = \\{8.00, 9.00, 11.00, 12.00\\}$\n-   Known sampling variances: $\\sigma^2 = \\{5.00, 6.00, 7.00, 8.00\\}$\n\nUsing the method of moments on the observed data $\\{Y_j\\}$, an analyst is tasked with estimating the between-district variance hyperparameter, $\\tau^2$. Based on the result of this estimation, a conclusion must be drawn about the model.\n\nSelect the option that correctly states the initial method-of-moments estimate for $\\tau^2$ (rounded to three significant figures) and describes the standard interpretation or procedural step that follows in an empirical Bayes framework.\n\nA. The estimate is $\\hat{\\tau}^2 = -3.17$. This estimate is truncated to 0, leading to the conclusion that there is no evidence of true between-district variation in effectiveness.\n\nB. The estimate is $\\hat{\\tau}^2 = 3.33$. This indicates that the true between-district variance is positive but smaller than the average sampling uncertainty.\n\nC. The estimate is $\\hat{\\tau}^2 = -3.17$. A negative variance estimate invalidates the Normal prior assumption, and the analysis cannot proceed without choosing a different prior distribution.\n\nD. The estimate is $\\hat{\\tau}^2 = 6.50$. This suggests the between-district variance is equal to the average sampling variance, indicating a high level of uncertainty.\n\nE. The estimate is $\\hat{\\tau}^2 = 0$. This value is obtained because the sample variance of the observations is smaller than the average sampling variance, rendering the method of moments inapplicable.", "solution": "We start from the hierarchical normal model with known sampling variances. For each district $j$, the sampling model is $Y_{j} \\mid \\theta_{j} \\sim N(\\theta_{j}, \\sigma_{j}^{2})$ and the prior is $\\theta_{j} \\sim N(\\mu, \\tau^{2})$. By the law of total variance,\n$$\n\\operatorname{Var}(Y_{j}) \\;=\\; \\operatorname{E}\\!\\left[\\operatorname{Var}(Y_{j}\\mid \\theta_{j})\\right] \\;+\\; \\operatorname{Var}\\!\\left(\\operatorname{E}[Y_{j}\\mid \\theta_{j}]\\right) \\;=\\; \\sigma_{j}^{2} \\;+\\; \\tau^{2}.\n$$\nBecause the $\\sigma_{j}^{2}$ differ across districts, the method-of-moments equates the empirical variance of $\\{Y_{j}\\}$ to the average of the model variances:\n$$\n\\frac{1}{J}\\sum_{j=1}^{J}\\operatorname{Var}(Y_{j}) \\;=\\; \\tau^{2} \\;+\\; \\frac{1}{J}\\sum_{j=1}^{J}\\sigma_{j}^{2}.\n$$\nUsing the sample variance of the observations as the moment estimator for the left-hand side, the method-of-moments estimator is\n$$\n\\hat{\\tau}^{2} \\;=\\; s_{Y}^{2} \\;-\\; \\bar{\\sigma^{2}},\n$$\nwhere\n$$\n\\bar{\\sigma^{2}} \\;=\\; \\frac{1}{J}\\sum_{j=1}^{J}\\sigma_{j}^{2}, \\qquad s_{Y}^{2} \\;=\\; \\frac{1}{J-1}\\sum_{j=1}^{J}\\left(Y_{j}-\\bar{Y}\\right)^{2}, \\qquad \\bar{Y} \\;=\\; \\frac{1}{J}\\sum_{j=1}^{J}Y_{j}.\n$$\nCompute $\\bar{Y}$ and $s_{Y}^{2}$ from the data $Y=\\{8.00,9.00,11.00,12.00\\}$ with $J=4$. First,\n$$\n\\bar{Y} \\;=\\; \\frac{8+9+11+12}{4} \\;=\\; 10.\n$$\nThen the deviations are $-2,-1,1,2$ with squared deviations summing to $10$, so\n$$\ns_{Y}^{2} \\;=\\; \\frac{10}{4-1} \\;=\\; \\frac{10}{3}.\n$$\nThe average sampling variance is\n$$\n\\bar{\\sigma^{2}} \\;=\\; \\frac{5+6+7+8}{4} \\;=\\; \\frac{26}{4} \\;=\\; \\frac{13}{2}.\n$$\nTherefore,\n$$\n\\hat{\\tau}^{2} \\;=\\; \\frac{10}{3} \\;-\\; \\frac{13}{2} \\;=\\; \\frac{20-39}{6} \\;=\\; -\\frac{19}{6} \\;\\approx\\; -3.17,\n$$\nrounded to three significant figures. In empirical Bayes practice, variance components are constrained to be nonnegative, so a negative moment estimate is truncated at $0$. The standard interpretation is that there is no evidence of true between-district heterogeneity beyond sampling error, and one proceeds with $\\hat{\\tau}^{2}=0$.\n\nHence, the correct option is A.", "answer": "$$\\boxed{A}$$", "id": "1915166"}, {"introduction": "The ultimate goal of estimating a prior is to use it for improved inference on individual cases. This final exercise completes the empirical Bayes workflow by showing you what to do *after* you have estimated the prior hyperparameters. Building on the Beta-Binomial framework, you will take the summary statistics from a collection of hospitals, derive an empirical prior, and then use it to calculate the posterior variance for a single hospital's success rate, quantifying the updated uncertainty after borrowing strength from the group [@problem_id:1915179].", "problem": "A team of biostatisticians is analyzing the success rates of a novel surgical procedure performed at a large number of hospitals. For each hospital $i$, the number of successful surgeries, $X_i$, out of a total of $n_i$ surgeries is recorded. The team adopts a hierarchical model to account for variability among hospitals.\n\nThe model assumes that for each hospital $i$, the number of successes $X_i$ follows a Binomial distribution with parameters $n_i$ and $p_i$, where $p_i$ is the true success probability for that specific hospital. That is, $X_i | p_i \\sim \\text{Binomial}(n_i, p_i)$. Furthermore, it is assumed that the true success rates $p_i$ are themselves random variables drawn from a common underlying distribution, which is modeled as a Beta distribution with shape parameters $\\alpha$ and $\\beta$. That is, $p_i \\sim \\text{Beta}(\\alpha, \\beta)$.\n\nThe parameters $\\alpha$ and $\\beta$ of the prior distribution are unknown. To estimate them, the team uses an empirical Bayes approach based on the method of moments. A study was conducted where each hospital performed the same number of surgeries, so $n_i = n = 50$ for all $i$. From the data collected across all hospitals, the sample mean number of successes was calculated to be $\\bar{X} = 40.5$, and the sample variance was $S^2 = 75$.\n\nConsider a specific hospital, Hospital J, which reported $X_J = 45$ successes in its $n=50$ surgeries. Using the empirical Bayes methodology, first estimate the prior parameters $\\alpha$ and $\\beta$ from the summary statistics ($\\bar{X}$, $S^2$, $n$), and then determine the posterior variance of the success probability $p_J$ for Hospital J.\n\nCalculate this posterior variance and report your answer as a real number. Round your final answer to four significant figures.", "solution": "We model $X_{i} \\mid p_{i} \\sim \\text{Binomial}(n, p_{i})$ with $p_{i} \\sim \\text{Beta}(\\alpha, \\beta)$. Marginally, $X_{i}$ follows a Beta-Binomial distribution with\n$$\n\\mu := \\mathbb{E}[p_{i}] = \\frac{\\alpha}{\\alpha + \\beta}, \n\\quad\nA := \\alpha + \\beta,\n$$\nand for $X_{i}$,\n$$\n\\mathbb{E}[X_{i}] = n \\mu, \n\\quad \n\\operatorname{Var}(X_{i}) = n \\mu (1 - \\mu)\\frac{n + A}{A + 1}.\n$$\n\nMethod of moments uses the sample mean and variance of $X_{i}$ across hospitals. Given $n=50$, $\\bar{X} = 40.5$, and $S^{2} = 75$, we have\n$$\n\\hat{\\mu} = \\frac{\\bar{X}}{n} = \\frac{40.5}{50} = 0.81,\n\\quad\nn \\hat{\\mu}(1 - \\hat{\\mu}) = 50 \\cdot 0.81 \\cdot 0.19 = 7.695.\n$$\nSet the theoretical variance equal to the sample variance:\n$$\n75 = 7.695 \\cdot \\frac{50 + A}{A + 1}.\n$$\nDefine $r := \\frac{75}{7.695} = \\frac{75000}{7695} = \\frac{15000}{1539}$. Then\n$$\n\\frac{50 + A}{A + 1} = r \n\\;\\;\\Longrightarrow\\;\\;\n50 + A = r(A + 1)\n\\;\\;\\Longrightarrow\\;\\;\nA(1 - r) = r - 50,\n$$\nso\n$$\n\\hat{A} = \\frac{r - 50}{1 - r} = \\frac{50 - r}{r - 1}.\n$$\nUsing $r = \\frac{15000}{1539}$,\n$$\n\\hat{A} = \\frac{50 - \\frac{15000}{1539}}{\\frac{15000}{1539} - 1}\n= \\frac{50 \\cdot 1539 - 15000}{15000 - 1539}\n= \\frac{61950}{13461}\n= \\frac{20650}{4487}\n\\approx 4.60218.\n$$\nHence\n$$\n\\hat{\\alpha} = \\hat{\\mu}\\hat{A} = 0.81 \\cdot \\hat{A} = \\frac{81}{100}\\cdot\\frac{20650}{4487} = \\frac{33453}{8974} \\approx 3.72777,\n$$\n$$\n\\hat{\\beta} = (1 - \\hat{\\mu})\\hat{A} = 0.19 \\cdot \\hat{A} = \\frac{19}{100}\\cdot\\frac{20650}{4487} = \\frac{7847}{8974} \\approx 0.87441.\n$$\n\nFor Hospital J, with $X_{J} = 45$ and $n = 50$, the posterior for $p_{J}$ is\n$$\np_{J} \\mid X_{J} \\sim \\text{Beta}(\\hat{\\alpha} + X_{J}, \\hat{\\beta} + n - X_{J})\n= \\text{Beta}\\left(\\hat{\\alpha} + 45, \\hat{\\beta} + 5\\right).\n$$\nThus,\n$$\na_{\\text{post}} = \\hat{\\alpha} + 45 \\approx 48.72777,\n\\quad\nb_{\\text{post}} = \\hat{\\beta} + 5 \\approx 5.87441,\n\\quad\ns_{\\text{post}} = a_{\\text{post}} + b_{\\text{post}} \\approx 54.60218.\n$$\nThe variance of a $\\text{Beta}(a,b)$ distribution is\n$$\n\\operatorname{Var}(p) = \\frac{ab}{(a + b)^{2}(a + b + 1)}.\n$$\nTherefore,\n$$\n\\operatorname{Var}(p_{J} \\mid X_{J})\n= \\frac{a_{\\text{post}}\\,b_{\\text{post}}}{s_{\\text{post}}^{2}(s_{\\text{post}} + 1)}\n\\approx \\frac{48.72777 \\times 5.87441}{(54.60218)^{2} \\times 55.60218}.\n$$\nNumerically,\n$$\na_{\\text{post}}\\,b_{\\text{post}} \\approx 286.24708,\n\\quad\ns_{\\text{post}}^{2}(s_{\\text{post}} + 1) \\approx 165772.23163,\n$$\nso\n$$\n\\operatorname{Var}(p_{J} \\mid X_{J}) \\approx \\frac{286.24708}{165772.23163} \\approx 0.00172675.\n$$\nRounded to four significant figures, the posterior variance is $0.001727$.", "answer": "$$\\boxed{0.001727}$$", "id": "1915179"}]}