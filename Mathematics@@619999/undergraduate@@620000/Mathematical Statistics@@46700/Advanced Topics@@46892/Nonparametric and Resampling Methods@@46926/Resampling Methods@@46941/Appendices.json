{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with a permutation test, a powerful and intuitive resampling method for hypothesis testing. This exercise demonstrates how to compare the variability of two groups without assuming their data follows a specific distribution, like the normal distribution. By resampling—in this case, shuffling the group labels—we can empirically build the null distribution for our test statistic and determine the significance of our observed result, a foundational skill in computational statistics. [@problem_id:1951649]", "problem": "An industrial statistician is tasked with comparing the consistency of two different manufacturing processes for producing a specific type of resistor. Process A and Process B are used to create batches of resistors, and the resistance values are measured. The goal is to determine if Process B exhibits greater variability than Process A. Due to the potential for outliers and non-normal data, a robust, non-parametric approach is chosen.\n\nTwo independent random samples of resistance values (in Ohms) are collected:\n- Sample A (from Process A): $\\{10, 12, 13, 15\\}$\n- Sample B (from Process B): $\\{40, 48, 50, 53, 61\\}$\n\nThe statistician decides to use a test based on the ratio of the Median Absolute Deviations (MAD) of the two samples. The MAD of a sample $\\{x_1, x_2, \\dots, x_n\\}$ is defined as the median of the absolute differences between each data point and the sample's median:\n$$ \\text{MAD} = \\text{median} \\left( |x_i - \\text{median}(\\{x_j\\})| \\right) $$\nFor this analysis, any standard scaling constant for the MAD is ignored as it will cancel in the ratio. The test statistic is defined as $T = \\frac{\\text{MAD}(B)}{\\text{MAD}(A)}$.\n\nTo assess the significance of the observed test statistic, a computational permutation procedure was performed. The $4+5=9$ total data points were pooled together. From this combined set, 9,999 random permutations were generated. In each permutation, a new sample of size 4 (let's call it A') and a new sample of size 5 (B') were formed without replacement, and the statistic $T^* = \\frac{\\text{MAD}(B')}{\\text{MAD}(A')}$ was calculated.\n\nThe 30 largest values of $T^*$ from the 9,999 permutations, sorted in descending order, are:\n`3.15, 2.98, 2.81, 2.75, 2.66, 2.54, 2.49, 2.41, 2.35, 2.33, 2.28, 2.22, 2.19, 2.15, 2.11, 2.08, 2.05, 2.02, 1.99, 1.97, 1.94, 1.90, 1.88, 1.85, 1.83, 1.80, 1.77, 1.76, 1.75, 1.72`\n\nUsing the provided simulation results, calculate the one-sided p-value for testing the hypothesis that Process B has a greater scale (variability) than Process A. The p-value is to be computed as $p = \\frac{1+k}{1+N}$, where $N$ is the number of permutations and $k$ is the number of permuted statistics $T^*$ that are greater than or equal to the statistic observed from the original samples. Give your answer as a decimal rounded to four significant figures.", "solution": "We are testing whether Process B has greater variability than Process A using the ratio of the Median Absolute Deviations (MAD). The MAD of a sample $\\{x_{1},\\dots,x_{n}\\}$ is defined as\n$$\n\\text{MAD}=\\text{median}\\left(|x_{i}-\\text{median}(\\{x_{j}\\})|\\right).\n$$\nFirst compute the observed statistic $T=\\frac{\\text{MAD}(B)}{\\text{MAD}(A)}$.\n\nFor Sample A, $\\{10,12,13,15\\}$, the sample median is the average of the two middle order statistics:\n$$\n\\text{median}(A)=\\frac{12+13}{2}=12.5.\n$$\nThe absolute deviations from $12.5$ are\n$$\n|10-12.5|=2.5,\\quad |12-12.5|=0.5,\\quad |13-12.5|=0.5,\\quad |15-12.5|=2.5.\n$$\nSorting these gives $0.5,0.5,2.5,2.5$, so the MAD is the median of these four numbers, i.e., the average of the two middle values:\n$$\n\\text{MAD}(A)=\\frac{0.5+2.5}{2}=1.5.\n$$\n\nFor Sample B, $\\{40,48,50,53,61\\}$, the sample median is the middle order statistic:\n$$\n\\text{median}(B)=50.\n$$\nThe absolute deviations from $50$ are\n$$\n|40-50|=10,\\quad |48-50|=2,\\quad |50-50|=0,\\quad |53-50|=3,\\quad |61-50|=11.\n$$\nSorting these gives $0,2,3,10,11$, so the MAD is the middle value:\n$$\n\\text{MAD}(B)=3.\n$$\nTherefore, the observed test statistic is\n$$\nT=\\frac{\\text{MAD}(B)}{\\text{MAD}(A)}=\\frac{3}{1.5}=2.\n$$\n\nFrom the permutation procedure with $N=9999$ permutations, we must count $k$, the number of permuted statistics $T^{*}$ that are greater than or equal to the observed $T=2$. The $30$ largest $T^{*}$ values in descending order are given. Among these, the $18$th largest is $2.02\\geq 2$, while the $19$th largest is $1.992$. Since all remaining values are less than or equal to $1.99$, it follows that exactly $k=18$ permutations satisfy $T^{*}\\geq 2$.\n\nUsing the add-one p-value formula\n$$\np=\\frac{1+k}{1+N}=\\frac{1+18}{1+9999}=\\frac{19}{10000}=1.9\\times 10^{-3}.\n$$\nRounded to four significant figures, this is\n$$\n1.900\\times 10^{-3}.\n$$", "answer": "$$\\boxed{1.900 \\times 10^{-3}}$$", "id": "1951649"}, {"introduction": "Having explored resampling for hypothesis testing, we now confront a critical challenge in applying these methods: non-independent data. Real-world datasets often have a clustered structure, which violates the assumptions of a naive bootstrap. This problem [@problem_id:1951652] requires you to think not just as a calculator, but as a statistical designer, by choosing a valid bootstrap procedure that correctly accounts for within-group correlation.", "problem": "An environmental scientist is investigating the effect of industrial discharge on mercury levels in fish. Data is collected from $M$ distinct river systems. In each river system $i$ (where $i=1, \\dots, M$), $n_i$ fish are sampled, and for each fish $j$ (where $j=1, \\dots, n_i$), two measurements are recorded: its mercury concentration, $Y_{ij}$, and its proximity to a specific industrial discharge point, $X_{ij}$. The total number of fish sampled is $N = \\sum_{i=1}^M n_i$.\n\nThe scientist proposes a simple linear regression model to describe the relationship:\n$$\nY_{ij} = \\beta_0 + \\beta_1 X_{ij} + \\epsilon_{ij}\n$$\nThe primary goal is to construct a 95% confidence interval for the coefficient $\\beta_1$. A key consideration is that observations from the same river system are likely not independent. Unobserved factors common to a river (e.g., local water chemistry, specific food chain characteristics) can induce correlation in the error terms. That is, for fish within the same river $i$, $\\text{Cov}(\\epsilon_{ij}, \\epsilon_{ik}) \\neq 0$ for $j \\neq k$. However, observations from different river systems are assumed to be independent.\n\nTo account for this data structure, several bootstrap-based procedures are considered for estimating the sampling distribution of the Ordinary Least Squares (OLS) estimator, $\\hat{\\beta_1}$. Which of the following statements provides the most accurate description of a valid procedure and the reasoning for its validity in this context?\n\nA. The Non-clustered (Naive) Bootstrap: Create a bootstrap sample by drawing $N$ individual fish with replacement from the full dataset of all fish, ignoring which river they came from. This procedure is valid because, for a large total number of fish $N$, the distribution of the OLS estimator $\\hat{\\beta_1}$ will be approximately normal by the Central Limit Theorem.\n\nB. The Clustered Bootstrap: Create a bootstrap sample by first drawing $M$ river systems with replacement from the original list of $M$ rivers. Then, for each selected river, include all of its associated fish samples in the new bootstrap dataset. This procedure is valid because it treats the river systems as the independent sampling units, thereby preserving the within-river correlation structure of the original data.\n\nC. The Parametric Bootstrap: First, fit the OLS model to the original data to obtain estimates $\\hat{\\beta_0}$ and $\\hat{\\beta_1}$ and the set of all $N$ residuals, $\\{e_{ij}\\}$. Then, create a bootstrap outcome $Y_{ij}^*$ for each observation by sampling a residual $e_{ij}^*$ with replacement from $\\{e_{ij}\\}$ and setting $Y_{ij}^* = \\hat{\\beta_0} + \\hat{\\beta_1} X_{ij} + e_{ij}^*$. This procedure is valid because it simulates new data from the fitted model while honoring the original predictor values.\n\nD. The Within-Cluster Resampling Bootstrap: Create a bootstrap sample by keeping the original set of $M$ rivers fixed. Then, for each river $i$, a new set of $n_i$ fish for that river is generated by resampling with replacement from the original $n_i$ fish in that same river. This procedure is valid because it correctly models the sampling variability that occurs within each individual river system.\n\nE. The Fixed-X Bootstrap: Create a bootstrap sample by first fitting the OLS model to get residuals $\\{e_{ij}\\}$. Then, for each fish, create a new outcome $Y_{ij}^* = \\hat{\\beta_0} + \\hat{\\beta_1} X_{ij} + \\delta_{ij}$, where $\\delta_{ij}$ is a random value drawn from a standard normal distribution, $N(0, \\hat{\\sigma}^2)$, with $\\hat{\\sigma}^2$ being the estimated variance of the residuals. This procedure is valid as long as the errors are homoscedastic and approximately normal.", "solution": "We are given clustered data: fish are nested within river systems. The linear model is\n$$\nY_{ij}=\\beta_{0}+\\beta_{1}X_{ij}+\\epsilon_{ij},\n$$\nwith independence across rivers and within-river correlation. Formally, for $i \\neq i'$,\n$$\n\\text{Cov}(\\epsilon_{ij},\\epsilon_{i'k})=0,\n$$\nwhile for the same river $i$ and distinct fish $j \\neq k$,\n$$\n\\text{Cov}(\\epsilon_{ij},\\epsilon_{ik}) \\neq 0.\n$$\nA standard way to express this is via a random-effects decomposition,\n$$\n\\epsilon_{ij}=u_{i}+v_{ij},\n$$\nwhere $u_{i}$ is a river-specific component and $v_{ij}$ is an idiosyncratic component, with $\\text{Var}(u_{i})=\\sigma_{u}^{2}$, $\\text{Var}(v_{ij})=\\sigma_{v}^{2}$, $\\text{Cov}(u_{i},v_{ij})=0$, implying\n$$\n\\text{Var}(\\epsilon_{ij})=\\sigma_{u}^{2}+\\sigma_{v}^{2},\\quad \\text{Cov}(\\epsilon_{ij},\\epsilon_{ik})=\\sigma_{u}^{2}\\quad \\text{for }j \\neq k.\n$$\nThe sampling units that are independent are the clusters $\\mathcal{C}_{i}=\\{(X_{ij},Y_{ij}):j=1,\\dots,n_{i}\\}$ across $i=1,\\dots,M$. For the bootstrap to be consistent for the sampling distribution of $\\hat{\\beta}_{1}$ under cluster dependence, the resampling scheme must mimic this dependence structure: resample the independent units (the rivers) and preserve the within-cluster joint distribution.\n\nEvaluation of the proposed procedures:\n- Option A (Naive individual-level bootstrap) draws $N$ fish i.i.d. from the pooled sample, ignoring river membership. This imposes an i.i.d. error structure across all resampled observations and does not reproduce the within-river covariance $\\text{Cov}(\\epsilon_{ij},\\epsilon_{ik})=\\sigma_{u}^{2}$. It therefore yields a bootstrap variance that is typically biased downward when $\\sigma_{u}^{2}0$. Appealing to a central limit theorem for large $N$ does not fix the bootstrap inconsistency; the bootstrap must replicate the correct dependence to estimate the variance of $\\hat{\\beta}_{1}$ under clustering.\n- Option B (Clustered bootstrap) samples rivers with replacement from $\\{1,\\dots,M\\}$ and includes all fish from each selected river, thus resampling $\\{\\mathcal{C}_{i}\\}$ as the i.i.d. units. This preserves the within-river correlation induced by $u_{i}$ and reflects the randomness in which rivers enter the sample. Under standard regularity (in particular, $M \\to \\infty$ with bounded or suitably controlled $n_{i}$), this procedure is asymptotically valid for the sampling distribution of $\\hat{\\beta}_{1}$ with clustered errors.\n- Option C (Residual bootstrap pooling all residuals) samples residuals i.i.d. from the pooled set $\\{e_{ij}\\}$ and constructs $Y_{ij}^{*}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{ij}+e_{ij}^{*}$. This enforces i.i.d. errors in the bootstrap world and destroys the within-river covariance structure; it is therefore invalid for clustered dependence.\n- Option D (Within-cluster resampling with clusters fixed) resamples fish within each observed river, keeping the set of rivers fixed. This conditions on the particular realized cluster effects and does not reflect the between-river sampling variability that drives the sampling distribution of $\\hat{\\beta}_{1}$ when rivers are the independent units. It underestimates variance when cluster effects are random and is not generally valid for inference that targets the population of rivers.\n- Option E (Fixed-$X$ Gaussian parametric bootstrap with i.i.d. noise) draws $\\delta_{ij}\\sim N(0,\\hat{\\sigma}^{2})$ independently and sets $Y_{ij}^{*}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{ij}+\\delta_{ij}$. This imposes homoscedastic i.i.d. errors and fails to encode the within-river covariance; even with normality, the correct parametric bootstrap would need to draw a multivariate normal error vector within each river with the estimated cluster covariance, not independent draws. As stated, it is invalid for clustered dependence.\n\nTherefore, the procedure that correctly treats rivers as the independent sampling units and preserves the within-river correlation is the clustered bootstrap described in option B, and its stated reasoning matches the required justification.", "answer": "$$\\boxed{B}$$", "id": "1951652"}, {"introduction": "The final practice moves from theory and design to implementation, challenging you to build the core resampling algorithms from first principles. By programming the bootstrap and jackknife procedures yourself, you will translate abstract statistical definitions into concrete computational steps [@problem_id:2404323]. This exercise solidifies your understanding of the underlying mechanics of these methods and equips you with the foundational skill to implement and adapt resampling techniques for your own unique data analysis problems.", "problem": "You must write a complete program that implements nonparametric resampling for uncertainty quantification in the following sense. Given a finite dataset $\\{x_{1},x_{2},\\dots,x_{n}\\}$ of real numbers and a statistic $T$ that maps any finite sequence of real numbers to a real number, your goal is to compute two uncertainty quantification measures: the bootstrap standard error and the jackknife standard error of $T$ on the given dataset, and a bootstrap percentile confidence interval (confidence interval (CI)). The implementation must use only a source of independent draws $U \\sim \\mathrm{Uniform}(0,1)$ to perform bootstrap resampling; no built-in sampling function that directly samples indices or elements with replacement may be used. The correctness of the bootstrap index sampling must follow from the following fact: if $U \\sim \\mathrm{Uniform}(0,1)$ and $n \\in \\mathbb{N}$ is the dataset size, then the integer $J=\\lfloor n U \\rfloor$ is uniformly distributed on $\\{0,1,\\dots,n-1\\}$, that is, $\\mathbb{P}(J=k)=1/n$ for each integer $k \\in \\{0,1,\\dots,n-1\\}$. Use this fact to map independent draws of $U$ to independent bootstrap indices. You must not call any function that directly samples elements or indices with replacement. Use the following foundational definitions as your starting point. For a chosen statistic $T$, the bootstrap procedure forms $B$ bootstrap replicates by drawing, for each replicate $b \\in \\{1,2,\\dots,B\\}$, a resample of size $n$ by sampling indices with replacement from $\\{0,1,\\dots,n-1\\}$ and computing $T$ on that resample. Denote these bootstrap statistics by $\\{\\hat{\\theta}_{b}\\}_{b=1}^{B}$. The bootstrap standard error is the sample standard deviation of $\\{\\hat{\\theta}_{b}\\}_{b=1}^{B}$, namely $s_{\\mathrm{boot}}=\\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{\\theta}_{b}-\\bar{\\theta}\\right)^{2}}$ with $\\bar{\\theta}=\\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}_{b}$. The bootstrap percentile confidence interval at nominal level $1-\\alpha$ is defined by the empirical quantiles of $\\{\\hat{\\theta}_{b}\\}$ at probabilities $p_{\\ell}=\\alpha/2$ and $p_{u}=1-\\alpha/2$. To avoid ambiguity, define the empirical quantile at probability $p \\in [0,1]$ as follows: if $t_{(1)} \\le t_{(2)} \\le \\dots \\le t_{(B)}$ are the sorted bootstrap values, then $q_{p}=t_{(k)}$ with $k=\\lceil p B \\rceil$ and the convention that $k$ is clipped to the range $\\{1,2,\\dots,B\\}$ if $p$ is $0$ or $1$. For the jackknife, define the leave-one-out statistics $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$ where $\\hat{\\theta}_{(i)}=T(x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{n})$ is computed on the dataset with $x_{i}$ omitted. Let $\\bar{\\theta}_{\\mathrm{jack}}=\\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$. The jackknife standard error is $s_{\\mathrm{jack}}=\\sqrt{\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{\\mathrm{jack}}\\right)^{2}}$. Your program must implement these definitions exactly. Implement the following statistics $T$ on a finite array of real numbers: the sample mean and the sample median, where the median for even length is the average of the two central order statistics. You must not use any built-in resampling function such as a direct choice-with-replacement routine; all bootstrap indices must be produced by transforming independent draws from $\\mathrm{Uniform}(0,1)$ using $J=\\lfloor n U \\rfloor$. Use the following test suite. For each test case, you are given a dataset, a statistic choice, the number of bootstrap replicates $B$, a nominal tail probability $\\alpha$, and a random seed. For each test case, compute and return in order four values: the bootstrap standard error $s_{\\mathrm{boot}}$, the jackknife standard error $s_{\\mathrm{jack}}$, and the lower and upper bounds $(q_{\\ell},q_{u})$ of the bootstrap percentile confidence interval at level $1-\\alpha$ using the quantile definition above. The test suite is:\n- Case $1$: data $[1.2,2.0,3.4,2.2]$, statistic mean, $B=5000$, $\\alpha=0.1$, seed $=12345$.\n- Case $2$: data $[5.0,5.0,5.0,5.0,5.0]$, statistic median, $B=3000$, $\\alpha=0.2$, seed $=2468$.\n- Case $3$: data $[0.2,0.5,1.1,2.8,4.0,7.5,9.0]$, statistic median, $B=6000$, $\\alpha=0.1$, seed $=13579$.\n- Case $4$: data $[0.2,0.5,1.1,2.8,4.0,7.5,9.0]$, statistic mean, $B=6000$, $\\alpha=0.05$, seed $=98765$.\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain $16$ real numbers in this order: for Case $1$, output $s_{\\mathrm{boot}}$, $s_{\\mathrm{jack}}$, $q_{\\ell}$, $q_{u}$; then for Case $2$ in the same order; then for Case $3$; then for Case $4$. For numerical stability and to make the results directly comparable, round each output value to exactly $6$ decimal places. No physical units are involved. Angles are not involved. Percentages must be expressed as decimals, so $\\alpha$ is provided directly as a number in $[0,1]$ and you must not print any percentage signs.", "solution": "The problem is valid. It presents a clear, self-contained, and scientifically sound task in computational statistics. All definitions, data, and parameters are provided unambiguously, allowing for a direct and verifiable implementation. The core of the problem is to implement two nonparametric resampling techniques—the bootstrap and the jackknife—to estimate the uncertainty of a given statistic.\n\nThe solution proceeds by first defining the necessary statistical functions and then implementing the resampling procedures as specified.\n\n**1. Statistical Preliminaries**\n\nGiven a dataset $X = \\{x_{1}, x_{2}, \\dots, x_{n}\\}$ of size $n$, and a statistic $T$, our objective is to quantify the uncertainty in the estimate $\\hat{\\theta} = T(X)$.\n\nThe problem requires implementing two specific statistics:\n- **Sample Mean**: For a dataset $\\{y_1, \\dots, y_k\\}$, the mean is $\\bar{y} = \\frac{1}{k}\\sum_{i=1}^{k} y_i$.\n- **Sample Median**: For an ordered dataset $y_{(1)} \\le y_{(2)} \\le \\dots \\le y_{(k)}$, the median is defined as $y_{((k+1)/2)}$ if $k$ is odd, and $\\frac{1}{2}(y_{(k/2)} + y_{(k/2+1)})$ if $k$ is even.\n\n**2. Bootstrap Procedure**\n\nThe bootstrap method estimates the sampling distribution of $\\hat{\\theta}$ by repeatedly sampling from the given dataset.\n\n- **Resampling**: The procedure involves generating $B$ bootstrap replicates. For each replicate $b \\in \\{1, 2, \\dots, B\\}$, we construct a bootstrap sample $X^{*b}$ of size $n$ by drawing indices with replacement from $\\{0, 1, \\dots, n-1\\}$. The problem mandates a specific method for this: for each position in the bootstrap sample, an index $J \\in \\{0, 1, \\dots, n-1\\}$ is generated from a uniform random variate $U \\sim \\mathrm{Uniform}(0,1)$ using the formula $J = \\lfloor nU \\rfloor$. This process is repeated $n$ times to obtain a full set of indices for one bootstrap sample.\n- **Bootstrap Statistics**: For each bootstrap sample $X^{*b}$, the statistic $T$ is computed, yielding a bootstrap statistic $\\hat{\\theta}_b = T(X^{*b})$. This process is repeated for all $B$ replicates to form the bootstrap distribution $\\{\\hat{\\theta}_1, \\hat{\\theta}_2, \\dots, \\hat{\\theta}_B\\}$.\n\n- **Bootstrap Standard Error ($s_{\\mathrm{boot}}$)**: The bootstrap estimate of the standard error of $\\hat{\\theta}$ is the sample standard deviation of the bootstrap statistics:\n$$s_{\\mathrm{boot}} = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{\\theta}_{b}-\\bar{\\theta}\\right)^{2}}$$\nwhere $\\bar{\\theta} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}_{b}$ is the average of the bootstrap statistics.\n\n- **Bootstrap Percentile Confidence Interval**: To construct a $(1-\\alpha)$ confidence interval, we use the quantiles of the ordered bootstrap statistics $t_{(1)} \\le t_{(2)} \\le \\dots \\le t_{(B)}$. The interval is given by $[q_{\\ell}, q_{u}]$, where $q_{\\ell}$ and $q_{u}$ are the empirical quantiles corresponding to probabilities $p_{\\ell} = \\alpha/2$ and $p_{u} = 1-\\alpha/2$, respectively. According to the problem's definition, the quantile $q_p$ is $t_{(k)}$, where the index $k$ is calculated as $k = \\lceil pB \\rceil$. This 1-based index $k$ is clipped to the range $\\{1, 2, \\dots, B\\}$. To implement this, for a given probability $p$, we compute $k = \\max(1, \\lceil pB \\rceil)$ and select the element at index $k-1$ from the 0-indexed sorted array of bootstrap statistics.\n\n**3. Jackknife Procedure**\n\nThe jackknife is an alternative resampling technique that systematically omits each observation from the dataset.\n\n- **Resampling**: For each observation $i \\in \\{1, 2, \\dots, n\\}$, a jackknife sample $X_{(i)}$ is formed by removing $x_i$ from the original dataset. This creates $n$ datasets, each of size $n-1$.\n- **Jackknife Statistics**: The statistic $T$ is computed for each of these $n$ samples, yielding the leave-one-out statistics $\\{\\hat{\\theta}_{(1)}, \\hat{\\theta}_{(2)}, \\dots, \\hat{\\theta}_{(n)}\\}$.\n\n- **Jackknife Standard Error ($s_{\\mathrm{jack}}$)**: The jackknife estimate of the standard error of $\\hat{\\theta}$ is defined as:\n$$s_{\\mathrm{jack}} = \\sqrt{\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{\\mathrm{jack}}\\right)^{2}}$$\nwhere $\\bar{\\theta}_{\\mathrm{jack}} = \\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$ is the average of the jackknife statistics.\n\n**4. Implementation Strategy**\n\nThe overall program is structured to handle the specified test cases. A main function iterates through each case, calling a core computational function. This function performs the following steps for a given dataset, statistic, and parameters ($B, \\alpha$, seed):\n1.  Set the random number generator seed to ensure reproducibility.\n2.  Perform the bootstrap procedure: generate $B$ bootstrap samples using the specified $\\lfloor nU \\rfloor$ method, compute the $B$ statistics, and then calculate $s_{\\mathrm{boot}}$ and the percentile confidence interval bounds $(q_{\\ell}, q_{u})$.\n3.  Perform the jackknife procedure: generate the $n$ leave-one-out samples, compute the $n$ statistics, and calculate $s_{\\mathrm{jack}}$.\n4.  Return the four required values: $s_{\\mathrm{boot}}, s_{\\mathrm{jack}}, q_{\\ell}, q_{u}$.\n\nThe final results from all test cases are collected, rounded to $6$ decimal places, and printed in the required single-line format.", "answer": "```python\nimport numpy as np\nimport math\n\ndef compute_uncertainties(data, statistic_name, B, alpha, seed):\n    \"\"\"\n    Computes bootstrap and jackknife standard errors and a bootstrap percentile CI.\n\n    Args:\n        data (np.ndarray): The input dataset.\n        statistic_name (str): The name of the statistic ('mean' or 'median').\n        B (int): The number of bootstrap replicates.\n        alpha (float): The significance level for the confidence interval.\n        seed (int): The random seed for reproducibility.\n\n    Returns:\n        tuple: A tuple containing (s_boot, s_jack, ci_lower, ci_upper).\n    \"\"\"\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n\n    # Convert data to numpy array\n    data = np.array(data, dtype=float)\n    n = len(data)\n\n    # Define statistic functions\n    if statistic_name == 'mean':\n        statistic_fn = np.mean\n    elif statistic_name == 'median':\n        statistic_fn = np.median\n    else:\n        raise ValueError(\"Unknown statistic\")\n\n    # --- Bootstrap Procedure ---\n    bootstrap_stats = np.empty(B)\n    for i in range(B):\n        # Generate n uniform random numbers U ~ Uniform(0,1)\n        uniform_draws = np.random.rand(n)\n        # Generate bootstrap indices using J = floor(n*U)\n        bootstrap_indices = np.floor(n * uniform_draws).astype(int)\n        # Create bootstrap sample\n        bootstrap_sample = data[bootstrap_indices]\n        # Compute statistic\n        bootstrap_stats[i] = statistic_fn(bootstrap_sample)\n\n    # Bootstrap Standard Error\n    s_boot = np.std(bootstrap_stats, ddof=1)\n\n    # Bootstrap Percentile Confidence Interval\n    sorted_bootstrap_stats = np.sort(bootstrap_stats)\n    \n    # Lower bound\n    p_lower = alpha / 2.0\n    k_lower = int(math.ceil(p_lower * B))\n    k_lower = max(1, k_lower)\n    ci_lower = sorted_bootstrap_stats[k_lower - 1]\n\n    # Upper bound\n    p_upper = 1.0 - alpha / 2.0\n    k_upper = int(math.ceil(p_upper * B))\n    k_upper = max(1, k_upper) \n    ci_upper = sorted_bootstrap_stats[k_upper - 1]\n\n    # --- Jackknife Procedure ---\n    jackknife_stats = np.empty(n)\n    for i in range(n):\n        # Create leave-one-out sample\n        jackknife_sample = np.delete(data, i)\n        # Compute statistic\n        jackknife_stats[i] = statistic_fn(jackknife_sample)\n\n    # Jackknife Standard Error\n    theta_jack_mean = np.mean(jackknife_stats)\n    sum_sq_diff = np.sum((jackknife_stats - theta_jack_mean)**2)\n    s_jack = np.sqrt(((n - 1) / n) * sum_sq_diff)\n    \n    return s_boot, s_jack, ci_lower, ci_upper\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        {'data': [1.2, 2.0, 3.4, 2.2], 'statistic': 'mean', 'B': 5000, 'alpha': 0.1, 'seed': 12345},\n        {'data': [5.0, 5.0, 5.0, 5.0, 5.0], 'statistic': 'median', 'B': 3000, 'alpha': 0.2, 'seed': 2468},\n        {'data': [0.2, 0.5, 1.1, 2.8, 4.0, 7.5, 9.0], 'statistic': 'median', 'B': 6000, 'alpha': 0.1, 'seed': 13579},\n        {'data': [0.2, 0.5, 1.1, 2.8, 4.0, 7.5, 9.0], 'statistic': 'mean', 'B': 6000, 'alpha': 0.05, 'seed': 98765}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = compute_uncertainties(\n            case['data'],\n            case['statistic'],\n            case['B'],\n            case['alpha'],\n            case['seed']\n        )\n        all_results.extend(results)\n\n    # Format results to 6 decimal places and create the final output string\n    formatted_results = [f\"{val:.6f}\" for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2404323"}]}