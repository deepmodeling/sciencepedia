{"hands_on_practices": [{"introduction": "To begin, we'll establish a solid foundation by directly applying the definition of the Cramér-Rao Lower Bound. This first practice problem [@problem_id:1912009] involves a Beta distribution, a model frequently used in fields like reliability engineering to represent probabilities. By working through the calculation of the Fisher information for the parameter $\\alpha$, you will develop the core mechanical skills needed to determine the theoretical limit on the precision of any unbiased estimator.", "problem": "In the field of reliability engineering, the Beta distribution is often used to model the probability of an event occurring. Consider a specific case of the Beta distribution with its second parameter fixed at $1$, whose probability density function (PDF) for a random variable $X$ is given by\n$$\nf(x; \\alpha) = \\alpha x^{\\alpha-1}\n$$\nfor $0 < x < 1$ and a shape parameter $\\alpha > 0$.\n\nSuppose we have a random sample of $n$ observations, $X_1, X_2, \\dots, X_n$, drawn independently from this distribution. We are interested in estimating the unknown parameter $\\alpha$.\n\nDetermine the Cramér-Rao Lower Bound (CRLB), which provides a lower bound on the variance of any unbiased estimator of $\\alpha$. Express your answer as a symbolic expression in terms of $\\alpha$ and $n$.", "solution": "We have the density $f(x;\\alpha)=\\alpha x^{\\alpha-1}$ for $0<x<1$ and $\\alpha>0$. For an independent sample $X_{1},\\dots,X_{n}$, the log-likelihood is\n$$\n\\ell(\\alpha)=\\sum_{i=1}^{n}\\ln f(X_{i};\\alpha)=\\sum_{i=1}^{n}\\left(\\ln\\alpha+(\\alpha-1)\\ln X_{i}\\right)=n\\ln\\alpha+(\\alpha-1)\\sum_{i=1}^{n}\\ln X_{i}.\n$$\nDifferentiate with respect to $\\alpha$ to obtain the score:\n$$\n\\frac{d\\ell(\\alpha)}{d\\alpha}=\\frac{n}{\\alpha}+\\sum_{i=1}^{n}\\ln X_{i}.\n$$\nDifferentiate again to obtain the observed information:\n$$\n\\frac{d^{2}\\ell(\\alpha)}{d\\alpha^{2}}=-\\frac{n}{\\alpha^{2}}.\n$$\nThe Fisher information for the sample is the negative expectation of the second derivative,\n$$\nI_{n}(\\alpha)=-\\mathbb{E}\\!\\left[\\frac{d^{2}\\ell(\\alpha)}{d\\alpha^{2}}\\right]=\\frac{n}{\\alpha^{2}}.\n$$\nEquivalently, one can verify that $\\mathbb{E}\\!\\left[\\frac{d\\ell}{d\\alpha}\\right]=0$ by computing $\\mathbb{E}[\\ln X]$ under $f(x;\\alpha)$. Using $\\int_{0}^{1}x^{a-1}\\,dx=\\frac{1}{a}$, we have\n$$\n\\int_{0}^{1}\\ln x\\,x^{a-1}\\,dx=\\frac{d}{da}\\int_{0}^{1}x^{a-1}\\,dx=-\\frac{1}{a^{2}},\n$$\nso with the density factor $\\alpha$,\n$$\n\\mathbb{E}[\\ln X]=\\alpha\\int_{0}^{1}\\ln x\\,x^{\\alpha-1}\\,dx=-\\frac{1}{\\alpha},\n$$\nand therefore $\\mathbb{E}\\!\\left[\\frac{d\\ell}{d\\alpha}\\right]=\\frac{n}{\\alpha}+n\\mathbb{E}[\\ln X]=0$, confirming regularity. The Cramér-Rao Lower Bound for any unbiased estimator $\\hat{\\alpha}$ is\n$$\n\\operatorname{Var}(\\hat{\\alpha})\\geq\\frac{1}{I_{n}(\\alpha)}=\\frac{\\alpha^{2}}{n}.\n$$", "answer": "$$\\boxed{\\frac{\\alpha^{2}}{n}}$$", "id": "1912009"}, {"introduction": "Often, our interest lies not in a distribution's direct parameter, but in a function of it that has a more practical interpretation. This practice [@problem_id:1912024] explores such a scenario using the Poisson distribution to model discrete events, where we aim to estimate the probability of observing zero events, $g(\\lambda) = \\exp(-\\lambda)$. Mastering this demonstrates how to transform the CRLB for a parameter $\\lambda$ into a bound for a function $g(\\lambda)$, a vital skill for applied statistical inference.", "problem": "In a data transmission study, the number of packets dropped per second, denoted by $X$, is modeled as a random variable following a Poisson distribution with an unknown mean rate $\\lambda > 0$. The probability mass function is given by $P(X=x) = \\frac{e^{-\\lambda}\\lambda^x}{x!}$ for $x = 0, 1, 2, \\dots$. An experiment is conducted where the number of dropped packets is recorded for $n$ independent one-second intervals, yielding a random sample $X_1, X_2, \\dots, X_n$.\n\nWe are interested in estimating the probability that zero packets are dropped in a given one-second interval, which is a function of the rate parameter, $g(\\lambda) = e^{-\\lambda}$.\n\nDetermine the Cramér-Rao lower bound for the variance of any unbiased estimator of $g(\\lambda)$. Express your answer as an analytic expression in terms of $n$ and $\\lambda$.", "solution": "Let $X_{1},\\dots,X_{n}$ be independent and identically distributed with $X_{i}\\sim\\text{Poisson}(\\lambda)$, where the pmf is $P(X=x)=\\exp(-\\lambda)\\lambda^{x}/x!$ for $x\\in\\{0,1,2,\\dots\\}$. The joint likelihood is\n$$\nL(\\lambda; x_{1},\\dots,x_{n})=\\prod_{i=1}^{n}\\exp(-\\lambda)\\frac{\\lambda^{x_{i}}}{x_{i}!}.\n$$\nThe log-likelihood is\n$$\n\\ell(\\lambda)=\\sum_{i=1}^{n}\\left[-\\lambda+x_{i}\\ln\\lambda-\\ln(x_{i}!)\\right]=-n\\lambda+\\left(\\sum_{i=1}^{n}x_{i}\\right)\\ln\\lambda-\\sum_{i=1}^{n}\\ln(x_{i}!).\n$$\nThe score function is\n$$\n\\frac{\\partial\\ell(\\lambda)}{\\partial\\lambda}=-n+\\frac{\\sum_{i=1}^{n}x_{i}}{\\lambda}.\n$$\nThe second derivative is\n$$\n\\frac{\\partial^{2}\\ell(\\lambda)}{\\partial\\lambda^{2}}=-\\frac{\\sum_{i=1}^{n}x_{i}}{\\lambda^{2}}.\n$$\nTaking expectation under $\\lambda$, using $\\mathbb{E}_{\\lambda}[X_{i}]=\\lambda$, gives\n$$\n-\\mathbb{E}_{\\lambda}\\left[\\frac{\\partial^{2}\\ell(\\lambda)}{\\partial\\lambda^{2}}\\right]=-\\left(-\\frac{n\\lambda}{\\lambda^{2}}\\right)=\\frac{n}{\\lambda}.\n$$\nHence the Fisher information in the sample is $I_{n}(\\lambda)=n/\\lambda$.\n\nWe seek the Cramér-Rao lower bound for unbiased estimation of $g(\\lambda)=\\exp(-\\lambda)$. The derivative is\n$$\ng'(\\lambda)=-\\exp(-\\lambda),\n$$\nso\n$$\n\\left(g'(\\lambda)\\right)^{2}=\\exp(-2\\lambda).\n$$\nFor regular families, the Cramér-Rao inequality for any unbiased estimator $T$ of $g(\\lambda)$ is\n$$\n\\operatorname{Var}_{\\lambda}(T)\\geq\\frac{\\left(g'(\\lambda)\\right)^{2}}{I_{n}(\\lambda)}=\\frac{\\exp(-2\\lambda)}{n/\\lambda}=\\frac{\\lambda}{n}\\exp(-2\\lambda).\n$$\nTherefore, the Cramér-Rao lower bound is $\\frac{\\lambda}{n}\\exp(-2\\lambda)$.", "answer": "$$\\boxed{\\frac{\\lambda}{n}\\exp(-2\\lambda)}$$", "id": "1912024"}, {"introduction": "A true mastery of any scientific tool includes understanding its limitations. This final practice [@problem_id:1912001] challenges us to think critically about the applicability of the Cramér-Rao theorem itself by examining a Laplace distribution. You will investigate why the standard CRLB cannot be applied in this case, highlighting the importance of verifying the underlying 'regularity conditions' before employing a statistical theorem and ensuring a deeper conceptual grasp of the material.", "problem": "Let $X_1, X_2, \\ldots, X_n$ be a random sample drawn from a Laplace distribution. The probability density function (PDF) for a single observation $X$ from this distribution is given by\n$$f(x; \\mu) = \\frac{1}{2} \\exp(-|x - \\mu|)$$\nwhere $\\mu \\in \\mathbb{R}$ is the unknown location parameter, which is also the median of the distribution. We are interested in finding a lower bound for the variance of any unbiased estimator of $\\mu$. The Cramér-Rao theorem is a common tool for this purpose, but its application is contingent on certain regularity conditions being met.\n\nEvaluate the following statements concerning the applicability and result of the Cramér-Rao Lower Bound (CRLB) for the variance of an unbiased estimator of the parameter $\\mu$. Which statement is the most accurate description of the situation?\n\nA. The CRLB is applicable, and a lower bound for the variance of any unbiased estimator of $\\mu$ is $1/n$.\n\nB. The CRLB is applicable, and a lower bound for the variance of any unbiased estimator of $\\mu$ is $2/n$.\n\nC. The CRLB is not applicable because the support of the distribution, which is $(-\\infty, \\infty)$, depends on the parameter $\\mu$.\n\nD. The CRLB is not applicable because the derivative of the logarithm of the PDF with respect to $\\mu$ does not exist for all values of $x$ in the support.\n\nE. The CRLB is not applicable because the expected value of the score function (the derivative of the log-likelihood with respect to the parameter) is non-zero.", "solution": "We have a Laplace location family with density\n$$\nf(x;\\mu)=\\frac{1}{2}\\exp(-|x-\\mu|), \\quad x\\in \\mathbb{R}, \\ \\mu\\in \\mathbb{R}.\n$$\nFirst, note that the support is $(-\\infty,\\infty)$ for all $\\mu$, hence the support does not depend on $\\mu$. Therefore, statement C is false.\n\nThe log-density for one observation is\n$$\n\\ell(x;\\mu)=\\ln f(x;\\mu)=-|x-\\mu|-\\ln 2.\n$$\nThe score function for one observation is\n$$\ns(x;\\mu)=\\frac{\\partial}{\\partial \\mu}\\ell(x;\\mu)=\\frac{\\partial}{\\partial \\mu}\\left(-|x-\\mu|\\right).\n$$\nUsing $\\frac{\\partial}{\\partial \\mu}|x-\\mu|=-\\operatorname{sgn}(x-\\mu)$ for $x\\neq \\mu$, we get\n$$\ns(x;\\mu)=\\operatorname{sgn}(x-\\mu), \\quad \\text{for } x\\neq \\mu.\n$$\nAt $x=\\mu$ this derivative does not exist because of the cusp in $|x-\\mu|$. Since $x=\\mu$ belongs to the support for every $\\mu$, the derivative of the log-density with respect to $\\mu$ does not exist for all $x$ in the support. This violates a standard regularity condition for the classical Cramér-Rao bound which typically requires that $\\frac{\\partial}{\\partial \\mu}\\ell(x;\\mu)$ exist for all $x$ such that $f(x;\\mu)>0$. Hence, strictly speaking, the usual Cramér-Rao theorem is not applicable; this validates the rationale in statement D.\n\nFor completeness, check the other statements:\n- The expected score is\n$$\n\\mathbb{E}_{\\mu}[s(X;\\mu)]=\\mathbb{P}_{\\mu}(X>\\mu)-\\mathbb{P}_{\\mu}(X<\\mu)=\\frac{1}{2}-\\frac{1}{2}=0,\n$$\nso statement E is false.\n- If one informally computes the Fisher information using $I(\\mu)=\\mathbb{E}_{\\mu}[s(X;\\mu)^{2}]$, then $s(X;\\mu)^{2}=1$ with probability $1$, giving $I(\\mu)=1$ for one observation and $n$ for $n$ i.i.d. observations, which would suggest a bound $1/n$ as in A. However, this relies on applying the Cramér-Rao theorem despite a failure of its regularity conditions. Therefore A is not the most accurate statement about applicability.\n- Statement B claims $2/n$, which is not supported by the above computation even in the informal calculation.\n\nThus, the most accurate description is that the classical CRLB is not applicable because the derivative of the log-PDF with respect to $\\mu$ does not exist for all $x$ in the support.", "answer": "$$\\boxed{D}$$", "id": "1912001"}]}