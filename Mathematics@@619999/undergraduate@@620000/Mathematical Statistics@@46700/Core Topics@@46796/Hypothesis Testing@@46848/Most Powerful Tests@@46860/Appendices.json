{"hands_on_practices": [{"introduction": "The foundation of constructing a Most Powerful (MP) test is the Neyman-Pearson Lemma, which provides a clear recipe: rank the potential outcomes of an experiment by their likelihood ratio. This first exercise strips the concept down to its core by presenting a simple scenario with only three possible outcomes. By directly calculating and comparing the likelihood ratios, you will build an MP test from first principles, gaining a solid intuition before tackling more complex distributions [@problem_id:1937968].", "problem": "A research team is developing a new type of quantum sensor designed to detect a single, exotic particle. Based on a single measurement, the sensor outputs a discrete signal level, $X$, which can take one of the values from the set $\\{1, 2, 3\\}$. The statistical behavior of the sensor's output depends on whether the particle is present or absent.\n\nThe null hypothesis, $H_0$, corresponds to the particle being absent. The probability mass function of the signal $X$ under $H_0$ is given by:\n$P(X=1|H_0) = 0.5$\n$P(X=2|H_0) = 0.4$\n$P(X=3|H_0) = 0.1$\n\nThe alternative hypothesis, $H_1$, corresponds to the particle being present. The probability mass function of the signal $X$ under $H_1$ is:\n$P(X=1|H_1) = 0.1$\n$P(X=2|H_1) = 0.4$\n$P(X=3|H_1) = 0.5$\n\nThe team wants to construct a decision rule (a statistical test) based on a single sensor reading. A \"rejection\" of the null hypothesis corresponds to concluding that the particle is present. The test must be the most powerful one possible for a fixed size (Type I error probability) of $\\alpha = 0.1$.\n\nWhich of the following sets represents the rejection region for this most powerful test? The rejection region is the set of observed values of $X$ for which the null hypothesis $H_0$ is rejected.\n\nA. $\\{1\\}$\n\nB. $\\{3\\}$\n\nC. $\\{1, 2\\}$\n\nD. $\\{2, 3\\}$\n\nE. $\\{1, 3\\}$\n\nF. $\\{2\\}$", "solution": "We seek the most powerful test of size $\\alpha=0.1$ for testing $H_{0}$ versus $H_{1}$ based on a single observation $X \\in \\{1,2,3\\}$. By the Neyman–Pearson lemma, the most powerful test at level $\\alpha$ rejects $H_{0}$ when the likelihood ratio $\\Lambda(x)=\\frac{P(X=x \\mid H_{1})}{P(X=x \\mid H_{0})}$ is large, with a threshold chosen to satisfy the size constraint.\n\nCompute the likelihood ratios:\n$$\n\\Lambda(1)=\\frac{0.1}{0.5}=0.2,\\quad \\Lambda(2)=\\frac{0.4}{0.4}=1,\\quad \\Lambda(3)=\\frac{0.5}{0.1}=5.\n$$\nOrder them by decreasing $\\Lambda$: $x=3$ (largest), then $x=2$, then $x=1$.\n\nTo achieve size $\\alpha=0.1$, we include outcomes with the largest likelihood ratios until the total $H_{0}$ probability of the rejection region equals $\\alpha$, possibly using randomization at a boundary if needed. Under $H_{0}$,\n$$\nP_{0}(X=3)=0.1,\\quad P_{0}(X=2)=0.4,\\quad P_{0}(X=1)=0.5.\n$$\nTaking the top outcome $x=3$ alone yields\n$$\nP_{0}(\\{3\\})=0.1=\\alpha,\n$$\nso no randomization is needed. Including any additional outcome would exceed the size constraint. Therefore, the most powerful level-$\\alpha$ test rejects $H_{0}$ if and only if $X=3$.\n\nThis corresponds to the rejection region $\\{3\\}$, which matches option B.", "answer": "$$\\boxed{B}$$", "id": "1937968"}, {"introduction": "Once a test is constructed, we must ask: how well does it perform? This practice shifts our focus from building a test to analyzing its effectiveness. Here, we quantify performance by calculating the test's *power*—the probability of correctly identifying that the alternative hypothesis is true. This exercise demonstrates how to derive an analytical expression for the power of a test for the mean of a normal distribution, revealing its direct relationship with the sample size $n$ and the chosen significance level $\\alpha$ [@problem_id:1937923].", "problem": "A signal processing system is designed to distinguish a target signal from background noise. When only noise is present, a measurement $X$ is well-modeled by a normal distribution with a mean of 0 and a variance of 1, i.e., $N(0, 1)$. When the target signal is present, the measurement is modeled by a normal distribution with a mean of 1 and a variance of 1, i.e., $N(1, 1)$.\n\nTo make a decision, a random sample of $n$ independent measurements, $X_1, X_2, \\ldots, X_n$, is collected. A hypothesis test is formulated with the null hypothesis $H_0: \\mu=0$ (signal absent) against the alternative hypothesis $H_1: \\mu=1$ (signal present).\n\nThe Neyman-Pearson Lemma guarantees that the most powerful (MP) test at a significance level $\\alpha$ will reject the null hypothesis $H_0$ if the sample mean $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ is greater than some critical value $c$.\n\nYour task is to find the power of this most powerful test. Provide your answer as a single analytic expression in terms of the sample size $n$, the significance level $\\alpha$, and the cumulative distribution function (CDF) of the standard normal distribution, denoted by $\\Phi(\\cdot)$. The inverse of the CDF, or the quantile function, can be denoted by $\\Phi^{-1}(\\cdot)$.", "solution": "Under the null hypothesis $H_{0}:\\mu=0$, each $X_{i}\\sim N(0,1)$ independently, so the sample mean $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$ satisfies\n$$\n\\bar{X}\\mid H_{0}\\sim N\\!\\left(0,\\frac{1}{n}\\right).\n$$\nThe most powerful level-$\\alpha$ test rejects $H_{0}$ when $\\bar{X}c$, where $c$ is chosen to satisfy the size constraint\n$$\n\\Pr_{H_{0}}(\\bar{X}c)=\\alpha.\n$$\nStandardizing under $H_{0}$ gives\n$$\n\\Pr\\!\\left(Zc\\sqrt{n}\\right)=\\alpha,\\quad Z\\sim N(0,1),\n$$\nso\n$$\nc\\sqrt{n}=\\Phi^{-1}(1-\\alpha)\\quad\\Rightarrow\\quad c=\\frac{1}{\\sqrt{n}}\\Phi^{-1}(1-\\alpha).\n$$\n\nUnder the alternative hypothesis $H_{1}:\\mu=1$, we have\n$$\n\\bar{X}\\mid H_{1}\\sim N\\!\\left(1,\\frac{1}{n}\\right).\n$$\nTherefore, the power of the test is\n$$\n\\Pr_{H_{1}}(\\bar{X}c)=\\Pr\\!\\left(Z(c-1)\\sqrt{n}\\right)=1-\\Phi\\!\\left((c-1)\\sqrt{n}\\right),\n$$\nwhere $Z\\sim N(0,1)$. Substituting $c=\\frac{1}{\\sqrt{n}}\\Phi^{-1}(1-\\alpha)$ yields\n$$\n(c-1)\\sqrt{n}=\\Phi^{-1}(1-\\alpha)-\\sqrt{n},\n$$\nand hence the power equals\n$$\n1-\\Phi\\!\\left(\\Phi^{-1}(1-\\alpha)-\\sqrt{n}\\right)=\\Phi\\!\\left(\\sqrt{n}-\\Phi^{-1}(1-\\alpha)\\right).\n$$\nThis expresses the power in terms of $n$, $\\alpha$, and $\\Phi$, with $\\Phi^{-1}$ appearing through the critical value.", "answer": "$$\\boxed{\\Phi\\!\\left(\\sqrt{n}-\\Phi^{-1}(1-\\alpha)\\right)}$$", "id": "1937923"}, {"introduction": "This final practice bridges statistical theory and practical experimental design, addressing a question of paramount importance for any researcher: \"How much data do I need?\" By setting explicit performance requirements—a cap on the Type I error rate ($\\alpha$) and a minimum for the power—you will determine the minimum sample size necessary for a reliable conclusion. This exercise synthesizes the concepts of significance and power into a practical design calculation, illustrating the trade-offs inherent in hypothesis testing [@problem_id:1937987].", "problem": "A sensitive scientific instrument is designed to produce an output signal that follows a normal distribution with a mean $\\mu$ and a known variance $\\sigma^2 = 1$. Under perfect calibration, the mean signal is $\\mu_0 = 0$. A specific malfunction causes the mean signal to drift to a new value of $\\mu_1 = 0.5$. A diagnostic test is to be designed based on a random sample of $n$ independent measurements from the instrument.\n\nThis test must satisfy two strict performance criteria:\n1. The probability of falsely concluding that the instrument has malfunctioned when it is, in fact, perfectly calibrated must not exceed $0.05$.\n2. The probability of correctly identifying a malfunction when it has indeed occurred must be at least $0.90$.\n\nDetermine the smallest integer sample size $n$ that is required for the diagnostic test to meet both criteria.", "solution": "Let $X_{1},\\dots,X_{n}$ be independent with $X_{i} \\sim \\mathcal{N}(\\mu,1)$. We test $H_{0}:\\mu=0$ versus the one-sided alternative $H_{1}:\\mu=0.5$. For known variance and a larger-mean alternative, the uniformly most powerful level-$\\alpha$ test rejects for large $\\bar{X}$.\n\nUnder $H_{0}$, $\\bar{X} \\sim \\mathcal{N}(0,1/n)$. Choose a critical value $c$ so that the size is $0.05$:\n$$\n\\mathbb{P}_{\\mu=0}(\\bar{X} \\ge c)=0.05\n\\;\\Longleftrightarrow\\;\n\\mathbb{P}\\!\\left(Z \\ge c\\sqrt{n}\\right)=0.05\n\\;\\Longleftrightarrow\\;\nc\\sqrt{n}=z_{0.95},\n$$\nso\n$$\nc=\\frac{z_{0.95}}{\\sqrt{n}},\n$$\nwhere $z_{p}=\\Phi^{-1}(p)$ and $\\Phi$ is the standard normal cumulative distribution function.\n\nUnder $\\mu=0.5$, the power is\n$$\n\\mathbb{P}_{\\mu=0.5}(\\bar{X} \\ge c)\n=\\mathbb{P}\\!\\left(\\frac{\\bar{X}-0.5}{1/\\sqrt{n}} \\ge (c-0.5)\\sqrt{n}\\right)\n=1-\\Phi\\!\\left((c-0.5)\\sqrt{n}\\right).\n$$\nSubstituting $c=z_{0.95}/\\sqrt{n}$ gives\n$$\n\\text{power}=1-\\Phi\\!\\left(z_{0.95}-0.5\\sqrt{n}\\right).\n$$\nRequiring this to be at least $0.90$ yields\n$$\n1-\\Phi\\!\\left(z_{0.95}-0.5\\sqrt{n}\\right) \\ge 0.90\n\\;\\Longleftrightarrow\\;\n\\Phi\\!\\left(z_{0.95}-0.5\\sqrt{n}\\right) \\le 0.10\n\\;\\Longleftrightarrow\\;\nz_{0.95}-0.5\\sqrt{n} \\le z_{0.10}.\n$$\nUsing symmetry $z_{0.10}=-z_{0.90}$, this is\n$$\n0.5\\sqrt{n} \\ge z_{0.95}-z_{0.10}=z_{0.95}+z_{0.90}\n\\;\\Longleftrightarrow\\;\n\\sqrt{n} \\ge 2\\bigl(z_{0.95}+z_{0.90}\\bigr)\n\\;\\Longleftrightarrow\\;\nn \\ge \\left[2\\bigl(z_{0.95}+z_{0.90}\\bigr)\\right]^{2}.\n$$\nWith $z_{0.95}\\approx 1.644853626$ and $z_{0.90}\\approx 1.281551566$,\n$$\n2\\bigl(z_{0.95}+z_{0.90}\\bigr) \\approx 5.852810384,\n\\quad\nn \\ge 34.256\\ldots\n$$\nThus the smallest integer $n$ satisfying both criteria is $35$. A direct check gives power $=\\Phi\\!\\left(0.5\\sqrt{35}-z_{0.95}\\right)\\approx \\Phi(1.313)\\approx 0.905 \\ge 0.90$, while $n=34$ yields power below $0.90$.", "answer": "$$\\boxed{35}$$", "id": "1937987"}]}