{"hands_on_practices": [{"introduction": "The first step in designing any hypothesis test is deciding on an acceptable level of risk for making a specific kind of error. We must control the probability of rejecting the null hypothesis when it is actually true, an outcome known as a Type I error. This practice [@problem_id:1918510] gives you a concrete opportunity to calculate this probability, known as the significance level or size ($\\alpha$), from first principles for a test based on a simple binomial experiment.", "problem": "A team of data scientists is evaluating the performance of a new machine learning model for binary classification. The standard model for this task has a well-established success rate of $p=0.5$. The team wants to test if their new model is superior. They formulate a null hypothesis, $H_0$, that their new model is no better than the standard one, so its success probability is $p=0.5$.\n\nTo test this hypothesis, they run the new model on a validation set of $15$ independent trials. Let the random variable $X$ represent the number of successful classifications in these $15$ trials. The team decides on the following decision rule: they will reject the null hypothesis $H_0$ if the number of observed successes $X$ is strictly greater than 10.\n\nGiven that the null hypothesis $H_0: p=0.5$ is true, calculate the exact significance level (the size) of this statistical test. Express your answer as a single, irreducible fraction.", "solution": "Under the null hypothesis $H_{0}: p=0.5$, the number of successes $X$ in $n=15$ independent Bernoulli trials follows a binomial distribution with parameters $n=15$ and $p=\\frac{1}{2}$:\n$$\nX \\sim \\text{Binomial}(15, \\tfrac{1}{2}).\n$$\nThe significance level (size) of the test is the probability, under $H_{0}$, of rejecting $H_{0}$. The decision rule is to reject $H_{0}$ if $X>10$, hence the size $\\alpha$ is\n$$\n\\alpha = \\mathbb{P}_{H_{0}}(X>10) = \\sum_{k=11}^{15} \\binom{15}{k} \\left(\\tfrac{1}{2}\\right)^{15}.\n$$\nCompute the required binomial coefficients:\n$$\n\\binom{15}{11} = \\binom{15}{4} = 1365,\\quad\n\\binom{15}{12} = \\binom{15}{3} = 455,\\quad\n\\binom{15}{13} = \\binom{15}{2} = 105,\\quad\n\\binom{15}{14} = \\binom{15}{1} = 15,\\quad\n\\binom{15}{15} = 1.\n$$\nThus,\n$$\n\\sum_{k=11}^{15} \\binom{15}{k} = 1365 + 455 + 105 + 15 + 1 = 1941.\n$$\nTherefore,\n$$\n\\alpha = \\frac{1941}{2^{15}} = \\frac{1941}{32768}.\n$$\nSince the denominator is a power of $2$ and the numerator $1941$ is odd, the fraction is irreducible.", "answer": "$$\\boxed{\\frac{1941}{32768}}$$", "id": "1918510"}, {"introduction": "While controlling for false positives (Type I errors) is crucial, a good test must also be able to detect an effect when one truly exists. The 'power' of a test is its ability to correctly reject a false null hypothesis, and it is a vital concept in experimental design. This exercise [@problem_id:1918509] puts you in the role of an analyst evaluating the power of a given test, a critical step in judging whether an experiment has a high chance of success.", "problem": "A semiconductor manufacturing company is evaluating a new fabrication process designed to reduce defects in their microchips. The existing process has a well-established success rate, where a chip passes the final quality control check with a probability of 0.5. The engineering team claims that the new process is superior.\n\nTo test this claim, a hypothesis test is set up. Let $p$ be the true probability that a chip produced by the new process passes the quality control check. The null hypothesis, $H_0$, states that the new process is no better than the old one ($p=0.5$), while the alternative hypothesis, $H_A$, states that the new process is an improvement ($p > 0.5$).\n\nA sample of 10 chips is produced using the new process and subjected to the quality control check. Let $X$ be the number of chips in the sample that pass the check. The team decides on the following decision rule: they will reject the null hypothesis $H_0$ and conclude the new process is superior if the number of successful chips, $X$, is greater than 8.\n\nAssuming that the true success probability of the new process is actually $p=0.7$, calculate the power of this test. Round your final answer to four significant figures.", "solution": "The power of a hypothesis test is the probability of correctly rejecting the null hypothesis, $H_0$, when the alternative hypothesis, $H_A$, is true. In this problem, we are asked to calculate the power of the test given that the true probability of success is $p=0.7$.\n\nThe power is defined as:\n$$ \\text{Power} = P(\\text{Reject } H_0 | H_A \\text{ is true}) $$\n\nThe rejection rule is to reject $H_0$ if the number of successful chips, $X$, is greater than 8. The total number of chips in the sample is $n=10$. Therefore, the rejection region consists of the outcomes $X=9$ and $X=10$.\n\nThe power of the test is the probability that $X$ falls into this rejection region, calculated using the true value of $p$, which is given as $p=0.7$.\n$$ \\text{Power} = P(X > 8 | p=0.7) = P(X=9 | p=0.7) + P(X=10 | p=0.7) $$\n\nThe number of successful chips, $X$, in a fixed number of independent trials, $n$, follows a binomial distribution, $X \\sim \\text{Binomial}(n, p)$. The probability mass function (PMF) for the binomial distribution is:\n$$ P(X=k) = \\binom{n}{k} p^k (1-p)^{n-k} $$\n\nHere, $n=10$ and we are given the true probability $p=0.7$. Thus, $1-p = 0.3$. We can now calculate the probabilities for $X=9$ and $X=10$.\n\nFor $X=9$:\n$$ P(X=9) = \\binom{10}{9} (0.7)^9 (0.3)^{10-9} $$\n$$ P(X=9) = \\frac{10!}{9!1!} (0.7)^9 (0.3)^1 $$\n$$ P(X=9) = 10 \\times (0.7)^9 \\times 0.3 $$\nUsing a calculator, $(0.7)^9 \\approx 0.040353607$.\n$$ P(X=9) \\approx 10 \\times 0.040353607 \\times 0.3 = 0.121060821 $$\n\nFor $X=10$:\n$$ P(X=10) = \\binom{10}{10} (0.7)^{10} (0.3)^{10-10} $$\n$$ P(X=10) = \\frac{10!}{10!0!} (0.7)^{10} (0.3)^0 $$\n$$ P(X=10) = 1 \\times (0.7)^{10} \\times 1 $$\nUsing a calculator, $(0.7)^{10} \\approx 0.0282475249$.\n$$ P(X=10) \\approx 0.0282475249 $$\n\nThe power of the test is the sum of these two probabilities:\n$$ \\text{Power} = P(X=9) + P(X=10) \\approx 0.121060821 + 0.0282475249 = 0.1493083459 $$\n\nThe problem asks for the answer to be rounded to four significant figures.\n$$ \\text{Power} \\approx 0.1493 $$", "answer": "$$\\boxed{0.1493}$$", "id": "1918509"}, {"introduction": "Perhaps the most common misinterpretation in statistics is confusing a 'failure to reject the null hypothesis' with 'proof that the null hypothesis is true'. This logical fallacy, often summarized as 'absence of evidence is not evidence of absence,' stems from a misunderstanding of what a high p-value implies. This conceptual problem [@problem_id:1918527] will challenge you to articulate the correct statistical reasoning and understand why a non-significant result does not prove the null hypothesis, often due to limitations like a test's power.", "problem": "A quality control engineer at a company that manufactures high-precision electronic components is tasked with verifying the mean capacitance of a new batch of capacitors. The design specification requires the mean capacitance to be $\\mu_0 = 250.0$ picofarads (pF). The engineer plans to perform a two-tailed hypothesis test with a significance level of $\\alpha = 0.05$. The null and alternative hypotheses are set as:\n\n$H_0: \\mu = 250.0$ pF\n$H_a: \\mu \\neq 250.0$ pF\n\nThe engineer collects a random sample of $n = 40$ capacitors from the batch and measures their capacitance. The sample mean is found to be $\\bar{x} = 250.8$ pF, and the sample standard deviation is $s = 4.5$ pF. After performing the appropriate statistical test, the engineer calculates a p-value of approximately $0.26$. Since this p-value is greater than the significance level $\\alpha = 0.05$, the engineer fails to reject the null hypothesis.\n\nUpon seeing the report, a manager exclaims, \"Excellent! This result proves that the average capacitance of our new batch is exactly 250.0 pF, right on target.\"\n\nWhich of the following statements provides the best statistical explanation for why the manager's conclusion is incorrect?\n\nA. The test only indicates there is insufficient evidence to conclude the mean is different from 250.0 pF. The true mean could be slightly different, but the test may not have had enough statistical power to detect this difference.\n\nB. A Type I error might have occurred. This means the null hypothesis was incorrectly rejected, and the true mean is indeed 250.0 pF.\n\nC. The large p-value of 0.26 indicates that there is a 26% probability that the null hypothesis is true, which is not high enough to constitute a proof.\n\nD. The conclusion is based on a sample, not the entire population. To prove the mean is 250.0 pF, every single capacitor in the batch must be measured.\n\nE. The significance level of $\\alpha = 0.05$ was too large. A smaller significance level (e.g., $\\alpha = 0.01$) should have been used to provide definitive proof for the null hypothesis.", "solution": "We formalize the test the engineer performed. The hypotheses are $H_{0}:\\mu=\\mu_{0}$ versus $H_{a}:\\mu\\neq\\mu_{0}$ with $\\mu_{0}=250.0$. Using a sample of size $n$ with sample mean $\\bar{X}$ and sample standard deviation $S$, the usual test statistic for a two-sided one-sample mean test is\n$$\nT=\\frac{\\bar{X}-\\mu_{0}}{S/\\sqrt{n}}.\n$$\nThe two-sided p-value is\n$$\np=P\\left(|T^{\\ast}|\\geq |T_{\\text{obs}}|\\mid H_{0}\\right),\n$$\nwhere $T^{\\ast}$ denotes the sampling distribution of $T$ under $H_{0}$. The decision rule at level $\\alpha$ is: reject $H_{0}$ if $p\\leq \\alpha$; otherwise, fail to reject $H_{0}$.\n\nIn the report, $p>\\alpha$, so the correct statistical conclusion is to fail to reject $H_{0}$. Crucially, this decision does not establish that $H_{0}$ is true; it only indicates that the observed data do not provide sufficient evidence against $H_{0}$ at the chosen $\\alpha$.\n\nTo see why the manager’s statement is incorrect, recall the concepts of Type I and Type II errors and power. A Type I error occurs when $H_{0}$ is rejected even though $H_{0}$ is true, with probability $P(\\text{Type I})=\\alpha$. That possibility is only relevant when the decision is to reject. Here, there was no rejection, so a Type I error cannot have occurred. A Type II error occurs when $H_{0}$ is not rejected even though $H_{0}$ is false, with probability $\\beta(\\mu)$, and the test’s power is $1-\\beta(\\mu)$. Power depends on the true effect size $\\delta=\\mu-\\mu_{0}$, the sample size $n$, the variability (through $S$), and the test form. If $|\\delta|$ is modest relative to the standard error $S/\\sqrt{n}$, the test may have low to moderate power, and thus it may fail to detect a real but small difference. Therefore, a nonrejection (a large p-value) is consistent both with $H_{0}$ being true and with $H_{0}$ being false by a small margin; it does not “prove” equality.\n\nWe now evaluate the options:\n- Option A correctly states that failing to reject $H_{0}$ indicates insufficient evidence of a difference and that the true mean could still differ slightly, potentially undetected due to limited power. This matches the correct interpretation of $p>\\alpha$ and the role of power.\n- Option B invokes a Type I error, which would require a rejection that did not occur; thus it is inapplicable.\n- Option C misinterprets the p-value as $P(H_{0}\\mid\\text{data})$, which it is not. The p-value is $P(\\text{data or more extreme}\\mid H_{0})$, not a posterior probability of $H_{0}$.\n- Option D shifts to the idea of measuring every item. While a census could reveal the finite-batch mean, hypothesis testing does not require a census to justify nonproof of $H_{0}$; the key point is that nonrejection does not establish truth of $H_{0}$, regardless of census considerations.\n- Option E incorrectly suggests that a smaller $\\alpha$ can provide “definitive proof” for $H_{0}$. Hypothesis tests do not prove $H_{0}$; they can only fail to find evidence against it, and decreasing $\\alpha$ makes rejection harder, not proof stronger.\n\nTherefore, the best statistical explanation is precisely the one given in Option A.", "answer": "$$\\boxed{A}$$", "id": "1918527"}]}