{"hands_on_practices": [{"introduction": "The foundation of Fisher's Exact Test lies in calculating the probability of a specific arrangement of data, assuming the null hypothesis is true. This first practice exercise [@problem_id:1917964] offers a direct application of the hypergeometric probability formula. By working through this scenario, you will gain hands-on experience in computing the exact probability of a given 2x2 contingency table, which is the fundamental building block for determining statistical significance.", "problem": "A chemical engineering team is developing a new synthesis process and is comparing two potential catalysts, Catalyst Alpha and Catalyst Beta. In a series of trials, the outcomes were recorded. Catalyst Alpha was used in 6 trials, resulting in 5 successful syntheses and 1 failure. Catalyst Beta was used in 5 trials, resulting in 1 successful synthesis and 4 failures.\n\nTo evaluate if there is a statistically significant difference in efficacy, an analysis is performed under the null hypothesis that the success rate of a synthesis is independent of the catalyst used. The analysis is conditioned on the observed marginal totals: specifically, the total number of trials for each catalyst (6 for Alpha, 5 for Beta) and the total number of successes and failures across all trials (6 successes, 5 failures in total).\n\nUnder this null hypothesis, what is the exact probability of observing this particular distribution of outcomes? Express your answer as a decimal rounded to four significant figures.", "solution": "We model the allocation of the total $6$ successes among the $11$ trials, with $6$ trials conducted using Catalyst Alpha and $5$ using Catalyst Beta, under the null hypothesis that success is independent of catalyst and conditioning on the observed marginal totals. This corresponds to a hypergeometric model for the number of successes observed in the $6$ Alpha trials.\n\nLet $X$ be the number of successes in the $6$ Alpha trials. Under the null with fixed margins (total $K=6$ successes in $N=11$ trials, and $n=6$ Alpha trials), the probability of observing exactly $k$ successes in Alpha is\n$$\n\\Pr(X=k)=\\frac{\\binom{K}{k}\\binom{N-K}{n-k}}{\\binom{N}{n}}=\\frac{\\binom{6}{k}\\binom{5}{6-k}}{\\binom{11}{6}}.\n$$\nThe observed table has $k=5$ successes in Alpha (and thus $1$ success in Beta), so the exact probability of observing this particular distribution is\n$$\n\\Pr(X=5)=\\frac{\\binom{6}{5}\\binom{5}{1}}{\\binom{11}{6}}=\\frac{6\\cdot 5}{\\binom{11}{6}}=\\frac{30}{462}=\\frac{5}{77}.\n$$\nExpressed as a decimal rounded to four significant figures, this is\n$$\n\\frac{5}{77}\\approx 0.06494.\n$$", "answer": "$$\\boxed{0.06494}$$", "id": "1917964"}, {"introduction": "Beyond pure calculation, a crucial aspect of statistical inference is ensuring the test aligns with the scientific question at hand. This exercise [@problem_id:1917992] explores the vital decision between using a one-tailed versus a two-tailed test. It highlights how a directional research hypothesis—for instance, investigating if a new treatment is strictly *better* than a placebo—directly informs the setup of the statistical analysis.", "problem": "A biotechnology firm has developed\n a new gene therapy treatment intended to increase the expression of a beneficial protein. A clinical trial is designed to test its efficacy. Twenty patients with a diagnosed deficiency of this protein are enrolled and randomly assigned to one of two groups. Group A (10 patients) receives a placebo, and Group B (10 patients) receives the new gene therapy. After a three-month period, each patient is categorized as either \"Improved\" or \"Not Improved\" based on whether their protein expression level has crossed a clinically meaningful threshold.\n\nThe research team is only interested in whether the new therapy is strictly more effective than the placebo. If the therapy is equally effective or less effective, it will be considered a failure. The team plans to analyze the resulting 2x2 contingency table of counts (Group vs. Outcome) using Fisher's exact test, which is appropriate for this experimental design with small sample sizes.\n\nWhich of the following statements best describes the appropriate statistical approach and its justification?\n\nA. A two-tailed Fisher's exact test should be used because the null hypothesis is that there is no association between the treatment and the outcome, and a two-tailed test is the standard method for testing this hypothesis.\n\nB. A one-tailed Fisher's exact test should be used because the scientific question is directional; the researchers are specifically investigating if the new therapy is *better* than the placebo, not just different.\n\nC. A two-tailed Fisher's exact test should be used because it provides more statistical power than a one-tailed test to detect any significant effect.\n\nD. A one-tailed Fisher's exact test should be used only if the number of patients in the 'Improved' category is greater than the number in the 'Not Improved' category across both groups combined.\n\nE. The choice between a one-tailed and a two-tailed test cannot be made until after the data is collected and a preliminary analysis is performed.", "solution": "The core of this problem lies in understanding the relationship between a research question and the formulation of statistical hypotheses, which in turn dictates the type of statistical test to be used (one-tailed vs. two-tailed).\n\nFirst, let's define the null hypothesis ($H_0$) and the alternative hypothesis ($H_A$).\nThe null hypothesis ($H_0$) is a statement of no effect or no difference. In this context, it would be that the new gene therapy has no effect, meaning the proportion of \"Improved\" patients in the therapy group is the same as in the placebo group.\nThe alternative hypothesis ($H_A$) is the statement that the researcher is trying to find evidence for. It directly reflects the research question.\n\nNext, we must distinguish between one-tailed and two-tailed tests.\nA **two-tailed test** is used when the researcher is interested in detecting a difference in either direction. The alternative hypothesis would be that the proportion of improved patients in the therapy group is simply *not equal* to the proportion in the placebo group. This would test if the therapy is either better *or* worse than the placebo.\n\nA **one-tailed test** is used when the researcher has a specific, directional hypothesis. The alternative hypothesis would state that the proportion of improved patients in the therapy group is *greater than* the proportion in the placebo group (a right-tailed test) or *less than* (a left-tailed test). This choice is made *a priori*, before collecting or analyzing the data, based on the scientific objective.\n\nIn this problem, the scenario explicitly states: \"The research team is only interested in whether the new therapy is strictly more effective than the placebo.\" This is a clear, directional question. The firm does not care to distinguish between \"no effect\" and \"worse than placebo\"; both outcomes lead to the project's failure. They are only looking for evidence of superiority.\n\nTherefore, the appropriate alternative hypothesis ($H_A$) is: The proportion of \"Improved\" patients in the gene therapy group (Group B) is greater than the proportion of \"Improved\" patients in the placebo group (Group A).\n\nThis directional alternative hypothesis requires a **one-tailed test**. The test will calculate the probability of observing a result as extreme or more extreme *in the direction of the alternative hypothesis* (i.e., more people improving in the therapy group), assuming the null hypothesis is true. A two-tailed test would be inappropriate as it would also consider the probability of the therapy being significantly worse, which is not the question of interest and would misallocate statistical power.\n\nNow let's evaluate the given options:\n\n*   **A. A two-tailed Fisher's exact test should be used because the null hypothesis is that there is no association...** This is incorrect. While the null hypothesis is one of no association, the choice between one and two tails is determined by the *alternative hypothesis*, which is shaped by the research question.\n*   **B. A one-tailed Fisher's exact test should be used because the scientific question is directional; the researchers are specifically investigating if the new therapy is *better* than the placebo, not just different.** This is the correct statement. It accurately links the directional nature of the research question (seeking superiority) to the choice of a one-tailed test.\n*   **C. A two-tailed Fisher's exact test should be used because it provides more statistical power...** This is false. For a fixed significance level ($\\alpha$), a one-tailed test has more statistical power to detect an effect in the specified direction than a two-tailed test. The two-tailed test must split the rejection region ($\\alpha$) into two tails, making it harder to find a significant result in either specific direction.\n*   **D. A one-tailed Fisher's exact test should be used only if the number of patients in the 'Improved' category is greater...** This is incorrect. The choice of the test is based on the *hypothesis* before the experiment, not on the *outcome* of the experiment. Using the data to decide which test to run is a form of p-hacking and is statistically invalid.\n*   **E. The choice between a one-tailed and a two-tailed test cannot be made until after the data is collected...** This is fundamentally incorrect. The hypothesis, and therefore the type of test, must be specified before data analysis to ensure the integrity of the statistical inference process.\n\nThus, the only correct description and justification is provided in option B.", "answer": "$$\\boxed{B}$$", "id": "1917992"}, {"introduction": "A robust statistical method should produce conclusions that are not dependent on arbitrary labeling or presentation of the data. This final practice [@problem_id:1918000] investigates a key property of the Fisher's Exact Test: its invariance to the arrangement of rows and columns. By analyzing how the p-value behaves when the table is reconfigured, you will develop a deeper understanding of the test's underlying mathematical symmetry and reliability.", "problem": "In statistical analysis, a 2x2 contingency table is often used to summarize the relationship between two categorical variables. Consider a generic 2x2 contingency table with cell counts denoted as follows:\n\n$$\n\\begin{array}{c|cc|c}\n & \\text{Group 1} & \\text{Group 2} & \\text{Total} \\\\\n\\hline\n\\text{Outcome A} & a & b & a+b \\\\\n\\text{Outcome B} & c & d & c+d \\\\\n\\hline\n\\text{Total} & a+c & b+d & N\n\\end{array}\n$$\n\nwhere $N = a+b+c+d$ is the grand total. The Fisher's exact test is a statistical significance test used to determine if there are non-random associations between the two variables. The test involves calculating a p-value based on the hypergeometric distribution of the cell counts, conditional on fixed marginal totals.\n\nNow, imagine you create a new contingency table by swapping the two columns (\"Group 1\" and \"Group 2\"). The new table would be:\n\n$$\n\\begin{array}{c|cc|c}\n & \\text{Group 2} & \\text{Group 1} & \\text{Total} \\\\\n\\hline\n\\text{Outcome A} & b & a & a+b \\\\\n\\text{Outcome B} & d & c & c+d \\\\\n\\hline\n\\text{Total} & b+d & a+c & N\n\\end{array}\n$$\n\nHow does this column swap affect the two-sided p-value calculated from a Fisher's exact test? Select the statement that is always true.\n\nA. The p-value will change because swapping columns inverts the odds ratio, and the test's p-value is directly dependent on the magnitude of the odds ratio.\n\nB. The p-value will not change because the grand total and all four marginal totals (two row totals and two column totals) remain the same after the swap.\n\nC. The p-value will not change. The probability of any specific table configuration is determined by the factorials of the cell counts and the marginal totals. Swapping columns permutes these terms in the underlying formula in a way that leaves the probability of the observed table, and thus the p-value, unchanged.\n\nD. The p-value will most likely change. The set of \"more extreme\" tables used for the p-value calculation depends on which specific cell counts are observed, and these are rearranged by the column swap, altering the summation.", "solution": "Let the original table have counts $(a,b,c,d)$ with row totals $r_{1}=a+b$, $r_{2}=c+d$, column totals $c_{1}=a+c$, $c_{2}=b+d$, and grand total $N=r_{1}+r_{2}=c_{1}+c_{2}$. Fisher’s exact test conditions on $(r_{1},r_{2},c_{1},c_{2})$ and assigns to each table with these margins the hypergeometric probability of observing $a$ successes in $r_{1}$ draws from a population with $c_{1}$ successes in $N$ items:\n$$\nP(a \\mid r_{1},r_{2},c_{1},c_{2})=\\frac{\\binom{r_{1}}{a}\\binom{r_{2}}{c_{1}-a}}{\\binom{N}{c_{1}}}.\n$$\nEquivalently, the probability of the full table $(a,b,c,d)$ given the margins can be written in a symmetric factorial form:\n$$\nP(a,b,c,d \\mid r_{1},r_{2},c_{1},c_{2})=\\frac{r_{1}!\\,r_{2}!\\,c_{1}!\\,c_{2}!}{N!\\,a!\\,b!\\,c!\\,d!}.\n$$\nConsider swapping the columns, yielding $(b,a,d,c)$ with the same row totals $(r_{1},r_{2})$ and swapped column totals $(c_{2},c_{1})$. The hypergeometric expression for the swapped table’s observed top-left count $b$ is\n$$\nP'(b \\mid r_{1},r_{2},c_{2},c_{1})=\\frac{\\binom{r_{1}}{b}\\binom{r_{2}}{c_{2}-b}}{\\binom{N}{c_{2}}}.\n$$\nUsing $b=r_{1}-a$, $c_{2}=N-c_{1}$, and the binomial identities $\\binom{r_{1}}{r_{1}-a}=\\binom{r_{1}}{a}$, $\\binom{r_{2}}{c_{2}-b}=\\binom{r_{2}}{r_{2}-(c_{1}-a)}=\\binom{r_{2}}{c_{1}-a}$, and $\\binom{N}{N-c_{1}}=\\binom{N}{c_{1}}$, we obtain\n$$\nP'(b \\mid r_{1},r_{2},c_{2},c_{1})=P(a \\mid r_{1},r_{2},c_{1},c_{2}).\n$$\nEquivalently, from the factorial form,\n$$\nP'(b,a,d,c \\mid r_{1},r_{2},c_{2},c_{1})=\\frac{r_{1}!\\,r_{2}!\\,c_{2}!\\,c_{1}!}{N!\\,b!\\,a!\\,d!\\,c!}=P(a,b,c,d \\mid r_{1},r_{2},c_{1},c_{2}),\n$$\nshowing that swapping columns preserves the probability of every specific table when conditioning on the margins.\n\nFor the two-sided Fisher p-value defined by summing probabilities of all tables with probability less than or equal to that of the observed table (the standard “probability ordering” definition), write\n$$\np=\\sum_{t:\\;P(t)\\leq P(t_{\\text{obs}})} P(t).\n$$\nDefine the column-swap mapping $S$ that sends any table $t=(a,b,c,d)$ to $S(t)=(b,a,d,c)$. This $S$ is a bijection on the set of all margin-compatible tables, and by the calculation above $P(S(t))=P(t)$ for all $t$, and $S(t_{\\text{obs}})=t'_{\\text{obs}}$ is the swapped observed table with $P(t'_{\\text{obs}})=P(t_{\\text{obs}})$. Therefore\n$$\np'=\\sum_{t':\\;P(t')\\leq P(t'_{\\text{obs}})} P(t')=\\sum_{t:\\;P(S(t))\\leq P(S(t_{\\text{obs}}))} P(S(t))=\\sum_{t:\\;P(t)\\leq P(t_{\\text{obs}})} P(t)=p.\n$$\nHence the two-sided p-value is invariant under swapping the columns.\n\nIf the two-sided p-value is instead computed as $2\\min\\{P(A\\leq a),\\,P(A\\geq a)\\}$ using the one-sided hypergeometric tails, invariance still holds because the column swap interchanges the left and right tails while leaving the hypergeometric distribution unchanged; thus the minimum of the two tails, and its doubling (with any capping at $1$), remains unchanged.\n\nTherefore, the two-sided p-value from Fisher’s exact test does not change under a column swap, and the correct justification is that the hypergeometric probabilities and the induced probability ordering are preserved by the permutation of columns. Option C is always true, whereas A and D are false because the two-sided p-value is symmetric under odds-ratio inversion and the “more extreme” set is mapped bijectively with preserved probabilities; B’s rationale is incomplete, while C provides the correct probabilistic invariance.", "answer": "$$\\boxed{C}$$", "id": "1918000"}]}