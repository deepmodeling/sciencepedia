{"hands_on_practices": [{"introduction": "The first step in analyzing a potential linear relationship between two variables is to determine if there is statistically significant evidence that a relationship exists at all. This practice exercise guides you through the fundamental procedure of testing a hypothesis about the regression slope, $\\beta_1$. By calculating the t-statistic from raw summary data, you will gain a hands-on understanding of how we measure the strength of evidence against the null hypothesis of no effect ([@problem_id:1923256]).", "problem": "An agricultural research institute is investigating the effect of a new bio-stimulant on the yield of quinoa. In a controlled experiment, $n=20$ identical plots of land were treated with varying amounts of the bio-stimulant. A simple linear regression model, $Y = \\beta_0 + \\beta_1 x + \\epsilon$, is proposed to relate the quinoa yield, $Y$ (in kilograms per hectare), to the amount of bio-stimulant applied, $x$ (in liters per hectare). The random errors $\\epsilon$ are assumed to be independent and normally distributed with a mean of 0 and a constant variance $\\sigma^2$.\n\nThe researchers want to determine if there is evidence to suggest that the bio-stimulant has a positive effect on yield. To do this, they will conduct a hypothesis test on the slope of the regression line.\n\nFrom the experimental data, the following summary statistics were calculated:\n- $\\sum_{i=1}^{20} x_i = 100$\n- $\\sum_{i=1}^{20} y_i = 35000$\n- $\\sum_{i=1}^{20} x_i^2 = 620$\n- $\\sum_{i=1}^{20} y_i^2 = 61850000$\n- $\\sum_{i=1}^{20} x_i y_i = 181000$\n\nCalculate the value of the test statistic for testing the null hypothesis $H_0: \\beta_1 = 0$ against the alternative hypothesis $H_a: \\beta_1 > 0$. Round your final answer to three significant figures.", "solution": "We test $H_{0}: \\beta_{1}=0$ versus $H_{a}: \\beta_{1}>0$ using the $t$-statistic\n$$\nt=\\frac{\\hat{\\beta}_{1}-0}{\\operatorname{SE}(\\hat{\\beta}_{1})}, \\quad \\operatorname{SE}(\\hat{\\beta}_{1})=\\sqrt{\\frac{\\hat{\\sigma}^{2}}{S_{xx}}}, \\quad \\hat{\\sigma}^{2}=\\frac{\\text{SSE}}{n-2}.\n$$\nFor simple linear regression,\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}}, \\quad S_{xx}=\\sum x_{i}^{2}-\\frac{\\left(\\sum x_{i}\\right)^{2}}{n}, \\quad S_{yy}=\\sum y_{i}^{2}-\\frac{\\left(\\sum y_{i}\\right)^{2}}{n}, \\quad S_{xy}=\\sum x_{i}y_{i}-\\frac{\\left(\\sum x_{i}\\right)\\left(\\sum y_{i}\\right)}{n}.\n$$\nGiven $n=20$, $\\sum x_{i}=100$, $\\sum y_{i}=35000$, $\\sum x_{i}^{2}=620$, $\\sum y_{i}^{2}=61850000$, $\\sum x_{i}y_{i}=181000$, compute\n$$\nS_{xx}=620-\\frac{100^{2}}{20}=620-500=120,\n$$\n$$\nS_{yy}=61850000-\\frac{35000^{2}}{20}=61850000-61250000=600000,\n$$\n$$\nS_{xy}=181000-\\frac{(100)(35000)}{20}=181000-175000=6000.\n$$\nThen\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}}=\\frac{6000}{120}=50.\n$$\nThe error sum of squares is\n$$\n\\text{SSE}=S_{yy}-\\hat{\\beta}_{1}S_{xy}=600000-(50)(6000)=300000,\n$$\nso\n$$\n\\hat{\\sigma}^{2}=\\frac{\\text{SSE}}{n-2}=\\frac{300000}{18}=\\frac{50000}{3}.\n$$\nThe standard error of $\\hat{\\beta}_{1}$ is\n$$\n\\operatorname{SE}(\\hat{\\beta}_{1})=\\sqrt{\\frac{\\hat{\\sigma}^{2}}{S_{xx}}}=\\sqrt{\\frac{50000/3}{120}}=\\sqrt{\\frac{50000}{360}}=\\sqrt{\\frac{1250}{9}}.\n$$\nTherefore the test statistic is\n$$\nt=\\frac{50}{\\sqrt{1250/9}}=\\frac{50 \\times 3}{\\sqrt{1250}}=\\frac{150}{25\\sqrt{2}}=\\frac{6}{\\sqrt{2}}=3\\sqrt{2}\\approx 4.24.\n$$\nDegrees of freedom are $n-2=18$, and since $\\hat{\\beta}_{1}>0$, the one-sided test statistic is $t=3\\sqrt{2}$.", "answer": "$$\\boxed{4.24}$$", "id": "1923256"}, {"introduction": "Once we have evidence of a significant relationship, we often want to make predictions; however, a single point estimate is incomplete without a measure of its uncertainty. This exercise demonstrates how to construct a confidence interval for the *mean response*, providing a plausible range for the average outcome at a specific value of the predictor variable. This is a crucial skill for making reliable, data-driven forecasts ([@problem_id:1923200]).", "problem": "A university's data science team is analyzing the relationship between the usage of a new online tutoring platform and student performance in a challenging introductory physics course. They collect data from a random sample of 25 students. Let $Y$ be the final grade (a numerical score out of 100) in the course, and let $X$ be the average number of hours per week the student spent using the tutoring platform.\n\nThe team fits a simple linear regression model of the form $Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$, where the errors $\\epsilon_i$ are assumed to be independent and normally distributed with a mean of 0 and a constant variance $\\sigma^2$.\n\nFrom the sample of 25 students, the analysis yields the following summary statistics:\n- Estimated intercept: $\\hat{\\beta}_0 = 63.0$\n- Estimated slope: $\\hat{\\beta}_1 = 3.0$\n- Sample mean of weekly hours: $\\bar{x} = 4.0$ hours\n- Sum of squared deviations for weekly hours: $S_{xx} = \\sum_{i=1}^{25} (x_i - \\bar{x})^2 = 100.0 \\text{ hours}^2$\n- Standard error of the regression: $s_e = 5.0$ grade points\n\nUsing this information, construct a 95% confidence interval for the true mean final grade for the subpopulation of all students who spend exactly $x_0 = 5.0$ hours per week on the platform. The critical value from the t-distribution needed for this calculation is $t_{0.025, 23} = 2.069$.\n\nProvide the lower and upper bounds of the confidence interval, in that order. Round your final answers to four significant figures.", "solution": "We fit the simple linear regression model $Y_{i}=\\beta_{0}+\\beta_{1}X_{i}+\\epsilon_{i}$ with $\\epsilon_{i}\\sim \\mathcal{N}(0,\\sigma^{2})$ independently. The mean response at $x_{0}$ is $\\mu_{Y|X=x_{0}}=\\beta_{0}+\\beta_{1}x_{0}$, estimated by $\\hat{Y}(x_{0})=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}x_{0}$. For $x_{0}=5.0$, the point estimate is\n$$\n\\hat{Y}(5)=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}\\cdot 5=63.0+3.0\\cdot 5=78.0.\n$$\nThe standard error of the estimated mean response at $x_{0}$ is\n$$\n\\operatorname{SE}\\big(\\hat{Y}(x_{0})\\big)=s_{e}\\sqrt{\\frac{1}{n}+\\frac{(x_{0}-\\bar{x})^{2}}{S_{xx}}},\n$$\nwith $n=25$, $\\bar{x}=4.0$, $S_{xx}=100.0$, and $s_{e}=5.0$. Substituting these values for $x_{0}=5.0$ gives\n$$\n\\operatorname{SE}\\big(\\hat{Y}(5)\\big)=5.0\\sqrt{\\frac{1}{25}+\\frac{(5.0-4.0)^{2}}{100.0}}=5.0\\sqrt{0.04+0.01}=5.0\\sqrt{0.05}=\\frac{\\sqrt{5}}{2}.\n$$\nA two-sided $95\\%$ confidence interval for the mean response at $x_{0}$ is\n$$\n\\hat{Y}(x_{0})\\pm t_{0.025,\\,n-2}\\,\\operatorname{SE}\\big(\\hat{Y}(x_{0})\\big),\n$$\nwith $t_{0.025,\\,23}=2.069$. Thus,\n$$\n78.0\\pm 2.069\\cdot \\frac{\\sqrt{5}}{2}.\n$$\nComputing the margin,\n$$\n2.069\\cdot \\frac{\\sqrt{5}}{2}\\approx 2.3132123227,\n$$\nso the interval is approximately\n$$\n[78.0-2.3132123227,\\;78.0+2.3132123227]=[75.6867876773,\\;80.3132123227].\n$$\nRounding to four significant figures yields the lower and upper bounds $75.69$ and $80.31$.", "answer": "$$\\boxed{\\begin{pmatrix} 75.69 & 80.31 \\end{pmatrix}}$$", "id": "1923200"}, {"introduction": "Real-world models often involve multiple predictors, and our scientific questions can be more complex than simply testing one coefficient at a time. This advanced problem introduces the general F-test, a powerful tool for testing joint hypotheses involving multiple regression parameters simultaneously. Working through this example will equip you to answer nuanced questions about the combined effects and relationships between different variables in your model ([@problem_id:1923209]).", "problem": "An economist is investigating the price of a specific agricultural commodity. They propose a multiple linear regression model to explain the commodity's price based on several factors. The model is given by:\n\n$$P_i = \\beta_0 + \\beta_1 S_i + \\beta_2 D_i + \\beta_3 I_i + \\epsilon_i$$\n\nwhere for each observation $i$:\n- $P_i$ is the price of the commodity.\n- $S_i$ is a measure of the total supply.\n- $D_i$ is a measure of the total demand.\n- $I_i$ is an aggregate inflation index.\n- $\\epsilon_i$ are the error terms, assumed to be independent and identically distributed (i.i.d.) normal random variables with mean 0 and variance $\\sigma^2$.\n\nThe model is fitted using ordinary least squares (OLS) on a dataset of $n=54$ observations. The analysis yielded the following results for the full model:\n\nThe estimated coefficient vector is $\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\beta}_2, \\hat{\\beta}_3)^T = (10.5, -2.1, 3.2, 1.5)^T$.\n\nThe sum of squared errors for the full model is $SSE_F = 450.0$.\n\nIf $\\mathbf{X}$ is the design matrix for the model, the matrix $(\\mathbf{X}^T\\mathbf{X})^{-1}$ is given by:\n$$ (\\mathbf{X}^T\\mathbf{X})^{-1} = \\begin{pmatrix} 0.8 & -0.1 & -0.2 & 0.05 \\\\ -0.1 & 0.5 & 0.1 & -0.1 \\\\ -0.2 & 0.1 & 0.6 & -0.2 \\\\ 0.05 & -0.1 & -0.2 & 0.4 \\end{pmatrix} $$\n\nThe economist wishes to test a specific joint null hypothesis $H_0$ that makes two claims:\n1. The effect of supply is an equal and opposite reaction to the effect of demand.\n2. The effect of the inflation index is exactly 1.0.\n\nCalculate the value of the F-statistic for testing this joint null hypothesis. Round your final answer to three significant figures.", "solution": "We test the joint linear hypothesis using the general linear F-test. Define the restriction matrix and vector for\n$$H_{0}:\\ \\beta_{1}+\\beta_{2}=0,\\ \\ \\beta_{3}=1,$$\nwith parameter ordering $(\\beta_{0},\\beta_{1},\\beta_{2},\\beta_{3})$. Then\n$$\n\\mathbf{R}=\\begin{pmatrix}\n0 & 1 & 1 & 0\\\\\n0 & 0 & 0 & 1\n\\end{pmatrix},\\quad\n\\mathbf{r}=\\begin{pmatrix}\n0\\\\\n1\n\\end{pmatrix}.\n$$\nThe F-statistic is\n$$\nF=\\frac{(\\mathbf{R}\\hat{\\boldsymbol{\\beta}}-\\mathbf{r})^{T}\\left[\\mathbf{R}(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{R}^{T}\\right]^{-1}(\\mathbf{R}\\hat{\\boldsymbol{\\beta}}-\\mathbf{r})}{q\\,\\hat{\\sigma}^{2}},\n$$\nwhere $q=2$ is the number of restrictions and $\\hat{\\sigma}^{2}=SSE_{F}/(n-p)$ with $n=54$ and $p=4$.\n\nCompute the discrepancy vector:\n$$\n\\mathbf{d}=\\mathbf{R}\\hat{\\boldsymbol{\\beta}}-\\mathbf{r}\n=\\begin{pmatrix} \\hat{\\beta}_{1}+\\hat{\\beta}_{2} \\\\ \\hat{\\beta}_{3} \\end{pmatrix}-\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n=\\begin{pmatrix} -2.1+3.2 \\\\ 1.5 \\end{pmatrix}-\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n=\\begin{pmatrix} 1.1 \\\\ 0.5 \\end{pmatrix}.\n$$\nCompute the covariance matrix of $\\mathbf{R}\\hat{\\boldsymbol{\\beta}}$:\n$$\n\\mathbf{S}=\\mathbf{R}(\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{R}^{T}\n=\\begin{pmatrix}\n1.3 & -0.3\\\\\n-0.3 & 0.4\n\\end{pmatrix},\n$$\nusing the given $(\\mathbf{X}^{T}\\mathbf{X})^{-1}$. Its inverse is\n$$\n\\mathbf{S}^{-1}=\\frac{1}{0.52-0.09}\\begin{pmatrix} 0.4 & 0.3\\\\ 0.3 & 1.3 \\end{pmatrix}\n=\\frac{1}{0.43}\\begin{pmatrix} 0.4 & 0.3\\\\ 0.3 & 1.3 \\end{pmatrix}.\n$$\nForm the quadratic term:\n$$\nQ=\\mathbf{d}^{T}\\mathbf{S}^{-1}\\mathbf{d}\n=\\frac{1}{0.43}\\,\\mathbf{d}^{T}\\begin{pmatrix} 0.4 & 0.3\\\\ 0.3 & 1.3 \\end{pmatrix}\\mathbf{d}\n=\\frac{1}{0.43}\\,(1.1,\\,0.5)\\begin{pmatrix} 0.59\\\\ 0.98 \\end{pmatrix}\n=\\frac{1.139}{0.43}\\approx 2.648837.\n$$\nThe mean squared error from the full model is\n$$\n\\hat{\\sigma}^{2}=\\frac{SSE_{F}}{n-p}=\\frac{450}{54-4}=9.\n$$\nTherefore,\n$$\nF=\\frac{Q}{q\\,\\hat{\\sigma}^{2}}=\\frac{2.648837}{2\\times 9}\\approx 0.147158.\n$$\nRounded to three significant figures, the F-statistic is $0.147$.", "answer": "$$\\boxed{0.147}$$", "id": "1923209"}]}