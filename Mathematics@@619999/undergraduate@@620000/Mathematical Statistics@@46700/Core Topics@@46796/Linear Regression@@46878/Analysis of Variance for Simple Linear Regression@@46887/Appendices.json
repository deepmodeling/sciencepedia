{"hands_on_practices": [{"introduction": "The Analysis of Variance (ANOVA) framework provides a powerful method for evaluating the significance of a regression model. Its core principle is the partitioning of total variability in the response variable, measured by the Total Sum of Squares ($SST$), into a component explained by the regression model ($SSR$) and a component left unexplained, the residual error ($SSE$). This exercise will guide you through the fundamental mechanics of constructing an ANOVA table for simple linear regression, culminating in the calculation of the F-statistic, which is used to test if the model provides a better fit than a model with no predictor variables. [@problem_id:1895393]", "problem": "A data analyst at a university is investigating the relationship between the number of hours a student spends studying per week and their score on a standardized final exam. A simple linear regression model is proposed to describe this relationship, with study hours as the predictor variable and a student's exam score as the response variable. Data is collected from a random sample of 25 students.\n\nAfter fitting the model, an Analysis of Variance (ANOVA) is conducted to assess the model's significance. The analysis yields a Total Sum of Squares ($SST$) of 2480.0 and an Error Sum of Squares ($SSE$) of 455.0.\n\nBased on this information, calculate the F-statistic for the test of the overall significance of the regression model. Round your final answer to four significant figures.", "solution": "We have a simple linear regression with one predictor and an intercept. For this model:\n- Total degrees of freedom: $df_{T} = n - 1$.\n- Regression degrees of freedom: $df_{R} = 1$.\n- Error degrees of freedom: $df_{E} = n - 2$.\n\nGiven $n = 25$, we have $df_{R} = 1$ and $df_{E} = 25 - 2 = 23$.\n\nThe sums of squares satisfy $SST = SSR + SSE$, so the regression sum of squares is\n$$\nSSR = SST - SSE = 2480.0 - 455.0 = 2025.0.\n$$\n\nMean squares are defined as $MSR = \\frac{SSR}{df_{R}}$ and $MSE = \\frac{SSE}{df_{E}}$. Therefore,\n$$\nMSR = \\frac{2025.0}{1} = 2025.0, \\quad MSE = \\frac{455.0}{23}.\n$$\n\nThe $F$-statistic for testing overall significance is\n$$\nF = \\frac{MSR}{MSE} = \\frac{2025.0}{455.0/23} = \\frac{2025 \\times 23}{455} = \\frac{405 \\times 23}{91}.\n$$\nNumerically,\n$$\nF \\approx 102.362637\\ldots\n$$\nRounding to four significant figures gives $F \\approx 102.4$.", "answer": "$$\\boxed{102.4}$$", "id": "1895393"}, {"introduction": "To truly understand statistical concepts, it's often helpful to explore their behavior in extreme, idealized scenarios. This thought experiment considers a case of a perfect linear relationship where the regression line passes through every single data point, meaning the Sum of Squared Errors ($SSE$) is zero. By examining this hypothetical situation, you can build a deeper intuition for the coefficient of determination ($R^2$) and the sample correlation coefficient ($r$), and see precisely how they connect to the fundamental ANOVA identity. [@problem_id:1895411]", "problem": "In the context of a simple linear regression model, an Analysis of Variance (ANOVA) is often performed to partition the total variability in the response variable. The Total Sum of Squares (SST) is decomposed into the Regression Sum of Squares (SSR) and the Sum of Squared Errors (SSE), such that $SST = SSR + SSE$.\n\nConsider a specific simple linear regression analysis performed on a dataset where the calculated Sum of Squared Errors (SSE) is found to be exactly zero. This scenario implies a perfect fit of the regression line to the data points. Given this information, what must be the values of the coefficient of determination, denoted as $R^2$, and the absolute value of the sample correlation coefficient, denoted as $|r|$?\n\nSelect the correct pair of values from the options below.\n\nA. $R^2 = 1$ and $|r|=1$\n\nB. $R^2 = 0$ and $|r|=0$\n\nC. $R^2 = 1$ and $|r|=0$\n\nD. $R^2 = 0$ and $|r|=1$\n\nE. The values depend on the sample size and cannot be determined.", "solution": "In simple linear regression, the total variability in the response is decomposed as $SST = SSR + SSE$. The coefficient of determination is defined as\n$$\nR^{2} = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}.\n$$\nGiven $SSE = 0$ and assuming $SST > 0$ so that $R^{2}$ is well-defined, it follows that\n$$\nR^{2} = 1 - \\frac{0}{SST} = 1.\n$$\nFor simple linear regression, the identity $R^{2} = r^{2}$ holds, where $r$ is the sample correlation coefficient between the predictor and response. Therefore,\n$$\n|r| = \\sqrt{R^{2}} = 1.\n$$\nHence the correct option is $R^{2} = 1$ and $|r| = 1$.", "answer": "$$\\boxed{A}$$", "id": "1895411"}, {"introduction": "In simple linear regression, we can test the significance of the relationship between the predictor and response in two seemingly different ways: a t-test for the slope coefficient ($\\beta_1$) and an F-test for the overall model. This comprehensive exercise demonstrates that these two tests are fundamentally linked. Starting from a raw dataset, you will calculate both the t-statistic and the F-statistic and then verify the crucial identity $F = t^2$, solidifying your understanding of how these different statistical tools provide a consistent conclusion about the model's validity. [@problem_id:1895391]", "problem": "An undergraduate student in chemical engineering is investigating the relationship between the concentration of a novel catalyst and the rate of a chemical reaction. The student performs the reaction five times, each with a different catalyst concentration, and measures the resulting reaction rate. The collected data are as follows:\n\n-   Catalyst Concentration, $x$ (in mol/L): `{1.0, 2.0, 3.0, 4.0, 5.0}`\n-   Reaction Rate, $y$ (in mol/L/s): `{2.5, 4.0, 4.8, 6.0, 7.5}`\n\nThe student proposes a simple linear regression model of the form $Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$, where the errors $\\epsilon_i$ are assumed to be independent and normally distributed with mean 0 and constant variance $\\sigma^2$.\n\nYour task is to perform two key statistical tests on this model.\nFirst, calculate the t-statistic for testing the null hypothesis $H_0: \\beta_1 = 0$ against the two-sided alternative $H_a: \\beta_1 \\neq 0$.\nSecond, construct an Analysis of Variance (ANOVA) table for the regression and calculate the F-statistic.\n\nProvide the values of the t-statistic and the F-statistic. Report your answers, rounded to four significant figures, as a row matrix in the format `[t-statistic, F-statistic]`.", "solution": "We adopt the simple linear regression model $Y_{i}=\\beta_{0}+\\beta_{1}x_{i}+\\epsilon_{i}$ with independent, normally distributed errors of constant variance. For simple linear regression with intercept, the least-squares slope estimator and its standard error are\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}},\\quad S_{xx}=\\sum_{i=1}^{n}(x_{i}-\\bar{x})^{2},\\quad S_{xy}=\\sum_{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar{y}),\n$$\nand\n$$\n\\operatorname{SE}(\\hat{\\beta}_{1})=\\sqrt{\\frac{\\operatorname{MSE}}{S_{xx}}},\\quad \\operatorname{MSE}=\\frac{\\operatorname{SSE}}{n-2},\\quad \\operatorname{SSE}=S_{yy}-\\frac{S_{xy}^{2}}{S_{xx}},\\quad S_{yy}=\\sum_{i=1}^{n}(y_{i}-\\bar{y})^{2}.\n$$\nThe $t$-statistic for testing $H_{0}:\\beta_{1}=0$ against $H_{a}:\\beta_{1}\\neq 0$ is\n$$\nt=\\frac{\\hat{\\beta}_{1}}{\\operatorname{SE}(\\hat{\\beta}_{1})}.\n$$\n\nUsing the data $x=\\{1,2,3,4,5\\}$ and $y=\\{2.5,4.0,4.8,6.0,7.5\\}$ with $n=5$, compute the sample means $\\bar{x}=3$ and $\\bar{y}=\\frac{2.5+4.0+4.8+6.0+7.5}{5}=4.96$. Then\n$$\nS_{xx}=\\sum(x_{i}-\\bar{x})^{2}=10,\\quad S_{xy}=\\sum(x_{i}-\\bar{x})(y_{i}-\\bar{y})=12.\n$$\nHence the slope estimate is\n$$\n\\hat{\\beta}_{1}=\\frac{S_{xy}}{S_{xx}}=\\frac{12}{10}=1.2.\n$$\nNext, compute\n$$\nS_{yy}=\\sum(y_{i}-\\bar{y})^{2}=\\left(\\sum y_{i}^{2}\\right)-n\\bar{y}^{2}=(6.25+16+23.04+36+56.25)-5(4.96)^{2}=137.54-123.008=14.532.\n$$\nTherefore,\n$$\n\\operatorname{SSE}=S_{yy}-\\frac{S_{xy}^{2}}{S_{xx}}=14.532-\\frac{144}{10}=14.532-14.4=0.132,\\quad \\operatorname{MSE}=\\frac{\\operatorname{SSE}}{n-2}=\\frac{0.132}{3}=0.044.\n$$\nThe standard error of the slope is\n$$\n\\operatorname{SE}(\\hat{\\beta}_{1})=\\sqrt{\\frac{\\operatorname{MSE}}{S_{xx}}}=\\sqrt{\\frac{0.044}{10}}=\\sqrt{0.0044}=\\sqrt{\\frac{11}{2500}}=\\frac{\\sqrt{11}}{50}.\n$$\nThus the $t$-statistic is\n$$\nt=\\frac{\\hat{\\beta}_{1}}{\\operatorname{SE}(\\hat{\\beta}_{1})}=\\frac{1.2}{\\sqrt{11}/50}=\\frac{60}{\\sqrt{11}}\\approx 18.09\\quad(\\text{with }3\\text{ degrees of freedom}).\n$$\n\nFor the ANOVA, the regression sum of squares is\n$$\n\\operatorname{SSR}=\\frac{S_{xy}^{2}}{S_{xx}}=\\frac{144}{10}=14.4,\n$$\nwith $1$ degree of freedom, and the error sum of squares is $\\operatorname{SSE}=0.132$ with $n-2=3$ degrees of freedom. The mean squares are\n$$\n\\operatorname{MSR}=\\frac{\\operatorname{SSR}}{1}=14.4,\\quad \\operatorname{MSE}=\\frac{\\operatorname{SSE}}{3}=0.044.\n$$\nThe $F$-statistic for testing the overall regression is\n$$\nF=\\frac{\\operatorname{MSR}}{\\operatorname{MSE}}=\\frac{14.4}{0.044}=\\frac{3600}{11}\\approx 327.3.\n$$\nIn simple linear regression, $F=t^{2}$ holds, and indeed $\\left(\\frac{60}{\\sqrt{11}}\\right)^{2}=\\frac{3600}{11}$.\n\nRounded to four significant figures, the requested statistics are $t\\approx 18.09$ and $F\\approx 327.3$.", "answer": "$$\\boxed{[18.09, 327.3]}$$", "id": "1895391"}]}