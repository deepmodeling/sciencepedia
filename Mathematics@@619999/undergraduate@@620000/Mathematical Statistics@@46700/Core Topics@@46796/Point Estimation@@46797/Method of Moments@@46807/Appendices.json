{"hands_on_practices": [{"introduction": "This first exercise provides a direct application of the Method of Moments (MOM) in its simplest form. You will apply the core principle—equating the first theoretical moment to the sample mean—to estimate a single parameter for a Beta distribution within a materials science context. This practice solidifies the fundamental concept of MOM and how a single sample statistic can be used to infer properties of an entire population [@problem_id:1935335].", "problem": "A materials scientist is studying the porosity of a new type of ceramic. The porosity, defined as the fraction of void volume in the material, is a value between 0 and 1. The scientist models the porosity measurements with a Beta distribution. A random variable $X$ following a Beta distribution with shape parameters $\\alpha > 0$ and $\\beta > 0$ has a mean (expected value) given by $E[X] = \\frac{\\alpha}{\\alpha + \\beta}$.\n\nBased on the synthesis process, theoretical considerations suggest that the first shape parameter can be fixed at $\\alpha = 1$. The scientist then collects a small sample of porosity measurements from five different ceramic specimens, which are recorded as follows:\n$$ \\{0.18, 0.41, 0.25, 0.33, 0.29\\} $$\nAssuming these measurements are independent and identically distributed realizations from a Beta($1, \\beta$) distribution, calculate the estimate for the parameter $\\beta$ using the Method of Moments (MOM).\n\nProvide your answer as a single numerical value, rounded to three significant figures.", "solution": "For a Beta distribution with parameters $\\alpha>0$ and $\\beta>0$, the mean is $E[X]=\\frac{\\alpha}{\\alpha+\\beta}$. With $\\alpha=1$, this becomes\n$$\nE[X]=\\frac{1}{1+\\beta}.\n$$\nThe Method of Moments sets the sample mean $\\bar{x}$ equal to the theoretical mean:\n$$\n\\bar{x}=\\frac{1}{1+\\beta}.\n$$\nSolving for $\\beta$ gives\n$$\n1+\\beta=\\frac{1}{\\bar{x}}\\quad\\Rightarrow\\quad \\beta=\\frac{1}{\\bar{x}}-1=\\frac{1-\\bar{x}}{\\bar{x}}.\n$$\nFrom the data $\\{0.18,0.41,0.25,0.33,0.29\\}$, the sample mean is\n$$\n\\bar{x}=\\frac{0.18+0.41+0.25+0.33+0.29}{5}=\\frac{1.46}{5}=0.292.\n$$\nThus, the MOM estimate is\n$$\n\\hat{\\beta}=\\frac{1-0.292}{0.292}=\\frac{0.708}{0.292}\\approx 2.424657\\dots\n$$\nRounded to three significant figures, this is $2.42$.", "answer": "$$\\boxed{2.42}$$", "id": "1935335"}, {"introduction": "Building on the single-parameter case, this problem demonstrates how to handle models with multiple unknown parameters. You will derive estimators for both the location and scale parameters of a logistic distribution by setting up and solving a system of two equations based on the first two moments. This practice is crucial for learning how to leverage higher-order moments to capture more complex features of a distribution [@problem_id:1935311].", "problem": "In a study of neural response, the time delay $X$ for a neuron to fire after a specific external stimulus is modeled as a continuous random variable. A researcher posits that $X$ follows a logistic distribution, which is characterized by a location parameter $\\mu$ and a positive scale parameter $\\sigma$.\n\nFor a logistic distribution with these parameters, the following properties are known:\n- The theoretical mean (first raw moment) is $E[X] = \\mu$.\n- The theoretical variance is $Var(X) = \\frac{\\pi^2 \\sigma^2}{3}$.\n\nA random sample of $n$ response times, $X_1, X_2, \\ldots, X_n$, is observed. The first two sample moments are calculated from this data as:\n- First sample moment: $m_1 = \\frac{1}{n} \\sum_{i=1}^{n} X_i$\n- Second sample moment: $m_2 = \\frac{1}{n} \\sum_{i=1}^{n} X_i^2$\n\nUsing the Method of Moments (MOM), find the estimators for the parameters $\\mu$ and $\\sigma$, denoted by $\\hat{\\mu}$ and $\\hat{\\sigma}$ respectively. Express your estimators in terms of $m_1$ and $m_2$. Present your final answer as a row matrix of the form $\\begin{pmatrix} \\hat{\\mu} & \\hat{\\sigma} \\end{pmatrix}$.", "solution": "By the method of moments, equate the first two sample raw moments to the corresponding theoretical raw moments.\n\nThe theoretical first raw moment is the mean, given by $E[X]=\\mu$. Equating to the first sample moment $m_{1}$ gives\n$$\nm_{1}=\\mu \\quad \\Rightarrow \\quad \\hat{\\mu}=m_{1}.\n$$\nThe theoretical variance is $Var(X)=\\frac{\\pi^{2}\\sigma^{2}}{3}$. Therefore, the theoretical second raw moment is\n$$\nE[X^{2}]=Var(X)+\\left(E[X]\\right)^{2}=\\mu^{2}+\\frac{\\pi^{2}\\sigma^{2}}{3}.\n$$\nEquating this to the second sample moment $m_{2}$, and replacing the parameters by their MOM estimators, yields\n$$\nm_{2}=\\hat{\\mu}^{2}+\\frac{\\pi^{2}\\hat{\\sigma}^{2}}{3}.\n$$\nSubstituting $\\hat{\\mu}=m_{1}$ and solving for $\\hat{\\sigma}$ gives\n$$\n\\hat{\\sigma}^{2}=\\frac{3}{\\pi^{2}}\\left(m_{2}-m_{1}^{2}\\right),\n$$\nand since $\\sigma>0$, choose the positive root,\n$$\n\\hat{\\sigma}=\\sqrt{\\frac{3}{\\pi^{2}}\\left(m_{2}-m_{1}^{2}\\right)}.\n$$\nThus, the MOM estimators expressed in terms of $m_{1}$ and $m_{2}$ are $\\hat{\\mu}=m_{1}$ and $\\hat{\\sigma}=\\sqrt{\\frac{3}{\\pi^{2}}\\left(m_{2}-m_{1}^{2}\\right)}$.", "answer": "$$\\boxed{\\begin{pmatrix} m_{1} & \\sqrt{\\frac{3}{\\pi^{2}}\\left(m_{2}-m_{1}^{2}\\right)} \\end{pmatrix}}$$", "id": "1935311"}, {"introduction": "The practical utility of estimation often lies in evaluating performance metrics that are functions of a model's parameters. This exercise illustrates this by guiding you to estimate a specific probability derived from a Geometric distribution, rather than just the parameter itself. This highlights the invariance property of MOM estimators and their direct application in assessing system performance and risk [@problem_id:1948416].", "problem": "In a digital communication system, the number of consecutively corrupted data packets, $X$, received before a clean packet arrives is modeled by a random variable. This random variable follows a Geometric distribution with parameter $p \\in (0, 1)$, where $p$ is the probability of receiving a clean packet. The probability mass function (PMF) is given by $f(k; p) = P(X=k) = (1-p)^{k}p$ for $k = 0, 1, 2, \\dots$. An engineer observes a series of independent transmissions, recording the values $X_1, X_2, \\dots, X_n$, which constitute a random sample from this distribution.\n\nThe system is considered to be performing poorly if there are frequently long sequences of corrupted packets. A key performance metric is the probability of observing more than two corrupted packets before a clean one, i.e., $P(X > 2)$.\n\nBased on the random sample $X_1, X_2, \\dots, X_n$, determine the method of moments estimator (MOME) for this performance metric, $P(X > 2)$. Express your answer in terms of the sample mean, $\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$.", "solution": "The model is geometric with support $k \\in \\{0,1,2,\\dots\\}$ and PMF $f(k;p)=(1-p)^{k}p$. Its mean is\n$$\n\\mathbb{E}[X]=\\sum_{k=0}^{\\infty}k(1-p)^{k}p\n= p \\sum_{k=0}^{\\infty}k r^{k}, \\quad r=1-p,\n$$\nand using the identity $\\sum_{k=0}^{\\infty}k r^{k}=\\frac{r}{(1-r)^{2}}$ for $|r|<1$, we obtain\n$\n\\mathbb{E}[X]=p \\cdot \\frac{1-p}{p^{2}}=\\frac{1-p}{p}.\n$\nThe method of moments sets $\\bar{X}_{n}=\\mathbb{E}[X]=\\frac{1-p}{p}$, yielding\n$$\n\\bar{X}_{n}=\\frac{1}{p}-1 \\quad \\Longrightarrow \\quad \\frac{1}{p}=1+\\bar{X}_{n} \\quad \\Longrightarrow \\quad \\hat{p}_{\\text{MOM}}=\\frac{1}{1+\\bar{X}_{n}}.\n$$\nThe performance metric is\n$$\nP(X>2)=\\sum_{k=3}^{\\infty}(1-p)^{k}p=(1-p)^{3}\\sum_{t=0}^{\\infty}(1-p)^{t}p=(1-p)^{3}.\n$$\nThe method of moments estimator plugs in $\\hat{p}_{\\text{MOM}}$:\n$$\n\\widehat{P(X>2)}_{\\text{MOM}}=\\left(1-\\hat{p}_{\\text{MOM}}\\right)^{3}\n=\\left(1-\\frac{1}{1+\\bar{X}_{n}}\\right)^{3}\n=\\left(\\frac{\\bar{X}_{n}}{1+\\bar{X}_{n}}\\right)^{3}.\n$$", "answer": "$$\\boxed{\\left(\\frac{\\bar{X}_{n}}{1+\\bar{X}_{n}}\\right)^{3}}$$", "id": "1948416"}]}