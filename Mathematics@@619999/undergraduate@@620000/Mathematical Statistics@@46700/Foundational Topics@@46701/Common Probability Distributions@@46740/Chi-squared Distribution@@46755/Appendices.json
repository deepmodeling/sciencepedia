{"hands_on_practices": [{"introduction": "Before we can apply the chi-squared distribution, we must first understand its fundamental origin. This practice challenges you to think like a computational statistician and construct a chi-squared random variable from the ground up, using only standard normal random variables. Mastering this concept through a simulation algorithm [@problem_id:1903721] solidifies the definitional link between the normal and chi-squared distributions, a cornerstone of statistical theory.", "problem": "In the development of a custom statistical simulation library, a programmer is tasked with creating a function to generate random variates from a chi-squared distribution with $k$ degrees of freedom, denoted as $\\chi^2(k)$, where $k$ is a positive integer. The only available tool is a pre-existing function, `get_std_normal()`, which returns a single random number drawn from the standard normal distribution, $N(0, 1)$.\n\nThe programmer must design an algorithm that correctly produces a single random variate from the $\\chi^2(k)$ distribution by making one or more calls to `get_std_normal()`. Which of the following proposed algorithms correctly accomplishes this task?\n\nA. Initialize a variable `sum_of_squares` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, add $z^2$ to `sum_of_squares`. The final value of `sum_of_squares` is the result.\n\nB. Initialize a variable `sum_val` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, and add $z$ to `sum_val`. The final value of `sum_val` is the result.\n\nC. Initialize a variable `sum_val` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, and add $z$ to `sum_val`. The final result is `sum_val` squared.\n\nD. Call `get_std_normal()` exactly once to get a value $z$. The result is $k \\times z$.\n\nE. Initialize a variable `sum_of_squares` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, add $z^2$ to `sum_of_squares`. The final result is `sum_of_squares` divided by $k$.", "solution": "Let $Z_{1},\\dots,Z_{k}$ be independent standard normal random variables, each obtained by a call to get_std_normal(), so $Z_{i} \\sim N(0,1)$ and the $Z_{i}$ are independent. By the defining property of the chi-squared distribution, the sum of squares\n$$\nQ=\\sum_{i=1}^{k} Z_{i}^{2}\n$$\nhas the $\\chi^{2}(k)$ distribution. This can be verified, for example, via the moment generating function: for $t<\\frac{1}{2}$, the mgf of $Z_{i}^{2}$ is $(1-2t)^{-1/2}$, and by independence\n$$\nM_{Q}(t)=\\prod_{i=1}^{k}(1-2t)^{-1/2}=(1-2t)^{-k/2},\n$$\nwhich is the mgf of $\\chi^{2}(k)$. Therefore, computing the sum of the squares of $k$ independent standard normals is exactly the correct algorithm.\n\nNow assess each proposed algorithm:\n\nA. This computes $Q=\\sum_{i=1}^{k} Z_{i}^{2}$, which by definition has distribution $\\chi^{2}(k)$. Hence A is correct.\n\nB. This computes $S=\\sum_{i=1}^{k} Z_{i}$, which is normal with $S \\sim N(0,k)$, not chi-squared. Hence B is incorrect.\n\nC. This computes $S^{2}$ where $S=\\sum_{i=1}^{k} Z_{i} \\sim N(0,k)$. Then $S/\\sqrt{k} \\sim N(0,1)$ and $S^{2}=k\\,(S/\\sqrt{k})^{2}$, so $S^{2}$ has the distribution $k \\cdot \\chi^{2}(1)$, which is not $\\chi^{2}(k)$ unless $k=1$. Hence C is incorrect in general.\n\nD. This computes $k Z$ for a single $Z \\sim N(0,1)$, yielding $N(0,k^{2})$, not chi-squared. Hence D is incorrect.\n\nE. This computes $\\frac{1}{k}\\sum_{i=1}^{k} Z_{i}^{2}=\\frac{1}{k}\\,\\chi^{2}(k)$, a scaled chi-squared variable, not $\\chi^{2}(k)$. Hence E is incorrect.\n\nTherefore, the only correct algorithm is A.", "answer": "$$\\boxed{A}$$", "id": "1903721"}, {"introduction": "With the constructive definition in hand, we can now explore the properties of the chi-squared distribution through direct calculation. This exercise [@problem_id:1903718] presents a scenario where the sum of two squared standard normal variables, representing noise power, follows a $\\chi^2(2)$ distribution. By calculating a probability, you will not only apply the definition but also uncover the special relationship between the chi-squared distribution with two degrees of freedom and the exponential distribution.", "problem": "In a simplified model analyzing noise in a radar system, the signal's quadrature components are represented by two independent random variables, $X$ and $Y$. Both $X$ and $Y$ follow a standard normal distribution, meaning each has a mean of 0 and a variance of 1. The instantaneous power of the noise signal is defined by the random variable $W = X^2 + Y^2$.\n\nA detection algorithm flags an event if the instantaneous noise power $W$ exceeds a certain threshold. Calculate the probability that the noise power $W$ is greater than 3.5. Provide your answer as a single real number, rounded to four significant figures.", "solution": "Let $X \\sim \\mathcal{N}(0,1)$ and $Y \\sim \\mathcal{N}(0,1)$ be independent. Then the sum of squares $W = X^{2} + Y^{2}$ has a chi-square distribution with $2$ degrees of freedom:\n$$\nW \\sim \\chi^{2}(2).\n$$\nThe probability density function of $\\chi^{2}(2)$ is\n$$\nf_{W}(w) = \\frac{1}{2^{1}\\Gamma(1)} w^{1-1} \\exp\\!\\left(-\\frac{w}{2}\\right) = \\frac{1}{2}\\exp\\!\\left(-\\frac{w}{2}\\right), \\quad w \\geq 0.\n$$\nThe tail probability for $t \\geq 0$ is\n$$\n\\mathbb{P}(W > t) = \\int_{t}^{\\infty} \\frac{1}{2}\\exp\\!\\left(-\\frac{w}{2}\\right) \\, dw.\n$$\nMake the substitution $u = \\frac{w}{2}$ so that $dw = 2\\,du$ and when $w = t$, $u = \\frac{t}{2}$. Then\n$$\n\\mathbb{P}(W > t) = \\int_{t/2}^{\\infty} \\exp(-u)\\,du = \\exp\\!\\left(-\\frac{t}{2}\\right).\n$$\nFor $t = 3.5$,\n$$\n\\mathbb{P}(W > 3.5) = \\exp\\!\\left(-\\frac{3.5}{2}\\right) = \\exp(-1.75).\n$$\nNumerically, $\\exp(-1.75) \\approx 0.1738$ when rounded to four significant figures.", "answer": "$$\\boxed{0.1738}$$", "id": "1903718"}, {"introduction": "The true power of the chi-squared distribution lies in its application to statistical inference, particularly in hypothesis testing. This problem [@problem_id:1903706] places you in the role of a scientist testing a genetic model using a chi-squared goodness-of-fit test. You will practice the crucial skill of using a statistical table to translate a calculated test statistic into a p-value, bridging the gap between theoretical distributions and practical data analysis.", "problem": "A team of agronomists is studying the inheritance of flower color in a newly discovered plant species. According to their genetic model, cross-breeding a specific pair of parent plants should produce offspring with four distinct flower colors (Red, Blue, Yellow, White) in a fixed theoretical ratio. To test this model, they conduct an experiment and count the number of offspring in each color category.\n\nThey use the chi-squared goodness-of-fit test. The test statistic, denoted by $X$, is calculated from the observed and expected counts. Under the assumption that their genetic model is correct (the null hypothesis), this test statistic $X$ follows a chi-squared distribution. The number of degrees of freedom ($df$) for this test is given by $k - 1$, where $k$ is the number of categories (in this case, the four flower colors).\n\nAfter completing their experiment, the agronomists calculate a test statistic value of $X_{\\text{obs}} = 6.251$. In statistical testing, the p-value is the probability of obtaining a test result at least as extreme as the one that was actually observed, assuming the null hypothesis is true. For this test, a more extreme result corresponds to a larger value of the test statistic.\n\nUsing the provided table of cumulative probabilities for the chi-squared distribution, $P(X \\le \\chi^2)$, determine the probability that a random variable following the appropriate chi-squared distribution is greater than the observed test statistic of $6.251$. Express your answer as a decimal.\n\n**Table of Cumulative Probabilities for the Chi-Squared Distribution**\nThe table below gives values of $\\chi^2$ for selected degrees of freedom ($df$) and cumulative probabilities $p$. The entry for a given row and column is the value $\\chi^2$ such that $P(X \\le \\chi^2) = p$.\n\n| | **Cumulative Probability (p)** | | | |\n| :---: | :---: | :---: | :---: | :---: |\n| **df** | **0.05** | **0.10** | **0.90** | **0.95** |\n| **2** | 0.103 | 0.211 | 4.605 | 5.991 |\n| **3** | 0.352 | 0.584 | 6.251 | 7.815 |\n| **4** | 0.711 | 1.064 | 7.779 | 9.488 |", "solution": "We have $k=4$ color categories, so the chi-squared goodness-of-fit test has degrees of freedom $df=k-1=4-1=3$. The observed test statistic is $X_{\\text{obs}}=6.251$. We want the probability $P(X>6.251)$ where $X\\sim\\chi^{2}(3)$.\n\nFrom the provided table for $df=3$, the entry at cumulative probability $p=0.90$ is $\\chi^{2}=6.251$. By definition of the table, this means $P(X\\leq 6.251)=0.90$.\n\nTherefore,\n$$\nP(X>6.251)=1-P(X\\leq 6.251)=1-0.90=0.10.\n$$", "answer": "$$\\boxed{0.10}$$", "id": "1903706"}]}