{"hands_on_practices": [{"introduction": "A key feature of the log-normal distribution is its intimate relationship with the normal distribution. This connection allows us to leverage the extensive tools available for normal variables, particularly the standard normal distribution, to solve problems involving log-normal variables. This first exercise [@problem_id:1401199] is a foundational practice in making that crucial translation, showing how to convert a probability question about a log-normal variable into an equivalent one for a standard normal variable, a skill essential for practical calculations.", "problem": "The distribution of asset prices in financial modeling is often better described by a log-normal distribution rather than a normal distribution, as asset prices cannot be negative. Let the price of a particular stock at a future time be represented by the random variable $X$. It is assumed that $X$ follows a log-normal distribution with parameters $\\mu$ and $\\sigma^2$, denoted as $X \\sim \\text{Log-Normal}(\\mu, \\sigma^2)$. By definition, this implies that the natural logarithm of the stock price, $Y = \\ln(X)$, follows a normal distribution with mean $\\mu$ and variance $\\sigma^2$.\n\nA financial analyst wants to calculate the probability that the stock price will not exceed a certain target price $k$, where $k$ is a positive constant. This probability is $P(X \\le k)$. For computational purposes, it is standard practice to convert this probability into an equivalent statement involving a standard normal random variable $Z$, which has a mean of 0 and a variance of 1.\n\nThe probability $P(X \\le k)$ can be rewritten in the form $P(Z \\le c)$. Determine the expression for the constant $c$ in terms of the parameters $\\mu$, $\\sigma$, and $k$.", "solution": "Let $X \\sim \\text{Log-Normal}(\\mu,\\sigma^{2})$, so $Y=\\ln(X)$ satisfies $Y \\sim \\mathcal{N}(\\mu,\\sigma^{2})$. For a positive constant $k$, the event $\\{X \\le k\\}$ is equivalent to $\\{\\ln(X) \\le \\ln(k)\\}$, hence\n$$\nP(X \\le k)=P(\\ln(X) \\le \\ln(k))=P(Y \\le \\ln(k)).\n$$\nTo express this in terms of a standard normal random variable, define $Z=\\frac{Y-\\mu}{\\sigma}$, which implies $Z \\sim \\mathcal{N}(0,1)$. Then\n$$\nP(Y \\le \\ln(k))=P\\!\\left(\\frac{Y-\\mu}{\\sigma} \\le \\frac{\\ln(k)-\\mu}{\\sigma}\\right)=P\\!\\left(Z \\le \\frac{\\ln(k)-\\mu}{\\sigma}\\right).\n$$\nTherefore, the constant $c$ satisfying $P(X \\le k)=P(Z \\le c)$ is\n$$\nc=\\frac{\\ln(k)-\\mu}{\\sigma}.\n$$", "answer": "$$\\boxed{\\frac{\\ln(k)-\\mu}{\\sigma}}$$", "id": "1401199"}, {"introduction": "In many real-world modeling scenarios, we may have estimates for macroscopic properties like the mean and variance, but not the underlying distribution parameters. This practice [@problem_id:1401198] bridges that gap by demonstrating how to work backward from the known mean $E[X]$ and variance $\\text{Var}(X)$ of a log-normal distribution to determine the parameters $\\mu$ and $\\sigma^2$ of the associated normal distribution. This is a practical application of the method of moments and is vital for fitting log-normal models to empirical data.", "problem": "A financial analyst is modeling the price of a speculative digital asset one year from now. The price, denoted by the random variable $X$, is assumed to follow a log-normal distribution. This means that the natural logarithm of the price, $Y = \\ln(X)$, follows a normal distribution with mean $\\mu$ and standard deviation $\\sigma$. Based on market analysis, the expected price is estimated to be $E[X] = 200$ dollars, and the variance of the price is estimated to be $\\text{Var}(X) = 90000 \\text{ dollars}^2$.\n\nFor reference, the mean and variance of a log-normal random variable $X$ with underlying normal parameters $\\mu$ and $\\sigma$ are given by the formulas:\n$$E[X] = \\exp\\left(\\mu + \\frac{\\sigma^2}{2}\\right)$$\n$$\\text{Var}(X) = \\left(\\exp(\\sigma^2) - 1\\right) \\exp\\left(2\\mu + \\sigma^2\\right)$$\n\nUsing the given information, determine the value of the parameter $\\mu$ of the underlying normal distribution. Round your final answer to four significant figures.", "solution": "Let $m = E[X]$ and $v = \\text{Var}(X)$. For a log-normal $X$, the given formulas are\n$$\nm = \\exp\\left(\\mu + \\frac{\\sigma^{2}}{2}\\right), \\quad\nv = \\left(\\exp(\\sigma^{2}) - 1\\right)\\exp\\left(2\\mu + \\sigma^{2}\\right).\n$$\nFirst, note that\n$$\nm^{2} = \\exp\\left(2\\mu + \\sigma^{2}\\right).\n$$\nTherefore,\n$$\n\\frac{v}{m^{2}} = \\exp(\\sigma^{2}) - 1 \\quad \\Longrightarrow \\quad \\exp(\\sigma^{2}) = 1 + \\frac{v}{m^{2}} \\quad \\Longrightarrow \\quad \\sigma^{2} = \\ln\\left(1 + \\frac{v}{m^{2}}\\right).\n$$\nGiven $m = 200$ and $v = 90000$, we compute\n$$\n\\frac{v}{m^{2}} = \\frac{90000}{200^{2}} = \\frac{90000}{40000} = 2.25,\n$$\nso\n$$\n\\sigma^{2} = \\ln(1 + 2.25) = \\ln(3.25).\n$$\nFrom the mean formula,\n$$\nm = \\exp\\left(\\mu + \\frac{\\sigma^{2}}{2}\\right) \\quad \\Longrightarrow \\quad \\ln(m) = \\mu + \\frac{\\sigma^{2}}{2} \\quad \\Longrightarrow \\quad \\mu = \\ln(m) - \\frac{\\sigma^{2}}{2}.\n$$\nSubstituting $m = 200$ and $\\sigma^{2} = \\ln(3.25)$,\n$$\n\\mu = \\ln(200) - \\frac{1}{2}\\ln(3.25).\n$$\nNumerically,\n$$\n\\ln(3.25) \\approx 1.178654996, \\quad \\frac{1}{2}\\ln(3.25) \\approx 0.589327498, \\quad \\ln(200) \\approx 5.298317367,\n$$\nhence\n$$\n\\mu \\approx 5.298317367 - 0.589327498 = 4.708989868 \\approx 4.709 \\text{ (to four significant figures)}.\n$$", "answer": "$$\\boxed{4.709}$$", "id": "1401198"}, {"introduction": "Moving beyond estimation from summary statistics, we often need to determine model parameters directly from a sample of raw data. This exercise [@problem_id:1401201] introduces one of the most powerful and fundamental techniques in statistical inference: Maximum Likelihood Estimation (MLE). By deriving the MLEs for the log-normal parameters $\\mu$ and $\\sigma^2$, you will learn how to find the parameter values that make your observed data most probable, a cornerstone of modern data analysis.", "problem": "A set of $n$ measurements, represented by the random variables $X_1, X_2, \\dots, X_n$, are considered to be independent and identically distributed (i.i.d.). These measurements are modeled by a log-normal distribution.\n\nA random variable $X$ follows a log-normal distribution with parameters $\\mu$ and $\\sigma^2$ if its natural logarithm, $\\ln(X)$, is normally distributed with mean $\\mu$ and variance $\\sigma^2$. The Probability Density Function (PDF) for $X$ is given by:\n$$\nf(x; \\mu, \\sigma^2) = \\frac{1}{x \\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(x) - \\mu)^2}{2\\sigma^2}\\right)\n$$\nfor $x > 0$, $\\mu \\in \\mathbb{R}$, and $\\sigma > 0$.\n\nGiven a set of observed sample data $x_1, x_2, \\dots, x_n$, find the maximum likelihood estimators (MLEs) for the parameters $\\mu$ and $\\sigma^2$, denoted as $\\hat{\\mu}$ and $\\hat{\\sigma}^2$, respectively. Express your final answers for $\\hat{\\mu}$ and $\\hat{\\sigma}^2$ in terms of the sample observations.", "solution": "Let $X_{1},\\dots,X_{n}$ be i.i.d. with the log-normal density\n$$\nf(x;\\mu,\\sigma^{2})=\\frac{1}{x\\sigma\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{(\\ln(x)-\\mu)^{2}}{2\\sigma^{2}}\\right),\\quad x0,\\ \\mu\\in\\mathbb{R},\\ \\sigma0.\n$$\nThe likelihood for observations $x_{1},\\dots,x_{n}$ is\n$$\nL(\\mu,\\sigma^{2})=\\prod_{i=1}^{n}\\frac{1}{x_{i}\\sigma\\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{(\\ln(x_{i})-\\mu)^{2}}{2\\sigma^{2}}\\right).\n$$\nThe log-likelihood is\n$$\n\\ell(\\mu,\\sigma^{2})=\\ln L(\\mu,\\sigma^{2})=-n\\ln\\sigma-\\sum_{i=1}^{n}\\ln(x_{i})-\\frac{n}{2}\\ln(2\\pi)-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{n}\\left(\\ln(x_{i})-\\mu\\right)^{2}.\n$$\nEquivalently, using $\\ln\\sigma=\\frac{1}{2}\\ln(\\sigma^{2})$,\n$$\n\\ell(\\mu,\\sigma^{2})=-\\frac{n}{2}\\ln(\\sigma^{2})-\\sum_{i=1}^{n}\\ln(x_{i})-\\frac{n}{2}\\ln(2\\pi)-\\frac{1}{2\\sigma^{2}}\\sum_{i=1}^{n}\\left(\\ln(x_{i})-\\mu\\right)^{2}.\n$$\nDifferentiate with respect to $\\mu$:\n$$\n\\frac{\\partial \\ell}{\\partial \\mu}=-\\frac{1}{2\\sigma^{2}}\\cdot 2\\sum_{i=1}^{n}\\left(\\ln(x_{i})-\\mu\\right)(-1)=\\frac{1}{\\sigma^{2}}\\sum_{i=1}^{n}\\left(\\ln(x_{i})-\\mu\\right).\n$$\nSet to zero and solve:\n$$\n\\sum_{i=1}^{n}\\ln(x_{i})-n\\mu=0\\quad\\Rightarrow\\quad \\hat{\\mu}=\\frac{1}{n}\\sum_{i=1}^{n}\\ln(x_{i}).\n$$\nThe second derivative $\\partial^{2}\\ell/\\partial\\mu^{2}=-n/\\sigma^{2}0$ confirms a maximum in $\\mu$.\n\nNow differentiate with respect to $\\sigma^{2}$. Let $S(\\mu)=\\sum_{i=1}^{n}(\\ln(x_{i})-\\mu)^{2}$. Then\n$$\n\\ell(\\mu,\\sigma^{2})=-\\frac{n}{2}\\ln(\\sigma^{2})-\\sum_{i=1}^{n}\\ln(x_{i})-\\frac{n}{2}\\ln(2\\pi)-\\frac{S(\\mu)}{2\\sigma^{2}},\n$$\nso\n$$\n\\frac{\\partial \\ell}{\\partial \\sigma^{2}}=-\\frac{n}{2}\\frac{1}{\\sigma^{2}}+\\frac{S(\\mu)}{2}\\frac{1}{\\sigma^{4}}.\n$$\nSet to zero:\n$$\n-\\frac{n}{2}\\frac{1}{\\sigma^{2}}+\\frac{S(\\mu)}{2}\\frac{1}{\\sigma^{4}}=0\\ \\Longrightarrow\\ -n\\sigma^{2}+S(\\mu)=0\\ \\Longrightarrow\\ \\hat{\\sigma}^{2}=\\frac{S(\\hat{\\mu})}{n}.\n$$\nSubstitute $\\hat{\\mu}$:\n$$\n\\hat{\\sigma}^{2}=\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\ln(x_{i})-\\frac{1}{n}\\sum_{j=1}^{n}\\ln(x_{j})\\right)^{2}.\n$$\nThe second derivative test in terms of $t=\\sigma^{2}$ gives $\\ell''(t)=(n/2)t^{-2}-S(\\mu)t^{-3}$, which at $t=\\hat{\\sigma}^{2}$ with $S(\\hat{\\mu})=n\\hat{\\sigma}^{2}$ yields $\\ell''(\\hat{\\sigma}^{2})=-(n/2)\\hat{\\sigma}^{-4}0$, confirming a maximum.\n\nTherefore, the MLEs are the sample mean and (uncorrected) sample variance of the transformed data $\\ln(x_{i})$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{n}\\sum_{i=1}^{n}\\ln(x_{i})  \\frac{1}{n}\\sum_{i=1}^{n}\\left(\\ln(x_{i})-\\frac{1}{n}\\sum_{j=1}^{n}\\ln(x_{j})\\right)^{2}\\end{pmatrix}}$$", "id": "1401201"}]}