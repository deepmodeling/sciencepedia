{"hands_on_practices": [{"introduction": "We begin our practice by exploring one of the most fundamental concepts in probability: the expected value. This exercise demonstrates how to calculate the expectation for simple discrete uniform distributions and introduces the powerful property of linearity of expectation. By working through a scenario involving a cryptographic key score, you'll gain hands-on experience in calculating the average outcome of a process composed of multiple independent random parts.", "problem": "In a simplified model for generating a cryptographic key, the key's total security score is determined by two independently generated integer components, Component A and Component B. Component A is an integer selected uniformly at random from the set $\\{1, 2\\}$. Component B is an integer selected uniformly at random from the set $\\{1, 2, 3\\}$. The total security score is the sum of the values of the two components. Calculate the expected total security score.", "solution": "Let $A$ be uniformly distributed over $\\{1,2\\}$ and $B$ be uniformly distributed over $\\{1,2,3\\}$, independent of $A$. The total score is $T=A+B$.\n\nUsing linearity of expectation, which does not require independence,\n$$\n\\mathbb{E}[T]=\\mathbb{E}[A]+\\mathbb{E}[B].\n$$\n\nCompute each expectation from the definitions:\n$$\n\\mathbb{E}[A]=\\sum_{a\\in\\{1,2\\}} a\\,\\mathbb{P}(A=a)=1\\cdot \\frac{1}{2}+2\\cdot \\frac{1}{2}=\\frac{1+2}{2}=\\frac{3}{2},\n$$\n$$\n\\mathbb{E}[B]=\\sum_{b\\in\\{1,2,3\\}} b\\,\\mathbb{P}(B=b)=1\\cdot \\frac{1}{3}+2\\cdot \\frac{1}{3}+3\\cdot \\frac{1}{3}=\\frac{1+2+3}{3}=\\frac{6}{3}=2.\n$$\n\nTherefore,\n$$\n\\mathbb{E}[T]=\\frac{3}{2}+2=\\frac{7}{2}.\n$$", "answer": "$$\\boxed{\\frac{7}{2}}$$", "id": "1913774"}, {"introduction": "Probabilistic models become truly powerful when they can adapt to new information. This next practice delves into the concept of conditional probability, showing how our assessment of an outcome's likelihood changes once we know a related event has occurred. The problem uses a computer simulation model to illustrate how the probability space is redefined by a filtering condition, revealing that the resulting conditional distribution is itself uniform on a new, smaller set.", "problem": "In a computer simulation, a random integer $X$ is generated. The process ensures that $X$ follows a discrete uniform distribution on the set of integers $\\{1, 2, \\dots, N\\}$, where $N$ is a fixed positive integer. A subsequent step in the simulation filters these results, keeping only the integers that are less than or equal to a certain threshold $m$, where $m$ is a positive integer such that $1 \\le m < N$.\n\nConsider a specific integer outcome $k$ such that $1 \\le k \\le m$. We are interested in quantifying how the knowledge from the filtering step alters the likelihood of observing this specific outcome $k$.\n\nYour task is to find a symbolic expression for the ratio of the conditional probability of observing the outcome $k$ given the filtering condition, to the original unconditional probability of observing $k$. Specifically, determine the value of the ratio $\\frac{P(X=k | X \\le m)}{P(X=k)}$. Express your answer in terms of $N$ and $m$.", "solution": "Let $X$ be discrete uniform on $\\{1,2,\\dots,N\\}$. Then for any $k \\in \\{1,\\dots,N\\}$,\n$$\nP(X=k)=\\frac{1}{N}.\n$$\nLet $A=\\{X=k\\}$ and $B=\\{X \\le m\\}$ with $1 \\le k \\le m < N$. Since $k \\le m$, we have $A \\subseteq B$. By the definition of conditional probability,\n$$\nP(X=k \\mid X \\le m)=\\frac{P(A \\cap B)}{P(B)}=\\frac{P(A)}{P(B)}.\n$$\nCompute $P(B)$ using uniformity:\n$$\nP(X \\le m)=\\sum_{j=1}^{m}P(X=j)=\\sum_{j=1}^{m}\\frac{1}{N}=\\frac{m}{N}.\n$$\nThus,\n$$\nP(X=k \\mid X \\le m)=\\frac{\\frac{1}{N}}{\\frac{m}{N}}=\\frac{1}{m}.\n$$\nThe required ratio is\n$$\n\\frac{P(X=k \\mid X \\le m)}{P(X=k)}=\\frac{\\frac{1}{m}}{\\frac{1}{N}}=\\frac{N}{m}.\n$$\nEquivalently, since $A \\subseteq B$,\n$$\n\\frac{P(X=k \\mid X \\le m)}{P(X=k)}=\\frac{P(A)/P(B)}{P(A)}=\\frac{1}{P(B)}=\\frac{N}{m}.\n$$", "answer": "$$\\boxed{\\frac{N}{m}}$$", "id": "1913769"}, {"introduction": "Our final practice takes a significant step from theoretical probability to practical statistical inference. Here, we tackle a common real-world problem: estimating an unknown parameter of a distribution based on observed data. By analyzing a sample of captured network security keys, you will learn to apply the method of Maximum Likelihood Estimation (MLE) to determine the most likely size of the key space, a crucial task in system analysis and cryptography.", "problem": "A new security protocol for a Wireless Sensor Network (WSN) generates session keys for communication. For a particular network configuration, all keys are integers drawn independently and uniformly from the set $\\{1, 2, \\ldots, S\\}$, where the maximum possible key value $S$ is an unknown, fixed integer parameter.\nA network analyst captures a small sample of five session keys. The captured keys, in the order they were observed, are $(34, 117, 82, 250, 59)$.\nAn important step in analyzing the protocol's strength is to estimate the size of the key space. A common initial approach is to use the maximum likelihood estimate for the parameter $S$ based on the observed sample. Assuming the true value of $S$ is equal to this maximum likelihood estimate, what is the probability of observing this specific sequence of five keys? Express your answer in scientific notation, rounded to three significant figures.", "solution": "Let $X_{1},\\ldots,X_{n}$ be independent and identically distributed with $X_{i} \\sim \\text{Uniform}\\{1,2,\\ldots,S\\}$, where $S$ is an unknown positive integer and $n=5$. For observed values $x_{1},\\ldots,x_{n}$, the joint probability mass function is\n$$\nP(X_{1}=x_{1},\\ldots,X_{n}=x_{n}\\,|\\,S)=\\prod_{i=1}^{n}\\frac{1}{S}\\,\\mathbf{1}\\{1 \\leq x_{i} \\leq S\\}\n=\\begin{cases}\nS^{-n}, & S \\geq m,\\\\\n0, & S<m,\n\\end{cases}\n$$\nwhere $m=\\max\\{x_{1},\\ldots,x_{n}\\}$. Thus, the likelihood is $L(S)=S^{-n}$ for $S \\geq m$ and $L(S)=0$ otherwise. Since $S^{-n}$ is strictly decreasing in $S$ for $S \\geq m$, the maximum likelihood estimator is $\\hat{S}=m$.\n\nFor the observed sequence $(34,117,82,250,59)$, we have $m=250$, so $\\hat{S}=250$. Assuming the true parameter equals this MLE, i.e., $S=250$, the probability of observing this specific ordered sequence is\n$$\nP=\\left(\\frac{1}{250}\\right)^{5}=\\frac{1}{250^{5}}.\n$$\nCompute $250^{5}$ by writing $250=25 \\cdot 10$, giving\n$$\n250^{5}=(25 \\cdot 10)^{5}=25^{5}\\cdot 10^{5}.\n$$\nSince $25^{5}=9{,}765{,}625$, it follows that\n$$\n250^{5}=9{,}765{,}625 \\times 10^{5}=9.765625 \\times 10^{11}.\n$$\nTherefore,\n$$\nP=\\frac{1}{9.765625 \\times 10^{11}}=1.024 \\times 10^{-12}.\n$$\nRounding to three significant figures gives $1.02 \\times 10^{-12}$.", "answer": "$$\\boxed{1.02 \\times 10^{-12}}$$", "id": "1913791"}]}