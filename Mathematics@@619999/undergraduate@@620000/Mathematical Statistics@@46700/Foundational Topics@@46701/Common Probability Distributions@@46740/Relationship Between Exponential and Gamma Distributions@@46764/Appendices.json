{"hands_on_practices": [{"introduction": "Our first practice grounds the theory in a familiar scenario: waiting for a bus. We will explore how the total waiting time for a series of events is constructed from individual, exponentially distributed inter-arrival times. By calculating the standard deviation of this total time, you will gain hands-on experience with how the moments of a Gamma distribution relate directly to the parameters of its underlying exponential components [@problem_id:1950915].", "problem": "The time intervals, in minutes, between consecutive arrivals of a city bus at a specific stop are modeled as independent and identically distributed exponential random variables. The expected time between any two consecutive arrivals is 10 minutes. A statistician begins observing the stop at time $t=0$, just as one bus is departing. What is the standard deviation of the waiting time until the 16th bus arrives? Provide your answer in minutes.", "solution": "Let $X_{1}, X_{2}, \\ldots, X_{16}$ be the i.i.d. interarrival times, each exponentially distributed with rate $\\lambda$ and mean $E[X_{i}] = \\frac{1}{\\lambda} = 10$. Hence $\\lambda = \\frac{1}{10}$ per minute. The waiting time until the 16th bus arrives is the sum\n$$\nT_{16} = \\sum_{i=1}^{16} X_{i}.\n$$\nBy independence and the variance of an exponential random variable, $\\operatorname{Var}(X_{i}) = \\frac{1}{\\lambda^{2}}$, we have\n$$\n\\operatorname{Var}(T_{16}) = \\sum_{i=1}^{16} \\operatorname{Var}(X_{i}) = \\frac{16}{\\lambda^{2}}.\n$$\nTherefore, the standard deviation is\n$$\n\\sigma_{T_{16}} = \\sqrt{\\operatorname{Var}(T_{16})} = \\sqrt{\\frac{16}{\\lambda^{2}}} = \\frac{4}{\\lambda}.\n$$\nSubstituting $\\lambda = \\frac{1}{10}$ gives\n$$\n\\sigma_{T_{16}} = \\frac{4}{\\frac{1}{10}} = 40,\n$$\nin minutes.", "answer": "$$\\boxed{40}$$", "id": "1950915"}, {"introduction": "Moving beyond simple moments, this exercise challenges you to calculate a probability related to system reliability, a critical application in engineering. You will model the total lifetime of a system with redundant components as the sum of independent exponential lifetimes. This practice requires you to use the cumulative distribution function (or survival function) of the resulting Gamma distribution to quantify the system's performance [@problem_id:1950932].", "problem": "A deep-space probe is equipped with a primary and a secondary communication module. The modules operate in a sequential, 'cold standby' mode: the secondary module is only activated upon the failure of the primary one. The operational lifetime of each module is independent and can be modeled by an exponential distribution with a mean lifetime of $\\mu = 4000$ hours.\n\nCalculate the probability that the total operational lifetime provided by both modules exceeds 5000 hours. Round your final answer to four significant figures.", "solution": "Let $X_{1}$ and $X_{2}$ denote the independent operational lifetimes (in hours) of the primary and secondary modules, respectively. Each is exponentially distributed with mean $\\mu=4000$, so the rate is $\\lambda=\\frac{1}{\\mu}$. In cold standby, the total operational lifetime is the sum $T=X_{1}+X_{2}$.\n\nSince $X_{1}$ and $X_{2}$ are independent and identically distributed exponential random variables with rate $\\lambda$, $T$ has an Erlang (Gamma) distribution with shape $k=2$ and rate $\\lambda$. The density of $T$ is\n$$\nf_{T}(t)=\\lambda^{2} t \\exp(-\\lambda t), \\quad t \\ge 0.\n$$\nThe survival function is\n$$\nS_{T}(t)=\\mathbb{P}(T>t)=\\int_{t}^{\\infty} \\lambda^{2} s \\exp(-\\lambda s)\\, ds.\n$$\nIntegrating by parts with $u=s$ and $dv=\\lambda^{2}\\exp(-\\lambda s)\\,ds$ gives $v=-\\lambda \\exp(-\\lambda s)$, hence\n$$\nS_{T}(t)=\\left[s(-\\lambda \\exp(-\\lambda s))\\right]_{t}^{\\infty}-\\int_{t}^{\\infty}(-\\lambda \\exp(-\\lambda s))\\, ds\n= \\lambda t \\exp(-\\lambda t)+\\exp(-\\lambda t)\n=\\exp(-\\lambda t)\\left(1+\\lambda t\\right).\n$$\nTherefore,\n$$\n\\mathbb{P}(T>5000)=\\exp\\!\\left(-\\lambda \\cdot 5000\\right)\\left(1+\\lambda \\cdot 5000\\right)\n=\\exp\\!\\left(-\\frac{5000}{\\mu}\\right)\\left(1+\\frac{5000}{\\mu}\\right).\n$$\nWith $\\mu=4000$, this becomes\n$$\n\\mathbb{P}(T>5000)=\\exp(-1.25)\\cdot 2.25.\n$$\nNumerically, $\\exp(-1.25)\\approx 0.2865047969$, so\n$$\n\\mathbb{P}(T>5000)\\approx 2.25 \\times 0.2865047969=0.6446357926,\n$$\nwhich rounds to four significant figures as $0.6446$.", "answer": "$$\\boxed{0.6446}$$", "id": "1950932"}, {"introduction": "Our final practice offers a more profound insight by reversing the typical direction of inquiry. Instead of predicting a sum, we analyze the properties of an individual component given that the total time is already known. This thought-provoking problem on conditional distributions reveals a surprisingly elegant result that is a hallmark of processes built from exponential variables, deepening your understanding of their unique characteristics [@problem_id:1950951].", "problem": "A specialized signal processing unit is designed with two sequential filtering stages. The time duration required for the first stage to process a signal is a random variable $X_1$, and the time for the second stage is $X_2$. The durations $X_1$ and $X_2$ are modeled as independent and identically distributed (i.i.d.) random variables, each following an exponential distribution with a rate parameter $\\lambda > 0$.\n\nFor quality control, a particular unit is tested. The total time taken for a signal to pass through both stages, $X_1 + X_2$, is measured to be a fixed constant value $T$. Given this empirical observation, we are interested in the statistical properties of the duration of the first stage, $X_1$.\n\nDetermine the conditional variance of the duration of the first stage, $Var(X_1 | X_1 + X_2 = T)$. Express your answer as a closed-form analytic expression in terms of the total measured time, $T$.", "solution": "Let $X_{1}$ and $X_{2}$ be independent and identically distributed as $\\mathrm{Exp}(\\lambda)$ with joint density\n$$\nf_{X_{1},X_{2}}(x_{1},x_{2})=\\lambda^{2}\\exp\\!\\big(-\\lambda(x_{1}+x_{2})\\big), \\quad x_{1}\\geq 0,\\; x_{2}\\geq 0.\n$$\nDefine the sum $S=X_{1}+X_{2}$. Its density is obtained by convolution:\n$$\nf_{S}(s)=\\int_{0}^{s} f_{X_{1},X_{2}}(x,s-x)\\,dx=\\int_{0}^{s}\\lambda^{2}\\exp(-\\lambda s)\\,dx=\\lambda^{2}s\\exp(-\\lambda s), \\quad s\\geq 0.\n$$\nThe conditional density of $X_{1}$ given $S=s$ is\n$$\nf_{X_{1}\\mid S}(x\\mid s)=\\frac{f_{X_{1},X_{2}}(x,s-x)}{f_{S}(s)}=\\frac{\\lambda^{2}\\exp(-\\lambda s)}{\\lambda^{2}s\\exp(-\\lambda s)}=\\frac{1}{s}, \\quad 0<x<s,\n$$\nand $0$ otherwise. Thus $X_{1}\\mid S=s\\sim \\mathrm{Uniform}(0,s)$.\n\nCompute the conditional mean and second moment:\n$$\n\\mathbb{E}[X_{1}\\mid S=s]=\\int_{0}^{s} x\\cdot \\frac{1}{s}\\,dx=\\frac{1}{s}\\cdot \\frac{s^{2}}{2}=\\frac{s}{2},\n$$\n$$\n\\mathbb{E}[X_{1}^{2}\\mid S=s]=\\int_{0}^{s} x^{2}\\cdot \\frac{1}{s}\\,dx=\\frac{1}{s}\\cdot \\frac{s^{3}}{3}=\\frac{s^{2}}{3}.\n$$\nTherefore,\n$$\n\\operatorname{Var}(X_{1}\\mid S=s)=\\mathbb{E}[X_{1}^{2}\\mid S=s]-\\big(\\mathbb{E}[X_{1}\\mid S=s]\\big)^{2}=\\frac{s^{2}}{3}-\\left(\\frac{s}{2}\\right)^{2}=\\frac{s^{2}}{12}.\n$$\nSubstituting $s=T$ yields\n$$\n\\operatorname{Var}(X_{1}\\mid X_{1}+X_{2}=T)=\\frac{T^{2}}{12}.\n$$", "answer": "$$\\boxed{\\frac{T^{2}}{12}}$$", "id": "1950951"}]}