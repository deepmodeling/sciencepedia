{"hands_on_practices": [{"introduction": "The first step in working with any continuous random variable is ensuring its probability density function (PDF) is mathematically valid. This practice [@problem_id:1909879] focuses on the fundamental concept of normalization, the principle that the total probability over all possible outcomes must integrate to one. By determining the normalization constant for a given function, you will gain essential skills in applying the condition $\\int_{-\\infty}^{\\infty} f(x) \\,dx = 1$, the cornerstone of continuous probability theory.", "problem": "A materials scientist is studying the degradation characteristics of a new type of polymer used in flexible electronics. During stress testing, a sample is subjected to a normalized strain level, $x$, which can vary from $x=0$ (no strain) to $x=2$ (the maximum design strain). The scientist models the likelihood of a microscopic fracture occurring at a specific strain level with a Probability Density Function (PDF), denoted $f(x)$.\n\nBased on initial observations, the proposed model for this PDF is given by:\n$$ f(x) = \\begin{cases} C(2x - x^2) & \\text{for } 0 \\le x \\le 2 \\\\ 0 & \\text{otherwise} \\end{cases} $$\nHere, $C$ is a positive constant that ensures the function is properly normalized. For $f(x)$ to be a mathematically valid PDF, the total probability over its entire domain must be equal to 1.\n\nDetermine the exact numerical value of the normalization constant $C$.", "solution": "For the function $f(x)$ to be a valid Probability Density Function (PDF), it must satisfy two primary conditions:\n1. $f(x) \\ge 0$ for all real numbers $x$.\n2. The total integral of $f(x)$ over its domain must equal 1, i.e., $\\int_{-\\infty}^{\\infty} f(x) \\,dx = 1$.\n\nLet's first verify the non-negativity condition. The problem states that $C$ is a positive constant. The function is defined as $f(x) = C(2x - x^2)$ on the interval $[0, 2]$. We can factor the polynomial part as $x(2-x)$. For any $x$ in the interval $[0, 2]$, the term $x$ is non-negative and the term $(2-x)$ is also non-negative. Therefore, their product $x(2-x)$ is non-negative on this interval. Since $C > 0$, the function $f(x) = C(2x - x^2)$ is greater than or equal to zero for $x \\in [0, 2]$. Outside this interval, $f(x) = 0$, so the non-negativity condition is satisfied for all real $x$.\n\nNext, we apply the normalization condition. The integral of $f(x)$ over all real numbers must be equal to 1. Since $f(x)$ is zero everywhere except on the interval $[0, 2]$, the integral simplifies to:\n$$ \\int_{-\\infty}^{\\infty} f(x) \\,dx = \\int_{0}^{2} C(2x - x^2) \\,dx = 1 $$\n\nWe can pull the constant $C$ out of the integral:\n$$ C \\int_{0}^{2} (2x - x^2) \\,dx = 1 $$\n\nNow, we evaluate the definite integral. The antiderivative of $2x - x^2$ is found by integrating term by term:\n$$ \\int (2x - x^2) \\,dx = 2\\frac{x^2}{2} - \\frac{x^3}{3} = x^2 - \\frac{x^3}{3} $$\n\nUsing the Fundamental Theorem of Calculus, we evaluate the definite integral from $0$ to $2$:\n$$ \\int_{0}^{2} (2x - x^2) \\,dx = \\left[ x^2 - \\frac{x^3}{3} \\right]_{0}^{2} $$\n\nSubstitute the limits of integration:\n$$ \\left[ x^2 - \\frac{x^3}{3} \\right]_{0}^{2} = \\left( (2)^2 - \\frac{(2)^3}{3} \\right) - \\left( (0)^2 - \\frac{(0)^3}{3} \\right) $$\n$$ = \\left( 4 - \\frac{8}{3} \\right) - (0) $$\n$$ = \\frac{12}{3} - \\frac{8}{3} = \\frac{4}{3} $$\n\nNow, we substitute this result back into the normalization equation:\n$$ C \\left( \\frac{4}{3} \\right) = 1 $$\n\nFinally, we solve for $C$:\n$$ C = \\frac{3}{4} $$\n\nThus, the value of the normalization constant is $\\frac{3}{4}$.", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1909879"}, {"introduction": "Once a probability model is established, we often use its key characteristics, like mean and variance, to understand the system it describes. This exercise [@problem_id:1909913] illustrates the powerful link between a distribution's theoretical properties and its defining parameters. You will see how knowing the variance of a uniformly distributed random variable allows you to deduce the exact boundaries of its possible values, a common task in fields like signal processing and quality control.", "problem": "An engineer is testing a new type of sensor designed to measure liquid pressure. The measurement error of the sensor, which can be modeled as a continuous random variable $X$, is known to follow a uniform distribution. The sensor is calibrated such that it never underestimates the pressure, meaning the error is always non-negative. However, there is a maximum possible error, denoted by $w$. Thus, the error $X$ is uniformly distributed on the interval $[0, w]$. After extensive calibration experiments, the variance of the measurement error is determined to be exactly $3.0$ units squared.\n\nBased on this information, calculate the value of the maximum possible error, $w$.", "solution": "The measurement error $X$ is uniformly distributed on $[0,w]$, so its probability density function is $f_{X}(x)=\\frac{1}{w}$ for $0 \\leq x \\leq w$. For a uniform distribution on $[0,w]$,\n$$\n\\mathbb{E}[X]=\\frac{w}{2}, \\quad \\mathbb{E}[X^{2}]=\\int_{0}^{w} x^{2}\\frac{1}{w}\\,dx=\\frac{1}{w}\\left[\\frac{x^{3}}{3}\\right]_{0}^{w}=\\frac{w^{2}}{3}.\n$$\nThus the variance is\n$$\n\\operatorname{Var}(X)=\\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2}=\\frac{w^{2}}{3}-\\left(\\frac{w}{2}\\right)^{2}=\\frac{w^{2}}{3}-\\frac{w^{2}}{4}=\\frac{w^{2}}{12}.\n$$\nGiven $\\operatorname{Var}(X)=3.0$, we set\n$$\n\\frac{w^{2}}{12}=3.0 \\quad \\Longrightarrow \\quad w^{2}=36 \\quad \\Longrightarrow \\quad w=6,\n$$\nwhere we take the positive root because $w$ is a maximum possible error and must be non-negative.", "answer": "$$\\boxed{6}$$", "id": "1909913"}, {"introduction": "Some probability distributions possess unique properties that offer deep insights into the processes they model, and the exponential distribution is a prime example. This problem [@problem_id:1909902] explores the fascinating and often counter-intuitive \"memoryless\" property, which states that the future probability of an event is independent of past waiting time. Working through this scenario will solidify your understanding of this concept, which is crucial for accurately analyzing waiting-time phenomena in physics, engineering, and finance.", "problem": "In a physics laboratory, a Geiger counter is used to measure radioactive decay. The time intervals between the detection of successive alpha particles from a specific radioactive sample are modeled as a continuous random variable. This detection time is well-described by an exponential distribution with a mean time between detections of $\\tau = 40.0$ seconds. An experiment begins, and after an initial period of $t_{wait} = 60.0$ seconds, no particle has yet been detected. Calculate the probability that a particle will be detected within the next $t_{interval} = 15.0$ seconds.\n\nRound your final answer to three significant figures.", "solution": "Let $T$ be the continuous random variable representing the time in seconds until the next alpha particle is detected. The problem states that $T$ follows an exponential distribution.\n\nThe probability density function (PDF) of an exponential distribution is given by $f(t) = \\lambda \\exp(-\\lambda t)$ for $t \\ge 0$, where $\\lambda$ is the rate parameter. The mean of the exponential distribution is related to the rate parameter by $\\mu = 1/\\lambda$.\n\nFrom the problem statement, the mean time between detections is $\\tau = 40.0$ seconds.\nTherefore, the rate parameter $\\lambda$ is:\n$$ \\lambda = \\frac{1}{\\tau} = \\frac{1}{40.0} \\, \\text{s}^{-1} $$\n\nWe are asked to find the probability that a particle is detected within the next $t_{interval} = 15.0$ seconds, given that no particle has been detected for the past $t_{wait} = 60.0$ seconds. This is a conditional probability.\n\nLet $A$ be the event that a particle is detected within the time interval $(t_{wait}, t_{wait} + t_{interval})$. This can be written as $t_{wait} < T < t_{wait} + t_{interval}$.\nLet $B$ be the event that no particle was detected in the first $t_{wait}$ seconds. This can be written as $T > t_{wait}$.\n\nWe need to calculate $P(A | B) = P(t_{wait} < T < t_{wait} + t_{interval} | T > t_{wait})$.\nLet's substitute the given values:\n$t_{wait} = 60.0$ s\n$t_{interval} = 15.0$ s\nThe probability we need to find is $P(60.0 < T < 75.0 | T > 60.0)$.\n\nA key feature of the exponential distribution is its **memoryless property**. This property states that for any $s > 0$ and $t > 0$:\n$$ P(T > s + t | T > s) = P(T > t) $$\nThis means the probability that the event occurs in the next $t$ seconds is independent of how long we have already waited ($s$ seconds).\n\nWe are seeking the probability of detection *within* the next interval, which is the complement of *not* detecting in that interval. Let's rephrase our problem using the survival function $P(T>t)$. The probability we want is:\n$$ P(T < 60.0 + 15.0 | T > 60.0) = 1 - P(T > 60.0 + 15.0 | T > 60.0) $$\n$$ = 1 - P(T > 75.0 | T > 60.0) $$\nApplying the memoryless property with $s = 60.0$ and $t = 15.0$:\n$$ P(T > 75.0 | T > 60.0) = P(T > 15.0) $$\nSo, the probability we seek becomes:\n$$ 1 - P(T > 15.0) = P(T \\le 15.0) $$\nThis confirms that due to the memoryless nature of the process, the 60.0 seconds of waiting has no effect on the future probability. We just need to calculate the probability of a detection within 15.0 seconds from any starting point.\n\nThe cumulative distribution function (CDF) for an exponential distribution is $F(t) = P(T \\le t) = 1 - \\exp(-\\lambda t)$.\nUsing the CDF, we can calculate the probability:\n$$ P(T \\le 15.0) = 1 - \\exp(-\\lambda \\times 15.0) $$\nSubstituting the value of $\\lambda = 1/40.0$:\n$$ P(T \\le 15.0) = 1 - \\exp\\left(-\\frac{1}{40.0} \\times 15.0\\right) = 1 - \\exp\\left(-\\frac{15.0}{40.0}\\right) = 1 - \\exp(-0.375) $$\n\nNow, we compute the numerical value:\n$$ 1 - \\exp(-0.375) \\approx 1 - 0.687289... = 0.312710... $$\n\nThe problem asks to round the final answer to three significant figures.\nThe first three significant figures are 3, 1, 2. The fourth digit is 7, so we round up the last significant digit.\n$$ 0.313 $$\n\nAlternatively, without directly invoking the memoryless property, we can use the definition of conditional probability:\n$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$\nHere, the event $A \\cap B$ is $60.0 < T < 75.0$.\nSo, we need to calculate:\n$$ P(60.0 < T < 75.0 | T > 60.0) = \\frac{P(60.0 < T < 75.0)}{P(T > 60.0)} $$\nThe survival function is $P(T > t) = \\exp(-\\lambda t)$.\nThe denominator is:\n$$ P(T > 60.0) = \\exp(-\\lambda \\times 60.0) = \\exp\\left(-\\frac{60.0}{40.0}\\right) = \\exp(-1.5) $$\nThe numerator is:\n$$ P(60.0 < T < 75.0) = P(T < 75.0) - P(T \\le 60.0) $$\n$$ = (1 - \\exp(-\\lambda \\times 75.0)) - (1 - \\exp(-\\lambda \\times 60.0)) $$\n$$ = \\exp(-\\lambda \\times 60.0) - \\exp(-\\lambda \\times 75.0) $$\n$$ = \\exp\\left(-\\frac{60.0}{40.0}\\right) - \\exp\\left(-\\frac{75.0}{40.0}\\right) = \\exp(-1.5) - \\exp(-1.875) $$\nNow, divide the numerator by the denominator:\n$$ P(\\text{event}) = \\frac{\\exp(-1.5) - \\exp(-1.875)}{\\exp(-1.5)} = 1 - \\frac{\\exp(-1.875)}{\\exp(-1.5)} $$\n$$ = 1 - \\exp(-1.875 - (-1.5)) = 1 - \\exp(-1.875 + 1.5) = 1 - \\exp(-0.375) $$\nThis confirms the previous result. The numerical calculation remains the same.\n$$ 1 - \\exp(-0.375) \\approx 0.312710... \\approx 0.313 $$", "answer": "$$\\boxed{0.313}$$", "id": "1909902"}]}