{"hands_on_practices": [{"introduction": "One of the most powerful tools in probability is the linearity of expectation, which states that the expected value of a sum of random variables is the sum of their individual expected values. This practice problem [@problem_id:1916150] provides a tangible scenario involving game design to demonstrate this principle. Instead of calculating the probability of every possible sum from two non-standard dice, a tedious task, you will see how this property allows you to find the expected sum by simply adding the individual expected values of each die, a much more efficient approach.", "problem": "A game designer is creating a new board game that uses two distinct, non-standard six-sided dice, referred to as Die A and Die B. Both dice are fair, meaning that for each die, any of its six faces is equally likely to land facing up after a roll. The set of integers on the six faces of Die A is $\\{0, 1, 1, 2, 4, 5\\}$. The set of integers on the six faces of Die B is $\\{2, 3, 4, 5, 6, 6\\}$. If a player rolls both dice simultaneously, what is the expected value of the sum of the numbers that appear on their top faces?", "solution": "Let $X$ be the random variable representing the numerical outcome of rolling Die A, and let $Y$ be the random variable representing the numerical outcome of rolling Die B. We are asked to find the expected value of the sum of these two random variables, which is denoted as $E[X+Y]$.\n\nA fundamental property of expected values is the linearity of expectation. This property states that for any two random variables $X$ and $Y$, the expected value of their sum is equal to the sum of their individual expected values:\n$$E[X+Y] = E[X] + E[Y]$$\nThis holds true regardless of whether the variables are independent or not. In this case, the rolls of the two dice are independent events.\n\nFirst, we calculate the expected value of the outcome of Die A, $E[X]$. The expected value of a discrete random variable is calculated by summing the product of each possible value and its probability. Since Die A is a fair six-sided die, the probability of any specific face landing up is $\\frac{1}{6}$. The values on the faces are $\\{0, 1, 1, 2, 4, 5\\}$.\nThe expected value $E[X]$ is the average of these values:\n$$E[X] = 0 \\cdot \\frac{1}{6} + 1 \\cdot \\frac{1}{6} + 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6}$$\n$$E[X] = \\frac{1}{6} (0 + 1 + 1 + 2 + 4 + 5)$$\n$$E[X] = \\frac{13}{6}$$\n\nNext, we calculate the expected value of the outcome of Die B, $E[Y]$. The values on the faces of Die B are $\\{2, 3, 4, 5, 6, 6\\}$. Since Die B is also a fair six-sided die, the probability of any face landing up is $\\frac{1}{6}$.\nThe expected value $E[Y]$ is the average of these values:\n$$E[Y] = 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6}$$\n$$E[Y] = \\frac{1}{6} (2 + 3 + 4 + 5 + 6 + 6)$$\n$$E[Y] = \\frac{26}{6}$$\n$$E[Y] = \\frac{13}{3}$$\n\nFinally, we use the linearity of expectation to find the expected sum $E[X+Y]$:\n$$E[X+Y] = E[X] + E[Y]$$\n$$E[X+Y] = \\frac{13}{6} + \\frac{26}{6}$$\n$$E[X+Y] = \\frac{13 + 26}{6}$$\n$$E[X+Y] = \\frac{39}{6}$$\nTo simplify the fraction, we divide the numerator and the denominator by their greatest common divisor, which is 3:\n$$E[X+Y] = \\frac{39 \\div 3}{6 \\div 3} = \\frac{13}{2}$$\n\nThus, the expected sum of the numbers shown on the top faces of the two dice is $\\frac{13}{2}$.", "answer": "$$\\boxed{\\frac{13}{2}}$$", "id": "1916150"}, {"introduction": "Expected value is not limited to the random variable itself; we can also compute the expectation of any function of that variable. This exercise [@problem_id:1916121] explores this concept within a simplified model from physics, where you'll determine the expected kinetic energy, $E[\\frac{1}{2}mV^2]$, of a particle. This requires you to work with a continuous probability density function and apply the definition of the expectation of a function, $E[g(V)] = \\int g(v) f(v) \\, dv$, a fundamental skill for applying probability in scientific contexts.", "problem": "In a simplified one-dimensional model of a rarefied gas, the speeds of non-interacting particles are described by a continuous random variable $V$. The probability density function (PDF) for the speed of a randomly selected particle is given by\n$$ f(v) = \\begin{cases} A v^{2}  \\text{if } 0 \\le v \\le v_{max} \\\\ 0  \\text{otherwise} \\end{cases} $$\nwhere $v_{max}$ is a positive constant representing the maximum possible speed of any particle, and $A$ is a normalization constant. Each particle has a mass $m$.\n\nDetermine the expected kinetic energy of a randomly selected particle. Express your answer as a closed-form analytic expression in terms of the particle mass $m$ and the maximum speed $v_{max}$.", "solution": "The probability density function is $f(v)=A v^{2}$ for $0\\leq v \\leq v_{max}$ and zero otherwise. The normalization condition $\\int_{-\\infty}^{\\infty} f(v)\\,dv=1$ reduces to\n$$\n\\int_{0}^{v_{max}} A v^{2}\\,dv = 1.\n$$\nEvaluating the integral gives\n$$\nA \\int_{0}^{v_{max}} v^{2}\\,dv = A \\left[\\frac{v^{3}}{3}\\right]_{0}^{v_{max}} = A \\frac{v_{max}^{3}}{3} = 1,\n$$\nso\n$$\nA = \\frac{3}{v_{max}^{3}}.\n$$\n\nThe kinetic energy of a particle with speed $v$ is $K(v)=\\frac{1}{2} m v^{2}$. The expected kinetic energy is\n$$\n\\mathbb{E}[K] = \\int_{0}^{v_{max}} \\frac{1}{2} m v^{2} f(v)\\,dv = \\frac{1}{2} m \\int_{0}^{v_{max}} v^{2} \\left(A v^{2}\\right)\\,dv = \\frac{1}{2} m A \\int_{0}^{v_{max}} v^{4}\\,dv.\n$$\nCompute the integral and substitute $A$:\n$$\n\\frac{1}{2} m A \\left[\\frac{v^{5}}{5}\\right]_{0}^{v_{max}} = \\frac{1}{2} m A \\frac{v_{max}^{5}}{5} = \\frac{1}{2} m \\left(\\frac{3}{v_{max}^{3}}\\right) \\frac{v_{max}^{5}}{5} = \\frac{3}{10} m v_{max}^{2}.\n$$\nTherefore, the expected kinetic energy is $\\frac{3}{10} m v_{max}^{2}$.", "answer": "$$\\boxed{\\frac{3}{10} m v_{max}^{2}}$$", "id": "1916121"}, {"introduction": "What happens to our expectation of a random outcome when we are given some partial information? This question leads us to the concept of conditional expectation, a cornerstone of modern statistics and machine learning. This problem [@problem_id:1916164] invites you to calculate the expected value of a standard normal random variable given that its value is positive. This exercise provides a concrete application for how to derive a conditional probability density function and compute a conditional expectation, $E[Z | Z > 0]$.", "problem": "A random variable $Z$ follows the standard normal distribution, which has the Probability Density Function (PDF) given by $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$ for all real numbers $z$. Consider the event $A$ that the observed value of $Z$ is positive, i.e., $A = \\{Z > 0\\}$. Calculate the conditional expected value of $Z$ given the event $A$, denoted as $E[Z | Z > 0]$. Express your answer as a symbolic expression in terms of $\\pi$.", "solution": "Let $Z$ be a standard normal random variable with Probability Density Function (PDF) $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$. We are asked to find the conditional expectation $E[Z | Z > 0]$.\n\nThe definition of conditional expectation for a continuous random variable $Z$ given an event $A$ is:\n$$ E[Z | A] = \\int_{-\\infty}^{\\infty} z f_{Z|A}(z) \\, dz $$\nwhere $f_{Z|A}(z)$ is the conditional PDF of $Z$ given the event $A$.\n\nThe conditional PDF is defined as:\n$$ f_{Z|A}(z) = \\begin{cases} \\frac{\\phi(z)}{P(A)}  \\text{if } z \\text{ is in the set corresponding to event } A \\\\ 0  \\text{otherwise} \\end{cases} $$\nIn this problem, the event is $A = \\{Z > 0\\}$. First, we must calculate the probability of this event, $P(A) = P(Z > 0)$.\nThe standard normal distribution is symmetric about its mean of 0. Therefore, the area under the curve for $z>0$ is exactly half of the total area, which is 1.\n$$ P(Z > 0) = \\int_{0}^{\\infty} \\phi(z) dz = \\frac{1}{2} $$\nNow we can construct the conditional PDF for $Z$ given $Z>0$:\n$$ f_{Z|Z>0}(z) = \\begin{cases} \\frac{\\phi(z)}{1/2} = 2\\phi(z)  \\text{if } z > 0 \\\\ 0  \\text{if } z \\le 0 \\end{cases} $$\nSubstituting the expression for $\\phi(z)$, we have:\n$$ f_{Z|Z>0}(z) = \\begin{cases} 2 \\cdot \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)  \\text{if } z > 0 \\\\ 0  \\text{if } z \\le 0 \\end{cases} $$\nNow we compute the conditional expectation. The integration is over all real numbers, but the integrand is zero for $z \\le 0$, so the integral is effectively from $0$ to $\\infty$.\n$$ E[Z | Z > 0] = \\int_{0}^{\\infty} z \\cdot f_{Z|Z>0}(z) dz = \\int_{0}^{\\infty} z \\left( \\frac{2}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) \\right) dz $$\nWe can pull the constant term out of the integral:\n$$ E[Z | Z > 0] = \\frac{2}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} z \\exp\\left(-\\frac{z^2}{2}\\right) dz $$\nTo evaluate the integral, we use the method of substitution. Let $u = \\frac{z^2}{2}$. The differential is then $du = \\frac{1}{2}(2z)dz = z dz$. We also need to transform the limits of integration.\nWhen $z = 0$, $u = \\frac{0^2}{2} = 0$.\nAs $z \\to \\infty$, $u \\to \\infty$.\nSubstituting $u$ and $du$ into the integral transforms it as follows:\n$$ E[Z | Z > 0] = \\frac{2}{\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\exp(-u) du $$\nThe integral of $\\exp(-u)$ is a standard result:\n$$ \\int_{0}^{\\infty} \\exp(-u) du = [-\\exp(-u)]_{0}^{\\infty} = \\lim_{b \\to \\infty} [-\\exp(-u)]_{0}^{b} = \\lim_{b \\to \\infty} (-\\exp(-b)) - (-\\exp(-0)) = 0 - (-1) = 1 $$\nSubstituting this result back into our expression for the expectation:\n$$ E[Z | Z > 0] = \\frac{2}{\\sqrt{2\\pi}} \\cdot 1 = \\frac{2}{\\sqrt{2\\pi}} $$\nFinally, we simplify this expression:\n$$ \\frac{2}{\\sqrt{2\\pi}} = \\frac{\\sqrt{2} \\cdot \\sqrt{2}}{\\sqrt{2} \\cdot \\sqrt{\\pi}} = \\frac{\\sqrt{2}}{\\sqrt{\\pi}} = \\sqrt{\\frac{2}{\\pi}} $$\nThus, the conditional expected value of a standard normal random variable, given that it is positive, is $\\sqrt{\\frac{2}{\\pi}}$.", "answer": "$$\\boxed{\\sqrt{\\frac{2}{\\pi}}}$$", "id": "1916164"}]}