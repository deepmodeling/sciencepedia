{"hands_on_practices": [{"introduction": "The expected value, or mean, is a cornerstone concept for describing the center of a probability distribution. This exercise provides fundamental practice in calculating the mean for a discrete random variable, a common task in fields from quantum mechanics to finance. As you work through the problem [@problem_id:1934427], take note of the final result; it illustrates the important principle that the expected value represents a weighted average and may not correspond to any of the actual observable outcomes.", "problem": "In a quantum optics experiment, a single atom is confined in a magneto-optical trap. After being excited by a laser pulse, the atom's electronic state can relax into one of four possible discrete energy levels. Let the random variable $X$ represent the measured energy of the atom's final state in electron-volts (eV). The set of possible energy values for $X$ is $\\{1.0, 2.5, 4.0, 5.0\\}$.\n\nA series of measurements reveals the following probability distribution for these energy levels:\n- $P(X=1.0 \\text{ eV}) = 0.40$\n- $P(X=2.5 \\text{ eV}) = c$\n- $P(X=4.0 \\text{ eV}) = 2c$\n- $P(X=5.0 \\text{ eV}) = 0.10$\n\nHere, $c$ is an unknown constant determined by the physics of the system.\n\nCalculate the expected energy level, $E[X]$, of the atom. Express your final answer in eV, rounded to three significant figures.", "solution": "We model the measured final energy as a discrete random variable $X$ with support $\\{1.0, 2.5, 4.0, 5.0\\}$ and probabilities $P(X=1.0)=0.40$, $P(X=2.5)=c$, $P(X=4.0)=2c$, and $P(X=5.0)=0.10$. The normalization of probabilities requires that their sum equals $1$:\n$$\n0.40 + c + 2c + 0.10 = 1.\n$$\nWriting $0.40=\\frac{2}{5}$ and $0.10=\\frac{1}{10}$ for exactness,\n$$\n\\frac{2}{5} + c + 2c + \\frac{1}{10} = 1 \\;\\;\\Rightarrow\\;\\; 3c + \\left(\\frac{2}{5} + \\frac{1}{10}\\right) = 1 \\;\\;\\Rightarrow\\;\\; 3c + \\frac{1}{2} = 1,\n$$\nso\n$$\n3c = \\frac{1}{2} \\;\\;\\Rightarrow\\;\\; c = \\frac{1}{6}.\n$$\nThe expected value of a discrete random variable is $E[X]=\\sum x\\,P(X=x)$. Therefore,\n$$\nE[X] = 1.0\\cdot 0.40 + 2.5\\cdot c + 4.0\\cdot (2c) + 5.0\\cdot 0.10.\n$$\nUsing exact fractions, $1.0=\\frac{10}{10}$, $0.40=\\frac{2}{5}$, $2.5=\\frac{5}{2}$, $4.0=4$, and $0.10=\\frac{1}{10}$, we obtain\n$$\nE[X] = \\frac{2}{5} + \\frac{5}{2}c + 8c + \\frac{1}{2} = \\frac{9}{10} + \\left(\\frac{5}{2}+8\\right)c = \\frac{9}{10} + \\frac{21}{2}c.\n$$\nSubstituting $c=\\frac{1}{6}$,\n$$\nE[X] = \\frac{9}{10} + \\frac{21}{2}\\cdot \\frac{1}{6} = \\frac{9}{10} + \\frac{7}{4} = \\frac{53}{20} = 2.65.\n$$\nRounded to three significant figures in eV, the expected energy is $2.65$.", "answer": "$$\\boxed{2.65}$$", "id": "1934427"}, {"introduction": "While both the mean and the median measure central tendency, they possess very different mathematical properties. One of the most powerful properties of the mean (expectation) is its linearity: $E[X+Y] = E[X] + E[Y]$ for random variables $X$ and $Y$. This exercise [@problem_id:1934426] challenges you to investigate whether the median shares this intuitive property. By constructing a simple counterexample, you will uncover a fundamental distinction that highlights the non-linear nature of the median, a crucial insight for robust statistical analysis.", "problem": "In probability theory, while the expectation of a sum of random variables is always the sum of their expectations, the same does not hold true for the median. This problem explores this property using a specific example.\n\nLet $X_1$ and $X_2$ be two independent and identically distributed discrete random variables. Their common probability mass function is given by:\n$$ P(X_i = 1) = \\frac{2}{3} $$\n$$ P(X_i = 100) = \\frac{1}{3} $$\nfor $i=1, 2$.\n\nThe median of a random variable $W$ with cumulative distribution function $F_W(w) = P(W \\le w)$ is defined as $\\text{median}(W) = \\inf\\{w \\in \\mathbb{R} \\mid F_W(w) \\ge 0.5\\}$.\n\nCalculate the discrepancy $\\Delta = \\text{median}(X_1+X_2) - (\\text{median}(X_1) + \\text{median}(X_2))$.", "solution": "By definition, for any random variable $W$ with cumulative distribution function $F_{W}(w)=P(W\\le w)$, the median is $\\inf\\{w\\in\\mathbb{R}\\mid F_{W}(w)\\ge 0.5\\}$.\n\nFirst compute $\\text{median}(X_{i})$. The distribution of $X_{i}$ is $P(X_{i}=1)=\\frac{2}{3}$ and $P(X_{i}=100)=\\frac{1}{3}$. Its cumulative distribution function satisfies $F_{X_{i}}(w)=0$ for $w<1$, $F_{X_{i}}(1)=\\frac{2}{3}$, and $F_{X_{i}}(w)=1$ for $w\\ge 100$. Since $F_{X_{i}}(1)=\\frac{2}{3}\\ge 0.5$ and for $w<1$ we have $F_{X_{i}}(w)=0<0.5$, it follows that\n$$\n\\text{median}(X_{i})=1.\n$$\nHence $\\text{median}(X_{1})+\\text{median}(X_{2})=1+1=2$.\n\nNext compute the distribution of $S=X_{1}+X_{2}$. By independence,\n$$\nP(S=2)=P(X_{1}=1,X_{2}=1)=\\left(\\frac{2}{3}\\right)^{2}=\\frac{4}{9},\n$$\n$$\nP(S=101)=P(X_{1}=1,X_{2}=100)+P(X_{1}=100,X_{2}=1)=2\\cdot \\frac{2}{3}\\cdot \\frac{1}{3}=\\frac{4}{9},\n$$\n$$\nP(S=200)=P(X_{1}=100,X_{2}=100)=\\left(\\frac{1}{3}\\right)^{2}=\\frac{1}{9}.\n$$\nThus the cumulative distribution function of $S$ satisfies\n$$\nF_{S}(w)=\\begin{cases}\n0, & w<2,\\\\\n\\frac{4}{9}, & 2\\le w<101,\\\\\n\\frac{8}{9}, & 101\\le w<200,\\\\\n1, & w\\ge 200.\n\\end{cases}\n$$\nThe median of $S$ is the infimum of $w$ such that $F_{S}(w)\\ge 0.5$. We have $F_{S}(2)=\\frac{4}{9}<0.5$ and $F_{S}(101)=\\frac{8}{9}\\ge 0.5$, so\n$$\n\\text{median}(X_{1}+X_{2})=101.\n$$\nTherefore, the discrepancy is\n$$\n\\Delta=\\text{median}(X_{1}+X_{2})-\\bigl(\\text{median}(X_{1})+\\text{median}(X_{2})\\bigr)=101-2=99.\n$$", "answer": "$$\\boxed{99}$$", "id": "1934426"}, {"introduction": "Moving from theory to application, how do we efficiently compute the mean for a continuous stream of data without storing every observation? This challenge is common in fields like sensor networks, online machine learning, and financial monitoring. This problem [@problem_id:1934443] guides you to derive a \"running\" or \"online\" update rule for the arithmetic mean. Mastering this one-pass algorithm is not just a mathematical exercise; it's a step toward understanding how statistical measures are implemented in computationally constrained, real-world systems.", "problem": "An onboard computer for a deep-space probe is tasked with analyzing the flux of high-energy particles. The probe's sensor generates a stream of measurements, $x_1, x_2, x_3, \\dots$, where $x_k$ is the measurement taken at time step $k$. Due to severe memory constraints, the computer cannot store the entire history of measurements. Instead, it must compute the running arithmetic mean in a single pass.\n\nLet $\\mu_n$ be the arithmetic mean of the first $n$ measurements, i.e., $\\mu_n = \\frac{1}{n}\\sum_{i=1}^{n} x_i$. When a new measurement $x_n$ arrives (for $n > 1$), the computer updates the previous mean $\\mu_{n-1}$ to the new mean $\\mu_n$. This update rule can be formulated as a linear combination of the previous mean and the new data point:\n$$ \\mu_n = A_n \\mu_{n-1} + B_n x_n $$\nwhere the coefficients $A_n$ and $B_n$ are functions of the number of measurements, $n$.\n\nDetermine the expression for the coefficient $B_n$ as a function of $n$.", "solution": "We start from the definition of the running mean of the first $n$ measurements:\n$$\n\\mu_{n}=\\frac{1}{n}\\sum_{i=1}^{n}x_{i}.\n$$\nSplit the sum into the first $n-1$ terms and the $n$th term:\n$$\n\\mu_{n}=\\frac{1}{n}\\left(\\sum_{i=1}^{n-1}x_{i}+x_{n}\\right).\n$$\nExpress the partial sum $\\sum_{i=1}^{n-1}x_{i}$ in terms of $\\mu_{n-1}$ using the definition $\\mu_{n-1}=\\frac{1}{n-1}\\sum_{i=1}^{n-1}x_{i}$, which implies\n$$\n\\sum_{i=1}^{n-1}x_{i}=(n-1)\\mu_{n-1}.\n$$\nSubstitute this into the expression for $\\mu_{n}$:\n$$\n\\mu_{n}=\\frac{1}{n}\\left((n-1)\\mu_{n-1}+x_{n}\\right)=\\frac{n-1}{n}\\mu_{n-1}+\\frac{1}{n}x_{n}.\n$$\nComparing with the update form $\\mu_{n}=A_{n}\\mu_{n-1}+B_{n}x_{n}$, we identify\n$$\nB_{n}=\\frac{1}{n}.\n$$", "answer": "$$\\boxed{\\frac{1}{n}}$$", "id": "1934443"}]}