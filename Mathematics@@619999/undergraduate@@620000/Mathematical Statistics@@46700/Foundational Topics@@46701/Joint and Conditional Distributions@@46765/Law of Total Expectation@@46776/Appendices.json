{"hands_on_practices": [{"introduction": "We begin with a classic scenario from quality control that perfectly illustrates the core idea of the Law of Total Expectation. By breaking down a two-stage sampling process—first selecting a source, then sampling from it—we can calculate the overall expected outcome in an intuitive way. This practice [@problem_id:1928925] demonstrates how conditioning on the outcome of the first stage simplifies the calculation for the second, providing a foundational understanding of this powerful tool.", "problem": "A quality control department at a technology firm stores electronic components from three different suppliers in three separate, large bins. The composition of components in each bin is as follows:\n\n- Bin 1 contains 50 defective components and 50 non-defective components.\n- Bin 2 contains 30 defective components and 90 non-defective components.\n- Bin 3 contains 80 defective components and 20 non-defective components.\n\nAn inspector follows a two-stage sampling procedure. First, the inspector selects one of the three bins at random, with each bin having an equal probability of being chosen. Second, from the selected bin, the inspector draws a sample of 40 components without replacement for testing.\n\nCalculate the expected number of defective components in the inspector's sample. Round your final answer to three significant figures.", "solution": "Let $B \\in \\{1,2,3\\}$ denote the bin selected uniformly at random, so $P(B=i)=\\frac{1}{3}$ for each $i$. Let $X$ be the number of defective components in the sample of size $n=40$. Conditional on choosing bin $i$, the sample follows a hypergeometric model with population size $N_{i}$ and defective count $D_{i}$. A standard property of the hypergeometric distribution (or by linearity of expectation using indicator variables) gives\n$$\n\\mathbb{E}[X \\mid B=i]=n \\cdot \\frac{D_{i}}{N_{i}}.\n$$\nBy the law of total expectation,\n$$\n\\mathbb{E}[X]=\\sum_{i=1}^{3} P(B=i)\\,\\mathbb{E}[X \\mid B=i]=\\frac{1}{3}\\sum_{i=1}^{3} n \\cdot \\frac{D_{i}}{N_{i}}=\\frac{n}{3}\\left(\\frac{D_{1}}{N_{1}}+\\frac{D_{2}}{N_{2}}+\\frac{D_{3}}{N_{3}}\\right).\n$$\nFrom the problem data, $(N_{1},D_{1})=(100,50)$, $(N_{2},D_{2})=(120,30)$, and $(N_{3},D_{3})=(100,80)$, with $n=40$. Substituting,\n$$\n\\mathbb{E}[X]=\\frac{40}{3}\\left(\\frac{50}{100}+\\frac{30}{120}+\\frac{80}{100}\\right)=\\frac{40}{3}\\left(\\frac{1}{2}+\\frac{1}{4}+\\frac{4}{5}\\right).\n$$\nCompute the sum inside the parentheses:\n$$\n\\frac{1}{2}+\\frac{1}{4}+\\frac{4}{5}=\\frac{10+5+16}{20}=\\frac{31}{20}.\n$$\nTherefore,\n$$\n\\mathbb{E}[X]=\\frac{40}{3}\\cdot \\frac{31}{20}=\\frac{2}{3}\\cdot 31=\\frac{62}{3}\\approx 20.666\\ldots\n$$\nRounding to three significant figures gives $20.7$.", "answer": "$$\\boxed{20.7}$$", "id": "1928925"}, {"introduction": "Building on the foundational concept, this next practice explores a scenario familiar to any student: taking a multiple-choice exam. Here, we use the Law of Total Expectation to model the uncertainty of knowing an answer versus guessing [@problem_id:1400544]. This exercise highlights how the law can be seamlessly integrated with other powerful principles, such as the linearity of expectation, to analyze systems composed of many independent parts.", "problem": "A student is taking a specialized entrance exam for a data science program. The exam consists of two sections of multiple-choice questions.\n\nSection 1, on foundational theory, contains $N_1$ questions. Each question in this section has $m_1$ options, with only one correct answer. For any given question in this section, the student knows the correct answer with probability $p_1$. If the student does not know the answer, they guess randomly and uniformly among all available options. A correct answer is awarded $a_1$ points, while an incorrect answer results in a penalty of $b_1$ points (i.e., a score of $-b_1$).\n\nSection 2, on applied problems, contains $N_2$ questions. Each question here has $m_2$ options, again with only one correct answer. Due to the higher difficulty, the student knows the correct answer with probability $p_2$. If they do not know the answer, they follow the same random guessing strategy. In this section, a correct answer is awarded $a_2$ points, and an incorrect answer incurs a penalty of $b_2$ points.\n\nAssume the student's knowledge of each question is an independent event. Determine the total expected score for the student on the entire exam. Express your answer as a symbolic expression in terms of $N_1, N_2, m_1, m_2, p_1, p_2, a_1, b_1, a_2,$ and $b_2$.", "solution": "Let $X_{1}$ denote the score on a single question from Section 1. The student knows the answer with probability $p_{1}$ and then answers correctly, earning $a_{1}$ points. If the student does not know the answer (probability $1 - p_{1}$), they guess uniformly among $m_{1}$ options, so the probability of a correct guess is $\\frac{1}{m_{1}}$ and of an incorrect guess is $\\frac{m_{1} - 1}{m_{1}}$, yielding $a_{1}$ or $-b_{1}$ respectively. By the law of total expectation,\n$$\n\\mathbb{E}[X_{1}] = p_{1} \\cdot a_{1} + (1 - p_{1})\\left( \\frac{1}{m_{1}} a_{1} + \\frac{m_{1} - 1}{m_{1}} (-b_{1}) \\right).\n$$\nThis simplifies to\n$$\n\\mathbb{E}[X_{1}] = a_{1}\\left( p_{1} + \\frac{1 - p_{1}}{m_{1}} \\right) - b_{1} \\frac{(1 - p_{1})(m_{1} - 1)}{m_{1}} = \\frac{a_{1}\\left(1 + (m_{1} - 1)p_{1}\\right) - b_{1}(m_{1} - 1)(1 - p_{1})}{m_{1}}.\n$$\nBy linearity of expectation, the expected total score from Section 1 with $N_{1}$ questions is\n$$\nS_{1} = N_{1} \\mathbb{E}[X_{1}] = \\frac{N_{1}}{m_{1}}\\left( a_{1}\\left(1 + (m_{1} - 1)p_{1}\\right) - b_{1}(m_{1} - 1)(1 - p_{1}) \\right).\n$$\n\nSimilarly, let $X_{2}$ denote the score on a single question from Section 2. Repeating the same reasoning with parameters $m_{2}, p_{2}, a_{2}, b_{2}$,\n$$\n\\mathbb{E}[X_{2}] = p_{2} \\cdot a_{2} + (1 - p_{2})\\left( \\frac{1}{m_{2}} a_{2} + \\frac{m_{2} - 1}{m_{2}} (-b_{2}) \\right)\n= \\frac{a_{2}\\left(1 + (m_{2} - 1)p_{2}\\right) - b_{2}(m_{2} - 1)(1 - p_{2})}{m_{2}}.\n$$\nThus the expected total score from Section 2 with $N_{2}$ questions is\n$$\nS_{2} = N_{2} \\mathbb{E}[X_{2}] = \\frac{N_{2}}{m_{2}}\\left( a_{2}\\left(1 + (m_{2} - 1)p_{2}\\right) - b_{2}(m_{2} - 1)(1 - p_{2}) \\right).\n$$\n\nBy additivity of expectation across sections, the total expected score is\n$$\nS_{\\text{total}} = S_{1} + S_{2} = \\frac{N_{1}}{m_{1}}\\left( a_{1}\\left(1 + (m_{1} - 1)p_{1}\\right) - b_{1}(m_{1} - 1)(1 - p_{1}) \\right) + \\frac{N_{2}}{m_{2}}\\left( a_{2}\\left(1 + (m_{2} - 1)p_{2}\\right) - b_{2}(m_{2} - 1)(1 - p_{2}) \\right).\n$$", "answer": "$$\\boxed{\\frac{N_{1}}{m_{1}}\\left( a_{1}\\left(1 + (m_{1} - 1)p_{1}\\right) - b_{1}(m_{1} - 1)(1 - p_{1}) \\right) + \\frac{N_{2}}{m_{2}}\\left( a_{2}\\left(1 + (m_{2} - 1)p_{2}\\right) - b_{2}(m_{2} - 1)(1 - p_{2}) \\right)}$$", "id": "1400544"}, {"introduction": "Our final practice delves into a more intricate multi-stage process involving sequential random divisions, a common model in fields like resource allocation and geometric probability. This problem requires a nested application of the Law of Total Expectation, often called the \"tower property\", to navigate through multiple layers of uncertainty [@problem_id:1400554]. Mastering this exercise will solidify your ability to deconstruct complex probabilistic models by conditioning step-by-step, revealing the power of this law in its full recursive form.", "problem": "A research agency allocates its annual budget of $L$ dollars by a two-stage randomized process. First, the total budget is partitioned into two sub-budgets at a division point chosen uniformly at random along the interval $[0, L]$. One of these two sub-budgets is then selected with equal probability for a specific research division. This selected sub-budget is then itself partitioned into two final project grants at a second division point chosen uniformly at random along its length.\n\nDetermine the expected value of the smaller of the two final project grants. Express your answer as a closed-form analytic expression in terms of $L$.", "solution": "Let's define the random variables involved in this two-stage process.\n\nLet $L$ be the total initial budget.\nIn the first stage, the budget is partitioned at a point $X_1$, where $X_1$ is a random variable uniformly distributed on $[0, L]$. The probability density function (PDF) of $X_1$ is $f_{X_1}(x_1) = 1/L$ for $x_1 \\in [0, L]$. This creates two sub-budgets of sizes $X_1$ and $L - X_1$.\n\nLet $Y_1$ be the random variable representing the size of the sub-budget selected from these two. Since the selection is made with equal probability, given $X_1 = x_1$, the value of $Y_1$ is $x_1$ with probability $1/2$ or $L-x_1$ with probability $1/2$.\n\nIn the second stage, the selected sub-budget of size $Y_1$ is partitioned. Let's say $Y_1=y_1$. The partition point $X_2$ is chosen uniformly at random from $[0, y_1]$. This creates two final project grants of sizes $X_2$ and $y_1 - X_2$.\n\nLet $S$ be the random variable for the size of the smaller of these two final grants. Our goal is to find the expected value of $S$, i.e., $E[S]$.\n\nWe can solve this using the Law of Total Expectation, also known as the tower property, which states that $E[S] = E[E[S|Y_1]]$. We will compute this in two steps: first the inner expectation conditional on $Y_1$, and then the outer expectation.\n\n**Step 1: Compute the inner expectation, $E[S|Y_1=y_1]$**\n\nThe inner expectation $E[S|Y_1=y_1]$ is the expected value of the smaller piece when a budget of size $y_1$ is split randomly. The random split point $X_2$ is uniformly distributed on $[0, y_1]$, so its PDF is $f_{X_2}(x_2) = 1/y_1$ for $x_2 \\in [0, y_1]$. The smaller piece has size $\\min(X_2, y_1-X_2)$.\n\n$$E[S|Y_1=y_1] = E[\\min(X_2, y_1-X_2)] = \\int_{0}^{y_1} \\min(x_2, y_1-x_2) f_{X_2}(x_2) dx_2$$\n\nThe term $\\min(x_2, y_1-x_2)$ equals $x_2$ when $x_2 \\le y_1/2$ and $y_1-x_2$ when $x_2 > y_1/2$. We split the integral at $y_1/2$:\n\n$$E[S|Y_1=y_1] = \\frac{1}{y_1} \\left( \\int_{0}^{y_1/2} x_2 \\,dx_2 + \\int_{y_1/2}^{y_1} (y_1-x_2) \\,dx_2 \\right)$$\n\nEvaluating the first integral:\n$$\\int_{0}^{y_1/2} x_2 \\,dx_2 = \\left[ \\frac{x_2^2}{2} \\right]_{0}^{y_1/2} = \\frac{(y_1/2)^2}{2} - 0 = \\frac{y_1^2}{8}$$\n\nEvaluating the second integral:\n$$\\int_{y_1/2}^{y_1} (y_1-x_2) \\,dx_2 = \\left[ y_1x_2 - \\frac{x_2^2}{2} \\right]_{y_1/2}^{y_1} = \\left(y_1^2 - \\frac{y_1^2}{2}\\right) - \\left(y_1\\frac{y_1}{2} - \\frac{(y_1/2)^2}{2}\\right) = \\frac{y_1^2}{2} - \\left(\\frac{y_1^2}{2} - \\frac{y_1^2}{8}\\right) = \\frac{y_1^2}{8}$$\n\nSubstituting these back into the expression for the conditional expectation:\n$$E[S|Y_1=y_1] = \\frac{1}{y_1} \\left( \\frac{y_1^2}{8} + \\frac{y_1^2}{8} \\right) = \\frac{1}{y_1} \\left( \\frac{2y_1^2}{8} \\right) = \\frac{y_1}{4}$$\n\nSo, we have the general relationship $E[S|Y_1] = Y_1/4$.\n\n**Step 2: Compute the outer expectation, $E[Y_1/4]$**\n\nNow we can find the overall expectation of $S$:\n$$E[S] = E[E[S|Y_1]] = E\\left[\\frac{Y_1}{4}\\right] = \\frac{1}{4} E[Y_1]$$\n\nTo find $E[Y_1]$, we again use the Law of Total Expectation, this time conditioning on the first split point $X_1$.\n$$E[Y_1] = E[E[Y_1|X_1]]$$\n\nGiven that the first split occurs at $X_1 = x_1$, the two sub-budgets are $x_1$ and $L-x_1$. One is chosen with equal probability ($1/2$). The conditional expectation of the chosen size $Y_1$ is:\n$$E[Y_1|X_1=x_1] = x_1 \\cdot \\frac{1}{2} + (L-x_1) \\cdot \\frac{1}{2} = \\frac{x_1 + L - x_1}{2} = \\frac{L}{2}$$\n\nThis result is a constant and does not depend on $x_1$. Now we take the expectation over all possible values of $X_1$:\n$$E[Y_1] = E\\left[\\frac{L}{2}\\right]$$\n\nSince $L/2$ is a constant, its expectation is just itself:\n$$E[Y_1] = \\frac{L}{2}$$\n\n**Step 3: Combine the results**\n\nFinally, substitute the value of $E[Y_1]$ back into the expression for $E[S]$:\n$$E[S] = \\frac{1}{4} E[Y_1] = \\frac{1}{4} \\left(\\frac{L}{2}\\right) = \\frac{L}{8}$$\n\nThe expected value of the smaller of the two final project grants is $L/8$.", "answer": "$$\\boxed{\\frac{L}{8}}$$", "id": "1400554"}]}