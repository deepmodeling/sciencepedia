{"hands_on_practices": [{"introduction": "The core magic of the Central Limit Theorem (CLT) is its ability to find order in randomness, predicting a normal distribution from the sum of independent variables, even if they aren't normally distributed themselves. This exercise provides a foundational practice by starting with a simple uniform distribution—a clear example of a non-normal case—and applying the CLT to approximate a probability related to a sum of these variables [@problem_id:1959588]. It is the perfect first step to building intuition for this powerful theorem and its wide-ranging applications in modeling aggregate behavior.", "problem": "An automated data processing server handles a continuous stream of small, independent tasks. The time required to process a single task is a random variable, uniformly distributed between 2.0 seconds and 6.0 seconds. An analyst is interested in the total processing time for a batch of 75 such tasks.\n\nAssuming the processing times for all tasks are independent and identically distributed, calculate the approximate probability that the total time to process all 75 tasks is less than 285 seconds.\n\nExpress your answer as a decimal, rounded to three significant figures.", "solution": "Let $X$ denote the processing time for a single task. Given $X \\sim \\text{Uniform}(a,b)$ with $a=2$ and $b=6$, the mean and variance are\n$$\n\\mu_{X}=\\frac{a+b}{2}=\\frac{2+6}{2}=4, \\quad \\sigma_{X}^{2}=\\frac{(b-a)^{2}}{12}=\\frac{(6-2)^{2}}{12}=\\frac{16}{12}=\\frac{4}{3}.\n$$\nLet $S_{75}=\\sum_{i=1}^{75} X_{i}$ be the total time for 75 independent tasks. By linearity of expectation and additivity of variance for independent variables,\n$$\n\\mu_{S}=\\mathbb{E}[S_{75}]=75\\mu_{X}=75\\cdot 4=300, \\quad \\sigma_{S}^{2}=\\operatorname{Var}(S_{75})=75\\sigma_{X}^{2}=75\\cdot \\frac{4}{3}=100,\n$$\nso $\\sigma_{S}=\\sqrt{100}=10$.\n\nBy the Central Limit Theorem, for large $n$, $S_{75}$ is approximately normal: $S_{75} \\approx \\mathcal{N}(\\mu_{S},\\sigma_{S}^{2})$. Therefore,\n$$\n\\mathbb{P}(S_{75}<285)\\approx \\Phi\\!\\left(\\frac{285-\\mu_{S}}{\\sigma_{S}}\\right)=\\Phi\\!\\left(\\frac{285-300}{10}\\right)=\\Phi(-1.5).\n$$\nUsing the standard normal cumulative distribution function, $\\Phi(-1.5)\\approx 0.066807\\ldots$, which rounded to three significant figures is $0.0668$.", "answer": "$$\\boxed{0.0668}$$", "id": "1959588"}, {"introduction": "The power of the Central Limit Theorem extends beyond single variables into multiple dimensions, a concept crucial in fields like robotics, physics, and finance, where outcomes are described by vectors. This practice challenges you to apply the CLT to the individual components of a two-dimensional error vector, a scenario common in precision engineering [@problem_id:1959603]. By doing so, you will learn to reason about the distribution of the vector's magnitude, gaining insight into how overall precision is quantified and controlled in multidimensional systems.", "problem": "In a high-precision semiconductor manufacturing process, a robotic arm is tasked with placing a tiny component at the origin $(0, 0)$ of a coordinate system on a silicon wafer. Due to microscopic random vibrations and electronic noise, the actual position of the placed component has an error, represented by a random vector $(X, Y)$, where $X$ and $Y$ are measured in micrometers ($\\mu\\text{m}$).\n\nThe process is calibrated such that the error components $X$ and $Y$ are independent random variables, each drawn from a distribution with a mean of $0 \\text{ } \\mu\\text{m}$ and a variance of $1 \\text{ } \\mu\\text{m}^2$.\n\nTo assess the overall precision of the robotic arm, a quality control test is performed by placing $n=40$ components. This yields 40 independent and identically distributed error vectors $(X_1, Y_1), (X_2, Y_2), \\dots, (X_{40}, Y_{40})$. The average error vector is then computed as $(\\bar{X}, \\bar{Y})$, where $\\bar{X} = \\frac{1}{40}\\sum_{i=1}^{40} X_i$ and $\\bar{Y} = \\frac{1}{40}\\sum_{i=1}^{40} Y_i$.\n\nA test batch is considered to pass quality control if the magnitude of the average error vector, $\\sqrt{\\bar{X}^2 + \\bar{Y}^2}$, is less than or equal to $0.2 \\text{ } \\mu\\text{m}$. Assuming $n=40$ is a sufficiently large sample size for the Central Limit Theorem to provide a good approximation, calculate the probability that a test batch will pass quality control.\n\nProvide your final answer as a numerical value rounded to four significant figures.", "solution": "Let $(X_{i},Y_{i})$ be i.i.d. with $E[X_{i}]=0$, $E[Y_{i}]=0$, $\\operatorname{Var}(X_{i})=1$, $\\operatorname{Var}(Y_{i})=1$, and $X_{i}$ independent of $Y_{i}$ for each $i$. Define the sample means $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$ and $\\bar{Y}=\\frac{1}{n}\\sum_{i=1}^{n}Y_{i}$ with $n=40$.\n\nBy linearity of expectation and variance of sample means,\n$$\nE[\\bar{X}]=0,\\quad \\operatorname{Var}(\\bar{X})=\\frac{1}{n},\\qquad E[\\bar{Y}]=0,\\quad \\operatorname{Var}(\\bar{Y})=\\frac{1}{n}.\n$$\nIndependence across coordinates and across $i$ implies $\\bar{X}$ and $\\bar{Y}$ are independent. By the Central Limit Theorem, for $n$ sufficiently large, $(\\bar{X},\\bar{Y})$ is approximately bivariate normal with mean $(0,0)$ and covariance matrix $\\frac{1}{n}I_{2}$. Write\n$$\n\\bar{X}=\\sigma Z_{1},\\qquad \\bar{Y}=\\sigma Z_{2},\\qquad \\sigma^{2}=\\frac{1}{n},\n$$\nwhere $Z_{1},Z_{2}$ are approximately independent standard normal variables.\n\nThe magnitude of the average error vector is $R=\\sqrt{\\bar{X}^{2}+\\bar{Y}^{2}}=\\sigma\\sqrt{Z_{1}^{2}+Z_{2}^{2}}$. Hence $R$ has approximately a Rayleigh distribution with scale $\\sigma$. The Rayleigh cumulative distribution function is\n$$\n\\mathbb{P}(R\\le r)=1-\\exp\\!\\left(-\\frac{r^{2}}{2\\sigma^{2}}\\right).\n$$\nWith $n=40$ and threshold $r=0.2$, we have $\\sigma^{2}=\\frac{1}{40}$, so\n$$\n\\mathbb{P}\\!\\left(\\sqrt{\\bar{X}^{2}+\\bar{Y}^{2}}\\le 0.2\\right)\n=1-\\exp\\!\\left(-\\frac{(0.2)^{2}}{2\\cdot \\frac{1}{40}}\\right)\n=1-\\exp(-0.8).\n$$\nNumerically, $1-\\exp(-0.8)\\approx 0.550671\\ldots$, which rounded to four significant figures is $0.5507$.", "answer": "$$\\boxed{0.5507}$$", "id": "1959603"}, {"introduction": "While the CLT masterfully describes the distribution of a sample mean, $\\bar{X}_n$, statisticians are often more interested in a function of that mean, let's say $g(\\bar{X}_n)$. The Delta method provides a powerful bridge, leveraging the result of the CLT to find an approximate distribution for this transformed statistic. This advanced practice will guide you through using the Delta method to determine the asymptotic variance of an estimator [@problem_id:852592], demonstrating how the CLT serves as a cornerstone for the broader theory of statistical inference.", "problem": "Consider a sequence of $n$ independent and identically distributed (i.i.d.) random variables, $X_1, X_2, \\ldots, X_n$, drawn from a geometric distribution. The probability mass function (PMF) for this distribution, which represents the number of trials needed to obtain the first success, is given by\n$$\nP(X=k) = (1-p)^{k-1}p\n$$\nfor $k = 1, 2, 3, \\ldots$, where $p$ is the probability of success on any given trial, and $0 < p < 1$.\n\nLet $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$ be the sample mean. The reciprocal of the sample mean, $1/\\bar{X}_n$, is a consistent estimator for the success probability $p$.\n\nUsing the Delta method, determine the asymptotic variance of the estimator $1/\\bar{X}_n$. The asymptotic variance of an estimator $\\hat{\\theta}_n$ for a parameter $\\theta$ is defined as the variance $V$ of the limiting normal distribution such that $\\sqrt{n}(\\hat{\\theta}_n - \\theta) \\xrightarrow{d} N(0, V)$.", "solution": "1. For $X_i\\sim\\mathrm{Geom}(p)$ we have \n$$\\mu=E[X_i]=\\frac{1}{p},\\qquad\\sigma^2=\\operatorname{Var}(X_i)=\\frac{1-p}{p^2}.$$\n2. The sample mean satisfies \n$$\\sqrt{n}(\\bar X_n-\\mu)\\xrightarrow{d}N(0,\\sigma^2).$$\n3. Define $g(x)=1/x$. Then $g'(\\mu)=-1/\\mu^2$ and by the Delta method\n$$\\sqrt{n}\\bigl(g(\\bar X_n)-g(\\mu)\\bigr)\\xrightarrow{d}N\\Bigl(0,\\,[g'(\\mu)]^2\\,\\sigma^2\\Bigr).$$\n4. Compute\n$$[g'(\\mu)]^2\\,\\sigma^2=\\frac{1}{\\mu^4}\\,\\frac{1-p}{p^2}\n=\\frac{p^4}{1}\\,\\frac{1-p}{p^2}\n=p^2(1-p).$$ \nHence the asymptotic variance is $p^2(1-p)\\,$.", "answer": "$$\\boxed{p^2(1-p)}$$", "id": "852592"}]}