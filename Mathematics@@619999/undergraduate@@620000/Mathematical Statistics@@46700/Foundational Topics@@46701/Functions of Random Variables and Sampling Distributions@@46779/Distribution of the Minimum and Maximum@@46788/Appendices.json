{"hands_on_practices": [{"introduction": "Understanding the minimum value of a set of random variables is crucial in many fields, especially in reliability engineering and risk assessment. This practice provides a foundational exercise in calculating the expected value of the minimum from a sample. By working through a scenario involving a redundant sensor system, you will apply the tail integral formula, a powerful tool for computing expectations, to determine the average detection time [@problem_id:1914346].", "problem": "A redundant detection system uses two independent sensors to monitor for a specific type of critical failure in an industrial machine. Empirical data shows that the time, in minutes, for either sensor to detect a failure, once it has occurred, is a random variable uniformly distributed on the interval $[5, 15]$. The system logs the failure as soon as the first sensor triggers an alert. Let $T_1$ and $T_2$ be the detection times for the two sensors. The system's recorded detection time is $T_{sys} = \\min(T_1, T_2)$. Calculate the expected value of the system's detection time, $E[T_{sys}]$, in minutes. Express your answer as an exact fraction.", "solution": "Let $T_{1}$ and $T_{2}$ be independent and identically distributed as $\\mathrm{Uniform}[5,15]$, and let $T_{\\text{sys}}=\\min(T_{1},T_{2})$. For a continuous nonnegative random variable $X$, the tail integral formula gives $E[X]=\\int_{0}^{\\infty} \\mathbb{P}(X>t)\\,dt$. Applying this to $T_{\\text{sys}}$ and using independence,\n$$\nE[T_{\\text{sys}}]=\\int_{0}^{\\infty} \\mathbb{P}(T_{\\text{sys}}>t)\\,dt=\\int_{0}^{\\infty} \\mathbb{P}(T_{1}>t,\\,T_{2}>t)\\,dt=\\int_{0}^{\\infty} \\left[\\mathbb{P}(T_{1}>t)\\right]^{2}\\,dt.\n$$\nSince $T_{1}\\sim \\mathrm{Uniform}[5,15]$, its cumulative distribution function on $[5,15]$ is $F(t)=\\frac{t-5}{10}$, so the survival function is $S(t)=1-F(t)=\\frac{15-t}{10}$ for $t\\in[5,15]$. Moreover, $S(t)=1$ for $t<5$ and $S(t)=0$ for $t>15$. Therefore,\n$$\nE[T_{\\text{sys}}]=\\int_{0}^{5} 1\\,dt+\\int_{5}^{15}\\left(\\frac{15-t}{10}\\right)^{2}dt=\\;5+\\frac{1}{100}\\int_{5}^{15}(15-t)^{2}dt.\n$$\nWith the substitution $u=15-t$ (so $du=-dt$), the bounds $t=5$ to $t=15$ map to $u=10$ to $u=0$, giving\n$$\n\\frac{1}{100}\\int_{5}^{15}(15-t)^{2}dt=\\frac{1}{100}\\int_{0}^{10}u^{2}\\,du=\\frac{1}{100}\\left[\\frac{u^{3}}{3}\\right]_{0}^{10}=\\frac{1}{100}\\cdot \\frac{1000}{3}=\\frac{10}{3}.\n$$\nHence,\n$$\nE[T_{\\text{sys}}]=5+\\frac{10}{3}=\\frac{25}{3}.\n$$", "answer": "$$\\boxed{\\frac{25}{3}}$$", "id": "1914346"}, {"introduction": "Beyond analyzing the minimum or maximum in isolation, it is often important to understand the relationship between them. This problem challenges you to calculate the probability of an event defined by the relative values of the minimum and maximum of two random variables [@problem_id:1914331]. This exercise is excellent for developing a geometric intuition for joint probability distributions, as the solution can be visualized as an area within the sample space.", "problem": "Two independent nodes in a decentralized communication network are programmed to broadcast a status update at a random time. The time for each broadcast, measured in seconds from the start of a specific one-second cycle, is a random variable that follows a Uniform distribution on the interval $[0, 1]$. Let the two broadcast times be $T_1$ and $T_2$.\n\nCalculate the probability that the later broadcast occurs more than twice as far in time from the start of the cycle as the earlier broadcast. Express your answer as a fraction.", "solution": "Let $T_{1}$ and $T_{2}$ be independent and identically distributed with Uniform$[0,1]$. Their joint density is $f_{T_{1},T_{2}}(t_{1},t_{2})=1$ on the unit square $\\{(t_{1},t_{2}):0\\leq t_{1}\\leq 1,\\,0\\leq t_{2}\\leq 1\\}$.\n\nThe event that the later broadcast occurs more than twice as far from the start as the earlier is $\\{\\max(T_{1},T_{2})>2\\min(T_{1},T_{2})\\}$. This is equivalent to the union of the two disjoint events (up to a set of measure zero):\n$$\nE_{1}=\\{T_{1}>2T_{2}\\},\\quad E_{2}=\\{T_{2}>2T_{1}\\}.\n$$\nThus,\n$$\n\\mathbb{P}\\big(\\max(T_{1},T_{2})>2\\min(T_{1},T_{2})\\big)=\\mathbb{P}(E_{1})+\\mathbb{P}(E_{2}).\n$$\nBy symmetry, $\\mathbb{P}(E_{1})=\\mathbb{P}(E_{2})$, so it suffices to compute $\\mathbb{P}(E_{1})$.\n\nFor $E_{1}$, the constraint $T_{1}>2T_{2}$ within $[0,1]^{2}$ implies $0\\leq T_{2}\\leq \\frac{1}{2}$ and, for each such $T_{2}$, $2T_{2}\\leq T_{1}\\leq 1$. Therefore,\n$$\n\\mathbb{P}(E_{1})=\\int_{0}^{1/2}\\int_{2t_{2}}^{1} 1 \\, dt_{1}\\, dt_{2}\n=\\int_{0}^{1/2} \\big(1-2t_{2}\\big)\\, dt_{2}\n=\\left[t_{2}-t_{2}^{2}\\right]_{0}^{1/2}\n=\\frac{1}{2}-\\frac{1}{4}\n=\\frac{1}{4}.\n$$\nHence,\n$$\n\\mathbb{P}\\big(\\max(T_{1},T_{2})>2\\min(T_{1},T_{2})\\big)=\\mathbb{P}(E_{1})+\\mathbb{P}(E_{2})=\\frac{1}{4}+\\frac{1}{4}=\\frac{1}{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1914331"}, {"introduction": "A more advanced task in statistics is to derive the full probability distribution of a statistic built from sample data. This practice guides you through the process of finding the probability density function (PDF) for the sample mid-range, $M = \\frac{X_{(1)} + X_{(n)}}{2}$, a measure of central tendency [@problem_id:1914354]. Successfully completing this problem requires synthesizing your knowledge of the joint distribution of order statistics with the method of transformations, a cornerstone technique in mathematical statistics.", "problem": "In a high-precision manufacturing process for quantum dot displays, the wavelength of light emitted by a quantum dot is a critical parameter. After a normalization procedure, these wavelengths are modeled as independent and identically distributed random variables from a Uniform distribution on the interval $(0, \\theta)$, where $\\theta$ is a known positive design parameter.\n\nFor quality control, a random sample of $n$ quantum dots (where $n > 1$) is selected from a production batch. Let their normalized wavelengths be $X_1, X_2, \\ldots, X_n$. The two extreme wavelength values in the sample, the minimum $X_{(1)}$ and the maximum $X_{(n)}$, are recorded. To monitor the central tendency of the production, engineers analyze a statistic called the sample mid-range, defined as $M = \\frac{X_{(1)} + X_{(n)}}{2}$.\n\nTo establish statistical control limits for this metric, it is necessary to determine its probability distribution. Find the Probability Density Function (PDF) of the sample mid-range, $M$. Express your answer as a function of $m$, the sample size $n$, and the parameter $\\theta$.", "solution": "Let $X_{1},\\ldots,X_{n}$ be i.i.d. $\\operatorname{Uniform}(0,\\theta)$ with pdf $f(x)=\\frac{1}{\\theta}$ for $0<x<\\theta$ and cdf $F(x)=\\frac{x}{\\theta}$ for $0<x<\\theta$. Denote the minimum by $U=X_{(1)}$ and the maximum by $V=X_{(n)}$. For continuous i.i.d. samples, the joint pdf of $(U,V)$ is\n$$\nf_{U,V}(u,v)=n(n-1)\\bigl(F(v)-F(u)\\bigr)^{n-2}f(u)f(v), \\quad u<v.\n$$\nFor the uniform case this becomes, on $0<u<v<\\theta$,\n$$\nf_{U,V}(u,v)=n(n-1)\\left(\\frac{v-u}{\\theta}\\right)^{n-2}\\frac{1}{\\theta}\\frac{1}{\\theta}\n=\\frac{n(n-1)}{\\theta^{n}}(v-u)^{n-2}.\n$$\n\nDefine the mid-range $M=\\frac{U+V}{2}$ and the range $R=V-U$. Use the transformation\n$$\nm=\\frac{u+v}{2},\\quad r=v-u,\n$$\nwith inverse\n$$\nu=m-\\frac{r}{2},\\qquad v=m+\\frac{r}{2}.\n$$\nThe Jacobian determinant is\n$$\nJ=\\left|\\det\\begin{pmatrix}\n\\frac{\\partial u}{\\partial m} & \\frac{\\partial u}{\\partial r}\\\\\n\\frac{\\partial v}{\\partial m} & \\frac{\\partial v}{\\partial r}\n\\end{pmatrix}\\right|\n=\\left|\\det\\begin{pmatrix}1 & -\\frac{1}{2} \\\\ 1 & \\frac{1}{2}\\end{pmatrix}\\right|\n=\\left|\\frac{1}{2}-\\left(-\\frac{1}{2}\\right)\\right|=1.\n$$\nThe support transforms as $0<u<v<\\theta$ to $r>0$ and $m-\\frac{r}{2}>0$, $m+\\frac{r}{2}<\\theta$, i.e.,\n$$\nr>0,\\qquad \\frac{r}{2}<m<\\theta-\\frac{r}{2}.\n$$\nThus the joint pdf of $(M,R)$ is\n$$\nf_{M,R}(m,r)=\\frac{n(n-1)}{\\theta^{n}}\\,r^{n-2}, \\quad r>0,\\ \\frac{r}{2}<m<\\theta-\\frac{r}{2}.\n$$\n\nTo find the marginal pdf of $M$, integrate out $r$. For a fixed $m$, the admissible $r$ satisfy $0<r<2\\min\\{m,\\theta-m\\}$. Therefore,\n$$\nf_{M}(m)=\\int_{0}^{2\\min\\{m,\\theta-m\\}} \\frac{n(n-1)}{\\theta^{n}}\\,r^{n-2}\\,dr\n=\\frac{n(n-1)}{\\theta^{n}}\\cdot \\frac{\\left(2\\min\\{m,\\theta-m\\}\\right)^{n-1}}{n-1}.\n$$\nThis simplifies to\n$$\nf_{M}(m)=\\frac{n\\,2^{n-1}}{\\theta^{n}}\\left(\\min\\{m,\\theta-m\\}\\right)^{n-1}, \\quad 0<m<\\theta,\n$$\nand $f_{M}(m)=0$ otherwise. Equivalently, in piecewise form,\n$$\nf_{M}(m)=\\begin{cases}\n\\frac{n\\,2^{n-1}}{\\theta^{n}}\\,m^{n-1} & 0<m<\\frac{\\theta}{2}\\\\[6pt]\n\\frac{n\\,2^{n-1}}{\\theta^{n}}\\,(\\theta-m)^{n-1} & \\frac{\\theta}{2}<m<\\theta\\\\[6pt]\n0 & m\\leq 0 \\text{ or } m\\geq \\theta\n\\end{cases}\n$$\nThis integrates to one by symmetry, confirming it is a valid pdf.", "answer": "$$\\boxed{f_{M}(m)=\\begin{cases}\n\\dfrac{n\\,2^{n-1}}{\\theta^{n}}\\,m^{n-1} & 0<m<\\dfrac{\\theta}{2}\\\\[6pt]\n\\dfrac{n\\,2^{n-1}}{\\theta^{n}}\\,(\\theta-m)^{n-1} & \\dfrac{\\theta}{2}<m<\\theta\\\\[6pt]\n0 & m\\leq 0 \\text{ or } m\\geq \\theta\n\\end{cases}}$$", "id": "1914354"}]}