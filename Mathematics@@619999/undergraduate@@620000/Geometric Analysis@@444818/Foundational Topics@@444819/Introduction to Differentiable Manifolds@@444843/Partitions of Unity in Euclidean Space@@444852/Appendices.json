{"hands_on_practices": [{"introduction": "The entire theory of partitions of unity is built upon the existence of a very special type of function: a smooth ($C^\\infty$) function that is positive on a bounded set and identically zero everywhere else. This might seem simple, but it is impossible in the world of real-analytic functions, which are rigidly determined by their local behavior. This exercise guides you through the foundational construction of such a \"bump function,\" the essential building block for all partitions of unity, from first principles. [@problem_id:3059002]", "problem": "Let $n \\in \\mathbb{N}$ and let $\\|\\cdot\\|$ denote the Euclidean norm on $\\mathbb{R}^{n}$. A function $\\eta : \\mathbb{R}^{n} \\to \\mathbb{R}$ is said to be of class $C^{\\infty}$ (infinitely continuously differentiable) if all of its partial derivatives of every order exist and are continuous on $\\mathbb{R}^{n}$. A function $\\eta$ is called radial if there exists a one-variable function $\\rho : [0,\\infty) \\to \\mathbb{R}$ such that $\\eta(x) = \\rho(\\|x\\|)$ for all $x \\in \\mathbb{R}^{n}$. A function $\\eta$ is said to have compact support in the closed unit ball $\\overline{B(0,1)} = \\{ x \\in \\mathbb{R}^{n} : \\|x\\| \\le 1 \\}$ if $\\eta(x) = 0$ whenever $\\|x\\| > 1$.\n\nUsing only the fundamental facts that compositions of $C^{\\infty}$ functions are $C^{\\infty}$, and that the exponential function and polynomial functions are $C^{\\infty}$ on their domains, construct a radial function $\\eta \\in C^{\\infty}(\\mathbb{R}^{n})$ such that $\\eta(x) = 0$ for all $\\|x\\| \\ge 1$ and $\\eta(x) > 0$ for all $\\|x\\| < 1$. Prove rigorously that $\\eta$ is $C^{\\infty}$ at the boundary $\\{ x \\in \\mathbb{R}^{n} : \\|x\\| = 1 \\}$ by showing that every partial derivative of $\\eta$ of any order extends continuously to the boundary and equals $0$ there.\n\nYour final answer must be the explicit closed-form analytical expression for the constructed function $\\eta(x)$, written as a single expression. No rounding is required and no physical units are involved.", "solution": "The problem statement is a valid exercise in real analysis, specifically concerning the construction of a smooth bump function. It is mathematically well-posed, self-contained, and scientifically grounded. We shall proceed with the construction and proof.\n\nThe goal is to construct a radial function $\\eta \\in C^{\\infty}(\\mathbb{R}^{n})$ such that $\\eta(x) > 0$ for $\\|x\\| < 1$ and $\\eta(x) = 0$ for $\\|x\\| \\ge 1$. The construction relies on a one-dimensional auxiliary function that is $C^{\\infty}$ but not analytic.\n\nLet us first define a function $g: \\mathbb{R} \\to \\mathbb{R}$ as follows:\n$$ g(t) = \\begin{cases} \\exp\\left(-\\frac{1}{t}\\right) & \\text{if } t > 0 \\\\ 0 & \\text{if } t \\le 0 \\end{cases} $$\nWe will prove that $g(t)$ is a $C^{\\infty}$ function on $\\mathbb{R}$. The function is clearly $C^{\\infty}$ for $t \\neq 0$, as it is a composition of $C^{\\infty}$ functions (the exponential function and $t \\mapsto -1/t$) for $t > 0$, and the zero function for $t < 0$. The critical point to investigate is $t=0$.\n\nFirst, we check continuity at $t=0$. The left-sided limit is $\\lim_{t \\to 0^-} g(t) = 0$, which equals $g(0)$. For the right-sided limit, let $s = 1/t$. As $t \\to 0^+$, $s \\to \\infty$.\n$$ \\lim_{t \\to 0^+} g(t) = \\lim_{t \\to 0^+} \\exp\\left(-\\frac{1}{t}\\right) = \\lim_{s \\to \\infty} \\exp(-s) = 0 $$\nSince the left and right limits both equal $g(0)$, the function $g$ is continuous at $t=0$.\n\nNext, we prove that all derivatives of $g$ exist at $t=0$ and are equal to $0$. We will show by induction that for any integer $k \\ge 0$, the $k$-th derivative of $g(t)$ for $t>0$ has the form $g^{(k)}(t) = P_k(1/t) \\exp(-1/t)$ for some polynomial $P_k$, and that the derivative at $t=0$ is $g^{(k)}(0)=0$.\n\nThe base case $k=0$ is $g(t) = P_0(1/t) \\exp(-1/t)$ with $P_0(s)=1$. We have already shown $g(0)=0$.\n\nAssume for some integer $k \\ge 0$ that for $t>0$, $g^{(k)}(t) = P_k(1/t) \\exp(-1/t)$ for some polynomial $P_k$, and that $g^{(k)}(0)=0$. For $t>0$, the $(k+1)$-th derivative is found by the chain and product rules:\n$$ g^{(k+1)}(t) = \\frac{d}{dt} \\left[ P_k\\left(\\frac{1}{t}\\right)\\exp\\left(-\\frac{1}{t}\\right) \\right] = P_k'\\left(\\frac{1}{t}\\right) \\left(-\\frac{1}{t^2}\\right) \\exp\\left(-\\frac{1}{t}\\right) + P_k\\left(\\frac{1}{t}\\right) \\exp\\left(-\\frac{1}{t}\\right) \\left(\\frac{1}{t^2}\\right) $$\nLet $s=1/t$. Then $g^{(k+1)}(t) = \\left[ -s^2 P_k'(s) + s^2 P_k(s) \\right] \\exp(-s)$. The term in the brackets, $P_{k+1}(s) = s^2(P_k(s) - P_k'(s))$, is a polynomial in $s=1/t$. Thus, the inductive form is maintained for $t>0$.\n\nNow we must show that $g^{(k+1)}(0)=0$. By definition of the derivative:\n$$ g^{(k+1)}(0) = \\lim_{t \\to 0} \\frac{g^{(k)}(t) - g^{(k)}(0)}{t} $$\nThe left-sided limit is $\\lim_{t \\to 0^-} \\frac{0-0}{t} = 0$. For the right-sided limit:\n$$ \\lim_{t \\to 0^+} \\frac{g^{(k)}(t)}{t} = \\lim_{t \\to 0^+} \\frac{1}{t} P_k\\left(\\frac{1}{t}\\right) \\exp\\left(-\\frac{1}{t}\\right) $$\nLet $s=1/t$. As $t \\to 0^+$, $s \\to \\infty$. The limit becomes $\\lim_{s \\to \\infty} s P_k(s) \\exp(-s)$. Let $Q(s) = s P_k(s)$, which is also a polynomial. We need to show that $\\lim_{s \\to \\infty} Q(s) \\exp(-s) = 0$ for any polynomial $Q$.\n\nLet $Q(s)$ be a polynomial of degree $m$. It is sufficient to show that $\\lim_{s \\to \\infty} s^j \\exp(-s) = 0$ for any non-negative integer $j$. From the Taylor series expansion of the exponential function, we know that for $s>0$, $\\exp(s) = \\sum_{k=0}^{\\infty} \\frac{s^k}{k!}$. Since all terms are positive, we can bound $\\exp(s)$ from below by any single term, for instance, $\\exp(s) > \\frac{s^{j+1}}{(j+1)!}$.\nThis gives us the inequality for $s>0$:\n$$ 0 < s^j \\exp(-s) = \\frac{s^j}{\\exp(s)} < \\frac{s^j}{s^{j+1}/(j+1)!} = \\frac{(j+1)!}{s} $$\nAs $s \\to \\infty$, the term $\\frac{(j+1)!}{s} \\to 0$. By the Squeeze Theorem, we conclude that $\\lim_{s \\to \\infty} s^j \\exp(-s) = 0$. This holds for any term in the polynomial $Q(s)$, so $\\lim_{s \\to \\infty} Q(s) \\exp(-s) = 0$.\n\nThus, $g^{(k+1)}(0) = 0$. By induction, $g^{(k)}(0)=0$ for all $k \\ge 0$. This confirms that $g(t)$ is of class $C^{\\infty}$ on $\\mathbb{R}$.\n\nNow, we construct the desired function $\\eta(x)$. The function must be radial, so it will depend on $\\|x\\|$. We want it to be positive for $\\|x\\| < 1$ and zero for $\\|x\\| \\ge 1$. Let us define $\\eta(x)$ using our $C^{\\infty}$ function $g(t)$:\n$$ \\eta(x) = g(1-\\|x\\|^2) $$\nwhere $\\|x\\|^2 = \\sum_{i=1}^n x_i^2$. Let's analyze this function:\n1.  If $\\|x\\| < 1$, then $0 < \\|x\\|^2 < 1$, which implies $1-\\|x\\|^2 > 0$. In this case, $\\eta(x) = \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right)$. Since the argument of the exponential is finite, $\\eta(x) > 0$.\n2.  If $\\|x\\| \\ge 1$, then $\\|x\\|^2 \\ge 1$, which implies $1-\\|x\\|^2 \\le 0$. In this case, by definition of $g$, $\\eta(x) = 0$.\n\nThis function satisfies the positivity and support conditions. We must now prove that $\\eta(x)$ is of class $C^{\\infty}(\\mathbb{R}^n)$.\nLet $u(x) = 1-\\|x\\|^2$. As $\\|x\\|^2$ is a polynomial in the components of $x$, $u(x)$ is a $C^{\\infty}$ function on $\\mathbb{R}^n$. Our function is $\\eta(x) = g(u(x))$.\n\n-   In the open ball $B(0,1) = \\{x \\in \\mathbb{R}^n : \\|x\\| < 1\\}$, the function $u(x)$ maps to the interval $(0, 1]$. On this interval for its argument, $g$ is $C^{\\infty}$. Since $\\eta(x)$ is a composition of $C^{\\infty}$ functions ($g$ and $u$) in this domain, it is $C^{\\infty}$ on $B(0,1)$.\n-   In the open set $\\{x \\in \\mathbb{R}^n : \\|x\\| > 1\\}$, $u(x) < 0$, so $\\eta(x)$ is identically zero. The zero function is $C^{\\infty}$.\n-   The critical region is the boundary sphere $S^{n-1} = \\{x \\in \\mathbb{R}^n : \\|x\\|=1\\}$. We must show that for any multi-index $\\alpha$, the partial derivative $\\partial^{\\alpha}\\eta(x)$ is continuous at any point $x_0$ with $\\|x_0\\|=1$. Since $\\partial^{\\alpha}\\eta(x) = 0$ for $\\|x\\|>1$, we need to show that $\\lim_{x \\to x_0, \\|x\\|<1} \\partial^{\\alpha}\\eta(x) = 0$.\n\nThe partial derivatives of $\\eta(x) = g(u(x))$ for $\\|x\\|<1$ are found using the multivariate chain rule (FaÃ  di Bruno's formula). Any partial derivative $\\partial^{\\alpha}\\eta$ is a sum of terms of the form:\n$$ C \\cdot g^{(k)}(u(x)) \\cdot \\prod_{j} (\\partial^{\\beta_j} u(x)) $$\nwhere $1 \\le k \\le |\\alpha|$, $C$ is a constant, and $\\beta_j$ are multi-indices. The derivatives of $u(x)=1-\\|x\\|^2$ are polynomials in the components of $x$ (e.g., $\\partial_i u = -2x_i$, $\\partial_i \\partial_j u = -2\\delta_{ij}$, and higher derivatives are zero). Therefore, for $\\|x\\|<1$, $\\partial^{\\alpha}\\eta(x)$ can be expressed as a finite sum:\n$$ \\partial^{\\alpha}\\eta(x) = \\sum_{k=1}^{|\\alpha|} Q_k(x) g^{(k)}(1-\\|x\\|^2) $$\nwhere each $Q_k(x)$ is a polynomial in the components $x_1, \\ldots, x_n$.\nFor $\\|x\\|<1$, we have $1-\\|x\\|^2 > 0$, so we can substitute the form of $g^{(k)}$:\n$$ \\partial^{\\alpha}\\eta(x) = \\sum_{k=1}^{|\\alpha|} Q_k(x) P_k\\left(\\frac{1}{1-\\|x\\|^2}\\right) \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right) $$\nwhere $P_k$ are the polynomials from our analysis of $g(t)$. Let $x_0$ be a point with $\\|x_0\\|=1$. We examine the limit of a generic term in the sum as $x \\to x_0$ from within the ball $\\|x\\|<1$:\n$$ \\lim_{x \\to x_0, \\|x\\|<1} Q_k(x) P_k\\left(\\frac{1}{1-\\|x\\|^2}\\right) \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right) $$\nLet $t=1-\\|x\\|^2$. As $x \\to x_0$ with $\\|x\\|<1$, we have $t \\to 0^+$. The polynomial $Q_k(x)$ is continuous, so $\\lim_{x\\to x_0} Q_k(x) = Q_k(x_0)$. The limit becomes:\n$$ Q_k(x_0) \\cdot \\lim_{t \\to 0^+} P_k\\left(\\frac{1}{t}\\right) \\exp\\left(-\\frac{1}{t}\\right) $$\nAs established during the analysis of $g(t)$, this limit is $0$. Since every term in the sum for $\\partial^{\\alpha}\\eta(x)$ approaches $0$ as $x \\to x_0$, we have $\\lim_{x \\to x_0, \\|x\\|<1} \\partial^{\\alpha}\\eta(x) = 0$.\nSince $\\partial^{\\alpha}\\eta(x) \\equiv 0$ for $\\|x\\|>1$, the limit from outside the ball is also $0$. Thus, for any multi-index $\\alpha$, the partial derivative $\\partial^{\\alpha}\\eta(x)$ is continuous across the boundary $\\|x\\|=1$ and equals $0$ on it.\nThis completes the proof that $\\eta(x)$ is of class $C^{\\infty}$ on all of $\\mathbb{R}^n$.\n\nThe constructed function is:\n$$ \\eta(x) = \\begin{cases} \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right) & \\text{if } \\|x\\| < 1 \\\\ 0 & \\text{if } \\|x\\| \\ge 1 \\end{cases} $$\nThis function is radial, $C^{\\infty}$ on $\\mathbb{R}^n$, positive on the open unit ball, and zero on and outside the boundary of the unit ball, as required.", "answer": "$$\n\\boxed{\n\\eta(x) = \\begin{cases} \\exp\\left(-\\frac{1}{1-\\|x\\|^2}\\right) & \\text{if } \\|x\\| < 1 \\\\ 0 & \\text{if } \\|x\\| \\ge 1 \\end{cases}\n}\n$$", "id": "3059002"}, {"introduction": "One of the primary applications of partitions of unity is to \"localize\" analytical problems, breaking a complex global issue into simpler local pieces. This practice problem provides a compelling demonstration of this \"divide and conquer\" strategy by tackling a singular integral. You will use a partition of unity to decompose an integral with a logarithmic singularity at the origin, isolating the problematic behavior into one manageable term while showing the other part becomes trivial. [@problem_id:3058995]", "problem": "Let $\\mathbb{R}^{2}$ be covered by the two open sets $U_{1} = B(0,2)$ and $U_{2} = \\mathbb{R}^{2} \\setminus \\overline{B(0,1)}$. Let $\\chi \\in C_{c}^{\\infty}(\\mathbb{R}^{2})$ satisfy $0 \\leq \\chi \\leq 1$, $\\chi \\equiv 1$ on $B(0,1)$, and $\\mathrm{supp}(\\chi) \\subset B(0,2)$. Define $\\psi := 1 - \\chi$. Then $(\\chi,\\psi)$ is a partition of unity subordinate to $\\{U_{1},U_{2}\\}$ in the sense that $\\chi + \\psi \\equiv 1$, $\\mathrm{supp}(\\chi) \\subset U_{1}$, and $\\mathrm{supp}(\\psi) \\subset U_{2}$. Consider the singular kernel $x \\mapsto \\ln|x|$ and the smooth function $f(x) := \\exp(-|x|^{2})$. Define\n$$\nI := \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta f(x) \\, dx.\n$$\nUsing only the core definitions of partitions of unity, properties of smooth functions, and standard integration by parts in $\\mathbb{R}^{2}$, do the following:\n- Explain why the partition of unity localizes $I$ by writing $f = \\chi f + \\psi f$ and hence $I = \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\chi f) \\, dx + \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\psi f) \\, dx$.\n- Argue why the second integral is taken entirely over a region where $\\ln|x|$ is smooth and can be treated by classical integration by parts without producing any singular contribution.\n- For the first integral, justify rigorously how to isolate the singularity in a ball by introducing a small radius $\\varepsilon > 0$, restricting the domain to an annulus, and applying the divergence theorem (integration by parts) to reduce the computation to a boundary term on $\\partial B(0,\\varepsilon)$. Carefully take the limit as $\\varepsilon \\to 0$.\nCompute the exact value of $I$. Express the final answer in exact form.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective before a solution is attempted.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Sets:** The space is $\\mathbb{R}^{2}$. The open cover is $\\{U_{1}, U_{2}\\}$ where $U_{1} = B(0,2)$ and $U_{2} = \\mathbb{R}^{2} \\setminus \\overline{B(0,1)}$.\n- **Partition of Unity:** A function $\\chi \\in C_{c}^{\\infty}(\\mathbb{R}^{2})$ is given with properties: $0 \\leq \\chi \\leq 1$; $\\chi \\equiv 1$ on $B(0,1)$; and $\\mathrm{supp}(\\chi) \\subset B(0,2)$. A second function is defined as $\\psi := 1 - \\chi$. The pair $(\\chi, \\psi)$ is a partition of unity subordinate to $\\{U_{1}, U_{2}\\}$, satisfying $\\chi + \\psi \\equiv 1$, $\\mathrm{supp}(\\chi) \\subset U_{1}$, and $\\mathrm{supp}(\\psi) \\subset U_{2}$.\n- **Functions:** A singular kernel $x \\mapsto \\ln|x|$ and a smooth function $f(x) := \\exp(-|x|^{2})$.\n- **Integral:** The integral to be computed is $I := \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta f(x) \\, dx$.\n- **Methodology:** The solution must follow a prescribed path using the partition of unity to split the integral, analyzing each part separately, and carefully handling the singularity at the origin using a limiting argument based on the divergence theorem.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, using standard concepts from mathematical analysis, specifically the theory of distributions and partial differential equations on Euclidean space. The kernel $\\ln|x|$ is proportional to the fundamental solution of the Laplace operator in two dimensions. The function $f(x)$ is a Gaussian, which is a smooth function that decays rapidly at infinity. The partition of unity is a standard tool to localize problems in analysis on manifolds. All definitions are standard and consistent. For instance, the property $\\mathrm{supp}(\\psi) \\subset U_{2}$ is consistent with the definitions of $\\psi$ and $\\chi$. Since $\\chi \\in C_c^\\infty(\\mathbb{R}^2)$ and $\\chi \\equiv 1$ on $B(0,1)$, continuity implies $\\chi \\equiv 1$ on $\\overline{B(0,1)}$. Thus $\\psi = 1-\\chi \\equiv 0$ on $\\overline{B(0,1)}$. The support of $\\psi$ is the closure of $\\{x | \\psi(x) \\neq 0\\}$, which is therefore contained in $\\mathbb{R}^2 \\setminus \\overline{B(0,1)} = U_2$. The problem is well-posed, objective, and contains no ambiguities or contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided following the specified methodology.\n\n### Solution\n\nThe value to compute is the integral $I := \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta f(x) \\, dx$, where $f(x) = \\exp(-|x|^{2})$. The integral is improper due to the singularity of $\\ln|x|$ at $x=0$. We use the provided partition of unity $(\\chi, \\psi)$ to analyze the integral.\n\nFirst, we decompose the function $f$ using the partition of unity: $f(x) = 1 \\cdot f(x) = (\\chi(x) + \\psi(x))f(x) = \\chi(x)f(x) + \\psi(x)f(x)$. By the linearity of the Laplacian operator $\\Delta$ and the integral, we can write $I$ as the sum of two integrals:\n$$\nI = \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\chi f)(x) \\, dx + \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\psi f)(x) \\, dx =: I_{1} + I_{2}.\n$$\nThis decomposition localizes the problem. The first integral, $I_{1}$, involves a function $\\chi f$ with support near the origin, thus containing the singularity of $\\ln|x|$. The second integral, $I_{2}$, involves a function $\\psi f$ whose support is away from the origin, thus avoiding the singularity.\n\nLet's analyze the second integral, $I_{2}$. The integrand is $\\ln|x| \\Delta(\\psi f)(x)$. The support of the function $\\psi f$ is contained in $\\mathrm{supp}(\\psi)$. We are given that $\\mathrm{supp}(\\psi) \\subset U_{2} = \\mathbb{R}^{2} \\setminus \\overline{B(0,1)}$. This means that for any $x$ in the domain of integration of $I_{2}$, we have $|x| > 1$. In this region, the function $x \\mapsto \\ln|x|$ is smooth ($C^{\\infty}$). The function $\\psi f$ is smooth and has compact support. Let $g(x) := (\\psi f)(x)$. Then $I_{2} = \\int_{\\mathbb{R}^2} \\ln|x| \\Delta g(x) dx$. We can use Green's second identity, which states that for smooth functions $u$ and $v$ where at least one has compact support, $\\int_{\\mathbb{R}^2} (u \\Delta v - v \\Delta u) dx = 0$. Let $u(x) = \\ln|x|$ and $v(x) = g(x)$. Then,\n$$\nI_{2} = \\int_{\\mathbb{R}^{2}} g(x) \\Delta(\\ln|x|) \\, dx.\n$$\nWe compute the Laplacian of $\\ln|x|$ for $x \\neq 0$. Let $r = |x| = \\sqrt{x_{1}^{2} + x_{2}^{2}}$. Then $\\ln|x| = \\ln r$. The gradient is $\\nabla(\\ln r) = \\frac{x}{r^{2}}$. The Laplacian is $\\Delta(\\ln r) = \\nabla \\cdot \\nabla(\\ln r) = \\nabla \\cdot (\\frac{x}{r^2})$. In Cartesian coordinates,\n$$\n\\Delta(\\ln r) = \\frac{\\partial^{2}}{\\partial x_{1}^{2}}(\\ln r) + \\frac{\\partial^{2}}{\\partial x_{2}^{2}}(\\ln r) = \\frac{r^{2} - 2x_{1}^{2}}{r^{4}} + \\frac{r^{2} - 2x_{2}^{2}}{r^{4}} = \\frac{2r^{2} - 2(x_{1}^{2}+x_{2}^{2})}{r^{4}} = \\frac{2r^{2}-2r^{2}}{r^{4}} = 0.\n$$\nSince the support of $g(x)=\\psi f(x)$ is contained in the region where $|x|>1$, the origin $x=0$ is excluded. Thus, $\\Delta(\\ln|x|)=0$ everywhere on the support of the integrand of $I_{2}$. Consequently,\n$$\nI_{2} = \\int_{\\mathbb{R}^{2}} g(x) \\cdot 0 \\, dx = 0.\n$$\n\nNow we focus on the first integral, $I_{1} = \\int_{\\mathbb{R}^{2}} \\ln|x| \\, \\Delta(\\chi f)(x) \\, dx$. Let $h(x) := (\\chi f)(x)$. The function $h(x)$ is smooth and has compact support contained in $\\mathrm{supp}(\\chi) \\subset B(0,2)$. The singularity of $\\ln|x|$ at $x=0$ lies within the support of $h(x)$, since $\\chi \\equiv 1$ on $B(0,1)$. To evaluate $I_{1}$, we must regularize the integral by excising a small ball of radius $\\varepsilon > 0$ around the origin. Let $D_{\\varepsilon} = B(0,R) \\setminus \\overline{B(0,\\varepsilon)}$, where $R=2$ so that $\\mathrm{supp}(h) \\subset B(0,2)$. Then,\n$$\nI_{1} = \\lim_{\\varepsilon \\to 0} \\int_{D_{\\varepsilon}} \\ln|x| \\, \\Delta h(x) \\, dx.\n$$\nWe apply Green's second identity on the domain $D_{\\varepsilon}$ to the functions $u(x)=\\ln|x|$ and $v(x)=h(x)$. On $D_{\\varepsilon}$, $\\Delta u = \\Delta(\\ln|x|) = 0$.\n$$\n\\int_{D_{\\varepsilon}} u \\Delta v \\, dx = \\int_{\\partial D_{\\varepsilon}} (u \\nabla v - v \\nabla u) \\cdot n \\, dS,\n$$\nwhere $n$ is the outward unit normal vector to the boundary $\\partial D_{\\varepsilon}$. The boundary consists of two parts: $\\partial B(0,2)$ and $\\partial B(0,\\varepsilon)$.\nThe support of $h(x)$ is contained strictly within $B(0,2)$, so $h$ and its derivatives are zero on $\\partial B(0,2)$. Therefore, the boundary integral over $\\partial B(0,2)$ vanishes.\nWe are left with the integral over $\\partial B(0,\\varepsilon)$. On this boundary, the outward normal vector from $D_{\\varepsilon}$ points towards the origin, so $n = -x/|x| = -x/\\varepsilon$.\n\\begin{align*}\n\\int_{D_{\\varepsilon}} \\ln|x| \\Delta h(x) \\, dx &= \\int_{\\partial B(0,\\varepsilon)} (\\ln|x| \\nabla h(x) - h(x) \\nabla\\ln|x|) \\cdot \\left(-\\frac{x}{\\varepsilon}\\right) \\, dS \\\\\n&= -\\int_{\\partial B(0,\\varepsilon)} \\ln(\\varepsilon) (\\nabla h(x) \\cdot \\frac{x}{\\varepsilon}) \\, dS + \\int_{\\partial B(0,\\varepsilon)} h(x) (\\nabla\\ln|x| \\cdot \\frac{x}{\\varepsilon}) \\, dS.\n\\end{align*}\nLet's analyze these two terms in the limit $\\varepsilon \\to 0$.\nFor the first term, since $h(x)$ is smooth, its gradient $\\nabla h(x)$ is bounded near the origin. Let $M$ be an upper bound for $|\\nabla h(x) \\cdot x/\\varepsilon|$ on $\\partial B(0,\\varepsilon)$. The magnitude of this term is bounded by $|\\ln(\\varepsilon)| \\cdot M \\cdot (2\\pi\\varepsilon)$, which is proportional to $\\varepsilon \\ln \\varepsilon$. As $\\varepsilon \\to 0$, $\\lim_{\\varepsilon \\to 0} \\varepsilon \\ln \\varepsilon = 0$. So, the first term vanishes in the limit.\nFor the second term, we have $\\nabla\\ln|x| = \\nabla\\ln r = x/r^{2}$. On $\\partial B(0,\\varepsilon)$, $r=\\varepsilon$, so $\\nabla\\ln|x| = x/\\varepsilon^2$. The dot product is $\\nabla\\ln|x| \\cdot (x/\\varepsilon) = (x/\\varepsilon^2) \\cdot (x/\\varepsilon) = |x|^2/\\varepsilon^3 = \\varepsilon^2/\\varepsilon^3 = 1/\\varepsilon$.\nThe integral becomes:\n$$\n\\int_{\\partial B(0,\\varepsilon)} h(x) \\frac{1}{\\varepsilon} \\, dS = \\frac{1}{\\varepsilon} \\int_{\\partial B(0,\\varepsilon)} h(x) \\, dS.\n$$\nBy the Mean Value Theorem for integrals, there exists a point $x_{\\varepsilon} \\in \\partial B(0,\\varepsilon)$ such that $\\int_{\\partial B(0,\\varepsilon)} h(x) \\, dS = h(x_{\\varepsilon}) \\cdot (\\text{length of } \\partial B(0,\\varepsilon)) = h(x_{\\varepsilon}) \\cdot 2\\pi\\varepsilon$.\nSo, the second term is $\\frac{1}{\\varepsilon} (h(x_{\\varepsilon}) \\cdot 2\\pi\\varepsilon) = 2\\pi h(x_{\\varepsilon})$.\nAs $\\varepsilon \\to 0$, $x_{\\varepsilon} \\to 0$. Since $h(x)$ is continuous, $\\lim_{\\varepsilon \\to 0} h(x_{\\varepsilon}) = h(0)$.\nThe limit of the second term is $2\\pi h(0)$.\nWe calculate $h(0) = (\\chi f)(0) = \\chi(0)f(0)$. By definition, $\\chi(0)=1$ because $0 \\in B(0,1)$. Also, $f(0)=\\exp(-|0|^2)=1$. Thus, $h(0)=1 \\cdot 1 = 1$.\nTherefore, $I_{1} = \\lim_{\\varepsilon \\to 0} (0 + 2\\pi h(x_{\\varepsilon})) = 2\\pi h(0) = 2\\pi$.\n\nFinally, we combine the results for $I_{1}$ and $I_{2}$:\n$$\nI = I_{1} + I_{2} = 2\\pi + 0 = 2\\pi.\n$$", "answer": "$$\\boxed{2\\pi}$$", "id": "3058995"}, {"introduction": "Beyond dissecting problems, partitions of unity are also indispensable for synthesis: patching local information into a coherent global structure. This is the essence of many constructions in differential geometry and modern analysis. This exercise explores this \"globalization\" principle by showing how you can construct a global, smooth approximation of a function by \"gluing\" together its local Taylor polynomial approximations using a partition of unity as the \"mortar\". [@problem_id:3058980]", "problem": "Let $K \\subset \\mathbb{R}^n$ be compact, let $k \\in \\mathbb{N}$, and let $f \\in C^k(U)$ on an open neighborhood $U \\supset K$. Consider a locally finite open cover $\\{U_i\\}_{i \\in I}$ of $K$ by sets $U_i \\subset U$ and a partition of unity $\\{\\varphi_i\\}_{i \\in I}$ subordinate to this cover, meaning $\\varphi_i \\in C^\\infty_c(U_i)$, $\\varphi_i \\ge 0$, the family is locally finite, and $\\sum_{i \\in I} \\varphi_i \\equiv 1$ on $K$. Fix points $x_i \\in K \\cap U_i$ and let $P_i$ denote the degree-$k$ Taylor polynomial of $f$ at $x_i$ (in the sense that all partial derivatives of $P_i$ up to order $k$ at $x_i$ match those of $f$). Define the patched function\n$$\nF(x) := \\sum_{i \\in I} \\varphi_i(x)\\, P_i(x), \\quad x \\in K.\n$$\nYou may assume standard facts: partitions of unity subordinate to locally finite covers exist in $\\mathbb{R}^n$; Taylor polynomials exist for $C^k$ functions; and all derivatives are taken in the classical sense.\n\nWhich of the following statements are true? Select all that apply.\n\nA. Suppose $f \\in C^{k+1}(U)$. For any $\\varepsilon>0$ there exist a locally finite cover of $K$ by balls $\\{B_i\\}$ with radii $r_i<\\varepsilon$ and a smooth partition of unity $\\{\\varphi_i\\}$ subordinate to $\\{B_i\\}$, points $x_i \\in K \\cap B_i$, and associated degree-$k$ Taylor polynomials $P_i$ such that the patched function $F=\\sum_i \\varphi_i P_i$ satisfies\n$$\n\\sup_{|\\alpha|\\le k}\\, \\|\\partial^\\alpha(f-F)\\|_{L^\\infty(K)} \\le C\\, \\varepsilon,\n$$\nfor a constant $C$ depending only on $n$, $k$, and $\\sup_{|\\beta|=k+1}\\|\\partial^\\beta f\\|_{L^\\infty(U)}$.\n\nB. With the same setup, $F$ equals $f$ on $K$ for any choice of subordinate partition of unity and centers $x_i$ as long as degree-$k$ Taylor polynomials are used, regardless of the size of the covering sets.\n\nC. The local finiteness of the partition of unity is not needed: even if infinitely many $\\varphi_i$ are nonzero at a point, the sum defining $F$ still makes sense and defines a smooth function on $K$.\n\nD. If the partition of unity $\\{\\varphi_i\\}$ is only of class $C^k$ (not necessarily smooth), then $F \\in C^k(K)$ provided $f \\in C^k(U)$.\n\nE. Suppose $f \\in C^k(U)$ and all partial derivatives of order $k$ are uniformly continuous on $U$. Then there exist subordinate covers whose sets have diameters bounded by $\\delta>0$ and corresponding partitions of unity such that, for the associated $F$, one has\n$$\n\\sup_{|\\alpha|\\le k}\\, \\|\\partial^\\alpha(f-F)\\|_{L^\\infty(K)} \\to 0 \\quad \\text{as } \\delta \\to 0.\n$$\n\nF. In the situation of A, the constant $C$ can be chosen independently of the particular choice of the subordinate partition of unity $\\{\\varphi_i\\}$ and the points $\\{x_i\\}$, depending only on $n$, $k$, and $\\sup_{|\\beta|=k+1}\\|\\partial^\\beta f\\|_{L^\\infty(U)}$.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n-   $K \\subset \\mathbb{R}^n$ is a compact set.\n-   $k \\in \\mathbb{N}$ is a natural number.\n-   $f \\in C^k(U)$ for an open neighborhood $U \\supset K$.\n-   $\\{U_i\\}_{i \\in I}$ is a locally finite open cover of $K$ with $U_i \\subset U$.\n-   $\\{\\varphi_i\\}_{i \\in I}$ is a partition of unity subordinate to the cover $\\{U_i\\}$.\n-   Properties of the partition of unity:\n    1.  $\\varphi_i \\in C^\\infty_c(U_i)$ (infinitely differentiable with compact support contained in $U_i$).\n    2.  $\\varphi_i(x) \\ge 0$ for all $x$.\n    3.  The family of functions $\\{\\varphi_i\\}_{i \\in I}$ is locally finite.\n    4.  $\\sum_{i \\in I} \\varphi_i(x) = 1$ for all $x \\in K$.\n-   $x_i \\in K \\cap U_i$ are specified points.\n-   $P_i$ is the Taylor polynomial of degree $k$ of the function $f$ centered at the point $x_i$.\n-   A new function $F$ is defined on $K$ by the formula $F(x) := \\sum_{i \\in I} \\varphi_i(x)\\, P_i(x)$.\n-   Standard existence theorems for partitions of unity and Taylor polynomials are assumed.\n\n### Step 2: Validate Using Extracted Givens\nThe problem setup describes a classic construction in mathematical analysis, specifically in the theory of function approximation and extension on Euclidean spaces and manifolds. This construction is often referred to as a Whitney-type approximation or extension.\n\n-   **Scientifically Grounded:** The problem is firmly rooted in the principles of real and functional analysis. All conceptsâcompactness, $C^k$ functions, partitions of unity, Taylor polynomialsâare standard and rigorously defined in mathematics. The construction of the function $F$ is a well-known technique.\n-   **Well-Posed:** The function $F(x)$ is well-defined. Due to the local finiteness of the family $\\{\\varphi_i\\}$, the sum defining $F(x)$ is a finite sum in a neighborhood of any point $x \\in \\mathbb{R}^n$. Since all $\\varphi_i$ and $P_i$ are smooth, $F$ is a smooth function on $\\mathbb{R}^n$. The questions posed are about the properties of $F$ on the set $K$, which are meaningful and analyzable questions.\n-   **Objective:** The language is precise mathematical terminology. There are no subjective or ambiguous statements in the problem's setup.\n-   **Consistency and Completeness:** The provided information is self-consistent and sufficient to define the object of study, $F(x)$, and to analyze its relationship with $f(x)$.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. It describes a standard, well-defined mathematical construction and asks precise questions about its properties. The solution process will now proceed.\n\n### Solution Derivation\nThe core of the problem is to analyze the error function $f(x) - F(x)$ and its derivatives on the compact set $K$.\nUsing the property $\\sum_{i \\in I} \\varphi_i(x) = 1$ for all $x \\in K$, we can write $f(x)$ as:\n$$\nf(x) = f(x) \\cdot 1 = f(x) \\sum_{i \\in I} \\varphi_i(x) = \\sum_{i \\in I} \\varphi_i(x) f(x).\n$$\nThe error is therefore:\n$$\nf(x) - F(x) = \\sum_{i \\in I} \\varphi_i(x) f(x) - \\sum_{i \\in I} \\varphi_i(x) P_i(x) = \\sum_{i \\in I} \\varphi_i(x) [f(x) - P_i(x)].\n$$\nLet $R_i(x) = f(x) - P_i(x)$ be the remainder of the degree-$k$ Taylor expansion of $f$ at $x_i$. By definition of the Taylor polynomial $P_i$, we have that $\\partial^\\alpha R_i(x_i) = 0$ for all multi-indices $\\alpha$ with $|\\alpha| \\le k$.\n\nTo estimate the derivatives of the error, we use the Leibniz rule for a multi-index $\\alpha$:\n$$\n\\partial^\\alpha (f(x) - F(x)) = \\partial^\\alpha \\left( \\sum_{i \\in I} \\varphi_i(x) R_i(x) \\right).\n$$\nSince the sum is locally finite, we can interchange differentiation and summation:\n$$\n\\partial^\\alpha (f(x) - F(x)) = \\sum_{i \\in I} \\partial^\\alpha (\\varphi_i(x) R_i(x)) = \\sum_{i \\in I} \\sum_{\\gamma \\le \\alpha} \\binom{\\alpha}{\\gamma} \\partial^{\\alpha-\\gamma}\\varphi_i(x) \\, \\partial^\\gamma R_i(x).\n$$\nThis formula is the basis for analyzing the options.\n\n---\n### Option-by-Option Analysis\n\n**A. Suppose $f \\in C^{k+1}(U)$. For any $\\varepsilon>0$ there exist a locally finite cover of $K$ by balls $\\{B_i\\}$ with radii $r_i<\\varepsilon$ and a smooth partition of unity $\\{\\varphi_i\\}$ subordinate to $\\{B_i\\}$, points $x_i \\in K \\cap B_i$, and associated degree-$k$ Taylor polynomials $P_i$ such that the patched function $F=\\sum_i \\varphi_i P_i$ satisfies $\\sup_{|\\alpha|\\le k}\\, \\|\\partial^\\alpha(f-F)\\|_{L^\\infty(K)} \\le C\\, \\varepsilon,$ for a constant $C$ depending only on $n$, $k$, and $\\sup_{|\\beta|=k+1}\\|\\partial^\\beta f\\|_{L^\\infty(U)}$.**\n\nThe proof of this statement relies on careful construction and estimation. We can cover the compact set $K$ by a finite number of balls $\\{B_i\\}$ with radii $r_i < \\varepsilon$. This cover is locally finite. We can then construct a subordinate partition of unity $\\{\\varphi_i\\}$ such that the derivatives of $\\varphi_i$ are controlled by the radii: for any multi-index $\\mu$, there is a constant $C_\\mu$ (depending on $\\mu$ and $n$) such that $\\|\\partial^\\mu \\varphi_i\\|_{L^\\infty} \\le C_\\mu r_i^{-|\\mu|}$.\n\nLet's estimate the terms in the sum for $\\partial^\\alpha(f-F)$, where $|\\alpha| \\le k$:\n1.  **Remainder term $\\partial^\\gamma R_i(x)$:** For $x \\in B_i$ and $x_i \\in B_i$, we have $|x - x_i| < 2r_i < 2\\varepsilon$. The function $\\partial^\\gamma R_i(x) = \\partial^\\gamma f(x) - \\partial^\\gamma P_i(x)$ is the remainder term for the Taylor expansion of $\\partial^\\gamma f$ of order $k-|\\gamma|$. Since $f \\in C^{k+1}$, Taylor's theorem provides the bound:\n    $$\n    |\\partial^\\gamma R_i(x)| \\le C_{\\gamma, k} \\sup_{|\\beta|=k+1, y \\in B_i} |\\partial^\\beta f(y)| \\cdot |x-x_i|^{k-|\\gamma|+1}.\n    $$\n    Let $M_{k+1} = \\sup_{|\\beta|=k+1}\\|\\partial^\\beta f\\|_{L^\\infty(U)}$. Since $x, x_i \\in B_i$ and radius $r_i < \\varepsilon$, we have $\\|\\partial^\\gamma R_i\\|_{L^\\infty(\\text{supp}(\\varphi_i))} \\le C_1 M_{k+1} \\varepsilon^{k-|\\gamma|+1}$.\n\n2.  **Partition of unity term $\\partial^{\\alpha-\\gamma}\\varphi_i(x)$:** As stated, we can construct $\\{\\varphi_i\\}$ such that $\\|\\partial^{\\alpha-\\gamma}\\varphi_i\\|_{L^\\infty} \\le C_2 \\varepsilon^{-|\\alpha-\\gamma|}$.\n\nCombining these, a single term in the sum is bounded by:\n$$\n\\|\\partial^{\\alpha-\\gamma}\\varphi_i\\|_{L^\\infty} \\|\\partial^\\gamma R_i\\|_{L^\\infty} \\le (C_2 \\varepsilon^{-|\\alpha-\\gamma|}) \\cdot (C_1 M_{k+1} \\varepsilon^{k-|\\gamma|+1}) = C_3 M_{k+1} \\varepsilon^{k-|\\alpha|+1}.\n$$\nThe exponent $k-|\\alpha|+1 \\ge 1$ because $|\\alpha| \\le k$.\nThe sum over $i$ is locally finite, and for a compact set $K$, we can choose the cover such that its multiplicity (maximum number of overlapping sets at any point) is bounded by a constant $N(n)$ depending only on the dimension $n$.\nSumming all contributions, we get:\n$$\n\\|\\partial^\\alpha(f-F)\\|_{L^\\infty(K)} \\le N(n) \\cdot (\\text{number of } \\gamma \\le \\alpha) \\cdot \\max_{\\gamma \\le \\alpha} (C_3 M_{k+1} \\varepsilon^{k-|\\alpha|+1}).\n$$\nThe overall bound is of the form $C_{n,k} M_{k+1} \\varepsilon^{k-|\\alpha|+1}$. The worst case is when the exponent of $\\varepsilon$ is smallest, which is $1$ (for $|\\alpha|=k$). Thus, for all $|\\alpha| \\le k$, the error is bounded by $C \\varepsilon$. The constant $C$ depends on $n,k,$ and $M_{k+1}$. This confirms the statement.\n\nVerdict: **Correct**.\n\n**B. With the same setup, $F$ equals $f$ on $K$ for any choice of subordinate partition of unity and centers $x_i$ as long as degree-$k$ Taylor polynomials are used, regardless of the size of the covering sets.**\n\nThis statement claims that $F(x) = f(x)$ for all $x \\in K$. This would mean the error $f(x)-F(x) = \\sum_i \\varphi_i(x)R_i(x)$ is identically zero on $K$. The remainder term $R_i(x) = f(x) - P_i(x)$ is not generally zero for $x \\neq x_i$.\nConsider a simple counterexample. Let $n=1$, $K=[0,1]$, $k=0$, and $f(x)=x^2$. A degree-$0$ Taylor polynomial at $x_i$ is $P_i(x) = f(x_i) = x_i^2$.\nThe patched function is $F(x) = \\sum_i \\varphi_i(x) x_i^2$.\nLet's use a cover $U_1 = (-1, 0.6)$, $U_2 = (0.4, 2)$, with centers $x_1=0 \\in K \\cap U_1$ and $x_2=1 \\in K \\cap U_2$. Then $P_1(x) = 0^2 = 0$ and $P_2(x) = 1^2 = 1$. Let $\\{\\varphi_1, \\varphi_2\\}$ be a subordinate partition of unity.\nOn $K=[0,1]$, we have $\\varphi_1(x)+\\varphi_2(x)=1$.\n$F(x) = \\varphi_1(x) \\cdot 0 + \\varphi_2(x) \\cdot 1 = \\varphi_2(x)$.\nThe statement implies $F(x) = f(x)$, i.e., $\\varphi_2(x) = x^2$ for all $x \\in [0,1]$.\nHowever, a standard construction of $\\varphi_2$ would have $\\text{supp}(\\varphi_2) \\subset U_2=(0.4, 2)$, so $\\varphi_2(x)$ must be $0$ for $x \\le 0.4$. This contradicts $\\varphi_2(x)=x^2$ (e.g., at $x=0.1$, $0 \\neq 0.01$).\nIn general, $F(x)$ is an approximation of $f(x)$, not an exact replica, unless $f$ itself is a polynomial of degree at most $k$.\n\nVerdict: **Incorrect**.\n\n**C. The local finiteness of the partition of unity is not needed: even if infinitely many $\\varphi_i$ are nonzero at a point, the sum defining $F$ still makes sense and defines a smooth function on $K$.**\n\nLocal finiteness ensures that for any point $x$, there is a neighborhood where the sum $F(x) = \\sum_i \\varphi_i(x)P_i(x)$ is a finite sum. A finite sum of smooth ($C^\\infty$) functions is smooth. If the family $\\{\\varphi_i\\}$ is not locally finite, then at some point $x_0$, the sum for $F(x_0)$ may be an infinite series. Even if this series converges (which it does for $x \\in K$ since $\\sum \\varphi_i(x) = 1$ and the polynomials $P_i(x)$ are bounded on the compact set $K$), the smoothness of the sum is not guaranteed. To check for smoothness, one must differentiate the series term-by-term: $\\partial^\\alpha F(x) = \\sum_i \\partial^\\alpha(\\varphi_i(x)P_i(x))$. The convergence of this new series is not guaranteed. For instance, if the supports of $\\varphi_i$ become progressively smaller, the magnitudes of their derivatives can grow without bound, potentially causing the series of derivatives to diverge. Local finiteness is the standard condition that circumvents this issue and guarantees smoothness.\n\nVerdict: **Incorrect**.\n\n**D. If the partition of unity $\\{\\varphi_i\\}$ is only of class $C^k$ (not necessarily smooth), then $F \\in C^k(K)$ provided $f \\in C^k(U)$.**\n\nThis option modifies the initial setup, assuming $\\varphi_i \\in C^k_c(U_i)$. The function $F(x)$ is defined as $F(x) = \\sum_{i \\in I} \\varphi_i(x) P_i(x)$. The family $\\{\\varphi_i\\}$ is still locally finite.\nFor any point $x_0 \\in K$, there exists an open neighborhood $V$ of $x_0$ and a finite set of indices $I_0 \\subset I$ such that for any $x \\in V$, $F(x) = \\sum_{i \\in I_0} \\varphi_i(x) P_i(x)$.\n-   Each $\\varphi_i$ is, by this option's hypothesis, a $C^k$ function.\n-   Each $P_i(x)$ is a polynomial, which is a $C^\\infty$ (and thus $C^k$) function.\n-   The product of a $C^k$ function and a $C^\\infty$ function is a $C^k$ function. Thus, each term $\\varphi_i(x) P_i(x)$ is of class $C^k$.\n-   A finite sum of $C^k$ functions is a $C^k$ function.\nTherefore, $F(x)$ is of class $C^k$ on the neighborhood $V$. Since this holds for any $x_0 \\in K$, the function $F$ is of class $C^k$ on $K$. The condition $f \\in C^k(U)$ is necessary to ensure the degree-$k$ Taylor polynomials $P_i$ are well-defined.\n\nVerdict: **Correct**.\n\n**E. Suppose $f \\in C^k(U)$ and all partial derivatives of order $k$ are uniformly continuous on $U$. Then there exist subordinate covers whose sets have diameters bounded by $\\delta>0$ and corresponding partitions of unity such that, for the associated $F$, one has $\\sup_{|\\alpha|\\le k}\\, \\|\\partial^\\alpha(f-F)\\|_{L^\\infty(K)} \\to 0 \\quad \\text{as } \\delta \\to 0.$**\n\nThis is a more general version of the approximation result in A. The condition $f \\in C^{k+1}$ is relaxed to uniform continuity of the $k$-th order derivatives. Let $\\omega(\\delta)$ be the modulus of continuity for all partial derivatives of $f$ of order $k$ on $U$. Uniform continuity means $\\omega(\\delta) \\to 0$ as $\\delta \\to 0$.\nFollowing the analysis for A, we estimate $\\|\\partial^\\gamma R_i\\|_{L^\\infty(\\text{supp}(\\varphi_i))}$ for $|\\gamma| \\le k$ and $\\text{diam}(U_i) \\le \\delta$.\nUsing a more refined version of Taylor's theorem, the remainder can be bounded using the modulus of continuity. For a function $g$ whose $m$-th derivatives have modulus of continuity $\\omega_m$, the error of the Taylor polynomial of degree $m-1$ is bounded by $C|x-x_i|^m \\omega_m(|x-x_i|)$.\nHere, for $g = \\partial^\\gamma f$, we consider its Taylor expansion of order $k-|\\gamma|-1$. The relevant derivatives are of order $k-|\\gamma|$ on $g$, which are order $k$ on $f$.\nThis leads to the estimate: $\\|\\partial^\\gamma R_i\\|_{L^\\infty(U_i)} \\le C' \\delta^{k-|\\gamma|} \\omega(\\delta)$.\nThe derivative of the partition of unity scales as $\\|\\partial^{\\alpha-\\gamma} \\varphi_i\\|_{L^\\infty} \\le C'' \\delta^{-|\\alpha-\\gamma|}$.\nCombining these, each component of the error derivative is bounded by a term of the form:\n$$\n(C'' \\delta^{-|\\alpha-\\gamma|}) \\cdot (C' \\delta^{k-|\\gamma|} \\omega(\\delta)) = C \\delta^{k-|\\alpha|} \\omega(\\delta).\n$$\nSince $|\\alpha| \\le k$, the exponent of $\\delta$ is non-negative. As $\\delta \\to 0$, $\\omega(\\delta) \\to 0$, and thus the entire expression approaches $0$. This holds for all $|\\alpha| \\le k$.\nThis establishes the convergence to $0$ in the $C^k$ norm on $K$.\n\nVerdict: **Correct**.\n\n**F. In the situation of A, the constant $C$ can be chosen independently of the particular choice of the subordinate partition of unity $\\{\\varphi_i\\}$ and the points $\\{x_i\\}$, depending only on $n$, $k$, and $\\sup_{|\\beta|=k+1}\\|\\partial^\\beta f\\|_{L^\\infty(U)}$.**\n\nThis statement claims that the constant $C$ in the inequality of option A is universal for any valid choice of partition of unity and center points, given a cover by balls of radii less than $\\varepsilon$.\nThe derivation of the bound in A depended on an estimate for the derivatives of the partition of unity functions: $\\|\\partial^\\mu \\varphi_i\\|_{L^\\infty} \\le C_\\mu r_i^{-|\\mu|}$. This bound is true for *some* constructions of partitions of unity (the \"standard\" ones), but not for *all*.\nFor a fixed open cover $\\{U_i\\}$, the set of subordinate partitions of unity is large. It is possible to construct partitions of unity with derivatives of arbitrarily large magnitude. For example, one can add a small, rapidly oscillating function with zero integral to one $\\varphi_i$ and subtract it from another $\\varphi_j$ (where supports overlap), maintaining the partition of unity properties but dramatically increasing the derivative norms.\nThe error bound $\\left\\|\\partial^\\alpha(f-F)\\right\\|_{L^\\infty}$ explicitly depends on the norms of the derivatives of the $\\varphi_i$ functions, as seen in the main formula $\\sum_i \\sum_{\\gamma \\le \\alpha} \\binom{\\alpha}{\\gamma} \\partial^{\\alpha-\\gamma}\\varphi_i \\, \\partial^\\gamma R_i$. If $\\|\\partial^{\\alpha-\\gamma}\\varphi_i\\|_{L^\\infty}$ can be arbitrarily large, then the constant $C$ in the final inequality cannot be independent of the choice of $\\{\\varphi_i\\}$.\nThe choice of points $x_i$ has a less dramatic, but still present, effect on the local error constants, though the main dependence is on the properties of $\\{\\varphi_i\\}$. The primary reason this statement fails is the dependence on the partition of unity.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{ADE}$$", "id": "3058980"}]}