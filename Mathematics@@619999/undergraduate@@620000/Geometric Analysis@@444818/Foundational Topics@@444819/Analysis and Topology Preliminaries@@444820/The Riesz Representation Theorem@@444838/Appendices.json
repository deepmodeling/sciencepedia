{"hands_on_practices": [{"introduction": "The Riesz Representation Theorem provides a powerful link between the geometric structure of a Hilbert space and the analytic objects of linear functionals. In a finite-dimensional setting like $\\mathbb{R}^n$, the theorem guarantees that every linear functional can be visualized as taking an inner product with a unique, fixed vector. This exercise makes the abstract theorem concrete, guiding you to find this representing vector by translating the functional's properties into a familiar system of linear equations [@problem_id:3075091].", "problem": "Let $H$ be the real Hilbert space $\\mathbb{R}^{4}$ equipped with the standard Euclidean inner product $\\langle x, y \\rangle = \\sum_{i=1}^{4} x_{i} y_{i}$. Let $\\{e_{1}, e_{2}, e_{3}, e_{4}\\}$ be the standard orthonormal basis of $H$. Consider a linear functional $f : H \\to \\mathbb{R}$ that satisfies the following values on certain vectors:\n- $f(e_{1} + e_{2}) = 2$,\n- $f(e_{1} - e_{3}) = 1$,\n- $f(2 e_{2} + e_{4}) = 7$,\n- $f(e_{1} + e_{2} + e_{3} + e_{4}) = 5$.\nBy the Riesz representation theorem, there exists a unique vector $y \\in H$ such that $f(x) = \\langle x, y \\rangle$ for all $x \\in H$. Determine the coordinate vector of $y$ with respect to the orthonormal basis $\\{e_{1}, e_{2}, e_{3}, e_{4}\\}$. Express your final answer as an exact vector without approximation.", "solution": "The problem is well-posed and scientifically grounded. It presents a standard application of the Riesz representation theorem in a finite-dimensional Hilbert space. The given information is sufficient and consistent to determine a unique solution.\n\nLet $H$ be the real Hilbert space $\\mathbb{R}^{4}$ with the standard inner product $\\langle x, y \\rangle = \\sum_{i=1}^{4} x_{i} y_{i}$. The set $\\{e_{1}, e_{2}, e_{3}, e_{4}\\}$ is the standard orthonormal basis for $H$, where $e_{1} = (1, 0, 0, 0)$, $e_{2} = (0, 1, 0, 0)$, etc.\n\nThe Riesz representation theorem states that for any continuous linear functional $f: H \\to \\mathbb{R}$, there exists a unique vector $y \\in H$ such that $f(x) = \\langle x, y \\rangle$ for all $x \\in H$. Since every linear functional on a finite-dimensional Hilbert space is continuous, the theorem applies.\n\nOur goal is to find this unique vector $y$. We can express $y$ in terms of the standard basis:\n$$y = y_{1}e_{1} + y_{2}e_{2} + y_{3}e_{3} + y_{4}e_{4}$$\nwhere $(y_{1}, y_{2}, y_{3}, y_{4})$ are the coordinates of $y$ that we need to determine.\n\nThe defining property of $y$ is $f(x) = \\langle x, y \\rangle$. Since the basis $\\{e_i\\}$ is orthonormal, the components of $y$ are given by $y_i = \\langle y, e_i \\rangle$. Using the symmetry of the real inner product, $y_i = \\langle e_i, y \\rangle$. From the Riesz representation, we also have $f(e_i) = \\langle e_i, y \\rangle$. Therefore, the components of $y$ are simply the values of the functional $f$ on the basis vectors: $y_i = f(e_i)$.\n\nWe are given the values of $f$ on four specific vectors. Since $f$ is a linear functional, we can use these values to set up a system of linear equations for the unknowns $y_{1}, y_{2}, y_{3}, y_{4}$. We also use the linearity of the inner product.\n\nThe given conditions are:\n$1.$ $f(e_{1} + e_{2}) = 2$\n$2.$ $f(e_{1} - e_{3}) = 1$\n$3.$ $f(2 e_{2} + e_{4}) = 7$\n$4.$ $f(e_{1} + e_{2} + e_{3} + e_{4}) = 5$\n\nLet's translate each condition using the representation $f(x) = \\langle x, y \\rangle$:\n\n$1.$ $f(e_{1} + e_{2}) = \\langle e_{1} + e_{2}, y \\rangle = \\langle e_{1}, y \\rangle + \\langle e_{2}, y \\rangle = y_{1} + y_{2}$.\nThus, we have the equation:\n$$y_{1} + y_{2} = 2 \\quad (I)$$\n\n$2.$ $f(e_{1} - e_{3}) = \\langle e_{1} - e_{3}, y \\rangle = \\langle e_{1}, y \\rangle - \\langle e_{3}, y \\rangle = y_{1} - y_{3}$.\nThis gives:\n$$y_{1} - y_{3} = 1 \\quad (II)$$\n\n$3.$ $f(2 e_{2} + e_{4}) = \\langle 2 e_{2} + e_{4}, y \\rangle = 2\\langle e_{2}, y \\rangle + \\langle e_{4}, y \\rangle = 2y_{2} + y_{4}$.\nThis gives:\n$$2y_{2} + y_{4} = 7 \\quad (III)$$\n\n$4.$ $f(e_{1} + e_{2} + e_{3} + e_{4}) = \\langle e_{1} + e_{2} + e_{3} + e_{4}, y \\rangle = y_1 + y_2 + y_3 + y_4$.\nThis gives:\n$$y_{1} + y_{2} + y_{3} + y_{4} = 5 \\quad (IV)$$\n\nWe now have a system of four linear equations for the four unknowns $y_{1}, y_{2}, y_{3}, y_{4}$. We can solve this system.\n\nFrom equation $(I)$, we know $y_{1} + y_{2} = 2$. Substituting this into equation $(IV)$:\n$$(y_{1} + y_{2}) + y_{3} + y_{4} = 5$$\n$$2 + y_{3} + y_{4} = 5$$\n$$y_{3} + y_{4} = 3 \\quad (V)$$\n\nNow we can express $y_3$ and $y_4$ in terms of $y_1$ and $y_2$ and substitute them into equation $(V)$.\nFrom $(II)$, we have $y_{3} = y_{1} - 1$.\nFrom $(III)$, we have $y_{4} = 7 - 2y_{2}$.\n\nSubstitute these into $(V)$:\n$$(y_{1} - 1) + (7 - 2y_{2}) = 3$$\n$$y_{1} - 2y_{2} + 6 = 3$$\n$$y_{1} - 2y_{2} = -3 \\quad (VI)$$\n\nNow we have a system of two equations for $y_{1}$ and $y_{2}$:\n$$y_{1} + y_{2} = 2 \\quad (I)$$\n$$y_{1} - 2y_{2} = -3 \\quad (VI)$$\n\nSubtract equation $(VI)$ from equation $(I)$:\n$$(y_{1} + y_{2}) - (y_{1} - 2y_{2}) = 2 - (-3)$$\n$$3y_{2} = 5$$\n$$y_{2} = \\frac{5}{3}$$\n\nSubstitute the value of $y_{2}$ back into equation $(I)$:\n$$y_{1} + \\frac{5}{3} = 2$$\n$$y_{1} = 2 - \\frac{5}{3} = \\frac{6}{3} - \\frac{5}{3} = \\frac{1}{3}$$\n\nNow we can find $y_{3}$ and $y_{4}$ using their relations to $y_{1}$ and $y_{2}$.\nUsing $y_{3} = y_{1} - 1$:\n$$y_{3} = \\frac{1}{3} - 1 = \\frac{1}{3} - \\frac{3}{3} = -\\frac{2}{3}$$\n\nUsing $y_{4} = 7 - 2y_{2}$:\n$$y_{4} = 7 - 2\\left(\\frac{5}{3}\\right) = 7 - \\frac{10}{3} = \\frac{21}{3} - \\frac{10}{3} = \\frac{11}{3}$$\n\nSo, the coordinates of the vector $y$ are $(y_{1}, y_{2}, y_{3}, y_{4}) = (\\frac{1}{3}, \\frac{5}{3}, -\\frac{2}{3}, \\frac{11}{3})$.\nThe unique vector $y \\in H$ is given by:\n$$y = \\frac{1}{3}e_{1} + \\frac{5}{3}e_{2} - \\frac{2}{3}e_{3} + \\frac{11}{3}e_{4}$$\n\nThe coordinate vector of $y$ with respect to the standard orthonormal basis is $(\\frac{1}{3}, \\frac{5}{3}, -\\frac{2}{3}, \\frac{11}{3})$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{3}  \\frac{5}{3}  -\\frac{2}{3}  \\frac{11}{3} \\end{pmatrix}}\n$$", "id": "3075091"}, {"introduction": "Moving from finite dimensions to the infinite-dimensional world of function spaces, we explore a crucial consequence of the theorem: the correspondence between a functional and its representing vector is an isometry. This means the operator norm of the functional is precisely equal to the norm of the vector that represents it. This practice asks you to verify this fundamental property in the space $L^2$, demonstrating how the \"size\" of the functional is perfectly captured by the $L^2$ norm of its representing function [@problem_id:3075104].", "problem": "Let $X$ be the unit circle $\\mathbb{S}^{1}$ parametrized by $\\theta \\in [0,2\\pi]$ with its standard Lebesgue measure $d\\theta$, and let $L^{2}(X)$ denote the real $L^{2}$ space with inner product $\\langle h,k\\rangle = \\int_{0}^{2\\pi} h(\\theta)k(\\theta)\\, d\\theta$ and norm $\\|h\\|_{L^{2}} = \\left( \\int_{0}^{2\\pi} |h(\\theta)|^{2}\\, d\\theta \\right)^{1/2}$. Consider the linear functional $f:L^{2}(X)\\to \\mathbb{R}$ defined by\n$$\nf(h) = \\int_{0}^{2\\pi} h(\\theta)\\, g(\\theta)\\, d\\theta,\n$$\nwhere\n$$\ng(\\theta) = 1 + 2\\cos(3\\theta) - \\sqrt{3}\\,\\sin(5\\theta).\n$$\nStarting from the inner product structure on $L^{2}(X)$, the definition of the operator norm $\\|f\\| = \\sup_{\\|h\\|_{L^{2}}=1} |f(h)|$, and the Cauchyâ€“Schwarz inequality, do the following:\n- Identify the representing function for $f$ given by the Riesz representation theorem.\n- Derive an exact expression for $\\|f\\|$ in terms of $g$ and evaluate it explicitly for the above $g$.\n\nReport the final answer as a single exact expression. No rounding is required.", "solution": "The problem asks for the identification of the representing function for a linear functional $f$ on the Hilbert space $L^2(X)$ and for the calculation of the norm of this functional.\n\nThe space $X = \\mathbb{S}^1$ is equipped with the Lebesgue measure $d\\theta$. The space $L^2(X)$ is the real Hilbert space of square-integrable functions on the interval $[0, 2\\pi]$ with the inner product defined as\n$$\n\\langle h,k\\rangle = \\int_{0}^{2\\pi} h(\\theta)k(\\theta)\\, d\\theta.\n$$\nThe norm associated with this inner product is $\\|h\\|_{L^2} = \\sqrt{\\langle h,h \\rangle} = \\left( \\int_{0}^{2\\pi} h(\\theta)^2\\, d\\theta \\right)^{1/2}$.\n\nThe linear functional $f:L^{2}(X)\\to \\mathbb{R}$ is defined by\n$$\nf(h) = \\int_{0}^{2\\pi} h(\\theta)\\, g(\\theta)\\, d\\theta,\n$$\nwhere $g(\\theta) = 1 + 2\\cos(3\\theta) - \\sqrt{3}\\,\\sin(5\\theta)$. Since $g$ is a continuous function on the compact interval $[0, 2\\pi]$, it is bounded and thus square-integrable, i.e., $g \\in L^2(X)$.\n\n**Part 1: Identify the representing function**\n\nThe Riesz representation theorem states that for any continuous linear functional $f$ on a Hilbert space $H$, there exists a unique element $y_f \\in H$ such that for all $x \\in H$, $f(x) = \\langle x, y_f \\rangle$.\n\nIn our case, the Hilbert space is $H = L^2(X)$ and the inner product is $\\langle h, k \\rangle = \\int_0^{2\\pi} h(\\theta)k(\\theta) d\\theta$. The given functional is $f(h) = \\int_0^{2\\pi} h(\\theta)g(\\theta) d\\theta$. By direct comparison with the definition of the inner product, we can write $f(h)$ as:\n$$\nf(h) = \\langle h, g \\rangle.\n$$\nAccording to the Riesz representation theorem, the representing function for the functional $f$ is precisely the function $g(\\theta)$.\n\n**Part 2: Derive and evaluate the norm of the functional**\n\nThe Riesz representation theorem also states that the norm of the functional $f$ is equal to the norm of its representing element $y_f$, which in our case is $g$. That is, $\\|f\\| = \\|g\\|_{L^2}$. The problem requires a derivation of this fact from first principles.\n\nThe norm of the functional $f$ is defined as\n$$\n\\|f\\| = \\sup_{\\|h\\|_{L^{2}}=1} |f(h)|.\n$$\nSubstituting the inner product form of $f(h)$, we have\n$$\n\\|f\\| = \\sup_{\\|h\\|_{L^{2}}=1} |\\langle h, g \\rangle|.\n$$\nThe Cauchy-Schwarz inequality for the inner product on $L^2(X)$ states that for any $h, g \\in L^2(X)$,\n$$\n|\\langle h, g \\rangle| \\leq \\|h\\|_{L^2} \\|g\\|_{L^2}.\n$$\nFor any function $h$ with $\\|h\\|_{L^2} = 1$, the inequality becomes\n$$\n|\\langle h, g \\rangle| \\leq 1 \\cdot \\|g\\|_{L^2} = \\|g\\|_{L^2}.\n$$\nThis shows that $\\|g\\|_{L^2}$ is an upper bound for the set $\\{|f(h)| : \\|h\\|_{L^2}=1\\}$. Therefore, the supremum of this set must be less than or equal to this upper bound:\n$$\n\\|f\\| \\leq \\|g\\|_{L^2}.\n$$\nTo establish equality, we must show that this upper bound is attained for some function $h_0$ with $\\|h_0\\|_{L^2}=1$. The equality in the Cauchy-Schwarz inequality holds if and only if the two functions are linearly dependent, i.e., $h = c \\cdot g$ for some scalar $c \\in \\mathbb{R}$.\n\nAssuming $g$ is not the zero function (which is true in this problem), we have $\\|g\\|_{L^2} > 0$. Let us choose the specific function $h_0 = \\frac{g}{\\|g\\|_{L^2}}$. Let's verify its norm:\n$$\n\\|h_0\\|_{L^2} = \\left\\| \\frac{g}{\\|g\\|_{L^2}} \\right\\|_{L^2} = \\frac{1}{\\|g\\|_{L^2}} \\|g\\|_{L^2} = 1.\n$$\nNow, we evaluate $f(h_0)$:\n$$\nf(h_0) = \\langle h_0, g \\rangle = \\left\\langle \\frac{g}{\\|g\\|_{L^2}}, g \\right\\rangle = \\frac{1}{\\|g\\|_{L^2}} \\langle g,g \\rangle = \\frac{1}{\\|g\\|_{L^2}} \\|g\\|_{L^2}^2 = \\|g\\|_{L^2}.\n$$\nSince we have found a function $h_0$ in the unit sphere of $L^2(X)$ for which $|f(h_0)| = \\|g\\|_{L^2}$, the supremum must be exactly $\\|g\\|_{L^2}$. Thus, we have rigorously shown that\n$$\n\\|f\\| = \\|g\\|_{L^2}.\n$$\n\n**Part 3: Explicit calculation**\n\nWe now compute $\\|g\\|_{L^2}$ for $g(\\theta) = 1 + 2\\cos(3\\theta) - \\sqrt{3}\\,\\sin(5\\theta)$.\n$$\n\\|f\\|^2 = \\|g\\|_{L^2}^2 = \\int_0^{2\\pi} \\left( 1 + 2\\cos(3\\theta) - \\sqrt{3}\\,\\sin(5\\theta) \\right)^2 d\\theta.\n$$\nThe set of functions $\\{1, \\cos(n\\theta), \\sin(m\\theta)\\}$ for $n, m \\in \\mathbb{N}$ forms an orthogonal basis for $L^2([0, 2\\pi])$. We use the following standard integrals, which are consequences of orthogonality:\n$$\n\\int_0^{2\\pi} \\cos(m\\theta) \\cos(n\\theta) d\\theta = \\pi \\delta_{mn} \\quad (m, n \\neq 0)\n$$\n$$\n\\int_0^{2\\pi} \\sin(m\\theta) \\sin(n\\theta) d\\theta = \\pi \\delta_{mn} \\quad (m, n \\neq 0)\n$$\n$$\n\\int_0^{2\\pi} \\cos(m\\theta) \\sin(n\\theta) d\\theta = 0 \\quad (\\forall m, n)\n$$\n$$\n\\int_0^{2\\pi} \\cos(m\\theta) d\\theta = 0, \\quad \\int_0^{2\\pi} \\sin(m\\theta) d\\theta = 0 \\quad (m \\neq 0)\n$$\nAlso, the norms of the basis functions are:\n$$\n\\int_0^{2\\pi} 1^2 d\\theta = 2\\pi\n$$\n$$\n\\int_0^{2\\pi} \\cos^2(n\\theta) d\\theta = \\pi \\quad (n \\neq 0)\n$$\n$$\n\\int_0^{2\\pi} \\sin^2(n\\theta) d\\theta = \\pi \\quad (n \\neq 0)\n$$\nWhen we expand the square of $g(\\theta)$, all cross-product terms will integrate to zero due to orthogonality. For instance, $\\int_0^{2\\pi} 1 \\cdot 2\\cos(3\\theta) d\\theta = 0$.\nSo, we can apply Parseval's theorem (or the Pythagorean theorem for orthogonal functions):\n$$\n\\|g\\|_{L^2}^2 = \\int_0^{2\\pi} 1^2 d\\theta + \\int_0^{2\\pi} (2\\cos(3\\theta))^2 d\\theta + \\int_0^{2\\pi} (-\\sqrt{3}\\sin(5\\theta))^2 d\\theta\n$$\n$$\n\\|g\\|_{L^2}^2 = \\int_0^{2\\pi} 1 d\\theta + 4\\int_0^{2\\pi} \\cos^2(3\\theta) d\\theta + 3\\int_0^{2\\pi} \\sin^2(5\\theta) d\\theta\n$$\nUsing the integral values above:\n$$\n\\|g\\|_{L^2}^2 = (2\\pi) + 4(\\pi) + 3(\\pi) = 2\\pi + 4\\pi + 3\\pi = 9\\pi.\n$$\nThe norm of the functional is the square root of this value:\n$$\n\\|f\\| = \\|g\\|_{L^2} = \\sqrt{9\\pi} = 3\\sqrt{\\pi}.\n$$", "answer": "$$\n\\boxed{3\\sqrt{\\pi}}\n$$", "id": "3075104"}, {"introduction": "The Riesz Representation Theorem is not just an elegant abstract result; it is a powerful practical tool in applied mathematics, particularly in the theory of partial differential equations (PDEs). This exercise takes place in a Sobolev space, which is fundamental to the modern study of PDEs. By applying the theorem, you will see how finding a representing element transforms the problem into solving a differential equation, a technique that forms the theoretical basis for powerful numerical methods like the finite element method [@problem_id:587180].", "problem": "Consider the Sobolev space $H^1_0([0,1])$, defined as the space of absolutely continuous functions $u : [0,1] \\to \\mathbb{R}$ with $u(0) = u(1) = 0$ and derivative $u' \\in L^2([0,1])$. Equip this space with the inner product $\\langle u, v \\rangle = \\int_0^1 u'(x) v'(x) \\, dx$. Let $\\phi : H^1_0([0,1]) \\to \\mathbb{R}$ be the linear functional given by $\\phi(u) = \\int_0^1 x u(x) \\, dx$.  \n\nUsing the Riesz Representation Theorem for Hilbert spaces, find the unique function $v_\\phi \\in H^1_0([0,1])$ such that $\\langle v_\\phi, u \\rangle = \\phi(u)$ for all $u \\in H^1_0([0,1])$. Express $v_\\phi(x)$ as a closed-form analytic expression.", "solution": "We seek $v_\\phi \\in H^1_0([0,1])$ such that for all $u \\in H^1_0([0,1])$\n\n$$\n\\langle v_\\phi,u\\rangle\n=\\int_0^1v_\\phi'(x)\\,u'(x)\\,dx\n=\\phi(u)\n=\\int_0^1x\\,u(x)\\,dx.\n$$\n\n1. Integrate by parts on the left side, using $u(0)=u(1)=0$ (and assuming $v_\\phi$ is sufficiently smooth):\n\n$$\n\\int_0^1v_\\phi'(x)\\,u'(x)\\,dx\n= [v_\\phi'(x)u(x)]_0^1 - \\int_0^1v_\\phi''(x)\\,u(x)\\,dx\n= -\\int_0^1 v_\\phi''(x)\\,u(x)\\,dx.\n$$\n\n2. Equate integrands (since this holds for all $u$) to get the ODE\n\n$$\n-v_\\phi''(x)=x\n\\quad\\Longrightarrow\\quad\nv_\\phi''(x)=-x.\n$$\n\n3. Integrate twice, introducing constants $C_1,C_2$:\n\n$$\nv_\\phi'(x)=-\\frac{x^2}{2}+C_1,\n\\quad\nv_\\phi(x)=-\\frac{x^3}{6}+C_1x+C_2.\n$$\n\n4. Impose boundary conditions $v_\\phi(0)=0$ and $v_\\phi(1)=0$:\n\n$$\nv_\\phi(0)=C_2=0,\n\\quad\nv_\\phi(1)=-\\frac{1}{6}+C_1=0\n\\;\\Longrightarrow\\;\nC_1=\\frac{1}{6}.\n$$\n\n5. Substitute constants back:\n\n$$\nv_\\phi(x)\n=-\\frac{x^3}{6}+\\frac{x}{6}\n=\\frac{x-x^3}{6}.\n$$", "answer": "$$\\boxed{\\frac{x-x^3}{6}}$$", "id": "587180"}]}