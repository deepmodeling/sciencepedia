{"hands_on_practices": [{"introduction": "To build a solid understanding of differential operators, it is best to start in the most familiar setting: Euclidean space. This first exercise explores the deep connection between the Hessian operator and the metric tensor itself. By calculating the Hessian of the squared distance function from the origin, $f(x) = \\frac{1}{2}|x|^2$, you will see from first principles that it recovers the Euclidean metric $\\delta$ [@problem_id:3069873]. This fundamental result not only serves as a perfect entry point but also provides a crucial piece of intuition for how second-order derivatives capture the underlying geometry.", "problem": "Let $\\left(\\mathbb{R}^{n},\\delta\\right)$ denote $n$-dimensional Euclidean space equipped with its standard Euclidean metric $\\delta$. Consider the smooth function $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ defined by $f(x)=\\tfrac{1}{2}|x|^{2}$, where $|x|^{2}=\\delta(x,x)$ is the squared Euclidean norm. Using only the following fundamental definitions:\n- the gradient $\\nabla f$ is the unique vector field satisfying $\\delta(\\nabla f, X)=X(f)$ for every smooth vector field $X$,\n- the Levi-Civita covariant derivative $\\nabla$ is the unique torsion-free, metric-compatible connection on $\\left(\\mathbb{R}^{n},\\delta\\right)$,\n- the Hessian of $f$ is the symmetric $(0,2)$-tensor defined by $\\operatorname{Hess}f(X,Y)=\\delta\\!\\left(\\nabla_{X}\\nabla f,\\,Y\\right)$ for smooth vector fields $X,Y$,\n\nderive an explicit expression for $\\operatorname{Hess}f$ at an arbitrary point of $\\mathbb{R}^{n}$ and show that it coincides with the metric $\\delta$. Express your final answer as a single closed-form analytic expression.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n-   Manifold: $n$-dimensional Euclidean space $\\left(\\mathbb{R}^{n},\\delta\\right)$, where $\\delta$ is the standard Euclidean metric.\n-   Function: A smooth function $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ defined by $f(x)=\\frac{1}{2}|x|^{2}$, where $|x|^{2}=\\delta(x,x)$.\n-   Definition of the gradient: $\\nabla f$ is the unique vector field satisfying $\\delta(\\nabla f, X)=X(f)$ for every smooth vector field $X$.\n-   Definition of the Levi-Civita connection: $\\nabla$ is the unique torsion-free, metric-compatible connection on $\\left(\\mathbb{R}^{n},\\delta\\right)$.\n-   Definition of the Hessian: $\\operatorname{Hess}f$ is the symmetric $(0,2)$-tensor defined by $\\operatorname{Hess}f(X,Y)=\\delta\\!\\left(\\nabla_{X}\\nabla f,\\,Y\\right)$ for smooth vector fields $X$ and $Y$.\n-   Task: Derive an explicit expression for $\\operatorname{Hess}f$ at an arbitrary point of $\\mathbb{R}^{n}$ and show that it coincides with the metric $\\delta$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It is a standard exercise in introductory Riemannian geometry. It provides clear, standard definitions for the gradient, Levi-Civita connection, and Hessian on a Riemannian manifold. The setting is the simplest possible Riemannian manifold, Euclidean space. The function is smooth and well-defined. There are no contradictions, ambiguities, or missing pieces of information required to solve the problem from the given fundamental definitions. The problem does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe objective is to compute the Hessian of the function $f(x) = \\frac{1}{2}|x|^2$ on $(\\mathbb{R}^n, \\delta)$ and show that it is equal to the metric tensor $\\delta$. The derivation will proceed in three steps: first, we compute the gradient vector field $\\nabla f$; second, we compute the covariant derivative of the gradient, $\\nabla_X \\nabla f$; third, we use the result to find the Hessian.\n\nLet $x$ denote the position vector field on $\\mathbb{R}^n$, which at a point $p \\in \\mathbb{R}^n$ yields the vector from the origin to $p$. In terms of the standard inner product $\\delta$, the function is $f(p) = \\frac{1}{2}\\delta(x_p, x_p)$.\n\n**Step 1: Compute the gradient $\\nabla f$**\n\nBy definition, the gradient vector field $\\nabla f$ is uniquely determined by the relation $\\delta(\\nabla f, X) = X(f)$ for any arbitrary smooth vector field $X$. We first compute the action of $X$ on $f$, which is the directional derivative of $f$ along $X$. At an arbitrary point $p \\in \\mathbb{R}^n$, this is given by:\n$$\nX_p(f) = \\frac{d}{dt}\\bigg|_{t=0} f(p + t X_p)\n$$\nSubstituting the expression for $f$:\n$$\nX_p(f) = \\frac{d}{dt}\\bigg|_{t=0} \\left( \\frac{1}{2} \\delta(p + t X_p, p + t X_p) \\right)\n$$\nUsing the bilinearity of the metric $\\delta$, we expand the inner term:\n$$\n\\delta(p + t X_p, p + t X_p) = \\delta(p,p) + 2t\\delta(p, X_p) + t^2\\delta(X_p, X_p)\n$$\nNow, we differentiate with respect to $t$ and evaluate at $t=0$:\n$$\nX_p(f) = \\frac{1}{2} \\frac{d}{dt}\\bigg|_{t=0} \\left( \\delta(p,p) + 2t\\delta(p, X_p) + t^2\\delta(X_p, X_p) \\right) = \\frac{1}{2} \\left[ 2\\delta(p, X_p) + 2t\\delta(X_p, X_p) \\right]_{t=0} = \\delta(p, X_p)\n$$\nThe defining property for the gradient at point $p$ is $\\delta((\\nabla f)_p, X_p) = X_p(f)$. Substituting our result for $X_p(f)$, we get:\n$$\n\\delta((\\nabla f)_p, X_p) = \\delta(p, X_p)\n$$\nSince this equality must hold for any vector $X_p \\in T_p\\mathbb{R}^n$ and the metric $\\delta$ is non-degenerate, we must have $(\\nabla f)_p = p$. Identifying the point $p$ with its position vector $x_p$, we have $(\\nabla f)_p = x_p$. As this is true for all $p \\in \\mathbb{R}^n$, the gradient vector field $\\nabla f$ is identical to the position vector field $x$.\n$$\n\\nabla f = x\n$$\n\n**Step 2: Compute the covariant derivative $\\nabla_X \\nabla f$**\n\nWe need to compute $\\nabla_X (\\nabla f) = \\nabla_X x$ for an arbitrary vector field $X$. The Levi-Civita connection $\\nabla$ on Euclidean space $(\\mathbb{R}^n, \\delta)$ is \"flat\", meaning that the standard notion of a directional derivative of a vector field (viewed as a map from $\\mathbb{R}^n$ to $\\mathbb{R}^n$) coincides with the covariant derivative. That is, for a vector field $Y$, its covariant derivative along $X$ at a point $p$ is given by:\n$$\n(\\nabla_X Y)_p = \\lim_{h\\to 0} \\frac{Y(p+hX_p) - Y(p)}{h}\n$$\nwhere $Y(p)$ and $Y(p+hX_p)$ are vectors in $\\mathbb{R}^n$ and the subtraction is the standard vector subtraction. This definition satisfies the torsion-free and metric-compatibility conditions for the Euclidean metric.\n\nIn our case, the vector field is $Y = \\nabla f = x$. The action of the position vector field $x$ on a point $q$ is simply to return the position vector of that point, i.e., $x(q) = q$. Applying this to the formula for the covariant derivative at a point $p$:\n$$\n(\\nabla_X(\\nabla f))_p = (\\nabla_X x)_p = \\lim_{h\\to 0} \\frac{x(p+hX_p) - x(p)}{h}\n$$\nSubstituting the action of $x$:\n$$\n(\\nabla_X x)_p = \\lim_{h\\to 0} \\frac{(p+hX_p) - p}{h} = \\lim_{h\\to 0} \\frac{hX_p}{h} = X_p\n$$\nSince this holds for any point $p \\in \\mathbb{R}^n$, the vector field $\\nabla_X \\nabla f$ is identical to the vector field $X$.\n$$\n\\nabla_X \\nabla f = X\n$$\n\n**Step 3: Compute the Hessian $\\operatorname{Hess}f$**\n\nThe Hessian of $f$ is defined as the $(0,2)$-tensor field $\\operatorname{Hess}f(X,Y) = \\delta(\\nabla_X \\nabla f, Y)$ for any pair of smooth vector fields $X, Y$.\nUsing the result from Step 2, we substitute $\\nabla_X \\nabla f = X$ into the definition of the Hessian:\n$$\n\\operatorname{Hess}f(X,Y) = \\delta(X, Y)\n$$\nThis equation shows that the action of the tensor field $\\operatorname{Hess}f$ on any pair of vector fields $(X,Y)$ is identical to the action of the metric tensor $\\delta$ on the same pair. Therefore, the Hessian tensor of $f$ is the metric tensor itself.\n$$\n\\operatorname{Hess}f = \\delta\n$$\nThis completes the derivation. The explicit expression for the Hessian of $f(x)=\\frac{1}{2}|x|^2$ is the Euclidean metric tensor $\\delta$.", "answer": "$$\\boxed{\\delta}$$", "id": "3069873"}, {"introduction": "Having established a baseline in Cartesian coordinates, we now explore how these geometric operators behave under a change of coordinates. This practice moves to the Euclidean plane $\\mathbb{R}^2$ but uses polar coordinates, a setting where the metric components are no longer constant and Christoffel symbols become non-trivial [@problem_id:3069879]. You will compute the divergence of a vector field using two distinct, fundamental definitions—one involving the Lie derivative of the volume form and the other using the trace of the covariant derivative—and verify they yield the same result. This exercise is essential for developing computational fluency and appreciating the coordinate-invariant nature of the divergence operator.", "problem": "Let $\\left(\\mathbb{R}^{2}, g\\right)$ be the Euclidean plane written in polar coordinates $(r,\\theta)$, with metric $g$ given by the line element $ds^{2} = dr^{2} + r^{2}\\, d\\theta^{2}$ and Riemannian volume form $\\mu_{g} = r\\, dr \\wedge d\\theta$. Consider the smooth vector field $X$ expressed in the coordinate basis $\\{\\partial_{r}, \\partial_{\\theta}\\}$ by\n$$\nX = X^{r}(r,\\theta)\\, \\partial_{r} + X^{\\theta}(r,\\theta)\\, \\partial_{\\theta}, \\quad X^{r}(r,\\theta) = r^{2}\\cos(2\\theta), \\quad X^{\\theta}(r,\\theta) = r\\sin(\\theta).\n$$\nHere $\\theta$ is the standard angular coordinate measured in radians.\n\nUsing only foundational definitions from Riemannian geometry, proceed as follows:\n- Using the defining property of divergence on a Riemannian manifold, namely that the Lie derivative $\\mathcal{L}_{X}$ of the Riemannian volume form satisfies $\\mathcal{L}_{X}\\mu_{g} = \\left(\\operatorname{div}_{g} X\\right)\\mu_{g}$, compute $\\operatorname{div}_{g} X$ explicitly as a function of $r$ and $\\theta$.\n- Independently, compute the Levi-Civita covariant derivative $\\nabla$ of $g$ in these coordinates and take the trace $\\nabla_{i}X^{i}$ to obtain the divergence, and verify that this agrees with your first computation.\n\nProvide your final answer as a single simplified analytic expression in terms of $r$ and $\\theta$. No rounding is required. Do not include any units in your final answer.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. It is a standard exercise in Riemannian geometry. I will proceed with the solution.\n\nThe problem asks for the computation of the divergence of a vector field $X$ on the Riemannian manifold $(\\mathbb{R}^2, g)$ with the metric in polar coordinates $(r, \\theta)$ given by $ds^2 = dr^2 + r^2 d\\theta^2$. The vector field is given by $X = r^2\\cos(2\\theta) \\partial_r + r\\sin(\\theta) \\partial_\\theta$. The computation must be performed in two distinct ways.\n\nThe components of the metric tensor $g$ are $g_{rr} = 1$, $g_{\\theta\\theta} = r^2$, and $g_{r\\theta} = g_{\\theta r} = 0$. The Riemannian volume form is $\\mu_g = \\sqrt{\\det(g_{ij})} \\, dr \\wedge d\\theta = \\sqrt{1 \\cdot r^2} \\, dr \\wedge d\\theta = r \\, dr \\wedge d\\theta$, which is consistent with the problem statement.\n\n**Method 1: Using the Lie Derivative of the Volume Form**\n\nThe divergence of a vector field $X$ on a Riemannian manifold $(M,g)$ is defined by the relation $\\mathcal{L}_X \\mu_g = (\\operatorname{div}_g X) \\mu_g$, where $\\mathcal{L}_X$ is the Lie derivative with respect to $X$ and $\\mu_g$ is the Riemannian volume form.\n\nWe use Cartan's formula for the Lie derivative of a differential form $\\omega$: $\\mathcal{L}_X \\omega = d(i_X \\omega) + i_X(d\\omega)$. In this case, $\\omega = \\mu_g = r \\, dr \\wedge d\\theta$ is a $2$-form on a $2$-dimensional manifold. Such a form is a top-form, and its exterior derivative is always zero, so $d\\mu_g = 0$. The formula simplifies to $\\mathcal{L}_X \\mu_g = d(i_X \\mu_g)$.\n\nFirst, we compute the interior product $i_X \\mu_g$. The vector field is $X = X^r \\partial_r + X^\\theta \\partial_\\theta$, where $X^r = r^2\\cos(2\\theta)$ and $X^\\theta = r\\sin(\\theta)$.\n$$\ni_X \\mu_g = i_{X^r \\partial_r + X^\\theta \\partial_\\theta} (r \\, dr \\wedge d\\theta)\n$$\nUsing the linearity of the interior product, we have:\n$$\ni_X \\mu_g = X^r \\cdot i_{\\partial_r}(r \\, dr \\wedge d\\theta) + X^\\theta \\cdot i_{\\partial_\\theta}(r \\, dr \\wedge d\\theta)\n$$\nThe action of the interior product on the basis $2$-form is:\n$i_{\\partial_r}(dr \\wedge d\\theta) = d\\theta$ and $i_{\\partial_\\theta}(dr \\wedge d\\theta) = -dr$.\nSubstituting these into the expression for $i_X \\mu_g$:\n$$\ni_X \\mu_g = X^r \\cdot (r \\, d\\theta) + X^\\theta \\cdot (r (-dr)) = r X^r d\\theta - r X^\\theta dr\n$$\nNow, substituting the given components of $X$:\n$$\ni_X \\mu_g = r(r^2\\cos(2\\theta)) d\\theta - r(r\\sin(\\theta)) dr = -r^2\\sin(\\theta) dr + r^3\\cos(2\\theta) d\\theta\n$$\nThis is a $1$-form. Next, we compute its exterior derivative, $d(i_X \\mu_g)$:\n$$\nd(i_X \\mu_g) = d(-r^2\\sin(\\theta) dr + r^3\\cos(2\\theta) d\\theta) = d(-r^2\\sin(\\theta) dr) + d(r^3\\cos(2\\theta) d\\theta)\n$$\nFor a $1$-form $\\alpha = P dr + Q d\\theta$, its exterior derivative is $d\\alpha = (\\frac{\\partial Q}{\\partial r} - \\frac{\\partial P}{\\partial \\theta}) dr \\wedge d\\theta$.\nHere, $P(r,\\theta) = -r^2\\sin(\\theta)$ and $Q(r,\\theta) = r^3\\cos(2\\theta)$.\n$$\n\\frac{\\partial P}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta}(-r^2\\sin(\\theta)) = -r^2\\cos(\\theta)\n$$\n$$\n\\frac{\\partial Q}{\\partial r} = \\frac{\\partial}{\\partial r}(r^3\\cos(2\\theta)) = 3r^2\\cos(2\\theta)\n$$\nSo, the exterior derivative is:\n$$\nd(i_X \\mu_g) = (3r^2\\cos(2\\theta) - (-r^2\\cos(\\theta))) dr \\wedge d\\theta = (3r^2\\cos(2\\theta) + r^2\\cos(\\theta)) dr \\wedge d\\theta\n$$\nWe have $\\mathcal{L}_X \\mu_g = (3r^2\\cos(2\\theta) + r^2\\cos(\\theta)) dr \\wedge d\\theta$.\nFrom the definition, we equate this with $(\\operatorname{div}_g X)\\mu_g$:\n$$\n(\\operatorname{div}_g X) (r \\, dr \\wedge d\\theta) = (3r^2\\cos(2\\theta) + r^2\\cos(\\theta)) dr \\wedge d\\theta\n$$\nSolving for $\\operatorname{div}_g X$:\n$$\n\\operatorname{div}_g X = \\frac{3r^2\\cos(2\\theta) + r^2\\cos(\\theta)}{r} = 3r\\cos(2\\theta) + r\\cos(\\theta)\n$$\n\n**Method 2: Using the Covariant Derivative**\n\nThe divergence can also be computed as the trace of the covariant derivative of the vector field, $\\operatorname{div}_g X = \\operatorname{tr}(\\nabla X) = \\nabla_i X^i$. In a coordinate basis $\\{\\partial_i\\}$, this is given by the sum over $i$:\n$$\n\\operatorname{div}_g X = \\sum_i \\nabla_i X^i = \\sum_i \\left(\\partial_i X^i + \\sum_k \\Gamma^i_{ik} X^k\\right)\n$$\nwhere $\\Gamma^k_{ij}$ are the Christoffel symbols of the Levi-Civita connection. In our coordinates $(x^1, x^2) = (r, \\theta)$, this becomes:\n$$\n\\operatorname{div}_g X = \\left(\\partial_r X^r + \\Gamma^r_{rr}X^r + \\Gamma^r_{r\\theta}X^\\theta\\right) + \\left(\\partial_\\theta X^\\theta + \\Gamma^\\theta_{\\theta r}X^r + \\Gamma^\\theta_{\\theta\\theta}X^\\theta\\right)\n$$\nWe must first compute the Christoffel symbols using the formula $\\Gamma^k_{ij} = \\frac{1}{2} g^{kl}(\\partial_i g_{jl} + \\partial_j g_{il} - \\partial_l g_{ij})$. The metric components are $g_{rr}=1$, $g_{\\theta\\theta}=r^2$, $g_{r\\theta}=0$. The inverse components are $g^{rr}=1$, $g^{\\theta\\theta}=1/r^2$, $g^{r\\theta}=0$. The only non-zero partial derivative of the metric components is $\\partial_r g_{\\theta\\theta} = 2r$.\n\nThe non-zero Christoffel symbols are:\n$$\n\\Gamma^r_{\\theta\\theta} = \\frac{1}{2} g^{rr}(\\partial_\\theta g_{\\theta r} + \\partial_\\theta g_{\\theta r} - \\partial_r g_{\\theta\\theta}) = \\frac{1}{2}(1)(0+0-2r) = -r\n$$\n$$\n\\Gamma^\\theta_{r\\theta} = \\Gamma^\\theta_{\\theta r} = \\frac{1}{2} g^{\\theta\\theta}(\\partial_r g_{\\theta\\theta} + \\partial_\\theta g_{r\\theta} - \\partial_\\theta g_{r\\theta}) = \\frac{1}{2} \\frac{1}{r^2}(2r+0-0) = \\frac{1}{r}\n$$\nAll other Christoffel symbols are zero.\n\nNow, we substitute these into the expression for the divergence. The sum over $i$ gives two terms:\nFor $i=r$: $\\partial_r X^r + \\Gamma^r_{rr}X^r + \\Gamma^r_{r\\theta}X^\\theta = \\partial_r X^r + (0)X^r + (0)X^\\theta = \\partial_r X^r$.\nFor $i=\\theta$: $\\partial_\\theta X^\\theta + \\Gamma^\\theta_{\\theta r}X^r + \\Gamma^\\theta_{\\theta\\theta}X^\\theta = \\partial_\\theta X^\\theta + (\\frac{1}{r})X^r + (0)X^\\theta = \\partial_\\theta X^\\theta + \\frac{1}{r}X^r$.\n\nSumming these terms gives the divergence:\n$$\n\\operatorname{div}_g X = \\partial_r X^r + \\partial_\\theta X^\\theta + \\frac{1}{r} X^r\n$$\nWe have the components $X^r = r^2\\cos(2\\theta)$ and $X^\\theta = r\\sin(\\theta)$. We compute the necessary partial derivatives:\n$$\n\\partial_r X^r = \\frac{\\partial}{\\partial r}(r^2\\cos(2\\theta)) = 2r\\cos(2\\theta)\n$$\n$$\n\\partial_\\theta X^\\theta = \\frac{\\partial}{\\partial \\theta}(r\\sin(\\theta)) = r\\cos(\\theta)\n$$\nThe third term is:\n$$\n\\frac{1}{r} X^r = \\frac{1}{r}(r^2\\cos(2\\theta)) = r\\cos(2\\theta)\n$$\nSumming these three parts gives the final result:\n$$\n\\operatorname{div}_g X = 2r\\cos(2\\theta) + r\\cos(\\theta) + r\\cos(2\\theta) = 3r\\cos(2\\theta) + r\\cos(\\theta)\n$$\n\n**Conclusion**\nBoth methods yield the same result: $\\operatorname{div}_g X = 3r\\cos(2\\theta) + r\\cos(\\theta)$. This confirms the correctness of the calculation.", "answer": "$$\n\\boxed{3r\\cos(2\\theta) + r\\cos(\\theta)}\n$$", "id": "3069879"}, {"introduction": "The true power of Riemannian geometry lies in its ability to describe intrinsically curved spaces. This final practice takes you from the flat world of Euclidean geometry to the hyperbolic upper half-plane $\\mathbb{H}^2$, a canonical example of a space with constant negative curvature. Your task is to derive the explicit coordinate formulas for the gradient, divergence, and Laplace-Beltrami operator directly from their fundamental definitions in this non-Euclidean setting [@problem_id:3069887]. By mastering this calculation, you will demonstrate your ability to apply the full machinery of geometric analysis to any Riemannian manifold, given its metric.", "problem": "Let $\\mathbb{H}^{2}=\\{(x,y)\\in\\mathbb{R}^{2}:y>0\\}$ be the upper half-plane equipped with the Riemannian metric $g=\\frac{dx^{2}+dy^{2}}{y^{2}}$. Work in the global coordinates $(x,y)$ and use only fundamental definitions from Riemannian geometry: the Riemannian gradient $\\nabla f$ of a smooth function $f$ is the unique vector field satisfying $g(\\nabla f,V)=df(V)$ for all vector fields $V$, the divergence $\\operatorname{div}X$ of a smooth vector field $X$ is the trace of its covariant derivative with respect to the Levi-Civita connection determined by $g$, and the Laplace-Beltrami operator $\\Delta$ is defined by $\\Delta f=\\operatorname{div}(\\nabla f)$. Begin from these definitions and derive explicit coordinate formulas for $\\nabla f$, $\\operatorname{div}X$, and $\\Delta f$ in terms of $(x,y)$ and the coordinate components of $f$ and $X$.\n\nAfter you have established these formulas, apply them to the specific function $f(x,y)=x\\,y^{3}+\\ln y$ and the vector field $X(x,y)=y^{2}\\,\\partial_{x}+x\\,y\\,\\partial_{y}$ to compute the single quantity $\\Delta f(1,1)-\\operatorname{div}X(1,1)$. Express your final answer as an exact real number. No rounding is required.", "solution": "We first record the metric components. In the coordinates $(x,y)$, the metric tensor is\n$$\ng_{ij}=\\frac{1}{y^{2}}\\delta_{ij},\\quad\\text{so}\\quad g_{xx}=g_{yy}=\\frac{1}{y^{2}},\\; g_{xy}=0,\n$$\nand its inverse is\n$$\ng^{ij}=y^{2}\\delta_{ij},\\quad\\text{so}\\quad g^{xx}=g^{yy}=y^{2},\\; g^{xy}=0.\n$$\nThe determinant of $g_{ij}$ is $\\det(g)=\\frac{1}{y^{4}}$, hence the Riemannian volume density is $\\sqrt{\\det(g)}=\\frac{1}{y^{2}}$.\n\nGradient. By definition, for any smooth $f$, $\\nabla f$ is the unique vector field with $g(\\nabla f,V)=df(V)$ for all $V$. In coordinates, write $\\nabla f = (\\nabla f)^{i}\\partial_{i}$, and note that\n$$\ng(\\nabla f, \\partial_{j}) = g_{ji} (\\nabla f)^{i} = \\partial_{j} f.\n$$\nSolving for $(\\nabla f)^{i}$ gives $(\\nabla f)^{i}=g^{ij}\\partial_{j} f$. Thus,\n$$\n\\nabla f = g^{ij}\\,\\partial_{j} f\\,\\partial_{i} = y^{2}\\left( \\partial_{x} f\\,\\partial_{x} + \\partial_{y} f\\,\\partial_{y} \\right).\n$$\n\nDivergence. The divergence of a vector field $X=X^{i}\\partial_{i}$ is defined as the trace of the covariant derivative with respect to the Levi-Civita connection $\\nabla$, namely $\\operatorname{div}X=\\nabla_{i}X^{i}$, where $\\nabla_{i}X^{i}=\\partial_{i}X^{i}+\\Gamma^{i}_{ik}X^{k}$ in coordinates, and $\\Gamma^{i}_{jk}$ are the Christoffel symbols of $g$. We compute the nonzero Christoffel symbols using\n$$\n\\Gamma^{k}_{ij}=\\frac{1}{2}g^{k\\ell}\\left(\\partial_{i}g_{j\\ell}+\\partial_{j}g_{i\\ell}-\\partial_{\\ell}g_{ij}\\right).\n$$\nBecause $g_{ij}=\\frac{1}{y^{2}}\\delta_{ij}$ depends only on $y$, we have $\\partial_{y}g_{xx}=\\partial_{y}g_{yy}=-\\frac{2}{y^{3}}$ and $\\partial_{x}g_{ij}=0$. A straightforward computation yields\n$$\n\\Gamma^{x}_{xy}=\\Gamma^{x}_{yx}=-\\frac{1}{y},\\quad \\Gamma^{y}_{xx}=\\frac{1}{y},\\quad \\Gamma^{y}_{yy}=-\\frac{1}{y},\n$$\nwith all other $\\Gamma^{i}_{jk}$ equal to $0$. The sum $\\nabla_i X^i = (\\partial_x X^x + \\Gamma^x_{xk}X^k) + (\\partial_y X^y + \\Gamma^y_{yk}X^k)$ expands to:\n$$\n\\operatorname{div}X = (\\partial_x X^x + \\Gamma^x_{xx}X^x + \\Gamma^x_{xy}X^y) + (\\partial_y X^y + \\Gamma^y_{yx}X^x + \\Gamma^y_{yy}X^y)\n$$\nSubstituting the non-zero Christoffel symbols:\n$$\n\\operatorname{div}X = (\\partial_x X^x - \\frac{1}{y}X^y) + (\\partial_y X^y - \\frac{1}{y}X^y) = \\partial_x X^x + \\partial_y X^y - \\frac{2}{y}X^y.\n$$\nEquivalently, one can derive from the divergence theorem and the Levi-Civita volume form that\n$$\n\\operatorname{div}X=\\frac{1}{\\sqrt{\\det(g)}}\\partial_{i}\\big(\\sqrt{\\det(g)}\\,X^{i}\\big)=y^{2}\\left[\\partial_{x}\\!\\left(\\frac{X^{x}}{y^{2}}\\right)+\\partial_{y}\\!\\left(\\frac{X^{y}}{y^{2}}\\right)\\right],\n$$\nwhich simplifies to the same coordinate expression above.\n\nLaplacian. The Laplace-Beltrami operator is $\\Delta f=\\operatorname{div}(\\nabla f)$. Using the standard coordinate formula\n$$\n\\Delta f=\\frac{1}{\\sqrt{\\det(g)}}\\,\\partial_{i}\\!\\left(\\sqrt{\\det(g)}\\,g^{ij}\\,\\partial_{j}f\\right),\n$$\nand substituting $\\sqrt{\\det(g)}=\\frac{1}{y^{2}}$ and $g^{ij}=y^{2}\\delta^{ij}$, we obtain\n$$\n\\sqrt{\\det(g)}\\,g^{ij}=\\frac{1}{y^{2}}\\cdot y^{2}\\delta^{ij}=\\delta^{ij},\n$$\nso\n$$\n\\Delta f=\\frac{1}{\\sqrt{\\det(g)}}\\partial_{i}\\left(\\delta^{ij}\\partial_{j}f\\right)=y^{2}\\left(\\partial_{x}^{2}f+\\partial_{y}^{2}f\\right).\n$$\n\nApplication to $f$ and $X$. Let $f(x,y)=x\\,y^{3}+\\ln y$. Compute the first and second partial derivatives:\n$$\n\\partial_{x}f=y^{3},\\quad \\partial_{y}f=3xy^{2}+\\frac{1}{y},\\quad \\partial_{x}^{2}f=0,\\quad \\partial_{y}^{2}f=6xy-\\frac{1}{y^{2}}.\n$$\nHence,\n$$\n\\Delta f = y^{2}\\left(0+6xy-\\frac{1}{y^{2}}\\right)=6xy^{3}-1.\n$$\nFor the vector field $X(x,y)=y^{2}\\,\\partial_{x}+x\\,y\\,\\partial_{y}$, the coordinate components are $X^{x}=y^{2}$ and $X^{y}=xy$. Using the divergence formula,\n$$\n\\operatorname{div}X=\\partial_{x}(y^{2})+\\partial_{y}(xy)-\\frac{2}{y}(xy)=0+x-2x=-x.\n$$\nEvaluate at $(x,y)=(1,1)$:\n$$\n\\Delta f(1,1)=6\\cdot 1\\cdot 1^{3}-1=5,\\qquad \\operatorname{div}X(1,1)=-1,\n$$\nso\n$$\n\\Delta f(1,1)-\\operatorname{div}X(1,1)=5-(-1)=6.\n$$", "answer": "$$\\boxed{6}$$", "id": "3069887"}]}