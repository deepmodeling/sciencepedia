{"hands_on_practices": [{"introduction": "The essence of a Killing vector field is that it represents a continuous symmetry of a geometry. A great way to begin is by verifying this concept in a familiar setting like the Euclidean plane, which we intuitively know is symmetric under translations. This exercise provides hands-on practice with the fundamental definition of a Killing vector field, $\\mathcal{L}_X g = 0$, where $\\mathcal{L}_X g$ is the Lie derivative of the metric $g$ with respect to the vector field $X$. By using polar coordinates to describe a simple translation [@problem_id:1649413], you will reinforce your skills in applying the Lie derivative formula in a non-Cartesian system, where the calculation becomes a richer and more insightful test of your understanding.", "problem": "In the study of symmetries in differential geometry, a Killing vector field on a Riemannian manifold represents an infinitesimal isometry, a transformation that preserves the metric. Consider the two-dimensional Euclidean plane described by polar coordinates $(r, \\theta)$, where $r > 0$. The metric tensor $g$ in this coordinate system is given by the line element $ds^2 = dr^2 + r^2 d\\theta^2$. The non-zero components of the metric tensor are $g_{rr} = 1$ and $g_{\\theta\\theta} = r^2$.\n\nA vector field $X$ is a Killing vector field if the Lie derivative of the metric tensor with respect to $X$ is zero, i.e., $\\mathcal{L}_X g = 0$.\n\nNow, consider the vector field $X$ given by:\n$$\nX = \\cos\\theta \\frac{\\partial}{\\partial r} - \\frac{\\sin\\theta}{r} \\frac{\\partial}{\\partial \\theta}\n$$\nBy computing the components of the Lie derivative tensor $(\\mathcal{L}_X g)_{ij}$, determine which of the following statements is true for this vector field and metric.\n\nA. The component $(\\mathcal{L}_X g)_{rr} = -2\\sin\\theta$ and therefore the field is not a Killing field.\n\nB. The component $(\\mathcal{L}_X g)_{\\theta\\theta} = 2r\\cos\\theta$ and therefore the field is not a Killing field.\n\nC. The component $(\\mathcal{L}_X g)_{r\\theta} = -\\sin\\theta + \\frac{1}{r}$ and therefore the field is not a Killing field.\n\nD. The Lie derivative tensor $\\mathcal{L}_X g$ is identically zero, and therefore the field is a Killing field.\n\nE. All components of the Lie derivative tensor are non-zero, and therefore the field is not a Killing field.", "solution": "To determine if the vector field $X$ is a Killing vector field, we need to compute the Lie derivative of the metric tensor $g$ with respect to $X$, denoted by $\\mathcal{L}_X g$. A vector field $X$ is a Killing field if and only if $\\mathcal{L}_X g = 0$. The components of the Lie derivative of a $(0,2)$-tensor like the metric are given by the formula:\n$$\n(\\mathcal{L}_X g)_{ij} = X^k \\frac{\\partial g_{ij}}{\\partial x^k} + g_{kj} \\frac{\\partial X^k}{\\partial x^i} + g_{ik} \\frac{\\partial X^k}{\\partial x^j}\n$$\nIn our case, the coordinates are $(x^1, x^2) = (r, \\theta)$.\n\nFirst, let's identify the components of the vector field $X$ and the metric tensor $g$.\nThe vector field is $X = \\cos\\theta \\frac{\\partial}{\\partial r} - \\frac{\\sin\\theta}{r} \\frac{\\partial}{\\partial \\theta}$. Its components are:\n$$\nX^r = \\cos\\theta, \\quad X^\\theta = -\\frac{\\sin\\theta}{r}\n$$\nThe metric tensor components are given by $ds^2 = dr^2 + r^2 d\\theta^2$:\n$$\ng_{rr} = 1, \\quad g_{\\theta\\theta} = r^2, \\quad g_{r\\theta} = g_{\\theta r} = 0\n$$\n\nNext, we need the partial derivatives of the vector field components:\n$$\n\\frac{\\partial X^r}{\\partial r} = \\frac{\\partial}{\\partial r}(\\cos\\theta) = 0\n$$\n$$\n\\frac{\\partial X^r}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta}(\\cos\\theta) = -\\sin\\theta\n$$\n$$\n\\frac{\\partial X^\\theta}{\\partial r} = \\frac{\\partial}{\\partial r}\\left(-\\frac{\\sin\\theta}{r}\\right) = \\frac{\\sin\\theta}{r^2}\n$$\n$$\n\\frac{\\partial X^\\theta}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta}\\left(-\\frac{\\sin\\theta}{r}\\right) = -\\frac{\\cos\\theta}{r}\n$$\nAnd the partial derivatives of the metric components:\n$$\n\\frac{\\partial g_{rr}}{\\partial r} = 0, \\quad \\frac{\\partial g_{rr}}{\\partial \\theta} = 0\n$$\n$$\n\\frac{\\partial g_{\\theta\\theta}}{\\partial r} = \\frac{\\partial}{\\partial r}(r^2) = 2r, \\quad \\frac{\\partial g_{\\theta\\theta}}{\\partial \\theta} = 0\n$$\n$$\n\\frac{\\partial g_{r\\theta}}{\\partial r} = 0, \\quad \\frac{\\partial g_{r\\theta}}{\\partial \\theta} = 0\n$$\n\nNow we compute each component of $(\\mathcal{L}_X g)_{ij}$.\n\n**Component $(\\mathcal{L}_X g)_{rr}$:**\n$$\n(\\mathcal{L}_X g)_{rr} = X^k \\frac{\\partial g_{rr}}{\\partial x^k} + g_{kr} \\frac{\\partial X^k}{\\partial r} + g_{rk} \\frac{\\partial X^k}{\\partial r} = X^k \\frac{\\partial g_{rr}}{\\partial x^k} + 2g_{kr} \\frac{\\partial X^k}{\\partial r}\n$$\nSince $g_{rr}$ is constant, its derivatives are zero, so the first term vanishes.\n$$\n(\\mathcal{L}_X g)_{rr} = 2 \\left( g_{rr} \\frac{\\partial X^r}{\\partial r} + g_{\\theta r} \\frac{\\partial X^\\theta}{\\partial r} \\right) = 2 \\left( (1)(0) + (0)\\left(\\frac{\\sin\\theta}{r^2}\\right) \\right) = 0\n$$\n\n**Component $(\\mathcal{L}_X g)_{\\theta\\theta}$:**\n$$\n(\\mathcal{L}_X g)_{\\theta\\theta} = X^k \\frac{\\partial g_{\\theta\\theta}}{\\partial x^k} + g_{k\\theta} \\frac{\\partial X^k}{\\partial \\theta} + g_{\\theta k} \\frac{\\partial X^k}{\\partial \\theta} = X^k \\frac{\\partial g_{\\theta\\theta}}{\\partial x^k} + 2g_{k\\theta} \\frac{\\partial X^k}{\\partial \\theta}\n$$\nLet's expand the terms:\n$$\nX^k \\frac{\\partial g_{\\theta\\theta}}{\\partial x^k} = X^r \\frac{\\partial g_{\\theta\\theta}}{\\partial r} + X^\\theta \\frac{\\partial g_{\\theta\\theta}}{\\partial \\theta} = (\\cos\\theta)(2r) + \\left(-\\frac{\\sin\\theta}{r}\\right)(0) = 2r\\cos\\theta\n$$\n$$\n2g_{k\\theta} \\frac{\\partial X^k}{\\partial \\theta} = 2 \\left( g_{r\\theta} \\frac{\\partial X^r}{\\partial \\theta} + g_{\\theta\\theta} \\frac{\\partial X^\\theta}{\\partial \\theta} \\right) = 2 \\left( (0)(-\\sin\\theta) + (r^2)\\left(-\\frac{\\cos\\theta}{r}\\right) \\right) = 2(-r\\cos\\theta) = -2r\\cos\\theta\n$$\nCombining these results:\n$$\n(\\mathcal{L}_X g)_{\\theta\\theta} = 2r\\cos\\theta - 2r\\cos\\theta = 0\n$$\n\n**Component $(\\mathcal{L}_X g)_{r\\theta}$:**\nDue to the symmetry of the Lie derivative tensor, $(\\mathcal{L}_X g)_{r\\theta} = (\\mathcal{L}_X g)_{\\theta r}$.\n$$\n(\\mathcal{L}_X g)_{r\\theta} = X^k \\frac{\\partial g_{r\\theta}}{\\partial x^k} + g_{kr} \\frac{\\partial X^k}{\\partial \\theta} + g_{k\\theta} \\frac{\\partial X^k}{\\partial r}\n$$\nSince $g_{r\\theta}$ is zero and constant, the first term vanishes.\n$$\n(\\mathcal{L}_X g)_{r\\theta} = \\left( g_{rr} \\frac{\\partial X^r}{\\partial \\theta} + g_{\\theta r} \\frac{\\partial X^\\theta}{\\partial \\theta} \\right) + \\left( g_{r\\theta} \\frac{\\partial X^r}{\\partial r} + g_{\\theta\\theta} \\frac{\\partial X^\\theta}{\\partial r} \\right)\n$$\nSubstituting the known values:\n$$\n(\\mathcal{L}_X g)_{r\\theta} = \\left( (1)(-\\sin\\theta) + (0)\\left(-\\frac{\\cos\\theta}{r}\\right) \\right) + \\left( (0)(0) + (r^2)\\left(\\frac{\\sin\\theta}{r^2}\\right) \\right)\n$$\n$$\n(\\mathcal{L}_X g)_{r\\theta} = -\\sin\\theta + \\sin\\theta = 0\n$$\n\nSince all components $(\\mathcal{L}_X g)_{rr}$, $(\\mathcal{L}_X g)_{\\theta\\theta}$, and $(\\mathcal{L}_X g)_{r\\theta}$ are zero, the Lie derivative tensor $\\mathcal{L}_X g$ is the zero tensor. This satisfies the condition for $X$ to be a Killing vector field.\n\nComparing our results with the given options:\nA. Incorrect, we found $(\\mathcal{L}_X g)_{rr} = 0$.\nB. Incorrect, we found $(\\mathcal{L}_X g)_{\\theta\\theta} = 0$.\nC. Incorrect, we found $(\\mathcal{L}_X g)_{r\\theta} = 0$.\nD. Correct, the Lie derivative tensor is identically zero, and the field is a Killing field.\nE. Incorrect, all components are zero.", "answer": "$$\\boxed{D}$$", "id": "1649413"}, {"introduction": "After confirming a genuine isometry, it is equally instructive to analyze a transformation that does not preserve distances. Uniform scaling is a perfect example, as it stretches the entire space. This practice explores the radial vector field, which generates just such a scaling transformation, and asks you to compute how the metric changes under its flow. This exercise [@problem_id:1649466] serves as a crucial counterexample, clarifying that the Lie derivative is a precise tool for diagnosing when a vector field fails to be a Killing field. You will discover that the result is not zero but is proportional to the metric itself, which is the defining property of a homothetic vector field—a transformation that preserves angles but not lengths.", "problem": "Consider the two-dimensional Euclidean plane $\\mathbb{R}^2$ with standard Cartesian coordinates, which we label as $(x^1, x^2) = (x, y)$. The geometry of this plane is described by the standard Euclidean metric tensor $g$, corresponding to the line element $ds^2 = (dx^1)^2 + (dx^2)^2$.\n\nA vector field $X$ on this plane, which corresponds to an infinitesimal uniform scaling transformation, is given by $X = x^1 \\frac{\\partial}{\\partial x^1} + x^2 \\frac{\\partial}{\\partial x^2}$.\n\nCalculate the components of the Lie derivative of the metric tensor $g$ with respect to the vector field $X$, denoted as $\\mathcal{L}_X g$. Express your answer as a $2 \\times 2$ matrix, representing the components $(\\mathcal{L}_X g)_{ij}$ in the aforementioned coordinate basis.", "solution": "We work in Cartesian coordinates $(x^{1},x^{2})=(x,y)$ on $\\mathbb{R}^{2}$ with the Euclidean metric whose components are $g_{ij}=\\delta_{ij}$, which are constant in these coordinates. The vector field is $X=X^{i}\\partial_{i}$ with components $X^{i}=x^{i}$.\n\nThe Lie derivative of the metric with respect to $X$ has components\n$$\n(\\mathcal{L}_{X}g)_{ij}=X^{k}\\partial_{k}g_{ij}+g_{kj}\\partial_{i}X^{k}+g_{ik}\\partial_{j}X^{k}.\n$$\nSince $g_{ij}=\\delta_{ij}$ are constant, $\\partial_{k}g_{ij}=0$, so the first term vanishes:\n$$\nX^{k}\\partial_{k}g_{ij}=0.\n$$\nNext, we compute $\\partial_{i}X^{k}=\\partial_{i}x^{k}=\\delta_{i}^{k}$. Using $g_{kj}=\\delta_{kj}$ and $g_{ik}=\\delta_{ik}$, we obtain\n$$\n(\\mathcal{L}_{X}g)_{ij}=\\delta_{kj}\\delta_{i}^{k}+\\delta_{ik}\\delta_{j}^{k}=\\delta_{ij}+\\delta_{ij}=2\\delta_{ij}.\n$$\nEquivalently, $\\mathcal{L}_{X}g=2g$. In the given coordinate basis, this corresponds to the $2\\times 2$ matrix with diagonal entries $2$ and off-diagonal entries $0$.", "answer": "$$\\boxed{\\begin{pmatrix}2 & 0 \\\\ 0 & 2\\end{pmatrix}}$$", "id": "1649466"}, {"introduction": "The true power of the Killing vector formalism is revealed when applied to curved spaces, where symmetries are often far from obvious. This problem moves beyond flat space to the Poincaré half-plane, a fundamental model of hyperbolic geometry with constant negative curvature. Here, you will use the full Killing equation, $\\nabla_i X_j + \\nabla_j X_i = 0$, which involves the covariant derivative and Christoffel symbols, to determine the specific form of an isometry. By solving for the unknown coefficients of a given vector field [@problem_id:1649446], you will progress from simply verifying a symmetry to actively discovering its analytical structure, deepening your understanding of the profound connection between a manifold's metric, its curvature, and its isometries.", "problem": "Consider the Poincaré half-plane, defined as the manifold $M = \\{(x,y) \\in \\mathbb{R}^2 \\mid y>0\\}$ equipped with the metric $g$ whose line element is given by\n$$ ds^2 = \\frac{1}{y^2} \\left( dx^2 + dy^2 \\right) $$\nA vector field $X$ on this manifold is defined in the coordinate basis $\\{\\frac{\\partial}{\\partial x}, \\frac{\\partial}{\\partial y}\\}$ as\n$$ X = (Ax+By)\\frac{\\partial}{\\partial x} + (Cx+Dy)\\frac{\\partial}{\\partial y} $$\nwhere $A, B, C,$ and $D$ are real constants.\n\nThe vector field $X$ is known to be a Killing vector field for the given metric. Additionally, it satisfies a condition related to its divergence with respect to the standard Euclidean metric $\\delta$ on $\\mathbb{R}^2$: the Euclidean divergence of $X$, defined as $\\text{div}_{\\delta}(X) = \\frac{\\partial X^x}{\\partial x} + \\frac{\\partial X^y}{\\partial y}$, evaluates to 4 at the point $(x,y)=(1,2)$.\n\nDetermine the values of the constants $(A, B, C, D)$. Present your answer as a row matrix.", "solution": "We use the Killing equation $\\nabla_{i}X_{j}+\\nabla_{j}X_{i}=0$ for the metric $g_{ij}=y^{-2}\\delta_{ij}$ on $M=\\{(x,y)\\in\\mathbb{R}^{2}\\mid y>0\\}$. First compute the nonzero Christoffel symbols for $g_{ij}=y^{-2}\\delta_{ij}$. Writing $\\Omega=y^{-1}$ and $\\ln\\Omega=-\\ln y$, we have $\\partial_{x}\\ln\\Omega=0$ and $\\partial_{y}\\ln\\Omega=-y^{-1}$. The standard formula for conformally flat metrics yields:\n$$\n\\Gamma^{x}_{xy}=\\Gamma^{x}_{yx}=-\\frac{1}{y},\\quad \\Gamma^{y}_{xx}=\\frac{1}{y},\\quad \\Gamma^{y}_{yy}=-\\frac{1}{y},\n$$\nwith all other $\\Gamma^{k}_{ij}$ zero.\n\nWrite $X^{x}=A x+B y$ and $X^{y}=C x+D y$, and lower indices by $X_{x}=g_{xx}X^{x}=y^{-2}(A x+B y)$ and $X_{y}=g_{yy}X^{y}=y^{-2}(C x+D y)$.\n\nCompute the needed covariant derivatives:\n- For $(i,j)=(x,x)$,\n$$\n\\nabla_{x}X_{x}=\\partial_{x}X_{x}-\\Gamma^{k}_{xx}X_{k}=y^{-2}A-\\frac{1}{y}X_{y}.\n$$\nThe Killing equation gives $\\nabla_{x}X_{x}=0$, hence\n$$\ny^{-2}A-\\frac{1}{y}\\cdot y^{-2}(C x+D y)=0 \\;\\Longrightarrow\\; A y-(C x+D y)=0.\n$$\nSince this holds for all $x,y$, we obtain\n$$\nC=0,\\qquad D=A.\n$$\n- For $(i,j)=(y,y)$,\n$$\n\\nabla_{y}X_{y}=\\partial_{y}X_{y}-\\Gamma^{k}_{yy}X_{k}=-2 y^{-3}(C x+D y)+y^{-2}D+\\frac{1}{y}X_{y}.\n$$\nWith $C=0$ and $D=A$, this becomes\n$$\n-2A y^{-2}+A y^{-2}+A y^{-2}=0,\n$$\nso it imposes no new condition.\n- For $(i,j)=(x,y)$,\n$$\n\\nabla_{x}X_{y}=\\partial_{x}X_{y}-\\Gamma^{k}_{xy}X_{k}=y^{-2}C+\\frac{1}{y}X_{x},\\qquad\n\\nabla_{y}X_{x}=\\partial_{y}X_{x}-\\Gamma^{k}_{yx}X_{k}=-2 y^{-3}(A x+B y)+y^{-2}B+\\frac{1}{y}X_{x}.\n$$\nThus\n$$\n\\nabla_{x}X_{y}+\\nabla_{y}X_{x}=y^{-2}C-2 y^{-3}(A x+B y)+y^{-2}B+\\frac{2}{y}X_{x}.\n$$\nUsing $C=0$ and $X_{x}=y^{-2}(A x+B y)$ gives cancellation of the $x,y$-dependent terms and yields\n$$\ny^{-2}B=0 \\;\\Longrightarrow\\; B=0.\n$$\n\nTherefore the Killing conditions force\n$$\nB=0,\\qquad C=0,\\qquad D=A,\n$$\nso $X=A\\,(x\\,\\partial_{x}+y\\,\\partial_{y})$.\n\nNow impose the Euclidean divergence condition. The Euclidean divergence is\n$$\n\\operatorname{div}_{\\delta}(X)=\\frac{\\partial X^{x}}{\\partial x}+\\frac{\\partial X^{y}}{\\partial y}=A+D.\n$$\nAt $(x,y)=(1,2)$ this equals $4$, and since $D=A$ we have\n$$\nA+D=2A=4 \\;\\Longrightarrow\\; A=2.\n$$\nHence $D=2$ and $B=C=0$. The constants are\n$$\n(A,B,C,D)=(2,0,0,2).\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 2 & 0 & 0 & 2 \\end{pmatrix}}$$", "id": "1649446"}]}