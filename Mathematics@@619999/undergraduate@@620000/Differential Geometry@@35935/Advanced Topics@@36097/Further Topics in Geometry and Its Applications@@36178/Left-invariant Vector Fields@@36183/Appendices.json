{"hands_on_practices": [{"introduction": "To begin, let's ground the abstract definition of a left-invariant vector field in a simple and familiar setting. This first exercise [@problem_id:1649947] uses the Lie group $S^1$, the unit circle, to provide a concrete example of how a tangent vector at the identity generates an entire vector field across the group. By working through this problem, you will practice the fundamental skill of applying the pushforward of the left-translation map to determine the vector field's components at any point.", "problem": "Let the Lie group $S^1$ be the unit circle in the plane, consisting of points $g = (x,y)$ such that $x^2+y^2=1$. The group operation is defined by identifying a point $(x,y)$ with the complex number $x+iy$ and using complex multiplication. For two points $g_1=(x_1,y_1)$ and $g_2=(x_2,y_2)$, the product is given by $g_1 g_2 = (x_1x_2 - y_1y_2, x_1y_2 + x_2y_1)$. The identity element of this group is $e=(1,0)$.\n\nA vector field $X$ on $S^1$ is called left-invariant if the vector $X_g$ at any point $g$ is obtained by left-translating the vector at the identity, $X_e$. Formally, this relationship is expressed as $X_g = (dL_g)_e(X_e)$, where $L_g(h) = gh$ is the left-translation map and $(dL_g)_e$ is its differential (or pushforward map) evaluated at the identity.\n\nConsider the tangent vector $X_e = (0,1)$ in the tangent space at the identity, $T_eS^1$. Find the corresponding left-invariant vector field $X$ expressed in Cartesian coordinates. That is, determine the component functions $u(x,y)$ and $v(x,y)$ such that the vector field at any point $(x,y)$ on the circle is given by $X_{(x,y)} = (u(x,y), v(x,y))$.", "solution": "We identify $S^{1}$ with the unit complex numbers. For $g=(x,y)$ and $h=(u,v)$ corresponding to $x+iy$ and $u+iv$, left-translation is $L_{g}(h)=gh$, i.e.,\n$$\nL_{g}(u,v)=(xu-yv, \\, xv+yu).\n$$\nThe differential $(dL_{g})_{e}$ acts on a tangent vector $w=(u,v)\\in T_{e}S^{1}$ by the Jacobian of $L_{g}$ at $e$, which here equals the linear map\n$$\n(u,v)\\mapsto (xu-yv, \\, xv+yu),\n$$\nsince when $g$ is fixed, multiplication by $g$ is linear in $(u,v)$. Equivalently, this is the real $2\\times 2$ matrix\n$$\n\\begin{pmatrix}\nx & -y \\\\\ny & x\n\\end{pmatrix}\n$$\nacting on $(u,v)$. Therefore, for the given $X_{e}=(0,1)$,\n$$\nX_{(x,y)}=(dL_{g})_{e}(X_{e})=\\begin{pmatrix} x & -y \\\\ y & x \\end{pmatrix}\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}=\\begin{pmatrix}-y\\\\x\\end{pmatrix}.\n$$\nThus the component functions are $u(x,y)=-y$ and $v(x,y)=x$.", "answer": "$$\\boxed{\\begin{pmatrix}-y \\\\ x\\end{pmatrix}}$$", "id": "1649947"}, {"introduction": "Having seen a simple case, we now scale up to a more complex and widely applicable Lie group: the Special Euclidean group $SE(2)$, which describes rotations and translations in the plane. This practice [@problem_id:1649977] challenges you to construct a complete basis of left-invariant vector fields from the basis vectors of the tangent space at the identity. This exercise is crucial for understanding how the structure of the group multiplication explicitly determines the form of these fundamental vector fields.", "problem": "The Special Euclidean group in two dimensions, denoted as $SE(2)$, is the set of all rigid body transformations (rotations and translations) in the Euclidean plane. An element $g \\in SE(2)$ can be parameterized by coordinates $(x, y, \\theta)$, where $(x, y)$ represents the translation of the origin and $\\theta$ is the angle of counter-clockwise rotation. The identity element of the group is $e = (0, 0, 0)$.\n\nThe group multiplication, which corresponds to the composition of transformations, is defined as a map $SE(2) \\times SE(2) \\to SE(2)$. For two elements $g_1 = (x_1, y_1, \\theta_1)$ and $g_2 = (x_2, y_2, \\theta_2)$, their product $g_1 g_2$ results in a new element $(x', y', \\theta')$ with coordinates:\n$$x' = x_1 + x_2 \\cos \\theta_1 - y_2 \\sin \\theta_1$$\n$$y' = y_1 + x_2 \\sin \\theta_1 + y_2 \\cos \\theta_1$$\n$$\\theta' = \\theta_1 + \\theta_2$$\nLet $L_{g_1}: SE(2) \\to SE(2)$ denote the left-multiplication map, defined by $L_{g_1}(g_2) = g_1 g_2$.\n\nA vector field $X$ on the manifold $SE(2)$ is called left-invariant if its value at any point $g \\in SE(2)$ is obtained by the pushforward of its value at the identity, $X_e = v \\in T_e SE(2)$. That is, $X_g = (dL_g)_e(v)$ for all $g \\in SE(2)$. The set of all left-invariant vector fields forms a three-dimensional vector space, which is a basis for the Lie algebra $\\mathfrak{se}(2)$.\n\nConsider the standard basis for the tangent space at the identity, $T_e SE(2)$, given by the vectors:\n$v_1 = \\frac{\\partial}{\\partial x}|_e$, corresponding to an infinitesimal translation along the x-axis.\n$v_2 = \\frac{\\partial}{\\partial y}|_e$, corresponding to an infinitesimal translation along the y-axis.\n$v_3 = \\frac{\\partial}{\\partial \\theta}|_e$, corresponding to an infinitesimal rotation.\n\nLet $X_1, X_2, X_3$ be the three left-invariant vector fields on $SE(2)$ generated by $v_1, v_2, v_3$ respectively. At an arbitrary point $g=(x,y,\\theta)$, each vector field can be expressed in the coordinate basis $\\{\\frac{\\partial}{\\partial x}, \\frac{\\partial}{\\partial y}, \\frac{\\partial}{\\partial \\theta}\\}$ as:\n$X_i = f_{i1}(x,y,\\theta)\\frac{\\partial}{\\partial x} + f_{i2}(x,y,\\theta)\\frac{\\partial}{\\partial y} + f_{i3}(x,y,\\theta)\\frac{\\partial}{\\partial \\theta}$\nfor $i=1, 2, 3$.\n\nDetermine the component functions $f_{ij}(x,y,\\theta)$. Your final answer should be given as a $3 \\times 3$ matrix $F$ whose entry in the $i$-th row and $j$-th column is the function $F_{ij} = f_{ij}(x,y,\\theta)$.", "solution": "We use the definition of left-invariance: for each $i \\in \\{1,2,3\\}$ and any $g=(x,y,\\theta) \\in SE(2)$, the left-invariant vector field generated by $v_{i} \\in T_{e}SE(2)$ is $X_{i}(g)=(dL_{g})_{e}(v_{i})$, where $L_{g}(h)=g h$.\n\nFix $g_{1}=(x,y,\\theta)$ and write $g_{2}=(x_{2},y_{2},\\theta_{2})$. The left-multiplication map $L_{g_{1}}: SE(2)\\to SE(2)$ is\n$$\nL_{g_{1}}(g_{2})=(x',y',\\theta'),\\quad\n\\begin{cases}\nx' = x + x_{2}\\cos\\theta - y_{2}\\sin\\theta,\\\\\ny' = y + x_{2}\\sin\\theta + y_{2}\\cos\\theta,\\\\\n\\theta' = \\theta + \\theta_{2}.\n\\end{cases}\n$$\nTo compute $(dL_{g_{1}})_{e}$, we take the Jacobian of $(x',y',\\theta')$ with respect to $(x_{2},y_{2},\\theta_{2})$ and evaluate at $g_{2}=e=(0,0,0)$ (the result is independent of $(x_{2},y_{2},\\theta_{2})$ here):\n$$\n\\frac{\\partial(x',y',\\theta')}{\\partial(x_{2},y_{2},\\theta_{2})}\n=\n\\begin{pmatrix}\n\\frac{\\partial x'}{\\partial x_{2}} & \\frac{\\partial x'}{\\partial y_{2}} & \\frac{\\partial x'}{\\partial \\theta_{2}}\\\\ [4pt]\n\\frac{\\partial y'}{\\partial x_{2}} & \\frac{\\partial y'}{\\partial y_{2}} & \\frac{\\partial y'}{\\partial \\theta_{2}}\\\\ [4pt]\n\\frac{\\partial \\theta'}{\\partial x_{2}} & \\frac{\\partial \\theta'}{\\partial y_{2}} & \\frac{\\partial \\theta'}{\\partial \\theta_{2}}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\cos\\theta & -\\sin\\theta & 0\\\\\n\\sin\\theta & \\cos\\theta & 0\\\\\n0 & 0 & 1\n\\end{pmatrix}.\n$$\nIdentify the basis at the identity as $v_{1}=\\frac{\\partial}{\\partial x}\\big|_{e}$, $v_{2}=\\frac{\\partial}{\\partial y}\\big|_{e}$, $v_{3}=\\frac{\\partial}{\\partial \\theta}\\big|_{e}$. The pushforward sends these basis vectors to the columns of the Jacobian, expressed in the coordinate basis $\\{\\frac{\\partial}{\\partial x},\\frac{\\partial}{\\partial y},\\frac{\\partial}{\\partial \\theta}\\}$ at $g$:\n- $(dL_{g})_{e}(v_{1})$ has components $(\\cos\\theta,\\ \\sin\\theta,\\ 0)$, hence\n$$\nX_{1}=\\cos\\theta\\,\\frac{\\partial}{\\partial x}+\\sin\\theta\\,\\frac{\\partial}{\\partial y}+0\\,\\frac{\\partial}{\\partial \\theta}.\n$$\n- $(dL_{g})_{e}(v_{2})$ has components $(-\\sin\\theta,\\ \\cos\\theta,\\ 0)$, hence\n$$\nX_{2}=-\\sin\\theta\\,\\frac{\\partial}{\\partial x}+\\cos\\theta\\,\\frac{\\partial}{\\partial y}+0\\,\\frac{\\partial}{\\partial \\theta}.\n$$\n- $(dL_{g})_{e}(v_{3})$ has components $(0,\\ 0,\\ 1)$, hence\n$$\nX_{3}=0\\,\\frac{\\partial}{\\partial x}+0\\,\\frac{\\partial}{\\partial y}+1\\,\\frac{\\partial}{\\partial \\theta}=\\frac{\\partial}{\\partial \\theta}.\n$$\n\nTherefore, the component functions $f_{ij}(x,y,\\theta)$ form the $3\\times 3$ matrix\n$$\nF(x,y,\\theta)=\\begin{pmatrix}\n\\cos\\theta & \\sin\\theta & 0\\\\\n-\\sin\\theta & \\cos\\theta & 0\\\\\n0 & 0 & 1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\cos\\theta & \\sin\\theta & 0\\\\ -\\sin\\theta & \\cos\\theta & 0\\\\ 0 & 0 & 1\\end{pmatrix}}$$", "id": "1649977"}, {"introduction": "Left-invariant vector fields do not just exist in isolation; they form a Lie algebra, with the Lie bracket as the algebraic operation. This final exercise [@problem_id:1649953] makes a pivotal connection between the geometric Lie bracket of vector fields and the algebraic commutator of matrices in the Lie algebra $\\mathfrak{su}(2)$, which is central to quantum mechanics. By calculating the structure constants, you will verify that the algebraic structure of the matrix Lie algebra is perfectly mirrored by the algebra of its corresponding left-invariant vector fields.", "problem": "Consider the Special Unitary group, denoted $SU(2)$, which is the group of $2 \\times 2$ complex unitary matrices with determinant 1. Its associated Lie algebra, $\\mathfrak{su}(2)$, is the vector space of all $2 \\times 2$ traceless, skew-hermitian matrices.\n\nA standard basis for the real vector space $\\mathfrak{su}(2)$ is given by the matrices $\\{T_1, T_2, T_3\\}$, where $T_j = -\\frac{i}{2}\\sigma_j$ and $\\sigma_j$ for $j \\in \\{1,2,3\\}$ are the Pauli matrices:\n$$ \\sigma_1 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad \\sigma_2 = \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix}, \\quad \\sigma_3 = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} $$\n\nFor any matrix Lie group $G$ with Lie algebra $\\mathfrak{g}$, an element $A \\in \\mathfrak{g}$ generates a left-invariant vector field $X_A$ on $G$. This vector field is defined at any point $g \\in G$ by the matrix product $X_A(g) = gA$. Let $\\{X_1, X_2, X_3\\}$ be the basis of left-invariant vector fields on $SU(2)$ corresponding to the basis $\\{T_1, T_2, T_3\\}$ of $\\mathfrak{su}(2)$, such that $X_j = X_{T_j}$.\n\nThe Lie bracket of two such vector fields generated by algebra elements $A$ and $B$ is given by the formula $[X_A, X_B](g) = g(AB - BA) = g[A, B]$. Because the Lie bracket of two left-invariant vector fields is itself left-invariant, the result of bracketing two basis fields $[X_i, X_j]$ must be a linear combination of the basis vector fields:\n$$ [X_i, X_j] = \\sum_{k=1}^{3} c^k_{ij} X_k $$\nThe coefficients $c^k_{ij}$ are the structure constants of the Lie algebra $\\mathfrak{su}(2)$ with respect to the chosen basis.\n\nYour task is to determine these structure constants. Find a general, closed-form expression for $c^k_{ij}$ for $i,j,k \\in \\{1,2,3\\}$. Your answer should be expressed in terms of the Levi-Civita symbol $\\varepsilon_{ijk}$, which is defined as $+1$ for an even permutation of $(1,2,3)$, $-1$ for an odd permutation, and $0$ if any index is repeated.", "solution": "The problem asks for the structure constants $c^k_{ij}$ of the Lie algebra $\\mathfrak{su}(2)$ with respect to the basis of left-invariant vector fields $\\{X_1, X_2, X_3\\}$ corresponding to the Lie algebra basis $\\{T_1, T_2, T_3\\}$.\n\nThe structure constants are defined by the relation:\n$$ [X_i, X_j] = \\sum_{k=1}^{3} c^k_{ij} X_k $$\n\nWe are given the formula for the Lie bracket of left-invariant vector fields generated by Lie algebra elements $A$ and $B$: $[X_A, X_B](g) = g[A, B]$, where $[A,B] = AB-BA$ is the matrix commutator. For our basis vector fields $X_i = X_{T_i}$ and $X_j = X_{T_j}$, this becomes:\n$$ [X_i, X_j](g) = g[T_i, T_j] $$\n\nThe definition of the structure constants can be evaluated at a point $g \\in SU(2)$. Using the definition $X_k(g) = gT_k$, we have:\n$$ \\left( \\sum_{k=1}^{3} c^k_{ij} X_k \\right)(g) = \\sum_{k=1}^{3} c^k_{ij} X_k(g) = \\sum_{k=1}^{3} c^k_{ij} (gT_k) = g\\left( \\sum_{k=1}^{3} c^k_{ij} T_k \\right) $$\n\nEquating the two expressions for $[X_i, X_j](g)$, we find:\n$$ g[T_i, T_j] = g\\left( \\sum_{k=1}^{3} c^k_{ij} T_k \\right) $$\nSince this equality must hold for all $g \\in SU(2)$, we can left-multiply by $g^{-1}$ to get an identity in the Lie algebra $\\mathfrak{su}(2)$:\n$$ [T_i, T_j] = \\sum_{k=1}^{3} c^k_{ij} T_k $$\nThis shows that the structure constants of the Lie algebra of left-invariant vector fields are identical to the structure constants of the matrix Lie algebra $\\mathfrak{su}(2)$ itself, with respect to the basis $\\{T_k\\}$.\n\nOur task is now to compute the commutators $[T_i, T_j]$ and express the result as a linear combination of the basis elements $T_k$. The basis is $T_j = -\\frac{i}{2}\\sigma_j$.\nThe commutator is:\n$$ [T_i, T_j] = T_i T_j - T_j T_i = \\left(-\\frac{i}{2}\\sigma_i\\right) \\left(-\\frac{i}{2}\\sigma_j\\right) - \\left(-\\frac{i}{2}\\sigma_j\\right) \\left(-\\frac{i}{2}\\sigma_i\\right) = \\left(-\\frac{i}{2}\\right)^2 (\\sigma_i \\sigma_j - \\sigma_j \\sigma_i) = -\\frac{1}{4}[\\sigma_i, \\sigma_j] $$\n\nNext, we compute the commutators of the Pauli matrices. Let's compute one explicit example, for $(i,j)=(1,2)$:\n$$ [\\sigma_1, \\sigma_2] = \\sigma_1 \\sigma_2 - \\sigma_2 \\sigma_1 = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & -i \\\\ i & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} $$\n$$ = \\begin{pmatrix} i & 0 \\\\ 0 & -i \\end{pmatrix} - \\begin{pmatrix} -i & 0 \\\\ 0 & i \\end{pmatrix} = \\begin{pmatrix} 2i & 0 \\\\ 0 & -2i \\end{pmatrix} = 2i \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = 2i\\sigma_3 $$\nA well-known property of the Pauli matrices, which can be verified by direct computation for all pairs, is $[\\sigma_i, \\sigma_j] = 2i \\sum_{k=1}^3 \\varepsilon_{ijk} \\sigma_k$.\n\nNow, we substitute this result back into our expression for the commutator of the $T$ matrices:\n$$ [T_i, T_j] = -\\frac{1}{4}[\\sigma_i, \\sigma_j] = -\\frac{1}{4} \\left( 2i \\sum_{k=1}^{3} \\varepsilon_{ijk} \\sigma_k \\right) = -\\frac{i}{2} \\sum_{k=1}^{3} \\varepsilon_{ijk} \\sigma_k $$\n\nTo find the coefficients $c^k_{ij}$, we need to express this result in the basis $\\{T_k\\}$. We have $T_k = -\\frac{i}{2}\\sigma_k$, which implies $\\sigma_k = \\frac{2T_k}{-i} = 2iT_k$. Substituting this for $\\sigma_k$:\n$$ [T_i, T_j] = -\\frac{i}{2} \\sum_{k=1}^{3} \\varepsilon_{ijk} (2iT_k) = (-i^2) \\sum_{k=1}^{3} \\varepsilon_{ijk} T_k = \\sum_{k=1}^{3} \\varepsilon_{ijk} T_k $$\n\nWe have now calculated the commutator in the desired form:\n$$ [T_i, T_j] = \\sum_{k=1}^{3} \\varepsilon_{ijk} T_k $$\nComparing this expression with the definition of the structure constants, $[T_i, T_j] = \\sum_{k=1}^{3} c^k_{ij} T_k$, we can directly identify the coefficients by matching terms for each basis vector $T_k$:\n$$ c^k_{ij} = \\varepsilon_{ijk} $$\nThe position of the index $k$ is up in $c^k_{ij}$ and down in $\\varepsilon_{ijk}$, but in this context with an orthonormal basis (with respect to the Killing form), this distinction is merely notational, and the equality holds for the components. To be explicit, the component of the vector $[T_i, T_j]$ along the basis vector $T_k$ is $c^k_{ij}$, which we found to be $\\varepsilon_{ijk}$.", "answer": "$$\\boxed{\\varepsilon_{ijk}}$$", "id": "1649953"}]}