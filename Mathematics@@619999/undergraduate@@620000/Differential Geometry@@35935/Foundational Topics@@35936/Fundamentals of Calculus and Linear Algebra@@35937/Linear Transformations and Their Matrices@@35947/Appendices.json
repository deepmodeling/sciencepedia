{"hands_on_practices": [{"introduction": "A crucial step in understanding any linear transformation is to identify its kernelâ€”the set of all vectors that the transformation maps to the zero vector. This exercise [@problem_id:1651517] provides a hands-on opportunity to connect this algebraic concept to a clear geometric picture. By analyzing an orthogonal projection, you will develop an intuition for how the kernel, $\\ker(L)$, reveals what information is 'lost' by a transformation.", "problem": "Consider a linear transformation $L: \\mathbb{R}^3 \\to \\mathbb{R}^3$ that maps any vector in three-dimensional space to its orthogonal projection onto the $xy$-plane. The kernel of this transformation, denoted $\\ker(L)$, is the set of all input vectors that are mapped to the zero vector by $L$. Which of the following options provides a complete and accurate geometric description of $\\ker(L)$?\n\nA. The origin point $(0, 0, 0)$ only.\n\nB. The set of all vectors lying on the $x$-axis.\n\nC. The set of all vectors lying on the $z$-axis.\n\nD. The set of all vectors lying in the $xy$-plane.\n\nE. The set of all vectors lying in the $yz$-plane.", "solution": "Let a general vector in $\\mathbb{R}^3$ be represented by $\\mathbf{v} = (x, y, z)$. The linear transformation $L$ projects this vector orthogonally onto the $xy$-plane. This means the transformation sets the $z$-component of the vector to zero, while leaving the $x$ and $y$ components unchanged. Therefore, the action of the transformation $L$ on the vector $\\mathbf{v}$ can be expressed as:\n$$L(\\mathbf{v}) = L(x, y, z) = (x, y, 0)$$\n\nThe kernel of a linear transformation $L$, denoted $\\ker(L)$, is the set of all vectors $\\mathbf{v}$ in the domain such that $L(\\mathbf{v}) = \\mathbf{0}$, where $\\mathbf{0}$ is the zero vector in the codomain. In this case, the domain and codomain are both $\\mathbb{R}^3$, so the zero vector is $\\mathbf{0} = (0, 0, 0)$.\n\nTo find the kernel of $L$, we must solve the equation $L(\\mathbf{v}) = \\mathbf{0}$:\n$$L(x, y, z) = (0, 0, 0)$$\nUsing the definition of our transformation $L$, this becomes:\n$$(x, y, 0) = (0, 0, 0)$$\n\nFor this vector equation to be true, each corresponding component must be equal. This gives us a system of equations:\n1.  $x = 0$\n2.  $y = 0$\n3.  $0 = 0$\n\nThe first two equations state that the $x$ and $y$ components of any vector in the kernel must be zero. The third equation, $0=0$, is always true and places no constraint on the $z$-component. Therefore, the variable $z$ can be any real number.\n\nAny vector $\\mathbf{v}$ in the kernel of $L$ must have the form $\\mathbf{v} = (0, 0, z)$ where $z \\in \\mathbb{R}$. This is the set of all vectors that point along the $z$-axis, including the zero vector (when $z=0$). Geometrically, this set of vectors constitutes the entire $z$-axis.\n\nNow we evaluate the given options:\nA. The origin point $(0, 0, 0)$ only. This is incorrect because it only accounts for the case where $z=0$. The kernel includes infinitely many other vectors, such as $(0, 0, 1)$ and $(0, 0, -5)$.\nB. The set of all vectors lying on the $x$-axis. This corresponds to vectors of the form $(x, 0, 0)$, which is incorrect.\nC. The set of all vectors lying on the $z$-axis. This corresponds to vectors of the form $(0, 0, z)$, which matches our result.\nD. The set of all vectors lying in the $xy$-plane. This corresponds to vectors of the form $(x, y, 0)$. These are the vectors that are *unchanged* by the projection (the image of L), not the vectors mapped to zero.\nE. The set of all vectors lying in the $yz$-plane. This corresponds to vectors of the form $(0, y, z)$, which is incorrect.\n\nThus, the correct geometric description of the kernel of $L$ is the entire $z$-axis.", "answer": "$$\\boxed{C}$$", "id": "1651517"}, {"introduction": "In many applications, from robotics to computer graphics, complex operations are built by chaining together simpler linear transformations. This practice [@problem_id:1651567] explores this process of composition, where you will first project a vector and then rotate it. The key takeaway is learning how this sequence of geometric operations is elegantly captured by the product of their corresponding matrices, a fundamental concept in linear algebra.", "problem": "In a simplified 2D computer graphics pipeline, a shape is processed through a series of transformations. Consider two such linear transformations acting on vectors in the plane $\\mathbb{R}^2$. The first transformation, $P: \\mathbb{R}^2 \\to \\mathbb{R}^2$, is an orthogonal projection that maps any vector onto the x-axis. The second transformation, $R: \\mathbb{R}^2 \\to \\mathbb{R}^2$, is a counterclockwise rotation about the origin by an angle of $\\frac{\\pi}{4}$ radians.\n\nA composite transformation, $L: \\mathbb{R}^2 \\to \\mathbb{R}^2$, is formed by first applying the projection $P$ to a vector, and then applying the rotation $R$ to the resulting vector.\n\nDetermine the $2 \\times 2$ standard matrix representation of the composite linear transformation $L$ with respect to the standard basis of $\\mathbb{R}^2$.", "solution": "The problem asks for the standard matrix representation of a composite linear transformation $L$, which is defined as $L = R \\circ P$. This means for any vector $\\mathbf{v} \\in \\mathbb{R}^2$, $L(\\mathbf{v}) = R(P(\\mathbf{v}))$. The matrix of a composition of linear transformations is the product of their individual matrices. If $[P]$ is the matrix for the projection and $[R]$ is the matrix for the rotation, the matrix for the composite transformation $L$, denoted as $[L]$, is given by the product $[L] = [R][P]$.\n\nOur first step is to find the standard matrix for the projection $P$. The transformation $P$ projects any vector $(x, y)$ onto the x-axis. The result of this projection is the vector $(x, 0)$. We can find the matrix $[P]$ by observing how it transforms the standard basis vectors of $\\mathbb{R}^2$, which are $\\mathbf{e}_1 = (1, 0)$ and $\\mathbf{e}_2 = (0, 1)$.\nThe image of $\\mathbf{e}_1$ under $P$ is $P(\\mathbf{e}_1) = P(1, 0) = (1, 0)$. This forms the first column of the matrix $[P]$.\nThe image of $\\mathbf{e}_2$ under $P$ is $P(\\mathbf{e}_2) = P(0, 1) = (0, 0)$. This forms the second column of the matrix $[P]$.\nTherefore, the matrix for the projection $P$ is:\n$$\n[P] = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\n\nOur second step is to find the standard matrix for the rotation $R$. The transformation $R$ is a counterclockwise rotation about the origin by an angle $\\theta$. The general form of the matrix for such a rotation is:\n$$\n[R_\\theta] = \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}\n$$\nIn our case, the angle is $\\theta = \\frac{\\pi}{4}$ radians. We evaluate the trigonometric functions for this angle:\n$$\n\\cos\\left(\\frac{\\pi}{4}\\right) = \\frac{\\sqrt{2}}{2}\n$$\n$$\n\\sin\\left(\\frac{\\pi}{4}\\right) = \\frac{\\sqrt{2}}{2}\n$$\nSubstituting these values into the rotation matrix formula gives us the matrix for $R$:\n$$\n[R] = \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} \\end{pmatrix}\n$$\n\nThe final step is to compute the matrix for the composite transformation $L$ by multiplying the matrices $[R]$ and $[P]$ in the correct order, which is $[L] = [R][P]$.\n$$\n[L] = [R][P] = \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n$$\nWe perform the matrix multiplication:\n$$\n[L] = \\begin{pmatrix} \\left(\\frac{\\sqrt{2}}{2}\\right)(1) + \\left(-\\frac{\\sqrt{2}}{2}\\right)(0) & \\left(\\frac{\\sqrt{2}}{2}\\right)(0) + \\left(-\\frac{\\sqrt{2}}{2}\\right)(0) \\\\ \\left(\\frac{\\sqrt{2}}{2}\\right)(1) + \\left(\\frac{\\sqrt{2}}{2}\\right)(0) & \\left(\\frac{\\sqrt{2}}{2}\\right)(0) + \\left(\\frac{\\sqrt{2}}{2}\\right)(0) \\end{pmatrix}\n$$\n$$\n[L] = \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & 0 \\\\ \\frac{\\sqrt{2}}{2} & 0 \\end{pmatrix}\n$$\nThis is the standard matrix representation of the composite transformation $L$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\sqrt{2}}{2} & 0 \\\\ \\frac{\\sqrt{2}}{2} & 0 \\end{pmatrix}}$$", "id": "1651567"}, {"introduction": "While rotations in a 2D plane are straightforward, rotations in 3D space introduce a new layer of complexity, especially when the axis of rotation is arbitrary. This challenge [@problem_id:1651534] guides you through constructing the matrix for such a transformation using the powerful Rodrigues' rotation formula. Mastering this technique is essential for tackling problems in physics, engineering, and advanced geometry where describing spatial orientation is key.", "problem": "Consider a linear transformation $T: \\mathbb{R}^3 \\to \\mathbb{R}^3$ that represents a rotation in three-dimensional Euclidean space. The rotation is performed by an angle $\\theta = \\frac{2\\pi}{3}$ radians around an axis defined by the unit vector $\\mathbf{u} = \\frac{1}{\\sqrt{3}}(1, 1, 1)$. The direction of rotation is determined by the right-hand rule with respect to the vector $\\mathbf{u}$.\n\nDetermine the standard $3 \\times 3$ matrix $R$ that represents this transformation, such that $T(\\mathbf{v}) = R\\mathbf{v}$ for any vector $\\mathbf{v} \\in \\mathbb{R}^3$. The entries of the matrix should be numerical values.", "solution": "We use Rodrigues' rotation formula for a rotation by angle $\\theta$ about a unit axis $\\mathbf{u}$:\n$$\nR=\\cos\\theta\\,I+(1-\\cos\\theta)\\,\\mathbf{u}\\mathbf{u}^{T}+\\sin\\theta\\,[\\mathbf{u}]_{\\times},\n$$\nwhere $I$ is the $3\\times 3$ identity, $\\mathbf{u}\\mathbf{u}^{T}$ is the outer product, and $[\\mathbf{u}]_{\\times}$ is the skew-symmetric matrix representing cross product with $\\mathbf{u}$:\n$$\n[\\mathbf{u}]_{\\times}=\\begin{pmatrix}\n0 & -u_{3} & u_{2}\\\\\nu_{3} & 0 & -u_{1}\\\\\n-u_{2} & u_{1} & 0\n\\end{pmatrix}.\n$$\nHere $\\theta=\\frac{2\\pi}{3}$ so $\\cos\\theta=-\\frac{1}{2}$ and $\\sin\\theta=\\frac{\\sqrt{3}}{2}$. The axis is $\\mathbf{u}=\\frac{1}{\\sqrt{3}}(1,1,1)$, so\n$$\n\\mathbf{u}\\mathbf{u}^{T}=\\frac{1}{3}\\begin{pmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{pmatrix},\\qquad\n[\\mathbf{u}]_{\\times}=\\frac{1}{\\sqrt{3}}\\begin{pmatrix}\n0 & -1 & 1\\\\\n1 & 0 & -1\\\\\n-1 & 1 & 0\n\\end{pmatrix}.\n$$\nCompute each term:\n$$\n\\cos\\theta\\,I=-\\frac{1}{2}I,\\qquad\n(1-\\cos\\theta)\\,\\mathbf{u}\\mathbf{u}^{T}=\\frac{3}{2}\\cdot\\frac{1}{3}\\begin{pmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{pmatrix}=\\frac{1}{2}\\begin{pmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{pmatrix},\n$$\n$$\n\\sin\\theta\\,[\\mathbf{u}]_{\\times}=\\frac{\\sqrt{3}}{2}\\cdot \\frac{1}{\\sqrt{3}}\\begin{pmatrix}\n0 & -1 & 1\\\\\n1 & 0 & -1\\\\\n-1 & 1 & 0\n\\end{pmatrix}=\\frac{1}{2}\\begin{pmatrix}\n0 & -1 & 1\\\\\n1 & 0 & -1\\\\\n-1 & 1 & 0\n\\end{pmatrix}.\n$$\nSumming these three matrices gives\n$$\nR=-\\frac{1}{2}I+\\frac{1}{2}\\begin{pmatrix}\n1 & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1\n\\end{pmatrix}+\\frac{1}{2}\\begin{pmatrix}\n0 & -1 & 1\\\\\n1 & 0 & -1\\\\\n-1 & 1 & 0\n\\end{pmatrix}=\\begin{pmatrix}\n0 & 0 & 1\\\\\n1 & 0 & 0\\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nThis matrix performs the right-hand rotation by $\\frac{2\\pi}{3}$ around the axis $\\mathbf{u}$.", "answer": "$$\\boxed{\\begin{pmatrix}0 & 0 & 1\\\\ 1 & 0 & 0\\\\ 0 & 1 & 0\\end{pmatrix}}$$", "id": "1651534"}]}