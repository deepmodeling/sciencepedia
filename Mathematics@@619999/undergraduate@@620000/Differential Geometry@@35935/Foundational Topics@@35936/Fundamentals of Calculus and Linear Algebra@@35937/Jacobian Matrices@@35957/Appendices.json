{"hands_on_practices": [{"introduction": "The first step toward mastering the Jacobian matrix is practicing its direct computation. This exercise provides foundational practice by asking you to calculate the Jacobian for a map from a 2D parameter space to 3D Euclidean space. The transformation itself describes a conical surface, a familiar geometric object, which helps connect the abstract matrix of partial derivatives to a tangible shape [@problem_id:1648610].", "id": "1648610", "problem": "Consider a transformation $F$ from a 2-dimensional parameter space with coordinates $(u, v)$ to a 3-dimensional Euclidean space with coordinates $(x, y, z)$. This transformation is defined by the following component functions:\n$x(u, v) = u \\cos(v)$\n$y(u, v) = u \\sin(v)$\n$z(u, v) = u$\n\nThis transformation describes a conical surface where $u$ represents the distance from the apex along a generator line and $v$ is the azimuthal angle.\n\nCalculate the Jacobian matrix of the transformation $F$, denoted as $J_F$.\n\n", "solution": "We are given a mapping $F:(u,v)\\mapsto (x(u,v),y(u,v),z(u,v))$ with\n$$\nx(u,v)=u\\cos(v),\\quad y(u,v)=u\\sin(v),\\quad z(u,v)=u.\n$$\nThe Jacobian matrix $J_{F}$ is the matrix of first-order partial derivatives of $(x,y,z)$ with respect to $(u,v)$, organized with rows corresponding to $x,y,z$ and columns to $u,v$:\n$$\nJ_{F}(u,v)=\n\\begin{pmatrix}\n\\frac{\\partial x}{\\partial u} & \\frac{\\partial x}{\\partial v} \\\\\n\\frac{\\partial y}{\\partial u} & \\frac{\\partial y}{\\partial v} \\\\\n\\frac{\\partial z}{\\partial u} & \\frac{\\partial z}{\\partial v}\n\\end{pmatrix}.\n$$\nCompute each partial derivative explicitly:\n- For $x(u,v)=u\\cos(v)$,\n$$\n\\frac{\\partial x}{\\partial u}=\\cos(v),\\qquad \\frac{\\partial x}{\\partial v}=-u\\sin(v).\n$$\n- For $y(u,v)=u\\sin(v)$,\n$$\n\\frac{\\partial y}{\\partial u}=\\sin(v),\\qquad \\frac{\\partial y}{\\partial v}=u\\cos(v).\n$$\n- For $z(u,v)=u$,\n$$\n\\frac{\\partial z}{\\partial u}=1,\\qquad \\frac{\\partial z}{\\partial v}=0.\n$$\nSubstituting these into the Jacobian matrix gives\n$$\nJ_{F}(u,v)=\n\\begin{pmatrix}\n\\cos(v) & -u\\sin(v) \\\\\n\\sin(v) & u\\cos(v) \\\\\n1 & 0\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\cos(v) & -u\\sin(v) \\\\ \\sin(v) & u\\cos(v) \\\\ 1 & 0\\end{pmatrix}}$$"}, {"introduction": "A key application of the Jacobian is identifying singular points where a transformation behaves degenerately. At these points, the Jacobian determinant vanishes, indicating that the map is not locally invertibleâ€”it may \"crush\" or \"fold\" space. This exercise challenges you to find such singular points for a given transformation and demonstrates the deep connection between the determinant of the Jacobian and the local properties of a function [@problem_id:1648612].", "id": "1648612", "problem": "Consider a two-dimensional transformation from Cartesian coordinates $(x,y)$ to a new coordinate system $(u,v)$ defined by the map $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$. The specific transformation is given by:\n$$ u(x,y) = \\sin(x) $$\n$$ v(x,y) = y^3 - 3y $$\nPoints in the $(x,y)$-plane where the Jacobian determinant of this transformation is zero are called singular points, as the transformation is not locally invertible at these locations.\nYour task is to find all such singular points that also lie on the circle defined by the equation $x^2 + y^2 = \\frac{\\pi^2}{4}$. After identifying all these points, calculate the sum of the squares of their $x$-coordinates. Express your answer as a single closed-form analytic expression in terms of $\\pi$.\n\n", "solution": "The problem asks for the sum of the squares of the $x$-coordinates of all points $(x,y)$ that satisfy two conditions:\n1. The Jacobian determinant of the transformation $f(x,y) = (\\sin(x), y^3 - 3y)$ is zero.\n2. The point $(x,y)$ lies on the circle $x^2 + y^2 = \\frac{\\pi^2}{4}$.\n\nFirst, let's compute the Jacobian matrix $J_f$ of the transformation $f(x,y) = (u(x,y), v(x,y))$.\nThe components of the transformation are $u(x,y) = \\sin(x)$ and $v(x,y) = y^3 - 3y$.\nThe Jacobian matrix is defined as:\n$$ J_f(x,y) = \\begin{pmatrix} \\frac{\\partial u}{\\partial x} & \\frac{\\partial u}{\\partial y} \\\\ \\frac{\\partial v}{\\partial x} & \\frac{\\partial v}{\\partial y} \\end{pmatrix} $$\nWe calculate the partial derivatives:\n$\\frac{\\partial u}{\\partial x} = \\cos(x)$\n$\\frac{\\partial u}{\\partial y} = 0$\n$\\frac{\\partial v}{\\partial x} = 0$\n$\\frac{\\partial v}{\\partial y} = 3y^2 - 3$\n\nSubstituting these into the matrix, we get:\n$$ J_f(x,y) = \\begin{pmatrix} \\cos(x) & 0 \\\\ 0 & 3y^2 - 3 \\end{pmatrix} $$\nThe Jacobian determinant is the determinant of this matrix:\n$$ \\det(J_f) = \\cos(x) (3y^2 - 3) $$\nThe first condition states that the points are singular, meaning the Jacobian determinant is zero:\n$$ \\cos(x) (3y^2 - 3) = 0 $$\nThis equation holds true if either $\\cos(x) = 0$ or $3y^2 - 3 = 0$. We must now find the points satisfying one of these conditions along with the circle equation $x^2 + y^2 = \\frac{\\pi^2}{4}$. We analyze the two cases separately.\n\nCase 1: $3y^2 - 3 = 0$.\nSolving for $y$, we have $3y^2 = 3$, which gives $y^2 = 1$, so $y = 1$ or $y = -1$.\nWe substitute these values into the circle equation $x^2 + y^2 = \\frac{\\pi^2}{4}$.\nFor both $y=1$ and $y=-1$, we have $y^2=1$.\n$x^2 + 1 = \\frac{\\pi^2}{4}$\n$x^2 = \\frac{\\pi^2}{4} - 1$\nThis gives two possible values for $x$: $x = \\pm \\sqrt{\\frac{\\pi^2}{4} - 1}$.\nSince $\\pi \\approx 3.14$, $\\pi^2 \\approx 9.86$, and $\\frac{\\pi^2}{4} \\approx 2.465$. Thus, $\\frac{\\pi^2}{4} - 1 > 0$, and real solutions for $x$ exist.\nThis case yields four points:\n$(\\sqrt{\\frac{\\pi^2}{4} - 1}, 1)$, $(-\\sqrt{\\frac{\\pi^2}{4} - 1}, 1)$, $(\\sqrt{\\frac{\\pi^2}{4} - 1}, -1)$, and $(-\\sqrt{\\frac{\\pi^2}{4} - 1}, -1)$.\n\nCase 2: $\\cos(x) = 0$.\nThe general solution for $\\cos(x) = 0$ is $x = \\frac{\\pi}{2} + k\\pi$ for any integer $k$.\nWe substitute this into the circle equation $x^2 + y^2 = \\frac{\\pi^2}{4}$ to find the corresponding $y$ values.\n$y^2 = \\frac{\\pi^2}{4} - x^2 = \\frac{\\pi^2}{4} - (\\frac{\\pi}{2} + k\\pi)^2$.\nFor real solutions for $y$ to exist, we must have $y^2 \\ge 0$, which implies $x^2 \\le \\frac{\\pi^2}{4}$.\nSo, we must have $(\\frac{\\pi}{2} + k\\pi)^2 \\le \\frac{\\pi^2}{4}$.\nTaking the square root of both sides gives $| \\frac{\\pi}{2} + k\\pi | \\le \\frac{\\pi}{2}$, which is equivalent to $|\\pi(\\frac{1}{2} + k)| \\le \\frac{\\pi}{2}$, or $|\\frac{1}{2} + k| \\le \\frac{1}{2}$.\nThis inequality simplifies to $-\\frac{1}{2} \\le \\frac{1}{2} + k \\le \\frac{1}{2}$.\nSubtracting $\\frac{1}{2}$ from all parts gives $-1 \\le k \\le 0$.\nSince $k$ must be an integer, the only possible values for $k$ are $k=0$ and $k=-1$.\nIf $k=0$, then $x = \\frac{\\pi}{2}$. The circle equation becomes $(\\frac{\\pi}{2})^2 + y^2 = \\frac{\\pi^2}{4}$, which gives $y^2=0$, so $y=0$. The point is $(\\frac{\\pi}{2}, 0)$.\nIf $k=-1$, then $x = \\frac{\\pi}{2} - \\pi = -\\frac{\\pi}{2}$. The circle equation becomes $(-\\frac{\\pi}{2})^2 + y^2 = \\frac{\\pi^2}{4}$, which also gives $y^2=0$, so $y=0$. The point is $(-\\frac{\\pi}{2}, 0)$.\nThis case yields two points.\n\nIn total, we have found six points:\n1. Four points from Case 1: $(\\pm\\sqrt{\\frac{\\pi^2}{4} - 1}, \\pm 1)$. The x-coordinates are $\\sqrt{\\frac{\\pi^2}{4} - 1}$ and $-\\sqrt{\\frac{\\pi^2}{4} - 1}$.\n2. Two points from Case 2: $(\\pm\\frac{\\pi}{2}, 0)$. The x-coordinates are $\\frac{\\pi}{2}$ and $-\\frac{\\pi}{2}$.\n\nThe problem asks for the sum of the squares of the $x$-coordinates of all these points. Let this sum be $S$.\nThe four points from Case 1 each have an $x$-coordinate whose square is $(\\pm\\sqrt{\\frac{\\pi^2}{4} - 1})^2 = \\frac{\\pi^2}{4} - 1$.\nThe two points from Case 2 each have an $x$-coordinate whose square is $(\\pm\\frac{\\pi}{2})^2 = \\frac{\\pi^2}{4}$.\nSo, the sum is:\n$$ S = \\left(\\frac{\\pi^2}{4} - 1\\right) + \\left(\\frac{\\pi^2}{4} - 1\\right) + \\left(\\frac{\\pi^2}{4} - 1\\right) + \\left(\\frac{\\pi^2}{4} - 1\\right) + \\left(\\frac{\\pi^2}{4}\\right) + \\left(\\frac{\\pi^2}{4}\\right) $$\n$$ S = 4 \\left( \\frac{\\pi^2}{4} - 1 \\right) + 2 \\left( \\frac{\\pi^2}{4} \\right) $$\n$$ S = (\\pi^2 - 4) + \\frac{\\pi^2}{2} $$\n$$ S = \\frac{2\\pi^2}{2} - 4 + \\frac{\\pi^2}{2} $$\n$$ S = \\frac{3\\pi^2}{2} - 4 $$\nThe final answer is an analytic expression in terms of $\\pi$.", "answer": "$$\\boxed{\\frac{3\\pi^{2}}{2} - 4}$$"}, {"introduction": "Many complex processes can be modeled as a sequence of simpler transformations, and the multivariable chain rule is the essential tool for analyzing them. This principle elegantly states that the Jacobian of a composite map is the matrix product of the individual Jacobian matrices. This exercise provides hands-on practice with this fundamental theorem, reinforcing both differentiation and the mechanics of matrix multiplication in a meaningful context [@problem_id:1648639].", "id": "1648639", "problem": "Consider two differentiable maps, $f: \\mathbb{R} \\to \\mathbb{R}^2$ and $g: \\mathbb{R}^2 \\to \\mathbb{R}^2$. The function $f$ maps a real number $t$ to a point in the plane, and is defined by:\n$$f(t) = (\\cos(t), \\sin(2t))$$\nThe function $g$ maps a point $(u,v)$ in the plane to another point, and is defined by:\n$$g(u,v) = (u+v^2, uv)$$\nLet $h = g \\circ f$ be the composition of these two maps, such that $h(t) = g(f(t))$.\nUsing the chain rule for multivariable functions, find the Jacobian matrix of the composite map $h$ at the point $t = \\frac{\\pi}{6}$.\n\n", "solution": "The problem asks for the Jacobian matrix of the composite function $h = g \\circ f$ at $t = \\pi/6$. The chain rule for Jacobian matrices states that $J_h(t) = J_{g \\circ f}(t) = J_g(f(t)) \\cdot J_f(t)$, where $J_g(f(t))$ is the Jacobian matrix of $g$ evaluated at the point $f(t)$, and $J_f(t)$ is the Jacobian matrix of $f$ evaluated at $t$. The operation `Â·` denotes matrix multiplication.\n\nFirst, let's determine the components of our maps.\nThe map $f: \\mathbb{R} \\to \\mathbb{R}^2$ is given by $f(t) = (f_1(t), f_2(t))$ where $f_1(t) = \\cos(t)$ and $f_2(t) = \\sin(2t)$.\nThe map $g: \\mathbb{R}^2 \\to \\mathbb{R}^2$ is given by $g(u,v) = (g_1(u,v), g_2(u,v))$ where $g_1(u,v) = u+v^2$ and $g_2(u,v) = uv$.\nThe composite map $h = g \\circ f$ maps from $\\mathbb{R}$ to $\\mathbb{R}^2$. Its Jacobian matrix $J_h(t)$ will be a $2 \\times 1$ matrix (a column vector).\n\nStep 1: Compute the Jacobian matrix of $f(t)$.\nThe Jacobian of $f(t)$ is a $2 \\times 1$ matrix whose entries are the derivatives of its component functions with respect to $t$.\n$$J_f(t) = \\begin{pmatrix} \\frac{df_1}{dt} \\\\ \\frac{df_2}{dt} \\end{pmatrix} = \\begin{pmatrix} \\frac{d}{dt}(\\cos(t)) \\\\ \\frac{d}{dt}(\\sin(2t)) \\end{pmatrix} = \\begin{pmatrix} -\\sin(t) \\\\ 2\\cos(2t) \\end{pmatrix}$$\nNow, we evaluate this Jacobian at the specified point $t = \\pi/6$.\n$$J_f\\left(\\frac{\\pi}{6}\\right) = \\begin{pmatrix} -\\sin(\\pi/6) \\\\ 2\\cos(2 \\cdot \\pi/6) \\end{pmatrix} = \\begin{pmatrix} -\\sin(\\pi/6) \\\\ 2\\cos(\\pi/3) \\end{pmatrix} = \\begin{pmatrix} -1/2 \\\\ 2(1/2) \\end{pmatrix} = \\begin{pmatrix} -1/2 \\\\ 1 \\end{pmatrix}$$\n\nStep 2: Compute the Jacobian matrix of $g(u,v)$.\nThe Jacobian of $g(u,v)$ is a $2 \\times 2$ matrix of its partial derivatives.\n$$J_g(u,v) = \\begin{pmatrix} \\frac{\\partial g_1}{\\partial u} & \\frac{\\partial g_1}{\\partial v} \\\\ \\frac{\\partial g_2}{\\partial u} & \\frac{\\partial g_2}{\\partial v} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\partial}{\\partial u}(u+v^2) & \\frac{\\partial}{\\partial v}(u+v^2) \\\\ \\frac{\\partial}{\\partial u}(uv) & \\frac{\\partial}{\\partial v}(uv) \\end{pmatrix} = \\begin{pmatrix} 1 & 2v \\\\ v & u \\end{pmatrix}$$\n\nStep 3: Determine the point at which to evaluate $J_g$.\nAccording to the chain rule, we need to evaluate $J_g$ at the point $f(t) = f(\\pi/6)$.\n$$f\\left(\\frac{\\pi}{6}\\right) = \\left(\\cos\\left(\\frac{\\pi}{6}\\right), \\sin\\left(2 \\cdot \\frac{\\pi}{6}\\right)\\right) = \\left(\\cos\\left(\\frac{\\pi}{6}\\right), \\sin\\left(\\frac{\\pi}{3}\\right)\\right) = \\left(\\frac{\\sqrt{3}}{2}, \\frac{\\sqrt{3}}{2}\\right)$$\nSo, we substitute $(u,v) = (\\sqrt{3}/2, \\sqrt{3}/2)$ into the expression for $J_g(u,v)$.\n$$J_g\\left(f\\left(\\frac{\\pi}{6}\\right)\\right) = J_g\\left(\\frac{\\sqrt{3}}{2}, \\frac{\\sqrt{3}}{2}\\right) = \\begin{pmatrix} 1 & 2\\left(\\frac{\\sqrt{3}}{2}\\right) \\\\ \\frac{\\sqrt{3}}{2} & \\frac{\\sqrt{3}}{2} \\end{pmatrix} = \\begin{pmatrix} 1 & \\sqrt{3} \\\\ \\frac{\\sqrt{3}}{2} & \\frac{\\sqrt{3}}{2} \\end{pmatrix}$$\n\nStep 4: Apply the chain rule by multiplying the Jacobian matrices.\nNow we perform the matrix multiplication $J_h(\\pi/6) = J_g(f(\\pi/6)) \\cdot J_f(\\pi/6)$.\n$$J_h\\left(\\frac{\\pi}{6}\\right) = \\begin{pmatrix} 1 & \\sqrt{3} \\\\ \\frac{\\sqrt{3}}{2} & \\frac{\\sqrt{3}}{2} \\end{pmatrix} \\begin{pmatrix} -1/2 \\\\ 1 \\end{pmatrix}$$\nMultiplying the matrices gives:\n$$J_h\\left(\\frac{\\pi}{6}\\right) = \\begin{pmatrix} (1)(-\\frac{1}{2}) + (\\sqrt{3})(1) \\\\ (\\frac{\\sqrt{3}}{2})(-\\frac{1}{2}) + (\\frac{\\sqrt{3}}{2})(1) \\end{pmatrix} = \\begin{pmatrix} -\\frac{1}{2} + \\sqrt{3} \\\\ -\\frac{\\sqrt{3}}{4} + \\frac{\\sqrt{3}}{2} \\end{pmatrix}$$\nSimplifying the entries yields the final result.\nFor the first entry: $-\\frac{1}{2} + \\sqrt{3} = \\frac{2\\sqrt{3}-1}{2}$.\nFor the second entry: $-\\frac{\\sqrt{3}}{4} + \\frac{2\\sqrt{3}}{4} = \\frac{\\sqrt{3}}{4}$.\nThus, the Jacobian matrix of $h$ at $t=\\pi/6$ is:\n$$J_h\\left(\\frac{\\pi}{6}\\right) = \\begin{pmatrix} \\frac{2\\sqrt{3}-1}{2} \\\\ \\frac{\\sqrt{3}}{4} \\end{pmatrix}$$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{2\\sqrt{3}-1}{2} \\\\ \\frac{\\sqrt{3}}{4} \\end{pmatrix}}$$"}]}