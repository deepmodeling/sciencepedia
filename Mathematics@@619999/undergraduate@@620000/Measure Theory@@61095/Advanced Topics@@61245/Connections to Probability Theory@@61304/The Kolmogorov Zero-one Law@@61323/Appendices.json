{"hands_on_practices": [{"introduction": "The first step in applying the Kolmogorov Zero-one Law is mastering the ability to identify which events are truly \"tail events.\" This exercise challenges you to apply the formal definition to a variety of common scenarios in probability theory. By determining which events depend only on the long-term behavior of a sequence of independent random variables, you will build a strong intuition for the scope of this powerful law [@problem_id:1370049].", "problem": "Let $\\{X_n\\}_{n \\ge 1}$ be a sequence of independent random variables defined on a common probability space $(\\Omega, \\mathcal{F}, P)$. Let $\\mathcal{T}_k = \\sigma(X_k, X_{k+1}, \\dots)$ be the $\\sigma$-algebra generated by the random variables from index $k$ onwards. The tail $\\sigma$-algebra, denoted by $\\mathcal{T}$, is the intersection of all such $\\sigma$-algebras: $\\mathcal{T} = \\bigcap_{k=1}^{\\infty} \\mathcal{T}_k$.\n\nAn event $A$ is called a **tail event** if it belongs to the tail $\\sigma$-algebra $\\mathcal{T}$. Informally, this means that the occurrence of event $A$ does not depend on the values of any finite number of variables from the sequence $\\{X_n\\}$. For instance, changing the values of $X_1, X_2, \\ldots, X_{100}$ would not change whether a tail event $A$ has occurred.\n\nGiven the definitions above, consider the following list of events. Select all the options that describe a tail event.\n\nA. The series $\\sum_{n=1}^\\infty X_n$ converges.\n\nB. The partial sums $S_n = \\sum_{k=1}^n X_k$ are positive for all $n \\ge 10$.\n\nC. $\\limsup_{n\\to\\infty} \\frac{X_n}{n} > 1$.\n\nD. $X_n > X_{n-1}$ for infinitely many $n \\ge 2$.\n\nE. $X_1 < X_2 < \\dots < X_N$ for a fixed integer $N > 2$.", "solution": "To determine which of the events are tail events, we must check if each event $A$ belongs to the tail $\\sigma$-algebra $\\mathcal{T} = \\bigcap_{k=1}^{\\infty} \\sigma(X_k, X_{k+1}, \\dots)$. An event $A$ is a tail event if for any positive integer $k$, the event $A$ is measurable with respect to the $\\sigma$-algebra $\\sigma(X_k, X_{k+1}, \\dots)$, which means the event's outcome is determined solely by the variables $X_k, X_{k+1}, \\dots$.\n\n**A. The series $\\sum_{n=1}^\\infty X_n$ converges.**\nLet $A$ be this event. The convergence of a series is determined by the behavior of its tail. For any finite integer $k > 0$, the series $\\sum_{n=1}^\\infty X_n$ converges if and only if the series $\\sum_{n=k}^\\infty X_n$ converges. This is because the initial partial sum $\\sum_{n=1}^{k-1} X_n$ is a finite value that does not affect the convergence of the infinite series. The event that $\\sum_{n=k}^\\infty X_n$ converges depends only on the variables $X_k, X_{k+1}, \\dots$. Therefore, for any $k \\ge 1$, event $A$ is in $\\sigma(X_k, X_{k+1}, \\dots)$. Since this holds for all $k$, $A$ is in the intersection $\\mathcal{T}$. Thus, event A is a tail event.\n\n**B. The partial sums $S_n = \\sum_{k=1}^n X_k$ are positive for all $n \\ge 10$.**\nLet $B$ be this event. By definition, $B = \\bigcap_{n=10}^\\infty \\{S_n > 0\\}$. Let's check if this event is in $\\mathcal{T}_2 = \\sigma(X_2, X_3, \\dots)$. To be in $\\mathcal{T}_2$, the occurrence of event $B$ must not depend on the value of $X_1$.\nConsider the condition for $n=10$, which is $\\{S_{10} > 0\\}$ or $\\{X_1 + X_2 + \\dots + X_{10} > 0\\}$. The outcome of this event clearly depends on $X_1$.\nTo be more formal, let's construct two sample outcomes $\\omega$ and $\\omega'$ that differ only in $X_1$ but yield different outcomes for event $B$.\nLet $X_2(\\omega) = \\dots = X_{10}(\\omega) = 1$, and $X_n(\\omega)=0$ for $n>10$.\nLet $X_1(\\omega) = -11$. Then $S_{10}(\\omega) = -11+9 = -2 \\le 0$. Event $B$ does not occur for $\\omega$.\nNow, let $\\omega'$ be identical to $\\omega$ except that $X_1(\\omega') = 0$. Then $S_{10}(\\omega') = 0+9 = 9 > 0$. For $n>10$, $S_n(\\omega') = S_{10}(\\omega') + \\sum_{k=11}^n X_k(\\omega') = 9+0=9>0$. So, event $B$ occurs for $\\omega'$.\nSince the two outcomes have identical sequences from $X_2$ onwards, but the event outcomes differ, the event is not independent of $X_1$. It is not in $\\mathcal{T}_2$, and therefore cannot be a tail event.\n\n**C. $\\limsup_{n\\to\\infty} \\frac{X_n}{n} > 1$.**\nLet $C$ be this event. The limit superior of a sequence is determined by the tail of the sequence. For any finite $k$, changing the first $k-1$ values of the sequence $\\{X_n\\}_{n \\ge 1}$ only changes the first $k-1$ terms of the sequence $\\{a_n = X_n/n\\}_{n \\ge 1}$. Altering a finite number of terms in a sequence does not change its limit superior.\nTherefore, the occurrence of event $C$ depends only on the variables $\\{X_k, X_{k+1}, \\dots\\}$ for any choice of $k$. Thus, $C \\in \\sigma(X_k, X_{k+1}, \\dots)$ for all $k \\ge 1$. This means $C$ is a tail event.\n\n**D. $X_n > X_{n-1}$ for infinitely many $n \\ge 2$.**\nLet $D$ be this event. Let's analyze whether its occurrence depends on any finite prefix of the sequence, say $X_1, \\dots, X_{k-1}$.\nLet $S(\\omega) = \\{ n \\ge 2 \\mid X_n(\\omega) > X_{n-1}(\\omega) \\}$. The event $D$ is the set of outcomes $\\omega$ for which $S(\\omega)$ is an infinite set.\nFor any fixed $k \\ge 1$, let's consider two outcomes $\\omega$ and $\\omega'$ that differ only in the first $k-1$ coordinates, i.e., $X_j(\\omega) \\ne X_j(\\omega')$ for some $j < k$, but $X_j(\\omega) = X_j(\\omega')$ for all $j \\ge k$.\nLet's see how $S(\\omega)$ and $S(\\omega')$ are related. The condition $X_n > X_{n-1}$ involves variables with indices $n$ and $n-1$. If $n-1 \\ge k$, then both $X_n$ and $X_{n-1}$ are the same for $\\omega$ and $\\omega'$. So, for $n \\ge k+1$, the condition $X_n > X_{n-1}$ is met for $\\omega$ if and only if it is met for $\\omega'$.\nThe sets $S(\\omega)$ and $S(\\omega')$ can only differ for indices $n \\in \\{2, 3, \\dots, k\\}$. This is a finite set of indices.\nTherefore, $S(\\omega)$ and $S(\\omega')$ differ by at most a finite number of elements. A set is infinite if and only if it remains infinite after adding or removing a finite number of elements. Thus, $S(\\omega)$ is infinite if and only if $S(\\omega')$ is infinite.\nThis shows that the occurrence of event $D$ does not depend on the values of $X_1, \\dots, X_{k-1}$ for any $k$. Therefore, $D$ is a tail event.\n\n**E. $X_1 < X_2 < \\dots < X_N$ for a fixed integer $N > 2$.**\nLet $E$ be this event. The event is defined by a set of conditions on the random variables $X_1, \\dots, X_N$. The occurrence of this event is completely determined by these first $N$ variables. It does not depend at all on any $X_k$ for $k > N$.\nTherefore, this event is in $\\sigma(X_1, \\dots, X_N)$, but it is not in $\\sigma(X_{N+1}, X_{N+2}, \\dots)$. For instance, we can fix the sequence from $X_{N+1}$ onwards, and then toggle the value of $X_1$ to make the event occur or not occur. So, it is not independent of $X_1, \\dots, X_N$. Thus, $E$ is not a tail event.\n\nIn summary, the tail events are A, C, and D.", "answer": "$$\\boxed{ACD}$$", "id": "1370049"}, {"introduction": "Not all events that seem to describe long-term behavior are tail events. This practice problem explores a classic scenario—a simple random walk on the integers—to highlight a crucial subtlety in the definition of a tail event. Analyzing whether reaching a specific position is determined solely by the \"tail\" of the sequence of steps will sharpen your understanding and help you avoid common interpretative pitfalls [@problem_id:1370058].", "problem": "Consider a sequence of independent and identically distributed (i.i.d.) random variables $\\{X_i\\}_{i=1}^{\\infty}$, which represent the steps of a particle on a one-dimensional integer lattice. For each step, the probability of moving to the right by one unit is $P(X_i = 1) = 1/2$, and the probability of moving to the left by one unit is $P(X_i = -1) = 1/2$. The position of the particle after $n$ steps is given by the simple symmetric random walk $S_n = \\sum_{i=1}^n X_i$, with the starting position defined as $S_0 = 0$.\n\nIn probability theory, an event $A$ is known as a **tail event** if its occurrence or non-occurrence is determined solely by the \"tail\" of the sequence of random variables. More formally, an event is a tail event if for any positive integer $m$, the event is independent of the first $m$ random variables $(X_1, X_2, \\dots, X_m)$.\n\nLet $E$ be the event that the particle visits the integer position 10 at least once. That is, $E = \\{ \\omega \\in \\Omega : \\exists n \\ge 1 \\text{ such that } S_n(\\omega) = 10 \\}$.\n\nWhich of the following statements correctly classifies the event $E$ and provides the correct justification?\n\nA. Yes, $E$ is a tail event. This is because the question of whether the walk *ever* reaches 10 depends on the entire infinite sequence of steps, which is characteristic of long-term behavior.\n\nB. No, $E$ is not a tail event. This is because the occurrence of $E$ is not independent of the first step, $X_1$. Knowing the value of $X_1$ alters the condition that the subsequent steps must satisfy for the walk to reach 10.\n\nC. Yes, $E$ is a tail event. This is because for a one-dimensional simple symmetric random walk, the event $E$ has a probability of 1. According to Kolmogorov's Zero-One Law, any event that is a tail event must have a probability of 0 or 1. Since $P(E)=1$, $E$ must be a tail event.\n\nD. No, $E$ is not a tail event. This is because the event $E$ is fully contained in the $\\sigma$-algebra generated by a finite number of variables, for example $\\sigma(X_1, X_2, \\dots, X_{10})$.", "solution": "We formalize the tail sigma-algebra for the i.i.d. sequence $\\{X_{i}\\}_{i \\ge 1}$ as\n$$\n\\mathcal{T}=\\bigcap_{m=1}^{\\infty}\\sigma(X_{m+1},X_{m+2},\\dots).\n$$\nAn event is a tail event if and only if it is measurable with respect to $\\mathcal{T}$, which is equivalent to the invariance property: for every $m \\in \\mathbb{N}$, if two sample paths agree on $(X_{m+1},X_{m+2},\\dots)$, then either both belong to the event or both do not.\n\nLet\n$$\nE=\\{\\exists n \\ge 1:\\ S_{n}=10\\},\\quad S_{n}=\\sum_{i=1}^{n}X_{i},\\quad S_{0}=0.\n$$\nWe show $E \\notin \\mathcal{T}$ by constructing two sample paths that agree on the tail but differ on membership in $E$.\n\nFix any $m \\ge 10$. Choose a tail $(X_{m+1},X_{m+2},\\dots)$ such that the partial sums never hit $10$ after time $m$. For instance, take\n$$\nX_{k}=-1 \\text{ for all } k>m,\n$$\nso that $S_{n}$ strictly decreases for $n>m$ and hence cannot hit $10$ after time $m$ regardless of $S_{m}$.\n\nNow pick two initial segments of length $m$:\n- For the first path $\\omega$, let the first $10$ steps be $X_{1}=\\cdots=X_{10}=1$, and then choose $X_{11},\\dots,X_{m}$ arbitrarily (e.g., all $-1$). This yields $S_{10}(\\omega)=10$, so $\\omega \\in E$.\n- For the second path $\\omega'$, let $X_{1}=\\cdots=X_{m}=-1$, so $S_{n}(\\omega')<10$ for all $n \\le m$. By construction of the common tail, neither $\\omega$ nor $\\omega'$ hits $10$ after time $m$.\n\nMake $\\omega$ and $\\omega'$ identical on the tail $(X_{m+1},X_{m+2},\\dots)$ chosen above. Then $\\omega$ and $\\omega'$ agree on the tail, yet $\\omega \\in E$ and $\\omega' \\notin E$. Therefore $E$ is not measurable with respect to $\\sigma(X_{m+1},X_{m+2},\\dots)$ for this $m$, and hence not in $\\mathcal{T}$. Consequently, $E$ is not a tail event.\n\nRemarks on the options:\n- The classification in A is incorrect: depending on the entire infinite sequence does not imply tail measurability; tail events must be invariant under altering finitely many initial coordinates.\n- The classification in C is incorrect: Kolmogorov's zero-one law states that tail events have probability $0$ or $1$, but the converse is false; $P(E)=1$ does not imply $E$ is a tail event.\n- The classification in D is incorrect: $E$ is not measurable with respect to any finite $\\sigma(X_{1},\\dots,X_{m})$; reaching $10$ may occur at arbitrarily large times.\n- The correct classification is that $E$ is not a tail event, as it can be affected by finitely many initial steps while keeping the tail fixed. This aligns with option B’s conclusion (even though a precise justification should invoke tail invariance rather than probabilistic independence).", "answer": "$$\\boxed{B}$$", "id": "1370058"}, {"introduction": "The Zero-one Law is profound because it guarantees that a tail event's probability is either 0 or 1, but it doesn't specify which. This final exercise demonstrates how to move from this abstract certainty to a concrete answer. By combining the Zero-one Law with a powerful computational tool like Kolmogorov's Three-Series Theorem, you will determine the exact probability of series convergence for a given sequence of random variables [@problem_id:874884].", "problem": "Consider a sequence of independent random variables $\\{X_n\\}_{n=1}^{\\infty}$ defined on a common probability space. The probability mass function for each $X_n$ is given by\n$$\nP(X_n = n^{-1/2}) = n^{-1/2}\n$$\nand\n$$\nP(X_n = 0) = 1 - n^{-1/2}\n$$\nfor all integers $n \\ge 1$.\n\nThe event that the series $S = \\sum_{n=1}^{\\infty} X_n$ converges is a tail event. According to Kolmogorov's Zero-One Law, the probability of any tail event for a sequence of independent random variables must be either 0 or 1.\n\nTo determine this probability, one can use Kolmogorov's Three-Series Theorem. This theorem states that for a sequence of independent random variables $\\{X_n\\}$, the series $\\sum X_n$ converges almost surely if and only if for some constant $A > 0$, the following three conditions are met:\n1. The series $\\sum_{n=1}^{\\infty} P(|X_n| > A)$ converges.\n2. The series $\\sum_{n=1}^{\\infty} E[Y_n]$ converges, where $Y_n = X_n I(|X_n| \\le A)$ is the truncated random variable.\n3. The series $\\sum_{n=1}^{\\infty} \\text{Var}(Y_n)$ converges.\n\nIf any of these conditions fail for some $A > 0$, then the series $\\sum X_n$ diverges almost surely.\n\nDerive the probability that the series $S = \\sum_{n=1}^{\\infty} X_n$ converges.", "solution": "1. By Kolmogorov's Three-Series Theorem, for any fixed $A>0$ we define \n$$Y_n=X_n\\mathbf1_{\\{|X_n|\\le A\\}}\\,. $$\nSince $X_n\\in\\{0,n^{-1/2}\\}$, for sufficiently large $n$ we have $n^{-1/2}<A$, hence \n$$P(|X_n|>A)=0\\quad\\text{and}\\quad Y_n=X_n\\quad\\text{for large }n.$$ \nThus condition 1 is satisfied:\n$$\\sum_{n=1}^\\infty P(|X_n|>A)<\\infty.$$\n2. For large $n$, \n$$E[Y_n]=E[X_n]=n^{-1/2}\\cdot n^{-1/2}=n^{-1},$$ \nso\n$$\\sum_{n=1}^\\infty E[Y_n]=\\sum_{n=1}^\\infty n^{-1}=\\infty.$$ \nTherefore condition 2 fails, and the series $\\sum X_n$ diverges almost surely.\n3. By Kolmogorov's Zero-One Law the probability of convergence is $0$ or $1$, and since it diverges a.s. the probability of convergence is $0$.", "answer": "$$\\boxed{0}$$", "id": "874884"}]}