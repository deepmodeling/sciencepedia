{"hands_on_practices": [{"introduction": "This first practice brings the abstract definition of tightness down to a concrete level. We will analyze a simple sequence of two-point probability measures to build a core intuition. This exercise demonstrates the fundamental link between the tightness of a family of measures and the boundedness of their supports, showing how tightness effectively prevents probability mass from \"escaping to infinity\" [@problem_id:1462682].", "problem": "Consider a sequence of probability measures $\\{\\mu_n\\}_{n=1}^{\\infty}$ defined on the real line $\\mathbb{R}$ equipped with its Borel sigma-algebra. Each measure $\\mu_n$ in the sequence is given by\n$$\n\\mu_n = \\frac{1}{2}\\delta_{-a_n} + \\frac{1}{2}\\delta_{a_n}\n$$\nwhere $\\{a_n\\}_{n=1}^{\\infty}$ is a sequence of non-negative real numbers, and $\\delta_x$ denotes the Dirac measure that assigns a mass of 1 to the point $x$ and 0 to any set not containing $x$.\n\nA sequence of probability measures $\\{\\mu_n\\}$ is defined as being tight if for every $\\epsilon > 0$, there exists a compact set $K \\subset \\mathbb{R}$ such that $\\mu_n(K) \\geq 1 - \\epsilon$ for all $n \\in \\{1, 2, 3, \\dots\\}$.\n\nWhich of the following is the necessary and sufficient condition on the sequence $\\{a_n\\}$ for the sequence of measures $\\{\\mu_n\\}$ to be tight?\n\nA. The sequence $\\{a_n\\}$ must converge.\n\nB. The sequence $\\{a_n\\}$ must be bounded.\n\nC. The sequence $\\{a_n\\}$ must converge to 0.\n\nD. The sum $\\sum_{n=1}^{\\infty} a_n$ must be finite.\n\nE. The sequence $\\{a_n\\}$ must have only a finite number of distinct values.", "solution": "By definition, the family $\\{\\mu_n\\}$ is tight if and only if for every $\\epsilon > 0$ there exists a compact $K \\subset \\mathbb{R}$ such that $\\mu_n(K) \\geq 1-\\epsilon$ for all $n$.\n\nOn $\\mathbb{R}$, compact sets are bounded. Hence, there exists $R>0$ with $K \\subset [-R,R]$. By monotonicity of measures,\n$$\n\\mu_n([-R,R]) \\geq \\mu_n(K) \\geq 1-\\epsilon \\quad \\text{for all } n.\n$$\nFor any fixed $R \\geq 0$ and any $n$, the measure of the interval is\n$$\n\\mu_n([-R,R]) = \\frac{1}{2}\\delta_{-a_n}([-R,R]) + \\frac{1}{2}\\delta_{a_n}([-R,R]) =\n\\begin{cases}\n1,  a_n \\leq R,\\\\\n0,  a_n > R,\n\\end{cases}\n$$\nbecause either both atoms $\\{-a_n,a_n\\}$ lie inside $[-R,R]$ (when $a_n \\leq R$) or both lie outside (when $a_n > R$). Since $1-\\epsilon > 0$ for any $\\epsilon \\in (0,1)$, the inequality $\\mu_n([-R,R]) \\geq 1-\\epsilon$ forces $\\mu_n([-R,R])=1$, hence $a_n \\leq R$ for all $n$. Therefore, tightness implies that $\\{a_n\\}$ is bounded.\n\nConversely, if $\\{a_n\\}$ is bounded, let $A = \\sup_n a_n  \\infty$ and choose $K=[-A,A]$, which is compact. Then for every $n$ both atoms lie in $K$, so\n$$\n\\mu_n(K)=1 \\geq 1-\\epsilon \\quad \\text{for all } \\epsilon > 0.\n$$\nThus the family $\\{\\mu_n\\}$ is tight.\n\nHence, the necessary and sufficient condition is that $\\{a_n\\}$ be bounded. Evaluating the options:\n- A (convergence) is stronger than needed and not necessary.\n- B (boundedness) is exactly the required condition.\n- C (convergence to $0$) is not necessary.\n- D (finiteness of $\\sum a_n$) is irrelevant to tightness here.\n- E (finitely many distinct values) implies boundedness but is not necessary.\n\nTherefore, the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1462682"}, {"introduction": "Moving from direct definitions to powerful general techniques, this exercise introduces the moment method for proving tightness. You will use a uniform bound on the second moments of a family of Gaussian measures, coupled with Markov's inequality, to elegantly control their tail probabilities [@problem_id:1458421]. This approach is a cornerstone of modern probability theory, providing a practical tool for establishing the tightness of more complex families of distributions.", "problem": "In measure theory, the concept of tightness is crucial for studying the convergence of probability measures. A family of probability measures $\\{\\nu_\\alpha\\}_{\\alpha \\in I}$ on the real line $\\mathbb{R}$ (equipped with its Borel sigma-algebra) is said to be **tight** if for every $\\epsilon > 0$, there exists a compact set $K \\subset \\mathbb{R}$ such that $\\nu_\\alpha(K^c)  \\epsilon$ for all $\\alpha \\in I$. Here, $K^c$ denotes the complement of $K$.\n\nConsider the family of all Gaussian measures on $\\mathbb{R}$. A Gaussian measure, denoted $N(\\mu, \\sigma^2)$, is a probability measure with mean $\\mu \\in \\mathbb{R}$ and variance $\\sigma^2 \\ge 0$. If $\\sigma^2 > 0$, its probability density function is given by $f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)$. If $\\sigma^2 = 0$, the measure is the Dirac delta measure $\\delta_\\mu$ centered at $\\mu$.\n\nLet $\\mathcal{F}$ be the family of all such Gaussian measures $N(\\mu, \\sigma^2)$ where the mean $\\mu$ and variance $\\sigma^2$ are constrained by the inequality:\n$$ \\mu^2 + \\sigma^2 \\le 1 $$\n\nWhich of the following statements about the family $\\mathcal{F}$ is true?\n\nA. The family $\\mathcal{F}$ is tight.\n\nB. The family $\\mathcal{F}$ is not tight because the means $\\mu$ can vary.\n\nC. The family $\\mathcal{F}$ is not tight because the variances $\\sigma^2$ can be arbitrarily close to zero.\n\nD. The family $\\mathcal{F}$ is not tight because the support of each individual Gaussian measure with $\\sigma^2 > 0$ is the entire real line, which is not compact.\n\nE. The tightness of the family $\\mathcal{F}$ cannot be determined without more information.", "solution": "We must determine whether the family $\\mathcal{F}=\\{N(\\mu, \\sigma^2): \\mu^2 + \\sigma^2 \\le 1\\}$ is tight on $\\mathbb{R}$. By definition, tightness means: for every $\\epsilon > 0$, there exists a compact $K \\subset \\mathbb{R}$ such that, for all $\\nu \\in \\mathcal{F}$, $\\nu(K^c)  \\epsilon$.\n\nFix any $N(\\mu, \\sigma^2) \\in \\mathcal{F}$ and let $X \\sim N(\\mu, \\sigma^2)$. Its second moment is\n$$\n\\mathbb{E}[X^2] = \\operatorname{Var}(X) + (\\mathbb{E}[X])^2 = \\sigma^2 + \\mu^2 \\le 1,\n$$\nby the constraint defining $\\mathcal{F}$. Apply Markov's inequality to the nonnegative random variable $X^2$: for any $R > 0$,\n$$\n\\mathbb{P}(|X| > R) = \\mathbb{P}(X^2 > R^2) \\le \\frac{\\mathbb{E}[X^2]}{R^2} \\le \\frac{1}{R^2}.\n$$\nNow fix $\\epsilon > 0$ and choose $R = \\epsilon^{-1/2}$. Let $K=[-R,R]$, which is compact in $\\mathbb{R}$. Then, uniformly over all $\\nu \\in \\mathcal{F}$,\n$$\n\\nu(K^c) = \\mathbb{P}(|X| > R) \\le \\epsilon.\n$$\nTherefore, for every $\\epsilon > 0$, there exists a compact $K$ such that $\\sup_{\\nu \\in \\mathcal{F}}\\nu(K^c) \\le \\epsilon$, proving that $\\mathcal{F}$ is tight.\n\nConsequently, statement A is true. The alternatives are false for the following reasons: B is false because variation in means does not prevent tightness here; indeed $\\mu^2 \\le 1$ ensures uniformly bounded second moments. C is false because allowing $\\sigma^2 \\to 0$ only concentrates mass and does not harm tightness; the same bound applies even to Dirac measures. D is false because tightness does not require compact support; it requires that most mass lie in some compact set uniformly across the family, which we have shown. E is false because the given constraint is sufficient to establish tightness.", "answer": "$$\\boxed{A}$$", "id": "1458421"}, {"introduction": "While the previous exercise showed that uniformly bounded moments are a sufficient condition for tightness, are they also necessary? This practice provides a crucial counterexample to explore the boundaries of this relationship [@problem_id:1462684]. By constructing a specific sequence of measures that is tight yet possesses unbounded first moments, you will develop a more nuanced and precise understanding of what tightness truly entails.", "problem": "In measure theory, a family of probability measures $\\{\\mu_{\\alpha}\\}_{\\alpha \\in I}$ on the real line $\\mathbb{R}$ is called **tight** if for every $\\epsilon > 0$, there exists a compact set $K \\subset \\mathbb{R}$ such that $\\mu_{\\alpha}(\\mathbb{R} \\setminus K)  \\epsilon$ for all $\\alpha \\in I$. For a probability measure on $\\mathbb{R}$, this is equivalent to the condition that for every $\\epsilon > 0$, there exists a real number $R > 0$ such that $\\mu_{\\alpha}(\\mathbb{R} \\setminus [-R, R])  \\epsilon$ for all $\\alpha \\in I$.\n\nThe first moment of a probability measure $\\mu$ is given by $M_1(\\mu) = \\int_{\\mathbb{R}} |x| d\\mu(x)$.\n\nConsider a sequence of probability measures $\\{\\mu_n\\}_{n \\in \\mathbb{N}}$ on $\\mathbb{R}$ defined by:\n$$ \\mu_n = \\left(1 - \\frac{1}{n^2}\\right)\\delta_0 + \\frac{1}{n^2}\\delta_{n^3} $$\nwhere $n \\ge 1$ is an integer and $\\delta_x$ denotes the Dirac measure concentrated at point $x$. Let $M_1(\\mu_n)$ be the first moment of the measure $\\mu_n$.\n\nWhich of the following statements accurately describes the properties of the sequence $\\{\\mu_n\\}$ and its first moments?\n\nA. The sequence of measures $\\{\\mu_n\\}$ is tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is bounded.\n\nB. The sequence of measures $\\{\\mu_n\\}$ is not tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is bounded.\n\nC. The sequence of measures $\\{\\mu_n\\}$ is not tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is unbounded.\n\nD. The sequence of measures $\\{\\mu_n\\}$ is tight, and the sequence of first moments $\\{M_1(\\mu_n)\\}$ is unbounded.", "solution": "For each $n \\in \\mathbb{N}$, the measure is $\\mu_n = \\left(1 - \\frac{1}{n^2}\\right)\\delta_0 + \\frac{1}{n^2}\\delta_{n^3}$. Its first moment is\n$$\nM_1(\\mu_n) = \\int_{\\mathbb{R}}|x|\\,d\\mu_n(x) = \\left(1 - \\frac{1}{n^2}\\right)\\cdot 0 + \\frac{1}{n^2}\\cdot n^3 = n,\n$$\nso the sequence $\\{M_1(\\mu_n)\\}$ is unbounded.\n\nTo show tightness of $\\{\\mu_n\\}$, fix $\\epsilon > 0$ and set $N = \\lfloor 1/\\sqrt{\\epsilon} \\rfloor + 1$ and $R = (N-1)^3$. For any $n \\in \\mathbb{N}$, if $n^3 \\le R$ then $\\mu_n(\\mathbb{R}\\setminus[-R,R])=0$. If $n^3 > R$, then $n \\ge N$, hence\n$$\n\\mu_n(\\mathbb{R}\\setminus[-R,R]) = \\frac{1}{n^2} \\le \\frac{1}{N^2}  \\epsilon.\n$$\nTherefore, for all $n$ we have $\\mu_n(\\mathbb{R}\\setminus[-R,R])  \\epsilon$, which proves tightness.\n\nThus the sequence $\\{\\mu_n\\}$ is tight, while $\\{M_1(\\mu_n)\\}$ is unbounded. The correct choice is D.", "answer": "$$\\boxed{D}$$", "id": "1462684"}]}