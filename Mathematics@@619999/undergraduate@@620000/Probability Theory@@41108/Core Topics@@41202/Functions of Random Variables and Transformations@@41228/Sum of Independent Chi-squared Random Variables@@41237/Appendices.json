{"hands_on_practices": [{"introduction": "Understanding the variability of a composite statistical measure is a fundamental skill. This first practice provides a direct application of key principles for calculating the variance of a sum of independent chi-squared variables. Through this exercise [@problem_id:1391081], you will reinforce your understanding of two crucial rules: the variance of a sum of independent variables is the sum of their variances, and the variance of a chi-squared random variable with $k$ degrees of freedom is simply $2k$.", "problem": "In a statistical analysis, two independent variables, $X$ and $Y$, are modeled using chi-squared distributions. The variable $X$ follows a chi-squared distribution with 5 degrees of freedom, denoted as $X \\sim \\chi^2(5)$. The variable $Y$ follows a chi-squared distribution with 9 degrees of freedom, denoted as $Y \\sim \\chi^2(9)$. A new random variable, $Z$, is constructed as a linear combination of these variables: $Z = X + Y + 15$.\n\nCalculate the variance of the random variable $Z$.", "solution": "We are given independent random variables $X \\sim \\chi^2(5)$ and $Y \\sim \\chi^2(9)$, and $Z = X + Y + 15$. We need $\\operatorname{Var}(Z)$.\n\nUse the properties of variance:\n1) For any constant $c$, $\\operatorname{Var}(U + c) = \\operatorname{Var}(U)$.\n2) For independent $U$ and $V$, $\\operatorname{Var}(U + V) = \\operatorname{Var}(U) + \\operatorname{Var}(V)$.\n\nAlso, if $W \\sim \\chi^2(k)$, then viewing it as a gamma distribution with shape $k/2$ and scale $2$ gives\n$$\n\\operatorname{Var}(W) = \\left(\\frac{k}{2}\\right) \\cdot 2^{2} = 2k.\n$$\n\nApply this to $X$ and $Y$:\n$$\n\\operatorname{Var}(X) = 2 \\cdot 5 = 10, \\quad \\operatorname{Var}(Y) = 2 \\cdot 9 = 18.\n$$\nIndependence and shift invariance yield\n$$\n\\operatorname{Var}(Z) = \\operatorname{Var}(X + Y + 15) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) = 10 + 18 = 28.\n$$", "answer": "$$\\boxed{28}$$", "id": "1391081"}, {"introduction": "Now that we have practiced calculating properties of a known sum, we can explore the core theorem from a different angle. This problem [@problem_id:1391082] is a classic thought experiment that tests your grasp of the additive property of independent chi-squared distributions. By being asked to identify an unknown component of a sum, you are challenged to work backward and truly internalize why this family of distributions is closed under addition.", "problem": "In a statistical analysis of experimental data, a summary statistic $Z$ is calculated. It is known that $Z$ follows a chi-squared distribution with 15 degrees of freedom, denoted as $Z \\sim \\chi^2(15)$.\n\nThis statistic $Z$ is found to be the sum of two independent components, $X$ and $Y$, such that $Z = X + Y$. The component $X$ is known to model a specific source of variation and follows a chi-squared distribution with 9 degrees of freedom, i.e., $X \\sim \\chi^2(9)$.\n\nIdentify the probability distribution of the component $Y$.\n\nA. The Normal distribution with mean 6 and variance 12, $N(6, 12)$.\n\nB. The chi-squared distribution with 24 degrees of freedom, $\\chi^2(24)$.\n\nC. The chi-squared distribution with 6 degrees of freedom, $\\chi^2(6)$.\n\nD. The Student's t-distribution with 6 degrees of freedom, $t(6)$.", "solution": "We are given that $Z \\sim \\chi^2(15)$, $X \\sim \\chi^2(9)$, and $Z = X + Y$ with $X$ and $Y$ independent. We seek the distribution of $Y$.\n\nUse the moment generating function (MGF) of the chi-squared distribution: if $W \\sim \\chi^2(k)$, then for $t < \\frac{1}{2}$,\n$$\nM_{W}(t) = (1 - 2t)^{-k/2}.\n$$\nSince $Z = X + Y$ with independence, the MGF factorizes:\n$$\nM_{Z}(t) = M_{X}(t) M_{Y}(t).\n$$\nThus,\n$$\nM_{Y}(t) = \\frac{M_{Z}(t)}{M_{X}(t)} = \\frac{(1 - 2t)^{-15/2}}{(1 - 2t)^{-9/2}} = (1 - 2t)^{-(15-9)/2} = (1 - 2t)^{-6/2}.\n$$\nRecognizing this as the MGF of a chi-squared distribution with $6$ degrees of freedom, we conclude\n$$\nY \\sim \\chi^2(6).\n$$\nTherefore, the correct option is C.", "answer": "$$\\boxed{C}$$", "id": "1391082"}, {"introduction": "Our final practice moves beyond simple sums to explore the statistical relationship between different linear combinations of random variables. This exercise [@problem_id:1391110] asks you to determine the covariance between the sum and the difference of two independent chi-squared variables. Successfully solving this requires applying the bilinearity property of covariance, which elegantly reduces the problem to the variances of the original variables, offering a deeper insight into their interconnectedness.", "problem": "In the quality control process for a newly designed dual-filament lamp, the energy output fluctuations of its two independent segments, A and B, are analyzed. Statistical models based on extensive testing have shown that the scaled energy fluctuation of segment A, denoted by the random variable $X$, follows a chi-squared distribution with $k_A$ degrees of freedom. Similarly, the scaled energy fluctuation of segment B, denoted by $Y$, follows a chi-squared distribution with $k_B$ degrees of freedom. The two segments are manufactured and operate independently.\n\nAn engineer is interested in the statistical relationship between the total fluctuation of the lamp, defined as $S = X + Y$, and the imbalance in fluctuation between the segments, defined as $D = X - Y$.\n\nDetermine the covariance between the total fluctuation $S$ and the imbalance $D$, denoted as $\\text{Cov}(S, D)$. Express your answer as an analytic expression in terms of the parameters $k_A$ and $k_B$.", "solution": "Let $X \\sim \\chi^2_{k_A}$ and $Y \\sim \\chi^2_{k_B}$ be independent. Define $S=X+Y$ and $D=X-Y$. We seek $\\text{Cov}(S,D)$.\n\nUse the definition and bilinearity of covariance:\n$$\n\\text{Cov}(S,D)=\\text{Cov}(X+Y,\\,X-Y)=\\text{Cov}(X,X)-\\text{Cov}(X,Y)+\\text{Cov}(Y,X)-\\text{Cov}(Y,Y).\n$$\nIndependence implies $\\text{Cov}(X,Y)=\\text{Cov}(Y,X)=0$, and $\\text{Cov}(X,X)=\\text{Var}(X)$, $\\text{Cov}(Y,Y)=\\text{Var}(Y)$. Hence,\n$$\n\\text{Cov}(S,D)=\\text{Var}(X)-\\text{Var}(Y).\n$$\nFor a chi-squared random variable with $k$ degrees of freedom, $\\text{Var}(\\chi^2_k)=2k$. Therefore,\n$$\n\\text{Cov}(S,D)=2k_{A}-2k_{B}=2\\left(k_{A}-k_{B}\\right).\n$$\nThis provides the required analytic expression in terms of $k_{A}$ and $k_{B}$.", "answer": "$$\\boxed{2\\left(k_{A}-k_{B}\\right)}$$", "id": "1391110"}]}