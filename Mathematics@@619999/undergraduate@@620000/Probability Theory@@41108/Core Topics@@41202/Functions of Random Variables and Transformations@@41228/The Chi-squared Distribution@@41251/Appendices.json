{"hands_on_practices": [{"introduction": "The chi-squared distribution is fundamentally linked to the familiar standard normal distribution. This first practice problem invites you to explore this connection by examining the expectation of the sum of squared standard normal variables, which form the building blocks of any chi-squared variable. Successfully working through this exercise reinforces key concepts like linearity of expectation and the definition of variance.", "problem": "Let $Z_1$ and $Z_2$ be two independent random variables, each following a standard normal distribution. A random variable $Z$ is said to have a standard normal distribution if its expectation (mean) is $E[Z] = 0$ and its variance is $Var(Z) = 1$. The variance is related to the expectation via the formula $Var(Z) = E[Z^2] - (E[Z])^2$.\n\nA new random variable, $Y$, is constructed from $Z_1$ and $Z_2$ as follows:\n$$Y = c(Z_1^2 + Z_2^2)$$\nwhere $c$ is a given positive real constant.\n\nDerive the expectation of the random variable $Y$, denoted as $E[Y]$.", "solution": "We have \n$$Y = c\\bigl(Z_1^2 + Z_2^2\\bigr)\\,. $$\nBy the linearity of expectation,\n$$E[Y] = c\\bigl(E[Z_1^2] + E[Z_2^2]\\bigr)\\,. $$\nSince $Z_1$ and $Z_2$ are standard normal,\n$$E[Z_i]=0,\\quad \\text{Var}(Z_i)=1,\\quad \\text{Var}(Z_i)=E[Z_i^2]-(E[Z_i])^2\n\\;\\Longrightarrow\\;E[Z_i^2]=1.$$\nTherefore,\n$$E[Y] = c\\,(1+1) = 2c\\,. $$", "answer": "$$\\boxed{2c}$$", "id": "2277"}, {"introduction": "Building upon the concept of squared normal variables, we now consider how to construct a complete chi-squared distribution from scratch [@problem_id:2277]. This exercise challenges you to think like a programmer and devise a simulation algorithm to generate $\\chi^2$ random variates using only a standard normal random number generator. This task solidifies the formal definition of the chi-squared distribution by translating it into a practical, step-by-step procedure.", "problem": "In the development of a custom statistical simulation library, a programmer is tasked with creating a function to generate random variates from a chi-squared distribution with $k$ degrees of freedom, denoted as $\\chi^2(k)$, where $k$ is a positive integer. The only available tool is a pre-existing function, `get_std_normal()`, which returns a single random number drawn from the standard normal distribution, $N(0, 1)$.\n\nThe programmer must design an algorithm that correctly produces a single random variate from the $\\chi^2(k)$ distribution by making one or more calls to `get_std_normal()`. Which of the following proposed algorithms correctly accomplishes this task?\n\nA. Initialize a variable `sum_of_squares` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, add $z^2$ to `sum_of_squares`. The final value of `sum_of_squares` is the result.\n\nB. Initialize a variable `sum_val` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, and add $z$ to `sum_val`. The final value of `sum_val` is the result.\n\nC. Initialize a variable `sum_val` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, and add $z$ to `sum_val`. The final result is `sum_val` squared.\n\nD. Call `get_std_normal()` exactly once to get a value $z$. The result is $k \\times z$.\n\nE. Initialize a variable `sum_of_squares` to 0. Loop $k$ times: in each iteration, call `get_std_normal()` to get a value $z$, add $z^2$ to `sum_of_squares`. The final result is `sum_of_squares` divided by $k$.", "solution": "Let $Z_{1},\\dots,Z_{k}$ be independent standard normal random variables, each obtained by a call to get_std_normal(), so $Z_{i} \\sim N(0,1)$ and the $Z_{i}$ are independent. By the defining property of the chi-squared distribution, the sum of squares\n$$\nQ=\\sum_{i=1}^{k} Z_{i}^{2}\n$$\nhas the $\\chi^{2}(k)$ distribution. This can be verified, for example, via the moment generating function: for $t<\\frac{1}{2}$, the mgf of $Z_{i}^{2}$ is $(1-2t)^{-1/2}$, and by independence\n$$\nM_{Q}(t)=\\prod_{i=1}^{k}(1-2t)^{-1/2}=(1-2t)^{-k/2},\n$$\nwhich is the mgf of $\\chi^{2}(k)$. Therefore, computing the sum of the squares of $k$ independent standard normals is exactly the correct algorithm.\n\nNow assess each proposed algorithm:\n\nA. This computes $Q=\\sum_{i=1}^{k} Z_{i}^{2}$, which by definition has distribution $\\chi^{2}(k)$. Hence A is correct.\n\nB. This computes $S=\\sum_{i=1}^{k} Z_{i}$, which is normal with $S \\sim N(0,k)$, not chi-squared. Hence B is incorrect.\n\nC. This computes $S^{2}$ where $S=\\sum_{i=1}^{k} Z_{i} \\sim N(0,k)$. Then $S/\\sqrt{k} \\sim N(0,1)$ and $S^{2}=k\\,(S/\\sqrt{k})^{2}$, so $S^{2}$ has the distribution $k \\cdot \\chi^{2}(1)$, which is not $\\chi^{2}(k)$ unless $k=1$. Hence C is incorrect in general.\n\nD. This computes $k Z$ for a single $Z \\sim N(0,1)$, yielding $N(0,k^{2})$, not chi-squared. Hence D is incorrect.\n\nE. This computes $\\frac{1}{k}\\sum_{i=1}^{k} Z_{i}^{2}=\\frac{1}{k}\\,\\chi^{2}(k)$, a scaled chi-squared variable, not $\\chi^{2}(k)$. Hence E is incorrect.\n\nTherefore, the only correct algorithm is A.", "answer": "$$\\boxed{A}$$", "id": "1903721"}, {"introduction": "One of the most powerful and widely used features of the chi-squared distribution is its additivity property. This final exercise explores how independent chi-squared variables combine, a principle that is foundational to many statistical tests, such as the analysis of variance (ANOVA). By solving this problem, you will gain insight into how degrees of freedom are partitioned and combined in statistical modeling.", "problem": "Let $X$ and $Y$ be independent random variables. The variable $X$ is known to follow a chi-squared distribution with $k_X = 4$ degrees of freedom, denoted as $X \\sim \\chi^2(4)$. Their sum, $Z = X+Y$, is also a chi-squared random variable, following a distribution with $k_Z = 10$ degrees of freedom, i.e., $Z \\sim \\chi^2(10)$.\n\nYou are provided with the following fundamental properties of the chi-squared distribution:\n1.  **Additivity Property:** If two random variables $U \\sim \\chi^2(k_1)$ and $V \\sim \\chi^2(k_2)$ are independent, then their sum $U+V$ also follows a chi-squared distribution with degrees of freedom equal to the sum of their individual degrees of freedom: $U+V \\sim \\chi^2(k_1+k_2)$. This property implies that if $U$ and $V$ are independent, and both $U$ and $U+V$ are chi-squared variables, then $V$ must also be a chi-squared variable.\n2.  **Variance Formula:** The variance of a random variable $W$ that follows a chi-squared distribution with $k$ degrees of freedom is given by $\\text{Var}(W) = 2k$.\n\nBased on this information, derive the variance of the random variable $Y$.", "solution": "By the additivity of chi-squared distributions, if $X\\sim\\chi^2(k_X)$ and $Y\\sim\\chi^2(k_Y)$ are independent then \n$$Z=X+Y\\sim\\chi^2(k_X+k_Y)\\,. $$\nHere $k_X=4$ and $k_Z=10$, so\n$$k_Y=k_Z-k_X=10-4=6\\,. $$\n\nThe variance of a chi-squared random variable with $k$ degrees of freedom is $\\text{Var}(W)=2k$.  Therefore\n$$\\text{Var}(Y)=2k_Y=2\\cdot6=12\\,. $$", "answer": "$$\\boxed{12}$$", "id": "2278"}]}