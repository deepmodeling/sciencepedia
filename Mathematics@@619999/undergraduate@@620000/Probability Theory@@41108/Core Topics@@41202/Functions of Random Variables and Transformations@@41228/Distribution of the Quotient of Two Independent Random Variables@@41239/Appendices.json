{"hands_on_practices": [{"introduction": "Let's begin with a fundamental case involving discrete random variables. This exercise [@problem_id:1358252] will guide you through constructing the Probability Mass Function (PMF) for a quotient of two independent variables with distinct distributionsâ€”one finite and one infinite. Mastering this helps build a strong intuition for how the combination of variables shapes the resulting probability space before we tackle continuous cases.", "problem": "Consider two independent discrete random variables, $X$ and $Y$.\n\nThe random variable $X$ models the outcome of a fair coin toss, where $X=1$ for heads and $X=0$ for tails.\n\nThe random variable $Y$ follows a geometric distribution with a success probability of $p=\\frac{1}{3}$. The Probability Mass Function (PMF), which gives the probability of an outcome, for $Y$ is given by $P(Y=k) = (1-p)^{k-1}p$ for any positive integer $k \\in \\{1, 2, 3, \\dots\\}$.\n\nA new random variable $Z$ is defined as the quotient $Z = \\frac{X}{Y}$.\n\nDetermine the PMF of $Z$. Your answer should be a complete definition of the function $f_Z(z) = P(Z=z)$ for all real numbers $z$.", "solution": "Let $X$ be a Bernoulli random variable with $P(X=1)=\\frac{1}{2}$ and $P(X=0)=\\frac{1}{2}$, and let $Y$ be a geometric random variable with success probability $p=\\frac{1}{3}$ on $\\{1,2,3,\\dots\\}$, so $P(Y=k)=(1-p)^{k-1}p=\\left(\\frac{2}{3}\\right)^{k-1}\\frac{1}{3}$ for $k\\in\\{1,2,3,\\dots\\}$. Assume $X$ and $Y$ are independent. Define $Z=\\frac{X}{Y}$.\n\nFirst, compute $P(Z=0)$. Since $Y\\in\\{1,2,\\dots\\}$ almost surely, we have $Z=0$ if and only if $X=0$. Therefore,\n$$\nP(Z=0)=P(X=0)=\\frac{1}{2}.\n$$\n\nNext, for $z>0$, note that $Z=\\frac{X}{Y}$ can be positive only if $X=1$, in which case $Z=\\frac{1}{Y}$. Hence the only positive values that $Z$ can take are $z=\\frac{1}{k}$ for $k\\in\\{1,2,3,\\dots\\}$. For each $k\\in\\{1,2,3,\\dots\\}$,\n$$\nP\\!\\left(Z=\\frac{1}{k}\\right)=P(X=1,\\,Y=k)=P(X=1)\\,P(Y=k)=\\frac{1}{2}\\left(\\frac{2}{3}\\right)^{k-1}\\frac{1}{3},\n$$\nusing independence of $X$ and $Y$.\n\nFor any other real $z$ not in $\\{0\\}\\cup\\left\\{\\frac{1}{k}:k\\in\\{1,2,3,\\dots\\}\\right\\}$, we have $P(Z=z)=0$.\n\nA normalization check confirms\n$$\nP(Z=0)+\\sum_{k=1}^{\\infty}P\\!\\left(Z=\\frac{1}{k}\\right)\n=\\frac{1}{2}+\\sum_{k=1}^{\\infty}\\frac{1}{2}\\left(\\frac{2}{3}\\right)^{k-1}\\frac{1}{3}\n=\\frac{1}{2}+\\frac{1}{2}\\cdot\\frac{1}{3}\\cdot\\frac{1}{1-\\frac{2}{3}}=\\frac{1}{2}+\\frac{1}{2}=1,\n$$\nso the PMF is valid.\n\nTherefore, the PMF of $Z$ is\n$$\nf_{Z}(z)=\n\\begin{cases}\n\\frac{1}{2}, & z=0,\\\\[6pt]\n\\frac{1}{2}\\left(\\frac{2}{3}\\right)^{k-1}\\frac{1}{3}, & z=\\frac{1}{k},\\ k\\in\\{1,2,3,\\dots\\},\\\\[6pt]\n0, & \\text{otherwise}.\n\\end{cases}\n$$", "answer": "$$\\boxed{f_{Z}(z)=\\begin{cases}\n\\frac{1}{2}, & z=0,\\\\[6pt]\n\\frac{1}{2}\\left(\\frac{2}{3}\\right)^{k-1}\\frac{1}{3}, & z=\\frac{1}{k},\\ k\\in\\{1,2,3,\\dots\\},\\\\[6pt]\n0, & \\text{otherwise}.\n\\end{cases}}$$", "id": "1358252"}, {"introduction": "We now move into the continuous domain, which is central to modeling physical phenomena. This problem [@problem_id:1358270] presents a classic scenario of finding a signal-to-noise ratio and will give you hands-on practice with the powerful method of transformations for deriving a Probability Density Function (PDF). Pay close attention to how the bounds of the original uniform distributions define the piecewise nature of the final result.", "problem": "In a communication systems lab, a student is analyzing a noisy signal. The instantaneous value of a signal component, $X$, is modeled as a random variable uniformly distributed on the interval $[-2, 2]$. The instantaneous value of a noise component, $Y$, is modeled as an independent random variable uniformly distributed on the interval $[1, 4]$. A crucial measure for system performance is the signal-to-noise ratio, which for this simplified model is given by the quotient $Z = X/Y$. Your task is to determine the probability density function (PDF), $f_Z(z)$, of this ratio $Z$. The function should be specified for all real values of $z$.", "solution": "Let $X \\sim \\operatorname{Unif}[-2,2]$ and $Y \\sim \\operatorname{Unif}[1,4]$ be independent. Then $f_{X}(x) = \\frac{1}{4}$ for $x \\in [-2,2]$ and $f_{Y}(y) = \\frac{1}{3}$ for $y \\in [1,4]$. Define $Z = X/Y$ and use the transformation $(Z,V) = (X/Y, Y)$ so that $X = ZV$, $Y = V$. The Jacobian determinant is $\\left|\\frac{\\partial(x,y)}{\\partial(z,v)}\\right| = |v| = v$ since $v=y \\geq 1$. Therefore, using independence,\n$$\nf_{Z}(z) = \\int_{v=1}^{4} f_{X,Y}(zv, v)\\, v \\, dv = \\int_{1}^{4} \\left(\\frac{1}{12}\\right) v \\, \\mathbf{1}\\{-2 \\leq zv \\leq 2\\} \\, dv,\n$$\nwhere $\\mathbf{1}\\{\\cdot\\}$ is the indicator function. Since $v>0$, the constraint $-2 \\leq zv \\leq 2$ is equivalent to $|z| v \\leq 2$, i.e., $v \\leq \\frac{2}{|z|}$. Hence\n$$\nf_{Z}(z) = \\frac{1}{12} \\int_{1}^{\\min\\{4,\\, 2/|z|\\}} v \\, dv,\n$$\nwith the understanding that the integral is zero if $\\min\\{4, 2/|z|\\} < 1$, which occurs when $|z| > 2$. Evaluating the integral gives\n$$\nf_{Z}(z) = \\begin{cases}\n0, & |z| > 2, \\\\\n\\frac{1}{12} \\cdot \\frac{1}{2} \\left(4^{2} - 1^{2}\\right) = \\frac{5}{8}, & |z| \\leq \\frac{1}{2}, \\\\\n\\frac{1}{12} \\cdot \\frac{1}{2} \\left(\\left(\\frac{2}{|z|}\\right)^{2} - 1\\right) = \\frac{1}{24}\\left(\\frac{4}{z^{2}} - 1\\right), & \\frac{1}{2} < |z| \\leq 2.\n\\end{cases}\n$$\nThis $f_{Z}(z)$ is even, supported on $[-2,2]$, and integrates to $1$, as can be verified by direct calculation.", "answer": "$$\\boxed{f_{Z}(z)=\\begin{cases}\n\\frac{5}{8}, & |z| \\leq \\frac{1}{2},\\\\[4pt]\n\\frac{1}{24}\\left(\\frac{4}{z^{2}}-1\\right), & \\frac{1}{2}<|z|\\leq 2,\\\\[4pt]\n0, & |z|>2\n\\end{cases}}$$", "id": "1358270"}, {"introduction": "Our final practice builds upon the previous exercise by introducing the important concept of conditioning. In many real-world applications, we analyze systems under specific constraints, and this problem [@problem_id:1358210] asks you to find the distribution of a signal-to-noise ratio given a \"weak noise\" condition. This practice demonstrates how to first modify the sample space based on the given condition and then apply standard techniques to the new, conditional joint distribution.", "problem": "In a simplified model of a digital communication channel, a signal's amplitude $S$ is represented by a random variable uniformly distributed on the interval $[0, 1]$. The channel introduces noise, whose amplitude $N$ is independently drawn from the same uniform distribution on $[0, 1]$. For reliable communication, the noise must be considered \"weak,\" which is defined by the event that its amplitude is less than half of its maximum possible value, i.e., $N < 0.5$.\n\nLet the signal-to-noise ratio be defined as the random variable $Z = S/N$. Your task is to determine the conditional Probability Density Function (PDF) of $Z$, given that the noise is weak. Present your answer as a single mathematical expression, which may be piecewise.", "solution": "Let $S$ and $N$ be independent with $S \\sim \\text{Unif}(0,1)$ and $N \\sim \\text{Unif}(0,1)$. Define the event $W=\\{N<\\frac{1}{2}\\}$. The unconditional joint PDF is $f_{S,N}(s,n)=1$ for $(s,n)\\in[0,1]\\times[0,1]$. The probability of $W$ is $P(W)=P(N<\\frac{1}{2})=\\frac{1}{2}$.\n\nThus, the conditional joint PDF on $W$ is\n$$\nf_{S,N \\mid W}(s,n)=\\frac{f_{S,N}(s,n)}{P(W)}=\\begin{cases}\n2, & 0 \\le s \\le 1,\\ 0 \\le n \\le \\frac{1}{2},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\nDefine $Z=S/N$ and use the transformation $(Z,N) \\mapsto (S,N)$ given by $S=ZN$, $N=N$. The Jacobian determinant is\n$$\nJ=\\left|\\det\\begin{pmatrix}\n\\frac{\\partial s}{\\partial z} & \\frac{\\partial s}{\\partial n}\\\\\n\\frac{\\partial n}{\\partial z} & \\frac{\\partial n}{\\partial n}\n\\end{pmatrix}\\right|=\\left|\\det\\begin{pmatrix}\nn & z\\\\\n0 & 1\n\\end{pmatrix}\\right|=|n|=n,\n$$\nsince $n \\ge 0$ on $W$. The support in $(z,n)$ is determined by $0 \\le n \\le \\frac{1}{2}$ and $0 \\le s=zn \\le 1$, i.e., $0 \\le z \\le \\frac{1}{n}$ for $n>0$.\n\nTherefore, the conditional joint PDF of $(Z,N)$ given $W$ is\n$$\nf_{Z,N \\mid W}(z,n)=f_{S,N \\mid W}(zn,n)\\,J=\\begin{cases}\n2n, & 0 \\le n \\le \\frac{1}{2},\\ 0 \\le z \\le \\frac{1}{n},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\nMarginalizing over $n$ gives the conditional PDF of $Z$:\n$$\nf_{Z \\mid W}(z)=\\int_{0}^{\\min\\{\\frac{1}{2},\\,\\frac{1}{z}\\}} 2n\\,dn,\n$$\nfor $z \\ge 0$, and $f_{Z \\mid W}(z)=0$ for $z<0$.\n\nEvaluate the integral piecewise:\n- If $0 \\le z \\le 2$, then $\\frac{1}{z} \\ge \\frac{1}{2}$, so\n$$\nf_{Z \\mid W}(z)=\\int_{0}^{\\frac{1}{2}} 2n\\,dn=\\left[n^{2}\\right]_{0}^{\\frac{1}{2}}=\\frac{1}{4}.\n$$\n- If $z > 2$, then $\\frac{1}{z} < \\frac{1}{2}$, so\n$$\nf_{Z \\mid W}(z)=\\int_{0}^{\\frac{1}{z}} 2n\\,dn=\\left[n^{2}\\right]_{0}^{\\frac{1}{z}}=\\frac{1}{z^{2}}.\n$$\n\nFor completeness, verify normalization:\n$$\n\\int_{0}^{2} \\frac{1}{4}\\,dz + \\int_{2}^{\\infty} \\frac{1}{z^{2}}\\,dz = \\frac{1}{4}\\cdot 2 + \\left[-\\frac{1}{z}\\right]_{2}^{\\infty}=\\frac{1}{2}+\\frac{1}{2}=1.\n$$\n\nThus, the conditional PDF of $Z=S/N$ given $N<\\frac{1}{2}$ is\n$$\nf_{Z \\mid N<\\frac{1}{2}}(z)=\\begin{cases}\n\\frac{1}{4}, & 0 \\le z \\le 2,\\\\\n\\frac{1}{z^{2}}, & z > 2,\\\\\n0, & z < 0.\n\\end{cases}\n$$", "answer": "$$\\boxed{f_{Z \\mid N<\\frac{1}{2}}(z)=\\begin{cases}\\frac{1}{4}, & 0 \\le z \\le 2,\\\\ \\frac{1}{z^{2}}, & z > 2,\\\\ 0, & z < 0.\\end{cases}}$$", "id": "1358210"}]}