{"hands_on_practices": [{"introduction": "The additivity property is a cornerstone of working with Gamma distributions, stating that the sum of independent Gamma variables with a common rate parameter is also Gamma distributed. This first exercise provides a direct hands-on application of this powerful theorem. By modeling sequential project phases, you will calculate the variance of the total project duration, reinforcing how the parameters of the resulting Gamma distribution are determined [@problem_id:1391363].", "problem": "A software development project is divided into two sequential phases: an algorithm design phase and an implementation phase. The time required to complete the design phase, let's call it $T_1$, and the time required to complete the implementation phase, $T_2$, are modeled as independent random variables.\n\nThe duration $T_1$ follows a Gamma distribution with a shape parameter $\\alpha_1 = 2$ and a rate parameter $\\beta = \\frac{1}{3}$. The duration $T_2$ follows a Gamma distribution with a shape parameter $\\alpha_2 = 3$ and the same rate parameter $\\beta = \\frac{1}{3}$. The probability density function of a Gamma distributed random variable $X$ with shape parameter $\\alpha$ and rate parameter $\\beta$ is given by $f(x) = \\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp(-\\beta x)$ for $x > 0$.\n\nThe total duration of the project is the sum of the durations of the two phases, $T = T_1 + T_2$. Calculate the variance of the total project duration, $\\text{Var}(T)$.", "solution": "Let $T_{1} \\sim \\Gamma(\\alpha_{1},\\beta)$ and $T_{2} \\sim \\Gamma(\\alpha_{2},\\beta)$ be independent, with $\\alpha_{1}=2$, $\\alpha_{2}=3$, and $\\beta=\\frac{1}{3}$, using the rate parametrization given by the density $f(x)=\\frac{\\beta^{\\alpha}}{\\Gamma(\\alpha)}x^{\\alpha-1}\\exp(-\\beta x)$ for $x>0$.\n\nFor a Gamma$(\\alpha,\\beta)$ random variable with rate $\\beta$, the variance is\n$$\n\\operatorname{Var}(X)=\\frac{\\alpha}{\\beta^{2}}.\n$$\n\nSince $T=T_{1}+T_{2}$ is the sum of two independent Gamma variables with the same rate, $T$ is Gamma with shape parameter $\\alpha_{1}+\\alpha_{2}$ and the same rate $\\beta$. Therefore,\n$$\n\\operatorname{Var}(T)=\\frac{\\alpha_{1}+\\alpha_{2}}{\\beta^{2}}.\n$$\nSubstituting $\\alpha_{1}=2$, $\\alpha_{2}=3$, and $\\beta=\\frac{1}{3}$ gives\n$$\n\\operatorname{Var}(T)=\\frac{2+3}{\\left(\\frac{1}{3}\\right)^{2}}=\\frac{5}{\\frac{1}{9}}=45.\n$$\nEquivalently, by independence, $\\operatorname{Var}(T)=\\operatorname{Var}(T_{1})+\\operatorname{Var}(T_{2})=\\frac{\\alpha_{1}}{\\beta^{2}}+\\frac{\\alpha_{2}}{\\beta^{2}}=\\frac{\\alpha_{1}+\\alpha_{2}}{\\beta^{2}}$, yielding the same result.", "answer": "$$\\boxed{45}$$", "id": "1391363"}, {"introduction": "A foundational link in probability theory is that the Exponential distribution is a special case of the Gamma distribution, specifically $\\text{Gamma}(1, \\lambda)$. This next practice explores the consequence of this relationship by examining the sum of two independent, exponentially distributed processing times. You will calculate a key performance metric, the expected squared total time, which illustrates how summing exponential variables gives rise to a Gamma distribution with a new shape parameter [@problem_id:1391349].", "problem": "A simple web server processes incoming requests in two sequential, independent stages. The time, $T_1$, required to complete the first stage follows an exponential distribution with a rate parameter $\\lambda > 0$. Similarly, the time, $T_2$, for the second stage is also an independent random variable following an exponential distribution with the same rate parameter $\\lambda$. The probability density function for a random variable $X$ following an exponential distribution with rate $\\lambda$ is given by $f(x) = \\lambda \\exp(-\\lambda x)$ for $x \\ge 0$.\n\nThe total processing time for a single request is the sum of the times for the two stages, $T = T_1 + T_2$. For system performance analysis, a key metric is the expected value of the square of the total processing time. Calculate this metric, $E[T^2]$, as an analytic expression in terms of the rate parameter $\\lambda$.", "solution": "Let $T_{1}$ and $T_{2}$ be independent exponential random variables with common rate $\\lambda>0$, each having density $f(x)=\\lambda \\exp(-\\lambda x)$ for $x\\ge 0$. The total processing time is $T=T_{1}+T_{2}$. We seek $E[T^{2}]$.\n\nStart by expanding the square and taking expectation:\n$$\nE[T^{2}]=E\\big[(T_{1}+T_{2})^{2}\\big]=E[T_{1}^{2}]+2E[T_{1}T_{2}]+E[T_{2}^{2}].\n$$\nBy independence, $E[T_{1}T_{2}]=E[T_{1}]E[T_{2}]$. Since $T_{1}$ and $T_{2}$ are identically distributed, $E[T_{1}]=E[T_{2}]$ and $E[T_{1}^{2}]=E[T_{2}^{2}]$. Thus,\n$$\nE[T^{2}]=2E[T_{1}^{2}]+2\\big(E[T_{1}]\\big)^{2}.\n$$\n\nWe now compute the first two moments of a single exponential variable $X\\sim \\text{Exp}(\\lambda)$. For the mean,\n$$\nE[X]=\\int_{0}^{\\infty}x\\,\\lambda \\exp(-\\lambda x)\\,dx.\n$$\nUse the substitution $y=\\lambda x$ so that $x=\\frac{y}{\\lambda}$ and $dx=\\frac{dy}{\\lambda}$:\n$$\nE[X]=\\int_{0}^{\\infty}\\left(\\frac{y}{\\lambda}\\right)\\lambda \\exp(-y)\\frac{dy}{\\lambda}=\\frac{1}{\\lambda}\\int_{0}^{\\infty}y\\exp(-y)\\,dy=\\frac{1}{\\lambda}\\,\\Gamma(2)=\\frac{1}{\\lambda}.\n$$\nFor the second moment,\n$$\nE[X^{2}]=\\int_{0}^{\\infty}x^{2}\\,\\lambda \\exp(-\\lambda x)\\,dx.\n$$\nWith the same substitution $y=\\lambda x$,\n$$\nE[X^{2}]=\\int_{0}^{\\infty}\\left(\\frac{y^{2}}{\\lambda^{2}}\\right)\\lambda \\exp(-y)\\frac{dy}{\\lambda}=\\frac{1}{\\lambda^{2}}\\int_{0}^{\\infty}y^{2}\\exp(-y)\\,dy=\\frac{1}{\\lambda^{2}}\\,\\Gamma(3)=\\frac{2}{\\lambda^{2}}.\n$$\n\nApplying these to $T_{1}$,\n$$\nE[T_{1}]=\\frac{1}{\\lambda},\\qquad E[T_{1}^{2}]=\\frac{2}{\\lambda^{2}}.\n$$\nTherefore,\n$$\nE[T^{2}]=2\\left(\\frac{2}{\\lambda^{2}}\\right)+2\\left(\\frac{1}{\\lambda}\\right)^{2}=\\frac{4}{\\lambda^{2}}+\\frac{2}{\\lambda^{2}}=\\frac{6}{\\lambda^{2}}.\n$$\n\nThis matches the known result for a Gamma (Erlang) distribution with shape parameter $k=2$ and rate $\\lambda$, for which $E[T^{2}]=\\operatorname{Var}(T)+\\big(E[T]\\big)^{2}=\\frac{k}{\\lambda^{2}}+\\left(\\frac{k}{\\lambda}\\right)^{2}=\\frac{2}{\\lambda^2} + \\left(\\frac{2}{\\lambda}\\right)^2 = \\frac{6}{\\lambda^{2}}$.", "answer": "$$\\boxed{\\frac{6}{\\lambda^{2}}}$$", "id": "1391349"}, {"introduction": "The principles of summing random variables are not just theoretical; they have profound implications in engineering and system design. This final practice applies the concept of summing exponential random variables to a realistic scenario in reliability engineering, involving a device with primary and backup power sources. Your task is to calculate the probability that the total operational lifetime exceeds a critical threshold, demonstrating the practical utility of the Gamma distribution in assessing system success and failure [@problem_id:1391396].", "problem": "A Deep-Oceanographic Reconnaissance Vehicle (DORV) is deployed for a long-term underwater survey mission. The vehicle is equipped with two identical, independent power sources: a primary unit and a backup unit. The DORV operates on the primary unit until it is fully depleted, at which point it instantaneously switches to the backup unit.\n\nThe operational lifetime of each power source is unpredictable and can be modeled as an independent random variable following an exponential distribution with a mean lifetime of 1000 hours.\n\nFor the mission to be considered a success, the DORV must remain operational for a total of at least 2500 hours. Calculate the probability that the mission is successful. Round your final answer to three significant figures.", "solution": "Let the primary and backup lifetimes be independent random variables $X_{1}$ and $X_{2}$, each exponentially distributed with mean $1000$ hours. The rate parameter is $\\lambda=\\frac{1}{1000}$. The total operational time is $S=X_{1}+X_{2}$. Since $X_{1}$ and $X_{2}$ are independent and identically exponentially distributed, $S$ has an Erlang (Gamma) distribution with shape parameter $k=2$ and rate $\\lambda$.\n\nThe probability density function of $S$ is\n$$\nf_{S}(t)=\\lambda^{2} t \\exp(-\\lambda t) \\quad \\text{for } t \\geq 0.\n$$\nThe mission succeeds if $S \\geq T$ with $T=2500$. Therefore,\n$$\n\\mathbb{P}(S \\geq T)=\\int_{T}^{\\infty} \\lambda^{2} t \\exp(-\\lambda t)\\, dt.\n$$\nEvaluate the integral by parts. Let $u=t$ and $dv=\\lambda^{2}\\exp(-\\lambda t)\\, dt$, so $du=dt$ and $v=-\\lambda \\exp(-\\lambda t)$. Then\n$$\n\\int \\lambda^{2} t \\exp(-\\lambda t)\\, dt = t(-\\lambda \\exp(-\\lambda t)) - \\int (-\\lambda \\exp(-\\lambda t))\\, dt = -\\lambda t \\exp(-\\lambda t) - \\exp(-\\lambda t) + C.\n$$\nThus,\n$$\n\\int_{T}^{\\infty} \\lambda^{2} t \\exp(-\\lambda t)\\, dt = \\left[ -\\lambda t \\exp(-\\lambda t) - \\exp(-\\lambda t) \\right]_{t=T}^{\\infty} = \\exp(-\\lambda T)\\left(1+\\lambda T\\right).\n$$\nWith $\\lambda=\\frac{1}{1000}$ and $T=2500$,\n$$\n\\mathbb{P}(S \\geq 2500)=\\exp\\!\\left(-\\frac{2500}{1000}\\right)\\left(1+\\frac{2500}{1000}\\right)=\\exp(-2.5)\\cdot 3.5.\n$$\nNumerically, $\\exp(-2.5)\\cdot 3.5 \\approx 0.287297\\ldots$, which rounded to three significant figures is $0.287$.", "answer": "$$\\boxed{0.287}$$", "id": "1391396"}]}