{"hands_on_practices": [{"introduction": "The concept of a sum of Bernoulli trials is fundamental to reliability engineering. Many critical systems, from aircraft to data centers, rely on redundancy where multiple independent components perform the same function. This practice problem [@problem_id:1390659] models such a scenario, where the total number of successful components follows a Binomial distribution. By working backward from a required system-level reliability, you will determine the necessary quality for each individual component, a common task in engineering design.", "problem": "An aerospace engineering team is designing a redundant braking system for a new aircraft. The system consists of three identical and independent hydraulic subsystems. The overall braking system is considered operational if at least two of the three subsystems function correctly. Let $p$ represent the reliability of a single hydraulic subsystem, which is its probability of functioning correctly.\n\nThe team has a strict design requirement that the overall reliability of the braking system must be precisely $0.972$. Assuming the reliability $p$ of each subsystem is the same, determine the value of $p$ that must be achieved for each subsystem to meet this requirement.", "solution": "Let $X$ denote the number of functioning subsystems among three identical, independent subsystems, each functioning with probability $p$. Then $X \\sim \\mathrm{Binomial}(3,p)$.\n\nThe overall system is operational if at least two subsystems function, so the reliability $R(p)$ is\n$$\nR(p) = \\mathbb{P}(X \\ge 2) = \\mathbb{P}(X=2) + \\mathbb{P}(X=3).\n$$\nUsing the binomial formula $\\mathbb{P}(X=k) = \\binom{3}{k} p^{k} (1-p)^{3-k}$, we obtain\n$$\nR(p) = \\binom{3}{2} p^{2} (1-p) + \\binom{3}{3} p^{3} = 3 p^{2} (1-p) + p^{3}.\n$$\nAlgebraically simplifying yields\n$$\nR(p) = 3 p^{2} - 2 p^{3}.\n$$\nThe design requirement is $R(p) = 0.972$, so we solve\n$$\n3 p^{2} - 2 p^{3} = 0.972.\n$$\nEquivalently,\n$$\n2 p^{3} - 3 p^{2} + 0.972 = 0.\n$$\nWe test $p = 0.9$:\n$$\n3 (0.9)^{2} - 2 (0.9)^{3} = 3 \\cdot 0.81 - 2 \\cdot 0.729 = 2.43 - 1.458 = 0.972,\n$$\nwhich satisfies the requirement. To see the solution is unique in $[0,1]$, note that\n$$\nR'(p) = 6 p - 6 p^{2} = 6 p (1 - p) \\ge 0 \\quad \\text{for } p \\in [0,1],\n$$\nso $R(p)$ is nondecreasing and strictly increasing on $(0,1)$, ensuring a unique $p$ satisfying the equation.\n\nTherefore, the required subsystem reliability is $p = 0.9$.", "answer": "$$\\boxed{0.9}$$", "id": "1390659"}, {"introduction": "While many introductory problems assume trials are identically distributed, real-world conditions often vary. This exercise [@problem_id:1390626] explores the sum of independent Bernoulli variables that do not share the same success probability. You will discover how to calculate the variance in this more general case by applying the fundamental property that the variance of a sum of independent variables is the sum of their variances, deepening your understanding beyond standard formulas.", "problem": "An archer shoots a total of $n$ arrows at a target. The archer's concentration wavers methodically throughout the competition. For the first shot, third shot, and all subsequent odd-numbered shots, the probability of hitting the target is $p_1$. For the second shot, fourth shot, and all subsequent even-numbered shots, the probability of hitting the target is $p_2$. The outcome of each shot is independent of all other shots.\n\nLet the random variable $H$ represent the total number of times the archer hits the target in these $n$ shots.\n\nDetermine a single, general expression for the variance of $H$, denoted as $Var(H)$. Your expression must be in terms of $n$, $p_1$, and $p_2$, and it must be valid for any positive integer $n$, whether $n$ is even or odd.", "solution": "Let $X_{i}$ be the indicator random variable for a hit on shot $i$, so $X_{i}=1$ if the $i$-th shot hits and $X_{i}=0$ otherwise. By the problem statement, for odd $i$ we have $\\Pr(X_{i}=1)=p_{1}$, and for even $i$ we have $\\Pr(X_{i}=1)=p_{2}$. The shots are independent, hence the $\\{X_{i}\\}$ are independent.\n\nThe total number of hits is $H=\\sum_{i=1}^{n}X_{i}$. Using variance of a sum,\n$$\n\\operatorname{Var}(H)\n=\\operatorname{Var}\\!\\left(\\sum_{i=1}^{n}X_{i}\\right)\n=\\sum_{i=1}^{n}\\operatorname{Var}(X_{i})+2\\sum_{1\\leq i<j\\leq n}\\operatorname{Cov}(X_{i},X_{j}).\n$$\nIndependence implies $\\operatorname{Cov}(X_{i},X_{j})=0$ for $i\\neq j$, so\n$$\n\\operatorname{Var}(H)=\\sum_{i=1}^{n}\\operatorname{Var}(X_{i}).\n$$\n\nFor a Bernoulli random variable with success probability $p$, $X^{2}=X$ implies $\\operatorname{Var}(X)=\\mathbb{E}[X^{2}]-\\mathbb{E}[X]^{2}=p-p^{2}=p(1-p)$. Therefore,\n- if $i$ is odd, $\\operatorname{Var}(X_{i})=p_{1}(1-p_{1})$;\n- if $i$ is even, $\\operatorname{Var}(X_{i})=p_{2}(1-p_{2})$.\n\nLet $m_{1}$ be the number of odd indices in $\\{1,\\dots,n\\}$ and $m_{2}$ be the number of even indices. Then $m_{1}=\\left\\lceil \\frac{n}{2}\\right\\rceil$ and $m_{2}=\\left\\lfloor \\frac{n}{2}\\right\\rfloor$. Hence,\n$$\n\\operatorname{Var}(H)=\\left\\lceil \\frac{n}{2}\\right\\rceil p_{1}\\left(1-p_{1}\\right)+\\left\\lfloor \\frac{n}{2}\\right\\rfloor p_{2}\\left(1-p_{2}\\right).\n$$\nThis single expression is valid for all positive integers $n$, whether $n$ is even or odd. (Equivalently, one may write $\\operatorname{Var}(H)=\\frac{n}{2}\\left[p_{1}(1-p_{1})+p_{2}(1-p_{2})\\right]+\\frac{1-(-1)^{n}}{4}\\left[p_{1}(1-p_{1})-p_{2}(1-p_{2})\\right]$.)", "answer": "$$\\boxed{\\left\\lceil \\frac{n}{2} \\right\\rceil p_{1}\\left(1-p_{1}\\right)+\\left\\lfloor \\frac{n}{2} \\right\\rfloor p_{2}\\left(1-p_{2}\\right)}$$", "id": "1390626"}, {"introduction": "Moving beyond simple analysis, this advanced problem delves into the realm of strategic optimization. Here, the parameters of the Bernoulli trials are not fixed but are choices to be made under a constraint to achieve a specific goal regarding the outcome's predictability. By analyzing how to maximize and minimize the variance of the total successes, $S$, you will engage with the deeper implications of how the distribution of probabilities $\\{p_i\\}$ influences the overall uncertainty of a system, a key concept in fields like cybersecurity and portfolio management [@problem_id:1390664].", "problem": "A cybersecurity firm is analyzing the strategic behavior of an adversary targeting a network of $N$ identical, independent servers. The adversary can allocate resources to attack each server, resulting in a probability $p_i$ of successfully compromising server $i$, for $i = 1, \\dots, N$. Each probability $p_i$ can be any real number in the interval $[0, 1]$.\n\nThe adversary operates under a strict \"attack potential\" constraint, such that the sum of the individual success probabilities is a fixed constant $C$. That is, $\\sum_{i=1}^N p_i = C$. The firm assumes the adversary is a rational agent who will choose the set of probabilities $\\{p_i\\}_{i=1}^N$ to achieve a specific goal.\n\nLet $S$ be the random variable representing the total number of servers compromised in an attack. The firm wants to understand the full range of unpredictability in the number of compromised servers. To this end, they model two extreme adversarial strategies: one that maximizes the variance of $S$, $\\text{Var}(S)$, and one that minimizes it.\n\nFor a system with $N=10$ servers and a total attack potential of $C=4.1$, determine the ratio $\\mathcal{R} = \\frac{V_{\\max}}{V_{\\min}}$, where $V_{\\max}$ is the maximum possible variance of $S$ and $V_{\\min}$ is the minimum possible variance of $S$ over all valid choices of $\\{p_i\\}$.\n\nExpress your final answer as a single real number, rounded to four significant figures.", "solution": "Let $X_{i}$ be the indicator of server $i$ being compromised, so $X_{i}\\sim\\text{Bernoulli}(p_{i})$, independent across $i=1,\\dots,N$. Then\n$$\nS=\\sum_{i=1}^{N}X_{i},\\quad \\mathbb{E}[S]=\\sum_{i=1}^{N}p_{i}=C,\n$$\nand, by independence,\n$$\n\\mathrm{Var}(S)=\\sum_{i=1}^{N}\\mathrm{Var}(X_{i})=\\sum_{i=1}^{N}p_{i}(1-p_{i})=\\sum_{i=1}^{N}p_{i}-\\sum_{i=1}^{N}p_{i}^{2}=C-\\sum_{i=1}^{N}p_{i}^{2}.\n$$\nThus, maximizing $\\mathrm{Var}(S)$ is equivalent to minimizing $\\sum_{i=1}^{N}p_{i}^{2}$ subject to $0\\leq p_{i}\\leq 1$ and $\\sum_{i=1}^{N}p_{i}=C$, while minimizing $\\mathrm{Var}(S)$ is equivalent to maximizing $\\sum_{i=1}^{N}p_{i}^{2}$ under the same constraints.\n\nBecause $x\\mapsto x^{2}$ is convex, Jensenâ€™s inequality (or the Cauchy-Schwarz inequality) implies\n$$\n\\sum_{i=1}^{N}p_{i}^{2}\\geq N\\left(\\frac{1}{N}\\sum_{i=1}^{N}p_{i}\\right)^{2}=\\frac{C^{2}}{N},\n$$\nwith equality at $p_{i}=C/N$ for all $i$, provided $C/N\\in[0,1]$. Here $N=10$ and $C=4.1$ give $C/N=0.41\\in[0,1]$, so the bound is feasible. Therefore,\n$$\nV_{\\max}=C-\\frac{C^{2}}{N}.\n$$\n\nTo maximize $\\sum_{i=1}^{N}p_{i}^{2}$ under $0\\leq p_{i}\\leq 1$ and fixed sum $C$, convexity implies the extremum occurs by pushing as many $p_{i}$ to the boundary $1$ as possible, then one residual $r\\in[0,1)$, with all others $0$. Let $k=\\lfloor C\\rfloor$ and $r=C-k\\in[0,1)$. Then the maximizing configuration is $k$ entries equal to $1$, one entry equal to $r$, and $N-k-1$ entries equal to $0$. Hence\n$$\n\\sum_{i=1}^{N}p_{i}^{2}=k\\cdot 1^{2}+r^{2}=k+r^{2},\n$$\nand thus\n$$\nV_{\\min}=C-(k+r^{2})=(k+r)-(k+r^{2})=r-r^{2}.\n$$\n\nFor $N=10$ and $C=4.1$, we have $k=\\lfloor 4.1\\rfloor=4$ and $r=0.1$. Therefore,\n$$\nV_{\\max}=4.1-\\frac{(4.1)^{2}}{10}=4.1-\\frac{16.81}{10}=4.1-1.681=2.419,\n$$\n$$\nV_{\\min}=0.1-0.1^{2}=0.1-0.01=0.09.\n$$\nThe desired ratio is\n$$\n\\mathcal{R}=\\frac{V_{\\max}}{V_{\\min}}=\\frac{2.419}{0.09}=\\frac{2419}{90}\\approx 26.877777\\ldots\n$$\nRounded to four significant figures, this is $26.88$.", "answer": "$$\\boxed{26.88}$$", "id": "1390664"}]}