{"hands_on_practices": [{"introduction": "We begin with a direct application of the one-sided Chebyshev inequality, also known as Cantelli's inequality. This powerful tool allows us to find a conservative upper bound for the probability of a random variable deviating significantly from its mean in one direction, without any knowledge of its specific distribution. This exercise [@problem_id:1377624] demonstrates how to apply the inequality in a practical scenario, a crucial skill for risk assessment where only the mean and variance are known.", "problem": "A sports analytics firm is modeling the performance of a baseball team, the \"Stochastic Sluggers.\" Let $X$ be a random variable representing the total number of runs the team scores in a season. The model is based on historical data, which indicates that the expected value (mean) of $X$ is $\\mu = 780$ runs, and the standard deviation is $\\sigma = 50$ runs. The firm wants to determine a conservative estimate for the likelihood of an exceptionally successful offensive season.\n\nWithout making any assumptions about the specific probability distribution of $X$ (such as it being a normal distribution), determine the tightest possible upper bound for the probability that the team scores at least 905 runs in the upcoming season.\n\nProvide your answer as a decimal rounded to three significant figures.", "solution": "We have a random variable $X$ with mean $\\mu=780$ and standard deviation $\\sigma=50$. We seek an upper bound for $P(X \\ge 905)$ without assuming a specific distribution.\n\nFor any real-valued random variable with mean $\\mu$ and variance $\\sigma^{2}$, Cantelli's inequality (one-sided Chebyshev) states that for any $t \\ge 0$,\n$$\nP(X-\\mu \\ge t) \\le \\frac{\\sigma^{2}}{\\sigma^{2}+t^{2}}.\n$$\nWe set $t=905-\\mu=905-780=125$ and $\\sigma^{2}=50^{2}=2500$. Substituting into Cantelli's inequality gives\n$$\nP(X \\ge 905) = P(X-\\mu \\ge 125) \\le \\frac{2500}{2500+125^{2}} = \\frac{2500}{2500+15625} = \\frac{2500}{18125}.\n$$\nThis fraction simplifies by dividing numerator and denominator by $625$:\n$$\n\\frac{2500}{18125} = \\frac{4}{29}.\n$$\nAs a decimal rounded to three significant figures,\n$$\n\\frac{4}{29} \\approx 0.138.\n$$\nTherefore, the tightest possible upper bound using only the mean and variance is $0.138$.", "answer": "$$\\boxed{0.138}$$", "id": "1377624"}, {"introduction": "Moving beyond simply calculating probabilities, we often face 'inverse problems' in fields like engineering and quality control. In this practice [@problem_id:1377638], instead of finding a probability bound from a known variance, you will determine the maximum permissible variance $\\sigma^2$ to ensure a risk level remains below a specified threshold. This reframes the inequality as a design tool, helping to set operational constraints to guarantee system reliability.", "problem": "A critical temperature sensor in a cryogenic cooling system is being evaluated for its reliability. The sensor provides readings that fluctuate randomly around a known average. Let $X$ be the random variable representing the temperature reading in Kelvin (K). The expected value (mean) of the sensor's reading is known to be $\\mu = 850$ K. A system alert is triggered if the sensor reading drops below a critical threshold of $c = 820$ K. The design specification requires that the probability of such an alert (a reading below the threshold) must be no more than $0.04$. Assuming no other information about the distribution of the sensor readings is available, what is the maximum permissible variance, $\\sigma^2$, of the sensor's readings? Express your answer in units of K$^2$, rounded to three significant figures.", "solution": "We are given only the mean $\\mu = 850$ and wish to ensure $P(X  c) \\le 0.04$ for $c = 820$. With no further distributional information, the appropriate one-sided bound is Cantelli's inequality (one-sided Chebyshev), which states that for any $a > 0$,\n$$\nP(X - \\mu \\le -a) \\le \\frac{\\sigma^{2}}{\\sigma^{2} + a^{2}}.\n$$\nHere, set $a = \\mu - c$. Then\n$$\nP(X  c) = P(X - \\mu \\le -(\\mu - c)) \\le \\frac{\\sigma^{2}}{\\sigma^{2} + (\\mu - c)^{2}}.\n$$\nTo enforce the specification $P(X  c) \\le 0.04$, require\n$$\n\\frac{\\sigma^{2}}{\\sigma^{2} + (\\mu - c)^{2}} \\le 0.04.\n$$\nSolve this inequality for $\\sigma^{2}$:\n$$\n\\sigma^{2} \\le 0.04\\left(\\sigma^{2} + (\\mu - c)^{2}\\right),\n$$\n$$\n\\sigma^{2} \\le 0.04\\sigma^{2} + 0.04(\\mu - c)^{2},\n$$\n$$\n(1 - 0.04)\\sigma^{2} \\le 0.04(\\mu - c)^{2},\n$$\n$$\n\\sigma^{2} \\le \\frac{0.04}{1 - 0.04}(\\mu - c)^{2}.\n$$\nSubstitute $\\mu = 850$ and $c = 820$, so $\\mu - c = 30$:\n$$\n\\sigma^{2} \\le \\frac{0.04}{0.96} \\cdot 30^{2} = \\frac{1}{24} \\cdot 900 = 37.5.\n$$\nThus, the maximum permissible variance is $37.5$ K$^{2}$, which to three significant figures is $37.5$.", "answer": "$$\\boxed{37.5}$$", "id": "1377638"}, {"introduction": "A fundamental question about any inequality is how 'tight' its bounds are. The one-sided Chebyshev inequality is described as 'sharp,' meaning its bound cannot be universally improved upon. This final practice [@problem_id:1903433] delves into this theoretical aspect by challenging you to construct a specific probability distribution for which the inequality becomes a perfect equality. Successfully completing this demonstrates why this bound is the best possible one given only the mean and variance, solidifying your understanding of its theoretical limits.", "problem": "Cantelli's inequality, also known as the one-sided Chebyshev inequality, provides an upper bound on the probability that a random variable deviates from its mean by a certain amount in one direction. For a random variable $X$ with a well-defined mean $\\mu$ and a finite, non-zero variance $\\sigma^2$, the inequality states that for any constant $k  0$:\n$$P(X - \\mu \\ge k\\sigma) \\le \\frac{1}{1+k^2}$$\nThis inequality is known to be \"sharp,\" which means that for any given $k0$, it is possible to construct a probability distribution for which the equality holds.\n\nConsider a discrete random variable $X$ whose probability distribution is supported on exactly two distinct points, $x_1$ and $x_2$. The probabilities associated with these points are $P(X=x_1) = p_1$ and $P(X=x_2) = p_2$, where $p_1  0$, $p_2  0$, and $p_1 + p_2 = 1$. This distribution is specifically designed so that Cantelli's inequality becomes an exact equality for the value $k=2$. Furthermore, the points are chosen such that the event $\\{X - \\mu \\ge 2\\sigma\\}$ is identical to the event $\\{X = x_1\\}$.\n\nDetermine the value of the probability $p_1$. Express your answer as a fraction in its simplest form.", "solution": "Let $X$ be supported on $\\{x_{1},x_{2}\\}$ with $P(X=x_{1})=p_{1}$ and $P(X=x_{2})=p_{2}$, where $p_{1}+p_{2}=1$, and let $\\mu=\\mathbb{E}[X]$ and $\\sigma^{2}=\\operatorname{Var}(X)$.\n\nCantelli's inequality states that for any $k0$,\n$$\nP(X-\\mu \\ge k\\sigma) \\le \\frac{1}{1+k^{2}}.\n$$\nThe problem specifies that the distribution is designed so that this inequality is an equality at $k=2$. Therefore,\n$$\nP(X-\\mu \\ge 2\\sigma)=\\frac{1}{1+2^{2}}=\\frac{1}{5}.\n$$\nIt is further given that the event $\\{X-\\mu \\ge 2\\sigma\\}$ is identical to the event $\\{X=x_{1}\\}$. Hence,\n$$\nP(X-\\mu \\ge 2\\sigma)=P(X=x_{1})=p_{1}.\n$$\nCombining these equalities yields\n$$\np_{1}=\\frac{1}{5}.\n$$\nThis fraction is already in simplest form.", "answer": "$$\\boxed{\\frac{1}{5}}$$", "id": "1903433"}]}