{"hands_on_practices": [{"introduction": "To begin, we'll tackle a foundational calculation. This exercise will help you master the relationship between variance, covariance, and the correlation coefficient when dealing with a linear combination of random variables. Understanding this is a cornerstone for many applications, from finance to signal processing. [@problem_id:1383136]", "problem": "In a signal processing application, two random signals, represented by the random variables $X$ and $Y$, are being analyzed. The statistical properties of these signals have been determined from experimental data. The variance of signal $X$ is found to be $\\text{Var}(X) = 1$, and the variance of signal $Y$ is $\\text{Var}(Y) = 4$. The correlation coefficient between the two signals is $\\rho(X,Y) = 0.5$. A new signal $Z$ is constructed by taking the difference of the original signals, such that $Z = X - Y$. Calculate the variance of the signal $Z$.", "solution": "We are given $Z=X-Y$. For any real constants $a$ and $b$, the variance of a linear combination satisfies\n$$\n\\operatorname{Var}(aX+bY)=a^{2}\\operatorname{Var}(X)+b^{2}\\operatorname{Var}(Y)+2ab\\,\\operatorname{Cov}(X,Y).\n$$\nWith $a=1$ and $b=-1$, this gives\n$$\n\\operatorname{Var}(Z)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)-2\\,\\operatorname{Cov}(X,Y).\n$$\nThe covariance is related to the correlation coefficient by\n$$\n\\operatorname{Cov}(X,Y)=\\rho(X,Y)\\,\\sigma_{X}\\sigma_{Y},\n$$\nwhere $\\sigma_{X}=\\sqrt{\\operatorname{Var}(X)}$ and $\\sigma_{Y}=\\sqrt{\\operatorname{Var}(Y)}$. Using the given values, $\\sigma_{X}=\\sqrt{1}=1$, $\\sigma_{Y}=\\sqrt{4}=2$, and $\\rho(X,Y)=\\frac{1}{2}$, we obtain\n$$\n\\operatorname{Cov}(X,Y)=\\frac{1}{2}\\cdot 1 \\cdot 2=1.\n$$\nTherefore,\n$$\n\\operatorname{Var}(Z)=1+4-2\\cdot 1=3.\n$$", "answer": "$$\\boxed{3}$$", "id": "1383136"}, {"introduction": "Next, let's explore correlation from a geometric perspective. This practice uses the intuitive scenario of a point on a circle to illustrate a crucial concept: zero correlation does not imply independence. By working through this problem, you'll gain a deeper appreciation for how the correlation coefficient specifically measures the strength of a *linear* relationship. [@problem_id:1383115]", "problem": "A sensor is mounted on the edge of a large circular disk of radius 1 unit, which is centered at the origin of a Cartesian coordinate system. The disk spins at a constant rate. At a random moment in time, the disk is stopped and the position of the sensor is recorded. Let the random variables $X$ and $Y$ represent the coordinates of the sensor at that instant. Due to the nature of the random stop, the sensor's final position $(X, Y)$ is a point chosen with uniform probability from the circumference of the unit circle.\n\nCalculate the Pearson correlation coefficient, $\\rho(X, Y)$, between the $X$ and $Y$ coordinates.", "solution": "Let $\\Theta$ denote the random angle of the sensor position measured from the positive $x$-axis. Since the stopping time is uniform and the point is uniformly distributed on the unit circle, we have $\\Theta \\sim \\text{Uniform}[0,2\\pi)$, and hence $X=\\cos\\Theta$ and $Y=\\sin\\Theta$.\n\nFirst, compute the means:\n$$\n\\mathbb{E}[X] = \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\cos\\theta\\,d\\theta = 0, \\quad\n\\mathbb{E}[Y] = \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\sin\\theta\\,d\\theta = 0.\n$$\n\nNext, compute the second moments using the identities $\\cos^{2}\\theta = \\frac{1+\\cos(2\\theta)}{2}$ and $\\sin^{2}\\theta = \\frac{1-\\cos(2\\theta)}{2}$:\n$$\n\\mathbb{E}[X^{2}] = \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\cos^{2}\\theta\\,d\\theta \n= \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\frac{1+\\cos(2\\theta)}{2}\\,d\\theta \n= \\frac{1}{2},\n$$\n$$\n\\mathbb{E}[Y^{2}] = \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\sin^{2}\\theta\\,d\\theta \n= \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\frac{1-\\cos(2\\theta)}{2}\\,d\\theta \n= \\frac{1}{2}.\n$$\nTherefore,\n$$\n\\operatorname{Var}(X) = \\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2} = \\frac{1}{2}, \\quad\n\\operatorname{Var}(Y) = \\mathbb{E}[Y^{2}] - (\\mathbb{E}[Y])^{2} = \\frac{1}{2}.\n$$\n\nCompute the cross-moment:\n$$\n\\mathbb{E}[XY] = \\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\cos\\theta\\sin\\theta\\,d\\theta\n= \\frac{1}{4\\pi}\\int_{0}^{2\\pi}\\sin(2\\theta)\\,d\\theta = 0,\n$$\nso\n$$\n\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y] = 0.\n$$\n\nBy definition, the Pearson correlation coefficient is\n$$\n\\rho(X,Y) = \\frac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}} \n= \\frac{0}{\\sqrt{\\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right)}} = 0.\n$$", "answer": "$$\\boxed{0}$$", "id": "1383115"}, {"introduction": "Our final practice challenges you to think about the bigger picture: the constraints that govern a system of correlations. You will discover that correlation coefficients are not independent of one another; they must satisfy certain mathematical rules for a valid joint distribution to exist. This problem introduces the powerful concept of the positive semi-definite correlation matrix to define the theoretical limits of a relationship. [@problem_id:1383120]", "problem": "An engineer in a signal processing lab is characterizing a system involving three fluctuating voltage signals, which are modeled as zero-mean random variables $X$, $Y$, and $Z$. Due to the system's architecture, direct measurement of the relationship between all three signals simultaneously is not possible. However, pairwise measurements have been reliably established. The correlation coefficient between $X$ and $Y$ is known to be $\\rho(X,Y) = 0.5$. Similarly, the correlation coefficient between $Y$ and $Z$ is $\\rho(Y,Z) = 0.5$. The correlation coefficient between $X$ and $Z$, denoted as $\\rho_{xz}$, is unknown.\n\nAssuming that a valid joint probability distribution for the triad $(X, Y, Z)$ exists, determine the range of all theoretically possible values for $\\rho_{xz}$. Your task is to find the minimum and maximum values that $\\rho_{xz}$ can take. Present your answer as a pair of numbers for the minimum and maximum value, respectively.", "solution": "Let $\\rho_{xz}=r$. A set of three variables with correlations $\\rho_{xy}=\\frac{1}{2}$, $\\rho_{yz}=\\frac{1}{2}$, and $\\rho_{xz}=r$ admits a valid joint distribution if and only if the $3\\times 3$ correlation matrix\n$$\nR=\\begin{pmatrix}\n1  \\frac{1}{2}  r\\\\\n\\frac{1}{2}  1  \\frac{1}{2}\\\\\nr  \\frac{1}{2}  1\n\\end{pmatrix}\n$$\nis positive semidefinite. This requires all principal minors to be nonnegative.\n\nThe $2\\times 2$ principal minors give $1-\\left(\\frac{1}{2}\\right)^{2}\\ge 0$ (satisfied) and $1-r^{2}\\ge 0$, hence $|r|\\le 1$.\n\nThe determinant must satisfy $\\det(R)\\ge 0$. Compute\n$$\n\\det(R)=\\begin{vmatrix}\n1  a  r\\\\\na  1  a\\\\\nr  a  1\n\\end{vmatrix}\n=1(1-a^{2})-a(a-ar)+r(a^{2}-r),\\quad a=\\frac{1}{2}.\n$$\nThis simplifies to\n$$\n\\det(R)=1-a^{2}-a^{2}+2a^{2}r-r^{2}.\n$$\nWith $a=\\frac{1}{2}$,\n$$\n\\det(R)=1-\\frac{1}{4}-\\frac{1}{4}+\\frac{1}{2}r-r^{2}\n=\\frac{1}{2}+\\frac{1}{2}r-r^{2}.\n$$\nThus\n$$\n\\frac{1}{2}+\\frac{1}{2}r-r^{2}\\ge 0\n\\;\\;\\Longleftrightarrow\\;\\;\n1+r-2r^{2}\\ge 0\n\\;\\;\\Longleftrightarrow\\;\\;\n2r^{2}-r-1\\le 0.\n$$\nThe roots of $2r^{2}-r-1=0$ are\n$$\nr=\\frac{1\\pm\\sqrt{1+8}}{4}=\\frac{1\\pm 3}{4}\\in\\left\\{-\\frac{1}{2},\\,1\\right\\}.\n$$\nSince the quadratic opens upward, the inequality holds for\n$$\n-\\frac{1}{2}\\le r\\le 1.\n$$\nCombining with $|r|\\le 1$ yields the final range $r\\in\\left[-\\frac{1}{2},\\,1\\right]$. The endpoints are attainable (they make $\\det(R)=0$ and all principal minors nonnegative), hence represent valid correlation structures.", "answer": "$$\\boxed{\\begin{pmatrix}-\\frac{1}{2}  1\\end{pmatrix}}$$", "id": "1383120"}]}