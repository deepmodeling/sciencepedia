{"hands_on_practices": [{"introduction": "Our exploration begins with the foundational structure of a joint probability mass function (PMF), often presented in a table. This first exercise [@problem_id:9946] is a classic starting point that reinforces a crucial property: the sum of all probabilities across the entire sample space must equal 1. By applying this rule, you will first determine the unknown constant in the PMF, a common task in probability modeling, and then use the completed PMF to calculate the probability of a specific event where the two random variables are equal.", "problem": "Let $X$ and $Y$ be two discrete random variables. The possible values for $X$ are from the set $S_X = \\{0, 1\\}$, and the possible values for $Y$ are from the set $S_Y = \\{0, 1, 2\\}$. Their joint probability mass function (PMF), denoted as $p(x, y) = P(X=x, Y=y)$, is given by the following table, where $c$ is a positive real constant:\n\n| $p(x,y)$ | $Y=0$ | $Y=1$ | $Y=2$ |\n| :--- | :--- | :--- | :--- |\n| **$X=0$**  | $c$ | $2c$ | $c$ |\n| **$X=1$**  | $2c$ | $3c$ | $3c$ |\n\nYour task is to derive the probability that the random variable $X$ is equal to the random variable $Y$, which is denoted as $P(X=Y)$.", "solution": "The joint PMF must sum to 1, so\n$$\n\\sum_{x\\in\\{0,1\\}}\\sum_{y\\in\\{0,1,2\\}}p(x,y)\n=(c+2c+c)+(2c+3c+3c)\n=4c+8c=12c=1\n$$\nhence\n$$\nc=\\frac{1}{12}.\n$$\nNext,\n$$\nP(X=Y)=\\sum_{x=y}p(x,y)=p(0,0)+p(1,1)=c+3c=4c.\n$$\nSubstituting $c=1/12$ gives\n$$\nP(X=Y)=4\\cdot\\frac{1}{12}=\\frac{1}{3}.\n$$", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "9946"}, {"introduction": "While tables are useful, joint PMFs are often defined by a mathematical formula. This next practice [@problem_id:9965] transitions us to this functional representation and introduces another essential concept: calculating the expected value of a function of two random variables. You will apply the general formula for expectation, $E[g(X, Y)] = \\sum_{x} \\sum_{y} g(x,y) p(x,y)$, to find $E[X-Y]$, a summary statistic that provides insight into the average difference between the two variables.", "problem": "Two discrete random variables, $X$ and $Y$, have a joint probability mass function (PMF) given by:\n$$\np(x, y) = \\begin{cases} C(x+y)  \\text{for } x \\in \\{1, 2\\} \\text{ and } y \\in \\{1, 2\\} \\\\ 0  \\text{otherwise} \\end{cases}\n$$\nwhere $C$ is a normalization constant.\n\nDerive the value of the expectation of the difference of the two random variables, $E[X-Y]$.", "solution": "The solution is a two-step process. First, we must determine the value of the normalization constant $C$. Second, we use the definition of expectation for a function of two random variables to calculate $E[X-Y]$.\n\n**Step 1: Determine the normalization constant C**\n\nThe sum of the probabilities over all possible outcomes must be equal to 1. The possible pairs of $(x, y)$ for which the probability is non-zero are (1,1), (1,2), (2,1), and (2,2).\n$$\n\\sum_{x=1}^{2} \\sum_{y=1}^{2} p(x, y) = 1\n$$\nSubstituting the given PMF:\n$$\n\\sum_{x=1}^{2} \\sum_{y=1}^{2} C(x+y) = 1\n$$\nWe can factor out the constant $C$:\n$$\nC \\sum_{x=1}^{2} \\sum_{y=1}^{2} (x+y) = 1\n$$\nNow, we evaluate the sum by plugging in all possible values for $x$ and $y$:\n$$\nC \\left[ (1+1) + (1+2) + (2+1) + (2+2) \\right] = 1\n$$\n$$\nC \\left[ 2 + 3 + 3 + 4 \\right] = 1\n$$\n$$\nC(12) = 1\n$$\nSolving for $C$, we find:\n$$\nC = \\frac{1}{12}\n$$\nSo, the joint PMF is $p(x, y) = \\frac{x+y}{12}$ for $x,y \\in \\{1,2\\}$.\n\n**Step 2: Calculate the expectation E[X-Y]**\n\nThe expectation of a function $g(X, Y)$ of two discrete random variables is defined as:\n$$\nE[g(X,Y)] = \\sum_{x} \\sum_{y} g(x,y) p(x,y)\n$$\nIn this problem, the function is $g(X, Y) = X - Y$. Therefore, we need to calculate:\n$$\nE[X-Y] = \\sum_{x=1}^{2} \\sum_{y=1}^{2} (x-y) p(x,y)\n$$\nSubstituting the PMF we found in Step 1:\n$$\nE[X-Y] = \\sum_{x=1}^{2} \\sum_{y=1}^{2} (x-y) \\left(\\frac{x+y}{12}\\right)\n$$\nWe can factor out the constant $\\frac{1}{12}$ and expand the sum:\n$$\nE[X-Y] = \\frac{1}{12} \\left[ (1-1)(1+1) + (1-2)(1+2) + (2-1)(2+1) + (2-2)(2+2) \\right]\n$$\nNow, we calculate the value of each term in the sum:\nFor $(x,y)=(1,1)$: $(0)(2) = 0$\nFor $(x,y)=(1,2)$: $(-1)(3) = -3$\nFor $(x,y)=(2,1)$: $(1)(3) = 3$\nFor $(x,y)=(2,2)$: $(0)(4) = 0$\n\nSubstitute these values back into the equation:\n$$\nE[X-Y] = \\frac{1}{12} \\left[ 0 + (-3) + 3 + 0 \\right]\n$$\n$$\nE[X-Y] = \\frac{1}{12} [0]\n$$\n$$\nE[X-Y] = 0\n$$\nAlternatively, one could notice the symmetry in the problem. Since the PMF $p(x,y) = C(x+y)$ is symmetric with respect to $x$ and $y$ (i.e., $p(x,y)=p(y,x)$) and the sample space for both variables is the same, their marginal distributions must be identical. Therefore, $E[X] = E[Y]$. Using the linearity of expectation, $E[X-Y] = E[X] - E[Y] = 0$. The direct calculation above confirms this.", "answer": "$$\n\\boxed{0}\n$$", "id": "9965"}, {"introduction": "In many real-world scenarios, we don't have the complete joint PMF; instead, we might know certain marginal or conditional probabilities. This exercise [@problem_id:1369669] showcases the powerful interplay between joint, marginal, and conditional distributions, using a practical example from quality control. Starting from partial information, you will reason through the relationships that bind the PMF table together to deduce the complete joint distribution and then calculate a conditional probability, a key skill for statistical inference.", "problem": "In a quality control analysis for a new type of satellite communication module, two specific microchips, let's call them A and B, are tested. Let $X$ be a random variable representing the state of chip A, where $X=1$ if the chip is functional and $X=0$ if it is non-functional. Similarly, let $Y$ be a random variable for the state of chip B, where $Y=1$ if functional and $Y=0$ if non-functional.\n\nBased on extensive testing of individual chips from the production line, the marginal probability that any given chip A is functional is $P(X=1) = \\frac{1}{2}$, and the marginal probability that any given chip B is functional is $P(Y=1) = \\frac{1}{2}$.\n\nHowever, when assembled on the same module, the chips are subject to shared operational stressors such as thermal load and power supply fluctuations. This introduces a dependency between their states. It is found that the joint probability of both chips being functional simultaneously is $P(X=1, Y=1) = \\frac{3}{8}$.\n\nGiven this information, calculate the conditional probability that chip B is non-functional, given that chip A is non-functional. Express your answer as a decimal or a fraction.", "solution": "The problem asks for the conditional probability $P(Y=0 | X=0)$. The formula for conditional probability is:\n$$P(Y=0 | X=0) = \\frac{P(X=0, Y=0)}{P(X=0)}$$\n\nWe are given the marginal probabilities for the functional states:\n$P(X=1) = \\frac{1}{2}$\n$P(Y=1) = \\frac{1}{2}$\n\nFrom these, we can find the marginal probabilities for the non-functional states, as there are only two possible states for each chip:\n$P(X=0) = 1 - P(X=1) = 1 - \\frac{1}{2} = \\frac{1}{2}$\n$P(Y=0) = 1 - P(Y=1) = 1 - \\frac{1}{2} = \\frac{1}{2}$\n\nNow we need to determine the joint probability $P(X=0, Y=0)$. We can construct the joint probability mass function (PMF) table for $(X,Y)$. The table has four entries corresponding to the pairs of outcomes $(x,y)$.\n\n|       | Y=0   | Y=1   | Total (Marginal for X) |\n|-------|-------|-------|------------------------|\n| **X=0** | $p_{00}$  | $p_{01}$  | $P(X=0) = 1/2$      |\n| **X=1** | $p_{10}$  | $p_{11}$  | $P(X=1) = 1/2$      |\n| **Total (Marginal for Y)**| $P(Y=0) = 1/2$ | $P(Y=1) = 1/2$ | 1 |\n\nHere, $p_{xy} = P(X=x, Y=y)$.\n\nWe are given $P(X=1, Y=1) = p_{11} = \\frac{3}{8}$.\n\nWe can use the marginal probabilities to find the other entries. The sum of probabilities in a row or column must equal the marginal probability for that row or column.\n\nConsider the row for $X=1$:\n$P(X=1) = P(X=1, Y=0) + P(X=1, Y=1)$\n$\\frac{1}{2} = p_{10} + p_{11}$\n$\\frac{1}{2} = p_{10} + \\frac{3}{8}$\n$p_{10} = \\frac{1}{2} - \\frac{3}{8} = \\frac{4}{8} - \\frac{3}{8} = \\frac{1}{8}$\n\nNow consider the column for $Y=1$:\n$P(Y=1) = P(X=0, Y=1) + P(X=1, Y=1)$\n$\\frac{1}{2} = p_{01} + p_{11}$\n$\\frac{1}{2} = p_{01} + \\frac{3}{8}$\n$p_{01} = \\frac{1}{2} - \\frac{3}{8} = \\frac{4}{8} - \\frac{3}{8} = \\frac{1}{8}$\n\nFinally, we find $p_{00} = P(X=0, Y=0)$. We can use the row for $X=0$:\n$P(X=0) = P(X=0, Y=0) + P(X=0, Y=1)$\n$\\frac{1}{2} = p_{00} + p_{01}$\n$\\frac{1}{2} = p_{00} + \\frac{1}{8}$\n$p_{00} = \\frac{1}{2} - \\frac{1}{8} = \\frac{4}{8} - \\frac{1}{8} = \\frac{3}{8}$\n\nWe have now found the required joint probability: $P(X=0, Y=0) = \\frac{3}{8}$.\n\nWe can now calculate the final conditional probability:\n$P(Y=0 | X=0) = \\frac{P(X=0, Y=0)}{P(X=0)} = \\frac{3/8}{1/2}$\n$P(Y=0 | X=0) = \\frac{3}{8} \\times \\frac{2}{1} = \\frac{6}{8} = \\frac{3}{4}$\n\nAs a decimal, this is $0.75$.", "answer": "$$\\boxed{0.75}$$", "id": "1369669"}]}