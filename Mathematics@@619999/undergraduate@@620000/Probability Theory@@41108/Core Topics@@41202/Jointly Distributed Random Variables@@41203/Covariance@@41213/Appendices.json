{"hands_on_practices": [{"introduction": "We begin with a familiar scenario: rolling two dice. This exercise grounds the abstract concept of covariance in a concrete, discrete setting. By calculating the covariance between the minimum and maximum values of the two rolls, we not only practice the core definition but also build an intuition for positive correlationâ€”when one value tends to be high, the other does too. This problem [@problem_id:1911479] also introduces an elegant computational shortcut, demonstrating how clever algebraic identities can simplify what might otherwise be a tedious enumeration of outcomes.", "problem": "Consider an experiment where two fair, standard six-sided dice are rolled independently. Let the outcome of the first die be $D_1$ and the second die be $D_2$. We define two random variables based on the outcomes: $X_{min} = \\min(D_1, D_2)$, representing the minimum value observed, and $X_{max} = \\max(D_1, D_2)$, representing the maximum value observed.\n\nCalculate the covariance between $X_{min}$ and $X_{max}$. Express your answer as an exact fraction in simplest form.", "solution": "Let $D_{1}$ and $D_{2}$ be independent and uniformly distributed on $\\{1,2,3,4,5,6\\}$. Define $X_{\\min}=\\min(D_{1},D_{2})$ and $X_{\\max}=\\max(D_{1},D_{2})$. For any real numbers $a$ and $b$,\n$$\n\\min(a,b)+\\max(a,b)=a+b,\\quad \\min(a,b)\\max(a,b)=ab.\n$$\nHence,\n$$\nX_{\\min}+X_{\\max}=D_{1}+D_{2},\\quad X_{\\min}X_{\\max}=D_{1}D_{2}.\n$$\nWe compute the expectations needed for covariance $\\operatorname{Cov}(X_{\\min},X_{\\max})=E[X_{\\min}X_{\\max}]-E[X_{\\min}]E[X_{\\max}]$.\n\nFirst, $E[D_{1}]=E[D_{2}]=\\frac{1}{6}\\sum_{i=1}^{6}i=\\frac{7}{2}$, so by independence,\n$$\nE[X_{\\min}X_{\\max}]=E[D_{1}D_{2}]=E[D_{1}]E[D_{2}]=\\left(\\frac{7}{2}\\right)^{2}=\\frac{49}{4}.\n$$\nNext, compute $E[X_{\\min}]$ using the tail-sum formula. For $k\\in\\{1,\\dots,6\\}$,\n$$\nP(X_{\\min}\\geq k)=P(D_{1}\\geq k)P(D_{2}\\geq k)=\\left(\\frac{7-k}{6}\\right)^{2}.\n$$\nTherefore,\n$$\nE[X_{\\min}]=\\sum_{k=1}^{6}P(X_{\\min}\\geq k)=\\frac{1}{36}\\sum_{k=1}^{6}(7-k)^{2}=\\frac{1}{36}\\sum_{t=1}^{6}t^{2}=\\frac{1}{36}\\cdot\\frac{6\\cdot 7\\cdot 13}{6}=\\frac{91}{36}.\n$$\nUsing $X_{\\min}+X_{\\max}=D_{1}+D_{2}$ and $E[D_{1}+D_{2}]=7$, we get\n$$\nE[X_{\\max}]=7-E[X_{\\min}]=7-\\frac{91}{36}=\\frac{161}{36}.\n$$\nThus,\n$$\nE[X_{\\min}]E[X_{\\max}]=\\frac{91}{36}\\cdot\\frac{161}{36}=\\frac{14651}{1296},\n$$\nand\n$$\nE[X_{\\min}X_{\\max}]=\\frac{49}{4}=\\frac{15876}{1296}.\n$$\nTherefore, the covariance is\n$$\n\\operatorname{Cov}(X_{\\min},X_{\\max})=\\frac{15876}{1296}-\\frac{14651}{1296}=\\frac{1225}{1296}.\n$$\nThis fraction is already in simplest form since $1225=5^{2}\\cdot 7^{2}$ shares no common prime factors with $1296=2^{4}\\cdot 3^{4}$.", "answer": "$$\\boxed{\\frac{1225}{1296}}$$", "id": "1911479"}, {"introduction": "Moving from a discrete to a continuous domain, this practice explores covariance in a geometric context. We consider a point chosen randomly from a simple triangular region and investigate the relationship between its coordinates, $X$ and $Y$. This problem [@problem_id:1911471] is a fundamental exercise in applying the definition of covariance, $\\text{Cov}(X,Y)=\\text{E}[XY] - \\text{E}[X]\\text{E}[Y]$, which requires the setup and evaluation of double integrals. It also serves to sharpen our intuition, as the shape of the region itself suggests a positive linear relationship, hinting at a positive covariance.", "problem": "Let $X$ and $Y$ be two continuous random variables. A point $(X, Y)$ is selected uniformly at random from a triangular region in the Cartesian plane. The vertices of this triangle are located at the coordinates $(0, 0)$, $(1, 0)$, and $(1, 1)$.\n\nDetermine the value of the covariance between $X$ and $Y$, denoted as $Cov(X, Y)$. Your final answer should be a single closed-form analytic expression.", "solution": "The triangular region with vertices at $(0,0)$, $(1,0)$, and $(1,1)$ is described by the set $D=\\{(x,y): 0 \\leq x \\leq 1,\\ 0 \\leq y \\leq x\\}$. Its area is\n$$\n|D|=\\frac{1}{2}.\n$$\nFor a uniform selection over $D$, the joint density is constant on $D$ and equals\n$$\nf_{X,Y}(x,y)=\\frac{1}{|D|}=2 \\quad \\text{for } (x,y)\\in D, \\text{ and } 0 \\text{ otherwise}.\n$$\nWe use the definition of covariance,\n$$\n\\operatorname{Cov}(X,Y)=\\operatorname{E}[XY]-\\operatorname{E}[X]\\operatorname{E}[Y].\n$$\nFirst compute $\\operatorname{E}[X]$:\n$$\n\\operatorname{E}[X]=\\iint_{D} x f_{X,Y}(x,y)\\,dx\\,dy\n=2\\int_{0}^{1}\\int_{0}^{x} x \\, dy \\, dx\n=2\\int_{0}^{1} x\\left[y\\right]_{0}^{x} dx\n=2\\int_{0}^{1} x^{2}\\,dx\n=\\frac{2}{3}.\n$$\nNext compute $\\operatorname{E}[Y]$:\n$$\n\\operatorname{E}[Y]=\\iint_{D} y f_{X,Y}(x,y)\\,dx\\,dy\n=2\\int_{0}^{1}\\int_{0}^{x} y \\, dy \\, dx\n=2\\int_{0}^{1} \\frac{x^{2}}{2}\\,dx\n=\\int_{0}^{1} x^{2}\\,dx\n=\\frac{1}{3}.\n$$\nNow compute $\\operatorname{E}[XY]$:\n$$\n\\operatorname{E}[XY]=\\iint_{D} xy \\, f_{X,Y}(x,y)\\,dx\\,dy\n=2\\int_{0}^{1}\\int_{0}^{x} xy \\, dy \\, dx\n=2\\int_{0}^{1} x \\left[\\frac{y^{2}}{2}\\right]_{0}^{x} dx\n=2\\int_{0}^{1} x \\cdot \\frac{x^{2}}{2}\\,dx\n=\\int_{0}^{1} x^{3}\\,dx\n=\\frac{1}{4}.\n$$\nSubstitute into the covariance formula:\n$$\n\\operatorname{Cov}(X,Y)=\\frac{1}{4}-\\left(\\frac{2}{3}\\right)\\left(\\frac{1}{3}\\right)=\\frac{1}{4}-\\frac{2}{9}=\\frac{9-8}{36}=\\frac{1}{36}.\n$$", "answer": "$$\\boxed{\\frac{1}{36}}$$", "id": "1911471"}, {"introduction": "One of the most critical, and often misunderstood, aspects of covariance is the distinction between zero covariance and independence. This final practice directly confronts this issue by examining the relationship between a random variable $X$ and its square, $Y=X^2$. While $Y$ is clearly dependent on $X$, this exercise [@problem_id:1354397] demonstrates how specific symmetries in a variable's distribution can result in a covariance of zero. Understanding this powerful counterexample is crucial for avoiding common interpretive errors, reinforcing that covariance only measures the linear component of a relationship.", "problem": "An engineer is analyzing the thermal noise in a sensitive electronic component. The noise voltage, after being normalized, is modeled as a continuous random variable $X$. The Probability Density Function (PDF) of $X$ is found to be a triangular distribution given by:\n$$\nf_X(x) = \\begin{cases}\n    C(a - |x|) & \\text{for } |x| \\le a \\\\\n    0 & \\text{otherwise}\n\\end{cases}\n$$\nwhere $a$ is a positive constant representing the maximum magnitude of the normalized noise, and $C$ is a normalization constant. The instantaneous power dissipated by the noise is proportional to the square of the voltage. The engineer models this normalized power as another random variable $Y = X^2$.\n\nTo understand the linear relationship between the noise voltage and the power it dissipates, the engineer needs to determine their covariance. Calculate the covariance, $\\text{Cov}(X, Y)$. Your final answer should be a numerical value.", "solution": "We are given that $X$ has the probability density function\n$$\nf_{X}(x)=\\begin{cases}\nC\\left(a-|x|\\right) & \\text{for }|x|\\leq a,\\\\\n0 & \\text{otherwise},\n\\end{cases}\n$$\nwith $a>0$ and $C$ chosen so that $f_{X}$ integrates to one, and $Y=X^{2}$. We are asked for $\\text{Cov}(X,Y)$, where by definition\n$$\n\\text{Cov}(X,Y)=\\mathbb{E}[XY]-\\mathbb{E}[X]\\mathbb{E}[Y].\n$$\nSince $Y=X^{2}$, this becomes\n$$\n\\text{Cov}(X,Y)=\\mathbb{E}[X^{3}]-\\mathbb{E}[X]\\mathbb{E}[X^{2}].\n$$\n\nFirst, determine the normalization constant $C$ by enforcing $\\int_{-\\!a}^{a}f_{X}(x)\\,dx=1$:\n$$\n\\int_{-\\!a}^{a}C\\left(a-|x|\\right)\\,dx\n=2C\\int_{0}^{a}\\left(a-x\\right)\\,dx\n=2C\\left[a x-\\frac{x^{2}}{2}\\right]_{0}^{a}\n=2C\\left(a^{2}-\\frac{a^{2}}{2}\\right)\n=2C\\left(\\frac{a^{2}}{2}\\right)\n=C a^{2}.\n$$\nThus $C a^{2}=1$, so\n$$\nC=\\frac{1}{a^{2}}.\n$$\n\nNext, observe that $f_{X}(x)$ is an even function because $f_{X}(-x)=C\\left(a-|-x|\\right)=C\\left(a-|x|\\right)=f_{X}(x)$. Therefore all odd moments of $X$ that exist are zero. In particular,\n$$\n\\mathbb{E}[X]=\\int_{-\\!a}^{a}x\\,f_{X}(x)\\,dx=0,\n\\qquad\n\\mathbb{E}[X^{3}]=\\int_{-\\!a}^{a}x^{3}\\,f_{X}(x)\\,dx=0,\n$$\nsince each integrand is an odd function multiplied by an even function, yielding an overall odd integrand integrated over the symmetric interval $[-a,a]$.\n\nFor completeness, one may verify that $\\mathbb{E}[X^{2}]$ is finite:\n$$\n\\mathbb{E}[X^{2}]\n=\\int_{-\\!a}^{a}x^{2}f_{X}(x)\\,dx\n=2\\int_{0}^{a}x^{2}\\,C\\left(a-x\\right)\\,dx\n=2C\\left[\\int_{0}^{a}a x^{2}\\,dx-\\int_{0}^{a}x^{3}\\,dx\\right]\n=2C\\left(\\frac{a^{4}}{3}-\\frac{a^{4}}{4}\\right)\n=2C\\left(\\frac{a^{4}}{12}\\right)\n=\\frac{C a^{4}}{6}\n=\\frac{a^{2}}{6},\n$$\nusing $C=1/a^{2}$. This value is not needed for the covariance once $\\mathbb{E}[X]=0$ is established.\n\nTherefore,\n$$\n\\text{Cov}(X,Y)=\\mathbb{E}[X^{3}]-\\mathbb{E}[X]\\mathbb{E}[X^{2}]=0-0\\cdot \\mathbb{E}[X^{2}]=0.\n$$", "answer": "$$\\boxed{0}$$", "id": "1354397"}]}