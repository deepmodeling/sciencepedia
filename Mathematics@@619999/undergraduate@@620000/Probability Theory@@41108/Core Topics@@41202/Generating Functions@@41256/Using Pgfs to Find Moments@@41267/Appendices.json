{"hands_on_practices": [{"introduction": "This first practice grounds your understanding by asking you to build a Probability Generating Function (PGF) from its fundamental definition. For a simple discrete distribution, you will translate the probabilities of each outcome into the polynomial form of the PGF, solidifying the link between a probability mass function and its generating function before we use them for calculations. [@problem_id:1409525]", "problem": "A simple electronic device models a random process where it can occupy one of four discrete energy states, labeled by the integers 1, 2, 3, and 4. At any given moment, the device is equally likely to be in any one of these four states. Let the random variable $X$ denote the energy state of the device observed at a random instant.\n\nDetermine the Probability Generating Function (PGF), $G_X(z)$, for the random variable $X$, and also determine the variance of $X$, denoted $\\text{Var}(X)$.\n\nYour final answer should be a composite expression containing the polynomial for $G_X(z)$ followed by the value of $\\text{Var}(X)$. The variance must be expressed as an exact fraction.", "solution": "The random variable $X$ takes values in the set $\\{1,2,3,4\\}$ with equal probability for each state. Therefore, for $k \\in \\{1,2,3,4\\}$, we have $P(X=k)=\\frac{1}{4}$.\n\nBy definition, the probability generating function (PGF) of $X$ is\n$$\nG_{X}(z)=\\mathbb{E}[z^{X}]=\\sum_{k=0}^{\\infty}P(X=k)z^{k}.\n$$\nSince $X$ takes values only in $\\{1,2,3,4\\}$, this reduces to\n$$\nG_{X}(z)=\\sum_{k=1}^{4}P(X=k)z^{k}=\\frac{1}{4}\\left(z+z^{2}+z^{3}+z^{4}\\right).\n$$\n\nTo compute the variance, we use $\\text{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}$.\nFirst compute the mean:\n$$\n\\mathbb{E}[X]=\\sum_{k=1}^{4}k\\cdot P(X=k)=\\frac{1}{4}\\sum_{k=1}^{4}k=\\frac{1}{4}\\cdot\\frac{4\\cdot 5}{2}=\\frac{10}{4}=\\frac{5}{2}.\n$$\nNext compute the second moment:\n$$\n\\mathbb{E}[X^{2}]=\\sum_{k=1}^{4}k^{2}\\cdot P(X=k)=\\frac{1}{4}\\sum_{k=1}^{4}k^{2}=\\frac{1}{4}\\cdot\\frac{4\\cdot 5\\cdot 9}{6}=\\frac{30}{4}=\\frac{15}{2}.\n$$\nTherefore,\n$$\n\\mathrm{Var}(X)=\\mathbb{E}[X^{2}]-(\\mathbb{E}[X])^{2}=\\frac{15}{2}-\\left(\\frac{5}{2}\\right)^{2}=\\frac{30}{4}-\\frac{25}{4}=\\frac{5}{4}.\n$$\nThus the PGF and variance are as stated.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{1}{4}\\left(z+z^{2}+z^{3}+z^{4}\\right) & \\frac{5}{4}\\end{pmatrix}}$$", "id": "1409525"}, {"introduction": "With the ability to construct a PGF, the next step is to use it. This exercise focuses on the core technique for finding moments: differentiation. You will apply the fundamental theorem $\\mathbb{E}[X] = G'_X(1)$ to a given PGF, practicing the mechanics of differentiation and evaluation that make this method a powerful and efficient shortcut for calculating expected values. [@problem_id:1409497]", "problem": "A team of computer scientists is analyzing the behavior of a specialized recursive algorithm designed to search for a solution within a vast, structured state space. The algorithm explores the space in discrete steps. At each step, it either finds a valid solution and terminates, or it continues to the next step. The process is stochastic, meaning there is a certain probability of success at each step, independent of the previous steps.\n\nLet the random variable $X$ represent the total number of steps the algorithm takes until it finds a solution and terminates. A theoretical analysis of the algorithm's performance yields its Probability Generating Function (PGF), $G_X(s)$, which is given by the expression:\n\n$$G_X(s) = \\frac{s}{4 - 3s}$$\n\nCalculate the expected number of steps, $E[X]$, that the algorithm will take to find a solution.", "solution": "For a nonnegative integer-valued random variable $X$ with probability generating function $G_{X}(s) = \\mathbb{E}[s^{X}]$, the expectation is given by the derivative at $s=1$:\n$$\n\\mathbb{E}[X] = G_{X}'(1).\n$$\nGiven $G_{X}(s) = \\frac{s}{4 - 3s}$, differentiate using the quotient rule. Let $f(s) = s$ and $g(s) = 4 - 3s$, so $f'(s) = 1$ and $g'(s) = -3$. Then\n$$\nG_{X}'(s) = \\frac{f'(s)g(s) - f(s)g'(s)}{g(s)^{2}} = \\frac{(1)(4 - 3s) - s(-3)}{(4 - 3s)^{2}} = \\frac{4 - 3s + 3s}{(4 - 3s)^{2}} = \\frac{4}{(4 - 3s)^{2}}.\n$$\nEvaluating at $s=1$,\n$$\n\\mathbb{E}[X] = G_{X}'(1) = \\frac{4}{(4 - 3)^{2}} = 4.\n$$\nAs a consistency check, rewrite the PGF as $G_{X}(s) = \\frac{1}{4}\\frac{s}{1 - \\frac{3}{4}s}$, which is the PGF of a geometric distribution on $\\{1,2,\\dots\\}$ with success probability $p = \\frac{1}{4}$, yielding $\\mathbb{E}[X] = \\frac{1}{p} = 4$, in agreement with the derivative method.", "answer": "$$\\boxed{4}$$", "id": "1409497"}, {"introduction": "This final problem reveals the true analytical power of PGFs in a scenario where the function itself is not explicitly known. You will be presented with a recursive relationship characteristic of branching processes and challenged to find the expected value by differentiating the entire functional equation. This practice demonstrates that we can extract key properties like the mean of a distribution even when solving for the PGF directly is difficult or unnecessary. [@problem_id:1409566]", "problem": "A simplified model for a signal cascade within a specialized detector is described as follows. A single primary particle enters the detector. Two mutually exclusive events can occur:\n1.  With a probability $p$, the particle is directly absorbed, generating a fixed number $k$ of detectable signals.\n2.  With a probability $1-p$, the particle fissions into two identical daughter particles. Each of these daughter particles then independently initiates a new cascade process, behaving exactly like the original primary particle.\n\nLet $X$ be the random variable representing the total number of detectable signals generated from a single initial primary particle. The system is designed such that the probability $p$ satisfies $1/2 < p < 1$, and $k$ is a positive integer. This ensures that the cascade process does not, on average, grow indefinitely.\n\nDetermine the expected value of $X$, denoted $E[X]$, in terms of $p$ and $k$.", "solution": "Let $G_X(s)$ be the Probability Generating Function (PGF) for the random variable $X$, which is defined as $G_X(s) = E[s^X]$. We can construct a functional equation for $G_X(s)$ by conditioning on the first event in the cascade.\n\nAccording to the problem description, there are two possibilities for the initial particle:\n1.  With probability $p$, the process terminates and generates $k$ signals. The random variable is a constant $k$. The PGF for this outcome is $s^k$.\n2.  With probability $1-p$, the particle fissions into two daughter particles. Each daughter particle generates a total number of signals, let's say $X_1$ and $X_2$. The total number of signals in this case is $X = X_1 + X_2$. Since each daughter particle behaves identically and independently to the original primary particle, $X_1$ and $X_2$ are independent and identically distributed random variables, with the same distribution as $X$. The PGF of a sum of independent random variables is the product of their individual PGFs. Therefore, the PGF for this outcome is $G_{X_1}(s)G_{X_2}(s) = G_X(s)G_X(s) = (G_X(s))^2$.\n\nUsing the law of total expectation (or by the properties of mixture distributions), the overall PGF for $X$ is the weighted average of the PGFs for each case:\n$$G_X(s) = p \\cdot s^k + (1-p) \\cdot (G_X(s))^2$$\n\nThe problem asks for the expected value of $X$, which can be found from the PGF using the relation $E[X] = G_X'(1)$. We do not need to solve the functional equation for $G_X(s)$ explicitly. Instead, we can differentiate the entire equation with respect to $s$. Using the product rule and chain rule for differentiation, we get:\n$$G_X'(s) = \\frac{d}{ds} \\left( p s^k + (1-p) (G_X(s))^2 \\right)$$\n$$G_X'(s) = p k s^{k-1} + (1-p) \\cdot 2 G_X(s) G_X'(s)$$\n\nNow, we evaluate this differentiated equation at $s=1$. We use two fundamental properties of any PGF:\n1.  $G_X(1) = \\sum_{n=0}^{\\infty} P(X=n) (1)^n = \\sum P(X=n) = 1$.\n2.  $G_X'(1) = E[X]$. Let's denote $E[X]$ by $\\mu$.\n\nSubstituting $s=1$, $G_X(1)=1$, and $G_X'(1)=\\mu$ into the differentiated equation:\n$$G_X'(1) = p k (1)^{k-1} + (1-p) \\cdot 2 G_X(1) G_X'(1)$$\n$$\\mu = p k + (1-p) \\cdot 2 \\cdot (1) \\cdot \\mu$$\n$$\\mu = pk + 2(1-p)\\mu$$\n\nNow, we solve this linear equation for $\\mu$:\n$$\\mu - 2(1-p)\\mu = pk$$\n$$\\mu(1 - 2 + 2p) = pk$$\n$$\\mu(2p - 1) = pk$$\n\nSince the problem states that $1/2  p  1$, we have $2p - 1 > 0$, so we can divide by $(2p-1)$ to find a unique, positive, and finite mean.\n$$\\mu = \\frac{pk}{2p-1}$$\n\nThis expression gives the expected total number of signals generated from a single initial particle.", "answer": "$$\\boxed{\\frac{pk}{2p-1}}$$", "id": "1409566"}]}