{"hands_on_practices": [{"introduction": "This first practice is a foundational exercise designed to build your core computational skills with Moment Generating Functions (MGFs). You will learn how to extract key statistical moments, such as the mean and variance, directly from an MGF by using differentiation. This hands-on problem involves calculating the variance for two distinct random variables based on their MGFs and then applying the property of variance for a sum of independent variables, a common scenario in statistical modeling. [@problem_id:1376258]", "problem": "In a simplified model of a digital communication channel, data is transmitted in packets of two types, Type A and Type B. Let the random variable $X$ represent the number of bit errors found in a randomly selected packet of Type A, and let $Y$ be the number of bit errors in a randomly selected packet of Type B. The statistical properties of these errors are captured by their Moment Generating Functions (MGFs), which are given as follows:\n\nThe MGF of $X$ is $M_X(t) = 0.1 + 0.2e^t + 0.4e^{2t} + 0.3e^{3t}$.\nThe MGF of $Y$ is $M_Y(t) = 0.6e^{2t} + 0.4e^{4t}$.\n\nAssume that the number of errors in a Type A packet is statistically independent of the number of errors in a Type B packet. A single transmission session consists of sending exactly one packet of Type A and one packet of Type B.\n\nCalculate the variance of the total number of bit errors in a single transmission session.", "solution": "Let $S=X+Y$ be the total number of bit errors in one session. By independence, $\\operatorname{Var}(S)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)$. From MGFs, for any random variable $Z$ with MGF $M_{Z}(t)$, we use $M_{Z}'(0)=\\mathbb{E}[Z]$ and $M_{Z}''(0)=\\mathbb{E}[Z^{2}]$, hence $\\operatorname{Var}(Z)=M_{Z}''(0)-\\left(M_{Z}'(0)\\right)^{2}$ since $M_{Z}(0)=1$.\n\nFor $X$ with $M_{X}(t)=0.1+0.2\\exp(t)+0.4\\exp(2t)+0.3\\exp(3t)$,\n$$\nM_{X}'(t)=0.2\\exp(t)+0.8\\exp(2t)+0.9\\exp(3t),\\quad M_{X}'(0)=0.2+0.8+0.9=1.9,\n$$\n$$\nM_{X}''(t)=0.2\\exp(t)+1.6\\exp(2t)+2.7\\exp(3t),\\quad M_{X}''(0)=0.2+1.6+2.7=4.5.\n$$\nTherefore,\n$$\n\\operatorname{Var}(X)=4.5-(1.9)^{2}=4.5-3.61=0.89.\n$$\n\nFor $Y$ with $M_{Y}(t)=0.6\\exp(2t)+0.4\\exp(4t)$,\n$$\nM_{Y}'(t)=1.2\\exp(2t)+1.6\\exp(4t),\\quad M_{Y}'(0)=1.2+1.6=2.8,\n$$\n$$\nM_{Y}''(t)=2.4\\exp(2t)+6.4\\exp(4t),\\quad M_{Y}''(0)=2.4+6.4=8.8.\n$$\nTherefore,\n$$\n\\operatorname{Var}(Y)=8.8-(2.8)^{2}=8.8-7.84=0.96.\n$$\n\nBy independence,\n$$\n\\operatorname{Var}(S)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)=0.89+0.96=1.85.\n$$", "answer": "$$\\boxed{1.85}$$", "id": "1376258"}, {"introduction": "Building on the direct computation of moments, this exercise introduces the crucial skill of pattern recognition. The form of a Moment Generating Function often acts as a unique signature, allowing us to identify the underlying probability distribution. Here, you'll work with an MGF characteristic of the normal distribution and explore how variance is affected by a linear transformation of the random variable, a fundamental property in all of statistics. [@problem_id:1937144]", "problem": "Let $Y$ be a continuous random variable. The statistical properties of $Y$ are fully described by its Moment Generating Function (MGF), which is given by the expression:\n$$M_Y(t) = \\exp(3t + 8t^2)$$\nwhere $t$ is a real variable for which the function is defined.\n\nConsider a new random variable $X$ that is defined as a linear transformation of $Y$:\n$$X = 5 - 2Y$$\nCalculate the variance of the random variable $X$.", "solution": "We are given the moment generating function of $Y$ as $M_{Y}(t)=\\exp(3t+8t^{2})$. By definition of the MGF, the first and second moments of $Y$ are obtained from derivatives at $t=0$:\n- $\\mathbb{E}[Y]=M_{Y}'(0)$,\n- $\\mathbb{E}[Y^{2}]=M_{Y}''(0)$,\nand the variance is $\\operatorname{Var}(Y)=M_{Y}''(0)-\\left(M_{Y}'(0)\\right)^{2}$.\n\nDifferentiate $M_{Y}(t)$ using the chain rule. Let $g(t)=\\exp(3t+8t^{2})$. Then\n$$\nM_{Y}'(t)=\\frac{d}{dt}\\exp(3t+8t^{2})=(3+16t)\\exp(3t+8t^{2})=(3+16t)g(t).\n$$\nEvaluating at $t=0$ gives\n$$\nM_{Y}'(0)=(3+0)\\exp(0)=3,\n$$\nso $\\mathbb{E}[Y]=3$.\n\nFor the second derivative, use the product rule with $f(t)=3+16t$ and $g(t)=\\exp(3t+8t^{2})$:\n$$\nM_{Y}''(t)=f'(t)g(t)+f(t)g'(t).\n$$\nWe have $f'(t)=16$ and $g'(t)=(3+16t)g(t)$ by the chain rule, hence\n$$\nM_{Y}''(t)=16\\,g(t)+(3+16t)(3+16t)\\,g(t)=\\left(16+(3+16t)^{2}\\right)\\exp(3t+8t^{2}).\n$$\nEvaluating at $t=0$ yields\n$$\nM_{Y}''(0)=\\left(16+3^{2}\\right)\\exp(0)=25,\n$$\nso $\\mathbb{E}[Y^{2}]=25$. Therefore,\n$$\n\\operatorname{Var}(Y)=\\mathbb{E}[Y^{2}]-\\left(\\mathbb{E}[Y]\\right)^{2}=25-3^{2}=16.\n$$\n\nNow consider $X=5-2Y$. For a linear transformation $X=a+bY$, the variance satisfies $\\operatorname{Var}(X)=b^{2}\\operatorname{Var}(Y)$. Here $b=-2$, so\n$$\n\\operatorname{Var}(X)=(-2)^{2}\\operatorname{Var}(Y)=4\\cdot 16=64.\n$$", "answer": "$$\\boxed{64}$$", "id": "1937144"}, {"introduction": "Our final practice demonstrates the deeper analytical power of MGFs, moving beyond moment calculation to structural analysis. In this thought experiment, you will work in reverse: starting with a given MGF, you will use an algebraic technique—partial fraction decomposition—to deconstruct it into simpler components. This process reveals that the original random variable can be elegantly described as a probabilistic mixture of two simpler distributions, showcasing how MGFs provide powerful insights into the composition of complex random phenomena. [@problem_id:1937156]", "problem": "Let a random variable $X$ have the moment generating function (MGF) $M_X(t) = (1 - \\beta^2 t^2)^{-1}$ for a positive constant $\\beta$ and for all $t$ in a neighborhood of zero where the MGF is defined. It is known that $X$ can be described as a probabilistic mixture of two simpler random variables. Specifically, the MGF of $X$ can be written in the form $M_X(t) = p \\cdot M_{W_1}(t) + (1-p) \\cdot M_{W_2}(t)$, where $p$ is the mixing probability ($0  p  1$), and $M_{W_1}(t)$ and $M_{W_2}(t)$ are the MGFs for an exponential random variable and its negative, respectively. Let the exponential random variable, $W_1$, have a rate parameter $\\lambda  0$. The other variable is then $W_2 = -W_1$.\n\nDetermine the value of the mixing probability $p$ and the rate parameter $\\lambda$ in terms of $\\beta$. Present your answer as a pair $(p, \\lambda)$.", "solution": "The problem requires us to find the parameters of a mixture distribution that result in a given moment generating function (MGF).\n\nFirst, let's establish the MGFs for the component random variables, $W_1$ and $W_2$.\nThe random variable $W_1$ follows an Exponential distribution with rate $\\lambda$. The MGF of an exponential random variable with rate $\\lambda$ is given by:\n$$M_{W_1}(t) = \\mathbb{E}[\\exp(tW_1)] = \\frac{\\lambda}{\\lambda - t} = \\frac{1}{1 - t/\\lambda}$$\nThis MGF is defined for $t  \\lambda$.\n\nThe random variable $W_2$ is the negative of $W_1$, so $W_2 = -W_1$. Its MGF can be found from the MGF of $W_1$:\n$$M_{W_2}(t) = \\mathbb{E}[\\exp(tW_2)] = \\mathbb{E}[\\exp(t(-W_1))] = \\mathbb{E}[\\exp((-t)W_1)] = M_{W_1}(-t)$$\nSubstituting $-t$ into the expression for $M_{W_1}(t)$, we get:\n$$M_{W_2}(t) = \\frac{1}{1 - (-t)/\\lambda} = \\frac{1}{1 + t/\\lambda}$$\nThis MGF is defined for $t > -\\lambda$.\n\nThe problem states that $X$ is a mixture of $W_1$ and $W_2$ with mixing probability $p$. The MGF of such a mixture is the weighted sum of the individual MGFs:\n$$M_X(t) = p \\cdot M_{W_1}(t) + (1-p) \\cdot M_{W_2}(t)$$\nSubstituting the expressions for the MGFs of $W_1$ and $W_2$:\n$$M_X(t) = \\frac{p}{1 - t/\\lambda} + \\frac{1-p}{1 + t/\\lambda}$$\n\nNext, we analyze the given MGF for $X$, $M_X(t) = (1 - \\beta^2 t^2)^{-1}$. To compare this with the mixture form, we need to express it as a sum of simpler fractions. This is achieved through partial fraction decomposition.\nFirst, factor the denominator:\n$$M_X(t) = \\frac{1}{1 - \\beta^2 t^2} = \\frac{1}{(1 - \\beta t)(1 + \\beta t)}$$\nWe seek to find constants $A$ and $B$ such that:\n$$\\frac{1}{(1 - \\beta t)(1 + \\beta t)} = \\frac{A}{1 - \\beta t} + \\frac{B}{1 + \\beta t}$$\nTo find $A$ and $B$, we combine the terms on the right-hand side and equate the numerators:\n$$1 = A(1 + \\beta t) + B(1 - \\beta t)$$\nThis equation must hold for all values of $t$. We can solve for $A$ and $B$ by substituting convenient values for $t$.\nLet $t = 1/\\beta$:\n$$1 = A(1 + \\beta(1/\\beta)) + B(1 - \\beta(1/\\beta)) = A(1+1) + B(0) = 2A$$\nThis gives $A = 1/2$.\n\nLet $t = -1/\\beta$:\n$$1 = A(1 + \\beta(-1/\\beta)) + B(1 - \\beta(-1/\\beta)) = A(0) + B(1+1) = 2B$$\nThis gives $B = 1/2$.\n\nSo, the partial fraction decomposition of $M_X(t)$ is:\n$$M_X(t) = \\frac{1/2}{1 - \\beta t} + \\frac{1/2}{1 + \\beta t}$$\n\nFinally, we equate the two expressions for $M_X(t)$:\n$$\\frac{p}{1 - t/\\lambda} + \\frac{1-p}{1 + t/\\lambda} = \\frac{1/2}{1 - \\beta t} + \\frac{1/2}{1 + \\beta t}$$\nBy comparing the terms, we can identify the unknown parameters. The uniqueness of the partial fraction decomposition allows for a direct term-by-term comparison.\nComparing the first term on each side:\n$$\\frac{p}{1 - t/\\lambda} = \\frac{1/2}{1 - \\beta t}$$\nFor the denominators to be equal for all $t$, we must have $t/\\lambda = \\beta t$, which implies $\\lambda = 1/\\beta$.\nFor the numerators to be equal, we must have $p = 1/2$.\n\nComparing the second term on each side provides a consistency check:\n$$\\frac{1-p}{1 + t/\\lambda} = \\frac{1/2}{1 + \\beta t}$$\nAgain, the denominators imply $\\lambda = 1/\\beta$. The numerators imply $1-p = 1/2$, which also gives $p = 1/2$.\nBoth comparisons yield the same results.\n\nThus, the mixing probability is $p=1/2$, and the rate parameter of the exponential distribution is $\\lambda = 1/\\beta$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2}  \\frac{1}{\\beta} \\end{pmatrix}}$$", "id": "1937156"}]}