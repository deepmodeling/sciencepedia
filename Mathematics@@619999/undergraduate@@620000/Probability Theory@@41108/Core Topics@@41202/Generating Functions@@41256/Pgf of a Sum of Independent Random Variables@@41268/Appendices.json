{"hands_on_practices": [{"introduction": "A foundational application of Probability Generating Functions (PGFs) is modeling systems where independent processes combine. This first practice explores a classic scenario from digital communications: a signal corrupted by additive noise [@problem_id:1379454]. By finding the PGF of the sum of a signal (a Geometric random variable) and noise (a Bernoulli random variable), you will directly apply the central theorem that the PGF of a sum of independent random variables is the product of their individual PGFs.", "problem": "In a simplified model of a digital communication system, a signal's amplitude $S$ is represented by a non-negative integer. The random variable $S$ follows a geometric distribution with a success probability parameter $p \\in (0, 1)$. The probability mass function is given by $P(S=k) = p(1-p)^k$ for $k = 0, 1, 2, \\dots$.\n\nDuring transmission, the signal is corrupted by an independent additive noise source, represented by a random variable $N$. The noise follows a Bernoulli distribution with parameter $q \\in (0, 1)$, where $P(N=1) = q$ and $P(N=0) = 1-q$.\n\nThe observed signal at the receiver is $O = S + N$. The signal $S$ and the noise $N$ are statistically independent. The Probability Generating Function (PGF) of a discrete random variable $X$ with support on the non-negative integers is defined as $G_X(s) = E[s^X]$, where $s$ is a real-valued dummy variable.\n\nDetermine the PGF of the observed signal $O$. Express your answer as a function of $s$, $p$, and $q$.", "solution": "We are given $S$ and $N$ independent, with $S$ geometric on $\\{0,1,2,\\dots\\}$ with $P(S=k)=p(1-p)^{k}$ and $N$ Bernoulli with $P(N=1)=q$, $P(N=0)=1-q$. The observed signal is $O=S+N$. The probability generating function (PGF) of a nonnegative integer-valued random variable $X$ is defined as $G_{X}(s)=E[s^{X}]$.\n\nWe first use the property that for independent nonnegative integer-valued random variables $X$ and $Y$, the PGF of the sum satisfies\n$$\nG_{X+Y}(s)=E[s^{X+Y}]=E[s^{X}s^{Y}]=E[s^{X}]\\,E[s^{Y}]=G_{X}(s)G_{Y}(s).\n$$\nApplying this to $O=S+N$ with independence,\n$$\nG_{O}(s)=G_{S}(s)\\,G_{N}(s).\n$$\n\nWe compute $G_{S}(s)$:\n$$\nG_{S}(s)=E[s^{S}]=\\sum_{k=0}^{\\infty}s^{k}P(S=k)=\\sum_{k=0}^{\\infty}s^{k}p(1-p)^{k}\n=p\\sum_{k=0}^{\\infty}\\left((1-p)s\\right)^{k}.\n$$\nUsing the geometric series sum $\\sum_{k=0}^{\\infty}r^{k}=\\frac{1}{1-r}$ for $|r|<1$, we obtain\n$$\nG_{S}(s)=\\frac{p}{1-(1-p)s}.\n$$\n\nWe compute $G_{N}(s)$:\n$$\nG_{N}(s)=E[s^{N}]=s^{0}P(N=0)+s^{1}P(N=1)=(1-q)+qs.\n$$\n\nMultiplying,\n$$\nG_{O}(s)=G_{S}(s)G_{N}(s)=\\frac{p}{1-(1-p)s}\\left((1-q)+qs\\right).\n$$\nThis expression gives the PGF of $O$ as a function of $s$, $p$, and $q$.", "answer": "$$\\boxed{\\frac{p\\left((1-q)+qs\\right)}{1-(1-p)s}}$$", "id": "1379454"}, {"introduction": "Building on the basic principle, we can extend the use of PGFs to more complex combinations of random variables, such as linear combinations. This exercise [@problem_id:1379453] presents a scoring system where one component is weighted, resulting in a total score of $S = 2X+Y$. To solve this, you will need to utilize a more general property of PGFs, specifically how to find the PGF of a scaled random variable, $G_{aX}(s) = G_X(s^a)$, demonstrating the flexibility of this powerful tool.", "problem": "A computational model for a scoring system generates a total score $S$ in a two-stage procedure.\n\nIn the first stage, a primary value, represented by the random variable $X$, is generated by selecting an integer uniformly at random from the set $\\{1, 2, 3, 4, 5, 6\\}$.\n\nIn the second stage, an independent bonus value, represented by the random variable $Y$, is determined. This bonus is governed by a separate event which succeeds with a probability of $p_B = \\frac{1}{3}$. If the event succeeds, the bonus value is $Y=5$. If the event fails, the bonus value is $Y=0$.\n\nThe total score $S$ is calculated by doubling the primary value and then adding the bonus value, such that $S = 2X + Y$.\n\nDetermine the Probability Generating Function (PGF) of the total score $S$, denoted as $G_S(z)$. Express your answer as a single polynomial expression in terms of the variable $z$.", "solution": "We need the probability generating function (PGF) of $S=2X+Y$, where $X$ is uniform on $\\{1,2,3,4,5,6\\}$ and $Y$ is independent with $\\mathbb{P}(Y=0)=\\frac{2}{3}$ and $\\mathbb{P}(Y=5)=\\frac{1}{3}$. By definition, $G_{S}(z)=\\mathbb{E}[z^{S}]$. Using independence and the linear form of $S$, we have\n$$\nG_{S}(z)=\\mathbb{E}\\left[z^{2X+Y}\\right]=\\mathbb{E}\\left[z^{2X}\\right]\\mathbb{E}\\left[z^{Y}\\right].\n$$\nCompute each factor separately. Since $X$ is uniform on $\\{1,2,3,4,5,6\\}$,\n$$\n\\mathbb{E}\\left[z^{2X}\\right]=\\sum_{k=1}^{6}\\mathbb{P}(X=k)z^{2k}=\\frac{1}{6}\\sum_{k=1}^{6}z^{2k}=\\frac{1}{6}\\left(z^{2}+z^{4}+z^{6}+z^{8}+z^{10}+z^{12}\\right).\n$$\nFor $Y$,\n$$\n\\mathbb{E}\\left[z^{Y}\\right]=\\frac{2}{3}z^{0}+\\frac{1}{3}z^{5}=\\frac{2}{3}+\\frac{1}{3}z^{5}.\n$$\nTherefore,\n$$\nG_{S}(z)=\\left(\\frac{1}{6}\\left(z^{2}+z^{4}+z^{6}+z^{8}+z^{10}+z^{12}\\right)\\right)\\left(\\frac{2}{3}+\\frac{1}{3}z^{5}\\right).\n$$\nExpanding gives\n$$\nG_{S}(z)=\\frac{1}{9}\\left(z^{2}+z^{4}+z^{6}+z^{8}+z^{10}+z^{12}\\right)+\\frac{1}{18}\\left(z^{7}+z^{9}+z^{11}+z^{13}+z^{15}+z^{17}\\right),\n$$\nwhich is equivalently the single polynomial\n$$\nG_{S}(z)=\\frac{1}{9}z^{2}+\\frac{1}{9}z^{4}+\\frac{1}{9}z^{6}+\\frac{1}{9}z^{8}+\\frac{1}{9}z^{10}+\\frac{1}{9}z^{12}+\\frac{1}{18}z^{7}+\\frac{1}{18}z^{9}+\\frac{1}{18}z^{11}+\\frac{1}{18}z^{13}+\\frac{1}{18}z^{15}+\\frac{1}{18}z^{17}.\n$$\nAs a check, $G_{S}(1)=1$.", "answer": "$$\\boxed{\\frac{1}{9}z^{2}+\\frac{1}{9}z^{4}+\\frac{1}{9}z^{6}+\\frac{1}{9}z^{8}+\\frac{1}{9}z^{10}+\\frac{1}{9}z^{12}+\\frac{1}{18}z^{7}+\\frac{1}{18}z^{9}+\\frac{1}{18}z^{11}+\\frac{1}{18}z^{13}+\\frac{1}{18}z^{15}+\\frac{1}{18}z^{17}}$$", "id": "1379453"}, {"introduction": "The true test of understanding a mathematical tool often comes from using it in reverse. This problem [@problem_id:1382722] challenges you to work backwards: given the PGF for a total count, you must decompose it to identify the distributions of the underlying independent processes. This practice of factoring a PGF enhances your analytical skills and deepens your understanding of how the structure of a PGF directly reflects the probability distribution it represents.", "problem": "In the study of cascade reactions in a particle detector, the total number of secondary particles produced, denoted by the random variable $Z$, is modeled as the sum of particles originating from two independent and distinct internal processes. Let $X_1$ and $X_2$ be the number of particles produced by the first and second processes, respectively, such that $Z = X_1 + X_2$. Both $X_1$ and $X_2$ are non-constant random variables (i.e., their variance is strictly positive).\n\nAfter extensive experimentation, the Probability Generating Function (PGF) for the total number of particles $Z$ was found to be:\n$$G_Z(s) = (0.2 + 0.8s^2)(0.5 + 0.5s)^2$$\n\nBased on this PGF, which of the following statements correctly describes the probability distributions of $X_1$ and $X_2$?\n\nA. $X_1$ follows a Binomial distribution with parameters $n=2, p=0.8$, and $X_2$ follows a Binomial distribution with parameters $n=2, p=0.5$.\n\nB. $X_1$ is a discrete random variable with probability mass function $P(X_1=0)=0.2, P(X_1=2)=0.8$, and $X_2$ follows a Binomial distribution with parameters $n=2, p=0.5$.\n\nC. $X_1$ is a discrete random variable with probability mass function $P(X_1=0)=0.2, P(X_1=1)=0.8$, and $X_2$ follows a Binomial distribution with parameters $n=2, p=0.5$.\n\nD. $X_1$ follows a Bernoulli distribution with parameter $p=0.8$, and $X_2$ follows a Poisson distribution with mean $\\lambda=1$.\n\nE. The total count $Z$ cannot be decomposed into the sum of two independent non-constant random variables as described.", "solution": "By definition, the probability generating function (PGF) of the sum of two independent integer-valued random variables equals the product of their PGFs. Thus, if $Z=X_{1}+X_{2}$ with $X_{1}$ and $X_{2}$ independent, then\n$$\nG_{Z}(s)=G_{X_{1}}(s)\\,G_{X_{2}}(s).\n$$\nWe are given\n$$\nG_{Z}(s)=(0.2+0.8s^{2})(0.5+0.5s)^{2}.\n$$\nA valid factorization into PGFs is\n$$\nG_{X_{1}}(s)=0.2+0.8s^{2},\\qquad G_{X_{2}}(s)=(0.5+0.5s)^{2}.\n$$\nEach factor is a valid PGF: the coefficients are nonnegative and sum to $1$, and neither factor is constant (hence both $X_{1}$ and $X_{2}$ are non-constant).\n\nInterpretation of $G_{X_{1}}(s)=0.2+0.8s^{2}$: this is the PGF of a discrete variable supported on $\\{0,2\\}$ with\n$$\n\\mathbb{P}(X_{1}=0)=0.2,\\qquad \\mathbb{P}(X_{1}=2)=0.8.\n$$\n\nInterpretation of $G_{X_{2}}(s)=(0.5+0.5s)^{2}$: recalling that the PGF of a binomial $X\\sim\\mathrm{Bin}(n,p)$ is $(q+ps)^{n}$ with $q=1-p$, we identify\n$$\nG_{X_{2}}(s)=(0.5+0.5s)^{2}=(q+ps)^{2}\\ \\text{with}\\ p=0.5,\\ n=2,\n$$\nso $X_{2}\\sim\\mathrm{Bin}(2,0.5)$.\n\nTherefore, the correct description is: $X_{1}$ has $\\mathbb{P}(X_{1}=0)=0.2$, $\\mathbb{P}(X_{1}=2)=0.8$, and $X_{2}\\sim\\mathrm{Bin}(2,0.5)$.\n\nChecking the options:\n- A is incorrect because it would imply $G_{X_{1}}(s)=(0.2+0.8s)^{2}$, not $0.2+0.8s^{2}$.\n- C is incorrect because $G_{X_{1}}(s)$ would be $0.2+0.8s$, not $0.2+0.8s^{2}$.\n- D is incorrect because multiplying a Bernoulli and a Poisson PGF would not yield the given polynomial PGF.\n- E is false because we have exhibited a valid decomposition into two independent non-constant variables.\n\nHence the correct choice is B.", "answer": "$$\\boxed{B}$$", "id": "1382722"}]}