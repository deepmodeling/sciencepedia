{"hands_on_practices": [{"introduction": "This first practice provides a foundational exercise in using Moment Generating Functions (MGFs). You will be given the explicit MGF for a random variable modeling noise in a communication channel. Your task is to apply the core technique of finding moments: differentiating the MGF and evaluating the derivatives at $t=0$ to calculate the variance. This problem solidifies the fundamental mechanics of how an MGF generates moments. [@problem_id:1409242]", "problem": "In a simplified model for noise in a digital communication channel, a random variable $N$ representing the noise signal is characterized by its moment generating function (MGF). The MGF of $N$ is given by the expression:\n$$ M_N(t) = \\exp(\\mu t) \\cosh(\\sigma t) $$\nHere, $\\mu$ represents a constant DC bias in the signal, and $\\sigma$ represents the amplitude of the noise fluctuations. For a particular measurement, the parameters are determined to be $\\mu = -5$ and $\\sigma = 7$.\nCalculate the variance of the noise, $\\text{Var}(N)$.", "solution": "The variance can be obtained from the moment generating function $M_{N}(t)$ using the identities $E[N]=M_{N}'(0)$ and $\\text{Var}(N)=M_{N}''(0)-\\left(M_{N}'(0)\\right)^{2}$. Given $M_{N}(t)=\\exp(\\mu t)\\cosh(\\sigma t)$, differentiate:\n$$\nM_{N}'(t)=\\frac{d}{dt}\\left(\\exp(\\mu t)\\cosh(\\sigma t)\\right)=\\exp(\\mu t)\\left(\\mu \\cosh(\\sigma t)+\\sigma \\sinh(\\sigma t)\\right).\n$$\nDifferentiate again:\n$$\nM_{N}''(t)=\\exp(\\mu t)\\left[\\mu\\left(\\mu \\cosh(\\sigma t)+\\sigma \\sinh(\\sigma t)\\right)+\\left(\\mu \\sigma \\sinh(\\sigma t)+\\sigma^{2}\\cosh(\\sigma t)\\right)\\right],\n$$\nwhich simplifies to\n$$\nM_{N}''(t)=\\exp(\\mu t)\\left((\\mu^{2}+\\sigma^{2})\\cosh(\\sigma t)+2\\mu \\sigma \\sinh(\\sigma t)\\right).\n$$\nEvaluate at $t=0$ using $\\exp(0)=1$, $\\cosh(0)=1$, and $\\sinh(0)=0$:\n$$\nM_{N}'(0)=\\mu,\\qquad M_{N}''(0)=\\mu^{2}+\\sigma^{2}.\n$$\nTherefore,\n$$\n\\text{Var}(N)=M_{N}''(0)-\\left(M_{N}'(0)\\right)^{2}=(\\mu^{2}+\\sigma^{2})-\\mu^{2}=\\sigma^{2}.\n$$\nWith $\\mu=-5$ and $\\sigma=7$, this gives\n$$\n\\text{Var}(N)=7^{2}=49.\n$$", "answer": "$$\\boxed{49}$$", "id": "1409242"}, {"introduction": "Now, let's explore the connection between moments and MGFs from a reverse perspective. Instead of starting with the MGF, you are provided with a formula for all the raw moments of a random variable. This exercise challenges you to reconstruct the MGF by leveraging its Maclaurin series expansion, whose coefficients are directly related to the moments. This practice deepens the understanding that an MGF is a compact representation that \"encodes\" the entire moment sequence of a distribution. [@problem_id:1409256]", "problem": "A continuous random variable $X$ has its raw moments about the origin, $E[X^k]$, described by the formula $E[X^k] = (k+1)! 2^k$ for all non-negative integers $k=0, 1, 2, \\dots$. The Moment Generating Function (MGF) of a random variable, denoted $M_X(t)$, is formally defined by the expectation $M_X(t) = E[\\exp(tX)]$, provided this expectation exists for $t$ in some open interval containing zero. For a random variable whose moments are all finite, the MGF can be represented by its Maclaurin series expansion. Your task is to determine the variance of the random variable $X$.", "solution": "The Moment Generating Function (MGF) of a random variable $X$, $M_X(t)$, can be expressed as a Maclaurin series where the coefficients are related to the raw moments $E[X^k]$. The general form of this expansion is:\n$$M_X(t) = \\sum_{k=0}^{\\infty} \\frac{E[X^k]}{k!} t^k$$\nWe are given that the raw moments of $X$ are $E[X^k] = (k+1)! 2^k$. Substituting this expression into the series for the MGF, we get:\n$$M_X(t) = \\sum_{k=0}^{\\infty} \\frac{(k+1)! 2^k}{k!} t^k$$\nWe can simplify the term inside the summation:\n$$\\frac{(k+1)!}{k!} = \\frac{(k+1) \\cdot k!}{k!} = k+1$$\nThus, the MGF becomes:\n$$M_X(t) = \\sum_{k=0}^{\\infty} (k+1) 2^k t^k = \\sum_{k=0}^{\\infty} (k+1) (2t)^k$$\nTo find a closed-form expression for this series, let $u = 2t$. The series is $S(u) = \\sum_{k=0}^{\\infty} (k+1) u^k$.\nWe recognize this series as being related to the geometric series. Recall the formula for a geometric series:\n$$G(u) = \\sum_{k=0}^{\\infty} u^k = \\frac{1}{1-u}, \\quad \\text{for } |u| < 1$$\nDifferentiating both sides with respect to $u$ gives:\n$$\\frac{d}{du} G(u) = \\frac{d}{du} \\sum_{k=0}^{\\infty} u^k = \\sum_{k=1}^{\\infty} k u^{k-1} = \\frac{1}{(1-u)^2}$$\nOur series $\\sum_{k=0}^{\\infty} (k+1) u^k$ is exactly the derivative of the geometric series if we shift the index. A more direct approach is to recognize that $\\sum_{k=0}^{\\infty} (k+1) u^k = \\frac{d}{du} \\sum_{k=0}^{\\infty} u^{k+1} = \\frac{d}{du} \\left( \\frac{u}{1-u} \\right)$.\nUsing the quotient rule for differentiation on the right side:\n$$\\frac{d}{du} \\left( \\frac{u}{1-u} \\right) = \\frac{(1)(1-u) - (u)(-1)}{(1-u)^2} = \\frac{1-u+u}{(1-u)^2} = \\frac{1}{(1-u)^2}$$\nSo, we have found the closed form for our series $S(u) = \\frac{1}{(1-u)^2}$.\nSubstituting back $u = 2t$, we obtain the closed-form expression for the MGF of $X$:\n$$M_X(t) = \\frac{1}{(1-2t)^2}$$\nThis MGF is valid for $|2t| < 1$, or $|t| < 1/2$.\n\nThe variance of $X$ is given by the formula $\\text{Var}(X) = E[X^2] - (E[X])^2$. The moments can be found by differentiating the MGF and evaluating at $t=0$. Specifically, $E[X^n] = M_X^{(n)}(0)$, where $M_X^{(n)}(t)$ is the $n$-th derivative of $M_X(t)$.\n\nFirst, we find the first moment (the mean), $E[X]$:\n$E[X] = M_X^{(1)}(0)$.\nLet's find the first derivative of $M_X(t) = (1-2t)^{-2}$:\n$$M_X^{(1)}(t) = \\frac{d}{dt} (1-2t)^{-2} = -2(1-2t)^{-3} \\cdot (-2) = 4(1-2t)^{-3}$$\nEvaluating at $t=0$:\n$$E[X] = M_X^{(1)}(0) = 4(1-0)^{-3} = 4$$\n\nNext, we find the second moment, $E[X^2]$:\n$E[X^2] = M_X^{(2)}(0)$.\nLet's find the second derivative of $M_X(t)$ by differentiating $M_X^{(1)}(t)$:\n$$M_X^{(2)}(t) = \\frac{d}{dt} \\left( 4(1-2t)^{-3} \\right) = 4(-3)(1-2t)^{-4} \\cdot (-2) = 24(1-2t)^{-4}$$\nEvaluating at $t=0$:\n$$E[X^2] = M_X^{(2)}(0) = 24(1-0)^{-4} = 24$$\n\nFinally, we can calculate the variance:\n$$\\text{Var}(X) = E[X^2] - (E[X])^2 = 24 - (4)^2 = 24 - 16 = 8$$", "answer": "$$\\boxed{8}$$", "id": "1409256"}, {"introduction": "Our final practice demonstrates the abstract power of the MGF framework. Here, you won't have the explicit formula for the MGF. Instead, you are given a differential equation that the MGF is known to satisfy. This fascinating problem illustrates that you can extract key properties, like the variance, by manipulating the given equation and using the fundamental properties of MGFs and their derivatives at the origin. It's a testament to how MGFs can facilitate problem-solving even with incomplete information. [@problem_id:1409269]", "problem": "Let $X$ be a random variable whose Moment Generating Function (MGF), denoted by $M_X(t) = E[\\exp(tX)]$, is known to exist for all values of $t$ in an open interval containing the origin. Suppose that for all $t$ in this interval, the MGF satisfies the following first-order ordinary differential equation:\n$$(1-2t)\\frac{d}{dt}M_X(t) = 3 M_X(t)$$\nWithout solving for the explicit functional form of $M_X(t)$ or identifying the distribution of $X$, calculate the variance of the random variable $X$.", "solution": "Let $M(t) \\equiv M_{X}(t) = E[\\exp(tX)]$. Since $M$ is an MGF, $M(0)=1$, $M'(0)=E[X]$, and $M''(0)=E[X^{2}]$. The given differential equation is\n$$(1-2t)M'(t)=3M(t).$$\nEvaluate at $t=0$:\n$$(1-0)M'(0)=3M(0) \\implies M'(0)=3(1)=3.$$\nSo, $E[X]=3$.\n\nDifferentiate both sides of the original equation with respect to $t$ using the product rule on the left side:\n$$\\frac{d}{dt}[(1-2t)M'(t)] = \\frac{d}{dt}[3M(t)]$$\n$$(-2)M'(t)+(1-2t)M''(t)=3M'(t).$$\nRearrange to solve for $M''(t)$:\n$$(1-2t)M''(t)=5M'(t).$$\nEvaluate at $t=0$:\n$$(1-0)M''(0)=5M'(0) \\implies M''(0)=5(3)=15.$$\nSo, $E[X^{2}]=15$.\n\nTherefore, the variance is\n$$\\operatorname{Var}(X)=E[X^{2}]-(E[X])^{2}=15-3^{2}=15-9=6.$$", "answer": "$$\\boxed{6}$$", "id": "1409269"}]}