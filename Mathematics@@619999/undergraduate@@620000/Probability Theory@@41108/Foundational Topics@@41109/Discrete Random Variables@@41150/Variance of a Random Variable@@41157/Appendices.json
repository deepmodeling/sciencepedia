{"hands_on_practices": [{"introduction": "Understanding a new mathematical concept like variance begins with mastering its direct calculation. This first exercise provides a foundational workout, focusing on a simple discrete random variable. By working through the steps to find the variance from a given probability mass function, you will practice normalizing a distribution, calculating the expected value $E[X]$ and the second moment $E[X^2]$, and applying the core computational formula for variance, $\\text{Var}(X) = E[X^2] - (E[X])^2$ [@problem_id:1409820].", "problem": "A discrete random variable $X$ can take only the integer values $1$, $2$, and $3$. Its probability mass function (PMF) is defined as $p(k) = P(X=k) = c \\cdot k^2$ for $k \\in \\{1, 2, 3\\}$, where $c$ is a normalization constant. Calculate the variance, $\\text{Var}(X)$, of this random variable. Your final answer should be an exact fraction in simplest form.", "solution": "We have a discrete random variable $X$ taking values in $\\{1,2,3\\}$ with probability mass function $p(k)=c k^{2}$. The normalization condition is $\\sum_{k=1}^{3} p(k)=1$, hence\n$$\n\\sum_{k=1}^{3} c k^{2} = c \\sum_{k=1}^{3} k^{2} = 1 \\quad \\Rightarrow \\quad c = \\frac{1}{\\sum_{k=1}^{3} k^{2}} = \\frac{1}{1+4+9} = \\frac{1}{14}.\n$$\nFor a discrete random variable, $E[g(X)] = \\sum_{k} g(k) p(k)$. Therefore,\n$$\nE[X] = \\sum_{k=1}^{3} k \\, p(k) = \\sum_{k=1}^{3} k \\left(c k^{2}\\right) = c \\sum_{k=1}^{3} k^{3} = \\frac{1}{14} \\left(1+8+27\\right) = \\frac{36}{14} = \\frac{18}{7},\n$$\nand\n$$\nE[X^{2}] = \\sum_{k=1}^{3} k^{2} \\, p(k) = \\sum_{k=1}^{3} k^{2} \\left(c k^{2}\\right) = c \\sum_{k=1}^{3} k^{4} = \\frac{1}{14} \\left(1+16+81\\right) = \\frac{98}{14} = 7.\n$$\nUsing the variance formula $\\text{Var}(X) = E[X^{2}] - \\left(E[X]\\right)^{2}$, we get\n$$\n\\text{Var}(X) = 7 - \\left(\\frac{18}{7}\\right)^{2} = 7 - \\frac{324}{49} = \\frac{343 - 324}{49} = \\frac{19}{49}.\n$$", "answer": "$$\\boxed{\\frac{19}{49}}$$", "id": "1409820"}, {"introduction": "Having addressed the discrete case, we now extend the concept of variance to continuous random variables. The fundamental principle remains unchanged, but our mathematical toolkit shifts from summation to integration. This problem uses the scenario of a particle detector to illustrate how to calculate variance from a probability density function, reinforcing your understanding of how to compute expected values in a continuous context [@problem_id:1409779].", "problem": "A one-dimensional particle detector, with a length of 1 meter, is placed along the x-axis from $x=0$ to $x=1$. A subatomic particle is fired towards the detector, and its position of impact, represented by the random variable $X$, is recorded. Due to the detector's specific physical properties, the probability of the particle being detected at a certain position is not uniform. The probability density function (PDF) for the particle's position $X$ is found to be directly proportional to its distance from the origin. This relationship is modeled by the function $f(x) = C x$ for $x \\in [0, 1]$, and $f(x) = 0$ otherwise, where $C$ is a normalization constant.\n\nYour task is to calculate the variance of the particle's detected position, $\\text{Var}(X)$. Express your final answer for the variance as a fraction, in units of meters squared ($\\text{m}^2$).", "solution": "The probability density function is $f(x)=C x$ on $[0,1]$ and $0$ otherwise. To normalize, require $\\int_{0}^{1} f(x)\\,dx=1$:\n$$\n\\int_{0}^{1} C x\\,dx = C \\int_{0}^{1} x\\,dx = C \\left[\\frac{x^{2}}{2}\\right]_{0}^{1} = \\frac{C}{2} = 1 \\quad \\Rightarrow \\quad C=2.\n$$\nThus $f(x)=2x$ on $[0,1]$. Compute the mean:\n$$\n\\mathbb{E}[X] = \\int_{0}^{1} x f(x)\\,dx = \\int_{0}^{1} 2 x^{2}\\,dx = 2 \\left[\\frac{x^{3}}{3}\\right]_{0}^{1} = \\frac{2}{3}.\n$$\nCompute the second moment:\n$$\n\\mathbb{E}[X^{2}] = \\int_{0}^{1} x^{2} f(x)\\,dx = \\int_{0}^{1} 2 x^{3}\\,dx = 2 \\left[\\frac{x^{4}}{4}\\right]_{0}^{1} = \\frac{1}{2}.\n$$\nTherefore, the variance is\n$$\n\\operatorname{Var}(X) = \\mathbb{E}[X^{2}] - \\left(\\mathbb{E}[X]\\right)^{2} = \\frac{1}{2} - \\left(\\frac{2}{3}\\right)^{2} = \\frac{1}{2} - \\frac{4}{9} = \\frac{1}{18}.\n$$\nSince $X$ is measured in meters, the variance has units of meters squared; the numerical value is $\\frac{1}{18}$.", "answer": "$$\\boxed{\\frac{1}{18}}$$", "id": "1409779"}, {"introduction": "Beyond mere calculation, a deep understanding of variance involves grasping its conceptual meaning as a measure of uncertainty or unpredictability. This final practice moves from \"how\" to \"why\" by asking you to find the conditions that maximize the variance of a simple binary event. By solving this, you will discover a fundamental principle about randomness and solidify your intuition for what variance truly represents in information theory and other fields [@problem_id:1667143].", "problem": "In information theory, a fundamental building block is a binary source, which emits one of two possible symbols, conventionally denoted by '0' and '1'. Let the output of such a source be represented by a random variable $X$. The probability that the source emits a '1' is given by a parameter $p$, and consequently, the probability of emitting a '0' is $1-p$. A random variable following this probability distribution is known as a Bernoulli random variable.\n\nThe variance of a random variable, denoted $\\text{Var}(X)$, quantifies the spread of its values around the mean. It serves as a measure of the randomness or unpredictability of the source output. For the binary source described, the variance is a function of the probability parameter $p$.\n\nYour task is to determine the specific numerical value of the probability $p$, where $p$ is in the range $[0, 1]$, that maximizes the variance of the output variable $X$.", "solution": "Let $X$ be the Bernoulli random variable representing the output of the binary source. The probability mass function of $X$ is given by:\n$P(X=1) = p$\n$P(X=0) = 1-p$\n\nThe variance of any random variable $X$ is defined as $\\text{Var}(X) = E[X^2] - (E[X])^2$, where $E[\\cdot]$ denotes the expected value. We first need to calculate the expected value of $X$ and the expected value of $X^2$.\n\nThe expected value of $X$ is calculated as the sum of each possible value multiplied by its probability:\n$$E[X] = (1) \\cdot P(X=1) + (0) \\cdot P(X=0)$$\n$$E[X] = (1)(p) + (0)(1-p) = p$$\n\nNext, we calculate the expected value of $X^2$.\n$$E[X^2] = (1^2) \\cdot P(X=1) + (0^2) \\cdot P(X=0)$$\n$$E[X^2] = (1)(p) + (0)(1-p) = p$$\nAlternatively, one could note that for a Bernoulli random variable, the only possible values for $X$ are 0 and 1. In both cases, $X^2 = X$. Therefore, $E[X^2] = E[X] = p$.\n\nNow, we can substitute these results into the formula for the variance:\n$$\\text{Var}(X) = E[X^2] - (E[X])^2 = p - p^2$$\n\nTo find the value of $p$ that maximizes the variance, we need to find the maximum of the function $V(p) = p - p^2$ on the interval $[0, 1]$. We can use calculus to solve this optimization problem. First, we find the derivative of $V(p)$ with respect to $p$:\n$$\\frac{dV}{dp} = \\frac{d}{dp}(p - p^2) = 1 - 2p$$\n\nTo find the critical points, we set the derivative equal to zero:\n$$1 - 2p = 0$$\n$$2p = 1$$\n$$p = \\frac{1}{2}$$\n\nTo determine if this critical point corresponds to a maximum, we can use the second derivative test. The second derivative of $V(p)$ is:\n$$\\frac{d^2V}{dp^2} = \\frac{d}{dp}(1 - 2p) = -2$$\n\nSince the second derivative is negative ($-2 < 0$), the function $V(p)$ is concave down everywhere, which means the critical point we found at $p = 1/2$ is a global maximum. The values at the endpoints of the interval are $V(0) = 0 - 0^2 = 0$ and $V(1) = 1 - 1^2 = 0$. The value at our critical point is $V(1/2) = 1/2 - (1/2)^2 = 1/2 - 1/4 = 1/4$, which is greater than the endpoint values.\n\nThus, the variance of the Bernoulli random variable is maximized when the probability $p$ is $1/2$. This corresponds to the case of maximum uncertainty, where the outcomes '0' and '1' are equally likely.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1667143"}]}