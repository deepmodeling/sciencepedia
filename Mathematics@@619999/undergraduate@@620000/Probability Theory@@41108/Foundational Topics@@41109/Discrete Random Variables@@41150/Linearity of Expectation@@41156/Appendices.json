{"hands_on_practices": [{"introduction": "Let's begin with a practical problem from computer science. Hashing is a fundamental technique for storing and retrieving data efficiently, but what happens when two different pieces of data are assigned to the same location? This exercise uses linearity of expectation and indicator variables to quantify the expected number of these \"collisions,\" a crucial metric for analyzing the performance of hash-based data structures.", "problem": "A university's computer science department is tasked with archiving student projects. There are $m$ distinct student projects to be stored on a set of $n$ available servers. The system administrator employs a simple distribution scheme: each of the $m$ projects is assigned to exactly one of the $n$ servers, with the choice of server for each project being made independently and uniformly at random from the set of available servers.\n\nA \"collision\" is defined as an event where a pair of two distinct projects are assigned to the same server. Determine the expected total number of such colliding pairs. Provide your answer as a closed-form analytic expression in terms of $m$ and $n$.", "solution": "Let $X$ be the random variable representing the total number of colliding pairs of projects. Our goal is to find the expected value of $X$, denoted as $E[X]$.\n\nA direct calculation of the probability distribution of $X$ is complex. A more effective method is to use linearity of expectation. We can express $X$ as a sum of simpler random variables.\n\nFirst, let's identify all possible pairs of projects. Since there are $m$ projects, the total number of distinct pairs of projects is given by the binomial coefficient $\\binom{m}{2}$. Let the projects be indexed from $1$ to $m$. A generic pair of projects can be denoted as $(i, j)$, where $1 \\le i < j \\le m$.\n\nFor each such pair $(i, j)$, we define an indicator random variable, $X_{ij}$, as follows:\n$$\nX_{ij} =\n\\begin{cases}\n1 & \\text{if project } i \\text{ and project } j \\text{ are assigned to the same server} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$$\nThe total number of collisions, $X$, is the sum of these indicator variables over all unique pairs of projects:\n$$\nX = \\sum_{1 \\le i < j \\le m} X_{ij}\n$$\nBy the linearity of expectation, the expected total number of collisions is the sum of the expected values of these individual indicator variables:\n$$\nE[X] = E\\left[\\sum_{1 \\le i < j \\le m} X_{ij}\\right] = \\sum_{1 \\le i < j \\le m} E[X_{ij}]\n$$\nThe expectation of an indicator random variable is equal to the probability of the event it indicates. Therefore, for any pair $(i, j)$:\n$$\nE[X_{ij}] = P(X_{ij} = 1)\n$$\n$P(X_{ij} = 1)$ is the probability that project $i$ and project $j$ are assigned to the same server. Let's calculate this probability.\n\nProject $i$ can be assigned to any of the $n$ servers. Let's say it is assigned to server $k$. Since the assignments are independent and uniform, the probability of project $j$ being assigned to that same server $k$ is $\\frac{1}{n}$. This holds regardless of which server project $i$ was assigned to.\n\nAlternatively, we can consider the total sample space of assignments for the pair $(i, j)$. There are $n$ choices for project $i$ and $n$ choices for project $j$, so there are $n \\times n = n^2$ possible outcomes in the sample space, each equally likely. A collision occurs if both projects are assigned to server 1, or both to server 2, ..., or both to server $n$. There are $n$ such favorable outcomes. Thus, the probability of a collision for the pair $(i, j)$ is:\n$$\nP(X_{ij} = 1) = \\frac{\\text{Number of favorable outcomes}}{\\text{Total number of outcomes}} = \\frac{n}{n^2} = \\frac{1}{n}\n$$\nSo, the expectation of each indicator variable is $E[X_{ij}] = \\frac{1}{n}$.\n\nNow we can substitute this back into the sum for $E[X]$. The sum is taken over all unique pairs of projects. The number of such pairs is:\n$$\n\\binom{m}{2} = \\frac{m(m-1)}{2}\n$$\nTherefore, the expected total number of collisions is:\n$$\nE[X] = \\sum_{1 \\le i < j \\le m} \\frac{1}{n} = \\left(\\text{Number of pairs}\\right) \\times \\frac{1}{n} = \\binom{m}{2} \\cdot \\frac{1}{n}\n$$\nSubstituting the expression for the binomial coefficient, we get:\n$$\nE[X] = \\frac{m(m-1)}{2} \\cdot \\frac{1}{n} = \\frac{m(m-1)}{2n}\n$$\nThis is the final expression for the expected number of colliding pairs.", "answer": "$$\\boxed{\\frac{m(m-1)}{2n}}$$", "id": "1381865"}, {"introduction": "Now, let's explore an application in finance, where we model asset price fluctuations. This problem moves beyond simply counting events and asks for the expected squared deviation, $E[S_N^2]$, a measure related to volatility. You'll see how linearity of expectation helps dissect the expression $E[(\\sum X_i)^2]$ by handling cross-product terms, highlighting the powerful role that independence plays in simplifying such calculations.", "problem": "A simplified stochastic model is proposed to describe the daily price fluctuations of a particular financial asset. Let $S_N$ be the total log-return of the asset over a period of $N$ consecutive trading days. This total log-return is the sum of the daily log-returns, $X_k$, for each day $k=1, 2, \\dots, N$. That is, $S_N = \\sum_{k=1}^{N} X_k$.\n\nThe daily log-returns, $X_k$, are modeled as independent and identically distributed random variables. For any given day, the log-return $X_k$ can take one of three values according to the following probability distribution:\n-   $X_k = +\\alpha$ with probability $p$.\n-   $X_k = -\\alpha$ with probability $p$.\n-   $X_k = 0$ with probability $1-2p$.\n\nHere, $\\alpha$ is a positive constant representing the magnitude of a significant price movement, and $p$ is the probability of such a movement occurring, with $0 < p \\le 1/2$. A key measure of the overall volatility of the asset over the $N$-day period is the expected value of the squared total log-return, $E[S_N^2]$.\n\nFind an analytic expression for $E[S_N^2]$ in terms of the parameters $N$, $p$, and $\\alpha$.", "solution": "We are asked to compute the expected value of the squared total log-return, $E[S_N^2]$, where $S_N = \\sum_{k=1}^{N} X_k$.\n\nWe begin by writing out the square of the sum:\n$$S_N^2 = \\left(\\sum_{i=1}^{N} X_i\\right)^2 = \\left(\\sum_{i=1}^{N} X_i\\right)\\left(\\sum_{j=1}^{N} X_j\\right) = \\sum_{i=1}^{N} \\sum_{j=1}^{N} X_i X_j$$\nTaking the expectation of this expression, and using the linearity of expectation, we can move the expectation operator inside the summations:\n$$E[S_N^2] = E\\left[\\sum_{i=1}^{N} \\sum_{j=1}^{N} X_i X_j\\right] = \\sum_{i=1}^{N} \\sum_{j=1}^{N} E[X_i X_j]$$\nWe can split the double summation into two parts: the terms where the indices are equal ($i=j$) and the terms where they are different ($i \\neq j$).\n$$E[S_N^2] = \\sum_{i=1}^{N} E[X_i^2] + \\sum_{i=1}^{N} \\sum_{j=1, j\\neq i}^{N} E[X_i X_j]$$\nTo proceed, we need to calculate the first and second moments of the daily log-return, $X_k$. Since the $X_k$ are identically distributed, we can drop the subscript $k$ for this calculation. Let $X$ be a random variable representing a single day's log-return.\n\nThe expected value (first moment) of $X$ is:\n$$E[X] = (+\\alpha) \\cdot P(X = \\alpha) + (-\\alpha) \\cdot P(X = -\\alpha) + (0) \\cdot P(X = 0)$$\n$$E[X] = \\alpha \\cdot p - \\alpha \\cdot p + 0 \\cdot (1-2p) = 0$$\nThe expected value of the square of $X$ (second moment) is:\n$$E[X^2] = (+\\alpha)^2 \\cdot P(X = \\alpha) + (-\\alpha)^2 \\cdot P(X = -\\alpha) + (0)^2 \\cdot P(X = 0)$$\n$$E[X^2] = \\alpha^2 \\cdot p + \\alpha^2 \\cdot p + 0 \\cdot (1-2p) = 2p\\alpha^2$$\nNow we can evaluate the two parts of our expansion for $E[S_N^2]$.\n\nFor the terms where $i \\neq j$, the daily log-returns $X_i$ and $X_j$ are independent random variables. Therefore, the expectation of their product is the product of their expectations:\n$$E[X_i X_j] = E[X_i]E[X_j]$$\nUsing our result for the first moment, we get:\n$$E[X_i X_j] = 0 \\cdot 0 = 0$$\nThis means that every term in the second sum, $\\sum_{i=1}^{N} \\sum_{j=1, j\\neq i}^{N} E[X_i X_j]$, is zero. So, this entire sum evaluates to zero.\n\nFor the terms where $i = j$, we have $E[X_i^2]$. Since the variables are identically distributed, $E[X_i^2] = E[X^2] = 2p\\alpha^2$ for all $i$. The first sum becomes:\n$$\\sum_{i=1}^{N} E[X_i^2] = \\sum_{i=1}^{N} 2p\\alpha^2$$\nSince $2p\\alpha^2$ is a constant with respect to the summation index $i$, we are simply adding this constant to itself $N$ times:\n$$\\sum_{i=1}^{N} 2p\\alpha^2 = N(2p\\alpha^2)$$\nCombining the results for the two parts of the summation, we get the final answer:\n$$E[S_N^2] = N(2p\\alpha^2) + 0 = 2Np\\alpha^2$$", "answer": "$$\\boxed{2Np\\alpha^{2}}$$", "id": "1371032"}, {"introduction": "Our final practice demonstrates the creative power of combining probabilistic tools with knowledge from other fields. We will analyze the fragmentation of a communication network modeled as a tree, where individual links can fail randomly. The solution beautifully merges linearity of expectation with a fundamental identity from graph theory, leading to a surprisingly simple and elegant result that holds for any tree structure.", "problem": "A newly deployed constellation of $n$ satellites is designed for deep-space communication. The network topology connecting the satellites is a tree, ensuring that there is a unique communication path between any two satellites and that the number of active links is minimized.\n\nDuring a period of intense solar activity, each active communication link is subject to potential failure. It has been determined that each link fails independently of the others with a constant probability $p$, where $0 < p < 1$. When a link fails, it is permanently removed from the network. The failure of links may cause the network to fragment into several disconnected clusters. A cluster is defined as a maximal set of satellites that can still communicate with each other, either directly or indirectly.\n\nAssuming the initial network is an arbitrary tree with $n$ vertices (satellites), determine the expected number of disconnected clusters after the solar event. Express your answer as a single closed-form analytic expression in terms of $n$ and $p$.", "solution": "Let the initial satellite network be modeled as a tree $T = (V, E)$, where $V$ is the set of $n$ satellites (vertices) and $E$ is the set of $n-1$ communication links (edges). After the solar event, some edges are deleted, resulting in a new graph $G' = (V, E')$, where $E' \\subseteq E$. Since the original graph $T$ is a tree, it contains no cycles. The new graph $G'$, being a subgraph of $T$, also contains no cycles. A graph with no cycles is a forest.\n\nA fundamental property of any forest is the relationship between its number of vertices, edges, and connected components. For any forest with $V_{\\text{forest}}$ vertices, $E_{\\text{forest}}$ edges, and $C_{\\text{forest}}$ connected components, the identity $C_{\\text{forest}} = V_{\\text{forest}} - E_{\\text{forest}}$ holds.\n\nIn our problem, the resulting graph $G'$ is a forest. The number of vertices in $G'$ is fixed at $|V| = n$. The number of edges, $|E'|$, is a random variable, as is the number of clusters (connected components), which we denote by the random variable $C$. Applying the forest identity to $G'$, we get the relation:\n$$C = n - |E'|$$\nOur goal is to find the expected number of clusters, $E[C]$. Using the relation above and the property of linearity of expectation, we have:\n$$E[C] = E[n - |E'|] = E[n] - E[|E'|]$$\nSince $n$ is a constant, its expectation is $n$. The problem thus reduces to finding the expected number of edges in the resulting graph, $E[|E'|]$.\n$$E[C] = n - E[|E'|]$$\nTo find $E[|E'|]$, we can define indicator random variables. The initial tree has $|E| = n-1$ edges. Let's label them $e_1, e_2, \\ldots, e_{n-1}$. For each edge $e_i \\in E$, let $X_i$ be an indicator variable such that:\n$$X_i = \\begin{cases} 1 & \\text{if edge } e_i \\text{ survives (does not fail)} \\\\ 0 & \\text{if edge } e_i \\text{ fails} \\end{cases}$$\nThe problem states that each link fails with probability $p$. Therefore, the probability that a link survives is $1-p$.\nThe expectation of the indicator variable $X_i$ is given by:\n$$E[X_i] = 1 \\cdot P(X_i=1) + 0 \\cdot P(X_i=0) = P(X_i=1) = 1-p$$\nThe total number of edges in the final graph $G'$ is the sum of these indicator variables over all initial edges:\n$$|E'| = \\sum_{i=1}^{n-1} X_i$$\nWe can now find the expected value of $|E'|$ by again using the linearity of expectation:\n$$E[|E'|] = E\\left[\\sum_{i=1}^{n-1} X_i\\right] = \\sum_{i=1}^{n-1} E[X_i]$$\nSince the expectation of each $X_i$ is $1-p$, and there are $n-1$ edges in the initial tree, we have:\n$$E[|E'|] = \\sum_{i=1}^{n-1} (1-p) = (n-1)(1-p)$$\nFinally, we substitute this result back into our expression for $E[C]$:\n$$E[C] = n - E[|E'|] = n - (n-1)(1-p)$$\nExpanding and simplifying the expression gives the final answer:\n$$E[C] = n - (n - np - 1 + p) = n - n + np + 1 - p = 1 + p(n-1)$$\nThis result is notably independent of the specific structure of the initial tree, depending only on the number of satellites $n$ and the failure probability $p$.", "answer": "$$\\boxed{1 + (n-1)p}$$", "id": "1381828"}]}