{"hands_on_practices": [{"introduction": "This first practice problem takes us back to the fundamental definition of expected value. Using a simplified model from quantum mechanics, we are given the average outcome of an experiment and must work backward to find the underlying probabilities of the system's states [@problem_id:1361824]. This exercise not only reinforces that expected value is a weighted average but also sharpens your algebraic skills in applying this core concept in reverse.", "problem": "A physicist is investigating a simplified model of a two-level quantum system. When a measurement is performed, the system collapses into one of two distinct energy states: the ground state, which has an energy of $E_0$, or the excited state, which has an energy of $E_1$. For a particular preparation of the system, the probability of it collapsing to the ground state upon measurement is $p$, and consequently, the probability of it collapsing to the excited state is $1-p$.\n\nThrough a large number of repeated experiments on identically prepared systems, the physicist determines that the average measured energy of the system is $\\langle E \\rangle$.\n\nGiven that the energy levels are $E_0 = -1.2 \\text{ eV}$ and $E_1 = 3.8 \\text{ eV}$, and the experimentally determined average energy is $\\langle E \\rangle = 2.5 \\text{ eV}$, determine the value of the probability $p$. Express your answer as a decimal.", "solution": "For a two-level system with outcomes $E_{0}$ and $E_{1}$ occurring with probabilities $p$ and $1-p$, respectively, the expectation value of the measured energy is given by the discrete expectation formula:\n$$\n\\langle E \\rangle = p E_{0} + (1 - p) E_{1}.\n$$\nSubstituting the given values $E_{0} = -1.2$, $E_{1} = 3.8$, and $\\langle E \\rangle = 2.5$ (all in electronvolts) into the expectation equation gives\n$\n2.5 = p(-1.2) + (1 - p) 3.8.\n$\nExpanding and collecting like terms,\n$$\n2.5 = -1.2 p + 3.8 - 3.8 p = 3.8 - 5.0 p.\n$$\nSolving for $p$,\n$$\n5.0 p = 3.8 - 2.5 = 1.3 \\quad \\Rightarrow \\quad p = \\frac{1.3}{5.0} = 0.26.\n$$\nTherefore, the probability of collapsing to the ground state is $p = 0.26$.", "answer": "$$\\boxed{0.26}$$", "id": "1361824"}, {"introduction": "Building on the basics, we now explore one of the most powerful properties of expectation: its linearity. This problem uses a scenario from digital imaging to demonstrate how the relationship $E[aX + b] = aE[X] + b$ allows us to efficiently find the expectation of a transformed variable [@problem_id:1361825]. Mastering this property is crucial as it dramatically simplifies calculations in many complex probability models, bypassing the need to derive the full probability distribution of the new variable.", "problem": "In the field of digital imaging, a single pixel in a scientific-grade Charge-Coupled Device (CCD) is being analyzed for noise. During a standardized exposure time in a thermally controlled environment, the number of spurious \"dark current\" electrons, denoted by the random variable $X$, that are generated is found to follow a Poisson distribution with a mean of $\\lambda$. A quality score, $Y$, is assigned to the pixel's performance for this exposure. The score starts at a maximum value of 10 points, and 2 points are deducted for each dark current electron detected. Determine the expected value of the quality score, $E[Y]$, for a single exposure. Express your answer as a closed-form analytic expression in terms of $\\lambda$.", "solution": "The problem asks for the expected value of the quality score, $Y$. We are given the relationship between the quality score $Y$ and the number of dark current electrons $X$. The score starts at 10 and decreases by 2 for each electron. This can be expressed as a linear transformation of the random variable $X$:\n$$Y = 10 - 2X$$\n\nWe are told that the number of dark current electrons, $X$, follows a Poisson distribution with a mean of $\\lambda$. A key property of the Poisson distribution is that its expected value is equal to its mean parameter. Therefore, the expected value of $X$ is:\n$$E[X] = \\lambda$$\n\nTo find the expected value of $Y$, we use the linearity of expectation. For any random variable $X$ and constants $a$ and $b$, the expectation of a linear transformation $aX+b$ is given by:\n$$E[aX + b] = aE[X] + b$$\n\nIn our problem, we can identify the constants $a = -2$ and $b = 10$ from the expression for $Y$:\n$$Y = (-2)X + 10$$\n\nApplying the property of linearity of expectation to $Y$:\n$$E[Y] = E[-2X + 10]$$\n$$E[Y] = -2E[X] + E[10]$$\n\nThe expectation of a constant is the constant itself, so $E[10] = 10$. We can now substitute the known values for $E[X]$ and $E[10]$ into the equation:\n$$E[Y] = -2(\\lambda) + 10$$\n\nRearranging the terms gives the final expression for the expected quality score:\n$$E[Y] = 10 - 2\\lambda$$", "answer": "$$\\boxed{10 - 2\\lambda}$$", "id": "1361825"}, {"introduction": "Our final challenge introduces an elegant and powerful alternative for calculating the expectation of non-negative integer-valued random variables: the tail-sum formula. This problem presents a scenario where the probability of an event count being *at least* a certain value, $P(X \\ge k)$, is known, making the standard definition of expectation cumbersome to apply [@problem_id:1361787]. You will see how the formula $E[X] = \\sum_{k=1}^{\\infty} P(X \\ge k)$ provides a more direct path to the solution, beautifully connecting probability theory with a famous result from the study of infinite series.", "problem": "A discrete random variable $X$ represents the number of failures before the first success in a sequence of experimental trials. The variable $X$ can take any non-negative integer value, i.e., $X \\in \\{0, 1, 2, \\dots\\}$. Due to an unusual long-range correlation between trials, the probability that at least $k$ failures occur before the first success (which is equivalent to the event $X \\ge k$) is given by the relation:\n$$\nP(X \\ge k) = \\frac{1}{(k+1)^2}\n$$\nfor any integer $k \\ge 0$.\n\nCalculate the expected number of failures before the first success, $E[X]$. Express your answer as a closed-form analytic expression. You may assume as a known result the solution to the Basel problem, $\\sum_{n=1}^{\\infty} \\frac{1}{n^2} = \\frac{\\pi^2}{6}$.", "solution": "We use the tail-sum formula for a nonnegative integer-valued random variable. Starting from the definition,\n$$\nE[X] = \\sum_{k=0}^{\\infty} k\\,P(X=k).\n$$\nWrite $k$ as a sum of $1$’s: $k = \\sum_{j=1}^{k} 1$. Substituting,\n$$\nE[X] = \\sum_{k=0}^{\\infty} \\left(\\sum_{j=1}^{k} 1\\right) P(X=k) = \\sum_{k=0}^{\\infty} \\sum_{j=1}^{k} P(X=k).\n$$\nSince all terms are nonnegative, we interchange the order of summation (Tonelli’s theorem) to obtain\n$$\nE[X] = \\sum_{j=1}^{\\infty} \\sum_{k=j}^{\\infty} P(X=k) = \\sum_{j=1}^{\\infty} P(X \\ge j).\n$$\nGiven $P(X \\ge k) = \\frac{1}{(k+1)^{2}}$ for all integers $k \\ge 0$, we have\n$$\nE[X] = \\sum_{j=1}^{\\infty} \\frac{1}{(j+1)^{2}} = \\sum_{n=2}^{\\infty} \\frac{1}{n^{2}} = \\sum_{n=1}^{\\infty} \\frac{1}{n^{2}} - 1.\n$$\nUsing the Basel result $\\sum_{n=1}^{\\infty} \\frac{1}{n^{2}} = \\frac{\\pi^{2}}{6}$, we conclude\n$$\nE[X] = \\frac{\\pi^{2}}{6} - 1.\n$$\nThis series converges since $\\sum_{n=1}^{\\infty} \\frac{1}{n^{2}}$ is finite, so the expectation is well-defined.", "answer": "$$\\boxed{\\frac{\\pi^{2}}{6}-1}$$", "id": "1361787"}]}