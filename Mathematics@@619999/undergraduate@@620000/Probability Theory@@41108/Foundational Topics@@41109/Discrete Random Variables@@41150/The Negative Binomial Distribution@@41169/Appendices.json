{"hands_on_practices": [{"introduction": "The negative binomial distribution is fundamentally about counting trials until a specific number of successes are achieved. Before we can use it for complex modeling, we must first understand how to calculate the probability of a single outcome. This foundational exercise ([@problem_id:12863]) guides you through deriving the probability mass function for a specific scenario, reinforcing the combinatorial logic that underpins the distribution's formula.", "problem": "Consider a sequence of independent Bernoulli trials, where each trial can result in one of two outcomes: 'success' or 'failure'. The probability of a success in any given trial is constant and denoted by $p$, while the probability of a failure is $1-p$.\n\nLet the random variable $X$ be the trial number on which the $r$-th success occurs. In this problem, we are interested in the specific case where we want to find the probability that the 3rd success occurs on the 10th trial.\n\nDerive the expression for the probability $P(X=10)$ for $r=3$ successes. Your final answer should be a closed-form expression in terms of the success probability $p$.", "solution": "We model the number of trials $X$ required to obtain $r$ successes in independent Bernoulli trials with success probability $p$ by the negative‐binomial distribution.  The probability that the $r$‐th success occurs on the $n$‐th trial is\n$$\nP(X=n)\\;=\\;\\binom{n-1}{r-1}\\,p^r\\,(1-p)^{\\,n-r}\\,.\n$$\nFor $r=3$ and $n=10$, this gives\n$$\nP(X=10)\n=\\binom{10-1}{3-1}\\,p^3\\,(1-p)^{10-3}\n=\\binom{9}{2}\\,p^3\\,(1-p)^7.\n$$\nSince \n$$\n\\binom{9}{2}=\\frac{9\\cdot8}{2}=36,\n$$\nwe obtain\n$$\nP(X=10)=36\\,p^3\\,(1-p)^7.\n$$", "answer": "$$\\boxed{36\\,p^3\\,(1-p)^7}$$", "id": "12863"}, {"introduction": "Beyond calculating single probabilities, it's crucial to understand a distribution's overall shape and behavior, which are summarized by its mean and variance. This practice ([@problem_id:1373790]) shifts our focus to these descriptive statistics. By calculating the standard deviation for a waiting-time process in a hypothetical machine learning context, you'll gain a practical grasp of how to quantify the expected variability in a negative binomial experiment.", "problem": "A team of data scientists is evaluating the performance of a new machine learning model designed to predict user churn. The model is tested sequentially on a stream of user data. Each test on a single user's data is an independent trial. A \"critical failure\" is recorded if the model incorrectly predicts a non-churning user will churn, an event that occurs with a constant probability $p = 0.15$. To adequately assess the model's worst-case performance, the testing protocol requires that the process continues until exactly $r=60$ critical failures have been observed.\n\nCalculate the standard deviation of the total number of users that must be tested to complete this protocol. Round your final answer to four significant figures.", "solution": "Let $N$ denote the total number of users tested until exactly $r=60$ critical failures are observed. Each user test is an independent Bernoulli trial with probability of a critical failure $p=0.15$. The number of trials needed to obtain $r$ such events follows a negative binomial distribution with parameters $(r,p)$, counting the total number of trials to achieve $r$ successes (here, critical failures).\n\nFor $N \\sim \\text{NegBin}(r,p)$ (trials to $r$ successes with success probability $p$), the mean and variance are\n$$\n\\mathbb{E}[N] = \\frac{r}{p}, \\qquad \\operatorname{Var}(N) = \\frac{r(1-p)}{p^{2}}.\n$$\nTherefore, the standard deviation is\n$$\n\\operatorname{SD}(N) = \\sqrt{\\operatorname{Var}(N)} = \\frac{\\sqrt{r(1-p)}}{p}.\n$$\n\nSubstituting $r=60$ and $p=0.15$ gives\n$$\n\\operatorname{SD}(N) = \\frac{\\sqrt{60(1-0.15)}}{0.15} = \\frac{\\sqrt{51}}{0.15}.\n$$\nNumerically,\n$$\n\\sqrt{51} \\approx 7.141428428,\\quad \\frac{\\sqrt{51}}{0.15} \\approx 47.60952286.\n$$\nRounding to four significant figures yields $47.61$.", "answer": "$$\\boxed{47.61}$$", "id": "1373790"}, {"introduction": "In many scientific and engineering fields, we don't know the underlying parameters of a process; instead, we have data. This final practice ([@problem_id:1939495]) bridges theory and application by introducing parameter estimation. Using observed sample mean and variance from a data science scenario, you will work backwards to determine the most likely parameters of the negative binomial model. This exercise also highlights a common alternative definition of the negative binomial random variable, which counts failures before successes, an important distinction in practical applications.", "problem": "A team of data scientists is modeling user engagement on a new social media platform. They are interested in the number of posts a user makes until they achieve a certain number of \"successful\" posts, defined as posts that receive a high level of community interaction.\n\nThe team models this process using a negative binomial distribution. Let the random variable $X$ represent the number of \"unsuccessful\" posts a user creates before achieving a target of $r$ successful posts. The probability of any given post being successful is $p$, and each post is an independent trial.\n\nFrom a large dataset of user histories, the team has calculated the sample mean and variance for the number of unsuccessful posts. The estimated mean is $E[X] = 10$ and the estimated variance is $Var(X) = 20$.\n\nBased on these empirical estimates, determine the parameters of the negative binomial distribution that models this process: the target number of successful posts, $r$, and the probability of success for a single post, $p$. Your answer should be the ordered pair $(r, p)$.", "solution": "Let $X$ denote the number of failures before achieving $r$ successes in independent Bernoulli trials with success probability $p$. In this parameterization of the negative binomial distribution, $X$ can be written as the sum of $r$ independent geometric random variables (each counting failures before one success), each with mean $(1-p)/p$ and variance $(1-p)/p^{2}$. Therefore,\n$$\nE[X]=r\\frac{1-p}{p},\\qquad \\operatorname{Var}(X)=r\\frac{1-p}{p^{2}}.\n$$\nLet $\\mu=E[X]$ and $\\sigma^{2}=\\operatorname{Var}(X)$. Then\n$$\n\\frac{\\sigma^{2}}{\\mu}=\\frac{r(1-p)/p^{2}}{r(1-p)/p}=\\frac{1}{p}\\quad\\Longrightarrow\\quad p=\\frac{\\mu}{\\sigma^{2}}.\n$$\nNext, solve for $r$ from the mean:\n$$\n\\mu=r\\frac{1-p}{p}\\quad\\Longrightarrow\\quad r=\\frac{\\mu p}{1-p}.\n$$\nSubstitute $p=\\mu/\\sigma^{2}$:\n$$\nr=\\frac{\\mu\\left(\\frac{\\mu}{\\sigma^{2}}\\right)}{1-\\frac{\\mu}{\\sigma^{2}}}\n=\\frac{\\mu^{2}}{\\sigma^{2}-\\mu}.\n$$\nWith the empirical estimates $\\mu=10$ and $\\sigma^{2}=20$, we obtain\n$$\np=\\frac{10}{20}=\\frac{1}{2},\\qquad r=\\frac{10^{2}}{20-10}=\\frac{100}{10}=10.\n$$\nThus, the parameters are $(r,p)=(10,\\frac{1}{2})$.", "answer": "$$\\boxed{(10, \\frac{1}{2})}$$", "id": "1939495"}]}