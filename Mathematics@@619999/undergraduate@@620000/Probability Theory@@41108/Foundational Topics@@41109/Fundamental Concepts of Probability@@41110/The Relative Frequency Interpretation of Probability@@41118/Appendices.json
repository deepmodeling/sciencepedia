{"hands_on_practices": [{"introduction": "Let's begin with a foundational application of the relative frequency interpretation of probability. This practice explores how to estimate the likelihood of an event by analyzing a finite set of real-world data. By examining the operational log of a customer service system, you will apply the core principle of dividing the number of successful outcomes by the total number of observations to find a meaningful probability estimate [@problem_id:1405741].", "problem": "A technology company, TechForward Solutions, utilizes an advanced Interactive Voice Response (IVR) system to manage its customer support hotline. This system is designed to handle a variety of customer inquiries automatically. For quality assurance and performance analysis, the system logs the final outcome of every incoming call. Over the last fiscal quarter, the system's logs provided the following breakdown of call outcomes:\n\n*   Calls successfully and fully resolved by the IVR system without any human interaction: 18,542\n*   Calls where the customer's query was not resolved by the IVR and was transferred to a human agent in the technical support department: 4,120\n*   Calls where the customer's query was not resolved by the IVR and was transferred to a human agent in the billing department: 8,315\n*   Calls that were disconnected by the customer before the IVR system could either resolve the query or initiate a transfer: 2,551\n*   Calls that were disconnected by the customer while they were on hold, waiting to be connected to a human agent: 987\n\nBased on this dataset, use the relative frequency interpretation of probability to estimate the probability that a randomly selected incoming call is resolved by the IVR system without any need for human intervention. Provide your answer as a decimal rounded to three significant figures.", "solution": "Using the relative frequency interpretation of probability, the probability that a randomly selected call is resolved by the IVR without human intervention equals the number of such successes divided by the total number of calls observed.\n\nLet $N$ be the total number of calls and $N_{\\text{IVR}}$ be the number resolved by the IVR. From the data:\n$$\nN_{\\text{IVR}} = 18542,\n$$\n$$\nN = 18542 + 4120 + 8315 + 2551 + 987 = 34515.\n$$\nTherefore, the estimated probability is\n$$\np = \\frac{N_{\\text{IVR}}}{N} = \\frac{18542}{34515}.\n$$\nCompute a decimal approximation and round to three significant figures:\n$$\np \\approx 0.5372 \\quad \\Rightarrow \\quad p \\approx 0.537 \\text{ (to three significant figures)}.\n$$", "answer": "$$\\boxed{0.537}$$", "id": "1405741"}, {"introduction": "Building on direct data analysis, we now turn to the power of simulation. In many complex systems, such as the analysis of computer algorithms, it is impractical to enumerate all possibilities or rely solely on historical data. This exercise demonstrates how to use large-scale computational experiments (a Monte Carlo method) to estimate the probability of a specific event, providing practical insight into the performance and reliability of a randomized algorithm [@problem_id:1405750].", "problem": "A software development team at a data science company is stress-testing a new implementation of the Randomized Quicksort algorithm. The algorithm sorts an array of distinct elements by repeatedly performing the following steps:\n1.  Choose an element from the current subarray uniformly at random. This element is called the pivot.\n2.  Partition the other elements into two subarrays: those less than the pivot and those greater than the pivot. The number of element-to-element comparisons performed in this step is equal to the size of the subarray minus one.\n3.  Recursively apply the algorithm to the two subarrays.\n\nThe team is particularly interested in the number of element-to-element comparisons, as this is the dominant factor in the algorithm's runtime. They are testing the algorithm on arrays of size $n=40$ containing a random permutation of distinct integers.\n\nFrom theoretical analysis, it is known that while the algorithm is very efficient on average, there is a non-zero chance of \"unlucky\" pivot choices leading to a high number of comparisons. The team defines a \"performance degradation event\" as an instance where the total number of comparisons, $C$, required to sort a single array of size $n=40$ exceeds a threshold of $C_{max} = 500$.\n\nTo empirically estimate the likelihood of such an event, they run a large-scale simulation. They generate and sort a total of $N = 7,500,000$ independent random arrays of size $n=40$. Throughout this experiment, they observe that the number of comparisons exceeded the threshold $C_{max}$ a total of $k = 243$ times.\n\nBased on the results of this simulation, what is the estimated probability of a performance degradation event for an array of size $n=40$? Report your answer as a decimal, rounded to three significant figures.", "solution": "Treat each run as an independent Bernoulli trial with success defined as a performance degradation event. Let $X_{i}$ be the indicator of success on run $i$, so $X_{i} \\in \\{0,1\\}$ and $\\mathbb{P}(X_{i}=1)=p$. Over $N$ runs, the total number of events is $K=\\sum_{i=1}^{N} X_{i}$, with observed value $k=243$. The standard estimator for $p$ is the empirical frequency\n$$\n\\hat{p}=\\frac{k}{N}.\n$$\nSubstituting the given values,\n$$\n\\hat{p}=\\frac{243}{7{,}500{,}000}=\\frac{243}{7.5 \\times 10^{6}}=\\left(\\frac{243}{7.5}\\right)\\times 10^{-6}=32.4 \\times 10^{-6}=3.24 \\times 10^{-5}.\n$$\nExpressed as a decimal and rounded to three significant figures, this is\n$$\n0.0000324.\n$$", "answer": "$$\\boxed{0.0000324}$$", "id": "1405750"}, {"introduction": "Our first two practices focused on estimating probabilities from finite data. But what value do these estimates approach as the number of observations grows infinitely large? This final problem bridges the gap between empirical estimation and theoretical probability. By analyzing a classic chaotic system, you will calculate the exact, long-run probability that the system's state is found in a specific region, revealing the underlying probability distribution that governs the system's dynamics [@problem_id:1405773].", "problem": "The one-dimensional logistic map is a classic example of a simple system capable of exhibiting complex, chaotic behavior. It is defined by the iterative equation $x_{k+1} = r x_k(1 - x_k)$, where $x_k \\in [0, 1]$ is the state of the system at step $k$ and $r$ is a parameter.\n\nFor the specific case of full chaos at $r=4$, the map is $x_{k+1} = 4x_k(1-x_k)$. For almost all initial conditions $x_0 \\in (0, 1)$, the sequence of points $\\{x_k\\}_{k=0}^{\\infty}$ generated by this map neither converges nor becomes periodic. Instead, the points are distributed across the interval $[0, 1]$ according to a specific probability law.\n\nIn the long run, the probability of finding a point of the orbit within a subinterval $[a, b] \\subseteq [0, 1]$ is given by the integral of the system's unique absolutely continuous invariant probability density function, $\\rho(x)$, over that subinterval. For the map $x_{k+1} = 4x_k(1-x_k)$, this invariant density function is given by:\n$$\n\\rho(x) = \\frac{1}{\\pi\\sqrt{x(1-x)}}\n$$\nThis function describes the relative frequency with which different regions of the interval $[0, 1]$ are visited by a typical orbit.\n\nCalculate the exact theoretical probability that a point $x_k$ from a long chaotic orbit of this map will be found in the subinterval $[3/4, 1]$. Express your final answer as an exact analytic expression.", "solution": "For the logistic map at parameter value $r=4$, the unique absolutely continuous invariant density is $\\rho(x)=\\frac{1}{\\pi\\sqrt{x(1-x)}}$ on $[0,1]$. The long-run probability of finding $x_{k}$ in a subinterval $[a,b]\\subseteq[0,1]$ is given by\n$$\nP([a,b])=\\int_{a}^{b}\\rho(x)\\,dx=\\int_{a}^{b}\\frac{1}{\\pi\\sqrt{x(1-x)}}\\,dx.\n$$\nTherefore, the required probability is\n$$\nP\\left(\\left[\\frac{3}{4},1\\right]\\right)=\\int_{3/4}^{1}\\frac{1}{\\pi\\sqrt{x(1-x)}}\\,dx.\n$$\nTo evaluate this integral, use the substitution $x=\\sin^{2}t$ with $t\\in\\left[0,\\frac{\\pi}{2}\\right]$. Then $dx=2\\sin t\\cos t\\,dt$ and\n$$\n\\sqrt{x(1-x)}=\\sqrt{\\sin^{2}t\\,\\cos^{2}t}=\\sin t\\cos t,\n$$\nsince $\\sin t,\\cos t\\geq 0$ on $\\left[0,\\frac{\\pi}{2}\\right]$. Hence,\n$$\n\\frac{dx}{\\sqrt{x(1-x)}}=\\frac{2\\sin t\\cos t\\,dt}{\\sin t\\cos t}=2\\,dt.\n$$\nThe limits transform as follows: when $x=\\frac{3}{4}$, $\\sin^{2}t=\\frac{3}{4}$ so $\\sin t=\\frac{\\sqrt{3}}{2}$ and $t=\\frac{\\pi}{3}$; when $x=1$, $\\sin^{2}t=1$ so $t=\\frac{\\pi}{2}$. Therefore,\n$$\n\\int_{3/4}^{1}\\frac{1}{\\pi\\sqrt{x(1-x)}}\\,dx=\\frac{1}{\\pi}\\int_{3/4}^{1}\\frac{dx}{\\sqrt{x(1-x)}}=\\frac{1}{\\pi}\\int_{\\pi/3}^{\\pi/2}2\\,dt=\\frac{2}{\\pi}\\left(\\frac{\\pi}{2}-\\frac{\\pi}{3}\\right)=\\frac{1}{3}.\n$$\nThus, the exact theoretical probability is $\\frac{1}{3}$.", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1405773"}]}