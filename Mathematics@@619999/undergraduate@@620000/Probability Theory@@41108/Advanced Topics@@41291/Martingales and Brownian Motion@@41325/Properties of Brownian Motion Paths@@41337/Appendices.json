{"hands_on_practices": [{"introduction": "To begin our exploration, we will focus on the foundational properties that define Brownian motion. This first practice invites you to apply the principles of independent increments and variance scaling to a simple linear combination of the process at different time points [@problem_id:1381539]. Mastering this type of calculation is the first step toward understanding more complex path behaviors.", "problem": "A standard one-dimensional Brownian motion, denoted by $\\{B_t\\}_{t \\ge 0}$, is a stochastic process characterized by the following properties:\n1.  $B_0 = 0$.\n2.  It has independent increments: for any sequence of times $0 \\le s_1 < t_1 \\le s_2 < t_2$, the random variables $B_{t_1} - B_{s_1}$ and $B_{t_2} - B_{s_2}$ are independent.\n3.  For any $t > s \\ge 0$, the increment $B_t - B_s$ is a normally distributed random variable with a mean of 0 and a variance of $t-s$. This is often denoted as $B_t - B_s \\sim N(0, t-s)$.\n4.  The sample paths $t \\mapsto B_t$ are continuous almost surely.\n\nConsider a fixed time $t > 0$. A new random variable $X$ is constructed as a linear combination of the Brownian motion at two different time points:\n$$X = B_{9t} - 3B_t$$\n\nWhich of the following describes the probability distribution of the random variable $X$?\n\nA. $N(0, 0)$, a deterministic value of 0.\n\nB. $N(0, 6t)$\n\nC. $N(0, 12t)$\n\nD. $N(0, 18t)$\n\nE. The distribution is not Gaussian.", "solution": "We use that Brownian motion is a Gaussian process with mean zero, stationary independent increments, and for any $s < u$, the increment $B_{u} - B_{s} \\sim N(0, u - s)$ and is independent of $\\{B_{r}: r \\le s\\}$.\n\nWrite\n$$\nB_{9t} = B_{t} + \\big(B_{9t} - B_{t}\\big),\n$$\nso that\n$$\nX = B_{9t} - 3B_{t} = \\big(B_{t} + (B_{9t} - B_{t})\\big) - 3B_{t} = -2B_{t} + \\big(B_{9t} - B_{t}\\big).\n$$\nBy the independent increments property, $B_{t}$ and $B_{9t} - B_{t}$ are independent. Moreover, $B_{t} \\sim N(0, t)$ and $B_{9t} - B_{t} \\sim N(0, 9t - t) = N(0, 8t)$.\n\nSince a linear combination of independent Gaussian random variables is Gaussian, $X$ is Gaussian with mean\n$$\n\\mathbb{E}[X] = -2\\,\\mathbb{E}[B_{t}] + \\mathbb{E}[B_{9t} - B_{t}] = 0,\n$$\nand variance\n$$\n\\operatorname{Var}(X) = (-2)^{2}\\operatorname{Var}(B_{t}) + \\operatorname{Var}(B_{9t} - B_{t}) = 4t + 8t = 12t.\n$$\nTherefore, $X \\sim N(0, 12t)$, which corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1381539"}, {"introduction": "Building on the definition of Brownian motion, we now move to calculating key characteristics of its path. This exercise asks you to compute the expected distance from the origin, $\\mathbb{E}[|B_t|]$, by leveraging the known normal distribution of the process [@problem_id:1381543]. This practice connects the abstract probability density function to a tangible, physically meaningful quantity.", "problem": "A standard one-dimensional Brownian motion, denoted by the stochastic process $\\{B_t\\}_{t \\geq 0}$, is a fundamental model for random movement. It is characterized by the property that for any time $t > 0$, the position of the particle, $B_t$, is a random variable that follows a normal distribution with a mean of 0 and a variance equal to $t$. The probability density function (PDF) for $B_t$ is therefore given by:\n$$f(x; t) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^2}{2t}\\right)$$\nfor $-\\infty < x < \\infty$.\n\nNow, consider the process $X_t = |B_t|$, which represents the magnitude of the displacement from the origin at time $t$. This is often called a reflected Brownian motion.\n\nYour task is to determine the expected value of $X_t$ for any given time $t > 0$. Provide your answer as a closed-form analytic expression in terms of $t$.", "solution": "We are given that for each fixed $t>0$, $B_{t}$ has density $f(x;t)=\\frac{1}{\\sqrt{2\\pi t}}\\exp\\!\\left(-\\frac{x^{2}}{2t}\\right)$ on $(-\\infty,\\infty)$. Define $X_{t}=|B_{t}|$. Then\n$$\n\\mathbb{E}[X_{t}]=\\mathbb{E}[|B_{t}|]=\\int_{-\\infty}^{\\infty}|x|\\,f(x;t)\\,dx.\n$$\nUsing the evenness of both $|x|$ and $f(x;t)$, we obtain\n$$\n\\mathbb{E}[|B_{t}|]=2\\int_{0}^{\\infty}x\\,\\frac{1}{\\sqrt{2\\pi t}}\\exp\\!\\left(-\\frac{x^{2}}{2t}\\right)\\,dx.\n$$\nSet $u=\\frac{x^{2}}{2t}$ so that $du=\\frac{x}{t}\\,dx$ and hence $x\\,dx=t\\,du$. The limits map as $x=0\\mapsto u=0$ and $x\\to\\infty\\mapsto u\\to\\infty$. Therefore,\n$$\n\\mathbb{E}[|B_{t}|]=2\\cdot\\frac{1}{\\sqrt{2\\pi t}}\\int_{0}^{\\infty}\\exp(-u)\\,t\\,du\n=2\\cdot\\frac{t}{\\sqrt{2\\pi t}}\\int_{0}^{\\infty}\\exp(-u)\\,du.\n$$\nSince $\\int_{0}^{\\infty}\\exp(-u)\\,du=1$, we have\n$$\n\\mathbb{E}[|B_{t}|]=\\frac{2t}{\\sqrt{2\\pi t}}=\\sqrt{\\frac{2t}{\\pi}}.\n$$\nThus, for $t>0$,\n$$\n\\mathbb{E}[X_{t}]=\\sqrt{\\frac{2t}{\\pi}}.\n$$", "answer": "$$\\boxed{\\sqrt{\\frac{2t}{\\pi}}}$$", "id": "1381543"}, {"introduction": "Our final practice delves into one of the most elegant concepts in stochastic processes: conditioning on future events. Here, you will investigate how observing the position of a Brownian particle at a later time $t$ influences our knowledge of its position at an earlier time $s$ [@problem_id:1381542]. This problem introduces the idea of a Brownian bridge, a fundamental structure in probability theory with wide-ranging applications.", "problem": "A standard one-dimensional Brownian motion, denoted by $\\{B_t\\}_{t \\ge 0}$, is a continuous-time stochastic process that models the random movement of a particle. It is defined by the following properties:\n1.  The process starts at the origin: $B_0 = 0$.\n2.  The process has independent increments: for any sequence of times $0 \\le t_1 < t_2 < \\dots < t_n$, the random variables $B_{t_2} - B_{t_1}, B_{t_3} - B_{t_2}, \\dots, B_{t_n} - B_{t_{n-1}}$ are mutually independent.\n3.  The increments are normally distributed: for any $t > s \\ge 0$, the increment $B_t - B_s$ follows a normal distribution with mean 0 and variance $t-s$, denoted as $B_t - B_s \\sim N(0, t-s)$.\n\nConsider a microscopic particle whose position in one dimension is described by $B_t$. At time $t=0$, the particle is at the origin. An experimenter observes the particle's trajectory and records its position at a positive time $t$ to be exactly $x$. Unfortunately, the measurement of the particle's position at an earlier time $s$, where $0 < s < t$, was lost.\n\nYour task is to determine the expected position and the variance of the position of the particle at time $s$, given the observation that its position at time $t$ is $x$. In other words, find the conditional expectation $\\mathbb{E}[B_s | B_t = x]$ and the conditional variance $\\text{Var}(B_s | B_t = x)$.\n\nExpress your answer as a $1 \\times 2$ matrix, where the first element is the conditional expectation and the second element is the conditional variance. Your answer should be in terms of the symbolic parameters $s$, $t$, and $x$.", "solution": "Let $0<s<t$ be fixed. From the independent increments of Brownian motion, write $B_{t}=B_{s}+(B_{t}-B_{s})$ with $B_{s}\\sim N(0,s)$, $B_{t}-B_{s}\\sim N(0,t-s)$, and $B_{s}$ independent of $B_{t}-B_{s}$. Then\n$$\n\\mathbb{E}[B_{s}]=0,\\quad \\mathbb{E}[B_{t}]=0,\n$$\n$$\n\\operatorname{Var}(B_{s})=s,\\quad \\operatorname{Var}(B_{t})=t,\n$$\nand\n$$\n\\operatorname{Cov}(B_{s},B_{t})=\\mathbb{E}\\big[B_{s}(B_{s}+B_{t}-B_{s})\\big]=\\mathbb{E}[B_{s}^{2}]+\\mathbb{E}[B_{s}(B_{t}-B_{s})]=s+0=s.\n$$\nThus the vector $(B_{s},B_{t})^{\\top}$ is bivariate normal with mean vector $(0,0)^{\\top}$ and covariance matrix\n$$\n\\Sigma=\\begin{pmatrix} s & s \\\\ s & t \\end{pmatrix}.\n$$\nFor a bivariate normal $(X,Y)^{\\top}$ with mean $(0,0)^{\\top}$ and covariance entries $\\sigma_{XX}$, $\\sigma_{YY}$, $\\sigma_{XY}$, the conditional distribution $X\\,|\\,Y=y$ is normal with\n$$\n\\mathbb{E}[X\\,|\\,Y=y]=\\sigma_{XY}\\,\\sigma_{YY}^{-1}\\,y,\\qquad \\operatorname{Var}(X\\,|\\,Y=y)=\\sigma_{XX}-\\sigma_{XY}\\,\\sigma_{YY}^{-1}\\,\\sigma_{YX}.\n$$\nApplying this with $X=B_{s}$, $Y=B_{t}$, $\\sigma_{XX}=s$, $\\sigma_{YY}=t$, and $\\sigma_{XY}=s$, we obtain\n$$\n\\mathbb{E}[B_{s}\\,|\\,B_{t}=x]=\\frac{s}{t}\\,x,\n$$\n$$\n\\operatorname{Var}(B_{s}\\,|\\,B_{t}=x)=s-\\frac{s^{2}}{t}=\\frac{s(t-s)}{t}.\n$$\nThese are the desired conditional expectation and variance.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{s}{t}x & \\frac{s(t-s)}{t}\\end{pmatrix}}$$", "id": "1381542"}]}