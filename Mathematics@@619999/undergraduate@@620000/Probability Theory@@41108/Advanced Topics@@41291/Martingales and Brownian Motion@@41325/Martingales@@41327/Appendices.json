{"hands_on_practices": [{"introduction": "A central idea in martingale theory is that of a 'fair game,' where the expected future value, given the past, is simply the current value. Many important stochastic processes, however, are not martingales on their own. This first exercise [@problem_id:1310316] demonstrates a powerful technique: transforming a non-martingale process, in this case the square of a simple random walk, into a true martingale by subtracting a predictable 'compensator' process. Mastering this calculation is a key first step in understanding the underlying structure of martingales.", "problem": "Consider a simplified model for the discrete-time evolution of a financial instrument. Let $X_i$ for $i=1, 2, 3, \\dots$ be a sequence of independent and identically distributed random variables representing daily market shocks, with $P(X_i = 1) = P(X_i = -1) = \\frac{1}{2}$. The position of the instrument at the end of day $n$ is given by a simple symmetric random walk $S_n = \\sum_{i=1}^n X_i$, starting from $S_0 = 0$. The natural filtration generated by these shocks is denoted by $\\mathcal{F}_n = \\sigma(X_1, X_2, \\dots, X_n)$, representing the history of market information up to day $n$.\n\nA certain financial derivative has a value quadratically dependent on this position, given by the process $Y_n = S_n^2$. To make this derivative a \"fair game\", we introduce a non-random, deterministic cost adjustment process, $a_n$, which is subtracted from the value. The resulting net value process is $M_n = S_n^2 - a_n$.\n\nFind the explicit formula for the deterministic sequence $a_n$ for $n \\ge 0$ that makes the process $M_n$ a martingale with respect to the filtration $\\mathcal{F}_n$, assuming the initial cost is zero, i.e., $a_0 = 0$.", "solution": "We require that the process $M_{n} = S_{n}^{2} - a_{n}$ be a martingale with respect to $\\mathcal{F}_{n}$, i.e., for all $n \\geq 0$,\n$$\n\\mathbb{E}\\!\\left[M_{n+1}\\mid \\mathcal{F}_{n}\\right] = M_{n}.\n$$\nUsing $S_{n+1} = S_{n} + X_{n+1}$, expand $S_{n+1}^{2}$:\n$$\nS_{n+1}^{2} = (S_{n} + X_{n+1})^{2} = S_{n}^{2} + 2 S_{n} X_{n+1} + X_{n+1}^{2}.\n$$\nTaking conditional expectation given $\\mathcal{F}_{n}$ and using that $X_{n+1}$ is independent of $\\mathcal{F}_{n}$ with $\\mathbb{E}[X_{n+1}]=0$ and $X_{n+1}^{2}=1$ almost surely, we obtain\n$$\n\\mathbb{E}\\!\\left[S_{n+1}^{2}\\mid \\mathcal{F}_{n}\\right] = S_{n}^{2} + 2 S_{n} \\mathbb{E}[X_{n+1}] + \\mathbb{E}[X_{n+1}^{2}] = S_{n}^{2} + 1.\n$$\nTherefore,\n$$\n\\mathbb{E}\\!\\left[M_{n+1}\\mid \\mathcal{F}_{n}\\right] = \\mathbb{E}\\!\\left[S_{n+1}^{2} - a_{n+1}\\mid \\mathcal{F}_{n}\\right] = S_{n}^{2} + 1 - a_{n+1}.\n$$\nFor the martingale property, this must equal $M_{n} = S_{n}^{2} - a_{n}$, so\n$$\nS_{n}^{2} + 1 - a_{n+1} = S_{n}^{2} - a_{n} \\quad \\Longrightarrow \\quad a_{n+1} - a_{n} = 1.\n$$\nWith the initial condition $a_{0} = 0$, this first-order difference equation solves to\n$$\na_{n} = \\sum_{k=1}^{n} 1 = n \\quad \\text{for all } n \\geq 0.\n$$\nA direct verification confirms the martingale property:\n$$\n\\mathbb{E}\\!\\left[M_{n+1}\\mid \\mathcal{F}_{n}\\right] = S_{n}^{2} + 1 - (n+1) = S_{n}^{2} - n = M_{n}.\n$$\nThus, the required deterministic sequence is $a_{n} = n$.", "answer": "$$\\boxed{n}$$", "id": "1310316"}, {"introduction": "What happens when we apply a function to a martingale? The result is not always another martingale. This practice problem [@problem_id:1310339] explores this question by examining the absolute value of a simple symmetric random walk, which is itself a martingale. You will discover the concept of a submartingale—a process that, on average, is expected to increase or stay the same—and see how this property is elegantly linked to the convexity of the function via Jensen's inequality.", "problem": "Let $\\{X_i\\}_{i \\in \\mathbb{N}}$ be a sequence of independent and identically distributed random variables on a probability space $(\\Omega, \\mathcal{F}, P)$, with $P(X_i = 1) = P(X_i = -1) = 1/2$. A simple symmetric random walk $\\{S_n\\}_{n \\ge 0}$ is defined by $S_0 = 0$ and $S_n = \\sum_{i=1}^n X_i$ for $n \\ge 1$. Let $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ be the natural filtration generated by this sequence, where $\\mathcal{F}_n = \\sigma(X_1, \\dots, X_n)$ for $n \\ge 1$ and $\\mathcal{F}_0 = \\{\\emptyset, \\Omega\\}$.\n\nConsider a new stochastic process $\\{M_n\\}_{n \\ge 0}$ defined by $M_n = |S_n|$.\n\nWhich one of the following statements correctly describes the properties of the process $\\{M_n\\}_{n \\ge 0}$ with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$?\n\nA. $\\{M_n\\}_{n \\ge 0}$ is a martingale.\n\nB. $\\{M_n\\}_{n \\ge 0}$ is a submartingale, but not a martingale.\n\nC. $\\{M_n\\}_{n \\ge 0}$ is a supermartingale, but not a martingale.\n\nD. $\\{M_n\\}_{n \\ge 0}$ is neither a submartingale nor a supermartingale.", "solution": "We first check that $\\{M_{n}\\}_{n \\ge 0}$ is adapted and integrable. Since $S_{n}$ is $\\mathcal{F}_{n}$-measurable, $M_{n}=\\lvert S_{n}\\rvert$ is $\\mathcal{F}_{n}$-measurable, hence adapted. Moreover, $\\lvert S_{n}\\rvert\\leq n$ almost surely, so $\\mathbb{E}[\\lvert M_{n}\\rvert]\\leq n\\infty$ for each $n$, hence integrable.\n\nNext, we compute the conditional expectation of $M_{n+1}$ given $\\mathcal{F}_{n}$:\n$$\n\\mathbb{E}[M_{n+1}\\mid \\mathcal{F}_{n}]\n=\\mathbb{E}[\\lvert S_{n}+X_{n+1}\\rvert\\mid \\mathcal{F}_{n}]\n=\\frac{1}{2}\\big(\\lvert S_{n}+1\\rvert+\\lvert S_{n}-1\\rvert\\big),\n$$\nusing the independence of $X_{n+1}$ from $\\mathcal{F}_{n}$ and $P(X_{n+1}=1)=P(X_{n+1}=-1)=\\frac{1}{2}$.\n\nWe compare this with $M_{n}=\\lvert S_{n}\\rvert$. For any real $s$, consider\n$$\n\\frac{1}{2}\\big(\\lvert s+1\\rvert+\\lvert s-1\\rvert\\big)\\geq \\lvert s\\rvert.\n$$\nThis inequality can be verified by cases:\n- If $s\\geq 1$, then $\\lvert s+1\\rvert=s+1$ and $\\lvert s-1\\rvert=s-1$, hence the average equals $s=\\lvert s\\rvert$.\n- If $-1\\leq s\\leq 1$, then $\\lvert s+1\\rvert+\\lvert s-1\\rvert=2$, so the average equals $1\\geq \\lvert s\\rvert$, with strict inequality unless $s= \\pm 1$ or $s=0$ is treated separately as below.\n- If $s\\leq -1$, write $s=-a$ with $a\\geq 1$, then $\\lvert s+1\\rvert=a-1$ and $\\lvert s-1\\rvert=a+1$, so the average equals $a=\\lvert s\\rvert$.\n\nEquivalently, by convexity of $x\\mapsto \\lvert x\\rvert$ and $\\mathbb{E}[X_{n+1}\\mid \\mathcal{F}_{n}]=0$, Jensen's inequality yields\n$$\n\\mathbb{E}[\\lvert S_{n}+X_{n+1}\\rvert\\mid \\mathcal{F}_{n}]\n\\geq \\lvert S_{n}+\\mathbb{E}[X_{n+1}\\mid \\mathcal{F}_{n}]\\rvert\n=\\lvert S_{n}\\rvert=M_{n}.\n$$\nThus $\\{M_{n}\\}_{n\\ge 0}$ is a submartingale.\n\nTo show it is not a martingale, it suffices to find an event in $\\mathcal{F}_{n}$ of positive probability where the inequality is strict. On the event $\\{S_{n}=0\\}$ we have\n$$\n\\mathbb{E}[M_{n+1}\\mid \\mathcal{F}_{n}]=\\frac{1}{2}(\\lvert 1\\rvert+\\lvert -1\\rvert)=1M_{n}=\\lvert 0\\rvert=0.\n$$\nSince $P(S_{n}=0)0$ for even $n$, the martingale equality fails with positive probability for those $n$. Therefore, $\\{M_{n}\\}_{n\\ge 0}$ is not a martingale.\n\nConsequently, $\\{M_{n}\\}_{n\\ge 0}$ is a submartingale but not a martingale.", "answer": "$$\\boxed{B}$$", "id": "1310339"}, {"introduction": "Much of the power of martingale theory comes from analyzing processes evaluated at random times. However, not just any random time will do; it must be a 'stopping time,' meaning the decision to stop must be based only on the past, not the future. This exercise [@problem_id:1372277] moves from calculation to concept, asking you to determine if the first moment a random walk returns to its origin qualifies as a valid stopping time. A clear understanding of this definition is crucial for applying advanced tools like the Optional Stopping Theorem.", "problem": "Consider a simple symmetric random walk $\\{S_n\\}_{n \\ge 0}$ starting at $S_0 = 0$. The position of the walk at time $n$ is given by $S_n = \\sum_{i=1}^n X_i$, where the steps $X_i$ are independent and identically distributed random variables with a probability distribution $P(X_i = 1) = P(X_i = -1) = 1/2$.\n\nLet $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ be the natural filtration generated by the random walk, where $\\mathcal{F}_n = \\sigma(X_1, X_2, \\dots, X_n)$ represents the information available from observing the first $n$ steps of the walk. For completeness, $\\mathcal{F}_0$ is the trivial sigma-algebra.\n\nNow, define a random variable $T$ as the time of the first return to the origin:\n$$T = \\inf\\{n \\ge 1 : S_n = 0\\}$$\nIf the walk never returns to the origin, $T$ is taken to be infinite.\n\nWhich of the following statements correctly assesses whether $T$ is a stopping time with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ and provides the correct justification?\n\nA. Yes, $T$ is a stopping time because for any integer $n \\ge 1$, the event $\\{T=n\\}$ can be determined by knowing the path of the walk $\\{S_0, S_1, \\dots, S_n\\}$.\n\nB. No, $T$ is not a stopping time because determining that $T=n$ requires knowledge that the walk will not return to the origin at some future time $k  n$.\n\nC. No, $T$ is not a stopping time because it is possible that the walk never returns to the origin, which means $T$ can be infinite. A stopping time must be finite with probability 1.\n\nD. Yes, $T$ is a stopping time, but only because a one-dimensional simple symmetric random walk is guaranteed to return to the origin (i.e., it is recurrent). If it were not recurrent, $T$ would not be a stopping time.", "solution": "To determine if the random variable $T$ is a stopping time with respect to the filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$, we must check if it satisfies the definition of a stopping time.\n\nA random variable $T$ taking values in $\\{0, 1, 2, \\dots, \\infty\\}$ is a stopping time with respect to a filtration $\\{\\mathcal{F}_n\\}_{n \\ge 0}$ if for every non-negative integer $n$, the event $\\{T=n\\}$ is an element of the sigma-algebra $\\mathcal{F}_n$. In other words, for any given time $n$, we must be able to decide whether the event \"the stopping time occurs exactly at time $n$\" has happened, based solely on the information available up to time $n$.\n\nLet's analyze the event $\\{T=n\\}$ for an arbitrary integer $n \\ge 1$. The random variable $T$ is defined as the *first* time the walk returns to the origin. Therefore, the event $\\{T=n\\}$ occurs if and only if the walk has not returned to the origin at any time $k$ between 1 and $n-1$, and it returns to the origin exactly at time $n$.\n\nWe can write this condition formally using the positions of the random walk:\n$$\\{T=n\\} = \\{S_1 \\neq 0, S_2 \\neq 0, \\dots, S_{n-1} \\neq 0, S_n = 0\\}$$\nNote that for $n=0$, the definition of $T$ requires $n \\ge 1$, so $\\{T=0\\} = \\emptyset$. The empty set is in every sigma-algebra, so it is in $\\mathcal{F}_0$.\n\nNow, we need to check if this event $\\{T=n\\}$ is in the sigma-algebra $\\mathcal{F}_n$.\nThe filtration $\\mathcal{F}_n$ is defined as $\\mathcal{F}_n = \\sigma(X_1, X_2, \\dots, X_n)$. This means that any event whose outcome is determined by the first $n$ steps $(X_1, \\dots, X_n)$ is in $\\mathcal{F}_n$.\n\nLet's look at each part of the event $\\{T=n\\}$:\nFor any $k$ such that $1 \\le k \\le n$, the position $S_k = \\sum_{i=1}^k X_i$ is a function of the first $k$ steps $(X_1, \\dots, X_k)$.\nTherefore, the event $\\{S_k \\neq 0\\}$ is determined by the first $k$ steps. Since $k \\le n$, the information $(X_1, \\dots, X_k)$ is a subset of the information $(X_1, \\dots, X_n)$. This means that the event $\\{S_k \\neq 0\\}$ is in $\\mathcal{F}_k$, and since $\\mathcal{F}_k \\subseteq \\mathcal{F}_n$ for $k \\le n$, it is also in $\\mathcal{F}_n$.\n\nSimilarly, the event $\\{S_n = 0\\}$ is determined by the first $n$ steps, so it is in $\\mathcal{F}_n$.\n\nThe event $\\{T=n\\}$ is the intersection of $n$ separate events:\n$$\\{T=n\\} = \\{S_1 \\neq 0\\} \\cap \\{S_2 \\neq 0\\} \\cap \\dots \\cap \\{S_{n-1} \\neq 0\\} \\cap \\{S_n = 0\\}$$\nEach of these individual events is in $\\mathcal{F}_n$. By the properties of a sigma-algebra, a finite intersection of events in $\\mathcal{F}_n$ is also in $\\mathcal{F}_n$.\nTherefore, for any $n \\ge 1$, the event $\\{T=n\\}$ is in $\\mathcal{F}_n$.\n\nSince the condition $\\{T=n\\} \\in \\mathcal{F}_n$ holds for all $n \\ge 0$, $T$ is a stopping time.\n\nNow let's evaluate the given options:\n- **A. Yes, $T$ is a stopping time because for any integer $n \\ge 1$, the event $\\{T=n\\}$ can be determined by knowing the path of the walk $\\{S_0, S_1, \\dots, S_n\\}$.** This is correct. As shown, to know if $T=n$, we only need to check the history of the walk up to time $n$.\n- **B. No, $T$ is not a stopping time because determining that $T=n$ requires knowledge that the walk will not return to the origin at some future time $k  n$.** This is incorrect. The definition of $T$ is the *first* return time. We do not need to know anything about the future beyond time $n$ to determine if the first return happened at time $n$.\n- **C. No, $T$ is not a stopping time because it is possible that the walk never returns to the origin, which means $T$ can be infinite. A stopping time must be finite with probability 1.** This is a common misconception. The definition of a stopping time allows it to be infinite. The condition $\\{T=n\\} \\in \\mathcal{F}_n$ is only required for finite $n$. The property of being almost surely finite is separate from the definition of a stopping time.\n- **D. Yes, $T$ is a stopping time, but only because a one-dimensional simple symmetric random walk is guaranteed to return to the origin (i.e., it is recurrent). If it were not recurrent, $T$ would not be a stopping time.** This is incorrect. The property of being a stopping time is about measurability with respect to the filtration. It does not depend on the long-term properties like recurrence or transience. The first return time for a simple random walk in 3 dimensions (which is transient, i.e., $P(T=\\infty)0$) is also a stopping time, by the exact same logic.\n\nThus, statement A provides the correct conclusion and justification.", "answer": "$$\\boxed{A}$$", "id": "1372277"}]}