{"hands_on_practices": [{"introduction": "The Optional Stopping Theorem is a cornerstone of martingale theory, providing a powerful tool for analyzing random processes. This practice offers a foundational exercise on its application [@problem_id:849549]. By constructing a specific exponential martingale for a biased random walk, you will calculate the probability of hitting one boundary before another, a classic problem that demonstrates the elegance and efficiency of this method compared to solving recurrence relations directly.", "problem": "Consider a one-dimensional biased random walk $S_n = \\sum_{i=1}^n X_i$ starting from $S_0 = 0$. The steps $X_i$ are independent and identically distributed random variables with $P(X_i = 1) = p$ and $P(X_i = -1) = q = 1-p$, where $p \\neq 1/2$.\n\nFor this random walk, the process $M_n = (q/p)^{S_n}$ is a martingale with respect to the natural filtration $\\mathcal{F}_n = \\sigma(X_1, \\dots, X_n)$.\n\nLet $a$ and $b$ be positive integers representing absorbing barriers. Define the stopping time $T$ as the first time the walk reaches either level $a$ or level $-b$:\n$$T = \\inf\\{ n \\ge 1 : S_n = a \\text{ or } S_n = -b \\}$$\n\nUsing the Optional Stopping Theorem on the martingale $M_n$, derive a closed-form expression for the probability that the walk hits the level $a$ before hitting the level $-b$. This probability is denoted by $P(S_T = a)$. Express your answer in terms of $p, q, a,$ and $b$.", "solution": "1. Recall $M_n = \\bigl(\\tfrac{q}{p}\\bigr)^{S_n}$ is a martingale and $T=\\inf\\{n\\ge1:S_n=a\\text{ or }S_n=-b\\}$ is bounded a.s.  \n2. By the Optional Stopping Theorem,  \n   $$\\mathbb{E}[M_T]=\\mathbb{E}[M_0]=\\bigl(\\tfrac{q}{p}\\bigr)^0=1\\,. $$\n3. At time $T$, $S_T$ is either $a$ or $-b$. Let $\\alpha=P(S_T=a)$. Then  \n   $$\\mathbb{E}[M_T]\n     =\\alpha\\bigl(\\tfrac{q}{p}\\bigr)^a+(1-\\alpha)\\bigl(\\tfrac{q}{p}\\bigr)^{-b}\n     =1\\,. $$\n4. Denote $r=\\tfrac{q}{p}$. Then  \n   $$\\alpha\\,r^a+(1-\\alpha)\\,r^{-b}=1\n     \\quad\\Longrightarrow\\quad\n     \\alpha\\,(r^a-r^{-b})=1-r^{-b}\n     \\quad\\Longrightarrow\\quad\n     \\alpha=\\frac{1-r^{-b}}{\\,r^a-r^{-b}\\,}\\,. $$\n5. Multiply numerator and denominator by $r^b$:  \n   $$\\alpha=\\frac{r^b-1}{\\,r^{\\,a+b}-1\\,}\n     =\\frac{1-(q/p)^b}{\\,1-(q/p)^{a+b}\\,}\\,. $$\nThus the probability of hitting $a$ before $-b$ is $\\displaystyle\\frac{1-(q/p)^b}{1-(q/p)^{a+b}}$.", "answer": "$$\\boxed{\\frac{1 - (q/p)^b}{1 - (q/p)^{a+b}}}$$", "id": "849549"}, {"introduction": "Moving from discrete random walks to continuous-time processes, this exercise explores a crucial application of stopping times in quantitative finance [@problem_id:849541]. We will model a stock's price using Geometric Brownian Motion and determine the probability of a simple investment strategy succeeding. This problem requires using Itô's lemma to transform the process into a Brownian motion with drift, thereby applying the same core principles of hitting probabilities to a more advanced and practical scenario.", "problem": "A non-dividend-paying stock has a price $S_t$ at time $t$ that is modeled by a geometric Brownian motion (GBM), following the stochastic differential equation:\n$$\ndS_t = \\mu S_t dt + \\sigma S_t dB_t\n$$\nwhere $\\mu$ is the constant expected rate of return, $\\sigma > 0$ is the constant volatility, and $B_t$ is a standard one-dimensional Brownian motion. An investor purchases the stock at an initial price $S_0 > 0$. The investor employs a strategy to sell the stock as soon as its price reaches either an upper target price $U = k_U S_0$ or a lower stop-loss price $L = k_L S_0$, where $k_U > 1$ and $0 < k_L < 1$ are fixed multiplicative factors.\n\nAssume that the effective drift of the log-price process, $\\mu - \\frac{1}{2}\\sigma^2$, is non-zero.\n\nDerive a closed-form expression for the probability that the investor sells the stock at the upper target price $U$ rather than the lower stop-loss price $L$. Express your answer in terms of $\\mu$, $\\sigma$, $k_U$, and $k_L$.", "solution": "Define the log-price process \n$$X_t=\\ln\\frac{S_t}{S_0},$$ \nthen by Itô’s lemma \n$$dX_t=\\Bigl(\\mu-\\tfrac12\\sigma^2\\Bigr)\\,dt+\\sigma\\,dB_t.$$\nSet \n$$m=\\mu-\\tfrac12\\sigma^2,\\quad a=\\ln k_L<0,\\quad b=\\ln k_U>0,$$ \nand note $X_0=0$.  For a Brownian motion with drift $m$ and diffusion $\\sigma$, the probability of hitting $b$ before $a$ starting at $x$ is \n$$P_x\\{\\,\\tau_b<\\tau_a\\}\n=\\frac{\\displaystyle\\int_a^x e^{-2m y/\\sigma^2}\\,dy}{\\displaystyle\\int_a^b e^{-2m y/\\sigma^2}\\,dy}.$$\nSetting $x=0$ gives\n$$P=\\frac{\\displaystyle\\int_a^0e^{-2m y/\\sigma^2}dy}{\\displaystyle\\int_a^b e^{-2m y/\\sigma^2}dy}\n=\\frac{e^{-2m a/\\sigma^2}-1}{e^{-2m a/\\sigma^2}-e^{-2m b/\\sigma^2}}.$$\nSubstitute $a=\\ln k_L$, $b=\\ln k_U$:\n$$e^{-2m a/\\sigma^2}=k_L^{-2m/\\sigma^2},\\quad e^{-2m b/\\sigma^2}=k_U^{-2m/\\sigma^2},$$\nso\n$$P\n=\\frac{k_L^{-2m/\\sigma^2}-1}{k_L^{-2m/\\sigma^2}-k_U^{-2m/\\sigma^2}},\\quad m=\\mu-\\tfrac12\\sigma^2.$$", "answer": "$$\\boxed{\\frac{k_L^{-2(\\mu-\\sigma^2/2)/\\sigma^2}-1}{k_L^{-2(\\mu-\\sigma^2/2)/\\sigma^2}-k_U^{-2(\\mu-\\sigma^2/2)/\\sigma^2}}}$$", "id": "849541"}, {"introduction": "The Coupon Collector's Problem is a famous and insightful puzzle in probability theory, where the stopping time is the number of trials needed to acquire a complete set of items. This exercise demonstrates a powerful technique for analyzing such stopping times: decomposition [@problem_id:849585]. By breaking the total collection time into a series of simpler, independent geometric random variables, you can calculate not just the expected time, but also its variance, providing a deeper understanding of the process's fluctuations and its surprising asymptotic connection to the Basel problem's result, $\\frac{\\pi^2}{6}$.", "problem": "In the coupon collector's problem, a collector aims to acquire a complete set of $N$ distinct coupons. At each time step, one coupon is drawn, with each of the $N$ types being equally likely with a probability of $1/N$. The draws are independent. Let $T_N$ be the random variable representing the total number of draws required to obtain a full set of $N$ distinct coupons.\n\nFor large $N$, the variance of $T_N$, denoted $\\text{Var}(T_N)$, grows quadratically with $N$. Your task is to derive the exact value of the coefficient of this quadratic growth term. Specifically, calculate the limit:\n$$\nL = \\lim_{N\\to\\infty} \\frac{\\text{Var}(T_N)}{N^2}\n$$\nYou may use the known result from the Basel problem: $\\sum_{k=1}^{\\infty} \\frac{1}{k^2} = \\frac{\\pi^2}{6}$.", "solution": "We decompose \n$$T_N=\\sum_{k=0}^{N-1}X_k,$$\nwhere $X_k$ is the number of additional draws to see a new coupon once $k$ distinct ones have been collected.  Since each draw yields a new coupon with probability \n$$p_k=\\frac{N-k}{N},$$\nwe have\n1. \n$$\\mathbb{E}[X_k]=\\frac{1}{p_k}=\\frac{N}{\\,N-k\\,},$$\n2. \n$$\\mathrm{Var}(X_k)=\\frac{1-p_k}{p_k^2}\n=\\frac{k/N}{((N-k)/N)^2}\n=\\frac{k\\,N}{(N-k)^2}.$$\nHence\n$$\\mathrm{Var}(T_N)\n=\\sum_{k=0}^{N-1}\\mathrm{Var}(X_k)\n=\\sum_{k=0}^{N-1}\\frac{k\\,N}{(N-k)^2}\n=N\\sum_{j=1}^{N}\\frac{N-j}{j^2},$$\nwhere we set $j=N-k$.  Since the term $j=N$ vanishes we may write\n$$\\mathrm{Var}(T_N)\n=N\\Bigl(N\\sum_{j=1}^N\\frac{1}{j^2}-\\sum_{j=1}^N\\frac{1}{j}\\Bigr)\n=N^2\\sum_{j=1}^N\\frac{1}{j^2}-N\\,H_N.$$\nDividing by $N^2$ and taking $N\\to\\infty$, using\n$$\\sum_{j=1}^\\infty\\frac{1}{j^2}=\\frac{\\pi^2}{6},\\qquad\n\\frac{H_N}{N}\\to0,$$\ngives\n$$L=\\lim_{N\\to\\infty}\\frac{\\mathrm{Var}(T_N)}{N^2}\n=\\frac{\\pi^2}{6}.$$", "answer": "$$\\boxed{\\frac{\\pi^2}{6}}$$", "id": "849585"}]}