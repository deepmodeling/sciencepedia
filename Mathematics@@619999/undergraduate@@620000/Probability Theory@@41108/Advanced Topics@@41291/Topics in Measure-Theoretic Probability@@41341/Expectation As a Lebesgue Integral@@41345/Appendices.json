{"hands_on_practices": [{"introduction": "To ground our understanding of expectation as a Lebesgue integral, let's begin with a classic example: a single roll of a fair die. This problem asks you to calculate the familiar expected value by formally representing the outcome as a simple function on a discrete probability space. This exercise [@problem_id:1360918] provides a concrete link between the abstract definition of the Lebesgue integral and the intuitive concept of a weighted average from introductory probability.", "problem": "Consider the experiment of rolling a single fair six-sided die. This process is modeled by the probability space $(\\Omega, \\mathcal{F}, P)$, where the sample space is $\\Omega = \\{1, 2, 3, 4, 5, 6\\}$, the sigma-algebra $\\mathcal{F}$ is the power set of $\\Omega$, and the probability measure $P$ is defined by $P(A) = \\frac{|A|}{6}$ for any event $A \\in \\mathcal{F}$.\nLet the random variable $X: \\Omega \\to \\mathbb{R}$ represent the outcome of the roll, such that $X(\\omega) = \\omega$ for any outcome $\\omega \\in \\Omega$.\nThe expected value of $X$, denoted $E[X]$, is defined as the Lebesgue integral of $X$ with respect to the measure $P$, i.e., $E[X] = \\int_{\\Omega} X \\, dP$.\nBy representing the random variable $X$ as a simple function in its canonical form, calculate its expected value. Express your final answer as a decimal number rounded to two significant figures.", "solution": "The random variable $X:\\Omega\\to\\mathbb{R}$ takes finitely many values, so it is a simple function. Its canonical representation is given by the sum over its distinct values multiplied by the indicators of their preimages:\n$$\nX(\\omega)=\\sum_{k=1}^{6} k\\,\\mathbf{1}_{\\{\\omega\\in\\Omega:X(\\omega)=k\\}}(\\omega)=\\sum_{k=1}^{6} k\\,\\mathbf{1}_{\\{k\\}}(\\omega),\n$$\nsince $X(\\omega)=\\omega$ and therefore $\\{\\omega:X(\\omega)=k\\}=\\{k\\}$. The Lebesgue integral of a simple function $\\phi=\\sum_{i=1}^{n} a_{i}\\mathbf{1}_{A_{i}}$ with respect to a measure $P$ is\n$$\n\\int_{\\Omega} \\phi \\, dP=\\sum_{i=1}^{n} a_{i} P(A_{i}).\n$$\nApplying this to $X$, we obtain\n$$\nE[X]=\\int_{\\Omega} X\\, dP=\\sum_{k=1}^{6} k\\,P(\\{k\\}).\n$$\nBy the given probability measure $P(A)=\\frac{|A|}{6}$, we have $P(\\{k\\})=\\frac{1}{6}$ for each $k\\in\\{1,2,3,4,5,6\\}$. Hence,\n$$\nE[X]=\\sum_{k=1}^{6} k \\cdot \\frac{1}{6}=\\frac{1}{6}\\sum_{k=1}^{6} k=\\frac{1}{6}\\cdot \\frac{6\\cdot 7}{2}=\\frac{21}{6}=\\frac{7}{2}=3.5.\n$$\nExpressed as a decimal rounded to two significant figures, the result is $3.5$.", "answer": "$$\\boxed{3.5}$$", "id": "1360918"}, {"introduction": "The power of the Lebesgue framework truly shines when we deal with more complex random variables. This practice introduces an elegant and powerful problem-solving strategy: the method of indicator functions, which relies on the linearity of expectation. By representing the cardinality of a randomly chosen set as a sum of simpler variables, we can solve a seemingly difficult combinatorial problem with remarkable ease, showcasing a technique that is indispensable in modern probability theory [@problem_id:1418516].", "problem": "Consider a finite set of $N$ distinct elements, $U = \\{1, 2, \\dots, N\\}$, where $N$ is a positive integer. Let $\\Omega$ be the power set of $U$, which is the set of all possible subsets of $U$. We define a probability space $(\\Omega, \\mathcal{F}, P)$ where the sample space is $\\Omega$, the $\\sigma$-algebra $\\mathcal{F}$ is the power set of $\\Omega$, and the probability measure $P$ is uniform, meaning every subset in $\\Omega$ is an equally likely outcome.\n\nLet $X$ be a random variable that maps each subset $S \\in \\Omega$ to its cardinality, i.e., $X(S) = |S|$.\n\nDetermine the expectation of this random variable, $E[X]$, as a function of $N$.", "solution": "The sample space is the power set $\\Omega$ of $U=\\{1,2,\\dots,N\\}$, so $|\\Omega|=2^{N}$. The probability measure is uniform, hence for every subset $S \\subseteq U$, $P(\\{S\\})=\\frac{1}{2^{N}}$.\n\nDefine indicator random variables for each element $i \\in U$ by\n$$\nI_{i}(S)=\\begin{cases}\n1, & \\text{if } i \\in S,\\\\\n0, & \\text{if } i \\notin S.\n\\end{cases}\n$$\nFor any $S \\in \\Omega$, the cardinality satisfies\n$$\nX(S)=|S|=\\sum_{i=1}^{N} I_{i}(S).\n$$\nTaking expectation and using linearity of expectation,\n$$\nE[X]=E\\left[\\sum_{i=1}^{N} I_{i}\\right]=\\sum_{i=1}^{N} E[I_{i}].\n$$\nFor a fixed $i$, $E[I_{i}]=P(i \\in S)$. Under the uniform measure on $\\Omega$, exactly those subsets containing $i$ contribute, and there are $2^{N-1}$ such subsets (each determined by an arbitrary choice of elements from $U \\setminus \\{i\\}$). Therefore,\n$$\nP(i \\in S)=\\frac{2^{N-1}}{2^{N}}=\\frac{1}{2},\n$$\nso\n$$\nE[I_{i}]=\\frac{1}{2}.\n$$\nHence,\n$$\nE[X]=\\sum_{i=1}^{N} \\frac{1}{2}=\\frac{N}{2}.\n$$", "answer": "$$\\boxed{\\frac{N}{2}}$$", "id": "1418516"}, {"introduction": "One of the main motivations for adopting the Lebesgue integral in probability is its superior behavior when dealing with limits of random variables. This exercise presents a famous and important counterexample where the limit of expectations is not equal to the expectation of the limit, i.e., $\\lim_{n \\to \\infty} E[X_n] \\ne E[\\lim_{n \\to \\infty} X_n]$. Analyzing this sequence [@problem_id:1360914] highlights the subtleties of interchanging limit and integration operations and implicitly demonstrates the need for powerful convergence theorems, such as the Dominated Convergence Theorem.", "problem": "Consider a sequence of random variables $\\{X_n\\}_{n=1}^{\\infty}$ defined on the probability space $(\\Omega, \\mathcal{F}, P)$, where the sample space is the unit interval $\\Omega = [0, 1]$, the sigma-algebra $\\mathcal{F}$ is the Borel sigma-algebra on $[0,1]$, and the probability measure $P$ is the Lebesgue measure on $[0,1]$ (corresponding to a continuous uniform distribution).\n\nEach random variable in the sequence is defined by the function $X_n(\\omega) = n \\cdot I_{(0, 1/n)}(\\omega)$, where $I_A(\\omega)$ is the indicator function for the set $A$, which equals 1 if $\\omega \\in A$ and 0 otherwise.\n\nThis sequence can be interpreted as a simplified model for a series of high-intensity, short-duration phenomena. As $n$ increases, the magnitude of the outcome, $n$, grows, while the interval over which it occurs, $(0, 1/n)$, shrinks.\n\nYour task is to analyze the limiting behavior of the expectations of this sequence.\n1.  First, calculate the limit of the expected values, denoted as $L_E = \\lim_{n \\to \\infty} E[X_n]$.\n2.  Second, determine the pointwise limit of the sequence of random variables, which we'll call $X(\\omega) = \\lim_{n \\to \\infty} X_n(\\omega)$ for each $\\omega \\in [0, 1]$. Then, calculate the expectation of this limiting random variable, denoted as $E_L = E[X]$.\n\nProvide the values of $L_E$ and $E_L$ as an ordered pair $(L_E, E_L)$.", "solution": "We are given $X_{n}(\\omega)=n\\,I_{(0,1/n)}(\\omega)$ on $\\Omega=[0,1]$ with Lebesgue measure $P$. By definition of expectation for a nonnegative measurable function,\n$$\nE[X_{n}]=\\int_{0}^{1}X_{n}(\\omega)\\,d\\omega=\\int_{0}^{1}n\\,I_{(0,1/n)}(\\omega)\\,d\\omega.\n$$\nUsing linearity of the integral and the property $\\int I_{A}\\,dP=P(A)$,\n$$\nE[X_{n}]=n\\,P\\big((0,1/n)\\big)=n\\cdot\\frac{1}{n}=1.\n$$\nTherefore, the limit of the expectations is\n$$\nL_{E}=\\lim_{n\\to\\infty}E[X_{n}]=\\lim_{n\\to\\infty}1=1.\n$$\n\nNext, fix $\\omega\\in[0,1]$ and analyze the pointwise limit $X(\\omega)=\\lim_{n\\to\\infty}X_{n}(\\omega)$. If $\\omega=0$, then $I_{(0,1/n)}(0)=0$ for all $n$, hence $X_{n}(0)=0$ for all $n$ and $\\lim_{n\\to\\infty}X_{n}(0)=0$. If $\\omega>0$, choose $N\\in\\mathbb{N}$ with $N>\\frac{1}{\\omega}$, which implies that for all $n\\geq N$ we have $\\frac{1}{n}<\\omega$, so $\\omega\\notin(0,1/n)$ and $I_{(0,1/n)}(\\omega)=0$. Thus $X_{n}(\\omega)=0$ for all sufficiently large $n$, and therefore $\\lim_{n\\to\\infty}X_{n}(\\omega)=0$. It follows that\n$$\nX(\\omega)=0\\quad\\text{for all }\\omega\\in[0,1].\n$$\nHence $X\\equiv 0$ almost everywhere, and its expectation is\n$$\nE_{L}=E[X]=\\int_{0}^{1}0\\,d\\omega=0.\n$$\n\nTherefore, the ordered pair is $(L_{E},E_{L})=(1,0)$.", "answer": "$$\\boxed{\\begin{pmatrix}1 & 0\\end{pmatrix}}$$", "id": "1360914"}]}