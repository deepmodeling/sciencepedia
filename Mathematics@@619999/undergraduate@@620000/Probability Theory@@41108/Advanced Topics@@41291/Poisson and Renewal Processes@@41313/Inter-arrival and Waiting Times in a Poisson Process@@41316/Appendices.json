{"hands_on_practices": [{"introduction": "The waiting time for the $k$-th event in a Poisson process is a fundamental concept, governed by the Gamma distribution. This first exercise provides a direct application for calculating the expected value, or mean, of this waiting time. By working through this problem [@problem_id:1366250], you'll solidify the crucial connection between the process rate $\\lambda$ and the average time it takes for a specific number of events to occur.", "problem": "A physicist is operating a small, heavily shielded particle detector designed to capture rare cosmic ray events. The detection of these specific events can be modeled as occurring randomly and independently over time. Based on long-term observation, the detector registers an average of 3.5 of these events per day.\n\nWhat is the expected waiting time, starting from an arbitrary point in time, until the detector has registered its 6th event? Express your answer in units of days, rounded to three significant figures.", "solution": "Model the detections as a homogeneous Poisson process with rate $\\lambda$ events per day. Given the average is $3.5$ events per day, set $\\lambda=3.5$.\n\nIn a Poisson process, interarrival times $X_{i}$ are independent and identically distributed exponential random variables with parameter $\\lambda$, so $\\mathbb{E}[X_{i}]=\\frac{1}{\\lambda}$. The waiting time to the $k$-th event is the sum $T_{k}=\\sum_{i=1}^{k}X_{i}$, which has a Gamma (Erlang) distribution with shape $k$ and rate $\\lambda$. By linearity of expectation,\n$$\n\\mathbb{E}[T_{k}]=\\sum_{i=1}^{k}\\mathbb{E}[X_{i}]=\\frac{k}{\\lambda}.\n$$\nFor $k=6$ and $\\lambda=3.5=\\frac{7}{2}$,\n$$\n\\mathbb{E}[T_{6}]=\\frac{6}{3.5}=\\frac{6}{\\frac{7}{2}}=\\frac{12}{7}\\ \\text{days}\\approx 1.714285\\ \\text{days}.\n$$\nRounded to three significant figures, this is $1.71$ days.", "answer": "$$\\boxed{1.71}$$", "id": "1366250"}, {"introduction": "Moving beyond simple averages, we can explore more subtle and powerful relationships within the Poisson process. This practice [@problem_id:1366219] challenges you to think about the relative timing of the first two events, a question that appears more complex than it is. The key to the solution lies in translating the problem from the language of waiting times ($S_k$) back to the simpler, independent inter-arrival times ($X_i$), revealing an elegant result that deepens your intuition about the process.", "problem": "In a deep underground laboratory, an experiment is designed to detect hypothetical weakly interacting particles. The detection events are modeled as a Poisson process with a constant average rate of $\\lambda$ events per unit time. Let $S_1$ be the waiting time for the first detection event and $S_2$ be the waiting time for the second detection event, both measured from the start of the experiment at $t=0$. A theoretical physicist proposes a test based on the relative timing of these first two events. To evaluate this test, calculate the probability that the waiting time for the second event is more than twice the waiting time for the first event, i.e., find $P(S_2 > 2S_1)$. Your final answer should be a single numerical value, which can be expressed as a fraction or a decimal.", "solution": "Let $\\{N(t): t \\geq 0\\}$ be a Poisson process with constant rate $\\lambda$. The interarrival times $X_{1}$ and $X_{2}$ are independent and identically distributed with $X_{i} \\sim \\text{Exp}(\\lambda)$, having density $f_{X}(x) = \\lambda \\exp(-\\lambda x)$ for $x \\geq 0$. The waiting times for the first and second events are $S_{1} = X_{1}$ and $S_{2} = X_{1} + X_{2}$.\n\nThe event of interest is\n$$\n\\{S_{2} > 2 S_{1}\\} = \\{X_{1} + X_{2} > 2 X_{1}\\} = \\{X_{2} > X_{1}\\}.\n$$\nThus,\n$$\nP(S_{2} > 2 S_{1}) = P(X_{2} > X_{1}).\n$$\nSince $X_{1}$ and $X_{2}$ are i.i.d. continuous random variables, by symmetry $P(X_{2} > X_{1}) = \\frac{1}{2}$. For completeness, compute it by integration:\n$$\nP(X_{2} > X_{1}) = \\int_{0}^{\\infty} P(X_{2} > x_{1}) f_{X_{1}}(x_{1}) \\, dx_{1}\n= \\int_{0}^{\\infty} \\left[\\int_{x_{1}}^{\\infty} \\lambda \\exp(-\\lambda x_{2}) \\, dx_{2}\\right] \\lambda \\exp(-\\lambda x_{1}) \\, dx_{1}.\n$$\nEvaluate the inner integral:\n$$\n\\int_{x_{1}}^{\\infty} \\lambda \\exp(-\\lambda x_{2}) \\, dx_{2} = \\exp(-\\lambda x_{1}).\n$$\nTherefore,\n$$\nP(X_{2} > X_{1}) = \\int_{0}^{\\infty} \\lambda \\exp(-\\lambda x_{1}) \\exp(-\\lambda x_{1}) \\, dx_{1}\n= \\int_{0}^{\\infty} \\lambda \\exp(-2 \\lambda x_{1}) \\, dx_{1}\n= \\left[-\\frac{1}{2} \\exp(-2 \\lambda x_{1})\\right]_{0}^{\\infty}\n= \\frac{1}{2}.\n$$\nHence,\n$$\nP(S_{2} > 2 S_{1}) = \\frac{1}{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1366219"}, {"introduction": "Our final practice delves into the important topic of conditional probability within the context of a Poisson process. Here, we investigate what we can know about the past, given information about a later event. Specifically, by determining the probability distribution of the first arrival time, given that we know exactly when the second arrival occurred [@problem_id:1366223], you will uncover a fundamental property regarding how Poisson events are distributed in time and gain valuable experience with conditional probability density functions.", "problem": "A sensitive radiation detector is modeled as recording particle arrivals according to a Poisson process with a constant average rate of $\\lambda$ particles per second. Let $S_1$ and $S_2$ be the random variables representing the times (in seconds) of the first and second particle arrivals, respectively, measured from the moment the detector is switched on at time $t=0$. An experiment is conducted, and it is observed that the second particle arrives at exactly time $t_{obs}$. Determine the conditional Probability Density Function (PDF) of the first arrival time, $S_1$, given that $S_2 = t_{obs}$. Your answer should be the expression for $f_{S_1|S_2}(s_1 | t_{obs})$ valid for the interval $0  s_1  t_{obs}$.", "solution": "To find the conditional Probability Density Function (PDF) $f_{S_1|S_2}(s_1 | t_{obs})$, we use the definition of conditional probability for continuous random variables:\n$$f_{S_1|S_2}(s_1|s_2) = \\frac{f_{S_1, S_2}(s_1, s_2)}{f_{S_2}(s_2)}$$\nwhere $f_{S_1, S_2}(s_1, s_2)$ is the joint PDF of the first two arrival times, and $f_{S_2}(s_2)$ is the marginal PDF of the second arrival time. We will evaluate this for the given condition $s_2 = t_{obs}$.\n\nFirst, let's determine the joint PDF $f_{S_1, S_2}(s_1, s_2)$. We can derive this from the properties of the inter-arrival times in a Poisson process. Let $T_1 = S_1$ be the time of the first arrival, and $T_2 = S_2 - S_1$ be the time between the first and second arrivals. For a Poisson process with rate $\\lambda$, the inter-arrival times $T_1, T_2, \\dots$ are independent and identically distributed (i.i.d.) exponential random variables with rate $\\lambda$. The PDF of an exponential random variable $T$ with rate $\\lambda$ is $f_T(\\tau) = \\lambda \\exp(-\\lambda \\tau)$ for $\\tau \\ge 0$.\n\nSince $T_1$ and $T_2$ are independent, their joint PDF is the product of their individual PDFs:\n$$f_{T_1, T_2}(t_1, t_2) = f_{T_1}(t_1) f_{T_2}(t_2) = (\\lambda \\exp(-\\lambda t_1))(\\lambda \\exp(-\\lambda t_2)) = \\lambda^2 \\exp(-\\lambda(t_1 + t_2))$$\nThis is valid for $t_1 \\ge 0$ and $t_2 \\ge 0$.\n\nNext, we perform a change of variables to find the joint PDF of $S_1$ and $S_2$. The transformation is $S_1 = T_1$ and $S_2 = T_1 + T_2$. The inverse transformation is $T_1 = S_1$ and $T_2 = S_2 - S_1$. The domain $t_1 \\ge 0, t_2 \\ge 0$ transforms to $s_1 \\ge 0$ and $s_2 - s_1 \\ge 0$, which implies $0 \\le s_1 \\le s_2$.\n\nThe Jacobian of the inverse transformation is:\n$$J = \\det \\begin{pmatrix} \\frac{\\partial t_1}{\\partial s_1}  \\frac{\\partial t_1}{\\partial s_2} \\\\ \\frac{\\partial t_2}{\\partial s_1}  \\frac{\\partial t_2}{\\partial s_2} \\end{pmatrix} = \\det \\begin{pmatrix} 1  0 \\\\ -1  1 \\end{pmatrix} = (1)(1) - (0)(-1) = 1$$\nThe absolute value of the Jacobian is $|J|=1$.\n\nThe joint PDF of $S_1$ and $S_2$ is then:\n$$f_{S_1, S_2}(s_1, s_2) = f_{T_1, T_2}(s_1, s_2 - s_1) |J| = \\lambda^2 \\exp(-\\lambda(s_1 + (s_2 - s_1))) \\cdot 1 = \\lambda^2 \\exp(-\\lambda s_2)$$\nThis is valid for the domain $0 \\le s_1 \\le s_2$.\n\nNow, we need to find the marginal PDF of $S_2$, $f_{S_2}(s_2)$. We can obtain this by integrating the joint PDF $f_{S_1, S_2}(s_1, s_2)$ over all possible values of $s_1$:\n$$f_{S_2}(s_2) = \\int_{-\\infty}^{\\infty} f_{S_1, S_2}(s_1, s_2) \\, ds_1 = \\int_{0}^{s_2} \\lambda^2 \\exp(-\\lambda s_2) \\, ds_1$$\nSince $\\lambda^2 \\exp(-\\lambda s_2)$ is constant with respect to $s_1$, we have:\n$$f_{S_2}(s_2) = \\lambda^2 \\exp(-\\lambda s_2) \\int_{0}^{s_2} \\, ds_1 = \\lambda^2 \\exp(-\\lambda s_2) [s_1]_0^{s_2} = \\lambda^2 s_2 \\exp(-\\lambda s_2)$$\nThis is valid for $s_2 \\ge 0$. This is the PDF of a Gamma distribution with shape parameter 2 and rate parameter $\\lambda$, as expected for the second arrival time in a Poisson process.\n\nFinally, we can compute the conditional PDF. We substitute $s_2 = t_{obs}$ into our expressions for the joint and marginal PDFs:\n$$f_{S_1|S_2}(s_1 | t_{obs}) = \\frac{f_{S_1, S_2}(s_1, t_{obs})}{f_{S_2}(t_{obs})}$$\nThe variables $s_1$ and $t_{obs}$ must satisfy the domain constraint $0 \\le s_1 \\le t_{obs}$. For values of $s_1$ outside this range, the conditional PDF is zero.\n$$f_{S_1|S_2}(s_1 | t_{obs}) = \\frac{\\lambda^2 \\exp(-\\lambda t_{obs})}{\\lambda^2 t_{obs} \\exp(-\\lambda t_{obs})}$$\nBoth numerator and denominator are non-zero for $t_{obs} > 0$. The terms $\\lambda^2$ and $\\exp(-\\lambda t_{obs})$ cancel out, leaving:\n$$f_{S_1|S_2}(s_1 | t_{obs}) = \\frac{1}{t_{obs}}$$\nThis result is valid for $0  s_1  t_{obs}$. This indicates that given the second arrival occurred at time $t_{obs}$, the first arrival time $S_1$ is uniformly distributed over the interval $(0, t_{obs})$.", "answer": "$$\\boxed{\\frac{1}{t_{obs}}}$$", "id": "1366223"}]}