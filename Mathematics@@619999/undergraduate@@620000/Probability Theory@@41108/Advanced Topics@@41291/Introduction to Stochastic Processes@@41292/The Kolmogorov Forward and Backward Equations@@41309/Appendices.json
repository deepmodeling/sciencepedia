{"hands_on_practices": [{"introduction": "We begin our hands-on practice with the fundamental building block of continuous-time Markov chains: the two-state system. By analyzing a simple, intuitive model of a stochastic traffic light [@problem_id:1399783], you will learn the core skill of translating transition rates into a system of differential equations known as the Kolmogorov forward equations. Solving this system will reveal the explicit formula for the probability of being in a particular state at any given time $t$, providing a complete picture of the system's dynamics.", "problem": "Consider a simplified model for a single traffic intersection controlled by a stochastic signal. The traffic light can be in one of two states: State 0, where the North-South direction has a green light, or State 1, where the East-West direction has a green light. The system behaves as a continuous-time Markov process.\n\nThe light does not operate on a fixed timer. Instead, if the light is in State 0 ('North-South green'), it has a constant rate $\\lambda_1$ of switching to State 1 ('East-West green'). Conversely, if the light is in State 1, it has a constant rate $\\lambda_2$ of switching back to State 0. The rates $\\lambda_1$ and $\\lambda_2$ have units of inverse time.\n\nAssume that at time $t=0$, the system is definitively in State 0 ('North-South green').\n\nDetermine the probability that the light is in State 0 at a later time $t > 0$. Your answer should be an analytic expression in terms of $\\lambda_1$, $\\lambda_2$, and $t$.", "solution": "Let $X(t) \\in \\{0,1\\}$ denote the traffic light state at time $t$, with transition rates $\\lambda_{1}$ from $0 \\to 1$ and $\\lambda_{2}$ from $1 \\to 0$. This is a two-state continuous-time Markov chain with generator\n$$\nQ=\\begin{pmatrix}\n-\\lambda_{1} & \\lambda_{1} \\\\\n\\lambda_{2} & -\\lambda_{2}\n\\end{pmatrix}.\n$$\nLet $p_{0}(t)=\\mathbb{P}(X(t)=0)$ and $p_{1}(t)=\\mathbb{P}(X(t)=1)=1-p_{0}(t)$. The Kolmogorov forward equations give\n$$\n\\frac{d}{dt}p_{0}(t)=-\\lambda_{1}p_{0}(t)+\\lambda_{2}p_{1}(t)=-\\left(\\lambda_{1}+\\lambda_{2}\\right)p_{0}(t)+\\lambda_{2},\n$$\nwith initial condition $p_{0}(0)=1$.\n\nThis is a first-order linear ODE. Using the integrating factor $\\exp\\!\\left((\\lambda_{1}+\\lambda_{2})t\\right)$, we obtain\n$$\n\\frac{d}{dt}\\Big(p_{0}(t)\\exp\\!\\left((\\lambda_{1}+\\lambda_{2})t\\right)\\Big)=\\lambda_{2}\\exp\\!\\left((\\lambda_{1}+\\lambda_{2})t\\right).\n$$\nIntegrating from $0$ to $t$:\n$$\np_{0}(t)\\exp\\!\\left((\\lambda_{1}+\\lambda_{2})t\\right)-p_{0}(0)=\\lambda_{2}\\int_{0}^{t}\\exp\\!\\left((\\lambda_{1}+\\lambda_{2})s\\right)\\,ds\n=\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\left(\\exp\\!\\left((\\lambda_{1}+\\lambda_{2})t\\right)-1\\right).\n$$\nSolving for $p_{0}(t)$ and using $p_{0}(0)=1$:\n$$\np_{0}(t)=\\exp\\!\\left(-(\\lambda_{1}+\\lambda_{2})t\\right)+\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}\\left(1-\\exp\\!\\left(-(\\lambda_{1}+\\lambda_{2})t\\right)\\right)\n=\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}+\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}\\exp\\!\\left(-(\\lambda_{1}+\\lambda_{2})t\\right).\n$$\nThis is the required probability that the light is in State $0$ at time $t>0$.", "answer": "$$\\boxed{\\frac{\\lambda_{2}}{\\lambda_{1}+\\lambda_{2}}+\\frac{\\lambda_{1}}{\\lambda_{1}+\\lambda_{2}}\\exp\\!\\left(-(\\lambda_{1}+\\lambda_{2})t\\right)}$$", "id": "1399783"}, {"introduction": "Building on the two-state model, we now explore systems that progress through multiple stages, a common scenario in reliability engineering, biology, and chemistry. This exercise models the life cycle of a component from 'New' to 'Worn' to 'Failed', introducing the important concept of an absorbing state [@problem_id:1399745]. Your task is not just to find the probability of being in the intermediate 'Worn' state, but to use calculus to determine when this probability is maximized, demonstrating how these probabilistic models are used to answer critical real-world questions.", "problem": "A newly manufactured electronic component is subject to wear and eventual failure. Its condition can be modeled as a continuous-time stochastic process with three states: State 1 ('New'), State 2 ('Worn'), and State 3 ('Failed'). A component always begins its life in State 1.\n\nThe transition from the 'New' state to the 'Worn' state occurs as a Poisson process with a constant rate $\\lambda_1$. Similarly, the transition from the 'Worn' state to the 'Failed' state occurs as a Poisson process with a constant rate $\\lambda_2$. The 'Failed' state is an absorbing state, meaning no further transitions occur once a component has failed. This model reflects accelerated degradation, so it is given that $0 < \\lambda_1 < \\lambda_2$.\n\nDetermine the time $t$ at which the probability of the component being in the 'Worn' state is maximized. Express your answer as a symbolic expression in terms of $\\lambda_1$ and $\\lambda_2$.", "solution": "Let $T_{1}$ denote the random time to transition from State 1 to State 2. Since this transition occurs as a Poisson process with constant rate $\\lambda_{1}$, we have $T_{1} \\sim \\text{Exp}(\\lambda_{1})$ with density $f_{T_{1}}(s) = \\lambda_{1} \\exp(-\\lambda_{1} s)$ for $s \\geq 0$. Let $T_{2}$ denote the random time to transition from State 2 to State 3 after entering State 2; since this occurs with constant rate $\\lambda_{2}$ and by the memoryless property, $T_{2} \\sim \\text{Exp}(\\lambda_{2})$ and is independent of $T_{1}$.\n\nThe component is in the 'Worn' state at time $t$ if and only if the transition to State 2 has already occurred by time $t$ and the subsequent transition to State 3 has not yet occurred by time $t$. This event is $\\{T_{1} \\leq t,\\ T_{1} + T_{2} > t\\}$. Using independence and conditioning on $T_{1} = s$, we obtain\n$$\nP_{2}(t) = \\int_{0}^{t} f_{T_{1}}(s) \\, \\mathbb{P}(T_{2} > t - s) \\, ds \n= \\int_{0}^{t} \\lambda_{1} \\exp(-\\lambda_{1} s) \\exp(-\\lambda_{2} (t - s)) \\, ds.\n$$\nFactor out $\\exp(-\\lambda_{2} t)$ and integrate:\n$$\nP_{2}(t) = \\lambda_{1} \\exp(-\\lambda_{2} t) \\int_{0}^{t} \\exp\\big((\\lambda_{2} - \\lambda_{1}) s\\big) \\, ds \n= \\lambda_{1} \\exp(-\\lambda_{2} t) \\cdot \\frac{\\exp\\big((\\lambda_{2} - \\lambda_{1}) t\\big) - 1}{\\lambda_{2} - \\lambda_{1}}.\n$$\nThis simplifies to the known form\n$$\nP_{2}(t) = \\frac{\\lambda_{1}}{\\lambda_{2} - \\lambda_{1}} \\left( \\exp(-\\lambda_{1} t) - \\exp(-\\lambda_{2} t) \\right).\n$$\n\nTo find the time $t$ that maximizes $P_{2}(t)$, differentiate with respect to $t$ and set the derivative to zero:\n$$\nP_{2}'(t) = \\frac{\\lambda_{1}}{\\lambda_{2} - \\lambda_{1}} \\left( -\\lambda_{1} \\exp(-\\lambda_{1} t) + \\lambda_{2} \\exp(-\\lambda_{2} t) \\right) = 0.\n$$\nThus\n$$\n-\\lambda_{1} \\exp(-\\lambda_{1} t) + \\lambda_{2} \\exp(-\\lambda_{2} t) = 0\n\\quad \\Longleftrightarrow \\quad\n\\lambda_{2} \\exp(-\\lambda_{2} t) = \\lambda_{1} \\exp(-\\lambda_{1} t).\n$$\nRearranging gives\n$$\n\\exp\\big( -(\\lambda_{2} - \\lambda_{1}) t \\big) = \\frac{\\lambda_{1}}{\\lambda_{2}}\n\\quad \\Longrightarrow \\quad\nt^{\\ast} = \\frac{1}{\\lambda_{2} - \\lambda_{1}} \\ln\\!\\left( \\frac{\\lambda_{2}}{\\lambda_{1}} \\right).\n$$\nSince $0 < \\lambda_{1} < \\lambda_{2}$, we have $\\ln(\\lambda_{2}/\\lambda_{1}) > 0$, so $t^{\\ast} \\geq 0$. Moreover, $P_{2}(0) = 0$ and $\\lim_{t \\to \\infty} P_{2}(t) = 0$, and evaluating the second derivative at $t^{\\ast}$ yields\n$$\nP_{2}''(t^{\\ast}) = \\frac{\\lambda_{1}}{\\lambda_{2} - \\lambda_{1}} \\left( \\lambda_{1}^{2} \\exp(-\\lambda_{1} t^{\\ast}) - \\lambda_{2}^{2} \\exp(-\\lambda_{2} t^{\\ast}) \\right) \n= \\frac{\\lambda_{1}}{\\lambda_{2} - \\lambda_{1}} \\lambda_{2} (\\lambda_{1} - \\lambda_{2}) \\exp(-\\lambda_{2} t^{\\ast}) < 0,\n$$\nconfirming that $t^{\\ast}$ is the unique time maximizing $P_{2}(t)$.\n\nTherefore, the probability of being in the 'Worn' state is maximized at\n$$\nt^{\\ast} = \\frac{1}{\\lambda_{2} - \\lambda_{1}} \\ln\\!\\left( \\frac{\\lambda_{2}}{\\lambda_{1}} \\right).\n$$", "answer": "$$\\boxed{\\frac{1}{\\lambda_{2}-\\lambda_{1}} \\ln\\!\\left(\\frac{\\lambda_{2}}{\\lambda_{1}}\\right)}$$", "id": "1399745"}, {"introduction": "Our final practice shifts the focus from asking *where* the process will be at time $t$ to asking *how long* it takes to reach a specific state for the first time. This class of problems, concerning first-passage times, is often best addressed using the Kolmogorov backward equations. In this advanced problem [@problem_id:1399808], you will analyze the time to failure in a model of a quantum memory cell, a crucial question for device reliability. You will derive the Laplace transform of the first-passage time distribution, a powerful technique that converts differential equations into algebraic ones and is a cornerstone of advanced stochastic modeling.", "problem": "A simplified model for the state of a single quantum-dot memory cell involves a continuous-time Markov chain on the state space $S = \\{0, 1, 2\\}$. State 0 represents the desired \"data-written\" ground state. State 1 is an unstable excited state. State 2 is a permanent, non-recoverable \"corrupted\" error state, which acts as an absorbing state.\n\nFrom the ground state (State 0), thermal energy can cause a transition to the excited state (State 1) at a rate $\\alpha > 0$. From the excited state (State 1), the cell can either relax back to the ground state at a rate $\\beta > 0$ or tunnel into the corrupted state (State 2) at a rate $\\gamma > 0$. No other transitions are possible.\n\nThe memory cell is initialized in the ground state (State 0) at time $t=0$. The reliability of the cell is related to how long it remains functional before failure. Let $T$ be the random variable for the first-passage time from the initial ground state to the corrupted state.\n\nDerive an expression for the Laplace transform of the probability density function of this first-passage time, $T$. Express your answer in terms of the variable $s$ and the constant positive rates $\\alpha$, $\\beta$, and $\\gamma$.", "solution": "Let $X(t)$ be the state of the system at time $t$. The system is a continuous-time Markov chain with state space $S = \\{0, 1, 2\\}$. The problem asks for the Laplace transform of the probability density function of the first-passage time to state 2, given the system starts in state 0. Let $T_{iJ}$ be the first-passage time from state $i$ to a target set of states $J$. We are interested in $T_{02}$, so the starting state is $i=0$ and the target set is $J=\\{2\\}$.\n\nLet $\\phi_i(s) = E[\\exp(-s T_{iJ}) | X(0)=i]$ be the Laplace transform of the probability density function for the first-passage time from state $i$ to the set $J$. Our goal is to find $\\phi_0(s)$ for the target set $J=\\{2\\}$.\n\nWe can derive a system of equations for $\\phi_i(s)$ by considering the process over an infinitesimal time interval $\\delta t$. For any state $i \\notin J$, we condition on the first step of the process.\nIn a small time interval $\\delta t$, the system starting in state $i$ can either jump to another state $j \\neq i$ with probability $q_{ij}\\delta t + o(\\delta t)$, or it can remain in state $i$ with probability $1 - q_i \\delta t + o(\\delta t)$, where $q_{ij}$ is the transition rate from $i$ to $j$ and $q_i = \\sum_{j \\neq i} q_{ij}$ is the total rate of leaving state $i$.\n\nBy the law of total expectation and the memoryless property of the Markov chain:\n$$ \\phi_i(s) = E[\\exp(-s T_{iJ})] = (1 - q_i \\delta t) E[\\exp(-s(\\delta t + T_{iJ}))] + \\sum_{j \\neq i} (q_{ij}\\delta t) E[\\exp(-s(\\delta t + T_{jJ}))] + o(\\delta t) $$\nUsing the approximation $\\exp(-s\\delta t) \\approx 1-s\\delta t$ and the independence of the increment and future evolution, this becomes:\n$$ \\phi_i(s) \\approx (1 - q_i \\delta t)(1 - s \\delta t) \\phi_i(s) + \\sum_{j \\neq i} (q_{ij}\\delta t)(1 - s \\delta t) \\phi_j(s) $$\nExpanding this and keeping only terms up to first order in $\\delta t$:\n$$ \\phi_i(s) \\approx (1 - (q_i+s)\\delta t) \\phi_i(s) + \\sum_{j \\neq i} (q_{ij}\\delta t) \\phi_j(s) $$\nRearranging the terms:\n$$ (q_i+s)\\delta t \\phi_i(s) \\approx \\sum_{j \\neq i} (q_{ij}\\delta t) \\phi_j(s) $$\nDividing by $\\delta t$ and taking the limit as $\\delta t \\to 0$, we get the system of equations for $i \\notin J$:\n$$ (s + q_i) \\phi_i(s) = \\sum_{j \\neq i} q_{ij} \\phi_j(s) $$\nFor any state $k \\in J$, the first-passage time $T_{kJ}$ is zero by definition. Therefore, we have the boundary condition:\n$$ \\phi_k(s) = E[\\exp(-s \\cdot 0)] = 1 \\quad \\text{for } k \\in J $$\nNow, we apply this framework to our specific problem.\nThe states are $\\{0, 1, 2\\}$. The starting state is $i=0$ and the target set is $J=\\{2\\}$.\nThe non-zero transition rates are $q_{01} = \\alpha$, $q_{10} = \\beta$, and $q_{12} = \\gamma$.\nThe total exit rates for the non-target states are $q_0 = q_{01} = \\alpha$ and $q_1 = q_{10} + q_{12} = \\beta + \\gamma$.\n\nWe need to solve for $\\phi_0(s)$ and $\\phi_1(s)$. The boundary condition is $\\phi_2(s) = 1$.\n\nFor state $i=0$ (not in $J$):\n$$ (s + q_0)\\phi_0(s) = q_{01}\\phi_1(s) + q_{02}\\phi_2(s) $$\nSince $q_{02}=0$, this simplifies to:\n$$ (s + \\alpha)\\phi_0(s) = \\alpha\\phi_1(s) \\quad (1) $$\n\nFor state $i=1$ (not in $J$):\n$$ (s + q_1)\\phi_1(s) = q_{10}\\phi_0(s) + q_{12}\\phi_2(s) $$\nSubstituting the rates and the boundary condition $\\phi_2(s)=1$:\n$$ (s + \\beta + \\gamma)\\phi_1(s) = \\beta\\phi_0(s) + \\gamma \\cdot 1 \\quad (2) $$\nWe have a system of two linear equations for $\\phi_0(s)$ and $\\phi_1(s)$. We want to find $\\phi_0(s)$.\nFrom equation (1), we express $\\phi_1(s)$ in terms of $\\phi_0(s)$:\n$$ \\phi_1(s) = \\frac{s+\\alpha}{\\alpha}\\phi_0(s) $$\nNow, substitute this expression into equation (2):\n$$ (s + \\beta + \\gamma)\\left(\\frac{s+\\alpha}{\\alpha}\\phi_0(s)\\right) = \\beta\\phi_0(s) + \\gamma $$\nLet's solve for $\\phi_0(s)$. First, group the terms with $\\phi_0(s)$:\n$$ \\left[ \\frac{(s + \\beta + \\gamma)(s+\\alpha)}{\\alpha} - \\beta \\right] \\phi_0(s) = \\gamma $$\nFind a common denominator for the term in the brackets:\n$$ \\left[ \\frac{s^2 + \\alpha s + (\\beta+\\gamma)s + \\alpha(\\beta+\\gamma) - \\alpha\\beta}{\\alpha} \\right] \\phi_0(s) = \\gamma $$\n$$ \\left[ \\frac{s^2 + s(\\alpha+\\beta+\\gamma) + \\alpha\\beta + \\alpha\\gamma - \\alpha\\beta}{\\alpha} \\right] \\phi_0(s) = \\gamma $$\n$$ \\left[ \\frac{s^2 + s(\\alpha+\\beta+\\gamma) + \\alpha\\gamma}{\\alpha} \\right] \\phi_0(s) = \\gamma $$\nFinally, isolate $\\phi_0(s)$:\n$$ \\phi_0(s) = \\frac{\\alpha\\gamma}{s^2 + s(\\alpha+\\beta+\\gamma) + \\alpha\\gamma} $$\nThis is the desired Laplace transform of the first-passage time probability density function.", "answer": "$$\\boxed{\\frac{\\alpha \\gamma}{s^{2} + s(\\alpha + \\beta + \\gamma) + \\alpha \\gamma}}$$", "id": "1399808"}]}