{"hands_on_practices": [{"introduction": "Stochastic processes can appear abstract, so let's begin with a concrete and visual example. This problem models a knight's movement on a chessboard as a discrete-time Markov chain, where each square is a state and each legal move is a transition. By calculating the probability of returning to the starting position, you will practice the foundational skill of tracking state changes and applying the rules of conditional probability in a simple, tangible setting. [@problem_id:1367723]", "problem": "A knight is placed on an empty 3x3 chessboard. The squares of the board are identified by coordinates (row, column), where the row and column numbers range from 1 to 3. The knight moves in an 'L' shape: two squares in a cardinal direction (horizontal or vertical), followed by one square in a perpendicular direction. A move is only considered legal if the knight lands on a square that is within the boundaries of the 3x3 board.\n\nThe knight starts at the corner square (1,1). At each step, it makes a single, randomly chosen legal move. If there are $k$ legal moves available from its current square, the knight chooses any one of them with a probability of $1/k$.\n\nCalculate the probability that the knight is back at the starting square (1,1) after making exactly two sequential moves. Express your answer as a fraction.", "solution": "A knight moves by vectors $(\\pm 2,\\pm 1)$ or $(\\pm 1,\\pm 2)$. From the starting corner $(1,1)$ on a $3\\times 3$ board, the legal destinations are those within $\\{1,2,3\\}$ for both coordinates. Enumerating:\n- $(1\\pm 2,1\\pm 1)$ yields $(3,2)$ valid and all others invalid.\n- $(1\\pm 1,1\\pm 2)$ yields $(2,3)$ valid and all others invalid.\nThus the set of legal first moves is $S=\\{(3,2),(2,3)\\}$ with $|S|=2$, and each is chosen with probability $1/2$.\n\nFrom $(3,2)$, legal knight moves within the board are obtained by adding the same move vectors:\n- $(3\\pm 2,2\\pm 1)$ yields $(1,3)$ and $(1,1)$ valid; others are out of bounds.\n- $(3\\pm 1,2\\pm 2)$ are all out of bounds.\nHence there are $k(3,2)=2$ legal moves, and $(1,1)$ is one of them, so the return probability in one move from $(3,2)$ is $1/2$.\n\nFrom $(2,3)$, similarly:\n- $(2\\pm 2,3\\pm 1)$ are out of bounds.\n- $(2\\pm 1,3\\pm 2)$ yields $(3,1)$ and $(1,1)$ valid; others are out of bounds.\nHence $k(2,3)=2$, and the return probability in one move from $(2,3)$ is $1/2$.\n\nBy the law of total probability, letting $X_{t}$ be the position after $t$ moves,\n$$\n\\Pr\\big(X_{2}=(1,1)\\big)\n=\\sum_{v\\in S}\\Pr\\big(X_{1}=v\\big)\\Pr\\big(X_{2}=(1,1)\\mid X_{1}=v\\big)\n=\\sum_{v\\in S}\\frac{1}{|S|}\\cdot\\frac{1}{k(v)}\n=2\\cdot\\frac{1}{2}\\cdot\\frac{1}{2}\n=\\frac{1}{2}.\n$$\nTherefore, the probability of being back at $(1,1)$ after exactly two moves is $\\frac{1}{2}$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "1367723"}, {"introduction": "After exploring an intuitive example of a Markov chain, it's crucial to solidify the formal definition. This problem challenges you to test whether a process possesses the \"memoryless\" Markov property, a cornerstone concept that dictates that the future is conditionally independent of the past given the present state. Working through this exercise sharpens your analytical skills by forcing you to look beyond the surface construction of a process and rigorously check its fundamental properties. [@problem_id:1367774]", "problem": "Consider a sequence of independent, identically distributed (i.i.d.) random variables $\\{X_n\\}_{n \\ge 0}$, where each random variable can take the value $1$ or $-1$ with equal probability, i.e., $P(X_n=1) = P(X_n=-1) = 0.5$.\n\nA new stochastic process $\\{Y_n\\}_{n \\ge 1}$ is constructed from this sequence as a simple moving average:\n$$Y_n = \\frac{1}{2}(X_n + X_{n-1})$$\nNow, consider the following assertion: \"The stochastic process $\\{Y_n\\}_{n \\ge 1}$ is a Markov process.\"\n\nWhich of the following statements correctly evaluates this assertion and provides the correct justification?\n\nA. The assertion is true. A process built from i.i.d. random variables is always a Markov process.\n\nB. The assertion is false. To predict the distribution of $Y_{n+1} = \\frac{1}{2}(X_{n+1} + X_n)$, knowing the current state $Y_n = \\frac{1}{2}(X_n + X_{n-1})$ is not enough. The past state $Y_{n-1}$ provides more information about $X_{n-1}$, which in turn helps specify $X_n$ from $Y_n$, thereby changing the prediction for $Y_{n+1}$.\n\nC. The assertion is true. The future state $Y_{n+1}$ only depends on the current state $Y_n$ and the new random variable $X_{n+1}$, which is the definition of a Markov process.\n\nD. The assertion is false. A process can only be a Markov process if its expectation is non-zero, but $E[Y_n] = 0$.\n\nE. The assertion is true. The process is time-homogeneous, meaning its transition probabilities are independent of the time step $n$, which implies it must be a Markov process.", "solution": "We are given i.i.d. random variables $\\{X_{n}\\}_{n \\ge 0}$ with $P(X_{n}=1)=P(X_{n}=-1)=\\frac{1}{2}$, and a process $\\{Y_{n}\\}_{n \\ge 1}$ defined by $Y_{n}=\\frac{1}{2}(X_{n}+X_{n-1})$. The state space of $Y_{n}$ is $\\{-1,0,1\\}$ since $X_{n}+X_{n-1}\\in\\{-2,0,2\\}$.\n\nThe Markov property requires that for all $n\\ge 1$ and all states $y_{n+1},y_{n},y_{n-1},\\dots$,\n$$\nP\\big(Y_{n+1}=y_{n+1}\\,\\big|\\,Y_{n}=y_{n},Y_{n-1}=y_{n-1},\\dots\\big)\n=\nP\\big(Y_{n+1}=y_{n+1}\\,\\big|\\,Y_{n}=y_{n}\\big).\n$$\nWe will show this fails by exhibiting a pair of histories for which the conditional distribution of $Y_{n+1}$ changes when we include $Y_{n-1}$ in addition to $Y_{n}$.\n\nFirst compute the law of $Y_{n+1}$ given only $Y_{n}=0$. The event $Y_{n}=0$ is equivalent to\n$$\n\\frac{1}{2}(X_{n}+X_{n-1})=0 \\quad\\Longleftrightarrow\\quad (X_{n},X_{n-1})\\in\\{(1,-1),(-1,1)\\}.\n$$\nBy independence and symmetry of the $X$â€™s,\n$$\nP\\big(X_{n}=1\\,\\big|\\,Y_{n}=0\\big)=\\frac{1}{2},\\qquad P\\big(X_{n}=-1\\,\\big|\\,Y_{n}=0\\big)=\\frac{1}{2}.\n$$\nConditional on $X_{n}$, we have\n$$\nY_{n+1}=\\frac{1}{2}(X_{n+1}+X_{n}).\n$$\nThus,\n- If $X_{n}=1$, then $Y_{n+1}\\in\\{0,1\\}$ with\n$$\nP\\big(Y_{n+1}=1\\,\\big|\\,X_{n}=1\\big)=\\frac{1}{2},\\quad P\\big(Y_{n+1}=0\\,\\big|\\,X_{n}=1\\big)=\\frac{1}{2},\\quad P\\big(Y_{n+1}=-1\\,\\big|\\,X_{n}=1\\big)=0.\n$$\n- If $X_{n}=-1$, then $Y_{n+1}\\in\\{0,-1\\}$ with\n$$\nP\\big(Y_{n+1}=-1\\,\\big|\\,X_{n}=-1\\big)=\\frac{1}{2},\\quad P\\big(Y_{n+1}=0\\,\\big|\\,X_{n}=-1\\big)=\\frac{1}{2},\\quad P\\big(Y_{n+1}=1\\,\\big|\\,X_{n}=-1\\big)=0.\n$$\nAveraging over $X_{n}$ given $Y_{n}=0$ yields\n$$\nP\\big(Y_{n+1}=1\\,\\big|\\,Y_{n}=0\\big)=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4},\\quad\nP\\big(Y_{n+1}=-1\\,\\big|\\,Y_{n}=0\\big)=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4},\n$$\nand hence\n$$\nP\\big(Y_{n+1}=0\\,\\big|\\,Y_{n}=0\\big)=1-\\frac{1}{4}-\\frac{1}{4}=\\frac{1}{2}.\n$$\n\nNow include the additional information $Y_{n-1}=1$. The event $Y_{n-1}=1$ implies\n$$\n\\frac{1}{2}(X_{n-1}+X_{n-2})=1 \\quad\\Longleftrightarrow\\quad X_{n-1}=1\\ \\text{ and }\\ X_{n-2}=1.\n$$\nCombining $Y_{n}=0$ with $X_{n-1}=1$ gives\n$$\n\\frac{1}{2}(X_{n}+X_{n-1})=0 \\ \\text{ and }\\ X_{n-1}=1 \\quad\\Longleftrightarrow\\quad X_{n}=-1.\n$$\nTherefore, under $\\{Y_{n}=0,\\,Y_{n-1}=1\\}$ we have $X_{n}=-1$ deterministically, so\n$$\nP\\big(Y_{n+1}=1\\,\\big|\\,Y_{n}=0,\\,Y_{n-1}=1\\big)=P\\big(Y_{n+1}=1\\,\\big|\\,X_{n}=-1\\big)=0,\n$$\nwhereas we previously found\n$$\nP\\big(Y_{n+1}=1\\,\\big|\\,Y_{n}=0\\big)=\\frac{1}{4}.\n$$\nSince these probabilities differ, the conditional law of $Y_{n+1}$ given the present state $Y_{n}$ is altered by including the past state $Y_{n-1}$. This violates the Markov property. Hence $\\{Y_{n}\\}$ is not a Markov process.\n\nAmong the options, this matches the reasoning in option B. Options A, C, and E incorrectly infer Markovness from i.i.d. inputs, a dependence on only $Y_{n}$ plus new noise, or time-homogeneity; option D is irrelevant and false.", "answer": "$$\\boxed{B}$$", "id": "1367774"}, {"introduction": "Stochastic processes are powerful tools for modeling real-world systems, from finance to biology. This problem introduces the continuous-time birth-death process, a versatile model for population dynamics, using the hypothetical scenario of self-replicating nanobots. Here, you will explore the critical concept of an absorbing state, learning how the transition rates, particularly at the boundaries of the state space, can fundamentally determine the long-term behavior and ultimate fate of the system. [@problem_id:1367738]", "problem": "A biomedical engineer is developing a mathematical model for the number of active, self-replicating nanobots within a patient's bloodstream. The number of nanobots, $N(t)$, is modeled as a continuous-time birth-death process on the state space of non-negative integers $S = \\{0, 1, 2, \\dots\\}$.\n\nThe dynamics are as follows:\n- When the population size is $n$, a nanobot successfully replicates (a \"birth\") at a rate of $\\lambda_n$, causing a transition from state $n$ to $n+1$.\n- When the population size is $n$, a nanobot is neutralized by the body's immune system (a \"death\") at a rate of $\\mu_n$, causing a transition from state $n$ to $n-1$.\n\nFor the model to be considered safe, it must satisfy a critical property: if the nanobot population is ever completely eliminated (i.e., the system reaches state 0), it must be impossible for the population to grow again from zero. In other words, once the state $n=0$ is reached, the system must remain in that state for all future times.\n\nIt is given that for $n \\ge 1$, both $\\lambda_n > 0$ and $\\mu_n > 0$. The birth rate from state 0 is $\\lambda_0$, and the death rate from state 0 is $\\mu_0$. By the definition of a process on non-negative integers, a transition from state 0 to state -1 is impossible, which implies that $\\mu_0$ is structurally zero.\n\nWhich one of the following conditions on the rates is both necessary and sufficient to guarantee that a completely eliminated nanobot population can never spontaneously reappear?\n\nA. $\\lambda_0 = 0$\nB. $\\mu_1 = 0$\nC. $\\lambda_n = 0$ for all $n \\ge 1$\nD. $\\lambda_n / \\mu_n = 1$ for all $n \\ge 1$\nE. $\\lambda_0 > 0$ and $\\mu_1 > 0$", "solution": "The problem asks for the necessary and sufficient condition to ensure that once the system reaches state 0, it remains there forever. This is the definition of an absorbing state in a Markov process. We need to find the condition on the birth and death rates ($\\lambda_n$ and $\\mu_n$) that makes state 0 an absorbing state.\n\nIn a continuous-time Markov process, a state $k$ is absorbing if and only if the total rate of transitioning out of state $k$ to any other state is zero.\n\nLet's analyze the transitions from state $n=0$. A birth-death process only allows transitions to adjacent states.\nThe possible transitions from state 0 are:\n1.  A \"birth\": A transition from state 0 to state 1. This occurs with rate $\\lambda_0$.\n2.  A \"death\": A transition from state 0 to state -1. This occurs with rate $\\mu_0$.\n\nThe total rate of leaving state 0 is the sum of the rates of all possible outbound transitions, which is $\\lambda_0 + \\mu_0$.\n\nThe problem states that the process is defined on the set of non-negative integers $S = \\{0, 1, 2, \\dots\\}$. This means that a state of -1 is not in the state space, so a transition from 0 to -1 is impossible. Consequently, the rate of such a transition must be zero. Thus, $\\mu_0 = 0$. This is a structural feature of any birth-death process on the non-negative integers, as mentioned in the problem statement.\n\nWith $\\mu_0 = 0$, the only possible transition out of state 0 is the birth transition to state 1, which occurs at rate $\\lambda_0$. For state 0 to be absorbing, the total rate of leaving must be zero. Therefore, we must have:\n$$\n\\lambda_0 + \\mu_0 = \\lambda_0 + 0 = 0\n$$\nThis implies that we must have $\\lambda_0 = 0$.\n\nLet's check if this condition is both necessary and sufficient.\n- **Necessity**: If $\\lambda_0 > 0$, there is a non-zero rate of leaving state 0. This means that if the system is in state 0, it will eventually transition to state 1 with some positive probability. Therefore, state 0 would not be absorbing. So, for state 0 to be absorbing, it is necessary that $\\lambda_0 = 0$.\n- **Sufficiency**: If $\\lambda_0 = 0$, the total rate of leaving state 0 is $\\lambda_0 + \\mu_0 = 0 + 0 = 0$. A zero transition rate means the event will never happen. Hence, if the system enters state 0, it will stay there forever. Thus, $\\lambda_0 = 0$ is a sufficient condition.\n\nSince the condition $\\lambda_0=0$ is both necessary and sufficient, it is the correct answer. Now let's evaluate the given options:\n\nA. $\\lambda_0 = 0$: This is the necessary and sufficient condition we derived. This option is correct.\n\nB. $\\mu_1 = 0$: This condition means that if the system is in state 1, it cannot transition to state 0. This would actually prevent the system from ever reaching the eliminated state from state 1. It makes state 0 harder to reach, but it doesn't determine if state 0 is absorbing.\n\nC. $\\lambda_n = 0$ for all $n \\ge 1$: If all birth rates for $n \\ge 1$ are zero, the process can only experience deaths, so the population will always decrease until it reaches 0. If we also have $\\lambda_0 = 0$, the system will then become trapped at 0. So this is a *sufficient* condition for the system to eventually be absorbed at 0. However, it is not *necessary*. We could have $\\lambda_1 > 0$ and state 0 could still be absorbing, as long as $\\lambda_0 = 0$. Since the question asks for a necessary and sufficient condition, this is not the answer.\n\nD. $\\lambda_n / \\mu_n = 1$ for all $n \\ge 1$: This condition affects the long-term behavior of the process when it is not in state 0 (e.g., whether it is null-recurrent or positive-recurrent), but it has no bearing on whether state 0 itself is an exit or an absorbing boundary. The system can still leave state 0 if $\\lambda_0 > 0$.\n\nE. $\\lambda_0 > 0$ and $\\mu_1 > 0$: The condition $\\lambda_0 > 0$ explicitly makes state 0 *not* absorbing (it is a reflecting boundary). This describes a scenario where the nanobot population can be spontaneously generated from a zero-population state. This is the opposite of the desired behavior.\n\nTherefore, the only condition that is both necessary and sufficient is $\\lambda_0 = 0$.", "answer": "$$\\boxed{A}$$", "id": "1367738"}]}