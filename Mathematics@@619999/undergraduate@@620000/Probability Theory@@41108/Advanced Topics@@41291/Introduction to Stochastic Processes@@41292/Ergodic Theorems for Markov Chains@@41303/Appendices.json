{"hands_on_practices": [{"introduction": "This first exercise provides a direct application of the core concept of a stationary distribution. By modeling a simple automaton's movement as a Markov chain, you will calculate the long-run proportion of time it spends in a particular state [@problem_id:1360494]. This practice is fundamental to understanding how ergodic systems settle into a predictable, steady-state behavior over time.", "problem": "A small automaton moves a token among three squares on a track, labeled 1, 2, and 3 from left to right. The position of the token is updated at discrete time steps according to a set of fixed probabilistic rules. The process can be modeled as a Markov chain where the state is the label of the square the token occupies.\n\nThe rules for the token's movement are as follows:\n- If the token is on square 1, it will always move to square 2 in the next step.\n- If the token is on square 2, it will move to square 1 with a probability of $1/2$ or to square 3 with a probability of $1/2$ in the next step.\n- If the token is on square 3, it will move to square 2 with a probability of $1/3$ or remain on square 3 with a probability of $2/3$ in the next step.\n\nAssuming the automaton runs for a very long time, what is the long-run proportion of time that the token is on square 2? Express your answer as a fraction in simplest form.", "solution": "Model the token’s location as a finite Markov chain with states labeled $1,2,3$. The transition matrix $P$ (rows indexed by current state, columns by next state) is\n$$\nP=\\begin{pmatrix}\n0 & 1 & 0 \\\\\n\\frac{1}{2} & 0 & \\frac{1}{2} \\\\\n0 & \\frac{1}{3} & \\frac{2}{3}\n\\end{pmatrix}.\n$$\nThe chain is irreducible (each state can reach the others) and aperiodic (state $3$ has a self-loop), so it has a unique stationary distribution $\\pi=(\\pi_{1},\\pi_{2},\\pi_{3})$ with $\\pi=\\pi P$ and $\\pi_{1}+\\pi_{2}+\\pi_{3}=1$. Writing $\\pi=\\pi P$ componentwise gives\n$$\n\\pi_{1}=\\frac{1}{2}\\pi_{2},\\qquad\n\\pi_{2}=\\pi_{1}+\\frac{1}{3}\\pi_{3},\\qquad\n\\pi_{3}=\\frac{1}{2}\\pi_{2}+\\frac{2}{3}\\pi_{3}.\n$$\nFrom the first equation, $\\pi_{1}=\\frac{1}{2}\\pi_{2}$. From the third equation,\n$$\n\\pi_{3}-\\frac{2}{3}\\pi_{3}=\\frac{1}{2}\\pi_{2}\\;\\;\\Longrightarrow\\;\\;\\frac{1}{3}\\pi_{3}=\\frac{1}{2}\\pi_{2}\\;\\;\\Longrightarrow\\;\\;\\pi_{3}=\\frac{3}{2}\\pi_{2}.\n$$\nImpose normalization:\n$$\n\\pi_{1}+\\pi_{2}+\\pi_{3}=\\frac{1}{2}\\pi_{2}+\\pi_{2}+\\frac{3}{2}\\pi_{2}=3\\pi_{2}=1,\n$$\nso $\\pi_{2}=\\frac{1}{3}$. This is the long-run proportion of time the token is on square $2$.", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1360494"}, {"introduction": "Building on the basic concept of stationary distributions, this practice explores the famous Ehrenfest model, a cornerstone in statistical mechanics, here framed as a server load-balancing problem [@problem_id:1360469]. You will determine the stationary distribution for a system with a variable number of components, $N$, revealing an elegant connection to a well-known probability distribution. This exercise demonstrates how the principles of ergodicity scale to more complex, structured systems.", "problem": "Consider a simplified model for dynamic load balancing between two identical servers, Server A and Server B. Initially, a total of $N$ independent computational jobs are distributed in some manner between the two servers. The system evolves in discrete time steps according to the following rule: at each step, one of the $N$ jobs is selected uniformly at random (regardless of which server it is currently on) and is immediately moved to the other server.\n\nAssuming the system runs for a very long time, it approaches a statistical equilibrium. Determine the long-run probability that one of the two servers is completely empty (i.e., all $N$ jobs are located on the other server).\n\nExpress your answer as a closed-form analytic expression in terms of $N$.", "solution": "Let $X_{t}$ denote the number of jobs on Server A at time $t$, so $X_{t}\\in\\{0,1,\\dots,N\\}$. The evolution is a birth-death Markov chain with transitions\n$$\n\\mathbb{P}(X_{t+1}=k+1\\,|\\,X_{t}=k)=\\frac{N-k}{N},\\qquad \\mathbb{P}(X_{t+1}=k-1\\,|\\,X_{t}=k)=\\frac{k}{N},\n$$\nwhere choosing a job on Server B moves it to A and increases $k$ by $1$, and choosing a job on Server A moves it to B and decreases $k$ by $1$. At the boundaries, $k=0$ transitions to $1$ with probability $1$, and $k=N$ transitions to $N-1$ with probability $1$.\n\nWe determine the stationary distribution $\\pi=\\{\\pi_{k}\\}_{k=0}^{N}$ by enforcing detailed balance for this reversible birth-death chain. Suppose\n$$\n\\pi_{k}=c\\,\\binom{N}{k},\\qquad k=0,1,\\dots,N,\n$$\nfor some normalizing constant $c>0$. Then the detailed balance equations for adjacent states $k$ and $k+1$ require\n$$\n\\pi_{k}\\,\\mathbb{P}(k\\to k+1)=\\pi_{k+1}\\,\\mathbb{P}(k+1\\to k).\n$$\nSubstituting the expressions gives\n$$\nc\\,\\binom{N}{k}\\,\\frac{N-k}{N}=c\\,\\binom{N}{k+1}\\,\\frac{k+1}{N}.\n$$\nThis holds identically because\n$$\n\\binom{N}{k}\\,(N-k)=\\binom{N}{k+1}\\,(k+1).\n$$\nThus $\\pi_{k}\\propto \\binom{N}{k}$. Normalization $\\sum_{k=0}^{N}\\pi_{k}=1$ yields\n$$\nc=\\left(\\sum_{k=0}^{N}\\binom{N}{k}\\right)^{-1}=2^{-N},\n$$\nso the unique stationary distribution is\n$$\n\\pi_{k}=2^{-N}\\binom{N}{k},\\qquad k=0,1,\\dots,N.\n$$\n\nThe long-run probability that one of the two servers is completely empty corresponds to the event $\\{X=0\\}\\cup\\{X=N\\}$ under the stationary distribution. Therefore,\n$$\n\\mathbb{P}(\\text{one server empty})=\\pi_{0}+\\pi_{N}=2^{-N}\\binom{N}{0}+2^{-N}\\binom{N}{N}=2^{-N}+2^{-N}=2^{1-N}.\n$$\nThis is the desired closed-form expression in terms of $N$.", "answer": "$$\\boxed{2^{1-N}}$$", "id": "1360469"}, {"introduction": "This final problem reveals a deeper consequence of the ergodic theorem by connecting the stationary distribution to the concept of mean recurrence time. By analyzing a simple card-shuffling model, you will calculate the expected number of steps for the system to return to its starting configuration [@problem_id:1360475]. This powerful result, a consequence of what is known as Kac's Lemma, shows that the stationary probability of a state is precisely the reciprocal of its expected return time, providing a profound link between long-run frequencies and recurrence.", "problem": "A simplified model for a card shuffling process is studied using a small deck of four distinct cards, which are initially in a sorted order. A single \"shuffle\" operation consists of taking the card currently at the top of the deck and re-inserting it into one of the four possible positions (i.e., back at the top, between the first and second cards, between the second and third cards, or at the bottom of the deck). Each of these four positions is chosen with equal probability.\n\nThe process is repeated, with each shuffle being independent of the previous ones. We are interested in how long it takes for the deck to return to its initial sorted order.\n\nCalculate the expected number of shuffles required for the deck to return to its initial sorted order for the first time. The initial state is considered step 0, so the first possible return is at step 1. Provide your answer as an exact integer.", "solution": "Let the state space be the set of all permutations of the four distinct cards; hence there are $4!=24$ states.\n\nOne shuffle is defined as follows: from a state $s=(x_{1},x_{2},x_{3},x_{4})$, choose $j\\in\\{1,2,3,4\\}$ uniformly and move $x_{1}$ into position $j$ among the four positions. Denote the resulting state by $T_{j}(s)$. The transition probabilities are\n$$\nP(s,t)=\\begin{cases}\n\\frac{1}{4}, & \\text{if } t=T_{j}(s) \\text{ for some } j\\in\\{1,2,3,4\\},\\\\\n0, & \\text{otherwise}.\n\\end{cases}\n$$\n\nWe show the transition matrix is doubly stochastic. Fix any target state $t=(t_{1},t_{2},t_{3},t_{4})$. For each $j\\in\\{1,2,3,4\\}$, define a unique predecessor\n$$\ns_{j}(t)=(t_{j},\\,t_{1},\\,\\ldots,\\,t_{j-1},\\,t_{j+1},\\,\\ldots,\\,t_{4}).\n$$\nThen $T_{j}(s_{j}(t))=t$. These $s_{j}(t)$ are distinct for distinct $j$ because the top card differs. Therefore the total incoming probability to $t$ is\n$$\n\\sum_{s}P(s,t)=\\sum_{j=1}^{4}\\frac{1}{4}=1,\n$$\nso every column sum equals $1$. Since every row sum is $1$ by construction, the transition matrix is doubly stochastic.\n\nIt follows that the uniform distribution $\\mu$ on the $24$ states, given by $\\mu(s)=\\frac{1}{24}$ for all states $s$, is stationary.\n\nThe chain is aperiodic because $P(s,s)=\\frac{1}{4}>0$ (choosing $j=1$ leaves the state unchanged). It is also irreducible (from any permutation, repeated top insertions can realize any permutation). Hence the chain is positive recurrent and ergodic.\n\nBy the standard recurrence-time identity (Kac’s lemma for Markov chains), the expected time to return to a given state $s$ (the expected first return time after time $0$), starting from $s$, equals the reciprocal of its stationary probability:\n$$\n\\mathbb{E}_{s}[T_{s}^{+}]=\\frac{1}{\\mu(s)}.\n$$\nSince $\\mu(s)=\\frac{1}{24}$ for every state, we obtain\n$$\n\\mathbb{E}_{s}[T_{s}^{+}]=24.\n$$\n\nTherefore, the expected number of shuffles required for the deck to return to its initial sorted order for the first time is $24$.", "answer": "$$\\boxed{24}$$", "id": "1360475"}]}