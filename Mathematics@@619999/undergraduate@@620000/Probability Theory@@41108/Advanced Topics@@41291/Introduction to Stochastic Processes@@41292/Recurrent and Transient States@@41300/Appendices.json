{"hands_on_practices": [{"introduction": "We begin by exploring a cornerstone principle of Markov chains. For systems with a finite number of states, a key property emerges when the chain is irreducible—meaning it is possible to get from any state to any other. This exercise [@problem_id:1329949] challenges you to apply this fundamental theorem to confirm the nature of states in such a system, helping you distinguish essential structural properties from superficial details.", "id": "1329949", "problem": "A stochastic process is described by a discrete-time Markov chain on a finite state space $S = \\{s_1, s_2, \\ldots, s_N\\}$, where the number of states $N$ is an integer greater than or equal to 3. The chain is known to be irreducible, meaning that it is possible to go from any state to any other state (not necessarily in one step).\n\nA peculiar feature of this system's dynamics is that it is impossible for the process to remain in the same state for two consecutive time steps. Mathematically, this translates to the property that all diagonal entries of the transition probability matrix $P$ are zero, i.e., $P_{ii} = 0$ for all states $i \\in S$.\n\nBased only on the information provided, what can be definitively concluded about the classification of the states in this Markov chain?\n\nA. All states are transient.\nB. All states are recurrent.\nC. Some states are recurrent and some are transient.\nD. The classification of the states as recurrent or transient cannot be determined without knowing the specific values of the non-diagonal entries of the transition matrix $P$.\n\n", "solution": "Let $(X_{n})_{n \\geq 0}$ be a discrete-time Markov chain on the finite state space $S=\\{s_{1},\\ldots,s_{N}\\}$ with $N \\geq 3$, with transition matrix $P=(P_{ij})_{i,j \\in S}$ satisfying:\n- Irreducibility: for all $i,j \\in S$, there exists $n \\geq 1$ with $(P^{n})_{ij} > 0$.\n- No self-loops: $P_{ii} = 0$ for all $i \\in S$.\n\nWe are asked to determine, based only on this information, what can be concluded about recurrence versus transience of the states.\n\nFirst, use the finiteness and irreducibility. Since $P$ is a finite, irreducible, nonnegative matrix with each row summing to $1$, the Perron–Frobenius theorem implies the existence of a strictly positive vector $\\pi \\in \\mathbb{R}^{N}$ such that\n$$\nP^{\\top}\\pi = \\pi, \\qquad \\pi_{i} > 0 \\text{ for all } i \\in S.\n$$\nNormalize to obtain a probability vector by setting\n$$\n\\sum_{i \\in S} \\pi_{i} = 1.\n$$\nThen $\\pi$ is a stationary distribution:\n$$\n\\pi^{\\top} P = \\pi^{\\top}, \\qquad \\sum_{i \\in S} \\pi_{i} = 1, \\qquad \\pi_{i} > 0 \\ \\forall i.\n$$\n\nIn an irreducible Markov chain, the existence of a stationary distribution implies positive recurrence. More precisely, for each state $i$, let the return time be\n$$\nT_{i}^{+} = \\inf\\{n \\geq 1 : X_{n} = i \\mid X_{0} = i\\}.\n$$\nKac’s formula gives the identity\n$$\n\\mathbb{E}_{i}[T_{i}^{+}] = \\frac{1}{\\pi_{i}} \\quad \\text{for each } i \\in S,\n$$\nso, because $\\pi_{i} > 0$, it follows that\n$$\n\\mathbb{E}_{i}[T_{i}^{+}] < \\infty.\n$$\nIf $\\mathbb{P}_{i}(T_{i}^{+} = \\infty) > 0$, then $\\mathbb{E}_{i}[T_{i}^{+}]$ would be infinite. Hence necessarily\n$$\n\\mathbb{P}_{i}(T_{i}^{+} < \\infty) = 1,\n$$\nso every state $i$ is recurrent (indeed, positive recurrent).\n\nTherefore, in any finite irreducible Markov chain, all states are recurrent, regardless of periodicity. The additional constraint $P_{ii}=0$ only constrains the period (for example, it rules out one-step returns but does not prevent aperiodicity if both odd and even return lengths occur); it does not affect the recurrence classification.\n\nConsequently, the correct choice is that all states are recurrent.", "answer": "$$\\boxed{B}$$"}, {"introduction": "Having established the behavior of finite chains, we now venture into infinite state spaces where the rules can change dramatically. This practice problem [@problem_id:1288903] models a particle's movement with a slight directional bias along a one-dimensional line. You will investigate how even a small, persistent drift influences the long-term behavior of the walk, providing a clear and calculable demonstration of transience.", "id": "1288903", "problem": "A simplified model for the movement of a point defect along a one-dimensional polymer chain describes the defect's position as a random walk on the set of integers $\\mathbb{Z}$. The state of the system at any time is the integer coordinate $n$ of the defect. At each discrete time step, the defect's position changes based on the following probabilistic rules, which are influenced by the polymer's asymmetric chemical structure:\n- The defect moves one step to the right (from $n$ to $n+1$) with probability $p_R$.\n- The defect moves one step to the left (from $n$ to $n-1$) with probability $p_L$.\n- The defect remains at its current position $n$ with probability $p_S$.\n\nThe probabilities are given in terms of a positive constant $k$ related to the polymer's material properties:\n$p_R = \\frac{k+1}{2k+4}$, $p_L = \\frac{k}{2k+4}$, and $p_S = \\frac{3}{2k+4}$.\n\nThe Markov chain formed by this random walk is irreducible, meaning all states belong to a single communicating class and thus share the same properties. Analyze the nature of the states in this chain and select the correct classification from the options below.\n\nA. Recurrent and Aperiodic\nB. Recurrent and Periodic\nC. Transient and Aperiodic\nD. Transient and Periodic\nE. The classification depends on the specific value of the positive constant $k$.\n\n", "solution": "We verify the transition probabilities. Given $p_{R}=\\frac{k+1}{2k+4}$, $p_{L}=\\frac{k}{2k+4}$, and $p_{S}=\\frac{3}{2k+4}$ with $k>0$, we have\n$$\np_{R}+p_{L}+p_{S}=\\frac{k+1}{2k+4}+\\frac{k}{2k+4}+\\frac{3}{2k+4}=\\frac{2k+4}{2k+4}=1,\n$$\nand each term is strictly positive for $k>0$, so the chain is well-defined and irreducible on $\\mathbb{Z}$ because from any $n$ one can reach any $m$ by a sequence of left and right moves, each having positive probability.\n\nTo determine periodicity, recall the period $d(i)$ of a state $i$ is\n$$\nd(i)=\\gcd\\{n\\geq 1: P^{n}(i,i)>0\\}.\n$$\nSince $P(i,i)=p_{S}>0$, we have $1\\in\\{n\\geq 1: P^{n}(i,i)>0\\}$, hence $d(i)=1$. Therefore all states are aperiodic.\n\nTo determine recurrence versus transience, consider the increment $\\Delta X_{t}=X_{t+1}-X_{t}$, which satisfies\n$$\n\\Delta X_{t}=\\begin{cases}\n+1 & \\text{with probability } p_{R},\\\\\n-1 & \\text{with probability } p_{L},\\\\\n0 & \\text{with probability } p_{S}.\n\\end{cases}\n$$\nThese increments are independent and identically distributed across time, since the transition probabilities are time-homogeneous and state-independent for the increment. The drift (mean increment) is\n$$\n\\mu=\\mathbb{E}[\\Delta X_{t}]=p_{R}-p_{L}=\\frac{k+1}{2k+4}-\\frac{k}{2k+4}=\\frac{1}{2k+4}>0.\n$$\nBy the strong law of large numbers, for $S_{n}=X_{n}-X_{0}=\\sum_{t=0}^{n-1}\\Delta X_{t}$,\n$$\n\\frac{S_{n}}{n}\\to \\mu \\quad \\text{almost surely,}\n$$\nso $S_{n}\\to +\\infty$ almost surely. Thus the walk drifts to $+\\infty$ and visits any fixed state only finitely many times almost surely, which implies all states are transient.\n\nCombining these, the chain is transient and aperiodic for every $k>0$. Hence the correct option is C.", "answer": "$$\\boxed{C}$$"}, {"introduction": "Does an infinite state space always imply that a random walker will eventually get lost? This exercise [@problem_id:1384260] explores that question in the context of a two-dimensional grid, a classic scenario in probability theory. By analyzing a symmetric random walk, you will determine if returning to the origin is a certainty or a mere possibility, touching upon a famous result from Pólya regarding the role of dimensionality in random processes.", "id": "1384260", "problem": "A random walker moves on the two-dimensional integer lattice, $\\mathbb{Z}^2$. The walker starts at the origin, $\\mathbf{X}_0 = (0,0)$. At each discrete time step $n=1, 2, 3, \\ldots$, the walker first chooses one of its four neighboring sites (up, down, left, or right) with equal probability $1/4$. Let this intended destination be $\\mathbf{y}'$. The edge connecting the walker's current position $\\mathbf{X}_{n-1}$ to $\\mathbf{y}'$ is 'open' for passage with a fixed probability $p \\in (0,1)$, and 'closed' with probability $1-p$. The state of the edge is determined independently at each time step and for each potential move. If the chosen edge is open, the walker moves to the new site, so $\\mathbf{X}_n = \\mathbf{y}'$. If the chosen edge is closed, the walker does not move and remains at its current position, so $\\mathbf{X}_n = \\mathbf{X}_{n-1}$.\n\nA state in a Markov chain is defined as recurrent if, starting from that state, the probability of eventually returning to it is 1. If this probability is less than 1, the state is transient. For the described random walk, which is an irreducible Markov chain on $\\mathbb{Z}^2$, all states are of the same type.\n\nDetermine for which values of the probability $p$ the random walk is recurrent. Choose the correct range of values for $p$ from the options below.\n\nA. The walk is recurrent only for $p=1$.\nB. The walk is recurrent only for $p > 1/2$.\nC. The walk is recurrent for all $p \\in (0, 1)$.\nD. The walk is recurrent only for $p > \\pi/4$.\nE. The walk is transient for all $p \\in (0, 1)$.\n\n", "solution": "At each time step, the walker chooses one of the four neighbors uniformly and then moves if and only if the chosen edge is open. Therefore, for any site $x \\in \\mathbb{Z}^{2}$ and any of its four neighbors $x+e$ (with $e$ a coordinate unit vector or its negative),\n$$\n\\mathbb{P}(X_{n}=x \\mid X_{n-1}=x)=1-p,\\quad \\mathbb{P}(X_{n}=x+e \\mid X_{n-1}=x)=\\frac{p}{4}.\n$$\nThus the chain is a lazy nearest-neighbor symmetric random walk: it holds with probability $1-p$ and moves to each neighbor with probability $p/4$.\n\nDefine the sequence of move times by $T_{0}=0$ and\n$$\nT_{k}=\\inf\\{n>T_{k-1}: X_{n}\\neq X_{n-1}\\},\\quad k\\geq 1,\n$$\nthe times at which an actual move occurs. Let $Y_{k}=X_{T_{k}}$ be the embedded chain that records only the positions after successful moves.\n\nWe first identify the law of the holding times. At each step, the chosen edge is independently open with probability $p$, hence the indicator of a move at a given time is an independent Bernoulli random variable with parameter $p$. Therefore,\n$$\nT_{k}-T_{k-1}\\ \\text{are i.i.d. geometric with parameter }p,\\quad \\mathbb{P}(T_{k}-T_{k-1}=m)=(1-p)^{m-1}p,\\ m\\in\\mathbb{N}.\n$$\nNext, we determine the transition law of $Y_{k}$. When a move occurs, the direction is the neighbor initially chosen, which is uniform among the four neighbors and independent of the open/closed outcome. Hence, for each neighbor $y$ of $x$,\n$$\n\\mathbb{P}(Y_{k}=y \\mid Y_{k-1}=x)=\\frac{1}{4},\n$$\nand $Y_{k}$ is the simple symmetric random walk on $\\mathbb{Z}^{2}$.\n\nLet $\\tau_{Y}=\\inf\\{k\\geq 1: Y_{k}=0\\}$ and $\\tau_{X}=\\inf\\{n\\geq 1: X_{n}=0\\}$ be the first return times to the origin for the embedded and the original chains, respectively. Since $X_{n}$ only changes at move times and equals $Y_{k}$ for all $n$ with $T_{k}\\leq n<T_{k+1}$, a return to the origin by $X$ occurs if and only if a return occurs by $Y$, and in fact\n$$\n\\{\\tau_{X}<\\infty\\}=\\{\\tau_{Y}<\\infty\\},\\quad \\text{with } \\tau_{X}=T_{\\tau_{Y}} \\text{ on } \\{\\tau_{Y}<\\infty\\}.\n$$\nTherefore, the recurrence or transience of $X_{n}$ is identical to that of $Y_{k}$.\n\nBy Pólya’s theorem, the simple symmetric random walk on $\\mathbb{Z}^{2}$ is recurrent, i.e.,\n$$\n\\mathbb{P}_{0}(\\tau_{Y}<\\infty)=1.\n$$\nConsequently,\n$$\n\\mathbb{P}_{0}(\\tau_{X}<\\infty)=1,\n$$\nso the described walk is recurrent for every $p\\in(0,1)$.\n\nHence the correct choice is that the walk is recurrent for all $p\\in(0,1)$.", "answer": "$$\\boxed{C}$$"}]}