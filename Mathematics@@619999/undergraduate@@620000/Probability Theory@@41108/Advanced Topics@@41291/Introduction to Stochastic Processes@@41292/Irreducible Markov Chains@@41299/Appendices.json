{"hands_on_practices": [{"introduction": "The first step in analyzing a Markov chain is to understand its underlying structure. This exercise will guide you through the fundamental skill of partitioning a state space into communicating classes, which allows you to determine if a chain is irreducible. Mastering this concept is crucial, as irreducibility is the key property that ensures a system can eventually reach any state from any other state, paving the way for predictable long-term behavior. [@problem_id:1312394]", "problem": "A simplified model for a software process describes its behavior as a sequence of states in a discrete-time Markov chain. The state space of the process is given by the set $\\{S_1, S_2, S_3, S_4\\}$. The transitions between states are governed by the following probabilistic rules:\n\n- From state $S_1$, the system transitions to state $S_2$ with probability $p_1$ or remains in state $S_1$ with probability $1 - p_1$.\n- From state $S_2$, the system always transitions to state $S_3$.\n- From state $S_3$, the system transitions to state $S_4$ with probability $p_3$ or transitions back to state $S_2$ with probability $1 - p_3$.\n- From state $S_4$, the system always transitions back to state $S_3$.\n\nFor the specific case where the probabilities are $p_1 = 0.4$ and $p_3 = 0.7$, which of the following statements correctly describes the properties of this Markov chain?\n\nA. The chain is irreducible, so there is only one communicating class: $\\{S_1, S_2, S_3, S_4\\}$.\n\nB. The chain has two communicating classes: $\\{S_1, S_2\\}$ and $\\{S_3, S_4\\}$.\n\nC. The chain has two communicating classes: $\\{S_1\\}$ and $\\{S_2, S_3, S_4\\}$. State $S_1$ is transient.\n\nD. The chain has two communicating classes: $\\{S_1, S_2, S_3\\}$ and $\\{S_4\\}$. State $S_4$ is absorbing.\n\nE. The chain has three communicating classes: $\\{S_1\\}$, $\\{S_2, S_3\\}$, and $\\{S_4\\}$.", "solution": "To determine the correct description of the Markov chain, we need to identify its communicating classes. Two states, $i$ and $j$, are said to communicate, denoted $i \\leftrightarrow j$, if state $j$ is reachable from state $i$ and state $i$ is reachable from state $j$. A communicating class is a maximal set of states in which every pair of states communicates. A Markov chain is irreducible if all states belong to a single communicating class.\n\nLet's analyze the reachability between the states using the given transition probabilities $p_1 = 0.4$ and $p_3 = 0.7$. A transition from state $i$ to state $j$ is possible if the transition probability $P_{ij}$ is greater than zero.\n\nThe transition probabilities are:\n- $P_{11} = 1 - p_1 = 0.6$\n- $P_{12} = p_1 = 0.4$\n- $P_{23} = 1$\n- $P_{32} = 1 - p_3 = 0.3$\n- $P_{34} = p_3 = 0.7$\n- $P_{43} = 1$\nAll other transition probabilities are zero.\n\nLet's examine the communication relationships.\n\n1.  **Start with state $S_1$**:\n    - Can $S_1$ reach other states? Yes. There is a path $S_1 \\to S_2$ since $P_{12} = 0.4 > 0$. From $S_2$, the system must go to $S_3$ ($P_{23}=1$). From $S_3$, it can reach $S_4$ ($P_{34}=0.7>0$). Thus, $S_1$ can reach $S_2$, $S_3$, and $S_4$.\n    - Can other states reach $S_1$? Let's check for any transitions into $S_1$. The only transitions into $S_1$ would be $P_{11}, P_{21}, P_{31}, P_{41}$. We have $P_{11} > 0$, but $P_{21}=0$, $P_{31}=0$, and $P_{41}=0$. This means that once the system leaves state $S_1$, it can never return.\n    - Since $S_2$ cannot reach $S_1$, $S_1$ and $S_2$ do not communicate ($S_1 \\not\\leftrightarrow S_2$). By extension, $S_1$ does not communicate with $S_3$ or $S_4$.\n    - Therefore, $\\{S_1\\}$ forms a communicating class by itself. Since it is possible to leave this state (with probability $p_1=0.4$) and never return, state $S_1$ is a transient state.\n\n2.  **Examine the remaining states $\\{S_2, S_3, S_4\\}$**:\n    - **Communication between $S_2$ and $S_3$**:\n        - Can $S_2$ reach $S_3$? Yes, $P_{23} = 1 > 0$.\n        - Can $S_3$ reach $S_2$? Yes, $P_{32} = 0.3 > 0$.\n        - So, $S_2$ and $S_3$ communicate: $S_2 \\leftrightarrow S_3$.\n    - **Communication between $S_3$ and $S_4$**:\n        - Can $S_3$ reach $S_4$? Yes, $P_{34} = 0.7 > 0$.\n        - Can $S_4$ reach $S_3$? Yes, $P_{43} = 1 > 0$.\n        - So, $S_3$ and $S_4$ communicate: $S_3 \\leftrightarrow S_4$.\n    - **Communication between $S_2$ and $S_4$**:\n        - Since communication is a transitive relation ($S_2 \\leftrightarrow S_3$ and $S_3 \\leftrightarrow S_4$), we can conclude that $S_2 \\leftrightarrow S_4$. Let's verify:\n        - Path from $S_2$ to $S_4$: $S_2 \\to S_3 \\to S_4$. This path exists.\n        - Path from $S_4$ to $S_2$: $S_4 \\to S_3 \\to S_2$. This path exists.\n        - So, $S_2$ and $S_4$ communicate as well.\n\n3.  **Conclusion**:\n    - The states $\\{S_2, S_3, S_4\\}$ form a single communicating class because every state in this set communicates with every other state in the set, and no state outside this set communicates with them.\n    - This class is closed because there are no transitions from any state in $\\{S_2, S_3, S_4\\}$ to state $S_1$. Once the chain enters this class, it can never leave. This means $\\{S_2, S_3, S_4\\}$ is a recurrent class.\n    - The chain is not irreducible because it has more than one communicating class.\n    - The communicating classes are $\\{S_1\\}$ and $\\{S_2, S_3, S_4\\}$.\n    - State $S_1$ is transient, as it is possible to leave the state and impossible to return.\n\nComparing our findings with the given options:\n- A is incorrect because the chain is not irreducible.\n- B is incorrect because $S_2$ and $S_3$ are in the same class.\n- C is correct. It correctly identifies the two communicating classes, $\\{S_1\\}$ and $\\{S_2, S_3, S_4\\}$, and correctly identifies $S_1$ as transient.\n- D is incorrect as it misidentifies the classes. Also, $S_4$ is not an absorbing state because it is possible to leave it ($P_{43}=1$). An absorbing state $i$ must have $P_{ii}=1$.\n- E is incorrect as there are only two communicating classes.", "answer": "$$\\boxed{C}$$", "id": "1312394"}, {"introduction": "A core consequence of an irreducible and aperiodic finite-state Markov chain is its convergence to a unique long-term equilibrium. This practice provides a concrete application, modeling a server's operational states, where you will calculate this equilibrium, known as the stationary distribution. By solving for the long-run proportion of time spent in each state, you will apply the foundational equations that connect irreducibility to practical, predictive power. [@problem_id:1312364]", "problem": "A specialized server in a data center operates in a discrete time model, where its state is evaluated at the end of each hour. The server can be in one of three states: Operational (actively processing tasks), Standby (idle but ready for tasks), or Failed (crashed and awaiting repair).\n\nBased on extensive logging data, the following one-hour transition probabilities have been established:\n- If the server is Operational, there is a 0.2 probability it will transition to Standby (task completion) and a 0.1 probability it will transition to Failed (hardware/software error).\n- If the server is on Standby, there is a 0.6 probability it will become Operational (new task assigned) and a 0.1 probability it will transition to Failed (e.g., a power-supply fault).\n- If the server is in a Failed state, there is an 0.8 probability that it will be repaired and returned to the Standby state within the hour. It is not possible for a failed server to become directly Operational after repair; it must first go through the Standby state.\n\nAny transition not specified implies the server remains in its current state for that hour. Assuming the server operates continuously for a very long time, what is the long-run proportion of time it spends in the Operational state? Express your answer as a decimal rounded to three significant figures.", "solution": "Model the server as a discrete-time, finite-state Markov chain with states Operational ($O$), Standby ($S$), and Failed ($F$). By the rule that unspecified transitions imply remaining in the current state, the one-step transition probabilities are:\n- From $O$: $P_{OO}=1-0.2-0.1=0.7$, $P_{OS}=0.2$, $P_{OF}=0.1$.\n- From $S$: $P_{SO}=0.6$, $P_{SS}=1-0.6-0.1=0.3$, $P_{SF}=0.1$.\n- From $F$: $P_{FS}=0.8$, $P_{FF}=1-0.8=0.2$, $P_{FO}=0$.\n\nWith state order $(O,S,F)$, the transition matrix is\n$$\nP=\\begin{pmatrix}\n0.7 & 0.2 & 0.1\\\\\n0.6 & 0.3 & 0.1\\\\\n0 & 0.8 & 0.2\n\\end{pmatrix}.\n$$\nLet the stationary distribution be $\\pi=(\\pi_{O},\\pi_{S},\\pi_{F})$ with $\\pi=\\pi P$ and $\\pi_{O}+\\pi_{S}+\\pi_{F}=1$. The balance equations are\n$$\n\\pi_{O}=0.7\\pi_{O}+0.6\\pi_{S}+0\\cdot\\pi_{F},\\quad\n\\pi_{S}=0.2\\pi_{O}+0.3\\pi_{S}+0.8\\pi_{F},\\quad\n\\pi_{F}=0.1\\pi_{O}+0.1\\pi_{S}+0.2\\pi_{F}.\n$$\nFrom the first equation,\n$$\n\\pi_{O}-0.7\\pi_{O}-0.6\\pi_{S}=0\\;\\Rightarrow\\;0.3\\pi_{O}=0.6\\pi_{S}\\;\\Rightarrow\\;\\pi_{O}=2\\pi_{S}.\n$$\nFrom the third equation,\n$$\n\\pi_{F}-0.2\\pi_{F}=0.1\\pi_{O}+0.1\\pi_{S}\\;\\Rightarrow\\;0.8\\pi_{F}=0.1(\\pi_{O}+\\pi_{S})\\;\\Rightarrow\\;\\pi_{F}=\\frac{1}{8}(\\pi_{O}+\\pi_{S}).\n$$\nSubstitute $\\pi_{O}=2\\pi_{S}$ to obtain\n$$\n\\pi_{F}=\\frac{1}{8}(2\\pi_{S}+\\pi_{S})=\\frac{3}{8}\\pi_{S}.\n$$\nUse the normalization $\\pi_{O}+\\pi_{S}+\\pi_{F}=1$:\n$$\n2\\pi_{S}+\\pi_{S}+\\frac{3}{8}\\pi_{S}=1\\;\\Rightarrow\\;3\\pi_{S}+\\frac{3}{8}\\pi_{S}=\\frac{27}{8}\\pi_{S}=1\\;\\Rightarrow\\;\\pi_{S}=\\frac{8}{27}.\n$$\nThen\n$$\n\\pi_{O}=2\\pi_{S}=\\frac{16}{27},\\qquad \\pi_{F}=\\frac{3}{8}\\pi_{S}=\\frac{1}{9}.\n$$\nThus, the long-run proportion of time in the Operational state is $\\pi_{O}=\\frac{16}{27}\\approx 0.59259\\ldots$, which rounded to three significant figures is $0.593$.", "answer": "$$\\boxed{0.593}$$", "id": "1312364"}, {"introduction": "Irreducibility guarantees communication between all states, but what if the chain moves between sets of states in a fixed, cyclical pattern? This exercise introduces the important concept of periodicity in irreducible chains. You will analyze a system whose state does not converge in the usual sense but whose long-term behavior can still be understood by examining the chain at specific intervals, a powerful technique for studying periodic systems. [@problem_id:1368007]", "problem": "A specialized computer memory cell is modeled as a discrete-time Markov chain. The state of the cell at any given time step is described by two properties: a \"logical\" state (0 or 1) and a \"physical\" state ('Active' or 'Passive'). This gives rise to a four-state system, where $X_t$ denotes the state of the cell at time step $t$:\n- State 1: Logical 0, Active ($0_A$)\n- State 2: Logical 0, Passive ($0_P$)\n- State 3: Logical 1, Active ($1_A$)\n- State 4: Logical 1, Passive ($1_P$)\n\nThe cell's state transitions are governed by a clock. At each clock tick, the logical state is guaranteed to flip. The specific transition probabilities to the subsequent physical state depend on the current state, as follows:\n- From state $0_A$ (State 1), the cell transitions to state $1_A$ (State 3) with probability $p$, and to state $1_P$ (State 4) with probability $1-p$.\n- From state $0_P$ (State 2), the cell transitions to state $1_A$ (State 3) with probability $q$, and to state $1_P$ (State 4) with probability $1-q$.\n- From state $1_A$ (State 3), the cell transitions to state $0_A$ (State 1) with probability $r$, and to state $0_P$ (State 2) with probability $1-r$.\n- From state $1_P$ (State 4), the cell transitions to state $0_A$ (State 1) with probability $s$, and to state $0_P$ (State 2) with probability $1-s$.\n\nAll parameters $p, q, r, s$ are constants in the interval $(0, 1)$.\n\nSuppose the memory cell starts in the 'Logical 0, Active' state (State 1). Determine the long-term probability that the cell is found in this same state after a large number of *even* clock ticks. Specifically, calculate the limit:\n$$ \\lim_{n \\to \\infty} P(X_{2n} = 1 | X_0 = 1) $$\nProvide the answer as a closed-form analytic expression in terms of $p, q, r,$ and $s$.", "solution": "Let the state order be $(1,2,3,4)=(0_{A},0_{P},1_{A},1_{P})$. The one-step transition matrix is\n$$\nP=\\begin{pmatrix}\n0 & 0 & p & 1-p\\\\\n0 & 0 & q & 1-q\\\\\nr & 1-r & 0 & 0\\\\\ns & 1-s & 0 & 0\n\\end{pmatrix}.\n$$\nBecause the logical bit flips every step, after two steps the chain returns to the logical-$0$ class $\\{1,2\\}$. The two-step transition matrix restricted to $\\{1,2\\}$ is the $2\\times 2$ matrix $M$ given by\n$$\nM=P^{2}\\big|_{\\{1,2\\}}=\\begin{pmatrix}\nM_{11} & M_{12}\\\\\nM_{21} & M_{22}\n\\end{pmatrix},\n$$\nwith entries computed via two-step paths through states $3$ and $4$:\n$$\nM_{11}=pr+(1-p)s,\\quad M_{12}=p(1-r)+(1-p)(1-s),\n$$\n$$\nM_{21}=qr+(1-q)s,\\quad M_{22}=q(1-r)+(1-q)(1-s).\n$$\nSince $p,q,r,s\\in(0,1)$, all entries of $M$ lie in $(0,1)$, hence this $2$-state chain is irreducible and aperiodic. Therefore, for any initial state in $\\{1,2\\}$, the even-time distribution converges to the unique stationary distribution $\\pi$ of $M$. Writing $\\pi=(\\pi_{1},\\pi_{2})$ with $\\pi=\\pi M$ and $\\pi_{1}+\\pi_{2}=1$, the standard $2$-state balance gives\n$$\n\\pi_{1}=\\frac{M_{21}}{M_{12}+M_{21}}.\n$$\nSubstituting the entries,\n$$\n\\pi_{1}=\\frac{qr+(1-q)s}{\\,p(1-r)+(1-p)(1-s)+qr+(1-q)s\\,}.\n$$\nEquivalently, simplifying the denominator,\n$$\np(1-r)+(1-p)(1-s)+qr+(1-q)s = 1+(q-p)(r-s),\n$$\nso\n$$\n\\lim_{n\\to\\infty}P(X_{2n}=1\\mid X_{0}=1)=\\frac{qr+(1-q)s}{1+(q-p)(r-s)}.\n$$", "answer": "$$\\boxed{\\frac{qr+(1-q)s}{1+(q-p)(r-s)}}$$", "id": "1368007"}]}