{"hands_on_practices": [{"introduction": "Many real-world systems, from robotics to population dynamics, eventually settle into a predictable long-term pattern. This problem uses the familiar scenario of an automated vacuum cleaner to introduce the concept of a stationary distribution. You will calculate this distribution to determine the long-run average performance of the system, a common goal in engineering and operations research. This exercise [@problem_id:1370817] provides a tangible application for stationary distributions, grounding an abstract concept in a practical problem.", "problem": "An advanced automated vacuum cleaner operates in a three-room apartment, consisting of a Living Room (State 1), a Bedroom (State 2), and a Kitchen (State 3). At the end of each minute, the vacuum cleaner decides to either stay in the current room or move to a different one. Its movement is modeled as a discrete-time Markov chain. The transition probabilities are given by the matrix $P$, where $P_{ij}$ is the probability of moving from room $i$ to room $j$ in one minute:\n$$\nP = \\begin{pmatrix} 0 & 1/2 & 1/2 \\\\ 1/4 & 1/2 & 1/4 \\\\ 1/2 & 1/3 & 1/6 \\end{pmatrix}\n$$\nThe rate at which the vacuum cleaner collects dirt depends on the room it is in. The collection rates are:\n- Living Room (State 1): $d_1 = 5.0$ grams per minute.\n- Bedroom (State 2): $d_2 = 2.0$ grams per minute.\n- Kitchen (State 3): $d_3 = 8.0$ grams per minute.\n\nAssuming the vacuum cleaner runs for a very long time, what is its average dirt collection rate over the long run? Express your answer in grams per minute, rounded to three significant figures.", "solution": "We model the long-run average collection rate using the stationary distribution of the Markov chain. Let $\\pi = (\\pi_{1},\\pi_{2},\\pi_{3})$ be the stationary distribution, which satisfies $\\pi P = \\pi$ and $\\pi_{1}+\\pi_{2}+\\pi_{3}=1$. Writing the component equations from $\\pi P = \\pi$:\n$$\n\\pi_{1} = \\tfrac{1}{4}\\pi_{2} + \\tfrac{1}{2}\\pi_{3}, \\quad\n\\pi_{2} = \\tfrac{1}{2}\\pi_{1} + \\tfrac{1}{2}\\pi_{2} + \\tfrac{1}{3}\\pi_{3}, \\quad\n\\pi_{3} = \\tfrac{1}{2}\\pi_{1} + \\tfrac{1}{4}\\pi_{2} + \\tfrac{1}{6}\\pi_{3}.\n$$\nFrom the second equation,\n$$\n\\pi_{2} - \\tfrac{1}{2}\\pi_{2} = \\tfrac{1}{2}\\pi_{1} + \\tfrac{1}{3}\\pi_{3} \\;\\;\\Rightarrow\\;\\; \\tfrac{1}{2}\\pi_{2} = \\tfrac{1}{2}\\pi_{1} + \\tfrac{1}{3}\\pi_{3} \\;\\;\\Rightarrow\\;\\; \\pi_{2} = \\pi_{1} + \\tfrac{2}{3}\\pi_{3}.\n$$\nSubstitute $\\pi_{1} = \\tfrac{1}{4}\\pi_{2} + \\tfrac{1}{2}\\pi_{3}$ from the first equation into this:\n$$\n\\pi_{2} = \\left(\\tfrac{1}{4}\\pi_{2} + \\tfrac{1}{2}\\pi_{3}\\right) + \\tfrac{2}{3}\\pi_{3} = \\tfrac{1}{4}\\pi_{2} + \\tfrac{7}{6}\\pi_{3}\n\\;\\;\\Rightarrow\\;\\; \\tfrac{3}{4}\\pi_{2} = \\tfrac{7}{6}\\pi_{3}\n\\;\\;\\Rightarrow\\;\\; \\pi_{2} = \\tfrac{14}{9}\\pi_{3}.\n$$\nThen\n$$\n\\pi_{1} = \\tfrac{1}{4}\\pi_{2} + \\tfrac{1}{2}\\pi_{3} = \\tfrac{1}{4}\\cdot\\tfrac{14}{9}\\pi_{3} + \\tfrac{1}{2}\\pi_{3} = \\tfrac{7}{18}\\pi_{3} + \\tfrac{9}{18}\\pi_{3} = \\tfrac{16}{18}\\pi_3 = \\tfrac{8}{9}\\pi_{3}.\n$$\nImposing $\\pi_{1}+\\pi_{2}+\\pi_{3}=1$ gives\n$$\n\\left(\\tfrac{8}{9} + \\tfrac{14}{9} + 1\\right)\\pi_{3} = \\tfrac{31}{9}\\pi_{3} = 1 \\;\\;\\Rightarrow\\;\\; \\pi_{3} = \\tfrac{9}{31}, \\;\\; \\pi_{1} = \\tfrac{8}{31}, \\;\\; \\pi_{2} = \\tfrac{14}{31}.\n$$\nThe long-run average dirt collection rate equals the stationary expectation of the per-minute rates $d_{1}=5$, $d_{2}=2$, $d_{3}=8$:\n$$\n\\bar{d} = \\pi_{1}d_{1} + \\pi_{2}d_{2} + \\pi_{3}d_{3} = \\tfrac{8}{31}\\cdot 5 + \\tfrac{14}{31}\\cdot 2 + \\tfrac{9}{31}\\cdot 8 = \\tfrac{40+28+72}{31} = \\tfrac{140}{31}.\n$$\nThus $\\bar{d} = \\tfrac{140}{31} \\approx 4.516129\\ldots$, which rounded to three significant figures is $4.52$ grams per minute.", "answer": "$$\\boxed{4.52}$$", "id": "1370817"}, {"introduction": "The first step in analyzing any random process is to build an accurate mathematical model. This problem focuses on that crucial skill: translating a set of probabilistic rules for a game into a formal transition matrix for a Markov chain. By solving for the stationary distribution in terms of a parameter $p$, you will practice the fundamental algebraic techniques that underpin the analysis of these systems. This practice [@problem_id:1370822] hones your ability to construct and solve a Markov model from its description.", "problem": "A token moves on a circular game board with four spaces, labeled 0, 1, 2, and 3 in order. The movement of the token is governed by a set of probabilistic rules. At each turn, if the token is on space 0, 1, or 2, it moves forward one space with probability $p$ or forward two spaces with probability $1-p$, where $0 < p < 1$. All moves are on the circular track, meaning a move from space 3 back to space 0 is a forward move of one space. If the token is on space 3, at the next turn it will always move to space 0 with certainty.\n\nAfter the game has been running for a very long time, the location of the token can be described by a stationary probability distribution. Find the stationary probability that the token is on space 0. Express your answer as a function of $p$.", "solution": "This system can be modeled as a discrete-time Markov chain on the state space $S = \\{0, 1, 2, 3\\}$. Let $\\pi = (\\pi_0, \\pi_1, \\pi_2, \\pi_3)$ be the stationary probability distribution, where $\\pi_i$ is the long-term probability of the token being on space $i$.\n\nFirst, we determine the transition probability matrix $P$, where $P_{ij}$ is the probability of moving from state $i$ to state $j$. The movements are on a circular track, so they are performed modulo 4.\n\nFrom state 0:\n- Move to $(0+1)\\pmod{4} = 1$ with probability $p$.\n- Move to $(0+2)\\pmod{4} = 2$ with probability $1-p$.\nSo, the first row of $P$ is $[0, p, 1-p, 0]$.\n\nFrom state 1:\n- Move to $(1+1)\\pmod{4} = 2$ with probability $p$.\n- Move to $(1+2)\\pmod{4} = 3$ with probability $1-p$.\nSo, the second row of $P$ is $[0, 0, p, 1-p]$.\n\nFrom state 2:\n- Move to $(2+1)\\pmod{4} = 3$ with probability $p$.\n- Move to $(2+2)\\pmod{4} = 0$ with probability $1-p$.\nSo, the third row of $P$ is $[1-p, 0, 0, p]$.\n\nFrom state 3:\n- Move to state 0 with probability 1.\nSo, the fourth row of $P$ is $[1, 0, 0, 0]$.\n\nCombining these, the transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n0 & p & 1-p & 0 \\\\\n0 & 0 & p & 1-p \\\\\n1-p & 0 & 0 & p \\\\\n1 & 0 & 0 & 0\n\\end{pmatrix}\n$$\n\nThe stationary distribution $\\pi$ must satisfy the equation $\\pi P = \\pi$, which translates to the following system of linear equations:\n1.  $\\pi_0 = 0 \\cdot \\pi_0 + 0 \\cdot \\pi_1 + (1-p) \\cdot \\pi_2 + 1 \\cdot \\pi_3 \\implies \\pi_0 = (1-p)\\pi_2 + \\pi_3$\n2.  $\\pi_1 = p \\cdot \\pi_0 + 0 \\cdot \\pi_1 + 0 \\cdot \\pi_2 + 0 \\cdot \\pi_3 \\implies \\pi_1 = p\\pi_0$\n3.  $\\pi_2 = (1-p) \\cdot \\pi_0 + p \\cdot \\pi_1 + 0 \\cdot \\pi_2 + 0 \\cdot \\pi_3 \\implies \\pi_2 = (1-p)\\pi_0 + p\\pi_1$\n4.  $\\pi_3 = 0 \\cdot \\pi_0 + (1-p) \\cdot \\pi_1 + p \\cdot \\pi_2 + 0 \\cdot \\pi_3 \\implies \\pi_3 = (1-p)\\pi_1 + p\\pi_2$\n\nAdditionally, the probabilities must sum to 1:\n5.  $\\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 = 1$\n\nWe can solve this system by expressing $\\pi_1$, $\\pi_2$, and $\\pi_3$ in terms of $\\pi_0$.\nFrom equation (2), we have:\n$$ \\pi_1 = p\\pi_0 $$\n\nSubstitute this into equation (3):\n$$ \\pi_2 = (1-p)\\pi_0 + p(p\\pi_0) = (1-p+p^2)\\pi_0 $$\n\nNow, substitute the expressions for $\\pi_1$ and $\\pi_2$ into equation (4):\n$$ \\pi_3 = (1-p)(p\\pi_0) + p((1-p+p^2)\\pi_0) $$\n$$ \\pi_3 = (p-p^2)\\pi_0 + (p-p^2+p^3)\\pi_0 = (2p-2p^2+p^3)\\pi_0 $$\n\nWe have now expressed all other probabilities in terms of $\\pi_0$. Let's use the normalization condition (equation 5):\n$$ \\pi_0 + \\pi_1 + \\pi_2 + \\pi_3 = 1 $$\n$$ \\pi_0 + p\\pi_0 + (1-p+p^2)\\pi_0 + (2p-2p^2+p^3)\\pi_0 = 1 $$\n\nFactor out $\\pi_0$:\n$$ \\pi_0 (1 + p + (1-p+p^2) + (2p-2p^2+p^3)) = 1 $$\n\nCombine the terms inside the parenthesis:\n$$ \\pi_0 ( (1+1) + (p-p+2p) + (p^2-2p^2) + p^3 ) = 1 $$\n$$ \\pi_0 (2 + 2p - p^2 + p^3) = 1 $$\n\nFinally, solve for $\\pi_0$:\n$$ \\pi_0 = \\frac{1}{p^3 - p^2 + 2p + 2} $$\nThis expression gives the stationary probability of the token being on space 0 as a function of $p$.", "answer": "$$\\boxed{\\frac{1}{p^{3} - p^{2} + 2p + 2}}$$", "id": "1370822"}, {"introduction": "While solving systems of linear equations is a universal method for finding stationary distributions, it can be cumbersome. Fortunately, for special classes of Markov chains like random walks on graphs, we can use powerful theoretical shortcuts. This problem explores such a case, where the long-term behavior of a particle on a network is deeply connected to the network's structure. You will apply a key theorem linking a vertex's stationary probability to its number of connections (degree), showcasing a more elegant and insightful approach to problem-solving [@problem_id:1370816].", "problem": "Consider a system of 8 interconnected sites, labeled $V = \\{A_1, A_2, A_3, A_4, B_1, B_2, B_3, B_4\\}$. The connections between these sites form a graph with the following structure:\n1.  The set of sites $\\{A_1, A_2, A_3, A_4\\}$ forms a complete graph; that is, every site in this set is connected to every other site in this set.\n2.  The set of sites $\\{B_1, B_2, B_3, B_4\\}$ also forms a complete graph.\n3.  A single connection exists between site $A_4$ and site $B_1$, linking the two complete graphs.\nThere are no other connections.\n\nA particle performs a random walk on this network of sites. At each discrete time step, the particle, currently at a site, moves to one of its directly connected (adjacent) sites. The destination site is chosen uniformly at random from all available adjacent sites.\n\nAfter a very large number of time steps, the system approaches a steady state where the probability of finding the particle at any given site becomes constant. This is known as the limiting probability.\n\nDetermine the limiting probability of finding the particle at site $A_2$. Express your answer as an exact fraction in simplest form.", "solution": "Model the random walk as a Markov chain on an undirected, connected graph. For a simple random walk on an undirected graph with vertex set $V$ and edge set $E$, the transition probability from a vertex $u$ to an adjacent vertex $v$ is\n$$\nP(u \\to v) = \\frac{1}{\\deg(u)} \\quad \\text{if } \\{u,v\\} \\in E,\n$$\nand zero otherwise. A standard result using detailed balance shows that the stationary distribution $\\pi$ is\n$$\n\\pi(v) = \\frac{\\deg(v)}{2|E|} \\quad \\text{for all } v \\in V,\n$$\nbecause for adjacent $u,v$,\n$$\n\\pi(u)P(u \\to v) = \\frac{\\deg(u)}{2|E|} \\cdot \\frac{1}{\\deg(u)} = \\frac{1}{2|E|} = \\frac{\\deg(v)}{2|E|} \\cdot \\frac{1}{\\deg(v)} = \\pi(v)P(v \\to u).\n$$\nThe given graph is connected and contains triangles (each $K_{4}$ clique), so the chain is irreducible and aperiodic, implying convergence to the unique stationary distribution.\n\nCompute degrees:\n- In each $K_{4}$, every vertex has degree $3$ within its clique.\n- The bridge adds one edge between $A_{4}$ and $B_{1}$, so $\\deg(A_{4}) = 4$ and $\\deg(B_{1}) = 4$.\n- All other vertices retain degree $3$.\n\nThus,\n$$\n\\deg(A_{1})=\\deg(A_{2})=\\deg(A_{3})=3,\\quad \\deg(A_{4})=4,\\quad \\deg(B_{1})=4,\\quad \\deg(B_{2})=\\deg(B_{3})=\\deg(B_{4})=3.\n$$\nCount edges: each $K_{4}$ contributes $\\binom{4}{2}=6$ edges, and the bridge adds $1$, so\n$$\n|E| = 6 + 6 + 1 = 13, \\quad \\text{hence} \\quad 2|E| = 26.\n$$\nEquivalently, the handshaking lemma confirms $\\sum_{v \\in V} \\deg(v) = 3+3+3+4+4+3+3+3 = 26 = 2|E|$.\n\nTherefore, the limiting probability at $A_{2}$ is\n$$\n\\pi(A_{2}) = \\frac{\\deg(A_{2})}{2|E|} = \\frac{3}{26}.\n$$", "answer": "$$\\boxed{\\frac{3}{26}}$$", "id": "1370816"}]}