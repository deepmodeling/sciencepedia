{"hands_on_practices": [{"introduction": "The cornerstone of working with discrete-time Markov chains is understanding how to predict the system's state in the future. This first practice focuses on that fundamental skill. By defining a transition matrix $P$ and an initial distribution $\\pi^{(0)}$, we can calculate the state distribution $\\pi^{(n)}$ after any number of steps, providing a direct glimpse into the chain's evolution. [@problem_id:1297401]", "problem": "A data science team is developing a simplified model to predict user engagement on a new social media platform. The model assumes a user can be in one of two states at any given time step: State 1 (\"Actively Browsing\") or State 2 (\"Considering Leaving\"). The state of the user is re-evaluated after they are shown each new piece of content.\n\nThe transitions between states are modeled as a discrete-time Markov chain with the following rules:\n- If a user is \"Actively Browsing\" (State 1), the next piece of content will keep them in this state with a probability of $\\alpha$.\n- If a user is \"Considering Leaving\" (State 2), a special re-engagement algorithm is used. The content shown will successfully transition them back to \"Actively Browsing\" (State 1) with a probability of $\\beta$.\n\nAssume $0 < \\alpha < 1$ and $0 < \\beta < 1$.\n\nA new user begins a session on the platform. The initial probability that they are in the \"Actively Browsing\" state is $p_0$, and thus the probability they are in the \"Considering Leaving\" state is $1-p_0$.\n\nDetermine the probability distribution of the user's state after they have been shown exactly two pieces of content. Your answer should be a row vector of two components, where the first component is the probability of being in State 1 and the second component is the probability of being in State 2. Express your answer in terms of $\\alpha$, $\\beta$, and $p_0$.", "solution": "Let the state space of the Markov chain be $S = \\{1, 2\\}$, where State 1 represents \"Actively Browsing\" and State 2 represents \"Considering Leaving\".\n\nFirst, we define the initial probability distribution vector, $\\pi^{(0)}$. According to the problem, the initial probability of being in State 1 is $p_0$ and in State 2 is $1-p_0$.\n$$\n\\pi^{(0)} = \\begin{pmatrix} p_0 & 1-p_0 \\end{pmatrix}\n$$\n\nNext, we construct the one-step transition probability matrix $P$. The element $P_{ij}$ represents the probability of transitioning from state $i$ to state $j$.\nFrom the problem description:\n- The probability of transitioning from State 1 to State 1 is $P_{11} = \\alpha$.\n- Since the probabilities in any row must sum to 1, the probability of transitioning from State 1 to State 2 is $P_{12} = 1 - \\alpha$.\n- The probability of transitioning from State 2 to State 1 is $P_{21} = \\beta$.\n- Similarly, the probability of remaining in State 2 is $P_{22} = 1 - \\beta$.\n\nThus, the transition matrix $P$ is:\n$$\nP = \\begin{pmatrix}\n\\alpha & 1-\\alpha \\\\\n\\beta & 1-\\beta\n\\end{pmatrix}\n$$\n\nThe probability distribution after $n$ steps, $\\pi^{(n)}$, is given by the equation $\\pi^{(n)} = \\pi^{(0)} P^n$. We need to find the distribution after two steps, $\\pi^{(2)}$, which is calculated as $\\pi^{(2)} = \\pi^{(0)} P^2$.\n\nFirst, let's compute the two-step transition matrix, $P^2 = P \\times P$.\n$$\nP^2 = \\begin{pmatrix}\n\\alpha & 1-\\alpha \\\\\n\\beta & 1-\\beta\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha & 1-\\alpha \\\\\n\\beta & 1-\\beta\n\\end{pmatrix}\n$$\nThe components of $P^2$ are:\n$$\n(P^2)_{11} = (\\alpha)(\\alpha) + (1-\\alpha)(\\beta) = \\alpha^2 + \\beta - \\alpha\\beta\n$$\n$$\n(P^2)_{12} = (\\alpha)(1-\\alpha) + (1-\\alpha)(1-\\beta) = \\alpha - \\alpha^2 + 1 - \\beta - \\alpha + \\alpha\\beta = 1 - \\alpha^2 - \\beta + \\alpha\\beta\n$$\n$$\n(P^2)_{21} = (\\beta)(\\alpha) + (1-\\beta)(\\beta) = \\alpha\\beta + \\beta - \\beta^2\n$$\n$$\n(P^2)_{22} = (\\beta)(1-\\alpha) + (1-\\beta)(1-\\beta) = \\beta - \\alpha\\beta + 1 - 2\\beta + \\beta^2 = 1 - \\beta - \\alpha\\beta + \\beta^2\n$$\nSo, the two-step transition matrix is:\n$$\nP^2 = \\begin{pmatrix}\n\\alpha^2 + \\beta - \\alpha\\beta & 1 - \\alpha^2 - \\beta + \\alpha\\beta \\\\\n\\alpha\\beta + \\beta - \\beta^2 & 1 - \\alpha\\beta - \\beta + \\beta^2\n\\end{pmatrix}\n$$\n\nNow we can compute $\\pi^{(2)} = \\pi^{(0)} P^2$.\n$$\n\\pi^{(2)} = \\begin{pmatrix} \\pi_1^{(2)} & \\pi_2^{(2)} \\end{pmatrix} = \\begin{pmatrix} p_0 & 1-p_0 \\end{pmatrix} \\begin{pmatrix}\n(P^2)_{11} & (P^2)_{12} \\\\\n(P^2)_{21} & (P^2)_{22}\n\\end{pmatrix}\n$$\nThe first component, $\\pi_1^{(2)}$, which is the probability of being in State 1 after two steps, is:\n$$\n\\pi_1^{(2)} = p_0 (P^2)_{11} + (1-p_0) (P^2)_{21}\n$$\n$$\n\\pi_1^{(2)} = p_0 (\\alpha^2 + \\beta - \\alpha\\beta) + (1-p_0) (\\alpha\\beta + \\beta - \\beta^2)\n$$\nExpanding this expression:\n$$\n\\pi_1^{(2)} = p_0 \\alpha^2 + p_0 \\beta - p_0 \\alpha\\beta + \\alpha\\beta + \\beta - \\beta^2 - p_0 \\alpha\\beta - p_0 \\beta + p_0 \\beta^2\n$$\nThe terms $p_0 \\beta$ and $-p_0 \\beta$ cancel out. Grouping the remaining terms:\n$$\n\\pi_1^{(2)} = p_0 \\alpha^2 - 2 p_0 \\alpha\\beta + p_0 \\beta^2 + \\alpha\\beta + \\beta - \\beta^2\n$$\nWe can factor $p_0$ from the first three terms and $\\beta$ from the last three terms:\n$$\n\\pi_1^{(2)} = p_0 (\\alpha^2 - 2\\alpha\\beta + \\beta^2) + \\beta(\\alpha + 1 - \\beta)\n$$\nRecognizing the perfect square, we get a simplified expression for the first component:\n$$\n\\pi_1^{(2)} = p_0 (\\alpha-\\beta)^2 + \\beta(1+\\alpha-\\beta)\n$$\nThe second component, $\\pi_2^{(2)}$, is the probability of being in State 2. Since there are only two states, the probabilities must sum to 1, so $\\pi_2^{(2)} = 1 - \\pi_1^{(2)}$.\n$$\n\\pi_2^{(2)} = 1 - \\left[ p_0 (\\alpha-\\beta)^2 + \\beta(1+\\alpha-\\beta) \\right]\n$$\n$$\n\\pi_2^{(2)} = 1 - p_0 (\\alpha-\\beta)^2 - \\beta(1+\\alpha-\\beta)\n$$\nTherefore, the probability distribution after two steps is $\\pi^{(2)} = \\begin{pmatrix} \\pi_1^{(2)} & \\pi_2^{(2)} \\end{pmatrix}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\np_0 (\\alpha-\\beta)^2 + \\beta(1+\\alpha-\\beta) & 1 - p_0 (\\alpha-\\beta)^2 - \\beta(1+\\alpha-\\beta)\n\\end{pmatrix}\n}\n$$", "id": "1297401"}, {"introduction": "Markov chains possess an underlying structure that dictates their long-term behavior. This exercise moves beyond simple calculation to an analysis of this structure, introducing the concept of a state's period. By examining the possible number of steps to return to a starting state, you will learn to classify states and identify fundamental patterns within the chain's dynamics. [@problem_id:1297460]", "problem": "A small autonomous cleaning robot operates on a large, square-shaped solar panel installation. At each of the four corners of the square, there is a charging station. We can label these stations $S_1$, $S_2$, $S_3$, and $S_4$ in a clockwise manner.\n\nThe robot's movement can be modeled as a discrete-time Markov chain. The robot moves from one station to an adjacent station at each time step. Due to a slight mechanical bias, the robot's movements are not uniformly random. From any given station, the robot moves to the next station in the clockwise direction with a probability $p = 3/5$, and to the next station in the counter-clockwise direction with a probability $1-p = 2/5$. For instance, from station $S_1$, it will move to $S_2$ with probability $3/5$ or to $S_4$ with probability $2/5$. The robot cannot stay at the same station or move to the diagonally opposite station in a single step.\n\nThe period of a state in a Markov chain is defined as the greatest common divisor of all possible numbers of steps it can take to return to that state, starting from that state.\n\nDetermine the period of the state corresponding to the robot being at station $S_1$.", "solution": "We model the robot as a discrete-time Markov chain on the state space $\\{S_{1},S_{2},S_{3},S_{4}\\}$, where from any state the robot moves to one of its two adjacent states with positive probabilities: clockwise with probability $p=\\frac{3}{5}$ and counter-clockwise with probability $1-p=\\frac{2}{5}$. Thus, from each station there are exactly two outgoing transitions, both with positive probability.\n\nThe period $d(i)$ of a state $i$ is defined by\n$$\nd(i)=\\gcd\\{n\\geq 1: P_{ii}^{(n)}>0\\},\n$$\nwhere $P_{ii}^{(n)}$ is the $n$-step return probability to $i$.\n\nFirst, observe that the underlying graph is the $4$-cycle, which is bipartite with bipartition $\\{S_{1},S_{3}\\}$ and $\\{S_{2},S_{4}\\}$. Every move switches the part because the robot always moves to an adjacent station and cannot remain in place. Therefore, starting from $S_{1}\\in\\{S_{1},S_{3}\\}$, after an odd number of steps the robot must be in $\\{S_{2},S_{4}\\}$ and cannot be at $S_{1}$. Hence, for all odd $n$,\n$$\nP_{11}^{(n)}=0.\n$$\n\nNext, we show that returns in even times occur with positive probability. In $2$ steps, one can take $S_{1}\\to S_{2}\\to S_{1}$ with probability $p(1-p)>0$ or $S_{1}\\to S_{4}\\to S_{1}$ with probability $(1-p)p>0$, so\n$$\nP_{11}^{(2)}\\geq p(1-p)+(1-p)p=2p(1-p)>0.\n$$\nFor any even $n=2k$, one can concatenate $k$ copies of a $2$-step back-and-forth path (for example, $(S_{1}\\to S_{2}\\to S_{1})^{k}$), which has probability $\\left(p(1-p)\\right)^{k}>0$. Therefore, for every even $n$,\n$$\nP_{11}^{(2k)}\\geq \\left(p(1-p)\\right)^{k}>0.\n$$\n\nCombining these two facts, the set $\\{n\\geq 1: P_{11}^{(n)}>0\\}$ is exactly the set of positive even integers. Its greatest common divisor is\n$$\n\\gcd\\{2,4,6,\\dots\\}=2.\n$$\nTherefore, the period of state $S_{1}$ is $2$.", "answer": "$$\\boxed{2}$$", "id": "1297460"}, {"introduction": "Many systems modeled by Markov chains eventually end up in a terminal or 'absorbing' state, which raises a crucial question: what is the probability of ending in one terminal state versus another? This practice introduces a powerful technique called First-Step Analysis, which uses the Markov property to set up a system of linear equations to find these 'absorption probabilities'. Mastering this method is key to analyzing the ultimate fate of a process. [@problem_id:1297439]", "problem": "A simplified model for the operational status of a piece of industrial machinery is described by a discrete-time Markov chain on the state space $S = \\{1, 2, 3, 4\\}$. The states are defined as:\n- State 1: Under Maintenance\n- State 2: Idle\n- State 3: Active\n- State 4: Critical Failure\n\nThe state of the machinery is observed at the end of each hour. Once the machine enters State 1 or State 4, it remains in that state. For the other states, the one-step transition probabilities are as follows:\n\nFrom State 2 (Idle), the machine transitions to:\n- State 1 with probability $p_{21} = 0.1$\n- State 2 with probability $p_{22} = 0.5$\n- State 3 with probability $p_{23} = 0.3$\n- State 4 with probability $p_{24} = 0.1$\n\nFrom State 3 (Active), the machine transitions to:\n- State 1 with probability $p_{31} = 0.2$\n- State 2 with probability $p_{32} = 0.4$\n- State 3 with probability $p_{33} = 0.1$\n- State 4 with probability $p_{34} = 0.3$\n\nSuppose the machine is currently in the Idle state (State 2). Calculate the probability that it will enter Critical Failure (State 4) before it enters the Under Maintenance state (State 1). Express your answer as an exact fraction.", "solution": "We model the event of hitting State 4 (Critical Failure) before State 1 (Under Maintenance) using hitting probabilities in an absorbing Markov chain. Let $h_{i}$ denote the probability that, starting from state $i$, the chain reaches State $4$ before State $1$. Since States $1$ and $4$ are absorbing, the boundary conditions are $h_{1}=0$ and $h_{4}=1$. By first-step analysis for transient states $2$ and $3$, we have\n$$\nh_{2} = p_{22} h_{2} + p_{23} h_{3} + p_{24}\\cdot 1 + p_{21}\\cdot 0,\n\\quad\nh_{3} = p_{32} h_{2} + p_{33} h_{3} + p_{34}\\cdot 1 + p_{31}\\cdot 0.\n$$\nSubstituting the given transition probabilities, written as exact fractions,\n$$\nh_{2} = \\frac{1}{2} h_{2} + \\frac{3}{10} h_{3} + \\frac{1}{10}, \n\\quad\nh_{3} = \\frac{2}{5} h_{2} + \\frac{1}{10} h_{3} + \\frac{3}{10}.\n$$\nRearranging,\n$$\n\\left(1 - \\frac{1}{2}\\right) h_{2} - \\frac{3}{10} h_{3} = \\frac{1}{10},\n\\quad\n-\\frac{2}{5} h_{2} + \\left(1 - \\frac{1}{10}\\right) h_{3} = \\frac{3}{10},\n$$\nwhich simplifies to\n$$\n\\frac{1}{2} h_{2} - \\frac{3}{10} h_{3} = \\frac{1}{10},\n\\quad\n-\\frac{2}{5} h_{2} + \\frac{9}{10} h_{3} = \\frac{3}{10}.\n$$\nMultiplying both equations by $10$ gives\n$$\n5 h_{2} - 3 h_{3} = 1,\n\\quad\n-4 h_{2} + 9 h_{3} = 3.\n$$\nFrom the first equation, $h_{2} = \\frac{1 + 3 h_{3}}{5}$. Substituting into the second,\n$$\n-4 \\cdot \\frac{1 + 3 h_{3}}{5} + 9 h_{3} = 3\n\\;\\Rightarrow\\;\n-\\frac{4}{5} - \\frac{12}{5} h_{3} + 9 h_{3} = 3\n\\;\\Rightarrow\\;\n\\frac{33}{5} h_{3} - \\frac{4}{5} = 3.\n$$\nMultiplying by $5$,\n$$\n33 h_{3} - 4 = 15 \\;\\Rightarrow\\; 33 h_{3} = 19 \\;\\Rightarrow\\; h_{3} = \\frac{19}{33}.\n$$\nThen\n$$\nh_{2} = \\frac{1 + 3 \\cdot \\frac{19}{33}}{5} = \\frac{\\frac{33}{33} + \\frac{57}{33}}{5} = \\frac{\\frac{90}{33}}{5} = \\frac{90}{165} = \\frac{6}{11}.\n$$\nThus, starting from State $2$ (Idle), the probability of entering State $4$ (Critical Failure) before State $1$ (Under Maintenance) is $\\frac{6}{11}$.", "answer": "$$\\boxed{\\frac{6}{11}}$$", "id": "1297439"}]}