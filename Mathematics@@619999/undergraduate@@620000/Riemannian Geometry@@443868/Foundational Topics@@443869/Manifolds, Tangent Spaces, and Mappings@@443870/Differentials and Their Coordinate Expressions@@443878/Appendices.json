{"hands_on_practices": [{"introduction": "The differential, or pushforward, is the fundamental tool for understanding how a smooth map between manifolds transforms tangent vectors. At its core, it provides the best linear approximation of the map at a point. This first exercise [@problem_id:3043931] guides you through computing the differential directly from its abstract definition, connecting it to the more familiar and computationally practical Jacobian matrix. Mastering this connection is the first step toward analyzing the local behavior of maps in any coordinate system.", "problem": "Let $\\phi:\\mathbb{R}^{3}\\to\\mathbb{R}^{2}$ be the smooth map defined by $\\phi(u,v,w)=(u^{2}+v^{2},\\,w)$. Equip $\\mathbb{R}^{3}$ and $\\mathbb{R}^{2}$ with their standard Euclidean structures and use the standard coordinate bases $\\left\\{\\frac{\\partial}{\\partial u},\\frac{\\partial}{\\partial v},\\frac{\\partial}{\\partial w}\\right\\}$ at a point $p=(u,v,w)\\in\\mathbb{R}^{3}$ and $\\left\\{\\frac{\\partial}{\\partial x},\\frac{\\partial}{\\partial y}\\right\\}$ at the point $\\phi(p)\\in\\mathbb{R}^{2}$, where $(x,y)$ denote the standard coordinates on $\\mathbb{R}^{2}$. Starting from the definition of the pushforward (differential) $d\\phi_{p}:T_{p}\\mathbb{R}^{3}\\to T_{\\phi(p)}\\mathbb{R}^{2}$ as the unique linear map satisfying $d\\phi_{p}(X)(f)=X(f\\circ\\phi)$ for all tangent vectors $X\\in T_{p}\\mathbb{R}^{3}$ and smooth functions $f$ on $\\mathbb{R}^{2}$, compute $d\\phi_{p}$ acting on the basis vectors $\\frac{\\partial}{\\partial u}\\big|_{p}$, $\\frac{\\partial}{\\partial v}\\big|_{p}$, and $\\frac{\\partial}{\\partial w}\\big|_{p}$. Then, express the corresponding Jacobian matrix of $\\phi$ at $p$ relative to these bases.\n\nProvide your final answer as a single closed-form analytic expression for the Jacobian matrix with entries in terms of $u$, $v$, and $w$. No rounding is required.", "solution": "The problem as stated is valid. It is a well-posed, self-contained, and scientifically grounded exercise in differential geometry, asking for the computation of the differential of a smooth map and its corresponding Jacobian matrix. All terms are standard and clearly defined.\n\nLet the smooth map be $\\phi:\\mathbb{R}^{3}\\to\\mathbb{R}^{2}$ defined by $\\phi(u,v,w)=(u^{2}+v^{2},\\,w)$. The coordinates on $\\mathbb{R}^{3}$ are $(u,v,w)$ and on $\\mathbb{R}^{2}$ are $(x,y)$. The point in the domain is $p=(u,v,w)$, and its image is $\\phi(p)=(u^{2}+v^{2}, w)$. The standard coordinate bases for the tangent spaces are $\\left\\{\\frac{\\partial}{\\partial u}\\big|_{p}, \\frac{\\partial}{\\partial v}\\big|_{p}, \\frac{\\partial}{\\partial w}\\big|_{p}\\right\\}$ for $T_{p}\\mathbb{R}^{3}$ and $\\left\\{\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)}, \\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}\\right\\}$ for $T_{\\phi(p)}\\mathbb{R}^{2}$.\n\nThe pushforward (or differential) of $\\phi$ at $p$, denoted $d\\phi_{p}:T_{p}\\mathbb{R}^{3}\\to T_{\\phi(p)}\\mathbb{R}^{2}$, is defined by its action on a smooth function $f$ on $\\mathbb{R}^{2}$. For any tangent vector $X \\in T_{p}\\mathbb{R}^{3}$, the vector $d\\phi_{p}(X) \\in T_{\\phi(p)}\\mathbb{R}^{2}$ is defined such that for any smooth function $f:\\mathbb{R}^{2}\\to\\mathbb{R}$, we have $[d\\phi_{p}(X)](f) = X(f\\circ\\phi)$.\n\nWe are asked to compute the action of $d\\phi_{p}$ on the basis vectors of $T_{p}\\mathbb{R}^{3}$. The results will be vectors in $T_{\\phi(p)}\\mathbb{R}^{2}$, which can be expressed as linear combinations of the basis vectors $\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)}$ and $\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$.\n\nLet $d\\phi_{p}\\left(\\frac{\\partial}{\\partial u}\\big|_{p}\\right) = A_{1}\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)} + B_{1}\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$. To find the coefficients $A_{1}$ and $B_{1}$, we evaluate this vector on the coordinate functions $x$ and $y$ on $\\mathbb{R}^{2}$.\nUsing the property that $\\frac{\\partial}{\\partial x}(x)=1$, $\\frac{\\partial}{\\partial x}(y)=0$, $\\frac{\\partial}{\\partial y}(x)=0$, and $\\frac{\\partial}{\\partial y}(y)=1$, we find:\n$A_{1} = \\left[d\\phi_{p}\\left(\\frac{\\partial}{\\partial u}\\big|_{p}\\right)\\right](x)$\n$B_{1} = \\left[d\\phi_{p}\\left(\\frac{\\partial}{\\partial u}\\big|_{p}\\right)\\right](y)$\n\nUsing the definition of the pushforward, we relate these to derivatives in the domain:\n$A_{1} = \\frac{\\partial}{\\partial u}\\big|_{p}(x\\circ\\phi)$\n$B_{1} = \\frac{\\partial}{\\partial u}\\big|_{p}(y\\circ\\phi)$\n\nThe composition functions are found by substituting the definition of $\\phi$ into the coordinate functions $x$ and $y$. Let $x(\\cdot,\\cdot)$ and $y(\\cdot,\\cdot)$ be the projection maps on $\\mathbb{R}^2$.\nThen $x\\circ\\phi(u,v,w) = x(u^{2}+v^{2}, w) = u^{2}+v^{2}$.\nAnd $y\\circ\\phi(u,v,w) = y(u^{2}+v^{2}, w) = w$.\n\nNow we compute the coefficients for each basis vector.\n\n1.  For the basis vector $\\frac{\\partial}{\\partial u}\\big|_{p}$:\n    $A_{1} = \\frac{\\partial}{\\partial u}(u^{2}+v^{2}) = 2u$\n    $B_{1} = \\frac{\\partial}{\\partial u}(w) = 0$\n    Thus, $d\\phi_{p}\\left(\\frac{\\partial}{\\partial u}\\big|_{p}\\right) = 2u\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)} + 0\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$.\n\n2.  For the basis vector $\\frac{\\partial}{\\partial v}\\big|_{p}$:\n    Let $d\\phi_{p}\\left(\\frac{\\partial}{\\partial v}\\big|_{p}\\right) = A_{2}\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)} + B_{2}\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$.\n    $A_{2} = \\frac{\\partial}{\\partial v}(x\\circ\\phi) = \\frac{\\partial}{\\partial v}(u^{2}+v^{2}) = 2v$\n    $B_{2} = \\frac{\\partial}{\\partial v}(y\\circ\\phi) = \\frac{\\partial}{\\partial v}(w) = 0$\n    Thus, $d\\phi_{p}\\left(\\frac{\\partial}{\\partial v}\\big|_{p}\\right) = 2v\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)} + 0\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$.\n\n3.  For the basis vector $\\frac{\\partial}{\\partial w}\\big|_{p}$:\n    Let $d\\phi_{p}\\left(\\frac{\\partial}{\\partial w}\\big|_{p}\\right) = A_{3}\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)} + B_{3}\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$.\n    $A_{3} = \\frac{\\partial}{\\partial w}(x\\circ\\phi) = \\frac{\\partial}{\\partial w}(u^{2}+v^{2}) = 0$\n    $B_{3} = \\frac{\\partial}{\\partial w}(y\\circ\\phi) = \\frac{\\partial}{\\partial w}(w) = 1$\n    Thus, $d\\phi_{p}\\left(\\frac{\\partial}{\\partial w}\\big|_{p}\\right) = 0\\frac{\\partial}{\\partial x}\\big|_{\\phi(p)} + 1\\frac{\\partial}{\\partial y}\\big|_{\\phi(p)}$.\n\nThe Jacobian matrix of $\\phi$ at $p$, denoted $J(\\phi)_{p}$, is the matrix representation of the linear map $d\\phi_{p}$ with respect to the given bases. Its columns are the coordinate vectors of the images of the domain's basis vectors.\nThe first column is the coordinate vector of $d\\phi_{p}\\left(\\frac{\\partial}{\\partial u}\\big|_{p}\\right)$, which is $\\begin{pmatrix} 2u \\\\ 0 \\end{pmatrix}$.\nThe second column is the coordinate vector of $d\\phi_{p}\\left(\\frac{\\partial}{\\partial v}\\big|_{p}\\right)$, which is $\\begin{pmatrix} 2v \\\\ 0 \\end{pmatrix}$.\nThe third column is the coordinate vector of $d\\phi_{p}\\left(\\frac{\\partial}{\\partial w}\\big|_{p}\\right)$, which is $\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\n\nAssembling these columns gives the Jacobian matrix:\n$J(\\phi)_{p} = \\begin{pmatrix} 2u & 2v & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$\n\nThis matrix is also obtained by computing the partial derivatives of the component functions of $\\phi$. If we let $\\phi(u,v,w) = (\\phi_1(u,v,w), \\phi_2(u,v,w))$, where $\\phi_1(u,v,w) = u^2+v^2$ and $\\phi_2(u,v,w) = w$, the Jacobian matrix $J$ has entries $J_{ij} = \\frac{\\partial \\phi_i}{\\partial u^j}$, where $u^1=u, u^2=v, u^3=w$.\n$J = \\begin{pmatrix} \\frac{\\partial\\phi_{1}}{\\partial u} & \\frac{\\partial\\phi_{1}}{\\partial v} & \\frac{\\partial\\phi_{1}}{\\partial w} \\\\ \\frac{\\partial\\phi_{2}}{\\partial u} & \\frac{\\partial\\phi_{2}}{\\partial v} & \\frac{\\partial\\phi_{2}}{\\partial w} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\partial}{\\partial u}(u^{2}+v^{2}) & \\frac{\\partial}{\\partial v}(u^{2}+v^{2}) & \\frac{\\partial}{\\partial w}(u^{2}+v^{2}) \\\\ \\frac{\\partial}{\\partial u}(w) & \\frac{\\partial}{\\partial v}(w) & \\frac{\\partial}{\\partial w}(w) \\end{pmatrix} = \\begin{pmatrix} 2u & 2v & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$.\nThe result is consistent.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2u & 2v & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n}\n$$", "id": "3043931"}, {"introduction": "While the differential $df$ tells us about the direction of a function's steepest ascent, it doesn't by itself tell us the *magnitude* of this change. On a Riemannian manifold, this information is encoded in the metric tensor $g$. This practice [@problem_id:3043932] demonstrates how to use the metric to define a norm on the cotangent space, allowing us to calculate the pointwise magnitude of the gradient, $|df|$. You will see how the geometry of the space, in this case the stretching of coordinates in the polar system, directly affects our measurement of the function's rate of change.", "problem": "Consider the Riemannian metric $g$ on $\\mathbb{R}^{2}\\setminus\\{(0,0)\\}$ written in polar coordinates $(r,\\theta)$ as $g = dr^{2} + r^{2}\\, d\\theta^{2}$. Let $f \\colon \\mathbb{R}^{2}\\setminus\\{(0,0)\\} \\to \\mathbb{R}$ be the function $f(r,\\theta) = \\log r$. Using only the definition that a Riemannian metric $g$ induces an inner product on cotangent spaces via the inverse metric $g^{-1}$, compute the pointwise norm $\\lvert df \\rvert$ of the differential $df$ with respect to $g$, expressed as a coordinate function of $(r,\\theta)$. Then, interpret its behavior as $r \\to 0$ within the given domain. Your final answer must be a single closed-form expression for $\\lvert df \\rvert$ in terms of $r$. No rounding is required, and no units are involved.", "solution": "The problem as stated is well-posed, scientifically grounded, and provides all necessary information for a unique solution. We can proceed with the calculation.\n\nThe problem asks for the pointwise norm of the differential $df$ of the function $f(r,\\theta) = \\log r$ on the manifold $M = \\mathbb{R}^{2}\\setminus\\{(0,0)\\}$ with the Riemannian metric $g = dr^{2} + r^{2}\\, d\\theta^{2}$. By convention in this field, $\\log r$ denotes the natural logarithm, $\\ln r$. The domain of the polar coordinates $(r, \\theta)$ is $r \\in (0, \\infty)$ and $\\theta \\in [0, 2\\pi)$.\n\nFirst, we write the metric tensor $g$ in matrix form with respect to the coordinate basis of the cotangent space, $\\{dr, d\\theta\\}$. The components $g_{ij}$ are the coefficients of the quadratic form $g = \\sum_{i,j=1}^{2} g_{ij} dx^i \\otimes dx^j$. For coordinates $(x^1, x^2) = (r, \\theta)$, we have $g_{11}=g_{rr}=1$, $g_{22}=g_{\\theta\\theta}=r^2$, and $g_{12}=g_{21}=g_{r\\theta}=0$. The matrix representation of the metric tensor is:\n$$\n[g_{ij}] = \\begin{pmatrix} 1 & 0 \\\\ 0 & r^2 \\end{pmatrix}\n$$\n\nThe norm of a $1$-form (like $df$) is defined using the inverse metric tensor, $g^{-1}$. The components of the inverse metric, denoted $g^{ij}$, form a matrix $[g^{ij}]$ which is the inverse of $[g_{ij}]$.\n$$\n[g^{ij}] = [g_{ij}]^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & r^2 \\end{pmatrix}^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{r^2} \\end{pmatrix}\n$$\nThus, the non-zero components of the inverse metric tensor are $g^{rr} = 1$ and $g^{\\theta\\theta} = \\frac{1}{r^2}$.\n\nNext, we compute the differential of the function $f(r, \\theta) = \\log r$. The differential $df$ is a $1$-form given by the expression:\n$$\ndf = \\frac{\\partial f}{\\partial r} dr + \\frac{\\partial f}{\\partial \\theta} d\\theta\n$$\nThe partial derivatives of $f$ are:\n$$\n\\frac{\\partial f}{\\partial r} = \\frac{\\partial}{\\partial r}(\\log r) = \\frac{1}{r}\n$$\n$$\n\\frac{\\partial f}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta}(\\log r) = 0\n$$\nSubstituting these into the expression for $df$, we get:\n$$\ndf = \\frac{1}{r} dr + 0 \\cdot d\\theta = \\frac{1}{r} dr\n$$\nThe components of the $1$-form $df$ in the coordinate basis are therefore $(\\partial_r f, \\partial_\\theta f) = \\left(\\frac{1}{r}, 0\\right)$.\n\nThe squared pointwise norm of $df$, denoted $|df|^2_g$, is calculated using the components of the inverse metric tensor and the components of $df$:\n$$\n|df|^2_g = \\sum_{i,j=1}^{2} g^{ij} (\\partial_i f) (\\partial_j f) = g^{rr} \\left(\\frac{\\partial f}{\\partial r}\\right)^2 + 2 g^{r\\theta} \\left(\\frac{\\partial f}{\\partial r}\\right)\\left(\\frac{\\partial f}{\\partial \\theta}\\right) + g^{\\theta\\theta} \\left(\\frac{\\partial f}{\\partial \\theta}\\right)^2\n$$\nSubstituting the values we found for $g^{ij}$ and the partial derivatives of $f$:\n$$\n|df|^2_g = (1) \\left(\\frac{1}{r}\\right)^2 + 2(0)\\left(\\frac{1}{r}\\right)(0) + \\left(\\frac{1}{r^2}\\right)(0)^2\n$$\n$$\n|df|^2_g = \\frac{1}{r^2}\n$$\nThe pointwise norm $|df|_g$ is the square root of this value. Since the coordinate $r$ is always positive in the domain $\\mathbb{R}^{2}\\setminus\\{(0,0)\\}$, we take the positive square root:\n$$\n|df|_g = \\sqrt{\\frac{1}{r^2}} = \\frac{1}{|r|} = \\frac{1}{r}\n$$\n\nThe problem also asks for an interpretation of the behavior of $|df|$ as $r \\to 0$. We examine the limit:\n$$\n\\lim_{r \\to 0^+} |df|_g = \\lim_{r \\to 0^+} \\frac{1}{r} = +\\infty\n$$\nThe norm of the differential, $|df|$, is the magnitude of the gradient of the function $f$. The fact that this norm diverges to infinity as one approaches the origin means that the function $f(r,\\theta) = \\log r$ changes infinitely rapidly near the origin. The level sets of $f$ are concentric circles, and the spacing between these level sets becomes infinitesimally small as $r \\to 0$, which corresponds to an unbounded rate of change.", "answer": "$$\\boxed{\\frac{1}{r}}$$", "id": "3043932"}, {"introduction": "Having learned to compute the differential $df$ and its norm $|df|$, we can now apply these tools to solve geometric optimization problems. On a compact manifold like the two-dimensional torus, a continuous function must attain a maximum and minimum value; similarly, the rate of change of the function, $|df|$, must also be maximized somewhere. This exercise [@problem_id:3043939] challenges you to find the points on a flat torus where a given function is \"steepest,\" synthesizing your skills in calculus and differential geometry to answer a natural geometric question.", "problem": "Let $T^{2}$ denote the flat two-dimensional torus realized as $\\left[0,2\\pi\\right) \\times \\left[0,2\\pi\\right)$ with the standard Euclidean Riemannian metric given in coordinates by $g = dx^{2} + dy^{2}$, where the coordinates $x$ and $y$ are measured in radians. Consider the smooth function $f : T^{2} \\to \\mathbb{R}$ defined by $f(x,y) = \\sin x + 2 \\cos y$. Using the coordinate definition of the differential as a covector field, compute the differential $df$ explicitly, and then use the induced pointwise norm on cotangent vectors (the dual norm from the metric $g$) to determine the points in $T^{2}$ at which the pointwise norm $\\lvert df \\rvert$ attains its maximum. Report only the maximal value of $\\lvert df \\rvert$ as your final answer. No rounding is required.", "solution": "The problem statement is a valid exercise in Riemannian geometry. It is self-contained, scientifically sound, and well-posed. We proceed with the solution.\n\nLet the manifold be the two-dimensional torus $T^{2}$, realized as the square $\\left[0,2\\pi\\right) \\times \\left[0,2\\pi\\right)$ with coordinates $(x, y)$. The problem specifies the standard flat Riemannian metric, which in these coordinates is given by $g = dx^{2} + dy^{2}$. The matrix representation of this metric tensor is:\n$$ g_{ij} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\nwhere the indices $i, j$ correspond to the coordinates $x, y$ respectively.\n\nWe are given a smooth function $f : T^{2} \\to \\mathbb{R}$ defined by $f(x,y) = \\sin x + 2 \\cos y$.\n\nThe first step is to compute the differential of $f$, which is a $1$-form (a covector field) denoted by $df$. In local coordinates $(x^1, \\dots, x^n)$, the differential is given by the formula $df = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x^i} dx^i$. For our two-dimensional case with coordinates $(x,y)$, this becomes:\n$$ df = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy $$\nWe compute the partial derivatives of $f$:\n$$ \\frac{\\partial f}{\\partial x} = \\frac{\\partial}{\\partial x}(\\sin x + 2 \\cos y) = \\cos x $$\n$$ \\frac{\\partial f}{\\partial y} = \\frac{\\partial}{\\partial y}(\\sin x + 2 \\cos y) = -2 \\sin y $$\nSubstituting these expressions into the formula for $df$, we obtain the explicit form of the differential:\n$$ df = (\\cos x) dx + (-2 \\sin y) dy $$\nThis expression defines the covector $df$ at each point $(x,y) \\in T^{2}$. The components of $df$ in the cotangent basis $\\{dx, dy\\}$ are $(\\cos x, -2 \\sin y)$.\n\nThe second step is to compute the pointwise norm of the covector field $df$, which we denote by $\\lvert df \\rvert$. This norm is induced by the Riemannian metric $g$. The components of the inverse metric, $g^{ij}$, are used to define the inner product on the cotangent space at each point. The matrix of $g^{ij}$ is the inverse of the matrix of $g_{ij}$. In this case:\n$$ g^{ij} = (g_{ij})^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} $$\nThe squared norm of a $1$-form $\\omega = \\omega_x dx + \\omega_y dy$ at a point is given by the general formula $|\\omega|^2 = g^{ij}\\omega_i\\omega_j = g^{xx}(\\omega_x)^2 + 2g^{xy}\\omega_x \\omega_y + g^{yy}(\\omega_y)^2$.\nFor our differential $df$, the components are $\\omega_x = \\cos x$ and $\\omega_y = -2 \\sin y$. Using the components of $g^{ij}$, we find the squared norm of $df$:\n$$ \\lvert df \\rvert^2 = g^{xx}(\\cos x)^2 + g^{yy}(-2 \\sin y)^2 $$\n$$ \\lvert df \\rvert^2 = (1)(\\cos x)^2 + (1)(-2 \\sin y)^2 $$\n$$ \\lvert df \\rvert^2 = \\cos^2 x + 4 \\sin^2 y $$\nThe pointwise norm is therefore $\\lvert df \\rvert(x,y) = \\sqrt{\\cos^2 x + 4 \\sin^2 y}$.\n\nThe final step is to find the maximum value of $\\lvert df \\rvert$ on the torus $T^{2}$. Since the square root function is strictly increasing for non-negative arguments, maximizing $\\lvert df \\rvert$ is equivalent to maximizing its square, $\\lvert df \\rvert^2$. Let $H(x,y) = \\lvert df \\rvert^2 = \\cos^2 x + 4 \\sin^2 y$. We need to find the maximum of $H(x,y)$ for $(x,y) \\in [0, 2\\pi) \\times [0, 2\\pi)$.\n\nThe function $H(x,y)$ is a sum of two non-negative terms, one depending only on $x$ and the other only on $y$. To maximize the sum, we can maximize each term independently.\nThe first term is $\\cos^2 x$. The maximum value of $\\cos^2 x$ is $1$, which occurs when $\\cos x = \\pm 1$. This corresponds to $x=0$ and $x=\\pi$.\nThe second term is $4 \\sin^2 y$. The maximum value of this term occurs when $\\sin^2 y$ is maximal. The maximum value of $\\sin^2 y$ is $1$, which occurs when $\\sin y = \\pm 1$. This corresponds to $y=\\frac{\\pi}{2}$ and $y=\\frac{3\\pi}{2}$.\n\nThe maximum value of $H(x,y)$ is the sum of the maxima of the individual terms:\n$$ \\max_{(x,y) \\in T^2} H(x,y) = \\left( \\max_{x \\in [0, 2\\pi)} \\cos^2 x \\right) + \\left( \\max_{y \\in [0, 2\\pi)} 4 \\sin^2 y \\right) $$\n$$ \\max H(x,y) = 1 + 4(1) = 5 $$\nThis maximum is attained at the four points $(0, \\frac{\\pi}{2})$, $(0, \\frac{3\\pi}{2})$, $(\\pi, \\frac{\\pi}{2})$, and $(\\pi, \\frac{3\\pi}{2})$.\n\nThe maximum value of the squared norm $\\lvert df \\rvert^2$ is $5$. Therefore, the maximum value of the norm $\\lvert df \\rvert$ is the square root of this value.\n$$ \\max \\lvert df \\rvert = \\sqrt{5} $$", "answer": "$$\\boxed{\\sqrt{5}}$$", "id": "3043939"}]}