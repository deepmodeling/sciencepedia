{"hands_on_practices": [{"introduction": "To build a solid understanding of the exterior derivative, we begin with a foundational exercise in applying its core rules. This practice focuses on computing the derivative of a simple 2-form on the plane $\\mathbb{R}^2$ by strictly adhering to the axiomatic properties of $d$, such as linearity and the graded Leibniz rule. By working through this calculation step-by-step [@problem_id:3070342], you will gain confidence in manipulating differential forms and see a concrete verification of the important principle that on an $n$-dimensional manifold, any $n$-form is automatically closed (its exterior derivative is zero).", "problem": "Let $(M,g)$ be the Riemannian manifold $(\\mathbb{R}^{2}, g_{\\text{Euc}})$ with standard coordinates $(x,y)$. Consider the $2$-form $\\omega = f(x)\\,g(y)\\, dx \\wedge dy$, where $f$ and $g$ are smooth functions of a single real variable. Using only the foundational properties that define the exterior derivative $d$ on differential forms, namely: linearity, its action on $0$-forms as the differential (so that $d h = \\sum_{i} \\frac{\\partial h}{\\partial x^{i}}\\, dx^{i}$ in local coordinates), the graded Leibniz rule $d(\\alpha \\wedge \\beta) = d\\alpha \\wedge \\beta + (-1)^{\\deg \\alpha}\\, \\alpha \\wedge d\\beta$, and the fact that $d(dx) = 0$ and $d(dy) = 0$, compute $d\\omega$ explicitly in terms of $f$, $g$, and their derivatives. Organize your computation so that it directly confirms the sign in the graded Leibniz rule by viewing $\\omega$ as $(f(x)\\, dx) \\wedge (g(y)\\, dy)$ at an intermediate step. Express your final answer as a single simplified analytic expression for $d\\omega$.", "solution": "The user wants me to solve the following problem:\nLet $(M,g)$ be the Riemannian manifold $(\\mathbb{R}^{2}, g_{\\text{Euc}})$ with standard coordinates $(x,y)$. Consider the $2$-form $\\omega = f(x)\\,g(y)\\, dx \\wedge dy$, where $f$ and $g$ are smooth functions of a single real variable. Using only the foundational properties that define the exterior derivative $d$ on differential forms, namely: linearity, its action on $0$-forms as the differential (so that $d h = \\sum_{i} \\frac{\\partial h}{\\partial x^{i}}\\, dx^{i}$ in local coordinates), the graded Leibniz rule $d(\\alpha \\wedge \\beta) = d\\alpha \\wedge \\beta + (-1)^{\\deg \\alpha}\\, \\alpha \\wedge d\\beta$, and the fact that $d(dx) = 0$ and $d(dy) = 0$, compute $d\\omega$ explicitly in terms of $f$, $g$, and their derivatives. Organize your computation so that it directly confirms the sign in the graded Leibniz rule by viewing $\\omega$ as $(f(x)\\, dx) \\wedge (g(y)\\, dy)$ at an intermediate step. Express your final answer as a single simplified analytic expression for $d\\omega$.\n\n### Step 1: Extract Givens\n-   Manifold: $(M,g) = (\\mathbb{R}^{2}, g_{\\text{Euc}})$ with coordinates $(x,y)$.\n-   2-form: $\\omega = f(x)\\,g(y)\\, dx \\wedge dy$.\n-   Functions: $f$ and $g$ are smooth functions of a single real variable.\n-   Axioms of the exterior derivative $d$:\n    1.  Linearity: $d(a\\alpha + b\\beta) = a d\\alpha + b d\\beta$.\n    2.  Action on 0-forms: For a function $h$, $d h = \\sum_{i} \\frac{\\partial h}{\\partial x^{i}}\\, dx^{i}$.\n    3.  Graded Leibniz rule: $d(\\alpha \\wedge \\beta) = d\\alpha \\wedge \\beta + (-1)^{\\deg \\alpha}\\, \\alpha \\wedge d\\beta$.\n    4.  Nilpotency on basis 1-forms: $d(dx) = 0$ and $d(dy) = 0$.\n-   Procedural Constraint: The computation must be organized by viewing $\\omega$ as the wedge product $(f(x)\\, dx) \\wedge (g(y)\\, dy)$ to explicitly demonstrate the sign in the graded Leibniz rule.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is a standard exercise in differential geometry, based on the well-established axiomatic definition of the exterior derivative. It is scientifically and mathematically sound.\n2.  **Well-Posed**: The problem is clearly stated, with all necessary definitions and constraints provided. A unique solution exists and can be derived from the given axioms.\n3.  **Objective**: The problem is posed in precise, objective mathematical language.\n4.  **Flaws**: There are no scientific or factual unsoundness, no missing information, no contradictions, and no ambiguities. The problem is a valid and well-posed mathematical question.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\n### Detailed Solution\n\nThe problem requires us to compute the exterior derivative $d\\omega$ of the $2$-form $\\omega = f(x)\\,g(y)\\, dx \\wedge dy$ on $\\mathbb{R}^2$. The computation must strictly follow the provided axiomatic properties of the exterior derivative.\n\nAs stipulated by the problem, we begin by expressing $\\omega$ as the wedge product of two $1$-forms. Let us define the $1$-form $\\alpha = f(x)\\, dx$ and the $1$-form $\\beta = g(y)\\, dy$. Then, the $2$-form $\\omega$ can be written as:\n$$\n\\omega = \\alpha \\wedge \\beta\n$$\nThe degree of the form $\\alpha$ is $\\deg \\alpha = 1$. We now apply the graded Leibniz rule to find $d\\omega$:\n$$\nd\\omega = d(\\alpha \\wedge \\beta) = d\\alpha \\wedge \\beta + (-1)^{\\deg \\alpha}\\, \\alpha \\wedge d\\beta\n$$\nSubstituting $\\deg \\alpha = 1$, we explicitly see the role of the sign factor:\n$$\nd\\omega = d\\alpha \\wedge \\beta + (-1)^{1}\\, \\alpha \\wedge d\\beta = d\\alpha \\wedge \\beta - \\alpha \\wedge d\\beta\n$$\nThis formulation satisfies the organizational requirement of the problem. Our next task is to compute $d\\alpha$ and $d\\beta$.\n\nTo compute $d\\alpha = d(f(x)\\, dx)$, we treat $f(x)$ as a $0$-form and $dx$ as a $1$-form and apply the graded Leibniz rule again:\n$$\nd\\alpha = d(f(x) \\wedge dx) = d(f(x)) \\wedge dx + (-1)^{\\deg(f(x))}\\, f(x) \\wedge d(dx)\n$$\nSince $f(x)$ is a $0$-form, its degree is $0$, so $(-1)^{0} = 1$. The expression becomes:\n$$\nd\\alpha = d(f(x)) \\wedge dx + f(x) \\wedge d(dx)\n$$\nWe now evaluate the terms using the other given axioms.\nFirst, for the $0$-form $f(x)$, its exterior derivative is given by its total differential. Since $f$ is a function of $x$ only, we have:\n$$\nd(f(x)) = \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy = \\frac{df}{dx} dx + 0 = f'(x)\\, dx\n$$\nwhere $f'(x)$ is the ordinary derivative of $f$ with respect to its argument.\nSecond, we use the given property that $d(dx) = 0$.\nSubstituting these into the expression for $d\\alpha$:\n$$\nd\\alpha = (f'(x)\\, dx) \\wedge dx + f(x) \\wedge 0\n$$\nBy the alternating property of the wedge product, $dx \\wedge dx = 0$. Therefore, the first term is zero. The second term is also zero.\n$$\nd\\alpha = f'(x)\\,(dx \\wedge dx) + 0 = 0\n$$\n\nNext, we perform an analogous computation for $d\\beta = d(g(y)\\, dy)$. We apply the graded Leibniz rule to the product of the $0$-form $g(y)$ and the $1$-form $dy$:\n$$\nd\\beta = d(g(y)) \\wedge dy + (-1)^{0}\\, g(y) \\wedge d(dy) = d(g(y)) \\wedge dy + g(y) \\wedge d(dy)\n$$\nThe exterior derivative of the $0$-form $g(y)$ is:\n$$\nd(g(y)) = \\frac{\\partial g}{\\partial x} dx + \\frac{\\partial g}{\\partial y} dy = 0 + \\frac{dg}{dy} dy = g'(y)\\, dy\n$$\nwhere $g'(y)$ is the ordinary derivative of $g$. We are also given that $d(dy)=0$.\nSubstituting these results:\n$$\nd\\beta = (g'(y)\\, dy) \\wedge dy + g(y) \\wedge 0\n$$\nSince $dy \\wedge dy = 0$, the first term vanishes.\n$$\nd\\beta = g'(y)\\,(dy \\wedge dy) + 0 = 0\n$$\n\nFinally, we substitute our findings for $d\\alpha$ and $d\\beta$ back into the expression for $d\\omega$:\n$$\nd\\omega = d\\alpha \\wedge \\beta - \\alpha \\wedge d\\beta\n$$\n$$\nd\\omega = 0 \\wedge (g(y)\\, dy) - (f(x)\\, dx) \\wedge 0\n$$\nThe wedge product of any differential form with the zero form is the zero form. Thus, both terms are zero.\n$$\nd\\omega = 0 - 0 = 0\n$$\nThe computation explicitly shows, using only the fundamental axioms, that the exterior derivative of the given $2$-form is zero. This result is consistent with the general theorem that for an $n$-dimensional manifold, the exterior derivative of any differential form of top degree $n$ is always zero. Here, $\\omega$ is a $2$-form on the $2$-dimensional manifold $\\mathbb{R}^2$.", "answer": "$$\\boxed{0}$$", "id": "3070342"}, {"introduction": "With the mechanics of the exterior derivative in hand, we now explore one of its most profound implications: the distinction between closed and exact forms. This exercise introduces a famous 1-form $\\omega$ on the punctured plane, $\\mathbb{R}^2 \\setminus \\{(0,0)\\}$. You will first show that this form is closed, meaning $d\\omega = 0$ [@problem_id:3070343]. Then, by computing its line integral around a closed loop, you will discover a non-zero result, which proves that $\\omega$ cannot be exact (i.e., it is not the derivative of any function). This classic example powerfully demonstrates that the existence of a potential function depends not just on local calculations but on the global topology of the underlying space.", "problem": "Let $M=\\mathbb{R}^{2}\\setminus\\{(0,0)\\}$ be the punctured plane equipped with its standard Riemannian metric, and let the $1$-form $\\omega$ on $M$ be given in standard coordinates $(x,y)$ by\n$$\n\\omega=\\frac{-y\\, dx+x\\, dy}{x^{2}+y^{2}}.\n$$\nStarting from the defining properties of the exterior derivative $d$ on differential forms (linearity; agreement with the usual differential on $0$-forms; the graded Leibniz rule for the wedge product; and the nilpotency $d\\circ d=0$), compute $d\\omega$ explicitly in the coordinates $(x,y)$ and simplify your result. Then, consider the positively oriented unit circle $\\gamma:[0,2\\pi]\\to M$ given by $\\gamma(t)=(\\cos t,\\sin t)$, and evaluate the line integral $\\oint_{\\gamma}\\omega$. Use your findings to explain why $\\omega$ is not globally exact on $M$. Report as your final answer the exact value of $\\oint_{\\gamma}\\omega$.", "solution": "The problem is first validated to ensure it is self-contained, scientifically grounded, and well-posed.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n-   Manifold: $M = \\mathbb{R}^{2}\\setminus\\{(0,0)\\}$, the punctured plane with the standard Riemannian metric.\n-   $1$-form: $\\omega = \\frac{-y\\, dx + x\\, dy}{x^{2}+y^{2}}$ on $M$ in coordinates $(x,y)$.\n-   Properties of the exterior derivative $d$: linearity, agreement with the usual differential on $0$-forms, graded Leibniz rule, and nilpotency ($d \\circ d = 0$).\n-   Curve for integration: $\\gamma:[0,2\\pi] \\to M$, a positively oriented unit circle given by $\\gamma(t) = (\\cos t, \\sin t)$.\n-   Tasks:\n    1.  Compute $d\\omega$ and simplify.\n    2.  Evaluate $\\oint_{\\gamma}\\omega$.\n    3.  Explain why $\\omega$ is not globally exact on $M$.\n    4.  Report the value of the integral as the final answer.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is a standard, canonical example in differential geometry and advanced calculus, demonstrating the distinction between closed and exact differential forms and introducing concepts related to de Rham cohomology. All definitions and objects ($M$, $\\omega$, $d$, $\\gamma$) are standard and rigorously defined. The problem is scientifically sound.\n-   **Well-Posedness**: The problem is well-posed. The computations required are unambiguous, and the required explanation follows directly from the results of these computations and fundamental theorems of calculus on manifolds. A unique, meaningful solution exists.\n-   **Objectivity**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective content.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A complete, reasoned solution will be provided.\n\n**Solution**\n\nThe problem asks for three things: the computation of the exterior derivative $d\\omega$, the evaluation of the line integral $\\oint_{\\gamma}\\omega$, and an explanation of why $\\omega$ is not globally exact on $M = \\mathbb{R}^{2}\\setminus\\{(0,0)\\}$.\n\n**1. Computation of $d\\omega$**\n\nThe given $1$-form is $\\omega = P(x,y)dx + Q(x,y)dy$, where\n$$\nP(x,y) = \\frac{-y}{x^{2}+y^{2}} \\quad \\text{and} \\quad Q(x,y) = \\frac{x}{x^{2}+y^{2}}.\n$$\nThe exterior derivative $d$ acts on a $1$-form in $\\mathbb{R}^2$ as follows:\n$$\nd\\omega = d(Pdx + Qdy) = (dP) \\wedge dx + (dQ) \\wedge dy.\n$$\nFor the $0$-forms (functions) $P$ and $Q$, their exterior derivatives are their total differentials:\n$$\ndP = \\frac{\\partial P}{\\partial x} dx + \\frac{\\partial P}{\\partial y} dy\n$$\n$$\ndQ = \\frac{\\partial Q}{\\partial x} dx + \\frac{\\partial Q}{\\partial y} dy\n$$\nSubstituting these into the expression for $d\\omega$ and using the properties of the wedge product ($dx \\wedge dx = 0$, $dy \\wedge dy = 0$, and $dy \\wedge dx = -dx \\wedge dy$), we get:\n$$\nd\\omega = \\left(\\frac{\\partial P}{\\partial x} dx + \\frac{\\partial P}{\\partial y} dy\\right) \\wedge dx + \\left(\\frac{\\partial Q}{\\partial x} dx + \\frac{\\partial Q}{\\partial y} dy\\right) \\wedge dy\n$$\n$$\nd\\omega = \\frac{\\partial P}{\\partial y} dy \\wedge dx + \\frac{\\partial Q}{\\partial x} dx \\wedge dy = \\left(\\frac{\\partial Q}{\\partial x} - \\frac{\\partial P}{\\partial y}\\right) dx \\wedge dy.\n$$\nWe now compute the necessary partial derivatives using the quotient rule.\nFor $P(x,y) = \\frac{-y}{x^{2}+y^{2}}$:\n$$\n\\frac{\\partial P}{\\partial y} = \\frac{(-1)(x^{2}+y^{2}) - (-y)(2y)}{(x^{2}+y^{2})^{2}} = \\frac{-x^{2}-y^{2}+2y^{2}}{(x^{2}+y^{2})^{2}} = \\frac{y^{2}-x^{2}}{(x^{2}+y^{2})^{2}}.\n$$\nFor $Q(x,y) = \\frac{x}{x^{2}+y^{2}}$:\n$$\n\\frac{\\partial Q}{\\partial x} = \\frac{(1)(x^{2}+y^{2}) - (x)(2x)}{(x^{2}+y^{2})^{2}} = \\frac{x^{2}+y^{2}-2x^{2}}{(x^{2}+y^{2})^{2}} = \\frac{y^{2}-x^{2}}{(x^{2}+y^{2})^{2}}.\n$$\nSubstituting these into the expression for $d\\omega$:\n$$\nd\\omega = \\left(\\frac{y^{2}-x^{2}}{(x^{2}+y^{2})^{2}} - \\frac{y^{2}-x^{2}}{(x^{2}+y^{2})^{2}}\\right) dx \\wedge dy = 0 \\cdot dx \\wedge dy = 0.\n$$\nThus, we find that $d\\omega = 0$. A differential form whose exterior derivative is zero is called a **closed** form.\n\n**2. Evaluation of $\\oint_{\\gamma}\\omega$**\n\nThe line integral is evaluated by pulling back the $1$-form $\\omega$ to the parameter space of the curve $\\gamma$, which is the interval $[0, 2\\pi]$. The curve is given by $\\gamma(t) = (x(t), y(t)) = (\\cos t, \\sin t)$ for $t \\in [0, 2\\pi]$.\nThe pullback $\\gamma^*\\omega$ is found by substituting the expressions for $x$, $y$, $dx$, and $dy$ in terms of $t$ and $dt$.\nFirst, we find $dx$ and $dy$:\n$$\nx(t) = \\cos t \\implies dx = \\frac{dx}{dt} dt = -\\sin t \\, dt\n$$\n$$\ny(t) = \\sin t \\implies dy = \\frac{dy}{dt} dt = \\cos t \\, dt\n$$\nWe also have the denominator:\n$$\nx(t)^{2} + y(t)^{2} = \\cos^{2}t + \\sin^{2}t = 1.\n$$\nNow, substitute these into the expression for $\\omega$:\n$$\n\\gamma^*\\omega = \\frac{-y(t)dx + x(t)dy}{x(t)^{2}+y(t)^{2}} = \\frac{-(\\sin t)(-\\sin t \\, dt) + (\\cos t)(\\cos t \\, dt)}{1}\n$$\n$$\n\\gamma^*\\omega = (\\sin^{2}t + \\cos^{2}t)dt = 1 \\cdot dt = dt.\n$$\nThe line integral is then the integral of the pullback form over the domain of the parameter $t$:\n$$\n\\oint_{\\gamma}\\omega = \\int_{0}^{2\\pi} \\gamma^*\\omega = \\int_{0}^{2\\pi} dt = [t]_{0}^{2\\pi} = 2\\pi - 0 = 2\\pi.\n$$\n\n**3. Explanation for Non-Exactness**\n\nA $p$-form $\\omega$ is called **exact** on a manifold $M$ if there exists a $(p-1)$-form $\\alpha$ on $M$ such that $\\omega = d\\alpha$.\nOne of the defining properties of the exterior derivative is its nilpotency, $d \\circ d = 0$. This implies that if a form is exact, it must also be closed. That is, if $\\omega = d\\alpha$, then $d\\omega = d(d\\alpha) = 0$.\n\nIn our case, we found that $d\\omega = 0$, so $\\omega$ is a closed form. The question is whether it is also exact. If $\\omega$ were exact on $M = \\mathbb{R}^{2}\\setminus\\{(0,0)\\}$, then there must exist a $0$-form (a smooth function) $f: M \\to \\mathbb{R}$ such that $\\omega = df$.\n\nAccording to the generalized Stokes' theorem, for any $1$-form $\\alpha$ and any oriented $2$-dimensional surface $S$ with boundary $\\partial S$, we have $\\int_{S} d\\alpha = \\int_{\\partial S} \\alpha$. A specific consequence for line integrals is the fundamental theorem of calculus for line integrals: if a curve $C$ runs from point $A$ to point $B$, then $\\int_{C} df = f(B) - f(A)$.\nIf $\\omega$ were exact, i.e., $\\omega = df$, then the integral of $\\omega$ along any closed loop $\\gamma$ (where the start and end points are the same) would have to be zero:\n$$\n\\oint_{\\gamma}\\omega = \\oint_{\\gamma} df = f(\\gamma(2\\pi)) - f(\\gamma(0)) = 0,\n$$\nsince for the closed loop $\\gamma$, we have $\\gamma(2\\pi) = (\\cos(2\\pi), \\sin(2\\pi)) = (1,0)$ and $\\gamma(0) = (\\cos(0), \\sin(0)) = (1,0)$, so $\\gamma(0) = \\gamma(2\\pi)$.\n\nHowever, we have explicitly calculated that for the unit circle $\\gamma$,\n$$\n\\oint_{\\gamma}\\omega = 2\\pi.\n$$\nSince this result is not zero, it contradicts the necessary condition for $\\omega$ to be exact on $M$. Therefore, $\\omega$ is not globally exact on $M$.\n\nThe reason this is possible is that the manifold $M = \\mathbb{R}^{2}\\setminus\\{(0,0)\\}$ has a \"hole\" at the origin and is not simply connected. Poincar√©'s lemma guarantees that on a contractible (e.g., star-shaped) domain, every closed form is exact. The domain $M$ is not contractible, which allows for the existence of closed forms that are not exact. The form $\\omega$ is the canonical example of this phenomenon.", "answer": "$$\n\\boxed{2\\pi}\n$$", "id": "3070343"}, {"introduction": "This final practice elevates the concepts from the previous exercise to a more general and powerful level by introducing de Rham cohomology. Using the same non-exact 1-form from the previous problem, you will now restrict it to the unit circle $S^1$ and formally prove that a closed 1-form on the circle is exact if and only if its integral is zero [@problem_id:3070365]. This insight allows you to establish a remarkable connection: the integral acts as a map that perfectly characterizes the first cohomology group $H^1(S^1)$, revealing it to be a one-dimensional vector space. This exercise serves as a capstone, illustrating how the machinery of the exterior derivative allows us to compute deep topological invariants of a manifold.", "problem": "Let $S^{1} \\subset \\mathbb{R}^{2}$ be the unit circle with its standard orientation induced by the counterclockwise parameterization $p : \\mathbb{R} \\to S^{1}$ given by $p(t) = (\\cos t, \\sin t)$. Consider the smooth $1$-form on $\\mathbb{R}^{2} \\setminus \\{(0,0)\\}$ defined by\n$$\\alpha = \\frac{-y \\, dx + x \\, dy}{x^{2} + y^{2}},$$\nand let $\\omega = i^{\\ast}\\alpha$ be its pullback to $S^{1}$ by the inclusion $i : S^{1} \\hookrightarrow \\mathbb{R}^{2} \\setminus \\{(0,0)\\}$.\n\nUsing only the core definitions of the exterior derivative $d$, closed and exact forms, and the generalized Stokes' theorem on manifolds with boundary, do the following:\n1. Show that $\\omega$ is a closed $1$-form on $S^{1}$.\n2. Compute $\\int_{S^{1}} \\omega$ using the parameterization $p$ and conclude that $\\omega$ is not exact.\n3. Prove that a smooth $1$-form $\\eta$ on $S^{1}$ is exact if and only if $\\int_{S^{1}} \\eta = 0$. Your proof should construct an explicit potential function when the integral vanishes, using the lift of $\\eta$ to $\\mathbb{R}$ under $p$ and the fundamental theorem of calculus.\n4. Using the integral over $S^{1}$ as a detector for exactness, deduce that the map $I : H^{1}(S^{1}) \\to \\mathbb{R}$ defined by $I([\\eta]) = \\int_{S^{1}} \\eta$ is a vector space isomorphism. Conclude the real dimension of $H^{1}(S^{1})$.\n\nProvide your final answer as the single real number equal to the dimension of $H^{1}(S^{1})$.", "solution": "The problem is subjected to validation and is deemed a valid, well-posed problem in differential geometry. We proceed with the solution, addressing each of the four parts in sequence.\n\nPart 1: Show that $\\omega$ is a closed $1$-form on $S^{1}$.\n\nA differential form is defined as closed if its exterior derivative is zero. We must show that $d\\omega = 0$.\n\nFirst, we can use a general argument based on the dimension of the manifold. The manifold $S^{1}$ is a $1$-dimensional manifold. The form $\\omega$ is a $1$-form on $S^{1}$. The exterior derivative of a $k$-form is a $(k+1)$-form. Therefore, $d\\omega$ is a $2$-form on $S^{1}$. For any point $q \\in S^{1}$, the tangent space $T_q S^{1}$ is a $1$-dimensional vector space. The space of $2$-covectors on $T_q S^{1}$, denoted $\\Lambda^{2}(T_q^*S^1)$, is trivial, i.e., it is the zero vector space. This is because any alternating $2$-tensor on a $1$-dimensional space must be zero. Since $d\\omega$ evaluates to zero at every point, $d\\omega$ is the zero $2$-form. Thus, $\\omega$ is a closed form. This argument applies to any $1$-form on $S^{1}$.\n\nAlternatively, we can show this by first computing the exterior derivative of $\\alpha$ on $\\mathbb{R}^{2} \\setminus \\{(0,0)\\}$ and then using the property that the pullback commutes with the exterior derivative. The form $\\alpha$ is given by\n$$ \\alpha = \\frac{-y}{x^{2} + y^{2}} \\, dx + \\frac{x}{x^{2} + y^{2}} \\, dy $$\nLet $f(x,y) = \\frac{-y}{x^{2} + y^{2}}$ and $g(x,y) = \\frac{x}{x^{2} + y^{2}}$. The exterior derivative of $\\alpha = f \\, dx + g \\, dy$ is $d\\alpha = (\\frac{\\partial g}{\\partial x} - \\frac{\\partial f}{\\partial y}) \\, dx \\wedge dy$. We compute the partial derivatives:\n$$ \\frac{\\partial g}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( \\frac{x}{x^{2} + y^{2}} \\right) = \\frac{(1)(x^{2} + y^{2}) - x(2x)}{(x^{2} + y^{2})^{2}} = \\frac{y^{2} - x^{2}}{(x^{2} + y^{2})^{2}} $$\n$$ \\frac{\\partial f}{\\partial y} = \\frac{\\partial}{\\partial y} \\left( \\frac{-y}{x^{2} + y^{2}} \\right) = \\frac{(-1)(x^{2} + y^{2}) - (-y)(2y)}{(x^{2} + y^{2})^{2}} = \\frac{-x^{2} - y^{2} + 2y^{2}}{(x^{2} + y^{2})^{2}} = \\frac{y^{2} - x^{2}}{(x^{2} + y^{2})^{2}} $$\nSince $\\frac{\\partial g}{\\partial x} = \\frac{\\partial f}{\\partial y}$, we have $d\\alpha = 0$ on its domain $\\mathbb{R}^{2} \\setminus \\{(0,0)\\}$.\nThe form $\\omega$ is the pullback of $\\alpha$ by the inclusion map $i: S^{1} \\to \\mathbb{R}^{2} \\setminus \\{(0,0)\\}$, so $\\omega = i^*\\alpha$. Using the property that $d(i^*\\alpha) = i^*(d\\alpha)$, we have\n$$ d\\omega = d(i^*\\alpha) = i^*(d\\alpha) = i^*(0) = 0 $$\nThus, $\\omega$ is a closed $1$-form on $S^{1}$.\n\nPart 2: Compute $\\int_{S^{1}} \\omega$ and conclude that $\\omega$ is not exact.\n\nTo compute the integral, we use the given parameterization $p: \\mathbb{R} \\to S^{1}$, $p(t) = (\\cos t, \\sin t)$. The integral of $\\omega$ over $S^1$ is given by the integral of its pullback to an interval that covers the circle once, for example $[0, 2\\pi]$.\n$$ \\int_{S^{1}} \\omega = \\int_{0}^{2\\pi} p^*\\omega $$\nSince $\\omega = i^*\\alpha$, we have $p^*\\omega = p^*(i^*\\alpha) = (i \\circ p)^*\\alpha$. The composition $i \\circ p$ is simply the map $p$ viewed as taking values in $\\mathbb{R}^2$. Let $x(t) = \\cos t$ and $y(t) = \\sin t$. The differentials are $dx = -\\sin t \\, dt$ and $dy = \\cos t \\, dt$. The denominator in $\\alpha$ becomes $x(t)^{2} + y(t)^{2} = \\cos^2 t + \\sin^2 t = 1$.\nWe compute the pullback $p^*\\alpha$:\n$$ p^*\\alpha = \\frac{-y(t) \\, (dx/dt \\, dt) + x(t) \\, (dy/dt \\, dt)}{x(t)^{2} + y(t)^{2}} = \\frac{-(\\sin t)(-\\sin t \\, dt) + (\\cos t)(\\cos t \\, dt)}{1} $$\n$$ p^*\\alpha = (\\sin^{2} t + \\cos^{2} t) \\, dt = 1 \\, dt = dt $$\nNow we can compute the integral:\n$$ \\int_{S^{1}} \\omega = \\int_{0}^{2\\pi} p^*\\alpha = \\int_{0}^{2\\pi} dt = [t]_{0}^{2\\pi} = 2\\pi - 0 = 2\\pi $$\nTo show that $\\omega$ is not exact, we assume for contradiction that it is. If $\\omega$ were exact, there would exist a smooth function (a $0$-form) $f: S^{1} \\to \\mathbb{R}$ such that $\\omega = df$.\nThe generalized Stokes' theorem states that for any smooth $(n-1)$-form $\\eta$ on an oriented $n$-manifold $M$ with boundary $\\partial M$, we have $\\int_{M} d\\eta = \\int_{\\partial M} \\eta$.\nIn our case, $M=S^{1}$ is a $1$-dimensional manifold. It is compact and has no boundary, i.e., $\\partial S^{1} = \\emptyset$. If $\\omega = df$, then applying Stokes' theorem:\n$$ \\int_{S^{1}} \\omega = \\int_{S^{1}} df = \\int_{\\partial S^{1}} f = 0 $$\nwhere the integral over an empty set is defined to be $0$.\nHowever, we computed $\\int_{S^{1}} \\omega = 2\\pi$. Since $2\\pi \\neq 0$, we have a contradiction. Therefore, $\\omega$ cannot be an exact form.\n\nPart 3: Prove that a smooth $1$-form $\\eta$ on $S^{1}$ is exact if and only if $\\int_{S^{1}} \\eta = 0$.\n\nThis is a biconditional statement.\n\n($\\Rightarrow$) Assume $\\eta$ is an exact $1$-form on $S^{1}$. By definition, there exists a smooth function $f: S^{1} \\to \\mathbb{R}$ such that $\\eta = df$. As shown in Part 2, using Stokes' theorem on the boundaryless manifold $S^{1}$, we have $\\int_{S^{1}} \\eta = \\int_{S^{1}} df = 0$.\n\n($\\Leftarrow$) Assume $\\eta$ is a smooth $1$-form on $S^{1}$ such that $\\int_{S^{1}} \\eta = 0$. We need to construct a smooth function $f: S^{1} \\to \\mathbb{R}$ such that $\\eta = df$.\nLet $p: \\mathbb{R} \\to S^{1}$ be the parameterization $p(t) = (\\cos t, \\sin t)$. Consider the pullback of $\\eta$ to $\\mathbb{R}$, denoted $\\tilde{\\eta} = p^*\\eta$. $\\tilde{\\eta}$ is a smooth $1$-form on $\\mathbb{R}$, so it can be written as $\\tilde{\\eta} = g(t) \\, dt$ for some smooth function $g: \\mathbb{R} \\to \\mathbb{R}$.\nSince $\\eta$ is a form on $S^1$, the pullback $\\tilde{\\eta}$ must be periodic with period $2\\pi$. The map $p$ identifies $t$ with $t+2\\pi$. Thus, for any $t \\in \\mathbb{R}$, the value of the pullback at $t$ must equal its value at $t+2\\pi$. The form $\\tilde{\\eta}$ at a point $t$ is the map $v \\in T_t\\mathbb{R} \\mapsto \\eta_{p(t)}(p_*(v))$. Since $p(t) = p(t+2\\pi)$ and $p'(t) = p'(t+2\\pi)$, it follows that $g(t) = g(t+2\\pi)$ for all $t \\in \\mathbb{R}$.\nDefine a function $F: \\mathbb{R} \\to \\mathbb{R}$ by the integral:\n$$ F(t) = \\int_{0}^{t} g(s) \\, ds $$\nBy the Fundamental Theorem of Calculus, $F'(t) = g(t)$, so $dF = F'(t) \\, dt = g(t) \\, dt = \\tilde{\\eta}$.\nFor $F$ to descend to a well-defined function on $S^1$, it must be $2\\pi$-periodic. Let's check this condition:\n$$ F(t+2\\pi) = \\int_{0}^{t+2\\pi} g(s) \\, ds = \\int_{0}^{t} g(s) \\, ds + \\int_{t}^{t+2\\pi} g(s) \\, ds = F(t) + \\int_{t}^{t+2\\pi} g(s) \\, ds $$\nSince $g$ is $2\\pi$-periodic, the integral $\\int_{t}^{t+2\\pi} g(s) \\, ds$ is constant for all $t$. Evaluating at $t=0$, this constant is $\\int_{0}^{2\\pi} g(s) \\, ds$.\nThis integral is precisely the integral of $\\eta$ over $S^1$:\n$$ \\int_{0}^{2\\pi} g(s) \\, ds = \\int_{0}^{2\\pi} p^*\\eta = \\int_{S^{1}} \\eta $$\nBy our initial assumption, $\\int_{S^{1}} \\eta = 0$.\nTherefore, $F(t+2\\pi) - F(t) = 0$, which means $F(t+2\\pi) = F(t)$. The function $F$ is $2\\pi$-periodic.\nThis periodicity allows us to define a function $f: S^{1} \\to \\mathbb{R}$ by setting $f(q) = F(t)$ for any $t \\in \\mathbb{R}$ such that $p(t) = q$. Since $F$ is periodic, this value is independent of the choice of $t$ (which are all of the form $t_0 + 2k\\pi$). Since $F$ is smooth, and $p$ is a local diffeomorphism, the resulting function $f$ is smooth on $S^1$.\nFinally, we must verify that $df = \\eta$. On $\\mathbb{R}$, we have $dF = \\tilde{\\eta} = p^*\\eta$. Also, by definition of $f$, we have $F = f \\circ p$, so $dF = d(f \\circ p) = p^*(df)$.\nThus, $p^*(df) = p^*\\eta$. Since $p$ is a surjective local diffeomorphism, this implies that $df = \\eta$. This completes the proof.\n\nPart 4: Show $I: H^{1}(S^{1}) \\to \\mathbb{R}$ is a vector space isomorphism and find $\\dim_{\\mathbb{R}}(H^{1}(S^{1}))$.\n\nThe first de Rham cohomology group is defined as the quotient space $H^{1}(S^{1}) = Z^{1}(S^{1}) / B^{1}(S^{1})$, where $Z^{1}(S^{1})$ is the vector space of closed $1$-forms on $S^{1}$ and $B^{1}(S^{1})$ is the subspace of exact $1$-forms. As shown in Part 1, all $1$-forms on $S^1$ are closed, so $Z^{1}(S^{1})$ is the space of all smooth $1$-forms on $S^{1}$.\nThe map is given by $I([\\eta]) = \\int_{S^{1}} \\eta$, where $[\\eta]$ is the cohomology class of a closed $1$-form $\\eta$.\n\n1.  **Well-defined:** Let $[\\eta_1] = [\\eta_2]$. This means $\\eta_1 - \\eta_2$ is an exact form. So, $\\eta_1 - \\eta_2 = df$ for some function $f$ on $S^{1}$. Then $\\int_{S^{1}} (\\eta_1 - \\eta_2) = \\int_{S^{1}} df = 0$ by Stokes' theorem. It follows that $\\int_{S^{1}} \\eta_1 = \\int_{S^{1}} \\eta_2$, so $I([\\eta_1]) = I([\\eta_2])$. The map $I$ is well-defined.\n\n2.  **Linearity:** For any $c_1, c_2 \\in \\mathbb{R}$ and $[\\eta_1], [\\eta_2] \\in H^1(S^1)$,\n    $$ I(c_1[\\eta_1] + c_2[\\eta_2]) = I([c_1\\eta_1 + c_2\\eta_2]) = \\int_{S^1} (c_1\\eta_1+c_2\\eta_2) = c_1\\int_{S^1}\\eta_1 + c_2\\int_{S^1}\\eta_2 = c_1 I([\\eta_1]) + c_2 I([\\eta_2]) $$\n    by linearity of the integral. Thus, $I$ is a linear map of vector spaces.\n\n3.  **Injectivity:** We determine the kernel of $I$.\n    $$ \\ker(I) = \\{[\\eta] \\in H^{1}(S^{1}) \\mid I([\\eta]) = 0 \\} = \\{[\\eta] \\in H^{1}(S^{1}) \\mid \\int_{S^{1}} \\eta = 0 \\} $$\n    From Part 3, we know that a $1$-form $\\eta$ on $S^{1}$ has $\\int_{S^{1}} \\eta = 0$ if and only if $\\eta$ is exact.\n    So, $\\int_{S^{1}} \\eta = 0$ is equivalent to $\\eta \\in B^{1}(S^{1})$. The class $[\\eta]$ is the zero element in the quotient space $H^{1}(S^{1})$ if and only if $\\eta$ is exact.\n    Therefore, $\\ker(I) = \\{[0]\\}$, the trivial subspace. This proves that $I$ is injective.\n\n4.  **Surjectivity:** We need to show that for any $c \\in \\mathbb{R}$, there exists a class $[\\eta] \\in H^{1}(S^{1})$ such that $I([\\eta]) = c$.\n    From Part 2, we have the closed $1$-form $\\omega$ for which $\\int_{S^{1}} \\omega = 2\\pi$. Consider the form $\\eta = \\frac{c}{2\\pi} \\omega$.\n    Since $\\omega$ is closed and $\\frac{c}{2\\pi}$ is a constant, $d\\eta = \\frac{c}{2\\pi} d\\omega = 0$, so $\\eta$ is also closed. Its class $[\\eta]$ is in $H^{1}(S^{1})$.\n    Now, we compute its integral:\n    $$ I([\\eta]) = \\int_{S^{1}} \\eta = \\int_{S^{1}} \\frac{c}{2\\pi} \\omega = \\frac{c}{2\\pi} \\int_{S^{1}} \\omega = \\frac{c}{2\\pi} (2\\pi) = c $$\n    This shows that for any $c \\in \\mathbb{R}$, we can find a cohomology class that maps to it. Thus, $I$ is surjective.\n\nSince $I: H^{1}(S^{1}) \\to \\mathbb{R}$ is a linear, injective, and surjective map, it is a vector space isomorphism.\nIsomorphic vector spaces have the same dimension. The dimension of the vector space $\\mathbb{R}$ over the field $\\mathbb{R}$ is $1$.\nTherefore, we conclude that the real dimension of the first de Rham cohomology group of the circle is $1$.\n$$ \\dim_{\\mathbb{R}}(H^{1}(S^{1})) = \\dim_{\\mathbb{R}}(\\mathbb{R}) = 1 $$\n\nThe final answer is the dimension of $H^{1}(S^{1})$.", "answer": "$$\\boxed{1}$$", "id": "3070365"}]}