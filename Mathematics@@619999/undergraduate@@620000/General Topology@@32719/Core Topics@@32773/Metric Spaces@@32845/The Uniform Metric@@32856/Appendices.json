{"hands_on_practices": [{"introduction": "To begin, let's ground our understanding of the uniform metric with a direct calculation. This first practice [@problem_id:1552592] requires you to compute the distance between two simple polynomial functions, transforming the abstract definition of the supremum metric into a familiar calculus problem: finding the maximum value of a function on a closed interval. This exercise builds a crucial bridge between the topological concept of distance and the practical tools of analysis.", "problem": "In the study of abstract mathematical spaces, the set of all real-valued continuous functions on a closed interval $[a, b]$, denoted as $C[a, b]$, forms a metric space when equipped with a suitable distance function. One of the most important metrics on this space is the supremum metric (or uniform metric), defined as\n$$d_{\\infty}(f, g) = \\sup_{x \\in [a, b]} |f(x) - g(x)|$$\nfor any two functions $f$ and $g$ in $C[a, b]$.\n\nConsider the specific metric space $C[0, 1]$ with the supremum metric. Let two functions in this space be defined by $f(x) = x^2$ and $g(x) = x^3$.\n\nCalculate the distance $d_{\\infty}(f, g)$ between these two functions. Present your answer as an exact fraction.", "solution": "We are given $f(x) = x^{2}$ and $g(x) = x^{3}$ on $[0,1]$ with the supremum metric\n$$\nd_{\\infty}(f,g) = \\sup_{x \\in [0,1]} |f(x) - g(x)|.\n$$\nCompute the pointwise difference:\n$$\n|f(x) - g(x)| = |x^{2} - x^{3}| = x^{2}(1 - x),\n$$\nsince for $x \\in [0,1]$ we have $x^{2} \\ge 0$ and $1 - x \\ge 0$, so the absolute value is unnecessary.\n\nDefine $h(x) = x^{2}(1 - x)$ on $[0,1]$ and maximize it. Differentiate:\n$$\nh'(x) = 2x(1 - x) - x^{2} = 2x - 3x^{2} = x(2 - 3x).\n$$\nCritical points occur when $h'(x) = 0$, giving $x = 0$ or $x = \\frac{2}{3}$. Evaluate $h$ at the critical points and endpoints:\n$$\nh(0) = 0, \\quad h(1) = 0, \\quad h\\!\\left(\\frac{2}{3}\\right) = \\left(\\frac{2}{3}\\right)^{2}\\!\\left(1 - \\frac{2}{3}\\right) = \\frac{4}{9} \\cdot \\frac{1}{3} = \\frac{4}{27}.\n$$\nTherefore,\n$$\nd_{\\infty}(f,g) = \\sup_{x \\in [0,1]} x^{2}(1 - x) = \\frac{4}{27}.\n$$", "answer": "$$\\boxed{\\frac{4}{27}}$$", "id": "1552592"}, {"introduction": "Having practiced a basic distance calculation, we now explore how the uniform metric defines the topological structure of the function space. This exercise [@problem_id:1591328] asks whether a set of functions defined by an analytical property—having a zero net integral—is a closed set. To solve this, you will apply the sequential definition of a closed set, which powerfully illustrates a key consequence of uniform convergence: the ability to interchange the limit and integral operations.", "problem": "In functional analysis, the space of all real-valued continuous functions on the interval $[0, 1]$ is denoted by $C[0,1]$. This space can be equipped with various metrics. One of the most important is the uniform metric, $d_{\\infty}$, defined for any two functions $f, g \\in C[0,1]$ as:\n$$\nd_{\\infty}(f, g) = \\sup_{x \\in [0,1]} |f(x) - g(x)|\n$$\nConvergence in this metric is known as uniform convergence.\n\nConsider a subset $S$ of $C[0,1]$ defined as the set of all continuous functions on $[0,1]$ whose definite integral over the interval is zero. In signal processing, this would correspond to signals with no Direct Current (DC) offset. The set is formally defined as:\n$$\nS = \\left\\{ f \\in C[0,1] \\;\\middle|\\; \\int_{0}^{1} f(x) \\, dx = 0 \\right\\}\n$$\nWithin the metric space $(C[0,1], d_{\\infty})$, is the set $S$ a closed set?\n\nA. The set is closed.\n\nB. The set is open but not closed.\n\nC. The set is neither open nor closed.\n\nD. The set is both open and closed.\n\nE. The topological property of the set (being closed or not) depends on the specific choice of functions.", "solution": "To determine if the set $S$ is closed in the metric space $(C[0,1], d_{\\infty})$, we will use the sequence-based definition of a closed set. A set is closed if and only if it contains all of its limit points. This is equivalent to showing that for any sequence of elements in the set that converges to a limit in the larger space, the limit itself must also be an element of the set.\n\nLet's formalize this. We need to show that if $(f_n)_{n=1}^{\\infty}$ is a sequence of functions such that:\n1.  $f_n \\in S$ for all $n \\in \\mathbb{N}$.\n2.  The sequence $(f_n)$ converges to a function $f \\in C[0,1]$ with respect to the uniform metric $d_{\\infty}$.\n\n... then the limit function $f$ must also be in $S$.\n\nFrom condition (1), since each $f_n$ is in $S$, we know by definition of $S$ that for every $n \\in \\mathbb{N}$:\n$$\n\\int_{0}^{1} f_n(x) \\, dx = 0\n$$\n\nFrom condition (2), the sequence $(f_n)$ converges uniformly to $f$. This means:\n$$\n\\lim_{n \\to \\infty} d_{\\infty}(f_n, f) = \\lim_{n \\to \\infty} \\left( \\sup_{x \\in [0,1]} |f_n(x) - f(x)| \\right) = 0\n$$\nThe problem states that the limit function $f$ is in $C[0,1]$. This is guaranteed because $(C[0,1], d_{\\infty})$ is a complete metric space, meaning every Cauchy sequence (and thus every convergent sequence) of continuous functions converges to a continuous function.\n\nNow we must check if the limit function $f$ satisfies the condition to be in $S$, which is $\\int_{0}^{1} f(x) \\, dx = 0$.\n\nA fundamental theorem in real analysis states that if a sequence of Riemann-integrable functions $(f_n)$ on a closed interval $[a, b]$ converges uniformly to a function $f$, then the limit of the integrals is equal to the integral of the limit. That is:\n$$\n\\lim_{n \\to \\infty} \\int_{a}^{b} f_n(x) \\, dx = \\int_{a}^{b} \\left( \\lim_{n \\to \\infty} f_n(x) \\right) \\, dx = \\int_{a}^{b} f(x) \\, dx\n$$\nSince all functions in $C[0,1]$ are continuous and therefore Riemann-integrable on $[0,1]$, we can apply this theorem to our sequence $(f_n)$.\n\nWe have:\n$$\n\\int_{0}^{1} f(x) \\, dx = \\int_{0}^{1} \\lim_{n \\to \\infty} f_n(x) \\, dx\n$$\nUsing the theorem, we can swap the limit and the integral:\n$$\n\\int_{0}^{1} f(x) \\, dx = \\lim_{n \\to \\infty} \\int_{0}^{1} f_n(x) \\, dx\n$$\nSince each $f_n \\in S$, we know that $\\int_{0}^{1} f_n(x) \\, dx = 0$ for all $n$. Substituting this into our equation:\n$$\n\\int_{0}^{1} f(x) \\, dx = \\lim_{n \\to \\infty} (0) = 0\n$$\nThis result shows that the limit function $f$ satisfies the condition $\\int_{0}^{1} f(x) \\, dx = 0$. Therefore, the limit function $f$ is an element of the set $S$.\n\nSince we have shown that for any convergent sequence of functions in $S$, the limit function is also in $S$, we conclude that $S$ is a closed set in $(C[0,1], d_{\\infty})$. This corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1591328"}, {"introduction": "Our final practice addresses one of the most fundamental structural properties of a metric space: completeness. Using the familiar space of polynomials as a case study, this problem [@problem_id:1591319] challenges you to determine if this subspace is complete by examining a specific sequence of polynomials. This classic example reveals that a sequence of simpler functions (polynomials) can converge to a limit outside the original set, thereby highlighting the importance of working within the complete space of all continuous functions, $C[0,1]$.", "problem": "Let $C[0,1]$ represent the set of all continuous real-valued functions defined on the closed interval $[0,1]$. This set forms a metric space when equipped with the uniform metric, $d_{\\infty}$, defined as:\n$$d_{\\infty}(f, g) = \\sup_{x \\in [0,1]} |f(x) - g(x)|$$\nfor any two functions $f, g \\in C[0,1]$.\n\nLet $\\mathcal{P}$ be the subset of $C[0,1]$ consisting of all polynomial functions. We consider $\\mathcal{P}$ as a subspace of $(C[0,1], d_{\\infty})$ with the inherited metric.\n\nNow, consider the sequence of functions $(p_n)_{n \\geq 0}$ where each $p_n$ is a polynomial in $\\mathcal{P}$ defined by:\n$$p_n(x) = \\sum_{k=0}^{n} \\frac{x^k}{k!}$$\nA metric space (or a subspace) is called 'complete' if every Cauchy sequence of points in the space converges to a limit that is also in the space.\n\nBased on this information, which of the following statements is correct?\n\nA. The sequence $(p_n)$ is not a Cauchy sequence with respect to the metric $d_{\\infty}$.\n\nB. The sequence $(p_n)$ is a Cauchy sequence in $(\\mathcal{P}, d_{\\infty})$, and the subspace $\\mathcal{P}$ is complete.\n\nC. The sequence $(p_n)$ is a Cauchy sequence in $(\\mathcal{P}, d_{\\infty})$, but its limit function in the larger space $(C[0,1], d_{\\infty})$ is not a member of $\\mathcal{P}$.\n\nD. The sequence $(p_n)$ converges to a limit function within the subspace $\\mathcal{P}$.\n\nE. The sequence $(p_n)$ does not converge to any function in the larger space $(C[0,1], d_{\\infty})$.", "solution": "We analyze the sequence of polynomials $p_{n}(x) = \\sum_{k=0}^{n} \\frac{x^{k}}{k!}$ on $[0,1]$ with the uniform metric $d_{\\infty}(f,g) = \\sup_{x \\in [0,1]} |f(x)-g(x)|$.\n\nFirst, we show that $(p_{n})$ is Cauchy in $(\\mathcal{P}, d_{\\infty})$. For $m>n$,\n$$\nd_{\\infty}(p_{m},p_{n}) = \\sup_{x \\in [0,1]} \\left|\\sum_{k=n+1}^{m} \\frac{x^{k}}{k!}\\right|\n\\le \\sum_{k=n+1}^{m} \\sup_{x \\in [0,1]} \\frac{|x|^{k}}{k!}\n\\le \\sum_{k=n+1}^{m} \\frac{1}{k!}.\n$$\nSince $\\sum_{k=0}^{\\infty} \\frac{1}{k!}$ converges (for example by the ratio test, or by identifying it with $\\exp(1)$), its tails satisfy\n$$\n\\lim_{n \\to \\infty} \\sum_{k=n+1}^{\\infty} \\frac{1}{k!} = 0.\n$$\nHence, given any $\\varepsilon>0$, there exists $N$ such that for all $m>n \\geq N$,\n$$\nd_{\\infty}(p_{m},p_{n}) \\le \\sum_{k=n+1}^{m} \\frac{1}{k!} \\le \\sum_{k=n+1}^{\\infty} \\frac{1}{k!} < \\varepsilon,\n$$\nso $(p_{n})$ is Cauchy in $(\\mathcal{P}, d_{\\infty})$.\n\nNext, we identify its limit in $(C[0,1], d_{\\infty})$. Consider the series $\\sum_{k=0}^{\\infty} \\frac{x^{k}}{k!}$. For $x \\in [0,1]$ and each $k \\geq 0$,\n$$\n\\left|\\frac{x^{k}}{k!}\\right| \\le \\frac{1}{k!}.\n$$\nSince $\\sum_{k=0}^{\\infty} \\frac{1}{k!}$ converges, by the Weierstrass M-test the series $\\sum_{k=0}^{\\infty} \\frac{x^{k}}{k!}$ converges uniformly on $[0,1]$ to a continuous function\n$$\nf(x) = \\sum_{k=0}^{\\infty} \\frac{x^{k}}{k!}.\n$$\nTherefore $d_{\\infty}(p_{n},f) \\to 0$ as $n \\to \\infty$, so $p_{n} \\to f$ in $(C[0,1], d_{\\infty})$. By the power-series definition, $f(x) = \\exp(x)$ for all $x \\in [0,1]$.\n\nFinally, we show that $f$ is not a polynomial. Suppose $f$ equals a polynomial $q$ of degree $d$. Then $q^{(d+1)} \\equiv 0$, but $f^{(d+1)}(x) = \\exp(x)$ for all $x$, which is never zero. This is a contradiction. Hence $f \\notin \\mathcal{P}$.\n\nTherefore, $(p_{n})$ is a Cauchy sequence in $(\\mathcal{P}, d_{\\infty})$ whose limit in $(C[0,1], d_{\\infty})$ is not in $\\mathcal{P}$. The correct statement is option C.", "answer": "$$\\boxed{C}$$", "id": "1591319"}]}