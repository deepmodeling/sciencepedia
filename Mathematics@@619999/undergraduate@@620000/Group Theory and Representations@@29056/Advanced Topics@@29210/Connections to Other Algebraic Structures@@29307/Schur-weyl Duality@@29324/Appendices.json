{"hands_on_practices": [{"introduction": "Schur-Weyl duality describes a profound relationship between two different group actions on a tensor product space. One of these is the action of the symmetric group, $S_k$, which permutes the tensor factors. This first exercise provides a concrete opportunity to compute the matrix representation for such a permutation action, transforming an abstract algebraic definition into a tangible linear operator. [@problem_id:1639998]", "problem": "Let $V = \\mathbb{C}^2$ be a two-dimensional complex vector space with the standard ordered basis $\\{e_1, e_2\\}$, where $e_1 = (1, 0)^T$ and $e_2 = (0, 1)^T$. Consider the three-fold tensor product space $W = V^{\\otimes 3} = V \\otimes V \\otimes V$. The dimension of $W$ is $2^3 = 8$.\n\nWe define an ordered basis $B$ for $W$ using lexicographical ordering of the indices. Specifically, the basis vector $e_{i_1} \\otimes e_{i_2} \\otimes e_{i_3}$ is placed at position $1 + 4(i_1-1) + 2(i_2-1) + (i_3-1)$ in the basis list. This corresponds to the sequence:\n$B = \\{e_1 \\otimes e_1 \\otimes e_1, e_1 \\otimes e_1 \\otimes e_2, e_1 \\otimes e_2 \\otimes e_1, e_1 \\otimes e_2 \\otimes e_2, e_2 \\otimes e_1 \\otimes e_1, e_2 \\otimes e_1 \\otimes e_2, e_2 \\otimes e_2 \\otimes e_1, e_2 \\otimes e_2 \\otimes e_2\\}$.\n\nThe symmetric group on three elements, $S_3$, acts on the space $W$ by permuting the tensor factors. For a simple tensor $w = v_1 \\otimes v_2 \\otimes v_3 \\in W$ and a permutation $\\sigma \\in S_3$, this left action is defined as:\n$$ \\sigma \\cdot (v_1 \\otimes v_2 \\otimes v_3) = v_{\\sigma^{-1}(1)} \\otimes v_{\\sigma^{-1}(2)} \\otimes v_{\\sigma^{-1}(3)} $$\nThis definition extends linearly to all vectors in $W$.\n\nYour task is to determine the matrix representation of the cyclic permutation $\\sigma = (123) \\in S_3$ with respect to the ordered basis $B$.", "solution": "We consider the linear operator $T_{\\sigma}$ on $W=V^{\\otimes 3}$ induced by the permutation $\\sigma=(123)\\in S_{3}$ with the left action defined by\n$$\n\\sigma\\cdot(v_{1}\\otimes v_{2}\\otimes v_{3})=v_{\\sigma^{-1}(1)}\\otimes v_{\\sigma^{-1}(2)}\\otimes v_{\\sigma^{-1}(3)}.\n$$\nSince $\\sigma=(123)$ has inverse $\\sigma^{-1}=(132)$, we obtain for a simple tensor\n$$\nT_{\\sigma}(v_{1}\\otimes v_{2}\\otimes v_{3})=v_{3}\\otimes v_{1}\\otimes v_{2}.\n$$\nWith respect to the ordered basis $B=\\{e_{1}\\otimes e_{1}\\otimes e_{1},e_{1}\\otimes e_{1}\\otimes e_{2},e_{1}\\otimes e_{2}\\otimes e_{1},e_{1}\\otimes e_{2}\\otimes e_{2},e_{2}\\otimes e_{1}\\otimes e_{1},e_{2}\\otimes e_{1}\\otimes e_{2},e_{2}\\otimes e_{2}\\otimes e_{1},e_{2}\\otimes e_{2}\\otimes e_{2}\\}$, we compute the images:\n$$\n\\begin{aligned}\nT_{\\sigma}(e_{1}\\otimes e_{1}\\otimes e_{1})&=e_{1}\\otimes e_{1}\\otimes e_{1}\\quad\\Rightarrow\\quad 1\\mapsto 1,\\\\\nT_{\\sigma}(e_{1}\\otimes e_{1}\\otimes e_{2})&=e_{2}\\otimes e_{1}\\otimes e_{1}\\quad\\Rightarrow\\quad 2\\mapsto 5,\\\\\nT_{\\sigma}(e_{1}\\otimes e_{2}\\otimes e_{1})&=e_{1}\\otimes e_{1}\\otimes e_{2}\\quad\\Rightarrow\\quad 3\\mapsto 2,\\\\\nT_{\\sigma}(e_{1}\\otimes e_{2}\\otimes e_{2})&=e_{2}\\otimes e_{1}\\otimes e_{2}\\quad\\Rightarrow\\quad 4\\mapsto 6,\\\\\nT_{\\sigma}(e_{2}\\otimes e_{1}\\otimes e_{1})&=e_{1}\\otimes e_{2}\\otimes e_{1}\\quad\\Rightarrow\\quad 5\\mapsto 3,\\\\\nT_{\\sigma}(e_{2}\\otimes e_{1}\\otimes e_{2})&=e_{2}\\otimes e_{2}\\otimes e_{1}\\quad\\Rightarrow\\quad 6\\mapsto 7,\\\\\nT_{\\sigma}(e_{2}\\otimes e_{2}\\otimes e_{1})&=e_{1}\\otimes e_{2}\\otimes e_{2}\\quad\\Rightarrow\\quad 7\\mapsto 4,\\\\\nT_{\\sigma}(e_{2}\\otimes e_{2}\\otimes e_{2})&=e_{2}\\otimes e_{2}\\otimes e_{2}\\quad\\Rightarrow\\quad 8\\mapsto 8.\n\\end{aligned}\n$$\nThus the matrix $[T_{\\sigma}]_{B}$ has a $1$ in row $r$, column $c$ when $T_{\\sigma}(b_{c})=b_{r}$ and zeros elsewhere. Therefore,\n$$\n[T_{\\sigma}]_{B}=\n\\begin{pmatrix}\n1&0&0&0&0&0&0&0\\\\\n0&0&1&0&0&0&0&0\\\\\n0&0&0&0&1&0&0&0\\\\\n0&0&0&0&0&0&1&0\\\\\n0&1&0&0&0&0&0&0\\\\\n0&0&0&1&0&0&0&0\\\\\n0&0&0&0&0&1&0&0\\\\\n0&0&0&0&0&0&0&1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\n1&0&0&0&0&0&0&0\\\\\n0&0&1&0&0&0&0&0\\\\\n0&0&0&0&1&0&0&0\\\\\n0&0&0&0&0&0&1&0\\\\\n0&1&0&0&0&0&0&0\\\\\n0&0&0&1&0&0&0&0\\\\\n0&0&0&0&0&1&0&0\\\\\n0&0&0&0&0&0&0&1\n\\end{pmatrix}}$$", "id": "1639998"}, {"introduction": "Once we understand how permutations act on tensor spaces, a natural next step is to find vectors that behave simply under this action. This practice focuses on identifying the symmetric subspace of $(\\mathbb{C}^3)^{\\otimes 2}$â€”the set of all tensors left unchanged by the permutation of its factors. Constructing a basis for this invariant subspace is a key step towards the decomposition of the tensor space predicted by Schur-Weyl duality. [@problem_id:1640035]", "problem": "Let $V = \\mathbb{C}^3$ be a 3-dimensional complex vector space with the standard basis $\\{e_1, e_2, e_3\\}$. Consider the tensor product space $W = V \\otimes V = (\\mathbb{C}^3)^{\\otimes 2}$. The dimension of this space is 9, and its standard basis is given by $\\{e_i \\otimes e_j \\mid i, j \\in \\{1, 2, 3\\}\\}$.\n\nThe permutation group $S_2$ consists of two elements: the identity permutation, $id$, and the transposition, $\\tau = (1 \\leftrightarrow 2)$. This group acts on the space $W$. The action of $\\sigma \\in S_2$ on a pure tensor $v_1 \\otimes v_2 \\in W$ is defined as:\n$$ \\sigma \\cdot (v_1 \\otimes v_2) = v_{\\sigma^{-1}(1)} \\otimes v_{\\sigma^{-1}(2)} $$\nThis action is extended linearly to all of $W$. For the non-identity element $\\tau$, this means $\\tau \\cdot (v_1 \\otimes v_2) = v_2 \\otimes v_1$.\n\nA vector $x \\in W$ is said to be *fixed by the group action* if $\\sigma \\cdot x = x$ for all $\\sigma \\in S_2$. This is equivalent to requiring that $\\tau \\cdot x = x$. The set of all such fixed vectors forms a subspace of $W$.\n\nWhich of the following sets constitutes a basis for the subspace of vectors in $W$ that are fixed by the action of $S_2$?\n\nA. $\\{e_1 \\otimes e_1, e_2 \\otimes e_2, e_3 \\otimes e_3, e_1 \\otimes e_2 + e_2 \\otimes e_1, e_1 \\otimes e_3 + e_3 \\otimes e_1, e_2 \\otimes e_3 + e_3 \\otimes e_2\\}$\n\nB. $\\{e_1 \\otimes e_2 - e_2 \\otimes e_1, e_1 \\otimes e_3 - e_3 \\otimes e_1, e_2 \\otimes e_3 - e_3 \\otimes e_2\\}$\n\nC. $\\{e_1 \\otimes e_1, e_1 \\otimes e_2, e_1 \\otimes e_3, e_2 \\otimes e_1, e_2 \\otimes e_2, e_2 \\otimes e_3, e_3 \\otimes e_1, e_3 \\otimes e_2, e_3 \\otimes e_3\\}$\n\nD. $\\{e_1 \\otimes e_1, e_2 \\otimes e_2, e_3 \\otimes e_3, e_1 \\otimes e_2, e_2 \\otimes e_1, e_1 \\otimes e_3\\}$\n\nE. $\\{e_1 \\otimes e_1, e_2 \\otimes e_2, e_3 \\otimes e_3, e_1 \\otimes e_2 + e_2 \\otimes e_1, e_1 \\otimes e_3 + e_3 \\otimes e_1, e_2 \\otimes e_3 + e_3 \\otimes e_2, e_1 \\otimes e_1 + e_1 \\otimes e_2 + e_2 \\otimes e_1\\}$", "solution": "We are tasked with finding a basis for the subspace of $W = (\\mathbb{C}^3)^{\\otimes 2}$ containing all vectors $x$ such that $\\tau \\cdot x = x$, where $\\tau$ is the non-identity element of the permutation group $S_2$.\n\nA general vector $x \\in W$ can be written as a linear combination of the basis vectors $\\{e_i \\otimes e_j\\}$:\n$$ x = \\sum_{i=1}^{3} \\sum_{j=1}^{3} c_{ij} e_i \\otimes e_j $$\nwhere $c_{ij}$ are complex coefficients.\n\nThe action of $\\tau$ on $x$ is given by applying $\\tau$ to each term in the sum. The action on a basis vector is $\\tau \\cdot (e_i \\otimes e_j) = e_j \\otimes e_i$.\n$$ \\tau \\cdot x = \\tau \\cdot \\left( \\sum_{i,j=1}^{3} c_{ij} e_i \\otimes e_j \\right) = \\sum_{i,j=1}^{3} c_{ij} (\\tau \\cdot (e_i \\otimes e_j)) = \\sum_{i,j=1}^{3} c_{ij} e_j \\otimes e_i $$\nThe condition for a vector to be in the fixed subspace is $\\tau \\cdot x = x$. So we set the expression for $\\tau \\cdot x$ equal to the expression for $x$:\n$$ \\sum_{i,j=1}^{3} c_{ij} e_j \\otimes e_i = \\sum_{i,j=1}^{3} c_{ij} e_i \\otimes e_j $$\nTo compare the coefficients, we can relabel the summation indices on the left-hand side. Let's swap the dummy indices $i$ and $j$:\n$$ \\sum_{j,i=1}^{3} c_{ji} e_i \\otimes e_j = \\sum_{i,j=1}^{3} c_{ij} e_i \\otimes e_j $$\nSince the vectors $\\{e_i \\otimes e_j\\}$ form a basis for $W$, they are linearly independent. Therefore, for the equality to hold, the coefficients of each basis vector must be equal:\n$$ c_{ji} = c_{ij} \\quad \\text{for all } i, j \\in \\{1, 2, 3\\} $$\nThis condition means that the $3 \\times 3$ matrix of coefficients $C = (c_{ij})$ must be a symmetric matrix.\n\nOur goal is to find a basis for the space of vectors $x$ whose coefficient matrices are symmetric. We can construct this basis by considering the independent components of a symmetric $3 \\times 3$ matrix.\nThe independent components are the diagonal elements ($c_{11}, c_{22}, c_{33}$) and the off-diagonal elements in the upper (or lower) triangle ($c_{12}, c_{13}, c_{23}$). This gives a total of $3+3=6$ independent coefficients, so the dimension of the fixed subspace is 6.\n\nLet's construct the basis vectors by setting one independent coefficient to 1 and all others to 0.\n\n1.  **Diagonal terms ($i=j$)**:\n    -   Set $c_{11}=1$ and all other $c_{kl}=0$. This gives the vector $x_1 = 1 \\cdot e_1 \\otimes e_1 = e_1 \\otimes e_1$.\n    -   Set $c_{22}=1$ and all other $c_{kl}=0$. This gives the vector $x_2 = e_2 \\otimes e_2$.\n    -   Set $c_{33}=1$ and all other $c_{kl}=0$. This gives the vector $x_3 = e_3 \\otimes e_3$.\n    These three vectors are clearly fixed by $\\tau$: $\\tau \\cdot (e_i \\otimes e_i) = e_i \\otimes e_i$.\n\n2.  **Off-diagonal terms ($i \\neq j$)**:\n    -   Consider the pair $(1,2)$. The condition is $c_{12} = c_{21}$. Let's set $c_{12}=c_{21}=1$ and all other coefficients to 0. This gives the vector $x_4 = 1 \\cdot e_1 \\otimes e_2 + 1 \\cdot e_2 \\otimes e_1 = e_1 \\otimes e_2 + e_2 \\otimes e_1$.\n    -   Consider the pair $(1,3)$. The condition is $c_{13} = c_{31}$. Let's set $c_{13}=c_{31}=1$ and all other coefficients to 0. This gives the vector $x_5 = e_1 \\otimes e_3 + e_3 \\otimes e_1$.\n    -   Consider the pair $(2,3)$. The condition is $c_{23} = c_{32}$. Let's set $c_{23}=c_{32}=1$ and all other coefficients to 0. This gives the vector $x_6 = e_2 \\otimes e_3 + e_3 \\otimes e_2$.\n    These three vectors are also fixed by $\\tau$, for example: $\\tau \\cdot (e_1 \\otimes e_2 + e_2 \\otimes e_1) = \\tau \\cdot (e_1 \\otimes e_2) + \\tau \\cdot (e_2 \\otimes e_1) = e_2 \\otimes e_1 + e_1 \\otimes e_2$.\n\nThe set $\\{x_1, x_2, x_3, x_4, x_5, x_6\\}$ consists of 6 linearly independent vectors that span the fixed subspace. Thus, it is a basis. This set is:\n$$ \\{e_1 \\otimes e_1, e_2 \\otimes e_2, e_3 \\otimes e_3, e_1 \\otimes e_2 + e_2 \\otimes e_1, e_1 \\otimes e_3 + e_3 \\otimes e_1, e_2 \\otimes e_3 + e_3 \\otimes e_2\\} $$\nThis matches the set given in option A.\n\nLet's briefly examine the other options:\n-   Option B is a basis for the anti-symmetric subspace, where $\\tau \\cdot x = -x$. The dimension is $\\binom{3}{2}=3$.\n-   Option C is the standard basis for the entire space $W$. Its dimension is 9. It contains vectors like $e_1 \\otimes e_2$, which are not fixed by $\\tau$.\n-   Option D is a set of 6 vectors, but it is not a basis for the fixed subspace. For example, it includes $e_1 \\otimes e_2$ and $e_2 \\otimes e_1$ separately. Neither of these is fixed by $\\tau$ ($\\tau \\cdot (e_1 \\otimes e_2) = e_2 \\otimes e_1$).\n-   Option E contains 7 vectors. Since the dimension of the subspace is 6, this set cannot be a basis as it is not linearly independent. The last vector is a linear combination of the first and fourth vectors in the set.\n\nTherefore, the correct basis is the one presented in option A.", "answer": "$$\\boxed{A}$$", "id": "1640035"}, {"introduction": "The power of Schur-Weyl duality lies in the fact that the action of the general linear group $GL(V)$ and the action of the symmetric group $S_k$ on $V^{\\otimes k}$ commute with each other. This final practice delves into the heart of this relationship by asking you to determine the precise conditions under which an operator derived from the $GL(V)$ action commutes with the permutation action of $S_2$. Solving this will provide deep insight into the structure that makes the duality possible. [@problem_id:1639986]", "problem": "Let $V$ be a finite-dimensional vector space over the field of complex numbers $\\mathbb{C}$, with dimension $\\dim(V) \\ge 2$. Let $\\text{End}(V)$ denote the space of linear operators from $V$ to itself. Consider two operators $A, B \\in \\text{End}(V)$. These operators can be used to construct a new operator $T = A \\otimes B$ on the tensor product space $V \\otimes V$. The action of $T$ on a simple tensor $v \\otimes w \\in V \\otimes V$ is defined as $T(v \\otimes w) = (Av) \\otimes (Bw)$, and this action is extended linearly to all of $V \\otimes V$.\n\nAnother important operator on $V \\otimes V$ is the flip operator, $S$, which is defined by its action on simple tensors as $S(v \\otimes w) = w \\otimes v$, and is extended linearly to the entire space.\n\nWhich of the following presents a necessary and sufficient condition on the operators $A$ and $B$ for the operator $T$ to commute with the flip operator $S$, i.e., for $ST = TS$?\n\nA. $A=B$.\n\nB. $A$ and $B$ are linearly dependent in the vector space $\\text{End}(V)$.\n\nC. $A$ and $B$ must commute with each other, i.e., $AB = BA$.\n\nD. Both $A$ and $B$ must be scalar multiples of the identity operator $I \\in \\text{End}(V)$.\n\nE. At least one of the operators $A$ or $B$ must be the zero operator.", "solution": "Let $T = A \\otimes B$ and let $S$ be the flip operator on $V \\otimes V$, with $S^{2} = I$ and $S(v \\otimes w) = w \\otimes v$. The commutation condition $ST = TS$ is equivalent to\n$$\nT = S T S,\n$$\nsince left-multiplying $ST = TS$ by $S$ and using $S^{2} = I$ yields $T = S T S$. On simple tensors,\n$$\nS(A \\otimes B)S(v \\otimes w) = S(A \\otimes B)(w \\otimes v) = S(Aw \\otimes Bv) = Bv \\otimes Aw,\n$$\nso $S(A \\otimes B)S = B \\otimes A$. Therefore,\n$$\nST = TS \\quad \\Longleftrightarrow \\quad A \\otimes B = B \\otimes A.\n$$\n\nWe now characterize when $A \\otimes B = B \\otimes A$. Acting on $v \\otimes w$ gives, for all $v,w \\in V$,\n$$\nA v \\otimes B w = B v \\otimes A w. \\quad (\\ast)\n$$\n\nSufficiency of linear dependence: If $B = \\lambda A$ for some scalar $\\lambda \\in \\mathbb{C}$ (which includes the case $A=0$ or $B=0$), then $A \\otimes B = A \\otimes \\lambda A = \\lambda(A \\otimes A) = \\lambda(A \\otimes A) = B \\otimes A$, hence $(\\ast)$ holds and $ST = TS$.\n\nNecessity of linear dependence: Assume $A \\otimes B = B \\otimes A$ and suppose $B \\neq 0$. From $(\\ast)$, fix $v \\in V$. If $A v$ and $B v$ were linearly independent for some $v$, then there exists a linear functional $f \\in V^{\\ast}$ such that $f(B v) = 0$ and $f(A v) \\neq 0$. Applying $f \\otimes \\mathrm{id}$ to $(\\ast)$ yields\n$$\nf(A v)\\, B w = f(B v)\\, A w = 0 \\quad \\text{for all } w \\in V,\n$$\nwhich implies $B = 0$, contradicting $B \\neq 0$. Hence, for every $v \\in V$, the vectors $A v$ and $B v$ are colinear.\n\nDefine $U = \\{v \\in V : A v \\neq 0\\}$. If $v \\in U$, there exists $c(v) \\in \\mathbb{C}$ with $B v = c(v)\\, A v$. If $v \\in \\ker A$, then taking $w$ with $A w \\neq 0$ in $(\\ast)$ gives $0 = B v \\otimes A w$, hence $B v = 0$, so $\\ker A \\subset \\ker B$. By symmetry of $A \\otimes B = B \\otimes A$ (interchanging $A$ and $B$), we also get $\\ker B \\subset \\ker A$, hence\n$$\n\\ker A = \\ker B.\n$$\n\nIf $\\operatorname{rank}(A) \\ge 2$, choose $u,v \\in V$ with $A u$ and $A v$ linearly independent. Then\n$$\nB(u+v) = B u + B v = c(u) A u + c(v) A v\n$$\nmust be colinear with\n$$\nA(u+v) = A u + A v.\n$$\nSince $A u$ and $A v$ are linearly independent, colinearity forces $c(u) = c(v)$. Varying $u,v$ in $U$ shows $c(\\cdot)$ is constant on $U$, say $c(\\cdot) \\equiv \\lambda$. Using $\\ker A = \\ker B$, the relation $B v = \\lambda A v$ holds for all $v \\in V$, hence $B = \\lambda A$.\n\nIf $\\operatorname{rank}(A) = 1$, then $\\operatorname{im} A$ is one-dimensional, and for all $v$ we have $B v$ colinear with $A v$, so $\\operatorname{im} B \\subset \\operatorname{im} A$. Since $\\ker A = \\ker B$, the ranks are equal, hence $\\operatorname{im} B = \\operatorname{im} A$. Thus there exists $x \\in V$ and linear functionals $\\alpha,\\beta \\in V^{\\ast}$ such that $A = x \\otimes \\alpha$ and $B = x \\otimes \\beta$. From $\\ker A = \\ker B$, we get $\\ker \\alpha = \\ker \\beta$, which implies $\\beta = \\lambda \\alpha$ for some $\\lambda \\in \\mathbb{C}$, hence $B = \\lambda A$.\n\nTherefore, in all cases, $A \\otimes B = B \\otimes A$ if and only if $A$ and $B$ are linearly dependent in $\\text{End}(V)$. By the initial equivalence, this is exactly the necessary and sufficient condition for $ST = TS$.\n\nAmong the options, this is option B. The other options are either sufficient but not necessary (A, D, E) or false in general (C).", "answer": "$$\\boxed{B}$$", "id": "1639986"}]}