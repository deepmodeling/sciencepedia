{"hands_on_practices": [{"introduction": "Understanding the structure of a group begins with understanding the behavior of its individual elements. This exercise provides fundamental practice in calculating the order of a matrix within a general linear group over a finite field, $GL_2(\\mathbb{F}_3)$. Mastering this type of calculation is essential, as it bridges the abstract concept of an element's order with concrete matrix multiplication under modular arithmetic [@problem_id:1629625].", "problem": "Consider the General Linear group of degree 2 over the finite field with 3 elements, denoted $GL_2(\\mathbb{F}_3)$. This group consists of all $2 \\times 2$ invertible matrices with entries from the field $\\mathbb{F}_3 = \\{0, 1, 2\\}$, where all arithmetic (addition and multiplication) is performed modulo 3. Determine the order of the matrix $A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 1 \\end{pmatrix}$ within this group.", "solution": "We seek the order of $A$ in $GL_{2}(\\mathbb{F}_{3})$, i.e., the least positive integer $k$ such that $A^{k}=I$, with all arithmetic performed modulo $3$.\n\nFirst, verify invertibility by computing the determinant:\n$$\n\\det(A)=2\\cdot 1-1\\cdot 1=1 \\mod 3,\n$$\nso $A\\in GL_{2}(\\mathbb{F}_{3})$.\n\nCompute the characteristic polynomial using the formula for $2\\times 2$ matrices. The trace is $\\operatorname{tr}(A)=2+1=3\\equiv 0 \\mod 3$, and the determinant is $1$. Therefore,\n$$\np(t)=t^{2}-\\operatorname{tr}(A)\\,t+\\det(A)=t^{2}+1 \\in \\mathbb{F}_{3}[t].\n$$\nSince $t^{2}+1$ has no roots in $\\mathbb{F}_{3}$ (indeed, $1^{2}+1=2\\neq 0$ and $2^{2}+1=1+1=2\\neq 0$), it is irreducible over $\\mathbb{F}_{3}$, hence it is the minimal polynomial of $A$. By the Cayley–Hamilton theorem, $A$ satisfies its characteristic polynomial:\n$$\nA^{2}+I=0 \\quad \\Rightarrow \\quad A^{2}=-I.\n$$\nOver $\\mathbb{F}_{3}$, $-1\\equiv 2$, so this is\n$$\nA^{2}=2I.\n$$\nSquaring both sides gives\n$$\nA^{4}=(A^{2})^{2}=(2I)^{2}=4I \\equiv I \\mod 3.\n$$\nThus $A^{4}=I$, so the order of $A$ divides $4$. To determine the exact order, we check smaller exponents. Clearly $A\\neq I$. Also,\n$$\nA^{2}=2I\\neq I \\quad \\text{in } \\mathbb{F}_{3},\n$$\nand\n$$\nA^{3}=A\\cdot A^{2}=A\\cdot 2I=2A\\neq I.\n$$\nTherefore, the smallest positive exponent yielding the identity is $4$.\n\nAs a direct verification, we can also compute $A^{2}$ explicitly:\n$$\nA^{2}=\\begin{pmatrix}2 & 1 \\\\ 1 & 1\\end{pmatrix}\\begin{pmatrix}2 & 1 \\\\ 1 & 1\\end{pmatrix}\n=\\begin{pmatrix}2\\cdot 2+1\\cdot 1 & 2\\cdot 1+1\\cdot 1 \\\\ 1\\cdot 2+1\\cdot 1 & 1\\cdot 1+1\\cdot 1\\end{pmatrix}\n=\\begin{pmatrix}5 & 3 \\\\ 3 & 2\\end{pmatrix}\n\\equiv \\begin{pmatrix}2 & 0 \\\\ 0 & 2\\end{pmatrix}=2I \\mod 3,\n$$\nwhich matches $A^{2}=2I$, confirming the above reasoning.\n\nHence, the order of $A$ is $4$.", "answer": "$$\\boxed{4}$$", "id": "1629625"}, {"introduction": "A core skill in group theory is identifying which subsets of a group are themselves groups, known as subgroups. This problem asks you to investigate whether a set of matrices defined by a specific property—being both invertible and skew-symmetric—forms a subgroup of $GL_n(\\mathbb{R})$. This practice is invaluable for developing a rigorous approach to verifying the subgroup axioms and shows how a plausible-sounding collection of elements can fail to form a subgroup [@problem_id:1629599].", "problem": "Let $GL_n(\\mathbb{R})$ denote the general linear group of degree $n$ over the real numbers. This group consists of all $n \\times n$ invertible matrices with real entries, with the group operation being matrix multiplication. A square matrix $A$ is defined as skew-symmetric if its transpose is equal to its negative, i.e., $A^T = -A$.\n\nConsider the subset $S_n \\subseteq GL_n(\\mathbb{R})$ which consists of all $n \\times n$ matrices that are both invertible and skew-symmetric. We are interested in whether $S_n$ forms a subgroup of $GL_n(\\mathbb{R})$.\n\nWhich of the following statements provides the most accurate and complete analysis regarding the assertion \"$S_n$ is a subgroup of $GL_n(\\mathbb{R})$\"?\n\nA. The assertion is true for all integers $n \\ge 1$.\n\nB. The assertion is false because, while $S_n$ is closed under taking inverses, it is not closed under matrix multiplication for any $n \\ge 2$.\n\nC. The assertion is false because the identity matrix $I_n$, which is the identity element of $GL_n(\\mathbb{R})$, is never skew-symmetric for $n \\ge 1$.\n\nD. The assertion is false. For any odd integer $n$, the set $S_n$ is empty. For any even integer $n \\ge 2$, the set $S_n$ is non-empty but is not closed under matrix multiplication.\n\nE. The assertion is false because the determinant of any skew-symmetric matrix is always zero, meaning the set $S_n$ of invertible skew-symmetric matrices is always empty.", "solution": "Let $S_{n}=\\{A\\in GL_{n}(\\mathbb{R}) : A^{T}=-A\\}$ be the set of invertible skew-symmetric $n\\times n$ real matrices. For a subset $H\\subseteq GL_{n}(\\mathbb{R})$ to be a subgroup, it must contain the identity matrix $I_{n}$ and be closed under matrix multiplication and inverses.\n\nFirst, observe that $I_{n}$ is not skew-symmetric: since $I_{n}^{T}=I_{n}$, the condition $I_{n}^{T}=-I_{n}$ would force $I_{n}=-I_{n}$, hence $2I_{n}=0$, which is impossible over $\\mathbb{R}$. Therefore $I_{n}\\notin S_{n}$, so $S_{n}$ cannot be a subgroup for any $n\\geq 1$.\n\nNext, analyze non-emptiness by parity. If $A$ is skew-symmetric, then\n$$\n\\det(A)=\\det(A^{T})=\\det(-A)=(-1)^{n}\\det(A).\n$$\nIf $n$ is odd, then $(-1)^{n}=-1$, so $\\det(A)=-\\det(A)$, hence $\\det(A)=0$. Thus no skew-symmetric matrix is invertible when $n$ is odd, and\n$$\nS_{n}=\\varnothing \\quad \\text{for odd } n.\n$$\nIf $n$ is even, then $S_{n}$ is non-empty. For example, when $n=2$, take\n$$\nJ=\\begin{pmatrix}0 & 1 \\\\ -1 & 0\\end{pmatrix},\n$$\nwhich satisfies $J^{T}=-J$ and $\\det(J)=1$, hence $J\\in S_{2}$. For general even $n$, block-diagonal matrices with $J$ on the diagonal give invertible skew-symmetric examples.\n\nNow check closure properties within $S_{n}$. If $A\\in S_{n}$ is invertible and skew-symmetric, then\n$$\nA^{T}=-A \\implies (A^{T})^{-1}=(-A)^{-1} \\implies (A^{-1})^{T}=-A^{-1},\n$$\nso $A^{-1}$ is also skew-symmetric. Hence $S_{n}$ is closed under taking inverses (whenever it is non-empty).\n\nHowever, $S_{n}$ is not closed under matrix multiplication (for even $n$ where it is non-empty). Indeed, for $n=2$,\n$$\nJ^{2}=-I_{2},\n$$\nand $-I_{2}$ is not skew-symmetric because $(-I_{2})^{T}=-I_{2}\\neq I_{2}=-(-I_{2})$. More generally, for skew-symmetric $A,B$, one has\n$$\n(AB)^{T}=B^{T}A^{T}=(-B)(-A)=BA,\n$$\nso $AB$ is skew-symmetric if and only if $BA=-AB$, which does not hold in general. Therefore $S_{n}$ fails closure under multiplication for even $n$.\n\nPutting these facts together:\n- For odd $n$, $S_{n}=\\varnothing$.\n- For even $n\\geq 2$, $S_{n}\\neq\\varnothing$, is closed under inverses, but is not closed under products, and in any case does not contain $I_{n}$.\n\nAmong the options, the statement that correctly and completely reflects these facts is: for odd $n$ the set is empty; for even $n$ it is non-empty but not closed under multiplication. This is exactly option D.", "answer": "$$\\boxed{D}$$", "id": "1629599"}, {"introduction": "The interplay between group theory and linear algebra is a source of many powerful results and interesting questions. This problem explores the connection between a group-theoretic property (being abelian) and a linear-algebraic one (simultaneous diagonalizability). You are tasked with evaluating whether every abelian subgroup of $GL_2(\\mathbb{R})$ is simultaneously diagonalizable, a process that requires a careful search for counterexamples and deepens your understanding of the conditions under which this important property holds [@problem_id:1629582].", "problem": "In linear algebra and group theory, we study the properties of sets of matrices. Let the General Linear group of degree 2, denoted $GL_2(\\mathbb{R})$, be the set of all $2 \\times 2$ invertible matrices with real entries, where the group operation is matrix multiplication. A subgroup $G$ of $GL_2(\\mathbb{R})$ is called abelian if for any two matrices $A, B \\in G$, their product commutes, i.e., $AB = BA$.\n\nA set of matrices $S \\subseteq GL_2(\\mathbb{R})$ is said to be simultaneously diagonalizable over $\\mathbb{R}$ if there exists a single invertible matrix $P$ with real entries such that for every matrix $A \\in S$, the matrix $P^{-1}AP$ is a diagonal matrix.\n\nConsider the following proposition: \"Every abelian subgroup of $GL_2(\\mathbb{R})$ is simultaneously diagonalizable over $\\mathbb{R}$.\"\n\nYour task is to determine if this proposition is true or false. If it is false, you must identify all choices from the list below that serve as valid counterexamples. A valid counterexample is a set of matrices that is an abelian subgroup of $GL_2(\\mathbb{R})$ but is not simultaneously diagonalizable over $\\mathbb{R}$. Select all options that apply.\n\nA. The set of all matrices of the form $\\begin{pmatrix} \\cosh(t) & \\sinh(t) \\\\ \\sinh(t) & \\cosh(t) \\end{pmatrix}$ for all $t \\in \\mathbb{R}$.\n\nB. The set of all matrices of the form $\\begin{pmatrix} a & 0 \\\\ 0 & d \\end{pmatrix}$ where $a, d \\in \\mathbb{R}$ and $ad \\neq 0$.\n\nC. The set of all matrices of the form $\\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{pmatrix}$ for all $\\theta \\in \\mathbb{R}$.\n\nD. The set of all matrices of the form $\\begin{pmatrix} 1 & b \\\\ 0 & 1 \\end{pmatrix}$ for all $b \\in \\mathbb{R}$.", "solution": "We analyze the proposition by checking, for each listed set, whether it is an abelian subgroup of $GL_{2}(\\mathbb{R})$ and whether it is simultaneously diagonalizable over $\\mathbb{R}$. A necessary condition for simultaneous diagonalization over $\\mathbb{R}$ is that every matrix in the set be diagonalizable over $\\mathbb{R}$: if a set $S$ is simultaneously diagonalizable, there exists $P \\in GL_{2}(\\mathbb{R})$ such that for each $A \\in S$, $P^{-1}AP$ is diagonal, hence each $A$ is diagonalizable over $\\mathbb{R}$.\n\nOption A: Consider $A(t)=\\begin{pmatrix}\\cosh(t)&\\sinh(t)\\\\ \\sinh(t)&\\cosh(t)\\end{pmatrix}$. This set is a subgroup since $A(t)A(s)=A(t+s)$ and $A(0)=I$, and it is abelian since $A(t)A(s)=A(s)A(t)$. For diagonalization, note that\n$$\nA(t)\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}\\cosh(t)+\\sinh(t)\\\\ \\sinh(t)+\\cosh(t)\\end{pmatrix}=\\exp(t)\\begin{pmatrix}1\\\\1\\end{pmatrix},\n$$\nand\n$$\nA(t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}=\\begin{pmatrix}\\cosh(t)-\\sinh(t)\\\\ \\sinh(t)-\\cosh(t)\\end{pmatrix}=\\exp(-t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nThus the eigenvectors $\\begin{pmatrix}1\\\\1\\end{pmatrix}$ and $\\begin{pmatrix}1\\\\-1\\end{pmatrix}$ are independent of $t$, with eigenvalues $\\exp(t)$ and $\\exp(-t)$. Letting $P=\\begin{pmatrix}1&1\\\\1&-1\\end{pmatrix}$, we obtain $P^{-1}A(t)P=\\operatorname{diag}(\\exp(t),\\exp(-t))$ for all $t$, so the set is simultaneously diagonalizable over $\\mathbb{R}$. Hence A is not a counterexample.\n\nOption B: The set of all diagonal invertible matrices $\\begin{pmatrix}a&0\\\\0&d\\end{pmatrix}$ with $ad\\neq 0$ is a subgroup, abelian (diagonal matrices commute), and already diagonal in the standard basis. Taking $P=I$, it is simultaneously diagonalizable over $\\mathbb{R}$. Hence B is not a counterexample.\n\nOption C: The rotation matrices $R(\\theta)=\\begin{pmatrix}\\cos(\\theta)&-\\sin(\\theta)\\\\ \\sin(\\theta)&\\cos(\\theta)\\end{pmatrix}$ form a subgroup with $R(\\theta)R(\\phi)=R(\\theta+\\phi)$ and $R(0)=I$, and the group is abelian since $R(\\theta)R(\\phi)=R(\\phi)R(\\theta)$. For $\\theta$ with $\\theta \\not\\equiv 0 \\pmod{\\pi}$, the characteristic polynomial is $\\lambda^{2}-2\\cos(\\theta)\\lambda+1$, whose discriminant is $4(\\cos^{2}(\\theta)-1)<0$, so the eigenvalues are nonreal. Therefore such $R(\\theta)$ is not diagonalizable over $\\mathbb{R}$. Since simultaneous diagonalization over $\\mathbb{R}$ would force every element to be diagonalizable over $\\mathbb{R}$, this set cannot be simultaneously diagonalizable over $\\mathbb{R}$. Hence C is a valid counterexample.\n\nOption D: The unipotent upper triangular matrices $U(b)=\\begin{pmatrix}1&b\\\\0&1\\end{pmatrix}$ satisfy $U(b_{1})U(b_{2})=U(b_{1}+b_{2})$ and form an abelian subgroup. For $b\\neq 0$, $U(b)$ has a single eigenvalue $1$ and is a nontrivial Jordan block, hence is not diagonalizable over $\\mathbb{R}$. Therefore the set cannot be simultaneously diagonalizable over $\\mathbb{R}$. Hence D is a valid counterexample.\n\nTherefore, the proposition is false. The valid counterexamples among the options are C and D.", "answer": "$$\\boxed{CD}$$", "id": "1629582"}]}