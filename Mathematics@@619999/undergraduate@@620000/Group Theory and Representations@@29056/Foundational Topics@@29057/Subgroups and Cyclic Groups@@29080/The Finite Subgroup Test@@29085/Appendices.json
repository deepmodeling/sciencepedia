{"hands_on_practices": [{"introduction": "The Finite Subgroup Test is a powerful shortcut in group theory. It states that for any non-empty, finite subset of a group, if it's closed under the group's operation, it's automatically a subgroup. This exercise [@problem_id:1647701] provides a direct application of this principle within the familiar setting of rational numbers, allowing you to solidify your understanding of why finiteness combined with closure is enough to guarantee the existence of an identity and inverses.", "problem": "Let $(\\mathbb{Q}^*, \\cdot)$ denote the multiplicative group of non-zero rational numbers. Consider a non-empty, finite subset $H$ of $\\mathbb{Q}^*$ which is closed under the operation of multiplication. That is, for any two elements $a, b \\in H$, their product $ab$ is also in $H$.\n\nWhich of the following statements is a necessary consequence of these conditions?\n\nA. $H$ must be a subgroup of $(\\mathbb{Q}^*, \\cdot)$.\n\nB. It is possible for $H$ to not contain the identity element, $1$.\n\nC. $H$ could contain an element $x$ for which the multiplicative inverse $x^{-1}$ is not in $H$.\n\nD. It is possible for $H$ to contain the number $3$.\n\nE. The set $H = \\left\\{\\frac{1}{2}, \\frac{1}{4}\\right\\}$ is a valid example of such a set.", "solution": "We are given a non-empty, finite subset $H \\subset \\mathbb{Q}^{*}$ that is closed under multiplication. We analyze the structural consequences.\n\nFirst, we show that $1 \\in H$. Take any $x \\in H$. By closure under multiplication, the powers $x^{k} \\in H$ for all integers $k \\geq 1$, proven by induction: $x^{1} = x \\in H$, and if $x^{k} \\in H$ then $x^{k+1} = x^{k} \\cdot x \\in H$. Since $H$ is finite, there exist integers $m,n$ with $1 \\leq m  n$ such that $x^{m} = x^{n}$. Then\n$$\nx^{n-m} = x^{n} \\cdot x^{-m} = x^{m} \\cdot x^{-m} = 1.\n$$\nMoreover, by closure, $x^{n-m} \\in H$, hence $1 \\in H$.\n\nNext, we show that for every $x \\in H$, its inverse $x^{-1}$ is in $H$. From $x^{n-m} = 1$ above with $n-m \\geq 1$, we have\n$$\nx^{-1} = x^{n-m-1},\n$$\nand since $x^{k} \\in H$ for all $k \\geq 1$, it follows that $x^{-1} \\in H$. Therefore $H$ is closed under taking inverses.\n\nCombining closure under multiplication, the presence of the identity, and closure under inverses, $H$ satisfies the subgroup criteria in $(\\mathbb{Q}^{*}, \\cdot)$. Hence statement A must be true.\n\nWe now assess the remaining options:\n- B is false because we proved $1 \\in H$ is necessary.\n- C is false because we proved that for every $x \\in H$, $x^{-1} \\in H$.\n- D is false under the given finiteness condition. If $3 \\in H$, then by closure all powers $3^{k} \\in H$ for $k \\geq 1$. These are all distinct because $3^{i} = 3^{j}$ implies $3^{j-i} = 1$, which forces $i = j$. This yields an infinite subset of $H$, contradicting finiteness. Thus $3 \\notin H$ for any such finite $H$.\n- E is false because $H = \\{\\frac{1}{2}, \\frac{1}{4}\\}$ is not closed: $\\frac{1}{2} \\cdot \\frac{1}{4} = \\frac{1}{8} \\notin H$.\n\nTherefore, the only necessary consequence is that $H$ is a subgroup of $(\\mathbb{Q}^{*}, \\cdot)$, which corresponds to option A.", "answer": "$$\\boxed{A}$$", "id": "1647701"}, {"introduction": "Mathematical theorems are built on precise conditions, and understanding these boundaries is as important as knowing the theorem itself. What happens if we relax the 'non-empty' condition of the Finite Subgroup Test? This practice problem [@problem_id:1647682] investigates this very question within the context of vector spaces, highlighting the importance of considering all assumptions and revealing a rather striking property of finite, closed sets in this specific group.", "problem": "Consider the group $G = (\\mathbb{R}^n, +)$, where $\\mathbb{R}^n$ is the set of $n$-dimensional real vectors for some integer $n \\ge 1$, and $+$ is the standard component-wise vector addition. Let $H$ be a subset of $\\mathbb{R}^n$ that possesses the following two properties:\n1. $H$ is a finite set.\n2. $H$ is closed under vector addition (i.e., for any two vectors $\\mathbf{u}, \\mathbf{v} \\in H$, the vector sum $\\mathbf{u}+\\mathbf{v}$ is also in $H$).\n\nWhich of the following statements is the most accurate assessment of whether $H$ is necessarily a subgroup of $G$?\n\nA. Yes, because any finite subset of a group that is closed under the group operation is always a subgroup.\n\nB. Yes, because the given conditions imply that $H$ must be the trivial subgroup $\\{\\mathbf{0}\\}$.\n\nC. No, because it is not guaranteed that $H$ contains the identity element of $G$.\n\nD. No, because while $H$ must contain the identity element, it is not guaranteed to be closed under inverses.", "solution": "We work in the additive group $G=(\\mathbb{R}^{n},+)$.\n\n1. Suppose first that $H$ is nonempty. Pick any $\\mathbf{u}\\in H$. Because $H$ is closed under vector addition, for every positive integer $k$ the element\n$$\nk\\mathbf{u}=\\underbrace{\\mathbf{u}+\\cdots+\\mathbf{u}}_{k\\ \\text{times}}\n$$\nlies in $H$. Since $H$ is finite, there exist integers $mn\\geq 1$ such that $m\\mathbf{u}=n\\mathbf{u}$. Subtracting gives\n$$\n(m-n)\\mathbf{u}=\\mathbf{0}.\n$$\nIn the vector space $\\mathbb{R}^{n}$, the only solution to $k\\mathbf{x}=\\mathbf{0}$ with $k\\in\\mathbb{Z}\\setminus\\{0\\}$ is $\\mathbf{x}=\\mathbf{0}$, because the linear map $\\mathbf{x}\\mapsto k\\mathbf{x}$ has determinant $k^{n}\\neq 0$ and hence trivial kernel. Therefore $\\mathbf{u}=\\mathbf{0}$. Since $\\mathbf{u}$ was arbitrary in $H$, it follows that if $H$ is nonempty, then $H=\\{\\mathbf{0}\\}$, which is a subgroup of $G$.\n\n2. However, the hypotheses only assert that $H$ is finite and closed under addition; they do not assert that $H$ is nonempty. The empty set is finite and vacuously closed under addition, but it is not a subgroup because it does not contain the identity element $\\mathbf{0}$.\n\nTherefore, $H$ is not necessarily a subgroup of $G$ under the given assumptions. The most accurate reason among the options is that it is not guaranteed that $H$ contains the identity element of $G$.\n\nOption analysis:\n- A is false as stated because it omits the necessary nonemptiness condition (the empty set is a counterexample).\n- B would be true if $H$ were assumed nonempty, but as stated it fails because $H$ could be empty.\n- C correctly identifies the failure: the identity need not be present.\n- D is incorrect; in the only possible nonempty case $H=\\{\\mathbf{0}\\}$, closure under inverses holds trivially.\n\nHence the correct choice is C.", "answer": "$$\\boxed{C}$$", "id": "1647682"}, {"introduction": "Now that we have explored the Finite Subgroup Test, we can use it as a powerful tool to uncover deeper structural properties in more complex groups. This problem [@problem_id:1647692] takes us into the world of matrix groups, $GL_n(\\mathbb{C})$. By first confirming that a given set of matrices forms a finite subgroup, we can then deduce non-obvious and elegant properties about the matrices themselves, linking abstract group theory directly to key concepts in linear algebra like diagonalizability and determinants.", "problem": "Let $S$ be a finite, non-empty subset of $GL_n(\\mathbb{C})$, the group of $n \\times n$ invertible matrices with complex entries. Suppose that for any two matrices $A, B \\in S$, their product $AB$ is also in $S$ (i.e., $S$ is closed under matrix multiplication).\n\nWhich one of the following statements about such a set $S$ is NOT necessarily true?\n\nA. The identity matrix $I_n$ is an element of $S$.\n\nB. For any matrix $M \\in S$, its inverse $M^{-1}$ is also an element of $S$.\n\nC. The determinant of every matrix in $S$ is a root of unity.\n\nD. Every matrix in $S$ is diagonalizable over $\\mathbb{C}$.\n\nE. All matrices in $S$ are simultaneously diagonalizable.", "solution": "Let $S$ be a finite, non-empty subset of $GL_{n}(\\mathbb{C})$ closed under matrix multiplication.\n\nFirst, fix $A \\in S$. By closure, all positive powers $A^{m}$ belong to $S$ by induction: $A^{1}=A \\in S$, and if $A^{m} \\in S$ then $A^{m+1}=A^{m}A \\in S$. Since $S$ is finite, the sequence $\\{A^{m}\\}_{m \\geq 1}$ takes only finitely many values, so there exist integers $1 \\leq i  j$ with $A^{i}=A^{j}$. Because $A$ is invertible in $GL_{n}(\\mathbb{C})$, multiply on the left by $A^{-i}$ (in $GL_{n}(\\mathbb{C})$) to get $A^{j-i}=I_{n}$. But $A^{j-i}$ is a product of copies of $A$, hence $A^{j-i} \\in S$ by closure. Therefore $I_{n} \\in S$. This proves statement A.\n\nNext, for any $A \\in S$, from $A^{j-i}=I_{n}$ above we have $A^{j-i-1}$ is an inverse of $A$, i.e., $A A^{j-i-1}=I_{n}$. In a group, right inverses are unique and equal to $A^{-1}$, hence $A^{-1}=A^{j-i-1} \\in S$ as a power of $A$. This proves statement B. Consequently, $S$ is a finite subgroup of $GL_{n}(\\mathbb{C})$.\n\nFor statement C, let $M \\in S$. Since $S$ is a finite group, $M$ has finite order: there exists $k \\in \\mathbb{N}$ with $M^{k}=I_{n}$. Taking determinants gives $(\\det M)^{k}=\\det(M^{k})=\\det(I_{n})=1$, so $\\det M$ is a root of unity. Thus C is true.\n\nFor statement D, again for $M \\in S$ with $M^{k}=I_{n}$, the minimal polynomial $m_{M}(x)$ divides $x^{k}-1$. Over $\\mathbb{C}$, $x^{k}-1$ splits completely into linear factors, and it is square-free because its derivative $(x^{k}-1)'=k x^{k-1}$ shares no common root with $x^{k}-1$ (the only potential common root would be $x=0$, which is not a root of $x^{k}-1$). Therefore $m_{M}(x)$ has no repeated roots, which implies $M$ is diagonalizable over $\\mathbb{C}$. Hence D is true.\n\nFor statement E, simultaneous diagonalizability over $\\mathbb{C}$ implies pairwise commutativity: if all matrices in $S$ are simultaneously diagonalizable, then there exists an invertible $U$ such that every $U^{-1}MU$ is diagonal; diagonal matrices commute, so the original matrices commute as well. However, there exist finite subgroups of $GL_{n}(\\mathbb{C})$ that are not abelian. For example, let $S$ be the subgroup of $GL_{3}(\\mathbb{C})$ consisting of all $3 \\times 3$ permutation matrices (isomorphic to the symmetric group on three letters). Take\n$$\nA=\\begin{pmatrix}\n0  1  0\\\\\n1  0  0\\\\\n0  0  1\n\\end{pmatrix}, \\quad\nB=\\begin{pmatrix}\n1  0  0\\\\\n0  0  1\\\\\n0  1  0\n\\end{pmatrix}.\n$$\nThen $A,B \\in S$, $A^{2}=I_{3}$ and $B^{2}=I_{3}$, so both are diagonalizable; yet $AB \\neq BA$, so they cannot be simultaneously diagonalizable (since simultaneous diagonalization would force commutativity). Thus E is not necessarily true.\n\nTherefore, the only statement that is not necessarily true is E.", "answer": "$$\\boxed{E}$$", "id": "1647692"}]}