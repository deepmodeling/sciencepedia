## Applications and Interdisciplinary Connections

In the last chapter, we witnessed a triumph of ingenuity: the [priority method](@article_id:149723). We saw how Friedberg and Muchnik, with a beautifully simple system of priorities and restraints, constructed two [computably enumerable sets](@article_id:148453), $A$ and $B$, that were Turing-incomparable. They solved Post's problem and revealed that the universe of [unsolvable problems](@article_id:153308) was not a simple linear hierarchy. But the invention of a great new tool always begs the question: what else can it do? A telescope designed to resolve a specific double star can then be turned upon the whole of the heavens. So too with the [priority method](@article_id:149723). It is not just a solution to a single problem, but a versatile lathe for shaping the very fabric of [computability](@article_id:275517). In this chapter, we will explore the stunning zoological garden of computational objects that this method, and its more powerful descendants, allow us to construct.

### Fine-Tuning the Universe: Adding More Properties

Imagine you have the power to design abstract "creatures"—[computably enumerable sets](@article_id:148453)—and you can specify their properties. The [priority method](@article_id:149723) is our design toolkit. So far, we've specified one property: that our two creatures, $A$ and $B$, are incomparable. What if we want to add more traits?

For instance, can we construct these incomparable sets to also be *simple*? [@problem_id:2986966]. What does "simple" mean? Intuitively, a simple set is a c.e. set that is "thin" or "sparse"—its complement is infinite. Yet, it's also ubiquitous in a funny way: its complement, despite being infinite, is so cleverly sprinkled with elements of the set that it cannot contain any infinite c.e. set. A simple set is like a net that is mostly holes, yet is woven so skillfully that any infinite, algorithmically generated school of fish ($W_e$) is guaranteed to have at least one member caught in the net. This property makes a set non-computable, but in a very particular way.

So, can we build two sets $A$ and $B$ that are both simple *and* incomparable? The answer is a resounding yes. We simply add new "simplicity requirements" to our priority list. A requirement to make $A$ simple, $P_e^A$, might say: "If the c.e. set $W_e$ looks infinite, catch one of its elements for $A$." This is a *positive* requirement; it wants to *add* elements to $A$. This seems to be in direct conflict with the incomparability requirements, which are often *negative*—they want to *prevent* elements from entering a set to preserve a disagreement. Here is the beauty of the [priority method](@article_id:149723): it is a robust system for mediating conflict. By carefully ordering the requirements and respecting their restraints, we can satisfy everyone in the long run. The simplicity requirements are weaker; they can afford to wait for a witness that doesn't step on the toes of a higher-priority diagonalization. Because an infinite c.e. set will offer up infinitely many candidates, one will eventually be found that is "safe" to grab.

Let's try for an even subtler property: *lowness* [@problem_id:2986959]. For any set $A$, we can ask a new question: "What is [the halting problem](@article_id:264747) *relative to* $A$?" This gives us a new, more complex set, the *jump* of $A$, denoted $A'$. A non-computable set $A$ can be of low complexity in a higher-order sense if its jump, $A'$, is no more complex than the ordinary [halting problem](@article_id:136597), $\emptyset'$. We write this as $A' \equiv_T \emptyset'$. Such a set is called *low*. It’s like discovering a creature with a complex anatomy ($A$ is non-computable) but whose "shadow" in the next dimension of complexity ($A'$) is surprisingly simple. Can we build our incomparable sets to be low?

Once again, the [priority method](@article_id:149723) is up to the task. We can interleave "lowness requirements" into our priority list [@problem_id:2986943]. A lowness requirement $L_e$ for a set $A$ aims to ensure that if a computation $\Phi_e^A(e)$ halts, its convergence is "stable" and not the result of infinitely many changes in the oracle $A$. The strategy is to protect such convergent computations with restraints, just as we did for [diagonalization](@article_id:146522). This often involves a new, powerful technique called **permitting**, where we allow an element to enter $A$ only when a "permission slip" is granted by some other process, such as a change in the oracle for the other set, $B$ [@problem_id:2986947]. By carefully controlling the construction of $A$ in this way, we can ensure it doesn't become unnecessarily complex from this higher-order perspective.

### The Edge of a Gentler World: When Things Get Messy

The finite-injury [priority method](@article_id:149723) we've used so far is, in a sense, very "civilized." Each requirement gets pushed around by its superiors, but only for a while. Eventually, the higher-priority requirements finish their business, and every requirement gets a permanent, peaceful window to satisfy its goal. Every requirement is injured only a finite number of times. But what happens if our construction goals are more ambitious?

Consider the **Sacks Splitting Theorem** [@problem_id:2986979]. Given a non-computable c.e. set $W$, can we "split" it into two simpler c.e. sets, $A$ and $B$, such that $A$ and $B$ together can reconstruct all of $W$ (i.e., $A \oplus B \equiv_T W$), but neither $A$ nor $B$ alone is as complex as $W$? Or consider the problem of constructing a **[minimal pair](@article_id:147967)** [@problem_id:2986971]: can we find two non-computable c.e. sets $A$ and $B$ whose only common computational power is what's already computable? They are non-trivial on their own, but their computational "intersection" is trivial.

These goals are fundamentally harder. The strategies to achieve them are not a "one-and-done" affair. For a [minimal pair](@article_id:147967), for example, the requirement is not to force a disagreement, but to ensure that if two computations, one from $A$ and one from $B$, agree on a function, that function must be computable. This requires a strategy that must be prepared to monitor and repair agreements indefinitely. A single action by a higher-priority requirement can undo this delicate balance, and the strategy may have to start over, again and again, *infinitely often*.

This is the wild world of **infinite-injury** priority arguments. The analogy is moving from an orderly committee meeting to a chaotic, endless debate. To prove that anything gets done at all requires a far more sophisticated architecture. Instead of a simple priority list, a **priority tree** is used, where the branches represent different possible futures for the construction. We can only prove that along the "true path" of this tree—the future that is actually realized—our goals are met. The Friedberg-Muchnik method was our first, elegant step into the landscape of priority constructions, but that landscape contains far vaster and stormier terrains.

### The Grand Structure: A Universe in a Nutshell

Having seen the power and flexibility of these methods, let's step back and ask a very Feynman-esque question: What does this all *mean*? What does this menagerie of constructed objects tell us about the deep structure of the computational universe? The answer is profound.

First, there is the **Relativization Principle** [@problem_id:2986950]. It turns out that all the intricate structures we have so pains-takingly constructed—incomparable sets, low sets, minimal pairs, and so on—can be built not just from the ground up (relative to the computable sets, $\emptyset$), but on top of *any* arbitrary set $B$ used as an oracle. The entire drama of the c.e. degrees, with its incomparable pairs and splittable degrees, plays out in the world of sets "c.e. in $B$." It is as if we discovered that the fundamental laws of biology not only produce the life we see on Earth, but would produce a structurally identical tapestry of life on any planet, regardless of its "primordial soup" (the oracle $B$). The architecture of computability is not an accident of our starting point; it appears to be a universal, fractal-like pattern.

Second, and perhaps most astonishingly, is the **Embedding Theorem** for finite partial orders [@problem_id:2978718]. The Friedberg-Muchnik theorem can be seen as embedding the simplest non-trivial [partial order](@article_id:144973)—two incomparable elements—into the c.e. degrees. But this is just the tip of the iceberg. The full truth, established through more powerful priority arguments, is that *any* finite partial order, no matter how complex its web of dependencies, can be faithfully embedded into the c.e. degrees. Take any chart of organizational hierarchy, any network of prerequisites, any family tree—as long as it's finite, there exist [computably enumerable sets](@article_id:148453) whose Turing degrees are arranged in precisely that same structure.

This is the ultimate application of the [priority method](@article_id:149723). It is the mathematical telescope that has revealed the staggering richness of the c.e. degrees. This is not some barren wasteland of a few exceptional [unsolvable problems](@article_id:153308). It is a universe teeming with structure, a world complex enough to contain a copy of every finite structural possibility. Hidden within the seemingly simple notion of what can be "listed by a computer" is a cosmos of breathtaking complexity, and the [priority method](@article_id:149723) is our key to exploring it.

And how does this amazing machinery work on the inside? How can a strategy in the construction "know its own name" to synchronize its actions with another process? This is where the whole subject folds back on itself, using deep results like Kleene's Recursion Theorem to create [self-referential programs](@article_id:636540) that act as the agents in our priority arguments [@problem_id:2986962]. The entire edifice is a beautiful, self-contained testament to the power of pure reason to map the invisible world of computation.