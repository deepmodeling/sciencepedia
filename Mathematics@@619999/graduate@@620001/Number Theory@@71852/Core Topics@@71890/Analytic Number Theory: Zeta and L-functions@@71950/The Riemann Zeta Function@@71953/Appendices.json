{"hands_on_practices": [{"introduction": "Before venturing into the complexities of analytic continuation and the critical strip, it is essential to build intuition for the Riemann zeta function in its natural domain of convergence. This first practice invites you to use the fundamental integral test from calculus to establish simple but powerful bounds for $\\zeta(s)$ when $s$ is a real number with $s \\gt 1$. This exercise not only sharpens your analytic estimation skills but also provides a clear view of the function's singularity at $s=1$ by quantifying how it diverges as $s \\to 1^{+}$ [@problem_id:2282759].", "problem": "The Riemann zeta function, denoted $\\zeta(s)$, is a crucial function in number theory and analysis. For real values of the argument $s$ where $s1$, it is defined by the infinite series:\n$$ \\zeta(s) = \\sum_{n=1}^{\\infty} \\frac{1}{n^s} = 1 + \\frac{1}{2^s} + \\frac{1}{3^s} + \\dots $$\nWhich of the following inequalities correctly describes the bounds for $\\zeta(s)$ for all real numbers $s  1$?\n\nA. $1  \\zeta(s)  \\frac{1}{s-1}$\n\nB. $1  \\zeta(s)  1 + \\frac{1}{s-1}$\n\nC. $\\frac{1}{s-1}  \\zeta(s)  1$\n\nD. $\\zeta(s)  1 + \\frac{1}{s-1}$\n\nE. $1  \\zeta(s)  1 + \\frac{1}{s}$", "solution": "For $s1$, consider the positive, continuous, and strictly decreasing function $f(x)=x^{-s}$ on $[1,\\infty)$. For such $f$, the integral test bounds give, for each integer $n\\geq 1$,\n$$\nf(n+1)\\int_{n}^{n+1} f(x)\\,dx  f(n).\n$$\nSumming from $n=1$ to $N$ and letting $N \\to \\infty$ yields\n$$\n\\sum_{n=2}^{\\infty} f(n)  \\int_{1}^{\\infty} f(x)\\,dx  \\sum_{n=1}^{\\infty} f(n).\n$$\nWith $f(x)=x^{-s}$, this becomes\n$$\n\\sum_{n=2}^{\\infty} \\frac{1}{n^{s}}  \\int_{1}^{\\infty} x^{-s}\\,dx  \\sum_{n=1}^{\\infty} \\frac{1}{n^{s}}=\\zeta(s).\n$$\nTherefore,\n$$\n\\zeta(s)=1+\\sum_{n=2}^{\\infty} \\frac{1}{n^{s}}  1+\\int_{1}^{\\infty} x^{-s}\\,dx.\n$$\nCompute the integral for $s1$:\n$$\n\\int_{1}^{\\infty} x^{-s}\\,dx=\\lim_{b \\to \\infty}\\int_{1}^{b} x^{-s}\\,dx=\\lim_{b \\to \\infty}\\left[\\frac{x^{1-s}}{1-s}\\right]_{1}^{b}\n=\\lim_{b \\to \\infty}\\left(\\frac{b^{1-s}}{1-s}-\\frac{1}{1-s}\\right)\n=\\frac{1}{s-1},\n$$\nsince $1-s0$ implies $b^{1-s} \\to 0$ as $b \\to \\infty$. Because all terms in the defining series are positive, $\\zeta(s)1$. Combining, we obtain the strict bounds\n$$\n1\\zeta(s)1+\\frac{1}{s-1}\\quad\\text{for all }s1.\n$$\nThis corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "2282759"}, {"introduction": "The definition of $\\zeta(s)$ as a Dirichlet series is limited to the half-plane $\\operatorname{Re}(s) \\gt 1$. This exercise provides a hands-on guide through the pivotal process of analytic continuation, allowing us to assign meaningful values to $\\zeta(s)$ outside this domain. By manipulating the integral representation of $\\zeta(s)$ and leveraging the generating function for Bernoulli numbers, you will concretely calculate the famous values $\\zeta(0)$ and $\\zeta(-1)$, transforming an abstract concept into a powerful computational tool [@problem_id:3029119].", "problem": "Let $\\zeta(s)$ denote the Riemann zeta function defined for $\\operatorname{Re}(s)  1$ by the Dirichlet series $\\zeta(s) = \\sum_{n=1}^{\\infty} n^{-s}$, and let $\\Gamma(s)$ denote the Euler gamma function. Define the Bernoulli numbers $\\{B_{n}\\}_{n \\geq 0}$ by the generating function\n$$\n\\frac{t}{\\exp(t) - 1} \\;=\\; \\sum_{n=0}^{\\infty} B_{n} \\,\\frac{t^{n}}{n!}.\n$$\nStarting only from these definitions and the Mellin transform identity\n$$\n\\Gamma(s)\\,\\zeta(s) \\;=\\; \\int_{0}^{\\infty} \\frac{x^{\\,s-1}}{\\exp(x)-1}\\,dx \\quad \\text{for } \\operatorname{Re}(s)  1,\n$$\nperform an analytic continuation of $\\zeta(s)$ to a neighborhood of $s=0$ and $s=-1$ by subtracting and adding the small-$x$ singular terms of the integrand that are implied by the Bernoulli-number generating function. Then extract the finite values of $\\zeta(0)$ and $\\zeta(-1)$ by comparing the poles of $\\Gamma(s)\\zeta(s)$ with those of $\\Gamma(s)$. Express your final answer as a single row matrix $\\begin{pmatrix}\\zeta(0)  \\zeta(-1)\\end{pmatrix}$. No numerical approximation is required; give exact values.", "solution": "The problem requires the determination of the values of the Riemann zeta function at $s=0$ and $s=-1$, denoted $\\zeta(0)$ and $\\zeta(-1)$, starting from fundamental definitions.\n\nThe initial definition for the Riemann zeta function is the Dirichlet series $\\zeta(s) = \\sum_{n=1}^{\\infty} n^{-s}$, which converges for complex numbers $s$ with real part $\\operatorname{Re}(s) > 1$. The problem provides the following integral representation involving the Euler gamma function $\\Gamma(s)$:\n$$\n\\Gamma(s)\\zeta(s) = \\int_{0}^{\\infty} \\frac{x^{s-1}}{\\exp(x)-1}\\,dx, \\quad \\text{for } \\operatorname{Re}(s)  1\n$$\nThis integral representation is also valid only for $\\operatorname{Re}(s)1$ because the integrand behaves as $x^{s-2}$ for $x \\to 0$, and the integral $\\int_0 \\cdot dx$ converges only if the exponent $s-2$ is greater than $-1$. To find values of $\\zeta(s)$ for other $s$, we must analytically continue this expression.\n\nThe problem directs us to use the generating function for the Bernoulli numbers, $\\{B_n\\}$, which is given as:\n$$\n\\frac{t}{\\exp(t) - 1} = \\sum_{n=0}^{\\infty} B_{n} \\frac{t^{n}}{n!}\n$$\nWe can use this to expand the term $\\frac{1}{\\exp(x)-1}$ in the integrand for small $x$:\n$$\n\\frac{1}{\\exp(x)-1} = \\frac{1}{x} \\left( \\frac{x}{\\exp(x)-1} \\right) = \\frac{1}{x} \\sum_{n=0}^{\\infty} B_n \\frac{x^n}{n!} = \\sum_{n=0}^{\\infty} \\frac{B_n}{n!} x^{n-1}\n$$\nThis expansion reveals the nature of the singularity at $x=0$. We can find the first few Bernoulli numbers by expanding the left-hand side of the generating function definition as a power series in $t$:\n$$\n\\frac{t}{\\exp(t) - 1} = \\frac{t}{(1+t+\\frac{t^2}{2!}+\\frac{t^3}{3!}+\\dots) - 1} = \\frac{t}{t+\\frac{t^2}{2}+\\frac{t^3}{6}+\\dots} = \\frac{1}{1+\\frac{t}{2}+\\frac{t^2}{6}+\\dots}\n$$\nPerforming a long division or using the geometric series expansion $1/(1-u) \\approx 1+u+u^2$:\n$$\n1 - \\left(\\frac{t}{2}+\\frac{t^2}{6}\\right) + \\left(\\frac{t}{2}\\right)^2 - \\dots = 1 - \\frac{t}{2} - \\frac{t^2}{6} + \\frac{t^2}{4} + O(t^3) = 1 - \\frac{1}{2}t + \\frac{1}{12}t^2 + O(t^3)\n$$\nComparing this to $\\sum_{n=0}^{\\infty} B_n \\frac{t^n}{n!} = B_0 + B_1 t + \\frac{B_2}{2!}t^2 + \\dots$:\n$B_0 = 1$\n$B_1 = -\\frac{1}{2}$\n$\\frac{B_2}{2} = \\frac{1}{12} \\implies B_2 = \\frac{1}{6}$\n\nTo perform the analytic continuation, we split the integral for $\\Gamma(s)\\zeta(s)$ at $x=1$:\n$$\n\\Gamma(s)\\zeta(s) = \\int_{1}^{\\infty} \\frac{x^{s-1}}{\\exp(x)-1}\\,dx + \\int_{0}^{1} \\frac{x^{s-1}}{\\exp(x)-1}\\,dx\n$$\nThe first integral, $\\int_{1}^{\\infty} \\frac{x^{s-1}}{\\exp(x)-1}\\,dx$, converges for all complex $s$ because the term $\\exp(x)$ in the denominator grows much faster than any power $x^{s-1}$, making this part an entire function of $s$. The second integral harbors the singularity. We handle it by subtracting and adding the singular terms from the Bernoulli expansion:\n$$\n\\int_{0}^{1} \\frac{x^{s-1}}{\\exp(x)-1}\\,dx = \\int_{0}^{1} x^{s-1} \\left( \\sum_{n=0}^{N-1} \\frac{B_n}{n!}x^{n-1} \\right) dx + \\int_{0}^{1} x^{s-1} \\left( \\frac{1}{\\exp(x)-1} - \\sum_{n=0}^{N-1} \\frac{B_n}{n!}x^{n-1} \\right) dx\n$$\nThe first part can be integrated term-by-term:\n$$\n\\int_{0}^{1} x^{s-1} \\left( \\sum_{n=0}^{N-1} \\frac{B_n}{n!}x^{n-1} \\right) dx = \\sum_{n=0}^{N-1} \\frac{B_n}{n!} \\int_{0}^{1} x^{s+n-2}\\,dx = \\sum_{n=0}^{N-1} \\frac{B_n}{n!} \\frac{1}{s+n-1}\n$$\nThis expression is a meromorphic function of $s$ with simple poles at $s=1-n$ for $n=0, 1, \\dots, N-1$.\nThe second part involves a remainder term which, for $x\\to 0$, is of order $O(x^{N-1})$. The integral is then $\\int_0^1 x^{s-1} O(x^{N-1}) dx = \\int_0^1 O(x^{s+N-2}) dx$. This integral converges if $\\operatorname{Re}(s+N-2) > -1$, which means $\\operatorname{Re}(s) > 1-N$.\nThus, we have an expression for $\\Gamma(s)\\zeta(s)$ that is analytic for $\\operatorname{Re}(s) > 1-N$ except for the explicit poles:\n$$\n\\Gamma(s)\\zeta(s) = \\Phi_N(s) + \\sum_{n=0}^{N-1} \\frac{B_n}{n!(s+n-1)}\n$$\nwhere $\\Phi_N(s)$ is an analytic function in the half-plane $\\operatorname{Re}(s) > 1-N$.\n\nTo find $\\zeta(0)$, we must choose $N$ such that the domain of analyticity includes a neighborhood of $s=0$, i.e., $0 > 1-N \\implies N>1$. Let's choose $N=2$. The expression is valid for $\\operatorname{Re}(s)>-1$.\n$$\n\\Gamma(s)\\zeta(s) = \\Phi_2(s) + \\frac{B_0}{0!(s-1)} + \\frac{B_1}{1!(s)} = \\Phi_2(s) + \\frac{1}{s-1} - \\frac{1}{2s}\n$$\nThe function $\\zeta(s)$ is analytic at $s=0$. The gamma function $\\Gamma(s)$ has a simple pole at $s=0$ with residue $\\operatorname{Res}_{s=0}\\Gamma(s) = 1$. The Laurent series of $\\Gamma(s)$ and $\\zeta(s)$ around $s=0$ are:\n$\\Gamma(s) = \\frac{1}{s} + \\gamma + O(s)$\n$\\zeta(s) = \\zeta(0) + \\zeta'(0)s + O(s^2)$\nTheir product is:\n$\\Gamma(s)\\zeta(s) = \\left(\\frac{1}{s} + \\dots\\right)(\\zeta(0) + \\dots) = \\frac{\\zeta(0)}{s} + O(1)$\nThe principal part of Laurent series of $\\Gamma(s)\\zeta(s)$ at $s=0$ is $\\frac{\\zeta(0)}{s}$.\nFrom our derived expression for $\\Gamma(s)\\zeta(s)$, the parts $\\Phi_2(s)$ and $\\frac{1}{s-1}$ are analytic at $s=0$. The only term contributing to the pole at $s=0$ is $-\\frac{1}{2s}$.\nEquating the principal parts:\n$$\n\\frac{\\zeta(0)}{s} = -\\frac{1}{2s} \\quad \\implies \\quad \\zeta(0) = -\\frac{1}{2}\n$$\n\nTo find $\\zeta(-1)$, we need $N$ such that $-1 > 1-N \\implies N>2$. Let's choose $N=3$. The expression is valid for $\\operatorname{Re}(s)>-2$.\n$$\n\\Gamma(s)\\zeta(s) = \\Phi_3(s) + \\frac{B_0}{s-1} + \\frac{B_1}{s} + \\frac{B_2}{2!(s+1)} = \\Phi_3(s) + \\frac{1}{s-1} - \\frac{1}{2s} + \\frac{1}{12(s+1)}\n$$\nThe function $\\zeta(s)$ is analytic at $s=-1$. $\\Gamma(s)$ has a simple pole at $s=-1$ with residue $\\operatorname{Res}_{s=-1}\\Gamma(s) = \\frac{(-1)^1}{1!} = -1$.\nThe Laurent series around $s=-1$ are:\n$\\Gamma(s) = \\frac{-1}{s+1} + c_0 + O(s+1)$\n$\\zeta(s) = \\zeta(-1) + \\zeta'(-1)(s+1) + O((s+1)^2)$\nTheir product is:\n$\\Gamma(s)\\zeta(s) = \\left(\\frac{-1}{s+1} + \\dots\\right)(\\zeta(-1) + \\dots) = \\frac{-\\zeta(-1)}{s+1} + O(1)$\nThe principal part of $\\Gamma(s)\\zeta(s)$ at $s=-1$ is $\\frac{-\\zeta(-1)}{s+1}$.\nFrom our derived expression, the terms $\\Phi_3(s)$, $\\frac{1}{s-1}$, and $-\\frac{1}{2s}$ are analytic at $s=-1$. The pole at $s=-1$ comes from the term $\\frac{1}{12(s+1)}$.\nEquating the principal parts:\n$$\n\\frac{-\\zeta(-1)}{s+1} = \\frac{1}{12(s+1)} \\quad \\implies \\quad -\\zeta(-1) = \\frac{1}{12} \\quad \\implies \\quad \\zeta(-1) = -\\frac{1}{12}\n$$\nWe have found the exact values $\\zeta(0) = -\\frac{1}{2}$ and $\\zeta(-1) = -\\frac{1}{12}$. The question asks for the answer as a single row matrix.", "answer": "$$\n\\boxed{\\begin{pmatrix} -\\frac{1}{2}  -\\frac{1}{12} \\end{pmatrix}}\n$$", "id": "3029119"}, {"introduction": "The heart of the mystery surrounding the Riemann zeta function lies in the location of its zeros. This practice moves from pure theory to the logic of computational number theory, exploring how zeros on the critical line are rigorously located and counted. You will analyze the properties of the Hardy function $Z(t)$, a real-valued transformation of $\\zeta(s)$ on the critical line $\\operatorname{Re}(s) = \\frac{1}{2}$, and assess the mathematical principles that underpin the modern search for zeros and the verification of the Riemann Hypothesis up to enormous heights [@problem_id:3029124].", "problem": "Let $\\zeta(s)$ denote the Riemann zeta function, initially defined for $\\operatorname{Re}(s)1$ by the Dirichlet series $\\zeta(s)=\\sum_{n=1}^{\\infty} n^{-s}$ and extended to a meromorphic function on $\\mathbb{C}$ with a simple pole at $s=1$, satisfying the functional equation for the completed function $\\xi(s)=\\tfrac{1}{2}s(s-1)\\pi^{-s/2}\\Gamma\\!\\left(\\tfrac{s}{2}\\right)\\zeta(s)$, namely $\\xi(s)=\\xi(1-s)$. Define the Hardy function $Z(t)$ by $Z(t)=e^{i\\theta(t)}\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$, where $\\theta(t)$ is a real-valued function constructed from the gamma factor in the functional equation so that $Z(t)\\in\\mathbb{R}$ for all real $t$. You have access to a numerical routine that evaluates $Z(t)$ at prescribed real inputs $t$ to a guaranteed absolute error less than $10^{-12}$.\n\nYou intend to numerically locate zeros of $\\zeta(s)$ on the critical line $\\operatorname{Re}(s)=\\tfrac{1}{2}$ up to height $T0$ by tracking sign changes of $Z(t)$ on a mesh $0=t_{0}t_{1}\\cdotst_{N}=T$. Consider the following statements about the mathematical justification and limitations of this approach.\n\nWhich of the following statements are correct?\n\nA. If $Z(t)$ changes sign between $t_{j}$ and $t_{j+1}$, then there exists at least one zero of $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$ in the open interval $(t_{j},t_{j+1})$.\n\nB. If $Z(t)$ exhibits no sign changes on the entire interval $[t_{j},t_{j+1}]$, then there are no zeros of $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$ in $(t_{j},t_{j+1})$.\n\nC. Counting sign changes of the sampled values $Z(t_{j})$ yields a rigorous lower bound for the number of zeros of $\\zeta(s)$ on the critical line in $0t\\le T$.\n\nD. The number of sign changes of $Z(t)$ on $[0,T]$ always equals the total number of zeros $\\rho=\\beta+i\\gamma$ of $\\zeta(s)$ with $0\\gamma\\le T$ (counted with multiplicity), regardless of whether $\\beta=\\tfrac{1}{2}$.\n\nE. If $Z(t_{0})=0$ and $Z'(t_{0})\\neq 0$ for some real $t_{0}$, then $\\zeta(s)$ has a simple zero at $s=\\tfrac{1}{2}+it_{0}$.\n\nF. By combining a count of sign changes of $Z(t)$ on $[0,T]$ with the Riemann–von Mangoldt formula for $N(T)$ (the number of zeros $\\rho=\\beta+i\\gamma$ with $0\\gamma\\le T$) and explicit bounds for the argument function $S(T)$, one can certify that all zeros with $0\\Im(s)\\le T$ lie on the critical line $\\operatorname{Re}(s)=\\tfrac{1}{2}$.\n\nG. Since $\\theta(t)$ is strictly increasing for all sufficiently large $t$, each Gram interval contains exactly one zero of $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$.\n\nSelect all that apply. Give a principled justification based on the functional equation, the reality of $Z(t)$, and standard zero-counting facts for $\\zeta(s)$; do not assume unproven conjectures such as the Riemann Hypothesis or the simplicity of zeros.", "solution": "The problem statement is a valid exercise in analytic number theory. It provides standard definitions for the Riemann zeta function $\\zeta(s)$, the completed zeta function $\\xi(s)$, the functional equation, and the Hardy function $Z(t)$. The question asks to evaluate the correctness of several statements concerning a standard numerical method for locating zeros of $\\zeta(s)$ on the critical line. All definitions are correct and the problem is well-posed and scientifically grounded.\n\nLet us analyze each statement based on the provided definitions and established principles of the theory of the Riemann zeta function. The core definitions are:\n1.  $\\zeta(s)$ is a meromorphic function on $\\mathbb{C}$.\n2.  The functional equation is $\\xi(s) = \\xi(1-s)$, where $\\xi(s)=\\tfrac{1}{2}s(s-1)\\pi^{-s/2}\\Gamma\\!\\left(\\tfrac{s}{2}\\right)\\zeta(s)$.\n3.  Hardy's function $Z(t) = e^{i\\theta(t)}\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$ is a real-valued function for real $t$. The phase factor $e^{i\\theta(t)}$ is defined as $\\pi^{-it/2}\\Gamma(\\frac{1}{4}+\\frac{it}{2}) / |\\pi^{-it/2}\\Gamma(\\frac{1}{4}+\\frac{it}{2})|$. Because $e^{i\\theta(t)}$ is always on the unit circle in $\\mathbb{C}$, it is never zero.\n4.  Consequently, for a real value $t$, $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right) = 0$ if and only if $Z(t)=0$.\n5.  $Z(t)$ is a real analytic, and therefore continuous, function for all real $t$.\n\n**A. If $Z(t)$ changes sign between $t_{j}$ and $t_{j+1}$, then there exists at least one zero of $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$ in the open interval $(t_{j},t_{j+1})$.**\n\nThis statement concerns the properties of a continuous function. A sign change of $Z(t)$ between $t_j$ and $t_{j+1}$ means that $Z(t_j)$ and $Z(t_{j+1})$ are non-zero and have opposite signs, i.e., $Z(t_j)Z(t_{j+1})  0$. Since $Z(t)$ is a continuous function of $t$, the Intermediate Value Theorem guarantees that there must exist at least one value $t^* \\in (t_j, t_{j+1})$ such that $Z(t^*) = 0$. As established, $Z(t^*) = 0$ is equivalent to $\\zeta\\!\\left(\\tfrac{1}{2}+it^*\\right) = 0$. Thus, a sign change implies the existence of a zero on the critical line within the open interval.\n\n**Verdict: Correct.**\n\n**B. If $Z(t)$ exhibits no sign changes on the entire interval $[t_{j},t_{j+1}]$, then there are no zeros of $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$ in $(t_{j},t_{j+1})$.**\n\nThis statement is false. The absence of a sign change does not preclude the existence of zeros. There are two primary scenarios where this fails:\n1.  There could be an even number of simple zeros in the interval $(t_j, t_{j+1})$. For example, if there are two zeros, the function $Z(t)$ could cross the axis from positive to negative and then back to positive. It is possible that the mesh points $t_j$ and $t_{j+1}$ are such that $Z(t_j)  0$ and $Z(t_{j+1})  0$, completely missing the two zeros.\n2.  There could be a zero of even multiplicity in the interval. If $t^*$ is a zero of even multiplicity $m \\ge 2$, the function $Z(t)$ behaves like $C(t-t^*)^m$ near $t^*$. It touches the $t$-axis at $t=t^*$ but does not cross it. Therefore, there is a zero at $t^*$ but no sign change in the neighborhood of $t^*$. The problem explicitly states not to assume the simplicity of zeros.\n\n**Verdict: Incorrect.**\n\n**C. Counting sign changes of the sampled values $Z(t_{j})$ yields a rigorous lower bound for the number of zeros of $\\zeta(s)$ on the critical line in $0t\\le T$.**\n\nLet the number of sign changes in the sequence of sampled values $\\{Z(t_j)\\}_{j=0}^N$ be $k$. A sign change occurs between $t_j$ and $t_{j+1}$ if $Z(t_j)Z(t_{j+1})  0$. Let the set of indices where this occurs be $J = \\{j_1, j_2, \\dots, j_k\\}$. For each $j \\in J$, by statement A, we have a guarantee of at least one zero in the interval $(t_j, t_{j+1})$. Since the intervals $(t_j, t_{j+1})$ for different $j$ are disjoint, we have located at least $k$ distinct zeros of $\\zeta(s)$ on the critical line. The total number of zeros on the critical line in $(0, T]$, denoted $N_0(T)$, must therefore satisfy $N_0(T) \\ge k$. This means $k$ is a rigorous lower bound for $N_0(T)$. This bound may be poor if the mesh is coarse and misses zeros (as per the reasoning in B), but it is a lower bound nonetheless.\n\n**Verdict: Correct.**\n\n**D. The number of sign changes of $Z(t)$ on $[0,T]$ always equals the total number of zeros $\\rho=\\beta+i\\gamma$ of $\\zeta(s)$ with $0\\gamma\\le T$ (counted with multiplicity), regardless of whether $\\beta=\\tfrac{1}{2}$.**\n\nThis statement is incorrect for multiple reasons.\n1.  The function $Z(t)$ is defined only for real $t$, corresponding to the line $\\operatorname{Re}(s)=\\tfrac{1}{2}$. The behavior of $Z(t)$ provides information only about zeros on this line. It cannot detect or count zeros $\\rho=\\beta+i\\gamma$ where $\\beta \\neq \\tfrac{1}{2}$ (off-critical-line zeros). The statement explicitly includes these.\n2.  Even if all zeros were on the critical line (i.e., assuming the Riemann Hypothesis), the number of sign changes only counts zeros of odd multiplicity. As explained in the analysis of statement B, zeros of even multiplicity do not produce a sign change. The statement requires counting zeros with multiplicity, so a zero of multiplicity $m=2$ would contribute $2$ to the total count but $0$ to the sign-change count.\n\n**Verdict: Incorrect.**\n\n**E. If $Z(t_{0})=0$ and $Z'(t_{0})\\neq 0$ for some real $t_{0}$, then $\\zeta(s)$ has a simple zero at $s=\\tfrac{1}{2}+it_{0}$.**\n\nA zero $s_0$ of $\\zeta(s)$ is simple if $\\zeta(s_0)=0$ and $\\zeta'(s_0)\\neq 0$.\nGiven $Z(t_0)=0$, and $Z(t_0) = e^{i\\theta(t_0)}\\zeta(\\tfrac{1}{2}+it_0)$, since $e^{i\\theta(t_0)}\\neq0$, it must be that $\\zeta(\\tfrac{1}{2}+it_0)=0$. So $s_0 = \\tfrac{1}{2}+it_0$ is a zero.\nTo check its multiplicity, we differentiate $Z(t)$ with respect to $t$ using the product and chain rules:\n$$Z'(t) = \\frac{d}{dt}\\left(e^{i\\theta(t)}\\right)\\zeta(\\tfrac{1}{2}+it) + e^{i\\theta(t)}\\frac{d}{dt}\\left(\\zeta(\\tfrac{1}{2}+it)\\right)$$\n$$Z'(t) = i\\theta'(t)e^{i\\theta(t)}\\zeta(\\tfrac{1}{2}+it) + e^{i\\theta(t)}\\left(i\\zeta'(\\tfrac{1}{2}+it)\\right)$$\nNow we evaluate this expression at $t=t_0$. Since $\\zeta(\\tfrac{1}{2}+it_0)=0$, the first term vanishes:\n$$Z'(t_0) = i\\theta'(t_0)e^{i\\theta(t_0)}(0) + ie^{i\\theta(t_0)}\\zeta'(\\tfrac{1}{2}+it_0) = ie^{i\\theta(t_0)}\\zeta'(\\tfrac{1}{2}+it_0)$$\nWe are given that $Z'(t_0) \\neq 0$. The factor $i$ is non-zero, and the factor $e^{i\\theta(t_0)}$ is also non-zero. Therefore, it must be that $\\zeta'(\\tfrac{1}{2}+it_0) \\neq 0$.\nThe conditions $\\zeta(\\tfrac{1}{2}+it_0)=0$ and $\\zeta'(\\tfrac{1}{2}+it_0)\\neq 0$ are precisely the definition of a simple zero at $s_0 = \\tfrac{1}{2}+it_0$.\n\n**Verdict: Correct.**\n\n**F. By combining a count of sign changes of $Z(t)$ on $[0,T]$ with the Riemann–von Mangoldt formula for $N(T)$ (the number of zeros $\\rho=\\beta+i\\gamma$ with $0\\gamma\\le T$) and explicit bounds for the argument function $S(T)$, one can certify that all zeros with $0\\Im(s)\\le T$ lie on the critical line $\\operatorname{Re}(s)=\\tfrac{1}{2}$.**\n\nThis statement describes what is known as Turing's method, a valid strategy to verify the Riemann Hypothesis up to a certain height $T$. The method proceeds as follows:\n1.  The Riemann–von Mangoldt formula, in its precise form $N(T) = \\frac{\\theta(T)}{\\pi} + 1 + S(T)$, relates the total number of zeros $N(T)$ in the critical strip $0  \\operatorname{Re}(s)  1, 0  \\Im(s) \\le T$ to the function $\\theta(T)$ and the argument function $S(T) = \\frac{1}{\\pi}\\arg\\zeta(\\tfrac{1}{2}+iT)$.\n2.  By computing $\\theta(T)$ and using rigorous numerical bounds on $S(T)$ (e.g., $|S(T)| \\le C$ for some constant $C$), one can often determine the exact integer value of $N(T)$.\n3.  Separately, one conducts a search for zeros on the critical line in the interval $(0, T]$. This involves finding sign changes of $Z(t)$ and also carefully checking for missed zeros (e.g., pairs of zeros or multiple zeros). This process can be made rigorous, yielding a certified count $N_{0, \\text{found}}$ of zeros on the critical line, such that $N_0(T) \\ge N_{0, \\text{found}}$.\n4.  If the search is successful and one finds $N_{0, \\text{found}} \\ge N(T)$, since we know that the number of zeros on the line, $N_0(T)$, cannot exceed the total number of zeros in the strip, $N(T)$, we must have $N_0(T) = N(T)$.\nThis proves that all $N(T)$ zeros in the strip for $0  \\Im(s) \\le T$ are in fact on the critical line. The statement correctly asserts that this certification is possible by combining these tools.\n\n**Verdict: Correct.**\n\n**G. Since $\\theta(t)$ is strictly increasing for all sufficiently large $t$, each Gram interval contains exactly one zero of $\\zeta\\!\\left(\\tfrac{1}{2}+it\\right)$.**\n\nThis statement is known as Gram's Law. Gram points $g_n$ are defined by $\\theta(g_n) = n\\pi$ for an integer $n$. A Gram interval is an interval $[g_n, g_{n+1})$. The premise that $\\theta(t)$ is strictly increasing for large $t$ is correct and ensures the Gram points are well-defined and ordered. However, the conclusion that each Gram interval contains *exactly one* zero is false. While Gram's Law is a useful heuristic that holds for a large proportion of intervals, it is known to fail infinitely often. The first failure occurs for the interval $[g_{126}, g_{127})$, which contains no zero. This is compensated by the preceding interval containing two zeros. Therefore, this is not a generally true statement.\n\n**Verdict: Incorrect.**\n\nSummary of correct statements: A, C, E, F.", "answer": "$$\\boxed{ACEF}$$", "id": "3029124"}]}