{"hands_on_practices": [{"introduction": "Before tackling high-degree polynomials, mastering the linear case $f(n) = \\alpha n$ is essential. This exercise [@problem_id:3014067] grounds our understanding by deriving the value of a linear exponential sum from first principles as a geometric series. The result cleanly illustrates the fundamental concept of complete cancellation over a full period, a phenomenon that lies at the heart of more advanced differencing techniques.", "problem": "Let $a$ and $q$ be integers with $q \\geq 1$, and let $N$ be a positive integer. Consider the exponential sum\n$$\nS(N;a,q) \\;=\\; \\sum_{n=1}^{N} \\exp\\!\\left(2\\pi i \\frac{a n}{q}\\right).\n$$\nStarting from the fundamental definitions of exponential sums and the basic properties of geometric progressions, derive an exact closed-form expression for $S(N;a,q)$ without invoking any pre-stated summation formulas. Express your final answer in terms of elementary functions. Then, using only first principles (periodicity of complex exponentials and divisibility in the integers), deduce the necessary and sufficient conditions on $N$ under which $S(N;a,q)=0$ in the nontrivial case $q \\nmid a$. Finally, briefly explain how the vanishing condition you obtain reflects the type of cancellation exploited by Weyl differencing in the analysis of exponential sums with linear phases.\n\nYour final boxed answer must be the exact analytic expression for $S(N;a,q)$ in the case $q \\nmid a$. No rounding is required. Do not include any text or conditions inside the final boxed expression.", "solution": "We begin from the definition of the sum\n$$\nS(N;a,q) \\;=\\; \\sum_{n=1}^{N} \\exp\\!\\left(2\\pi i \\frac{a n}{q}\\right).\n$$\nLet\n$$\nr \\;=\\; \\exp\\!\\left(2\\pi i \\frac{a}{q}\\right).\n$$\nThen $S(N;a,q)$ is the finite geometric progression\n$$\nS(N;a,q) \\;=\\; \\sum_{n=1}^{N} r^{n}.\n$$\nWe do not invoke any ready-made geometric series formula; instead we derive it directly. Consider\n$$\n(1-r)\\,S(N;a,q) \\;=\\; \\sum_{n=1}^{N} r^{n} - \\sum_{n=1}^{N} r^{n+1}.\n$$\nThe right-hand side telescopes:\n$$\n\\sum_{n=1}^{N} r^{n} - \\sum_{n=1}^{N} r^{n+1}\n\\;=\\;\nr + r^{2} + \\cdots + r^{N} \\;-\\; r^{2} - r^{3} - \\cdots - r^{N+1}\n\\;=\\; r - r^{N+1}.\n$$\nTherefore,\n$$\n(1-r)\\,S(N;a,q) \\;=\\; r - r^{N+1},\n$$\nand when $r \\neq 1$ we have\n$$\nS(N;a,q) \\;=\\; \\frac{r - r^{N+1}}{1 - r} \\;=\\; r\\,\\frac{1-r^{N}}{1-r}.\n$$\nWe now express this in terms of real-valued elementary functions. Write $r=\\exp(i\\theta)$ with $\\theta = 2\\pi a/q$. Then\n$$\nS(N;a,q) \\;=\\; \\exp(i\\theta)\\,\\frac{1-\\exp(iN\\theta)}{1-\\exp(i\\theta)}.\n$$\nUse the identity\n$$\n1-\\exp(i\\phi) \\;=\\; \\exp\\!\\left(\\frac{i\\phi}{2}\\right)\\left(\\exp\\!\\left(-\\frac{i\\phi}{2}\\right)-\\exp\\!\\left(\\frac{i\\phi}{2}\\right)\\right)\n\\;=\\; -2i\\,\\exp\\!\\left(\\frac{i\\phi}{2}\\right)\\sin\\!\\left(\\frac{\\phi}{2}\\right),\n$$\napplied to $\\phi=N\\theta$ and $\\phi=\\theta$. Then\n$$\n\\frac{1-\\exp(iN\\theta)}{1-\\exp(i\\theta)}\n\\;=\\;\n\\frac{-2i\\,\\exp\\!\\left(\\frac{iN\\theta}{2}\\right)\\sin\\!\\left(\\frac{N\\theta}{2}\\right)}{-2i\\,\\exp\\!\\left(\\frac{i\\theta}{2}\\right)\\sin\\!\\left(\\frac{\\theta}{2}\\right)}\n\\;=\\;\n\\exp\\!\\left(\\frac{i(N\\theta-\\theta)}{2}\\right)\\,\\frac{\\sin\\!\\left(\\frac{N\\theta}{2}\\right)}{\\sin\\!\\left(\\frac{\\theta}{2}\\right)}.\n$$\nMultiplying by $\\exp(i\\theta)$ yields\n$$\nS(N;a,q)\n\\;=\\;\n\\exp(i\\theta)\\,\\exp\\!\\left(\\frac{i(N\\theta-\\theta)}{2}\\right)\\,\\frac{\\sin\\!\\left(\\frac{N\\theta}{2}\\right)}{\\sin\\!\\left(\\frac{\\theta}{2}\\right)}\n\\;=\\;\n\\exp\\!\\left(\\frac{i(N+1)\\theta}{2}\\right)\\,\\frac{\\sin\\!\\left(\\frac{N\\theta}{2}\\right)}{\\sin\\!\\left(\\frac{\\theta}{2}\\right)}.\n$$\nSubstituting $\\theta=2\\pi a/q$ gives the exact closed form\n$$\nS(N;a,q)\n\\;=\\;\n\\exp\\!\\left(\\pi i \\frac{a(N+1)}{q}\\right)\\,\\frac{\\sin\\!\\left(\\pi \\frac{aN}{q}\\right)}{\\sin\\!\\left(\\pi \\frac{a}{q}\\right)},\n$$\nprovided $r \\neq 1$, i.e., $q \\nmid a$. In the complementary case $q \\mid a$, we have $r=\\exp(2\\pi i \\cdot \\text{integer})=1$, so $S(N;a,q)=N$ trivially from the definition.\n\nWe now deduce the vanishing condition in the nontrivial case $q \\nmid a$. From the closed form,\n$$\nS(N;a,q)=0\n\\quad\\Longleftrightarrow\\quad\n\\sin\\!\\left(\\pi \\frac{aN}{q}\\right)=0,\n$$\nsince the denominator $\\sin\\!\\left(\\pi \\frac{a}{q}\\right)\\neq 0$ when $q \\nmid a$. The equality $\\sin(\\pi x)=0$ holds if and only if $x\\in\\mathbb{Z}$. Therefore,\n$$\n\\sin\\!\\left(\\pi \\frac{aN}{q}\\right)=0\n\\quad\\Longleftrightarrow\\quad\n\\frac{aN}{q}\\in\\mathbb{Z}\n\\quad\\Longleftrightarrow\\quad\nq \\mid aN.\n$$\nLet $d=\\gcd(a,q)$. Then $aN$ is divisible by $q$ if and only if $\\frac{q}{d}$ divides $N$. Thus,\n$$\nS(N;a,q)=0\n\\quad\\Longleftrightarrow\\quad\n\\frac{q}{\\gcd(a,q)} \\mid N,\n\\qquad \\text{when } q \\nmid a.\n$$\nThis condition exhibits exact cancellation over one full period of the linear phase $\\exp(2\\pi i a n/q)$, whose period length is $\\frac{q}{\\gcd(a,q)}$: summing a full number of periods yields zero. This cancellation principle underlies Weyl differencing for linear phases: discrete differencing with step size $h=\\frac{q}{\\gcd(a,q)}$ yields\n$$\n\\exp\\!\\left(2\\pi i \\frac{a(n+h)}{q}\\right) - \\exp\\!\\left(2\\pi i \\frac{a n}{q}\\right)\n\\;=\\;\n\\exp\\!\\left(2\\pi i \\frac{a n}{q}\\right)\\left(\\exp\\!\\left(2\\pi i \\frac{a h}{q}\\right)-1\\right)\n\\;=\\; 0,\n$$\nsince $\\exp\\!\\left(2\\pi i \\frac{a h}{q}\\right)=\\exp\\!\\left(2\\pi i \\frac{a}{\\gcd(a,q)}\\right)=1$. The exact vanishing of the discrete difference at this step size reflects the periodic structure exploited by Weyl differencing to obtain cancellation in exponential sums with linear phases.", "answer": "$$\\boxed{\\exp\\!\\left(\\pi i \\frac{a(N+1)}{q}\\right)\\,\\frac{\\sin\\!\\left(\\pi \\frac{aN}{q}\\right)}{\\sin\\!\\left(\\pi \\frac{a}{q}\\right)}}$$", "id": "3014067"}, {"introduction": "Quadratic Gauss sums represent a classic and pivotal example in the theory of exponential sums. This exercise [@problem_id:3014046] demonstrates the power of Weyl's method by applying it to a quadratic phase, reducing the problem to a sum over a linear phase. This process uncovers the celebrated \"square-root cancellation,\" a profound improvement over trivial bounds and a benchmark for what can be achieved with these methods.", "problem": "Let $a$ and $q$ be integers with $\\gcd(a,q)=1$. Define the complete quadratic Gauss sum\n$$G(a,q) \\;=\\; \\sum_{n=0}^{q-1} \\exp\\!\\left(\\frac{2\\pi i\\, a n^{2}}{q}\\right).$$\nStarting from the orthogonality of additive characters modulo $q$, the structure of quadratic residues modulo prime powers, and the Chinese Remainder Theorem (CRT), derive an explicit closed-form evaluation of $G(a,q)$ in the case $q$ odd, expressed in terms of the Jacobi symbol $\\left(\\frac{a}{q}\\right)$. Then, using Weyl differencing (the van der Corput method) applied to the quadratic phase $\\frac{a n^{2}}{q}$, obtain a sharp square-root law for the magnitude $|G(a,q)|$ that depends explicitly on the parity class of $q$. Your final answer must be a single analytical expression, possibly piecewise, and contain no inequalities or equations other than what is necessary to specify the expression. If you choose to present more than one component (for example, the explicit evaluation and the magnitude law), organize them as a single row matrix using the LaTeX pmatrix environment. No numerical approximation is required.", "solution": "The problem asks for an explicit evaluation of the quadratic Gauss sum $G(a,q)$ for odd integers $q$, and for a determination of its magnitude $|G(a,q)|$ for any integer $q$ using Weyl differencing. We are given $\\gcd(a,q)=1$. The Gauss sum is defined as\n$$G(a,q) = \\sum_{n=0}^{q-1} \\exp\\left(\\frac{2\\pi i a n^{2}}{q}\\right).$$\n\nFirst, we derive the closed-form expression for $G(a,q)$ when $q$ is an odd positive integer. This derivation proceeds in two main steps: relating $G(a,q)$ to $G(1,q)$ and then evaluating $G(1,q)$.\n\n**Step 1: Relation between $G(a,q)$ and $G(1,q)$ for odd $q$**\n\nWe will prove that for any odd integer $q>0$ and any integer $a$ with $\\gcd(a,q)=1$, the following relation holds:\n$$G(a,q) = \\left(\\frac{a}{q}\\right) G(1,q),$$\nwhere $\\left(\\frac{a}{q}\\right)$ is the Jacobi symbol. The proof is by induction on the number of prime factors of $q$.\n\nBase Case: $q=p$, an odd prime.\nThe number of solutions to the congruence $x^2 \\equiv r \\pmod p$ is $1 + \\left(\\frac{r}{p}\\right)$. We can rewrite the sum for $G(a,p)$ by grouping terms with the same value of $n^2 \\pmod p$:\n$$G(a,p) = \\sum_{n=0}^{p-1} \\exp\\left(\\frac{2\\pi i a n^2}{p}\\right) = \\sum_{r=0}^{p-1} \\left(1 + \\left(\\frac{r}{p}\\right)\\right) \\exp\\left(\\frac{2\\pi i a r}{p}\\right).$$\nThis separates into two sums:\n$$G(a,p) = \\sum_{r=0}^{p-1} \\exp\\left(\\frac{2\\pi i a r}{p}\\right) + \\sum_{r=0}^{p-1} \\left(\\frac{r}{p}\\right) \\exp\\left(\\frac{2\\pi i a r}{p}\\right).$$\nThe first sum is over a complete set of residues modulo $p$. Since $\\gcd(a,p)=1$, the terms $ar$ also form a complete set of residues. The sum of all $p$-th roots of unity is zero, so $\\sum_{r=0}^{p-1} \\exp\\left(\\frac{2\\pi i a r}{p}\\right) = 0$.\nThe second sum is a Gauss sum for the Legendre character $\\chi(r) = \\left(\\frac{r}{p}\\right)$. Let's denote it $\\tau(\\chi, a)$. With a change of variables $s=ar$, so $r=a^{-1}s$ where $a^{-1}$ is the multiplicative inverse of $a$ modulo $p$, we have:\n$$\\sum_{r=0}^{p-1} \\left(\\frac{r}{p}\\right) \\exp\\left(\\frac{2\\pi i a r}{p}\\right) = \\sum_{s=0}^{p-1} \\left(\\frac{a^{-1}s}{p}\\right) \\exp\\left(\\frac{2\\pi i s}{p}\\right) = \\left(\\frac{a^{-1}}{p}\\right) \\sum_{s=0}^{p-1} \\left(\\frac{s}{p}\\right) \\exp\\left(\\frac{2\\pi i s}{p}\\right).$$\nSince $\\left(\\frac{a^{-1}}{p}\\right) = \\left(\\frac{a}{p}\\right)$, this becomes $\\left(\\frac{a}{p}\\right) \\sum_{s=0}^{p-1} \\left(\\frac{s}{p}\\right) \\exp\\left(\\frac{2\\pi i s}{p}\\right)$. By the same logic as above, this final sum is precisely $G(1,p)$. Thus, for $q=p$, we have established $G(a,p) = \\left(\\frac{a}{p}\\right)G(1,p)$.\n\nInductive Step: Let $q=q_1 q_2$ where $q_1, q_2 > 1$ are coprime odd integers. Assume the formula holds for $q_1$ and $q_2$. By the Chinese Remainder Theorem, as $n_1$ and $n_2$ run through complete residue systems modulo $q_1$ and $q_2$ respectively, $n=n_1q_2+n_2q_1$ runs through a complete residue system modulo $q=q_1q_2$.\n$$a n^2 = a(n_1q_2+n_2q_1)^2 = a n_1^2 q_2^2 + a n_2^2 q_1^2 + 2an_1n_2q_1q_2.$$\nDividing by $q=q_1q_2$, we get $\\frac{an^2}{q} = \\frac{an_1^2q_2}{q_1} + \\frac{an_2^2q_1}{q_2} + 2an_1n_2$. The last term is an integer. Thus,\n$$G(a,q) = \\sum_{n_1=0}^{q_1-1} \\sum_{n_2=0}^{q_2-1} \\exp\\left(\\frac{2\\pi i a q_2 n_1^2}{q_1}\\right) \\exp\\left(\\frac{2\\pi i a q_1 n_2^2}{q_2}\\right) = G(aq_2, q_1) G(aq_1, q_2).$$\nBy the inductive hypothesis and properties of the Jacobi symbol:\n$$G(aq_2, q_1) = \\left(\\frac{aq_2}{q_1}\\right) G(1,q_1) = \\left(\\frac{a}{q_1}\\right)\\left(\\frac{q_2}{q_1}\\right) G(1,q_1).$$\n$$G(aq_1, q_2) = \\left(\\frac{aq_1}{q_2}\\right) G(1,q_2) = \\left(\\frac{a}{q_2}\\right)\\left(\\frac{q_1}{q_2}\\right) G(1,q_2).$$\nMultiplying these gives:\n$$G(a,q) = \\left(\\frac{a}{q_1}\\right)\\left(\\frac{a}{q_2}\\right) \\left(\\frac{q_2}{q_1}\\right)\\left(\\frac{q_1}{q_2}\\right) G(1,q_1)G(1,q_2) = \\left(\\frac{a}{q}\\right) \\left(\\left(\\frac{q_2}{q_1}\\right)\\left(\\frac{q_1}{q_2}\\right) G(1,q_1)G(1,q_2)\\right).$$\nBy the same logic, applying the multiplicative formula to $G(1,q)$:\n$$G(1,q) = G(q_2, q_1)G(q_1, q_2) = \\left(\\frac{q_2}{q_1}\\right)G(1,q_1) \\left(\\frac{q_1}{q_2}\\right)G(1,q_2).$$\nComparing the two expressions, we see that $G(a,q) = \\left(\\frac{a}{q}\\right)G(1,q)$. This completes the induction.\n\n**Step 2: Evaluation of $G(1,q)$ for odd $q$**\n\nIt is a classical result established by Gauss that for an odd prime $p$,\n$$G(1,p) = \\begin{cases} \\sqrt{p} & \\text{if } p \\equiv 1 \\pmod 4 \\\\ i\\sqrt{p} & \\text{if } p \\equiv 3 \\pmod 4 \\end{cases}.$$\nWe now extend this to any odd composite $q$ by induction. Let $q=q_1q_2$ with $\\gcd(q_1,q_2)=1$. We use the formula derived above:\n$$G(1,q) = \\left(\\frac{q_2}{q_1}\\right)\\left(\\frac{q_1}{q_2}\\right)G(1,q_1)G(1,q_2).$$\nBy the law of quadratic reciprocity, for odd coprime $q_1, q_2$, we have $\\left(\\frac{q_2}{q_1}\\right)\\left(\\frac{q_1}{q_2}\\right) = (-1)^{\\frac{q_1-1}{2}\\frac{q_2-1}{2}}$.\nLet's assume the formula holds for $q_1, q_2$.\nIf $q_1 \\equiv 1 \\pmod 4$, then $\\frac{q_1-1}{2}$ is even, so the reciprocity factor is $1$. Then $G(1,q)=G(1,q_1)G(1,q_2)$. With $G(1,q_1)=\\sqrt{q_1}$, we get $G(1,q)=\\sqrt{q_1}G(1,q_2)$. Since $q=q_1q_2 \\equiv q_2 \\pmod 4$, this case is consistent.\nIf $q_1 \\equiv 3 \\pmod 4$ and $q_2 \\equiv 3 \\pmod 4$, then $\\frac{q_1-1}{2}$ and $\\frac{q_2-1}{2}$ are both odd, so the reciprocity factor is $-1$. And $q=q_1q_2 \\equiv 9 \\equiv 1 \\pmod 4$.\n$G(1,q) = (-1) G(1,q_1)G(1,q_2) = (-1)(i\\sqrt{q_1})(i\\sqrt{q_2}) = (-1)(i^2)\\sqrt{q_1q_2} = \\sqrt{q}$. This is consistent with $q \\equiv 1 \\pmod 4$.\nA systematic check of all cases ($q_1, q_2 \\pmod 4$) confirms the general formula:\n$$G(1,q) = \\begin{cases} \\sqrt{q} & \\text{if } q \\equiv 1 \\pmod 4 \\\\ i\\sqrt{q} & \\text{if } q \\equiv 3 \\pmod 4 \\end{cases}.$$\nCombining these results, the explicit formula for $G(a,q)$ for odd $q$ is:\n$$G(a,q) = \\left(\\frac{a}{q}\\right) \\begin{cases} \\sqrt{q} & \\text{if } q \\equiv 1 \\pmod 4 \\\\ i\\sqrt{q} & \\text{if } q \\equiv 3 \\pmod 4 \\end{cases}.$$\n\n**Derivation of $|G(a,q)|$ using Weyl Differencing**\n\nNext, we apply Weyl differencing (also known as the van der Corput method) to find the magnitude $|G(a,q)|$. We consider the square of the magnitude:\n$$|G(a,q)|^2 = \\left(\\sum_{n=0}^{q-1} \\exp\\left(\\frac{2\\pi i a n^2}{q}\\right)\\right) \\left(\\sum_{m=0}^{q-1} \\exp\\left(-\\frac{2\\pi i a m^2}{q}\\right)\\right) = \\sum_{n=0}^{q-1} \\sum_{m=0}^{q-1} \\exp\\left(\\frac{2\\pi i a (n^2-m^2)}{q}\\right).$$\nLet $n=m+h$, where $h$ also runs over a complete residue system modulo $q$.\n$$|G(a,q)|^2 = \\sum_{m=0}^{q-1} \\sum_{h=0}^{q-1} \\exp\\left(\\frac{2\\pi i a ((m+h)^2 - m^2)}{q}\\right) = \\sum_{m=0}^{q-1} \\sum_{h=0}^{q-1} \\exp\\left(\\frac{2\\pi i a (2mh+h^2)}{q}\\right).$$\nWe can interchange the order of summation:\n$$|G(a,q)|^2 = \\sum_{h=0}^{q-1} \\exp\\left(\\frac{2\\pi i a h^2}{q}\\right) \\left(\\sum_{m=0}^{q-1} \\exp\\left(\\frac{2\\pi i (2ah)m}{q}\\right)\\right).$$\nThe inner sum is a geometric series of roots of unity. It equals $q$ if $2ah \\equiv 0 \\pmod q$ and $0$ otherwise.\nSince we are given $\\gcd(a,q)=1$, this condition simplifies to $2h \\equiv 0 \\pmod q$. We analyze this based on the parity of $q$.\n\nCase 1: $q$ is odd.\nSince $\\gcd(2,q)=1$, the congruence $2h \\equiv 0 \\pmod q$ implies $h \\equiv 0 \\pmod q$. In the range $0 \\le h < q$, the only solution is $h=0$.\nFor $h=0$, the inner sum is $q$ and the outer exponential term is $\\exp(0)=1$. All other terms for $h \\ne 0$ are zero.\nTherefore, for odd $q$: $$|G(a,q)|^2 = 1 \\cdot q = q \\implies |G(a,q)| = \\sqrt{q}.$$\n\nCase 2: $q$ is even.\nLet $q=2k$ for some integer $k$. The congruence becomes $2h \\equiv 0 \\pmod{2k}$, which is equivalent to $h \\equiv 0 \\pmod k$.\nThe solutions for $h$ in the range $0 \\le h < q=2k$ are $h=0$ and $h=k=q/2$.\nThe sum for $|G(a,q)|^2$ has two non-zero terms:\n$$|G(a,q)|^2 = \\exp\\left(\\frac{2\\pi i a \\cdot 0^2}{q}\\right) \\cdot q + \\exp\\left(\\frac{2\\pi i a (q/2)^2}{q}\\right) \\cdot q$$\n$$|G(a,q)|^2 = q \\left(1 + \\exp\\left(\\frac{2\\pi i a q^2}{4q}\\right)\\right) = q \\left(1 + \\exp\\left(\\frac{\\pi i a q}{2}\\right)\\right).$$\nWe analyze this further based on $q \\pmod 4$. Since $\\gcd(a,q)=1$ and $q$ is even, $a$ must be odd.\n\nSubcase 2a: $q \\equiv 2 \\pmod 4$.\nThis means $q = 4m+2$ for some integer $m$. Then $q/2 = 2m+1$ is odd.\n$$|G(a,q)|^2 = q \\left(1 + \\exp\\left(\\frac{\\pi i a (4m+2)}{2}\\right)\\right) = q \\left(1 + \\exp(\\pi i a (2m+1))\\right).$$\nSince $a$ and $2m+1$ are both odd, their product is odd. Thus $\\exp(\\pi i \\cdot \\text{odd}) = -1$.\n$$|G(a,q)|^2 = q(1-1) = 0 \\implies |G(a,q)| = 0.$$\n\nSubcase 2b: $q \\equiv 0 \\pmod 4$.\nThis means $q=4m$ for some integer $m$. Then $q/2 = 2m$ is even.\n$$|G(a,q)|^2 = q \\left(1 + \\exp\\left(\\frac{\\pi i a (4m)}{2}\\right)\\right) = q \\left(1 + \\exp(2\\pi i am)\\right).$$\nSince $am$ is an integer, $\\exp(2\\pi i am) = 1$.\n$$|G(a,q)|^2 = q(1+1) = 2q \\implies |G(a,q)| = \\sqrt{2q}.$$\n\nIn summary, the sharp square-root law for the magnitude $|G(a,q)|$ is:\n$$|G(a,q)| = \\begin{cases} \\sqrt{q} & \\text{if } q \\text{ is odd} \\\\ 0 & \\text{if } q \\equiv 2 \\pmod 4 \\\\ \\sqrt{2q} & \\text{if } q \\equiv 0 \\pmod 4 \\end{cases}.$$\n\nAssembling the final answer as requested, we combine the evaluation for odd $q$ and the general magnitude law.\nFor odd $q$, let $\\epsilon_q = 1$ if $q \\equiv 1 \\pmod 4$ and $\\epsilon_q = i$ if $q \\equiv 3 \\pmod 4$. The explicit evaluation is $G(a,q) = \\left(\\frac{a}{q}\\right) \\epsilon_q \\sqrt{q}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nG(a,q) = \\left(\\frac{a}{q}\\right)\\sqrt{q} \\times \\begin{cases} 1 & \\text{if } q \\equiv 1 \\pmod{4} \\\\ i & \\text{if } q \\equiv 3 \\pmod{4} \\end{cases} \\text{ for odd } q\n&\n|G(a,q)| = \\begin{cases} \\sqrt{q} & \\text{if } q \\text{ is odd} \\\\ 0 & \\text{if } q \\equiv 2 \\pmod{4} \\\\ \\sqrt{2q} & \\text{if } q \\equiv 0 \\pmod{4} \\end{cases}\n\\end{pmatrix}\n}\n$$", "id": "3014046"}, {"introduction": "Applying the Weyl differencing technique effectively is an art that involves optimizing its parameters. This problem [@problem_id:3014036] delves into the strategic heart of the method, asking you to determine the optimal choice for the differencing length $H$ in the van der Corput inequality. By balancing the terms in the inequality, you will develop a deeper intuition for how these powerful bounds are derived and sharpened in practice.", "problem": "Let $N \\in \\mathbb{N}$ be large and let $f:[1,N] \\to \\mathbb{R}$ be twice continuously differentiable. Define the exponential sum $S(N)$ by\n$$\nS(N) \\;=\\; \\sum_{n=1}^{N} \\exp\\!\\big(2\\pi i\\, f(n)\\big),\n$$\nand for $h \\in \\{1,2,\\dots,N-1\\}$ define the first Weyl difference sum\n$$\nS_h(N) \\;=\\; \\sum_{n=1}^{N-h} \\exp\\!\\big(2\\pi i\\, \\big(f(n+h)-f(n)\\big)\\big).\n$$\nAssume that the second derivative $f''$ is nondecreasing on $[1,N]$ and satisfies $f''(x) \\ge \\lambda_2$ for all $x\\in[1,N]$, with $0 < \\lambda_2 \\le 1$.\n\nA standard form of the van der Corput inequality (also known as Weyl differencing) yields, for any integer $H$ with $1 \\le H \\le N$,\n$$\n|S(N)|^{2} \\;\\ll\\; N H^{-1} \\;+\\; \\sum_{h=1}^{H} |S_h(N)|,\n$$\nwhere the implied constant may depend on $f$ but is independent of $N$ and $H$. Using only the above structural assumptions and well-tested facts such as the First Derivative Test (FDT) for exponential sums, set up and solve the optimization problem to choose $H$ as a function of $N$ and $\\lambda_2$ so as to minimize the right-hand side up to constant factors.\n\nYour final answer must be a single closed-form analytic expression for the optimal choice $H$ in terms of $N$ and $\\lambda_2$ (with $0 < \\lambda_2 \\le 1$).", "solution": "The user wants me to solve an optimization problem related to the Weyl differencing method for exponential sums.\n\n### Step 1: Extract Givens\n-   The exponential sum is defined as $S(N) = \\sum_{n=1}^{N} \\exp(2\\pi i f(n))$ for a large integer $N$.\n-   The function $f:[1,N] \\to \\mathbb{R}$ is twice continuously differentiable.\n-   The first Weyl difference sum is defined as $S_h(N) = \\sum_{n=1}^{N-h} \\exp(2\\pi i (f(n+h)-f(n)))$ for $h \\in \\{1,2,\\dots,N-1\\}$.\n-   The second derivative $f''(x)$ is nondecreasing on $[1,N]$.\n-   There is a constant $\\lambda_2$ such that $0 < \\lambda_2 \\le 1$ and $f''(x) \\ge \\lambda_2$ for all $x \\in [1,N]$.\n-   The van der Corput inequality is given as $|S(N)|^{2} \\ll N H^{-1} + \\sum_{h=1}^{H} |S_h(N)|$ for any integer $H$ with $1 \\le H \\le N$. The implied constant is independent of $N$ and $H$.\n-   The task is to choose $H$ as a function of $N$ and $\\lambda_2$ to minimize the right-hand side of the inequality, up to constant factors, using facts like the First Derivative Test (FDT) for exponential sums.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is rooted in analytic number theory, specifically the theory of exponential sums. The concepts of Weyl differencing, the van der Corput inequality, and the First Derivative Test are standard and well-established. The assumptions on the function $f(x)$ are typical for such problems. The problem is scientifically and mathematically sound.\n-   **Well-Posed**: The problem provides a clear objective: to minimize a given expression with respect to one of its parameters, $H$. The constraints on the parameters are given. The problem is structured to admit a unique solution for the optimal $H$ (in the sense of its functional dependence on $N$ and $\\lambda_2$).\n-   **Objective**: The problem is stated using precise mathematical definitions and language. There are no subjective or ambiguous terms.\n-   **Conclusion**: The problem is valid. It is a standard exercise in the application of exponential sum theory.\n\n### Step 3: Proceed with Solution\n\nThe objective is to minimize the expression on the right-hand side of the given inequality, which we denote by $E(H)$:\n$$\nE(H) = N H^{-1} + \\sum_{h=1}^{H} |S_h(N)|\n$$\nTo do this, we first need to estimate the magnitude of the inner sums $|S_h(N)|$. The problem directs us to use the First Derivative Test (FDT) for exponential sums. The sum $S_h(N)$ is an exponential sum with phase function $g_h(n) = f(n+h) - f(n)$.\n\nThe FDT (also known as the Kusmin-Landau theorem) states that for a real-valued function $F(x)$, if its derivative $F'(x)$ is monotonic and satisfies $|F'(x)| \\ge \\delta > 0$ on an interval $[a,b]$, then\n$$\n\\left| \\sum_{n=a}^{b} \\exp(2\\pi i F(n)) \\right| \\ll \\frac{1}{\\delta}\n$$\nwhere the implied constant is absolute.\n\nLet's analyze the derivative of our phase function $g_h(x) = f(x+h) - f(x)$. Its derivative with respect to $x$ is:\n$$\ng_h'(x) = f'(x+h) - f'(x)\n$$\nBy the Mean Value Theorem, there exists a $c \\in (x, x+h)$ such that:\n$$\ng_h'(x) = h \\cdot f''(c)\n$$\nWe are given that $f''(y) \\ge \\lambda_2$ for all $y \\in [1,N]$. Therefore, for $h \\ge 1$:\n$$\ng_h'(x) \\ge h \\lambda_2\n$$\nSo, we can set $\\delta = h \\lambda_2$. For the FDT, we also need to check the monotonicity of $g_h'(x)$. We examine its derivative, which is the second derivative of $g_h(x)$:\n$$\ng_h''(x) = f''(x+h) - f''(x)\n$$\nWe are given that $f''$ is nondecreasing, which means $f''(x+h) \\ge f''(x)$ for $h>0$. Thus, $g_h''(x) \\ge 0$. This implies that $g_h'(x)$ is nondecreasing, so it is monotonic.\n\nThe conditions for the FDT are satisfied for each sum $S_h(N)$. Applying the test, we obtain the bound:\n$$\n|S_h(N)| \\ll \\frac{1}{h \\lambda_2}\n$$\nNow, we substitute this bound into the expression for $E(H)$:\n$$\nE(H) \\ll N H^{-1} + \\sum_{h=1}^{H} \\frac{1}{h \\lambda_2} = N H^{-1} + \\frac{1}{\\lambda_2} \\sum_{h=1}^{H} \\frac{1}{h}\n$$\nThe sum is the $H$-th harmonic number, which for large $H$ has the well-known asymptotic behavior:\n$$\n\\sum_{h=1}^{H} \\frac{1}{h} = \\ln(H) + \\gamma + O(H^{-1})\n$$\nwhere $\\gamma$ is the Euler-Mascheroni constant.\n\nSince we are minimizing \"up to constant factors\", we can ignore the constant $\\gamma$ and the lower-order terms, and focus on the principal terms that depend on $H$. Let $K$ be a constant representing the product of the implied constant from the FDT and any other constants. The function to minimize with respect to $H$ is of the form:\n$$\nF(H) = N H^{-1} + \\frac{K}{\\lambda_2} \\ln(H)\n$$\nTo find the minimum, we treat $H$ as a continuous variable and differentiate $F(H)$ with respect to $H$, setting the derivative to zero:\n$$\n\\frac{dF}{dH} = -N H^{-2} + \\frac{K}{\\lambda_2} H^{-1} = 0\n$$\n$$\n\\frac{N}{H^2} = \\frac{K}{\\lambda_2 H}\n$$\nSolving for $H$, we find:\n$$\nH = \\frac{N \\lambda_2}{K}\n$$\nThe problem asks for the optimal choice of $H$ as a function of $N$ and $\\lambda_2$ \"up to constant factors\". This means we can disregard the unknown constant $K$. The optimal choice for $H$ is therefore directly proportional to $N \\lambda_2$. We can express this by setting the constant of proportionality to $1$. The constraints $1 \\le H \\le N$ are satisfied for large $N$ since $0 < \\lambda_2 \\le 1$ implies $0 < N\\lambda_2 \\le N$, and $N\\lambda_2$ will be greater than $1$ unless $\\lambda_2$ is exceptionally small (less than $1/N$).\n\nThus, the optimal choice for $H$ that minimizes the right-hand side of the inequality up to constant factors is:\n$$\nH = N \\lambda_2\n$$", "answer": "$$\\boxed{N \\lambda_2}$$", "id": "3014036"}]}