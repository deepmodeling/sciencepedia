{"hands_on_practices": [{"introduction": "The Kato inequality provides a fundamental pointwise estimate relating the gradient of the norm of a differential form to the norm of its covariant derivative. This first practice establishes the inequality in the foundational setting of a $1$-form on Euclidean space. By working through the proof from first principles, you will see how the geometric statement translates into a direct application of the Cauchy-Schwarz inequality in coordinates, building a core competency for tackling more complex geometric estimates. [@problem_id:3031617]", "problem": "Let $\\mathbb{R}^{n}$ be equipped with the standard Euclidean metric and Levi-Civita connection. For a smooth $1$-form $\\omega=\\sum_{i=1}^{n} a_{i}(x)\\,dx^{i}$ with compact support, define the pointwise norm $|\\omega|=\\left(\\sum_{i=1}^{n} a_{i}^{2}\\right)^{1/2}$, the covariant derivative $\\nabla\\omega$ by $(\\nabla\\omega)_{ij}=\\partial_{j}a_{i}$, and the corresponding norms $|\\nabla\\omega|=\\left(\\sum_{i,j=1}^{n}(\\partial_{j}a_{i})^{2}\\right)^{1/2}$, and, for a scalar function $f$, $|\\nabla f|=\\left(\\sum_{j=1}^{n}(\\partial_{j}f)^{2}\\right)^{1/2}$. Working pointwise and using only these definitions together with the Cauchyâ€“Schwarz inequality, do the following tasks:\n1. Compute $\\nabla\\left(|\\omega|\\right)$ at points where $|\\omega|\\neq 0$ in terms of $\\{a_{i}\\}$ and their first derivatives, and hence express $|\\nabla\\left(|\\omega|\\right)|$ in terms of $\\{a_{i}\\}$ and $\\{\\partial_{j}a_{i}\\}$.\n2. From your computation, determine the smallest constant $C_{\\star}\\geq 0$ such that the pointwise inequality $|\\nabla\\left(|\\omega|\\right)|\\leq C_{\\star}\\,|\\nabla\\omega|$ holds for all smooth compactly supported $1$-forms $\\omega$ on $\\mathbb{R}^{n}$.\n3. Justify the optimality of your constant by exhibiting a local construction that attains equality at a point.\n\nGive your final answer as the exact value of $C_{\\star}$ (no units).", "solution": "The problem asks for the determination of the optimal constant $C_\\star$ in a pointwise inequality relating the norm of the gradient of the norm of a $1$-form, $|\\nabla(|\\omega|)|$, to the norm of the covariant derivative of the $1$-form itself, $|\\nabla\\omega|$. The problem is set in $\\mathbb{R}^n$ with the standard Euclidean metric. We will address the three tasks sequentially.\n\nFirst, we address Task 1: Compute $\\nabla(|\\omega|)$ and $|\\nabla(|\\omega|)|$.\nLet the smooth $1$-form be $\\omega = \\sum_{i=1}^{n} a_i(x) dx^i$. Its pointwise norm is given by $|\\omega| = \\left( \\sum_{i=1}^{n} a_i^2 \\right)^{1/2}$. We consider $|\\omega|$ as a scalar function on $\\mathbb{R}^n$. The gradient of a scalar function $f$, denoted $\\nabla f$, in the standard coordinates of $\\mathbb{R}^n$ corresponds to the vector of its partial derivatives, $(\\partial_1 f, \\dots, \\partial_n f)$. The problem asks for $\\nabla(|\\omega|)$, whose components are $\\partial_j(|\\omega|)$ for $j=1, \\dots, n$.\n\nAt a point where $|\\omega| \\neq 0$, we can differentiate $|\\omega|$ with respect to the coordinate $x^j$ using the chain rule:\n$$ \\partial_j(|\\omega|) = \\partial_j \\left( \\sum_{k=1}^{n} a_k^2 \\right)^{1/2} $$\n$$ \\partial_j(|\\omega|) = \\frac{1}{2} \\left( \\sum_{k=1}^{n} a_k^2 \\right)^{-1/2} \\cdot \\frac{\\partial}{\\partial x^j} \\left( \\sum_{i=1}^{n} a_i^2 \\right) $$\nApplying the chain rule again to the term $a_i^2$:\n$$ \\partial_j(|\\omega|) = \\frac{1}{2|\\omega|} \\sum_{i=1}^{n} 2 a_i \\frac{\\partial a_i}{\\partial x^j} $$\nUsing the problem's definition $(\\nabla\\omega)_{ij} = \\partial_j a_i$, we have:\n$$ \\partial_j(|\\omega|) = \\frac{1}{|\\omega|} \\sum_{i=1}^{n} a_i (\\partial_j a_i) $$\nThis gives the components of $\\nabla(|\\omega|)$. Next, we compute its norm, $|\\nabla(|\\omega|)|$, which is defined as $\\left(\\sum_{j=1}^{n}(\\partial_{j}f)^{2}\\right)^{1/2}$ for a scalar function $f=|\\omega|$.\n$$ |\\nabla(|\\omega|)|^2 = \\sum_{j=1}^{n} (\\partial_j(|\\omega|))^2 = \\sum_{j=1}^{n} \\left( \\frac{1}{|\\omega|} \\sum_{i=1}^{n} a_i (\\partial_j a_i) \\right)^2 $$\n$$ |\\nabla(|\\omega|)|^2 = \\frac{1}{|\\omega|^2} \\sum_{j=1}^{n} \\left( \\sum_{i=1}^{n} a_i (\\partial_j a_i) \\right)^2 $$\nTaking the square root, we obtain the expression for $|\\nabla(|\\omega|)|$:\n$$ |\\nabla(|\\omega|)| = \\frac{1}{|\\omega|} \\left( \\sum_{j=1}^{n} \\left( \\sum_{i=1}^{n} a_i (\\partial_j a_i) \\right)^2 \\right)^{1/2} $$\n\nNow, we proceed to Task 2: Determine the smallest constant $C_\\star \\geq 0$.\nWe seek the smallest $C_\\star$ such that $|\\nabla(|\\omega|)| \\leq C_{\\star} |\\nabla\\omega|$ holds pointwise. This is equivalent to finding the smallest $C_\\star^2$ such that $|\\nabla(|\\omega|)|^2 \\leq C_{\\star}^2 |\\nabla\\omega|^2$.\nUsing our result from Task 1 and the definition $|\\nabla\\omega|^2 = \\sum_{i,j=1}^{n}(\\partial_{j}a_{i})^{2}$:\n$$ \\frac{1}{|\\omega|^2} \\sum_{j=1}^{n} \\left( \\sum_{i=1}^{n} a_i (\\partial_j a_i) \\right)^2 \\le C_\\star^2 \\sum_{i,j=1}^{n} (\\partial_j a_i)^2 $$\nLet's analyze the term $\\sum_{i=1}^{n} a_i (\\partial_j a_i)$ for a fixed $j$. This is the standard Euclidean inner product in $\\mathbb{R}^n$ of the vector of coefficients $a = (a_1, \\dots, a_n)$ and the vector of partial derivatives $v_j = (\\partial_j a_1, \\dots, \\partial_j a_n)$. So, the sum is $\\langle a, v_j \\rangle$.\nBy the Cauchy-Schwarz inequality, for each $j \\in \\{1,\\dots,n\\}$:\n$$ (\\langle a, v_j \\rangle)^2 \\le |a|^2 |v_j|^2 $$\nHere, $|a|^2 = \\sum_{i=1}^n a_i^2 = |\\omega|^2$ and $|v_j|^2 = \\sum_{i=1}^n (\\partial_j a_i)^2$.\nSumming this inequality over $j$ from $1$ to $n$:\n$$ \\sum_{j=1}^n (\\langle a, v_j \\rangle)^2 \\le \\sum_{j=1}^n |a|^2 |v_j|^2 = |a|^2 \\sum_{j=1}^n |v_j|^2 $$\nSubstituting the definitions back:\n$$ \\sum_{j=1}^n \\left( \\sum_{i=1}^n a_i (\\partial_j a_i) \\right)^2 \\le |\\omega|^2 \\sum_{j=1}^n \\left( \\sum_{i=1}^n (\\partial_j a_i)^2 \\right) = |\\omega|^2 \\sum_{i,j=1}^n (\\partial_j a_i)^2 = |\\omega|^2 |\\nabla\\omega|^2 $$\nNow we substitute this into the expression for $|\\nabla(|\\omega|)|^2$:\n$$ |\\nabla(|\\omega|)|^2 = \\frac{1}{|\\omega|^2} \\sum_{j=1}^{n} \\left( \\sum_{i=1}^{n} a_i (\\partial_j a_i) \\right)^2 \\le \\frac{1}{|\\omega|^2} (|\\omega|^2 |\\nabla\\omega|^2) = |\\nabla\\omega|^2 $$\nTaking the square root of both sides, we obtain the inequality:\n$$ |\\nabla(|\\omega|)| \\le |\\nabla\\omega| $$\nThis shows that the inequality holds for $C_\\star = 1$. Since $C_\\star$ must be the smallest such constant, we have $C_\\star \\le 1$.\n\nFinally, for Task 3, we justify the optimality of $C_\\star = 1$.\nTo show that $C_\\star=1$ is optimal, we must exhibit a case where equality is attained. Equality in our derivation holds if and only if the Cauchy-Schwarz inequality $\\sum_{j=1}^n (\\langle a, v_j \\rangle)^2 \\le |a|^2 \\sum_{j=1}^n |v_j|^2$ becomes an equality. This happens if $(\\langle a, v_j \\rangle)^2 = |a|^2 |v_j|^2$ for all $j=1, \\dots, n$ (assuming not all $v_j$ are zero). This in turn requires that for each $j$, the vector $v_j$ is a scalar multiple of the vector $a$. That is, for each $j$, there is a scalar $\\lambda_j$ such that $v_j = \\lambda_j a$. In components:\n$$ \\partial_j a_i = \\lambda_j a_i \\quad \\text{for all } i=1, \\dots, n $$\nWe need to construct a smooth, compactly supported $1$-form $\\omega$ for which this condition holds at least at one point. Let's construct such a form locally around the origin $x=0$.\nConsider the $1$-form $\\omega_0 = \\exp(x_1) dx^1$. Its components are $a_1 = \\exp(x_1)$ and $a_i=0$ for $i1$. This form is not compactly supported, but we will use it to demonstrate the local behavior.\nAt any point $x$, we have $|\\omega_0|(x) = \\sqrt{(\\exp(x_1))^2} = \\exp(x_1)$.\nThe gradient of this norm function is $\\nabla(|\\omega_0|) = \\nabla(\\exp(x_1))$. The components are $\\partial_1(\\exp(x_1)) = \\exp(x_1)$ and $\\partial_j(\\exp(x_1))=0$ for $j1$.\nThe norm of this gradient is $|\\nabla(|\\omega_0|)| = \\sqrt{(\\exp(x_1))^2 + 0 + \\dots} = \\exp(x_1)$.\nNow for $|\\nabla\\omega_0|$. The components of the covariant derivative are $(\\nabla\\omega_0)_{ij} = \\partial_j a_i$. The only non-zero component is $(\\nabla\\omega_0)_{11} = \\partial_1 a_1 = \\exp(x_1)$. All other components are zero.\nThus, $|\\nabla\\omega_0| = \\sqrt{\\sum_{i,j} ((\\nabla\\omega_0)_{ij})^2} = \\sqrt{(\\exp(x_1))^2} = \\exp(x_1)$.\nFor this form $\\omega_0$, we have $|\\nabla(|\\omega_0|)| = |\\nabla\\omega_0|$ everywhere.\n\nTo satisfy the compact support condition from the problem statement, let $\\phi(x)$ be a smooth bump function on $\\mathbb{R}^n$ such that $\\phi(x)=1$ for $|x| \\le 1/2$ and $\\phi(x)=0$ for $|x| \\ge 1$. Let's define the 1-form $\\omega = \\phi(x) \\omega_0 = \\phi(x) \\exp(x_1) dx^1$. This form is smooth and has compact support.\nLet's evaluate the inequality at the origin $x=0$.\nAt $x=0$, we have $\\phi(0)=1$ and $\\partial_j\\phi(0)=0$ for all $j$.\nThe components of $\\omega$ are $a_1(x) = \\phi(x)\\exp(x_1)$ and $a_i(x)=0$ for $i1$.\nAt $x=0$: $a_1(0) = \\phi(0)\\exp(0) = 1$, and $a_i(0)=0$ for $i1$. So $|\\omega|(0) = 1$.\nThe derivatives are $\\partial_j a_1 = (\\partial_j\\phi)\\exp(x_1) + \\phi(\\partial_j\\exp(x_1))$.\nAt $x=0$:\n$\\partial_1 a_1(0) = (\\partial_1\\phi(0))\\exp(0) + \\phi(0)\\exp(0) = 0 \\cdot 1 + 1 \\cdot 1 = 1$.\n$\\partial_j a_1(0) = 0$ for $j1$.\nFor $i1$, $\\partial_j a_i(0)=0$.\nSo at $x=0$, the only non-zero component of $\\nabla\\omega$ is $(\\nabla\\omega)_{11}=1$.\nThis gives $|\\nabla\\omega|(0) = \\sqrt{1^2} = 1$.\nNow for $|\\nabla(|\\omega|)|$ at $x=0$. From our general formula:\n$$ \\partial_j(|\\omega|)(0) = \\frac{1}{|\\omega|(0)} \\sum_{i=1}^n a_i(0) (\\partial_j a_i)(0) $$\n$\\partial_1(|\\omega|)(0) = \\frac{1}{1} (a_1(0)\\partial_1 a_1(0)) = 1 \\cdot 1 = 1$.\n$\\partial_j(|\\omega|)(0) = \\frac{1}{1} (a_1(0)\\partial_j a_1(0)) = 1 \\cdot 0 = 0$ for $j1$.\nSo $|\\nabla(|\\omega|)|(0) = \\sqrt{1^2+0+\\dots} = 1$.\nAt the origin, for this compactly supported form $\\omega$, we have $|\\nabla(|\\omega|)|(0) = 1$ and $|\\nabla\\omega|(0) = 1$. Equality is achieved.\nThis proves that no constant smaller than $1$ can satisfy the inequality for all forms. Therefore, the optimal constant is $C_\\star = 1$.", "answer": "$$\\boxed{1}$$", "id": "3031617"}, {"introduction": "Understanding when an inequality becomes an equality is key to grasping its deeper implications. This exercise provides a hands-on calculation for a specially constructed radial $p$-form, a scenario where the Kato inequality is sharp. Working through this concrete example will provide you with crucial intuition about the geometric structures, such as forms built from parallel fields, that saturate the inequality and play a significant role in rigidity results. [@problem_id:3031629]", "problem": "Let $\\mathbb{R}^{n}$ be equipped with its standard Euclidean metric and Levi-Civita connection $\\nabla$. Fix an integer $p$ with $1 \\leq p \\leq n$ and let $\\eta$ be a constant unit $p$-form, so that $|\\eta|=1$. Define $r=|x|$ for $x \\in \\mathbb{R}^{n}$ with $x \\neq 0$. Consider the smooth radial function $f:(0,\\infty)\\to(0,\\infty)$ given by $f(r)=\\exp(-r^{2})$, and define the $p$-form field $\\omega:\\mathbb{R}^{n}\\setminus\\{0\\}\\to\\Lambda^{p}(\\mathbb{R}^{n})$ by $\\omega(x)=f(|x|)\\,\\eta$.\n\nUsing only the definitions of the pointwise norms of differential forms and their covariant derivatives induced by the Euclidean metric, and the coordinate expression for covariant derivatives in $\\mathbb{R}^{n}$, compute explicitly the three quantities $|\\omega(x)|$, $|\\nabla(|\\omega|)(x)|$, and $|\\nabla\\omega(x)|$ in terms of $r$, and directly verify the Kato inequality $|\\nabla(|\\omega|)(x)| \\leq |\\nabla\\omega(x)|$ for all $x \\neq 0$. Then define the ratio\n$$\nQ(x)=\\frac{|\\nabla\\omega(x)|}{|\\nabla(|\\omega|)(x)|}, \\quad x \\neq 0,\n$$\nand evaluate $Q(x)$ in its simplest closed form. Provide your final answer as a single expression for $Q(x)$.", "solution": "The problem requires the computation of three quantities associated with a $p$-form $\\omega$ on $\\mathbb{R}^{n}\\setminus\\{0\\}$, a verification of the Kato inequality for this form, and the evaluation of the ratio $Q(x)$. We are instructed to use coordinate expressions for the covariant derivatives and pointwise norms.\n\nLet $x = (x^1, \\dots, x^n)$ be the standard Cartesian coordinates on $\\mathbb{R}^n$. The Euclidean metric is given by the identity matrix, $g_{ij} = \\delta_{ij}$. The associated Levi-Civita connection $\\nabla$ is flat, meaning all its Christoffel symbols in this coordinate system are zero: $\\Gamma^k_{ij} = 0$. The radial distance is $r = |x| = \\sqrt{\\sum_{i=1}^n (x^i)^2}$.\n\nThe given $p$-form is $\\omega(x) = f(|x|)\\eta$, where $f(r) = \\exp(-r^2)$ and $\\eta$ is a constant unit $p$-form. The term \"constant form\" implies that its components in the standard basis $\\{dx^{i_1} \\wedge \\dots \\wedge dx^{i_p}\\}$ are constant numbers. Let $I = (i_1, \\dots, i_p)$ be an ordered multi-index with $1 \\leq i_1  \\dots  i_p \\leq n$. We can write $\\eta = \\sum_I \\eta_I dx^I$, where $\\eta_I$ are constants. The condition that $\\eta$ is a unit form means its pointwise norm is $1$: $|\\eta|^2 = \\sum_I (\\eta_I)^2 = 1$. The form $\\omega$ can then be written as $\\omega(x) = \\sum_I f(r)\\eta_I dx^I$.\n\nFirst, we compute $|\\omega(x)|$. The pointwise norm squared of a $p$-form $\\alpha = \\sum_I \\alpha_I dx^I$ is $|\\alpha|^2 = \\sum_I (\\alpha_I)^2$.\nFor $\\omega(x)$, the components are $\\omega_I(x) = f(r)\\eta_I$.\n$$|\\omega(x)|^2 = \\sum_I (\\omega_I(x))^2 = \\sum_I (f(r)\\eta_I)^2 = (f(r))^2 \\sum_I (\\eta_I)^2$$\nGiven that $\\sum_I (\\eta_I)^2 = |\\eta|^2 = 1$, this simplifies to:\n$$|\\omega(x)|^2 = (f(r))^2 = (\\exp(-r^2))^2 = \\exp(-2r^2)$$\nSince the norm must be non-negative, we take the positive square root:\n$$|\\omega(x)| = \\sqrt{\\exp(-2r^2)} = \\exp(-r^2)$$\n\nSecond, we compute $|\\nabla(|\\omega|)(x)|$. Let $\\phi(x) = |\\omega(x)| = \\exp(-r^2)$. This is a scalar function on $\\mathbb{R}^n \\setminus \\{0\\}$. The covariant derivative of a scalar function is its gradient vector field, $\\nabla\\phi$. The norm squared of the gradient is $|\\nabla\\phi|^2 = \\sum_{i=1}^n (\\frac{\\partial\\phi}{\\partial x^i})^2$.\nWe compute the partial derivatives of $\\phi$ using the chain rule. For any a function $g(r)$, we have $\\frac{\\partial g(r)}{\\partial x^i} = \\frac{dg}{dr} \\frac{\\partial r}{\\partial x^i}$.\nHere, $g(r) = f(r) = \\exp(-r^2)$, so $\\frac{df}{dr} = -2r\\exp(-r^2)$.\nAlso, $r = (\\sum_{j=1}^n (x^j)^2)^{1/2}$, so $\\frac{\\partial r}{\\partial x^i} = \\frac{x^i}{r}$.\nThus, the components of the gradient are:\n$$\\frac{\\partial\\phi}{\\partial x^i} = \\frac{\\partial f(r)}{\\partial x^i} = \\frac{df}{dr} \\frac{\\partial r}{\\partial x^i} = (-2r\\exp(-r^2)) \\left(\\frac{x^i}{r}\\right) = -2x^i\\exp(-r^2)$$\nThe squared norm of this gradient vector is:\n$$|\\nabla(|\\omega|)(x)|^2 = \\sum_{i=1}^n \\left(-2x^i\\exp(-r^2)\\right)^2 = 4(\\exp(-r^2))^2 \\sum_{i=1}^n (x^i)^2 = 4\\exp(-2r^2)r^2$$\nTaking the square root for the norm ($r  0$):\n$$|\\nabla(|\\omega|)(x)| = \\sqrt{4r^2\\exp(-2r^2)} = 2r\\exp(-r^2)$$\n\nThird, we compute $|\\nabla\\omega(x)|$. The covariant derivative $\\nabla\\omega$ is a tensor field of type $(0, p+1)$. Its components in Cartesian coordinates are given by $(\\nabla_k \\omega)_I = \\frac{\\partial \\omega_I}{\\partial x^k}$, since the Christoffel symbols are zero.\nThe components of $\\omega$ are $\\omega_I(x) = f(r)\\eta_I$. Since $\\eta_I$ are constants:\n$$(\\nabla_k \\omega)_I = \\frac{\\partial}{\\partial x^k}(f(r)\\eta_I) = \\eta_I \\frac{\\partial f(r)}{\\partial x^k} = \\eta_I (-2x^k\\exp(-r^2))$$\nThe pointwise norm squared of $\\nabla\\omega$ is defined as $|\\nabla\\omega|^2 = \\sum_{k=1}^n \\sum_I ((\\nabla_k \\omega)_I)^2$.\n$$|\\nabla\\omega(x)|^2 = \\sum_{k=1}^n \\sum_I \\left(\\eta_I (-2x^k\\exp(-r^2))\\right)^2 = \\sum_{k=1}^n \\left((-2x^k\\exp(-r^2))^2 \\sum_I (\\eta_I)^2\\right)$$\nUsing $\\sum_I (\\eta_I)^2 = 1$:\n$$|\\nabla\\omega(x)|^2 = \\sum_{k=1}^n (-2x^k\\exp(-r^2))^2 = \\sum_{k=1}^n 4(x^k)^2 \\exp(-2r^2) = 4\\exp(-2r^2) \\sum_{k=1}^n (x^k)^2$$\nRecognizing that $\\sum_{k=1}^n (x^k)^2 = r^2$:\n$$|\\nabla\\omega(x)|^2 = 4r^2\\exp(-2r^2)$$\nTaking the square root for the norm ($r  0$):\n$$|\\nabla\\omega(x)| = \\sqrt{4r^2\\exp(-2r^2)} = 2r\\exp(-r^2)$$\n\nNow, we directly verify the Kato inequality, $|\\nabla(|\\omega|)(x)| \\leq |\\nabla\\omega(x)|$, for all $x \\neq 0$.\nSubstituting our results:\n$$2r\\exp(-r^2) \\leq 2r\\exp(-r^2)$$\nFor $x \\neq 0$, we have $r0$, so this inequality holds, as it is in fact an equality.\n\nFinally, we evaluate the ratio $Q(x) = \\frac{|\\nabla\\omega(x)|}{|\\nabla(|\\omega|)(x)|}$.\nThe denominator $|\\nabla(|\\omega|)(x)| = 2r\\exp(-r^2)$ is non-zero for $x \\neq 0$ (i.e., $r  0$), so the ratio is well-defined.\n$$Q(x) = \\frac{2r\\exp(-r^2)}{2r\\exp(-r^2)} = 1$$\nThe ratio $Q(x)$ is constant and equal to $1$ for all $x \\in \\mathbb{R}^n \\setminus \\{0\\}$. The equality is a direct consequence of the fact that the form $\\omega$ is constructed by scaling a parallel form $\\eta$ (i.e., $\\nabla\\eta=0$) by a scalar function $f$.\n\nThe computed quantities are:\n$|\\omega(x)| = \\exp(-r^2)$\n$|\\nabla(|\\omega|)(x)| = 2r\\exp(-r^2)$\n$|\\nabla\\omega(x)| = 2r\\exp(-r^2)$\nThe ratio $Q(x)$ is $1$.", "answer": "$$\\boxed{1}$$", "id": "3031629"}, {"introduction": "The classical Kato inequality can often be improved by incorporating additional structure. This advanced practice explores such a \"refined\" Kato inequality for harmonic $1$-forms, where conditions $d\\omega=0$ and $\\delta\\omega=0$ constrain the covariant derivative $\\nabla\\omega$ to be a symmetric, trace-free tensor. By connecting this geometric problem to an algebraic question about matrix norms, you will learn a powerful technique for deriving sharper estimates and appreciate the interplay between analysis, geometry, and linear algebra. [@problem_id:3031618]", "problem": "Let $\\mathbb{R}^{n}$ be equipped with its standard Euclidean metric $g$ and the Levi-Civita connection $\\nabla$. For a smooth $1$-form $\\omega$ on $\\mathbb{R}^{n}$, define the pointwise norm $|\\omega|$ induced by $g$, and write the exterior derivative as $d\\omega$ and the codifferential as $\\delta\\omega$. Consider the refined Kato inequality for closed and co-closed $1$-forms (that is, $d\\omega=0$ and $\\delta\\omega=0$), which estimates $|\\nabla|\\omega||$ in terms of $|\\nabla\\omega|$ at points where $\\omega\\neq 0$. Define the refined Kato constant $c_{n,1}$ to be the smallest $c\\geq 0$ such that, for every smooth $1$-form $\\omega$ with $d\\omega=0$ and $\\delta\\omega=0$, one has the pointwise inequality\n$$\n|\\nabla|\\omega|| \\leq c\\,|\\nabla\\omega|\n$$\nat all points where $\\omega\\neq 0$.\n\nUsing only fundamental definitions (the decomposition of tensor spaces under the orthogonal group $O(n)$, the identification of $T^{*}\\otimes \\Lambda^{1}$ with the direct sum of irreducible components corresponding to the skew-symmetric part, the trace part, and the symmetric trace-free part), compute the exact value of $c_{n,1}$ by identifying the relevant $O(n)$-equivariant operator norm. Then, verify that your constant is sharp by constructing explicit extremal examples: give a family of smooth $1$-forms on $\\mathbb{R}^{n}$ that are closed and co-closed and for which equality is attained in the refined Kato inequality at some nonzero point. Express your final answer for $c_{n,1}$ as a closed-form analytic expression in $n$.", "solution": "The problem asks for the determination of the refined Kato constant $c_{n,1}$ for closed and co-closed $1$-forms on Euclidean space $\\mathbb{R}^n$.\n\nLet $\\omega$ be a smooth $1$-form on $\\mathbb{R}^n$, which is equipped with the standard Euclidean metric $g$ and the Levi-Civita connection $\\nabla$. In standard Cartesian coordinates $\\{x^i\\}$, $g_{ij} = \\delta_{ij}$ and $\\nabla_i = \\partial_i$.\nThe $1$-form can be written as $\\omega = \\sum_{j=1}^n \\omega_j dx^j$. Its pointwise norm is given by $|\\omega|^2 = \\sum_{j=1}^n \\omega_j^2$.\nThe covariant derivative of $\\omega$, denoted $\\nabla\\omega$, is a $(0,2)$-tensor field with components $(\\nabla\\omega)_{ij} = \\nabla_i\\omega_j = \\partial_i \\omega_j$. Its pointwise norm is $|\\nabla\\omega|^2 = \\sum_{i,j=1}^n (\\partial_i \\omega_j)^2$.\n\nThe problem states that $\\omega$ is closed, $d\\omega=0$, and co-closed, $\\delta\\omega=0$. Let us analyze these conditions.\nThe exterior derivative $d\\omega$ is a $2$-form with components $(d\\omega)_{ij} = \\partial_i \\omega_j - \\partial_j \\omega_i$. The condition $d\\omega=0$ implies $\\partial_i \\omega_j = \\partial_j \\omega_i$. This means that the tensor $\\nabla\\omega$ is symmetric.\nThe codifferential $\\delta\\omega$ is a function given by $\\delta\\omega = - \\operatorname{tr}_g(\\nabla\\omega) = -g^{ij} \\nabla_i \\omega_j = -\\sum_{i=1}^n \\partial_i \\omega_i$. The condition $\\delta\\omega=0$ implies $\\sum_{i=1}^n \\partial_i \\omega_i = 0$. This means the trace of the tensor $\\nabla\\omega$ is zero.\n\nLet $T$ denote the $(0,2)$-tensor field $\\nabla\\omega$. The conditions on $\\omega$ imply that at each point $x \\in \\mathbb{R}^n$, the tensor $T(x)$ is a symmetric, trace-free endomorphism of the tangent space $T_x \\mathbb{R}^n \\cong \\mathbb{R}^n$. This is precisely the content of the problem's hint to use the decomposition of $T^* \\otimes T^*$: the tensor $\\nabla\\omega$ lies in the irreducible $O(n)$-submodule of symmetric trace-free tensors, denoted $S_0^2(T^*)$.\n\nWe are interested in the inequality $|\\nabla|\\omega|| \\leq c |\\nabla\\omega|$ at points where $\\omega \\neq 0$. Let us compute the left-hand side. The gradient of the scalar function $|\\omega|$ is a $1$-form $\\nabla|\\omega|$.\n$|\\omega| = (\\sum_{k=1}^n \\omega_k^2)^{1/2}$.\nThe $i$-th component of $\\nabla|\\omega|$ is:\n$$ (\\nabla|\\omega|)_i = \\partial_i(|\\omega|) = \\frac{1}{2|\\omega|} \\partial_i\\left(\\sum_{k=1}^n \\omega_k^2\\right) = \\frac{1}{|\\omega|} \\sum_{k=1}^n \\omega_k (\\partial_i \\omega_k) = \\frac{1}{|\\omega|} \\sum_{k=1}^n \\omega_k T_{ik} $$\nThe squared norm of $\\nabla|\\omega|$ is:\n$$ |\\nabla|\\omega||^2 = \\sum_{i=1}^n ((\\nabla|\\omega|)_i)^2 = \\frac{1}{|\\omega|^2} \\sum_{i=1}^n \\left(\\sum_{k=1}^n T_{ik} \\omega_k\\right)^2 $$\nLet $\\mathbf{v}_\\omega$ be the vector field dual to $\\omega$ via the metric $g$. In Cartesian coordinates, its components are simply $\\omega_k$. The expression $\\sum_{k=1}^n T_{ik} \\omega_k$ is the $i$-th component of the vector resulting from the action of the matrix $T$ on the vector $\\mathbf{v}_\\omega$. Let's denote this by $(T\\mathbf{v}_\\omega)_i$. Then $|\\nabla|\\omega||^2 = \\frac{|T\\mathbf{v}_\\omega|^2}{|\\omega|^2}$.\n\nThe refined Kato inequality is therefore $\\frac{|T\\mathbf{v}_\\omega|^2}{|\\omega|^2} \\leq c^2 |T|^2$.\nThe constant $c_{n,1}$ is the smallest $c \\geq 0$ satisfying this for all harmonic $1$-forms. Thus, $c_{n,1}^2$ is the supremum of the ratio $\\frac{|T\\mathbf{v}_\\omega|^2}{|\\omega|^2|T|^2}$ over all possible configurations. This is a pointwise problem. For any point $x$, we have a symmetric trace-free tensor $T=T(x)$ and a vector $\\mathbf{v}_\\omega=\\mathbf{v}_\\omega(x)$. The problem reduces to finding the supremum:\n$$ c_{n,1}^2 = \\sup_{T \\in S_0^2(\\mathbb{R}^n), T \\neq 0} \\sup_{\\mathbf{v} \\in \\mathbb{R}^n, \\mathbf{v} \\neq 0} \\frac{|T\\mathbf{v}|^2}{|\\mathbf{v}|^2 |T|^2} $$\nThe term $\\sup_{\\mathbf{v} \\neq 0} \\frac{|T\\mathbf{v}|^2}{|\\mathbf{v}|^2}$ is the definition of the squared operator norm of $T$, denoted $\\|T\\|_{op}^2$. Since $T$ is a symmetric matrix, its operator norm is the maximum absolute value of its eigenvalues, i.e., $\\|T\\|_{op} = \\max_i |\\lambda_i(T)|$.\nThe norm $|T|^2 = \\sum_{i,j} T_{ij}^2$ is the squared Frobenius norm, which is also equal to the trace of $T^T T$. Since $T$ is symmetric, this is $\\operatorname{Tr}(T^2) = \\sum_{i=1}^n \\lambda_i(T)^2$.\n\nThe problem is now purely algebraic: find the supremum of the ratio of the squared operator norm to the squared Frobenius norm over the space of non-zero symmetric trace-free $n \\times n$ matrices.\n$$ c_{n,1}^2 = \\sup \\left\\{ \\frac{(\\max_i |\\lambda_i|)^2}{\\sum_{j=1}^n \\lambda_j^2} \\;\\middle|\\; (\\lambda_1, \\dots, \\lambda_n) \\in \\mathbb{R}^n \\setminus \\{0\\}, \\sum_{j=1}^n \\lambda_j = 0 \\right\\} $$\nLet's assume, without loss of generality, that the maximum absolute value is $|\\lambda_1|$. We want to maximize the expression $F(\\lambda_1, \\dots, \\lambda_n) = \\frac{\\lambda_1^2}{\\sum_{j=1}^n \\lambda_j^2}$ subject to the constraint $\\sum_{j=1}^n \\lambda_j = 0$.\nThe expression is homogeneous of degree $0$ in the eigenvalues, so we can fix $\\lambda_1 = 1$. The constraint becomes $\\sum_{j=2}^n \\lambda_j = -1$.\nWe want to maximize $\\frac{1}{1 + \\sum_{j=2}^n \\lambda_j^2}$. This is equivalent to minimizing the denominator, i.e., minimizing $\\sum_{j=2}^n \\lambda_j^2$ subject to $\\sum_{j=2}^n \\lambda_j = -1$.\nThis is a standard quadratic minimization problem. By Cauchy-Schwarz inequality or Lagrange multipliers, the minimum is achieved when all variables are equal: $\\lambda_2 = \\lambda_3 = \\dots = \\lambda_n$.\nLet this common value be $\\lambda$. Then $(n-1)\\lambda = -1$, so $\\lambda = -\\frac{1}{n-1}$.\nThis holds for $n \\geq 2$. If $n=1$, the trace-free condition implies $\\lambda_1=0$, so $T=0$, $|\\nabla\\omega|=0$. Since $\\omega$ would be constant, $|\\omega|$ is constant, so $\\nabla|\\omega|=0$. Thus $0 \\le c \\cdot 0$, making $c_{1,1}=0$. Our formula will reflect this.\nFor $n \\ge 2$, the optimal set of eigenvalues (up to scaling) is proportional to $(1, -\\frac{1}{n-1}, \\dots, -\\frac{1}{n-1})$. The largest squared eigenvalue is $1^2=1$.\nThe sum of squared eigenvalues is:\n$$ \\sum_{j=1}^n \\lambda_j^2 = 1^2 + \\sum_{j=2}^n \\left(-\\frac{1}{n-1}\\right)^2 = 1 + (n-1) \\frac{1}{(n-1)^2} = 1 + \\frac{1}{n-1} = \\frac{n}{n-1} $$\nThe maximum value of the ratio is:\n$$ c_{n,1}^2 = \\frac{1}{n/(n-1)} = \\frac{n-1}{n} $$\nTherefore, the refined Kato constant is $c_{n,1} = \\sqrt{\\frac{n-1}{n}}$.\n\nTo verify this constant is sharp, we must construct a smooth harmonic $1$-form $\\omega$ for which equality is attained at some point.\nA $1$-form given by $\\omega = df$ for a harmonic function $f$ (i.e., $\\Delta f = 0$) is both closed ($d\\omega=d(df)=0$) and co-closed ($\\delta\\omega = \\delta d f = -\\Delta f = 0$). For such a form, $\\nabla\\omega$ corresponds to the Hessian matrix $\\operatorname{Hess}(f)$, with components $T_{ij} = \\partial_i \\partial_j f$.\nWe need to find a harmonic function $f$ whose Hessian has the extremal eigenvalue distribution we found. Let's choose the eigenvalues to be $(n-1, -1, \\dots, -1)$. A matrix with these eigenvalues is $T = \\operatorname{diag}(n-1, -1, \\dots, -1)$.\nConsider the quadratic polynomial $f(x_1, \\dots, x_n) = \\frac{1}{2}((n-1)x_1^2 - \\sum_{j=2}^n x_j^2)$.\nThe Laplacian is $\\Delta f = \\partial_1^2 f + \\sum_{j=2}^n \\partial_j^2 f = (n-1) + \\sum_{j=2}^n (-1) = (n-1) - (n-1) = 0$. So $f$ is harmonic.\nThe corresponding $1$-form is $\\omega = df = (n-1)x_1 dx^1 - \\sum_{j=2}^n x_j dx^j$.\nThe Hessian matrix is $\\operatorname{Hess}(f) = \\nabla\\omega = T$, which is constant.\nThe extremal case for the ratio $\\frac{|T\\mathbf{v}|^2}{|\\mathbf{v}|^2|T|^2}$ occurs when $\\mathbf{v}$ is an eigenvector of $T$ corresponding to the eigenvalue with the largest magnitude, which is $n-1$. The corresponding eigenvectors are multiples of $e_1 = (1, 0, \\dots, 0)^T$.\nLet's evaluate the inequality at the point $p=(1, 0, \\dots, 0)$.\nAt $p$, the vector dual to $\\omega(p)$ is $\\mathbf{v}_\\omega(p) = ((n-1)\\cdot 1, -0, \\dots, -0)^T = (n-1)e_1$. This is a non-zero vector, so $\\omega(p) \\neq 0$.\nThe left-hand side of the inequality $|\\nabla|\\omega||^2 \\le c_{n,1}^2 |\\nabla\\omega|^2$ at $p$ is:\n$$ |\\nabla|\\omega||^2(p) = \\frac{|T \\mathbf{v}_\\omega(p)|^2}{|\\omega(p)|^2} = \\frac{|T((n-1)e_1)|^2}{|(n-1)e_1|^2} = \\frac{(n-1)^2 |Te_1|^2}{(n-1)^2|e_1|^2} = |(n-1)e_1|^2 = (n-1)^2 $$\nThe right-hand side is:\n$$ c_{n,1}^2 |\\nabla\\omega|^2(p) = \\left(\\frac{n-1}{n}\\right) |T|^2 $$\nThe squared Frobenius norm of $T = \\operatorname{diag}(n-1, -1, \\dots, -1)$ is:\n$$ |T|^2 = \\sum_i \\lambda_i^2 = (n-1)^2 + \\sum_{j=2}^n (-1)^2 = (n-1)^2 + (n-1) = (n-1)(n-1+1) = n(n-1) $$\nSo, the right-hand side is $\\left(\\frac{n-1}{n}\\right) (n(n-1)) = (n-1)^2$.\nSince $|\\nabla|\\omega||^2(p) = (n-1)^2$ and $c_{n,1}^2 |\\nabla\\omega|^2(p) = (n-1)^2$, equality holds at point $p$. This demonstrates that the constant $c_{n,1} = \\sqrt{\\frac{n-1}{n}}$ is sharp for all $n \\ge 2$. For $n=1$, the value is $0$, which is correct as reasoned earlier.", "answer": "$$\\boxed{\\sqrt{\\frac{n-1}{n}}}$$", "id": "3031618"}]}