{"hands_on_practices": [{"introduction": "The modern theory of optimal transport is built upon the Kantorovich relaxation of the original Monge problem. This first exercise provides a crucial, hands-on demonstration of why this relaxation is necessary by constructing a simple scenario where a transport map cannot exist, requiring instead a transport plan that can 'split' mass. Mastering this distinction is the first step toward understanding the broader applicability of optimal transport theory [@problem_id:3032195].", "problem": "Consider the following metric measure space in the sense of geometric analysis. Let $X$ be the metric graph obtained by gluing two closed intervals $[0,2]$ and $[0,3]$ at their $0$-endpoints, and denote the common point by $o$. Equip $X$ with the path metric $d$ induced by the Euclidean length along the graph, and let $m$ be the one-dimensional Hausdorff measure restricted to $X$. Denote the endpoint of the interval $[0,2]$ by $y_{1}$ and the endpoint of the interval $[0,3]$ by $y_{2}$, so that $d(o,y_{1})=2$ and $d(o,y_{2})=3$. Consider the cost function $c(x,y)=d(x,y)^{2}$. Define the source probability measure $\\mu=\\delta_{o}$ and the target probability measure $\\nu=\\frac{1}{3}\\,\\delta_{y_{1}}+\\frac{2}{3}\\,\\delta_{y_{2}}$ on the Borel $\\sigma$-algebra of $X$. \n\nStarting from the fundamental definitions of the Monge formulation (searching for a measurable transport map $T:X\\to X$ with $T_{\\#}\\mu=\\nu$ that minimizes $\\int c(x,T(x))\\,\\mathrm{d}\\mu(x)$) and the Kantorovich formulation (searching for a coupling $\\pi$ of $(\\mu,\\nu)$ that minimizes $\\int c(x,y)\\,\\mathrm{d}\\pi(x,y)$), do the following:\n\n1. Explain why the Monge formulation is infeasible in this setting, using only the pushforward definition and the structure of $\\mu$ and $\\nu$.\n2. Construct an admissible Kantorovich coupling $\\pi$ and justify that it minimizes the transport cost among all admissible couplings.\n3. Compute the optimal Kantorovich cost $\\int c(x,y)\\,\\mathrm{d}\\pi(x,y)$ explicitly. Your final answer must be a single real number.\n\nNo part of your reasoning may rely on shortcuts that presuppose specialized existence results for transport maps; instead, use only the core definitions of pushforward measures, couplings, and the cost functional. You may reference the general context of curvature-dimension theory by recalling that the curvature-dimension condition (CD(K,N)) interacts with existence and uniqueness of transport maps under absolute continuity and non-branching hypotheses, but do not assume these hypotheses here. Express your final numerical answer exactly; no rounding is required.", "solution": "The problem is well-defined and can be solved by a direct application of the fundamental definitions of the Monge and Kantorovich formulations of optimal transport.\n\nThe metric measure space is $(X, d, m)$, where $X$ is a metric graph formed by joining two intervals, which can be identified with $[0,2]$ and $[0,3]$, at the point $o$ (corresponding to $0$ in both intervals). The metric $d$ is the shortest path distance. The source measure is $\\mu = \\delta_{o}$, a Dirac mass at the junction point $o$. The target measure is $\\nu = \\frac{1}{3}\\delta_{y_{1}} + \\frac{2}{3}\\delta_{y_{2}}$, a weighted sum of Dirac masses at the two other endpoints of the graph, where $d(o, y_{1}) = 2$ and $d(o, y_{2}) = 3$. The cost function is $c(x, y) = d(x, y)^{2}$.\n\n1. Infeasibility of the Monge Formulation\n\nThe Monge problem seeks a measurable map $T: X \\to X$ that minimizes the transport cost $\\int_{X} c(x, T(x))\\,\\mathrm{d}\\mu(x)$, subject to the pushforward constraint $T_{\\#}\\mu = \\nu$. Let us analyze this constraint. The source measure is $\\mu = \\delta_{o}$. The pushforward measure $T_{\\#}\\mu$ is defined by its action on any Borel set $A \\subseteq X$:\n$$ (T_{\\#}\\mu)(A) = \\mu(T^{-1}(A)) = \\delta_{o}(T^{-1}(A)) $$\nBy the definition of the Dirac measure, $\\delta_{o}(S)$ is equal to $1$ if $o \\in S$ and $0$ otherwise. Therefore:\n$$ (T_{\\#}\\mu)(A) = \\begin{cases} 1 & \\text{if } o \\in T^{-1}(A) \\\\ 0 & \\text{if } o \\notin T^{-1}(A) \\end{cases} $$\nThe condition $o \\in T^{-1}(A)$ is equivalent to $T(o) \\in A$. This implies that the pushforward measure $T_{\\#}\\mu$ is a Dirac measure concentrated at the single point $T(o) \\in X$. That is, $T_{\\#}\\mu = \\delta_{T(o)}$.\n\nThe pushforward constraint $T_{\\#}\\mu = \\nu$ thus becomes:\n$$ \\delta_{T(o)} = \\frac{1}{3}\\delta_{y_{1}} + \\frac{2}{3}\\delta_{y_{2}} $$\nThis equation asserts an equality of two measures. For this equality to hold, the measures must agree on all measurable sets. Let us test this for the singleton set $\\{y_{1}\\}$.\nThe measure on the left-hand side gives $\\delta_{T(o)}(\\{y_{1}\\})$, which can only take the value $1$ (if $T(o) = y_{1}$) or $0$ (if $T(o) \\neq y_{1}$).\nThe measure on the right-hand side gives:\n$$ \\nu(\\{y_{1}\\}) = \\left(\\frac{1}{3}\\delta_{y_{1}} + \\frac{2}{3}\\delta_{y_{2}}\\right)(\\{y_{1}\\}) = \\frac{1}{3}\\delta_{y_{1}}(\\{y_{1}\\}) + \\frac{2}{3}\\delta_{y_{2}}(\\{y_{1}\\}) = \\frac{1}{3}(1) + \\frac{2}{3}(0) = \\frac{1}{3} $$\nThus, the equality would require $\\delta_{T(o)}(\\{y_{1}\\}) = \\frac{1}{3}$. This is a contradiction, as a Dirac measure of a set can only be $0$ or $1$. The core of the issue is that a map $T$ sends the point $o$ to a single point $T(o)$, so it cannot \"split\" the mass of $\\delta_o$ to be distributed over the two distinct points $y_{1}$ and $y_{2}$. Consequently, no such transport map $T$ exists, and the Monge problem is infeasible as it has no admissible solutions.\n\n2. Optimal Kantorovich Coupling\n\nThe Kantorovich problem seeks a probability measure $\\pi$ on the product space $X \\times X$, called a coupling, that has $\\mu$ and $\\nu$ as its marginals and minimizes the total cost $\\int_{X \\times X} c(x, y)\\,\\mathrm{d}\\pi(x, y)$. A coupling $\\pi$ is admissible if for all Borel sets $A, B \\subseteq X$:\n$$ \\pi(A \\times X) = \\mu(A) \\quad \\text{and} \\quad \\pi(X \\times B) = \\nu(B) $$\nLet's apply the first marginal constraint with $\\mu = \\delta_{o}$. For any Borel set $A \\subseteq X$ such that $o \\notin A$, we have $\\mu(A) = \\delta_{o}(A) = 0$. The constraint implies $\\pi(A \\times X) = 0$. This forces the support of the measure $\\pi$ to be a subset of $\\{o\\} \\times X$. In other words, any admissible coupling $\\pi$ must be of the form $\\pi = \\delta_{o} \\otimes \\rho$ for some probability measure $\\rho$ on $X$.\n\nNow we apply the second marginal constraint. For any Borel set $B \\subseteq X$:\n$$ \\pi(X \\times B) = (\\delta_{o} \\otimes \\rho)(X \\times B) = \\delta_{o}(X) \\rho(B) = (1) \\rho(B) = \\rho(B) $$\nThe constraint $\\pi(X \\times B) = \\nu(B)$ requires that $\\rho(B) = \\nu(B)$ for all Borel sets $B$. This uniquely determines the measure $\\rho$ to be $\\nu$.\nTherefore, there exists only one admissible coupling that satisfies both marginal conditions:\n$$ \\pi = \\delta_{o} \\otimes \\nu $$\nSubstituting the expression for $\\nu$:\n$$ \\pi = \\delta_{o} \\otimes \\left(\\frac{1}{3}\\delta_{y_{1}} + \\frac{2}{3}\\delta_{y_{2}}\\right) $$\nBy the bilinearity of the tensor product of measures, this is:\n$$ \\pi = \\frac{1}{3}(\\delta_{o} \\otimes \\delta_{y_{1}}) + \\frac{2}{3}(\\delta_{o} \\otimes \\delta_{y_{2}}) $$\nThis measure can be identified with a measure on $X \\times X$ as $\\pi = \\frac{1}{3}\\delta_{(o, y_{1})} + \\frac{2}{3}\\delta_{(o, y_{2})}$, where $\\delta_{(a,b)}$ a Dirac mass at the point $(a,b) \\in X \\times X$.\n\nSince there is only a single admissible coupling $\\pi$, the set of all admissible couplings $\\Pi(\\mu, \\nu)$ is a singleton. The minimization of the cost functional over a singleton set is trivially achieved by the sole element of that set. Thus, this unique coupling $\\pi = \\delta_{o} \\otimes \\nu$ is the optimal Kantorovich coupling. The failure of the Monge formulation alongside the existence of a unique Kantorovich coupling is characteristic of problems involving mass splitting. This situation underscores why the Kantorovich relaxation is essential. Theories like curvature-dimension CD(K,N) often provide conditions for the existence of an optimal transport *map* (a Monge solution), but these typically require the source measure to be absolutely continuous with respect to the reference measure $m$ and the space to be non-branchingâ€”conditions which are clearly violated in this problem setup.\n\n3. Computation of the Optimal Cost\n\nThe optimal Kantorovich cost is the value of the transport cost functional evaluated for the optimal coupling $\\pi$.\n$$ \\text{Cost} = \\int_{X \\times X} c(x, y)\\,\\mathrm{d}\\pi(x, y) = \\int_{X \\times X} d(x, y)^{2}\\,\\mathrm{d}\\pi(x, y) $$\nSubstituting the optimal coupling $\\pi = \\frac{1}{3}\\delta_{(o, y_{1})} + \\frac{2}{3}\\delta_{(o, y_{2})}$:\n$$ \\text{Cost} = \\int_{X \\times X} d(x, y)^{2}\\,\\mathrm{d}\\left(\\frac{1}{3}\\delta_{(o, y_{1})} + \\frac{2}{3}\\delta_{(o, y_{2})}\\right) $$\nBy the linearity of integration:\n$$ \\text{Cost} = \\frac{1}{3}\\int_{X \\times X} d(x, y)^{2}\\,\\mathrm{d}\\delta_{(o, y_{1})} + \\frac{2}{3}\\int_{X \\times X} d(x, y)^{2}\\,\\mathrm{d}\\delta_{(o, y_{2})} $$\nThe integral of a function $f(p)$ against a Dirac measure $\\delta_{p_0}$ is $f(p_0)$. Applying this rule:\n$$ \\text{Cost} = \\frac{1}{3}d(o, y_{1})^{2} + \\frac{2}{3}d(o, y_{2})^{2} $$\nThe problem provides the distances $d(o, y_{1}) = 2$ and $d(o, y_{2}) = 3$. Substituting these values:\n$$ \\text{Cost} = \\frac{1}{3}(2)^{2} + \\frac{2}{3}(3)^{2} = \\frac{1}{3}(4) + \\frac{2}{3}(9) = \\frac{4}{3} + \\frac{18}{3} = \\frac{22}{3} $$\nThe optimal Kantorovich cost is $\\frac{22}{3}$.", "answer": "$$\n\\boxed{\\frac{22}{3}}\n$$", "id": "3032195"}, {"introduction": "With the foundational framework in place, we now turn to a concrete calculation of the Wasserstein distance and the construction of a geodesic in the space of probability measures. This practice demystifies abstract concepts by grounding them in the well-understood setting of the real line, where optimal plans are elegantly described by monotone rearrangements. By explicitly constructing the path of measures via displacement interpolation, you will gain a tangible intuition for the geometric structure of Wasserstein space [@problem_id:3032182].", "problem": "Consider the space of Borel probability measures on the real line $\\mathbb{R}$ equipped with the Euclidean distance $d(x,y)=|x-y|$ and the quadratic Wasserstein distance of order $2$ defined by\n$$\nW_{2}(\\mu,\\nu)^{2}=\\inf_{\\pi\\in\\Pi(\\mu,\\nu)}\\int_{\\mathbb{R}\\times\\mathbb{R}}|x-y|^{2}\\,d\\pi(x,y),\n$$\nwhere $\\Pi(\\mu,\\nu)$ denotes the set of all couplings of $\\mu$ and $\\nu$. On the line, optimal couplings can be characterized by monotone rearrangement via cumulative distribution functions (CDF), defined for a probability measure $\\mu$ by $F_{\\mu}(x)=\\mu((-\\infty,x])$, and the corresponding quantile function $F_{\\mu}^{-1}(u)=\\inf\\{x\\in\\mathbb{R}:F_{\\mu}(x)\\ge u\\}$ for $u\\in(0,1)$. A $W_{2}$-geodesic between $\\mu_{0}$ and $\\mu_{1}$ is a curve $(\\mu_{t})_{t\\in[0,1]}$ constructed by transporting mass along straight lines between optimally coupled pairs.\n\nLet\n$$\n\\mu_{0}=\\frac{1}{2}\\,\\delta_{0}+\\frac{1}{2}\\,\\delta_{3},\\qquad \\mu_{1}=\\frac{1}{4}\\,\\delta_{-1}+\\frac{1}{2}\\,\\delta_{2}+\\frac{1}{4}\\,\\delta_{5}.\n$$\nUsing only the definition of $W_{2}$ and the monotone rearrangement principle on $\\mathbb{R}$, determine the unique optimal coupling between $\\mu_{0}$ and $\\mu_{1}$, explicitly construct the $W_{2}$-geodesic $(\\mu_{t})_{t\\in[0,1]}$ by displacement interpolation under this coupling, and then compute the exact closed-form expression of $W_{2}(\\mu_{t},\\mu_{1/3})$ as a function of $t\\in[0,1]$. Express your final answer as a single analytic expression. No rounding is required and no physical units are involved.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard problem in the field of optimal transport theory on metric spaces. All necessary definitions and data are provided, and there are no contradictions or ambiguities.\n\nThe problem asks for three items: the optimal coupling between two given measures $\\mu_{0}$ and $\\mu_{1}$, the explicit construction of the $W_{2}$-geodesic $(\\mu_{t})_{t\\in[0,1]}$, and the computation of $W_{2}(\\mu_{t},\\mu_{1/3})$.\n\n**Step 1: Determine the Optimal Coupling**\n\nThe optimal coupling between two probability measures on $\\mathbb{R}$ is determined by the principle of monotone rearrangement. For discrete measures, this means matching the mass components in increasing order of their locations. We first compute the cumulative distribution functions (CDFs) and their generalized inverses, the quantile functions.\n\nThe initial measure is $\\mu_{0}=\\frac{1}{2}\\,\\delta_{0}+\\frac{1}{2}\\,\\delta_{3}$. Its CDF is:\n$$\nF_{\\mu_{0}}(x) = \\begin{cases} 0 & \\text{if } x < 0 \\\\ \\frac{1}{2} & \\text{if } 0 \\le x < 3 \\\\ 1 & \\text{if } x \\ge 3 \\end{cases}\n$$\nThe corresponding quantile function $F_{\\mu_{0}}^{-1}(u) = \\inf\\{x \\in \\mathbb{R} : F_{\\mu_{0}}(x) \\ge u\\}$ for $u \\in (0,1)$ is:\n$$\nF_{\\mu_{0}}^{-1}(u) = \\begin{cases} 0 & \\text{if } 0 < u \\le \\frac{1}{2} \\\\ 3 & \\text{if } \\frac{1}{2} < u \\le 1 \\end{cases}\n$$\n\nThe final measure is $\\mu_{1}=\\frac{1}{4}\\,\\delta_{-1}+\\frac{1}{2}\\,\\delta_{2}+\\frac{1}{4}\\,\\delta_{5}$. Its CDF is:\n$$\nF_{\\mu_{1}}(x) = \\begin{cases} 0 & \\text{if } x < -1 \\\\ \\frac{1}{4} & \\text{if } -1 \\le x < 2 \\\\ \\frac{3}{4} & \\text{if } 2 \\le x < 5 \\\\ 1 & \\text{if } x \\ge 5 \\end{cases}\n$$\nThe corresponding quantile function is:\n$$\nF_{\\mu_{1}}^{-1}(u) = \\begin{cases} -1 & \\text{if } 0 < u \\le \\frac{1}{4} \\\\ 2 & \\text{if } \\frac{1}{4} < u \\le \\frac{3}{4} \\\\ 5 & \\text{if } \\frac{3}{4} < u \\le 1 \\end{cases}\n$$\n\nThe optimal transport plan matches the quantiles. We consider the intervals of the quantile variable $u \\in (0,1)$:\n1. For $u \\in (0, \\frac{1}{4}]$, we have $F_{\\mu_{0}}^{-1}(u)=0$ and $F_{\\mu_{1}}^{-1}(u)=-1$. This means a mass of $\\frac{1}{4}$ is transported from $0$ to $-1$.\n2. For $u \\in (\\frac{1}{4}, \\frac{1}{2}]$, we have $F_{\\mu_{0}}^{-1}(u)=0$ and $F_{\\mu_{1}}^{-1}(u)=2$. This means a mass of $\\frac{1}{4}$ is transported from $0$ to $2$.\n3. For $u \\in (\\frac{1}{2}, \\frac{3}{4}]$, we have $F_{\\mu_{0}}^{-1}(u)=3$ and $F_{\\mu_{1}}^{-1}(u)=2$. This means a mass of $\\frac{1}{4}$ is transported from $3$ to $2$.\n4. For $u \\in (\\frac{3}{4}, 1]$, we have $F_{\\mu_{0}}^{-1}(u)=3$ and $F_{\\mu_{1}}^{-1}(u)=5$. This means a mass of $\\frac{1}{4}$ is transported from $3$ to $5$.\n\nThe optimal coupling $\\pi \\in \\Pi(\\mu_{0},\\mu_{1})$ is therefore the discrete measure on $\\mathbb{R}\\times\\mathbb{R}$:\n$$\n\\pi = \\frac{1}{4}\\,\\delta_{(0, -1)} + \\frac{1}{4}\\,\\delta_{(0, 2)} + \\frac{1}{4}\\,\\delta_{(3, 2)} + \\frac{1}{4}\\,\\delta_{(3, 5)}\n$$\n\n**Step 2: Construct the $W_{2}$-Geodesic**\n\nThe $W_{2}$-geodesic $(\\mu_{t})_{t\\in[0,1]}$ is constructed by displacement interpolation. Each particle of mass moves along a straight line path from its initial position $x$ to its final position $y$ at constant speed. The position at time $t$ is given by $(1-t)x + ty$. Applying this to the support of the optimal coupling $\\pi$:\n1. A mass of $\\frac{1}{4}$ moves from $0$ to $-1$. At time $t$, it is at $(1-t)0 + t(-1) = -t$.\n2. A mass of $\\frac{1}{4}$ moves from $0$ to $2$. At time $t$, it is at $(1-t)0 + t(2) = 2t$.\n3. A mass of $\\frac{1}{4}$ moves from $3$ to $2$. At time $t$, it is at $(1-t)3 + t(2) = 3-3t+2t = 3-t$.\n4. A mass of $\\frac{1}{4}$ moves from $3$ to $5$. At time $t$, it is at $(1-t)3 + t(5) = 3-3t+5t = 3+2t$.\n\nThus, the measure $\\mu_{t}$ at time $t \\in [0,1]$ is given by:\n$$\n\\mu_{t} = \\frac{1}{4}\\,\\delta_{-t} + \\frac{1}{4}\\,\\delta_{2t} + \\frac{1}{4}\\,\\delta_{3-t} + \\frac{1}{4}\\,\\delta_{3+2t}\n$$\n\n**Step 3: Compute $W_{2}(\\mu_{t}, \\mu_{1/3})$**\n\nWe need to find the Wasserstein distance between $\\mu_{t}$ and $\\mu_{s}$ for $s = \\frac{1}{3}$. First, let's write down $\\mu_{1/3}$:\n$$\n\\mu_{1/3} = \\frac{1}{4}\\,\\delta_{-1/3} + \\frac{1}{4}\\,\\delta_{2/3} + \\frac{1}{4}\\,\\delta_{3-1/3} + \\frac{1}{4}\\,\\delta_{3+2/3} = \\frac{1}{4}\\,\\delta_{-1/3} + \\frac{1}{4}\\,\\delta_{2/3} + \\frac{1}{4}\\,\\delta_{8/3} + \\frac{1}{4}\\,\\delta_{11/3}\n$$\nBoth $\\mu_{t}$ and $\\mu_{1/3}$ are discrete measures with four atoms of equal weight $\\frac{1}{4}$. To compute the $W_{2}$ distance, we again use the monotone rearrangement principle. We must order the support points of each measure.\n\nThe support points of $\\mu_{t}$ are $x_1(t)=-t$, $x_2(t)=2t$, $x_3(t)=3-t$, and $x_4(t)=3+2t$. For $t \\in (0,1)$, we have $-t < 2t < 3-t < 3+2t$.\nThe support points of $\\mu_{1/3}$ are $y_1=-1/3$, $y_2=2/3$, $y_3=8/3$, and $y_4=11/3$.\n\nThe optimal coupling between $\\mu_{t}$ and $\\mu_{1/3}$ pairs the $i$-th ordered point of $\\mu_{t}$ with the $i$-th ordered point of $\\mu_{1/3}$. The squared $W_{2}$ distance is then the weighted sum of squared distances between these paired points:\n$$\nW_{2}(\\mu_{t}, \\mu_{1/3})^{2} = \\frac{1}{4}\\sum_{i=1}^{4} |x_i(t) - y_i|^2\n$$\nLet's compute the individual squared differences:\n\\begin{itemize}\n    \\item $|x_1(t) - y_1|^2 = |-t - (-1/3)|^2 = |\\frac{1}{3} - t|^2 = (t - \\frac{1}{3})^2$\n    \\item $|x_2(t) - y_2|^2 = |2t - 2/3|^2 = |2(t - \\frac{1}{3})|^2 = 4(t - \\frac{1}{3})^2$\n    \\item $|x_3(t) - y_3|^2 = |(3-t) - 8/3|^2 = |\\frac{9-8}{3} - t|^2 = |\\frac{1}{3} - t|^2 = (t - \\frac{1}{3})^2$\n    \\item $|x_4(t) - y_4|^2 = |(3+2t) - 11/3|^2 = |\\frac{9-11}{3} + 2t|^2 = |2t - \\frac{2}{3}|^2 = 4(t - \\frac{1}{3})^2$\n\\end{itemize}\nSumming these gives:\n$$\n\\sum_{i=1}^{4} |x_i(t) - y_i|^2 = (t - \\frac{1}{3})^2 + 4(t - \\frac{1}{3})^2 + (t - \\frac{1}{3})^2 + 4(t - \\frac{1}{3})^2 = 10(t - \\frac{1}{3})^2\n$$\nNow we substitute this back into the expression for the squared distance:\n$$\nW_{2}(\\mu_{t}, \\mu_{1/3})^{2} = \\frac{1}{4} \\left( 10(t - \\frac{1}{3})^2 \\right) = \\frac{5}{2}(t - \\frac{1}{3})^2\n$$\nTaking the square root, we obtain the final expression for the distance:\n$$\nW_{2}(\\mu_{t}, \\mu_{1/3}) = \\sqrt{\\frac{5}{2}(t - \\frac{1}{3})^2} = \\sqrt{\\frac{5}{2}} |t - \\frac{1}{3}|\n$$\nThis result is consistent with the general property of $W_2$-geodesics, which states that $W_{2}(\\mu_s, \\mu_t) = |s-t| W_{2}(\\mu_0, \\mu_1)$. Our calculation confirms this property without relying on it as a premise.", "answer": "$$\\boxed{\\sqrt{\\frac{5}{2}} \\left|t - \\frac{1}{3}\\right|}$$", "id": "3032182"}, {"introduction": "This final practice bridges the gap between optimal transport and modern geometric analysis by exploring the concept of synthetic Ricci curvature. The Bakryâ€“Ã‰mery curvature-dimension condition, CD(K,N), generalizes the notion of curvature to metric measure spaces where classical differential geometry does not apply. This exercise invites you to compute the curvature parameters for the fundamental example of the Gaussian measure space, revealing how analytic tools provide powerful geometric insights [@problem_id:3032188].", "problem": "Let $(\\mathbb{R}^n, d, \\gamma_n)$ be the metric measure space where $d$ is the Euclidean distance and $\\gamma_n$ is the Gaussian probability measure with density $(2\\pi)^{-n/2}\\exp(-|x|^2/2)$ with respect to the Lebesgue measure. Consider the Ornsteinâ€“Uhlenbeck operator $L$ acting on smooth functions $f \\in C^{\\infty}(\\mathbb{R}^n)$ by $L f = \\Delta f - \\langle x, \\nabla f \\rangle$, where $\\Delta$ is the Euclidean Laplacian, $\\nabla$ is the Euclidean gradient, and $\\langle \\cdot,\\cdot \\rangle$ is the Euclidean inner product. Define the carrÃ© du champ operator $\\Gamma$ by\n$$\n\\Gamma(f,g) \\coloneqq \\frac{1}{2}\\big(L(fg) - f\\,L g - g\\,L f\\big), \\quad \\Gamma(f) \\coloneqq \\Gamma(f,f),\n$$\nand the iterated carrÃ© du champ by\n$$\n\\Gamma_2(f) \\coloneqq \\frac{1}{2}\\big(L\\,\\Gamma(f) - 2\\,\\Gamma(f, L f)\\big).\n$$\nThe Bakryâ€“Ã‰mery curvature-dimension condition CD(K,N) with parameters $K \\in \\mathbb{R}$ and $N \\in (1,\\infty]$ is the pointwise inequality that requires for all smooth functions $f$,\n$$\n\\Gamma_2(f) \\;\\ge\\; K\\,\\Gamma(f) \\;+\\; \\frac{1}{N}\\,\\big(L f\\big)^2,\n$$\nwith the convention that when $N=\\infty$ the last term is omitted.\n\nStarting from the above definitions and using only standard multivariable calculus identities, compute explicit formulas for $\\Gamma(f,g)$ and $\\Gamma_2(f)$ for the operator $L$ on $(\\mathbb{R}^n, \\gamma_n)$. Then determine the largest curvature lower bound $K$ and the smallest dimension parameter $N \\in (n,\\infty]$ (allowing $N=\\infty$) such that CD(K,N) holds pointwise for all smooth $f$. Report your final answer as the pair $(K,N)$ written as a row matrix using the $\\mathrm{pmatrix}$ notation. No numerical rounding is required.", "solution": "The user has requested the computation of the carrÃ© du champ operators and the determination of the optimal Bakryâ€“Ã‰mery curvature-dimension parameters for the Ornsteinâ€“Uhlenbeck operator on Gaussian space.\n\nThe problem statement is validated as follows:\n- **Givens**: The metric measure space is $(\\mathbb{R}^n, d, \\gamma_n)$ where $d$ is Euclidean distance and $\\gamma_n$ is the standard Gaussian measure. The Ornsteinâ€“Uhlenbeck operator is $L f = \\Delta f - \\langle x, \\nabla f \\rangle$. The operators $\\Gamma(f,g)$, $\\Gamma(f)$, and $\\Gamma_2(f)$ are defined, as is the $\\mathrm{CD}(K,N)$ condition: $\\Gamma_2(f) \\ge K\\,\\Gamma(f) + \\frac{1}{N}\\,(L f)^2$. The parameters must satisfy $K \\in \\mathbb{R}$ and $N \\in (n,\\infty]$.\n- **Validation**: The problem is scientifically grounded, well-posed, and objective. It is a standard and fundamental exercise in the theory of Bakryâ€“Ã‰mery curvature. All terms are formally defined, and the premises are mathematically sound. The problem is valid.\n\nWe proceed with the solution.\n\nFirst, we compute an explicit formula for the carrÃ© du champ operator $\\Gamma(f,g)$. By definition,\n$$\n\\Gamma(f,g) \\coloneqq \\frac{1}{2}\\big(L(fg) - f\\,L g - g\\,L f\\big)\n$$\nWe substitute the definition of the operator $L h = \\Delta h - \\langle x, \\nabla h \\rangle$ into this expression. To do so, we need expressions for $L(fg)$. We use the standard product rules from multivariable calculus:\n- Gradient of a product: $\\nabla(fg) = f\\nabla g + g\\nabla f$.\n- Laplacian of a product: $\\Delta(fg) = \\nabla \\cdot \\nabla(fg) = \\nabla \\cdot (f\\nabla g + g\\nabla f) = (\\nabla f \\cdot \\nabla g + f\\Delta g) + (\\nabla g \\cdot \\nabla f + g\\Delta f) = f\\Delta g + g\\Delta f + 2\\langle\\nabla f, \\nabla g\\rangle$.\n\nNow, we compute $L(fg)$:\n$$\nL(fg) = \\Delta(fg) - \\langle x, \\nabla(fg) \\rangle = \\big( f\\Delta g + g\\Delta f + 2\\langle\\nabla f, \\nabla g\\rangle \\big) - \\langle x, f\\nabla g + g\\nabla f \\rangle\n$$\n$$\nL(fg) = f\\Delta g + g\\Delta f + 2\\langle\\nabla f, \\nabla g\\rangle - f\\langle x, \\nabla g \\rangle - g\\langle x, \\nabla f \\rangle\n$$\nNext, we expand the terms $f\\,Lg$ and $g\\,Lf$:\n$$\nf\\,Lg = f(\\Delta g - \\langle x, \\nabla g \\rangle) = f\\Delta g - f\\langle x, \\nabla g \\rangle\n$$\n$$\ng\\,Lf = g(\\Delta f - \\langle x, \\nabla f \\rangle) = g\\Delta f - g\\langle x, \\nabla f \\rangle\n$$\nWe substitute these expressions back into the definition of $\\Gamma(f,g)$:\n$$\n2\\,\\Gamma(f,g) = \\big( f\\Delta g + g\\Delta f + 2\\langle\\nabla f, \\nabla g\\rangle - f\\langle x, \\nabla g \\rangle - g\\langle x, \\nabla f \\rangle \\big) - \\big(f\\Delta g - f\\langle x, \\nabla g \\rangle\\big) - \\big(g\\Delta f - g\\langle x, \\nabla f \\rangle\\big)\n$$\nThe terms $f\\Delta g$, $g\\Delta f$, $f\\langle x, \\nabla g \\rangle$, and $g\\langle x, \\nabla f \\rangle$ all cancel out, leaving:\n$$\n2\\,\\Gamma(f,g) = 2\\langle\\nabla f, \\nabla g\\rangle\n$$\nThus, the explicit formula for the carrÃ© du champ is:\n$$\n\\Gamma(f,g) = \\langle\\nabla f, \\nabla g\\rangle\n$$\nAnd for $g=f$, we have $\\Gamma(f) \\coloneqq \\Gamma(f,f)$:\n$$\n\\Gamma(f) = \\langle\\nabla f, \\nabla f\\rangle = |\\nabla f|^2\n$$\n\nNext, we compute the iterated carrÃ© du champ operator $\\Gamma_2(f)$. By definition,\n$$\n\\Gamma_2(f) \\coloneqq \\frac{1}{2}\\big(L\\,\\Gamma(f) - 2\\,\\Gamma(f, L f)\\big)\n$$\nWe compute the two terms separately. First, $L\\,\\Gamma(f) = L(|\\nabla f|^2)$.\nWe need the gradient and Laplacian of $|\\nabla f|^2 = \\sum_{i=1}^n (\\partial_i f)^2$. The $k$-th component of the gradient is:\n$$\n(\\nabla|\\nabla f|^2)_k = \\partial_k \\sum_{i=1}^n (\\partial_i f)^2 = \\sum_{i=1}^n 2(\\partial_i f)(\\partial_{ki} f) = 2 \\sum_{i=1}^n H_{ki}(f) (\\partial_i f)\n$$\nwhere $H(f)$ is the Hessian matrix of $f$, with entries $H_{ij}(f) = \\partial_{ij} f$. In vector notation, this is $\\nabla(|\\nabla f|^2) = 2 H(f) \\nabla f$.\nThe Laplacian is the divergence of the gradient:\n$$\n\\Delta(|\\nabla f|^2) = \\nabla \\cdot (2 H(f) \\nabla f) = \\sum_{k=1}^n \\partial_k \\left( 2 \\sum_{i=1}^n (\\partial_i f)(\\partial_{ki} f) \\right)\n$$\n$$\n= 2 \\sum_{k,i=1}^n \\left( (\\partial_{ki} f)(\\partial_{ki} f) + (\\partial_i f)(\\partial_{kki} f) \\right)\n$$\nThe first term is $2\\sum_{k,i}(\\partial_{ki}f)^2 = 2|H(f)|_{HS}^2$, where $|\\cdot|_{HS}$ is the Hilbert-Schmidt norm. The second term, by interchanging order of summation and differentiation (Clairaut's theorem for smooth functions), is $2\\sum_{i}(\\partial_i f) \\partial_i (\\sum_k \\partial_{kk}f) = 2\\langle \\nabla f, \\nabla(\\Delta f) \\rangle$.\nSo, $\\Delta(|\\nabla f|^2) = 2|H(f)|_{HS}^2 + 2\\langle \\nabla f, \\nabla(\\Delta f) \\rangle$.\nNow we can write $L(\\Gamma(f))$:\n$$\nL(\\Gamma(f)) = L(|\\nabla f|^2) = \\Delta(|\\nabla f|^2) - \\langle x, \\nabla(|\\nabla f|^2) \\rangle = 2|H(f)|_{HS}^2 + 2\\langle \\nabla f, \\nabla(\\Delta f) \\rangle - \\langle x, 2 H(f) \\nabla f \\rangle\n$$\nThe second term we need for $\\Gamma_2(f)$ is $\\Gamma(f, L f)$. Using our formula $\\Gamma(f,g) = \\langle \\nabla f, \\nabla g \\rangle$, we have:\n$$\n\\Gamma(f, L f) = \\langle \\nabla f, \\nabla(L f) \\rangle\n$$\nWe compute $\\nabla(Lf) = \\nabla(\\Delta f - \\langle x, \\nabla f \\rangle) = \\nabla(\\Delta f) - \\nabla(\\langle x, \\nabla f \\rangle)$.\nThe $k$-th component of $\\nabla(\\langle x, \\nabla f \\rangle)$ is $\\partial_k(\\sum_j x_j \\partial_j f) = \\sum_j (\\delta_{kj}\\partial_j f + x_j \\partial_{kj} f) = \\partial_k f + \\sum_j x_j H_{kj}(f)$. In vector form, $\\nabla(\\langle x, \\nabla f \\rangle) = \\nabla f + H(f)x$.\nSo, $\\nabla(Lf) = \\nabla(\\Delta f) - \\nabla f - H(f)x$.\nSubstituting this into the expression for $\\Gamma(f, L f)$:\n$$\n\\Gamma(f, L f) = \\langle \\nabla f, \\nabla(\\Delta f) - \\nabla f - H(f)x \\rangle = \\langle \\nabla f, \\nabla(\\Delta f) \\rangle - |\\nabla f|^2 - \\langle \\nabla f, H(f)x \\rangle\n$$\nNow we assemble $\\Gamma_2(f)$:\n$$\n2\\Gamma_2(f) = L(\\Gamma(f)) - 2\\Gamma(f, L f)\n$$\n$$\n= \\left( 2|H(f)|_{HS}^2 + 2\\langle \\nabla f, \\nabla(\\Delta f) \\rangle - 2\\langle x, H(f) \\nabla f \\rangle \\right) - 2\\left( \\langle \\nabla f, \\nabla(\\Delta f) \\rangle - |\\nabla f|^2 - \\langle \\nabla f, H(f)x \\rangle \\right)\n$$\nSince the Hessian matrix $H(f)$ is symmetric, $\\langle x, H(f) \\nabla f \\rangle = \\langle H(f)x, \\nabla f \\rangle = \\langle \\nabla f, H(f)x \\rangle$. Thus, these terms cancel. The terms involving $\\langle \\nabla f, \\nabla(\\Delta f) \\rangle$ also cancel.\n$$\n2\\Gamma_2(f) = 2|H(f)|_{HS}^2 - (-2|\\nabla f|^2) = 2|H(f)|_{HS}^2 + 2|\\nabla f|^2\n$$\nThe explicit formula for the iterated carrÃ© du champ is:\n$$\n\\Gamma_2(f) = |H(f)|_{HS}^2 + |\\nabla f|^2\n$$\nFinally, we determine the optimal parameters $K$ and $N$ for the CD(K,N) condition, which is the pointwise inequality:\n$$\n\\Gamma_2(f) \\ge K\\,\\Gamma(f) + \\frac{1}{N}\\,(L f)^2\n$$\nSubstituting our computed expressions:\n$$\n|H(f)|_{HS}^2 + |\\nabla f|^2 \\ge K\\,|\\nabla f|^2 + \\frac{1}{N}\\,(L f)^2\n$$\nRearranging the terms, we obtain the inequality that must hold for all smooth functions $f$ at all points $x \\in \\mathbb{R}^n$:\n$$\n(1-K)|\\nabla f|^2 + |H(f)|_{HS}^2 - \\frac{1}{N}\\,(L f)^2 \\ge 0\n$$\nTo find the sharpest parameters, we test this inequality with specific functions. Consider a non-constant linear function $f(x) = \\langle a, x \\rangle$ for a fixed non-zero vector $a \\in \\mathbb{R}^n$. For this function, we compute:\n- $\\nabla f = a$, so $|\\nabla f|^2 = |a|^2$.\n- $H(f) = 0$, the zero matrix, so $|H(f)|_{HS}^2 = 0$.\n- $\\Delta f = 0$.\n- $L f = \\Delta f - \\langle x, \\nabla f \\rangle = 0 - \\langle x, a \\rangle = -\\langle x, a \\rangle$.\n\nSubstituting these into the inequality gives:\n$$\n(1-K)|a|^2 + 0 - \\frac{1}{N}\\,(-\\langle x, a \\rangle)^2 \\ge 0\n$$\n$$\n(1-K)|a|^2 \\ge \\frac{1}{N}\\,\\langle x, a \\rangle^2\n$$\nThis inequality must hold for all $x \\in \\mathbb{R}^n$. The left-hand side is a constant for a given $f$. The right-hand side, however, depends on $x$. Since $a \\neq 0$, the term $\\langle x, a \\rangle^2$ is unbounded as $|x| \\to \\infty$. Given that $N \\in (n, \\infty]$, $1/N$ is non-negative. If $N$ were finite, $1/N > 0$, and the right-hand side could be made arbitrarily large, which would violate the inequality. Thus, for the inequality to hold for all $x$, we must have the coefficient of the $x$-dependent term equal to zero. This implies $1/N = 0$, so we must have $N=\\infty$. This is the \"smallest\" value in the allowed set $(n, \\infty]$ that can satisfy the condition.\n\nWith $N=\\infty$, the term $\\frac{1}{N}(Lf)^2$ vanishes, and the inequality simplifies to:\n$$\n(1-K)|\\nabla f|^2 + |H(f)|_{HS}^2 \\ge 0\n$$\nThis must hold for all smooth functions $f$. Using our test function $f(x)=\\langle a, x \\rangle$ again, for which $|\\nabla f|^2=|a|^2$ and $H(f)=0$, the inequality becomes:\n$$\n(1-K)|a|^2 \\ge 0\n$$\nSince this must be true for any choice of vector $a \\neq 0$, we must have the coefficient $(1-K) \\ge 0$, which implies $K \\le 1$. To find the largest possible curvature lower bound, we take the supremum, which is $K=1$.\n\nWe now verify if the pair $(K,N)=(1, \\infty)$ satisfies the condition for all smooth functions $f$. The inequality becomes:\n$$\n(1-1)|\\nabla f|^2 + |H(f)|_{HS}^2 \\ge 0\n$$\n$$\n|H(f)|_{HS}^2 \\ge 0\n$$\nThe Hilbert-Schmidt norm squared of the Hessian matrix is given by $|H(f)|_{HS}^2 = \\sum_{i,j=1}^n (\\partial_{ij}f)^2$. As a sum of squares of real numbers, this quantity is always non-negative. Therefore, the condition is satisfied for all smooth functions $f$.\n\nThe largest value for $K$ is $1$ and the corresponding smallest value for $N \\in (n, \\infty]$ is $\\infty$. The pair is $(K,N) = (1, \\infty)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 & \\infty\n\\end{pmatrix}\n}\n$$", "id": "3032188"}]}