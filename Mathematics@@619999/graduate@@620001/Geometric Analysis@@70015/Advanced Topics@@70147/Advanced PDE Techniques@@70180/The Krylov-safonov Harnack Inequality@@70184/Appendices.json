{"hands_on_practices": [{"introduction": "The theory of elliptic partial differential equations often relies on the construction of \"barrier\" functions to control the behavior of solutions. This first exercise provides hands-on practice with this fundamental technique. You will see how the uniform ellipticity constants, $\\lambda$ and $\\Lambda$, directly constrain the action of the operator $L$ on a simple quadratic paraboloid, allowing you to build explicit subsolutions and supersolutions [@problem_id:3035823]. Mastering this calculation is a key step toward understanding the proofs of the Aleksandrov-Bakelman-Pucci maximum principle and the Krylov-Safonov results.", "problem": "Let $n \\geq 2$ and let $B_{r}(x_{0}) \\subset \\mathbb{R}^{n}$ be a ball. Consider a linear second-order nondivergence-form elliptic operator\n$$\nL u(x) = a^{ij}(x)\\,\\partial_{ij} u(x),\n$$\nwith bounded measurable symmetric coefficients $a^{ij}(x) = a^{ji}(x)$ that are uniformly elliptic with constants $0 < \\lambda \\leq \\Lambda < \\infty$ in the sense that for every $x \\in B_{r}(x_{0})$ and every $\\xi \\in \\mathbb{R}^{n}$,\n$$\n\\lambda\\,|\\xi|^{2} \\leq a^{ij}(x)\\,\\xi_{i}\\,\\xi_{j} \\leq \\Lambda\\,|\\xi|^{2}.\n$$\nDefine the quadratic function $\\phi(x) = A\\,|x - x_{0}|^{2}$ with parameter $A \\in \\mathbb{R}$. Using only the uniform ellipticity bounds and basic linear algebra, determine:\n- the smallest value $A_{\\mathrm{sub}} \\geq 0$ such that $\\phi$ is a subsolution of the partial differential equation (PDE) $L u = 1$ in $B_{r}(x_{0})$ in the classical sense, that is,\n$$\nL \\phi(x) \\geq 1 \\quad \\text{for all } x \\in B_{r}(x_{0}) \\text{ and for all coefficient fields } a^{ij} \\text{ satisfying the above bounds};\n$$\n- the largest value $A_{\\mathrm{super}} \\geq 0$ such that $\\phi$ is a supersolution of the PDE $L u = 1$ in $B_{r}(x_{0})$ in the classical sense, that is,\n$$\nL \\phi(x) \\leq 1 \\quad \\text{for all } x \\in B_{r}(x_{0}) \\text{ and for all coefficient fields } a^{ij} \\text{ satisfying the above bounds}.\n$$\nExpress your final answer as a single row vector $\\big(A_{\\mathrm{sub}},\\,A_{\\mathrm{super}}\\big)$ in closed form in terms of $n$, $\\lambda$, and $\\Lambda$. No numerical approximation is required.", "solution": "The problem requires the determination of parameters $A_{\\mathrm{sub}}$ and $A_{\\mathrm{super}}$ for a quadratic function $\\phi(x)$ to be a classical subsolution and supersolution, respectively, to the partial differential equation $L u = 1$.\n\nLet the given function be $\\phi(x) = A\\,|x - x_{0}|^{2}$. For simplicity and without loss of generality, we can center our coordinate system at $x_{0}$, so that $\\phi(x) = A\\,|x|^{2} = A \\sum_{k=1}^{n} x_{k}^{2}$. The derivatives of $\\phi$ are independent of the choice of origin $x_{0}$.\n\nFirst, we compute the first and second partial derivatives of $\\phi(x)$ with respect to the coordinates $x_j$.\nThe first partial derivatives are:\n$$\n\\partial_{j} \\phi(x) = \\frac{\\partial}{\\partial x_{j}} \\left( A \\sum_{k=1}^{n} x_{k}^{2} \\right) = 2A\\,x_{j}\n$$\nThe second partial derivatives, which form the components of the Hessian matrix of $\\phi$, are:\n$$\n\\partial_{ij} \\phi(x) = \\frac{\\partial}{\\partial x_{i}} (2A\\,x_{j}) = 2A\\,\\delta_{ij}\n$$\nwhere $\\delta_{ij}$ is the Kronecker delta, which is $1$ if $i=j$ and $0$ if $i \\neq j$.\n\nNow, we apply the operator $L u(x) = a^{ij}(x)\\,\\partial_{ij} u(x)$ to our function $\\phi(x)$.\n$$\nL \\phi(x) = \\sum_{i,j=1}^{n} a^{ij}(x)\\,\\partial_{ij} \\phi(x) = \\sum_{i,j=1}^{n} a^{ij}(x)\\,(2A\\,\\delta_{ij})\n$$\nThe sum simplifies due to the Kronecker delta:\n$$\nL \\phi(x) = 2A \\sum_{i=1}^{n} a^{ii}(x)\n$$\nThe expression $\\sum_{i=1}^{n} a^{ii}(x)$ is the trace of the coefficient matrix $a(x) = [a^{ij}(x)]$, denoted as $\\mathrm{tr}(a(x))$. Thus, we have:\n$$\nL \\phi(x) = 2A\\,\\mathrm{tr}(a(x))\n$$\n\nThe coefficient matrix $a(x)$ is symmetric and uniformly elliptic. The ellipticity condition, $\\lambda\\,|\\xi|^{2} \\leq a^{ij}(x)\\,\\xi_{i}\\,\\xi_{j} \\leq \\Lambda\\,|\\xi|^{2}$ for all $\\xi \\in \\mathbb{R}^{n}$, is equivalent to stating that the eigenvalues of the matrix $a(x)$, let's call them $\\mu_{1}(x), \\mu_{2}(x), \\dots, \\mu_{n}(x)$, are all contained in the interval $[\\lambda, \\Lambda]$. That is, for all $k \\in \\{1, 2, \\dots, n\\}$, we have $0 < \\lambda \\leq \\mu_{k}(x) \\leq \\Lambda < \\infty$.\n\nThe trace of a matrix is the sum of its eigenvalues, so $\\mathrm{tr}(a(x)) = \\sum_{k=1}^{n} \\mu_{k}(x)$. We can therefore bound the trace using the bounds on the eigenvalues:\n$$\nn\\lambda = \\sum_{k=1}^{n} \\lambda \\leq \\sum_{k=1}^{n} \\mu_{k}(x) \\leq \\sum_{k=1}^{n} \\Lambda = n\\Lambda\n$$\nSo, for any coefficient matrix $a(x)$ satisfying the uniform ellipticity condition, its trace must satisfy $n\\lambda \\leq \\mathrm{tr}(a(x)) \\leq n\\Lambda$. These bounds on the trace are sharp. The minimum value $n\\lambda$ is achieved for the matrix $a(x) = \\lambda I_{n}$ (where $I_n$ is the $n \\times n$ identity matrix), and the maximum value $n\\Lambda$ is achieved for $a(x) = \\Lambda I_{n}$. Both of these choices for $a(x)$ satisfy the given ellipticity condition.\n\nWith this result, we can now determine $A_{\\mathrm{sub}}$ and $A_{\\mathrm{super}}$.\n\n**Determination of $A_{\\mathrm{sub}}$**\n\nThe function $\\phi$ is a subsolution if $L \\phi(x) \\geq 1$ for all $x \\in B_{r}(x_{0})$ and for all valid coefficient fields $a^{ij}$. Substituting our expression for $L\\phi(x)$, we get:\n$$\n2A\\,\\mathrm{tr}(a(x)) \\geq 1\n$$\nWe are seeking the smallest value $A_{\\mathrm{sub}} \\geq 0$ for which this inequality holds for *every* permissible matrix $a(x)$. Since we are looking for $A \\ge 0$ and $\\mathrm{tr}(a(x)) > 0$, we can rearrange the inequality to:\n$$\nA \\geq \\frac{1}{2\\,\\mathrm{tr}(a(x))}\n$$\nFor this to hold for all valid $a(x)$, $A$ must be greater than or equal to the maximum possible value of the right-hand side. The maximum of $\\frac{1}{2\\,\\mathrm{tr}(a(x))}$ corresponds to the minimum of $\\mathrm{tr}(a(x))$.\n$$\nA \\geq \\sup_{a(x)} \\left( \\frac{1}{2\\,\\mathrm{tr}(a(x))} \\right) = \\frac{1}{2\\,\\inf_{a(x)} \\mathrm{tr}(a(x))}\n$$\nAs established, the minimum value of the trace is $\\inf_{a(x)} \\mathrm{tr}(a(x)) = n\\lambda$.\nTherefore, we require:\n$$\nA \\geq \\frac{1}{2n\\lambda}\n$$\nThe smallest non-negative value $A$ that satisfies this condition is the lower bound itself. Thus,\n$$\nA_{\\mathrm{sub}} = \\frac{1}{2n\\lambda}\n$$\n\n**Determination of $A_{\\mathrm{super}}$**\n\nThe function $\\phi$ is a supersolution if $L \\phi(x) \\leq 1$ for all $x \\in B_{r}(x_{0})$ and for all valid coefficient fields $a^{ij}$. This condition is:\n$$\n2A\\,\\mathrm{tr}(a(x)) \\leq 1\n$$\nAgain, assuming $A \\ge 0$, we can write:\n$$\nA \\leq \\frac{1}{2\\,\\mathrm{tr}(a(x))}\n$$\nFor this to hold for all valid $a(x)$, $A$ must be less than or equal to the minimum possible value of the right-hand side. The minimum of $\\frac{1}{2\\,\\mathrm{tr}(a(x))}$ corresponds to the maximum of $\\mathrm{tr}(a(x))$.\n$$\nA \\leq \\inf_{a(x)} \\left( \\frac{1}{2\\,\\mathrm{tr}(a(x))} \\right) = \\frac{1}{2\\,\\sup_{a(x)} \\mathrm{tr}(a(x))}\n$$\nAs established, the maximum value of the trace is $\\sup_{a(x)} \\mathrm{tr}(a(x)) = n\\Lambda$.\nTherefore, we require:\n$$\nA \\leq \\frac{1}{2n\\Lambda}\n$$\nThe largest non-negative value $A$ that satisfies this condition is the upper bound itself. Thus,\n$$\nA_{\\mathrm{super}} = \\frac{1}{2n\\Lambda}\n$$\n\nThe required values are $A_{\\mathrm{sub}} = \\frac{1}{2n\\lambda}$ and $A_{\\mathrm{super}} = \\frac{1}{2n\\Lambda}$. The final answer is to be expressed as a single row vector $(A_{\\mathrm{sub}}, A_{\\mathrm{super}})$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2n\\lambda} & \\frac{1}{2n\\Lambda} \\end{pmatrix}}\n$$", "id": "3035823"}, {"introduction": "A cornerstone achievement of the Krylov-Safonov theory is proving that solutions to nondivergence-form elliptic equations are Hölder continuous, a significant regularity result. This practice demonstrates the elegant and powerful iteration argument that transforms a local oscillation decay into a global continuity estimate. By systematically applying the oscillation lemma on a sequence of shrinking balls, you will derive the precise Hölder exponent $\\alpha$, revealing the quantitative nature of this profound connection [@problem_id:3035837].", "problem": "Let $u$ be a bounded solution of a uniformly elliptic nondivergence-form partial differential equation (PDE) in the unit ball $B_{1} \\subset \\mathbb{R}^{n}$ with measurable coefficients and ellipticity constants bounded between $\\lambda$ and $\\Lambda$, with $0<\\lambda \\leq \\Lambda < \\infty$. Assume the Krylov-Safonov oscillation lemma holds in the following quantitative form: there exist universal constants $0<\\theta<1$ and $0<\\gamma<1$, depending only on $n$, $\\lambda$, and $\\Lambda$, such that for every ball $B_{r}(x_{0}) \\subset B_{1}$,\n$$\n\\operatorname{osc}_{B_{\\theta r}(x_{0})} u \\leq (1-\\gamma)\\,\\operatorname{osc}_{B_{r}(x_{0})} u,\n$$\nwhere $\\operatorname{osc}_{E} u := \\sup_{E} u - \\inf_{E} u$.\n\nStarting only from this oscillation lemma and basic properties of oscillation and scaling, construct an iteration scheme on the nested balls $B_{r_{k}}(x_{0})$ with $r_{k} := \\theta^{k} r_{0}$, and derive a Hölder-type decay of oscillation of the form\n$$\n\\operatorname{osc}_{B_{\\rho}(x_{0})} u \\leq C\\left(\\frac{\\rho}{r_{0}}\\right)^{\\alpha} \\operatorname{osc}_{B_{r_{0}}(x_{0})} u \\quad \\text{for all } 0<\\rho\\le r_{0},\n$$\nwith a universal constant $C \\ge 1$ independent of $u$, $x_{0}$, and $r_{0}$. Determine, by matching the discrete decay with the power decay, an explicit analytical expression for the Hölder exponent $\\alpha$ as a function of the oscillation decay parameter $\\gamma$ and the radius contraction factor $\\theta$.\n\nYour final answer must be a single closed-form expression for $\\alpha$ in terms of $\\gamma$ and $\\theta$.", "solution": "The problem provides the quantitative form of the Krylov-Safonov oscillation lemma for a bounded solution $u$ to a certain class of elliptic PDEs. For any ball $B_{r}(x_{0}) \\subset B_{1}$, the lemma states:\n$$\n\\operatorname{osc}_{B_{\\theta r}(x_{0})} u \\leq (1-\\gamma)\\,\\operatorname{osc}_{B_{r}(x_{0})} u\n$$\nwhere $\\operatorname{osc}_{E} u := \\sup_{E} u - \\inf_{E} u$. The constants $\\theta$ and $\\gamma$ are universal, with $0 < \\theta < 1$ and $0 < \\gamma < 1$.\n\nOur goal is to derive the Hölder exponent $\\alpha$ in the decay estimate:\n$$\n\\operatorname{osc}_{B_{\\rho}(x_{0})} u \\leq C\\left(\\frac{\\rho}{r_{0}}\\right)^{\\alpha} \\operatorname{osc}_{B_{r_{0}}(x_{0})} u \\quad \\text{for all } 0<\\rho\\le r_{0}\n$$\n\nWe begin by constructing an iteration scheme based on the oscillation lemma. Let us fix a ball $B_{r_{0}}(x_{0}) \\subset B_{1}$. We define a sequence of nested balls $B_{r_{k}}(x_{0})$ with radii $r_{k} = \\theta^{k} r_{0}$ for integers $k \\geq 0$.\n\nLet $\\omega(r) = \\operatorname{osc}_{B_{r}(x_{0})} u$. The oscillation lemma can be written as $\\omega(\\theta r) \\leq (1-\\gamma)\\omega(r)$. We apply this relation iteratively.\nFor $k=1$, we have $r_{1} = \\theta r_{0}$. The lemma directly gives:\n$$\n\\omega(r_{1}) = \\omega(\\theta r_{0}) \\leq (1-\\gamma)\\omega(r_{0})\n$$\nFor $k=2$, we have $r_{2} = \\theta r_{1} = \\theta^{2} r_{0}$. Applying the lemma again:\n$$\n\\omega(r_{2}) = \\omega(\\theta r_{1}) \\leq (1-\\gamma)\\omega(r_{1}) \\leq (1-\\gamma)(1-\\gamma)\\omega(r_{0}) = (1-\\gamma)^{2}\\omega(r_{0})\n$$\nBy induction, for any integer $k \\geq 0$, we establish the discrete decay of oscillation:\n$$\n\\operatorname{osc}_{B_{r_{k}}(x_{0})} u \\equiv \\omega(r_{k}) = \\omega(\\theta^{k} r_{0}) \\leq (1-\\gamma)^{k} \\omega(r_{0}) = (1-\\gamma)^{k} \\operatorname{osc}_{B_{r_{0}}(x_{0})} u\n$$\n\nThe problem asks us to determine the exponent $\\alpha$ by matching this discrete decay with the desired continuous power-law decay. The continuous decay form is expected to hold for any radius $\\rho \\in (0, r_{0}]$. A natural consistency requirement is that for the specific radii $r_k = \\theta^k r_0$ in our sequence, the continuous form should approximate or bound the discrete decay.\n\nLet us set $\\rho = r_{k} = \\theta^{k} r_{0}$ in the target inequality. The ratio $\\rho/r_{0}$ becomes:\n$$\n\\frac{\\rho}{r_{0}} = \\frac{\\theta^{k} r_{0}}{r_{0}} = \\theta^{k}\n$$\nSubstituting this into the power-law decay form, we get:\n$$\n\\operatorname{osc}_{B_{\\theta^{k}r_{0}}(x_{0})} u \\leq C \\left(\\theta^{k}\\right)^{\\alpha} \\operatorname{osc}_{B_{r_{0}}(x_{0})} u = C \\, \\theta^{k\\alpha} \\operatorname{osc}_{B_{r_{0}}(x_{0})} u\n$$\nWe compare this with the result from our iteration:\n$$\n\\operatorname{osc}_{B_{\\theta^{k}r_{0}}(x_{0})} u \\leq (1-\\gamma)^{k} \\operatorname{osc}_{B_{r_{0}}(x_{0})} u\n$$\nIgnoring the constant $C$ for a moment (as it does not affect the exponent), we match the decay factors to find the relationship between $\\gamma$, $\\theta$, and $\\alpha$:\n$$\n(1-\\gamma)^{k} = \\theta^{k\\alpha}\n$$\nTaking the $k$-th root of both sides, we get:\n$$\n1 - \\gamma = \\theta^{\\alpha}\n$$\nTo solve for $\\alpha$, we take the natural logarithm of both sides of the equation:\n$$\n\\ln(1-\\gamma) = \\ln(\\theta^{\\alpha})\n$$\nUsing the property of logarithms $\\ln(x^{y}) = y \\ln(x)$, we have:\n$$\n\\ln(1-\\gamma) = \\alpha \\ln(\\theta)\n$$\nSince $0 < \\theta < 1$, we have $\\ln(\\theta) \\neq 0$, so we can divide by it to isolate $\\alpha$:\n$$\n\\alpha = \\frac{\\ln(1-\\gamma)}{\\ln(\\theta)}\n$$\nThis is the explicit analytical expression for the Hölder exponent $\\alpha$. Since $0 < \\gamma < 1$, we have $0 < 1-\\gamma < 1$, which implies $\\ln(1-\\gamma) < 0$. Similarly, $0 < \\theta < 1$ implies $\\ln(\\theta) < 0$. Therefore, $\\alpha$ is a ratio of two negative numbers, making it positive, as expected for a Hölder exponent.\n\nFor completeness, a more rigorous justification confirms this result. For any $\\rho \\in (0, r_{0})$, we can find a unique integer $k \\ge 1$ such that $\\theta^{k}r_{0} \\le \\rho < \\theta^{k-1}r_{0}$. Then $\\operatorname{osc}_{B_{\\rho}} u \\le \\operatorname{osc}_{B_{\\theta^{k-1}r_{0}}} u \\le (1-\\gamma)^{k-1}\\operatorname{osc}_{B_{r_{0}}}u$. From the inequality $\\theta^{k}r_{0} \\le \\rho$, we derive $(1-\\gamma)^{k} \\le (\\rho/r_{0})^{\\alpha}$. This leads to $\\operatorname{osc}_{B_{\\rho}}u \\le (1-\\gamma)^{-1}(\\rho/r_{0})^{\\alpha}\\operatorname{osc}_{B_{r_{0}}}u$, which is the desired form with $C=(1-\\gamma)^{-1}$ and the same exponent $\\alpha$. This confirms that our matching procedure yields the correct exponent.\n\nThe final expression for $\\alpha$ depends only on the universal constants $\\gamma$ and $\\theta$.", "answer": "$$\n\\boxed{\\frac{\\ln(1-\\gamma)}{\\ln(\\theta)}}\n$$", "id": "3035837"}, {"introduction": "The Krylov-Safonov inequality provides a powerful but local comparison of a solution's values within a small ball. This final exercise introduces the \"Harnack chain,\" a robust technique for extending this local information across a much larger domain. You will build a sequence of overlapping balls to connect two distant points, and by iterating the local inequality along this chain, you will derive a global comparison estimate [@problem_id:3035832]. This practice showcases how local analytic control can be strategically scaled up to yield global insights.", "problem": "Let $n \\geq 2$ and $0<\\lambda \\leq \\Lambda$. Consider the uniformly elliptic nondivergence-form operator $L u := a^{ij}(x) \\partial_{ij} u$ with bounded measurable coefficients $a^{ij}$ satisfying $\\lambda I \\leq (a^{ij}(x)) \\leq \\Lambda I$ in the sense of symmetric matrices. Let $u$ be a positive solution to the partial differential equation (PDE) $L u = 0$ in the annular region\n$$\n\\Omega' := \\{ x \\in \\mathbb{R}^{n} : \\tfrac{\\rho}{2} < |x| < 2 R \\},\n$$\nwhere $0<\\rho<R$. Assume the local Krylov–Safonov Harnack property holds: there exists a constant $H \\geq 1$, depending only on $(n,\\lambda,\\Lambda)$, such that for every ball $B_{2r}(z) \\subset \\Omega'$ one has\n$$\n\\sup_{B_{r}(z)} u \\leq H \\inf_{B_{r}(z)} u.\n$$\nFix a parameter $0<\\theta \\leq \\tfrac{1}{4}$. For each $s \\in [\\rho, R]$, the ball $B_{2 \\theta s}(s e_{1})$ is contained in $\\Omega'$. Construct a Harnack chain of balls $\\{ B_{j} \\}_{j=0}^{k}$ along the radial segment in the direction $e_{1}$ by setting\n$$\nx_{j} := s_{j} e_{1}, \\quad s_{0} := \\rho, \\quad s_{j+1} := (1+\\tfrac{\\theta}{2}) s_{j}, \\quad r_{j} := \\theta s_{j}, \\quad B_{j} := B_{r_{j}}(x_{j}),\n$$\nand select the minimal integer $k$ such that $s_{k} \\geq R$. Using only the stated assumptions and properties, do the following:\n\n(1) Estimate the length of the Harnack chain by deriving a closed-form expression for the minimal $k$ in terms of $\\rho$, $R$, and $\\theta$.\n\n(2) Using the local Harnack property along the chain $\\{ B_{j} \\}_{j=0}^{k}$ and the fact that $B_{2 r_{j}}(x_{j}) \\subset \\Omega'$ for all $j$, derive an explicit multiplicative constant $C = C(\\rho, R, \\theta, H)$ such that\n$$\nu(\\rho e_{1}) \\leq C \\, u(R e_{1}).\n$$\n\nProvide your final answer as a single closed-form analytic expression for $C$ in terms of $H$, $\\rho$, $R$, and $\\theta$.", "solution": "The solution is developed in two parts as requested by the problem statement.\n\n**(1) Derivation of the minimal integer $k$**\n\nThe sequence of radial positions $\\{s_j\\}$ is defined by the geometric progression $s_0 = \\rho$ and $s_{j+1} = (1 + \\frac{\\theta}{2})s_j$. The explicit formula for $s_j$ is\n$$\ns_j = \\rho \\left(1 + \\frac{\\theta}{2}\\right)^j.\n$$\nThe integer $k$ is the minimal integer for which $s_k \\geq R$. We set up the inequality:\n$$\n\\rho \\left(1 + \\frac{\\theta}{2}\\right)^k \\geq R\n$$\n$$\n\\left(1 + \\frac{\\theta}{2}\\right)^k \\geq \\frac{R}{\\rho}\n$$\nTaking the natural logarithm of both sides, which is a strictly increasing function, preserves the inequality:\n$$\nk \\ln\\left(1 + \\frac{\\theta}{2}\\right) \\geq \\ln\\left(\\frac{R}{\\rho}\\right)\n$$\nSince $0 < \\theta \\leq \\frac{1}{4}$, we have $1 + \\frac{\\theta}{2} > 1$, so $\\ln(1 + \\frac{\\theta}{2}) > 0$. We can divide by it without changing the direction of the inequality:\n$$\nk \\geq \\frac{\\ln\\left(\\frac{R}{\\rho}\\right)}{\\ln\\left(1 + \\frac{\\theta}{2}\\right)}\n$$\nSince $k$ must be an integer, the minimal integer $k$ satisfying this condition is the ceiling of the right-hand side:\n$$\nk = \\left\\lceil \\frac{\\ln(R/\\rho)}{\\ln(1+\\theta/2)} \\right\\rceil.\n$$\n\n**(2) Derivation of the multiplicative constant $C$**\n\nThe goal is to find a constant $C$ such that $u(\\rho e_1) \\leq C u(R e_1)$. We use the constructed Harnack chain to bridge the values of $u$ from the point $\\rho e_1$ to the point $R e_1$.\n\nFirst, we establish a relationship between $u(x_j)$ and $u(x_{j+1})$ for $j=0, 1, \\dots, k-1$.\nThe center of the ball $B_j$ is $x_j = s_j e_1$ and its radius is $r_j = \\theta s_j$. The center of the next ball in the chain is $x_{j+1} = s_{j+1} e_1 = (1 + \\frac{\\theta}{2}) s_j e_1$. The distance between the centers is\n$$\n|x_{j+1} - x_j| = s_{j+1} - s_j = \\left(1 + \\frac{\\theta}{2}\\right)s_j - s_j = \\frac{\\theta}{2} s_j.\n$$\nSince $\\frac{\\theta}{2}s_j < \\theta s_j = r_j$, the point $x_{j+1}$ lies inside the ball $B_j$.\n\nFor each $j \\in \\{0, 1, \\dots, k-1\\}$, we have $s_j < R$. Since $s_j \\geq \\rho$, $s_j \\in [\\rho, R]$. The problem statement guarantees that for such $s_j$, the ball $B_{2r_j}(x_j) = B_{2\\theta s_j}(s_j e_1)$ is contained in $\\Omega'$. This allows us to apply the local Harnack property on the ball $B_j = B_{r_j}(x_j)$:\n$$\n\\sup_{B_j} u \\leq H \\inf_{B_j} u.\n$$\nSince $x_j \\in B_j$ and $x_{j+1} \\in B_j$, we can write the following chain of inequalities:\n$$\nu(x_j) \\leq \\sup_{B_j} u \\leq H \\inf_{B_j} u \\leq H u(x_{j+1}).\n$$\nThis gives us the relation $u(x_j) \\leq H u(x_{j+1})$. Applying this relation iteratively from $j=0$ to $j=k-1$:\n$$\nu(x_0) \\leq H u(x_1) \\leq H^2 u(x_2) \\leq \\dots \\leq H^k u(x_k).\n$$\nSince $x_0 = \\rho e_1$ and $x_k = s_k e_1$, this becomes\n$$\nu(\\rho e_1) \\leq H^k u(s_k e_1).\n$$\n\nNext, we need to relate $u(s_k e_1)$ to $u(R e_1)$. Both points lie in the final region of our chain. Let's use the ball $B_k = B_{r_k}(x_k) = B_{\\theta s_k}(s_k e_1)$. For the Harnack property to apply to $B_k$, the ball $B_{2r_k}(x_k) = B_{2\\theta s_k}(s_k e_1)$ must be in $\\Omega'$.\nBy definition of $k$, we have $s_{k-1} < R \\leq s_k$. Also, $s_k = (1+\\frac{\\theta}{2})s_{k-1} < (1+\\frac{\\theta}{2})R$.\nLet's verify that the point $R e_1$ is in the ball $B_k$. The distance is\n$$\n|R e_1 - x_k| = |R - s_k| = s_k - R.\n$$\nWe need to show $s_k - R < r_k = \\theta s_k$. This is equivalent to $s_k(1-\\theta) < R$.\nUsing $s_k < (1+\\frac{\\theta}{2})R$, we check if $(1+\\frac{\\theta}{2})R(1-\\theta) < R$. This simplifies to $1 - \\theta + \\frac{\\theta}{2} - \\frac{\\theta^2}{2} < 1$, or $-\\frac{\\theta}{2} - \\frac{\\theta^2}{2} < 0$, which is true for $\\theta > 0$. Thus, $R e_1 \\in B_k$.\n\nNow we apply the Harnack inequality on $B_k$: $\\sup_{B_k} u \\leq H \\inf_{B_k} u$.\nSince both $s_k e_1 = x_k$ and $R e_1$ are in $B_k$, we have:\n$$\nu(s_k e_1) \\leq \\sup_{B_k} u \\leq H \\inf_{B_k} u \\leq H u(R e_1).\n$$\nThis gives the inequality $u(s_k e_1) \\leq H u(R e_1)$.\n\nFinally, we combine our two main inequalities:\n$$\nu(\\rho e_1) \\leq H^k u(s_k e_1) \\quad \\text{and} \\quad u(s_k e_1) \\leq H u(R e_1).\n$$\nThis yields\n$$\nu(\\rho e_1) \\leq H^k (H u(R e_1)) = H^{k+1} u(R e_1).\n$$\nThe constant $C$ is therefore $H^{k+1}$. Substituting the expression for $k$:\n$$\nC = H^{1+k} = H^{1 + \\left\\lceil \\frac{\\ln(R/\\rho)}{\\ln(1+\\theta/2)} \\right\\rceil}.\n$$\nThis is the explicit multiplicative constant $C$ in terms of $H$, $\\rho$, $R$, and $\\theta$.", "answer": "$$\\boxed{H^{1 + \\left\\lceil \\frac{\\ln(R/\\rho)}{\\ln(1+\\theta/2)} \\right\\rceil}}$$", "id": "3035832"}]}