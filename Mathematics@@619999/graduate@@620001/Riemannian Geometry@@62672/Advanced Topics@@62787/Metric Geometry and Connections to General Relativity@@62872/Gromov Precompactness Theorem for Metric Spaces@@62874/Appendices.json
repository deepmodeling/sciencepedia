{"hands_on_practices": [{"introduction": "The Gromov Precompactness Theorem provides conditions for a set of metric spaces to be precompact in the Gromov-Hausdorff topology, with uniform total boundedness being a crucial requirement. This exercise provides a concrete opportunity to engage with this fundamental concept by constructing a space that is totally bounded but not complete [@problem_id:2977862]. By explicitly computing a covering number $N(X,d,\\varepsilon)$, you will gain a hands-on understanding of what it means for a space to be \"finitely approximable\" at any given scale.", "problem": "Let $(X,d)$ be a metric space. Recall that $X$ is called totally bounded if for every $\\varepsilon>0$ there exists a finite set $\\{x_1, \\dots, x_N\\} \\subset X$ such that $X \\subset \\bigcup_{i=1}^{N} B[x_i, \\varepsilon]$, where $B[x, \\varepsilon] := \\{y \\in X : d(x,y) \\le \\varepsilon\\}$ denotes the closed ball of radius $\\varepsilon$ centered at $x$. The covering number $N(X,d,\\varepsilon)$ is the minimal $N \\in \\mathbb{N}$ for which such a cover exists. A metric space $X$ is complete if every Cauchy sequence converges in $X$.\n\nConstruct explicitly a metric space $(X,d)$ that is totally bounded but not complete. Then, for your constructed example, compute the exact value of the covering number $N(X,d,\\varepsilon_0)$ for the prescribed radius $\\varepsilon_0 = \\frac{1}{7}$, using closed balls as above. Your final answer must be a single integer. No rounding is needed.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard exercise in metric space theory.\n\nFirst, we must construct a metric space $(X,d)$ that is totally bounded but not complete. A canonical example is an open interval of the real line with the standard metric. Let us choose $X$ to be the open interval $(0,1)$ and $d$ to be the standard Euclidean metric on $\\mathbb{R}$, i.e., $d(x,y) = |x-y|$ for any $x,y \\in X$.\n\nWe verify the properties of this space ($(0,1), |\\cdot|$).\n\n1.  **Total Boundedness**: The space $X = (0,1)$ is a subset of the compact metric space $([0,1], |\\cdot|)$. A fundamental theorem in topology states that a metric space is compact if and only if it is complete and totally bounded. Thus, $[0,1]$ is totally bounded. Any subset of a totally bounded space is also totally bounded. To be explicit, for any $\\varepsilon>0$, we can find a finite $\\varepsilon$-cover of $[0,1]$. This same finite set of balls, intersected with $(0,1)$, will cover $(0,1)$. While the centers of these balls may not lie in $(0,1)$, we can always find centers within $(0,1)$ that form a finite $\\varepsilon$-cover. For instance, if $\\{y_i\\}$ are centers in $[0,1]$ for a cover of $[0,1]$, we can choose rational points $x_i \\in (0,1)$ sufficiently close to each $y_i$ such that the balls centered at $x_i$ with a slightly larger radius still cover $(0,1)$. Hence, $X=(0,1)$ is totally bounded.\n\n2.  **Incompleteness**: A metric space is complete if every Cauchy sequence in the space converges to a limit that is also in the space. Consider the sequence $(x_n)_{n\\in\\mathbb{N}}$ in $X=(0,1)$ defined by $x_n = \\frac{1}{n+1}$ for $n \\ge 1$. This sequence is $(\\frac{1}{2}, \\frac{1}{3}, \\frac{1}{4}, \\dots)$. Each term is clearly in $(0,1)$. This sequence is a Cauchy sequence because for any $\\delta > 0$, we can find an integer $M$ such that for all $m,n > M$, $|x_n - x_m| = |\\frac{1}{n+1} - \\frac{1}{m+1}|  \\frac{1}{M+1}  \\delta$. The sequence converges to $\\lim_{n \\to \\infty} \\frac{1}{n+1} = 0$. However, the limit point $0$ is not an element of the space $X = (0,1)$. Therefore, we have found a Cauchy sequence in $X$ that does not converge to a point in $X$, proving that the space is not complete.\n\nHaving constructed a valid example, we now proceed to compute the covering number $N(X, d, \\varepsilon_0)$ for $\\varepsilon_0 = \\frac{1}{7}$. We need to find the minimum number of closed balls of radius $\\frac{1}{7}$ required to cover the interval $(0,1)$, with the centers of the balls being in $(0,1)$.\n\nFirst, we establish a lower bound for $N = N((0,1), |\\cdot|, 1/7)$.\nA closed ball $B[x, \\varepsilon_0]$ in our space is the set $\\{y \\in (0,1) : |x-y| \\le \\varepsilon_0\\}$, which corresponds to the interval $[x-\\varepsilon_0, x+\\varepsilon_0] \\cap (0,1)$. The length of this interval (its Lebesgue measure) is at most $2\\varepsilon_0$.\nIf we cover the space $X=(0,1)$ with $N$ such balls, the total length of the union of these balls must be at least the length of $X$.\nThe length of $X = (0,1)$ is $1$. Using the subadditivity of measure, the length of the union of $N$ balls is no more than the sum of their individual lengths:\n$$1 = \\operatorname{length}((0,1)) \\le \\operatorname{length}\\left(\\bigcup_{i=1}^{N} B[x_i, \\varepsilon_0]\\right) \\le \\sum_{i=1}^{N} \\operatorname{length}(B[x_i, \\varepsilon_0]) \\le \\sum_{i=1}^{N} 2\\varepsilon_0 = N \\cdot 2\\varepsilon_0$$\nSubstituting $\\varepsilon_0 = \\frac{1}{7}$, we get:\n$$1 \\le N \\cdot 2 \\cdot \\frac{1}{7} = \\frac{2N}{7}$$\n$$N \\ge \\frac{7}{2} = 3.5$$\nSince the covering number $N$ must be an integer, we must have $N \\ge 4$.\n\nNext, we establish an upper bound for $N$ by constructing an explicit cover with $4$ balls. We need to find four points $x_1, x_2, x_3, x_4$ in $(0,1)$ such that $(0,1) \\subset \\bigcup_{i=1}^{4} B[x_i, \\frac{1}{7}]$. Let us choose the following centers:\n$x_1 = \\frac{1}{7}$\n$x_2 = \\frac{3}{7}$\n$x_3 = \\frac{5}{7}$\n$x_4 = \\frac{6}{7}$\nAll these centers are in the interval $(0,1)$. Let's analyze the coverage provided by the balls centered at these points with radius $\\varepsilon_0 = \\frac{1}{7}$:\n1.  Ball 1: $B[x_1, \\varepsilon_0] = B[\\frac{1}{7}, \\frac{1}{7}] = \\{y \\in (0,1) : |y-\\frac{1}{7}| \\le \\frac{1}{7}\\} = [0, \\frac{2}{7}] \\cap (0,1) = (0, \\frac{2}{7}]$.\n2.  Ball 2: $B[x_2, \\varepsilon_0] = B[\\frac{3}{7}, \\frac{1}{7}] = \\{y \\in (0,1) : |y-\\frac{3}{7}| \\le \\frac{1}{7}\\} = [\\frac{2}{7}, \\frac{4}{7}] \\cap (0,1) = [\\frac{2}{7}, \\frac{4}{7}]$.\n3.  Ball 3: $B[x_3, \\varepsilon_0] = B[\\frac{5}{7}, \\frac{1}{7}] = \\{y \\in (0,1) : |y-\\frac{5}{7}| \\le \\frac{1}{7}\\} = [\\frac{4}{7}, \\frac{6}{7}] \\cap (0,1) = [\\frac{4}{7}, \\frac{6}{7}]$.\n4.  Ball 4: $B[x_4, \\varepsilon_0] = B[\\frac{6}{7}, \\frac{1}{7}] = \\{y \\in (0,1) : |y-\\frac{6}{7}| \\le \\frac{1}{7}\\} = [\\frac{5}{7}, 1] \\cap (0,1) = [\\frac{5}{7}, 1)$.\n\nThe union of these four sets is:\n$$(0, \\frac{2}{7}] \\cup [\\frac{2}{7}, \\frac{4}{7}] \\cup [\\frac{4}{7}, \\frac{6}{7}] \\cup [\\frac{5}{7}, 1)$$\nThe union of the first three is $(0, \\frac{6}{7}]$.\nThe union of all four is $(0, \\frac{6}{7}] \\cup [\\frac{5}{7}, 1)$. Since $\\frac{5}{7}  \\frac{6}{7}$, this union is equal to $(0, 1)$.\nThus, we have successfully covered the entire space $X=(0,1)$ with $4$ balls. This shows that $N \\le 4$.\n\nCombining the lower and upper bounds, we have $N \\ge 4$ and $N \\le 4$. The only integer satisfying these inequalities is $N=4$. Therefore, the minimal number of balls, the covering number, is exactly $4$.", "answer": "$$\n\\boxed{4}\n$$", "id": "2977862"}, {"introduction": "The Gromov-Hausdorff distance quantifies the dissimilarity between two metric spaces, and one of the most intuitive ways to understand this is through the lens of $\\epsilon$-isometries—maps that almost preserve distances. This problem challenges you to construct such a map between two circles with their intrinsic arc-length metrics and find the minimal \"error\" $\\epsilon$ [@problem_id:2977861]. This practice illuminates how the Gromov-Hausdorff distance is sensitive to scaling differences in the metric structure, a central theme in geometric analysis.", "problem": "Let $r0$ and $r'0$. Consider the circles $S^1_r$ and $S^1_{r'}$ equipped with their intrinsic (path) metrics induced by the standard Riemannian metric on $\\mathbb{R}^{2}$, so that the distance between two points with angular coordinates $\\theta_1, \\theta_2 \\in \\mathbb{R}/2\\pi\\mathbb{Z}$ is given by $$d_r(\\theta_1, \\theta_2) = r \\cdot \\min_{k \\in \\mathbb{Z}}|\\theta_1 - \\theta_2 + 2\\pi k|,$$ and similarly for $d_{r'}$. An $\\epsilon$-isometry $f:X \\to Y$ between compact metric spaces $(X,d_X)$ and $(Y,d_Y)$ is a map such that for all $x,x'\\in X$ one has $$|d_Y(f(x), f(x')) - d_X(x, x')| \\le \\epsilon,$$ and $f(X)$ is $\\epsilon$-dense in $Y$. This notion is fundamental in the study of the Gromov-Hausdorff (GH) distance and Gromov's precompactness theorem.\n\nConstruct an explicit $\\epsilon$-isometry between $S^1_r$ and $S^1_{r'}$ and compute the smallest $\\epsilon$ for which your map is an $\\epsilon$-isometry, expressed in closed form in terms of $|r-r'|$. Your final answer must be a single closed-form analytic expression. Do not provide an inequality. No units are required.", "solution": "The problem requires us to construct an explicit $\\epsilon$-isometry between two circles, $S^1_r$ and $S^1_{r'}$, and to compute the smallest value of $\\epsilon$ for which the constructed map satisfies the given definition.\n\nLet the two circles be $(X, d_X) = (S^1_r, d_r)$ and $(Y, d_Y) = (S^1_{r'}, d_{r'})$. The radii are $r0$ and $r'0$. Points on the circles can be parameterized by an angular coordinate $\\theta \\in \\mathbb{R}/(2\\pi\\mathbb{Z})$. Let $p_r(\\theta)$ denote the point on $S^1_r$ at angle $\\theta$. The distance between two points $p_r(\\theta_1)$ and $p_r(\\theta_2)$ on $S^1_r$ is given by the length of the shorter arc connecting them:\n$$d_r(p_r(\\theta_1), p_r(\\theta_2)) = r \\cdot \\min_{k\\in\\mathbb{Z}}|\\theta_1 - \\theta_2 + 2\\pi k|$$\nLet $\\Delta\\theta = \\min_{k\\in\\mathbb{Z}}|\\theta_1 - \\theta_2 + 2\\pi k|$ be the angular separation. This value represents the distance on a unit circle and is restricted to the interval $[0, \\pi]$. Thus, $d_r(p_r(\\theta_1), p_r(\\theta_2)) = r\\Delta\\theta$. The metric $d_{r'}$ is defined analogously.\n\nWe construct a map $f: S^1_r \\to S^1_{r'}$ by identifying points with the same angular coordinate. That is, for any point $p_r(\\theta) \\in S^1_r$, we define its image as:\n$$f(p_r(\\theta)) = p_{r'}(\\theta)$$\nThis map is a homeomorphism between the two circles.\n\nAn $\\epsilon$-isometry, as defined in the problem, is a map $f: X \\to Y$ that must satisfy two conditions for some $\\epsilon \\ge 0$:\n$1$. The distortion condition: For all $x, x' \\in X$, $|d_Y(f(x), f(x')) - d_X(x, x')| \\le \\epsilon$.\n$2$. The density condition: The image $f(X)$ must be $\\epsilon$-dense in $Y$. This means that for every $y \\in Y$, there exists an $x \\in X$ such that $d_Y(y, f(x)) \\le \\epsilon$.\n\nWe will find the minimum $\\epsilon$ required for each condition for our constructed map $f$, and the overall minimum $\\epsilon$ will be the maximum of these two values.\n\nFirst, let us analyze the density condition. The image of our map $f$ is\n$$f(S^1_r) = \\{ f(p_r(\\theta)) \\mid \\theta \\in \\mathbb{R}/(2\\pi\\mathbb{Z}) \\} = \\{ p_{r'}(\\theta) \\mid \\theta \\in \\mathbb{R}/(2\\pi\\mathbb{Z}) \\} = S^1_{r'}$$\nSince the map $f$ is surjective, its image $f(S^1_r)$ is the entire space $S^1_{r'}$. For any point $y \\in S^1_{r'}$, we can choose $x \\in S^1_r$ such that $f(x) = y$. Then the distance is $d_{r'}(y, f(x)) = d_{r'}(y, y) = 0$. This means that $f(S^1_r)$ is $0$-dense in $S^1_{r'}$. The smallest $\\epsilon$ satisfying the density condition is therefore $\\epsilon_{\\text{dense}} = 0$.\n\nNext, we analyze the distortion condition. Let $x = p_r(\\theta_1)$ and $x' = p_r(\\theta_2)$ be two arbitrary points on $S^1_r$. Their images under $f$ are $f(x) = p_{r'}(\\theta_1)$ and $f(x') = p_{r'}(\\theta_2)$. The distance between $x$ and $x'$ is $d_r(x, x') = r\\Delta\\theta$, where $\\Delta\\theta$ is their angular separation. The distance between their images is $d_{r'}(f(x), f(x')) = r'\\Delta\\theta$.\n\nThe distortion is given by the expression $|d_{r'}(f(x), f(x')) - d_r(x, x')|$. Substituting the expressions for the distances, we get:\n$$|r'\\Delta\\theta - r\\Delta\\theta| = |r' - r|\\Delta\\theta$$\nTo satisfy the distortion condition, we must have $|r' - r|\\Delta\\theta \\le \\epsilon$ for all possible pairs of points, which means for all possible values of $\\Delta\\theta$. The angular separation $\\Delta\\theta$ can take any value in the interval $[0, \\pi]$. To find the smallest $\\epsilon$ that works for all pairs of points, we must find the supremum of the distortion over this interval:\n$$\\epsilon_{\\text{dist}} = \\sup_{\\Delta\\theta \\in [0, \\pi]} |r' - r|\\Delta\\theta$$\nSince $|r' - r|$ is a non-negative constant, the supremum is achieved when $\\Delta\\theta$ is at its maximum value, which is $\\pi$. This corresponds to two diametrically opposite points on the circle.\n$$\\epsilon_{\\text{dist}} = |r' - r|\\pi$$\n\nThe smallest value $\\epsilon$ for which our map $f$ is an $\\epsilon$-isometry must satisfy both the density and distortion conditions. Therefore, it must be at least as large as both $\\epsilon_{\\text{dense}}$ and $\\epsilon_{\\text{dist}}$.\n$$\\epsilon = \\max(\\epsilon_{\\text{dense}}, \\epsilon_{\\text{dist}}) = \\max(0, |r' - r|\\pi)$$\nSince $r$ and $r'$ are positive radii, $|r' - r| \\ge 0$ and $\\pi > 0$, so $|r' - r|\\pi \\ge 0$.\nThus, the smallest value for $\\epsilon$ is:\n$$\\epsilon = |r' - r|\\pi$$\nThis expression can also be written as $\\pi|r-r'|$.", "answer": "$$\\boxed{\\pi |r-r'|}$$", "id": "2977861"}, {"introduction": "An equivalent and powerful formulation of the Gromov-Hausdorff distance uses the notion of a correspondence and its associated distortion, providing a way to relate points between two spaces directly. This advanced exercise asks you to derive the fundamental inequality relating the GH distance to the distortion of a correspondence, $d_{GH}(X,Y) \\le \\frac{1}{2}\\operatorname{dis}(R)$, and then to test the sharpness of this bound on a simple but illustrative example [@problem_id:2977855]. Successfully completing this task demonstrates a deep understanding of the relationship between different definitions of Gromov-Hausdorff distance and the geometric intuition behind them.", "problem": "Let $(X,d_X)$ and $(Y,d_Y)$ be compact metric spaces. A correspondence $R \\subset X \\times Y$ is a subset whose projections to $X$ and $Y$ are both surjective. The distortion of $R$ is\n$$\n\\operatorname{dis}(R) \\coloneqq \\sup\\left\\{\\,\\big|d_{X}(x,x') - d_{Y}(y,y')\\big| : (x,y),(x',y') \\in R\\,\\right\\}.\n$$\nThe Gromov–Hausdorff (GH) distance $d_{GH}(X,Y)$ is defined by\n$$\nd_{GH}(X,Y) \\coloneqq \\inf\\left\\{\\, d_{H}^{Z}\\big(\\varphi(X),\\psi(Y)\\big) \\,:\\, \\varphi:X\\to Z,\\ \\psi:Y\\to Z\\ \\text{are isometric embeddings into a metric space }(Z,d_{Z}) \\,\\right\\},\n$$\nwhere $d_{H}^{Z}$ denotes the Hausdorff distance (HD) computed in $(Z,d_Z)$.\n\n1) Using only these definitions and the triangle inequality for metrics, derive an explicit upper bound on $d_{GH}(X,Y)$ in terms of $\\operatorname{dis}(R)$ that holds for every correspondence $R$, and determine the best possible constant (i.e., the smallest universal constant) that can appear in front of $\\operatorname{dis}(R)$ in such an inequality.\n\n2) Consider the finite metric spaces $X=\\{a,b\\}$ with $d_{X}(a,b)=2$ and $Y=\\{c,d\\}$ with $d_{Y}(c,d)=5$. Let $R=\\{(a,c),(b,d)\\}$ be a correspondence. Compute $\\operatorname{dis}(R)$ and then compute the exact value of $d_{GH}(X,Y)$ directly from the definition via isometric embeddings and Hausdorff distance, verifying that the bound from part 1) is sharp in this example. Report the exact value of $d_{GH}(X,Y)$ as your final answer. No rounding is required.", "solution": "The problem consists of two parts. First, we must derive an upper bound for the Gromov-Hausdorff distance $d_{GH}(X,Y)$ in terms of the distortion $\\operatorname{dis}(R)$ of a given correspondence $R$, and find the best possible constant in this inequality. Second, we must verify this bound and its sharpness using a specific example of two finite metric spaces.\n\nPart 1: Derivation of the bound and determination of the best constant.\n\nLet $(X, d_X)$ and $(Y, d_Y)$ be compact metric spaces, and let $R \\subset X \\times Y$ be a correspondence. The distortion of $R$ is given by $\\varepsilon \\coloneqq \\operatorname{dis}(R) = \\sup \\{ |d_X(x, x') - d_Y(y, y')| : (x, y), (x', y') \\in R \\}$.\nThe Gromov-Hausdorff distance $d_{GH}(X,Y)$ is the infimum of the Hausdorff distances between isometric images of $X$ and $Y$ in any common metric space $Z$. To find an upper bound on $d_{GH}(X,Y)$, we must construct a specific metric space $(Z, d_Z)$ containing isometric copies of $X$ and $Y$ and then compute an upper bound for the Hausdorff distance between these copies.\n\nLet's construct the space $Z$ as the disjoint union of $X$ and $Y$, i.e., $Z \\coloneqq X \\sqcup Y$. We define a function $d_Z: Z \\times Z \\to \\mathbb{R}_{\\ge 0}$ as follows:\n1. For $p, q \\in X$, $d_Z(p, q) \\coloneqq d_X(p, q)$.\n2. For $p, q \\in Y$, $d_Z(p, q) \\coloneqq d_Y(p, q)$.\n3. For $x \\in X$ and $y \\in Y$, $d_Z(x, y) \\coloneqq \\inf_{(x_0, y_0) \\in R} \\{d_X(x, x_0) + d_Y(y_0, y)\\} + \\frac{\\varepsilon}{2}$. We also set $d_Z(y,x) = d_Z(x,y)$.\n\nWith this definition, the natural inclusion maps $\\varphi: X \\to Z$ and $\\psi: Y \\to Z$ are isometric embeddings. It can be shown that $d_Z$ is a pseudometric (verifying the triangle inequality is the main step, which we omit here for brevity), and its associated metric space provides the required setting.\n\nNow, we compute the Hausdorff distance $d_H^Z(\\varphi(X), \\psi(Y))$ in our constructed space $Z$.\n$d_H^Z(\\varphi(X), \\psi(Y)) = \\max\\left( \\sup_{x \\in X} d_Z(x, \\psi(Y)), \\sup_{y \\in Y} d_Z(y, \\varphi(X)) \\right)$.\nLet's analyze the first term: $\\sup_{x \\in X} \\inf_{y \\in Y} d_Z(x, y)$.\nLet $x \\in X$. Since $R$ is a correspondence, its projection onto $X$ is surjective. Therefore, there exists at least one $y_x \\in Y$ such that $(x, y_x) \\in R$.\nLet's evaluate $d_Z(x, y_x)$:\n$d_Z(x, y_x) = \\inf_{(x_0, y_0) \\in R} \\{d_X(x, x_0) + d_Y(y_0, y_x)\\} + \\frac{\\varepsilon}{2}$.\nWe can obtain an upper bound for this infimum by choosing the particular pair $(x, y_x) \\in R$ for $(x_0, y_0)$:\n$d_Z(x, y_x) \\le d_X(x, x) + d_Y(y_x, y_x) + \\frac{\\varepsilon}{2} = 0 + 0 + \\frac{\\varepsilon}{2} = \\frac{\\varepsilon}{2}$.\nThus, for any $x \\in X$, we have $\\inf_{y \\in Y} d_Z(x, y) \\le d_Z(x, y_x) \\le \\frac{\\varepsilon}{2}$.\nThis implies $\\sup_{x \\in X} \\inf_{y \\in Y} d_Z(x, y) \\le \\frac{\\varepsilon}{2}$.\nBy a symmetric argument, using the surjectivity of the projection of $R$ onto $Y$, we find $\\sup_{y \\in Y} \\inf_{x \\in X} d_Z(y, x) \\le \\frac{\\varepsilon}{2}$.\nCombining these results, the Hausdorff distance is bounded by:\n$d_H^Z(\\varphi(X), \\psi(Y)) \\le \\frac{\\varepsilon}{2} = \\frac{1}{2}\\operatorname{dis}(R)$.\nSince $d_{GH}(X,Y)$ is the infimum over all possible common metric spaces $Z$ and all isometric embeddings, it must be less than or equal to the value for our specific construction:\n$d_{GH}(X,Y) \\le \\frac{1}{2}\\operatorname{dis}(R)$.\nThis establishes an upper bound, and the constant is $C=\\frac{1}{2}$. The problem also asks for the best possible (smallest) constant. The analysis in Part 2 will demonstrate that for a specific choice of $X$, $Y$, and $R$, we have the equality $d_{GH}(X,Y) = \\frac{1}{2}\\operatorname{dis}(R)$. This implies that no constant smaller than $\\frac{1}{2}$ can be universally valid. Thus, $C=\\frac{1}{2}$ is the best possible constant.\n\nPart 2: Explicit computation for an example.\n\nWe are given $X=\\{a,b\\}$ with $d_{X}(a,b)=2$ and $Y=\\{c,d\\}$ with $d_{Y}(c,d)=5$. The correspondence is $R=\\{(a,c),(b,d)\\}$.\n\nFirst, we compute the distortion $\\operatorname{dis}(R)$. The set of pairs of points from $R$ is $\\{((a,c), (a,c)), ((b,d), (b,d)), ((a,c), (b,d)), ((b,d), (a,c))\\}$. The non-trivial case is for distinct points:\n$\\operatorname{dis}(R) = \\sup\\{\\big|d_{X}(a,b) - d_{Y}(c,d)\\big|\\} = |2-5| = 3$.\n\nNext, we compute $d_{GH}(X,Y)$ directly from its definition. Let $\\varphi:X \\to Z$ and $\\psi:Y \\to Z$ be isometric embeddings into a metric space $(Z,d_Z)$. Let $A=\\varphi(a)$, $B=\\varphi(b)$, $C=\\psi(c)$, $D=\\psi(d)$.\nThe isometry condition implies $d_Z(A,B) = d_X(a,b) = 2$ and $d_Z(C,D) = d_Y(c,d) = 5$.\nThe Hausdorff distance $d_H^Z(\\varphi(X),\\psi(Y))$ is given by $d_H^Z(\\{A,B\\},\\{C,D\\}) = \\max\\big(\\sup_{p \\in \\{A,B\\}}d_Z(p,\\{C,D\\}), \\sup_{q \\in \\{C,D\\}}d_Z(q,\\{A,B\\})\\big)$.\nLet $\\delta = d_{H}^Z(\\varphi(X),\\psi(Y))$. By definition, every point in one set must be within distance $\\delta$ of the other set. This leads to four conditions:\n1. $\\min(d_Z(A,C), d_Z(A,D)) \\le \\delta$\n2. $\\min(d_Z(B,C), d_Z(B,D)) \\le \\delta$\n3. $\\min(d_Z(C,A), d_Z(C,B)) \\le \\delta$\n4. $\\min(d_Z(D,A), d_Z(D,B)) \\le \\delta$\n\nThere are two primary \"pairing\" scenarios for these conditions to be met with minimal $\\delta$:\na) $d_Z(A,C) \\le \\delta$ and $d_Z(B,D) \\le \\delta$. By the triangle inequality in $Z$: $d_Z(C,D) \\le d_Z(C,A) + d_Z(A,B) + d_Z(B,D)$. Substituting the known distances gives $5 \\le d_Z(A,C) + 2 + d_Z(B,D)$. Thus, $d_Z(A,C) + d_Z(B,D) \\ge 3$. Combining with the pairing assumption, we get $\\delta + \\delta \\ge 3$, which implies $\\delta \\ge \\frac{3}{2}$.\nb) $d_Z(A,D) \\le \\delta$ and $d_Z(B,C) \\le \\delta$. Similarly, from $d_Z(C,D) \\le d_Z(C,B) + d_Z(B,A) + d_Z(A,D)$, we get $5 \\le d_Z(B,C) + 2 + d_Z(A,D)$, so $d_Z(B,C) + d_Z(A,D) \\ge 3$. This again implies $\\delta \\ge \\frac{3}{2}$.\nOther scenarios, such as both $C$ and $D$ being close to $A$ (i.e., $d_Z(A,C) \\le \\delta, d_Z(A,D) \\le \\delta$), lead to a larger lower bound for $\\delta$. From $d_Z(C,D) \\le d_Z(C,A) + d_Z(A,D)$, we get $5 \\le \\delta+\\delta=2\\delta$, so $\\delta \\ge \\frac{5}{2}$.\nThe minimum possible Hausdorff distance must therefore be at least $\\frac{3}{2}$. So, $d_{GH}(X,Y) \\ge \\frac{3}{2}$.\n\nTo show that this lower bound is achieved, we must construct an embedding where the Hausdorff distance is exactly $\\frac{3}{2}$. Consider placing the four points $A,B,C,D$ on the real line $\\mathbb{R}$ with the standard metric. Let $A=0$ and $B=2$. We seek positions $C=c$ and $D=d$ such that $d_Z(C,D)=|d-c|=5$, and we aim for a configuration that minimizes the Hausdorff distance. The bound $\\delta \\ge \\frac{3}{2}$ was tightest when $d_Z(A,C)+d_Z(B,D)=3$. Let's try to achieve $d_Z(A,C)=\\frac{3}{2}$ and $d_Z(B,D)=\\frac{3}{2}$.\nThis gives $|c-0|=\\frac{3}{2}$ and $|d-2|=\\frac{3}{2}$.\nSo $c=\\pm\\frac{3}{2}$ and $d=2\\pm\\frac{3}{2}$, i.e., $d=\\frac{7}{2}$ or $d=\\frac{1}{2}$.\nWe check the combinations for $|d-c|=5$:\n- If $c=\\frac{3}{2}$, $| \\frac{7}{2} - \\frac{3}{2} | = 2 \\ne 5$, $|\\frac{1}{2} - \\frac{3}{2}| = 1 \\ne 5$.\n- If $c=-\\frac{3}{2}$, $|\\frac{7}{2} - (-\\frac{3}{2})| = |\\frac{10}{2}| = 5$. This works.\nSo, we can place the points at $C = -\\frac{3}{2}$, $A=0$, $B=2$, $D=\\frac{7}{2}$.\nLet's compute the Hausdorff distance for this configuration: $\\varphi(X) = \\{0,2\\}$, $\\psi(Y) = \\{-\\frac{3}{2}, \\frac{7}{2}\\}$.\n$\\sup_{p \\in \\varphi(X)} d(p, \\psi(Y)) = \\max(d(0, \\{-\\frac{3}{2},\\frac{7}{2}\\}), d(2, \\{-\\frac{3}{2},\\frac{7}{2}\\}))$.\n$d(0, \\{-\\frac{3}{2},\\frac{7}{2}\\}) = \\min(|0-(-\\frac{3}{2})|, |0-\\frac{7}{2}|) = \\min(\\frac{3}{2}, \\frac{7}{2}) = \\frac{3}{2}$.\n$d(2, \\{-\\frac{3}{2},\\frac{7}{2}\\}) = \\min(|2-(-\\frac{3}{2})|, |2-\\frac{7}{2}|) = \\min(\\frac{7}{2}, \\frac{3}{2}) = \\frac{3}{2}$.\nSo, $\\sup_{p \\in \\varphi(X)} d(p, \\psi(Y)) = \\max(\\frac{3}{2}, \\frac{3}{2}) = \\frac{3}{2}$.\n$\\sup_{q \\in \\psi(Y)} d(q, \\varphi(X)) = \\max(d(-\\frac{3}{2}, \\{0,2\\}), d(\\frac{7}{2}, \\{0,2\\}))$.\n$d(-\\frac{3}{2}, \\{0,2\\}) = \\min(|-\\frac{3}{2}-0|, |-\\frac{3}{2}-2|) = \\min(\\frac{3}{2}, \\frac{7}{2}) = \\frac{3}{2}$.\n$d(\\frac{7}{2}, \\{0,2\\}) = \\min(|\\frac{7}{2}-0|, |\\frac{7}{2}-2|) = \\min(\\frac{7}{2}, \\frac{3}{2}) = \\frac{3}{2}$.\nSo, $\\sup_{q \\in \\psi(Y)} d(q, \\varphi(X)) = \\max(\\frac{3}{2}, \\frac{3}{2}) = \\frac{3}{2}$.\nThe Hausdorff distance for this embedding is $\\max(\\frac{3}{2}, \\frac{3}{2}) = \\frac{3}{2}$.\nSince we have shown that for any embedding $d_H^Z \\ge \\frac{3}{2}$ and we have found an embedding that achieves this value, the infimum is exactly $\\frac{3}{2}$.\nTherefore, $d_{GH}(X,Y) = \\frac{3}{2}$.\n\nThis result verifies the sharpness of the bound from Part 1. We have $d_{GH}(X,Y) = \\frac{3}{2}$ and $\\operatorname{dis}(R)=3$. Indeed, $\\frac{3}{2} = \\frac{1}{2} \\times 3$, so $d_{GH}(X,Y) = \\frac{1}{2}\\operatorname{dis}(R)$ for this example.\n\nThe final answer is the exact value of $d_{GH}(X,Y)$.", "answer": "$$\n\\boxed{\\frac{3}{2}}\n$$", "id": "2977855"}]}