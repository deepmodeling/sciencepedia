{"hands_on_practices": [{"introduction": "This first exercise grounds the abstract theory of Lie groups in a concrete calculation on the special orthogonal group $SO(3)$. You will translate the definition of a left-invariant vector field into a tangible matrix operation and then derive its corresponding one-parameter subgroup by solving a differential equation. This practice is fundamental, as it explicitly demonstrates how an element of the Lie algebra $\\mathfrak{g}$ gives rise to a flow on the Lie group $G$ via the exponential map.", "problem": "Let $G = \\mathrm{SO}(3)$ be the Special Orthogonal group (SO) of real $3 \\times 3$ orthogonal matrices with determinant $1$, and let $\\mathfrak{g} = \\mathfrak{so}(3)$ denote its Lie algebra of real $3 \\times 3$ skew-symmetric matrices. For $g \\in G$, let $L_{g} : G \\to G$ be left translation by $g$, defined by $L_{g}(h) = gh$. For $v \\in \\mathfrak{g}$, the associated left-invariant vector field $X^{v}$ on $G$ is defined at $g \\in G$ by $X^{v}(g) := d(L_{g})_{e}(v)$, where $e$ denotes the identity element, and $d(L_{g})_{e}$ is the differential of $L_{g}$ at $e$. Use only these core definitions and the identification of tangent vectors with derivatives of smooth curves to compute, in explicit matrix form, the left-invariant vector field $X^{v}$ when $v$ is the skew-symmetric basis element\n$$\nE_{3} \\;=\\; \\begin{pmatrix}\n0 & -1 & 0\\\\\n1 & \\;\\;0 & 0\\\\\n0 & \\;\\;0 & 0\n\\end{pmatrix} \\;\\in\\; \\mathfrak{so}(3).\n$$\nThen, using the characterization of integral curves of a vector field, express $X^{v}$ as a matrix Ordinary Differential Equation (ODE) along curves $g(t) \\in \\mathrm{SO}(3)$ and solve this ODE with initial condition $g(0) = I$, where $I$ is the $3 \\times 3$ identity matrix. Your final answer must be a single closed-form analytic expression for the $3 \\times 3$ matrix $g(t)$ as a function of $t$. No rounding is required.", "solution": "The problem is well-posed and scientifically grounded in the theory of Lie groups and differential geometry. It is a standard exercise in computing a left-invariant vector field on $\\mathrm{SO}(3)$ and finding its corresponding integral curve, which is a one-parameter subgroup.\n\nThe problem consists of two main parts: first, to find the explicit matrix form of the left-invariant vector field $X^{v}$ associated with the Lie algebra element $v = E_3$, and second, to solve the differential equation for the integral curve of this vector field starting at the identity.\n\nLet $G = \\mathrm{SO}(3)$ be the Lie group of $3 \\times 3$ real orthogonal matrices with determinant $1$. Its Lie algebra, $\\mathfrak{g} = \\mathfrak{so}(3)$, is the space of $3 \\times 3$ real skew-symmetric matrices. The identity element of the group is the $3 \\times 3$ identity matrix, which we denote by $e$ or $I$.\n\nA tangent vector $v \\in T_{e}G = \\mathfrak{g}$ can be identified with the derivative of a smooth curve $\\alpha: (-\\epsilon, \\epsilon) \\to G$ at $s=0$, such that $\\alpha(0) = e$ and $\\frac{d\\alpha}{ds}(0) = v$.\n\nThe left-invariant vector field $X^{v}$ generated by $v \\in \\mathfrak{g}$ is defined at an arbitrary point $g \\in G$ by $X^{v}(g) = d(L_{g})_{e}(v)$. Here, $L_{g}$ is the left translation map $L_{g}(h) = gh$, and $d(L_{g})_{e}$ is its differential (or pushforward) at the identity $e$.\n\nTo compute $d(L_{g})_{e}(v)$, we apply the map $L_{g}$ to the curve $\\alpha(s)$. This produces a new curve $\\beta(s) = L_{g}(\\alpha(s)) = g\\alpha(s)$, which passes through $g$ at $s=0$ since $\\beta(0) = g\\alpha(0) = ge = g$. The differential $d(L_{g})_{e}(v)$ is the tangent vector to this new curve $\\beta(s)$ at $s=0$. We can compute this by taking the derivative with respect to $s$:\n$$\n\\frac{d\\beta}{ds}(s) = \\frac{d}{ds}(g\\alpha(s))\n$$\nSince $g$ is a constant matrix with respect to the parameter $s$, we can use the product rule for matrix differentiation, treating $g$ as a constant operator acting on the curve $\\alpha(s)$:\n$$\n\\frac{d\\beta}{ds}(s) = g \\frac{d\\alpha}{ds}(s)\n$$\nEvaluating at $s=0$, we obtain the expression for the vector field at $g$:\n$$\nX^{v}(g) = \\frac{d\\beta}{ds}(0) = g \\frac{d\\alpha}{ds}(0) = gv\n$$\nThis is a general result for matrix Lie groups: the left-invariant vector field $X^{v}$ at a point $g$ is given by the matrix product $gv$.\n\nThe specific problem gives the Lie algebra element\n$$\nv = E_{3} = \\begin{pmatrix}\n0 & -1 & 0\\\\\n1 & \\;\\;0 & 0\\\\\n0 & \\;\\;0 & 0\n\\end{pmatrix}\n$$\nThus, the corresponding left-invariant vector field at a point $g \\in \\mathrm{SO}(3)$ is given by\n$$\nX^{E_{3}}(g) = g E_{3}\n$$\nIf we write $g$ in terms of its entries, $g = (g_{ij})$, then the matrix form of the vector field is\n$$\nX^{E_{3}}(g) = \\begin{pmatrix}\ng_{11} & g_{12} & g_{13} \\\\\ng_{21} & g_{22} & g_{23} \\\\\ng_{31} & g_{32} & g_{33}\n\\end{pmatrix}\n\\begin{pmatrix}\n0 & -1 & 0\\\\\n1 & \\;\\;0 & 0\\\\\n0 & \\;\\;0 & 0\n\\end{pmatrix} =\n\\begin{pmatrix}\ng_{12} & -g_{11} & 0 \\\\\ng_{22} & -g_{21} & 0 \\\\\ng_{32} & -g_{31} & 0\n\\end{pmatrix}\n$$\nThis is the explicit matrix form for the left-invariant vector field.\n\nNext, we must find the integral curve $g(t)$ for this vector field, with the initial condition $g(0) = I$. An integral curve satisfies the differential equation where its tangent vector at each point equals the vector field at that point. The tangent vector to the curve $g(t)$ is its derivative $\\frac{d}{dt}g(t)$. Therefore, the matrix ordinary differential equation (ODE) is:\n$$\n\\frac{d}{dt}g(t) = X^{E_{3}}(g(t)) = g(t) E_{3}\n$$\nThis is a first-order linear homogeneous matrix ODE with constant coefficients. The solution to the initial value problem $\\frac{dY}{dt} = Y A$ with $Y(0) = Y_{0}$ is given by $Y(t) = Y_{0}\\exp(tA)$.\nIn our case, $A = E_{3}$ and the initial condition is $g(0) = I$. The solution is therefore:\n$$\ng(t) = I \\exp(t E_{3}) = \\exp(t E_{3})\n$$\nTo find the explicit form of $g(t)$, we must compute the matrix exponential $\\exp(t E_{3})$. We can do this using the Taylor series definition $\\exp(M) = \\sum_{k=0}^{\\infty} \\frac{M^k}{k!}$. Let's compute the powers of the matrix $tE_3$:\nLet $M = tE_3 = t \\begin{pmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -t & 0 \\\\ t & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}$.\nThe powers of $M$ are:\n$$\nM^{0} = I = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\n$$\nM^{1} = \\begin{pmatrix} 0 & -t & 0 \\\\ t & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\n$$\nM^{2} = \\begin{pmatrix} 0 & -t & 0 \\\\ t & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -t & 0 \\\\ t & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} -t^2 & 0 & 0 \\\\ 0 & -t^2 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\n$$\nM^{3} = M^{2}M = \\begin{pmatrix} -t^2 & 0 & 0 \\\\ 0 & -t^2 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & -t & 0 \\\\ t & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & t^3 & 0 \\\\ -t^3 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = -t^2 M\n$$\nThe pattern can be more clearly seen by factoring out $t$ and focusing on the powers of $E_3$. We let $J = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}$, so $E_3 = \\begin{pmatrix} J & 0 \\\\ 0 & 0 \\end{pmatrix}$.\nPowers of $J$:\n$J^1 = J$, $J^2 = -I_2$, $J^3 = -J$, $J^4 = I_2$.\nThe matrix exponential $\\exp(tE_3)$ becomes:\n$$\n\\exp(tE_3) = \\begin{pmatrix} \\exp(tJ) & 0 \\\\ 0 & \\exp(0) \\end{pmatrix} = \\begin{pmatrix} \\exp(tJ) & 0 \\\\ 0 & 1 \\end{pmatrix}\n$$\nWe compute $\\exp(tJ)$ using its Taylor series and the powers of $J$:\n$$\n\\exp(tJ) = I_{2} + tJ + \\frac{(tJ)^2}{2!} + \\frac{(tJ)^3}{3!} + \\frac{(tJ)^4}{4!} + \\dots\n$$\n$$\n\\exp(tJ) = I_{2} + tJ - \\frac{t^2}{2!}I_{2} - \\frac{t^3}{3!}J + \\frac{t^4}{4!}I_{2} + \\dots\n$$\nGrouping terms with $I_2$ and $J$:\n$$\n\\exp(tJ) = I_{2} \\left( 1 - \\frac{t^2}{2!} + \\frac{t^4}{4!} - \\dots \\right) + J \\left( t - \\frac{t^3}{3!} + \\frac{t^5}{5!} - \\dots \\right)\n$$\nThe series in parentheses are the Maclaurin series for $\\cos(t)$ and $\\sin(t)$, respectively.\n$$\n\\exp(tJ) = I_{2}\\cos(t) + J\\sin(t)\n$$\nSubstituting the matrices $I_2$ and $J$:\n$$\n\\exp(tJ) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\cos(t) + \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}\\sin(t) = \\begin{pmatrix} \\cos(t) & -\\sin(t) \\\\ \\sin(t) & \\cos(t) \\end{pmatrix}\n$$\nTherefore, the solution $g(t)$ is:\n$$\ng(t) = \\exp(tE_3) = \\begin{pmatrix} \\cos(t) & -\\sin(t) & 0 \\\\ \\sin(t) & \\cos(t) & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\nThis matrix represents a rotation in $\\mathbb{R}^3$ about the $z$-axis by an angle $t$. This is the one-parameter subgroup of $\\mathrm{SO}(3)$ generated by the Lie algebra element $E_3$.\nThe result is a $3 \\times 3$ matrix, which is orthogonal with determinant $1$, so it lies in $\\mathrm{SO}(3)$ for all $t \\in \\mathbb{R}$, as expected.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\cos(t) & -\\sin(t) & 0 \\\\ \\sin(t) & \\cos(t) & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}}\n$$", "id": "2982718"}, {"introduction": "Having explored a single left-invariant vector field, we now examine their collective algebraic structure. This problem guides you to prove a cornerstone result: the Lie bracket of two left-invariant vector fields is itself left-invariant, which implies their structure 'functions' are actually constants. By then calculating these structure constants for the non-abelian Heisenberg group, you will gain hands-on experience with the algebraic data that encodes the local geometry of a Lie group.", "problem": "Let $G$ be a finite-dimensional Lie group, and let $\\{e_{1},e_{2},\\dots,e_{n}\\}$ be a global frame of smooth vector fields on $G$ such that each $e_{i}$ is left-invariant, meaning that for every $g \\in G$ and every $p \\in G$, one has $(dL_{g})_{p}(e_{i}(p)) = e_{i}(gp)$, where $L_{g}:G \\to G$ denotes left translation by $g$. For the Lie bracket $[\\cdot,\\cdot]$ of vector fields, define the structure functions $f_{ij}^{k}:G \\to \\mathbb{R}$ by $[e_{i},e_{j}] = \\sum_{k=1}^{n} f_{ij}^{k} \\, e_{k}$. Starting from the definitions of Lie group, left translation, left-invariant vector field, and the naturality of the pushforward under diffeomorphisms, prove that the $f_{ij}^{k}$ are constant functions on $G$ and hence determine structure constants $c_{ij}^{k} \\in \\mathbb{R}$ such that $[e_{i},e_{j}] = \\sum_{k=1}^{n} c_{ij}^{k} \\, e_{k}$.\n\nNext, compute these constants explicitly for the $3$-dimensional Heisenberg group $\\mathbb{H}$ realized as $\\mathbb{R}^{3}$ with coordinates $(x,y,z)$ and group law\n$$(x,y,z)\\cdot(x',y',z') = \\big(x+x',\\; y+y',\\; z+z' + \\tfrac{1}{2}(x y' - y x')\\big).$$\nLet $e = (0,0,0)$ be the identity. Define $e_{1},e_{2},e_{3}$ to be the unique left-invariant vector fields whose values at $e$ agree with the coordinate basis vectors of $T_{e}\\mathbb{R}^{3}$, namely $e_{1}(e) = \\partial_{x}|_{e}$, $e_{2}(e) = \\partial_{y}|_{e}$, and $e_{3}(e) = \\partial_{z}|_{e}$. Using only the definitions above, compute the commutators $[e_{i},e_{j}]$ and extract the resulting structure constants $c_{ij}^{k}$.\n\nAnswer specification:\n- Your final output must be the ordered row vector of all $c_{ij}^{k}$ for $i,j,k \\in \\{1,2,3\\}$, listed in lexicographic order of triples $(i,j,k)$: $(1,1,1)$, $(1,1,2)$, $(1,1,3)$, $(1,2,1)$, $(1,2,2)$, $(1,2,3)$, $(1,3,1)$, $(1,3,2)$, $(1,3,3)$, $(2,1,1)$, $(2,1,2)$, $(2,1,3)$, $(2,2,1)$, $(2,2,2)$, $(2,2,3)$, $(2,3,1)$, $(2,3,2)$, $(2,3,3)$, $(3,1,1)$, $(3,1,2)$, $(3,1,3)$, $(3,2,1)$, $(3,2,2)$, $(3,2,3)$, $(3,3,1)$, $(3,3,2)$, $(3,3,3)$. Present this row vector using the $\\mathrm{pmatrix}$ environment. No rounding is required.", "solution": "The problem consists of two parts. First, a proof concerning the structure functions of a Lie group, and second, a calculation of structure constants for the Heisenberg group.\n\n### Part 1: Constancy of Structure Functions\n\nLet $G$ be a finite-dimensional Lie group with identity element $e \\in G$. Let $\\{e_{1}, e_{2}, \\dots, e_{n}\\}$ be a basis of left-invariant vector fields. By definition, a vector field $X$ on $G$ is left-invariant if for any $g \\in G$, its pushforward under the left translation map $L_g: p \\mapsto gp$ is the vector field itself. That is, $(L_g)_*X = X$. The problem provides an equivalent pointwise definition: for every $g \\in G$ and $p \\in G$, $(dL_g)_p(X(p)) = X(gp)$. To see that these are equivalent, let $q=gp$. The pushforward of $X$ by $L_g$ at the point $q$ is defined as $((L_g)_*X)(q) = (dL_g)_{L_g^{-1}(q)}(X(L_g^{-1}(q))) = (dL_g)_p(X(p))$. Thus, the condition $(L_g)_*X = X$ is equivalent to $((L_g)_*X)(q) = X(q)$ for all $q \\in G$, which translates to $(dL_g)_p(X(p)) = X(gp)$.\n\nThe structure functions $f_{ij}^{k}: G \\to \\mathbb{R}$ are defined by the relation $[e_{i}, e_{j}] = \\sum_{k=1}^{n} f_{ij}^{k} e_{k}$. Our goal is to prove that these functions are constant on $G$.\n\nA fundamental property of the Lie bracket of vector fields is its naturality with respect to diffeomorphisms. For any diffeomorphism $\\phi: M \\to N$ and any two vector fields $X, Y$ on $M$, we have $[\\phi_*X, \\phi_*Y] = \\phi_*[X,Y]$.\n\nWe apply this property to the left translation map $L_g: G \\to G$, which is a diffeomorphism for any $g \\in G$. Let $e_i$ and $e_j$ be two vector fields from our left-invariant frame.\n$$\n[(L_g)_*e_i, (L_g)_*e_j] = (L_g)_*[e_i, e_j]\n$$\nSince $e_i$ and $e_j$ are left-invariant, we have $(L_g)_*e_i = e_i$ and $(L_g)_*e_j = e_j$. Substituting these into the left-hand side of the naturality equation gives:\n$$\n[e_i, e_j] = (L_g)_*[e_i, e_j]\n$$\nThis equation states that the Lie bracket of two left-invariant vector fields is itself a left-invariant vector field. Now we substitute the definition of the structure functions:\n$$\n\\sum_{k=1}^{n} f_{ij}^{k} e_{k} = (L_g)_* \\left( \\sum_{k=1}^{n} f_{ij}^{k} e_{k} \\right)\n$$\nThe pushforward operator $(L_g)_*$ acts on a vector field of the form $fX$ (a function $f$ times a vector field $X$) as follows: $(L_g)_*(fX) = (f \\circ L_g^{-1})((L_g)_*X)$, where $f \\circ L_g^{-1}$ is the composite function. Applying this to our equation:\n$$\n\\sum_{k=1}^{n} f_{ij}^{k} e_{k} = \\sum_{k=1}^{n} (L_g)_*(f_{ij}^{k} e_{k}) = \\sum_{k=1}^{n} (f_{ij}^{k} \\circ L_g^{-1}) ((L_g)_*e_{k})\n$$\nSince each $e_k$ is left-invariant, $(L_g)_*e_k = e_k$. The equation simplifies to:\n$$\n\\sum_{k=1}^{n} f_{ij}^{k} e_{k} = \\sum_{k=1}^{n} (f_{ij}^{k} \\circ L_g^{-1}) e_{k}\n$$\nThis is an equality between two vector fields on $G$. For it to hold, the coefficients of the basis vector fields $\\{e_k\\}$ must be equal at every point $p \\in G$. Evaluating at an arbitrary point $p$:\n$$\n\\sum_{k=1}^{n} f_{ij}^{k}(p) e_{k}(p) = \\sum_{k=1}^{n} (f_{ij}^{k} \\circ L_g^{-1})(p) e_{k}(p) = \\sum_{k=1}^{n} f_{ij}^{k}(g^{-1}p) e_{k}(p)\n$$\nSince $\\{e_k(p)\\}$ forms a basis for the tangent space $T_pG$, we can equate the coefficients:\n$$\nf_{ij}^{k}(p) = f_{ij}^{k}(g^{-1}p)\n$$\nThis equality holds for all $p, g \\in G$. Let us choose $p=g$. Then we have:\n$$\nf_{ij}^{k}(g) = f_{ij}^{k}(g^{-1}g) = f_{ij}^{k}(e)\n$$\nSince $g$ was an arbitrary element of $G$, this shows that the value of the function $f_{ij}^{k}$ at any point $g$ is equal to its value at the identity $e$. Therefore, $f_{ij}^{k}$ is a constant function on $G$. We can define the structure constants $c_{ij}^{k}$ as this constant value: $c_{ij}^{k} = f_{ij}^{k}(p)$ for any $p \\in G$.\n\n### Part 2: Structure Constants for the Heisenberg Group\n\nThe Heisenberg group $\\mathbb{H}$ is the Lie group $(\\mathbb{R}^{3}, \\cdot)$ with coordinates $p=(x,y,z)$ and the group law:\n$$\n(x,y,z) \\cdot (x',y',z') = \\left(x+x',\\; y+y',\\; z+z' + \\frac{1}{2}(xy' - yx')\\right)\n$$\nThe identity element is $e=(0,0,0)$. Let a point in the group be $p=(x,y,z)$. The left translation by $p$ is the map $L_p: \\mathbb{R}^3 \\to \\mathbb{R}^3$ given by $L_p(p') = p \\cdot p'$.\nTo find the left-invariant vector fields, we compute the differential $(dL_p)_e$. Let $p' = (x', y', z')$. The map is $L_p(x', y', z') = (x+x', y+y', z+z' + \\frac{1}{2}(xy' - yx'))$. The Jacobian matrix of this transformation with respect to the variables $(x', y', z')$ is:\n$$\nJ(L_p) = \\frac{\\partial(L_p(p'))}{\\partial p'} = \\begin{pmatrix}\n\\frac{\\partial}{\\partial x'}(x+x') & \\frac{\\partial}{\\partial y'}(x+x') & \\frac{\\partial}{\\partial z'}(x+x') \\\\\n\\frac{\\partial}{\\partial x'}(y+y') & \\frac{\\partial}{\\partial y'}(y+y') & \\frac{\\partial}{\\partial z'}(y+y') \\\\\n\\frac{\\partial}{\\partial x'}(z+z'+\\frac{1}{2}(xy'-yx')) & \\frac{\\partial}{\\partial y'}(z+z'+\\frac{1}{2}(xy'-yx')) & \\frac{\\partial}{\\partial z'}(z+z'+\\frac{1}{2}(xy'-yx'))\n\\end{pmatrix}\n= \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ -\\frac{1}{2}y & \\frac{1}{2}x & 1 \\end{pmatrix}\n$$\nThis matrix represents $(dL_p)_{p'}$ for any $p'$, including $p'=e$. A left-invariant vector field $E$ is determined by its value $E(e)$ at the identity via the relation $E(p) = (dL_p)_e(E(e))$.\nWe are given $e_1(e) = \\partial_x|_e$, $e_2(e) = \\partial_y|_e$, and $e_3(e) = \\partial_z|_e$. In the standard basis of $T_e\\mathbb{R}^3$, these are $(1,0,0)^T$, $(0,1,0)^T$, and $(0,0,1)^T$ respectively.\nAt a point $p=(x,y,z)$, the vectors are:\n$$\ne_{1}(p) = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ -\\frac{1}{2}y & \\frac{1}{2}x & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ -\\frac{1}{2}y \\end{pmatrix} \\implies e_{1} = \\partial_{x} - \\frac{1}{2}y\\partial_{z}\n$$\n$$\ne_{2}(p) = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ -\\frac{1}{2}y & \\frac{1}{2}x & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ \\frac{1}{2}x \\end{pmatrix} \\implies e_{2} = \\partial_{y} + \\frac{1}{2}x\\partial_{z}\n$$\n$$\ne_{3}(p) = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ -\\frac{1}{2}y & \\frac{1}{2}x & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} \\implies e_{3} = \\partial_{z}\n$$\nNow we compute the Lie brackets using the formula $[X,Y]f = X(Y(f)) - Y(X(f))$ or the identity $[fU, gV] = fg[U,V] + f(Ug)V - g(Vf)U$. We use that coordinate vector fields commute, i.e., $[\\partial_i, \\partial_j]=0$.\n\n$[e_1, e_2] = [\\partial_x - \\frac{1}{2}y\\partial_z, \\partial_y + \\frac{1}{2}x\\partial_z]$\n$= [\\partial_x, \\partial_y] + [\\partial_x, \\frac{1}{2}x\\partial_z] - [\\frac{1}{2}y\\partial_z, \\partial_y] - [\\frac{1}{2}y\\partial_z, \\frac{1}{2}x\\partial_z]$\nThe term $[\\partial_x, \\partial_y]=0$.\nFor $[\\partial_x, \\frac{1}{2}x\\partial_z] = (\\partial_x(\\frac{1}{2}x))\\partial_z = \\frac{1}{2}\\partial_z$.\nFor $-[\\frac{1}{2}y\\partial_z, \\partial_y] = -(-\\partial_y(\\frac{1}{2}y)\\partial_z) = \\frac{1}{2}\\partial_z$.\nFor $-[\\frac{1}{2}y\\partial_z, \\frac{1}{2}x\\partial_z] = -\\frac{1}{4}[y\\partial_z, x\\partial_z] = -\\frac{1}{4}(y(\\partial_z x) - x(\\partial_z y))\\partial_z = 0$.\nSo, $[e_1, e_2] = \\frac{1}{2}\\partial_z + \\frac{1}{2}\\partial_z = \\partial_z = e_3$.\n\n$[e_1, e_3] = [\\partial_x - \\frac{1}{2}y\\partial_z, \\partial_z] = [\\partial_x, \\partial_z] - [\\frac{1}{2}y\\partial_z, \\partial_z]$. The first term is $0$. The second term is $-(\\partial_z(\\frac{1}{2}y))\\partial_z = 0$. So, $[e_1, e_3] = 0$.\n\n$[e_2, e_3] = [\\partial_y + \\frac{1}{2}x\\partial_z, \\partial_z] = [\\partial_y, \\partial_z] + [\\frac{1}{2}x\\partial_z, \\partial_z]$. The first term is $0$. The second term is $-(\\partial_z(\\frac{1}{2}x))\\partial_z=0$. So, $[e_2, e_3] = 0$.\n\nThe non-zero Lie brackets are:\n$[e_1, e_2] = e_3 = 0 \\cdot e_1 + 0 \\cdot e_2 + 1 \\cdot e_3 \\implies c_{12}^1=0, c_{12}^2=0, c_{12}^3=1$.\nBy anti-symmetry, $[e_2, e_1] = -e_3 \\implies c_{21}^1=0, c_{21}^2=0, c_{21}^3=-1$.\nAll other brackets $[e_i, e_j]$ are zero. This includes $[e_i, e_i]=0$.\n\nWe can now list all $27$ structure constants $c_{ij}^{k}$ for $i,j,k \\in \\{1,2,3\\}$ in lexicographic order of $(i,j,k)$:\n- For $i=1$:\n  - $j=1$: $[e_1,e_1]=0 \\implies (c_{11}^1,c_{11}^2,c_{11}^3) = (0,0,0)$.\n  - $j=2$: $[e_1,e_2]=e_3 \\implies (c_{12}^1,c_{12}^2,c_{12}^3) = (0,0,1)$.\n  - $j=3$: $[e_1,e_3]=0 \\implies (c_{13}^1,c_{13}^2,c_{13}^3) = (0,0,0)$.\n- For $i=2$:\n  - $j=1$: $[e_2,e_1]=-e_3 \\implies (c_{21}^1,c_{21}^2,c_{21}^3) = (0,0,-1)$.\n  - $j=2$: $[e_2,e_2]=0 \\implies (c_{22}^1,c_{22}^2,c_{22}^3) = (0,0,0)$.\n  - $j=3$: $[e_2,e_3]=0 \\implies (c_{23}^1,c_{23}^2,c_{23}^3) = (0,0,0)$.\n- For $i=3$:\n  - For $j=1,2,3$: $[e_3, e_j]=0 \\implies (c_{3j}^1,c_{3j}^2,c_{3j}^3) = (0,0,0)$.\n\nThe resulting row vector of constants is constructed by concatenating these triples.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix}\n}\n$$", "id": "2982723"}, {"introduction": "This final practice connects the algebraic properties of a Lie algebra to the global geometry of the corresponding Lie group. It asks you to identify the precise conditions under which a Lie group can support a bi-invariant Riemannian metric—a metric that is symmetric with respect to both left and right multiplication. By analyzing the adjoint representation of the Heisenberg group's Lie algebra, you will discover why its specific non-abelian structure, characterized by the structure constants you explored previously, makes the existence of such a highly symmetric metric impossible.", "problem": "Consider a connected Lie group $G$ with Lie algebra $\\mathfrak{g}$. A Riemannian metric on $G$ is called left-invariant if it is preserved by left translations, and bi-invariant if it is preserved by both left and right translations. Write $\\operatorname{Ad}(G)$ for the adjoint representation and $\\operatorname{ad}_x$ for the adjoint action of $x \\in \\mathfrak{g}$ on $\\mathfrak{g}$. A bilinear form $\\langle \\cdot, \\cdot \\rangle$ on $\\mathfrak{g}$ is called $\\operatorname{ad}$-invariant if for all $x,y,z \\in \\mathfrak{g}$ one has $\\langle [x,y], z\\rangle + \\langle y, [x,z]\\rangle = 0$. Recall that the Killing form $B$ on $\\mathfrak{g}$ is defined by $B(x,y) = \\operatorname{tr}(\\operatorname{ad}_x \\circ \\operatorname{ad}_y)$.\n\nFundamental base:\n- A bi-invariant Riemannian metric on $G$ corresponds to an $\\operatorname{Ad}(G)$-invariant positive-definite inner product on $\\mathfrak{g}$ via left translation.\n- For a Riemannian metric with Levi-Civita connection $\\nabla$, the Koszul formula holds for vector fields $X,Y,Z$:\n$$\n2\\langle \\nabla_X Y, Z\\rangle \\;=\\; X\\langle Y,Z\\rangle + Y\\langle Z,X\\rangle - Z\\langle X,Y\\rangle + \\langle [X,Y],Z\\rangle - \\langle [Y,Z],X\\rangle - \\langle [Z,X],Y\\rangle.\n$$\n- For left-invariant vector fields on $G$ induced by elements of $\\mathfrak{g}$, the bracket of fields is the left-invariant field induced by the Lie bracket on $\\mathfrak{g}$.\n\nLet $H_3$ denote the $3$-dimensional real Heisenberg group with Lie algebra spanned by $\\{X,Y,Z\\}$ and nontrivial bracket $[X,Y] = Z$ (with $Z$ central). One-parameter subgroups in $G$ are curves of the form $\\exp(tu)$ for $u \\in \\mathfrak{g}$.\n\nChoose the option that gives a correct necessary and sufficient criterion for the existence of a bi-invariant Riemannian metric on a connected, possibly non-semisimple Lie group $G$, and a correct explanation of why the Heisenberg group $H_3$ fails to admit such a metric. You may assume all groups are finite-dimensional and all metrics are positive-definite.\n\nA. $G$ admits a bi-invariant Riemannian metric if and only if there exists an $\\operatorname{Ad}(G)$-invariant positive-definite inner product on $\\mathfrak{g}$, equivalently, $\\operatorname{ad}_x$ is skew-symmetric with respect to some positive-definite inner product for every $x \\in \\mathfrak{g}$. This holds precisely when $\\mathfrak{g}$ decomposes as $\\mathfrak{g} = \\mathfrak{s} \\oplus \\mathfrak{z}$ with $\\mathfrak{s}$ compact semisimple and $\\mathfrak{z}$ a central abelian subalgebra. The Heisenberg group fails because its noncentral elements have nonzero nilpotent $\\operatorname{ad}$-maps, which cannot be skew-symmetric in any positive-definite inner product.\n\nB. $G$ admits a bi-invariant Riemannian metric if and only if the Killing form $B$ on $\\mathfrak{g}$ is nondegenerate; the Heisenberg group fails because its Killing form is degenerate (indeed, zero).\n\nC. $G$ admits a bi-invariant Riemannian metric if and only if $G$ is unimodular and every one-parameter subgroup is a geodesic for some left-invariant metric; the Heisenberg group fails because it is not unimodular.\n\nD. $G$ admits a bi-invariant Riemannian metric if and only if the center of $G$ is trivial; the Heisenberg group fails because it has a nontrivial center.", "solution": "The problem statement is a valid question in the field of differential geometry and Lie theory. It provides standard definitions and asks for the application of a known classification theorem to a specific example. All provided information is scientifically sound and mathematically consistent.\n\nA connected Lie group $G$ admits a bi-invariant Riemannian metric if and only if its Lie algebra $\\mathfrak{g}$ admits a positive-definite inner product $\\langle \\cdot, \\cdot \\rangle$ that is invariant under the adjoint representation $\\operatorname{Ad}(G)$. This means for any $g \\in G$ and $u, v \\in \\mathfrak{g}$, we have $\\langle \\operatorname{Ad}_g(u), \\operatorname{Ad}_g(v) \\rangle = \\langle u, v \\rangle$.\n\nSince $G$ is connected, this is equivalent to the inner product being invariant under the adjoint action of the Lie algebra $\\mathfrak{g}$. For any $x \\in \\mathfrak{g}$, the operator $\\operatorname{ad}_x: \\mathfrak{g} \\to \\mathfrak{g}$ must be skew-symmetric with respect to the inner product. That is, for all $x, y, z \\in \\mathfrak{g}$:\n$$\n\\langle \\operatorname{ad}_x(y), z \\rangle + \\langle y, \\operatorname{ad}_x(z) \\rangle = 0\n$$\nUsing the definition $\\operatorname{ad}_x(y) = [x,y]$, this is precisely the condition for an $\\operatorname{ad}$-invariant bilinear form given in the problem statement:\n$$\n\\langle [x,y], z \\rangle + \\langle y, [x,z] \\rangle = 0\n$$\nAn operator on a finite-dimensional real vector space is skew-symmetric with respect to some positive-definite inner product if and only if the operator is diagonalizable over the complex numbers $\\mathbb{C}$ and has purely imaginary eigenvalues. A key property of operators that are skew-symmetric with respect to an inner product is that they are normal. A normal operator is diagonalizable. A nilpotent operator is diagonalizable if and only if it is the zero operator. Therefore, a non-zero nilpotent operator cannot be skew-symmetric with respect to any positive-definite inner product.\n\nThe structure theorem for real Lie algebras that admit such an inner product states that $\\mathfrak{g}$ must be a direct sum of ideals $\\mathfrak{g} = \\mathfrak{s} \\oplus \\mathfrak{z}$, where $\\mathfrak{s} = [\\mathfrak{g},\\mathfrak{g}]$ is a semisimple Lie algebra whose associated connected and simply connected Lie group is compact (such an $\\mathfrak{s}$ is called a compact semisimple Lie algebra), and $\\mathfrak{z}$ is the center of $\\mathfrak{g}$. Such Lie algebras are called reductive of compact type.\n\nNow, we analyze the $3$-dimensional real Heisenberg Lie algebra, $\\mathfrak{h}_3$. It has a basis $\\{X,Y,Z\\}$ with the Lie bracket relations $[X,Y]=Z$, $[X,Z]=0$, and $[Y,Z]=0$. The element $Z$ spans the center of $\\mathfrak{h}_3$.\nThe adjoint operators are:\n$\\operatorname{ad}_X(X)=0$, $\\operatorname{ad}_X(Y)=Z$, $\\operatorname{ad}_X(Z)=0$.\n$\\operatorname{ad}_Y(X)=-Z$, $\\operatorname{ad}_Y(Y)=0$, $\\operatorname{ad}_Y(Z)=0$.\n$\\operatorname{ad}_Z(u)=0$ for all $u \\in \\mathfrak{h}_3$.\n\nIn the basis $\\{X,Y,Z\\}$, the matrix representations of these operators are:\n$$\n\\operatorname{ad}_X = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 1 & 0 \\end{pmatrix}, \\quad \\operatorname{ad}_Y = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ -1 & 0 & 0 \\end{pmatrix}, \\quad \\operatorname{ad}_Z = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\nThe operators $\\operatorname{ad}_X$ and $\\operatorname{ad}_Y$ are non-zero. They are also nilpotent, as $(\\operatorname{ad}_X)^2 = 0$ and $(\\operatorname{ad}_Y)^2 = 0$. As established, a non-zero nilpotent operator cannot be skew-symmetric with respect to any positive-definite inner product.\nThus, there is no positive-definite inner product on $\\mathfrak{h}_3$ for which all operators $\\operatorname{ad}_u$ ($u \\in \\mathfrak{h}_3$) are skew-symmetric. Consequently, the Heisenberg group $H_3$ does not admit a bi-invariant Riemannian metric. The Lie algebra $\\mathfrak{h}_3$ is nilpotent and non-abelian, so it does not have the required structure $\\mathfrak{s} \\oplus \\mathfrak{z}$.\n\nWith this foundation, we evaluate the options.\n\n**Option A:** \"$G$ admits a bi-invariant Riemannian metric if and only if there exists an $\\operatorname{Ad}(G)$-invariant positive-definite inner product on $\\mathfrak{g}$, equivalently, $\\operatorname{ad}_x$ is skew-symmetric with respect to some positive-definite inner product for every $x \\in \\mathfrak{g}$. This holds precisely when $\\mathfrak{g}$ decomposes as $\\mathfrak{g} = \\mathfrak{s} \\oplus \\mathfrak{z}$ with $\\mathfrak{s}$ compact semisimple and $\\mathfrak{z}$ a central abelian subalgebra. The Heisenberg group fails because its noncentral elements have nonzero nilpotent $\\operatorname{ad}$-maps, which cannot be skew-symmetric in any positive-definite inner product.\"\n\nThis option correctly states the equivalence between a bi-invariant metric on $G$ and an $\\operatorname{Ad}(G)$-invariant (or $\\operatorname{ad}$-invariant) inner product on $\\mathfrak{g}$. It correctly gives the structure theorem for such Lie algebras. The explanation for why $H_3$ fails to admit such a metric is also correct: the non-zero operators $\\operatorname{ad}_X$ and $\\operatorname{ad}_Y$ are nilpotent and therefore cannot be skew-symmetric with respect to any positive-definite inner product.\n**Verdict: Correct.**\n\n**Option B:** \"$G$ admits a bi-invariant Riemannian metric if and only if the Killing form $B$ on $\\mathfrak{g}$ is nondegenerate; the Heisenberg group fails because its Killing form is degenerate (indeed, zero).\"\n\nThe criterion is incorrect. A non-degenerate Killing form is the definition of a semisimple Lie algebra. While a compact semisimple Lie group admits a bi-invariant metric (given by the negative of the Killing form), this condition is not necessary. For example, any abelian Lie group (like a torus $T^n$) has a bi-invariant metric (the flat one), but its Lie bracket is trivial, so $\\operatorname{ad}_x=0$ for all $x$, and its Killing form is identically zero, which is degenerate. The Heisenberg algebra $\\mathfrak{h}_3$ is nilpotent, so its Killing form is identically zero, $B(u,v) = \\operatorname{tr}(\\operatorname{ad}_u \\circ \\operatorname{ad}_v) = 0$ for all $u,v \\in \\mathfrak{h}_3$. So while the facts about $H_3$ are correct, the necessary and sufficient criterion is false.\n**Verdict: Incorrect.**\n\n**Option C:** \"$G$ admits a bi-invariant Riemannian metric if and only if $G$ is unimodular and every one-parameter subgroup is a geodesic for some left-invariant metric; the Heisenberg group fails because it is not unimodular.\"\n\nThis option is incorrect. First, the property that every one-parameter subgroup is a geodesic for a left-invariant metric is equivalent to that metric being bi-invariant. The criterion is therefore tautological and thus flawed. Second, the reason given for the Heisenberg group's failure is factually wrong. The Heisenberg group is unimodular (since its Lie algebra is nilpotent, $\\operatorname{tr}(\\operatorname{ad}_x) = 0$ for all $x$). While unimodularity is necessary for a bi-invariant metric, it is not sufficient, with the Heisenberg group being a key counterexample.\n**Verdict: Incorrect.**\n\n**Option D:** \"$G$ admits a bi-invariant Riemannian metric if and only if the center of $G$ is trivial; the Heisenberg group fails because it has a nontrivial center.\"\n\nThe criterion is false. A non-trivial center does not preclude the existence of a bi-invariant metric. The torus $T^n = \\mathbb{R}^n/\\mathbb{Z}^n$ is abelian, so its center is the entire group, yet it possesses a bi-invariant flat metric. Therefore, the condition is not necessary. It is also not sufficient. For example, the group $G=\\mathrm{PSL}(2,\\mathbb{R})$ has a trivial center but is non-compact and simple, and does not admit a bi-invariant metric. While it is true that $H_3$ has a nontrivial center and fails to admit a bi-invariant metric, the causal link asserted by the \"if and only if\" statement is incorrect.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "2982733"}]}