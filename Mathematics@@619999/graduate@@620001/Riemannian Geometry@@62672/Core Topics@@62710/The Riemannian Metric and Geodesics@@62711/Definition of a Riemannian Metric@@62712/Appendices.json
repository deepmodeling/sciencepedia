{"hands_on_practices": [{"introduction": "A Riemannian metric forms the bedrock of geometry on a manifold, endowing it with concepts of length, angle, and volume. For a symmetric $(0,2)$-tensor field to qualify as a metric, it must satisfy two crucial conditions at every point: smoothness and positive-definiteness. This exercise [@problem_id:2973806] challenges you to vet these axioms by examining a carefully constructed tensor field that is positive-definite almost everywhere, forcing a precise understanding of why the definition leaves no room for exceptions.", "problem": "Let $M$ be the smooth manifold $\\mathbb{R}^{n}$ equipped with its standard differentiable structure, and let $\\langle \\cdot, \\cdot \\rangle_{\\mathrm{eucl}}$ denote the standard Euclidean inner product on each tangent space $T_{p}\\mathbb{R}^{n} \\cong \\mathbb{R}^{n}$. A Riemannian metric on $M$ is, by definition, a smooth, symmetric, positive-definite $(0,2)$-tensor field $g$, meaning that for each point $p \\in M$, $g_{p}$ is a symmetric bilinear form on $T_{p}M$ such that $g_{p}(v,v) > 0$ for all nonzero $v \\in T_{p}M$, and the assignment $p \\mapsto g_{p}$ is smooth. \n\nWhich one of the following options correctly constructs a smooth, symmetric $(0,2)$-tensor field $g$ on $M$ that is positive-definite on a dense subset of $M$ but not everywhere, and provides a correct explanation of why it fails to define a Riemannian metric?\n\nA. Define $g_{p}(u,v) = \\|p\\| \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$, where $\\|p\\| = \\sqrt{p_{1}^{2} + \\cdots + p_{n}^{2}}$. Then $g$ is smooth and symmetric, it is positive-definite for all $p \\neq 0$, and $g_{0}$ is the zero form. It fails to be a Riemannian metric solely because it is not positive-definite at $p=0$.\n\nB. Define $g_{p}(u,v) = \\sin(\\|p\\|) \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$. Then $g$ is smooth and symmetric, it is positive-definite on the dense subset of points with $\\sin(\\|p\\|) > 0$, and it fails to be a Riemannian metric because it is not positive-definite at points where $\\sin(\\|p\\|) = 0$.\n\nC. Define $\\varphi \\colon \\mathbb{R}^{n} \\to \\mathbb{R}$ by $\\varphi(p) = e^{-1/\\|p\\|^{2}}$ for $p \\neq 0$ and $\\varphi(0) = 0$, and set $g_{p}(u,v) = \\varphi(p) \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$. Then $g$ is smooth and symmetric; it is positive-definite on the dense subset $\\mathbb{R}^{n} \\setminus \\{0\\}$, while $g_{0}$ is the zero bilinear form. It fails to be a Riemannian metric because a Riemannian metric must be positive-definite at every point, which fails at $p=0$.\n\nD. Define $g_{p}(u,v) = \\|u\\| \\, \\|v\\|$ for $u,v \\in T_{p}\\mathbb{R}^{n} \\cong \\mathbb{R}^{n}$. Then $g$ is symmetric and positive for all nonzero $u,v$, so it is positive-definite on a dense subset of $M$ but not everywhere. It fails to be a Riemannian metric because it vanishes on some vectors.\n\nSelect the unique correct option.", "solution": "The user requires a critical validation of the problem statement, followed by a detailed solution and evaluation of the given options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   The manifold is $M = \\mathbb{R}^{n}$ with its standard differentiable structure.\n-   $\\langle \\cdot, \\cdot \\rangle_{\\mathrm{eucl}}$ is the standard Euclidean inner product on each tangent space $T_{p}\\mathbb{R}^{n}$, which is identified with $\\mathbb{R}^{n}$.\n-   A Riemannian metric $g$ is defined as a smooth, symmetric, positive-definite $(0,2)$-tensor field.\n-   Positive-definiteness of $g$ at a point $p \\in M$ means $g_{p}(v,v) > 0$ for all nonzero tangent vectors $v \\in T_{p}M$.\n-   Smoothness means the assignment $p \\mapsto g_{p}$ is a smooth map from $M$ to the bundle of symmetric $(0,2)$-tensors.\n-   The task is to identify the option that correctly constructs a tensor field $g$ on $M=\\mathbb{R}^n$ with the following properties:\n    1.  $g$ is a smooth, symmetric $(0,2)$-tensor field.\n    2.  $g$ is positive-definite on a dense subset of $M$.\n    3.  $g$ is *not* positive-definite everywhere on $M$.\n    4.  The option provides a correct explanation for why $g$ fails to be a Riemannian metric.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is based on the standard and fundamental definition of a Riemannian metric in differential geometry. All concepts used are standard and well-defined.\n-   **Well-Posed:** The problem is clearly stated. It asks for the evaluation of several proposed constructions against a precise set of criteria derived from the definition of a Riemannian metric. The question is unambiguous and admits a verifiable answer.\n-   **Objective:** The problem is phrased using precise mathematical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\n-   **Verdict:** The problem statement is valid. It is a standard exercise in verifying the axioms of a mathematical structure.\n-   **Action:** Proceed to the solution phase by analyzing each option.\n\n### Solution Derivation and Option-by-Option Analysis\n\nA $(0,2)$-tensor field $g$ on $M=\\mathbb{R}^n$ of the form $g_{p}(u,v) = f(p) \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$ for a function $f: \\mathbb{R}^n \\to \\mathbb{R}$ must satisfy several conditions to be a Riemannian metric:\n1.  **Bilinearity and Symmetry:** For any fixed $p$, $g_p$ must be a symmetric bilinear form. The Euclidean inner product $\\langle \\cdot, \\cdot \\rangle_{\\mathrm{eucl}}$ is a symmetric bilinear form. Multiplying it by a scalar $f(p)$ preserves these properties. So, for options A, B, and C, $g_p$ is a symmetric bilinear form for each $p$.\n2.  **Smoothness:** The tensor field $p \\mapsto g_p$ must be smooth. Since the standard Euclidean metric is smooth (its components in standard coordinates are constant), this is equivalent to the scalar function $f(p)$ being a smooth ($C^{\\infty}$) function on $\\mathbb{R}^n$.\n3.  **Positive-Definiteness:** For every $p \\in M$, $g_p$ must be positive-definite. This means $g_p(v,v) > 0$ for all nonzero $v \\in T_pM$. For the given form, $g_p(v,v) = f(p) \\langle v, v \\rangle_{\\mathrm{eucl}} = f(p) \\|v\\|_{\\mathrm{eucl}}^2$. Since $\\|v\\|_{\\mathrm{eucl}}^2 > 0$ for $v \\neq 0$, this condition is equivalent to $f(p) > 0$ for all $p \\in \\mathbb{R}^n$.\n\nWe now evaluate each option against these criteria.\n\n**A. Define $g_{p}(u,v) = \\|p\\| \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$, where $\\|p\\| = \\sqrt{p_{1}^{2} + \\cdots + p_{n}^{2}}$.**\n-   This corresponds to $f(p) = \\|p\\|$.\n-   **Smoothness:** The function $f(p) = \\|p\\|$ is not smooth on $\\mathbb{R}^n$. It is not differentiable at $p=0$. For example, in the case $n=1$, $f(p) = |p|$, which is not differentiable at $p=0$. For $n>1$, the partial derivative $\\frac{\\partial}{\\partial p_i} \\|p\\| = \\frac{p_i}{\\|p\\|}$ is undefined at $p=0$. Since a Riemannian metric must be a smooth tensor field, this construction fails on the smoothness criterion.\n-   **Conclusion:** The statement in option A that \"$g$ is smooth\" is false. Therefore, the option provides an incorrect construction. The reason it fails to be a Riemannian metric is not *solely* the lack of positive-definiteness at $p=0$; it also fails the smoothness condition at $p=0$.\n-   **Verdict:** **Incorrect**.\n\n**B. Define $g_{p}(u,v) = \\sin(\\|p\\|) \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$.**\n-   This corresponds to $f(p) = \\sin(\\|p\\|)$.\n-   **Smoothness:** The function $f(p)$ is a composition of the sine function (which is smooth) and the norm function $\\|p\\|$. As established in the analysis of option A, $\\|p\\|$ is not smooth at $p=0$. The composition of a smooth function with a non-smooth function is generally not smooth. Let's check for $n=1$: $f(p) = \\sin(|p|)$. The derivative for $p \\neq 0$ is $f'(p) = \\cos(|p|) \\cdot \\text{sgn}(p)$. As $p \\to 0^+$, $f'(p) \\to 1$. As $p \\to 0^-$, $f'(p) \\to -1$. Since the limits of the derivative do not match, the function is not differentiable at $p=0$. Thus, $g$ is not a smooth tensor field on $\\mathbb{R}^n$.\n-   **Conclusion:** The statement in option B that \"$g$ is smooth\" is false. This option is incorrect for the same primary reason as option A. Additionally, the condition for positive-definiteness is $\\sin(\\|p\\|) > 0$. At points where $\\sin(\\|p\\|) < 0$, the form $g_p$ is negative-definite, which is also a failure. The given explanation is incomplete.\n-   **Verdict:** **Incorrect**.\n\n**C. Define $\\varphi \\colon \\mathbb{R}^{n} \\to \\mathbb{R}$ by $\\varphi(p) = e^{-1/\\|p\\|^{2}}$ for $p \\neq 0$ and $\\varphi(0) = 0$, and set $g_{p}(u,v) = \\varphi(p) \\, \\langle u, v \\rangle_{\\mathrm{eucl}}$.**\n-   This corresponds to $f(p) = \\varphi(p)$.\n-   **Smoothness:** The function $\\varphi(p)$ is a standard example of a smooth function that is not analytic at the origin. For $p \\neq 0$, $\\varphi(p)$ is a composition of smooth functions ($p \\mapsto \\|p\\|^2$, $t \\mapsto -1/t$, $s \\mapsto e^s$), so it is smooth. At $p=0$, one can show that all partial derivatives of any order exist and are equal to $0$. This involves showing that for any multi-index $\\alpha$, $\\lim_{p \\to 0} D^{\\alpha}\\varphi(p) = 0$. The derivatives for $p \\neq 0$ are of the form $P(p) \\|p\\|^{-k} e^{-1/\\|p\\|^2}$ for some polynomial $P$ and integer $k$. The exponential term $e^{-1/\\|p\\|^2}$ goes to $0$ faster than any polynomial in $\\|p\\|^{-1}$ grows as $p \\to 0$. Thus, all derivatives approach $0$ at the origin, proving that $\\varphi(p)$ is a smooth ($C^{\\infty}$) function on all of $\\mathbb{R}^n$. Consequently, $g$ is a smooth, symmetric $(0,2)$-tensor field.\n-   **Positive-Definiteness:** For $g_p$ to be positive-definite, we need $\\varphi(p) > 0$.\n    -   For any $p \\neq 0$, $\\|p\\|^2 > 0$, so $e^{-1/\\|p\\|^2} > 0$. Thus, $g_p$ is positive-definite on the set $\\mathbb{R}^n \\setminus \\{0\\}$. This set is a dense subset of $\\mathbb{R}^n$.\n    -   At $p=0$, $\\varphi(0) = 0$ by definition. This means $g_{0}(u,v) = 0 \\cdot \\langle u,v \\rangle_{\\mathrm{eucl}} = 0$ for all $u,v$. For any nonzero vector $v \\in T_0 \\mathbb{R}^n$, we have $g_0(v,v)=0$, which violates the positive-definiteness condition $g_0(v,v)>0$. So, $g$ is not positive-definite everywhere.\n-   **Explanation:** The option correctly identifies that $g$ is smooth and symmetric, is positive-definite on the dense set $\\mathbb{R}^n \\setminus \\{0\\}$, and fails to be a Riemannian metric because it is not positive-definite at the single point $p=0$. This explanation is accurate and complete.\n-   **Verdict:** **Correct**.\n\n**D. Define $g_{p}(u,v) = \\|u\\| \\, \\|v\\|$ for $u,v \\in T_{p}\\mathbb{R}^{n} \\cong \\mathbb{R}^{n}$.**\n-   **Bilinearity:** This proposed object $g_p$ is not a bilinear form, and therefore not a $(0,2)$-tensor. Let's check linearity in the first argument. For $\\alpha \\in \\mathbb{R}$ and $u, v \\in T_p \\mathbb{R}^n$:\n    $g_p(\\alpha u, v) = \\|\\alpha u\\| \\|v\\| = |\\alpha| \\|u\\| \\|v\\|$.\n    For this to equal $\\alpha g_p(u, v) = \\alpha \\|u\\| \\|v\\|$, we would need $|\\alpha| = \\alpha$, which is only true for $\\alpha \\ge 0$. Since this does not hold for all $\\alpha \\in \\mathbb{R}$, $g_p$ is not linear in the first argument. It is not a bilinear form.\n-   **Conclusion:** The fundamental premise that $g$ is a $(0,2)$-tensor field is false. Any subsequent discussion of positive-definiteness or why it fails to be a Riemannian metric is moot. The term \"positive-definite\" is defined for symmetric bilinear forms, a category to which $g_p$ does not belong.\n-   **Verdict:** **Incorrect**.\n\nBased on the detailed analysis, only option C correctly constructs a tensor field with the specified properties and provides a correct explanation for its failure to be a Riemannian metric.", "answer": "$$\\boxed{C}$$", "id": "2973806"}, {"introduction": "With the definition of a Riemannian metric established, we turn to its primary application: measuring distance. The metric $g$ provides a way to calculate the length of any tangent vector $v$ at a point $p$ via the norm $|v|_{g} = \\sqrt{g_{p}(v,v)}$, and integrating this pointwise norm along a curve yields its total length. This practice [@problem_id:2973818] provides a concrete scenario to apply this procedure, calculating the length of a path in the Poincar√© disk model of hyperbolic space and demonstrating how the metric dictates the geometry.", "problem": "Let $M$ be the open unit disk $D=\\{(x,y)\\in\\mathbb{R}^{2}\\,:\\,x^{2}+y^{2}<1\\}$ endowed with the Riemannian metric $g$ whose coordinate components in the standard coordinates $(x,y)$ are\n$$\ng_{ij}(x,y)=\\frac{1}{\\bigl(1-x^{2}-y^{2}\\bigr)^{2}}\\,\\delta_{ij},\\quad i,j\\in\\{1,2\\}.\n$$\nA Riemannian metric is a smooth field of positive-definite symmetric bilinear forms, and it induces at each point a pointwise norm on tangent vectors by $|\\dot{\\gamma}(t)|_{g}=\\sqrt{g_{ij}(\\gamma(t))\\,\\dot{x}^{i}(t)\\,\\dot{x}^{j}(t)}$ for a curve $\\gamma(t)=(x^{1}(t),x^{2}(t))=(x(t),y(t))$. The length of a piecewise smooth curve $\\gamma\\colon[a,b]\\to M$ is $L(\\gamma)=\\int_{a}^{b}|\\dot{\\gamma}(t)|_{g}\\,dt$.\n\nConsider the $x$-coordinate curve at $y=0$ from $x=0$ to $x=a$, where $a\\in(0,1)$, parametrized by $\\gamma(t)=(t,0)$ for $t\\in[0,a]$. Using only the definitions above, compute the length $L(\\gamma)$ and express your final answer as a closed-form analytic expression in $a$. Also interpret the integrand as the pointwise norm $\\sqrt{g_{ij}\\dot{x}^{i}\\dot{x}^{j}}$ along $\\gamma$. No rounding is required and no units are to be included.", "solution": "The problem asks for the length of a specific curve within the open unit disk $M = D = \\{(x,y)\\in\\mathbb{R}^{2}\\,:\\,x^{2}+y^{2}<1\\}$, which is endowed with a Riemannian metric $g$.\n\nFirst, we establish the necessary components for the calculation based on the provided definitions.\nThe Riemannian metric $g$ has components $g_{ij}(x,y)=\\frac{1}{(1-x^{2}-y^{2})^{2}}\\,\\delta_{ij}$ in the standard coordinates $(x,y)$, where $\\delta_{ij}$ is the Kronecker delta. Let $x^1 = x$ and $x^2 = y$. The metric tensor can be written in matrix form as:\n$$\n[g_{ij}(x,y)] = \n\\begin{pmatrix}\ng_{11} & g_{12} \\\\\ng_{21} & g_{22}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{1}{(1-x^2-y^2)^2} & 0 \\\\\n0 & \\frac{1}{(1-x^2-y^2)^2}\n\\end{pmatrix}\n$$\nThe curve in question, $\\gamma$, is the $x$-coordinate curve from $x=0$ to $x=a$, where $a \\in (0, 1)$, at a constant $y=0$. This curve is parametrized by $\\gamma(t) = (x(t), y(t)) = (t, 0)$ for $t \\in [0, a]$.\n\nTo calculate the length $L(\\gamma) = \\int_{0}^{a} |\\dot{\\gamma}(t)|_{g}\\,dt$, we first need to find the tangent vector $\\dot{\\gamma}(t)$ and its pointwise norm $|\\dot{\\gamma}(t)|_g$.\nThe tangent vector is the derivative of the curve with respect to the parameter $t$:\n$$\n\\dot{\\gamma}(t) = (\\dot{x}(t), \\dot{y}(t)) = \\left(\\frac{d}{dt}(t), \\frac{d}{dt}(0)\\right) = (1, 0)\n$$\nIn indexed notation, this corresponds to $\\dot{x}^1(t) = 1$ and $\\dot{x}^2(t) = 0$.\n\nNext, we evaluate the metric tensor components along the curve $\\gamma(t)$. We substitute $x=t$ and $y=0$ into the expression for $g_{ij}(x,y)$:\n$$\ng_{ij}(\\gamma(t)) = g_{ij}(t, 0) = \\frac{1}{(1-t^2-0^2)^2}\\,\\delta_{ij} = \\frac{1}{(1-t^2)^2}\\,\\delta_{ij}\n$$\nSo, along the curve, we have $g_{11}(\\gamma(t)) = \\frac{1}{(1-t^2)^2}$, $g_{22}(\\gamma(t)) = \\frac{1}{(1-t^2)^2}$, and $g_{12}(\\gamma(t)) = g_{21}(\\gamma(t)) = 0$.\n\nNow we compute the integrand, which is the pointwise norm $|\\dot{\\gamma}(t)|_g$. As per the problem's definition, this norm is given by the square root of the inner product of the tangent vector with itself:\n$$\n|\\dot{\\gamma}(t)|_g = \\sqrt{g_{ij}(\\gamma(t))\\,\\dot{x}^{i}(t)\\,\\dot{x}^{j}(t)}\n$$\nExpanding the sum using Einstein notation:\n$$\n|\\dot{\\gamma}(t)|_g^2 = g_{11}(\\dot{x}^1)^2 + g_{12}\\dot{x}^1\\dot{x}^2 + g_{21}\\dot{x}^2\\dot{x}^1 + g_{22}(\\dot{x}^2)^2\n$$\nSubstituting the values for the metric components along $\\gamma$ and the components of the tangent vector $\\dot{\\gamma}$:\n$$\n|\\dot{\\gamma}(t)|_g^2 = \\left(\\frac{1}{(1-t^2)^2}\\right)(1)^2 + (0)(1)(0) + (0)(0)(1) + \\left(\\frac{1}{(1-t^2)^2}\\right)(0)^2 = \\frac{1}{(1-t^2)^2}\n$$\nTaking the square root gives the pointwise norm:\n$$\n|\\dot{\\gamma}(t)|_g = \\sqrt{\\frac{1}{(1-t^2)^2}} = \\frac{1}{|1-t^2|}\n$$\nSince the parameter $t$ lies in the interval $[0, a]$ and $a \\in (0, 1)$, we have $0 \\le t < 1$, which implies $t^2 < 1$ and therefore $1-t^2 > 0$. Thus, we can remove the absolute value signs:\n$$\n|\\dot{\\gamma}(t)|_g = \\frac{1}{1-t^2}\n$$\nThis expression is the integrand for the length calculation. This also fulfills the requirement to interpret the integrand as the pointwise norm.\n\nFinally, we compute the length $L(\\gamma)$ by integrating this norm from $t=0$ to $t=a$:\n$$\nL(\\gamma) = \\int_0^a \\frac{1}{1-t^2} \\, dt\n$$\nTo evaluate this integral, we use partial fraction decomposition for the integrand:\n$$\n\\frac{1}{1-t^2} = \\frac{1}{(1-t)(1+t)} = \\frac{A}{1-t} + \\frac{B}{1+t}\n$$\nMultiplying by $(1-t)(1+t)$ gives $1 = A(1+t) + B(1-t)$. Setting $t=1$ yields $1 = 2A$, so $A=\\frac{1}{2}$. Setting $t=-1$ yields $1 = 2B$, so $B=\\frac{1}{2}$.\nThe integrand is therefore:\n$$\n\\frac{1}{1-t^2} = \\frac{1}{2}\\left(\\frac{1}{1-t} + \\frac{1}{1+t}\\right)\n$$\nNow we can integrate:\n$$\nL(\\gamma) = \\int_0^a \\frac{1}{2}\\left(\\frac{1}{1-t} + \\frac{1}{1+t}\\right) dt = \\frac{1}{2} \\left[ -\\ln|1-t| + \\ln|1+t| \\right]_0^a\n$$\nThis can be written as:\n$$\nL(\\gamma) = \\frac{1}{2} \\left[ \\ln\\left|\\frac{1+t}{1-t}\\right| \\right]_0^a\n$$\nAs established before, for $t \\in [0,a]$ with $a<1$, the terms $1+t$ and $1-t$ are always positive, so we can drop the absolute value bars. Evaluating the definite integral:\n$$\nL(\\gamma) = \\frac{1}{2} \\left( \\ln\\left(\\frac{1+a}{1-a}\\right) - \\ln\\left(\\frac{1+0}{1-0}\\right) \\right) = \\frac{1}{2} \\left( \\ln\\left(\\frac{1+a}{1-a}\\right) - \\ln(1) \\right)\n$$\nSince $\\ln(1)=0$, the length of the curve is:\n$$\nL(\\gamma) = \\frac{1}{2}\\ln\\left(\\frac{1+a}{1-a}\\right)\n$$\nThis is the closed-form analytic expression for the length of the curve $\\gamma$ in terms of $a$. This expression is equivalent to the inverse hyperbolic tangent, $\\operatorname{artanh}(a)$.", "answer": "$$\n\\boxed{\\frac{1}{2}\\ln\\left(\\frac{1+a}{1-a}\\right)}\n$$", "id": "2973818"}, {"introduction": "Beyond its component form $g_{ij}$, a Riemannian metric can be expressed in terms of an orthonormal coframe $\\{\\theta^{i}\\}$, where the metric takes the simple form $g = \\sum_{i} \\theta^{i} \\otimes \\theta^{i}$. This exercise [@problem_id:2973830] guides you through the constructive process of finding such a coframe from the metric components, a procedure equivalent to a pointwise matrix factorization. Mastering this technique provides a gateway to the powerful \"method of moving frames,\" essential for advanced calculations in geometry and physics.", "problem": "Let $M = \\mathbb{R}^{3}$ with global coordinates $(x,y,z)$ and coordinate coframe $\\{dx,dy,dz\\}$. A Riemannian metric is a smooth field of symmetric positive-definite bilinear forms $g_{p}$ on each tangent space $T_{p}M$, and in local coordinates it is represented by a symmetric positive-definite matrix field $[g_{ij}(x,y,z)]$ via $g = g_{ij}\\,dx^{i}\\otimes dx^{j}$ (Einstein summation convention). An orthonormal coframe $\\{\\theta^{1},\\theta^{2},\\theta^{3}\\}$ for $g$ is a set of $1$-forms such that $g = \\delta_{ij}\\,\\theta^{i}\\otimes \\theta^{j}$, where $\\delta_{ij}$ is the Kronecker delta.\n\nConsider the metric given in the coordinate coframe $\\{dx,dy,dz\\}$ by the smooth symmetric positive-definite matrix field\n$$\n[g_{ij}(x,y,z)] \\;=\\;\n\\begin{pmatrix}\n(1+x^{2})^{2} & y(1+x^{2}) & z(1+x^{2}) \\\\\ny(1+x^{2}) & y^{2}+(1+y^{2})^{2} & yz(2+y^{2}) \\\\\nz(1+x^{2}) & yz(2+y^{2}) & z^{2}+y^{2}z^{2}+(1+z^{2})^{2}\n\\end{pmatrix}.\n$$\nUsing only the facts that a Riemannian metric is pointwise symmetric positive-definite and that such matrices admit a smooth pointwise factorization into a product of a transpose and itself with positive diagonal entries, construct an orthonormal coframe $\\{\\theta^{1},\\theta^{2},\\theta^{3}\\}$ relative to $\\{dx,dy,dz\\}$, written explicitly in terms of $x$, $y$, $z$ and the coordinate $1$-forms $dx$, $dy$, $dz$.\n\nExpress your final answer as a single row matrix containing $(\\theta^{1},\\theta^{2},\\theta^{3})$ in closed form. No rounding is required, and no units are involved.", "solution": "The problem statement is a valid exercise in Riemannian geometry. It is scientifically grounded, well-posed, and objective. All necessary data and definitions are provided, and there are no internal contradictions or ambiguities. We may therefore proceed with the solution.\n\nThe problem asks for the construction of an orthonormal coframe $\\{\\theta^{1}, \\theta^{2}, \\theta^{3}\\}$ for a given Riemannian metric $g$ on $M=\\mathbb{R}^{3}$. The metric is specified by its component matrix $[g_{ij}]$ in the standard coordinate coframe $\\{dx^{1}, dx^{2}, dx^{3}\\} = \\{dx, dy, dz\\}$. The relationship between the metric $g$ and its components is given by the Einstein summation convention as $g = g_{ij} dx^{i} \\otimes dx^{j}$.\n\nAn orthonormal coframe is a set of $1$-forms $\\{\\theta^{1}, \\theta^{2}, \\theta^{3}\\}$ such that the metric can be expressed as $g = \\sum_{k=1}^{3} \\theta^{k} \\otimes \\theta^{k}$, which is equivalent to $g = \\delta_{ij} \\theta^{i} \\otimes \\theta^{j}$. Each element $\\theta^{k}$ of the coframe is a $1$-form and can be expressed as a linear combination of the basis $1$-forms $\\{dx^{j}\\}$:\n$$\n\\theta^{k} = \\sum_{j=1}^{3} A^{k}_{j} dx^{j}\n$$\nThe functions $A^{k}_{j}(x,y,z)$ are the components of the coframe relative to the coordinate basis. Let $A$ be the $3 \\times 3$ matrix with entries $[A]_{kj} = A^{k}_{j}$.\n\nSubstituting the expression for $\\theta^{k}$ into the orthonormal representation of the metric $g$, we get:\n$$\ng = \\sum_{k=1}^{3} \\left( \\sum_{i=1}^{3} A^{k}_{i} dx^{i} \\right) \\otimes \\left( \\sum_{j=1}^{3} A^{k}_{j} dx^{j} \\right) = \\sum_{i,j=1}^{3} \\left( \\sum_{k=1}^{3} A^{k}_{i} A^{k}_{j} \\right) dx^{i} \\otimes dx^{j}\n$$\nBy comparing this with the coordinate representation $g = g_{ij} dx^{i} \\otimes dx^{j}$, we identify the components of the metric tensor as:\n$$\ng_{ij} = \\sum_{k=1}^{3} A^{k}_{i} A^{k}_{j}\n$$\nThis equation in matrix form is $G = A^{T}A$, where $G$ is the matrix $[g_{ij}]$ and $A^{T}$ is the transpose of $A$.\n\nThe problem states that we must use the fact that the symmetric positive-definite matrix $G$ admits a factorization $G = A^{T}A$ where $A$ has positive diagonal entries. A standard procedure to find such a matrix $A$ is the Cholesky decomposition, which finds a unique lower triangular matrix $L$ with positive diagonal entries such that $G=LL^{T}$. If we set $A=L^{T}$, then $A$ is upper triangular with positive diagonal entries, and $A^{T}A = (L^{T})^{T}L^{T} = LL^{T} = G$, satisfying the requirement.\n\nLet $A$ be an upper triangular matrix:\n$$\nA = \\begin{pmatrix} A^{1}_{1} & A^{1}_{2} & A^{1}_{3} \\\\ 0 & A^{2}_{2} & A^{2}_{3} \\\\ 0 & 0 & A^{3}_{3} \\end{pmatrix}\n$$\nwith $A^{1}_{1} > 0$, $A^{2}_{2} > 0$, and $A^{3}_{3} > 0$. Then its transpose is:\n$$\nA^{T} = \\begin{pmatrix} A^{1}_{1} & 0 & 0 \\\\ A^{1}_{2} & A^{2}_{2} & 0 \\\\ A^{1}_{3} & A^{2}_{3} & A^{3}_{3} \\end{pmatrix}\n$$\nThe product $A^{T}A$ yields the matrix of metric components:\n$$\nG = A^{T}A = \\begin{pmatrix}\n(A^{1}_{1})^{2} & A^{1}_{1}A^{1}_{2} & A^{1}_{1}A^{1}_{3} \\\\\nA^{1}_{1}A^{1}_{2} & (A^{1}_{2})^{2}+(A^{2}_{2})^{2} & A^{1}_{2}A^{1}_{3}+A^{2}_{2}A^{2}_{3} \\\\\nA^{1}_{1}A^{1}_{3} & A^{1}_{2}A^{1}_{3}+A^{2}_{2}A^{2}_{3} & (A^{1}_{3})^{2}+(A^{2}_{3})^{2}+(A^{3}_{3})^{2}\n\\end{pmatrix}\n$$\nThe given metric matrix is:\n$$\nG = [g_{ij}] =\n\\begin{pmatrix}\n(1+x^{2})^{2} & y(1+x^{2}) & z(1+x^{2}) \\\\\ny(1+x^{2}) & y^{2}+(1+y^{2})^{2} & yz(2+y^{2}) \\\\\nz(1+x^{2}) & yz(2+y^{2}) & z^{2}+y^{2}z^{2}+(1+z^{2})^{2}\n\\end{pmatrix}\n$$\nWe now solve for the entries of $A$ by equating the components of $G$ with the expression for $A^{T}A$.\n\nFrom the $(1,1)$ component:\n$g_{11} = (A^{1}_{1})^{2} = (1+x^{2})^{2}$. Since $A^{1}_{1}>0$, we have $A^{1}_{1} = 1+x^{2}$.\n\nFrom the $(1,2)$ component:\n$g_{12} = A^{1}_{1}A^{1}_{2} = y(1+x^{2})$. Substituting $A^{1}_{1}$, we get $(1+x^{2})A^{1}_{2} = y(1+x^{2})$, which implies $A^{1}_{2} = y$.\n\nFrom the $(1,3)$ component:\n$g_{13} = A^{1}_{1}A^{1}_{3} = z(1+x^{2})$. Substituting $A^{1}_{1}$, we get $(1+x^{2})A^{1}_{3} = z(1+x^{2})$, which implies $A^{1}_{3} = z$.\n\nFrom the $(2,2)$ component:\n$g_{22} = (A^{1}_{2})^{2}+(A^{2}_{2})^{2} = y^{2}+(1+y^{2})^{2}$. Substituting $A^{1}_{2}=y$, we have $y^{2}+(A^{2}_{2})^{2} = y^{2}+(1+y^{2})^{2}$. This simplifies to $(A^{2}_{2})^{2}=(1+y^{2})^{2}$. Since $A^{2}_{2}>0$, we have $A^{2}_{2} = 1+y^{2}$.\n\nFrom the $(2,3)$ component:\n$g_{23} = A^{1}_{2}A^{1}_{3}+A^{2}_{2}A^{2}_{3} = yz(2+y^{2})$. Substituting the known values for $A^{1}_{2}, A^{1}_{3}, A^{2}_{2}$:\n$y \\cdot z + (1+y^{2})A^{2}_{3} = yz(2+y^{2})$. Expanding the right-hand side gives $yz + (1+y^{2})A^{2}_{3} = 2yz + y^3z$. Subtracting $yz$ from both sides gives $(1+y^{2})A^{2}_{3} = yz + y^3z = yz(1+y^2)$. This implies $A^{2}_{3} = yz$.\n\nFrom the $(3,3)$ component:\n$g_{33} = (A^{1}_{3})^{2}+(A^{2}_{3})^{2}+(A^{3}_{3})^{2} = z^{2}+y^{2}z^{2}+(1+z^{2})^{2}$. Substituting the known values for $A^{1}_{3}, A^{2}_{3}$:\n$z^{2} + (yz)^{2} + (A^{3}_{3})^{2} = z^{2}+y^{2}z^{2}+(1+z^{2})^{2}$.\nThis simplifies to $(A^{3}_{3})^{2} = (1+z^{2})^{2}$. Since $A^{3}_{3}>0$, we have $A^{3}_{3} = 1+z^{2}$.\n\nThus, we have determined all the components of the matrix $A$:\n$$\nA = \\begin{pmatrix} 1+x^{2} & y & z \\\\ 0 & 1+y^{2} & yz \\\\ 0 & 0 & 1+z^{2} \\end{pmatrix}\n$$\nThe rows of this matrix $A$ define the components of the orthonormal coframe $\\{\\theta^{1}, \\theta^{2}, \\theta^{3}\\}$ with respect to the basis $\\{dx, dy, dz\\}$.\n\nThe first $1$-form, $\\theta^{1}$, has components given by the first row of $A$:\n$$\n\\theta^{1} = A^{1}_{1} dx + A^{1}_{2} dy + A^{1}_{3} dz = (1+x^{2})dx + y\\,dy + z\\,dz\n$$\nThe second $1$-form, $\\theta^{2}$, has components given by the second row of $A$:\n$$\n\\theta^{2} = A^{2}_{1} dx + A^{2}_{2} dy + A^{2}_{3} dz = 0 \\cdot dx + (1+y^{2})dy + yz\\,dz = (1+y^{2})dy + yz\\,dz\n$$\nThe third $1$-form, $\\theta^{3}$, has components given by the third row of $A$:\n$$\n\\theta^{3} = A^{3}_{1} dx + A^{3}_{2} dy + A^{3}_{3} dz = 0 \\cdot dx + 0 \\cdot dy + (1+z^{2})dz = (1+z^{2})dz\n$$\nThis set $\\{\\theta^{1}, \\theta^{2}, \\theta^{3}\\}$ is the required orthonormal coframe.", "answer": "$$\n\\boxed{\\begin{pmatrix} (1+x^{2})dx + y\\,dy + z\\,dz & (1+y^{2})dy + yz\\,dz & (1+z^{2})dz \\end{pmatrix}}\n$$", "id": "2973830"}]}