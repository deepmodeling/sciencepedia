{"hands_on_practices": [{"introduction": "The Lie bracket provides a way to measure the \"failure to commute\" of two vector fields when viewed as differential operators. This hands-on exercise is a foundational step in mastering the algebraic computation of the Lie bracket. By applying the definition to two vector fields with clear geometric interpretations—a rotation and a hyperbolic flow—you will build both computational fluency and a preliminary intuition for how distinct flows interact. [@problem_id:1679054]", "problem": "Consider the two-dimensional Euclidean space $\\mathbb{R}^2$ with standard Cartesian coordinates $(x, y)$. Two smooth vector fields, $V_1$ and $V_2$, are defined on this space.\n\nThe first vector field, $V_1$, represents a velocity field for pure rotation around the origin. Its component form is given by the differential operator:\n$$ V_1 = -y \\frac{\\partial}{\\partial x} + x \\frac{\\partial}{\\partial y} $$\n\nThe second vector field, $V_2$, represents a hyperbolic flow field, also given as a differential operator:\n$$ V_2 = x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y} $$\n\nThe Lie bracket of two vector fields $V_1$ and $V_2$, denoted as $[V_1, V_2]$ or as the Lie derivative $\\mathcal{L}_{V_1} V_2$, is a new vector field. It can be computed via the commutator of the vector fields viewed as differential operators: $[V_1, V_2] = V_1 V_2 - V_2 V_1$. Alternatively, for vector fields $V_1 = \\sum_i V_1^i \\frac{\\partial}{\\partial x^i}$ and $V_2 = \\sum_i V_2^i \\frac{\\partial}{\\partial x^i}$, the $k$-th component of the Lie bracket is given by $([V_1, V_2])^k = V_1(V_2^k) - V_2(V_1^k)$.\n\nCalculate the Lie bracket $[V_1, V_2]$. Express your answer as a vector field in the form $A(x,y) \\frac{\\partial}{\\partial x} + B(x,y) \\frac{\\partial}{\\partial y}$.", "solution": "We write the components of the vector fields as follows: $V_{1}^{x} = -y$, $V_{1}^{y} = x$, $V_{2}^{x} = x$, and $V_{2}^{y} = -y$. The Lie bracket is computed componentwise using $([V_{1},V_{2}])^{k} = V_{1}(V_{2}^{k}) - V_{2}(V_{1}^{k})$.\n\nFor the $x$-component,\n$$\n([V_{1},V_{2}])^{x} = V_{1}(V_{2}^{x}) - V_{2}(V_{1}^{x}) = \\left(-y \\frac{\\partial}{\\partial x} + x \\frac{\\partial}{\\partial y}\\right)(x) - \\left(x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y}\\right)(-y)\n$$\nEvaluate each term:\n$$\nV_{1}(x) = (-y)(1) + (x)(0) = -y\n$$\n$$\nV_{2}(-y) = (x)(0) + (-y)(-1) = y\n$$\nHence,\n$$\n([V_{1},V_{2}])^{x} = -y - y = -2y.\n$$\n\nFor the $y$-component,\n$$\n([V_{1},V_{2}])^{y} = V_{1}(V_{2}^{y}) - V_{2}(V_{1}^{y}) = \\left(-y \\frac{\\partial}{\\partial x} + x \\frac{\\partial}{\\partial y}\\right)(-y) - \\left(x \\frac{\\partial}{\\partial x} - y \\frac{\\partial}{\\partial y}\\right)(x)\n$$\nEvaluate each term:\n$$\nV_{1}(-y) = (-y)(0) + (x)(-1) = -x\n$$\n$$\nV_{2}(x) = (x)(1) + (-y)(0) = x\n$$\nHence,\n$$\n([V_{1},V_{2}])^{y} = -x - x = -2x.\n$$\n\nTherefore, the Lie bracket vector field is\n$$\n[V_{1},V_{2}] = -2y \\frac{\\partial}{\\partial x} - 2x \\frac{\\partial}{\\partial y}.\n$$", "answer": "$$\\boxed{-2y \\frac{\\partial}{\\partial x} - 2x \\frac{\\partial}{\\partial y}}$$", "id": "1679054"}, {"introduction": "A fundamental property of a coordinate basis, such as $\\{\\frac{\\partial}{\\partial x}, \\frac{\\partial}{\\partial y}\\}$, is that its basis vectors have a vanishing Lie bracket. This problem explores what happens in a more general scenario using the physically intuitive orthonormal basis for polar coordinates. By calculating the Lie bracket of the radial and angular basis vectors, you will uncover a non-zero result, revealing an intrinsic \"twisting\" of the basis and demonstrating that the Lie bracket is a powerful tool for characterizing the geometry of vector frames. [@problem_id:1679068]", "problem": "Consider a two-dimensional Euclidean plane, $\\mathbb{R}^2$. A point in this plane can be described by Cartesian coordinates $(x, y)$ or by polar coordinates $(r, \\theta)$, where $x = r \\cos(\\theta)$ and $y = r \\sin(\\theta)$. The angle $\\theta$ is measured in radians.\n\nIn the polar coordinate system, a local orthonormal basis (also known as a physical basis) can be defined at every point (for $r>0$). This basis consists of two vector fields, $\\hat{e}_r$ and $\\hat{e}_\\theta$, defined as:\n$$ \\hat{e}_r = \\frac{\\partial}{\\partial r} $$\n$$ \\hat{e}_\\theta = \\frac{1}{r} \\frac{\\partial}{\\partial \\theta} $$\nYour task is to compute the Lie bracket $[\\hat{e}_r, \\hat{e}_\\theta]$.\n\nTo perform this calculation, you must first express the vector fields $\\hat{e}_r$ and $\\hat{e}_\\theta$ in terms of the Cartesian coordinate basis vectors, $\\frac{\\partial}{\\partial x}$ and $\\frac{\\partial}{\\partial y}$. After computing the Lie bracket in the Cartesian basis, express the resulting vector field back in terms of the polar orthonormal basis $\\{\\hat{e}_r, \\hat{e}_\\theta\\}$.", "solution": "We work on the domain $r>0$. Using the coordinate change $x=r\\cos(\\theta)$, $y=r\\sin(\\theta)$, the chain rule gives\n$$\n\\frac{\\partial}{\\partial r}=\\frac{\\partial x}{\\partial r}\\frac{\\partial}{\\partial x}+\\frac{\\partial y}{\\partial r}\\frac{\\partial}{\\partial y}\n=\\cos(\\theta)\\frac{\\partial}{\\partial x}+\\sin(\\theta)\\frac{\\partial}{\\partial y},\n$$\n$$\n\\frac{\\partial}{\\partial \\theta}=\\frac{\\partial x}{\\partial \\theta}\\frac{\\partial}{\\partial x}+\\frac{\\partial y}{\\partial \\theta}\\frac{\\partial}{\\partial y}\n=-r\\sin(\\theta)\\frac{\\partial}{\\partial x}+r\\cos(\\theta)\\frac{\\partial}{\\partial y},\n$$\nhence\n$$\n\\hat{e}_{r}=\\cos(\\theta)\\frac{\\partial}{\\partial x}+\\sin(\\theta)\\frac{\\partial}{\\partial y},\\qquad\n\\hat{e}_{\\theta}=\\frac{1}{r}\\frac{\\partial}{\\partial \\theta}=-\\sin(\\theta)\\frac{\\partial}{\\partial x}+\\cos(\\theta)\\frac{\\partial}{\\partial y}.\n$$\nLet's denote $\\hat{e}_{r} = A$ and $\\hat{e}_{\\theta} = B$. For vector fields $A=a^{x}\\partial_{x}+a^{y}\\partial_{y}$ and $B=b^{x}\\partial_{x}+b^{y}\\partial_{y}$, the Lie bracket is\n$$\n[A,B]=\\big(A(b^{x})-B(a^{x})\\big)\\frac{\\partial}{\\partial x}+\\big(A(b^{y})-B(a^{y})\\big)\\frac{\\partial}{\\partial y}.\n$$\nHere $a^{x}=\\cos(\\theta)$, $a^{y}=\\sin(\\theta)$, $b^{x}=-\\sin(\\theta)$, and $b^{y}=\\cos(\\theta)$. These are functions of $(x,y)$ via $\\theta=\\arctan(y/x)$ and $r=\\sqrt{x^{2}+y^{2}}$.\n\nFirst, we compute the x-component of the bracket, $A(b^x) - B(a^x)$:\n$$A(b^x) = \\hat{e}_r(-\\sin\\theta) = \\partial_r(-\\sin\\theta) = -\\cos\\theta \\frac{\\partial\\theta}{\\partial r} = 0$$\n$$B(a^x) = \\hat{e}_\\theta(\\cos\\theta) = \\frac{1}{r}\\partial_\\theta(\\cos\\theta) = \\frac{1}{r}(-\\sin\\theta) = -\\frac{\\sin\\theta}{r}$$\nSo, $A(b^{x})-B(a^{x}) = 0 - (-\\frac{\\sin\\theta}{r}) = \\frac{\\sin\\theta}{r}$.\n\nNext, we compute the y-component, $A(b^y) - B(a^y)$:\n$$A(b^y) = \\hat{e}_r(\\cos\\theta) = \\partial_r(\\cos\\theta) = -\\sin\\theta \\frac{\\partial\\theta}{\\partial r} = 0$$\n$$B(a^y) = \\hat{e}_\\theta(\\sin\\theta) = \\frac{1}{r}\\partial_\\theta(\\sin\\theta) = \\frac{1}{r}(\\cos\\theta) = \\frac{\\cos\\theta}{r}$$\nSo, $A(b^{y})-B(a^{y})= 0 - \\frac{\\cos\\theta}{r} = -\\frac{\\cos\\theta}{r}$.\n\nTherefore, in the Cartesian basis,\n$$\n[\\hat{e}_{r},\\hat{e}_{\\theta}]=\\frac{\\sin\\theta}{r}\\frac{\\partial}{\\partial x}-\\frac{\\cos\\theta}{r}\\frac{\\partial}{\\partial y}.\n$$\nWe can factor this expression:\n$$\n[\\hat{e}_{r},\\hat{e}_{\\theta}]=-\\frac{1}{r}\\left(-\\sin(\\theta)\\frac{\\partial}{\\partial x}+\\cos(\\theta)\\frac{\\partial}{\\partial y}\\right).\n$$\nRecognizing that the term in the parentheses is $\\hat{e}_{\\theta}$, we find\n$$\n[\\hat{e}_{r},\\hat{e}_{\\theta}]=-\\frac{1}{r}\\hat{e}_{\\theta}.\n$$", "answer": "$$\\boxed{-\\frac{1}{r}\\hat{e}_{\\theta}}$$", "id": "1679068"}, {"introduction": "One of the most powerful results in local differential geometry is the Flow-Box Theorem, which states that any non-vanishing vector field can be 'straightened' by a clever choice of local coordinates. This exercise moves beyond mere calculation to construction, guiding you through the explicit steps to find such a coordinate system for a given vector field. By finding functions that are invariant along the flow and that parameterize the flow, you will gain a deep, practical understanding of this fundamental theorem and its connection to solving partial differential equations. [@problem_id:3037091]", "problem": "Let $X$ be the smooth vector field on $\\mathbb{R}^{2}$ defined by $X = \\partial_{x} + x \\partial_{y}$. Recall the following fundamental definitions. A smooth vector field $X$ on a manifold is a first-order differential operator acting on smooth functions by the Leibniz rule, and an integral curve of $X$ is a smooth curve $\\gamma(t)$ such that $\\dot{\\gamma}(t) = X(\\gamma(t))$. The flow of $X$ is the local one-parameter family of diffeomorphisms obtained by moving along integral curves. The straightening theorem states that if $X$ is nonvanishing at a point, then there exist local coordinates in which $X$ is represented as a coordinate vector field. Using only these definitions and the method of characteristics for first-order linear partial differential equations, construct explicitly a local coordinate system $(u,v)$ near $(0,0) \\in \\mathbb{R}^{2}$ in which $X$ becomes $\\partial_{u}$. Your construction must proceed by:\n- Solving for integral curves of $X$ and identifying an invariant function $v$ satisfying $X(v) = 0$.\n- Identifying a coordinate function $u$ satisfying $X(u) = 1$.\n- Verifying, via the chain rule and Jacobian computation, that the change of variables $(x,y) \\mapsto (u(x,y), v(x,y))$ is a local diffeomorphism near $(0,0)$ and that $X$ transforms to $\\partial_{u}$ in these coordinates.\n\nProvide the explicit coordinate transformation $(u(x,y), v(x,y))$ simplified. The final answer must be the explicit pair of functions $(u(x,y), v(x,y))$ as a single closed-form analytic expression. No numerical approximation is required.", "solution": "The construction of the coordinate system $(u,v)$ will be carried out in the prescribed sequence of steps.\n\n**Step 1: Find an invariant function $v$ satisfying $X(v) = 0$.**\nAn integral curve of $X$, denoted by $\\gamma(t) = (x(t), y(t))$, is a solution to the system of ordinary differential equations given by $\\dot{\\gamma}(t) = X(\\gamma(t))$. For $X = \\partial_{x} + x \\partial_{y}$, this corresponds to the system:\n$$\n\\begin{cases}\n\\frac{dx}{dt} = 1 \\\\\n\\frac{dy}{dt} = x(t)\n\\end{cases}\n$$\nIntegrating the first equation, we find $x(t) = t + C_1$. Let the initial condition at $t=0$ be $(x_0, y_0)$, so $x(0) = x_0$, which gives $C_1 = x_0$. Thus, $x(t) = t + x_0$.\nSubstituting this into the second equation gives $\\frac{dy}{dt} = t + x_0$. Integrating with respect to $t$ yields $y(t) = \\frac{1}{2}t^2 + x_0 t + C_2$. Using the initial condition $y(0) = y_0$, we get $C_2 = y_0$. The integral curve is therefore $\\gamma(t) = (t+x_0, \\frac{1}{2}t^2 + x_0 t + y_0)$.\n\nAn invariant function $v(x,y)$ is constant along these integral curves. We can find such a function by eliminating $t$ from the equations for $x(t)$ and $y(t)$. From $x = t+x_0$, we have $t = x-x_0$. Substituting this into the equation for $y$:\n$$y = \\frac{1}{2}(x-x_0)^2 + x_0(x-x_0) + y_0$$\n$$y = \\frac{1}{2}(x^2 - 2xx_0 + x_0^2) + x_0x - x_0^2 + y_0$$\n$$y = \\frac{1}{2}x^2 - xx_0 + \\frac{1}{2}x_0^2 + x_0x - x_0^2 + y_0$$\n$$y = \\frac{1}{2}x^2 - \\frac{1}{2}x_0^2 + y_0$$\nRearranging this equation gives $y - \\frac{1}{2}x^2 = y_0 - \\frac{1}{2}x_0^2$. The expression on the left, $y - \\frac{1}{2}x^2$, depends only on the point $(x,y)$ and is constant along any given integral curve. We can therefore define our invariant function $v$ as:\n$$v(x,y) = y - \\frac{1}{2}x^2$$\nTo confirm, we check if $X(v)=0$:\n$$X(v) = (\\partial_{x} + x \\partial_{y})(y - \\frac{1}{2}x^2) = \\partial_{x}(y - \\frac{1}{2}x^2) + x \\partial_{y}(y - \\frac{1}{2}x^2) = (-x) + x(1) = 0$$\nThis confirms our choice of $v$.\n\n**Step 2: Find a coordinate function $u$ satisfying $X(u) = 1$.**\nWe need to solve the first-order linear partial differential equation $X(u)=1$:\n$$\\frac{\\partial u}{\\partial x} + x \\frac{\\partial u}{\\partial y} = 1$$\nWe seek a simple solution. Let's test a function of $x$ alone, $u(x,y) = f(x)$. The equation becomes $f'(x) + x \\cdot 0 = 1$, which means $f'(x) = 1$. Integrating gives $f(x)=x+C$. The simplest choice is to take the constant $C=0$. Let's propose:\n$$u(x,y) = x$$\nWe verify this choice:\n$$X(u) = (\\partial_{x} + x \\partial_{y})(x) = \\partial_{x}(x) + x \\partial_{y}(x) = 1 + x(0) = 1$$\nThis is a valid choice for the coordinate function $u$. Our proposed coordinate system is $(u,v)$ defined by the transformation:\n$$u(x,y) = x$$\n$$v(x,y) = y - \\frac{1}{2}x^2$$\n\n**Step 3: Verify the transformation and the result.**\nFirst, we must verify that the map $(x,y) \\mapsto (u(x,y), v(x,y))$ is a local diffeomorphism near $(0,0)$. This is established by computing the Jacobian determinant and checking that it is non-zero. The Jacobian matrix of the transformation is:\n$$J = \\begin{pmatrix} \\frac{\\partial u}{\\partial x} & \\frac{\\partial u}{\\partial y} \\\\ \\frac{\\partial v}{\\partial x} & \\frac{\\partial v}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ -x & 1 \\end{pmatrix}$$\nThe determinant of the Jacobian is:\n$$\\det(J) = (1)(1) - (0)(-x) = 1$$\nSince $\\det(J) = 1 \\neq 0$ for all $(x,y) \\in \\mathbb{R}^2$, the transformation is a local diffeomorphism everywhere, and thus certainly near $(0,0)$.\n\nSecond, we must verify that the vector field $X$ becomes $\\partial_{u}$ in the new coordinates. We can express the original basis vectors $\\partial_x$ and $\\partial_y$ in terms of the new basis vectors $\\partial_u$ and $\\partial_v$ using the chain rule:\n$$\\partial_{x} = \\frac{\\partial u}{\\partial x}\\partial_{u} + \\frac{\\partial v}{\\partial x}\\partial_{v} = (1)\\partial_{u} + (-x)\\partial_{v} = \\partial_{u} - x\\partial_{v}$$\n$$\\partial_{y} = \\frac{\\partial u}{\\partial y}\\partial_{u} + \\frac{\\partial v}{\\partial y}\\partial_{v} = (0)\\partial_{u} + (1)\\partial_{v} = \\partial_{v}$$\nNow, we substitute these expressions into the definition of $X$:\n$$X = \\partial_{x} + x \\partial_{y} = (\\partial_{u} - x\\partial_{v}) + x(\\partial_{v}) = \\partial_{u} - x\\partial_{v} + x\\partial_{v} = \\partial_{u}$$\nThe transformation is successful. In the coordinate system $(u,v) = (x, y - \\frac{1}{2}x^2)$, the vector field $X$ is given by $\\partial_{u}$.\n\nThe explicit coordinate transformation is the pair of functions $(u(x,y), v(x,y))$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nx & y - \\frac{1}{2}x^{2}\n\\end{pmatrix}\n}\n$$", "id": "3037091"}]}