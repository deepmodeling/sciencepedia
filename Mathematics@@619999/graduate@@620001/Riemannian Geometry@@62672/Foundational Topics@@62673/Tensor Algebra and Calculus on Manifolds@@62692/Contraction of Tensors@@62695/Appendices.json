{"hands_on_practices": [{"introduction": "The operation of tensor contraction can be understood as a powerful generalization of familiar concepts from linear algebra. Just as a matrix acts on a vector to produce another vector, a rank-2 tensor can be contracted with a vector, transforming it into a new vector. This exercise provides a concrete look at this process, exploring the intriguing case where a non-zero tensor and a non-zero vector contract to produce the zero vector, introducing the notion of a tensor's null space and solidifying the connection between abstract tensor algebra and matrix operations. [@problem_id:1498206]", "problem": "In a 2-dimensional Cartesian coordinate system, a rank-2 covariant tensor $T_{ij}$ and a contravariant vector $v^j$ (where indices $i, j$ can be 1 or 2) are defined by their components. The contraction of the tensor with the vector produces a new vector $C_i$ according to the rule $C_i = T_{ij}v^j$, where the Einstein summation convention is implied over the repeated index $j$.\n\nYour task is to identify which of the following pairs of a non-zero tensor $T_{ij}$ and a non-zero vector $v^j$ results in a zero vector $C_i = (0, 0)$. The components of the tensors and vectors are given in matrix form.\n\nA. $T_{ij} = \\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}$, $v^j = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$\n\nB. $T_{ij} = \\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}$, $v^j = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$\n\nC. $T_{ij} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$, $v^j = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$\n\nD. $T_{ij} = \\begin{pmatrix} 3 & 1 \\\\ 6 & 2 \\end{pmatrix}$, $v^j = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$", "solution": "We use the contraction rule $C_{i} = T_{ij} v^{j}$ with Einstein summation over $j \\in \\{1,2\\}$. Componentwise, this is\n$$\nC_{1} = T_{11} v^{1} + T_{12} v^{2}, \\quad C_{2} = T_{21} v^{1} + T_{22} v^{2}.\n$$\n\nOption A: $T_{ij} = \\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}$ and $v^{j} = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. Then\n$$\nC_{1} = 1 \\cdot (-2) + 2 \\cdot 1 = -2 + 2 = 0, \\quad C_{2} = 2 \\cdot (-2) + 4 \\cdot 1 = -4 + 4 = 0,\n$$\nso $C_{i} = (0,0)$.\n\nOption B: $T_{ij} = \\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}$ and $v^{j} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. Then\n$$\nC_{1} = 1 \\cdot 1 + 2 \\cdot 1 = 3, \\quad C_{2} = 2 \\cdot 1 + 4 \\cdot 1 = 6,\n$$\nso $C_{i} \\neq (0,0)$.\n\nOption C: $T_{ij} = \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix}$ and $v^{j} = \\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. Then\n$$\nC_{1} = 1 \\cdot (-2) + 1 \\cdot 1 = -1, \\quad C_{2} = 0 \\cdot (-2) + 1 \\cdot 1 = 1,\n$$\nso $C_{i} \\neq (0,0)$.\n\nOption D: $T_{ij} = \\begin{pmatrix} 3 & 1 \\\\ 6 & 2 \\end{pmatrix}$ and $v^{j} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. Then\n$$\nC_{1} = 3 \\cdot 1 + 1 \\cdot 1 = 4, \\quad C_{2} = 6 \\cdot 1 + 2 \\cdot 1 = 8,\n$$\nso $C_{i} \\neq (0,0)$.\n\nTherefore, only Option A yields the zero vector upon contraction.", "answer": "$$\\boxed{A}$$", "id": "1498206"}, {"introduction": "One of the most significant applications of tensor contraction is the construction of scalar invariants—quantities whose values are independent of the chosen coordinate system. These invariants capture the intrinsic geometric or physical properties of a system. This practice focuses on computing a fundamental invariant, $I = T_{kl}T^{kl}$, which can be interpreted as the squared magnitude of the tensor. Mastering this calculation is a key step towards understanding how physical laws can be expressed in a coordinate-free, universal form. [@problem_id:1498240]", "problem": "In the theoretical modeling of a two-dimensional anisotropic medium, a physical property is represented by a rank-2 contravariant tensor, denoted as $T^{ij}$. Within a standard Cartesian coordinate system $(x^1, x^2)$, the components of this tensor are given by the matrix:\n$$\nT^{ij} = \\begin{pmatrix} 4 & -1 \\\\ 2 & 3 \\end{pmatrix}\n$$\nLet's say the components of this tensor have physical units of 'Q'. The geometry of the two-dimensional space is Euclidean. Consequently, the covariant metric tensor $g_{ij}$ and the contravariant metric tensor $g^{ij}$ are both represented by the identity matrix in this coordinate system.\n\nA fundamental scalar quantity, often used to characterize the overall magnitude of the tensor property, is the invariant $I = T_{kl}T^{kl}$, where $T_{kl}$ represents the covariant version of the tensor.\n\nCalculate the value of this scalar invariant $I$. Express your final answer as a number in units of Q$^2$.", "solution": "The covariant components are obtained from the contravariant components by lowering indices with the metric:\n$$\nT_{ij} = g_{ik} g_{jl} T^{kl}.\n$$\nIn a Euclidean Cartesian system, $g_{ij} = \\delta_{ij}$. This means that the covariant components $T_{ij}$ are numerically identical to the contravariant components $T^{ij}$. The invariant is the contraction:\n$$\nI = T_{kl}T^{kl} = \\sum_{k,l} T_{kl}T^{kl}\n$$\nSince the components are identical, this becomes the sum of the squares of the given components:\n$$\nI = (T^{11})^{2} + (T^{12})^{2} + (T^{21})^{2} + (T^{22})^{2}.\n$$\nWith $T^{ij} = \\begin{pmatrix} 4 & -1 \\\\ 2 & 3 \\end{pmatrix}$, we compute\n$$\nI = 4^{2} + (-1)^{2} + 2^{2} + 3^{2} = 16 + 1 + 4 + 9 = 30.\n$$\nSince each $T^{ij}$ has units Q, the invariant has units Q$^{2}$. The requested final answer is the numerical value.", "answer": "$$\\boxed{30}$$", "id": "1498240"}, {"introduction": "In Riemannian geometry, the metric tensor $g_{ij}$ defines a canonical isomorphism between vectors and one-forms, known as the musical isomorphisms of \"raising\" and \"lowering\" indices. A natural assumption is that applying these operations sequentially—lowering an index and then raising it—returns the original vector. This advanced exercise challenges that intuition by replacing the symmetric metric tensor with an antisymmetric symplectic form, $\\omega_{ij}$. By performing this sequence of contractions, you will uncover how the underlying geometry encoded in the tensor fundamentally defines the properties of the isomorphism, revealing a crucial distinction between metric and symplectic structures. [@problem_id:1498219]", "problem": "In a two-dimensional vector space, a contravariant vector $V$ has components $V^i = (v_1, v_2)$. The relationship between contravariant vectors (vectors) and covariant vectors (one-forms) is established using a rank-2 tensor. In this space, we use a non-degenerate, antisymmetric tensor $\\omega_{ij}$, known as a symplectic form, whose components are given by the matrix:\n$$\n\\omega_{ij} = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}\n$$\nThe operation of \"lowering an index\" maps the vector $V$ to a one-form $\\alpha$ by contracting the tensor components, where the components of $\\alpha$ are given by $\\alpha_j = V^i \\omega_{ij}$. The standard Einstein summation convention for repeated indices is implied.\n\nThe inverse operation of \"raising an index\" maps a one-form back to a vector using the inverse tensor, $\\omega^{ij}$, whose components are the entries of the matrix inverse of $\\omega_{ij}$. A new vector $W$ with components $W^k$ can be obtained from the one-form $\\alpha$ via the contraction $W^k = \\omega^{kj} \\alpha_j$.\n\nStarting with the vector $V$, first apply the index-lowering operation to obtain the one-form $\\alpha$, and then apply the index-raising operation to $\\alpha$ to obtain a new vector $W$. Determine the components of the resulting vector $W$ in terms of the original components $v_1$ and $v_2$. Your final answer should be expressed as a row matrix representing the components $(W^1, W^2)$.", "solution": "The problem asks us to find the components of a vector $W$, which is obtained by first lowering the index of a vector $V$ using a symplectic form $\\omega_{ij}$ to get a one-form $\\alpha$, and then raising the index of $\\alpha$ using the inverse form $\\omega^{ij}$.\n\nLet the initial vector be $V$ with components $V^1 = v_1$ and $V^2 = v_2$.\nThe components of the symplectic form are given by the matrix $\\Omega = \\begin{pmatrix} 0 & 1 \\\\ -1 & 0 \\end{pmatrix}$. So, $\\omega_{11}=0$, $\\omega_{12}=1$, $\\omega_{21}=-1$, and $\\omega_{22}=0$.\n\nFirst, we perform the index-lowering operation to find the components of the one-form $\\alpha$: $\\alpha_j = V^i \\omega_{ij}$. We calculate each component of $\\alpha$ separately using the Einstein summation convention over the index $i$.\n\nFor $j=1$:\n$$\n\\alpha_1 = \\sum_{i=1}^{2} V^i \\omega_{i1} = V^1 \\omega_{11} + V^2 \\omega_{21} = v_1(0) + v_2(-1) = -v_2\n$$\n\nFor $j=2$:\n$$\n\\alpha_2 = \\sum_{i=1}^{2} V^i \\omega_{i2} = V^1 \\omega_{12} + V^2 \\omega_{22} = v_1(1) + v_2(0) = v_1\n$$\nSo, the one-form $\\alpha$ has components $\\alpha_j = (-v_2, v_1)$.\n\nNext, we need to find the inverse tensor $\\omega^{ij}$. This is given by the components of the inverse of the matrix $\\Omega$. The determinant of $\\Omega$ is:\n$$\n\\det(\\Omega) = (0)(0) - (1)(-1) = 1\n$$\nThe inverse of a 2x2 matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$ is $\\frac{1}{ad-bc}\\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$.\nApplying this to $\\Omega$:\n$$\n\\Omega^{-1} = \\frac{1}{1} \\begin{pmatrix} 0 & -1 \\\\ -(-1) & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}\n$$\nThe components of the inverse tensor $\\omega^{ij}$ are therefore $\\omega^{11}=0$, $\\omega^{12}=-1$, $\\omega^{21}=1$, and $\\omega^{22}=0$.\n\nNow, we perform the index-raising operation on $\\alpha$ to find the components of the new vector $W$: $W^k = \\omega^{kj} \\alpha_j$. We calculate each component of $W$ by summing over the index $j$.\n\nFor $k=1$:\n$$\nW^1 = \\sum_{j=1}^{2} \\omega^{1j} \\alpha_j = \\omega^{11} \\alpha_1 + \\omega^{12} \\alpha_2 = (0)(-v_2) + (-1)(v_1) = -v_1\n$$\n\nFor $k=2$:\n$$\nW^2 = \\sum_{j=1}^{2} \\omega^{2j} \\alpha_j = \\omega^{21} \\alpha_1 + \\omega^{22} \\alpha_2 = (1)(-v_2) + (0)(v_1) = -v_2\n$$\nThe components of the resulting vector $W$ are $W^1 = -v_1$ and $W^2 = -v_2$.\n\nThe problem asks for the answer as a row matrix $(W^1, W^2)$. Therefore, the final result is $(-v_1, -v_2)$. This demonstrates that applying the musical isomorphism defined by a symplectic form twice results in the negative of the original vector, in contrast to the case of a metric tensor where it would return the original vector.", "answer": "$$\\boxed{\\begin{pmatrix} -v_1 & -v_2 \\end{pmatrix}}$$", "id": "1498219"}]}