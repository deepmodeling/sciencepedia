{"hands_on_practices": [{"introduction": "要真正掌握欧拉-丸山法，最好的方式莫过于亲手推导并应用它。这个练习将引导你为金融学中至关重要的几何布朗运动（GBM）随机微分方程推导欧拉-丸山格式。通过这个过程，你不仅能理解该方法的基本构造，还将发现一个重要的警示：尽管真实的GBM过程严格为正，其数值近似却可能出现负值，这揭示了数值方法与真实解之间的一个深刻差异。[@problem_id:3080335]", "problem": "考虑几何布朗运动 (GBM) 的随机微分方程 (SDE)\n$$\ndX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t},\\quad X_{0}=x_{0}>0,\n$$\n其中$W_{t}$是标准维纳过程，$\\mu,\\sigma$是实常数且$\\sigma>0$。给定一个步长为$h>0$的均匀时间网格$t_{n}=n h$。\n\n仅使用该 SDE 在$[t_{n},t_{n+1}]$上的积分形式以及欧拉-丸山 (EM) 方法作为伊藤积分的左点黎曼近似的定义，推导以$X_{n}$表示的$X_{n+1}$的 EM 更新。然后，在$X_{n}>0$的条件下，利用维纳过程高斯增量的基本性质，求出 EM 单步近似$X_{n+1}$为非正的概率的闭式解析表达式。\n\n最后，定性解释该概率如何依赖于$h$、$\\mu$和$\\sigma$，并说明在何种条件下，即使在给定$x_{0}>0$时，精确的 GBM 解对所有$t>0$都是严格为正的，EM 近似也可能违反其正性。\n\n将您的最终答案以单步概率$\\mathbb{P}(X_{n+1}\\le 0\\,|\\,X_{n}>0)$作为$\\mu$、$\\sigma$和$h$的函数的闭式解析表达式形式提供。不需要进行数值近似或舍入，也无需报告单位。", "solution": "所述问题在科学上是合理的、提法恰当且客观的。所有必要信息均已提供，并且任务在随机微分方程和数值方法的标准框架内有明确定义。该问题是有效的。\n\n几何布朗运动 (GBM) 的随机微分方程 (SDE) 由下式给出：\n$$\ndX_{t}=\\mu X_{t}\\,dt+\\sigma X_{t}\\,dW_{t},\n$$\n初始条件为$X_{0}=x_{0}>0$。这里，$W_{t}$是一个标准维纳过程，$\\mu, \\sigma$是实常数且$\\sigma>0$。\n\n第一步是推导此 SDE 的欧拉-丸山 (EM) 数值格式。SDE 在时间区间$[t_{n}, t_{n+1}]$上的积分形式是：\n$$\nX_{t_{n+1}} - X_{t_{n}} = \\int_{t_{n}}^{t_{n+1}} \\mu X_{s}\\,ds + \\int_{t_{n}}^{t_{n+1}} \\sigma X_{s}\\,dW_{s}.\n$$\n设$h = t_{n+1} - t_{n}$为均匀时间步长。设$X_{n}$表示$X_{t_{n}}$的数值近似。欧拉-丸山方法是通过使用被积函数在区间左端点$t_{n}$处的值来近似上式中的积分而推导出来的。这是一种左点黎曼近似。\n\n对于漂移项（一个标准黎曼积分）：\n$$\n\\int_{t_{n}}^{t_{n+1}} \\mu X_{s}\\,ds \\approx \\mu X_{t_{n}} \\int_{t_{n}}^{t_{n+1}} ds = \\mu X_{n} (t_{n+1} - t_{n}) = \\mu X_{n} h.\n$$\n对于扩散项（一个伊藤积分）：\n$$\n\\int_{t_{n}}^{t_{n+1}} \\sigma X_{s}\\,dW_{s} \\approx \\sigma X_{t_{n}} \\int_{t_{n}}^{t_{n+1}} dW_{s} = \\sigma X_{n} (W_{t_{n+1}} - W_{t_{n}}).\n$$\n将这些近似代入积分方程，得到 EM 更新法则：\n$$\nX_{n+1} = X_{n} + \\mu X_{n} h + \\sigma X_{n} (W_{t_{n+1}} - W_{t_{n}}).\n$$\n维纳过程的增量$\\Delta W_{n} = W_{t_{n+1}} - W_{t_{n}}$是一个均值为$0$、方差为$t_{n+1} - t_{n} = h$的正态分布随机变量。我们可以写成$\\Delta W_{n} = \\sqrt{h} Z_{n}$，其中$Z_{n}$是一个标准正态随机变量，$Z_{n} \\sim \\mathcal{N}(0, 1)$。\n\n因此，EM 更新法则可以写成：\n$$\nX_{n+1} = X_{n} (1 + \\mu h + \\sigma \\sqrt{h} Z_{n}).\n$$\n这就是推导出的以$X_{n}$表示$X_{n+1}$的 EM 更新。\n\n接下来，我们计算在条件$X_{n}>0$下，单步近似$X_{n+1}$为非正的概率。我们关心的是$\\mathbb{P}(X_{n+1} \\le 0 \\,|\\, X_{n} > 0)$。\n使用 EM 更新公式：\n$$\n\\mathbb{P}(X_{n} (1 + \\mu h + \\sigma \\sqrt{h} Z_{n}) \\le 0 \\,|\\, X_{n} > 0).\n$$\n由于条件是$X_{n} > 0$，我们可以用$X_{n}$除以不等式两边而不改变其方向：\n$$\n\\mathbb{P}(1 + \\mu h + \\sigma \\sqrt{h} Z_{n} \\le 0).\n$$\n我们现在分离出标准正态随机变量$Z_{n}$：\n$$\n\\sigma \\sqrt{h} Z_{n} \\le -(1 + \\mu h).\n$$\n由于$\\sigma>0$且$h>0$，我们有$\\sigma\\sqrt{h}>0$。我们可以除以该项：\n$$\nZ_{n} \\le -\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}.\n$$\n该事件的概率由标准正态分布的累积分布函数 (CDF) 给出，记为$\\Phi(z) = \\mathbb{P}(Z \\le z)$，其中$Z \\sim \\mathcal{N}(0,1)$。\n因此，概率为：\n$$\n\\mathbb{P}(X_{n+1} \\le 0 \\,|\\, X_{n} > 0) = \\Phi\\left(-\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}\\right).\n$$\n这就是该概率的闭式解析表达式。\n\n最后，我们对结果进行定性解释。违反正性的概率$P = \\Phi\\left(-\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}\\right)$依赖于 CDF 的参数。由于$\\Phi$是一个单调递增函数，概率$P$随着其参数$z = -\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}$的增加（变得不那么负）而增加。\n\n- **对步长$h$的依赖性**：当步长$h$从$0$开始增加时，分母中的项$\\sqrt{h}$增加，分子中的项$(1+\\mu h)$也增加。对于小的$h$来说，主导项是$-1/(\\sigma\\sqrt{h})$。当$h \\to 0^{+}$时，该项趋于$-\\infty$，因此概率趋于$0$。随着$h$的增加，参数$z$通常会增加，导致出现负值的概率更高。更大的时间步长允许更大的随机跳跃方差$(\\sigma X_n \\sqrt{h})^2$，使得单步克服当前正值的可能性更大。\n\n- **对波动率$\\sigma$的依赖性**：当波动率$\\sigma$增加时，分母$\\sigma\\sqrt{h}$的大小增加。这使得为负的参数$z$（假设$1+\\mu h > 0$）变得不那么负（即增加）。更大的$z$会导致更大的$\\Phi(z)$值。因此，更高的波动率$\\sigma$会增加 EM 近似变为非正的概率。这是因为更高的波动率意味着更大的潜在随机波动。\n\n- **对漂移$\\mu$的依赖性**：当漂移$\\mu$增加时，分子$1+\\mu h$增加。这使得参数$z$变得更负（即减小）。更小的$z$会导致更小的$\\Phi(z)$值。因此，更高的正漂移$\\mu$会降低非正性的概率，因为它系统地将过程推向更高的值，为抵抗负向随机冲击提供了更大的缓冲。\n\nGBM SDE 的精确解是$X_t = X_0 \\exp\\left((\\mu - \\frac{1}{2}\\sigma^2)t + \\sigma W_t\\right)$，对于$X_0 > 0$而言，该解是严格为正的。EM 方法作为一种离散近似，可能无法保持这种正性。当参数$-\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}$不是一个大的负数时，违反正性的可能性就会变大。当表示达到零所需的标准差数的“安全边际”$\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}$很小时，就会发生这种情况。大步长$h$、大波动率$\\sigma$或小（或负）漂移$\\mu$会促成此条件。本质上，当单步的随机部分$\\sigma X_{n}\\sqrt{h}Z_{n}$足够大且为负，足以压倒确定性部分$X_{n}(1+\\mu h)$时，EM 近似就可能变为非正。", "answer": "$$\n\\boxed{\\Phi\\left(-\\frac{1 + \\mu h}{\\sigma \\sqrt{h}}\\right)}\n$$", "id": "3080335"}, {"introduction": "应用了数值方法后，一个自然而然的问题是：“它的精度如何？”。本练习将向你介绍强收敛性的概念，并指导你设计一个数值实验来测量欧拉-丸山法在求解 Ornstein-Uhlenbeck 过程时的收敛速度。你将学到一种无需知道精确解即可进行误差分析的强大技巧，即通过比较不同步长下的样本路径来估计收敛阶。[@problem_id:3226818]", "problem": "要求您设计并实现一个数值实验，以估计欧拉-丸山（Euler–Maruyama）方法在求解 Ornstein–Uhlenbeck 随机微分方程时的经验强收敛阶。考虑由以下随机微分方程定义的随机过程\n$$\ndX_t = -\\lambda X_t\\,dt + \\sigma\\,dW_t,\\quad X_0=x_0,\n$$\n其中$W_t$是一个标准维纳过程，$\\lambda \\ge 0$和$\\sigma \\ge 0$是常数，而$x_0 \\in \\mathbb{R}$是确定性的。\n\n从随机微分方程在一个大小为$h>0$的时间步长上的积分形式出发，\n$$\nX_{t+h} - X_t = \\int_t^{t+h} -\\lambda X_s\\,ds + \\int_t^{t+h} \\sigma\\,dW_s,\n$$\n并利用 Itō 积分和维纳过程的定义属性：$W_{t+h}-W_t \\sim \\mathcal{N}(0,h)$、独立增量以及$\\mathbb{E}[W_{t+h}-W_t]=0$。基于这些基础，推导一个一阶时间步进近似方案，该方案仅使用大小为$h$的步长内的局部信息来更新在时间$t_n = nh$处的近似值$X_n \\approx X_{t_n}$。除了这些基本定义和事实外，不要使用任何现成的简化公式。\n\n为了在不使用闭式精确解的情况下估计强收敛阶，请使用跨时间步长的路径耦合。对于一个给定的层级，设粗糙步长为$h$，定义精细步长为$h/2$。在同一个概率空间上，生成独立同分布的精细布朗增量$\\Delta W^{(h/2)}_k \\sim \\mathcal{N}(0,h/2)$，并通过配对相邻的精细增量来构造粗糙增量，\n$$\n\\Delta W^{(h)}_j = \\Delta W^{(h/2)}_{2j} + \\Delta W^{(h/2)}_{2j+1}.\n$$\n使用$\\Delta W^{(h)}_j$在粗糙网格上和使用$\\Delta W^{(h/2)}_k$在精细网格上模拟欧拉-丸山近似，两者都从相同的初始值$x_0$开始，以获得在$t=T$时的终端值$X_T^{(h)}$和$X_T^{(h/2)}$。将层级均方根耦合误差定义为\n$$\ne(h) = \\left(\\mathbb{E}\\left[\\left|X_T^{(h)} - X_T^{(h/2)}\\right|^2\\right]\\right)^{1/2}.\n$$\n对于一系列层级，其步长为$h_\\ell = T/(N_0\\,2^{\\ell-1})$，其中$\\ell=1,2,\\dots,L$，通过对数据$\\{(\\log h_\\ell, \\log e(h_\\ell))\\}_{\\ell=1}^L$拟合一条最小二乘直线，并将其斜率作为经验强收敛阶$p$的估计值。\n\n请实现一个程序，在以下约束条件下执行此实验，并为指定的测试套件输出数值结果。\n\n实现要求：\n- 为保证可复现性，使用固定种子$123456$的伪随机数生成器。\n- 对于每个随机测试，通过对$N_{\\text{paths}}$条独立的耦合样本路径进行蒙特卡洛平均来近似期望$\\mathbb{E}[\\cdot]$。对于确定性情况$\\sigma=0$，不需要随机性；直接从确定性迭代中精确计算误差。\n- 对于随机情况$\\sigma>0$，完全按照上述规定使用布朗增量的耦合。\n- 对于每个随机层级，从蒙特卡洛估计中计算$e(h)$\n$$\ne(h) \\approx \\left(\\frac{1}{N_{\\text{paths}}}\\sum_{i=1}^{N_{\\text{paths}}} \\left|X_{T,i}^{(h)} - X_{T,i}^{(h/2)}\\right|^2\\right)^{1/2}.\n$$\n- 对于每个$\\sigma>0$的情况，通过对所有$e(h_\\ell)>0$的层级上的$\\{(\\log h_\\ell,\\log e(h_\\ell))\\}$进行最小二乘回归来估计斜率$p$。\n- 对于退化布朗情况$\\lambda=0$和$\\sigma>0$，报告所有层级中$e(h_\\ell)$的最大值，而不是斜率。\n- 对于确定性情况$\\sigma=0$，使用相同的回归方法估计斜率$p$，但无需随机性。\n\n测试套件：\n- 情况 1 (典型随机)：$\\lambda=1.2$, $\\sigma=0.8$, $T=1.0$, $x_0=1.0$, $N_0=16$, $L=4$, $N_{\\text{paths}}=12000$。\n- 情况 2 (更刚性的随机情况)：$\\lambda=4.0$, $\\sigma=0.3$, $T=1.0$, $x_0=0.1$, $N_0=64$, $L=3$, $N_{\\text{paths}}=8000$。\n- 情况 3 (纯布朗极限)：$\\lambda=0.0$, $\\sigma=0.9$, $T=1.0$, $x_0=0.0$, $N_0=16$, $L=4$, $N_{\\text{paths}}=20000$。为此情况返回$\\max_{\\ell} e(h_\\ell)$。\n- 情况 4 (确定性极限)：$\\lambda=1.5$, $\\sigma=0.0$, $T=1.0$, $x_0=2.0$, $N_0=16$, $L=4$。返回斜率$p$。\n\n最终输出格式：\n- 您的程序必须生成单行文本，其中包含从情况 1 到情况 4 的所有结果，按顺序排列，以逗号分隔并用方括号括起，例如[$r_1$,$r_2$,$r_3$,$r_4$]，其中每个$r_k$是一个四舍五入到三位小数的实数。\n- 无需指定物理单位。\n\n您的程序必须是自包含的，不得读取任何输入，也不得访问文件或网络。它必须仅使用标准库和数值数组。伪随机数生成器的种子必须在模拟开始时设置为$123456$。", "solution": "该问题是有效的，因为它是科学有据、适定且客观的。它提出了一个随机微分方程（SDE）数值分析中的标准任务，并给出了一套清晰完整的指令。\n\n目标是推导 Ornstein-Uhlenbeck SDE 的欧拉-丸山方法，然后用它来数值估计其强收敛阶。Ornstein-Uhlenbeck 过程由以下 SDE 定义：\n$$\ndX_t = -\\lambda X_t\\,dt + \\sigma\\,dW_t, \\quad X_0=x_0\n$$\n其中 $\\lambda \\ge 0$ 和 $\\sigma \\ge 0$ 是常数，$x_0$ 是确定性初始条件，$W_t$ 是标准维纳过程。\n\n首先，我们推导数值时间步进格式。问题陈述提供了 SDE 在时间区间 $[t, t+h]$ 上的积分形式：\n$$\nX_{t+h} - X_t = \\int_t^{t+h} -\\lambda X_s\\,ds + \\int_t^{t+h} \\sigma\\,dW_s\n$$\n为了推导一阶近似，我们使用区间开始时刻 $t$ 的可用信息来近似积分。设 $t_n = nh$（$n \\ge 0$ 为整数，$h > 0$ 为步长）。我们将 $X_{t_n}$ 的数值近似表示为 $X_n$。从 $X_n$ 到 $X_{n+1}$ 的更新是通过近似 $[t_n, t_{n+1}]$ 上的 SDE 来推导的。\n\n漂移项积分使用左矩形法则进行近似。我们假设对于小的步长 $h$，过程 $X_s$ 与其在区间开始时的值 $X_{t_n}$ 相比变化不大。因此，我们做近似 $X_s \\approx X_{t_n}$ 对于 $s \\in [t_n, t_{n+1}]$：\n$$\n\\int_{t_n}^{t_{n+1}} -\\lambda X_s\\,ds \\approx \\int_{t_n}^{t_{n+1}} -\\lambda X_{t_n}\\,ds = -\\lambda X_{t_n} \\int_{t_n}^{t_{n+1}} ds = -\\lambda X_{t_n} h\n$$\n用我们的数值近似表示，这变为 $-\\lambda X_n h$。\n\n扩散项是一个 Itô 随机积分。由于 $\\sigma$ 是一个常数，可以将其提出：\n$$\n\\int_{t_n}^{t_{n+1}} \\sigma\\,dW_s = \\sigma \\int_{t_n}^{t_{n+1}} dW_s = \\sigma (W_{t_{n+1}} - W_{t_n})\n$$\n项 $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ 是维纳过程在区间 $[t_n, t_{n+1}]$ 上的增量。根据维纳过程的基本性质，这些增量在不重叠的区间上是独立的，并且服从均值为 $0$、方差等于时间区间长度 $h$ 的正态分布。因此，$\\Delta W_n \\sim \\mathcal{N}(0,h)$。在数值实现中，我们可以将此增量生成为 $\\Delta W_n = \\sqrt{h} Z_n$，其中 $Z_n$ 是从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取的随机变量。\n\n结合这两个近似，我们将精确值 $X_{t_n}$ 和 $X_{t_{n+1}}$ 替换为它们的数值对应物 $X_n$ 和 $X_{n+1}$：\n$$\nX_{n+1} - X_n \\approx -\\lambda X_n h + \\sigma \\Delta W_n\n$$\n整理后得到 Ornstein-Uhlenbeck 过程的显式欧拉-丸山更新规则：\n$$\nX_{n+1} = X_n - \\lambda X_n h + \\sigma \\Delta W_n = (1 - \\lambda h)X_n + \\sigma \\Delta W_n\n$$\n该格式在时间上是一阶的，并且仅使用时间 $t_n$ 的局部信息来将解推进到 $t_{n+1}$。\n\n问题的第二部分是设计一个数值实验来估计强收敛阶 $p$。强误差关注的是数值解与精确解之间的路径差异。收敛阶 $p$ 的定义是，在固定时间 $T$ 的误差 $\\mathbb{E}[|X_N^{(h)} - X_T|]$，在步长 $h \\to 0$ 时与 $h^p$ 成正比。\n\n由于不使用精确解，我们通过比较两种不同步长（粗糙步长 $h$ 和精细步长 $h/2$）的解来估计收敛阶。关键在于，为了使比较有效，两个模拟必须由相同的底层随机过程驱动。这通过路径耦合实现。我们为精细网格生成布朗增量 $\\Delta W^{(h/2)}_k \\sim \\mathcal{N}(0, h/2)$。然后通过对相邻的精细增量求和来构造粗糙网格增量：$\\Delta W^{(h)}_j = \\Delta W^{(h/2)}_{2j} + \\Delta W^{(h/2)}_{2j+1}$。根据正态变量的性质，这种构造正确地产生了服从分布 $\\mathcal{N}(0,h)$ 的粗糙增量。\n\n对于一系列粗糙步长 $h_\\ell = T/(N_0 2^{\\ell-1})$，我们在粗糙和精细网格上计算数值解 $X_T^{(h_\\ell)}$ 和 $X_T^{(h_\\ell/2)}$，两者都从相同的 $x_0$ 开始，并使用耦合的增量。这两个近似之间的均方根误差定义为 $e(h_\\ell) = (\\mathbb{E}[|X_T^{(h_\\ell)} - X_T^{(h_\\ell/2)}|^2])^{1/2}$。期望 $\\mathbb{E}[\\cdot]$ 通过对大量独立路径对进行蒙特卡洛平均来估计。\n\n假设误差行为为 $e(h) \\approx C h^p$（对于某个常数 $C$），取对数得到 $\\log e(h) \\approx \\log C + p \\log h$。这是 $\\log e(h)$ 和 $\\log h$ 之间的线性关系。因此，收敛阶 $p$ 可以估计为拟合点集 $\\{(\\log h_\\ell, \\log e(h_\\ell))\\}$ 的最小二乘直线的斜率。\n\n特殊情况按规定处理：\n-   对于确定性情况（$\\sigma=0$），问题简化为常微分方程的前向欧拉法。误差直接计算，无需蒙特卡洛，收敛阶 $p$ 通过回归求得。我们预期 $p \\approx 1$。\n-   对于纯布朗情况（$\\lambda=0$），欧拉-丸山格式是精确的，意味着对于耦合路径 $X_T^{(h)} - X_T^{(h/2)} = 0$。误差 $e(h)$ 将为零（或由于浮点精度而接近零）。要求的输出是观察到的最大误差，该值应接近于零。\n-   对于标准随机情况（$\\sigma>0, \\lambda>0$），理论上的强收敛阶是 $p=0.5$。数值实验应得到一个接近该值的斜率。\n\n以下程序实现了这整个过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment for all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: (lambda, sigma, T, x0, N0, L, N_paths)\n        {'lambda_val': 1.2, 'sigma': 0.8, 'T': 1.0, 'x0': 1.0, 'N0': 16, 'L': 4, 'N_paths': 12000, 'case_type': 'slope'},\n        # Case 2: (lambda, sigma, T, x0, N0, L, N_paths)\n        {'lambda_val': 4.0, 'sigma': 0.3, 'T': 1.0, 'x0': 0.1, 'N0': 64, 'L': 3, 'N_paths': 8000, 'case_type': 'slope'},\n        # Case 3: (lambda, sigma, T, x0, N0, L, N_paths)\n        {'lambda_val': 0.0, 'sigma': 0.9, 'T': 1.0, 'x0': 0.0, 'N0': 16, 'L': 4, 'N_paths': 20000, 'case_type': 'max_error'},\n        # Case 4: (lambda, sigma, T, x0, N0, L, N_paths)\n        {'lambda_val': 1.5, 'sigma': 0.0, 'T': 1.0, 'x0': 2.0, 'N0': 16, 'L': 4, 'N_paths': None, 'case_type': 'slope'},\n    ]\n\n    # Initialize a single random number generator for the entire suite for reproducibility.\n    rng = np.random.default_rng(123456)\n    \n    results = []\n    \n    for case_params in test_cases:\n        result = run_single_case(rng, **case_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_single_case(rng, lambda_val, sigma, T, x0, N0, L, N_paths, case_type):\n    \"\"\"\n    Executes the simulation for a single test case.\n    \"\"\"\n    log_h_values = []\n    log_e_values = []\n    e_values = []\n\n    for l in range(1, L + 1):\n        h_coarse = T / (N0 * (2**(l - 1)))\n        h_fine = h_coarse / 2.0\n        \n        n_coarse = int(round(T / h_coarse))\n        n_fine = int(round(T / h_fine))\n\n        if sigma == 0.0:  # Deterministic case\n            # Simulate one path without randomness\n            X_coarse = float(x0)\n            for _ in range(n_coarse):\n                X_coarse = (1.0 - lambda_val * h_coarse) * X_coarse\n            \n            X_fine = float(x0)\n            for _ in range(n_fine):\n                X_fine = (1.0 - lambda_val * h_fine) * X_fine\n\n            e_h = np.abs(X_coarse - X_fine)\n        else:  # Stochastic case\n            # Generate fine-grid Brownian increments for all paths\n            delta_W_fine = rng.normal(loc=0.0, scale=np.sqrt(h_fine), size=(N_paths, n_fine))\n            \n            # Construct coarse-grid increments by coupling\n            delta_W_coarse = delta_W_fine[:, 0::2] + delta_W_fine[:, 1::2]\n\n            # Initialize paths\n            X_coarse = np.full(N_paths, x0, dtype=float)\n            X_fine = np.full(N_paths, x0, dtype=float)\n\n            # Evolve coarse paths\n            for j in range(n_coarse):\n                X_coarse = (1.0 - lambda_val * h_coarse) * X_coarse + sigma * delta_W_coarse[:, j]\n\n            # Evolve fine paths\n            for k in range(n_fine):\n                X_fine = (1.0 - lambda_val * h_fine) * X_fine + sigma * delta_W_fine[:, k]\n            \n            # Calculate RMS error for the level\n            squared_errors = (X_coarse - X_fine)**2\n            mean_squared_error = np.mean(squared_errors)\n            e_h = np.sqrt(mean_squared_error)\n\n        e_values.append(e_h)\n        if e_h > 0:\n            log_h_values.append(np.log(h_coarse))\n            log_e_values.append(np.log(e_h))\n\n    # Determine the final result based on the case type\n    if case_type == 'max_error':\n        return max(e_values)\n    elif case_type == 'slope':\n        # Perform least-squares regression if there are enough data points\n        if len(log_h_values)  2:\n            return np.nan  # Not enough points to fit a line\n\n        x = np.array(log_h_values, dtype=float)\n        y = np.array(log_e_values, dtype=float)\n        \n        # Using numpy's polyfit to get the slope of the best-fit line\n        # This is equivalent to manual least-squares calculation.\n        slope, _ = np.polyfit(x, y, 1)\n        return slope\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "3226818"}, {"introduction": "现实世界中的许多系统包含在截然不同的时间尺度上变化的动态，这种特性被称为“刚性”（stiffness）。本练习将揭示显式的欧拉-丸山法在处理刚性随机微分方程时所面临的挑战，即除非使用极小的步长，否则数值解会变得不稳定。这个实践突显了在为复杂系统选择数值方法时，除了精度之外，稳定性也是一个必须考量的关键因素。[@problem_id:3226679]", "problem": "考虑一个表现出两种不同时间尺度的二维线性随机微分方程 (SDE)，该方程由独立的 Ornstein–Uhlenbeck 分量定义。设状态为 $(X_t, Y_t)$，初始条件为 $(X_0, Y_0)$，动力学方程为\n$$\ndX_t = -\\alpha X_t\\,dt + \\sigma_1\\,dW_t^{(1)}, \\quad dY_t = -\\beta Y_t\\,dt + \\sigma_2\\,dW_t^{(2)},\n$$\n其中 $W_t^{(1)}$ 和 $W_t^{(2)}$ 是独立的一维标准维纳过程，$\\alpha  0$ 是慢衰减率，$\\beta \\gg \\alpha$ 是快衰减率。该系统是刚性的，因为快速分量对显式时间步进方法的稳定性施加了严格的限制。\n\n从 SDE 的欧拉-丸山方法的核心定义出发，推导在步长为 $h$、直到时间 $t_N = Nh$ 共 $N = \\lfloor T / h \\rfloor$ 步的均匀时间网格上，每个分量的离散时间动力学。利用线性 SDE 的基本性质和 Itō 积分，推导 $X_{t_N}$ 和 $Y_{t_N}$ 的精确均值和方差，以及显式欧拉-丸山离散化在第 $N$ 步产生的均值和方差的闭式表达式。不要假设或使用任何预先推导的稳定性或误差公式；相反，应从第一性原理（线性性、Itō 等距性和欧拉-丸山方法的定义）出发来获得它们。\n\n对于任何正数量 $q$ 及其近似值 $\\hat{q}$，将相对误差定义为\n$$\n\\mathrm{RelErr}(q,\\hat{q}) = \\frac{|q - \\hat{q}|}{\\max(|q|, \\varepsilon)},\n$$\n其中 $\\varepsilon = 10^{-12}$ 是一个固定的正小数，以避免除以零。对于每个参数集，计算四个相对误差：$X_{t_N}$ 的均值和方差以及 $Y_{t_N}$ 的均值和方差。为该参数集报告一个标量，该标量等于这四个相对误差中的最大值。\n\n您的程序必须使用欧拉-丸山方法和闭式精确统计量来实现上述计算，并为以下每个测试用例生成最大相对误差。不涉及任何物理单位。\n\n测试套件：\n- 情况 A（正常路径，小步长）：$\\alpha = 1$，$\\beta = 100$，$\\sigma_1 = 0.5$，$\\sigma_2 = 0.5$，$X_0 = 1$，$Y_0 = 1$，$T = 1$，$h = 10^{-3}$。\n- 情况 B（边界条件，接近快速尺度的不稳定阈值）：参数与情况 A 相同，但 $h = 0.02$。\n- 情况 C（边缘情况，超出快速尺度的显式欧拉稳定性阈值）：参数与情况 A 相同，但 $h = 0.03$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[$r_1$,$r_2$,$r_3$]”），其中 $r_i$ 是情况 $i$ 的最大相对误差。每个 $r_i$ 都必须是浮点数。", "solution": "用户提供的问题陈述已经过验证，并被确定为是合理的。它具有科学依据，定义明确且客观。它提出了一个随机微分方程数值分析中的形式化问题，没有任何明显的缺陷。因此，我们可以继续进行完整的求解。\n\n该问题要求分析应用于具有刚性动力学的二维线性随机微分方程 (SDE) 的欧拉-丸山方法。状态向量为 $(X_t, Y_t)$，各分量根据 Ornstein-Uhlenbeck 过程独立演化：\n$$\ndX_t = -\\alpha X_t\\,dt + \\sigma_1\\,dW_t^{(1)}, \\quad X(0) = X_0\n$$\n$$\ndY_t = -\\beta Y_t\\,dt + \\sigma_2\\,dW_t^{(2)}, \\quad Y(0) = Y_0\n$$\n由于 $X_t$ 和 $Y_t$ 的动力学形式相同且解耦，我们可以对单个 Ornstein-Uhlenbeck 过程进行一般性推导，然后将结果应用于每个分量。让我们考虑以下通用 SDE：\n$$\ndZ_t = -k Z_t\\,dt + \\sigma dW_t, \\quad Z(0) = Z_0\n$$\n其中 $k  0$ 和 $\\sigma$ 是常数，$W_t$ 是标准的一维维纳过程。初始条件 $Z_0$ 被视为一个确定性常数。\n\n### 精确均值和方差的推导\n\n我们使用积分因子 $f(t) = e^{kt}$ 来求解这个线性 SDE。根据 Itō 的乘积法则，$e^{kt}Z_t$ 的微分是：\n$$\nd(e^{kt}Z_t) = (de^{kt})Z_t + e^{kt}(dZ_t) + d(e^{kt})d(Z_t)\n$$\n微分项为 $de^{kt} = k e^{kt} dt$ 和 $dZ_t = -kZ_t dt + \\sigma dW_t$。二次协变项 $d(e^{kt})d(Z_t)$ 的阶数为 $dt \\cdot dW_t \\sim dt^{3/2}$ 和 $dt \\cdot dt \\sim dt^2$，在微积分中它们都为零。\n代入微分项：\n$$\nd(e^{kt}Z_t) = (k e^{kt} dt)Z_t + e^{kt}(-kZ_t dt + \\sigma dW_t)\n$$\n$$\nd(e^{kt}Z_t) = k e^{kt} Z_t dt - k e^{kt} Z_t dt + \\sigma e^{kt} dW_t = \\sigma e^{kt} dW_t\n$$\n从 $s=0$ 到 $s=t$ 积分：\n$$\n\\int_0^t d(e^{ks}Z_s) = \\int_0^t \\sigma e^{ks} dW_s\n$$\n$$\ne^{kt}Z_t - e^{k \\cdot 0}Z_0 = \\sigma \\int_0^t e^{ks} dW_s\n$$\n$$\nZ_t = Z_0 e^{-kt} + \\sigma e^{-kt} \\int_0^t e^{ks} dW_s = Z_0 e^{-kt} + \\sigma \\int_0^t e^{-k(t-s)} dW_s\n$$\n这是 $Z_t$ 的精确解。\n\n**精确均值** $\\mathbb{E}[Z_t]$ 可通过对解取期望得到。利用期望的线性性质以及 Itō 积分的期望为零的事实：\n$$\n\\mathbb{E}[Z_t] = \\mathbb{E}[Z_0 e^{-kt}] + \\mathbb{E}\\left[\\sigma \\int_0^t e^{-k(t-s)} dW_s\\right] = Z_0 e^{-kt} + 0\n$$\n$$\n\\mathbb{E}[Z_t] = Z_0 e^{-kt}\n$$\n**精确方差** $\\mathrm{Var}(Z_t)$ 是与均值偏差平方的期望：\n$$\n\\mathrm{Var}(Z_t) = \\mathbb{E}[(Z_t - \\mathbb{E}[Z_t])^2] = \\mathbb{E}\\left[\\left(\\sigma \\int_0^t e^{-k(t-s)} dW_s\\right)^2\\right]\n$$\n使用 Itō 等距性质，即 $\\mathbb{E}[(\\int_0^t f(s)dW_s)^2] = \\int_0^t \\mathbb{E}[f(s)^2]ds$：\n$$\n\\mathrm{Var}(Z_t) = \\sigma^2 \\int_0^t (e^{-k(t-s)})^2 ds = \\sigma^2 \\int_0^t e^{-2k(t-s)} ds\n$$\n该积分的计算结果为：\n$$\n\\int_0^t e^{-2k(t-s)} ds = \\left[ \\frac{e^{-2k(t-s)}}{2k} \\right]_0^t = \\frac{e^0 - e^{-2kt}}{2k} = \\frac{1 - e^{-2kt}}{2k}\n$$\n因此，精确方差为：\n$$\n\\mathrm{Var}(Z_t) = \\frac{\\sigma^2}{2k}(1 - e^{-2kt})\n$$\n\n### 欧拉-丸山均值和方差的推导\n\n欧拉-丸山方法在均匀时间网格 $t_n = nh$（$n=0, 1, \\dots, N$）上离散化 SDE。更新规则为：\n$$\n\\hat{Z}_{n+1} = \\hat{Z}_n - k \\hat{Z}_n h + \\sigma (W_{t_{n+1}} - W_{t_n})\n$$\n其中 $\\hat{Z}_n$ 是 $Z_{t_n}$ 的数值近似。维纳增量 $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ 是一个服从正态分布的随机变量，其均值为 $0$，方差为 $h$。我们可以写成 $\\Delta W_n = \\sqrt{h} \\xi_n$，其中 $\\xi_n \\sim \\mathcal{N}(0,1)$ 是独立同分布的标准正态随机变量。该近似的递推关系为：\n$$\n\\hat{Z}_{n+1} = (1 - kh) \\hat{Z}_n + \\sigma \\sqrt{h} \\xi_n\n$$\n从 $\\hat{Z}_0 = Z_0$ 开始，我们可以展开递推关系以找到 $\\hat{Z}_N$ 的显式表达式：\n$$\n\\hat{Z}_N = (1-kh)^N Z_0 + \\sigma \\sqrt{h} \\sum_{n=0}^{N-1} (1-kh)^{N-1-n} \\xi_n\n$$\n\n**数值近似的均值** $\\mathbb{E}[\\hat{Z}_N]$ 可通过取期望得到。由于 $\\mathbb{E}[\\xi_n] = 0$：\n$$\n\\mathbb{E}[\\hat{Z}_N] = \\mathbb{E}[(1-kh)^N Z_0] + \\sigma \\sqrt{h} \\sum_{n=0}^{N-1} (1-kh)^{N-1-n} \\mathbb{E}[\\xi_n] = (1-kh)^N Z_0\n$$\n$$\n\\mathbb{E}[\\hat{Z}_N] = Z_0 (1-kh)^N\n$$\n**数值近似的方差** $\\mathrm{Var}(\\hat{Z}_N)$ 为：\n$$\n\\mathrm{Var}(\\hat{Z}_N) = \\mathbb{E}[(\\hat{Z}_N - \\mathbb{E}[\\hat{Z}_N])^2] = \\mathbb{E}\\left[\\left(\\sigma \\sqrt{h} \\sum_{n=0}^{N-1} (1-kh)^{N-1-n} \\xi_n\\right)^2\\right]\n$$\n$$\n\\mathrm{Var}(\\hat{Z}_N) = \\sigma^2 h \\mathbb{E}\\left[\\left(\\sum_{n=0}^{N-1} (1-kh)^{N-1-n} \\xi_n\\right)^2\\right]\n$$\n由于 $\\xi_n$ 是独立的且方差为 1，平方和的期望简化为系数平方的和：\n$$\n\\mathrm{Var}(\\hat{Z}_N) = \\sigma^2 h \\sum_{n=0}^{N-1} \\left((1-kh)^{N-1-n}\\right)^2 = \\sigma^2 h \\sum_{j=0}^{N-1} ((1-kh)^2)^j\n$$\n这是一个公比为 $r = (1-kh)^2$ 的几何级数。\n如果 $r \\neq 1$，则和为 $\\frac{1-r^N}{1-r}$。方差为：\n$$\n\\mathrm{Var}(\\hat{Z}_N) = \\sigma^2 h \\frac{1 - ((1-kh)^2)^N}{1 - (1-kh)^2} = \\sigma^2 h \\frac{1 - (1-kh)^{2N}}{1 - (1 - 2kh + k^2h^2)} = \\sigma^2 h \\frac{1 - (1-kh)^{2N}}{2kh - k^2h^2}\n$$\n$$\n\\mathrm{Var}(\\hat{Z}_N) = \\frac{\\sigma^2}{k(2-kh)} (1 - (1-kh)^{2N})\n$$\n该方法的均方稳定性要求 $|1-kh|1$，即 $0  kh  2$。快速分量 $Y_t$ 的 $k=\\beta$，因此其稳定性要求 $h  2/\\beta$。\n当 $kh=2$ 时，即在稳定性的边界上，会出现一种特殊情况。此时，公比 $r=(1-2)^2=1$。几何级数的和变为 $\\sum_{j=0}^{N-1} 1^j = N$。方差为：\n$$\n\\mathrm{Var}(\\hat{Z}_N) = \\sigma^2 h N = \\sigma^2 t_N \\quad (\\text{当 } kh=2)\n$$\n\n### 计算步骤\n\n对于每个测试用例，我们计算步数 $N = \\lfloor T / h \\rfloor$ 和最终时间 $t_N = Nh$。然后我们计算四组统计量：$X$ 和 $Y$ 分量的精确值和数值。\n\n- **对于 X 分量**：使用 $k = \\alpha$, $\\sigma = \\sigma_1$, $Z_0 = X_0$。\n- **对于 Y 分量**：使用 $k = \\beta$, $\\sigma = \\sigma_2$, $Z_0 = Y_0$。\n\n在时间 $t_N$ 为通用分量 $Z$ 计算以下量：\n- 精确均值：$\\mathbb{E}[Z_{t_N}] = Z_0 e^{-kt_N}$\n- 精确方差：$\\mathrm{Var}(Z_{t_N}) = \\frac{\\sigma^2}{2k}(1 - e^{-2kt_N})$\n- 数值均值：$\\mathbb{E}[\\hat{Z}_N] = Z_0 (1-kh)^N$\n- 数值方差：$\\mathrm{Var}(\\hat{Z}_N)$，根据 $kh=2$ 是否成立使用相应的公式。\n\n精确值 $q$ 与其近似值 $\\hat{q}$ 之间的相对误差计算如下：\n$$\n\\mathrm{RelErr}(q,\\hat{q}) = \\frac{|q - \\hat{q}|}{\\max(|q|, \\varepsilon)}, \\quad \\varepsilon = 10^{-12}\n$$\n对于每个测试用例，我们计算 $X$ 和 $Y$ 分量的均值和方差的四个相对误差。该用例的最终结果是这四个误差中的最大值。\n- $\\mathrm{RelErr}(\\mathbb{E}[X_{t_N}], \\mathbb{E}[\\hat{X}_N])$\n- $\\mathrm{RelErr}(\\mathrm{Var}(X_{t_N}), \\mathrm{Var}(\\hat{X}_N))$\n- $\\mathrm{RelErr}(\\mathbb{E}[Y_{t_N}], \\mathbb{E}[\\hat{Y}_N])$\n- $\\mathrm{RelErr}(\\mathrm{Var}(Y_{t_N}), \\mathrm{Var}(\\hat{Y}_N))$\n\n这些测试用例探讨了快速分量 $Y_t$ 的不同稳定性区域，其稳定性阈值为 $h  2/\\beta = 2/100 = 0.02$。\n- 情况 A ($h=0.001$)：稳定区域。\n- 情况 B ($h=0.02$)：稳定性边界。\n- 情况 C ($h=0.03$)：不稳定区域。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the maximum relative error between exact and Euler-Maruyama statistics\n    for a stiff two-component Ornstein-Uhlenbeck process.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (happy path, small step size)\n        {\"alpha\": 1.0, \"beta\": 100.0, \"sigma1\": 0.5, \"sigma2\": 0.5, \"X0\": 1.0, \"Y0\": 1.0, \"T\": 1.0, \"h\": 1e-3},\n        # Case B (boundary condition, near instability threshold for fast scale)\n        {\"alpha\": 1.0, \"beta\": 100.0, \"sigma1\": 0.5, \"sigma2\": 0.5, \"X0\": 1.0, \"Y0\": 1.0, \"T\": 1.0, \"h\": 0.02},\n        # Case C (edge case, beyond explicit Euler stability threshold for fast scale)\n        {\"alpha\": 1.0, \"beta\": 100.0, \"sigma1\": 0.5, \"sigma2\": 0.5, \"X0\": 1.0, \"Y0\": 1.0, \"T\": 1.0, \"h\": 0.03},\n    ]\n\n    results = []\n    \n    # Epsilon for relative error calculation to avoid division by zero\n    epsilon = 1e-12\n\n    def calculate_statistics(k, sigma, z0, h, N, t_N):\n        \"\"\"\n        Calculates exact and numerical mean and variance for a generic\n        Ornstein-Uhlenbeck process dZ = -k*Z*dt + sigma*dW.\n        \"\"\"\n        # Exact statistics\n        exact_mean = z0 * np.exp(-k * t_N)\n        exact_var = (sigma**2 / (2.0 * k)) * (1.0 - np.exp(-2.0 * k * t_N))\n\n        # Euler-Maruyama statistics\n        numerical_mean = z0 * np.power(1.0 - k * h, N)\n\n        kh = k * h\n        # Check for the stability boundary condition kh = 2\n        if np.isclose(kh, 2.0):\n            numerical_var = sigma**2 * t_N\n        else:\n            term = 1.0 - np.power(1.0 - kh, 2 * N)\n            denominator = k * (2.0 - kh)\n            numerical_var = (sigma**2 / denominator) * term\n        \n        return exact_mean, exact_var, numerical_mean, numerical_var\n\n    def relative_error(q, q_hat):\n        \"\"\"Calculates the relative error.\"\"\"\n        return np.abs(q - q_hat) / np.maximum(np.abs(q), epsilon)\n\n    for case in test_cases:\n        alpha, beta, sigma1, sigma2, X0, Y0, T, h = (\n            case[\"alpha\"], case[\"beta\"], case[\"sigma1\"], case[\"sigma2\"],\n            case[\"X0\"], case[\"Y0\"], case[\"T\"], case[\"h\"]\n        )\n\n        N = int(np.floor(T / h))\n        t_N = N * h\n        \n        # Calculate statistics for the X component (slow)\n        ex_mean_X, ex_var_X, num_mean_X, num_var_X = calculate_statistics(\n            alpha, sigma1, X0, h, N, t_N\n        )\n\n        # Calculate statistics for the Y component (fast)\n        ex_mean_Y, ex_var_Y, num_mean_Y, num_var_Y = calculate_statistics(\n            beta, sigma2, Y0, h, N, t_N\n        )\n        \n        # Compute the four relative errors\n        err_mean_X = relative_error(ex_mean_X, num_mean_X)\n        err_var_X = relative_error(ex_var_X, num_var_X)\n        err_mean_Y = relative_error(ex_mean_Y, num_mean_Y)\n        err_var_Y = relative_error(ex_var_Y, num_var_Y)\n        \n        # Find the maximum of the four errors\n        max_rel_error = max(err_mean_X, err_var_X, err_mean_Y, err_var_Y)\n        results.append(max_rel_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3226679"}]}