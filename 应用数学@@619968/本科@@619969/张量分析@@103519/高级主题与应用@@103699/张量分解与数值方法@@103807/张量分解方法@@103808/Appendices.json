{"hands_on_practices": [{"introduction": "许多张量分解算法，尤其是 CANDECOMP/PARAFAC (CP) 分解，其核心是高效的数值计算。本练习将引导你实践一个基础但至关重要的运算——Khatri-Rao 积，它是理解交替最小二乘法 (ALS) 等迭代求解过程的关键。通过这个具体的计算，你将对因子矩阵如何相互作用以构建最终的张量模型有一个更清晰的认识 [@problem_id:1542398]。", "problem": "在张量分析中，按列 Khatri-Rao 积是一种基本运算，用于各种张量分解方法，例如 CANDECOMP/PARAFAC (CP) 分解。\n\n考虑两个实值矩阵 $B$ 和 $C$，它们由下式给出：\n$$\nB = \\begin{pmatrix} 1 & 5 \\\\ 2 & 0 \\\\ 3 & 1 \\end{pmatrix}\n$$\n和\n$$\nC = \\begin{pmatrix} 4 & 2 \\\\ 6 & 3 \\\\ 7 & 8 \\end{pmatrix}\n$$\n\n计算它们的按列 Khatri-Rao 积，记为 $A = C \\odot B$。", "solution": "两个具有相同列数的矩阵的按列 Khatri-Rao 积定义如下：如果 $B \\in \\mathbb{R}^{I \\times K}$ 且 $C \\in \\mathbb{R}^{J \\times K}$，那么 $C \\odot B \\in \\mathbb{R}^{IJ \\times K}$ 的各列由 $(C \\odot B)_{: , k} = c_{k} \\otimes b_{k}$ 给出，其中 $k = 1, \\ldots, K$，$\\otimes$ 表示 Kronecker 积。\n\n给定\n$$\nB = \\begin{pmatrix} 1 & 5 \\\\ 2 & 0 \\\\ 3 & 1 \\end{pmatrix}, \\quad\nC = \\begin{pmatrix} 4 & 2 \\\\ 6 & 3 \\\\ 7 & 8 \\end{pmatrix},\n$$\n两者都有 $K=2$ 列，因此 $A = C \\odot B \\in \\mathbb{R}^{9 \\times 2}$。\n\n使用 $c_{1} = \\begin{pmatrix} 4 \\\\ 6 \\\\ 7 \\end{pmatrix}$ 和 $b_{1} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$ 计算第一列：\n$$\nc_{1} \\otimes b_{1} = \\begin{pmatrix} 4 b_{1} \\\\ 6 b_{1} \\\\ 7 b_{1} \\end{pmatrix}\n= \\begin{pmatrix} 4 \\\\ 8 \\\\ 12 \\\\ 6 \\\\ 12 \\\\ 18 \\\\ 7 \\\\ 14 \\\\ 21 \\end{pmatrix}.\n$$\n\n使用 $c_{2} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 8 \\end{pmatrix}$ 和 $b_{2} = \\begin{pmatrix} 5 \\\\ 0 \\\\ 1 \\end{pmatrix}$ 计算第二列：\n$$\nc_{2} \\otimes b_{2} = \\begin{pmatrix} 2 b_{2} \\\\ 3 b_{2} \\\\ 8 b_{2} \\end{pmatrix}\n= \\begin{pmatrix} 10 \\\\ 0 \\\\ 2 \\\\ 15 \\\\ 0 \\\\ 3 \\\\ 40 \\\\ 0 \\\\ 8 \\end{pmatrix}.\n$$\n\n将这些列向量堆叠起来得到\n$$\nA = C \\odot B = \\begin{pmatrix}\n4 & 10 \\\\\n8 & 0 \\\\\n12 & 2 \\\\\n6 & 15 \\\\\n12 & 0 \\\\\n18 & 3 \\\\\n7 & 40 \\\\\n14 & 0 \\\\\n21 & 8\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\n4 & 10 \\\\\n8 & 0 \\\\\n12 & 2 \\\\\n6 & 15 \\\\\n12 & 0 \\\\\n18 & 3 \\\\\n7 & 40 \\\\\n14 & 0 \\\\\n21 & 8\n\\end{pmatrix}}$$", "id": "1542398"}, {"introduction": "张量的高维结构初看起来可能令人望而生畏，但我们可以通过一种称为“矩阵化”或“展开”的强大技术，将其与我们熟悉的矩阵联系起来。本练习将带你动手将一个三阶张量从不同模式展开为矩阵，并计算其多线性秩，这个过程不仅是 Tucker 分解等方法的理论基础，更能让你直观地理解张量在不同维度上的内在复杂性。这让你能够将成熟的矩阵分析工具应用于高维数据 [@problem_id:1542439]。", "problem": "在张量分析中，一个高阶张量可以通过一个称为矩阵化（或展开）的过程表示为矩阵形式。这使得应用标准的矩阵分析工具来理解张量的属性成为可能。多线性秩就是这样一种属性。\n\n考虑一个三阶张量 $T \\in \\mathbb{R}^{2 \\times 3 \\times 4}$。张量 $T$ 的元素，记为 $t_{ijk}$，其中 $i \\in \\{1,2\\}$, $j \\in \\{1,2,3\\}$, $k \\in \\{1,2,3,4\\}$，由其四个正面切片 $F_k = T(:,:,k) \\in \\mathbb{R}^{2 \\times 3}$ 给出：\n\n$F_1 = \\begin{pmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix}$\n\n$F_2 = \\begin{pmatrix} 0 & 1 & 1 \\\\ 1 & -1 & 0 \\end{pmatrix}$\n\n$F_3 = \\begin{pmatrix} 2 & 1 & 3 \\\\ 1 & 0 & 1 \\end{pmatrix}$\n\n$F_4 = \\begin{pmatrix} 1 & 1 & 2 \\\\ 1 & 0 & 1 \\end{pmatrix}$\n\n张量 $T$ 可以以三种主要方式进行矩阵化，每种方式对应其一个模态。对于一个大小为 $I_1 \\times I_2 \\times I_3$ 的张量：\n- 模1矩阵化 $T_{(1)}$ 是一个大小为 $I_1 \\times (I_2 I_3)$ 的矩阵，其行是向量化后的水平切片 $T(i,:,:)$。\n- 模2矩阵化 $T_{(2)}$ 是一个大小为 $I_2 \\times (I_1 I_3)$ 的矩阵，其行是向量化后的侧向切片 $T(:,j,:)$。\n- 模3矩阵化 $T_{(3)}$ 是一个大小为 $I_3 \\times (I_1 I_2)$ 的矩阵，其行是向量化后的正面切片 $T(:,:,k)$。\n\n为了向量化的目的，一个矩阵通过将其列按顺序堆叠来展开。例如，对于矩阵 $M = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$，其向量化是 $\\text{vec}(M) = \\begin{pmatrix} a \\\\ c \\\\ b \\\\ d \\end{pmatrix}$。\n\n张量 $T$ 的多线性秩定义为其矩阵化的秩的元组 $(R_1, R_2, R_3)$，其中 $R_n = \\text{rank}(T_{(n)})$。\n\n计算给定张量 $T$ 的多线性秩 $(R_1, R_2, R_3)$。将你的答案表示为一个包含三个整数元素的行矩阵。", "solution": "我们给定一个三阶张量 $T \\in \\mathbb{R}^{2 \\times 3 \\times 4}$，它由其正面切片 $F_{k} = T(:,:,k) \\in \\mathbb{R}^{2 \\times 3}$ 给出，其中向量化定义为堆叠矩阵的列。多线性秩为 $(R_{1},R_{2},R_{3})$，其中 $R_{n} = \\operatorname{rank}(T_{(n)})$。\n\n模3矩阵化 $T_{(3)}$ 的大小为 $I_{3} \\times (I_{1} I_{2}) = 4 \\times 6$，其第 $k$ 行是 $\\operatorname{vec}(F_{k})^{\\top}$。计算这四个向量：\n$$\n\\operatorname{vec}(F_{1}) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix},\\quad\n\\operatorname{vec}(F_{2}) = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix},\\quad\n\\operatorname{vec}(F_{3}) = \\begin{pmatrix} 2 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 3 \\\\ 1 \\end{pmatrix},\\quad\n\\operatorname{vec}(F_{4}) = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\n观察到 $F_{4} = F_{1} + F_{2}$，因此 $\\operatorname{vec}(F_{4}) = \\operatorname{vec}(F_{1}) + \\operatorname{vec}(F_{2})$，所以 $\\operatorname{rank}(T_{(3)}) \\leq 3$。为了检查 $\\operatorname{vec}(F_{1}), \\operatorname{vec}(F_{2}), \\operatorname{vec}(F_{3})$ 是否线性无关，假设 $a\\,F_{1} + b\\,F_{2} + c\\,F_{3} = 0$。逐个查看位置 $(2,2)$、$(1,1)$ 和 $(2,1)$ 上的元素可得\n$$\na - b = 0,\\quad a + 2c = 0,\\quad b + c = 0.\n$$\n由 $a=b$ 和 $b = -c$，我们得到 $a = -c$，然后 $a + 2c = 0$ 得到 $c = 0$，因此 $a=b=0$。因此这三者是线性无关的，所以 $R_{3} = \\operatorname{rank}(T_{(3)}) = 3$。\n\n模1矩阵化 $T_{(1)}$ 的大小为 $I_{1} \\times (I_{2} I_{3}) = 2 \\times 12$，其第 $i$ 行等于 $\\operatorname{vec}(T(i,:,:))^{\\top}$。对于 $i=1$，构造 $M_{1} = T(1,:,:) \\in \\mathbb{R}^{3 \\times 4}$，其第 $k$ 列是 $F_{k}$ 第一行的转置：\n$$\nM_{1} = \\begin{pmatrix}\n1 & 0 & 2 & 1 \\\\\n0 & 1 & 1 & 1 \\\\\n1 & 1 & 3 & 2\n\\end{pmatrix},\\quad\n\\operatorname{vec}(M_{1}) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 2 \\\\ 1 \\\\ 3 \\\\ 1 \\\\ 1 \\\\ 2 \\end{pmatrix}.\n$$\n对于 $i=2$，构造 $M_{2} = T(2,:,:) \\in \\mathbb{R}^{3 \\times 4}$，其第 $k$ 列是 $F_{k}$ 第二行的转置：\n$$\nM_{2} = \\begin{pmatrix}\n0 & 1 & 1 & 1 \\\\\n1 & -1 & 0 & 0 \\\\\n1 & 0 & 1 & 1\n\\end{pmatrix},\\quad\n\\operatorname{vec}(M_{2}) = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\n$T_{(1)}$ 的两个行向量是 $\\operatorname{vec}(M_{1})^{\\top}$ 和 $\\operatorname{vec}(M_{2})^{\\top}$。它们不成比例，因为它们的第一个分量不同（$1$ 对 $0$）。因此 $R_{1} = \\operatorname{rank}(T_{(1)}) = 2$。\n\n模2矩阵化 $T_{(2)}$ 的大小为 $I_{2} \\times (I_{1} I_{3}) = 3 \\times 8$，其第 $j$ 行等于 $\\operatorname{vec}(T(:,j,:))^{\\top}$。对于每个 $j$，$T(:,j,:)$ 是一个 $2 \\times 4$ 矩阵，其第 $k$ 列是 $F_{k}$ 的第 $j$ 列。因此：\n$$\nA_{1} = T(:,1,:) = \\begin{pmatrix} 1 & 0 & 2 & 1 \\\\ 0 & 1 & 1 & 1 \\end{pmatrix},\\quad\n\\operatorname{vec}(A_{1}) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 2 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix},\n$$\n$$\nA_{2} = T(:,2,:) = \\begin{pmatrix} 0 & 1 & 1 & 1 \\\\ 1 & -1 & 0 & 0 \\end{pmatrix},\\quad\n\\operatorname{vec}(A_{2}) = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix},\n$$\n$$\nA_{3} = T(:,3,:) = \\begin{pmatrix} 1 & 1 & 3 & 2 \\\\ 1 & 0 & 1 & 1 \\end{pmatrix},\\quad\n\\operatorname{vec}(A_{3}) = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 3 \\\\ 1 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\n我们有 $A_{3} = A_{1} + A_{2}$，因此 $\\operatorname{vec}(A_{3}) = \\operatorname{vec}(A_{1}) + \\operatorname{vec}(A_{2})$，所以 $\\operatorname{rank}(T_{(2)}) \\leq 2$。由于 $\\operatorname{vec}(A_{1})$ 和 $\\operatorname{vec}(A_{2})$ 不成比例（它们的第一个元素是 $1$ 和 $0$），它们是线性无关的。因此 $R_{2} = \\operatorname{rank}(T_{(2)}) = 2$。\n\n汇总这三个秩，得到多线性秩元组 $(R_{1}, R_{2}, R_{3}) = (2, 2, 3)$。", "answer": "$$\\boxed{\\begin{pmatrix} 2 & 2 & 3 \\end{pmatrix}}$$", "id": "1542439"}, {"introduction": "在理论计算之外，将张量分解应用于实际数据分析时，一个核心的挑战是如何选择合适的秩 $R$。一个过低的秩可能无法捕捉数据中的关键模式，而一个过高的秩则可能导致模型过拟合并解释噪音。本练习模拟了一个典型的数据科学场景，要求你根据重构误差与秩的关系图，运用“肘部法则”这一常用启发式方法来做出决策，从而在模型复杂性与拟合优度之间找到一个理想的平衡点 [@problem_id:1542404]。", "problem": "一位数据科学家正在分析一个新电子商务平台的用户交互数据。该数据被构建为一个三阶张量 $\\mathcal{X}$，其维度为（用户 $\\times$ 产品 $\\times$ 天），其中每个条目代表特定某天用户与某个产品交互的分数。为了揭示潜在的购买模式，该科学家决定使用规范多元分解（Canonical Polyadic (CP) Decomposition），也称为 CANDECOMP/PARAFAC。该方法将数据张量建模为一个近似值 $\\hat{\\mathcal{X}}$，该近似值是 $R$ 个秩一张量之和。整数 $R$ 是分解的秩，对应于待识别的潜在模式的数量。\n\n一个关键步骤是为秩 $R$ 选择一个合适的值。由于真实模式的数量是未知的，该科学家在一系列秩（从 $R=1$ 到 $R=12$）上计算了CP分解。对于每个秩 $R$，他们计算重构误差 $E(R)$，定义为残差张量的弗罗贝尼乌斯范数 $E(R) = ||\\mathcal{X} - \\hat{\\mathcal{X}}_R||_F$，其中 $\\hat{\\mathcal{X}}_R$ 是秩为 $R$ 的重构张量。绘制出 $E(R)$ 与 $R$ 的关系图，可以观察到该曲线是单调递减的：在 $R=1$ 时误差最高，在 $R=12$ 时误差最低。曲线在最初的几个秩处急剧下降，然后开始变得平缓，之后秩的每一次增加带来的误差减小量都更小。\n\n给定这张重构误差与秩的关系图，以下哪项描述了最常用且最有效的启发式方法，用于选择一个既能捕捉数据基本结构又不会导致严重过拟合的合适的秩 $R$？\n\nA. 选择秩 $R=12$，因为这个秩在所有测试值中产生了绝对最小的重构误差。\n\nB. 选择与图上最大曲率点对应的秩 $R$，该点通常被称为“肘部”或“膝部”，在此处误差减小的速率显著减慢。\n\nC. 选择秩 $R=1$，因为它对应于最主要的单个模式，因此代表了数据最重要的特征。\n\nD. 选择秩 $R=6$，它是测试秩范围 $[1, 12]$ 的中位数，在搜索空间中提供了一种平衡。\n\nE. 选择第一个使误差 $E(R)$ 降至某个任意阈值以下的秩 $R$，例如，低于初始误差 $E(1)$ 的10%。", "solution": "我们使用秩为 $R$ 的 CP 分解对三阶张量进行建模，将秩为 $R$ 的近似写为\n$$\n\\hat{\\mathcal{X}}_{R}=\\sum_{r=1}^{R}\\lambda_{r}\\,a_{r}\\circ b_{r}\\circ c_{r},\n$$\n并使用重构误差来衡量拟合程度\n$$\nE(R)=\\|\\mathcal{X}-\\hat{\\mathcal{X}}_{R}\\|_{F}.\n$$\n根据其构造，允许更多的分量不会增加可达到的最佳拟合度，因此 $E(R)$ 是关于 $R$ 的单调非增函数。在实践中，增加 $R$ 会减少 $E(R)$，但最终会产生递减的回报，同时增加了模型复杂度和过拟合的风险。\n\n一个权衡拟合度和复杂度的常用启发式方法是，在 $E(R)$ 相对于 $R$ 的曲线上定位收益递减点，通常称为曲线的“肘部”或“膝部”。在离散形式下，可以通过一阶差分来表征收益递减\n$$\n\\Delta E(R)=E(R-1)-E(R),\n$$\n它是非负的，以及离散曲率（二阶差分）\n$$\n\\Delta^{2}E(R)=\\Delta E(R)-\\Delta E(R+1).\n$$\n肘部对应于 $\\Delta^{2}E(R)$ 最大的 $R$ 值，即误差减少率下降最显著的地方。选择这个 $R$ 值可以捕捉到基本结构，同时避免了主要用于拟合噪声的不必要分量。\n\n评估各个选项：\n- 选项A仅仅因为最大测试秩能最小化训练误差而选择它；由于 $E(R)$ 总是随 $R$ 减小，这种做法忽略了过拟合，并且不是基于曲线形状的标准启发式方法。\n- 选项C选择了 $R=1$，这通常限制性太强，会丢弃重要的结构。\n- 选项D使用了测试范围的中位数，这是任意的，并非由数据驱动。\n- 选项E使用了相对于 $E(1)$ 的一个任意阈值；除非这个阈值有外部标准作为依据，否则它不是标准的基于形状的启发式方法。\n- 选项B明确选择了肘部/膝部（最大曲率点），对于一条单调递减并趋于平缓的误差曲线而言，这是最常用且最有效的启发式方法。\n\n因此，正确的选择是在误差曲线的肘部/膝部选择秩。", "answer": "$$\\boxed{B}$$", "id": "1542404"}]}