{"hands_on_practices": [{"introduction": "Metropolis算法是MCMC方法的一块基石，其威力蕴藏在一个简洁而优雅的接受准则中。第一个练习将通过具体的计算来揭开这个核心机制的神秘面纱。通过计算一个提议移动的接受概率，你将亲身体验马尔可夫链如何决定是探索一个新状态还是停留在当前位置 [@problem_id:1371728]。", "problem": "一位数据科学家正在实现一个马尔可夫链蒙特卡洛 (MCMC) 模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与该参数负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法，并采用对称的提议分布 $q(x'|x)$，其中给定当前状态 $x$ 提议一个新状态 $x'$ 的概率等于给定 $x'$ 提议 $x$ 的概率（即 $q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步，链的当前状态是 $x = 1.5$。该算法接着提议移动到一个新的候选状态 $x' = 2.0$。\n\n计算此特定移动的接受概率。您的答案应为一个无量纲实数。将最终答案四舍五入至四位有效数字。", "solution": "对于从 $x$ 到 $x'$ 的移动，当提议分布 $q(x'|x)=q(x|x')$ 对称时，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率可简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，因此\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，当四舍五入到四位有效数字时，$\\exp(-0.5)\\approx 0.6065$。", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "在基础的Metropolis算法之外，Gibbs抽样为多维问题提供了一种强大的替代方案。它的效率取决于我们能否从目标分布的完全条件分布中进行抽样。这个练习要求你推导一个相互作用粒子系统的条件分布，揭示一个复杂的联合概率函数如何能够分解成我们所熟悉的、更简单的分布形式 [@problem_id:1316600]。", "problem": "考虑一个由A和B两种相互作用的粒子组成的系统。令随机变量 $X$ 和 $Y$ 分别表示A类粒子和B类粒子的数量。粒子对 $(X, Y)$ 的状态空间是所有非负整数对的集合，即 $(x, y)$ 其中 $x, y \\in \\{0, 1, 2, \\ldots\\}$。已知观测到特定状态 $(x, y)$ 的联合概率质量函数与以下函数成正比：\n$$\nf(x, y) = \\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)\n$$\n其中 $\\alpha$、$\\beta$ 和 $\\lambda$ 是正常数，分别代表内在产生率和相互作用强度。\n\n你的任务是推导在固定 $y$ 时的条件概率质量函数 $P(X=x | Y=y)$ 和在固定 $x$ 时的条件概率质量函数 $P(Y=y | X=x)$。请将最终答案表示为这两个概率的一对符号表达式。", "solution": "问题要求在联合分布 $P(X=x, Y=y) \\propto f(x, y)$ 的情况下，求条件概率质量函数（PMF）$P(X=x | Y=y)$ 和 $P(Y=y | X=x)$。\n\n对于离散随机变量，条件概率的基本定义是：\n$$\nP(X=x | Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)}\n$$\n边缘概率质量函数 $P(Y=y)$ 可通过将联合概率质量函数对所有可能的 $X$ 值求和得到：\n$$\nP(Y=y) = \\sum_{x'=0}^{\\infty} P(X=x', Y=y)\n$$\n由于联合概率质量函数与 $f(x, y)$ 成正比，我们可以写成 $P(X=x, Y=y) = C \\cdot f(x, y)$，其中 $C$ 是一个不依赖于 $x$ 或 $y$ 的归一化常数。将此代入条件概率公式，我们得到：\n$$\nP(X=x | Y=y) = \\frac{C \\cdot f(x, y)}{\\sum_{x'=0}^{\\infty} C \\cdot f(x', y)} = \\frac{f(x, y)}{\\sum_{x'=0}^{\\infty} f(x', y)}\n$$\n这表明我们可以在不需要计算整体归一化常数 $C$ 的情况下求出条件分布。\n\n首先，我们来推导 $P(X=x | Y=y)$。\n分子是 $f(x, y) = \\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)$。\n分母是在固定 $y$ 的情况下，对所有可能的 $x'$ 值求和：\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\sum_{x'=0}^{\\infty} \\frac{\\alpha^{x'} \\beta^y}{x' ! y!} \\exp(-\\lambda x' y)\n$$\n对于这个求和，$y$ 是一个常数。我们可以将所有不依赖于求和指标 $x'$ 的项提取出来：\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\frac{\\beta^y}{y!} \\sum_{x'=0}^{\\infty} \\frac{\\alpha^{x'}}{x'!} \\exp(-\\lambda x' y) = \\frac{\\beta^y}{y!} \\sum_{x'=0}^{\\infty} \\frac{(\\alpha \\exp(-\\lambda y))^{x'}}{x'!}\n$$\n该求和具有指数函数泰勒级数的形式，即 $\\sum_{k=0}^{\\infty} \\frac{z^k}{k!} = \\exp(z)$。在我们的例子中，$z = \\alpha \\exp(-\\lambda y)$。因此，这个和是：\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\frac{\\beta^y}{y!} \\exp(\\alpha \\exp(-\\lambda y))\n$$\n现在我们可以写出条件概率：\n$$\nP(X=x | Y=y) = \\frac{\\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)}{\\frac{\\beta^y}{y!} \\exp(\\alpha \\exp(-\\lambda y))}\n$$\n$\\frac{\\beta^y}{y!}$ 项相互抵消，剩下：\n$$\nP(X=x | Y=y) = \\frac{\\alpha^x \\exp(-\\lambda x y)}{x! \\exp(\\alpha \\exp(-\\lambda y))} = \\frac{(\\alpha \\exp(-\\lambda y))^x}{x!} \\exp(-\\alpha \\exp(-\\lambda y))\n$$\n这是一个参数为 $\\alpha \\exp(-\\lambda y)$ 的泊松分布的概率质量函数。\n\n接下来，我们来推导 $P(Y=y | X=x)$。其过程是对称的。\n$$\nP(Y=y | X=x) = \\frac{f(x, y)}{\\sum_{y'=0}^{\\infty} f(x, y')}\n$$\n分母是在固定 $x$ 的情况下，对所有可能的 $y'$ 值求和：\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\sum_{y'=0}^{\\infty} \\frac{\\alpha^x \\beta^{y'}}{x! y'!} \\exp(-\\lambda x y')\n$$\n将不依赖于求和指标 $y'$ 的项提取出来：\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\frac{\\alpha^x}{x!} \\sum_{y'=0}^{\\infty} \\frac{\\beta^{y'}}{y'!} \\exp(-\\lambda x y') = \\frac{\\alpha^x}{x!} \\sum_{y'=0}^{\\infty} \\frac{(\\beta \\exp(-\\lambda x))^{y'}}{y'!}\n$$\n再次使用指数函数的泰勒级数，此时 $z = \\beta \\exp(-\\lambda x)$：\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\frac{\\alpha^x}{x!} \\exp(\\beta \\exp(-\\lambda x))\n$$\n现在我们写出条件概率：\n$$\nP(Y=y | X=x) = \\frac{\\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)}{\\frac{\\alpha^x}{x!} \\exp(\\beta \\exp(-\\lambda x))}\n$$\n$\\frac{\\alpha^x}{x!}$ 项相互抵消，剩下：\n$$\nP(Y=y | X=x) = \\frac{\\beta^y \\exp(-\\lambda x y)}{y! \\exp(\\beta \\exp(-\\lambda x))} = \\frac{(\\beta \\exp(-\\lambda x))^y}{y!} \\exp(-\\beta \\exp(-\\lambda x))\n$$\n这是一个参数为 $\\beta \\exp(-\\lambda x)$ 的泊松分布的概率质量函数。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{(\\alpha \\exp(-\\lambda y))^{x}}{x!} \\exp(-\\alpha \\exp(-\\lambda y)) & \\frac{(\\beta \\exp(-\\lambda x))^{y}}{y!} \\exp(-\\beta \\exp(-\\lambda x)) \\end{pmatrix}}\n$$", "id": "1316600"}, {"introduction": "一个 MCMC 抽样器的成功并非必然；它关键性地依赖于算法参数与目标分布形态之间的相互作用。这个问题呈现了一个典型的场景：一个调校不佳的抽样器未能探索一个多峰分布，而被困在单一的高概率区域。通过分析这种情况，你将培养诊断MCMC收敛问题的关键技能，并理解正确配置抽样器的重要性 [@problem_id:1932795]。", "problem": "一位数据科学家正在使用马尔可夫链蒙特卡洛（MCMC）方法，从一个复杂的一维目标概率密度函数 $\\pi(x)$ 中抽取样本。已知该目标分布是一个对称双峰分布，具体来说是两个高斯分布的等权重混合。其密度正比于两个高斯概率密度函数之和：\n$$ \\pi(x) \\propto \\exp\\left(-\\frac{(x - \\mu_A)^2}{2\\sigma_{mode}^2}\\right) + \\exp\\left(-\\frac{(x - \\mu_B)^2}{2\\sigma_{mode}^2}\\right) $$\n给定的参数为 $\\mu_A = -10$，$\\mu_B = 10$ 和 $\\sigma_{mode} = 1$。这种结构导致了两个以 $x=-10$ 和 $x=10$ 为中心的狭窄且分离良好的概率模态，它们之间存在一个概率密度极低的区域。\n\n该科学家使用随机游走 Metropolis 算法。在每一步，从一个以当前状态 $x_t$ 为中心的高斯分布中提议一个新状态 $x'$，即 $x' \\sim N(x_t, \\sigma_{step}^2)$。为了获得高接受率，该科学家选择了一个非常小的步长方差，设定 $\\sigma_{step} = 0.1$。MCMC 链在其中一个模态的峰值处初始化，即 $x_0 = -10$，并运行 $N=10^6$ 次迭代。\n\n下列哪个陈述最准确地描述了该 MCMC 采样器的行为以及所得样本集 $\\{x_1, x_2, \\dots, x_N\\}$ 的统计特性？\n\nA. 样本将分布在目标分布的真实均值 $x=0$ 周围。样本均值将接近 0，但样本方差会很大（大于 100），准确反映了两个模态之间的显著分离。\n\nB. 提议移动的接受率将非常低（接近 0），因为步长没有根据目标分布的整体尺度进行良好调整。链将停留在或非常接近其初始位置 $x_0 = -10$。\n\nC. 提议移动的接受率将非常高（接近 1）。生成的样本将充分探索对应于 $x=-10$ 处模态的区域，但链将无法转换到 $x=10$ 处的另一个模态。样本均值将约为 $-10$。\n\nD. 采样器将高效地探索整个状态空间。链将在两个模态之间频繁地来回跳跃，样本的直方图将正确地形成以 $x=-10$ 和 $x=10$ 为中心的两个不同峰。\n\nE. 采样器将表现得像一个简单的随机游走，导致样本从起始点扩散开。最终的样本集合将近似均匀分布在一个以 $x=-10$ 为中心的宽区间上。", "solution": "我们将目标建模为两个高斯密度的等权重混合，它们具有共同的标准差 $\\sigma_{mode}$ 和均值 $\\mu_{A}$、$\\mu_{B}$。在忽略比例常数的情况下，\n$$\n\\pi(x) \\propto \\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right) + \\exp\\!\\left(-\\frac{(x-\\mu_{B})^{2}}{2\\sigma_{mode}^{2}}\\right).\n$$\n使用一个带有对称高斯提议 $q(x' \\mid x)=\\mathcal{N}(x,\\sigma_{step}^{2})$ 的随机游走 Metropolis 采样器，对于状态 $x_{t}$ 和提议 $x'$，其 Metropolis–Hastings 接受概率为\n$$\n\\alpha(x_{t},x')=\\min\\!\\left(1,\\frac{\\pi(x')}{\\pi(x_{t})}\\right).\n$$\n\n在 $x_{0}=\\mu_{A}$ 处初始化。由于模态是良好分离的，当 $x$ 接近 $\\mu_{A}$ 时，$\\pi(x)$ 中来自 $\\mu_{B}$ 分量的贡献相对于来自 $\\mu_{A}$ 分量的贡献是可以忽略不计的。对于一个小的提议增量 $\\epsilon:=x'-x$ 且满足 $|\\epsilon| \\ll \\sigma_{mode}$，主导比率近似给出\n$$\n\\frac{\\pi(x')}{\\pi(x)} \\approx \\frac{\\exp\\!\\left(-\\frac{(x'+\\!-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right)}{\\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right)}=\\exp\\!\\left(-\\frac{(x'-\\mu_{A})^{2}-(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right).\n$$\n在 $x\\approx\\mu_{A}$ 处，对于小的 $\\epsilon$，这可以简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)} \\approx \\exp\\!\\left(-\\frac{\\epsilon^{2}}{2\\sigma_{mode}^{2}}\\right),\n$$\n因此，当 $\\sigma_{step} \\ll \\sigma_{mode}$ 时，接受概率接近 1，因为典型的 $|\\epsilon|$ 的量级与 $\\sigma_{step}$ 相当。因此，当链在探索起始模态的邻域时，接受率非常高。\n\n在一次提议中，要从 $\\mu_{A}$ 的邻域直接跳跃到 $\\mu_{B}$ 的邻域，需要一个量级为 $|\\mu_{B}-\\mu_{A}|$ 的位移。在方差为 $\\sigma_{step}^{2}$ 的高斯提议下，这种跳跃的概率量级为\n$$\n\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{2\\sigma_{step}^{2}}\\right),\n$$\n当 $|\\mu_{B}-\\mu_{A}| \\gg \\sigma_{step}$ 时，这个概率是可以忽略不计的。\n\n通过许多小的被接受的步来穿过低密度区域，在有限次运行内同样是极不可能的，因为谷底的稳态密度比峰值处呈指数级地小。在中点 $x^{\\star}=(\\mu_{A}+\\mu_{B})/2$ 处，目标密度为\n$$\n\\pi(x^{\\star}) \\propto 2\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{8\\sigma_{mode}^{2}}\\right),\n$$\n而在 $x=\\mu_{A}$ 附近，它是 $\\pi(\\mu_{A}) \\propto 1$（另一分量在那里的贡献可以忽略）。因此，比率\n$$\n\\frac{\\pi(x^{\\star})}{\\pi(\\mu_{A})} \\approx 2\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{8\\sigma_{mode}^{2}}\\right)\n$$\n在 $|\\mu_{B}-\\mu_{A}| \\gg \\sigma_{mode}$ 时是指数级小的。这意味着到达谷底或另一个模态的期望时间是指数级大的，其量级为该比率的倒数，当分离很大且提议非常局部时，这远远超过给定的 $N$。\n\n因此，当选择的 $\\sigma_{step}$ 相对于 $\\sigma_{mode}$ 非常小且模态是良好分离的时，该链具有非常高的接受率，能够充分探索起始模态 $x=\\mu_{A}$ 周围的局部盆地，在运行中基本上永远不会转换到另一个模态，并产生一个约等于 $\\mu_{A}$ 的样本均值。在这些选项中，这对应于陈述 C。", "answer": "$$\\boxed{C}$$", "id": "1932795"}]}