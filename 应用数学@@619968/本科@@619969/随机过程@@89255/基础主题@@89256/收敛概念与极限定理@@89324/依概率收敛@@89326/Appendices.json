{"hands_on_practices": [{"introduction": "这个练习将帮助你巩固依概率收敛的一个基本性质：两个收敛序列之和的极限等于它们极限的和。通过这个例子，你将练习如何结合切比雪夫不等式和依概率收敛的定义，来证明一个新构造的随机变量序列的收敛性。这个问题是理解随机变量极限“代数”性质的一个很好的起点。 [@problem_id:1910723]", "problem": "设 $\\{X_n\\}_{n=1}^{\\infty}$ 和 $\\{Y_n\\}_{n=1}^{\\infty}$ 是两个随机变量序列。已知序列 $\\{X_n\\}$ 依概率收敛于常数 5。序列 $\\{Y_n\\}$ 的特征为，对所有正整数 $n$，其均值为 $E[Y_n] = 0$，方差为 $Var(Y_n) = \\frac{1}{\\sqrt{n}}$。\n\n定义一个新的随机变量序列 $\\{Z_n\\}_{n=1}^{\\infty}$，其形式为 $Z_n = X_n + Y_n$。\n\n求序列 $\\{Z_n\\}$ 依概率收敛到的数值。", "solution": "我们已知 $X_{n} \\xrightarrow{p} 5$，即对于任意 $\\varepsilon>0$，\n$$\n\\lim_{n\\to\\infty} P\\big(|X_{n}-5|>\\varepsilon\\big)=0.\n$$\n对于 $Y_{n}$，我们有 $\\mathbb{E}[Y_{n}]=0$ 且对所有 $n$ 有 $\\operatorname{Var}(Y_{n})=n^{-1/2}$。根据切比雪夫不等式，对任意 $\\varepsilon>0$，\n$$\nP\\big(|Y_{n}|>\\varepsilon\\big)=P\\big(|Y_{n}-\\mathbb{E}[Y_{n}]|>\\varepsilon\\big)\\leq \\frac{\\operatorname{Var}(Y_{n})}{\\varepsilon^{2}}=\\frac{n^{-1/2}}{\\varepsilon^{2}}\\xrightarrow[n\\to\\infty]{}0.\n$$\n因此 $Y_{n}\\xrightarrow{p}0$。\n\n定义 $Z_{n}=X_{n}+Y_{n}$。对任意 $\\varepsilon>0$，根据三角不等式，\n$$\n|Z_{n}-5|=\\big|(X_{n}-5)+Y_{n}\\big|\\leq |X_{n}-5|+|Y_{n}|.\n$$\n因此，使用并集不等式 (union bound)，\n$$\nP\\big(|Z_{n}-5|>\\varepsilon\\big)\\leq P\\big(|X_{n}-5|>\\varepsilon/2\\big)+P\\big(|Y_{n}|>\\varepsilon/2\\big)\\xrightarrow[n\\to\\infty]{}0,\n$$\n因为第一项由 $X_{n}\\xrightarrow{p}5$ 可知其趋于零，第二项由以上所示的切比雪夫不等式可知其趋于零。因此 $Z_{n}\\xrightarrow{p}5$。\n\n所以，$Z_{n}$ 依概率收敛到的数值是 $5$。", "answer": "$$\\boxed{5}$$", "id": "1910723"}, {"introduction": "这个练习将理论与实践联系起来，展示了依概率收敛在统计推断中的一个核心应用：证明估计量的一致性。你将看到弱大数定律和连续映射定理如何协同工作，证明由样本均值的比率构成的估计量会收敛到总体均值的真实比率。这个原理在工程和经济学等领域中对于评估模型参数至关重要。 [@problem_id:1910693]", "problem": "一位工程师正在对一种新型热电发电机进行特性分析。在一系列 $n$ 次独立试验中，每次试验 $i$ 都会测量两个物理量：流经发电机的热流 $X_i$ 和产生的电功率输出 $Y_i$。\n\n测量序列 $\\{X_1, X_2, \\dots, X_n\\}$ 和 $\\{Y_1, Y_2, \\dots, Y_n\\}$ 可以按如下方式建模：\n- 热流测量值 $\\{X_i\\}$ 是独立同分布 (i.i.d.) 的随机变量，其真实平均热流为 $\\mathbb{E}[X_i] = \\mu_{Q}$ 且方差有限。\n- 功率输出测量值 $\\{Y_i\\}$ 是独立同分布 (i.i.d.) 的随机变量，其真实平均功率输出为 $\\mathbb{E}[Y_i] = \\mu_{P}$ 且方差有限。\n- 已知真实平均热流非零，即 $\\mu_{Q} \\neq 0$。\n\n为了估计发电机的转换效率，工程师在 $n$ 次试验后计算了两组测量值的样本均值：\n$$\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\quad \\text{和} \\quad \\bar{Y}_n = \\frac{1}{n} \\sum_{i=1}^{n} Y_i\n$$\n然后，工程师将效率的估计量 $\\eta_n$ 定义为样本平均功率输出与样本平均热流之比：\n$$\n\\eta_n = \\frac{\\bar{Y}_n}{\\bar{X}_n}\n$$\n当试验次数 $n$ 趋于无穷大时，确定随机变量序列 $\\eta_n$ 依概率收敛到的值。请用包含 $\\mu_{Q}$ 和 $\\mu_{P}$ 的解析表达式表示你的答案。", "solution": "根据假设，热流测量值 $\\{X_i\\}$ 是独立同分布的，具有有限方差和均值 $\\mathbb{E}[X_i]=\\mu_{Q}$；功率测量值 $\\{Y_i\\}$ 也是独立同分布的，具有有限方差和均值 $\\mathbb{E}[Y_i]=\\mu_{P}$。定义样本均值\n$$\n\\bar{X}_n=\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\qquad \\bar{Y}_n=\\frac{1}{n}\\sum_{i=1}^{n}Y_i.\n$$\n根据弱大数定律 (WLLN)，有限方差意味着\n$$\n\\bar{X}_n \\xrightarrow{p} \\mu_{Q}\\quad\\text{和}\\quad \\bar{Y}_n \\xrightarrow{p} \\mu_{P}\\quad\\text{当 }n\\to\\infty.\n$$\n由此可得，这对变量联合依概率收敛：对于任何 $\\varepsilon>0$，\n$$\nP\\!\\left(\\left\\|(\\bar{X}_n,\\bar{Y}_n)-(\\mu_{Q},\\mu_{P})\\right\\|>\\varepsilon\\right)\n\\leq P\\!\\left(|\\bar{X}_n-\\mu_{Q}|>\\frac{\\varepsilon}{2}\\right)+P\\!\\left(|\\bar{Y}_n-\\mu_{P}|>\\frac{\\varepsilon}{2}\\right)\\to 0,\n$$\n所以 $(\\bar{X}_n,\\bar{Y}_n)\\xrightarrow{p}(\\mu_{Q},\\mu_{P})$。因为 $\\mu_{Q}\\neq 0$，映射 $g(x,y)=y/x$ 在 $(\\mu_{Q},\\mu_{P})$ 点是连续的。根据连续映射定理，\n$$\n\\eta_n=\\frac{\\bar{Y}_n}{\\bar{X}_n}=g(\\bar{X}_n,\\bar{Y}_n)\\xrightarrow{p} g(\\mu_{Q},\\mu_{P})=\\frac{\\mu_{P}}{\\mu_{Q}}.\n$$\n最后，$\\mu_{Q}\\neq 0$ 这一事实也保证了 $P(|\\bar{X}_n|>\\tfrac{|\\mu_{Q}|}{2})\\to 1$，因此该比值以趋于 1 的概率是良定义的。\n因此，$\\eta_n$ 依概率收敛于 $\\mu_{P}/\\mu_{Q}$。", "answer": "$$\\boxed{\\frac{\\mu_{P}}{\\mu_{Q}}}$$", "id": "1910693"}, {"introduction": "一个直觉上合理的估计量，未必就是一个好的估计量。这个练习作为一个思想实验，提出了一个虽然无偏但却不具备一致性的估计量，这有助于我们辨析统计学中两个重要的概念。通过分析为什么这个估计量会失效，你将更深刻地理解依概率收敛的定义，并认识到为什么“利用更多的数据”是保证估计量收敛到真实参数值的关键。 [@problem_id:1910737]", "problem": "设 $X_1, X_2, \\dots, X_n$ 是一列来自某个总体的独立同分布 (i.i.d.) 随机变量，该总体的均值 $E[X_i] = \\mu$ 有限，方差 $Var(X_i) = \\sigma^2$ 有限且非零。\n\n一位研究者提出了一个总体均值 $\\mu$ 的估计量，定义为 $\\hat{\\mu}_n = X_1$。该估计量仅使用第一个观测值，而与总样本量 $n$ 无关。我们希望分析该估计量的一致性。\n\n当样本量 $n$ 趋于无穷大时，下列哪个陈述正确地描述了估计量 $\\hat{\\mu}_n$ 的收敛性质？\n\nA. $\\hat{\\mu}_n$ 依概率收敛于 $\\mu$，因为它是 $\\mu$ 的一个无偏估计量。\n\nB. $\\hat{\\mu}_n$ 依概率收敛于 $\\mu$，因为大数定律保证了当样本量 $n$ 无限增大时，任何估计量都会收敛。\n\nC. $\\hat{\\mu}_n$ 不依概率收敛于 $\\mu$，因为随着 $n$ 的增加，该估计量与 $\\mu$ 的距离超过某个小数的概率保持为一个固定的正数。\n\nD. $\\hat{\\mu}_n$ 不依概率收敛于 $\\mu$，因为该估计量是有偏的，而有偏估计量永远不可能是一致的。\n\nE. 在不知道 $X_i$ 变量的底层分布是否为正态分布的情况下，无法确定 $\\hat{\\mu}_n$ 是否依概率收敛于 $\\mu$。", "solution": "设 $\\{X_{i}\\}_{i=1}^{n}$ 为独立同分布 (i.i.d.) 的随机变量，满足 $E[X_{i}] = \\mu$ 且 $\\operatorname{Var}(X_{i}) = \\sigma^{2}$，其中 $\\sigma^{2} \\in (0,\\infty)$。所提出的估计量为 $\\hat{\\mu}_{n} = X_{1}$，对所有 $n$ 成立。\n\n根据定义，$\\hat{\\mu}_{n}$ 是 $\\mu$ 的一致估计量，当且仅当对任意 $\\varepsilon > 0$，\n$$\n\\lim_{n \\to \\infty} P\\!\\left(|\\hat{\\mu}_{n} - \\mu| > \\varepsilon\\right) = 0.\n$$\n因为对所有 $n$ 都有 $\\hat{\\mu}_{n} = X_{1}$，所以对于任意 $\\varepsilon > 0$ 和任意 $n$，我们有\n$$\nP\\!\\left(|\\hat{\\mu}_{n} - \\mu| > \\varepsilon\\right) = P\\!\\left(|X_{1} - \\mu| > \\varepsilon\\right) =: p(\\varepsilon),\n$$\n该概率不依赖于 $n$。\n\n我们现在证明，对于至少一个 $\\varepsilon > 0$，$p(\\varepsilon)$ 严格为正。使用反证法，假设对所有 $\\varepsilon > 0$ 都有 $p(\\varepsilon) = 0$。那么对于任意满足 $\\varepsilon_{k} \\downarrow 0$ 的有理数序列 $\\{\\varepsilon_{k}\\}$，\n$$\nP\\!\\left(|X_{1} - \\mu| \\le \\varepsilon_{k}\\right) = 1 \\quad \\text{对所有 } k,\n$$\n因此\n$$\nP\\!\\left(\\bigcap_{k=1}^{\\infty} \\{|X_{1} - \\mu| \\le \\varepsilon_{k}\\}\\right) = 1,\n$$\n这意味着 $P(X_{1} = \\mu) = 1$，因而 $\\operatorname{Var}(X_{1}) = 0$，这与 $\\sigma^{2} > 0$ 矛盾。因此存在 $\\varepsilon_{0} > 0$ 使得\n$$\np(\\varepsilon_{0}) = P\\!\\left(|X_{1} - \\mu| > \\varepsilon_{0}\\right) > 0.\n$$\n所以，\n$$\n\\lim_{n \\to \\infty} P\\!\\left(|\\hat{\\mu}_{n} - \\mu| > \\varepsilon_{0}\\right) = \\lim_{n \\to \\infty} p(\\varepsilon_{0}) = p(\\varepsilon_{0}) > 0,\n$$\n所以一致性条件不成立。因此，$\\hat{\\mu}_{n}$ 不依概率收敛于 $\\mu$。\n\n逐项分析选项：\n- A 是错误的：仅有无偏性并不意味着一致性。\n- B 是错误的：大数定律适用于依赖于 $n$ 的样本均值，而不适用于忽略了 $n$ 的 $X_{1}$。\n- C 是正确的：对于某个小的 $\\varepsilon$，误差概率是一个与 $n$ 无关的固定正常数。\n- D 是错误的：该估计量是无偏的，并且在一般情况下，有偏性并不排除一致性。\n- E 是错误的：正态性是不必要的；该论证仅依赖于 $\\sigma^{2} > 0$。\n\n因此，正确选项是 C。", "answer": "$$\\boxed{C}$$", "id": "1910737"}]}