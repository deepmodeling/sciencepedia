{"hands_on_practices": [{"introduction": "在进行任何蒙特卡洛模拟之前，一个基本问题是需要生成多少条样本路径才能达到预期的精度。此练习将引导您完成一个核心计算，该计算将均方根误差（RMSE）与待估量本身的方差 $V$ 以及所需的样本量 $N$ 联系起来。掌握这种关系是规划计算实验和预估计算成本的基础，确保我们能够以合理的资源获得可靠的结果 [@problem_id:2988319]。", "problem": "考虑一个由 $dX_{t}=\\mu(X_{t},t)\\,dt+\\sigma(X_{t},t)\\,dW_{t}$ 给出的一个维 Itô 随机微分方程 (SDE)，其具有确定性初始条件 $X_{0}=x_{0}$，其中 $\\mu$ 和 $\\sigma$ 满足标准条件，以确保强解的存在性和唯一性以及 $X_{t}$ 的泛函具有有限二阶矩。设 $T>0$ 为一个固定的终端时间，并设 $\\varphi:\\mathbb{R}\\to\\mathbb{R}$ 是一个可测函数，使得 $\\mathbb{E}\\big[|\\varphi(X_{T})|^{2}\\big]<\\infty$。计算任务是通过蒙特卡洛抽样来近似期望 $\\mathbb{E}[\\varphi(X_{T})]$。\n\n假设在一个理想化的设定中，$X_{T}$ 的抽样是精确的（即，忽略任何离散化偏差），并假设可以抽取 $N$ 个独立样本 $Y_{1},\\dots,Y_{N}$，其中 $Y_{i}=\\varphi(X_{T}^{(i)})$，$X_{T}^{(i)}$ 是 $X_{T}$ 的独立副本。设 $V=\\mathrm{Var}(Y_{1})$ 已知且有限，且 $V>0$。对于蒙特卡洛估计量 $\\widehat{m}_{N}=\\frac{1}{N}\\sum_{i=1}^{N}Y_{i}$，施加一个目标均方根误差 (RMSE) 阈值 $\\varepsilon>0$。\n\n从方差、独立性和均方误差的定义出发，在零偏差的假设下，推导为确保 $\\widehat{m}_{N}$ 的均方根误差不超过 $\\varepsilon$ 所需的最小整数样本量 $N$。然后，通过推导连续松弛 $N(V)$ 相对于 $V$ 的一阶敏感性以及在 $V$ 处的相应相对敏感性，来量化所需样本量对方差误估的敏感性。\n\n您的最终答案必须是单个闭式解析表达式或包含您的表达式的单个行矩阵。不需要数值近似。", "solution": "我们从使用蒙特卡洛估计量 $\\widehat{m}_{N}=\\frac{1}{N}\\sum_{i=1}^{N}Y_{i}$ 估计期望 $\\mathbb{E}[\\varphi(X_{T})]$ 的目标开始，其中 $Y_{i}=\\varphi(X_{T}^{(i)})$ 且 $X_{T}^{(i)}$ 是 $X_{T}$ 的独立实现。在所述假设下，样本 $Y_{1},\\dots,Y_{N}$ 是独立同分布的，其方差 $V=\\mathrm{Var}(Y_{1})$ 有限，均值为 $m=\\mathbb{E}[Y_{1}]=\\mathbb{E}[\\varphi(X_{T})]$。\n\n$\\widehat{m}_{N}$ 的均方误差 (MSE) 定义为\n$$\n\\mathrm{MSE}(\\widehat{m}_{N})=\\mathbb{E}\\big[(\\widehat{m}_{N}-m)^{2}\\big].\n$$\n根据偏差-方差分解，\n$$\n\\mathrm{MSE}(\\widehat{m}_{N})=\\big(\\mathbb{E}[\\widehat{m}_{N}]-m\\big)^{2}+\\mathrm{Var}(\\widehat{m}_{N}).\n$$\n在我们的理想化设定中，不存在离散化偏差，且估计量是无偏的，因此 $\\mathbb{E}[\\widehat{m}_{N}]=m$，偏差项为零。所以，\n$$\n\\mathrm{MSE}(\\widehat{m}_{N})=\\mathrm{Var}(\\widehat{m}_{N}).\n$$\n利用独立同分布的性质，样本均值的方差为\n$$\n\\mathrm{Var}(\\widehat{m}_{N})=\\mathrm{Var}\\!\\left(\\frac{1}{N}\\sum_{i=1}^{N}Y_{i}\\right)=\\frac{1}{N^{2}}\\sum_{i=1}^{N}\\mathrm{Var}(Y_{i})=\\frac{1}{N^{2}}\\cdot N\\cdot V=\\frac{V}{N}.\n$$\n均方根误差 (RMSE) 是均方误差 (MSE) 的平方根：\n$$\n\\mathrm{RMSE}(\\widehat{m}_{N})=\\sqrt{\\mathrm{MSE}(\\widehat{m}_{N})}=\\sqrt{\\frac{V}{N}}.\n$$\n施加目标均方根误差阈值 $\\varepsilon>0$ 意味着要求\n$$\n\\sqrt{\\frac{V}{N}}\\leq \\varepsilon.\n$$\n将两边平方并求解 $N$，\n$$\n\\frac{V}{N}\\leq \\varepsilon^{2}\\quad\\Longleftrightarrow\\quad N\\geq \\frac{V}{\\varepsilon^{2}}.\n$$\n因为 $N$ 必须是整数，所以达到该目标的最小整数样本量为\n$$\nN^{\\star}=\\left\\lceil\\frac{V}{\\varepsilon^{2}}\\right\\rceil.\n$$\n\n我们现在分析所需样本量对方差误估的敏感性。考虑连续松弛 $N(V)=\\frac{V}{\\varepsilon^{2}}$（为进行微分分析，忽略上取整函数）。$N$ 相对于 $V$ 的一阶敏感性是其导数\n$$\n\\frac{dN}{dV}=\\frac{d}{dV}\\left(\\frac{V}{\\varepsilon^{2}}\\right)=\\frac{1}{\\varepsilon^{2}}.\n$$\n为了量化相对敏感性，定义对数导数（弹性）\n$$\nS_{\\mathrm{rel}}(V)=\\frac{dN/N}{dV/V}=\\frac{\\frac{dN}{dV}\\cdot \\frac{1}{N}}{\\frac{1}{V}}.\n$$\n代入 $N(V)=\\frac{V}{\\varepsilon^{2}}$ 和 $\\frac{dN}{dV}=\\frac{1}{\\varepsilon^{2}}$，我们得到\n$$\nS_{\\mathrm{rel}}(V)=\\frac{\\left(\\frac{1}{\\varepsilon^{2}}\\right)\\cdot \\left(\\frac{\\varepsilon^{2}}{V}\\right)}{\\frac{1}{V}}=1.\n$$\n因此，一阶近似下，所需（连续）样本量的相对误差等于 $V$ 的相对误差：如果 $V$ 被误估为 $V(1+\\delta)$（其中 $\\delta$ 很小），那么 $N$ 将被误估为 $N(1+\\delta)$，这尚未考虑上取整算子的影响。特别地，对 $V$ 的一定比例的低估会导致对所需 $N$ 的同等比例的低估，这有违反 RMSE 约束 $\\sqrt{V/N}\\leq \\varepsilon$ 的风险；而对 $V$ 的高估会相应地过量提供 $N$，这是一种保守的做法。", "answer": "$$\\boxed{\\begin{pmatrix}\\left\\lceil \\dfrac{V}{\\varepsilon^{2}} \\right\\rceil & \\dfrac{1}{\\varepsilon^{2}} & 1\\end{pmatrix}}$$", "id": "2988319"}, {"introduction": "蒙特卡洛模拟中的误差有两个主要来源：由有限样本量引起的统计误差，以及由SDE数值离散化引入的系统性偏差。本练习将关注后一种被称为“弱偏差”的误差。通过对经典的几何布朗运动（GBM）过程使用欧拉-丸山（Euler-Maruyama）格式，您将分析推导出期望值的离散化偏差，从而将一个重要的理论概念转化为一个具体且可计算的量 [@problem_id:2988356]。", "problem": "设 $\\{X_t\\}_{t \\in [0,T]}$ 是几何布朗运动 (GBM) 随机微分方程 (SDE) 的解\n$$\ndX_t \\;=\\; \\mu\\,X_t\\,dt \\;+\\; \\sigma\\,X_t\\,dW_t, \\qquad X_0 \\;=\\; x \\;>\\; 0,\n$$\n其中 $\\mu \\in \\mathbb{R}$ 和 $\\sigma \\geq 0$ 是常数，$\\{W_t\\}_{t \\geq 0}$ 是标准布朗运动。考虑具有均匀时间步长 $\\Delta t \\;=\\; T/N$（其中 $N \\geq 1$ 为某个整数）的欧拉-丸山 (EM) 时间离散化，该离散化由以下递推关系定义\n$$\nX_{n+1}^{\\Delta t} \\;=\\; X_n^{\\Delta t} \\;+\\; \\mu\\,X_n^{\\Delta t}\\,\\Delta t \\;+\\; \\sigma\\,X_n^{\\Delta t}\\,\\Delta W_n, \\qquad X_0^{\\Delta t} \\;=\\; x,\n$$\n其中 $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$ 是独立同分布的，并且独立于 $X_0^{\\Delta t}$。一个基于 EM 和 $L$ 条独立模拟路径的 $\\mathbb{E}[X_T]$ 的蒙特卡洛估计量是\n$$\n\\widehat{M}_L(\\Delta t) \\;=\\; \\frac{1}{L}\\sum_{\\ell=1}^{L} X_{N}^{\\Delta t,(\\ell)},\n$$\n其中 $X_{N}^{\\Delta t,(\\ell)}$ 表示第 $\\ell$ 条路径在时间 $T$ 的终端 EM 近似值。\n\n仅从 SDE 定义、EM 递推关系以及布朗运动增量的基本性质出发，推导 $\\mathbb{E}[X_{N}^{\\Delta t}]$ 作为 $\\mu$、$\\sigma$、$x$、$T$ 和 $\\Delta t$ 的函数的闭式表达式，然后为精确的 GBM 解推导 $\\mathbb{E}[X_T]$。使用这些结果计算基于 EM 的蒙特卡洛估计量的弱偏差，其定义为\n$$\n\\operatorname{bias}(\\Delta t) \\;=\\; \\mathbb{E}[X_{N}^{\\Delta t}] \\;-\\; \\mathbb{E}[X_T].\n$$\n以 $\\operatorname{bias}(\\Delta t)$ 关于 $\\mu$、$\\sigma$、$x$、$T$ 和 $\\Delta t$ 的单一闭式解析表达式的形式给出最终答案。不需要数值。", "solution": "该问题要求推导欧拉-丸山 (EM) 方法应用于几何布朗运动 (GBM) 过程的弱偏差。弱偏差定义为 $\\operatorname{bias}(\\Delta t) = \\mathbb{E}[X_{N}^{\\Delta t}] - \\mathbb{E}[X_T]$，其中 $X_{N}^{\\Delta t}$ 是时间 $T$ 的数值解，$X_T$ 是精确解。推导将分三步进行：首先，我们计算 EM 近似的期望 $\\mathbb{E}[X_{N}^{\\Delta t}]$；其次，我们计算精确解的期望 $\\mathbb{E}[X_T]$；第三，我们计算它们的差。\n\n首先，我们确定从欧拉-丸山格式得到的数值解的期望。递推关系由下式给出：\n$$\nX_{n+1}^{\\Delta t} \\;=\\; X_n^{\\Delta t} \\;+\\; \\mu\\,X_n^{\\Delta t}\\,\\Delta t \\;+\\; \\sigma\\,X_n^{\\Delta t}\\,\\Delta W_n\n$$\n其中 $n = 0, 1, \\dots, N-1$。我们可以提出因子 $X_n^{\\Delta t}$ 得到：\n$$\nX_{n+1}^{\\Delta t} \\;=\\; X_n^{\\Delta t}\\,(1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n)\n$$\n设 $\\mathcal{F}_{t_n}$ 是由布朗运动直到时间 $t_n = n\\Delta t$ 生成的信息流。$X_n^{\\Delta t}$ 的值在时间 $t_n$ 是已知的，因此它是 $\\mathcal{F}_{t_n}$-可测的。布朗增量 $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ 独立于 $\\mathcal{F}_{t_n}$。我们通过先对 $\\mathcal{F}_{t_n}$ 取条件期望，然后应用全期望定律来计算 $X_{n+1}^{\\Delta t}$ 的期望。\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}] \\;=\\; \\mathbb{E}[X_n^{\\Delta t}(1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n) | \\mathcal{F}_{t_n}]\n$$\n由于 $X_n^{\\Delta t}$ 是 $\\mathcal{F}_{t_n}$-可测的，我们可以在条件期望中将其视为常数：\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}] \\;=\\; X_n^{\\Delta t} \\,\\mathbb{E}[1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n | \\mathcal{F}_{t_n}]\n$$\n由于 $\\Delta W_n$ 独立于 $\\mathcal{F}_{t_n}$ 以及性质 $\\mathbb{E}[\\Delta W_n] = 0$，该表达式简化为：\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}] \\;=\\; X_n^{\\Delta t} \\,(1 + \\mu\\,\\Delta t + \\sigma\\,\\mathbb{E}[\\Delta W_n]) \\;=\\; X_n^{\\Delta t}\\,(1 + \\mu\\,\\Delta t)\n$$\n现在，使用全期望定律 $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y|\\mathcal{F}]]$ 对两边取无条件期望，我们得到：\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t}] \\;=\\; \\mathbb{E}[\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}]] \\;=\\; \\mathbb{E}[X_n^{\\Delta t}\\,(1 + \\mu\\,\\Delta t)] \\;=\\; (1 + \\mu\\,\\Delta t)\\,\\mathbb{E}[X_n^{\\Delta t}]\n$$\n这是一个关于 $\\mathbb{E}[X_n^{\\Delta t}]$ 的递推关系。初始条件是 $\\mathbb{E}[X_0^{\\Delta t}] = \\mathbb{E}[x] = x$。我们可以通过从 $n=0$ 迭代到 $N$ 来解这个递推关系：\n$$\n\\mathbb{E}[X_N^{\\Delta t}] \\;=\\; (1 + \\mu\\,\\Delta t)^N \\mathbb{E}[X_0^{\\Delta t}] \\;=\\; x(1 + \\mu\\,\\Delta t)^N\n$$\n代入 $N = T/\\Delta t$，我们得到 EM 近似期望的闭式表达式：\n$$\n\\mathbb{E}[X_N^{\\Delta t}] \\;=\\; x\\left(1 + \\mu\\,\\Delta t\\right)^{T/\\Delta t}\n$$\n\n其次，我们推导精确解 $X_T$ 的期望。SDE 的微分形式为 $dX_t = \\mu X_t dt + \\sigma X_t dW_t$。其积分形式是：\n$$\nX_T \\;=\\; X_0 + \\int_0^T \\mu\\,X_t\\,dt + \\int_0^T \\sigma\\,X_t\\,dW_t\n$$\n对两边取期望，我们得到：\n$$\n\\mathbb{E}[X_T] \\;=\\; \\mathbb{E}[X_0] + \\mathbb{E}\\left[\\int_0^T \\mu\\,X_t\\,dt\\right] + \\mathbb{E}\\left[\\int_0^T \\sigma\\,X_t\\,dW_t\\right]\n$$\n我们计算右侧的每一项。初始条件给出 $\\mathbb{E}[X_0] = x$。对于漂移项，根据 Fubini 定理，我们可以交换期望和黎曼积分：\n$$\n\\mathbb{E}\\left[\\int_0^T \\mu\\,X_t\\,dt\\right] \\;=\\; \\mu \\int_0^T \\mathbb{E}[X_t]\\,dt\n$$\n对于扩散项，Itô 积分的一个基本性质是其期望为零，前提是被积函数是一个满足特定可积条件的适应过程，这对于 GBM SDE 的解是成立的。因此：\n$$\n\\mathbb{E}\\left[\\int_0^T \\sigma\\,X_t\\,dW_t\\right] \\;=\\; 0\n$$\n将这些代回，并令 $m(t) = \\mathbb{E}[X_t]$，我们得到一个关于 $m(T)$ 的积分方程：\n$$\nm(T) \\;=\\; x + \\mu \\int_0^T m(t)\\,dt\n$$\n对 $T$ 求导，得到常微分方程 (ODE)：\n$$\n\\frac{dm(T)}{dT} \\;=\\; \\mu\\,m(T)\n$$\n初始条件为 $m(0) = \\mathbb{E}[X_0] = x$。该 ODE 的解是：\n$$\nm(T) \\;=\\; x\\,\\exp(\\mu T)\n$$\n因此，精确解的期望是：\n$$\n\\mathbb{E}[X_T] \\;=\\; x\\,\\exp(\\mu T)\n$$\n注意，数值解和精确解的期望都与波动率参数 $\\sigma$ 无关。\n\n最后，我们通过计算上面推导的两个期望之差来计算弱偏差：\n$$\n\\operatorname{bias}(\\Delta t) \\;=\\; \\mathbb{E}[X_{N}^{\\Delta t}] - \\mathbb{E}[X_T] \\;=\\; x\\left(1 + \\mu\\,\\Delta t\\right)^{T/\\Delta t} - x\\,\\exp(\\mu T)\n$$\n该表达式可以因式分解以得到最终形式：\n$$\n\\operatorname{bias}(\\Delta t) \\;=\\; x\\left(\\left(1 + \\mu\\,\\Delta t\\right)^{T/\\Delta t} - \\exp(\\mu T)\\right)\n$$\n这是弱偏差作为指定参数的函数的闭式表达式。", "answer": "$$\n\\boxed{x\\left(\\left(1 + \\mu\\Delta t\\right)^{\\frac{T}{\\Delta t}} - \\exp(\\mu T)\\right)}\n$$", "id": "2988356"}, {"introduction": "本练习将理论与实践相结合，引导您探索一种前沿的方差缩减技术——多层蒙特卡洛（MLMC）方法的核心思想。为了高效地平衡统计误差与离散化误差，MLMC巧妙地在不同时间步长上耦合了模拟路径。通过亲手实现精细路径与粗糙路径之间的耦合，并数值验证修正项方差的关键缩放性质，您将深刻理解为何MLMC能够大幅提升计算效率 [@problem_id:2988362]。", "problem": "考虑随机微分方程 (SDE) $dX_t = a X_t \\, dt + \\sigma \\, dW_t$，初始条件为 $X_0 = x_0$，其中 $W_t$ 是标准布朗运动，且 $a,\\sigma,x_0 \\in \\mathbb{R}$。令 $\\phi:\\mathbb{R}\\to\\mathbb{R}$ 为函数 $\\phi(x) = \\sin(x)$，该函数是全局 Lipschitz 的，Lipschitz 常数 $L = 1$。我们关注欧拉-丸山 (EM) 方法以及由精细和粗糙时间离散化的显式耦合构建的多层蒙特卡洛 (MLMC) 层级差的方差缩放。该框架纯属数学性质，不涉及物理单位；所有量纲均为无量纲。\n\n基本依据和定义：\n- 随机微分方程 (SDE) 是一种由随机过程驱动的微分方程，此处为 $dX_t = a X_t \\, dt + \\sigma \\, dW_t$，其中 $W_t$ 是一个布朗运动，其特征是具有独立的高斯增量，即 $W_{t+\\Delta t} - W_t \\sim \\mathcal{N}(0,\\Delta t)$ 且独立于过去。\n- 对于时间步长 $h>0$，欧拉-丸山 (EM) 方法通过递归式 $X_{n+1}^{(h)} = X_n^{(h)} + a X_n^{(h)} h + \\sigma \\Delta W_n^{(h)}$ 来近似 SDE，其中 $\\Delta W_n^{(h)} \\sim \\mathcal{N}(0,h)$ 是独立增量。\n- 多层蒙特卡洛 (MLMC) 方法通过结合多个离散化层级和一种最小化层级差异方差的耦合来估计期望值；这里，我们考虑一个双层差异 $Y = \\phi(X_T^{(h)}) - \\phi(X_T^{(H)})$，其中 $H = 2h$。\n\n耦合指令：\n通过聚合高斯增量，构建一个时间步长为 $h$ 的精细层级与时间步长为 $H = 2h$ 的粗糙层级之间的显式耦合。具体来说，对于每个粗糙区间 $[(t_{2m}), (t_{2m+2})]$，将粗糙增量定义为 $\\Delta W_m^{(H)} := \\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)}$。验证这保留了高斯定律，即 $\\Delta W_m^{(H)} \\sim \\mathcal{N}(0, H)$，并且该耦合利用共同的随机性来减小 $Y$ 的方差。\n\n方差缩放分析目标：\n从布朗运动的基本性质和 EM 递归式出发，分析上述线性 SDE 和 Lipschitz 支付函数 $\\phi$ 的 $\\operatorname{Var}(Y)$ 作为 $h$ 的函数的缩放行为。分析必须从定义出发，并使用经过充分检验的事实，例如布朗运动的独立增量性质和线性系统上 EM 方法的标准稳定性界。不要使用任何捷径或预先声明的缩放公式；从适用于此背景的第一性原理推导方差阶数。\n\n算法构建要求：\n实现一个完整的程序，该程序\n- 通过对精细增量求和以形成粗糙增量来强制执行显式耦合。\n- 使用 $N=20000$ 条独立的耦合路径和一个固定的随机种子 $42$ 来计算蒙特卡洛估计量。\n- 对每个测试用例，计算经验方差 $\\operatorname{Var}(Y)$（使用无偏样本方差）和选定的归一化量以研究缩放行为。\n\n测试套件规范：\n使用以下科学上合理的参数集来测试不同方面（理想路径、边界条件和边界情况）：\n\n1. 理想路径缩放测试：\n   - 参数：$a = -1$, $\\sigma = 0.7$, $x_0 = 0.5$, $T = 1$。\n   - 精细步长：$h \\in \\{1/64, 1/128, 1/256\\}$，粗糙步长 $H = 2h$。\n   - 对每个 $h$，计算 $V(h) = \\operatorname{Var}(Y)$ 和缩放量 $S(h) = V(h)/h$。\n\n2. 缩放比例检查：\n   - 参数与理想路径相同。\n   - 计算 $R = V(1/128)/V(1/64)$ 和布尔值 $B$，表示 $|R - 1/2| \\leq 0.1$ 是否成立。\n\n3. 无漂移边界：\n   - 参数：$a = 0$, $\\sigma = 0.7$, $x_0 = 0.5$, $T = 1$, $h = 1/64$, $H = 2h$。\n   - 计算 $V_{\\text{driftless}} = \\operatorname{Var}(Y)$。\n\n4. 确定性边界：\n   - 参数：$a = -1$, $\\sigma = 0$, $x_0 = 0.5$, $T = 1$, $h = 1/64$, $H = 2h$。\n   - 计算 $V_{\\text{det}} = \\operatorname{Var}(Y)$。\n\n5. 短时边界情况：\n   - 参数：$a = -1$, $\\sigma = 0.7$, $x_0 = 0.5$, $T = 1/8$, $h = 1/256$, $H = 2h$。\n   - 计算 $S_{\\text{short}} = V(h)/h$。\n\n最终输出格式要求：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，顺序完全如下：\n$[S(1/64), S(1/128), S(1/256), R, B, V_{\\text{driftless}}, V_{\\text{det}}, S_{\\text{short}}]$。\n所有输出必须是数值浮点数或布尔值。不应打印任何其他文本。", "solution": "该问题是有效的，因为它在科学上是合理的、适定的和完整的。它提出了一个关于随机微分方程数值分析的标准但实质性的练习。问题的核心是从第一性原理推导多层蒙特卡洛 (MLMC) 层级差的方差缩放，然后通过数值模拟来验证这一点。\n\n我们得到线性随机微分方程 (SDE)，也称为 Ornstein-Uhlenbeck 过程，\n$$dX_t = a X_t \\, dt + \\sigma \\, dW_t, \\quad X_0 = x_0$$\n其中 $W_t$ 是一个标准布朗运动。我们感兴趣的是 $\\phi(X_T) = \\sin(X_T)$ 的期望值。这将使用欧拉-丸山 (EM) 方法进行估计。\n\n时间步长为 $h$ 的 EM 离散化由以下递推关系给出：\n$$X_{n+1}^{(h)} = X_n^{(h)} (1 + ah) + \\sigma \\Delta W_n^{(h)}$$\n其中 $\\Delta W_n^{(h)} \\sim \\mathcal{N}(0,h)$ 是独立的随机增量。\n\n目标是分析精细近似和粗糙近似之间差异的方差，$Y = \\phi(X_T^{(h)}) - \\phi(X_T^{(H)})$，其中粗糙时间步长为 $H = 2h$。这两种近似通过构建粗糙布朗增量与精细布朗增量来耦合。具体来说，在一个长度为 $H$ 的粗糙时间区间内，粗糙增量 $\\Delta W_m^{(H)}$ 是两个相应精细增量 $\\Delta W_{2m}^{(h)}$ 和 $\\Delta W_{2m+1}^{(h)}$ 的和：\n$$\\Delta W_m^{(H)} = \\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)}$$\n由于精细增量是独立同分布的 $\\mathcal{N}(0,h)$，它们的和是一个高斯随机变量，其均值为 $0+0=0$，方差为 $h+h=2h=H$。因此，$\\Delta W_m^{(H)} \\sim \\mathcal{N}(0,H)$，正确地保留了粗糙路径的统计特性。\n\n我们用 $\\hat{X}_k = X_{t_k}^{(h)}$ 表示在精细时间步 $t_k = kh$ 处的精细路径，用 $X_m = X_{t'_m}^{(H)}$ 表示在粗糙时间步 $t'_m = mH$ 处的粗糙路径。注意 $t'_{m} = t_{2m}$。我们在粗糙网格点上分析路径之间的差异 $e_m = \\hat{X}_{2m} - X_m$ 的演变。初始差异为 $e_0 = \\hat{X}_0 - X_0 = x_0 - x_0 = 0$。\n\n粗糙路径从 $t'_m$ 到 $t'_{m+1}$ 演变一步：\n$$X_{m+1} = X_m (1+aH) + \\sigma \\Delta W_m^{(H)} = X_m (1+2ah) + \\sigma (\\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)})$$\n\n精细路径从 $t_{2m}$ 到 $t_{2m+2}$ 演变两步：\n$$\\hat{X}_{2m+1} = \\hat{X}_{2m} (1+ah) + \\sigma \\Delta W_{2m}^{(h)}$$\n$$\\hat{X}_{2m+2} = \\hat{X}_{2m+1} (1+ah) + \\sigma \\Delta W_{2m+1}^{(h)} = \\left(\\hat{X}_{2m} (1+ah) + \\sigma \\Delta W_{2m}^{(h)}\\right)(1+ah) + \\sigma \\Delta W_{2m+1}^{(h)}$$\n$$\\hat{X}_{2m+2} = \\hat{X}_{2m} (1+ah)^2 + \\sigma(1+ah)\\Delta W_{2m}^{(h)} + \\sigma \\Delta W_{2m+1}^{(h)}$$\n$$\\hat{X}_{2m+2} = \\hat{X}_{2m} (1+2ah+a^2h^2) + \\sigma(1+ah)\\Delta W_{2m}^{(h)} + \\sigma \\Delta W_{2m+1}^{(h)}$$\n\n差异 $e_{m+1} = \\hat{X}_{2m+2} - X_{m+1}$ 为：\n$$e_{m+1} = \\left[ \\hat{X}_{2m} (1+2ah+a^2h^2) + \\sigma(1+ah)\\Delta W_{2m}^{(h)} + \\sigma \\Delta W_{2m+1}^{(h)} \\right] - \\left[ X_m(1+2ah) + \\sigma (\\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)}) \\right]$$\n代入 $\\hat{X}_{2m} = X_m + e_m$ 并化简：\n$$e_{m+1} = (X_m+e_m)(1+2ah+a^2h^2) - X_m(1+2ah) + \\sigma(1+ah-1)\\Delta W_{2m}^{(h)}$$\n$$e_{m+1} = X_m(a^2h^2) + e_m(1+2ah+a^2h^2) + \\sigma a h \\Delta W_{2m}^{(h)}$$\n由于 $H=2h$，我们可以将其写为 $e_{m+1} = e_m(1+aH+O(h^2)) + \\left( X_m a^2h^2 + \\sigma a h \\Delta W_{2m}^{(h)} \\right)$。\n\n括号中的项是在步骤 $m$ 引入的局部误差。它有一个 $O(h^2)$ 阶的确定性部分和一个 $h \\times (\\text{方差为 } h \\text{ 的高斯变量})$（即大小为 $O(h^{3/2})$）的随机部分。该局部误差的均方由随机项主导：\n$$\\mathbb{E}\\left[ \\left( \\sigma a h \\Delta W_{2m}^{(h)} \\right)^2 \\bigg| \\mathcal{F}_{t_{2m}} \\right] = \\sigma^2 a^2 h^2 \\mathbb{E}\\left[ (\\Delta W_{2m}^{(h)})^2 \\right] = \\sigma^2 a^2 h^2 \\cdot h = \\sigma^2 a^2 h^3$$\n粗糙步数是 $M_c = T/H = T/(2h) = O(h^{-1})$。最终的均方误差 $\\mathbb{E}[e_{M_c}^2] = \\mathbb{E}[(X_T^{(h)} - X_T^{(H)})^2]$ 是这些局部均方误差在所有粗糙步骤上累积的总和。一个离散的 Gronwall 论证表明，这将导致一个 $O(h^{-1}) \\times O(h^3) = O(h^2)$ 阶的全局均方误差。这种高阶收敛性，即 $\\mathbb{E}[(X_T^{(h)} - X_T^{(H)})^2] = O(h^2)$，是具有可加或可交换噪声的 SDE 的一个特殊特征，对于这类 SDE，欧拉-丸山格式的强收敛阶为 $\\beta=1$。\n\n现在我们考虑 $Y = \\phi(X_T^{(h)}) - \\phi(X_T^{(H)})$ 的方差。支付函数 $\\phi(x) = \\sin(x)$ 是无限可微的 ($C^\\infty$)，其导数有界。因此，我们可以对差异 $E_T = X_T^{(h)} - X_T^{(H)}$ 进行泰勒展开：\n$$Y = \\phi(X_T^{(H)} + E_T) - \\phi(X_T^{(H)}) \\approx \\phi'(X_T^{(H)}) E_T$$\n然后方差为 $\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$。\n平方差为 $Y^2 \\approx (\\phi'(X_T^{(H)}))^2 E_T^2$。取期望，并假设支付函数的导数与误差项近似独立，我们得到：\n$$\\mathbb{E}[Y^2] \\approx \\mathbb{E}[(\\phi'(X_T^{(H)}))^2] \\mathbb{E}[E_T^2]$$\n由于 $\\mathbb{E}[E_T^2] = O(h^2)$，我们有 $\\mathbb{E}[Y^2] = O(h^2)$。EM 格式的弱误差阶为 $O(h)$，所以 $\\mathbb{E}[Y] = O(h)$ 且 $(\\mathbb{E}[Y])^2 = O(h^2)$。\n因此，$\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2 = O(h^2) - O(h^2) = O(h^2)$。\n\n这个理论结果，即 $\\operatorname{Var}(Y)$ 与 $h^2$ 成比例缩放，是一个关键发现。它意味着缩放量 $S(h) = \\operatorname{Var}(Y)/h$ 应该与 $O(h)$ 成比例。它还意味着对于步长 $h$ 和 $h/2$ 的方差比应为：\n$$R = \\frac{\\operatorname{Var}(Y \\text{ for } h/2)}{\\operatorname{Var}(Y \\text{ for } h)} \\approx \\frac{C (h/2)^2}{C h^2} = \\frac{1}{4}$$\n问题要求计算 $B = \\text{bool}(|R - 1/2| \\leq 0.1)$。根据我们的分析，我们预计 $R \\approx 0.25$，因此 $|0.25 - 0.5| = 0.25$，这不小于或等于 $0.1$。我们预测 $B$ 将是 `False`。\n\n对于边界情况：\n- 如果 $a=0$（无漂移），SDE 为 $dX_t = \\sigma dW_t$。EM 格式变为 $X_{n+1} = X_n + \\sigma \\Delta W_n$。对于指定的耦合，精细和粗糙路径在粗糙时间点上是相同的，即对于每条路径都有 $X_T^{(h)} = X_T^{(H)}$。因此，对于所有路径 $Y=0$，且 $\\operatorname{Var}(Y) = 0$。\n- 如果 $\\sigma=0$（确定性），SDE 是 ODE $dX_t = a X_t dt$。数值解 $X_T^{(h)}$ 和 $X_T^{(H)}$ 是确定但不相等的值。差异 $Y$ 是一个常数，而常数的样本方差为零。因此，$\\operatorname{Var}(Y) = 0$。\n\n实现将通过蒙特卡洛模拟计算这些量，并遵循指定的参数。", "answer": "```python\nimport numpy as np\n\ndef simulate_one_coupled_path(params, T, h, rng):\n    \"\"\"\n    Simulates one pair of coupled paths (fine and coarse) for the SDE.\n    dX_t = a * X_t * dt + sigma * dW_t\n\n    Args:\n        params (tuple): (a, sigma, x0)\n        T (float): Final time.\n        h (float): Fine time step.\n        rng (numpy.random.Generator): Random number generator.\n\n    Returns:\n        tuple: (x_fine, x_coarse) final values of the paths.\n    \"\"\"\n    a, sigma, x0 = params\n    H = 2 * h\n    \n    # Ensure T/h is an even integer for proper coupling.\n    # This is guaranteed by the problem statement for the given test cases.\n    num_fine_steps = int(round(T / h))\n    num_coarse_steps = num_fine_steps // 2\n\n    x_fine = float(x0)\n    x_coarse = float(x0)\n\n    sqrt_h = np.sqrt(h)\n\n    for _ in range(num_coarse_steps):\n        # Generate two fine-scale Brownian increments\n        dw1 = rng.normal(0.0, sqrt_h)\n        dw2 = rng.normal(0.0, sqrt_h)\n        \n        # Store current coarse path value for its update\n        x_coarse_prev = x_coarse\n\n        # Update fine path twice\n        x_fine = x_fine * (1 + a * h) + sigma * dw1\n        x_fine = x_fine * (1 + a * h) + sigma * dw2\n\n        # Update coarse path once using the coupled increment\n        dw_coarse = dw1 + dw2\n        x_coarse = x_coarse_prev * (1 + a * H) + sigma * dw_coarse\n\n    return x_fine, x_coarse\n\ndef compute_variance_of_difference(params, T, h, N, rng):\n    \"\"\"\n    Computes the sample variance of phi(X_T^h) - phi(X_T^H).\n    \"\"\"\n    payoff_diffs = np.zeros(N)\n    \n    for i in range(N):\n        x_fine_T, x_coarse_T = simulate_one_coupled_path(params, T, h, rng)\n        payoff_diffs[i] = np.sin(x_fine_T) - np.sin(x_coarse_T)\n        \n    # Use unbiased sample variance (ddof=1)\n    variance = np.var(payoff_diffs, ddof=1)\n    return variance\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    N = 20000\n    SEED = 42\n    rng = np.random.default_rng(seed=SEED)\n\n    results = []\n\n    # --- Test Case 1: Happy path scaling test ---\n    params_happy = (-1.0, 0.7, 0.5)\n    T_happy = 1.0\n    h_values = [1/64, 1/128, 1/256]\n    \n    variances = []\n    for h in h_values:\n        V = compute_variance_of_difference(params_happy, T_happy, h, N, rng)\n        variances.append(V)\n        S = V / h\n        results.append(S)\n\n    # --- Test Case 2: Ratio check for scaling ---\n    v_64, v_128 = variances[0], variances[1]\n    R = v_128 / v_64 if v_64 != 0 else np.nan\n    B = np.abs(R - 0.5) <= 0.1\n    results.append(R)\n    results.append(B)\n\n    # --- Test Case 3: Driftless boundary ---\n    params_driftless = (0.0, 0.7, 0.5)\n    T_driftless = 1.0\n    h_driftless = 1/64\n    V_driftless = compute_variance_of_difference(params_driftless, T_driftless, h_driftless, N, rng)\n    results.append(V_driftless)\n\n    # --- Test Case 4: Deterministic boundary ---\n    params_det = (-1.0, 0.0, 0.5)\n    T_det = 1.0\n    h_det = 1/64\n    V_det = compute_variance_of_difference(params_det, T_det, h_det, N, rng)\n    results.append(V_det)\n\n    # --- Test Case 5: Short-time edge case ---\n    params_short = (-1.0, 0.7, 0.5)\n    T_short = 1/8\n    h_short = 1/256\n    V_short = compute_variance_of_difference(params_short, T_short, h_short, N, rng)\n    S_short = V_short / h_short\n    results.append(S_short)\n    \n    # Format and print the final output\n    # Ensure boolean is lowercase 'true'/'false' as per Python's str()\n    formatted_results = [f\"{r}\".lower() if isinstance(r, bool) else f\"{r}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "2988362"}]}