{"hands_on_practices": [{"introduction": "在随机变量的收敛理论中，几乎必然收敛（almost sure convergence）和依概率收敛（convergence in probability）是两个核心且关系紧密的概念。虽然几乎必然收敛可以推导出依概率收敛，但反之并不成立。这个练习提供了一个经典的范例，通过一个模拟带有时间相关故障的监测系统的简单场景，清晰地揭示了这两个概念之间的关键差异[@problem_id:1319227]。掌握这一区别对于理解随机过程的长期路径行为至关重要。", "problem": "一个数字监控系统被设计用于追踪一个稳定的环境参数，其真实的恒定值被归一化为 0。该系统在每个离散时间步 $n = 1, 2, 3, \\ldots$ 进行一次测量。我们将系统在时间 $n$ 记录的值记为随机变量 $X_n$。\n\n由于一个奇特的时间相关故障，该系统有很小的几率报告一个错误的值。具体来说，对于每个时间步 $n$，系统以 $1 - \\frac{1}{n}$ 的概率报告正确值 $X_n = 0$，并以 $\\frac{1}{n}$ 的概率报告错误值 $X_n = 1$。不同时间步的测量结果是相互独立的事件。\n\n为方便参考，我们定义随机变量序列 $\\{Y_n\\}$ 收敛于常数 $c$ 的两种模式：\n1.  **依概率收敛**：对于任意正数 $\\epsilon > 0$，当 $n$ 趋于无穷大时，概率 $P(|Y_n - c| \\ge \\epsilon)$ 趋近于 0。\n2.  **几乎必然收敛**：数值结果序列 $Y_n$ 当 $n$ 趋于无穷大时收敛于 $c$ 的概率等于 1。形式上地，$P(\\lim_{n \\to \\infty} Y_n = c) = 1$。\n\n现在，考虑以下关于测量序列 $\\{X_n\\}$ 及其向真值 0 收敛的两个陈述：\n\n陈述 I：序列 $\\{X_n\\}$ 依概率收敛于 0。\n陈述 II：序列 $\\{X_n\\}$ 几乎必然收敛于 0。\n\n以下哪个选项正确地描述了这两个陈述的真伪性？\n\nA. 陈述 I 和陈述 II 都为真。\n\nB. 陈述 I 为真，但陈述 II 为假。\n\nC. 陈述 I 为假，但陈述 II 为真。\n\nD. 陈述 I 和陈述 II 都为假。", "solution": "对于每个 $n \\in \\mathbb{N}$，$X_{n}$ 在 $\\{0,1\\}$ 中取值，满足 $P(X_{n}=1)=\\frac{1}{n}$ 和 $P(X_{n}=0)=1-\\frac{1}{n}$，且随机变量之间相互独立。\n\n为了检验是否依概率收敛于 $0$，我们固定 $\\epsilon>0$ 并计算\n$$\nP(|X_{n}-0|\\ge \\epsilon)=\n\\begin{cases}\nP(X_{n}=1)=\\frac{1}{n}, & \\text{if } 0<\\epsilon\\le 1,\\\\\n0, & \\text{if } \\epsilon>1.\n\\end{cases}\n$$\n在这两种情况下，$\\lim_{n\\to\\infty}P(|X_{n}-0|\\ge \\epsilon)=0$，因为 $\\frac{1}{n}\\to 0$。因此 $X_{n}$ 依概率收敛于 $0$。所以，陈述 I 为真。\n\n为了检验是否几乎必然收敛，我们定义事件 $E_{n}=\\{X_{n}=1\\}$。那么 $P(E_{n})=\\frac{1}{n}$，并且这些事件是独立的。我们有\n$$\n\\sum_{n=1}^{\\infty}P(E_{n})=\\sum_{n=1}^{\\infty}\\frac{1}{n}=+\\infty.\n$$\n根据第二 Borel–Cantelli 引理（该引理因事件的独立性而适用），\n$$\nP(E_{n}\\ \\text{i.o.})=1,\n$$\n即，事件 $X_{n}=1$ 会发生无限多次的概率为 1。因此，该序列不会最终停留在例如 0 附近的区间 $(-\\tfrac{1}{2},\\tfrac{1}{2})$ 之内的概率为 1。因此 $X_{n}$ 不几乎必然收敛于 0。所以，陈述 II 为假。\n\n正确选项是 B。", "answer": "$$\\boxed{B}$$", "id": "1319227"}, {"introduction": "接下来，我们将探讨依概率收敛与更弱的收敛形式——依分布收敛（convergence in distribution）之间的关系。依概率收敛比依分布收敛更强，意味着前者可以推导出后者。本练习构建了一个巧妙的“振荡”序列，其中每个随机变量的分布都完全相同，因此序列自然依分布收敛，但它却无法依概率收敛到一个确定的极限[@problem_id:1936888]。这个例子有助于巩固这样的理解：依分布收敛只关心随机变量概率分布“形状”的趋同，而并不保证随机变量序列本身会“稳定”下来。", "problem": "设 $X$ 为一个随机变量，服从区间 $(0, 1)$ 上的连续均匀分布，记作 $X \\sim U(0,1)$。考虑如下定义的随机变量序列 $\\{X_n\\}_{n=1}^{\\infty}$：\n- 若 $n$ 为奇正整数，则 $X_n = X$。\n- 若 $n$ 为偶正整数，则 $X_n = 1 - X$。\n\n为便于参考，我们回顾随机变量序列 $\\{Y_n\\}$ 和随机变量 $Y$ 的两种基本收敛模式的定义：\n1.  **依分布收敛**：若 $Y_n$ 的累积分布函数（CDF）的极限在 $Y$ 的累积分布函数的所有连续点上都等于 $Y$ 的累积分布函数，则称序列 $\\{Y_n\\}$ 依分布收敛于 $Y$，记作 $Y_n \\xrightarrow{d} Y$。即 $\\lim_{n \\to \\infty} F_{Y_n}(y) = F_Y(y)$。\n2.  **依概率收敛**：若对任意实数 $\\epsilon > 0$，$Y_n$ 与 $Y$ 的绝对差大于 $\\epsilon$ 的概率趋于零，则称序列 $\\{Y_n\\}$ 依概率收敛于 $Y$，记作 $Y_n \\xrightarrow{p} Y$。即 $\\lim_{n \\to \\infty} P(|Y_n - Y| > \\epsilon) = 0$。\n\n根据这些定义，下列关于序列 $\\{X_n\\}$ 的陈述哪一个是正确的？\n\nA. 序列 $\\{X_n\\}$ 依分布收敛，且依概率收敛。\n\nB. 序列 $\\{X_n\\}$ 依分布收敛，但不依概率收敛。\n\nC. 序列 $\\{X_n\\}$ 不依分布收敛，但依概率收敛。\n\nD. 序列 $\\{X_n\\}$ 既不依分布收敛，也不依概率收敛。\n\nE. 序列 $\\{X_n\\}$ 依概率收敛于常数 $c = 1/2$。", "solution": "根据构造，$X \\sim U(0,1)$。定义当 $n$ 为奇数时 $X_{n}=X$，当 $n$ 为偶数时 $X_{n}=1-X$。\n\n首先，我们分析依分布收敛。当 $n$ 为奇数时，$X_{n}=X$，因此对所有 $t$ 都有 $F_{X_{n}}(t)=F_{X}(t)$。当 $n$ 为偶数时，计算 $1-X$ 的累积分布函数：对于 $t<0$，$P(1-X \\le t)=0$；对于 $0 \\le t \\le 1$，\n$$\nP(1-X \\le t)=P(X \\ge 1-t)=1-P(X<1-t)=1-(1-t)=t,\n$$\n并且对于 $t>1$，$P(1-X \\le t)=1$。因此 $1-X \\sim U(0,1)$，故对所有 $t$ 和所有 $n$ 都有 $F_{X_{n}}(t)=F_{X}(t)$。因此，$F_{X_{n}}(t)$ 对 $n$ 是常数且等于 $F_{X}(t)$，所以 $X_{n} \\xrightarrow{d} X \\sim U(0,1)$。\n\n接下来，我们分析依概率收敛。用反证法，假设存在一个随机变量 $Y$ 使得 $X_{n} \\xrightarrow{p} Y$。那么它的每个子序列都必须依概率收敛到同一个 $Y$。考虑奇数子序列 $X_{2k-1}=X$（对所有 $k$）。根据依概率收敛的定义，\n$$\n\\lim_{k \\to \\infty} P(|X_{2k-1}-Y|>\\epsilon)=0 \\quad \\text{for all } \\epsilon>0.\n$$\n但左边一项对于 $k$ 是常数，因此这意味着对所有 $\\epsilon>0$ 都有 $P(|X-Y|>\\epsilon)=0$，故 $X=Y$ 几乎必然成立。现在考虑偶数子序列 $X_{2k}=1-X$；同样的推理可得 $1-X=Y$ 几乎必然成立。两者结合，我们得到 $X=1-X$ 几乎必然成立，因此 $X=\\frac{1}{2}$ 几乎必然成立，这与 $X \\sim U(0,1)$ 相矛盾。因此，$X_{n}$ 不依概率收敛于任何随机变量。\n\n为排除 $X_{n} \\xrightarrow{p} \\frac{1}{2}$ 这一特定断言，注意对任意 $\\epsilon \\in \\left(0,\\frac{1}{2}\\right)$ 和任意 $n$，\n$$\nP\\left(\\left|X_{n}-\\frac{1}{2}\\right|>\\epsilon\\right)\n= P\\left(\\left|X-\\frac{1}{2}\\right|>\\epsilon\\right)\n= 1-2\\epsilon,\n$$\n当 $n \\to \\infty$ 时，此式不趋近于 $0$。\n\n因此，序列 $\\{X_{n}\\}$ 依分布收敛（收敛于 $U(0,1)$），但不依概率收敛。这对应于选项 B。", "answer": "$$\\boxed{B}$$", "id": "1936888"}, {"introduction": "最后，我们通过一个与随机微分方程（SDE）数值方法相关的高级练习，来深入探讨弱收敛（weak convergence）与强收敛（strong convergence）的差异。强收敛通常指 $L^p$ 范数下的收敛，而弱收敛则与依分布收敛密切相关。这个问题构建了一个会罕见地产生灾难性巨大误差的数值格式模型，生动地展示了这类异常值如何破坏强收敛性（例如在 $L^1$ 范数下），却能保持对于有界测试函数的弱收敛性[@problem_id:2987750]。这个案例研究对于研究生来说尤为深刻，因为它揭示了在分析SDE数值近似的稳定性和准确性时，不同收敛模式的实际意义。", "problem": "设 $(\\Omega,\\mathcal{F},\\mathbb{P})$ 是一个概率空间，且 $X$ 是一个标准正态随机变量，它被解释为伊藤（Itô）随机微分方程 $dX_{t} = dW_{t}$（初值为 $X_{0}=0$）在时间 $t=1$ 时的精确值。对于每个整数 $n \\geq 1$，通过引入一个稀有但超线性大偏差事件来定义一个近似 $Y_{n}$，具体如下：设 $B_{n}$ 是一个伯努利（Bernoulli）随机变量，满足 $\\mathbb{P}(B_{n}=1)=\\frac{1}{n}$ 和 $\\mathbb{P}(B_{n}=0)=1-\\frac{1}{n}$，且与 $X$ 独立。令\n$$\nY_{n} \\coloneqq (1-B_{n})\\,X + B_{n}\\,n^{2}.\n$$\n这个构造模仿了一种用于求解具有超线性增长系数的随机微分方程（SDE）的数值格式，该格式会以 $\\frac{1}{n}$ 的小概率产生一个大小为 $n^{2}$ 的灾难性离群值。\n\n1. 仅使用随机变量收敛的基本定义，证明对于任意有界连续的检验函数 $\\varphi:\\mathbb{R}\\to\\mathbb{R}$，序列 $(Y_{n})_{n\\in\\mathbb{N}}$ 与 $X$ 是弱相合的，即 $\\lim_{n\\to\\infty}\\mathbb{E}[\\varphi(Y_{n})]=\\mathbb{E}[\\varphi(X)]$。解释为什么 $\\varphi$ 的有界性对此结论至关重要，并将此有界性解释为一种矩截断。\n\n2. 证明在 $L^{1}$ 意义下的强收敛不成立，即证明 $\\lim_{n\\to\\infty}\\mathbb{E}[|Y_{n}-X|]=+\\infty$，从而展示超线性离群值对强误差的影响。\n\n3. 定义有界连续的检验函数 $\\varphi(x)=\\arctan(x)$。计算精确极限\n$$\nL \\coloneqq \\lim_{n\\to\\infty}\\Big(\\mathbb{E}[\\varphi(Y_{n})]-\\mathbb{E}[\\varphi(X)]\\Big).\n$$\n你的最终答案必须是单个实数 $L$。无需四舍五入，也无需单位。", "solution": "本题研究一个随机变量序列 $(Y_n)_{n \\in \\mathbb{N}}$ 的收敛性质，该序列定义为 $Y_n \\coloneqq (1-B_n)X + B_n n^2$，其中 $X \\sim N(0,1)$，$B_n$ 是一个独立的伯努利（Bernoulli）随机变量，其成功概率为 $\\mathbb{P}(B_n=1) = \\frac{1}{n}$。\n\n1. 对有界连续检验函数的弱相合性证明。\n\n要证明 $Y_n$ 弱收敛于 $X$（记为 $Y_n \\xrightarrow{d} X$），需要证明对于任意有界连续函数 $\\varphi:\\mathbb{R}\\to\\mathbb{R}$，都有 $\\lim_{n\\to\\infty}\\mathbb{E}[\\varphi(Y_n)] = \\mathbb{E}[\\varphi(X)]$。\n\n我们使用全期望公式，通过对伯努利变量 $B_n$ 的取值进行条件化，来计算期望 $\\mathbb{E}[\\varphi(Y_n)]$。\n$$\n\\mathbb{E}[\\varphi(Y_n)] = \\mathbb{E}[\\varphi(Y_n) | B_n=0]\\mathbb{P}(B_n=0) + \\mathbb{E}[\\varphi(Y_n) | B_n=1]\\mathbb{P}(B_n=1)\n$$\n概率由题设给出 $\\mathbb{P}(B_n=0) = 1-\\frac{1}{n}$ 和 $\\mathbb{P}(B_n=1) = \\frac{1}{n}$。\n我们计算条件期望：\n- 如果 $B_n=0$，则 $Y_n = (1-0)X + 0 \\cdot n^2 = X$。由于 $X$ 和 $B_n$ 独立，条件期望为 $\\mathbb{E}[\\varphi(X) | B_n=0] = \\mathbb{E}[\\varphi(X)]$。\n- 如果 $B_n=1$，则 $Y_n = (1-1)X + 1 \\cdot n^2 = n^2$。条件期望为 $\\mathbb{E}[\\varphi(n^2) | B_n=1] = \\varphi(n^2)$，因为对于关于 $X$ 的期望而言，$n^2$ 是一个常数。\n\n将这些代入 $\\mathbb{E}[\\varphi(Y_n)]$ 的公式，得到：\n$$\n\\mathbb{E}[\\varphi(Y_n)] = \\mathbb{E}[\\varphi(X)] \\left(1-\\frac{1}{n}\\right) + \\varphi(n^2) \\frac{1}{n}\n$$\n现在，我们取 $n \\to \\infty$ 的极限：\n$$\n\\lim_{n\\to\\infty}\\mathbb{E}[\\varphi(Y_n)] = \\lim_{n\\to\\infty} \\left( \\mathbb{E}[\\varphi(X)] \\left(1-\\frac{1}{n}\\right) + \\frac{\\varphi(n^2)}{n} \\right)\n$$\n我们分别分析这两项。对于第一项，由于 $\\mathbb{E}[\\varphi(X)]$ 是一个有限常数（因为 $\\varphi$ 有界且 $X$ 有一个正则分布），我们有：\n$$\n\\lim_{n\\to\\infty} \\mathbb{E}[\\varphi(X)] \\left(1-\\frac{1}{n}\\right) = \\mathbb{E}[\\varphi(X)] \\cdot 1 = \\mathbb{E}[\\varphi(X)]\n$$\n对于第二项，我们利用 $\\varphi$ 是有界的性质。这意味着存在一个常数 $M > 0$，使得对于所有 $x \\in \\mathbb{R}$ 都有 $|\\varphi(x)| \\le M$。因此，我们可以如下界定该项：\n$$\n0 \\le \\left| \\frac{\\varphi(n^2)}{n} \\right| \\le \\frac{M}{n}\n$$\n由于 $\\lim_{n\\to\\infty} \\frac{M}{n} = 0$，根据夹逼定理（Squeeze Theorem），可知 $\\lim_{n\\to\\infty} \\frac{\\varphi(n^2)}{n} = 0$。\n\n结合这两项的极限，我们得出结论：\n$$\n\\lim_{n\\to\\infty}\\mathbb{E}[\\varphi(Y_n)] = \\mathbb{E}[\\varphi(X)] + 0 = \\mathbb{E}[\\varphi(X)]\n$$\n这就证明了 $Y_n$ 依分布（弱）收敛于 $X$。\n\n$\\varphi$ 的有界性是至关重要的。如果 $\\varphi$ 不是有界的，$\\varphi(n^2)$ 这一项的增长速度可能比 $n$ 的线性增长更快，导致 $\\frac{\\varphi(n^2)}{n}$ 这一项发散。例如，如果我们取（无界的）连续函数 $\\varphi(x)=x^2$，那么期望 $\\mathbb{E}[Y_n^2]$ 将是 $\\mathbb{E}[X^2](1-\\frac{1}{n}) + (n^2)^2 \\frac{1}{n} = (1-\\frac{1}{n}) + n^3$。当 $n\\to\\infty$ 时，这个表达式显然发散，而 $\\mathbb{E}[X^2]=1$。检验函数的有界性有效地“截断”了随机变量的矩，使得期望对于稀有但极大的偏差不敏感。离群值的概率（$\\frac{1}{n}$）消失得足够快，仅当检验函数不放大此离群值的值时，才能克服其影响。\n\n2. 在 $L^1$ 中收敛的失败。\n\n为了证明在 $L^1$ 意义下的强收敛不成立，我们必须证明 $\\mathbb{E}[|Y_n - X|]$ 不收敛于 $0$。我们将证明它发散到 $+\\infty$。\n我们再次通过对 $B_n$ 进行条件化来计算期望 $\\mathbb{E}[|Y_n - X|]$。\n$Y_n - X$ 的表达式为 $(1-B_n)X + B_n n^2 - X = B_n(n^2 - X)$。\n$$\n|Y_n - X| = |B_n(n^2-X)| = B_n|n^2-X|\n$$\n这是因为 $B_n$ 的取值是 $0$ 或 $1$。\n期望为：\n$$\n\\mathbb{E}[|Y_n - X|] = \\mathbb{E}[B_n|n^2-X|]\n$$\n由于 $B_n$ 和 $X$ 独立，乘积的期望等于期望的乘积：\n$$\n\\mathbb{E}[|Y_n - X|] = \\mathbb{E}[B_n] \\mathbb{E}[|n^2 - X|] = \\frac{1}{n} \\mathbb{E}[|n^2 - X|]\n$$\n我们可以使用反三角不等式 $|a-b| \\ge |a|-|b|$ 来确定 $\\mathbb{E}[|n^2-X|]$ 的一个下界。\n$$\n|n^2 - X| \\ge |n^2| - |X| = n^2 - |X|\n$$\n对两边取期望：\n$$\n\\mathbb{E}[|n^2 - X|] \\ge \\mathbb{E}[n^2 - |X|] = n^2 - \\mathbb{E}[|X|]\n$$\n一个标准正态随机变量 $X \\sim N(0,1)$ 的期望绝对值是一个常数：\n$$\n\\mathbb{E}[|X|] = \\int_{-\\infty}^{\\infty} |x| \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right) dx = 2 \\int_{0}^{\\infty} x \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right) dx = \\sqrt{\\frac{2}{\\pi}}\n$$\n将此代回，我们得到：\n$$\n\\mathbb{E}[|n^2 - X|] \\ge n^2 - \\sqrt{\\frac{2}{\\pi}}\n$$\n因此，$L^1$-误差有如下下界：\n$$\n\\mathbb{E}[|Y_n - X|] \\ge \\frac{1}{n} \\left( n^2 - \\sqrt{\\frac{2}{\\pi}} \\right) = n - \\frac{1}{n}\\sqrt{\\frac{2}{\\pi}}\n$$\n当 $n\\to\\infty$ 时，下界 $n - \\frac{1}{n}\\sqrt{\\frac{2}{\\pi}}$ 发散到 $+\\infty$。根据极限的比较检验法，我们必有：\n$$\n\\lim_{n\\to\\infty}\\mathbb{E}[|Y_n - X|] = +\\infty\n$$\n因此，$Y_n$ 不在 $L^1$ 中收敛于 $X$。离群值 $n^2$ 的超线性增长足够强，即使乘以概率 $\\frac{1}{n}$，它对平均绝对误差的贡献（其行为类似 $\\frac{n^2}{n}=n$）仍然无界增长。\n\n3. 极限 $L$ 的计算。\n\n题目要求我们计算 $L \\coloneqq \\lim_{n\\to\\infty}\\Big(\\mathbb{E}[\\varphi(Y_{n})]-\\mathbb{E}[\\varphi(X)]\\Big)$，其中检验函数是特定的有界连续函数 $\\varphi(x)=\\arctan(x)$。\n\n根据第1部分的推导，我们有一般表达式：\n$$\n\\mathbb{E}[\\varphi(Y_n)] = \\mathbb{E}[\\varphi(X)] \\left(1-\\frac{1}{n}\\right) + \\frac{\\varphi(n^2)}{n}\n$$\n整理此式求差，得到：\n$$\n\\mathbb{E}[\\varphi(Y_n)] - \\mathbb{E}[\\varphi(X)] = \\mathbb{E}[\\varphi(X)]\\left(1-\\frac{1}{n} - 1\\right) + \\frac{\\varphi(n^2)}{n} = \\frac{\\varphi(n^2) - \\mathbb{E}[\\varphi(X)]}{n}\n$$\n所以，极限为：\n$$\nL = \\lim_{n\\to\\infty} \\frac{\\varphi(n^2) - \\mathbb{E}[\\varphi(X)]}{n}\n$$\n现在，我们代入 $\\varphi(x) = \\arctan(x)$：\n$$\nL = \\lim_{n\\to\\infty} \\frac{\\arctan(n^2) - \\mathbb{E}[\\arctan(X)]}{n}\n$$\n我们计算分子中的两项。\n首先，$\\arctan(n^2)$ 的极限：\n$$\n\\lim_{n\\to\\infty} \\arctan(n^2) = \\frac{\\pi}{2}\n$$\n其次，期望 $\\mathbb{E}[\\arctan(X)]$。被积函数是 $\\arctan(x)$ 乘以 $X \\sim N(0,1)$ 的概率密度函数，即 $f_X(x) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{x^2}{2})$。\n$$\n\\mathbb{E}[\\arctan(X)] = \\int_{-\\infty}^{\\infty} \\arctan(x) \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{x^2}{2}\\right) dx\n$$\n函数 $g(x) = \\arctan(x) \\exp(-\\frac{x^2}{2})$ 是一个奇函数，因为 $\\arctan(x)$ 是奇函数，而 $\\exp(-\\frac{x^2}{2})$ 是偶函数，所以 $g(-x) = \\arctan(-x) \\exp(-\\frac{(-x)^2}{2}) = -\\arctan(x) \\exp(-\\frac{x^2}{2}) = -g(x)$。一个奇函数在对称区间 $(-\\infty, \\infty)$ 上的积分为零。\n$$\n\\mathbb{E}[\\arctan(X)] = 0\n$$\n将这些值代回 $L$ 的表达式中：\n$$\nL = \\lim_{n\\to\\infty} \\frac{\\frac{\\pi}{2} - 0}{n} = \\lim_{n\\to\\infty} \\frac{\\pi}{2n}\n$$\n由于分子是常数，分母趋于无穷大，所以极限为零。\n$$\nL = 0\n$$\n这个结果是第1部分中证明的一般弱收敛的一个特例。由于 $\\lim_{n\\to\\infty}\\mathbb{E}[\\varphi(Y_{n})] = \\mathbb{E}[\\varphi(X)]$，直接可以得出 $\\lim_{n\\to\\infty}(\\mathbb{E}[\\varphi(Y_{n})]-\\mathbb{E}[\\varphi(X)])=0$。本次计算验证了这一结论。", "answer": "$$\\boxed{0}$$", "id": "2987750"}]}