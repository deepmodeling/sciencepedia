{"hands_on_practices": [{"introduction": "粒子滤波器的一个核心挑战是权重退化现象，尤其是在高维状态空间中，这一问题尤为严重，即所谓的“维度灾难”。本练习将引导你通过一个简化的、但极具启发性的高斯模型，亲手推导出归一化重要性权重的方差与状态维度 $d$ 的函数关系 [@problem_id:2990102]。通过这个推导，你将定量地理解权重方差是如何随着维度指数级增长的，从而深刻洞察为何标准粒子滤波器在高维问题中会失效。", "problem": "考虑一个$d$维潜状态$X_t$，它遵循一个具有全局渐近稳定平衡点和各向同性平稳协方差的 Itô 随机微分方程 (Itô SDE) 进行演化，具体为一个由 $dX_t = -\\lambda X_t\\,dt + \\sqrt{2\\lambda \\tau^2}\\,dW_t$ 给出的 Ornstein–Uhlenbeck (OU) 模型，其中$W_t$是一个$d$维标准维纳过程，且$\\tau^2 > 0$。在平稳状态下，$X_t$的分布为$X \\sim \\mathcal{N}(0, \\tau^2 I_d)$。在一个序贯蒙特卡罗 (SMC) 自举粒子滤波器（提议分布即先验分布）中，考虑一个单一的滤波步骤，其观测模型为 $Y = H X + V$，$H = I_d$，$V \\sim \\mathcal{N}(0, \\sigma^2 I_d)$与$X$独立，实现的观测值为$y = 0$。根据贝叶斯法则，目标后验密度正比于先验预测密度乘以似然贡献，因此目标是一个似然倾斜的先验分布。对于状态值为$x$的粒子，其未归一化的增量重要性权重正比于似然因子$\\ell(x) = \\exp\\!\\big(-\\|x\\|^2/(2\\sigma^2)\\big)$。\n\n在提议分布 $p(x) = \\mathcal{N}(0, \\tau^2 I_d)$ 下，将归一化的重要性权重定义为 $w(x) = \\ell(x)\\big/\\mathbb{E}_p[\\ell(X)]$，从而使得 $\\mathbb{E}_p[w(X)] = 1$。仅使用第一性原理——贝叶斯法则、高斯积分的性质以及重要性采样的定义——推导方差 $\\mathrm{Var}_p[w(X)]$ 作为维度 $d$ 和参数 $\\tau^2$、$\\sigma^2$ 的函数的闭式表达式。将你的最终答案表示为关于 $d$、$\\tau^2$ 和 $\\sigma^2$ 的单一解析表达式。", "solution": "该问题陈述已经过验证，并被认为是科学上合理的、良定的和客观的。它提出了一个贝叶斯滤波中的标准场景，并要求使用第一性原理推导一个量。所有必要信息均已提供，没有矛盾或歧义。\n\n目标是计算归一化重要性权重的方差 $\\mathrm{Var}_p[w(X)]$。提议分布，即粒子 $X$ 的抽样来源，是 Ornstein-Uhlenbeck 过程的平稳分布，给定为 $p(x) = \\mathcal{N}(0, \\tau^2 I_d)$。对于向量 $x \\in \\mathbb{R}^d$，其概率密度函数为：\n$$\np(x) = \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\exp\\left(-\\frac{\\|x\\|^2}{2\\tau^2}\\right)\n$$\n未归一化的重要性权重由似然因子 $\\ell(x)$ 给出，它来自观测模型 $Y = X + V$（其中 $V \\sim \\mathcal{N}(0, \\sigma^2 I_d)$）和一个已实现的观测值 $y=0$。在给定观测值 $y=0$ 的条件下，状态 $x$ 的似然为：\n$$\np(y=0|x) \\propto \\exp\\left(-\\frac{\\|0-x\\|^2}{2\\sigma^2}\\right) = \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)\n$$\n因此，我们将未归一化的权重函数确定为 $\\ell(x) = \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)$。\n\n问题将归一化的重要性权重定义为 $w(x) = \\ell(x) / \\mathbb{E}_p[\\ell(X)]$。根据这个定义，在提议分布下，归一化权重的期望为1：\n$$\n\\mathbb{E}_p[w(X)] = \\mathbb{E}_p\\left[\\frac{\\ell(X)}{\\mathbb{E}_p[\\ell(X)]}\\right] = \\frac{1}{\\mathbb{E}_p[\\ell(X)]}\\mathbb{E}_p[\\ell(X)] = 1\n$$\n归一化权重的方差由标准公式给出：\n$$\n\\mathrm{Var}_p[w(X)] = \\mathbb{E}_p[w(X)^2] - (\\mathbb{E}_p[w(X)])^2 = \\mathbb{E}_p[w(X)^2] - 1\n$$\n我们的任务简化为计算二阶矩 $\\mathbb{E}_p[w(X)^2]$。我们用 $\\ell(x)$ 来表示它：\n$$\n\\mathbb{E}_p[w(X)^2] = \\mathbb{E}_p\\left[\\left(\\frac{\\ell(X)}{\\mathbb{E}_p[\\ell(X)]}\\right)^2\\right] = \\frac{\\mathbb{E}_p[\\ell(X)^2]}{(\\mathbb{E}_p[\\ell(X)])^2}\n$$\n我们必须计算两个期望：$\\mathbb{E}_p[\\ell(X)]$ 和 $\\mathbb{E}_p[\\ell(X)^2]$。\n\n首先，我们计算 $\\mathbb{E}_p[\\ell(X)]$，它是权重的归一化常数：\n$$\n\\mathbb{E}_p[\\ell(X)] = \\int_{\\mathbb{R}^d} \\ell(x) p(x) \\,dx = \\int_{\\mathbb{R}^d} \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right) \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\exp\\left(-\\frac{\\|x\\|^2}{2\\tau^2}\\right) \\,dx\n$$\n合并指数项，我们得到：\n$$\n\\mathbb{E}_p[\\ell(X)] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\int_{\\mathbb{R}^d} \\exp\\left(-\\|x\\|^2 \\left(\\frac{1}{2\\sigma^2} + \\frac{1}{2\\tau^2}\\right)\\right) \\,dx\n$$\n我们简化括号中的项：$\\frac{1}{2\\sigma^2} + \\frac{1}{2\\tau^2} = \\frac{\\tau^2 + \\sigma^2}{2\\sigma^2\\tau^2}$。积分现在是：\n$$\n\\int_{\\mathbb{R}^d} \\exp\\left(-\\frac{1}{2} \\|x\\|^2 \\left(\\frac{\\tau^2 + \\sigma^2}{\\sigma^2\\tau^2}\\right)\\right) \\,dx\n$$\n这是一个未归一化的$d$维高斯密度的积分，其均值为零，协方差矩阵为 $(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2})I_d$。这样一个积分 $\\int_{\\mathbb{R}^d}\\exp(-\\frac{1}{2}x^T\\Sigma^{-1}x)dx$ 的值是 $(2\\pi)^{d/2}|\\Sigma|^{1/2}$。在这里，$\\Sigma^{-1} = \\frac{\\tau^2+\\sigma^2}{\\sigma^2\\tau^2}I_d$，所以 $|\\Sigma|^{1/2} = \\left(\\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^d\\right)^{1/2} = \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2}$。\n因此，该积分的计算结果为 $(2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2}$。\n将此结果代回到 $\\mathbb{E}_p[\\ell(X)]$ 的表达式中：\n$$\n\\mathbb{E}_p[\\ell(X)] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} (2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2} = \\frac{1}{(\\tau^2)^{d/2}} \\left(\\frac{\\sigma^2\\tau^2}{\\tau^2+\\sigma^2}\\right)^{d/2} = \\left(\\frac{\\sigma^2}{\\tau^2+\\sigma^2}\\right)^{d/2}\n$$\n\n接下来，我们计算 $\\mathbb{E}_p[\\ell(X)^2]$。似然因子的平方是 $\\ell(x)^2 = \\left(\\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right)\\right)^2 = \\exp\\left(-\\frac{\\|x\\|^2}{\\sigma^2}\\right)$。\n$$\n\\mathbb{E}_p[\\ell(X)^2] = \\int_{\\mathbb{R}^d} \\ell(x)^2 p(x) \\,dx = \\int_{\\mathbb{R}^d} \\exp\\left(-\\frac{\\|x\\|^2}{\\sigma^2}\\right) \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\exp\\left(-\\frac{\\|x\\|^2}{2\\tau^2}\\right) \\,dx\n$$\n再次合并指数项：\n$$\n\\mathbb{E}_p[\\ell(X)^2] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} \\int_{\\mathbb{R}^d} \\exp\\left(-\\|x\\|^2 \\left(\\frac{1}{\\sigma^2} + \\frac{1}{2\\tau^2}\\right)\\right) \\,dx\n$$\n括号中的项是 $\\frac{1}{\\sigma^2} + \\frac{1}{2\\tau^2} = \\frac{2\\tau^2 + \\sigma^2}{2\\sigma^2\\tau^2}$。该积分同样是高斯形式。通过将 $-\\|x\\|^2(\\dots)$ 对应于 $-\\frac{1}{2}x^T\\Sigma^{-1}x$，可知逆协方差为 $\\Sigma^{-1} = \\frac{2\\tau^2+\\sigma^2}{\\sigma^2\\tau^2}I_d$，积分值为 $(2\\pi)^{d/2}|\\Sigma|^{1/2} = (2\\pi)^{d/2}\\left(\\frac{\\sigma^2\\tau^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}$。\n将此结果代回到 $\\mathbb{E}_p[\\ell(X)^2]$ 的表达式中：\n$$\n\\mathbb{E}_p[\\ell(X)^2] = \\frac{1}{(2\\pi \\tau^2)^{d/2}} (2\\pi)^{d/2} \\left(\\frac{\\sigma^2\\tau^2}{2\\tau^2+\\sigma^2}\\right)^{d/2} = \\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}\n$$\n\n现在我们可以计算 $\\mathbb{E}_p[w(X)^2]$：\n$$\n\\mathbb{E}_p[w(X)^2] = \\frac{\\mathbb{E}_p[\\ell(X)^2]}{(\\mathbb{E}_p[\\ell(X)])^2} = \\frac{\\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}}{\\left(\\left(\\frac{\\sigma^2}{\\tau^2+\\sigma^2}\\right)^{d/2}\\right)^2} = \\frac{\\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2}}{\\left(\\frac{\\sigma^2}{\\tau^2+\\sigma^2}\\right)^d}\n$$\n$$\n= \\left(\\frac{\\sigma^2}{2\\tau^2+\\sigma^2}\\right)^{d/2} \\left(\\frac{\\tau^2+\\sigma^2}{\\sigma^2}\\right)^d = \\frac{(\\sigma^2)^{d/2}}{(2\\tau^2+\\sigma^2)^{d/2}} \\frac{(\\tau^2+\\sigma^2)^d}{(\\sigma^2)^d} = \\frac{(\\tau^2+\\sigma^2)^d}{(2\\tau^2+\\sigma^2)^{d/2}(\\sigma^2)^{d/2}}\n$$\n通过将各项归到 $d/2$ 次幂下，可以更紧凑地写为：\n$$\n\\mathbb{E}_p[w(X)^2] = \\frac{\\left((\\tau^2+\\sigma^2)^2\\right)^{d/2}}{\\left(\\sigma^2(2\\tau^2+\\sigma^2)\\right)^{d/2}} = \\left(\\frac{(\\tau^2+\\sigma^2)^2}{\\sigma^2(2\\tau^2+\\sigma^2)}\\right)^{d/2}\n$$\n最后，方差为 $\\mathbb{E}_p[w(X)^2] - 1$：\n$$\n\\mathrm{Var}_p[w(X)] = \\left(\\frac{(\\tau^2+\\sigma^2)^2}{\\sigma^2(2\\tau^2+\\sigma^2)}\\right)^{d/2} - 1\n$$\n该表达式给出了归一化重要性权重的方差，作为模型参数 $d$、$\\tau^2$ 和 $\\sigma^2$ 的函数。对于 $\\tau^2>0, \\sigma^2>0$，可以验证指数的底数大于1：\n$$\n\\frac{(\\tau^2+\\sigma^2)^2}{\\sigma^2(2\\tau^2+\\sigma^2)} = \\frac{\\tau^4 + 2\\tau^2\\sigma^2 + \\sigma^4}{2\\tau^2\\sigma^2 + \\sigma^4} = 1 + \\frac{\\tau^4}{2\\tau^2\\sigma^2 + \\sigma^4} > 1\n$$\n这确保了方差为正，符合要求。", "answer": "$$\n\\boxed{\\left(\\frac{(\\tau^2 + \\sigma^2)^2}{\\sigma^2(2\\tau^2 + \\sigma^2)}\\right)^{d/2} - 1}\n$$", "id": "2990102"}, {"introduction": "除了数值稳定性和权重退化，粒子滤波器的实际应用还受到其计算效率的制约，尤其是在处理高维系统或需要大量粒子时。本练习旨在解决这一关键的数值稳定性问题，你将学习并实现一种被称为“log-sum-exp”的技巧，以确保在对数域中安全地进行权重更新和归一化 [@problem_id:2990126]。掌握这项技术是开发任何能够处理极端数值范围的可靠统计模型（包括粒子滤波器）的基础技能。", "problem": "考虑一个通过对随机微分方程进行 Euler–Maruyama 离散化得到的离散时间非线性隐马尔可夫模型。设隐藏状态为 $x_k \\in \\mathbb{R}^n$，其演化遵循\n$$\nx_k = x_{k-1} + f(x_{k-1})\\,\\Delta t + G(x_{k-1})\\,\\sqrt{\\Delta t}\\,\\eta_k,\n$$\n其中 $f(\\cdot)$ 是一个漂移项，$G(\\cdot)$ 是一个扩散项，$\\Delta t$ 是时间步长，$\\eta_k$ 是一个标准高斯随机向量。观测由下式给出\n$$\ny_k = h(x_k) + v_k,\n$$\n其中 $h(\\cdot)$ 是一个非线性传感器模型，$v_k$ 是一个高斯噪声向量。\n\n在用于此系统的粒子滤波器中，假设我们有 $N$ 个粒子 $\\{x_k^{(i)}\\}_{i=1}^N$ 及其先前满足 $\\sum_{i=1}^N w_{k-1}^{(i)} = 1$ 的归一化权重 $\\{w_{k-1}^{(i)}\\}_{i=1}^N$。在时间 $k$ 的测量更新基于贝叶斯法则和重要性采样原理：未归一化的新权重与前一权重和似然的乘积成正比，\n$$\n\\tilde{w}_k^{(i)} \\propto w_{k-1}^{(i)}\\,p(y_k \\mid x_k^{(i)}),\n$$\n归一化后的权重则为\n$$\nw_k^{(i)} = \\frac{\\tilde{w}_k^{(i)}}{\\sum_{j=1}^N \\tilde{w}_k^{(j)}}.\n$$\n\n当似然 $p(y_k \\mid x_k^{(i)})$ 非常小（例如由于严重不匹配或测量噪声协方差很小）时，在浮点运算中直接计算 $\\tilde{w}_k^{(i)}$ 可能会下溢为零。一个稳健的计算策略是在对数域中操作。定义对数权重\n$$\n\\ell_{k-1}^{(i)} = \\log w_{k-1}^{(i)}, \\quad \\lambda_k^{(i)} = \\log p(y_k \\mid x_k^{(i)}),\n$$\n以及更新后的对数权重\n$$\n\\ell_k^{(i)} = \\ell_{k-1}^{(i)} + \\lambda_k^{(i)}.\n$$\n归一化后的 $w_k^{(i)}$ 随后可以使用一种数值安全的方法稳定地恢复，即使当 $\\lambda_k^{(i)}$ 是极端的负数时也能避免灾难性下溢。\n\n你的任务是，基于上述基础且不假设任何快捷公式，推导出一个基于对数权重的数值稳定的 $\\{w_k^{(i)}\\}_{i=1}^N$ 归一化过程，该过程在某些 $\\lambda_k^{(i)}$ 非常小或为 $-\\infty$（表示零似然）时仍保持稳健。在一个完整的程序中实现此过程，对于下面提供的每个测试用例，该程序接收前一权重数组和对数似然增量，计算更新后的对数权重，并以数值稳定的方式对其进行归一化。如果所有更新后的对数权重均为 $-\\infty$（即当前观测下所有粒子都具有零似然），你必须返回均匀权重 $w_k^{(i)} = 1/N$ 的备用方案以避免退化。\n\n设计你的程序以处理以下测试套件。对于每个用例，输入包括先前的归一化权重 $\\{w_{k-1}^{(i)}\\}$ 和对数似然增量 $\\{\\lambda_k^{(i)}\\}$，输出是归一化权重列表 $\\{w_k^{(i)}\\}$，四舍五入到十二位小数：\n\n- 测试用例 1（常见极端尺度下的正常路径）：$N=5$。先前权重 $[0.2,\\,0.3,\\,0.1,\\,0.25,\\,0.15]$。对数似然增量 $[-1000.0,\\,-1000.0,\\,-1000.0,\\,-1000.0,\\,-1000.0]$。\n- 测试用例 2（混合极端情况与不可能粒子）：$N=5$。先前权重 $[0.2,\\,0.2,\\,0.2,\\,0.2,\\,0.2]$。对数似然增量 $[-1000.0,\\,-2000.0,\\,-\\infty,\\,-1200.0,\\,-1100.0]$。\n- 测试用例 3（严重不匹配中的单个主导支撑）：$N=5$。先前权重 $[0.05,\\,0.05,\\,0.8,\\,0.05,\\,0.05]$。对数似然增量 $[-1000.0,\\,-1000.0,\\,0.0,\\,-1000.0,\\,-1000.0]$。\n- 测试用例 4（全部不可能，回退到均匀权重）：$N=4$。先前权重 $[0.1,\\,0.2,\\,0.3,\\,0.4]$。对数似然增量 $[-\\infty,\\,-\\infty,\\,-\\infty,\\,-\\infty]$。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。这个顶层列表的每个元素必须是对应测试用例的归一化权重列表，四舍五入到十二位小数。例如，你的输出行必须如下所示\n$[ [\\cdots], [\\cdots], [\\cdots], [\\cdots] ]$\n无任何附加文本。角度和物理单位不适用于此问题，唯一的输出是四舍五入到十二位小数的浮点数列表。请确保你的实现对于所提供的边缘情况是数值稳定和稳健的。", "solution": "该问题要求推导并实现一个数值稳定的程序，用以在粒子滤波器中归一化粒子权重，特别是在对数域中操作以减轻浮点下溢问题。\n\n出发点是粒子权重的标准重要性采样更新规则。给定一组具有先前归一化权重 $\\{w_{k-1}^{(i)}\\}_{i=1}^N$（满足 $\\sum_{i=1}^N w_{k-1}^{(i)} = 1$）的 $N$ 个粒子，时间步 $k$ 的未归一化更新权重 $\\tilde{w}_k^{(i)}$ 由先验权重与新观测 $y_k$ 在给定粒子状态 $x_k^{(i)}$ 下的似然的乘积给出：\n$$\n\\tilde{w}_k^{(i)} = w_{k-1}^{(i)} \\, p(y_k \\mid x_k^{(i)})\n$$\n然后通过归一化得到新的权重 $w_k^{(i)}$：\n$$\nw_k^{(i)} = \\frac{\\tilde{w}_k^{(i)}}{\\sum_{j=1}^N \\tilde{w}_k^{(j)}}\n$$\n直接计算该表达式容易出现数值下溢。如果似然值 $p(y_k \\mid x_k^{(i)})$ 极小，乘积 $\\tilde{w}_k^{(i)}$ 在有限精度算术中可能对所有 $i$ 都计算为零，从而导致除以零。\n\n为规避此问题，我们在对数域中进行操作。设 $\\ell_{k-1}^{(i)} = \\log w_{k-1}^{(i)}$ 为先前的对数权重，$\\lambda_k^{(i)} = \\log p(y_k \\mid x_k^{(i)})$ 为对数似然。未归一化的更新后对数权重 $\\ell_k^{(i)}$ 为：\n$$\n\\ell_k^{(i)} = \\log(\\tilde{w}_k^{(i)}) = \\log(w_{k-1}^{(i)}) + \\log(p(y_k \\mid x_k^{(i)})) = \\ell_{k-1}^{(i)} + \\lambda_k^{(i)}\n$$\n由此，归一化权重 $w_k^{(i)}$ 可表示为：\n$$\nw_k^{(i)} = \\frac{\\exp(\\ell_k^{(i)})}{\\sum_{j=1}^N \\exp(\\ell_k^{(j)})}\n$$\n这种形式仍然存在同样的下溢问题，因为 $\\ell_k^{(i)}$ 可能是很大的负数（例如 -1000），导致 $\\exp(\\ell_k^{(i)})$ 计算为零。\n\n稳定计算的关键是“log-sum-exp”技巧。令 $L_{max}$ 为所有未归一化更新后对数权重中的最大值：\n$$\nL_{max} = \\max_{j \\in \\{1, \\dots, N\\}} \\{\\ell_k^{(j)}\\}\n$$\n我们可以将 $w_k^{(i)}$ 表达式的分子和分母乘以同一个非零因子 $\\exp(-L_{max})$，而其值不变：\n$$\nw_k^{(i)} = \\frac{\\exp(\\ell_k^{(i)}) \\cdot \\exp(-L_{max})}{\\left(\\sum_{j=1}^N \\exp(\\ell_k^{(j)})\\right) \\cdot \\exp(-L_{max})}\n$$\n利用属性 $\\exp(a)\\exp(b) = \\exp(a+b)$ 并将因子分配到和中，我们得到：\n$$\nw_k^{(i)} = \\frac{\\exp(\\ell_k^{(i)} - L_{max})}{\\sum_{j=1}^N \\exp(\\ell_k^{(j)} - L_{max})}\n$$\n这个表达式是数值稳定的。我们来分析一下它的组成部分：\n1.  对于和中的任何项，指数 $(\\ell_k^{(j)} - L_{max})$ 总是小于或等于 $0$，因为 $L_{max}$ 是集合 $\\{\\ell_k^{(j)}\\}$ 中的最大值。这可以防止 $\\exp(\\cdot)$ 的参数成为大的正数，从而避免上溢。\n2.  至少存在一个粒子（假设索引为 $m$），其满足 $\\ell_k^{(m)} = L_{max}$。对于这个粒子，和中的项为 $\\exp(\\ell_k^{(m)} - L_{max}) = \\exp(0) = 1$。\n3.  因此，分母 $S = \\sum_{j=1}^N \\exp(\\ell_k^{(j)} - L_{max})$ 保证大于或等于 $1$。这可以防止和下溢为零，而这正是主要的数值不稳定性所在。\n4.  如果 $\\ell_k^{(i)}$ 远小于 $L_{max}$，项 $\\exp(\\ell_k^{(i)} - L_{max})$ 仍可能下溢为零。然而，这是一个正确且期望的结果，因为它反映了与最可能的粒子相比，粒子 $i$ 的权重可以忽略不计。\n\n当所有粒子都具有零似然时，会出现一个特殊情况，这对应于所有对数似然 $\\lambda_k^{(i)}$ 均为 $-\\infty$，或某种组合导致所有 $\\ell_k^{(i)}$ 均为 $-\\infty$。在此场景下，$L_{max} = -\\infty$。直接应用该公式是未定义的。问题指定了一个稳健的回退机制：如果所有更新后的对数权重均为 $-\\infty$，则通过分配均匀权重 $w_k^{(i)} = 1/N$（对所有 $i$）来重置滤波器。这可以防止滤波器退化。\n\n完整且数值稳定的算法如下：\n1.  对每个粒子 $i \\in \\{1, \\dots, N\\}$，计算未归一化的对数权重：$\\ell_k^{(i)} = \\log(w_{k-1}^{(i)}) + \\lambda_k^{(i)}$。注意，如果 $w_{k-1}^{(i)}=0$，那么 $\\ell_{k-1}^{(i)}=-\\infty$，因此 $\\ell_k^{(i)}=-\\infty$。\n2.  找到最大对数权重：$L_{max} = \\max_{i} \\{\\ell_k^{(i)}\\}$。\n3.  检查退化情况：如果 $L_{max} = -\\infty$，则对所有 $i=1, \\dots, N$ 设置 $w_k^{(i)} = 1/N$ 并终止。\n4.  如果 $L_{max}$ 是有限的，计算移位的对数权重：$\\ell'^{(i)}_k = \\ell_k^{(i)} - L_{max}$。\n5.  计算稳定的未归一化权重：$w'^{(i)}_k = \\exp(\\ell'^{(i)}_k)$。\n6.  计算它们的和：$S = \\sum_{j=1}^N w'^{(j)}_k$。\n7.  计算最终的归一化权重：$w_k^{(i)} = \\frac{w'^{(i)}_k}{S}$。\n此过程确保了即使在对数似然值极端的情况下，权重归一化也能保持稳健和准确。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the particle filter weight normalization problem for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1: happy path with common extreme scaling\n        (np.array([0.2, 0.3, 0.1, 0.25, 0.15]), np.array([-1000.0, -1000.0, -1000.0, -1000.0, -1000.0])),\n        # Test Case 2: mixed extremes and impossible particle\n        (np.array([0.2, 0.2, 0.2, 0.2, 0.2]), np.array([-1000.0, -2000.0, -np.inf, -1200.0, -1100.0])),\n        # Test Case 3: single dominant support amid severe mismatch\n        (np.array([0.05, 0.05, 0.8, 0.05, 0.05]), np.array([-1000.0, -1000.0, 0.0, -1000.0, -1000.0])),\n        # Test Case 4: all impossible, fallback to uniform\n        (np.array([0.1, 0.2, 0.3, 0.4]), np.array([-np.inf, -np.inf, -np.inf, -np.inf]))\n    ]\n    \n    results = []\n\n    for prev_weights, log_likelihoods in test_cases:\n        # Step 1: Compute previous log-weights and updated unnormalized log-weights.\n        # np.log handles arrays and np.log(0) correctly returns -inf.\n        # Since all given prev_weights are > 0, we don't encounter np.log(0).\n        log_prev_weights = np.log(prev_weights)\n        \n        # This is l_k^{(i)} in the problem description.\n        updated_log_weights = log_prev_weights + log_likelihoods\n        \n        # Step 2: Find the maximum log-weight.\n        max_log_weight = np.max(updated_log_weights)\n        \n        # Step 3: Handle the degenerate case where all particles have zero likelihood.\n        if max_log_weight == -np.inf:\n            num_particles = len(prev_weights)\n            normalized_weights = np.full(num_particles, 1.0 / num_particles)\n        else:\n            # Step 4: Compute shifted log-weights.\n            # This is l_k^{(i)} - L_max.\n            shifted_log_weights = updated_log_weights - max_log_weight\n            \n            # Step 5 & 6: Exponentiate and compute the sum.\n            # This is exp(l_k^{(i)} - L_max).\n            exp_weights = np.exp(shifted_log_weights)\n            sum_exp_weights = np.sum(exp_weights)\n            \n            # Step 7: Compute the final normalized weights.\n            normalized_weights = exp_weights / sum_exp_weights\n            \n        # Round the final weights to 12 decimal places as required.\n        rounded_weights = np.round(normalized_weights, 12).tolist()\n        results.append(rounded_weights)\n\n    # Format the final output string as specified.\n    # The problem specifies that the output for each test case is a list.\n    # The overall output is a list of these lists.\n    # A simple map to str over `results` would create strings of lists.\n    # We must format it carefully.\n    result_strings = [str(r) for r in results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "2990126"}, {"introduction": "除了数值稳定性和权重退化，粒子滤波器的实际应用还受到其计算效率的制约，尤其是在处理高维系统或需要大量粒子时。本练习要求你从第一性原理出发，对粒子滤波器的每个核心阶段——传播、权重计算和重采样——进行计算复杂性分析 [@problem_id:2990065]。通过推导算法复杂度与粒子数 $N$ 和状态维数 $d$ 的关系，你将学会如何识别计算瓶颈，这对于优化算法性能和进行有根据的硬件选择至关重要。", "problem": "考虑一个状态维度为 $d$ 的非线性连续时间随机动力学系统，由一个随机微分方程（SDE）所描述\n$$\n\\mathrm{d}X_{t} \\;=\\; f(X_{t})\\,\\mathrm{d}t \\;+\\; G(X_{t})\\,\\mathrm{d}W_{t},\n$$\n其中 $X_{t}\\in\\mathbb{R}^{d}$ 是状态，$f:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ 是一个漂移场，$G:\\mathbb{R}^{d}\\to\\mathbb{R}^{d\\times d}$ 是一个扩散场（该扩散场对于典型状态是稠密的），$W_{t}$ 是一个标准的 $d$ 维维纳过程。在时间点 $\\{t_{k}\\}$ 的离散时间观测由下式给出\n$$\nY_{k} \\;=\\; h(X_{t_{k}}) \\;+\\; V_{k},\n$$\n其中 $h:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ 是一个非线性测量函数，$V_{k}\\sim \\mathcal{N}(0,S)$ 是高斯测量噪声，其协方差 $S\\in\\mathbb{R}^{d\\times d}$ 是时不变的稠密矩阵。假设 $S$ 是非奇异的，并且其逆矩阵或 Cholesky 分解被预先计算一次并重复使用。\n\n一个包含 $N$ 个粒子的序贯蒙特卡罗（SMC）粒子滤波器被用来近似滤波分布。在每个时间步 $t_{k}\\to t_{k+1}$，该滤波器执行三个阶段：\n\n(1) 传播：每个粒子 $X^{(i)}_{t_{k}}$ 使用步长为 $\\Delta t$ 的 Euler–Maruyama 方法推进到 $X^{(i)}_{t_{k+1}}$，即\n$$\nX^{(i)}_{t_{k+1}} \\;=\\; X^{(i)}_{t_{k}} \\;+\\; f\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta t \\;+\\; G\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta W^{(i)}_{k},\n$$\n其中 $\\Delta W^{(i)}_{k}\\sim \\mathcal{N}(0,\\Delta t\\,I_{d})$ 对每个粒子是独立的。假设评估 $f$ 每个粒子需要 $\\Theta(d)$ 次算术运算，$G(X)$ 是稠密的，因此形成 $G(X)\\in\\mathbb{R}^{d\\times d}$ 并将其乘以 $\\Delta W\\in\\mathbb{R}^{d}$ 每个粒子需要 $\\Theta(d^{2})$ 次算术运算。\n\n(2) 权重计算：对每个粒子状态 $x^{(i)}$，计算残差 $r^{(i)}=y_{k+1}-h(x^{(i)})$（假设 $h$ 需要 $\\Theta(d)$ 次运算），并通过二次型 $Q^{(i)}=(r^{(i)})^{\\top}S^{-1}r^{(i)}$ 评估高斯似然（不考虑归一化常数），或等价地，使用预先计算的 Cholesky 分解 $S=LL^{\\top}$，通过求解 $Lz=r^{(i)}$，然后计算 $Q^{(i)}=\\|z\\|^{2}$。对于稠密的 $L\\in\\mathbb{R}^{d\\times d}$，三角求解每个粒子耗费 $\\Theta(d^{2})$ 次运算，而计算 $\\|z\\|^{2}$ 耗费 $\\Theta(d)$ 次运算。\n\n(3) 重采样：执行系统重采样，从加权集合中抽取 $N$ 个新粒子。计算归一化权重、它们的累积和以及生成重采样索引，假设每个时间步的成本为 $\\Theta(N)$。\n\n从上述关于 SDE 离散化、高斯似然评估和系统重采样的第一性原理描述出发，将整个粒子滤波器每个时间步的主导阶渐近计算复杂度推导为关于 $N$ 和 $d$ 的单一表达式，忽略所有常数因子和低阶项。您的推导必须明确指出在所述假设下，哪个（些）阶段构成了计算瓶颈。以大O表示法的封闭形式渐近表达式提供您的最终答案。不需要数值近似或四舍五入。", "solution": "该问题要求推导一个应用于状态维度为 $d$ 的系统的、包含 $N$ 个粒子的序贯蒙特卡罗（SMC）粒子滤波器每个时间步的主导阶渐近计算复杂度。总复杂度是其三个组成阶段（传播、权重计算和重采样）的复杂度之和。我们将依次分析每个阶段。\n\n设 $N$ 为粒子数，$d$ 为状态空间 $\\mathbb{R}^{d}$ 的维度。\n\n1.  **传播阶段：**\n    此阶段将 $N$ 个粒子中的每一个从时间 $t_{k}$ 推进到 $t_{k+1}$。此阶段的成本是每个粒子的成本乘以粒子数 $N$。对于单个粒子 $X^{(i)}_{t_{k}}$，更新规则为：\n    $$\n    X^{(i)}_{t_{k+1}} \\;=\\; X^{(i)}_{t_{k}} \\;+\\; f\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta t \\;+\\; G\\!\\big(X^{(i)}_{t_{k}}\\big)\\,\\Delta W^{(i)}_{k}\n    $$\n    单个粒子的计算成本是评估右侧各项并执行向量加法的成本之和。\n    -   漂移项 $f(X^{(i)}_{t_{k}})$ 的评估，据称需要 $\\Theta(d)$ 次运算。随后的标量-向量乘法（乘以 $\\Delta t$）也需要 $\\Theta(d)$ 次运算。\n    -   扩散项的评估涉及形成稠密的 $d \\times d$ 矩阵 $G(X^{(i)}_{t_{k}})$ 并将其与 $d \\times 1$ 向量 $\\Delta W^{(i)}_{k}$ 相乘。稠密矩阵-向量乘积需要 $\\Theta(d^{2})$ 次算术运算。从 $\\mathcal{N}(0, \\Delta t\\,I_{d})$ 生成随机向量 $\\Delta W^{(i)}_{k}$ 涉及抽取 $d$ 个独立的高斯样本，成本为 $\\Theta(d)$。\n    -   两次向量加法每次成本为 $\\Theta(d)$。\n    传播步骤中每个粒子的总成本是这些单个成本的总和：$\\Theta(d) + \\Theta(d) + (\\Theta(d^{2}) + \\Theta(d)) + \\Theta(d) + \\Theta(d)$。此和中的主导项是 $\\Theta(d^{2})$，源于稠密矩阵-向量乘法 $G \\Delta W$。\n    因此，传播一个粒子的复杂度为 $\\Theta(d^{2})$。\n    对于所有 $N$ 个粒子，传播阶段的总复杂度为：\n    $$\n    C_{\\text{prop}} = N \\times \\Theta(d^{2}) = \\Theta(Nd^{2})\n    $$\n\n2.  **权重计算阶段：**\n    此阶段为 $N$ 个传播后的粒子中的每一个计算一个重要性权重。成本同样是每个粒子的成本乘以 $N$。对于单个粒子 $x^{(i)} = X^{(i)}_{t_{k+1}}$ 和观测值 $y_{k+1}$，未归一化的权重与给定粒子状态下观测值的似然成正比。这涉及计算二次型 $Q^{(i)}=(r^{(i)})^{\\top}S^{-1}r^{(i)}$，其中 $r^{(i)}=y_{k+1}-h(x^{(i)})$。\n    -   测量函数 $h(x^{(i)})$ 的评估，据称成本为 $\\Theta(d)$。\n    -   通过向量减法计算残差向量 $r^{(i)}$ 的成本额外为 $\\Theta(d)$。\n    -   二次型 $Q^{(i)}$ 的计算是使用预先计算的 Cholesky 分解 $S = LL^{\\top}$ 来执行的。这包括两个步骤：首先，使用前向替换求解下三角系统 $Lz = r^{(i)}$ 得到 $z$；其次，计算平方范数 $Q^{(i)} = z^{\\top}z = \\|z\\|^{2}$。对于一个稠密的 $d \\times d$ 矩阵 $L$，前向替换的成本为 $\\Theta(d^{2})$ 次运算。随后计算 $d$ 维向量 $z$ 的平方范数的成本为 $\\Theta(d)$。似然的评估，例如 $\\exp(-Q^{(i)}/2)$，是一个成本为 $\\Theta(1)$ 的标量运算。\n    权重计算中每个粒子的总成本是这些成本的总和：$(\\Theta(d) + \\Theta(d)) + (\\Theta(d^{2}) + \\Theta(d)) + \\Theta(1)$。这里的主导项是 $\\Theta(d^{2})$，它来自于求解三角线性系统。\n    因此，为一个粒子计算权重的复杂度为 $\\Theta(d^{2})$。\n    对于所有 $N$ 个粒子，权重计算阶段的总复杂度为：\n    $$\n    C_{\\text{weight}} = N \\times \\Theta(d^{2}) = \\Theta(Nd^{2})\n    $$\n\n3.  **重采样阶段：**\n    此阶段从当前的加权集合中抽取一组新的 $N$ 个粒子，以解决退化问题。问题陈述，系统重采样，涉及计算归一化权重、它们的累积和以及抽取新索引，其总计算成本为 $\\Theta(N)$。此成本显著地与状态维度 $d$ 无关。\n    $$\n    C_{\\text{resample}} = \\Theta(N)\n    $$\n\n**总复杂度和瓶颈**\n每个时间步的总计算复杂度 $C_{\\text{total}}$ 是三个阶段的复杂度之和：\n$$\nC_{\\text{total}} = C_{\\text{prop}} + C_{\\text{weight}} + C_{\\text{resample}} = \\Theta(Nd^{2}) + \\Theta(Nd^{2}) + \\Theta(N)\n$$\n为了找到主导阶渐近复杂度，我们识别出当 $N$ 和 $d$ 变大时增长最快的项。因为 $d \\ge 1$，所以项 $Nd^{2}$ 支配 $N$。\n$$\nC_{\\text{total}} = \\Theta(Nd^{2})\n$$\n计算瓶颈是其复杂度与此主导阶项相匹配的阶段。在此分析中，**传播**阶段和**权重计算**阶段的复杂度均为 $\\Theta(Nd^{2})$。它们的成本随状态维度 $d$ 呈二次方增长，这源于涉及稠密矩阵 $G$ 和 $S$（或其 Cholesky 因子 $L$）的线性代数运算。重采样阶段的复杂度为 $\\Theta(N)$，当 $d>1$ 时不是瓶颈。因此，对于这种粒子滤波器配置，传播和权重计算都是主要的计算负担。\n\n最终答案，按要求以大O表示法表示，是从此分析中得出的主导阶项。", "answer": "$$\n\\boxed{O(Nd^{2})}\n$$", "id": "2990065"}]}