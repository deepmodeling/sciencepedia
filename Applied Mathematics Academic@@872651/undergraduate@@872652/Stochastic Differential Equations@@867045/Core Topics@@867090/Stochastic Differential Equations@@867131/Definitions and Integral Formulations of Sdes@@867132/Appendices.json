{"hands_on_practices": [{"introduction": "Before attempting to solve a stochastic differential equation (SDE), we must first have a precise understanding of what constitutes a \"solution\". Unlike ordinary differential equations, verifying a solution in the stochastic world involves subtle conditions related to measurability, path continuity, and the nature of \"almost sure\" convergence. This exercise challenges you to move beyond formal manipulations and engage with the rigorous definition of an Itô solution, helping you distinguish between a true pathwise solution and weaker, insufficient conditions [@problem_id:3048330].", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\in[0,T]},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions and carrying a standard $1$-dimensional Wiener process $W=(W_t)_{t\\in[0,T]}$. Consider the stochastic differential equation (in the Itô sense)\n$$\ndX_t = b(t,X_t)\\,dt + \\sigma(t,X_t)\\,dW_t,\\quad t\\in[0,T],\\qquad X_0=\\xi,\n$$\nwhere $b:[0,T]\\times\\mathbb{R}\\to\\mathbb{R}$ and $\\sigma:[0,T]\\times\\mathbb{R}\\to\\mathbb{R}$ are Borel measurable and $\\xi$ is $\\mathcal{F}_0$-measurable. You are given a candidate process $X=(X_t)_{t\\in[0,T]}$ taking values in $\\mathbb{R}$.\n\nYour task is to identify which verification procedures correctly establish that $X$ solves the stochastic differential equation above, using only the integral formulation. Select all options that are valid and sufficient procedures, grounded in the definition of an Itô solution and the well-posedness of the relevant integrals.\n\nA. Verify that $X$ is $(\\mathcal{F}_t)$-adapted with almost surely continuous sample paths, that $b(\\cdot,X_{\\cdot})$ is Lebesgue integrable on $[0,T]$ almost surely, and that $\\sigma(\\cdot,X_{\\cdot})$ is progressively measurable and square-integrable on $[0,T]$ almost surely, so that the integrals\n$$\n\\int_0^t b(s,X_s)\\,ds \\quad\\text{and}\\quad \\int_0^t \\sigma(s,X_s)\\,dW_s\n$$\nare well-defined for all $t\\in[0,T]$, and moreover there exists a null set $N\\in\\mathcal{F}$, $\\mathbb{P}(N)=0$, such that for all $\\omega\\in N^{c}$ and all $t\\in[0,T]$,\n$$\nX_t(\\omega) = X_0(\\omega) + \\int_0^t b(s,X_s(\\omega))\\,ds + \\int_0^t \\sigma(s,X_s(\\omega))\\,dW_s(\\omega).\n$$\n\nB. For each fixed $t\\in[0,T]$, verify that there exists a null set $N_t$ (possibly depending on $t$) such that\n$$\nX_t = X_0 + \\int_0^t b(s,X_s)\\,ds + \\int_0^t \\sigma(s,X_s)\\,dW_s\n$$\nholds almost surely (i.e., off $N_t$). It is not necessary to ensure that the exceptional set is the same for different times $t$, nor to verify any measurability or integrability properties of the integrands.\n\nC. Replace the stochastic integral $\\int_0^t \\sigma(s,X_s)\\,dW_s$ by a pathwise Riemann–Stieltjes integral $\\int_0^t \\sigma(s,X_s)\\,dW_s$ defined as a limit of Riemann sums along refining deterministic partitions, and check the integral equation path by path for all $\\omega\\in\\Omega$.\n\nD. Verify the integral equation on the countable dense subset $\\mathbb{Q}\\cap[0,T]$ as follows: show that there exists a null set $N\\in\\mathcal{F}$, $\\mathbb{P}(N)=0$, such that for all $\\omega\\in N^{c}$ and all $q\\in\\mathbb{Q}\\cap[0,T]$,\n$$\nX_q(\\omega) = X_0(\\omega) + \\int_0^q b(s,X_s(\\omega))\\,ds + \\int_0^q \\sigma(s,X_s(\\omega))\\,dW_s(\\omega),\n$$\nand additionally verify that $X$ has almost surely continuous sample paths and that the two integrals define almost surely continuous processes of $t$. Conclude from continuity that the equality holds for all $t\\in[0,T]$ for $\\omega\\in N^{c}$.\n\nE. It is sufficient to verify that for each $t\\in[0,T]$,\n$$\n\\mathbb{E}[X_t] = \\mathbb{E}[X_0] + \\int_0^t \\mathbb{E}[b(s,X_s)]\\,ds,\n$$\nand\n$$\n\\operatorname{Var}(X_t) = \\int_0^t \\mathbb{E}[\\sigma(s,X_s)^2]\\,ds,\n$$\nsince these conditions imply that the integral equation holds almost surely.", "solution": "The problem asks for valid and sufficient procedures to verify if a given process $X = (X_t)_{t\\in[0,T]}$ is a solution to the Itô stochastic differential equation (SDE)\n$$\ndX_t = b(t,X_t)\\,dt + \\sigma(t,X_t)\\,dW_t, \\quad t\\in[0,T], \\quad X_0=\\xi.\n$$\nThe starting point for this analysis is the formal definition of a strong solution to this SDE, which is given in its integral form.\n\nA process $X = (X_t)_{t\\in[0,T]}$ is a strong solution to the SDE if it satisfies the following three conditions:\n1.  $X$ is $(\\mathcal{F}_t)$-adapted and its sample paths are continuous almost surely.\n2.  The coefficient processes satisfy the integrability conditions:\n    $$\n    \\mathbb{P}\\left(\\int_0^T |b(s,X_s)|\\,ds  \\infty\\right) = 1\n    $$\n    and\n    $$\n    \\mathbb{P}\\left(\\int_0^T \\sigma(s,X_s)^2\\,ds  \\infty\\right) = 1.\n    $$\n    These conditions ensure that the Lebesgue integral and the Itô integral, respectively, are well-defined.\n3.  The integral equation\n    $$\n    X_t = X_0 + \\int_0^t b(s,X_s)\\,ds + \\int_0^t \\sigma(s,X_s)\\,dW_s\n    $$\n    holds almost surely for all $t\\in[0,T]$. This means there exists a single null set $N \\subset \\Omega$ such that for every $\\omega \\in N^c$, the equality holds for all $t \\in [0,T]$.\n\nWith this definition as our benchmark, we evaluate each option.\n\n**A. Verify that $X$ is $(\\mathcal{F}_t)$-adapted with almost surely continuous sample paths, that $b(\\cdot,X_{\\cdot})$ is Lebesgue integrable on $[0,T]$ almost surely, and that $\\sigma(\\cdot,X_{\\cdot})$ is progressively measurable and square-integrable on $[0,T]$ almost surely, so that the integrals are well-defined for all $t\\in[0,T]$, and moreover there exists a null set $N\\in\\mathcal{F}$, $\\mathbb{P}(N)=0$, such that for all $\\omega\\in N^{c}$ and all $t\\in[0,T]$, the integral equation holds.**\n\nThis option is a meticulous restatement of the formal definition of a strong solution.\n- It correctly requires $X$ to be adapted and to have a.s. continuous paths.\n- It correctly requires the integrability conditions on the coefficients $b$ and $\\sigma$ that ensure the integrals are well-defined. The requirement that $\\sigma(\\cdot, X_\\cdot)$ be progressively measurable is a standard sufficient condition for the Itô integral to be well-defined.\n- Crucially, it captures the strong requirement that the integral equation must hold for all $t \\in [0,T]$ simultaneously, outside of a single null set $N$. This is the meaning of \"almost surely as processes\".\n\nThis procedure is both valid and sufficient.\nVerdict: **Correct**.\n\n**B. For each fixed $t\\in[0,T]$, verify that there exists a null set $N_t$ (possibly depending on $t$) such that the integral equation holds almost surely (i.e., off $N_t$). It is not necessary to ensure that the exceptional set is the same for different times $t$, nor to verify any measurability or integrability properties of the integrands.**\n\nThis procedure is flawed for two fundamental reasons.\n1.  It fails to verify the well-posedness of the integrals. Without checking the integrability conditions for $b(\\cdot, X_\\cdot)$ and $\\sigma(\\cdot, X_\\cdot)$, the expressions $\\int_0^t b(s,X_s)\\,ds$ and $\\int_0^t \\sigma(s,X_s)\\,dW_s$ may not be defined. A verification procedure cannot omit the prerequisites for its own terms.\n2.  The condition that the equality holds on $\\Omega \\setminus N_t$ for each $t$ is significantly weaker than the definition requires. The union of uncountably many null sets, $\\cup_{t \\in [0,T]} N_t$, is not in general a null set. Therefore, this condition does not guarantee that there exists even a single sample path $\\omega$ for which the equality $X_t(\\omega) = \\dots$ holds for all $t \\in [0,T]$. This weaker property is sometimes called a \"wide-sense\" solution, but it is not what is meant by a solution to an SDE in the standard Itô sense.\n\nVerdict: **Incorrect**.\n\n**C. Replace the stochastic integral $\\int_0^t \\sigma(s,X_s)\\,dW_s$ by a pathwise Riemann–Stieltjes integral $\\int_0^t \\sigma(s,X_s)\\,dW_s$ defined as a limit of Riemann sums along refining deterministic partitions, and check the integral equation path by path for all $\\omega\\in\\Omega$.**\n\nThis procedure fundamentally misunderstands the nature of the Itô integral. The Itô integral is a stochastic integral, not a pathwise Stieltjes-type integral. A key property of the Wiener process $W_t$ is that its sample paths are almost surely of unbounded variation on any interval. Pathwise Riemann–Stieltjes integrals with respect to functions of unbounded variation are generally not well-defined. The theory of stochastic integration (Itô calculus) was specifically developed to define integration with respect to processes like the Wiener process. Attempting to use a Riemann-Stieltjes framework is a categorical error.\n\nVerdict: **Incorrect**.\n\n**D. Verify the integral equation on the countable dense subset $\\mathbb{Q}\\cap[0,T]$ as follows: show that there exists a null set $N\\in\\mathcal{F}$, $\\mathbb{P}(N)=0$, such that for all $\\omega\\in N^{c}$ and all $q\\in\\mathbb{Q}\\cap[0,T]$, the integral equation holds, and additionally verify that $X$ has almost surely continuous sample paths and that the two integrals define almost surely continuous processes of $t$. Conclude from continuity that the equality holds for all $t\\in[0,T]$ for $\\omega\\in N^{c}$.**\n\nThis describes a valid and common technique for verifying the process equality. The argument relies on a standard result from real analysis: if two continuous functions on a closed interval agree on a dense subset of that interval, they must be identical over the entire interval.\nThe procedure requires verifying:\n1.  Both the left-hand side, $L_t(\\omega) = X_t(\\omega)$, and the right-hand side, $R_t(\\omega) = X_0(\\omega) + \\int_0^t b(s,X_s(\\omega))\\,ds + \\int_0^t \\sigma(s,X_s(\\omega))\\,dW_s(\\omega)$, are continuous functions of $t$ for almost all $\\omega$. The continuity of $X_t$ is a direct assumption. The continuity of $R_t$ follows from the fact that the Lebesgue integral of an L$^1$ function is continuous in its upper limit, and a fundamental property of the Itô integral is that it is a process with continuous sample paths (this holds if the integrand is square-integrable a.s., which must be verified for the integral to be well-defined).\n2.  The equality $L_t(\\omega) = R_t(\\omega)$ holds for all $t \\in \\mathbb{Q}\\cap[0,T]$ for almost all $\\omega$ (i.e., on a set of probability $1$).\n\nSince $\\mathbb{Q}\\cap[0,T]$ is dense in $[0,T]$, for any $\\omega$ where both processes are continuous and agree on this dense set, they must agree for all $t \\in [0,T]$. Since the premises hold almost surely, the conclusion (equality for all $t$) holds almost surely. This establishes the existence of a single null set outside of which the equality holds for all $t$, which matches the requirement of the formal definition.\n\nVerdict: **Correct**.\n\n**E. It is sufficient to verify that for each $t\\in[0,T]$, $\\mathbb{E}[X_t] = \\mathbb{E}[X_0] + \\int_0^t \\mathbb{E}[b(s,X_s)]\\,ds$, and $\\operatorname{Var}(X_t) = \\int_0^t \\mathbb{E}[\\sigma(s,X_s)^2]\\,ds$, since these conditions imply that the integral equation holds almost surely.**\n\nThis is incorrect. The SDE defines a relationship between sample paths, which is a much stronger condition than matching moments.\n- The first equation for the mean is a *consequence* of the SDE holding (under conditions that allow interchange of expectation and integration and assuming the Itô integral has zero mean), but it is not sufficient. Many different stochastic processes can have the same mean function.\n- The second equation for the variance is not even generally correct. For a general Itô process $X_t$, the evolution of its variance is more complex. Even if it were correct, it only concerns a second-order moment.\n- The fundamental error is that equality of moments (even all moments) does not, in general, imply almost sure pathwise equality of the processes. The SDE solution is a pathwise statement, and this procedure only checks properties of the marginal distributions of $X_t$ at each time $t$.\n\nVerdict: **Incorrect**.", "answer": "$$\\boxed{AD}$$", "id": "3048330"}, {"introduction": "With a solid definition of a solution in hand, our next step is to develop techniques to find one. This problem invites you to solve one of the most fundamental SDEs: the homogeneous linear SDE, which models geometric Brownian motion. By applying Itô's formula, you will transform the equation into a simpler form and uncover the famous log-normal distribution of its solution, a cornerstone result in financial mathematics and other fields. This practice is essential for building proficiency with Itô calculus and for understanding the statistical properties of stochastic processes [@problem_id:3048360].", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\in [0,T]},\\mathbb{P})$ be a filtered probability space supporting a standard one-dimensional Brownian motion $W$. Let $a:[0,T]\\to\\mathbb{R}$ and $b:[0,T]\\to\\mathbb{R}$ be deterministic Borel functions satisfying $\\int_{0}^{T}\\big(|a(s)|+b(s)^{2}\\big)\\,ds\\infty$. Consider the homogeneous linear Stochastic Differential Equation (SDE)\n$$\ndX_t \\;=\\; a(t)\\,X_t\\,dt \\;+\\; b(t)\\,X_t\\,dW_t,\\qquad X_0 = x_00,\\quad t\\in[0,T].\n$$\nStarting from the integral formulation of the SDE and using only core definitions and properties of the Itô integral and Itô’s formula, derive the distribution of $X_t$ for a fixed $t\\in(0,T]$, show that $X_t$ is log-normal, and compute $\\mathbb{E}[X_t]$ and $\\operatorname{Var}(X_t)$ explicitly in terms of $a$ and $b$. Express your final answer as a $1\\times 2$ row vector whose first entry is $\\mathbb{E}[X_t]$ and whose second entry is $\\operatorname{Var}(X_t)$. No rounding is required.", "solution": "The problem statement is a well-posed exercise in stochastic differential equations. It provides all necessary information: a valid SDE, an initial condition, and standard assumptions on the coefficients and the underlying Brownian motion. The problem is scientifically grounded, objective, and contains no contradictions or ambiguities. Therefore, it is valid, and we may proceed to the solution.\n\nThe stochastic differential equation (SDE) is given by\n$$\ndX_t = a(t)X_t dt + b(t)X_t dW_t\n$$\nwith initial condition $X_0 = x_0  0$, where $t \\in [0, T]$. The functions $a(t)$ and $b(t)$ are deterministic. The integral form of this SDE is\n$$\nX_t = X_0 + \\int_0^t a(s)X_s ds + \\int_0^t b(s)X_s dW_s.\n$$\nTo solve this SDE, we introduce a new process $Y_t$ by the transformation $Y_t = f(X_t) = \\ln(X_t)$. This transformation is well-defined because the solution $X_t$ to this SDE with a positive initial condition $x_0  0$ remains positive for all $t \\ge 0$ almost surely. We apply Itô's formula to $Y_t$. For a twice-differentiable function $f(x)$, Itô's lemma for the process $X_t$ states\n$$\nd f(X_t) = f'(X_t) dX_t + \\frac{1}{2} f''(X_t) (dX_t)^2.\n$$\nIn our case, $f(x) = \\ln(x)$, so we have the derivatives $f'(x) = \\frac{1}{x}$ and $f''(x) = -\\frac{1}{x^2}$. The quadratic variation term $(dX_t)^2$ is computed using the rules of Itô calculus, $(dt)^2=0$, $dt dW_t = 0$, and $(dW_t)^2=dt$:\n$$\n(dX_t)^2 = (a(t)X_t dt + b(t)X_t dW_t)^2 = b(t)^2 X_t^2 (dW_t)^2 = b(t)^2 X_t^2 dt.\n$$\nSubstituting these into Itô's formula for $Y_t = \\ln(X_t)$:\n$$\ndY_t = \\frac{1}{X_t} dX_t + \\frac{1}{2} \\left( -\\frac{1}{X_t^2} \\right) (dX_t)^2\n$$\n$$\ndY_t = \\frac{1}{X_t} (a(t)X_t dt + b(t)X_t dW_t) - \\frac{1}{2X_t^2} (b(t)^2 X_t^2 dt)\n$$\n$$\ndY_t = (a(t) dt + b(t) dW_t) - \\frac{1}{2} b(t)^2 dt\n$$\n$$\ndY_t = \\left( a(t) - \\frac{1}{2} b(t)^2 \\right) dt + b(t) dW_t.\n$$\nThis is a simple SDE for $Y_t$ with an additive noise term. We can solve for $Y_t$ by direct integration from $0$ to $t$:\n$$\nY_t - Y_0 = \\int_0^t \\left( a(s) - \\frac{1}{2} b(s)^2 \\right) ds + \\int_0^t b(s) dW_s.\n$$\nThe initial condition is $Y_0 = \\ln(X_0) = \\ln(x_0)$. Therefore,\n$$\nY_t = \\ln(x_0) + \\int_0^t \\left( a(s) - \\frac{1}{2} b(s)^2 \\right) ds + \\int_0^t b(s) dW_s.\n$$\nNow we can determine the distribution of $Y_t$. The expression for $Y_t$ consists of two parts: a deterministic part and a stochastic integral.\nThe first two terms are deterministic for a fixed $t$:\n$$\n\\mu_Y(t) = \\ln(x_0) + \\int_0^t \\left( a(s) - \\frac{1}{2} b(s)^2 \\right) ds.\n$$\nThe third term is an Itô integral with a deterministic integrand $b(s)$. A fundamental property of the Itô integral is that for a deterministic, square-integrable function $g(s)$, the random variable $Z_t = \\int_0^t g(s) dW_s$ is normally distributed with mean $0$ and variance $\\int_0^t g(s)^2 ds$. In our case, $g(s) = b(s)$, so the stochastic integral $\\int_0^t b(s) dW_s$ is a normal random variable with mean $\\mathbb{E}[\\int_0^t b(s) dW_s] = 0$ and variance $\\operatorname{Var}(\\int_0^t b(s) dW_s) = \\int_0^t b(s)^2 ds$.\n\nThus, $Y_t$ is the sum of a constant and a normal random variable, which means $Y_t$ itself is a normal random variable. Its distribution is\n$$\nY_t \\sim \\mathcal{N}\\left( \\ln(x_0) + \\int_0^t \\left( a(s) - \\frac{1}{2} b(s)^2 \\right) ds, \\int_0^t b(s)^2 ds \\right).\n$$\nSince $X_t = \\exp(Y_t)$ and $Y_t$ is normally distributed, the random variable $X_t$ has a log-normal distribution by definition. This proves the first part of the problem.\n\nTo compute the expectation and variance of $X_t$, we use the properties of the log-normal distribution. If $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then for any real number $k$, the $k$-th moment of $X = \\exp(Y)$ is given by\n$$\n\\mathbb{E}[X^k] = \\mathbb{E}[\\exp(kY)] = \\exp\\left( k\\mu + \\frac{1}{2}k^2\\sigma^2 \\right).\n$$\nFor our process $X_t = \\exp(Y_t)$, we have:\n$$\n\\mu_t = \\mathbb{E}[Y_t] = \\ln(x_0) + \\int_0^t \\left( a(s) - \\frac{1}{2}b(s)^2 \\right) ds\n$$\n$$\n\\sigma_t^2 = \\operatorname{Var}(Y_t) = \\int_0^t b(s)^2 ds\n$$\nThe expectation of $X_t$ corresponds to the first moment ($k=1$):\n$$\n\\mathbb{E}[X_t] = \\exp\\left( \\mu_t + \\frac{1}{2}\\sigma_t^2 \\right)\n$$\n$$\n\\mathbb{E}[X_t] = \\exp\\left( \\left[ \\ln(x_0) + \\int_0^t \\left( a(s) - \\frac{1}{2}b(s)^2 \\right) ds \\right] + \\frac{1}{2} \\int_0^t b(s)^2 ds \\right)\n$$\n$$\n\\mathbb{E}[X_t] = \\exp\\left( \\ln(x_0) + \\int_0^t a(s) ds - \\frac{1}{2}\\int_0^t b(s)^2 ds + \\frac{1}{2}\\int_0^t b(s)^2 ds \\right)\n$$\n$$\n\\mathbb{E}[X_t] = \\exp\\left( \\ln(x_0) + \\int_0^t a(s) ds \\right) = x_0 \\exp\\left( \\int_0^t a(s) ds \\right).\n$$\nTo find the variance, we first compute the second moment $\\mathbb{E}[X_t^2]$ (using $k=2$):\n$$\n\\mathbb{E}[X_t^2] = \\exp\\left( 2\\mu_t + \\frac{1}{2}(2^2)\\sigma_t^2 \\right) = \\exp\\left( 2\\mu_t + 2\\sigma_t^2 \\right)\n$$\n$$\n\\mathbb{E}[X_t^2] = \\exp\\left( 2\\left[ \\ln(x_0) + \\int_0^t \\left( a(s) - \\frac{1}{2}b(s)^2 \\right) ds \\right] + 2 \\int_0^t b(s)^2 ds \\right)\n$$\n$$\n\\mathbb{E}[X_t^2] = \\exp\\left( 2\\ln(x_0) + 2\\int_0^t a(s) ds - \\int_0^t b(s)^2 ds + 2\\int_0^t b(s)^2 ds \\right)\n$$\n$$\n\\mathbb{E}[X_t^2] = \\exp\\left( 2\\ln(x_0) + 2\\int_0^t a(s) ds + \\int_0^t b(s)^2 ds \\right)\n$$\n$$\n\\mathbb{E}[X_t^2] = x_0^2 \\exp\\left( 2\\int_0^t a(s) ds + \\int_0^t b(s)^2 ds \\right).\n$$\nThe variance is given by $\\operatorname{Var}(X_t) = \\mathbb{E}[X_t^2] - (\\mathbb{E}[X_t])^2$:\n$$\n\\operatorname{Var}(X_t) = x_0^2 \\exp\\left( 2\\int_0^t a(s) ds + \\int_0^t b(s)^2 ds \\right) - \\left( x_0 \\exp\\left( \\int_0^t a(s) ds \\right) \\right)^2\n$$\n$$\n\\operatorname{Var}(X_t) = x_0^2 \\exp\\left( 2\\int_0^t a(s) ds \\right) \\exp\\left( \\int_0^t b(s)^2 ds \\right) - x_0^2 \\exp\\left( 2\\int_0^t a(s) ds \\right)\n$$\nFactoring out the common term $x_0^2 \\exp\\left( 2\\int_0^t a(s) ds \\right)$, we obtain:\n$$\n\\operatorname{Var}(X_t) = x_0^2 \\exp\\left( 2\\int_0^t a(s) ds \\right) \\left[ \\exp\\left( \\int_0^t b(s)^2 ds \\right) - 1 \\right].\n$$\nThe two required quantities are the expectation $\\mathbb{E}[X_t]$ and the variance $\\operatorname{Var}(X_t)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} x_0 \\exp\\left( \\int_0^t a(s) \\, ds \\right)  x_0^2 \\exp\\left( 2\\int_0^t a(s) \\, ds \\right) \\left[ \\exp\\left( \\int_0^t b(s)^2 \\, ds \\right) - 1 \\right] \\end{pmatrix}}\n$$", "id": "3048360"}, {"introduction": "The world of stochastic calculus is governed by rules that depend on the chosen definition of the stochastic integral, with the Itô and Stratonovich integrals being the two dominant conventions. The Itô integral is a martingale, which simplifies many theoretical proofs, while the Stratonovich integral obeys the standard chain rule from ordinary calculus, making it intuitive for modeling physical systems. This exercise guides you through the crucial derivation of the conversion formula between these two frameworks, a practical skill necessary for correctly interpreting and manipulating SDEs from different scientific domains [@problem_id:3048335].", "problem": "Consider an $n$-dimensional stochastic differential equation (SDE) in the Stratonovich sense for a process $X_{t} \\in \\mathbb{R}^{n}$ driven by an $m$-dimensional standard Brownian motion (BM) $W_{t} \\in \\mathbb{R}^{m}$:\n$$\nX_{t} = X_{0} + \\int_{0}^{t} \\alpha\\!\\left(X_{s}\\right)\\,\\mathrm{d}s + \\int_{0}^{t} b\\!\\left(X_{s}\\right) \\circ \\mathrm{d}W_{s},\n$$\nwhere $\\alpha : \\mathbb{R}^{n} \\to \\mathbb{R}^{n}$ is continuously differentiable and $b : \\mathbb{R}^{n} \\to \\mathbb{R}^{n \\times m}$ has columns $b^{(k)}(x) \\in \\mathbb{R}^{n}$, $k = 1,\\dots,m$, each twice continuously differentiable with appropriate growth and Lipschitz conditions ensuring existence and uniqueness of solutions and well-defined stochastic integrals. The integral $\\int_{0}^{t} b(X_{s}) \\circ \\mathrm{d}W_{s}$ is to be understood in the Stratonovich sense via midpoint Riemann sums, while $\\int_{0}^{t} b(X_{s})\\,\\mathrm{d}W_{s}$ is the Itô integral defined via left-point Riemann sums.\n\nStarting only from the integral definitions of the Itô and Stratonovich integrals for semimartingale integrands and the quadratic variation properties of Brownian motion, derive the drift correction vector $\\Delta(x)$ that must be added to the Stratonovich drift $\\alpha(x)$ so that the corresponding Itô-form SDE,\n$$\nX_{t} = X_{0} + \\int_{0}^{t} \\big(\\alpha\\!\\left(X_{s}\\right) + \\Delta\\!\\left(X_{s}\\right)\\big)\\,\\mathrm{d}s + \\int_{0}^{t} b\\!\\left(X_{s}\\right)\\,\\mathrm{d}W_{s},\n$$\nhas the same solution process $\\{X_{t}\\}_{t \\ge 0}$.\n\nExpress your final answer for $\\Delta(x)$ as a single closed-form analytic expression in terms of the diffusion matrix $b(x)$ and the Jacobians of its columns. Let $J_{b^{(k)}}(x) \\in \\mathbb{R}^{n \\times n}$ denote the Jacobian matrix of the vector field $b^{(k)}(x)$. Your final answer must be a single expression and not an equation. No numerical approximation or rounding is required.", "solution": "The objective is to derive the drift correction vector $\\Delta(x)$ that links the Stratonovich and Itô representations of a given stochastic differential equation (SDE). We are given the Stratonovich SDE:\n$$\n\\mathrm{d}X_{t} = \\alpha(X_{t})\\,\\mathrm{d}t + b(X_{t}) \\circ \\mathrm{d}W_{t}\n\\tag{1}\n$$\nand its equivalent Itô form:\n$$\n\\mathrm{d}X_{t} = \\left(\\alpha(X_{t}) + \\Delta(X_{t})\\right)\\,\\mathrm{d}t + b(X_{t})\\,\\mathrm{d}W_{t}\n\\tag{2}\n$$\nwhere $X_t \\in \\mathbb{R}^n$, $W_t \\in \\mathbb{R}^m$, $\\alpha: \\mathbb{R}^n \\to \\mathbb{R}^n$, and $b: \\mathbb{R}^n \\to \\mathbb{R}^{n \\times m}$. The columns of the matrix $b(x)$ are denoted by $b^{(k)}(x)$ for $k=1, \\dots, m$.\n\nThe fundamental difference between the Itô and Stratonovich integrals lies in their definitions as limits of Riemann sums. The Itô integral uses the left endpoint of the time interval for evaluation of the integrand, while the Stratonovich integral uses the midpoint.\n\nLet us express the Stratonovich stochastic term as a sum over the components of the Brownian motion $W_t$:\n$$\n\\int_{0}^{t} b(X_{s}) \\circ \\mathrm{d}W_{s} = \\sum_{k=1}^{m} \\int_{0}^{t} b^{(k)}(X_{s}) \\circ \\mathrm{d}W_{s}^{(k)}\n$$\nWe will analyze a single term $\\int_{0}^{t} b^{(k)}(X_{s}) \\circ \\mathrm{d}W_{s}^{(k)}$. Let's consider a partition of the interval $[0, t]$ as $0 = t_0  t_1  \\dots  t_N = t$. The Stratonovich integral is the limit of the sum:\n$$\nS_N^{(k)} = \\sum_{i=0}^{N-1} b^{(k)}\\left(\\frac{X_{t_{i+1}} + X_{t_i}}{2}\\right) (W_{t_{i+1}}^{(k)} - W_{t_i}^{(k)})\n$$\nWe can rewrite the evaluation point of $b^{(k)}$ as $X_{t_i} + \\frac{1}{2}(X_{t_{i+1}} - X_{t_i})$. Let $\\Delta X_{t_i} = X_{t_{i+1}} - X_{t_i}$ and $\\Delta W_{t_i}^{(k)} = W_{t_{i+1}}^{(k)} - W_{t_i}^{(k)}$.\n\nWith the assumption that $b^{(k)}$ is twice continuously differentiable, we can perform a Taylor expansion of $b^{(k)}(x)$ around $X_{t_i}$:\n$$\nb^{(k)}\\left(X_{t_i} + \\frac{1}{2}\\Delta X_{t_i}\\right) = b^{(k)}(X_{t_i}) + \\frac{1}{2} J_{b^{(k)}}(X_{t_i}) \\Delta X_{t_i} + O\\left(\\|\\Delta X_{t_i}\\|^2\\right)\n$$\nwhere $J_{b^{(k)}}(x)$ is the $n \\times n$ Jacobian matrix of the vector field $b^{(k)}(x)$, whose $(p,q)$-th entry is $\\frac{\\partial b_{p}^{(k)}}{\\partial x_q}(x) = \\frac{\\partial b_{pk}}{\\partial x_q}(x)$.\n\nSubstituting this expansion into the sum $S_N^{(k)}$:\n$$\nS_N^{(k)} = \\sum_{i=0}^{N-1} \\left( b^{(k)}(X_{t_i}) + \\frac{1}{2} J_{b^{(k)}}(X_{t_i}) \\Delta X_{t_i} \\right) \\Delta W_{t_i}^{(k)} + \\sum_{i=0}^{N-1} O\\left(\\|\\Delta X_{t_i}\\|^2\\right) \\Delta W_{t_i}^{(k)}\n$$\nThe first term in the parentheses, $\\sum_{i=0}^{N-1} b^{(k)}(X_{t_i}) \\Delta W_{t_i}^{(k)}$, corresponds to the Riemann sum defining the Itô integral $\\int_{0}^{t} b^{(k)}(X_{s}) \\mathrm{d}W_{s}^{(k)}$.\n\nFor the second term, we need to approximate $\\Delta X_{t_i}$. From the Itô form of the SDE (Equation 2), the lowest order approximation for the increment $\\Delta X_{t_i}$ over a small interval $\\Delta t_i = t_{i+1}-t_i$ is determined by the stochastic part, since $\\mathrm{d}t$ is of a lower order than $\\sqrt{\\mathrm{d}t}$:\n$$\n\\Delta X_{t_i} \\approx b(X_{t_i}) \\Delta W_{t_i} = \\sum_{l=1}^{m} b^{(l)}(X_{t_i}) \\Delta W_{t_i}^{(l)}\n$$\nWe substitute this approximation for $\\Delta X_{t_i}$ into the second part of the sum:\n$$\n\\frac{1}{2} \\sum_{i=0}^{N-1} J_{b^{(k)}}(X_{t_i}) \\left( \\sum_{l=1}^{m} b^{(l)}(X_{t_i}) \\Delta W_{t_i}^{(l)} \\right) \\Delta W_{t_i}^{(k)} = \\frac{1}{2} \\sum_{l=1}^{m} \\sum_{i=0}^{N-1} J_{b^{(k)}}(X_{t_i}) b^{(l)}(X_{t_i}) \\Delta W_{t_i}^{(l)} \\Delta W_{t_i}^{(k)}\n$$\nAs the partition becomes finer (i.e., $\\max_i \\Delta t_i \\to 0$), we use the quadratic covariation property of independent standard Brownian motions:\n$$\n\\sum_{i=0}^{N-1} \\Delta W_{t_i}^{(l)} \\Delta W_{t_i}^{(k)} \\longrightarrow [W^{(l)}, W^{(k)}]_t = \\delta_{kl} t\n$$\nwhere $\\delta_{kl}$ is the Kronecker delta. In differential form, this is written as $\\mathrm{d}W_{t}^{(l)} \\mathrm{d}W_{t}^{(k)} = \\delta_{kl} \\mathrm{d}t$.\nThe sum therefore converges to a standard Riemann integral with respect to time:\n$$\n\\frac{1}{2} \\sum_{l=1}^{m} \\int_{0}^{t} J_{b^{(k)}}(X_{s}) b^{(l)}(X_{s}) \\delta_{kl} \\mathrm{d}s = \\frac{1}{2} \\int_{0}^{t} J_{b^{(k)}}(X_{s}) b^{(k)}(X_{s}) \\mathrm{d}s\n$$\nThe higher-order terms involving $O(\\|\\Delta X_{t_i}\\|^2)$ vanish in the limit.\n\nCombining the results, we find the relationship between the Stratonovich and Itô integrals for the $k$-th component:\n$$\n\\int_{0}^{t} b^{(k)}(X_{s}) \\circ \\mathrm{d}W_{s}^{(k)} = \\int_{0}^{t} b^{(k)}(X_{s}) \\mathrm{d}W_{s}^{(k)} + \\frac{1}{2} \\int_{0}^{t} J_{b^{(k)}}(X_{s}) b^{(k)}(X_{s}) \\mathrm{d}s\n$$\nSumming over all components $k=1, \\dots, m$:\n$$\n\\int_{0}^{t} b(X_{s}) \\circ \\mathrm{d}W_{s} = \\int_{0}^{t} b(X_{s}) \\mathrm{d}W_{s} + \\frac{1}{2} \\int_{0}^{t} \\sum_{k=1}^{m} J_{b^{(k)}}(X_{s}) b^{(k)}(X_{s}) \\mathrm{d}s\n$$\nNow we substitute this expression back into the Stratonovich SDE (Equation 1):\n$$\nX_{t} = X_{0} + \\int_{0}^{t} \\alpha(X_{s})\\,\\mathrm{d}s + \\int_{0}^{t} b(X_{s})\\,\\mathrm{d}W_{s} + \\frac{1}{2} \\int_{0}^{t} \\sum_{k=1}^{m} J_{b^{(k)}}(X_{s}) b^{(k)}(X_{s}) \\mathrm{d}s\n$$\nGrouping the $\\mathrm{d}s$ terms:\n$$\nX_{t} = X_{0} + \\int_{0}^{t} \\left( \\alpha(X_{s}) + \\frac{1}{2} \\sum_{k=1}^{m} J_{b^{(k)}}(X_{s}) b^{(k)}(X_{s}) \\right)\\,\\mathrm{d}s + \\int_{0}^{t} b(X_{s})\\,\\mathrm{d}W_{s}\n$$\nBy comparing this with the Itô SDE form (Equation 2), we can identify the drift correction term $\\Delta(x)$:\n$$\n\\alpha(x) + \\Delta(x) = \\alpha(x) + \\frac{1}{2} \\sum_{k=1}^{m} J_{b^{(k)}}(x) b^{(k)}(x)\n$$\nTherefore, the drift correction vector is:\n$$\n\\Delta(x) = \\frac{1}{2} \\sum_{k=1}^{m} J_{b^{(k)}}(x) b^{(k)}(x)\n$$\nThis vector $\\Delta(x)$ is often referred to as the Itô-Stratonovich correction term. In component form, the $j$-th component of $\\Delta(x)$ is given by $\\Delta_j(x) = \\frac{1}{2} \\sum_{k=1}^{m} \\sum_{i=1}^{n} b_{ik}(x) \\frac{\\partial b_{jk}}{\\partial x_i}(x)$.", "answer": "$$\\boxed{\\frac{1}{2} \\sum_{k=1}^{m} J_{b^{(k)}}(x) b^{(k)}(x)}$$", "id": "3048335"}]}