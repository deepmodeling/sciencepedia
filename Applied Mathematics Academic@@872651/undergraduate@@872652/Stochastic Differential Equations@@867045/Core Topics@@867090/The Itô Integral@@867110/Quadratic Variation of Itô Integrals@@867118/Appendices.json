{"hands_on_practices": [{"introduction": "A central idea in stochastic calculus is that a semimartingale can be viewed as the sum of a \"rough\" martingale component and a \"smooth\" drift component. This first exercise challenges you to prove a foundational result: that the quadratic variation of a process is insensitive to its drift. By working through this problem [@problem_id:3071350], you will solidify your understanding that quadratic variation exclusively measures the volatility inherent in the martingale part, a key distinction from classical calculus.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t\\geq 0},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions, and let $W=(W_t)_{t\\geq 0}$ be a standard Brownian motion adapted to $(\\mathcal{F}_t)_{t\\geq 0}$. Fix $t0$. Let $\\sigma=(\\sigma_s)_{0\\leq s\\leq t}$ and $\\mu=(\\mu_s)_{0\\leq s\\leq t}$ be bounded, $(\\mathcal{F}_s)_{s\\geq 0}$-predictable processes such that $\\int_{0}^{t}\\sigma_s^{2}\\,ds\\infty$ almost surely. Define the continuous local martingale $M=(M_s)_{0\\leq s\\leq t}$ by\n$$\nM_s=\\int_{0}^{s}\\sigma_u\\,dW_u,\n$$\nand the finite variation process $A=(A_s)_{0\\leq s\\leq t}$ by\n$$\nA_s=\\int_{0}^{s}\\mu_u\\,du.\n$$\nConsider the continuous semimartingale $X=(X_s)_{0\\leq s\\leq t}$ given by $X_s=M_s+A_s$. Using the definition of Quadratic Variation (QV) as the limit of sums of squared increments along refining time partitions and only foundational properties of stochastic integrals (such as Itô isometry), compute the quadratic variation $[X]_t$. Express your final answer as a closed-form symbolic expression in terms of $\\sigma$. This computation should make clear that adding a finite variation process can change drift but does not change quadratic variation. No numerical approximation is required.", "solution": "The problem requires the computation of the quadratic variation $[X]_t$ for the continuous semimartingale $X_s = M_s + A_s$, where $M_s = \\int_{0}^{s} \\sigma_u \\, dW_u$ is a continuous local martingale and $A_s = \\int_{0}^{s} \\mu_u \\, du$ is a continuous finite variation process. The computation must be based on the definition of quadratic variation as the limit of sums of squared increments.\n\nLet $\\Pi_n = \\{0 = t_0^{(n)}  t_1^{(n)}  \\dots  t_{k_n}^{(n)} = t\\}$ be a sequence of partitions of the interval $[0, t]$ such that the mesh of the partition, $\\|\\Pi_n\\| = \\max_{j} (t_{j+1}^{(n)} - t_j^{(n)})$, converges to $0$ as $n \\to \\infty$. The quadratic variation of the process $X$ at time $t$, denoted $[X]_t$, is defined as the limit in probability of the sum of squared increments over this sequence of partitions:\n$$\n[X]_t = \\operatorname{p-lim}_{n \\to \\infty} \\sum_{j=0}^{k_n-1} (X_{t_{j+1}^{(n)}} - X_{t_j^{(n)}})^2\n$$\n\nLet's denote the increment of a process $Y$ over the interval $[t_j^{(n)}, t_{j+1}^{(n)}]$ as $\\Delta Y_j^{(n)} = Y_{t_{j+1}^{(n)}} - Y_{t_j^{(n)}}$. For simplicity, we will drop the superscript $(n)$ in the notation for the partition points and increments, writing $t_j$ and $\\Delta Y_j$. The increment of $X$ is given by:\n$$\n\\Delta X_j = X_{t_{j+1}} - X_{t_j} = (M_{t_{j+1}} + A_{t_{j+1}}) - (M_{t_j} + A_{t_j}) = (M_{t_{j+1}} - M_{t_j}) + (A_{t_{j+1}} - A_{t_j}) = \\Delta M_j + \\Delta A_j\n$$\nThe sum of squared increments can be expanded as:\n$$\n\\sum_{j=0}^{k_n-1} (\\Delta X_j)^2 = \\sum_{j=0}^{k_n-1} (\\Delta M_j + \\Delta A_j)^2 = \\sum_{j=0}^{k_n-1} (\\Delta M_j)^2 + 2\\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) + \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2\n$$\nBy the properties of limits in probability, the quadratic variation $[X]_t$ is the sum of the limits of these three terms, provided they exist:\n$$\n[X]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta M_j)^2 + 2 \\cdot \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) + \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2\n$$\nThese three limits correspond to the quadratic variations $[M]_t$, $[A]_t$, and the covariation $[M, A]_t$, respectively. We will analyze each term individually.\n\nFirst, consider the term involving the finite variation process $A_s = \\int_{0}^{s} \\mu_u \\, du$. The process $\\mu = (\\mu_s)_{0 \\le s \\le t}$ is given as bounded. This means there exists a constant $K  0$ such that $|\\mu_s(\\omega)| \\le K$ for almost all $(\\omega, s) \\in \\Omega \\times [0, t]$. The increment $\\Delta A_j$ is:\n$$\n\\Delta A_j = A_{t_{j+1}} - A_{t_j} = \\int_{t_j}^{t_{j+1}} \\mu_u \\, du\n$$\nWe can bound its absolute value:\n$$\n|\\Delta A_j| = \\left| \\int_{t_j}^{t_{j+1}} \\mu_u \\, du \\right| \\le \\int_{t_j}^{t_{j+1}} |\\mu_u| \\, du \\le K (t_{j+1} - t_j) = K \\Delta t_j\n$$\nNow, consider the sum of squared increments of $A$:\n$$\n0 \\le \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 \\le \\sum_{j=0}^{k_n-1} (K \\Delta t_j)^2 = K^2 \\sum_{j=0}^{k_n-1} (\\Delta t_j)^2\n$$\nWe can further bound this sum:\n$$\n\\sum_{j=0}^{k_n-1} (\\Delta t_j)^2 \\le \\left( \\max_{0 \\le j \\le k_n-1} \\Delta t_j \\right) \\left( \\sum_{j=0}^{k_n-1} \\Delta t_j \\right) = \\|\\Pi_n\\| \\cdot t\n$$\nCombining these inequalities, we have:\n$$\n0 \\le \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 \\le K^2 t \\|\\Pi_n\\|\n$$\nAs $\\|\\Pi_n\\| \\to 0$, the right-hand side converges to $0$. By the Squeeze Theorem, the sum of squared increments for $A$ also converges to $0$. Thus, the quadratic variation of the finite variation process $A$ is zero:\n$$\n[A]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 = 0\n$$\n\nNext, we analyze the cross term, which defines the covariation $[M, A]_t$. We use the Cauchy-Schwarz inequality for sums:\n$$\n\\left| \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) \\right| \\le \\left( \\sum_{j=0}^{k_n-1} (\\Delta M_j)^2 \\right)^{1/2} \\left( \\sum_{j=0}^{k_n-1} (\\Delta A_j)^2 \\right)^{1/2}\n$$\nTaking the limit as $\\|\\Pi_n\\| \\to 0$, we have already shown that the second term on the right-hand side converges to $\\sqrt{[A]_t} = \\sqrt{0} = 0$. The first term on the right-hand side converges in probability to $\\sqrt{[M]_t}$. Since $\\int_0^t \\sigma_s^2 ds  \\infty$ almost surely, $[M]_t$ is an almost surely finite random variable. Therefore, the product converges in probability to $0$:\n$$\n\\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\left| \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) \\right| = 0\n$$\nThis implies that the covariation is zero:\n$$\n[M, A]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} (\\Delta M_j)(\\Delta A_j) = 0\n$$\n\nFinally, we consider the first term, $\\sum_{j=0}^{k_n-1} (\\Delta M_j)^2$. The process $M$ is defined as the Itô integral $M_s = \\int_{0}^{s} \\sigma_u \\, dW_u$. A foundational result in the theory of stochastic integration is that the quadratic variation of such a process is given by the integral of the square of the integrand. That is:\n$$\n[M]_t = \\operatorname{p-lim}_{\\|\\Pi_n\\| \\to 0} \\sum_{j=0}^{k_n-1} \\left( \\int_{t_j}^{t_{j+1}} \\sigma_u \\, dW_u \\right)^2 = \\int_0^t \\sigma_s^2 \\, ds\n$$\nThe problem statement allows the use of such foundational properties.\n\nCombining the results for the three terms, we find the quadratic variation of $X_t$:\n$$\n[X]_t = [M]_t + 2[M, A]_t + [A]_t = \\int_0^t \\sigma_s^2 \\, ds + 2(0) + 0 = \\int_0^t \\sigma_s^2 \\, ds\n$$\nThis derivation makes it clear that the addition of a continuous process of finite variation, $A_s$, which alters the drift of the process $X_s$, does not affect its quadratic variation. The quadratic variation is determined solely by the local martingale part, $M_s$.", "answer": "$$\n\\boxed{\\int_{0}^{t}\\sigma_s^{2}\\,ds}\n$$", "id": "3071350"}, {"introduction": "Now that we've established that quadratic variation isolates the martingale component, let's apply this insight to a classic example: the process $X_t = B_t^2$. This practice guides you to first decompose the process into its martingale and finite variation parts using Itô's formula. Calculating the quadratic variation from this decomposition provides a concrete verification of the principle from our previous exercise [@problem_id:3071350] and deepens your skill in applying the core formula of Itô calculus.", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion starting at $B_{0}=0$. Define the process $X_{t} = B_{t}^{2}$ for $t \\geq 0$. Using only fundamental properties of Brownian motion and the definition of quadratic variation for continuous semimartingales, derive an explicit expression for the quadratic variation $[X]_{t}$ as a functional of the Brownian path $\\{B_{s}\\}_{0 \\leq s \\leq t}$. Then, explain how your expression is consistent with the decomposition $X_{t} = 2 \\int_{0}^{t} B_{s} \\, dB_{s} + [B]_{t}$ obtained from Itô's formula, where $[B]_{t}$ denotes the quadratic variation of Brownian motion. Provide your final answer for $[X]_{t}$ as a single closed-form expression. No rounding is required.", "solution": "The solution proceeds in two parts as requested. First, we derive the quadratic variation $[X]_t$ from its definition. Second, we demonstrate consistency with the result obtained via Itô's formula.\n\n**Part 1: Derivation of $[X]_t$ from the Definition**\n\nLet $X_t$ be a continuous semimartingale. Its quadratic variation over the interval $[0, t]$, denoted $[X]_t$, is defined as the limit in probability of the sum of squared increments over a sequence of partitions of the interval. Let $\\Pi_n = \\{0 = t_0^{(n)}  t_1^{(n)}  \\dots  t_{k_n}^{(n)} = t\\}$ be a sequence of partitions of $[0, t]$ such that the mesh $\\|\\Pi_n\\| = \\max_{i} (t_{i+1}^{(n)} - t_i^{(n)})$ approaches $0$ as $n \\to \\infty$. The quadratic variation is given by:\n$$ [X]_t = \\operatorname*{p-lim}_{n \\to \\infty} \\sum_{i=0}^{k_n-1} (X_{t_{i+1}^{(n)}} - X_{t_i^{(n)}})^2 $$\nFor simplicity, we will drop the superscript $(n)$ and let $\\|\\pi\\| \\to 0$. The process is $X_t = B_t^2$. The increment of $X_t$ over a subinterval $[t_i, t_{i+1}]$ is:\n$$ X_{t_{i+1}} - X_{t_i} = B_{t_{i+1}}^2 - B_{t_i}^2 $$\nLet $\\Delta B_i = B_{t_{i+1}} - B_{t_i}$. We can write $B_{t_{i+1}} = B_{t_i} + \\Delta B_i$. The increment of $X_t$ can be expanded as:\n$$ X_{t_{i+1}} - X_{t_i} = (B_{t_{i+1}} - B_{t_i})(B_{t_{i+1}} + B_{t_i}) = (\\Delta B_i)(B_{t_i} + \\Delta B_i + B_{t_i}) = 2B_{t_i}\\Delta B_i + (\\Delta B_i)^2 $$\nNow, we must square this increment and sum over the partition:\n$$ \\sum_{i=0}^{k-1} (X_{t_{i+1}} - X_{t_i})^2 = \\sum_{i=0}^{k-1} (2B_{t_i}\\Delta B_i + (\\Delta B_i)^2)^2 $$\nExpanding the squared term:\n$$ (2B_{t_i}\\Delta B_i + (\\Delta B_i)^2)^2 = 4B_{t_i}^2 (\\Delta B_i)^2 + 4B_{t_i} (\\Delta B_i)^3 + (\\Delta B_i)^4 $$\nWe analyze the limit of the sum of each of these three terms as $\\|\\pi\\| \\to 0$.\n\n1.  **First term:** $\\sum_{i=0}^{k-1} 4B_{t_i}^2 (\\Delta B_i)^2$.\n    This sum is a stochastic integral in disguise. For a continuous process $Y_s$, the integral $\\int_0^t Y_s d[B]_s$ can be defined as the limit in probability of the sums $\\sum_i Y_{t_i} ([B]_{t_{i+1}} - [B]_{t_i})$. Since for standard Brownian motion, $[B]_t = t$, this is $\\int_0^t Y_s ds$. The sum $\\sum_i Y_{t_i} (\\Delta B_i)^2$ is a discrete approximation to this integral. The process $Y_s = 4B_s^2$ is continuous. It is a standard result in stochastic calculus that\n    $$ \\operatorname*{p-lim}_{\\|\\pi\\| \\to 0} \\sum_{i=0}^{k-1} 4B_{t_i}^2 (\\Delta B_i)^2 = \\int_0^t 4B_s^2 d[B]_s $$\n    Since $d[B]_s = ds$ for standard Brownian motion, the limit is:\n    $$ \\int_0^t 4B_s^2 ds $$\n\n2.  **Second term:** $\\sum_{i=0}^{k-1} 4B_{t_i} (\\Delta B_i)^3$.\n    We show that this term converges to $0$ in $L^1$, which implies convergence in probability. The increment $\\Delta B_i = B_{t_{i+1}} - B_{t_i}$ is independent of the sigma-algebra $\\mathcal{F}_{t_i}$, to which $B_{t_i}$ is adapted. Let $\\Delta t_i = t_{i+1} - t_i$. The moments of $\\Delta B_i \\sim \\mathcal{N}(0, \\Delta t_i)$ are $E[\\Delta B_i] = 0$, $E[(\\Delta B_i)^2] = \\Delta t_i$, $E[|\\Delta B_i|^3] = E[|Z|^3](\\Delta t_i)^{3/2}$ where $Z \\sim \\mathcal{N}(0,1)$, and $E[(\\Delta B_i)^3] = 0$.\n    The expectation of the absolute value of the sum is:\n    $$ E\\left[ \\left| \\sum_{i=0}^{k-1} 4B_{t_i} (\\Delta B_i)^3 \\right| \\right] \\leq \\sum_{i=0}^{k-1} 4 E\\left[ |B_{t_i} (\\Delta B_i)^3| \\right] = \\sum_{i=0}^{k-1} 4 E[|B_{t_i}|] E[|(\\Delta B_i)^3|] $$\n    $E[|B_{t_i}|] = \\sqrt{2/\\pi}\\sqrt{t_i} \\leq \\sqrt{2t/\\pi}$ for $t_i \\in [0, t]$. Let $C_3 = E[|Z|^3]$, a constant.\n    $$ \\leq \\sum_{i=0}^{k-1} 4 \\sqrt{\\frac{2t}{\\pi}} C_3 (\\Delta t_i)^{3/2} \\leq 4 \\sqrt{\\frac{2t}{\\pi}} C_3 \\sqrt{\\|\\pi\\|} \\sum_{i=0}^{k-1} \\Delta t_i = 4 t \\sqrt{\\frac{2t}{\\pi}} C_3 \\sqrt{\\|\\pi\\|} $$\n    As $\\|\\pi\\| \\to 0$, this upper bound goes to $0$. Thus, the sum converges to $0$ in $L^1$.\n\n3.  **Third term:** $\\sum_{i=0}^{k-1} (\\Delta B_i)^4$.\n    We again show this term converges to $0$ in $L^1$.\n    $$ E\\left[ \\sum_{i=0}^{k-1} (\\Delta B_i)^4 \\right] = \\sum_{i=0}^{k-1} E[(\\Delta B_i)^4] $$\n    For a normal random variable $Y \\sim N(0, \\sigma^2)$, $E[Y^4] = 3\\sigma^4$. Here, $\\sigma^2 = \\Delta t_i$.\n    $$ E\\left[ \\sum_{i=0}^{k-1} (\\Delta B_i)^4 \\right] = \\sum_{i=0}^{k-1} 3(\\Delta t_i)^2 \\leq 3 \\|\\pi\\| \\sum_{i=0}^{k-1} \\Delta t_i = 3t\\|\\pi\\| $$\n    As $\\|\\pi\\| \\to 0$, the expectation goes to $0$. Thus, the sum converges to $0$ in $L^1$.\n\nCombining the limits of the three terms, we find:\n$$ [X]_t = \\int_0^t 4B_s^2 ds + 0 + 0 = 4\\int_0^t B_s^2 ds $$\nThis expression is a functional of the Brownian path $\\{B_s\\}_{0 \\leq s \\leq t}$.\n\n**Part 2: Consistency with Itô's Formula**\n\nThe problem provides the decomposition of $X_t$ from Itô's formula: $X_{t} = 2 \\int_{0}^{t} B_{s} \\, dB_{s} + [B]_{t}$.\nLet's first verify this decomposition. Let $f(x) = x^2$. Then $f'(x) = 2x$ and $f''(x) = 2$. By Itô's formula for a function of a Brownian motion,\n$$ dX_t = df(B_t) = f'(B_t)dB_t + \\frac{1}{2}f''(B_t)d[B]_t $$\n$$ d(B_t^2) = 2B_t dB_t + \\frac{1}{2}(2)d[B]_t = 2B_t dB_t + d[B]_t $$\nIntegrating from $0$ to $t$ and using $X_0=B_0^2=0$ and $[B]_0=0$:\n$$ X_t - X_0 = \\int_0^t 2B_s dB_s + \\int_0^t d[B]_s \\implies X_t = 2\\int_0^t B_s dB_s + [B]_t $$\nThis confirms the given decomposition.\n\nNow, we compute the quadratic variation of $X_t$ from this semimartingale representation.\nLet $M_t = 2\\int_0^t B_s dB_s$ be the local martingale part and $A_t = [B]_t = t$ be the finite variation part.\nThe quadratic variation of a semimartingale $X_t = M_t + A_t$ is given by the polarization identity:\n$$ [X]_t = [M+A, M+A]_t = [M,M]_t + 2[M,A]_t + [A,A]_t $$\nWe evaluate each term:\n-   $[A,A]_t = [t,t]_t$. Since $A_t=t$ is a process of bounded (and hence finite) variation, its quadratic variation is zero. The sum of squared increments is $\\sum_i (t_{i+1}-t_i)^2 \\leq \\|\\pi\\| \\sum_i (t_{i+1}-t_i) = t\\|\\pi\\| \\to 0$. So, $[A,A]_t = 0$.\n-   $[M,A]_t$. The cross-variation of a continuous local martingale and a continuous process of finite variation is zero. Thus, $[M,A]_t = 0$.\n-   $[M,M]_t = [2\\int_0^\\cdot B_s dB_s, 2\\int_0^\\cdot B_s dB_s]_t$. For an Itô integral of the form $I_t = \\int_0^t H_s dB_s$, its quadratic variation is $[I]_t = \\int_0^t H_s^2 d[B]_s$. In our case, the integrand is $H_s = 2B_s$.\n    Therefore,\n    $$ [M]_t = \\int_0^t (2B_s)^2 d[B]_s = \\int_0^t 4B_s^2 ds $$\n\nSubstituting these back into the expression for $[X]_t$:\n$$ [X]_t = \\int_0^t 4B_s^2 ds + 2(0) + 0 = 4\\int_0^t B_s^2 ds $$\nThis result is identical to the one derived from the fundamental definition. This demonstrates the internal consistency of the theory of stochastic calculus, showing that the definitional approach and the more powerful Itô calculus yield the same result. The final expression for the quadratic variation of $X_t=B_t^2$ is an integral functional of the Brownian path.", "answer": "$$\n\\boxed{4 \\int_{0}^{t} B_{s}^{2} \\, ds}\n$$", "id": "3071180"}, {"introduction": "Beyond being a measure of volatility, quadratic variation plays a critical role in defining the stochastic integral itself. This final practice explores the profound connection between quadratic covariation and the two most common stochastic integrals: Itô and Stratonovich. By deriving the conversion formula from first principles [@problem_id:3071531], you will see that their difference is exactly half the quadratic covariation, demonstrating that this concept is not an abstract curiosity but a fundamental building block of the entire theory.", "problem": "Let $\\{B_{t}\\}_{t \\ge 0}$ be a standard one-dimensional Brownian motion on a filtered probability space satisfying the usual conditions, and define the process $H_{t} := B_{t}$. The quadratic covariation $[X,Y]_{t}$ of two continuous semimartingales $X$ and $Y$ is defined as the limit in probability, as the mesh of the partition $\\pi = \\{0 = t_{0}  t_{1}  \\cdots  t_{n} = t\\}$ goes to zero, of the sums $\\sum_{i=0}^{n-1} \\big(X_{t_{i+1}} - X_{t_{i}}\\big)\\big(Y_{t_{i+1}} - Y_{t_{i}}\\big)$. The Itô integral $\\int_{0}^{t} H_{s}\\,dB_{s}$ is defined as the limit in the mean square sense of stochastic Riemann sums evaluated at left endpoints, and the Stratonovich integral $\\int_{0}^{t} H_{s} \\circ dB_{s}$ is defined as the limit in probability of symmetric Riemann sums evaluated at midpoints.\n\nUsing only these definitions and the fundamental properties of Brownian motion (independent, stationary Gaussian increments and almost sure continuity), first determine $[H,B]_{t}$, and then derive, from first principles, the explicit value of the difference\n$$\n\\int_{0}^{t} B_{s} \\circ dB_{s} \\;-\\; \\int_{0}^{t} B_{s}\\,dB_{s}\n$$\nas a function of $t$. Express your final answer as a single closed-form analytic expression in $t$. No rounding is required.", "solution": "The problem requires the derivation of two related results in stochastic calculus from first principles, using the provided definitions and fundamental properties of Brownian motion. Specifically, we must first determine the quadratic covariation of a standard Brownian motion with itself, $[B,B]_{t}$, and then use this insight to compute the difference between the Stratonovich and Itô integrals of the Brownian motion process with respect to itself, $\\int_{0}^{t} B_{s} \\circ dB_{s} - \\int_{0}^{t} B_{s}\\,dB_{s}$.\n\nLet $\\{B_{t}\\}_{t \\ge 0}$ be a standard one-dimensional Brownian motion. The fundamental properties we will use are:\n1.  $B_{0} = 0$ almost surely.\n2.  The process has independent increments: for any times $0 \\le s  t  u  v$, the random variables $B_{t}-B_{s}$ and $B_{v}-B_{u}$ are independent.\n3.  The process has stationary, Gaussian increments: for any $s  t$, the increment $B_{t}-B_{s}$ is a normally distributed random variable with mean $0$ and variance $t-s$, denoted $B_{t}-B_{s} \\sim \\mathcal{N}(0, t-s)$.\n4.  The sample paths $t \\mapsto B_{t}(\\omega)$ are continuous for almost all $\\omega$.\n\nThe problem states that for two continuous semimartingales $X$ and $Y$, the quadratic covariation is given by the limit in probability\n$$\n[X,Y]_{t} = \\lim_{\\|\\pi\\| \\to 0} \\sum_{i=0}^{n-1} (X_{t_{i+1}} - X_{t_{i}})(Y_{t_{i+1}} - Y_{t_{i}})\n$$\nwhere $\\pi = \\{0 = t_{0}  t_{1}  \\cdots  t_{n} = t\\}$ is a partition of the interval $[0, t]$ and $\\|\\pi\\| = \\max_{i}(t_{i+1}-t_{i})$ is its mesh.\n\nFirst, we determine $[H,B]_{t}$ where $H_{t} = B_{t}$. This is the quadratic variation of $B_{t}$, denoted $[B,B]_{t}$ or simply $[B]_{t}$. Following the definition, we consider the sum\n$$\nS_{\\pi} = \\sum_{i=0}^{n-1} (B_{t_{i+1}} - B_{t_{i}})(B_{t_{i+1}} - B_{t_{i}}) = \\sum_{i=0}^{n-1} (B_{t_{i+1}} - B_{t_{i}})^{2}\n$$\nLet $\\Delta B_{i} = B_{t_{i+1}} - B_{t_{i}}$ and $\\Delta t_{i} = t_{i+1} - t_{i}$. From the properties of Brownian motion, $\\Delta B_{i}$ are independent random variables, with $\\Delta B_{i} \\sim \\mathcal{N}(0, \\Delta t_{i})$.\n\nWe analyze the convergence of $S_{\\pi}$ by examining its mean and variance. The expectation of $S_{\\pi}$ is\n$$\nE[S_{\\pi}] = E\\left[\\sum_{i=0}^{n-1} (\\Delta B_{i})^{2}\\right] = \\sum_{i=0}^{n-1} E[(\\Delta B_{i})^{2}]\n$$\nThe second moment $E[(\\Delta B_{i})^{2}]$ is the variance of $\\Delta B_{i}$ since its mean is $0$. Thus, $E[(\\Delta B_{i})^{2}] = \\text{Var}(\\Delta B_{i}) = \\Delta t_{i}$.\n$$\nE[S_{\\pi}] = \\sum_{i=0}^{n-1} \\Delta t_{i} = t_{n} - t_{0} = t\n$$\nThe variance of $S_{\\pi}$, due to the independence of the increments $\\Delta B_{i}$, is the sum of the variances:\n$$\n\\text{Var}(S_{\\pi}) = \\text{Var}\\left(\\sum_{i=0}^{n-1} (\\Delta B_{i})^{2}\\right) = \\sum_{i=0}^{n-1} \\text{Var}((\\Delta B_{i})^{2})\n$$\nFor a random variable $Z \\sim \\mathcal{N}(0, \\sigma^{2})$, its variance is $\\text{Var}(Z^{2}) = E[Z^{4}] - (E[Z^{2}])^{2}$. The moments of a centered normal distribution are $E[Z^{2}] = \\sigma^{2}$ and $E[Z^{4}] = 3\\sigma^{4}$. Therefore, $\\text{Var}(Z^{2}) = 3\\sigma^{4} - (\\sigma^{2})^{2} = 2\\sigma^{4}$.\nApplying this to $\\Delta B_{i}$ with $\\sigma^{2} = \\Delta t_{i}$, we get $\\text{Var}((\\Delta B_{i})^{2}) = 2(\\Delta t_{i})^{2}$.\nThe variance of the sum is\n$$\n\\text{Var}(S_{\\pi}) = \\sum_{i=0}^{n-1} 2(\\Delta t_{i})^{2} = 2\\sum_{i=0}^{n-1} (\\Delta t_{i})^{2}\n$$\nWe can bound this sum:\n$$\n\\text{Var}(S_{\\pi}) \\le 2 \\left( \\max_{i} \\Delta t_{i} \\right) \\left( \\sum_{i=0}^{n-1} \\Delta t_{i} \\right) = 2\\|\\pi\\|t\n$$\nAs the mesh of the partition $\\|\\pi\\| \\to 0$, the variance $\\text{Var}(S_{\\pi}) \\to 0$. Since $S_{\\pi}$ has a constant mean of $t$ and its variance converges to $0$, the sum $S_{\\pi}$ converges in mean square, and therefore in probability, to its mean $t$.\nThus, we have established that\n$$\n[B,B]_{t} = t\n$$\n\nNext, we derive the value of the difference $\\int_{0}^{t} B_{s} \\circ dB_{s} - \\int_{0}^{t} B_{s}\\,dB_{s}$. We use the provided definitions of the Itô and Stratonovich integrals as limits of Riemann-type sums. For a partition $\\pi$, the Itô sum is $I_{\\pi}^{\\text{Itô}} = \\sum_{i=0}^{n-1} B_{t_{i}} (B_{t_{i+1}} - B_{t_{i}})$, and the Stratonovich sum is $I_{\\pi}^{\\text{Strat}} = \\sum_{i=0}^{n-1} B_{\\tau_{i}} (B_{t_{i+1}} - B_{t_{i}})$ where $\\tau_{i} = \\frac{t_{i}+t_{i+1}}{2}$ is the midpoint.\n\nThe difference of the sums is\n$$\nI_{\\pi}^{\\text{Strat}} - I_{\\pi}^{\\text{Itô}} = \\sum_{i=0}^{n-1} \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right) (B_{t_{i+1}} - B_{t_{i}})\n$$\nLet's analyze the summand. We can rewrite the second term by adding and subtracting $B_{\\frac{t_{i}+t_{i+1}}{2}}$:\n$$\n(B_{t_{i+1}} - B_{t_{i}}) = \\left( B_{t_{i+1}} - B_{\\frac{t_{i}+t_{i+1}}{2}} \\right) + \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right)\n$$\nSubstituting this into the summand gives:\n$$\n\\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right) \\left[ \\left( B_{t_{i+1}} - B_{\\frac{t_{i}+t_{i+1}}{2}} \\right) + \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right) \\right]\n$$\n$$\n= \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right) \\left( B_{t_{i+1}} - B_{\\frac{t_{i}+t_{i+1}}{2}} \\right) + \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right)^{2}\n$$\nThe difference of the integrals is the limit of the sum of these terms. We analyze the two parts of the sum separately.\n\nPart A: Limit of $\\sum_{i=0}^{n-1} \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right)^{2}$.\nThis is a quadratic variation sum. Let $\\Delta t'_{i} = \\frac{t_{i}+t_{i+1}}{2} - t_{i} = \\frac{\\Delta t_{i}}{2}$. The increments are over non-overlapping time intervals. The total length of these intervals is $\\sum_{i=0}^{n-1} \\Delta t'_{i} = \\sum_{i=0}^{n-1} \\frac{\\Delta t_{i}}{2} = \\frac{1}{2} \\sum_{i=0}^{n-1} \\Delta t_{i} = \\frac{t}{2}$.\nBy the same argument used to calculate $[B,B]_{t}$, this sum converges in probability to the total length of the time intervals.\n$$\n\\lim_{\\|\\pi\\|\\to 0} \\sum_{i=0}^{n-1} \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right)^{2} = \\frac{t}{2}\n$$\n\nPart B: Limit of $\\sum_{i=0}^{n-1} \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right) \\left( B_{t_{i+1}} - B_{\\frac{t_{i}+t_{i+1}}{2}} \\right)$.\nLet $U_{i} = B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}}$ and $V_{i} = B_{t_{i+1}} - B_{\\frac{t_{i}+t_{i+1}}{2}}$. For a fixed $i$, $U_{i}$ and $V_{i}$ are increments of Brownian motion over adjacent, non-overlapping intervals $[t_{i}, \\frac{t_{i}+t_{i+1}}{2}]$ and $[\\frac{t_{i}+t_{i+1}}{2}, t_{i+1}]$. Therefore, $U_{i}$ and $V_{i}$ are independent. Also, the pairs $(U_{i}, V_{i})$ are independent for different $i$.\nLet $S'_{\\pi} = \\sum_{i=0}^{n-1} U_{i}V_{i}$. We compute its mean and variance.\n$$\nE[S'_{\\pi}] = \\sum_{i=0}^{n-1} E[U_{i}V_{i}] = \\sum_{i=0}^{n-1} E[U_{i}]E[V_{i}]\n$$\nSince $E[U_{i}]=0$ and $E[V_{i}]=0$, we have $E[S'_{\\pi}] = 0$.\nThe variance is:\n$$\n\\text{Var}(S'_{\\pi}) = \\sum_{i=0}^{n-1} \\text{Var}(U_{i}V_{i}) = \\sum_{i=0}^{n-1} \\left( E[(U_{i}V_{i})^{2}] - (E[U_{i}V_{i}])^{2} \\right)\n$$\nSince $E[U_{i}V_{i}]=0$, this simplifies to $\\sum_{i=0}^{n-1} E[U_{i}^{2}V_{i}^{2}]$. By independence of $U_{i}$ and $V_{i}$, this is $\\sum_{i=0}^{n-1} E[U_{i}^{2}]E[V_{i}^{2}]$.\nWe have $E[U_{i}^{2}] = \\text{Var}(U_{i}) = \\frac{t_{i+1}-t_{i}}{2} = \\frac{\\Delta t_{i}}{2}$ and $E[V_{i}^{2}] = \\text{Var}(V_{i}) = \\frac{t_{i+1}-t_{i}}{2} = \\frac{\\Delta t_{i}}{2}$.\nSo, $\\text{Var}(S'_{\\pi}) = \\sum_{i=0}^{n-1} \\left(\\frac{\\Delta t_{i}}{2}\\right) \\left(\\frac{\\Delta t_{i}}{2}\\right) = \\frac{1}{4} \\sum_{i=0}^{n-1} (\\Delta t_{i})^{2}$.\nAs shown before, $\\sum (\\Delta t_{i})^{2} \\le \\|\\pi\\|t$, so $\\text{Var}(S'_{\\pi}) \\le \\frac{\\|\\pi\\|t}{4}$. As $\\|\\pi\\| \\to 0$, $\\text{Var}(S'_{\\pi}) \\to 0$.\nThe sum $S'_{\\pi}$ converges in probability to its mean, which is $0$.\n\nCombining the limits from Part A and Part B, the limit of the difference sum is the sum of the limits:\n$$\n\\lim_{\\|\\pi\\|\\to 0} (I_{\\pi}^{\\text{Strat}} - I_{\\pi}^{\\text{Itô}}) = \\lim_{\\|\\pi\\|\\to 0} \\sum_{i=0}^{n-1} \\left( B_{\\frac{t_{i}+t_{i+1}}{2}} - B_{t_{i}} \\right) (B_{t_{i+1}} - B_{t_{i}}) = 0 + \\frac{t}{2} = \\frac{t}{2}\n$$\nThis establishes the result from first principles. The difference between the Stratonovich and Itô integrals is\n$$\n\\int_{0}^{t} B_{s} \\circ dB_{s} - \\int_{0}^{t} B_{s}\\,dB_{s} = \\frac{t}{2}\n$$\nThis result is a specific instance of the general Itô-Stratonovich conversion formula, which states that $\\int_{0}^{t} X_{s} \\circ dB_{s} = \\int_{0}^{t} X_{s}\\,dB_{s} + \\frac{1}{2}[X,B]_{t}$. For $X_{t}=B_{t}$, this gives $\\frac{1}{2}[B,B]_{t} = \\frac{1}{2}t$, consistent with our derivation.", "answer": "$$\n\\boxed{\\frac{t}{2}}\n$$", "id": "3071531"}]}