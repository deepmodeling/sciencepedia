{"hands_on_practices": [{"introduction": "The journey into Brownian motion begins with understanding its most fundamental statistical features. This exercise guides you through a foundational derivation, using only the core axioms of Brownian motion to prove that the process is centered and to find its characteristic covariance function. Mastering this calculation [@problem_id:3048018] is essential, as the result $\\mathbb{E}[B_s B_t] = \\min(s,t)$ underpins countless other properties and applications of the process.", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$, defined by the following properties:\n- $B_{0}=0$ almost surely (almost surely (a.s.)),\n- $t \\mapsto B_{t}$ has continuous sample paths,\n- for all $0 \\leq s  t$, the increment $B_{t}-B_{s}$ is independent of $\\mathcal{F}_{s}$ and is Gaussian (normal) with mean $0$ and variance $t-s$.\n\nUsing only the above defining properties, do the following:\n1. Prove that the process is centered, i.e., for every $t \\geq 0$, $\\mathbb{E}[B_{t}]=0$.\n2. Compute the second mixed moment $\\mathbb{E}[B_{s} B_{t}]$ as an explicit function of $(s,t) \\in [0,\\infty)^{2}$.\n\nYour final answer must be a single closed-form analytic expression for $\\mathbb{E}[B_{s} B_{t}]$ in terms of $s$ and $t$ (no units). No rounding is required.", "solution": "The problem is well-defined and requires proving two fundamental properties of a standard one-dimensional Brownian motion $\\{B_t\\}_{t \\geq 0}$ using its axiomatic definition. We will address each part of the problem sequentially. The properties given are:\n1. $B_{0}=0$ almost surely (a.s.).\n2. The sample paths $t \\mapsto B_{t}$ are continuous a.s.\n3. For any $0 \\leq s  t$, the increment $B_{t}-B_{s}$ is a Gaussian random variable with mean $0$ and variance $t-s$.\n4. For any $0 \\leq s  t$, the increment $B_{t}-B_{s}$ is independent of the filtration $\\mathcal{F}_{s}$, which contains the history of the process up to time $s$.\n\nPart 1: Prove that the process is centered, i.e., $\\mathbb{E}[B_{t}]=0$ for every $t \\geq 0$.\n\nWe consider two cases for the time $t$.\n\nCase (i): $t=0$.\nThe definition states that $B_{0}=0$ a.s. The expectation of a random variable that is equal to a constant almost surely is that constant. Therefore,\n$$ \\mathbb{E}[B_{0}] = \\mathbb{E}[0] = 0 $$\n\nCase (ii): $t > 0$.\nWe can express the random variable $B_{t}$ as the sum of its initial value $B_{0}$ and the increment from time $0$ to $t$:\n$$ B_{t} = B_{0} + (B_{t} - B_{0}) $$\nBy the linearity of the expectation operator, we have:\n$$ \\mathbb{E}[B_{t}] = \\mathbb{E}[B_{0} + (B_{t} - B_{0})] = \\mathbb{E}[B_{0}] + \\mathbb{E}[B_{t} - B_{0}] $$\nFrom Case (i), we know that $\\mathbb{E}[B_{0}] = 0$.\nFor the second term, we use the third defining property with $s=0$. For $t>0$, the increment $B_{t}-B_{0}$ is a Gaussian random variable with mean $0$ and variance $t-0=t$. The expectation of this random variable is its mean.\n$$ \\mathbb{E}[B_{t} - B_{0}] = 0 $$\nSubstituting these results back into the equation for $\\mathbb{E}[B_t]$, we get:\n$$ \\mathbb{E}[B_{t}] = 0 + 0 = 0 $$\nCombining both cases, we have proven that $\\mathbb{E}[B_{t}]=0$ for all $t \\geq 0$.\n\nPart 2: Compute the second mixed moment $\\mathbb{E}[B_{s} B_{t}]$ as an explicit function of $(s,t) \\in [0,\\infty)^{2}$.\n\nThe value of this expectation depends on the relative order of $s$ and $t$. We consider three cases.\n\nCase (i): $s = t$.\nThe expectation becomes:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[B_{t} B_{t}] = \\mathbb{E}[B_{t}^{2}] $$\nFor any random variable $X$, its variance is given by $\\text{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$. Rearranging, we have $\\mathbb{E}[X^2] = \\text{Var}(X) + (\\mathbb{E}[X])^2$.\nLetting $X=B_t$, and using the result from Part 1 that $\\mathbb{E}[B_t]=0$, we get:\n$$ \\mathbb{E}[B_{t}^{2}] = \\text{Var}(B_{t}) + (\\mathbb{E}[B_{t}])^{2} = \\text{Var}(B_{t}) + 0^{2} = \\text{Var}(B_{t}) $$\nTo find the variance of $B_t$, we consider the increment $B_t - B_0$. Since $B_0=0$ a.s., $\\text{Var}(B_t) = \\text{Var}(B_t - B_0)$.\nFrom the third property, for $s=0$ and $t>0$, the increment $B_t - B_0$ has variance $t-0=t$. If $t=0$, $\\text{Var}(B_0)=\\text{Var}(0)=0$. Thus, for all $t \\geq 0$, $\\text{Var}(B_t) = t$.\nTherefore, for $s=t$, we have:\n$$ \\mathbb{E}[B_{t}^{2}] = t $$\n\nCase (ii): $0 \\leq s  t$.\nWe can write $B_t$ as the sum of $B_s$ and the subsequent increment $B_t - B_s$:\n$$ B_t = B_s + (B_t - B_s) $$\nSubstituting this into the expectation:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[B_{s}(B_{s} + (B_{t} - B_{s}))] $$\nBy linearity of expectation:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[B_{s}^{2}] + \\mathbb{E}[B_{s}(B_{t} - B_{s})] $$\nFrom Case (i) with $t$ replaced by $s$, we know that $\\mathbb{E}[B_{s}^{2}] = s$.\nFor the second term, $\\mathbb{E}[B_{s}(B_{t} - B_{s})]$, we use the independence property. The process $\\{B_t\\}$ is adapted to the filtration $\\{\\mathcal{F}_t\\}$, meaning $B_s$ is an $\\mathcal{F}_s$-measurable random variable. The fourth property states that the increment $B_t - B_s$ is independent of $\\mathcal{F}_s$. Consequently, $B_s$ and $B_t - B_s$ are independent random variables.\nThe expectation of the product of two independent random variables is the product of their expectations:\n$$ \\mathbb{E}[B_{s}(B_{t} - B_{s})] = \\mathbb{E}[B_{s}]\\mathbb{E}[B_{t} - B_{s}] $$\nFrom Part 1, we have $\\mathbb{E}[B_{s}]=0$. From the third property, the increment $B_t - B_s$ has mean $0$, so $\\mathbb{E}[B_{t} - B_{s}]=0$.\n$$ \\mathbb{E}[B_{s}(B_{t} - B_{s})] = 0 \\cdot 0 = 0 $$\nCombining the terms, for $0 \\leq s  t$:\n$$ \\mathbb{E}[B_{s} B_{t}] = s + 0 = s $$\n\nCase (iii): $0 \\leq t  s$.\nThis case is symmetric to Case (ii). By interchanging the roles of $s$ and $t$, the same logic applies. We expect the result to be $t$. Let's verify this explicitly.\nWe write $B_s = B_t + (B_s - B_t)$.\n$$ \\mathbb{E}[B_{s} B_{t}] = \\mathbb{E}[(B_{t} + (B_{s} - B_{t}))B_{t}] = \\mathbb{E}[B_{t}^{2}] + \\mathbb{E}[(B_{s} - B_{t})B_{t}] $$\nAs before, $\\mathbb{E}[B_{t}^{2}] = t$.\nThe increment $B_s - B_t$ is independent of $\\mathcal{F}_t$, and $B_t$ is $\\mathcal{F}_t$-measurable. Thus, they are independent.\n$$ \\mathbb{E}[(B_{s} - B_{t})B_{t}] = \\mathbb{E}[B_{s} - B_{t}] \\mathbb{E}[B_{t}] = 0 \\cdot 0 = 0 $$\nTherefore, for $0 \\leq t  s$:\n$$ \\mathbb{E}[B_{s} B_{t}] = t + 0 = t $$\n\nSummary:\n- If $s  t$, then $\\mathbb{E}[B_s B_t] = s$.\n- If $t  s$, then $\\mathbb{E}[B_s B_t] = t$.\n- If $s = t$, then $\\mathbb{E}[B_s B_t] = s = t$.\n\nAll three cases can be written concisely using the minimum function:\n$$ \\mathbb{E}[B_{s} B_{t}] = \\min(s, t) $$\nThis expression gives the second mixed moment for all $(s,t) \\in [0,\\infty)^2$. Since the mean of the process is zero, this is also the covariance function, $\\text{Cov}(B_s, B_t) = \\min(s, t)$.", "answer": "$$ \\boxed{\\min(s, t)} $$", "id": "3048018"}, {"introduction": "Beyond the standard Brownian motion, many related processes are crucial in modeling and theory. This exercise introduces the \"Brownian bridge,\" a version of Brownian motion that is pinned to return to zero at a future time $T$. By constructing this process explicitly and analyzing its properties, you will see how the fundamental characteristics of Brownian motion can be used to understand more complex, derived stochastic objects [@problem_id:3048066].", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion defined on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\geq 0},\\mathbb{P})$, where by definition $B_{0}=0$ almost surely, $\\mathbb{E}[B_{t}]=0$ for all $t \\geq 0$, the increments are independent and stationary, the covariance is $\\mathbb{E}[B_{s}B_{t}]=\\min\\{s,t\\}$ for all $s,t \\geq 0$, and the sample paths are almost surely continuous. Fix a time horizon $T0$, and define the process $\\{\\beta_{t}\\}_{t \\in [0,T]}$ by\n$$\n\\beta_{t} \\triangleq B_{t} - \\frac{t}{T} B_{T}, \\quad t \\in [0,T].\n$$\nStarting only from the fundamental defining properties of standard Brownian motion given above, carry out the following tasks:\n1. Prove that the finite-dimensional distributions of $\\{\\beta_{t}\\}_{t \\in [0,T]}$ are multivariate Gaussian, and compute the mean function $m(t)=\\mathbb{E}[\\beta_{t}]$.\n2. Derive the covariance function $C(s,t)=\\operatorname{Cov}(\\beta_{s},\\beta_{t})$ explicitly in terms of $s$, $t$, and $T$.\n3. Prove that the sample paths of $\\{\\beta_{t}\\}_{t \\in [0,T]}$ are almost surely continuous, and verify $\\beta_{0}=0$ and $\\beta_{T}=0$ almost surely.\n4. Using your covariance function, compute the variance\n$$\n\\operatorname{Var}\\!\\left(\\int_{0}^{T} \\beta_{t} \\, dt\\right)\n$$\nas a closed-form expression depending only on $T$.\n\nYour final reported answer must be the single closed-form analytical expression obtained in item $4$. Do not introduce any numerical approximations.", "solution": "We address the four tasks in sequence.\n\n**1. Finite-dimensional distributions and mean function of $\\{\\beta_{t}\\}$}\n\nLet $\\{B_{t}\\}_{t \\geq 0}$ be a standard one-dimensional Brownian motion. By definition, $\\{B_{t}\\}_{t \\geq 0}$ is a Gaussian process. This means that for any finite set of time points $t_{1}, t_{2}, \\dots, t_{n}$ in its domain, the random vector $(B_{t_{1}}, B_{t_{2}}, \\dots, B_{t_{n}})$ has a multivariate Gaussian distribution.\n\nThe process $\\{\\beta_{t}\\}_{t \\in [0,T]}$ is defined by $\\beta_{t} = B_{t} - \\frac{t}{T} B_{T}$. Let's consider an arbitrary finite set of time points $t_{1}, t_{2}, \\dots, t_{n}$ in $[0,T]$. The random vector $(\\beta_{t_{1}}, \\beta_{t_{2}}, \\dots, \\beta_{t_{n}})$ can be expressed as a linear transformation of the random vector $(B_{t_{1}}, B_{t_{2}}, \\dots, B_{t_{n}}, B_{T})$. Specifically, we can write:\n$$\n\\begin{pmatrix} \\beta_{t_{1}} \\\\ \\beta_{t_{2}} \\\\ \\vdots \\\\ \\beta_{t_{n}} \\end{pmatrix} = \\begin{pmatrix} 1  0  \\cdots  0  -t_{1}/T \\\\ 0  1  \\cdots  0  -t_{2}/T \\\\ \\vdots  \\vdots  \\ddots  \\vdots  \\vdots \\\\ 0  0  \\cdots  1  -t_{n}/T \\end{pmatrix} \\begin{pmatrix} B_{t_{1}} \\\\ B_{t_{2}} \\\\ \\vdots \\\\ B_{t_{n}} \\\\ B_{T} \\end{pmatrix}\n$$\nSince $\\{B_{t}\\}$ is a Gaussian process, the vector $(B_{t_{1}}, \\dots, B_{t_{n}}, B_{T})$ is a multivariate Gaussian random vector. A linear transformation of a multivariate Gaussian vector is also a multivariate Gaussian vector. Therefore, the vector $(\\beta_{t_{1}}, \\dots, \\beta_{t_{n}})$ is multivariate Gaussian for any choice of $t_{1}, \\dots, t_{n}$. This proves that $\\{\\beta_{t}\\}_{t \\in [0,T]}$ is a Gaussian process.\n\nThe mean function $m(t)=\\mathbb{E}[\\beta_{t}]$ is computed using the linearity of expectation and the fact that $\\mathbb{E}[B_{s}] = 0$ for all $s \\geq 0$.\n$$\nm(t) = \\mathbb{E}[\\beta_{t}] = \\mathbb{E}\\left[B_{t} - \\frac{t}{T} B_{T}\\right] = \\mathbb{E}[B_{t}] - \\frac{t}{T}\\mathbb{E}[B_{T}]\n$$\nSince $t, T \\ge 0$, we have $\\mathbb{E}[B_{t}]=0$ and $\\mathbb{E}[B_{T}]=0$. Thus,\n$$\nm(t) = 0 - \\frac{t}{T}(0) = 0\n$$\nThe mean function is $m(t)=0$ for all $t \\in [0,T]$.\n\n**2. Covariance function of $\\{\\beta_{t}\\}$}\n\nThe covariance function is $C(s,t)=\\operatorname{Cov}(\\beta_{s},\\beta_{t})$. Since the mean function is zero, the covariance is given by the expectation of the product:\n$$\nC(s,t) = \\mathbb{E}[(\\beta_{s}-m(s))(\\beta_{t}-m(t))] = \\mathbb{E}[\\beta_{s}\\beta_{t}]\n$$\nSubstituting the definition of $\\beta_{t}$:\n$$\nC(s,t) = \\mathbb{E}\\left[ \\left(B_{s} - \\frac{s}{T}B_{T}\\right) \\left(B_{t} - \\frac{t}{T}B_{T}\\right) \\right]\n$$\nExpanding the product, we get:\n$$\nC(s,t) = \\mathbb{E}\\left[ B_{s}B_{t} - \\frac{t}{T}B_{s}B_{T} - \\frac{s}{T}B_{t}B_{T} + \\frac{st}{T^{2}}B_{T}^{2} \\right]\n$$\nBy linearity of expectation:\n$$\nC(s,t) = \\mathbb{E}[B_{s}B_{t}] - \\frac{t}{T}\\mathbb{E}[B_{s}B_{T}] - \\frac{s}{T}\\mathbb{E}[B_{t}B_{T}] + \\frac{st}{T^{2}}\\mathbb{E}[B_{T}^{2}]\n$$\nWe use the given covariance of standard Brownian motion, $\\mathbb{E}[B_{u}B_{v}] = \\min\\{u,v\\}$, for any $u,v \\geq 0$. For $s,t \\in [0,T]$:\n\\begin{itemize}\n    \\item $\\mathbb{E}[B_{s}B_{t}] = \\min\\{s,t\\}$\n    \\item $\\mathbb{E}[B_{s}B_{T}] = \\min\\{s,T\\} = s$\n    \\item $\\mathbb{E}[B_{t}B_{T}] = \\min\\{t,T\\} = t$\n    \\item $\\mathbb{E}[B_{T}^{2}] = \\mathbb{E}[B_{T}B_{T}] = \\min\\{T,T\\} = T$\n\\end{itemize}\nSubstituting these into the expression for $C(s,t)$:\n$$\nC(s,t) = \\min\\{s,t\\} - \\frac{t}{T}(s) - \\frac{s}{T}(t) + \\frac{st}{T^{2}}(T)\n$$\n$$\nC(s,t) = \\min\\{s,t\\} - \\frac{st}{T} - \\frac{st}{T} + \\frac{st}{T} = \\min\\{s,t\\} - \\frac{st}{T}\n$$\nThe covariance function is $C(s,t) = \\min\\{s,t\\} - \\frac{st}{T}$ for $s,t \\in [0,T]$. This process is known as a Brownian bridge.\n\n**3. Continuity of sample paths and boundary conditions**\n\nSample paths of standard Brownian motion $\\{B_{t}\\}$ are almost surely continuous. For any sample path $\\omega$ for which $t \\mapsto B_{t}(\\omega)$ is a continuous function on $[0,T]$, the function $t \\mapsto \\beta_{t}(\\omega)$ is given by\n$$\n\\beta_{t}(\\omega) = B_{t}(\\omega) - \\frac{t}{T}B_{T}(\\omega)\n$$\nFor a fixed path $\\omega$, $B_{T}(\\omega)$ is a constant. The function $f(t)=t$ is continuous. Thus, $t \\mapsto \\beta_{t}(\\omega)$ is a linear combination of continuous functions of $t$ and is therefore itself continuous on $[0,T]$. Since this holds for almost all $\\omega$, the sample paths of $\\{\\beta_{t}\\}$ are almost surely continuous.\n\nNext, we verify the boundary conditions for $t \\in \\{0, T\\}$:\nFor $t=0$:\n$$\n\\beta_{0} = B_{0} - \\frac{0}{T}B_{T} = B_{0}\n$$\nSince $B_{0}=0$ almost surely, it follows that $\\beta_{0}=0$ almost surely.\n\nFor $t=T$:\n$$\n\\beta_{T} = B_{T} - \\frac{T}{T}B_{T} = B_{T} - B_{T} = 0\n$$\nThis holds for every sample path, so $\\beta_{T}=0$ almost surely.\n\n**4. Variance of the integral**\n\nWe need to compute $\\operatorname{Var}\\!\\left(\\int_{0}^{T} \\beta_{t} \\, dt\\right)$. Let $I = \\int_{0}^{T} \\beta_{t} \\, dt$. The mean of $I$ is:\n$$\n\\mathbb{E}[I] = \\mathbb{E}\\left[\\int_{0}^{T} \\beta_{t} \\, dt\\right]\n$$\nUsing the Fubini-Tonelli theorem (which applies here as $\\mathbb{E}[\\int_{0}^{T} |\\beta_t| \\, dt]  \\infty$), we can swap the expectation and integral:\n$$\n\\mathbb{E}[I] = \\int_{0}^{T} \\mathbb{E}[\\beta_{t}] \\, dt = \\int_{0}^{T} m(t) \\, dt = \\int_{0}^{T} 0 \\, dt = 0\n$$\nThe variance is then given by $\\operatorname{Var}(I) = \\mathbb{E}[I^{2}] - (\\mathbb{E}[I])^{2} = \\mathbb{E}[I^{2}]$.\n$$\n\\operatorname{Var}(I) = \\mathbb{E}\\left[ \\left(\\int_{0}^{T} \\beta_{t} \\, dt\\right)^{2} \\right] = \\mathbb{E}\\left[ \\left(\\int_{0}^{T} \\beta_{s} \\, ds\\right) \\left(\\int_{0}^{T} \\beta_{t} \\, dt\\right) \\right]\n$$\n$$\n\\operatorname{Var}(I) = \\mathbb{E}\\left[ \\int_{0}^{T} \\int_{0}^{T} \\beta_{s}\\beta_{t} \\, ds \\, dt \\right]\n$$\nAgain, by Fubini's theorem, we can interchange expectation and integration:\n$$\n\\operatorname{Var}(I) = \\int_{0}^{T} \\int_{0}^{T} \\mathbb{E}[\\beta_{s}\\beta_{t}] \\, ds \\, dt = \\int_{0}^{T} \\int_{0}^{T} C(s,t) \\, ds \\, dt\n$$\nSubstituting the derived covariance function $C(s,t) = \\min\\{s,t\\} - \\frac{st}{T}$:\n$$\n\\operatorname{Var}(I) = \\int_{0}^{T} \\int_{0}^{T} \\left( \\min\\{s,t\\} - \\frac{st}{T} \\right) \\, ds \\, dt\n$$\nWe can split the integral into two parts:\n$$\n\\operatorname{Var}(I) = \\int_{0}^{T} \\int_{0}^{T} \\min\\{s,t\\} \\, ds \\, dt - \\int_{0}^{T} \\int_{0}^{T} \\frac{st}{T} \\, ds \\, dt\n$$\nFirst, we evaluate the second term, which is a separable integral:\n$$\n\\int_{0}^{T} \\int_{0}^{T} \\frac{st}{T} \\, ds \\, dt = \\frac{1}{T} \\left( \\int_{0}^{T} s \\, ds \\right) \\left( \\int_{0}^{T} t \\, dt \\right) = \\frac{1}{T} \\left[ \\frac{s^{2}}{2} \\right]_{0}^{T} \\left[ \\frac{t^{2}}{2} \\right]_{0}^{T} = \\frac{1}{T} \\left( \\frac{T^{2}}{2} \\right) \\left( \\frac{T^{2}}{2} \\right) = \\frac{T^{3}}{4}\n$$\nNext, we evaluate the first term. We split the domain of integration (the square $[0,T] \\times [0,T]$) into two regions: where $s \\leq t$ and where $s  t$. By symmetry, the integral over these two regions is identical.\n$$\n\\int_{0}^{T} \\int_{0}^{T} \\min\\{s,t\\} \\, ds \\, dt = 2 \\int_{0}^{T} \\left( \\int_{0}^{t} \\min\\{s,t\\} \\, ds \\right) \\, dt = 2 \\int_{0}^{T} \\left( \\int_{0}^{t} s \\, ds \\right) \\, dt\n$$\nThe inner integral is:\n$$\n\\int_{0}^{t} s \\, ds = \\left[ \\frac{s^{2}}{2} \\right]_{0}^{t} = \\frac{t^{2}}{2}\n$$\nSubstituting this into the outer integral:\n$$\n2 \\int_{0}^{T} \\frac{t^{2}}{2} \\, dt = \\int_{0}^{T} t^{2} \\, dt = \\left[ \\frac{t^{3}}{3} \\right]_{0}^{T} = \\frac{T^{3}}{3}\n$$\nCombining the two parts gives the final variance:\n$$\n\\operatorname{Var}\\!\\left(\\int_{0}^{T} \\beta_{t} \\, dt\\right) = \\frac{T^{3}}{3} - \\frac{T^{3}}{4} = \\frac{4T^{3} - 3T^{3}}{12} = \\frac{T^{3}}{12}\n$$", "answer": "$$\n\\boxed{\\frac{T^{3}}{12}}\n$$", "id": "3048066"}, {"introduction": "One of the most striking features of Brownian motion is the continuity of its sample paths, a property that belies their intricate and jagged nature. This practice problem delves deeper, connecting the statistical moments of Brownian increments to the geometric regularity of its paths via the celebrated Kolmogorov continuity criterion. By completing this derivation, you will quantify the \"roughness\" of the process and prove the famous result that Brownian paths are Hölder continuous for any exponent $\\gamma  1/2$ [@problem_id:3048021].", "problem": "Let $\\{B_{t}\\}_{t \\geq 0}$ be a standard Brownian motion, defined as a real-valued stochastic process with $B_{0} = 0$, stationary and independent increments, and for $0 \\leq s  t$, the increment $B_{t} - B_{s}$ is Gaussian with mean $0$ and variance $t - s$. Starting from these core properties and the definition of the Gaussian distribution, derive an exact formula for the moment $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$ for a fixed $p  0$. As a second task, use your derived expression to verify a continuity criterion of the Kolmogorov type by exhibiting constants $\\alpha  0$, $\\beta  0$, and $C  0$ (as functions of $p$) such that $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{\\alpha}\\right] \\leq C\\,|t - s|^{1 + \\beta}$ for all $s,t$ in a bounded interval, and deduce the largest Hölder continuity exponent guaranteed by this criterion in terms of $p$. Your final reported answer must be the exact closed-form expression for $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$ in terms of $p$, $t$, and $s$. No rounding is required.", "solution": "We begin by calculating the moment $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$ for a fixed $p  0$. Let $X = B_{t} - B_{s}$. According to the problem statement, for any $t, s \\geq 0$, the increment $X$ is a Gaussian random variable with mean $0$ and variance $\\sigma^2 = |t-s|$. The probability density function (PDF) of $X$ is given by:\n$$f_{X}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right)$$\nThe $p$-th absolute moment of $X$ is defined as the expectation of $|X|^{p}$, which can be computed by integrating over the entire real line:\n$$\\mathbb{E}\\!\\left[|X|^{p}\\right] = \\int_{-\\infty}^{\\infty} |x|^{p} f_{X}(x) \\,dx = \\int_{-\\infty}^{\\infty} |x|^{p} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\,dx$$\nThe integrand $|x|^{p} \\exp(-x^2/(2\\sigma^2))$ is an even function of $x$. Thus, we can simplify the integral by considering only the positive real axis and multiplying by $2$:\n$$\\mathbb{E}\\!\\left[|X|^{p}\\right] = 2 \\int_{0}^{\\infty} x^{p} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\,dx = \\frac{2}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} x^{p} \\exp\\left(-\\frac{x^2}{2\\sigma^2}\\right) \\,dx$$\nTo evaluate this integral, we perform a change of variables. Let $u = \\frac{x^2}{2\\sigma^2}$. This implies $x^2 = 2\\sigma^2 u$, so $x = \\sqrt{2\\sigma^2 u} = \\sigma\\sqrt{2u}$. The differential is $dx = \\frac{\\sigma\\sqrt{2}}{2\\sqrt{u}} du = \\frac{\\sigma}{\\sqrt{2u}} du$. The limits of integration remain from $0$ to $\\infty$. Substituting these into the integral:\n\\begin{align*} \\mathbb{E}\\!\\left[|X|^{p}\\right] = \\frac{2}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\left(\\sigma\\sqrt{2u}\\right)^{p} \\exp(-u) \\frac{\\sigma}{\\sqrt{2u}} \\,du \\\\ = \\frac{2}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} \\sigma^{p} (2u)^{p/2} \\exp(-u) \\frac{\\sigma}{\\sqrt{2u}} \\,du \\\\ = \\frac{2 \\sigma^{p+1}}{\\sigma\\sqrt{2\\pi}} \\int_{0}^{\\infty} 2^{p/2} u^{p/2} \\exp(-u) \\frac{1}{\\sqrt{2} u^{1/2}} \\,du \\\\ = \\frac{2 \\sigma^{p}}{\\sqrt{2\\pi}} \\frac{2^{p/2}}{\\sqrt{2}} \\int_{0}^{\\infty} u^{p/2 - 1/2} \\exp(-u) \\,du \\\\ = \\frac{2^{1/2} \\sigma^{p}}{\\sqrt{\\pi}} 2^{p/2-1/2} \\int_{0}^{\\infty} u^{(p-1)/2} \\exp(-u) \\,du \\\\ = \\frac{2^{p/2} \\sigma^{p}}{\\sqrt{\\pi}} \\int_{0}^{\\infty} u^{\\frac{p+1}{2} - 1} \\exp(-u) \\,du \\end{align*}\nThe integral is the definition of the Gamma function, $\\Gamma(z) = \\int_{0}^{\\infty} t^{z-1}\\exp(-t)dt$, with $z = \\frac{p+1}{2}$.\nTherefore, the integral evaluates to $\\Gamma\\left(\\frac{p+1}{2}\\right)$.\nSubstituting this back, we get:\n$$\\mathbb{E}\\!\\left[|X|^{p}\\right] = \\frac{2^{p/2} \\sigma^{p}}{\\sqrt{\\pi}} \\Gamma\\left(\\frac{p+1}{2}\\right)$$\nRecalling that $\\sigma^2 = |t-s|$, we have $\\sigma^{p} = (\\sqrt{|t-s|})^{p} = |t-s|^{p/2}$. Thus, the final expression for the moment is:\n$$\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right] = \\frac{2^{p/2} \\Gamma\\left(\\frac{p+1}{2}\\right)}{\\sqrt{\\pi}} |t-s|^{p/2}$$\n\nNext, we address the second task concerning the Kolmogorov continuity criterion. The criterion states that if a stochastic process $\\{X_t\\}_{t \\geq 0}$ satisfies the condition $\\mathbb{E}\\!\\left[|X_{t} - X_{s}|^{\\alpha}\\right] \\leq C\\,|t - s|^{1 + \\beta}$ for some constants $\\alpha > 0$, $\\beta > 0$, and $C > 0$, and for all $s,t$ in a bounded interval, then there exists a modification of the process whose sample paths are almost surely Hölder continuous with any exponent $\\gamma \\in (0, \\beta/\\alpha)$.\n\nWe use our derived expression for the moments of Brownian motion. Let us choose $\\alpha = p$ for some $p > 0$. Our derived formula is an equality:\n$$\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right] = C_{p} |t-s|^{p/2}$$\nwhere $C_{p} = \\frac{2^{p/2} \\Gamma\\left(\\frac{p+1}{2}\\right)}{\\sqrt{\\pi}}$ is a positive constant depending only on $p$.\nTo satisfy the Kolmogorov criterion, we need to find $p$ such that the exponent of $|t-s|$ is greater than $1$. That is, we require $\\frac{p}{2} > 1$, which implies $p > 2$.\nFor any such fixed $p > 2$, we can set $\\alpha = p$. The condition becomes:\n$$C_{p} |t-s|^{p/2} \\leq C |t-s|^{1+\\beta}$$\nWe can write the exponent $\\frac{p}{2}$ as $1 + \\left(\\frac{p}{2} - 1\\right)$. Let $\\beta = \\frac{p}{2} - 1$. Since $p > 2$, we have $\\beta > 0$.\nNow we can set $\\alpha = p  0$, $\\beta = \\frac{p}{2} - 1  0$, and $C = C_{p}  0$. With these choices, we have the equality:\n$$\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{\\alpha}\\right] = C |t-s|^{1+\\beta}$$\nThis satisfies the condition of the Kolmogorov continuity criterion. The theorem then guarantees that Brownian motion has a modification that is a.s. Hölder continuous for any exponent $\\gamma$ such that:\n$$0  \\gamma  \\frac{\\beta}{\\alpha} = \\frac{\\frac{p}{2} - 1}{p} = \\frac{1}{2} - \\frac{1}{p}$$\nThis result holds for any choice of $p > 2$. To find the best possible guarantee on the Hölder exponent from this method, we can consider the limit as $p \\to \\infty$:\n$$\\lim_{p \\to \\infty} \\left(\\frac{1}{2} - \\frac{1}{p}\\right) = \\frac{1}{2}$$\nThis means that for any exponent $\\gamma  1/2$, we can choose a sufficiently large $p$ (specifically, $p  1/(1/2 - \\gamma)$) such that the Kolmogorov criterion guarantees $\\gamma$-Hölder continuity. Therefore, the criterion ensures that Brownian motion sample paths have a modification that is Hölder continuous for any exponent strictly less than $1/2$. The largest such exponent is the supremum over all possible $\\gamma$, which is $1/2$. It is a classical result that the paths are not Hölder continuous for exponent $1/2$.\n\nThe problem asks for the single, final expression for $\\mathbb{E}\\!\\left[|B_{t} - B_{s}|^{p}\\right]$, which we derived first.", "answer": "$$\n\\boxed{\\frac{2^{p/2} \\Gamma\\left(\\frac{p+1}{2}\\right)}{\\sqrt{\\pi}} |t-s|^{p/2}}\n$$", "id": "3048021"}]}