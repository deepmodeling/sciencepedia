{"hands_on_practices": [{"introduction": "Before simulating a complex Stochastic Differential Equation (SDE), we must first master the simulation of its fundamental driver: Brownian motion. This practice guides you through generating discrete Brownian paths and verifying that their statistical properties match theoretical predictions, ensuring your random walk building blocks are sound. This is a critical first step for any Monte Carlo simulation involving SDEs.", "problem": "Consider a standard Brownian motion (BM), also known as a Wiener process, which is a continuous-time stochastic process denoted by $W_t$ with $t \\ge 0$ that satisfies the following core properties: $W_0 = 0$, it has independent increments, and for any times $0 \\le s < t$, the increment $W_t - W_s$ is Gaussian with mean $0$ and variance $t - s$. In the context of stochastic differential equations (SDEs), Monte Carlo (MC) simulation approximates such processes by discretizing time and sampling from the appropriate Gaussian distributions.\n\nYour task is to implement a program that, for several test cases, constructs a discrete time grid $\\{t_n\\}_{n=0}^N$ on $[0,T]$ and generates $M$ independent discrete BM paths via cumulative sums of independent, normally distributed increments. Specifically, for each test case:\n\n- Construct a uniform time grid by choosing a positive integer number of steps $N$ and setting the time step size $\\Delta t = T/N$ and $t_n = n \\Delta t$ for $n = 0,1,\\dots,N$.\n- Generate independent increments $\\Delta W_k \\sim \\mathcal{N}(0,\\Delta t)$ for $k = 1,2,\\dots,N$.\n- Form the discrete BM values by $W_0 = 0$ and $W_{t_n} = \\sum_{k=1}^n \\Delta W_k$ for $n = 1,2,\\dots,N$.\n\nFor each test case with parameters $(T,N,M,\\varepsilon_{\\text{mean}},\\varepsilon_{\\text{var}},\\varepsilon_{\\text{qv}})$, simulate $M$ paths and compute the following empirical quantities:\n- The sample mean of the endpoints $W_T$, denoted $\\widehat{\\mu}_T$.\n- The sample variance of the endpoints $W_T$, denoted $\\widehat{\\sigma}^2_T$.\n- The average discrete quadratic variation, defined per path as $\\sum_{k=1}^N (\\Delta W_k)^2$, and averaged over all $M$ paths to yield $\\widehat{Q}_T$.\n\nUsing the foundational properties of BM, the true values satisfy $\\mathbb{E}[W_T] = 0$, $\\mathrm{Var}(W_T) = T$, and the quadratic variation over $[0,T]$ is $T$. Therefore, for each test case, evaluate the three logical conditions:\n- $|\\widehat{\\mu}_T - 0| \\le \\varepsilon_{\\text{mean}}$,\n- $|\\widehat{\\sigma}^2_T - T| \\le \\varepsilon_{\\text{var}}$,\n- $|\\widehat{Q}_T - T| \\le \\varepsilon_{\\text{qv}}$,\nand return all three results as boolean values.\n\nTest Suite:\n- Case $1$: $(T,N,M,\\varepsilon_{\\text{mean}},\\varepsilon_{\\text{var}},\\varepsilon_{\\text{qv}}) = (\\,1.0,\\,1000,\\,5000,\\,0.03,\\,0.05,\\,0.03\\,)$.\n- Case $2$: $(T,N,M,\\varepsilon_{\\text{mean}},\\varepsilon_{\\text{var}},\\varepsilon_{\\text{qv}}) = (\\,0.0,\\,10,\\,1000,\\,10^{-10},\\,10^{-10},\\,10^{-10}\\,)$.\n- Case $3$: $(T,N,M,\\varepsilon_{\\text{mean}},\\varepsilon_{\\text{var}},\\varepsilon_{\\text{qv}}) = (\\,2.0,\\,1,\\,5000,\\,0.05,\\,0.07,\\,0.07\\,)$.\n- Case $4$: $(T,N,M,\\varepsilon_{\\text{mean}},\\varepsilon_{\\text{var}},\\varepsilon_{\\text{qv}}) = (\\,1.0,\\,5,\\,5000,\\,0.03,\\,0.05,\\,0.05\\,)$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the booleans for all three checks for each case concatenated in order, resulting in a list of length $12$. For example, an output line like $[\\text{True},\\text{False},\\text{True},\\dots]$ is acceptable. No other text should be printed.", "solution": "The user-provided problem has been analyzed and validated.\n\n### Step 1: Extract Givens\n-   **Process:** Standard Brownian motion (BM) or Wiener process, $W_t$, for $t \\ge 0$.\n-   **BM Properties:** $W_0 = 0$; has independent increments; for $0 \\le s < t$, the increment $W_t - W_s$ is Gaussian with mean $0$ and variance $t - s$, denoted $\\mathcal{N}(0, t-s)$.\n-   **Simulation Method:** Monte Carlo (MC) using a discrete time grid.\n-   **Time Discretization:**\n    -   Time interval: $[0,T]$.\n    -   Number of steps: $N$, a positive integer.\n    -   Time step size: $\\Delta t = T/N$.\n    -   Time grid points: $t_n = n \\Delta t$ for $n = 0, 1, \\dots, N$.\n-   **Path Generation:**\n    -   Number of independent paths: $M$.\n    -   Increments: $\\Delta W_k \\sim \\mathcal{N}(0, \\Delta t)$ for $k = 1, 2, \\dots, N$.\n    -   Discrete BM path: $W_0 = 0$ and $W_{t_n} = \\sum_{k=1}^n \\Delta W_k$ for $n = 1, 2, \\dots, N$.\n-   **Empirical Quantities to Compute:**\n    -   Sample mean of endpoints $W_T$: $\\widehat{\\mu}_T$.\n    -   Sample variance of endpoints $W_T$: $\\widehat{\\sigma}^2_T$.\n    -   Average discrete quadratic variation: $\\widehat{Q}_T$, which is the average over $M$ paths of $\\sum_{k=1}^N (\\Delta W_k)^2$.\n-   **Theoretical Values for Comparison:**\n    -   Expected value of endpoint: $\\mathbb{E}[W_T] = 0$.\n    -   Variance of endpoint: $\\mathrm{Var}(W_T) = T$.\n    -   Quadratic variation over $[0,T]$: $T$.\n-   **Logical Conditions to Evaluate:**\n    -   $|\\widehat{\\mu}_T - 0| \\le \\varepsilon_{\\text{mean}}$\n    -   $|\\widehat{\\sigma}^2_T - T| \\le \\varepsilon_{\\text{var}}$\n    -   $|\\widehat{Q}_T - T| \\le \\varepsilon_{\\text{qv}}$\n-   **Test Suite:**\n    -   Case 1: $(T, N, M, \\varepsilon_{\\text{mean}}, \\varepsilon_{\\text{var}}, \\varepsilon_{\\text{qv}}) = (1.0, 1000, 5000, 0.03, 0.05, 0.03)$.\n    -   Case 2: $(T, N, M, \\varepsilon_{\\text{mean}}, \\varepsilon_{\\text{var}}, \\varepsilon_{\\text{qv}}) = (0.0, 10, 1000, 10^{-10}, 10^{-10}, 10^{-10})$.\n    -   Case 3: $(T, N, M, \\varepsilon_{\\text{mean}}, \\varepsilon_{\\text{var}}, \\varepsilon_{\\text{qv}}) = (2.0, 1, 5000, 0.05, 0.07, 0.07)$.\n    -   Case 4: $(T, N, M, \\varepsilon_{\\text{mean}}, \\varepsilon_{\\text{var}}, \\varepsilon_{\\text{qv}}) = (1.0, 5, 5000, 0.03, 0.05, 0.05)$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to rigorous validation.\n\n1.  **Scientific or Factual Soundness:** The problem is based on the standard definition and properties of a Wiener process (Brownian motion), a cornerstone of stochastic calculus. The prescribed simulation method, involving the cumulative summation of independent Gaussian increments, is the canonical procedure for generating discrete approximations of BM paths. The theoretical values for the mean, variance, and quadratic variation are correct. The problem is scientifically and mathematically sound.\n\n2.  **Non-Formalizable or Irrelevant:** The problem is a well-defined numerical task directly related to *Monte Carlo simulation for SDEs*. It is not metaphorical or irrelevant.\n\n3.  **Incomplete or Contradictory Setup:** All necessary parameters ($T$, $N$, $M$, and tolerances) for each test case are explicitly provided. The definitions of the quantities to be computed are clear. The edge case $T=0$ is well-defined and serves as a valid logical test, as $\\Delta t = 0$ implies all increments and path values are deterministically zero, satisfying the checks against the theoretical values of zero. The case $N=1$ is also well-defined, reducing the simulation to drawing samples directly from the terminal distribution $\\mathcal{N}(0,T)$. The setup is complete and internally consistent.\n\n4.  **Unrealistic or Infeasible:** The specified parameters for the number of paths $M$ and time steps $N$ are computationally tractable. The simulation is feasible on standard computing hardware.\n\n5.  **Ill-Posed or Poorly Structured:** The problem is well-posed. Although the outcome of a Monte Carlo simulation is stochastic, the problem asks for the evaluation of logical conditions based on the results of one such simulation. For a given random seed, the output is deterministic. The Law of Large Numbers and the consistency of the sample variance estimator guarantee that for large $M$, the empirical statistics will converge towards their theoretical counterparts, making the validation checks meaningful.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a standard, well-posed exercise in computational stochastic processes. A solution will now be provided.\n\n### Solution\n\nThe objective is to simulate paths of a standard Brownian motion and verify that the statistical properties of the simulated paths are consistent with theory. This is accomplished using a Monte Carlo method.\n\n**1. Theoretical Framework**\n\nA standard one-dimensional Brownian motion, $W_t$, is a stochastic process characterized by three properties:\n-   $W_0 = 0$.\n-   For any sequence of times $0 \\le t_1 < t_2 < \\dots < t_k$, the increments $W_{t_2}-W_{t_1}, W_{t_3}-W_{t_2}, \\dots, W_{t_k}-W_{t_{k-1}}$ are independent random variables.\n-   For any $0 \\le s < t$, the increment $W_t - W_s$ is normally distributed with mean $0$ and variance $t-s$, i.e., $W_t - W_s \\sim \\mathcal{N}(0, t-s)$.\n\nFrom these properties, we can determine the theoretical values for the quantities of interest at a terminal time $T > 0$:\n-   **Mean of the endpoint:** $\\mathbb{E}[W_T] = \\mathbb{E}[W_T - W_0] = 0$.\n-   **Variance of the endpoint:** $\\mathrm{Var}(W_T) = \\mathrm{Var}(W_T - W_0) = T - 0 = T$.\n-   **Quadratic Variation:** The quadratic variation of a Brownian motion over the interval $[0, T]$ is a fundamental property and is equal to $T$.\n\n**2. Discretization and Path Generation**\n\nTo simulate a BM path on a computer, we must discretize the time interval $[0, T]$. We create a uniform grid of $N+1$ points, $t_n = n \\Delta t$ for $n = 0, 1, \\dots, N$, where the time step is $\\Delta t = T/N$.\n\nA discrete path is constructed as follows:\n-   Start at $W_{t_0} = W_0 = 0$.\n-   Generate a sequence of $N$ independent random increments, $\\Delta W_k$, for $k=1, \\dots, N$. According to the BM properties, each increment $\\Delta W_k = W_{t_k} - W_{t_{k-1}}$ must be sampled from the distribution $\\mathcal{N}(0, t_k - t_{k-1}) = \\mathcal{N}(0, \\Delta t)$. A standard way to do this is to generate a standard normal random variable $Z_k \\sim \\mathcal{N}(0, 1)$ and scale it: $\\Delta W_k = \\sqrt{\\Delta t} \\cdot Z_k$.\n-   The value of the process at each grid point $t_n$ is obtained by summing the increments: $W_{t_n} = \\sum_{k=1}^n \\Delta W_k$. The endpoint of the path is $W_T = W_{t_N} = \\sum_{k=1}^N \\Delta W_k$.\n\n**3. Monte Carlo Estimation**\n\nWe generate $M$ independent paths of the process. Let $W_T^{(j)}$ be the endpoint of the $j$-th path and $\\{\\Delta W_k^{(j)}\\}_{k=1}^N$ be the increments of the $j$-th path, for $j = 1, \\dots, M$. We then compute the following empirical estimators:\n\n-   **Sample Mean of Endpoints:** This estimates $\\mathbb{E}[W_T]$. By the Law of Large Numbers, as $M \\to \\infty$, the sample mean converges to the true mean.\n    $$ \\widehat{\\mu}_T = \\frac{1}{M} \\sum_{j=1}^M W_T^{(j)} $$\n-   **Sample Variance of Endpoints:** This estimates $\\mathrm{Var}(W_T)$. We use the unbiased sample variance, which is a consistent estimator.\n    $$ \\widehat{\\sigma}^2_T = \\frac{1}{M-1} \\sum_{j=1}^M \\left(W_T^{(j)} - \\widehat{\\mu}_T\\right)^2 $$\n-   **Average Discrete Quadratic Variation:** This estimates the true quadratic variation, $T$. The discrete quadratic variation for a single path is $\\sum_{k=1}^N (\\Delta W_k^{(j)})^2$. The expected value of this sum is $\\sum_{k=1}^N \\mathbb{E}[(\\Delta W_k^{(j)})^2] = \\sum_{k=1}^N \\Delta t = N \\Delta t = T$. By averaging over $M$ paths, we obtain a more robust estimate.\n    $$ \\widehat{Q}_T = \\frac{1}{M} \\sum_{j=1}^M \\left( \\sum_{k=1}^N (\\Delta W_k^{(j)})^2 \\right) $$\n\n**4. Algorithmic Implementation**\n\nFor each test case with parameters $(T, N, M, \\varepsilon_{\\text{mean}}, \\varepsilon_{\\text{var}}, \\varepsilon_{\\text{qv}})$:\n\n1.  Set a random seed for reproducibility.\n2.  Handle the edge case $T=0$. If $T=0$, then $\\Delta t=0$, and all increments, endpoints, and variations are deterministically $0$. The checks against the theoretical value of $0$ are trivially true.\n3.  If $T>0$, calculate $\\Delta t = T/N$.\n4.  Generate an $M \\times N$ matrix of independent standard normal random variables, $Z_{j,k} \\sim \\mathcal{N}(0,1)$.\n5.  Calculate the matrix of increments $\\Delta W$ by scaling $Z$ by $\\sqrt{\\Delta t}$.\n6.  Calculate the vector of $M$ endpoints, $W_T$, by summing the increments along each row (axis $1$) of the $\\Delta W$ matrix.\n7.  Calculate the vector of $M$ discrete quadratic variations by summing the squares of the increments along each row of the $\\Delta W$ matrix.\n8.  Compute the estimators:\n    -   $\\widehat{\\mu}_T = \\mathrm{mean}(W_T)$\n    -   $\\widehat{\\sigma}^2_T = \\mathrm{var}(W_T, \\text{ddof}=1)$\n    -   $\\widehat{Q}_T = \\mathrm{mean}(\\text{quadratic variations})$\n9.  Evaluate the three logical conditions specified in the problem statement and store the boolean results.\n\nThis procedure is repeated for all test cases, and the boolean results are concatenated into a single list for the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates Brownian Motion paths and validates their statistical properties.\n    \"\"\"\n    # Set a random seed for reproducibility of the Monte Carlo simulation.\n    np.random.seed(0)\n\n    # Define the test cases from the problem statement.\n    # Format: (T, N, M, eps_mean, eps_var, eps_qv)\n    test_cases = [\n        (1.0, 1000, 5000, 0.03, 0.05, 0.03),\n        (0.0, 10, 1000, 1e-10, 1e-10, 1e-10),\n        (2.0, 1, 5000, 0.05, 0.07, 0.07),\n        (1.0, 5, 5000, 0.03, 0.05, 0.05),\n    ]\n\n    results = []\n    for case in test_cases:\n        T, N, M, eps_mean, eps_var, eps_qv = case\n\n        # The theoretical values for the statistics\n        true_mean = 0.0\n        true_var = T\n        true_qv = T\n\n        # Handle the deterministic case where T=0\n        if T == 0.0:\n            # If T=0, W_t is always 0. All statistics are exactly 0.\n            mu_hat_T = 0.0\n            sigma2_hat_T = 0.0\n            Q_hat_T = 0.0\n        else:\n            # Standard simulation for T > 0\n            # Calculate time step\n            dt = T / N\n            \n            # Generate random increments for M paths with N steps.\n            # Increments are drawn from N(0, dt).\n            # This is done by generating from N(0, 1) and scaling by sqrt(dt).\n            # Shape of increments is (M, N)\n            increments = np.random.normal(loc=0.0, scale=np.sqrt(dt), size=(M, N))\n\n            # --- Calculate statistics ---\n\n            # 1. Endpoints W_T\n            # For each path, W_T is the sum of its increments.\n            # Shape of endpoints is (M,)\n            endpoints = np.sum(increments, axis=1)\n\n            # Sample mean of the endpoints\n            mu_hat_T = np.mean(endpoints)\n            \n            # Unbiased sample variance of the endpoints (ddof=1)\n            # This is the standard estimator for variance.\n            sigma2_hat_T = np.var(endpoints, ddof=1)\n\n            # 2. Discrete Quadratic Variation\n            # For each path, this is the sum of the squares of the increments.\n            # Shape of quadratic_variations_per_path is (M,)\n            quadratic_variations_per_path = np.sum(np.square(increments), axis=1)\n\n            # Average discrete quadratic variation over all paths\n            Q_hat_T = np.mean(quadratic_variations_per_path)\n\n        # --- Evaluate logical conditions ---\n        \n        # Condition 1: Check absolute error of the sample mean\n        check_mean = np.abs(mu_hat_T - true_mean) <= eps_mean\n        \n        # Condition 2: Check absolute error of the sample variance\n        check_var = np.abs(sigma2_hat_T - true_var) <= eps_var\n        \n        # Condition 3: Check absolute error of the average quadratic variation\n        check_qv = np.abs(Q_hat_T - true_qv) <= eps_qv\n        \n        results.extend([check_mean, check_var, check_qv])\n\n    # Convert boolean results to lowercase strings for printing\n    # This is a common requirement, but problem asks for bool values.\n    # The repr of a bool is 'True' or 'False' which is correct. Let's use map(str, ...)\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3067070"}, {"introduction": "With a simulated Brownian path in hand, the next task is to discretize and solve the SDE itself. This exercise focuses on the most fundamental numerical scheme, the Euler-Maruyama method, by having you compute a single step for the widely-used Geometric Brownian Motion model. Mastering this single-step update, $X_{n+1} \\approx X_n + \\mu X_n \\Delta t + \\sigma X_n \\Delta W_n$, is key to understanding how entire sample paths are constructed in a simulation.", "problem": "Consider the geometric Brownian motion, a Stochastic Differential Equation (SDE), given by $dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$, where $W_t$ is a standard Brownian motion. In a Monte Carlo (MC) simulation, time is discretized on a uniform grid $t_n$ with step size $\\Delta t = t_{n+1} - t_n$. At each step, the Brownian increment $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ is sampled from a normal distribution with mean $0$ and variance $\\Delta t$, that is $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$. \n\nYou are given the parameter values $\\mu = 0.05$, $\\sigma = 0.2$, the current state $X_n = 50$, and the time step $\\Delta t = 0.01$. Suppose a MC draw yields a standard normal variate $Z_n = 0.32$, and we set $\\Delta W_n = \\sqrt{\\Delta t}\\,Z_n$. Using a first-principles discretization of the SDE over one time step from $t_n$ to $t_{n+1}$, compute the updated value $X_{n+1}$ produced by one Euler-Maruyama step starting from $X_n$. \n\nRound your final result to four significant figures.", "solution": "The geometric Brownian motion SDE is given by $dX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t$. Over a small time interval $[t_n, t_{n+1}]$ with $\\Delta t = t_{n+1} - t_n$, the integral form is\n$$\nX_{t_{n+1}} - X_{t_n} = \\int_{t_n}^{t_{n+1}} \\mu X_s\\,ds + \\int_{t_n}^{t_{n+1}} \\sigma X_s\\,dW_s.\n$$\nA first-order explicit time discretization, known as the Euler-Maruyama method, approximates the drift integral by evaluating the integrand at the left endpoint and multiplying by the step size, and approximates the Itô integral by evaluating the integrand at the left endpoint and multiplying by the Brownian increment. Thus,\n$$\nX_{n+1} \\approx X_n + \\mu X_n \\Delta t + \\sigma X_n \\Delta W_n.\n$$\nIn a Monte Carlo implementation, the Brownian increment $\\Delta W_n$ is sampled according to $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$. A convenient construction uses a standard normal variate $Z_n \\sim \\mathcal{N}(0,1)$ and sets\n$$\n\\Delta W_n = \\sqrt{\\Delta t}\\, Z_n.\n$$\nWith the given values $\\Delta t = 0.01$ and $Z_n = 0.32$, we compute\n$$\n\\sqrt{\\Delta t} = \\sqrt{0.01} = 0.1,\n$$\nso\n$$\n\\Delta W_n = 0.1 \\times 0.32 = 0.032.\n$$\nNow substitute $\\mu = 0.05$, $\\sigma = 0.2$, $X_n = 50$, and $\\Delta t = 0.01$, $\\Delta W_n = 0.032$ into the Euler-Maruyama update:\n$$\nX_{n+1} = 50 + (0.05)(50)(0.01) + (0.2)(50)(0.032).\n$$\nCompute the contributions term by term:\n- Drift term: $(0.05)(50)(0.01) = 0.05 \\times 0.5 = 0.025$.\n- Diffusion term: $(0.2)(50)(0.032) = 0.2 \\times 1.6 = 0.32$.\nTherefore,\n$$\nX_{n+1} = 50 + 0.025 + 0.32 = 50.345.\n$$\nRounding to four significant figures gives $50.35$.", "answer": "$$\\boxed{50.35}$$", "id": "3067105"}, {"introduction": "Implementing a simulation is one thing; quantifying its accuracy is another. This advanced practice ties everything together by guiding you through a numerical experiment to measure convergence rates, a crucial aspect of validating any numerical method. By empirically estimating the strong error, $\\mathbb{E}[|X_T^{\\Delta t}-X_T|^2]^{1/2}$, and the weak error, $|\\mathbb{E}[\\varphi(X_T^{\\Delta t})] - \\mathbb{E}[\\varphi(X_T)]|$, you will gain deep insight into the performance of the Euler-Maruyama scheme and learn a standard technique for analyzing computational methods for SDEs.", "problem": "Design and implement a self-contained numerical experiment to empirically estimate strong and weak convergence rates for a time-discretization method applied to a stochastic differential equation (SDE), by refining the time step and comparing pathwise and expectation errors.\n\nYou must base your work on the following fundamental setup and definitions.\n\n1. Stochastic differential equation model. Consider the Geometric Brownian Motion (GBM) SDE\n$$\ndX_t = \\mu X_t\\,dt + \\sigma X_t\\,dW_t,\\quad X_0>0,\n$$\nwhere $W_t$ is a standard Brownian motion, and $\\mu,\\sigma \\in \\mathbb{R}$ are constants. For time discretization, use the Euler–Maruyama (EM) method, which is the most basic scheme derived from the Itô integral definition and the increment approximation $dW_t \\approx \\Delta W$ with $\\Delta W \\sim \\mathcal{N}(0,\\Delta t)$.\n\n2. Error notions. For a fixed final time $T>0$, let $X_T^{\\Delta t}$ denote the EM approximation at time $T$ with time step $\\Delta t$. Define:\n- The strong error at time $T$ as\n$$\ne_{\\text{strong}}(\\Delta t) = \\left(\\mathbb{E}\\left[\\,|X_T^{\\Delta t}-X_T|^2\\,\\right]\\right)^{1/2}.\n$$\n- The weak error at time $T$ for a test function $\\varphi$ as\n$$\ne_{\\text{weak}}(\\Delta t) = \\left|\\,\\mathbb{E}\\left[\\varphi\\left(X_T^{\\Delta t}\\right)\\right] - \\mathbb{E}\\left[\\varphi\\left(X_T\\right)\\right]\\right|.\n$$\n\n3. Monte Carlo (MC) experiment design. Use Monte Carlo to estimate these errors for a sequence of refined time steps $\\Delta t$. For the strong error, couple the Brownian paths across refinements by reusing a single fine Brownian grid whose increments are summed to form coarser-grid increments. For the weak error, evaluate $\\varphi$ on the EM terminal values and compare to the exact value of $\\mathbb{E}[\\varphi(X_T)]$ obtained from first principles. Use the following test functions to ensure closed-form targets:\n- Case $\\varphi(x)=x^k$ with $k \\in \\{1,2\\}$.\n\n4. Convergence rates. For each sequence of decreasing time steps $\\{\\Delta t_\\ell\\}$ and corresponding error estimates $\\{e(\\Delta t_\\ell)\\}$, estimate the empirical convergence rate $p$ by a linear least-squares fit of $\\log e(\\Delta t_\\ell)$ versus $\\log \\Delta t_\\ell$, i.e., fit\n$$\n\\log e(\\Delta t_\\ell) \\approx a + p \\,\\log \\Delta t_\\ell,\n$$\nand take the slope $p$ as the estimated rate.\n\nProgram requirements and test suite.\n\nA. Implement a program that:\n- Simulates the EM approximation of GBM to time $T$ for a sequence of time steps formed by $M \\in \\{4,8,16,32,64\\}$ uniform subintervals, i.e., $\\Delta t = T/M$.\n- Uses a single finest grid with $M_{\\max}=64$ to generate Brownian increments $\\Delta W$; obtain coarser-level increments by summing disjoint consecutive blocks of fine increments to enforce pathwise coupling across refinements.\n- Estimates the strong error by a Monte Carlo root-mean-square (RMS) over coupled paths using the exact solution $X_T$ evaluated on the same Brownian terminal values to define $X_T$ pathwise.\n- Estimates the weak error using the Monte Carlo average of $\\varphi(X_T^{\\Delta t})$ and the exact value of $\\mathbb{E}[\\varphi(X_T)]$ derived from the GBM law.\n- Uses $N$ Monte Carlo paths with a fixed random seed for reproducibility.\n\nB. Use the following test suite of parameter sets, covering typical, boundary, and edge-like regimes. For each test case, report two floats: the estimated strong convergence rate and the estimated weak convergence rate, in this order.\n\n- Test case $1$ (happy path): $X_0=1.0$, $\\mu=0.3$, $\\sigma=0.5$, $T=1.0$, $\\varphi(x)=x$ (i.e., $k=1$), $N=20000$, seed $=12345$.\n- Test case $2$ (boundary: zero drift, nonlinear moment): $X_0=2.0$, $\\mu=0.0$, $\\sigma=0.8$, $T=2.0$, $\\varphi(x)=x^2$ (i.e., $k=2$), $N=20000$, seed $=12346$.\n- Test case $3$ (edge-like: negative drift, large volatility, short horizon): $X_0=1.5$, $\\mu=-0.2$, $\\sigma=1.2$, $T=0.5$, $\\varphi(x)=x$ (i.e., $k=1$), $N=20000$, seed $=12347$.\n\nC. Final output format. Your program should produce a single line of output containing the results as a list of lists of floats, one inner list per test case in the order given above:\n- The format must be\n$$\n\\big[ [p_{\\text{strong},1},\\, p_{\\text{weak},1}],\\; [p_{\\text{strong},2},\\, p_{\\text{weak},2}],\\; [p_{\\text{strong},3},\\, p_{\\text{weak},3}] \\big],\n$$\nwith each float rounded to three decimal places.\n\nNo external inputs or files are allowed. The program must run as is and follow the specified random seeds. No physical units or angle units are involved. The output must be exactly one line in the specified format.", "solution": "The objective is to empirically determine the strong and weak convergence rates of the Euler-Maruyama (EM) method for the Geometric Brownian Motion (GBM) stochastic differential equation (SDE). This will be accomplished through a Monte Carlo simulation experiment where the time step is refined, and the resulting errors are analyzed.\n\n### 1. Theoretical Framework\n\n#### 1.1. The Geometric Brownian Motion SDE and its Solution\nThe problem is based on the Geometric Brownian Motion SDE:\n$$\ndX_t = \\mu X_t \\,dt + \\sigma X_t \\,dW_t, \\quad X(0) = X_0 > 0\n$$\nwhere $\\mu$ is the drift rate, $\\sigma$ is the volatility, and $W_t$ is a standard Wiener process (Brownian motion). This SDE possesses a known strong solution, which can be found using Itô's lemma on $f(x) = \\log(x)$. The solution for the process at time $T$ is:\n$$\nX_T = X_0 \\exp\\left( \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T + \\sigma W_T \\right)\n$$\nHere, $W_T$ is a normally distributed random variable, $W_T \\sim \\mathcal{N}(0, T)$. This exact solution is fundamental for calculating the pathwise error required for the strong convergence analysis.\n\n#### 1.2. The Euler-Maruyama Discretization\nThe Euler-Maruyama method is a numerical scheme for approximating the solution of an SDE. For a time interval $[0, T]$ discretized into $M$ steps of size $\\Delta t = T/M$, the scheme for the GBM SDE is given by the iterative formula:\n$$\nX_{n+1} = X_n + \\mu X_n \\Delta t + \\sigma X_n \\Delta W_{n+1}\n$$\nwhere $X_n$ is the approximation of $X_{t_n}$ at time $t_n = n\\Delta t$. The term $\\Delta W_{n+1} = W_{t_{n+1}} - W_{t_n}$ is an increment of the Wiener process, which is simulated as an independent random variable drawn from a normal distribution $\\mathcal{N}(0, \\Delta t)$. The terminal value of this approximation at time $T$ is denoted as $X_T^{\\Delta t}$.\n\n#### 1.3. Error Definitions and Convergence Rates\nThe analysis relies on two types of error metrics.\n-   The **strong error** measures the pathwise-average deviation between the numerical approximation and the exact solution. It is defined as the root-mean-square error:\n    $$\n    e_{\\text{strong}}(\\Delta t) = \\left( \\mathbb{E}\\left[ |X_T^{\\Delta t} - X_T|^2 \\right] \\right)^{1/2}\n    $$\n    The strong convergence rate $p_{\\text{strong}}$ is such that $e_{\\text{strong}}(\\Delta t) = \\mathcal{O}((\\Delta t)^{p_{\\text{strong}}})$. For the Euler-Maruyama method, the theoretical strong rate is $p_{\\text{strong}} = 0.5$.\n\n-   The **weak error** measures the error in the expectation of functions of the solution. For a given test function $\\varphi$, it is defined as:\n    $$\n    e_{\\text{weak}}(\\Delta t) = \\left| \\mathbb{E}\\left[\\varphi\\left(X_T^{\\Delta t}\\right)\\right] - \\mathbb{E}\\left[\\varphi\\left(X_T\\right)\\right] \\right|\n    $$\n    The weak convergence rate $p_{\\text{weak}}$ is such that $e_{\\text{weak}}(\\Delta t) = \\mathcal{O}((\\Delta t)^{p_{\\text{weak}}})$. For the Euler-Maruyama method, the theoretical weak rate is $p_{\\text{weak}} = 1.0$.\n\nFor this problem, the test functions are monomials $\\varphi(x) = x^k$. The exact expectation $\\mathbb{E}[\\varphi(X_T)] = \\mathbb{E}[X_T^k]$ can be calculated from the log-normal distribution of $X_T$. Since $\\ln(X_T) \\sim \\mathcal{N}\\left(\\ln(X_0) + (\\mu - \\frac{1}{2}\\sigma^2)T, \\sigma^2 T\\right)$, the $k$-th moment is:\n$$\n\\mathbb{E}[X_T^k] = X_0^k \\exp\\left( k\\mu T + \\frac{1}{2}k(k-1)\\sigma^2 T \\right)\n$$\nThis formula provides the exact value against which the numerical average $\\mathbb{E}[\\varphi(X_T^{\\Delta t})]$ is compared.\n\n### 2. Numerical Experiment Design\n\nThe convergence rates are estimated empirically from a numerical experiment.\n\n#### 2.1. Monte Carlo Simulation and Path Coupling\nWe generate $N$ independent sample paths to estimate the expectations. A crucial element for strong error estimation is **path coupling**. To ensure that the difference $|X_T^{\\Delta t} - X_T|$ is meaningful, both the approximate and exact solutions must be driven by the same realization of the underlying Brownian path $W_t$. We achieve this by generating a single set of Brownian increments on the finest grid, with $M_{\\max}$ steps. Let these fine increments be $\\{\\Delta W_i^{\\text{fine}}\\}_{i=1}^{M_{\\max}}$. A coarser grid with $M < M_{\\max}$ steps (where $M$ divides $M_{\\max}$) uses increments $\\Delta W_j^{\\text{coarse}}$ formed by summing blocks of fine increments:\n$$\n\\Delta W_j^{\\text{coarse}} = \\sum_{i=(j-1)S+1}^{jS} \\Delta W_i^{\\text{fine}}, \\quad \\text{where } S = M_{\\max} / M\n$$\nThe total Brownian motion at the final time, $W_T = \\sum_i \\Delta W_i$, is therefore identical for all discretization levels, enabling a valid path-by-path comparison.\n\n#### 2.2. Error Estimation\nThe expectations in the error definitions are approximated by Monte Carlo averages over the $N$ sample paths.\n-   The strong error is estimated by:\n    $$\n    \\hat{e}_{\\text{strong}}(\\Delta t) = \\left( \\frac{1}{N} \\sum_{j=1}^{N} \\left| X_{T, j}^{\\Delta t} - X_{T, j} \\right|^2 \\right)^{1/2}\n    $$\n    where $j$ indexes the Monte Carlo path.\n-   The weak error is estimated by:\n    $$\n    \\hat{e}_{\\text{weak}}(\\Delta t) = \\left| \\left( \\frac{1}{N} \\sum_{j=1}^{N} \\varphi(X_{T, j}^{\\Delta t}) \\right) - \\mathbb{E}[\\varphi(X_T)] \\right|\n    $$\n\n#### 2.3. Convergence Rate Calculation\nWe generate a sequence of time steps $\\{\\Delta t_\\ell = T/M_\\ell\\}$ for $M_\\ell \\in \\{4, 8, 16, 32, 64\\}$ and compute the corresponding error estimates $\\{\\hat{e}(\\Delta t_\\ell)\\}$. The convergence rate $p$ is determined by fitting the model $\\log \\hat{e}(\\Delta t_\\ell) \\approx a + p \\log \\Delta t_\\ell$. This is a linear regression problem for $(\\log \\Delta t_\\ell, \\log \\hat{e}(\\Delta t_\\ell))$. The slope $p$ of the best-fit line is the estimated convergence rate. This can be calculated using standard methods, such as a polynomial fit of degree $1$.\n\n### 3. Implementation\nThe implementation will follow these steps for each test case:\n1.  Set the parameters $X_0, \\mu, \\sigma, T, k, N$ and the random seed.\n2.  Generate $N \\times M_{\\max}$ standard normal random variables, scaled to represent the fine-grid Brownian increments $\\Delta W_i^{\\text{fine}}$.\n3.  For each of the $N$ paths, calculate the exact terminal value $X_T$ using the sum of all fine increments for $W_T$.\n4.  Calculate the exact moment $\\mathbb{E}[\\varphi(X_T)]$.\n5.  Iterate through the specified refinement levels $M \\in \\{4, 8, 16, 32, 64\\}$:\n    a. Construct the coarser Brownian increments by summing blocks of the fine increments.\n    b. Simulate the EM paths to time $T$ to get $X_T^{\\Delta t}$.\n    c. Compute and store the strong and weak error estimates for this $\\Delta t$.\n6.  Perform a linear regression on the log-log plot of errors versus time steps to find the slopes, which are the estimated strong and weak convergence rates.\n7.  The results from all test cases are collected and formatted into the required output string.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs and implements a numerical experiment to estimate strong and weak\n    convergence rates for the Euler-Maruyama method applied to the Geometric\n    Brownian Motion SDE.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (X0, mu, sigma, T, k, N, seed)\n        (1.0, 0.3, 0.5, 1.0, 1, 20000, 12345),\n        (2.0, 0.0, 0.8, 2.0, 2, 20000, 12346),\n        (1.5, -0.2, 1.2, 0.5, 1, 20000, 12347)\n    ]\n\n    # Levels of discretization (number of steps)\n    M_levels = [4, 8, 16, 32, 64]\n    M_max = 64\n\n    results = []\n    for case in test_cases:\n        X0, mu, sigma, T, k, N, seed = case\n        \n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # --- Monte Carlo Simulation Setup ---\n        \n        # Generate all Brownian increments for the finest grid (M_max)\n        # These are used to build increments for all coarser grids\n        dt_fine = T / M_max\n        fine_shocks = rng.normal(loc=0.0, scale=np.sqrt(dt_fine), size=(N, M_max))\n\n        # Calculate the exact solution X_T for each path\n        # W_T is the sum of all fine increments\n        W_T = fine_shocks.sum(axis=1)\n        X_T_exact = X0 * np.exp((mu - 0.5 * sigma**2) * T + sigma * W_T)\n\n        # Calculate the exact expectation for the weak error component\n        # E[X_T^k] = X0^k * exp(k*mu*T + 0.5*k*(k-1)*sigma^2*T)\n        exact_moment = (X0**k) * np.exp(k * mu * T + 0.5 * k * (k - 1) * (sigma**2) * T)\n\n        # Store errors and step sizes for regression\n        dts = []\n        strong_errors = []\n        weak_errors = []\n\n        # --- Loop over refinement levels ---\n        for M in M_levels:\n            dt = T / M\n            dts.append(dt)\n\n            # --- Path Generation (Euler-Maruyama) ---\n            \n            # Construct coarse Brownian increments from fine ones (path coupling)\n            # Sum blocks of fine_shocks to get shocks for the current grid size M\n            step_size = M_max // M\n            coarse_shocks = fine_shocks.reshape(N, M, step_size).sum(axis=2)\n\n            # Simulate paths using Euler-Maruyama\n            X_em = np.full(N, X0)\n            for i in range(M):\n                # The formula is X_{n+1} = X_n * (1 + mu*dt + sigma*dW)\n                X_em += mu * X_em * dt + sigma * X_em * coarse_shocks[:, i]\n            \n            X_T_em = X_em\n\n            # --- Error Calculation ---\n\n            # Strong error: (E[|X_T^EM - X_T_exact|^2])^0.5\n            strong_error = np.sqrt(np.mean((X_T_em - X_T_exact)**2))\n            strong_errors.append(strong_error)\n\n            # Weak error: |E[phi(X_T^EM)] - E[phi(X_T_exact)]|\n            # where phi(x) = x^k\n            em_moment = np.mean(X_T_em**k)\n            weak_error = np.abs(em_moment - exact_moment)\n            weak_errors.append(weak_error)\n\n        # --- Convergence Rate Estimation ---\n        \n        # Use linear regression on log-log data to find the slope (rate)\n        # log(error) = a + p * log(dt)\n        # np.polyfit(x, y, 1) returns [p, a]\n        \n        log_dts = np.log(dts)\n        \n        # Strong rate\n        log_strong_errors = np.log(strong_errors)\n        p_strong = np.polyfit(log_dts, log_strong_errors, 1)[0]\n        \n        # Weak rate\n        log_weak_errors = np.log(weak_errors)\n        p_weak = np.polyfit(log_dts, log_weak_errors, 1)[0]\n        \n        results.append([p_strong, p_weak])\n\n    # --- Final Output Formatting ---\n    # The format must be [[p_strong,1, p_weak,1], [p_strong,2, p_weak,2], [p_strong,3, p_weak,3]]\n    # Each float is rounded to three decimal places.\n    output_str = f\"[{', '.join([f'[{s:.3f}, {w:.3f}]' for s, w in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3067097"}]}