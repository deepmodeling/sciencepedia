{"hands_on_practices": [{"introduction": "Before delving into the complexities of stochastic processes, it is essential to understand their deterministic counterparts. This practice grounds your understanding by examining a simple, continuously differentiable path, treating it as a stochastic process [@problem_id:3064274]. By applying the definitions of a semimartingale and quadratic variation from first principles, you will demonstrate a fundamental result: smooth, predictable paths have zero quadratic variation and, consequently, a trivial local time.", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\geq 0},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions. Fix a finite time horizon $T0$, and let $x:[0,T]\\to\\mathbb{R}$ be a deterministic function that is continuously differentiable on $[0,T]$, i.e., $x\\in C^{1}([0,T])$. Consider the stochastic process defined by $X_{t}=x(t)$ for $t\\in[0,T]$.\n\nUsing only foundational definitions and well-tested facts, justify why $X$ is a continuous semimartingale by identifying an admissible decomposition into a local martingale part and a finite variation part, and by verifying the finite variation property from first principles. Then, starting from the definition of quadratic variation via partition limits, compute the quadratic variation of $X$ over $[0,T]$, denoted $[X]_{T}$, by evaluating the limit of the sum of squared increments over a sequence of partitions whose mesh tends to $0$.\n\nYour final answer must be a single exact value for $[X]_{T}$. No rounding is required.", "solution": "The process $X_{t}=x(t)$ is deterministic and continuous on $[0,T]$ because $x\\in C^{1}([0,T])$ implies $x$ is continuous. It is adapted to any filtration $(\\mathcal{F}_{t})_{t\\geq 0}$ because a deterministic process is measurable with respect to the trivial $\\sigma$-algebra at all times and thus adapted.\n\nBy definition, a semimartingale is a process that can be decomposed as the sum of a local martingale and a finite variation process. We exhibit the decomposition\n$$\nX_{t} \\;=\\; M_{t} + A_{t}, \\quad \\text{with} \\quad M_{t}=0 \\quad \\text{and} \\quad A_{t}=x(t).\n$$\nThe process $M$ is trivially a (continuous) local martingale since it is constant zero. To complete the justification that $X$ is a continuous semimartingale, it suffices to show that $A$ has finite variation on $[0,T]$.\n\nRecall the total variation of a function $x$ on $[0,T]$ is defined as\n$$\nV_{T}(x) \\;=\\; \\sup_{\\Pi}\\sum_{i=1}^{n} \\big| x(t_{i}) - x(t_{i-1}) \\big|,\n$$\nwhere the supremum is taken over all finite partitions $\\Pi=\\{0=t_{0}t_{1}\\dotst_{n}=T\\}$ of $[0,T]$. Since $x\\in C^{1}([0,T])$, the fundamental theorem of calculus yields\n$$\nx(t_{i}) - x(t_{i-1}) \\;=\\; \\int_{t_{i-1}}^{t_{i}} x'(s)\\, \\mathrm{d}s.\n$$\nApplying the triangle inequality and summing over the partition,\n$$\n\\sum_{i=1}^{n} \\big| x(t_{i}) - x(t_{i-1}) \\big|\n\\;=\\; \\sum_{i=1}^{n} \\left| \\int_{t_{i-1}}^{t_{i}} x'(s)\\, \\mathrm{d}s \\right|\n\\;\\leq\\; \\sum_{i=1}^{n} \\int_{t_{i-1}}^{t_{i}} |x'(s)|\\, \\mathrm{d}s\n\\;=\\; \\int_{0}^{T} |x'(s)|\\, \\mathrm{d}s.\n$$\nBecause $x'$ is continuous on $[0,T]$, the integral $\\int_{0}^{T} |x'(s)|\\, \\mathrm{d}s$ is finite. Hence $V_{T}(x)\\infty$, so $A$ has finite variation on $[0,T]$. Therefore $X$ is a continuous semimartingale via the decomposition $X=M+A$ with $M=0$ and $A=x$.\n\nWe now compute the quadratic variation $[X]_{T}$ from first principles. By definition, for a continuous process $X$, the quadratic variation on $[0,T]$ is given by the limit\n$$\n[X]_{T} \\;=\\; \\lim_{n\\to\\infty} \\sum_{i=1}^{m(n)} \\big( X_{t_{i}^{(n)}} - X_{t_{i-1}^{(n)}} \\big)^{2},\n$$\nwhere $\\{0=t_{0}^{(n)}t_{1}^{(n)}\\dotst_{m(n)}^{(n)}=T\\}$ is a sequence of partitions of $[0,T]$ whose mesh $\\|P_{n}\\|=\\max_{i}(t_{i}^{(n)}-t_{i-1}^{(n)})$ tends to $0$ as $n\\to\\infty$. Since $X_{t}=x(t)$ and $x\\in C^{1}([0,T])$, the mean value theorem ensures that for each interval $[t_{i-1}^{(n)},t_{i}^{(n)}]$ there exists $\\xi_{i}^{(n)}\\in (t_{i-1}^{(n)},t_{i}^{(n)})$ such that\n$$\nx\\big(t_{i}^{(n)}\\big) - x\\big(t_{i-1}^{(n)}\\big) \\;=\\; x'\\big(\\xi_{i}^{(n)}\\big)\\, \\big( t_{i}^{(n)} - t_{i-1}^{(n)} \\big).\n$$\nTherefore,\n$$\n\\sum_{i=1}^{m(n)} \\big( x\\big(t_{i}^{(n)}\\big) - x\\big(t_{i-1}^{(n)}\\big) \\big)^{2}\n\\;=\\; \\sum_{i=1}^{m(n)} \\big( x'\\big(\\xi_{i}^{(n)}\\big) \\big)^{2} \\big( t_{i}^{(n)} - t_{i-1}^{(n)} \\big)^{2}.\n$$\nLet $K=\\sup_{t\\in[0,T]} |x'(t)|$, which is finite because $x'$ is continuous on the compact interval $[0,T]$. Then\n$$\n\\sum_{i=1}^{m(n)} \\big( x\\big(t_{i}^{(n)}\\big) - x\\big(t_{i-1}^{(n)}\\big) \\big)^{2}\n\\;\\leq\\; K^{2}\\, \\sum_{i=1}^{m(n)} \\big( t_{i}^{(n)} - t_{i-1}^{(n)} \\big)^{2}\n\\;\\leq\\; K^{2}\\, \\|P_{n}\\| \\sum_{i=1}^{m(n)} \\big( t_{i}^{(n)} - t_{i-1}^{(n)} \\big)\n\\;=\\; K^{2}\\, \\|P_{n}\\|\\, T.\n$$\nAs $n\\to\\infty$, $\\|P_{n}\\|\\to 0$, hence the upper bound $K^{2}\\, \\|P_{n}\\|\\, T \\to 0$, which forces\n$$\n\\lim_{n\\to\\infty} \\sum_{i=1}^{m(n)} \\big( x\\big(t_{i}^{(n)}\\big) - x\\big(t_{i-1}^{(n)}\\big) \\big)^{2} \\;=\\; 0.\n$$\nTherefore, the quadratic variation of $X$ on $[0,T]$ is\n$$\n[X]_{T} \\;=\\; 0.\n$$\n\nAs a contextual remark related to local time of continuous semimartingales, note that continuous finite variation processes (such as $X$ here) have vanishing quadratic variation and consequently have trivial local time at any level: the local time $L^{a}_{t}$ of $X$ is identically $0$ for all $a\\in\\mathbb{R}$ and $t\\in[0,T]$. This aligns with the occupation density perspective, where local time reflects time spent oscillating at a level in a quadratic variation sense, which does not occur for finite variation paths.\n\nThe required computation is complete.", "answer": "$$\\boxed{0}$$", "id": "3064274"}, {"introduction": "Having established that smooth paths do not accumulate local time, we now turn to the canonical example of a process that does: standard Brownian motion. This exercise guides you through a classic derivation to compute the expected local time at the origin, a cornerstone result in stochastic calculus [@problem_id:3064283]. You will masterfully combine the reflection principle with Tanaka's formula to uncover the deep connection between local time and the expected absolute value of the process.", "problem": "Let $\\{W_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion starting at $W_{0} = 0$. For a fixed $t  0$, let $L_{t}^{0}(W)$ denote the local time of $W$ at level $0$ up to time $t$, defined as the continuous, increasing process satisfying the occupation density property for continuous semimartingales, and equivalently appearing in Tanaka's formula. Denote by $M_{t} = \\sup_{0 \\leq s \\leq t} W_{s}$ the running maximum of $W$ up to time $t$.\n\nUsing only fundamental properties of Brownian motion (independent stationary Gaussian increments, symmetry, continuity of paths) together with the reflection principle and the characterization of local time via Tanaka's formula, carry out the following steps:\n\n1. Derive the tail distribution of $M_{t}$ via the reflection principle, and use it to show that $M_{t}$ and $|W_{t}|$ have the same distribution.\n2. Compute $E[|W_{t}|]$ in closed form by an explicit integration against the Gaussian distribution, without invoking any pre-tabulated integrals beyond the basic properties of the Gaussian density.\n3. Justify carefully, using Tanaka's formula and martingale properties, that $E[L_{t}^{0}(W)] = E[|W_{t}|]$.\n\nYour final task is to provide a single closed-form analytic expression for $E[L_{t}^{0}(W)]$ as a function of $t$. Do not approximate or round; provide the exact expression.", "solution": "The problem is valid as it is scientifically grounded in the theory of stochastic processes, is well-posed with a unique and meaningful solution, and is stated objectively using precise mathematical language. We shall proceed by following the three steps laid out in the problem statement to derive the final expression for $E[L_{t}^{0}(W)]$.\n\nLet $\\{W_{t}\\}_{t \\geq 0}$ be a one-dimensional standard Brownian motion starting at $W_{0} = 0$. Let $M_{t} = \\sup_{0 \\leq s \\leq t} W_{s}$ be its running maximum.\n\nStep 1: Derivation of the distribution of $M_{t}$ and its relation to $|W_{t}|$.\nWe first determine the tail distribution of $M_{t}$, which is $P(M_{t} \\geq a)$ for any real number $a$. Since $W_{0}=0$ and the paths of $W$ are continuous, $M_{t} \\geq 0$ almost surely. Thus, for any $a \\leq 0$, $P(M_{t} \\geq a) = 1$.\n\nNow, consider $a  0$. The event $\\{M_{t} \\geq a\\}$ means that the Brownian path has reached or exceeded the level $a$ at some time in the interval $[0, t]$. Let $\\tau_{a} = \\inf\\{s \\geq 0: W_{s} = a\\}$ be the first hitting time of level $a$. Then $\\{M_{t} \\geq a\\} = \\{\\tau_{a} \\leq t\\}$.\nWe use the reflection principle for Brownian motion. We can partition the event $\\{M_{t} \\geq a\\}$ as follows:\n$$P(M_{t} \\geq a) = P(M_{t} \\geq a, W_{t} \\geq a) + P(M_{t} \\geq a, W_{t}  a)$$\nIf $W_{t} \\geq a$, then its maximum over $[0, t]$ must also be at least $a$. Thus, the event $\\{M_{t} \\geq a, W_{t} \\geq a\\}$ is the same as the event $\\{W_{t} \\geq a\\}$. So,\n$$P(M_{t} \\geq a, W_{t} \\geq a) = P(W_{t} \\geq a)$$\nFor the second term, on the event $\\{M_{t} \\geq a, W_{t}  a\\}$, the process must have hit level $a$ at some time $\\tau_{a} \\leq t$ and then finished at a value below $a$. By the strong Markov property of Brownian motion, the process $\\{W_{\\tau_{a}+u} - W_{\\tau_{a}}\\}_{u \\geq 0}$ is a standard Brownian motion independent of the pre-$\\tau_{a}$ filtration. At time $\\tau_a$, we have $W_{\\tau_a}=a$. The condition $W_{t}  a$ on the set $\\{\\tau_a \\le t\\}$ is equivalent to $W_t - W_{\\tau_a}  0$. By the symmetry of Brownian motion, the probability of the process being negative at time $t-\\tau_a$ is the same as the probability of it being positive.\nThus, conditioned on the event $\\{\\tau_{a} \\leq t\\}$, we have $P(W_{t}  a) = P(W_{t}  a)$. This implies:\n$$P(M_{t} \\geq a, W_{t}  a) = P(M_{t} \\geq a, W_{t}  a)$$\nThe event $\\{M_{t} \\geq a, W_{t}  a\\}$ is simply $\\{W_{t}  a\\}$, because if $W_{t}  a$, its maximum $M_{t}$ is certainly greater than $a$. Since $W_{t}$ has a continuous distribution, $P(W_{t}  a) = P(W_{t} \\geq a)$.\nTherefore, $P(M_{t} \\geq a, W_{t}  a) = P(W_{t} \\geq a)$.\nCombining these results, we have for $a  0$:\n$$P(M_{t} \\geq a) = P(W_{t} \\geq a) + P(W_{t} \\geq a) = 2 P(W_{t} \\geq a)$$\nNow, we find the tail distribution of $|W_{t}|$. For $a \\leq 0$, $P(|W_{t}| \\geq a) = 1$, which matches $P(M_{t} \\geq a)$. For $a  0$:\n$$P(|W_{t}| \\geq a) = P(W_{t} \\geq a \\text{ or } W_{t} \\leq -a)$$\nSince these two events are disjoint, we have:\n$$P(|W_{t}| \\geq a) = P(W_{t} \\geq a) + P(W_{t} \\leq -a)$$\nBy the symmetry of the standard Brownian motion, $W_{t}$ has the same distribution as $-W_{t}$. Hence, $P(W_{t} \\leq -a) = P(-W_{t} \\geq a) = P(W_{t} \\geq a)$.\nSubstituting this into the expression for the tail probability of $|W_{t}|$:\n$$P(|W_{t}| \\geq a) = P(W_{t} \\geq a) + P(W_{t} \\geq a) = 2 P(W_{t} \\geq a)$$\nWe have shown that for all $a \\in \\mathbb{R}$, $P(M_{t} \\geq a) = P(|W_{t}| \\geq a)$. This implies that the random variables $M_{t}$ and $|W_{t}|$ have the same distribution, denoted $M_{t} \\stackrel{d}{=} |W_{t}|$.\n\nStep 2: Computation of $E[|W_{t}|]$.\nThe random variable $W_{t}$ follows a normal distribution with mean $0$ and variance $t$, denoted $W_{t} \\sim N(0, t)$. Its probability density function (PDF) is given by:\n$$f_{W_{t}}(x) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^{2}}{2t}\\right)$$\nThe expected value of $|W_{t}|$ is computed by integrating $|x|$ against this density:\n$$E[|W_{t}|] = \\int_{-\\infty}^{\\infty} |x| \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^{2}}{2t}\\right) dx$$\nThe integrand is an even function of $x$. We can therefore simplify the integral:\n$$E[|W_{t}|] = 2 \\int_{0}^{\\infty} x \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^{2}}{2t}\\right) dx = \\frac{2}{\\sqrt{2\\pi t}} \\int_{0}^{\\infty} x \\exp\\left(-\\frac{x^{2}}{2t}\\right) dx$$\nTo evaluate the integral, we perform a substitution. Let $u = \\frac{x^{2}}{2t}$. Then $du = \\frac{2x}{2t} dx = \\frac{x}{t} dx$, which implies $x \\, dx = t \\, du$. The limits of integration remain $0$ to $\\infty$.\n$$E[|W_{t}|] = \\frac{2}{\\sqrt{2\\pi t}} \\int_{0}^{\\infty} \\exp(-u) (t \\, du) = \\frac{2t}{\\sqrt{2\\pi t}} \\int_{0}^{\\infty} \\exp(-u) du$$\nThe standard integral $\\int_{0}^{\\infty} \\exp(-u) du = [-\\exp(-u)]_{0}^{\\infty} = -(0 - 1) = 1$.\nSubstituting this result back, we get:\n$$E[|W_{t}|] = \\frac{2t}{\\sqrt{2\\pi t}} = \\frac{2t}{\\sqrt{2\\pi}\\sqrt{t}} = \\frac{2\\sqrt{t}}{\\sqrt{2\\pi}} = \\sqrt{\\frac{4t}{2\\pi}} = \\sqrt{\\frac{2t}{\\pi}}$$\n\nStep 3: Justification that $E[L_{t}^{0}(W)] = E[|W_{t}|]$.\nWe apply Tanaka's formula to the process $W_{t}$ and the function $f(x) = |x|$. For a level $a=0$ and starting point $W_0=0$, Tanaka's formula states:\n$$|W_{t}| - |W_{0}| = \\int_{0}^{t} \\text{sgn}(W_{s}) dW_{s} + L_{t}^{0}(W)$$\nwhere we use the standard definition of local time that appears in this identity. Since $W_{0}=0$, this simplifies to:\n$$|W_{t}| = \\int_{0}^{t} \\text{sgn}(W_{s}) dW_{s} + L_{t}^{0}(W)$$\nWe take the expectation of both sides of this equation:\n$$E[|W_{t}|] = E\\left[\\int_{0}^{t} \\text{sgn}(W_{s}) dW_{s}\\right] + E[L_{t}^{0}(W)]$$\nLet us analyze the stochastic integral term, $I_{t} = \\int_{0}^{t} \\text{sgn}(W_{s}) dW_{s}$. The integrand is $H_{s} = \\text{sgn}(W_{s})$. This process is adapted to the filtration generated by $W$. To determine if $I_{t}$ is a martingale, we check the Itô isometry condition:\n$$E\\left[\\int_{0}^{t} H_{s}^{2} ds\\right] = E\\left[\\int_{0}^{t} (\\text{sgn}(W_{s}))^{2} ds\\right]$$\nThe set of times $\\{s \\in [0,t] : W_{s} = 0\\}$ has Lebesgue measure zero almost surely. Thus, $(\\text{sgn}(W_{s}))^{2} = 1$ for almost every $s \\in [0,t]$.\n$$E\\left[\\int_{0}^{t} 1 \\, ds\\right] = E[t] = t$$\nSince $t  \\infty$, the stochastic integral $I_{t}$ is a true martingale. The martingale starts at $I_{0} = 0$. A fundamental property of martingales is that their expectation is constant over time. Therefore, for all $t \\geq 0$:\n$$E[I_{t}] = E[I_{0}] = 0$$\nHence, $E\\left[\\int_{0}^{t} \\text{sgn}(W_{s}) dW_{s}\\right] = 0$.\nSubstituting this back into the expectation of Tanaka's formula yields:\n$$E[|W_{t}|] = 0 + E[L_{t}^{0}(W)]$$\nThis gives the desired identity: $E[L_{t}^{0}(W)] = E[|W_{t}|]$.\n\nFinal Task: Provide the closed-form expression.\nBy combining the results from Step 2 and Step 3, we obtain the final answer.\nFrom Step 3, $E[L_{t}^{0}(W)] = E[|W_{t}|]$.\nFrom Step 2, $E[|W_{t}|] = \\sqrt{\\frac{2t}{\\pi}}$.\nTherefore, the expected local time of a standard Brownian motion at level $0$ up to time $t$ is:\n$$E[L_{t}^{0}(W)] = \\sqrt{\\frac{2t}{\\pi}}$$", "answer": "$$\\boxed{\\sqrt{\\frac{2t}{\\pi}}}$$", "id": "3064283"}, {"introduction": "Building on our analysis of Brownian motion, we now generalize to a broad class of Itô diffusions and derive a powerful unifying principle. This exercise challenges you to derive the celebrated occupation times formula, which provides a profound link between a process's quadratic variation and its local time across all levels [@problem_id:3064278]. By working from Itô's and Tanaka's formulas, you will understand how local time acts as a density, measuring the time a process \"occupies\" each point in space.", "problem": "Let $\\{X_t\\}_{t \\geq 0}$ be a real-valued continuous semimartingale that is the unique strong solution to the stochastic differential equation $dX_t = b(X_t)\\,dt + \\sigma(X_t)\\,dW_t$ with $X_0 \\in \\mathbb{R}$, where $W_t$ is a standard one-dimensional Brownian motion, and $b,\\sigma:\\mathbb{R}\\to\\mathbb{R}$ are globally Lipschitz with at most linear growth. For each level $a \\in \\mathbb{R}$, let $L_t^a(X)$ denote the local time of $X$ at level $a$ up to time $t$, defined via the Tanaka formula for continuous semimartingales.\n\nStarting from the fundamental definitions and facts below, derive an integral representation for the quantity $\\int_{0}^{t} g(X_s)\\,\\sigma(X_s)^{2}\\,ds$ in terms of the local time $L_t^a(X)$, where $g:\\mathbb{R}\\to\\mathbb{R}$ is a bounded, continuous function. Your derivation must proceed from first principles of continuous semimartingales, including: the semimartingale decomposition into a local martingale and a finite-variation process, the quadratic variation of the local martingale part, and the definition of local time through Tanaka’s formula. Do not invoke any shortcut formulas without justification; instead, logically build the argument that identifies the correct integral representation.\n\nConclude by specializing your result to the specific test function $g(a)=a^{2}\\exp(-a^{2})$, and provide the requested expression for $\\int_{0}^{t} g(X_s)\\,\\sigma(X_s)^{2}\\,ds$ as your final answer. Your final answer must be a single closed-form analytic expression (no equality signs) involving $L_t^a(X)$ and standard operations. No numerical rounding is required.", "solution": "The problem is valid as it is scientifically grounded in the theory of stochastic differential equations, well-posed with sufficient conditions for existence and uniqueness of the solution, and stated objectively using precise mathematical language. We may proceed to derive the solution.\n\nThe objective is to find an integral representation for the quantity $\\int_{0}^{t} g(X_s)\\,\\sigma(X_s)^{2}\\,ds$ in terms of the local time $L_t^a(X)$ for a given function $g$. This relationship is a form of the celebrated occupation times formula. We will derive this formula from foundational principles as requested.\n\nLet $\\{X_t\\}_{t \\geq 0}$ be a real-valued continuous semimartingale satisfying the stochastic differential equation (SDE):\n$$dX_t = b(X_t)\\,dt + \\sigma(X_t)\\,dW_t$$\nwhere $b$ and $\\sigma$ are Lipschitz continuous functions. The process $X_t$ can be decomposed into a finite-variation part $A_t = \\int_0^t b(X_s)\\,ds$ and a local martingale part $M_t = \\int_0^t \\sigma(X_s)\\,dW_s$. The quadratic variation of the continuous semimartingale $X_t$ is given by the quadratic variation of its local martingale part:\n$$d\\langle X \\rangle_t = d\\langle M \\rangle_t = \\left(\\sigma(X_t)\\right)^2 dt$$\n\nThe starting point for introducing local time is the Itô-Tanaka formula. For a function $F:\\mathbb{R} \\to \\mathbb{R}$ that is a difference of two convex functions, its second derivative $F''$ exists in the sense of distributions as a signed measure. The Itô-Tanaka formula states:\n$$F(X_t) - F(X_0) = \\int_0^t F'_{-}(X_s)\\,dX_s + \\frac{1}{2} \\int_{-\\infty}^{\\infty} L_t^a(X) F''(da)$$\nwhere $F'_{-}$ denotes the left-derivative of $F$, and $L_t^a(X)$ is the local time of $X$ at level $a$ up to time $t$. The expression $F''(da)$ denotes integration with respect to the measure defined by the second derivative of $F$.\n\nNow, let us consider the special case where the function $F$ is twice continuously differentiable, i.e., $F \\in C^2(\\mathbb{R})$. In this case, the standard Itô's formula applies:\n$$dF(X_t) = F'(X_t)\\,dX_t + \\frac{1}{2} F''(X_t)\\,d\\langle X \\rangle_t$$\nSubstituting $d\\langle X \\rangle_t = \\sigma(X_t)^2\\,dt$, the integral form becomes:\n$$F(X_t) - F(X_0) = \\int_0^t F'(X_s)\\,dX_s + \\frac{1}{2} \\int_0^t F''(X_s)\\,\\sigma(X_s)^2\\,ds$$\nFor a $C^2$ function, the left-derivative $F'_-$ is simply the standard derivative $F'$, and the measure $F''(da)$ is absolutely continuous with respect to the Lebesgue measure, with density $F''(a)$, so $F''(da) = F''(a)\\,da$. Thus, for a $C^2$ function, the Itô-Tanaka formula can be written as:\n$$F(X_t) - F(X_0) = \\int_0^t F'(X_s)\\,dX_s + \\frac{1}{2} \\int_{-\\infty}^{\\infty} F''(a)\\,L_t^a(X)\\,da$$\nSince both formulas must yield the same result for any $F \\in C^2(\\mathbb{R})$, we can equate the two expressions for $F(X_t) - F(X_0)$:\n$$\\int_0^t F'(X_s)\\,dX_s + \\frac{1}{2} \\int_0^t F''(X_s)\\,\\sigma(X_s)^2\\,ds = \\int_0^t F'(X_s)\\,dX_s + \\frac{1}{2} \\int_{-\\infty}^{\\infty} F''(a)\\,L_t^a(X)\\,da$$\nThe stochastic integral terms $\\int_0^t F'(X_s)\\,dX_s$ are identical and finite under the problem's assumptions. Thus, we can cancel them, leading to the equality:\n$$\\frac{1}{2} \\int_0^t F''(X_s)\\,\\sigma(X_s)^2\\,ds = \\frac{1}{2} \\int_{-\\infty}^{\\infty} F''(a)\\,L_t^a(X)\\,da$$\nMultiplying by $2$, we obtain:\n$$\\int_0^t F''(X_s)\\,\\sigma(X_s)^2\\,ds = \\int_{-\\infty}^{\\infty} F''(a)\\,L_t^a(X)\\,da$$\nThis identity holds for any function of the form $g(x) = F''(x)$ where $F \\in C^2(\\mathbb{R})$. The set of such functions is sufficiently rich (e.g., all continuous functions with compact support) that by a standard measure-theoretic or functional-analytic approximation argument (e.g., using the Stone-Weierstrass theorem or mollifiers), this identity can be extended to hold for any bounded, continuous function $g: \\mathbb{R} \\to \\mathbb{R}$.\n\nThus, we have derived the general integral representation, also known as the occupation times formula:\n$$\\int_{0}^{t} g(X_s)\\,\\sigma(X_s)^{2}\\,ds = \\int_{-\\infty}^{\\infty} g(a)\\,L_t^a(X)\\,da$$\n\nThe problem asks to specialize this result to the test function $g(a) = a^{2}\\exp(-a^{2})$. This function is bounded and continuous on $\\mathbb{R}$. Substituting this specific function $g$ into our derived formula, we obtain the integral representation for $\\int_{0}^{t} g(X_s)\\,\\sigma(X_s)^{2}\\,ds$:\n$$\\int_{0}^{t} X_s^{2}\\exp(-X_s^{2})\\,\\sigma(X_s)^{2}\\,ds = \\int_{-\\infty}^{\\infty} a^{2}\\exp(-a^{2})\\,L_t^a(X)\\,da$$\nThe expression on the right-hand side is the requested integral representation.", "answer": "$$\\boxed{\\int_{-\\infty}^{\\infty} a^{2} \\exp(-a^{2}) L_t^a(X) \\, da}$$", "id": "3064278"}]}