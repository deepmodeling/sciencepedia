{"hands_on_practices": [{"introduction": "This exercise provides a foundational insight into the structure of the Burkholder-Davis-Gundy inequalities. By leveraging the self-similarity or scaling property of Brownian motion, you can directly derive the characteristic $T^{p/2}$ dependence in the bounds for $\\mathbb{E}[\\sup_{t \\le T}|W_t|^p]$. This practice is valuable because it builds intuition from first principles, showing why the BDG inequalities take the form they do in the most fundamental case, before tackling more complex martingales ([@problem_id:3042951]).", "problem": "Let $\\{W_{t}\\}_{t \\ge 0}$ be a standard Brownian motion, also called a Wiener process, defined by the properties that $W_{0} = 0$, it has continuous sample paths, stationary independent increments, and for each $t \\ge 0$ the random variable $W_{t}$ is centered Gaussian with variance $t$. Fix $p \\in (0,\\infty)$ and $T  0$. Consider the scaled process defined by $B_{s} := T^{-1/2} W_{Ts}$ for $s \\in [0,1]$.\n\nStarting only from the defining properties of Brownian motion above, and the characterization of Gaussian increments, proceed as follows:\n- First, establish that $\\{B_{s}\\}_{s \\in [0,1]}$ is itself a standard Brownian motion on the interval $[0,1]$.\n- Next, use this scaling to relate the random variable $\\sup_{t \\le T} |W_{t}|$ to $\\sup_{s \\le 1} |B_{s}|$.\n- Then, deduce an explicit analytic expression for $\\mathbb{E}\\!\\left[\\sup_{t \\le T} |W_{t}|^{p}\\right]$ in terms of $T$ and $\\mathbb{E}\\!\\left[\\sup_{s \\le 1} |W_{s}|^{p}\\right]$.\n\nFinally, explain why this scaling verifies the $T^{p/2}$ dependence predicted by the Burkholder-Davis-Gundy (BDG) inequalities for continuous martingales when specialized to Brownian motion, without using any explicit constants from those inequalities.\n\nYour final answer must be a single closed-form analytic expression for $\\mathbb{E}\\!\\left[\\sup_{t \\le T} |W_{t}|^{p}\\right]$ written in terms of $T$ and $\\mathbb{E}\\!\\left[\\sup_{s \\le 1} |W_{s}|^{p}\\right]$. No rounding is required. Do not include any inequalities or bound statements in the final answer.", "solution": "The problem statement is evaluated as valid. It is self-contained, mathematically sound, and well-posed within the established framework of stochastic calculus. The definitions and objectives are clear and logically consistent.\n\nWe are given a standard Brownian motion $\\{W_{t}\\}_{t \\ge 0}$ with defining properties:\n1. $W_{0} = 0$.\n2. Continuous sample paths.\n3. Stationary independent increments.\n4. For any $t  u \\ge 0$, the increment $W_t - W_u$ is a centered Gaussian random variable with variance $t-u$. From this, $W_t \\sim \\mathcal{N}(0, t)$.\n\nWe are asked to analyze the scaled process $B_{s} := T^{-1/2} W_{Ts}$ for $s \\in [0,1]$, where $T  0$ is a fixed constant.\n\nFirst, we establish that $\\{B_{s}\\}_{s \\in [0,1]}$ is a standard Brownian motion on the interval $[0,1]$. We verify the defining properties:\n1.  **Initial Value**: At $s=0$, we have $B_{0} = T^{-1/2} W_{T \\cdot 0} = T^{-1/2} W_{0}$. Since $W_{0} = 0$, it follows that $B_{0} = 0$.\n2.  **Continuity of Paths**: The function $s \\mapsto Ts$ is continuous for $s \\in [0,1]$. Since $\\{W_t\\}$ has continuous sample paths, the composition $s \\mapsto W_{Ts}$ is a continuous function of $s$. Multiplication by the constant $T^{-1/2}$ preserves continuity. Therefore, $\\{B_s\\}$ has continuous sample paths.\n3.  **Stationary and Independent Increments**: Let's consider increments of $B_s$. For any $0 \\le u  s \\le 1$, the increment is:\n    $$B_{s} - B_{u} = T^{-1/2} W_{Ts} - T^{-1/2} W_{Tu} = T^{-1/2} (W_{Ts} - W_{Tu})$$\n    a. **Independence**: Let $0 \\le u_1  s_1 \\le u_2  s_2 \\le 1$. The corresponding time intervals for the process $W$ are $[Tu_1, Ts_1]$ and $[Tu_2, Ts_2]$. Since $T  0$, these intervals $[Tu_1, Ts_1]$ and $[Tu_2, Ts_2]$ are non-overlapping. The increments of $W$, namely $W_{Ts_1} - W_{Tu_1}$ and $W_{Ts_2} - W_{Tu_2}$, are independent by the definition of Brownian motion. The increments of $B$, being constant multiples of these, are therefore also independent.\n    b. **Stationarity and Distribution**: The increment $W_{Ts} - W_{Tu}$ depends on the time interval of length $Ts - Tu = T(s-u)$. By the stationary increments property of $W$, the distribution of $W_{Ts} - W_{Tu}$ is the same as the distribution of $W_{T(s-u)} - W_0 = W_{T(s-u)}$. We know that $W_{t'}$ is a centered Gaussian with variance $t'$. Thus, $W_{T(s-u)}$ is a centered Gaussian with variance $T(s-u)$.\n    The increment $B_s - B_u$ is a scaling of this Gaussian variable:\n    $$B_s - B_u \\sim T^{-1/2} \\mathcal{N}(0, T(s-u))$$\n    A linear transformation of a Gaussian random variable is also Gaussian. The mean remains $T^{-1/2} \\cdot 0 = 0$. The variance is:\n    $$\\mathbb{E}[(B_s - B_u)^2] = \\mathbb{E}[(T^{-1/2}(W_{Ts} - W_{Tu}))^2] = T^{-1} \\mathbb{E}[(W_{Ts} - W_{Tu})^2] = T^{-1} \\text{Var}(W_{T(s-u)}) = T^{-1} (T(s-u)) = s-u$$\n    So, the increment $B_s - B_u$ is a centered Gaussian random variable with variance $s-u$. This distribution depends only on the length of the interval, $s-u$.\n\nAll defining properties are satisfied, so $\\{B_{s}\\}_{s \\in [0,1]}$ is a standard Brownian motion on $[0,1]$.\n\nNext, we relate the random variables $\\sup_{t \\le T} |W_{t}|$ and $\\sup_{s \\le 1} |B_{s}|$. From the definition $B_{s} = T^{-1/2} W_{Ts}$, we can write $W_{Ts} = T^{1/2} B_s$. Let $t=Ts$. As $s$ varies over the interval $[0,1]$, $t$ varies over the interval $[0,T]$. We can therefore write:\n$$\\sup_{t \\in [0,T]} |W_{t}| = \\sup_{s \\in [0,1]} |W_{Ts}|$$\nSubstituting the relationship $W_{Ts} = T^{1/2} B_s$:\n$$\\sup_{t \\in [0,T]} |W_{t}| = \\sup_{s \\in [0,1]} |T^{1/2} B_s|$$\nSince $T^{1/2}$ is a positive constant, it can be factored out of the supremum:\n$$\\sup_{t \\in [0,T]} |W_{t}| = T^{1/2} \\sup_{s \\in [0,1]} |B_{s}|$$\nThis equation establishes the relationship between the two random variables.\n\nNow, we deduce the expression for $\\mathbb{E}[\\sup_{t \\le T} |W_{t}|^{p}]$. We take the $p$-th power of the equality above and then compute the expectation:\n$$\\mathbb{E}\\left[\\left(\\sup_{t \\le T} |W_{t}|\\right)^p\\right] = \\mathbb{E}\\left[\\left(T^{1/2} \\sup_{s \\le 1} |B_{s}|\\right)^p\\right]$$\nUsing the linearity of expectation to factor out the constant $(T^{1/2})^p = T^{p/2}$:\n$$\\mathbb{E}\\left[\\sup_{t \\le T} |W_{t}|^{p}\\right] = T^{p/2} \\mathbb{E}\\left[\\left(\\sup_{s \\le 1} |B_{s}|\\right)^p\\right]$$\nWe have established that $\\{B_{s}\\}_{s \\in [0,1]}$ is a standard Brownian motion. This means that the law of the process $\\{B_s\\}_{s \\in [0,1]}$ is identical to the law of the process $\\{W_s\\}_{s \\in [0,1]}$. Consequently, the distribution of any functional of the process path is the same for both. In particular, the random variable $\\sup_{s \\le 1} |B_{s}|$ has the same distribution as the random variable $\\sup_{s \\le 1} |W_{s}|$. Therefore, their moments must be equal:\n$$\\mathbb{E}\\left[\\left(\\sup_{s \\le 1} |B_{s}|\\right)^p\\right] = \\mathbb{E}\\left[\\left(\\sup_{s \\le 1} |W_{s}|\\right)^p\\right]$$\nSubstituting this back into our expression, we arrive at the final result:\n$$\\mathbb{E}\\left[\\sup_{t \\le T} |W_{t}|^{p}\\right] = T^{p/2} \\mathbb{E}\\left[\\sup_{s \\le 1} |W_{s}|^{p}\\right]$$\n\nFinally, we explain the connection to the Burkholder-Davis-Gundy (BDG) inequalities. For a continuous local martingale $M_t$ with $M_0=0$, the BDG inequalities state that for $p \\in (0, \\infty)$, there exist constants $c_p$ and $C_p$ such that for any stopping time $\\tau$:\n$$c_p \\mathbb{E}[\\langle M \\rangle_{\\tau}^{p/2}] \\le \\mathbb{E}\\left[\\left(\\sup_{t \\le \\tau} |M_t|\\right)^p\\right] \\le C_p \\mathbb{E}[\\langle M \\rangle_{\\tau}^{p/2}]$$\nStandard Brownian motion $W_t$ is a continuous martingale. Its quadratic variation is given by $\\langle W \\rangle_t = t$. For the fixed time $\\tau = T$, the quadratic variation $\\langle W \\rangle_T = T$ is a deterministic quantity. The BDG inequalities for Brownian motion thus become:\n$$c_p \\mathbb{E}[T^{p/2}] \\le \\mathbb{E}\\left[\\left(\\sup_{t \\le T} |W_t|\\right)^p\\right] \\le C_p \\mathbb{E}[T^{p/2}]$$\nSince $T$ is a constant, $\\mathbb{E}[T^{p/2}] = T^{p/2}$. Therefore, the BDG inequalities predict:\n$$c_p T^{p/2} \\le \\mathbb{E}\\left[\\sup_{t \\le T} |W_{t}|^{p}\\right] \\le C_p T^{p/2}$$\nThis implies that $\\mathbb{E}[\\sup_{t \\le T} |W_{t}|^{p}]$ must be proportional to $T^{p/2}$. Our derived equality, $\\mathbb{E}[\\sup_{t \\le T} |W_{t}|^{p}] = (\\mathbb{E}[\\sup_{s \\le 1} |W_{s}|^{p}]) T^{p/2}$, confirms this prediction exactly. The constant of proportionality is identified as $\\mathbb{E}[\\sup_{s \\le 1} |W_{s}|^{p}]$, a finite constant that depends only on $p$. The fundamental scaling property of Brownian motion provides a direct, constructive proof of the $T^{p/2}$ dependence for this specific and important martingale, without resource to the more general and complex proof of the full BDG inequalities.", "answer": "$$\\boxed{T^{p/2} \\mathbb{E}\\!\\left[\\sup_{s \\le 1} |W_{s}|^{p}\\right]}$$", "id": "3042951"}, {"introduction": "With a foundational understanding of the BDG bounds, we now move to a direct application. This practice demonstrates how to use the BDG inequality as a concrete computational tool to control the moments of a stochastic integral with a random integrand. Establishing such bounds is a crucial skill in stochastic analysis, particularly for proving the existence, uniqueness, and stability of solutions to stochastic differential equations ([@problem_id:1311312]).", "problem": "Consider a standard one-dimensional Brownian motion $W_s$ starting at $W_0=0$, defined on a probability space $(\\Omega, \\mathcal{F}, P)$. A stochastic process $M_t$ is constructed as an Itô integral with respect to this Brownian motion:\n$$ M_t = \\int_0^t \\cos(W_s) dW_s $$\nIt is a known result that $M_t$ is a continuous local martingale. The Burkholder-Davis-Gundy (BDG) inequality provides a relationship between the moments of a martingale and the moments of its quadratic variation. A version of this inequality states that for any $p1$, there exists a constant $C_p$ such that for any continuous local martingale $M_t$ with $M_0=0$:\n$$ \\mathbb{E}\\left[|M_T|^p\\right] \\le C_p \\mathbb{E}\\left[ \\langle M \\rangle_T^{p/2} \\right] $$\nwhere $\\langle M \\rangle_T$ is the quadratic variation of the process $M_t$ at time $T$.\n\nFor the specific case of $p=4$, you may use the numerical constant $C_4 = 36$.\n\nYour task is to establish a non-trivial upper bound for the fourth moment of the martingale at a fixed time $T  0$, i.e., for $\\mathbb{E}\\left[|M_T|^4\\right]$. Express your answer as an expression in terms of $T$.", "solution": "We start from the given Itô integral\n$$\nM_{t}=\\int_{0}^{t}\\cos(W_{s})\\,dW_{s},\n$$\nwhich is a continuous local martingale. Its quadratic variation is given by:\n$$\n\\langle M\\rangle_{T}=\\int_{0}^{T}\\cos^{2}(W_{s})\\,ds.\n$$\nApply the Burkholder-Davis-Gundy inequality with $p=4$, using the provided constant $C_{4}=36$:\n$$\n\\mathbb{E}\\left[|M_{T}|^{4}\\right]\\leq 36\\,\\mathbb{E}\\left[\\langle M\\rangle_{T}^{2}\\right].\n$$\nTo bound $\\mathbb{E}\\left[\\langle M\\rangle_{T}^{2}\\right]$, use the pointwise bound $\\cos^{2}(x)\\leq 1$ for all $x\\in\\mathbb{R}$, which yields\n$$\n\\langle M\\rangle_{T}=\\int_{0}^{T}\\cos^{2}(W_{s})\\,ds\\leq\\int_{0}^{T}1\\,ds=T.\n$$\nTherefore,\n$$\n\\langle M\\rangle_{T}^{2}\\leq T^{2}\\quad\\text{and hence}\\quad \\mathbb{E}\\left[\\langle M\\rangle_{T}^{2}\\right]\\leq T^{2}.\n$$\nCombining this with the BDG inequality gives\n$$\n\\mathbb{E}\\left[|M_{T}|^{4}\\right]\\leq 36\\,T^{2}.\n$$\nThis provides the requested upper bound in terms of $T$.", "answer": "$$\\boxed{36\\,T^{2}}$$", "id": "1311312"}, {"introduction": "The power of the Burkholder-Davis-Gundy inequalities extends beyond the continuous world of Brownian motion. This final practice showcases the versatility of the BDG framework by applying it to a compensated Poisson process, a canonical example of a pure-jump martingale. Mastering this application demonstrates a deeper understanding of the inequalities and their role in providing a unified approach to controlling a wide class of stochastic processes ([@problem_id:3042938]).", "problem": "Let $\\{N_{t}\\}_{t\\geq 0}$ be a Poisson process with rate $\\lambda0$, and define its compensated process by $M_{t}=N_{t}-\\lambda t$. Fix $p\\geq 1$ and a horizon $T0$. Starting from the core definitions of quadratic variation for pure-jump martingales and the compensator structure of counting processes, derive the predictable quadratic variation $\\langle M\\rangle_{T}$ of $M$ and its expectation. Then, using the Burkholder-Davis-Gundy inequalities, express the optimal-form upper bound for $\\mathbb{E}\\!\\left[\\sup_{0\\leq t\\leq T}|M_{t}|^{p}\\right]$ in terms of $\\mathbb{E}\\!\\left[\\langle M\\rangle_{T}^{p/2}\\right]$, and finally write that bound explicitly as a closed-form symbolic expression in $\\lambda$, $T$, and $p$, with the universal BDG constant written as $C_{p}$ (depending only on $p$). Provide your final answer as the single expression for the BDG upper bound, using only $\\lambda$, $T$, $p$, and $C_{p}$.", "solution": "The problem requires the derivation of a closed-form expression for the Burkholder-Davis-Gundy (BDG) upper bound on the $p$-th moment of the supremum of a compensated Poisson process. We shall proceed by first determining the predictable quadratic variation of the process and then applying the BDG inequality.\n\nLet $\\{N_{t}\\}_{t\\geq 0}$ be a Poisson process with a constant rate $\\lambda  0$. By definition, $N_t$ counts the number of arrivals in the interval $[0, t]$. The process has stationary and independent increments. The expectation of $N_t$ is $\\mathbb{E}[N_t] = \\lambda t$.\n\nThe compensated Poisson process is defined as $M_t = N_t - \\lambda t$. This process is a martingale with respect to the natural filtration generated by $N_t$. We are given $p \\geq 1$ and a fixed time horizon $T  0$. Our goal is to find an upper bound for $\\mathbb{E}\\!\\left[\\sup_{0\\leq t\\leq T}|M_{t}|^{p}\\right]$.\n\nFirst, we must compute the predictable quadratic variation of $M_t$, denoted as $\\langle M \\rangle_t$. The process $M_t$ is a pure-jump process. Its jumps occur at the same times as the jumps of the Poisson process $N_t$. Let the jump times be $\\tau_1, \\tau_2, \\ldots$. For any time $s  0$, the jump size is $\\Delta M_s = M_s - M_{s-} = (N_s - N_{s-}) - \\lambda(s-s-) = \\Delta N_s$. Since $N_t$ is a standard Poisson process, its jumps are all of size $1$, so $\\Delta N_s = 1$ if a jump occurs at time $s$, and $\\Delta N_s = 0$ otherwise.\n\nThe quadratic variation of $M_t$, denoted $[M]_t$, is defined as the sum of the squares of its jumps up to time $t$:\n$$\n[M]_t = \\sum_{0  s \\leq t} (\\Delta M_s)^2\n$$\nSubstituting $\\Delta M_s = \\Delta N_s$, we get:\n$$\n[M]_t = \\sum_{0  s \\leq t} (\\Delta N_s)^2\n$$\nSince each jump has size $1$, $(\\Delta N_s)^2 = 1$ if there is a jump at time $s$ and $0$ otherwise. The sum therefore counts the number of jumps up to time $t$, which is precisely $N_t$.\n$$\n[M]_t = N_t\n$$\nThe predictable quadratic variation, $\\langle M \\rangle_t$, is the compensator of the quadratic variation $[M]_t$. By the Doob-Meyer decomposition theorem, any submartingale can be uniquely decomposed into the sum of a martingale and a predictable process (its compensator). Here, the process $[M]_t = N_t$ is a submartingale. We need to find its compensator.\n\nBy the very definition of the compensated Poisson process, we know that $M_t = N_t - \\lambda t$ is a martingale. This equation can be rewritten as $N_t = M_t + \\lambda t$. This is the Doob-Meyer decomposition of the submartingale $N_t$, where $M_t$ is the martingale part and $\\lambda t$ is the predictable part. Therefore, the compensator of $N_t$ is $\\lambda t$.\n\nSince $[M]_t = N_t$, the compensator of $[M]_t$ is also $\\lambda t$. This means the predictable quadratic variation of $M_t$ is:\n$$\n\\langle M \\rangle_t = \\lambda t\n$$\nAt the time horizon $T$, we have $\\langle M \\rangle_T = \\lambda T$.\n\nThe problem also asks for the expectation of this quantity. Since $\\lambda$ and $T$ are given positive constants, $\\langle M \\rangle_T$ is a deterministic value. Thus, its expectation is the value itself:\n$$\n\\mathbb{E}[\\langle M \\rangle_T] = \\mathbb{E}[\\lambda T] = \\lambda T\n$$\nNext, we apply the Burkholder-Davis-Gundy (BDG) inequalities. For a local martingale $M$ with $M_0 = 0$ and for any $p \\geq 1$, there exists a universal constant $C_p$ (which depends only on $p$) such that:\n$$\n\\mathbb{E}\\left[\\sup_{0 \\leq t \\leq T} |M_t|^p\\right] \\leq C_p \\mathbb{E}\\left[\\langle M \\rangle_T^{p/2}\\right]\n$$\nThis is the \"optimal-form\" upper bound inequality referenced in the problem statement. The process $M_t=N_t - \\lambda t$ satisfies $M_0 = N_0 - \\lambda \\cdot 0 = 0 - 0 = 0$, so the inequality is applicable.\n\nWe now substitute our derived expression for $\\langle M \\rangle_T$ into the right-hand side of the BDG inequality:\n$$\n\\mathbb{E}\\left[\\sup_{0 \\leq t \\leq T} |M_t|^p\\right] \\leq C_p \\mathbb{E}\\left[(\\lambda T)^{p/2}\\right]\n$$\nThe term $(\\lambda T)^{p/2}$ is a deterministic constant because $\\lambda$, $T$, and $p$ are constant parameters. The expectation of a constant is the constant itself.\n$$\n\\mathbb{E}\\left[(\\lambda T)^{p/2}\\right] = (\\lambda T)^{p/2}\n$$\nTherefore, the BDG upper bound for $\\mathbb{E}\\!\\left[\\sup_{0\\leq t\\leq T}|M_{t}|^{p}\\right]$ is given by:\n$$\nC_p (\\lambda T)^{p/2}\n$$\nThis is the final closed-form symbolic expression for the upper bound, expressed in terms of the given parameters $\\lambda$, $T$, $p$, and the constant $C_p$.", "answer": "$$\n\\boxed{C_{p}(\\lambda T)^{p/2}}\n$$", "id": "3042938"}]}