{"hands_on_practices": [{"introduction": "A cornerstone of quantitative finance is the ability to simulate asset price paths using computers. This practice guides you through the derivation of the exact simulation formula for Geometric Brownian Motion. By applying Itô's lemma to the logarithm of the asset price, $\\ln(S_t)$, we can find a closed-form solution over a discrete time step, allowing us to generate price paths that are free from the numerical approximation errors often introduced by simpler schemes.", "problem": "An asset price process $\\{S_t\\}_{t \\ge 0}$ is modeled as a geometric Brownian motion (GBM), governed by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}S_t = \\mu S_t \\,\\mathrm{d}t + \\sigma S_t \\,\\mathrm{d}W_t,\n$$\nwhere $\\mu \\in \\mathbb{R}$ and $\\sigma  0$ are constants and $\\{W_t\\}_{t \\ge 0}$ is a standard Brownian motion. Consider an equidistant time grid $\\{t_k\\}_{k=0}^{n}$ with $t_k = k\\,\\Delta t$ for $k \\in \\{0,1,\\dots,n\\}$ and fixed $\\Delta t  0$.\n\nStarting only from fundamental definitions and well-tested facts, namely Itô's formula, the chain rule for logarithms, and the independent, stationary, Gaussian increment property of Brownian motion, derive an exact one-step simulation formula that expresses $S_{t_{k+1}}$ solely in terms of $S_{t_k}$, the parameters $\\mu$, $\\sigma$, the step size $\\Delta t$, and a standard normal random variable $Z_k \\sim \\mathcal{N}(0,1)$.\n\nYour final answer must be a single explicit expression for $S_{t_{k+1}}$ as a function of $S_{t_k}$, $\\mu$, $\\sigma$, $\\Delta t$, and $Z_k$. Do not make any approximations. No rounding is required.", "solution": "The problem requires the derivation of an exact one-step simulation formula for a geometric Brownian motion (GBM) process $\\{S_t\\}_{t \\ge 0}$. The process is governed by the stochastic differential equation (SDE):\n$$\n\\mathrm{d}S_t = \\mu S_t \\,\\mathrm{d}t + \\sigma S_t \\,\\mathrm{d}W_t\n$$\nwhere $\\mu$ is the drift, $\\sigma$ is the volatility, and $\\{W_t\\}_{t \\ge 0}$ is a standard Brownian motion. The objective is to express $S_{t_{k+1}}$ in terms of $S_{t_k}$ over a time step $\\Delta t = t_{k+1} - t_k$.\n\nTo solve this SDE, we introduce a transformation of the process $S_t$. The multiplicative nature of the noise term suggests a logarithmic transformation. Let us define a new process $X_t = f(S_t) = \\ln(S_t)$. We can find the dynamics of $X_t$ by applying Itô's formula.\n\nFor a process $X_t = f(t, Y_t)$ where the dynamics of $Y_t$ are given by $\\mathrm{d}Y_t = a(t, Y_t)\\mathrm{d}t + b(t, Y_t)\\mathrm{d}W_t$, Itô's formula states:\n$$\n\\mathrm{d}X_t = \\left( \\frac{\\partial f}{\\partial t} + a \\frac{\\partial f}{\\partial Y_t} + \\frac{1}{2} b^2 \\frac{\\partial^2 f}{\\partial Y_t^2} \\right) \\mathrm{d}t + b \\frac{\\partial f}{\\partial Y_t} \\mathrm{d}W_t\n$$\nIn our case, $Y_t = S_t$ and the function is $f(S_t) = \\ln(S_t)$, which does not explicitly depend on $t$. The coefficients of the SDE for $S_t$ are $a(t, S_t) = \\mu S_t$ and $b(t, S_t) = \\sigma S_t$.\n\nWe first compute the required partial derivatives of $f(S_t) = \\ln(S_t)$ with respect to $S_t$:\n- The first partial derivative: $\\frac{\\partial f}{\\partial S_t} = \\frac{1}{S_t}$\n- The second partial derivative: $\\frac{\\partial^2 f}{\\partial S_t^2} = -\\frac{1}{S_t^2}$\n- The partial derivative with respect to time is $\\frac{\\partial f}{\\partial t} = 0$.\n\nNow, we substitute these derivatives and the coefficients $a$ and $b$ into Itô's formula to find the SDE for $X_t = \\ln(S_t)$:\n$$\n\\mathrm{d}(\\ln S_t) = \\left( 0 + (\\mu S_t) \\left( \\frac{1}{S_t} \\right) + \\frac{1}{2} (\\sigma S_t)^2 \\left( -\\frac{1}{S_t^2} \\right) \\right) \\mathrm{d}t + (\\sigma S_t) \\left( \\frac{1}{S_t} \\right) \\mathrm{d}W_t\n$$\nSimplifying the terms within the parentheses gives:\n$$\n\\mathrm{d}(\\ln S_t) = \\left( \\mu - \\frac{1}{2} \\sigma^2 S_t^2 \\frac{1}{S_t^2} \\right) \\mathrm{d}t + \\sigma \\mathrm{d}W_t\n$$\nThis simplifies to a linear SDE with constant coefficients, representing an arithmetic Brownian motion with drift $(\\mu - \\frac{1}{2}\\sigma^2)$ and volatility $\\sigma$:\n$$\n\\mathrm{d}(\\ln S_t) = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\mathrm{d}t + \\sigma \\mathrm{d}W_t\n$$\nTo find the one-step simulation formula, we integrate this SDE over the time interval $[t_k, t_{k+1}]$:\n$$\n\\int_{t_k}^{t_{k+1}} \\mathrm{d}(\\ln S_t) = \\int_{t_k}^{t_{k+1}} \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\mathrm{d}t + \\int_{t_k}^{t_{k+1}} \\sigma \\mathrm{d}W_t\n$$\nEvaluating the integrals yields:\n$$\n\\ln(S_{t_{k+1}}) - \\ln(S_{t_k}) = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) (t_{k+1} - t_k) + \\sigma (W_{t_{k+1}} - W_{t_k})\n$$\nLet $\\Delta t = t_{k+1} - t_k$. The equation becomes:\n$$\n\\ln(S_{t_{k+1}}) - \\ln(S_{t_k}) = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma (W_{t_{k+1}} - W_{t_k})\n$$\nThe problem statement requires using the property that increments of a standard Brownian motion are independent and normally distributed. For any $t  s$, the increment $W_t - W_s$ follows a normal distribution with mean $0$ and variance $t-s$. Thus, for our time interval $\\Delta t$:\n$$\nW_{t_{k+1}} - W_{t_k} \\sim \\mathcal{N}(0, \\Delta t)\n$$\nA random variable drawn from $\\mathcal{N}(0, \\Delta t)$ can be expressed as the product of $\\sqrt{\\Delta t}$ and a standard normal random variable $Z \\sim \\mathcal{N}(0, 1)$. For each independent time step $k$, we can write:\n$$\nW_{t_{k+1}} - W_{t_k} = \\sqrt{\\Delta t} \\, Z_k\n$$\nwhere $\\{Z_k\\}$ is a sequence of independent and identically distributed standard normal random variables.\n\nSubstituting this into our integrated equation gives:\n$$\n\\ln(S_{t_{k+1}}) - \\ln(S_{t_k}) = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_k\n$$\nTo find the explicit formula for $S_{t_{k+1}}$, we first isolate $\\ln(S_{t_{k+1}})$:\n$$\n\\ln(S_{t_{k+1}}) = \\ln(S_{t_k}) + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_k\n$$\nFinally, we exponentiate both sides to solve for $S_{t_{k+1}}$:\n$$\nS_{t_{k+1}} = \\exp\\left( \\ln(S_{t_k}) + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_k \\right)\n$$\nUsing the property $\\exp(a+b) = \\exp(a)\\exp(b)$, we can separate the $S_{t_k}$ term:\n$$\nS_{t_{k+1}} = \\exp(\\ln(S_{t_k})) \\exp\\left( \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_k \\right)\n$$\nSince $\\exp(\\ln(x))=x$, we arrive at the exact one-step simulation formula for geometric Brownian motion:\n$$\nS_{t_{k+1}} = S_{t_k} \\exp\\left( \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma \\sqrt{\\Delta t} \\, Z_k \\right)\n$$\nThis formula expresses $S_{t_{k+1}}$ solely in terms of $S_{t_k}$ and the given parameters, as required.", "answer": "$$\n\\boxed{S_{t_{k+1}} = S_{t_k} \\exp\\left( \\left(\\mu - \\frac{1}{2}\\sigma^2\\right) \\Delta t + \\sigma \\sqrt{\\Delta t} Z_k \\right)}\n$$", "id": "3057144"}, {"introduction": "While simulation is powerful, analytical solutions provide deep insight and a crucial benchmark for verifying numerical models. This exercise challenges you to calculate the probability that an asset price $S_t$ will lie within a specific range at a future time. You will leverage the key property that $\\ln(S_t)$ follows a normal distribution, enabling the use of the standard normal CDF to obtain an exact, closed-form answer for this fundamental risk-management question.", "problem": "Consider an asset price process $\\{S_{t}\\}_{t \\geq 0}$ modeled as geometric Brownian motion (GBM) under the stochastic differential equation $dS_{t}=\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t}$, where $W_{t}$ is a standard Brownian motion, $\\mu \\in \\mathbb{R}$ is a constant drift, and $\\sigma0$ is a constant volatility. Let $0 \\leq u  t$ be fixed times and suppose an observation $S_{u}=x$ is available with $x0$. Let $a$ and $b$ be positive real numbers satisfying $0ab$. Starting only from the definition of GBM above and the properties of Brownian motion and Itō calculus, derive the conditional distribution of $\\ln S_{t}$ given $S_{u}=x$ and use it to evaluate the conditional probability $\\mathbb{P}(S_{t}\\in(a,b)\\mid S_{u}=x)$. Express your final answer in closed form in terms of the standard normal cumulative distribution function (CDF), denoted by $\\Phi$. Do not invoke any memorized log-normal distribution formulas; the derivation must originate from the stochastic differential equation and the transformation of variables.", "solution": "The asset price process $\\{S_{t}\\}_{t \\geq 0}$ is governed by the stochastic differential equation (SDE) for a geometric Brownian motion (GBM):\n$$dS_{t}=\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t}$$\nwhere $W_{t}$ is a standard Brownian motion, $\\mu$ is the constant drift, and $\\sigma  0$ is the constant volatility. We are given the condition $S_{u}=x$ for a fixed time $u \\geq 0$ and $x0$. Our objective is to find the conditional probability $\\mathbb{P}(S_{t}\\in(a,b)\\mid S_{u}=x)$ for fixed times $0 \\leq u  t$ and constants $0ab$.\n\nThe derivation must originate from the SDE itself. To find the distribution of $S_{t}$, we first seek the distribution of its logarithm, $\\ln S_{t}$. Let us define a new process $Y_{t} = f(S_{t}) = \\ln S_{t}$. To find the SDE for $Y_{t}$, we apply Itō's lemma. For a function $f(t, s)$ of time and a stochastic process $S_t$, Itō's lemma states:\n$$df(t, S_t) = \\frac{\\partial f}{\\partial t} dt + \\frac{\\partial f}{\\partial s} dS_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial s^2} (dS_t)^2$$\nIn our case, $f(S_{t}) = \\ln S_{t}$, so $f$ does not have explicit time dependence, i.e., $\\frac{\\partial f}{\\partial t} = 0$. The necessary derivatives of $f(s) = \\ln s$ with respect to $s$ are:\n$$f'(s) = \\frac{df}{ds} = \\frac{1}{s}$$\n$$f''(s) = \\frac{d^2f}{ds^2} = -\\frac{1}{s^2}$$\nSubstituting $s=S_t$, we get $\\frac{\\partial f}{\\partial S_t} = \\frac{1}{S_t}$ and $\\frac{\\partial^2 f}{\\partial S_t^2} = -\\frac{1}{S_t^2}$.\n\nThe quadratic variation term $(dS_{t})^2$ is computed using the Itō multiplication rules ($dt^2=0$, $dt\\,dW_t=0$, $dW_t^2=dt$):\n$$(dS_{t})^2 = (\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t})^2 = (\\mu S_{t}\\,dt)^2 + 2(\\mu S_{t}\\,dt)(\\sigma S_t\\,dW_t) + (\\sigma S_t\\,dW_t)^2$$\n$$(dS_{t})^2 = \\mu^2 S_t^2\\,(dt)^2 + 2\\mu\\sigma S_t^2\\,dt\\,dW_t + \\sigma^2 S_t^2\\,(dW_t)^2 = 0 + 0 + \\sigma^2 S_t^2\\,dt = \\sigma^2 S_t^2\\,dt$$\n\nNow we substitute these components into Itō's lemma for $Y_t = \\ln S_t$:\n$$dY_{t} = d(\\ln S_{t}) = \\left(\\frac{1}{S_{t}}\\right) dS_{t} + \\frac{1}{2}\\left(-\\frac{1}{S_{t}^2}\\right) (dS_{t})^2$$\nSubstituting the expressions for $dS_t$ and $(dS_t)^2$:\n$$dY_{t} = \\frac{1}{S_{t}}(\\mu S_{t}\\,dt+\\sigma S_{t}\\,dW_{t}) - \\frac{1}{2S_{t}^2}(\\sigma^2 S_{t}^2\\,dt)$$\n$$dY_{t} = (\\mu\\,dt + \\sigma\\,dW_{t}) - \\frac{1}{2}\\sigma^2\\,dt$$\nCollecting the $dt$ and $dW_{t}$ terms, we obtain the SDE for $Y_t$:\n$$dY_{t} = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)dt + \\sigma\\,dW_{t}$$\nThis is the SDE for an arithmetic Brownian motion with a constant drift $\\left(\\mu - \\frac{1}{2}\\sigma^2\\right)$ and constant volatility $\\sigma$.\n\nTo find the value of $Y_{t}$ given its value at time $u$, we integrate the SDE from $u$ to $t$:\n$$\\int_{u}^{t} dY_{s} = \\int_{u}^{t} \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)ds + \\int_{u}^{t} \\sigma\\,dW_{s}$$\n$$Y_{t} - Y_{u} = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u) + \\sigma (W_{t}-W_{u})$$\nSubstituting $Y_{t} = \\ln S_{t}$ and the given condition $S_{u}=x$, which implies $Y_u = \\ln S_u = \\ln x$:\n$$\\ln S_{t} - \\ln x = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u) + \\sigma (W_{t}-W_{u})$$\n$$\\ln S_{t} = \\ln x + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u) + \\sigma (W_{t}-W_{u})$$\nThe properties of standard Brownian motion state that for $tu$, the increment $W_{t}-W_{u}$ is a normally distributed random variable with mean $0$ and variance $t-u$. That is, $W_{t}-W_{u} \\sim \\mathcal{N}(0, t-u)$.\nConsequently, the term $\\sigma(W_{t}-W_{u})$ is also normally distributed: $\\sigma(W_{t}-W_{u}) \\sim \\mathcal{N}(0, \\sigma^2(t-u))$.\nThe expression for $\\ln S_{t}$ is the sum of a constant term (since $S_u=x$ is a fixed value) and a normally distributed random variable. Thus, conditional on $S_{u}=x$, the random variable $\\ln S_{t}$ is normally distributed. Its mean and variance are:\n$$\\mathbb{E}[\\ln S_{t} \\mid S_{u}=x] = \\ln x + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)$$\n$$\\text{Var}[\\ln S_{t} \\mid S_{u}=x] = \\text{Var}[\\sigma (W_{t}-W_{u})] = \\sigma^2 (t-u)$$\nSo, the conditional distribution of $\\ln S_{t}$ given $S_u=x$ is:\n$$\\ln S_{t} \\mid S_{u}=x \\sim \\mathcal{N}\\left(\\ln x + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u), \\sigma^2(t-u)\\right)$$\nThis completes the first part of the derivation.\n\nNext, we evaluate the conditional probability $\\mathbb{P}(S_{t}\\in(a,b)\\mid S_{u}=x)$. Since $\\ln(\\cdot)$ is a strictly increasing function, the event $a  S_{t}  b$ is equivalent to the event $\\ln a  \\ln S_{t}  \\ln b$.\n$$\\mathbb{P}(a  S_{t}  b \\mid S_{u}=x) = \\mathbb{P}(\\ln a  \\ln S_{t}  \\ln b \\mid S_{u}=x)$$\nTo compute this probability, we standardize the normal random variable $\\ln S_{t}$. Let $Z$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$. We have:\n$$Z = \\frac{\\ln S_{t} - \\mathbb{E}[\\ln S_{t} \\mid S_{u}=x]}{\\sqrt{\\text{Var}[\\ln S_{t} \\mid S_{u}=x]}} = \\frac{\\ln S_{t} - \\left(\\ln x + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)\\right)}{\\sigma\\sqrt{t-u}}$$\nWe transform the inequality $\\ln a  \\ln S_{t}  \\ln b$ into an inequality for $Z$:\n$$\\frac{\\ln a - \\left(\\ln x + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)\\right)}{\\sigma\\sqrt{t-u}}  Z  \\frac{\\ln b - \\left(\\ln x + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)\\right)}{\\sigma\\sqrt{t-u}}$$\nUsing the property $\\ln a - \\ln x = \\ln(a/x)$, the inequality becomes:\n$$\\frac{\\ln(a/x) - \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)}{\\sigma\\sqrt{t-u}}  Z  \\frac{\\ln(b/x) - \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)}{\\sigma\\sqrt{t-u}}$$\nThe probability of a standard normal variable $Z$ falling in an interval $(c,d)$ is given by $\\Phi(d) - \\Phi(c)$, where $\\Phi$ is the cumulative distribution function (CDF) of the standard normal distribution.\nLet's define the lower and upper bounds of the interval for $Z$:\n$$c = \\frac{\\ln(a/x) - \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)}{\\sigma\\sqrt{t-u}}$$\n$$d = \\frac{\\ln(b/x) - \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)}{\\sigma\\sqrt{t-u}}$$\nTherefore, the required conditional probability is:\n$$\\mathbb{P}(S_{t}\\in(a,b)\\mid S_{u}=x) = \\mathbb{P}(c  Z  d) = \\Phi(d) - \\Phi(c)$$\nSubstituting the expressions for $c$ and $d$, we arrive at the final closed-form solution:\n$$\\mathbb{P}(S_{t}\\in(a,b)\\mid S_{u}=x) = \\Phi\\left(\\frac{\\ln\\left(\\frac{b}{x}\\right) - \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)}{\\sigma\\sqrt{t-u}}\\right) - \\Phi\\left(\\frac{\\ln\\left(\\frac{a}{x}\\right) - \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)(t-u)}{\\sigma\\sqrt{t-u}}\\right)$$", "answer": "$$\\boxed{\\mathbb{P}(S_{t}\\in(a,b)\\mid S_{u}=x) = \\Phi\\left(\\frac{\\ln\\left(\\frac{b}{x}\\right) - \\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)(t-u)}{\\sigma\\sqrt{t-u}}\\right) - \\Phi\\left(\\frac{\\ln\\left(\\frac{a}{x}\\right) - \\left(\\mu - \\frac{1}{2}\\sigma^{2}\\right)(t-u)}{\\sigma\\sqrt{t-u}}\\right)}$$", "id": "3057140"}, {"introduction": "Having derived the exact simulation scheme [@problem_id:3057144], it is natural to ask why a more straightforward discretization of the SDE, such as the Euler-Maruyama method, is not always preferred for its simplicity. This advanced exercise requires you to analytically compute the bias and variance for Monte Carlo estimators built from both the exact and the Euler-Maruyama methods. By directly comparing these quantities, you will uncover the subtle but critical flaws in the approximate scheme and gain a profound understanding of the importance of using numerically sound simulation techniques.", "problem": "Consider an asset price modeled as Geometric Brownian Motion (GBM), defined by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}S_t = \\mu S_t \\,\\mathrm{d}t + \\sigma S_t \\,\\mathrm{d}W_t,\n$$\nwhere $S_t$ is the asset price at time $t$, $\\mu$ is the drift, $\\sigma$ is the volatility, and $W_t$ is a standard Brownian motion. From first principles of Itô calculus and the independence and stationarity of Brownian increments, one can derive properties of the expectation and moments of GBM, as well as design numerical schemes to approximate its evolution.\n\nYou are to compare two Monte Carlo estimators for the expectation $\\mathbb{E}[S_T]$ at a fixed horizon $T$:\n- An estimator based on the Euler–Maruyama discretization for the SDE on a uniform time grid of $M$ steps, where the discrete-time update is\n$$\nS_{n+1} = S_n + \\mu S_n \\Delta t + \\sigma S_n \\Delta W_n,\n$$\nwith $\\Delta t = T/M$ and $\\Delta W_n$ representing independent Gaussian increments with mean $0$ and variance $\\Delta t$; and\n- An estimator based on exact log-normal sampling that uses the closed-form distribution of $S_T$ implied by GBM.\n\nStarting from the SDE and fundamental properties of Brownian motion (independence and Gaussian increments) and Itô calculus, derive the analytical bias and variance of the Monte Carlo sample-mean estimator for $\\mathbb{E}[S_T]$ produced by:\n- Euler–Maruyama discretization on $M$ steps; and\n- Exact log-normal sampling.\n\nFor the Euler–Maruyama estimator, you must derive formulas for $\\mathbb{E}[S_M]$ and $\\mathrm{Var}(S_M)$ purely from the discrete update, independence of $\\Delta W_n$, and properties of the normal distribution. For the exact log-normal estimator, you must derive the distribution of $\\log S_T$ via Itô calculus and then compute $\\mathbb{E}[S_T]$ and $\\mathrm{Var}(S_T)$ using properties of the exponential of a normal random variable.\n\nDefine the estimator bias as the difference between the estimator’s expected value and the true $\\mathbb{E}[S_T]$:\n$$\n\\text{bias} := \\mathbb{E}[\\widehat{\\mathbb{E}}[S_T]] - \\mathbb{E}[S_T],\n$$\nand the estimator variance as the variance of the sample mean across $N$ independent paths:\n$$\n\\mathrm{Var}(\\widehat{\\mathbb{E}}[S_T]) = \\frac{\\mathrm{Var}(S_T^{\\text{model}})}{N},\n$$\nwhere $S_T^{\\text{model}}$ denotes the terminal value under the chosen modeling approach (Euler–Maruyama or exact log-normal).\n\nYour program must implement these derived analytical expressions (not empirical Monte Carlo estimates) and compute, for each test case, the four quantities:\n- Euler–Maruyama bias,\n- Euler–Maruyama variance of the sample-mean estimator,\n- Exact log-normal sampling bias,\n- Exact log-normal sampling variance of the sample-mean estimator.\n\nUse the following test suite, which covers typical, coarse-discretization, zero-volatility, and negative-drift scenarios:\n- Test case $1$: $S_0 = 100$, $\\mu = 0.05$, $\\sigma = 0.2$, $T = 1.0$, $M = 252$, $N = 100000$.\n- Test case $2$: $S_0 = 100$, $\\mu = -0.03$, $\\sigma = 0.3$, $T = 1.5$, $M = 300$, $N = 200000$.\n- Test case $3$: $S_0 = 50$, $\\mu = 0.1$, $\\sigma = 0.0$, $T = 2.0$, $M = 100$, $N = 50000$.\n- Test case $4$: $S_0 = 100$, $\\mu = 0.08$, $\\sigma = 0.5$, $T = 1.0$, $M = 12$, $N = 80000$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of lists, with each inner list ordered as $[\\text{bias}_{\\text{EM}}, \\mathrm{Var}_{\\text{EM}}, \\text{bias}_{\\text{Exact}}, \\mathrm{Var}_{\\text{Exact}}]$. For example, the output format must be\n$$\n[[b_1,v_1,b_2,v_2],[b_1',v_1',b_2',v_2'],\\dots]\n$$\nwhere each $b_i$ and $v_i$ is a real number (float). No physical units are involved, and all angles and percentages are irrelevant to this task. The program must be completely deterministic and must not perform any random sampling.", "solution": "The objective is to derive and implement analytical formulas for the bias and variance of two Monte Carlo estimators for the expected asset price, $\\mathbb{E}[S_T]$, under the Geometric Brownian Motion (GBM) model. The GBM model is described by the stochastic differential equation (SDE):\n$$\n\\mathrm{d}S_t = \\mu S_t \\,\\mathrm{d}t + \\sigma S_t \\,\\mathrm{d}W_t\n$$\nwhere $S_t$ is the price at time $t$, $\\mu$ is the drift, $\\sigma$ is the volatility, and $W_t$ is a standard Brownian motion. We will analyze an estimator based on the Euler-Maruyama discretization and one based on exact sampling from the known log-normal distribution of $S_T$.\n\n### 1. Analysis of the True Continuous-Time Process\n\nTo understand the properties of the estimators, we must first establish the true properties of $S_T$. We derive the distribution of $S_T$ using Itô's lemma. Let $X_t = \\log S_t$. Applying Itô's lemma for a function $f(S_t) = \\log S_t$, with derivatives $f'(S_t) = 1/S_t$ and $f''(S_t) = -1/S_t^2$, we obtain:\n$$\n\\mathrm{d}X_t = \\frac{\\partial f}{\\partial t}\\mathrm{d}t + \\frac{\\partial f}{\\partial S_t}\\mathrm{d}S_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial S_t^2}(\\mathrm{d}S_t)^2\n$$\nThe Ito multiplication rule gives $(\\mathrm{d}S_t)^2 = \\sigma^2 S_t^2 \\mathrm{d}t$. Substituting the derivatives and $\\mathrm{d}S_t$ yields:\n$$\n\\mathrm{d}X_t = 0 + \\frac{1}{S_t}(\\mu S_t \\mathrm{d}t + \\sigma S_t \\mathrm{d}W_t) + \\frac{1}{2}\\left(-\\frac{1}{S_t^2}\\right)(\\sigma^2 S_t^2 \\mathrm{d}t)\n$$\n$$\n\\mathrm{d}X_t = (\\mu - \\frac{1}{2}\\sigma^2)\\mathrm{d}t + \\sigma \\mathrm{d}W_t\n$$\nIntegrating from $t=0$ to $t=T$:\n$$\nX_T - X_0 = \\int_0^T \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)\\mathrm{d}t + \\int_0^T \\sigma \\mathrm{d}W_t = \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T + \\sigma W_T\n$$\nSince $W_T \\sim \\mathcal{N}(0, T)$, the variable $X_T = \\log S_T$ is normally distributed:\n$$\n\\log S_T \\sim \\mathcal{N}\\left(\\log S_0 + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T, \\sigma^2 T\\right)\n$$\nThus, $S_T$ follows a log-normal distribution. The moments of a log-normal variable $Z = e^Y$ where $Y \\sim \\mathcal{N}(m, s^2)$ are $\\mathbb{E}[Z] = e^{m + s^2/2}$ and $\\mathrm{Var}(Z) = (e^{s^2}-1)e^{2m+s^2}$.\nFor $S_T$, we have $m = \\log S_0 + (\\mu - \\frac{1}{2}\\sigma^2)T$ and $s^2 = \\sigma^2 T$.\n\nThe true expectation $\\mathbb{E}[S_T]$ is:\n$$\n\\mathbb{E}[S_T] = \\exp\\left( \\log S_0 + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T + \\frac{1}{2}\\sigma^2 T \\right) = \\exp(\\log S_0 + \\mu T) = S_0 e^{\\mu T}\n$$\nThe true variance $\\mathrm{Var}(S_T)$ is:\n$$\n\\mathrm{Var}(S_T) = \\left(e^{\\sigma^2 T} - 1\\right) \\exp\\left(2\\left(\\log S_0 + \\left(\\mu - \\frac{1}{2}\\sigma^2\\right)T\\right) + \\sigma^2 T\\right)\n$$\n$$\n\\mathrm{Var}(S_T) = \\left(e^{\\sigma^2 T} - 1\\right) \\exp(2\\log S_0 + 2\\mu T - \\sigma^2 T + \\sigma^2 T) = S_0^2 e^{2\\mu T} (e^{\\sigma^2 T} - 1)\n$$\nThese quantities serve as the benchmark for evaluating the estimators.\n\n### 2. Analysis of the Exact Log-Normal Sampling Estimator\n\nThis estimator generates samples directly from the true distribution of $S_T$. The sample mean estimator from $N$ samples is $\\widehat{\\mathbb{E}}[S_T] = \\frac{1}{N}\\sum_{i=1}^N S_{T,i}$, where each $S_{T,i}$ is an independent draw from the true distribution.\nThe expectation of this estimator is:\n$$\n\\mathbb{E}[\\widehat{\\mathbb{E}}[S_T]] = \\mathbb{E}\\left[\\frac{1}{N}\\sum_{i=1}^N S_{T,i}\\right] = \\frac{1}{N}\\sum_{i=1}^N \\mathbb{E}[S_{T,i}] = \\mathbb{E}[S_T]\n$$\nThe bias is defined as $\\text{bias} := \\mathbb{E}[\\widehat{\\mathbb{E}}[S_T]] - \\mathbb{E}[S_T]$.\n$$\n\\text{bias}_{\\text{Exact}} = \\mathbb{E}[S_T] - \\mathbb{E}[S_T] = 0\n$$\nThe exact estimator is unbiased.\n\nThe variance of the sample-mean estimator is given by $\\mathrm{Var}(\\widehat{\\mathbb{E}}[S_T]) = \\mathrm{Var}(S_T)/N$, as the samples are independent.\n$$\n\\mathrm{Var}_{\\text{Exact}} = \\frac{\\mathrm{Var}(S_T)}{N} = \\frac{S_0^2 e^{2\\mu T} (e^{\\sigma^2 T} - 1)}{N}\n$$\n\n### 3. Analysis of the Euler-Maruyama Estimator\n\nThe Euler-Maruyama scheme discretizes the SDE into $M$ steps of size $\\Delta t = T/M$:\n$$\nS_{n+1} = S_n + \\mu S_n \\Delta t + \\sigma S_n \\Delta W_n = S_n(1 + \\mu \\Delta t + \\sigma \\Delta W_n)\n$$\nwhere $\\Delta W_n \\sim \\mathcal{N}(0, \\Delta t)$ are independent increments. Let $S_M$ denote the terminal price $S_T^{\\text{EM}}$.\n\nFirst, we find the expectation $\\mathbb{E}[S_M]$. Using the law of total expectation:\n$$\n\\mathbb{E}[S_{n+1}] = \\mathbb{E}[\\mathbb{E}[S_{n+1} | S_n]] = \\mathbb{E}[S_n(1 + \\mu \\Delta t + \\sigma \\mathbb{E}[\\Delta W_n])] = \\mathbb{E}[S_n](1 + \\mu \\Delta t)\n$$\nThis is a recurrence relation. Starting from $\\mathbb{E}[S_0] = S_0$, we obtain:\n$$\n\\mathbb{E}[S_M] = S_0(1 + \\mu \\Delta t)^M = S_0\\left(1 + \\mu \\frac{T}{M}\\right)^M\n$$\nThe bias of the Euler-Maruyama estimator is therefore:\n$$\n\\text{bias}_{\\text{EM}} = \\mathbb{E}[S_M] - \\mathbb{E}[S_T] = S_0\\left(1 + \\mu \\frac{T}{M}\\right)^M - S_0 e^{\\mu T}\n$$\n\nNext, we find the variance $\\mathrm{Var}(S_M)$. We begin by calculating the second moment $\\mathbb{E}[S_M^2]$. We find the recurrence for $\\mathbb{E}[S_{n+1}^2]$:\n$$\n\\mathbb{E}[S_{n+1}^2 | S_n] = \\mathbb{E}[S_n^2(1 + \\mu \\Delta t + \\sigma \\Delta W_n)^2 | S_n]\n$$\n$$\n= S_n^2 \\mathbb{E}[1 + \\mu^2(\\Delta t)^2 + \\sigma^2(\\Delta W_n)^2 + 2\\mu\\Delta t + 2\\sigma\\Delta W_n + 2\\mu\\sigma\\Delta t\\Delta W_n]\n$$\nUsing $\\mathbb{E}[\\Delta W_n]=0$ and $\\mathbb{E}[(\\Delta W_n)^2] = \\Delta t$:\n$$\n\\mathbb{E}[S_{n+1}^2 | S_n] = S_n^2 (1 + \\mu^2(\\Delta t)^2 + \\sigma^2\\Delta t + 2\\mu\\Delta t)\n$$\nTaking the full expectation:\n$$\n\\mathbb{E}[S_{n+1}^2] = \\mathbb{E}[S_n^2](1 + 2\\mu\\Delta t + \\sigma^2\\Delta t + \\mu^2(\\Delta t)^2)\n$$\nStarting with $\\mathbb{E}[S_0^2]=S_0^2$, the solution to this recurrence is:\n$$\n\\mathbb{E}[S_M^2] = S_0^2 \\left(1 + 2\\mu\\Delta t + \\sigma^2\\Delta t + \\mu^2(\\Delta t)^2\\right)^M\n$$\nThe variance is $\\mathrm{Var}(S_M) = \\mathbb{E}[S_M^2] - (\\mathbb{E}[S_M])^2$.\n$$\n(\\mathbb{E}[S_M])^2 = \\left(S_0(1+\\mu\\Delta t)^M\\right)^2 = S_0^2 \\left((1+\\mu\\Delta t)^2\\right)^M = S_0^2(1+2\\mu\\Delta t + \\mu^2(\\Delta t)^2)^M\n$$\nTherefore, the variance of a single Euler-Maruyama path is:\n$$\n\\mathrm{Var}(S_M) = S_0^2 \\left[ \\left(1 + 2\\mu\\Delta t + \\sigma^2\\Delta t + \\mu^2(\\Delta t)^2\\right)^M - \\left(1+2\\mu\\Delta t + \\mu^2(\\Delta t)^2\\right)^M \\right]\n$$\nSubstituting $\\Delta t = T/M$:\n$$\n\\mathrm{Var}(S_M) = S_0^2 \\left[ \\left(1 + (2\\mu + \\sigma^2)\\frac{T}{M} + \\mu^2\\frac{T^2}{M^2}\\right)^M - \\left(1 + 2\\mu\\frac{T}{M} + \\mu^2\\frac{T^2}{M^2}\\right)^M \\right]\n$$\nThe variance of the sample-mean estimator is $\\mathrm{Var}(S_M)/N$.\n$$\n\\mathrm{Var}_{\\text{EM}} = \\frac{S_0^2}{N} \\left[ \\left(1 + (2\\mu + \\sigma^2)\\frac{T}{M} + \\mu^2\\frac{T^2}{M^2}\\right)^M - \\left(\\left(1 + \\mu \\frac{T}{M}\\right)^2\\right)^M \\right]\n$$\n\n### 4. Summary of Analytical Formulas\nFor each test case with parameters $(S_0, \\mu, \\sigma, T, M, N)$, we compute the following four quantities:\n\n1.  **Euler-Maruyama Bias**: $\\text{bias}_{\\text{EM}} = S_0\\left(1 + \\mu \\frac{T}{M}\\right)^M - S_0 e^{\\mu T}$\n2.  **Euler-Maruyama Estimator Variance**: $\\mathrm{Var}_{\\text{EM}} = \\frac{S_0^2}{N} \\left[ \\left(1 + (2\\mu + \\sigma^2)\\frac{T}{M} + \\mu^2\\frac{T^2}{M^2}\\right)^M - \\left(1 + \\mu \\frac{T}{M}\\right)^{2M} \\right]$\n3.  **Exact Sampling Bias**: $\\text{bias}_{\\text{Exact}} = 0$\n4.  **Exact Sampling Estimator Variance**: $\\mathrm{Var}_{\\text{Exact}} = \\frac{S_0^2 e^{2\\mu T} (e^{\\sigma^2 T} - 1)}{N}$\n\nThese formulas will be implemented programmatically.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the analytical bias and variance for Euler-Maruyama and\n    exact log-normal sampling estimators for the expected value of a\n    Geometric Brownian Motion process.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (S0, mu, sigma, T, M, N)\n        (100, 0.05, 0.2, 1.0, 252, 100000),\n        (100, -0.03, 0.3, 1.5, 300, 200000),\n        (50, 0.1, 0.0, 2.0, 100, 50000),\n        (100, 0.08, 0.5, 1.0, 12, 80000),\n    ]\n\n    results = []\n    for case in test_cases:\n        S0, mu, sigma, T, M, N = case\n        \n        # --- True (Continuous-Time) Process Properties ---\n        # True expectation of S_T\n        true_exp_S_T = S0 * np.exp(mu * T)\n        \n        # True variance of S_T\n        true_var_S_T = S0**2 * np.exp(2 * mu * T) * (np.exp(sigma**2 * T) - 1)\n\n        # --- Exact Log-normal Sampling Estimator ---\n        # Bias is zero by construction, as samples are drawn from the true distribution.\n        bias_exact = 0.0\n        \n        # Variance of the sample-mean estimator.\n        var_exact = true_var_S_T / N\n\n        # --- Euler-Maruyama Discretization Estimator ---\n        dt = T / M\n        \n        # Expected value of the terminal price under EM discretization.\n        exp_em_S_T = S0 * (1 + mu * dt)**M\n        \n        # Bias of the EM estimator.\n        bias_em = exp_em_S_T - true_exp_S_T\n        \n        # Variance of a single terminal price path under EM discretization.\n        # Var(S_M) = E[S_M^2] - (E[S_M])^2\n        # E[S_M^2] = S0^2 * (1 + 2*mu*dt + sigma^2*dt + mu^2*dt^2)^M\n        # (E[S_M])^2 = (S0 * (1 + mu*dt)^M)^2 = S0^2 * ((1+mu*dt)^2)^M\n        \n        # Use np.power for potentially large exponents for numerical stability.\n        term1 = np.power(1 + (2 * mu + sigma**2) * dt + (mu**2) * (dt**2), M)\n        term2 = np.power(1 + mu * dt, 2 * M)\n        var_em_single_path = S0**2 * (term1 - term2)\n        \n        # Variance of the sample-mean estimator.\n        var_em = var_em_single_path / N\n        \n        # Append the four required quantities in the specified order.\n        results.append([bias_em, var_em, bias_exact, var_exact])\n\n    # Format the output as a comma-separated list of lists.\n    # e.g., [[b1,v1,b2,v2],[b1p,v1p,b2p,v2p],...]\n    outer_list_str = [f\"[{','.join(map(str, inner_list))}]\" for inner_list in results]\n    final_output_str = f\"[{','.join(outer_list_str)}]\"\n\n    print(final_output_str)\n\nsolve()\n```", "id": "3057119"}]}