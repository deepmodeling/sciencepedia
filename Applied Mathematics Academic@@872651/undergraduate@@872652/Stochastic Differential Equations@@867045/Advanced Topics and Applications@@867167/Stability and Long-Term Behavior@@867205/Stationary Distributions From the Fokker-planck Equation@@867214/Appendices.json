{"hands_on_practices": [{"introduction": "Our first practice explores the Ornstein-Uhlenbeck process, a cornerstone model for systems relaxing to thermal equilibrium. The process describes a particle subject to a linear restoring force (like a spring) and random thermal fluctuations. This exercise [@problem_id:3076241] provides a fundamental walkthrough of deriving the stationary distribution by solving the time-independent Fokker-Planck equation, a technique that demonstrates how the balance between drift and diffusion gives rise to the celebrated Boltzmann-Gibbs distribution.", "problem": "Consider the one-dimensional Itô stochastic differential equation (SDE) on the real line $\\mathbb{R}$,\n$$\n\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t,\n$$\nwhere $a(x)$ is the drift, $D>0$ is a constant diffusion coefficient, and $W_t$ is a standard Wiener process. The probability density function (pdf) $p(x,t)$ of $X_t$ evolves according to the Fokker–Planck equation\n$$\n\\frac{\\partial}{\\partial t}p(x,t) = -\\frac{\\partial}{\\partial x}\\big(a(x)\\,p(x,t)\\big) + D\\,\\frac{\\partial^2}{\\partial x^2}p(x,t).\n$$\nAssume the drift is linear and confining, $a(x) = -\\lambda x$, with $\\lambda>0$, and seek a stationary pdf $p_s(x)$ that is normalizable on $\\mathbb{R}$ and for which the probability current vanishes at $|x|\\to\\infty$.\n\nUsing only the Fokker–Planck equation and the integrating factor method for ordinary differential equations, do the following:\n- Derive the stationary $p_s(x)$ up to a normalization constant by solving the stationary Fokker–Planck equation under the stated boundary conditions.\n- Determine the normalization constant so that $p_s(x)$ is a valid pdf on $\\mathbb{R}$.\n- From your resulting stationary density, compute the variance of $X$ under $p_s(x)$ as a closed-form expression in terms of $D$ and $\\lambda$.\n\nYour final answer must be the variance as a single analytical expression. No rounding is required and no units need to be reported.", "solution": "The problem asks for the variance of a stochastic process $X_t$ described by an Itô SDE in its stationary state. The solution requires finding the stationary probability density function (pdf) $p_s(x)$ by solving the stationary Fokker-Planck equation, normalizing it, and then calculating the variance.\n\n### Step 1: Problem Validation\n\nFirst, I will validate the problem statement.\n\n**Extracted Givens:**\n- The one-dimensional Itô SDE is $\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t$, where $D>0$ is a constant diffusion coefficient and $W_t$ is a standard Wiener process.\n- The corresponding Fokker-Planck equation for the pdf $p(x,t)$ is $\\frac{\\partial}{\\partial t}p(x,t) = -\\frac{\\partial}{\\partial x}\\big(a(x)\\,p(x,t)\\big) + D\\,\\frac{\\partial^2}{\\partial x^2}p(x,t)$.\n- The drift function is linear and confining: $a(x) = -\\lambda x$, with $\\lambda>0$.\n- The goal is to find a stationary pdf $p_s(x)$.\n- Condition 1: $p_s(x)$ must be normalizable on $\\mathbb{R}$.\n- Condition 2: The probability current must vanish at infinity, i.e., as $|x|\\to\\infty$.\n- The derivation must use the integrating factor method.\n\n**Validation using Extracted Givens:**\nThe problem is scientifically grounded. The Itô SDE with a linear drift, $a(x) = -\\lambda x$, describes the Ornstein-Uhlenbeck process, a fundamental model in statistical mechanics and stochastic processes. The Fokker-Planck equation provided is the correct forward Kolmogorov equation for this process. The conditions of a confining drift ($\\lambda>0$) and constant diffusion ($D>0$) are standard for ensuring the existence of a unique, stable stationary distribution. The problem is self-contained, with all necessary equations, parameters, and boundary conditions clearly defined. It is well-posed and objective. The problem is a standard exercise in stochastic calculus and is free of any of the invalidating flaws listed in the instructions.\n\n**Verdict:** The problem is valid.\n\n### Step 2: Derivation of the Stationary Solution\n\nThe stationary pdf, denoted $p_s(x)$, is defined by the condition $\\frac{\\partial p_s(x,t)}{\\partial t} = 0$. Applying this to the given Fokker-Planck equation yields the stationary Fokker-Planck equation:\n$$\n0 = -\\frac{\\mathrm{d}}{\\mathrm{d}x}\\big(a(x)\\,p_s(x)\\big) + D\\,\\frac{\\mathrm{d}^2}{\\mathrm{d}x^2}p_s(x)\n$$\nThis equation can be expressed as $\\frac{\\mathrm{d}}{\\mathrm{d}x} J(x) = 0$, where $J(x)$ is the probability current, defined as:\n$$\nJ(x) = a(x)\\,p_s(x) - D\\,\\frac{\\mathrm{d}}{\\mathrm{d}x}p_s(x)\n$$\nThe condition $\\frac{\\mathrm{d}J(x)}{\\mathrm{d}x} = 0$ implies that the probability current $J(x)$ is a constant, say $J_0$. The problem states that the probability current vanishes for $|x|\\to\\infty$. This implies that $J_0=0$. Therefore, the probability current must be zero for all $x \\in \\mathbb{R}$. This gives us a first-order ordinary differential equation (ODE) for $p_s(x)$:\n$$\na(x)\\,p_s(x) - D\\,\\frac{\\mathrm{d}p_s(x)}{\\mathrm{d}x} = 0\n$$\nSubstituting the given drift term $a(x) = -\\lambda x$:\n$$\n-\\lambda x\\,p_s(x) - D\\,\\frac{\\mathrm{d}p_s(x)}{\\mathrm{d}x} = 0\n$$\nRearranging this into a standard form for a first-order linear homogeneous ODE:\n$$\n\\frac{\\mathrm{d}p_s}{\\mathrm{d}x} + \\frac{\\lambda}{D}x\\,p_s(x) = 0\n$$\nAs requested by the problem, we use the integrating factor method. The integrating factor $I(x)$ is given by $I(x) = \\exp\\left(\\int \\frac{\\lambda}{D}x\\,\\mathrm{d}x\\right)$.\nCalculating the integral in the exponent:\n$$\n\\int \\frac{\\lambda}{D}x\\,\\mathrm{d}x = \\frac{\\lambda}{2D}x^2\n$$\nSo the integrating factor is $I(x) = \\exp\\left(\\frac{\\lambda x^2}{2D}\\right)$. Multiplying the ODE by $I(x)$:\n$$\n\\exp\\left(\\frac{\\lambda x^2}{2D}\\right)\\frac{\\mathrm{d}p_s}{\\mathrm{d}x} + \\frac{\\lambda}{D}x\\,\\exp\\left(\\frac{\\lambda x^2}{2D}\\right)p_s(x) = 0\n$$\nThe left-hand side is the derivative of a product, $\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(p_s(x)I(x)\\right)$:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(p_s(x)\\exp\\left(\\frac{\\lambda x^2}{2D}\\right)\\right) = 0\n$$\nIntegrating both sides with respect to $x$ gives:\n$$\np_s(x)\\exp\\left(\\frac{\\lambda x^2}{2D}\\right) = C\n$$\nwhere $C$ is a constant of integration. Solving for $p_s(x)$, we obtain the stationary distribution up to a normalization constant:\n$$\np_s(x) = C\\,\\exp\\left(-\\frac{\\lambda x^2}{2D}\\right)\n$$\n\n### Step 3: Normalization of the Stationary PDF\n\nFor $p_s(x)$ to be a valid pdf, its integral over the entire real line must equal $1$:\n$$\n\\int_{-\\infty}^{\\infty} p_s(x)\\,\\mathrm{d}x = 1\n$$\nSubstituting the expression for $p_s(x)$:\n$$\n\\int_{-\\infty}^{\\infty} C\\,\\exp\\left(-\\frac{\\lambda x^2}{2D}\\right)\\,\\mathrm{d}x = 1\n$$\nThis is a standard Gaussian integral of the form $\\int_{-\\infty}^{\\infty} \\exp(-ax^2)\\,\\mathrm{d}x = \\sqrt{\\frac{\\pi}{a}}$. In our case, the parameter $a$ is $\\frac{\\lambda}{2D}$. Therefore:\n$$\nC \\sqrt{\\frac{\\pi}{\\frac{\\lambda}{2D}}} = C \\sqrt{\\frac{2\\pi D}{\\lambda}} = 1\n$$\nSolving for the normalization constant $C$:\n$$\nC = \\sqrt{\\frac{\\lambda}{2\\pi D}}\n$$\nThus, the fully normalized stationary probability density function is:\n$$\np_s(x) = \\sqrt{\\frac{\\lambda}{2\\pi D}} \\exp\\left(-\\frac{\\lambda x^2}{2D}\\right)\n$$\n\n### Step 4: Calculation of the Variance\n\nThe stationary distribution $p_s(x)$ is a Gaussian (normal) distribution. A general Gaussian pdf has the form:\n$$\nf(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n$$\nwhere $\\mu$ is the mean and $\\sigma^2$ is the variance.\nBy comparing our $p_s(x)$ with the general form, we can identify the mean and variance. Our distribution can be written as:\n$$\np_s(x) = \\frac{1}{\\sqrt{2\\pi \\frac{D}{\\lambda}}} \\exp\\left(-\\frac{x^2}{2\\frac{D}{\\lambda}}\\right)\n$$\nFrom this comparison, we can directly identify the mean $\\mu = 0$ and the variance $\\sigma^2 = \\frac{D}{\\lambda}$.\n\nAlternatively, we can compute the variance using its definition, $\\text{Var}(X) = E[X^2] - (E[X])^2$.\nFirst, we compute the mean $E[X]$:\n$$\nE[X] = \\int_{-\\infty}^{\\infty} x p_s(x)\\,\\mathrm{d}x = \\int_{-\\infty}^{\\infty} x \\sqrt{\\frac{\\lambda}{2\\pi D}} \\exp\\left(-\\frac{\\lambda x^2}{2D}\\right)\\,\\mathrm{d}x\n$$\nThe integrand is an odd function (a product of an odd function $x$ and an even function, the Gaussian), integrated over a symmetric interval $(-\\infty, \\infty)$. Therefore, the integral is zero. $E[X] = 0$.\n\nNext, we compute the second moment $E[X^2]$:\n$$\nE[X^2] = \\int_{-\\infty}^{\\infty} x^2 p_s(x)\\,\\mathrm{d}x = \\sqrt{\\frac{\\lambda}{2\\pi D}} \\int_{-\\infty}^{\\infty} x^2 \\exp\\left(-\\frac{\\lambda x^2}{2D}\\right)\\,\\mathrm{d}x\n$$\nThis integral is a known result for Gaussian distributions. For an integral of the form $\\int_{-\\infty}^{\\infty}x^2\\exp(-ax^2)\\,\\mathrm{d}x = \\frac{1}{2a}\\sqrt{\\frac{\\pi}{a}}$. Here, $a = \\frac{\\lambda}{2D}$.\n$$\n\\int_{-\\infty}^{\\infty} x^2 \\exp\\left(-\\frac{\\lambda x^2}{2D}\\right)\\,\\mathrm{d}x = \\frac{1}{2\\left(\\frac{\\lambda}{2D}\\right)}\\sqrt{\\frac{\\pi}{\\frac{\\lambda}{2D}}} = \\frac{D}{\\lambda}\\sqrt{\\frac{2\\pi D}{\\lambda}}\n$$\nSubstituting this back into the expression for $E[X^2]$:\n$$\nE[X^2] = \\sqrt{\\frac{\\lambda}{2\\pi D}} \\left(\\frac{D}{\\lambda}\\sqrt{\\frac{2\\pi D}{\\lambda}}\\right) = \\frac{D}{\\lambda}\n$$\nThe variance is then $\\text{Var}(X) = E[X^2] - (E[X])^2 = \\frac{D}{\\lambda} - 0^2 = \\frac{D}{\\lambda}$. Both methods yield the same result. The variance of the process $X$ in the stationary state is $\\frac{D}{\\lambda}$.", "answer": "$$\\boxed{\\frac{D}{\\lambda}}$$", "id": "3076241"}, {"introduction": "While many systems settle into a well-behaved Gaussian stationary state, nature also presents scenarios with more extreme fluctuations. This practice moves beyond the simple harmonic potential to explore a system with a weaker, long-range confining force, leading to a 'heavy-tailed' stationary distribution. By working through this problem [@problem_id:3076166], you will discover the intriguing consequences of such distributions, where some statistical moments diverge, and grapple with the physical implications for ergodicity—the equivalence of time and ensemble averages.", "problem": "Consider the one-dimensional Itô Stochastic Differential Equation (SDE)\n$$\n\\mathrm{d}X_t = \\mu(X_t)\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t,\n$$\nwhere $D>0$ is a constant and $W_t$ is standard Brownian motion, with drift\n$$\n\\mu(x) = -\\frac{2pD\\,x}{1+x^2},\n$$\nfor a fixed parameter $p>0$. The corresponding probability density $\\rho(x,t)$ evolves according to the Fokker–Planck equation\n$$\n\\frac{\\partial \\rho}{\\partial t} = -\\frac{\\partial}{\\partial x}\\left(\\mu(x)\\,\\rho\\right) + D\\,\\frac{\\partial^2 \\rho}{\\partial x^2}.\n$$\nAssume natural (no-flux) boundaries at $\\pm\\infty$ so that in the stationary regime the probability current vanishes.\n\nTasks:\n- Using only the Fokker–Planck equation and the no-flux condition at stationarity, derive the stationary probability density $\\rho_s(x)$ up to a normalization constant, and determine for which values of $p$ it is normalizable.\n- By analyzing the tail behavior of $\\rho_s(x)$ and the definition of moments, determine the supremum $\\tau(p)$ of orders $m \\ge 0$ such that the absolute moment of order $m$, given by $\\int_{\\mathbb{R}} |x|^m \\rho_s(x)\\,\\mathrm{d}x$, is finite.\n- Provide the final answer as a single closed-form analytic expression for $\\tau(p)$ in terms of $p$.\n\nExplain in words what the existence of a stationary density with some divergent moments implies about the ergodicity of moments, i.e., whether the time average $\\lim_{T\\to\\infty}\\frac{1}{T}\\int_0^T |X_t|^m\\,\\mathrm{d}t$ equals the ensemble average $\\int_{\\mathbb{R}} |x|^m \\rho_s(x)\\,\\mathrm{d}x$ for a given $m$. No rounding is required for the final expression.", "solution": "The analysis begins with the Fokker-Planck equation provided for the probability density $\\rho(x,t)$:\n$$\n\\frac{\\partial \\rho}{\\partial t} = -\\frac{\\partial}{\\partial x}\\left(\\mu(x)\\,\\rho\\right) + D\\,\\frac{\\partial^2 \\rho}{\\partial x^2}\n$$\nThis equation can be expressed as a continuity equation $\\frac{\\partial \\rho}{\\partial t} = -\\frac{\\partial J}{\\partial x}$, where $J(x,t)$ is the probability current, defined as:\n$$\nJ(x,t) = \\mu(x)\\,\\rho(x,t) - D\\,\\frac{\\partial \\rho(x,t)}{\\partial x}\n$$\nIn the stationary regime, the probability density becomes time-independent, $\\rho(x,t) = \\rho_s(x)$, which implies $\\frac{\\partial \\rho_s}{\\partial t} = 0$. Consequently, the Fokker-Planck equation reduces to $\\frac{\\partial J_s}{\\partial x} = 0$, where $J_s(x)$ is the stationary current. This implies that $J_s(x)$ must be a constant for all $x$.\n\nThe problem specifies natural (no-flux) boundary conditions at infinity, which means that the probability current must vanish at the boundaries: $\\lim_{x\\to\\pm\\infty} J_s(x) = 0$. Since $J_s(x)$ is a constant for all $x$ and is zero at the boundaries, it must be zero everywhere: $J_s(x) = 0$.\n\nThis leads to a first-order ordinary differential equation for the stationary density $\\rho_s(x)$:\n$$\n\\mu(x)\\,\\rho_s(x) - D\\,\\frac{\\mathrm{d} \\rho_s(x)}{\\mathrm{d} x} = 0\n$$\nSubstituting the given drift function $\\mu(x) = -\\frac{2pD\\,x}{1+x^2}$:\n$$\n-\\frac{2pD\\,x}{1+x^2}\\,\\rho_s(x) = D\\,\\frac{\\mathrm{d} \\rho_s(x)}{\\mathrm{d} x}\n$$\nAssuming $\\rho_s(x) \\neq 0$, we can separate variables:\n$$\n\\frac{1}{\\rho_s}\\,\\frac{\\mathrm{d} \\rho_s}{\\mathrm{d} x} = -\\frac{2p\\,x}{1+x^2}\n$$\nIntegrating both sides with respect to $x$ yields:\n$$\n\\int \\frac{\\mathrm{d} \\rho_s}{\\rho_s} = \\int -\\frac{2p\\,x}{1+x^2}\\,\\mathrm{d}x\n$$\n$$\n\\ln(\\rho_s(x)) = -p \\int \\frac{2x}{1+x^2}\\,\\mathrm{d}x = -p \\ln(1+x^2) + C_0\n$$\nwhere $C_0$ is the constant of integration. Exponentiating both sides gives the stationary distribution up to a normalization constant $N = \\exp(C_0)$:\n$$\n\\rho_s(x) = \\exp(-p \\ln(1+x^2) + C_0) = N\\,(1+x^2)^{-p}\n$$\nThis is the unnormalized stationary probability density.\n\nNext, we determine the condition for normalizability. The total probability must be finite, which requires the integral of $\\rho_s(x)$ over its domain to converge:\n$$\n\\int_{-\\infty}^{\\infty} \\rho_s(x)\\,\\mathrm{d}x = N \\int_{-\\infty}^{\\infty} (1+x^2)^{-p}\\,\\mathrm{d}x  \\infty\n$$\nTo assess the convergence of this integral, we examine the asymptotic behavior of the integrand as $|x| \\to \\infty$. For large $|x|$, $(1+x^2)^{-p} \\sim (x^2)^{-p} = |x|^{-2p}$. The integral $\\int_a^\\infty x^{-k}\\,\\mathrm{d}x$ converges if and only if $k>1$. In our case, the exponent is $k=2p$. Therefore, the normalization integral converges if and only if $2p > 1$, which means $p > 1/2$.\n\nNow, we determine the supremum $\\tau(p)$ of orders $m \\ge 0$ for which the absolute moment is finite. We assume the density is normalizable, so $p > 1/2$. The $m$-th absolute moment is given by the integral:\n$$\n\\langle |x|^m \\rangle = \\int_{-\\infty}^{\\infty} |x|^m \\rho_s(x)\\,\\mathrm{d}x = N \\int_{-\\infty}^{\\infty} |x|^m (1+x^2)^{-p}\\,\\mathrm{d}x\n$$\nThe integrand is an even function, so we can write this as:\n$$\n\\langle |x|^m \\rangle = 2N \\int_{0}^{\\infty} x^m (1+x^2)^{-p}\\,\\mathrm{d}x\n$$\nFor the integral to be finite, the integrand must decay sufficiently quickly as $x \\to \\infty$. For large $x$, the integrand behaves as $x^m (x^2)^{-p} = x^{m-2p}$. The integral $\\int_a^\\infty x^k\\,\\mathrm{d}x$ converges if and only if $k  -1$. In our case, the exponent is $k = m-2p$. Thus, for the moment to be finite, we require:\n$$\nm - 2p  -1 \\implies m  2p - 1\n$$\nSince we are considering moments of order $m \\ge 0$, the set of orders for which the absolute moment is finite is the interval $[0, 2p-1)$. The supremum of this set is the upper bound of the interval. Therefore, the supremum is:\n$$\n\\tau(p) = 2p - 1\n$$\nThis result is derived under the assumption that $p > 1/2$, which ensures that $\\tau(p) > 0$ and at least the $0$-th moment (normalization) exists.\n\nFinally, we address the question of ergodicity. Ergodicity for an observable $f(X_t)$ implies that the long-time average of the observable for a single trajectory equals the ensemble average computed with the stationary distribution:\n$$\n\\lim_{T\\to\\infty}\\frac{1}{T}\\int_0^T f(X_t)\\,\\mathrm{d}t = \\int_{\\mathbb{R}} f(x)\\,\\rho_s(x)\\,\\mathrm{d}x\n$$\nA fundamental result of ergodic theory for stochastic processes is that this equality holds (the time average converges to the finite ensemble average) if the ensemble average itself is finite, i.e., $\\int_{\\mathbb{R}} |f(x)|\\,\\rho_s(x)\\,\\mathrm{d}x  \\infty$.\nIn our case, the observable is $f(x)=|x|^m$. The ensemble average $\\int_{\\mathbb{R}} |x|^m \\rho_s(x)\\,\\mathrm{d}x$ is finite only for $m  \\tau(p) = 2p-1$. For these values of $m$, the process is ergodic with respect to the observable $|x|^m$, and the time average will converge to the finite ensemble average.\nHowever, for $m \\ge \\tau(p) = 2p-1$, the ensemble average $\\int_{\\mathbb{R}} |x|^m \\rho_s(x)\\,\\mathrm{d}x$ diverges. This divergence implies a breakdown of ergodicity for the observable $|x|^m$. The time average $\\lim_{T\\to\\infty}\\frac{1}{T}\\int_0^T |X_t|^m\\,\\mathrm{d}t$ will not converge to a finite constant. Instead, due to the heavy tails of the distribution $\\rho_s(x)$, the particle will experience increasingly long excursions far from the origin, causing the time average of $|X_t|^m$ to also diverge to infinity. In this sense, ergodicity is broken because the fundamental property of convergence to a finite ensemble average is lost.", "answer": "$$\n\\boxed{2p-1}\n$$", "id": "3076166"}, {"introduction": "Not all stationary states are states of equilibrium. Many systems in physics, chemistry, and biology are maintained in a non-equilibrium steady state (NESS) by a continuous flux of energy or matter. This exercise introduces this crucial concept using a simple yet profound model: a Brownian rotor driven by a constant torque. You will find that while the system reaches a steady probability distribution, it sustains a perpetual probability current, leading to the crucial distinction between 'global balance' (stationarity) and 'detailed balance' (equilibrium) [@problem_id:3076213].", "problem": "Consider the overdamped angular dynamics of a Brownian rotor on a ring driven by a constant torque. The angular coordinate is $\\theta \\in [0,2\\pi)$ with periodic boundary conditions, and the dynamics is modeled by the stochastic differential equation (SDE) $d\\theta_{t}=\\omega\\,dt+\\sqrt{2D}\\,dW_{t}$, where $\\omega$ and $D$ are strictly positive constants and $W_{t}$ is a standard Wiener process. Using only the probabilistic continuity equation associated with the Fokker–Planck equation, determine the stationary probability density $p_{s}(\\theta)$ and the stationary probability current $J_{s}(\\theta)$ subject to periodicity and normalization on $[0,2\\pi)$. Then, verify whether $\\nabla\\cdot J_s=0$ holds and state whether detailed balance holds or fails for $\\omega \\neq 0$, clearly articulating the physical distinction between global balance and detailed balance in this context. Express your final answer as a single row matrix containing $p_{s}(\\theta)$ and $J_{s}$ in that order. No rounding is required, and no units are needed.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It is a standard problem in non-equilibrium statistical mechanics and is free from any discernible flaws. Therefore, a full solution is warranted.\n\nThe dynamics of the Brownian rotor are described by the one-dimensional stochastic differential equation (SDE) on the domain $\\theta \\in [0, 2\\pi)$:\n$$d\\theta_{t}=\\omega\\,dt+\\sqrt{2D}\\,dW_{t}$$\nwhere $\\omega$ and $D$ are positive constants. This is a Langevin equation with a constant drift term $A(\\theta) = \\omega$ and a constant diffusion coefficient which we identify from the structure of the corresponding Fokker-Planck equation. The general form of the Fokker-Planck equation for a process $dx_t = A(x, t) dt + B(x, t) dW_t$ is $\\frac{\\partial p}{\\partial t} = -\\frac{\\partial}{\\partial x}(A p) + \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}(B^2 p)$.\n\nIn this specific case, $A(\\theta) = \\omega$ and $B(\\theta) = \\sqrt{2D}$, so $B(\\theta)^2 = 2D$. The Fokker-Planck equation for the probability density $p(\\theta, t)$ is:\n$$\\frac{\\partial p(\\theta,t)}{\\partial t} = -\\frac{\\partial}{\\partial \\theta}[\\omega p(\\theta,t)] + \\frac{1}{2}\\frac{\\partial^2}{\\partial \\theta^2}[(2D) p(\\theta,t)]$$\n$$\\frac{\\partial p(\\theta,t)}{\\partial t} = -\\omega \\frac{\\partial p(\\theta,t)}{\\partial \\theta} + D \\frac{\\partial^2 p(\\theta,t)}{\\partial \\theta^2}$$\nThis equation can be expressed as a probabilistic continuity equation, $\\frac{\\partial p}{\\partial t} + \\frac{\\partial J}{\\partial \\theta} = 0$, where $J(\\theta, t)$ is the probability current. By comparing the two forms, we identify the current as:\n$$J(\\theta, t) = \\omega p(\\theta, t) - D \\frac{\\partial p(\\theta, t)}{\\partial \\theta}$$\nThe problem asks for the stationary solution, where the probability density does not change with time, i.e., $\\frac{\\partial p_s(\\theta)}{\\partial t} = 0$. The subscript $s$ denotes the stationary state. From the continuity equation, this implies that the divergence of the stationary current is zero. In one dimension, this means the derivative of the stationary current with respect to the spatial coordinate is zero:\n$$\\frac{\\partial J_s(\\theta)}{\\partial \\theta} = 0$$\nThis demonstrates that the stationary probability current, $J_s(\\theta)$, must be a constant, which we shall denote as $J_0$. So, $J_s(\\theta) = J_0$.\n\nWe now have a first-order ordinary differential equation for the stationary probability density $p_s(\\theta)$:\n$$J_0 = \\omega p_s(\\theta) - D \\frac{d p_s(\\theta)}{d \\theta}$$\nRearranging this gives:\n$$\\frac{d p_s}{d \\theta} - \\frac{\\omega}{D} p_s(\\theta) = -\\frac{J_0}{D}$$\nThis is a linear first-order ODE. We solve it using an integrating factor $I(\\theta) = \\exp\\left(\\int -\\frac{\\omega}{D} d\\theta\\right) = \\exp\\left(-\\frac{\\omega}{D}\\theta\\right)$. Multiplying the ODE by $I(\\theta)$ yields:\n$$\\frac{d}{d\\theta}\\left(p_s(\\theta) \\exp\\left(-\\frac{\\omega}{D}\\theta\\right)\\right) = -\\frac{J_0}{D} \\exp\\left(-\\frac{\\omega}{D}\\theta\\right)$$\nIntegrating both sides with respect to $\\theta$:\n$$p_s(\\theta) \\exp\\left(-\\frac{\\omega}{D}\\theta\\right) = \\int -\\frac{J_0}{D} \\exp\\left(-\\frac{\\omega}{D}\\theta\\right) d\\theta = -\\frac{J_0}{D}\\left(\\frac{-D}{\\omega}\\right)\\exp\\left(-\\frac{\\omega}{D}\\theta\\right) + C$$\nwhere $C$ is the constant of integration.\n$$p_s(\\theta) \\exp\\left(-\\frac{\\omega}{D}\\theta\\right) = \\frac{J_0}{\\omega}\\exp\\left(-\\frac{\\omega}{D}\\theta\\right) + C$$\nSolving for $p_s(\\theta)$:\n$$p_s(\\theta) = \\frac{J_0}{\\omega} + C \\exp\\left(\\frac{\\omega}{D}\\theta\\right)$$\nWe have two unknown constants, $J_0$ and $C$, which we determine using the physical constraints of the system: periodicity and normalization.\n\n1.  **Periodicity**: The angular coordinate $\\theta$ is on a ring, so the probability density must be periodic with period $2\\pi$. This means $p_s(\\theta) = p_s(\\theta + 2\\pi)$, and specifically $p_s(0) = p_s(2\\pi)$.\n    $$p_s(0) = \\frac{J_0}{\\omega} + C \\exp(0) = \\frac{J_0}{\\omega} + C$$\n    $$p_s(2\\pi) = \\frac{J_0}{\\omega} + C \\exp\\left(\\frac{2\\pi\\omega}{D}\\right)$$\n    Equating these two expressions:\n    $$\\frac{J_0}{\\omega} + C = \\frac{J_0}{\\omega} + C \\exp\\left(\\frac{2\\pi\\omega}{D}\\right)$$\n    $$C = C \\exp\\left(\\frac{2\\pi\\omega}{D}\\right) \\implies C\\left(1 - \\exp\\left(\\frac{2\\pi\\omega}{D}\\right)\\right) = 0$$\n    Since the problem states $\\omega > 0$ and $D > 0$, the term $\\exp\\left(\\frac{2\\pi\\omega}{D}\\right)$ is strictly greater than $1$. Therefore, the factor $\\left(1 - \\exp\\left(\\frac{2\\pi\\omega}{D}\\right)\\right)$ is non-zero. This forces the integration constant to be zero: $C = 0$.\n    The stationary distribution is thus a constant:\n    $$p_s(\\theta) = \\frac{J_0}{\\omega}$$\n\n2.  **Normalization**: The total probability over the entire domain must be equal to $1$.\n    $$\\int_0^{2\\pi} p_s(\\theta) d\\theta = 1$$\n    $$\\int_0^{2\\pi} \\frac{J_0}{\\omega} d\\theta = 1$$\n    $$\\frac{J_0}{\\omega} [\\theta]_0^{2\\pi} = 1$$\n    $$\\frac{J_0}{\\omega} (2\\pi - 0) = 1 \\implies J_0 = \\frac{\\omega}{2\\pi}$$\n\nHaving found $J_0$, we can determine both $p_s(\\theta)$ and $J_s(\\theta)$.\nThe stationary probability density is:\n$$p_s(\\theta) = \\frac{J_0}{\\omega} = \\frac{\\omega/(2\\pi)}{\\omega} = \\frac{1}{2\\pi}$$\nThe stationary probability current is:\n$$J_s(\\theta) = J_0 = \\frac{\\omega}{2\\pi}$$\nThe resulting stationary distribution $p_s(\\theta) = \\frac{1}{2\\pi}$ is uniform, which indicates that the rotor has no preferred position on the ring. The stationary current $J_s = \\frac{\\omega}{2\\pi}$ is constant and non-zero, indicating a net flow of probability in the direction of the torque $\\omega$.\n\nNext, we verify whether $\\nabla \\cdot J_s = 0$ holds. In one dimension, this is $\\frac{dJ_s}{d\\theta} = 0$. Since we found $J_s(\\theta)=\\frac{\\omega}{2\\pi}$, which is a constant, its derivative is indeed zero:\n$$\\frac{d}{d\\theta}\\left(\\frac{\\omega}{2\\pi}\\right) = 0$$\nThis condition, known as **global balance**, is a defining characteristic of any stationary state (both equilibrium and non-equilibrium). It ensures that the probability density at any point is time-invariant.\n\nFinally, we assess whether detailed balance holds. **Detailed balance** is a stricter condition that requires the net probability current to be identically zero everywhere, i.e., $J_s(\\theta) = 0$ for all $\\theta$. In our case, for $\\omega \\neq 0$:\n$$J_s = \\frac{\\omega}{2\\pi} \\neq 0$$\nSince the stationary current is non-zero, **detailed balance fails**.\n\nThe physical distinction between these two conditions is crucial.\n**Global balance** ($\\nabla \\cdot J_s = 0$) characterizes a **stationary state**. It requires that the total probability flowing into any region of state space equals the total probability flowing out, thus keeping the density within that region constant. This allows for a non-zero net circulation of probability, which is the case here. This system is in a **non-equilibrium steady state (NESS)**. The constant torque $\\omega$ is a non-conservative force ($-\\omega \\theta$ is not a single-valued potential on the circle) that continuously performs work on the rotor, which is dissipated as heat into the environment (implicit in the overdamped SDE). This constant input and dissipation of energy maintains the system out of thermodynamic equilibrium, driving the non-zero current $J_s$.\n**Detailed balance** ($J_s = 0$) characterizes **thermodynamic equilibrium**. It requires that the rate of transition between any two states is equal to the rate of the reverse transition. This implies zero net flow of probability between any two points and forbids any macroscopic currents. Detailed balance would only hold in this system if the driving torque were zero, $\\omega=0$. In that case, $J_s=0$, and the system would be in equilibrium with its thermal environment.\nThe failure of detailed balance is a direct consequence of the non-conservative force (torque) breaking time-reversal symmetry and driving the system into a NESS.\n\nThe requested final answer is a row matrix containing $p_s(\\theta)$ and $J_s$.\n$p_s(\\theta) = \\frac{1}{2\\pi}$\n$J_s = \\frac{\\omega}{2\\pi}$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2\\pi}  \\frac{\\omega}{2\\pi} \\end{pmatrix}}$$", "id": "3076213"}]}