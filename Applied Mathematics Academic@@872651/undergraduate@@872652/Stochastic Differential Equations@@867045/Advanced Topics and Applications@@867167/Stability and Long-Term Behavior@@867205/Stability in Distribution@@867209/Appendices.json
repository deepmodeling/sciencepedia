{"hands_on_practices": [{"introduction": "To begin our hands-on exploration of stability, we will directly apply the central tool of the theory: the Foster-Lyapunov drift condition. This practice involves choosing a simple quadratic Lyapunov function, $V(x)$, and computing how it is expected to change infinitesimally over time, a quantity captured by the generator $\\mathcal{L}V(x)$. By deriving a specific inequality for $\\mathcal{L}V(x)$, you will build the foundational skill of quantifying a stochastic system's tendency to remain confined, which is the essence of stability in distribution [@problem_id:3075105].", "problem": "Consider the linear stochastic differential equation in dimension $2$ driven by two-dimensional standard Brownian motion,\n$$\n\\mathrm{d}X_{t} = A\\,X_{t}\\,\\mathrm{d}t + \\Sigma\\,\\mathrm{d}W_{t}, \\quad X_{t} \\in \\mathbb{R}^{2},\n$$\nwhere $A = -I_{2}$ and $\\Sigma = \\mathrm{diag}(1,2)$. Let $V:\\mathbb{R}^{2}\\to\\mathbb{R}$ be the Lyapunov candidate $V(x) = 1 + |x|^{2}$, where $|x|$ denotes the Euclidean norm. Starting from the definition of the infinitesimal generator and using Itô’s formula, compute the generator $\\mathcal{L}V(x)$ and verify a linear drift inequality of the form\n$$\n\\mathcal{L}V(x) \\leq -\\alpha\\,V(x) + \\beta \\quad \\text{for all } x \\in \\mathbb{R}^{2},\n$$\nwith explicit constants $\\alpha > 0$ and $\\beta \\ge 0$. Determine the largest admissible $\\alpha$ for which such an inequality holds, and, for that choice of $\\alpha$, determine the smallest $\\beta$ that makes the inequality valid for all $x \\in \\mathbb{R}^{2}$. Provide your final answer as the row matrix $(\\alpha,\\beta)$. No rounding is required, and no physical units are involved.", "solution": "The problem requires us to compute the infinitesimal generator $\\mathcal{L}V(x)$ for a given stochastic differential equation (SDE) and a Lyapunov candidate function $V(x)$, and then to determine a pair of optimal constants $(\\alpha, \\beta)$ satisfying a certain inequality.\n\nThe SDE is given in $\\mathbb{R}^{2}$ as:\n$$\n\\mathrm{d}X_{t} = A\\,X_{t}\\,\\mathrm{d}t + \\Sigma\\,\\mathrm{d}W_{t}\n$$\nwhere $X_{t} = \\begin{pmatrix} X_{t,1} \\\\ X_{t,2} \\end{pmatrix}$, $A = -I_{2} = \\begin{pmatrix} -1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, and $\\Sigma = \\mathrm{diag}(1,2) = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}$.\nThe process $W_{t}$ is a $2$-dimensional standard Brownian motion. This SDE is of the general form $\\mathrm{d}X_{t} = b(X_t)\\mathrm{d}t + \\sigma(X_t)\\mathrm{d}W_{t}$, where the drift vector is $b(x) = Ax = -x$ and the diffusion matrix is $\\sigma(x) = \\Sigma$.\n\nThe infinitesimal generator $\\mathcal{L}$ of the process $X_t$, when applied to a twice continuously differentiable function $f:\\mathbb{R}^{2}\\to\\mathbb{R}$, is defined as:\n$$\n\\mathcal{L}f(x) = \\sum_{i=1}^{2} b_i(x) \\frac{\\partial f}{\\partial x_i}(x) + \\frac{1}{2} \\sum_{i,j=1}^{2} (\\sigma(x)\\sigma(x)^T)_{ij} \\frac{\\partial^2 f}{\\partial x_i \\partial x_j}(x)\n$$\nIn our case, $b(x) = (-x_1, -x_2)^T$. The diffusion matrix $\\sigma$ is constant, so we compute the covariance matrix $\\sigma\\sigma^T$:\n$$\n\\Sigma\\Sigma^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix}^T = \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 2 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix}\n$$\nThe Lyapunov candidate function is $V(x) = 1 + |x|^{2} = 1 + x_1^2 + x_2^2$. We need to compute its first and second partial derivatives:\nFirst derivatives:\n$$\n\\frac{\\partial V}{\\partial x_1} = 2x_1, \\quad \\frac{\\partial V}{\\partial x_2} = 2x_2\n$$\nThe gradient is $\\nabla V(x) = (2x_1, 2x_2)^T = 2x$.\nSecond derivatives:\n$$\n\\frac{\\partial^2 V}{\\partial x_1^2} = 2, \\quad \\frac{\\partial^2 V}{\\partial x_2^2} = 2, \\quad \\frac{\\partial^2 V}{\\partial x_1 \\partial x_2} = 0\n$$\n\nNow we compute the two parts of $\\mathcal{L}V(x)$.\nThe drift part is:\n$$\n\\sum_{i=1}^{2} b_i(x) \\frac{\\partial V}{\\partial x_i}(x) = b(x) \\cdot \\nabla V(x) = (-x_1, -x_2) \\cdot (2x_1, 2x_2) = -2x_1^2 - 2x_2^2 = -2|x|^2\n$$\nThe diffusion part is:\n$$\n\\frac{1}{2} \\sum_{i,j=1}^{2} (\\Sigma\\Sigma^T)_{ij} \\frac{\\partial^2 V}{\\partial x_i \\partial x_j}(x)\n= \\frac{1}{2} \\left[ (\\Sigma\\Sigma^T)_{11}\\frac{\\partial^2 V}{\\partial x_1^2} + (\\Sigma\\Sigma^T)_{12}\\frac{\\partial^2 V}{\\partial x_1 \\partial x_2} + (\\Sigma\\Sigma^T)_{21}\\frac{\\partial^2 V}{\\partial x_2 \\partial x_1} + (\\Sigma\\Sigma^T)_{22}\\frac{\\partial^2 V}{\\partial x_2^2} \\right]\n$$\nSubstituting the values:\n$$\n= \\frac{1}{2} \\left[ (1)(2) + (0)(0) + (0)(0) + (4)(2) \\right] = \\frac{1}{2}(2 + 8) = 5\n$$\nCombining both parts, we obtain the expression for the generator applied to $V(x)$:\n$$\n\\mathcal{L}V(x) = -2|x|^2 + 5\n$$\nNext, we need to find the largest $\\alpha > 0$ and the corresponding smallest $\\beta \\ge 0$ that satisfy the inequality for all $x \\in \\mathbb{R}^2$:\n$$\n\\mathcal{L}V(x) \\leq -\\alpha\\,V(x) + \\beta\n$$\nSubstituting the expressions for $\\mathcal{L}V(x)$ and $V(x)$:\n$$\n-2|x|^2 + 5 \\leq -\\alpha(1 + |x|^2) + \\beta\n$$\n$$\n-2|x|^2 + 5 \\leq -\\alpha - \\alpha|x|^2 + \\beta\n$$\nTo analyze this inequality, we rearrange it by grouping terms involving $|x|^2$ and constant terms:\n$$\n\\alpha|x|^2 - 2|x|^2 + 5 + \\alpha - \\beta \\leq 0\n$$\n$$\n(\\alpha - 2)|x|^2 + (5 + \\alpha - \\beta) \\leq 0\n$$\nThis inequality must hold for all $x \\in \\mathbb{R}^2$, which is equivalent to it holding for all possible values of $|x|^2 \\ge 0$. Let $u = |x|^2$. The inequality is:\n$$\n(\\alpha - 2)u + (5 + \\alpha - \\beta) \\leq 0 \\quad \\text{for all } u \\ge 0\n$$\nThis is a linear function of $u$. For this inequality to hold for all $u \\ge 0$, two conditions must be satisfied:\n1. The coefficient of $u$, which is the slope of the function, must be non-positive. If $(\\alpha - 2) > 0$, the left side would become arbitrarily large and positive as $u \\to \\infty$, violating the inequality. Thus, we must have:\n$$\n\\alpha - 2 \\leq 0 \\implies \\alpha \\leq 2\n$$\n2. The value of the linear function at $u=0$ must be non-positive. Since the slope is non-positive, the function's maximum value on the interval $[0, \\infty)$ is attained at $u=0$. Therefore, we need:\n$$\n(\\alpha - 2)(0) + (5 + \\alpha - \\beta) \\leq 0 \\implies 5 + \\alpha - \\beta \\leq 0 \\implies \\beta \\ge 5 + \\alpha\n$$\nThe problem asks for the largest admissible $\\alpha > 0$. From the first condition, the maximum possible value is $\\alpha = 2$. This value satisfies $\\alpha > 0$.\n\nFor this choice of $\\alpha = 2$, we must find the smallest $\\beta$ that makes the inequality valid. From the second condition, we have:\n$$\n\\beta \\ge 5 + \\alpha\n$$\nSubstituting $\\alpha = 2$, we get:\n$$\n\\beta \\ge 5 + 2 \\implies \\beta \\ge 7\n$$\nThe smallest value of $\\beta$ is therefore $7$. This value satisfies the requirement $\\beta \\ge 0$.\nWith $\\alpha = 2$ and $\\beta = 7$, the inequality becomes:\n$$\n(2 - 2)|x|^2 + (5 + 2 - 7) \\leq 0 \\implies 0 \\cdot |x|^2 + 0 \\leq 0 \\implies 0 \\leq 0\n$$\nThis is true for all $x \\in \\mathbb{R}^2$.\nThus, the largest admissible $\\alpha$ is $2$, and for this $\\alpha$, the smallest $\\beta$ is $7$. The requested answer is the row matrix $(\\alpha, \\beta)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 & 7\n\\end{pmatrix}\n}\n$$", "id": "3075105"}, {"introduction": "After establishing stability in a clear-cut case, it is just as important to understand what happens when the conditions for stability are not met. This exercise examines the critical borderline case of an Ornstein-Uhlenbeck process with zero drift, which is mathematically equivalent to a scaled Brownian motion. By analyzing the long-term behavior of its characteristic function and investigating the concept of \"tightness,\" you will discover from first principles why the absence of a restoring drift leads to the failure of stability in distribution [@problem_id:3075108].", "problem": "Consider the one-dimensional Ornstein–Uhlenbeck process, defined as the unique strong solution to the linear stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t \\,=\\, -\\alpha X_t\\,\\mathrm{d}t \\,+\\, \\sigma\\,\\mathrm{d}W_t,\\qquad X_0 \\text{ independent of } W,\n$$\nwhere $\\alpha \\ge 0$ is a constant drift parameter, $\\sigma>0$ is a constant diffusion coefficient, and $W_t$ is a standard Brownian motion. Let $\\varphi_t(u) \\equiv \\mathbb{E}[\\exp(\\mathrm{i}uX_t)]$ denote the characteristic function of $X_t$ for real $u$. Focus on the borderline case $\\alpha=0$. Using only the defining properties of Brownian motion, linear SDEs, and the characteristic function of a Gaussian random variable, derive from first principles whether stability in distribution holds or fails as $t \\to \\infty$. Your reasoning should explicitly address tightness or its failure for the family of laws $\\{\\mathcal{L}(X_t): t \\ge 0\\}$. \n\nProvide your final answer as the closed-form expression of the limit of the characteristic functions $\\lim_{t\\to\\infty}\\varphi_t(u)$ as a function of $u$. No numerical rounding is required. Your final boxed answer must be this limiting function of $u$ alone.", "solution": "We begin with the Ornstein–Uhlenbeck SDE\n$$\n\\mathrm{d}X_t \\,=\\, -\\alpha X_t\\,\\mathrm{d}t \\,+\\, \\sigma\\,\\mathrm{d}W_t,\\qquad X_0 \\text{ independent of } W,\n$$\nand specialize to the borderline case $\\alpha=0$. In that case, the SDE reduces to\n$$\n\\mathrm{d}X_t \\,=\\, \\sigma\\,\\mathrm{d}W_t.\n$$\nBy the fundamental properties of Itô integrals for deterministic integrands and the definition of a strong solution, the unique solution is\n$$\nX_t \\,=\\, X_0 \\,+\\, \\sigma W_t.\n$$\nThus, for each fixed $t \\ge 0$, the conditional distribution of $X_t$ given $X_0$ is Gaussian with mean $X_0$ and variance $\\sigma^2 t$, and unconditionally $X_t$ is a location mixture of Gaussians. We compute the characteristic function $\\varphi_t(u) = \\mathbb{E}[\\exp(\\mathrm{i}u X_t)]$ using independence of $X_0$ and $W$ and the characteristic function of a centered Gaussian $\\mathcal{N}(0,\\sigma^2 t)$:\n$$\n\\varphi_t(u) \\,=\\, \\mathbb{E}\\big[\\exp(\\mathrm{i}u(X_0 + \\sigma W_t))\\big]\n\\,=\\, \\mathbb{E}\\big[\\exp(\\mathrm{i}uX_0)\\,\\mathbb{E}[\\exp(\\mathrm{i}u\\sigma W_t)\\mid X_0]\\big]\n\\,=\\, \\mathbb{E}[\\exp(\\mathrm{i}uX_0)]\\,\\exp\\!\\Big(-\\tfrac{1}{2}\\sigma^2 u^2 t\\Big).\n$$\nLet $\\varphi_{X_0}(u) \\equiv \\mathbb{E}[\\exp(\\mathrm{i}u X_0)]$ denote the characteristic function of $X_0$. Then\n$$\n\\varphi_t(u) \\,=\\, \\varphi_{X_0}(u)\\,\\exp\\!\\Big(-\\tfrac{1}{2}\\sigma^2 u^2 t\\Big).\n$$\nWe now take the limit as $t\\to\\infty$. For any fixed $u \\neq 0$, the exponential factor satisfies\n$$\n\\exp\\!\\Big(-\\tfrac{1}{2}\\sigma^2 u^2 t\\Big)\\,\\longrightarrow\\, 0 \\quad \\text{as } t\\to\\infty,\n$$\nand hence\n$$\n\\lim_{t\\to\\infty}\\varphi_t(u) \\,=\\, 0 \\quad \\text{for all } u \\neq 0.\n$$\nAt $u=0$, for all $t\\ge 0$,\n$$\n\\varphi_t(0) \\,=\\, \\mathbb{E}[\\exp(0)] \\,=\\, 1,\n$$\nso\n$$\n\\lim_{t\\to\\infty}\\varphi_t(0) \\,=\\, 1.\n$$\nTherefore, the pointwise limit of the characteristic functions is the function\n$$\nu \\,\\mapsto\\, \\mathbf{1}_{\\{u=0\\}}.\n$$\nThis function is not continuous at $u=0$ and hence is not a characteristic function of any probability distribution. Consequently, the distributions $\\mathcal{L}(X_t)$ do not converge in distribution as $t\\to\\infty$.\n\nTo connect this to tightness, recall that a sufficient condition for tightness of a family of probability measures on $\\mathbb{R}$ is that for each $\\varepsilon>0$ there exists $R>0$ such that $\\sup_{t\\ge 0}\\mathbb{P}(|X_t|>R)  \\varepsilon$. We show this fails. Since $X_t = X_0 + \\sigma W_t$, its conditional variance given $X_0$ is $\\sigma^2 t$, which grows to infinity. For any fixed $R>0$, the probability that $X_t$ remains in the interval $[-R, R]$ goes to zero as $t \\to \\infty$. Formally:\n$$\n\\mathbb{P}(|X_t|\\le R) \\,=\\, \\mathbb{E}\\Big[\\mathbb{P}\\big(|X_0 + \\sigma W_t| \\le R \\,\\big|\\, X_0\\big)\\Big]\n\\,\\longrightarrow\\, 0 \\quad \\text{as } t\\to\\infty.\n$$\nEquivalently, $\\lim_{t\\to\\infty}\\mathbb{P}(|X_t|R) = 1$ for each fixed $R>0$, so the family $\\{\\mathcal{L}(X_t): t\\ge 0\\}$ is not tight. Lack of tightness rules out convergence in distribution to any probability measure on $\\mathbb{R}$. This confirms that stability in distribution fails for the borderline case $\\alpha=0$.\n\nIn summary, the limiting characteristic function exists pointwise and equals the indicator function at the origin, which is not a characteristic function. Hence stability in distribution fails, and the requested limiting expression is the indicator function $\\mathbf{1}_{\\{u=0\\}}$.", "answer": "$$\\boxed{\\mathbf{1}_{\\{u=0\\}}}$$", "id": "3075108"}, {"introduction": "Our theoretical understanding of stability has direct consequences in the practical world of numerical simulation. This problem challenges you to analyze the popular Euler-Maruyama scheme applied to a stable Ornstein–Uhlenbeck process, demonstrating that the stability of the original SDE does not automatically transfer to its numerical approximation. By deriving a discrete-time drift condition, you will determine the critical step size beyond which the numerical method itself becomes unstable, a crucial insight for any practitioner simulating stochastic systems [@problem_id:3075162].", "problem": "Consider the scalar Ornstein–Uhlenbeck stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_{t} \\;=\\; -\\alpha\\,X_{t}\\,\\mathrm{d}t \\;+\\; \\sigma\\,\\mathrm{d}W_{t},\n$$\nwhere $\\alpha0$, $\\sigma0$, and $W_{t}$ is a standard Brownian motion. It is known that in continuous time this SDE admits a unique stationary distribution and is stable in distribution. Now discretize this SDE by the explicit Euler–Maruyama scheme with fixed step size $\\Delta t0$:\n$$\nX_{n+1} \\;=\\; X_{n} \\;-\\; \\alpha\\,\\Delta t\\,X_{n} \\;+\\; \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_{n},\n$$\nwhere $(\\xi_{n})_{n\\ge 0}$ are independent and identically distributed standard normal random variables with $\\mathbb{E}[\\xi_{n}]=0$ and $\\mathbb{E}[\\xi_{n}^{2}]=1$.\n\nUsing the quadratic Lyapunov function $V(x)=x^{2}$ and the Foster–Lyapunov drift criterion for Markov chains, derive from first principles a one-step drift inequality of the form\n$$\n\\mathbb{E}\\!\\left[V(X_{n+1})\\mid X_{n}=x\\right] - V(x) \\;\\le\\; -\\lambda(\\Delta t)\\,V(x) \\;+\\; \\beta(\\Delta t),\n$$\nwith explicit expressions for $\\lambda(\\Delta t)$ and $\\beta(\\Delta t)$ in terms of $\\alpha$, $\\sigma$, and $\\Delta t$. Then use your inequality to determine the largest step size $\\Delta t_{\\mathrm{max}}(\\alpha)$ such that there exists a positive constant $\\lambda(\\Delta t)0$ making the drift negative for all sufficiently large $|x|$, thereby ensuring stability in distribution of the Euler–Maruyama chain. Your final answer must be the closed-form analytic expression for $\\Delta t_{\\mathrm{max}}(\\alpha)$.\n\nFinally, explain, using the derived expressions, how and why the scheme becomes unstable in distribution when $\\Delta t\\Delta t_{\\mathrm{max}}(\\alpha)$, diagnosing the failure through the sign of the drift bound.\n\nExpress the final answer as an analytic expression. No rounding is required.", "solution": "The problem asks for an analysis of the stability in distribution for the Euler-Maruyama discretization of the scalar Ornstein-Uhlenbeck process. The analysis is to be performed using a quadratic Lyapunov function and the Foster-Lyapunov drift criterion.\n\nThe discrete-time process is given by the stochastic recurrence relation:\n$$\nX_{n+1} \\;=\\; X_{n} \\;-\\; \\alpha\\,\\Delta t\\,X_{n} \\;+\\; \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_{n} \\;=\\; (1 - \\alpha\\,\\Delta t)\\,X_{n} \\;+\\; \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_{n}\n$$\nwhere $\\alpha0$, $\\sigma0$, $\\Delta t0$, and $\\xi_n$ are independent and identically distributed standard normal random variables, i.e., $\\xi_n \\sim \\mathcal{N}(0, 1)$, which implies $\\mathbb{E}[\\xi_n] = 0$ and $\\mathbb{E}[\\xi_n^2] = 1$.\n\nWe are given the quadratic Lyapunov function $V(x) = x^2$. Our first goal is to derive the one-step drift inequality. The one-step drift of the Lyapunov function, conditioned on the current state $X_n=x$, is defined as $\\Delta V(x) = \\mathbb{E}[V(X_{n+1}) \\mid X_n=x] - V(x)$.\n\nLet's compute the conditional expectation $\\mathbb{E}[V(X_{n+1}) \\mid X_n=x] = \\mathbb{E}[X_{n+1}^2 \\mid X_n=x]$.\nSubstituting the expression for $X_{n+1}$ with $X_n=x$:\n$$\n\\mathbb{E}[X_{n+1}^2 \\mid X_n=x] \\;=\\; \\mathbb{E}\\!\\left[\\left( (1 - \\alpha\\,\\Delta t)\\,x + \\sigma\\,\\sqrt{\\Delta t}\\,\\xi_n \\right)^2\\right]\n$$\nExpanding the square inside the expectation gives:\n$$\n\\mathbb{E}\\!\\left[ (1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; 2\\,(1 - \\alpha\\,\\Delta t)\\,x\\,\\sigma\\,\\sqrt{\\Delta t}\\,\\xi_n \\;+\\; (\\sigma\\,\\sqrt{\\Delta t}\\,\\xi_n)^2 \\right]\n$$\nBy the linearity of expectation, we can write:\n$$\n(1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; 2\\,(1 - \\alpha\\,\\Delta t)\\,x\\,\\sigma\\,\\sqrt{\\Delta t}\\,\\mathbb{E}[\\xi_n] \\;+\\; \\sigma^2\\,\\Delta t\\,\\mathbb{E}[\\xi_n^2]\n$$\nUsing the properties of the standard normal random variable $\\xi_n$, where $\\mathbb{E}[\\xi_n]=0$ and $\\mathbb{E}[\\xi_n^2]=1$, the expression simplifies to:\n$$\n(1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; 2\\,(1 - \\alpha\\,\\Delta t)\\,x\\,\\sigma\\,\\sqrt{\\Delta t}\\,(0) \\;+\\; \\sigma^2\\,\\Delta t\\,(1)\n$$\n$$\n\\mathbb{E}[X_{n+1}^2 \\mid X_n=x] \\;=\\; (1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\nNow, we compute the drift $\\Delta V(x)$:\n$$\n\\Delta V(x) \\;=\\; \\mathbb{E}[X_{n+1}^2 \\mid X_n=x] - x^2 \\;=\\; \\left[ (1 - \\alpha\\,\\Delta t)^2\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t \\right] - x^2\n$$\nGrouping the terms with $x^2$:\n$$\n\\Delta V(x) \\;=\\; \\left( (1 - \\alpha\\,\\Delta t)^2 - 1 \\right)\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\nExpanding the squared term $(1 - \\alpha\\,\\Delta t)^2 = 1 - 2\\alpha\\,\\Delta t + (\\alpha\\,\\Delta t)^2$:\n$$\n\\Delta V(x) \\;=\\; \\left( 1 - 2\\alpha\\,\\Delta t + \\alpha^2\\,(\\Delta t)^2 - 1 \\right)\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\n$$\n\\Delta V(x) \\;=\\; \\left( \\alpha^2\\,(\\Delta t)^2 - 2\\alpha\\,\\Delta t \\right)\\,x^2 \\;+\\; \\sigma^2\\,\\Delta t\n$$\nThis expression is the exact one-step drift. We need to match it to the form $\\Delta V(x) \\le -\\lambda(\\Delta t)\\,V(x) + \\beta(\\Delta t)$, where $V(x)=x^2$. Since we have an exact equality, it satisfies the inequality trivially.\nBy comparing our derived expression for the drift with the target form:\n$$\n\\left( \\alpha^2\\,(\\Delta t)^2 - 2\\alpha\\,\\Delta t \\right)\\,V(x) \\;+\\; \\sigma^2\\,\\Delta t \\;=\\; -\\lambda(\\Delta t)\\,V(x) \\;+\\; \\beta(\\Delta t)\n$$\nWe can identify the functions $\\lambda(\\Delta t)$ and $\\beta(\\Delta t)$ by equating the coefficients of $V(x)$ and the constant terms:\n$$\n-\\lambda(\\Delta t) \\;=\\; \\alpha^2\\,(\\Delta t)^2 - 2\\alpha\\,\\Delta t \\quad \\implies \\quad \\lambda(\\Delta t) \\;=\\; 2\\alpha\\,\\Delta t - \\alpha^2\\,(\\Delta t)^2\n$$\n$$\n\\beta(\\Delta t) \\;=\\; \\sigma^2\\,\\Delta t\n$$\nThis completes the first part of the problem.\n\nThe second part is to determine the largest step size $\\Delta t_{\\mathrm{max}}(\\alpha)$ that ensures stability in distribution. The Foster-Lyapunov drift criterion for the existence of a stationary distribution (and ergodicity) requires that the drift is negative for all states $x$ outside some compact set. That is, for sufficiently large $|x|$, we must have $\\Delta V(x)  0$. This is guaranteed if the coefficient of $V(x)$ is strictly negative. In our notation, this corresponds to requiring $\\lambda(\\Delta t)  0$.\nSo, the condition for numerical stability in distribution is:\n$$\n\\lambda(\\Delta t) \\;\\; 0\n$$\nSubstituting our expression for $\\lambda(\\Delta t)$:\n$$\n2\\alpha\\,\\Delta t - \\alpha^2\\,(\\Delta t)^2 \\;\\; 0\n$$\nWe can factor out $\\alpha\\,\\Delta t$. Since both $\\alpha  0$ and $\\Delta t  0$, the term $\\alpha\\,\\Delta t$ is strictly positive, so we can divide the inequality by it without changing the direction:\n$$\n\\alpha\\,\\Delta t \\,(2 - \\alpha\\,\\Delta t) \\;\\; 0 \\quad \\implies \\quad 2 - \\alpha\\,\\Delta t \\;\\; 0\n$$\nThis inequality can be solved for $\\Delta t$:\n$$\n2 \\;\\; \\alpha\\,\\Delta t \\quad \\implies \\quad \\Delta t \\;\\; \\frac{2}{\\alpha}\n$$\nThe scheme is stable in distribution for any step size $\\Delta t$ in the interval $(0, 2/\\alpha)$. The problem asks for the largest step size $\\Delta t_{\\mathrm{max}}(\\alpha)$ such that $\\lambda(\\Delta t)  0$. This corresponds to the supremum of the set of allowed step sizes.\nTherefore, the maximum step size is:\n$$\n\\Delta t_{\\mathrm{max}}(\\alpha) \\;=\\; \\frac{2}{\\alpha}\n$$\n\nFinally, we explain the instability when $\\Delta t  \\Delta t_{\\mathrm{max}}(\\alpha)$.\nIf we choose a step size $\\Delta t  \\frac{2}{\\alpha}$, then it follows that $\\alpha\\,\\Delta t  2$, or $2-\\alpha\\,\\Delta t  0$.\nLet us examine the drift coefficient $-\\lambda(\\Delta t) = \\alpha^2 (\\Delta t)^2 - 2\\alpha \\Delta t$:\n$$\n-\\lambda(\\Delta t) \\;=\\; \\alpha\\,\\Delta t\\,(\\alpha\\,\\Delta t - 2)\n$$\nSince $\\alpha\\,\\Delta t  2$, the term $(\\alpha\\,\\Delta t - 2)$ is positive. As $\\alpha\\,\\Delta t$ is also positive, the entire coefficient $-\\lambda(\\Delta t)$ is positive.\nThe drift is then:\n$$\n\\Delta V(x) \\;=\\; -\\lambda(\\Delta t)\\,V(x) + \\beta(\\Delta t) \\;=\\; (\\text{positive coefficient}) \\cdot x^2 + (\\text{positive constant})\n$$\nSince $-\\lambda(\\Delta t)  0$ and $\\beta(\\Delta t) = \\sigma^2 \\Delta t  0$, the drift $\\Delta V(x)$ is strictly positive for all $x$. Furthermore, as $|x| \\to \\infty$, the drift grows quadratically, $\\Delta V(x) \\to +\\infty$.\nThis means that, on average, the squared value of the process, $V(X_{n+1})$, is always greater than its current value, $V(X_n)$. Instead of being pulled back towards the origin (which is what a negative drift for large $|x|$ accomplishes), the process is actively pushed away from the origin at every step, regardless of its current state. The variance of the process, $\\mathbb{E}[X_n^2]$, will grow without bound as $n \\to \\infty$. This explosive behavior demonstrates that the discrete Markov chain does not possess a stationary distribution and is therefore unstable in distribution.\nAt the critical boundary, $\\Delta t = \\Delta t_{\\mathrm{max}}(\\alpha) = 2/\\alpha$, we have $\\lambda(\\Delta t)=0$, and the drift becomes $\\Delta V(x) = \\beta(\\Delta t) = \\sigma^2 (2/\\alpha)  0$. The expected variance increases by a constant amount at each step, $\\mathbb{E}[X_{n+1}^2] = \\mathbb{E}[X_n^2] + 2\\sigma^2/\\alpha$, leading to linear growth in variance, which is also an unstable regime.", "answer": "$$\n\\boxed{\\frac{2}{\\alpha}}\n$$", "id": "3075162"}]}