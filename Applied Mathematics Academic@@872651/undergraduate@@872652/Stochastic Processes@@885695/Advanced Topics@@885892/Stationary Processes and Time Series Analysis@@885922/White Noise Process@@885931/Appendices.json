{"hands_on_practices": [{"introduction": "A great way to understand the fundamental nature of a mathematical or statistical object is to see how it behaves under simple operations. This first practice does just that by exploring whether the white noise property is preserved under addition. By analyzing the sum of two independent white noise processes [@problem_id:1349983], you will directly apply the three core conditions—zero mean, constant variance, and zero autocovariance—to solidify your understanding of the definition of a white noise process.", "problem": "In the analysis of stochastic processes, a discrete-time white noise process is defined as a sequence of random variables $\\{X_t\\}$ indexed by integers $t$, which satisfies the following three conditions:\n1.  The mean is zero for all time: $\\mathbb{E}[X_t] = 0$.\n2.  The variance is a finite constant for all time: $\\operatorname{Var}(X_t) = \\sigma_X^2$.\n3.  The autocovariance is zero for any two different points in time: $\\operatorname{Cov}(X_s, X_t) = 0$ for all $s \\neq t$.\n\nConsider two independent discrete-time white noise processes, $\\{W_t\\}$ and $\\{V_t\\}$, with constant variances $\\sigma_W^2$ and $\\sigma_V^2$, respectively. A new process, $\\{Z_t\\}$, is formed by their sum, such that $Z_t = W_t + V_t$ for all integers $t$.\n\nWhich of the following statements correctly describes the process $\\{Z_t\\}$?\n\nA. $\\{Z_t\\}$ is a white noise process with variance $\\sigma_W^2 + \\sigma_V^2$.\n\nB. $\\{Z_t\\}$ is a white noise process with variance $(\\sigma_W + \\sigma_V)^2$.\n\nC. $\\{Z_t\\}$ is a white noise process with variance $\\sqrt{\\sigma_W^4 + \\sigma_V^4}$.\n\nD. $\\{Z_t\\}$ is not a white noise process because its mean is not guaranteed to be zero.\n\nE. $\\{Z_t\\}$ is not a white noise process because it has non-zero autocovariance for $s \\neq t$.", "solution": "We are given two independent discrete-time white noise processes $\\{W_{t}\\}$ and $\\{V_{t}\\}$ with $\\mathbb{E}[W_{t}]=0$, $\\operatorname{Var}(W_{t})=\\sigma_{W}^{2}$, $\\operatorname{Cov}(W_{s},W_{t})=0$ for $s\\neq t$, and similarly for $\\{V_{t}\\}$ with variance $\\sigma_{V}^{2}$. Define $Z_{t}=W_{t}+V_{t}$.\n\nMean: By linearity of expectation,\n$$\n\\mathbb{E}[Z_{t}]=\\mathbb{E}[W_{t}+V_{t}]=\\mathbb{E}[W_{t}]+\\mathbb{E}[V_{t}]=0+0=0 \\quad \\text{for all } t.\n$$\n\nVariance: Using $\\operatorname{Var}(X+Y)=\\operatorname{Var}(X)+\\operatorname{Var}(Y)+2\\,\\operatorname{Cov}(X,Y)$ and independence of $W_{t}$ and $V_{t}$ for each fixed $t$ (hence $\\operatorname{Cov}(W_{t},V_{t})=0$),\n$$\n\\operatorname{Var}(Z_{t})=\\operatorname{Var}(W_{t})+\\operatorname{Var}(V_{t})=\\sigma_{W}^{2}+\\sigma_{V}^{2} \\quad \\text{for all } t.\n$$\n\nAutocovariance for $s\\neq t$: Using bilinearity of covariance,\n$$\n\\operatorname{Cov}(Z_{s},Z_{t})=\\operatorname{Cov}(W_{s}+V_{s},\\,W_{t}+V_{t})\n=\\operatorname{Cov}(W_{s},W_{t})+\\operatorname{Cov}(W_{s},V_{t})+\\operatorname{Cov}(V_{s},W_{t})+\\operatorname{Cov}(V_{s},V_{t}).\n$$\nFor white noise, $\\operatorname{Cov}(W_{s},W_{t})=0$ and $\\operatorname{Cov}(V_{s},V_{t})=0$ when $s\\neq t$. Because the processes are independent, $W_{s}$ and $V_{t}$ are independent for all $s,t$, hence $\\operatorname{Cov}(W_{s},V_{t})=0$ and $\\operatorname{Cov}(V_{s},W_{t})=0$. Therefore,\n$$\n\\operatorname{Cov}(Z_{s},Z_{t})=0 \\quad \\text{for } s\\neq t.\n$$\n\nThus $\\{Z_{t}\\}$ satisfies the defining properties of a discrete-time white noise process with constant variance $\\sigma_{W}^{2}+\\sigma_{V}^{2}$. Among the options, this is exactly statement A.", "answer": "$$\\boxed{A}$$", "id": "1349983"}, {"introduction": "Having established the basic properties, we now move to a practical application common in signal processing and finance. A moving average is a fundamental tool used to smooth out random fluctuations by averaging recent data points. This exercise [@problem_id:1350043] investigates how this common linear filter transforms a white noise input, focusing on how the variance is reduced, which is a key step toward understanding how more complex models are built from white noise.", "problem": "In digital signal processing, a common technique to reduce noise is to apply a smoothing filter. Consider a discrete-time signal that can be modeled as a standard white noise process, denoted by $\\{W_t\\}$, where $t$ is an integer representing time steps. This process has the following properties:\n1.  The expected value is zero for all time steps: $\\mathbb{E}[W_t] = 0$.\n2.  The variance is constant and equal to one for all time steps: $\\operatorname{Var}(W_t) = 1$.\n3.  The values of the process at different time steps are uncorrelated: $\\operatorname{Cov}(W_t, W_s) = 0$ for $t \\neq s$.\n\nA new process, $\\{Y_t\\}$, is generated by applying a three-point simple moving average filter to $\\{W_t\\}$. The value of the new process at time $t$ is given by the expression:\n$$\nY_t = \\frac{1}{3}(W_t + W_{t-1} + W_{t-2})\n$$\nCalculate the variance of the process $Y_t$, denoted as $\\operatorname{Var}(Y_t)$. Express your answer as a fraction in simplest form.", "solution": "We use linearity and variance properties. Define $S_{t}=W_{t}+W_{t-1}+W_{t-2}$. Then\n$$\nY_{t}=\\frac{1}{3}S_{t},\n$$\nso by the scaling property of variance, $\\operatorname{Var}(aX)=a^{2}\\operatorname{Var}(X)$,\n$$\n\\operatorname{Var}(Y_{t})=\\left(\\frac{1}{3}\\right)^{2}\\operatorname{Var}(S_{t})=\\frac{1}{9}\\operatorname{Var}(W_{t}+W_{t-1}+W_{t-2}).\n$$\nUsing $\\operatorname{Var}\\left(\\sum_{i}X_{i}\\right)=\\sum_{i}\\operatorname{Var}(X_{i})+2\\sum_{i<j}\\operatorname{Cov}(X_{i},X_{j})$,\n$$\n\\operatorname{Var}(W_{t}+W_{t-1}+W_{t-2})=\\operatorname{Var}(W_{t})+\\operatorname{Var}(W_{t-1})+\\operatorname{Var}(W_{t-2})+2\\big(\\operatorname{Cov}(W_{t},W_{t-1})+\\operatorname{Cov}(W_{t},W_{t-2})+\\operatorname{Cov}(W_{t-1},W_{t-2})\\big).\n$$\nGiven $\\operatorname{Var}(W_{s})=1$ for all $s$ and $\\operatorname{Cov}(W_{s},W_{r})=0$ for $s\\neq r$, we obtain\n$$\n\\operatorname{Var}(S_{t})=1+1+1=3.\n$$\nTherefore,\n$$\n\\operatorname{Var}(Y_{t})=\\frac{1}{9}\\cdot 3=\\frac{1}{3}.\n$$", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1350043"}, {"introduction": "Our first two practices involved linear operations, but many real-world phenomena involve non-linear dynamics. This final practice explores what happens when we apply a simple non-linear function—squaring—to a Gaussian white noise process. By investigating the properties of the resulting process $Y_t = W_t^2$ [@problem_id:1350050], you will discover that the white noise property is not always preserved, an insight that is crucial for understanding more advanced concepts like volatility modeling in finance.", "problem": "In signal processing and time series analysis, a fundamental concept is that of a white noise process, which serves as a building block for more complex models. Let $\\{W_t\\}_{t \\in \\mathbb{Z}}$ be a discrete-time Gaussian white noise process. This means that for each integer time index $t$, the random variable $W_t$ is drawn from a normal (Gaussian) distribution with a mean of 0 and a variance of $\\sigma^2$. Furthermore, the random variables $\\{W_t\\}$ are independent and identically distributed for all $t$.\n\nNow, consider a new stochastic process $\\{Y_t\\}_{t \\in \\mathbb{Z}}$ which is derived by squaring the values of the original white noise process. That is, for each time $t$, the new random variable is defined as $Y_t = W_t^2$.\n\nYour task is to determine the variance of this new process, denoted as $\\operatorname{Var}(Y_t)$. Express your final answer as a symbolic expression in terms of the parameter $\\sigma$.", "solution": "Let $W_{t} \\sim \\mathcal{N}(0,\\sigma^{2})$ and define $Y_{t} = W_{t}^{2}$. We want $\\operatorname{Var}(Y_{t})$.\n\nBy the definition of variance,\n$$\n\\operatorname{Var}(Y_{t}) = \\mathbb{E}[Y_{t}^{2}] - \\left(\\mathbb{E}[Y_{t}]\\right)^{2} = \\mathbb{E}[W_{t}^{4}] - \\left(\\mathbb{E}[W_{t}^{2}]\\right)^{2}.\n$$\nSince $W_{t}$ is zero-mean Gaussian with variance $\\sigma^{2}$, we have\n$$\n\\mathbb{E}[W_{t}^{2}] = \\sigma^{2}.\n$$\nFor the fourth moment of a zero-mean Gaussian, using Isserlis’ (Wick’s) theorem or the standard central moment of a normal variable, \n$$\n\\mathbb{E}[W_{t}^{4}] = 3\\left(\\mathbb{E}[W_{t}^{2}]\\right)^{2} = 3\\sigma^{4}.\n$$\nSubstituting into the variance expression,\n$$\n\\operatorname{Var}(Y_{t}) = 3\\sigma^{4} - (\\sigma^{2})^{2} = 3\\sigma^{4} - \\sigma^{4} = 2\\sigma^{4}.\n$$\nTherefore, the variance of $Y_{t}$ is $2\\sigma^{4}$.", "answer": "$$\\boxed{2\\sigma^{4}}$$", "id": "1350050"}]}