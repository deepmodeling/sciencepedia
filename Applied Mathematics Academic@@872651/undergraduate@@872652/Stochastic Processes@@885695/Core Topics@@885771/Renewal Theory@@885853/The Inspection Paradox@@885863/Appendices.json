{"hands_on_practices": [{"introduction": "We begin with the classic scenario that gives the inspection paradox its fame: waiting for a bus. This problem challenges our intuition by asking for the expected waiting time when arrivals follow a Poisson process. By working through this exercise [@problem_id:1293652], you will uncover the surprising role of the memoryless property and see why a random arrival doesn't land you in the middle of a typical interval.", "problem": "A city's public transit authority is testing a new dynamic dispatch system where buses are sent from the depot based on real-time passenger flow data, rather than adhering to a fixed schedule. Over a long period, observations at a particular downtown bus stop show that bus arrivals can be accurately modeled as a Poisson process. The average rate of arrivals at this stop is 6 buses per hour.\n\nA commuter, who is unaware of this new system, arrives at the stop at a random moment in time. What is this commuter's expected waiting time for the next bus to arrive?\n\nExpress your final answer in minutes.", "solution": "Let the arrival of buses at the stop be described by a Poisson process with a rate parameter $\\lambda$. The problem states that the average rate of arrivals is 6 buses per hour.\n\nFirst, we convert the rate $\\lambda$ into units consistent with the desired answer format (minutes).\n$$\n\\lambda = \\frac{6 \\text{ buses}}{1 \\text{ hour}} = \\frac{6 \\text{ buses}}{60 \\text{ minutes}} = \\frac{1}{10} \\text{ buses per minute}\n$$\n\nA defining characteristic of a Poisson process is that the time intervals between consecutive events are independent and identically distributed (i.i.d.) random variables following an exponential distribution with the same rate parameter $\\lambda$. Let $T$ represent the time between two consecutive bus arrivals. The probability density function (PDF) of $T$ is given by:\n$$\nf_T(t) = \\lambda \\exp(-\\lambda t), \\quad \\text{for } t \\ge 0\n$$\nThe expected value of this exponential distribution, which represents the average time between bus arrivals, is:\n$$\nE[T] = \\frac{1}{\\lambda}\n$$\nPlugging in our value for $\\lambda$:\n$$\nE[T] = \\frac{1}{1/10 \\text{ min}^{-1}} = 10 \\text{ minutes}\n$$\n\nThe question asks for the expected waiting time for a commuter who arrives at a random time. Let's call this waiting time $W$. A crucial property of the exponential distribution (and therefore of the inter-arrival times of a Poisson process) is the memoryless property. This property states that the probability of waiting an additional amount of time is independent of how long one has already waited. Formally, for an exponentially distributed random variable $T$, the property is expressed as $P(T > t + s | T > s) = P(T > t)$ for any non-negative $t$ and $s$.\n\nWhen the commuter arrives at a random time, they arrive at some point within an inter-arrival interval. Let's say the last bus arrived at time $t_{last}$ and the next bus is due at time $t_{next}$. The commuter arrives at time $t_{arrival}$ where $t_{last} < t_{arrival} < t_{next}$. The time that has already passed since the last bus, $t_{arrival} - t_{last}$, does not influence the remaining waiting time, $W = t_{next} - t_{arrival}$, due to the memoryless property.\n\nTherefore, the distribution of the remaining waiting time $W$ is identical to the original distribution of the inter-arrival time $T$. Consequently, their expected values are the same.\n$$\nE[W] = E[T]\n$$\nThis leads to the conclusion that the commuter's expected waiting time is equal to the average time between buses.\n$$\nE[W] = 10 \\text{ minutes}\n$$\nThis result is often referred to as the \"waiting time paradox\" or \"inspection paradox.\" While one might intuitively guess the answer is half the average interval (5 minutes), the fact that a random arrival is more likely to occur within a longer-than-average interval skews the result. For the specific case of a Poisson process, this effect exactly cancels the \"averaging-over-the-interval\" intuition, making the expected wait equal to the full average inter-arrival time.", "answer": "$$\\boxed{10}$$", "id": "1293652"}, {"introduction": "Is the inspection paradox just a strange feature of Poisson processes? This exercise [@problem_id:832996] demonstrates that the answer is no by exploring a bus service with non-exponential inter-arrival times. You will apply the principles of renewal theory to see how length-biased sampling creates the paradox in a more general setting, proving it's a fundamental statistical phenomenon.", "problem": "Consider a bus service where the time intervals between consecutive bus arrivals, known as inter-arrival times, are independent and identically distributed random variables. These inter-arrival times, denoted by $X$, are drawn from a discrete distribution. Specifically, an inter-arrival time can take one of two deterministic values, $T_1$ or $T_2$, with equal probability:\n$$\nP(X = T_1) = \\frac{1}{2}, \\quad P(X = T_2) = \\frac{1}{2}\n$$\nwhere $T_1 > 0$ and $T_2 > 0$ are distinct time durations ($T_1 \\neq T_2$). This describes a renewal process for the bus arrivals.\n\nAn observer arrives at the bus stop at a random time $t$, which is assumed to be very large ($t \\to \\infty$), implying the system is in steady state. The observer's arrival time is independent of the bus arrival schedule. This scenario is a classic example of the \"inspection paradox,\" where the observer is more likely to arrive during a longer-than-average interval.\n\nDerive the expected waiting time for the next bus, from the perspective of the observer. Express your answer as a closed-form analytic expression in terms of $T_1$ and $T_2$.", "solution": "First, we calculate the moments of the inter-arrival time distribution $X$. The mean (first moment) of the inter-arrival time is:\n$$\nE[X] = \\frac{1}{2} T_1 + \\frac{1}{2} T_2 = \\frac{T_1 + T_2}{2}\n$$\nThe second moment of the inter-arrival time is:\n$$\nE[X^2] = \\frac{1}{2} T_1^2 + \\frac{1}{2} T_2^2 = \\frac{T_1^2 + T_2^2}{2}\n$$\nFor a general renewal process in steady state, the expected waiting time for the next event (the mean residual life), $E[R]$, is given by the formula from renewal theory:\n$$\nE[R] = \\frac{E[X^2]}{2E[X]}\n$$\nSubstituting the expressions for the first and second moments we derived:\n$$\nE[R] = \\frac{\\frac{T_1^2+T_2^2}{2}}{2\\left(\\frac{T_1+T_2}{2}\\right)} = \\frac{T_1^2+T_2^2}{2\\,(T_1+T_2)}\n$$", "answer": "$$\\boxed{\\frac{T_1^2+T_2^2}{2\\,(T_1+T_2)}}$$", "id": "832996"}, {"introduction": "Having established that an observer is more likely to sample a longer interval, we can ask: exactly how much longer and more variable are these intervals? This final practice [@problem_id:1339061] returns to the Poisson process but pushes beyond the expected value to have you calculate the variance of the observed interval. This will provide a quantitative measure of the inspection paradox's strength and solidify your understanding of how the observed distribution is skewed.", "problem": "A physicist is studying high-energy cosmic rays using a specialized particle detector. The arrival times of cosmic ray events at the detector are well-modeled by a Poisson process. The long-term average of the time interval between any two consecutive detections has been measured to be a constant value $\\tau$.\n\nTo perform a spot check, the physicist picks a random moment in time, say $t_{obs}$, and measures the length of the particular time interval that contains $t_{obs}$. This is the interval between the last detection before $t_{obs}$ and the first detection after $t_{obs}$. Let the random variable representing the length of this observed interval be denoted by $L$.\n\nAssuming the system has been running for a very long time before the observation is made, determine the variance of the observed interval length, $\\text{Var}(L)$. Express your answer as a closed-form analytic expression in terms of $\\tau$.", "solution": "Let the Poisson process have rate $\\lambda$, so the inter-arrival times are independent and identically distributed exponential random variables with mean $1/\\lambda$. The problem states that the long-term average inter-arrival time is $\\tau$, hence\n$$\n\\lambda=\\frac{1}{\\tau}.\n$$\n\nBy stationarity (the system has been running a long time), we can take the observation time as $t_{obs}=0$ without loss of generality. Let $S$ denote the backward recurrence time (time since the last detection before $0$) and $T$ the forward recurrence time (time until the next detection after $0$). The observed interval length is\n$$\nL=S+T.\n$$\n\nFor a Poisson process, disjoint increments are independent. Therefore, the events in $(-s,0]$ and $(0,t]$ are independent. For $s,t \\geq 0$,\n$$\n\\mathbb{P}(S>s,\\,T>t)=\\mathbb{P}(\\text{no events in }(-s,0])\\,\\mathbb{P}(\\text{no events in }(0,t])=\\exp(-\\lambda s)\\exp(-\\lambda t)=\\exp(-\\lambda(s+t)).\n$$\nFrom this, the marginals are\n$$\n\\mathbb{P}(S>s)=\\exp(-\\lambda s),\\qquad \\mathbb{P}(T>t)=\\exp(-\\lambda t),\n$$\nso $S$ and $T$ are independent and each is exponential with rate $\\lambda$.\n\nHence $L=S+T$ is the sum of two independent $\\operatorname{Exp}(\\lambda)$ random variables, i.e., $L$ has a gamma (Erlang) distribution with shape parameter $2$ and rate $\\lambda$. Using independence,\n$$\n\\operatorname{Var}(L)=\\operatorname{Var}(S)+\\operatorname{Var}(T)=\\frac{1}{\\lambda^{2}}+\\frac{1}{\\lambda^{2}}=\\frac{2}{\\lambda^{2}}.\n$$\nSubstituting $\\lambda=1/\\tau$ gives\n$$\n\\operatorname{Var}(L)=2\\tau^{2}.\n$$", "answer": "$$\\boxed{2\\tau^{2}}$$", "id": "1339061"}]}