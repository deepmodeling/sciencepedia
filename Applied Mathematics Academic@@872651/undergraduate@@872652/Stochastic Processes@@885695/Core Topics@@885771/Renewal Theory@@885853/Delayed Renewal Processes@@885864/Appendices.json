{"hands_on_practices": [{"introduction": "Delayed renewal processes are ideal for modeling systems where the initial event differs from all subsequent ones. This first practice presents a classic example, analyzing visitor traffic on a new website, where initial curiosity might differ from sustained engagement [@problem_id:1296680]. By working through this problem, you will learn to calculate the expected number of events over time, $E[N(t)]$, using the fundamental and intuitive method of conditioning on the first arrival.", "problem": "A new e-commerce website goes live. The user traffic on a typical day is modeled as a stochastic process. The time until the first visitor arrives, denoted by $Y_1$, follows an exponential distribution with a rate parameter $\\lambda_1$. After the first visitor, the time intervals between each subsequent pair of consecutive visitors, denoted by $Y_k$ for $k \\ge 2$, are independent and identically distributed, each following an exponential distribution with a rate parameter $\\lambda_2$. The two rates, $\\lambda_1$ and $\\lambda_2$, are not necessarily equal, reflecting a potential difference between initial curiosity and sustained user engagement.\n\nLet $N(t)$ be the total number of visitors that have arrived at the website by time $t \\ge 0$, measured from the moment the site goes live. Determine the expected number of visitors by time $t$, denoted by $m(t) = E[N(t)]$. Express your answer as a single closed-form analytic expression in terms of $t$, $\\lambda_1$, and $\\lambda_2$. Assume $\\lambda_1  0$ and $\\lambda_2  0$.", "solution": "Let the interarrival times be $Y_{1} \\sim \\text{Exp}(\\lambda_{1})$ and, for $k \\geq 2$, $Y_{k} \\sim \\text{Exp}(\\lambda_{2})$ i.i.d., independent of $Y_{1}$. Denote by $S_{1}=Y_{1}$ the time of the first arrival. For $t \\geq 0$, the counting process satisfies\n$$\nN(t)=\\begin{cases}\n0,  \\text{if } Y_{1}>t,\\\\\n1+M(t-Y_{1}),  \\text{if } Y_{1} \\leq t,\n\\end{cases}\n$$\nwhere $M(u)$ is the number of subsequent arrivals in an interval of length $u$ with i.i.d. exponential interarrivals of rate $\\lambda_{2}$. This is a homogeneous Poisson process of rate $\\lambda_{2}$ after the first arrival, hence $E[M(u)]=\\lambda_{2} u$. Using the law of total expectation,\n$$\nm(t)=E[N(t)]=E\\big[E[N(t)\\mid Y_{1}]\\big]=E\\big[\\mathbf{1}_{\\{Y_{1} \\leq t\\}}\\big(1+\\lambda_{2}(t-Y_{1})\\big)\\big].\n$$\nTherefore,\n$$\nm(t)=P(Y_{1} \\leq t)+\\lambda_{2} E\\big[(t-Y_{1})\\mathbf{1}_{\\{Y_{1} \\leq t\\}}\\big].\n$$\nSince $Y_{1} \\sim \\text{Exp}(\\lambda_{1})$, we have $P(Y_{1} \\leq t)=1-\\exp(-\\lambda_{1} t)$. For the second term,\n$$\nE\\big[(t-Y_{1})\\mathbf{1}_{\\{Y_{1} \\leq t\\}}\\big]=\\int_{0}^{t} (t-y)\\lambda_{1}\\exp(-\\lambda_{1} y)\\,dy.\n$$\nCompute the integral by separating terms:\n$$\n\\int_{0}^{t} (t-y)\\lambda_{1}\\exp(-\\lambda_{1} y)\\,dy\n=\\lambda_{1}\\left[t\\int_{0}^{t}\\exp(-\\lambda_{1} y)\\,dy-\\int_{0}^{t} y\\exp(-\\lambda_{1} y)\\,dy\\right].\n$$\nWe have\n$$\n\\int_{0}^{t}\\exp(-\\lambda_{1} y)\\,dy=\\frac{1-\\exp(-\\lambda_{1} t)}{\\lambda_{1}},\n$$\nand, by integration by parts,\n$$\n\\int_{0}^{t} y\\exp(-\\lambda_{1} y)\\,dy=-\\frac{t}{\\lambda_{1}}\\exp(-\\lambda_{1} t)+\\frac{1}{\\lambda_{1}^{2}}\\big(1-\\exp(-\\lambda_{1} t)\\big).\n$$\nSubstituting gives\n$$\n\\int_{0}^{t} (t-y)\\lambda_{1}\\exp(-\\lambda_{1} y)\\,dy\n=\\lambda_{1}\\left[\\frac{t}{\\lambda_{1}}-\\frac{1}{\\lambda_{1}^{2}}\\big(1-\\exp(-\\lambda_{1} t)\\big)\\right]\n=t-\\frac{1-\\exp(-\\lambda_{1} t)}{\\lambda_{1}}.\n$$\nHence,\n$$\nm(t)=\\big(1-\\exp(-\\lambda_{1} t)\\big)+\\lambda_{2}\\left[t-\\frac{1-\\exp(-\\lambda_{1} t)}{\\lambda_{1}}\\right].\n$$\nSimplifying,\n$$\nm(t)=\\lambda_{2} t+\\left(1-\\frac{\\lambda_{2}}{\\lambda_{1}}\\right)\\big(1-\\exp(-\\lambda_{1} t)\\big).\n$$\nThis expression satisfies $m(0)=0$ and reduces to $m(t)=\\lambda t$ when $\\lambda_{1}=\\lambda_{2}=\\lambda$, as expected for a standard Poisson process.", "answer": "$$\\boxed{\\lambda_{2} t+\\left(1-\\frac{\\lambda_{2}}{\\lambda_{1}}\\right)\\left(1-\\exp(-\\lambda_{1} t)\\right)}$$", "id": "1296680"}, {"introduction": "Real-world systems can have start-up phases that are more complex than a single, simple delay. This problem models a futuristic manufacturing process with a multi-stage initiation phase, showing how to characterize a delay period that is itself a stochastic process [@problem_id:1296691]. This exercise is an excellent opportunity to apply the powerful Laplace transform technique, a cornerstone for efficiently solving many renewal theory problems.", "problem": "A futuristic manufacturing system relies on self-replicating nanofactories. The process begins at time $t=0$ with a single \"seed\" nanofactory. This seed factory does not produce a new factory directly but instead makes a series of \"initiation attempts\" to establish the first operational \"daughter\" factory.\n\nThe duration of each initiation attempt is a random variable drawn from an exponential distribution with a mean of $1/\\lambda$. Each attempt has an independent probability $p$ of being successful. If an attempt fails (with probability $1-p$), the seed factory immediately begins a new attempt, with the duration of the new attempt again drawn from the same exponential distribution. This continues until the first successful attempt, at which point the first daughter factory is completed. Let this completion time be $Y_1$.\n\nUpon its completion, the first daughter factory is a \"standard\" factory. It immediately begins to build the second daughter factory. The time required for a standard factory to build a new one is also a random variable drawn from an exponential distribution with mean $1/\\lambda$. When the second factory is completed at time $Y_1 + Y_2$, it, in turn, begins building the third, and so on. All subsequent factory build times, $Y_k$ for $k \\ge 2$, are independent and identically distributed draws from this same exponential distribution.\n\nThe completion of a new daughter factory is considered a \"renewal\" event. Given this model, derive an analytic expression for the expected total number of daughter factories completed in the time interval $[0, t]$, for $t \\ge 0$. Your answer should be a closed-form analytic expression in terms of the time $t$, the rate parameter $\\lambda$, and the success probability $p$.", "solution": "Let the factory completion times be the events of a renewal process. The inter-arrival times are the random variables $Y_1, Y_2, Y_3, \\dots$. This is a delayed renewal process because the distribution of the first inter-arrival time, $Y_1$, is different from the subsequent ones, $Y_k$ for $k \\ge 2$. The quantity we need to find is the renewal function, $m(t) = E[N(t)]$, where $N(t)$ is the number of renewals (completed factories) by time $t$.\n\n**Step 1: Characterize the inter-arrival time distributions.**\nThe problem states that for $k \\ge 2$, the build time $Y_k$ follows an exponential distribution with mean $1/\\lambda$. The probability density function (PDF) for these times is $f(y) = \\lambda \\exp(-\\lambda y)$ for $y \\ge 0$.\n\nThe first inter-arrival time, $Y_1$, is the total duration of a series of initiation attempts. Let $N$ be the number of attempts required for the first success. Since each attempt is an independent Bernoulli trial with success probability $p$, $N$ follows a geometric distribution on $\\{1, 2, 3, \\dots\\}$ with probability mass function $P(N=n) = (1-p)^{n-1}p$. Let $Z_j$ be the duration of the $j$-th attempt, where $Z_j$ are independent and identically distributed (i.i.d.) random variables with $Z_j \\sim \\text{Exp}(\\lambda)$. The total time for the first factory is the sum of these attempt durations: $Y_1 = \\sum_{j=1}^{N} Z_j$.\n\n**Step 2: Find the distribution of the first inter-arrival time, $Y_1$.**\nWe can find the distribution of $Y_1$ by conditioning on $N$ and using Laplace transforms. Let $\\tilde{g}(s) = E[\\exp(-sX)]$ denote the Laplace transform of the PDF of a random variable $X$.\nThe Laplace transform of the duration of a single attempt $Z_j \\sim \\text{Exp}(\\lambda)$ is $\\tilde{f}_Z(s) = \\frac{\\lambda}{s+\\lambda}$.\n\nThe Laplace transform of $Y_1$, denoted $\\tilde{f}_1(s)$, can be found using the law of total expectation:\n$$ \\tilde{f}_1(s) = E[\\exp(-s Y_1)] = E\\left[ E[\\exp(-s Y_1) | N] \\right] $$\nConditional on $N=n$, $Y_1 = \\sum_{j=1}^n Z_j$. Since the $Z_j$ are i.i.d., the Laplace transform of their sum is the product of their individual Laplace transforms:\n$$ E[\\exp(-s \\sum_{j=1}^n Z_j)] = \\prod_{j=1}^n E[\\exp(-s Z_j)] = (\\tilde{f}_Z(s))^n $$\nNow we can compute the expectation over $N$:\n$$ \\tilde{f}_1(s) = \\sum_{n=1}^{\\infty} (\\tilde{f}_Z(s))^n P(N=n) = \\sum_{n=1}^{\\infty} (\\tilde{f}_Z(s))^n (1-p)^{n-1}p $$\nThis is the probability generating function of the geometric distribution, $G_N(z) = E[z^N] = \\frac{pz}{1-z(1-p)}$, evaluated at $z = \\tilde{f}_Z(s)$.\n$$ \\tilde{f}_1(s) = G_N(\\tilde{f}_Z(s)) = \\frac{p \\tilde{f}_Z(s)}{1 - (1-p)\\tilde{f}_Z(s)} $$\nSubstituting $\\tilde{f}_Z(s) = \\frac{\\lambda}{s+\\lambda}$:\n$$ \\tilde{f}_1(s) = \\frac{p \\frac{\\lambda}{s+\\lambda}}{1 - (1-p)\\frac{\\lambda}{s+\\lambda}} = \\frac{p\\lambda}{s+\\lambda - (1-p)\\lambda} = \\frac{p\\lambda}{s+\\lambda-\\lambda+p\\lambda} = \\frac{p\\lambda}{s+p\\lambda} $$\nThis is the Laplace transform of an exponential distribution with rate $p\\lambda$. Thus, the first inter-arrival time $Y_1$ follows an exponential distribution with PDF $f_1(y) = p\\lambda \\exp(-p\\lambda y)$.\n\n**Step 3: Use the renewal equation in the Laplace domain.**\nFor a delayed renewal process, the Laplace transform of the renewal function $m(t)$, denoted $\\tilde{m}(s)$, is given by:\n$$ \\tilde{m}(s) = \\frac{\\mathcal{L}\\{f_1(t)\\}(s)}{s(1-\\mathcal{L}\\{f(t)\\}(s))} $$\nwhere $\\mathcal{L}\\{f_1(t)\\}(s)$ is the Laplace transform of the first inter-arrival time PDF and $\\mathcal{L}\\{f(t)\\}(s)$ is the Laplace transform of the subsequent inter-arrival time PDF.\nWe have $\\mathcal{L}\\{f_1(t)\\}(s) = \\frac{p\\lambda}{s+p\\lambda}$ and $\\mathcal{L}\\{f(t)\\}(s) = \\frac{\\lambda}{s+\\lambda}$.\n\nSubstituting these into the formula for $\\tilde{m}(s)$:\n$$ \\tilde{m}(s) = \\frac{\\frac{p\\lambda}{s+p\\lambda}}{s\\left(1 - \\frac{\\lambda}{s+\\lambda}\\right)} = \\frac{\\frac{p\\lambda}{s+p\\lambda}}{s\\left(\\frac{s+\\lambda-\\lambda}{s+\\lambda}\\right)} = \\frac{\\frac{p\\lambda}{s+p\\lambda}}{s\\left(\\frac{s}{s+\\lambda}\\right)} = \\frac{p\\lambda}{s+p\\lambda} \\cdot \\frac{s+\\lambda}{s^2} = \\frac{p\\lambda(s+\\lambda)}{s^2(s+p\\lambda)} $$\n\n**Step 4: Invert the Laplace transform to find $m(t)$.**\nWe use partial fraction expansion to invert $\\tilde{m}(s)$. Let\n$$ \\tilde{m}(s) = \\frac{p\\lambda(s+\\lambda)}{s^2(s+p\\lambda)} = \\frac{A}{s} + \\frac{B}{s^2} + \\frac{C}{s+p\\lambda} $$\nWe find the coefficients $A$, $B$, and $C$.\nThe coefficient $B$ is found by multiplying by $s^2$ and taking the limit as $s \\to 0$:\n$$ B = \\lim_{s\\to 0} s^2 \\tilde{m}(s) = \\lim_{s\\to 0} \\frac{p\\lambda(s+\\lambda)}{s+p\\lambda} = \\frac{p\\lambda(\\lambda)}{p\\lambda} = \\lambda $$\nThe coefficient $C$ is found by multiplying by $(s+p\\lambda)$ and taking the limit as $s \\to -p\\lambda$:\n$$ C = \\lim_{s\\to -p\\lambda} (s+p\\lambda) \\tilde{m}(s) = \\lim_{s\\to -p\\lambda} \\frac{p\\lambda(s+\\lambda)}{s^2} = \\frac{p\\lambda(-p\\lambda+\\lambda)}{(-p\\lambda)^2} = \\frac{p\\lambda^2(1-p)}{p^2\\lambda^2} = \\frac{1-p}{p} $$\nThe coefficient $A$ can be found from the derivative of the term for $B$:\n$$ A = \\lim_{s\\to 0} \\frac{d}{ds} \\left(s^2 \\tilde{m}(s)\\right) = \\lim_{s\\to 0} \\frac{d}{ds} \\left(\\frac{p\\lambda s + p\\lambda^2}{s+p\\lambda}\\right) $$\nUsing the quotient rule:\n$$ A = \\lim_{s\\to 0} \\frac{(p\\lambda)(s+p\\lambda) - (p\\lambda s + p\\lambda^2)(1)}{(s+p\\lambda)^2} = \\frac{(p\\lambda)(p\\lambda) - (p\\lambda^2)}{(p\\lambda)^2} = \\frac{p^2\\lambda^2 - p\\lambda^2}{p^2\\lambda^2} = \\frac{p-1}{p} $$\nSo the partial fraction expansion is:\n$$ \\tilde{m}(s) = \\frac{p-1}{p}\\frac{1}{s} + \\lambda\\frac{1}{s^2} + \\frac{1-p}{p}\\frac{1}{s+p\\lambda} $$\n\n**Step 5: Perform the inverse Laplace transform.**\nWe invert term-by-term using standard Laplace transform pairs: $\\mathcal{L}^{-1}\\{1/s\\} = 1$, $\\mathcal{L}^{-1}\\{1/s^2\\} = t$, and $\\mathcal{L}^{-1}\\{1/(s-a)\\} = \\exp(at)$.\n$$ m(t) = \\mathcal{L}^{-1}\\{\\tilde{m}(s)\\} = \\frac{p-1}{p} \\cdot 1 + \\lambda \\cdot t + \\frac{1-p}{p} \\cdot \\exp(-p\\lambda t) $$\nRearranging the terms for a cleaner expression:\n$$ m(t) = \\lambda t + \\frac{p-1}{p} + \\frac{1-p}{p} \\exp(-p\\lambda t) = \\lambda t - \\frac{1-p}{p} + \\frac{1-p}{p} \\exp(-p\\lambda t) $$\n$$ m(t) = \\lambda t + \\frac{1-p}{p} (\\exp(-p \\lambda t) - 1) $$\nThis is the expected number of completed factories in $[0, t]$.", "answer": "$$\\boxed{\\lambda t + \\frac{1-p}{p} (\\exp(-p \\lambda t) - 1)}$$", "id": "1296691"}, {"introduction": "Beyond calculating transient effects, a key goal in system design is achieving stability from the very beginning. This advanced practice explores the profound concept of a stationary renewal process, where the initial delay is specifically chosen to achieve steady-state behavior from time zero [@problem_id:1330913]. Solving this problem reveals the famous and counter-intuitive \"inspection paradox,\" providing deep insight into the long-run properties of systems in equilibrium.", "problem": "In the management of a large-scale data center, a critical server component is known to fail at random times and is immediately replaced, with the replacement having the same statistical lifetime properties as the original. The lifetime of a standard component, denoted by the random variable $X$, is governed by a continuous probability distribution with Cumulative Distribution Function (CDF) $F(x)$. These lifetimes are independent and identically distributed with a finite mean $E[X] = \\mu$ and a finite, non-zero variance $\\text{Var}(X) = \\sigma^2$.\n\nTo optimize system stability from the moment of launch, engineers propose a special \"burn-in\" protocol for the very first component installed. This initial component has a lifetime $X_D$ drawn from a potentially different CDF, $F_D(x)$. The goal is to choose $F_D(x)$ such that the system exhibits no start-up transient effects in its failure behavior. Specifically, the expected number of component failures up to any time $t$, denoted $E[N_D(t)]$, must be perfectly proportional to the elapsed time $t$, following the relationship $E[N_D(t)] = t/\\mu$ for all $t \\geq 0$.\n\nAssuming that such a burn-in protocol is successfully implemented, an auditor, arriving at some arbitrary time $t > 0$, inspects the system. Your task is to determine the expected value of the total operational lifetime of the specific component that the auditor finds currently in service. Express your answer as a single closed-form analytic expression in terms of $\\mu$ and $\\sigma^2$.", "solution": "Let $\\{X_{n}\\}_{n\\geq 1}$ be i.i.d. lifetimes with CDF $F$, mean $E[X]=\\mu$ and variance $\\text{Var}(X)=\\sigma^{2}$. Let $X_{D}$ be the initial lifetime with CDF $F_{D}$. The counting process $N_{D}(t)$ for the delayed renewal process satisfies $E[N_{D}(t)]=t/\\mu$ for all $t\\geq 0$ by assumption. This is the defining property of a stationary (equilibrium) renewal process with rate $1/\\mu$, which is achieved by choosing the initial life to have the equilibrium (stationary excess) law. Consequently, the process is stationary from time $0$, and any fixed time $t0$ is a typical time with respect to the stationary measure.\n\nLet $T$ denote the total lifetime of the component that is in service at an arbitrary time $t0$. In a stationary renewal process, the probability that the observation time falls in a cycle of length in a Borel set $B\\subset(0,\\infty)$ equals the long-run fraction of time spent in such cycles. By the renewal-reward theorem, with reward $R_{n}=\\mathbf{1}\\{X_{n}\\in B\\}$ and cycle length $X_{n}$, the long-run time-average fraction is\n$$\n\\frac{E[X\\,\\mathbf{1}\\{X\\in B\\}]}{E[X]}=\\frac{E[X\\,\\mathbf{1}\\{X\\in B\\}]}{\\mu}.\n$$\nTherefore, $T$ has the size-biased distribution with density $f_{T}(x)=x f(x)/\\mu$ when $F$ has density $f$. Its mean is\n$$\nE[T]=\\frac{E[X^{2}]}{\\mu}.\n$$\nUsing $E[X^{2}]=\\text{Var}(X)+(E[X])^{2}=\\sigma^{2}+\\mu^{2}$, we obtain\n$$\nE[T]=\\frac{\\sigma^{2}+\\mu^{2}}{\\mu}=\\mu+\\frac{\\sigma^{2}}{\\mu}.\n$$\nBecause the process is stationary from time $0$, this expectation does not depend on the auditorâ€™s arrival time $t0$.", "answer": "$$\\boxed{\\mu+\\frac{\\sigma^{2}}{\\mu}}$$", "id": "1330913"}]}