{"hands_on_practices": [{"introduction": "Understanding the long-term behavior of a Markov chain often begins with finding its stationary distribution. This practice provides a foundational exercise in calculating this distribution for a simple two-state system, a simplified climate model. By solving the core equation $\\boldsymbol{\\pi} = \\boldsymbol{\\pi}P$, you will develop the essential algebraic skills needed to determine the long-run probabilities of the system, regardless of its starting state [@problem_id:1314745].", "problem": "Consider a simplified climate model for a region that can be characterized by one of two states each year: 'Dry' or 'Wet'. We label the 'Dry' state as state 1 and the 'Wet' state as state 2. The climate's evolution is modeled as a discrete-time Markov chain, where the state of any given year depends only on the state of the immediately preceding year.\n\nThe transition probabilities are as follows:\n- If a year is Dry (state 1), the probability that the next year will also be Dry is $2/3$.\n- If a year is Wet (state 2), the probability that the next year will be Dry is $1/4$.\n\nThe one-step transition probability matrix $P$ is a $2 \\times 2$ matrix where the entry $P_{ij}$ is the probability of moving from state $i$ to state $j$ in one year.\n\nLet $P^n$ be the $n$-step transition matrix. Determine the limiting matrix $L = \\lim_{n \\to \\infty} P^n$. In your final answer, present the four entries of this limiting matrix, $L_{11}, L_{12}, L_{21}, L_{22}$, as a single row matrix of the form $\\begin{pmatrix} L_{11}  L_{12}  L_{21}  L_{22} \\end{pmatrix}$. The answer should be in exact fractional form.", "solution": "The Markov chain has two states with transition probabilities:\n- From state 1 (Dry) to state 1 with probability $\\frac{2}{3}$, hence to state 2 with probability $\\frac{1}{3}$.\n- From state 2 (Wet) to state 1 with probability $\\frac{1}{4}$, hence to state 2 with probability $\\frac{3}{4}$.\n\nTherefore, the one-step transition matrix is\n$$\nP=\\begin{pmatrix}\n\\frac{2}{3}  \\frac{1}{3} \\\\\n\\frac{1}{4}  \\frac{3}{4}\n\\end{pmatrix}.\n$$\nEach row sums to $1$, so $P$ is stochastic. Because $P_{11}>0$ and $P_{22}>0$, the chain is aperiodic, and since both off-diagonal entries are positive, the chain is irreducible. For a finite, irreducible, aperiodic Markov chain, there is a unique stationary distribution $\\boldsymbol{\\pi}$ satisfying $\\boldsymbol{\\pi}=\\boldsymbol{\\pi}P$ and $\\pi_{1}+\\pi_{2}=1$, and\n$$\n\\lim_{n\\to\\infty}P^{n}=\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\boldsymbol{\\pi}.\n$$\nThus each row of the limiting matrix equals $\\boldsymbol{\\pi}$.\n\nCompute $\\boldsymbol{\\pi}=(\\pi_{1},\\pi_{2})$ from $\\boldsymbol{\\pi}=\\boldsymbol{\\pi}P$ and $\\pi_{1}+\\pi_{2}=1$. From the first component,\n$$\n\\pi_{1}=\\frac{2}{3}\\pi_{1}+\\frac{1}{4}\\pi_{2}\n\\;\\Rightarrow\\;\n\\pi_{1}-\\frac{2}{3}\\pi_{1}=\\frac{1}{4}\\pi_{2}\n\\;\\Rightarrow\\;\n\\frac{1}{3}\\pi_{1}=\\frac{1}{4}\\pi_{2}\n\\;\\Rightarrow\\;\n4\\pi_{1}=3\\pi_{2}\n\\;\\Rightarrow\\;\n\\pi_{1}=\\frac{3}{4}\\pi_{2}.\n$$\nUsing $\\pi_{1}+\\pi_{2}=1$ gives\n$$\n\\frac{3}{4}\\pi_{2}+\\pi_{2}=\\frac{7}{4}\\pi_{2}=1\n\\;\\Rightarrow\\;\n\\pi_{2}=\\frac{4}{7},\\quad \\pi_{1}=\\frac{3}{7}.\n$$\nHence the limiting matrix $L=\\lim_{n\\to\\infty}P^{n}$ has identical rows equal to $(\\frac{3}{7},\\frac{4}{7})$, so\n$$\nL=\\begin{pmatrix}\n\\frac{3}{7}  \\frac{4}{7} \\\\\n\\frac{3}{7}  \\frac{4}{7}\n\\end{pmatrix}.\n$$\nTherefore, the entries are $L_{11}=\\frac{3}{7}$, $L_{12}=\\frac{4}{7}$, $L_{21}=\\frac{3}{7}$, $L_{22}=\\frac{4}{7}$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{3}{7}  \\frac{4}{7}  \\frac{3}{7}  \\frac{4}{7} \\end{pmatrix}}$$", "id": "1314745"}, {"introduction": "The concept of limiting behavior extends beyond stable state distributions to questions of survival or extinction. This problem models an information cascade as a branching process, a special type of stochastic process where the population size can change over time. You will calculate the probability of extinction by finding a fixed point of the offspring generating function, offering insight into how the dynamics of individual transmissions determine the ultimate fate of the entire cascade [@problem_id:1314725].", "problem": "Consider a simplified model for an information cascade on a large social network, initiated by a single user. This initiator, part of generation 0, propagates a piece of information. Each individual who receives the information (in any generation) will independently decide how many *new* individuals to share it with, and then becomes inactive with respect to this specific information cascade. An individual shares the information with 0 new individuals (i.e., the chain of transmission ends through this path) with probability $p_0$, with 1 new individual with probability $p_1$, and with 3 new individuals with probability $p_3$. These outcomes are mutually exclusive, and their probabilities sum to one: $p_0 + p_1 + p_3 = 1$. The process continues as each newly informed individual acts in the same manner, creating subsequent generations.\n\nThe information cascade is considered \"extinct\" if, at some generation, no new individuals are informed. Suppose the process starts with a single initiator and the parameters of the model satisfy the condition $p_0  2p_3$. Determine the long-term probability that this information cascade goes extinct. Express your answer as a single closed-form analytic expression in terms of $p_0$ and $p_3$.", "solution": "Model the cascade as a Galton–Watson branching process with offspring distribution: an individual produces $0$ new individuals with probability $p_{0}$, $1$ with probability $p_{1}$, and $3$ with probability $p_{3}$, where $p_{0}+p_{1}+p_{3}=1$. Let $q$ denote the extinction probability starting from a single initiator. The standard fixed-point equation for extinction in a Galton–Watson process is\n$$\nq = f(q),\n$$\nwhere $f(s)$ is the offspring generating function. Here,\n$$\nf(s) = p_{0} + p_{1}s + p_{3}s^{3},\n$$\nso $q$ satisfies\n$$\nq = p_{0} + p_{1}q + p_{3}q^{3}.\n$$\nRearranging gives\n$$\np_{3}q^{3} + (p_{1}-1)q + p_{0} = 0.\n$$\nUsing $p_{1} = 1 - p_{0} - p_{3}$, this becomes\n$$\np_{3}q^{3} - (p_{0}+p_{3})q + p_{0} = 0.\n$$\nObserve that $q=1$ is always a root because $f(1)=1$. Factor out $(q-1)$ by writing\n$$\np_{3}q^{3} - (p_{0}+p_{3})q + p_{0} = (q-1)\\left(p_{3}q^{2} + p_{3}q - p_{0}\\right).\n$$\nTherefore, the extinction probabilities are the roots of $q=1$ and the quadratic\n$$\np_{3}q^{2} + p_{3}q - p_{0} = 0.\n$$\nSolve the quadratic to get\n$$\nq = \\frac{-p_{3} \\pm \\sqrt{p_{3}^{2} + 4p_{3}p_{0}}}{2p_{3}}.\n$$\nSince $p_{0}  2p_{3}$ implies the mean number of offspring $m = p_{1} + 3p_{3} = 1 - p_{0} + 2p_{3}  1$, the process is supercritical, and there is a unique extinction probability in $(0,1)$. Among the two quadratic roots, the one with the plus sign is nonnegative and lies in $(0,1)$ under $p_{0}  2p_{3}$, while the other is negative. Dividing numerator and denominator by $p_{3}0$ yields the closed form\n$$\nq = \\frac{-1 + \\sqrt{1 + \\frac{4p_{0}}{p_{3}}}}{2}.\n$$\nThis is the long-term extinction probability when $p_{0}  2p_{3}$.", "answer": "$$\\boxed{\\frac{-1+\\sqrt{1+\\frac{4p_{0}}{p_{3}}}}{2}}$$", "id": "1314725"}, {"introduction": "While analytical solutions are powerful, many real-world systems are analyzed computationally. This practice challenges you to implement the power iteration method, an algorithm that numerically approximates the stationary distribution by repeatedly applying the transition matrix [@problem_id:2393833]. By testing this algorithm on different types of Markov chains—including ergodic, absorbing, and periodic ones—you will gain a practical understanding of the theoretical conditions that guarantee convergence to a unique limiting distribution.", "problem": "Given a finite-state time-homogeneous Markov chain with a row-stochastic transition matrix $P \\in \\mathbb{R}^{n \\times n}$, a stationary distribution is any row vector $\\pi \\in \\mathbb{R}^{1 \\times n}$ with nonnegative components summing to $1$ that satisfies the fixed-point equation $\\pi = \\pi P$. Define the mapping $T(\\pi) = \\pi P$. For each test case below, let $\\pi_0$ be the specified initial row probability vector. Construct a sequence $(\\pi_n)_{n \\ge 0}$ by $\\pi_{n+1} = T(\\pi_n)$, and check convergence using the $\\ell_1$-norm: stop at the first index $n$ such that $\\|\\pi_{n+1} - \\pi_n\\|_1  \\varepsilon$ or after a maximum of $N_{\\max}$ iterations, whichever occurs first. If convergence occurs, report the approximate stationary distribution $\\pi_{n+1}$ with each component rounded to $8$ decimal places. If the stopping criterion is not met within $N_{\\max}$ iterations, report the integer $-1$ for that test case. All arithmetic is real-valued. Angles are not involved. There are no physical units. The norm to be used is the $\\ell_1$-norm.\n\nUse the following test suite, where each test case specifies the transition matrix $P$, the initial distribution $\\pi_0$, the tolerance $\\varepsilon$, and the maximum iteration count $N_{\\max}$.\n\n- Test case $1$ (strictly positive, ergodic):\n  - $P = \\begin{bmatrix}\n  0.6  0.3  0.1 \\\\\n  0.2  0.5  0.3 \\\\\n  0.25  0.25  0.5\n  \\end{bmatrix}$\n  - $\\pi_0 = \\left[\\dfrac{1}{3}, \\dfrac{1}{3}, \\dfrac{1}{3}\\right]$\n  - $\\varepsilon = 10^{-10}$\n  - $N_{\\max} = 10^6$\n\n- Test case $2$ (absorbing state):\n  - $P = \\begin{bmatrix}\n  0.5  0.5  0.0 \\\\\n  0.0  1.0  0.0 \\\\\n  0.1  0.0  0.9\n  \\end{bmatrix}$\n  - $\\pi_0 = \\left[\\dfrac{1}{3}, \\dfrac{1}{3}, \\dfrac{1}{3}\\right]$\n  - $\\varepsilon = 10^{-10}$\n  - $N_{\\max} = 10^6$\n\n- Test case $3$ (multiple closed classes; limit depends on $\\pi_0$):\n  - $P = \\begin{bmatrix}\n  1.0  0.0  0.0  0.0 \\\\\n  1.0  0.0  0.0  0.0 \\\\\n  0.0  0.0  0.0  1.0 \\\\\n  0.0  0.0  0.0  1.0\n  \\end{bmatrix}$\n  - $\\pi_0 = \\left[\\dfrac{1}{4}, \\dfrac{1}{4}, \\dfrac{1}{4}, \\dfrac{1}{4}\\right]$\n  - $\\varepsilon = 10^{-12}$\n  - $N_{\\max} = 10^6$\n\n- Test case $4$ (period-$2$ chain that does not converge from the given $\\pi_0$):\n  - $P = \\begin{bmatrix}\n  0.0  1.0 \\\\\n  1.0  0.0\n  \\end{bmatrix}$\n  - $\\pi_0 = \\left[1.0, 0.0\\right]$\n  - $\\varepsilon = 10^{-12}$\n  - $N_{\\max} = 10^5$\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases. For a converged case, output the list of rounded components; for a non-converged case, output the integer $-1$. For example, an output with four results must look like $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$ with no spaces anywhere in the line. Each list of components must be written with each entry rounded to $8$ decimal places.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- **Model**: Finite-state, time-homogeneous Markov chain.\n- **Transition Matrix**: A row-stochastic matrix $P \\in \\mathbb{R}^{n \\times n}$.\n- **Stationary Distribution**: A row vector $\\pi \\in \\mathbb{R}^{1 \\times n}$ with non-negative components summing to $1$ that is a fixed point of the equation $\\pi = \\pi P$.\n- **Iterative Mapping**: $T(\\pi) = \\pi P$.\n- **Iterative Sequence**: The sequence is defined by $\\pi_{n+1} = T(\\pi_n)$, starting from a given initial probability vector $\\pi_0$.\n- **Stopping Criterion**: The iteration stops at the first index $n$ for which the $\\ell_1$-norm of the difference between consecutive iterates is less than a tolerance $\\varepsilon$, i.e., $\\|\\pi_{n+1} - \\pi_n\\|_1  \\varepsilon$.\n- **Maximum Iterations**: A hard limit $N_{\\max}$ on the number of iterations.\n- **Output on Convergence**: The vector $\\pi_{n+1}$, with each component rounded to $8$ decimal places.\n- **Output on Non-convergence**: The integer $-1$.\n- **Test Case 1**: $P = \\begin{bmatrix} 0.6  0.3  0.1 \\\\ 0.2  0.5  0.3 \\\\ 0.25  0.25  0.5 \\end{bmatrix}$, $\\pi_0 = \\left[\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\right]$, $\\varepsilon = 10^{-10}$, $N_{\\max} = 10^6$.\n- **Test Case 2**: $P = \\begin{bmatrix} 0.5  0.5  0.0 \\\\ 0.0  1.0  0.0 \\\\ 0.1  0.0  0.9 \\end{bmatrix}$, $\\pi_0 = \\left[\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\right]$, $\\varepsilon = 10^{-10}$, $N_{\\max} = 10^6$.\n- **Test Case 3**: $P = \\begin{bmatrix} 1.0  0.0  0.0  0.0 \\\\ 1.0  0.0  0.0  0.0 \\\\ 0.0  0.0  0.0  1.0 \\\\ 0.0  0.0  0.0  1.0 \\end{bmatrix}$, $\\pi_0 = \\left[\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4}\\right]$, $\\varepsilon = 10^{-12}$, $N_{\\max} = 10^6$.\n- **Test Case 4**: $P = \\begin{bmatrix} 0.0  1.0 \\\\ 1.0  0.0 \\end{bmatrix}$, $\\pi_0 = \\left[1.0, 0.0\\right]$, $\\varepsilon = 10^{-12}$, $N_{\\max} = 10^5$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the required criteria.\n\n- **Scientifically Grounded**: The problem addresses the computation of a stationary distribution for a Markov chain. This is a fundamental concept in the theory of stochastic processes. The proposed iterative method, $\\pi_{k+1} = \\pi_k P$, is the standard power iteration method for finding the left eigenvector associated with the eigenvalue $\\lambda=1$. The existence and uniqueness of such distributions under various conditions (ergodicity, reducibility) are well-established mathematical facts. The problem is scientifically and mathematically sound.\n\n- **Well-Posed**: The problem is completely specified. For each test case, all necessary inputs—the transition matrix $P$, the initial vector $\\pi_0$, the convergence tolerance $\\varepsilon$, and the maximum iteration count $N_{\\max}$—are provided. The algorithm is deterministically defined, and the conditions for reporting either a converged result or a failure are unambiguous.\n\n- **Objective**: The problem is stated using precise, formal mathematical language. All quantities are defined, and there are no subjective or opinion-based assertions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is scientifically grounded, well-posed, and objective. A solution will be constructed.\n\n### Solution\nThe problem requires the implementation of a fixed-point iteration to find the stationary distribution $\\pi$ of a finite-state Markov chain. A stationary distribution satisfies the equation $\\pi = \\pi P$, where $P$ is the row-stochastic transition matrix. This equation identifies $\\pi$ as a left eigenvector of $P$ corresponding to the eigenvalue $\\lambda=1$. The Perron-Frobenius theorem for stochastic matrices guarantees that such an eigenvector exists and that $\\lambda=1$ is the largest eigenvalue in magnitude.\n\nThe iterative procedure is given by $\\pi_{k+1} = \\pi_k P$ for $k=0, 1, 2, \\ldots$, starting with an initial probability distribution $\\pi_0$. This is known as the power method. The iteration is terminated under one of two conditions:\n$1$. Convergence: The $\\ell_1$-norm of the difference between successive iterates falls below a given tolerance $\\varepsilon$. The $\\ell_1$-norm of a vector $\\mathbf{x} = [x_1, \\ldots, x_n]$ is $\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n |x_i|$. The condition is $\\|\\pi_{k+1} - \\pi_k\\|_1  \\varepsilon$.\n$2$. Non-convergence: The number of iterations exceeds a specified maximum, $N_{\\max}$.\n\nThe behavior of the sequence $(\\pi_k)_{k \\ge 0}$ depends on the properties of the matrix $P$.\n- **Case 1**: The matrix $P$ is strictly positive, which implies the corresponding Markov chain is ergodic (irreducible and aperiodic). For such a chain, the power method is guaranteed to converge to the unique stationary distribution, regardless of the initial probability vector $\\pi_0$.\n- **Case 2**: The matrix $P$ is reducible. State $2$ (with index $1$) is an absorbing state since $P_{11}=1.0$. From any initial state, there is a non-zero probability of eventually reaching the absorbing state. The iteration will converge to a distribution with all probability mass concentrated on the absorbing states. In this specific case, the limit will be $[0, 1, 0]$.\n- **Case 3**: The matrix $P$ is reducible, with two closed recurrent classes corresponding to states $\\{1\\}$ and $\\{4\\}$. The limiting distribution depends on the initial distribution $\\pi_0$. The total probability mass initially in states that can reach state $1$ will eventually collect in state $1$. Similarly for state $4$. Here, states $1$ and $2$ (indices $0,1$) lead to state $1$, and states $3$ and $4$ (indices $2,3$) lead to state $4$. Thus, the final mass in state $1$ will be $\\pi_{0,0} + \\pi_{0,1}$, and the final mass in state $4$ will be $\\pi_{0,2} + \\pi_{0,3}$. For $\\pi_0 = [0.25, 0.25, 0.25, 0.25]$, the limit is expected to be $[0.5, 0, 0, 0.5]$. The iteration will converge rapidly.\n- **Case 4**: The matrix $P$ corresponds to a periodic chain with period $2$. For the initial distribution $\\pi_0 = [1.0, 0.0]$, the sequence of distributions will be $\\pi_0 = [1.0, 0.0]$, $\\pi_1 = [0.0, 1.0]$, $\\pi_2 = [1.0, 0.0]$, and so on. The sequence oscillates and does not converge to a single limit. The difference $\\|\\pi_{k+1} - \\pi_k\\|_1$ will always be $2$, so the convergence criterion will never be met. The procedure will terminate after $N_{\\max}$ iterations, and the result must be $-1$.\n\nThe algorithm to be implemented will iterate for each test case, performing the vector-matrix multiplication $\\pi_{k+1} = \\pi_k P$ and checking the stopping criteria at each step. If convergence is achieved, the resulting vector $\\pi_{k+1}$ is rounded to $8$ decimal places. Otherwise, $-1$ is reported.", "answer": "```\n[[0.37209302,0.34883721,0.27906977],[0.00000000,1.00000000,0.00000000],[0.50000000,0.00000000,0.00000000,0.50000000],-1]\n```", "id": "2393833"}]}