{"hands_on_practices": [{"introduction": "A single snapshot of a Brownian motion at time $t$ is a normally distributed random variable, but the \"motion\" aspect is captured by how its positions at different times relate to one another. This first exercise [@problem_id:1326863] provides essential practice with the joint distribution of the process, a direct consequence of its independent increments. By calculating the probability of the process being positive at two different times, you will solidify your understanding of its fundamental covariance structure.", "problem": "Consider a standard one-dimensional Brownian motion, denoted by $\\{B_t\\}_{t \\ge 0}$. This stochastic process is defined by the following properties:\n1. $B_0 = 0$.\n2. For any time $t > s \\ge 0$, the increment $B_t - B_s$ is a normally distributed random variable with a mean of 0 and a variance of $t-s$.\n3. For any sequence of times $0 \\le t_1  t_2  \\dots  t_n$, the increments $B_{t_2} - B_{t_1}, B_{t_3} - B_{t_2}, \\dots, B_{t_n} - B_{t_{n-1}}$ are mutually independent.\n\nCalculate the probability that the process is positive at time $t=1$ and also positive at time $t=4$. That is, determine the value of the probability $P(B_1 > 0, B_4 > 0)$.\n\nExpress your answer as a simplified fraction.", "solution": "Let $\\{B_t\\}_{t \\ge 0}$ be a standard Brownian motion. By the covariance structure $\\operatorname{Cov}(B_{s},B_{t})=\\min\\{s,t\\}$, the pair $(B_{1},B_{4})$ is jointly Gaussian with mean zero, variances $\\operatorname{Var}(B_{1})=1$ and $\\operatorname{Var}(B_{4})=4$, and covariance $\\operatorname{Cov}(B_{1},B_{4})=\\min\\{1,4\\}=1$. Hence the correlation is\n$$\n\\rho=\\frac{\\operatorname{Cov}(B_{1},B_{4})}{\\sqrt{\\operatorname{Var}(B_{1})\\operatorname{Var}(B_{4})}}=\\frac{1}{\\sqrt{1\\cdot 4}}=\\frac{1}{2}.\n$$\nDefine $X=B_{1}$ and $Y=B_{4}/2$. Then $(X,Y)$ is a zero-mean bivariate normal with unit variances and correlation $\\rho=\\frac{1}{2}$. Since scaling by a positive constant preserves sign, the event $\\{B_{1}>0,B_{4}>0\\}$ equals $\\{X>0,Y>0\\}$.\n\nFor a zero-mean bivariate normal $(X,Y)$ with unit variances and correlation $\\rho$, the orthant probability is\n$$\n\\mathbb{P}(X>0,Y>0)=\\frac{1}{4}+\\frac{1}{2\\pi}\\arcsin(\\rho).\n$$\nSubstituting $\\rho=\\frac{1}{2}$ gives\n$$\n\\mathbb{P}(B_{1}>0,B_{4}>0)=\\frac{1}{4}+\\frac{1}{2\\pi}\\arcsin\\left(\\frac{1}{2}\\right)=\\frac{1}{4}+\\frac{1}{2\\pi}\\cdot\\frac{\\pi}{6}=\\frac{1}{4}+\\frac{1}{12}=\\frac{1}{3}.\n$$\nTherefore, the desired probability equals $\\frac{1}{3}$.", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "1326863"}, {"introduction": "Building on the concept of joint distributions, we can ask a more nuanced question: how does information about the future affect our understanding of the past? This practice [@problem_id:1326857] delves into the powerful idea of conditional expectation, guiding you to derive the expected path of a Brownian motion given its final destination. This leads to the concept of the \"Brownian bridge,\" a fundamental object in stochastic calculus with wide-ranging applications.", "problem": "A standard one-dimensional Brownian motion $\\{B_t\\}_{t \\geq 0}$ is a stochastic process characterized by the following properties: (i) $B_0 = 0$; (ii) it has stationary and independent increments; (iii) for any time $t > 0$, the random variable $B_t$ is normally distributed with mean 0 and variance $t$.\n\nConsider a new stochastic process $\\{X_t\\}_{t \\geq 0}$ derived from this Brownian motion, defined by the integral:\n$$ X_t = \\int_0^t (\\alpha B_s + \\beta s) ds $$\nwhere $\\alpha$ and $\\beta$ are given real constants.\n\nYour task is to calculate the conditional expectation of the process $X_t$ at a fixed time $T > 0$, given that the Brownian motion reaches a value of $x$ at that same time. In other words, find the value of $\\mathbb{E}[X_T | B_T = x]$.\n\nProvide your answer as a closed-form analytic expression in terms of $\\alpha$, $\\beta$, $T$, and $x$.", "solution": "We are given a standard one-dimensional Brownian motion $\\{B_{t}\\}_{t \\geq 0}$ with $B_{0}=0$, stationary independent increments, and $B_{t} \\sim \\mathcal{N}(0,t)$, and a process $X_{t}$ defined by\n$$\nX_{t}=\\int_{0}^{t}\\left(\\alpha B_{s}+\\beta s\\right) ds,\n$$\nfor real constants $\\alpha$ and $\\beta$. We seek $\\mathbb{E}[X_{T}\\mid B_{T}=x]$ for a fixed $T>0$.\n\nBy linearity of conditional expectation and the interchange of conditional expectation with the Lebesgue integral (justified by Fubini/Tonelli since $\\mathbb{E}\\left[\\int_{0}^{T}|\\alpha B_{s}+\\beta s| ds\\right]\\infty$), we have\n$$\n\\mathbb{E}\\left[X_{T}\\mid B_{T}\\right]=\\int_{0}^{T}\\left(\\alpha\\,\\mathbb{E}\\left[B_{s}\\mid B_{T}\\right]+\\beta s\\right) ds.\n$$\nTo compute $\\mathbb{E}\\left[B_{s}\\mid B_{T}\\right]$, use the joint Gaussian regression formula for the pair $(B_{s},B_{T})$. Since $\\mathbb{E}[B_{s}]=0$, $\\mathbb{E}[B_{T}]=0$, $\\operatorname{Var}(B_{T})=T$, and $\\operatorname{Cov}(B_{s},B_{T})=\\min\\{s,T\\}=s$ for $0\\leq s\\leq T$, we obtain\n$$\n\\mathbb{E}\\left[B_{s}\\mid B_{T}\\right]=\\frac{\\operatorname{Cov}(B_{s},B_{T})}{\\operatorname{Var}(B_{T})}B_{T}=\\frac{s}{T}B_{T}.\n$$\nSubstituting into the integral,\n$$\n\\mathbb{E}\\left[X_{T}\\mid B_{T}\\right]=\\int_{0}^{T}\\left(\\alpha \\frac{s}{T} B_{T}+\\beta s\\right) ds\n=\\alpha B_{T}\\int_{0}^{T}\\frac{s}{T} ds+\\beta \\int_{0}^{T} s\\, ds.\n$$\nEvaluate the integrals:\n$$\n\\int_{0}^{T}\\frac{s}{T} ds=\\frac{1}{T}\\int_{0}^{T}s\\, ds=\\frac{1}{T}\\cdot \\frac{T^{2}}{2}=\\frac{T}{2}, \\qquad \\int_{0}^{T}s\\, ds=\\frac{T^{2}}{2}.\n$$\nHence,\n$$\n\\mathbb{E}\\left[X_{T}\\mid B_{T}\\right]=\\frac{\\alpha T}{2}\\,B_{T}+\\frac{\\beta T^{2}}{2}.\n$$\nFinally, conditioning on the event $\\{B_{T}=x\\}$ gives\n$$\n\\mathbb{E}\\left[X_{T}\\mid B_{T}=x\\right]=\\frac{\\alpha x T}{2}+\\frac{\\beta T^{2}}{2}.\n$$\nThis is a closed-form expression in terms of $\\alpha$, $\\beta$, $T$, and $x$.", "answer": "$$\\boxed{\\frac{\\alpha x T}{2}+\\frac{\\beta T^{2}}{2}}$$", "id": "1326857"}, {"introduction": "Many critical questions in finance and physics depend not on a particle's final position, but on the extremes it reached along its journey. To answer such questions, we need tools that can handle the properties of the entire sample path. This exercise [@problem_id:1326870] introduces the elegant and powerful reflection principle to analyze the distribution of the maximum value of a Brownian motion, a technique that is indispensable for pricing barrier options and analyzing ruin probabilities.", "problem": "A particle's position in one dimension is described by the stochastic process $X_t = x_0 + B_t$ for time $t \\ge 0$. Here, $x_0$ is a positive constant representing the initial position, and $B_t$ is a standard one-dimensional Wiener process (Brownian motion) starting at the origin, characterized by $B_0=0$ and having a variance of $\\operatorname{Var}(B_t) = t$.\n\nWe are interested in two key metrics related to the particle's trajectory over the interval $[0, t]$:\n1. The historical maximum position, $M_t = \\max_{0 \\le s \\le t} X_s$.\n2. The final absolute distance from the origin, $A_t = |X_t|$.\n\nThese two random variables, $M_t$ and $A_t$, generally have different properties and distributions. To quantify this difference, calculate the ratio of their expected values.\n\nFind an analytic expression for the ratio $\\frac{\\mathbb{E}[M_t]}{\\mathbb{E}[A_t]}$ in terms of the dimensionless parameter $\\alpha = \\frac{x_0}{\\sqrt{t}}$. Your final expression may include the standard normal probability density function (PDF), $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{z^2}{2})$, and the standard normal cumulative distribution function (CDF), $\\Phi(z) = \\int_{-\\infty}^{z} \\phi(u) du$.", "solution": "We have $X_{t}=x_{0}+B_{t}$ with $B_{t}$ a standard Brownian motion, and we define $M_{t}=\\max_{0\\le s\\le t}X_{s}$ and $A_{t}=|X_{t}|$. Introduce the dimensionless parameter $\\alpha=x_{0}/\\sqrt{t}$.\n\nFirst, compute $\\mathbb{E}[M_{t}]$. Since $X_{s}=x_{0}+B_{s}$, we have\n$$\nM_{t}=\\max_{0\\le s\\le t}(x_{0}+B_{s})=x_{0}+\\max_{0\\le s\\le t}B_{s}.\n$$\nLet $M^{0}_{t}=\\max_{0\\le s\\le t}B_{s}$. The reflection principle gives, for $a\\ge 0$,\n$$\n\\mathbb{P}(M^{0}_{t}\\le a)=2\\Phi\\left(\\frac{a}{\\sqrt{t}}\\right)-1.\n$$\nHence\n$$\n\\mathbb{E}[M^{0}_{t}]=\\int_{0}^{\\infty}\\mathbb{P}(M^{0}_{t}>y)\\,dy=\\int_{0}^{\\infty}2\\left(1-\\Phi\\left(\\frac{y}{\\sqrt{t}}\\right)\\right)dy\n=2\\sqrt{t}\\int_{0}^{\\infty}\\left(1-\\Phi(z)\\right)dz.\n$$\nUsing $\\int_{0}^{\\infty}\\left(1-\\Phi(z)\\right)dz=\\phi(0)=\\frac{1}{\\sqrt{2\\pi}}$, we obtain\n$$\n\\mathbb{E}[M^{0}_{t}]=\\sqrt{\\frac{2t}{\\pi}}.\n$$\nTherefore,\n$$\n\\mathbb{E}[M_{t}]=x_{0}+\\mathbb{E}[M^{0}_{t}]=x_{0}+\\sqrt{\\frac{2t}{\\pi}}=\\sqrt{t}\\left(\\alpha+\\sqrt{\\frac{2}{\\pi}}\\right).\n$$\n\nNext, compute $\\mathbb{E}[A_{t}]=\\mathbb{E}[|X_{t}|]$ with $X_{t}\\sim \\mathcal{N}(x_{0},t)$. Let $\\mu=x_{0}$ and $\\sigma=\\sqrt{t}$. For a normal random variable $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$, its expected absolute value is given by the formula for the mean of a folded normal distribution:\n$$\n\\mathbb{E}|Y|=2\\sigma\\phi\\left(\\frac{\\mu}{\\sigma}\\right)+\\mu\\left(2\\Phi\\left(\\frac{\\mu}{\\sigma}\\right)-1\\right).\n$$\nApplying this with $\\mu=x_{0}$ and $\\sigma=\\sqrt{t}$ yields\n$$\n\\mathbb{E}[A_{t}]=2\\sqrt{t}\\phi\\left(\\frac{x_{0}}{\\sqrt{t}}\\right)+x_{0}\\left(2\\Phi\\left(\\frac{x_{0}}{\\sqrt{t}}\\right)-1\\right)\n=\\sqrt{t}\\left(2\\phi(\\alpha)+\\alpha\\left(2\\Phi(\\alpha)-1\\right)\\right).\n$$\n\nTherefore, the requested ratio in terms of $\\alpha$ is\n$$\n\\frac{\\mathbb{E}[M_{t}]}{\\mathbb{E}[A_{t}]}=\\frac{\\sqrt{t}\\left(\\alpha+\\sqrt{\\frac{2}{\\pi}}\\right)}{\\sqrt{t}\\left(2\\phi(\\alpha)+\\alpha\\left(2\\Phi(\\alpha)-1\\right)\\right)}\n=\\frac{\\alpha+\\sqrt{\\frac{2}{\\pi}}}{2\\phi(\\alpha)+\\alpha\\left(2\\Phi(\\alpha)-1\\right)}.\n$$", "answer": "$$\\boxed{\\frac{\\alpha+\\sqrt{\\frac{2}{\\pi}}}{2\\phi(\\alpha)+\\alpha\\left(2\\Phi(\\alpha)-1\\right)}}$$", "id": "1326870"}]}