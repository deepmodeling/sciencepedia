{"hands_on_practices": [{"introduction": "A core task in studying random phenomena is to determine the underlying rate of events. This practice exercise demonstrates how to do just that for a Poisson process by using the expected waiting time for a specific number of arrivals [@problem_id:1349209]. By understanding the direct relationship between the average waiting time, $E[T_n]$, and the rate parameter $\\lambda$, we can infer the fundamental characteristics of the process from observed data.", "problem": "A deep-space observatory is engaged in a long-term project to detect faint, transient astrophysical signals originating from a specific sector of the sky. The occurrences of these signals are unpredictable but are well-approximated by a Poisson process. Based on theoretical models and preliminary data, the mission scientists have determined that the expected waiting time until the detection of the fourth such signal is 2.5 years.\n\nFor the purpose of your calculation, assume a year consists of exactly 365 days.\n\nCalculate the average rate of signal detection in units of signals per hour. Express your answer rounded to three significant figures.", "solution": "Let the detections follow a Poisson process with rate $\\lambda$ (signals per unit time). The waiting time until the $k$-th event, $T_{k}$, has a Gamma distribution with shape $k$ and rate $\\lambda$, whose expectation is\n$$\n\\mathbb{E}[T_{k}] = \\frac{k}{\\lambda}.\n$$\nGiven the expected waiting time to the fourth signal is $2.5$ years,\n$$\n\\frac{4}{\\lambda} = 2.5 \\;\\;\\Rightarrow\\;\\; \\lambda = \\frac{4}{2.5} \\text{ per year}.\n$$\nTo express $\\lambda$ in signals per hour, use 1 year = 365 days and 1 day = 24 hours, so 1 year = $365 \\times 24 = 8760$ hours. Thus,\n$$\n\\lambda_{\\text{per hour}} = \\frac{\\lambda}{8760} = \\frac{\\frac{4}{2.5}}{365 \\times 24}\n= \\frac{4}{2.5 \\times 365 \\times 24}\n= \\frac{8}{5 \\times 8760}\n= \\frac{1}{5475} \\text{ per hour}.\n$$\nNumerically,\n$$\n\\lambda_{\\text{per hour}} = \\frac{1}{5475} \\approx 1.83 \\times 10^{-4},\n$$\nrounded to three significant figures.", "answer": "$$\\boxed{1.83 \\times 10^{-4}}$$", "id": "1349209"}, {"introduction": "While the waiting time $T_n$ is a continuous variable, we can cleverly calculate its probabilities by thinking about the number of events. This problem illustrates a crucial duality in Poisson processes: the probability that the $n$-th event occurs by a certain time $t$ is the same as the probability that at least $n$ events have occurred within that time frame [@problem_id:1349214]. This powerful technique allows us to use the familiar discrete Poisson distribution to solve problems about continuous waiting times.", "problem": "In a semiconductor manufacturing facility, the occurrence of a specific type of microscopic flaw on a silicon wafer follows a Poisson process. On average, these flaws are detected at a rate of $\\lambda = 1.25$ flaws per hour of inspection. A new automated diagnostic protocol is initiated, which requires observing a total of $n=3$ such flaws to complete its calibration cycle. What is the probability that the system completes its calibration cycle in under $t=3$ hours? Round your final answer to four significant figures.", "solution": "Let $T_n$ be the random variable representing the waiting time for the $n$-th event in a Poisson process with rate $\\lambda$. The problem asks for the probability $P(T_3  3)$, given $\\lambda = 1.25$ flaws per hour and $n=3$.\n\nA key property of the Poisson process is the relationship between the waiting time for the $n$-th event and the number of events occurring in a fixed time interval. The event \"the $n$-th flaw occurs before time $t$\" (i.e., $T_n  t$) is equivalent to the event \"the number of flaws observed by time $t$ is at least $n$\".\n\nLet $N(t)$ be the number of flaws observed in the time interval $[0, t]$. Since the flaw occurrences follow a Poisson process with rate $\\lambda$, $N(t)$ is a Poisson random variable with mean (and parameter) $\\mu = \\lambda t$.\n\nIn this problem, we have $\\lambda = 1.25$ flaws/hour and the time interval is $t = 3$ hours. Therefore, the mean number of flaws in 3 hours is:\n$$\n\\mu = \\lambda t = (1.25 \\text{ flaws/hour}) \\times (3 \\text{ hours}) = 3.75\n$$\nSo, the number of flaws in 3 hours, $N(3)$, follows a Poisson distribution with parameter $\\mu = 3.75$.\n\nWe need to calculate the probability that the 3rd flaw occurs in under 3 hours, which is equivalent to the probability that the number of flaws in 3 hours is at least 3.\n$$\nP(T_3  3) = P(N(3) \\ge 3)\n$$\nThe probability mass function (PMF) for a Poisson distribution with mean $\\mu$ is given by:\n$$\nP(N(t)=k) = \\frac{\\mu^k e^{-\\mu}}{k!}\n$$\nIt is easier to calculate the complement probability, $P(N(3)  3)$, and subtract it from 1.\n$$\nP(N(3) \\ge 3) = 1 - P(N(3)  3) = 1 - [P(N(3)=0) + P(N(3)=1) + P(N(3)=2)]\n$$\nNow we calculate each term with $\\mu = 3.75$:\nFor $k=0$:\n$$\nP(N(3)=0) = \\frac{(3.75)^0 e^{-3.75}}{0!} = e^{-3.75}\n$$\nFor $k=1$:\n$$\nP(N(3)=1) = \\frac{(3.75)^1 e^{-3.75}}{1!} = 3.75 e^{-3.75}\n$$\nFor $k=2$:\n$$\nP(N(3)=2) = \\frac{(3.75)^2 e^{-3.75}}{2!} = \\frac{14.0625}{2} e^{-3.75} = 7.03125 e^{-3.75}\n$$\nSumming these probabilities:\n$$\nP(N(3)  3) = e^{-3.75} + 3.75 e^{-3.75} + 7.03125 e^{-3.75}\n$$\n$$\nP(N(3)  3) = (1 + 3.75 + 7.03125) e^{-3.75} = 11.78125 e^{-3.75}\n$$\nNow we can find the desired probability:\n$$\nP(T_3  3) = 1 - 11.78125 e^{-3.75}\n$$\nTo get the numerical value, we first calculate $e^{-3.75}$:\n$$\ne^{-3.75} \\approx 0.02351774\n$$\nNow substitute this value back into our expression:\n$$\nP(T_3  3) \\approx 1 - 11.78125 \\times 0.02351774\n$$\n$$\nP(T_3  3) \\approx 1 - 0.27706708\n$$\n$$\nP(T_3  3) \\approx 0.72293292\n$$\nThe problem asks to round the final answer to four significant figures.\n$$\nP(T_3  3) \\approx 0.7229\n$$", "answer": "$$\\boxed{0.7229}$$", "id": "1349214"}, {"introduction": "Understanding the variability of a process is as important as knowing its average behavior. This exercise explores the variance of the waiting time and introduces the powerful concept of scaling a random variable to uncover its fundamental nature [@problem_id:1903698]. By analyzing the scaled waiting time $Y = 2\\lambda T_k$, you will not only practice calculating variance but also discover a profound connection between the Gamma-distributed waiting time and the chi-squared distribution, a cornerstone of statistical hypothesis testing.", "problem": "In the field of high-energy astrophysics, particle detectors are often used to monitor the arrival of cosmic rays. A simplified model treats the arrivals of these cosmic rays as events in a Poisson process with a constant average rate of $\\lambda$ arrivals per second.\n\nLet $T_k$ be the random variable representing the waiting time, in seconds, until the $k$-th cosmic ray is detected, where $k$ is a positive integer. For data analysis purposes, this waiting time is often scaled to form a new dimensionless random variable $Y$, defined as $Y = 2\\lambda T_k$.\n\nTo evaluate the statistical fluctuations in this scaled data, a key required quantity is its variance. Determine the variance of the scaled waiting time, $\\text{Var}(Y)$, as an expression in terms of the number of arrivals, $k$.", "solution": "In a homogeneous Poisson process with constant rate $\\lambda$, the interarrival times are independent and identically distributed exponential random variables with parameter $\\lambda$. Let $X_{1},\\dots,X_{k}$ denote these interarrival times. Then the waiting time to the $k$-th arrival can be written as the sum\n$$\nT_{k}=\\sum_{i=1}^{k}X_{i}.\n$$\nFor each exponential interarrival time, the variance is\n$$\n\\text{Var}(X_{i})=\\frac{1}{\\lambda^{2}}.\n$$\nUsing independence, the variance of the sum is the sum of variances, so\n$$\n\\text{Var}(T_{k})=\\sum_{i=1}^{k}\\text{Var}(X_{i})=\\sum_{i=1}^{k}\\frac{1}{\\lambda^{2}}=\\frac{k}{\\lambda^{2}}.\n$$\nThe scaled variable is defined by $Y=2\\lambda T_{k}$. Using the variance scaling property $\\text{Var}(aX)=a^{2}\\text{Var}(X)$ for a constant $a$, we obtain\n$$\n\\text{Var}(Y)=\\text{Var}\\!\\left(2\\lambda T_{k}\\right)=(2\\lambda)^{2}\\text{Var}(T_{k})=4\\lambda^{2}\\cdot\\frac{k}{\\lambda^{2}}=4k.\n$$\nThus, the variance of the scaled waiting time depends only on $k$ and is equal to $4k$.", "answer": "$$\\boxed{4k}$$", "id": "1903698"}]}