{"hands_on_practices": [{"introduction": "This first practice problem establishes the foundational skill for analyzing any finite continuous-time Markov chain. By modeling a simple three-state server system [@problem_id:1333676], you will practice the core procedure of constructing the generator matrix $Q$ from transition rates and solving the balance equations $\\pi Q = \\mathbf{0}$ to find the long-term probabilities. Mastering this process is essential for tackling more complex systems.", "problem": "Consider a simplified model for a computer server that can be in one of three states: {1: Idle, 2: Computing, 3: Updating}. The server transitions between these states according to a continuous-time Markov chain.\nThe transitions are as follows:\n- From 'Idle' (state 1), a new task arrives, causing a transition to 'Computing' (state 2) at a rate of $3\\lambda$.\n- From 'Idle' (state 1), the system can initiate a self-update, transitioning to 'Updating' (state 3) at a rate of $\\lambda$.\n- From 'Computing' (state 2), the current task can complete, returning the server to 'Idle' (state 1) at a rate of $4\\lambda$.\n- From 'Computing' (state 2), a mandatory system patch can interrupt the task, forcing a transition to 'Updating' (state 3) at a rate of $\\lambda$.\n- From 'Updating' (state 3), the update process completes, and the server always returns to 'Idle' (state 1) at a rate of $4\\lambda$.\nNo other transitions are possible. The parameter $\\lambda$ is a positive constant representing the base rate of transitions.\n\nAssuming the system has been running for a very long time, it reaches a stationary state. Determine the stationary probability distribution vector $\\pi = (\\pi_1, \\pi_2, \\pi_3)$, where $\\pi_i$ is the long-term probability of finding the server in state $i$.", "solution": "Let the state space of the continuous-time Markov chain be $S = \\{1, 2, 3\\}$, corresponding to the states {Idle, Computing, Updating}. The stationary distribution is a probability vector $\\pi = (\\pi_1, \\pi_2, \\pi_3)$ that satisfies the equation $\\pi Q = \\mathbf{0}$, where $Q$ is the generator matrix of the chain, and the normalization condition $\\sum_{i=1}^3 \\pi_i = 1$.\n\nFirst, we construct the generator matrix $Q$. The off-diagonal elements $q_{ij}$ for $i \\neq j$ are the transition rates $\\lambda_{ij}$ from state $i$ to state $j$. The diagonal elements $q_{ii}$ are given by $q_{ii} = -\\sum_{j \\neq i} q_{ij}$. From the problem description, the transition rates are:\n$q_{12} = 3\\lambda$\n$q_{13} = \\lambda$\n$q_{21} = 4\\lambda$\n$q_{23} = \\lambda$\n$q_{31} = 4\\lambda$\n$q_{32} = 0$ (no transition from Updating to Computing)\nAll other off-diagonal rates not listed are zero ($q_{11}$, $q_{22}$, etc. are not rates).\n\nNow, we calculate the diagonal elements:\n$q_{11} = -(q_{12} + q_{13}) = -(3\\lambda + \\lambda) = -4\\lambda$\n$q_{22} = -(q_{21} + q_{23}) = -(4\\lambda + \\lambda) = -5\\lambda$\n$q_{33} = -(q_{31} + q_{32}) = -(4\\lambda + 0) = -4\\lambda$\n\nSo, the generator matrix $Q$ is:\n$$\nQ = \\begin{pmatrix}\n-4\\lambda  3\\lambda  \\lambda \\\\\n4\\lambda  -5\\lambda  \\lambda \\\\\n4\\lambda  0  -4\\lambda\n\\end{pmatrix}\n$$\n\nThe condition $\\pi Q = \\mathbf{0}$ yields a system of linear equations. We can divide by the common factor $\\lambda$ since $\\lambda  0$.\n$$\n(\\pi_1, \\pi_2, \\pi_3) \\begin{pmatrix}\n-4  3  1 \\\\\n4  -5  1 \\\\\n4  0  -4\n\\end{pmatrix} = (0, 0, 0)\n$$\nThis results in the following equations, corresponding to each column:\n1.  $-4\\pi_1 + 4\\pi_2 + 4\\pi_3 = 0$\n2.  $3\\pi_1 - 5\\pi_2 + 0\\pi_3 = 0$\n3.  $\\pi_1 + \\pi_2 - 4\\pi_3 = 0$\n\nThis system of three equations with three unknowns is linearly dependent. We can use any two of these equations along with the normalization condition $\\pi_1 + \\pi_2 + \\pi_3 = 1$.\n\nLet's use equation (2):\n$3\\pi_1 - 5\\pi_2 = 0 \\implies 5\\pi_2 = 3\\pi_1 \\implies \\pi_2 = \\frac{3}{5}\\pi_1$.\n\nNext, let's simplify equation (1) by dividing by 4:\n$-\\pi_1 + \\pi_2 + \\pi_3 = 0 \\implies \\pi_3 = \\pi_1 - \\pi_2$.\nNow, substitute the expression for $\\pi_2$ in terms of $\\pi_1$:\n$\\pi_3 = \\pi_1 - \\frac{3}{5}\\pi_1 = \\frac{2}{5}\\pi_1$.\n\nWe now have both $\\pi_2$ and $\\pi_3$ expressed in terms of $\\pi_1$. We can use the normalization condition to solve for $\\pi_1$:\n$\\pi_1 + \\pi_2 + \\pi_3 = 1$\n$\\pi_1 + \\frac{3}{5}\\pi_1 + \\frac{2}{5}\\pi_1 = 1$\nMultiplying everything by 5 to clear the denominators:\n$5\\pi_1 + 3\\pi_1 + 2\\pi_1 = 5$\n$10\\pi_1 = 5$\n$\\pi_1 = \\frac{5}{10} = \\frac{1}{2}$.\n\nNow we can find the values of $\\pi_2$ and $\\pi_3$:\n$\\pi_2 = \\frac{3}{5}\\pi_1 = \\frac{3}{5} \\left(\\frac{1}{2}\\right) = \\frac{3}{10}$.\n$\\pi_3 = \\frac{2}{5}\\pi_1 = \\frac{2}{5} \\left(\\frac{1}{2}\\right) = \\frac{2}{10} = \\frac{1}{5}$.\n\nThe stationary distribution vector is $\\pi = (\\pi_1, \\pi_2, \\pi_3) = \\left(\\frac{1}{2}, \\frac{3}{10}, \\frac{1}{5}\\right)$.\nWe can verify this result with the third equation from the system: $\\pi_1 + \\pi_2 - 4\\pi_3 = \\frac{1}{2} + \\frac{3}{10} - 4\\left(\\frac{1}{5}\\right) = \\frac{5}{10} + \\frac{3}{10} - \\frac{8}{10} = 0$, which holds true. The sum of probabilities is $\\frac{1}{2} + \\frac{3}{10} + \\frac{1}{5} = \\frac{5}{10} + \\frac{3}{10} + \\frac{2}{10} = \\frac{10}{10} = 1$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2}  \\frac{3}{10}  \\frac{1}{5} \\end{pmatrix}}$$", "id": "1333676"}, {"introduction": "Many real-world systems, from queues to population dynamics, can be modeled as birth-death processes, a special class of Markov chain where transitions only occur to adjacent states. This exercise [@problem_id:1333674] demonstrates how to leverage this special structure, using detailed balance equations to find the stationary distribution more efficiently than the general matrix method. You will explore how arrival ($\\lambda$) and service ($\\mu$) rates determine the long-run behavior of a capacity-constrained system.", "problem": "Consider a simplified model for a small web server that can handle a maximum of two concurrent user sessions. Let $N(t)$ be the number of active sessions at time $t$. The state space for the number of sessions is therefore $\\{0, 1, 2\\}$.\n\nNew session requests arrive according to a Poisson process with a constant rate $\\lambda > 0$. If the server is not at full capacity (i.e., if $N(t)  2$), an incoming request is accepted, and the number of active sessions increases by one. If the server is at full capacity ($N(t) = 2$), any new incoming requests are rejected and have no effect on the system.\n\nEach active session terminates independently of all other sessions and new session arrivals. The time until a single session terminates is exponentially distributed with rate $\\mu > 0$. This means that if there are $n$ active sessions, the total rate at which sessions terminate is $n\\mu$.\n\nAssuming the system has been running for a long time and has reached a statistical equilibrium, determine the long-run probabilities for the number of active sessions. Let these probabilities be $p_0$, $p_1$, and $p_2$ for having 0, 1, and 2 sessions, respectively.\n\nYour answer should be in the form of a row vector $(p_0, p_1, p_2)$, where each component is an expression in terms of the parameters $\\lambda$ and $\\mu$.", "solution": "We model $\\{N(t)\\}$ as a continuous-time birth-death Markov chain on the state space $\\{0, 1, 2\\}$. The birth (arrival) rates are $\\lambda_0 = \\lambda$, $\\lambda_1 = \\lambda$, and $\\lambda_2 = 0$ (blocked at capacity). The death (service completion) rates are $\\mu_1 = \\mu$ and $\\mu_2 = 2\\mu$.\n\nIn steady state, for a birth-death chain, detailed balance holds:\n$$\np_n \\lambda_n = p_{n+1} \\mu_{n+1}.\n$$\nApplying this,\n$$\np_0 \\lambda = p_1 \\mu \\quad\\Rightarrow\\quad p_1 = \\frac{\\lambda}{\\mu} p_0,\n$$\n$$\np_1 \\lambda = p_2 \\cdot 2\\mu \\quad\\Rightarrow\\quad p_2 = \\frac{\\lambda}{2\\mu} p_1 = \\frac{\\lambda^2}{2\\mu^2} p_0.\n$$\n\nUse normalization $\\sum_{n=0}^{2} p_n = 1$:\n$$\np_0 + p_1 + p_2 = p_0 \\left(1 + \\frac{\\lambda}{\\mu} + \\frac{\\lambda^2}{2\\mu^2}\\right) = 1,\n$$\nhence\n$$\np_0 = \\frac{1}{1+\\frac{\\lambda}{\\mu}+\\frac{\\lambda^2}{2\\mu^2}} = \\frac{2\\mu^2}{2\\mu^2 + 2\\lambda\\mu + \\lambda^2}.\n$$\nThen\n$$\np_1 = \\frac{\\lambda}{\\mu}p_0 = \\frac{2\\lambda\\mu}{2\\mu^2 + 2\\lambda\\mu + \\lambda^2},\\qquad\np_2 = \\frac{\\lambda^2}{2\\mu^2}p_0 = \\frac{\\lambda^2}{2\\mu^2 + 2\\lambda\\mu + \\lambda^2}.\n$$\n\nTherefore, the long-run probability vector is\n$$\n\\begin{pmatrix}\n\\frac{2\\mu^2}{2\\mu^2+2\\lambda\\mu+\\lambda^2} \n\\frac{2\\lambda\\mu}{2\\mu^2+2\\lambda\\mu+\\lambda^2} \n\\frac{\\lambda^2}{2\\mu^2+2\\lambda\\mu+\\lambda^2}\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{2\\mu^{2}}{2\\mu^{2}+2\\lambda\\mu+\\lambda^{2}}  \\frac{2\\lambda\\mu}{2\\mu^{2}+2\\lambda\\mu+\\lambda^{2}}  \\frac{\\lambda^{2}}{2\\mu^{2}+2\\lambda\\mu+\\lambda^{2}}\\end{pmatrix}}$$", "id": "1333674"}, {"introduction": "Moving beyond systems with a small, fixed number of states, this problem challenges you to analyze a network whose size is a variable parameter, $N$. By modeling a data packet's journey through a linear network [@problem_id:1333689], you will learn to identify and solve recurrence relations that describe the stationary probabilities. This approach is crucial for understanding the scalability and long-term behavior of larger, structured systems.", "problem": "Consider a simplified model of a data packet traversing a linear communication network. The network consists of a source node, labeled 0, and a sequence of $N$ subsequent nodes, labeled $1, 2, \\dots, N$. The location of the packet in this network can be modeled as a Continuous-Time Markov Chain (CTMC) on the state space $S = \\{0, 1, \\dots, N\\}$.\n\nThe dynamics of the packet's movement are as follows:\n- From any node $i$ where $0 \\le i  N$, the packet attempts to move forward to the next node, $i+1$. This transition occurs at a constant rate $\\lambda > 0$.\n- From any node $i$ where $1 \\le i \\le N$, there is a risk of the packet being dropped. If dropped, the packet is instantaneously retransmitted from the source node, 0. This \"drop and return\" event occurs at a constant rate $\\mu > 0$.\n- The packet cannot be dropped from the source node 0. Once the packet reaches node $N$, it can only be dropped and returned to node 0.\n\nAssuming the process has been running for a long time and has reached a stationary state, determine the probability of finding the packet at the final destination, node $N$. Your answer should be a closed-form analytic expression in terms of $N$, $\\lambda$, and $\\mu$.", "solution": "Model the packet location as a CTMC on $S=\\{0, 1, \\dots, N\\}$ with generator entries:\n- For $i=0$: $q_{0,1}=\\lambda$, $q_{0,0}=-\\lambda$.\n- For $1 \\le i \\le N-1$: $q_{i,i+1}=\\lambda$, $q_{i,0}=\\mu$, $q_{i,i}=-(\\lambda+\\mu)$.\n- For $i=N$: $q_{N,0}=\\mu$, $q_{N,N}=-\\mu$.\n\nLet $\\pi_i$ denote the stationary probability of state $i$. Stationarity requires $\\pi Q = 0$ and $\\sum_{i=0}^{N}\\pi_i = 1$. Writing the global balance at each state gives:\n- For $i=0$: inflow equals outflow,\n$$\n\\mu\\sum_{i=1}^{N}\\pi_i = \\lambda \\pi_0.\n$$\n- For $1 \\le i \\le N-1$: the only inflow to $i$ is from $i-1$ and outflows are to $0$ and $i+1$,\n$$\n\\lambda \\pi_{i-1} = (\\lambda+\\mu)\\pi_i.\n$$\n- For $i=N$: the only inflow is from $N-1$ and outflow is to $0$,\n$$\n\\lambda \\pi_{N-1} = \\mu \\pi_N.\n$$\n\nDefine $r = \\frac{\\lambda}{\\lambda+\\mu}$. The recursion for $1 \\le i \\le N-1$ yields\n$$\n\\pi_i = r^i \\pi_0.\n$$\nUsing the $i=N$ balance,\n$$\n\\pi_N = \\frac{\\lambda}{\\mu}\\pi_{N-1} = \\frac{\\lambda}{\\mu}r^{N-1}\\pi_0.\n$$\n\nNormalize using $\\sum_{i=0}^{N}\\pi_i = 1$:\n$$\n1 = \\pi_0\\left(\\sum_{i=0}^{N-1}r^{i}+\\frac{\\lambda}{\\mu}r^{N-1}\\right)\n= \\pi_0\\left(\\frac{1-r^{N}}{1-r}+\\frac{\\lambda}{\\mu}r^{N-1}\\right).\n$$\nSince $1-r = \\frac{\\mu}{\\lambda+\\mu}$ and $r = \\frac{\\lambda}{\\lambda+\\mu}$,\n$$\n\\frac{1-r^{N}}{1-r} = \\frac{\\lambda+\\mu}{\\mu}(1-r^{N}),\n$$\nso\n$$\n1 = \\pi_0\\left(\\frac{\\lambda+\\mu}{\\mu}(1-r^{N})+\\frac{\\lambda}{\\mu}r^{N-1}\\right)\n= \\pi_0\\cdot\\frac{\\lambda+\\mu}{\\mu},\n$$\nbecause $-(\\lambda+\\mu)r^{N}+\\lambda r^{N-1} = r^{N-1}\\left(-(\\lambda+\\mu)r+\\lambda\\right) = 0$. Hence\n$$\n\\pi_0 = \\frac{\\mu}{\\lambda+\\mu}.\n$$\nTherefore\n$$\n\\pi_N = \\frac{\\lambda}{\\mu}r^{N-1}\\pi_0 = \\frac{\\lambda}{\\lambda+\\mu}r^{N-1} = r^{N} = \\left(\\frac{\\lambda}{\\lambda+\\mu}\\right)^{N}.\n$$\nThis is the stationary probability of being at node $N$.", "answer": "$$\\boxed{\\left(\\frac{\\lambda}{\\lambda+\\mu}\\right)^{N}}$$", "id": "1333689"}]}