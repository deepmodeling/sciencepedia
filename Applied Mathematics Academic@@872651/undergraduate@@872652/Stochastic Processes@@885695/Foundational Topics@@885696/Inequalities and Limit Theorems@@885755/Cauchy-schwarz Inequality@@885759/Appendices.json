{"hands_on_practices": [{"introduction": "We begin our hands-on exploration in the familiar setting of three-dimensional Euclidean space. This problem demonstrates how the Cauchy-Schwarz inequality is not just a theoretical bound but a practical tool for solving constrained optimization problems. By re-framing the question in terms of vector dot products, we can find the maximum value of a function without resorting to more complex methods like Lagrange multipliers, offering an elegant geometric solution instead [@problem_id:945977].", "problem": "Find the maximum value of the linear form $ x_1 + 2x_2 + 3x_3 $ over real numbers $ x_1, x_2, x_3 $ subject to the constraint $ x_1^2 + x_2^2 + x_3^2 = 1 $.", "solution": "To maximize the linear form $ x_1 + 2x_2 + 3x_3 $ subject to the constraint $ x_1^2 + x_2^2 + x_3^2 = 1 $, we use the Cauchy-Schwarz inequality. \n\n### Step 1: Define vectors for the dot product\nLet $ \\mathbf{a} = (1, 2, 3) $ and $ \\mathbf{x} = (x_1, x_2, x_3) $. The linear form to maximize is the dot product $ \\mathbf{a} \\cdot \\mathbf{x} $, and the constraint is $ \\|\\mathbf{x}\\| = 1 $ (since $ \\|\\mathbf{x}\\|^2 = x_1^2 + x_2^2 + x_3^2 = 1 $).\n\n### Step 2: Apply the Cauchy-Schwarz inequality\nThe Cauchy-Schwarz inequality states $ |\\mathbf{a} \\cdot \\mathbf{x}| \\leq \\|\\mathbf{a}\\| \\|\\mathbf{x}\\| $. For the constraint $ \\|\\mathbf{x}\\| = 1 $, this simplifies to $ |\\mathbf{a} \\cdot \\mathbf{x}| \\leq \\|\\mathbf{a}\\| $. Equality holds when $ \\mathbf{x} $ is parallel to $ \\mathbf{a} $, so the maximum value of $ \\mathbf{a} \\cdot \\mathbf{x} $ is $ \\|\\mathbf{a}\\| $.\n\n### Step 3: Compute $ \\|\\mathbf{a}\\| $\nThe norm of $ \\mathbf{a} $ is:\n$$\n\\|\\mathbf{a}\\| = \\sqrt{1^2 + 2^2 + 3^2} = \\sqrt{1 + 4 + 9} = \\sqrt{14}\n$$\n\nThus, the maximum value of the linear form is $ \\sqrt{14} $.", "answer": "$$\\boxed{\\sqrt{14}}$$", "id": "945977"}, {"introduction": "Next, we generalize the inequality from finite-dimensional vectors to the realm of random variables. This exercise applies the Cauchy-Schwarz inequality to the Poisson process, a fundamental model in the study of stochastic processes [@problem_id:1287492]. Here, you will see how the concept of an inner product extends to the expectation of a product of random variables, providing a powerful method to establish sharp bounds on statistical quantities and deepen your understanding of the structure of probability spaces.", "problem": "A stochastic process that models the number of times a certain event occurs over time is known as a counting process. One of the most fundamental counting processes is the Poisson process, denoted by $\\{N(t) : t \\ge 0\\}$, which counts the cumulative number of events that have occurred up to time $t$. This process is characterized by a constant positive rate, $\\lambda$, which represents the average number of events per unit time. For a Poisson process, the random variable $N(t)$ follows a Poisson distribution with a mean of $\\lambda t$.\n\nGiven two distinct positive time instances, $t_1 > 0$ and $t_2 > 0$, we are interested in the statistical relationship between the number of counts at these two times. Determine a tight upper bound for the expected value of the geometric mean of the counts, i.e., find an upper bound for the quantity $E[\\sqrt{N(t_1) N(t_2)}]$. Your final answer should be a closed-form analytic expression in terms of $\\lambda$, $t_1$, and $t_2$.", "solution": "Let $N(t)$ be a Poisson process with rate $\\lambda>0$. For each $t>0$, the marginal distribution is $N(t)\\sim \\text{Poisson}(\\lambda t)$, so its mean is\n$$\n\\mathbb{E}[N(t)] = \\lambda t.\n$$\nWe seek an upper bound for $\\mathbb{E}\\big[\\sqrt{N(t_{1})N(t_{2})}\\big]$ when $t_{1}>0$ and $t_{2}>0$.\n\nUse the Cauchy-Schwarz inequality for square-integrable random variables $U$ and $V$:\n$$\n\\mathbb{E}[UV] \\le \\sqrt{\\mathbb{E}[U^{2}]\\,\\mathbb{E}[V^{2}]}.\n$$\nSet $U=\\sqrt{N(t_{1})}$ and $V=\\sqrt{N(t_{2})}$. Then\n$$\n\\mathbb{E}\\big[\\sqrt{N(t_{1})N(t_{2})}\\big]\n= \\mathbb{E}[UV]\n\\le \\sqrt{\\mathbb{E}[U^{2}]\\,\\mathbb{E}[V^{2}]}\n= \\sqrt{\\mathbb{E}[N(t_{1})]\\;\\mathbb{E}[N(t_{2})]}.\n$$\nUsing $\\mathbb{E}[N(t)]=\\lambda t$, we obtain\n$$\n\\mathbb{E}\\big[\\sqrt{N(t_{1})N(t_{2})}\\big] \\le \\sqrt{(\\lambda t_{1})(\\lambda t_{2})} = \\lambda \\sqrt{t_{1}t_{2}}.\n$$\n\nThis bound is tight in the sense that it cannot be improved using only the marginal means: equality is achieved when $t_{1}=t_{2}$, because then $N(t_{1})=N(t_{2})$ almost surely and\n$$\n\\mathbb{E}\\big[\\sqrt{N(t_{1})N(t_{2})}\\big] = \\mathbb{E}[N(t_{1})] = \\lambda t_{1} = \\lambda \\sqrt{t_{1}t_{2}}.\n$$\nFor $t_{1}\\neq t_{2}$, the inequality remains valid and is the sharpest general upper bound expressible solely in terms of $\\lambda$, $t_{1}$, and $t_{2}$.", "answer": "$$\\boxed{\\lambda \\sqrt{t_{1} t_{2}}}$$", "id": "1287492"}, {"introduction": "Our final practice problem takes the concept to its full generality by exploring its application in an infinite-dimensional function space, specifically the space of square-integrable functions $L^2[-1, 1]$. This advanced exercise asks you to minimize the \"energy\" of a function, defined by an integral, subject to certain constraints [@problem_id:945877]. Solving this problem provides insight into the powerful methods of functional analysis and illustrates how the Cauchy-Schwarz inequality serves as a unifying principle across different mathematical domains, from simple vectors to continuous functions.", "problem": "Consider the space of square-integrable functions on the interval $[-1, 1]$. Find the minimum value of $\\int_{-1}^{1} [f(x)]^2  dx$ over all functions $f \\in L^2[-1,1]$ satisfying the conditions:  \n\n$$  \n\\int_{-1}^{1} f(x)  dx = 0 \\quad \\text{and} \\quad \\int_{-1}^{1} x f(x)  dx = 1.  \n$$\n  \nThe final answer should be a single real number.", "solution": "To find the minimum of $\\int_{-1}^{1} f(x)^2  dx$ subject to the constraints $\\int_{-1}^{1} f(x)  dx = 0$ and $\\int_{-1}^{1} x f(x)  dx = 1$, we use the Cauchy-Schwarz inequality for integrals. For any real numbers $\\alpha$ and $\\beta$, define the function $g(x) = \\alpha + \\beta x$. The inner product of $f$ and $g$ is:  \n\n$$  \n\\int_{-1}^{1} f(x) g(x)  dx = \\int_{-1}^{1} f(x) (\\alpha + \\beta x)  dx = \\alpha \\int_{-1}^{1} f(x)  dx + \\beta \\int_{-1}^{1} x f(x)  dx = \\alpha \\cdot 0 + \\beta \\cdot 1 = \\beta.  \n$$\n  \nBy the Cauchy-Schwarz inequality:  \n\n$$  \n\\left( \\int_{-1}^{1} f(x) g(x)  dx \\right)^2 \\leq \\left( \\int_{-1}^{1} [f(x)]^2  dx \\right) \\left( \\int_{-1}^{1} [g(x)]^2  dx \\right),  \n$$\n  \nwhich gives:  \n\n$$  \n\\beta^2 \\leq \\left( \\int_{-1}^{1} f(x)^2  dx \\right) \\left( \\int_{-1}^{1} (\\alpha + \\beta x)^2  dx \\right).  \n$$\n  \nTherefore,  \n\n$$  \n\\int_{-1}^{1} f(x)^2  dx \\geq \\frac{\\beta^2}{\\int_{-1}^{1} (\\alpha + \\beta x)^2  dx}.  \n$$\n  \nThis inequality holds for all $\\alpha, \\beta$ (not both zero). To obtain the best lower bound, we maximize the right-hand side over $\\alpha$ and $\\beta$. Since the expression is homogeneous, set $u = \\alpha / \\beta$ (assuming $\\beta \\neq 0$):  \n\n$$  \n\\int_{-1}^{1} f(x)^2  dx \\geq \\frac{\\beta^2}{\\int_{-1}^{1} (\\beta u + \\beta x)^2  dx} = \\frac{\\beta^2}{\\beta^2 \\int_{-1}^{1} (u + x)^2  dx} = \\frac{1}{\\int_{-1}^{1} (u + x)^2  dx}.  \n$$\n  \nDefine $I(u) = \\int_{-1}^{1} (u + x)^2  dx$. Then:  \n\n$$  \nI(u) = \\int_{-1}^{1} (u^2 + 2u x + x^2)  dx = \\left[ u^2 x + u x^2 + \\frac{x^3}{3} \\right]_{-1}^{1}.  \n$$\n  \nEvaluating the definite integral:  \n\n$$  \nI(u) = \\left( u^2 (1) + u (1)^2 + \\frac{1^3}{3} \\right) - \\left( u^2 (-1) + u (-1)^2 + \\frac{(-1)^3}{3} \\right) = \\left( u^2 + u + \\frac{1}{3} \\right) - \\left( -u^2 + u - \\frac{1}{3} \\right) = 2u^2 + \\frac{2}{3}.  \n$$\n  \nThe minimum value of $I(u)$ occurs when $u = 0$, giving $I(0) = \\frac{2}{3}$. Thus,  \n\n$$  \n\\int_{-1}^{1} f(x)^2  dx \\geq \\frac{1}{\\frac{2}{3}} = \\frac{3}{2}.  \n$$\n  \nEquality holds when $f$ is proportional to $g$ and the constraints are satisfied. At $u = 0$, $g(x) = \\beta x$. Set $f(x) = c x$. Then:  \n- $\\int_{-1}^{1} f(x)  dx = \\int_{-1}^{1} c x  dx = c \\left[ \\frac{x^2}{2} \\right]_{-1}^{1} = c \\left( \\frac{1}{2} - \\frac{1}{2} \\right) = 0$, satisfying the first constraint.  \n- $\\int_{-1}^{1} x f(x)  dx = \\int_{-1}^{1} x (c x)  dx = c \\int_{-1}^{1} x^2  dx = c \\left[ \\frac{x^3}{3} \\right]_{-1}^{1} = c \\left( \\frac{1}{3} - \\left(-\\frac{1}{3}\\right) \\right) = c \\left( \\frac{2}{3} \\right) = 1$, so $c = \\frac{3}{2}$.  \nThen, $\\int_{-1}^{1} \\left( \\frac{3}{2} x \\right)^2  dx = \\frac{9}{4} \\int_{-1}^{1} x^2  dx = \\frac{9}{4} \\cdot \\frac{2}{3} = \\frac{3}{2}$, achieving the bound. Therefore, the minimum is $\\frac{3}{2}$.", "answer": "$$ \\boxed{\\frac{3}{2}} $$", "id": "945877"}]}