{"hands_on_practices": [{"introduction": "Our first practice delves into the fundamental mechanics of joint probability for discrete random variables. By considering two independent signals, we explore how to determine the joint probability of new parameters derived from themâ€”their sum and absolute difference [@problem_id:1314022]. This exercise is crucial for building intuition about how transformations of random variables create new probabilistic structures and for mastering the combinatorial methods used to analyze them.", "problem": "In a simplified model for a digital signal processing system, two independent random integer signals, $X$ and $Y$, are generated. Both $X$ and $Y$ are drawn from a discrete uniform distribution over the set $\\{1, 2, 3, 4, 5\\}$. The system then computes two new parameters from these signals: their sum, $S = X + Y$, and their absolute difference, $D = |X - Y|$.\n\nAn analyst is interested in the joint statistical properties of $S$ and $D$. Calculate the value of the joint probability mass function $P(S=s, D=d)$ for the specific case where the sum is $s=7$ and the absolute difference is $d=3$.\n\nProvide your answer as an exact fraction.", "solution": "Let the two independent random variables be $X$ and $Y$. Both variables are drawn from a discrete uniform distribution over the set $\\mathcal{A} = \\{1, 2, 3, 4, 5\\}$. The size of this set is $|\\mathcal{A}| = 5$.\n\nSince $X$ and $Y$ are independent and uniformly distributed on $\\mathcal{A}$, the probability of $X$ taking any specific value $x \\in \\mathcal{A}$ is $P(X=x) = \\frac{1}{5}$. Similarly, $P(Y=y) = \\frac{1}{5}$ for any $y \\in \\mathcal{A}$.\n\nThe sample space of outcomes consists of all possible pairs $(x, y)$, where $x, y \\in \\mathcal{A}$. The total number of possible outcomes is $5 \\times 5 = 25$. Due to the independence of $X$ and $Y$, the probability of any specific pair $(x, y)$ occurring is the product of their individual probabilities:\n$$P(X=x, Y=y) = P(X=x) P(Y=y) = \\frac{1}{5} \\times \\frac{1}{5} = \\frac{1}{25}$$\nEach of the 25 pairs is equally likely.\n\nWe are asked to find the probability of the joint event where the sum $S = X + Y$ is 7 and the absolute difference $D = |X - Y|$ is 3. We need to find all pairs $(x, y)$ from the sample space that simultaneously satisfy these two conditions:\n1. $x + y = 7$\n2. $|x - y| = 3$\n\nLet's analyze the second condition, $|x-y|=3$. This implies two possibilities:\n- Case A: $x - y = 3$, which means $x = y + 3$.\n- Case B: $x - y = -3$, which means $y = x + 3$.\n\nWe can now substitute these into the first condition, $x + y = 7$.\n\nFor Case A ($x = y + 3$):\nSubstitute $x$ in the sum equation:\n$(y + 3) + y = 7$\n$2y + 3 = 7$\n$2y = 4$\n$y = 2$\nNow, find the corresponding value of $x$:\n$x = y + 3 = 2 + 3 = 5$\nThis gives us the pair $(x, y) = (5, 2)$. We must verify that both $x=5$ and $y=2$ are in the set $\\mathcal{A} = \\{1, 2, 3, 4, 5\\}$. They are, so $(5, 2)$ is a valid outcome.\n\nFor Case B ($y = x + 3$):\nSubstitute $y$ in the sum equation:\n$x + (x + 3) = 7$\n$2x + 3 = 7$\n$2x = 4$\n$x = 2$\nNow, find the corresponding value of $y$:\n$y = x + 3 = 2 + 3 = 5$\nThis gives us the pair $(x, y) = (2, 5)$. We must verify that both $x=2$ and $y=5$ are in the set $\\mathcal{A}$. They are, so $(2, 5)$ is another valid outcome.\n\nTherefore, the event $\\{S=7, D=3\\}$ corresponds to the set of outcomes $\\{(2, 5), (5, 2)\\}$. There are two favorable outcomes.\n\nThe probability of the joint event is the sum of the probabilities of these individual outcomes. Since each outcome has a probability of $\\frac{1}{25}$, the total probability is:\n$$P(S=7, D=3) = P((X,Y)=(2,5)) + P((X,Y)=(5,2))$$\n$$P(S=7, D=3) = \\frac{1}{25} + \\frac{1}{25} = \\frac{2}{25}$$", "answer": "$$\\boxed{\\frac{2}{25}}$$", "id": "1314022"}, {"introduction": "Building upon the basics, this practice introduces the powerful concept of conditioning, which allows us to update our knowledge about one variable given information about another. We will analyze a hypothetical model linking the number of sales calls to the number of successful sales to calculate a conditional expectation [@problem_id:1314031]. This problem illustrates the essential procedure for moving from a joint probability mass function to making specific, conditional predictions about dependent events.", "problem": "A data scientist at a marketing firm is modeling the relationship between the number of cold calls an agent makes in a day, denoted by the random variable $C$, and the number of sales they secure, denoted by the random variable $S$. After analyzing a large dataset, she proposes a joint probability mass function (PMF) to describe this relationship. The proposed joint PMF is given by:\n$$\np_{C,S}(c,s) = K \\frac{s}{c!}\n$$\nfor integers $c \\geq 1$ and $0 \\leq s \\leq c$. For any other combination of $c$ and $s$, $p_{C,S}(c,s) = 0$. In this model, $K$ is a normalization constant that ensures the probabilities sum to one.\n\nYour task is to calculate the expected number of sales on a day when it is known that exactly 20 calls were made. Express your answer as a single numerical value, rounded to four significant figures.", "solution": "We are asked to compute the conditional expectation $E[S \\mid C=20]$ given the joint PMF\n$$\np_{C,S}(c,s)=K \\frac{s}{c!}, \\quad c \\geq 1,\\; 0 \\leq s \\leq c,\n$$\nand zero otherwise. Use the definition of conditional PMF:\n$$\np_{S \\mid C}(s \\mid c)=\\frac{p_{C,S}(c,s)}{p_{C}(c)}.\n$$\nFirst compute the marginal PMF of $C$ by summing over all valid $s$:\n$$\np_{C}(c)=\\sum_{s=0}^{c} p_{C,S}(c,s)=\\sum_{s=0}^{c} K \\frac{s}{c!}=\\frac{K}{c!}\\sum_{s=0}^{c} s=\\frac{K}{c!}\\cdot \\frac{c(c+1)}{2}.\n$$\nHence, for $s=0,1,\\dots,c$,\n$$\np_{S \\mid C}(s \\mid c)=\\frac{K \\frac{s}{c!}}{\\frac{K}{c!}\\cdot \\frac{c(c+1)}{2}}=\\frac{2s}{c(c+1)}.\n$$\nThis is a valid PMF since\n$$\n\\sum_{s=0}^{c} \\frac{2s}{c(c+1)}=\\frac{2}{c(c+1)}\\sum_{s=0}^{c} s=\\frac{2}{c(c+1)}\\cdot \\frac{c(c+1)}{2}=1.\n$$\nNow compute the conditional expectation using the discrete expectation formula:\n$$\nE[S \\mid C=c]=\\sum_{s=0}^{c} s \\, p_{S \\mid C}(s \\mid c)=\\sum_{s=0}^{c} s \\cdot \\frac{2s}{c(c+1)}=\\frac{2}{c(c+1)}\\sum_{s=0}^{c} s^{2}.\n$$\nUsing the identity $\\sum_{s=0}^{c} s^{2}=\\frac{c(c+1)(2c+1)}{6}$, we obtain\n$$\nE[S \\mid C=c]=\\frac{2}{c(c+1)}\\cdot \\frac{c(c+1)(2c+1)}{6}=\\frac{2c+1}{3}.\n$$\nSubstituting $c=20$ gives\n$$\nE[S \\mid C=20]=\\frac{2\\cdot 20+1}{3}=\\frac{41}{3}\\approx 13.666\\dots\n$$\nRounded to four significant figures, this is $13.67$.", "answer": "$$\\boxed{13.67}$$", "id": "1314031"}, {"introduction": "To complete our exploration, we transition from discrete sums to continuous integrals by tackling a problem in a three-dimensional space. We will find the conditional expectation of one coordinate of a point chosen uniformly from a tetrahedron, given the other two coordinates [@problem_id:1314007]. This practice solidifies the concept of conditioning by demonstrating its application in a continuous setting and highlights the geometric intuition behind slicing a joint density function to obtain a conditional distribution.", "problem": "A point with coordinates $(X,Y,Z)$ is generated according to a uniform probability distribution over a specific region in three-dimensional Euclidean space. This region is a solid tetrahedron defined by four vertices: the origin $(0,0,0)$, and the points $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$ on the coordinate axes. The random variables $X$, $Y$, and $Z$ represent the coordinates of this point.\n\nDetermine the conditional expectation of the random variable $Z$, given that the random variables $X$ and $Y$ have taken on the specific values $x$ and $y$, respectively. This quantity is denoted as $E[Z|X=x, Y=y]$. Your answer should be an expression in terms of $x$ and $y$, valid for all $(x,y)$ where this conditional expectation is well-defined.", "solution": "The solid tetrahedron is the set $T=\\{(x,y,z): x\\geq 0,\\ y\\geq 0,\\ z\\geq 0,\\ x+y+z\\leq 1\\}$. A uniform distribution on $T$ has a joint density of the form $f_{X,Y,Z}(x,y,z)=c$ for $(x,y,z)\\in T$ and $0$ otherwise, where $c$ is a positive normalization constant.\n\nFor given $(x,y)$, the conditional density of $Z$ is defined by\n$$\nf_{Z\\mid X,Y}(z\\mid x,y)=\\frac{f_{X,Y,Z}(x,y,z)}{f_{X,Y}(x,y)},\n$$\nwhenever $f_{X,Y}(x,y)0$. The marginal $f_{X,Y}(x,y)$ is obtained by integrating out $z$ over the feasible $z$ given $(x,y)$:\n$$\nf_{X,Y}(x,y)=\\int_{-\\infty}^{\\infty} f_{X,Y,Z}(x,y,z)\\,dz\n= \\int_{0}^{1-x-y} c\\,dz,\n$$\nwhich is valid when $x\\geq 0$, $y\\geq 0$, and $x+y\\leq 1$ (otherwise $f_{X,Y}(x,y)=0$). Thus,\n$$\nf_{X,Y}(x,y)=c\\,(1-x-y)\\quad \\text{for } x\\geq 0,\\ y\\geq 0,\\ x+y\\leq 1.\n$$\nTherefore, for such $(x,y)$ the conditional density is\n$$\nf_{Z\\mid X,Y}(z\\mid x,y)=\\frac{c}{c\\,(1-x-y)}=\\frac{1}{1-x-y},\\quad 0\\leq z\\leq 1-x-y,\n$$\nand zero otherwise. Hence, $Z\\mid (X=x,Y=y)$ is uniformly distributed on the interval $[0,\\,1-x-y]$.\n\nThe conditional expectation is then the mean of a uniform distribution on $[0,\\,1-x-y]$:\n$$\nE[Z\\mid X=x,Y=y]=\\int_{0}^{1-x-y} z\\,\\frac{1}{1-x-y}\\,dz\n= \\left.\\frac{z^{2}}{2(1-x-y)}\\right|_{0}^{1-x-y}\n= \\frac{1-x-y}{2},\n$$\nvalid for $x\\geq 0$, $y\\geq 0$, $x+y\\leq 1$ (including the boundary where it equals $0$ when $1-x-y=0$).", "answer": "$$\\boxed{\\frac{1 - x - y}{2}}$$", "id": "1314007"}]}