{"hands_on_practices": [{"introduction": "The best way to begin understanding a powerful tool like the Euler-Lagrange equation is to apply it to its simplest form. This first exercise explores a functional that depends only on the derivative of the path, $y'(x)$, which greatly simplifies the governing equation [@problem_id:2141518]. By solving this problem, you will see the core mechanism of variational calculus in action and discover how it confirms our intuition that the simplest extremal path is often a straight line.", "problem": "Consider a physical system whose state is described by a function $y(x)$ over an interval $[a, b]$. The \"action\" of the system is given by a functional $J[y]$, which is an integral that depends on the path taken by $y(x)$. For this particular system, the action is defined as:\n$$\nJ[y] = \\int_{a}^{b} (y'(x))^3 \\, dx\n$$\nwhere $y'(x)$ is the derivative of $y(x)$ with respect to $x$.\n\nWe seek the path $y(x)$ that extremizes this action. The path must satisfy the fixed boundary conditions $y(a) = y_a$ and $y(b) = y_b$, where $a, b, y_a,$ and $y_b$ are given real constants with $a \\neq b$.\n\nDetermine the function $y(x)$ that extremizes the functional $J[y]$. Express your final answer for $y(x)$ as a single closed-form analytic expression in terms of $x$, $a$, $b$, $y_a$, and $y_b$.", "solution": "We are to extremize the functional\n$$\nJ[y] = \\int_{a}^{b} (y'(x))^{3} \\, dx,\n$$\nsubject to the fixed endpoints $y(a)=y_{a}$ and $y(b)=y_{b}$. Let $L(y,y',x)=(y')^{3}$. The necessary condition for an extremum with fixed endpoints is the Euler–Lagrange equation\n$$\n\\frac{\\partial L}{\\partial y} - \\frac{d}{dx}\\left(\\frac{\\partial L}{\\partial y'}\\right) = 0.\n$$\nSince $L$ depends only on $y'$ and not on $y$, we have\n$$\n\\frac{\\partial L}{\\partial y} = 0, \\qquad \\frac{\\partial L}{\\partial y'} = 3\\,(y')^{2}.\n$$\nTherefore,\n$$\n-\\frac{d}{dx}\\left(3\\,(y')^{2}\\right)=0 \\quad \\Longrightarrow \\quad \\frac{d}{dx}\\left(3\\,(y')^{2}\\right)=0.\n$$\nIntegrating with respect to $x$ gives\n$$\n3\\,(y')^{2} = C,\n$$\nwhere $C$ is a constant. Hence $(y')^{2}$ is constant, which implies $y'$ is constant. Denote $y'(x)=m$ with $m$ a real constant. Integrating once,\n$$\ny(x) = m x + d,\n$$\nwhere $d$ is another constant. Imposing the boundary conditions $y(a)=y_{a}$ and $y(b)=y_{b}$ yields\n$$\ny_{a} = m a + d, \\qquad y_{b} = m b + d.\n$$\nSubtracting these equations gives\n$$\ny_{b} - y_{a} = m\\,(b - a) \\quad \\Longrightarrow \\quad m = \\frac{y_{b} - y_{a}}{b - a}.\n$$\nSubstituting back, we find\n$$\nd = y_{a} - m a = y_{a} - a\\,\\frac{y_{b} - y_{a}}{b - a}.\n$$\nTherefore,\n$$\ny(x) = y_{a} + \\frac{y_{b} - y_{a}}{b - a}\\,(x - a).\n$$\nThis linear function satisfies the Euler–Lagrange equation and the fixed boundary conditions, and hence is the extremal for the given functional. Depending on the sign of the slope, the extremum may be a minimum, maximum, or a saddle, but the extremizing path itself is uniquely determined by the boundary data as above.", "answer": "$$\\boxed{y_{a}+\\frac{y_{b}-y_{a}}{b-a}\\,(x-a)}$$", "id": "2141518"}, {"introduction": "Having mastered a simplified case, we now advance to a scenario where the system's behavior depends on both the path $y(x)$ and its slope $y'(x)$. This practice requires the use of the full Euler-Lagrange equation, engaging all its components [@problem_id:2141487]. It serves as a perfect demonstration of how the partial derivatives with respect to $y$ and $y'$ interact to define the differential equation that the extremal path must satisfy.", "problem": "A physical system's state is described by a function $y(x)$ over the domain $x \\in [0, 1]$. The behavior of the system is governed by the principle of least action, which requires that a certain integral quantity, denoted by $J$, is made stationary. The integral is defined as:\n$$J[y] = \\int_0^1 \\left( \\left(\\frac{dy}{dx}\\right)^2 + y \\frac{dy}{dx} \\right) dx$$\nThe system is constrained by fixed boundary conditions, such that the function $y(x)$ must satisfy $y(0) = 0$ and $y(1) = 2$.\n\nDetermine the specific function $y(x)$ that makes the integral $J$ stationary under these conditions.", "solution": "We consider the functional with fixed endpoints:\n$$J[y] = \\int_{0}^{1} \\left( \\left(\\frac{dy}{dx}\\right)^{2} + y \\frac{dy}{dx} \\right) dx,$$\nsubject to $y(0)=0$ and $y(1)=2$.\n\nLet $L(y,y',x) = (y')^{2} + y y'$. To find the stationary function, we use the Euler–Lagrange equation\n$$\\frac{d}{dx}\\left(\\frac{\\partial L}{\\partial y'}\\right) - \\frac{\\partial L}{\\partial y} = 0.$$\nCompute the partial derivatives:\n$$\\frac{\\partial L}{\\partial y'} = 2 y' + y, \\qquad \\frac{\\partial L}{\\partial y} = y'.$$\nThen\n$$\\frac{d}{dx}\\left(2 y' + y\\right) - y' = 0 \\;\\;\\Rightarrow\\;\\; 2 y'' + y' - y' = 0 \\;\\;\\Rightarrow\\;\\; y'' = 0.$$\n\nThe general solution of $y''=0$ is\n$$y(x) = c_{1} x + c_{0}.$$\nImposing the boundary conditions:\n$$y(0) = c_{0} = 0, \\qquad y(1) = c_{1} = 2.$$\nTherefore,\n$$y(x) = 2x.$$\n\nFor completeness, the same result follows from the first variation. Let $y \\mapsto y + \\epsilon \\eta$ with $\\eta(0)=\\eta(1)=0$. The first variation is\n$$\\delta J = \\int_{0}^{1} \\left(2 y' \\eta' + \\eta y' + y \\eta'\\right) dx = \\int_{0}^{1} (2 y' + y)\\eta' \\, dx + \\int_{0}^{1} \\eta y' \\, dx.$$\nIntegrating the first integral by parts and using the fixed endpoints,\n$$\\delta J = \\left[(2 y' + y)\\eta\\right]_{0}^{1} - \\int_{0}^{1} (2 y'' + y') \\eta \\, dx + \\int_{0}^{1} \\eta y' \\, dx = - \\int_{0}^{1} 2 y'' \\eta \\, dx.$$\nStationarity for arbitrary $\\eta$ implies $y''=0$, leading again to $y(x)=2x$.", "answer": "$$\\boxed{2x}$$", "id": "2141487"}, {"introduction": "The Euler-Lagrange equation is not limited to finding a single optimal path; it can also reveal the fundamental, intrinsic properties of a physical system. This final exercise introduces the concept of an eigenvalue problem within the framework of variational principles, a concept central to fields like quantum mechanics and vibration analysis [@problem_id:2141504]. You will determine the specific conditions under which a system can support non-trivial states, connecting the principle of stationary action to the idea of quantized solutions.", "problem": "In the calculus of variations, we seek functions, called extremals, that make a given functional stationary. Consider a system whose state is described by a function $y(x)$ defined on the interval $[0, 1]$. The behavior of this system is governed by the principle of stationary action for the functional $J[y]$, defined as:\n$$J[y] = \\int_0^1 \\left( (y'(x))^2 - \\lambda (y(x))^2 \\right) dx$$\nHere, $y'(x)$ is the derivative of $y(x)$ with respect to $x$, and $\\lambda$ is a real constant parameter. The system is constrained such that the function $y(x)$ must satisfy the boundary conditions $y(0) = 0$ and $y(1) = 0$.\n\nFor most values of $\\lambda$, the only function that satisfies these conditions and makes the functional stationary is the trivial function $y(x) = 0$. However, for certain specific values of $\\lambda$, non-trivial extremals (i.e., solutions where $y(x)$ is not identically zero) can exist. These specific values of $\\lambda$ are known as the eigenvalues of the variational problem.\n\nDetermine the smallest positive value of the parameter $\\lambda$ for which the functional $J[y]$ admits a non-trivial extremal.", "solution": "We consider admissible variations of the form $y_{\\epsilon}(x) = y(x) + \\epsilon h(x)$ with $h(0) = 0$ and $h(1) = 0$, and compute the first variation $\\delta J[y;h] = \\left.\\frac{d}{d\\epsilon} J[y_{\\epsilon}]\\right|_{\\epsilon=0}$. The integrand is\n$$(y_{\\epsilon}'(x))^{2} - \\lambda (y_{\\epsilon}(x))^{2} = (y'(x) + \\epsilon h'(x))^{2} - \\lambda (y(x) + \\epsilon h(x))^{2}.$$\nExpanding to first order in $\\epsilon$ gives\n$$(y'(x))^{2} - \\lambda (y(x))^{2} + 2 \\epsilon \\left(y'(x) h'(x) - \\lambda y(x) h(x)\\right) + O(\\epsilon^{2}).$$\nTherefore,\n$$\\delta J[y;h] = 2 \\int_{0}^{1} \\left(y'(x) h'(x) - \\lambda y(x) h(x)\\right) dx.$$\nIntegrating the first term by parts,\n$$\\int_{0}^{1} y'(x) h'(x) dx = \\left[y'(x) h(x)\\right]_{0}^{1} - \\int_{0}^{1} y''(x) h(x) dx.$$\nThe boundary term vanishes because $h(0) = h(1) = 0$, hence\n$$\\delta J[y;h] = -2 \\int_{0}^{1} \\left(y''(x) + \\lambda y(x)\\right) h(x) dx.$$\nFor stationarity, $\\delta J[y;h] = 0$ for all admissible $h$, which implies the Euler–Lagrange equation\n$$y''(x) + \\lambda y(x) = 0,$$\nwith boundary conditions $y(0) = 0$ and $y(1) = 0$.\n\nWe solve the boundary-value problem by cases:\n- If $\\lambda > 0$, let $k = \\sqrt{\\lambda}$. The general solution is $y(x) = A \\cos(kx) + B \\sin(kx)$. The condition $y(0) = 0$ gives $A = 0$, so $y(x) = B \\sin(kx)$. The condition $y(1) = 0$ then requires $B \\sin(k) = 0$. For a non-trivial solution ($B \\neq 0$), we need $\\sin(k) = 0$, hence $k = n \\pi$ with $n \\in \\mathbb{N}$. Therefore,\n$$\\lambda = k^{2} = n^{2} \\pi^{2}.$$\n- If $\\lambda = 0$, then $y''(x) = 0$ gives $y(x) = Cx + D$, and the boundary conditions force $C = D = 0$, so only the trivial solution exists.\n- If $\\lambda < 0$, write $\\lambda = -\\mu^{2}$ with $\\mu > 0$. Then $y''(x) - \\mu^{2} y(x) = 0$ has solutions $y(x) = A \\exp(\\mu x) + B \\exp(-\\mu x)$. The boundary conditions imply $A + B = 0$ and $A \\exp(\\mu) + B \\exp(-\\mu) = 0$, which together force $A = B = 0$, giving only the trivial solution.\n\nHence non-trivial extremals exist precisely when $\\lambda = n^{2} \\pi^{2}$ with $n \\in \\mathbb{N}$. The smallest positive such value is obtained for $n = 1$, namely $\\lambda = \\pi^{2}$.", "answer": "$$\\boxed{\\pi^{2}}$$", "id": "2141504"}]}