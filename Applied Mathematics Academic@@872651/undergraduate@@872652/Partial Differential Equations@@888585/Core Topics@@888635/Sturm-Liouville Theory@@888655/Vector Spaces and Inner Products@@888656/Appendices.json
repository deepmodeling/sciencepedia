{"hands_on_practices": [{"introduction": "In the study of partial differential equations, we often treat functions as 'vectors' in an abstract space. However, for this powerful analogy to work, the set of functions must obey the specific axioms that define a vector space. This first exercise [@problem_id:2154959] is a foundational check, asking you to determine if a seemingly intuitive collection of functions—all non-negative continuous functions on an interval—actually qualifies as a vector space. It's a critical practice in understanding that the underlying algebraic structure is precise and not all sets of functions will suffice.", "problem": "In the study of function spaces, which are fundamental to the theory of partial differential equations, it is crucial to determine if a given set of functions constitutes a vector space. Consider the set $S$ of all real-valued, continuous functions defined on the closed interval $[0, 1]$ that are non-negative. That is,\n$$ S = \\{f: [0, 1] \\to \\mathbb{R} \\mid f \\text{ is continuous and } f(x) \\ge 0 \\text{ for all } x \\in [0, 1] \\} $$\nWe examine whether $S$ forms a vector space over the field of real numbers, $\\mathbb{R}$, with the standard operations of function addition and scalar multiplication.\n\nWhich of the following vector space axioms are NOT satisfied by the set $S$? Select all that apply.\n\nA. **Closure under vector addition:** For any two functions $f, g \\in S$, their sum $f+g$ is also in $S$.\n\nB. **Existence of a zero vector:** There exists a function $\\mathbf{0} \\in S$ such that for any function $f \\in S$, $f + \\mathbf{0} = f$.\n\nC. **Existence of additive inverses:** For each function $f \\in S$, there exists a function $-f \\in S$ such that $f + (-f) = \\mathbf{0}$.\n\nD. **Closure under scalar multiplication:** For any real number $c \\in \\mathbb{R}$ and any function $f \\in S$, the product $cf$ is also in $S$.", "solution": "We analyze each listed axiom for the set $S=\\{f:[0,1]\\to\\mathbb{R}\\mid f\\text{ is continuous and }f(x)\\ge 0\\text{ for all }x\\in[0,1]\\}$ under pointwise addition and scalar multiplication.\n\nFor A (closure under vector addition): If $f,g\\in S$, then for every $x\\in[0,1]$ we have $f(x)\\ge 0$ and $g(x)\\ge 0$, hence $(f+g)(x)=f(x)+g(x)\\ge 0$. Since the sum of continuous functions is continuous, $f+g\\in S$. Therefore A is satisfied.\n\nFor B (existence of a zero vector): The zero function $0$ defined by $0(x)=0$ for all $x\\in[0,1]$ is continuous and satisfies $0(x)\\ge 0$ for all $x$, so $0\\in S$, and for any $f\\in S$, $f+0=f$. Therefore B is satisfied.\n\nFor C (existence of additive inverses): Let $f\\in S$ with $f\\not\\equiv 0$. By continuity, there exists $x_{0}\\in[0,1]$ such that $f(x_{0})>0$. Then $(-f)(x_{0})=-f(x_{0})<0$, so $-f\\notin S$. Thus not every $f\\in S$ has its additive inverse in $S$, and C fails.\n\nFor D (closure under scalar multiplication): Let $c\\in\\mathbb{R}$ with $c<0$ and choose any $f\\in S$ with $f\\not\\equiv 0$. As above, there exists $x_{0}$ with $f(x_{0})>0$, so $(cf)(x_{0})=c\\,f(x_{0})<0$, implying $cf\\notin S$. Therefore closure under scalar multiplication for all real scalars fails, and D is not satisfied.\n\nHence the axioms not satisfied by $S$ are C and D.", "answer": "$$\\boxed{CD}$$", "id": "2154959"}, {"introduction": "After establishing a vector space of functions, we can introduce an inner product to define geometric notions like length and angle. The concept of orthogonality, where the inner product of two functions is zero, is the function-space equivalent of perpendicular vectors and is a cornerstone of many solution methods. This practice [@problem_id:2154979] offers a concrete entry point, guiding you through the calculation to find a simple polynomial that is orthogonal to a constant function, making this abstract geometric idea tangible.", "problem": "In the study of differential equations, functions can be treated as vectors in an infinite-dimensional vector space. Consider the vector space of all real-valued polynomials defined on the interval $[-1, 1]$. We can define an inner product for any two polynomials $f(x)$ and $g(x)$ in this space as follows:\n$$ \\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) \\, dx $$\nTwo polynomials are said to be orthogonal if their inner product is zero. Let $p_0(x) = 1$ be the constant polynomial. Your task is to find an example of a non-zero polynomial $p_1(x)$ of degree exactly one that is orthogonal to $p_0(x)$ with respect to the given inner product. Express your answer as a polynomial in the variable $x$.", "solution": "We require a non-zero degree-one polynomial $p_{1}(x)$ orthogonal to $p_{0}(x)=1$ with respect to the inner product $\\langle f,g\\rangle=\\int_{-1}^{1}f(x)g(x)\\,dx$. Orthogonality means $\\langle p_{1},p_{0}\\rangle=0$.\n\nLet a general degree-one polynomial be $p_{1}(x)=ax+b$ with $a\\neq 0$ to ensure degree exactly one. Compute the inner product:\n$$\n\\langle p_{1},p_{0}\\rangle=\\int_{-1}^{1}(ax+b)\\cdot 1\\,dx=\\int_{-1}^{1}(ax+b)\\,dx.\n$$\nSplit the integral:\n$$\n\\int_{-1}^{1}(ax+b)\\,dx=a\\int_{-1}^{1}x\\,dx+b\\int_{-1}^{1}1\\,dx.\n$$\nEvaluate each integral:\n$$\n\\int_{-1}^{1}x\\,dx=\\left.\\frac{x^{2}}{2}\\right|_{-1}^{1}=\\frac{1}{2}-\\frac{1}{2}=0,\\qquad \\int_{-1}^{1}1\\,dx=\\left.x\\right|_{-1}^{1}=1-(-1)=2.\n$$\nHence\n$$\n\\langle p_{1},p_{0}\\rangle=a\\cdot 0+b\\cdot 2=2b.\n$$\nThe orthogonality condition $\\langle p_{1},p_{0}\\rangle=0$ implies $2b=0$, so $b=0$. With $a\\neq 0$, any choice of $a$ yields a valid example. Choosing $a=1$ gives\n$$\np_{1}(x)=x,\n$$\nwhich is non-zero, of degree exactly one, and orthogonal to $p_{0}(x)=1$ on $[-1,1]$.", "answer": "$$\\boxed{x}$$", "id": "2154979"}, {"introduction": "While finding a single pair of orthogonal functions is a good start, the real power in solving PDEs comes from constructing an entire basis of mutually orthogonal functions. The Gram-Schmidt process is the standard algorithm for accomplishing this, allowing us to systematically convert any ordinary basis into a more useful orthonormal one. This hands-on practice [@problem_id:2154971] will walk you through this essential procedure, a skill that is fundamental for building Fourier series and other eigenfunction expansions.", "problem": "Let $V$ be the vector space of all continuous real-valued functions defined on the interval $[0, 1]$. The inner product for two functions $f(x)$ and $g(x)$ in this space is defined as:\n$$\n\\langle f, g \\rangle = \\int_{0}^{1} f(x)g(x) \\, dx\n$$\nConsider the subspace $W$ spanned by the ordered basis $S = \\{v_1(x), v_2(x)\\}$ where $v_1(x) = 1$ and $v_2(x) = x$.\n\nYour task is to apply the Gram-Schmidt process to the basis $S$ to obtain an orthonormal set of functions $\\{u_1(x), u_2(x)\\}$. Present the two resulting functions $u_1(x)$ and $u_2(x)$ in order as a final answer.", "solution": "We work in $V=C[0,1]$ with inner product $\\langle f,g\\rangle=\\int_{0}^{1}f(x)g(x)\\,dx$. The given ordered basis is $S=\\{v_{1},v_{2}\\}$ with $v_{1}(x)=1$ and $v_{2}(x)=x$.\n\nStep 1 (first orthonormal vector): Set $u_{1}=\\dfrac{v_{1}}{\\|v_{1}\\|}$. Compute\n$$\n\\langle v_{1},v_{1}\\rangle=\\int_{0}^{1}1\\cdot 1\\,dx=\\int_{0}^{1}1\\,dx=1,\n$$\nso $\\|v_{1}\\|=\\sqrt{1}=1$ and hence\n$$\nu_{1}(x)=1.\n$$\n\nStep 2 (second orthonormal vector): First orthogonalize $v_{2}$ against $u_{1}$:\n$$\nw_{2}=v_{2}-\\langle v_{2},u_{1}\\rangle u_{1}.\n$$\nCompute $\\langle v_{2},u_{1}\\rangle$:\n$$\n\\langle v_{2},u_{1}\\rangle=\\int_{0}^{1}x\\cdot 1\\,dx=\\int_{0}^{1}x\\,dx=\\left.\\frac{x^{2}}{2}\\right|_{0}^{1}=\\frac{1}{2}.\n$$\nThus\n$$\nw_{2}(x)=x-\\frac{1}{2}.\n$$\nNormalize $w_{2}$ to get $u_{2}$:\n$$\n\\|w_{2}\\|^{2}=\\langle w_{2},w_{2}\\rangle=\\int_{0}^{1}\\left(x-\\frac{1}{2}\\right)^{2}dx=\\int_{0}^{1}\\left(x^{2}-x+\\frac{1}{4}\\right)dx=\\left.\\left(\\frac{x^{3}}{3}-\\frac{x^{2}}{2}+\\frac{x}{4}\\right)\\right|_{0}^{1}=\\frac{1}{3}-\\frac{1}{2}+\\frac{1}{4}=\\frac{1}{12}.\n$$\nHence $\\|w_{2}\\|=\\sqrt{\\frac{1}{12}}=\\frac{1}{2\\sqrt{3}}$ and\n$$\nu_{2}(x)=\\frac{w_{2}(x)}{\\|w_{2}\\|}=\\sqrt{12}\\left(x-\\frac{1}{2}\\right)=2\\sqrt{3}\\,x-\\sqrt{3}.\n$$\n\nTherefore, the Gram-Schmidt process yields the orthonormal set $\\{u_{1}(x),u_{2}(x)\\}$ with $u_{1}(x)=1$ and $u_{2}(x)=\\sqrt{12}\\left(x-\\frac{1}{2}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & \\sqrt{12}\\left(x-\\frac{1}{2}\\right) \\end{pmatrix}}$$", "id": "2154971"}]}