{"hands_on_practices": [{"introduction": "The power of a parity-check matrix lies in its simple yet powerful definition of a linear code: a vector is a valid codeword if, and only if, it satisfies the equation $H\\mathbf{c}^T = \\mathbf{0}$. This exercise will give you direct practice in applying this fundamental rule to find a specific codeword within a code defined by a given matrix. Mastering this step is essential for understanding the relationship between the algebraic structure of the matrix and the properties of the code it generates. [@problem_id:1388956]", "problem": "In linear coding theory, a binary linear code can be defined as the set of all vectors $c$ that satisfy the equation $Hc^T = \\mathbf{0}$, where $H$ is a given matrix called the parity-check matrix, and all arithmetic is performed modulo 2 (i.e., over the finite field $\\mathbb{F}_2 = \\{0, 1\\}$). These vectors $c$ are called codewords.\n\nConsider a code defined by the following $2 \\times 4$ parity-check matrix:\n$$H = \\begin{pmatrix} 1 & 1 & 1 & 0 \\\\ 0 & 1 & 1 & 1 \\end{pmatrix}$$\nYour task is to find a specific non-zero codeword $c = (c_1, c_2, c_3, c_4)$ for this code. The codeword must satisfy the additional condition that its first component is $1$ (i.e., $c_1=1$). If multiple such codewords exist, choose the one that is lexicographically smallest. (A vector $u$ is lexicographically smaller than a vector $v$ if at the first position where they differ, the entry in $u$ is smaller than the entry in $v$).\n\nExpress your answer for the codeword $c$ as a row vector.", "solution": "We work over the field $\\mathbb{F}_{2}$. A codeword $c = (c_{1},c_{2},c_{3},c_{4})$ satisfies $Hc^{T}=\\mathbf{0}$, where\n$$\nH=\\begin{pmatrix}1&1&1&0\\\\0&1&1&1\\end{pmatrix}.\n$$\nThis gives the system\n$$\nc_{1}+c_{2}+c_{3}=0,\\qquad c_{2}+c_{3}+c_{4}=0,\n$$\nwith all sums modulo $2$. The additional constraint is $c_{1}=1$.\n\nFrom the first equation with $c_{1}=1$,\n$$\n1+c_{2}+c_{3}=0 \\;\\;\\Rightarrow\\;\\; c_{2}+c_{3}=1 \\;\\;\\Rightarrow\\;\\; c_{3}=1+c_{2}.\n$$\nSubstitute into the second equation:\n$$\nc_{2}+(1+c_{2})+c_{4}=0 \\;\\;\\Rightarrow\\;\\; (c_{2}+c_{2})+1+c_{4}=0 \\;\\;\\Rightarrow\\;\\; 0+1+c_{4}=0 \\;\\;\\Rightarrow\\;\\; c_{4}=1.\n$$\nThus all solutions with $c_{1}=1$ have the form\n$$\n(c_{1},c_{2},c_{3},c_{4})=(1,\\,c_{2},\\,1+c_{2},\\,1),\n$$\nwhere $c_{2}\\in\\{0,1\\}$. To obtain the lexicographically smallest vector among those with $c_{1}=1$, choose the smallest possible $c_{2}$, namely $c_{2}=0$. This yields\n$$\nc=(1,0,1,1).\n$$\nIt is non-zero and satisfies both parity-check equations.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & 0 & 1 & 1 \\end{pmatrix}}$$", "id": "1388956"}, {"introduction": "While any valid parity-check matrix defines a code, not all forms are equally convenient for practical implementation, especially for encoding message bits into codewords. The 'systematic form', often written as $[A | I_{m}]$, is a standardized structure that clearly separates message bits from parity bits. This practice will guide you through the essential skill of converting a given parity-check matrix into its systematic equivalent using elementary row operations over the binary field. [@problem_id:1645141]", "problem": "In the study of error-correcting codes, a binary linear block code is often described by its parity-check matrix, $H$. A particularly useful representation is the systematic form, $H_{sys} = [A | I_{m}]$, where $I_m$ is the $m \\times m$ identity matrix and all arithmetic is performed in the Galois Field GF(2), which means addition and subtraction are equivalent to the XOR operation (e.g., $1+1=0$).\n\nConsider a binary linear block code defined by the following non-systematic parity-check matrix:\n$$ H = \\begin{pmatrix} 0 & 1 & 0 & 1 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 & 0 & 1 & 1 \\\\ 0 & 1 & 1 & 1 & 0 & 0 & 1 \\\\ \\end{pmatrix} $$\nThe dimensions of this matrix are $m \\times n$, where $m$ is the number of parity-check equations and $n$ is the codeword length. By applying elementary row operations (swapping two rows, or adding one row to another), transform this matrix $H$ into its equivalent systematic form $H_{sys} = [A | I_{3}]$.\n\nDetermine the resulting matrix $A$.", "solution": "We work over GF(2), where row operations are row swaps and adding one row to another, and addition satisfies $1+1=0$. The given parity-check matrix is\n$$\nH=\\begin{pmatrix}\n0 & 1 & 0 & 1 & 1 & 1 & 0\\\\\n1 & 0 & 0 & 1 & 0 & 1 & 1\\\\\n0 & 1 & 1 & 1 & 0 & 0 & 1\n\\end{pmatrix}.\n$$\nTo obtain the systematic form $H_{sys}=[A\\mid I_{3}]$ with the identity in the last three columns, we examine the $3\\times 3$ submatrix consisting of columns $5,6,7$:\n$$\nS=\\begin{pmatrix}\n1 & 1 & 0\\\\\n0 & 1 & 1\\\\\n0 & 0 & 1\n\\end{pmatrix}.\n$$\nWe perform row operations to transform $S$ into $I_{3}$, applying the same operations to the full matrix $H$.\n\n1) Add row $2$ to row $1$: $r_{1}\\leftarrow r_{1}+r_{2}$. This gives\n$$\nH\\;\\to\\;\\begin{pmatrix}\n1 & 1 & 0 & 0 & 1 & 0 & 1\\\\\n1 & 0 & 0 & 1 & 0 & 1 & 1\\\\\n0 & 1 & 1 & 1 & 0 & 0 & 1\n\\end{pmatrix},\n$$\nand the last three columns for $r_{1}$ become $[1,0,1]$ as desired for elimination.\n\n2) Add row $3$ to row $2$: $r_{2}\\leftarrow r_{2}+r_{3}$. This gives\n$$\nH\\;\\to\\;\\begin{pmatrix}\n1 & 1 & 0 & 0 & 1 & 0 & 1\\\\\n1 & 1 & 1 & 0 & 0 & 1 & 0\\\\\n0 & 1 & 1 & 1 & 0 & 0 & 1\n\\end{pmatrix},\n$$\nand in the last three columns $r_{2}$ becomes $[0,1,0]$.\n\n3) Add row $3$ to row $1$: $r_{1}\\leftarrow r_{1}+r_{3}$. This gives\n$$\nH_{sys}=\\begin{pmatrix}\n1 & 0 & 1 & 1 & 1 & 0 & 0\\\\\n1 & 1 & 1 & 0 & 0 & 1 & 0\\\\\n0 & 1 & 1 & 1 & 0 & 0 & 1\n\\end{pmatrix}.\n$$\nNow the last three columns form $I_{3}$, so $H_{sys}=[A\\mid I_{3}]$ with\n$$\nA=\\begin{pmatrix}\n1 & 0 & 1 & 1\\\\\n1 & 1 & 1 & 0\\\\\n0 & 1 & 1 & 1\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}1 & 0 & 1 & 1\\\\ 1 & 1 & 1 & 0\\\\ 0 & 1 & 1 & 1\\end{pmatrix}}$$", "id": "1645141"}, {"introduction": "The ultimate purpose of a parity-check matrix is to detect and correct errors that occur during data transmission or storage. This hands-on problem takes you into a realistic decoding scenario where you must not only calculate the error 'syndrome' but also use additional information about error likelihoods to make the most probable correction. This exercise demonstrates how the theoretical concept of a syndrome is applied in maximum-likelihood decoding, a crucial technique in modern communication and data storage systems. [@problem_id:1388964]", "problem": "In a new type of experimental non-volatile memory, data is stored in blocks of 7 bits. To protect against errors, these blocks are restricted to be codewords of a linear code defined by the following parity-check matrix $H$ over the finite field $\\mathbb{F}_2$:\n$$\nH = \\begin{pmatrix}\n1 & 0 & 1 & 1 & 0 & 1 & 1 \\\\\n0 & 1 & 1 & 0 & 1 & 0 & 1 \\\\\n1 & 1 & 0 & 0 & 1 & 1 & 0\n\\end{pmatrix}\n$$\nDue to the physical layout of the memory cells, the likelihood of a single bit-flip error is not uniform across the 7 positions. After extensive testing, it has been determined that if a single bit-flip occurs, the conditional probability that the flip is at position $i$ (where $i$ is 1-indexed) is given by the vector $P = (p_1, p_2, p_3, p_4, p_5, p_6, p_7)$, where:\n$p_1=0.10$, $p_2=0.05$, $p_3=0.20$, $p_4=0.15$, $p_5=0.25$, $p_6=0.10$, $p_7=0.15$.\n\nA memory block is read, yielding the received word $r = (1, 1, 0, 0, 0, 1, 0)$. It is known that exactly one bit-flip error has corrupted the original codeword. Following the principle of maximum likelihood decoding, determine the most probable 1-indexed position of the flipped bit.", "solution": "Let the transmitted codeword be $c \\in \\mathbb{F}_{2}^{7}$ satisfying $Hc^{T}=0$. With exactly one bit-flip at position $i$, the error vector is $e=e_{i}$ and the received word is $r=c+e$ over $\\mathbb{F}_{2}$. The syndrome is\n$$\ns=Hr^{T}=H(c+e)^{T}=Hc^{T}+He^{T}=0+He^{T}=He^{T},\n$$\nso $s$ must equal the $i$-th column $h_{i}$ of $H$. Therefore, the set of feasible error positions is\n$$\n\\{i : h_{i}=s\\}.\n$$\nCompute the syndrome $s=Hr^{T}$ for $r=(1,1,0,0,0,1,0)$ over $\\mathbb{F}_{2}$:\n- First component: $1\\cdot 1+0\\cdot 1+1\\cdot 0+1\\cdot 0+0\\cdot 0+1\\cdot 1+1\\cdot 0=1+0+0+0+1+0=2\\equiv 0$.\n- Second component: $0\\cdot 1+1\\cdot 1+1\\cdot 0+0\\cdot 0+1\\cdot 0+0\\cdot 1+1\\cdot 0=0+1+0+0+0+0+0=1$.\n- Third component: $1\\cdot 1+1\\cdot 1+0\\cdot 0+0\\cdot 0+1\\cdot 0+1\\cdot 1+0\\cdot 0=1+1+0+0+0+1+0=3\\equiv 1$.\nThus\n$$\ns=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix}.\n$$\nList the columns of $H$:\n$$\nh_{1}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix},\\quad\nh_{2}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix},\\quad\nh_{3}=\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix},\\quad\nh_{4}=\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix},\\quad\nh_{5}=\\begin{pmatrix}0\\\\1\\\\1\\end{pmatrix},\\quad\nh_{6}=\\begin{pmatrix}1\\\\0\\\\1\\end{pmatrix},\\quad\nh_{7}=\\begin{pmatrix}1\\\\1\\\\0\\end{pmatrix}.\n$$\nThe feasible positions satisfy $h_{i}=s$, hence $i \\in \\{2,5\\}$. Under maximum likelihood with the known single-error model and prior probabilities $p_{i}$ for the error position, the posterior over feasible $i$ is proportional to $p_{i}$:\n$$\n\\Pr(i \\mid r,\\text{ one error}) \\propto p_{i}\\,\\mathbf{1}\\{h_{i}=s\\}.\n$$\nTherefore we choose\n$$\n\\arg\\max_{i \\in \\{2,5\\}} p_{i}=\\arg\\max\\{p_{2},p_{5}\\}=\\arg\\max\\{0.05,0.25\\}=5.\n$$\nHence, the most probable flipped bit position is $5$.", "answer": "$$\\boxed{5}$$", "id": "1388964"}]}