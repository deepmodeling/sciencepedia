{"hands_on_practices": [{"introduction": "The journey of a message in a digital system often begins with encoding, where it is transformed into a more robust form called a codeword. This exercise explores this fundamental step using a generator matrix $G$, focusing on a particularly intuitive class of codes known as systematic codes. By working backward from a received (error-free) codeword, you will see how the original message is neatly preserved within the structure of the final codeword, offering a clear insight into the encoding process. [@problem_id:1367870]", "problem": "In a simplified digital communication protocol, message vectors are encoded using a linear block code to add redundancy and allow for error detection. The protocol uses a specific $(6, 3)$-code, which transforms 3-bit message vectors into 6-bit codewords. The encoding is performed via multiplication by a generator matrix $G$.\n\nThe relationship between a 3-bit message vector $m = [m_1, m_2, m_3]$ and its corresponding 6-bit codeword $c$ is given by the equation $c = mG$, where all arithmetic is performed over the binary field $\\mathbb{F}_2$ (i.e., addition is equivalent to the XOR operation, and $1+1=0$).\n\nThe generator matrix for this code is:\n$$ G = \\begin{pmatrix} 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 0 & 1 \\end{pmatrix} $$\n\nSuppose the codeword $c = [0, 1, 1, 1, 0, 1]$ is received, and it is known that no errors occurred during transmission. Determine the original 3-bit message vector $m$ that was encoded. Express your answer as a $1 \\times 3$ row matrix.", "solution": "We work over the binary field $\\mathbb{F}_2$, so all additions are modulo $2$. The encoding rule is $c = mG$, where $m$ is a $1 \\times 3$ row vector, $G$ is a $3 \\times 6$ matrix, and $c$ is a $1 \\times 6$ row vector.\n\nObserve that the given generator matrix can be partitioned as\n$$\nG = \\begin{pmatrix} 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 1 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 0 & 1 \\end{pmatrix}\n= \\bigl[\\,P \\;\\big|\\; I_{3}\\,\\bigr],\n$$\nwhere\n$$\nP = \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\\\ 1 & 0 & 1 \\end{pmatrix}, \\quad I_{3} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}.\n$$\nThus, for any message $m$, the codeword splits as\n$$\nc = mG = \\bigl[\\, mP \\;\\big|\\; mI_{3} \\,\\bigr] = \\bigl[\\, mP \\;\\big|\\; m \\,\\bigr].\n$$\nTherefore, the last three components of $c$ equal the original message $m$.\n\nGiven the received codeword $c = [0, 1, 1, 1, 0, 1]$ and no transmission errors, we read off\n$$\nm = [c_{4}, c_{5}, c_{6}] = [1, 0, 1].\n$$\nAs a consistency check, compute $mP$ over $\\mathbb{F}_2$:\n$$\nmP = [1,0,1] \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\\\ 1 & 0 & 1 \\end{pmatrix}\n= \\bigl[\\, 1\\cdot 1 + 0\\cdot 0 + 1\\cdot 1,\\; 1\\cdot 1 + 0\\cdot 1 + 1\\cdot 0,\\; 1\\cdot 0 + 0\\cdot 1 + 1\\cdot 1 \\,\\bigr]\n= [0, 1, 1],\n$$\nwhich matches the first three components of $c$, confirming correctness.\n\nHence, the original message vector is the $1 \\times 3$ row matrix $\\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix}}$$", "id": "1367870"}, {"introduction": "Once a message is encoded and transmitted, the receiver must verify its integrity. This is where the parity-check matrix $H$ and the concept of a syndrome come into play. The syndrome acts as a simple \"check-up\" on the received data; a non-zero result immediately signals that an error has occurred. This practice problem provides direct experience in computing the syndrome for a received word, a core skill in the mechanics of error detection. [@problem_id:1367894]", "problem": "In the theory of linear block codes over the binary field $\\mathbb{F}_2 = \\{0, 1\\}$, the syndrome of a received word $y$ is a vector $s$ used for error detection. It is calculated as the matrix-vector product $s = H y^T$, where $H$ is the code's parity-check matrix and $y^T$ is the transpose of the word $y$. All arithmetic operations are performed modulo 2, where $1+1=0$.\n\nConsider a specific linear code defined by the following parity-check matrix:\n$$\nH = \\begin{pmatrix}\n1 & 1 & 0 & 1 & 0 \\\\\n0 & 1 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 1 & 0\n\\end{pmatrix}\n$$\nSuppose a word $y = (1, 0, 1, 1, 0)$ is received. Calculate the corresponding syndrome $s$. Express your answer as a row matrix.", "solution": "We compute the syndrome $s$ over $\\mathbb{F}_{2}$ using $s=H y^{T}$, where arithmetic is modulo $2$. The given parity-check matrix is\n$$\nH=\\begin{pmatrix}\n1 & 1 & 0 & 1 & 0 \\\\\n0 & 1 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 1 & 0\n\\end{pmatrix},\n$$\nand the received word as a column vector is\n$$\ny^{T}=\\begin{pmatrix}1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0\\end{pmatrix}.\n$$\nCompute each component of $s$ as the dot product of the corresponding row of $H$ with $y^{T}$, all modulo $2$:\n- First component: $(1)(1)+(1)(0)+(0)(1)+(1)(1)+(0)(0)=1+0+0+1+0=2\\equiv 0 \\pmod{2}$.\n- Second component: $(0)(1)+(1)(0)+(1)(1)+(0)(1)+(1)(0)=0+0+1+0+0=1\\equiv 1 \\pmod{2}$.\n- Third component: $(1)(1)+(0)(0)+(1)(1)+(1)(1)+(0)(0)=1+0+1+1+0=3\\equiv 1 \\pmod{2}$.\n\nThus $s=\\begin{pmatrix}0 \\\\ 1 \\\\ 1\\end{pmatrix}$ as a column vector, which as a row matrix is $\\begin{pmatrix}0 & 1 & 1\\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}0 & 1 & 1\\end{pmatrix}}$$", "id": "1367894"}, {"introduction": "After learning how to calculate a syndrome, a critical next step is to correctly interpret the result. This problem addresses a common and important question: what can we conclude with certainty if the syndrome is the zero vector? It challenges you to think beyond the calculation and consider the underlying structure of the code itself as a vector space. This exercise is crucial for developing a robust conceptual understanding of what a syndrome test can—and cannot—tell us about transmission errors. [@problem_id:1367883]", "problem": "In a digital communication system, a linear block code is used to handle transmission errors. The code, denoted by $C$, is a subspace of the vector space $\\mathbb{F}_2^n$, where $\\mathbb{F}_2 = \\{0, 1\\}$ and all vector arithmetic is performed modulo 2. The code is defined by its parity-check matrix, $H$, which is an $(n-k) \\times n$ matrix with entries in $\\mathbb{F}_2$. A vector $v \\in \\mathbb{F}_2^n$ is a valid codeword (i.e., $v \\in C$) if and only if its product with the parity-check matrix results in the zero vector: $Hv^T = 0$.\n\nWhen a codeword $x \\in C$ is transmitted over a noisy channel, a possibly different vector $y \\in \\mathbb{F}_2^n$ is received. The difference between the received word and the transmitted codeword is the error vector, $e = y - x$. Note that in $\\mathbb{F}_2$, subtraction is the same as addition, so $e = y + x$.\n\nTo check for errors, the receiver calculates the *syndrome* of the received word $y$, which is defined as $S(y) = Hy^T$.\n\nAn engineer monitoring the system observes a particular received word, $y_{obs}$, and after computing its syndrome, finds that the result is the zero vector, i.e., $S(y_{obs}) = 0$.\n\nBased *only* on this observation, which of the following statements can the engineer conclude with absolute certainty? Select all that apply.\n\nA. The received word $y_{obs}$ is identical to the codeword that was originally transmitted.\n\nB. No errors occurred during the transmission of the codeword.\n\nC. The received word $y_{obs}$ is an element of the set of valid codewords $C$.\n\nD. The error vector $e$, corresponding to the difference between the received word $y_{obs}$ and the transmitted codeword, is itself a valid codeword in $C$.", "solution": "We are given a linear block code $C \\subseteq \\mathbb{F}_{2}^{n}$ defined by the parity-check matrix $H$ with $C=\\{v \\in \\mathbb{F}_{2}^{n} : Hv^{T}=0\\}$, and the syndrome of any $y \\in \\mathbb{F}_{2}^{n}$ is $S(y)=Hy^{T}$. A codeword $x \\in C$ is transmitted, and $y$ is received with error vector $e=y-x$, noting that over $\\mathbb{F}_{2}$ we have $e=y+x$.\n\nFrom the observation $S(y_{obs})=0$, we have $Hy_{obs}^{T}=0$. By the definition of $C$ as the null space of $H$, this implies $y_{obs} \\in C$. Therefore, statement C holds with certainty.\n\nTo analyze A and B, consider that $x \\in C$ satisfies $Hx^{T}=0$ by definition. If $e \\in C$ is any (possibly nonzero) codeword, then $y=x+e$ also satisfies\n$$\nHy^{T}=H(x+e)^{T}=Hx^{T}+He^{T}=0+0=0,\n$$\nso $S(y)=0$ can occur even when $e \\neq 0$ and $y \\neq x$. Hence, from $S(y_{obs})=0$ alone, one cannot conclude that $y_{obs}=x$ (statement A) or that no errors occurred (statement B). Both A and B are therefore not guaranteed.\n\nFor D, define $e=y_{obs}-x=y_{obs}+x$ in $\\mathbb{F}_{2}^{n}$. Using linearity of $H$ and that $Hx^{T}=0$ (since $x \\in C$) and $Hy_{obs}^{T}=0$ (by observation), we get\n$$\nHe^{T}=H(y_{obs}+x)^{T}=Hy_{obs}^{T}+Hx^{T}=0+0=0.\n$$\nThus $e \\in C$. Therefore, statement D holds with certainty.\n\nIn conclusion, the only statements that can be concluded with absolute certainty from $S(y_{obs})=0$ are C and D.", "answer": "$$\\boxed{CD}$$", "id": "1367883"}]}