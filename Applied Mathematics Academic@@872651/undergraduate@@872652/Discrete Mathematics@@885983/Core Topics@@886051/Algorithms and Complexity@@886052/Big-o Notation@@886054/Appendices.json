{"hands_on_practices": [{"introduction": "To truly grasp Big-O notation, it's helpful to move from the abstract definition to a concrete calculation. This first exercise challenges you to do just that by finding the specific constants involved in an asymptotic bound [@problem_id:1351719]. By working directly with the inequality $f(n) \\le C \\cdot g(n)$, you will build a foundational understanding of how one function's growth can be formally bounded by another's.", "problem": "Let a function $f(n)$ be defined for positive integers $n$ as $f(n) = 3n^2 \\log_{10}(n) + 12n^2$. Find the smallest positive integer $C$ such that the inequality $f(n) \\le C \\cdot n^2 \\log_{10}(n)$ is satisfied for all integers $n \\ge 100$.", "solution": "We are given $f(n) = 3n^{2}\\log_{10}(n) + 12n^{2}$ and seek the smallest positive integer $C$ such that for all integers $n \\ge 100$,\n$$\nf(n) \\le C \\cdot n^{2}\\log_{10}(n).\n$$\nFor $n \\ge 100$, we have $n^{2} > 0$ and $\\log_{10}(n) > 0$, so we may divide both sides of the inequality by $n^{2}\\log_{10}(n)$ without changing the inequality direction:\n$$\n\\frac{3n^{2}\\log_{10}(n) + 12n^{2}}{n^{2}\\log_{10}(n)} \\le C\n\\;\\;\\Longleftrightarrow\\;\\;\n3 + \\frac{12}{\\log_{10}(n)} \\le C.\n$$\nDefine $h(n) = 3 + \\frac{12}{\\log_{10}(n)}$. Since $\\log_{10}(n)$ is strictly increasing for $n \\ge 1$, the function $\\frac{12}{\\log_{10}(n)}$ is strictly decreasing, hence $h(n)$ is strictly decreasing for $n \\ge 1$. Therefore, on the domain of integers $n \\ge 100$, the maximum of $h(n)$ occurs at the smallest $n$, namely $n=100$. Evaluating,\n$$\nh(100) = 3 + \\frac{12}{\\log_{10}(100)} = 3 + \\frac{12}{2} = 9.\n$$\nThus, for all integers $n \\ge 100$,\n$$\n3 + \\frac{12}{\\log_{10}(n)} \\le 9,\n$$\nso $C=9$ satisfies the required inequality. Moreover, any $C < 9$ would violate the inequality at $n=100$, hence the smallest positive integer $C$ is $9$.", "answer": "$$\\boxed{9}$$", "id": "1351719"}, {"introduction": "In the real world, analyzing an algorithm's performance often involves working with functions that are more complex than simple polynomials. This practice presents a rational function, typical of runtime analysis, and asks you to determine its tightest asymptotic bound [@problem_id:1351732]. Mastering this skill is essential for quickly assessing how an algorithm will scale as input sizes grow.", "problem": "The running time of a particular algorithm on an input of size $n$ (for $n \\ge 1$) is described by the function $f(n)$ given by:\n$$f(n) = \\frac{(n^2+1)(n+3)}{2n+1}$$\nDetermine the tightest asymptotic bound for this function, expressed using Big-Theta ($\\Theta$) notation. Select the correct complexity class from the options below.\n\nA. $\\Theta(n)$\n\nB. $\\Theta(n \\log n)$\n\nC. $\\Theta(n^2)$\n\nD. $\\Theta(n^3)$", "solution": "We are given the function\n$$\nf(n)=\\frac{(n^{2}+1)(n+3)}{2n+1}, \\quad n\\geq 1.\n$$\nFirst expand the numerator:\n$$\n(n^{2}+1)(n+3)=n^{3}+3n^{2}+n+3.\n$$\nThus,\n$$\nf(n)=\\frac{n^{3}+3n^{2}+n+3}{2n+1}.\n$$\nPerform polynomial division by seeking constants $A$, $B$, and $C$ and a constant remainder $R$ such that\n$$\n\\frac{n^{3}+3n^{2}+n+3}{2n+1}=A n^{2}+B n+C+\\frac{R}{2n+1}.\n$$\nEquivalently,\n$$\nn^{3}+3n^{2}+n+3=(2n+1)(A n^{2}+B n+C)+R.\n$$\nExpand the product on the right:\n$$\n(2n+1)(A n^{2}+B n+C)=2A n^{3}+(2B+A)n^{2}+(2C+B)n+C.\n$$\nMatch coefficients with the left-hand side:\n- From $n^{3}$: $2A=1 \\implies A=\\frac{1}{2}$.\n- From $n^{2}$: $2B+A=3 \\implies 2B+\\frac{1}{2}=3 \\implies B=\\frac{5}{4}$.\n- From $n^{1}$: $2C+B=1 \\implies 2C+\\frac{5}{4}=1 \\implies C=-\\frac{1}{8}$.\n- For the constant term, the product contributes $C=-\\frac{1}{8}$, so to reach $3$ we require\n$$\nR=3-\\left(-\\frac{1}{8}\\right)=\\frac{25}{8}.\n$$\nTherefore,\n$$\nf(n)=\\frac{1}{2}n^{2}+\\frac{5}{4}n-\\frac{1}{8}+\\frac{\\frac{25}{8}}{2n+1}.\n$$\nThe last term is $\\Theta\\!\\left(\\frac{1}{n}\\right)$, and the remaining polynomial part is dominated by its leading term $\\frac{1}{2}n^{2}$. Hence\n$$\nf(n)=\\frac{1}{2}n^{2}+O(n)=\\Theta(n^{2}).\n$$\nTherefore, the tightest asymptotic bound is $\\Theta(n^{2})$, which corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1351732"}, {"introduction": "Asymptotic notation can sometimes defy our initial intuition, making it crucial to rely on formal definitions. This problem presents a common logical proposition and asks you to determine its validity, testing whether you can spot a subtle but significant flaw in reasoning about $\\Theta$-notation [@problem_id:1351738]. Engaging with such counterexamples deepens your understanding and prevents common misconceptions.", "problem": "Consider two functions, $f(n)$ and $g(n)$, that map the set of positive integers to the set of positive real numbers. We are asked to evaluate the validity of the following logical proposition:\n\n**Proposition P:** If $f(n) = \\Theta(g(n))$, then the difference $d(n) = f(n) - g(n)$ must satisfy $d(n) = O(1)$.\n\nFor reference, the formal definitions of the asymptotic notations are provided below:\n- **Theta Notation**: A function $f(n)$ is in $\\Theta(g(n))$ if there exist positive constants $c_1$, $c_2$, and an integer $n_0$ such that $0 \\le c_1 g(n) \\le f(n) \\le c_2 g(n)$ for all integers $n \\ge n_0$. This signifies that $f(n)$ and $g(n)$ grow at the same rate.\n- **Big-O Notation**: A function $h(n)$ is in $O(k(n))$ if there exist a positive constant $c$ and an integer $n_0$ such that $0 \\le |h(n)| \\le c \\cdot k(n)$ for all integers $n \\ge n_0$. In the context of Proposition P, $d(n)=O(1)$ means that the absolute value of the difference, $|d(n)|$, is bounded by some constant for all sufficiently large $n$.\n\nWhich of the following statements correctly evaluates Proposition P?\n\nA. Proposition P is true, because if $f(n)$ and $g(n)$ grow at the same rate, their difference must approach a constant value.\n\nB. Proposition P is false. A counterexample is $f(n) = n^2 + n$ and $g(n) = n^2$, because $f(n) = \\Theta(g(n))$ is true but their difference grows linearly with $n$.\n\nC. Proposition P is true, because the definition of $\\Theta$-notation implies that the ratio $f(n)/g(n)$ is bounded by constants, which in turn must bound the difference $f(n) - g(n)$.\n\nD. Proposition P is false. A counterexample is $f(n) = 2^n$ and $g(n) = 3^n$, because their difference grows exponentially.", "solution": "We test Proposition P using the definition of $\\Theta$-notation. Assume $f(n)=\\Theta(g(n))$. Then there exist constants $c_{1}>0$, $c_{2}>0$, and $n_{0}\\in\\mathbb{N}$ such that for all $n\\ge n_{0}$,\n$$\n0<c_{1}g(n)\\le f(n)\\le c_{2}g(n).\n$$\nSince $g(n)>0$ for all $n$ by hypothesis, we can bound the ratio:\n$$\nc_{1}\\le \\frac{f(n)}{g(n)}\\le c_{2}\\quad\\text{for all }n\\ge n_{0}.\n$$\nConsider the difference $d(n)=f(n)-g(n)$. Then\n$$\n|d(n)|=\\left|f(n)-g(n)\\right|=g(n)\\left|\\frac{f(n)}{g(n)}-1\\right|.\n$$\nUsing the bounds on $\\frac{f(n)}{g(n)}$, we obtain\n$$\n\\left|\\frac{f(n)}{g(n)}-1\\right|\\le \\max\\left(|c_{1}-1|,\\;|c_{2}-1|\\right),\n$$\nand hence\n$$\n|d(n)|\\le \\max\\left(|c_{1}-1|,\\;|c_{2}-1|\\right)\\cdot g(n).\n$$\nThis shows that, in general, $d(n)=O(g(n))$, not necessarily $O(1)$, unless additionally $g(n)=O(1)$. Therefore, Proposition P is not guaranteed to hold.\n\nA concrete counterexample invalidates Proposition P. Let $g(n)=n^{2}$ and $f(n)=n^{2}+n$. For all $n\\ge 1$,\n$$\nn^{2}\\le n^{2}+n\\le 2n^{2},\n$$\nso $f(n)=\\Theta(g(n))$ with $c_{1}=1$, $c_{2}=2$, and $n_{0}=1$. However, the difference is\n$$\nd(n)=f(n)-g(n)=n,\n$$\nand\n$$\n|d(n)|=n\\notin O(1).\n$$\nThus Proposition P is false.\n\nNow evaluate the options:\n- A is false because equal growth rate does not force a bounded difference; the counterexample above shows the difference can grow unboundedly.\n- B is correct, providing the valid counterexample $f(n)=n^{2}+n$, $g(n)=n^{2}$ where $f(n)=\\Theta(g(n))$ but $d(n)=n\\notin O(1)$.\n- C is false: bounding $\\frac{f(n)}{g(n)}$ only implies $|f(n)-g(n)|\\le C\\cdot g(n)$, not $O(1)$.\n- D is false as a justification: $f(n)=2^{n}$ and $g(n)=3^{n}$ are not in a $\\Theta$-relationship since $\\frac{2^{n}}{3^{n}}=(\\frac{2}{3})^{n}$ is not bounded below by a positive constant.\n\nTherefore, the correct evaluation is option B.", "answer": "$$\\boxed{B}$$", "id": "1351738"}]}