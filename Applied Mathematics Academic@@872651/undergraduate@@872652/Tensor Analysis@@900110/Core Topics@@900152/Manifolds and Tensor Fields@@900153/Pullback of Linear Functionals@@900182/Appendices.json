{"hands_on_practices": [{"introduction": "Our journey into the practical application of pullbacks begins with the most fundamental task: transforming basis covectors. Since any linear functional can be expressed as a combination of basis covectors, understanding how these basis elements transform is essential for any further work. This exercise [@problem_id:1533750] provides direct practice in applying the definition of the pullback to the standard coordinate differentials, laying the groundwork for more complex scenarios.", "problem": "Let the standard Cartesian coordinates on the vector space $\\mathbb{R}^2$ be $(u, v)$ and on $\\mathbb{R}^3$ be $(x, y, z)$. The corresponding bases for the dual spaces, denoted $(\\mathbb{R}^2)^*$ and $(\\mathbb{R}^3)^*$, are $\\{du, dv\\}$ and $\\{dx, dy, dz\\}$, respectively.\n\nConsider the linear map $T: \\mathbb{R}^2 \\rightarrow \\mathbb{R}^3$ defined by the component functions:\n$x(u,v) = u - v$\n$y(u,v) = u + v$\n$z(u,v) = 2u$\n\nThe map $T$ induces a pullback map $T^*: (\\mathbb{R}^3)^* \\rightarrow (\\mathbb{R}^2)^*$ that transforms covectors (linear functionals) on $\\mathbb{R}^3$ into covectors on $\\mathbb{R}^2$.\n\nYour task is to compute the pullbacks of the standard basis covectors $dx$, $dy$, and $dz$ under the map $T$. Each result should be expressed as a linear combination of the basis covectors $du$ and $dv$.\n\nYour final answer should be a single expression in the form of a row matrix, where the elements are the resulting covectors for $T^*(dx)$, $T^*(dy)$, and $T^*(dz)$, in that specific order.", "solution": "We are given the smooth linear map $T: \\mathbb{R}^{2} \\to \\mathbb{R}^{3}$ with component functions\n$$\nx(u,v) = u - v, \\quad y(u,v) = u + v, \\quad z(u,v) = 2u.\n$$\nThe pullback $T^{*}$ on $1$-forms is defined by the principle that for any smooth function $f$ on the target space,\n$$\nT^{*}(df) = d(f \\circ T).\n$$\nIn particular, with the coordinate functions $x,y,z$ on $\\mathbb{R}^{3}$ we have:\n1) For $dx$:\n$$\nx \\circ T(u,v) = u - v \\quad \\Rightarrow \\quad T^{*}(dx) = d(u - v) = du - dv.\n$$\nHere we used linearity of the exterior derivative: $d(u) = du$, $d(v) = dv$, and $d(a u + b v) = a\\,du + b\\,dv$ for constants $a,b$.\n\n2) For $dy$:\n$$\ny \\circ T(u,v) = u + v \\quad \\Rightarrow \\quad T^{*}(dy) = d(u + v) = du + dv.\n$$\n\n3) For $dz$:\n$$\nz \\circ T(u,v) = 2u \\quad \\Rightarrow \\quad T^{*}(dz) = d(2u) = 2\\,du.\n$$\n\nThus, expressed in the basis $\\{du, dv\\}$ of $(\\mathbb{R}^{2})^{*}$, the pullbacks are\n$$\nT^{*}(dx) = du - dv, \\quad T^{*}(dy) = du + dv, \\quad T^{*}(dz) = 2du.\n$$\nAs a row matrix listing these in the order $T^{*}(dx), T^{*}(dy), T^{*}(dz)$, we have the single-row matrix with entries the corresponding covectors.", "answer": "$$\\boxed{\\begin{pmatrix} du - dv & du + dv & 2du \\end{pmatrix}}$$", "id": "1533750"}, {"introduction": "With the basic computational mechanics in hand, we can now explore the deeper geometric meaning of the pullback. A map between spaces often involves a change in dimension, such as a projection, which can lead to a loss of information. This exercise [@problem_id:1533701] investigates which \"measurements\" (covectors) in the higher-dimensional space become trivial when viewed from the lower-dimensional space, connecting the algebraic concept of the pullback's kernel to the geometric nature of the map.", "problem": "In fields like computer graphics and data analysis, high-dimensional data is often projected onto a lower-dimensional subspace. Consider a linear projection map $T$ from a 2-dimensional parameter space, with coordinates $(u, v)$, to a 3-dimensional observation space, with coordinates $(x, y, z)$. The map is defined by the transformation:\n$$T(u, v) = (u+v, u-v, 0)$$\nThis map takes any point in the parameter plane and places it onto the $xy$-plane within the 3D space.\n\nA linear measurement on the 3D space is represented by a covector $\\alpha$ from the dual space $(\\mathbb{R}^3)^*$. A covector is a linear functional that acts on a vector to produce a scalar value. The pullback of $\\alpha$ by $T$, denoted $T^*\\alpha$, represents the equivalent measurement performed in the 2D parameter space. It is defined by $(T^*\\alpha)(\\mathbf{p}) = \\alpha(T(\\mathbf{p}))$ for any vector $\\mathbf{p}$ in the parameter space.\n\nSome measurements in the 3D space might yield no information when pulled back to the parameter space, meaning the pullback $T^*\\alpha$ is the zero covector. Your task is to characterize this set of \"trivial\" measurements.\n\nDetermine the set of all covectors $\\alpha \\in (\\mathbb{R}^3)^*$ for which the pullback $T^*\\alpha$ is the zero covector. Express this set by providing a basis for it. The basis covector(s) should be expressed in terms of the standard dual basis $\\{dx, dy, dz\\}$ of $(\\mathbb{R}^3)^*$, where the action of these basis covectors on a vector $(x, y, z)$ is given by $dx(x,y,z)=x$, $dy(x,y,z)=y$, and $dz(x,y,z)=z$.", "solution": "Let a general covector $\\alpha \\in (\\mathbb{R}^{3})^{*}$ be written in the standard dual basis as\n$$\n\\alpha = A\\,dx + B\\,dy + C\\,dz,\n$$\nso that for any $(x,y,z) \\in \\mathbb{R}^{3}$,\n$$\n\\alpha(x,y,z) = A x + B y + C z.\n$$\nThe pullback $T^{*}\\alpha$ is defined by $(T^{*}\\alpha)(u,v) = \\alpha(T(u,v))$. With $T(u,v) = (u+v,\\,u-v,\\,0)$, we obtain\n$$\n(T^{*}\\alpha)(u,v) = \\alpha(u+v,\\,u-v,\\,0) = A(u+v) + B(u-v) + C \\cdot 0 = (A+B)u + (A-B)v.\n$$\nThe pullback $T^{*}\\alpha$ is the zero covector on $\\mathbb{R}^{2}$ if and only if it vanishes for all $(u,v) \\in \\mathbb{R}^{2}$. Hence we require\n$$\nA + B = 0, \\qquad A - B = 0.\n$$\nAdding and subtracting these equations yields $A = 0$ and $B = 0$, while $C$ is unrestricted. Therefore\n$$\n\\alpha = C\\,dz,\n$$\nso the set of all covectors whose pullback is zero is the one-dimensional subspace $\\operatorname{span}\\{dz\\}$. A basis for this subspace is $\\{dz\\}$.", "answer": "$$\\boxed{dz}$$", "id": "1533701"}, {"introduction": "This final practice presents an \"inverse problem\" that solidifies the algebraic relationship between a linear map and its pullback. When a transformation is invertible, it preserves all information, meaning we can uniquely reverse the mapping. This problem [@problem_id:1533749] challenges you to use the matrix representation of the pullback to reconstruct the original covector, demonstrating the elegant duality between the forward map $T$ and the pullback map $T^*$.", "problem": "Let $V = \\mathbb{R}^2$ be a real vector space. Consider an invertible linear transformation $T: V \\to V$ represented by the matrix $M_T$ with respect to the standard basis $\\{e_1, e_2\\}$:\n$$\nM_T = \\begin{pmatrix} 3 & 1 \\\\ 5 & 2 \\end{pmatrix}\n$$\nLet $\\alpha$ be a covector (a linear functional) on $V$. The pullback of $\\alpha$ by $T$, denoted $T^*\\alpha$, is a covector on $V$ defined by the relation $(T^*\\alpha)(v) = \\alpha(T(v))$ for any vector $v \\in V$.\n\nIf the components of the pullback covector $T^*\\alpha$ with respect to the dual basis corresponding to $\\{e_1, e_2\\}$ are given by the pair $(2, 1)$, determine the components of the original covector $\\alpha$.\n\nExpress your answer as a row matrix of the form $\\begin{pmatrix} a_1 & a_2 \\end{pmatrix}$.", "solution": "We represent vectors in $V$ as column vectors relative to the basis $\\{e_{1}, e_{2}\\}$, so $T$ is represented by $M_{T}=\\begin{pmatrix}3 & 1 \\\\ 5 & 2\\end{pmatrix}$ via $T(v)=M_{T}v$. A covector $\\alpha$ is represented as a row vector $\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}$ with respect to the dual basis, so that for any $v$ with coordinate column $x$, we have $\\alpha(v)=\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}x$.\n\nBy definition of the pullback, for all $v$,\n$$\n(T^{*}\\alpha)(v)=\\alpha(T(v))=\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}M_{T}v.\n$$\nTherefore, the row vector of components of $T^{*}\\alpha$ equals $\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}M_{T}$. We are given that the components of $T^{*}\\alpha$ are $\\begin{pmatrix}2 & 1\\end{pmatrix}$. Hence,\n$$\n\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}M_{T}=\\begin{pmatrix}2 & 1\\end{pmatrix}.\n$$\nSince $T$ is invertible, $M_{T}$ is invertible, and we can solve for $\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}$ by right-multiplying by $M_{T}^{-1}$:\n$$\n\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}=\\begin{pmatrix}2 & 1\\end{pmatrix}M_{T}^{-1}.\n$$\nCompute $M_{T}^{-1}$ using the $2\\times 2$ inverse formula. The determinant is\n$$\n\\det(M_{T})=3\\cdot 2-1\\cdot 5=1,\n$$\nso\n$$\nM_{T}^{-1}=\\frac{1}{\\det(M_{T})}\\begin{pmatrix}2 & -1 \\\\ -5 & 3\\end{pmatrix}=\\begin{pmatrix}2 & -1 \\\\ -5 & 3\\end{pmatrix}.\n$$\nThus,\n$$\n\\begin{pmatrix}a_{1} & a_{2}\\end{pmatrix}=\\begin{pmatrix}2 & 1\\end{pmatrix}\\begin{pmatrix}2 & -1 \\\\ -5 & 3\\end{pmatrix}=\\begin{pmatrix}2\\cdot 2+1\\cdot(-5) & 2\\cdot(-1)+1\\cdot 3\\end{pmatrix}=\\begin{pmatrix}-1 & 1\\end{pmatrix}.\n$$\nTherefore, the components of $\\alpha$ are $\\begin{pmatrix}-1 & 1\\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}-1 & 1\\end{pmatrix}}$$", "id": "1533749"}]}