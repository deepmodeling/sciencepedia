{"hands_on_practices": [{"introduction": "The concept of uniform convergence formalizes the idea of a sequence of functions $f_n$ approaching a limit function $f$ at the same rate across the entire domain. This first exercise provides a direct application of the definition of uniform convergence, which centers on the behavior of the supremum norm of the difference $|f_n(x) - f(x)|$. By analyzing the simple sequence of power functions $f_n(x) = x^n$ on a restricted interval [@problem_id:40394], you will practice the fundamental technique of finding this supremum and determining if it vanishes as $n$ approaches infinity, thereby building a solid foundation for more complex scenarios.", "problem": "#### Background\nA sequence of functions $(f_n)$, where $n=1, 2, 3, \\ldots$, defined on a set $S \\subseteq \\mathbb{R}$, is said to converge uniformly to a limit function $f$ on $S$ if the following condition is met:\n$$\n\\lim_{n \\to \\infty} M_n = 0\n$$\nwhere $M_n$ is the supremum of the absolute difference between $f_n(x)$ and $f(x)$ over the set $S$, defined as:\n$$\nM_n = \\sup_{x \\in S} |f_n(x) - f(x)|\n$$\nThe value $M_n$ represents the largest discrepancy between the function $f_n$ and the limit function $f$ for a given $n$. The limit of $M_n$ as $n \\to \\infty$, which we will call $L$, is a decisive criterion for determining uniform convergence.\n\n#### Problem Statement\nConsider the sequence of functions $f_n(x) = x^n$ defined on the closed interval $S = [0, \\frac{1}{2}]$.\nYour task is to derive the value of the limit $L$, where:\n$$\nL = \\lim_{n \\to \\infty} \\left( \\sup_{x \\in S} |f_n(x) - f(x)| \\right)\n$$\nand $f(x)$ is the pointwise limit of the sequence $f_n(x)$ on $S$.", "solution": "The problem asks for the calculation of the limit $L = \\lim_{n \\to \\infty} M_n$, where $M_n = \\sup_{x \\in [0, 1/2]} |f_n(x) - f(x)|$. We will solve this by following a four-step process.\n\n**Step 1: Determine the pointwise limit function $f(x)$**\n\nThe pointwise limit $f(x)$ is defined as the limit of $f_n(x)$ as $n \\to \\infty$ for each fixed $x$ in the interval $S = [0, \\frac{1}{2}]$.\n$$\nf(x) = \\lim_{n \\to \\infty} f_n(x) = \\lim_{n \\to \\infty} x^n\n$$\nFor any $x$ in the interval $[0, \\frac{1}{2}]$, the value of $x$ satisfies $|x| \\le \\frac{1}{2}  1$. The limit of a geometric sequence $r^n$ as $n \\to \\infty$ is $0$ if $|r|1$.\nThus, for every $x \\in [0, \\frac{1}{2}]$, the limit is zero.\n$$\nf(x) = 0\n$$\nSo, the pointwise limit function on the interval $S$ is the zero function.\n\n**Step 2: Formulate the expression for $M_n$**\n\nNow we substitute the expressions for $f_n(x)$ and $f(x)$ into the definition of $M_n$.\n$$\nM_n = \\sup_{x \\in [0, 1/2]} |f_n(x) - f(x)| = \\sup_{x \\in [0, 1/2]} |x^n - 0|\n$$\n$$\nM_n = \\sup_{x \\in [0, 1/2]} |x^n|\n$$\nSince $x$ is in the interval $[0, \\frac{1}{2}]$, $x$ is always non-negative. Therefore, $x^n$ is also non-negative, and the absolute value bars can be removed.\n$$\nM_n = \\sup_{x \\in [0, 1/2]} (x^n)\n$$\n\n**Step 3: Evaluate the supremum for $M_n$**\n\nWe need to find the least upper bound (supremum) of the function $g(x) = x^n$ on the closed interval $[0, \\frac{1}{2}]$ for a fixed integer $n \\ge 1$.\nTo find the maximum value of $g(x)$, we can analyze its derivative with respect to $x$:\n$$\ng'(x) = \\frac{d}{dx}(x^n) = n x^{n-1}\n$$\nFor any $x \\in (0, \\frac{1}{2}]$, we have $x  0$ and $n \\ge 1$, so $g'(x) = n x^{n-1}  0$. This indicates that the function $g(x) = x^n$ is strictly increasing on the interval $[0, \\frac{1}{2}]$.\nFor a continuous function that is strictly increasing on a closed interval $[a, b]$, its supremum (and maximum value) is attained at the right endpoint, $x=b$.\nIn our case, the supremum of $x^n$ on $[0, \\frac{1}{2}]$ occurs at $x=\\frac{1}{2}$.\n$$\nM_n = \\left(\\frac{1}{2}\\right)^n = \\frac{1}{2^n}\n$$\n\n**Step 4: Calculate the final limit $L$**\n\nFinally, we compute the limit of $M_n$ as $n \\to \\infty$.\n$$\nL = \\lim_{n \\to \\infty} M_n = \\lim_{n \\to \\infty} \\frac{1}{2^n}\n$$\nThis is the limit of a geometric sequence with ratio $r = \\frac{1}{2}$. Since $|r|  1$, the limit is $0$.\n$$\nL = 0\n$$\nThe value of the limit is $0$, which confirms that the sequence of functions $f_n(x) = x^n$ converges uniformly on the interval $[0, \\frac{1}{2}]$. The question asks for the derivation of this limit value.", "answer": "$$\n\\boxed{0}\n$$", "id": "40394"}, {"introduction": "While many sequences converge uniformly, it is equally important to understand the ways in which this property can fail. This practice problem introduces a classic example of a sequence that converges pointwise but not uniformly [@problem_id:2332959]. The functions in this sequence exhibit a \"traveling hump\" whose peak remains at a constant height while its position shifts as $n$ increases. Analyzing this behavior requires using calculus to find the maximum of each function in the sequence, a crucial skill for rigorously demonstrating the failure of uniform convergence.", "problem": "Consider the sequence of functions $f_n: [0, 1] \\to \\mathbb{R}$ defined by\n$$\nf_n(x) = \\frac{nx}{1 + n^2x^2}\n$$\nfor each integer $n \\ge 1$.\n\nFirst, determine the pointwise limit function $f(x) = \\lim_{n \\to \\infty} f_n(x)$ for all $x \\in [0, 1]$. Then, to analyze the nature of this convergence, evaluate the limit $L = \\lim_{n \\to \\infty} M_n$, where $M_n = \\sup_{x \\in [0,1]} |f_n(x) - f(x)|$.\n\nBased on your analysis, which one of the following statements is correct?\n\nA. The sequence converges uniformly, and $L=0$.\n\nB. The sequence does not converge uniformly, and $L=1/2$.\n\nC. The sequence does not converge uniformly, and $L=1$.\n\nD. The sequence does not converge uniformly, and $L=0$.\n\nE. The sequence converges uniformly, and $L=1/2$.", "solution": "We analyze the sequence $f_{n}(x) = \\frac{n x}{1 + n^{2} x^{2}}$ on $[0,1]$.\n\nFirst, we determine the pointwise limit $f(x) = \\lim_{n \\to \\infty} f_{n}(x)$. For $x=0$, we have $f_{n}(0) = 0$ for all $n$, so $\\lim_{n \\to \\infty} f_{n}(0) = 0$. For $x \\in (0,1]$, rewrite\n$$\nf_{n}(x) = \\frac{n x}{1 + n^{2} x^{2}} = \\frac{1}{\\frac{1}{n x} + n x}.\n$$\nAs $n \\to \\infty$, we have $n x \\to \\infty$ and $\\frac{1}{n x} \\to 0$, hence the denominator tends to $+\\infty$ and $f_{n}(x) \\to 0$. Therefore, the pointwise limit is\n$$\nf(x) = 0 \\quad \\text{for all } x \\in [0,1].\n$$\n\nNext, we analyze the nature of convergence by computing $M_{n} = \\sup_{x \\in [0,1]} |f_{n}(x) - f(x)| = \\sup_{x \\in [0,1]} f_{n}(x)$, since $f(x)=0$ and $f_{n}(x) \\ge 0$ on $[0,1]$. To find the supremum, differentiate\n$$\nh(x) = \\frac{n x}{1 + n^{2} x^{2}},\n$$\nso\n$$\nh'(x) = \\frac{n(1 + n^{2} x^{2}) - n x \\cdot 2 n^{2} x}{(1 + n^{2} x^{2})^{2}} = \\frac{n - n^{3} x^{2}}{(1 + n^{2} x^{2})^{2}}.\n$$\nCritical points satisfy $n - n^{3} x^{2} = 0$, i.e., $x = \\frac{1}{n}$. Evaluating $h$ at $x=\\frac{1}{n}$ gives\n$$\nh\\!\\left(\\frac{1}{n}\\right) = \\frac{n \\cdot \\frac{1}{n}}{1 + n^{2} \\cdot \\frac{1}{n^{2}}} = \\frac{1}{2}.\n$$\nSince $h(0)=0$ and $h$ increases on $\\left[0,\\frac{1}{n}\\right]$ and decreases on $\\left[\\frac{1}{n},1\\right]$, the supremum on $[0,1]$ is attained at $x=\\frac{1}{n}$ with value\n$$\nM_{n} = \\sup_{x \\in [0,1]} f_{n}(x) = \\frac{1}{2}.\n$$\nTherefore,\n$$\nL = \\lim_{n \\to \\infty} M_{n} = \\lim_{n \\to \\infty} \\frac{1}{2} = \\frac{1}{2}.\n$$\nSince $M_{n}$ does not tend to $0$, the convergence is not uniform. The correct statement is: the sequence does not converge uniformly, and $L = \\frac{1}{2}$.", "answer": "$$\\boxed{B}$$", "id": "2332959"}, {"introduction": "A primary reason for the importance of uniform convergence in mathematical analysis is its role in justifying the interchange of limit operations, such as differentiation and integration. This exercise explores the delicate relationship between uniform convergence and differentiation [@problem_id:2332994]. You will investigate a sequence of functions that does converge uniformly, yet whose sequence of derivatives fails to converge at all. This serves as a critical cautionary tale, illustrating that uniform convergence of $f_n$ to $f$ is not sufficient on its own to ensure that the derivatives $f_n'$ converge to $f'$, and motivating the need for stronger theorems to handle such cases.", "problem": "Consider the sequence of real-valued functions $\\{f_n\\}_{n=1}^{\\infty}$ defined on the set of all real numbers, $\\mathbb{R}$, by the formula:\n$$f_n(x) = \\frac{\\sin(n^2 x)}{n\\sqrt{n}}$$\nfor each positive integer $n$ and for all $x \\in \\mathbb{R}$.\n\nAnalyze the convergence properties of this sequence and its sequence of derivatives, $\\{f_n'\\}_{n=1}^{\\infty}$. Based on your analysis, select the statement that correctly describes the behavior of these sequences.\n\nA. The sequence $f_n(x)$ converges uniformly on $\\mathbb{R}$, and the sequence of derivatives $f_n'(x)$ converges pointwise on $\\mathbb{R}$.\n\nB. The sequence $f_n(x)$ converges uniformly on $\\mathbb{R}$, but the sequence of derivatives $f_n'(x)$ does not converge pointwise on $\\mathbb{R}$.\n\nC. The sequence $f_n(x)$ does not converge uniformly on $\\mathbb{R}$, but the sequence of derivatives $f_n'(x)$ converges pointwise on $\\mathbb{R}$.\n\nD. The sequence $f_n(x)$ does not converge uniformly on $\\mathbb{R}$, and the sequence of derivatives $f_n'(x)$ also does not converge pointwise on $\\mathbb{R}$.\n\nE. The sequence $f_n(x)$ converges pointwise but not uniformly on $\\mathbb{R}$, and the sequence of derivatives $f_n'(x)$ converges uniformly on $\\mathbb{R}$.", "solution": "We analyze the sequence $f_{n}(x) = \\frac{\\sin(n^{2} x)}{n \\sqrt{n}}$ on $\\mathbb{R}$.\n\nFirst, for every $x \\in \\mathbb{R}$ and every $n \\in \\mathbb{N}$,\n$$\n|f_{n}(x)| = \\left|\\frac{\\sin(n^{2} x)}{n \\sqrt{n}}\\right| \\leq \\frac{1}{n \\sqrt{n}} = \\frac{1}{n^{3/2}}.\n$$\nSince $\\frac{1}{n^{3/2}} \\to 0$ as $n \\to \\infty$, it follows that $f_{n}(x) \\to 0$ pointwise for all $x \\in \\mathbb{R}$. Moreover,\n$$\n\\sup_{x \\in \\mathbb{R}} |f_{n}(x)| \\leq \\frac{1}{n^{3/2}} \\to 0,\n$$\nso given any $\\varepsilon > 0$, choose $N$ such that for all $n \\geq N$ we have $\\frac{1}{n^{3/2}}  \\varepsilon$. Then for all $x \\in \\mathbb{R}$ and all $n \\geq N$, $|f_{n}(x) - 0| \\leq \\frac{1}{n^{3/2}}  \\varepsilon$. Hence $f_{n} \\to 0$ uniformly on $\\mathbb{R}$.\n\nNext, we compute derivatives using the chain rule:\n$$\nf_{n}'(x) = \\frac{d}{dx}\\left(\\frac{\\sin(n^{2} x)}{n \\sqrt{n}}\\right) = \\frac{n^{2} \\cos(n^{2} x)}{n \\sqrt{n}} = \\sqrt{n}\\,\\cos(n^{2} x).\n$$\nWe examine pointwise convergence of $f_{n}'(x)$. At $x = 0$,\n$$\nf_{n}'(0) = \\sqrt{n}\\,\\cos(0) = \\sqrt{n} \\to +\\infty \\quad \\text{as } n \\to \\infty,\n$$\nso the sequence $\\{f_{n}'(x)\\}$ does not converge at $x = 0$. Therefore the sequence of derivatives does not converge pointwise on $\\mathbb{R}$.\n\nCombining these, $f_{n}$ converges uniformly on $\\mathbb{R}$, while $f_{n}'$ does not converge pointwise on $\\mathbb{R}$. This corresponds to option B.", "answer": "$$\\boxed{B}$$", "id": "2332994"}]}