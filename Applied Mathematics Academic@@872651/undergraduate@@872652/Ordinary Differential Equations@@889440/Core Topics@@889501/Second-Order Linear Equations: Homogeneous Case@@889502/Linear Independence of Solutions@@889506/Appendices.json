{"hands_on_practices": [{"introduction": "Understanding linear dependence starts with its core definition: a set of functions is linearly dependent if a non-trivial linear combination of them equals zero for all values in the domain. This first exercise provides a direct application of this principle, where you will use known identities to find the specific constants that reveal a linear relationship among a set of hyperbolic functions. This practice solidifies the foundational concept before we introduce more systematic computational tools. [@problem_id:2183817]", "problem": "Consider the following set of three functions defined for all real numbers $x$:\n$f_1(x) = \\cosh(2x)$\n$f_2(x) = \\sinh^2(x)$\n$f_3(x) = 1$\n\nIt is given that this set of functions is linearly dependent. Therefore, a non-trivial linear combination of these functions is equal to zero for all $x$. Select the tuple of coefficients $(c_1, c_2, c_3)$ from the choices below that satisfies the condition $c_1 f_1(x) + c_2 f_2(x) + c_3 f_3(x) = 0$.\n\nA. $(1, 2, 1)$\n\nB. $(1, -2, -1)$\n\nC. $(1, 1, -2)$\n\nD. $(2, -1, 1)$\n\nE. $(2, 1, -1)$", "solution": "We seek nontrivial constants $c_{1},c_{2},c_{3}$ such that for all real $x$,\n$$\nc_{1}\\cosh(2x)+c_{2}\\sinh^{2}(x)+c_{3}=0.\n$$\nUsing the definitions $\\cosh(x)=\\frac{\\exp(x)+\\exp(-x)}{2}$ and $\\sinh(x)=\\frac{\\exp(x)-\\exp(-x)}{2}$, compute\n$$\n\\cosh(2x)=\\frac{\\exp(2x)+\\exp(-2x)}{2},\n$$\nand\n$$\n2\\sinh^{2}(x)+1=2\\left(\\frac{\\exp(x)-\\exp(-x)}{2}\\right)^{2}+1=2\\cdot\\frac{\\exp(2x)-2+\\exp(-2x)}{4}+1=\\frac{\\exp(2x)+\\exp(-2x)}{2}.\n$$\nTherefore,\n$$\n\\cosh(2x)=2\\sinh^{2}(x)+1 \\quad \\text{for all } x.\n$$\nRearranging gives\n$$\n\\cosh(2x)-2\\sinh^{2}(x)-1=0 \\quad \\text{for all } x,\n$$\nwhich matches the required form with coefficients $(c_{1},c_{2},c_{3})=(1,-2,-1)$. Among the given options, this corresponds to choice B.", "answer": "$$\\boxed{B}$$", "id": "2183817"}, {"introduction": "While applying the definition directly is fundamental, testing for linear independence across an entire interval can be challenging. The Wronskian provides a more powerful and systematic method, particularly for functions that are solutions to linear ordinary differential equations. In this problem, you will compute the Wronskian for a set of three functions to test for their linear independence, gaining procedural fluency with this essential determinant-based tool. [@problem_id:2183825]", "problem": "In the study of homogeneous linear ordinary differential equations, the Wronskian is a determinant used to analyze the linear independence of a set of solutions. Consider a system where the behavior of certain physical quantities is described by the following three functions, defined for all real numbers $x$:\n\n$f_1(x) = e^{-x}$\n$f_2(x) = x e^{-x}$\n$f_3(x) = x^2 e^{-x}$\n\nCalculate the Wronskian of this set of functions, denoted as $W(f_1, f_2, f_3)(x)$. Express your answer as a function of $x$.", "solution": "The Wronskian of three functions $f_{1}, f_{2}, f_{3}$ is defined by\n$$\nW(f_{1},f_{2},f_{3})(x)=\\det\\begin{pmatrix}\nf_{1}  f_{2}  f_{3}\\\\\nf_{1}'  f_{2}'  f_{3}'\\\\\nf_{1}''  f_{2}''  f_{3}''\n\\end{pmatrix}.\n$$\nGiven $f_{1}(x)=\\exp(-x)$, $f_{2}(x)=x\\exp(-x)$, and $f_{3}(x)=x^{2}\\exp(-x)$, compute derivatives using the product rule and $\\frac{d}{dx}\\exp(-x)=-\\exp(-x)$:\n$$\nf_{1}'=-\\exp(-x),\\quad f_{1}''=\\exp(-x),\n$$\n$$\nf_{2}'=\\exp(-x)-x\\exp(-x)=(1-x)\\exp(-x),\\quad f_{2}''=(x-2)\\exp(-x),\n$$\n$$\nf_{3}'=(2x-x^{2})\\exp(-x),\\quad f_{3}''=(x^{2}-4x+2)\\exp(-x).\n$$\nThus,\n$$\nW=\\det\\begin{pmatrix}\n\\exp(-x)  x\\exp(-x)  x^{2}\\exp(-x)\\\\\n-\\exp(-x)  (1-x)\\exp(-x)  (2x-x^{2})\\exp(-x)\\\\\n\\exp(-x)  (x-2)\\exp(-x)  (x^{2}-4x+2)\\exp(-x)\n\\end{pmatrix}.\n$$\nFactor $\\exp(-x)$ from each column to obtain\n$$\nW=\\exp(-3x)\\det\\begin{pmatrix}\n1  x  x^{2}\\\\\n-1  1-x  2x-x^{2}\\\\\n1  x-2  x^{2}-4x+2\n\\end{pmatrix}.\n$$\nCompute the remaining determinant using row operations that preserve the determinant (adding a multiple of one row to another):\nperform $R_{2}\\leftarrow R_{2}+R_{1}$ and $R_{3}\\leftarrow R_{3}-R_{1}$ to get\n$$\n\\det\\begin{pmatrix}\n1  x  x^{2}\\\\\n0  1  2x\\\\\n0  -2  -4x+2\n\\end{pmatrix}.\n$$\nExpanding along the first column,\n$$\n\\det=\\det\\begin{pmatrix}1  2x\\\\ -2  -4x+2\\end{pmatrix}\n=1\\cdot(-4x+2)-(2x)(-2)=(-4x+2)+4x=2.\n$$\nTherefore,\n$$\nW(f_{1},f_{2},f_{3})(x)=2\\exp(-3x).\n$$", "answer": "$$\\boxed{2\\exp(-3x)}$$", "id": "2183825"}, {"introduction": "The Wronskian is a powerful test, but it is essential to understand its theoretical limits. A non-zero Wronskian on an interval guarantees linear independence, but the converse is not always true; a Wronskian that is identically zero does not automatically imply linear dependence without additional conditions. This final exercise explores a famous counterexample with piecewise functions that highlights this crucial subtlety, reinforcing that the fundamental definition of linear independence is the ultimate criterion. [@problem_id:2183800]", "problem": "Consider two functions, $y_1(x)$ and $y_2(x)$, defined on the interval $(-\\infty, \\infty)$ as follows:\n\n$$\ny_1(x) = \\begin{cases} x^2,  x \\ge 0 \\\\ 0,  x  0 \\end{cases}\n$$\n\n$$\ny_2(x) = \\begin{cases} 0,  x \\ge 0 \\\\ x^2,  x  0 \\end{cases}\n$$\n\nDetermine the linear dependence or independence of these two functions on the entire interval $(-\\infty, \\infty)$. Choose the statement that correctly describes the relationship.\n\nA. The functions are linearly independent.\n\nB. The functions are linearly dependent because their Wronskian $W(y_1, y_2)(x)$ is equal to zero for all $x$ in $(-\\infty, \\infty)$.\n\nC. The functions are linearly dependent because $y_1(x)$ is a constant multiple of $y_2(x)$.\n\nD. The relationship cannot be determined because the functions are not twice differentiable at $x=0$.", "solution": "We use the definition of linear dependence for functions on a set: functions $y_{1}$ and $y_{2}$ are linearly dependent on $(-\\infty,\\infty)$ if there exist constants $\\alpha$ and $\\beta$, not both zero, such that\n$$\n\\alpha y_{1}(x)+\\beta y_{2}(x)=0 \\quad \\text{for all } x\\in(-\\infty,\\infty).\n$$\nOtherwise, they are linearly independent.\n\nAssume $\\alpha y_{1}(x)+\\beta y_{2}(x)=0$ for all $x$. For $x>0$, we have $y_{1}(x)=x^{2}$ and $y_{2}(x)=0$, so the relation becomes\n$$\n\\alpha x^{2}=0 \\quad \\text{for all } x>0,\n$$\nwhich implies $\\alpha=0$. For $x0$, we have $y_{1}(x)=0$ and $y_{2}(x)=x^{2}$, so the relation becomes\n$$\n\\beta x^{2}=0 \\quad \\text{for all } x0,\n$$\nwhich implies $\\beta=0$. This contradicts the requirement that not both coefficients are zero. Therefore, $y_{1}$ and $y_{2}$ are linearly independent on $(-\\infty,\\infty)$.\n\nTo address the provided options: option C is false because $y_{1}$ is not a constant multiple of $y_{2}$; for $x0$, $y_{1}(x)=x^{2}$ while $y_{2}(x)=0$, which cannot be related by a nonzero constant factor. Option B incorrectly concludes dependence from the Wronskian being identically zero. Indeed, computing derivatives,\n$$\ny_{1}'(x)=\\begin{cases}2x, x0\\\\0, x\\le 0\\end{cases}, \\quad\ny_{2}'(x)=\\begin{cases}0, x\\ge 0\\\\2x, x0\\end{cases},\n$$\ngives the Wronskian\n$$\nW(y_{1},y_{2})(x)=y_{1}(x)y_{2}'(x)-y_{2}(x)y_{1}'(x)=0 \\quad \\text{for all } x,\n$$\nbut $W\\equiv 0$ does not imply linear dependence unless additional hypotheses hold (such as both functions being solutions of the same second-order linear homogeneous differential equation with continuous coefficients on an interval). Option D is false because linear independence is determined by the algebraic definition above and does not require twice differentiability at $x=0$.\n\nHence, the correct statement is that the functions are linearly independent.", "answer": "$$\\boxed{A}$$", "id": "2183800"}]}