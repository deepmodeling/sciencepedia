{"hands_on_practices": [{"introduction": "Numerical methods for ODEs broadly fall into two categories: one-step methods and multi-step methods. While multi-step methods like the Adams-Bashforth family are often more computationally efficient, they require several previous data points to compute the next step. This practice demonstrates a common and practical solution: using a robust, self-starting one-step method like the classical fourth-order Runge-Kutta (RK4) to generate the initial values needed to \"bootstrap\" the multi-step solver. [@problem_id:2158977]", "problem": "Consider the initial value problem (IVP) defined by the ordinary differential equation:\n$$\ny'(t) = t - y(t)^2\n$$\nwith the initial condition $y(0) = 1$.\n\nYou are tasked with approximating the value of $y(t)$ at $t=0.3$. Use a fixed step size of $h=0.1$. To obtain the solution, you must employ a hybrid numerical procedure. First, perform two consecutive steps of the classical fourth-order Runge-Kutta (RK4) method, starting from the initial condition at $t=0$, to find the approximate values of $y(0.1)$ and $y(0.2)$. Subsequently, apply a single step of the two-step Adams-Bashforth (AB2) method to find the final approximation for $y(0.3)$.\n\nFor a generic first-order ODE $y' = f(t, y)$, the formulas for the methods are given by:\n\n- **Classical fourth-order Runge-Kutta (RK4) method:**\n  $y_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)$\n  where\n  $k_1 = f(t_n, y_n)$\n  $k_2 = f(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_1)$\n  $k_3 = f(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_2)$\n  $k_4 = f(t_n + h, y_n + h k_3)$\n\n- **Two-step Adams-Bashforth (AB2) method:**\n  $y_{n+2} = y_{n+1} + \\frac{h}{2}\\left(3f(t_{n+1}, y_{n+1}) - f(t_n, y_n)\\right)$\n\nReport your final numerical answer for the approximation of $y(0.3)$ rounded to five significant figures.", "solution": "We are given the IVP $y'(t)=f(t,y)=t-y^{2}$ with $y(0)=1$ and step size $h=0.1$. We must take two RK4 steps to obtain $y(0.1)$ and $y(0.2)$, then one AB2 step to obtain $y(0.3)$.\n\nFirst RK4 step from $t_{0}=0$, $y_{0}=1$ to $t_{1}=0.1$:\nCompute\n$$\nk_{1}=f(0,1)=0-1=-1,\n$$\n$$\nk_{2}=f\\!\\left(0.05,\\,1+\\frac{h}{2}k_{1}\\right)=f(0.05,\\,1-0.05)=0.05-(0.95)^{2}=0.05-0.9025=-0.8525,\n$$\n$$\nk_{3}=f\\!\\left(0.05,\\,1+\\frac{h}{2}k_{2}\\right)=f(0.05,\\,1+0.05\\cdot(-0.8525))=f(0.05,\\,0.957375)=0.05-(0.957375)^{2}.\n$$\nSince $(0.957375)^{2}=0.916566890625$, we get $k_{3}=0.05-0.916566890625=-0.866566890625$.\nNext,\n$$\nk_{4}=f\\!\\left(0.1,\\,1+h\\,k_{3}\\right)=f(0.1,\\,1+0.1\\cdot(-0.866566890625))=f(0.1,\\,0.9133433109375)=0.1-(0.9133433109375)^{2}.\n$$\nUsing $(0.9133433109375)^{2}=0.8341960036362748$, we get $k_{4}=0.1-0.8341960036362748=-0.7341960036362748$.\nThus,\n$$\ny_{1}=y_{0}+\\frac{h}{6}\\left(k_{1}+2k_{2}+2k_{3}+k_{4}\\right)\n=1+\\frac{0.1}{6}\\left(-1-1.705-1.73313378125-0.7341960036362748\\right),\n$$\nso\n$$\ny_{1}=1+\\frac{0.1}{6}\\left(-5.172329784886275\\right)=1-0.08620549641477125=0.9137945035852288.\n$$\n\nSecond RK4 step from $t_{1}=0.1$, $y_{1}=0.9137945035852288$ to $t_{2}=0.2$:\nCompute\n$$\nk_{1}'=f(0.1,y_{1})=0.1-y_{1}^{2}.\n$$\nWith $y_{1}^{2}=0.8350203947825746$, this gives $k_{1}'=0.1-0.8350203947825746=-0.7350203947825746$.\nNext,\n$$\nk_{2}'=f\\!\\left(0.15,\\,y_{1}+\\frac{h}{2}k_{1}'\\right)=f\\!\\left(0.15,\\,0.9137945035852288+0.05\\cdot(-0.7350203947825746)\\right)\n=f(0.15,\\,0.8770434838461001),\n$$\nso\n$$\nk_{2}'=0.15-(0.8770434838461001)^{2}=-0.6192052725569046.\n$$\nThen\n$$\nk_{3}'=f\\!\\left(0.15,\\,y_{1}+\\frac{h}{2}k_{2}'\\right)=f\\!\\left(0.15,\\,0.9137945035852288+0.05\\cdot(-0.6192052725569046)\\right)\n=f(0.15,\\,0.8828342399573836),\n$$\nhence\n$$\nk_{3}'=0.15-(0.8828342399573836)^{2}=-0.6293962952407671.\n$$\nFinally,\n$$\nk_{4}'=f\\!\\left(0.2,\\,y_{1}+h\\,k_{3}'\\right)=f\\!\\left(0.2,\\,0.9137945035852288+0.1\\cdot(-0.6293962952407671)\\right)\n=f(0.2,\\,0.8508548740611521),\n$$\nso\n$$\nk_{4}'=0.2-(0.8508548740611521)^{2}=-0.5239540167137337.\n$$\nNow compute\n$$\ny_{2}=y_{1}+\\frac{h}{6}\\left(k_{1}'+2k_{2}'+2k_{3}'+k_{4}'\\right)\n=0.9137945035852288+\\frac{0.1}{6}\\left(-0.7350203947825746-1.2384105451138092-1.2587925904815342-0.5239540167137337\\right),\n$$\nso\n$$\ny_{2}=0.9137945035852288+\\frac{0.1}{6}\\left(-3.7561775470916517\\right)\n=0.9137945035852288-0.06260295911819419=0.8511915444670346.\n$$\n\nAdamsâ€“Bashforth two-step (AB2) from $t_{2}=0.2$ to $t_{3}=0.3$:\nWe need $f_{1}=f(t_{1},y_{1})$ and $f_{2}=f(t_{2},y_{2})$.\nWe already have $f_{1}=k_{1}'=-0.7350203947825746$.\nNext,\n$$\nf_{2}=f(0.2,\\,y_{2})=0.2-y_{2}^{2}=0.2-(0.8511915444670346)^{2}=-0.5245270453721758.\n$$\nNow apply AB2:\n$$\ny_{3}=y_{2}+\\frac{h}{2}\\left(3f_{2}-f_{1}\\right)\n=0.8511915444670346+\\frac{0.1}{2}\\left(3\\cdot(-0.5245270453721758)-(-0.7350203947825746)\\right).\n$$\nCompute the bracket:\n$$\n3f_{2}-f_{1}=-1.5735811361165274+0.7350203947825746=-0.8385607413339528,\n$$\nso\n$$\ny_{3}=0.8511915444670346+0.05\\cdot(-0.8385607413339528)=0.8511915444670346-0.04192803706669764=0.8092635074003369.\n$$\n\nRounding to five significant figures gives $y(0.3)\\approx 0.80926$.", "answer": "$$\\boxed{0.80926}$$", "id": "2158977"}, {"introduction": "A central theme in numerical analysis is not just finding an answer, but also understanding and improving its accuracy. This exercise introduces Richardson extrapolation, a powerful and general technique for creating a more accurate result from two less accurate ones. By running the simple Forward Euler method with two different step sizes, $h$ and $h/2$, you can strategically combine the results to cancel out the dominant error term, yielding a higher-order approximation. [@problem_id:2158966] This practice provides a concrete look at the principles underlying error estimation and accuracy enhancement.", "problem": "Consider the initial value problem defined by the differential equation $y'(t) = y(t)$ with the initial condition $y(0) = 1$. We wish to find a high-quality approximation for the value of the solution at time $t=h$, for some small step size $h>0$.\n\nLet $A_1$ be the numerical approximation of $y(h)$ obtained by applying one step of the Forward Euler method with a step size of $h$.\n\nLet $A_2$ be the numerical approximation of $y(h)$ obtained by applying two successive steps of the Forward Euler method, each with a step size of $h/2$.\n\nThe Forward Euler method is known to be a first-order accurate method. However, by appropriately combining the two approximations $A_1$ and $A_2$, one can cancel the leading error term and obtain a new approximation for $y(h)$ which is second-order accurate.\n\nDerive the expression for this improved, second-order accurate approximation in terms of the step size $h$.", "solution": "We use the Forward Euler method $y_{n+1}=y_{n}+h f(t_{n},y_{n})$ with $f(t,y)=y$ and $y(0)=1$.\n\nOne step of size $h$ gives\n$$\nA_{1}=y(h)\\ \\text{(approx)}=y_{0}+h f(t_{0},y_{0})=1+h.\n$$\nTwo successive steps of size $h/2$ give\n$$\ny\\left(\\tfrac{h}{2}\\right)\\ \\text{(approx)}=1+\\tfrac{h}{2},\\qquad\nA_{2}=y(h)\\ \\text{(approx)}=y\\left(\\tfrac{h}{2}\\right)+\\tfrac{h}{2} f\\!\\left(\\tfrac{h}{2},y\\left(\\tfrac{h}{2}\\right)\\right)=\\left(1+\\tfrac{h}{2}\\right)+\\tfrac{h}{2}\\left(1+\\tfrac{h}{2}\\right)=1+h+\\tfrac{h^{2}}{4}.\n$$\nSince Forward Euler is first-order accurate, the global error when integrating to a fixed time $T$ behaves as $y(T) - A(h) = Ch + O(h^2)$, where $A(h)$ is the numerical result using step size $h$. This implies $A(h) = y(T) - Ch - O(h^2)$. Applying this to our problem where the final time is $h$:\n$$\nA_{1}=y(h)+C h+O(h^{2}),\\qquad A_{2}=y(h)+C \\tfrac{h}{2}+O(h^{2}),\n$$\nfor some constant $C$ independent of $h$. Eliminating the $Ch$ term by Richardson extrapolation yields the improved estimate $A_{\\text{new}} = 2A_2 - A_1$. This combination has an error of $O(h^2)$.\n$$\ny(h) \\approx 2A_{2}-A_{1}.\n$$\nSubstituting the computed $A_{1}$ and $A_{2}$:\n$$\n2A_{2}-A_{1}=2\\left(1+h+\\tfrac{h^{2}}{4}\\right)-(1+h)=1+h+\\tfrac{h^{2}}{2}.\n$$\nThis matches the Taylor expansion of the exact solution $y(h)=\\exp(h)=1+h+\\tfrac{h^{2}}{2}+O(h^{3})$ through terms of order $h^{2}$, confirming second-order accuracy. Therefore, the improved, second-order accurate approximation in terms of $h$ is $1+h+\\tfrac{h^{2}}{2}$.", "answer": "$$\\boxed{1+h+\\frac{h^{2}}{2}}$$", "id": "2158966"}, {"introduction": "For many challenging ODEs, the solution's behavior can vary dramatically, from smooth and slow to nearly instantaneous changes. In these cases, a fixed step size is highly inefficient. This is where adaptive step-size methods, like the Runge-Kutta-Fehlberg (RKF45) method, become essential. This problem presents a hypothetical scenario where you analyze how such a method intelligently reduces its step size as it approaches a finite-time singularity, a point where the solution \"blows up.\" [@problem_id:2158951] By deriving the theoretical scaling of the step size, you will gain insight into the sophisticated inner workings of modern ODE solvers.", "problem": "An adaptive step-size numerical method is used to solve the Ordinary Differential Equation (ODE) initial value problem given by:\n$$ y'(t) = 1 + [y(t)]^2, \\quad y(0) = 0 $$\nThe analytical solution to this problem is known to be $y(t) = \\tan(t)$, which exhibits a finite-time singularity (blow-up) at $t_s = \\pi/2$.\n\nThe numerical solver is based on the Runge-Kutta-Fehlberg 4(5) (RKF45) method. This method computes two simultaneous approximations to the solution, one of fourth-order accuracy and one of fifth-order accuracy. The difference between these two approximations provides an estimate for the local truncation error of the fourth-order method. For a step size $h$, this error estimate is known to be proportional to $h^5 |y^{(5)}(t)|$, where $y^{(5)}(t)$ is the fifth derivative of the exact solution. The solver's step-size control algorithm adjusts $h$ at each step to keep this estimated error approximately constant and equal to a predefined tolerance.\n\nAs the numerical integration approaches the singularity at $t_s$, the step size $h$ must decrease dramatically to maintain the desired accuracy. It is hypothesized that for times $t$ close to $t_s$, the step size $h$ taken at time $t$ scales with the distance to the singularity, $(t_s - t)$, according to the power law:\n$$ h \\approx C (t_s - t)^k $$\nfor some constant $C$ and a scaling exponent $k$.\n\nAssuming this scaling model is accurate, determine the theoretical value of the exponent $k$. Express your answer as a decimal rounded to three significant figures.", "solution": "The RKF45 controller keeps the estimated local error of the fourth-order solution approximately equal to a prescribed tolerance. As given, the error estimate at time $t$ with step size $h$ scales like\n$$\nE(t,h) \\sim K\\, h^{5}\\, |y^{(5)}(t)|,\n$$\nfor some constant $K>0$. Enforcing $E(t,h)\\approx \\text{tol}$ yields\n$$\nh^{5}\\, |y^{(5)}(t)| \\sim \\text{const} \\quad \\Longrightarrow \\quad h \\sim \\left(\\text{const}\\right)^{1/5}\\, |y^{(5)}(t)|^{-1/5}.\n$$\nThus the step-size scaling is determined by the asymptotics of $|y^{(5)}(t)|$ as $t \\to t_{s}^{-}$.\n\nFor the exact solution $y(t)=\\tan t$ with $t_{s}=\\frac{\\pi}{2}$, set $\\delta=t_{s}-t$. Using trigonometric expansions for $t$ near $t_s$ (i.e., $\\delta$ near 0),\n$$\n\\cos t=\\cos(t_{s}-\\delta)=\\sin \\delta \\sim \\delta, \\qquad \\sin t=\\sin(t_{s}-\\delta)=\\cos \\delta \\sim 1,\n$$\nso\n$$\ny(t)=\\tan t=\\frac{\\sin t}{\\cos t} \\sim \\frac{1}{\\delta}=\\frac{1}{t_{s}-t}.\n$$\nDifferentiating $\\delta^{-1}=(t_s-t)^{-1}$ repeatedly with respect to $t$, one finds by induction that\n$$\n\\frac{d^{n}}{dt^{n}}\\left((t_s-t)^{-1}\\right)=n!\\,(t_s-t)^{-(n+1)},\n$$\nup to an overall sign, which is irrelevant under absolute value. Therefore,\n$$\n|y^{(5)}(t)| \\sim 5!\\, (t_{s}-t)^{-6}.\n$$\nSubstituting this into the step-size relation gives\n$$\nh \\sim \\left(\\text{const}\\right)^{1/5}\\, \\left[(t_{s}-t)^{-6}\\right]^{-1/5} = C\\,(t_{s}-t)^{6/5},\n$$\nfor some constant $C>0$. Hence the scaling exponent is\n$$\nk=\\frac{6}{5}=1.20.\n$$", "answer": "$$\\boxed{1.20}$$", "id": "2158951"}]}