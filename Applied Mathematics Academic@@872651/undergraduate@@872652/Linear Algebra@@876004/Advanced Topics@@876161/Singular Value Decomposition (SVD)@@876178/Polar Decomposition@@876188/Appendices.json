{"hands_on_practices": [{"introduction": "We begin with a foundational case to build intuition for the polar decomposition. A pure rotation matrix is, by definition, an orthogonal transformation, so what happens when we decompose it? This exercise demonstrates how the polar decomposition correctly identifies that no stretching or scaling is involved, isolating the rotation and revealing a trivial scaling component, thereby solidifying the core concept of separating a transformation into its rotational and stretching parts [@problem_id:1383651].", "problem": "A linear transformation in a two-dimensional real vector space, $\\mathbb{R}^2$, is given by a counter-clockwise rotation about the origin by an angle $\\theta$, where $0  \\theta  \\pi$. This transformation is represented by the matrix:\n$$A = \\begin{pmatrix} \\cos\\theta  -\\sin\\theta \\\\ \\sin\\theta  \\cos\\theta \\end{pmatrix}$$\nAny invertible real matrix $A$ has a unique polar decomposition of the form $A = UP$, where $U$ is an orthogonal matrix (satisfying $U^T U = I$, where $I$ is the identity matrix) and $P$ is a symmetric positive-definite matrix (a symmetric matrix with all positive eigenvalues). The matrix $U$ represents a pure rotation or reflection, while $P$ represents a pure scaling (stretching/compression) along orthogonal axes.\n\nFor the given rotation matrix $A$, which of the following options correctly identifies the matrices $U$ and $P$ in its polar decomposition? Let $I$ be the $2 \\times 2$ identity matrix.\n\nA) $U=A$ and $P=I$.\n\nB) $U=I$ and $P=A$.\n\nC) $U=A^T$ and $P=I$.\n\nD) $U=\\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}$ and $P=\\begin{pmatrix} \\cos\\theta  \\sin\\theta \\\\ \\sin\\theta  -\\cos\\theta \\end{pmatrix}$.\n\nE) Such a decomposition does not exist for the matrix $A$.", "solution": "We use the polar decomposition theorem: for any invertible real matrix $A$, there is a unique factorization $A=UP$ with $U$ orthogonal and $P$ symmetric positive-definite, given explicitly by\n$$\nP=(A^{T}A)^{1/2}, \\qquad U=A\\, (A^{T}A)^{-1/2}.\n$$\nFor the given $2\\times 2$ rotation matrix\n$$\nA=\\begin{pmatrix}\n\\cos\\theta  -\\sin\\theta\\\\\n\\sin\\theta  \\cos\\theta\n\\end{pmatrix},\n$$\nwe first compute its transpose:\n$$\nA^{T}=\\begin{pmatrix}\n\\cos\\theta  \\sin\\theta\\\\\n-\\sin\\theta  \\cos\\theta\n\\end{pmatrix}.\n$$\nThen\n$$\nA^{T}A=\n\\begin{pmatrix}\n\\cos\\theta  \\sin\\theta\\\\\n-\\sin\\theta  \\cos\\theta\n\\end{pmatrix}\n\\begin{pmatrix}\n\\cos\\theta  -\\sin\\theta\\\\\n\\sin\\theta  \\cos\\theta\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\cos^{2}\\theta+\\sin^{2}\\theta  -\\cos\\theta\\sin\\theta+\\sin\\theta\\cos\\theta\\\\\n-\\sin\\theta\\cos\\theta+\\cos\\theta\\sin\\theta  \\sin^{2}\\theta+\\cos^{2}\\theta\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1  0\\\\\n0  1\n\\end{pmatrix}\n=I.\n$$\nTherefore,\n$$\nP=(A^{T}A)^{1/2}=I^{1/2}=I, \\qquad U=A\\,(A^{T}A)^{-1/2}=A\\,I=A.\n$$\nThe matrix $I$ is symmetric positive-definite, and $A$ is orthogonal since $A^{T}A=I$; thus $A=UP$ with $U=A$ and $P=I$ is indeed the polar decomposition. By uniqueness of the polar decomposition, this is the only valid choice.\n\nTo confirm the exclusivity among the options: option B would set $P=A$, which is not symmetric for $0\\theta\\pi$ (since $A=A^{T}$ only if $\\sin\\theta=0$, excluded by the given range). Option C would imply $A=A^{T}$, again false in the given range. Option D produces a matrix $P$ with determinant $-1$, hence not positive-definite. Option E is false because the decomposition exists for all invertible matrices, including rotations.\n\nThus the correct identification is $U=A$ and $P=I$.", "answer": "$$\\boxed{A}$$", "id": "1383651"}, {"introduction": "Having seen the decomposition of a pure rotation, we now tackle a transformation that combines both scaling and reorientation. This practice is a classic application of the standard polar decomposition procedure, where you must compute the positive semi-definite component $P$ from the matrix product $A^T A$. It highlights the power of the decomposition to cleanly disentangle these two distinct geometric actions—stretching and rotation/reflection—from a single, combined transformation matrix [@problem_id:1383671].", "problem": "A linear transformation on the Euclidean plane $\\mathbb{R}^2$ is represented by the matrix $A = \\begin{pmatrix} 0  2 \\\\ 3  0 \\end{pmatrix}$. This transformation can be uniquely factored into a scaling operation followed by a rigid motion (a rotation or reflection). This factorization is known as the polar decomposition, written as $A = UP$, where $P$ is a positive semi-definite symmetric matrix representing the scaling, and $U$ is an orthogonal matrix representing the rigid motion. The eigenvalues of the scaling matrix $P$ represent the factors by which the space is stretched along a set of orthogonal principal axes.\n\nCalculate the sum of these scaling factors.", "solution": "We seek the polar decomposition $A = UP$ with $U$ orthogonal and $P$ symmetric positive semidefinite. The scaling matrix is $P = \\sqrt{A^{T}A}$, and its eigenvalues (the singular values of $A$) are the scaling factors. Their sum equals the trace of $P$.\n\nCompute $A^{T}A$:\n$$\nA^{T} = \\begin{pmatrix} 0  3 \\\\ 2  0 \\end{pmatrix}, \\quad\nA^{T}A = \\begin{pmatrix} 0  3 \\\\ 2  0 \\end{pmatrix}\\begin{pmatrix} 0  2 \\\\ 3  0 \\end{pmatrix}\n= \\begin{pmatrix} 9  0 \\\\ 0  4 \\end{pmatrix}.\n$$\nSince $A^{T}A$ is diagonal with positive entries, its unique positive semidefinite square root is\n$$\nP = \\sqrt{A^{T}A} = \\begin{pmatrix} 3  0 \\\\ 0  2 \\end{pmatrix}.\n$$\nThus the scaling factors (eigenvalues of $P$) are $3$ and $2$, and their sum is\n$$\n3 + 2 = 5.\n$$", "answer": "$$\\boxed{5}$$", "id": "1383671"}, {"introduction": "Beyond direct calculation, the polar decomposition can be approached through dynamic, iterative processes. This advanced problem introduces a powerful algorithm that numerically converges to the unitary factor of a given matrix. By tracking how the singular values evolve with each iteration, you will gain a deeper appreciation for the geometric meaning of the decomposition, visualizing it as a process of progressively \"un-stretching\" a transformation until only the pure rotational/reflective part remains [@problem_id:1383647].", "problem": "The polar decomposition of an invertible matrix $A \\in \\mathbb{C}^{n \\times n}$ is a factorization of the form $A=UP$, where $U$ is a unitary matrix and $P$ is a positive-definite Hermitian matrix. The singular values of $A$ are defined as the eigenvalues of $P$.\n\nAn iterative algorithm, sometimes called the Newton-Schulz iteration, for finding the unitary factor $U$ is given by the matrix sequence:\n$$A_{k+1} = \\frac{1}{2}\\left(A_k + (A_k^*)^{-1}\\right), \\quad k \\ge 0$$\nwhere $A_k^*$ denotes the conjugate transpose of $A_k$. For any invertible starting matrix $A_0$, the sequence $\\{A_k\\}$ converges to the unitary factor of $A_0$'s polar decomposition.\n\nSuppose an initial invertible matrix $A_0$ is chosen such that its singular values are all members of the set $\\{3, 1/2, 1\\}$. Note that each value in this set is indeed a singular value of $A_0$.\nAfter two iterations of the algorithm, we obtain the matrix $A_2$. Let $\\{\\lambda_j\\}$ be the set of all distinct singular values of $A_2$.\n\nCompute the sum of all elements in the set $\\{\\lambda_j\\}$. Express your answer as an exact fraction in simplest form.", "solution": "Let the polar decomposition of the initial matrix be $A_0 = U_0 P_0$, where $U_0$ is unitary and $P_0$ is positive-definite Hermitian. The singular values of $A_0$ are the eigenvalues of $P_0$.\n\nWe analyze the first step of the iteration:\n$$A_1 = \\frac{1}{2}\\left(A_0 + (A_0^*)^{-1}\\right)$$\nThe conjugate transpose of $A_0$ is $A_0^* = (U_0 P_0)^* = P_0^* U_0^*$. Since $P_0$ is Hermitian, $P_0^*=P_0$, so $A_0^* = P_0 U_0^*$.\nThe inverse of the conjugate transpose is $(A_0^*)^{-1} = (P_0 U_0^*)^{-1} = (U_0^*)^{-1} P_0^{-1}$. Since $U_0$ is unitary, $(U_0^*)^{-1} = (U_0^{-1})^{-1} = U_0$.\nTherefore, $(A_0^*)^{-1} = U_0 P_0^{-1}$.\n\nSubstituting this back into the expression for $A_1$:\n$$A_1 = \\frac{1}{2}\\left(U_0 P_0 + U_0 P_0^{-1}\\right) = U_0 \\left( \\frac{1}{2}(P_0 + P_0^{-1}) \\right)$$\nLet's define a new matrix $P_1 = \\frac{1}{2}(P_0 + P_0^{-1})$. If $P_0$ is positive-definite Hermitian, then so is $P_0^{-1}$, and their sum $P_1$ is also positive-definite Hermitian. Thus, $A_1 = U_0 P_1$ is the polar decomposition of $A_1$.\n\nThis reveals a crucial property of the iteration: the unitary factor $U_0$ remains constant for all iterates, i.e., $A_k = U_0 P_k$ for all $k \\ge 0$. The sequence of positive-definite matrices $\\{P_k\\}$ evolves according to the rule:\n$$P_{k+1} = \\frac{1}{2}(P_k + P_k^{-1})$$\nThe singular values of $A_k$ are the eigenvalues of $P_k$. Since all matrices $P_k$ are functions of $P_0$ (specifically, they are polynomials in $P_0$ and $P_0^{-1}$), they commute and are simultaneously diagonalizable. This means the matrix iteration on $P_k$ can be understood as a set of independent scalar iterations on its eigenvalues.\nLet $\\sigma^{(k)}$ be a singular value of $A_k$ (i.e., an eigenvalue of $P_k$). Then the corresponding singular value of $A_{k+1}$ is given by:\n$$\\sigma^{(k+1)} = \\frac{1}{2}\\left(\\sigma^{(k)} + \\frac{1}{\\sigma^{(k)}}\\right)$$\n\nThe problem states that the initial singular values of $A_0$ are from the set $\\{3, 1/2, 1\\}$. We need to find the distinct singular values of $A_2$ by applying the scalar iteration twice for each initial value.\n\n1.  For the initial singular value $\\sigma^{(0)} = 3$:\n    $$\\sigma^{(1)} = \\frac{1}{2}\\left(3 + \\frac{1}{3}\\right) = \\frac{1}{2}\\left(\\frac{10}{3}\\right) = \\frac{5}{3}$$\n    $$\\sigma^{(2)} = \\frac{1}{2}\\left(\\frac{5}{3} + \\frac{3}{5}\\right) = \\frac{1}{2}\\left(\\frac{25 + 9}{15}\\right) = \\frac{1}{2}\\left(\\frac{34}{15}\\right) = \\frac{17}{15}$$\n\n2.  For the initial singular value $\\sigma^{(0)} = 1/2$:\n    $$\\sigma^{(1)} = \\frac{1}{2}\\left(\\frac{1}{2} + 2\\right) = \\frac{1}{2}\\left(\\frac{5}{2}\\right) = \\frac{5}{4}$$\n    $$\\sigma^{(2)} = \\frac{1}{2}\\left(\\frac{5}{4} + \\frac{4}{5}\\right) = \\frac{1}{2}\\left(\\frac{25 + 16}{20}\\right) = \\frac{1}{2}\\left(\\frac{41}{20}\\right) = \\frac{41}{40}$$\n\n3.  For the initial singular value $\\sigma^{(0)} = 1$:\n    $$\\sigma^{(1)} = \\frac{1}{2}\\left(1 + \\frac{1}{1}\\right) = 1$$\n    This value is a fixed point of the iteration. Thus, the corresponding singular value in $A_2$ is also 1.\n\nThe set of distinct singular values of $A_2$, denoted by $\\{\\lambda_j\\}$, is therefore $\\left\\{\\frac{17}{15}, \\frac{41}{40}, 1\\right\\}$.\n\nThe problem asks for the sum of these distinct singular values:\n$$\\text{Sum} = \\frac{17}{15} + \\frac{41}{40} + 1$$\nTo sum these fractions, we find a common denominator. The least common multiple of 15 and 40 is 120.\n$$\\text{Sum} = \\frac{17 \\times 8}{15 \\times 8} + \\frac{41 \\times 3}{40 \\times 3} + \\frac{120}{120}$$\n$$\\text{Sum} = \\frac{136}{120} + \\frac{123}{120} + \\frac{120}{120}$$\n$$\\text{Sum} = \\frac{136 + 123 + 120}{120} = \\frac{379}{120}$$\nThe numerator 379 is a prime number, and the denominator is $120 = 2^3 \\cdot 3 \\cdot 5$. They share no common factors, so the fraction is in its simplest form.", "answer": "$$\\boxed{\\frac{379}{120}}$$", "id": "1383647"}]}