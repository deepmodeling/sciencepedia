{"hands_on_practices": [{"introduction": "Before applying a numerical method, it is crucial to understand its objective. This exercise will help you solidify the theoretical foundation of the inverse power method by identifying which eigenvalue it is designed to find from a given set [@problem_id:2216079]. This principle, which connects the method to the eigenvalue with the smallest magnitude, governs the application and utility of the entire algorithm.", "problem": "Consider a real square matrix $A$. The standard inverse power method is an iterative algorithm used to find a specific eigenvalue-eigenvector pair of $A$. The method starts with a non-zero vector $x_0$ and iteratively applies the relation $x_{k+1} = \\frac{A^{-1}x_k}{\\|A^{-1}x_k\\|}$ for $k=0, 1, 2, \\dots$. For a generic choice of the initial vector $x_0$, this process converges to the eigenvector corresponding to one of the eigenvalues of $A$.\n\nA particular non-singular $4 \\times 4$ real matrix $A$ is known to have the following set of eigenvalues: $\\{3, -1, 0.5+2i, 0.5-2i\\}$. If the standard inverse power method is applied to this matrix, which eigenvalue will the iteration converge to, assuming a generic initial vector is chosen?\n\nA. 3\n\nB. -1\n\nC. $0.5 + 2i$\n\nD. The method will not converge because there are complex eigenvalues.\n\nE. Convergence is not unique because there are two distinct eigenvalues with the smallest magnitude.", "solution": "The inverse power method applies the iteration $x_{k+1}=\\dfrac{A^{-1}x_{k}}{\\|A^{-1}x_{k}\\|}$, which is equivalent to the standard power method applied to $A^{-1}$. The power method converges to an eigenvector corresponding to the eigenvalue of largest magnitude of the matrix it is applied to, provided a generic initial vector is used and there is a unique dominant magnitude.\n\nLet the eigenvalues of $A$ be $\\{\\lambda_{1},\\lambda_{2},\\lambda_{3},\\lambda_{4}\\}=\\{3,-1,0.5+2i,0.5-2i\\}$. Then the eigenvalues of $A^{-1}$ are $\\{1/\\lambda_{1},1/\\lambda_{2},1/\\lambda_{3},1/\\lambda_{4}\\}$. The magnitudes are\n$$\n\\left|\\frac{1}{\\lambda}\\right|=\\frac{1}{|\\lambda|}.\n$$\nHence the eigenvalue of $A^{-1}$ with largest magnitude corresponds to the eigenvalue of $A$ with smallest magnitude.\n\nCompute the magnitudes of the eigenvalues of $A$:\n- For $\\lambda=3$, $|\\lambda|=3$.\n- For $\\lambda=-1$, $|\\lambda|=1$.\n- For $\\lambda=0.5\\pm 2i$, $|\\lambda|=\\sqrt{(0.5)^{2}+2^{2}}=\\sqrt{\\frac{1}{4}+4}=\\sqrt{\\frac{17}{4}}=\\frac{\\sqrt{17}}{2}$.\n\nSince $1\\frac{\\sqrt{17}}{2}3$, the unique smallest magnitude is $|\\lambda|=1$, attained by $\\lambda=-1$. Therefore, for a generic initial vector, the inverse power method converges to the eigenvector associated with $\\lambda=-1$. The presence of complex eigenvalues does not prevent convergence in this case, and there is no ambiguity since the smallest magnitude eigenvalue is unique.\n\nThus the correct option is B.", "answer": "$$\\boxed{B}$$", "id": "2216079"}, {"introduction": "The inverse power method is an iterative process, and its core lies in repeatedly solving a specific linear system. This practice provides hands-on experience with this fundamental calculation, allowing you to execute a single, crucial step of the shifted algorithm [@problem_id:1395843]. Mastering this operation is the first step toward implementing and understanding the method's behavior in finding an eigenvalue near a chosen shift $\\sigma$.", "problem": "In a numerical algorithm, a sequence of vectors is generated starting from an initial vector $x_0$. The first unnormalized vector in this sequence, denoted as $y_1$, is found by solving the linear system $(A-\\sigma I)y_1 = x_0$, where $A$ is a square matrix, $\\sigma$ is a scalar shift, and $I$ is the identity matrix of the same dimension as $A$.\n\nGiven the matrix $A = \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix}$, the shift $\\sigma = 1.5$, and the initial vector $x_0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, determine the components of the vector $y_1$. Present your answer as a row matrix where each component is an exact fraction or decimal.", "solution": "We are asked to solve the linear system $(A-\\sigma I) y_{1} = x_{0}$ for $y_{1}$, where $A = \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix}$, $\\sigma = \\frac{3}{2}$, and $x_{0} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n\nFirst compute the shifted matrix:\n$$\nA - \\sigma I = \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix} - \\frac{3}{2} \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2}  -1 \\\\ -1  \\frac{3}{2} \\end{pmatrix}.\n$$\nDenote $M = A - \\sigma I$. Then $y_{1} = M^{-1} x_{0}$. For a $2 \\times 2$ matrix $M = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$, we use $M^{-1} = \\frac{1}{\\det(M)} \\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}$. Here $a = d = \\frac{3}{2}$ and $b = c = -1$, so\n$$\n\\det(M) = \\left(\\frac{3}{2}\\right)\\left(\\frac{3}{2}\\right) - (-1)(-1) = \\frac{9}{4} - 1 = \\frac{5}{4},\n$$\nand\n$$\n\\operatorname{adj}(M) = \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix}.\n$$\nTherefore,\n$$\nM^{-1} = \\frac{1}{\\frac{5}{4}} \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix}.\n$$\nMultiplying by $x_{0}$,\n$$\ny_{1} = M^{-1} x_{0} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2}  1 \\\\ 1  \\frac{3}{2} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\frac{4}{5} \\begin{pmatrix} \\frac{3}{2} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{6}{5} \\\\ \\frac{4}{5} \\end{pmatrix}.\n$$\nThus the components of $y_{1}$ are $\\frac{6}{5}$ and $\\frac{4}{5}$, which we present as a row matrix.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{6}{5}  \\frac{4}{5} \\end{pmatrix}}$$", "id": "1395843"}, {"introduction": "Beyond just knowing that a method converges, a numerical analyst must often assess *how quickly* it converges. This practice bridges the gap between theory and application by demonstrating how to estimate the algorithm's convergence rate from its numerical output [@problem_id:1395834]. This skill is vital for diagnosing performance and optimizing numerical computations in practical scenarios, as the rate is determined by the separation between the target and next-closest eigenvalues.", "problem": "A computational scientist is using the shifted inverse power method to find an eigenpair of a very large, real, symmetric matrix $A$. The method iteratively computes a sequence of vectors $\\{x_k\\}$ starting from an initial random vector $x_0$. The iteration is defined by solving $(A - \\sigma I) y_{k+1} = x_k$ for $y_{k+1}$, and then normalizing to get $x_{k+1} = y_{k+1} / \\|y_{k+1}\\|_2$, where $I$ is the identity matrix. A shift of $\\sigma = 4.5$ is used.\n\nAfter many iterations, the convergence has become linear, and the scientist records the Euclidean norms of the differences between consecutive iterates:\n$$\n\\|x_{150} - x_{149}\\|_2 = 8.12 \\times 10^{-7}\n$$\n$$\n\\|x_{151} - x_{150}\\|_2 = 1.48 \\times 10^{-7}\n$$\n\nLet $\\lambda_{target}$ be the eigenvalue of $A$ closest to the shift $\\sigma$, and let $\\lambda_{subdominant}$ be the second-closest eigenvalue to $\\sigma$. Based on the observed data, estimate the value of the spectral gap ratio $R = \\frac{|\\lambda_{target} - \\sigma|}{|\\lambda_{subdominant} - \\sigma|}$. Round your final answer to three significant figures.", "solution": "The problem asks us to estimate a ratio involving eigenvalues of a matrix $A$ based on the convergence behavior of the shifted inverse power method.\n\nThe shifted inverse power method is defined by the iteration:\n1. Solve $(A - \\sigma I) y_{k+1} = x_k$ for $y_{k+1}$. This is equivalent to $y_{k+1} = (A - \\sigma I)^{-1} x_k$.\n2. Normalize the vector: $x_{k+1} = \\frac{y_{k+1}}{\\|y_{k+1}\\|_2}$.\n\nThis iterative process is mathematically equivalent to applying the standard power method to the matrix $B = (A - \\sigma I)^{-1}$. Let the eigenvalues of $A$ be $\\{\\lambda_i\\}$ with corresponding eigenvectors $\\{v_i\\}$. The eigenvalues of $B$ are then $\\mu_i = \\frac{1}{\\lambda_i - \\sigma}$, and they share the same eigenvectors $\\{v_i\\}$.\n\nThe power method converges to the eigenvector associated with the eigenvalue of largest magnitude (the dominant eigenvalue). For the matrix $B = (A - \\sigma I)^{-1}$, the dominant eigenvalue $\\mu_{dom}$ is the one for which $|\\mu_i| = \\frac{1}{|\\lambda_i - \\sigma|}$ is maximized. This occurs for the eigenvalue $\\lambda_i$ of $A$ that minimizes $|\\lambda_i - \\sigma|$. This eigenvalue is denoted as $\\lambda_{target}$ in the problem statement. Thus, the dominant eigenvalue of $B$ is $\\mu_{dom}$ with magnitude $|\\mu_{dom}| = \\frac{1}{|\\lambda_{target} - \\sigma|}$. The inverse power method causes the vector sequence $\\{x_k\\}$ to converge to the eigenvector corresponding to $\\lambda_{target}$.\n\nThe rate of convergence of the power method is determined by the ratio of the magnitudes of the second-largest eigenvalue (the subdominant eigenvalue) to the dominant eigenvalue. Let the subdominant eigenvalue of $B$ be $\\mu_{sub}$. Its magnitude is determined by the eigenvalue of $A$, denoted $\\lambda_{subdominant}$, that is second-closest to the shift $\\sigma$. Thus, $|\\mu_{sub}| = \\frac{1}{|\\lambda_{subdominant} - \\sigma|}$.\n\nThe asymptotic rate of convergence for the vector sequence is given by the ratio $\\rho = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|}$. For large $k$, the error in the vector $x_k$ (i.e., its component orthogonal to the true eigenvector) is reduced by a factor of approximately $\\rho$ at each step.\n\nA common way to monitor convergence in practice is to observe the norm of the difference between successive iterates, $\\|x_{k+1} - x_k\\|_2$. When the method is converging linearly and $k$ is large, the ratio of the norms of consecutive difference vectors provides a good estimate of the convergence rate $\\rho$.\n$$\n\\rho \\approx \\frac{\\|x_{k+1} - x_k\\|_2}{\\|x_k - x_{k-1}\\|_2}\n$$\n\nUsing the data provided in the problem statement for $k=150$:\n$$\n\\rho \\approx \\frac{\\|x_{151} - x_{150}\\|_2}{\\|x_{150} - x_{149}\\|_2}\n$$\nSubstituting the given numerical values:\n$$\n\\rho \\approx \\frac{1.48 \\times 10^{-7}}{8.12 \\times 10^{-7}} = \\frac{1.48}{8.12} \\approx 0.18226600985\n$$\n\nThe problem asks for the spectral gap ratio $R = \\frac{|\\lambda_{target} - \\sigma|}{|\\lambda_{subdominant} - \\sigma|}$. We can relate this to the convergence rate $\\rho$:\n$$\n\\rho = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|} = \\frac{\\frac{1}{|\\lambda_{subdominant} - \\sigma|}}{\\frac{1}{|\\lambda_{target} - \\sigma|}} = \\frac{|\\lambda_{target} - \\sigma|}{|\\lambda_{subdominant} - \\sigma|}\n$$\nThus, the quantity we estimated, $\\rho$, is exactly the spectral gap ratio $R$ that we need to find.\n$$\nR = \\rho \\approx 0.18226600985\n$$\n\nThe problem requires the final answer to be rounded to three significant figures.\n$$\nR \\approx 0.182\n$$", "answer": "$$\\boxed{0.182}$$", "id": "1395834"}]}