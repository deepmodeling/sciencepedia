{"hands_on_practices": [{"introduction": "The behavior of any regime-switching diffusion is fundamentally governed by the underlying Markov chain that dictates the switches. To understand the long-term properties of the modulated system, one must first analyze the chain itself. This exercise focuses on calculating the stationary distribution, a key measure that describes the long-run fraction of time the system spends in each operational mode or \"regime.\" [@problem_id:2993994]", "problem": "Consider a continuous-time Markov chain with finite state set $S=\\{1,2,3\\}$ and conservative generator matrix $Q\\in\\mathbb{R}^{3\\times 3}$ given by\n$$\nQ=\\begin{pmatrix}\n-5  2  3 \\\\\n1  -4  3 \\\\\n4  2  -6\n\\end{pmatrix}.\n$$\nAssume the chain is irreducible. In the context of a regime-switching diffusion, this chain modulates coefficients of a stochastic differential equation via its stationary regime occupancy. Compute the stationary distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3)$ by solving $\\pi Q=0$ together with $\\sum_{i\\in S}\\pi_i=1$. In addition, state the conditions under which this stationary distribution is unique and strictly positive, expressed in terms of structural properties of $Q$ and the chain. The final answer must be the stationary distribution $\\pi$ expressed as a single row matrix. No rounding is required.", "solution": "The user wants me to solve the following problem:\nConsider a continuous-time Markov chain with finite state set $S=\\{1,2,3\\}$ and conservative generator matrix $Q\\in\\mathbb{R}^{3\\times 3}$ given by\n$$\nQ=\\begin{pmatrix}\n-5  2  3 \\\\\n1  -4  3 \\\\\n4  2  -6\n\\end{pmatrix}.\n$$\nAssume the chain is irreducible. In the context of a regime-switching diffusion, this chain modulates coefficients of a stochastic differential equation via its stationary regime occupancy. Compute the stationary distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3)$ by solving $\\pi Q=0$ together with $\\sum_{i\\in S}\\pi_i=1$. In addition, state the conditions under which this stationary distribution is unique and strictly positive, expressed in terms of structural properties of $Q$ and the chain. The final answer must be the stationary distribution $\\pi$ expressed as a single row matrix. No rounding is required.\n\n### Step 1: Extract Givens\n- State set of the continuous-time Markov chain: $S=\\{1,2,3\\}$.\n- Generator matrix: $Q=\\begin{pmatrix} -5  2  3 \\\\ 1  -4  3 \\\\ 4  2  -6 \\end{pmatrix}$.\n- The matrix $Q$ is conservative, meaning the sum of each row is $0$.\n- The chain is assumed to be irreducible.\n- The stationary distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3)$ must be computed.\n- The defining equations for the stationary distribution are:\n  1. $\\pi Q = 0$, where $0$ is the zero vector in $\\mathbb{R}^3$.\n  2. $\\sum_{i=1}^{3} \\pi_i = 1$.\n- The secondary task is to state the conditions for the uniqueness and strict positivity of $\\pi$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is first validated for scientific soundness, completeness, and objectivity.\n\n1.  **Scientific and Factual Soundness:** The problem is a standard exercise in the theory of continuous-time Markov chains, a core topic in stochastic processes. The concept of a generator matrix $Q$, stationary distribution $\\pi$, and the defining equations $\\pi Q = 0$ and $\\sum \\pi_i = 1$ are fundamental and mathematically correct. The given matrix $Q$ is a valid generator matrix for a conservative chain: its off-diagonal entries are non-negative, and its row sums are all zero:\n    - Row $1$: $-5+2+3 = 0$\n    - Row $2$: $1-4+3 = 0$\n    - Row $3$: $4+2-6 = 0$\n2.  **Completeness and Consistency:** The problem is self-contained. It provides the state space, the generator matrix, and the explicit assumption of irreducibility. Let's verify this assumption. The non-zero off-diagonal entries $q_{ij}$ for $i \\neq j$ indicate possible transitions $i \\to j$. From $Q$, we have transitions $1 \\to 2$, $1 \\to 3$, $2 \\to 1$, $2 \\to 3$, $3 \\to 1$, and $3 \\to 2$. This implies that every state is reachable from every other state, so the graph of the chain is strongly connected. Thus, the chain is indeed irreducible, and the given assumption is consistent with the provided matrix $Q$.\n3.  **Well-Posedness:** For any finite-state, irreducible continuous-time Markov chain, a unique stationary distribution exists. The problem provides all necessary information to find this unique solution.\n4.  **Objectivity:** The problem is stated in precise mathematical language, free from ambiguity or subjective claims.\n\nThe problem is deemed **valid** as it is scientifically sound, well-posed, and complete.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the solution.\n\nFirst, we address the conditions for uniqueness and strict positivity of the stationary distribution. For a continuous-time Markov chain with a finite state space, a stationary distribution $\\pi$ exists. A fundamental theorem states that this stationary distribution is unique and strictly positive (i.e., $\\pi_i > 0$ for all states $i$) if and only if the chain is irreducible. The problem statement explicitly assumes irreducibility. Structurally, this corresponds to the graph of transitions defined by the non-zero off-diagonal elements of the generator matrix $Q$ being strongly connected. As verified during validation, the provided matrix $Q$ corresponds to an irreducible chain.\n\nNext, we compute the stationary distribution $\\pi = (\\pi_1, \\pi_2, \\pi_3)$ by solving the system of linear equations given by $\\pi Q = 0$ and the normalization condition $\\sum_{i=1}^3 \\pi_i = 1$.\n\nThe matrix equation $\\pi Q = 0$ is:\n$$\n(\\pi_1, \\pi_2, \\pi_3) \\begin{pmatrix} -5  2  3 \\\\ 1  -4  3 \\\\ 4  2  -6 \\end{pmatrix} = (0, 0, 0)\n$$\nThis yields a system of three linear equations:\n1.  $-5\\pi_1 + \\pi_2 + 4\\pi_3 = 0$\n2.  $2\\pi_1 - 4\\pi_2 + 2\\pi_3 = 0$\n3.  $3\\pi_1 + 3\\pi_2 - 6\\pi_3 = 0$\n\nSince $Q$ is a generator matrix for a conservative chain, its rows sum to zero, which means the column vector $(1, 1, 1)^T$ is in the null space of $Q^T$. This implies that the columns of $Q$ are linearly dependent, and therefore the three equations above are linearly dependent. We can use any two of these equations along with the normalization condition.\n\nLet's simplify equations $2$ and $3$:\n- From equation $2$: Dividing by $2$ gives $\\pi_1 - 2\\pi_2 + \\pi_3 = 0$. (Eq. A)\n- From equation $3$: Dividing by $3$ gives $\\pi_1 + \\pi_2 - 2\\pi_3 = 0$. (Eq. B)\n\nFrom Eq. A, we can express $\\pi_3$ in terms of $\\pi_1$ and $\\pi_2$:\n$$\n\\pi_3 = 2\\pi_2 - \\pi_1\n$$\nSubstitute this expression for $\\pi_3$ into Eq. B:\n$$\n\\pi_1 + \\pi_2 - 2(2\\pi_2 - \\pi_1) = 0\n$$\n$$\n\\pi_1 + \\pi_2 - 4\\pi_2 + 2\\pi_1 = 0\n$$\n$$\n3\\pi_1 - 3\\pi_2 = 0\n$$\nThis simplifies to $\\pi_1 = \\pi_2$.\n\nNow, substitute $\\pi_2 = \\pi_1$ into the expression for $\\pi_3$:\n$$\n\\pi_3 = 2\\pi_1 - \\pi_1 = \\pi_1\n$$\nThus, we have found that $\\pi_1 = \\pi_2 = \\pi_3$.\n\nWe must verify this relationship using the first equation, $-5\\pi_1 + \\pi_2 + 4\\pi_3 = 0$:\n$$\n-5\\pi_1 + (\\pi_1) + 4(\\pi_1) = -5\\pi_1 + 5\\pi_1 = 0\n$$\nThe relationship is consistent with all three equations from $\\pi Q = 0$.\n\nFinally, we use the normalization condition $\\pi_1 + \\pi_2 + \\pi_3 = 1$:\n$$\n\\pi_1 + \\pi_1 + \\pi_1 = 1\n$$\n$$\n3\\pi_1 = 1\n$$\n$$\n\\pi_1 = \\frac{1}{3}\n$$\nSince $\\pi_1 = \\pi_2 = \\pi_3$, it follows that $\\pi_1 = \\frac{1}{3}$, $\\pi_2 = \\frac{1}{3}$, and $\\pi_3 = \\frac{1}{3}$.\n\nThe stationary distribution is the row vector $\\pi = (\\pi_1, \\pi_2, \\pi_3)$.\n$$\n\\pi = \\left(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}\\right)\n$$\nThis distribution is indeed unique and strictly positive, as expected for an irreducible chain.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3}\n\\end{pmatrix}\n}\n$$", "id": "2993994"}, {"introduction": "A powerful technique in the study of SDEs is the transformation of variables, guided by Itô's Lemma. In this exercise, we apply this fundamental tool to a Markov-modulated geometric Brownian motion, a cornerstone model in finance. This practice demonstrates how a change of coordinates can simplify a complex multiplicative process into a more tractable additive one, revealing an arithmetic Brownian motion whose drift is modulated by the regime. [@problem_id:2993970]", "problem": "Consider a continuous-time Markov chain (CTMC) $I_t$ taking values in the finite state space $\\{1,\\dots,m\\}$ with infinitesimal generator $Q=\\big(q_{ij}\\big)_{i,j\\in\\{1,\\dots,m\\}}$, and a standard Brownian motion (Wiener process) $W_t$ independent of $I_t$. For each regime $i\\in\\{1,\\dots,m\\}$, let the drift and volatility parameters be $\\mu(i)\\in\\mathbb{R}$ and $\\sigma(i)\\in(0,\\infty)$, respectively. Consider the Markov-modulated geometric Brownian motion $X_t$ defined by the stochastic differential equation (SDE)\n$$\ndX_t \\;=\\; X_t\\big(\\mu(I_t)\\,dt \\;+\\; \\sigma(I_t)\\,dW_t\\big), \\qquad X_0 \\in (0,\\infty).\n$$\nDefine the logarithmic transformation $Y_t=\\ln X_t$. Starting from fundamental principles of Itô stochastic calculus and the definition of the quadratic variation of a semimartingale, derive the SDE satisfied by $Y_t$, making explicit how the drift and diffusion coefficients depend on the regime process $I_t$. Your derivation must be self-contained and must not assume any pre-stated transformation formulas. Provide the final answer as the pair of analytic expressions for the drift coefficient and diffusion amplitude of $dY_t$ in terms of $\\mu(I_t)$ and $\\sigma(I_t)$, presented as a row matrix. No numerical approximation is required for this problem, and no physical units apply. The final answer must be a single analytic expression with no equality sign and must be given in the order: first the drift coefficient, then the diffusion amplitude.", "solution": "The problem is valid. It is a well-posed mathematical problem in the field of stochastic differential equations, grounded in established theory and presented with sufficient clarity and precision for a unique solution to be derived.\n\nThe objective is to derive the stochastic differential equation (SDE) for the process $Y_t = \\ln X_t$, where $X_t$ is a Markov-modulated geometric Brownian motion given by\n$$\ndX_t = X_t\\big(\\mu(I_t)\\,dt + \\sigma(I_t)\\,dW_t\\big)\n$$\nwith $X_0 > 0$. The derivation must proceed from fundamental principles of Itô calculus, without assuming pre-stated formulas such as Itô's lemma.\n\nLet the transformation be defined by the function $f(x) = \\ln(x)$. We are interested in the dynamics of $Y_t = f(X_t)$. The foundation of Itô calculus is a second-order Taylor expansion for functions of stochastic processes. We consider the change in $Y_t$ over a small time interval $\\Delta t$, which is $\\Delta Y_t = Y_{t+\\Delta t} - Y_t = f(X_{t+\\Delta t}) - f(X_t)$.\n\nExpanding $f(X_{t+\\Delta t})$ around $X_t$ using Taylor's theorem up to the second-order term gives:\n$$\nf(X_{t+\\Delta t}) \\approx f(X_t) + f'(X_t)(X_{t+\\Delta t} - X_t) + \\frac{1}{2}f''(X_t)(X_{t+\\Delta t} - X_t)^2\n$$\nIn differential notation, this becomes:\n$$\ndY_t = f'(X_t)dX_t + \\frac{1}{2}f''(X_t)(dX_t)^2\n$$\nThis expression is interpreted in the context of Itô calculus, where the term $(dX_t)^2$ represents the quadratic variation of the process $X_t$, denoted $d\\langle X, X \\rangle_t$.\n\nThe derivatives of $f(x) = \\ln(x)$ are:\n$$\nf'(x) = \\frac{1}{x}\n$$\n$$\nf''(x) = -\\frac{1}{x^2}\n$$\nSubstituting these into the differential expression for $dY_t$:\n$$\ndY_t = \\frac{1}{X_t}dX_t - \\frac{1}{2X_t^2}(dX_t)^2\n$$\nNow, we must evaluate the terms $dX_t$ and $(dX_t)^2$. The term $dX_t$ is given by the problem statement:\n$$\ndX_t = X_t \\mu(I_t)\\,dt + X_t \\sigma(I_t)\\,dW_t\n$$\nThe term $(dX_t)^2 = d\\langle X, X \\rangle_t$ requires using the multiplication rules of Itô calculus, which are the fundamental principles upon which the theory is built. These rules are, for infinitesimal increments:\n* $(dt)^2 = 0$\n* $dt \\cdot dW_t = 0$\n* $(dW_t)^2 = dt$\nThese rules capture the limiting behavior of the moments of the increments. Specifically, $(dW_t)^2$ is not $0$ because the variance of a Brownian increment $\\Delta W_t = W_{t+\\Delta t} - W_t$ is $\\Delta t$, not $(\\Delta t)^2$.\n\nWe expand $(dX_t)^2$:\n$$\n(dX_t)^2 = \\left(X_t \\mu(I_t)\\,dt + X_t \\sigma(I_t)\\,dW_t\\right)^2\n$$\n$$\n(dX_t)^2 = \\left(X_t \\mu(I_t)\\right)^2 (dt)^2 + 2 X_t^2 \\mu(I_t) \\sigma(I_t)\\,dt\\,dW_t + \\left(X_t \\sigma(I_t)\\right)^2 (dW_t)^2\n$$\nApplying the Itô multiplication rules, the first two terms vanish as they are of a lower order than $dt$. The third term becomes:\n$$\n(dX_t)^2 = \\left(X_t \\sigma(I_t)\\right)^2 dt = X_t^2 \\sigma(I_t)^2 dt\n$$\nThis is the quadratic variation of the process $X_t$.\n\nNow we substitute the expressions for $dX_t$ and $(dX_t)^2$ back into the equation for $dY_t$:\n$$\ndY_t = \\frac{1}{X_t} \\left(X_t \\mu(I_t)\\,dt + X_t \\sigma(I_t)\\,dW_t\\right) - \\frac{1}{2X_t^2} \\left(X_t^2 \\sigma(I_t)^2 dt\\right)\n$$\nSimplifying the terms:\n$$\ndY_t = \\left(\\mu(I_t)\\,dt + \\sigma(I_t)\\,dW_t\\right) - \\frac{1}{2}\\sigma(I_t)^2 dt\n$$\nFinally, we group the $dt$ and $dW_t$ terms to obtain the SDE for $Y_t$:\n$$\ndY_t = \\left(\\mu(I_t) - \\frac{1}{2}\\sigma(I_t)^2\\right) dt + \\sigma(I_t)\\,dW_t\n$$\nThis SDE describes an arithmetic Brownian motion with a drift coefficient that depends on the state of the Markov chain $I_t$.\n\nFrom this final form, we identify the drift coefficient and the diffusion amplitude of the process $Y_t$.\nThe drift coefficient is the term multiplying $dt$:\n$$\n\\text{Drift} = \\mu(I_t) - \\frac{1}{2}\\sigma(I_t)^2\n$$\nThe diffusion amplitude (or diffusion coefficient) is the term multiplying $dW_t$:\n$$\n\\text{Diffusion Amplitude} = \\sigma(I_t)\n$$\nThe problem asks for these two expressions presented as a row matrix.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\mu(I_t) - \\frac{1}{2}\\sigma(I_t)^2  \\sigma(I_t) \\end{pmatrix}}\n$$", "id": "2993970"}, {"introduction": "Beyond understanding instantaneous dynamics, it is crucial to construct the entire trajectory of a process over time. This exercise guides you through finding the explicit, pathwise solution for a Markov-modulated Ornstein-Uhlenbeck process, conditional on a known sequence of regime switches. This skill is essential for simulation, pricing, and control applications, as it reveals precisely how the process evolves by piecing together solutions from each constant-coefficient interval. [@problem_id:2993989]", "problem": "Consider a finite-state continuous-time Markov chain $I_t$ with state space $\\mathcal{S} = \\{1, \\dots, M\\}$ and a standard Brownian motion $W_t$ on a filtered probability space satisfying the usual conditions. Assume $I_t$ and $W_t$ are independent. Define the Markov-modulated Ornstein–Uhlenbeck (OU) process $X_t$ by the stochastic differential equation\n$$\ndX_t \\;=\\; -\\kappa(I_t)\\bigl(X_t - \\theta(I_t)\\bigr)\\,dt \\;+\\; \\sigma(I_t)\\,dW_t,\\qquad X_0 = x_0,\n$$\nwhere $\\kappa:\\mathcal{S}\\to(0,\\infty)$, $\\theta:\\mathcal{S}\\to\\mathbb{R}$, and $\\sigma:\\mathcal{S}\\to(0,\\infty)$ are given functions.\n\nFix a deterministic regime path $i:[0,T]\\to \\mathcal{S}$ that is piecewise constant with a finite number of switches in $(0,T)$ at times $0=\\tau_0\\tau_1\\cdots\\tau_n\\tau_{n+1}=T$. On each half-open interval $[\\tau_j,\\tau_{j+1})$, the regime is constant $i(t)=i_j\\in\\mathcal{S}$, and hence the coefficients are constant $\\kappa_j := \\kappa(i_j)$, $\\theta_j := \\theta(i_j)$, and $\\sigma_j := \\sigma(i_j)$.\n\nStarting from first principles for linear stochastic differential equations and using only foundational results from Itô calculus, derive the explicit closed-form expression for $X_T$ conditional on the fixed regime path $i(\\cdot)$. Your derivation must make clear why the solution is continuous in time and how the piecewise constant coefficients enter the solution through the switching times. In particular, explain how the mean-reversion speed and level change at the switching times $\\tau_j$ and how these changes are reflected in the conditional solution.\n\nProvide the final answer as a single closed-form analytic expression for $X_T$ in terms of $x_0$, $\\{\\kappa_j,\\theta_j,\\sigma_j\\}_{j=0}^n$, $\\{\\tau_j\\}_{j=0}^{n+1}$, and stochastic integrals with respect to $W_t$. No numerical evaluation is required. The final answer must be a single expression and must not include any discussion or commentary.", "solution": "### Step 1: Extract Givens\n-   **Process Definition:** A Markov-modulated Ornstein–Uhlenbeck (OU) process $X_t$ is defined by the stochastic differential equation (SDE):\n    $$\n    dX_t \\;=\\; -\\kappa(I_t)\\bigl(X_t - \\theta(I_t)\\bigr)\\,dt \\;+\\; \\sigma(I_t)\\,dW_t\n    $$\n-   **Initial Condition:** $X_0 = x_0$.\n-   **Modulating Process:** $I_t$ is a continuous-time Markov chain on a finite state space $\\mathcal{S} = \\{1, \\dots, M\\}$.\n-   **Noise Process:** $W_t$ is a standard Brownian motion. $I_t$ and $W_t$ are independent.\n-   **Coefficients:** The functions $\\kappa:\\mathcal{S}\\to(0,\\infty)$, $\\theta:\\mathcal{S}\\to\\mathbb{R}$, and $\\sigma:\\mathcal{S}\\to(0,\\infty)$ define the mean-reversion speed, mean-reversion level, and volatility, respectively, for each state of the Markov chain.\n-   **Conditional Path:** The problem considers a fixed, deterministic, piecewise constant regime path $i:[0,T]\\to \\mathcal{S}$.\n-   **Path Structure:** There is a partition of the interval $[0,T]$ given by $0=\\tau_0\\tau_1\\cdots\\tau_n\\tau_{n+1}=T$.\n-   **Piecewise Constant Coefficients:** For any $t \\in [\\tau_j, \\tau_{j+1})$ where $j \\in \\{0, 1, \\dots, n\\}$, the regime is constant, $i(t)=i_j\\in\\mathcal{S}$. This implies the SDE coefficients are also piecewise constant: $\\kappa(i(t)) = \\kappa_j$, $\\theta(i(t)) = \\theta_j$, and $\\sigma(i(t)) = \\sigma_j$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem describes a Markov-modulated OU process, a standard and important model in stochastic analysis, physics, and mathematical finance. The task is to find a conditional solution along a deterministic path, which is a well-defined mathematical exercise based on the foundational principles of Itô calculus. The problem is sound.\n-   **Well-Posed:** The SDE is linear with piecewise continuous (and thus locally bounded) coefficients. Given an initial condition, the existence and uniqueness of a strong solution is guaranteed by standard SDE theory. The request for a closed-form expression is feasible for this specific type of linear SDE.\n-   **Objective:** The problem is stated in precise, formal mathematical language, with no ambiguity or subjective elements.\n-   **Completeness and Consistency:** All necessary information—the SDE, initial condition, and a complete description of the coefficient path—is provided. There are no contradictions in the setup.\n-   **Other Checks:** The problem is not trivial, as it requires a careful application of Itô calculus and step-by-step integration. It is directly relevant to the topic of regime-switching diffusions. It does not contain any of the other flaws listed in the validation criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete, reasoned solution will be provided.\n\n### Derivation of the Solution\nThe analysis begins by treating the SDE as a linear first-order stochastic differential equation with time-varying coefficients. The SDE is\n$$\ndX_t \\;=\\; -\\kappa(i(t))\\bigl(X_t - \\theta(i(t))\\bigr)\\,dt \\;+\\; \\sigma(i(t))\\,dW_t.\n$$\nThis can be rearranged into the standard form for a linear SDE:\n$$\ndX_t + \\kappa(i(t)) X_t \\,dt \\;=\\; \\kappa(i(t))\\theta(i(t))\\,dt \\;+\\; \\sigma(i(t))\\,dW_t.\n$$\nTo solve this equation, we use the integrating factor method, which is a foundational technique. Let the integrating factor be $U_t = \\exp\\left(\\int_0^t \\kappa(i(s))\\,ds\\right)$. Since the path $i(\\cdot)$ is deterministic, the function $U_t$ is also deterministic and differentiable with respect to $t$.\n\nWe consider the process $Y_t = U_t X_t$. Using Itô's product rule for the differential $dY_t$:\n$$\ndY_t = d(U_t X_t) = (\\frac{dU_t}{dt})X_t\\,dt + U_t dX_t.\n$$\nThe derivative of the integrating factor is $\\frac{dU_t}{dt} = \\kappa(i(t))\\exp\\left(\\int_0^t \\kappa(i(s))\\,ds\\right) = \\kappa(i(t))U_t$. Substituting this and the expression for $dX_t$ into the equation for $dY_t$:\n$$\ndY_t = (\\kappa(i(t))U_t)X_t\\,dt + U_t \\left(-\\kappa(i(t)) X_t \\,dt + \\kappa(i(t))\\theta(i(t))\\,dt + \\sigma(i(t))\\,dW_t\\right).\n$$\nThe terms involving $X_t$ cancel out:\n$$\ndY_t = \\kappa(i(t))U_t X_t\\,dt - \\kappa(i(t))U_t X_t \\,dt + U_t \\kappa(i(t))\\theta(i(t))\\,dt + U_t \\sigma(i(t))\\,dW_t.\n$$\nThis simplifies to:\n$$\ndY_t = U_t\\left(\\kappa(i(t))\\theta(i(t))\\,dt + \\sigma(i(t))\\,dW_t\\right).\n$$\nIntegrating both sides from $t=0$ to $t=T$:\n$$\nY_T - Y_0 = \\int_0^T U_s \\kappa(i(s))\\theta(i(s))\\,ds + \\int_0^T U_s \\sigma(i(s))\\,dW_s.\n$$\nSubstituting back $Y_t = U_t X_t$:\n$$\nU_T X_T - U_0 X_0 = \\int_0^T U_s \\kappa(i(s))\\theta(i(s))\\,ds + \\int_0^T U_s \\sigma(i(s))\\,dW_s.\n$$\nSince $U_0 = \\exp(0) = 1$, we can solve for $X_T$:\n$$\nX_T = U_T^{-1} X_0 + U_T^{-1} \\int_0^T U_s \\kappa(i(s))\\theta(i(s))\\,ds + U_T^{-1} \\int_0^T U_s \\sigma(i(s))\\,dW_s.\n$$\nBringing the $U_T^{-1}$ term inside the integrals and using the definition $U_t = \\exp\\left(\\int_0^t \\kappa(i(s))\\,ds\\right)$:\n$$\nU_T^{-1} U_s = \\exp\\left(-\\int_0^T \\kappa(i(u))\\,du\\right)\\exp\\left(\\int_0^s \\kappa(i(u))\\,du\\right) = \\exp\\left(-\\int_s^T \\kappa(i(u))\\,du\\right).\n$$\nThis yields the general solution for $X_T$:\n$$\nX_T = X_0 \\exp\\left(-\\int_0^T \\kappa(i(s))\\,ds\\right) + \\int_0^T \\exp\\left(-\\int_s^T \\kappa(i(u))\\,du\\right) \\kappa(i(s))\\theta(i(s))\\,ds + \\int_0^T \\exp\\left(-\\int_s^T \\kappa(i(u))\\,du\\right) \\sigma(i(s))\\,dW_s.\n$$\nThe solution path $t \\mapsto X_t$ is almost surely continuous because it is the solution to an SDE with locally bounded coefficients driven by a continuous process $W_t$. The solution at each switching time $\\tau_j$ serves as the initial condition for the subsequent interval, ensuring continuity of the entire path.\n\nNow, we specialize this general expression using the given piecewise constant path $i(t)$. The path is defined by regimes $i_j$ on intervals $[\\tau_j, \\tau_{j+1})$, with corresponding constant coefficients $\\kappa_j$, $\\theta_j$, and $\\sigma_j$.\n\nFirst, we evaluate the exponential decay terms. For the term multiplying $X_0$:\n$$\n\\int_0^T \\kappa(i(s))\\,ds = \\sum_{j=0}^{n} \\int_{\\tau_j}^{\\tau_{j+1}} \\kappa_j\\,ds = \\sum_{j=0}^{n} \\kappa_j(\\tau_{j+1}-\\tau_j).\n$$\nFor the integrands, we consider $s \\in [\\tau_j, \\tau_{j+1})$ for some $j \\in \\{0, \\dots, n\\}$. The integral in the exponent is:\n$$\n\\int_s^T \\kappa(i(u))\\,du = \\int_s^{\\tau_{j+1}} \\kappa_j\\,du + \\sum_{k=j+1}^{n} \\int_{\\tau_k}^{\\tau_{k+1}} \\kappa_k\\,du = \\kappa_j(\\tau_{j+1}-s) + \\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k).\n$$\nNote that for $j=n$, the sum $\\sum_{k=n+1}^{n}$ is empty and its value is $0$.\n\nThe overall integrals from $0$ to $T$ can be decomposed into a sum of integrals over the subintervals $[\\tau_j, \\tau_{j+1})$:\n- **Term 1 (Initial Condition):**\n$$\nX_0 \\exp\\left(-\\sum_{j=0}^{n} \\kappa_j(\\tau_{j+1}-\\tau_j)\\right).\n$$\n\n- **Term 2 (Deterministic Integral):**\n$$\n\\begin{align*}\n \\int_0^T \\exp\\left(-\\int_s^T \\kappa(i(u))\\,du\\right) \\kappa(i(s))\\theta(i(s))\\,ds \\\\\n= \\sum_{j=0}^{n} \\int_{\\tau_j}^{\\tau_{j+1}} \\exp\\left(-\\kappa_j(\\tau_{j+1}-s) - \\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right) \\kappa_j\\theta_j\\,ds \\\\\n= \\sum_{j=0}^{n} \\kappa_j\\theta_j \\exp\\left(-\\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right) \\int_{\\tau_j}^{\\tau_{j+1}} \\exp\\left(-\\kappa_j(\\tau_{j+1}-s)\\right)\\,ds.\n\\end{align*}\n$$\nThe integral with respect to $s$ evaluates to:\n$$\n\\int_{\\tau_j}^{\\tau_{j+1}} \\exp\\left(-\\kappa_j(\\tau_{j+1}-s)\\right)\\,ds = \\left[\\frac{1}{\\kappa_j}\\exp\\left(-\\kappa_j(\\tau_{j+1}-s)\\right)\\right]_{s=\\tau_j}^{s=\\tau_{j+1}} = \\frac{1}{\\kappa_j}\\left(1 - \\exp(-\\kappa_j(\\tau_{j+1}-\\tau_j))\\right).\n$$\nThus, the deterministic term becomes:\n$$\n\\sum_{j=0}^{n} \\theta_j \\left(1 - \\exp(-\\kappa_j(\\tau_{j+1}-\\tau_j))\\right) \\exp\\left(-\\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right).\n$$\n\n- **Term 3 (Stochastic Integral):**\n$$\n\\begin{align*}\n \\int_0^T \\exp\\left(-\\int_s^T \\kappa(i(u))\\,du\\right) \\sigma(i(s))\\,dW_s \\\\\n= \\sum_{j=0}^{n} \\int_{\\tau_j}^{\\tau_{j+1}} \\exp\\left(-\\kappa_j(\\tau_{j+1}-s) - \\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right) \\sigma_j\\,dW_s \\\\\n= \\sum_{j=0}^{n} \\sigma_j \\exp\\left(-\\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right) \\int_{\\tau_j}^{\\tau_{j+1}} \\exp(-\\kappa_j(\\tau_{j+1}-s))\\,dW_s.\n\\end{align*}\n$$\n\nCombining these three terms gives the final closed-form expression for $X_T$. The expression explicitly shows how the solution is built up from contributions over each constant-regime interval. The parameters $(\\kappa_j, \\theta_j)$ define the local mean-reverting dynamics within interval $j$. The final state $X_T$ is a weighted sum where the influence of each interval's dynamics is attenuated by the mean-reversion speeds $\\kappa_k$ of all subsequent intervals, reflecting how memory of past states decays over time at a rate determined by the regime path.\n\nThe full expression is:\n$$\nX_T = X_0 \\exp\\left(-\\sum_{j=0}^{n} \\kappa_j(\\tau_{j+1}-\\tau_j)\\right) + \\sum_{j=0}^{n} \\theta_j \\left(1 - \\exp(-\\kappa_j(\\tau_{j+1}-\\tau_j))\\right) \\exp\\left(-\\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right) + \\sum_{j=0}^{n} \\sigma_j \\exp\\left(-\\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right) \\int_{\\tau_j}^{\\tau_{j+1}} \\exp(-\\kappa_j(\\tau_{j+1}-s))\\,dW_s.\n$$", "answer": "$$\n\\boxed{\nX_0 \\exp\\left(-\\sum_{j=0}^{n} \\kappa_j(\\tau_{j+1}-\\tau_j)\\right) + \\sum_{j=0}^{n} \\left[ \\theta_j \\left(1 - \\exp(-\\kappa_j(\\tau_{j+1}-\\tau_j))\\right) + \\sigma_j \\int_{\\tau_j}^{\\tau_{j+1}} \\exp(-\\kappa_j(\\tau_{j+1}-s))\\,dW_s \\right] \\exp\\left(-\\sum_{k=j+1}^{n} \\kappa_k(\\tau_{k+1}-\\tau_k)\\right)\n}\n$$", "id": "2993989"}]}