{"hands_on_practices": [{"introduction": "The change of measure technique is a cornerstone of modern nonlinear filtering theory, allowing us to reframe complex conditional expectation problems under a more tractable reference measure. This first exercise guides you through the derivation of the celebrated Kallianpur-Striebel formula, which provides an explicit representation for the filter $\\pi_{t}(\\varphi)$ [@problem_id:2988875]. Mastering this derivation is fundamental to understanding how information from observations updates our belief about the hidden state.", "problem": "Consider a continuous-time nonlinear filtering model on a filtered probability space $\\left(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\ge 0},\\mathbb{P}\\right)$ satisfying the usual conditions. Let $\\{W_{t}\\}_{t \\ge 0}$ and $\\{V_{t}\\}_{t \\ge 0}$ be independent standard Brownian motions of dimensions $d$ and $m$, respectively, adapted to $\\{\\mathcal{F}_{t}\\}_{t \\ge 0}$. The unobserved signal $\\{X_{t}\\}_{t \\ge 0}$ solves the stochastic differential equation (SDE)\n$$\ndX_{t} \\;=\\; a\\!\\left(X_{t}\\right)\\,dt \\;+\\; \\sigma\\!\\left(X_{t}\\right)\\,dW_{t},\n$$\nwith $X_{0}$ independent of $\\{V_{t}\\}_{t \\ge 0}$, where $a:\\mathbb{R}^{d}\\to\\mathbb{R}^{d}$ and $\\sigma:\\mathbb{R}^{d}\\to\\mathbb{R}^{d \\times d}$ are such that the SDE admits a unique strong solution. The observation process $\\{Y_{t}\\}_{t \\ge 0}$ is given by\n$$\ndY_{t} \\;=\\; h\\!\\left(X_{t}\\right)\\,dt \\;+\\; dV_{t},\n$$\nwhere $h:\\mathbb{R}^{d}\\to\\mathbb{R}^{m}$ is bounded and measurable. Let $\\mathcal{Y}_{t}:=\\sigma\\!\\left(Y_{s}:0\\le s\\le t\\right)$ denote the observation $\\sigma$-algebra. For any bounded measurable test function $\\varphi:\\mathbb{R}^{d}\\to\\mathbb{R}$, define the (normalized) conditional expectation\n$$\n\\pi_{t}(\\varphi)\\;:=\\;\\mathbb{E}^{\\mathbb{P}}\\!\\left[\\varphi(X_{t})\\mid \\mathcal{Y}_{t}\\right].\n$$\n\nAssume that the Novikov condition holds so that the exponential local martingales below are true martingales. Define the likelihood process\n$$\nZ_{t}\\;:=\\;\\exp\\!\\left(\\int_{0}^{t} h\\!\\left(X_{s}\\right)^{\\top} dY_{s}\\;-\\;\\frac{1}{2}\\int_{0}^{t}\\big\\|h\\!\\left(X_{s}\\right)\\big\\|^{2}\\,ds\\right),\n$$\nand the probability measure $\\mathbb{Q}$ on $\\mathcal{F}_{t}$ by the Radon–Nikodym derivative\n$$\n\\frac{d\\mathbb{Q}}{d\\mathbb{P}}\\bigg|_{\\mathcal{F}_{t}} \\;=\\; Z_{t}^{-1}.\n$$\nUnder $\\mathbb{Q}$, the process $\\{Y_{t}\\}_{t \\ge 0}$ is a standard $m$-dimensional Brownian motion independent of $\\{W_{t}\\}_{t \\ge 0}$. Starting only from the definitions of conditional expectation, the Radon–Nikodym theorem, and the Girsanov change-of-measure theorem, derive a representation for $\\pi_{t}(\\varphi)$ in terms of conditional expectations under $\\mathbb{Q}$ and the weight $Z_{t}$.\n\nThen, use your representation to evaluate the exact value of $\\pi_{t}(\\mathbf{1})$, where $\\mathbf{1}$ denotes the constant function $\\mathbf{1}(x)\\equiv 1$.\n\nYour final answer must be a single exact number without units.", "solution": "The problem is well-posed and scientifically grounded within the mathematical framework of nonlinear filtering theory and stochastic calculus. We shall proceed with the derivation.\n\nOur primary goal is to derive a representation for the conditional expectation $\\pi_{t}(\\varphi) = \\mathbb{E}^{\\mathbb{P}}[\\varphi(X_{t}) \\mid \\mathcal{Y}_{t}]$ under a new measure $\\mathbb{Q}$. This derivation is a classic application of the change of measure technique, often referred to as the Kallianpur-Striebel formula. We will then use this representation to evaluate $\\pi_{t}(\\mathbf{1})$.\n\nFirst, we derive a general formula for the change of measure for conditional expectations. Let $\\xi$ be a bounded $\\mathcal{F}_{t}$-measurable random variable and let $\\mathcal{G}$ be a sub-$\\sigma$-algebra of $\\mathcal{F}_{t}$. The conditional expectation $\\eta := \\mathbb{E}^{\\mathbb{P}}[\\xi \\mid \\mathcal{G}]$ is, by definition, the unique (up to almost sure equality) bounded $\\mathcal{G}$-measurable random variable satisfying\n$$\n\\mathbb{E}^{\\mathbb{P}}[\\eta A] = \\mathbb{E}^{\\mathbb{P}}[\\xi A]\n$$\nfor all bounded $\\mathcal{G}$-measurable random variables $A$.\n\nThe problem defines a new probability measure $\\mathbb{Q}$ via the Radon-Nikodym derivative $\\frac{d\\mathbb{Q}}{d\\mathbb{P}}\\big|_{\\mathcal{F}_{t}} = Z_{t}^{-1}$. Consequently, the inverse relationship is $\\frac{d\\mathbb{P}}{d\\mathbb{Q}}\\big|_{\\mathcal{F}_{t}} = Z_{t}$. The relationship between expectations under $\\mathbb{P}$ and $\\mathbb{Q}$ for any integrable random variable $U$ on $(\\Omega, \\mathcal{F}_t)$ is given by the Radon-Nikodym theorem as\n$$\n\\mathbb{E}^{\\mathbb{P}}[U] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[U \\frac{d\\mathbb{P}}{d\\mathbb{Q}}\\right] = \\mathbb{E}^{\\mathbb{Q}}[U Z_{t}].\n$$\nApplying this change of measure to the defining equation of conditional expectation, we obtain\n$$\n\\mathbb{E}^{\\mathbb{Q}}[\\eta A Z_{t}] = \\mathbb{E}^{\\mathbb{Q}}[\\xi A Z_{t}].\n$$\nUsing the tower property of conditional expectation, the left-hand side can be written as:\n$$\n\\mathbb{E}^{\\mathbb{Q}}[\\eta A Z_{t}] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\mathbb{E}^{\\mathbb{Q}}[\\eta A Z_{t} \\mid \\mathcal{G}]\\right].\n$$\nSince $\\eta$ and $A$ are $\\mathcal{G}$-measurable by definition, they can be treated as constants with respect to the inner conditional expectation:\n$$\n\\mathbb{E}^{\\mathbb{Q}}[\\eta A Z_{t}] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\eta A \\mathbb{E}^{\\mathbb{Q}}[Z_{t} \\mid \\mathcal{G}]\\right].\n$$\nSimilarly, for the right-hand side of our main equation:\n$$\n\\mathbb{E}^{\\mathbb{Q}}[\\xi A Z_{t}] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\mathbb{E}^{\\mathbb{Q}}[\\xi A Z_{t} \\mid \\mathcal{G}]\\right] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[A \\mathbb{E}^{\\mathbb{Q}}[\\xi Z_{t} \\mid \\mathcal{G}]\\right].\n$$\nEquating the transformed sides, we have\n$$\n\\mathbb{E}^{\\mathbb{Q}}\\!\\left[A \\eta \\mathbb{E}^{\\mathbb{Q}}[Z_{t} \\mid \\mathcal{G}]\\right] = \\mathbb{E}^{\\mathbb{Q}}\\!\\left[A \\mathbb{E}^{\\mathbb{Q}}[\\xi Z_{t} \\mid \\mathcal{G}]\\right].\n$$\nThis equality must hold for any bounded $\\mathcal{G}$-measurable random variable $A$. This implies that the random variables multiplying $A$ inside the expectations must be equal almost surely under $\\mathbb{Q}$:\n$$\n\\eta \\mathbb{E}^{\\mathbb{Q}}[Z_{t} \\mid \\mathcal{G}] = \\mathbb{E}^{\\mathbb{Q}}[\\xi Z_{t} \\mid \\mathcal{G}].\n$$\nSolving for $\\eta = \\mathbb{E}^{\\mathbb{P}}[\\xi \\mid \\mathcal{G}]$, we arrive at the abstract Bayes' formula:\n$$\n\\mathbb{E}^{\\mathbb{P}}[\\xi \\mid \\mathcal{G}] = \\frac{\\mathbb{E}^{\\mathbb{Q}}[\\xi Z_{t} \\mid \\mathcal{G}]}{\\mathbb{E}^{\\mathbb{Q}}[Z_{t} \\mid \\mathcal{G}]}.\n$$\nNow, we apply this general result to the specific filtering problem. We set $\\xi = \\varphi(X_{t})$ and $\\mathcal{G} = \\mathcal{Y}_{t}$. This immediately yields the desired representation of $\\pi_{t}(\\varphi)$ in terms of conditional expectations under $\\mathbb{Q}$:\n$$\n\\pi_{t}(\\varphi) = \\frac{\\mathbb{E}^{\\mathbb{Q}}\\!\\left[\\varphi(X_{t}) Z_{t} \\mid \\mathcal{Y}_{t}\\right]}{\\mathbb{E}^{\\mathbb{Q}}[Z_{t} \\mid \\mathcal{Y}_{t}]}.\n$$\nThis expression is the first part of the answer. It represents the posterior distribution as a ratio of two unnormalized conditional distributions. A crucial aspect provided in the problem statement is that under the measure $\\mathbb{Q}$, the observation process $\\{Y_t\\}_{t \\ge 0}$ is a standard Brownian motion *independent* of the driving noise $\\{W_t\\}_{t \\ge 0}$ of the signal process. Since the signal $\\{X_t\\}_{t \\ge 0}$ is a functional of its initial condition $X_0$ and the path of $\\{W_s\\}_{0 \\le s \\le t}$, it follows that the entire process $\\{X_t\\}_{t \\ge 0}$ is independent of the filtration $\\mathcal{Y}_t$ under the measure $\\mathbb{Q}$.\n\nThis independence property allows for a significant simplification of the conditional expectations. For a functional $F(X, Y)$ that depends on the paths of both processes $X$ and $Y$, the conditional expectation given $\\mathcal{Y}_t$ under $\\mathbb{Q}$ is calculated by integrating over the paths of $X$, treating the path of $Y$ as a fixed parameter:\n$$\n\\mathbb{E}^{\\mathbb{Q}}[F(X,Y) \\mid \\mathcal{Y}_t] = \\mathbb{E}_{X}^{\\mathbb{Q}}[F(X,Y)].\n$$\nHere, $\\mathbb{E}_{X}^{\\mathbb{Q}}$ denotes the expectation with respect to the law of the process $X$ under $\\mathbb{Q}$. Since the Radon-Nikodym derivative $Z_t^{-1}$ involves only $X$ and $V$ (via $Y$), the law of the process $X$ (driven by $W$) is the same under $\\mathbb{P}$ and $\\mathbb{Q}$. Thus we can simply write $\\mathbb{E}_X$. Applying this to our formula for $\\pi_t(\\varphi)$:\nThe numerator becomes $\\mathbb{E}_{X}[\\varphi(X_{t}) Z_{t}]$, and the denominator becomes $\\mathbb{E}_{X}[Z_{t}]$.\nHere, $Z_{t} = \\exp(\\int_{0}^{t} h(X_{s})^{\\top} dY_{s} - \\frac{1}{2}\\int_{0}^{t}\\|h(X_{s})\\|^{2}\\,ds)$ is treated as a functional where the stochastic integral is with respect to the observed path of $Y$, and the expectation averages over all paths of $X$.\n\nThe final representation for the filter is:\n$$\n\\pi_{t}(\\varphi) = \\frac{\\mathbb{E}_{X}\\!\\left[\\varphi(X_t) \\exp\\!\\left(\\int_{0}^{t} h(X_{s})^{\\top} dY_{s} - \\frac{1}{2}\\int_{0}^{t}\\|h(X_{s})\\|^{2}\\,ds\\right)\\right]}{\\mathbb{E}_{X}\\!\\left[\\exp\\!\\left(\\int_{0}^{t} h(X_{s})^{\\top} dY_{s} - \\frac{1}{2}\\int_{0}^{t}\\|h(X_{s})\\|^{2}\\,ds\\right)\\right]}.\n$$\n\nNow, we proceed to the second part of the task: to evaluate $\\pi_{t}(\\mathbf{1})$. The function $\\mathbf{1}$ is the constant function such that $\\mathbf{1}(x) = 1$ for all $x \\in \\mathbb{R}^d$.\nWe can evaluate this directly from the definition of $\\pi_t(\\varphi)$:\n$$\n\\pi_{t}(\\mathbf{1}) = \\mathbb{E}^{\\mathbb{P}}[\\mathbf{1}(X_{t}) \\mid \\mathcal{Y}_{t}] = \\mathbb{E}^{\\mathbb{P}}[1 \\mid \\mathcal{Y}_{t}].\n$$\nThe conditional expectation of a constant is the constant itself. Thus,\n$$\n\\pi_{t}(\\mathbf{1}) = 1.\n$$\nTo confirm this result using the derived representation, we substitute $\\varphi(X_t) = \\mathbf{1}(X_t) = 1$ into our formula:\n$$\n\\pi_{t}(\\mathbf{1}) = \\frac{\\mathbb{E}_{X}[1 \\cdot Z_{t}]}{\\mathbb{E}_{X}[Z_{t}]} = \\frac{\\mathbb{E}_{X}[Z_{t}]}{\\mathbb{E}_{X}[Z_{t}]}.\n$$\nSince the Novikov condition is assumed to hold, the exponential martingale $Z_t$ has a well-defined and positive expectation. Thus, the denominator $\\mathbb{E}_{X}[Z_{t}]$ is strictly positive. Therefore, the expression simplifies to $1$. Both methods yield the same result. The exact value is $1$.", "answer": "$$\\boxed{1}$$", "id": "2988875"}, {"introduction": "With the abstract Kallianpur-Striebel formula in hand, we now apply it to a concrete and illustrative scenario: estimating a hidden binary state from noisy observations [@problem_id:2988892]. This exercise demonstrates how the general theory elegantly simplifies for a finite state space, yielding a surprisingly compact and intuitive closed-form solution for the filter. Solving this canonical problem is a rite of passage that builds powerful intuition for the interplay between signal, observation, and posterior belief.", "problem": "Consider a hidden signal process $\\{X_t\\}_{t \\in [0,1]}$ taking values in the finite state space $\\{-1,+1\\}$, with piecewise constant paths specified by $X_t \\equiv X_0$ almost surely. Assume the prior distribution is symmetric, $\\mathbb{P}(X_0=+1)=\\mathbb{P}(X_0=-1)=\\tfrac{1}{2}$. The observation process $\\{Y_t\\}_{t \\in [0,1]}$ is scalar and governed by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}Y_t \\;=\\; \\theta\\, X_t\\, \\mathrm{d}t \\;+\\; \\mathrm{d}W_t,\n$$\nwhere $\\theta0$ is known and $\\{W_t\\}$ is a standard Wiener process independent of $X_0$. For a bounded test function $\\varphi:\\{-1,+1\\}\\to\\mathbb{R}$, define the nonlinear filter\n$$\n\\pi_t(\\varphi) \\;=\\; \\mathbb{E}\\!\\left[\\,\\varphi(X_t)\\,\\middle|\\,\\mathcal{F}_t^Y\\right],\n$$\nwhere $\\mathcal{F}_t^Y$ is the $\\sigma$-algebra generated by $\\{Y_s:0\\le s\\le t\\}$. Starting from the fundamental definition of conditional expectation, the existence of a reference probability measure under which $\\{Y_t\\}$ is a standard Wiener process independent of $\\{X_t\\}$, and the Radon–Nikodym likelihood process represented by a Doléans–Dade exponential, derive an explicit closed-form expression for $\\pi_t(\\varphi)$ as a functional of the observed path $\\{Y_s: 0 \\le s \\le t\\}$ in the special case $\\varphi(x)=x$.\n\nThen evaluate your expression at time $t=1$ for the observation whose terminal value satisfies $Y_1=\\frac{1}{2\\theta}\\ln 3$. Express your final answer as a single real number. No units are required, and no rounding is necessary.", "solution": "The problem is well-posed and represents a canonical example in nonlinear filtering theory. We shall proceed with its solution. The objective is to derive an explicit expression for the nonlinear filter $\\pi_t(\\varphi) = \\mathbb{E}[\\varphi(X_t) \\mid \\mathcal{F}_t^Y]$ for the special case $\\varphi(x)=x$, and then evaluate it under a specific condition.\n\nLet the underlying probability space be $(\\Omega, \\mathcal{F}, \\mathbb{P})$. The observation process is given by the SDE:\n$$\n\\mathrm{d}Y_t = \\theta X_t \\mathrm{d}t + \\mathrm{d}W_t, \\quad Y_0 = 0\n$$\nwhere $\\{W_t\\}$ is a standard Wiener process under $\\mathbb{P}$ and is independent of $X_0$.\n\nThe core of the solution lies in the change of probability measure technique. We define a new reference measure $\\mathbb{P}_0$ under which the observation process $\\{Y_t\\}$ behaves as a standard Wiener process. According to Girsanov's theorem, we can define such a measure $\\mathbb{P}_0$ via its Radon-Nikodym derivative with respect to $\\mathbb{P}$ on the filtration $\\mathcal{F}_t = \\sigma(X_0) \\vee \\mathcal{F}_t^W$, where $\\mathcal{F}_t^W$ is the filtration generated by $\\{W_s: 0 \\le s \\le t\\}$. Let us define the process $Z_t$ such that $\\mathrm{d}Y_t = Z_t \\mathrm{d}t + \\mathrm{d}W_t$. Here, $Z_t = \\theta X_t$. The Novikov condition, $\\mathbb{E}[\\exp(\\frac{1}{2}\\int_0^t Z_s^2 \\mathrm{d}s)]  \\infty$, is satisfied since $X_s^2 = 1$, so $\\int_0^t Z_s^2 \\mathrm{d}s = \\theta^2 t$, which is deterministic and finite.\n\nWe define the likelihood process (or Radon-Nikodym density process) $L_t$ as the Doléans-Dade exponential:\n$$\nL_t = \\frac{\\mathrm{d}\\mathbb{P}}{\\mathrm{d}\\mathbb{P}_0}\\bigg|_{\\mathcal{F}_t^Y} = \\exp\\left( \\int_0^t \\theta X_s \\mathrm{d}Y_s - \\frac{1}{2} \\int_0^t (\\theta X_s)^2 \\mathrm{d}s \\right)\n$$\nwhere under the new measure $\\mathbb{P}_0$, the process $\\{Y_t\\}$ is a standard Wiener process independent of $\\{X_t\\}$. The integral $\\int_0^t \\theta X_s \\mathrm{d}Y_s$ is an Itô integral with respect to $\\{Y_t\\}$, which is a semimartingale under $\\mathbb{P}$ but a Wiener process under $\\mathbb{P}_0$.\n\nThe problem states that $X_t \\equiv X_0$ almost surely for $t \\in [0,1]$. This simplifies the exponents:\n$$\n\\int_0^t \\theta X_s \\mathrm{d}Y_s = \\theta X_0 \\int_0^t \\mathrm{d}Y_s = \\theta X_0 Y_t\n$$\n$$\n\\int_0^t (\\theta X_s)^2 \\mathrm{d}s = \\int_0^t \\theta^2 \\mathrm{d}s = \\theta^2 t\n$$\nThus, the likelihood process becomes:\n$$\nL_t = \\exp\\left( \\theta X_0 Y_t - \\frac{1}{2}\\theta^2 t \\right)\n$$\n\nThe fundamental formula for nonlinear filtering, often called the Kallianpur-Striebel formula, connects the conditional expectation under $\\mathbb{P}$ to an expectation under the reference measure $\\mathbb{P}_0$. For any bounded test function $\\varphi$,\n$$\n\\pi_t(\\varphi) = \\mathbb{E}[\\varphi(X_t) \\mid \\mathcal{F}_t^Y] = \\frac{\\mathbb{E}_0[\\varphi(X_t) L_t \\mid \\mathcal{F}_t^Y]}{\\mathbb{E}_0[L_t \\mid \\mathcal{F}_t^Y]}\n$$\nSince $X_t = X_0$ and $\\{Y_t\\}$ is independent of $X_0$ under $\\mathbb{P}_0$, and $Y_t$ is $\\mathcal{F}_t^Y$-measurable, we can simplify the numerator and denominator. The term $L_t$ explicitly depends on $X_0$ and $Y_t$.\nThe numerator is:\n$$\n\\mathbb{E}_0[\\varphi(X_0) L_t \\mid \\mathcal{F}_t^Y] = \\mathbb{E}_0\\left[\\varphi(X_0) \\exp\\left( \\theta X_0 Y_t - \\frac{1}{2}\\theta^2 t \\right) \\mid \\mathcal{F}_t^Y\\right]\n$$\nSince $X_0$ is independent of $\\mathcal{F}_t^Y$ under $\\mathbb{P}_0$, we can take the expectation with respect to $X_0$ only:\n$$\n\\mathbb{E}_0[\\varphi(X_0) L_t \\mid \\mathcal{F}_t^Y] = \\mathbb{E}_0\\left[\\varphi(X_0) \\exp\\left( \\theta X_0 Y_t - \\frac{1}{2}\\theta^2 t \\right)\\right]\n$$\nThis expectation is over the distribution of $X_0$, which is the same under both $\\mathbb{P}$ and $\\mathbb{P}_0$. The term $\\exp(-\\frac{1}{2}\\theta^2 t)$ is a constant with respect to the random variable $X_0$.\nLet's define the unnormalized filter $\\sigma_t(\\varphi) = \\mathbb{E}_0[\\varphi(X_0) L_t]$. Then:\n$$\n\\pi_t(\\varphi) = \\frac{\\sigma_t(\\varphi)}{\\sigma_t(1)}\n$$\nwhere $\\sigma_t(1)$ corresponds to the case $\\varphi(x)=1$.\n\nWe now evaluate $\\sigma_t(\\varphi)$ using the given prior distribution $\\mathbb{P}(X_0=+1) = \\mathbb{P}(X_0=-1) = \\frac{1}{2}$.\n$$\n\\sigma_t(\\varphi) = \\sum_{k \\in \\{-1, +1\\}} \\varphi(k) \\exp\\left( \\theta k Y_t - \\frac{1}{2}\\theta^2 t \\right) \\mathbb{P}(X_0=k)\n$$\n$$\n\\sigma_t(\\varphi) = \\frac{1}{2}\\exp\\left(-\\frac{1}{2}\\theta^2 t\\right) \\left[ \\varphi(1) \\exp(\\theta Y_t) + \\varphi(-1) \\exp(-\\theta Y_t) \\right]\n$$\nFor the specific case $\\varphi(x)=x$, we have $\\varphi(1)=1$ and $\\varphi(-1)=-1$.\n$$\n\\sigma_t(x) = \\frac{1}{2}\\exp\\left(-\\frac{1}{2}\\theta^2 t\\right) \\left[ \\exp(\\theta Y_t) - \\exp(-\\theta Y_t) \\right]\n$$\nFor the denominator, we set $\\varphi(x)=1$, which gives $\\varphi(1)=1$ and $\\varphi(-1)=1$.\n$$\n\\sigma_t(1) = \\frac{1}{2}\\exp\\left(-\\frac{1}{2}\\theta^2 t\\right) \\left[ \\exp(\\theta Y_t) + \\exp(-\\theta Y_t) \\right]\n$$\nTaking the ratio gives the desired filter expression:\n$$\n\\pi_t(x) = \\frac{\\sigma_t(x)}{\\sigma_t(1)} = \\frac{\\frac{1}{2}\\exp(-\\frac{1}{2}\\theta^2 t) [ \\exp(\\theta Y_t) - \\exp(-\\theta Y_t) ]}{\\frac{1}{2}\\exp(-\\frac{1}{2}\\theta^2 t) [ \\exp(\\theta Y_t) + \\exp(-\\theta Y_t) ]} = \\frac{\\exp(\\theta Y_t) - \\exp(-\\theta Y_t)}{\\exp(\\theta Y_t) + \\exp(-\\theta Y_t)}\n$$\nThis expression is the definition of the hyperbolic tangent function. Thus, the explicit closed-form expression for the filter is:\n$$\n\\pi_t(x) = \\tanh(\\theta Y_t)\n$$\nThis is the conditional expectation of $X_t$ given the history of observations up to time $t$, i.e., $\\mathbb{E}[X_t \\mid \\mathcal{F}_t^Y]$.\n\nNow, we must evaluate this expression at time $t=1$ for the specific observation path whose terminal value is $Y_1 = \\frac{1}{2\\theta}\\ln 3$.\nWe need to compute $\\pi_1(x) = \\tanh(\\theta Y_1)$.\nSubstituting the given value of $Y_1$:\n$$\n\\pi_1(x) = \\tanh\\left(\\theta \\cdot \\frac{1}{2\\theta}\\ln 3\\right) = \\tanh\\left(\\frac{1}{2}\\ln 3\\right)\n$$\nWe can simplify this expression. First, use the property $a\\ln b = \\ln(b^a)$:\n$$\n\\frac{1}{2}\\ln 3 = \\ln(3^{1/2}) = \\ln(\\sqrt{3})\n$$\nSo, we need to evaluate $\\tanh(\\ln(\\sqrt{3}))$. Using the definition $\\tanh(z) = \\frac{\\exp(z)-\\exp(-z)}{\\exp(z)+\\exp(-z)}$:\n$$\n\\tanh(\\ln(\\sqrt{3})) = \\frac{\\exp(\\ln(\\sqrt{3})) - \\exp(-\\ln(\\sqrt{3}))}{\\exp(\\ln(\\sqrt{3})) + \\exp(-\\ln(\\sqrt{3}))}\n$$\nSince $\\exp(\\ln a) = a$ and $\\exp(-\\ln a) = \\exp(\\ln(1/a)) = 1/a$:\n$$\n\\tanh(\\ln(\\sqrt{3})) = \\frac{\\sqrt{3} - \\frac{1}{\\sqrt{3}}}{\\sqrt{3} + \\frac{1}{\\sqrt{3}}}\n$$\nTo simplify the fraction, we multiply the numerator and the denominator by $\\sqrt{3}$:\n$$\n\\tanh(\\ln(\\sqrt{3})) = \\frac{\\sqrt{3}\\left(\\sqrt{3} - \\frac{1}{\\sqrt{3}}\\right)}{\\sqrt{3}\\left(\\sqrt{3} + \\frac{1}{\\sqrt{3}}\\right)} = \\frac{(\\sqrt{3})^2 - 1}{(\\sqrt{3})^2 + 1} = \\frac{3-1}{3+1} = \\frac{2}{4} = \\frac{1}{2}\n$$\nThe value of the filter at $t=1$ is $\\frac{1}{2}$. This means that given the observation path ending at $Y_1 = \\frac{1}{2\\theta}\\ln 3$, the conditional probability of $X_1$ being $+1$ is $\\mathbb{P}(X_1=+1 \\mid \\mathcal{F}_1^Y) = \\frac{1+\\pi_1(x)}{2} = \\frac{1+1/2}{2} = \\frac{3}{4}$, and the probability of it being $-1$ is $\\frac{1}{4}$. The conditional expectation is $(+1)\\frac{3}{4} + (-1)\\frac{1}{4} = \\frac{2}{4} = \\frac{1}{2}$.", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "2988892"}, {"introduction": "While analytical solutions are invaluable for building intuition, most practical filtering problems are analytically intractable, necessitating numerical methods. This final practice moves from theory to computation, focusing on the Zakai stochastic partial differential equation (SPDE) that governs the unnormalized conditional density [@problem_id:2988907]. You are tasked with analyzing and selecting a consistent, stable, and convergent numerical scheme, a critical skill for applying filtering theory to real-world challenges.", "problem": "Consider a nonlinear filtering model in continuous time on a bounded spatial interval. The hidden signal process satisfies the stochastic differential equation (SDE)\n$$\n\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + \\sigma(X_t)\\,\\mathrm{d}W_t,\n$$\nand the observation process satisfies\n$$\n\\mathrm{d}Y_t = h(X_t)\\,\\mathrm{d}t + \\mathrm{d}V_t,\n$$\nwhere $W_t$ and $V_t$ are independent standard Wiener processes, $a:\\mathbb{R}\\to\\mathbb{R}$, $\\sigma:\\mathbb{R}\\to\\mathbb{R}$, and $h:\\mathbb{R}\\to\\mathbb{R}$ are sufficiently smooth functions with at most linear growth. Let the initial signal density be $p_0 \\in L^1(\\mathbb{R})$, and suppose we approximate the spatial domain by a closed interval $[x_{\\min},x_{\\max}]$ with suitable boundary conditions that guarantee well-posedness of the forward Kolmogorov operator.\n\nThe unnormalized conditional density (Zakai density) $\\tilde p_t(x)$ satisfies the linear stochastic partial differential equation (SPDE), in its density form,\n$$\n\\mathrm{d}\\tilde p_t(x) \\;=\\; \\mathcal{L}^*\\tilde p_t(x)\\,\\mathrm{d}t \\;+\\; \\tilde p_t(x)\\,h(x)\\,\\mathrm{d}Y_t,\n$$\nwhere the adjoint generator $\\mathcal{L}^*$ associated with the signal SDE is (formally)\n$$\n\\mathcal{L}^* \\varphi(x) \\;=\\; -\\frac{\\partial}{\\partial x}\\big(a(x)\\,\\varphi(x)\\big) \\;+\\; \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\big(\\sigma^2(x)\\,\\varphi(x)\\big).\n$$\n\nYou are tasked with proposing a consistent time–space discretization for this Zakai SPDE and stating mathematically precise stability and convergence conditions that guarantee mean-square stability and strong convergence of the scheme.\n\nAssume:\n- The coefficients $a$, $\\sigma$, and $h$ are globally Lipschitz with bounded first derivatives, and $\\sigma^2(x) \\ge \\nu  0$ (uniform ellipticity).\n- The spatial domain is truncated to $[x_{\\min},x_{\\max}]$, partitioned into a uniform grid $\\{x_j\\}_{j=0}^{J}$ with mesh width $\\Delta x$, and time is discretized as $t_n = n\\,\\Delta t$.\n- The observed data are available as increments $\\Delta Y_n := Y_{t_{n+1}} - Y_{t_n}$.\n\nWhich of the following options proposes a consistent numerical scheme together with correct stability and convergence conditions for the Zakai SPDE under the stated assumptions?\n\nA. Use a semi-implicit Crank–Nicolson time-stepping for the deterministic operator and an explicit treatment of the multiplicative observation noise:\n$$\n\\big(I - \\tfrac{1}{2}\\Delta t\\,A\\big)\\,p^{n+1} \\;=\\; \\big(I + \\tfrac{1}{2}\\Delta t\\,A\\big)\\,p^{n} \\;+\\; \\operatorname{diag}(h)\\,p^{n}\\,\\Delta Y_n,\n$$\nwhere $A$ is the second-order central-difference discretization of $\\mathcal{L}^*$ on $[x_{\\min},x_{\\max}]$ with conservative fluxes and boundary conditions chosen so that $A$ is an $M$-matrix. Then:\n- The scheme is consistent with order $\\mathcal{O}(\\Delta x^2)$ in space and strong order $\\mathcal{O}(\\Delta t^{1/2})$ in time.\n- Mean-square stability holds without a Courant–Friedrichs–Lewy (CFL) restriction from the deterministic part, and there exists $C0$ such that\n$$\n\\mathbb{E}\\big[\\|p^{n+1}\\|_2^2\\big] \\le \\big(1 + C\\,\\Delta t\\big)\\,\\mathbb{E}\\big[\\|p^{n}\\|_2^2\\big],\n$$\nprovided $\\|h\\|_\\infty\\infty$, which yields $\\sup_{n\\Delta t\\le T}\\mathbb{E}[\\|p^n\\|_2^2]\\le C_T\\,\\mathbb{E}[\\|p^0\\|_2^2]$ for $T\\infty$.\n- Strong convergence in $L^2(\\Omega; \\ell^2)$ holds with error $\\mathcal{O}(\\Delta x^2 + \\Delta t^{1/2})$ under the stated smoothness and ellipticity conditions.\n\nB. Use a fully explicit Euler–Maruyama time-stepping with second-order central differences for $\\mathcal{L}^*$:\n$$\np^{n+1} \\;=\\; \\big(I + \\Delta t\\,A\\big)\\,p^n \\;+\\; \\operatorname{diag}(h)\\,p^{n}\\,\\Delta Y_n,\n$$\nand claim unconditional mean-square stability with strong temporal order $\\mathcal{O}(\\Delta t)$ and spatial order $\\mathcal{O}(\\Delta x^2)$, independent of any relation between $\\Delta t$ and $\\Delta x$.\n\nC. Use fully implicit time-stepping for both the deterministic and stochastic terms:\n$$\n\\big(I - \\Delta t\\,A - \\operatorname{diag}(h)\\,\\Delta Y_n\\big)\\,p^{n+1} \\;=\\; p^n,\n$$\nand claim that the method is positivity-preserving and unconditionally mean-square stable for arbitrary $\\Delta t0$ and any bounded $h$, with strong temporal order $\\mathcal{O}(1)$.\n\nD. Use a spectral Galerkin projection onto the first $K$ eigenfunctions of the Laplacian with homogeneous Neumann boundary conditions, combined with a first-order Strang splitting in time for drift–diffusion and multiplicative noise, and claim strong temporal order $\\mathcal{O}(\\Delta t)$ without Lévy area or commutator terms, provided only that $\\Delta t = o(\\Delta x^4)$ as $\\Delta x\\to 0$.\n\nSelect the correct option(s). Provide justification grounded in the definitions of the adjoint generator, Itô calculus for stochastic integrators, and standard stability concepts for linear stochastic recursion in mean-square. Your reasoning should explain why the proposed conditions are necessary and sufficient for stability and convergence in the sense stated, and why the alternative options fail or overclaim.", "solution": "The user wants me to analyze a problem in nonlinear filtering theory.\n\n### Step 1: Extract Givens\nThe problem statement provides the following information:\n- The hidden signal process is given by the Stochastic Differential Equation (SDE):\n$$\n\\mathrm{d}X_t = a(X_t)\\,\\mathrm{d}t + \\sigma(X_t)\\,\\mathrm{d}W_t\n$$\n- The observation process is given by:\n$$\n\\mathrm{d}Y_t = h(X_t)\\,\\mathrm{d}t + \\mathrm{d}V_t\n$$\n- $W_t$ and $V_t$ are independent standard Wiener processes.\n- The functions $a:\\mathbb{R}\\to\\mathbb{R}$, $\\sigma:\\mathbb{R}\\to\\mathbb{R}$, and $h:\\mathbb{R}\\to\\mathbb{R}$ are sufficiently smooth with at most linear growth.\n- The initial signal density is $p_0 \\in L^1(\\mathbb{R})$.\n- The unnormalized conditional density (Zakai density) $\\tilde p_t(x)$ satisfies the linear Stochastic Partial Differential Equation (SPDE):\n$$\n\\mathrm{d}\\tilde p_t(x) \\;=\\; \\mathcal{L}^*\\tilde p_t(x)\\,\\mathrm{d}t \\;+\\; \\tilde p_t(x)\\,h(x)\\,\\mathrm{d}Y_t\n$$\n- The adjoint generator $\\mathcal{L}^*$ is formally defined as:\n$$\n\\mathcal{L}^* \\varphi(x) \\;=\\; -\\frac{\\partial}{\\partial x}\\big(a(x)\\,\\varphi(x)\\big) \\;+\\; \\frac{1}{2}\\frac{\\partial^2}{\\partial x^2}\\big(\\sigma^2(x)\\,\\varphi(x)\\big)\n$$\n- **Assumptions for the numerical scheme:**\n    - The coefficients $a$, $\\sigma$, and $h$ are globally Lipschitz with bounded first derivatives.\n    - Uniform ellipticity holds: $\\sigma^2(x) \\ge \\nu  0$.\n    - The spatial domain is truncated to $[x_{\\min},x_{\\max}]$ and discretized with a uniform grid $\\{x_j\\}_{j=0}^{J}$ with mesh width $\\Delta x$.\n    - Time is discretized as $t_n = n\\,\\Delta t$.\n    - Observation increments are given as $\\Delta Y_n := Y_{t_{n+1}} - Y_{t_n}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the established criteria:\n\n- **Scientifically Grounded:** The problem is firmly situated in the mathematical field of stochastic analysis, specifically nonlinear filtering theory. The signal-observation model is standard, and the resulting Zakai equation is a cornerstone of this theory. The equation for the unnormalized density is a well-established linear SPDE. The definition of the adjoint generator $\\mathcal{L}^*$ is correct for the given signal SDE (it is the generator of the associated Fokker-Planck equation). The assumptions on the coefficients ($a, \\sigma, h$) are standard conditions required to ensure the well-posedness of both the continuous problem and its numerical approximations. The problem is mathematically and scientifically sound.\n- **Well-Posed:** The task is to evaluate proposed numerical schemes for a well-posed SPDE under standard regularity assumptions. This is a clear and meaningful problem in numerical analysis for SPDEs. A unique and stable solution to the Zakai equation is known to exist under the given conditions.\n- **Objective:** The language is formal, precise, and devoid of any subjective or ambiguous terminology. All terms are standard within the relevant field of mathematics.\n- **Completeness and Consistency:** The problem is self-contained. It provides the continuous model, the target SPDE, the necessary assumptions, and the discretization setup. There are no internal contradictions.\n- **Other Flaws:** The problem is not trivial, as it requires a nuanced understanding of numerical stability and convergence for SPDEs with multiplicative noise. It is not metaphorical, circular, or otherwise ill-structured.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. It is a well-posed, scientifically grounded, and clearly articulated problem in the numerical analysis of SPDEs for nonlinear filtering. I will now proceed with the solution and evaluation of the options.\n\n### Derivation and Analysis\n\nThe Zakai equation is a linear SPDE of the form\n$$\n\\mathrm{d}p_t = \\mathcal{A}p_t\\,\\mathrm{d}t + \\mathcal{B}(p_t)\\,\\mathrm{d}Y_t,\n$$\nwhere $p_t = \\tilde p_t(x)$, $\\mathcal{A} = \\mathcal{L}^*$, and the multiplication operator $\\mathcal{B}(p_t) = h(x)p_t$ is linear in $p_t$. We are considering a finite-dimensional approximation where $p^n \\in \\mathbb{R}^{J+1}$ approximates the solution $\\tilde{p}_{t_n}(x)$ at the grid points. The operator $\\mathcal{A}$ is approximated by a matrix $A$, and $\\mathcal{B}$ by a matrix-vector product involving $\\operatorname{diag}(h)$. The observation increment $\\Delta Y_n$ is approximately $\\mathbb{E}[h(X_{t_n}) | \\mathcal{F}_{t_n}^Y]\\,\\Delta t + \\Delta \\nu_n$, where $\\Delta \\nu_n$ is an increment of the innovations Wiener process, having variance $\\Delta t$. For the purpose of analyzing the numerical scheme's stability and convergence, we can treat $\\Delta Y_n$ as a random variable with variance $\\Delta t$, i.e., $\\mathbb{E}[(\\Delta Y_n)^2] = \\Delta t + \\mathcal{O}(\\Delta t^2)$.\n\nLet's analyze the properties of a general time-stepping scheme for the discretized system:\n$$\np^{n+1} = \\mathcal{F}(\\Delta t, \\Delta Y_n, A, \\operatorname{diag}(h)) p^n.\n$$\n\n**Key Concepts:**\n1.  **Strong Convergence:** A scheme has strong order $\\gamma$ in time and $\\beta$ in space if the strong error satisfies $\\mathbb{E}\\big[\\|p^n - p(t_n)\\|^2\\big]^{1/2} = \\mathcal{O}(\\Delta t^\\gamma + \\Delta x^\\beta)$. For SPDEs with multiplicative noise, the benchmark strong order for simple time-stepping schemes (like Euler-Maruyama) is $\\gamma = 1/2$.\n2.  **Mean-Square Stability:** The scheme is mean-square stable if the second moment of the numerical solution remains bounded. A sufficient condition is that there exists a constant $C$ such that for all $n$, $\\mathbb{E}\\big[\\|p^{n+1}\\|_2^2\\big] \\le (1 + C\\,\\Delta t)\\,\\mathbb{E}\\big[\\|p^n\\|_2^2\\big]$. This, by a discrete Gronwall inequality, implies $\\sup_{n\\Delta t \\le T} \\mathbb{E}\\big[\\|p^n\\|_2^2\\big]  \\infty$.\n3.  **CFL Condition:** For explicit time-stepping schemes applied to parabolic PDEs (like the deterministic part), stability typically requires a constraint linking the time step and space step, such as $\\Delta t \\le C\\,\\Delta x^2$. This is the Courant–Friedrichs–Lewy (CFL) condition. Implicit schemes can often remove this restriction.\n\n### Option-by-Option Analysis\n\n**A. Use a semi-implicit Crank–Nicolson time-stepping...**\n\nThe proposed scheme is:\n$$\n\\big(I - \\tfrac{1}{2}\\Delta t\\,A\\big)\\,p^{n+1} \\;=\\; \\big(I + \\tfrac{1}{2}\\Delta t\\,A\\big)\\,p^{n} \\;+\\; \\operatorname{diag}(h)\\,p^{n}\\,\\Delta Y_n\n$$\nThis can be rewritten as:\n$$\np^{n+1} \\;=\\; \\big(I - \\tfrac{1}{2}\\Delta t\\,A\\big)^{-1} \\bigg[ \\Big(I + \\tfrac{1}{2}\\Delta t\\,A\\Big)\\,p^{n} \\;+\\; \\operatorname{diag}(h)\\,p^{n}\\,\\Delta Y_n \\bigg]\n$$\n- **Consistency and Convergence Order:** The numerical operator for the deterministic part is the Crank-Nicolson operator, which is second-order accurate in time, i.e., $\\mathcal{O}(\\Delta t^2)$. The spatial discretization is a second-order central-difference scheme, giving an error of $\\mathcal{O}(\\Delta x^2)$. The stochastic term is treated with an explicit Euler-Maruyama type step. The strong order of the Euler-Maruyama method for SDEs/SPDEs is $\\mathcal{O}(\\Delta t^{1/2})$. The overall strong order of the scheme is limited by the term with the lowest order, which is the stochastic term. Therefore, the strong convergence rate is $\\mathcal{O}(\\Delta x^2 + \\Delta t^{1/2})$. This claim is correct.\n\n- **Stability:** The matrix $A$ discretizes the operator $\\mathcal{L}^*$, which is dissipative. With appropriate boundary conditions (e.g., homogeneous Dirichlet or Neumann), the eigenvalues of $A$ are non-positive. For such an $A$, the Crank-Nicolson operator $C = (I - \\frac{1}{2}\\Delta t A)^{-1}(I + \\frac{1}{2}\\Delta t A)$ is unconditionally stable with spectral radius $\\rho(C) \\le 1$. Let's analyze the mean-square norm of $p^{n+1}$.\n$$\n\\mathbb{E}\\big[\\|p^{n+1}\\|_2^2\\big] = \\mathbb{E}\\left[\\left\\| \\big(I - \\tfrac{1}{2}\\Delta t\\,A\\big)^{-1} \\left( \\big(I + \\tfrac{1}{2}\\Delta t\\,A\\big) p^n + \\operatorname{diag}(h)p^n \\Delta Y_n \\right) \\right\\|_2^2\\right]\n$$\nUsing $\\|(I - \\frac{1}{2}\\Delta t A)^{-1}\\|_2 \\le 1$ for dissipative $A$, and the fact that $p^n$ is $\\mathcal{F}_{t_n}$-measurable while $\\Delta Y_n$ is an increment independent of past values of $p^n$ (in the sense that $\\mathbb{E}[\\cdot|\\mathcal{F}_{t_n}]$ applies), the cross term $\\mathbb{E}[ \\langle \\cdot , \\cdot \\rangle \\Delta Y_n ]$ vanishes.\nLet $R = (I - \\frac{1}{2}\\Delta t A)^{-1}$.\n$p^{n+1} = R(I+\\frac{1}{2}\\Delta t A)p^n + R\\,\\operatorname{diag}(h)p^n \\Delta Y_n = C p^n + R\\,\\operatorname{diag}(h)p^n \\Delta Y_n$.\n$\\mathbb{E}[\\|p^{n+1}\\|_2^2 | \\mathcal{F}_{t_n}] = \\|C p^n\\|_2^2 + \\mathbb{E}[\\|R\\,\\operatorname{diag}(h)p^n \\Delta Y_n\\|_2^2 | \\mathcal{F}_{t_n}]$.\n$\\mathbb{E}[\\|p^{n+1}\\|_2^2 | \\mathcal{F}_{t_n}] = \\|C p^n\\|_2^2 + \\|R\\,\\operatorname{diag}(h)p^n\\|_2^2 \\mathbb{E}[(\\Delta Y_n)^2 | \\mathcal{F}_{t_n}]$.\nSince $\\|C\\|_2 \\le 1$, $\\|R\\|_2 \\le 1$, $\\mathbb{E}[(\\Delta Y_n)^2 | \\mathcal{F}_{t_n}] = \\Delta t + (\\text{drift term})^2 \\Delta t^2 \\approx \\Delta t$, and $\\|\\operatorname{diag}(h)\\|_2 \\le \\|h\\|_\\infty$, we get:\n$\\mathbb{E}[\\|p^{n+1}\\|_2^2 | \\mathcal{F}_{t_n}] \\le \\|p^n\\|_2^2 + \\|h\\|_\\infty^2 \\|p^n\\|_2^2 \\Delta t = (1 + \\|h\\|_\\infty^2 \\Delta t)\\|p^n\\|_2^2$.\nTaking expectation, $\\mathbb{E}[\\|p^{n+1}\\|_2^2] \\le (1 + C \\Delta t)\\mathbb{E}[\\|p^n\\|_2^2]$ with $C=\\|h\\|_\\infty^2$. This is exactly the condition for mean-square stability, and it holds without any CFL condition relating $\\Delta t$ and $\\Delta x$. The subsequent claim of boundedness over a finite time interval $[0, T]$ is a direct consequence of the discrete Gronwall lemma. This part is correct.\n\n- **Conclusion for A:** All statements in option A regarding the consistency, convergence order, and stability of the proposed scheme are correct and conform to the standard theory of numerical methods for linear SPDEs.\n\n**Verdict: Correct**\n\n**B. Use a fully explicit Euler–Maruyama time-stepping...**\n\nThe proposed scheme is:\n$$\np^{n+1} \\;=\\; \\big(I + \\Delta t\\,A\\big)\\,p^n \\;+\\; \\operatorname{diag}(h)\\,p^{n}\\,\\Delta Y_n\n$$\n- **Stability:** The scheme is fully explicit. The operator $A$ is a discretization of $\\mathcal{L}^*$, a second-order differential operator. The stability of the explicit Euler method for the deterministic part $p^{n+1} = (I + \\Delta t A)p^n$ depends on the spectral radius of $(I + \\Delta t A)$. The eigenvalues of $A$ are approximately $-\\frac{c_1}{\\Delta x^2}$ for the diffusion part. The diffusion term dominates and imposes a CFL condition of the form $\\Delta t \\le K\\,\\Delta x^2$. The claim of \"unconditional mean-square stability\" and stability \"independent of any relation between $\\Delta t$ and $\\Delta x$\" is therefore false.\n- **Convergence Order:** The Euler-Maruyama scheme has a strong temporal order of $\\mathcal{O}(\\Delta t^{1/2})$. The claim of strong temporal order $\\mathcal{O}(\\Delta t)$ is incorrect. Strong order $1$ schemes (like Milstein schemes) exist but the basic Euler-Maruyama scheme is not order $1$.\n\n**Verdict: Incorrect**\n\n**C. Use fully implicit time-stepping for both the deterministic and stochastic terms...**\n\nThe proposed scheme is:\n$$\n\\big(I - \\Delta t\\,A - \\operatorname{diag}(h)\\,\\Delta Y_n\\big)\\,p^{n+1} \\;=\\; p^n\n$$\n- **Scheme Structure and Stability:** This scheme requires the inversion of a random matrix $M_n = I - \\Delta t\\,A - \\operatorname{diag}(h)\\,\\Delta Y_n$ at each step. $\\Delta Y_n$ is a random variable, approximately Gaussian with variance $\\Delta t$. It can take positive or negative values. If for some $j$ and a realization of $\\Delta Y_n$, the value of $1 - \\Delta t\\,A_{jj} - h(x_j)\\,\\Delta Y_n$ is close to zero or negative, the matrix $M_n$ can become singular or ill-conditioned. The norm of the inverse, $\\|M_n^{-1}\\|$, is not bounded uniformly in $n$ and $\\omega$ (the random outcome). Therefore, the claim of \"unconditionally mean-square stable\" is highly suspect and very likely false.\n- **Positivity:** A scheme is positivity-preserving if $p^n \\ge 0$ implies $p^{n+1} \\ge 0$. This often requires the inverse of the scheme's matrix to be a positive matrix (element-wise non-negative). This typically means the matrix itself must be an M-matrix. The matrix $M_n$ will not be an M-matrix in general because the random term $-\\operatorname{diag}(h)\\,\\Delta Y_n$ can violate the M-matrix conditions. The claim is not justified.\n- **Convergence Order:** The option claims a strong temporal order of $\\mathcal{O}(1)$. A convergence order of $\\mathcal{O}(1)$ means the error does not decrease as $\\Delta t \\to 0$. This signifies a non-convergent scheme. This is a fatal flaw.\n\n**Verdict: Incorrect**\n\n**D. Use a spectral Galerkin projection ... and a first-order Strang splitting...**\n\n- **Splitting and Commutators:** The proposal is to split the SPDE evolution into a part for $\\mathcal{L}^*$ and a part for the noise term $h(x)\\,\\mathrm{d}Y_t$. For SDEs/SPDEs, the strong order of a splitting scheme depends on commutators of the operators. Let $A_0 p = \\mathcal{L}^*p$ and $A_1(p) = \\operatorname{diag}(h)p$. The commutator $[ \\mathcal{L}^*, \\operatorname{diag}(h)]$ is non-zero unless $h(x)$ is constant. Since the commutator is non-zero, a splitting scheme will not achieve strong order $\\mathcal{O}(\\Delta t)$ \"without Lévy area or commutator terms\". The strong order degrades to $\\mathcal{O}(\\Delta t^{1/2})$. The claim of strong order $\\mathcal{O}(\\Delta t)$ is false.\n- **Stability Condition:** The condition $\\Delta t = o(\\Delta x^4)$ is extremely restrictive. For a spectral method applied to a second-order parabolic operator like $\\mathcal{L}^*$, an explicit time-stepping stability condition would be $\\Delta t = \\mathcal{O}(1/K^2)$ where $K$ is the number of modes. Since $K \\sim 1/\\Delta x$, this gives $\\Delta t = \\mathcal{O}(\\Delta x^2)$. The proposed $\\Delta t = o(\\Delta x^4)$ condition is incorrect for this second-order SPDE.\n\n**Verdict: Incorrect**\n\n### Conclusion\n\nOnly option A correctly describes a standard, well-behaved numerical method for the Zakai equation and accurately states its properties concerning consistency, mean-square stability, and strong convergence. The other options make incorrect claims about stability (B, C), convergence order (B, C, D), or the structure of the numerical method (C, D).", "answer": "$$\\boxed{A}$$", "id": "2988907"}]}