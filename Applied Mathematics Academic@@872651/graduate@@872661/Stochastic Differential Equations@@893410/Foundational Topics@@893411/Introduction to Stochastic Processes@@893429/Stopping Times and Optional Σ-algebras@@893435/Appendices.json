{"hands_on_practices": [{"introduction": "The definition of a stopping time is central to stochastic calculus, as it formalizes the idea of a decision to stop that is based only on past information. This exercise challenges our intuition by exploring a scenario where a natural random time fails to be a stopping time with respect to one filtration but becomes one when the filtration is enlarged. By analyzing the properties of filtrations and independence, you will gain a deeper, more rigorous understanding of what it means for a time to be \"known\" by a process [@problem_id:2980195].", "problem": "Consider a complete probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$ that is the product of two probability spaces $(\\Omega_W,\\mathcal{F}^W,\\mathbb{P}_W)$ and $(\\Omega_T,\\mathcal{F}^T,\\mathbb{P}_T)$. On $(\\Omega_W,\\mathcal{F}^W,\\mathbb{P}_W)$, let $W=(W_t)_{t\\ge 0}$ be a standard Brownian motion, and let $(\\mathcal{G}_t)_{t\\ge 0}$ be its usual augmentation, i.e., $\\mathcal{G}_t$ is the completion and right-continuous modification of $\\sigma(W_s:s\\le t)$. On $(\\Omega_T,\\mathcal{F}^T,\\mathbb{P}_T)$, let $T:\\Omega_T\\to [0,\\infty)$ be an exponentially distributed random time with parameter $\\lambda0$, independent of $W$. We view all objects on the product space, with the product measure, so that $W$ depends only on the first coordinate and $T$ depends only on the second coordinate and $W$ and $T$ are independent.\n\nRecall the following definitions:\n- A random time $S:\\Omega\\to[0,\\infty]$ is a stopping time with respect to a filtration $(\\mathcal{F}_t)_{t\\ge 0}$ if for every $t\\ge 0$, the event $\\{S\\le t\\}$ is in $\\mathcal{F}_t$.\n- Two $\\sigma$-algebras $\\mathcal{A}$ and $\\mathcal{B}$ are independent if for every $A\\in \\mathcal{A}$ and $B\\in \\mathcal{B}$ we have $\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\mathbb{P}(B)$.\n- A process $W$ is a standard Brownian motion with respect to a filtration $(\\mathcal{F}_t)_{t\\ge 0}$ if $W$ is $(\\mathcal{F}_t)$-adapted, has continuous paths, $W_0=0$, and for all $0\\le st$, the increment $W_t-W_s$ is independent of $\\mathcal{F}_s$ and is Gaussian with mean $0$ and variance $t-s$.\n\nDefine an enlarged filtration by $\\mathcal{H}_t:=\\mathcal{G}_t\\vee \\sigma(T)$ for every $t\\ge 0$.\n\nSelect all statements that are true in this setting:\n\nA. $T$ is independent of the Brownian filtration $(\\mathcal{G}_t)_{t\\ge 0}$.\n\nB. $T$ is a stopping time with respect to $(\\mathcal{G}_t)_{t\\ge 0}$.\n\nC. $W$ is a standard Brownian motion with respect to the enlarged filtration $(\\mathcal{H}_t)_{t\\ge 0}$.\n\nD. For every fixed $t\\ge 0$, the $\\sigma$-algebras $\\sigma(T)$ and $\\mathcal{G}_t$ are independent.\n\nE. The random variable $W_T$ is independent of $\\sigma(T)$.\n\nF. $T$ is a stopping time with respect to the enlarged filtration $(\\mathcal{H}_t)_{t\\ge 0}$.", "solution": "The problem statement is scrutinized for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- A complete probability space $(\\Omega,\\mathcal{F},\\mathbb{P})$ is the product of two probability spaces $(\\Omega_W,\\mathcal{F}^W,\\mathbb{P}_W)$ and $(\\Omega_T,\\mathcal{F}^T,\\mathbb{P}_T)$.\n- $W=(W_t)_{t\\ge 0}$ is a standard Brownian motion on $(\\Omega_W,\\mathcal{F}^W,\\mathbb{P}_W)$.\n- $(\\mathcal{G}_t)_{t\\ge 0}$ is the usual augmentation of $\\sigma(W_s:s\\le t)$, i.e., the completion of the natural filtration of $W$ made right-continuous.\n- $T:\\Omega_T\\to [0,\\infty)$ is an exponentially distributed random time with parameter $\\lambda0$.\n- $W$ and $T$ are independent.\n- $W$ depends only on the first coordinate of the product space, and $T$ on the second.\n- The enlarged filtration is defined as $\\mathcal{H}_t:=\\mathcal{G}_t\\vee \\sigma(T)$ for every $t\\ge 0$.\n- Definitions for stopping time, independence of $\\sigma$-algebras, and standard Brownian motion with respect to a filtration are provided.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is formulated within the standard mathematical framework of modern probability theory and stochastic calculus. The concepts of product probability spaces, Brownian motion, filtrations, stopping times, and filtration enlargement are all central to this field. The setup is a canonical example used to study the properties of processes under a change of filtration. The problem is mathematically and scientifically sound.\n- **Well-Posed:** The problem provides all necessary definitions and specifies the mathematical objects and their relationships with precision. The questions posed are unambiguous and have definite answers (true or false) that can be derived from the given premises and standard theorems.\n- **Objective:** The language is formal, mathematical, and free of any subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is a well-posed and standard problem in stochastic process theory. I will proceed to solve it by evaluating each statement.\n\n### Analysis of the Options\n\nThe fundamental setup is that we have a product space $\\Omega = \\Omega_W \\times \\Omega_T$. A random variable measurable with respect to the history of $W$ up to time $t$ depends only on the coordinate $\\omega_W \\in \\Omega_W$. The random time $T$ depends only on the coordinate $\\omega_T \\in \\Omega_T$. The independence of $W$ and $T$ is formalized by the product measure $\\mathbb{P} = \\mathbb{P}_W \\times \\mathbb{P}_T$.\n\nThe filtration $\\mathcal{G}_t$ contains information about the path of the Brownian motion $(W_s)_{s \\le t}$. Events in $\\mathcal{G}_t$ are, up to null sets, of the form $A_W \\times \\Omega_T$ for some $A_W \\in \\mathcal{F}^W$, where $\\mathcal{F}^W$ is the filtration for $W$ on $\\Omega_W$. The $\\sigma$-algebra $\\sigma(T)$ contains information about the random time $T$. Events in $\\sigma(T)$ are of the form $\\Omega_W \\times B_T$ for some event $B_T$ concerning $T$. The enlarged filtration is $\\mathcal{H}_t = \\sigma(\\mathcal{G}_t \\cup \\sigma(T))$.\n\n**A. $T$ is independent of the Brownian filtration $(\\mathcal{G}_t)_{t\\ge 0}$.**\n\nThis statement is typically interpreted as the random variable $T$ being independent of the $\\sigma$-algebra $\\mathcal{G}_\\infty = \\sigma(\\cup_{t \\ge 0} \\mathcal{G}_t)$. Let us prove this stronger statement, which implies independence from $\\mathcal{G}_t$ for any finite $t$.\nAn event $A \\in \\mathcal{G}_\\infty$ is determined by the entire path of the Brownian motion $W$. Due to the product space structure, $A$ is of the form $A_W \\times \\Omega_T$ (up to a $\\mathbb{P}$-null set), where $A_W \\in \\mathcal{F}^W_\\infty$. An event $B \\in \\sigma(T)$ is of the form $\\Omega_W \\times B_T$, where $B_T$ is a Borel subset of $[0, \\infty)$ in the pre-image of $T$.\nThe intersection is $A \\cap B = (A_W \\times \\Omega_T) \\cap (\\Omega_W \\times B_T) = A_W \\times B_T$.\nUsing the definition of the product measure:\n$$ \\mathbb{P}(A \\cap B) = \\mathbb{P}(A_W \\times B_T) = \\mathbb{P}_W(A_W) \\mathbb{P}_T(B_T) $$\nAlso, we have:\n$$ \\mathbb{P}(A) = \\mathbb{P}(A_W \\times \\Omega_T) = \\mathbb{P}_W(A_W) \\mathbb{P}_T(\\Omega_T) = \\mathbb{P}_W(A_W) $$\n$$ \\mathbb{P}(B) = \\mathbb{P}(\\Omega_W \\times B_T) = \\mathbb{P}_W(\\Omega_W) \\mathbb{P}_T(B_T) = \\mathbb{P}_T(B_T) $$\nThus, $\\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B)$. This holds for any $A \\in \\mathcal{G}_\\infty$ and $B \\in \\sigma(T)$. This proves that $\\sigma(T)$ and $\\mathcal{G}_\\infty$ are independent. Therefore, $T$ is independent of the filtration $(\\mathcal{G}_t)_{t\\ge 0}$.\n\nVerdict: **Correct**.\n\n**B. $T$ is a stopping time with respect to $(\\mathcal{G}_t)_{t\\ge 0}$.**\n\nFor $T$ to be a $(\\mathcal{G}_t)$-stopping time, the event $\\{T \\le t\\}$ must belong to the $\\sigma$-algebra $\\mathcal{G}_t$ for every $t \\ge 0$.\nThe event $E_t := \\{T \\le t\\}$ is, by definition, an element of $\\sigma(T)$.\nFrom the analysis of option D (which is a more specific version of A), $\\sigma(T)$ and $\\mathcal{G}_t$ are independent for any $t \\ge 0$.\nIf an event $A$ belongs to two independent $\\sigma$-algebras, $\\mathcal{A}$ and $\\mathcal{B}$, i.e., $A \\in \\mathcal{A} \\cap \\mathcal{B}$, then $\\mathbb{P}(A) = \\mathbb{P}(A \\cap A) = \\mathbb{P}(A)\\mathbb{P}(A) = (\\mathbb{P}(A))^2$. This implies $\\mathbb{P}(A) = 0$ or $\\mathbb{P}(A) = 1$.\nIf $T$ were a $(\\mathcal{G}_t)$-stopping time, then for any $t \\ge 0$, the event $E_t = \\{T \\le t\\}$ would be in $\\mathcal{G}_t$. Since $E_t$ is also in $\\sigma(T)$, it would have to have probability $0$ or $1$.\nHowever, the probability of this event is given by the cumulative distribution function of the exponential distribution:\n$$ \\mathbb{P}(T \\le t) = 1 - e^{-\\lambda t} $$\nFor any $t \\in (0, \\infty)$ and $\\lambda  0$, we have $0  1 - e^{-\\lambda t}  1$.\nSince the probability is not $0$ or $1$, the event $\\{T \\le t\\}$ cannot be in $\\mathcal{G}_t$ for $t \\in (0, \\infty)$. Therefore, $T$ is not a $(\\mathcal{G}_t)$-stopping time.\n\nVerdict: **Incorrect**.\n\n**C. $W$ is a standard Brownian motion with respect to the enlarged filtration $(\\mathcal{H}_t)_{t\\ge 0}$.**\n\nWe check the three defining properties of a standard Brownian motion with respect to the filtration $\\mathcal{H}_t = \\mathcal{G}_t \\vee \\sigma(T)$.\n1.  **Adaptedness:** $W$ is adapted to $(\\mathcal{G}_t)_{t\\ge 0}$, meaning $W_t$ is $\\mathcal{G}_t$-measurable for all $t \\ge 0$. Since $\\mathcal{G}_t \\subseteq \\mathcal{H}_t$, $W_t$ is also $\\mathcal{H}_t$-measurable. This condition holds.\n2.  **Initial value and path continuity:** $W_0=0$ and $W$ having continuous paths are intrinsic properties of the process $W$ and are not affected by the choice of filtration. This condition holds.\n3.  **Independent increments:** For $0 \\le s  t$, the increment $W_t - W_s$ must be independent of $\\mathcal{H}_s$ and be a Gaussian random variable with mean $0$ and variance $t-s$.\nThe distributional property is intrinsic to $W$ and remains unchanged. The critical part is checking independence from $\\mathcal{H}_s = \\sigma(\\mathcal{G}_s, \\sigma(T))$.\nLet $X = W_t - W_s$. Let $\\mathcal{A} = \\mathcal{G}_s$ and $\\mathcal{B} = \\sigma(T)$. We established in options A and D that $\\mathcal{A}$ and $\\mathcal{B}$ are independent.\nFrom the properties of standard Brownian motion, the increment $X$ is independent of the past filtration $\\mathcal{A} = \\mathcal{G}_s$.\nBy the problem construction, the entire process $W$ is independent of the random variable $T$. This implies that any function of the $W$ process, including the increment $X=W_t-W_s$, is independent of any function of $T$, and thus is independent of the $\\sigma$-algebra $\\mathcal{B} = \\sigma(T)$.\nWe use a standard probability theory result: If a random variable $X$ is independent of two $\\sigma$-algebras $\\mathcal{A}$ and $\\mathcal{B}$, and if $\\mathcal{A}$ and $\\mathcal{B}$ are themselves independent, then $X$ is independent of the generated $\\sigma$-algebra $\\sigma(\\mathcal{A}, \\mathcal{B})$.\nAll premises of this result are satisfied here. Therefore, $W_t - W_s$ is independent of $\\mathcal{H}_s = \\sigma(\\mathcal{G}_s, \\sigma(T))$.\nAll conditions are met.\n\nVerdict: **Correct**.\n\n**D. For every fixed $t\\ge 0$, the $\\sigma$-algebras $\\sigma(T)$ and $\\mathcal{G}_t$ are independent.**\n\nThis is a specific instance of the reasoning used for option A. Let $A \\in \\mathcal{G}_t$ and $B \\in \\sigma(T)$. From the product space structure, up to null sets, $A = A_W \\times \\Omega_T$ for some $A_W$ in the filtration of $W$ on $\\Omega_W$, and $B = \\Omega_W \\times B_T$ for some $B_T$ in the filtration of $T$ on $\\Omega_T$.\nThen $A \\cap B = A_W \\times B_T$. By definition of the product measure:\n$$ \\mathbb{P}(A \\cap B) = \\mathbb{P}_W(A_W) \\mathbb{P}_T(B_T) $$\nAnd since $\\mathbb{P}(A) = \\mathbb{P}_W(A_W)$ and $\\mathbb{P}(B) = \\mathbb{P}_T(B_T)$, we have $\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)$. This is the definition of independence. The inclusion of null sets in the standard augmentation does not alter this conclusion.\n\nVerdict: **Correct**.\n\n**E. The random variable $W_T$ is independent of $\\sigma(T)$.**\n\nThis statement is equivalent to saying that the random variables $W_T$ and $T$ are independent.\nIntuitively, this is false: the distribution of $W_t$ is $N(0,t)$, which depends on $t$. So, conditional on $T=t$, the distribution of $W_T$ is $N(0,t)$. Since this conditional distribution depends on the value of $T$, the random variables cannot be independent.\nTo prove this formally, we can compute the joint characteristic function $\\Phi_{W_T, T}(u, v) = \\mathbb{E}[e^{i u W_T + i v T}]$ and check if it factorizes as $\\Phi_{W_T}(u) \\Phi_T(v)$.\nBy conditioning on $T=t$ (and using the independence of the process $W$ from the variable $T$):\n$$ \\mathbb{E}[e^{i u W_T + i v T}] = \\mathbb{E}[\\mathbb{E}[e^{i u W_T + i v T} | T]] = \\mathbb{E}[e^{i v T} \\mathbb{E}[e^{i u W_t}]|_{t=T}] $$\nSince $W_t \\sim N(0, t)$, its characteristic function is $\\mathbb{E}[e^{i u W_t}] = e^{-u^2 t / 2}$.\n$$ \\Phi_{W_T, T}(u, v) = \\mathbb{E}[e^{i v T} e^{-u^2 T / 2}] = \\mathbb{E}[e^{(iv - u^2/2)T}] $$\nThis is the moment-generating function of $T$ evaluated at $s = iv - u^2/2$. For $T \\sim \\text{Exp}(\\lambda)$, $M_T(s) = \\mathbb{E}[e^{sT}] = \\lambda/(\\lambda-s)$.\n$$ \\Phi_{W_T, T}(u, v) = \\frac{\\lambda}{\\lambda - (iv - u^2/2)} = \\frac{\\lambda}{\\lambda + u^2/2 - iv} $$\nThe individual characteristic functions are:\n$$ \\Phi_{W_T}(u) = \\Phi_{W_T, T}(u, 0) = \\frac{\\lambda}{\\lambda + u^2/2} $$\n$$ \\Phi_T(v) = \\Phi_{W_T, T}(0, v) = \\frac{\\lambda}{\\lambda - iv} $$\nThe product is:\n$$ \\Phi_{W_T}(u)\\Phi_T(v) = \\left(\\frac{\\lambda}{\\lambda + u^2/2}\\right) \\left(\\frac{\\lambda}{\\lambda - iv}\\right) = \\frac{\\lambda^2}{(\\lambda + u^2/2)(\\lambda - iv)} $$\nClearly, $\\Phi_{W_T, T}(u, v) \\ne \\Phi_{W_T}(u)\\Phi_T(v)$. Therefore, $W_T$ and $T$ are not independent.\n\nVerdict: **Incorrect**.\n\n**F. $T$ is a stopping time with respect to the enlarged filtration $(\\mathcal{H}_t)_{t\\ge 0}$.**\n\nFor $T$ to be a $(\\mathcal{H}_t)$-stopping time, the event $\\{T \\le t\\}$ must be in $\\mathcal{H}_t$ for every $t \\ge 0$.\nThe enlarged filtration is defined as $\\mathcal{H}_t = \\mathcal{G}_t \\vee \\sigma(T) = \\sigma(\\mathcal{G}_t \\cup \\sigma(T))$.\nBy definition of the $\\sigma$-algebra generated by a random variable, the event $\\{T \\le t\\}$ is in $\\sigma(T)$ for any $t \\ge 0$.\nBy the definition of $\\mathcal{H}_t$, any set in $\\sigma(T)$ is also in $\\mathcal{H}_t$. That is, $\\sigma(T) \\subseteq \\mathcal{H}_t$.\nTherefore, for any $t \\ge 0$, we have $\\{T \\le t\\} \\in \\sigma(T) \\subseteq \\mathcal{H}_t$.\nThe condition for a stopping time is satisfied.\n\nVerdict: **Correct**.", "answer": "$$\\boxed{ACDF}$$", "id": "2980195"}, {"introduction": "The Optional Sampling Theorem is a cornerstone of martingale theory, but its most basic form applies only to bounded stopping times, a significant restriction. This practice demonstrates a crucial and widely used technique to handle unbounded stopping times, such as the first exit time of a Brownian motion from an interval. By employing a truncation argument and the Dominated Convergence Theorem, you will learn how to extend the power of martingale methods to a much broader class of problems [@problem_id:2998513].", "problem": "Let $\\{B_{t}\\}_{t \\ge 0}$ be a standard Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\ge 0},\\mathbb{P})$ satisfying the usual conditions, and assume $B_{0}=x$ for some $x \\in \\mathbb{R}$. For fixed real numbers $ab$ with $x \\in (a,b)$, define the first exit time from the open interval $(a,b)$ by\n$$\n\\tau \\equiv \\inf\\{t \\ge 0 : B_{t} \\notin (a,b)\\}.\n$$\nIt is known from the fundamental definitions that $\\tau$ is a stopping time with respect to the natural filtration of $\\{B_{t}\\}_{t \\ge 0}$. Recall that the optional $\\sigma$-algebra $\\mathcal{O}$ on $\\Omega \\times \\mathbb{R}_{+}$ is generated by all right-continuous with left limits (càdlàg) adapted processes, and that for any stopping time $\\sigma$, the stopped process $B^{\\sigma}_{t} \\equiv B_{t \\wedge \\sigma}$ is optional and, when $\\{B_{t}\\}_{t \\ge 0}$ is a martingale, $\\{B^{\\sigma}_{t}\\}_{t \\ge 0}$ remains a martingale.\n\nUsing only the martingale property of $\\{B_{t}\\}_{t \\ge 0}$, the fact that $\\tau$ is a stopping time, and the Optional Sampling Theorem (also known as the Optional Stopping Theorem) for bounded stopping times together with a truncation argument, compute the quantity\n$$\n\\mathbb{E}[B_{\\tau}]\n$$\nin closed form as a function of $a$, $b$, and $x$. Your final answer must be a single analytic expression. Do not provide an inequality or an equation. No numerical approximation is required.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- The process $\\{B_{t}\\}_{t \\ge 0}$ is a standard Brownian motion on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_{t}\\}_{t \\ge 0},\\mathbb{P})$ satisfying the usual conditions.\n- The initial condition is $B_{0}=x$ for a given $x \\in \\mathbb{R}$.\n- Two real numbers $a$ and $b$ are fixed such that $ab$ and $x \\in (a,b)$.\n- The first exit time from the interval $(a,b)$ is defined as $\\tau \\equiv \\inf\\{t \\ge 0 : B_{t} \\notin (a,b)\\}$.\n- $\\tau$ is a stopping time with respect to the filtration $\\{\\mathcal{F}_{t}\\}_{t \\ge 0}$.\n- The process $\\{B_{t}\\}_{t \\ge 0}$ is a martingale.\n- The computation must use the martingale property, the fact that $\\tau$ is a stopping time, the Optional Sampling Theorem for bounded stopping times, and a truncation argument.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a standard exercise in the theory of stochastic processes.\n- **Scientifically Grounded:** The concepts of Brownian motion, martingales, stopping times, and the Optional Sampling Theorem are fundamental pillars of modern probability theory and stochastic calculus. The problem is firmly based on these established principles.\n- **Well-Posed:** The problem asks for a specific, computable quantity, $\\mathbb{E}[B_{\\tau}]$, for which a unique solution exists and is well-defined.\n- **Objective:** The problem is stated in precise, unambiguous mathematical language.\n- **Completeness and Consistency:** The problem provides all necessary information. The premise that $\\{B_{t}\\}_{t \\ge 0}$ with $B_0=x$ is a martingale is consistent, as for $s \\le t$, $\\mathbb{E}[B_t | \\mathcal{F}_s] = \\mathbb{E}[B_t - B_s + B_s | \\mathcal{F}_s] = \\mathbb{E}[B_t - B_s] + B_s = 0 + B_s = B_s$.\n\n**Verdict:** The problem is valid.\n\n**Step 3: Proceed to Solution**\nThe objective is to compute the expectation $\\mathbb{E}[B_{\\tau}]$, where $\\tau$ is the first time the Brownian motion $\\{B_{t}\\}_{t \\ge 0}$ exits the interval $(a,b)$, given it starts at $B_{0}=x \\in (a,b)$. We are given that $\\{B_{t}\\}_{t \\ge 0}$ is a martingale.\n\nThe Optional Sampling Theorem states that for a martingale $\\{M_t\\}_{t \\ge 0}$ and a stopping time $\\sigma$, under certain conditions, $\\mathbb{E}[M_{\\sigma}] = \\mathbb{E}[M_0]$. A primary condition for the theorem is that the stopping time $\\sigma$ is bounded. However, the first exit time $\\tau$ is not, in general, a bounded random variable. Therefore, we cannot apply the theorem directly to $\\tau$.\n\nAs stipulated by the problem, we employ a truncation argument. We define a sequence of stopping times $\\{\\tau_n\\}_{n \\in \\mathbb{N}}$ by truncating $\\tau$ at a deterministic time $n$:\n$$\n\\tau_n \\equiv \\tau \\wedge n = \\min(\\tau, n)\n$$\nFor any fixed $n \\in \\mathbb{N}$, the stopping time $\\tau_n$ is bounded, since $0 \\le \\tau_n \\le n$. We can therefore apply the Optional Sampling Theorem for bounded stopping times to the martingale $\\{B_t\\}_{t \\ge 0}$ and the stopping time $\\tau_n$. This yields:\n$$\n\\mathbb{E}[B_{\\tau_n}] = \\mathbb{E}[B_0]\n$$\nGiven the initial condition $B_0 = x$, we have:\n$$\n\\mathbb{E}[B_{\\tau_n}] = x \\quad \\text{for all } n \\in \\mathbb{N}\n$$\nOur goal is to determine $\\mathbb{E}[B_{\\tau}]$ by taking the limit as $n \\to \\infty$. To do this, we need to justify the interchange of the limit and expectation operators. We will use the Lebesgue Dominated Convergence Theorem. This theorem requires two conditions to be met for the sequence of random variables $\\{B_{\\tau_n}\\}_{n \\in \\mathbb{N}}$:\n1.  Almost sure convergence of the sequence to a limit random variable.\n2.  Domination of the sequence by an integrable random variable.\n\nFirst, we verify the almost sure convergence. For a one-dimensional Brownian motion, the probability of it ever exiting a finite interval is $1$. Thus, the stopping time $\\tau$ is almost surely finite, i.e., $\\mathbb{P}(\\tau  \\infty) = 1$. This implies that as $n \\to \\infty$, the sequence of truncated times $\\tau_n = \\tau \\wedge n$ converges to $\\tau$ almost surely. Since the sample paths of a Brownian motion are continuous almost surely, the sequence of random variables $B_{\\tau_n}$ converges to $B_\\tau$ almost surely:\n$$\n\\lim_{n \\to \\infty} B_{\\tau_n} = B_{\\tau} \\quad \\text{(a.s.)}\n$$\nSecond, we must find an integrable random variable that dominates the sequence $\\{|B_{\\tau_n}|\\}_{n \\in \\mathbb{N}}$. Let us examine the value of $B_{\\tau_n}$ for any given sample path $\\omega \\in \\Omega$.\nThe time is $\\tau_n(\\omega) = \\min(\\tau(\\omega), n)$.\n- If $\\tau(\\omega) \\le n$, then $\\tau_n(\\omega) = \\tau(\\omega)$. By the definition of $\\tau$ and the continuity of the paths, $B_{\\tau(\\omega)}(\\omega)$ must equal either $a$ or $b$. Hence, $B_{\\tau_n}(\\omega) \\in \\{a, b\\}$.\n- If $\\tau(\\omega)  n$, then $\\tau_n(\\omega) = n$. Since $n  \\tau(\\omega)$, the process has not yet exited the interval $(a,b)$ at time $n$. Therefore, $B_n(\\omega) \\in (a,b)$, which means $B_{\\tau_n}(\\omega) \\in (a,b)$.\n\nIn both cases, for any sample path $\\omega$ and any $n \\in \\mathbb{N}$, the value of $B_{\\tau_n}(\\omega)$ lies within the closed interval $[a,b]$. This implies that the random variable $B_{\\tau_n}$ is uniformly bounded in magnitude:\n$$\n|B_{\\tau_n}| \\le \\max(|a|, |b|)\n$$\nLet $C = \\max(|a|, |b|)$. This is a finite constant. The constant random variable $Y \\equiv C$ is integrable, since its expectation is $\\mathbb{E}[Y] = C  \\infty$. As $|B_{\\tau_n}| \\le Y$ for all $n$, the sequence $\\{B_{\\tau_n}\\}_{n \\in \\mathbb{N}}$ is dominated by an integrable random variable.\n\nWith both conditions of the Dominated Convergence Theorem satisfied, we are justified in interchanging the limit and the expectation:\n$$\n\\lim_{n \\to \\infty} \\mathbb{E}[B_{\\tau_n}] = \\mathbb{E}\\left[\\lim_{n \\to \\infty} B_{\\tau_n}\\right]\n$$\nSubstituting our previous findings into this equality:\n$$\n\\mathbb{E}[B_{\\tau}] = \\mathbb{E}\\left[\\lim_{n \\to \\infty} B_{\\tau_n}\\right] = \\lim_{n \\to \\infty} \\mathbb{E}[B_{\\tau_n}]\n$$\nSince we established that $\\mathbb{E}[B_{\\tau_n}] = x$ for all $n$, the limit is straightforward:\n$$\n\\mathbb{E}[B_{\\tau}] = \\lim_{n \\to \\infty} x = x\n$$\nThus, the expected value of the Brownian motion at the first exit time from the interval $(a,b)$ is simply its starting value, $x$.", "answer": "$$\\boxed{x}$$", "id": "2998513"}, {"introduction": "While martingales are foundational, many processes encountered in applications, such as counting processes, are submartingales. This exercise introduces the powerful Doob-Meyer decomposition, which splits a submartingale into a martingale and a predictable, increasing process called a compensator. This hands-on calculation for a Poisson process shows how the decomposition allows us to isolate the martingale component and apply powerful tools like the Optional Sampling Theorem to analyze processes that are not martingales themselves [@problem_id:2998510].", "problem": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t \\geq 0},\\mathbb{P})$ be a filtered probability space satisfying the usual conditions and carrying a standard rate-$\\lambda$ Poisson process $N=(N_{t})_{t \\geq 0}$ with $\\lambda0$, adapted to its natural, right-continuous, and complete filtration $(\\mathcal{F}_{t})_{t \\geq 0}$. Consider the process $X=(X_{t})_{t \\geq 0}$ defined by $X_{t}=N_{t}$, which is a submartingale. Let $T0$ be fixed and let the stopping time $\\tau$ be given by\n$$\n\\tau \\,=\\, \\inf\\{t \\geq 0 : N_{t} \\geq 1\\} \\,\\wedge\\, T,\n$$\nthat is, the first jump time of $N$ truncated at the deterministic horizon $T$. Starting explicitly from the definitions of a submartingale, stopping time, and the predictable $\\sigma$-algebra, use the canonical decomposition of a submartingale into a sum of a martingale and a predictable, integrable, finite-variation process to derive a closed-form expression for the expectation $\\mathbb{E}[X_{\\tau}]$ in terms of $\\lambda$ and $T$. In your derivation, justify the use of the Optional Sampling Theorem (OST) for bounded stopping times and explain the role of predictability in the compensator. Your final answer must be a single analytic expression involving only $\\lambda$ and $T$ (no unevaluated integrals). No numerical evaluation is required.", "solution": "The problem is to find the expectation $\\mathbb{E}[X_{\\tau}]$, where $X_t = N_t$ is a rate-$\\lambda$ Poisson process, and $\\tau = \\inf\\{t \\geq 0 : N_{t} \\geq 1\\} \\wedge T$. The derivation must be based on the canonical decomposition of the submartingale $X_t$.\n\nFirst, we validate the problem statement.\n### Step 1: Extract Givens\n- A filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t \\geq 0},\\mathbb{P})$ with usual conditions.\n- A standard rate-$\\lambda$ Poisson process $N=(N_{t})_{t \\geq 0}$ with $\\lambda0$, adapted to its natural, right-continuous, and complete filtration $(\\mathcal{F}_{t})_{t \\geq 0}$.\n- The process $X=(X_{t})_{t \\geq 0}$ is defined by $X_{t}=N_{t}$. It is stated to be a submartingale.\n- A fixed time horizon $T0$.\n- A stopping time $\\tau \\,=\\, \\inf\\{t \\geq 0 : N_{t} \\geq 1\\} \\,\\wedge\\, T$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem uses standard, well-established concepts from the theory of stochastic processes, including Poisson processes, filtrations, stopping times, submartingales, the Doob-Meyer decomposition, and the Optional Sampling Theorem. The premise that a Poisson process is a submartingale is correct. For $st$, $\\mathbb{E}[N_t | \\mathcal{F}_s] = N_s + \\mathbb{E}[N_t-N_s|\\mathcal{F}_s] = N_s + \\mathbb{E}[N_{t-s}] = N_s + \\lambda(t-s) \\ge N_s$.\n- **Well-Posed:** The problem is clearly stated and asks for a specific quantity, $\\mathbb{E}[X_{\\tau}]$, under well-defined conditions. The stopping time $\\tau$ is bounded ($0 \\le \\tau \\le T$), which guarantees the existence of the expectation and simplifies the application of theoretical results.\n- **Objective:** The language is formal and mathematical, free of ambiguity or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a standard exercise in stochastic calculus that is scientifically sound, well-posed, and objective. We proceed with the solution as required.\n\nThe solution will be derived by following these steps:\n1.  Apply the Doob-Meyer (canonical) decomposition to the submartingale $X_t = N_t$.\n2.  Use the decomposition to express $\\mathbb{E}[X_{\\tau}]$.\n3.  Apply the Optional Sampling Theorem to the martingale component.\n4.  Calculate the expectation of the predictable component at time $\\tau$.\n5.  Combine the results to obtain the final expression.\n\nThe process $X_t = N_t$ is a càdlàg submartingale with respect to its natural filtration. The Doob-Meyer decomposition theorem guarantees its unique decomposition into a sum of a martingale and a predictable, increasing process:\n$$\nX_t = M_t + A_t\n$$\nwhere $M$ is a martingale and $A$ is a predictable, non-decreasing, integrable process with $A_0=0$. For a standard Poisson process $N_t$ with rate $\\lambda  0$, the process $M_t = N_t - \\lambda t$ is a martingale. This can be verified by checking the martingale property for $st$:\n$$\n\\mathbb{E}[M_t | \\mathcal{F}_s] = \\mathbb{E}[N_t - \\lambda t | \\mathcal{F}_s] = \\mathbb{E}[N_t - N_s + N_s - \\lambda t | \\mathcal{F}_s]\n$$\nSince $N_s$ is $\\mathcal{F}_s$-measurable and the increment $N_t - N_s$ is independent of $\\mathcal{F}_s$:\n$$\n\\mathbb{E}[M_t | \\mathcal{F}_s] = \\mathbb{E}[N_t - N_s] + N_s - \\lambda t = \\lambda(t-s) + N_s - \\lambda t = N_s - \\lambda s = M_s\n$$\nThus, the canonical decomposition of $X_t = N_t$ is:\n$$\nN_t = (N_t - \\lambda t) + \\lambda t\n$$\nHere, the martingale is $M_t = N_t - \\lambda t$ and the predictable increasing process, known as the compensator, is $A_t = \\lambda t$. The role of predictability is crucial for the uniqueness of this decomposition. A process is predictable if it is measurable with respect to the predictable $\\sigma$-algebra, which is generated by all left-continuous adapted processes. The process $A_t = \\lambda t$ is deterministic and its sample paths are continuous functions of time. Any continuous adapted process is predictable, so $A_t$ satisfies this condition.\n\nWe want to calculate $\\mathbb{E}[X_{\\tau}] = \\mathbb{E}[N_{\\tau}]$. Using the decomposition at the stopping time $\\tau$:\n$$\nN_{\\tau} = M_{\\tau} + A_{\\tau}\n$$\nBy the linearity of expectation, we have:\n$$\n\\mathbb{E}[N_{\\tau}] = \\mathbb{E}[M_{\\tau}] + \\mathbb{E}[A_{\\tau}]\n$$\nWe evaluate each term separately.\n\nFor the martingale term $\\mathbb{E}[M_{\\tau}]$, we apply the Optional Sampling Theorem (OST). The stopping time is $\\tau = \\inf\\{t \\geq 0: N_t \\geq 1\\} \\wedge T$. Since $T$ is a positive constant, we have $0 \\le \\tau(\\omega) \\le T$ for all $\\omega \\in \\Omega$. Therefore, $\\tau$ is a bounded stopping time. The version of the OST for bounded stopping times states that if $M_t$ is a right-continuous martingale and $\\tau$ is a bounded stopping time, then $\\mathbb{E}[M_{\\tau}] = \\mathbb{E}[M_0]$. The process $M_t=N_t-\\lambda t$ is right-continuous because $N_t$ is a càdlàg process and the function $t \\mapsto \\lambda t$ is continuous. The conditions are met, so we can apply the theorem.\nThe value of the martingale at time $t=0$ is:\n$$\nM_0 = N_0 - \\lambda \\cdot 0\n$$\nFor a standard Poisson process, $N_0=0$. Thus, $M_0 = 0$.\nApplying the OST, we get:\n$$\n\\mathbb{E}[M_{\\tau}] = \\mathbb{E}[M_0] = 0\n$$\n\nNext, we evaluate the term $\\mathbb{E}[A_{\\tau}]$. The compensator is $A_t = \\lambda t$. At the stopping time $\\tau$, this becomes $A_{\\tau} = \\lambda \\tau$. We need to compute its expectation:\n$$\n\\mathbb{E}[A_{\\tau}] = \\mathbb{E}[\\lambda \\tau] = \\lambda \\mathbb{E}[\\tau]\n$$\nTo find $\\mathbb{E}[\\tau]$, we analyze the stopping time $\\tau = T_1 \\wedge T$, where $T_1 = \\inf\\{t \\geq 0 : N_t \\geq 1\\}$ is the time of the first arrival of the Poisson process. The random variable $T_1$ follows an exponential distribution with rate $\\lambda$, so $T_1 \\sim \\text{Exp}(\\lambda)$. The survival function of $T_1$ is $\\mathbb{P}(T_1  t) = \\exp(-\\lambda t)$ for $t \\ge 0$.\n\nFor any non-negative random variable $Y$, its expectation can be computed as $\\mathbb{E}[Y] = \\int_{0}^{\\infty} \\mathbb{P}(Y  t) dt$. Applying this to $\\tau$:\n$$\n\\mathbb{E}[\\tau] = \\int_{0}^{\\infty} \\mathbb{P}(\\tau  t) dt\n$$\nThe event $\\{\\tau  t\\}$ is equivalent to $\\{T_1 \\wedge T  t\\}$. We consider two cases for $t$:\n1.  If $t \\ge T$, then $\\mathbb{P}(\\tau  t) = 0$ because $\\tau \\le T$.\n2.  If $0 \\le t  T$, the condition $T_1 \\wedge T  t$ is equivalent to $T_1  t$ (since $T  t$ is already true). Thus, for $0 \\le t  T$, $\\mathbb{P}(\\tau  t) = \\mathbb{P}(T_1  t) = \\exp(-\\lambda t)$.\n\nNow, we can compute the integral for $\\mathbb{E}[\\tau]$:\n$$\n\\mathbb{E}[\\tau] = \\int_0^T \\mathbb{P}(\\tau  t) dt + \\int_T^\\infty \\mathbb{P}(\\tau  t) dt = \\int_0^T \\exp(-\\lambda t) dt + 0\n$$\nEvaluating the integral:\n$$\n\\mathbb{E}[\\tau] = \\left[ -\\frac{1}{\\lambda} \\exp(-\\lambda t) \\right]_0^T = -\\frac{1}{\\lambda} (\\exp(-\\lambda T) - \\exp(-\\lambda \\cdot 0)) = -\\frac{1}{\\lambda} (\\exp(-\\lambda T) - 1) = \\frac{1 - \\exp(-\\lambda T)}{\\lambda}\n$$\nNow we can find $\\mathbb{E}[A_{\\tau}]$:\n$$\n\\mathbb{E}[A_{\\tau}] = \\lambda \\mathbb{E}[\\tau] = \\lambda \\left( \\frac{1 - \\exp(-\\lambda T)}{\\lambda} \\right) = 1 - \\exp(-\\lambda T)\n$$\n\nFinally, we combine the two parts to find $\\mathbb{E}[X_{\\tau}]$:\n$$\n\\mathbb{E}[X_{\\tau}] = \\mathbb{E}[N_{\\tau}] = \\mathbb{E}[M_{\\tau}] + \\mathbb{E}[A_{\\tau}] = 0 + (1 - \\exp(-\\lambda T))\n$$\nTherefore, the expected value is $1 - \\exp(-\\lambda T)$.", "answer": "$$\\boxed{1 - \\exp(-\\lambda T)}$$", "id": "2998510"}]}