## Introduction
The study of [stochastic processes](@entry_id:141566) often boils down to a fundamental question: given a particle moving randomly within a specified domain, when will it leave, and where will it emerge? This question of "first passage" or "[exit time](@entry_id:190603)" is central to the theory of stochastic differential equations (SDEs), forming a critical link between the random paths of a diffusion process and the deterministic world of partial differential equations (PDEs). Understanding these exit phenomena is not just a theoretical exercise; it provides the mathematical tools to quantify [transition rates](@entry_id:161581) in chemical reactions, extinction risks in populations, and failure times in engineered systems. This article addresses the core challenge of characterizing these exit events, providing a comprehensive framework for their analysis.

Over the next three chapters, we will build this framework from the ground up. In **Principles and Mechanisms**, we will establish the foundational probabilistic concepts, such as [stopping times](@entry_id:261799) and the strong Markov property, and show how they lead to powerful analytical tools like the Feynman-Kac formula. We will then explore the vast reach of this theory in **Applications and Interdisciplinary Connections**, demonstrating how [exit time](@entry_id:190603) problems are formulated and solved in fields ranging from [molecular dynamics](@entry_id:147283) to control theory. Finally, the **Hands-On Practices** section will provide you with the opportunity to apply these principles to concrete problems, solidifying your understanding by solving for hitting probabilities and mean [exit times](@entry_id:193122) in canonical settings.

## Principles and Mechanisms

The study of exit phenomena forms a cornerstone of the theory of [stochastic differential equations](@entry_id:146618), connecting the probabilistic behavior of [diffusion processes](@entry_id:170696) to the analytical framework of [partial differential equations](@entry_id:143134). This chapter elucidates the fundamental principles and mechanisms governing the time it takes for a process to leave a given domain, and the distribution of the location where it first exits. We will begin with the core probabilistic concepts, explore their deep connections to elliptic PDEs, develop tools for calculation, and conclude with advanced perspectives on regularity and asymptotic behavior.

### Foundational Concepts: Exit Times and the Strong Markov Property

Let $X = (X_t)_{t \ge 0}$ be a time-homogeneous [diffusion process](@entry_id:268015) in $\mathbb{R}^d$, representing the unique [strong solution](@entry_id:198344) to the stochastic differential equation (SDE):
$$
dX_t = b(X_t)dt + \sigma(X_t)dW_t, \quad X_0 = x
$$
Here, $W_t$ is a standard multi-dimensional Brownian motion, and the drift $b$ and diffusion coefficient $\sigma$ are assumed to satisfy conditions ensuring the existence, uniqueness, and non-explosion of solutions with continuous [sample paths](@entry_id:184367).

Given an open set $D \subset \mathbb{R}^d$, the central object of study is the **[first exit time](@entry_id:201704)** from $D$, defined as:
$$
\tau_D = \inf\{ t \ge 0 : X_t \notin D \}
$$
This random variable captures the moment the process first leaves the domain $D$. A crucial property of $\tau_D$ is that it is a **stopping time** with respect to the [filtration](@entry_id:162013) generated by the process. A [filtration](@entry_id:162013) $(\mathcal{F}_t)_{t \ge 0}$ is an increasing family of $\sigma$-algebras representing the information available up to time $t$. A random time $T$ is a stopping time if the event $\{T \le t\}$ is $\mathcal{F}_t$-measurable for every $t \ge 0$; that is, the decision to stop at time $T$ can be made based solely on the history of the process up to that time. Since $X_t$ has [continuous paths](@entry_id:187361) and $D$ is an open set, the event $\{\tau_D \le t\}$ corresponds to the process hitting the [closed set](@entry_id:136446) $D^c$ at or before time $t$. This event can be determined by observing the path up to time $t$, confirming that $\tau_D$ is indeed a stopping time.

The theoretical engine that drives the analysis of [exit problems](@entry_id:192279) is the **strong Markov property**. While the ordinary Markov property states that the future of the process is independent of the past given the present state at a *deterministic* time $t$, the strong Markov property extends this to *[stopping times](@entry_id:261799)*. This extension is non-trivial and requires a careful setup of the underlying probability space.

To be precise, we consider the canonical path space $\Omega = C([0,\infty), \mathbb{R}^d)$ equipped with the filtration $(\mathcal{F}_t)_{t \ge 0}$ that satisfies the "usual conditions"—it is right-continuous and complete with respect to the probability measures $P^x$ governing the process started at $x$. The strong Markov property for the diffusion $X$ at the [stopping time](@entry_id:270297) $\tau_D$ can then be stated as follows [@problem_id:2974761]. Let $\theta_T$ be the [shift operator](@entry_id:263113) on path space, defined by $(\theta_T \omega)(s) = \omega(T+s)$, which represents the path starting from the random time $T$. For any bounded, [measurable function](@entry_id:141135) $h$ on the path space, we have:
$$
E^{x}\!\\left[\\,h\\!\\big(\\theta_{\\tau_D} X\\big)\\,\\middle|\\,\\mathcal{F}_{\\tau_D}\\right] = E^{X_{\\tau_D}}\\!\\left[\\,h(X)\\,\\right] \quad \\text{almost surely on }\\{\\tau_D \lt \\infty\\}
$$
Here, $\mathcal{F}_{\tau_D}$ is the $\sigma$-[algebra of events](@entry_id:272446) occurring up to the stopping time $\tau_D$. This powerful identity asserts that, conditional on the history up to the moment of exit, the subsequent evolution of the process is statistically identical to a new process starting from the exit location $X_{\tau_D}$, independent of the past that led it there. A frequently used special case involves taking $h(X) = f(X_t)$ for a bounded, Borel-[measurable function](@entry_id:141135) $f:\mathbb{R}^d \to \mathbb{R}$, which yields:
$$
E^{x}\\!\\left[\\,f\\!\\big(X_{\\tau_D + t}\\big)\\,\\middle|\\,\\mathcal{F}_{\\tau_D}\\right] = E^{X_{\\tau_D}}\\!\\left[\\,f\\!\\big(X_{t}\\big)\\,\\right]
$$

### Connecting Probability and Analysis: The Dirichlet Problem

The strong Markov property provides a profound link between SDEs and second-order [elliptic partial differential equations](@entry_id:141811). Consider the classical Dirichlet problem for the infinitesimal generator $L$ of the diffusion $X$. The generator is the operator acting on sufficiently [smooth functions](@entry_id:138942) $\varphi$ as:
$$
L \varphi(x) = \sum_{i=1}^d b_i(x)\,\\partial_i \varphi(x) + \\frac{1}{2}\\sum_{i,j=1}^d a_{ij}(x)\,\\partial_{ij} \varphi(x)
$$
where $a(x) = \sigma(x)\sigma(x)^{\top}$ is the [diffusion matrix](@entry_id:182965). The Dirichlet problem seeks a function $u$ that is harmonic with respect to $L$ inside $D$ and matches given boundary data $f$ on $\partial D$:
$$
\begin{cases}
L u(x) = 0  \\text{for } x \\in D \\\\
u(x) = f(x)  \\text{for } x \\in \\partial D
\end{cases}
$$
Remarkably, the solution to this PDE can be represented probabilistically. Let $u(x)$ be defined by the expectation of the function $f$ evaluated at the exit location of the process:
$$
u(x) = \\mathbb{E}_x\\big[f(X_{\\tau_D})\\big]
$$
This is a cornerstone result connecting the two fields [@problem_id:2974747]. To see how this connection arises, we can use **Itô's formula**. For a function $\varphi \in C^2(\mathbb{R}^d)$, Itô's formula states that the process $Y_t = \varphi(X_t)$ follows the SDE:
$$
d\varphi(X_t) = L\varphi(X_t)dt + \nabla\varphi(X_t)^{\top}\sigma(X_t)dW_t
$$
This implies that the process $M_t = \varphi(X_t) - \int_0^t L\varphi(X_s)ds$ is a **[local martingale](@entry_id:203733)**. If $L\varphi = 0$, then $\varphi(X_t)$ itself is a [local martingale](@entry_id:203733).

A pivotal tool in this context is the **Optional Stopping Theorem (OST)**. For a [martingale](@entry_id:146036) (or a [uniformly integrable](@entry_id:202893) [local martingale](@entry_id:203733)) $M_t$ and a [stopping time](@entry_id:270297) $T$, the OST allows us to state that $\mathbb{E}[M_T] = \mathbb{E}[M_0]$. Applying this to the [local martingale](@entry_id:203733) $\varphi(X_t)$ stopped at $\tau_D$, if conditions permit, we would obtain $\mathbb{E}_x[\varphi(X_{\tau_D})] = \varphi(x)$, which is precisely the probabilistic representation of the solution.

However, the application of the OST is not automatic, especially if $\tau_D$ can be infinite or the function $\varphi$ is unbounded. The validity of the step $\lim_{t \to \infty} \mathbb{E}[M_{t \wedge \tau_D}] = \mathbb{E}[M_{\tau_D}]$ hinges on the **[uniform integrability](@entry_id:199715)** of the stopped process $\{M_{t \wedge \tau_D}\}_{t \ge 0}$ [@problem_id:2974717]. Several conditions are sufficient to ensure this property. For instance:
- If the process $\{M_{t \wedge \tau_D}\}_{t \ge 0}$ is uniformly bounded in $L^p$ for some $p > 1$, i.e., $\sup_{t \ge 0} \mathbb{E}_x\big[|M_{t \wedge \tau_D}|^p\big]  \infty$.
- If the [local martingale](@entry_id:203733) is bounded. For example, if $L\varphi=0$ in $D$ and $\varphi$ is bounded on $D$, then $M_{t \wedge \tau_D} = \varphi(X_{t \wedge \tau_D})$ is a bounded [martingale](@entry_id:146036), which is always [uniformly integrable](@entry_id:202893).
- If the process is dominated by an integrable random variable. For instance, if both the function $f$ and its image under the generator, $Lf$, are bounded on $D$ and the [mean exit time](@entry_id:204800) $\mathbb{E}_x[\tau_D]$ is finite, then $|M_{t \wedge \tau_D}|$ is dominated by an integrable function of $\tau_D$, ensuring [uniform integrability](@entry_id:199715) [@problem_id:2974717].

### The Exit Distribution: Harmonic Measure and Poisson Kernel

The distribution of the exit location $X_{\tau_D}$ is a probability measure on the boundary $\partial D$ known as the **[harmonic measure](@entry_id:202752)**. For a starting point $x \in D$, the [harmonic measure](@entry_id:202752) is defined for any Borel set $B \subset \partial D$ by:
$$
\omega_D^x(B) = \mathbb{P}_x(X_{\tau_D} \in B)
$$
Using this notation, the probabilistic solution to the Dirichlet problem can be elegantly written as an integral against the [harmonic measure](@entry_id:202752):
$$
u(x) = \mathbb{E}_x[f(X_{\tau_D})] = \int_{\partial D} f(y) d\omega_D^x(y)
$$
This establishes the [harmonic measure](@entry_id:202752) as the fundamental object describing the exit distribution. For domains with sufficient boundary regularity (e.g., $C^2$ boundaries) and for uniformly elliptic diffusions, a deeper connection to classical [potential theory](@entry_id:141424) emerges [@problem_id:2974747].

In such cases, the [harmonic measure](@entry_id:202752) $\omega_D^x$ is absolutely continuous with respect to the surface measure $dS$ on $\partial D$. This means it has a density, known as the **Poisson kernel** $P_D(x,y)$:
$$
d\omega_D^x(y) = P_D(x,y) dS(y)
$$
The Poisson kernel itself has a representation in terms of the **Green's function** $G_D(x,y)$ for the operator $L$. The Green's function is the kernel of the inverse of $-L$ with Dirichlet boundary conditions. The Poisson kernel is then given by the normal derivative of the Green's function on the boundary:
$$
P_D(x,y) = -\frac{\partial G_D(x,y)}{\partial \mathbf{n}_y}
$$
where $\mathbf{n}_y$ is the outward unit normal at $y \in \partial D$. This chain of connections—from the probabilistic exit distribution to the [harmonic measure](@entry_id:202752), and then via its density (the Poisson kernel) to the Green's function—provides a powerful bridge between [stochastic analysis](@entry_id:188809) and the analytical machinery of [boundary value problems](@entry_id:137204).

### Mean Exit Time: The Kac Formula

Beyond *where* the process exits, we are often interested in *when* it exits. The key quantity is the [mean exit time](@entry_id:204800), $T(x) = \mathbb{E}_x[\tau_D]$. A beautiful formula, often attributed to Mark Kac, provides a PDE characterization for this quantity.

This result can be seen as a special case of a more general relationship, known as the **Feynman-Kac formula**, which connects expectations of integrated functionals of a diffusion path to Poisson-type PDEs. Consider the function $v_f(x)$ defined by the expected total time integral of a function $f$ until the process exits $D$:
$$
v_f(x) = \mathbb{E}_x\left[ \int_0^{\tau_D} f(X_t) dt \right]
$$
Using Dynkin's formula (a generalization of the OST), one can show that $v_f(x)$ is the unique solution to the Poisson equation [@problem_id:2974708]:
$$
\begin{cases}
-L v_f(x) = f(x)  \\text{for } x \in D \\\\
v_f(x) = 0  \\text{for } x \in \partial D
\end{cases}
$$
The [mean exit time](@entry_id:204800) $\mathbb{E}_x[\tau_D]$ corresponds to the special case where $f(x) \equiv 1$. Thus, the [mean exit time](@entry_id:204800) $T(x)$ is the unique solution to:
$$
-L T(x) = 1 \text{ in } D, \quad T(x)=0 \text{ on } \partial D.
$$
This PDE provides a direct method for calculating the [mean exit time](@entry_id:204800). Furthermore, using the Green's function representation for the solution to the Poisson equation, we arrive at **Kac's formula** for the [mean exit time](@entry_id:204800):
$$
\mathbb{E}_x[\tau_D] = \int_D G_D(x,y) dy
$$

A classic application of this result is computing the [mean exit time](@entry_id:204800) for standard $d$-dimensional Brownian motion ($b=0, \sigma=I$) from a ball of radius $R$, $D = B(0,R)$ [@problem_id:2974708]. In this case, the generator is $L = \frac{1}{2}\Delta$, where $\Delta$ is the Laplacian. The PDE for the [mean exit time](@entry_id:204800) $T(x)$ becomes $\Delta T(x) = -2$ in the ball, with $T(x)=0$ for $|x|=R$. By exploiting the [radial symmetry](@entry_id:141658) of the problem, one can solve this PDE explicitly to find the remarkably simple result:
$$
\mathbb{E}_x[\tau_{B(0,R)}] = \frac{R^2 - |x|^2}{d}
$$
This formula shows that the [mean exit time](@entry_id:204800) is largest at the center of the ball and decreases quadratically to zero at the boundary, with a dependence on the dimension $d$.

### Qualitative Properties of Exit Times

A fundamental qualitative question is whether a process is guaranteed to exit a domain in finite time. That is, under what conditions is $\mathbb{P}_x(\tau_D  \infty) = 1$ for all starting points $x \in D$? The answer depends on the interplay between the diffusion, the drift, and the geometry of the domain.

For a bounded domain $D$ and a uniformly elliptic diffusion (i.e., the [diffusion matrix](@entry_id:182965) $a(x)$ is uniformly [positive definite](@entry_id:149459)), exit is certain: $\mathbb{P}_x(\tau_D  \infty) = 1$ [@problem_id:2974763]. This can be proven by considering the [hitting probability](@entry_id:266865) $p(x) = \mathbb{P}_x(\tau_D  \infty)$. This function solves the Dirichlet problem $Lp=0$ in $D$ with boundary condition $p=1$ on $\partial D$. The function $q(x) \equiv 1$ is also a solution. By the maximum principle, which holds for uniformly [elliptic operators](@entry_id:181616), solutions are unique, so we must have $p(x)=1$ for all $x \in D$.

However, if the domain is unbounded or the diffusion is degenerate, the process might have a positive probability of never exiting. This is closely related to the concepts of **transience** and **recurrence**.
- **Example 1: Transience of Brownian Motion.** Standard Brownian motion is recurrent in dimensions $d=1$ and $d=2$ (it is guaranteed to return to any neighborhood of its starting point) but transient in dimensions $d \ge 3$ (it has a positive probability of drifting to infinity). Consider the exterior domain $D = \mathbb{R}^d \setminus \overline{B(0,1)}$ for $d \ge 3$. A Brownian motion starting in $D$ has a positive probability of never hitting the [unit ball](@entry_id:142558), meaning $\mathbb{P}_x(\tau_D = \infty)  0$ [@problem_id:2974763].
- **Example 2: Dominating Drift.** Consider a one-dimensional Brownian motion with a strong constant drift, $dX_t = \mu dt + dW_t$ with $\mu  0$, on the domain $D=(0, \infty)$. The process is pushed towards $+\infty$. While fluctuations can drive it towards the boundary at $0$, there is a positive probability that the drift will dominate permanently, causing the process to escape to infinity without ever hitting the origin. Thus, $\mathbb{P}_x(\tau_D = \infty)  0$ [@problem_id:2974763].

### Explicit Methods for One-Dimensional Diffusions

For [one-dimensional diffusions](@entry_id:198610) on an interval $I = (\ell, r)$, a powerful and explicit theory exists based on the concepts of the **scale function** and **speed measure** [@problem_id:2974716].

The **scale function** $s(x)$ is a strictly increasing function defined by the condition that it is annihilated by the generator, $Ls(x) = 0$. For $L = b(x)\frac{d}{dx} + \frac{1}{2}\sigma^2(x)\frac{d^2}{dx^2}$, this leads to the ODE $b(x)s'(x) + \frac{1}{2}\sigma^2(x)s''(x) = 0$. The canonical choice for the derivative of the scale function is:
$$
s'(x) = \exp\left( -\int^x \frac{2b(u)}{\sigma^2(u)}du \right)
$$
The crucial property of the scale function is that when composed with the process, $s(X_t)$ becomes a [local martingale](@entry_id:203733). This simplifies many calculations, most notably that of hitting probabilities. For any two points $a,b \in I$ with $a  x  b$, the probability that the process hits $b$ before $a$ is given by a simple linear interpolation in the scale coordinate:
$$
\mathbb{P}_x(\tau_b  \tau_a) = \frac{s(x) - s(a)}{s(b) - s(a)}
$$
The **speed measure** $m(dx)$ has a density given by $m'(x) = \frac{2}{\sigma^2(x) s'(x)}$. Together, these two objects allow for the representation of the generator in Sturm-Liouville form, $L = \frac{d}{dm}\frac{d}{ds}$, and provide explicit formulas for quantities like mean [exit times](@entry_id:193122) and Green's functions.

This framework is particularly useful for analyzing diffusions with **degenerate** coefficients, for instance, where $\sigma(x)$ vanishes at a boundary. The behavior of the process near such a boundary depends critically on whether the boundary is **attainable**. For a pure diffusion $dX_t = \sigma(X_t)dW_t$, the boundary at $0$ is attainable if and only if $\int_0^\epsilon \frac{y}{\sigma(y)^2} dy  \infty$ for some $\epsilon > 0$ [@problem_id:2974737]. For the SDE $dX_t = \sigma_0 X_t^\alpha dW_t$ on $(0,1)$, this integral converges if and only if $\alpha  1$.
- If $\alpha  1$, the boundary at $0$ is attainable, and the [hitting probability](@entry_id:266865) $\mathbb{P}_x(T_0  T_1)$ is non-zero. Since the generator is $\mathcal{L}f(x) = \frac{1}{2}\sigma_0^2 x^{2\alpha} f''(x)$, the scale function solves $s''(x)=0$, so $s(x)=x$. The [hitting probability](@entry_id:266865) is simply $\mathbb{P}_x(T_0  T_1) = 1-x$.
- If $\alpha \ge 1$, the boundary is not attainable. The process can never reach $0$, so $\mathbb{P}_x(T_0  T_1) = 0$. This illustrates how a subtle change in the local behavior of the diffusion coefficient can lead to a drastic change in the qualitative properties of the process.

### Advanced Topics: Analytical and Asymptotic Perspectives

#### Low Regularity and Viscosity Solutions

The connection between $u(x) = \mathbb{E}_x[f(X_{\tau_D})]$ and the PDE $Lu=0$ relies on Itô's formula, which requires the solution $u$ to be twice continuously differentiable ($C^2$). However, if the coefficients $b$ and $\sigma$ of the SDE are merely continuous (not Hölder continuous or smoother), [elliptic regularity theory](@entry_id:203755) does not guarantee that $u$ will be $C^2$.

In this setting, the PDE must be interpreted in a weaker sense. The appropriate framework is the theory of **[viscosity solutions](@entry_id:177596)** [@problem_id:2974730]. A continuous function $u$ is a [viscosity solution](@entry_id:198358) of $Lu=0$ if, at any point $x_0 \in D$ where a smooth "test function" $\varphi$ touches $u$ from above (i.e., $u-\varphi$ has a local maximum), we have $L\varphi(x_0) \ge 0$, and where $\varphi$ touches $u$ from below, we have $L\varphi(x_0) \le 0$. The probabilistic function $u(x)$ can be shown to satisfy these conditions, making it a [viscosity solution](@entry_id:198358).

A key result in this theory is the **[comparison principle](@entry_id:165563)**: if the operator $L$ is uniformly elliptic, then for a subsolution $v$ and supersolution $w$ with $v \le w$ on the boundary, we have $v \le w$ inside the domain. This principle ensures the uniqueness of the bounded, continuous [viscosity solution](@entry_id:198358) to the Dirichlet problem. For the probabilistic representation to be this unique solution, we also need boundary regularity, which ensures that $u(x)$ continuously attains its boundary values [@problem_id:2974730].

#### Small Noise Asymptotics and Large Deviations

A different and powerful perspective emerges when we consider the behavior of diffusions in the small-noise limit, $\varepsilon \to 0$:
$$
dX_t^\varepsilon = b(X_t^\varepsilon)dt + \sqrt{\varepsilon}\sigma(X_t^\varepsilon)dW_t
$$
In this regime, the process $X_t^\varepsilon$ converges to the deterministic trajectory governed by $\dot{\phi}(t) = b(\phi(t))$. Exiting a domain that contains a [stable equilibrium](@entry_id:269479) of the deterministic flow is a rare event. The **Freidlin-Wentzell theory of large deviations** provides a precise characterization of the probabilities of such rare events.

The theory states that the laws of the processes $\{X^\varepsilon\}_{\varepsilon > 0}$ satisfy a **Large Deviations Principle (LDP)** on path space with a rate function (or [action functional](@entry_id:169216)) $S_{0T}(\phi)$ [@problem_id:2974715]. For an absolutely continuous path $\phi$, this functional quantifies the "cost" of deviating from the deterministic flow:
$$
S_{0T}(\phi) = \frac{1}{2} \int_0^T \big(\dot{\phi}(t) - b(\phi(t))\big)^{\top} a(\phi(t))^{-1} \big(\dot{\phi}(t) - b(\phi(t))\big) dt
$$
The probability of observing a path in a certain set $A$ is, to leading [exponential order](@entry_id:162694), given by $P(X^\varepsilon \in A) \approx \exp(-\frac{1}{\varepsilon} \inf_{\phi \in A} S_{0T}(\phi))$.

For the exit problem, if the domain $D$ contains a stable equilibrium $x^\star$, the process spends most of its time near $x^\star$. To exit, it must follow an "optimal" path from $x^\star$ to the boundary $\partial D$ that minimizes the [action functional](@entry_id:169216). The minimum action required to travel from a point $x_1$ to $x_2$ is called the **[quasipotential](@entry_id:196547)**, $V(x_1, x_2)$. As $\varepsilon \to 0$, the exit location $X^\varepsilon_{\tau_D^\varepsilon}$ concentrates on the points $y \in \partial D$ that minimize the [quasipotential](@entry_id:196547) from the equilibrium, $V(x^\star, y)$.

The structure of the [quasipotential](@entry_id:196547) is determined by the interaction of the drift $b$ and the [diffusion matrix](@entry_id:182965) $a = \sigma\sigma^\top$. For example, consider a process attracted to the origin ($b(x)=-x$) in the unit disk.
- If the noise is anisotropic, e.g., $a = \text{diag}(\lambda_1, \lambda_2)$ with $\lambda_2 > \lambda_1 > 0$, the [quasipotential](@entry_id:196547) is $U(x) = \frac{x_1^2}{\lambda_1} + \frac{x_2^2}{\lambda_2}$. To exit, it is "cheaper" for the process to move in the direction of stronger noise (larger $\lambda$). Minimizing $U(x)$ on the unit circle $x_1^2+x_2^2=1$ shows that the exits will concentrate near $(0, \pm 1)$, the direction corresponding to the larger noise component $\lambda_2$ [@problem_id:29757].
- If the noise is degenerate, e.g., $a = \text{diag}(\lambda_1, 0)$, noise only acts in the $x_1$ direction. Any controlled path from the origin must remain on the $x_1$-axis. The [quasipotential](@entry_id:196547) is infinite for any point with a non-zero $x_2$ component. Consequently, exits can only occur at $(\pm 1, 0)$, the only points on the boundary reachable by the controlled dynamics [@problem_id:29757]. This demonstrates how the geometry of the noise profoundly shapes the landscape of rare events.