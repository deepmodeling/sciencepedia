{"hands_on_practices": [{"introduction": "Before delving into the subtleties that the Yamada-Watanabe theorem addresses, it is essential to master the classical framework that guarantees well-posedness for stochastic differential equations. This exercise [@problem_id:3004620] revisits the foundational Picard iteration method, which provides a constructive proof of strong existence and pathwise uniqueness under specific regularity and growth assumptions. By identifying these classical Lipschitz and linear growth conditions, you will solidify the baseline theory from which more advanced results depart and better appreciate the need for theorems that handle less regular coefficients.", "problem": "Consider the Itô Stochastic Differential Equation (SDE) on $\\mathbb{R}^d$ driven by an $m$-dimensional standard Brownian motion $W$, given by\n$$\ndX_t = b(X_t)\\,dt + \\sigma(X_t)\\,dW_t,\\qquad X_0\\in L^2(\\Omega;\\mathbb{R}^d),\n$$\nwhere $b:\\mathbb{R}^d\\to\\mathbb{R}^d$ and $\\sigma:\\mathbb{R}^d\\to\\mathbb{R}^{d\\times m}$ are Borel functions. A strong solution is an $\\mathbb{R}^d$-valued process adapted to the filtration generated by $X_0$ and $W$ that satisfies the integral equation in the usual sense. Pathwise uniqueness means that if $X$ and $Y$ are two strong solutions with the same $X_0$ and driven by the same Brownian motion $W$, then $\\mathbb{P}\\big(\\sup_{t\\in[0,T]}\\|X_t-Y_t\\|=0\\big)=1$ for every $T0$. The classical Picard iteration constructs $\\{X^{(n)}\\}_{n\\ge 0}$ via\n$$\nX^{(0)}_t := X_0,\\qquad X^{(n+1)}_t := X_0 + \\int_0^t b\\big(X^{(n)}_s\\big)\\,ds + \\int_0^t \\sigma\\big(X^{(n)}_s\\big)\\,dW_s,\n$$\nand derives a contraction estimate using the global behavior of $b$ and $\\sigma$, Gronwall’s inequality, and the Burkholder-Davis-Gundy inequality.\n\nWhich of the following sets of assumptions on $b$ and $\\sigma$ are the classical Lipschitz and linear growth conditions that ensure strong existence and pathwise uniqueness via Picard iteration for all finite horizons $[0,T]$?\n\nA. There exist constants $L0$ and $K0$ such that, for all $x,y\\in\\mathbb{R}^d$,\n$$\n\\|b(x)-b(y)\\|\\le L\\|x-y\\|,\\qquad \\|\\sigma(x)-\\sigma(y)\\|_{\\mathrm{HS}}\\le L\\|x-y\\|,\n$$\nand\n$$\n\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K\\big(1+\\|x\\|^2\\big),\n$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm on $\\mathbb{R}^d$ and $\\|\\cdot\\|_{\\mathrm{HS}}$ denotes the Hilbert-Schmidt norm on $\\mathbb{R}^{d\\times m}$.\n\nB. The function $b$ is globally Lipschitz on $\\mathbb{R}^d$, the function $\\sigma$ is continuous on $\\mathbb{R}^d$, and there exists $K0$ such that\n$$\n\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K\\big(1+\\|x\\|^2\\big)\\quad\\text{for all }x\\in\\mathbb{R}^d.\n$$\n\nC. In dimension $d=1$, there exists $L0$ such that\n$$\n(x-y)\\big(b(x)-b(y)\\big)\\le L|x-y|^2\\quad\\text{for all }x,y\\in\\mathbb{R},\n$$\nand $\\sigma$ is Hölder continuous of order $1/2$ on $\\mathbb{R}$ with linear growth.\n\nD. There exist constants $L0$ and $K0$ such that, for all $x,y\\in\\mathbb{R}^d$,\n$$\n\\|b(x)-b(y)\\|\\le L\\|x-y\\|,\\qquad \\|\\sigma(x)-\\sigma(y)\\|_{\\mathrm{HS}}\\le L\\|x-y\\|,\n$$\nand\n$$\n\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K\\big(1+\\|x\\|^4\\big).\n$$\n\nSelect the single best answer that matches the classical conditions used to implement the Picard iteration to obtain strong existence and pathwise uniqueness, and that are standardly paired with the Yamada-Watanabe theorem to conclude strong well-posedness.", "solution": "The user wants me to identify the classical set of conditions on the drift $b$ and diffusion $\\sigma$ coefficients that guarantee the existence of a unique strong solution to a stochastic differential equation (SDE) for all time, where the proof relies on the Picard iteration method.\n\n### Step 1: Extract Givens\nThe problem considers the Itô SDE on $\\mathbb{R}^d$:\n$$\ndX_t = b(X_t)\\,dt + \\sigma(X_t)\\,dW_t\n$$\n- Initial condition: $X_0 \\in L^2(\\Omega;\\mathbb{R}^d)$.\n- Brownian motion: $W$ is an $m$-dimensional standard Brownian motion.\n- Coefficients: $b:\\mathbb{R}^d\\to\\mathbb{R}^d$ and $\\sigma:\\mathbb{R}^d\\to\\mathbb{R}^{d\\times m}$ are Borel functions.\n- The problem asks for the classical conditions that ensure strong existence and pathwise uniqueness for all finite horizons $[0,T]$ via the Picard iteration method.\n- The Picard iteration is defined as:\n$$\nX^{(0)}_t := X_0,\\qquad X^{(n+1)}_t := X_0 + \\int_0^t b\\big(X^{(n)}_s\\big)\\,ds + \\int_0^t \\sigma\\big(X^{(n)}_s\\big)\\,dW_s\n$$\n- The methodology involves deriving a contraction estimate using Gronwall’s inequality and the Burkholder-Davis-Gundy (BDG) inequality.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement describes a canonical topic in the theory of stochastic differential equations. The definitions of the SDE, strong solution, pathwise uniqueness, and the Picard iteration scheme are all standard and mathematically correct. The question asks for the identification of a well-established theorem's hypotheses. The problem is scientifically grounded in established mathematical theory, is well-posed, and uses objective, precise language. There are no contradictions, ambiguities, or missing information that would render it invalid.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed with the derivation and analysis.\n\n### Derivation of the Classical Conditions\n\nThe standard proof for strong existence and uniqueness via Picard iteration involves two main parts:\n1.  **Uniqueness and Convergence of Iterates**: Showing that the mapping defined by the right-hand side of the SDE's integral form is a contraction on a suitable space of stochastic processes. This guarantees that if a solution exists, it is unique, and that the Picard sequence $\\{X^{(n)}\\}$ converges to a limit process $X$.\n2.  **Boundedness of Moments**: Ensuring that the solution process $X$ does not \"explode\" in finite time. This is typically done by showing that the moments of the Picard iterates, e.g., $\\mathbb{E}\\big[\\sup_{t \\in [0,T]}\\|X^{(n)}_t\\|^2\\big]$, are uniformly bounded on any finite time interval $[0,T]$.\n\n**Part 1: Uniqueness and Convergence (Contraction Argument)**\n\nLet $X$ and $Y$ be two solutions with the same initial condition $X_0$ and Brownian motion $W$. Their difference is:\n$$\nX_t - Y_t = \\int_0^t \\big(b(X_s) - b(Y_s)\\big)\\,ds + \\int_0^t \\big(\\sigma(X_s) - \\sigma(Y_s)\\big)\\,dW_s\n$$\nTaking the expectation of the squared norm and applying the inequality $(a+b)^2 \\le 2a^2 + 2b^2$:\n$$\n\\mathbb{E}\\big[\\|X_t - Y_t\\|^2\\big] \\le 2\\mathbb{E}\\left[\\left\\|\\int_0^t \\big(b(X_s) - b(Y_s)\\big)\\,ds\\right\\|^2\\right] + 2\\mathbb{E}\\left[\\left\\|\\int_0^t \\big(\\sigma(X_s) - \\sigma(Y_s)\\big)\\,dW_s\\right\\|^2\\right]\n$$\nUsing the Cauchy-Schwarz inequality for the drift term and Itô's isometry for the diffusion term:\n$$\n\\mathbb{E}\\big[\\|X_t - Y_t\\|^2\\big] \\le 2T\\int_0^t \\mathbb{E}\\big[\\|b(X_s) - b(Y_s)\\|^2\\big]\\,ds + 2\\int_0^t \\mathbb{E}\\big[\\|\\sigma(X_s) - \\sigma(Y_s)\\|_{\\mathrm{HS}}^2\\big]\\,ds\n$$\nTo proceed, we must control the terms $\\|b(X_s) - b(Y_s)\\|$ and $\\|\\sigma(X_s) - \\sigma(Y_s)\\|_{\\mathrm{HS}}$. The classical assumption is that both $b$ and $\\sigma$ are **globally Lipschitz continuous**. That is, there exists a constant $L0$ such that for all $x, y \\in \\mathbb{R}^d$:\n$$\n\\|b(x)-b(y)\\| \\le L\\|x-y\\| \\quad \\text{and} \\quad \\|\\sigma(x)-\\sigma(y)\\|_{\\mathrm{HS}} \\le L\\|x-y\\|\n$$\nApplying these conditions:\n$$\n\\mathbb{E}\\big[\\|X_t - Y_t\\|^2\\big] \\le 2T\\int_0^t L^2\\mathbb{E}\\big[\\|X_s - Y_s\\|^2\\big]\\,ds + 2\\int_0^t L^2\\mathbb{E}\\big[\\|X_s - Y_s\\|^2\\big]\\,ds\n$$\n$$\n\\mathbb{E}\\big[\\|X_t - Y_t\\|^2\\big] \\le 2L^2(T+1)\\int_0^t \\mathbb{E}\\big[\\|X_s - Y_s\\|^2\\big]\\,ds\n$$\nLet $\\phi(t) = \\mathbb{E}\\big[\\|X_t - Y_t\\|^2\\big]$. We have $\\phi(t) \\le C \\int_0^t \\phi(s)\\,ds$ for some constant $C$. Since $\\phi(0) = \\mathbb{E}\\big[\\|X_0 - Y_0\\|^2\\big] = 0$, Gronwall's inequality implies $\\phi(t) = 0$ for all $t \\ge 0$. A similar argument using the BDG inequality shows pathwise uniqueness. The same logic proves that the sequence of Picard iterates is a Cauchy sequence, thus ensuring convergence.\n\n**Part 2: Boundedness of Moments (Non-Explosion)**\n\nTo ensure the integrals in the Picard scheme are well-defined and that the solution exists for all time, we must control the growth of the solution's moments. Let's analyze $\\mathbb{E}\\big[\\|X_t\\|^2\\big]$ for a solution $X_t$.\n$$\n\\mathbb{E}\\big[\\|X_t\\|^2\\big] \\le 3\\mathbb{E}\\big[\\|X_0\\|^2\\big] + 3T\\int_0^t \\mathbb{E}\\big[\\|b(X_s)\\|^2\\big]\\,ds + 3\\int_0^t \\mathbb{E}\\big[\\|\\sigma(X_s)\\|_{\\mathrm{HS}}^2\\big]\\,ds\n$$\nTo control the integral terms, we need to bound $\\|b(x)\\|^2$ and $\\|\\sigma(x)\\|_{\\mathrm{HS}}^2$. The classical condition is **linear growth**: there exists a constant $K0$ such that for all $x \\in \\mathbb{R}^d$:\n$$\n\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K(1+\\|x\\|^2)\n$$\nWith this condition, we get:\n$$\n\\mathbb{E}\\big[\\|X_t\\|^2\\big] \\le 3\\mathbb{E}\\big[\\|X_0\\|^2\\big] + 3(T+1)\\int_0^t \\mathbb{E}\\big[K(1+\\|X_s\\|^2)\\big]\\,ds\n$$\n$$\n\\mathbb{E}\\big[\\|X_t\\|^2\\big] \\le 3\\mathbb{E}\\big[\\|X_0\\|^2\\big] + 3K(T+1)t + 3K(T+1)\\int_0^t \\mathbb{E}\\big[\\|X_s\\|^2\\big]\\,ds\n$$\nLet $\\psi(t) = \\mathbb{E}\\big[\\|X_t\\|^2\\big]$. Then $\\psi(t) \\le A + B\\int_0^t \\psi(s)\\,ds$, where $A$ and $B$ are constants depending on $T, K,$ and $\\mathbb{E}\\big[\\|X_0\\|^2\\big]$. Gronwall's inequality implies that $\\psi(t)$ is bounded on any finite interval $[0,T]$. This ensures the solution does not explode in finite time.\n\nThe combination of global Lipschitz and linear growth conditions is the classical set of sufficient conditions for strong existence and uniqueness. Note that the global Lipschitz condition implies the linear growth condition, as for any $x \\in \\mathbb{R}^d$:\n$\\|b(x)\\| \\le \\|b(x)-b(0)\\| + \\|b(0)\\| \\le L\\|x\\| + \\|b(0)\\|$, so $\\|b(x)\\|^2 \\le 2(L^2\\|x\\|^2 + \\|b(0)\\|^2) \\le C(1+\\|x\\|^2)$ for some constant $C$. A similar argument holds for $\\sigma$. Nonetheless, the two conditions are classically stated together.\n\n### Option-by-Option Analysis\n\n*   **A. There exist constants $L0$ and $K0$ such that, for all $x,y\\in\\mathbb{R}^d$, $\\|b(x)-b(y)\\|\\le L\\|x-y\\|$, $\\|\\sigma(x)-\\sigma(y)\\|_{\\mathrm{HS}}\\le L\\|x-y\\|$, and $\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K\\big(1+\\|x\\|^2\\big)$.**\n    This option states the global Lipschitz condition for both $b$ and $\\sigma$, and the linear growth condition. As derived above, these are precisely the classical conditions used in the standard Picard iteration proof to establish strong existence and pathwise uniqueness.\n    **Verdict: Correct.**\n\n*   **B. The function $b$ is globally Lipschitz on $\\mathbb{R}^d$, the function $\\sigma$ is continuous on $\\mathbb{R}^d$, and there exists $K0$ such that $\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K\\big(1+\\|x\\|^2\\big)$.**\n    This option weakens the condition on $\\sigma$ from Lipschitz to merely continuous. The contraction argument used in the Picard iteration method fundamentally relies on the Lipschitz property of $\\sigma$ to control the stochastic integral term. Mere continuity is insufficient to guarantee pathwise uniqueness or the convergence of the Picard iterates. A famous counterexample is the Tanaka SDE, $dX_t = \\text{sgn}(X_t)dW_t$, where $\\sigma$ is not continuous at $0$, but even with a continuous, non-Lipschitz $\\sigma$, uniqueness can fail.\n    **Verdict: Incorrect.**\n\n*   **C. In dimension $d=1$, there exists $L0$ such that $(x-y)\\big(b(x)-b(y)\\big)\\le L|x-y|^2$, and $\\sigma$ is Hölder continuous of order $1/2$ with linear growth.**\n    This option presents conditions that are weaker than the classical Lipschitz conditions. The one-sided Lipschitz condition on $b$ and Hölder continuity on $\\sigma$ are used in more advanced theorems to prove pathwise uniqueness, often in concert with the Yamada-Watanabe theorem (which states that weak existence + pathwise uniqueness implies strong existence). However, these are not the conditions used in the *classical Picard iteration* scheme, which hinges on a contraction mapping argument enabled by the stronger Lipschitz assumption.\n    **Verdict: Incorrect.**\n\n*   **D. There exist constants $L0$ and $K0$ such that, for all $x,y\\in\\mathbb{R}^d$, $\\|b(x)-b(y)\\|\\le L\\|x-y\\|$, $\\|\\sigma(x)-\\sigma(y)\\|_{\\mathrm{HS}}\\le L\\|x-y\\|$, and $\\|b(x)\\|^2 + \\|\\sigma(x)\\|_{\\mathrm{HS}}^2 \\le K\\big(1+\\|x\\|^4\\big)$.**\n    This option includes the correct Lipschitz conditions but specifies a superlinear growth condition of order $\\|x\\|^4$. As shown in the derivation for moment bounds, a linear growth condition ($\\|x\\|^2$) is required to use Gronwall's inequality to show that moments are finite on any interval $[0,T]$. A superlinear growth condition like this one does not guarantee that the solution will not explode in finite time. The problem asks for conditions ensuring existence for all finite horizons, which this condition fails to do.\n    **Verdict: Incorrect.**\n\nIn summary, Option A is the only one that correctly identifies the standard, classical set of sufficient conditions for proving strong existence and pathwise uniqueness for all time using the Picard iteration method.", "answer": "$$\\boxed{A}$$", "id": "3004620"}, {"introduction": "The Tanaka SDE is a cornerstone of modern stochastic analysis, famously illustrating a scenario where classical existence and uniqueness theorems fail due to a discontinuous diffusion coefficient. This exercise [@problem_id:3004600] offers a unique hands-on opportunity to move beyond theory and build a weak solution from first principles, using a reflecting Brownian motion and an independent random sign process. By completing this construction and deriving the surprising result that the solution is itself a Brownian motion, you will gain a profound, concrete understanding of weak solutions and the mechanisms that allow for their existence even when strong solutions fail.", "problem": "Consider the Tanaka stochastic differential equation (SDE)\n$$\ndX_{t} \\;=\\; \\operatorname{sgn}(X_{t})\\, dW_{t}, \\qquad X_{0}=0,\n$$\nwhere $W$ is a standard Brownian motion and $\\operatorname{sgn}(x)$ denotes the sign function with the convention $\\operatorname{sgn}(0)=0$. Work on a complete filtered probability space rich enough to support all random objects used below. Use the following context-appropriate fundamental bases: the Skorokhod problem for reflecting Brownian motion, semimartingale local time at $0$, the product rule for semimartingales, and Lévy’s characterization of Brownian motion.\n\nConstruct a weak solution to the Tanaka SDE by the following steps. First, let $R$ be the reflecting Brownian motion driven by $W$, that is, the unique strong solution to the Skorokhod problem\n$$\nR_{t} \\;=\\; W_{t} \\;+\\; L_{t}^{0}(R), \\qquad R_{t}\\ge 0,\n$$\nwhere $L_{t}^{0}(R)$ is the (continuous, nondecreasing) semimartingale local time of $R$ at $0$ that increases only on the set $\\{t: R_{t}=0\\}$. Second, index the excursion intervals of $R$ away from $0$ as $\\{I_{k}=(g_{k},d_{k})\\}_{k\\ge 1}$ in a measurable manner, and take an independent sequence $\\{\\varepsilon_{k}\\}_{k\\ge 1}$ of Rademacher random variables, $\\mathbb{P}(\\varepsilon_{k}=1)=\\mathbb{P}(\\varepsilon_{k}=-1)=\\frac{1}{2}$, independent of $W$. Define the predictable sign process\n$$\nU_{t} \\;=\\; \\sum_{k\\ge 1} \\varepsilon_{k}\\,\\mathbf{1}_{I_{k}}(t),\n$$\nand set\n$$\nX_{t} \\;=\\; U_{t}\\, R_{t}.\n$$\nUsing only the fundamental bases listed above (and no shortcut formulas), derive from first principles that $(X,W)$ is a weak solution of the Tanaka SDE, in the integral sense\n$$\nX_{t} \\;=\\; \\int_{0}^{t} \\operatorname{sgn}(X_{s})\\, dW_{s}.\n$$\nThen compute the exact law of $X_{t}$ at a fixed time $t0$ by giving its characteristic function\n$$\n\\varphi_{t}(u) \\;=\\; \\mathbb{E}\\big[\\exp(iu X_{t})\\big].\n$$\nProvide your final answer as a single closed-form analytic expression for $\\varphi_{t}(u)$ as a function of $u$ and $t$ (no rounding is required).", "solution": "The problem statement presented is a well-posed and scientifically grounded exercise in stochastic calculus. It details a standard construction of a weak solution to the Tanaka stochastic differential equation (SDE) and asks for its verification and the calculation of its characteristic function. All givens are clearly defined, scientifically sound, and internally consistent. The problem is a non-trivial application of fundamental concepts such as the Skorokhod problem, semimartingale local time, the product rule, and Lévy's characterization of Brownian motion. Therefore, the problem is deemed valid and a full solution is provided below.\n\nThe problem is divided into two parts. First, we must show that the constructed process $(X_t, W_t)$ is a weak solution to the Tanaka SDE. Second, we must compute the characteristic function of $X_t$.\n\n**Part 1: Verification of the Weak Solution**\n\nWe are given the candidate solution $X_t = U_t R_t$, where $R_t$ is the reflecting Brownian motion (RBM) solving the Skorokhod problem $R_t = W_t + L_t^0(R)$, and $U_t$ is a predictable sign process constructed from the excursions of $R_t$ and an independent Rademacher sequence $\\{\\varepsilon_k\\}_{k\\ge 1}$. We start with $X_0 = U_0 R_0$. Since $R_0 = W_0 + L_0^0(R) = 0+0=0$, we have $X_0 = 0$, which matches the initial condition of the SDE.\n\nTo find the dynamics of $X_t$, we apply the product rule for semimartingales (integration by parts formula) to $X_t = U_t R_t$. The general formula is:\n$$\nd(U_t R_t) = U_{t-} dR_t + R_{t-} dU_t + d[U, R]_t\n$$\nIn integral form, this is:\n$$\nX_t = X_0 + \\int_0^t U_{s-} dR_s + \\int_0^t R_{s-} dU_s + [U, R]_t\n$$\nWe analyze each term on the right-hand side.\nSince $X_0=0$:\n$$\nX_t = \\int_0^t U_{s-} dR_s + \\int_0^t R_{s-} dU_s + [U, R]_t\n$$\n1.  The term $\\int_0^t U_{s-} dR_s$:\n    We substitute $dR_s = dW_s + dL_s^0(R)$ from the definition of the RBM:\n    $$\n    \\int_0^t U_{s-} dR_s = \\int_0^t U_{s-} dW_s + \\int_0^t U_{s-} dL_s^0(R)\n    $$\n    The process $U_s$ is predictable, which means $U_{s-} = U_s$ almost everywhere with respect to the Lebesgue measure, allowing us to write the stochastic integral as $\\int_0^t U_s dW_s$. The second integral is a Stieltjes integral with respect to the local time $L_s^0(R)$. The process $L_s^0(R)$ is continuous and non-decreasing, and it increases only on the set of times $\\{s \\ge 0 : R_s = 0\\}$. By construction, the process $U_s$ is defined to be $0$ on this very set. Therefore, the integrand $U_s$ is zero whenever $dL_s^0(R)$ is non-zero. This implies $\\int_0^t U_s dL_s^0(R) = 0$.\n    Thus, the first term simplifies to $\\int_0^t U_s dW_s$.\n\n2.  The term $\\int_0^t R_{s-} dU_s$:\n    The process $U_t$ is a pure jump process. It is constant on the excursion intervals $I_k=(g_k, d_k)$ and on the zero set of $R$. Its jumps occur at the start times $g_k$ of the excursions, where $U_t$ jumps from $0$ to $\\varepsilon_k$. At these times $g_k$, the process $R_t$ is at $0$, so $R_{g_k} = R_{g_k-}=0$ due to the continuity of $R$. The integral is the sum of the jumps of $U$ scaled by the value of $R$ just before the jump: $\\int_0^t R_{s-} dU_s = \\sum_{s \\le t} R_{s-} \\Delta U_s$. As all jumps $\\Delta U_s$ occur at times when $R_{s-}=0$, this sum is zero.\n\n3.  The term $[U, R]_t$:\n    The quadratic covariation between a pure jump process $U$ and a continuous process $R$ is given by $[U, R]_t = \\sum_{s \\le t} \\Delta U_s \\Delta R_s$. Since $R_t$ is a continuous process, its jumps are $\\Delta R_s = 0$ for all $s$. Therefore, $[U, R]_t = 0$.\n\nCombining these results, we find that the dynamics of $X_t$ are given by:\n$$\nX_t = \\int_0^t U_s dW_s\n$$\nThe final step is to show that $U_s = \\operatorname{sgn}(X_s)$. We examine this equality based on the value of $R_s$:\n-   If $R_s  0$, then $s$ must belong to some excursion interval $I_k$. On this interval, $U_s = \\varepsilon_k$, where $\\varepsilon_k \\in \\{-1, 1\\}$.\n    - If $U_s = 1$, then $X_s = 1 \\cdot R_s = R_s  0$, so $\\operatorname{sgn}(X_s) = 1$. Thus $U_s = \\operatorname{sgn}(X_s)$.\n    - If $U_s = -1$, then $X_s = -1 \\cdot R_s = -R_s  0$, so $\\operatorname{sgn}(X_s) = -1$. Thus $U_s = \\operatorname{sgn}(X_s)$.\n-   If $R_s = 0$, then $X_s = U_s R_s = U_s \\cdot 0 = 0$. By the problem's convention, $\\operatorname{sgn}(X_s) = \\operatorname{sgn}(0) = 0$. By construction, $U_s=0$ when $R_s=0$. Thus $U_s = \\operatorname{sgn}(X_s)$.\n\nIn all cases, we have $U_s = \\operatorname{sgn}(X_s)$ for all $s \\ge 0$. Substituting this into the integral expression for $X_t$, we get:\n$$\nX_t = \\int_0^t \\operatorname{sgn}(X_s) dW_s\n$$\nThis is the integral form of the Tanaka SDE. The constructed pair $(X_t, W_t)$ solves the equation. Since the process $X_t$ is adapted not to the filtration of $W_t$ alone but to an enlarged filtration that includes the information from the Rademacher variables, this is a weak solution.\n\n**Part 2: Calculation of the Characteristic Function**\n\nWe wish to compute $\\varphi_t(u) = \\mathbb{E}[\\exp(iu X_t)]$. Using the construction $X_t = U_t R_t$, we have:\n$$\n\\varphi_t(u) = \\mathbb{E}\\big[ \\exp(iu U_t R_t) \\big]\n$$\nWe use the law of total expectation by conditioning on the Brownian motion $W$, which also determines the process $R$. The Rademacher sequence $\\{\\varepsilon_k\\}$ is independent of $W$. Let $\\mathcal{F}^W = \\sigma(\\{W_s : s \\ge 0\\})$.\n$$\n\\varphi_t(u) = \\mathbb{E}\\Big[ \\mathbb{E}\\big[ \\exp(iu U_t R_t) \\big| \\mathcal{F}^W \\big] \\Big]\n$$\nGiven a realization of $W$, the process $R_t$ and its excursion intervals are fixed.\n-   If, at time $t$, $R_t = 0$, then $X_t=0$ and $\\exp(iu U_t R_t) = 1$. In this case, $\\cos(u R_t) = \\cos(0) = 1$.\n-   If, at time $t$, $R_t  0$, then $t$ belongs to some excursion interval $I_k$. On this interval, $U_t = \\varepsilon_k$. Since $\\varepsilon_k$ is a Rademacher random variable independent of $\\mathcal{F}^W$, the conditional expectation is:\n    $$\n    \\mathbb{E}\\big[ \\exp(iu \\varepsilon_k R_t) \\big| \\mathcal{F}^W \\big] = \\frac{1}{2} \\exp(iu R_t) + \\frac{1}{2} \\exp(-iu R_t) = \\cos(u R_t)\n    $$\nCombining both cases, the conditional expectation is always $\\cos(u R_t)$.\n$$\n\\mathbb{E}\\big[ \\exp(iu U_t R_t) \\big| \\mathcal{F}^W \\big] = \\cos(u R_t)\n$$\nTaking the outer expectation, we get:\n$$\n\\varphi_t(u) = \\mathbb{E}\\big[ \\cos(u R_t) \\big]\n$$\nThe next step is to determine the law of $R_t$. The process $R_t$ is a reflecting Brownian motion starting at $0$. It is a standard result, derivable from the Itô-Tanaka formula and Lévy's characterization of Brownian motion, that the law of $R_t$ is the same as the law of $|B_t|$ for a standard Brownian motion $B_t$. Specifically, applying the Itô-Tanaka formula to $|B_t|$ yields $|B_t| = \\int_0^t \\operatorname{sgn}(B_s)dB_s + L^0_t(B)$. The stochastic integral term is a Brownian motion by Lévy's characterization, and $L^0_t(B) = L^0_t(|B|)$, so $|B_t|$ is a solution to the Skorokhod problem. Thus, $\\text{Law}(R_t) = \\text{Law}(|W_t|)$.\n\nOur task reduces to computing $\\mathbb{E}[\\cos(u|W_t|)]$, where $W_t \\sim N(0, t)$.\nThe probability density function of $W_t$ is $f(x) = \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^2}{2t}\\right)$.\n$$\n\\mathbb{E}[\\cos(u|W_t|)] = \\int_{-\\infty}^{\\infty} \\cos(u|x|) \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^2}{2t}\\right) dx\n$$\nSince the cosine function is even, $\\cos(u|x|) = \\cos(ux)$.\n$$\n\\mathbb{E}[\\cos(u|W_t|)] = \\int_{-\\infty}^{\\infty} \\cos(ux) \\frac{1}{\\sqrt{2\\pi t}} \\exp\\left(-\\frac{x^2}{2t}\\right) dx = \\mathbb{E}[\\cos(uW_t)]\n$$\nThis is the real part of the characteristic function of the random variable $W_t \\sim N(0,t)$. The characteristic function of a general normal random variable $Y \\sim N(\\mu, \\sigma^2)$ is $\\phi_Y(\\xi) = \\exp(i\\mu\\xi - \\sigma^2 \\xi^2/2)$. For $W_t$, we have $\\mu=0$ and $\\sigma^2=t$. Its characteristic function at argument $u$ is:\n$$\n\\phi_{W_t}(u) = \\mathbb{E}[\\exp(iuW_t)] = \\exp\\left(-\\frac{t u^2}{2}\\right)\n$$\nThe real part is $\\text{Re}(\\phi_{W_t}(u)) = \\exp(-\\frac{t u^2}{2})$, as the expression is already real-valued.\nTherefore, the characteristic function of $X_t$ is:\n$$\n\\varphi_t(u) = \\exp\\left(-\\frac{t u^2}{2}\\right)\n$$\nThis is the characteristic function of a $N(0,t)$ distribution. This reveals the remarkable result that the solution to the Tanaka SDE is itself a standard Brownian motion.", "answer": "$$\\boxed{\\exp\\left(-\\frac{t u^2}{2}\\right)}$$", "id": "3004600"}, {"introduction": "The failure of the classical Lipschitz condition can lead to a variety of outcomes, depending on the specific interplay between the drift and diffusion terms. This problem [@problem_id:2998962] challenges you to explore the boundaries of uniqueness by contrasting two critical scenarios beyond the standard theory. You will analyze how a uniformly non-degenerate diffusion term can regularize a merely measurable drift to ensure a unique strong solution, and conversely, how a diffusion coefficient that vanishes at a point can break uniqueness, a phenomenon precisely characterized by the Engelbert-Schmidt criterion. This practice will sharpen your ability to diagnose the well-posedness of SDEs with irregular coefficients.", "problem": "Consider the following pair of one-dimensional stochastic differential equations on a filtered probability space carrying a standard Brownian motion $W=(W_t)_{t \\ge 0}$.\n\nCase I (bounded measurable drift, nondegenerate constant diffusion):\n$$\ndX_t \\;=\\; b(X_t)\\,dt \\;+\\; dW_t, \\qquad X_0 \\;=\\; x_0 \\in \\mathbb{R},\n$$\nwhere $b:\\mathbb{R}\\to\\mathbb{R}$ is bounded and Borel measurable. For definiteness, you may keep in mind $b(x) = \\mathbf{1}_{\\{x \\ge 0\\}}$, which is bounded and measurable but discontinuous at $x=0$.\n\nCase II (vanishing diffusion at the origin):\n$$\ndY_t \\;=\\; |Y_t|^{\\alpha}\\, dW_t, \\qquad Y_0 \\;=\\; 0, \\qquad \\alpha \\in (0,\\tfrac{1}{2}).\n$$\n\nRecall the following core notions. A strong solution of an stochastic differential equation (SDE) is an adapted process $(Z_t)_{t\\ge 0}$ defined on a given filtered probability space supporting a given Brownian motion $(W_t)_{t\\ge 0}$ that satisfies the integral equation almost surely. Pathwise uniqueness means that if $(Z_t)_{t\\ge 0}$ and $(\\tilde Z_t)_{t\\ge 0}$ are two solutions driven by the same Brownian motion on the same filtered probability space with the same initial condition, then $\\mathbb{P}(Z_t=\\tilde Z_t \\text{ for all } t\\ge 0)=1$.\n\nSelect all correct statements about strong existence and uniqueness in these two cases.\n\nA. In Case I, for every $x_0 \\in \\mathbb{R}$, pathwise uniqueness holds and there exists a unique strong solution. In Case II with $\\alpha \\in (0,\\tfrac{1}{2})$ and $Y_0=0$, pathwise uniqueness fails.\n\nB. In Case I, because $b$ may be discontinuous, only weak uniqueness can hold; pathwise uniqueness fails in general.\n\nC. In Case II with $\\alpha \\in (0,\\tfrac{1}{2})$ and $Y_0=0$, even weak solutions do not exist.\n\nD. If, in Case I, one replaces the constant diffusion coefficient by a state-dependent diffusion $\\sigma(x)$ that vanishes at some point (for example, $\\sigma(x)=|x|^{\\alpha}$ with $\\alpha \\in (0,\\tfrac{1}{2})$) while keeping $b$ smooth, then pathwise uniqueness can fail.\n\nE. In Case II, if $\\alpha \\ge \\tfrac{1}{2}$, then pathwise uniqueness holds for every initial condition.", "solution": "The user wants an analysis of two one-dimensional stochastic differential equations (SDEs) concerning the existence and uniqueness of strong solutions.\n\n### Problem Validation\nThe problem statement is formally structured and mathematically sound.\n\n**Step 1: Extract Givens**\n-   **Case I SDE:** $dX_t = b(X_t) dt + dW_t$\n-   **Case I Initial Condition:** $X_0 = x_0 \\in \\mathbb{R}$\n-   **Case I Drift:** $b: \\mathbb{R} \\to \\mathbb{R}$ is bounded and Borel measurable. An example is $b(x) = \\mathbf{1}_{\\{x \\ge 0\\}}$.\n-   **Case I Diffusion:** $\\sigma(x) = 1$.\n-   **Case II SDE:** $dY_t = |Y_t|^{\\alpha} dW_t$\n-   **Case II Initial Condition:** $Y_0 = 0$\n-   **Case II Parameter:** $\\alpha \\in (0, \\frac{1}{2})$.\n-   **Definitions:** Strong solution and pathwise uniqueness are provided and conform to standard literature.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem uses standard SDEs that are canonical examples in the study of existence and uniqueness theorems. The concepts and terminology are central to the theory of stochastic calculus. The problem is scientifically and mathematically sound.\n-   **Well-Posed:** The problem provides two distinct cases and asks for an evaluation of several statements. The setup is clear and internally consistent, leading to a definite set of correct/incorrect answers based on established theorems.\n-   **Objective:** The problem is stated in precise mathematical language, free from ambiguity or subjective content.\n\n**Step 3: Verdict and Action**\nThe problem is valid. The analysis will proceed.\n\n### Analysis\n\nThe core of this problem lies in applying known theorems for existence and uniqueness of solutions to SDEs, particularly in situations where the standard global Lipschitz conditions are not met.\n\n**Analysis of Case I**\nThe SDE is $dX_t = b(X_t) dt + dW_t$, with $X_0 = x_0$. The drift coefficient $b(x)$ is bounded and measurable, while the diffusion coefficient $\\sigma(x) = 1$ is constant.\nThe standard existence and uniqueness theorem requires both $b$ and $\\sigma$ to be globally Lipschitz continuous. Here, $\\sigma(x)=1$ is Lipschitz (with constant $0$), but $b(x)$ is not, as exemplified by $b(x) = \\mathbf{1}_{\\{x \\ge 0\\}}$, which is discontinuous.\nHowever, a more powerful result, known as the Zvonkin-Veretennikov theorem, applies here. In one dimension, this theorem states that for an SDE of the form $dX_t = b(X_t)dt + \\sigma(X_t)dW_t$, if:\n1.  The diffusion coefficient $\\sigma(x)$ is bounded, uniformly non-degenerate (i.e., $|\\sigma(x)| \\ge c  0$ for some constant $c$), and sufficiently regular (e.g., Hölder continuous).\n2.  The drift coefficient $b(x)$ is bounded and measurable.\nThen for any initial condition $x_0 \\in \\mathbb{R}$, there exists a unique strong solution.\nIn Case I, $\\sigma(x) = 1$, which is bounded, constant (and thus infinitely differentiable), and uniformly non-degenerate since $|\\sigma(x)| = 1 \\ge 1  0$. The drift $b(x)$ is given as bounded and Borel measurable. All conditions of the theorem are satisfied. Therefore, a unique strong solution exists. The existence of a unique strong solution implies both strong existence and pathwise uniqueness.\n\n**Analysis of Case II**\nThe SDE is $dY_t = |Y_t|^{\\alpha} dW_t$, with $Y_0=0$ and $\\alpha \\in (0, \\frac{1}{2})$. The drift is $b(y)=0$ and the diffusion is $\\sigma(y) = |y|^{\\alpha}$.\nThe drift coefficient $b(y)=0$ is globally Lipschitz. The diffusion coefficient $\\sigma(y)$ is continuous since $\\alpha  0$, but it is not locally Lipschitz at $y=0$ because its formal derivative involves $|y|^{\\alpha-1}$, which blows up as $y\\to 0$ for $\\alpha  1$.\nFor one-dimensional SDEs of the form $dZ_t = \\sigma(Z_t)dW_t$, the Engelbert-Schmidt zero-one law provides a necessary and sufficient condition for pathwise uniqueness. Uniqueness holds for all initial conditions if and only if for every $z \\in \\mathbb{R}$ such that $\\sigma(z)=0$, the following integral condition holds:\n$$\n\\int_{-\\epsilon}^{\\epsilon} \\frac{1}{\\sigma(z+u)^2} du = \\infty\n$$\nfor any $\\epsilon  0$.\nIn Case II, $\\sigma(y) = |y|^\\alpha$ is zero only at $y=0$. We must therefore check the integral condition at $z=0$:\n$$\n\\int_{-\\epsilon}^{\\epsilon} \\frac{1}{\\sigma(u)^2} du = \\int_{-\\epsilon}^{\\epsilon} \\frac{1}{(|u|^{\\alpha})^2} du = \\int_{-\\epsilon}^{\\epsilon} |u|^{-2\\alpha} du = 2 \\int_{0}^{\\epsilon} u^{-2\\alpha} du\n$$\nThis is a standard p-integral. It converges if the exponent $-2\\alpha  -1$, and diverges if $-2\\alpha \\le -1$.\n-   Convergence: $2\\alpha  1 \\iff \\alpha  \\frac{1}{2}$.\n-   Divergence: $2\\alpha \\ge 1 \\iff \\alpha \\ge \\frac{1}{2}$.\nFor Case II, we are given $\\alpha \\in (0, \\frac{1}{2})$, so the integral converges. The failure of the Engelbert-Schmidt condition implies that pathwise uniqueness fails for the initial condition $Y_0=0$. Indeed, $Y_t \\equiv 0$ is a trivial solution, but because the integral converges, non-trivial solutions that start at $0$ and then move away also exist.\n\n### Evaluation of Options\n\n**A. In Case I, for every $x_0 \\in \\mathbb{R}$, pathwise uniqueness holds and there exists a unique strong solution. In Case II with $\\alpha \\in (0,\\tfrac{1}{2})$ and $Y_0=0$, pathwise uniqueness fails.**\n-   The first part is correct, as established by the Zvonkin-Veretennikov theorem.\n-   The second part is correct, as established by the failure of the Engelbert-Schmidt integral condition for $\\alpha  \\frac{1}{2}$.\n-   Verdict: **Correct**.\n\n**B. In Case I, because $b$ may be discontinuous, only weak uniqueness can hold; pathwise uniqueness fails in general.**\n-   This statement is a common misconception. The non-degeneracy of the diffusion coefficient is a powerful regularizing property that ensures strong uniqueness even with a merely measurable and bounded drift. This is precisely the content of the Zvonkin-Veretennikov theorem.\n-   Verdict: **Incorrect**.\n\n**C. In Case II with $\\alpha \\in (0,\\tfrac{1}{2})$ and $Y_0=0$, even weak solutions do not exist.**\n-   This is false. The process $Y_t \\equiv 0$ for all $t \\ge 0$ is a valid solution. Plugging it into the SDE gives $d(0) = |0|^\\alpha dW_t$, which simplifies to $0=0$. Thus, a solution (which is both strong and weak) certainly exists. In fact, the convergence of the Engelbert-Schmidt integral guarantees the existence of non-trivial weak solutions as well.\n-   Verdict: **Incorrect**.\n\n**D. If, in Case I, one replaces the constant diffusion coefficient by a state-dependent diffusion $\\sigma(x)$ that vanishes at some point (for example, $\\sigma(x)=|x|^{\\alpha}$ with $\\alpha \\in (0,\\tfrac{1}{2})$) while keeping $b$ smooth, then pathwise uniqueness can fail.**\n-   This statement claims that uniqueness *can* fail under these conditions, so we only need to provide one example. Consider the SDE $dX_t = b(X_t)dt + \\sigma(X_t)dW_t$. Let's select a smooth drift, for instance $b(x)=0$ for all $x$. This is an infinitely differentiable function. Let's use the suggested diffusion $\\sigma(x)=|x|^\\alpha$ with $\\alpha \\in (0, \\frac{1}{2})$, which vanishes at $x=0$. Let the initial condition be $X_0=0$.\n-   The resulting SDE is $dX_t = |X_t|^\\alpha dW_t$ with $X_0=0$ and $\\alpha \\in (0, \\frac{1}{2})$. This is precisely the SDE from Case II, where we have already established that pathwise uniqueness fails.\n-   Since we have found an instance where the premise holds (smooth drift, vanishing diffusion) and the conclusion is true (pathwise uniqueness fails), the statement is correct.\n-   Verdict: **Correct**.\n\n**E. In Case II, if $\\alpha \\ge \\tfrac{1}{2}$, then pathwise uniqueness holds for every initial condition.**\n-   This modifies Case II by changing the range of $\\alpha$ to $\\alpha \\ge \\frac{1}{2}$. The SDE is $dY_t = |Y_t|^\\alpha dW_t$.\n-   We again use the Engelbert-Schmidt criterion. The only point where the diffusion $\\sigma(y)=|y|^\\alpha$ vanishes is $y=0$. We test the integral $\\int_{-\\epsilon}^{\\epsilon} |u|^{-2\\alpha} du$. As shown before, this integral diverges if $2\\alpha \\ge 1$, i.e., $\\alpha \\ge \\frac{1}{2}$.\n-   Since the condition for pathwise uniqueness holds at the only zero of $\\sigma$, uniqueness is guaranteed for solutions starting at $Y_0=0$.\n-   If the initial condition is $Y_0 \\ne 0$, the solution is unique at least until it first hits zero (if ever), because $\\sigma(y)$ is locally Lipschitz away from zero. If the solution hits zero at some time $\\tau  0$, the strong Markov property of the solution allows us to restart the process at time $\\tau$ with value $0$. Since we have already established uniqueness from the origin, the path remains unique for all subsequent times.\n-   Therefore, pathwise uniqueness holds for every initial condition.\n-   Verdict: **Correct**.", "answer": "$$\\boxed{ADE}$$", "id": "2998962"}]}