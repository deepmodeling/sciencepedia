{"hands_on_practices": [{"introduction": "The first step in mastering curvature is to apply the full computational machinery to a tangible example. This practice guides you through calculating the Ricci scalar for a paraboloid of revolution, a familiar 2D surface embedded in 3D Euclidean space [@problem_id:1076532]. By working from the induced metric through the Christoffel symbols and finally to the Ricci scalar, you will build a foundational understanding of how intrinsic curvature is derived from first principles.", "problem": "Consider a surface in three-dimensional Euclidean space $\\mathbb{R}^3$ defined by the equation of a paraboloid of revolution $z = a(x^2 + y^2)$, where $a$ is a positive constant. The geometry of this two-dimensional surface is described by the induced metric, which is inherited from the standard Euclidean metric $ds^2 = dx^2 + dy^2 + dz^2$ of the ambient space.\n\nThe Ricci scalar, $R$, is a fundamental measure of the intrinsic curvature of a manifold. It is a scalar quantity obtained by contracting the Ricci tensor $R_{\\mu\\nu}$ with the inverse metric tensor $g^{\\mu\\nu}$, according to the formula $R = g^{\\mu\\nu} R_{\\mu\\nu}$ (using the Einstein summation convention). The Ricci tensor is, in turn, constructed from the Christoffel symbols $\\Gamma^\\lambda_{\\mu\\nu}$ and their partial derivatives, as given by the formula:\n$$\nR_{\\mu\\nu} = \\partial_\\lambda \\Gamma^\\lambda_{\\mu\\nu} - \\partial_\\nu \\Gamma^\\lambda_{\\mu\\lambda} + \\Gamma^\\lambda_{\\lambda\\sigma}\\Gamma^\\sigma_{\\mu\\nu} - \\Gamma^\\sigma_{\\nu\\lambda}\\Gamma^\\lambda_{\\mu\\sigma}\n$$\nThe Christoffel symbols of the second kind are defined by the metric tensor $g_{\\mu\\nu}$ as:\n$$\n\\Gamma^\\lambda_{\\mu\\nu} = \\frac{1}{2} g^{\\lambda\\sigma} (\\partial_\\mu g_{\\nu\\sigma} + \\partial_\\nu g_{\\mu\\sigma} - \\partial_\\sigma g_{\\mu\\nu})\n$$\n\nYour task is to derive the Ricci scalar $R$ for this paraboloid. Express your final answer as a function of the radial coordinate $\\rho = \\sqrt{x^2+y^2}$.", "solution": "We parameterize the paraboloid by $(\\rho,\\theta)$ with $x=\\rho\\cos\\theta,\\;y=\\rho\\sin\\theta,\\;z=a\\rho^2$.  Then\n$$ds^2 = d\\rho^2+\\rho^2d\\theta^2+(2a\\rho\\,d\\rho)^2\n=(1+4a^2\\rho^2)d\\rho^2+\\rho^2d\\theta^2$$\nso the metric components are\n$$g_{\\rho\\rho}=A,\\quad g_{\\theta\\theta}=\\rho^2,\\qquad A=1+4a^2\\rho^2.$$\nThus $g^{\\rho\\rho}=1/A,\\;g^{\\theta\\theta}=1/\\rho^2$.  The nonzero Christoffel symbols are\n$$\\Gamma^\\rho_{\\rho\\rho}=\\frac{A'}{2A},\\quad\\Gamma^\\rho_{\\theta\\theta}=-\\frac{\\rho}{A},\\quad\n\\Gamma^\\theta_{\\rho\\theta}=\\frac1\\rho,\\quad A'=\\frac{dA}{d\\rho}=8a^2\\rho.$$\nComputing the Ricci components (in 2D)\n\n$$\nR_{\\rho\\rho}=\\frac{A'}{2A\\rho}\n=\\frac{4a^2}{A},\\qquad\nR_{\\theta\\theta}=\\frac{4a^2\\rho^2}{A^2},\n$$\n\nand contracting with $g^{ij}$ gives\n\n$$\nR=g^{\\rho\\rho}R_{\\rho\\rho}+g^{\\theta\\theta}R_{\\theta\\theta}\n=\\frac{1}{A}\\frac{4a^2}{A}+\\frac{1}{\\rho^2}\\frac{4a^2\\rho^2}{A^2}\n=\\frac{8a^2}{A^2}\n=\\frac{8a^2}{(1+4a^2\\rho^2)^2}.\n$$", "answer": "$$\\boxed{\\frac{8a^2}{(1+4a^2\\rho^2)^2}}$$", "id": "1076532"}, {"introduction": "Building on the foundational 2D case, this exercise increases the complexity by moving to a three-dimensional manifold defined by a non-diagonal metric [@problem_id:1076389]. Calculating components of the Ricci tensor in this context requires careful handling of the inverse metric and a larger set of Christoffel symbols. This problem provides essential practice in the index manipulation required for more general and physically relevant spacetimes where such off-diagonal terms are common.", "problem": "In the context of differential geometry and general relativity, the curvature of a manifold is described by the Riemann curvature tensor and its contractions, the Ricci tensor and Ricci scalar. This problem involves calculating a component of the Ricci tensor for a specific three-dimensional Riemannian manifold.\n\nConsider the manifold $\\mathbb{R}^3$ with coordinates $(x, y, z)$. The geometry of this space is defined by the Riemannian metric given by the line element:\n$$\nds^2 = dx^2 + dy^2 + (x dy + y dz)^2\n$$\nYour task is to calculate the component $R_{xx}$ of the Ricci tensor for this metric.\n\n**Background Formulas:**\n\nLet the coordinates be denoted by $x^\\mu$, where $(x^1, x^2, x^3) = (x, y, z)$. The metric tensor is $g_{\\mu\\nu}$.\n\n1.  The Christoffel symbols of the second kind are given by:\n    $$\n    \\Gamma^\\rho_{\\mu\\nu} = \\frac{1}{2} g^{\\rho\\sigma} \\left( \\frac{\\partial g_{\\nu\\sigma}}{\\partial x^\\mu} + \\frac{\\partial g_{\\mu\\sigma}}{\\partial x^\\nu} - \\frac{\\partial g_{\\mu\\nu}}{\\partial x^\\sigma} \\right)\n    $$\n    where $g^{\\rho\\sigma}$ is the inverse of the metric tensor $g_{\\rho\\sigma}$.\n\n2.  The Ricci tensor $R_{\\mu\\nu}$ is defined in terms of the Christoffel symbols as:\n    $$\n    R_{\\mu\\nu} = \\frac{\\partial \\Gamma^\\rho_{\\mu\\nu}}{\\partial x^\\rho} - \\frac{\\partial \\Gamma^\\rho_{\\mu\\rho}}{\\partial x^\\nu} + \\Gamma^\\rho_{\\rho\\sigma} \\Gamma^\\sigma_{\\mu\\nu} - \\Gamma^\\rho_{\\nu\\sigma} \\Gamma^\\sigma_{\\mu\\rho}\n    $$\n\n**Problem:**\nUsing the formulas provided, derive the analytical expression for the component $R_{xx} \\equiv R_{11}$ of the Ricci tensor for the given metric.", "solution": "We label $(x^1,x^2,x^3)=(x,y,z)$ and compute the metric and its inverse.  From\n$$ds^2=dx^2+dy^2+(x\\,dy+y\\,dz)^2\n=dx^2+(1+x^2)\\,dy^2+2xy\\,dy\\,dz+y^2\\,dz^2$$\nwe read off\n$$g_{11}=1,\\quad g_{22}=1+x^2,\\quad g_{23}=g_{32}=xy,\\quad g_{33}=y^2.$$\nThe $2\\times2$ sub-matrix in $(y,z)$–space has determinant $y^2$, so\n$$g^{11}=1,\\;\ng^{22}=1,\\;g^{23}=-\\frac{x}{y},\\;g^{33}=\\frac{1+x^2}{y^2}.$$\nAll other $g^{\\mu\\nu}=0$.\n\n1.  Christoffel symbols with two “1”–indices vanish:\n    $$\\Gamma^\\rho_{11}=0.$$\n2.  The trace $\\Gamma^\\rho_{1\\rho}=\\Gamma^2_{12}+\\Gamma^3_{13}$.  We find\n    $$\\Gamma^2_{12}=\\frac{x}{2},\\qquad\\Gamma^3_{13}=-\\frac{x}{2},\\quad\n      \\Longrightarrow\\ \\Gamma^\\rho_{1\\rho}=0.$$\n3.  Hence the first two terms in\n    $$R_{11}\n      =\\p_\\rho\\Gamma^\\rho_{11}-\\p_1\\Gamma^\\rho_{1\\rho}\n       +\\Gamma^\\rho_{\\rho\\sigma}\\Gamma^\\sigma_{11}\n       -\\Gamma^\\rho_{1\\sigma}\\Gamma^\\sigma_{1\\rho}$$\n    vanish, and $\\Gamma^\\sigma_{11}=0$, so\n    $$R_{11}=-\\Gamma^\\rho_{1\\sigma}\\,\\Gamma^\\sigma_{1\\rho}.$$\n4.  The only nonzero $\\Gamma^\\rho_{1\\sigma}$ are\n    $$\\Gamma^2_{12}=\\frac{x}{2},\\quad \\Gamma^2_{13}=\\frac{y}{2},\\quad\n      \\Gamma^3_{12}=\\frac{1-x^2}{2y},\\quad \\Gamma^3_{13}=-\\frac{x}{2}.$$\n   Summing over $\\rho,\\sigma$ gives\n    $$\\sum_{\\rho,\\sigma}\\Gamma^\\rho_{1\\sigma}\\Gamma^\\sigma_{1\\rho}\n      =\\Big(\\frac{x}{2}\\Big)^2+\\Big(\\frac{x}{2}\\Big)^2\n       +2\\Big(\\frac{y}{2}\\cdot\\frac{1-x^2}{2y}\\Big)\n      =\\frac12.$$\n   Therefore\n    $$R_{11}=-\\frac12.$$", "answer": "$$\\boxed{-\\frac12}$$", "id": "1076389"}, {"introduction": "While manual calculations are crucial for building intuition, modern research relies heavily on computational methods. This exercise bridges the gap between abstract tensor algebra and practical implementation by asking you to codify the contraction of the Riemann tensor to produce the Ricci tensor [@problem_id:2442518]. By translating the rules of index raising and summation into a program, you will develop the vital skill of automating curvature calculations and verifying them against known analytical results.", "problem": "In computational engineering, the Einstein summation convention provides a coordinate-free way to express tensor operations via index notation. Given a metric tensor $g_{ij}$, its inverse $g^{ij}$ satisfies $g^{ik} g_{kj} = \\delta^{i}{}_{j}$, where $\\delta^{i}{}_{j}$ is the Kronecker delta. Raising and lowering indices is performed via contraction with $g^{ij}$ and $g_{ij}$ respectively. The contraction of a pair of one contravariant index and one covariant index reduces the order of a tensor by $2$ and is the fundamental operation used to obtain the Ricci tensor from the Riemann curvature tensor.\n\nYour task is to write a complete program that constructs, for a small set of test cases, a fully covariant Riemann curvature tensor $R_{l i k j}$ for a space of constant sectional curvature $K$, then computes the Ricci tensor $R_{i j}$ by:\n- First raising the first covariant index of $R_{l i k j}$ with the inverse metric $g^{a l}$ to form the mixed-index tensor $R^{a}{}_{i k j}$ given by $R^{a}{}_{i k j} = g^{a l} R_{l i k j}$, and\n- Then contracting the raised first index with the third covariant index to obtain the rank-$2$ tensor $R_{i j}$.\n\nYou must use the following well-tested formula for the fully covariant Riemann tensor of a constant-curvature space at a point:\n$$\nR_{l i k j} = K \\left( g_{l k} g_{i j} - g_{l j} g_{i k} \\right).\n$$\nUsing only the fundamental rules above, implement the index-raising and contraction steps to compute $R_{i j}$ from $R_{l i k j}$.\n\nFor each test case, compare your computed $R_{i j}$ with the analytical expression for constant-curvature spaces,\n$$\nR_{i j}^{(\\text{expected})} = (n - 1) K \\, g_{i j},\n$$\nwhere $n$ is the dimension of the space. Report whether the maximum absolute difference between your computed $R_{i j}$ and $R_{i j}^{(\\text{expected})}$ is less than or equal to a tolerance $\\tau = 10^{-12}$. Each test case produces a boolean result. Your program must aggregate all boolean results into a single line of output formatted as a comma-separated list enclosed in square brackets, for example, $[ \\text{true}, \\text{false} ]$ but using the exact Python boolean literals.\n\nTest suite specifications:\n- Test case $1$ (general happy path):\n  - Dimension $n = 2$.\n  - Metric $g_{ij} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$.\n  - Curvature $K = \\dfrac{3}{7}$.\n  - Expected $R_{i j}^{(\\text{expected})} = (2 - 1) \\cdot \\dfrac{3}{7} \\, g_{i j} = \\dfrac{3}{7} \\, g_{i j}$.\n- Test case $2$ (nontrivial metric, constant curvature):\n  - Dimension $n = 3$.\n  - Metric $g_{ij} = \\mathrm{diag}(2, 1.5, 0.7) = \\begin{bmatrix} 2 & 0 & 0 \\\\ 0 & 1.5 & 0 \\\\ 0 & 0 & 0.7 \\end{bmatrix}$.\n  - Curvature $K = \\dfrac{1}{3}$.\n  - Expected $R_{i j}^{(\\text{expected})} = (3 - 1) \\cdot \\dfrac{1}{3} \\, g_{i j} = \\dfrac{2}{3} \\, g_{i j}$.\n- Test case $3$ (flat space edge case):\n  - Dimension $n = 2$.\n  - Metric $g_{ij} = \\mathrm{diag}(1.7, 0.9) = \\begin{bmatrix} 1.7 & 0 \\\\ 0 & 0.9 \\end{bmatrix}$.\n  - Curvature $K = 0$.\n  - Expected $R_{i j}^{(\\text{expected})} = (2 - 1) \\cdot 0 \\cdot g_{i j} = 0 \\cdot g_{i j} = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}$.\n- Test case $4$ (boundary dimension $n = 1$):\n  - Dimension $n = 1$.\n  - Metric $g_{ij} = \\begin{bmatrix} 4.2 \\end{bmatrix}$.\n  - Curvature $K = 0.8$.\n  - Expected $R_{i j}^{(\\text{expected})} = (1 - 1) \\cdot 0.8 \\cdot g_{i j} = 0 \\cdot g_{i j} = \\begin{bmatrix} 0 \\end{bmatrix}$.\n\nImplementation requirements:\n- Construct $R_{l i k j}$ via the constant-curvature formula above for each test case using the provided $g_{i j}$ and $K$.\n- Compute $g^{i j}$ as the inverse of $g_{i j}$.\n- Form $R^{a}{}_{i k j} = g^{a l} R_{l i k j}$ and then contract the raised index with the third index to produce $R_{i j}$.\n- For each case, compute the maximum absolute entry-wise difference between $R_{i j}$ and $R_{i j}^{(\\text{expected})}$, and return a boolean indicating whether this difference is less than or equal to $\\tau = 10^{-12}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[True,False,True,True]$.", "solution": "The problem posed is a well-defined exercise in computational tensor algebra, grounded in the principles of differential geometry. It is scientifically sound, self-contained, and algorithmically tractable. Therefore, I will proceed with a full solution.\n\nThe task is to compute the Ricci tensor $R_{ij}$ from the fully covariant Riemann curvature tensor $R_{likj}$ for a space of constant sectional curvature $K$, and to verify this computation against a known analytical formula. We are given the dimension $n$ of the space, the metric tensor $g_{ij}$, and the curvature $K$.\n\nThe process is as follows:\n$1$. Construct the rank-$4$ Riemann tensor $R_{likj}$.\n$2$. Compute the inverse metric tensor $g^{ij}$.\n$3$. Raise the first index of the Riemann tensor to obtain the mixed-index tensor $R^{a}{}_{ikj}$.\n$4$. Contract the first and third indices of $R^{a}{}_{ikj}$ to obtain the rank-$2$ Ricci tensor $R_{ij}$.\n$5$. Compare the computed $R_{ij}$ with the expected analytical result $R_{i j}^{(\\text{expected})} = (n-1) K g_{ij}$.\n\nLet us detail each step of the calculation. We will represent tensors as multi-dimensional arrays, and the Einstein summation convention will be implemented using tensor contraction, for which the `numpy.einsum` function is exceptionally well-suited as it provides a direct mapping from index notation to computation.\n\n**Step 1: Construct the Riemann Curvature Tensor $R_{l i k j}$**\nThe problem provides the formula for the Riemann tensor in a space of constant curvature $K$:\n$$\nR_{l i k j} = K \\left( g_{l k} g_{i j} - g_{l j} g_{i k} \\right)\n$$\nHere, $R_{likj}$ is a rank-$4$ tensor, which we represent as a $4$-dimensional array. The indices $l, i, k, j$ each run from $0$ to $n-1$. The term $g_{lk}g_{ij}$ is the outer product of two metric tensors, which can be constructed computationally. Similarly for $g_{lj}g_{ik}$. In index notation, this is a straightforward composition. Using `einsum`, we can express the two terms as:\n- $g_{lk} g_{ij} \\rightarrow \\text{`np.einsum('lk,ij->likj', g, g)`}$\n- $g_{lj} g_{ik} \\rightarrow \\text{`np.einsum('lj,ik->likj', g, g)`}$\nThe resulting $4$-dimensional arrays are then combined according to the formula to yield $R_{likj}$.\n\n**Step 2: Compute the Inverse Metric Tensor $g^{ij}$**\nThe inverse metric tensor $g^{ij}$ is defined by the relation $g^{ik} g_{kj} = \\delta^{i}{}_{j}$, where $\\delta^{i}{}_{j}$ is the Kronecker delta. This means that the matrix representing $g^{ij}$ is the algebraic inverse of the matrix representing $g_{ij}$. This is a standard linear algebra operation.\n$$\n[g^{ij}] = ([g_{ij}])^{-1}\n$$\n\n**Step 3: Raise the First Index of the Riemann Tensor**\nWe are to compute the mixed tensor $R^{a}{}_{ikj}$ by raising the first index of $R_{likj}$ using the inverse metric. This is a contraction over the first index of $R_{likj}$:\n$$\nR^{a}{}_{i k j} = g^{a l} R_{l i k j}\n$$\nIn Einstein notation, the repeated index $l$ (one contravariant, one covariant) implies summation. This operation contracts the second index of $g^{al}$ with the first index of $R_{likj}$. The resulting tensor has indices $(a, i, k, j)$. Using `einsum`, this transformation is expressed as:\n- $g^{al} R_{likj} \\rightarrow \\text{`np.einsum('al,likj->aikj', g_inv, R)`}$\nwhere `g_inv` is the array for $g^{ij}$ and `R` is the array for $R_{likj}$.\n\n**Step 4: Compute the Ricci Tensor $R_{ij}$ by Contraction**\nThe Ricci tensor $R_{ij}$ is obtained by contracting the first (contravariant) and third (covariant) indices of the mixed Riemann tensor $R^{a}{}_{ikj}$.\n$$\nR_{i j} = R^{k}{}_{i k j}\n$$\nThis involves summing over the index $k$, where it appears in both a contravariant (first) and covariant (third) position. This reduces the rank of the tensor from $4$ to $2$, leaving the free indices $i$ and $j$. The `einsum` expression for this contraction is:\n- $R^{k}{}_{ikj} \\rightarrow \\text{`np.einsum('kikj->ij', R_mixed)`}$\nwhere `R_mixed` is the array for $R^{a}{}_{ikj}$.\n\n**Step 5: Verification**\nFinally, we compute the expected Ricci tensor for a space of constant curvature, given by the formula:\n$$\nR_{i j}^{(\\text{expected})} = (n - 1) K \\, g_{i j}\n$$\nThis is a simple scalar multiplication of the metric tensor $g_{ij}$.\nWe then calculate the maximum absolute difference between the entries of the computed and expected Ricci tensors:\n$$\n\\Delta = \\max_{i,j} | R_{ij} - R_{i j}^{(\\text{expected})} |\n$$\nThe result for each test case is a boolean value, `True` if $\\Delta \\le \\tau$ where the tolerance $\\tau$ is given as $10^{-12}$, and `False` otherwise.\n\nThis series of steps provides a robust and verifiable method to compute the Ricci tensor and validate the result against theory. The use of `einsum` ensures that the implementation stays true to the mathematical formalism of tensor index notation. For the special case of $n=1$, the Riemann tensor $R_{likj}$ is identically zero, because $R_{1111} = K(g_{11}g_{11} - g_{11}g_{11}) = 0$. Consequently, the computed Ricci tensor $R_{11}$ will also be $0$, which matches the expected result $R_{11}^{(\\text{expected})} = (1-1)Kg_{11} = 0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the computational engineering problem of calculating and verifying the Ricci tensor.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: n=2, Euclidean metric\n        {\n            \"n\": 2,\n            \"g\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"K\": 3.0 / 7.0,\n        },\n        # Test case 2: n=3, diagonal metric\n        {\n            \"n\": 3,\n            \"g\": np.array([[2.0, 0.0, 0.0], [0.0, 1.5, 0.0], [0.0, 0.0, 0.7]]),\n            \"K\": 1.0 / 3.0,\n        },\n        # Test case 3: n=2, flat space\n        {\n            \"n\": 2,\n            \"g\": np.array([[1.7, 0.0], [0.0, 0.9]]),\n            \"K\": 0.0,\n        },\n        # Test case 4: n=1, boundary dimension\n        {\n            \"n\": 1,\n            \"g\": np.array([[4.2]]),\n            \"K\": 0.8,\n        },\n    ]\n\n    tolerance = 1e-12\n    results = []\n\n    for case in test_cases:\n        n = case[\"n\"]\n        g = case[\"g\"]\n        K = case[\"K\"]\n\n        # Step 1: Construct the fully covariant Riemann tensor R_likj.\n        # R_likj = K * (g_lk * g_ij - g_lj * g_ik)\n        # The 'einsum' function directly translates index notation to computation.\n        term1 = np.einsum('lk,ij->likj', g, g)\n        term2 = np.einsum('lj,ik->likj', g, g)\n        R_likj = K * (term1 - term2)\n\n        # Step 2: Compute the inverse metric g^ij.\n        # This is the matrix inverse of g_ij.\n        g_inv = np.linalg.inv(g)\n\n        # Step 3: Raise the first index to form the mixed tensor R^a_ikj.\n        # R^a_ikj = g^al * R_likj\n        # This is a contraction over the index 'l'.\n        R_a_ikj = np.einsum('al,likj->aikj', g_inv, R_likj)\n\n        # Step 4: Contract to find the Ricci tensor R_ij.\n        # R_ij = R^k_ikj\n        # This contracts the first ('a', here renamed to 'k') and third ('k') indices.\n        Ricci_computed = np.einsum('kikj->ij', R_a_ikj)\n\n        # Step 5: Compute the expected Ricci tensor for comparison.\n        # R_ij^(expected) = (n - 1) * K * g_ij\n        Ricci_expected = (n - 1) * K * g\n\n        # Step 6: Compare the computed and expected tensors.\n        # Calculate the maximum absolute difference between the two tensors.\n        max_abs_diff = np.max(np.abs(Ricci_computed - Ricci_expected))\n\n        # Check if the difference is within the specified tolerance.\n        is_verified = max_abs_diff <= tolerance\n        results.append(is_verified)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2442518"}]}