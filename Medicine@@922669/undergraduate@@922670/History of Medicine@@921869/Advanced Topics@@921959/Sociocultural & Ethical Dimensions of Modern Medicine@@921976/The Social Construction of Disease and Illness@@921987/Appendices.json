{"hands_on_practices": [{"introduction": "A central argument for the social construction of disease is that diagnostic categories can be unstable, with unclear boundaries. This practice challenges you to move beyond qualitative description and use a standard statistical tool, Cohen’s kappa, to quantitatively measure the degree of agreement between clinicians. By analyzing diagnoses for historically debated conditions like Neurasthenia and Hysteria, you can assess whether these categories were reliable constructs or if their application was closer to chance, providing concrete evidence for their social contingency [@problem_id:4779268].", "problem": "In a hospital archive from the early twentieth century, two clinicians independently assigned diagnoses to $200$ case vignettes into four historically salient categories whose boundaries were widely debated in contemporaneous medical discourse: Neurasthenia (N), Hysteria (H), Melancholia (M), and Alcohol-related illness (A). The intersection counts of their assignments are summarized as the confusion matrix $\\mathbf{C}$, with rows indexing Clinician $1$’s categories in the order $\\{N,H,M,A\\}$ and columns indexing Clinician $2$’s categories in the same order:\n$$\n\\mathbf{C} \\;=\\;\n\\begin{pmatrix}\n35 & 10 & 9 & 6 \\\\\n6 & 30 & 6 & 13 \\\\\n5 & 14 & 20 & 6 \\\\\n4 & 16 & 5 & 15\n\\end{pmatrix}.\n$$\nUsing definitions from elementary probability and the standard construction of chance agreement under independence of raters given fixed marginal distributions, compute Cohen’s $\\kappa$ for these data. Round your final numerical value to four significant figures. Express the result as a dimensionless quantity. Then, based on first principles and historically informed reasoning about category boundaries, determine whether the observed agreement exceeds chance sufficiently to justify a claim of reliable categorization for these four diagnoses.", "solution": "The user has provided a problem that requires the calculation and interpretation of Cohen's kappa, a measure of inter-rater reliability.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- Total number of subjects (case vignettes), $N = 200$.\n- Number of categories, $k = 4$.\n- Categories: Neurasthenia (N), Hysteria (H), Melancholia (M), and Alcohol-related illness (A).\n- Confusion matrix $\\mathbf{C}$ for two clinicians:\n$$\n\\mathbf{C} \\;=\\;\n\\begin{pmatrix}\n35 & 10 & 9 & 6 \\\\\n6 & 30 & 6 & 13 \\\\\n5 & 14 & 20 & 6 \\\\\n4 & 16 & 5 & 15\n\\end{pmatrix}\n$$\n- The rows correspond to Clinician $1$'s ratings and columns to Clinician $2$'s ratings, in the order $\\{N, H, M, A\\}$.\n- The task is to compute Cohen’s $\\kappa$ and round the numerical value to four significant figures.\n- The secondary task is to interpret this value to determine if the categorization can be considered reliable.\n\n**1.2. Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is scientifically grounded. Cohen's kappa is a standard and widely used statistical measure for inter-rater agreement. The context provided—diagnoses from early twentieth-century medicine—is historically plausible. Neurasthenia, Hysteria, and Melancholia were indeed prominent and often overlapping diagnostic categories of that era.\n- **Well-Posedness**: The problem is well-posed. All the necessary data (the confusion matrix and total number of subjects) are provided to calculate Cohen's kappa. The formula for kappa is well-defined. The sum of the elements in the matrix is $35+10+9+6+6+30+6+13+5+14+20+6+4+16+5+15 = 200$, which is consistent with the stated total number of cases $N=200$. A unique numerical solution for $\\kappa$ exists.\n- **Objectivity**: The calculation of $\\kappa$ is an objective mathematical procedure. The interpretative part of the question, while involving conventional benchmarks, is a standard component of applied statistics and does not rely on subjective opinion but on established practice for interpreting the statistic's magnitude.\n- **Flaw Checklist**: The problem does not violate any of the invalidity criteria. It is scientifically sound, formalizable, complete, consistent, realistic, and well-posed.\n\n**1.3. Verdict and Action**\nThe problem is deemed valid. A full solution will be provided.\n\n### Step 2: Solution\n\nCohen's kappa ($\\kappa$) is a statistic that measures inter-rater agreement for categorical items. It is defined as:\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e}\n$$\nwhere $p_o$ is the relative observed agreement among raters (i.e., the proportion of items on which they agree), and $p_e$ is the hypothetical probability of chance agreement.\n\n**2.1. Calculation of Observed Agreement ($p_o$)**\n\nThe observed agreement is the proportion of cases for which both clinicians assigned the same diagnosis. These correspond to the diagonal elements of the confusion matrix $\\mathbf{C}$. The total number of cases is $N = 200$.\n\nLet $C_{ij}$ be the element in the $i$-th row and $j$-th column of $\\mathbf{C}$. The number of agreements is the sum of the diagonal elements:\n$$\n\\text{Agreements} = \\sum_{i=1}^{4} C_{ii} = C_{11} + C_{22} + C_{33} + C_{44}\n$$\n$$\n\\text{Agreements} = 35 + 30 + 20 + 15 = 100\n$$\nThe observed proportional agreement $p_o$ is this sum divided by the total number of cases $N$:\n$$\np_o = \\frac{100}{200} = 0.5\n$$\n\n**2.2. Calculation of Expected Chance Agreement ($p_e$)**\n\nThe expected chance agreement is calculated based on the marginal totals of the confusion matrix. Let $R_i$ be the total for row $i$ (the number of times Clinician $1$ used category $i$) and $K_j$ be the total for column $j$ (the number of times Clinician $2$ used category $j$).\n\nFirst, we compute the row and column totals:\nRow totals (Clinician $1$):\n- $R_1 = 35 + 10 + 9 + 6 = 60$\n- $R_2 = 6 + 30 + 6 + 13 = 55$\n- $R_3 = 5 + 14 + 20 + 6 = 45$\n- $R_4 = 4 + 16 + 5 + 15 = 40$\nThe sum of row totals is $60+55+45+40=200=N$.\n\nColumn totals (Clinician $2$):\n- $K_1 = 35 + 6 + 5 + 4 = 50$\n- $K_2 = 10 + 30 + 14 + 16 = 70$\n- $K_3 = 9 + 6 + 20 + 5 = 40$\n- $K_4 = 6 + 13 + 6 + 15 = 40$\nThe sum of column totals is $50+70+40+40=200=N$.\n\nThe expected number of agreements for category $i$ by chance is $\\frac{R_i K_i}{N}$. The total expected number of agreements is the sum over all categories. The expected proportional agreement, $p_e$, is this total divided by $N$.\n$$\np_e = \\frac{1}{N^2} \\sum_{i=1}^{4} R_i K_i\n$$\nLet's compute the sum of the products of the marginals:\n$$\n\\sum_{i=1}^{4} R_i K_i = (60 \\times 50) + (55 \\times 70) + (45 \\times 40) + (40 \\times 40)\n$$\n$$\n\\sum_{i=1}^{4} R_i K_i = 3000 + 3850 + 1800 + 1600 = 10250\n$$\nNow, we can calculate $p_e$:\n$$\np_e = \\frac{10250}{200^2} = \\frac{10250}{40000} = 0.25625\n$$\n\n**2.3. Calculation of Cohen's Kappa ($\\kappa$)**\n\nUsing the values of $p_o$ and $p_e$, we can compute $\\kappa$:\n$$\n\\kappa = \\frac{p_o - p_e}{1 - p_e} = \\frac{0.5 - 0.25625}{1 - 0.25625}\n$$\n$$\n\\kappa = \\frac{0.24375}{0.74375} \\approx 0.3277310924...\n$$\nRounding the result to four significant figures, as requested:\n$$\n\\kappa \\approx 0.3277\n$$\n\n**2.4. Interpretation of the Result**\n\nThe calculated Cohen's kappa is $\\kappa \\approx 0.3277$. To determine if this value justifies a claim of reliable categorization, we compare it to standard interpretation benchmarks (e.g., those proposed by Landis and Koch, 1977):\n- $0.01 - 0.20$: Slight agreement\n- $0.21 - 0.40$: Fair agreement\n- $0.41 - 0.60$: Moderate agreement\n- $0.61 - 0.80$: Substantial agreement\n- $0.81 - 1.00$: Almost perfect agreement\n\nA kappa value of $0.3277$ falls into the \"Fair agreement\" range. This indicates that the clinicians' agreement is better than what would be expected by chance, but the level of agreement is not strong.\n\nThe problem asks whether this level of agreement is sufficient \"to justify a claim of reliable categorization.\" In fields where diagnostic precision is critical, such as medicine, a \"fair\" level of agreement is generally considered insufficient for establishing a measure as reliable. Reliability typically requires at least \"substantial\" agreement ($\\kappa > 0.6$).\n\nFurthermore, the historical context is crucial. The diagnoses of Neurasthenia, Hysteria, and Melancholia were known in the early twentieth century for their vague and overlapping symptomatology. Neurasthenia was a broad category for fatigue and psychosomatic complaints, Hysteria covered a wide array of neurological and psychological symptoms, and the boundaries between these and Melancholia were notoriously ill-defined. Given these poorly differentiated category boundaries, a low-to-moderate level of inter-rater reliability is precisely what one would predict from a historical perspective. The statistical result quantitatively confirms the qualitative historical understanding of these as \"socially constructed\" or context-dependent diagnostic entities rather than discrete, clearly bounded diseases.\n\nTherefore, the observed agreement, while statistically exceeding chance, is not strong enough to support a claim of reliable categorization for these specific diagnoses from this historical period.", "answer": "$$\\boxed{0.3277}$$", "id": "4779268"}, {"introduction": "Even when a diagnostic test has fixed biological accuracy, its practical meaning is not fixed; it is constructed by the context of its use. This exercise explores how the prevalence of a disease dramatically alters the predictive value of a test, a core concept derived from Bayes' theorem. By calculating the Positive Predictive Value ($PPV$) during both a quiet period and an outbreak, you will see firsthand how the social reality of a positive test—and the public health actions it triggers—depends critically on the wider epidemiological environment [@problem_id:4779273].", "problem": "A public health authority in the mid-twentieth century deploys a mass-screening test for a respiratory illness. The test’s performance was established in clinical trials and is summarized by the following properties: sensitivity is the probability that the test result is positive given that the person truly has the disease, and specificity is the probability that the test result is negative given that the person truly does not have the disease. During a quiet period, the disease prevalence in the screened population is $p_{1} = 0.02$. During an outbreak, the prevalence rises to $p_{2} = 0.25$. The test’s sensitivity and specificity are constant across periods at $\\text{Se} = 0.93$ and $\\text{Sp} = 0.96$.\n\nIn the authority’s policy, a person is labeled a “presumptive case” and isolated if the posterior probability of disease conditional on a positive test result meets or exceeds a decision threshold $\\tau = 0.70$. This labeling is consequential and illustrates how diagnostic classifications shape social reality and resource allocation.\n\nStarting from the core definitions of sensitivity, specificity, and prevalence, and using foundational probability laws, derive the expressions needed to compute the Positive Predictive Value (PPV) and Negative Predictive Value (NPV) for each period, and then evaluate them numerically for the parameters above. Based on these values, determine whether the isolation policy would be triggered in each period by checking whether $PPV \\geq \\tau$.\n\nReport your final answer as a single row matrix in the order $\\left(PPV_{\\text{baseline}}, NPV_{\\text{baseline}}, I_{\\text{baseline}}, PPV_{\\text{outbreak}}, NPV_{\\text{outbreak}}, I_{\\text{outbreak}}\\right)$, where $I$ equals $1$ if the policy triggers isolation and $0$ otherwise. Express $PPV$ and $NPV$ as decimals and round each to four significant figures.", "solution": "The problem is first subjected to validation.\n\n**Step 1: Extract Givens**\n- Sensitivity of the test, $\\text{Se} = 0.93$. This is the probability of a positive test result given the person has the disease.\n- Specificity of the test, $\\text{Sp} = 0.96$. This is the probability of a negative test result given the person does not have the disease.\n- Disease prevalence during a quiet period (baseline), $p_{1} = 0.02$.\n- Disease prevalence during an outbreak, $p_{2} = 0.25$.\n- Decision threshold for labeling a \"presumptive case\", $\\tau = 0.70$.\n- Policy trigger condition: The posterior probability of disease given a positive test result is greater than or equal to $\\tau$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It is based on standard principles of probability theory, specifically Bayesian inference, as applied to medical diagnostics. The concepts of sensitivity, specificity, prevalence, Positive Predictive Value (PPV), and Negative Predictive Value (NPV) are foundational in epidemiology and public health. All necessary data are provided, the terminology is precise, and the goals are clearly defined. The numerical values are realistic for a diagnostic test. The problem does not violate any of the criteria for invalidity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full solution will be provided.\n\nLet $D$ denote the event that a person has the disease, and let $D^c$ denote the event that the person does not have the disease. Let $T^+$ be the event of a positive test result, and $T^-$ be the event of a negative test result. Let $p$ represent the prevalence of the disease, so $P(D) = p$.\n\nFrom the problem statement, we have the following conditional probabilities:\n- Sensitivity: $\\text{Se} = P(T^+ | D) = 0.93$\n- Specificity: $\\text{Sp} = P(T^- | D^c) = 0.96$\n\nFrom these, we can derive the probabilities of the complementary events:\n- False Negative Rate: $P(T^- | D) = 1 - P(T^+ | D) = 1 - \\text{Se} = 1 - 0.93 = 0.07$\n- False Positive Rate: $P(T^+ | D^c) = 1 - P(T^- | D^c) = 1 - \\text{Sp} = 1 - 0.96 = 0.04$\n\nThe Positive Predictive Value (PPV) is the posterior probability of having the disease given a positive test result, $P(D | T^+)$. We derive its formula using Bayes' theorem:\n$$PPV = P(D | T^+) = \\frac{P(T^+ | D) P(D)}{P(T^+)}$$\nThe denominator, $P(T^+)$, is the total probability of a positive test, found using the law of total probability:\n$$P(T^+) = P(T^+ | D) P(D) + P(T^+ | D^c) P(D^c)$$\n$$P(T^+) = (\\text{Se})(p) + (1 - \\text{Sp})(1 - p)$$\nSubstituting this into the PPV formula gives the general expression:\n$$PPV = \\frac{(\\text{Se})(p)}{(\\text{Se})(p) + (1 - \\text{Sp})(1 - p)}$$\n\nThe Negative Predictive Value (NPV) is the posterior probability of not having the disease given a negative test result, $P(D^c | T^-)$. Using Bayes' theorem again:\n$$NPV = P(D^c | T^-) = \\frac{P(T^- | D^c) P(D^c)}{P(T^-)}$$\nThe denominator, $P(T^-)$, is the total probability of a negative test:\n$$P(T^-) = P(T^- | D) P(D) + P(T^- | D^c) P(D^c)$$\n$$P(T^-) = (1 - \\text{Se})(p) + (\\text{Sp})(1 - p)$$\nSubstituting this into the NPV formula gives the general expression:\n$$NPV = \\frac{(\\text{Sp})(1 - p)}{(1 - \\text{Se})(p) + (\\text{Sp})(1 - p)}$$\n\nNow, we evaluate these expressions for the two specified periods.\n\n**Baseline Period (Quiet)**\nHere, the prevalence is $p = p_1 = 0.02$. Consequently, $1 - p_1 = 0.98$.\nThe PPV for the baseline period is:\n$$PPV_{\\text{baseline}} = \\frac{(0.93)(0.02)}{(0.93)(0.02) + (0.04)(0.98)} = \\frac{0.0186}{0.0186 + 0.0392} = \\frac{0.0186}{0.0578} \\approx 0.32180$$\nRounded to four significant figures, $PPV_{\\text{baseline}} = 0.3218$.\n\nThe NPV for the baseline period is:\n$$NPV_{\\text{baseline}} = \\frac{(0.96)(0.98)}{(0.07)(0.02) + (0.96)(0.98)} = \\frac{0.9408}{0.0014 + 0.9408} = \\frac{0.9408}{0.9422} \\approx 0.99851$$\nRounded to four significant figures, $NPV_{\\text{baseline}} = 0.9985$.\n\nTo determine if the isolation policy is triggered, we compare $PPV_{\\text{baseline}}$ to the threshold $\\tau = 0.70$:\n$$0.3218 < 0.70$$\nSince the PPV is less than the threshold, the isolation policy is not triggered. We assign $I_{\\text{baseline}} = 0$.\n\n**Outbreak Period**\nHere, the prevalence is $p = p_2 = 0.25$. Consequently, $1 - p_2 = 0.75$.\nThe PPV for the outbreak period is:\n$$PPV_{\\text{outbreak}} = \\frac{(0.93)(0.25)}{(0.93)(0.25) + (0.04)(0.75)} = \\frac{0.2325}{0.2325 + 0.03} = \\frac{0.2325}{0.2625} \\approx 0.88571$$\nRounded to four significant figures, $PPV_{\\text{outbreak}} = 0.8857$.\n\nThe NPV for the outbreak period is:\n$$NPV_{\\text{outbreak}} = \\frac{(0.96)(0.75)}{(0.07)(0.25) + (0.96)(0.75)} = \\frac{0.72}{0.0175 + 0.72} = \\frac{0.72}{0.7375} \\approx 0.97627$$\nRounded to four significant figures, $NPV_{\\text{outbreak}} = 0.9763$.\n\nTo determine if the isolation policy is triggered, we compare $PPV_{\\text{outbreak}}$ to the threshold $\\tau = 0.70$:\n$$0.8857 \\geq 0.70$$\nSince the PPV meets or exceeds the threshold, the isolation policy is triggered. We assign $I_{\\text{outbreak}} = 1$.\n\nThe final results are assembled into the required matrix format.\n$PPV_{\\text{baseline}} = 0.3218$\n$NPV_{\\text{baseline}} = 0.9985$\n$I_{\\text{baseline}} = 0$\n$PPV_{\\text{outbreak}} = 0.8857$\n$NPV_{\\text{outbreak}} = 0.9763$\n$I_{\\text{outbreak}} = 1$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.3218 & 0.9985 & 0 & 0.8857 & 0.9763 & 1\n\\end{pmatrix}\n}\n$$", "id": "4779273"}, {"introduction": "Disease categories are not static; they are actively revised by medical and public health authorities, sometimes reclassifying millions of people overnight. This hands-on practice uses the famous 2017 change in the definition of hypertension to model the profound social and clinical consequences of shifting a diagnostic threshold. You will use fundamental epidemiological tools to quantify both the massive increase in disease prevalence and the resulting public health trade-offs, such as the number of events prevented versus the number of people who must be treated [@problem_id:4779264].", "problem": "A central claim in the social construction of disease and illness is that diagnostic thresholds are human-defined conventions that reclassify bodies and behaviors, thereby changing who counts as ill without any immediate physiological shift in the population. To operationalize this claim using epidemiological first principles, consider a population of $100{,}000$ adults and a policy change in $2017$ that shifted the diagnostic threshold for hypertension from $140/90$ mmHg to $130/80$ mmHg. Use the following scientifically plausible and internally consistent assumptions.\n\nFundamental base and definitions to use:\n- Prevalence is defined as the proportion of individuals in a population who meet a diagnostic criterion at a point in time. If $n$ individuals meet the criterion out of $N$ total, then prevalence is $n/N$.\n- Absolute risk reduction (ARR) for an individual receiving an effective treatment over a fixed time horizon is the untreated baseline risk multiplied by the relative risk reduction (RRR). If the untreated risk over the horizon is $r$ and the relative risk reduction is $\\rho$, then $\\text{ARR} = r \\times \\rho$.\n- Number needed to treat (NNT) over the same time horizon is defined as $\\text{NNT} = 1/\\text{ARR}$.\n- Expected events prevented in a subgroup over the time horizon equal the number treated times the ARR in that subgroup.\n\nPopulation structure and risk data (assume these are stable over the $5$-year horizon, and risks are per person over $5$ years):\n- Blood pressure categories and counts under the pre-policy population distribution:\n  - Category $\\mathrm{A}$: blood pressure $<130/80$ mmHg, $50{,}000$ adults, baseline $5$-year cardiovascular event risk $r_{\\mathrm{A}} = 0.02$ (no pharmacotherapy in any scenario).\n  - Category $\\mathrm{B}$: blood pressure $130$–$139/80$–$89$ mmHg, $30{,}000$ adults, baseline $5$-year risk $r_{\\mathrm{B}} = 0.05$.\n  - Category $\\mathrm{C}$: blood pressure $\\ge 140/90$ mmHg, $20{,}000$ adults, baseline $5$-year risk $r_{\\mathrm{C}} = 0.10$.\n- Under the pre-$2017$ policy ($140/90$ mmHg threshold):\n  - Only Category $\\mathrm{C}$ is labeled hypertensive; of these, a fraction $c_{\\mathrm{C,old}} = 0.70$ receive and adhere to pharmacotherapy that confers a relative risk reduction $\\rho_{\\mathrm{C}} = 0.20$ over $5$ years.\n- Under the post-$2017$ policy ($130/80$ mmHg threshold):\n  - Both Category $\\mathrm{B}$ and Category $\\mathrm{C}$ are labeled hypertensive.\n  - In Category $\\mathrm{C}$, a fraction $c_{\\mathrm{C,new}} = 0.80$ receive and adhere to pharmacotherapy with the same $\\rho_{\\mathrm{C}} = 0.20$.\n  - In Category $\\mathrm{B}$, only a fraction $t_{\\mathrm{B}} = 0.40$ meet overall risk criteria for pharmacotherapy; among these eligible, a fraction $c_{\\mathrm{B}} = 0.60$ receive and adhere to pharmacotherapy that confers a relative risk reduction $\\rho_{\\mathrm{B}} = 0.12$ over $5$ years. Those in Category $\\mathrm{B}$ not treated receive lifestyle advice with negligible $5$-year relative risk reduction (assume $0$ for this analysis).\n\nAssume that classification does not change baseline risks within categories, that the only effect of policy is to change diagnosis labels and treatment uptake as described, and that treatment effects are independent and multiplicative only with risk (no spillovers across categories).\n\nTask:\n- Use the above definitions to derive the change in hypertension prevalence when moving from the $140/90$ mmHg threshold to the $130/80$ mmHg threshold.\n- Derive the number needed to treat for pharmacotherapy among treated individuals in Category $\\mathrm{B}$ over the $5$-year horizon.\n- Then compute the additional number of cardiovascular events prevented over $5$ years per $100{,}000$ adults when adopting the post-$2017$ policy instead of the pre-$2017$ policy. This is defined as the total expected events prevented under the post-$2017$ policy minus the total expected events prevented under the pre-$2017$ policy.\n\nReport only the final quantity: the additional number of events prevented per $100{,}000$ adults over $5$ years. Round your final answer to three significant figures, and express it in units of events per $100{,}000$ adults over $5$ years.", "solution": "The problem is scientifically grounded, well-posed, and objective. It presents a quantitative model to evaluate the public health consequences of changing a diagnostic threshold, a common practice in medicine. The provided data are internally consistent and sufficient for a unique solution. The problem is therefore deemed valid and can be solved as stated.\n\nThe objective is to calculate the additional number of cardiovascular events prevented over a $5$-year period in a population of $100,000$ adults due to a policy change that lowered the diagnostic threshold for hypertension. This requires calculating the total expected events prevented under both the pre-$2017$ and post-$2017$ policies and then finding the difference.\n\nFirst, we analyze the pre-$2017$ policy, where the hypertension threshold is $\\ge 140/90$ mmHg. Under this policy, only individuals in Category $\\mathrm{C}$ are diagnosed as hypertensive and considered for treatment.\nLet $N$ be the total population size, $N=100,000$. The number of individuals in Category $\\mathrm{C}$ is $N_{\\mathrm{C}} = 20,000$.\nThe fraction of this group that receives and adheres to pharmacotherapy is $c_{\\mathrm{C,old}} = 0.70$.\nThe number of treated individuals in Category $\\mathrm{C}$ under the old policy is:\n$$N_{\\mathrm{C, treated, old}} = N_{\\mathrm{C}} \\times c_{\\mathrm{C,old}} = 20,000 \\times 0.70 = 14,000$$\nThe baseline $5$-year cardiovascular event risk for an individual in Category $\\mathrm{C}$ is $r_{\\mathrm{C}} = 0.10$. The relative risk reduction (RRR) from treatment is $\\rho_{\\mathrm{C}} = 0.20$.\nThe absolute risk reduction (ARR) for a treated individual in this category is defined as $\\text{ARR} = r \\times \\rho$:\n$$\\text{ARR}_{\\mathrm{C}} = r_{\\mathrm{C}} \\times \\rho_{\\mathrm{C}} = 0.10 \\times 0.20 = 0.02$$\nThe total expected number of events prevented over $5$ years under the pre-$2017$ policy is the number of treated individuals multiplied by the ARR for that group:\n$$E_{\\text{prevented, pre}} = N_{\\mathrm{C, treated, old}} \\times \\text{ARR}_{\\mathrm{C}} = 14,000 \\times 0.02 = 280$$\n\nNext, we analyze the post-$2017$ policy, where the threshold is lowered to $\\ge 130/80$ mmHg. Now, individuals in both Category $\\mathrm{B}$ and Category $\\mathrm{C}$ are diagnosed as hypertensive. We calculate the events prevented in each category separately.\n\nFor Category $\\mathrm{C}$, the number of individuals remains $N_{\\mathrm{C}} = 20,000$. The fraction treated increases to $c_{\\mathrm{C,new}} = 0.80$.\nThe number of treated individuals in Category $\\mathrm{C}$ under the new policy is:\n$$N_{\\mathrm{C, treated, new}} = N_{\\mathrm{C}} \\times c_{\\mathrm{C,new}} = 20,000 \\times 0.80 = 16,000$$\nThe ARR for this group remains the same, $\\text{ARR}_{\\mathrm{C}} = 0.02$.\nThe expected events prevented in Category $\\mathrm{C}$ under the new policy is:\n$$E_{\\text{prevented, C, new}} = N_{\\mathrm{C, treated, new}} \\times \\text{ARR}_{\\mathrm{C}} = 16,000 \\times 0.02 = 320$$\n\nFor Category $\\mathrm{B}$, the number of individuals is $N_{\\mathrm{B}} = 30,000$. Of these, a fraction $t_{\\mathrm{B}} = 0.40$ are eligible for pharmacotherapy. Among those eligible, a fraction $c_{\\mathrm{B}} = 0.60$ receive and adhere to treatment.\nThe total number of treated individuals in Category $\\mathrm{B}$ is:\n$$N_{\\mathrm{B, treated}} = N_{\\mathrm{B}} \\times t_{\\mathrm{B}} \\times c_{\\mathrm{B}} = 30,000 \\times 0.40 \\times 0.60 = 12,000 \\times 0.60 = 7,200$$\nThe baseline $5$-year risk for an individual in Category $\\mathrm{B}$ is $r_{\\mathrm{B}} = 0.05$. The RRR from treatment is $\\rho_{\\mathrm{B}} = 0.12$.\nThe ARR for a treated individual in this new group is:\n$$\\text{ARR}_{\\mathrm{B}} = r_{\\mathrm{B}} \\times \\rho_{\\mathrm{B}} = 0.05 \\times 0.12 = 0.006$$\nThe expected events prevented in Category $\\mathrm{B}$ under the new policy is:\n$$E_{\\text{prevented, B, new}} = N_{\\mathrm{B, treated}} \\times \\text{ARR}_{\\mathrm{B}} = 7,200 \\times 0.006 = 43.2$$\n\nThe total expected number of events prevented under the post-$2017$ policy is the sum of events prevented in both categories:\n$$E_{\\text{prevented, post}} = E_{\\text{prevented, C, new}} + E_{\\text{prevented, B, new}} = 320 + 43.2 = 363.2$$\n\nThe problem asks for three derivations. We address the first two before the final calculation.\n1.  **Change in hypertension prevalence:**\n    Pre-policy prevalence: $P_{\\text{pre}} = \\frac{N_{\\mathrm{C}}}{N} = \\frac{20,000}{100,000} = 0.20$.\n    Post-policy prevalence: $P_{\\text{post}} = \\frac{N_{\\mathrm{B}} + N_{\\mathrm{C}}}{N} = \\frac{30,000 + 20,000}{100,000} = 0.50$.\n    The change is an increase of $0.30$, or $30$ percentage points.\n\n2.  **Number needed to treat (NNT) for Category B:**\n    The NNT is the reciprocal of the ARR. For treated individuals in Category B:\n    $$\\text{NNT}_{\\mathrm{B}} = \\frac{1}{\\text{ARR}_{\\mathrm{B}}} = \\frac{1}{0.006} = \\frac{1000}{6} \\approx 166.7$$\n    Thus, one must treat approximately $167$ individuals in Category $\\mathrm{B}$ for $5$ years to prevent one cardiovascular event.\n\nFinally, we compute the primary quantity of interest: the additional number of cardiovascular events prevented due to the policy change. This is the difference between the events prevented under the post-$2017$ and pre-$2017$ policies.\n$$\\Delta E_{\\text{prevented}} = E_{\\text{prevented, post}} - E_{\\text{prevented, pre}} = 363.2 - 280 = 83.2$$\nThe additional number of events prevented over $5$ years per $100,000$ adults is $83.2$. The problem requires this to be rounded to three significant figures, which it already is.", "answer": "$$\\boxed{83.2}$$", "id": "4779264"}]}