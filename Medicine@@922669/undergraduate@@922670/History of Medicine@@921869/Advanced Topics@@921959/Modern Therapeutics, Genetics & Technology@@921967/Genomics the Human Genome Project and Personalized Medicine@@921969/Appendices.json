{"hands_on_practices": [{"introduction": "The Human Genome Project's success hinged on our ability to read DNA sequences accurately. This practice delves into the Phred quality score, the universal standard for quantifying the confidence in each base called by a sequencer. By working through this problem, you will learn to translate the abstract logarithmic Phred score into a tangible error probability and estimate the number of errors in a real-world genomic dataset, a fundamental skill in assessing the quality of genomic data. [@problem_id:4747031]", "problem": "In the historical transition from the Human Genome Project (HGP) to modern personalized medicine, base-calling accuracy in DNA sequencing became central. A standard measure of base-call confidence is the Phred quality score, defined as follows: by definition, the Phred quality score $Q$ of a base call is related to its base-calling error probability $p$ by $Q=-10\\log_{10}(p)$. Consider a whole-genome sequencing dataset used to inform a personalized medicine decision. The dataset contains a total of $N=3.20\\times 10^{9}$ called bases, and its mean Phred quality score is $Q=35$. For the purpose of this calculation, assume that each base has the same error probability implied by this mean quality score and that base-calling errors across sites are independent. Using only the above definition and basic probability, compute the expected number of erroneous base calls in the dataset. Express your final answer as a pure number (no units), in scientific notation, rounded to three significant figures.", "solution": "The problem requires the calculation of the expected number of erroneous base calls in a genomic dataset. The solution proceeds from the fundamental definitions and principles provided.\n\nFirst, we are given the definition of the Phred quality score, $Q$, as a function of the base-calling error probability, $p$:\n$$Q = -10\\log_{10}(p)$$\nThe problem states that the dataset contains a total of $N = 3.20 \\times 10^{9}$ called bases and has a mean Phred score of $Q = 35$. A key assumption is provided for this calculation: we are to treat each base as having the same error probability $p$ that corresponds to this mean score.\n\nOur first step is to determine this error probability $p$. We can algebraically manipulate the definition of $Q$ to solve for $p$.\n$$-\\frac{Q}{10} = \\log_{10}(p)$$\nBy the definition of a logarithm, this is equivalent to:\n$$p = 10^{-Q/10}$$\nSubstituting the given value of $Q = 35$:\n$$p = 10^{-35/10} = 10^{-3.5}$$\n\nNext, we must determine the expected number of errors. The problem states that base-calling errors across sites are independent. Therefore, the process of calling $N$ bases can be modeled as a sequence of $N$ independent Bernoulli trials. In each trial, the outcome is either an error (with probability $p$) or a correct call (with probability $1-p$). The total number of errors in the dataset, let's call it a random variable $X$, follows a binomial distribution, $X \\sim B(N, p)$.\n\nThe expected value of a binomially distributed random variable is given by the product of the number of trials, $N$, and the probability of success in each trial, $p$. In this context, the \"success\" is a base-calling error. Therefore, the expected number of erroneous base calls, $E[X]$, is:\n$$E[X] = Np$$\n\nWe can now substitute the given value for $N$ and the calculated value for $p$ into this formula:\n$$E[X] = (3.20 \\times 10^9) \\times 10^{-3.5}$$\nTo facilitate the calculation, we combine the powers of $10$:\n$$E[X] = 3.20 \\times 10^{(9 - 3.5)} = 3.20 \\times 10^{5.5}$$\nTo express this in standard scientific notation ($a \\times 10^b$ where $1 \\le |a|  10$), we can rewrite $10^{5.5}$ as $10^{0.5} \\times 10^5$, which is $\\sqrt{10} \\times 10^5$.\n$$E[X] = 3.20 \\times \\sqrt{10} \\times 10^5$$\nThe numerical value of $\\sqrt{10}$ is approximately $3.16227766$.\n$$E[X] \\approx 3.20 \\times 3.16227766 \\times 10^5$$\n$$E[X] \\approx 10.1192885 \\times 10^5$$\nConverting this to standard scientific notation:\n$$E[X] \\approx 1.01192885 \\times 10^6$$\nThe problem requires the final answer to be rounded to three significant figures. The first three significant figures are $1.01$. The fourth significant figure is $1$, which is less than $5$, so we round down.\n$$E[X] \\approx 1.01 \\times 10^6$$\nThus, the expected number of erroneous base calls in the dataset is approximately $1.01 \\times 10^6$.", "answer": "$$\\boxed{1.01 \\times 10^6}$$", "id": "4747031"}, {"introduction": "Beyond the quality of individual base calls, ensuring the accuracy of genotyping across a whole study population is critical. This exercise introduces Hardy-Weinberg Equilibrium (HWE), a cornerstone principle of population genetics that describes an idealized state for allele and genotype frequencies. You will practice using HWE to calculate expected genotype counts and then apply the chi-squared test to see if observed data fit this expectation, a standard method for quality control in genetic studies. [@problem_id:4747024]", "problem": "In the wake of the Human Genome Project (HGP), population allele frequencies became widely available, enabling quality assessment of genotyping data in pharmacogenomics and personalized medicine. Consider a single nucleotide polymorphism (SNP) in a pharmacogene relevant to drug metabolism, with two alleles $A$ and $a$. In a cohort of $N=1000$ individuals of matched ancestry, genotyping yields observed counts $O_{AA}=120$, $O_{Aa}=460$, and $O_{aa}=420$. From an external HGP-derived reference panel for the same ancestry, suppose the allele frequency of $A$ in the underlying population is $p=0.35$. Under Hardy–Weinberg equilibrium (HWE), compute the expected genotype frequencies using $p$ and use them to derive expected counts. Then, use the chi-squared test to assess deviation from HWE by computing\n$$\\chi^{2}=\\sum_{g \\in \\{AA,Aa,aa\\}} \\frac{(O_{g}-E_{g})^{2}}{E_{g}},$$\nwhere $E_{g}$ are the HWE-expected counts. State clearly the biological and statistical assumptions that justify using HWE and the chi-squared test in this setting, including whether $p$ is treated as known or estimated and the implications for degrees of freedom. Report only the value of the chi-squared statistic, rounded to $4$ significant figures, as a pure number without units.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of population genetics and biostatistics, specifically the Hardy–Weinberg Equilibrium (HWE) model and the chi-squared goodness-of-fit test. The problem is well-posed, objective, and provides all necessary data for a unique solution.\n\nFirst, we address the biological and statistical assumptions that justify the application of the HWE principle and the chi-squared test.\n\nThe biological assumptions for a population to be in Hardy–Weinberg Equilibrium are:\n1.  The organism is diploid.\n2.  Reproduction is sexual.\n3.  Generations are non-overlapping.\n4.  Mating is random (panmixia) with respect to the locus in question.\n5.  The population size is infinitely large, meaning genetic drift is negligible.\n6.  There is no gene flow (migration) into or out of the population.\n7.  There is no mutation at the locus.\n8.  There is no natural selection; all genotypes have equal viability and fertility.\nIn the context of pharmacogenomics quality control, a significant deviation from HWE in a control population of matched ancestry can suggest genotyping errors, such as misclassification of heterozygotes, or population stratification not accounted for by the \"matched ancestry\" description.\n\nThe statistical assumptions for the Pearson's chi-squared ($\\chi^2$) goodness-of-fit test are:\n1.  The data are raw counts organized into discrete, non-overlapping categories (in this case, the genotypes $AA$, $Aa$, and $aa$).\n2.  The observations are independent. The genotype of one individual in the cohort does not influence the genotype of another.\n3.  The sample size is sufficiently large such that the expected count in each category ($E_g$) is not too small. A common guideline is that all expected counts should be greater than $5$.\n\nA crucial point in this problem is the source of the allele frequency $p$. The problem states that the frequency of allele $A$, $p=0.35$, is derived from an external HGP-derived reference panel, not estimated from the sample cohort of $N=1000$ individuals. This has a direct implication for the degrees of freedom ($df$) of the $\\chi^2$ test. The formula for degrees of freedom is $df = k - 1 - m$, where $k$ is the number of categories and $m$ is the number of parameters estimated from the data to generate the expected frequencies. Here, we have $k=3$ genotype categories ($AA$, $Aa$, $aa$). Since the allele frequency $p$ is treated as a known constant, no parameters are estimated from the sample data, so $m=0$. Therefore, the correct number of degrees of freedom for this test is $df = 3 - 1 - 0 = 2$.\n\nNow, we proceed with the calculation of the $\\chi^2$ statistic.\n\nThe given data are:\n-   Total sample size: $N = 1000$\n-   Observed genotype counts: $O_{AA} = 120$, $O_{Aa} = 460$, $O_{aa} = 420$. The sum is $120 + 460 + 420 = 1000$, which matches $N$.\n-   Population frequency of allele $A$: $p = 0.35$.\n\nThe frequency of allele $a$ must be $q = 1 - p$.\n$$q = 1 - 0.35 = 0.65$$\n\nUnder HWE, the expected genotype frequencies are given by $p^2$ for $AA$, $2pq$ for $Aa$, and $q^2$ for $aa$.\n-   Expected frequency of $AA$: $f_{AA} = p^2 = (0.35)^2 = 0.1225$.\n-   Expected frequency of $Aa$: $f_{Aa} = 2pq = 2 \\times 0.35 \\times 0.65 = 0.455$.\n-   Expected frequency of $aa$: $f_{aa} = q^2 = (0.65)^2 = 0.4225$.\nWe can check that these frequencies sum to $1$: $0.1225 + 0.455 + 0.4225 = 1$.\n\nNext, we calculate the expected counts ($E_g$) for each genotype in a sample of size $N=1000$.\n-   Expected count of $AA$: $E_{AA} = N \\times f_{AA} = 1000 \\times 0.1225 = 122.5$.\n-   Expected count of $Aa$: $E_{Aa} = N \\times f_{Aa} = 1000 \\times 0.455 = 455$.\n-   Expected count of $aa$: $E_{aa} = N \\times f_{aa} = 1000 \\times 0.4225 = 422.5$.\nThe sum of expected counts is $122.5 + 455 + 422.5 = 1000$, matching $N$. All expected counts are well above $5$, satisfying the assumption for the $\\chi^2$ test.\n\nWe can now compute the $\\chi^2$ statistic using the formula:\n$$\\chi^{2}=\\sum_{g \\in \\{AA,Aa,aa\\}} \\frac{(O_{g}-E_{g})^{2}}{E_{g}}$$\n\nSubstituting the observed ($O_g$) and expected ($E_g$) values:\n$$\\chi^{2} = \\frac{(O_{AA}-E_{AA})^{2}}{E_{AA}} + \\frac{(O_{Aa}-E_{Aa})^{2}}{E_{Aa}} + \\frac{(O_{aa}-E_{aa})^{2}}{E_{aa}}$$\n$$\\chi^{2} = \\frac{(120 - 122.5)^{2}}{122.5} + \\frac{(460 - 455)^{2}}{455} + \\frac{(420 - 422.5)^{2}}{422.5}$$\n$$\\chi^{2} = \\frac{(-2.5)^{2}}{122.5} + \\frac{(5)^{2}}{455} + \\frac{(-2.5)^{2}}{422.5}$$\n$$\\chi^{2} = \\frac{6.25}{122.5} + \\frac{25}{455} + \\frac{6.25}{422.5}$$\n\nNow we compute the value of each term:\n-   First term: $\\frac{6.25}{122.5} \\approx 0.0510204$\n-   Second term: $\\frac{25}{455} \\approx 0.0549451$\n-   Third term: $\\frac{6.25}{422.5} \\approx 0.0147929$\n\nSumming the terms gives the $\\chi^2$ value:\n$$\\chi^{2} \\approx 0.0510204 + 0.0549451 + 0.0147929 = 0.1207584$$\n\nThe problem requires the answer to be rounded to $4$ significant figures.\n$$\\chi^{2} \\approx 0.1208$$", "answer": "$$\\boxed{0.1208}$$", "id": "4747024"}, {"introduction": "The ultimate goal of sequencing is to understand the functional and clinical meaning of genetic variants, but this interpretation is highly context-dependent. This problem explores the historical ambiguity between the terms \"mutation\" and \"polymorphism\" and how large-scale population data has reshaped our understanding. By analyzing hypothetical data from different populations, you will see how a variant's frequency can dramatically alter its classification and its contribution to disease, highlighting why personalized medicine demands a nuanced, data-driven approach. [@problem_id:4747042]", "problem": "A clinical genetics team, working in the post–Human Genome Project (Human Genome Project (HGP)) era with access to large population reference datasets (for example, the Genome Aggregation Database (gnomAD)), confronts the historical ambiguity between the terms “mutation” and “polymorphism.” Historically, “mutation” referred to a sequence change (often rare and deleterious), while “polymorphism” referred to a variant present above a community threshold frequency in a population. Modern personalized medicine emphasizes context-specific interpretation supported by population data and disease epidemiology. Assume foundational principles only: the Central Dogma of Molecular Biology (deoxyribonucleic acid to ribonucleic acid to protein), the definition of allele frequency in a population, Hardy–Weinberg equilibrium (no need to assume any specific formula in advance), and the concept of penetrance.\n\nConsider an autosomal recessive, fully penetrant disorder caused by biallelic loss of function in gene $G$. A specific loss-of-function variant $v$ in $G$ has the following properties when surveyed in two distinct populations using high-quality post-HGP datasets:\n- In Population $A$: The minor allele frequency (MAF) of $v$ is $q_A = 0.02$ (that is, $2\\%$). The measured prevalence of the disorder in $A$ is approximately $1/2500$.\n- In Population $B$: The MAF of $v$ is $q_B = 0.0005$ (that is, $0.05\\%$). The measured prevalence of the disorder in $B$ is approximately $1/80000$.\n\nUsing only the fundamental bases listed above and the historical usage of the terms, select the single best statement that both (i) clarifies the distinction between “mutation” and “polymorphism” and (ii) argues, by explicit appeal to population frequency thresholds and disease prevalence, how the same variant $v$ can plausibly be classified differently across contexts in the history of genomic medicine.\n\nA. Historically, “polymorphism” was defined by a frequency threshold (commonly around $1\\%$) in a particular population, while “mutation” was used for rarer changes often associated with disease. Under Hardy–Weinberg reasoning for a fully penetrant autosomal recessive condition, a variant with $q_A = 0.02$ implies an expected homozygote frequency on the order of the observed $1/2500$ in Population $A$, consistent with $v$ being a major pathogenic allele there. Yet because $q_A \\ge 1\\%$, $v$ also exceeds the traditional “polymorphism” threshold in $A$, illustrating that “polymorphism” is a frequency label, not a guarantee of benign effect. In Population $B$, where $q_B = 0.0005 \\ll 1\\%$, $v$ is rare and would historically be called a “mutation”; its rarity also means it cannot by itself account for the higher disorder prevalence of $1/80000$ in $B$. Post-HGP population catalogs revealed such ancestry-specific frequencies, motivating context-dependent interpretation in personalized medicine.\n\nB. Once a variant demonstrates a loss-of-function mechanism in gene $G$, it is a “mutation” in all populations regardless of frequency or disease prevalence; the Human Genome Project (HGP) refined the gene sequence but did not change classification practices, which should depend only on molecular mechanism and not on population thresholds.\n\nC. A fixed global threshold of $5\\%$ MAF, applied across all ancestries, is both necessary and sufficient to classify “polymorphisms” without considering disease prevalence; the Human Genome Project (HGP) made such global thresholds reliable because large sample sizes remove the need to account for population structure or penetrance when judging pathogenicity.\n\nD. In autosomal recessive disease under Hardy–Weinberg equilibrium, the carrier frequency equals the disease prevalence. Therefore, a MAF of $q_A = 0.02$ in Population $A$ implies a disorder prevalence of $2\\%$, which far exceeds $1/2500$, proving that variant $v$ cannot be pathogenic in $A$ and must be a benign polymorphism there; by contrast, rarity in Population $B$ makes it a mutation in $B$ independent of disease prevalence.", "solution": "The solution requires applying Hardy-Weinberg equilibrium (HWE) principles to assess the relationship between allele frequency and disease prevalence in two different populations, and using this analysis to evaluate the historical definitions of \"mutation\" and \"polymorphism\".\n\nFor a fully penetrant autosomal recessive disorder, the prevalence of the disease is expected to be $q^2$, where $q$ is the frequency of the pathogenic allele, assuming HWE and that this allele is the sole cause of the disease.\n\n**Analysis of Population A:**\nThe allele frequency is $q_A = 0.02$. The expected disease prevalence from this variant alone is $q_A^2 = (0.02)^2 = 0.0004$, which is equal to $1/2500$. This perfectly matches the observed prevalence. This indicates that variant $v$ is likely the primary pathogenic allele for this disorder in Population A. However, its frequency of $2\\%$ is above the common historical threshold of $1\\%$ used to define a \"polymorphism\". This creates a conflict: the variant is clearly pathogenic, but its frequency would label it a polymorphism, demonstrating that frequency alone is not an indicator of function.\n\n**Analysis of Population B:**\nThe allele frequency is $q_B = 0.0005$. The expected disease prevalence from this variant alone is $q_B^2 = (0.0005)^2 = 2.5 \\times 10^{-7}$, which is equal to $1/4,000,000$. This expected prevalence is much lower than the observed prevalence of $1/80,000$. This implies that variant $v$ is only a minor contributor to the disease in Population B, and other pathogenic alleles must exist (allelic heterogeneity). In this population, the variant's low frequency ($0.05\\% \\ll 1\\%$) would lead to it being classified as a rare \"mutation\".\n\n**Evaluating the Options:**\n-   **Option A** correctly performs both analyses. It accurately calculates the prevalence in Population A, highlights the ambiguity of calling a pathogenic variant a \"polymorphism\" based on its frequency, and correctly deduces that variant $v$ cannot solely account for the disease prevalence in Population B. It correctly frames this as an example of context-dependent interpretation enabled by post-HGP data.\n-   **Option B** is incorrect. It falsely claims classification practices have not changed and should ignore population frequency, which contradicts the core lesson of modern genomics.\n-   **Option C** is incorrect. It proposes a rigid global threshold and claims population structure can be ignored, which is the opposite of best practice in genetic analysis.\n-   **Option D** is incorrect. It makes a fundamental error by stating that carrier frequency ($2pq$) equals disease prevalence ($q^2$), which is false. This incorrect premise invalidates all subsequent reasoning.\n\nTherefore, Option A provides the only accurate and comprehensive analysis that addresses all parts of the question.", "answer": "$$\\boxed{A}$$", "id": "4747042"}]}