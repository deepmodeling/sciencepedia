{"hands_on_practices": [{"introduction": "The modern pharmaceutical industry is built on a foundation of high-risk, high-reward research and development. This exercise introduces the concept of Expected Net Present Value ($ENPV$), a crucial financial tool used to decide whether the enormous upfront investment in a new drug is justified by its potential future profits, considering the low probability of success. By working through this calculation [@problem_id:4777141], you will gain insight into the economic rationale that drives decision-making in pharmaceutical innovation.", "problem": "In the post–World War II era, the rise of large research-intensive pharmaceutical firms was shaped by patent protection, regulatory data exclusivity, and risk-laden development pipelines. Consider an innovator drug project under a modern regulatory regime with the following characteristics: a development cost of $\\$1.2$ billion paid at time $t=0$, a probability of regulatory approval of $0.12$, an exclusivity length of $10$ years, and a constant annual after-tax operating profit of $\\$300$ million received at the end of each year during exclusivity if the drug is approved. Assume a constant discount rate $r=0.1$ that reflects the time value of money under risk-neutral valuation, and that if approval does not occur, no profit stream is realized.\n\nStarting only from the core definitions that (i) net present value is the present value of expected future cash flows minus the present investment, (ii) expected value is the probability-weighted average of outcomes, and (iii) discounting maps a future cash flow at time $t$ to its present value by multiplication with $(1+r)^{-t}$, derive an expression for the expected net present value and compute its numerical value under the parameters provided. Clearly state and justify each step of your derivation (including any series summation you use).\n\nExpress the final expected net present value in billions of dollars, and round your answer to three significant figures. Then, based on the sign of the computed expected net present value, briefly assess whether the investment is expected to create or destroy value under these assumptions.", "solution": "The problem asks for the derivation and computation of the expected net present value (ENPV) of a pharmaceutical drug project. The solution requires applying the core principles of financial valuation provided in the problem statement.\n\n### Step 1: Derivation of the Expected Net Present Value (ENPV)\n\nWe begin by formalizing the problem based on the provided definitions. The ENPV is the present value of all expected future cash flows minus the initial investment. The initial investment, $C_0$, is a certain cost incurred at time $t=0$. Its present value is simply $C_0$.\n\nThe future cash flows are uncertain and depend on regulatory approval. There are two states of the world:\n1.  **Approval**: Occurs with probability $p$. In this case, the project generates a profit of $\\pi$ at the end of each year for $T$ years.\n2.  **Non-approval**: Occurs with probability $1-p$. In this case, the project generates zero profit.\n\nLet's first determine the expected cash flow, $E[CF_t]$, at the end of any given year $t$ during the exclusivity period ($t \\in \\{1, 2, \\dots, T\\}$). Using the definition of expected value:\n$$ E[CF_t] = p \\cdot (\\text{Cash flow if approved}) + (1-p) \\cdot (\\text{Cash flow if not approved}) $$\n$$ E[CF_t] = p \\cdot \\pi + (1-p) \\cdot 0 = p\\pi $$\nFor $t > T$, the expected cash flow is $0$.\n\nNext, we calculate the present value of this stream of expected future cash flows, denoted as $PV(\\text{Expected CF})$. Using the given discounting rule, the present value of the expected cash flow at time $t$ is $E[CF_t](1+r)^{-t}$. We must sum these present values over the entire exclusivity period from $t=1$ to $t=T$.\n$$ PV(\\text{Expected CF}) = \\sum_{t=1}^{T} E[CF_t](1+r)^{-t} = \\sum_{t=1}^{T} (p\\pi)(1+r)^{-t} $$\nSince $p$ and $\\pi$ are constant, we can factor them out of the summation:\n$$ PV(\\text{Expected CF}) = p\\pi \\sum_{t=1}^{T} (1+r)^{-t} $$\nThe summation term is a finite geometric series with first term $a = (1+r)^{-1}$, common ratio $q = (1+r)^{-1}$, and $T$ terms. The sum of a finite geometric series is given by the formula $S_n = a \\frac{1-q^n}{1-q}$.\nApplying this formula with $n=T$:\n$$ \\sum_{t=1}^{T} (1+r)^{-t} = (1+r)^{-1} \\frac{1 - ((1+r)^{-1})^T}{1 - (1+r)^{-1}} $$\n$$ = \\frac{1}{1+r} \\frac{1 - (1+r)^{-T}}{\\frac{1+r-1}{1+r}} = \\frac{1}{1+r} \\frac{1 - (1+r)^{-T}}{\\frac{r}{1+r}} $$\nSimplifying this expression gives the standard formula for the present value of an ordinary annuity:\n$$ \\sum_{t=1}^{T} (1+r)^{-t} = \\frac{1 - (1+r)^{-T}}{r} $$\nSubstituting this back into the expression for $PV(\\text{Expected CF})$:\n$$ PV(\\text{Expected CF}) = p\\pi \\left[ \\frac{1-(1+r)^{-T}}{r} \\right] $$\nFinally, according to the definition of NPV, we subtract the present investment, $C_0$:\n$$ ENPV = PV(\\text{Expected CF}) - C_0 $$\nThis yields the final derived expression for the expected net present value:\n$$ ENPV = p\\pi \\left[ \\frac{1-(1+r)^{-T}}{r} \\right] - C_0 $$\n\n### Step 2: Numerical Computation\n\nWe now substitute the given numerical values into the derived expression. To maintain consistency, all monetary values will be expressed in billions of dollars.\n*   $C_0 = 1.2$ billion dollars.\n*   $\\pi = 300$ million dollars $= 0.3$ billion dollars.\n*   $p = 0.12$.\n*   $T = 10$.\n*   $r = 0.1$.\n\nFirst, we compute the present value factor of the annuity:\n$$ \\frac{1-(1+r)^{-T}}{r} = \\frac{1-(1+0.1)^{-10}}{0.1} = \\frac{1-(1.1)^{-10}}{0.1} $$\nUsing a calculator for $(1.1)^{-10}$:\n$$ (1.1)^{-10} \\approx 0.385543289 $$\n$$ \\frac{1-0.385543289}{0.1} = \\frac{0.614456711}{0.1} \\approx 6.14456711 $$\nNow, we calculate the present value of the expected profit stream:\n$$ PV(\\text{Expected CF}) = p\\pi \\times 6.14456711 = 0.12 \\times 0.3 \\times 6.14456711 $$\n$$ PV(\\text{Expected CF}) = 0.036 \\times 6.14456711 \\approx 0.221204416 \\text{ billion dollars} $$\nFinally, we compute the ENPV by subtracting the initial cost:\n$$ ENPV = 0.221204416 - 1.2 = -0.978795584 \\text{ billion dollars} $$\nThe problem requires rounding the final answer to three significant figures.\n$$ ENPV \\approx -0.979 \\text{ billion dollars} $$\n\n### Step 3: Assessment of the Investment\n\nThe computed expected net present value (ENPV) is negative ($-0.979$ billion). In financial decision-making, a project with a negative ENPV is expected to destroy value. This means that, on a probability-weighted basis, the present value of the anticipated future profits is insufficient to recover the initial investment, given the project's risk profile as captured by the discount rate and probability of success. Therefore, based on this analysis, the investment should not be undertaken as it is expected to result in a financial loss.", "answer": "$$\n\\boxed{-0.979}\n$$", "id": "4777141"}, {"introduction": "Once a drug project is deemed financially promising, it must pass the rigorous test of a randomized controlled trial (RCT), the gold standard for clinical evidence. This practice explores the statistical principles behind designing a trial that is large enough to confidently detect a real treatment effect, but not so large as to be wasteful or unethical. Calculating the required sample size [@problem_id:4777240] is a fundamental step that bridges statistical theory and the practical realities of drug evaluation.", "problem": "As randomized controlled trials (RCTs) became the evidentiary backbone of drug evaluation during the mid-twentieth-century rise of the pharmaceutical industry, firms increasingly needed to plan trial sizes from first principles of statistical inference rather than ad hoc convention. Consider a planned superiority RCT with equal allocation between $2$ arms testing a new small-molecule antihypertensive agent against standard care, where the primary endpoint is a continuous change score (baseline to follow-up) in systolic blood pressure. Assume independent observations, approximate normality of the endpoint within each arm, a common population standard deviation $\\sigma$, and a targeted mean difference (new minus control) equal to $\\delta$ under the alternative hypothesis.\n\nStarting from the definitions of Type I error $\\alpha$ and power $1-\\beta$ for a two-sided test of equality of means and the large-sample normal approximation to the sampling distribution of the difference in sample means, derive an analytic expression for the required equal per-arm sample size $n$ that would detect a true mean difference of magnitude $\\delta$ with two-sided significance level $\\alpha$ and power $1-\\beta$, assuming known common standard deviation $\\sigma$ and using a $z$-based test.\n\nThen, for the specific planning parameters $\\delta = 5$, $\\sigma = 10$, $\\alpha = 0.05$, and power $= 0.8$ (so $\\beta = 0.2$), evaluate the derived expression numerically to obtain the real-valued output of the sample size formula before any integer rounding rules typically applied in practice. Round your final numerical result to $4$ significant figures and report the value as a pure number with no units.", "solution": "The problem requires the derivation of a formula for the per-arm sample size, $n$, in a two-arm randomized controlled trial (RCT) with equal allocation. This derivation will be based on specified statistical parameters for a two-sided $z$-test of the difference between two means. Subsequently, the formula will be evaluated for a given set of numerical parameters.\n\nLet $\\mu_T$ be the population mean change in systolic blood pressure for the new agent arm and $\\mu_C$ be the population mean change for the standard care (control) arm. The objective of the superiority trial is to test whether the new agent produces a different mean change than the standard care. The null and alternative hypotheses for a two-sided test are:\n$$H_0: \\mu_T = \\mu_C \\quad (\\text{or } \\mu_T - \\mu_C = 0)$$\n$$H_1: \\mu_T \\neq \\mu_C \\quad (\\text{or } \\mu_T - \\mu_C \\neq 0)$$\n\nLet $\\bar{X}_T$ and $\\bar{X}_C$ be the sample mean changes in the treatment and control arms, respectively, each based on a sample of size $n$. The estimator for the difference in population means is $\\bar{D} = \\bar{X}_T - \\bar{X}_C$. Given that the observations are independent and normally distributed with a common standard deviation $\\sigma$, the sampling distribution of $\\bar{D}$ is also normal.\n\nThe expected value of $\\bar{D}$ is $E[\\bar{D}] = E[\\bar{X}_T] - E[\\bar{X}_C] = \\mu_T - \\mu_C$.\nThe variance of $\\bar{D}$ is $Var(\\bar{D}) = Var(\\bar{X}_T) + Var(\\bar{X}_C) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$.\nThe standard error of the difference is $SE(\\bar{D}) = \\sqrt{\\frac{2\\sigma^2}{n}} = \\sigma \\sqrt{\\frac{2}{n}}$.\n\nUnder the null hypothesis $H_0$, where $\\mu_T - \\mu_C = 0$, the test statistic $Z$ is given by:\n$$Z = \\frac{\\bar{D} - 0}{SE(\\bar{D})} = \\frac{\\bar{X}_T - \\bar{X}_C}{\\sigma \\sqrt{2/n}}$$\nThis statistic follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nThe Type I error rate, $\\alpha$, is the probability of rejecting $H_0$ when it is true. For a two-sided test, we reject $H_0$ if the absolute value of the test statistic exceeds a critical value. Let $z_{\\gamma}$ denote the upper critical value of the standard normal distribution such that $P(Z > z_{\\gamma}) = \\gamma$. The rejection region is thus defined by $|Z| > z_{\\alpha/2}$. This is equivalent to rejecting $H_0$ if $\\bar{D} > z_{\\alpha/2} \\sigma \\sqrt{2/n}$ or $\\bar{D} < -z_{\\alpha/2} \\sigma \\sqrt{2/n}$.\n\nPower, $1-\\beta$, is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_1$ is true. We assume a specific alternative hypothesis where the true mean difference is $\\mu_T - \\mu_C = \\delta$. Under this alternative, the sampling distribution of $\\bar{D}$ is $N(\\delta, 2\\sigma^2/n)$.\n\nThe power is the probability that $\\bar{D}$ falls into the rejection region, calculated under this alternative distribution:\n$$1 - \\beta = P(\\bar{D} > z_{\\alpha/2} \\sigma \\sqrt{2/n} \\ | \\ \\mu_T - \\mu_C = \\delta) + P(\\bar{D} < -z_{\\alpha/2} \\sigma \\sqrt{2/n} \\ | \\ \\mu_T - \\mu_C = \\delta)$$\nTo evaluate these probabilities, we standardize $\\bar{D}$ using its distribution under $H_1$:\n$$1 - \\beta = P\\left( \\frac{\\bar{D} - \\delta}{\\sigma \\sqrt{2/n}} > \\frac{z_{\\alpha/2} \\sigma \\sqrt{2/n} - \\delta}{\\sigma \\sqrt{2/n}} \\right) + P\\left( \\frac{\\bar{D} - \\delta}{\\sigma \\sqrt{2/n}} < \\frac{-z_{\\alpha/2} \\sigma \\sqrt{2/n} - \\delta}{\\sigma \\sqrt{2/n}} \\right)$$\nThe standardized variable $\\frac{\\bar{D} - \\delta}{\\sigma \\sqrt{2/n}}$ is a standard normal variable, $Z'$.\n$$1 - \\beta = P\\left( Z' > z_{\\alpha/2} - \\frac{\\delta}{\\sigma \\sqrt{2/n}} \\right) + P\\left( Z' < -z_{\\alpha/2} - \\frac{\\delta}{\\sigma \\sqrt{2/n}} \\right)$$\nAssuming the effect size $\\delta$ is positive, for a reasonably powered study, the term $-z_{\\alpha/2} - \\frac{\\delta}{\\sigma \\sqrt{2/n}}$ becomes a large negative number, and the probability $P(Z' < \\dots)$ becomes negligible. Therefore, we can approximate the power by the first term:\n$$1 - \\beta \\approx P\\left( Z' > z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma\\sqrt{2}} \\right)$$\nBy definition of power, we also know that $1 - \\beta = P(Z' > -z_{\\beta})$, where $z_\\beta$ is the upper $\\beta$ critical value. Equating the arguments of the probability functions, we get:\n$$-z_{\\beta} = z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma\\sqrt{2}}$$\nRearranging this equation to solve for $n$:\n$$z_{\\alpha/2} + z_{\\beta} = \\frac{\\delta\\sqrt{n}}{\\sigma\\sqrt{2}}$$\n$$\\sqrt{n} = \\frac{(z_{\\alpha/2} + z_{\\beta}) \\sigma \\sqrt{2}}{\\delta}$$\nSquaring both sides yields the final analytic expression for the per-arm sample size $n$:\n$$n = \\frac{2\\sigma^2(z_{\\alpha/2} + z_{\\beta})^2}{\\delta^2}$$\n\nNow, we evaluate this expression for the specific parameters provided:\n-   Mean difference to detect, $\\delta = 5$.\n-   Common standard deviation, $\\sigma = 10$.\n-   Two-sided significance level, $\\alpha = 0.05$.\n-   Power, $1-\\beta = 0.8$, which implies a Type II error rate of $\\beta = 0.2$.\n\nWe need the corresponding critical values from the standard normal distribution:\n1.  For $\\alpha = 0.05$, we need $z_{\\alpha/2} = z_{0.025}$. This is the value for which the upper tail probability is $0.025$, corresponding to a cumulative probability of $1 - 0.025 = 0.975$. The value is $z_{0.025} \\approx 1.959964$.\n2.  For $\\beta = 0.2$, we need $z_{\\beta} = z_{0.2}$. This is the value for which the upper tail probability is $0.2$, corresponding to a cumulative probability of $1 - 0.2 = 0.8$. The value is $z_{0.2} \\approx 0.841621$.\n\nSubstituting these values into the derived formula for $n$:\n$$n = \\frac{2(10)^2(1.959964 + 0.841621)^2}{5^2}$$\n$$n = \\frac{2(100)(2.801585)^2}{25}$$\n$$n = \\frac{200}{25} \\times (2.801585)^2$$\n$$n = 8 \\times 7.848879...$$\n$$n = 62.79103...$$\n\nThe problem requires rounding the final numerical result to $4$ significant figures. The first four significant digits are $6, 2, 7, 9$. The fifth digit is $1$, so we round down.\n$$n \\approx 62.79$$", "answer": "$$\\boxed{62.79}$$", "id": "4777240"}, {"introduction": "After a drug is approved and enters the market, its story is far from over; its real-world impact must be continually assessed. This exercise introduces two powerful concepts from clinical epidemiology: the Number Needed to Treat ($NNT$) and the Number Needed to Harm ($NNH$). By calculating and comparing these two metrics [@problem_id:4777210], we can distill complex clinical trial and safety data into a clear risk-benefit balance, a crucial skill for evaluating a therapy's ultimate value to patients.", "problem": "A mid-$20$th-century randomized controlled trial conducted during the rapid expansion of the pharmaceutical industry evaluated a new oral agent introduced to reduce post-myocardial infarction mortality. Investigators reported that, over a two-year horizon in trial populations typical of that era, the drug’s Number Needed to Treat (NNT), defined in clinical epidemiology as the number of patients who must receive the treatment for one additional beneficial outcome to occur compared with control, was $12$. Subsequent pharmacovigilance, a practice that matured as the industry grew and regulatory standards tightened, identified a rare serious adverse event whose absolute risk increase was measured as $0.002$ relative to control over the same horizon in the same population. Using first principles of absolute risk and expected value, compute the expected Number Needed to Harm (NNH), defined as the number of patients who must receive the treatment for one additional harmful outcome to occur compared with control. Then, from a history-of-medicine perspective grounded in the rise of the pharmaceutical industry, explain how the computed NNH compares to the reported NNT and what that implies for risk–benefit decision-making in that era’s evolving regulatory context. Express your final NNH as an integer count of patients; no rounding instruction is required beyond reporting the integer implied by the calculation. Do not include any units in your final numeric answer.", "solution": "The first step is to compute the Number Needed to Harm (NNH) using the principles of risk assessment. The Number Needed to Harm is defined as the number of patients who must be treated for one additional harmful outcome to occur, compared to a control group. This is mathematically the reciprocal of the Absolute Risk Increase (ARI) for the harm.\n\nLet $P_T(\\text{harm})$ be the probability (absolute risk) of the adverse event in the treatment group and $P_C(\\text{harm})$ be the probability of the adverse event in the control group. The Absolute Risk Increase is defined as:\n$$ARI_{\\text{harm}} = P_T(\\text{harm}) - P_C(\\text{harm})$$\nThe problem states that the absolute risk increase for the rare serious adverse event is $0.002$.\n$$ARI_{\\text{harm}} = 0.002$$\nThe Number Needed to Harm ($NNH$) is the inverse of the $ARI_{\\text{harm}}$:\n$$NNH = \\frac{1}{ARI_{\\text{harm}}}$$\nSubstituting the given value for $ARI_{\\text{harm}}$:\n$$NNH = \\frac{1}{0.002} = \\frac{1}{2 \\times 10^{-3}} = \\frac{1000}{2} = 500$$\nThus, the expected Number Needed to Harm is $500$. This means that for every $500$ patients treated with the new oral agent for two years, one additional serious adverse event is expected to occur that would not have occurred otherwise.\n\nThe second part of the task is to compare this computed $NNH$ of $500$ with the given Number Needed to Treat ($NNT$) of $12$ from a history-of-medicine perspective, specifically in the context of the mid-$20$th-century pharmaceutical industry and its regulatory environment.\n\nThe $NNT = 12$ indicates that treating $12$ patients for two years prevents one death from post-myocardial infarction. This represents a substantial therapeutic benefit. The risk-benefit profile is therefore characterized by these two numbers:\n- **Benefit (NNT):** $12$ patients treated to save $1$ life.\n- **Harm (NNH):** $500$ patients treated to cause $1$ serious adverse event.\n\nTo make a direct comparison, one can consider the outcomes per a fixed number of patients, for instance, $500$. In a group of $500$ patients treated for two years, one would expect:\n- Number of lives saved: $\\frac{500}{NNT} = \\frac{500}{12} \\approx 41.67$\n- Number of serious adverse events caused: $\\frac{500}{NNH} = \\frac{500}{500} = 1$\n\nFrom a mid-$20$th-century perspective, this risk-benefit ratio would have been considered exceptionally favorable. During this era of rapid pharmaceutical expansion, the primary focus of drug development and regulation was on demonstrating efficacy, especially for life-threatening conditions like myocardial infarction, which had high mortality and few effective treatments. The establishment of the randomized controlled trial as the gold standard was itself a major development, and a finding as dramatic as an $NNT$ of $12$ would have been hailed as a breakthrough.\n\nSimultaneously, the science and practice of pharmacovigilance—the systematic monitoring of drug safety after a product is on the market—were nascent. Before the strengthening of regulatory bodies like the FDA (e.g., via the $1962$ Kefauver-Harris Amendments in the U.S., spurred by the thalidomide tragedy), the capacity to detect, quantify, and act upon rare adverse events was limited. The discovery of a harm with an $ARI$ of $0.002$ ($1$ in $500$) represents a level of post-marketing surveillance that was only beginning to mature as the industry grew.\n\nTherefore, for a physician, regulator, or pharmaceutical company in that period, the decision-making calculus would be clear: a drug that saves approximately $42$ lives for every $1$ serious adverse event it causes offers a profound net benefit to public health. The high mortality of the underlying disease would make the risk of a rare side effect seem acceptable, if not negligible. This problem neatly encapsulates a key theme in the history of the pharmaceutical industry: the initial, powerful drive for potent new therapies was gradually balanced by an evolving, more sophisticated system for understanding and managing the inevitable risks associated with them, a regulatory and scientific maturation that continues to this day.", "answer": "$$\\boxed{500}$$", "id": "4777210"}]}