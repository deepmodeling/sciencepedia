{"hands_on_practices": [{"introduction": "A primary duty of a professional regulatory body is to serve as a gatekeeper, ensuring that only individuals who demonstrate minimal competence are granted a license to practice. This critical function relies on licensing examinations that are not only fair but also psychometrically robust and legally defensible. This exercise [@problem_id:4515847] asks you to apply core principles from measurement theory to evaluate a hypothetical licensing exam, connecting statistical concepts like reliability directly to the regulator's legal mandate to protect the public.", "problem": "A national medical council, acting under its statutory duty to protect the public by licensing only minimally competent practitioners, uses a written licensing examination. The latest cohort shows a pass rate of $80\\%$, and the exam’s reliability coefficient is reported as $r=0.85$. Assume that observed total scores are approximately normally distributed and have been standardized to $z$-scores with mean $0$ and standard deviation $1$. The council’s pass/fail decision is based on a single cut-score applied to the observed scores. Select the option that best evaluates whether the exam sufficiently discriminates competence for high-stakes licensure and proposes adjustments grounded in measurement theory and the duties of professional regulatory bodies.\n\nA. The high pass rate proves the exam fails to discriminate; to reduce false positives, the cut-score should be moved to the cohort median at $z=0$, and because $r=0.85$ is already high, the test length and item targeting should remain unchanged.\n\nB. The reliability $r=0.85$ is adequate for high-stakes licensure decisions, and a pass rate of $80\\%$ shows the cohort is competent; therefore, no material changes to the cut-score, test length, or content are needed.\n\nC. With $r=0.85$, the standard error of measurement is large enough that misclassification near the cut-score is nontrivial when the pass rate is $80\\%$ (cut near $z\\approx -0.84$). For high-stakes licensure, the council should target higher decision consistency (e.g., $r\\ge 0.90$), set the cut-score via a criterion-referenced standard-setting method anchored to minimal competence rather than a pass-rate target, and increase information at the cut (e.g., lengthen the test by approximately $60\\%$ or add items targeted around the cut) while evaluating error bands around the cut-score.\n\nD. To improve fairness and reduce false negatives, lower the cut-score to $z\\approx -1.5$ so that more candidates pass, and shorten the exam to reduce fatigue, which will increase reliability because shorter tests are more focused.\n\nE. To ensure public protection, enforce a fixed $20\\%$ failure rate by curving scores each year so that pass rates remain constant regardless of changes in exam difficulty or cohort ability.", "solution": "The user has provided a problem in the domain of psychometrics as applied to professional licensure, and has requested a rigorous evaluation of the problem and the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Context: A national medical council with a statutory duty to protect the public.\n- Instrument: A written licensing examination.\n- Pass/Fail Criterion: A single cut-score applied to observed scores.\n- Cohort Data: Pass rate of $80\\%$.\n- Test Property: Reliability coefficient $r = 0.85$.\n- Score Distribution: Observed total scores are approximately normally distributed and standardized to z-scores, with a mean of $0$ and a standard deviation of $1$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is firmly grounded in Classical Test Theory (CTT), a foundational framework in psychometrics. Key concepts like reliability coefficient ($r$), standard error of measurement (SEM), cut-scores, and standardized normal distributions are standard in this field. The application to high-stakes medical licensure is a textbook example of applied psychometrics.\n- **Well-Posedness**: The problem asks for an evaluation of the current testing practice and a proposal for adjustments. This is a standard task in program evaluation and educational measurement. Given the provided data ($r=0.85$, $80\\%$ pass rate, $N(0,1)$ distribution), a detailed quantitative and qualitative analysis is possible. A meaningful solution based on established principles can be derived.\n- **Objectivity**: The problem statement is factual and objective. It provides quantitative data and a clear context (statutory duty) without introducing subjective or biased language.\n\nThe problem does not exhibit any flaws. It is not scientifically unsound, incomplete, unrealistic, or ill-posed. The scenario is a realistic and common challenge faced by professional regulatory bodies.\n\n**Step 3: Verdict and Action**\nThe problem statement is **valid**. The solution process will now proceed.\n\n### Derivation of Solution\n\n**1. Foundational Principles**\nThis problem must be analyzed using principles of Classical Test Theory (CTT) and standard-setting for high-stakes assessments.\n- In CTT, an observed score ($X$) is composed of a true score ($T$) and a random error component ($E$), i.e., $X = T + E$.\n- The reliability coefficient, $r$, represents the proportion of observed score variance that is attributable to true score variance: $r = \\frac{\\sigma_T^2}{\\sigma_X^2}$. A value of $r=1$ implies no measurement error, while $r=0$ implies the score is entirely error.\n- The standard error of measurement (SEM) quantifies the typical amount of error in an individual's score. It is calculated as $SEM = \\sigma_X \\sqrt{1-r}$. The SEM is used to construct a confidence interval around an observed score to estimate the range within which a candidate's true score lies.\n- The primary duty of a licensing body is public protection, which means the primary concern is minimizing \"false positives\"—that is, certifying an individual as competent when they are, in fact, not. This requires a defensible standard of minimal competence.\n- The method for setting the pass/fail cut-score is critical. For licensure, the standard must be \"criterion-referenced,\" meaning it is linked to an absolute standard of knowledge and skill, rather than \"norm-referenced,\" which would base the standard on the performance of a particular group of test-takers.\n\n**2. Analysis of Provided Data**\n- The observed scores are standardized, so the standard deviation of observed scores is $\\sigma_X = 1$.\n- The reliability is given as $r=0.85$.\n- We can calculate the standard error of measurement (SEM):\n$$SEM = \\sigma_X \\sqrt{1-r} = 1 \\cdot \\sqrt{1 - 0.85} = \\sqrt{0.15} \\approx 0.387$$\nThis SEM value means that the standard deviation of measurement error is approximately $0.39$ standard deviation units of the score scale. A $95\\%$ confidence interval for an individual's true score would be $X \\pm 1.96 \\cdot SEM$, which has a width of $2 \\cdot 1.96 \\cdot 0.387 \\approx 1.52$ standard deviation units. This is a substantial amount of uncertainty for a high-stakes decision.\n\n- A pass rate of $80\\%$ on a normally distributed set of z-scores means that the cut-score is set at the $20^{th}$ percentile. We need to find the z-score, $z_c$, such that the area under the standard normal curve to its left is $0.20$.\n- Using the inverse cumulative distribution function for the standard normal distribution, $\\Phi^{-1}(0.20) \\approx -0.8416$. Let's denote the cut-score as $z_c \\approx -0.84$.\n\n**3. Evaluation of the Current Situation**\n- **Reliability**: For high-stakes decisions such as professional licensure, a reliability of $r=0.85$ is generally considered the minimum acceptable standard, with values of $r \\ge 0.90$ being the strong recommendation. The calculated SEM of approximately $0.39$ confirms that measurement error is a non-trivial concern.\n- **Misclassification**: The cut-score $z_c \\approx -0.84$ is located in a region of the normal distribution with relatively high density. This, combined with the significant SEM, means that a large number of candidates will have true scores that are plausibly on the opposite side of the cut-score from their observed score. The risk of misclassification (both false positives and false negatives) is therefore high for candidates scoring near the cut-score.\n- **Proposed Improvements**: To fulfill its duty of public protection, the council should seek to increase the precision of its pass/fail decisions. This involves two main lines of action:\n    a) **Improving the test**: The reliability must be increased. The Spearman-Brown prophecy formula, $r_{new} = \\frac{k \\cdot r_{old}}{1 + (k-1)r_{old}}$, can be used to estimate the required change in test length. To achieve a target reliability of $r_{new}=0.90$ from the current $r_{old}=0.85$, we solve for the factor $k$:\n    $$0.90 = \\frac{k \\cdot 0.85}{1 + (k-1)0.85} \\Rightarrow 0.90(1 + 0.85k - 0.85) = 0.85k$$\n    $$0.90(0.15 + 0.85k) = 0.85k \\Rightarrow 0.135 + 0.765k = 0.85k$$\n    $$0.135 = 0.085k \\Rightarrow k = \\frac{0.135}{0.085} \\approx 1.588$$\n    This implies the test would need to be lengthened by approximately $59\\%$ to reach a reliability of $0.90$. Alternatively, test information could be increased by adding or revising items to be more discriminating around the established cut-score.\n    b) **Improving the Standard-Setting Process**: The problem does not state how the cut-score was determined. A pass rate of $80\\%$ could be an arbitrary target (a norm-referenced approach) or the incidental result of a valid criterion-referenced standard-setting study (e.g., using the Angoff or Bookmark methods). For licensure, the latter is the only professionally and legally defensible approach. The council must ensure its cut-score is anchored to a defined standard of minimal competence, not a desire to pass a certain percentage of candidates.\n\n### Evaluation of Options\n\n**A. The high pass rate proves the exam fails to discriminate; to reduce false positives, the cut-score should be moved to the cohort median at $z=0$, and because $r=0.85$ is already high, the test length and item targeting should remain unchanged.**\nThis option contains multiple errors. The pass rate does not \"prove\" anything about discrimination. Moving the cut-score to the median ($z=0$) is an arbitrary norm-referenced standard, not one based on competence. A reliability of $r=0.85$ is not considered \"high\" for licensure, and given the high stakes, improving reliability is a key goal.\n**Verdict: Incorrect.**\n\n**B. The reliability $r=0.85$ is adequate for high-stakes licensure decisions, and a pass rate of $80\\%$ shows the cohort is competent; therefore, no material changes to the cut-score, test length, or content are needed.**\nThis option demonstrates complacency. A reliability of $r=0.85$ is marginal, not unequivocally adequate. A pass rate of $80\\%$ does not prove cohort competence; it is merely the result of placing the cut-score at a certain point. This option ignores the significant potential for misclassification error, which is a critical failure for a regulatory body.\n**Verdict: Incorrect.**\n\n**C. With $r=0.85$, the standard error of measurement is large enough that misclassification near the cut-score is nontrivial when the pass rate is $80\\%$ (cut near $z\\approx -0.84$). For high-stakes licensure, the council should target higher decision consistency (e.g., $r\\ge 0.90$), set the cut-score via a criterion-referenced standard-setting method anchored to minimal competence rather than a pass-rate target, and increase information at the cut (e.g., lengthen the test by approximately $60\\%$ or add items targeted around the cut) while evaluating error bands around the cut-score.**\nThis option correctly performs the analysis. It correctly identifies the cut-score ($z \\approx -0.84$) and correctly interprets the reliability $r=0.85$ as leading to a nontrivial SEM and risk of misclassification. The proposed solutions are all best practices in psychometrics for high-stakes testing: target higher reliability (e.g., $r \\ge 0.90$), use criterion-referenced standard setting, increase test information/length (the estimate of a $\\approx 60\\%$ increase is consistent with our calculation of $\\approx 59\\%$), and consider error bands for borderline scores. This is a comprehensive and correct evaluation.\n**Verdict: Correct.**\n\n**D. To improve fairness and reduce false negatives, lower the cut-score to $z\\approx -1.5$ so that more candidates pass, and shorten the exam to reduce fatigue, which will increase reliability because shorter tests are more focused.**\nThis option is deeply flawed. Lowering the cut-score to pass more candidates would increase the number of false positives, violating the council's primary duty to protect the public. The claim that shortening a test increases reliability is factually wrong; according to the Spearman-Brown formula, shorter tests are less reliable, all else being equal.\n**Verdict: Incorrect.**\n\n**E. To ensure public protection, enforce a fixed $20\\%$ failure rate by curving scores each year so that pass rates remain constant regardless of changes in exam difficulty or cohort ability.**\nThis option proposes a strict norm-referenced or \"curved\" standard. This is inappropriate for licensure because it uncouples the passing standard from any absolute measure of competence. If an entire cohort was very weak, $80\\%$ would still be licensed, failing to protect the public. Conversely, if a cohort was exceptionally strong, $20\\%$ would be unfairly denied licensure. This method does not ensure public protection.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{C}$$", "id": "4515847"}, {"introduction": "Licensure is the start, not the end, of a practitioner's professional obligations. Regulators ensure ongoing competence through programs like Continuing Professional Development (CPD), which mandate ongoing learning. This hands-on problem [@problem_id:4515829] provides a concrete look at how these abstract standards are translated into quantifiable rules by asking you to calculate a practitioner's compliance status, revealing the mathematical logic that underpins the enforcement of lifelong learning.", "problem": "A statutory professional regulatory body for physicians defines a Continuing Professional Development (CPD) requirement to ensure public protection and maintain professional competence. Under this regime, compliance for a given annual cycle is defined by two cumulative conditions: the total credits condition and the clinical relevance condition. Specifically, the body requires at least $N$ CPD credits per year and a clinical relevance proportion of at least $p$ across all credits claimed in that year, where the clinical relevance proportion is the ratio of clinically relevant credits to total credits.\n\nA practitioner reports a total of $T = 70$ CPD credits for the year, of which $C = 35$ credits are clinically relevant. The regulatory body’s threshold is $N = 50$ and the required clinical relevance proportion is $p = 0.60$.\n\nUsing the definitional foundations that:\n- compliance requires simultaneously satisfying $T \\geq N$ and $\\frac{C}{T} \\geq p$, and\n- any additional credits earned and claimed are added to both the total and the clinically relevant tallies only if they are clinically relevant,\n\ndetermine the minimal additional number of clinically relevant credits, denoted by $\\Delta$, that the practitioner must add to their record to achieve compliance if they currently do not satisfy both conditions. Express your final answer in credits as a single real number. No rounding is required.", "solution": "The problem will first be validated against the specified criteria before a solution is attempted.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\nThe givens extracted verbatim from the problem statement are:\n-   Required minimum total credits per year: $N = 50$.\n-   Required minimum clinical relevance proportion: $p = 0.60$.\n-   Practitioner's reported total credits: $T = 70$.\n-   Practitioner's reported clinically relevant credits: $C = 35$.\n-   Compliance condition 1: Total credits must be greater than or equal to $N$ ($T \\geq N$).\n-   Compliance condition 2: Clinical relevance proportion must be greater than or equal to $p$ ($\\frac{C}{T} \\geq p$).\n-   Compliance definition: Both conditions must be satisfied simultaneously.\n-   Rule for additional credits: If $\\Delta$ additional clinically relevant credits are added, the new total credits become $T+\\Delta$ and the new clinically relevant credits become $C+\\Delta$.\n-   Objective: Determine the minimal additional number of clinically relevant credits, $\\Delta$, required to achieve compliance.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed for validity:\n-   **Scientifically Grounded**: The problem is based on a set of algebraic inequalities. It is a mathematical formalization of a plausible regulatory scenario. It is logically and mathematically sound.\n-   **Well-Posed**: The problem is clearly defined with all necessary variables ($T, C, N, p$) and conditions. It asks for a minimum value ($\\Delta$) that satisfies a system of inequalities, which is a standard and well-defined mathematical task. A unique, stable, and meaningful solution is expected to exist.\n-   **Objective**: The problem is stated using precise, quantitative language and objective criteria for compliance. There are no subjective or ambiguous terms.\n\nThe problem does not exhibit any of the listed flaws (e.g., scientific unsoundness, incompleteness, contradiction, or ambiguity). It is a straightforward mathematical problem set in a professional context.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be derived.\n\n### Solution\n\nThe goal is to find the minimum number of additional clinically relevant credits, $\\Delta$, that the practitioner must obtain to meet the regulatory body's compliance requirements.\n\nFirst, we must assess the practitioner's current compliance status based on the reported credits. The two conditions for compliance are:\n1.  Total credits condition: $T \\geq N$\n2.  Clinical relevance condition: $\\frac{C}{T} \\geq p$\n\nLet's substitute the given values:\n-   Given $T = 70$ and $N = 50$. The first condition is $70 \\geq 50$. This is true. The practitioner satisfies the total credits condition.\n-   Given $C = 35$, $T = 70$, and $p = 0.60$. The second condition is $\\frac{35}{70} \\geq 0.60$. Calculating the proportion gives $\\frac{35}{70} = 0.50$. The inequality becomes $0.50 \\geq 0.60$. This is false. The practitioner does not satisfy the clinical relevance condition.\n\nSince compliance requires satisfying both conditions simultaneously, the practitioner is currently not compliant.\n\nThe practitioner must add a minimal number of clinically relevant credits, denoted by $\\Delta$, to achieve compliance. According to the problem definition, adding $\\Delta$ clinically relevant credits updates the practitioner's record as follows:\n-   New total credits: $T' = T + \\Delta = 70 + \\Delta$.\n-   New clinically relevant credits: $C' = C + \\Delta = 35 + \\Delta$.\n\nFor the practitioner to be compliant with the updated credits, both conditions must be met:\n1.  $T' \\geq N \\implies 70 + \\Delta \\geq 50$\n2.  $\\frac{C'}{T'} \\geq p \\implies \\frac{35 + \\Delta}{70 + \\Delta} \\geq 0.60$\n\nWe need to find the minimum non-negative value of $\\Delta$ that satisfies both inequalities.\n\nLet's analyze the first inequality:\n$70 + \\Delta \\geq 50$\nSince $\\Delta$ represents additional credits, it must be non-negative, $\\Delta \\geq 0$. For any $\\Delta \\geq 0$, we have $70 + \\Delta \\geq 70$, and since $70 > 50$, the inequality $70 + \\Delta \\geq 50$ is always satisfied for any permissible $\\Delta$. Therefore, we only need to focus on the second inequality to find the constraint on $\\Delta$.\n\nNow, let's analyze the second inequality:\n$\\frac{35 + \\Delta}{70 + \\Delta} \\geq 0.60$\nSince $\\Delta \\geq 0$, the denominator $70 + \\Delta$ is strictly positive. We can multiply both sides of the inequality by $70 + \\Delta$ without changing the direction of the inequality sign.\n$35 + \\Delta \\geq 0.60 \\times (70 + \\Delta)$\n$35 + \\Delta \\geq (0.60 \\times 70) + (0.60 \\times \\Delta)$\n$35 + \\Delta \\geq 42 + 0.60\\Delta$\n\nTo solve for $\\Delta$, we group the terms involving $\\Delta$ on one side and the constant terms on the other.\n$\\Delta - 0.60\\Delta \\geq 42 - 35$\n$0.40\\Delta \\geq 7$\n\nNow, we solve for $\\Delta$ by dividing by $0.40$.\n$\\Delta \\geq \\frac{7}{0.40}$\n$\\Delta \\geq \\frac{7}{4/10}$\n$\\Delta \\geq \\frac{70}{4}$\n$\\Delta \\geq 17.5$\n\nThe condition for compliance is $\\Delta \\geq 17.5$. The problem asks for the minimal additional number of credits required. This corresponds to the smallest value of $\\Delta$ that satisfies the inequality.\nThe minimal value is $\\Delta = 17.5$.\n\nTherefore, the practitioner must add a minimum of $17.5$ clinically relevant credits to their record to achieve compliance.", "answer": "$$\\boxed{17.5}$$", "id": "4515829"}, {"introduction": "Responding to public complaints is a resource-intensive and legally significant function of any regulatory body, demanding a balance between procedural fairness and operational efficiency. The ideal of a timely and thorough investigation often clashes with the reality of limited staffing and budgets. This practice [@problem_id:4515837] models the operational challenges of a disciplinary process, tasking you with conducting a capacity analysis that connects resource allocation directly to the practical delivery of administrative justice.", "problem": "A national Medical Practitioners Council receives $1{,}000$ written complaints per year. In line with administrative law and medical law principles, including the duty of procedural fairness (timely resolution and reasonable expedition), the Council’s scheme operates in three sequential stages: initial triage, formal investigation, and adjudicative hearing. Historical data show that of all complaints received, a proportion $0.40$ are closed at triage, a proportion $0.30$ proceed to formal investigation, and a proportion $0.10$ (of all received) proceed to an adjudicative hearing following investigation. All complaints are triaged; only those selected proceed to later stages.\n\nAssume the following resourcing and time-on-task parameters, which reflect casework hours only. Each full-time staff member works $220$ days per year at $7.5$ hours per day, with a productivity factor of $0.80$ devoted to casework (the balance accounts for training, leave, and non-case duties). Stage-specific casework times and staffing are:\n- Triage: $2$ hours per complaint; $2$ triage officers.\n- Investigation: $25$ hours per investigated complaint; $6$ investigators.\n- Hearing: $50$ hours per hearing case (including preparation, hearing-management, and decision drafting); $4$ legal officers.\n\nStatutory time frames require completion of triage within $14$ days of receipt, completion of investigation within $90$ days of triage completion, and completion of hearing (including a written decision) within $180$ days of the investigation report. For the purpose of this assessment, model arrivals as uniform over the year and take a necessary capacity-feasibility proxy for timeliness at each stage to be that the stage’s available annual casework hours are at least as large as the stage’s annual demanded casework hours. Define, for each stage $s$ in $\\{\\text{triage}, \\text{investigation}, \\text{hearing}\\}$, the utilization $u_s$ as the ratio of annual demanded casework hours to annual available casework hours at that stage. Define the fairness slack index by\n$$\nS \\equiv \\min_{s \\in \\{\\text{triage}, \\text{investigation}, \\text{hearing}\\}} \\left(1 - u_s\\right).\n$$\n\nTasks:\n1. Compute the expected annual caseload volume at each stage.\n2. Using the proxy above, assess whether timeliness consistent with procedural fairness is feasible by computing $S$.\n\nProvide the single final answer as the exact value of $S$ expressed as a reduced fraction. Do not include units and do not round.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- Total annual complaints: $N = 1{,}000$.\n- Stages: $s \\in \\{\\text{triage}, \\text{investigation}, \\text{hearing}\\}$.\n- Proportion of all complaints closed at triage: $p_{closed,T} = 0.40$.\n- Proportion of all complaints proceeding to investigation: $p_I = 0.30$.\n- Proportion of all complaints proceeding to hearing: $p_H = 0.10$.\n- All complaints are triaged.\n- Staff workdays per year: $D_{work} = 220$.\n- Staff hours per day: $H_{day} = 7.5$.\n- Staff productivity factor for casework: $f_{prod} = 0.80$.\n- Triage stage specifics: Casework time $T_T = 2$ hours/complaint; Staff count $M_T = 2$.\n- Investigation stage specifics: Casework time $T_I = 25$ hours/complaint; Staff count $M_I = 6$.\n- Hearing stage specifics: Casework time $T_H = 50$ hours/complaint; Staff count $M_H = 4$.\n- Definition of utilization: $u_s = \\frac{\\text{annual demanded casework hours at stage } s}{\\text{annual available casework hours at stage } s}$.\n- Definition of fairness slack index: $S \\equiv \\min_{s} (1 - u_s)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is a resource allocation and capacity analysis problem, a standard type of mathematical modeling found in operations research. It is grounded in established quantitative methods. The problem is well-posed, providing all necessary definitions and data for a unique solution. The language is objective and precise. The premise that the proportions of cases flowing to different stages do not sum to unity (i.e., $0.40 + 0.30 + 0.10 \\neq 1$) is not a contradiction; it simply implies that a fraction of cases ($1 - 0.40 - 0.30 = 0.30$ that enter triage are dispositioned in ways not specified because they are not relevant to calculating the load for the investigation and hearing stages, or that the $0.10$ to hearing are a subset of the $0.30$ to investigation and the remaining $0.40+ (0.30-0.10) = 0.60$ have their process terminated). The description of case flow is unambiguous for the required calculations. The problem is therefore deemed valid.\n\n**Step 3: Solution**\nThe solution proceeds by satisfying the two tasks outlined in the problem statement.\n\n**Task 1: Compute the expected annual caseload volume at each stage.**\nThe annual caseload volume, $N_s$, for each stage $s$ is determined from the total number of complaints, $N = 1{,}000$.\n- For the triage stage ($s=\\text{triage}$), all complaints are triaged.\n$$N_T = N = 1{,}000$$\n- For the investigation stage ($s=\\text{investigation}$), a proportion $p_I = 0.30$ of all received complaints proceed.\n$$N_I = N \\times p_I = 1{,}000 \\times 0.30 = 300$$\n- For the hearing stage ($s=\\text{hearing}$), a proportion $p_H = 0.10$ of all received complaints proceed.\n$$N_H = N \\times p_H = 1{,}000 \\times 0.10 = 100$$\n\n**Task 2: Compute the fairness slack index, $S$.**\nThis requires calculating the utilization $u_s$ for each stage, which in turn requires calculating the annual demanded hours ($H_{D,s}$) and annual available hours ($H_{A,s}$).\n\n**Calculation of Annual Available Casework Hours ($H_{A,s}$)**\nFirst, we compute the total available casework hours per staff member per year.\n$$H_{staff} = D_{work} \\times H_{day} \\times f_{prod} = 220 \\times 7.5 \\times 0.80 = 1{,}320 \\text{ hours}$$\nNext, we multiply this by the number of staff at each stage, $M_s$.\n- Triage: $H_{A,T} = M_T \\times H_{staff} = 2 \\times 1{,}320 = 2{,}640$ hours.\n- Investigation: $H_{A,I} = M_I \\times H_{staff} = 6 \\times 1{,}320 = 7{,}920$ hours.\n- Hearing: $H_{A,H} = M_H \\times H_{staff} = 4 \\times 1{,}320 = 5{,}280$ hours.\n\n**Calculation of Annual Demanded Casework Hours ($H_{D,s}$)**\nThe demanded hours are the product of the caseload volume ($N_s$) and the time per complaint ($T_s$) for each stage.\n- Triage: $H_{D,T} = N_T \\times T_T = 1{,}000 \\times 2 = 2{,}000$ hours.\n- Investigation: $H_{D,I} = N_I \\times T_I = 300 \\times 25 = 7{,}500$ hours.\n- Hearing: $H_{D,H} = N_H \\times T_H = 100 \\times 50 = 5{,}000$ hours.\n\n**Calculation of Utilization ($u_s$)**\nThe utilization for each stage is the ratio of demanded hours to available hours, $u_s = H_{D,s} / H_{A,s}$.\n- Triage: $u_T = \\frac{H_{D,T}}{H_{A,T}} = \\frac{2{,}000}{2{,}640}$.\n- Investigation: $u_I = \\frac{H_{D,I}}{H_{A,I}} = \\frac{7{,}500}{7{,}920}$.\n- Hearing: $u_H = \\frac{H_{D,H}}{H_{A,H}} = \\frac{5{,}000}{5{,}280}$.\n\nThe condition that available hours are at least as large as demanded hours ($u_s \\le 1$) is a proxy for timeliness being feasible.\n- $u_T = \\frac{2000}{2640} \\approx 0.758 \\le 1$. Feasible.\n- $u_I = \\frac{7500}{7920} \\approx 0.947 \\le 1$. Feasible.\n- $u_H = \\frac{5000}{5280} \\approx 0.947 \\le 1$. Feasible.\nSince all utilizations are less than or equal to $1$, the system is feasible according to the given proxy.\n\n**Calculation of the Fairness Slack Index ($S$)**\nThe fairness slack index is defined as $S = \\min_{s} (1 - u_s)$. We compute $(1 - u_s)$ for each stage.\n- Triage: $1 - u_T = 1 - \\frac{2{,}000}{2{,}640} = \\frac{2{,}640 - 2{,}000}{2{,}640} = \\frac{640}{2{,}640} = \\frac{64}{264} = \\frac{8}{33}$.\n- Investigation: $1 - u_I = 1 - \\frac{7{,}500}{7{,}920} = \\frac{7{,}920 - 7{,}500}{7{,}920} = \\frac{420}{7{,}920} = \\frac{42}{792} = \\frac{7}{132}$.\n- Hearing: $1 - u_H = 1 - \\frac{5{,}000}{5{,}280} = \\frac{5{,}280 - 5{,}000}{5{,}280} = \\frac{280}{5{,}280} = \\frac{28}{528} = \\frac{7}{132}$.\n\nNow we find the minimum of these values.\n$$S = \\min\\left(\\frac{8}{33}, \\frac{7}{132}, \\frac{7}{132}\\right)$$\nTo compare $\\frac{8}{33}$ and $\\frac{7}{132}$, we find a common denominator. Since $132 = 4 \\times 33$, we have:\n$$\\frac{8}{33} = \\frac{8 \\times 4}{33 \\times 4} = \\frac{32}{132}$$\nThus, we are comparing $\\frac{32}{132}$ with $\\frac{7}{132}$. Clearly, $\\frac{7}{132}$ is smaller.\n$$S = \\frac{7}{132}$$\nThe fraction $\\frac{7}{132}$ is in simplest form as $7$ is a prime number and $132 = 2^2 \\times 3 \\times 11$, so $7$ is not a factor of $132$.\nThe fairness slack index $S$ represents the smallest capacity buffer across all stages, indicating that the investigation and hearing stages are the system's bottlenecks.", "answer": "$$\\boxed{\\frac{7}{132}}$$", "id": "4515837"}]}