{"hands_on_practices": [{"introduction": "Coronaviruses possess an unusually large genome for an RNA virus, a feat made possible by a proofreading enzyme that corrects errors during replication. This practice explores the profound impact of this mechanism through a hypothetical scenario. By calculating the expected number of mutations with and without proofreading, you will quantitatively grasp why this function is critical for preventing \"error catastrophe\" and maintaining viral viability [@problem_id:4623017].", "problem": "Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) is a positive-sense ribonucleic acid (RNA) virus with an average genome length of $30\\,\\text{kb}$. Its RNA-dependent RNA polymerase generates point substitution errors during replication. Coronaviruses possess a proofreading exonuclease that reduces the per-site error probability. Assume the following scientifically plausible scenario for one genome replication:\n- Genome length $L = 3.0 \\times 10^{4}$ nucleotides.\n- Per-site error probability with proofreading $u_{\\text{p}} = 2.0 \\times 10^{-6}$.\n- Per-site error probability without proofreading $u_{\\text{np}} = 3.0 \\times 10^{-4}$.\n- Fraction of de novo point substitutions that are lethal $f_{\\text{L}} = 0.30$.\n- Lethal mutational threshold $\\theta = 1.0$ lethal mutation per genome replication, above which the virus is considered non-viable.\n\nStarting from the definitions of Bernoulli trials across $L$ sites and the linearity of expectation, derive the expected number of de novo point errors per genome replication with proofreading and without proofreading. Then, using the same foundational reasoning, derive the expected number of lethal mutations per genome replication in both conditions and decide viability by the rule: viable if the expected number of lethal mutations is less than $\\theta$, non-viable otherwise. Express the viability decision numerically using an indicator $V$ where $V=1$ denotes viability and $V=0$ denotes non-viability.\n\nRound all expected counts to three significant figures. No physical units are required. Express the final answer as a row matrix in the order $\\left(E_{\\text{mut,p}},\\,E_{\\text{mut,np}},\\,V_{\\text{p}},\\,V_{\\text{np}}\\right)$.", "solution": "The problem will first be validated for scientific and logical soundness.\n\n### Step 1: Extract Givens\nThe physical and biological parameters provided in the problem statement are:\n- Genome length: $L = 3.0 \\times 10^{4}$ nucleotides.\n- Per-site error probability with proofreading: $u_{\\text{p}} = 2.0 \\times 10^{-6}$.\n- Per-site error probability without proofreading: $u_{\\text{np}} = 3.0 \\times 10^{-4}$.\n- Fraction of de novo point substitutions that are lethal: $f_{\\text{L}} = 0.30$.\n- Lethal mutational threshold: $\\theta = 1.0$ lethal mutation per genome replication.\n- Viability rule: Viable if the expected number of lethal mutations is less than $\\theta$.\n- Viability indicator: $V=1$ for viable, $V=0$ for non-viable.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria:\n- **Scientifically Grounded:** The problem is based on fundamental principles of virology and molecular evolution. The premise of RNA virus replication, the function of RNA-dependent RNA polymerase, the existence of proofreading exonucleases in coronaviruses, and the concept of a mutational threshold (error catastrophe) are all well-established in the scientific literature. The given numerical values for genome size ($30\\,\\text{kb}$) and mutation rates ($u_{\\text{p}} \\approx 10^{-6}$, $u_{\\text{np}} \\approx 10^{-4}$) are scientifically plausible and consistent with empirical data for SARS-CoV-2.\n- **Well-Posed:** The problem is clearly defined. It provides all necessary parameters and defines a clear objective: to calculate expected mutation counts and determine viability based on a specified threshold. A unique solution is attainable through standard probabilistic methods.\n- **Objective:** The language is formal, precise, and free of subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is self-contained, scientifically sound, and well-posed. The solution process may proceed.\n\n### Solution Derivation\nThe derivation begins from the foundational principles of Bernoulli trials and the linearity of expectation, as requested.\n\nThe replication of a genome of length $L$ can be modeled as a series of $L$ independent Bernoulli trials, where each trial corresponds to the replication of a single nucleotide site. Let $X_i$ be a random variable for the $i$-th site (where $i=1, 2, ..., L$):\n$$\nX_i = \n\\begin{cases} \n1 & \\text{if a substitution error occurs at site } i \\\\\n0 & \\text{if no error occurs at site } i \n\\end{cases}\n$$\nThe probability of an error at any given site is the per-site error probability, which we denote as $u$. Thus, $P(X_i = 1) = u$ and $P(X_i = 0) = 1-u$.\n\nThe total number of errors (mutations) across the entire genome, denoted by the random variable $M$, is the sum of the outcomes of these individual trials:\n$$\nM = \\sum_{i=1}^{L} X_i\n$$\nThe problem asks for the expected number of de novo point errors, $E[M]$. By the linearity of expectation, the expectation of a sum of random variables is the sum of their individual expectations:\n$$\nE[M] = E\\left[\\sum_{i=1}^{L} X_i\\right] = \\sum_{i=1}^{L} E[X_i]\n$$\nThe expectation of a single Bernoulli random variable $X_i$ is given by:\n$$\nE[X_i] = (1) \\cdot P(X_i=1) + (0) \\cdot P(X_i=0) = P(X_i=1) = u\n$$\nSubstituting this back, we find the general formula for the expected number of mutations per genome replication:\n$$\nE[M] = \\sum_{i=1}^{L} u = L \\cdot u\n$$\n\nWe now apply this formula to the two specified conditions.\n\n**1. Expected Mutations with Proofreading ($E_{\\text{mut,p}}$)**\nUsing the per-site error probability with proofreading, $u_{\\text{p}} = 2.0 \\times 10^{-6}$, and the genome length $L = 3.0 \\times 10^{4}$:\n$$\nE_{\\text{mut,p}} = L \\cdot u_{\\text{p}} = (3.0 \\times 10^{4}) \\cdot (2.0 \\times 10^{-6}) = 6.0 \\times 10^{-2} = 0.06\n$$\nRounding to three significant figures, we get $E_{\\text{mut,p}} = 0.0600$.\n\n**2. Expected Mutations without Proofreading ($E_{\\text{mut,np}}$)**\nUsing the per-site error probability without proofreading, $u_{\\text{np}} = 3.0 \\times 10^{-4}$:\n$$\nE_{\\text{mut,np}} = L \\cdot u_{\\text{np}} = (3.0 \\times 10^{4}) \\cdot (3.0 \\times 10^{-4}) = 9.0 \\times 10^{0} = 9.0\n$$\nRounding to three significant figures, we get $E_{\\text{mut,np}} = 9.00$.\n\n**3. Expected Lethal Mutations and Viability Decision**\nNext, we determine the expected number of lethal mutations. A fraction $f_{\\text{L}}$ of all mutations are lethal. The expected number of lethal mutations, $E_{\\text{lethal}}$, is the total expected number of mutations multiplied by this fraction. This follows from the property of expectation, $E[c \\cdot X] = c \\cdot E[X]$, where we can conceptualize the number of lethal mutations as a random sampling from the total number of mutations. RIGOROUSLY, if $M_{\\text{L}}$ is the number of lethal mutations, then $E[M_L] = E[E[M_L|M]] = E[M \\cdot f_{\\text{L}}] = f_{\\text{L}} \\cdot E[M]$.\n$$\nE_{\\text{lethal}} = f_{\\text{L}} \\cdot E_{\\text{mut}}\n$$\nWe use this to assess viability, which requires the expected number of lethal mutations to be less than the threshold $\\theta = 1.0$.\n\n**Viability with Proofreading ($V_{\\text{p}}$)**\nThe expected number of lethal mutations with proofreading is:\n$$\nE_{\\text{lethal,p}} = f_{\\text{L}} \\cdot E_{\\text{mut,p}} = (0.30) \\cdot (0.06) = 0.018\n$$\nWe compare this to the threshold $\\theta = 1.0$.\nSince $0.018 < 1.0$, the condition for viability is met.\nTherefore, the viability indicator is $V_{\\text{p}} = 1$.\n\n**Viability without Proofreading ($V_{\\text{np}}$)**\nThe expected number of lethal mutations without proofreading is:\n$$\nE_{\\text{lethal,np}} = f_{\\text{L}} \\cdot E_{\\text{mut,np}} = (0.30) \\cdot (9.0) = 2.7\n$$\nWe compare this to the threshold $\\theta = 1.0$.\nSince $2.7 \\ge 1.0$, the condition for viability is not met. The virus has crossed the error catastrophe threshold.\nTherefore, the viability indicator is $V_{\\text{np}} = 0$.\n\nThe final results are the expected mutation counts and the viability indicators for both scenarios.\n\n- Expected mutations with proofreading: $E_{\\text{mut,p}} = 0.0600$.\n- Expected mutations without proofreading: $E_{\\text{mut,np}} = 9.00$.\n- Viability with proofreading: $V_{\\text{p}} = 1$.\n- Viability without proofreading: $V_{\\text{np}} = 0$.\n\nThese are combined into the requested row matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.0600 & 9.00 & 1 & 0\n\\end{pmatrix}\n}\n$$", "id": "4623017"}, {"introduction": "The primary tool for diagnosing and monitoring SARS-CoV-2 infection is reverse transcription quantitative polymerase chain reaction (RT-qPCR). This exercise provides a hands-on look at how raw laboratory data are transformed into clinically meaningful information. You will convert a cycle threshold ($C_{t}$) value into a viral load in copies per milliliter and explore how measurement uncertainty propagates, a crucial concept for interpreting any quantitative test result [@problem_id:4623122].", "problem": "A clinical laboratory quantifies Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) genomic RNA in nasopharyngeal swab specimens by reverse transcription quantitative polymerase chain reaction (RT-qPCR). A ten-fold dilution standard curve was generated under the same assay conditions and is well-described by a linear relationship between cycle threshold and the base-$10$ logarithm of initial template copies per reaction: the slope is $m=-3.30$ (cycles per $\\log_{10}$-copy), and the intercept is $b=41.2$ cycles. An unknown specimen yields a cycle threshold of $C_{t}=27.8$ cycles. Within-run technical replicates indicate a cycle threshold standard deviation of $\\sigma_{C_{t}}=0.20$ cycles.\n\nSample processing is as follows: starting volume of specimen is $140$ microliters (transport medium), ribonucleic acid (RNA) is eluted in 50 microliters, and 5 microliters of the eluate are used per RT-qPCR reaction well. Assume ideal recovery and that any uncertainty arises only from $C_{t}$ measurement variability; treat $m$, $b$, and all volumes as exact.\n\nUse only the following foundational facts as the starting point: (i) in RT-qPCR, cycle threshold is empirically linear in the base-$10$ logarithm of initial copy number per reaction, and (ii) for independent, small, normally distributed errors, first-order (Gaussian) error propagation states that if a quantity $f$ depends on a single variable $x$ with standard deviation $\\sigma_{x}$, then the standard deviation of $f$ is $\\sigma_{f}\\approx\\left|\\frac{df}{dx}\\right|\\sigma_{x}$; for a constant scaling by a factor $k$, the standard deviation scales as $\\sigma_{k f}=|k|\\,\\sigma_{f}$.\n\nStarting from these facts, derive an expression for the propagated standard deviation (absolute, not relative) of the inferred SARS-CoV-2 genome concentration in the original specimen, in copies per milliliter. Then evaluate it numerically for the values given above. Round your final numeric answer to three significant figures. Express the final answer in copies per mL.", "solution": "**1. Problem Validation**\n\nThe problem statement has been critically reviewed and is determined to be **valid**.\n\n*   **Givens:**\n    *   Linear model for cycle threshold ($C_t$): $C_t = m \\log_{10}(N) + b$, where $N$ is the initial template copies per reaction.\n    *   Slope: $m = -3.30$ cycles/$\\log_{10}$-copy.\n    *   Intercept: $b = 41.2$ cycles.\n    *   Measured cycle threshold for unknown specimen: $C_{t, \\text{specimen}} = 27.8$ cycles.\n    *   Standard deviation of cycle threshold measurement: $\\sigma_{C_t} = 0.20$ cycles.\n    *   Starting volume of specimen: $V_{\\text{start}} = 140 \\, \\mu L$.\n    *   RNA elution volume: $V_{\\text{elute}} = 50 \\, \\mu L$.\n    *   Volume of eluate per RT-qPCR reaction: $V_{\\text{rxn}} = 5 \\, \\mu L$.\n    *   Assumptions: Ideal recovery (no loss of RNA during processing); uncertainty arises only from $C_t$ measurement; $m$, $b$, and all volumes are exact constants.\n    *   Fundamental facts for derivation:\n        *   (i) $C_t$ is empirically linear in $\\log_{10}(N)$.\n        *   (ii) First-order error propagation for $f(x)$: $\\sigma_f \\approx \\left|\\frac{df}{dx}\\right|\\sigma_x$.\n        *   (iii) Error scaling for a constant $k$: $\\sigma_{kf} = |k|\\sigma_f$.\n\n*   **Validation Verdict:**\n    *   **Scientifically Grounded:** The problem accurately models a standard RT-qPCR experiment. The linear relationship is fundamental to quantitative PCR, and the given slope value ($m = -3.30$) is physically realistic, corresponding to a PCR efficiency of approximately $101\\%$, which is very common.\n    *   **Well-Posed:** All necessary data and relationships are provided to derive a unique solution.\n    *   **Objective:** The problem is stated in precise, quantitative terms.\n    *   The problem is free from the flaws listed in the instructions (e.g., it is not incomplete, contradictory, or trivial). Therefore, it is valid and a solution can be derived.\n\n**2. Derivation and Solution**\n\nThe objective is to derive an expression for the standard deviation ($\\sigma_C$) of the inferred SARS-CoV-2 genome concentration ($C$) in the original specimen, measured in copies per milliliter, and then evaluate it numerically.\n\nFirst, we establish the relationship between the final concentration $C$ and the measured cycle threshold $C_t$. Let $C$ be the concentration in copies/mL.\n\nThe number of template copies per reaction, $N$, is related to the original concentration $C$ through the sample processing volumes.\nThe concentration in the original specimen in copies per microliter is $c = C / 1000$.\nThe total number of viral genomes in the starting volume $V_{\\text{start}}$ is $c \\cdot V_{\\text{start}}$.\nAssuming ideal recovery, this total number of genomes is concentrated into the elution volume $V_{\\text{elute}}$. The concentration in the eluate is $c_{\\text{elute}} = (c \\cdot V_{\\text{start}}) / V_{\\text{elute}}$.\nA volume $V_{\\text{rxn}}$ of this eluate is used for the reaction. The number of copies in the reaction, $N$, is:\n$$N = c_{\\text{elute}} \\cdot V_{\\text{rxn}} = \\frac{c \\cdot V_{\\text{start}}}{V_{\\text{elute}}} \\cdot V_{\\text{rxn}}$$\nSubstituting $c = C/1000$:\n$$N = \\frac{(C/1000) \\cdot V_{\\text{start}} \\cdot V_{\\text{rxn}}}{V_{\\text{elute}}}$$\nThe problem provides the relationship between $C_t$ and the base-$10$ logarithm of $N$:\n$$C_t = m \\log_{10}(N) + b$$\nWe need to express $C$ as a function of $C_t$. First, we solve for $N$:\n$$\\log_{10}(N) = \\frac{C_t - b}{m}$$\n$$N = 10^{\\frac{C_t - b}{m}}$$\nNow, we solve the expression for $N$ in terms of $C$ for the concentration $C$:\n$$C = N \\cdot \\frac{1000 \\cdot V_{\\text{elute}}}{V_{\\text{start}} \\cdot V_{\\text{rxn}}}$$\nSubstituting the expression for $N$ in terms of $C_t$, we get the full relationship $C(C_t)$:\n$$C(C_t) = \\left( \\frac{1000 \\cdot V_{\\text{elute}}}{V_{\\text{start}} \\cdot V_{\\text{rxn}}} \\right) 10^{\\frac{C_t - b}{m}}$$\n\nNext, we propagate the uncertainty from $C_t$ to $C$. The problem provides the first-order error propagation formula, $\\sigma_C \\approx |\\frac{dC}{dC_t}| \\sigma_{C_t}$. We must find the derivative $\\frac{dC}{dC_t}$. The term in parentheses involving volumes is a constant factor. Let's call it $K$.\n$$K = \\frac{1000 \\cdot V_{\\text{elute}}}{V_{\\text{start}} \\cdot V_{\\text{rxn}}}$$\nSo, $C(C_t) = K \\cdot 10^{\\frac{C_t - b}{m}}$.\nUsing the chain rule for differentiation, and recalling that $\\frac{d}{dx}(a^x) = a^x \\ln(a)$:\n$$\\frac{dC}{dC_t} = K \\cdot \\frac{d}{dC_t}\\left(10^{\\frac{C_t - b}{m}}\\right)$$\n$$\\frac{dC}{dC_t} = K \\cdot \\left( 10^{\\frac{C_t - b}{m}} \\cdot \\ln(10) \\cdot \\frac{d}{dC_t}\\left(\\frac{C_t - b}{m}\\right) \\right)$$\n$$\\frac{dC}{dC_t} = K \\cdot 10^{\\frac{C_t - b}{m}} \\cdot \\ln(10) \\cdot \\frac{1}{m}$$\nRecognizing that $C(C_t) = K \\cdot 10^{\\frac{C_t - b}{m}}$, we can substitute $C(C_t)$ back into the derivative expression:\n$$\\frac{dC}{dC_t} = C(C_t) \\cdot \\frac{\\ln(10)}{m}$$\nNow, we can write the expression for the standard deviation $\\sigma_C$:\n$$\\sigma_C = \\left| \\frac{dC}{dC_t} \\right| \\sigma_{C_t} = \\left| C(C_t) \\cdot \\frac{\\ln(10)}{m} \\right| \\sigma_{C_t}$$\nSince concentration $C(C_t)$, $\\ln(10)$, and $\\sigma_{C_t}$ are non-negative, and $m$ is negative, the absolute value simplifies to:\n$$\\sigma_C = C(C_t) \\cdot \\frac{\\ln(10)}{|m|} \\cdot \\sigma_{C_t}$$\nThis is the derived symbolic expression for the absolute standard deviation of the specimen concentration.\n\nFinally, we evaluate this expression numerically.\nFirst, we calculate the mean concentration $C$ for the specimen with $C_t = 27.8$.\n$$C = \\left( \\frac{1000 \\, \\text{mL}^{-1} \\cdot 50 \\, \\mu L}{140 \\, \\mu L \\cdot 5 \\, \\mu L} \\right) \\cdot 10^{\\frac{27.8 - 41.2}{-3.30}}$$\n$$C = \\left( \\frac{50000}{700} \\right) \\cdot 10^{\\frac{-13.4}{-3.30}} \\, \\text{copies/mL}$$\n$$C = \\frac{500}{7} \\cdot 10^{4.060606...} \\, \\text{copies/mL}$$\n$$C \\approx 71.42857 \\cdot 11497.57 \\, \\text{copies/mL} \\approx 821255 \\, \\text{copies/mL}$$\nNow, we use this value to calculate $\\sigma_C$:\n$$\\sigma_C = C \\cdot \\frac{\\ln(10)}{|m|} \\cdot \\sigma_{C_t}$$\nSubstituting the given values:\n$$\\sigma_C \\approx 821255 \\, \\text{copies/mL} \\cdot \\frac{\\ln(10)}{|-3.30|} \\cdot 0.20$$\n$$\\sigma_C \\approx 821255 \\cdot \\frac{2.302585}{3.30} \\cdot 0.20 \\, \\text{copies/mL}$$\n$$\\sigma_C \\approx 821255 \\cdot 0.697753 \\cdot 0.20 \\, \\text{copies/mL}$$\n$$\\sigma_C \\approx 821255 \\cdot 0.1395506 \\, \\text{copies/mL}$$\n$$\\sigma_C \\approx 114605.3 \\, \\text{copies/mL}$$\nThe problem requires the answer to be rounded to three significant figures.\n$$\\sigma_C \\approx 115000 \\, \\text{copies/mL}$$\nIn scientific notation, this is $1.15 \\times 10^{5}$ copies/mL.", "answer": "$$\\boxed{1.15 \\times 10^{5}}$$", "id": "4623122"}, {"introduction": "A diagnostic test's utility is not solely defined by its intrinsic accuracy but also by the context in which it is used. This practice delves into the critical public health concepts of predictive values, which depend heavily on disease prevalence in the tested population. By analyzing a hypothetical screening program, you will learn why a positive test result in a low-prevalence setting warrants different consideration than one in a high-prevalence setting, providing the quantitative foundation for effective public health strategies [@problem_id:4623110].", "problem": "A university public health team is designing a severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) screening program using a rapid antigen assay with known performance characteristics. The assay has sensitivity = 0.82 and specificity = 0.985. The team considers two epidemiological settings: a low-prevalence screening context with prevalence $p_L = 0.01$, and a surge context with prevalence $p_H = 0.15$. Positive predictive value (PPV) is the probability of infection given a positive test, and negative predictive value (NPV) is the probability of no infection given a negative test.\n\nTasks:\n1) Using only the core definitions of sensitivity, specificity, and prevalence along with Bayes’ theorem, derive expressions for PPV and NPV in terms of sensitivity, specificity, and prevalence, and compute PPV and NPV for both $p_L$ and $p_H$.\n\n2) In the low-prevalence screening context $p_L$, compare two operational strategies for isolation decisions:\n- Strategy A: Isolate any individual after a single positive rapid antigen result.\n- Strategy B: Perform two sequential, independent rapid antigen tests immediately; isolate only if both tests are positive. Assume the two tests are conditionally independent given true infection status and each test has the same sensitivity and specificity as above.\n\nFor Strategy A and Strategy B under $p_L$, model the expected number of noninfected individuals isolated per $1000$ tested. Based on these expectations and your PPV/NPV results, briefly state which strategy is preferable in the low-prevalence setting to minimize unnecessary isolation while maintaining public health goals, justifying your choice in one sentence.\n\nFinally, report only the absolute reduction in the expected number of noninfected individuals isolated per $1000$ tested when using Strategy B instead of Strategy A under $p_L$. Round your final numerical answer to three significant figures. Express the unit conceptually as “people per $1000$ tested.”", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in established principles of epidemiology and biostatistics, well-posed with sufficient and consistent information, and objective in its formulation. All necessary parameters and assumptions, such as the conditional independence of sequential tests, are explicitly provided, allowing for a rigorous and unique solution.\n\nLet $D$ denote the event that an individual is infected with SARS-CoV-2, and $D^c$ denote the event that the individual is not infected. Let $T$ represent a positive test result and $T^c$ a negative test result. The prevalence is the prior probability of infection, $p = P(D)$. Consequently, $P(D^c) = 1 - p$.\n\nThe performance characteristics of the assay are given by:\n- Sensitivity, $Se = P(T|D) = 0.82$\n- Specificity, $Sp = P(T^c|D^c) = 0.985$\n\nFrom these, we can state the probabilities of incorrect test results:\n- False Positive Rate, $P(T|D^c) = 1 - P(T^c|D^c) = 1 - Sp = 1 - 0.985 = 0.015$\n- False Negative Rate, $P(T^c|D) = 1 - P(T|D) = 1 - Se = 1 - 0.82 = 0.18$\n\n**1) Derivation and Computation of PPV and NPV**\n\nPositive Predictive Value (PPV) is the probability of being infected given a positive test, $P(D|T)$. Negative Predictive Value (NPV) is the probability of not being infected given a negative test, $P(D^c|T^c)$. We use Bayes' theorem to derive expressions for these quantities.\n\nThe expression for PPV is derived as follows:\n$$PPV = P(D|T) = \\frac{P(T|D)P(D)}{P(T)}$$\nThe denominator, $P(T)$, is the total probability of a positive test, found using the law of total probability:\n$$P(T) = P(T|D)P(D) + P(T|D^c)P(D^c)$$\nSubstituting the definitions for sensitivity, specificity, and prevalence:\n$$P(T) = (Se)(p) + (1 - Sp)(1 - p)$$\nTherefore, the general expression for PPV is:\n$$PPV = \\frac{(Se)(p)}{(Se)(p) + (1 - Sp)(1 - p)}$$\n\nThe expression for NPV is derived similarly:\n$$NPV = P(D^c|T^c) = \\frac{P(T^c|D^c)P(D^c)}{P(T^c)}$$\nThe denominator, $P(T^c)$, is the total probability of a negative test:\n$$P(T^c) = P(T^c|D)P(D) + P(T^c|D^c)P(D^c) = (1 - Se)(p) + (Sp)(1 - p)$$\nTherefore, the general expression for NPV is:\n$$NPV = \\frac{(Sp)(1 - p)}{(Sp)(1 - p) + (1 - Se)(p)}$$\n\nWe now compute these values for the two given prevalence scenarios.\n\nFor the low-prevalence context, $p_L = 0.01$:\n$$PPV_{L} = \\frac{(0.82)(0.01)}{(0.82)(0.01) + (1 - 0.985)(1 - 0.01)} = \\frac{0.0082}{0.0082 + (0.015)(0.99)} = \\frac{0.0082}{0.0082 + 0.01485} = \\frac{0.0082}{0.02305} \\approx 0.355748$$\n$$NPV_{L} = \\frac{(0.985)(1 - 0.01)}{(0.985)(1 - 0.01) + (1 - 0.82)(0.01)} = \\frac{(0.985)(0.99)}{0.97515 + (0.18)(0.01)} = \\frac{0.97515}{0.97515 + 0.0018} = \\frac{0.97515}{0.97695} \\approx 0.998157$$\n\nFor the high-prevalence (surge) context, $p_H = 0.15$:\n$$PPV_{H} = \\frac{(0.82)(0.15)}{(0.82)(0.15) + (1 - 0.985)(1 - 0.15)} = \\frac{0.123}{0.123 + (0.015)(0.85)} = \\frac{0.123}{0.123 + 0.01275} = \\frac{0.123}{0.13575} \\approx 0.906077$$\n$$NPV_{H} = \\frac{(0.985)(1 - 0.15)}{(0.985)(1 - 0.15) + (1 - 0.82)(0.15)} = \\frac{(0.985)(0.85)}{0.83725 + (0.18)(0.15)} = \\frac{0.83725}{0.83725 + 0.027} = \\frac{0.83725}{0.86425} \\approx 0.968758$$\n\n**2) Comparison of Isolation Strategies in the Low-Prevalence Context**\n\nWe consider a population of $N=1000$ individuals tested in the low-prevalence setting, $p_L = 0.01$.\nThe expected number of infected individuals is $N \\times p_L = 1000 \\times 0.01 = 10$.\nThe expected number of non-infected individuals is $N \\times (1 - p_L) = 1000 \\times 0.99 = 990$.\n\nAn isolated non-infected individual represents a false positive outcome leading to unnecessary isolation. We calculate the expected number of such cases for each strategy.\n\n- **Strategy A: Isolate after a single positive test.**\nThe probability of a non-infected individual testing positive is the false positive rate, $P(T|D^c) = 1 - Sp = 0.015$.\nThe expected number of non-infected individuals isolated under Strategy A, $E_{A,noninf}$, is:\n$$E_{A,noninf} = (\\text{Number of non-infected}) \\times P(T|D^c) = 990 \\times 0.015 = 14.85$$\n\n- **Strategy B: Isolate after two consecutive positive tests.**\nLet $T_1$ and $T_2$ be the results of the first and second tests, respectively. Isolation occurs if both $T_1$ and $T_2$ are positive. The tests are conditionally independent given the true infection status.\nThe probability of a non-infected individual testing positive twice is $P(T_1 \\cap T_2 | D^c)$.\n$$P(T_1 \\cap T_2 | D^c) = P(T_1|D^c) \\times P(T_2|D^c) = (1 - Sp) \\times (1 - Sp) = (1 - Sp)^2$$\n$$P(T_1 \\cap T_2 | D^c) = (0.015)^2 = 0.000225$$\nThe expected number of non-infected individuals isolated under Strategy B, $E_{B,noninf}$, is:\n$$E_{B,noninf} = (\\text{Number of non-infected}) \\times P(T_1 \\cap T_2 | D^c) = 990 \\times 0.000225 = 0.22275$$\n\nThe low PPV of approximately $0.36$ for a single test indicates that nearly two-thirds of positive results are false positives. Strategy B is preferable because it dramatically reduces the number of false positive isolations by substantially increasing the positive predictive value of the test result, thereby minimizing the societal and personal costs of unnecessary isolation.\n\nFinally, we compute the absolute reduction in the expected number of non-infected individuals isolated per $1000$ tested when using Strategy B instead of Strategy A.\n$$\\text{Reduction} = E_{A,noninf} - E_{B,noninf} = 14.85 - 0.22275 = 14.62725$$\nRounding this result to three significant figures gives $14.6$.", "answer": "$$\\boxed{14.6}$$", "id": "4623110"}]}