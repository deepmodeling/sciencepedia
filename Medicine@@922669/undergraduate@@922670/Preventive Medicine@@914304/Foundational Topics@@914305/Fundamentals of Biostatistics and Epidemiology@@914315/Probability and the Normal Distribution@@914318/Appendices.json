{"hands_on_practices": [{"introduction": "Calculating probabilities is the first step in applying any probability distribution. The normal distribution is ubiquitous in medical and biological data, and understanding how to find the probability of an outcome falling within a specific range is a foundational skill. This exercise [@problem_id:1956240] provides practice in using the standard normal cumulative distribution function (CDF), typically denoted as $\\Phi(z)$, to determine probabilities for intervals, a necessary skill for hypothesis testing and risk assessment.", "problem": "In a quality control process for semiconductor manufacturing, the normalized electrical noise level of a certain type of microchip is found to be accurately modeled by a standard normal random variable, which we will denote as $Z$.\n\nThe standard normal distribution is a continuous probability distribution with a probability density function given by $f(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$ for $-\\infty < z < \\infty$. The probability that the random variable $Z$ takes on a value less than or equal to some constant $c$ is given by its Cumulative Distribution Function (CDF), which is commonly denoted as $\\Phi(c) = P(Z \\le c)$.\n\nA chip is designated as \"high-performance\" if its normalized noise level $Z$ falls strictly between a positive constant $k$ and twice that constant, i.e., $k < Z < 2k$.\n\nFind a general expression for the probability that a randomly selected microchip is classified as \"high-performance\". Your answer must be expressed solely in terms of the standard normal CDF, $\\Phi$, and the parameter $k$.", "solution": "Let $Z$ be a standard normal random variable with CDF $\\Phi(c) = P(Z \\le c)$. The event that a chip is \"high-performance\" is $\\{k<Z<2k\\}$, where $k>0$.\n\nBecause $Z$ has a continuous distribution with density $f(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^{2}}{2}\\right)$, it satisfies $P(Z=a)=0$ for any real $a$. Therefore, strict and non-strict inequalities have the same probabilities for interval events:\n$$\nP(k<Z<2k) = P(Z<2k) - P(Z\\le k)\n$$\nUsing the definition of the CDF,\n$$\nP(Z<2k) = \\Phi(2k) \\text{ and } P(Z\\le k) = \\Phi(k)\n$$\nso\n$$\nP(k<Z<2k) = \\Phi(2k) - \\Phi(k)\n$$\nThis expression is already in terms of $\\Phi$ and $k$, as required.", "answer": "$$\\boxed{\\Phi(2k)-\\Phi(k)}$$", "id": "1956240"}, {"introduction": "In preventive medicine, we often work with sample data to make inferences about an entire population's health. For continuous measurements like blood pressure or glucose levels, we need to estimate the true population mean and quantify our uncertainty. This practice problem [@problem_id:4563667] guides you through the crucial process of constructing and interpreting a confidence interval for a population mean when the variance is unknown, a common real-world scenario. It emphasizes the use of the Student's $t$-distribution and highlights the correct interpretation of \"confidence\" in a public health surveillance context.", "problem": "A community preventive medicine program conducts public health surveillance by periodically screening fasting plasma glucose among adults. In one screening round, a simple random sample of $n = 25$ adults is obtained under a design intended to approximate independent and identically distributed (iid) draws from a population. Let the individual measurements be $X_{1}, X_{2}, \\dots, X_{n}$, where each $X_{i}$ is modeled as iid Normal with common mean $\\mu$ and variance $\\sigma^{2}$, that is $X_{i} \\sim \\text{iid } N(\\mu, \\sigma^{2})$, and $\\sigma^{2}$ is unknown. The sample yields a sample mean of $\\bar{x} = 102$ milligrams per deciliter (mg/dL) and a sample standard deviation of $s = 18$ mg/dL.\n\nUsing only core definitions and well-tested facts about sampling distributions under the Normal model, first derive an analytic expression for the $100(1-\\alpha)\\%$ confidence interval for $\\mu$ when $\\sigma^{2}$ is unknown. Then, specialize to $\\alpha = 0.05$ and compute the numerical endpoints of the $95\\%$ confidence interval for $\\mu$ using the given data. Round your numerical endpoints to four significant figures. Express the final interval endpoints in mg/dL.\n\nFinally, interpret the coverage property of this interval in the surveillance context: explain, in terms of repeated rounds of such surveillance conducted under the same design and population conditions, what it means for the interval procedure to have $95\\%$ coverage.", "solution": "First, we derive an analytic expression for the $100(1-\\alpha)\\%$ confidence interval for the population mean $\\mu$ when the population variance $\\sigma^2$ is unknown.\nThe model states that the individual measurements $X_1, X_2, \\dots, X_n$ are independent and identically distributed (iid) draws from a Normal distribution with mean $\\mu$ and variance $\\sigma^2$, denoted as $X_i \\sim N(\\mu, \\sigma^2)$. The sample size is $n$.\nThe sample mean is $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$. Due to the properties of the Normal distribution, the sample mean $\\bar{X}$ is also normally distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$, i.e., $\\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})$.\n\nSince $\\sigma^2$ is unknown, it must be estimated from the sample. The unbiased estimator for $\\sigma^2$ is the sample variance, $S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2$. The sample standard deviation is $S = \\sqrt{S^2}$.\n\nA pivotal quantity is a function of the sample data and the unknown parameter whose distribution does not depend on the parameter. For a Normal sample with unknown variance, the appropriate pivotal quantity is the t-statistic:\n$$\nT = \\frac{\\bar{X} - \\mu}{S / \\sqrt{n}}\n$$\nBy a fundamental result in statistics (often related to Cochran's theorem), this quantity $T$ follows a Student's t-distribution with $\\nu = n-1$ degrees of freedom. We denote this as $T \\sim t_{n-1}$.\n\nTo construct a $100(1-\\alpha)\\%$ confidence interval, we find a critical value $t_{n-1, \\alpha/2}$ from the t-distribution such that the probability of a value falling in the tails is $\\alpha$. Specifically, $P(T > t_{n-1, \\alpha/2}) = \\alpha/2$. Due to the symmetry of the t-distribution about $0$, we have:\n$$\nP(-t_{n-1, \\alpha/2}  T  t_{n-1, \\alpha/2}) = 1 - \\alpha\n$$\nSubstituting the expression for $T$:\n$$\nP\\left(-t_{n-1, \\alpha/2}  \\frac{\\bar{X} - \\mu}{S / \\sqrt{n}}  t_{n-1, \\alpha/2}\\right) = 1 - \\alpha\n$$\nWe now rearrange the inequalities to isolate the parameter $\\mu$:\n$$\n-t_{n-1, \\alpha/2} \\cdot \\frac{S}{\\sqrt{n}}  \\bar{X} - \\mu  t_{n-1, \\alpha/2} \\cdot \\frac{S}{\\sqrt{n}}\n$$\nSubtracting $\\bar{X}$ from all parts:\n$$\n-\\bar{X} - t_{n-1, \\alpha/2} \\cdot \\frac{S}{\\sqrt{n}}  -\\mu  -\\bar{X} + t_{n-1, \\alpha/2} \\cdot \\frac{S}{\\sqrt{n}}\n$$\nMultiplying by $-1$ and reversing the direction of the inequalities:\n$$\n\\bar{X} + t_{n-1, \\alpha/2} \\cdot \\frac{S}{\\sqrt{n}} > \\mu > \\bar{X} - t_{n-1, \\alpha/2} \\cdot \\frac{S}{\\sqrt{n}}\n$$\nThis gives the analytical expression for the $100(1-\\alpha)\\%$ confidence interval for $\\mu$:\n$$\n\\left( \\bar{X} - t_{n-1, \\alpha/2} \\frac{S}{\\sqrt{n}}, \\bar{X} + t_{n-1, \\alpha/2} \\frac{S}{\\sqrt{n}} \\right)\n$$\nOr more compactly, $\\bar{X} \\pm t_{n-1, \\alpha/2} \\frac{S}{\\sqrt{n}}$.\n\nNext, we specialize this result for the given data and compute the $95\\%$ confidence interval.\nThe given values are:\nSample size $n = 25$.\nSample mean $\\bar{x} = 102$ mg/dL.\nSample standard deviation $s = 18$ mg/dL.\nThe confidence level is $95\\%$, so $1-\\alpha = 0.95$, which implies $\\alpha = 0.05$ and $\\alpha/2 = 0.025$.\nThe degrees of freedom are $\\nu = n-1 = 25 - 1 = 24$.\n\nWe need the critical value $t_{\\nu, \\alpha/2} = t_{24, 0.025}$. From a standard t-distribution table or statistical software, this value is approximately $2.064$.\n$t_{24, 0.025} \\approx 2.064$.\n\nThe standard error of the mean is calculated as:\n$$\nSE(\\bar{x}) = \\frac{s}{\\sqrt{n}} = \\frac{18}{\\sqrt{25}} = \\frac{18}{5} = 3.6\n$$\nThe margin of error (ME) is:\n$$\nME = t_{24, 0.025} \\times SE(\\bar{x}) \\approx 2.064 \\times 3.6 = 7.4304\n$$\nThe endpoints of the confidence interval are:\nLower bound: $\\bar{x} - ME = 102 - 7.4304 = 94.5696$.\nUpper bound: $\\bar{x} + ME = 102 + 7.4304 = 109.4304$.\n\nThe problem requires rounding the endpoints to four significant figures.\nFor the lower bound, $94.5696$, the four significant figures are $9$, $4$, $5$, and $6$. The next digit is $9$, so we round up: $94.57$.\nFor the upper bound, $109.4304$, the four significant figures are $1$, $0$, $9$, and $4$. The next digit is $3$, so we do not round up: $109.4$.\nThe numerical $95\\%$ confidence interval for $\\mu$ is $(94.57, 109.4)$ mg/dL.\n\nFinally, we interpret the coverage property of this interval procedure.\nThe $95\\%$ confidence level refers to the long-run performance of the method, not to a single calculated interval. In the context of the public health surveillance program, the interpretation is as follows: If this screening process (drawing a simple random sample of $n=25$ adults and computing the $95\\%$ confidence interval for the mean fasting glucose) were to be repeated a very large number of times under identical population conditions, then approximately $95\\%$ of the intervals so constructed would contain the true, unknown population mean glucose level, $\\mu$. The other $5\\%$ of the intervals would fail to capture $\\mu$. It is incorrect to state that there is a $95\\%$ probability that the specific interval $(94.57, 109.4)$ contains $\\mu$; once computed, this interval either does or does not contain $\\mu$. The probability is attached to the procedure of generating the interval, not to the outcome of a single instance.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n94.57  109.4\n\\end{pmatrix}\n}\n$$", "id": "4563667"}, {"introduction": "Real-world health outcomes are rarely independent; risk factors like blood pressure, BMI, and cholesterol are often correlated. To design effective studies or screening programs, researchers need to simulate realistic patient data that captures these complex relationships. This advanced exercise [@problem_id:4563690] introduces the powerful technique of generating correlated data using the multivariate normal distribution and Cholesky decomposition. Completing this simulation provides hands-on experience with the computational backbone of many modern epidemiological models and Monte Carlo studies.", "problem": "A public health research group is preparing a Monte Carlo study to evaluate a screening strategy in a large cohort. To realistically reflect joint variation in continuous risk factors that are approximately Gaussian after standard transformation (for example, systolic blood pressure, body mass index, and low-density lipoprotein cholesterol), they need to simulate correlated normal samples with prespecified mean vector and covariance matrix. The goal is to implement a principled algorithm, grounded in first principles, that generates multivariate normal samples with a given mean vector and covariance matrix, and then validate the empirical mean vector and covariance matrix against their targets using tolerances justified from sampling variability.\n\nFundamental base for the problem:\n- Definition of the multivariate normal distribution and the property that linear transformations of independent standard normal variables produce general multivariate normal variables.\n- Properties of covariance matrices, including symmetry and positive definiteness, and the existence and uniqueness of a lower-triangular factor for such matrices that can be used to construct the required linear transformation.\n- Sampling variability of empirical moments for independent and identically distributed draws from a multivariate normal distribution, including the variance of the sample mean and the variance structure of the maximum-likelihood covariance estimator when the true mean is known.\n\nYour task is to write a complete, runnable program that, for each provided test case, performs the following steps in a purely mathematical and algorithmic manner:\n\n1. Input specification is fixed within the program (no external input). For each test case, you are given:\n   - A dimension $d$ implied by the length of a mean vector $\\boldsymbol{\\mu} \\in \\mathbb{R}^d$.\n   - A symmetric covariance matrix $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}$ that is intended to be positive definite.\n   - A sample size $N \\in \\mathbb{N}$.\n   - A pseudo-random seed $s \\in \\mathbb{N}$.\n\n2. Validate that $\\boldsymbol{\\Sigma}$ is symmetric and positive definite. If $\\boldsymbol{\\Sigma}$ is not symmetric or is not positive definite, the test case result must be $[\\text{False},\\text{False}]$.\n\n3. Construct a transformation that maps independent standard normal draws to a multivariate normal draw with mean $\\boldsymbol{\\mu}$ and covariance $\\boldsymbol{\\Sigma}$ using the unique lower-triangular factor guaranteed by positive definiteness. Generate $N$ independent samples using a reproducible pseudo-random number generator initialized to seed $s$.\n\n4. Compute the empirical mean vector $\\widehat{\\boldsymbol{\\mu}} \\in \\mathbb{R}^d$ and the maximum-likelihood covariance estimate $\\widehat{\\boldsymbol{\\Sigma}} \\in \\mathbb{R}^{d \\times d}$ using centering at the known target mean $\\boldsymbol{\\mu}$.\n\n5. Define tolerance thresholds that reflect sampling variability under the multivariate normal model:\n   - For the mean, for each component $j \\in \\{1,\\dots,d\\}$, define the tolerance\n     $$\\tau^{(\\mu)}_j = k_{\\mu} \\sqrt{\\frac{\\boldsymbol{\\Sigma}_{jj}}{N}},$$\n     where $k_{\\mu} \\in \\mathbb{R}$ is a fixed multiplier. Use $k_{\\mu} = 4.0$.\n   - For the covariance, for each element $(i,j)$, define the tolerance\n     $$\\tau^{(\\Sigma)}_{ij} = k_{\\Sigma} \\sqrt{\\frac{\\boldsymbol{\\Sigma}_{ij}^2 + \\boldsymbol{\\Sigma}_{ii}\\boldsymbol{\\Sigma}_{jj}}{N}},$$\n     where $k_{\\Sigma} \\in \\mathbb{R}$ is a fixed multiplier. Use $k_{\\Sigma} = 4.0$.\n\n6. Determine two booleans for each test case:\n   - A mean-acceptance boolean that is $\\text{True}$ if and only if $|\\widehat{\\mu}_j - \\mu_j| \\le \\tau^{(\\mu)}_j$ for all $j \\in \\{1,\\dots,d\\}$.\n   - A covariance-acceptance boolean that is $\\text{True}$ if and only if $|\\widehat{\\Sigma}_{ij} - \\Sigma_{ij}| \\le \\tau^{(\\Sigma)}_{ij}$ for all $i,j \\in \\{1,\\dots,d\\}$.\n\n7. The final program output must be a single line containing a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a two-element list in square brackets containing the two booleans described in step $6$. For example, the format is\n   $$[\\,[b_{1,1},b_{1,2}],\\,[b_{2,1},b_{2,2}],\\,[b_{3,1},b_{3,2}],\\,[b_{4,1},b_{4,2}]\\,],$$\n   printed without spaces, where each $b_{k,\\ell}$ is either $\\text{True}$ or $\\text{False}$.\n\nTest suite:\n- Case $1$ (identity covariance, zero mean):\n  - $\\boldsymbol{\\mu} = [\\,0,\\,0,\\,0\\,]$.\n  - Correlation matrix $\\mathbf{C}_1 = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{bmatrix}$ and standard deviations $\\boldsymbol{\\sigma} = [\\,1,\\,1,\\,1\\,]$, so $\\boldsymbol{\\Sigma} = \\mathrm{diag}(\\boldsymbol{\\sigma})\\,\\mathbf{C}_1\\,\\mathrm{diag}(\\boldsymbol{\\sigma})$ equals the identity.\n  - $N = 50000$.\n  - $s = 12345$.\n\n- Case $2$ (realistic moderate correlations):\n  - $\\boldsymbol{\\mu} = [\\,120,\\,27,\\,130\\,]$.\n  - Correlation matrix $\\mathbf{C}_2 = \\begin{bmatrix} 1  0.4  -0.2 \\\\ 0.4  1  0.3 \\\\ -0.2  0.3  1 \\end{bmatrix}$ and standard deviations $\\boldsymbol{\\sigma} = [\\,12,\\,4,\\,25\\,]$, so $\\boldsymbol{\\Sigma} = \\mathrm{diag}(\\boldsymbol{\\sigma})\\,\\mathbf{C}_2\\,\\mathrm{diag}(\\boldsymbol{\\sigma})$.\n  - $N = 60000$.\n  - $s = 2468$.\n\n- Case $3$ (near-singular high correlation):\n  - $\\boldsymbol{\\mu} = [\\,50,\\,50,\\,50\\,]$.\n  - Correlation matrix with constant off-diagonal $r$: $\\mathbf{C}_3 = \\begin{bmatrix} 1  r  r \\\\ r  1  r \\\\ r  r  1 \\end{bmatrix}$ with $r = 0.99$ and standard deviations $\\boldsymbol{\\sigma} = [\\,10,\\,10,\\,10\\,]$, so $\\boldsymbol{\\Sigma} = \\mathrm{diag}(\\boldsymbol{\\sigma})\\,\\mathbf{C}_3\\,\\mathrm{diag}(\\boldsymbol{\\sigma})$.\n  - $N = 80000$.\n  - $s = 13579$.\n\n- Case $4$ (negative and mixed correlations):\n  - $\\boldsymbol{\\mu} = [\\,110,\\,23,\\,95\\,]$.\n  - Correlation matrix $\\mathbf{C}_4 = \\begin{bmatrix} 1  -0.4  0.1 \\\\ -0.4  1  0.3 \\\\ 0.1  0.3  1 \\end{bmatrix}$ and standard deviations $\\boldsymbol{\\sigma} = [\\,8,\\,6,\\,5\\,]$, so $\\boldsymbol{\\Sigma} = \\mathrm{diag}(\\boldsymbol{\\sigma})\\,\\mathbf{C}_4\\,\\mathrm{diag}(\\boldsymbol{\\sigma})$.\n  - $N = 70000$.\n  - $s = 97531$.\n\nImplementation constraints:\n- You must use a pseudorandom generator with a fixed seed per case to ensure reproducibility.\n- Center the covariance estimate at the known target $\\boldsymbol{\\mu}$ rather than the sample mean to align with the maximum-likelihood estimator under known mean.\n- No external inputs or files; all parameters are defined within the program.\n- The final output must be printed exactly as a single line in the format described in step $7$, with no spaces.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[\\,[\\text{True},\\text{True}],\\,[\\text{True},\\text{False}]\\,]$), printed without spaces.", "solution": "### Theoretical Framework\n\nThe generation of samples from a general multivariate normal distribution is predicated on a fundamental property of this distribution. A $d$-dimensional random vector $\\mathbf{X}$ is said to follow a multivariate normal distribution with mean vector $\\boldsymbol{\\mu} \\in \\mathbb{R}^d$ and covariance matrix $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}$, denoted $\\mathbf{X} \\sim \\mathcal{N}_d(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$, if for any constant vector $\\mathbf{a} \\in \\mathbb{R}^d$, the linear combination $\\mathbf{a}^T\\mathbf{X}$ is a univariate normal random variable.\n\nThe core principle for generating such samples is based on the affine transformation property. Let $\\mathbf{Z}$ be a $d$-dimensional random vector whose components are independent and identically distributed standard normal random variables, i.e., $Z_i \\sim \\mathcal{N}(0, 1)$ for $i=1, \\dots, d$. The mean of $\\mathbf{Z}$ is $\\mathbb{E}[\\mathbf{Z}] = \\mathbf{0}$ and its covariance matrix is $\\mathbb{E}[\\mathbf{Z}\\mathbf{Z}^T] = \\mathbf{I}$, the identity matrix.\n\nConsider a linear transformation of $\\mathbf{Z}$ of the form:\n$$ \\mathbf{X} = \\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z} $$\nwhere $\\mathbf{L}$ is a $d \\times d$ matrix. The mean of $\\mathbf{X}$ is:\n$$ \\mathbb{E}[\\mathbf{X}] = \\mathbb{E}[\\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z}] = \\boldsymbol{\\mu} + \\mathbf{L}\\mathbb{E}[\\mathbf{Z}] = \\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{0} = \\boldsymbol{\\mu} $$\nThe covariance matrix of $\\mathbf{X}$ is:\n$$ \\mathrm{Cov}(\\mathbf{X}) = \\mathbb{E}[(\\mathbf{X} - \\boldsymbol{\\mu})(\\mathbf{X} - \\boldsymbol{\\mu})^T] = \\mathbb{E}[(\\mathbf{L}\\mathbf{Z})(\\mathbf{L}\\mathbf{Z})^T] = \\mathbb{E}[\\mathbf{L}\\mathbf{Z}\\mathbf{Z}^T\\mathbf{L}^T] = \\mathbf{L}\\mathbb{E}[\\mathbf{Z}\\mathbf{Z}^T]\\mathbf{L}^T = \\mathbf{L}\\mathbf{I}\\mathbf{L}^T = \\mathbf{L}\\mathbf{L}^T $$\nTo generate samples $\\mathbf{X}$ with a target covariance matrix $\\boldsymbol{\\Sigma}$, we must find a matrix $\\mathbf{L}$ such that $\\boldsymbol{\\Sigma} = \\mathbf{L}\\mathbf{L}^T$.\n\n### Cholesky Decomposition\n\nA standard and computationally efficient method to find such a matrix $\\mathbf{L}$ is the Cholesky decomposition. A covariance matrix $\\boldsymbol{\\Sigma}$ must be symmetric and positive definite. A real, symmetric matrix $\\boldsymbol{\\Sigma}$ is positive definite if and only if it has a unique decomposition into the product of a lower-triangular matrix $\\mathbf{L}$ with positive diagonal entries and its transpose $\\mathbf{L}^T$:\n$$ \\boldsymbol{\\Sigma} = \\mathbf{L}\\mathbf{L}^T $$\nThis decomposition provides the required transformation matrix $\\mathbf{L}$. The existence of this unique decomposition is also a constructive test for positive definiteness. If the Cholesky decomposition algorithm succeeds, the matrix is positive definite; if it fails, the matrix is not.\n\n### Algorithm and Implementation\n\nThe solution proceeds through the following steps for each test case.\n\n1.  **Input Specification and Validation**: The given target mean vector $\\boldsymbol{\\mu}$, correlation matrix $\\mathbf{C}$, vector of standard deviations $\\boldsymbol{\\sigma}$, sample size $N$, and seed $s$ are defined. The covariance matrix $\\boldsymbol{\\Sigma}$ is constructed via the relation $\\boldsymbol{\\Sigma} = \\mathrm{diag}(\\boldsymbol{\\sigma})\\,\\mathbf{C}\\,\\mathrm{diag}(\\boldsymbol{\\sigma})$. The matrix $\\boldsymbol{\\Sigma}$ is first validated for symmetry, i.e., we check if $\\boldsymbol{\\Sigma} = \\boldsymbol{\\Sigma}^T$. Subsequently, its positive definiteness is confirmed by attempting to compute its Cholesky decomposition. If $\\boldsymbol{\\Sigma}$ is not symmetric or the decomposition fails, the matrix is not positive definite, and the result for the test case is recorded as $[\\text{False}, \\text{False}]$.\n\n2.  **Sample Generation**:\n    - A pseudo-random number generator is initialized with the specified seed $s$ for reproducibility.\n    - A matrix of $N \\times d$ independent standard normal samples, $\\mathbf{Z}_s$, is generated. Each row of $\\mathbf{Z}_s$ represents a single draw $\\mathbf{z}^T$ from the $d$-dimensional standard normal distribution.\n    - The Cholesky factor $\\mathbf{L}$ is computed from the valid covariance matrix $\\boldsymbol{\\Sigma}$.\n    - The $N$ samples from $\\mathcal{N}_d(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ are generated using the transformation. Let $\\mathbf{X}$ be the $N \\times d$ matrix of generated samples. The $i$-th row of $\\mathbf{X}$, denoted $\\mathbf{x}_i^T$, is computed as $\\mathbf{x}_i^T = \\boldsymbol{\\mu}^T + \\mathbf{z}_i^T \\mathbf{L}^T$. In matrix notation, this is $\\mathbf{X} = \\mathbf{1}\\boldsymbol{\\mu}^T + \\mathbf{Z}_s \\mathbf{L}^T$, where $\\mathbf{1}$ is a column vector of ones of length $N$.\n\n3.  **Empirical Moment Estimation**:\n    - The empirical mean vector $\\widehat{\\boldsymbol{\\mu}}$ is computed by averaging the sample vectors:\n      $$ \\widehat{\\boldsymbol{\\mu}} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{x}_i $$\n    - The maximum-likelihood estimate of the covariance matrix, given the known population mean $\\boldsymbol{\\mu}$, is computed as:\n      $$ \\widehat{\\boldsymbol{\\Sigma}} = \\frac{1}{N} \\sum_{i=1}^N (\\mathbf{x}_i - \\boldsymbol{\\mu})(\\mathbf{x}_i - \\boldsymbol{\\mu})^T $$\n\n4.  **Tolerance Calculation and Validation**:\n    - **Mean Validation**: For each component $j \\in \\{1,\\dots,d\\}$, the absolute difference $|\\widehat{\\mu}_j - \\mu_j|$ is compared against a tolerance $\\tau_j^{(\\mu)}$. This tolerance is proportional to the standard deviation of the sample mean estimator $\\widehat{\\mu}_j$, which is $\\sqrt{\\boldsymbol{\\Sigma}_{jj}/N}$. The tolerance is set to:\n      $$ \\tau_j^{(\\mu)} = k_{\\mu} \\sqrt{\\frac{\\boldsymbol{\\Sigma}_{jj}}{N}} $$\n      with $k_{\\mu} = 4.0$. The mean-acceptance boolean is $\\text{True}$ if $|\\widehat{\\mu}_j - \\mu_j| \\le \\tau_j^{(\\mu)}$ holds for all $j$.\n\n    - **Covariance Validation**: For each element $(i,j)$, the absolute difference $|\\widehat{\\Sigma}_{ij} - \\Sigma_{ij}|$ is compared against a tolerance $\\tau_{ij}^{(\\Sigma)}$. This tolerance is proportional to the standard deviation of the estimator $\\widehat{\\Sigma}_{ij}$, which for a normal distribution with known mean is $\\sqrt{(\\boldsymbol{\\Sigma}_{ij}^2 + \\boldsymbol{\\Sigma}_{ii}\\boldsymbol{\\Sigma}_{jj})/N}$. The tolerance is set to:\n      $$ \\tau_{ij}^{(\\Sigma)} = k_{\\Sigma} \\sqrt{\\frac{\\boldsymbol{\\Sigma}_{ij}^2 + \\boldsymbol{\\Sigma}_{ii}\\boldsymbol{\\Sigma}_{jj}}{N}} $$\n      with $k_{\\Sigma} = 4.0$. The covariance-acceptance boolean is $\\text{True}$ if $|\\widehat{\\Sigma}_{ij} - \\Sigma_{ij}| \\le \\tau_{ij}^{(\\Sigma)}$ holds for all pairs $(i, j)$.\n\nThe multiplier $k=4.0$ implies that the check is for whether the empirical estimate falls within $4$ standard deviations of its expected value. By Chebyshev's inequality, the probability of failure for any single check is less than $1/k^2 = 1/16$, and for a Gaussian estimator, it is much smaller (approximately $6 \\times 10^{-5}$). This makes the test stringent but accounts for expected sampling variability.\n\nThe final output is a list containing the pair of booleans $[\\text{mean-acceptance}, \\text{covariance-acceptance}]$ for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multivariate normal simulation and validation problem.\n    \"\"\"\n    test_cases = [\n        # Case 1: identity covariance, zero mean\n        {'mu': np.array([0., 0., 0.]),\n         'C': np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]]),\n         'sigma_vec': np.array([1., 1., 1.]),\n         'N': 50000,\n         's': 12345},\n        # Case 2: realistic moderate correlations\n        {'mu': np.array([120., 27., 130.]),\n         'C': np.array([[1., 0.4, -0.2], [0.4, 1., 0.3], [-0.2, 0.3, 1.]]),\n         'sigma_vec': np.array([12., 4., 25.]),\n         'N': 60000,\n         's': 2468},\n        # Case 3: near-singular high correlation\n        {'mu': np.array([50., 50., 50.]),\n         'C': np.array([[1., 0.99, 0.99], [0.99, 1., 0.99], [0.99, 0.99, 1.]]),\n         'sigma_vec': np.array([10., 10., 10.]),\n         'N': 80000,\n         's': 13579},\n        # Case 4: negative and mixed correlations\n        {'mu': np.array([110., 23., 95.]),\n         'C': np.array([[1., -0.4, 0.1], [-0.4, 1., 0.3], [0.1, 0.3, 1.]]),\n         'sigma_vec': np.array([8., 6., 5.]),\n         'N': 70000,\n         's': 97531},\n    ]\n\n    results = []\n    k_mu = 4.0\n    k_Sigma = 4.0\n\n    for case in test_cases:\n        mu = case['mu']\n        C = case['C']\n        sigma_vec = case['sigma_vec']\n        N = case['N']\n        s = case['s']\n\n        # 1. Construct covariance matrix Sigma\n        D = np.diag(sigma_vec)\n        Sigma = D @ C @ D\n        \n        # 2. Validate Sigma: must be symmetric and positive definite\n        # Check symmetry\n        if not np.allclose(Sigma, Sigma.T):\n            results.append([False, False])\n            continue\n        \n        # Check positive definiteness by attempting Cholesky decomposition\n        try:\n            L = np.linalg.cholesky(Sigma)\n        except np.linalg.LinAlgError:\n            results.append([False, False])\n            continue\n\n        # 3. Generate samples\n        d = len(mu)\n        rng = np.random.default_rng(seed=s)\n        Z = rng.standard_normal(size=(N, d))\n        # X = mu + Z @ L.T\n        X = mu + Z.dot(L.T)\n\n        # 4. Compute empirical statistics\n        # Empirical mean\n        mu_hat = np.mean(X, axis=0)\n        \n        # Empirical covariance (MLE with known mean mu)\n        X_centered_known_mean = X - mu\n        # Sigma_hat = (X_centered_known_mean.T @ X_centered_known_mean) / N\n        Sigma_hat = np.cov(X_centered_known_mean, rowvar=False, ddof=0)\n        \n        # 5. Define tolerance thresholds\n        # Mean tolerance\n        tol_mu = k_mu * np.sqrt(np.diag(Sigma) / N)\n        \n        # Covariance tolerance\n        Sigma_ii = np.diag(Sigma).reshape(-1, 1)\n        Sigma_jj = np.diag(Sigma).reshape(1, -1)\n        Sigma_ii_jj = Sigma_ii @ Sigma_jj\n        tol_Sigma = k_Sigma * np.sqrt((np.square(Sigma) + Sigma_ii_jj) / N)\n\n        # 6. Determine acceptance booleans\n        mean_accepted = np.all(np.abs(mu_hat - mu) = tol_mu)\n        cov_accepted = np.all(np.abs(Sigma_hat - Sigma) = tol_Sigma)\n        \n        results.append([bool(mean_accepted), bool(cov_accepted)])\n\n    # 7. Format final output\n    formatted_results = [str(r).replace(' ', '') for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4563690"}]}