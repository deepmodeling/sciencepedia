{"hands_on_practices": [{"introduction": "The first step in any data analysis is to accurately describe and summarize the dataset. While the sample mean is a common measure of central tendency, it can be highly misleading in the presence of outliers, which are common in medical data due to instrument or human error. This exercise [@problem_id:4519105] introduces robust descriptive statistics, such as the trimmed mean and the Median Absolute Deviation (MAD), which provide a more reliable picture of the data's center and spread when outliers are present. Working through this problem will provide crucial hands-on skills in identifying the impact of extreme values and choosing appropriate summary statistics, a fundamental practice in preventive medicine.", "problem": "A population screening in preventive medicine uses automated laboratory analyzers to measure fasting plasma glucose for $n=40$ adults (unit: $\\mathrm{mg/dL}$). Due to intermittent instrument error, exactly $5\\%$ of the measurements are gross outliers. The measured values (in $\\mathrm{mg/dL}$) are: $85, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 104, 105, 105, 105, 105, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 120, 122, 124, 126, 128, 400, 405$. Using the following foundational definitions from descriptive statistics:\n- The sample mean $\\bar{x}$ is $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$.\n- The $p$-trimmed mean discards the lowest $p$ proportion and highest $p$ proportion of the ordered sample and then computes the mean of the remaining observations; for $p=0.20$ and $n=40$, this removes $8$ lowest and $8$ highest values.\n- The sample median $\\tilde{x}$ is the midpoint of the ordered sample; for an even $n$, it is the average of the two middle values.\n- The Median Absolute Deviation (MAD) is defined here as $\\operatorname{MAD} = \\operatorname{median}\\left(|x_i - \\tilde{x}|\\right)$ (unscaled).\n\nCompute the $20\\%$ trimmed mean and the MAD for these measurements, and contrast them with the non-trimmed sample mean by forming the dimensionless quantity\n$$D = \\frac{\\bar{x} - \\bar{x}_{\\text{trim}}}{\\operatorname{MAD}}.$$\nRound your final answer for $D$ to four significant figures. No units are required for $D$.", "solution": "The problem requires the computation of a dimensionless quantity, $D$, which contrasts the standard sample mean with a robust measure of central tendency (the trimmed mean), scaled by a robust measure of dispersion (the Median Absolute Deviation, or MAD). The calculation will proceed in several steps: first, calculation of the sample mean $\\bar{x}$; second, the $20\\%$ trimmed mean $\\bar{x}_{\\text{trim}}$; third, the sample median $\\tilde{x}$ and the corresponding MAD; and finally, the value of $D$.\n\nThe provided dataset consists of $n=40$ measurements of fasting plasma glucose. The data are given in sorted order, which we denote as $x_{(i)}$ for $i=1, \\dots, 40$:\n$\\{85, 88, 90, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 104, 105, 105, 105, 105, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 120, 122, 124, 126, 128, 400, 405\\}$.\n\n**1. Calculation of the Sample Mean ($\\bar{x}$)**\nThe sample mean is defined as $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$.\nFirst, we compute the sum of all $40$ observations:\n$$ \\sum_{i=1}^{40} x_i = 85 + 88 + \\dots + 128 + 400 + 405 = 4833 $$\nThe sample mean is therefore:\n$$ \\bar{x} = \\frac{4833}{40} = 120.825 $$\n\n**2. Calculation of the $20\\%$ Trimmed Mean ($\\bar{x}_{\\text{trim}}$)**\nThe problem specifies a $p=0.20$ trimmed mean. For a sample size of $n=40$, the number of observations to be discarded from each end of the ordered sample is $k = p \\times n = 0.20 \\times 40 = 8$.\nWe must remove the $8$ lowest values and the $8$ highest values.\nThe $8$ lowest values are: $85, 88, 90, 92, 93, 94, 95, 96$.\nThe $8$ highest values are: $118, 120, 122, 124, 126, 128, 400, 405$.\nThe remaining number of observations is $n - 2k = 40 - 2(8) = 24$. These are the observations from $x_{(9)}$ to $x_{(32)}$.\nThe trimmed dataset is: $\\{98, 99, 100, 101, 102, 103, 104, 104, 105, 105, 105, 105, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116\\}$.\nThe sum of these $24$ values is:\n$$ \\sum_{i=9}^{32} x_{(i)} = 98 + 99 + \\dots + 116 = 2557 $$\nThe $20\\%$ trimmed mean is the mean of these remaining values:\n$$ \\bar{x}_{\\text{trim}} = \\frac{2557}{24} $$\n\n**3. Calculation of the Sample Median ($\\tilde{x}$) and Median Absolute Deviation (MAD)**\nFirst, we find the sample median $\\tilde{x}$. Since $n=40$ is an even number, the median is the average of the two middle observations, $x_{(n/2)}$ and $x_{(n/2)+1}$, which are $x_{(20)}$ and $x_{(21)}$.\nFrom the sorted data:\n$x_{(20)} = 105$\n$x_{(21)} = 105$\nThe sample median is:\n$$ \\tilde{x} = \\frac{105 + 105}{2} = 105 $$\nNext, we calculate the MAD, defined as $\\operatorname{MAD} = \\operatorname{median}\\left(|x_i - \\tilde{x}|\\right)$. We compute the absolute deviations $|x_i - 105|$ for all $40$ observations and then find the median of this new set of values.\nThe absolute deviations are:\n$|85-105|=20$, $|88-105|=17$, $|90-105|=15$, $|92-105|=13$, $|93-105|=12$, $|94-105|=11$, $|95-105|=10$, $|96-105|=9$, $|98-105|=7$, $|99-105|=6$, $|100-105|=5$, $|101-105|=4$, $|102-105|=3$, $|103-105|=2$, $|104-105|=1$ (twice), $|105-105|=0$ (five times), $|106-105|=1$, $|107-105|=2$, $|108-105|=3$, $|109-105|=4$, $|110-105|=5$, $|111-105|=6$, $|112-105|=7$, $|113-105|=8$, $|114-105|=9$, $|115-105|=10$, $|116-105|=11$, $|118-105|=13$, $|120-105|=15$, $|122-105|=17$, $|124-105|=19$, $|126-105|=21$, $|128-105|=23$, $|400-105|=295$, $|405-105|=300$.\n\nLet's sort these $40$ absolute deviations:\n$0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 9, 9, 10, 10, 11, 11, 12, 13, 13, 15, 15, 17, 17, 19, 20, 21, 23, 295, 300$.\nTo find the median of these $40$ values, we average the $20$-th and $21$-st values.\nThe $20$-th value is $7$.\nThe $21$-st value is $8$.\nThe MAD is:\n$$ \\operatorname{MAD} = \\frac{7 + 8}{2} = 7.5 $$\n\n**4. Calculation of the Dimensionless Quantity $D$**\nWe now compute $D$ using the formula $D = \\frac{\\bar{x} - \\bar{x}_{\\text{trim}}}{\\operatorname{MAD}}$.\nSubstituting the calculated values:\n$$ D = \\frac{120.825 - \\frac{2557}{24}}{7.5} $$\nFirst, we evaluate the numerator:\n$$ \\bar{x} - \\bar{x}_{\\text{trim}} = \\frac{4833}{40} - \\frac{2557}{24} = \\frac{4833 \\times 3}{120} - \\frac{2557 \\times 5}{120} = \\frac{14499 - 12785}{120} = \\frac{1714}{120} = \\frac{857}{60} $$\nNow, we divide by the MAD:\n$$ D = \\frac{857/60}{7.5} = \\frac{857/60}{15/2} = \\frac{857}{60} \\times \\frac{2}{15} = \\frac{857}{30 \\times 15} = \\frac{857}{450} $$\nTo obtain the final numerical answer, we perform the division:\n$$ D \\approx 1.90444... $$\nThe problem asks for the result to be rounded to four significant figures.\n$$ D \\approx 1.904 $$\nThe value of $D$ quantifies the substantial impact of the outliers on the sample mean. The difference between the sample mean and the trimmed mean is nearly twice the value of the median absolute deviation, indicating a significant distortion caused by the non-robustness of the sample mean.", "answer": "$$\\boxed{1.904}$$", "id": "4519105"}, {"introduction": "Beyond describing a single dataset, a primary goal of statistics is to make inferences by comparing groups. This practice [@problem_id:4771494] moves from descriptive to inferential statistics, tackling the common task of comparing the mean outcomes of two independent groups. You will learn to construct a confidence interval for the difference in means, which provides a range of plausible values for the true effect in the population, and to calculate Cohen's $d$, a standardized measure of effect size that quantifies the magnitude of the difference. These tools are essential for interpreting the results of clinical trials and observational studies.", "problem": "A historian of medicine is studying the long-running pedagogical debate between manualism (exposure to sign language) and oralism (speech-only methods) in early twentieth-century Deaf education, a central theme in the history of disability and rehabilitation medicine. From archival school records, two independent cohorts of students were identified. The first cohort consists of students exposed to sign language with a sample size of $n_{S} = 60$, sample mean literacy score $\\bar{x}_{S} = 78$, and sample standard deviation $s_{S} = 10$. The second cohort consists of students educated under oralism with a sample size of $n_{O} = 60$, sample mean literacy score $\\bar{x}_{O} = 68$, and sample standard deviation $s_{O} = 12$. Assume the scores are independent between groups and approximately normally distributed. Do not assume equal population variances unless justified by the sample evidence.\n\nUsing only foundational definitions and well-tested statistical results about sampling distributions for mean differences with unknown variances, compute:\n- The standardized mean difference (Cohen’s $d$) using the pooled within-group standard deviation.\n- A two-sided $95\\%$ confidence interval (CI) for the raw difference in means, defined as $\\bar{x}_{S} - \\bar{x}_{O}$, expressed in the test’s raw score points.\n\nRound all reported numerical results to $3$ significant figures. Provide your final answer as a row vector $[d,\\ \\text{lower bound},\\ \\text{upper bound}]$ with no units in the box.", "solution": "The solution requires two calculations: Cohen's $d$ and a $95\\%$ confidence interval for the difference in means.\n\n**1. Calculation of Cohen’s $d$**\n\nThe problem explicitly requests the use of the pooled within-group standard deviation, $s_p$. This is appropriate for calculating an effect size under the assumption of homogeneity of variances. The formula for the pooled standard deviation is:\n$$ s_p = \\sqrt{\\frac{(n_{S} - 1)s_{S}^2 + (n_{O} - 1)s_{O}^2}{n_{S} + n_{O} - 2}} $$\nSubstituting the given values:\n$$ n_{S} = 60, s_{S} = 10, n_{O} = 60, s_{O} = 12 $$\nSince the sample sizes are equal ($n_S = n_O = 60$), the formula for the squared pooled variance simplifies:\n$$ s_p^2 = \\frac{(60 - 1)10^2 + (60 - 1)12^2}{60 + 60 - 2} = \\frac{59(10^2 + 12^2)}{118} = \\frac{59(100 + 144)}{118} = \\frac{1}{2} \\times 244 = 122 $$\nThe pooled standard deviation is:\n$$ s_p = \\sqrt{122} \\approx 11.04536 $$\nCohen's $d$ is defined as the difference in means divided by the pooled standard deviation:\n$$ d = \\frac{\\bar{x}_{S} - \\bar{x}_{O}}{s_p} $$\nThe difference in means is $\\bar{x}_{S} - \\bar{x}_{O} = 78 - 68 = 10$.\n$$ d = \\frac{10}{\\sqrt{122}} \\approx \\frac{10}{11.04536} \\approx 0.90535 $$\nRounding to $3$ significant figures, Cohen's $d$ is $0.905$.\n\n**2. Calculation of the $95\\%$ Confidence Interval**\n\nIt is most appropriate to use the Welch-Satterthwaite method, which does not assume equal population variances. The formula for the confidence interval for the difference between two independent means, $\\mu_S - \\mu_O$, is:\n$$ (\\bar{x}_{S} - \\bar{x}_{O}) \\pm t_{\\alpha/2, \\nu} \\cdot \\sqrt{\\frac{s_{S}^2}{n_{S}} + \\frac{s_{O}^2}{n_{O}}} $$\nThe term under the square root is the squared standard error of the difference:\n$$ SE_{\\bar{x}_S - \\bar{x}_O} = \\sqrt{\\frac{10^2}{60} + \\frac{12^2}{60}} = \\sqrt{\\frac{100}{60} + \\frac{144}{60}} = \\sqrt{\\frac{244}{60}} = \\sqrt{\\frac{61}{15}} \\approx \\sqrt{4.06667} \\approx 2.01660 $$\nFor a $95\\%$ confidence interval, the significance level is $\\alpha = 1 - 0.95 = 0.05$, so $\\alpha/2 = 0.025$. The degrees of freedom, $\\nu$, are calculated using the Welch-Satterthwaite equation:\n$$ \\nu = \\frac{\\left(\\frac{s_{S}^2}{n_{S}} + \\frac{s_{O}^2}{n_{O}}\\right)^2}{\\frac{\\left(\\frac{s_{S}^2}{n_{S}}\\right)^2}{n_{S} - 1} + \\frac{\\left(\\frac{s_{O}^2}{n_{O}}\\right)^2}{n_{O} - 1}} $$\nSubstituting the values:\n$$ \\nu = \\frac{\\left(\\frac{100}{60} + \\frac{144}{60}\\right)^2}{\\frac{\\left(\\frac{100}{60}\\right)^2}{59} + \\frac{\\left(\\frac{144}{60}\\right)^2}{59}} = \\frac{\\left(\\frac{244}{60}\\right)^2}{\\frac{1}{59}\\left[\\left(\\frac{100}{60}\\right)^2 + \\left(\\frac{144}{60}\\right)^2\\right]} = \\frac{(\\frac{61}{15})^2}{\\frac{1}{59}\\left[(\\frac{5}{3})^2 + (\\frac{12}{5})^2\\right]} $$\n$$ \\nu = \\frac{16.5370}{\\frac{1}{59}\\left[2.7778 + 5.76\\right]} = \\frac{16.5370}{\\frac{8.5378}{59}} \\approx \\frac{16.5370}{0.144708} \\approx 114.28 $$\nThe degrees of freedom are typically truncated to the nearest integer, so $\\nu = 114$. We need the critical value $t_{0.025, 114}$ from the t-distribution. Using a standard statistical calculator, $t_{0.025, 114} \\approx 1.981$.\nThe margin of error ($ME$) is:\n$$ ME = t_{\\alpha/2, \\nu} \\cdot SE_{\\bar{x}_S - \\bar{x}_O} \\approx 1.981 \\times 2.01660 \\approx 3.99488 $$\nThe confidence interval is calculated around the observed difference in means, which is $10$:\n$$ CI = 10 \\pm 3.99488 $$\nLower bound: $10 - 3.99488 = 6.00512$\nUpper bound: $10 + 3.99488 = 13.99488$\nRounding these bounds to $3$ significant figures:\n- Lower bound: $6.01$\n- Upper bound: $14.0$\n\nThe final answer is a row vector containing Cohen's $d$, the lower bound of the CI, and the upper bound of the CI.\n$$ [d, \\text{lower bound}, \\text{upper bound}] = [0.905, 6.01, 14.0] $$", "answer": "$$ \\boxed{\\begin{pmatrix} 0.905  6.01  14.0 \\end{pmatrix}} $$", "id": "4771494"}, {"introduction": "In preventive medicine, we often work with binary outcomes like the presence or absence of a disease. This exercise [@problem_id:4519113] introduces a cornerstone of epidemiological analysis: the risk ratio ($RR$), which compares the probability of an event in an exposed group to that in an unexposed group. You will apply a critical technique—the logarithmic transformation—to construct a valid confidence interval for the $RR$, a method that overcomes the mathematical challenges posed by ratio measures. This practice will deepen your understanding of how to quantify relative risk and also connect the statistical concept of a confidence interval to the theoretical idea of Fisher information, which represents the amount of information the data provide about the parameter.", "problem": "A community-based hand-hygiene education program is evaluated in a prospective cohort study to prevent gastrointestinal infection. Among the intervention group, there are $n_1 = 1200$ individuals, of whom $a = 80$ develop infection during follow-up. Among the contemporaneous comparison group without the intervention, there are $n_0 = 1000$ individuals, of whom $c = 120$ develop infection. Let the risk in the intervention group be $p_1 = a/n_1$ and in the comparison group be $p_0 = c/n_0$, and let the risk ratio be $\\widehat{RR} = \\widehat{p}_1/\\widehat{p}_0$.\n\nUsing only the fundamental definitions of risk and risk ratio, the Central Limit Theorem (CLT) for binomial proportions, and the delta method, construct a two-sided $95\\%$ confidence interval for the risk ratio by first working on the $\\log$ scale and then back-transforming to the natural scale. Define the multiplicative width of the interval on the natural scale as $W = \\text{upper}/\\text{lower}$.\n\nFinally, interpret the interval width in terms of information for $\\log(\\widehat{RR})$ by using the connection between confidence interval width on the $\\log$ scale and the standard error. Compute the approximate expected Fisher information $I$ for $\\log(\\widehat{RR})$ that is implied by your construction. Round your final answer to four significant figures. Express your final answer as a unitless number.", "solution": "The problem asks for the approximate expected Fisher information for the logarithm of the risk ratio, derived from the construction of a $95\\%$ confidence interval. Let's proceed with the step-by-step derivation.\n\nFirst, we define the parameters and their estimators.\nThe risk of infection in the intervention group is $p_1$, estimated by $\\widehat{p}_1$.\nThe risk of infection in the comparison group is $p_0$, estimated by $\\widehat{p}_0$.\n\nThe givens are:\n- Intervention group size: $n_1 = 1200$\n- Infections in intervention group: $a = 80$\n- Comparison group size: $n_0 = 1000$\n- Infections in comparison group: $c = 120$\n\nThe point estimates for the risks are:\n$$ \\widehat{p}_1 = \\frac{a}{n_1} = \\frac{80}{1200} = \\frac{1}{15} $$\n$$ \\widehat{p}_0 = \\frac{c}{n_0} = \\frac{120}{1000} = \\frac{12}{100} = \\frac{3}{25} $$\n\nThe risk ratio, $RR$, is the ratio of these risks, $RR = p_1/p_0$. Its point estimate is:\n$$ \\widehat{RR} = \\frac{\\widehat{p}_1}{\\widehat{p}_0} = \\frac{1/15}{3/25} = \\frac{1}{15} \\times \\frac{25}{3} = \\frac{25}{45} = \\frac{5}{9} $$\n\nThe problem requires constructing a confidence interval by first working on the logarithmic scale. The parameter of interest on this scale is $\\theta = \\log(RR)$. Its estimator is $\\widehat{\\theta} = \\log(\\widehat{RR})$.\n$$ \\widehat{\\theta} = \\log(\\widehat{RR}) = \\log\\left(\\frac{\\widehat{p}_1}{\\widehat{p}_0}\\right) = \\log(\\widehat{p}_1) - \\log(\\widehat{p}_0) $$\nBy the Central Limit Theorem, for large $n$, the sample proportion $\\widehat{p}$ is approximately normally distributed. To find the variance of $\\log(\\widehat{RR})$, we use the delta method. For a function $g(X)$, the variance is approximately $\\text{Var}(g(X)) \\approx [g'(E[X])]^2 \\text{Var}(X)$.\nHere, we apply this to $\\log(\\widehat{p}_1)$ and $\\log(\\widehat{p}_0)$. Let $g(p) = \\log(p)$, so $g'(p) = 1/p$. The variance of a binomial proportion estimator $\\widehat{p}$ is $\\text{Var}(\\widehat{p}) = \\frac{p(1-p)}{n}$.\n\nApplying the delta method:\n$$ \\text{Var}(\\log(\\widehat{p})) \\approx \\left(\\frac{d}{dp}\\log(p)\\right)^2 \\text{Var}(\\widehat{p}) = \\left(\\frac{1}{p}\\right)^2 \\frac{p(1-p)}{n} = \\frac{1-p}{np} $$\nSince the two groups are independent, the variance of the difference is the sum of the variances:\n$$ \\text{Var}(\\log(\\widehat{RR})) = \\text{Var}(\\log(\\widehat{p}_1)) + \\text{Var}(\\log(\\widehat{p}_0)) \\approx \\frac{1-p_1}{n_1 p_1} + \\frac{1-p_0}{n_0 p_0} $$\nTo construct a confidence interval, we need the standard error, which is the square root of the estimated variance. We estimate the variance by substituting the sample proportions $\\widehat{p}_1$ and $\\widehat{p}_0$ for the true proportions $p_1$ and $p_0$:\n$$ \\widehat{\\text{Var}}(\\log(\\widehat{RR})) = \\frac{1-\\widehat{p}_1}{n_1 \\widehat{p}_1} + \\frac{1-\\widehat{p}_0}{n_0 \\widehat{p}_0} $$\nRecognizing that $n_1 \\widehat{p}_1 = a$ and $n_0 \\widehat{p}_0 = c$, we can simplify this to:\n$$ \\widehat{\\text{Var}}(\\log(\\widehat{RR})) = \\left(\\frac{1}{a} - \\frac{1}{n_1}\\right) + \\left(\\frac{1}{c} - \\frac{1}{n_0}\\right) $$\nPlugging in the given values:\n$$ \\widehat{\\text{Var}}(\\log(\\widehat{RR})) = \\left(\\frac{1}{80} - \\frac{1}{1200}\\right) + \\left(\\frac{1}{120} - \\frac{1}{1000}\\right) $$\n$$ \\widehat{\\text{Var}}(\\log(\\widehat{RR})) = \\left(\\frac{15}{1200} - \\frac{1}{1200}\\right) + \\left(\\frac{25}{3000} - \\frac{3}{3000}\\right) $$\n$$ \\widehat{\\text{Var}}(\\log(\\widehat{RR})) = \\frac{14}{1200} + \\frac{22}{3000} = \\frac{7}{600} + \\frac{11}{1500} $$\nTo sum these fractions, we find a common denominator, which is $3000$:\n$$ \\widehat{\\text{Var}}(\\log(\\widehat{RR})) = \\frac{7 \\times 5}{3000} + \\frac{11 \\times 2}{3000} = \\frac{35+22}{3000} = \\frac{57}{3000} $$\nA $95\\%$ confidence interval for $\\log(RR)$ is given by $\\widehat{\\theta} \\pm z_{1-\\alpha/2} \\times SE(\\widehat{\\theta})$, where $SE(\\widehat{\\theta}) = \\sqrt{\\widehat{\\text{Var}}(\\widehat{\\theta})}$. For a $95\\%$ CI, $\\alpha=0.05$ and $z_{0.975} \\approx 1.96$.\n\nThe problem then asks to connect this to Fisher information. The Fisher information, $I(\\theta)$, for a parameter $\\theta$ is, under regularity conditions, the reciprocal of the variance of its maximum likelihood estimator (MLE). For large samples, the estimator $\\widehat{\\theta} = \\log(\\widehat{RR})$ is the MLE for $\\theta = \\log(RR)$, and its variance approaches the Cramér-Rao lower bound, which is $1/I(\\theta)$.\n\nThe \"approximate expected Fisher information $I$ for $\\log(\\widehat{RR})$ that is implied by your construction\" refers to the estimated Fisher information, $\\widehat{I}$, which is the reciprocal of the estimated variance of the estimator.\n$$ I \\approx \\widehat{I}(\\log(RR)) = \\frac{1}{\\widehat{\\text{Var}}(\\log(\\widehat{RR}))} $$\nUsing the variance we calculated:\n$$ I \\approx \\frac{1}{57/3000} = \\frac{3000}{57} $$\nDividing both numerator and denominator by $3$ gives:\n$$ I \\approx \\frac{1000}{19} $$\nNow we compute the numerical value:\n$$ I \\approx 52.631578... $$\nRounding the final answer to four significant figures, we get $52.63$.\nThe connection to the confidence interval width is that the width is proportional to the standard error, and the information is inversely proportional to the variance (the square of the standard error). A narrower interval implies a smaller variance and thus higher information content from the data regarding the parameter.", "answer": "$$\n\\boxed{52.63}\n$$", "id": "4519113"}]}