{"hands_on_practices": [{"introduction": "The core power of network meta-analysis lies in its ability to compare treatments that have never been studied in a head-to-head trial. This is achieved by calculating an \"indirect\" estimate of effect, based on the fundamental assumption of network consistency. This foundational exercise [@problem_id:4977502] walks you through the derivation of an indirect treatment comparison, revealing how evidence can be chained together across a network and how the uncertainty of that evidence propagates.", "problem": "Consider a set of randomized controlled trials (RCTs) forming a minimally connected three-treatment network in which treatment $A$ has been compared to treatment $B$ and treatment $B$ has been compared to treatment $C$, but there is no direct comparison between treatment $A$ and treatment $C$. Assume the effect measure is on an additive scale (for example, a mean difference or the logarithm of a ratio-scale effect such that additivity holds on that transformed scale). Let each treatment $t \\in \\{A,B,C\\}$ be associated with a study-level parameter $\\theta_{t}$ representing its expected outcome on the additive scale. Define the relative effect of treatment $X$ versus treatment $Y$ as $d_{XY} = \\theta_{X} - \\theta_{Y}$.\n\nSuppose that the pairwise meta-analytic pooled estimates from the $A$ versus $B$ comparisons and from the $B$ versus $C$ comparisons are available as $\\hat{d}_{AB}$ and $\\hat{d}_{BC}$, respectively, each being unbiased for $d_{AB}$ and $d_{BC}$ under standard meta-analytic regularity conditions. Let their sampling variances be $v_{AB} = \\operatorname{Var}(\\hat{d}_{AB})$ and $v_{BC} = \\operatorname{Var}(\\hat{d}_{BC})$. Assume that the $A$ versus $B$ evidence and the $B$ versus $C$ evidence are drawn from disjoint sets of trials and there are no multi-arm trials linking $A$, $B$, and $C$ simultaneously, so that $\\hat{d}_{AB}$ and $\\hat{d}_{BC}$ are independent.\n\nStarting from the core definitions above and the network meta-analysis (NMA) consistency assumption that the treatment-specific parameters $\\theta_{t}$ are coherent across the network, derive the indirect estimator of the $A$ versus $C$ relative effect, $\\hat{d}_{AC}$, and determine its sampling variance under the stated independence. Express your final answer as a closed-form analytic expression in terms of $\\hat{d}_{AB}$, $\\hat{d}_{BC}$, $v_{AB}$, and $v_{BC}$. No numerical evaluation is required, and no rounding is needed. Provide your final answer as a two-element row matrix containing the indirect estimator and its variance.", "solution": "The problem presents a valid and well-posed question in the field of network meta-analysis. It provides a complete and consistent set of givens, adheres to established scientific principles, and is formulated in precise, objective language. The task is to derive the estimator for an indirect comparison and its corresponding variance, a fundamental procedure in this statistical domain.\n\nThe problem describes a three-treatment network involving treatments $A$, $B$, and $C$. The available evidence consists of direct comparisons between $A$ and $B$, and between $B$ and $C$. There is no direct evidence comparing $A$ and $C$. The goal is to estimate the relative effect of $A$ versus $C$, denoted $d_{AC}$, using the available information.\n\nLet $\\theta_A$, $\\theta_B$, and $\\theta_C$ represent the true mean effects of treatments $A$, $B$, and $C$, respectively, on an additive scale. The relative treatment effect between any two treatments $X$ and $Y$ is defined as $d_{XY} = \\theta_X - \\theta_Y$.\n\nThe core principle that enables the synthesis of evidence across a network is the consistency assumption. This assumption posits that all treatment effects are coherent and can be mapped onto a single underlying framework defined by the treatment-specific parameters $\\theta_t$. For our three-treatment chain $A-B-C$, the consistency equation relates the direct and indirect effects as follows:\n$$\nd_{AC} = d_{AB} + d_{BC}\n$$\nThis can be shown by substituting the definitions of the relative effects in terms of the absolute effects:\n$$\nd_{AB} + d_{BC} = (\\theta_A - \\theta_B) + (\\theta_B - \\theta_C) = \\theta_A - \\theta_C = d_{AC}\n$$\nThe consistency equation provides the theoretical foundation for estimating $d_{AC}$ indirectly.\n\nWe are given two independent, unbiased estimators for the direct comparisons:\n$1$. $\\hat{d}_{AB}$, an estimator for $d_{AB}$ with variance $v_{AB} = \\operatorname{Var}(\\hat{d}_{AB})$.\n$2$. $\\hat{d}_{BC}$, an estimator for $d_{BC}$ with variance $v_{BC} = \\operatorname{Var}(\\hat{d}_{BC})$.\n\nThe unbiasedness implies that $E[\\hat{d}_{AB}] = d_{AB}$ and $E[\\hat{d}_{BC}] = d_{BC}$. The independence implies that their covariance is zero: $\\operatorname{Cov}(\\hat{d}_{AB}, \\hat{d}_{BC}) = 0$.\n\nTo derive the indirect estimator for $d_{AC}$, which we shall denote $\\hat{d}_{AC}$, we use the \"plug-in\" principle based on the consistency equation. We substitute the estimators for the true effects into the equation:\n$$\n\\hat{d}_{AC} = \\hat{d}_{AB} + \\hat{d}_{BC}\n$$\nThis expression provides the point estimate for the indirect comparison of $A$ versus $C$. We can verify that this estimator is unbiased for $d_{AC}$. Using the linearity of the expectation operator:\n$$\nE[\\hat{d}_{AC}] = E[\\hat{d}_{AB} + \\hat{d}_{BC}] = E[\\hat{d}_{AB}] + E[\\hat{d}_{BC}]\n$$\nSubstituting the known expected values:\n$$\nE[\\hat{d}_{AC}] = d_{AB} + d_{BC}\n$$\nBy the consistency equation, $d_{AB} + d_{BC} = d_{AC}$, so we have:\n$$\nE[\\hat{d}_{AC}] = d_{AC}\n$$\nThus, the indirect estimator $\\hat{d}_{AC}$ is an unbiased estimator of the true relative effect $d_{AC}$.\n\nNext, we derive the sampling variance of this indirect estimator, $\\operatorname{Var}(\\hat{d}_{AC})$. The variance of a sum of two random variables is given by the formula:\n$$\n\\operatorname{Var}(X+Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) + 2\\operatorname{Cov}(X,Y)\n$$\nApplying this to our estimator $\\hat{d}_{AC}$:\n$$\n\\operatorname{Var}(\\hat{d}_{AC}) = \\operatorname{Var}(\\hat{d}_{AB} + \\hat{d}_{BC}) = \\operatorname{Var}(\\hat{d}_{AB}) + \\operatorname{Var}(\\hat{d}_{BC}) + 2\\operatorname{Cov}(\\hat{d}_{AB}, \\hat{d}_{BC})\n$$\nThe problem statement specifies that the evidence for $A$ versus $B$ and $B$ versus $C$ comes from disjoint sets of trials, ensuring that the estimators $\\hat{d}_{AB}$ and $\\hat{d}_{BC}$ are statistically independent. For independent random variables, the covariance is zero.\n$$\n\\operatorname{Cov}(\\hat{d}_{AB}, \\hat{d}_{BC}) = 0\n$$\nSubstituting this into the variance equation simplifies it to:\n$$\n\\operatorname{Var}(\\hat{d}_{AC}) = \\operatorname{Var}(\\hat{d}_{AB}) + \\operatorname{Var}(\\hat{d}_{BC})\n$$\nFinally, using the provided notation for the variances, $v_{AB} = \\operatorname{Var}(\\hat{d}_{AB})$ and $v_{BC} = \\operatorname{Var}(\\hat{d}_{BC})$, we obtain the final expression for the variance of the indirect estimator:\n$$\n\\operatorname{Var}(\\hat{d}_{AC}) = v_{AB} + v_{BC}\n$$\nThis demonstrates that for an indirect comparison, the point estimate is the sum of the constituent direct estimates, and its variance is the sum of their variances, under the assumption of independence.\n\nTherefore, the two quantities requested are the indirect estimator $\\hat{d}_{AC} = \\hat{d}_{AB} + \\hat{d}_{BC}$ and its sampling variance $\\operatorname{Var}(\\hat{d}_{AC}) = v_{AB} + v_{BC}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\hat{d}_{AB} + \\hat{d}_{BC} & v_{AB} + v_{BC} \\end{pmatrix}}\n$$", "id": "4977502"}, {"introduction": "In a network meta-analysis, not all evidence comes from simple two-arm trials. Multi-arm trials, which compare three or more treatments simultaneously, provide a wealth of information but introduce a statistical nuance: the effect estimates derived from them are correlated because they share a common comparator group. This practice [@problem_id:4977559] explains why this correlation exists and guides you through deriving the covariance matrix, a crucial step for accurately modeling the evidence from these efficient trial designs.", "problem": "Consider a single three-arm randomized controlled trial (RCT) included in a Network Meta-Analysis (NMA) comparing interventions $A$, $B$, and $C$, where $A$ is the common reference. For each arm $t \\in \\{A,B,C\\}$, suppose there is an arm-level estimator $\\hat{\\mu}_{t}$ of a marginal parameter $\\mu_{t}$ (for example, the log-risk in arm $t$ for a binary outcome), and assume the following foundational principles:\n- By large-sample theory for maximum likelihood estimators, each $\\hat{\\mu}_{t}$ is approximately normally distributed with mean $\\mu_{t}$ and variance $v_{t} = \\mathrm{Var}(\\hat{\\mu}_{t})$.\n- Due to randomization and non-overlapping patient groups across arms, the arm-level estimators are uncorrelated across arms, that is $\\mathrm{Cov}(\\hat{\\mu}_{t}, \\hat{\\mu}_{s}) = 0$ for $t \\neq s$.\n\nDefine the two contrasts that share the common reference arm $A$ by\n$$\n\\hat{d}_{BA} = \\hat{\\mu}_{B} - \\hat{\\mu}_{A}\n\\quad \\text{and} \\quad\n\\hat{d}_{CA} = \\hat{\\mu}_{C} - \\hat{\\mu}_{A}.\n$$\nExplain from first principles why $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$ are correlated in a multi-arm trial under the above assumptions. Then, using only the properties of variances and covariances of linear combinations of random variables, derive the $2 \\times 2$ covariance matrix of the vector of contrasts $\\big(\\hat{d}_{BA}, \\hat{d}_{CA}\\big)^{\\top}$ in closed form as a function of $v_{A}$, $v_{B}$, and $v_{C}$.\n\nExpress your final answer as a single analytic matrix expression. No rounding is required.", "solution": "The user-provided problem is valid. It is scientifically sound, grounded in the standard statistical theory underlying network meta-analysis, and is well-posed, with all necessary assumptions provided to derive a unique solution. We shall proceed with the derivation.\n\nThe problem requires a two-part answer: first, a conceptual explanation for the correlation between contrast estimators from a multi-arm trial, and second, a formal derivation of their covariance matrix. The foundational assumptions are that for a three-arm trial comparing treatments $A$, $B$, and $C$, the arm-level estimators $\\hat{\\mu}_{A}$, $\\hat{\\mu}_{B}$, and $\\hat{\\mu}_{C}$ are statistically uncorrelated, i.e., $\\mathrm{Cov}(\\hat{\\mu}_{t}, \\hat{\\mu}_{s}) = 0$ for $t \\neq s$, and have variances $\\mathrm{Var}(\\hat{\\mu}_{t}) = v_{t}$.\n\nThe two contrasts relative to the common reference arm $A$ are defined as:\n$$\n\\hat{d}_{BA} = \\hat{\\mu}_{B} - \\hat{\\mu}_{A}\n$$\n$$\n\\hat{d}_{CA} = \\hat{\\mu}_{C} - \\hat{\\mu}_{A}\n$$\n\n**Conceptual Explanation of Correlation**\n\nFrom first principles, two random variables are correlated if they share a common source of random variation. In this case, both $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$ are functions of the same random variable, $\\hat{\\mu}_{A}$. The arm-level estimator $\\hat{\\mu}_{A}$ is subject to sampling error; it is an estimate of the true parameter $\\mu_{A}$ and will deviate from this true value in any given sample.\n\nIf sampling error causes $\\hat{\\mu}_{A}$ to be an overestimate of $\\mu_{A}$, its value is subtracted in the calculation of both $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$. This will cause both $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$ to be systematically smaller than they would be otherwise. Conversely, if $\\hat{\\mu}_{A}$ is an underestimate of $\\mu_{A}$, its smaller value is subtracted, causing both $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$ to be systematically larger. Because a random deviation in $\\hat{\\mu}_{A}$ in one direction simultaneously pushes both $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$ in the opposite direction, the two contrast estimators are not independent; they are, in fact, correlated. The formal measure of this statistical dependence is their covariance, which we expect to be non-zero.\n\n**Derivation of the Covariance Matrix**\n\nThe task is to find the $2 \\times 2$ covariance matrix of the vector of contrasts $\\mathbf{\\hat{d}} = (\\hat{d}_{BA}, \\hat{d}_{CA})^{\\top}$. This matrix, denoted by $\\mathbf{\\Sigma}$, has the form:\n$$\n\\mathbf{\\Sigma} = \\begin{pmatrix} \\mathrm{Var}(\\hat{d}_{BA}) & \\mathrm{Cov}(\\hat{d}_{BA}, \\hat{d}_{CA}) \\\\ \\mathrm{Cov}(\\hat{d}_{CA}, \\hat{d}_{BA}) & \\mathrm{Var}(\\hat{d}_{CA}) \\end{pmatrix}\n$$\nWe will derive each component of this matrix using the fundamental properties of variance and covariance for linear combinations of random variables.\n\n**1. Variance of $\\hat{d}_{BA}$**\n\nThe variance of a difference of two random variables $X$ and $Y$ is given by $\\mathrm{Var}(X - Y) = \\mathrm{Var}(X) + \\mathrm{Var}(Y) - 2\\mathrm{Cov}(X, Y)$. Applying this to $\\hat{d}_{BA} = \\hat{\\mu}_{B} - \\hat{\\mu}_{A}$:\n$$\n\\mathrm{Var}(\\hat{d}_{BA}) = \\mathrm{Var}(\\hat{\\mu}_{B} - \\hat{\\mu}_{A}) = \\mathrm{Var}(\\hat{\\mu}_{B}) + \\mathrm{Var}(\\hat{\\mu}_{A}) - 2\\mathrm{Cov}(\\hat{\\mu}_{B}, \\hat{\\mu}_{A})\n$$\nUsing the given information: $\\mathrm{Var}(\\hat{\\mu}_{B}) = v_{B}$, $\\mathrm{Var}(\\hat{\\mu}_{A}) = v_{A}$, and $\\mathrm{Cov}(\\hat{\\mu}_{B}, \\hat{\\mu}_{A}) = 0$ (since $B \\neq A$).\n$$\n\\mathrm{Var}(\\hat{d}_{BA}) = v_{B} + v_{A} - 2(0) = v_{A} + v_{B}\n$$\n\n**2. Variance of $\\hat{d}_{CA}$**\n\nThe derivation is identical for $\\hat{d}_{CA} = \\hat{\\mu}_{C} - \\hat{\\mu}_{A}$:\n$$\n\\mathrm{Var}(\\hat{d}_{CA}) = \\mathrm{Var}(\\hat{\\mu}_{C} - \\hat{\\mu}_{A}) = \\mathrm{Var}(\\hat{\\mu}_{C}) + \\mathrm{Var}(\\hat{\\mu}_{A}) - 2\\mathrm{Cov}(\\hat{\\mu}_{C}, \\hat{\\mu}_{A})\n$$\nUsing the given information: $\\mathrm{Var}(\\hat{\\mu}_{C}) = v_{C}$, $\\mathrm{Var}(\\hat{\\mu}_{A}) = v_{A}$, and $\\mathrm{Cov}(\\hat{\\mu}_{C}, \\hat{\\mu}_{A}) = 0$ (since $C \\neq A$).\n$$\n\\mathrm{Var}(\\hat{d}_{CA}) = v_{C} + v_{A} - 2(0) = v_{A} + v_{C}\n$$\n\n**3. Covariance of $\\hat{d}_{BA}$ and $\\hat{d}_{CA}$**\n\nThis term quantifies the correlation explained conceptually above. Using the bilinearity property of the covariance operator:\n$$\n\\mathrm{Cov}(\\hat{d}_{BA}, \\hat{d}_{CA}) = \\mathrm{Cov}(\\hat{\\mu}_{B} - \\hat{\\mu}_{A}, \\hat{\\mu}_{C} - \\hat{\\mu}_{A})\n$$\nExpanding this expression gives:\n$$\n\\mathrm{Cov}(\\hat{d}_{BA}, \\hat{d}_{CA}) = \\mathrm{Cov}(\\hat{\\mu}_{B}, \\hat{\\mu}_{C}) - \\mathrm{Cov}(\\hat{\\mu}_{B}, \\hat{\\mu}_{A}) - \\mathrm{Cov}(\\hat{\\mu}_{A}, \\hat{\\mu}_{C}) + \\mathrm{Cov}(\\hat{\\mu}_{A}, \\hat{\\mu}_{A})\n$$\nWe now substitute the known values based on the problem's assumptions:\n-   $\\mathrm{Cov}(\\hat{\\mu}_{B}, \\hat{\\mu}_{C}) = 0$ (since $B \\neq C$)\n-   $\\mathrm{Cov}(\\hat{\\mu}_{B}, \\hat{\\mu}_{A}) = 0$ (since $B \\neq A$)\n-   $\\mathrm{Cov}(\\hat{\\mu}_{A}, \\hat{\\mu}_{C}) = 0$ (since $A \\neq C$)\n-   $\\mathrm{Cov}(\\hat{\\mu}_{A}, \\hat{\\mu}_{A}) = \\mathrm{Var}(\\hat{\\mu}_{A}) = v_{A}$\n\nSubstituting these results yields:\n$$\n\\mathrm{Cov}(\\hat{d}_{BA}, \\hat{d}_{CA}) = 0 - 0 - 0 + v_{A} = v_{A}\n$$\nSince the covariance operator is symmetric, $\\mathrm{Cov}(\\hat{d}_{CA}, \\hat{d}_{BA}) = \\mathrm{Cov}(\\hat{d}_{BA}, \\hat{d}_{CA}) = v_{A}$. The non-zero covariance confirms that the two contrasts are indeed correlated, and the correlation is positive since $v_A = \\mathrm{Var}(\\hat{\\mu}_A) \\ge 0$.\n\n**Assembly of the Covariance Matrix**\n\nFinally, we substitute the derived components back into the matrix $\\mathbf{\\Sigma}$:\n$$\n\\mathbf{\\Sigma} = \\begin{pmatrix}\nv_{A} + v_{B} & v_{A} \\\\\nv_{A} & v_{A} + v_{C}\n\\end{pmatrix}\n$$\nThis is the closed-form expression for the covariance matrix of the vector of contrasts.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nv_{A} + v_{B} & v_{A} \\\\\nv_{A} & v_{A} + v_{C}\n\\end{pmatrix}\n}\n$$", "id": "4977559"}, {"introduction": "The ultimate goal of medical research is to inform clinical decisions, and the results of a network meta-analysis are most useful when translated from statistical ratios into concrete, absolute terms. This exercise [@problem_id:4977475] demonstrates how to convert a relative effect, such as a log-risk ratio from an NMA, into an absolute risk for a specific patient population with a known baseline risk. Mastering this conversion is key to communicating the real-world impact of different health interventions.", "problem": "A medical decision analyst is using Network Meta-Analysis (NMA) to translate relative treatment effects into absolute risks for a target population. Let the target population baseline risk under standard care be $p_{0} = 0.20$. From an NMA that synthesizes randomized controlled trials under a fixed-effect model, the analyst has the following treatment-specific estimates relative to standard care: for treatment $A$, the estimated log-risk ratio is $\\hat{\\theta}_{A} = -0.2231435513$ with estimated variance $\\widehat{\\mathrm{Var}}(\\hat{\\theta}_{A}) = 0.04$; for treatment $B$, the estimated log-risk ratio is $\\hat{\\theta}_{B} = -0.5108256238$ with estimated variance $\\widehat{\\mathrm{Var}}(\\hat{\\theta}_{B}) = 0.0225$. Assume the large-sample normal approximation for the log-risk ratio estimator holds and that the baseline risk $p_{0}$ is externally valid for the target population.\n\nStarting from the core definitions of risk ratio and the log transformation, derive the formula to map from the log-risk ratio to the absolute risk on the probability scale, and construct a $95\\%$ interval for each treatmentâ€™s absolute risk using the normal approximation on the log scale and a monotone transformation to the risk scale. Compute the predicted absolute risk and its $95\\%$ interval for treatments $A$ and $B$, and present the final numerical answers as a single row matrix in the order $\\big(p_{A},\\ \\text{lower}_{A},\\ \\text{upper}_{A},\\ p_{B},\\ \\text{lower}_{B},\\ \\text{upper}_{B}\\big)$. Express all risks as decimal fractions and round all six numbers to four significant figures.", "solution": "The problem is deemed valid as it is scientifically grounded in the principles of network meta-analysis, well-posed with a complete and consistent set of givens, and objective in its formulation. The task is to derive the transformation from a log-risk ratio to an absolute risk and then to apply this to compute point estimates and $95\\%$ confidence intervals for the absolute risks of two treatments, A and B.\n\nFirst, we establish the theoretical foundation. Let $p_k$ be the absolute risk (probability of an event) for a patient receiving treatment $k$, and let $p_c$ be the absolute risk for a patient receiving the standard care or control treatment. The problem provides the baseline risk for the control group as $p_0 = 0.20$, so we identify $p_c = p_0$.\n\nThe Risk Ratio ($RR$) for treatment $k$ relative to the control is defined as the ratio of their risks:\n$$RR_k = \\frac{p_k}{p_c}$$\nThe log-risk ratio, denoted by $\\theta_k$, is the natural logarithm of the risk ratio:\n$$\\theta_k = \\ln(RR_k) = \\ln\\left(\\frac{p_k}{p_c}\\right)$$\nTo derive the formula for the absolute risk $p_k$ in terms of the log-risk ratio $\\theta_k$ and the baseline risk $p_c$, we solve the above equation for $p_k$. Exponentiating both sides yields:\n$$\\exp(\\theta_k) = \\frac{p_k}{p_c}$$\nMultiplying by $p_c$ isolates $p_k$:\n$$p_k = p_c \\cdot \\exp(\\theta_k)$$\nSubstituting the given baseline risk $p_0$ for $p_c$, the predictive mapping from the log-risk ratio to the absolute risk is:\n$$p_k = p_0 \\cdot \\exp(\\theta_k)$$\nGiven an estimate of the log-risk ratio, $\\hat{\\theta}_k$, the corresponding point estimate for the absolute risk, $\\hat{p}_k$, is:\n$$\\hat{p}_k = p_0 \\cdot \\exp(\\hat{\\theta}_k)$$\n\nNext, we address the construction of the $95\\%$ confidence interval ($CI$). The problem states that the large-sample normal approximation for the log-risk ratio estimator holds. This means we can model $\\hat{\\theta}_k$ as being drawn from a normal distribution:\n$$\\hat{\\theta}_k \\sim N(\\theta_k, \\widehat{\\mathrm{Var}}(\\hat{\\theta}_k))$$\nThe standard error ($SE$) of the estimator is the square root of its variance: $SE(\\hat{\\theta}_k) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\theta}_k)}$. A $(1-\\alpha) \\times 100\\%$ confidence interval for the true log-risk ratio $\\theta_k$ is constructed as:\n$$CI_{\\theta_k} = \\left[ \\hat{\\theta}_k - z_{1-\\alpha/2} \\cdot SE(\\hat{\\theta}_k), \\ \\hat{\\theta}_k + z_{1-\\alpha/2} \\cdot SE(\\hat{\\theta}_k) \\right]$$\nFor a $95\\%$ confidence interval, $\\alpha=0.05$, and the critical value from the standard normal distribution is $z_{1-0.05/2} = z_{0.975} \\approx 1.96$.\n\nThe transformation function $f(\\theta) = p_0 \\exp(\\theta)$ is a strictly monotonically increasing function. This property allows us to construct a confidence interval for the absolute risk $p_k$ by applying the transformation function to the lower and upper bounds of the confidence interval for $\\theta_k$.\nThe $95\\%$ confidence interval for $p_k$ is therefore:\n$$CI_{p_k} = \\left[ p_0 \\exp\\left(\\hat{\\theta}_k - z_{0.975} \\cdot SE(\\hat{\\theta}_k)\\right), \\ p_0 \\exp\\left(\\hat{\\theta}_k + z_{0.975} \\cdot SE(\\hat{\\theta}_k)\\right) \\right]$$\n\nNow we apply these formulas to the specific treatments, using the provided data and rounding the final results to four significant figures.\n\n**Treatment A**\nGivens:\n$\\hat{\\theta}_A = -0.2231435513$\n$\\widehat{\\mathrm{Var}}(\\hat{\\theta}_A) = 0.04$\n$p_0 = 0.20$\n\nFirst, compute the standard error for $\\hat{\\theta}_A$:\n$$SE(\\hat{\\theta}_A) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\theta}_A)} = \\sqrt{0.04} = 0.2$$\nThe point estimate for the absolute risk for treatment A, $\\hat{p}_A$, is:\n$$\\hat{p}_A = p_0 \\exp(\\hat{\\theta}_A) = 0.20 \\times \\exp(-0.2231435513) = 0.20 \\times 0.8 = 0.16$$\nTo four significant figures, $\\hat{p}_A = 0.1600$.\n\nThe $95\\%$ confidence interval for $\\theta_A$ is:\n$$CI_{\\theta_A} = [-0.2231435513 - 1.96 \\times 0.2, \\ -0.2231435513 + 1.96 \\times 0.2]$$\n$$CI_{\\theta_A} = [-0.2231435513 - 0.392, \\ -0.2231435513 + 0.392]$$\n$$CI_{\\theta_A} = [-0.6151435513, \\ 0.1688564487]$$\nThe $95\\%$ confidence interval for $p_A$ is found by transforming these bounds:\nLower bound: $p_{A, \\text{lower}} = 0.20 \\times \\exp(-0.6151435513) \\approx 0.108112$\nUpper bound: $p_{A, \\text{upper}} = 0.20 \\times \\exp(0.1688564487) \\approx 0.236788$\nRounding to four significant figures, the confidence interval is $[0.1081, 0.2368]$.\n\n**Treatment B**\nGivens:\n$\\hat{\\theta}_B = -0.5108256238$\n$\\widehat{\\mathrm{Var}}(\\hat{\\theta}_B) = 0.0225$\n$p_0 = 0.20$\n\nThe standard error for $\\hat{\\theta}_B$ is:\n$$SE(\\hat{\\theta}_B) = \\sqrt{\\widehat{\\mathrm{Var}}(\\hat{\\theta}_B)} = \\sqrt{0.0225} = 0.15$$\nThe point estimate for the absolute risk for treatment B, $\\hat{p}_B$, is:\n$$\\hat{p}_B = p_0 \\exp(\\hat{\\theta}_B) = 0.20 \\times \\exp(-0.5108256238) = 0.20 \\times 0.6 = 0.12$$\nTo four significant figures, $\\hat{p}_B = 0.1200$.\n\nThe $95\\%$ confidence interval for $\\theta_B$ is:\n$$CI_{\\theta_B} = [-0.5108256238 - 1.96 \\times 0.15, \\ -0.5108256238 + 1.96 \\times 0.15]$$\n$$CI_{\\theta_B} = [-0.5108256238 - 0.294, \\ -0.5108256238 + 0.294]$$\n$$CI_{\\theta_B} = [-0.8048256238, \\ -0.2168256238]$$\nThe $95\\%$ confidence interval for $p_B$ is found by transforming these bounds:\nLower bound: $p_{B, \\text{lower}} = 0.20 \\times \\exp(-0.8048256238) \\approx 0.089432$\nUpper bound: $p_{B, \\text{upper}} = 0.20 \\times \\exp(-0.2168256238) \\approx 0.161014$\nRounding to four significant figures, the confidence interval is $[0.08943, 0.1610]$.\n\nThe final results are compiled into a single row matrix as requested:\n$(\\hat{p}_A, p_{A, \\text{lower}}, p_{A, \\text{upper}}, \\hat{p}_B, p_{B, \\text{lower}}, p_{B, \\text{upper}})$.\nThe values are $(0.1600, 0.1081, 0.2368, 0.1200, 0.08943, 0.1610)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.1600 & 0.1081 & 0.2368 & 0.1200 & 0.08943 & 0.1610\n\\end{pmatrix}\n}\n$$", "id": "4977475"}]}