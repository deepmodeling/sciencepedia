{"hands_on_practices": [{"introduction": "This first exercise grounds us in the essential mechanics of hypothesis testing. Using a classic public health scenario—evaluating a new intervention's effectiveness—we will practice the core skill of converting an observed test statistic into a $p$-value [@problem_id:4538632]. This practice reinforces the fundamental definition of the $p$-value and the critical thinking required to translate a statistical result into a meaningful, context-aware conclusion.", "problem": "A public health department conducts a randomized controlled trial (RCT) to evaluate whether a new community health worker intervention increases colon cancer screening completion compared with standard outreach. The primary analysis uses a large-sample normal approximation for the difference in proportions, summarized by a standardized test statistic $z$ such that positive values indicate higher screening completion in the intervention arm. The null hypothesis is $H_{0}: \\Delta \\le 0$, and the one-sided superiority alternative is $H_{1}: \\Delta > 0$, where $\\Delta$ denotes the true difference in population proportions (intervention minus control). The observed value of the test statistic is $z=1.95$. The prespecified Type I error rate is $\\alpha=0.025$ for a one-sided test.\n\nUsing only the fundamental definition of a one-sided $p$-value as a tail probability under the null hypothesis and the properties of the standard normal distribution, compute the one-sided $p$-value corresponding to $z=1.95$. State the decision rule for a one-sided superiority test at level $\\alpha=0.025$ and interpret the result in the context of the trial. Round your $p$-value to three significant figures and express it as a decimal.", "solution": "The problem will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n- Study Type: Randomized controlled trial (RCT)\n- Intervention vs. Control: A new community health worker intervention vs. standard outreach.\n- Outcome: Colon cancer screening completion.\n- Analysis: Large-sample normal approximation for the difference in proportions, summarized by a standardized test statistic $z$.\n- Hypotheses: The null hypothesis is $H_{0}: \\Delta \\le 0$, and the one-sided superiority alternative is $H_{1}: \\Delta  0$, where $\\Delta$ is the true difference in population proportions (intervention minus control).\n- Observed Data: The value of the test statistic is $z=1.95$.\n- Significance Level: The prespecified Type I error rate is $\\alpha=0.025$ for a one-sided test.\n- Required Tasks:\n    1. Compute the one-sided $p$-value corresponding to $z=1.95$.\n    2. State the decision rule for a one-sided superiority test at level $\\alpha=0.025$.\n    3. Interpret the result in the context of the trial.\n- Formatting Requirement: Round the $p$-value to three significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded**: The problem is firmly rooted in the standard theory and application of statistical hypothesis testing, specifically the use of a $z$-test for comparing proportions in the context of a randomized controlled trial. This is a fundamental methodology in biostatistics, epidemiology, and preventive medicine. The framework is scientifically sound.\n- **Well-Posed**: The problem is fully specified. It provides the null and alternative hypotheses, the observed test statistic, the significance level, and the underlying distribution (standard normal). These elements are sufficient to uniquely determine the $p$-value, formulate a decision rule, and interpret the outcome.\n- **Objective**: The problem is presented using clear, precise, and unbiased language standard in scientific and statistical discourse.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. All information is consistent and realistic for a clinical or public health study.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution\n\nThe problem requires a three-part answer: the computation of a $p$-value, the statement of a decision rule, and the interpretation of the result.\n\n**1. Computation of the One-Sided $p$-Value**\n\nThe problem specifies a one-sided superiority test with the alternative hypothesis $H_{1}: \\Delta  0$. This indicates a right-tailed test, where evidence against the null hypothesis accumulates in the positive (upper) tail of the test statistic's distribution.\n\nThe fundamental definition of a $p$-value is the probability of obtaining a test result at least as extreme as the one that was actually observed, assuming the null hypothesis $H_0$ is true. For this right-tailed test, \"at least as extreme\" means greater than or equal to the observed test statistic.\n\nThe test statistic $z$ is stated to follow a standard normal distribution, $Z \\sim N(0,1)$, under the null hypothesis (specifically, at the boundary condition $\\Delta = 0$). The observed value is $z_{obs} = 1.95$.\n\nTherefore, the one-sided $p$-value is calculated as the tail probability:\n$$p = P(Z \\ge z_{obs}) = P(Z \\ge 1.95)$$\nwhere $Z$ is a standard normal random variable.\n\nUsing the cumulative distribution function (CDF) of the standard normal distribution, denoted by $\\Phi(z) = P(Z \\le z)$, we can express the $p$-value as:\n$$p = 1 - P(Z  1.95)$$\nSince the standard normal distribution is continuous, $P(Z  1.95)$ is equal to $P(Z \\le 1.95)$, which is $\\Phi(1.95)$.\n$$p = 1 - \\Phi(1.95)$$\nFrom standard normal distribution tables or a statistical calculator, the value of $\\Phi(1.95)$ is approximately $0.97441$.\n$$p \\approx 1 - 0.97441 = 0.02559$$\nThe problem requires the $p$-value to be rounded to three significant figures. The first three significant figures in $0.02559$ are $2$, $5$, and $5$. The next digit is $9$, so we round up the third significant digit.\n$$p \\approx 0.0256$$\n\n**2. Decision Rule**\n\nThe decision rule for a hypothesis test at a prespecified significance level $\\alpha$ dictates whether to reject or fail to reject the null hypothesis. The significance level, or Type I error rate, given is $\\alpha = 0.025$.\n\nThere are two equivalent ways to state the decision rule:\n\n- **Using the $p$-value:** The null hypothesis $H_0$ is rejected if the calculated $p$-value is less than or equal to the significance level $\\alpha$. Otherwise, we fail to reject $H_0$. For this problem, the rule is:\n  - If $p \\le 0.025$, reject $H_0$.\n  - If $p  0.025$, fail to reject $H_0$.\n\n- **Using the critical value:** The null hypothesis $H_0$ is rejected if the observed test statistic $z_{obs}$ falls in the rejection region, which is defined by a critical value $z_{\\alpha}$. For a one-sided test with $\\alpha = 0.025$, the critical value $z_{0.025}$ is the value such that $P(Z  z_{0.025}) = 0.025$. This corresponds to the $97.5$-th percentile of the standard normal distribution, since $\\Phi(z_{0.025}) = 1 - 0.025 = 0.975$. The well-known critical value is $z_{0.025} = 1.96$.\n  The rule is:\n  - If $z_{obs}  1.96$, reject $H_0$.\n  - If $z_{obs} \\le 1.96$, fail to reject $H_0$.\n\n**3. Interpretation of the Result**\n\nTo interpret the result, we apply the decision rule to our findings.\n\n- Using the $p$-value: Our calculated $p$-value is $p \\approx 0.0256$. We compare this to the significance level $\\alpha = 0.025$. Since $0.0256  0.025$, we fail to reject the null hypothesis.\n\n- Using the critical value: Our observed test statistic is $z_{obs} = 1.95$. We compare this to the critical value $z_{\\alpha} = 1.96$. Since $1.95 \\le 1.96$, we fail to reject the null hypothesis.\n\nBoth approaches lead to the same conclusion.\n\nA failure to reject the null hypothesis means that the evidence from the sample is not strong enough to conclude that the alternative hypothesis is true, at the chosen level of significance.\n\nIn the context of the trial, this result means that at the $\\alpha=0.025$ significance level, there is insufficient statistical evidence to conclude that the new community health worker intervention is superior to standard outreach in increasing colon cancer screening completion. The observed increase in screening rates in the intervention group, as reflected by the positive $z$-statistic of $1.95$, is not statistically significant. It is plausible that the observed difference is due to random chance rather than a true effect of the intervention.", "answer": "$$\\boxed{0.0256}$$", "id": "4538632"}, {"introduction": "Beyond mere calculation, valid statistical inference relies on a strict logical framework. This next exercise [@problem_id:4538523] presents a hypothetical scenario to demonstrate a crucial principle: the danger of post hoc decision-making. By deriving the actual Type I error rate when a hypothesis is chosen after viewing the data, you will gain a deeper appreciation for why pre-specification of the analysis plan is a non-negotiable rule in rigorous scientific research.", "problem": "A preventive medicine research team is evaluating a community-based hypertension prevention program in a randomized controlled trial (RCT). Let $D$ denote the individual-level difference in systolic blood pressure pre-to-post intervention, and suppose the primary estimand is the population mean difference $\\mu_{D}$. The pre-specified null hypothesis for regulatory and safety reasons is two-sided, $H_{0}:\\mu_{D}=0$, tested at significance level $\\alpha$, because both harmful increases and beneficial decreases in blood pressure are relevant.\n\nAssume a large sample size so that by the Central Limit Theorem and standard large-sample theory, the standardized test statistic $Z=\\frac{\\bar{D}}{\\sigma/\\sqrt{n}}$ is approximately standard normal under $H_{0}$, where $\\bar{D}$ is the sample mean of $D$, $\\sigma$ is the population standard deviation of $D$, and $n$ is the sample size. The p-value for a two-sided test is defined as the tail probability of observing a test statistic at least as extreme as $|Z|$ in either direction under $H_{0}$. The p-value for a one-sided test in a specified direction is defined as the corresponding one-tail probability under $H_{0}$.\n\nAfter examining the data, the investigators decide to switch post hoc from the pre-specified two-sided test to a one-sided test by choosing the tail that matches the observed sign of $\\bar{D}$, while retaining the same nominal significance level $\\alpha$. Specifically, the data-dependent decision rule is: observe $Z$, choose the one-sided hypothesis in the direction of $\\operatorname{sign}(Z)$, and reject $H_{0}$ if the resulting one-sided p-value is less than or equal to $\\alpha$.\n\nStarting from the definitions of Type I error as $P(\\text{reject }H_{0}\\mid H_{0}\\text{ true})$, and the standard normal distribution for $Z$ under $H_{0}$, derive the probability of a Type I error under this data-dependent switching rule and compare it to the pre-specified two-sided level $\\alpha$. Define the inflation factor $I$ as the ratio of the Type I error under the switching rule to the pre-specified $\\alpha$. Provide $I$ as your final answer. No rounding is required. Express your answer as a pure number.", "solution": "The core task is to calculate the probability of a Type I error under a data-dependent hypothesis testing rule. A Type I error occurs when the null hypothesis, $H_{0}$, is rejected given that it is true. Let $\\alpha_{\\text{eff}}$ be the effective Type I error rate of the described procedure. By definition:\n$$\n\\alpha_{\\text{eff}} = P(\\text{reject } H_{0} \\mid H_{0} \\text{ true})\n$$\nThe problem states that under $H_{0}$, the test statistic $Z$ follows a standard normal distribution, denoted as $Z \\sim N(0, 1)$. Let $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution, i.e., $\\Phi(z) = P(Z \\leq z)$.\n\nThe decision rule for rejecting $H_{0}$ is data-dependent and based on the sign of the observed test statistic, which we will also denote by $Z$. The rejection event can be partitioned into two mutually exclusive events based on whether $Z$ is positive or negative. We can neglect the case $Z=0$ as it has a probability of $0$ for a continuous random variable.\n\nPart 1: The case where the observed statistic $Z$ is positive ($Z > 0$).\nAccording to the rule, the investigators choose a one-sided, upper-tailed test. The p-value for this test is given by $p_{\\text{upper}} = P(Z' \\geq Z \\mid H_{0})$, where $Z'$ is a placeholder random variable following the null distribution $N(0, 1)$. The null hypothesis is rejected if this p-value is less than or equal to the nominal significance level $\\alpha$. So, the rejection condition is:\n$$\n(Z > 0) \\quad \\text{and} \\quad p_{\\text{upper}} \\leq \\alpha\n$$\nLet's formalize the p-value condition. $p_{\\text{upper}} = P(Z' \\geq Z) = 1 - \\Phi(Z)$. The inequality becomes:\n$$\n1 - \\Phi(Z) \\leq \\alpha \\implies \\Phi(Z) \\geq 1 - \\alpha\n$$\nLet $z_{1-\\alpha}$ be the $(1-\\alpha)$-quantile of the standard normal distribution, defined by $\\Phi(z_{1-\\alpha}) = 1 - \\alpha$. Since $\\Phi$ is a monotonically increasing function, the condition $\\Phi(Z) \\geq 1 - \\alpha$ is equivalent to $Z \\geq z_{1-\\alpha}$.\nFor any reasonable significance level (e.g., $\\alpha  0.5$), we have $1-\\alpha > 0.5$, which implies that the quantile $z_{1-\\alpha}$ is positive ($z_{1-\\alpha} > 0$). Therefore, the condition $Z \\geq z_{1-\\alpha}$ implies that $Z > 0$. The rejection event for this part simplifies to $Z \\geq z_{1-\\alpha}$. The probability of this event under $H_{0}$ is:\n$$\nP(Z \\geq z_{1-\\alpha}) = 1 - P(Z  z_{1-\\alpha}) = 1 - \\Phi(z_{1-\\alpha}) = 1 - (1 - \\alpha) = \\alpha\n$$\n\nPart 2: The case where the observed statistic $Z$ is negative ($Z  0$).\nIn this case, the investigators choose a one-sided, lower-tailed test. The p-value is $p_{\\text{lower}} = P(Z' \\leq Z \\mid H_{0})$. The null hypothesis is rejected if this p-value is less than or equal to $\\alpha$. So, the rejection condition is:\n$$\n(Z  0) \\quad \\text{and} \\quad p_{\\text{lower}} \\leq \\alpha\n$$\nThe p-value condition is $p_{\\text{lower}} = \\Phi(Z) \\leq \\alpha$. Let $z_{\\alpha}$ be the $\\alpha$-quantile of the standard normal distribution, defined by $\\Phi(z_{\\alpha}) = \\alpha$. The condition $\\Phi(Z) \\leq \\alpha$ is equivalent to $Z \\leq z_{\\alpha}$.\nFor $\\alpha  0.5$, the quantile $z_{\\alpha}$ is negative ($z_{\\alpha}  0$). Thus, the condition $Z \\leq z_{\\alpha}$ implies $Z  0$. The rejection event for this part simplifies to $Z \\leq z_{\\alpha}$. The probability of this event under $H_{0}$ is:\n$$\nP(Z \\leq z_{\\alpha}) = \\Phi(z_{\\alpha}) = \\alpha\n$$\n\nTotal Type I Error Rate:\nThe total event of rejecting $H_{0}$ is the union of the rejection events from Part 1 and Part 2. Since these events are disjoint ( $Z$ cannot be both $\\geq z_{1-\\alpha} > 0$ and $\\leq z_{\\alpha}  0$), the total probability of a Type I error, $\\alpha_{\\text{eff}}$, is the sum of their individual probabilities:\n$$\n\\alpha_{\\text{eff}} = P(\\text{reject } H_{0} \\mid H_{0}) = P(Z \\geq z_{1-\\alpha}) + P(Z \\leq z_{\\alpha}) = \\alpha + \\alpha = 2\\alpha\n$$\nThis demonstrates that the data-dependent switching rule results in an effective Type I error rate that is double the nominal significance level $\\alpha$. This contrasts with a pre-specified two-sided test at level $\\alpha$, which would have a rejection region of $|Z| \\geq z_{1-\\alpha/2}$ and a Type I error probability of exactly $\\alpha$.\n\nInflation Factor:\nThe problem defines the inflation factor $I$ as the ratio of the Type I error under the switching rule ($\\alpha_{\\text{eff}}$) to the pre-specified significance level $\\alpha$.\n$$\nI = \\frac{\\alpha_{\\text{eff}}}{\\alpha} = \\frac{2\\alpha}{\\alpha}\n$$\nAssuming $\\alpha > 0$, we can simplify this expression:\n$$\nI = 2\n$$\nThus, the procedure of choosing the hypothesis direction post hoc doubles the probability of making a Type I error compared to the pre-specified level $\\alpha$.", "answer": "$$\\boxed{2}$$", "id": "4538523"}, {"introduction": "Research in preventive medicine rarely involves a single question. More often, we test multiple interventions or measure many outcomes, leading to the challenge of multiple hypothesis testing where the risk of false positives increases. This advanced practice [@problem_id:4538642] moves beyond single tests to introduce the concept of the False Discovery Rate (FDR) and a widely used method to control it, the Benjamini-Hochberg procedure. Working through this example will equip you with a critical tool for interpreting results from complex, modern studies.", "problem": "A preventive medicine team conducts a community-based randomized evaluation of $m=10$ candidate interventions designed to increase uptake of a seasonal vaccination campaign. For each intervention $i \\in \\{1,\\dots,10\\}$, a null hypothesis $H_{0i}$ states that the intervention does not change vaccination uptake relative to control. The team computes two-sided $p$-values from independent tests, and the sorted $p$-values are given as $(0.001, 0.009, 0.013, 0.020, 0.031, 0.045, 0.051, 0.08, 0.12, 0.20)$.\n\nStarting from fundamental definitions relevant to multiple testing:\n- Under a true null hypothesis, a $p$-value is stochastically dominated by a $\\text{Uniform}([0,1])$ random variable, and under the standard idealization it is exactly $\\text{Uniform}([0,1])$.\n- The False Discovery Rate (FDR) is $\\mathbb{E}\\!\\left[\\frac{V}{R \\vee 1}\\right]$, where $V$ is the number of false rejections and $R$ is the total number of rejections.\n- A step-up multiple testing rule ranks the $p$-values and compares $p_{(i)}$ to an increasing sequence of critical values indexed by the rank $i$.\n\nUsing these bases, explain why a step-up rule that compares the ordered $p$-values $p_{(1)} \\leq p_{(2)} \\leq \\dots \\leq p_{(m)}$ to an increasing sequence of rank-dependent critical values can control the FDR at a target level $q \\in (0,1)$ under independence of the tests, and derive the functional form of this sequence in terms of $m$ and $q$ for the Benjamini–Hochberg procedure. Then, for $m=10$ and target FDR $q=0.10$, compute the complete set of Benjamini–Hochberg critical values and identify the largest index $k$ for which $p_{(k)}$ does not exceed its corresponding critical value. Let $t^{\\ast}$ denote the Benjamini–Hochberg cutoff threshold determined by this largest index. Report only $t^{\\ast}$ as your final answer. No rounding is required, and no units are applicable.", "solution": "The problem statement has been meticulously validated.\n\n### Step 1: Extract Givens\n-   Number of hypothesis tests: $m = 10$.\n-   Null hypotheses: For each intervention $i \\in \\{1,\\dots,10\\}$, $H_{0i}$ states no change in vaccination uptake.\n-   Assumption: The tests from which the $p$-values are computed are independent.\n-   Sorted $p$-values: $p_{(1)}, \\dots, p_{(10)}$ are given as $(0.001, 0.009, 0.013, 0.020, 0.031, 0.045, 0.051, 0.08, 0.12, 0.20)$.\n-   Definition of $p$-value under null: A $p$-value from a true null hypothesis is a random variable stochastically dominated by, or idealized as, a $\\text{Uniform}([0,1])$ variable.\n-   Definition of False Discovery Rate (FDR): $FDR = \\mathbb{E}\\!\\left[\\frac{V}{R \\vee 1}\\right]$, where $V$ is the number of false rejections (Type I errors) and $R$ is the total number of rejections.\n-   Definition of step-up rule: A rule that compares ordered $p$-values $p_{(1)} \\leq p_{(2)} \\leq \\dots \\leq p_{(m)}$ to an increasing sequence of rank-dependent critical values.\n-   Target FDR: $q=0.10$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, objective, and self-contained. It describes a standard and highly relevant statistical scenario in medical research—the need to correct for multiple hypothesis tests. The provided definitions are standard in the field of statistics. The data is complete and consistent, allowing for a unique and meaningful solution. The problem asks for a theoretical explanation, a derivation, and a specific calculation, all of which are central to the topic of multiple testing. No scientific, logical, or factual flaws are present.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution\n\nThe problem requires an explanation and application of the Benjamini–Hochberg (BH) procedure for controlling the False Discovery Rate (FDR).\n\nFirst, we address the theoretical components of the problem.\n\nA step-up multiple testing rule, such as the Benjamini–Hochberg procedure, controls the FDR by employing a sequence of critical values that adapt to the observed data. The FDR is the expected proportion of \"false discoveries\" (erroneously rejected null hypotheses) among all \"discoveries\" (all rejected null hypotheses). Let the total number of tests be $m$ and the target FDR be $q$. The $p$-values are sorted in ascending order: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$.\n\nThe Benjamini–Hochberg procedure compares each ordered $p$-value $p_{(i)}$ to a critical value that depends on its rank $i$. This increasing sequence of critical values accounts for the fact that as one considers p-values of higher rank (i.e., larger p-values), the probability of observing a small value just by chance across many tests increases. The specific functional form of the Benjamini–Hochberg critical value sequence, which we are asked to derive, arises directly from the goal of controlling the FDR. For independent tests, the procedure defines the critical value for the $i$-th ordered $p$-value as:\n$$c_i = \\frac{i}{m}q$$\nThis sequence $\\{c_i\\}_{i=1}^m$ is clearly increasing with rank $i$. The procedure itself involves finding the largest index $k$ such that $p_{(k)} \\le c_k = \\frac{k}{m}q$. If such a $k$ is found, all null hypotheses $H_{0(i)}$ for $i=1, \\dots, k$ are rejected. It has been proven that for independent tests, this procedure guarantees that $FDR \\le \\frac{m_0}{m}q \\le q$, where $m_0$ is the (unknown) number of true null hypotheses. The intuition is that the comparison $p_{(i)} \\le \\frac{i}{m}q$ is a check against what would be expected if the nulls were true. The expected value of the $i$-th ordered $p$-value from $m$ uniform distributions is $\\frac{i}{m+1}$. The BH procedure avers that if $p_{(i)}$ is smaller than this expectation scaled by $q$, it provides evidence of a true effect, and the procedure's specific rule for rejection maintains FDR control on average.\n\nNow, we apply this procedure to the given data. We are given $m=10$, a target FDR of $q=0.10$, and a vector of sorted $p$-values.\n\nThe functional form of the critical value sequence is $c_i = \\frac{i}{m}q$. Substituting the given values, we get:\n$$c_i = \\frac{i}{10} \\times 0.10 = \\frac{i}{100}$$\nWe can now compute the complete set of ten critical values:\n- $c_1 = \\frac{1}{100} = 0.01$\n- $c_2 = \\frac{2}{100} = 0.02$\n- $c_3 = \\frac{3}{100} = 0.03$\n- $c_4 = \\frac{4}{100} = 0.04$\n- $c_5 = \\frac{5}{100} = 0.05$\n- $c_6 = \\frac{6}{100} = 0.06$\n- $c_7 = \\frac{7}{100} = 0.07$\n- $c_8 = \\frac{8}{100} = 0.08$\n- $c_9 = \\frac{9}{100} = 0.09$\n- $c_{10} = \\frac{10}{100} = 0.10$\n\nNext, we must find the largest index $k$ for which the condition $p_{(k)} \\le c_k$ is met. We compare each sorted $p$-value to its corresponding critical value:\n- $i=1: p_{(1)} = 0.001 \\le c_1 = 0.01$ (Condition met)\n- $i=2: p_{(2)} = 0.009 \\le c_2 = 0.02$ (Condition met)\n- $i=3: p_{(3)} = 0.013 \\le c_3 = 0.03$ (Condition met)\n- $i=4: p_{(4)} = 0.020 \\le c_4 = 0.04$ (Condition met)\n- $i=5: p_{(5)} = 0.031 \\le c_5 = 0.05$ (Condition met)\n- $i=6: p_{(6)} = 0.045 \\le c_6 = 0.06$ (Condition met)\n- $i=7: p_{(7)} = 0.051 \\le c_7 = 0.07$ (Condition met)\n- $i=8: p_{(8)} = 0.08 \\le c_8 = 0.08$ (Condition met)\n- $i=9: p_{(9)} = 0.12  c_9 = 0.09$ (Condition not met)\n- $i=10: p_{(10)} = 0.20  c_{10} = 0.10$ (Condition not met)\n\nThe set of indices for which the condition is met is $\\{1, 2, 3, 4, 5, 6, 7, 8\\}$. The largest index in this set is $k=8$.\n\nAccording to the Benjamini–Hochberg procedure, having found this largest index $k$, we reject all null hypotheses with $p$-values less than or equal to $p_{(k)}$. Therefore, the effective rejection threshold for any of the original $m=10$ tests is $t^{\\ast} = p_{(k)}$. This is the \"Benjamini–Hochberg cutoff threshold determined by this largest index.\"\n\nWith $k=8$, the cutoff threshold is $t^{\\ast} = p_{(8)}$. From the provided data, the 8th sorted $p$-value is:\n$$t^{\\ast} = p_{(8)} = 0.08$$\n\nAny of the original interventions whose test yielded a $p$-value of $0.08$ or less would be declared to have a statistically significant effect, while controlling the FDR at the $10\\%$ level.", "answer": "$$\n\\boxed{0.08}\n$$", "id": "4538642"}]}