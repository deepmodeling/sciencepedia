{"hands_on_practices": [{"introduction": "To truly grasp the power and pitfalls of Mendelian Randomization (MR), it's invaluable to build the system from first principles. This exercise guides you through a simulation of the data-generating process, allowing you to observe how the MR instrumental variable estimator provides an unbiased estimate of a causal effect even in the presence of unmeasured confounding. By manipulating the simulation parameters, you will also see firsthand how violating key assumptions, such as the exclusion restriction or using weak instruments, can lead to biased results [@problem_id:2404055].", "problem": "Implement a fully deterministic simulation to evaluate the unbiasedness of the Mendelian randomization (MR) causal effect estimator under the core instrumental variable assumptions. Consider a data-generating process with a single bi-allelic genetic instrument, an unmeasured confounder, a continuous exposure, and a continuous outcome. Let $G$ denote the genetic instrument, $U$ the unmeasured confounder, $X$ the exposure, and $Y$ the outcome. Assume the following linear structural equations with additive noise:\n$$\nX \\;=\\; \\pi \\, G \\;+\\; \\gamma \\, U \\;+\\; \\varepsilon_X,\n$$\n$$\nY \\;=\\; \\beta \\, X \\;+\\; \\delta \\, U \\;+\\; \\alpha \\, G \\;+\\; \\varepsilon_Y,\n$$\nwhere $G \\sim \\text{Binomial}(2,p)$, $U \\sim \\mathcal{N}(0,1)$, $\\varepsilon_X \\sim \\mathcal{N}(0,\\sigma_X^2)$, and $\\varepsilon_Y \\sim \\mathcal{N}(0,\\sigma_Y^2)$. All random variables are mutually independent except as induced by the structural equations. The parameters $\\pi$, $\\gamma$, $\\delta$, $\\alpha$, $\\beta$, $p$, $\\sigma_X$, and $\\sigma_Y$ are fixed constants within a given simulation scenario.\n\nThe Mendelian randomization assumptions are the following:\n- Relevance: $G$ is associated with $X$, which corresponds to $\\pi \\neq 0$.\n- Independence: $G$ is independent of $U$ and of all other unmeasured causes of $X$ and $Y$.\n- Exclusion restriction: $G$ has no direct causal effect on $Y$ other than through $X$, which corresponds to $\\alpha = 0$.\n\nDefine the instrumental variable estimator $\\hat{\\beta}_{\\mathrm{IV}}$ for a single instrument as the unique scalar $\\hat{\\beta}$ satisfying the empirical moment condition\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} G_i \\,\\bigl(Y_i - \\hat{\\beta}\\, X_i \\bigr) \\;=\\; 0,\n$$\nfor a given sample of size $N$. Define the naive ordinary least squares (OLS) estimator $\\hat{\\beta}_{\\mathrm{OLS}}$ as the scalar $\\hat{\\beta}$ minimizing the empirical mean squared discrepancy\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} \\bigl(Y_i - \\hat{\\beta}\\, X_i \\bigr)^2.\n$$\n\nFor each test case below, you must generate $R$ independent Monte Carlo replicates. In each replicate, draw an independent sample of size $N$ from the specified data-generating process, compute $\\hat{\\beta}_{\\mathrm{IV}}$ from the replicate, and then compute the replicate bias $\\hat{\\beta}_{\\mathrm{IV}} - \\beta$. Aggregate the replicate biases by taking their arithmetic mean to obtain the mean instrumental-variable bias for that test case. Use a fixed pseudorandom number generator seed to ensure determinism: for the test case with index $k$ (starting at zero), use the seed $2025 + k$.\n\nUse the following test suite, where each item lists $(N, R, p, \\pi, \\beta, \\gamma, \\delta, \\alpha, \\sigma_X, \\sigma_Y)$:\n\n- Test case A (happy path, valid instrument with unmeasured confounding): $(\\,N=\\;4000,\\; R=\\;800,\\; p=\\;0.3,\\; \\pi=\\;0.2,\\; \\beta=\\;0.5,\\; \\gamma=\\;0.8,\\; \\delta=\\;0.8,\\; \\alpha=\\;0.0,\\; \\sigma_X=\\;1.0,\\; \\sigma_Y=\\;1.0\\,)$.\n- Test case B (boundary, weak but valid instrument with unmeasured confounding): $(\\,N=\\;4000,\\; R=\\;800,\\; p=\\;0.3,\\; \\pi=\\;0.01,\\; \\beta=\\;0.5,\\; \\gamma=\\;0.8,\\; \\delta=\\;0.8,\\; \\alpha=\\;0.0,\\; \\sigma_X=\\;1.0,\\; \\sigma_Y=\\;1.0\\,)$.\n- Test case C (edge case, exclusion restriction violated): $(\\,N=\\;4000,\\; R=\\;800,\\; p=\\;0.3,\\; \\pi=\\;0.2,\\; \\beta=\\;0.5,\\; \\gamma=\\;0.8,\\; \\delta=\\;0.8,\\; \\alpha=\\;0.2,\\; \\sigma_X=\\;1.0,\\; \\sigma_Y=\\;1.0\\,)$.\n- Test case D (edge case, no unmeasured confounding): $(\\,N=\\;4000,\\; R=\\;800,\\; p=\\;0.3,\\; \\pi=\\;0.2,\\; \\beta=\\;0.5,\\; \\gamma=\\;0.0,\\; \\delta=\\;0.0,\\; \\alpha=\\;0.0,\\; \\sigma_X=\\;1.0,\\; \\sigma_Y=\\;1.0\\,)$.\n\nLet the tolerance for unbiasedness be $\\tau = 0.05$. For each test case, output a boolean value indicating whether the absolute mean instrumental-variable bias is at most $\\tau$, that is, whether $\\bigl|\\frac{1}{R}\\sum_{r=1}^{R} (\\hat{\\beta}_{\\mathrm{IV},r} - \\beta)\\bigr| \\le \\tau$.\n\nYour program must produce a single line of output containing the booleans for the test cases A, B, C, D, in that order, as a comma-separated list enclosed in square brackets with no spaces, for example, `[True,False,True,True]`.", "solution": "The problem requires the implementation of a deterministic Monte Carlo simulation to assess the unbiasedness of the instrumental variable (IV) estimator for a causal effect, $\\beta$, within the framework of Mendelian randomization (MR). The assessment is performed under several scenarios, each defined by a set of parameters for a linear structural equation model.\n\nThe data generating process is defined by the following system of equations:\n$$\nX \\;=\\; \\pi \\, G \\;+\\; \\gamma \\, U \\;+\\; \\varepsilon_X\n$$\n$$\nY \\;=\\; \\beta \\, X \\;+\\; \\delta \\, U \\;+\\; \\alpha \\, G \\;+\\; \\varepsilon_Y\n$$\nHere, $G$ is the genetic instrument, $U$ is an unmeasured confounder, $X$ is the exposure, and $Y$ is the outcome. The random variables are distributed as follows: $G \\sim \\text{Binomial}(2,p)$, $U \\sim \\mathcal{N}(0,1)$, $\\varepsilon_X \\sim \\mathcal{N}(0,\\sigma_X^2)$, and $\\varepsilon_Y \\sim \\mathcal{N}(0,\\sigma_Y^2)$. All exogenous variables ($G$, $U$, $\\varepsilon_X$, $\\varepsilon_Y$) are stipulated to be mutually independent.\n\nThe problem defines the instrumental variable estimator, $\\hat{\\beta}_{\\mathrm{IV}}$, through the empirical moment condition:\n$$\n\\frac{1}{N} \\sum_{i=1}^{N} G_i \\,\\bigl(Y_i - \\hat{\\beta}_{\\mathrm{IV}}\\, X_i \\bigr) \\;=\\; 0\n$$\nfor a sample of size $N$. This condition must be satisfied. We can derive a closed-form expression for $\\hat{\\beta}_{\\mathrm{IV}}$ by simple algebraic manipulation. Distributing $G_i$ and rearranging the sum yields:\n$$\n\\sum_{i=1}^{N} G_i Y_i - \\hat{\\beta}_{\\mathrm{IV}} \\sum_{i=1}^{N} G_i X_i = 0\n$$\nSolving for $\\hat{\\beta}_{\\mathrm{IV}}$ gives the expression for the single-instrument estimator, often referred to as the Wald estimator:\n$$\n\\hat{\\beta}_{\\mathrm{IV}} = \\frac{\\sum_{i=1}^{N} G_i Y_i}{\\sum_{i=1}^{N} G_i X_i}\n$$\nThis formula is computationally straightforward and forms the basis of our simulation. The denominator can also be written as a sample mean, $\\mathbb{E}_N[GY] = \\frac{1}{N}\\sum G_i Y_i$, divided by another sample mean, $\\mathbb{E}_N[GX] = \\frac{1}{N}\\sum G_i X_i$.\n\nThe core instrumental variable assumptions are:\n$1$. **Relevance**: The instrument $G$ must be associated with the exposure $X$. In this model, this requires $\\pi \\neq 0$.\n$2$. **Independence**: The instrument $G$ must be independent of the unmeasured confounder $U$. This is guaranteed by the problem's data generating process.\n$3$. **Exclusion Restriction**: The instrument $G$ must not affect the outcome $Y$ except through the exposure $X$. This requires the direct effect parameter $\\alpha$ to be zero, i.e., $\\alpha = 0$.\n\nWhen these assumptions hold, the IV estimator is consistent for the true causal effect $\\beta$. That is, as $N \\to \\infty$, $\\hat{\\beta}_{\\mathrm{IV}} \\xrightarrow{p} \\beta$. However, in finite samples, or when assumptions are violated, the estimator can be biased.\n\nThe simulation algorithm proceeds as follows for each test case, specified by a parameter tuple $(N, R, p, \\pi, \\beta, \\gamma, \\delta, \\alpha, \\sigma_X, \\sigma_Y)$:\n$1$. A fixed pseudorandom number generator seed, $2025+k$ for the $k$-th test case (starting from $k=0$), is used to ensure deterministic and reproducible results.\n$2$. A total of $R$ Monte Carlo replicates are generated.\n$3$. In each replicate $r \\in \\{1, \\dots, R\\}$:\n    a. A sample of size $N$ is drawn. This involves generating $N$ independent draws for each of the exogenous variables: $G_i \\sim \\text{Binomial}(2,p)$, $U_i \\sim \\mathcal{N}(0,1)$, $\\varepsilon_{X,i} \\sim \\mathcal{N}(0,\\sigma_X^2)$, and $\\varepsilon_{Y,i} \\sim \\mathcal{N}(0,\\sigma_Y^2)$.\n    b. The endogenous variables $X_i$ and $Y_i$ are constructed for each observation $i \\in \\{1, \\dots, N\\}$ using the structural equations.\n    c. The IV estimate for the replicate, $\\hat{\\beta}_{\\mathrm{IV},r}$, is calculated using the formula derived above.\n    d. The bias for the replicate is computed as $\\hat{\\beta}_{\\mathrm{IV},r} - \\beta$.\n$4$. After all $R$ replicates are completed, the mean bias is calculated as the arithmetic mean of the individual replicate biases: $\\text{Mean Bias} = \\frac{1}{R} \\sum_{r=1}^{R} (\\hat{\\beta}_{\\mathrm{IV},r} - \\beta)$.\n$5$. Finally, the absolute value of the mean bias is compared against a specified tolerance $\\tau=0.05$. The result is `True` if $|\\text{Mean Bias}| \\le \\tau$ and `False` otherwise.\n\nWe analyze the expected outcome for each test case based on MR theory:\n- **Test case A**: All three MR assumptions are met with a strong instrument ($\\pi=0.2$). The estimator should be approximately unbiased. We expect the mean bias to be well within the tolerance $\\tau=0.05$.\n- **Test case B**: The instrument relevance assumption is met, but the instrument is weak ($\\pi=0.01$). Weak instruments are known to produce finite-sample bias that trends toward the bias of a naive OLS estimator. Since confounding is present ($\\gamma=0.8, \\delta=0.8$), the OLS estimate is biased, and thus the IV estimate will also be substantially biased. We expect the mean bias to exceed $\\tau=0.05$.\n- **Test case C**: The exclusion restriction is violated ($\\alpha=0.2$). This violation introduces asymptotic bias. The estimator $\\hat{\\beta}_{\\mathrm{IV}}$ converges in probability not to $\\beta$, but to $\\beta + \\alpha/\\pi$. In this case, the asymptotic bias is $0.2/0.2 = 1.0$, which is far greater than $\\tau=0.05$.\n- **Test case D**: There is no unmeasured confounding ($\\gamma = 0$ and $\\delta = 0$). In this scenario, the primary source of endogeneity is removed. The MR assumptions are met, and the IV estimator should be unbiased. Even a naive OLS estimator would be unbiased in this case. We expect the mean bias to be well within $\\tau=0.05$.\n\nThe implementation will follow this logic to provide the final boolean outputs.", "answer": "```python\nimport numpy as np\n\ndef run_simulation(N, R, p, pi, beta, gamma, delta, alpha, sigma_X, sigma_Y, seed):\n    \"\"\"\n    Runs a Monte Carlo simulation for a single Mendelian randomization scenario.\n    \n    Args:\n        N (int): Sample size per replicate.\n        R (int): Number of Monte Carlo replicates.\n        p (float): Allele frequency for the binomial genetic instrument.\n        pi (float): Effect of instrument G on exposure X.\n        beta (float): Causal effect of exposure X on outcome Y.\n        gamma (float): Effect of confounder U on exposure X.\n        delta (float): Effect of confounder U on outcome Y.\n        alpha (float): Direct effect of instrument G on outcome Y (pleiotropy).\n        sigma_X (float): Standard deviation of the noise term for X.\n        sigma_Y (float): Standard deviation of the noise term for Y.\n        seed (int): Seed for the pseudorandom number generator.\n        \n    Returns:\n        float: The mean bias of the IV estimator over all replicates.\n    \"\"\"\n    # Set the seed for reproducibility for this entire test case.\n    np.random.seed(seed)\n    \n    replicate_biases = []\n    \n    for _ in range(R):\n        # 1. Generate exogenous variables for a sample of size N.\n        G = np.random.binomial(2, p, size=N)\n        U = np.random.normal(0, 1, size=N)\n        eps_X = np.random.normal(0, sigma_X, size=N)\n        eps_Y = np.random.normal(0, sigma_Y, size=N)\n        \n        # 2. Generate endogenous variables based on structural equations.\n        X = pi * G + gamma * U + eps_X\n        Y = beta * X + delta * U + alpha * G + eps_Y\n        \n        # 3. Compute the IV estimator for the replicate.\n        sum_GX = np.sum(G * X)\n        sum_GY = np.sum(G * Y)\n        \n        # The probability of sum_GX being zero is astronomically small for the given\n        # parameters (N=4000, p=0.3) and can be safely disregarded.\n        if sum_GX == 0:\n            continue\n            \n        beta_iv = sum_GY / sum_GX\n        \n        # 4. Calculate and store the bias for this replicate.\n        bias = beta_iv - beta\n        replicate_biases.append(bias)\n        \n    # 5. Compute the mean bias over all replicates.\n    if not replicate_biases:\n        # This branch is effectively unreachable under the problem's constraints.\n        return np.nan\n        \n    mean_bias = np.mean(replicate_biases)\n    \n    return mean_bias\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the simulations, and prints the results.\n    \"\"\"\n    # Test cases defined as (N, R, p, pi, beta, gamma, delta, alpha, sigma_X, sigma_Y)\n    test_cases = [\n        # Case A: Happy path, valid instrument\n        (4000, 800, 0.3, 0.2, 0.5, 0.8, 0.8, 0.0, 1.0, 1.0),\n        # Case B: Boundary, weak instrument\n        (4000, 800, 0.3, 0.01, 0.5, 0.8, 0.8, 0.0, 1.0, 1.0),\n        # Case C: Edge case, exclusion restriction violated\n        (4000, 800, 0.3, 0.2, 0.5, 0.8, 0.8, 0.2, 1.0, 1.0),\n        # Case D: Edge case, no confounding\n        (4000, 800, 0.3, 0.2, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0),\n    ]\n    \n    tau = 0.05\n    results = []\n    \n    for k, case_params in enumerate(test_cases):\n        seed = 2025 + k\n        mean_bias = run_simulation(*case_params, seed=seed)\n        \n        # Check if the absolute mean bias is within the tolerance.\n        is_unbiased_within_tolerance = abs(mean_bias) = tau\n        results.append(is_unbiased_within_tolerance)\n        \n    # Print the final results in the specified format: [True,False,...]\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the main function.\nsolve()\n```", "id": "2404055"}, {"introduction": "In practice, MR is often performed using summary statistics from large-scale genome-wide association studies (GWAS). This practice shifts our focus from simulation to application, equipping you with the essential tools for a standard two-sample MR analysis. You will implement methods to calculate and visualize the relationships between instrument-exposure and instrument-outcome effects, including the widely-used scatter plot and funnel plot, to diagnose potential violations of MR assumptions like pleiotropy and heterogeneity [@problem_id:2404096].", "problem": "You are given summary association data from Genome-Wide Association Study (GWAS) instruments, each being a Single Nucleotide Polymorphism (SNP), in the setting of Mendelian randomization (MR). For each SNP, you have the association with an exposure, denoted $\\beta_{GX,i}$, and the association with an outcome, denoted $\\beta_{GY,i}$, together with the standard error of the outcome association $\\sigma_{GY,i}$. Assume the following fundamental base: (i) a linear causal model for the exposure–outcome relationship; (ii) instruments affect the outcome only through the exposure apart from any potential horizontal pleiotropy; (iii) sampling variability in $\\beta_{GY,i}$ is quantified by $\\sigma_{GY,i}$, and uncertainty in $\\beta_{GX,i}$ is negligible relative to $\\sigma_{GY,i}$ for the purpose of weighting; (iv) the causal effect is estimable by aggregating per-variant information using weighted least squares.\n\nYour task is to write a complete program that, for each test case described below, computes the numerical objects required to generate (a) a scatter plot of $\\beta_{GY}$ versus $\\beta_{GX}$ with both the intercept-constrained Inverse-Variance Weighted (IVW) regression line and the Mendelian randomization Egger (MR-Egger) regression line, and (b) a funnel plot of ratio estimates versus their standard errors to visually inspect for heterogeneity and pleiotropy. Instead of drawing any plot, your program must return the precise numerical quantities that define those plots.\n\nStarting only from the base principles above, implement the following computations for each test case:\n- Use weights $w_i$ defined by the inverse of the outcome variance, i.e., $w_i$ proportional to $1 / \\sigma_{GY,i}^2$.\n- Compute the intercept-constrained IVW estimate of the causal slope, by solving the weighted least squares problem with intercept fixed to zero that minimizes $\\sum_i w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2$ over $b$.\n- Compute the MR-Egger weighted regression line with an unconstrained intercept, by minimizing $\\sum_i w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2$ over $a$ and $b$.\n- Compute Cochran’s $Q$ statistic for heterogeneity under the IVW fit and the corresponding $I^2$ heterogeneity metric, where $Q$ compares the dispersion of the weighted residuals to their expected value under homogeneity.\n- For the funnel plot, compute the per-variant ratio estimate $\\theta_i$ and its approximate standard error $s_i$ under the assumption that uncertainty in $\\beta_{GX,i}$ is negligible relative to $\\sigma_{GY,i}$. Then compute the pseudo $95\\%$ funnel bounds for each variant around the pooled IVW effect as $\\theta_{\\text{IVW}} \\pm 1.96 \\, s_i$.\n\nYour program must apply these computations to the following test suite. Each test case is defined by three lists of equal length: $\\beta_{GX}$, $\\beta_{GY}$, and $\\sigma_{GY}$.\n\nTest case A (happy path; consistent instruments):\n- $\\beta_{GX} = [\\, 0.08, \\, 0.12, \\, 0.10, \\, 0.15, \\, 0.07, \\, 0.11 \\,]$\n- $\\beta_{GY} = [\\, 0.040, \\, 0.060, \\, 0.051, \\, 0.072, \\, 0.033, \\, 0.057 \\,]$\n- $\\sigma_{GY} = [\\, 0.020, \\, 0.018, \\, 0.022, \\, 0.019, \\, 0.021, \\, 0.020 \\,]$\n\nTest case B (directional pleiotropy; nonzero intercept expected):\n- $\\beta_{GX} = [\\, 0.05, \\, -0.04, \\, 0.09, \\, 0.12, \\, 0.03, \\, 0.07 \\,]$\n- $\\beta_{GY} = [\\, 0.037, \\, 0.007, \\, 0.048, \\, 0.054, \\, 0.029, \\, 0.042 \\,]$\n- $\\sigma_{GY} = [\\, 0.020, \\, 0.021, \\, 0.019, \\, 0.018, \\, 0.022, \\, 0.020 \\,]$\n\nTest case C (heterogeneity and a weak instrument):\n- $\\beta_{GX} = [\\, 0.20, \\, 0.15, \\, 0.10, \\, 0.05, \\, 0.004 \\,]$\n- $\\beta_{GY} = [\\, 0.080, \\, 0.070, \\, 0.045, \\, 0.050, \\, 0.010 \\,]$\n- $\\sigma_{GY} = [\\, 0.015, \\, 0.015, \\, 0.016, \\, 0.020, \\, 0.020 \\,]$\n\nTest case D (balanced pleiotropy; heterogeneity with approximately zero intercept):\n- $\\beta_{GX} = [\\, 0.10, \\, 0.12, \\, 0.09, \\, 0.11, \\, 0.08 \\,]$\n- $\\beta_{GY} = [\\, 0.080, \\, 0.052, \\, 0.064, \\, 0.056, \\, 0.048 \\,]$\n- $\\sigma_{GY} = [\\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020 \\,]$\n\nImplementation and numerical requirements:\n- Treat all weights as $w_i = 1 / \\sigma_{GY,i}^2$.\n- For the funnel plot, compute $\\theta_i = \\beta_{GY,i} / \\beta_{GX,i}$ and $s_i = \\sigma_{GY,i} / \\lvert \\beta_{GX,i} \\rvert$.\n- Use the IVW slope for the pooled effect in the funnel plot bounds $\\theta_{\\text{IVW}} \\pm 1.96 \\, s_i$.\n- For Cochran’s heterogeneity statistic under the IVW fit, compute $Q$ and then $I^2 = \\max\\left(0, \\frac{Q - (M - 1)}{Q}\\right)$ with $M$ the number of variants. If $Q = 0$, set $I^2 = 0$.\n- Your program must output, for each test case, a list of nine elements in the following order:\n  1. the IVW slope (a float),\n  2. the MR-Egger slope (a float),\n  3. the MR-Egger intercept (a float),\n  4. the IVW Cochran’s $Q$ (a float),\n  5. the IVW $I^2$ (a float),\n  6. the list of ratio estimates $[\\theta_i]$,\n  7. the list of ratio standard errors $[s_i]$,\n  8. the list of lower funnel bounds $[\\theta_{\\text{IVW}} - 1.96 \\, s_i]$,\n  9. the list of upper funnel bounds $[\\theta_{\\text{IVW}} + 1.96 \\, s_i]$.\n- Express all floats rounded to six decimal places.\n- Final output format: Your program should produce a single line of output containing the four per-test-case results aggregated as a comma-separated list enclosed in square brackets, with no spaces. That is, a single line of the form $[r_A, r_B, r_C, r_D]$ where each $r_\\cdot$ is the nine-element list described above.\n\nEdge conditions and scientific realism:\n- Enforce that $\\lvert \\beta_{GX,i} \\rvert$ is not zero to avoid division by zero in ratio computations. The provided test suite satisfies this; in general, if any $\\lvert \\beta_{GX,i} \\rvert$ were below a small threshold $\\varepsilon$, the variant should be excluded from the ratio and funnel components while remaining consistent in regression fits if handled appropriately. In this test suite, no exclusions are necessary.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the established principles of Mendelian randomization (MR), a standard method in genetic epidemiology. The problem is well-posed, providing all necessary data and explicit mathematical definitions for the required computations. The language is objective and formal, free of ambiguity or subjective claims. It presents a solvable computational task based on verifiable statistical and mathematical principles.\n\nWe will now proceed with a systematic derivation of the required quantities. The context is the estimation of a causal effect of an exposure on an outcome using genetic variants as instrumental variables. For each of $M$ genetic variants (SNPs), we are given its estimated association with the exposure, $\\beta_{GX,i}$, its estimated association with the outcome, $\\beta_{GY,i}$, and the standard error of the latter, $\\sigma_{GY,i}$.\n\nThe weights for all weighted calculations are defined by the inverse of the outcome variance, assuming uncertainty in $\\beta_{GX,i}$ is negligible for this purpose:\n$$\nw_i = \\frac{1}{\\sigma_{GY,i}^2}\n$$\n\n**1. Intercept-Constrained Inverse-Variance Weighted (IVW) Slope**\n\nThe IVW method estimates the causal effect, $b$, by solving a weighted least squares problem that forces the regression line through the origin. This corresponds to the assumption of no horizontal pleiotropy. The objective is to minimize the sum of weighted squared residuals:\n$$\nS(b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2\n$$\nTo find the minimum, we set the derivative with respect to $b$ to zero:\n$$\n\\frac{dS}{db} = -2 \\sum_{i=1}^{M} w_i \\beta_{GX,i} \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right) = 0\n$$\nSolving for $b$ yields the IVW estimate, which we denote $\\theta_{\\text{IVW}}$:\n$$\n\\theta_{\\text{IVW}} = \\frac{\\sum_{i=1}^{M} w_i \\beta_{GX,i} \\beta_{GY,i}}{\\sum_{i=1}^{M} w_i \\beta_{GX,i}^2}\n$$\n\n**2. Mendelian Randomization Egger (MR-Egger) Regression**\n\nThe MR-Egger method relaxes the no-pleiotropy assumption of the IVW method by allowing for a non-zero intercept in the regression of $\\beta_{GY,i}$ on $\\beta_{GX,i}$. The intercept, $a$, can be interpreted as an estimate of the average directional pleiotropic effect, while the slope, $b$, remains the estimate of the causal effect. We minimize the following objective function over both $a$ and $b$:\n$$\nS(a, b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2\n$$\nThis is a standard weighted linear regression problem. The solutions for the MR-Egger slope ($b_{\\text{Egger}}$) and intercept ($a_{\\text{Egger}}$) are given by the normal equations:\n$$\nb_{\\text{Egger}} = \\frac{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i} \\beta_{GY,i}\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right) \\left(\\sum w_i \\beta_{GY,i}\\right) }{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i}^2\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right)^2 }\n$$\n$$\na_{\\text{Egger}} = \\frac{\\sum w_i \\beta_{GY,i}}{\\sum w_i} - b_{\\text{Egger}} \\frac{\\sum w_i \\beta_{GX,i}}{\\sum w_i}\n$$\nThese formulas correspond to the standard solution for weighted least squares regression coefficients.\n\n**3. Cochran’s Q Statistic and I² Heterogeneity Metric**\n\nHeterogeneity among the instrument-specific causal estimates can indicate either violation of the MR assumptions (such as pleiotropy) or that the true causal effect differs for subsets of the population targeted by different instruments. Cochran’s $Q$ statistic for the IVW model quantifies this heterogeneity by summing the weighted squared differences between the individual ratio estimates and the pooled IVW estimate. It is calculated as:\n$$\nQ = \\sum_{i=1}^{M} w_i \\left( \\frac{\\beta_{GY,i}}{\\beta_{GX,i}} - \\theta_{\\text{IVW}} \\right)^2 \\beta_{GX,i}^2 = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - \\theta_{\\text{IVW}} \\beta_{GX,i} \\right)^2\n$$\nUnder the null hypothesis of homogeneity (i.e., all instruments estimate the same causal effect), $Q$ follows a chi-squared distribution with $M-1$ degrees of freedom.\n\nThe $I^2$ statistic describes the percentage of variation across instruments that is due to heterogeneity rather than sampling error. It is derived from $Q$:\n$$\nI^2 = \\max\\left(0, \\frac{Q - (M-1)}{Q}\\right)\n$$\nIf $Q=0$, which is highly unlikely in practice, $I^2$ is defined as $0$.\n\n**4. Funnel Plot Components**\n\nA funnel plot is a visual tool to investigate heterogeneity and publication bias. It plots the effect size of each instrument against a measure of its precision.\n\n-   **Per-variant ratio estimate ($\\theta_i$):** This is the causal effect estimated from a single instrument $i$:\n    $$\n    \\theta_i = \\frac{\\beta_{GY,i}}{\\beta_{GX,i}}\n    $$\n-   **Standard error of the ratio estimate ($s_i$):** Using the delta method and the assumption that $\\beta_{GX,i}$ is measured with negligible error, the standard error of $\\theta_i$ is approximated as:\n    $$\n    s_i = \\text{SE}(\\theta_i) \\approx \\frac{\\sigma_{GY,i}}{\\lvert \\beta_{GX,i} \\rvert}\n    $$\n-   **Funnel plot bounds:** The funnel is constructed around the pooled IVW causal estimate, $\\theta_{\\text{IVW}}$. For a pseudo $95\\%$ confidence interval, the bounds for each variant $i$ are:\n    $$\n    \\text{Bounds}_i = \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i\n    $$\n    The lower and upper bounds are $\\theta_{\\text{IVW}} - 1.96 \\, s_i$ and $\\theta_{\\text{IVW}} + 1.96 \\, s_i$, respectively.\n\nThe implementation will compute these nine quantities for each provided test case: the IVW slope, the MR-Egger slope and intercept, the Cochran's $Q$ and $I^2$ statistics for the IVW fit, and the lists of ratio estimates, their standard errors, and the corresponding lower and upper funnel bounds. All floating-point numbers will be rounded to six decimal places as required.", "answer": "```python\nimport numpy as np\n\ndef calculate_mr_metrics(beta_gx: list[float], beta_gy: list[float], sigma_gy: list[float]) - list:\n    \"\"\"\n    Computes Mendelian randomization metrics for a given set of summary statistics.\n\n    Args:\n        beta_gx: List of SNP-exposure associations.\n        beta_gy: List of SNP-outcome associations.\n        sigma_gy: List of standard errors for SNP-outcome associations.\n\n    Returns:\n        A list containing nine elements as specified in the problem description.\n    \"\"\"\n    # Convert lists to NumPy arrays for vectorized operations\n    bgx = np.array(beta_gx)\n    bgy = np.array(beta_gy)\n    sgy = np.array(sigma_gy)\n    \n    # 1. Weights\n    # w_i = 1 / sigma_GY,i^2\n    w = 1.0 / (sgy**2)\n    \n    # 2. IVW Slope (Intercept-constrained)\n    # theta_ivw = (sum w_i * beta_gx_i * beta_gy_i) / (sum w_i * beta_gx_i^2)\n    ivw_numerator = np.sum(w * bgx * bgy)\n    ivw_denominator = np.sum(w * bgx**2)\n    ivw_slope = ivw_numerator / ivw_denominator\n    \n    # 3. MR-Egger Slope and Intercept\n    # Weighted least squares regression of bgy on bgx with weights w\n    W = np.sum(w)\n    Swx = np.sum(w * bgx)\n    Swy = np.sum(w * bgy)\n    Swxx = np.sum(w * bgx**2)\n    Swxy = np.sum(w * bgx * bgy)\n    \n    egger_denominator = (W * Swxx - Swx**2)\n    if egger_denominator == 0:\n        # This case is unlikely with real data but handle for robustness\n        mr_egger_slope = np.nan\n        mr_egger_intercept = np.nan\n    else:\n        mr_egger_slope = (W * Swxy - Swx * Swy) / egger_denominator\n        mr_egger_intercept = (Swy / W) - mr_egger_slope * (Swx / W)\n\n    # 4. Cochran's Q for IVW\n    # Q = sum w_i * (beta_gy_i - theta_ivw * beta_gx_i)^2\n    cochran_q = np.sum(w * (bgy - ivw_slope * bgx)**2)\n    \n    # 5. I^2 for IVW\n    M = len(bgx)\n    df = M - 1\n    if cochran_q == 0:\n        i_squared = 0.0\n    else:\n        i_squared = max(0.0, (cochran_q - df) / cochran_q)\n\n    # 6. Ratio estimates (theta_i)\n    # theta_i = beta_gy_i / beta_gx_i\n    theta_i = bgy / bgx\n    \n    # 7. Ratio standard errors (s_i)\n    # s_i = sigma_gy_i / |beta_gx_i|\n    s_i = sgy / np.abs(bgx)\n    \n    # 8.  9. Funnel plot bounds\n    # lower/upper = theta_ivw +/- 1.96 * s_i\n    z_score = 1.96\n    funnel_lower_bounds = ivw_slope - z_score * s_i\n    funnel_upper_bounds = ivw_slope + z_score * s_i\n    \n    # Assemble results and round to 6 decimal places\n    results = [\n        round(ivw_slope, 6),\n        round(mr_egger_slope, 6),\n        round(mr_egger_intercept, 6),\n        round(cochran_q, 6),\n        round(i_squared, 6),\n        [round(val, 6) for val in theta_i],\n        [round(val, 6) for val in s_i],\n        [round(val, 6) for val in funnel_lower_bounds],\n        [round(val, 6) for val in funnel_upper_bounds],\n    ]\n    \n    return results\n\ndef format_result_list(res_list: list) - str:\n    \"\"\"Formats a single test case result list into the required string format.\"\"\"\n    str_parts = []\n    for item in res_list:\n        if isinstance(item, list):\n            formatted_list = f\"[{','.join([f'{x:.6f}' for x in item])}]\"\n            str_parts.append(formatted_list)\n        else:\n            str_parts.append(f\"{item:.6f}\")\n    return f\"[{','.join(str_parts)}]\"\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = {\n        'A': {\n            \"beta_gx\": [0.08, 0.12, 0.10, 0.15, 0.07, 0.11],\n            \"beta_gy\": [0.040, 0.060, 0.051, 0.072, 0.033, 0.057],\n            \"sigma_gy\": [0.020, 0.018, 0.022, 0.019, 0.021, 0.020]\n        },\n        'B': {\n            \"beta_gx\": [0.05, -0.04, 0.09, 0.12, 0.03, 0.07],\n            \"beta_gy\": [0.037, 0.007, 0.048, 0.054, 0.029, 0.042],\n            \"sigma_gy\": [0.020, 0.021, 0.019, 0.018, 0.022, 0.020]\n        },\n        'C': {\n            \"beta_gx\": [0.20, 0.15, 0.10, 0.05, 0.004],\n            \"beta_gy\": [0.080, 0.070, 0.045, 0.050, 0.010],\n            \"sigma_gy\": [0.015, 0.015, 0.016, 0.020, 0.020]\n        },\n        'D': {\n            \"beta_gx\": [0.10, 0.12, 0.09, 0.11, 0.08],\n            \"beta_gy\": [0.080, 0.052, 0.064, 0.056, 0.048],\n            \"sigma_gy\": [0.020, 0.020, 0.020, 0.020, 0.020]\n        }\n    }\n\n    all_results_str = []\n    # Process cases in alphabetical order to match output format\n    for key in sorted(test_cases.keys()):\n        case = test_cases[key]\n        result = calculate_mr_metrics(case[\"beta_gx\"], case[\"beta_gy\"], case[\"sigma_gy\"])\n        all_results_str.append(format_result_list(result))\n\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "2404096"}, {"introduction": "Diagnostic checks may reveal that not all genetic variants are valid instruments, which can bias the standard inverse-variance weighted (IVW) estimate. This hands-on practice introduces more robust MR methods designed to provide reliable causal estimates even when some instruments are invalid. You will implement and compare the weighted median and weighted mode estimators against the IVW method, developing a deeper understanding of how to choose an appropriate estimator based on the suspected pattern of pleiotropy [@problem_id:2404047].", "problem": "Implement a program that, given summarized two-sample Mendelian randomization (MR) data for several independent genetic variants, computes three causal effect estimators: the inverse-variance weighted (IVW) estimator, the weighted median estimator, and the weighted mode estimator. The context is Mendelian randomization (MR), where genetic variants serve as instrumental variables for an exposure-outcome relationship. You are given variant-level association estimates for the exposure and for the outcome, together with their standard errors, and you must compute each estimator from first principles using only these summary inputs.\n\nLet there be $m$ independent genetic variants (Single Nucleotide Polymorphisms (SNPs)), indexed by $i \\in \\{1,\\dots,m\\}$. For each variant $i$, you are given the exposure association $\\hat{\\gamma}_{X,i}$, its standard error $\\operatorname{se}(\\hat{\\gamma}_{X,i})$, the outcome association $\\hat{\\gamma}_{Y,i}$, and its standard error $\\operatorname{se}(\\hat{\\gamma}_{Y,i})$. Assume two-sample MR with no sample overlap, so that the measurement error in $\\hat{\\gamma}_{X,i}$ can be ignored when approximating the variance of the ratio estimator. For each variant, define the ratio estimate\n$$\n\\hat{\\beta}_i \\equiv \\frac{\\hat{\\gamma}_{Y,i}}{\\hat{\\gamma}_{X,i}},\n$$\nthe approximate standard error\n$$\n\\hat{\\sigma}_{\\beta_i} \\equiv \\frac{\\operatorname{se}(\\hat{\\gamma}_{Y,i})}{\\lvert\\hat{\\gamma}_{X,i}\\rvert},\n$$\nand the inverse-variance weight\n$$\nw_i \\equiv \\frac{1}{\\hat{\\sigma}_{\\beta_i}^2} = \\left(\\frac{\\lvert\\hat{\\gamma}_{X,i}\\rvert}{\\operatorname{se}(\\hat{\\gamma}_{Y,i})}\\right)^2.\n$$\n\nDefine the three estimators as follows:\n\n1. Inverse-variance weighted (IVW) estimator:\n$$\n\\hat{\\beta}_{\\mathrm{IVW}} \\equiv \\frac{\\sum_{i=1}^m w_i \\hat{\\beta}_i}{\\sum_{i=1}^m w_i}.\n$$\n\n2. Weighted median estimator: Let $(\\hat{\\beta}_{(1)}, \\dots, \\hat{\\beta}_{(m)})$ be the ratio estimates sorted in nondecreasing order with corresponding weights $(w_{(1)}, \\dots, w_{(m)})$ permuted consistently, and let $W \\equiv \\sum_{i=1}^m w_i$. The weighted median is any $\\hat{\\beta}_{(k)}$ satisfying\n$$\n\\sum_{j=1}^{k-1} \\frac{w_{(j)}}{W}  0.5 \\le \\sum_{j=1}^{k} \\frac{w_{(j)}}{W}.\n$$\nReturn the smallest such $\\hat{\\beta}_{(k)}$.\n\n3. Weighted mode estimator: For a fixed bandwidth $h > 0$, define the weighted Gaussian-kernel score for any $b \\in \\mathbb{R}$ as\n$$\nS_h(b) \\equiv \\sum_{i=1}^m w_i \\exp\\left(-\\frac{(b - \\hat{\\beta}_i)^2}{2 h^2}\\right).\n$$\nThe weighted mode estimator is\n$$\n\\hat{\\beta}_{\\mathrm{mode}}(h) \\equiv \\operatorname*{arg\\,max}_{b \\in \\mathbb{R}} S_h(b).\n$$\nFor numerical computation, evaluate $S_h(b)$ on a uniform grid covering\n$$\n\\left[\\min_i \\hat{\\beta}_i - 0.2,\\; \\max_i \\hat{\\beta}_i + 0.2\\right]\n$$\nwith at least $20001$ evenly spaced points, and take the maximizer on this grid. Use a common bandwidth $h = 0.06$ for all test cases.\n\nYour program must compute $(\\hat{\\beta}_{\\mathrm{IVW}}, \\hat{\\beta}_{\\mathrm{WM}}, \\hat{\\beta}_{\\mathrm{mode}})$ for each test case below, where $\\hat{\\beta}_{\\mathrm{WM}}$ denotes the weighted median, and then print all results on a single line as a list of lists, with each inner list corresponding to one test case in order, and with each numeric value rounded to exactly $4$ decimal places.\n\nTest Suite (three cases):\n- Case A (all instruments valid, cluster around a single causal effect): $m = 12$ with\n$$\n\\hat{\\gamma}_{X} = (0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{X}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02),\n$$\n$$\n\\hat{\\gamma}_{Y} = (0.053, 0.056, 0.042, -0.044, 0.080, -0.057, 0.038, 0.094, -0.062, 0.026, -0.084, 0.072),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{Y}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02).\n$$\n\n- Case B (exactly $50$ percent invalid instruments, two clusters; the invalid set exhibits directional pleiotropy proportional to exposure association): $m = 12$ with\n$$\n\\hat{\\gamma}_{X} = (0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{X}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02),\n$$\n$$\n\\hat{\\gamma}_{Y} = (0.052, 0.057, 0.041, -0.043, 0.079, -0.056, 0.057, 0.156, -0.101, 0.042, -0.132, 0.115),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{Y}) = (0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03).\n$$\nIn this case, $6$ variants (the first $6$ entries) are valid and $6$ variants (the last $6$ entries) are invalid.\n\n- Case C (exactly $50$ percent invalid instruments with one very weak instrument for the exposure): $m = 12$ with\n$$\n\\hat{\\gamma}_{X} = (0.02, 0.06, -0.07, 0.09, -0.05, 0.11, -0.10, 0.04, 0.13, -0.08, 0.03, 0.12),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{X}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02),\n$$\n$$\n\\hat{\\gamma}_{Y} = (0.011, 0.047, -0.034, 0.0655, -0.026, 0.0855, -0.048, 0.029, 0.062, -0.058, 0.016, 0.086),\n$$\n$$\n\\operatorname{se}(\\hat{\\gamma}_{Y}) = (0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02).\n$$\nIn this case, by construction, $6$ variants are valid and $6$ variants are invalid; the first entry includes a very weak exposure association $\\hat{\\gamma}_{X,1} = 0.02$.\n\nYour program should produce a single line of output containing the results for the three cases as a comma-separated list of lists in the form\n`[ [$\\hat{\\beta}_{\\mathrm{IVW}}^{(A)}$, $\\hat{\\beta}_{\\mathrm{WM}}^{(A)}$, $\\hat{\\beta}_{\\mathrm{mode}}^{(A)}$], [$\\hat{\\beta}_{\\mathrm{IVW}}^{(B)}$, $\\hat{\\beta}_{\\mathrm{WM}}^{(B)}$, $\\hat{\\beta}_{\\mathrm{mode}}^{(B)}$], [$\\hat{\\beta}_{\\mathrm{IVW}}^{(C)}$, $\\hat{\\beta}_{\\mathrm{WM}}^{(C)}$, $\\hat{\\beta}_{\\mathrm{mode}}^{(C)}$] ]`,\nwith each numeric value rounded to exactly $4$ decimal places. No additional text should be printed. Angles and physical units do not apply here. All numerical results must be reported as decimal floats in the specified list-of-lists format.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It presents a standard computational task within the field of Mendelian randomization (MR), a well-established method in statistical genetics and epidemiology. All necessary data, mathematical definitions, and numerical parameters are provided, rendering the problem self-contained and unambiguous. The defined estimators—Inverse-Variance Weighted (IVW), Weighted Median, and Weighted Mode—are standard in MR literature. The supplied numerical data is realistic for summary statistics from genome-wide association studies. Therefore, we proceed with the solution.\n\nThe task is to compute three distinct estimators for the causal effect of an exposure on an outcome using summary data from $m$ independent genetic variants, which serve as instrumental variables. For each variant $i \\in \\{1, \\dots, m\\}$, we are provided with the association estimate with the exposure, $\\hat{\\gamma}_{X,i}$, its standard error, $\\operatorname{se}(\\hat{\\gamma}_{X,i})$, the association estimate with the outcome, $\\hat{\\gamma}_{Y,i}$, and its standard error, $\\operatorname{se}(\\hat{\\gamma}_{Y,i})$.\n\nFirst, we compute two key quantities for each variant $i$: the ratio estimate of the causal effect, $\\hat{\\beta}_i$, and its corresponding inverse-variance weight, $w_i$.\n\nThe ratio estimate is the ratio of the variant-outcome association to the variant-exposure association:\n$$\n\\hat{\\beta}_i = \\frac{\\hat{\\gamma}_{Y,i}}{\\hat{\\gamma}_{X,i}}\n$$\nThis estimate represents the causal effect of the exposure on the outcome as instrumented by variant $i$.\n\nThe variance of this ratio estimate can be approximated using the delta method. Under the assumption of two-sample MR with no sample overlap, the covariance between $\\hat{\\gamma}_{X,i}$ and $\\hat{\\gamma}_{Y,i}$ is zero. Further, we can ignore the uncertainty in the denominator $\\hat{\\gamma}_{X,i}$ (the \"no measurement error\" or NOME assumption for the exposure), which is a common simplification when the variant-exposure associations are strong. This leads to the approximate variance:\n$$\n\\operatorname{Var}(\\hat{\\beta}_i) \\approx \\frac{\\operatorname{Var}(\\hat{\\gamma}_{Y,i})}{\\gamma_{X,i}^2} = \\frac{\\operatorname{se}(\\hat{\\gamma}_{Y,i})^2}{\\gamma_{X,i}^2}\n$$\nReplacing the true effect $\\gamma_{X,i}$ with its estimate $\\hat{\\gamma}_{X,i}$ gives the estimated standard error of the ratio estimate:\n$$\n\\hat{\\sigma}_{\\beta_i} = \\frac{\\operatorname{se}(\\hat{\\gamma}_{Y,i})}{\\lvert\\hat{\\gamma}_{X,i}\\rvert}\n$$\nThe absolute value is used to ensure the standard error is positive. The inverse-variance weight for each ratio estimate is the reciprocal of its estimated variance:\n$$\nw_i = \\frac{1}{\\hat{\\sigma}_{\\beta_i}^2} = \\left( \\frac{\\lvert\\hat{\\gamma}_{X,i}\\rvert}{\\operatorname{se}(\\hat{\\gamma}_{Y,i})} \\right)^2\n$$\nThese weights reflect the precision of each individual ratio estimate.\n\nWith $\\hat{\\beta}_i$ and $w_i$ computed for all $m$ variants, we can now define and compute the three required estimators.\n\n1.  **Inverse-Variance Weighted (IVW) Estimator**\n    The IVW estimator, $\\hat{\\beta}_{\\mathrm{IVW}}$, is the weighted average of the individual ratio estimates $\\hat{\\beta}_i$, with weights $w_i$:\n    $$\n    \\hat{\\beta}_{\\mathrm{IVW}} = \\frac{\\sum_{i=1}^m w_i \\hat{\\beta}_i}{\\sum_{i=1}^m w_i}\n    $$\n    This estimator is statistically efficient under the assumption that all variants are valid instruments and there is no horizontal pleiotropy (or that any pleiotropy is balanced around zero). It is equivalent to the slope from a weighted linear regression of $\\hat{\\gamma}_{Y,i}$ on $\\hat{\\gamma}_{X,i}$ with the intercept constrained to zero.\n\n2.  **Weighted Median Estimator**\n    The weighted median estimator, $\\hat{\\beta}_{\\mathrm{WM}}$, provides a robust estimate when a significant fraction (up to $50\\%$) of the genetic variants are invalid instruments (i.e., exhibit horizontal pleiotropy). The calculation proceeds as follows:\n    First, the ratio estimates $\\hat{\\beta}_i$ are sorted in non-decreasing order to obtain $(\\hat{\\beta}_{(1)}, \\dots, \\hat{\\beta}_{(m)})$. The corresponding weights $(w_{(1)}, \\dots, w_{(m)})$ are permuted consistently.\n    Second, the total weight $W = \\sum_{i=1}^m w_i$ is computed.\n    Third, we find the smallest index $k$ such that the cumulative sum of normalized weights up to that index is at least $0.5$. Formally, we seek $\\hat{\\beta}_{(k)}$ where:\n    $$\n    \\sum_{j=1}^{k-1} \\frac{w_{(j)}}{W}  0.5 \\le \\sum_{j=1}^{k} \\frac{w_{(j)}}{W}\n    $$\n    The weighted median estimate is then $\\hat{\\beta}_{\\mathrm{WM}} = \\hat{\\beta}_{(k)}$. The algorithm involves sorting the $(\\hat{\\beta}_i, w_i)$ pairs by $\\hat{\\beta}_i$ and identifying the value at which the cumulative normalized weight first meets or exceeds $0.5$.\n\n3.  **Weighted Mode Estimator**\n    The weighted mode estimator, $\\hat{\\beta}_{\\mathrm{mode}}$, identifies the causal effect as the mode of the distribution of the individual ratio estimates, weighted by their precision. This is particularly useful when the largest group of variants are valid instruments, even if they do not constitute a majority. The mode is estimated by finding the maximum of a weighted kernel density estimate of the $\\hat{\\beta}_i$ values. For a given bandwidth $h > 0$, the weighted Gaussian-kernel score function $S_h(b)$ is defined as:\n    $$\n    S_h(b) = \\sum_{i=1}^m w_i \\phi_h(b - \\hat{\\beta}_i) = \\sum_{i=1}^m w_i \\exp\\left(-\\frac{(b - \\hat{\\beta}_i)^2}{2 h^2}\\right)\n    $$\n    where the problem simplifies the Gaussian kernel normalization factor. The estimator is the value of $b$ that maximizes this score:\n    $$\n    \\hat{\\beta}_{\\mathrm{mode}}(h) = \\operatorname*{arg\\,max}_{b \\in \\mathbb{R}} S_h(b)\n    $$\n    For numerical computation, this maximization is performed via a grid search. We use the specified bandwidth $h = 0.06$. A uniform grid of $20001$ points is constructed over the interval $[\\min_i \\hat{\\beta}_i - 0.2, \\max_i \\hat{\\beta}_i + 0.2]$. The score $S_h(b)$ is evaluated at each point on this grid, and the value of $b$ that yields the maximum score is taken as the estimate $\\hat{\\beta}_{\\mathrm{mode}}$.\n\nThe program implements these three estimators for each of the test cases provided.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes IVW, Weighted Median, and Weighted Mode estimators for Mendelian Randomization.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            \"gamma_x\": np.array([0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14]),\n            \"se_gamma_x\": np.full(12, 0.02),\n            \"gamma_y\": np.array([0.053, 0.056, 0.042, -0.044, 0.080, -0.057, 0.038, 0.094, -0.062, 0.026, -0.084, 0.072]),\n            \"se_gamma_y\": np.full(12, 0.02),\n        },\n        # Case B\n        {\n            \"gamma_x\": np.array([0.10, 0.12, 0.08, -0.09, 0.15, -0.11, 0.07, 0.20, -0.13, 0.05, -0.16, 0.14]),\n            \"se_gamma_x\": np.full(12, 0.02),\n            \"gamma_y\": np.array([0.052, 0.057, 0.041, -0.043, 0.079, -0.056, 0.057, 0.156, -0.101, 0.042, -0.132, 0.115]),\n            \"se_gamma_y\": np.array([0.015, 0.015, 0.015, 0.015, 0.015, 0.015, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03]),\n        },\n        # Case C\n        {\n            \"gamma_x\": np.array([0.02, 0.06, -0.07, 0.09, -0.05, 0.11, -0.10, 0.04, 0.13, -0.08, 0.03, 0.12]),\n            \"se_gamma_x\": np.full(12, 0.02),\n            \"gamma_y\": np.array([0.011, 0.047, -0.034, 0.0655, -0.026, 0.0855, -0.048, 0.029, 0.062, -0.058, 0.016, 0.086]),\n            \"se_gamma_y\": np.full(12, 0.02),\n        }\n    ]\n\n    H_BANDWIDTH = 0.06\n    MODE_GRID_POINTS = 20001\n    \n    all_results = []\n\n    for case in test_cases:\n        gamma_x = case[\"gamma_x\"]\n        gamma_y = case[\"gamma_y\"]\n        se_gamma_y = case[\"se_gamma_y\"]\n\n        # Calculate ratio estimates and weights\n        beta_hat = gamma_y / gamma_x\n        w = (np.abs(gamma_x) / se_gamma_y)**2\n\n        # 1. Inverse-variance weighted (IVW) estimator\n        ivw_est = np.sum(w * beta_hat) / np.sum(w)\n\n        # 2. Weighted median estimator\n        sorted_indices = np.argsort(beta_hat)\n        beta_hat_sorted = beta_hat[sorted_indices]\n        w_sorted = w[sorted_indices]\n        \n        total_weight = np.sum(w)\n        w_cumsum_norm = np.cumsum(w_sorted) / total_weight\n        \n        median_index = np.where(w_cumsum_norm = 0.5)[0][0]\n        wm_est = beta_hat_sorted[median_index]\n        \n        # 3. Weighted mode estimator\n        b_min = np.min(beta_hat) - 0.2\n        b_max = np.max(beta_hat) + 0.2\n        b_grid = np.linspace(b_min, b_max, num=MODE_GRID_POINTS)\n\n        # Vectorized calculation of scores S_h(b)\n        b_grid_reshaped = b_grid[:, np.newaxis]\n        diff_sq = (b_grid_reshaped - beta_hat)**2\n        h_sq = 2 * H_BANDWIDTH**2\n        scores = np.sum(w * np.exp(-diff_sq / h_sq), axis=1)\n        \n        mode_est = b_grid[np.argmax(scores)]\n\n        all_results.append([ivw_est, wm_est, mode_est])\n\n    # Format the final output string as a list of lists with 4 decimal places\n    output_str_parts = []\n    for res in all_results:\n        inner_list_str = f\"[{res[0]:.4f}, {res[1]:.4f}, {res[2]:.4f}]\"\n        output_str_parts.append(inner_list_str)\n    \n    final_output_str = f\"[{', '.join(output_str_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "2404047"}]}