{"hands_on_practices": [{"introduction": "To effectively assess alcohol-related risk, we must first translate colloquial descriptions of drinking into a standard scientific unit: grams of pure ethanol. This foundational exercise [@problem_id:4502871] guides you through converting a typical drinking diary into precise daily and average consumption figures. By applying established risk thresholds, you will practice classifying drinking patterns and identifying high-risk behaviors like binge drinking, a critical skill for clinical assessment and public health surveillance.", "problem": "A public health researcher is analyzing a seven-day drinking diary for an adult female. Alcohol by volume (ABV) indicates the fraction of a beverage’s volume that is pure ethanol. Assume the density of ethanol is $\\rho = 0.789 \\ \\text{g/mL}$. The World Health Organization (WHO) risk drinking levels are defined by average daily consumption of ethanol, with sex-specific thresholds. For women: abstinent is $0$, low risk is $1$–$20 \\ \\text{g/day}$, medium risk is $21$–$40 \\ \\text{g/day}$, high risk is $41$–$60 \\ \\text{g/day}$, and very high risk is $>60 \\ \\text{g/day}$. For classification reporting, use numeric codes: $0$ for abstinent, $1$ for low risk, $2$ for medium risk, $3$ for high risk, and $4$ for very high risk. Define a binge (heavy episodic drinking) episode for women as any day with consumption of at least $40 \\ \\text{g}$ of ethanol.\n\nSeven-day diary (volumes are per item consumed):\n- Day $1$: $2$ glasses of wine, each $150 \\ \\text{mL}$ at $13\\%$ ABV.\n- Day $2$: $1$ can of beer, $355 \\ \\text{mL}$ at $5\\%$ ABV; $1$ shot of whiskey, $40 \\ \\text{mL}$ at $40\\%$ ABV.\n- Day $3$: No alcohol.\n- Day $4$: $3$ glasses of wine, each $150 \\ \\text{mL}$ at $13\\%$ ABV.\n- Day $5$: $2$ cocktails, each $200 \\ \\text{mL}$ at $15\\%$ ABV.\n- Day $6$: $4$ cans of beer, each $355 \\ \\text{mL}$ at $5\\%$ ABV.\n- Day $7$: $1$ bottle of cider, $500 \\ \\text{mL}$ at $6\\%$ ABV.\n\nTasks:\n1. Compute the average daily consumption of ethanol over the seven days in grams per day.\n2. Classify the WHO risk drinking level using the female thresholds above and report its numeric code.\n3. Identify the number of binge episodes over the seven days using the female binge threshold.\n\nExpress the final answer as a row matrix $\\begin{pmatrix} x & y & z \\end{pmatrix}$, where $x$ is the average daily grams of ethanol, $y$ is the WHO risk code for women as defined, and $z$ is the number of binge episodes. Round $x$ to four significant figures. Do not include units in the final boxed answer. In your working, express masses in grams and volumes in milliliters.", "solution": "We start from two foundational facts: (i) alcohol by volume (ABV) is the fraction of the beverage volume that is ethanol, so the ethanol volume is $V_{\\text{ethanol}} = V_{\\text{beverage}} \\times \\text{ABV}$; and (ii) mass equals density times volume, so ethanol mass is $m_{\\text{ethanol}} = \\rho \\, V_{\\text{ethanol}}$, where $\\rho = 0.789 \\ \\text{g/mL}$.\n\nCompute day-by-day ethanol mass in grams.\n\nDay $1$: Two $150 \\ \\text{mL}$ glasses of wine at $13\\%$ ABV.\n- Total beverage volume: $V = 2 \\times 150 = 300 \\ \\text{mL}$.\n- Ethanol volume: $V_{\\text{ethanol}} = 300 \\times 0.13 = 39 \\ \\text{mL}$.\n- Ethanol mass: $m_{1} = 39 \\times 0.789 = 30.771 \\ \\text{g}$.\n\nDay $2$: One $355 \\ \\text{mL}$ beer at $5\\%$ ABV and one $40 \\ \\text{mL}$ whiskey at $40\\%$ ABV.\n- Beer ethanol volume: $355 \\times 0.05 = 17.75 \\ \\text{mL}$, mass $= 17.75 \\times 0.789 = 14.00475 \\ \\text{g}$.\n- Whiskey ethanol volume: $40 \\times 0.40 = 16 \\ \\text{mL}$, mass $= 16 \\times 0.789 = 12.624 \\ \\text{g}$.\n- Total mass: $m_{2} = 14.00475 + 12.624 = 26.62875 \\ \\text{g}$.\n\nDay $3$: No alcohol, so $m_{3} = 0 \\ \\text{g}$.\n\nDay $4$: Three $150 \\ \\text{mL}$ glasses of wine at $13\\%$ ABV.\n- Total beverage volume: $V = 3 \\times 150 = 450 \\ \\text{mL}$.\n- Ethanol volume: $V_{\\text{ethanol}} = 450 \\times 0.13 = 58.5 \\ \\text{mL}$.\n- Ethanol mass: $m_{4} = 58.5 \\times 0.789 = 46.1565 \\ \\text{g}$.\n\nDay $5$: Two $200 \\ \\text{mL}$ cocktails at $15\\%$ ABV.\n- Total beverage volume: $V = 2 \\times 200 = 400 \\ \\text{mL}$.\n- Ethanol volume: $V_{\\text{ethanol}} = 400 \\times 0.15 = 60 \\ \\text{mL}$.\n- Ethanol mass: $m_{5} = 60 \\times 0.789 = 47.34 \\ \\text{g}$.\n\nDay $6$: Four $355 \\ \\text{mL}$ beers at $5\\%$ ABV.\n- Total beverage volume: $V = 4 \\times 355 = 1420 \\ \\text{mL}$.\n- Ethanol volume: $V_{\\text{ethanol}} = 1420 \\times 0.05 = 71 \\ \\text{mL}$.\n- Ethanol mass: $m_{6} = 71 \\times 0.789 = 56.019 \\ \\text{g}$.\n\nDay $7$: One $500 \\ \\text{mL}$ cider at $6\\%$ ABV.\n- Ethanol volume: $V_{\\text{ethanol}} = 500 \\times 0.06 = 30 \\ \\text{mL}$.\n- Ethanol mass: $m_{7} = 30 \\times 0.789 = 23.67 \\ \\text{g}$.\n\nWeekly total ethanol mass:\n$$\nM_{\\text{week}} = m_{1} + m_{2} + m_{3} + m_{4} + m_{5} + m_{6} + m_{7}.\n$$\n$$\nM_{\\text{week}} = 30.771 + 26.62875 + 0 + 46.1565 + 47.34 + 56.019 + 23.67 = 230.58525 \\ \\text{g}.\n$$\n\nAverage daily ethanol mass over $7$ days:\n$$\n\\bar{m} = \\frac{M_{\\text{week}}}{7} = \\frac{230.58525}{7} = 32.94075 \\ \\text{g/day}.\n$$\nRounded to four significant figures: $\\bar{m} = 32.94 \\ \\text{g/day}$.\n\nWHO risk classification for women is based on average daily intake:\n- Abstinent: $0$.\n- Low: $1$–$20 \\ \\text{g/day}$.\n- Medium: $21$–$40 \\ \\text{g/day}$.\n- High: $41$–$60 \\ \\text{g/day}$.\n- Very high: $>60 \\ \\text{g/day}$.\n\nSince $32.94 \\ \\text{g/day}$ lies in $21$–$40 \\ \\text{g/day}$, the risk level is medium. Using the numeric code mapping $\\{0,1,2,3,4\\}$ for $\\{\\text{abstinent}, \\text{low}, \\text{medium}, \\text{high}, \\text{very high}\\}$, the code is $2$.\n\nBinge episodes for women are days with at least $40 \\ \\text{g}$ ethanol. The daily totals are:\n- Day $1$: $30.771$ (no).\n- Day $2$: $26.62875$ (no).\n- Day $3$: $0$ (no).\n- Day $4$: $46.1565$ (yes).\n- Day $5$: $47.34$ (yes).\n- Day $6$: $56.019$ (yes).\n- Day $7$: $23.67$ (no).\n\nThus, the number of binge episodes is $3$.\n\nTherefore, the requested row matrix $\\begin{pmatrix} x & y & z \\end{pmatrix}$ is $\\begin{pmatrix} 32.94 & 2 & 3 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} 32.94 & 2 & 3 \\end{pmatrix}}$$", "id": "4502871"}, {"introduction": "Universal screening is a cornerstone of alcohol misuse prevention, but how well do our tools work in practice? This problem [@problem_id:4502898] delves into the mathematics of diagnostic accuracy, using a common screening tool, the AUDIT-C, as a case study. You will calculate the positive and negative predictive values to understand how a test's performance in a real-world clinic setting is influenced by the prevalence of unhealthy alcohol use, a crucial concept for designing and evaluating effective public health programs.", "problem": "A primary care clinic adopts the Alcohol Use Disorders Identification Test-Consumption (AUDIT-C) as its routine alcohol screening tool, using a single cutoff that yields a sensitivity of $0.78$ and a specificity of $0.85$ for detecting current unhealthy alcohol use as defined by the United States Preventive Services Task Force (USPSTF). In the clinic’s adult population, the base prevalence of unhealthy alcohol use is estimated to be $0.20$. The clinic sees $1000$ unique adult patients per month, and $90\\%$ of them complete screening during the visit. The clinic follows a Screening, Brief Intervention, and Referral to Treatment (SBIRT) model in which all patients with positive screens receive a brief intervention and further assessment as indicated.\n\nUsing only fundamental definitions of sensitivity, specificity, prevalence, conditional probability, and Bayes’ theorem, compute the positive predictive value and the negative predictive value of the AUDIT-C at this cutoff under the stated prevalence. Express both values as decimals and round each to four significant figures. Do not express results with a percentage sign.\n\nThen, based on these values and the clinic throughput assumptions, explain what they imply for SBIRT workload in terms of the expected balance between true positives, false positives, and false negatives requiring attention. Your final boxed answer should report only the positive predictive value and the negative predictive value, in that order, as two decimals rounded to four significant figures.", "solution": "Let us define the following events:\n- $D$: The event that a patient has current unhealthy alcohol use.\n- $D^c$: The event that a patient does not have current unhealthy alcohol use.\n- $T$: The event that the AUDIT-C test result is positive.\n- $T^c$: The event that the AUDIT-C test result is negative.\n\nFrom the problem statement, we extract the following probabilities:\n- The prevalence of the condition: $P(D) = 0.20$.\n- The probability of not having the condition is therefore $P(D^c) = 1 - P(D) = 1 - 0.20 = 0.80$.\n- The sensitivity of the test, which is the probability of a positive test given the person has the condition: $P(T|D) = 0.78$.\n- The specificity of the test, which is the probability of a negative test given the person does not have the condition: $P(T^c|D^c) = 0.85$.\n\nFrom these, we can also determine:\n- The false negative rate, which is the probability of a negative test given the person has the condition: $P(T^c|D) = 1 - P(T|D) = 1 - 0.78 = 0.22$.\n- The false positive rate, which is the probability of a positive test given the person does not have the condition: $P(T|D^c) = 1 - P(T^c|D^c) = 1 - 0.85 = 0.15$.\n\nThe first objective is to compute the positive predictive value (PPV), which is the probability that a patient with a positive test result actually has the condition, denoted $P(D|T)$. Using Bayes' theorem:\n$$P(D|T) = \\frac{P(T|D)P(D)}{P(T)}$$\nTo find $P(T)$, the overall probability of a positive test, we use the law of total probability:\n$$P(T) = P(T|D)P(D) + P(T|D^c)P(D^c)$$\nSubstituting the given values:\n$$P(T) = (0.78)(0.20) + (0.15)(0.80) = 0.156 + 0.120 = 0.276$$\nNow we can compute the PPV:\n$$P(D|T) = \\frac{0.156}{0.276} \\approx 0.56521739...$$\nRounding to four significant figures, the positive predictive value is $0.5652$.\n\nThe second objective is to compute the negative predictive value (NPV), which is the probability that a patient with a negative test result is truly free of the condition, denoted $P(D^c|T^c)$. Using the corresponding form of Bayes' theorem:\n$$P(D^c|T^c) = \\frac{P(T^c|D^c)P(D^c)}{P(T^c)}$$\nTo find $P(T^c)$, the overall probability of a negative test, we can use the complement of $P(T)$:\n$$P(T^c) = 1 - P(T) = 1 - 0.276 = 0.724$$\nAlternatively, using the law of total probability:\n$$P(T^c) = P(T^c|D)P(D) + P(T^c|D^c)P(D^c) = (0.22)(0.20) + (0.85)(0.80) = 0.044 + 0.680 = 0.724$$\nThe results are consistent. Now we can compute the NPV:\n$$P(D^c|T^c) = \\frac{(0.85)(0.80)}{0.724} = \\frac{0.680}{0.724} \\approx 0.9392265...$$\nRounding to four significant figures, the negative predictive value is $0.9392$.\n\nFor the second part of the question, we analyze the workload implications for a cohort of $1000$ patients per month, where $90\\%$ complete screening.\nNumber of patients screened per month: $N_{screened} = 1000 \\times 0.90 = 900$.\n\nWe can calculate the expected number of patients in each category for this screened population of $900$:\n- Expected number with the condition: $N_D = N_{screened} \\times P(D) = 900 \\times 0.20 = 180$.\n- Expected number without the condition: $N_{D^c} = N_{screened} \\times P(D^c) = 900 \\times 0.80 = 720$.\n\nFrom these groups, we find the expected number of test outcomes:\n- True Positives (TP): Patients with the condition who test positive. $N_{TP} = N_D \\times P(T|D) = 180 \\times 0.78 = 140.4$.\n- False Negatives (FN): Patients with the condition who test negative. $N_{FN} = N_D \\times P(T^c|D) = 180 \\times 0.22 = 39.6$.\n- False Positives (FP): Patients without the condition who test positive. $N_{FP} = N_{D^c} \\times P(T|D^c) = 720 \\times 0.15 = 108.0$.\n- True Negatives (TN): Patients without the condition who test negative. $N_{TN} = N_{D^c} \\times P(T^c|D^c) = 720 \\times 0.85 = 612.0$.\n\nThe total number of patients with a positive screen is $N_{pos} = N_{TP} + N_{FP} = 140.4 + 108.0 = 248.4$.\nThe total number of patients with a negative screen is $N_{neg} = N_{FN} + N_{TN} = 39.6 + 612.0 = 651.6$.\n\nImplications for SBIRT workload:\nThe SBIRT model requires intervention for all patients with a positive screen. This means the clinic must be prepared to conduct approximately $248$ brief interventions and further assessments each month.\n- The PPV of $0.5652$ implies that of these $248$ interventions, only about $56.5\\%$ (approximately $140$ patients) will be for individuals who truly have unhealthy alcohol use (true positives).\n- The remaining $43.5\\%$ (approximately $108$ patients) are false positives. This constitutes a substantial portion of the SBIRT workload, where clinical resources are expended on individuals who do not have the target condition. This is a direct consequence of the test's specificity of $0.85$ in a population with $20\\%$ prevalence.\n- The NPV of $0.9392$ is high, indicating that a negative test result is a strong indicator of the absence of the condition. Clinicians can be reasonably confident in a negative result.\n- However, the existence of false negatives means that cases are missed. Each month, approximately $N_{FN} \\approx 40$ patients with unhealthy alcohol use will be incorrectly screened as negative. These individuals, who require intervention, will be missed by the program. This represents a significant gap in care, as nearly $22\\%$ ($39.6 / 180$) of all true cases are missed by the screen.\n\nIn summary, the screening program generates a high volume of work, with nearly as many interventions delivered to false positives as to true positives. While the test is effective at ruling out the condition for those who screen negative, it simultaneously fails to identify a notable number of individuals who actually need the intervention. The clinic's workload balance is therefore skewed towards managing a large number of positive screens, a significant fraction of which are false, while also accepting that a non-trivial number of true cases will be systematically overlooked.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5652 & 0.9392\n\\end{pmatrix}\n}\n$$", "id": "4502898"}, {"introduction": "Establishing a causal link between a policy and a health outcome is one of the most challenging tasks in public health research. This exercise [@problem_id:4502883] introduces the powerful Regression Discontinuity (RD) design, which leverages a sharp policy cutoff—like the minimum legal drinking age—to estimate causal effects. By understanding the core assumptions and validity checks of this quasi-experimental method, you will learn how researchers can isolate the impact of a policy from other confounding factors, providing robust evidence for decision-making.", "problem": "A public health team in a state with a legal minimum drinking age of $21$ years wants to estimate the causal effect of reaching the legal drinking age on acute alcohol-related emergency department (ED) visits. Let the running variable $X_i$ be individual $i$’s age in days, with the policy cutoff $c$ corresponding to $21$ years. Let $D_i$ be an indicator of legal alcohol access (equal to $1$ if $X_i \\ge c$ and $0$ otherwise), and let $Y_i$ be an indicator for whether the ED visit is alcohol-related. They plan to use Regression Discontinuity (RD) to estimate the causal effect at the threshold.\n\nStarting from the potential outcomes framework and core identification assumptions for RD, explain how the causal effect is identified at the legal drinking age threshold and specify appropriate empirical tests to assess manipulation of the running variable near the cutoff. Select all options that correctly state identification and appropriate manipulation tests in this context.\n\nA. Under continuity of potential outcomes in $X$ at $X=c$ and the Stable Unit Treatment Value Assumption (SUTVA), a sharp RD identifies the local causal effect as the difference in the right and left limits of $E[Y \\mid X=x]$ at $x=c$. In a fuzzy RD, the effect is identified by the ratio of the discontinuity in $E[Y \\mid X=x]$ to the discontinuity in $E[D \\mid X=x]$ at $x=c$. Manipulation can be assessed by testing continuity of the running variable’s density at $x=c$ (e.g., the McCrary test) and continuity of predetermined covariates across $x=c$.\n\nB. Because chronological age cannot be self-manipulated, manipulation testing is unnecessary; instead, validity should be established by confirming continuity of the outcome density $f_Y(y)$ at the cutoff $x=c$.\n\nC. The causal effect can be identified by comparing average outcomes for individuals aged $22$ versus those aged $20$ without modeling $X_i$. Manipulation can be detected by testing whether the mean of $X_i$ differs across the cutoff, i.e., comparing $E[X \\mid X \\ge c]$ to $E[X \\mid X < c]$.\n\nD. In fuzzy RD, the estimand of interest is the Intention-To-Treat (ITT) effect defined as the discontinuity in $E[Y \\mid X=x]$ at $x=c$ without any monotonicity assumption. Manipulation should be assessed by testing whether $E[D \\mid X=x]$ is continuous at $x=c$.\n\nE. Validity can be strengthened by placebo cutoff tests (checking for no discontinuities at $x=c'$ where no policy change occurs), bandwidth and polynomial order sensitivity analyses, and by verifying that predetermined covariates such as sex or parental education are continuous at $x=c$. It is also informative to confirm an expected discontinuity in policy-proximal variables (e.g., alcohol purchase rates) at $x=c$ to assess compliance while ensuring the running variable’s density is continuous.", "solution": "### Theoretical Framework for Regression Discontinuity (RD)\n\nThe core objective is to estimate the causal effect of a treatment $D$ on an outcome $Y$, where treatment assignment is determined by whether a continuous running variable $X$ exceeds a known cutoff $c$.\n\nLet $Y_i(1)$ be the potential outcome for individual $i$ if they receive the treatment (legal alcohol access, $D_i=1$) and $Y_i(0)$ be the potential outcome if they do not receive the treatment ($D_i=0$). The observed outcome is $Y_i = D_i Y_i(1) + (1-D_i) Y_i(0)$. The individual causal effect is $Y_i(1) - Y_i(0)$, which is unobservable. We aim to estimate the average causal effect for the population at the cutoff, $c$, which corresponds to an age of $21$ years. The estimand is the Local Average Treatment Effect (LATE) at the cutoff:\n$$ \\tau_{RD} = E[Y_i(1) - Y_i(0) \\mid X_i = c] $$\nThe fundamental identification assumption of RD is the continuity of the conditional expectation of potential outcomes at the cutoff $c$:\n$$ E[Y_i(1) \\mid X_i = x] \\text{ and } E[Y_i(0) \\mid X_i = x] \\text{ are continuous in } x \\text{ at } x=c. $$\nThis assumption implies that individuals just below the cutoff are comparable to individuals just above the cutoff in all respects that could affect the outcome, except for the treatment itself. The Stable Unit Treatment Value Assumption (SUTVA), which posits no interference between individuals and a consistent definition of treatment, is also a standard background assumption.\n\n### Sharp vs. Fuzzy RD Identification\n\n**1. Sharp Regression Discontinuity (SRD):**\nThe problem statement defines a sharp RD design, where treatment status is a deterministic function of the running variable: $D_i = 1$ if $X_i \\ge c$ and $D_i = 0$ if $X_i < c$.\nFor individuals just above the cutoff, we observe their treated potential outcomes: $\\lim_{x \\to c^+} E[Y_i \\mid X_i=x] = \\lim_{x \\to c^+} E[Y_i(1) \\mid X_i=x]$.\nFor individuals just below the cutoff, we observe their untreated potential outcomes: $\\lim_{x \\to c^-} E[Y_i \\mid X_i=x] = \\lim_{x \\to c^-} E[Y_i(0) \\mid X_i=x]$.\nGiven the continuity assumption for potential outcomes, the causal effect at the cutoff is identified by the discontinuity in the conditional expectation of the observed outcome:\n$$ \\tau_{SRD} = E[Y_i(1) - Y_i(0) \\mid X_i = c] = \\lim_{x \\to c^+} E[Y_i \\mid X_i=x] - \\lim_{x \\to c^-} E[Y_i \\mid X_i=x] $$\n\n**2. Fuzzy Regression Discontinuity (FRD):**\nIn a fuzzy RD, crossing the cutoff does not perfectly determine treatment but changes the probability of being treated discontinuously. That is, $E[D_i \\mid X_i=x]$ is discontinuous at $x=c$. This could occur if some individuals under $21$ gain access to alcohol or some over $21$ do not drink. The FRD estimand is identified using an instrumental variables (IV) framework, where crossing the cutoff is the instrument for treatment.\nThe causal effect is the ratio of the discontinuity in the outcome to the discontinuity in the treatment probability:\n$$ \\tau_{FRD} = \\frac{\\lim_{x \\to c^+} E[Y_i \\mid X_i=x] - \\lim_{x \\to c^-} E[Y_i \\mid X_i=x]}{\\lim_{x \\to c^+} E[D_i \\mid X_i=x] - \\lim_{x \\to c^-} E[D_i \\mid X_i=x]} $$\nThis identifies a LATE for \"compliers\"—individuals whose treatment status is affected by crossing the cutoff. This requires the IV assumptions, including monotonicity (crossing the cutoff never causes someone to stop receiving treatment who otherwise would have).\n\n### Validity and Manipulation Tests\n\nThe central threat to RD validity is the manipulation of the running variable. If individuals can precisely control $X_i$ to fall on a preferred side of the cutoff, this sorting invalidates the \"as-if random\" assignment assumption near $c$.\n**1. Density of the Running Variable:** The primary test for manipulation is to examine the density of the running variable, $f_X(x)$. In the absence of manipulation, the density should be continuous across the cutoff. A statistically significant jump or drop in the density at $c$ is evidence of sorting. The standard formal procedure for this is the McCrary test.\n**2. Continuity of Predetermined Covariates:** Another critical validity check is to test for discontinuities in predetermined covariates (e.g., gender, race, parental background). Since these covariates are determined before the treatment, their conditional means should be continuous across the cutoff $c$. A discontinuity in a covariate would suggest that the populations on either side of the cutoff are systematically different, violating the core continuity assumption.\n\n### Option-by-Option Analysis\n\n**A. Under continuity of potential outcomes in $X$ at $X=c$ and the Stable Unit Treatment Value Assumption (SUTVA), a sharp RD identifies the local causal effect as the difference in the right and left limits of $E[Y \\mid X=x]$ at $x=c$. In a fuzzy RD, the effect is identified by the ratio of the discontinuity in $E[Y \\mid X=x]$ to the discontinuity in $E[D \\mid X=x]$ at $x=c$. Manipulation can be assessed by testing continuity of the running variable’s density at $x=c$ (e.g., the McCrary test) and continuity of predetermined covariates across $x=c$.**\nThis statement is perfectly aligned with the theoretical framework. It correctly describes the identification strategy for both sharp and fuzzy RD designs and their underlying assumptions. It also correctly specifies the two most fundamental empirical tests for the validity of the RD design: testing for manipulation of the running variable's density and testing for continuity of predetermined covariates.\n**Verdict: Correct**\n\n**B. Because chronological age cannot be self-manipulated, manipulation testing is unnecessary; instead, validity should be established by confirming continuity of the outcome density $f_Y(y)$ at the cutoff $x=c$.**\nThis statement contains two errors. First, while direct self-manipulation of chronological age is impossible, the distribution of the observed running variable can still be distorted due to data-entry errors, rounding, or other features of the data collection process. Dismissing manipulation testing is therefore a methodologically unsound practice. Second, the proposed validity check—continuity of the outcome density $f_Y(y)$—is incorrect. The RD assumption pertains to the continuity of the *conditional expectation of potential outcomes*, not the unconditional density of the observed outcome. A significant treatment effect would likely induce a change in the distribution of $Y$, making this an invalid test.\n**Verdict: Incorrect**\n\n**C. The causal effect can be identified by comparing average outcomes for individuals aged $22$ versus those aged $20$ without modeling $X_i$. Manipulation can be detected by testing whether the mean of $X_i$ differs across the cutoff, i.e., comparing $E[X \\mid X \\ge c]$ to $E[X \\mid X < c]$.**\nThis statement misrepresents the RD method. RD leverages a comparison of individuals *just* above and *just* below the cutoff. Comparing individuals at age $22$ versus $20$ is a simple pre-post comparison across a wide interval, which is highly susceptible to confounding by age-related trends. The proposed manipulation test is nonsensical; the mean of $X_i$ for the group with $X_i \\ge c$ will, by definition, be greater than the mean for the group with $X_i < c$. The correct test is for a discontinuity in the *density* of $X_i$ at the point $c$.\n**Verdict: Incorrect**\n\n**D. In fuzzy RD, the estimand of interest is the Intention-To-Treat (ITT) effect defined as the discontinuity in $E[Y \\mid X=x]$ at $x=c$ without any monotonicity assumption. Manipulation should be assessed by testing whether $E[D \\mid X=x]$ is continuous at $x=c$.**\nThis statement is flawed. The discontinuity in $E[Y \\mid X=x]$ is the ITT effect, but the standard estimand of interest in fuzzy RD is the LATE, which is the ITT scaled by the first-stage effect, and its causal interpretation relies on the monotonicity assumption. More critically, the proposed manipulation test is wrong. In a fuzzy RD, we *require* $E[D \\mid X=x]$ to be *discontinuous* at $c$; this is the \"first stage\" that shows the instrument is relevant. If it were continuous, the denominator of the FRD estimator would be zero and the effect would be unidentified. Manipulation is tested by examining the density of the running variable, $f_X(x)$, not the treatment probability function.\n**Verdict: Incorrect**\n\n**E. Validity can be strengthened by placebo cutoff tests (checking for no discontinuities at $x=c'$ where no policy change occurs), bandwidth and polynomial order sensitivity analyses, and by verifying that predetermined covariates such as sex or parental education are continuous at $x=c$. It is also informative to confirm an expected discontinuity in policy-proximal variables (e.g., alcohol purchase rates) at $x=c$ to assess compliance while ensuring the running variable’s density is continuous.**\nThis statement outlines a comprehensive set of best practices for establishing the validity and robustness of an RD analysis. Placebo tests, sensitivity analyses for bandwidth and polynomial choice, and checking for continuity in covariates are all standard and essential validity checks. Confirming a discontinuity in a \"first stage\" or policy-proximal variable (like alcohol purchase rates) is crucial for a fuzzy RD design and strengthens the causal interpretation. Finally, it correctly re-emphasizes that the running variable's density should be continuous. All claims are correct and describe appropriate procedures.\n**Verdict: Correct**", "answer": "$$\\boxed{AE}$$", "id": "4502883"}]}