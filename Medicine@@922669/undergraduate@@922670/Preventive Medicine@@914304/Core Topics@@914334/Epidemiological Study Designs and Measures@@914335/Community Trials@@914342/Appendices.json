{"hands_on_practices": [{"introduction": "In community trials, individuals within the same community often share environmental or social factors, making them more similar to each other than to individuals in other communities. This similarity is quantified by the Intraclass Correlation Coefficient (ICC), a foundational concept that influences both the design and analysis of these studies. This first exercise [@problem_id:4578645] will guide you through calculating the ICC from its core variance components and reasoning about its profound implications for choosing a statistically efficient analysis method.", "problem": "Consider a community-level intervention evaluated using a cluster randomized trial, where individuals are nested within community clusters. Suppose a continuous outcome is modeled by a random-intercept structure in which individual outcomes within the same cluster share a common random effect. The between-cluster variance is given by $\\sigma_{b}^{2} = 4$, and the within-cluster variance is given by $\\sigma_{w}^{2} = 16$. Using only the fundamental definitions of variance and covariance for a random-intercept model and the definition of the Intraclass Correlation Coefficient (ICC), compute the ICC, denoted $\\rho$. Provide $\\rho$ as an exact fraction. Then, based on the magnitude of $\\rho$, reason from first principles whether a cluster-level analysis of cluster means or an individual-level analysis with appropriate correction for clustering (for example, a linear mixed-effects model or Generalized Estimating Equations (GEE)) tends to be more statistically efficient for estimating a marginal treatment effect. No numerical result beyond $\\rho$ is required for the efficiency discussion, and no additional formulas are provided in the problem statement.", "solution": "The problem asks for two things: first, to compute the Intraclass Correlation Coefficient (ICC), denoted $\\rho$, for a given random-intercept model structure, and second, to reason about the relative statistical efficiency of cluster-level versus individual-level analysis based on the computed value of $\\rho$.\n\nLet $Y_{ij}$ represent the continuous outcome for individual $j$ (where $j=1, \\dots, m_i$) in cluster $i$ (where $i=1, \\dots, k$). The problem states that the outcome is modeled by a random-intercept structure. This model can be written as:\n$$Y_{ij} = \\mu + u_i + \\epsilon_{ij}$$\nHere, $\\mu$ is the overall mean outcome, $u_i$ is the random effect shared by all individuals in cluster $i$, and $\\epsilon_{ij}$ is the individual-level random error for person $j$ in cluster $i$.\n\nThe assumptions of the random-intercept model are:\n1. The cluster random effects $u_i$ are independent and identically distributed, with a mean of $E[u_i] = 0$ and a variance of $\\text{Var}(u_i) = \\sigma_{b}^{2}$. This is the between-cluster variance, given as $\\sigma_{b}^{2} = 4$.\n2. The individual-level errors $\\epsilon_{ij}$ are independent and identically distributed, with a mean of $E[\\epsilon_{ij}] = 0$ and a variance of $\\text{Var}(\\epsilon_{ij}) = \\sigma_{w}^{2}$. This is the within-cluster variance, given as $\\sigma_{w}^{2} = 16$.\n3. The random effects $u_i$ and the random errors $\\epsilon_{ij}$ are independent of each other for all $i$ and $j$.\n\nTo compute the ICC, we must first determine the total variance of an observation and the covariance between two distinct observations within the same cluster.\n\nThe total variance of a single observation $Y_{ij}$ is derived from its model definition. Since $\\mu$ is a constant and $u_i$ and $\\epsilon_{ij}$ are independent random variables:\n$$\\text{Var}(Y_{ij}) = \\text{Var}(\\mu + u_i + \\epsilon_{ij}) = \\text{Var}(u_i) + \\text{Var}(\\epsilon_{ij})$$\nSubstituting the given variance components, the total variance is:\n$$\\text{Var}(Y_{ij}) = \\sigma_{b}^{2} + \\sigma_{w}^{2}$$\n\nNext, we find the covariance between the outcomes of two different individuals, $j$ and $l$ ($j \\neq l$), from the same cluster $i$.\n$$\\text{Cov}(Y_{ij}, Y_{il}) = \\text{Cov}(\\mu + u_i + \\epsilon_{ij}, \\mu + u_i + \\epsilon_{il})$$\nUsing the properties of covariance and the independence assumptions (i.e., $\\text{Cov}(u_i, \\epsilon_{il}) = 0$, $\\text{Cov}(\\epsilon_{ij}, u_i) = 0$, and $\\text{Cov}(\\epsilon_{ij}, \\epsilon_{il}) = 0$ for $j \\neq l$):\n$$\\text{Cov}(Y_{ij}, Y_{il}) = \\text{Cov}(u_i, u_i) + \\text{Cov}(u_i, \\epsilon_{il}) + \\text{Cov}(\\epsilon_{ij}, u_i) + \\text{Cov}(\\epsilon_{ij}, \\epsilon_{il})$$\n$$\\text{Cov}(Y_{ij}, Y_{il}) = \\text{Var}(u_i) + 0 + 0 + 0 = \\sigma_{b}^{2}$$\nThe shared random effect $u_i$ is the sole source of covariance between two individuals in the same cluster.\n\nThe Intraclass Correlation Coefficient, $\\rho$, is defined as the correlation between two randomly selected individuals from the same randomly selected cluster. Using the fundamental definition of correlation:\n$$\\rho = \\text{Corr}(Y_{ij}, Y_{il}) = \\frac{\\text{Cov}(Y_{ij}, Y_{il})}{\\sqrt{\\text{Var}(Y_{ij})\\text{Var}(Y_{il})}}$$\nSince the variance is identical for all observations, $\\text{Var}(Y_{ij}) = \\text{Var}(Y_{il}) = \\sigma_{b}^{2} + \\sigma_{w}^{2}$, the formula simplifies to:\n$$\\rho = \\frac{\\text{Cov}(Y_{ij}, Y_{il})}{\\text{Var}(Y_{ij})} = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{w}^{2}}$$\nThis equation shows that $\\rho$ represents the proportion of the total variance that is attributable to variance between clusters.\n\nSubstituting the given values $\\sigma_{b}^{2} = 4$ and $\\sigma_{w}^{2} = 16$:\n$$\\rho = \\frac{4}{4 + 16} = \\frac{4}{20} = \\frac{1}{5}$$\n\nThe second part of the problem requires reasoning about the statistical efficiency of a cluster-level analysis versus an individual-level analysis with correction for clustering.\nThe calculated ICC is $\\rho = \\frac{1}{5} = 0.2$. This value indicates that $20\\%$ of the total variance in the outcome is due to variation between clusters, while the remaining $80\\%$ is due to variation among individuals within the clusters.\n\nA cluster-level analysis first calculates a summary statistic (e.g., the mean) for each cluster and then performs the analysis on these cluster-level summaries. This method discards all individual-level, within-cluster variation.\nAn individual-level analysis (like a mixed-effects model or GEE) uses data from all individuals and explicitly accounts for the correlation structure (parameterized by $\\rho$) in the model.\n\nStatistical efficiency is related to the precision of the estimate of the treatment effect; a more efficient method yields an estimate with a smaller variance (and smaller standard error). The choice between the two methods hinges on how much information is lost by aggregating the data to the cluster level.\n\nIn this problem, the within-cluster variance ($\\sigma_{w}^{2} = 16$) is four times larger than the between-cluster variance ($\\sigma_{b}^{2} = 4$). This signifies that there is substantial heterogeneity among individuals within each cluster. This large within-cluster variation is an important source of information. A cluster-level analysis, by collapsing all individual data points in a cluster to a single mean, discards this substantial source of information. The analysis effectively throws away $80\\%$ of the variance structure. This loss of information leads to less precise estimates of the treatment effect, and thus lower statistical efficiency.\n\nIn contrast, an individual-level analysis with an appropriate correction for clustering utilizes all available data points. By modeling both the between-cluster and within-cluster components of variance, it leverages the full information content of the data. This allows for a more precise estimation of all model parameters, including the treatment effect. The resulting estimates will have smaller standard errors compared to those from a cluster-level analysis.\n\nTherefore, given that $\\rho = 0.2$ is not close to $1$ and the within-cluster variance is large, an individual-level analysis with correction for clustering tends to be more statistically efficient. A cluster-level analysis would only approach the efficiency of an individual-level analysis if $\\rho$ were very high (close to $1$), which would imply that individuals within a cluster are nearly identical ($\\sigma_{w}^{2} \\approx 0$) and provide redundant information. As this is not the case here, preserving the individual-level information is crucial for achieving greater statistical efficiency.", "answer": "$$\\boxed{\\frac{1}{5}}$$", "id": "4578645"}, {"introduction": "A crucial step in designing a robust trial is determining the required sample size to detect a meaningful effect with adequate statistical power. In community trials, this calculation is not as simple as in individual-level trials, as it must account for the clustering effect we explored previously. This practice [@problem_id:4513249] walks you through the derivation of the complete sample size formula, demonstrating how the ICC directly inflates the variance and thus the number of communities needed for your study.", "problem": "A public health team is planning a parallel, two-arm Cluster Randomized Trial (CRT) to evaluate a community-level preventive intervention. Each community cluster contributes $m$ individuals on average, and the outcome is a continuous measure recorded on a scale where the individual-level variance is $\\sigma^{2}$. Within each cluster, individual outcomes are exchangeable with a common Intracluster Correlation Coefficient (ICC), denoted by $\\rho$, and independence is assumed across clusters. The intervention is expected to shift the arm means by a difference of $\\Delta$ on the measurement scale. The team will use a two-sided test with Type I error rate $\\alpha$ and desired power $1-\\beta$.\n\nStarting from first principles—namely, the variance and covariance rules for sums and averages under exchangeable correlation, and the large-sample normal approximation for the difference in two independent sample means—derive the analytical expression for the minimum number of clusters per arm required to detect the mean difference $\\Delta$ at the specified $(\\alpha, 1-\\beta)$. Then, compute this number for the following design parameters: $\\rho = 0.02$, $m = 40$, $\\sigma^{2} = 100$, $\\Delta = 5$, $\\alpha = 0.05$, and $1-\\beta = 0.80$. Report the smallest integer $k$ that satisfies your derived requirement. No rounding by significant figures is needed; provide the minimum integer that achieves the design targets.", "solution": "The problem asks for the minimum number of clusters per arm, $k$, required for a two-arm CRT. The derivation will be based on first principles, as requested.\n\nLet $Y_{ij}$ denote the continuous outcome for the $j$-th individual in the $i$-th cluster, where $i=1, \\dots, k$ for each arm and $j=1, \\dots, m$. We are given the following parameters:\n- The average number of individuals per cluster is $m$.\n- The individual-level variance is $\\text{Var}(Y_{ij}) = \\sigma^2$.\n- The Intracluster Correlation Coefficient (ICC) is $\\rho = \\text{Corr}(Y_{ij}, Y_{il})$ for $j \\neq l$.\n- The expected mean difference between arms is $\\Delta$.\n- The Type I error rate is $\\alpha$ (for a two-sided test).\n- The desired power is $1-\\beta$.\n\n**1. Variance of a Cluster Mean**\n\nFirst, we derive the variance of the mean outcome within a single cluster. The mean for cluster $i$ is $\\bar{Y}_i = \\frac{1}{m} \\sum_{j=1}^m Y_{ij}$.\nThe variance of this mean is:\n$$ \\text{Var}(\\bar{Y}_i) = \\text{Var}\\left(\\frac{1}{m} \\sum_{j=1}^m Y_{ij}\\right) = \\frac{1}{m^2} \\text{Var}\\left(\\sum_{j=1}^m Y_{ij}\\right) $$\nThe variance of the sum of these correlated random variables is the sum of their variances plus the sum of all covariances:\n$$ \\text{Var}\\left(\\sum_{j=1}^m Y_{ij}\\right) = \\sum_{j=1}^m \\text{Var}(Y_{ij}) + \\sum_{j \\neq l} \\text{Cov}(Y_{ij}, Y_{il}) $$\nThere are $m$ variance terms and $m(m-1)$ covariance terms. By definition, the covariance is $\\text{Cov}(Y_{ij}, Y_{il}) = \\rho \\sqrt{\\text{Var}(Y_{ij})\\text{Var}(Y_{il})} = \\rho \\sigma^2$.\nSubstituting this into the equation:\n$$ \\text{Var}\\left(\\sum_{j=1}^m Y_{ij}\\right) = m \\sigma^2 + m(m-1) \\rho \\sigma^2 = m\\sigma^2 [1 + (m-1)\\rho] $$\nTherefore, the variance of the cluster mean, which we denote as $\\sigma_c^2$, is:\n$$ \\sigma_c^2 = \\text{Var}(\\bar{Y}_i) = \\frac{1}{m^2} \\left( m\\sigma^2 [1 + (m-1)\\rho] \\right) = \\frac{\\sigma^2}{m} [1 + (m-1)\\rho] $$\nThe term $[1 + (m-1)\\rho]$ is known as the design effect or variance inflation factor (VIF), which quantifies how much the variance is inflated due to clustering.\n\n**2. Variance of the Difference in Arm Means**\n\nThe trial has two arms, Treatment ($T$) and Control ($C$), each with $k$ clusters. The overall mean for an arm is the average of its $k$ cluster means. For the treatment arm, this is $\\bar{Y}_T = \\frac{1}{k}\\sum_{i=1}^k \\bar{Y}_{iT}$.\nSince clusters are independent, the variance of the arm mean is:\n$$ \\text{Var}(\\bar{Y}_T) = \\text{Var}\\left(\\frac{1}{k}\\sum_{i=1}^k \\bar{Y}_{iT}\\right) = \\frac{1}{k^2} \\sum_{i=1}^k \\text{Var}(\\bar{Y}_{iT}) = \\frac{1}{k^2} (k \\sigma_c^2) = \\frac{\\sigma_c^2}{k} $$\nSimilarly, for the control arm, $\\text{Var}(\\bar{Y}_C) = \\frac{\\sigma_c^2}{k}$.\n\nThe statistic of interest is the difference in the two arm means, $D = \\bar{Y}_T - \\bar{Y}_C$. As the arms are independent, the variance of this difference is the sum of the variances:\n$$ \\text{Var}(D) = \\text{Var}(\\bar{Y}_T) + \\text{Var}(\\bar{Y}_C) = \\frac{\\sigma_c^2}{k} + \\frac{\\sigma_c^2}{k} = \\frac{2\\sigma_c^2}{k} $$\nSubstituting the expression for $\\sigma_c^2$:\n$$ \\text{Var}(D) = \\frac{2}{k} \\left( \\frac{\\sigma^2}{m} [1 + (m-1)\\rho] \\right) = \\frac{2\\sigma^2 [1 + (m-1)\\rho]}{mk} $$\nThe standard error of the difference is $SE(D) = \\sqrt{\\text{Var}(D)}$.\n\n**3. Power Calculation and Sample Size Derivation**\n\nWe use a large-sample normal approximation for the test statistic. The null and alternative hypotheses are:\n$H_0: \\mu_T - \\mu_C = 0$\n$H_A: |\\mu_T - \\mu_C| = \\Delta$\n\nThe test statistic under the null hypothesis is $Z = \\frac{D}{SE(D)}$, which is approximately distributed as a standard normal $N(0,1)$. For a two-sided test with Type I error rate $\\alpha$, we reject $H_0$ if $|Z| > z_{1-\\alpha/2}$, where $z_{q}$ is the $q$-th quantile of the standard normal distribution.\n\nPower ($1-\\beta$) is the probability of rejecting $H_0$ given that the true difference is $\\Delta$. Under $H_A$, the distribution of $D$ is approximately $N(\\Delta, \\text{Var}(D))$. The test statistic $\\frac{D - \\Delta}{SE(D)}$ is approximately $N(0,1)$.\n\nTo achieve power $1-\\beta$, we require:\n$P(\\text{Reject } H_0 | \\mu_T - \\mu_C = \\Delta) \\ge 1-\\beta$.\nThis is primarily driven by the upper tail of the test:\n$P\\left(\\frac{D}{SE(D)} > z_{1-\\alpha/2} \\bigg| \\mu_T - \\mu_C = \\Delta \\right) \\approx 1-\\beta$.\nWe standardize the expression under the alternative hypothesis:\n$$ P\\left(\\frac{D-\\Delta}{SE(D)} > z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)} \\right) \\approx 1-\\beta $$\nLet $Z' = \\frac{D-\\Delta}{SE(D)} \\sim N(0,1)$. Then $P(Z' > z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)}) \\approx 1-\\beta$.\nThe quantile function gives $z_{1-(1-\\beta)} = z_{\\beta} \\approx z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)}$.\nUsing the identity $z_{\\beta} = -z_{1-\\beta}$, we get $-z_{1-\\beta} \\approx z_{1-\\alpha/2} - \\frac{\\Delta}{SE(D)}$, which rearranges to the standard form:\n$$ \\frac{\\Delta}{SE(D)} \\approx z_{1-\\alpha/2} + z_{1-\\beta} $$\nTo ensure the power requirement is met, we use an inequality:\n$$ \\frac{\\Delta}{SE(D)} \\ge z_{1-\\alpha/2} + z_{1-\\beta} $$\nSquaring both sides and substituting $SE(D)^2 = \\text{Var}(D)$:\n$$ \\frac{\\Delta^2}{\\text{Var}(D)} \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\n$$ \\frac{\\Delta^2}{\\frac{2\\sigma^2 [1 + (m-1)\\rho]}{mk}} \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\n$$ \\frac{mk \\Delta^2}{2\\sigma^2 [1 + (m-1)\\rho]} \\ge (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\nFinally, we solve for $k$:\n$$ k \\ge \\frac{2\\sigma^2 [1 + (m-1)\\rho]}{m \\Delta^2} (z_{1-\\alpha/2} + z_{1-\\beta})^2 $$\nThis is the required analytical expression for the minimum number of clusters per arm.\n\n**4. Numerical Computation**\n\nWe are given the following parameters:\n- $\\rho = 0.02$\n- $m = 40$\n- $\\sigma^2 = 100$\n- $\\Delta = 5$\n- $\\alpha = 0.05$ (two-sided)\n- Power $1-\\beta = 0.80$\n\nFirst, we find the required quantiles from the standard normal distribution:\n- For $\\alpha=0.05$, $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975} \\approx 1.9600$.\n- For $1-\\beta=0.80$, $\\beta=0.20$, so $z_{1-\\beta} = z_{0.80} \\approx 0.8416$.\n\nNext, we calculate the design effect (VIF):\n$$ 1 + (m-1)\\rho = 1 + (40-1)(0.02) = 1 + (39)(0.02) = 1 + 0.78 = 1.78 $$\nNow, we substitute all values into the inequality for $k$:\n$$ k \\ge \\frac{2(100) [1.78]}{40 (5)^2} (1.9600 + 0.8416)^2 $$\n$$ k \\ge \\frac{200 \\times 1.78}{40 \\times 25} (2.8016)^2 $$\n$$ k \\ge \\frac{356}{1000} (7.84896256) $$\n$$ k \\ge 0.356 \\times 7.84896256 $$\n$$ k \\ge 2.79426... $$\nSince the number of clusters, $k$, must be an integer, we must take the smallest integer value that satisfies this condition. This is achieved by taking the ceiling of the result.\n$$ k = \\lceil 2.79426... \\rceil = 3 $$\nTherefore, a minimum of $3$ clusters per arm is required.", "answer": "$$\n\\boxed{3}\n$$", "id": "4513249"}, {"introduction": "Once a trial is complete, the data must be analyzed correctly to draw valid conclusions. A common characteristic of community trials is a relatively small number of randomized units (the communities), even if the total number of individual participants is large. This final exercise [@problem_id:4578574] highlights a critical pitfall in analysis, showing why standard statistical tests assuming large samples can be misleading and guiding you to use the appropriate statistical distribution for sound inference.", "problem": "A two-arm community randomized trial allocates entire communities to intervention or control. In such designs, the independent sampling units are the clusters (communities), not the individuals. Suppose the primary analysis is conducted at the cluster level, comparing the mean of a continuous, approximately normally distributed cluster-level outcome between the intervention arm and the control arm. Let the number of clusters be $J_1$ in the intervention arm and $J_2$ in the control arm, with $J_1 = 8$ and $J_2 = 8$. Assume cluster-level outcomes are independent across clusters, follow a normal distribution with a common but unknown variance across arms, and that the two arms are randomized independently.\n\nStarting from the definition of the sampling distribution of the difference in two independent normal means when the common variance is unknown and replaced by its pooled estimator, derive the appropriate reference distribution for the standardized difference in cluster means under the null hypothesis of equal arm means. Using this reference distribution, compute the two-sided critical value for a test at significance level $\\alpha = 0.05$. Round your final numerical answer to four significant figures. Then, explain why relying on a normal approximation would be scientifically inadequate in this setting of cluster-randomized inference.", "solution": "The randomization unit in a cluster randomized trial is the cluster, so the inferential sample size is determined by the number of clusters rather than the number of individuals. Let $\\bar{Y}_1$ and $\\bar{Y}_2$ denote the sample means of the cluster-level outcome in the intervention and control arms, respectively, computed over clusters. Under the assumptions stated, cluster-level outcomes within each arm are independent and identically distributed as normal with a common variance $\\sigma^{2}$, and outcomes are independent across arms.\n\nWe consider testing the null hypothesis $H_0: \\mu_1 = \\mu_2$, where $\\mu_1$ and $\\mu_2$ are the arm-specific mean outcomes at the cluster level. The fundamental base is as follows:\n\n- If $X_1, \\dots, X_{J_1} \\sim \\mathcal{N}(\\mu_1, \\sigma^{2})$ independently and $Y_1, \\dots, Y_{J_2} \\sim \\mathcal{N}(\\mu_2, \\sigma^{2})$ independently, then the sample means $\\bar{X}$ and $\\bar{Y}$ satisfy $(\\bar{X} - \\mu_1) \\sim \\mathcal{N}\\!\\left(0, \\frac{\\sigma^{2}}{J_1}\\right)$ and $(\\bar{Y} - \\mu_2) \\sim \\mathcal{N}\\!\\left(0, \\frac{\\sigma^{2}}{J_2}\\right)$, independently.\n- The difference of means $(\\bar{X} - \\bar{Y}) - (\\mu_1 - \\mu_2)$ is therefore normal with variance $\\sigma^{2}\\!\\left(\\frac{1}{J_1} + \\frac{1}{J_2}\\right)$.\n- When $\\sigma^{2}$ is unknown, the pooled variance estimator\n$$\nS_{p}^{2} \\;=\\; \\frac{(J_1 - 1)S_{1}^{2} + (J_2 - 1)S_{2}^{2}}{J_1 + J_2 - 2}\n$$\ncombines the within-arm sample variances $S_{1}^{2}$ and $S_{2}^{2}$. Under normality, each $(J_a - 1)S_{a}^{2}/\\sigma^{2}$ is chi-square with $J_a - 1$ degrees of freedom for $a \\in \\{1,2\\}$, and the sum is chi-square with $(J_1 - 1) + (J_2 - 1) = J_1 + J_2 - 2$ degrees of freedom.\n\nDefine the standardized test statistic that replaces $\\sigma^{2}$ with $S_{p}^{2}$:\n$$\nT \\;=\\; \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_1 - \\mu_2)}{S_{p}\\,\\sqrt{\\frac{1}{J_1} + \\frac{1}{J_2}}}.\n$$\nUnder $H_0: \\mu_1 = \\mu_2$, the numerator is centered at $0$, and by the above facts the ratio of a normal quantity to the square root of an independent chi-square divided by its degrees of freedom follows the Student $t$ distribution. Specifically,\n$$\nT \\sim t_{\\nu} \\quad \\text{with} \\quad \\nu = J_1 + J_2 - 2.\n$$\n\nWith $J_1 = 8$ and $J_2 = 8$, the degrees of freedom are\n$$\n\\nu = 8 + 8 - 2 = 14.\n$$\nFor a two-sided test at significance level $\\alpha = 0.05$, the critical value $c$ satisfies\n$$\n\\Pr\\!\\left(|T| \\leq c\\right) = 1 - \\alpha \\quad \\Rightarrow \\quad c = t_{1 - \\alpha/2,\\,\\nu} = t_{0.975,\\,14}.\n$$\nUsing standard Student $t$ quantiles, $t_{0.975,\\,14} \\approx 2.144786688$. Rounding to four significant figures yields $2.145$.\n\nFinally, the normal approximation is scientifically inadequate here because the inferential sample size is the number of clusters, which is small ($J_1 + J_2 = 16$). When $\\sigma^{2}$ is unknown and estimated from the data, the sampling distribution of the standardized mean difference has heavier tails than the normal distribution, captured by the Student $t$ distribution with $\\nu = 14$ degrees of freedom. Using the normal critical value $z_{0.975} = 1.96$ would ignore the additional uncertainty from estimating $\\sigma^{2}$ and the small degrees of freedom, resulting in anti-conservative inference (inflated Type I error) in cluster-randomized analyses with few clusters. Therefore, the appropriate reference is the Student $t$ distribution with $\\nu = 14$, and the corresponding two-sided $0.05$ critical value is $t_{0.975,\\,14}$.", "answer": "$$\\boxed{2.145}$$", "id": "4578574"}]}