{"hands_on_practices": [{"introduction": "In biostatistical analysis, we often encounter data that is \"sparse,\" meaning the sample size is small relative to the number of categories. This can lead to low or even zero counts in a contingency table, which violates a key assumption of the Pearson's chi-squared test—that expected cell counts should not be too small. This exercise provides hands-on practice with a common and pragmatic solution: collapsing categories in a way that is both statistically sound and clinically meaningful, allowing for a more robust analysis [@problem_id:4776955].", "problem": "A clinical epidemiology team is evaluating the association between empiric antibiotic regimen and early infection severity among adults admitted with confirmed Methicillin-Resistant Staphylococcus Aureus (MRSA) bacteremia. The cohort is observational, with each patient contributing a single observation and no repeated measures. The initial contingency table has four regimen categories and four severity categories at $72$ hours after admission. Some cells are zero, raising concerns about the appropriateness of the chi-squared test. The regimen categories are: beta-lactam monotherapy, clindamycin, vancomycin, and linezolid. The severity categories are: resolved, persistent localized infection, systemic infection, and septic shock. The observed counts are as follows:\n- Beta-lactam monotherapy: resolved $2$, localized $5$, systemic $9$, septic shock $5$.\n- Clindamycin: resolved $6$, localized $7$, systemic $1$, septic shock $0$.\n- Vancomycin: resolved $9$, localized $10$, systemic $2$, septic shock $2$.\n- Linezolid: resolved $7$, localized $6$, systemic $0$, septic shock $1$.\n\nFrom the standpoint of clinical decision-making and the assumptions of the chi-squared test in medical evidence synthesis, collapse the regimen categories into two groups: MRSA-active therapy (clindamycin, vancomycin, linezolid) versus non-MRSA-active therapy (beta-lactam monotherapy). Also collapse the severity categories into two groups: non-severe (resolved, localized) versus severe (systemic, septic shock). Under the null hypothesis that regimen group and severity group are independent, compute the expected cell counts for the resulting $2 \\times 2$ table. Report the four expected counts in the order $(E_{11}, E_{12}, E_{21}, E_{22})$, where row $1$ is non-MRSA-active therapy and row $2$ is MRSA-active therapy, and column $1$ is non-severe and column $2$ is severe. Round your answer to four significant figures.", "solution": "The problem requires the calculation of expected cell counts for a $2 \\times 2$ contingency table derived from a larger $4 \\times 4$ table. This procedure is common in statistical analysis, particularly in medical research, when initial data tabulation results in cells with low or zero counts, which can invalidate the assumptions of the chi-squared test of independence. The test's reliability is contingent upon having sufficiently large expected frequencies in each cell.\n\nFirst, we must construct the $2 \\times 2$ contingency table of observed counts by collapsing the categories as specified.\n\nThe initial regimen categories are:\n1. Beta-lactam monotherapy\n2. Clindamycin\n3. Vancomycin\n4. Linezolid\n\nThe initial severity categories are:\n1. Resolved\n2. Persistent localized infection (localized)\n3. Systemic infection (systemic)\n4. Septic shock\n\nThe collapsing rules are:\n-   **Regimen Groups**:\n    -   Row $1$: Non-MRSA-active therapy (`non-MRSA-active`), consisting of Beta-lactam monotherapy.\n    -   Row $2$: MRSA-active therapy (`MRSA-active`), consisting of Clindamycin, Vancomycin, and Linezolid.\n-   **Severity Groups**:\n    -   Column $1$: Non-severe outcome (`non-severe`), consisting of resolved and localized infection.\n    -   Column $2$: Severe outcome (`severe`), consisting of systemic infection and septic shock.\n\nLet $O_{ij}$ denote the observed count in row $i$ and column $j$ of the new $2 \\times 2$ table.\n\nThe observed count for `non-MRSA-active` and `non-severe` ($O_{11}$) is the sum of `resolved` and `localized` cases for Beta-lactam monotherapy:\n$$O_{11} = 2 + 5 = 7$$\n\nThe observed count for `non-MRSA-active` and `severe` ($O_{12}$) is the sum of `systemic` and `septic shock` cases for Beta-lactam monotherapy:\n$$O_{12} = 9 + 5 = 14$$\n\nThe observed count for `MRSA-active` and `non-severe` ($O_{21}$) is the sum of `resolved` and `localized` cases for Clindamycin, Vancomycin, and Linezolid:\n-   Clindamycin: $6 + 7 = 13$\n-   Vancomycin: $9 + 10 = 19$\n-   Linezolid: $7 + 6 = 13$\n$$O_{21} = (6 + 7) + (9 + 10) + (7 + 6) = 13 + 19 + 13 = 45$$\n\nThe observed count for `MRSA-active` and `severe` ($O_{22}$) is the sum of `systemic` and `septic shock` cases for Clindamycin, Vancomycin, and Linezolid:\n-   Clindamycin: $1 + 0 = 1$\n-   Vancomycin: $2 + 2 = 4$\n-   Linezolid: $0 + 1 = 1$\n$$O_{22} = (1 + 0) + (2 + 2) + (0 + 1) = 1 + 4 + 1 = 6$$\n\nThe resulting $2 \\times 2$ table of observed counts is:\n|                   | Non-severe | Severe | Row Total |\n|-------------------|------------|--------|-----------|\n| Non-MRSA-active   | $7$        | $14$   | $R_1$     |\n| MRSA-active       | $45$       | $6$    | $R_2$     |\n| **Column Total**  | $C_1$      | $C_2$  | $N$       |\n\nNext, we calculate the marginal totals:\n-   Row $1$ total: $R_1 = O_{11} + O_{12} = 7 + 14 = 21$\n-   Row $2$ total: $R_2 = O_{21} + O_{22} = 45 + 6 = 51$\n-   Column $1$ total: $C_1 = O_{11} + O_{21} = 7 + 45 = 52$\n-   Column $2$ total: $C_2 = O_{12} + O_{22} = 14 + 6 = 20$\n-   Grand total: $N = R_1 + R_2 = 21 + 51 = 72$. As a check, $N = C_1 + C_2 = 52 + 20 = 72$.\n\nThe null hypothesis ($H_0$) for the chi-squared test of independence states that there is no association between the row variable (regimen group) and the column variable (severity group). Under this hypothesis, the expected count $E_{ij}$ for the cell in row $i$ and column $j$ is calculated as:\n$$E_{ij} = \\frac{R_i \\times C_j}{N}$$\n\nWe now compute the four expected cell counts ($E_{11}, E_{12}, E_{21}, E_{22}$).\n\nExpected count for `non-MRSA-active` and `non-severe` ($E_{11}$):\n$$E_{11} = \\frac{R_1 \\times C_1}{N} = \\frac{21 \\times 52}{72} = \\frac{1092}{72} = 15.1666...$$\n\nExpected count for `non-MRSA-active` and `severe` ($E_{12}$):\n$$E_{12} = \\frac{R_1 \\times C_2}{N} = \\frac{21 \\times 20}{72} = \\frac{420}{72} = 5.8333...$$\n\nExpected count for `MRSA-active` and `non-severe` ($E_{21}$):\n$$E_{21} = \\frac{R_2 \\times C_1}{N} = \\frac{51 \\times 52}{72} = \\frac{2652}{72} = 36.8333...$$\n\nExpected count for `MRSA-active` and `severe` ($E_{22}$):\n$$E_{22} = \\frac{R_2 \\times C_2}{N} = \\frac{51 \\times 20}{72} = \\frac{1020}{72} = 14.1666...$$\n\nThe problem requires rounding these values to four significant figures.\n-   $E_{11} = 15.1666... \\approx 15.17$\n-   $E_{12} = 5.8333... \\approx 5.833$\n-   $E_{21} = 36.8333... \\approx 36.83$\n-   $E_{22} = 14.1666... \\approx 14.17$\n\nThe final answer is the set of these four expected counts presented in the specified order $(E_{11}, E_{12}, E_{21}, E_{22})$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n15.17 & 5.833 & 36.83 & 14.17\n\\end{pmatrix}\n}\n$$", "id": "4776955"}, {"introduction": "When the assumptions for the Pearson's chi-squared test are not met, particularly in studies with small sample sizes, what is the alternative? This practice directly contrasts the large-sample chi-squared approximation with Fisher's exact test, a method that provides a correct p-value regardless of sample size or expected frequencies. By working through this problem, you will gain a deeper appreciation for why the expected count rule exists and understand the potential for misleading conclusions if it is ignored [@problem_id:4776999].", "problem": "A $2 \\times 2$ contingency table in a clinical study has observed counts $O=\\begin{pmatrix}1&9\\\\8&2\\end{pmatrix}$, and the row margins are fixed at $(10,10)$ so that the grand total is $20$. Under the null hypothesis of independence in a randomized or stratified design where margins are fixed by design, the conditional distribution of the cell count in the first row and first column is determined by the combinatorial allocation of $9$ individuals into the first column across two rows of fixed sizes $(10,10)$. Starting from first principles of conditional inference under fixed margins (combinatorial enumeration) and the large-sample approximation that motivates Pearson’s chi-squared test via the Central Limit Theorem (CLT), identify the option that correctly outlines the calculation of the two-sided Fisher exact $p$-value for this table and contrasts it with Pearson’s chi-squared $p$-value, including appropriate numerical magnitudes and a principled discussion of assumptions and limitations relevant to medical evidence.\n\nChoose the single best option.\n\nA. Conditioning on the fixed margins $(10,10)$ and column totals $(9,11)$, the exact null distribution of the first cell $X$ is hypergeometric, and the two-sided Fisher $p$-value is obtained by summing the probabilities of all tables that are at least as unlikely as the observed table (here, those with $X \\in \\{0,1,8,9\\}$), yielding approximately $0.00548$. Pearson’s chi-squared statistic without continuity correction is approximately $9.90$ with $1$ degree of freedom, giving $p \\approx 0.0017$. Because two expected counts are less than $5$, the chi-squared approximation may be anticonservative, highlighting a limitation in this medical context.\n\nB. The exact two-sided $p$-value is approximately $0.032$, obtained by summing all tables with $X \\le 2$ and $X \\ge 8$, and Pearson’s $p$-value is also approximately $0.032$, so the chi-squared test remains valid even when several expected counts are below $5$.\n\nC. Fisher’s exact test conditions only on the grand total $N=20$, not on the margins, so the exact two-sided $p$-value equals the Pearson chi-squared $p$-value and is approximately $0.0017$ with $1$ degree of freedom.\n\nD. A proper contrast is that Fisher’s two-sided $p$-value must be approximated by Monte Carlo simulation in $2 \\times 2$ tables with fixed margins because exact enumeration is intractable; the exact value is much larger (around $0.07$) than Pearson’s $p$-value in this case.", "solution": "The user wants me to validate the problem statement, and if valid, solve the problem by deriving the correct answer and evaluating the given options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Observed counts in a $2 \\times 2$ contingency table: $O=\\begin{pmatrix}1&9\\\\8&2\\end{pmatrix}$.\n-   Fixed row margins: $(10, 10)$.\n-   Grand total: $20$.\n-   Null hypothesis: Independence in a design with fixed margins.\n-   Underlying distribution for conditional inference: The conditional distribution of the cell count in the first row and first column is determined by combinatorial allocation.\n-   Task: Identify the option correctly calculating the two-sided Fisher exact $p$-value and Pearson's chi-squared $p$-value, contrasting them with a discussion on assumptions and limitations.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically and mathematically sound. It describes a standard statistical scenario: the analysis of a $2 \\times 2$ contingency table using two fundamental methods, Fisher's exact test and Pearson's chi-squared test. The premise that under fixed margins the relevant null distribution for the cell counts is hypergeometric is a cornerstone of conditional inference (specifically, Fisher's exact test). The request to compare this with the large-sample chi-squared approximation is a canonical textbook problem. The problem is well-posed, providing all necessary data ($O$ and the margin constraints) to perform the calculations. The language is objective and precise. The problem is free of any of the invalidating flaws listed in the instructions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. I will proceed with a full derivation and evaluation of the options.\n\n### Derivation\n\nThe problem requires the calculation and comparison of two-sided $p$-values from Fisher's exact test and Pearson's chi-squared test for the given $2 \\times 2$ table.\n\n**1. Fisher's Exact Test**\n\nFirst, we complete the table with all margins.\nThe observed table is:\n$$\nO = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = \\begin{pmatrix} 1 & 9 \\\\ 8 & 2 \\end{pmatrix}\n$$\nThe row sums (margins) are $R_1 = 1+9 = 10$ and $R_2 = 8+2 = 10$. These are given as fixed.\nThe column sums (margins) are $C_1 = 1+8 = 9$ and $C_2 = 9+2 = 11$.\nThe grand total is $N = 10+10 = 20$.\n\nFisher's exact test conditions on all margins being fixed. Under the null hypothesis of no association between the row and column variables, the probability of observing a particular table with cell count $a$ in the top-left corner is given by the hypergeometric distribution:\n$$\nP(X=a) = \\frac{\\binom{R_1}{a}\\binom{R_2}{C_1-a}}{\\binom{N}{C_1}}\n$$\nHere, $X$ is the random variable for the count in cell $(1,1)$. With our margins, $R_1=10$, $R_2=10$, $C_1=9$, and $N=20$, the formula becomes:\n$$\nP(X=a) = \\frac{\\binom{10}{a}\\binom{10}{9-a}}{\\binom{20}{9}}\n$$\nThe denominator is $\\binom{20}{9} = \\frac{20!}{9!11!} = 167960$.\nThe possible values for $a$ are constrained by the margins: $a$ must be an integer such that $0 \\le a \\le R_1=10$ and $0 \\le C_1-a \\le R_2=10$, which implies $0 \\le a \\le 10$ and $-1 \\le a \\le 9$. Combining these, $a \\in \\{0, 1, ..., 9\\}$.\n\nThe observed value is $a_{obs} = 1$. The probability of this observation is:\n$$\nP(X=1) = \\frac{\\binom{10}{1}\\binom{10}{8}}{\\binom{20}{9}} = \\frac{10 \\times 45}{167960} = \\frac{450}{167960} \\approx 0.0026792\n$$\nThe two-sided $p$-value is the sum of probabilities of all tables that are as extreme or more extreme than the observed table. \"Extremity\" is measured by the probability of the table under the null hypothesis. We sum all $P(X=a)$ such that $P(X=a) \\le P(X=1)$. Due to the symmetry of the hypergeometric distribution when row or column margins are equal (here $R_1=R_2=10$), we know $P(X=a) = P(X=C_1-E[X]+(E[X]-a))$, where $E[X] = R_1C_1/N = 10 \\times 9 / 20 = 4.5$. This symmetry implies $P(X=a) = P(X=9-a)$.\nLet's list the probabilities:\n- $P(X=0) = \\frac{\\binom{10}{0}\\binom{10}{9}}{167960} = \\frac{1 \\times 10}{167960} \\approx 0.0000595$\n- $P(X=1) = \\frac{450}{167960} \\approx 0.0026792$\n- $P(X=2) = \\frac{\\binom{10}{2}\\binom{10}{7}}{167960} = \\frac{45 \\times 120}{167960} = \\frac{5400}{167960} \\approx 0.0321505$\n- $P(X=8) = P(X=9-1=8) = \\frac{\\binom{10}{8}\\binom{10}{1}}{167960} = \\frac{45 \\times 10}{167960} = P(X=1) \\approx 0.0026792$\n- $P(X=9) = P(X=9-0=9) = \\frac{\\binom{10}{9}\\binom{10}{0}}{167960} = \\frac{10 \\times 1}{167960} = P(X=0) \\approx 0.0000595$\n\nThe tables with probability less than or equal to $P(X=1)$ are those with $X \\in \\{0, 1, 8, 9\\}$.\nThe two-sided Fisher exact $p$-value is:\n$$\np_{Fisher} = P(X=0) + P(X=1) + P(X=8) + P(X=9)\n$$\n$$\np_{Fisher} = \\frac{10}{167960} + \\frac{450}{167960} + \\frac{450}{167960} + \\frac{10}{167960} = \\frac{920}{167960} \\approx 0.00547749\n$$\nRounding to three significant figures, $p_{Fisher} \\approx 0.00548$.\n\n**2. Pearson's Chi-squared Test**\n\nFirst, we calculate the expected counts, $E_{ij} = \\frac{R_i C_j}{N}$.\n- $E_{11} = \\frac{10 \\times 9}{20} = 4.5$\n- $E_{12} = \\frac{10 \\times 11}{20} = 5.5$\n- $E_{21} = \\frac{10 \\times 9}{20} = 4.5$\n- $E_{22} = \\frac{10 \\times 11}{20} = 5.5$\nThe table of expected counts is $E = \\begin{pmatrix} 4.5 & 5.5 \\\\ 4.5 & 5.5 \\end{pmatrix}$.\n\nThe Pearson chi-squared statistic (without continuity correction) is:\n$$\n\\chi^2 = \\sum_{i,j} \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n$$\n$$\n\\chi^2 = \\frac{(1 - 4.5)^2}{4.5} + \\frac{(9 - 5.5)^2}{5.5} + \\frac{(8 - 4.5)^2}{4.5} + \\frac{(2 - 5.5)^2}{5.5}\n$$\n$$\n\\chi^2 = \\frac{(-3.5)^2}{4.5} + \\frac{(3.5)^2}{5.5} + \\frac{(3.5)^2}{4.5} + \\frac{(-3.5)^2}{5.5} = 2 \\left( \\frac{12.25}{4.5} + \\frac{12.25}{5.5} \\right)\n$$\n$$\n\\chi^2 = 2 \\times 12.25 \\left( \\frac{1}{4.5} + \\frac{1}{5.5} \\right) = 24.5 \\left( \\frac{2}{9} + \\frac{2}{11} \\right) = 24.5 \\left( \\frac{22+18}{99} \\right) = 24.5 \\left( \\frac{40}{99} \\right) = \\frac{980}{99}\n$$\n$$\n\\chi^2 \\approx 9.8989...\n$$\nRounding to two decimal places, $\\chi^2 \\approx 9.90$.\n\nThis statistic is compared to a chi-squared distribution with $(R-1)(C-1) = (2-1)(2-1) = 1$ degree of freedom.\nThe $p$-value is $P(\\chi^2_1 \\ge 9.8989...)$. Using a statistical calculator, this $p$-value is approximately $0.001653$.\nRounding to four decimal places, $p_{\\chi^2} \\approx 0.0017$.\n\n**3. Discussion of Assumptions**\n\nThe chi-squared test is an approximation that relies on the Central Limit Theorem and is valid for large samples. A common rule of thumb (Cochran's rule) requires all expected cell counts to be $5$ or greater. In this problem, two of the four expected counts are $4.5$, which is less than $5$. This violation suggests the chi-squared approximation might be inaccurate.\n\nComparing the $p$-values: $p_{Fisher} \\approx 0.00548$ and $p_{\\chi^2} \\approx 0.0017$.\nThe chi-squared $p$-value is substantially smaller than the exact $p$-value. This implies that the chi-squared test overstates the statistical significance (i.e., it is anti-conservative or liberal). In a medical context, an anti-conservative test could lead to a false positive conclusion, for instance, declaring an ineffective treatment as effective, which carries significant risks. Fisher's exact test, which does not rely on large-sample approximations, provides the correct inference for any sample size and is therefore preferred when its assumptions (fixed margins) are met and expected counts are low.\n\n### Option-by-Option Analysis\n\n**A. Conditioning on the fixed margins $(10,10)$ and column totals $(9,11)$, the exact null distribution of the first cell $X$ is hypergeometric, and the two-sided Fisher $p$-value is obtained by summing the probabilities of all tables that are at least as unlikely as the observed table (here, those with $X \\in \\{0,1,8,9\\}$), yielding approximately $0.00548$. Pearson’s chi-squared statistic without continuity correction is approximately $9.90$ with $1$ degree of freedom, giving $p \\approx 0.0017$. Because two expected counts are less than $5$, the chi-squared approximation may be anticonservative, highlighting a limitation in this medical context.**\n\n-   **Analysis**: This statement correctly identifies the hypergeometric distribution as the basis for Fisher's test. It correctly describes the method for calculating the two-sided $p$-value and correctly identifies the set of more extreme tables ($X \\in \\{0,1,8,9\\}$). The calculated Fisher $p$-value of $\\approx 0.00548$ matches our derivation. It correctly calculates the Pearson $\\chi^2$ statistic as $\\approx 9.90$ and its corresponding $p$-value as $\\approx 0.0017$. Finally, it correctly notes that two expected counts are less than $5$ and correctly concludes that the chi-squared test is anti-conservative in this case, which is a key limitation. Every part of this option is accurate.\n-   **Verdict**: Correct.\n\n**B. The exact two-sided $p$-value is approximately $0.032$, obtained by summing all tables with $X \\le 2$ and $X \\ge 8$, and Pearson’s $p$-value is also approximately $0.032$, so the chi-squared test remains valid even when several expected counts are below $5$.**\n\n-   **Analysis**: The claimed exact $p$-value of $\\approx 0.032$ is incorrect; our calculation yielded $\\approx 0.00548$. The method described for its calculation (\"summing all tables with $X \\le 2$ and $X \\ge 8$\") is nonsensical for an observation of $X=1$. The claimed Pearson's $p$-value is also incorrect; our calculation gave $\\approx 0.0017$. The conclusion that the chi-squared test is valid is false; the significant discrepancy between the exact and approximate $p$-values proves it is not.\n-   **Verdict**: Incorrect.\n\n**C. Fisher’s exact test conditions only on the grand total $N=20$, not on the margins, so the exact two-sided $p$-value equals the Pearson chi-squared $p$-value and is approximately $0.0017$ with $1$ degree of freedom.**\n\n-   **Analysis**: This option makes a fundamental error regarding the conditioning of Fisher's exact test. The test is defined by conditioning on *both* row and column margins, not just the grand total. The consequence of this incorrect premise, that the exact and chi-squared $p$-values are equal, is also false. Our calculations show $p_{Fisher} \\approx 0.00548$ and $p_{\\chi^2} \\approx 0.0017$.\n-   **Verdict**: Incorrect.\n\n**D. A proper contrast is that Fisher’s two-sided $p$-value must be approximated by Monte Carlo simulation in $2 \\times 2$ tables with fixed margins because exact enumeration is intractable; the exact value is much larger (around $0.07$) than Pearson’s $p$-value in this case.**\n\n-   **Analysis**: The claim that exact enumeration is intractable for a $2 \\times 2$ table with $N=20$ is false. As demonstrated, the calculation is straightforward. Monte Carlo methods are for larger, more complex tables. The claimed exact $p$-value of $\\approx 0.07$ is also incorrect; the correct value is $\\approx 0.00548$.\n-   **Verdict**: Incorrect.", "answer": "$$\\boxed{A}$$", "id": "4776999"}, {"introduction": "Fixing a violated assumption is often a balancing act with inherent trade-offs. While collapsing categories can rescue a chi-squared analysis, it doesn't come for free; information is lost, and statistical properties of the test are altered. This advanced exercise guides you to explore the nuanced consequences of collapsing, specifically how it affects the test's degrees of freedom and a crucial measure of effect size, Cramér's $V$, revealing how this common fix can surprisingly alter the apparent strength of an association [@problem_id:4895176].", "problem": "A clinical genetics study cross-classifies patients by host genotype risk quartile ($4$ levels: $Q_{1}$, $Q_{2}$, $Q_{3}$, $Q_{4}$) and by infection severity ($3$ ordered categories: Mild, Moderate, Severe). The study design yields a single cross-sectional sample in which each patient contributes exactly one observation, and sampling is independent across patients. Investigators seek to apply the large-sample Pearson’s chi-squared test for independence, which presumes that categorical cell counts arise from independent sampling and that expected cell counts are not too small.\n\nThe observed counts are organized by genotype risk quartile (rows $Q_{1}$–$Q_{4}$) across severity (columns Mild, Moderate, Severe) as follows:\n- $Q_{1}$: $(40,\\ 8,\\ 2)$\n- $Q_{2}$: $(30,\\ 12,\\ 3)$\n- $Q_{3}$: $(20,\\ 6,\\ 4)$\n- $Q_{4}$: $(10,\\ 4,\\ 1)$\n\nThe investigators note that several expected counts under independence will be small. To address this assumption while retaining scientific interpretability, they propose collapsing the Moderate and Severe categories into a single “Moderate/Severe” category, leaving two severity levels (Mild vs. Moderate/Severe). The collapsed observed counts across severity are then:\n- $Q_{1}$: $(40,\\ 10)$\n- $Q_{2}$: $(30,\\ 15)$\n- $Q_{3}$: $(20,\\ 10)$\n- $Q_{4}$: $(10,\\ 5)$\n\nStarting from core definitions for contingency tables under the independence model and the large-sample Pearson’s chi-squared framework, derive how collapsing affects the degrees of freedom and the effect size measured by Cramér’s $V$, including verification of the expected-cell-count condition before and after collapsing. Then, using the given data, compute the ratio of the collapsed-table Cramér’s $V$ to the original-table Cramér’s $V$.\n\nRound your final numeric answer to four significant figures. Express the ratio as a decimal with no units.", "solution": "The problem requires an analysis of a contingency table, evaluating the statistical assumptions of a Pearson's chi-squared test, and understanding how collapsing categories affects the test's properties, specifically its degrees of freedom and the associated effect size, Cramér's $V$. The final objective is to compute the ratio of Cramér's $V$ for a collapsed table to that of the original table.\n\nFirst, we define the necessary statistical concepts. A contingency table cross-classifies data on two categorical variables. Let the number of rows be $r$ and the number of columns be $c$. The observed count in the cell at row $i$ and column $j$ is denoted by $O_{ij}$. The row totals are $R_i = \\sum_{j=1}^c O_{ij}$, the column totals are $C_j = \\sum_{i=1}^r O_{ij}$, and the grand total is $N = \\sum_{i=1}^r R_i = \\sum_{j=1}^c C_j$.\n\nThe Pearson's chi-squared test for independence tests the null hypothesis that the row and column variables are independent. Under this hypothesis, the expected count for cell $(i, j)$ is given by $E_{ij} = \\frac{R_i C_j}{N}$. The chi-squared statistic is calculated as $\\chi^2 = \\sum_{i=1}^r \\sum_{j=1}^c \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$. This statistic follows, for large $N$, a chi-squared distribution with degrees of freedom $df = (r-1)(c-1)$. A key assumption is that the expected counts $E_{ij}$ are not too small. A common rule of thumb is that all $E_{ij} \\ge 5$, or that no more than $20\\%$ of cells have $E_{ij} < 5$ and no cell has $E_{ij} < 1$.\n\nCramér's $V$ is a measure of the strength of association between the two categorical variables, ranging from $0$ (no association) to $1$ (perfect association). It is defined as $V = \\sqrt{\\frac{\\chi^2}{N \\cdot \\min(r-1, c-1)}}$.\n\nWe will now analyze the original and collapsed tables in sequence.\n\n**Analysis of the Original $4 \\times 3$ Table**\n\nThe original table has $r=4$ rows (Genotype Quartiles) and $c=3$ columns (Severity).\nThe observed counts $O_{ij}$ are:\n$$\n\\begin{pmatrix}\n40 & 8 & 2 \\\\\n30 & 12 & 3 \\\\\n20 & 6 & 4 \\\\\n10 & 4 & 1\n\\end{pmatrix}\n$$\nThe row totals are $R_1=50$, $R_2=45$, $R_3=30$, $R_4=15$.\nThe column totals are $C_1=100$, $C_2=30$, $C_3=10$.\nThe grand total is $N = 50+45+30+15 = 140$.\n\nThe expected counts $E_{ij} = \\frac{R_i C_j}{N}$ are:\n$$\nE = \\begin{pmatrix}\n\\frac{50 \\cdot 100}{140} & \\frac{50 \\cdot 30}{140} & \\frac{50 \\cdot 10}{140} \\\\\n\\frac{45 \\cdot 100}{140} & \\frac{45 \\cdot 30}{140} & \\frac{45 \\cdot 10}{140} \\\\\n\\frac{30 \\cdot 100}{140} & \\frac{30 \\cdot 30}{140} & \\frac{30 \\cdot 10}{140} \\\\\n\\frac{15 \\cdot 100}{140} & \\frac{15 \\cdot 30}{140} & \\frac{15 \\cdot 10}{140}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{250}{7} & \\frac{75}{7} & \\frac{25}{7} \\\\\n\\frac{225}{7} & \\frac{135}{14} & \\frac{45}{14} \\\\\n\\frac{150}{7} & \\frac{45}{7} & \\frac{15}{7} \\\\\n\\frac{75}{7} & \\frac{45}{14} & \\frac{15}{14}\n\\end{pmatrix}\n\\approx\n\\begin{pmatrix}\n35.71 & 10.71 & 3.57 \\\\\n32.14 & 9.64 & 3.21 \\\\\n21.43 & 6.43 & 2.14 \\\\\n10.71 & 3.21 & 1.07\n\\end{pmatrix}\n$$\nThe investigators' concern is justified: $5$ of the $12$ cells ($41.7\\%$) have expected counts below $5$. Specifically, $E_{13}$, $E_{23}$, $E_{33}$, $E_{42}$, and $E_{43}$ are all less than $5$. One cell, $E_{43}$, has an expected count of approximately $1.07$, which is very low and violates the large-sample assumption.\n\nThe chi-squared statistic $\\chi^2_{orig}$ is the sum of the terms $\\frac{(O_{ij} - E_{ij})^2}{E_{ij}}$:\n$\\chi^2_{orig} = \\frac{(40 - 250/7)^2}{250/7} + \\frac{(8 - 75/7)^2}{75/7} + \\dots + \\frac{(1 - 15/14)^2}{15/14} \\approx 4.6044$.\nThe degrees of freedom are $df_{orig} = (r-1)(c-1) = (4-1)(3-1) = 3 \\times 2 = 6$.\nCramér's $V$ for the original table is:\n$$V_{orig} = \\sqrt{\\frac{\\chi^2_{orig}}{N \\cdot \\min(r-1, c-1)}} = \\sqrt{\\frac{4.6044}{140 \\cdot \\min(3, 2)}} = \\sqrt{\\frac{4.6044}{140 \\cdot 2}} = \\sqrt{\\frac{4.6044}{280}}$$\n\n**Analysis of the Collapsed $4 \\times 2$ Table**\n\nThe Moderate and Severe categories are collapsed. The new table has $r'=4$ rows and $c'=2$ columns (Mild vs. Moderate/Severe).\nThe observed counts $O'_{ij}$ are:\n$$\n\\begin{pmatrix}\n40 & 10 \\\\\n30 & 15 \\\\\n20 & 10 \\\\\n10 & 5\n\\end{pmatrix}\n$$\nThe row totals $R'_i$ and grand total $N$ are unchanged. The new column totals are $C'_1 = 100$ and $C'_2 = 30+10 = 40$.\nThe new expected counts $E'_{ij} = \\frac{R'_i C'_j}{N}$ are:\n$$\nE' = \\begin{pmatrix}\n\\frac{50 \\cdot 100}{140} & \\frac{50 \\cdot 40}{140} \\\\\n\\frac{45 \\cdot 100}{140} & \\frac{45 \\cdot 40}{140} \\\\\n\\frac{30 \\cdot 100}{140} & \\frac{30 \\cdot 40}{140} \\\\\n\\frac{15 \\cdot 100}{140} & \\frac{15 \\cdot 40}{140}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{250}{7} & \\frac{100}{7} \\\\\n\\frac{225}{7} & \\frac{90}{7} \\\\\n\\frac{150}{7} & \\frac{60}{7} \\\\\n\\frac{75}{7} & \\frac{30}{7}\n\\end{pmatrix}\n\\approx\n\\begin{pmatrix}\n35.71 & 14.29 \\\\\n32.14 & 12.86 \\\\\n21.43 & 8.57 \\\\\n10.71 & 4.29\n\\end{pmatrix}\n$$\nAfter collapsing, only one cell out of $8$ ($12.5\\%$) has an expected count below $5$ ($E'_{42} \\approx 4.29$), and no cell has an expected count below $1$. This is a substantial improvement and makes the large-sample approximation more reliable.\n\nThe new chi-squared statistic, $\\chi^2_{coll}$, is:\n$\\chi^2_{coll} = \\frac{(40 - 250/7)^2}{250/7} + \\frac{(10 - 100/7)^2}{100/7} + \\dots + \\frac{(5 - 30/7)^2}{30/7} = 2.8$.\nAs expected, $\\chi^2_{coll} < \\chi^2_{orig}$ because information distinguishing between the 'Moderate' and 'Severe' categories has been discarded.\n\nThe degrees of freedom for the collapsed table are $df'_{coll} = (r'-1)(c'-1) = (4-1)(2-1) = 3 \\times 1 = 3$. Collapsing categories reduces the degrees of freedom. In general, collapsing $k$ columns into one reduces the degrees of freedom by $(r-1)(k-1)$. Here, $k=2$, so the reduction is $(4-1)(2-1)=3$.\n\nCramér's $V$ for the collapsed table is:\n$$V_{coll} = \\sqrt{\\frac{\\chi^2_{coll}}{N \\cdot \\min(r'-1, c'-1)}} = \\sqrt{\\frac{2.8}{140 \\cdot \\min(3, 1)}} = \\sqrt{\\frac{2.8}{140 \\cdot 1}} = \\sqrt{0.02} = \\sqrt{\\frac{1}{50}}$$\n\n**Derivation of Effect Change and Final Ratio Calculation**\n\nCollapsing categories affects Cramér's $V$ in two ways: it changes the numerator ($\\chi^2$) and can change the denominator term $\\min(r-1, c-1)$. In this case, $\\chi^2$ decreased from approximately $4.604$ to $2.8$. However, the term $\\min(r-1, c-1)$ in the denominator of $V^2$ decreased from $\\min(3, 2)=2$ to $\\min(3, 1)=1$. The net effect on $V$ depends on the relative magnitudes of these changes.\n\nWe now compute the ratio $\\frac{V_{coll}}{V_{orig}}$ using exact fractions for precision:\n$$\n\\frac{V_{coll}}{V_{orig}} = \\frac{\\sqrt{\\frac{2.8}{140}}}{\\sqrt{\\frac{4.6044}{280}}} = \\sqrt{\\frac{0.02}{4.6044 / 280}} = \\sqrt{\\frac{0.02 \\cdot 280}{4.6044}} = \\sqrt{\\frac{5.6}{4.6044}}\n$$\nUsing the exact fractions $\\chi^2_{orig} = 1036/225$ and $\\chi^2_{coll} = 14/5$:\n$$\nV_{orig} = \\sqrt{\\frac{1036/225}{140 \\cdot 2}} = \\sqrt{\\frac{1036}{63000}}\n$$\n$$\nV_{coll} = \\sqrt{\\frac{14/5}{140 \\cdot 1}} = \\sqrt{\\frac{14}{700}} = \\sqrt{\\frac{1}{50}}\n$$\nThe ratio is:\n$$\n\\frac{V_{coll}}{V_{orig}} = \\frac{\\sqrt{\\frac{1}{50}}}{\\sqrt{\\frac{1036}{63000}}} = \\sqrt{\\frac{1}{50} \\cdot \\frac{63000}{1036}} = \\sqrt{\\frac{1260}{1036}}\n$$\nTo simplify the fraction, we find common factors:\n$1260 = 4 \\cdot 315 = 4 \\cdot 7 \\cdot 45$\n$1036 = 4 \\cdot 259 = 4 \\cdot 7 \\cdot 37$\nSo, the ratio becomes:\n$$\n\\frac{V_{coll}}{V_{orig}} = \\sqrt{\\frac{4 \\cdot 7 \\cdot 45}{4 \\cdot 7 \\cdot 37}} = \\sqrt{\\frac{45}{37}}\n$$\nCalculating the numerical value:\n$$\n\\sqrt{\\frac{45}{37}} \\approx \\sqrt{1.216216...} \\approx 1.102822...\n$$\nRounding to four significant figures, the ratio is $1.103$. Despite the loss of information and a smaller $\\chi^2$ value, Cramér's $V$ increased because the reduction in the denominator term (related to degrees of freedom) was more substantial than the reduction in the $\\chi^2$ statistic. This illustrates that collapsing categories can sometimes concentrate the observed association into fewer degrees of freedom, potentially leading to a larger effect size measure like Cramér's $V$.", "answer": "$$\\boxed{1.103}$$", "id": "4895176"}]}