{"hands_on_practices": [{"introduction": "Mastering the two-sample t-test begins with understanding its core mechanics. This first exercise provides a practical scenario to build your foundational skills, guiding you through the calculation of the pooled two-sample $t$-statistic and its corresponding degrees of freedom [@problem_id:4963148]. By working through this problem, you will see how sample means, standard deviations, and sizes combine to create a single metric that quantifies the evidence against the null hypothesis, assuming the two groups share a common variance.", "problem": "A clinical research team is evaluating whether a new lifestyle intervention alters average fasting glucose compared with usual care. Two independent simple random samples are drawn from approximately normal populations with plausibly equal variances: a treatment group with size $n_1=22$ and a control group with size $n_2=18$. The observed sample means and sample standard deviations are $\\bar{X}=105.2$, $s_X=15.4$ for the treatment group and $\\bar{Y}=98.6$, $s_Y=12.1$ for the control group. Consider testing the null hypothesis $H_0:\\mu_1-\\mu_2=0$ using the equal-variance pooled two-sample approach appropriate for independent samples.\n\nStarting from first principles about sampling distributions of means and variances under independence and equal variances, compute the pooled two-sample $t$ statistic for $H_0:\\mu_1-\\mu_2=0$ and the corresponding degrees of freedom. Round the $t$ statistic to four significant figures and report the degrees of freedom as an exact integer. Provide your final answer as two numbers in the order $t$ statistic, degrees of freedom.", "solution": "The problem will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\nThe data and conditions provided in the problem statement are:\n-   Treatment group sample size: $n_1 = 22$\n-   Control group sample size: $n_2 = 18$\n-   Treatment group sample mean: $\\bar{X} = 105.2$\n-   Treatment group sample standard deviation: $s_X = 15.4$\n-   Control group sample mean: $\\bar{Y} = 98.6$\n-   Control group sample standard deviation: $s_Y = 12.1$\n-   Null Hypothesis: $H_0: \\mu_1 - \\mu_2 = 0$\n-   Assumptions: Two independent simple random samples, approximately normal populations, plausibly equal variances.\n-   Required Method: Equal-variance pooled two-sample approach.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established validation criteria.\n\n1.  **Scientifically Grounded:** The problem describes a standard scenario in biostatistics and clinical trials. The use of a two-sample t-test is a fundamental and widely accepted method for comparing the means of two independent groups. The assumptions of normality and equal variances are standard for applying this specific test. The problem is based on established statistical theory.\n2.  **Well-Posed:** The problem provides all necessary information (sample sizes, means, standard deviations) to calculate the requested statistics. The question is specific, asking for the value of the t-statistic and its degrees of freedom. A unique and meaningful solution exists.\n3.  **Objective:** The problem is stated in precise, quantitative, and unbiased language. There are no subjective claims or opinions.\n4.  **Complete and Consistent:** The data and conditions are internally consistent and sufficient for the task. No essential information is missing, and there are no contradictions.\n5.  **Relevant:** The problem is directly and explicitly about \"two-sample t tests for independent samples\" within the field of \"biostatistics\", as required.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is a standard, well-posed statistical calculation grounded in fundamental principles. A complete solution will be provided.\n\nThe task is to compute the pooled two-sample $t$ statistic and the corresponding degrees of freedom for testing the null hypothesis $H_0: \\mu_1 - \\mu_2 = 0$. The analysis will proceed from first principles as requested.\n\nThe general form for a test statistic is $\\frac{\\text{statistic} - \\text{hypothesized value}}{\\text{standard error of the statistic}}$. For the difference between two independent sample means, $\\bar{X}$ and $\\bar{Y}$, the sample statistic is $\\bar{X} - \\bar{Y}$. Under the null hypothesis $H_0: \\mu_1 - \\mu_2 = 0$, the hypothesized value of the difference is $0$. Thus, the $t$ statistic is given by:\n$$t = \\frac{(\\bar{X} - \\bar{Y}) - 0}{\\text{SE}(\\bar{X} - \\bar{Y})} = \\frac{\\bar{X} - \\bar{Y}}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\nwhere $\\text{SE}(\\bar{X} - \\bar{Y})$ is the standard error of the difference in means, which depends on the pooled standard deviation, $s_p$.\n\nThe derivation of the standard error begins with the variance of the difference between the two independent sample means. Due to independence, the variance of the difference is the sum of the variances:\n$$\\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y})$$\nFor a sample of size $n$ from a population with variance $\\sigma^2$, the variance of the sample mean is $\\frac{\\sigma^2}{n}$. Therefore:\n$$\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}$$\nThe problem specifies that we assume equal population variances, i.e., $\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$. The expression for the variance simplifies to:\n$$\\text{Var}(\\bar{X} - \\bar{Y}) = \\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2} = \\sigma^2 \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)$$\nSince the common population variance $\\sigma^2$ is unknown, it must be estimated from the sample data. The best estimator for $\\sigma^2$ is the pooled sample variance, $s_p^2$. It is a weighted average of the two sample variances, $s_X^2$ and $s_Y^2$, where the weights are the respective degrees of freedom, $n_1-1$ and $n_2-1$.\nThe formula for the pooled variance is:\n$$s_p^2 = \\frac{(n_1-1)s_X^2 + (n_2-1)s_Y^2}{(n_1-1) + (n_2-1)} = \\frac{(n_1-1)s_X^2 + (n_2-1)s_Y^2}{n_1 + n_2 - 2}$$\nThe denominator of this expression, $n_1 + n_2 - 2$, represents the total degrees of freedom ($df$) for the $t$ statistic.\n$$df = n_1 + n_2 - 2$$\nSubstituting the given values:\n$$df = 22 + 18 - 2 = 38$$\nThis is an exact integer value as required.\n\nNext, we calculate the pooled variance $s_p^2$ using the provided sample data:\n$n_1 = 22$, $s_X = 15.4 \\implies s_X^2 = (15.4)^2 = 237.16$\n$n_2 = 18$, $s_Y = 12.1 \\implies s_Y^2 = (12.1)^2 = 146.41$\n$$s_p^2 = \\frac{(22-1)(15.4)^2 + (18-1)(12.1)^2}{38} = \\frac{21 \\times 237.16 + 17 \\times 146.41}{38}$$\n$$s_p^2 = \\frac{4980.36 + 2488.97}{38} = \\frac{7469.33}{38} \\approx 196.5613158$$\nThe pooled standard deviation, $s_p$, is the square root of the pooled variance:\n$$s_p = \\sqrt{\\frac{7469.33}{38}} \\approx 14.02003266$$\nNow, we can calculate the standard error of the difference in means:\n$$\\text{SE}(\\bar{X} - \\bar{Y}) = s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}} = \\sqrt{\\frac{7469.33}{38}} \\sqrt{\\frac{1}{22} + \\frac{1}{18}}$$\n$$\\text{SE}(\\bar{X} - \\bar{Y}) = \\sqrt{\\frac{7469.33}{38} \\left(\\frac{1}{22} + \\frac{1}{18}\\right)} = \\sqrt{\\frac{7469.33}{38} \\left(\\frac{18 + 22}{22 \\times 18}\\right)} = \\sqrt{\\frac{7469.33}{38} \\left(\\frac{40}{396}\\right)}$$\n$$\\text{SE}(\\bar{X} - \\bar{Y}) = \\sqrt{\\frac{298773.2}{15048}} \\approx \\sqrt{19.854695} \\approx 4.4558607$$\nFinally, we compute the $t$ statistic. The difference in sample means is $\\bar{X} - \\bar{Y} = 105.2 - 98.6 = 6.6$.\n$$t = \\frac{\\bar{X} - \\bar{Y}}{\\text{SE}(\\bar{X} - \\bar{Y})} = \\frac{6.6}{4.4558607} \\approx 1.481193$$\nThe problem requires rounding the $t$ statistic to four significant figures.\n$$t \\approx 1.481$$\nThe computed values are the $t$ statistic, $1.481$, and the degrees of freedom, $38$.", "answer": "$$ \\boxed{ \\begin{pmatrix} 1.481  38 \\end{pmatrix} } $$", "id": "4963148"}, {"introduction": "A statistical test is only as reliable as its assumptions, and the independence of observations is one of the most critical for the two-sample t-test. This practice explores a common and subtle pitfall in experimental design: handling replicate measurements taken from the same subject [@problem_id:4963137]. By deriving the correct variance and comparing it to the naive approach, you will mathematically demonstrate how ignoring within-subject correlation leads to an underestimation of variance, an inflated test statistic, and an increased risk of false-positive conclusions.", "problem": "A clinical biostatistics team is evaluating a biomarker in two independent groups: a treated group ($j=1$) and a control group ($j=2$). Within each group, there are $n_{1}=28$ and $n_{2}=32$ subjects, respectively. For assay reliability, each subject is measured twice on the same day, producing two replicate measurements per subject. Let the two replicate measurements for subject $i$ in group $j$ be denoted $Y_{ij1}$ and $Y_{ij2}$.\n\nAssume the following scientifically standard stochastic structure:\n- Within a subject, the two replicates have identical variance, $\\operatorname{Var}(Y_{ij1})=\\operatorname{Var}(Y_{ij2})=\\sigma^{2}$, and positive within-subject correlation $\\rho$, so $\\operatorname{Cov}(Y_{ij1},Y_{ij2})=\\rho\\,\\sigma^{2}$ with $0\\rho1$.\n- Distinct subjects are independent, both within and across groups.\n- The two groups are independent samples.\n\nThe estimand is the difference in group means. The biostatistics team considers two analysis strategies:\n1. The correct strategy, which acknowledges the nonindependence of within-subject replicates by first averaging replicates within each subject and then comparing subject-level means across groups.\n2. A naive strategy, which incorrectly treats all $2n_{j}$ per-group replicate measurements as independent observations in a two-sample $t$ test, thereby doubling the nominal sample sizes.\n\nStarting from first principles of variance and covariance for sums of random variables and the definition of degrees of freedom (df) as the number of independent observational units minus the number of estimated mean parameters, do the following:\n- Derive the sampling variance of the difference in group means under the correct strategy, expressed in terms of $\\sigma^{2}$, $\\rho$, $n_{1}$, and $n_{2}$.\n- Derive the sampling variance of the difference in group means under the naive independence strategy, and demonstrate the multiplicative error induced by ignoring within-subject correlation.\n- Finally, compute the inflation in nominal degrees of freedom, defined as the naive df minus the correct df, for $n_{1}=28$ and $n_{2}=32$. Report only this inflation. No rounding is required.", "solution": "The problem is assessed to be valid as it is scientifically grounded in standard biostatistical models, is well-posed, and is presented using objective and precise language. All necessary information is provided for a unique solution.\n\nThe analysis proceeds by deriving the required quantities from first principles, as requested.\n\nLet $j=1$ denote the treated group and $j=2$ denote the control group, with respective sample sizes $n_{1}=28$ and $n_{2}=32$. For subject $i$ in group $j$, the two replicate measurements are $Y_{ij1}$ and $Y_{ij2}$.\nThe given variance-covariance structure is:\n$\\operatorname{Var}(Y_{ijk}) = \\sigma^{2}$ for $k \\in \\{1,2\\}$.\n$\\operatorname{Cov}(Y_{ij1}, Y_{ij2}) = \\rho\\sigma^{2}$, with $0  \\rho  1$.\nSubjects are independent, and the two groups are independent.\n\n**1. Sampling Variance of the Difference in Group Means (Correct Strategy)**\n\nThe correct strategy acknowledges the correlation between replicates by first averaging them for each subject. The subject-level mean for subject $i$ in group $j$ is:\n$$ \\bar{Y}_{ij} = \\frac{Y_{ij1} + Y_{ij2}}{2} $$\nThe variance of this subject-level mean is derived using the formula for the variance of a sum of random variables:\n$$ \\operatorname{Var}(\\bar{Y}_{ij}) = \\operatorname{Var}\\left(\\frac{1}{2}(Y_{ij1} + Y_{ij2})\\right) = \\frac{1}{4} \\operatorname{Var}(Y_{ij1} + Y_{ij2}) $$\n$$ \\operatorname{Var}(Y_{ij1} + Y_{ij2}) = \\operatorname{Var}(Y_{ij1}) + \\operatorname{Var}(Y_{ij2}) + 2\\operatorname{Cov}(Y_{ij1}, Y_{ij2}) $$\nSubstituting the given parameters:\n$$ \\operatorname{Var}(Y_{ij1} + Y_{ij2}) = \\sigma^{2} + \\sigma^{2} + 2\\rho\\sigma^{2} = 2\\sigma^{2}(1+\\rho) $$\nTherefore, the variance of the subject-level mean is:\n$$ \\operatorname{Var}(\\bar{Y}_{ij}) = \\frac{1}{4} [2\\sigma^{2}(1+\\rho)] = \\frac{\\sigma^{2}(1+\\rho)}{2} $$\nThe mean for group $j$, $\\bar{Y}_{j}$, is the average of these independent subject-level means:\n$$ \\bar{Y}_{j} = \\frac{1}{n_{j}} \\sum_{i=1}^{n_{j}} \\bar{Y}_{ij} $$\nBecause the subjects are independent, the variance of the group mean is:\n$$ \\operatorname{Var}(\\bar{Y}_{j}) = \\operatorname{Var}\\left(\\frac{1}{n_{j}} \\sum_{i=1}^{n_{j}} \\bar{Y}_{ij}\\right) = \\frac{1}{n_{j}^{2}} \\sum_{i=1}^{n_{j}} \\operatorname{Var}(\\bar{Y}_{ij}) = \\frac{1}{n_{j}^{2}} [n_{j} \\operatorname{Var}(\\bar{Y}_{ij})] = \\frac{\\operatorname{Var}(\\bar{Y}_{ij})}{n_{j}} $$\n$$ \\operatorname{Var}(\\bar{Y}_{j}) = \\frac{\\sigma^{2}(1+\\rho)}{2n_{j}} $$\nThe estimand is the difference in group means, $\\bar{Y}_{1} - \\bar{Y}_{2}$. Since the groups are independent, the variance of this difference is the sum of the variances of the group means:\n$$ \\operatorname{Var}_{\\text{correct}}(\\bar{Y}_{1} - \\bar{Y}_{2}) = \\operatorname{Var}(\\bar{Y}_{1}) + \\operatorname{Var}(\\bar{Y}_{2}) = \\frac{\\sigma^{2}(1+\\rho)}{2n_{1}} + \\frac{\\sigma^{2}(1+\\rho)}{2n_{2}} $$\n$$ \\operatorname{Var}_{\\text{correct}}(\\bar{Y}_{1} - \\bar{Y}_{2}) = \\frac{\\sigma^{2}(1+\\rho)}{2}\\left(\\frac{1}{n_{1}} + \\frac{1}{n_{2}}\\right) $$\n\n**2. Sampling Variance (Naive Strategy) and Multiplicative Error**\n\nThe naive strategy incorrectly assumes all $2n_{j}$ replicates in group $j$ are independent observations. The estimator for the group mean is the average of all these replicates:\n$$ \\bar{Y}'_{j} = \\frac{1}{2n_{j}} \\sum_{i=1}^{n_{j}} (Y_{ij1} + Y_{ij2}) $$\nThis is algebraically identical to the correct estimator, $\\bar{Y}_j$. The error is in the calculation of the variance. Under the false assumption of independence of all replicates, each with variance $\\sigma^{2}$, the sampling variance of the mean $\\bar{Y}'_{j}$ is calculated as:\n$$ \\operatorname{Var}_{\\text{naive-assumed}}(\\bar{Y}'_{j}) = \\frac{\\sigma^{2}}{2n_{j}} $$\nConsequently, the naively assumed sampling variance for the difference in group means is:\n$$ \\operatorname{Var}_{\\text{naive-assumed}}(\\bar{Y}'_{1} - \\bar{Y}'_{2}) = \\frac{\\sigma^{2}}{2n_{1}} + \\frac{\\sigma^{2}}{2n_{2}} = \\frac{\\sigma^{2}}{2}\\left(\\frac{1}{n_{1}} + \\frac{1}{n_{2}}\\right) $$\nThe multiplicative error induced by ignoring the correlation is the ratio of the true (correct) variance to the naively assumed variance:\n$$ \\text{Error Factor} = \\frac{\\operatorname{Var}_{\\text{correct}}(\\bar{Y}_{1} - \\bar{Y}_{2})}{\\operatorname{Var}_{\\text{naive-assumed}}(\\bar{Y}'_{1} - \\bar{Y}'_{2})} = \\frac{\\frac{\\sigma^{2}(1+\\rho)}{2}\\left(\\frac{1}{n_{1}} + \\frac{1}{n_{2}}\\right)}{\\frac{\\sigma^{2}}{2}\\left(\\frac{1}{n_{1}} + \\frac{1}{n_{2}}\\right)} = 1+\\rho $$\nThis demonstrates that the naive analysis underestimates the true variance by a factor of $1+\\rho$, which would artificially inflate the test statistic and the Type I error rate.\n\n**3. Inflation in Nominal Degrees of Freedom**\n\nThe degrees of freedom (df) are defined as the number of independent observational units minus the number of estimated mean parameters. In both strategies, we estimate $2$ mean parameters ($\\mu_{1}$ and $\\mu_{2}$).\n\n- **Correct Strategy**: The independent observational units are the subjects. The total number of subjects is $n_1 + n_2$.\n$$ df_{\\text{correct}} = (n_{1} + n_{2}) - 2 $$\nWith $n_{1}=28$ and $n_{2}=32$:\n$$ df_{\\text{correct}} = (28 + 32) - 2 = 60 - 2 = 58 $$\n\n- **Naive Strategy**: This approach incorrectly treats each replicate as an independent observational unit. The total number of (assumed) independent units is $2n_{1} + 2n_{2}$.\n$$ df_{\\text{naive}} = (2n_{1} + 2n_{2}) - 2 $$\nWith the given sample sizes:\n$$ df_{\\text{naive}} = (2 \\times 28 + 2 \\times 32) - 2 = (56 + 64) - 2 = 120 - 2 = 118 $$\n\nThe inflation in nominal degrees of freedom is the difference between the naive and correct df:\n$$ \\text{Inflation} = df_{\\text{naive}} - df_{\\text{correct}} $$\nSymbolically, the inflation is:\n$$ \\text{Inflation} = ((2n_{1} + 2n_{2}) - 2) - ((n_{1} + n_{2}) - 2) = n_{1} + n_{2} $$\nNumerically, the inflation is:\n$$ \\text{Inflation} = 118 - 58 = 60 $$\nThis result is consistent with the symbolic derivation, as $n_1 + n_2 = 28 + 32 = 60$.", "answer": "$$\\boxed{60}$$", "id": "4963137"}, {"introduction": "Beyond analyzing data you've already collected, a key skill for any researcher is planning studies that are both efficient and effective. This practice shifts our focus from analysis to design, tackling the crucial question of how many subjects are needed to detect a scientifically meaningful effect with high probability [@problem_id:4963135]. You will derive the optimal sample sizes for two groups with different variances, learning how to balance statistical power, effect size, and significance level to design a robust experiment from the ground up.", "problem": "A biostatistics research team is planning a randomized trial to compare the mean change in a continuous biomarker between a new treatment group and a control group using a two-sample $t$ test for independent samples. Prior data suggest that the outcome standard deviation in the treatment arm is $\\sigma_{1} = 12$ (in the same units as the biomarker) and in the control arm is $\\sigma_{2} = 8$. The team aims to detect a true mean difference of $\\Delta = 5$ units, using a two-sided test with type I error $\\alpha = 0.05$, and to achieve statistical power $0.9$. Assume independent samples, equal per-participant cost across arms, and that planning uses large-sample normal approximations justified by the Central Limit Theorem (CLT) and standard properties of sample means. Determine the arm-specific sample sizes $n_{1}$ and $n_{2}$ that achieve the target power while minimizing the total sample size, under an allocation that may differ between arms. Derive the result from first principles (beginning with the sampling distribution of the difference in sample means and the definition of statistical power for a two-sided test), and report the smallest integer values $n_{1}$ and $n_{2}$ that meet the design target. Express your final answer as the pair $\\left(n_{1}, n_{2}\\right)$ with no units.", "solution": "We begin with the two-sample setup: let $\\mu_{1}$ and $\\mu_{2}$ denote the population means in the treatment and control arms, respectively, with independent observations having standard deviations $\\sigma_{1}$ and $\\sigma_{2}$. The null hypothesis is $H_{0} : \\mu_{1} - \\mu_{2} = 0$, and the alternative hypothesis is $H_{1} : \\mu_{1} - \\mu_{2} = \\Delta$, where $\\Delta = 5$ is the target difference.\n\nBy the Central Limit Theorem (CLT) and standard properties of independent sample means, the difference of sample means\n$$\n\\bar{X}_{1} - \\bar{X}_{2}\n$$\nis approximately normally distributed with mean $(\\mu_{1} - \\mu_{2})$ and variance\n$$\n\\operatorname{Var}(\\bar{X}_{1} - \\bar{X}_{2}) = \\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}}.\n$$\nDefine the standard error\n$$\n\\text{SE} = \\sqrt{\\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}}}.\n$$\nUnder $H_{0}$, the standardized test statistic is approximately standard normal:\n$$\nZ_{0} = \\frac{(\\bar{X}_{1} - \\bar{X}_{2}) - 0}{\\text{SE}} \\approx \\mathcal{N}(0,1).\n$$\nA two-sided test at significance level $\\alpha$ rejects $H_{0}$ when $|Z_{0}|  z_{1 - \\alpha/2}$, where $z_{p}$ is the $p$-quantile of the standard normal distribution.\n\nPower is the probability of rejecting $H_{0}$ when $H_{1}$ is true. Under $H_{1}$ with $\\mu_{1} - \\mu_{2} = \\Delta$, the standardized statistic\n$$\nZ_{1} = \\frac{(\\bar{X}_{1} - \\bar{X}_{2}) - 0}{\\text{SE}}\n$$\nis approximately $\\mathcal{N}\\!\\left(\\frac{\\Delta}{\\text{SE}}, 1\\right)$. For a positive $\\Delta$, the two-sided power is\n$$\n\\Pr\\left(|Z_{1}|  z_{1 - \\alpha/2}\\right) = \\Pr\\left(Z_{1}  z_{1 - \\alpha/2}\\right) + \\Pr\\left(Z_{1}  -z_{1 - \\alpha/2}\\right).\n$$\nA standard and conservative design criterion equates the upper-tail event to the desired power level $1 - \\beta$:\n$$\n\\Pr\\left(Z_{1}  z_{1 - \\alpha/2}\\right) = 1 - \\beta,\n$$\nwhich, by normal shift, is satisfied when\n$$\n\\frac{\\Delta}{\\text{SE}} = z_{1 - \\alpha/2} + z_{1 - \\beta}.\n$$\nSolving for the standard error yields the design constraint\n$$\n\\text{SE} = \\frac{\\Delta}{z_{1 - \\alpha/2} + z_{1 - \\beta}},\n$$\nor, equivalently,\n$$\n\\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}} = \\left(\\frac{\\Delta}{z_{1 - \\alpha/2} + z_{1 - \\beta}}\\right)^{2}.\n$$\nLet\n$$\nC \\equiv \\left(\\frac{\\Delta}{z_{1 - \\alpha/2} + z_{1 - \\beta}}\\right)^{2}.\n$$\nWe seek to minimize the total sample size $n_{1} + n_{2}$ subject to the constraint\n$$\n\\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}} = C.\n$$\nUsing a Lagrange multiplier $\\lambda$,\n$$\n\\mathcal{L}(n_{1}, n_{2}, \\lambda) = n_{1} + n_{2} + \\lambda\\left(\\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}} - C\\right).\n$$\nSetting partial derivatives to zero:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_{1}} = 1 - \\lambda \\frac{\\sigma_{1}^{2}}{n_{1}^{2}} = 0 \\quad \\Rightarrow \\quad n_{1} = \\sqrt{\\lambda}\\,\\sigma_{1},\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_{2}} = 1 - \\lambda \\frac{\\sigma_{2}^{2}}{n_{2}^{2}} = 0 \\quad \\Rightarrow \\quad n_{2} = \\sqrt{\\lambda}\\,\\sigma_{2}.\n$$\nThus, the optimal allocation ratio that minimizes $n_{1}+n_{2}$ for fixed $C$ is\n$$\n\\frac{n_{1}}{n_{2}} = \\frac{\\sigma_{1}}{\\sigma_{2}}.\n$$\nImposing the constraint gives\n$$\n\\frac{\\sigma_{1}^{2}}{\\sqrt{\\lambda}\\,\\sigma_{1}} + \\frac{\\sigma_{2}^{2}}{\\sqrt{\\lambda}\\,\\sigma_{2}} = C\n\\quad \\Rightarrow \\quad\n\\frac{\\sigma_{1} + \\sigma_{2}}{\\sqrt{\\lambda}} = C\n\\quad \\Rightarrow \\quad\n\\sqrt{\\lambda} = \\frac{\\sigma_{1} + \\sigma_{2}}{C}.\n$$\nTherefore,\n$$\nn_{1} = \\sigma_{1}\\,\\frac{\\sigma_{1} + \\sigma_{2}}{C}\n\\quad \\text{and} \\quad\nn_{2} = \\sigma_{2}\\,\\frac{\\sigma_{1} + \\sigma_{2}}{C}.\n$$\nSubstituting $C$,\n$$\nn_{1} = \\sigma_{1}(\\sigma_{1} + \\sigma_{2})\\,\\frac{\\left(z_{1 - \\alpha/2} + z_{1 - \\beta}\\right)^{2}}{\\Delta^{2}},\n\\quad\nn_{2} = \\sigma_{2}(\\sigma_{1} + \\sigma_{2})\\,\\frac{\\left(z_{1 - \\alpha/2} + z_{1 - \\beta}\\right)^{2}}{\\Delta^{2}}.\n$$\n\nNow substitute the design parameters $\\alpha = 0.05$ (two-sided), $\\beta = 0.1$ (since the power is $0.9$), $\\Delta = 5$, $\\sigma_{1} = 12$, and $\\sigma_{2} = 8$. The required standard normal quantiles are $z_{1 - \\alpha/2} = z_{0.975} \\approx 1.959963984540054$ and $z_{1 - \\beta} = z_{0.9} \\approx 1.2815515655446004$, so\n$$\nz_{1 - \\alpha/2} + z_{1 - \\beta} \\approx 1.959963984540054 + 1.2815515655446004 \\approx 3.2415155500846544,\n$$\nand\n$$\n\\left(z_{1 - \\alpha/2} + z_{1 - \\beta}\\right)^{2} \\approx 3.2415155500846544^{2} \\approx 10.507423.\n$$\nCompute $n_{1}$ and $n_{2}$:\n$$\nn_{1} \\approx 12 \\times (12 + 8) \\times \\frac{10.507423}{5^{2}} = 12 \\times 20 \\times \\frac{10.507423}{25} \\approx 240 \\times 0.42029692 \\approx 100.87,\n$$\n$$\nn_{2} \\approx 8 \\times (12 + 8) \\times \\frac{10.507423}{5^{2}} = 8 \\times 20 \\times \\frac{10.507423}{25} \\approx 160 \\times 0.42029692 \\approx 67.25.\n$$\nTo ensure the design achieves at least the target power, we take the smallest integers not less than these values:\n$$\nn_{1} = 101, \\quad n_{2} = 68.\n$$\nA quick check of the resulting standard error confirms adequacy:\n$$\n\\text{SE}^{2} = \\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}} = \\frac{12^{2}}{101} + \\frac{8^{2}}{68} \\approx \\frac{144}{101} + \\frac{64}{68} \\approx 1.4257 + 0.9412 \\approx 2.3669,\n$$\nso\n$$\n\\frac{\\Delta}{\\text{SE}} \\approx \\frac{5}{\\sqrt{2.3669}} \\approx \\frac{5}{1.539} \\approx 3.249,\n$$\nwhich exceeds $z_{1 - \\alpha/2} + z_{1 - \\beta} \\approx 3.2415$, meeting the power requirement. Hence, the minimal integer sample sizes under the optimal allocation are $n_{1} = 101$ and $n_{2} = 68$.", "answer": "$$\\boxed{\\begin{pmatrix}101  68\\end{pmatrix}}$$", "id": "4963135"}]}