{"hands_on_practices": [{"introduction": "This first exercise grounds the theory in practice by having you calculate the Pearson correlation coefficient from first principles. By working step-by-step through a small, hypothetical medical dataset, you will compute the sample means, standard deviations, and covariance [@problem_id:4825168]. This process demystifies the formula for $r$ and builds a concrete understanding of how it quantifies the linear relationship between two variables.", "problem": "A pilot study in Evidence-Based Medicine (EBM) explores the linear association between baseline dietary sodium intake and 12-week change in systolic blood pressure among hypertensive adults. For each participant, the paired data $(x_i,y_i)$ consist of $x_i$ equal to grams of sodium consumed per day at baseline and $y_i$ equal to the follow-up change in systolic blood pressure in millimeters of mercury (a positive $y_i$ indicates an increase). The sample size is $n=5$ with observed pairs: $(2,3)$, $(4,5)$, $(6,4)$, $(8,9)$, $(10,11)$. \n\nUsing only foundational definitions appropriate to statistical inference, proceed from first principles to compute the following sample summaries for the sodium intake ($X$) and blood pressure change ($Y$): the sample means $\\bar{x}$ and $\\bar{y}$, the unbiased sample standard deviations $s_X$ and $s_Y$, the unbiased sample covariance $s_{XY}$, and the Pearson’s product-moment correlation coefficient $r$ interpreted as a standardized covariance. Provide a brief qualitative interpretation of the magnitude of $r$ in the context of EBM, acknowledging the small sample size. \n\nReport only the final value of $r$ to four significant figures. Do not round intermediate quantities more than is necessary for exact arithmetic; exact forms should be retained where possible. The final answer must be unitless and should be a single number.", "solution": "The problem requires the computation of several sample statistics from first principles for a set of $n=5$ paired observations $(x_i, y_i)$. The data are given as follows: $(2,3)$, $(4,5)$, $(6,4)$, $(8,9)$, $(10,11)$. Here, $x_i$ represents baseline dietary sodium intake in grams per day, and $y_i$ represents the change in systolic blood pressure in mmHg.\n\nFirst, we compute the sample means for $X$ and $Y$, denoted as $\\bar{x}$ and $\\bar{y}$.\nThe formula for the sample mean is $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$.\nFor the sodium intake data $X$:\n$$ \\sum_{i=1}^{5} x_i = 2 + 4 + 6 + 8 + 10 = 30 $$\n$$ \\bar{x} = \\frac{30}{5} = 6 $$\nFor the blood pressure change data $Y$:\n$$ \\sum_{i=1}^{5} y_i = 3 + 5 + 4 + 9 + 11 = 32 $$\n$$ \\bar{y} = \\frac{32}{5} = 6.4 $$\n\nNext, we calculate the unbiased sample standard deviations, $s_X$ and $s_Y$. This requires first computing the unbiased sample variances, $s_X^2$ and $s_Y^2$. The formula for unbiased sample variance is $s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (z_i - \\bar{z})^2$, where the term in the summation is the sum of squared deviations from the mean, often denoted $SS$.\n\nFor $X$, the sum of squared deviations, $SS_{xx}$, is:\n$$ SS_{xx} = \\sum_{i=1}^{5} (x_i - \\bar{x})^2 = (2-6)^2 + (4-6)^2 + (6-6)^2 + (8-6)^2 + (10-6)^2 $$\n$$ SS_{xx} = (-4)^2 + (-2)^2 + (0)^2 + (2)^2 + (4)^2 = 16 + 4 + 0 + 4 + 16 = 40 $$\nThe unbiased sample variance for $X$ is:\n$$ s_X^2 = \\frac{SS_{xx}}{n-1} = \\frac{40}{5-1} = \\frac{40}{4} = 10 $$\nThe unbiased sample standard deviation for $X$ is:\n$$ s_X = \\sqrt{s_X^2} = \\sqrt{10} $$\n\nFor $Y$, the sum of squared deviations, $SS_{yy}$, is:\n$$ SS_{yy} = \\sum_{i=1}^{5} (y_i - \\bar{y})^2 = (3-6.4)^2 + (5-6.4)^2 + (4-6.4)^2 + (9-6.4)^2 + (11-6.4)^2 $$\n$$ SS_{yy} = (-3.4)^2 + (-1.4)^2 + (-2.4)^2 + (2.6)^2 + (4.6)^2 = 11.56 + 1.96 + 5.76 + 6.76 + 21.16 = 47.2 $$\nThe unbiased sample variance for $Y$ is:\n$$ s_Y^2 = \\frac{SS_{yy}}{n-1} = \\frac{47.2}{5-1} = \\frac{47.2}{4} = 11.8 $$\nThe unbiased sample standard deviation for $Y$ is:\n$$ s_Y = \\sqrt{s_Y^2} = \\sqrt{11.8} $$\n\nNow, we compute the unbiased sample covariance, $s_{XY}$. The formula is $s_{XY} = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$. The summation term is the sum of the products of deviations, denoted $SS_{xy}$.\n$$ SS_{xy} = \\sum_{i=1}^{5} (x_i - \\bar{x})(y_i - \\bar{y}) $$\n$$ SS_{xy} = (2-6)(3-6.4) + (4-6)(5-6.4) + (6-6)(4-6.4) + (8-6)(9-6.4) + (10-6)(11-6.4) $$\n$$ SS_{xy} = (-4)(-3.4) + (-2)(-1.4) + (0)(-2.4) + (2)(2.6) + (4)(4.6) $$\n$$ SS_{xy} = 13.6 + 2.8 + 0 + 5.2 + 18.4 = 40 $$\nThe unbiased sample covariance is:\n$$ s_{XY} = \\frac{SS_{xy}}{n-1} = \\frac{40}{5-1} = \\frac{40}{4} = 10 $$\n\nFinally, we compute Pearson’s product-moment correlation coefficient, $r$. This is defined as the sample covariance standardized by the product of the sample standard deviations.\n$$ r = \\frac{s_{XY}}{s_X s_Y} $$\nSubstituting the values we calculated:\n$$ r = \\frac{10}{\\sqrt{10} \\sqrt{11.8}} = \\frac{\\sqrt{10}}{\\sqrt{11.8}} = \\sqrt{\\frac{10}{11.8}} = \\sqrt{\\frac{100}{118}} = \\sqrt{\\frac{50}{59}} $$\nTo obtain the final numerical value, we compute the square root and round to four significant figures:\n$$ r \\approx \\sqrt{0.8474576...} \\approx 0.9205746... $$\n$$ r \\approx 0.9206 $$\n\nThe qualitative interpretation of this result is as follows. A Pearson's correlation coefficient of $r \\approx 0.9206$ indicates a very strong positive linear relationship between baseline dietary sodium intake and the 12-week change in systolic blood pressure within this specific sample. As sodium intake increases, the change in systolic blood pressure also tends to increase in a highly linear fashion. However, in the context of EBM, this finding must be interpreted with extreme caution. The sample size of $n=5$ is exceptionally small for making any generalizable inferences. A strong correlation in such a small dataset could easily arise by chance, and the estimate of the population correlation is subject to a very large sampling error. Therefore, while suggestive, this pilot result is far from conclusive and would require validation in a much larger, well-designed study before any clinical relevance can be claimed.", "answer": "$$\\boxed{0.9206}$$", "id": "4825168"}, {"introduction": "The Pearson correlation coefficient is a powerful tool, but it is highly sensitive to outliers. This practice problem uses a deliberately constructed dataset with an extreme outlier to demonstrate how a single data point can drastically distort the resulting correlation [@problem_id:4825051]. By analyzing its disproportionate impact on the covariance and variance terms, you will learn a critical lesson: always visualize your data before drawing conclusions from a correlation coefficient.", "problem": "A translational medicine team investigates the association between a pro-inflammatory biomarker and a clinical severity score recorded on the same day in a small pilot cohort. For each individual, let $x$ denote the recorded biomarker value and $y$ denote the recorded clinical score. You are given $n=6$ observed pairs:\n$$(x,y)\\in\\{(1,5),(2,4),(3,3),(4,2),(5,1),(100,100)\\}.$$\nThe last pair is a suspected extreme outlier arising from a data handling error (for example, a misplaced unit conversion). Starting from the core definitions of sample mean, sample variance, sample covariance, and the Pearson product-moment correlation coefficient, derive the correlation from first principles by expressing it in terms of raw sums over the sample. Compute the sample Pearson correlation coefficient $r$ for all $6$ pairs and then, in your derivation, explicitly identify the terms corresponding to the cross-deviation (numerator) and the marginal sum-of-squares (denominator). Use these identified terms to explain how the single extreme outlier alters each component and thereby the value of $r$ in this medical data context. Round your final numerical answer for $r$ to $4$ significant figures.", "solution": "### Solution Derivation and Calculation\n\nThe Pearson product-moment correlation coefficient, $r$, is defined as the sample covariance of two variables divided by the product of their sample standard deviations.\n\nLet the two variables be $x$ and $y$, with a sample of $n$ pairs $(x_i, y_i)$.\nThe sample mean of $x$ is $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$.\nThe sample mean of $y$ is $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$.\n\nThe sample covariance is defined as $\\text{Cov}(x,y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$.\nThe sample variance of $x$ is $s_x^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$. The sample standard deviation is $s_x = \\sqrt{s_x^2}$.\nThe sample variance of $y$ is $s_y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{y})^2$. The sample standard deviation is $s_y = \\sqrt{s_y^2}$.\n\nThe Pearson correlation coefficient $r$ is given by:\n$$r = \\frac{\\text{Cov}(x,y)}{s_x s_y} = \\frac{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\nThe factor of $\\frac{1}{n-1}$ cancels from the numerator and denominator, yielding the expression in terms of sums of squares of deviations:\n$$r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$$\nThis is the required derivation from first principles.\n\nIn this formula:\n-   The numerator, $SS_{xy} = \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$, is the **sum of the cross-deviations**.\n-   The terms in the denominator's square root are the **marginal sums of squares**: $SS_{xx} = \\sum_{i=1}^{n} (x_i - \\bar{x})^2$ for $x$ and $SS_{yy} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$ for $y$.\n\nFor computational purposes, these sums can be expressed using raw sums, which avoids calculating each individual deviation:\n$SS_{xy} = \\sum x_i y_i - n\\bar{x}\\bar{y} = \\sum x_i y_i - \\frac{(\\sum x_i)(\\sum y_i)}{n}$\n$SS_{xx} = \\sum x_i^2 - n\\bar{x}^2 = \\sum x_i^2 - \\frac{(\\sum x_i)^2}{n}$\n$SS_{yy} = \\sum y_i^2 - n\\bar{y}^2 = \\sum y_i^2 - \\frac{(\\sum y_i)^2}{n}$\n\nThe data are: $n=6$, with pairs $(1,5), (2,4), (3,3), (4,2), (5,1), (100,100)$.\nFirst, we compute the necessary raw sums:\n$\\sum x_i = 1+2+3+4+5+100 = 115$\n$\\sum y_i = 5+4+3+2+1+100 = 115$\n$\\sum x_i^2 = 1^2+2^2+3^2+4^2+5^2+100^2 = 1+4+9+16+25+10000 = 10055$\n$\\sum y_i^2 = 5^2+4^2+3^2+2^2+1^2+100^2 = 25+16+9+4+1+10000 = 10055$\n$\\sum x_i y_i = (1)(5)+(2)(4)+(3)(3)+(4)(2)+(5)(1)+(100)(100) = 5+8+9+8+5+10000 = 10035$\n\nNow we compute the components $SS_{xy}$, $SS_{xx}$, and $SS_{yy}$:\n$SS_{xy} = 10035 - \\frac{(115)(115)}{6} = 10035 - \\frac{13225}{6} = \\frac{60210 - 13225}{6} = \\frac{46985}{6}$\n$SS_{xx} = 10055 - \\frac{(115)^2}{6} = 10055 - \\frac{13225}{6} = \\frac{60330 - 13225}{6} = \\frac{47105}{6}$\n$SS_{yy} = 10055 - \\frac{(115)^2}{6} = 10055 - \\frac{13225}{6} = \\frac{60330 - 13225}{6} = \\frac{47105}{6}$\n\nFinally, we compute $r$:\n$$r = \\frac{SS_{xy}}{\\sqrt{SS_{xx} SS_{yy}}} = \\frac{\\frac{46985}{6}}{\\sqrt{\\frac{47105}{6} \\cdot \\frac{47105}{6}}} = \\frac{\\frac{46985}{6}}{\\frac{47105}{6}} = \\frac{46985}{47105}$$\n$r \\approx 0.99745250...$\nRounding to $4$ significant figures, $r \\approx 0.9975$.\n\n### Explanation of the Outlier's Impact\n\nTo understand the outlier's influence, we first analyze the data without it. The first five pairs are $(1,5), (2,4), (3,3), (4,2), (5,1)$. For these $n'=5$ points:\n$\\sum x'_i = 1+2+3+4+5 = 15 \\implies \\bar{x}' = \\frac{15}{5} = 3$\n$\\sum y'_i = 5+4+3+2+1 = 15 \\implies \\bar{y}' = \\frac{15}{5} = 3$\n$SS'_{xy} = \\sum(x'_i - \\bar{x}')(y'_i - \\bar{y}') = (1-3)(5-3) + (2-3)(4-3) + (3-3)(3-3) + (4-3)(2-3) + (5-3)(1-3) = (-2)(2) + (-1)(1) + (0)(0) + (1)(-1) + (2)(-2) = -4 - 1 + 0 - 1 - 4 = -10$\n$SS'_{xx} = \\sum(x'_i - \\bar{x}')^2 = (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 = 4+1+0+1+4 = 10$\n$SS'_{yy} = \\sum(y'_i - \\bar{y}')^2 = (2)^2 + (1)^2 + 0^2 + (-1)^2 + (-2)^2 = 4+1+0+1+4 = 10$\nThe correlation for these five points is $r' = \\frac{-10}{\\sqrt{10 \\cdot 10}} = -1$.\nThis indicates a perfect negative linear relationship. These points lie on the line $y = 6 - x$.\n\nNow, we introduce the outlier $(100,100)$ and analyze its effect on the sums that determine the overall correlation. The new means are $\\bar{x} = \\frac{115}{6} \\approx 19.17$ and $\\bar{y} = \\frac{115}{6} \\approx 19.17$. The center of the data cloud is violently pulled from $(3,3)$ towards the outlier.\n\nLet's examine the contribution of the single outlier $(x_6, y_6) = (100, 100)$ to the sums of squares for the full dataset ($n=6$):\n1.  **Marginal Sum-of-Squares ($SS_{xx}$ and $SS_{yy}$)**: The outlier's contribution to $SS_{xx}$ is $(x_6 - \\bar{x})^2 = (100 - \\frac{115}{6})^2 = (\\frac{485}{6})^2 = \\frac{235225}{36} \\approx 6534.03$. The sum of contributions from the first five points is $\\sum_{i=1}^{5}(x_i - \\bar{x})^2 \\approx 1316.81$. The outlier's squared deviation in $x$ is thus $\\frac{6534.03}{1316.81} \\approx 4.96$ times larger than the sum of all other points' squared deviations. The same applies to $SS_{yy}$ due to the symmetry of the data. This single point enormously inflates the perceived variance in both $x$ and $y$.\n\n2.  **Cross-Deviation Sum ($SS_{xy}$)**: The outlier's contribution is $(x_6 - \\bar{x})(y_6 - \\bar{y}) = (100 - \\frac{115}{6})(100 - \\frac{115}{6}) = (\\frac{485}{6})^2 = \\frac{235225}{36} \\approx 6534.03$. The sum of contributions from the first five points is $\\sum_{i=1}^{5}(x_i - \\bar{x})(y_i - \\bar{y}) \\approx 1296.81$. The outlier's cross-product term is $\\frac{6534.03}{1296.81} \\approx 5.04$ times larger than the sum from all other points.\n\n**Conclusion**: The outlier $(100,100)$ has an extremely high-leverage effect. Because it is distant from the means $(\\bar{x}, \\bar{y})$, its individual contributions to the sums of squares ($SS_{xx}, SS_{yy}$) and the sum of cross-deviations ($SS_{xy}$) are immense. These single-point contributions dominate the sums, swamping the collective contribution from the other five points. The initial strong negative correlation ($r = -1$) was determined by the negative sum of cross-deviations ($SS'_{xy} = -10$) from the first five points. The outlier adds a massive positive value to this sum, flipping its sign and making it large and positive ($SS_{xy} \\approx 7830.83$). Simultaneously, it massively inflates the denominator terms $SS_{xx}$ and $SS_{yy}$. Because the outlier lies on the line $y=x$, its contribution to $SS_{xy}$ is nearly identical to its contributions to $SS_{xx}$ and $SS_{yy}$. This forces the ratio $\\frac{SS_{xy}}{\\sqrt{SS_{xx}SS_{yy}}}$ to be very close to $+1$, completely reversing and masking the underlying relationship in the bulk of the data. This demonstrates the profound sensitivity of Pearson's $r$ to single extreme outliers, a critical property to consider in any scientific data analysis.", "answer": "$$\\boxed{0.9975}$$", "id": "4825051"}, {"introduction": "A common pitfall is to interpret a low Pearson correlation as a lack of any relationship. This exercise is designed to correct that misconception by exploring a dataset with a perfect, yet nonlinear, monotonic association [@problem_id:4825067]. By calculating and comparing Pearson's $r$ with rank-based alternatives like Spearman's $\\rho_S$ and Kendall's $\\tau$, you will discover why $r$ specifically measures *linear* strength and how other tools can better capture monotonic trends.", "problem": "A clinical methods team is evaluating how different correlation measures reflect association strength in the presence of monotonic but nonlinear relationships. In a pilot design study, they purposely select $7$ participants so that a standardized exposure score $x$ spans symmetrically from low to high values. The laboratory then applies a strictly increasing cubic calibration $g(u) = u^{3}$ to the exposure score to form a derived biomarker $y = g(x)$. The observed data are the $7$ pairs\n$(x_{i}, y_{i}) \\in \\{(-3,-27),\\,(-2,-8),\\,(-1,-1),\\,(0,0),\\,(1,1),\\,(2,8),\\,(3,27)\\}$,\nwhich exhibit a monotonic but nonlinear association.\n\nStarting only from the core definitions of sample covariance, sample standard deviation, Pearson’s product-moment correlation coefficient, Spearman’s rank correlation coefficient, and Kendall’s tau rank correlation coefficient (no prepackaged shortcut formulas), compute the following three quantities for these data:\n- Pearson’s product-moment correlation coefficient $r$ between $x$ and $y$,\n- Spearman’s rank correlation coefficient $\\rho_{S}$ between $x$ and $y$,\n- Kendall’s tau rank correlation coefficient $\\tau$ between $x$ and $y$.\n\nExplain why, in this monotonic but nonlinear setting, $r$ can underestimate association strength relative to $\\rho_{S}$ and $\\tau$. Report your three coefficients rounded to four significant figures.", "solution": "The problem requires the computation of three correlation coefficients for the given dataset:\n$D = \\{(-3,-27),\\,(-2,-8),\\,(-1,-1),\\,(0,0),\\,(1,1),\\,(2,8),\\,(3,27)\\}$.\nThe sample size is $n=7$. Let the two variables be denoted by $x$ and $y$.\n\nFirst, we compute the sample means, $\\bar{x}$ and $\\bar{y}$.\nThe values for $x$ are $\\{-3, -2, -1, 0, 1, 2, 3\\}$.\n$$ \\sum_{i=1}^{7} x_i = -3 - 2 - 1 + 0 + 1 + 2 + 3 = 0 $$\nThus, the sample mean of $x$ is $\\bar{x} = \\frac{1}{7} \\sum_{i=1}^{7} x_i = \\frac{0}{7} = 0$.\n\nThe values for $y$ are $\\{-27, -8, -1, 0, 1, 8, 27\\}$.\n$$ \\sum_{i=1}^{7} y_i = -27 - 8 - 1 + 0 + 1 + 8 + 27 = 0 $$\nThus, the sample mean of $y$ is $\\bar{y} = \\frac{1}{7} \\sum_{i=1}^{7} y_i = \\frac{0}{7} = 0$.\n\nHaving $\\bar{x}=0$ and $\\bar{y}=0$ simplifies the calculations for the correlation coefficients.\n\n**1. Pearson’s Product-Moment Correlation Coefficient ($r$)**\n\nThe core definition of Pearson's correlation coefficient $r$ is the sample covariance of $x$ and $y$ divided by the product of their sample standard deviations.\n$$ r = \\frac{\\text{Cov}(x,y)}{s_x s_y} $$\nThe sample covariance is defined as $\\text{Cov}(x,y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})$.\nThe sample variances are $s_x^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2$ and $s_y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{y})^2$.\n\nSince $\\bar{x}=0$ and $\\bar{y}=0$, the formulas become:\n$$ \\text{Cov}(x,y) = \\frac{1}{n-1} \\sum_{i=1}^{n} x_i y_i $$\n$$ s_x^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} x_i^2 $$\n$$ s_y^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} y_i^2 $$\nSo, $r$ can be expressed as:\n$$ r = \\frac{\\frac{1}{n-1} \\sum x_i y_i}{\\sqrt{\\frac{1}{n-1} \\sum x_i^2} \\sqrt{\\frac{1}{n-1} \\sum y_i^2}} = \\frac{\\sum x_i y_i}{\\sqrt{(\\sum x_i^2)(\\sum y_i^2)}} $$\nWe compute the required sums:\n$$ \\sum_{i=1}^{7} x_i^2 = (-3)^2 + (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 + 3^2 = 9 + 4 + 1 + 0 + 1 + 4 + 9 = 28 $$\n$$ \\sum_{i=1}^{7} y_i^2 = (-27)^2 + (-8)^2 + (-1)^2 + 0^2 + 1^2 + 8^2 + 27^2 = 729 + 64 + 1 + 0 + 1 + 64 + 729 = 1588 $$\nNote that $y_i=x_i^3$. So, the sum of products is $\\sum x_i y_i = \\sum x_i (x_i^3) = \\sum x_i^4$.\n$$ \\sum_{i=1}^{7} x_i y_i = (-3)(-27) + (-2)(-8) + (-1)(-1) + (0)(0) + (1)(1) + (2)(8) + (3)(27) $$\n$$ \\sum_{i=1}^{7} x_i y_i = 81 + 16 + 1 + 0 + 1 + 16 + 81 = 196 $$\nNow, we substitute these sums into the formula for $r$:\n$$ r = \\frac{196}{\\sqrt{28 \\times 1588}} = \\frac{196}{\\sqrt{44464}} \\approx \\frac{196}{210.86488} \\approx 0.929532... $$\nRounding to four significant figures, $r \\approx 0.9295$.\n\n**2. Spearman’s Rank Correlation Coefficient ($\\rho_S$)**\n\nSpearman's rank correlation coefficient is defined as the Pearson correlation coefficient calculated on the ranks of the variables. Let $R(x_i)$ and $R(y_i)$ be the ranks of $x_i$ and $y_i$, respectively.\n\nThe $x$ values are already sorted: $\\{-3, -2, -1, 0, 1, 2, 3\\}$.\nThe corresponding ranks $R(x)$ are $\\{1, 2, 3, 4, 5, 6, 7\\}$.\n\nThe $y$ values are also sorted, as $y=x^3$ is a strictly increasing function: $\\{-27, -8, -1, 0, 1, 8, 27\\}$.\nThe corresponding ranks $R(y)$ are $\\{1, 2, 3, 4, 5, 6, 7\\}$.\n\nSince the ranks are identical, $R(x_i) = R(y_i)$ for all $i=1, \\dots, 7$, the relationship between the ranks is perfectly linear. When two variables are perfectly linearly related with a positive slope, their Pearson correlation is $1$. Therefore, Spearman's rank correlation coefficient $\\rho_S$ must be exactly $1$.\n\nTo confirm by calculation from the core definition, we apply the Pearson formula to the rank variables $u_i = R(x_i)$ and $v_i = R(y_i)$:\n$u = \\{1, 2, 3, 4, 5, 6, 7\\}$ and $v = \\{1, 2, 3, 4, 5, 6, 7\\}$.\nThe mean rank is $\\bar{u} = \\bar{v} = \\frac{1}{7} \\sum_{i=1}^7 i = \\frac{1}{7}\\frac{7(7+1)}{2} = 4$.\nThe sum of squared deviations for ranks is:\n$$ \\sum_{i=1}^7 (u_i - \\bar{u})^2 = \\sum_{i=1}^7 (i - 4)^2 = (-3)^2 + (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 + 3^2 = 9+4+1+0+1+4+9 = 28 $$\nSince $u_i=v_i$, we have $\\sum (v_i - \\bar{v})^2 = 28$ and $\\sum(u_i - \\bar{u})(v_i - \\bar{v}) = \\sum(u_i - \\bar{u})^2 = 28$.\n$$ \\rho_S = \\frac{\\sum(u_i - \\bar{u})(v_i - \\bar{v})}{\\sqrt{\\sum(u_i - \\bar{u})^2 \\sum(v_i - \\bar{v})^2}} = \\frac{28}{\\sqrt{28 \\times 28}} = \\frac{28}{28} = 1 $$\nRounded to four significant figures, $\\rho_S = 1.000$.\n\n**3. Kendall’s Tau Rank Correlation Coefficient ($\\tau$)**\n\nKendall's $\\tau$ is defined based on the number of concordant and discordant pairs of observations. For a set of pairs $(x_i, y_i)$, two pairs $(x_i, y_i)$ and $(x_j, y_j)$ are:\n- Concordant if the signs of $(x_i - x_j)$ and $(y_i - y_j)$ are the same.\n- Discordant if the signs of $(x_i - x_j)$ and $(y_i - y_j)$ are opposite.\nThere are no ties in the given data for either $x$ or $y$. The formula for $\\tau$ is:\n$$ \\tau = \\frac{N_c - N_d}{N_c + N_d} = \\frac{N_c - N_d}{\\binom{n}{2}} $$\nwhere $N_c$ is the number of concordant pairs and $N_d$ is the number of discordant pairs. The total number of unique pairs of observations is $\\binom{7}{2} = \\frac{7 \\times 6}{2} = 21$.\n\nThe data for $x$ are in increasing order. Since $y=x^3$ is a strictly increasing function, the data for $y$ are also in increasing order. This means for any two points $(x_i, y_i)$ and $(x_j, y_j)$ with $i  j$, we have $x_i  x_j$ and $y_i  y_j$. Therefore, $x_i - x_j$ and $y_i - y_j$ are both negative, and their signs are the same.\nConsequently, all $\\binom{7}{2}=21$ pairs are concordant.\n$N_c = 21$ and $N_d = 0$.\nSubstituting these values into the formula for $\\tau$:\n$$ \\tau = \\frac{21 - 0}{21} = 1 $$\nRounded to four significant figures, $\\tau = 1.000$.\n\n**Explanation of the Results**\n\nThe three coefficients are $r \\approx 0.9295$, $\\rho_S = 1.000$, and $\\tau = 1.000$. The reason for this discrepancy lies in what each coefficient measures.\n\n- **Pearson’s $r$** measures the strength and direction of a *linear* relationship between two variables. The value of $r=1$ or $r=-1$ is achieved only when the data points fall perfectly on a straight line. The data in this problem lie on the curve $y=x^3$. While this is a perfect functional relationship, it is a *nonlinear* one. The points do not lie on a line, so the Pearson correlation is less than $1$, reflecting the deviation from linearity.\n\n- **Spearman’s $\\rho_S$ and Kendall’s $\\tau$** are rank-based coefficients that measure the strength of a *monotonic* relationship. A monotonic relationship is one where the variables tend to move in the same relative direction, but not necessarily at a constant rate.\n    - Spearman's $\\rho_S$ assesses monotonicity by applying the Pearson correlation to the ranks of the data. The ranking process transforms any strictly monotonic relationship into a perfectly linear relationship of ranks. In this case, since $y=x^3$ is strictly increasing, the rank of $y_i$ is always identical to the rank of $x_i$. This perfect linear relationship between ranks results in $\\rho_S=1$.\n    - Kendall's $\\tau$ assesses monotonicity by comparing the ordering of all pairs of data points. For a strictly monotonic relationship like this one, every pair of points is concordant (an increase in $x$ is always associated with an increase in $y$). There are no discordant pairs, which yields the maximum possible value of $\\tau=1$.\n\nIn essence, $r$ indicates that the association is not perfectly linear, while $\\rho_S$ and $\\tau$ indicate that the association is perfectly monotonic. In a context where the primary interest is the direction and consistency of an association, rather than its specific linear form, $r$ can be said to \"underestimate\" the strength of the association. The rank-based coefficients correctly identify the perfect ordinal association present in the data.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.9295  1.000  1.000\n\\end{pmatrix}\n}\n$$", "id": "4825067"}]}