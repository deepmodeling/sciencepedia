{"hands_on_practices": [{"introduction": "After fitting a linear regression model, a fundamental first step is to assess its overall performance. The coefficient of determination, $R^2$, is a key metric for this, quantifying the proportion of variability in the outcome that our model successfully explains. This exercise [@problem_id:1895447] provides a direct application of this concept, linking the fundamental outputs of an Analysis of Variance (ANOVA) table—the sums of squares—to this essential measure of goodness-of-fit.", "problem": "An agricultural scientist is investigating the relationship between the amount of a specific nutrient supplement (in grams) added to the soil and the subsequent height of a newly developed plant species (in centimeters). A simple linear regression model is fitted to the collected data. To assess the goodness-of-fit of the model, an Analysis of Variance (ANOVA) is performed. The analysis yields a Regression Sum of Squares (SSR) of 90.0 cm$^2$ and a Total Sum of Squares (SST) of 120.0 cm$^2$.\n\nCalculate the coefficient of determination, denoted as $R^2$, for this linear regression model. Express your answer as a decimal value.", "solution": "The coefficient of determination for a linear regression is defined by the proportion of total variability explained by the regression:\n$$\nR^{2}=\\frac{\\text{SSR}}{\\text{SST}}.\n$$\nGiven $\\text{SSR}=90.0$ and $\\text{SST}=120.0$, substitute into the formula:\n$$\nR^{2}=\\frac{90.0}{120.0}=\\frac{9}{12}=\\frac{3}{4}=0.75.\n$$\nThus, the coefficient of determination is $0.75$.", "answer": "$$\\boxed{0.75}$$", "id": "1895447"}, {"introduction": "In biostatistics, we often find that the effect of one variable depends on the level of another. For instance, a medication's effectiveness might vary with a patient's age. This exercise [@problem_id:4919994] introduces the concept of an interaction term to model such complexities, challenging you to understand how the interpretation of a main effect, like a drug's impact, becomes conditional on another factor. This skill is crucial for accurately interpreting and communicating the nuanced findings of many clinical studies.", "problem": "A clinical trial investigates how a lipid-lowering medication affects low-density lipoprotein cholesterol (LDL-C) measured in milligrams per deciliter (mg/dL). Let the outcome be the fasting LDL-C level, denoted by $Y$. Two predictors are considered: a binary indicator $X_{1}$ for medication assignment ($X_{1}=1$ if patient received the medication, $X_{1}=0$ otherwise) and age in years, $X_{2}$. To allow the effect of medication to vary with age, an interaction term between $X_{1}$ and $X_{2}$ is included. The Ordinary Least Squares (OLS) estimate of the conditional mean function is\n$$\n\\mathbb{E}[Y \\mid X_{1}, X_{2}] = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} + \\beta_{3} X_{1} X_{2},\n$$\nwith fitted coefficients $\\beta_{0} = 160$, $\\beta_{1} = -30$, $\\beta_{2} = 0.6$, and $\\beta_{3} = 0.2$.\n\nStarting from the definition of the conditional mean in the linear model and the meaning of an interaction term, explain how the inclusion of the product $X_{1} X_{2}$ changes the interpretation of the main-effect coefficients $\\beta_{1}$ and $\\beta_{2}$ relative to a model that omits the interaction term. Then, using the fitted coefficients above, compute the marginal effect of $X_{1}$ on the expected LDL-C at $X_{2} = 60$, defined as the change in $\\mathbb{E}[Y \\mid X_{1}, X_{2}]$ when $X_{1}$ increases by one unit while holding $X_{2}$ fixed. Express your numerical answer in mg/dL and round your answer to four significant figures.", "solution": "The specified Ordinary Least Squares (OLS) model for the conditional mean of the outcome $Y$ (LDL-C level) given predictors $X_1$ (medication status) and $X_2$ (age) is:\n$$\n\\mathbb{E}[Y \\mid X_{1}, X_{2}] = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} + \\beta_{3} X_{1} X_{2}\n$$\n\nTo understand how the interaction term $X_{1}X_{2}$ alters the interpretation of the main-effect coefficients $\\beta_1$ and $\\beta_2$, we first consider a model without this term, often called an additive or main-effects model:\n$$\n\\mathbb{E}[Y \\mid X_{1}, X_{2}] = \\alpha_{0} + \\alpha_{1} X_{1} + \\alpha_{2} X_{2}\n$$\nIn this additive model, the coefficient $\\alpha_1$ represents the difference in the mean of $Y$ when $X_1$ changes from $0$ to $1$, holding $X_2$ constant. This effect is constant across all values of $X_2$. Similarly, $\\alpha_2$ represents the change in the mean of $Y$ for a one-unit increase in $X_2$, holding $X_1$ constant. This effect is assumed to be the same for both the medication group ($X_1=1$) and the control group ($X_1=0$).\n\nNow, we return to the model with the interaction term:\n$$\n\\mathbb{E}[Y \\mid X_{1}, X_{2}] = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} + \\beta_{3} X_{1} X_{2}\n$$\nThe inclusion of the product term $X_1X_2$ allows the effect of each predictor on the outcome to depend on the level of the other predictor.\n\n**Interpretation of $\\beta_1$:**\nThe \"effect\" of the medication, or the change in expected LDL-C when a patient receives the medication ($X_1$ goes from $0$ to $1$), is calculated by taking the difference in the conditional expectation:\n$$\n\\text{Effect of } X_1 = \\mathbb{E}[Y \\mid X_1=1, X_2] - \\mathbb{E}[Y \\mid X_1=0, X_2]\n$$\nSubstituting the model equation:\n$$\n\\text{Effect of } X_1 = (\\beta_0 + \\beta_1(1) + \\beta_2 X_2 + \\beta_3(1)X_2) - (\\beta_0 + \\beta_1(0) + \\beta_2 X_2 + \\beta_3(0)X_2)\n$$\n$$\n\\text{Effect of } X_1 = (\\beta_0 + \\beta_1 + \\beta_2 X_2 + \\beta_3 X_2) - (\\beta_0 + \\beta_2 X_2) = \\beta_1 + \\beta_3 X_2\n$$\nUnlike the additive model where the effect is constant ($\\alpha_1$), here the effect of the medication is a function of age, $X_2$. The coefficient $\\beta_1$ is no longer the overall main effect of the medication. Instead, it represents the effect of the medication under the specific condition that $X_2=0$. That is, $\\beta_1$ is the expected difference in LDL-C between the medication and control groups for a person of age $0$. In the additive model, $\\alpha_1$ represents this difference for any and all ages.\n\n**Interpretation of $\\beta_2$:**\nThe effect of a one-unit increase in age ($X_2$) on the expected LDL-C can be found by taking the partial derivative of the conditional mean function with respect to $X_2$:\n$$\n\\frac{\\partial}{\\partial X_2} \\mathbb{E}[Y \\mid X_1, X_2] = \\frac{\\partial}{\\partial X_2} (\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2) = \\beta_2 + \\beta_3 X_1\n$$\nThe effect of age is no longer a constant but depends on the medication status, $X_1$.\n- For the control group ($X_1=0$), the effect of a one-year increase in age is $\\beta_2 + \\beta_3(0) = \\beta_2$.\n- For the medication group ($X_1=1$), the effect of a one-year increase in age is $\\beta_2 + \\beta_3(1) = \\beta_2 + \\beta_3$.\n\nTherefore, the coefficient $\\beta_2$ is not the general effect of age as it would be in an additive model. Instead, it represents the specific effect of a one-year increase in age on LDL-C for the control group ($X_1=0$) only. In contrast, in the additive model, $\\alpha_2$ represents the effect of age for both groups.\n\n**In summary:** The inclusion of the interaction term $X_1X_2$ changes the interpretation of $\\beta_1$ and $\\beta_2$ from *average* or *main* effects to *conditional* or *simple* effects. $\\beta_1$ becomes the effect of $X_1$ when $X_2=0$, and $\\beta_2$ becomes the effect of $X_2$ when $X_1=0$.\n\nNow, we compute the marginal effect of $X_1$ on the expected LDL-C at $X_2 = 60$. The marginal effect of $X_1$ is the change in $\\mathbb{E}[Y \\mid X_1, X_2]$ when $X_1$ increases by one unit, which we have already derived:\n$$\n\\text{Marginal Effect of } X_1 = \\beta_1 + \\beta_3 X_2\n$$\nThe problem provides the fitted coefficients: $\\beta_1 = -30$, $\\beta_3 = 0.2$. We are asked to evaluate this effect at age $X_2 = 60$.\nSubstituting the values:\n$$\n\\text{Marginal Effect at } X_2=60 = -30 + (0.2)(60)\n$$\n$$\n= -30 + 12\n$$\n$$\n= -18\n$$\nThis means that for a $60$-year-old patient, receiving the medication is associated with an average decrease of $18$ mg/dL in LDL-C compared to not receiving the medication. The problem requires the answer to be rounded to four significant figures. Thus, $-18$ should be expressed as $-18.00$.", "answer": "$$\n\\boxed{-18.00}\n$$", "id": "4919994"}, {"introduction": "A regression model is only as reliable as the data it is built upon, and some data points can have a disproportionate and misleading influence on the results. Diagnostic statistics help us identify such influential points, but deciding what to do about them requires more than just applying a rule; it demands careful scientific reasoning. This practical case study [@problem_id:4920003] puts you in the role of a data analyst, using diagnostic tools to flag unusual observations and then applying scientific context to make a principled decision about how to handle them, ensuring the integrity of your model.", "problem": "A biostatistics team models fasting plasma glucose, denoted by $Y$ (in milligrams per deciliter), as a linear function of age, denoted by $X$ (in years), among non-diabetic adults in a community study with sample size $n=120$. The team fits the Ordinary Least Squares (OLS) simple linear regression model $Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i$ and uses standard diagnostics to assess unusual or influential observations. Two observations raise concerns:\n\n1. Subject A has $X=92$ and $Y=95$. The diagnostics for Subject A show leverage $h_{ii}=0.30$, studentized residual $r_i=0.4$, and Cook’s distance $D_i=0.08$. The subject’s age of $92$ years is within the study’s intended population, and repeat checks confirm the measurement procedures were followed correctly. The fitted model’s point prediction at $X=92$ is $98$, which is close to the observed $Y$.\n\n2. Subject B has $X=34$ and $Y=540$. The diagnostics for Subject B show leverage $h_{ii}=0.10$, studentized residual $r_i=5.2$, and Cook’s distance $D_i=1.1$. For non-diabetic fasting measurements, laboratory reference materials indicate that values above $400$ milligrams per deciliter are physiologically implausible without acute pathology inconsistent with the study’s inclusion criteria. A laboratory audit notes that the sample was severely hemolyzed and a calibration flag was triggered on the analyzer for this specimen.\n\nBased on first principles of linear regression and a scientifically grounded approach to outlier assessment, which option most appropriately distinguishes an outlier in $X$ from an outlier in $Y \\mid X$ and sets a principled course of action for possible exclusion?\n\nA. Exclude both subjects immediately because they are influential, as indicated by the diagnostics.\n\nB. Retain Subject A after confirming measurement validity and scientific plausibility; for Subject B, investigate data provenance, consider physiological plausibility and documented measurement error, and if a measurement error is substantiated or the value is implausible for the target population, exclude Subject B; otherwise, conduct sensitivity analyses by refitting with and without Subject B and report the impact.\n\nC. Exclude any observation with high leverage $h_{ii}$ regardless of its residual or plausibility, because high leverage always biases the slope estimate.\n\nD. Keep both observations and collect more data until their influence becomes negligible; exclusion is never justified because it can introduce bias.", "solution": "The core principle in handling unusual observations is that statistical diagnostics are tools for identification, not automatic arbiters for exclusion. The decision to remove a data point must be justified by evidence external to the model fit itself, typically relating to data integrity or population definition.\n\n**Analysis of Subject A:**\n- This observation has high leverage ($h_{ii}=0.30$), meaning its $X$-value ($X=92$) is far from the mean age of the subjects, $\\bar{X}$. A common threshold for high leverage is $2p/n$, where $p$ is the number of model parameters ($p=2$ for $\\beta_0$ and $\\beta_1$) and $n$ is the sample size ($n=120$). Here, $2p/n = 4/120 \\approx 0.033$. Since $0.30 \\gg 0.033$, Subject A has high leverage.\n- The studentized residual is small ($r_i=0.4$), indicating the observed $Y$ value ($Y=95$) is very close to the value predicted by the regression line ($\\hat{Y}=98$). This point conforms to the linear trend established by the other data points.\n- The Cook's distance ($D_i=0.08$) is above the threshold of $4/n \\approx 0.033$, indicating some influence, but it is not overwhelmingly large (e.g., not greater than 1).\n- The context is critical: the age is plausible for the population, and the measurements were verified.\n- **Conclusion for Subject A**: This is a \"good\" high-leverage point. It is an authentic observation from the target population that lies far out in the predictor space but is consistent with the model. Such points can improve the precision of the slope estimate (i.e., decrease the standard error of $\\hat{\\beta}_1$) and should be retained. There is no principled reason for its exclusion.\n\n**Analysis of Subject B:**\n- This observation has moderate leverage ($h_{ii}=0.10$), which is still above the $2p/n \\approx 0.033$ threshold but less extreme than Subject A.\n- The studentized residual is extremely large ($r_i=5.2$). A general rule of thumb flags observations with $|r_i|>3$ as extreme outliers. This means the observed $Y$ value ($Y=540$) is exceptionally far from the value predicted by the model for an age of $X=34$. This is a clear outlier in the $Y$ direction, conditional on $X$.\n- The Cook's distance is very large ($D_i=1.1$), exceeding the common threshold of 1, which indicates the point is highly influential. Its removal would cause substantial changes to the estimated intercept $\\hat{\\beta}_0$ and slope $\\hat{\\beta}_1$.\n- The context provides the definitive reason for action. A fasting glucose of $540$ mg/dL is noted as \"physiologically implausible\" for a non-diabetic individual. More importantly, specific, documented measurement error is present: \"severely hemolyzed\" sample and a \"calibration flag\".\n- **Conclusion for Subject B**: This point is not a valid representation of the underlying biological relationship in the target population. It is a contaminated measurement. The statistical diagnostics correctly flagged it as problematic, and the subsequent investigation confirmed that it is bad data. The correct action is to exclude this observation to avoid biasing the model with erroneous information.\n\n**Evaluation of Options**\n\n**A. Exclude both subjects immediately because they are influential, as indicated by the diagnostics.**\nThis is an improper, mechanical application of diagnostics. Subject A is a valid point and should be retained. Influence alone is not a sufficient criterion for exclusion. A point's validity and scientific context must be considered.\n**Verdict: Incorrect**\n\n**B. Retain Subject A after confirming measurement validity and scientific plausibility; for Subject B, investigate data provenance, consider physiological plausibility and documented measurement error, and if a measurement error is substantiated or the value is implausible for the target population, exclude Subject B; otherwise, conduct sensitivity analyses by refitting with and without Subject B and report the impact.**\nThis option describes the scientifically and statistically rigorous approach. It correctly advises retaining the valid high-leverage point (Subject A). For Subject B, it correctly prioritizes an investigation into the cause of the outlier status. Since the problem statement provides substantiation of measurement error and physiological implausibility for Subject B, exclusion is justified under this option's framework. It also correctly specifies sensitivity analysis as the fallback if the investigation were inconclusive. This is the correct methodology.\n**Verdict: Correct**\n\n**C. Exclude any observation with high leverage $h_{ii}$ regardless of its residual or plausibility, because high leverage always biases the slope estimate.**\nThis statement is false. High leverage does not always bias the slope. A high-leverage point with a small residual (like Subject A) conforms to the model and can increase the precision of the slope estimate. Excluding all high-leverage points is a flawed strategy that discards valuable information.\n**Verdict: Incorrect**\n\n**D. Keep both observations and collect more data until their influence becomes negligible; exclusion is never justified because it can introduce bias.**\nThis contains a dangerous fallacy. While injudicious exclusion can introduce bias, the assertion that exclusion is *never* justified is incorrect. Knowingly including a data point that is confirmed to be an error (due to equipment malfunction, sample contamination, etc., as with Subject B) will corrupt the analysis and bias the results. The goal is to model the true relationship, and including known-to-be-false data undermines this goal. Removing a demonstrably invalid data point is a necessary step to *reduce* bias.\n**Verdict: Incorrect**", "answer": "$$\\boxed{B}$$", "id": "4920003"}]}