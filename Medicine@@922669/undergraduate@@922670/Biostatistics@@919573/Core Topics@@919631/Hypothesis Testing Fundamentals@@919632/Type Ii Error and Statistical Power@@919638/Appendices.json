{"hands_on_practices": [{"introduction": "The most direct application of statistical power is in study design. Before collecting any data, researchers must determine the required sample size to have a reasonable probability of detecting an effect of a certain magnitude. This exercise guides you through the fundamental derivation of a sample size formula, connecting the abstract concepts of Type I and Type II errors to the concrete task of planning a well-powered clinical trial. Mastering this calculation is an essential skill for designing studies that are both scientifically rigorous and ethically responsible. [@problem_id:4992656]", "problem": "A two-arm Randomized Controlled Trial (RCT) is planned to compare an antihypertensive drug against placebo with equal allocation. The primary endpoint is the change in systolic blood pressure, measured in millimeters of mercury. Investigators will use a two-sided hypothesis test of the difference in population means with type I error rate $\\alpha = 0.05$. Assume individual patient outcomes within each arm are independent and identically distributed, approximately normal, with a common and known standard deviation $\\sigma = 10$ millimeters of mercury. The clinically meaningful difference to detect is a true mean reduction in the treatment arm relative to placebo of $\\delta = 4$ millimeters of mercury. The design target is statistical power $1 - \\beta = 0.80$.\n\nStarting from the definitions of type I error, type II error, and statistical power, and the distribution of the standardized difference in sample means under the null and under a fixed alternative, derive an expression for the required per-arm sample size for a two-sided test with equal allocation. Then compute the minimal integer number of participants per arm required to attain power at least $0.80$ for $\\delta = 4$, $\\sigma = 10$, and $\\alpha = 0.05$. Provide the final answer as a single integer giving the required per-arm sample size.", "solution": "Let $\\mu_1$ and $\\mu_2$ be the population mean changes in systolic blood pressure for the placebo and treatment arms, respectively. The sample sizes are equal, $n_1 = n_2 = n$. The outcomes are assumed to be normally distributed with a common known standard deviation $\\sigma$. The hypotheses for a two-sided test are:\n$$ H_0: \\mu_1 - \\mu_2 = 0 $$\n$$ H_a: \\mu_1 - \\mu_2 \\neq 0 $$\n\nThe test statistic is the standardized difference in sample means, $\\bar{X}_1 - \\bar{X}_2$. The sampling distribution of the difference is $\\bar{X}_1 - \\bar{X}_2 \\sim N(\\mu_1 - \\mu_2, \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n}) = N(\\mu_1 - \\mu_2, \\frac{2\\sigma^2}{n})$.\nUnder the null hypothesis $H_0$, the test statistic is:\n$$ Z = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{\\frac{2\\sigma^2}{n}}} $$\nwhich follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nA Type I error occurs if we reject $H_0$ when it is true. For a two-sided test at a significance level $\\alpha$, we reject $H_0$ if $|Z| > z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the upper $(1-\\alpha/2)$-quantile of the standard normal distribution. This defines the rejection region in terms of the observed sample difference as $|\\bar{X}_1 - \\bar{X}_2| > z_{1-\\alpha/2}\\sqrt{\\frac{2\\sigma^2}{n}}$.\n\nA Type II error occurs if we fail to reject $H_0$ when it is false. The probability of a Type II error is $\\beta$. Statistical power, $1-\\beta$, is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_a$ is true. We calculate power for a specific alternative, namely that the true difference is the clinically meaningful difference $\\delta$. So, we assume $\\mu_1 - \\mu_2 = \\delta$.\n\nUnder this alternative, the sampling distribution is $\\bar{X}_1 - \\bar{X}_2 \\sim N(\\delta, \\frac{2\\sigma^2}{n})$. The power is the probability that the observed difference falls in the rejection region, given $\\mu_1 - \\mu_2 = \\delta$:\n$$ 1 - \\beta = P\\left(|\\bar{X}_1 - \\bar{X}_2| > z_{1-\\alpha/2}\\sqrt{\\frac{2\\sigma^2}{n}} \\;\\middle|\\; \\mu_1 - \\mu_2 = \\delta\\right) $$\nAssuming $\\delta > 0$, the power is dominated by detections in the upper tail of the rejection region. The power can be expressed as:\n$$ 1 - \\beta = P\\left(\\bar{X}_1 - \\bar{X}_2 > z_{1-\\alpha/2}\\sqrt{\\frac{2\\sigma^2}{n}}\\right) + P\\left(\\bar{X}_1 - \\bar{X}_2  -z_{1-\\alpha/2}\\sqrt{\\frac{2\\sigma^2}{n}}\\right) $$\nTo evaluate this probability under $H_a$, we standardize using the mean $\\delta$:\n$$ Z' = \\frac{(\\bar{X}_1 - \\bar{X}_2) - \\delta}{\\sqrt{\\frac{2\\sigma^2}{n}}} \\sim N(0, 1) $$\nRewriting the inequalities in terms of $Z'$:\n$$ 1 - \\beta = P\\left(Z' > z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}\\right) + P\\left(Z'  -z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}\\right) $$\nFor typical study designs, the second term is negligible because $-z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}$ is a large negative number, making the probability extremely small. We thus proceed using the standard approximation:\n$$ 1 - \\beta \\approx P\\left(Z' > z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}\\right) $$\nLet $\\Phi(\\cdot)$ be the cumulative distribution function of the standard normal distribution. Then $1-\\beta \\approx 1 - \\Phi\\left(z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}\\right)$, which implies $\\beta \\approx \\Phi\\left(z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}}\\right)$.\nBy definition of normal quantiles, $z_\\beta = \\Phi^{-1}(\\beta)$. Thus:\n$$ z_\\beta = z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^2/n}} $$\nSince the standard normal distribution is symmetric about $0$, $z_\\beta = -z_{1-\\beta}$. Substituting this gives:\n$$ -z_{1-\\beta} = z_{1-\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma\\sqrt{2}} $$\nRearranging to solve for the sample size $n$:\n$$ \\frac{\\delta\\sqrt{n}}{\\sigma\\sqrt{2}} = z_{1-\\alpha/2} + z_{1-\\beta} $$\n$$ \\sqrt{n} = \\frac{\\sigma\\sqrt{2}(z_{1-\\alpha/2} + z_{1-\\beta})}{\\delta} $$\nSquaring both sides yields the desired expression for the per-arm sample size:\n$$ n = \\frac{2\\sigma^2(z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\delta^2} $$\nNow, we compute the minimal integer sample size for the given parameters:\nType I error rate $\\alpha = 0.05$.\nStatistical power $1 - \\beta = 0.80$, so the Type II error rate is $\\beta = 0.20$.\nCommon standard deviation $\\sigma = 10$ mmHg.\nClinically meaningful difference $\\delta = 4$ mmHg.\n\nFirst, we find the required quantiles from the standard normal distribution:\nFor a two-sided test with $\\alpha = 0.05$, we need the upper $1 - \\alpha/2 = 1 - 0.025 = 0.975$ quantile:\n$$ z_{1-\\alpha/2} = z_{0.975} \\approx 1.960 $$\nFor a power of $0.80$, we need the upper $1 - \\beta = 0.80$ quantile:\n$$ z_{1-\\beta} = z_{0.80} \\approx 0.842 $$\nSubstituting these values into the derived formula for $n$:\n$$ n = \\frac{2(10)^2(1.960 + 0.842)^2}{(4)^2} $$\n$$ n = \\frac{2 \\times 100 \\times (2.802)^2}{16} $$\n$$ n = \\frac{200 \\times 7.851204}{16} $$\n$$ n = 12.5 \\times 7.851204 $$\n$$ n \\approx 98.14005 $$\nSince the number of participants must be an integer, and the power must be *at least* $0.80$, we must round the calculated value of $n$ up to the next whole number. Choosing $n=98$ would result in a power slightly below the target of $0.80$. Therefore, the minimal integer number of participants required per arm is $99$.", "answer": "$$ \\boxed{99} $$", "id": "4992656"}, {"introduction": "Beyond study planning, statistical power is a critical lens for interpreting research findings, especially when results seem contradictory. This practice presents a realistic scenario from genetics research: a landmark discovery that fails to replicate in a subsequent study. This exercise challenges you to move beyond simple calculations and act as a scientific detective, using your understanding of power to dissect the multiple plausible reasons for replication failure. It demonstrates that a non-significant result is not a final verdict, but an observation that must be interpreted in the context of the study's power to find the truth. [@problem_id:2438780]", "problem": "A Genome-Wide Association Study (GWAS) of a binary disease in European-ancestry participants discovers a single-nucleotide polymorphism (SNP) with per-allele association that is genome-wide significant. The discovery cohort has $n_{\\text{case},1} = 30{,}000$ cases and $n_{\\text{control},1} = 70{,}000$ controls. The index SNP has European risk-allele frequency $p_{\\text{EUR}} = 0.30$, estimated odds ratio $\\widehat{\\mathrm{OR}}_1 = 1.08$, and a two-sided p-value $p_1 = 2\\times 10^{-9}$ (which is below the conventional threshold $5\\times 10^{-8}$ for genome-wide significance). An independent replication is attempted in East Asian ancestry with $n_{\\text{case},2} = 5{,}000$ and $n_{\\text{control},2} = 5{,}000$, testing the same index SNP or its best available proxy, which has squared correlation $r^2 = 0.80$ with the index SNP in Europeans. In the East Asian sample, the risk-allele frequency is $p_{\\text{EAS}} = 0.10$. The replication uses a two-sided threshold $p_2  0.05$ for this single pre-specified SNP and reports $\\widehat{\\mathrm{OR}}_2 = 1.05$ with $p_2 = 0.12$ (not significant). Both studies perform standard quality control and adjust for principal components of ancestry.\n\nUsing only fundamental definitions about statistical errors and widely accepted properties of statistical power in association testing, reason about why a genome-wide significant discovery can fail to replicate, and how to interpret such a failure in terms of Type I and Type II errors. Select all statements that are correct in this scenario.\n\nA. The failure to replicate implies the discovery was a Type I error, because a true association would have yielded $p_2  0.05$ in the replication.\n\nB. The replication may have committed a Type II error: smaller $n_{\\text{case},2}$ and $n_{\\text{control},2}$, lower $p_{\\text{EAS}}$, and imperfect linkage disequilibrium between the tested proxy and the causal variant reduce power, so non-significance can occur even if the association is real.\n\nC. If the causal effect is present in Europeans but absent or materially weaker in East Asians, then the null hypothesis may be true in the replication cohort; in that case, non-significance does not constitute a Type II error with respect to the replication’s hypothesis test.\n\nD. Achieving $p_1  5\\times 10^{-8}$ in discovery eliminates the possibility that the discovery was a Type I error.\n\nE. Despite $p_1 = 2\\times 10^{-9}$, the discovery could still be a Type I error; the genome-wide threshold controls but does not abolish the probability of false positives across many tested variants, and residual confounding could inflate test statistics.\n\nF. If, instead of $p_2  0.05$, the replication required $p_2  5\\times 10^{-8}$ for this single pre-specified SNP, the probability of a Type II error would increase substantially relative to using $p_2  0.05$.", "solution": "In hypothesis testing, we evaluate a null hypothesis ($H_0$) against an alternative hypothesis ($H_A$). In this context:\n- $H_0$: The true odds ratio for the association between the SNP and the disease is $1$. There is no effect.\n- $H_A$: The true odds ratio is not $1$. There is a real effect.\n\nTwo types of errors can occur:\n- **Type I Error (False Positive):** Rejecting $H_0$ when $H_0$ is true. The probability of this error is denoted by $\\alpha$, the significance level.\n- **Type II Error (False Negative):** Failing to reject $H_0$ when $H_A$ is true. The probability of this error is denoted by $\\beta$.\n\n**Statistical power** is the probability of correctly rejecting $H_0$ when it is false, i.e., Power $= 1 - \\beta$. Power is a critical concept for interpreting non-significant results and is influenced by several factors:\n1.  **Significance level ($\\alpha$):** A more stringent (smaller) $\\alpha$ reduces power.\n2.  **Effect size (true OR):** A larger effect size (OR further from $1$) increases power.\n3.  **Sample size ($n$):** Larger sample sizes increase power.\n4.  **Allele frequency ($p$):** For a binary trait and an additive genetic model, power is maximized when $p=0.5$ and decreases as the allele becomes rarer or more common. The effective sample size is proportional to $n \\cdot p(1-p)$.\n5.  **Linkage Disequilibrium (LD):** If the genotyped SNP is a proxy for the true causal variant, power is reduced by a factor of $r^2$, where $r^2$ is the squared correlation between the proxy and the causal variant.\n\nThe discovery study has a very large sample size ($n_1 = 100{,}000$) and found a highly significant result ($p_1 = 2 \\times 10^{-9}$), despite a small estimated effect size ($\\widehat{\\mathrm{OR}}_1 = 1.08$). The replication study failed to find a significant result ($p_2 = 0.12 > 0.05$). The task is to interpret this failure.\n\n**Option-by-Option Analysis**\n\n**A. The failure to replicate implies the discovery was a Type I error, because a true association would have yielded $p_2  0.05$ in the replication.**\nThis statement is incorrect. The word \"implies\" suggests a deterministic outcome, which is contrary to the probabilistic nature of statistics. A true association (i.e., the discovery was not a Type I error) does not guarantee a significant result in any given replication attempt. The replication study may lack sufficient statistical power to detect the true effect. If the power is less than $100\\%$, there is a non-zero probability of a Type II error. As will be shown in the analysis of option B, there are multiple reasons why the replication study has substantially lower power than the discovery study. Therefore, a failure to replicate cannot be taken as definitive proof that the original finding was a Type I error. It is a possibility, but not a certainty.\n**Verdict: Incorrect.**\n\n**B. The replication may have committed a Type II error: smaller $n_{\\text{case},2}$ and $n_{\\text{control},2}$, lower $p_{\\text{EAS}}$, and imperfect linkage disequilibrium between the tested proxy and the causal variant reduce power, so non-significance can occur even if the association is real.**\nThis statement correctly identifies several key factors that reduce statistical power.\n- **Sample size:** The replication total sample size ($n_2=10{,}000$) is one-tenth of the discovery sample size ($n_1=100{,}000$). This drastically reduces power.\n- **Allele frequency:** The risk-allele frequency is much lower in the replication cohort ($p_{\\text{EAS}} = 0.10$) than in the discovery cohort ($p_{\\text{EUR}} = 0.30$). Statistical power is proportional to the variance of the allele count, which is a function of $n \\cdot p(1-p)$. For discovery, this is proportional to $100{,}000 \\times 0.3 \\times 0.7 = 21{,}000$. For replication, it is proportional to $10{,}000 \\times 0.1 \\times 0.9 = 900$. This is a reduction in effective sample size by a factor of more than $20$, which severely cripples power.\n- **Imperfect LD:** The use of a proxy SNP with $r^2=0.80$ means that even if the effect size were identical in both populations and the index SNP were causal, the power in the replication is automatically reduced by a factor of approximately $r^2 = 0.80$.\nThese factors combine to make the replication study substantially underpowered to detect a small effect size like $\\mathrm{OR} = 1.08$. Thus, failing to achieve significance ($p_2  0.05$) is a highly plausible outcome even if the association is real, and this would constitute a Type II error.\n**Verdict: Correct.**\n\n**C. If the causal effect is present in Europeans but absent or materially weaker in East Asians, then the null hypothesis may be true in the replication cohort; in that case, non-significance does not constitute a Type II error with respect to the replication’s hypothesis test.**\nThis statement addresses the possibility of population-specific effects (genetic heterogeneity). It is scientifically plausible that a genetic variant has an effect on a disease in one ancestry group but not another, due to differing genetic backgrounds (e.g., interactions with other genes) or environmental exposures. If the true OR in the East Asian population is $1$, then the null hypothesis is true for the replication study. A Type II error is defined as failing to reject $H_0$ *when it is false*. If $H_0$ is true, it is impossible to commit a Type II error. In that scenario, the non-significant result ($p_2=0.12$) is a correct outcome, a failure to reject a true null hypothesis. The statement accurately describes this logical point.\n**Verdict: Correct.**\n\n**D. Achieving $p_1  5\\times 10^{-8}$ in discovery eliminates the possibility that the discovery was a Type I error.**\nThis statement reflects a fundamental misunderstanding of p-values. A p-value is a measure of evidence against the null hypothesis, not a proof of its falsehood. A p-value of $p_1 = 2 \\times 10^{-9}$ means that if the null hypothesis were true, there would be a $2 \\times 10^{-9}$ probability of observing a test statistic at least as extreme as the one found. While this probability is extremely small, it is not zero. Unlikely events can and do occur. The genome-wide significance threshold of $5 \\times 10^{-8}$ is chosen to control the family-wise error rate across the entire genome, making false positives rare, but it does not eliminate them. Therefore, a Type I error remains a possibility, however small.\n**Verdict: Incorrect.**\n\n**E. Despite $p_1 = 2\\times 10^{-9}$, the discovery could still be a Type I error; the genome-wide threshold controls but does not abolish the probability of false positives across many tested variants, and residual confounding could inflate test statistics.**\nThis statement is the correct interpretation. As explained for option D, a Type I error is always possible as long as the p-value is not exactly zero. The purpose of the stringent GWAS threshold is to control this error rate, not eliminate it. Furthermore, the statement correctly introduces another critical issue: confounding. GWAS test statistics can be inflated by unmeasured or imperfectly corrected confounding factors, such as subtle population structure, cryptic relatedness, or technical artifacts in genotyping. The problem states that principal components were used to adjust for ancestry, but this method may not perfectly capture all population-level differences. Such residual confounding can create spurious associations, leading to a Type I error that appears highly significant. This is a well-known vulnerability of observational studies.\n**Verdict: Correct.**\n\n**F. If, instead of $p_2  0.05$, the replication required $p_2  5\\times 10^{-8}$ for this single pre-specified SNP, the probability of a Type II error would increase substantially relative to using $p_2  0.05$.**\nThere is a direct trade-off between the Type I error rate ($\\alpha$) and the Type II error rate ($\\beta$). Statistical power is $1 - \\beta$. By making the significance threshold ($\\alpha$) more stringent (i.e., smaller), one makes it harder to reject the null hypothesis. This means that the region of the test statistic distribution that leads to rejection becomes smaller. Consequently, if the null hypothesis is false, the probability of rejecting it (power) decreases, and the probability of failing to reject it (Type II error, $\\beta$) increases. Changing the required significance level from $\\alpha = 0.05$ to $\\alpha = 5 \\times 10^{-8}$ is a dramatic increase in stringency (a decrease in $\\alpha$ by over six orders of magnitude). This would drastically reduce the power of the replication study and thus substantially increase the probability of a Type II error. This is precisely why replication studies of a *single*, pre-specified hypothesis use a conventional threshold like $\\alpha=0.05$ and not a genome-wide correction.\n**Verdict: Correct.**", "answer": "$$\\boxed{BCEF}$$", "id": "2438780"}, {"introduction": "Power calculations are not just formulas; they are models built on assumptions. A crucial, and often uncertain, assumption is the population's standard deviation, $\\sigma$. This advanced exercise takes you under the hood of the power formula to explore its sensitivity to this key input. Using calculus, you will quantify how an error in estimating $\\sigma$ propagates into the required sample size, revealing a surprisingly simple and powerful relationship. This practice highlights a vital lesson for all researchers: the conclusions of a power analysis are only as reliable as the assumptions put into them. [@problem_id:4963993]", "problem": "A biostatistician is designing a one-sample study to detect a clinically relevant mean shift using a two-sided hypothesis test of the form $H_0: \\mu = \\mu_0$ versus $H_1: \\mu \\neq \\mu_0$ at significance level $\\alpha$. The continuous endpoint is modeled as independent and identically distributed Normal with true mean $\\mu$ and true standard deviation $\\sigma$. The test statistic is $T = (\\bar{X} - \\mu_0) / (\\sigma/\\sqrt{n})$, and the critical region is $|T| > z_{1-\\alpha/2}$, where $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$-quantile of the Standard Normal distribution. Let $\\Delta = \\mu - \\mu_0$ denote a fixed, nonzero clinically relevant effect size, and define the power function $\\pi(\\mu)$ as the probability of rejecting $H_0$ under the true mean $\\mu$.\n\nUsing only the Normal model and the definitions of Type I error, Type II error, and statistical power, carry out the following:\n\n- Derive the partial derivative of the power function with respect to the standard deviation, $\\frac{\\partial \\pi(\\mu)}{\\partial \\sigma}$, treating $\\mu$, $n$, and $\\alpha$ as fixed.\n- Then, holding the target power fixed, use a total differential argument to derive the infinitesimal relationship between $d n$ and $d \\sigma$ required to keep power constant, and from this, define the local elasticity $E = \\frac{d n / n}{d \\sigma / \\sigma}$ of the required sample size with respect to the standard deviation.\n\nReport the value of $E$ as your final answer. No rounding is required.", "solution": "The power of the test, $\\pi(\\mu)$, is the probability of rejecting the null hypothesis $H_0$ given that the true mean is $\\mu$. Rejection occurs if the test statistic $T$ falls into the critical region, i.e., $|T| > z_{1-\\alpha/2}$.\n\nFirst, we must determine the distribution of the test statistic $T = (\\bar{X}-\\mu_0)/(\\sigma/\\sqrt{n})$ under the alternative hypothesis, where the true mean is $\\mu$. The sample mean $\\bar{X}$ follows a Normal distribution $\\bar{X} \\sim N(\\mu, \\sigma^2/n)$. To find the distribution of $T$, we standardize $\\bar{X}$ with its true mean $\\mu$ and add and subtract $\\mu$ in the numerator of $T$:\n$$T = \\frac{\\bar{X}-\\mu_0}{\\sigma/\\sqrt{n}} = \\frac{(\\bar{X}-\\mu) + (\\mu-\\mu_0)}{\\sigma/\\sqrt{n}} = \\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}} + \\frac{\\mu-\\mu_0}{\\sigma/\\sqrt{n}}$$\nThe term $\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{n}}$ is a standard Normal variable, $Z \\sim N(0,1)$. The term $\\frac{\\mu-\\mu_0}{\\sigma/\\sqrt{n}}$ is a constant, equal to $\\frac{\\Delta\\sqrt{n}}{\\sigma}$.\nThus, under the alternative hypothesis, $T \\sim N\\left(\\frac{\\Delta\\sqrt{n}}{\\sigma}, 1\\right)$.\n\nThe power function $\\pi(\\mu)$ is the probability $P(|T| > z_{1-\\alpha/2})$. Since $T$ is not a standard Normal variate, we must evaluate this probability using its derived distribution. Let $\\Phi(\\cdot)$ denote the cumulative distribution function (CDF) of the standard Normal distribution.\n$$\\pi(\\mu) = P(T > z_{1-\\alpha/2}) + P(T  -z_{1-\\alpha/2})$$\nLet the mean of $T$ be $\\delta_T = \\frac{\\Delta\\sqrt{n}}{\\sigma}$. Then $T = Z + \\delta_T$, where $Z \\sim N(0,1)$.\n$$P(T > z_{1-\\alpha/2}) = P(Z + \\delta_T > z_{1-\\alpha/2}) = P(Z > z_{1-\\alpha/2} - \\delta_T) = 1 - \\Phi(z_{1-\\alpha/2} - \\delta_T) = \\Phi(\\delta_T - z_{1-\\alpha/2})$$\n$$P(T  -z_{1-\\alpha/2}) = P(Z + \\delta_T  -z_{1-\\alpha/2}) = P(Z  -z_{1-\\alpha/2} - \\delta_T) = \\Phi(-z_{1-\\alpha/2} - \\delta_T)$$\nSubstituting $\\delta_T = \\frac{\\Delta\\sqrt{n}}{\\sigma}$, the power function, viewed as a function of $n$ and $\\sigma$, is:\n$$\\pi(n, \\sigma) = \\Phi\\left(\\frac{\\Delta\\sqrt{n}}{\\sigma} - z_{1-\\alpha/2}\\right) + \\Phi\\left(-\\frac{\\Delta\\sqrt{n}}{\\sigma} - z_{1-\\alpha/2}\\right)$$\n\nThe first task is to find the partial derivative $\\frac{\\partial \\pi}{\\partial \\sigma}$. Let $\\phi(\\cdot)$ be the probability density function (PDF) of the standard Normal distribution, so $\\frac{d\\Phi(x)}{dx} = \\phi(x)$. Let $A(n, \\sigma) = \\frac{\\Delta\\sqrt{n}}{\\sigma}$. Using the chain rule:\n$$\\frac{\\partial \\pi}{\\partial \\sigma} = \\phi\\left(A - z_{1-\\alpha/2}\\right) \\frac{\\partial A}{\\partial \\sigma} + \\phi\\left(-A - z_{1-\\alpha/2}\\right) \\frac{\\partial (-A)}{\\partial \\sigma}$$\nThe derivative of $A$ with respect to $\\sigma$ is $\\frac{\\partial A}{\\partial \\sigma} = \\frac{\\partial}{\\partial \\sigma}(\\Delta\\sqrt{n}\\sigma^{-1}) = -\\Delta\\sqrt{n}\\sigma^{-2} = -\\frac{A}{\\sigma}$.\nThus, $\\frac{\\partial (-A)}{\\partial \\sigma} = \\frac{A}{\\sigma}$.\nSubstituting these into the expression for $\\frac{\\partial \\pi}{\\partial \\sigma}$:\n$$\\frac{\\partial \\pi}{\\partial \\sigma} = \\phi\\left(A - z_{1-\\alpha/2}\\right) \\left(-\\frac{A}{\\sigma}\\right) + \\phi\\left(-A - z_{1-\\alpha/2}\\right) \\left(\\frac{A}{\\sigma}\\right)$$\n$$\\frac{\\partial \\pi}{\\partial \\sigma} = \\frac{A}{\\sigma} \\left[ \\phi\\left(-A - z_{1-\\alpha/2}\\right) - \\phi\\left(A - z_{1-\\alpha/2}\\right) \\right]$$\nUsing the property $\\phi(-x) = \\phi(x)$, we can write $\\phi(-A - z_{1-\\alpha/2}) = \\phi(A + z_{1-\\alpha/2})$.\n$$\\frac{\\partial \\pi}{\\partial \\sigma} = \\frac{A}{\\sigma} \\left[ \\phi\\left(A + z_{1-\\alpha/2}\\right) - \\phi\\left(A - z_{1-\\alpha/2}\\right) \\right]$$\nThis completes the first part of the derivation.\n\nNext, we hold the power $\\pi$ constant, which implies its total differential $d\\pi$ must be zero. The total differential of $\\pi(n, \\sigma)$ is:\n$$d\\pi = \\frac{\\partial \\pi}{\\partial n} dn + \\frac{\\partial \\pi}{\\partial \\sigma} d\\sigma = 0$$\nThis gives the relationship $\\frac{\\partial \\pi}{\\partial n} dn = - \\frac{\\partial \\pi}{\\partial \\sigma} d\\sigma$, from which we can find $\\frac{dn}{d\\sigma} = -\\frac{\\partial \\pi / \\partial \\sigma}{\\partial \\pi / \\partial n}$.\n\nWe need to compute $\\frac{\\partial \\pi}{\\partial n}$:\n$$\\frac{\\partial \\pi}{\\partial n} = \\phi\\left(A - z_{1-\\alpha/2}\\right) \\frac{\\partial A}{\\partial n} + \\phi\\left(-A - z_{1-\\alpha/2}\\right) \\frac{\\partial (-A)}{\\partial n}$$\nThe derivative of $A$ with respect to $n$ is $\\frac{\\partial A}{\\partial n} = \\frac{\\partial}{\\partial n}\\left(\\frac{\\Delta}{\\sigma}n^{1/2}\\right) = \\frac{\\Delta}{\\sigma}\\frac{1}{2}n^{-1/2} = \\frac{\\Delta\\sqrt{n}}{2n\\sigma} = \\frac{A}{2n}$.\nThus, $\\frac{\\partial (-A)}{\\partial n} = -\\frac{A}{2n}$.\nSubstituting these into the expression for $\\frac{\\partial \\pi}{\\partial n}$:\n$$\\frac{\\partial \\pi}{\\partial n} = \\phi\\left(A - z_{1-\\alpha/2}\\right) \\left(\\frac{A}{2n}\\right) + \\phi\\left(-A - z_{1-\\alpha/2}\\right) \\left(-\\frac{A}{2n}\\right)$$\n$$\\frac{\\partial \\pi}{\\partial n} = \\frac{A}{2n} \\left[ \\phi\\left(A - z_{1-\\alpha/2}\\right) - \\phi\\left(-A - z_{1-\\alpha/2}\\right) \\right]$$\nAgain using $\\phi(-x) = \\phi(x)$:\n$$\\frac{\\partial \\pi}{\\partial n} = \\frac{A}{2n} \\left[ \\phi\\left(A - z_{1-\\alpha/2}\\right) - \\phi\\left(A + z_{1-\\alpha/2}\\right) \\right]$$\nNow we form the ratio for $\\frac{dn}{d\\sigma}$:\n$$\\frac{dn}{d\\sigma} = -\\frac{\\frac{A}{\\sigma} \\left[ \\phi\\left(A + z_{1-\\alpha/2}\\right) - \\phi\\left(A - z_{1-\\alpha/2}\\right) \\right]}{\\frac{A}{2n} \\left[ \\phi\\left(A - z_{1-\\alpha/2}\\right) - \\phi\\left(A + z_{1-\\alpha/2}\\right) \\right]}$$\nThe term in the numerator's bracket is the negative of the term in the denominator's bracket. This is valid as long as the bracketed term is non-zero, which requires $A \\neq 0$ and $z_{1-\\alpha/2} \\neq 0$, conditions which are met. Also, $A$ can be cancelled as $A \\neq 0$.\n$$\\frac{dn}{d\\sigma} = -\\frac{\\frac{1}{\\sigma}}{\\frac{1}{2n}} \\cdot \\frac{\\phi\\left(A + z_{1-\\alpha/2}\\right) - \\phi\\left(A - z_{1-\\alpha/2}\\right)}{-\\left( \\phi\\left(A + z_{1-\\alpha/2}\\right) - \\phi\\left(A - z_{1-\\alpha/2}\\right) \\right)} = \\frac{1/\\sigma}{1/(2n)} = \\frac{2n}{\\sigma}$$\nSo, the infinitesimal relationship is $dn = \\frac{2n}{\\sigma} d\\sigma$.\n\nFinally, we calculate the local elasticity $E$, defined as $E = \\frac{dn/n}{d\\sigma/\\sigma}$.\nWe can rearrange our derived relationship as $\\frac{dn}{n} = 2 \\frac{d\\sigma}{\\sigma}$.\nTherefore, the elasticity is:\n$$E = \\frac{2 \\frac{d\\sigma}{\\sigma}}{\\frac{d\\sigma}{\\sigma}} = 2$$\nAlternatively, using the definition $E = \\frac{dn}{d\\sigma} \\frac{\\sigma}{n}$:\n$$E = \\left(\\frac{2n}{\\sigma}\\right) \\frac{\\sigma}{n} = 2$$\nThe elasticity of the required sample size with respect to the standard deviation is $2$. This implies that a small percentage increase in the standard deviation requires double that percentage increase in sample size to maintain the same statistical power.", "answer": "$$\n\\boxed{2}\n$$", "id": "4963993"}]}