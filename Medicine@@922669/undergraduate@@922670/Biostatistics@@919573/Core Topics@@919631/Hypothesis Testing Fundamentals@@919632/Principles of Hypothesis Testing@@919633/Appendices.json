{"hands_on_practices": [{"introduction": "A crucial first step in any scientific investigation is designing a study with enough statistical power to detect a meaningful effect. This practice exercise guides you through one of the most common tasks for a biostatistician: calculating the required sample size for a clinical trial. By working through the derivation [@problem_id:4941871], you will see how the desired significance level ($\\alpha$), power ($1-\\beta$), and effect size ($\\Delta$) come together to determine the feasibility and scale of an experiment.", "problem": "A randomized, parallel-group clinical trial will compare the mean reduction in systolic blood pressure between a new antihypertensive drug and placebo. Let $\\mu_{1}$ and $\\mu_{2}$ denote the true mean reductions in the drug and placebo groups, respectively, and suppose that the within-group standard deviation is common and equal to $\\sigma$ across groups. The investigators plan equal allocation with $n$ participants per group and will test the null hypothesis $H_{0}: \\mu_{1} - \\mu_{2} = 0$ against the two-sided alternative $H_{1}: \\mu_{1} - \\mu_{2} \\neq 0$ at significance level $\\alpha = 0.05$. For planning, they target a standardized mean difference $\\Delta = (\\mu_{1} - \\mu_{2})/\\sigma$ of magnitude $\\Delta = 0.40$ as clinically meaningful and require power $1 - \\beta = 0.90$ under this alternative. Assume that, by the Central Limit Theorem and stable variance planning, the two-sample $z$-statistic based on the sample means is approximately standard normal under $H_{0}$ and approximately normal with a nonzero mean under $H_{1}$. Let $z_{p}$ denote the $p$-quantile of the standard normal distribution, defined by $\\Phi(z_{p}) = p$, where $\\Phi(\\cdot)$ is the standard normal cumulative distribution function.\n\nStarting from the definitions of Type I error $\\alpha$, Type II error $\\beta$, and power $1 - \\beta$, and using the approximate distribution of the two-sample standardized mean difference under $H_{0}$ and $H_{1}$, determine the minimal per-group sample size $n$ required to achieve the design specifications. Report the smallest integer $n$ that meets the power requirement. The final answer must be a single number with no units.", "solution": "The user wants to determine the minimal per-group sample size $n$ for a randomized clinical trial comparing a new drug to a placebo.\n\n### Step 1: Validation of the Problem Statement\nThe user has provided the following information:\n- **Groups**: Two parallel groups (drug and placebo) with equal sample size $n$ per group.\n- **Parameters**: True mean reductions $\\mu_{1}$ (drug) and $\\mu_{2}$ (placebo), with a common within-group standard deviation $\\sigma$.\n- **Hypotheses**: Null hypothesis $H_{0}: \\mu_{1} - \\mu_{2} = 0$ versus the two-sided alternative $H_{1}: \\mu_{1} - \\mu_{2} \\neq 0$.\n- **Significance Level**: Type I error rate $\\alpha = 0.05$.\n- **Effect Size**: Target standardized mean difference $\\Delta = (\\mu_{1} - \\mu_{2})/\\sigma = 0.40$.\n- **Power**: Desired power $1 - \\beta = 0.90$, which implies a Type II error rate $\\beta = 0.10$.\n- **Assumptions**: A two-sample $z$-statistic is used, which is approximately standard normal under $H_{0}$ and approximately normal with a non-zero mean under $H_{1}$.\n- **Notation**: $z_{p}$ is the $p$-quantile of the standard normal distribution $\\Phi(\\cdot)$.\n\nThe problem is scientifically grounded, well-posed, and objective. It is a standard sample size calculation problem in biostatistics, and all necessary parameters and assumptions are provided. The problem is valid.\n\n### Step 2: Derivation of the Sample Size Formula\nLet $\\bar{X}_1$ and $\\bar{X}_2$ be the sample mean reductions in systolic blood pressure for the drug and placebo groups, respectively. Each group has a sample size of $n$. The estimator for the difference in population means is $\\bar{X}_1 - \\bar{X}_2$.\n\nThe variance of this estimator, assuming independence between groups and a common variance $\\sigma^2$, is:\n$$ \\text{Var}(\\bar{X}_1 - \\bar{X}_2) = \\text{Var}(\\bar{X}_1) + \\text{Var}(\\bar{X}_2) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n} $$\nThe standard error (SE) of the difference in means is:\n$$ \\text{SE} = \\sqrt{\\frac{2\\sigma^2}{n}} = \\sigma\\sqrt{\\frac{2}{n}} $$\nThe two-sample $z$-statistic is defined as:\n$$ Z_{\\text{obs}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\text{SE}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sigma\\sqrt{2/n}} $$\nUnder the null hypothesis $H_{0}: \\mu_{1} - \\mu_{2} = 0$, the expected value of the estimator is $E[\\bar{X}_1 - \\bar{X}_2] = 0$. By the Central Limit Theorem, the distribution of the test statistic is approximately standard normal:\n$$ Z_{\\text{obs}} \\mid H_0 \\sim N(0, 1) $$\nFor a two-sided test at a significance level $\\alpha$, we reject $H_{0}$ if the absolute value of the observed statistic exceeds a critical value $c$. This critical value is the $1-\\alpha/2$ quantile of the standard normal distribution.\n$$ \\text{Rejection Region: } |Z_{\\text{obs}}|  z_{1-\\alpha/2} $$\nGiven $\\alpha = 0.05$, we have $\\alpha/2 = 0.025$, and the critical value is $z_{1-0.025} = z_{0.975}$.\n\nNext, we consider the distribution of the test statistic under the specific alternative hypothesis required for planning, $H_1: (\\mu_1 - \\mu_2)/\\sigma = \\Delta$, which implies $\\mu_1 - \\mu_2 = \\Delta\\sigma$. The expected value of the estimator under this alternative is $E[\\bar{X}_1 - \\bar{X}_2] = \\Delta\\sigma$.\nThe expected value of the test statistic $Z_{\\text{obs}}$ under this $H_1$ is:\n$$ E[Z_{\\text{obs}} \\mid H_1] = \\frac{E[\\bar{X}_1 - \\bar{X}_2]}{\\sigma\\sqrt{2/n}} = \\frac{\\Delta\\sigma}{\\sigma\\sqrt{2/n}} = \\Delta\\sqrt{\\frac{n}{2}} $$\nThe variance of $Z_{\\text{obs}}$ remains $1$. Thus, under this alternative, the distribution is:\n$$ Z_{\\text{obs}} \\mid H_1 \\sim N\\left(\\Delta\\sqrt{\\frac{n}{2}}, 1\\right) $$\nPower, $1-\\beta$, is the probability of correctly rejecting $H_0$ when $H_1$ is true.\n$$ 1 - \\beta = P\\left(|Z_{\\text{obs}}|  z_{1-\\alpha/2} \\mid H_1\\right) $$\nThis is the sum of probabilities of rejection in both tails:\n$$ 1 - \\beta = P\\left(Z_{\\text{obs}}  z_{1-\\alpha/2} \\mid H_1\\right) + P\\left(Z_{\\text{obs}}  -z_{1-\\alpha/2} \\mid H_1\\right) $$\nSince $\\Delta = 0.40$ is positive, the mean of $Z_{\\text{obs}}$ under $H_1$ is positive. For any reasonable sample size, the distribution of $Z_{\\text{obs}}$ will be shifted to the right, and the term $P(Z_{\\text{obs}}  -z_{1-\\alpha/2} \\mid H_1)$ will be negligible. The power is therefore dominated by the probability of rejection in the upper tail. We can approximate the power as:\n$$ 1 - \\beta \\approx P\\left(Z_{\\text{obs}}  z_{1-\\alpha/2} \\mid H_1\\right) $$\nTo evaluate this probability, we standardize the random variable $Z_{\\text{obs}}$ using its distribution under $H_1$. Let $Z'$ be a standard normal random variable.\n$$ 1 - \\beta \\approx P\\left( \\frac{Z_{\\text{obs}} - \\Delta\\sqrt{n/2}}{1}  z_{1-\\alpha/2} - \\Delta\\sqrt{\\frac{n}{2}} \\right) $$\n$$ 1 - \\beta \\approx P\\left( Z'  z_{1-\\alpha/2} - \\Delta\\sqrt{\\frac{n}{2}} \\right) $$\nUsing the property of the standard normal CDF $\\Phi(\\cdot)$ that $P(Z'  x) = 1 - \\Phi(x) = \\Phi(-x)$:\n$$ 1 - \\beta \\approx \\Phi\\left( -\\left(z_{1-\\alpha/2} - \\Delta\\sqrt{\\frac{n}{2}}\\right) \\right) = \\Phi\\left( \\Delta\\sqrt{\\frac{n}{2}} - z_{1-\\alpha/2} \\right) $$\nWe are given that the required power is $1-\\beta$. By definition, $1-\\beta = \\Phi(z_{1-\\beta})$. Equating the arguments of $\\Phi(\\cdot)$:\n$$ z_{1-\\beta} = \\Delta\\sqrt{\\frac{n}{2}} - z_{1-\\alpha/2} $$\nNow, we solve for $n$:\n$$ z_{1-\\alpha/2} + z_{1-\\beta} = \\Delta\\sqrt{\\frac{n}{2}} $$\n$$ \\left(z_{1-\\alpha/2} + z_{1-\\beta}\\right)^2 = \\Delta^2 \\left(\\frac{n}{2}\\right) $$\n$$ n = \\frac{2\\left(z_{1-\\alpha/2} + z_{1-\\beta}\\right)^2}{\\Delta^2} $$\n\n### Step 3: Calculation of the Sample Size\nWe substitute the given values into the derived formula.\n- Significance level $\\alpha = 0.05 \\implies z_{1-\\alpha/2} = z_{0.975} \\approx 1.95996$.\n- Power $1-\\beta = 0.90 \\implies z_{1-\\beta} = z_{0.90} \\approx 1.28155$.\n- Standardized effect size $\\Delta = 0.40$.\n\n$$ n = \\frac{2(1.95996 + 1.28155)^2}{(0.40)^2} $$\n$$ n = \\frac{2(3.24151)^2}{0.16} $$\n$$ n = \\frac{2(10.50739)}{0.16} $$\n$$ n = \\frac{21.01478}{0.16} $$\n$$ n \\approx 131.342 $$\nSince the sample size $n$ must be an integer and the power requirement must be met, we must round this value up to the next whole number.\n$$ n = 132 $$\nTherefore, the minimal per-group sample size required is $132$ participants.", "answer": "$$\\boxed{132}$$", "id": "4941871"}, {"introduction": "Hypothesis testing requires choosing a method that correctly matches the structure of your data. This problem [@problem_id:4941841] explores the analysis of paired binary outcomes, a common design in studies measuring a change from a baseline state. You will derive McNemar's exact test, a classic method that cleverly focuses only on the subjects who change status, providing a powerful example of how conditioning can simplify a problem and lead to an elegant, exact test.", "problem": "A matched-pairs clinical study assesses the change in a binary biomarker status (present/absent) measured on the same $50$ patients before and after initiation of a new therapy. For each patient, define the paired outcome as $(Y_{\\text{pre}}, Y_{\\text{post}})$ with $Y \\in \\{0,1\\}$ indicating absence or presence of the biomarker, respectively. The observed $2 \\times 2$ table of paired outcomes is: $a$ patients with $(1,1)$, $b$ with $(1,0)$, $c$ with $(0,1)$, and $d$ with $(0,0)$, where $a=18$, $b=17$, $c=7$, and $d=8$.\n\nStarting from the definition of the null hypothesis $H_0: p_{\\text{pre}} = p_{\\text{post}}$ for the marginal probabilities of biomarker presence, and from first principles of hypothesis testing and the Bernoulli model for independent matched pairs, derive McNemarâ€™s exact test for paired binary outcomes by:\n- Justifying the conditioning strategy that removes the nuisance parameter associated with the overall discordance rate.\n- Specifying the distribution of the number of $(1,0)$ discordant pairs $B$ given the total number of discordant pairs $D=b+c$ under $H_0$.\n\nThen, using your derived exact test, compute the exact two-sided $p$-value for the observed data. Round your final numerical answer to four significant figures.", "solution": "The problem asks for the derivation of McNemar's exact test for paired binary outcomes and its application to a given dataset to compute a two-sided $p$-value.\n\nFirst, let us formalize the model. We have $N$ independent matched pairs. For each pair $i \\in \\{1, \\dots, N\\}$, the outcome is $(Y_{i, \\text{pre}}, Y_{i, \\text{post}})$, where each $Y$ can take a value of $0$ (biomarker absent) or $1$ (biomarker present). There are four possible outcomes for each pair: $(1,1)$, $(1,0)$, $(0,1)$, and $(0,0)$. Let the probabilities of these outcomes be $p_{11}$, $p_{10}$, $p_{01}$, and $p_{00}$ respectively, such that $p_{11} + p_{10} + p_{01} + p_{00} = 1$.\n\nThe marginal probability of biomarker presence before therapy is $p_{\\text{pre}} = P(Y_{\\text{pre}}=1)$. A patient has $Y_{\\text{pre}}=1$ if their outcome is either $(1,1)$ or $(1,0)$. Therefore, $p_{\\text{pre}} = p_{11} + p_{10}$.\nSimilarly, the marginal probability of biomarker presence after therapy is $p_{\\text{post}} = P(Y_{\\text{post}}=1)$. A patient has $Y_{\\text{post}}=1$ if their outcome is either $(1,1)$ or $(0,1)$. Therefore, $p_{\\text{post}} = p_{11} + p_{01}$.\n\nThe null hypothesis $H_0$ is that the marginal probabilities are equal: $H_0: p_{\\text{pre}} = p_{\\text{post}}$. Substituting the expressions in terms of the joint probabilities, we get:\n$$H_0: p_{11} + p_{10} = p_{11} + p_{01}$$\nSubtracting $p_{11}$ from both sides, the null hypothesis simplifies to:\n$$H_0: p_{10} = p_{01}$$\nThis means the null hypothesis is equivalent to stating that the probability of switching from present to absent is the same as switching from absent to present. The pairs that do not change status, known as concordant pairs (outcomes $(1,1)$ and $(0,0)$), do not contribute to the evaluation of this specific null hypothesis, as their underlying probability $p_{11}$ and $p_{00}$ are not involved in the simplified $H_0$.\n\nThe observed data consists of counts for each of the four outcomes: $a$ for $(1,1)$, $b$ for $(1,0)$, $c$ for $(0,1)$, and $d$ for $(0,0)$. For a total of $N=a+b+c+d$ pairs, the likelihood of observing these counts follows a multinomial distribution:\n$$L(p_{11}, p_{10}, p_{01}, p_{00} | a, b, c, d) \\propto p_{11}^a p_{10}^b p_{01}^c p_{00}^d$$\nUnder $H_0$, where $p_{10} = p_{01} = p_{\\text{discord}}$, the likelihood becomes:\n$$L \\propto p_{11}^a (p_{\\text{discord}})^b (p_{\\text{discord}})^c p_{00}^d = p_{11}^a p_{\\text{discord}}^{b+c} p_{00}^d$$\nThis likelihood depends on nuisance parameters, specifically $p_{11}$ and $p_{\\text{discord}}$ (or equivalently, $p_{11}$ and $p_{00}$, since the probabilities must sum to $1$). To construct a test that is independent of these nuisance parameters, we use a conditioning argument. We condition on aspects of the data that are sufficient for the nuisance parameters, so that the conditional distribution depends only on the parameter of interest.\n\nThe key insight is to focus only on the discordant pairs, those with outcomes $(1,0)$ and $(0,1)$. The total number of discordant pairs is $D = b+c$. Let's consider the conditional probability that a pair is of type $(1,0)$ *given* that it is discordant. Let this conditional probability be $\\pi$.\n$$\\pi = P(\\text{outcome is } (1,0) | \\text{outcome is discordant}) = \\frac{P(\\text{outcome is } (1,0))}{P(\\text{outcome is discordant})} = \\frac{p_{10}}{p_{10} + p_{01}}$$\nUnder the null hypothesis $H_0: p_{10} = p_{01}$, this conditional probability becomes:\n$$\\pi_0 = \\frac{p_{10}}{p_{10} + p_{10}} = \\frac{p_{10}}{2p_{10}} = \\frac{1}{2}$$\nThis conditioning strategy is powerful because it yields a parameter-free null distribution. Given that we observed a total of $D = b+c$ discordant pairs, each of these pairs can be thought of as an independent Bernoulli trial. Under $H_0$, the probability of a \"success\" (observing a $(1,0)$ pair) is $1/2$. Therefore, the number of $(1,0)$ pairs, denoted by the random variable $B$, conditional on the total number of discordant pairs $D$, follows a binomial distribution.\n\nSpecifically, the distribution of $B$ given $D=b+c$ under $H_0$ is:\n$$B | D=b+c \\sim \\text{Binomial}\\left(n = b+c, p = \\frac{1}{2}\\right)$$\nThe probability mass function is given by:\n$$P(B=k | D=n) = \\binom{n}{k} \\left(\\frac{1}{2}\\right)^k \\left(1-\\frac{1}{2}\\right)^{n-k} = \\binom{n}{k} \\left(\\frac{1}{2}\\right)^n$$\nThis is the basis for McNemar's exact test.\n\nNow, we apply this test to the provided data:\n- $a = 18$\n- $b = 17$ (these are the pairs of type $(1,0)$)\n- $c = 7$ (these are the pairs of type $(0,1)$)\n- $d = 8$\nThe total number of patients is $N = 18+17+7+8 = 50$.\n\nThe number of discordant pairs is $n = b+c = 17+7=24$.\nThe observed value of our test statistic is $b_{obs} = 17$.\nThe null distribution for this test is $\\text{Binomial}(n=24, p=1/2)$.\n\nWe need to calculate the two-sided $p$-value. This is the probability of observing a result as extreme as, or more extreme than, $b_{obs}=17$. For a symmetric distribution like the $\\text{Binomial}(n, 1/2)$, the expected value is $E[B] = n \\times p = 24 \\times 1/2 = 12$.\nThe observed value $17$ is $17-12=5$ units away from the mean. The equally extreme value in the lower tail is $12-5=7$. Thus, \"as or more extreme\" corresponds to observing $B \\ge 17$ or $B \\le 7$.\n\nThe two-sided $p$-value is $P(B \\ge 17) + P(B \\le 7)$.\n$$p\\text{-value} = \\sum_{k=17}^{24} P(B=k) + \\sum_{k=0}^{7} P(B=k)$$\n$$p\\text{-value} = \\sum_{k=17}^{24} \\binom{24}{k} \\left(\\frac{1}{2}\\right)^{24} + \\sum_{k=0}^{7} \\binom{24}{k} \\left(\\frac{1}{2}\\right)^{24}$$\nDue to the symmetry of the binomial coefficients, $\\binom{n}{k} = \\binom{n}{n-k}$. For our case, $\\binom{24}{17} = \\binom{24}{7}$, $\\binom{24}{18} = \\binom{24}{6}$, and so on. Therefore, the two sums are equal.\n$$p\\text{-value} = 2 \\times \\sum_{k=17}^{24} \\binom{24}{k} \\left(\\frac{1}{2}\\right)^{24}$$\nWe calculate the sum of the binomial coefficients:\n$\\binom{24}{17} = 346104$\n$\\binom{24}{18} = 134596$\n$\\binom{24}{19} = 42504$\n$\\binom{24}{20} = 10626$\n$\\binom{24}{21} = 2024$\n$\\binom{24}{22} = 276$\n$\\binom{24}{23} = 24$\n$\\binom{24}{24} = 1$\nThe sum is $346104 + 134596 + 42504 + 10626 + 2024 + 276 + 24 + 1 = 536155$.\nThe normalizing factor is $(1/2)^{24} = 1/16777216$.\n\nThe $p$-value is:\n$$p\\text{-value} = 2 \\times \\frac{536155}{16777216} = \\frac{1072310}{16777216}$$\n$$p\\text{-value} \\approx 0.06391404$$\nRounding to four significant figures, we get $0.06391$.", "answer": "$$\\boxed{0.06391}$$", "id": "4941841"}, {"introduction": "While many classical tests rely on assumptions about the underlying distribution of the data, modern computational power allows for robust, non-parametric alternatives. This hands-on coding challenge [@problem_id:4941799] invites you to implement a stratified permutation test from first principles. By creating the null distribution through the shuffling of treatment labels, you will gain a deep, intuitive understanding of what a $p$-value represents, free from the constraints of asymptotic theory.", "problem": "You are to construct a permutation test for a two-arm randomized controlled trial (RCT) with continuous outcomes under stratified randomization. The task requires you to formalize the null hypothesis, define a scientifically justified test statistic using stratification, specify an appropriate permutation scheme, and implement a program that computes two-sided randomization-based p-values for several test cases. The program must adhere to the following design principles and output requirements.\n\nThe fundamental basis for this derivation is the definition of hypothesis testing via randomization inference: under the null hypothesis of no treatment effect, the observed outcomes are invariant to treatment assignment, and the distribution of any test statistic under the null can be obtained by permuting treatment labels according to the randomization scheme. Specifically, under stratified randomization, treatment assignments are exchangeable within each stratum conditional on the numbers assigned to treatment and control within that stratum.\n\nDefine the null hypothesis as $H_0$: there is no effect of treatment on the outcome for any participant, so any difference in outcomes between arms is attributable to random assignment. Define the alternative hypothesis as $H_1$: there exists a non-zero difference in average outcomes between the treatment and control arms.\n\nYou must specify a test statistic that captures the average treatment effect while respecting the stratification. Conceptually, the test statistic should be the aggregate contrast of the arm means across strata, where each stratum contributes proportionally to its size, so that each participant contributes equally regardless of stratum. In words, compute the difference between the average outcome in the treatment arm and the average outcome in the control arm within each stratum, then aggregate these stratum-specific differences using weights proportional to the stratum sizes to form a single contrast.\n\nFor the permutation scheme, permute the treatment labels within each stratum only, while preserving the observed number of treated and control participants within that stratum. This respects the original stratified randomization and ensures exchangeability under $H_0$.\n\nFor the two-sided p-value, use the randomization distribution of the chosen test statistic under the stratified permutation scheme and compute the proportion of permutations whose absolute test statistic is at least as extreme as the absolute observed test statistic, i.e., count permutations with $|T_{\\text{perm}}| \\ge |T_{\\text{obs}}|$ and divide by the number of permutations considered. Express the p-value as a decimal.\n\nExact enumeration is feasible when the total number of stratified permutations is not too large. Let $n_h$ denote the size of stratum $h$ and let $n_{1h}$ denote the number treated in stratum $h$. The total number of stratified permutations is the product over strata of ${n_h \\choose n_{1h}}$. If this product is less than or equal to $100000$, your program must perform exact enumeration. If the product exceeds $100000$, perform a Monte Carlo (MC) approximation with $M=100000$ uniformly sampled stratified permutations. Use a fixed seed $42$ for the Monte Carlo random number generator for reproducibility.\n\nInput is embedded in the program; do not read external input. For each test case, you are given:\n- $y$: a list of continuous outcomes,\n- $z$: a list of binary treatment labels with $1$ for treatment and $0$ for control,\n- $s$: a list of integer stratum labels.\n\nCompute the two-sided stratified permutation p-value for each test case as described. Round each p-value to $6$ decimal places. Your program should produce a single line of output containing the p-values for all test cases as a comma-separated list enclosed in square brackets.\n\nTest suite to implement:\n- Case $1$ (two strata, balanced, exact enumeration):\n  - $y = [5.2, 4.8, 3.9, 4.1, 6.1, 5.2, 6.3, 5.0, 6.0, 5.1]$\n  - $z = [1, 1, 0, 0, 1, 0, 1, 0, 1, 0]$\n  - $s = [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]$\n- Case $2$ (single stratum, exact enumeration):\n  - $y = [10.2, 10.5, 9.4, 9.6, 10.1, 9.5]$\n  - $z = [1, 1, 0, 0, 1, 0]$\n  - $s = [0, 0, 0, 0, 0, 0]$\n- Case $3$ (three strata, unequal sizes, near-zero effect, exact enumeration):\n  - $y = [7.0, 7.1, 6.9, 5.0, 5.1, 5.2, 5.1, 8.0, 7.9, 8.1, 8.0, 8.0]$\n  - $z = [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0]$\n  - $s = [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2]$\n- Case $4$ (three strata, larger sizes, Monte Carlo approximation):\n  - $y = [11.0, 10.8, 11.2, 11.1, 10.3, 10.4, 10.2, 10.5, 9.5, 9.7, 9.0, 8.9, 9.1, 9.6, 9.0, 8.8, 9.4, 7.9, 7.5, 8.0, 7.6, 7.8, 7.4, 7.9, 7.5, 8.1, 7.6]$\n  - $z = [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]$\n  - $s = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]$\n\nFinal output format:\n- A single line containing the four p-values as a comma-separated list enclosed in square brackets, for example, $[p_1,p_2,p_3,p_4]$, where each $p_i$ is a decimal rounded to $6$ places.", "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the principles of randomization-based inference for controlled trials, is well-posed with a clear objective and sufficient data, and uses objective, formal language. We may therefore proceed with a solution.\n\nThe problem requires the implementation of a stratified permutation test for a two-arm randomized controlled trial (RCT). The solution involves formalizing the null hypothesis and test statistic, defining the permutation procedure that respects the stratified design, and calculating a two-sided p-value, switching between exact enumeration and Monte Carlo approximation based on the total number of possible permutations.\n\nLet the total number of participants be $N$. Each participant $i \\in \\{1, ..., N\\}$ is characterized by a continuous outcome $y_i$, a binary treatment assignment $z_i \\in \\{0, 1\\}$ ($1$ for treatment, $0$ for control), and a stratum label $s_i$. Let $H$ be the set of unique strata. For each stratum $h \\in H$, let $I_h = \\{i | s_i = h\\}$ be the set of indices of participants in that stratum. The size of stratum $h$ is $n_h = |I_h|$. The number of treated and control participants in stratum $h$ are $n_{1h} = \\sum_{i \\in I_h} z_i$ and $n_{0h} = n_h - n_{1h}$, respectively. The total sample size is $N = \\sum_{h \\in H} n_h$.\n\nThe sharp null hypothesis, $H_0$, posits that the treatment has no effect on the outcome for any participant. This means that each participant's outcome $y_i$ is a fixed characteristic, independent of their treatment assignment $z_i$. Under $H_0$, the observed outcomes would have been the same even if the treatment assignments had been different. The alternative hypothesis, $H_1$, is that there is a non-zero average treatment effect.\n\nThe test statistic must be a single value that summarizes the difference between treatment arms while accounting for the stratified design. The problem specifies a test statistic that is an aggregate of stratum-specific contrasts, weighted by stratum size. This ensures that larger strata contribute more to the overall statistic. Let's formalize this.\n\nWithin each stratum $h \\in H$, the average outcome for the treatment group is:\n$$ \\bar{y}_{1h} = \\frac{\\sum_{i \\in I_h} y_i z_i}{n_{1h}} $$\nAnd for the control group:\n$$ \\bar{y}_{0h} = \\frac{\\sum_{i \\in I_h} y_i (1 - z_i)}{n_{0h}} $$\nThe stratum-specific difference in means is $\\Delta_h = \\bar{y}_{1h} - \\bar{y}_{0h}$. The overall test statistic, $T$, is the weighted average of these differences, with weights proportional to the stratum sizes $n_h$:\n$$ T = \\sum_{h \\in H} w_h \\Delta_h = \\sum_{h \\in H} \\frac{n_h}{N} (\\bar{y}_{1h} - \\bar{y}_{0h}) $$\nThis is a standard and scientifically justified choice, often referred to as the stratified difference in means. The phrase in the problem \"so that each participant contributes equally\" should be interpreted in the context of this weighted average structure, which is the standard way to aggregate stratum-level effects to estimate an overall population-average effect, rather than as a literal equal coefficient for each $y_i$.\n\nUnder $H_0$, the treatment assignments $z_i$ are exchangeable within each stratum, conditional on the counts $n_{1h}$ and $n_{0h}$. This means that any permutation of the treatment labels within a stratum is as likely as the one observed. The total number of possible treatment assignments consistent with the stratified design is the product of the number of ways to choose the treated individuals within each stratum:\n$$ K = \\prod_{h \\in H} \\binom{n_h}{n_{1h}} $$\n\nThe permutation test proceeds as follows:\n1.  Calculate the test statistic for the observed data, denoted $T_{\\text{obs}}$.\n2.  Generate a reference distribution for the test statistic under $H_0$. This is done by creating a set of permuted treatment assignments, $z_{\\text{perm}}$. For each $z_{\\text{perm}}$, a corresponding test statistic $T_{\\text{perm}}$ is calculated.\n3.  The method for generating the set of permutations depends on the total count $K$:\n    a.  **Exact Enumeration**: If $K \\le 100000$, we generate all $K$ possible valid stratified assignments. For each stratum $h$, we consider all $\\binom{n_h}{n_{1h}}$ ways to assign $n_{1h}$ individuals to the treatment group. The full set of assignments is the Cartesian product of these possibilities across all strata.\n    b.  **Monte Carlo Approximation**: If $K  100000$, we generate a large number, $M=100000$, of random permutations. Each random permutation is constructed by randomly selecting $n_{1h}$ participants to be in the treatment group within each stratum $h$, independently across strata. This sampling is done without replacement.\n4.  The two-sided p-value is the proportion of permutations (either from the exact set or the Monte Carlo sample) for which the absolute value of the test statistic is greater than or equal to the absolute value of the observed test statistic:\n$$ p = \\frac{\\sum_{j=1}^{N_{\\text{total}}} \\mathbb{I}(|T_{j}| \\ge |T_{\\text{obs}}|)}{N_{\\text{total}}} $$\nHere, $N_{\\text{total}}$ is either $K$ for the exact test or $M$ for the Monte Carlo test, $T_j$ is the test statistic for the $j$-th permutation, and $\\mathbb{I}(\\cdot)$ is the indicator function. The observed data configuration is one of the possible permutations and is included in this calculation.\n\nThis procedure provides a non-parametric, assumption-free test of the sharp null hypothesis that correctly honors the randomization scheme used in the study design.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\nimport itertools\n\ndef calculate_p_value(y, z, s):\n    \"\"\"\n    Computes the two-sided stratified permutation p-value for a given dataset.\n\n    Args:\n        y (list): Continuous outcomes.\n        z (list): Binary treatment labels (1=treatment, 0=control).\n        s (list): Integer stratum labels.\n\n    Returns:\n        float: The calculated p-value, rounded to 6 decimal places.\n    \"\"\"\n    # Convert inputs to numpy arrays for efficient computation.\n    y = np.array(y)\n    z = np.array(z)\n    s = np.array(s)\n    N = len(y)\n\n    strata_labels = np.unique(s)\n    strata_info = {}\n    for stratum_label in strata_labels:\n        indices = np.where(s == stratum_label)[0]\n        n_h = len(indices)\n        n_1h = np.sum(z[indices])\n        strata_info[stratum_label] = {\n            'indices': indices,\n            'n_h': n_h,\n            'n_1h': int(n_1h)\n        }\n\n    def compute_statistic(z_vec):\n        \"\"\"Calculates the stratified difference in means test statistic.\"\"\"\n        stat_val = 0.0\n        for stratum_label, info in strata_info.items():\n            indices = info['indices']\n            n_h = info['n_h']\n            \n            y_h = y[indices]\n            z_h = z_vec[indices]\n            \n            n_1h = np.sum(z_h)\n            n_0h = n_h - n_1h\n\n            # If a stratum has all treated or all control, its contribution is 0.\n            if n_1h == 0 or n_0h == 0:\n                continue\n\n            mean_1h = np.sum(y_h[z_h == 1]) / n_1h\n            mean_0h = np.sum(y_h[z_h == 0]) / n_0h\n            \n            delta_h = mean_1h - mean_0h\n            stat_val += (n_h / N) * delta_h\n            \n        return stat_val\n\n    # Calculate the observed test statistic.\n    T_obs = compute_statistic(z)\n    abs_T_obs = abs(T_obs)\n\n    # Calculate the total number of possible permutations.\n    total_permutations = 1\n    for info in strata_info.values():\n        total_permutations *= comb(info['n_h'], info['n_1h'], exact=True)\n\n    if total_permutations = 100000:\n        # Perform exact enumeration.\n        \n        # Generate combinations of treated indices for each stratum.\n        stratum_combinations = []\n        for stratum_label in strata_labels:\n            info = strata_info[stratum_label]\n            indices_h = info['indices']\n            n_1h = info['n_1h']\n            stratum_combinations.append(list(itertools.combinations(indices_h, n_1h)))\n        \n        count_extreme = 0\n        \n        # Iterate through the Cartesian product of all stratum-level combinations.\n        for permuted_treated_indices_tuple in itertools.product(*stratum_combinations):\n            z_perm = np.zeros(N, dtype=int)\n            for treated_indices_for_stratum in permuted_treated_indices_tuple:\n                z_perm[list(treated_indices_for_stratum)] = 1\n            \n            T_perm = compute_statistic(z_perm)\n            \n            if abs(T_perm) = abs_T_obs:\n                count_extreme += 1\n                \n        p_value = count_extreme / total_permutations\n    \n    else:\n        # Perform Monte Carlo approximation.\n        M = 100000\n        rng = np.random.default_rng(seed=42)\n        count_extreme = 0\n        \n        for _ in range(M):\n            z_perm = np.zeros(N, dtype=int)\n            for info in strata_info.values():\n                indices_h = info['indices']\n                n_1h = info['n_1h']\n                \n                # Randomly choose which subjects are treated within the stratum.\n                permuted_treated_indices = rng.choice(indices_h, size=n_1h, replace=False)\n                z_perm[permuted_treated_indices] = 1\n            \n            T_perm = compute_statistic(z_perm)\n            \n            if abs(T_perm) = abs_T_obs:\n                count_extreme += 1\n                \n        p_value = count_extreme / M\n\n    return round(p_value, 6)\n    \ndef solve():\n    \"\"\"\n    Main function to define test cases and compute p-values.\n    \"\"\"\n    test_cases = [\n        # Case 1 (two strata, balanced, exact enumeration)\n        {\n            \"y\": [5.2, 4.8, 3.9, 4.1, 6.1, 5.2, 6.3, 5.0, 6.0, 5.1],\n            \"z\": [1, 1, 0, 0, 1, 0, 1, 0, 1, 0],\n            \"s\": [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n        },\n        # Case 2 (single stratum, exact enumeration)\n        {\n            \"y\": [10.2, 10.5, 9.4, 9.6, 10.1, 9.5],\n            \"z\": [1, 1, 0, 0, 1, 0],\n            \"s\": [0, 0, 0, 0, 0, 0]\n        },\n        # Case 3 (three strata, unequal sizes, near-zero effect, exact enumeration)\n        {\n            \"y\": [7.0, 7.1, 6.9, 5.0, 5.1, 5.2, 5.1, 8.0, 7.9, 8.1, 8.0, 8.0],\n            \"z\": [1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0],\n            \"s\": [0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n        },\n        # Case 4 (three strata, larger sizes, Monte Carlo approximation)\n        {\n            \"y\": [11.0, 10.8, 11.2, 11.1, 10.3, 10.4, 10.2, 10.5, 9.5, 9.7, 9.0, 8.9, 9.1, 9.6, 9.0, 8.8, 9.4, 7.9, 7.5, 8.0, 7.6, 7.8, 7.4, 7.9, 7.5, 8.1, 7.6],\n            \"z\": [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n            \"s\": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        p_val = calculate_p_value(case[\"y\"], case[\"z\"], case[\"s\"])\n        results.append(p_val)\n    \n    # Format the results into the required string format.\n    # The f-string formatting ensures each number has 6 decimal places.\n    output_str = f\"[{','.join([f'{p:.6f}' for p in results])}]\"\n    print(output_str)\n\nsolve()\n\n```", "id": "4941799"}]}