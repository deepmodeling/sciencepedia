{"hands_on_practices": [{"introduction": "Hypothesis testing is fundamentally tied to the design of an experiment. This practice explores the randomization test, which generates a null distribution directly from the act of randomization itself, without relying on theoretical probability models. By implementing this test [@problem_id:4954539], you will build a deep, intuitive understanding of the sharp null hypothesis and see how a $p$-value represents the probability of observing a result under all possible random assignments.", "problem": "You are given a randomized trial with a completely randomized design: exactly $m$ of $n$ participants are assigned to treatment and the remaining $n-m$ are assigned to control. Under the Sharp Null Hypothesis of No Treatment Effect, every participant’s outcome under treatment equals their outcome under control. The task is to implement and execute a randomization test that uses the known assignment mechanism to generate the null distribution of the difference in means, and then compute two-sided $p$-values.\n\nStarting point and core definitions:\n- The trial has $n$ units indexed by $i \\in \\{1,\\dots,n\\}$, with observed outcomes $Y_i$ and a binary assignment indicator $Z_i \\in \\{0,1\\}$ where $Z_i=1$ denotes treatment.\n- The Sharp Null Hypothesis of No Treatment Effect states $Y_i(1)=Y_i(0)$ for all $i$, which implies that the observed outcomes $Y_i$ are invariant to reassignment under the null.\n- The assignment mechanism in a completely randomized design distributes treatment labels by choosing uniformly at random one of the $\\binom{n}{m}$ possible binary assignment vectors $\\mathbf{Z}$ with exactly $m$ ones.\n- The test statistic is the difference in means,\n$$\nT(\\mathbf{Z}, \\mathbf{Y}) \\;=\\; \\overline{Y}_{\\text{treated}} - \\overline{Y}_{\\text{control}} \\;=\\; \\frac{1}{m}\\sum_{i:Z_i=1}Y_i \\;-\\; \\frac{1}{n-m}\\sum_{i:Z_i=0}Y_i.\n$$\n- Under the null, the randomization distribution of $T(\\mathbf{Z}, \\mathbf{Y})$ is generated by enumerating (or sampling) assignment vectors $\\mathbf{Z}'$ from the assignment mechanism and computing $T(\\mathbf{Z}', \\mathbf{Y})$ with the fixed observed outcomes $\\mathbf{Y}$.\n- The two-sided $p$-value is the tail probability of observing a test statistic at least as extreme as the observed one under the null distribution, computed as the proportion of assignments with $\\left|T(\\mathbf{Z}', \\mathbf{Y})\\right| \\ge \\left|T(\\mathbf{Z}, \\mathbf{Y})\\right|$. To ensure a valid Monte Carlo approximation, use the add-one adjustment: if $B$ null draws are used, report $\\frac{c+1}{B+1}$ where $c$ is the count of draws with extremeness at least that of the observed statistic.\n\nImplement the following steps of a hypothesis test:\n1. State the hypotheses: $H_0$ (Sharp Null) versus $H_1$ (there exists at least one unit with $Y_i(1)\\ne Y_i(0)$).\n2. Choose the test statistic $T(\\mathbf{Z}, \\mathbf{Y})$ defined above.\n3. Use the assignment mechanism to construct the null distribution of $T$ by either exact enumeration of all $\\binom{n}{m}$ assignments or Monte Carlo sampling of $B$ assignments when exact enumeration is computationally infeasible.\n4. Compute the two-sided $p$-value using the null distribution and the add-one adjustment when sampling is used.\n5. Report the $p$-value as a decimal (not a percentage). No physical units are involved.\n\nYour program must implement this procedure and apply it to the test suite below. For each case, produce the two-sided randomization-test $p$-value. If exact enumeration is specified, enumerate all assignments in the completely randomized design; if Monte Carlo sampling is specified, use the provided $B$ and random seed.\n\nTest suite:\n- Case 1 (exact, small $n$):\n  - $Y = [5.1, 4.9, 5.0, 5.3, 5.2, 5.4]$\n  - $Z = [1, 1, 1, 0, 0, 0]$\n  - Method: exact\n- Case 2 (Monte Carlo, larger $n$):\n  - $Y = [10.2, 9.8, 10.0, 9.5, 10.4, 9.7, 10.3, 9.6, 10.1, 9.9, 8.8, 9.0, 9.2, 8.9, 9.1, 8.7, 9.3, 8.6, 9.4, 8.5]$\n  - $Z = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]$\n  - Method: Monte Carlo with $B=20000$ draws and seed $123$\n- Case 3 (exact, zero difference boundary):\n  - $Y = [1.0, 2.0, 1.0, 2.0]$\n  - $Z = [1, 0, 0, 1]$\n  - Method: exact\n- Case 4 (exact, unbalanced allocation):\n  - $Y = [12.0, 10.0, 11.0, 9.0, 8.0, 13.0, 7.0]$\n  - $Z = [1, 1, 0, 0, 0, 0, 0]$\n  - Method: exact\n- Case 5 (exact, strong effect):\n  - $Y = [20.0, 21.0, 19.0, 22.0, 5.0, 6.0, 7.0, 4.0]$\n  - $Z = [1, 1, 1, 1, 0, 0, 0, 0]$\n  - Method: exact\n\nOutput specification:\n- Compute the two-sided randomization-test $p$-value for each case.\n- Express each $p$-value as a decimal and round to $6$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[p_1, p_2, p_3, p_4, p_5]$, where $p_j$ denotes the $p$-value for case $j$ in the order listed above.", "solution": "The problem asks for the implementation of a randomization test to calculate a two-sided $p$-value for the Sharp Null Hypothesis of no treatment effect in a completely randomized trial. The solution involves defining the statistical framework, calculating the observed test statistic, generating the null distribution of this statistic under the specified assignment mechanism, and finally computing the $p$-value.\n\n### Principle-Based Design\n\n**1. Hypotheses and Formal Setup**\n\nThe experimental setup consists of $n$ units, for which we observe a vector of outcomes $\\mathbf{Y} = (Y_1, \\dots, Y_n)$ and a vector of treatment assignments $\\mathbf{Z} = (Z_1, \\dots, Z_n)$. The assignment indicator $Z_i$ is $1$ if unit $i$ is in the treatment group and $0$ if in the control group. In a completely randomized design with $m$ treated units, the assignment vector $\\mathbf{Z}$ is a random draw from the set of all binary vectors of length $n$ containing exactly $m$ ones. The total number of such assignments is $\\binom{n}{m}$.\n\nThe potential outcomes framework defines two outcomes for each unit $i$: $Y_i(1)$, the outcome if treated, and $Y_i(0)$, the outcome if not treated. The observed outcome is $Y_i = Z_i Y_i(1) + (1-Z_i)Y_i(0)$.\n\nThe hypotheses to be tested are:\n- **Null Hypothesis ($H_0$)**: The Sharp Null Hypothesis of No Treatment Effect, which states that for every unit $i$, the treatment has no effect. Formally, $H_0: Y_i(1) = Y_i(0)$ for all $i \\in \\{1, \\dots, n\\}$.\n- **Alternative Hypothesis ($H_1$)**: The negation of the sharp null, which posits that for at least one unit $i$, the treatment has an effect. Formally, $H_1: \\exists i \\text{ such that } Y_i(1) \\neq Y_i(0)$.\n\nA crucial consequence of the Sharp Null Hypothesis is that the observed outcomes $Y_i$ are fixed and would have been the same regardless of the treatment assignment. That is, under $H_0$, $Y_i = Y_i(1) = Y_i(0)$. This invariance allows us to treat the vector $\\mathbf{Y}$ as a fixed set of numbers when evaluating the effect of different hypothetical assignments.\n\n**2. Test Statistic**\n\nThe chosen test statistic is the difference in the mean outcomes between the treatment and control groups:\n$$\nT(\\mathbf{Z}, \\mathbf{Y}) = \\overline{Y}_{\\text{treated}} - \\overline{Y}_{\\text{control}} = \\frac{\\sum_{i:Z_i=1} Y_i}{m} - \\frac{\\sum_{i:Z_i=0} Y_i}{n-m}\n$$\nwhere $m = \\sum_{i=1}^n Z_i$ is the number of treated units and $n-m$ is the number of control units. We first compute the observed value of this statistic, $T_{\\text{obs}} = T(\\mathbf{Z}_{\\text{obs}}, \\mathbf{Y}_{\\text{obs}})$, using the data provided in each test case.\n\n**3. Null Distribution Construction**\n\nThe randomization test's core logic is to generate the distribution of the test statistic $T$ under the null hypothesis. Since $H_0$ implies the outcomes $\\mathbf{Y}$ are fixed, the only source of randomness is the assignment vector $\\mathbf{Z}$. The null distribution, therefore, consists of the values of $T(\\mathbf{Z}', \\mathbf{Y})$ for all possible assignment vectors $\\mathbf{Z}'$ that could have been realized by the assignment mechanism.\n\nThere are two methods for constructing this distribution, as specified in the problem:\n\n- **Exact Enumeration**: If the number of possible assignments, $\\binom{n}{m}$, is computationally manageable, we can enumerate all of them. For each possible assignment vector $\\mathbf{Z}'$, we calculate the corresponding statistic $T' = T(\\mathbf{Z}', \\mathbf{Y})$. The collection of all such values $\\{T'\\}$ forms the exact null distribution. This involves generating all combinations of $m$ indices out of $n$ to represent the treatment group.\n\n- **Monte Carlo Sampling**: When $\\binom{n}{m}$ is too large for full enumeration, we approximate the null distribution by drawing a large number, $B$, of random assignments $\\mathbf{Z}'_1, \\mathbf{Z}'_2, \\dots, \\mathbf{Z}'_B$ from the set of all possible assignments. For each draw $\\mathbf{Z}'_j$, we compute the statistic $T'_j = T(\\mathbf{Z}'_j, \\mathbf{Y})$. The empirical distribution of these $B$ statistics serves as an approximation to the true null distribution. A random assignment is generated by taking the observed assignment vector $\\mathbf{Z}_{\\text{obs}}$ and randomly permuting its elements. The use of a random seed ensures reproducibility.\n\n**4. P-value Calculation**\n\nThe two-sided $p$-value is the probability, under the null hypothesis, of observing a test statistic at least as extreme as the one actually observed. \"Extreme\" is measured by the absolute value.\n\nFor the **exact method**, the $p$-value is the proportion of assignments in the null distribution whose test statistic is at least as large in magnitude as the observed statistic:\n$$\np = \\frac{\\left| \\{ \\mathbf{Z}' : |T(\\mathbf{Z}', \\mathbf{Y})| \\ge |T_{\\text{obs}}| \\} \\right|}{\\binom{n}{m}}\n$$\nwhere $|\\cdot|$ denotes the cardinality of the set.\n\nFor the **Monte Carlo method**, the $p$-value is estimated using the $B$ simulated statistics. We count the number of simulations, $c$, where the simulated statistic was at least as extreme as the observed one: $c = \\sum_{j=1}^B \\mathbb{I}(|T'_j| \\ge |T_{\\text{obs}}|)$, where $\\mathbb{I}(\\cdot)$ is the indicator function. The problem specifies using an add-one adjustment (or continuity correction) to avoid reporting a $p$-value of $0$ and to improve statistical properties, especially for smaller $B$:\n$$\np = \\frac{c+1}{B+1}\n$$\n\nThe entire procedure is implemented in a Python function that takes the observed data and procedural parameters as input and returns the calculated $p$-value, rounded as specified.", "answer": "```python\nimport numpy as np\nimport itertools\n\ndef compute_statistic(Y, Z):\n    \"\"\"\n    Computes the difference in means between treated and control groups.\n    Y: array of observed outcomes.\n    Z: binary assignment vector (1=treatment, 0=control).\n    \"\"\"\n    m = np.sum(Z)\n    n = len(Y)\n    \n    # The problem constraints ensure that m  0 and n-m  0.\n    mean_treated = np.sum(Y * Z) / m\n    mean_control = np.sum(Y * (1 - Z)) / (n - m)\n    \n    return mean_treated - mean_control\n\ndef calculate_p_value(Y, Z_obs, method, B=None, seed=None):\n    \"\"\"\n    Calculates the randomization test p-value for the sharp null hypothesis.\n    \"\"\"\n    n = len(Y)\n    m = int(np.sum(Z_obs))\n    \n    t_obs = compute_statistic(Y, Z_obs)\n    abs_t_obs = np.abs(t_obs)\n\n    if method == 'exact':\n        indices = np.arange(n)\n        null_stats = []\n        \n        # Generate all combinations of m indices for the treatment group\n        for treat_indices in itertools.combinations(indices, m):\n            Z_prime = np.zeros(n, dtype=int)\n            Z_prime[list(treat_indices)] = 1\n            t_prime = compute_statistic(Y, Z_prime)\n            null_stats.append(t_prime)\n            \n        null_stats = np.array(null_stats)\n        # To handle potential floating point inaccuracies, a small tolerance is used.\n        # abs_t_obs - 1e-9 ensures that values equal to abs_t_obs are included.\n        count_extreme = np.sum(np.abs(null_stats) = abs_t_obs - 1e-9)\n        p_value = count_extreme / len(null_stats)\n        \n    elif method == 'Monte Carlo':\n        # Legacy random number generation for reproducibility as per common practice\n        # when a simple seed is specified.\n        np.random.seed(seed)\n        count_extreme = 0\n        \n        for _ in range(B):\n            # A new random assignment is a random permutation of the observed one.\n            Z_prime = np.random.permutation(Z_obs)\n            t_prime = compute_statistic(Y, Z_prime)\n            if np.abs(t_prime) = abs_t_obs - 1e-9:\n                count_extreme += 1\n        \n        p_value = (count_extreme + 1) / (B + 1)\n        \n    return p_value\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (exact, small n)\n        {'Y': np.array([5.1, 4.9, 5.0, 5.3, 5.2, 5.4]),\n         'Z': np.array([1, 1, 1, 0, 0, 0]),\n         'method': 'exact', 'B': None, 'seed': None},\n        # Case 2 (Monte Carlo, larger n)\n        {'Y': np.array([10.2, 9.8, 10.0, 9.5, 10.4, 9.7, 10.3, 9.6, 10.1, 9.9,\n                        8.8, 9.0, 9.2, 8.9, 9.1, 8.7, 9.3, 8.6, 9.4, 8.5]),\n         'Z': np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n         'method': 'Monte Carlo', 'B': 20000, 'seed': 123},\n        # Case 3 (exact, zero difference boundary)\n        {'Y': np.array([1.0, 2.0, 1.0, 2.0]),\n         'Z': np.array([1, 0, 0, 1]),\n         'method': 'exact', 'B': None, 'seed': None},\n        # Case 4 (exact, unbalanced allocation)\n        {'Y': np.array([12.0, 10.0, 11.0, 9.0, 8.0, 13.0, 7.0]),\n         'Z': np.array([1, 1, 0, 0, 0, 0, 0]),\n         'method': 'exact', 'B': None, 'seed': None},\n        # Case 5 (exact, strong effect)\n        {'Y': np.array([20.0, 21.0, 19.0, 22.0, 5.0, 6.0, 7.0, 4.0]),\n         'Z': np.array([1, 1, 1, 1, 0, 0, 0, 0]),\n         'method': 'exact', 'B': None, 'seed': None}\n    ]\n\n    results = []\n    for case in test_cases:\n        p_value = calculate_p_value(case['Y'], case['Z'], case['method'], case['B'], case['seed'])\n        results.append(f\"{p_value:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4954539"}, {"introduction": "While randomization tests are powerful, many workhorse statistical methods use parametric models based on assumptions about the data's distribution. This exercise [@problem_id:4954547] walks you through the quintessential Student's $t$-test, a cornerstone for comparing means when data are approximately normal but population variance is unknown. You will apply the complete logical sequence of a hypothesis test, from stating hypotheses to calculating the test statistic and its corresponding $p$-value.", "problem": "A randomized crossover study evaluates whether a new dietary intervention changes fasting low-density lipoprotein cholesterol in adults. For each participant, the difference in fasting low-density lipoprotein cholesterol between the intervention and control periods is recorded. Assume the paired differences are independent and follow a normal distribution with unknown variance. You are given the sample size $n = 27$, the sample mean difference $\\bar{d} = 10$ (in mg/dL), and the sample standard deviation $s = 10\\sqrt{\\frac{27}{26}}$ (in mg/dL).\n\nStarting from the core definitions of a hypothesis test in biostatistics, proceed as follows: define the null and alternative hypotheses for a two-sided mean difference test; specify a test statistic suitable for an unknown variance under normality and justify its null distribution; compute the observed value of the test statistic from the given sample statistics; state what a two-sided $p$-value means conceptually and how to compute it from the null distribution; and clarify how the definition of “two-sidedness” generalizes when the null distribution of the chosen test statistic is asymmetric (that is, not symmetric about zero).\n\nFinally, express the two-sided $p$-value for this study as a single exact closed-form analytic expression in terms of the regularized incomplete beta function $I_{x}(a,b)$ with all numeric parameters substituted. Do not evaluate numerically. Your final answer must be a single analytic expression only, with no units.", "solution": "The solution proceeds by addressing each of the tasks outlined in the problem statement.\n\n**1. Null and Alternative Hypotheses**\n\nA hypothesis test begins with the formulation of two competing hypotheses. Let $\\mu_d$ represent the true population mean of the paired differences in fasting low-density lipoprotein cholesterol, where the difference is calculated as (intervention) $-$ (control).\n\n-   The **null hypothesis ($H_0$)** is the statement of no effect. It posits that the new dietary intervention has no impact on the mean cholesterol level, meaning the true mean difference is zero.\n    $$H_0: \\mu_d = 0$$\n-   The **alternative hypothesis ($H_A$)** for a two-sided test is the statement of an effect. It posits that the intervention does have an impact, causing the true mean difference to be non-zero, without specifying the direction of the change.\n    $$H_A: \\mu_d \\neq 0$$\n\n**2. Test Statistic and Null Distribution**\n\nThe problem states that the paired differences are sampled from a normal distribution with an unknown variance. The sample size is $n = 27$. For testing a hypothesis about the mean of a normally distributed population with unknown variance, the appropriate test statistic is the one-sample Student's t-statistic.\n\nThe statistic is defined as:\n$$T = \\frac{\\bar{d} - \\mu_{d,0}}{S_E}$$\nwhere $\\bar{d}$ is the sample mean difference, $\\mu_{d,0}$ is the hypothesized population mean difference under $H_0$, and $S_E$ is the standard error of the sample mean. The standard error is calculated as $S_E = \\frac{s}{\\sqrt{n}}$, where $s$ is the sample standard deviation and $n$ is the sample size.\n\nUnder the null hypothesis ($H_0: \\mu_d = 0$), the statistic becomes:\n$$T = \\frac{\\bar{d}}{s / \\sqrt{n}}$$\nBy the definition of the Student's t-distribution, this statistic $T$ follows a t-distribution with $\\nu = n-1$ degrees of freedom. For this study, the degrees of freedom are $\\nu = 27 - 1 = 26$. This distribution is appropriate because it accounts for the additional uncertainty introduced by estimating the population variance from the sample data.\n\n**3. Observed Value of the Test Statistic**\n\nUsing the given sample statistics, we compute the observed value of the test statistic, denoted $t_{obs}$.\n-   Sample size: $n = 27$.\n-   Sample mean difference: $\\bar{d} = 10$.\n-   Sample standard deviation: $s = 10\\sqrt{\\frac{27}{26}}$.\n\nFirst, we calculate the standard error of the mean:\n$$S_E = \\frac{s}{\\sqrt{n}} = \\frac{10\\sqrt{\\frac{27}{26}}}{\\sqrt{27}} = \\frac{10 \\cdot \\frac{\\sqrt{27}}{\\sqrt{26}}}{\\sqrt{27}} = \\frac{10}{\\sqrt{26}}$$\nNow, we compute the observed t-statistic:\n$$t_{obs} = \\frac{\\bar{d}}{S_E} = \\frac{10}{10/\\sqrt{26}} = \\sqrt{26}$$\n\n**4. Conceptual Meaning and Computation of a Two-Sided $p$-value**\n\nConceptually, a **$p$-value** is the probability of observing a test statistic as extreme as, or more extreme than, the one actually observed, under the assumption that the null hypothesis is true. The definition of \"extreme\" is determined by the alternative hypothesis.\n\nFor a **two-sided test**, \"extreme\" means far from the center of the null distribution in either direction (positive or negative). The center of the t-distribution is $0$. Therefore, the two-sided $p$-value is the probability that the absolute value of the test statistic under the null distribution ($T \\sim t_{26}$) is greater than or equal to the absolute value of the observed test statistic ($|t_{obs}|$).\n$$p\\text{-value} = P(|T| \\ge |t_{obs}| \\mid H_0)$$\nSince the t-distribution is symmetric about $0$, this probability can be calculated by finding the probability in one tail and doubling it:\n$$p\\text{-value} = P(T \\ge |t_{obs}|) + P(T \\le -|t_{obs}|) = 2 \\times P(T \\ge |t_{obs}|)$$\nFor this study, with $t_{obs} = \\sqrt{26}$, the $p$-value is $2 \\times P(T \\ge \\sqrt{26})$, where $T \\sim t_{26}$.\n\n**5. Generalization of \"Two-Sidedness\" to Asymmetric Distributions**\n\nFor a test statistic whose null distribution is symmetric about $0$ (e.g., normal, t-distribution), the \"equal tails\" method ($2 \\times P(T \\ge |t_{obs}|)$) is unambiguous. However, for an asymmetric null distribution (e.g., chi-squared, F-distribution), the concept of \"two-sidedness\" is not universally defined. The core principle remains: the $p$-value is the sum of probabilities of all outcomes that are at least as unlikely as the observed outcome.\n\nThe most principled generalization is the **probability density method**. Let $f(x)$ be the probability density function (PDF) of the test statistic $X$ under the null hypothesis, and let $x_{obs}$ be the observed value. The set of outcomes \"as or more extreme\" than $x_{obs}$ is defined as the set of all values $x$ for which the probability density is less than or equal to the density at the observed value, i.e., $\\{x \\mid f(x) \\le f(x_{obs})\\}$. The $p$-value is the integral of the PDF over this set:\n$$p\\text{-value} = \\int_{\\{x \\mid f(x) \\le f(x_{obs})\\}} f(x) \\, dx$$\nFor a unimodal distribution, this set is typically composed of two disjoint tails, thus preserving the \"two-sided\" nature of the test. This definition ensures that any outcome with an equal or smaller probability of occurring contributes to the $p$-value.\n\n**6. $p$-value Expression using the Regularized Incomplete Beta Function**\n\nThe final task is to express the two-sided $p$-value, $p = 2 \\times P(T \\ge \\sqrt{26})$ where $T \\sim t_{26}$, in terms of the regularized incomplete beta function, $I_{x}(a,b)$.\n\nThe cumulative distribution function (CDF) of the Student's t-distribution with $\\nu$ degrees of freedom, for a positive value $t$, is related to $I_{x}(a,b)$ by the formula:\n$$P(T_\\nu \\le t) = 1 - \\frac{1}{2} I_{z}\\left(\\frac{\\nu}{2}, \\frac{1}{2}\\right)$$\nwhere $z = \\frac{\\nu}{\\nu + t^2}$.\n\nThe probability in the upper tail is therefore:\n$$P(T_\\nu \\ge t) = 1 - P(T_\\nu  t) = 1 - P(T_\\nu \\le t) = 1 - \\left(1 - \\frac{1}{2} I_{z}\\left(\\frac{\\nu}{2}, \\frac{1}{2}\\right)\\right) = \\frac{1}{2} I_{z}\\left(\\frac{\\nu}{2}, \\frac{1}{2}\\right)$$\nThe two-sided $p$-value is twice this tail probability:\n$$p = 2 \\times P(T_\\nu \\ge t) = 2 \\times \\left(\\frac{1}{2} I_{z}\\left(\\frac{\\nu}{2}, \\frac{1}{2}\\right)\\right) = I_{z}\\left(\\frac{\\nu}{2}, \\frac{1}{2}\\right)$$\nWe substitute the specific values from this problem:\n-   Degrees of freedom: $\\nu = 26$.\n-   Observed statistic: $t_{obs} = \\sqrt{26}$.\n-   Parameters for the beta function: $a = \\frac{\\nu}{2} = \\frac{26}{2} = 13$ and $b = \\frac{1}{2}$.\n-   Argument for the beta function: $z = \\frac{\\nu}{\\nu + t_{obs}^2} = \\frac{26}{26 + (\\sqrt{26})^2} = \\frac{26}{26 + 26} = \\frac{26}{52} = \\frac{1}{2}$.\n\nSubstituting these values into the expression for the $p$-value gives the final analytical form.\n$$p = I_{\\frac{1}{2}}\\left(13, \\frac{1}{2}\\right)$$", "answer": "$$\\boxed{I_{\\frac{1}{2}}\\left(13, \\frac{1}{2}\\right)}$$", "id": "4954547"}, {"introduction": "Scientific studies rarely test a single hypothesis in isolation; often, researchers evaluate multiple endpoints to assess an intervention's overall effect. This introduces the \"multiple comparisons problem,\" where the chance of a false-positive finding increases with each test performed. In this practice [@problem_id:4954555], you will tackle this issue head-on by applying Holm's procedure to control the family-wise error rate, a crucial skill for interpreting results from complex clinical trials.", "problem": "A randomized, parallel-group clinical trial evaluates a new therapy against standard care on multiple co-primary endpoints to assess overall clinical benefit. There are $5$ endpoints: reduction in C-reactive protein, reduction in pain score, increase in $6$-minute walk distance, reduction in a disease activity index, and improvement in physician global assessment. For each endpoint, a valid two-sided hypothesis test comparing the new therapy to standard care has been conducted, yielding the following unadjusted $p$-values: reduction in C-reactive protein $p=0.048$, reduction in pain score $p=0.004$, $6$-minute walk distance $p=0.041$, disease activity index $p=0.013$, physician global assessment $p=0.22$. The scientific aim is to control the Family-Wise Error Rate (FWER) at level $\\alpha=0.05$ across these $5$ tests.\n\nUsing the steps of a hypothesis test grounded in core definitions, proceed as follows:\n- Explicitly state the null and alternative hypotheses for each endpoint in terms of no treatment effect versus a treatment effect.\n- Identify the relevant error rate being controlled and justify the need for multiplicity adjustment in this context of multiple endpoints.\n- Describe the decision framework of Holm’s sequentially rejective procedure in qualitative terms and order the given unadjusted $p$-values accordingly.\n- Compute the Holm-adjusted $p$-value for the $6$-minute walk distance endpoint, ensuring the monotonicity property of adjusted $p$-values is respected.\n- Interpret, in words, what this adjusted $p$-value means for the $6$-minute walk distance endpoint at $\\alpha=0.05$ in terms of rejecting or not rejecting its null hypothesis while controlling FWER.\n\nReport only the Holm-adjusted $p$-value for the $6$-minute walk distance endpoint, rounded to four significant figures. Do not include any units in the reported number.", "solution": "The problem presents a valid scenario from biostatistics concerning the analysis of a clinical trial with multiple endpoints. It is scientifically grounded, well-posed, and objective. All necessary data are provided, and the task is to apply a standard statistical procedure, the Holm-Bonferroni method, to control the Family-Wise Error Rate (FWER).\n\nThe problem statement requires a structured analysis involving several steps, which will be followed methodically.\n\n**1. Null and Alternative Hypotheses**\n\nFor a clinical trial comparing a new therapy to standard care across $m=5$ endpoints, we establish a pair of hypotheses for each endpoint. Let the index $i$ represent each of the $5$ endpoints. The null hypothesis, $H_{0,i}$, posits no difference in effect between the new therapy and standard care. The alternative hypothesis, $H_{A,i}$, posits that a difference exists.\n\n-   $H_{0,i}$: There is no treatment effect for endpoint $i$. (e.g., The true mean change in the 6-minute walk distance for the new therapy group is equal to the true mean change for the standard care group).\n-   $H_{A,i}$: There is a treatment effect for endpoint $i$. (e.g., The true mean change in the 6-minute walk distance for the new therapy group is not equal to the true mean change for the standard care group). This is a two-sided alternative, as is standard practice unless a directional effect is pre-specified with strong justification.\n\nThis formulation applies to all five endpoints: C-reactive protein, pain score, 6-minute walk distance, disease activity index, and physician global assessment.\n\n**2. Family-Wise Error Rate (FWER) and the Need for Multiplicity Adjustment**\n\nThe Family-Wise Error Rate (FWER) is the probability of making at least one Type I error (a false positive, i.e., rejecting a true null hypothesis) within a family of hypothesis tests. When multiple hypotheses are tested simultaneously, the probability of making at least one such error inflates if each test is naively assessed at the nominal significance level $\\alpha$.\n\nIf we conduct $m$ independent tests, each at a significance level $\\alpha$, and all $m$ null hypotheses are true, the probability of correctly not rejecting a single null hypothesis is $1 - \\alpha$. The probability of correctly not rejecting any of the $m$ null hypotheses is $(1 - \\alpha)^m$. Consequently, the FWER is given by:\n\n$$ \\text{FWER} = 1 - (1 - \\alpha)^m $$\n\nIn this problem, with $m=5$ endpoints and a desired control level of $\\alpha = 0.05$, the unadjusted FWER would be:\n\n$$ \\text{FWER} = 1 - (1 - 0.05)^5 = 1 - (0.95)^5 \\approx 1 - 0.77378 \\approx 0.2262 $$\n\nThis FWER of approximately $22.6\\%$ is substantially higher than the acceptable rate of $5\\%$. To maintain the overall probability of a false positive claim at or below the desired $\\alpha=0.05$, a multiplicity adjustment procedure is required. The Holm-Bonferroni method is one such procedure designed to control the FWER.\n\n**3. Holm's Sequentially Rejective Procedure and Ordering of p-values**\n\nHolm's method is a step-down procedure that provides strong control of the FWER. It is uniformly more powerful than the classical Bonferroni correction. The procedure operates as follows:\n\n1.  Order the $m$ unadjusted $p$-values from smallest to largest: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$. Let $H_{0,(j)}$ be the null hypothesis corresponding to the $j$-th ordered $p$-value, $p_{(j)}$.\n2.  Start with the smallest $p$-value, $p_{(1)}$. Compare it to a corrected significance level of $\\frac{\\alpha}{m}$. If $p_{(1)} \\le \\frac{\\alpha}{m}$, reject $H_{0,(1)}$ and proceed to the next step. Otherwise, fail to reject $H_{0,(1)}$ and all subsequent null hypotheses, and stop.\n3.  Proceed sequentially. For each step $j=2, \\dots, m$, if the hypothesis $H_{0,(j-1)}$ was rejected in the previous step, compare $p_{(j)}$ to the corrected significance level $\\frac{\\alpha}{m - j + 1}$. If $p_{(j)} \\le \\frac{\\alpha}{m - j + 1}$, reject $H_{0,(j)}$ and continue. Otherwise, fail to reject $H_{0,(j)}$ and all subsequent hypotheses ($H_{0,(j+1)}, \\dots, H_{0,(m)}$), and stop.\n\nThe given unadjusted $p$-values are:\n-   C-reactive protein: $p=0.048$\n-   Pain score: $p=0.004$\n-   6-minute walk distance: $p=0.041$\n-   Disease activity index: $p=0.013$\n-   Physician global assessment: $p=0.22$\n\nOrdering these $m=5$ p-values:\n-   $p_{(1)} = 0.004$ (Pain score)\n-   $p_{(2)} = 0.013$ (Disease activity index)\n-   $p_{(3)} = 0.041$ (6-minute walk distance)\n-   $p_{(4)} = 0.048$ (C-reactive protein)\n-   $p_{(5)} = 0.22$ (Physician global assessment)\n\n**4. Computation of the Holm-Adjusted p-value**\n\nThe Holm-adjusted $p$-value for the $j$-th ordered hypothesis, denoted $\\tilde{p}_{\\text{Holm},(j)}$, is calculated and enforced to be monotonically non-decreasing. The formula for the intermediate adjusted value is $\\tilde{p}_{(j)}' = (m-j+1)p_{(j)}$. The final adjusted $p$-value is then the cumulative maximum of these intermediate values.\n\n$$ \\tilde{p}_{\\text{Holm},(j)} = \\max_{k=1,\\dots,j} \\{ (m-k+1)p_{(k)} \\} $$\nAlternatively, this can be expressed recursively:\n$$ \\tilde{p}_{\\text{Holm},(j)} = \\max( \\tilde{p}_{\\text{Holm},(j-1)}, (m-j+1)p_{(j)} ) $$\nwith $\\tilde{p}_{\\text{Holm},(0)} = 0$.\n\nWe need to compute the adjusted $p$-value for the \"6-minute walk distance\" endpoint, which corresponds to the third ordered raw $p$-value, $p_{(3)} = 0.041$.\n\n-   For $j=1$: $p_{(1)} = 0.004$.\n    $$ \\tilde{p}_{\\text{Holm},(1)} = (5-1+1)p_{(1)} = 5 \\times 0.004 = 0.020 $$\n\n-   For $j=2$: $p_{(2)} = 0.013$.\n    $$ \\tilde{p}_{\\text{Holm},(2)} = \\max(\\tilde{p}_{\\text{Holm},(1)}, (5-2+1)p_{(2)}) = \\max(0.020, 4 \\times 0.013) = \\max(0.020, 0.052) = 0.052 $$\n\n-   For $j=3$: $p_{(3)} = 0.041$. This is the target value.\n    $$ \\tilde{p}_{\\text{Holm},(3)} = \\max(\\tilde{p}_{\\text{Holm},(2)}, (5-3+1)p_{(3)}) = \\max(0.052, 3 \\times 0.041) = \\max(0.052, 0.123) = 0.123 $$\n\nThe Holm-adjusted $p$-value for the 6-minute walk distance endpoint is $0.123$. The problem requires rounding to four significant figures, which gives $0.1230$.\n\n**5. Interpretation of the Adjusted p-value**\n\nThe calculated Holm-adjusted $p$-value for the 6-minute walk distance endpoint is $\\tilde{p}_{\\text{walk}} = 0.1230$. An adjusted $p$-value can be interpreted as the smallest family-wise error rate (FWER) $\\alpha$ at which a given null hypothesis would be rejected.\n\nThe decision rule is to compare this adjusted $p$-value to the pre-specified FWER, $\\alpha=0.05$. Since $\\tilde{p}_{\\text{walk}} = 0.1230 > 0.05$, we fail to reject the null hypothesis for the 6-minute walk distance endpoint. In practical terms, this means that after accounting for the testing of five co-primary endpoints, the observed result for the 6-minute walk distance (with an unadjusted $p$-value of $0.041$) is not statistically significant. There is insufficient evidence to conclude that the new therapy has an effect on this endpoint while controlling the FWER at the 5% level.", "answer": "$$\n\\boxed{0.1230}\n$$", "id": "4954555"}]}