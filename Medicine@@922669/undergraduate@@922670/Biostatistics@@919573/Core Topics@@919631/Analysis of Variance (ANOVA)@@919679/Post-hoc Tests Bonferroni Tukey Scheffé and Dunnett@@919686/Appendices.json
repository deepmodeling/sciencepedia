{"hands_on_practices": [{"introduction": "Before we can correct for the risk of false positives in multiple comparisons, we must first quantify the problem's scale. This foundational exercise guides you through deriving the formula for the total number of pairwise comparisons possible among a set of groups [@problem_id:4938861]. Mastering this simple combinatorial principle is the essential first step in planning any post-hoc analysis and appreciating why statistical adjustments are necessary as the number of groups grows.", "problem": "A biostatistician conducts a one-way analysis of variance across $k$ independent treatment groups in a randomized clinical study of antihypertensive agents. Having found a statistically significant omnibus result, the biostatistician plans to apply multiple comparison procedures, such as Tukey's Honestly Significant Difference (HSD) and the Bonferroni method, which require the count of distinct pairwise mean comparisons among groups to calibrate the Familywise Error Rate (FWER).\n\nUsing only fundamental counting principles and the definition of a pairwise comparison as an unordered comparison between two distinct group means (self-comparisons excluded and the comparison of group $A$ with group $B$ treated as identical to the comparison of group $B$ with group $A$), derive an analytic expression for the total number of distinct pairwise mean comparisons as a function of $k$. Then, compute this number when $k=7$.\n\nExpress the final answer as a single real number. No rounding is required.", "solution": "The problem requires the derivation of a general formula for the number of distinct pairwise comparisons among $k$ groups and the computation of this number for the specific case where $k=7$. The problem statement provides a precise definition of a pairwise comparison: an unordered comparison between two distinct group means.\n\nLet the set of $k$ treatment groups be denoted by $G = \\{G_1, G_2, \\dots, G_k\\}$. A pairwise comparison involves selecting two distinct groups from this set. The condition that the comparison is \"unordered\" means that the comparison between group $G_i$ and group $G_j$ is identical to the comparison between group $G_j$ and group $G_i$. The condition that the groups must be \"distinct\" means that $i \\neq j$, effectively excluding self-comparisons like $G_i$ versus $G_i$.\n\nThis problem is a classic combinatorial task of selecting a subset of size $2$ from a set of size $k$. The number of ways to choose $r$ elements from a set of $n$ elements without regard to the order of selection is given by the binomial coefficient, denoted as $\\binom{n}{r}$.\n\nIn our specific context, we are choosing $r=2$ groups from a set of $n=k$ groups. Therefore, the total number of distinct pairwise comparisons, which we can denote by $C$, is given by:\n$$ C = \\binom{k}{2} $$\n\nThe formula for the binomial coefficient is:\n$$ \\binom{n}{r} = \\frac{n!}{r!(n-r)!} $$\nSubstituting $n=k$ and $r=2$, we obtain the analytic expression for $C$ as a function of $k$:\n$$ C(k) = \\binom{k}{2} = \\frac{k!}{2!(k-2)!} $$\n\nWe can simplify this expression by expanding the factorial term $k!$ as $k \\times (k-1) \\times (k-2)!$:\n$$ C(k) = \\frac{k(k-1)(k-2)!}{2!(k-2)!} $$\nThe $(k-2)!$ term cancels out from the numerator and the denominator. Since $2! = 2 \\times 1 = 2$, the expression simplifies to:\n$$ C(k) = \\frac{k(k-1)}{2} $$\nThis is the required analytic expression for the total number of distinct pairwise mean comparisons.\n\nThis result can also be derived from first principles of counting. To form a pair of distinct groups, we first select one group from the $k$ available groups. There are $k$ choices for this first selection. After selecting one group, there are $k-1$ remaining groups from which to select the second group. This would seem to suggest there are $k(k-1)$ possible pairs. However, this procedure counts ordered pairs. For instance, it counts the pair $(G_1, G_2)$ as distinct from the pair $(G_2, G_1)$. The problem statement specifies that comparisons are unordered, meaning the comparison of group $A$ with group $B$ is the same as the comparison of group $B$ with group $A$. Since each pair of distinct groups is counted exactly twice in the ordered counting procedure (once as $(G_i, G_j)$ and once as $(G_j, G_i)$), we must divide the total number of ordered pairs by $2$ to find the number of unique, unordered pairs.\n$$ C(k) = \\frac{k(k-1)}{2} $$\nThis confirms our previous derivation using the binomial coefficient.\n\nThe second part of the problem asks to compute this number for a study with $k=7$ treatment groups. We substitute $k=7$ into our derived formula:\n$$ C(7) = \\frac{7(7-1)}{2} $$\n$$ C(7) = \\frac{7 \\times 6}{2} $$\n$$ C(7) = \\frac{42}{2} $$\n$$ C(7) = 21 $$\n\nThus, for a study with $7$ treatment groups, there are $21$ distinct pairwise mean comparisons to be considered in post-hoc analyses like Tukey's HSD or when applying a Bonferroni correction.", "answer": "$$\\boxed{21}$$", "id": "4938861"}, {"introduction": "The Bonferroni correction is a fundamental tool for controlling the familywise error rate, prized for its simplicity and universal applicability. This practice moves from theory to application, challenging you to use the Bonferroni method to adjust a set of raw $p$-values from a hypothetical study [@problem_id:4938829]. By working through this example, you will develop a concrete understanding of how to maintain statistical rigor when faced with multiple simultaneous hypothesis tests.", "problem": "A biostatistics study compares mean serum biomarker levels across $k$ treatment groups using a one-way Analysis of Variance (ANOVA). Post-hoc pairwise comparisons among all groups are performed using two-sample $t$-tests, yielding $m=10$ raw $p$-values for the set of all pairwise contrasts: $p=(0.001,\\,0.02,\\,0.07,\\,0.11,\\,0.23,\\,0.045,\\,0.0045,\\,0.39,\\,0.003,\\,0.12)$. The investigator wishes to control the Familywise Error Rate (FWER) at level $\\alpha=0.05$ across these $m$ comparisons. Starting from the union bound on probabilities and the definition of FWER, derive the Bonferroni family-wise control and the corresponding adjusted $p$-value mapping for a collection of $m$ simultaneous tests. Then apply this adjustment to the given raw $p$-values and determine the total number of rejected pairwise null hypotheses at level $\\alpha=0.05$. Report only the total count of rejections as your final numerical answer. No rounding is needed. Briefly justify, based on first principles, why the Bonferroni approach is applicable in this setting compared to Tukey, Scheffé, or Dunnett procedures, without using any shortcut formulas in the problem statement.", "solution": "The problem requires the derivation of the Bonferroni correction for controlling the Familywise Error Rate (FWER), its application to a given set of $p$-values, a count of the resulting rejections, and a justification for its use.\n\nFirst, we derive the Bonferroni correction from first principles. Let there be a family of $m$ null hypotheses, denoted by $H_{0,i}$ for $i \\in \\{1, 2, \\dots, m\\}$. The Familywise Error Rate (FWER) is defined as the probability of making at least one Type I error. A Type I error is the event of rejecting a true null hypothesis. Let $I_0$ be the subset of indices $\\{1, 2, \\dots, m\\}$ for which the corresponding null hypothesis $H_{0,i}$ is true. The FWER is then:\n$$\n\\text{FWER} = P\\left(\\bigcup_{i \\in I_0} \\{\\text{reject } H_{0,i}\\}\\right)\n$$\nSince the set $I_0$ is unknown in a real experimental setting, we seek to control the FWER by bounding the probability of rejecting any of the $m$ hypotheses, which is a conservative upper bound on the true FWER:\n$$\n\\text{FWER} \\le P\\left(\\bigcup_{i=1}^{m} \\{\\text{reject } H_{0,i}\\}\\right)\n$$\nWe invoke the union bound, also known as Boole's inequality, which states that for any collection of events $A_1, A_2, \\dots, A_m$, the probability of their union is less than or equal to the sum of their individual probabilities: $P(\\cup_{i=1}^m A_i) \\le \\sum_{i=1}^m P(A_i)$. Applying this to our expression for the FWER upper bound, where $A_i$ is the event {reject $H_{0,i}$}:\n$$\n\\text{FWER} \\le \\sum_{i=1}^{m} P(\\text{reject } H_{0,i})\n$$\nFor a single hypothesis test $i$, we reject $H_{0,i}$ if its associated $p$-value, $p_i$, is less than or equal to a chosen significance level, $\\alpha_i$. Under a true null hypothesis, the probability of rejecting it is controlled by this level: $P(\\text{reject } H_{0,i} | H_{0,i} \\text{ is true}) = \\alpha_i$. Therefore, $P(\\text{reject } H_{0,i}) \\le \\alpha_i$ for any $i$. Substituting this into the inequality gives:\n$$\n\\text{FWER} \\le \\sum_{i=1}^{m} \\alpha_i\n$$\nTo control the overall FWER at a desired level $\\alpha$, we must ensure that $\\sum_{i=1}^{m} \\alpha_i \\le \\alpha$. The simplest and most general way to satisfy this condition is to set the significance level for each individual test to be equal, i.e., $\\alpha_i = \\alpha^*$ for all $i$. This yields:\n$$\nm \\alpha^* \\le \\alpha \\implies \\alpha^* \\le \\frac{\\alpha}{m}\n$$\nThe Bonferroni procedure sets this individual significance threshold to $\\alpha^* = \\frac{\\alpha}{m}$. Therefore, the decision rule is to reject the null hypothesis $H_{0,i}$ if its raw $p$-value $p_i \\le \\frac{\\alpha}{m}$.\n\nThe corresponding adjusted $p$-value, $p_i^{\\text{adj}}$, is defined as the smallest FWER level $\\alpha$ at which the hypothesis $H_{0,i}$ would be rejected. Based on the Bonferroni rule, we reject if $p_i \\le \\frac{\\alpha}{m}$, which is equivalent to $\\alpha \\ge m \\cdot p_i$. The smallest value of $\\alpha$ that satisfies this inequality is $\\alpha = m \\cdot p_i$. Since a probability cannot exceed $1$, the Bonferroni-adjusted $p$-value is formally defined as:\n$$\np_i^{\\text{adj}} = \\min(m \\cdot p_i, 1)\n$$\nA hypothesis is rejected if its adjusted $p$-value is less than or equal to the desired FWER level, $p_i^{\\text{adj}} \\le \\alpha$.\n\nNow, we apply this to the given problem. We have $m=10$ pairwise comparisons and a desired FWER of $\\alpha=0.05$. The Bonferroni-corrected significance level for each individual test is:\n$$\n\\alpha^* = \\frac{\\alpha}{m} = \\frac{0.05}{10} = 0.005\n$$\nThe set of raw $p$-values is $p=(0.001, 0.02, 0.07, 0.11, 0.23, 0.045, 0.0045, 0.39, 0.003, 0.12)$. We must compare each raw $p$-value to the corrected threshold $\\alpha^*=0.005$ and count the number of hypotheses that are rejected.\n1. $p_1 = 0.001 \\le 0.005 \\implies$ Reject $H_{0,1}$\n2. $p_2 = 0.02 > 0.005 \\implies$ Do not reject $H_{0,2}$\n3. $p_3 = 0.07 > 0.005 \\implies$ Do not reject $H_{0,3}$\n4. $p_4 = 0.11 > 0.005 \\implies$ Do not reject $H_{0,4}$\n5. $p_5 = 0.23 > 0.005 \\implies$ Do not reject $H_{0,5}$\n6. $p_6 = 0.045 > 0.005 \\implies$ Do not reject $H_{0,6}$\n7. $p_7 = 0.0045 \\le 0.005 \\implies$ Reject $H_{0,7}$\n8. $p_8 = 0.39 > 0.005 \\implies$ Do not reject $H_{0,8}$\n9. $p_9 = 0.003 \\le 0.005 \\implies$ Reject $H_{0,9}$\n10. $p_{10} = 0.12 > 0.005 \\implies$ Do not reject $H_{0,10}$\n\nThe hypotheses corresponding to the raw $p$-values of $0.001$, $0.0045$, and $0.003$ are rejected. The total number of rejected pairwise null hypotheses is $3$.\n\nFinally, we justify the applicability of the Bonferroni method. The Bonferroni correction's derivation relies solely on the union bound of probability. This makes it universally applicable to any collection of $m$ hypothesis tests, as it makes no assumptions about the dependence structure between the tests or the nature of the data that generated the $p$-values. In contrast, other methods are more specialized:\n- **Tukey's HSD** is specifically designed for testing all pairwise comparisons following an ANOVA. Its validity rests on the assumptions of the ANOVA model, such as normality, independence of observations, and homogeneity of variances, and it performs best with equal sample sizes per group. The problem provides only the final $p$-values, not confirmation that these underlying assumptions are met.\n- **Scheffé's Method** is designed to control the FWER for all possible linear contrasts among group means, not just pairwise comparisons. It is unnecessarily conservative if the only goal is to test all pairwise differences.\n- **Dunnett's Method** is designed for the specific situation of comparing multiple treatment groups to a single control group, not for all possible pairwise comparisons among all groups.\nGiven that the problem only provides a set of $p$-values and the general goal of controlling the FWER for $m$ simultaneous tests, the Bonferroni method is the most appropriate procedure to apply from first principles, as its validity does not depend on any information beyond what is provided.", "answer": "$$\\boxed{3}$$", "id": "4938829"}, {"introduction": "While general corrections like Bonferroni are useful, more powerful statistical tests are available for specific experimental designs. This problem introduces Dunnett's procedure, which is tailored for the common research scenario of comparing multiple treatment groups to a single control group [@problem_id:4938839]. By applying this specialized test, you will learn how to leverage information from the initial ANOVA to conduct a more focused and statistically powerful post-hoc analysis.", "problem": "A biostatistics team analyzes a one-way study with $g=4$ treatment groups and one control group. Each group has $n_{0}=15$ for control and $n_{i}=15$ for each treatment $i \\in \\{1,2,3,4\\}$. A standard one-way Analysis of Variance (ANOVA) is used under the usual Gaussian model with common variance across groups, and the residual mean square (within-group mean square) is reported as $MS_{\\text{within}}=5.2$. From the fitted model, the estimated mean differences for each treatment versus control (treatment mean minus control mean) are observed to be $(1.1,\\,2.0,\\,-0.3,\\,1.7)$. Using Dunnett's multiple comparison procedure to control the familywise error rate (FWER) at $\\alpha=0.05$ for two-sided comparisons, determine how many treatments are declared significantly different from the control.\n\nUse the following information:\n- The comparison standard error under the common-variance normal model is given by $\\sqrt{MS_{\\text{within}}\\left(\\frac{1}{n_{0}}+\\frac{1}{n_{i}}\\right)}$.\n- The within-group degrees of freedom are $\\nu=\\sum_{j=0}^{g}(n_{j}-1)$.\n- The two-sided Dunnett critical value for $g=4$ and $\\nu=70$ at $\\alpha=0.05$ is $2.45$.\n\nExpress your final answer as a single integer equal to the number of significant treatments. No rounding of the final answer is required.", "solution": "The problem requires us to determine the number of treatments that are declared significantly different from a control group using Dunnett's multiple comparison procedure. The study involves $g=4$ treatment groups and one control group, making a total of $k=g+1=5$ groups. The sample size is equal for all groups, with $n_j=15$ for $j \\in \\{0, 1, 2, 3, 4\\}$. The familywise error rate for the two-sided comparisons is to be controlled at $\\alpha=0.05$.\n\nFirst, we verify the within-group degrees of freedom, $\\nu$, using the provided formula $\\nu=\\sum_{j=0}^{g}(n_{j}-1)$. Given $g=4$ and $n_j=15$ for all $j=0, \\dots, 4$, the calculation is:\n$$\n\\nu = \\sum_{j=0}^{4} (15-1) = 5 \\times (15-1) = 5 \\times 14 = 70\n$$\nThis result matches the value of $\\nu=70$ for which the problem supplies a critical value, confirming the internal consistency of the problem's data.\n\nDunnett's procedure is designed to compare each of the $g=4$ treatment means, denoted $\\bar{y}_i$ for $i \\in \\{1, 2, 3, 4\\}$, with the control group mean, $\\bar{y}_0$. A mean difference is declared statistically significant if the absolute value of the corresponding test statistic, $t_i$, exceeds the two-sided Dunnett critical value, which we denote as $d_{\\alpha, g, \\nu}$.\n\nThe test statistic for the $i$-th comparison is defined as:\n$$\nt_i = \\frac{|\\bar{y}_i - \\bar{y}_0|}{SE}\n$$\nwhere $SE$ represents the standard error of the difference between a treatment mean and the control mean. The problem provides the formula for this standard error:\n$$\nSE = \\sqrt{MS_{\\text{within}}\\left(\\frac{1}{n_{0}}+\\frac{1}{n_{i}}\\right)}\n$$\nWe are given $MS_{\\text{within}} = 5.2$, and the sample sizes are $n_0 = 15$ and $n_i = 15$. We can therefore compute the standard error:\n$$\nSE = \\sqrt{5.2 \\left(\\frac{1}{15}+\\frac{1}{15}\\right)} = \\sqrt{5.2 \\times \\frac{2}{15}} = \\sqrt{\\frac{10.4}{15}}\n$$\n\nThe condition for declaring the $i$-th comparison statistically significant is $t_i > d_{\\alpha, g, \\nu}$. With the provided critical value $d_{0.05, 4, 70} = 2.45$, the inequality becomes:\n$$\n\\frac{|\\bar{y}_i - \\bar{y}_0|}{SE} > 2.45\n$$\nAn equivalent approach is to calculate a \"critical difference,\" $D$, and compare the observed absolute mean differences directly against it. The difference is significant if $|\\bar{y}_i - \\bar{y}_0| > D$, where:\n$$\nD = d_{\\alpha, g, \\nu} \\times SE = 2.45 \\times \\sqrt{\\frac{10.4}{15}}\n$$\nTo maintain precision and avoid rounding errors from the square root, we can work with the squares of these quantities. The significance condition is thus $|\\bar{y}_i - \\bar{y}_0|^2 > D^2$. Let us calculate $D^2$:\n$$\nD^2 = (2.45)^2 \\times \\left(\\frac{10.4}{15}\\right) = 6.0025 \\times \\frac{10.4}{15} = \\frac{62.426}{15}\n$$\n$D^2 \\approx 4.16173$.\n\nThe observed mean differences, $(\\bar{y}_i - \\bar{y}_0)$, are given as the set $(1.1,\\,2.0,\\,-0.3,\\,1.7)$. We compute the square of the absolute value for each of these differences:\n- For treatment $1$: $|\\bar{y}_1 - \\bar{y}_0|^2 = |1.1|^2 = 1.21$\n- For treatment $2$: $|\\bar{y}_2 - \\bar{y}_0|^2 = |2.0|^2 = 4.00$\n- For treatment $3$: $|\\bar{y}_3 - \\bar{y}_0|^2 = |-0.3|^2 = 0.09$\n- For treatment $4$: $|\\bar{y}_4 - \\bar{y}_0|^2 = |1.7|^2 = 2.89$\n\nFinally, we compare each of these squared differences to the squared critical difference, $D^2 \\approx 4.16173$:\n- Treatment $1$: $1.21  4.16173$. The difference is not significant.\n- Treatment $2$: $4.00  4.16173$. The difference is not significant.\n- Treatment $3$: $0.09  4.16173$. The difference is not significant.\n- Treatment $4$: $2.89  4.16173$. The difference is not significant.\n\nSince none of the squared absolute mean differences exceed the squared critical difference, we fail to reject the null hypothesis for all four comparisons. No treatment mean is found to be significantly different from the control mean at the $\\alpha=0.05$ significance level.\n\nTherefore, the number of treatments declared significantly different from the control is $0$.", "answer": "$$\\boxed{0}$$", "id": "4938839"}]}