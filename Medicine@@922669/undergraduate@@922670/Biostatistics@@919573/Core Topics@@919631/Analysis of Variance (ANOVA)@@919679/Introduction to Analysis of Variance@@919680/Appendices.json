{"hands_on_practices": [{"introduction": "Before applying Analysis of Variance (ANOVA), it is essential to understand its mathematical foundation. This exercise guides you through deriving the parameter estimates for the one-way ANOVA model using the principle of least squares. By working through this derivation [@problem_id:4919613], you will gain a deeper appreciation for how ANOVA connects observed data to its underlying model parameters, such as the overall mean $\\mu$ and group effects $\\alpha_i$.", "problem": "A biostatistician is analyzing the effect of $k$ dietary interventions on systolic blood pressure levels in a fixed-effects framework using Analysis of Variance (ANOVA). For group $i$ and subject $j$ in that group, the measured outcome is modeled as $y_{ij} = \\mu + \\alpha_{i} + \\epsilon_{ij}$, where $i = 1, \\dots, k$, $j = 1, \\dots, n_{i}$, $\\mu$ is a common baseline, $\\alpha_{i}$ is the group effect for group $i$, and $\\epsilon_{ij}$ is a random error with $E(\\epsilon_{ij}) = 0$ and $\\operatorname{Var}(\\epsilon_{ij}) = \\sigma^{2}$, independent across observations. To ensure identifiability of the parameters, the model imposes the constraint $\\sum_{i=1}^{k} \\alpha_{i} = 0$. Let $N = \\sum_{i=1}^{k} n_{i}$ denote the total sample size, define the group sample means $\\bar{y}_{i\\cdot} = \\frac{1}{n_{i}} \\sum_{j=1}^{n_{i}} y_{ij}$, and the overall mean $\\bar{y}_{\\cdot\\cdot} = \\frac{1}{N} \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} y_{ij}$. Starting from the least squares principle, derive the normal equations for minimizing the residual sum of squares subject to the constraint $\\sum_{i=1}^{k} \\alpha_{i} = 0$, and solve those equations to express the least squares estimates $\\hat{\\mu}$ and $\\hat{\\alpha}_{i}$ in terms of the sample means. Provide your final result for $\\hat{\\mu}$ and $\\hat{\\alpha}_{i}$ as closed-form analytic expressions in terms of $\\bar{y}_{i\\cdot}$ and $k$. No numerical approximation or rounding is required, and no units should be provided in the final answer.", "solution": "The problem requires the derivation of the least squares estimates for the parameters of a one-way fixed-effects ANOVA model. The model for an observation $y_{ij}$ from group $i$ and subject $j$ is given by $y_{ij} = \\mu + \\alpha_{i} + \\epsilon_{ij}$, with the identifiability constraint $\\sum_{i=1}^{k} \\alpha_{i} = 0$. The goal is to find the estimates $\\hat{\\mu}$ and $\\hat{\\alpha}_{i}$ that minimize the Residual Sum of Squares (RSS).\n\nFirst, we define the objective function, which is the RSS, denoted by $S$. The RSS is the sum of the squared differences between the observed values $y_{ij}$ and the values predicted by the model, $\\mu + \\alpha_i$.\n$$\nS(\\mu, \\alpha_1, \\dots, \\alpha_k) = \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} (y_{ij} - (\\mu + \\alpha_{i}))^2 = \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} (y_{ij} - \\mu - \\alpha_{i})^2\n$$\nThis minimization must be performed subject to the constraint $g(\\alpha_1, \\dots, \\alpha_k) = \\sum_{i=1}^{k} \\alpha_{i} = 0$.\n\nWe use the method of Lagrange multipliers. The Lagrangian function, $L$, is constructed by adding the constraint multiplied by a Lagrange multiplier, which we will denote as $2\\lambda$ for algebraic convenience.\n$$\nL(\\mu, \\alpha_1, \\dots, \\alpha_k, \\lambda) = S(\\mu, \\alpha_1, \\dots, \\alpha_k) + 2\\lambda \\left(\\sum_{i=1}^{k} \\alpha_{i}\\right)\n$$\n$$\nL = \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} (y_{ij} - \\mu - \\alpha_{i})^2 + 2\\lambda \\sum_{i=1}^{k} \\alpha_{i}\n$$\nTo find the values of $\\mu$ and $\\alpha_i$ that minimize $S$ subject to the constraint, we must find the critical points of $L$. This is achieved by taking the partial derivatives of $L$ with respect to $\\mu$, each $\\alpha_i$ for $i=1, \\dots, k$, and $\\lambda$, and setting them to zero. The resulting equations are known as the normal equations.\n\nThe partial derivative with respect to $\\mu$:\n$$\n\\frac{\\partial L}{\\partial \\mu} = \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} 2(y_{ij} - \\mu - \\alpha_{i})(-1) = -2 \\left( \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} y_{ij} - \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} \\mu - \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} \\alpha_{i} \\right) = 0\n$$\nUsing the definitions $N = \\sum_{i=1}^{k} n_{i}$ and $\\bar{y}_{\\cdot\\cdot} = \\frac{1}{N} \\sum_{i=1}^{k} \\sum_{j=1}^{n_{i}} y_{ij}$, this simplifies to:\n$$\n\\sum_{i=1}^{k} n_{i} \\bar{y}_{i\\cdot} - N\\mu - \\sum_{i=1}^{k} n_{i}\\alpha_{i} = 0 \\implies N\\hat{\\mu} + \\sum_{i=1}^{k} n_{i}\\hat{\\alpha}_{i} = N\\bar{y}_{\\cdot\\cdot} \\quad (1)\n$$\nHere, we use hats to denote the least squares estimates.\n\nThe partial derivative with respect to a specific $\\alpha_i$:\n$$\n\\frac{\\partial L}{\\partial \\alpha_i} = \\sum_{j=1}^{n_{i}} 2(y_{ij} - \\mu - \\alpha_{i})(-1) + 2\\lambda = -2 \\left( \\sum_{j=1}^{n_{i}} y_{ij} - n_{i}\\mu - n_{i}\\alpha_{i} \\right) + 2\\lambda = 0\n$$\nUsing the definition of the group mean $\\bar{y}_{i\\cdot} = \\frac{1}{n_i} \\sum_{j=1}^{n_i} y_{ij}$, this gives:\n$$\nn_i \\bar{y}_{i\\cdot} - n_i\\mu - n_i\\alpha_i - \\lambda = 0 \\implies n_i(\\hat{\\mu} + \\hat{\\alpha}_i) - \\lambda = n_i\\bar{y}_{i\\cdot} \\quad (2)\n$$\nThis provides $k$ equations, one for each $i \\in \\{1, \\dots, k\\}$.\n\nThe partial derivative with respect to $\\lambda$ simply recovers the constraint:\n$$\n\\frac{\\partial L}{\\partial \\lambda} = 2\\sum_{i=1}^{k} \\alpha_{i} = 0 \\implies \\sum_{i=1}^{k} \\hat{\\alpha}_{i} = 0 \\quad (3)\n$$\nNow we must solve this system of $k+2$ equations for the $k+2$ unknowns ($\\hat{\\mu}, \\hat{\\alpha}_1, \\dots, \\hat{\\alpha}_k, \\lambda$). From equation $(2)$, we can write:\n$$\n\\hat{\\mu} + \\hat{\\alpha}_i = \\bar{y}_{i\\cdot} + \\frac{\\lambda}{n_i}\n$$\nSumming this expression over all $i$ from $1$ to $k$:\n$$\n\\sum_{i=1}^{k} (\\hat{\\mu} + \\hat{\\alpha}_i) = \\sum_{i=1}^{k} \\left(\\bar{y}_{i\\cdot} + \\frac{\\lambda}{n_i}\\right)\n$$\n$$\nk\\hat{\\mu} + \\sum_{i=1}^{k} \\hat{\\alpha}_i = \\sum_{i=1}^{k} \\bar{y}_{i\\cdot} + \\lambda \\sum_{i=1}^{k} \\frac{1}{n_i}\n$$\nApplying the constraint from equation $(3)$, $\\sum_{i=1}^{k} \\hat{\\alpha}_{i} = 0$:\n$$\nk\\hat{\\mu} = \\sum_{i=1}^{k} \\bar{y}_{i\\cdot} + \\lambda \\sum_{i=1}^{k} \\frac{1}{n_i} \\implies \\hat{\\mu} = \\frac{1}{k}\\sum_{i=1}^{k} \\bar{y}_{i\\cdot} + \\frac{\\lambda}{k} \\sum_{i=1}^{k} \\frac{1}{n_i}\n$$\nWe can also express $\\hat{\\alpha}_i$ in terms of $\\hat{\\mu}$:\n$$\n\\hat{\\alpha}_i = \\bar{y}_{i\\cdot} - \\hat{\\mu} + \\frac{\\lambda}{n_i}\n$$\nSubstitute the expression for $\\hat{\\mu}$:\n$$\n\\hat{\\alpha}_i = \\bar{y}_{i\\cdot} - \\left(\\frac{1}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot} + \\frac{\\lambda}{k} \\sum_{j=1}^{k} \\frac{1}{n_j}\\right) + \\frac{\\lambda}{n_i} = \\left(\\bar{y}_{i\\cdot} - \\frac{1}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot}\\right) + \\lambda\\left(\\frac{1}{n_i} - \\frac{1}{k}\\sum_{j=1}^{k} \\frac{1}{n_j}\\right)\n$$\nNow we substitute these expressions for $\\hat{\\mu}$ and $\\hat{\\alpha}_i$ into equation $(1)$:\n$$\nN \\left(\\frac{1}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot} + \\frac{\\lambda}{k} \\sum_{j=1}^{k} \\frac{1}{n_j}\\right) + \\sum_{i=1}^{k} n_i \\left[ \\left(\\bar{y}_{i\\cdot} - \\frac{1}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot}\\right) + \\lambda\\left(\\frac{1}{n_i} - \\frac{1}{k}\\sum_{j=1}^{k} \\frac{1}{n_j}\\right) \\right] = N\\bar{y}_{\\cdot\\cdot}\n$$\nLet's separate terms that contain $\\lambda$ from those that do not.\nThe terms without $\\lambda$:\n$$\n\\frac{N}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot} + \\sum_{i=1}^{k} n_i \\bar{y}_{i\\cdot} - \\sum_{i=1}^{k} n_i \\left(\\frac{1}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot}\\right) = \\frac{N}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot} + N\\bar{y}_{\\cdot\\cdot} - \\frac{N}{k}\\sum_{j=1}^{k} \\bar{y}_{j\\cdot} = N\\bar{y}_{\\cdot\\cdot}\n$$\nThis part of the equation is an identity, $N\\bar{y}_{\\cdot\\cdot} = N\\bar{y}_{\\cdot\\cdot}$. This implies that the sum of all terms multiplied by $\\lambda$ must be zero.\nThe terms with $\\lambda$:\n$$\n\\lambda \\left[ N\\left(\\frac{1}{k} \\sum_{j=1}^{k} \\frac{1}{n_j}\\right) + \\sum_{i=1}^{k} n_i \\left(\\frac{1}{n_i} - \\frac{1}{k}\\sum_{j=1}^{k} \\frac{1}{n_j}\\right) \\right] = 0\n$$\n$$\n\\lambda \\left[ \\frac{N}{k} \\sum_{j=1}^{k} \\frac{1}{n_j} + \\sum_{i=1}^{k} 1 - \\sum_{i=1}^{k} n_i \\left(\\frac{1}{k}\\sum_{j=1}^{k} \\frac{1}{n_j}\\right) \\right] = 0\n$$\n$$\n\\lambda \\left[ \\frac{N}{k} \\sum_{j=1}^{k} \\frac{1}{n_j} + k - \\frac{N}{k}\\sum_{j=1}^{k} \\frac{1}{n_j} \\right] = 0\n$$\n$$\n\\lambda k = 0\n$$\nSince the number of groups $k \\geq 1$, we must have $\\lambda = 0$.\n\nWith $\\lambda=0$, the expressions for the estimates simplify significantly.\nFrom equation $(2)$:\n$$\nn_i(\\hat{\\mu} + \\hat{\\alpha}_i) - 0 = n_i\\bar{y}_{i\\cdot} \\implies \\hat{\\mu} + \\hat{\\alpha}_i = \\bar{y}_{i\\cdot}\n$$\nThis gives $\\hat{\\alpha}_i = \\bar{y}_{i\\cdot} - \\hat{\\mu}$.\nSubstituting this into the constraint equation $(3)$:\n$$\n\\sum_{i=1}^{k} (\\bar{y}_{i\\cdot} - \\hat{\\mu}) = 0\n$$\n$$\n\\sum_{i=1}^{k} \\bar{y}_{i\\cdot} - \\sum_{i=1}^{k} \\hat{\\mu} = 0\n$$\n$$\n\\sum_{i=1}^{k} \\bar{y}_{i\\cdot} - k\\hat{\\mu} = 0\n$$\nSolving for $\\hat{\\mu}$ yields:\n$$\n\\hat{\\mu} = \\frac{1}{k} \\sum_{i=1}^{k} \\bar{y}_{i\\cdot}\n$$\nThis is the unweighted mean of the group sample means.\n\nFinally, we find the expression for $\\hat{\\alpha}_i$ by substituting the expression for $\\hat{\\mu}$:\n$$\n\\hat{\\alpha}_i = \\bar{y}_{i\\cdot} - \\hat{\\mu} = \\bar{y}_{i\\cdot} - \\frac{1}{k} \\sum_{j=1}^{k} \\bar{y}_{j\\cdot}\n$$\nThe estimate for each group effect is the deviation of its group mean from the unweighted average of all group means. Note the use of index $j$ in the summation to avoid confusion with the specific index $i$.\nThe final expressions for $\\hat{\\mu}$ and $\\hat{\\alpha}_{i}$ are in terms of the group means $\\bar{y}_{i\\cdot}$ and the number of groups $k$, as requested.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{k} \\sum_{j=1}^{k} \\bar{y}_{j\\cdot} & \\bar{y}_{i\\cdot} - \\frac{1}{k} \\sum_{j=1}^{k} \\bar{y}_{j\\cdot}\n\\end{pmatrix}\n}\n$$", "id": "4919613"}, {"introduction": "A critical assumption of the standard one-way ANOVA is that the variances within each group are equal, a property known as homoscedasticity. This practice [@problem_id:4919610] provides a hands-on opportunity to test this assumption using the robust Brown–Forsythe test, a variant of Levene's test. Performing this check from first principles will solidify your understanding of why and how we validate statistical model assumptions before drawing conclusions from the main analysis.", "problem": "A clinical study compares the change in systolic blood pressure (in millimeters of mercury) after $12$ weeks across three interventions. The outcome is the reduction from baseline, recorded for three independent groups:\n- Group $1$ (standard counseling): $6, 8, 7, 5, 9, 6, 7, 10$.\n- Group $2$ (low-dose medication): $3, 4, 2, 5, 3, 4, 3, 6, 5, 4$.\n- Group $3$ (high-intensity lifestyle program): $7, 9, 8, 10, 11, 9, 12, 8, 10$.\n\nIn the standard one-way Analysis of Variance (ANOVA), an assumption is that the population variances across groups are equal. To assess this assumption using a robust procedure, apply the median-based Levene variant known as the Brown–Forsythe test: transform each observation to its absolute deviation from its group’s median, then perform a one-way ANOVA on these absolute deviations.\n\nStarting from core definitions for sums of squares and mean squares in one-way ANOVA, compute the Brown–Forsythe test statistic $F_{BF}$ for equality of variances across the three groups. Use the following steps grounded in first principles: determine each group’s median, compute absolute deviations from these medians, derive the between-group and within-group sums of squares for the deviations, and then the corresponding mean squares and $F$ statistic under the null hypothesis of equal variances.\n\nUsing a significance level $\\alpha = 0.05$, interpret the implications of the computed $F_{BF}$ for the validity of performing a standard one-way ANOVA on the original outcomes. Round your final test statistic to four significant figures. No units are required in your final answer.", "solution": "The problem requires the computation of the Brown–Forsythe test statistic, denoted as $F_{BF}$, to assess the homogeneity of variances across three independent groups. This test is a robust variant of Levene's test that uses the group median instead of the group mean for the transformation of the data. The null hypothesis ($H_0$) for this test is that the population variances of the outcome variable are equal across all groups ($H_0: \\sigma_1^2 = \\sigma_2^2 = \\sigma_3^2$). The procedure involves performing a one-way Analysis of Variance (ANOVA) on the absolute deviations of each observation from its respective group median.\n\nLet the number of groups be $k$, and the number of observations in group $i$ be $n_i$. The total number of observations is $N = \\sum_{i=1}^k n_i$. The observation $j$ in group $i$ is denoted by $Y_{ij}$.\n\nIn this problem, we have $k=3$ groups.\nGroup $1$: $Y_{1j} = \\{6, 8, 7, 5, 9, 6, 7, 10\\}$. The sample size is $n_1=8$.\nGroup $2$: $Y_{2j} = \\{3, 4, 2, 5, 3, 4, 3, 6, 5, 4\\}$. The sample size is $n_2=10$.\nGroup $3$: $Y_{3j} = \\{7, 9, 8, 10, 11, 9, 12, 8, 10\\}$. The sample size is $n_3=9$.\nThe total sample size is $N = 8 + 10 + 9 = 27$.\n\nThe first step is to calculate the median for each group.\nFor Group $1$ ($n_1=8$), we sort the data: $\\{5, 6, 6, 7, 7, 8, 9, 10\\}$. Since $n_1$ is even, the median is the average of the $4^{th}$ and $5^{th}$ values:\n$$ \\text{Median}_1 = \\frac{7+7}{2} = 7 $$\nFor Group $2$ ($n_2=10$), we sort the data: $\\{2, 3, 3, 3, 4, 4, 4, 5, 5, 6\\}$. Since $n_2$ is even, the median is the average of the $5^{th}$ and $6^{th}$ values:\n$$ \\text{Median}_2 = \\frac{4+4}{2} = 4 $$\nFor Group $3$ ($n_3=9$), we sort the data: $\\{7, 8, 8, 9, 9, 10, 10, 11, 12\\}$. Since $n_3$ is odd, the median is the $5^{th}$ value:\n$$ \\text{Median}_3 = 9 $$\n\nThe second step is to transform the original data $Y_{ij}$ into new variables $Z_{ij}$, which are the absolute deviations from the group medians: $Z_{ij} = |Y_{ij} - \\text{Median}_i|$.\nFor Group $1$: $Z_{1j} = \\{ |6-7|, |8-7|, |7-7|, |5-7|, |9-7|, |6-7|, |7-7|, |10-7| \\} = \\{1, 1, 0, 2, 2, 1, 0, 3\\}$.\nFor Group $2$: $Z_{2j} = \\{ |3-4|, |4-4|, |2-4|, |5-4|, |3-4|, |4-4|, |3-4|, |6-4|, |5-4|, |4-4| \\} = \\{1, 0, 2, 1, 1, 0, 1, 2, 1, 0\\}$.\nFor Group $3$: $Z_{3j} = \\{ |7-9|, |9-9|, |8-9|, |10-9|, |11-9|, |9-9|, |12-9|, |8-9|, |10-9| \\} = \\{2, 0, 1, 1, 2, 0, 3, 1, 1\\}$.\n\nThe third step is to perform a one-way ANOVA on the transformed data $Z_{ij}$. We begin by calculating the means of the $Z_{ij}$ values for each group and the grand mean.\nGroup $1$ mean of deviations: $\\bar{Z}_1 = \\frac{1+1+0+2+2+1+0+3}{8} = \\frac{10}{8} = \\frac{5}{4} = 1.25$.\nGroup $2$ mean of deviations: $\\bar{Z}_2 = \\frac{1+0+2+1+1+0+1+2+1+0}{10} = \\frac{9}{10} = 0.9$.\nGroup $3$ mean of deviations: $\\bar{Z}_3 = \\frac{2+0+1+1+2+0+3+1+1}{9} = \\frac{11}{9}$.\n\nThe grand mean of the deviations, $\\bar{Z}_{..}$, is the mean of all $Z_{ij}$ values:\n$$ \\bar{Z}_{..} = \\frac{\\sum_{i=1}^k \\sum_{j=1}^{n_i} Z_{ij}}{N} = \\frac{10+9+11}{27} = \\frac{30}{27} = \\frac{10}{9} $$\n\nNext, we compute the Sum of Squares Between groups ($SS_B$) and the Sum of Squares Within groups ($SS_W$).\nThe formula for $SS_B$ is:\n$$ SS_B = \\sum_{i=1}^k n_i (\\bar{Z}_i - \\bar{Z}_{..})^2 $$\n$$ SS_B = 8\\left(\\frac{5}{4} - \\frac{10}{9}\\right)^2 + 10\\left(\\frac{9}{10} - \\frac{10}{9}\\right)^2 + 9\\left(\\frac{11}{9} - \\frac{10}{9}\\right)^2 $$\n$$ SS_B = 8\\left(\\frac{45-40}{36}\\right)^2 + 10\\left(\\frac{81-100}{90}\\right)^2 + 9\\left(\\frac{1}{9}\\right)^2 $$\n$$ SS_B = 8\\left(\\frac{5}{36}\\right)^2 + 10\\left(\\frac{-19}{90}\\right)^2 + 9\\left(\\frac{1}{81}\\right) $$\n$$ SS_B = 8\\left(\\frac{25}{1296}\\right) + 10\\left(\\frac{361}{8100}\\right) + \\frac{1}{9} = \\frac{200}{1296} + \\frac{361}{810} + \\frac{1}{9} $$\nSimplifying the fractions gives $\\frac{25}{162}$, $\\frac{361}{810}$, and $\\frac{1}{9}$. A common denominator is $810$.\n$$ SS_B = \\frac{25 \\cdot 5}{162 \\cdot 5} + \\frac{361}{810} + \\frac{1 \\cdot 90}{9 \\cdot 90} = \\frac{125}{810} + \\frac{361}{810} + \\frac{90}{810} = \\frac{125+361+90}{810} = \\frac{576}{810} = \\frac{32}{45} $$\n\nThe formula for $SS_W$ is:\n$$ SS_W = \\sum_{i=1}^k \\sum_{j=1}^{n_i} (Z_{ij} - \\bar{Z}_i)^2 $$\nFor Group $1$: $\\sum (Z_{1j} - \\bar{Z}_1)^2 = \\sum (Z_{1j} - 1.25)^2 = (1-1.25)^2 \\cdot 3 + (0-1.25)^2 \\cdot 2 + (2-1.25)^2 \\cdot 2 + (3-1.25)^2 = 0.0625 \\cdot 3 + 1.5625 \\cdot 2 + 0.5625 \\cdot 2 + 3.0625 = 0.1875 + 3.125 + 1.125 + 3.0625 = 7.5 = \\frac{15}{2}$.\nFor Group $2$: $\\sum (Z_{2j} - \\bar{Z}_2)^2 = \\sum (Z_{2j} - 0.9)^2 = (1-0.9)^2 \\cdot 5 + (0-0.9)^2 \\cdot 3 + (2-0.9)^2 \\cdot 2 = 0.01 \\cdot 5 + 0.81 \\cdot 3 + 1.21 \\cdot 2 = 0.05 + 2.43 + 2.42 = 4.9 = \\frac{49}{10}$.\nFor Group $3$: $\\sum (Z_{3j} - \\bar{Z}_3)^2 = \\sum (Z_{3j} - \\frac{11}{9})^2$. The values are $(2-\\frac{11}{9})^2 \\cdot 2 + (0-\\frac{11}{9})^2 \\cdot 2 + (1-\\frac{11}{9})^2 \\cdot 4 + (3-\\frac{11}{9})^2 = (\\frac{7}{9})^2 \\cdot 2 + (-\\frac{11}{9})^2 \\cdot 2 + (-\\frac{2}{9})^2 \\cdot 4 + (\\frac{16}{9})^2 = \\frac{49}{81} \\cdot 2 + \\frac{121}{81} \\cdot 2 + \\frac{4}{81} \\cdot 4 + \\frac{256}{81} = \\frac{98+242+16+256}{81} = \\frac{612}{81} = \\frac{68}{9}$.\n\nTotal $SS_W = \\frac{15}{2} + \\frac{49}{10} + \\frac{68}{9}$. A common denominator is $90$.\n$$ SS_W = \\frac{15 \\cdot 45}{90} + \\frac{49 \\cdot 9}{90} + \\frac{68 \\cdot 10}{90} = \\frac{675 + 441 + 680}{90} = \\frac{1796}{90} = \\frac{898}{45} $$\n\nNow, we calculate the Mean Squares ($MS$). The degrees of freedom are $df_B = k-1 = 3-1=2$ and $df_W = N-k = 27-3=24$.\nMean Square Between groups:\n$$ MS_B = \\frac{SS_B}{df_B} = \\frac{32/45}{2} = \\frac{16}{45} $$\nMean Square Within groups:\n$$ MS_W = \\frac{SS_W}{df_W} = \\frac{898/45}{24} = \\frac{898}{1080} = \\frac{449}{540} $$\n\nThe Brown–Forsythe test statistic $F_{BF}$ is the ratio of the mean squares:\n$$ F_{BF} = \\frac{MS_B}{MS_W} = \\frac{16/45}{449/540} = \\frac{16}{45} \\cdot \\frac{540}{449} = 16 \\cdot \\frac{12}{449} = \\frac{192}{449} $$\nConverting to a decimal, $F_{BF} \\approx 0.4276169...$\nRounding to four significant figures, the test statistic is $0.4276$.\n\nTo interpret this result at a significance level of $\\alpha = 0.05$, we compare the computed $F_{BF}$ statistic to the critical value from an $F$-distribution with $df_1=2$ and $df_2=24$ degrees of freedom. The critical value is $F_{\\text{crit}} = F_{0.05, 2, 24} \\approx 3.40$.\nSince our test statistic $F_{BF} \\approx 0.4276$ is substantially smaller than the critical value ($0.4276 < 3.40$), we fail to reject the null hypothesis $H_0$. This means there is no statistically significant evidence to conclude that the variances of the systolic blood pressure reductions are different among the three intervention groups. The homoscedasticity assumption required for a standard one-way ANOVA on the original data is therefore considered satisfied.", "answer": "$$\\boxed{0.4276}$$", "id": "4919610"}, {"introduction": "When an omnibus ANOVA test yields a significant result, it tells us that at least one group mean is different, but not which specific groups differ. This exercise [@problem_id:4919561] addresses this crucial next step by introducing post-hoc analysis with the Tukey Honestly Significant Difference (HSD) method. By calculating adjusted $p$-values for all pairwise comparisons, you will learn how to pinpoint significant differences while controlling the family-wise error rate.", "problem": "A randomized biostatistics study compares the effect of three antihypertensive treatments on reduction in low-density lipoprotein cholesterol, measured in milligrams per deciliter. Patients are randomly assigned to one of three treatments with equal sample sizes. After verifying model assumptions for a one-way analysis of variance, the analysis is carried out. The following summary information is available:\n\n- Number of treatments: $k = 3$.\n- Sample sizes: $n_1 = n_2 = n_3 = 8$.\n- Error degrees of freedom: $\\nu = 21$.\n- Mean square error (pooled within-group variance): $\\mathrm{MSE} = 8$ (in squared milligrams per deciliter).\n- Sample mean reductions: $\\bar{y}_1 = 12.0$, $\\bar{y}_2 = 16.5$, $\\bar{y}_3 = 18.0$ (all in milligrams per deciliter).\n\nUsing the principles of the one-way analysis of variance and the definition of the Studentized range statistic, compute the Tukey honestly significant difference adjusted $p$-values for all pairwise differences among the three treatment means. For this purpose, use the following survival function values for the Studentized range distribution with parameters $k = 3$ and $\\nu = 21$:\n- $S_Q(1.5; 3, 21) = 0.80$,\n- $S_Q(4.5; 3, 21) = 0.0042$,\n- $S_Q(6.0; 3, 21) = 1.0 \\times 10^{-6}$.\n\nHere $S_Q(q; k, \\nu)$ denotes $\\Pr(Q_{k,\\nu} \\ge q)$, where $Q_{k,\\nu}$ has the Studentized range distribution. Determine which pairwise mean differences are significant at family-wise significance level $\\alpha = 0.05$. When reporting the adjusted $p$-values, report them to four significant figures. As your final answer, report the number of significant pairwise differences as a single integer (no units).", "solution": "The task is to compute the Tukey HSD adjusted $p$-values for all pairwise comparisons of the three treatment means and determine which pairs are significantly different at a family-wise error rate of $\\alpha = 0.05$.\n\nThe Tukey HSD method uses the Studentized range statistic, $q$, to compare pairs of means. For a pairwise comparison between group $i$ and group $j$ in a balanced design (equal sample sizes $n$), the test statistic is calculated as:\n$$ q_{ij} = \\frac{|\\bar{y}_i - \\bar{y}_j|}{\\text{SE}} $$\nwhere the standard error, $\\text{SE}$, is given by:\n$$ \\text{SE} = \\sqrt{\\frac{\\mathrm{MSE}}{n}} $$\nGiven $\\mathrm{MSE} = 8$ and $n = 8$, the standard error is:\n$$ \\text{SE} = \\sqrt{\\frac{8}{8}} = \\sqrt{1} = 1.0 $$\nThere are $\\binom{k}{2} = \\binom{3}{2} = 3$ pairwise comparisons to be made: (Treatment 1 vs. Treatment 2), (Treatment 1 vs. Treatment 3), and (Treatment 2 vs. Treatment 3). We will calculate the observed $q$ statistic for each pair.\n\n1.  **Comparison of Treatment 1 and Treatment 2:**\n    The absolute difference in means is $|\\bar{y}_1 - \\bar{y}_2| = |12.0 - 16.5| = 4.5$.\n    The observed $q$ statistic is:\n    $$ q_{12} = \\frac{4.5}{1.0} = 4.5 $$\n    The Tukey HSD adjusted $p$-value is the probability that the Studentized range random variable $Q_{k,\\nu}$ is greater than or equal to the observed statistic $q_{12}$.\n    $$ p_{12} = \\Pr(Q_{3,21} \\ge 4.5) $$\n    From the provided information, $S_Q(4.5; 3, 21) = 0.0042$.\n    Thus, the adjusted $p$-value for this pair, reported to four significant figures, is $p_{12} = 0.004200$.\n    Since $p_{12} = 0.004200 \\le \\alpha = 0.05$, the difference between the means of Treatment 1 and Treatment 2 is statistically significant.\n\n2.  **Comparison of Treatment 1 and Treatment 3:**\n    The absolute difference in means is $|\\bar{y}_1 - \\bar{y}_3| = |12.0 - 18.0| = 6.0$.\n    The observed $q$ statistic is:\n    $$ q_{13} = \\frac{6.0}{1.0} = 6.0 $$\n    The adjusted $p$-value is:\n    $$ p_{13} = \\Pr(Q_{3,21} \\ge 6.0) $$\n    From the provided information, $S_Q(6.0; 3, 21) = 1.0 \\times 10^{-6}$.\n    Thus, the adjusted $p$-value for this pair, reported to four significant figures, is $p_{13} = 0.000001000$.\n    Since $p_{13} = 1.0 \\times 10^{-6} \\le \\alpha = 0.05$, the difference between the means of Treatment 1 and Treatment 3 is statistically significant.\n\n3.  **Comparison of Treatment 2 and Treatment 3:**\n    The absolute difference in means is $|\\bar{y}_2 - \\bar{y}_3| = |16.5 - 18.0| = 1.5$.\n    The observed $q$ statistic is:\n    $$ q_{23} = \\frac{1.5}{1.0} = 1.5 $$\n    The adjusted $p$-value is:\n    $$ p_{23} = \\Pr(Q_{3,21} \\ge 1.5) $$\n    From the provided information, $S_Q(1.5; 3, 21) = 0.80$.\n    Thus, the adjusted $p$-value for this pair, reported to four significant figures, is $p_{23} = 0.8000$.\n    Since $p_{23} = 0.8000 > \\alpha = 0.05$, the difference between the means of Treatment 2 and Treatment 3 is not statistically significant.\n\nIn summary, we have evaluated the three pairwise comparisons:\n- The pair (Treatment 1, Treatment 2) shows a significant difference ($p = 0.004200$).\n- The pair (Treatment 1, Treatment 3) shows a significant difference ($p = 1.0 \\times 10^{-6}$).\n- The pair (Treatment 2, Treatment 3) does not show a significant difference ($p = 0.8000$).\n\nThe number of pairwise differences that are significant at the $\\alpha = 0.05$ level is $2$.", "answer": "$$\n\\boxed{2}\n$$", "id": "4919561"}]}