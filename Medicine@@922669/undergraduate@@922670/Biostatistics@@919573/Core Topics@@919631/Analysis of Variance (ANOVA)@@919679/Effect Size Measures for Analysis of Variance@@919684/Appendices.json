{"hands_on_practices": [{"introduction": "Often in research, you may only have access to summary statistics from a published study, like an $F$-statistic and its degrees of freedom. This practice will equip you with the skill to derive the partial eta-squared ($\\eta_p^2$) effect size directly from these values, a crucial ability for meta-analyses and critical literature reviews. By working from the foundational definitions of ANOVA, you will solidify your understanding of the relationship between hypothesis testing and effect size estimation. [@problem_id:4909886]", "problem": "A biostatistics team conducts a one-way analysis of variance (ANOVA) to compare a continuous biomarker across $3$ treatment groups. The published summary reports an $F$-statistic of $F=12.0$ with numerator degrees of freedom (degrees of freedom for the effect) $df_{\\text{effect}}=2$ and denominator degrees of freedom (degrees of freedom for the error) $df_{\\text{error}}=40$. Starting from the foundational definitions of analysis of variance (ANOVA)—namely, that the sum of squares for the effect and for the error partition the modeled variability, that the mean square (MS) for a source equals its sum of squares divided by its degrees of freedom, and that the $F$-statistic equals the ratio of the mean square for the effect to the mean square for the error—derive the partial eta-squared $\\eta_{p}^{2}$ for the reported effect from first principles. Interpret partial eta-squared $\\eta_{p}^{2}$ as the proportion of model variability attributable to the effect when considering only the effect and error components.\n\nThen, to illustrate the relationship between the $F$-statistic, degrees of freedom, and the sums of squares, adopt an arbitrary scaling by setting the error mean square to $MS_{\\text{error}}=1$, and under this scaling back-calculate the corresponding $SS_{\\text{effect}}$ and $SS_{\\text{error}}$ that are consistent with the reported $F$, $df_{\\text{effect}}$, and $df_{\\text{error}}$. Use these to verify your derived expression for $\\eta_{p}^{2}$.\n\nReport only the numerical value of $\\eta_{p}^{2}$ as your final answer. Express your final answer as a decimal and round to four significant figures.", "solution": "The problem will be validated by first extracting the given information and then assessing its scientific validity and completeness.\n\n**Step 1: Extract Givens**\n-   The analysis is a one-way analysis of variance (ANOVA).\n-   Number of treatment groups: $3$.\n-   $F$-statistic: $F=12.0$.\n-   Numerator degrees of freedom (effect): $df_{\\text{effect}}=2$.\n-   Denominator degrees of freedom (error): $df_{\\text{error}}=40$.\n-   Foundational definitions:\n    -   The sum of squares for the effect ($SS_{\\text{effect}}$) and the sum of squares for the error ($SS_{\\text{error}}$) partition the modeled variability.\n    -   Mean Square (MS): $MS = \\frac{SS}{df}$.\n    -   $F$-statistic: $F = \\frac{MS_{\\text{effect}}}{MS_{\\text{error}}}$.\n-   Definition of partial eta-squared ($\\eta_p^2$): the proportion of model variability attributable to the effect when considering only the effect and error components. This implies $\\eta_p^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{effect}} + SS_{\\text{error}}}$.\n-   A verification task is required: Set $MS_{\\text{error}}=1$, back-calculate $SS_{\\text{effect}}$ and $SS_{\\text{error}}$, and use them to confirm the $\\eta_p^2$ value.\n-   The final answer for $\\eta_p^2$ must be a decimal rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective.\n-   **Scientific Grounding:** The problem is based on the fundamental principles of ANOVA, a standard and universally accepted statistical method. The provided definitions for $MS$, $F$, and $\\eta_p^2$ are correct. The number of groups ($k=3$) is consistent with the degrees of freedom for the effect, as $df_{\\text{effect}} = k-1 = 3-1 = 2$.\n-   **Well-Posedness:** All necessary information ($F$, $df_{\\text{effect}}$, $df_{\\text{error}}$) is provided to derive a unique value for $\\eta_p^2$. The instructions are clear and lead to a single, verifiable solution.\n-   **Objectivity:** The problem is posed using precise, standard statistical terminology, free of any subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. The solution process will now proceed.\n\nThe objective is to derive an expression for partial eta-squared, $\\eta_p^2$, in terms of the $F$-statistic and its associated degrees of freedom, and then to calculate its value.\n\nFrom the provided definition, partial eta-squared is the proportion of the sum of squares of the effect relative to the sum of the sum of squares of the effect and the sum of squares of the error. Mathematically, this is:\n$$ \\eta_p^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{effect}} + SS_{\\text{error}}} $$\nTo express this in terms of the given quantities, we use the foundational definitions of ANOVA. The $F$-statistic is the ratio of the mean square for the effect to the mean square for the error:\n$$ F = \\frac{MS_{\\text{effect}}}{MS_{\\text{error}}} $$\nThe mean squares are, in turn, defined as the sums of squares divided by their respective degrees of freedom:\n$$ MS_{\\text{effect}} = \\frac{SS_{\\text{effect}}}{df_{\\text{effect}}} \\quad \\text{and} \\quad MS_{\\text{error}} = \\frac{SS_{\\text{error}}}{df_{\\text{error}}} $$\nSubstituting these into the expression for the $F$-statistic gives:\n$$ F = \\frac{SS_{\\text{effect}} / df_{\\text{effect}}}{SS_{\\text{error}} / df_{\\text{error}}} $$\nFrom this equation, we can isolate the ratio of the sums of squares:\n$$ \\frac{SS_{\\text{effect}}}{SS_{\\text{error}}} = F \\cdot \\frac{df_{\\text{effect}}}{df_{\\text{error}}} $$\nNow, we return to the definition of $\\eta_p^2$. To relate it to this ratio, we can divide the numerator and the denominator of the $\\eta_p^2$ expression by $SS_{\\text{error}}$:\n$$ \\eta_p^2 = \\frac{SS_{\\text{effect}} / SS_{\\text{error}}}{(SS_{\\text{effect}} / SS_{\\text{error}}) + (SS_{\\text{error}} / SS_{\\text{error}})} = \\frac{SS_{\\text{effect}} / SS_{\\text{error}}}{(SS_{\\text{effect}} / SS_{\\text{error}}) + 1} $$\nSubstituting the expression for the ratio of sums of squares we derived from the $F$-statistic:\n$$ \\eta_p^2 = \\frac{F \\cdot \\frac{df_{\\text{effect}}}{df_{\\text{error}}}}{F \\cdot \\frac{df_{\\text{effect}}}{df_{\\text{error}}} + 1} $$\nTo simplify this expression, we multiply the numerator and the denominator by $df_{\\text{error}}$:\n$$ \\eta_p^2 = \\frac{F \\cdot df_{\\text{effect}}}{F \\cdot df_{\\text{effect}} + df_{\\text{error}}} $$\nThis is the general formula for partial eta-squared derived from first principles.\n\nWe can now substitute the given numerical values: $F=12.0$, $df_{\\text{effect}}=2$, and $df_{\\text{error}}=40$.\n$$ \\eta_p^2 = \\frac{12.0 \\times 2}{(12.0 \\times 2) + 40} = \\frac{24}{24 + 40} = \\frac{24}{64} $$\nSimplifying the fraction gives:\n$$ \\eta_p^2 = \\frac{3 \\times 8}{8 \\times 8} = \\frac{3}{8} = 0.375 $$\n\nNext, we perform the requested verification. We adopt an arbitrary scaling by setting the error mean square to $MS_{\\text{error}} = 1$.\nUsing the definition of the $F$-statistic, we can find the corresponding mean square for the effect:\n$$ MS_{\\text{effect}} = F \\cdot MS_{\\text{error}} = 12.0 \\times 1 = 12.0 $$\nNow, we back-calculate the sums of squares that are consistent with these mean squares and the given degrees of freedom:\n$$ SS_{\\text{effect}} = MS_{\\text{effect}} \\cdot df_{\\text{effect}} = 12.0 \\times 2 = 24 $$\n$$ SS_{\\text{error}} = MS_{\\text{error}} \\cdot df_{\\text{error}} = 1 \\times 40 = 40 $$\nUsing these sums of squares, we can calculate $\\eta_p^2$ directly from its fundamental definition:\n$$ \\eta_p^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{effect}} + SS_{\\text{error}}} = \\frac{24}{24 + 40} = \\frac{24}{64} = 0.375 $$\nThis result matches the value calculated using the derived formula, thereby verifying its correctness.\n\nThe problem requires the final answer to be rounded to four significant figures. The exact value is $0.375$. To express this with four significant figures, we write it as $0.3750$.\nThis value of $\\eta_p^2 = 0.3750$ means that $37.5\\%$ of the variability in the model (composed of effect and error) is attributable to the treatment group effect.", "answer": "$$\\boxed{0.3750}$$", "id": "4909886"}, {"introduction": "Building on the one-way ANOVA, we now explore how to partition variance in a two-factor design. This exercise uses a balanced experiment—an ideal scenario where the contributions of each factor and their interaction are independent and additive. You will calculate eta-squared ($\\eta^2$) for each model component and discover how they sum neatly to the overall model coefficient of determination ($R^2$), illustrating a key principle of orthogonal designs. [@problem_id:4909895]", "problem": "A biostatistics team conducts a balanced two-factor experiment to investigate variability in a continuous biomarker. Factor $A$ has fixed levels representing diet patterns, factor $B$ has fixed levels representing physical activity categories, and their interaction is considered. The study design is balanced across all cells, and a standard two-way Analysis of Variance (ANOVA) is used. The sums of squares reported from the fitted model are: total sum of squares $SS_T = 2400$, main effect sum of squares for factor $A$, $SS_A = 600$, main effect sum of squares for factor $B$, $SS_B = 300$, and interaction sum of squares $SS_{AB} = 200$.\n\nStarting from the core definition that an effect size in ANOVA quantifies the proportion of the total variability attributable to a particular source, and that the overall model’s explanatory power is quantified by the proportion of the total variability explained by all modeled sources collectively, derive and compute the effect size measure eta-squared $\\eta^2$ for each modeled source ($A$, $B$, and $A \\times B$) and the model coefficient of determination ($R^2$). Then, interpret whether there is any discrepancy between the sum of the eta-squared values for the individual sources and the model $R^2$ in this balanced two-way ANOVA context.\n\nReport all numerical values as exact fractions. No rounding is required. The interpretation should be included in your derivation, but the final answer must only contain the requested numerical results.", "solution": "The problem is valid as it is scientifically grounded in the principles of Analysis of Variance (ANOVA), is well-posed with sufficient and consistent data, and is expressed in objective language.\n\nThe analysis begins from the fundamental definitions of effect size measures in the context of ANOVA. The Total Sum of Squares, $SS_T$, represents the total variability in the collected data. The given value is $SS_T = 2400$.\n\nThe effect size measure eta-squared, denoted by $\\eta^2$, quantifies the proportion of the total variability that is attributable to a specific source of variation (a factor or an interaction). Its definition is:\n$$ \\eta^2_{\\text{source}} = \\frac{SS_{\\text{source}}}{SS_T} $$\nwhere $SS_{\\text{source}}$ is the sum of squares for the specific source.\n\nWe apply this definition to each of the modeled sources provided in the problem: factor $A$, factor $B$, and the interaction $A \\times B$.\n\nFor factor $A$, the sum of squares is $SS_A = 600$. The corresponding eta-squared is:\n$$ \\eta^2_A = \\frac{SS_A}{SS_T} = \\frac{600}{2400} = \\frac{1}{4} $$\nThis indicates that factor $A$ (diet patterns) accounts for $25\\%$ of the total variability in the biomarker.\n\nFor factor $B$, the sum of squares is $SS_B = 300$. The corresponding eta-squared is:\n$$ \\eta^2_B = \\frac{SS_B}{SS_T} = \\frac{300}{2400} = \\frac{3}{24} = \\frac{1}{8} $$\nThis indicates that factor $B$ (physical activity categories) accounts for $12.5\\%$ of the total variability.\n\nFor the interaction effect $A \\times B$, the sum of squares is $SS_{AB} = 200$. The corresponding eta-squared is:\n$$ \\eta^2_{AB} = \\frac{SS_{AB}}{SS_T} = \\frac{200}{2400} = \\frac{2}{24} = \\frac{1}{12} $$\nThis indicates that the interaction between diet and physical activity accounts for approximately $8.33\\%$ of the total variability.\n\nNext, we address the overall model's explanatory power, quantified by the coefficient of determination, $R^2$. $R^2$ is defined as the proportion of the total variability explained by all modeled sources collectively. This is the ratio of the model sum of squares, $SS_{\\text{model}}$, to the total sum of squares, $SS_T$.\n$$ R^2 = \\frac{SS_{\\text{model}}}{SS_T} $$\nThe model sum of squares, $SS_{\\text{model}}$, is the total variation captured by the ANOVA model, which includes all factors and their interactions. A critical piece of information is that the experiment has a **balanced design**. In a balanced ANOVA, the sums of squares for the different effects (main effects and interactions) are orthogonal. This implies that they represent non-overlapping sources of variance, and their sum equals the total sum of squares explained by the model.\nTherefore, for this balanced design, the model sum of squares is simply the sum of the sums of squares for each effect included in the model:\n$$ SS_{\\text{model}} = SS_A + SS_B + SS_{AB} $$\nUsing the given values:\n$$ SS_{\\text{model}} = 600 + 300 + 200 = 1100 $$\nNow, we can compute the coefficient of determination, $R^2$:\n$$ R^2 = \\frac{SS_{\\text{model}}}{SS_T} = \\frac{1100}{2400} = \\frac{11}{24} $$\nThis means the model as a whole (diet, activity, and their interaction) explains approximately $45.83\\%$ of the total variability in the biomarker.\n\nFinally, we interpret the relationship between the sum of the individual eta-squared values and the model $R^2$. Let us calculate the sum:\n$$ \\eta^2_A + \\eta^2_B + \\eta^2_{AB} = \\frac{1}{4} + \\frac{1}{8} + \\frac{1}{12} $$\nTo sum these fractions, we find a common denominator, which is $24$:\n$$ \\frac{6}{24} + \\frac{3}{24} + \\frac{2}{24} = \\frac{6+3+2}{24} = \\frac{11}{24} $$\nWe observe that:\n$$ \\eta^2_A + \\eta^2_B + \\eta^2_{AB} = R^2 $$\nIn this balanced two-way ANOVA context, there is no discrepancy. The sum of the eta-squared values for the individual sources is exactly equal to the model's overall coefficient of determination, $R^2$. This is a direct mathematical consequence of the orthogonality of the sums of squares in a balanced design. The total explained variance, $SS_{\\text{model}}$, is cleanly partitioned among the factors and their interaction, and this additive partitioning carries over directly to the proportions of total variance (the $\\eta^2$ values). It is important to note that this simple additive relationship does not hold for unbalanced designs, where the sums of squares for the effects are correlated and do not sum to the model sum of squares.\n\nThe computed numerical results are: $\\eta^2_A = \\frac{1}{4}$, $\\eta^2_B = \\frac{1}{8}$, $\\eta^2_{AB} = \\frac{1}{12}$, and $R^2 = \\frac{11}{24}$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{4} & \\frac{1}{8} & \\frac{1}{12} & \\frac{11}{24} \\end{pmatrix}}\n$$", "id": "4909895"}, {"introduction": "Experimental data in biostatistics is often imperfect, leading to unbalanced designs with unequal group sizes. This practice addresses this common challenge, demonstrating how to calculate eta-squared ($\\eta^2$) while also confronting the critical issue of how variance is attributed when factors are no longer orthogonal. You will explore the importance of different methods for calculating sums of squares, such as Type II sums of squares, and understand why this choice is fundamental to interpreting results in realistic research scenarios. [@problem_id:4909850]", "problem": "A two-factor study in biostatistics evaluates an inflammatory biomarker response under different dietary regimens and genotypes. Factor $\\mathcal{A}$ is dietary regimen with $3$ levels (low, medium, high), and factor $\\mathcal{B}$ is genotype with $2$ levels (X, Y). The design is unbalanced with cell sample sizes: $n_{A_1B_1}=12$, $n_{A_1B_2}=8$, $n_{A_2B_1}=9$, $n_{A_2B_2}=13$, $n_{A_3B_1}=11$, $n_{A_3B_2}=7$, so the total sample size is $N=60$. A two-way Analysis of Variance (ANOVA) with interaction was fit, and Type II sums of squares (SS) were reported as follows for the main effects and interaction: $SS_{\\mathcal{A}}=280$ with $\\mathrm{df}_{\\mathcal{A}}=2$, $SS_{\\mathcal{B}}=210$ with $\\mathrm{df}_{\\mathcal{B}}=1$, $SS_{\\mathcal{A}\\mathcal{B}}=70$ with $\\mathrm{df}_{\\mathcal{A}\\mathcal{B}}=2$. The residual (error) sum of squares is $SS_{\\mathrm{E}}=420$ with $\\mathrm{df}_{\\mathrm{E}}=54$, and the total sum of squares is $SS_{\\mathrm{T}}=980$ with $\\mathrm{df}_{\\mathrm{T}}=59$.\n\nStarting from first principles of ANOVA decomposition and the definition of proportion of explained variability, compute the effect size $\\eta^2$ for the main effect of diet $\\mathcal{A}$ using the provided Type II sums of squares. Round your answer to four significant figures and express it as a decimal (do not use a percentage sign). Then, based on the structure of sums of squares in factorial ANOVA, briefly explain why Type I (sequential) sums of squares would yield different values for the main effects in this unbalanced design compared to the Type II results.", "solution": "The problem requires the calculation of the effect size measure eta-squared ($\\eta^2$) for a main effect in a two-way Analysis of Variance (ANOVA) and a conceptual explanation of the differences between Type I and Type II sums of squares in the context of an unbalanced design.\n\nFirst, we validate the problem statement. The givens are:\n- Factor $\\mathcal{A}$ (diet) with $a=3$ levels.\n- Factor $\\mathcal{B}$ (genotype) with $b=2$ levels.\n- An unbalanced design with total sample size $N=60$.\n- Type II Sums of Squares (SS): $SS_{\\mathcal{A}}=280$, $SS_{\\mathcal{B}}=210$, $SS_{\\mathcal{A}\\mathcal{B}}=70$.\n- Residual (Error) Sum of Squares: $SS_{\\mathrm{E}}=420$.\n- Total Sum of Squares: $SS_{\\mathrm{T}}=980$.\n- Degrees of freedom (df): $\\mathrm{df}_{\\mathcal{A}}=a-1=2$, $\\mathrm{df}_{\\mathcal{B}}=b-1=1$, $\\mathrm{df}_{\\mathcal{A}\\mathcal{B}}=(a-1)(b-1)=2$, $\\mathrm{df}_{\\mathrm{E}}=N-ab=60-6=54$, and $\\mathrm{df}_{\\mathrm{T}}=N-1=59$.\nAll provided df values are consistent with the design parameters. The sum of the model SS and error SS is $SS_{\\mathcal{A}} + SS_{\\mathcal{B}} + SS_{\\mathcal{A}\\mathcal{B}} + SS_{\\mathrm{E}} = 280 + 210 + 70 + 420 = 980$, which equals the provided $SS_{\\mathrm{T}}$. This indicates that for this specific case (a two-factor model), the provided Type II SS partition the total sum of squares alongside the error term. The problem is internally consistent, scientifically grounded in statistical theory, and well-posed. We may proceed with the solution.\n\nPart 1: Calculation of Eta-Squared ($\\eta^2$) for Factor $\\mathcal{A}$\n\nThe eta-squared coefficient, $\\eta^2$, is a measure of effect size that quantifies the proportion of the total variance in a dependent variable that is associated with a particular independent variable (or factor). It is defined as the ratio of the sum of squares for the effect of interest to the total sum of squares.\n\nThe formula for $\\eta^2$ for a generic effect is:\n$$ \\eta^2_{\\text{effect}} = \\frac{SS_{\\text{effect}}}{SS_{\\mathrm{T}}} $$\nIn this problem, we are asked to compute $\\eta^2$ for the main effect of diet, which is factor $\\mathcal{A}$. The problem provides the necessary values: the sum of squares for factor $\\mathcal{A}$ is $SS_{\\mathcal{A}} = 280$, and the total sum of squares is $SS_{\\mathrm{T}} = 980$.\n\nSubstituting these values into the formula:\n$$ \\eta^2_{\\mathcal{A}} = \\frac{SS_{\\mathcal{A}}}{SS_{\\mathrm{T}}} = \\frac{280}{980} $$\nThe fraction can be simplified:\n$$ \\frac{280}{980} = \\frac{28}{98} = \\frac{14}{49} = \\frac{2}{7} $$\nTo express this as a decimal rounded to four significant figures, we perform the division:\n$$ \\eta^2_{\\mathcal{A}} = \\frac{2}{7} \\approx 0.28571428... $$\nRounding to four significant figures gives $0.2857$. This means that approximately $28.57\\%$ of the total variability in the inflammatory biomarker response is attributable to the main effect of the dietary regimen.\n\nPart 2: Explanation of Type I vs. Type II Sums of Squares\n\nThe distinction between different types of sums of squares (Type I, II, III) is critical in ANOVA for non-orthogonal designs, which are designs where the factors are correlated. Unbalanced designs, like the one in this problem with unequal cell sample sizes, are a primary example of non-orthogonality.\n\nIn a balanced factorial design (equal cell sizes), the factors are orthogonal. This means the sums of squares for the different effects ($SS_{\\mathcal{A}}$, $SS_{\\mathcal{B}}$, $SS_{\\mathcal{A}\\mathcal{B}}$) are independent and partition the model sum of squares additively and uniquely. In such a case, Type I and Type II sums of squares will be identical.\n\nIn an unbalanced design, the factors are not orthogonal. This non-orthogonality implies that there is an overlap in the variance explained by factor $\\mathcal{A}$ and factor $\\mathcal{B}$. The different types of SS represent different strategies for attributing this shared variance.\n\nType I (Sequential) Sums of Squares: This method is order-dependent. The sum of squares for each factor is calculated as the additional variance it explains given the factors that have already been entered into the model.\n- If the model is specified with order $\\mathcal{A}$, then $\\mathcal{B}$, the sums of squares are:\n  - $SS_{\\mathcal{A}}(\\text{Type I}) = SS(\\mathcal{A})$\n  - $SS_{\\mathcal{B}}(\\text{Type I}) = SS(\\mathcal{B} | \\mathcal{A})$\n- If the model is specified with order $\\mathcal{B}$, then $\\mathcal{A}$, the sums of squares are:\n  - $SS_{\\mathcal{B}}(\\text{Type I}) = SS(\\mathcal{B})$\n  - $SS_{\\mathcal{A}}(\\text{Type I}) = SS(\\mathcal{A} | \\mathcal{B})$\nDue to the non-orthogonality, $SS(\\mathcal{A}) \\neq SS(\\mathcal{A} | \\mathcal{B})$ and $SS(\\mathcal{B}) \\neq SS(\\mathcal{B} | \\mathcal{A})$. Therefore, the value of the main effect sum of squares for Type I depends on the order chosen for the analysis.\n\nType II (Partial) Sums of Squares: This method tests each main effect after accounting for all other main effects. It adheres to the principle of marginality by not adjusting a main effect for any interaction term that includes it. For a two-factor model with interaction:\n- The SS for factor $\\mathcal{A}$ is adjusted for factor $\\mathcal{B}$: $SS_{\\mathcal{A}}(\\text{Type II}) = SS(\\mathcal{A} | \\mathcal{B})$.\n- The SS for factor $\\mathcal{B}$ is adjusted for factor $\\mathcal{A}$: $SS_{\\mathcal{B}}(\\text{Type II}) = SS(\\mathcal{B} | \\mathcal{A})$.\n- The SS for the interaction is adjusted for both main effects: $SS_{\\mathcal{A}\\mathcal{B}}(\\text{Type II}) = SS(\\mathcal{A}\\mathcal{B} | \\mathcal{A}, \\mathcal{B})$.\nThese values are independent of the order in which the factors are specified in the model.\n\nConclusion of Comparison: The provided $SS_{\\mathcal{A}} = 280$ is a Type II sum of squares, representing $SS(\\mathcal{A} | \\mathcal{B})$. A Type I analysis would yield a different result for $SS_{\\mathcal{A}}$ if factor $\\mathcal{A}$ were entered into the model first. In that case, the Type I SS would be $SS(\\mathcal{A})$, which is the variance explained by $\\mathcal{A}$ alone, without adjusting for $\\mathcal{B}$. Because the design is unbalanced, this value would not be equal to $SS(\\mathcal{A} | \\mathcal{B})$. Thus, the sequential partitioning of variance in Type I SS leads to order-dependent results for main effects that differ from the order-independent results of Type II SS in an unbalanced design.", "answer": "$$ \\boxed{0.2857} $$", "id": "4909850"}]}