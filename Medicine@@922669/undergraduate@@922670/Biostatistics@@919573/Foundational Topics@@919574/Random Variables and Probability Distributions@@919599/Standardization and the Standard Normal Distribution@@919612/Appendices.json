{"hands_on_practices": [{"introduction": "Before tackling complex applications, a firm grasp of the fundamental properties of the normal distribution is essential. This exercise reinforces the core mechanism of standardization, which transforms any normal variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ into the universal standard normal scale. By solving for an unknown constant using the inherent symmetry of the distribution, you will practice the foundational skill that underpins nearly all statistical inference involving normal data [@problem_id:15198].", "problem": "Consider a continuous random variable $X$ that follows a normal distribution with a mean $\\mu$ and a variance $\\sigma^2$, denoted as $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$. The probability density function (PDF) for this distribution is symmetric about its mean $\\mu$.\n\nA constant $c$ is defined such that the probability of observing a value of $X$ greater than $c$ is equal to the probability of observing a value of $X$ less than $c - 2\\sigma$. This relationship is expressed as:\n$$\n\\mathbb{P}(X > c) = \\mathbb{P}(X  c - 2\\sigma)\n$$\nUsing the properties of the normal distribution, specifically the process of standardization and the symmetry of the standard normal distribution, derive an expression for the constant $c$ in terms of $\\mu$ and $\\sigma$.", "solution": "We are given that $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ and a constant $c$ is defined by the relation:\n$$\\mathbb{P}(X > c) = \\mathbb{P}(X  c - 2\\sigma)$$\nTo solve for $c$, we first standardize the random variable $X$ to a standard normal variable $Z = \\frac{X - \\mu}{\\sigma}$, so that $Z \\sim \\mathcal{N}(0, 1)$. We apply this transformation to the terms inside the probabilities.\n\nThe left side becomes:\n$$\\mathbb{P}(X > c) = \\mathbb{P}\\left(\\frac{X - \\mu}{\\sigma} > \\frac{c - \\mu}{\\sigma}\\right) = \\mathbb{P}\\left(Z > \\frac{c - \\mu}{\\sigma}\\right)$$\n\nThe right side becomes:\n$$\\mathbb{P}(X  c - 2\\sigma) = \\mathbb{P}\\left(\\frac{X - \\mu}{\\sigma}  \\frac{(c - 2\\sigma) - \\mu}{\\sigma}\\right) = \\mathbb{P}\\left(Z  \\frac{c - \\mu}{\\sigma} - 2\\right)$$\n\nLet $a = \\frac{c - \\mu}{\\sigma}$. The defining equation transforms to:\n$$\\mathbb{P}(Z > a) = \\mathbb{P}(Z  a - 2)$$\nThe standard normal distribution is symmetric about 0. This means that for any value $k$, $\\mathbb{P}(Z  k) = \\mathbb{P}(Z > -k)$. Applying this property to the right side of our equation, we get:\n$$\\mathbb{P}(Z  a - 2) = \\mathbbP(Z > -(a-2)) = \\mathbb{P}(Z > 2 - a)$$\nSo our equation becomes:\n$$\\mathbb{P}(Z > a) = \\mathbb{P}(Z > 2 - a)$$\nSince the survival function (the probability of being greater than a value) of the standard normal distribution is strictly monotonically decreasing, this equality implies that the arguments must be equal:\n$$a = 2 - a$$\n$$2a = 2$$\n$$a = 1$$\nNow, we substitute back the expression for $a$:\n$$\\frac{c - \\mu}{\\sigma} = 1$$\nSolving for $c$ gives:\n$$c = \\mu + \\sigma$$", "answer": "$$\\boxed{\\mu+\\sigma}$$", "id": "15198"}, {"introduction": "In practice, many biological measurements, such as biomarker concentrations, are strictly positive and exhibit right-skewed distributions. This exercise introduces the log-normal distribution, a common and powerful model for such data [@problem_id:4990401]. You will see how a simple logarithmic transformation allows us to leverage the entire toolkit of the standard normal distribution, enabling the calculation of percentiles and the establishment of clinical reference ranges for data that is not normally distributed on its original scale.", "problem": "A clinical laboratory models a strictly positive biomarker $X$ (for example, a concentration in serum) using a log-normal distribution motivated by multiplicative biological variation. Specifically, the natural logarithm $Y=\\ln X$ is assumed to be Gaussian with mean $\\mu$ and variance $\\sigma^2$, that is, $Y \\sim \\mathcal{N}(\\mu,\\sigma^2)$. Using only (i) the definition of the Cumulative Distribution Function (CDF) $F_W(w)=\\mathbb{P}(W \\le w)$ for a random variable $W$, (ii) the facts that the exponential function $x \\mapsto e^x$ is strictly increasing on $\\mathbb{R}$ and that the natural logarithm is its inverse, and (iii) the standardization property of the normal distribution to the standard normal cumulative distribution function $\\Phi(\\cdot)$, determine the correct expression for the CDF $F_X(x)$ of $X$ and describe the correct mapping between percentiles of $X$ and $z$-scores for $Y=\\ln X$. Choose the single option that correctly states both the CDF (including its support) and the percentile–$z$-score mapping.\n\nA. For $x \\in \\mathbb{R}$,\n$F_X(x)=\\begin{cases}\n0,  x \\le 0,\\\\\n\\Phi\\!\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right),  x  0,\n\\end{cases}$\nand the $p$th percentile $x_p$ of $X$ satisfies $z_p=\\Phi^{-1}(p)=\\dfrac{\\ln x_p-\\mu}{\\sigma}$, equivalently $x_p=\\exp\\!\\big(\\mu+\\sigma z_p\\big)$.\n\nB. For $x \\in \\mathbb{R}$,\n$F_X(x)=\\Phi\\!\\left(\\dfrac{x - \\mu}{\\sigma}\\right)$,\nand the $p$th percentile $x_p$ of $X$ is $x_p=\\mu+\\sigma z_p$ where $z_p=\\Phi^{-1}(p)$.\n\nC. For $x \\in \\mathbb{R}$,\n$F_X(x)=\\begin{cases}\n0,  x \\le 0,\\\\\n1-\\Phi\\!\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right),  x  0,\n\\end{cases}$\nand the $p$th percentile $x_p$ of $X$ satisfies $x_p=\\exp\\!\\big(\\mu-\\sigma z_p\\big)$ where $z_p=\\Phi^{-1}(p)$.\n\nD. For $x \\in \\mathbb{R}$,\n$F_X(x)=\\begin{cases}\n0,  x \\le 0,\\\\\n\\Phi\\!\\left(\\dfrac{\\ln x - \\mu}{\\sigma^2}\\right),  x  0,\n\\end{cases}$\nand the $p$th percentile $x_p$ of $X$ satisfies $x_p=\\exp\\!\\big(\\mu+\\sigma^2 z_p\\big)$ where $z_p=\\Phi^{-1}(p)$.\n\nE. For $x \\in \\mathbb{R}$,\n$F_X(x)=\\begin{cases}\n0,  x \\le \\mu,\\\\\n\\Phi\\!\\left(\\dfrac{\\ln(x-\\mu)}{\\sigma}\\right),  x  \\mu,\n\\endcases}$\nand the $p$th percentile $x_p$ of $X$ satisfies $x_p=\\mu\\cdot \\exp\\!\\big(\\sigma z_p\\big)$ where $z_p=\\Phi^{-1}(p)$.", "solution": "We begin from first principles. By assumption, $Y=\\ln X$ is Gaussian with mean $\\mu$ and variance $\\sigma^2$, that is, $Y \\sim \\mathcal{N}(\\mu,\\sigma^2)$. The Cumulative Distribution Function (CDF) of a random variable $W$ is by definition $F_W(w)=\\mathbb{P}(W \\le w)$.\n\nBecause the exponential function $x \\mapsto e^x$ is strictly increasing and the natural logarithm is its inverse, the event $\\{X \\le x\\}$ is equivalent to $\\{\\ln X \\le \\ln x\\}$ whenever $x0$. For $x \\le 0$, since $X=\\exp(Y)$ takes only strictly positive values, $\\mathbb{P}(X \\le x)=0$.\n\nTherefore, for $x0$,\n$$\\mathbb{P}(X \\le x)=\\mathbb{P}(\\ln X \\le \\ln x)=\\mathbb{P}(Y \\le \\ln x)$$\nStandardizing the Gaussian $Y$ gives\n$$\\mathbb{P}(Y \\le \\ln x)=\\mathbb{P}\\!\\left(\\dfrac{Y-\\mu}{\\sigma} \\le \\dfrac{\\ln x-\\mu}{\\sigma}\\right)=\\Phi\\!\\left(\\dfrac{\\ln x-\\mu}{\\sigma}\\right),$$\nwhere $\\Phi(\\cdot)$ denotes the standard normal cumulative distribution function.\n\nCollecting these facts, the CDF of $X$ is\n$$F_X(x)=\\begin{cases}\n0,  x \\le 0,\\\\\n\\Phi\\!\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right),  x  0.\n\\end{cases}$$\n\nNext, we relate percentiles of $X$ to $z$-scores of $Y=\\ln X$. Let $x_p$ denote the $p$th percentile (that is, the $p$-quantile) of $X$, defined by $F_X(x_p)=p$ for $p \\in (0,1)$. For $p \\in (0,1)$, $x_p0$ and thus\n$$p=F_X(x_p)=\\mathbb{P}(X \\le x_p)=\\mathbb{P}(Y \\le \\ln x_p)=\\Phi\\!\\left(\\dfrac{\\ln x_p - \\mu}{\\sigma}\\right).$$\nApplying the inverse of the standard normal cumulative distribution function, $\\Phi^{-1}(\\cdot)$, yields\n$$\\Phi^{-1}(p)=\\dfrac{\\ln x_p - \\mu}{\\sigma}.$$\nDefine $z_p=\\Phi^{-1}(p)$, the standard normal $z$-score corresponding to the cumulative probability $p$. Then\n$$z_p=\\dfrac{\\ln x_p - \\mu}{\\sigma} \\quad \\Longleftrightarrow \\quad \\ln x_p = \\mu + \\sigma z_p \\quad \\Longleftrightarrow \\quad x_p=\\exp\\!\\big(\\mu+\\sigma z_p\\big).$$\n\nThis mapping shows how percentile estimation for $X$ proceeds by computing the $z$-score threshold on $Y=\\ln X$ and exponentiating back to the original scale.\n\nOption-by-option analysis:\n\nA. States $F_X(x)=0$ for $x \\le 0$ and $F_X(x)=\\Phi\\!\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right)$ for $x0$, which matches the derivation. It also gives the correct percentile–$z$ mapping $z_p=\\dfrac{\\ln x_p-\\mu}{\\sigma}$, equivalently $x_p=\\exp(\\mu+\\sigma z_p)$. Verdict — Correct.\n\nB. Uses $F_X(x)=\\Phi\\!\\left(\\dfrac{x-\\mu}{\\sigma}\\right)$, which ignores the logarithmic transformation and treats $X$ as Gaussian. The percentile expression $x_p=\\mu+\\sigma z_p$ is the quantile of a Gaussian, not a log-normal. Verdict — Incorrect.\n\nC. Uses $1-\\Phi\\!\\left(\\dfrac{\\ln x - \\mu}{\\sigma}\\right)$ for $x0$, which would correspond to $\\mathbb{P}(Y \\ge \\ln x)$ rather than $\\mathbb{P}(Y \\le \\ln x)$. It also introduces an incorrect negative sign in the quantile mapping. Verdict — Incorrect.\n\nD. Replaces $\\sigma$ with $\\sigma^2$ inside $\\Phi(\\cdot)$ and in the exponent for the quantile, which is dimensionally inconsistent with standardization; standardization divides by the standard deviation $\\sigma$, not the variance $\\sigma^2$. Verdict — Incorrect.\n\nE. Shifts the support threshold to $x \\le \\mu$ and applies $\\ln(x-\\mu)$, incorrectly mixing a location shift on the $X$-scale with the log transformation. The quantile formula $x_p=\\mu \\cdot \\exp(\\sigma z_p)$ likewise misapplies location and scale. Verdict — Incorrect.\n\nTherefore, only Option A is correct.", "answer": "$$\\boxed{A}$$", "id": "4990401"}, {"introduction": "This practice demonstrates the real-world utility of standardization in the critical phase of experimental design. You will step into the role of a biostatistician planning a clinical screening study and determine the necessary sample size to ensure the research has a high probability of success [@problem_id:4953417]. This exercise integrates standardization with the key concepts of statistical power, effect size, and adjustments for multiple hypothesis tests, illustrating a cornerstone skill in modern biostatistics.", "problem": "A clinical team plans a screening study of $m = 5$ candidate inflammatory biomarkers to determine whether each biomarker’s mean concentration in a treated population exceeds a known historical mean $\\mu_0$ for healthy controls. For each biomarker, individual measurements are modeled as independent and identically distributed draws from a normal distribution with known standard deviation $\\sigma = 1.0$ (in arbitrary concentration units) and unknown mean $\\mu$. The study will enroll the same number $n$ of individuals for each biomarker.\n\nThey will perform $m$ separate one-sided tests $H_0: \\mu = \\mu_0$ versus $H_A: \\mu  \\mu_0$, and declare a “discovery” for a biomarker if its unadjusted one-sided $p$-value is less than $\\alpha/m$, where $\\alpha = 0.05$ is the target family-wise error rate (FWER) level and the division by $m$ implements the Bonferroni correction. The team wants to guarantee that, for any biomarker whose true mean satisfies $\\mu = \\mu_0 + \\Delta$ with $\\Delta = 0.5$, the probability of declaring a discovery (that is, the statistical power) is at least $0.90$ under this decision rule.\n\nUsing the definitions of $p$-values for one-sided $z$-tests, standardization to the standard normal distribution, and the interpretation of power as the probability of falling in the rejection region under the alternative, derive the minimal common per-biomarker sample size $n$ that achieves the stated FWER control and power target. Express your final answer as the smallest integer $n$ that meets the requirement. For numerical evaluation, you may use the standard normal quantiles $z_{0.99} = 2.326$ and $z_{0.90} = 1.282$ (each to four significant figures).", "solution": "This problem requires a sample size calculation for a one-sided $z$-test, adjusted for multiple comparisons using the Bonferroni correction. We need to find the smallest integer sample size $n$ that provides a power of at least $0.90$ for detecting a specific effect size.\n\nLet $\\bar{X}$ be the sample mean of the concentrations for one biomarker, based on a sample of size $n$. Since the individual measurements are normally distributed with mean $\\mu$ and known standard deviation $\\sigma$, the distribution of the sample mean is $\\bar{X} \\sim \\mathcal{N}(\\mu, \\sigma^2/n)$.\n\nThe test statistic for the one-sided hypothesis test $H_0: \\mu = \\mu_0$ versus $H_A: \\mu  \\mu_0$ is the $z$-statistic:\n$$Z = \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}$$\nUnder the null hypothesis $H_0$, this statistic follows a standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$.\n\nThe study performs $m=5$ tests. To control the family-wise error rate (FWER) at $\\alpha = 0.05$, the Bonferroni correction is used. This sets the significance level for each individual test, $\\alpha'$, to:\n$$\\alpha' = \\frac{\\alpha}{m} = \\frac{0.05}{5} = 0.01$$\nA \"discovery\" is declared if the $p$-value is less than $\\alpha'$. For a one-sided upper-tail test, this is equivalent to the test statistic $Z$ exceeding the critical value $z_{1-\\alpha'}$. The rejection region is defined by:\n$$\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}  z_{1-\\alpha'} = z_{0.99}$$\nUsing the provided value, the critical value is $z_{0.99} = 2.326$.\n\nNext, we establish the condition for statistical power. Power is the probability of correctly rejecting the null hypothesis when a specific alternative hypothesis is true. We require a power of at least $0.90$ when the true mean is $\\mu_A = \\mu_0 + \\Delta$, where $\\Delta = 0.5$.\n$$\\text{Power} = \\mathbb{P}\\left(\\text{Reject } H_0 \\mid \\mu = \\mu_A\\right) = \\mathbb{P}\\left(\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}  z_{0.99} \\mid \\mu = \\mu_0 + \\Delta\\right) \\ge 0.90$$\nWhen $\\mu = \\mu_A = \\mu_0 + \\Delta$, the sample mean $\\bar{X}$ is distributed as $\\mathcal{N}(\\mu_0 + \\Delta, \\sigma^2/n)$. To evaluate the probability, we standardize the expression with respect to this true distribution. We manipulate the inequality:\n$$ \\mathbb{P}\\left(\\frac{\\bar{X} - (\\mu_0 + \\Delta) + \\Delta}{\\sigma/\\sqrt{n}}  z_{0.99}\\right) \\ge 0.90 $$\n$$ \\mathbb{P}\\left(\\frac{\\bar{X} - \\mu_A}{\\sigma/\\sqrt{n}} + \\frac{\\Delta\\sqrt{n}}{\\sigma}  z_{0.99}\\right) \\ge 0.90 $$\nThe term $\\frac{\\bar{X} - \\mu_A}{\\sigma/\\sqrt{n}}$ is a standard normal random variable under the alternative hypothesis, let's call it $Z'$. So, $Z' \\sim \\mathcal{N}(0, 1)$. The inequality becomes:\n$$ \\mathbb{P}\\left(Z'  z_{0.99} - \\frac{\\Delta\\sqrt{n}}{\\sigma}\\right) \\ge 0.90 $$\nLet $\\Phi(\\cdot)$ be the cumulative distribution function (CDF) of the standard normal distribution. We know that $\\mathbb{P}(Z'  c) \\ge 0.90$ is equivalent to $c \\le z_{0.10}$. By symmetry, $z_{0.10} = -z_{0.90}$.\nTherefore, we require:\n$$ z_{0.99} - \\frac{\\Delta\\sqrt{n}}{\\sigma} \\le -z_{0.90} $$\nNow, we can solve for $n$:\n$$ z_{0.99} + z_{0.90} \\le \\frac{\\Delta\\sqrt{n}}{\\sigma} $$\n$$ \\sqrt{n} \\ge \\frac{\\sigma}{\\Delta}(z_{0.99} + z_{0.90}) $$\n$$ n \\ge \\left(\\frac{\\sigma}{\\Delta}(z_{0.99} + z_{0.90})\\right)^2 $$\nSubstitute the given values: $\\sigma = 1.0$, $\\Delta = 0.5$, $z_{0.99} = 2.326$, and $z_{0.90} = 1.282$.\n$$ n \\ge \\left(\\frac{1.0}{0.5}(2.326 + 1.282)\\right)^2 $$\n$$ n \\ge (2(3.608))^2 $$\n$$ n \\ge (7.216)^2 $$\n$$ n \\ge 52.070656 $$\nSince the sample size $n$ must be an integer, we must take the smallest integer that satisfies this condition, which is the ceiling of the calculated value.\n$$ n = \\lceil 52.070656 \\rceil = 53 $$\nThe minimal common per-biomarker sample size required is $53$.", "answer": "$$\\boxed{53}$$", "id": "4953417"}]}