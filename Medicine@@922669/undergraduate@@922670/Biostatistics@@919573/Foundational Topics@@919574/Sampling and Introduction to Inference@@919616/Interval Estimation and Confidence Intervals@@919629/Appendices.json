{"hands_on_practices": [{"introduction": "The first step in any rigorous quantitative study is planning. This practice guides you through one of the most fundamental calculations in study design: determining the necessary sample size. By deriving and applying the sample size formula for a population mean, you will gain a concrete understanding of the interplay between statistical confidence, desired precision, and the resources required for an investigation. [@problem_id:4560495]", "problem": "A clinical biomarker of systemic inflammation is quantified in milligrams per liter (mg/L). Investigators plan a study to estimate the population mean biomarker level, denoted by $\\mu$, using a two-sided confidence interval (CI) at confidence level $1 - \\alpha = 0.95$. Based on a prior meta-analysis across independent cohorts, the within-subject measurement process and biological variability for this biomarker are well-modeled by independent and identically distributed (i.i.d.) Gaussian observations $X_{1}, X_{2}, \\dots, X_{n}$ with mean $\\mu$ and known variance $\\sigma^{2}$. The meta-analysis provides an externally validated variance estimate $\\sigma^{2} = 64$ (mg/L)$^{2}$ that can be treated as known for planning purposes.\n\nStarting from the core definitions of a two-sided confidence interval and the sampling distribution of the sample mean under the Gaussian model with known variance, derive a relationship connecting the CI width $W$, the sample size $n$, the variance $\\sigma^{2}$, and the appropriate quantile of the standard normal distribution. Then, using this relationship, determine the smallest integer $n$ that guarantees a planned two-sided CI for $\\mu$ has total width $W = 3$ mg/L at confidence level $0.95$.\n\nReport the final sample size $n$ as a single integer. If non-integer calculations occur, choose the smallest integer $n$ that satisfies the width constraint $W \\leq 3$ mg/L. Do not include any units in your final numeric answer.", "solution": "The problem asks for the determination of the minimum sample size, $n$, required to achieve a specified confidence interval width for a population mean, $\\mu$, given a known population variance, $\\sigma^2$.\n\n### Step 1: Problem Validation\n\n**1.1. Extraction of Givens:**\n- Population parameter to be estimated: Population mean biomarker level, $\\mu$.\n- Data model: Independent and identically distributed (i.i.d.) Gaussian observations $X_{1}, X_{2}, \\dots, X_{n}$.\n- Distribution of observations: $X_i \\sim N(\\mu, \\sigma^2)$.\n- Known population variance: $\\sigma^2 = 64$ (mg/L)$^2$.\n- Confidence level: $1 - \\alpha = 0.95$.\n- Desired total width of the two-sided confidence interval: $W = 3$ mg/L.\n- Constraint: The final sample size $n$ must be the smallest integer that satisfies the width requirement.\n\n**1.2. Validation using Extracted Givens:**\n- **Scientific Grounding:** The problem is firmly grounded in standard statistical theory for hypothesis testing and estimation, specifically the construction of confidence intervals for the mean of a normal distribution with known variance. This is a canonical problem in biostatistics and clinical trial design. The values provided are plausible for a biological measurement.\n- **Well-Posedness:** The problem is well-posed. It provides all necessary information ($\\sigma^2$, confidence level, target width) to determine a unique integer solution for the sample size $n$.\n- **Objectivity:** The problem statement is objective, precise, and free of ambiguity or subjective language.\n\n**1.3. Verdict:**\nThe problem is valid. It is scientifically sound, well-posed, and objective. There are no contradictions, missing information, or violations of fundamental principles. We may proceed with the solution.\n\n### Step 2: Derivation and Solution\n\nThe estimator for the population mean $\\mu$ is the sample mean, $\\bar{X}$, defined as:\n$$\n\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n$$\nGiven that $X_i$ are i.i.d. random variables drawn from a normal distribution $N(\\mu, \\sigma^2)$, the sampling distribution of the sample mean $\\bar{X}$ is also normal. The mean of $\\bar{X}$ is $E[\\bar{X}] = \\mu$, and its variance is $\\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n}$. Thus, the sampling distribution is:\n$$\n\\bar{X} \\sim N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\n$$\nTo construct a confidence interval, we use a pivotal quantity whose distribution does not depend on the unknown parameter $\\mu$. We standardize $\\bar{X}$ to obtain a standard normal random variable, $Z$:\n$$\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim N(0, 1)\n$$\nA two-sided confidence interval with confidence level $1 - \\alpha$ is constructed from the probability statement:\n$$\nP(-z_{\\alpha/2} \\le Z \\le z_{\\alpha/2}) = 1 - \\alpha\n$$\nwhere $z_{\\alpha/2}$ is the upper $\\alpha/2$ quantile of the standard normal distribution, defined by $P(Z > z_{\\alpha/2}) = \\alpha/2$.\n\nSubstituting the expression for $Z$ gives:\n$$\nP\\left(-z_{\\alpha/2} \\le \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\le z_{\\alpha/2}\\right) = 1 - \\alpha\n$$\nWe rearrange the inequality to isolate the parameter $\\mu$:\n$$\n-z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\le \\bar{X} - \\mu \\le z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n$$\n$$\n-\\bar{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\le -\\mu \\le -\\bar{X} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n$$\n$$\n\\bar{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\le \\mu \\le \\bar{X} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n$$\nThis defines the $100(1-\\alpha)\\%$ confidence interval for $\\mu$:\n$$\n\\text{CI} = \\left[ \\bar{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\right]\n$$\nThe total width, $W$, of this confidence interval is the difference between the upper bound and the lower bound:\n$$\nW = \\left( \\bar{X} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\right) - \\left( \\bar{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\right) = 2 z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n$$\nThis equation provides the required relationship connecting the width $W$, the sample size $n$, the standard deviation $\\sigma$, and the standard normal quantile $z_{\\alpha/2}$.\n\nThe problem requires that the total width be $W = 3$ mg/L. To be more precise, the planned width should be at most $3$ mg/L. Thus, we have the inequality:\n$$\nW \\le 3 \\implies 2 z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\le 3\n$$\nWe can now solve for $n$:\n$$\n\\sqrt{n} \\ge \\frac{2 z_{\\alpha/2} \\sigma}{3}\n$$\n$$\nn \\ge \\left( \\frac{2 z_{\\alpha/2} \\sigma}{3} \\right)^2\n$$\nNow we substitute the given values.\nThe confidence level is $1 - \\alpha = 0.95$, so $\\alpha = 0.05$ and $\\alpha/2 = 0.025$. The corresponding quantile for the standard normal distribution is $z_{0.025}$. This is the value such that the cumulative probability is $1 - 0.025 = 0.975$. The standard value for $z_{0.025}$ is approximately $1.96$.\nThe known variance is $\\sigma^2 = 64$ (mg/L)$^2$, so the standard deviation is $\\sigma = \\sqrt{64} = 8$ mg/L.\nThe maximum desired width is $W = 3$ mg/L.\n\nSubstituting these values into the inequality for $n$:\n$$\nn \\ge \\left( \\frac{2 \\times 1.96 \\times 8}{3} \\right)^2\n$$\n$$\nn \\ge \\left( \\frac{31.36}{3} \\right)^2\n$$\n$$\nn \\ge (10.4533...)^2\n$$\n$$\nn \\ge 109.2718...\n$$\nSince the sample size $n$ must be an integer, we must take the smallest integer greater than or equal to $109.2718...$. This is necessary to ensure the width constraint $W \\le 3$ is met. Therefore, the minimum required sample size is $n=110$.", "answer": "$$\\boxed{110}$$", "id": "4560495"}, {"introduction": "While formulas provide the tools for statistical inference, their application requires critical thought. This exercise presents a scenario with sparse data—a common challenge in clinical trials—to demonstrate how standard, \"naive\" methods for confidence intervals can produce nonsensical results that fall outside the valid parameter space. By evaluating different approaches, you will learn why choosing a method that respects the underlying properties of the data is crucial for sound scientific conclusions. [@problem_id:4805492]", "problem": "A randomized clinical trial evaluates the risk of a serious adverse event in two independent arms: treatment arm with $n_1 = 10$ participants and $x_1 = 0$ events, and control arm with $n_2 = 10$ participants and $x_2 = 9$ events. Let $p_1$ and $p_2$ denote the true risks in the treatment and control arms, respectively. The primary estimands of interest are the risk difference $p_1 - p_2$ and the risk ratio $p_1 / p_2$. In small samples with parameters near the boundary of the parameter space, naive normal approximations can fail to respect constraints such as $p \\in [0,1]$ or $p_1 - p_2 \\in [-1,1]$ or $p_1/p_2 \\in (0,\\infty)$. You are asked to identify which statements below are correct, based on first principles of interval estimation, including the definition of a confidence interval as an inverted family of hypothesis tests, large-sample normal approximations derived from the Central Limit Theorem, and small-sample corrections such as using Student’s $t$ distributions with degrees of freedom obtained by the Welch–Satterthwaite approximation.\n\nWhich of the following statements about constructing $95$ percent confidence intervals in this setting are correct?\n\nA. The simple Wald $95$ percent confidence interval for the risk difference $p_1 - p_2$ applied to these data extends below $-1$, illustrating how a naive normal approximation can yield an invalid interval outside $[-1,1]$ in small samples near the boundary.\n\nB. Truncating any Wald interval that falls outside the parameter space to the nearest boundary point (for example, replacing a lower bound less than $-1$ by $-1$) restores valid $95$ percent coverage.\n\nC. A score-based interval for the risk difference $p_1 - p_2$ constructed by inverting the score test for the null hypothesis $H_0: p_1 - p_2 = \\delta$ across $\\delta \\in [-1,1]$ yields an interval that respects the natural bounds and typically exhibits substantially improved small-sample coverage compared with the Wald interval.\n\nD. For bounded outcomes or parameters handled via a monotone link function (for example, modeling on the logit scale and then inverse-transforming), a two-sample interval for a difference of means on the transformed scale that uses Student’s $t$ critical values with degrees of freedom given by the Welch–Satterthwaite approximation provides a small-sample correction; inverse transformation of group-specific intervals returns estimates confined to $[0,1]$. This strategy exemplifies a constrained interval construction for bounded parameters.\n\nE. For a single binomial proportion $p$, adding a continuity correction to the Wald interval guarantees that the interval lies within $[0,1]$ while maintaining nominal coverage, so no transformation or exact inversion is needed.\n\nSelect all that apply.", "solution": "The problem statement has been validated and is deemed sound. It presents a standard, albeit challenging, scenario in biostatistics involving interval estimation for proportions in small samples with extreme outcomes. The data and concepts are scientifically and mathematically well-defined.\n\nThe data provided are from a two-arm randomized clinical trial:\n- Treatment arm: $n_1 = 10$ participants, $x_1 = 0$ events. The sample proportion is $\\hat{p}_1 = x_1/n_1 = 0/10 = 0$.\n- Control arm: $n_2 = 10$ participants, $x_2 = 9$ events. The sample proportion is $\\hat{p}_2 = x_2/n_2 = 9/10 = 0.9$.\n\nThe estimand of primary interest is the risk difference, $p_1 - p_2$. The point estimate for the risk difference is $\\hat{p}_1 - \\hat{p}_2 = 0 - 0.9 = -0.9$. We are asked to evaluate several statements about the construction of $95\\%$ confidence intervals (CIs). The critical value from the standard normal distribution for a $95\\%$ CI is $z_{1 - 0.05/2} = z_{0.975} \\approx 1.96$.\n\n### Analysis of Option A\n\nThis statement claims that the simple Wald $95\\%$ confidence interval for the risk difference $p_1 - p_2$ extends below $-1$. The formula for the Wald interval for the difference of two independent proportions is:\n$$ (\\hat{p}_1 - \\hat{p}_2) \\pm z_{1-\\alpha/2} \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}} $$\nFirst, we calculate the standard error (SE):\n$$ SE(\\hat{p}_1 - \\hat{p}_2) = \\sqrt{\\frac{0(1-0)}{10} + \\frac{0.9(1-0.9)}{10}} = \\sqrt{0 + \\frac{0.9 \\times 0.1}{10}} = \\sqrt{\\frac{0.09}{10}} = \\sqrt{0.009} \\approx 0.09487 $$\nNext, we calculate the margin of error (ME):\n$$ ME = z_{0.975} \\times SE \\approx 1.96 \\times 0.09487 \\approx 0.18595 $$\nThe $95\\%$ Wald CI is then:\n$$ (\\hat{p}_1 - \\hat{p}_2) \\pm ME = -0.9 \\pm 0.18595 $$\nThis gives the interval $[-1.08595, -0.71405]$. The lower bound, $-1.08595$, is less than $-1$. The parameter space for the risk difference $p_1 - p_2$ is $[-1, 1]$, as probabilities must be a subset of $[0, 1]$. Therefore, the calculated Wald interval is not contained within the valid parameter space. The statement correctly identifies this well-known failure of the naive Wald method in small samples where estimates are on or near the boundary of the parameter space.\n\n**Verdict: Correct**\n\n### Analysis of Option B\n\nThis statement proposes that truncating an interval that extends beyond the parameter space to the nearest boundary point restores valid $95\\%$ coverage. In our example, this would mean replacing the interval $[-1.08595, -0.71405]$ with $[-1, -0.71405]$. A confidence interval procedure is said to have $95\\%$ coverage if, in repeated sampling, the intervals generated by the procedure contain the true parameter value $95\\%$ of the time. The failure of the Wald interval to stay within bounds is a symptom of a deeper problem: the normal approximation to the sampling distribution of $\\hat{p}_1 - \\hat{p}_2$ is poor in this setting. The distribution is skewed, and the symmetric Wald interval is incorrectly centered and/or has the wrong width. Simply truncating the interval (an ad-hoc fix) does not correct this underlying distributional misspecification. The resulting truncated interval procedure is not guaranteed to have $95\\%$ coverage and, in general, does not. Statistical literature shows that the coverage of such truncated intervals can still be systematically and substantially different from the nominal confidence level.\n\n**Verdict: Incorrect**\n\n### Analysis of Option C\n\nThis statement describes the properties of a score-based interval. Such an interval is constructed by finding the set of all null-hypothesized values of the parameter, $\\delta_0$, for which the score test of $H_0: p_1 - p_2 = \\delta_0$ does not reject. The score test statistic is based on a variance estimate calculated under the null hypothesis, which tends to make the test's and the inverted interval's properties more stable across the parameter space. It is a well-established result in statistical theory that score-based confidence intervals (also known as Wilson intervals in the single-proportion case) have superior performance compared to Wald intervals for binomial proportions, especially in small samples or with proportions near $0$ or $1$. Two key properties are:\n1.  **Range-respecting:** The score interval is guaranteed to lie within the valid parameter space (here, $[-1, 1]$) without any need for ad-hoc truncation.\n2.  **Improved coverage:** The actual coverage probability of the score interval procedure is typically much closer to the nominal level (e.g., $95\\%$) than that of the Wald procedure.\nThe statement accurately summarizes these fundamental advantages of the score method.\n\n**Verdict: Correct**\n\n### Analysis of Option D\n\nThis statement describes a general strategy for constructing confidence intervals for bounded parameters. Let us analyze its components:\n1.  **Handling bounded parameters via a monotone link function:** This refers to transforming the parameter $p \\in [0,1]$ using a function like the logit, $g(p) = \\log(p/(1-p))$, which maps to the entire real line $(-\\infty, \\infty)$. This is a standard and sound technique.\n2.  **Using a two-sample t-interval with Welch-Satterthwaite approximation:** On the transformed scale, one would have two sample means (e.g., $\\text{logit}(\\hat{p}_1)$ and $\\text{logit}(\\hat{p}_2)$) with potentially unequal variances. The Welch-Satterthwaite approximation for the degrees of freedom of a Student's $t$ distribution is the standard small-sample correction for comparing two means in this situation. This is a valid statistical principle.\n3.  **Inverse transformation confines intervals to $[0,1]$:** If an interval $[L, U]$ is constructed for a transformed parameter like $\\text{logit}(p)$, applying the inverse transformation $g^{-1}(y) = e^y/(1+e^y)$ to the endpoints yields an interval for $p$, guaranteed to be within $(0,1)$. This is a correct mathematical property.\n4.  **Exemplifies a constrained interval construction:** The combination of these techniques—transformation to an unbounded scale, interval construction, and back-transformation—is a textbook example of a principled method for creating intervals that respect the natural constraints of a parameter.\n\nThe statement is a correct description of a valid set of statistical principles that constitute a general strategy. While its naive application to the given data would require adjustment (e.g., adding pseudocounts because $\\hat{p}_1=0$, for which the logit is undefined), the statement itself, which describes the principles of the strategy, is factually correct.\n\n**Verdict: Correct**\n\n### Analysis of Option E\n\nThis statement claims that adding a continuity correction to the Wald interval for a single proportion guarantees the interval lies within $[0,1]$. A common form of the continuity-corrected Wald interval is $\\hat{p} \\pm (z_{1-\\alpha/2}\\sqrt{\\hat{p}(1-\\hat{p})/n} + 1/(2n))$. The term $1/(2n)$ is a correction that widens the interval to better approximate a discrete distribution with a continuous one. This widening does not, however, prevent the interval from crossing the $[0,1]$ boundaries. In fact, it can exacerbate the problem.\nLet's apply this to the control group data: $\\hat{p}_2 = 0.9$ and $n_2 = 10$. The uncorrected Wald interval upper bound was already greater than $1$: $0.9 + 1.96 \\sqrt{0.9(0.1)/10} \\approx 1.086$. With the continuity correction, the new upper bound is:\n$$ 0.9 + \\left(1.96 \\sqrt{\\frac{0.9(0.1)}{10}} + \\frac{1}{2 \\times 10}\\right) \\approx 0.9 + (0.186 + 0.05) = 1.136 $$\nThis is even further above $1$. The premise that the continuity correction guarantees the interval lies within $[0,1]$ is demonstrably false. Therefore, the conclusion that \"no transformation or exact inversion is needed\" is unsupported.\n\n**Verdict: Incorrect**", "answer": "$$\\boxed{ACD}$$", "id": "4805492"}, {"introduction": "How can we be sure that a $95\\%$ confidence interval procedure truly captures the parameter $95\\%$ of the time? This practice introduces you to a powerful, modern technique: the Monte Carlo simulation. You will act as a computational statistician to build a \"virtual laboratory\" that tests the performance of different interval methods, allowing you to empirically verify theoretical claims about their coverage probabilities and understand concepts like conservatism and asymptotic approximation in a tangible way. [@problem_id:4805580]", "problem": "Consider a binary outcome model in which the number of events $X$ observed in $n$ independent trials follows a Binomial distribution $X \\sim \\mathrm{Binomial}(n,p)$ with unknown event probability $p \\in (0,1)$. In the frequentist framework, the coverage of a confidence interval for $p$ is defined as the probability, under repeated sampling from the true model, that the interval contains the true parameter value. Formally, for a confidence interval procedure that maps data $X$ to an interval $I(X)$, the coverage at a particular $p$ is $C(p) = \\mathbb{P}_p\\{p \\in I(X)\\}$.\n\nDesign a simulation study to empirically assess the coverage of three different two-sided confidence intervals for the binomial proportion $p$, each at nominal confidence level $1-\\alpha$:\n\n- The Wald interval obtained from asymptotic normality of the maximum likelihood estimator $\\hat{p}=X/n$.\n- The Wilson score interval obtained by inverting the score test for $H_0: p=p_0$.\n- The exact Clopper–Pearson interval obtained by inverting the exact binomial test.\n\nUse the following fundamental base to derive and implement each interval:\n\n- The data-generating mechanism $X \\sim \\mathrm{Binomial}(n,p)$ and the maximum likelihood estimator $\\hat{p}=X/n$.\n- Asymptotic normality of $\\hat{p}$: under regularity, $\\sqrt{n}(\\hat{p}-p)$ is approximately normal with mean $0$ and variance $p(1-p)$, and a plug-in estimate may be used for $p$ in the variance term.\n- The score test for $H_0: p=p_0$ in the binomial model, and confidence intervals obtained by inverting this test.\n- Exact test inversion for the binomial model leading to equal-tailed confidence intervals, computable via quantiles of the Beta distribution.\n\nYou must implement a Monte Carlo simulation that, for each test case, generates $M$ independent realizations $X_1,\\dots,X_M$ from the Binomial model with the specified $(n,p)$, constructs the three confidence intervals for each realization, and estimates coverage for each method as the fraction of realizations whose interval contains the true $p$. Intervals must be clipped to the parameter space $[0,1]$ to ensure scientific realism. Randomness must be made reproducible by fixing the random number generator seed.\n\nSimulation parameters:\n\n- Nominal confidence: $1-\\alpha = 0.95$ (that is, $\\alpha = 0.05$).\n- Number of Monte Carlo replicates per test case: $M = 10000$.\n- Random seed: $12345$.\n\nTest suite (each test case is a pair $(n,p)$):\n\n- Case $1$: $(n,p) = (20,\\,0.01)$.\n- Case $2$: $(n,p) = (20,\\,0.10)$.\n- Case $3$: $(n,p) = (20,\\,0.50)$.\n- Case $4$: $(n,p) = (50,\\,0.01)$.\n- Case $5$: $(n,p) = (50,\\,0.10)$.\n- Case $6$: $(n,p) = (50,\\,0.50)$.\n- Case $7$: $(n,p) = (200,\\,0.01)$.\n- Case $8$: $(n,p) = (200,\\,0.10)$.\n- Case $9$: $(n,p) = (200,\\,0.50)$.\n\nFor each test case, report the empirical coverage for the three methods in the fixed order Wilson, Clopper–Pearson, Wald. Express each coverage as a decimal rounded to $4$ places. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a three-element list corresponding to a test case, for example, `[[c_1_Wilson, c_1_CP, c_1_Wald], [c_2_Wilson, c_2_CP, c_2_Wald], ...]`.", "solution": "The supplied problem is valid. It is a well-defined task in computational statistics, grounded in established statistical theory, and all necessary parameters for its execution are provided.\n\nThe objective is to conduct a Monte Carlo simulation study to evaluate the empirical coverage probability of three common confidence intervals for a binomial proportion, $p$. The coverage probability of an interval procedure $I(X)$ for a parameter $p$ is defined as the probability, over repeated sampling, that the computed interval contains the true value of $p$. For a nominal confidence level of $1-\\alpha$, a good interval procedure should have its actual coverage $C(p) = \\mathbb{P}_p\\{p \\in I(X)\\}$ close to $1-\\alpha$ for all possible values of $p$.\n\nThe simulation will proceed as follows. For each test case, defined by a number of trials $n$ and a true probability $p_{\\text{true}}$, we generate $M=10000$ independent outcomes $X_i \\sim \\mathrm{Binomial}(n, p_{\\text{true}})$. For each outcome $X_i$, we compute the three specified confidence intervals. The empirical coverage for each method is then estimated as the fraction of these $M$ intervals that contain $p_{\\text{true}}$. The nominal confidence level is $1-\\alpha = 0.95$, so $\\alpha = 0.05$. The critical value from the standard normal distribution is $z_{\\alpha/2} = z_{0.025}$, which is the $(1 - 0.025)$-th quantile of $\\mathcal{N}(0,1)$.\n\nLet $X$ be the number of successes in $n$ trials. The maximum likelihood estimator (MLE) for $p$ is $\\hat{p} = X/n$.\n\n### 1. Wald Interval\n\nThe Wald interval is derived from the asymptotic normality of the MLE. The Central Limit Theorem implies that for large $n$, the distribution of $\\hat{p}$ is approximately normal: $\\hat{p} \\sim \\mathcal{N}(p, \\frac{p(1-p)}{n})$. By Slutsky's theorem, we can substitute the consistent estimator $\\hat{p}$ for $p$ in the variance term, leading to the standardized statistic:\n$$ Z = \\frac{\\hat{p} - p}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}} $$\nwhich is approximately distributed as a standard normal $\\mathcal{N}(0,1)$. A $100(1-\\alpha)\\%$ confidence interval for $p$ is formed by finding the set of $p$ values for which $|Z| \\le z_{\\alpha/2}$:\n$$ \\mathbb{P}\\left(-z_{\\alpha/2} \\le \\frac{\\hat{p} - p}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}} \\le z_{\\alpha/2}\\right) \\approx 1-\\alpha $$\nSolving for $p$ yields the Wald interval:\n$$ \\left[ \\hat{p} - z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}, \\; \\hat{p} + z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\right] $$\nA practical issue arises when $X=0$ or $X=n$, making $\\hat{p}=0$ or $\\hat{p}=1$. In these cases, the standard error term $\\sqrt{\\hat{p}(1-\\hat{p})/n}$ becomes $0$, and the interval collapses to a point, $[0,0]$ or $[1,1]$, which unrealistically suggests perfect certainty. The computed interval will be clipped to $[0,1]$.\n\n### 2. Wilson Score Interval\n\nThe Wilson score interval is derived by inverting the score test. Unlike the Wald interval, the score test uses the variance under the null hypothesis, $p_0(1-p_0)/n$, which avoids the issue of using $\\hat{p}$ in the standard error. The interval is the set of all possible values $p_0$ for which the null hypothesis $H_0: p=p_0$ is not rejected at level $\\alpha$. This corresponds to the set of $p$ satisfying:\n$$ \\left| \\frac{\\hat{p} - p}{\\sqrt{\\frac{p(1-p)}{n}}} \\right| \\le z_{\\alpha/2} $$\nSquaring both sides and rearranging terms gives a quadratic inequality in $p$:\n$$ (\\hat{p} - p)^2 \\le z_{\\alpha/2}^2 \\frac{p(1-p)}{n} $$\n$$ n(\\hat{p}^2 - 2\\hat{p}p + p^2) \\le z_{\\alpha/2}^2 (p - p^2) $$\n$$ (n + z_{\\alpha/2}^2)p^2 - (2n\\hat{p} + z_{\\alpha/2}^2)p + n\\hat{p}^2 \\le 0 $$\nThe roots of the corresponding quadratic equation $Ap^2+Bp+C=0$ define the endpoints of the interval. Using the quadratic formula $\\frac{-B \\pm \\sqrt{B^2-4AC}}{2A}$ with $A = n+z_{\\alpha/2}^2$, $B = -(2n\\hat{p} + z_{\\alpha/2}^2)$, and $C = n\\hat{p}^2$, the interval is given by:\n$$ \\frac{2n\\hat{p} + z_{\\alpha/2}^2 \\pm z_{\\alpha/2}\\sqrt{4n\\hat{p}(1-\\hat{p}) + z_{\\alpha/2}^2}}{2(n+z_{\\alpha/2}^2)} $$\nThis can be expressed as:\n$$ \\frac{1}{1 + z_{\\alpha/2}^2/n} \\left( \\hat{p} + \\frac{z_{\\alpha/2}^2}{2n} \\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z_{\\alpha/2}^2}{4n^2}} \\right) $$\nThis interval has better performance than the Wald interval, especially for small sample sizes or when $p$ is close to $0$ or $1$.\n\n### 3. Clopper-Pearson Interval\n\nThe Clopper-Pearson interval is an \"exact\" method derived by inverting two one-sided binomial tests. It is constructed to guarantee that the coverage probability is at least $1-\\alpha$ for all values of $p$.\nThe lower endpoint, $p_L$, is the solution to:\n$$ \\mathbb{P}(X \\ge x | p=p_L) = \\sum_{k=x}^{n} \\binom{n}{k} p_L^k (1-p_L)^{n-k} = \\frac{\\alpha}{2} $$\nThe upper endpoint, $p_U$, is the solution to:\n$$ \\mathbb{P}(X \\le x | p=p_U) = \\sum_{k=0}^{x} \\binom{n}{k} p_U^k (1-p_U)^{n-k} = \\frac{\\alpha}{2} $$\nThese equations can be solved using the relationship between the binomial cumulative distribution function and the regularized incomplete beta function. The interval endpoints are given by quantiles of the Beta distribution:\n- The lower bound $p_L$ is the $\\alpha/2$ quantile of a Beta distribution with parameters $(x, n-x+1)$: $p_L = \\mathrm{Beta}^{-1}(\\alpha/2; x, n-x+1)$. For the special case $x=0$, $p_L=0$.\n- The upper bound $p_U$ is the $1-\\alpha/2$ quantile of a Beta distribution with parameters $(x+1, n-x)$: $p_U = \\mathrm{Beta}^{-1}(1-\\alpha/2; x+1, n-x)$. For the special case $x=n$, $p_U=1$.\n\nThis method is known to be conservative, meaning its actual coverage often exceeds the nominal $1-\\alpha$ level.\n\nThe simulation will be implemented in Python using the `numpy` library for vectorized computations and random number generation, and `scipy.stats` for statistical functions (quantiles of normal and beta distributions). The random number generator will be seeded with $12345$ for reproducibility.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, beta\n\ndef solve():\n    \"\"\"\n    Performs a Monte Carlo simulation to estimate the coverage of Wald, Wilson,\n    and Clopper-Pearson confidence intervals for a binomial proportion.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (20, 0.01),\n        (20, 0.10),\n        (20, 0.50),\n        (50, 0.01),\n        (50, 0.10),\n        (50, 0.50),\n        (200, 0.01),\n        (200, 0.10),\n        (200, 0.50),\n    ]\n\n    # Simulation parameters\n    M = 10000\n    alpha = 0.05\n    seed = 12345\n    rng = np.random.default_rng(seed)\n    \n    # Pre-calculate the standard normal critical value\n    z_crit = norm.ppf(1 - alpha / 2)\n    \n    all_results = []\n    \n    for n, p_true in test_cases:\n        # Generate M binomial random variates\n        # Shape: (M,)\n        X = rng.binomial(n, p_true, size=M)\n        \n        # Estimate of p\n        # Shape: (M,)\n        p_hat = X / n\n        \n        # --- 1. Wald Interval ---\n        # Standard error for the Wald interval\n        wald_se = np.sqrt(p_hat * (1 - p_hat) / n)\n        wald_lower = p_hat - z_crit * wald_se\n        wald_upper = p_hat + z_crit * wald_se\n        \n        # Clip interval to [0, 1]\n        wald_lower = np.maximum(0, wald_lower)\n        wald_upper = np.minimum(1, wald_upper)\n        \n        # Calculate coverage\n        wald_covered = (wald_lower <= p_true) & (p_true <= wald_upper)\n        wald_coverage = np.mean(wald_covered)\n        \n        # --- 2. Wilson Score Interval ---\n        z2 = z_crit**2\n        denom = 1 + z2 / n\n        center_adj = (p_hat + z2 / (2 * n))\n        \n        term = z_crit * np.sqrt( (p_hat * (1 - p_hat) / n) + (z2 / (4 * n**2)) )\n        \n        wilson_lower = (center_adj - term) / denom\n        wilson_upper = (center_adj + term) / denom\n\n        # Clip interval to [0, 1]\n        wilson_lower = np.maximum(0, wilson_lower)\n        wilson_upper = np.minimum(1, wilson_upper)\n        \n        # Calculate coverage\n        wilson_covered = (wilson_lower <= p_true) & (p_true <= wilson_upper)\n        wilson_coverage = np.mean(wilson_covered)\n\n        # --- 3. Clopper-Pearson Interval ---\n        alpha_half = alpha / 2\n        \n        # Lower bound\n        cp_lower = np.zeros_like(p_hat)\n        # Handle cases where X > 0, otherwise beta.ppf fails for a=0\n        mask_pos_x = X > 0\n        cp_lower[mask_pos_x] = beta.ppf(alpha_half, X[mask_pos_x], n - X[mask_pos_x] + 1)\n        \n        # Upper bound\n        cp_upper = np.ones_like(p_hat)\n        # Handle cases where X < n, otherwise beta.ppf fails for b=0\n        mask_lt_n = X < n\n        cp_upper[mask_lt_n] = beta.ppf(1 - alpha_half, X[mask_lt_n] + 1, n - X[mask_lt_n])\n        \n        # Calculate coverage\n        cp_covered = (cp_lower <= p_true) & (p_true <= cp_upper)\n        cp_coverage = np.mean(cp_covered)\n        \n        # Store results rounded to 4 decimal places in the specified order\n        # (Wilson, Clopper-Pearson, Wald)\n        case_results = [\n            round(wilson_coverage, 4),\n            round(cp_coverage, 4),\n            round(wald_coverage, 4)\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as specified\n    sub_results_str = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output_str = f\"[{','.join(sub_results_str)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```", "id": "4805580"}]}