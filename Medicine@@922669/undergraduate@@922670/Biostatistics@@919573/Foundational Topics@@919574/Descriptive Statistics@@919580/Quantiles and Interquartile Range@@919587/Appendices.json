{"hands_on_practices": [{"introduction": "To truly master quantiles, we must begin with their formal definition for continuous probability distributions. This exercise invites you to derive the quartiles and interquartile range (IQR) for the exponential distribution directly from its cumulative distribution function (CDF) [@problem_id:4826359]. This practice is fundamental, as it solidifies the theoretical underpinnings of quantiles and provides experience with a distribution commonly used in biostatistics to model time-to-event data.", "problem": "In a randomized clinical trial evaluating time to clinical response for an acute infection, suppose the time-to-event variable $T$ for each patient is modeled by an exponential distribution with a constant hazard rate parameter $\\lambda0$. Let $F_T(t)$ denote the cumulative distribution function (CDF) of $T$. Use only foundational definitions to derive the first and third quartiles of $T$ and the interquartile range. Specifically, proceed from the definition that, for a continuous distribution with a strictly increasing CDF, the $p$-th quantile $x_p$ is the unique real number satisfying $F_T(x_p)=p$ for $p \\in (0,1)$. The interquartile range (IQR) is defined as $\\mathrm{IQR}=Q_3-Q_1$, where $Q_1$ and $Q_3$ are the first and third quartiles corresponding to $p=\\frac{1}{4}$ and $p=\\frac{3}{4}$, respectively. Assume the standard exponential model form for $F_T(t)$ without providing any additional quantile formulas. Report only the final symbolic expression for $\\mathrm{IQR}$ as a function of $\\lambda$ in your final answer. Do not include units in your final boxed answer.", "solution": "The problem is deemed valid as it is scientifically grounded, well-posed, and objective. It presents a standard exercise in applying fundamental definitions from probability and statistics to a canonical distribution, the exponential distribution, which is commonly used in modeling time-to-event data in medical and engineering contexts. All provided information is self-contained and consistent.\n\nThe problem requires the derivation of the interquartile range (IQR) for a random variable $T$ that follows an exponential distribution. The derivation must proceed from first principles. The time-to-event variable $T$ is characterized by a constant hazard rate parameter $\\lambda  0$.\n\nFirst, we must establish the cumulative distribution function (CDF) for the exponential distribution. The probability density function (PDF) for a random variable $T$ following an exponential distribution with rate parameter $\\lambda$ is given by $f_T(t) = \\lambda \\exp(-\\lambda t)$ for $t \\ge 0$, and $f_T(t) = 0$ for $t  0$. The CDF, $F_T(t)$, is the probability that the event occurs by time $t$, i.e., $P(T \\le t)$. It is found by integrating the PDF from $0$ to $t$:\n$$F_T(t) = \\int_{0}^{t} \\lambda \\exp(-\\lambda \\tau) \\, d\\tau$$\nEvaluating this integral, we obtain:\n$$F_T(t) = \\left[ -\\exp(-\\lambda \\tau) \\right]_{0}^{t} = -\\exp(-\\lambda t) - (-\\exp(-\\lambda \\cdot 0)) = -\\exp(-\\lambda t) - (-1)$$\nThus, the CDF for the exponential distribution is:\n$$F_T(t) = 1 - \\exp(-\\lambda t) \\quad \\text{for } t \\ge 0$$\nFor $t  0$, $F_T(t)=0$. Since time-to-event cannot be negative, we are concerned with the domain $t \\ge 0$. The CDF is strictly increasing for $t \\ge 0$.\n\nThe problem states that the $p$-th quantile, which we denote as $t_p$, is the value such that $F_T(t_p) = p$, where $p \\in (0,1)$. We can use this definition to find a general expression for the quantiles of the exponential distribution. We set the CDF equal to $p$ and solve for $t_p$:\n$$1 - \\exp(-\\lambda t_p) = p$$\nRearranging the terms to solve for $t_p$:\n$$\\exp(-\\lambda t_p) = 1 - p$$\nTo isolate the exponent, we take the natural logarithm of both sides of the equation:\n$$\\ln(\\exp(-\\lambda t_p)) = \\ln(1 - p)$$\n$$-\\lambda t_p = \\ln(1 - p)$$\nSolving for $t_p$, we arrive at the quantile function for the exponential distribution:\n$$t_p = -\\frac{1}{\\lambda} \\ln(1 - p) = \\frac{1}{\\lambda} \\ln\\left(\\frac{1}{1-p}\\right)$$\n\nNext, we apply this derived formula to find the first and third quartiles. The first quartile, $Q_1$, corresponds to the $p = \\frac{1}{4}$ quantile:\n$$Q_1 = t_{1/4} = -\\frac{1}{\\lambda} \\ln\\left(1 - \\frac{1}{4}\\right) = -\\frac{1}{\\lambda} \\ln\\left(\\frac{3}{4}\\right)$$\nUsing the property of logarithms $\\ln(a/b) = -\\ln(b/a)$, this can be written as:\n$$Q_1 = \\frac{1}{\\lambda} \\ln\\left(\\frac{4}{3}\\right)$$\n\nThe third quartile, $Q_3$, corresponds to the $p = \\frac{3}{4}$ quantile:\n$$Q_3 = t_{3/4} = -\\frac{1}{\\lambda} \\ln\\left(1 - \\frac{3}{4}\\right) = -\\frac{1}{\\lambda} \\ln\\left(\\frac{1}{4}\\right)$$\nSimilarly, this can be written as:\n$$Q_3 = \\frac{1}{\\lambda} \\ln(4)$$\n\nFinally, the interquartile range (IQR) is defined as the difference between the third and first quartiles, $\\mathrm{IQR} = Q_3 - Q_1$. Substituting the expressions we found for $Q_1$ and $Q_3$:\n$$\\mathrm{IQR} = \\frac{1}{\\lambda} \\ln(4) - \\frac{1}{\\lambda} \\ln\\left(\\frac{4}{3}\\right)$$\nFactoring out the common term $\\frac{1}{\\lambda}$:\n$$\\mathrm{IQR} = \\frac{1}{\\lambda} \\left( \\ln(4) - \\ln\\left(\\frac{4}{3}\\right) \\right)$$\nUsing the logarithmic property $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$\\mathrm{IQR} = \\frac{1}{\\lambda} \\ln\\left(\\frac{4}{4/3}\\right) = \\frac{1}{\\lambda} \\ln\\left(4 \\cdot \\frac{3}{4}\\right)$$\nThis simplifies to the final expression for the interquartile range:\n$$\\mathrm{IQR} = \\frac{1}{\\lambda} \\ln(3)$$\nThis result shows that, for an exponential distribution, the interquartile range is a constant value determined solely by the rate parameter $\\lambda$ and is independent of time.", "answer": "$$\\boxed{\\frac{\\ln(3)}{\\lambda}}$$", "id": "4826359"}, {"introduction": "The five-number summary and its visual counterpart, the boxplot, are powerful tools for exploratory data analysis, but they do not capture every feature of a dataset. This hands-on problem demonstrates that two datasets can share an identical five-number summary yet possess different levels of variability, as measured by the standard deviation [@problem_id:1943502]. By working through these calculations, you will gain a deeper appreciation for the importance of using multiple summary statistics to achieve a comprehensive understanding of a distribution's shape.", "problem": "A fundamental concept in exploratory data analysis is the summarization of a dataset's distribution. The five-number summary—comprising the minimum, first quartile ($Q_1$), median, third quartile ($Q_3$), and maximum—is a widely used tool for this purpose, often visualized using a boxplot. However, this summary does not capture all characteristics of a distribution. Two datasets can have identical five-number summaries yet differ significantly in other statistical properties, such as their mean and variance.\n\nThis problem explores this phenomenon. Consider the following two datasets, Dataset A and Dataset B, each containing $n=13$ numerical observations which are already sorted in ascending order.\n\nDataset A: $\\{10, 15, 18, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100\\}$\nDataset B: $\\{10, 11, 19, 20, 21, 22, 50, 78, 79, 80, 81, 99, 100\\}$\n\nFor the purpose of this problem, we define the quartiles for a sorted dataset of size $n$ as follows:\n- The first quartile ($Q_1$) is the value at position $p_1 = 0.25(n-1)+1$.\n- The median ($Q_2$) is the value at position $p_2 = 0.5(n-1)+1$.\n- The third quartile ($Q_3$) is the value at position $p_3 = 0.75(n-1)+1$.\n\nThe sample standard deviation, $s$, is calculated using the formula $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2}$, where $\\bar{x}$ is the sample mean of the observations $x_i$.\n\nCalculate the value of the ratio $\\frac{s_B}{s_A}$, where $s_A$ and $s_B$ are the sample standard deviations of Dataset A and Dataset B, respectively. Round your final answer to three significant figures.", "solution": "We have $n=13$ for both datasets. For each dataset, let $S=\\sum_{i=1}^{n} x_{i}$, $\\bar{x}=\\frac{S}{n}$, and $\\sum x_{i}^{2}=\\sum_{i=1}^{n} x_{i}^{2}$. Using the identity\n$$\n\\sum_{i=1}^{n} (x_{i}-\\bar{x})^{2}=\\sum x_{i}^{2}-\\frac{S^{2}}{n},\n$$\nthe sample variance is\n$$\ns^{2}=\\frac{1}{n-1}\\left(\\sum x_{i}^{2}-\\frac{S^{2}}{n}\\right).\n$$\n\nDataset A: $\\{10,15,18,20,30,40,50,60,70,80,90,95,100\\}$.\nCompute $S_{A}$ and $\\sum x_{i}^{2}$:\n$$\nS_{A}=10+15+18+20+30+40+50+60+70+80+90+95+100=678,\n$$\n$$\n\\sum x_{i}^{2}=100+225+324+400+900+1600+2500+3600+4900+6400+8100+9025+10000=48074.\n$$\nThus\n$$\n\\mathrm{SS}_{A}=\\sum x_{i}^{2}-\\frac{S_{A}^{2}}{n}=48074-\\frac{678^{2}}{13}\n=\\frac{624962-459684}{13}=\\frac{165278}{13}.\n$$\nHence\n$$\ns_{A}^{2}=\\frac{\\mathrm{SS}_{A}}{n-1}=\\frac{\\frac{165278}{13}}{12}=\\frac{165278}{156}=\\frac{82639}{78}.\n$$\n\nDataset B: $\\{10,11,19,20,21,22,50,78,79,80,81,99,100\\}$.\nCompute $S_{B}$ and $\\sum x_{i}^{2}$:\n$$\nS_{B}=10+11+19+20+21+22+50+78+79+80+81+99+100=670,\n$$\n$$\n\\sum x_{i}^{2}=100+121+361+400+441+484+2500+6084+6241+6400+6561+9801+10000=49494.\n$$\nThus\n$$\n\\mathrm{SS}_{B}=\\sum x_{i}^{2}-\\frac{S_{B}^{2}}{n}=49494-\\frac{670^{2}}{13}\n=\\frac{643422-448900}{13}=\\frac{194522}{13}.\n$$\nHence\n$$\ns_{B}^{2}=\\frac{\\mathrm{SS}_{B}}{n-1}=\\frac{\\frac{194522}{13}}{12}=\\frac{194522}{156}=\\frac{97261}{78}.\n$$\n\nTherefore, the ratio of sample standard deviations is\n$$\n\\frac{s_{B}}{s_{A}}=\\sqrt{\\frac{s_{B}^{2}}{s_{A}^{2}}}=\\sqrt{\\frac{\\frac{97261}{78}}{\\frac{82639}{78}}}\n=\\sqrt{\\frac{97261}{82639}}.\n$$\nNumerically, $\\frac{97261}{82639}\\approx 1.176938249\\,$, so\n$$\n\\frac{s_{B}}{s_{A}} \\approx \\sqrt{1.176938249}\\approx 1.084866\\ldots\n$$\nRounded to three significant figures, this is $1.08$.", "answer": "$$\\boxed{1.08}$$", "id": "1943502"}, {"introduction": "The calculation of sample quantiles in statistical software is not governed by a single, universal rule; instead, multiple conventions exist, each with its own statistical properties. This advanced practice challenges you to perform a Monte Carlo simulation to compare the performance of several common quantile estimation methods under different distributional scenarios [@problem_id:4826295]. Please note that this exercise uses simulated data to illustrate the statistical principles of estimator performance; it provides a valuable look into the world of computational statistics and the critical task of selecting appropriate algorithms for data analysis.", "problem": "Consider a simulation-based comparison of sample quantile conventions in the context of statistical inference for medical data summaries. In evidence synthesis, quartiles and the Interquartile Range (IQR) are frequently reported to characterize skewness and variability. The goal is to compare different sample quantile conventions in small samples drawn from distributions that are skewed or heavy-tailed, quantifying their performance in estimating population quartiles and the IQR.\n\nFundamental base:\n- Let $X$ be a real-valued continuous random variable with cumulative distribution function (CDF) $F_{X}(x)$. The population quantile function $Q_{X}(p)$ is defined as $Q_{X}(p) = \\inf\\{x : F_{X}(x) \\ge p\\}$ for $p \\in (0,1)$.\n- Given a sample $\\{X_{1},\\dots,X_{n}\\}$ from $X$, let $X_{(1)} \\le \\cdots \\le X_{(n)}$ denote the order statistics. A sample quantile convention defines an estimator $\\widehat{Q}(p)$ as a function of $\\{X_{(i)}\\}_{i=1}^{n}$, typically via index mapping and interpolation rules.\n- Root Mean Square Error (RMSE) for an estimator $\\widehat{\\theta}$ of a true value $\\theta$ is defined as $\\operatorname{RMSE}(\\widehat{\\theta}) = \\sqrt{\\mathbb{E}\\left[(\\widehat{\\theta}-\\theta)^{2}\\right]}$, and the Mean Squared Error (MSE) is $\\operatorname{MSE}(\\widehat{\\theta}) = \\mathbb{E}\\left[(\\widehat{\\theta}-\\theta)^{2}\\right]$.\n\nYou must implement four sample quantile conventions:\n- Convention $1$: A linear interpolation convention consistent with Hyndman–Fan Type $7$.\n- Convention $2$: A linear interpolation convention consistent with Hyndman–Fan Type $8$.\n- Convention $3$: A linear interpolation convention consistent with Hyndman–Fan Type $9$.\n- Convention $4$: The Harrell–Davis quantile estimator based on Beta-distributed weights over all order statistics.\n\nFor each convention, estimate the first quartile $\\widehat{Q}(0.25)$, the median $\\widehat{Q}(0.50)$, the third quartile $\\widehat{Q}(0.75)$, and the Interquartile Range $\\widehat{\\mathrm{IQR}} = \\widehat{Q}(0.75) - \\widehat{Q}(0.25)$.\n\nTarget distributions and their population quantiles:\n- Log-normal distribution with parameters $(\\mu,\\sigma)$, defined by $Y = \\exp(Z)$ with $Z \\sim \\mathcal{N}(\\mu,\\sigma^{2})$. The population quantile is $Q_{Y}(p) = \\exp\\left(\\mu + \\sigma \\Phi^{-1}(p)\\right)$ where $\\Phi^{-1}$ is the inverse CDF of the standard normal distribution.\n- Student $t$ distribution with Degrees of Freedom (DoF) $\\nu$, whose population quantile is $Q_{T}(p) = t_{\\nu}^{-1}(p)$, the inverse CDF of the Student $t$ distribution with $\\nu$ degrees of freedom.\n\nPerformance metric:\n- For each convention and each target (quartiles and IQR), compute the Mean Squared Error (MSE) across Monte Carlo replications by comparing the estimator to the corresponding population quantity.\n- For each target, identify the convention index $c \\in \\{1,2,3,4\\}$ that minimizes MSE. In case of ties, choose the smallest index.\n\nSimulation design:\n- For each test case, simulate $R$ independent samples of size $n$ from the specified distribution, compute the four estimators for each replication, and aggregate MSEs over the replications.\n- Use a fixed random seed to ensure reproducibility.\n\nTest suite:\n- Case $1$: Log-normal with $(\\mu,\\sigma) = (0,1)$, sample size $n=10$, replications $R=5000$.\n- Case $2$: Log-normal with $(\\mu,\\sigma) = (0,1)$, sample size $n=5$, replications $R=5000$.\n- Case $3$: Student $t$ with $\\nu=2$, sample size $n=10$, replications $R=5000$.\n- Case $4$: Student $t$ with $\\nu=2$, sample size $n=20$, replications $R=5000$.\n\nTargets to evaluate in each case:\n- First quartile at $p=0.25$.\n- Median at $p=0.50$.\n- Third quartile at $p=0.75$.\n- Interquartile Range (IQR).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces. The result for each case must be a list of four integers in the order $[w_{Q1},w_{\\text{median}},w_{Q3},w_{\\text{IQR}}]$, where each integer is the index of the winning convention $\\in \\{1,2,3,4\\}$. Aggregate the four case results into a single top-level list. For example, a valid output would look like $[[1,2,3,4],[1,1,2,2],[3,3,3,1],[2,2,2,2]]$.", "solution": "The user has provided a well-defined computational statistics problem. The request is to validate the problem statement according to a strict set of criteria and, if valid, to provide a complete solution including a theoretical explanation and a Python implementation.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Objective:** Compare four sample quantile conventions by estimating their Mean Squared Error (MSE) in estimating population quartiles and the Interquartile Range (IQR).\n- **Quantile Conventions:**\n    1.  Hyndman-Fan Type $7$ (linear interpolation).\n    2.  Hyndman-Fan Type $8$ (linear interpolation).\n    3.  Hyndman-Fan Type $9$ (linear interpolation).\n    4.  Harrell-Davis quantile estimator.\n- **Targets for Estimation:** First quartile ($p=0.25$), median ($p=0.50$), third quartile ($p=0.75$), and IQR.\n- **Distributions for Simulation:**\n    - Log-normal distribution with parameters $(\\mu, \\sigma)$. Population quantile: $Q(p) = \\exp(\\mu + \\sigma \\Phi^{-1}(p))$.\n    - Student's $t$ distribution with $\\nu$ degrees of freedom. Population quantile: $Q(p) = t_{\\nu}^{-1}(p)$.\n- **Performance Metric:** Mean Squared Error (MSE), $\\operatorname{MSE}(\\widehat{\\theta}) = \\mathbb{E}[(\\widehat{\\theta}-\\theta)^2]$. The convention with the minimum MSE is the winner. Ties are broken by choosing the convention with the smallest index.\n- **Simulation Test Cases:**\n    - Case 1: Log-normal($\\mu=0, \\sigma=1$), sample size $n=10$, replications $R=5000$.\n    - Case 2: Log-normal($\\mu=0, \\sigma=1$), sample size $n=5$, replications $R=5000$.\n    - Case 3: Student's $t$($\\nu=2$), sample size $n=10$, replications $R=5000$.\n    - Case 4: Student's $t$($\\nu=2$), sample size $n=20$, replications $R=5000$.\n- **Reproducibility:** A fixed random seed must be used.\n- **Output:** A list containing four sublists, where each sublist contains the four integer indices ($1, 2, 3,$ or $4$) of the winning convention for $Q(0.25)$, median, $Q(0.75)$, and IQR, for each test case respectively.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientific Grounding:** The problem is firmly grounded in statistical theory. Quantile estimation, Monte Carlo simulation, MSE, and the specified estimators and distributions are all standard, well-documented concepts in statistics.\n2.  **Well-Posedness:** The problem is well-posed. It clearly specifies the inputs (distributions, parameters, sample sizes), the procedures (four estimation conventions), the metric for evaluation (MSE), and a clear objective with a tie-breaking rule. This ensures a unique, meaningful solution can be computed.\n3.  **Objectivity:** The problem is stated in precise, objective, and formal mathematical language. The evaluation criterion (minimum MSE) is quantitative and unambiguous.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. All required information is provided, and the task is a standard numerical experiment in computational statistics.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. The solution process will now proceed.\n\n### Solution\n\nThe objective is to evaluate the performance of four distinct sample quantile estimators against their true population counterparts for small samples drawn from skewed and heavy-tailed distributions. Performance is quantified by the Mean Squared Error (MSE), estimated via Monte Carlo simulation.\n\nLet a sample of size $n$ be drawn from a distribution, and let its order statistics be $X_{(0)} \\le X_{(1)} \\le \\dots \\le X_{(n-1)}$ using $0$-based indexing.\n\n**1. Sample Quantile Conventions**\n\nThe first three conventions are instances of the Hyndman-Fan framework, where a sample quantile $\\widehat{Q}(p)$ for a probability $p \\in (0,1)$ is calculated by linear interpolation between order statistics. The generic form is $\\widehat{Q}(p) = (1-g)X_{(j)} + gX_{(j+1)}$, where $j$ is an integer index and $g$ is a fractional part, both derived from a real-valued index $v_0$. Specifically, after clipping $v_0$ to the range $[0, n-1]$, we define $j = \\lfloor v_0 \\rfloor$ and $g = v_0 - j$. The quantile is then computed as $(1-g)X_{(j)} + gX_{(j+1)}$ for $j  n-1$, and as $X_{(n-1)}$ if $j=n-1$.\n\n- **Convention 1 (Hyndman-Fan Type 7):** This is the default method in many software packages (e.g., R, NumPy, SciPy). It is designed to be approximately unbiased for the expected values of the order statistics for a normal distribution. The $0$-based index $v_0$ is given by:\n$$ v_0 = (n-1)p $$\nThe value of $v_0$ naturally falls in $[0, n-1]$ for $p \\in [0,1]$, so no clipping is needed.\n\n- **Convention 2 (Hyndman-Fan Type 8):** This method is recommended by Hyndman and Fan for producing approximately median-unbiased estimates, regardless of the distribution. The $0$-based index $v_0$ is:\n$$ v_0 = p(n + 1/3) - 2/3 $$\nThe range of $v_0$ is approximately $[-2/3, n-1/3]$, so clipping at the lower end is necessary for small $p$.\n\n- **Convention 3 (Hyndman-Fan Type 9):** This method provides an approximately unbiased estimate for the quantile of a normal distribution. The $0$-based index $v_0$ is:\n$$ v_0 = p(n + 1/4) - 5/8 $$\nThe range of $v_0$ is approximately $[-5/8, n-3/8]$, requiring clipping for small $p$.\n\n- **Convention 4 (Harrell-Davis Estimator):** This is a non-parametric estimator that is a weighted average of all order statistics. It generally has a higher efficiency (lower variance) than interpolation-based methods, especially for small sample sizes. The estimator is defined as:\n$$ \\widehat{Q}_{HD}(p) = \\sum_{i=1}^{n} W_{n,i}(p) X_{(i-1)} $$\nThe weights $W_{n,i}(p)$ are given by the probability that a random variable following a Beta distribution with parameters $\\alpha = (n+1)p$ and $\\beta = (n+1)(1-p)$ falls within the interval $[\\frac{i-1}{n}, \\frac{i}{n}]$. This is computed using the regularized incomplete beta function, $I_x(\\alpha,\\beta)$:\n$$ W_{n,i}(p) = I_{i/n}(\\alpha, \\beta) - I_{(i-1)/n}(\\alpha, \\beta) $$\n\n**2. Simulation Procedure**\n\nFor each of the four test cases, the following steps are performed:\n1.  **Initialization:** A fixed random seed is set for reproducibility. An array is initialized to accumulate the sum of squared errors for each of the four conventions and four target quantities ($Q(0.25)$, $Q(0.50)$, $Q(0.75)$, IQR).\n2.  **Population Quantiles:** The true population quantiles for the specified distribution (Log-normal or Student's $t$) are calculated.\n    - For a Log-normal($\\mu, \\sigma$) distribution, the population quantile function is $Q(p) = \\exp(\\mu + \\sigma \\Phi^{-1}(p))$, where $\\Phi^{-1}$ is the inverse CDF of the standard normal distribution.\n    - For a Student's $t$ distribution with $\\nu$ degrees of freedom, the population quantile function $Q(p) = t_{\\nu}^{-1}(p)$ is the inverse CDF of the distribution.\n3.  **Monte Carlo Loop:** A loop is executed $R=5000$ times. In each iteration:\n    a. A random sample of size $n$ is generated from the specified distribution.\n    b. The sample is sorted to obtain the order statistics.\n    c. For each of the four conventions, the estimates $\\widehat{Q}(0.25)$, $\\widehat{Q}(0.50)$, and $\\widehat{Q}(0.75)$ are computed. The estimated IQR is derived as $\\widehat{\\mathrm{IQR}} = \\widehat{Q}(0.75) - \\widehat{Q}(0.25)$.\n    d. The squared error for each estimate, i.e., $(\\widehat{\\theta} - \\theta)^2$, is calculated by comparing it to the true population value $\\theta$. These squared errors are added to the corresponding accumulators.\n4.  **MSE Calculation:** After all $R$ replications, the accumulated sums of squared errors are divided by $R$ to obtain the final MSE for each estimator and target.\n5.  **Winner Identification:** For each target ($Q(0.25)$, median, $Q(0.75)$, IQR), the convention index ($1-4$) corresponding to the minimum MSE is identified. The problem's tie-breaking rule (select smallest index) is applied implicitly by standard minimum-finding algorithms.\n6.  **Result Aggregation:** The four winning indices for the current test case are stored. This process is repeated for all four test cases. The final result is an aggregation of the results from each case.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, t\nfrom scipy.special import betainc\n\ndef _quantile_hf(x_sorted, p, alpha, beta):\n    \"\"\"\n    General implementation of Hyndman-Fan type estimators using 0-based indexing.\n    This implementation follows the logic of scipy.stats.mstats.mquantiles.\n    \n    The 1-based index is v = n*p + alpha + p*(1-alpha-beta).\n    The 0-based index is v_0 = v - 1.\n    \"\"\"\n    n = len(x_sorted)\n    # 0-based real-valued index\n    v_0 = n * p + alpha + p * (1 - alpha - beta) - 1\n    \n    # Clip to ensure index is within valid range [0, n-1]\n    v_0_clipped = np.clip(v_0, 0, n - 1)\n    \n    j = int(v_0_clipped)\n    g = v_0_clipped - j\n    \n    if j == n - 1:\n        return x_sorted[n-1]\n    \n    return (1 - g) * x_sorted[j] + g * x_sorted[j + 1]\n\ndef quantile_C1(x_sorted, p):\n    \"\"\"Convention 1: Hyndman-Fan Type 7.\"\"\"\n    # alpha=1, beta=1\n    n = len(x_sorted)\n    v_0 = (n - 1) * p\n    j = int(v_0)\n    g = v_0 - j\n    \n    if j == n - 1:\n        return x_sorted[n-1]\n        \n    return (1 - g) * x_sorted[j] + g * x_sorted[j + 1]\n\ndef quantile_C2(x_sorted, p):\n    \"\"\"Convention 2: Hyndman-Fan Type 8.\"\"\"\n    # alpha=1/3, beta=1/3\n    return _quantile_hf(x_sorted, p, 1/3, 1/3)\n\ndef quantile_C3(x_sorted, p):\n    \"\"\"Convention 3: Hyndman-Fan Type 9.\"\"\"\n    # alpha=3/8, beta=3/8\n    return _quantile_hf(x_sorted, p, 3/8, 3/8)\n\ndef quantile_C4(x_sorted, p):\n    \"\"\"Convention 4: Harrell-Davis quantile estimator.\"\"\"\n    n = len(x_sorted)\n    a = (n + 1) * p\n    b = (n + 1) * (1 - p)\n    \n    i = np.arange(1, n + 1)\n    \n    # Regularized incomplete beta function is the CDF of the Beta distribution.\n    # betainc(a, b, x)\n    upper_bounds = i / n\n    lower_bounds = (i - 1) / n\n    \n    weights = betainc(a, b, upper_bounds) - betainc(a, b, lower_bounds)\n    \n    return np.dot(weights, x_sorted)\n\ndef run_simulation(dist_name, params, n, R, seed):\n    \"\"\"Runs one full Monte Carlo simulation for a given test case.\"\"\"\n    np.random.seed(seed)\n    \n    # Define quantile functions and probabilities\n    quantile_fns = [quantile_C1, quantile_C2, quantile_C3, quantile_C4]\n    probs = [0.25, 0.50, 0.75]\n    \n    # Calculate true population quantiles\n    if dist_name == \"lognormal\":\n        mu, sigma = params\n        true_q1 = np.exp(mu + sigma * norm.ppf(0.25))\n        true_med = np.exp(mu + sigma * norm.ppf(0.50))\n        true_q3 = np.exp(mu + sigma * norm.ppf(0.75))\n    elif dist_name == \"student_t\":\n        nu = params[0]\n        true_q1 = t.ppf(0.25, df=nu)\n        true_med = t.ppf(0.50, df=nu)\n        true_q3 = t.ppf(0.75, df=nu)\n    true_iqr = true_q3 - true_q1\n    \n    true_values = np.array([true_q1, true_med, true_q3, true_iqr])\n    \n    # Accumulators for Sum of Squared Errors (4 conventions x 4 targets)\n    sse = np.zeros((4, 4))\n    \n    # Monte Carlo loop\n    for _ in range(R):\n        if dist_name == \"lognormal\":\n            sample = np.random.lognormal(mean=params[0], sigma=params[1], size=n)\n        elif dist_name == \"student_t\":\n            sample = np.random.standard_t(df=params[0], size=n)\n        \n        x_sorted = np.sort(sample)\n        \n        for i, q_fn in enumerate(quantile_fns):\n            q1_hat = q_fn(x_sorted, probs[0])\n            med_hat = q_fn(x_sorted, probs[1])\n            q3_hat = q_fn(x_sorted, probs[2])\n            iqr_hat = q3_hat - q1_hat\n            \n            estimates = np.array([q1_hat, med_hat, q3_hat, iqr_hat])\n            sse[i, :] += (estimates - true_values) ** 2\n            \n    # Calculate MSE\n    mse = sse / R\n    \n    # Find winning convention for each target (argmin returns smallest index in case of tie)\n    winners = (np.argmin(mse, axis=0) + 1).tolist()\n    \n    return winners\n\ndef solve():\n    \"\"\"Main function to run all test cases and format the output.\"\"\"\n    test_cases = [\n        {\"dist_name\": \"lognormal\", \"params\": (0, 1), \"n\": 10, \"R\": 5000, \"seed\": 42},\n        {\"dist_name\": \"lognormal\", \"params\": (0, 1), \"n\": 5, \"R\": 5000, \"seed\": 42},\n        {\"dist_name\": \"student_t\", \"params\": (2,), \"n\": 10, \"R\": 5000, \"seed\": 42},\n        {\"dist_name\": \"student_t\", \"params\": (2,), \"n\": 20, \"R\": 5000, \"seed\": 42},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = run_simulation(case[\"dist_name\"], case[\"params\"], case[\"n\"], case[\"R\"], case[\"seed\"])\n        all_results.append(result)\n\n    # Format the output string exactly as required\n    inner_strings = [f\"[{','.join(map(str, res_list))}]\" for res_list in all_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "4826295"}]}