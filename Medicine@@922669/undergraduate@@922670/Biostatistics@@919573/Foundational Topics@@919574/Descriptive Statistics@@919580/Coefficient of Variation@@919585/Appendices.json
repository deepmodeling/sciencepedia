{"hands_on_practices": [{"introduction": "The first step in mastering any new statistical tool is to become fluent in its basic calculation. This exercise provides a direct application of the coefficient of variation (CV) formula, $\\mathrm{CV} = \\sigma / \\mu$, in a common biological context [@problem_id:1433673]. By calculating the CV for protein expression data, you will practice applying the fundamental definition and gain an initial intuition for how this metric quantifies relative variability, independent of the mean's magnitude.", "problem": "In a systems biology experiment, a researcher investigates gene expression noise in a population of genetically identical E. coli cells. The expression of a particular fluorescent protein is measured in thousands of individual cells using flow cytometry. The data analysis reveals that the mean fluorescence intensity, which is proportional to the protein concentration, is 150 arbitrary units (a.u.). The cell-to-cell variability in this expression level is characterized by a standard deviation of 35 a.u. To compare the relative noise of this protein's expression to that of other genes, it is necessary to calculate the coefficient of variation.\n\nCalculate the coefficient of variation for the protein's expression level. Express your answer as a decimal rounded to three significant figures.", "solution": "The coefficient of variation is defined as the ratio of the standard deviation to the mean. Let the standard deviation be $\\sigma$ and the mean be $\\mu$. Then the coefficient of variation is given by\n$$\n\\mathrm{CV}=\\frac{\\sigma}{\\mu}.\n$$\nSubstituting the given values $\\sigma=35$ and $\\mu=150$ yields\n$$\n\\mathrm{CV}=\\frac{35}{150}=\\frac{7}{30}.\n$$\nConverting to a decimal,\n$$\n\\frac{7}{30}=0.233333\\ldots\n$$\nRounding to three significant figures gives\n$$\n0.233.\n$$", "answer": "$$\\boxed{0.233}$$", "id": "1433673"}, {"introduction": "A deeper understanding of the coefficient of variation comes from exploring its properties within standard statistical models. This practice challenges you to derive the CV for a variable following a Gamma distribution, which is frequently used to model continuous, positive quantities in biology [@problem_id:4901329]. The key insight you will uncover is that the CV for a Gamma distribution depends only on its shape parameter ($k$), not its scale parameter ($\\theta$). This demonstrates the CV's fundamental property of scale-invariance, which is precisely why it is an invaluable tool for comparing the relative variability of datasets that may have vastly different means or units.", "problem": "A continuous positive random variable $X$ is modeled by a Gamma distribution with shape parameter $k>0$ and scale parameter $\\theta>0$, denoted $X \\sim \\mathrm{Gamma}(k,\\theta)$. The probability density function (PDF) is\n$$\nf_{X}(x)=\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\,x^{k-1}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right), \\quad x>0,\n$$\nwhere $\\Gamma(\\cdot)$ is the Gamma function. Starting only from the PDF definition, the integral definitions of the mean and variance for a continuous random variable, and standard properties of the Gamma function, do the following:\n\n- Using $E[X]=\\int_{0}^{\\infty} x f_{X}(x)\\,dx$ and $\\mathrm{Var}(X)=E[X^{2}]-\\left(E[X]\\right)^{2}$, compute $E[X]$ and $\\mathrm{Var}(X)$ for $X$.\n- Define the coefficient of variation (CV) as the ratio of the standard deviation to the mean, that is, $\\mathrm{CV}=\\sqrt{\\mathrm{Var}(X)}/E[X]$, and derive a fully simplified analytic expression for $\\mathrm{CV}$ in terms of $k$ and $\\theta$.\n- Justify from first principles why the resulting expression demonstrates scale-independence with respect to $\\theta$ by interpreting $\\theta$ as a multiplicative scale parameter.\n\nExpress your final answer as a single closed-form analytic expression in terms of $k$ only. No rounding is required.", "solution": "We start from the given probability density function (PDF)\n$$\nf_{X}(x)=\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\,x^{k-1}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right), \\quad x>0,\n$$\nwith $k>0$ and $\\theta>0$. For a continuous nonnegative random variable, the mean and second moment are given by\n$$\nE[X]=\\int_{0}^{\\infty} x f_{X}(x)\\,dx, \\qquad E[X^{2}]=\\int_{0}^{\\infty} x^{2} f_{X}(x)\\,dx,\n$$\nand the variance is $\\mathrm{Var}(X)=E[X^{2}]-\\left(E[X]\\right)^{2}$. We will compute these using the definition of the Gamma function,\n$$\n\\Gamma(a)=\\int_{0}^{\\infty} u^{a-1}\\exp(-u)\\,du, \\quad a>0,\n$$\nand the recursive identity $\\Gamma(a+1)=a\\,\\Gamma(a)$, which is a standard property following from integration by parts.\n\nStep $1$: Compute $E[X]$.\n$$\nE[X]=\\int_{0}^{\\infty} x\\,\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\,x^{k-1}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right)\\,dx=\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\int_{0}^{\\infty} x^{k}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right)\\,dx.\n$$\nUse the substitution $u=\\frac{x}{\\theta}$, so that $x=\\theta u$ and $dx=\\theta\\,du$. Then\n$$\n\\int_{0}^{\\infty} x^{k}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right)\\,dx=\\int_{0}^{\\infty} (\\theta u)^{k}\\exp(-u)\\,\\theta\\,du=\\theta^{k+1}\\int_{0}^{\\infty} u^{k}\\exp(-u)\\,du=\\theta^{k+1}\\Gamma(k+1).\n$$\nTherefore,\n$$\nE[X]=\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\,\\theta^{k+1}\\Gamma(k+1)=\\theta\\,\\frac{\\Gamma(k+1)}{\\Gamma(k)}=\\theta\\,k,\n$$\nusing $\\Gamma(k+1)=k\\,\\Gamma(k)$.\n\nStep $2$: Compute $E[X^{2}]$.\n$$\nE[X^{2}]=\\int_{0}^{\\infty} x^{2}\\,f_{X}(x)\\,dx=\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\int_{0}^{\\infty} x^{k+1}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right)\\,dx.\n$$\nWith the same substitution $u=\\frac{x}{\\theta}$, we obtain\n$$\n\\int_{0}^{\\infty} x^{k+1}\\,\\exp\\!\\left(-\\frac{x}{\\theta}\\right)\\,dx=\\int_{0}^{\\infty} (\\theta u)^{k+1}\\exp(-u)\\,\\theta\\,du=\\theta^{k+2}\\int_{0}^{\\infty} u^{k+1}\\exp(-u)\\,du=\\theta^{k+2}\\Gamma(k+2).\n$$\nHence,\n$$\nE[X^{2}]=\\frac{1}{\\Gamma(k)\\,\\theta^{k}}\\,\\theta^{k+2}\\Gamma(k+2)=\\theta^{2}\\,\\frac{\\Gamma(k+2)}{\\Gamma(k)}=\\theta^{2}\\,k(k+1),\n$$\nusing $\\Gamma(k+2)=(k+1)\\Gamma(k+1)=(k+1)k\\Gamma(k)$.\n\nStep $3$: Compute $\\mathrm{Var}(X)$ and the coefficient of variation $\\mathrm{CV}$.\n$$\n\\mathrm{Var}(X)=E[X^{2}]-\\left(E[X]\\right)^{2}=\\theta^{2}\\,k(k+1)-(\\theta k)^{2}=\\theta^{2}\\,k.\n$$\nThus the standard deviation is $\\sqrt{\\mathrm{Var}(X)}=\\theta\\,\\sqrt{k}$. By definition, the coefficient of variation (CV) is\n$$\n\\mathrm{CV}=\\frac{\\sqrt{\\mathrm{Var}(X)}}{E[X]}=\\frac{\\theta\\,\\sqrt{k}}{\\theta\\,k}=\\frac{1}{\\sqrt{k}}.\n$$\n\nStep $4$: Justify scale-independence with respect to $\\theta$.\nThe parameter $\\theta$ acts as a multiplicative scale. To see this from first principles, let $W\\sim \\mathrm{Gamma}(k,1)$ with PDF $f_{W}(w)=\\frac{1}{\\Gamma(k)}w^{k-1}\\exp(-w)$ for $w>0$, and define $X=\\theta W$. The transformation of variables shows that $X$ has the given PDF $f_{X}(x)=\\frac{1}{\\Gamma(k)\\theta^{k}}x^{k-1}\\exp(-x/\\theta)$, confirming $X=\\theta W$. For any positive scalar $a>0$, the coefficient of variation satisfies\n$$\n\\mathrm{CV}(aX)=\\frac{\\sqrt{\\mathrm{Var}(aX)}}{E[aX]}=\\frac{\\sqrt{a^{2}\\,\\mathrm{Var}(X)}}{a\\,E[X]}=\\frac{a\\,\\sqrt{\\mathrm{Var}(X)}}{a\\,E[X]}=\\mathrm{CV}(X).\n$$\nTherefore, the coefficient of variation depends only on the shape of the distribution and not on the scale. In the Gamma family, this yields $\\mathrm{CV}=\\frac{1}{\\sqrt{k}}$, which is independent of $\\theta$.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{k}}}$$", "id": "4901329"}, {"introduction": "In real-world data analysis, we often work with limited samples and need to assess the reliability of our calculated statistics. This hands-on exercise introduces bootstrapping, a powerful and intuitive computational method for estimating the uncertainty of a measure like the CV, especially when the underlying distribution is unknown [@problem_id:1420124]. By repeatedly resampling your own data and recalculating the statistic, you will simulate the process of collecting new datasets to observe the stability of your estimate. This practice will allow you to compute a bootstrap standard error, providing a tangible measure of confidence in your calculated CV.", "problem": "A systems biologist is investigating gene expression noise in a bacterial population. They measure the number of molecules of a specific fluorescent protein in a small sample of eight individual cells, obtaining the following counts:\n`[110, 90, 120, 80, 105, 95, 115, 85]`\n\nA key metric for quantifying this cell-to-cell variability is the Coefficient of Variation (CV), defined as the ratio of the sample standard deviation ($s$) to the sample mean ($\\bar{x}$):\n$$CV = \\frac{s}{\\bar{x}}$$\nThe sample standard deviation for a set of $N$ measurements $\\{x_1, x_2, ..., x_N\\}$ with mean $\\bar{x}$ is given by $s = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N (x_i - \\bar{x})^2}$.\n\nTo estimate the statistical uncertainty of the CV calculated from this small dataset, a computational method called bootstrapping is used. This involves generating new \"bootstrap samples\" by drawing eight data points *with replacement* from the original set of eight measurements. The biologist generates four such bootstrap samples:\n- **Sample 1:** `[110, 80, 110, 95, 120, 85, 95, 115]`\n- **Sample 2:** `[90, 85, 115, 95, 105, 90, 80, 80]`\n- **Sample 3:** `[120, 115, 105, 95, 110, 90, 120, 85]`\n- **Sample 4:** `[95, 105, 85, 115, 120, 80, 110, 90]`\n\nThe standard error of an estimator (in this case, the CV) can be approximated by calculating the standard deviation of the estimates obtained from a set of bootstrap samples. Based on the four provided bootstrap samples, calculate the bootstrap estimate of the standard error for the Coefficient of Variation.\n\nReport your answer as a decimal rounded to three significant figures.", "solution": "We are asked to compute a bootstrap estimate of the standard error of the Coefficient of Variation (CV). For a sample $\\{x_{i}\\}_{i=1}^{N}$ with mean $\\bar{x}$ and sample standard deviation $s=\\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(x_{i}-\\bar{x})^{2}}$, the CV is\n$$\nCV=\\frac{s}{\\bar{x}}.\n$$\nFor computational convenience, we use the identity\n$$\n\\sum_{i=1}^{N}(x_{i}-\\bar{x})^{2}=\\sum_{i=1}^{N}x_{i}^{2}-N\\bar{x}^{2},\n$$\nso that the sample variance is\n$$\ns^{2}=\\frac{1}{N-1}\\left(\\sum_{i=1}^{N}x_{i}^{2}-N\\bar{x}^{2}\\right).\n$$\nFor the $B=4$ bootstrap samples, we compute $CV_{b}$ for $b=1,2,3,4$, then take their empirical standard deviation\n$$\n\\widehat{SE}=\\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(CV_{b}-\\overline{CV}\\right)^{2}},\\qquad \\overline{CV}=\\frac{1}{B}\\sum_{b=1}^{B}CV_{b}.\n$$\n\nBootstrap sample 1: $[110,80,110,95,120,85,95,115]$. The sum is $S_{1}=810$, so $\\bar{x}_{1}=810/8=101.25$. The sum of squares is $SS_{1}=83500$. Then\n$$\ns_{1}^{2}=\\frac{1}{7}\\left(83500-8\\cdot 101.25^{2}\\right)=\\frac{1487.5}{7}=212.5,\\quad s_{1}=\\sqrt{212.5},\n$$\nand\n$$\nCV_{1}=\\frac{\\sqrt{212.5}}{101.25}\\approx 0.143974.\n$$\n\nBootstrap sample 2: $[90,85,115,95,105,90,80,80]$. The sum is $S_{2}=740$, so $\\bar{x}_{2}=740/8=92.5$. The sum of squares is $SS_{2}=69500$. Then\n$$\ns_{2}^{2}=\\frac{1}{7}\\left(69500-8\\cdot 92.5^{2}\\right)=\\frac{1050}{7}=150,\\quad s_{2}=\\sqrt{150},\n$$\nand\n$$\nCV_{2}=\\frac{\\sqrt{150}}{92.5}\\approx 0.132404858.\n$$\n\nBootstrap sample 3: $[120,115,105,95,110,90,120,85]$. The sum is $S_{3}=840$, so $\\bar{x}_{3}=840/8=105$. The sum of squares is $SS_{3}=89500$. Then\n$$\ns_{3}^{2}=\\frac{1}{7}\\left(89500-8\\cdot 105^{2}\\right)=\\frac{1300}{7},\\quad s_{3}=\\sqrt{\\frac{1300}{7}},\n$$\nand\n$$\nCV_{3}=\\frac{\\sqrt{1300/7}}{105}\\approx 0.129788.\n$$\n\nBootstrap sample 4: $[95,105,85,115,120,80,110,90]$. The sum is $S_{4}=800$, so $\\bar{x}_{4}=800/8=100$. The sum of squares is $SS_{4}=81500$. Then\n$$\ns_{4}^{2}=\\frac{1}{7}\\left(81500-8\\cdot 100^{2}\\right)=\\frac{1500}{7},\\quad s_{4}=\\sqrt{\\frac{1500}{7}},\n$$\nand\n$$\nCV_{4}=\\frac{\\sqrt{1500/7}}{100}\\approx 0.146385.\n$$\n\nNow compute the empirical mean of the four CV values:\n$$\n\\overline{CV}=\\frac{CV_{1}+CV_{2}+CV_{3}+CV_{4}}{4}\\approx \\frac{0.143974+0.132404858+0.129788+0.146385}{4}\\approx 0.138138.\n$$\nThe bootstrap standard error is the sample standard deviation of these four values:\n$$\n\\widehat{SE}=\\sqrt{\\frac{1}{3}\\sum_{b=1}^{4}\\left(CV_{b}-\\overline{CV}\\right)^{2}}\\approx 0.0082595.\n$$\nRounded to three significant figures, this is $0.00826$.", "answer": "$$\\boxed{0.00826}$$", "id": "1420124"}]}