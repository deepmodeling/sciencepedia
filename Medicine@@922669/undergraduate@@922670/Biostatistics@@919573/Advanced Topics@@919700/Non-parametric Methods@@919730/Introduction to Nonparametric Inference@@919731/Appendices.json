{"hands_on_practices": [{"introduction": "The foundation of many powerful nonparametric methods lies not in assumptions about a population distribution, but in the physical act of randomization used in an experiment. This exercise will guide you through constructing an exact permutation test, where the reference distribution for our test statistic is generated directly from the study's block randomization design. By working through this problem [@problem_id:4920236], you will gain a concrete understanding of the \"sharp null hypothesis\" and see how inference can be justified by the experimental design alone.", "problem": "A biostatistics team runs a Randomized Controlled Trial (RCT) to evaluate whether a new treatment increases a continuous biomarker response relative to control. Randomization uses permuted blocks with unequal allocation: within each block of size $3$, exactly $2$ participants are assigned to treatment and $1$ to control. There are $3$ blocks. The three post-treatment biomarker outcomes in each block, along with the actual observed assignment in this trial, are as follows.\nBlock $1$: outcomes $8$, $4$, $2$; the subjects with outcomes $8$ and $4$ were assigned to treatment, and the subject with outcome $2$ was assigned to control.\nBlock $2$: outcomes $7$, $6$, $1$; the subjects with outcomes $7$ and $6$ were assigned to treatment, and the subject with outcome $1$ was assigned to control.\nBlock $3$: outcomes $9$, $3$, $0$; the subjects with outcomes $9$ and $0$ were assigned to treatment, and the subject with outcome $3$ was assigned to control.\nYou will construct a randomization-based permutation test that respects the randomization scheme. Use the following fundamental base:\n- Under the null hypothesis $H_0$ of no treatment effect, the observed outcomes are fixed, and only the treatment labels are random according to the randomization mechanism.\n- To respect the randomization scheme, permutations must be restricted to relabelings that could have arisen from the actual design; here, within each block of size $3$, exactly $2$ labels must be treatment and $1$ label must be control.\nDefine the test statistic $T$ to be the difference in mean outcomes between the treatment group and the control group, $T = \\bar{Y}_T - \\bar{Y}_C$, and consider the one-sided alternative $H_1$ that the treatment increases the mean outcome. Construct the exact permutation distribution of $T$ under $H_0$ by enumerating all labelings consistent with the block randomization and the $2{:}1$ allocation within each block, and compute the exact one-sided $p$-value $\\Pr(T \\ge T_{\\text{obs}} \\mid H_0)$. Express your final answer as a single fraction in lowest terms. No rounding is required.", "solution": "The problem statement is scientifically grounded, well-posed, and contains all necessary information to conduct the requested analysis. It describes a standard randomization-based permutation test for a blocked Randomized Controlled Trial (RCT), a valid and fundamental procedure in nonparametric biostatistics. Therefore, I will proceed with the solution.\n\nThe problem requires the computation of an exact one-sided $p$-value for a permutation test based on a block randomization design. The null hypothesis, $H_0$, posits that the treatment has no effect on the biomarker outcomes. This is the sharp null hypothesis, which implies that the observed outcome for each participant would have been the same regardless of the treatment assignment they received. Under $H_0$, the set of all $9$ outcomes is considered fixed. The only source of randomness is the assignment of treatment labels, which follows the specified randomization scheme.\n\nThe randomization scheme consists of permuted blocks of size $3$. Within each of the $3$ blocks, $2$ participants are assigned to treatment and $1$ to control. The choice of which participant receives the control assignment within a block is random. For a block with $3$ participants, there are $\\binom{3}{1} = 3$ possible ways to assign $1$ control label and $2$ treatment labels. Since there are $3$ independent blocks, the total number of possible treatment assignments consistent with the randomization scheme is $3 \\times 3 \\times 3 = 27$. Under $H_0$, each of these $27$ assignments is equally likely, with probability $\\frac{1}{27}$.\n\nThe test statistic is defined as the difference in mean outcomes between the treatment group (T) and the control group (C): $T = \\bar{Y}_T - \\bar{Y}_C$. The total number of participants is $N=9$, with $N_T = 3 \\times 2 = 6$ in the treatment group and $N_C = 3 \\times 1 = 3$ in the control group.\n\nFirst, we calculate the observed value of the test statistic, $T_{\\text{obs}}$, based on the actual assignment given in the problem.\nThe outcomes in each block are:\nBlock $1$: $\\{8, 4, 2\\}$\nBlock $2$: $\\{7, 6, 1\\}$\nBlock $3$: $\\{9, 3, 0\\}$\n\nThe observed assignment is:\nTreatment group outcomes: $Y_T = \\{8, 4, 7, 6, 9, 0\\}$\nControl group outcomes: $Y_C = \\{2, 1, 3\\}$\n\nThe sum and mean for the observed treatment group are:\n$$ \\sum Y_T = 8 + 4 + 7 + 6 + 9 + 0 = 34 $$\n$$ \\bar{Y}_T = \\frac{34}{6} = \\frac{17}{3} $$\n\nThe sum and mean for the observed control group are:\n$$ \\sum Y_C = 2 + 1 + 3 = 6 $$\n$$ \\bar{Y}_C = \\frac{6}{3} = 2 $$\n\nThe observed test statistic is:\n$$ T_{\\text{obs}} = \\bar{Y}_T - \\bar{Y}_C = \\frac{17}{3} - 2 = \\frac{17}{3} - \\frac{6}{3} = \\frac{11}{3} $$\n\nThe one-sided $p$-value is the probability of observing a test statistic at least as extreme as $T_{\\text{obs}}$ under the null hypothesis, i.e., $p = \\Pr(T \\ge T_{\\text{obs}} \\mid H_0)$. To find this, we must consider all $27$ possible randomizations.\n\nWe can simplify the calculation by expressing $T$ in terms of a single variable, such as the sum of the control outcomes, $\\sum Y_C$. The total sum of all outcomes is a constant across all permutations:\n$$ S_{\\text{total}} = \\sum_{i=1}^{9} Y_i = (8+4+2) + (7+6+1) + (9+3+0) = 14 + 14 + 12 = 40 $$\nSince $\\sum Y_T + \\sum Y_C = S_{\\text{total}} = 40$, we have $\\sum Y_T = 40 - \\sum Y_C$.\nThe test statistic can be rewritten as:\n$$ T = \\frac{\\sum Y_T}{N_T} - \\frac{\\sum Y_C}{N_C} = \\frac{40 - \\sum Y_C}{6} - \\frac{\\sum Y_C}{3} = \\frac{40 - \\sum Y_C - 2\\sum Y_C}{6} = \\frac{40 - 3\\sum Y_C}{6} $$\nThe condition $T \\ge T_{\\text{obs}}$ is equivalent to:\n$$ \\frac{40 - 3\\sum Y_C}{6} \\ge \\frac{11}{3} $$\n$$ 40 - 3\\sum Y_C \\ge 6 \\times \\frac{11}{3} = 22 $$\n$$ 18 \\ge 3\\sum Y_C $$\n$$ \\sum Y_C \\le 6 $$\nThus, the $p$-value is the proportion of the $27$ possible randomizations for which the sum of the control group outcomes is less than or equal to $6$.\n\nWe need to enumerate the combinations of control assignments that satisfy this condition. For each randomization, one outcome from each block is chosen to be the control outcome. Let $y_{c1}$, $y_{c2}$, and $y_{c3}$ be the control outcomes from Block $1$, Block $2$, and Block $3$ respectively.\nThe possible control outcomes are:\n- From Block $1$: $y_{c1} \\in \\{2, 4, 8\\}$\n- From Block $2$: $y_{c2} \\in \\{1, 6, 7\\}$\n- From Block $3$: $y_{c3} \\in \\{0, 3, 9\\}$\n\nWe need to find all combinations $(y_{c1}, y_{c2}, y_{c3})$ such that $y_{c1} + y_{c2} + y_{c3} \\le 6$.\nLet's systematically enumerate them by starting with the smallest possible values from each set.\n1.  Choose the smallest value from each block: $y_{c1} = 2$, $y_{c2} = 1$, $y_{c3} = 0$. The sum is $2+1+0=3$. Since $3 \\le 6$, this is one such randomization.\n2.  Keep $y_{c1}=2$ and $y_{c2}=1$. The next value for $y_{c3}$ is $3$. The sum is $2+1+3=6$. Since $6 \\le 6$, this is a second such randomization (this is the observed case). The next value for $y_{c3}$ is $9$, giving a sum of $12$, which is greater than $6$.\n3.  Now, let's try the next value for $y_{c1}$, which is $4$, keeping other values minimal. Let $y_{c1}=4$, $y_{c2}=1$, $y_{c3}=0$. The sum is $4+1+0=5$. Since $5 \\le 6$, this is a third such randomization. If we change $y_{c3}$ to $3$, the sum becomes $4+1+3=8$, which is too large.\n4. If we start with $y_{c1}=8$, the smallest possible sum is $8+1+0=9$, which is already greater than $6$.\n5. If we start with $y_{c1}=2$ and use $y_{c2}=6$, the smallest sum is $2+6+0=8$, which is greater than $6$.\n\nTherefore, there are exactly $3$ possible randomizations (out of $27$) for which $\\sum Y_C \\le 6$. These are:\n- Control outcomes $\\{2, 1, 0\\}$, with sum $3$.\n- Control outcomes $\\{2, 1, 3\\}$, with sum $6$.\n- Control outcomes $\\{4, 1, 0\\}$, with sum $5$.\n\nEach of these $3$ randomizations results in a test statistic $T$ greater than or equal to $T_{\\text{obs}}$. Since each of the $27$ randomizations is equally likely, the exact one-sided $p$-value is the ratio of the number of favorable outcomes to the total number of outcomes.\n$$ p \\text{-value} = \\frac{\\text{Number of permutations with } T \\ge T_{\\text{obs}}}{\\text{Total number of permutations}} = \\frac{3}{27} $$\nExpressing this as a fraction in lowest terms, we get:\n$$ p \\text{-value} = \\frac{1}{9} $$", "answer": "$$\\boxed{\\frac{1}{9}}$$", "id": "4920236"}, {"introduction": "While permutation tests are powerful, many classic nonparametric methods achieve robustness by converting data into ranks. This practice problem focuses on the Wilcoxon signed-rank test for paired data, a cornerstone of rank-based inference [@problem_id:4920252]. You will confront the practical challenges of handling zero differences and tied ranks, and learn to compute an exact mid-$p$ value, a technique that provides a more accurate assessment of significance for discrete test statistics.", "problem": "A matched-pairs biostatistics study evaluates the within-subject change in a continuous biomarker between baseline and 12 weeks after intervention. Let the paired differences be denoted by $d_{i} = \\text{post}_{i} - \\text{pre}_{i}$ for $i=1,\\dots,25$. Due to instrument rounding and a detection limit, several observed differences are exactly zero and multiple nonzero absolute differences are tied. The observed differences are\n$$\n\\{0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,2,\\,2,\\,3,\\,3,\\,6,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0\\}.\n$$\nAssume the standard conditions for the Wilcoxon signed-rank test hold under the null hypothesis of symmetry of the difference distribution about $0$, with zero differences removed and tied absolute differences assigned average ranks.\n\nUsing only fundamental probabilistic reasoning under the null hypothesis (random signs with equal probability and independence across nonzero pairs), perform the exact Wilcoxon signed-rank test and compute the two-sided mid-$p$ value. Proceed by:\n- Removing the zero differences.\n- Ranking the nonzero absolute differences from smallest to largest, assigning average ranks for ties.\n- Computing the statistic $W^{+}$ as the sum of ranks associated with positive differences.\n- Using the exact distribution of $W^{+}$ induced by independent random signs to obtain the two-sided mid-$p$ value, defined by tail probabilities beyond the observed statistic plus one-half of the probability at equality on the relevant tail(s).\n\nExpress the final mid-$p$ value as an exact fraction or as a decimal rounded to four significant figures. Briefly explain how the presence of ties in the absolute differences affects the distribution of the signed-rank statistic and the interpretation of the mid-$p$ value. The final numerical answer must be a single value (no intervals or inequalities).", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**1. Extraction of Givens**\n- Sample size: $n=25$ paired differences, $d_i = \\text{post}_i - \\text{pre}_i$.\n- Observed differences: $\\{0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,2,\\,2,\\,3,\\,3,\\,6,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0\\}$.\n- Test: Wilcoxon signed-rank test.\n- Null Hypothesis ($H_0$): The distribution of the differences is symmetric about $0$.\n- Handling of zeros: Remove zero differences.\n- Handling of ties: Assign average ranks to tied absolute differences.\n- Test statistic: $W^{+}$, the sum of ranks corresponding to positive differences.\n- Task: Compute the exact two-sided mid-$p$ value.\n- Definition of mid-$p$ value: Tail probabilities beyond the observed statistic plus one-half of the probability at equality on the relevant tail(s).\n\n**2. Validation Verdict**\nThe problem is valid. It describes a standard application of the Wilcoxon signed-rank test, a well-established nonparametric method. The data, including the presence of zeros and ties, represent a realistic scenario in biostatistics. The instructions for handling these issues are clear and standard. The concept of an exact mid-$p$ value is a valid statistical tool for discrete test statistics. The problem is self-contained, logically consistent, and scientifically sound.\n\n**3. Solution**\n\nThe solution proceeds by following the steps outlined in the problem statement.\n\n**Step 1: Data Preparation**\nThe initial set consists of $n=25$ observed differences. We first handle the zero differences as instructed.\nThe number of zero differences is $m_0 = 16$.\nThese are removed from the analysis. The effective sample size for the test is the number of non-zero differences, $n'$.\nThe non-zero differences are $\\{1,\\,1,\\,1,\\,2,\\,2,\\,3,\\,3,\\,6\\}$.\nThere are $n'=8$ non-zero differences.\n\n**Step 2: Ranking of Absolute Differences**\nWe take the absolute values of the $n'=8$ non-zero differences: $\\{1,\\,1,\\,1,\\,2,\\,2,\\,3,\\,3,\\,6\\}$.\nWe then rank these absolute values from smallest to largest, assigning average ranks for ties.\n- The three values of $1$ occupy ranks $1$, $2$, and $3$. Their average rank is $\\frac{1+2+3}{3} = \\frac{6}{3} = 2$.\n- The two values of $2$ occupy ranks $4$ and $5$. Their average rank is $\\frac{4+5}{2} = \\frac{9}{2} = 4.5$.\n- The two values of $3$ occupy ranks $6$ and $7$. Their average rank is $\\frac{6+7}{2} = \\frac{13}{2} = 6.5$.\n- The value of $6$ occupies rank $8$. Its rank is $8$.\n\nThe set of ranks for the $n'=8$ non-zero differences is $\\{2,\\,2,\\,2,\\,4.5,\\,4.5,\\,6.5,\\,6.5,\\,8\\}$.\nA check on the sum of ranks: $3 \\times 2 + 2 \\times 4.5 + 2 \\times 6.5 + 8 = 6 + 9 + 13 + 8 = 36$. This matches the total sum of ranks for $n'=8$, which is $\\frac{n'(n'+1)}{2} = \\frac{8(8+1)}{2} = \\frac{72}{2} = 36$.\n\n**Step 3: Computation of the Test Statistic $W^{+}$**\nThe test statistic $W^{+}$ is the sum of the ranks corresponding to the positive differences.\nThe set of non-zero differences is $\\{1,\\,1,\\,1,\\,2,\\,2,\\,3,\\,3,\\,6\\}$. All of these are positive.\nTherefore, $W^{+}$ is the sum of all ranks.\nThe observed statistic is $W_{obs}^{+} = 2+2+2+4.5+4.5+6.5+6.5+8 = 36$.\n\n**Step 4: Exact Null Distribution and $p$-value Calculation**\nUnder the null hypothesis of symmetry about $0$, each non-zero difference is equally likely to be positive or negative. This is equivalent to randomly assigning a $+$ or $-$ sign to each of the $n'=8$ ranks, with each of the $2^{n'} = 2^8 = 256$ sign combinations being equally likely, having a probability of $(\\frac{1}{2})^8 = \\frac{1}{256}$.\n\nThe test statistic $W^{+}$ is the sum of the ranks assigned a $+$ sign. The minimum possible value of $W^{+}$ is $0$ (all signs are negative), and the maximum possible value is the total sum of ranks, $36$ (all signs are positive). The distribution of $W^{+}$ is symmetric about its mean, $E[W^{+}] = \\frac{1}{2} \\sum_{i=1}^{n'} R_i = \\frac{36}{2} = 18$.\n\nThe observed statistic is $W_{obs}^{+} = 36$, which is the most extreme value possible in the upper tail. The equally extreme value in the lower tail is $W_{symm}^{-} = 0$.\n\nThe two-sided mid-$p$ value is calculated as:\n$$p_{\\text{mid}} = P(W^{+} > W_{obs}^{+}) + \\frac{1}{2}P(W^{+} = W_{obs}^{+}) + P(W^{+}  W_{symm}^{-}) + \\frac{1}{2}P(W^{+} = W_{symm}^{-})$$\nSubstituting $W_{obs}^{+} = 36$ and $W_{symm}^{-} = 0$:\n$$p_{\\text{mid}} = P(W^{+} > 36) + \\frac{1}{2}P(W^{+} = 36) + P(W^{+}  0) + \\frac{1}{2}P(W^{+} = 0)$$\n\nWe now compute the probabilities:\n- $P(W^{+} > 36)$: The maximum possible value of $W^{+}$ is $36$, so this probability is $0$.\n- $P(W^{+} = 36)$: This occurs only if all $8$ non-zero differences are positive. There is only one such outcome among the $256$ equally likely possibilities. Thus, $P(W^{+} = 36) = \\frac{1}{256}$.\n- $P(W^{+}  0)$: The minimum possible value of $W^{+}$ is $0$, so this probability is $0$.\n- $P(W^{+} = 0)$: This occurs only if all $8$ non-zero differences are negative. There is only one such outcome. Thus, $P(W^{+} = 0) = \\frac{1}{256}$.\n\nSubstituting these probabilities into the formula for the mid-$p$ value:\n$$p_{\\text{mid}} = 0 + \\frac{1}{2} \\left( \\frac{1}{256} \\right) + 0 + \\frac{1}{2} \\left( \\frac{1}{256} \\right)$$\n$$p_{\\text{mid}} = \\frac{1}{512} + \\frac{1}{512} = \\frac{2}{512} = \\frac{1}{256}$$\n\nAs a decimal rounded to four significant figures, $\\frac{1}{256} \\approx 0.00390625$, which is $0.003906$. The question allows for an exact fraction, which is preferred.\n\n**Step 5: Explanation of the Effect of Ties**\nThe presence of ties in the absolute values of the differences has a crucial effect on the null distribution of the Wilcoxon signed-rank statistic, $W^{+}$.\n1.  **Modification of Ranks**: Instead of using the set of integer ranks $\\{1, 2, \\dots, n'\\}$, we must use average ranks for tied groups. This results in a set of ranks that contains non-integers and repeated values, as seen in our problem with the rank set $\\{2, 2, 2, 4.5, 4.5, 6.5, 6.5, 8\\}$.\n2.  **Custom Null Distribution**: The standard tables for the Wilcoxon signed-rank test distribution assume no ties and are therefore not applicable. The null distribution of $W^{+}$ must be generated specifically from the actual set of ranks obtained from the data. While the principle of $2^{n'}$ equally likely sign combinations remains, the set of possible values for $W^{+}$ and their corresponding probabilities are altered. For example, in the untied case for $n'=8$, $W^{+}$ could take the value $1$, but with our tied ranks, the minimum non-zero value is $2$.\n3.  **Interpretation of mid-$p$ value**: The mid-$p$ value is a general technique to correct for the conservatism of standard $p$-values when dealing with any discrete test statistic, whether ties are present or not. A standard two-sided $p$-value would be $P(W^{+} \\geq 36) + P(W^{+} \\leq 0) = \\frac{1}{256} + \\frac{1}{256} = \\frac{1}{128}$. The mid-$p$ value of $\\frac{1}{256}$ is less conservative. It is interpreted as the probability of obtaining a result more extreme than observed, plus half the probability of observing the result itself, summed over both tails. This provides a test whose size (the probability of a Type I error) is closer to the nominal significance level $\\alpha$.", "answer": "$$\\boxed{\\frac{1}{256}}$$", "id": "4920252"}, {"introduction": "Sometimes our scientific question is not just about a shift in location, but whether two groups have different distributions overall. The Kolmogorov-Smirnov (KS) test addresses this by comparing the empirical cumulative distribution functions (ECDFs) of the samples directly [@problem_id:4920263]. In this exercise, you will calculate the KS statistic from first principles and use its large-sample properties to approximate a $p$-value, giving you a powerful tool for detecting any type of distributional difference.", "problem": "A clinical study compares baseline biomarker concentrations between two independent cohorts. Assume the two cohorts are independent simple random samples from continuous distributions. Let the treatment cohort be a sample of size $n$ and the control cohort be a sample of size $m$. The observed values (in $\\mathrm{mg}/\\mathrm{dL}$) are:\n\n- Treatment cohort $\\mathcal{A}$ ($n = 8$): $3.1$, $4.7$, $5.0$, $5.2$, $6.3$, $6.8$, $7.4$, $9.0$.\n- Control cohort $\\mathcal{B}$ ($m = 7$): $2.9$, $3.5$, $4.4$, $5.5$, $6.0$, $7.9$, $8.2$.\n\nStarting from the fundamental definition of the empirical cumulative distribution function (ECDF) for a sample $X_{1}, \\dots, X_{n}$, given by $F_{n}(x)$ equal to the proportion of sample points not exceeding $x$, and analogously for $G_{m}(x)$ for the second sample, compute the two-sample Kolmogorov–Smirnov statistic, which is the supremum over $x$ of the absolute difference between the two ECDFs.\n\nThen, under the null hypothesis that both samples are drawn from the same continuous distribution, use the large-sample asymptotic null distribution of the scaled Kolmogorov–Smirnov statistic to obtain an approximation to the $p$-value. Round the $p$-value to four significant figures. Report your final answer as a row matrix containing, in order, the Kolmogorov–Smirnov statistic and the approximated $p$-value, with no units inside the matrix.", "solution": "The problem is scientifically sound, requiring the computation of the two-sample Kolmogorov-Smirnov (KS) statistic and its associated asymptotic $p$-value. The data and definitions provided are clear and sufficient for a unique solution.\n\n**Step 1: Compute the Kolmogorov-Smirnov Statistic**\n\nThe two-sample KS statistic is $D_{n,m} = \\sup_{x} |F_n(x) - G_m(x)|$, where $F_n(x)$ and $G_m(x)$ are the empirical cumulative distribution functions (ECDFs) for the two samples. Here, $n=8$ (cohort $\\mathcal{A}$) and $m=7$ (cohort $\\mathcal{B}$). The ECDF for cohort $\\mathcal{A}$, $F_8(x)$, increases by $1/8$ at each of its data points. The ECDF for cohort $\\mathcal{B}$, $G_7(x)$, increases by $1/7$ at each of its data points.\n\nThe supremum of the difference will occur at one of the observed data points. We create a combined, sorted list of all $n+m=15$ observations and calculate the difference $|F_8(x) - G_7(x)|$ after each jump.\n\n| $x$   | Cohort | Cum. Count $\\mathcal{A}$ | Cum. Count $\\mathcal{B}$ | $F_8(x)$ | $G_7(x)$ | $|F_8(x) - G_7(x)|$     |\n|-------|--------|-----------------|-----------------|----------|----------|---------------------------|\n| $2.9$| -      | 0               | 0               | $0/8$    | $0/7$    | $0$                       |\n| $2.9$ | $\\mathcal{B}$ | 0               | 1               | $0/8$    | $1/7$    | $|0 - 1/7| = 1/7 \\approx 0.1429$ |\n| $3.1$ | $\\mathcal{A}$ | 1               | 1               | $1/8$    | $1/7$    | $|1/8 - 1/7| = 1/56 \\approx 0.0179$ |\n| $3.5$ | $\\mathcal{B}$ | 1               | 2               | $1/8$    | $2/7$    | $|1/8 - 2/7| = 9/56 \\approx 0.1607$ |\n| $4.4$ | $\\mathcal{B}$ | 1               | 3               | $1/8$    | $3/7$    | $|1/8 - 3/7| = 17/56 \\approx 0.3036$ |\n| $4.7$ | $\\mathcal{A}$ | 2               | 3               | $2/8$    | $3/7$    | $|1/4 - 3/7| = 5/28 \\approx 0.1786$ |\n| $5.0$ | $\\mathcal{A}$ | 3               | 3               | $3/8$    | $3/7$    | $|3/8 - 3/7| = 3/56 \\approx 0.0536$ |\n| $5.2$ | $\\mathcal{A}$ | 4               | 3               | $4/8$    | $3/7$    | $|1/2 - 3/7| = 1/14 \\approx 0.0714$ |\n| $5.5$ | $\\mathcal{B}$ | 4               | 4               | $4/8$    | $4/7$    | $|1/2 - 4/7| = 1/14 \\approx 0.0714$ |\n| $6.0$ | $\\mathcal{B}$ | 4               | 5               | $4/8$    | $5/7$    | $|1/2 - 5/7| = 3/14 \\approx 0.2143$ |\n| $6.3$ | $\\mathcal{A}$ | 5               | 5               | $5/8$    | $5/7$    | $|5/8 - 5/7| = 5/56 \\approx 0.0893$ |\n| $6.8$ | $\\mathcal{A}$ | 6               | 5               | $6/8$    | $5/7$    | $|3/4 - 5/7| = 1/28 \\approx 0.0357$ |\n| $7.4$ | $\\mathcal{A}$ | 7               | 5               | $7/8$    | $5/7$    | $|7/8 - 5/7| = 9/56 \\approx 0.1607$ |\n| $7.9$ | $\\mathcal{B}$ | 7               | 6               | $7/8$    | $6/7$    | $|7/8 - 6/7| = 1/56 \\approx 0.0179$ |\n| $8.2$ | $\\mathcal{B}$ | 7               | 7               | $7/8$    | $7/7$    | $|7/8 - 1| = 1/8 \\approx 0.1250$     |\n| $9.0$ | $\\mathcal{A}$ | 8               | 7               | $8/8$    | $7/7$    | $|1 - 1| = 0$             |\n\nThe maximum absolute difference is $D_{8,7} = 17/56$.\n\n**Step 2: Approximate the $p$-value**\n\nUnder the null hypothesis that the samples are from the same continuous distribution, the scaled statistic $K_{n,m} = \\sqrt{\\frac{nm}{n+m}} D_{n,m}$ has an asymptotic Kolmogorov distribution. The $p$-value is given by $\\mathrm{Prob}(K \\ge k_{obs})$, where $k_{obs}$ is the observed value of the scaled statistic.\nThe tail probability can be calculated using the series:\n$$ p = 2 \\sum_{i=1}^{\\infty} (-1)^{i-1} \\exp(-2i^2 k^2) = 2 \\left( e^{-2k^2} - e^{-8k^2} + e^{-18k^2} - \\dots \\right) $$\n\nFirst, we compute the observed scaled statistic, $k_{obs}$:\n$$ k_{obs} = \\sqrt{\\frac{8 \\times 7}{8+7}} \\times \\frac{17}{56} = \\sqrt{\\frac{56}{15}} \\times \\frac{17}{56} = \\frac{17}{\\sqrt{15 \\times 56}} = \\frac{17}{\\sqrt{840}} $$\nNow, we calculate $k_{obs}^2$:\n$$ k_{obs}^2 = \\left(\\frac{17}{\\sqrt{840}}\\right)^2 = \\frac{289}{840} \\approx 0.3440476 $$\n\nNext, we evaluate the terms in the series for the $p$-value:\n- $2k_{obs}^2 = 2 \\times \\frac{289}{840} = \\frac{289}{420} \\approx 0.688095$\n- $8k_{obs}^2 = 8 \\times \\frac{289}{840} = \\frac{289 \\times 2}{105} \\approx 2.752381$\n- $18k_{obs}^2 = 18 \\times \\frac{289}{840} \\approx 6.192857$\n\nNow calculate the exponential terms:\n- $\\exp(-2k_{obs}^2) \\approx \\exp(-0.688095) \\approx 0.502534$\n- $\\exp(-8k_{obs}^2) \\approx \\exp(-2.752381) \\approx 0.063781$\n- $\\exp(-18k_{obs}^2) \\approx \\exp(-6.192857) \\approx 0.002044$\nThe subsequent terms will be negligible.\n\nSumming the terms for the $p$-value:\n$$ p \\approx 2 \\times (0.502534 - 0.063781 + 0.002044) $$\n$$ p \\approx 2 \\times (0.440797) $$\n$$ p \\approx 0.881594 $$\n\nRounding to four significant figures, the $p$-value is $0.8816$.\n\n**Step 3: Final Answer**\nThe Kolmogorov-Smirnov statistic is $17/56$. The approximated $p$-value is $0.8816$. The final answer is presented as a row matrix.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{17}{56}  0.8816 \\end{pmatrix} } $$", "id": "4920263"}]}