{"hands_on_practices": [{"introduction": "Before applying any statistical test, the first and most crucial step is to correctly formulate the null ($H_0$) and alternative ($H_a$) hypotheses. For the Mann-Whitney U test, this goes beyond a simple comparison of means or medians; it involves comparing the entire distributions. This exercise [@problem_id:1962407] challenges you to translate a practical research question—whether a new treatment 'stochastically increases' an outcome—into the formal language of cumulative distribution functions (CDFs), a core concept for correctly interpreting the test's results.", "problem": "A biotechnology company has developed a new genetically engineered microbe intended to enhance nutrient absorption in plants grown via hydroponics. To test its effectiveness, an experiment is conducted on a batch of lettuce seedlings. The seedlings are randomly divided into two groups. The first group, the 'Treated' group, is grown in a nutrient solution containing the new microbe. The second group, the 'Control' group, is grown in an identical nutrient solution but without the microbe.\n\nAfter a 30-day growth period, the biomass yield (in grams per plant) is measured for each plant. Because the researchers have no reason to assume the yield data from either group will follow a normal distribution, they decide to use a non-parametric test. They wish to perform a one-tailed Mann-Whitney U test (also known as the Wilcoxon rank-sum test) to determine if there is sufficient statistical evidence to conclude that the new microbe *stochastically increases* the crop yield.\n\nLet $F_T(y)$ and $F_C(y)$ represent the cumulative distribution functions (CDFs) of the biomass yield for the Treated and Control populations, respectively. Which of the following options correctly represents the null hypothesis ($H_0$) and the alternative hypothesis ($H_a$) for this investigation?\n\nA.\n$H_0$: $F_T(y) = F_C(y)$ for all $y$.\n$H_a$: $F_T(y) \\le F_C(y)$ for all $y$, and $F_T(y) < F_C(y)$ for some $y$.\n\nB.\n$H_0$: $F_T(y) = F_C(y)$ for all $y$.\n$H_a$: $F_T(y) \\ge F_C(y)$ for all $y$, and $F_T(y) > F_C(y)$ for some $y$.\n\nC.\n$H_0$: $F_T(y) = F_C(y)$ for all $y$.\n$H_a$: $F_T(y) \\neq F_C(y)$ for some $y$.\n\nD.\nLet $\\mu_T$ and $\\mu_C$ be the mean yields of the treated and control populations.\n$H_0$: $\\mu_T = \\mu_C$.\n$H_a$: $\\mu_T > \\mu_C$.\n\nE.\n$H_0$: $F_T(y) \\le F_C(y)$ for all $y$, and $F_T(y) < F_C(y)$ for some $y$.\n$H_a$: $F_T(y) = F_C(y)$ for all $y$.", "solution": "The goal of this hypothesis test is to determine if the new microbe stochastically increases crop yield. We will formulate the null and alternative hypotheses for a Mann-Whitney U test, which is a non-parametric test designed to compare two independent distributions.\n\nFirst, we establish the null hypothesis ($H_0$). The null hypothesis represents the default position of no effect or no difference between the two groups. In the context of comparing distributions using their cumulative distribution functions (CDFs), the statement of no difference is that the two distributions are identical. Therefore, the CDF of the Treated group's yield, $F_T(y)$, is equal to the CDF of the Control group's yield, $F_C(y)$, for all possible yield values $y$.\n$$H_0: F_T(y) = F_C(y) \\text{ for all } y$$\n\nNext, we establish the alternative hypothesis ($H_a$). The alternative hypothesis should reflect the research question, which is whether the microbe *stochastically increases* the yield. Let $Y_T$ be the random variable for the yield of the Treated group and $Y_C$ be the random variable for the yield of the Control group. The statement that $Y_T$ is \"stochastically greater than\" $Y_C$ means that for any given yield value $y$, the probability of obtaining a yield greater than $y$ is higher (or equal) for the Treated group than for the Control group.\n$$P(Y_T > y) \\ge P(Y_C > y) \\text{ for all } y$$\nwith the inequality being strict for at least one value of $y$.\n\nWe can express this relationship in terms of the CDFs. The CDF is defined as $F(y) = P(Y \\le y)$. The probability of a value being greater than $y$ is the complement, so $P(Y > y) = 1 - P(Y \\le y) = 1 - F(y)$. Substituting this into our inequality gives:\n$$1 - F_T(y) \\ge 1 - F_C(y)$$\nSubtracting 1 from both sides yields:\n$$-F_T(y) \\ge -F_C(y)$$\nMultiplying by -1 reverses the inequality sign:\n$$F_T(y) \\le F_C(y)$$\nThis result has a clear interpretation. If the Treated group yields are generally higher, the cumulative probability of getting a yield *at or below* any specific value $y$ will be smaller for the Treated group compared to the Control group. Therefore, the alternative hypothesis for a one-tailed test for a stochastic increase is that $F_T(y)$ is less than or equal to $F_C(y)$ for all $y$, and strictly less for at least one $y$.\n$$H_a: F_T(y) \\le F_C(y) \\text{ for all } y, \\text{ and } F_T(y) < F_C(y) \\text{ for some } y$$\n\nNow we evaluate the given options:\n- Option A correctly states the null hypothesis of no difference and the alternative hypothesis for the Treated group being stochastically greater than the Control group. This matches our derivation.\n- Option B states an alternative hypothesis, $F_T(y) \\ge F_C(y)$, which would test if the yield from the Treated group is stochastically *less* than the control. This is the opposite of the research goal.\n- Option C presents a two-tailed alternative hypothesis, $F_T(y) \\neq F_C(y)$, which tests for any difference in distribution, not specifically an increase.\n- Option D formulates the hypotheses in terms of population means ($\\mu$). This is incorrect because the Mann-Whitney U test is a non-parametric test on distributions, not a parametric test on means like the t-test.\n- Option E incorrectly swaps the null and alternative hypotheses. The null hypothesis must be the statement of equality or no effect.\n\nTherefore, the correct formulation of the hypotheses for this specific research question is provided in Option A.", "answer": "$$\\boxed{A}$$", "id": "1962407"}, {"introduction": "Now that we understand how to formulate the hypotheses, let's look under the hood at the test's mechanics. While software can compute a $p$-value instantly, working through the calculation by hand on a small dataset provides an invaluable understanding of the logic behind the test. This problem [@problem_id:4934903] guides you through computing an exact $p$-value for a Wilcoxon rank-sum test by ranking the data and considering all possible outcomes under the null hypothesis, revealing the combinatorial foundation of this powerful non-parametric method.", "problem": "A clinical study compares a continuous biomarker between two independent groups. Group A consists of $n_A = 3$ patients with biomarker values $5.1$, $6.3$, and $8.0$. Group B consists of $n_B = 4$ patients with biomarker values $2.0$, $2.9$, $3.5$, and $5.9$. Assume the biomarker is measured on a continuous scale and that, under the null hypothesis, both groups are samples from the same continuous distribution.\n\nUsing the Wilcoxon rank-sum framework, formulate and carry out a one-tailed test of\n$$H_0: \\text{median}_A = \\text{median}_B \\quad \\text{versus} \\quad H_1: \\text{median}_A > \\text{median}_B.$$\nConstruct the pooled ranks, compute the observed Wilcoxon rank-sum statistic for Group A, and, based on the exact randomization distribution implied by the null hypothesis, compute the exact one-tailed $p$-value\n$$p = \\mathbb{P}_{H_0}\\left(W_A \\geq w_{\\text{obs}}\\right),$$\nwhere $W_A$ is the rank-sum for Group A and $w_{\\text{obs}}$ is the observed value from the data above.\n\nExpress the $p$-value as a decimal rounded to $4$ significant figures.", "solution": "The Wilcoxon rank-sum test is a non-parametric test used to compare two independent samples. The procedure involves pooling the data from both groups, ranking the combined data, and then summing the ranks for one of the groups.\n\nFirst, we combine the observations from Group A and Group B and sort them in ascending order. The total number of observations is $N = n_A + n_B = 3 + 4 = 7$.\n\nThe pooled and sorted data are:\n$2.0$ (B), $2.9$ (B), $3.5$ (B), $5.1$ (A), $5.9$ (B), $6.3$ (A), $8.0$ (A)\n\nNext, we assign ranks to these observations from $1$ to $N = 7$. Since all data values are unique, there are no ties.\n\nThe ranks are assigned as follows:\n- Value $2.0$ from Group B receives rank $1$.\n- Value $2.9$ from Group B receives rank $2$.\n- Value $3.5$ from Group B receives rank $3$.\n- Value $5.1$ from Group A receives rank $4$.\n- Value $5.9$ from Group B receives rank $5$.\n- Value $6.3$ from Group A receives rank $6$.\n- Value $8.0$ from Group A receives rank $7$.\n\nThe ranks for the observations in Group A are $\\{4, 6, 7\\}$.\nThe ranks for the observations in Group B are $\\{1, 2, 3, 5\\}$.\n\nThe test statistic, $W_A$, is the sum of the ranks for Group A. The observed value of this statistic is:\n$$w_{\\text{obs}} = 4 + 6 + 7 = 17$$\n\nThe problem asks for the one-tailed p-value for the alternative hypothesis $H_1: \\text{median}_A > \\text{median}_B$. This hypothesis suggests that the values in Group A tend to be larger than in Group B, which would correspond to larger ranks for Group A and thus a large value for the rank-sum statistic $W_A$. The p-value is therefore the probability of observing a rank-sum for Group A that is at least as large as the observed value, $w_{\\text{obs}} = 17$, under the null hypothesis.\n$$p = \\mathbb{P}_{H_0}(W_A \\geq 17)$$\n\nUnder the null hypothesis, all possible combinations of assigning the $N=7$ ranks to the $n_A=3$ individuals in Group A are equally likely. The total number of ways to choose $n_A=3$ ranks from the set of $7$ available ranks is given by the binomial coefficient:\n$$\\text{Total combinations} = \\binom{N}{n_A} = \\binom{7}{3} = \\frac{7!}{3!(7-3)!} = \\frac{7 \\times 6 \\times 5}{3 \\times 2 \\times 1} = 35$$\nEach of these $35$ combinations is equally probable under $H_0$, with probability $\\frac{1}{35}$.\n\nTo find the p-value, we must count the number of combinations of $3$ ranks (from the set $\\{1, 2, 3, 4, 5, 6, 7\\}$) that result in a sum greater than or equal to $17$. We enumerate these \"extreme\" combinations. The maximum possible rank-sum occurs if Group A has the three largest ranks: $\\{5, 6, 7\\}$. The sum is $5 + 6 + 7 = 18$. This sum is $\\geq 17$ and accounts for one combination. The observed combination $\\{4, 6, 7\\}$ has a sum of $17$. To check for other combinations summing to 17, we can reason systematically. If a combination includes the largest rank, 7, the other two ranks must sum to $10$. From the remaining ranks $\\{1, 2, 3, 4, 5, 6\\}$, only the pair $\\{4, 6\\}$ works. If a combination does not include rank 7, the maximum possible sum is from $\\{4, 5, 6\\}$, which is $15$, a value less than $17$. Therefore, $\\{4, 6, 7\\}$ is the only combination that sums to $17$.\n\nIn total, there are two combinations of ranks for Group A that would yield a rank-sum greater than or equal to $17$:\n- $\\{4, 6, 7\\}$ (sum = $17$)\n- $\\{5, 6, 7\\}$ (sum = $18$)\n\nThe number of outcomes as extreme or more extreme than the observed outcome is $2$.\n\nThe exact p-value is the ratio of the number of these extreme outcomes to the total number of possible outcomes:\n$$p = \\frac{\\text{Number of combinations with } W_A \\geq 17}{\\text{Total number of combinations}} = \\frac{2}{35}$$\n\nFinally, we express this fraction as a decimal and round to $4$ significant figures.\n$$p = \\frac{2}{35} \\approx 0.057142857...$$\nRounding to $4$ significant figures gives:\n$$p \\approx 0.05714$$", "answer": "$$\n\\boxed{0.05714}\n$$", "id": "4934903"}, {"introduction": "A key reason to choose the Mann-Whitney U test over a classic $t$-test is its robustness against outliers, which are common in many biological datasets. This computational practice [@problem_id:2398972] powerfully demonstrates this principle by comparing the performance of both tests on data with and without extreme values. By observing how a single outlier can dramatically alter the $p$-value of a $t$-test while having minimal effect on the rank-based Wilcoxon test, you will build strong intuition for when and why to deploy this non-parametric tool.", "problem": "Construct a program that, for a fixed gene measured across two biological conditions in Ribonucleic Acid sequencing (RNA-seq), computes the two-sided p-values of both the two-sample Welch $t$-test and the Wilcoxon rank-sum test (also known as the Mann–Whitney $U$ test) and aggregates the results across a specified test suite. Assume each condition produces independent replicate counts for the gene, and treat the provided counts as the observed values. The null hypothesis for both tests is that the two conditions have equal central tendency, stated as $H_0$: the two conditions are sampled from populations with equal means (Welch $t$-test) or equal continuous distributions (Wilcoxon rank-sum test). No transformations are to be applied to the counts. All tests must be two-sided.\n\nYour program must process the following test suite, where each item specifies the counts for condition $A$ and condition $B$:\n\n- Test case $1$ (baseline, no outlier, comparable distributions):\n  - Condition $A$: $\\left(43, 50, 39, 61, 55, 47\\right)$\n  - Condition $B$: $\\left(45, 52, 41, 58, 53, 49\\right)$\n\n- Test case $2$ (single extreme high outlier in condition $B$):\n  - Condition $A$: $\\left(43, 50, 39, 61, 55, 47\\right)$\n  - Condition $B$: $\\left(45, 52, 41, 58, 53, 1000\\right)$\n\n- Test case $3$ (small sample size with a single extreme high outlier in condition $B$):\n  - Condition $A$: $\\left(20, 22, 25\\right)$\n  - Condition $B$: $\\left(19, 21, 400\\right)$\n\n- Test case $4$ (location shift with a single extreme low outlier in condition $B$):\n  - Condition $A$: $\\left(15, 16, 18, 20, 19, 17\\right)$\n  - Condition $B$: $\\left(28, 30, 27, 29, 31, 0\\right)$\n\nFor each test case $i \\in \\{1,2,3,4\\}$, compute:\n- $p_{t,i}$: the two-sided p-value from the two-sample Welch $t$-test comparing condition $A$ and condition $B$.\n- $p_{w,i}$: the two-sided p-value from the Wilcoxon rank-sum test comparing condition $A$ and condition $B$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain $8$ floating-point numbers ordered as $\\left[p_{t,1}, p_{w,1}, p_{t,2}, p_{w,2}, p_{t,3}, p_{w,3}, p_{t,4}, p_{w,4}\\right]$, where each number is rounded to $6$ decimal places. No additional text should be printed. All numbers are dimensionless and must be expressed as decimal fractions (for example, $0.012345$), not as percentages.", "solution": "The problem requires the computation of p-values from two distinct statistical hypothesis tests—the Welch two-sample $t$-test and the Wilcoxon rank-sum test—applied to RNA-sequencing count data from two conditions. The objective is to compare the performance of a parametric test against a non-parametric test, particularly in the presence of outliers, which are common in biological datasets. Before proceeding to the computational solution, we must establish the theoretical foundation for each test.\n\n**1. Welch's Two-Sample $t$-test**\n\nThe Welch's $t$-test is a statistical tool for comparing the means of two independent samples, denoted here as condition $A$ and condition $B$. It is an adaptation of the Student's $t$-test and is considered more reliable when the two samples have unequal variances, a scenario known as the Behrens-Fisher problem. The null hypothesis, $H_0$, posits that the population means are equal, i.e., $H_0: \\mu_A = \\mu_B$.\n\nThe test statistic $t$ is calculated as the difference between the sample means, scaled by the standard error of the difference:\n$$\nt = \\frac{\\bar{x}_A - \\bar{x}_B}{\\sqrt{\\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B}}}\n$$\nwhere:\n- $\\bar{x}_A$ and $\\bar{x}_B$ are the sample means for conditions $A$ and $B$, respectively.\n- $s_A^2$ and $s_B^2$ are the unbiased sample variances.\n- $n_A$ and $n_B$ are the sample sizes.\n\nUnlike the Student's $t$-test, the degrees of freedom, $\\nu$, for the Welch's test are not simply $n_A + n_B - 2$. Instead, they are approximated using the Welch-Satterthwaite equation:\n$$\n\\nu \\approx \\frac{\\left( \\frac{s_A^2}{n_A} + \\frac{s_B^2}{n_B} \\right)^2}{\\frac{(s_A^2/n_A)^2}{n_A - 1} + \\frac{(s_B^2/n_B)^2}{n_B - 1}}\n$$\nThe p-value is then determined from the Student's $t$-distribution with $\\nu$ degrees of freedom. For a two-sided test, the p-value is $2 \\cdot P(T_\\nu > |t|)$, where $T_\\nu$ is a random variable following the $t$-distribution.\n\nA critical assumption of the $t$-test is that the data in both samples are approximately normally distributed. The test's performance degrades in the presence of strong deviations from normality, such as skewness or heavy tails. Crucially, the sample mean $(\\bar{x})$ and variance $(s^2)$ are highly sensitive to extreme values (outliers), which can disproportionately influence the $t$-statistic and lead to erroneous conclusions.\n\n**2. Wilcoxon Rank-Sum (Mann-Whitney U) Test**\n\nThe Wilcoxon rank-sum test is a non-parametric alternative to the $t$-test. It does not assume a specific distribution for the data, making it more robust. The null hypothesis for this test is that for randomly selected values $X$ and $Y$ from the two populations, the probability of $X$ being greater than $Y$ is equal to the probability of $Y$ being greater than $X$. More generally, it tests if the two samples are drawn from populations with the same distribution.\n\nThe procedure is as follows:\n1. Combine all $n_A + n_B$ observations into a single ranked list. If ties exist, assign the average of the ranks that would have been assigned.\n2. Calculate the sum of the ranks for one of the samples, for instance, sample $A$, denoted as $R_A$.\n3. The test statistic $U$ is calculated based on this rank sum. For sample $A$, the statistic $U_A$ is:\n   $$\n   U_A = R_A - \\frac{n_A(n_A + 1)}{2}\n   $$\n   The test statistic $U$ is typically taken as $U = \\min(U_A, U_B)$, where $U_B$ is calculated similarly for sample $B$.\n4. The p-value is determined from the known distribution of the $U$ statistic under the null hypothesis. For small sample sizes, an exact distribution is used. For larger samples, a normal approximation with a continuity correction is employed.\n\nBecause the Wilcoxon test operates on ranks rather than the original data values, its statistic is not affected by the magnitude of outliers, only by their ordinal position. An extreme value is simply treated as the highest (or lowest) rank, and its specific numerical value does not further influence the test statistic. This property confers substantial robustness against outliers.\n\n**3. Application and Interpretation of Test Cases**\n\nThe provided test cases are designed to highlight the differing sensitivities of these two tests.\n- **Test case 1**: The distributions are similar and lack outliers. Both tests are expected to yield high p-values, indicating no significant difference.\n- **Test cases 2 and 3**: An extreme high outlier is introduced into condition $B$. The $t$-test's p-value is expected to be substantially affected because the outlier will inflate both the mean and variance of condition $B$. In contrast, the Wilcoxon test should be relatively unaffected, providing a more stable assessment of the central tendency shift.\n- **Test case 4**: An extreme low outlier is introduced into condition $B$, whose other members have shifted to higher values compared to condition $A$. This outlier pulls the mean of condition $B$ down, potentially masking the true location shift from the $t$-test. The rank-sum test, however, is better equipped to detect the consistent rank difference between the bulk of the two samples.\n\nThe computational implementation will use the `scipy.stats` library, specifically `ttest_ind` with the parameter `equal_var=False` to perform the Welch's $t$-test, and `mannwhitneyu` with `alternative='two-sided'` for the Wilcoxon rank-sum test. The results will be systematically computed for each test case and formatted as required.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import ttest_ind, mannwhitneyu\n\ndef solve():\n    \"\"\"\n    Computes and prints p-values for Welch's t-test and Wilcoxon rank-sum test\n    for a suite of RNA-seq count data test cases.\n    \"\"\"\n\n    # Define the test suite as specified in the problem statement.\n    test_cases = [\n        # Test case 1: baseline, no outlier, comparable distributions\n        (np.array([43, 50, 39, 61, 55, 47]), np.array([45, 52, 41, 58, 53, 49])),\n        # Test case 2: single extreme high outlier in condition B\n        (np.array([43, 50, 39, 61, 55, 47]), np.array([45, 52, 41, 58, 53, 1000])),\n        # Test case 3: small sample size with a single extreme high outlier in condition B\n        (np.array([20, 22, 25]), np.array([19, 21, 400])),\n        # Test case 4: location shift with a single extreme low outlier in condition B\n        (np.array([15, 16, 18, 20, 19, 17]), np.array([28, 30, 27, 29, 31, 0])),\n    ]\n\n    results = []\n    for cond_a, cond_b in test_cases:\n        # Perform Welch's two-sample t-test.\n        # The `equal_var=False` argument specifies that we should perform Welch's t-test,\n        # which does not assume equal population variance.\n        # The test is two-sided by default.\n        t_stat, p_t = ttest_ind(cond_a, cond_b, equal_var=False)\n        results.append(p_t)\n\n        # Perform the Wilcoxon rank-sum test (Mann-Whitney U test).\n        # We explicitly specify a two-sided test.\n        # The 'auto' method for p-value calculation is used by default,\n        # which chooses between an exact test and a normal approximation\n        # based on sample size and presence of ties.\n        u_stat, p_w = mannwhitneyu(cond_a, cond_b, alternative='two-sided')\n        results.append(p_w)\n\n    # Format the results as a comma-separated list of floating-point numbers\n    # rounded to 6 decimal places, enclosed in square brackets.\n    formatted_results = [f\"{p:.6f}\" for p in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2398972"}]}