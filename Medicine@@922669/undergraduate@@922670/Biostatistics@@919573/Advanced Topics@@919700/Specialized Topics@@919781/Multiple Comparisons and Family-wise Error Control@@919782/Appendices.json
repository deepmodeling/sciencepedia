{"hands_on_practices": [{"introduction": "When conducting multiple statistical tests simultaneously, such as in a biomarker study, the overall probability of making at least one false discovery (a Type I error) inflates. The Bonferroni correction is the most fundamental method to control this family-wise error rate (FWER). This exercise provides foundational practice in applying this essential correction and calculating adjusted $p$-values, grounding your understanding in the basic principles of probability [@problem_id:4930328].", "problem": "A translational oncology study evaluates whether five pre-specified serum biomarkers show differential levels between cases and controls. For each biomarker, a hypothesis test yields an unadjusted $p$-value. The family of tests is to be interpreted jointly, and the investigator seeks to control the Family-Wise Error Rate (FWER) at level $\\alpha=0.05$ using the Bonferroni principle.\n\nYou are given $m=5$ unadjusted $p$-values in the order of biomarkers $1$ through $5$: $(0.003, 0.01, 0.02, 0.04, 0.06)$.\n\nStarting from the definition of Family-Wise Error Rate (FWER) as the probability of making at least one type I error among the $m$ null hypotheses, use basic probability principles to justify a Bonferroni decision rule that controls FWER at level $\\alpha$, and determine which null hypotheses are rejected. Then compute the Bonferroni-adjusted $p$-values for each biomarker.\n\nReport your final answer as a single row matrix with $10$ entries: the first five entries are the Bonferroni-adjusted $p$-values for biomarkers $1$ through $5$ (in the order given), and the next five entries are indicators of rejection at family-wise level $\\alpha$ using the Bonferroni rule, with $1$ for “reject” and $0$ for “do not reject.” No rounding is required.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of biostatistics, specifically multiple hypothesis testing. It is well-posed, with all necessary data provided, and objective, using clear and precise language.\n\nThe task is to justify the Bonferroni correction starting from the definition of the Family-Wise Error Rate (FWER), apply it to a given set of $p$-values to determine which null hypotheses are rejected, and compute the corresponding Bonferroni-adjusted $p$-values.\n\nLet there be $m$ null hypotheses, $H_{0,1}, H_{0,2}, \\dots, H_{0,m}$. For each hypothesis test $i$, we obtain a $p$-value, $p_i$. The Family-Wise Error Rate (FWER) is defined as the probability of making at least one Type I error (rejecting a true null hypothesis) among the entire family of $m$ tests. Let $E_i$ be the event of committing a Type I error for the $i$-th hypothesis. The FWER is the probability of the union of these events:\n$$\n\\text{FWER} = P\\left(\\bigcup_{i \\in I_0} E_i\\right)\n$$\nwhere $I_0$ is the index set of the true null hypotheses. To control the FWER, we consider the worst-case scenario where all null hypotheses are true, i.e., $I_0 = \\{1, 2, \\dots, m\\}$. In this case,\n$$\n\\text{FWER} = P\\left(\\bigcup_{i=1}^{m} E_i\\right)\n$$\nBy Boole's inequality (also known as the union bound), the probability of a union of events is less than or equal to the sum of their individual probabilities:\n$$\nP\\left(\\bigcup_{i=1}^{m} E_i\\right) \\leq \\sum_{i=1}^{m} P(E_i)\n$$\nA Type I error for test $i$ occurs if we reject $H_{0,i}$ when it is true. The decision rule for a single test is to reject $H_{0,i}$ if its $p$-value $p_i$ is less than or equal to some significance level, let's call it $\\alpha_{ind}$ for \"individual\". The probability of this event, given that $H_{0,i}$ is true, is the definition of the significance level of the test: $P(E_i) = P(p_i \\leq \\alpha_{ind} | H_{0,i} \\text{ is true}) = \\alpha_{ind}$.\n\nSubstituting this into the inequality, we get:\n$$\n\\text{FWER} \\leq \\sum_{i=1}^{m} \\alpha_{ind}\n$$\nThe Bonferroni method uses the same individual significance level for all tests, so $\\alpha_{ind}$ is constant for all $i=1, \\dots, m$. The inequality simplifies to:\n$$\n\\text{FWER} \\leq m \\cdot \\alpha_{ind}\n$$\nTo control the FWER at a pre-specified level $\\alpha$, we must ensure that the right-hand side of the inequality is no greater than $\\alpha$. We set $m \\cdot \\alpha_{ind} \\leq \\alpha$, which yields $\\alpha_{ind} \\leq \\frac{\\alpha}{m}$. To be as powerful as possible (i.e., to use the largest possible individual significance level), we choose $\\alpha_{ind} = \\frac{\\alpha}{m}$.\n\nThis gives the Bonferroni decision rule: reject the null hypothesis $H_{0,i}$ if its unadjusted $p$-value $p_i$ is less than or equal to the Bonferroni-corrected significance threshold $\\frac{\\alpha}{m}$. This procedure guarantees that $\\text{FWER} \\leq \\alpha$.\n\nNow, we apply this rule to the given problem.\nThe number of hypothesis tests is $m=5$.\nThe desired family-wise error rate is $\\alpha=0.05$.\nThe Bonferroni-corrected significance threshold is $\\alpha_{adj} = \\frac{\\alpha}{m} = \\frac{0.05}{5} = 0.01$.\n\nThe unadjusted $p$-values are given as $p_1=0.003$, $p_2=0.01$, $p_3=0.02$, $p_4=0.04$, and $p_5=0.06$. We compare each $p$-value to $\\alpha_{adj} = 0.01$.\n\n1.  For biomarker 1: $p_1 = 0.003$. Since $0.003 \\leq 0.01$, we reject the null hypothesis $H_{0,1}$.\n2.  For biomarker 2: $p_2 = 0.01$. Since $0.01 \\leq 0.01$, we reject the null hypothesis $H_{0,2}$.\n3.  For biomarker 3: $p_3 = 0.02$. Since $0.02 > 0.01$, we do not reject the null hypothesis $H_{0,3}$.\n4.  For biomarker 4: $p_4 = 0.04$. Since $0.04 > 0.01$, we do not reject the null hypothesis $H_{0,4}$.\n5.  For biomarker 5: $p_5 = 0.06$. Since $0.06 > 0.01$, we do not reject the null hypothesis $H_{0,5}$.\n\nThe rejection indicators ($1$ for reject, $0$ for do not reject) for biomarkers $1$ through $5$ are $(1, 1, 0, 0, 0)$.\n\nNext, we compute the Bonferroni-adjusted $p$-values, denoted $\\tilde{p}_i$. The adjusted $p$-value is defined such that one can reject $H_{0,i}$ if $\\tilde{p}_i \\leq \\alpha$. The original rejection rule is $p_i \\leq \\frac{\\alpha}{m}$. Rearranging this gives $m \\cdot p_i \\leq \\alpha$. Thus, the adjusted $p$-value $\\tilde{p}_i$ is $m \\cdot p_i$. Since a probability cannot exceed $1$, the formal definition is:\n$$\n\\tilde{p}_i = \\min(m \\cdot p_i, 1)\n$$\nWe compute this for each biomarker with $m=5$:\n\n1.  $\\tilde{p}_1 = \\min(5 \\times 0.003, 1) = \\min(0.015, 1) = 0.015$.\n2.  $\\tilde{p}_2 = \\min(5 \\times 0.01, 1) = \\min(0.05, 1) = 0.05$.\n3.  $\\tilde{p}_3 = \\min(5 \\times 0.02, 1) = \\min(0.10, 1) = 0.1$.\n4.  $\\tilde{p}_4 = \\min(5 \\times 0.04, 1) = \\min(0.20, 1) = 0.2$.\n5.  $\\tilde{p}_5 = \\min(5 \\times 0.06, 1) = \\min(0.30, 1) = 0.3$.\n\nThe adjusted $p$-values for biomarkers $1$ through $5$ are $(0.015, 0.05, 0.1, 0.2, 0.3)$. We can verify the rejection decisions using these adjusted $p$-values against $\\alpha=0.05$:\n- $\\tilde{p}_1 = 0.015 \\leq 0.05 \\implies$ Reject.\n- $\\tilde{p}_2 = 0.05 \\leq 0.05 \\implies$ Reject.\n- $\\tilde{p}_3 = 0.1 > 0.05 \\implies$ Do not reject.\n- $\\tilde{p}_4 = 0.2 > 0.05 \\implies$ Do not reject.\n- $\\tilde{p}_5 = 0.3 > 0.05 \\implies$ Do not reject.\nThis confirms the previous findings.\n\nThe final answer requires a single row matrix containing the five adjusted $p$-values followed by the five rejection indicators.\nAdjusted $p$-values: $(0.015, 0.05, 0.1, 0.2, 0.3)$.\nRejection indicators: $(1, 1, 0, 0, 0)$.\n\nThe combined row matrix is $(0.015, 0.05, 0.1, 0.2, 0.3, 1, 1, 0, 0, 0)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.015  0.05  0.1  0.2  0.3  1  1  0  0  0\n\\end{pmatrix}\n}\n$$", "id": "4930328"}, {"introduction": "While the Bonferroni correction effectively controls the FWER, its uniform stringency can make it overly conservative, potentially causing you to miss true discoveries. The Holm procedure provides a more powerful step-down procedure that increases the chance of detecting true effects. This practice will guide you through the sequential logic of the Holm procedure, helping you compare its power to the Bonferroni method while still rigorously controlling the overall error rate [@problem_id:4930339].", "problem": "A biostatistics researcher analyzes $m=4$ pre-specified biomarkers for association with a clinical outcome, yielding ordered $p$-values $p_{(1)}=0.004$, $p_{(2)}=0.012$, $p_{(3)}=0.02$, and $p_{(4)}=0.08$. The goal is to control the family-wise error rate (FWER) at level $\\alpha=0.05$ using the sequentially rejective step-down procedure of Holm. Beginning from the definition of the family-wise error rate as the probability of at least one false rejection and using the Bonferroni inequality together with the logic of a step-down procedure that screens hypotheses in increasing order of their $p$-values, derive the stepwise critical values required to ensure strong control of the family-wise error rate at level $\\alpha$. Apply your derived procedure to the given ordered $p$-values to determine how many null hypotheses are rejected. Report your final answer as the integer count $k$ of rejected null hypotheses.", "solution": "The problem is evaluated to be valid as it is scientifically grounded, well-posed, objective, and complete. It presents a standard biostatistical task based on established principles.\n\nThe task is to derive the critical values for the Holm sequentially rejective procedure for controlling the family-wise error rate (FWER) and then apply it to a given dataset.\n\n**Part 1: Derivation of the Holm Procedure**\n\nThe family-wise error rate (FWER) is defined as the probability of making one or more Type I errors (false rejections) among all hypotheses tested. Let there be $m$ null hypotheses, $H_1, H_2, \\dots, H_m$, with corresponding $p$-values $p_1, p_2, \\dots, p_m$. Our goal is to ensure that $FWER \\le \\alpha$ for a pre-specified significance level $\\alpha$. This is known as strong control of the FWER, as it must hold for any configuration of true and false null hypotheses. Let $V$ be the number of true null hypotheses that are incorrectly rejected. The FWER is then $P(V \\ge 1)$.\n\nLet $I_0$ be the index set of the $m_0$ hypotheses that are truly null. The p-values corresponding to these hypotheses, $\\{p_i : i \\in I_0\\}$, are independent and identically distributed as Uniform$(0,1)$ random variables under their respective nulls.\n\nThe Holm procedure is a step-down method. First, the $p$-values are ordered from smallest to largest: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$. Let the hypotheses corresponding to these ordered $p$-values be $H_{(1)}, H_{(2)}, \\dots, H_{(m)}$. The procedure is as follows:\nFor $j = 1, 2, \\dots, m$, compare the $j$-th ordered $p$-value, $p_{(j)}$, with the critical value $\\alpha_j = \\frac{\\alpha}{m-j+1}$.\n- If $p_{(1)} > \\frac{\\alpha}{m}$, stop and reject no hypotheses.\n- Otherwise, reject $H_{(1)}$ and proceed to test $H_{(2)}$.\n- If $p_{(2)} > \\frac{\\alpha}{m-1}$, stop and reject only $H_{(1)}$.\n- Otherwise, reject $H_{(2)}$ and proceed to test $H_{(3)}$.\n- This process continues. At step $j$, if $p_{(j)} > \\frac{\\alpha}{m-j+1}$, the procedure stops, and only the hypotheses $H_{(1)}, \\dots, H_{(j-1)}$ are rejected. If $p_{(j)} \\le \\frac{\\alpha}{m-j+1}$, $H_{(j)}$ is rejected, and the procedure continues to step $j+1$.\n\nTo derive and prove that this procedure strongly controls the FWER at level $\\alpha$, we must show that $P(V \\ge 1) \\le \\alpha$ for any subset $I_0$ of true null hypotheses.\n\nLet $I_0$ be the set of indices for the $m_0$ true nulls. A Type I error occurs if we reject at least one hypothesis $H_i$ for $i \\in I_0$.\nLet $p_{\\min,0} = \\min_{i \\in I_0} \\{p_i\\}$ be the smallest $p$-value among all the true nulls.\nLet the rank of this specific $p$-value in the overall ordered list be $k$, so that $p_{\\min,0} = p_{(k)}$. By its definition, $H_{(k)}$ is the first true null hypothesis in the ordered list (i.e., hypotheses $H_{(1)}, \\dots, H_{(k-1)}$ must be false nulls).\n\nFor any Type I error to occur, at least one true null hypothesis must be rejected. Because the Holm procedure is sequential and stops at the first failure to reject, if any true null $H_{(l)}$ (with $l \\ge k$) is to be rejected, all preceding hypotheses, including $H_{(k)}$, must also be rejected. Therefore, the event of making at least one Type I error is equivalent to the event that $H_{(k)}$ is rejected.\n\nThe procedure rejects $H_{(k)}$ if and only if $p_{(j)} \\le \\frac{\\alpha}{m-j+1}$ for all $j=1, \\dots, k$.\nThis necessarily implies that $p_{(k)} \\le \\frac{\\alpha}{m-k+1}$.\nSo, if a Type I error occurs, it must be the case that $p_{(k)} \\le \\frac{\\alpha}{m-k+1}$.\n\nNow, we relate this condition to the number of true nulls, $m_0$.\nBy definition of $p_{(k)}$ as the smallest $p$-value from a true null, all $m_0$ true null hypotheses must be in the set $\\{H_{(k)}, H_{(k+1)}, \\dots, H_{(m)}\\}$. The size of this set is $m-k+1$.\nConsequently, the number of true nulls cannot exceed the size of this set, which gives the inequality $m_0 \\le m-k+1$.\nThis inequality can be rearranged to $\\frac{1}{m-k+1} \\le \\frac{1}{m_0}$.\n\nCombining these findings, the condition for a Type I error implies:\n$p_{(k)} \\le \\frac{\\alpha}{m-k+1} \\le \\frac{\\alpha}{m_0}$.\nLet $E$ be the event of making at least one Type I error. We have shown that the occurrence of $E$ implies the condition $p_{(k)} \\le \\frac{\\alpha}{m_0}$. This means $E$ is a subset of the event $\\{p_{(k)} \\le \\frac{\\alpha}{m_0}\\}$.\nTherefore, $FWER = P(E) \\le P(p_{(k)} \\le \\frac{\\alpha}{m_0})$.\n\nRecall that $p_{(k)}$ is the minimum of the $m_0$ p-values from the true nulls, $\\{p_i : i \\in I_0\\}$. The event $\\{p_{(k)} \\le \\frac{\\alpha}{m_0}\\}$ is thus equivalent to the event that at least one of these $m_0$ p-values is less than or equal to $\\frac{\\alpha}{m_0}$. We can express this as the union of events:\n$P(p_{(k)} \\le \\frac{\\alpha}{m_0}) = P\\left( \\bigcup_{i \\in I_0} \\left\\{p_i \\le \\frac{\\alpha}{m_0}\\right\\} \\right)$.\n\nWe now apply the Bonferroni inequality (also known as Boole's inequality), which states that for any set of events $A_1, \\dots, A_n$, $P(\\cup_{i=1}^n A_i) \\le \\sum_{i=1}^n P(A_i)$.\nApplying this to our situation:\n$P\\left( \\bigcup_{i \\in I_0} \\left\\{p_i \\le \\frac{\\alpha}{m_0}\\right\\} \\right) \\le \\sum_{i \\in I_0} P\\left(p_i \\le \\frac{\\alpha}{m_0}\\right)$.\n\nFor each true null hypothesis $H_i$, the p-value $p_i$ is distributed as $U(0,1)$. Therefore, for any value $x \\in [0,1]$, $P(p_i \\le x) = x$. Setting $x=\\frac{\\alpha}{m_0}$, we get $P(p_i \\le \\frac{\\alpha}{m_0}) = \\frac{\\alpha}{m_0}$.\nSubstituting this into the sum:\n$\\sum_{i \\in I_0} P\\left(p_i \\le \\frac{\\alpha}{m_0}\\right) = \\sum_{i \\in I_0} \\frac{\\alpha}{m_0} = m_0 \\times \\frac{\\alpha}{m_0} = \\alpha$.\n\nPutting it all together, we have shown:\n$FWER = P(E) \\le P(p_{(k)} \\le \\frac{\\alpha}{m_0}) \\le \\alpha$.\nThis demonstrates that the Holm procedure strongly controls the FWER at level $\\alpha$. The derived stepwise critical values are indeed $\\alpha_j = \\frac{\\alpha}{m-j+1}$ for $j=1, \\dots, m$.\n\n**Part 2: Application to the Given Problem**\n\nWe are given:\n- Number of hypotheses: $m=4$.\n- FWER control level: $\\alpha=0.05$.\n- Ordered $p$-values: $p_{(1)}=0.004$, $p_{(2)}=0.012$, $p_{(3)}=0.02$, and $p_{(4)}=0.08$.\n\nWe apply the Holm procedure step-by-step.\n\n**Step 1 ($j=1$):**\n- Test hypothesis $H_{(1)}$ with $p$-value $p_{(1)} = 0.004$.\n- The critical value is $\\alpha_1 = \\frac{\\alpha}{m-1+1} = \\frac{0.05}{4} = 0.0125$.\n- We compare $p_{(1)}$ to $\\alpha_1$: $0.004 \\le 0.0125$.\n- The condition is met, so we reject $H_{(1)}$ and proceed to the next step.\n\n**Step 2 ($j=2$):**\n- Test hypothesis $H_{(2)}$ with $p$-value $p_{(2)} = 0.012$.\n- The critical value is $\\alpha_2 = \\frac{\\alpha}{m-2+1} = \\frac{0.05}{3} \\approx 0.01667$.\n- We compare $p_{(2)}$ to $\\alpha_2$: $0.012 \\le \\frac{0.05}{3}$.\n- The condition is met, so we reject $H_{(2)}$ and proceed to the next step.\n\n**Step 3 ($j=3$):**\n- Test hypothesis $H_{(3)}$ with $p$-value $p_{(3)} = 0.02$.\n- The critical value is $\\alpha_3 = \\frac{\\alpha}{m-3+1} = \\frac{0.05}{2} = 0.025$.\n- We compare $p_{(3)}$ to $\\alpha_3$: $0.02 \\le 0.025$.\n- The condition is met, so we reject $H_{(3)}$ and proceed to the next step.\n\n**Step 4 ($j=4$):**\n- Test hypothesis $H_{(4)}$ with $p$-value $p_{(4)} = 0.08$.\n- The critical value is $\\alpha_4 = \\frac{\\alpha}{m-4+1} = \\frac{0.05}{1} = 0.05$.\n- We compare $p_{(4)}$ to $\\alpha_4$: $0.08 > 0.05$.\n- The condition is not met. We fail to reject $H_{(4)}$ and stop the procedure.\n\nBased on this procedure, we have rejected the null hypotheses corresponding to the three smallest $p$-values: $H_{(1)}, H_{(2)},$ and $H_{(3)}$. The total number of rejected null hypotheses is $k=3$.", "answer": "$$\\boxed{3}$$", "id": "4930339"}, {"introduction": "Classical methods like Bonferroni and Holm are powerful, but they often operate on $p$-values derived from tests with specific distributional assumptions. Permutation testing offers a flexible and robust computational alternative that generates a null distribution directly from your data, requiring fewer assumptions. This exercise introduces the logic of the max-statistic permutation approach, a cornerstone of modern biostatistics, and demonstrates how to compute adjusted $p$-values from an empirically derived distribution [@problem_id:4930335].", "problem": "You are analyzing $m$ simultaneous statistical tests (null hypotheses $H_1,\\dots,H_m$) with observed test statistics $t_1,\\dots,t_m$. To control the Family-Wise Error Rate (FWER), you will use a max-statistic permutation approach. Under the complete null hypothesis and assuming exchangeability of the test statistics under permutation of labels, the distribution of the maximum test statistic across all $m$ tests, denoted $M=\\max\\{T_1,\\dots,T_m\\}$, can be approximated by performing $B$ label permutations and recording the observed maxima $M^{(1)},\\dots,M^{(B)}$.\n\nFundamental base definitions to use:\n- The Family-Wise Error Rate (FWER) is defined as the probability of making at least one false rejection among $H_1,\\dots,H_m$: $FWER=\\mathbb{P}(\\text{at least one false rejection})$.\n- Under the complete null and exchangeability, the permutation distribution of the maximum test statistic $M$ is a valid approximation for the null distribution of the maximum.\n- For any test $j\\in\\{1,\\dots,m\\}$, the adjusted $p$-value is defined as the probability, under the null distribution of $M$, that $M$ is at least as extreme as the observed $t_j$.\n\nTasks:\n1. Starting from the definition of an adjusted $p$-value for test $j$ as the null tail probability of the maximum statistic at the threshold $t_j$, derive a computable estimator based on $B$ equally likely permutation maxima $M^{(1)},\\dots,M^{(B)}$. Your derivation must begin from the definition of probability as an expectation of an indicator function and the assumption of exchangeability under the complete null hypothesis. The estimator must be expressed without using percentages; use decimal values in $[0,1]$.\n2. Using your derived estimator, implement an algorithm that, for each $j\\in\\{1,\\dots,m\\}$, computes the adjusted $p$-value by comparing the observed $t_j$ to the permutation maxima $M^{(1)},\\dots,M^{(B)}$. Ties must be handled inclusively, meaning values equal to the threshold count as being at least as extreme.\n3. Apply your algorithm to the following test suite. Each test case provides $(m, t_1,\\dots,t_m)$ and $(B, M^{(1)},\\dots,M^{(B)})$:\n   - Test case 1 (general case): $m=4$, $(t_1,t_2,t_3,t_4)=(2.1,1.5,3.0,0.8)$; $B=10$, $(M^{(1)},\\dots,M^{(10)})=(1.9,2.2,3.1,2.8,2.4,1.7,2.0,3.0,2.6,2.3)$.\n   - Test case 2 (tie-handling): $m=3$, $(t_1,t_2,t_3)=(2.3,2.0,3.0)$; $B=3$, $(M^{(1)},M^{(2)},M^{(3)})=(2.3,2.3,2.3)$.\n   - Test case 3 (boundary $B=1$): $m=3$, $(t_1,t_2,t_3)=(1.0,2.5,3.0)$; $B=1$, $(M^{(1)})=(2.5)$.\n   - Test case 4 (negative values and edge extremes): $m=4$, $(t_1,t_2,t_3,t_4)=(-1.0,-0.3,0.0,0.5)$; $B=4$, $(M^{(1)},\\dots,M^{(4)})=(-0.5,-0.2,0.0,-0.1)$.\n4. The final output must be a single line containing the four lists of adjusted $p$-values, one list per test case, expressed as decimals, and formatted as a comma-separated list enclosed in square brackets where each inner list is itself enclosed in square brackets. For example, the output should look like $[[a_1,\\dots,a_m],[b_1,\\dots,b_m],[c_1,\\dots,c_m],[d_1,\\dots,d_m]]$, where each element is a real number in $[0,1]$.\n\nYour program must be self-contained, require no input, and print only the final formatted results as described.", "solution": "The problem statement has been validated and is determined to be sound, well-posed, and objective. It presents a standard task in computational statistics concerning the control of the Family-Wise Error Rate (FWER) using a permutation-based method. The provided definitions and data are consistent and sufficient for deriving and implementing a solution.\n\nThe solution proceeds in two parts. First, I will derive the computational formula for the adjusted $p$-value from fundamental statistical principles. Second, I will describe the algorithm to apply this formula to the provided data.\n\n### Part 1: Derivation of the Adjusted $p$-value Estimator\n\nThe objective is to derive a computable estimator for the adjusted $p$-value, $p_j^{\\text{adj}}$, associated with the observed test statistic $t_j$ for null hypothesis $H_j$.\n\nThe problem defines the adjusted $p$-value for test $j$ as the probability, under the complete null hypothesis $H_0^C$, that the maximum test statistic, $M = \\max\\{T_1, \\dots, T_m\\}$, is at least as extreme as the observed value $t_j$. Formally, this is written as:\n$$\np_j^{\\text{adj}} = \\mathbb{P}(M \\ge t_j \\mid H_0^C)\n$$\nHere, $T_1, \\dots, T_m$ are the random variables corresponding to the test statistics, and their joint distribution is considered under the complete null, where all $H_j$ are true.\n\nProbability can be expressed as the expectation of an indicator function. Let $\\mathbb{I}(\\cdot)$ be the indicator function, which evaluates to $1$ if its argument is true and $0$ otherwise. The definition of the adjusted $p$-value can then be rewritten as:\n$$\np_j^{\\text{adj}} = \\mathbb{E}[\\mathbb{I}(M \\ge t_j) \\mid H_0^C]\n$$\nwhere the expectation $\\mathbb{E}[\\cdot]$ is taken over the distribution of $M$ under the complete null hypothesis.\n\nIn practice, the true null distribution of $M$ is often unknown. The problem states we are to use a permutation-based approach to approximate this distribution. By performing $B$ permutations of the sample labels and re-computing the maximum test statistic for each permutation, we obtain a set of $B$ values, $\\{M^{(1)}, M^{(2)}, \\dots, M^{(B)}\\}$. Under the assumptions of the complete null and exchangeability, each $M^{(b)}$ is a draw from the true null distribution of $M$. The problem states that these are equally likely.\n\nThe principle of Monte Carlo estimation allows us to approximate an expectation by the sample mean of a function of random draws from the distribution. Therefore, we can estimate the expectation $\\mathbb{E}[\\mathbb{I}(M \\ge t_j) \\mid H_0^C]$ by taking the average of the indicator function evaluated over our $B$ permutation samples. Let $\\hat{p}_j^{\\text{adj}}$ be the estimator for $p_j^{\\text{adj}}$.\n$$\n\\hat{p}_j^{\\text{adj}} = \\frac{1}{B} \\sum_{b=1}^{B} \\mathbb{I}(M^{(b)} \\ge t_j)\n$$\nThe summation term, $\\sum_{b=1}^{B} \\mathbb{I}(M^{(b)} \\ge t_j)$, is precisely the count of the number of permutation maxima $M^{(b)}$ that are greater than or equal to the observed test statistic $t_j$. The instruction to handle ties inclusively (\"at least as extreme\") is naturally captured by the greater-than-or-equal-to operator, $\\ge$.\n\nThus, the final computable estimator for the adjusted $p$-value is:\n$$\n\\hat{p}_j^{\\text{adj}} = \\frac{\\text{Number of } M^{(b)} \\text{ such that } M^{(b)} \\ge t_j}{B}\n$$\nThis formula provides a direct, non-parametric estimate of the adjusted $p$-value based on the empirical distribution of the maximum statistic obtained from permutations. The values are decimals in the range $[0, 1]$, as required.\n\n### Part 2: Algorithm and Application\n\nThe algorithm to compute the adjusted $p$-values for a given test case follows directly from the derived estimator.\n\nFor each test case, we are given:\n- The number of tests, $m$.\n- A vector of observed test statistics, $t = (t_1, t_2, \\dots, t_m)$.\n- The number of permutations, $B$.\n- A vector of permutation maxima, $M_{\\text{perm}} = (M^{(1)}, M^{(2)}, \\dots, M^{(B)})$.\n\nThe algorithm is as follows:\n1. Initialize an empty list, `p_adjusted`, to store the results for the $m$ tests.\n2. For each observed statistic $t_j$ where $j$ ranges from $1$ to $m$:\n    a. Initialize a counter, `count_ge`, to $0$.\n    b. Iterate through each permutation maximum $M^{(b)}$ in the vector $M_{\\text{perm}}$, where $b$ ranges from $1$ to $B$.\n    c. In each iteration, compare $M^{(b)}$ with $t_j$. If $M^{(b)} \\ge t_j$, increment `count_ge` by $1$.\n    d. After iterating through all $B$ permutation maxima, calculate the adjusted $p$-value for test $j$ as $\\hat{p}_j^{\\text{adj}} = \\frac{\\text{count\\_ge}}{B}$.\n    e. Append $\\hat{p}_j^{\\text{adj}}$ to the `p_adjusted` list.\n3. After processing all $m$ statistics, the list `p_adjusted` contains the required set of adjusted $p$-values for the test case.\n\nThis procedure is repeated for each of the four test cases provided in the problem statement. The implementation will use numerical libraries for efficient vectorized computation of the comparison and counting steps, which is computationally equivalent to the described iterative algorithm.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes adjusted p-values using a max-statistic permutation approach\n    for a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: ((t_1..t_m), (M_1..M_B))\n    test_cases = [\n        # Test case 1 (general case)\n        (\n            (2.1, 1.5, 3.0, 0.8),\n            (1.9, 2.2, 3.1, 2.8, 2.4, 1.7, 2.0, 3.0, 2.6, 2.3)\n        ),\n        # Test case 2 (tie-handling)\n        (\n            (2.3, 2.0, 3.0),\n            (2.3, 2.3, 2.3)\n        ),\n        # Test case 3 (boundary B=1)\n        (\n            (1.0, 2.5, 3.0),\n            (2.5,)\n        ),\n        # Test case 4 (negative values and edge extremes)\n        (\n            (-1.0, -0.3, 0.0, 0.5),\n            (-0.5, -0.2, 0.0, -0.1)\n        )\n    ]\n\n    all_results = []\n    for t_obs_tuple, M_perm_tuple in test_cases:\n        # Convert tuples to numpy arrays for efficient computation\n        t_obs = np.array(t_obs_tuple)\n        M_perm = np.array(M_perm_tuple)\n        \n        # B is the number of permutation maxima\n        B = float(len(M_perm))\n\n        # Ensure B is not zero to avoid division by zero, though problem constraints\n        # imply B >= 1.\n        if B == 0:\n            # According to the formula, if B=0, the p-value is undefined.\n            # We can represent this as NaN or handle as an error.\n            # Assuming B>=1 based on the problem. \n            # For robustness, we could set p-values to 1.0 or NaN.\n            # Here we just proceed, as problem data has B >= 1.\n            pass\n\n        # Reshape t_obs for broadcasting.\n        # t_obs becomes a column vector of shape (m, 1).\n        # M_perm is a row vector of shape (1, B).\n        # The comparison M_perm >= t_obs[:, np.newaxis] results in a\n        # boolean matrix of shape (m, B). Each row corresponds to a t_j\n        # and contains the comparison result against all M^(b).\n        # The condition is M^(b) >= t_j, which means we compare the row vector M_perm\n        # against the column vector t_obs.\n        \n        # t_obs is (m,), M_perm is (B,). Reshape t_obs to (m, 1).\n        # The comparison M_perm (B,) >= t_obs[:, np.newaxis] (m, 1) broadcasts\n        # to a (m, B) boolean array.\n        comparison_matrix = M_perm >= t_obs[:, np.newaxis]\n        \n        # Sum the boolean values (True=1, False=0) along axis=1 (across permutations)\n        # to get the count of M^(b) >= t_j for each t_j.\n        counts = np.sum(comparison_matrix, axis=1)\n        \n        # Calculate the adjusted p-values by dividing counts by B.\n        adj_p_values = counts / B\n        \n        all_results.append(adj_p_values.tolist())\n\n    # Format the final output string exactly as specified in the problem.\n    # Example: [[a,b,c],[d,e],[f,g,h,i],[j,k]]\n    # 1. Convert each inner list of floats to a string of comma-separated values.\n    # 2. Enclose each of these strings in square brackets.\n    # 3. Join all these bracketed strings with commas.\n    # 4. Enclose the final joined string in square brackets.\n    \n    inner_strings = []\n    for res_list in all_results:\n        inner_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    final_output_string = f\"[{','.join(inner_strings)}]\"\n    \n    # The final print statement must produce only the single-line format.\n    print(final_output_string)\n\nsolve()\n```", "id": "4930335"}]}