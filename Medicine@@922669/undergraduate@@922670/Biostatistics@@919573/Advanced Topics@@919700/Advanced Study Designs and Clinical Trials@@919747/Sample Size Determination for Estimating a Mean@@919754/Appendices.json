{"hands_on_practices": [{"introduction": "Understanding the foundations of sample size formulas is key to applying them wisely. This first exercise guides you through deriving the sample size required to estimate a population proportion—a special case of a mean—starting from the Central Limit Theorem. By tackling this problem [@problem_id:4950125], you will not only solidify your theoretical understanding but also learn the practical difference between a conservative \"worst-case\" design and a more efficient design informed by prior knowledge of the likely outcome.", "problem": "A clinical epidemiology team plans to estimate the population mean of a binary outcome, coded as $a=0$ for absence and $b=1$ for presence of a pathogen-specific antibody. Let the underlying population mean be $p=\\mathbb{E}[X]$, where $X \\in \\{0,1\\}$. The team will use a two-sided normal-approximation confidence interval for the mean based on the sample mean $\\bar{X}$, with confidence level $1-\\alpha$ (take $1-\\alpha=0.95$ so $\\alpha=0.05$) and target half-width $d$ (take $d=0.03$). Assume independent and identically distributed sampling and that the finite population correction is negligible.\n\nStarting from the Central Limit Theorem (CLT) and the definition of a two-sided confidence interval formed by multiplying the standard error by the appropriate quantile of the standard normal distribution, derive the generic sample size requirement $n$ that guarantees the interval half-width does not exceed $d$.\n\nThen, specialize your derivation to the binary case where the variance is $\\sigma^{2}=p(1-p)$, and:\n\n- Derive the worst-case sample size $n_{\\text{worst}}$ using only the inequality $\\sigma^{2}\\leq \\frac{1}{4}$ that holds for any binary $X \\in \\{0,1\\}$.\n- Derive the prevalence-informed sample size $n(p)$ when an anticipated prevalence $p$ is available, using $\\sigma^{2}=p(1-p)$.\n- Derive, in closed form, the multiplicative reduction factor $R(p)=\\frac{n(p)}{n_{\\text{worst}}}$ that quantifies how much using $p$ reduces the required sample size relative to the worst case.\n\nExpress your final answers as closed-form analytic expressions in terms of $z_{\\alpha/2}$, $d$, and $p$, where $z_{\\alpha/2}$ denotes the upper $\\alpha/2$ quantile of the standard normal distribution. Provide your final answers as a single row matrix containing $n_{\\text{worst}}$, $n(p)$, and $R(p)$. No numerical evaluation is required, and no rounding is necessary. Percentages should be expressed as decimals (e.g., $0.95$ for $95$ percent).", "solution": "The problem is subjected to validation.\n\n### Step 1: Extract Givens\n- **Outcome:** Binary, coded as $a=0$ for absence and $b=1$ for presence of a pathogen-specific antibody.\n- **Random Variable:** $X \\in \\{0, 1\\}$.\n- **Population Mean:** $p = \\mathbb{E}[X]$.\n- **Confidence Interval:** Two-sided normal-approximation for the mean based on the sample mean $\\bar{X}$.\n- **Confidence Level:** $1-\\alpha = 0.95$ (so $\\alpha = 0.05$).\n- **Target Half-width (Margin of Error):** $d = 0.03$.\n- **Sampling Assumption:** Independent and identically distributed (i.i.d.).\n- **Finite Population Correction:** Negligible.\n- **Variance for Binary Case:** $\\sigma^2 = p(1-p)$.\n- **Worst-case Variance Constraint:** $\\sigma^2 \\le \\frac{1}{4}$.\n- **Quantile Definition:** $z_{\\alpha/2}$ is the upper $\\alpha/2$ quantile of the standard normal distribution.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is reviewed against the validation criteria.\n- **Scientifically Grounded:** The problem is a standard exercise in biostatistical sample size calculation for a proportion. It correctly applies the Central Limit Theorem (CLT) for the normal approximation to the binomial distribution, the standard formula for the variance of a Bernoulli random variable ($\\sigma^2 = p(1-p)$), and the construction of a confidence interval. All premises are well-established in statistical theory.\n- **Well-Posed:** The problem is clearly stated, providing all necessary information to derive the required quantities ($n_{\\text{worst}}$, $n(p)$, and $R(p)$). The objectives are specific and lead to unique analytical solutions.\n- **Objective:** The language is formal, precise, and devoid of subjective or ambiguous terminology.\n- **Other Flaws:** The problem does not violate any of the invalidity criteria. It is complete, consistent, realistic within its domain, and requires substantive derivation from first principles as outlined.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full, reasoned solution will be provided.\n\n### Derivation\nThe derivation begins from the Central Limit Theorem (CLT), as instructed. Let $X_1, X_2, \\dots, X_n$ be a sample of $n$ independent and identically distributed random variables from a population with mean $\\mu$ and finite variance $\\sigma^2$. The CLT states that for a sufficiently large sample size $n$, the distribution of the sample mean $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$ is approximately normal:\n$$\n\\bar{X} \\approx \\mathcal{N}\\left(\\mu, \\frac{\\sigma^2}{n}\\right)\n$$\nStandardizing the sample mean gives a random variable that approximates the standard normal distribution, $\\mathcal{N}(0, 1)$:\n$$\nZ = \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\approx \\mathcal{N}(0, 1)\n$$\nA two-sided confidence interval for the population mean $\\mu$ with a confidence level of $1-\\alpha$ is constructed from the pivotal quantity $Z$. Let $z_{\\alpha/2}$ be the upper $\\alpha/2$ quantile of the standard normal distribution, such that $P(Z > z_{\\alpha/2}) = \\alpha/2$. By symmetry, $P(-z_{\\alpha/2}  Z  z_{\\alpha/2}) = 1-\\alpha$. Substituting the expression for $Z$ yields:\n$$\nP\\left(-z_{\\alpha/2}  \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}  z_{\\alpha/2}\\right) \\approx 1-\\alpha\n$$\nThis inequality can be rearranged to isolate $\\mu$:\n$$\nP\\left(\\bar{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}  \\mu  \\bar{X} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\right) \\approx 1-\\alpha\n$$\nThe resulting $(1-\\alpha)$ confidence interval for $\\mu$ is $\\left[\\bar{X} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}, \\bar{X} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\\right]$. The half-width of this interval, also known as the margin of error, is denoted by $d$.\n$$\nd = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n$$\nTo find the required sample size $n$ that achieves a target half-width $d$, we solve this equation for $n$:\n$$\n\\sqrt{n} = \\frac{z_{\\alpha/2} \\sigma}{d}\n$$\n$$\nn = \\left(\\frac{z_{\\alpha/2} \\sigma}{d}\\right)^2 = \\frac{z_{\\alpha/2}^2 \\sigma^2}{d^2}\n$$\nThis is the generic formula for the sample size. In practice, the population variance $\\sigma^2$ is typically unknown. For a binary outcome where $X \\in \\{0, 1\\}$, the mean is the population proportion $p = \\mathbb{E}[X]$, and the variance is $\\sigma^2 = p(1-p)$.\n\n**1. Worst-Case Sample Size ($n_{\\text{worst}}$)**\nTo guarantee a half-width of at most $d$ without prior knowledge of $p$, we must use the maximum possible value for the variance $\\sigma^2 = p(1-p)$. The function $f(p) = p(1-p)$ is a quadratic in $p$ that opens downward, with its maximum at $p = \\frac{1}{2}$. The maximum value is:\n$$\n\\sigma^2_{\\text{max}} = f\\left(\\frac{1}{2}\\right) = \\frac{1}{2}\\left(1-\\frac{1}{2}\\right) = \\frac{1}{4}\n$$\nSubstituting this maximum variance into the sample size formula yields the worst-case sample size, $n_{\\text{worst}}$:\n$$\nn_{\\text{worst}} = \\frac{z_{\\alpha/2}^2 \\sigma^2_{\\text{max}}}{d^2} = \\frac{z_{\\alpha/2}^2 (1/4)}{d^2} = \\frac{z_{\\alpha/2}^2}{4d^2}\n$$\n\n**2. Prevalence-Informed Sample Size ($n(p)$)**\nIf an anticipated prevalence (proportion) $p$ is available from prior studies or expert opinion, we can use it to obtain a more precise estimate of the required sample size. We substitute $\\sigma^2 = p(1-p)$ directly into the general formula:\n$$\nn(p) = \\frac{z_{\\alpha/2}^2 p(1-p)}{d^2}\n$$\n\n**3. Multiplicative Reduction Factor ($R(p)$)**\nThe reduction factor $R(p)$ quantifies the efficiency gained by using an anticipated prevalence $p$ compared to the conservative worst-case scenario. It is the ratio of the prevalence-informed sample size to the worst-case sample size:\n$$\nR(p) = \\frac{n(p)}{n_{\\text{worst}}} = \\frac{\\frac{z_{\\alpha/2}^2 p(1-p)}{d^2}}{\\frac{z_{\\alpha/2}^2}{4d^2}}\n$$\nThe terms $z_{\\alpha/2}^2$ and $d^2$ cancel, simplifying the expression to:\n$$\nR(p) = \\frac{p(1-p)}{1/4} = 4p(1-p)\n$$\nThis factor shows that the required sample size is largest when $p=0.5$ (where $R(0.5) = 4(0.5)(0.5) = 1$) and decreases as $p$ approaches $0$ or $1$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{z_{\\alpha/2}^2}{4d^2}  \\frac{z_{\\alpha/2}^2 p(1-p)}{d^2}  4p(1-p)\n\\end{pmatrix}\n}\n$$", "id": "4950125"}, {"introduction": "Biomedical data are often skewed and require transformation, such as a logarithm, to better fit the assumptions of statistical models. This practice [@problem_id:4950147] explores the crucial and often misunderstood implications of such transformations on sample size planning. You will apply the delta method to link the desired precision on the original measurement scale to the corresponding precision on the log-transformed scale, revealing why a smaller variance on the transformed scale does not automatically lead to a smaller required sample size.", "problem": "A clinical laboratory seeks to estimate the population mean $\\mu$ of a strictly positive biomarker $X$ (units: $\\mathrm{ng/mL}$). A pilot study suggests a working mean $\\mu \\approx 50$ and a population standard deviation $\\sigma \\approx 20$. The design goal is to construct a two-sided $95\\%$ confidence interval (CI) for $\\mu$ whose half-width on the original scale is $w = 5$. An alternative planning approach is to work on a monotone differentiable transformation $g$, specifically $g(x) = \\log x$ (natural logarithm), with the intention to target a half-width $w_g$ for the CI on the $g$-scale and then back-transform through $g^{-1}$ to a CI for $\\mu$. The laboratory uses the Central Limit Theorem (CLT) for the sampling distribution of the sample mean and first-order Taylor approximations (the delta method) to relate widths between the original and transformed scales. Under these assumptions, choose the option that correctly states how to set $w_g$ so that the back-transformed CI has half-width $w$ on the original scale, and what this implies for the required sample size when compared to designing directly on the original scale. Where appropriate, numerically evaluate using $z_{0.975} = 1.96$, $\\mu = 50$, $\\sigma = 20$, and $w = 5$.\n\nA. The correct mapping is $w_g = \\lvert g'(\\mu) \\rvert \\, w$. For $g(x) = \\log x$ and $\\mu = 50$, this gives $w_g = \\frac{1}{50} \\cdot 5 = 0.1$. With this mapping, planning on either scale yields the same required sample size, numerically $n \\approx \\left( \\frac{1.96 \\cdot 20}{5} \\right)^2 \\approx 61.47$, so rounding up gives $n = 62$.\n\nB. Because $g$ is monotone, one may set $w_g = w = 5$ on the $g$-scale and obtain the same required sample size as planning on the original scale.\n\nC. The correct mapping is $w_g = \\frac{w}{\\lvert g'(\\mu) \\rvert}$, so with $g(x) = \\log x$ and $\\mu = 50$ one has $w_g = 250$, which implies a much smaller required sample size on the $g$-scale than on the original scale.\n\nD. Even if $w_g$ is set by the delta method, planning on the $\\log$-scale necessarily reduces the required sample size because $\\operatorname{Var}(\\log X)$ is smaller than $\\operatorname{Var}(X)$ for $X0$.\n\nE. If one sets $w_g = 0.1$ on the $\\log$-scale, the required sample size is $n \\approx \\left( \\frac{1.96 \\cdot 20}{0.1} \\right)^2 = 153{,}664$, which is far larger than on the original scale; therefore, planning on the transformed scale inflates $n$ relative to the original scale.", "solution": "The problem statement is evaluated for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n- Parameter of interest: Population mean $\\mu$ of a biomarker $X$.\n- Biomarker property: $X  0$.\n- Units of $X$: $\\mathrm{ng/mL}$.\n- Pilot study estimates: a working mean $\\mu \\approx 50$ and a population standard deviation $\\sigma \\approx 20$.\n- Design goal (original scale): Construct a two-sided $95\\%$ confidence interval (CI) for $\\mu$.\n- Target half-width on original scale: $w = 5$.\n- Alternative approach: Use a monotone differentiable transformation $g(x) = \\log x$ (natural logarithm).\n- Goal of alternative approach: Target a half-width $w_g$ for the CI on the $g$-scale, then back-transform to obtain a CI for $\\mu$ with half-width $w$ on the original scale.\n- Methodological assumptions: Central Limit Theorem (CLT) and first-order Taylor approximations (the delta method).\n- Constants for numerical evaluation: $z_{0.975} = 1.96$, $\\mu = 50$, $\\sigma = 20$, $w = 5$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in standard biostatistical theory, specifically sample size estimation for a mean, confidence intervals, the Central Limit Theorem, and the delta method for variance and interval transformation. The context is a common application in clinical laboratory science. The problem is well-posed, providing all necessary information ($\\mu$, $\\sigma$, confidence level, target width, and transformation function) to determine the relationship between the two design approaches and to calculate the required sample size. The language is objective and precise. The numerical values are consistent and plausible. For example, a mean of $\\mu=50$ and a standard deviation of $\\sigma=20$ is compatible with the biomarker being strictly positive, as the mean is $2.5$ standard deviations away from $0$. The problem is not trivial, as it requires a careful application of the delta method to relate CI widths across different scales.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. A solution will be derived.\n\n### Derivation\nThe problem requires comparing two approaches for sample size calculation.\n\n**Approach 1: Planning on the Original Scale**\nLet $\\bar{X}$ be the sample mean from a sample of size $n$. By the Central Limit Theorem (CLT), the sampling distribution of $\\bar{X}$ is approximately normal for large $n$: $\\bar{X} \\sim N(\\mu, \\sigma^2/n)$.\nA two-sided $100(1-\\alpha)\\%$ confidence interval for $\\mu$ is given by:\n$$ \\bar{X} \\pm z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} $$\nThe half-width of this confidence interval is $w = z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}$.\nTo achieve a target half-width $w$, the required sample size $n$ is:\n$$ n = \\left( \\frac{z_{1-\\alpha/2} \\sigma}{w} \\right)^2 $$\nUsing the provided values: $1-\\alpha = 0.95$, so $\\alpha = 0.05$ and $z_{1-\\alpha/2} = z_{0.975} = 1.96$. We have $\\sigma = 20$ and $w = 5$.\n$$ n_{\\text{orig}} = \\left( \\frac{1.96 \\cdot 20}{5} \\right)^2 = \\left( \\frac{39.2}{5} \\right)^2 = (7.84)^2 = 61.4656 $$\nSince the sample size must be an integer, we round up to $n_{\\text{orig}} = 62$.\n\n**Approach 2: Planning on the Transformed Scale**\nLet $Y = g(X) = \\log X$. We want to find a CI for $\\mu_g = E[Y] \\approx g(\\mu)=\\log \\mu$.\nFirst, we find the variance of $Y$ using the first-order Taylor approximation (delta method).\nLet $\\sigma_g^2 = \\operatorname{Var}(Y)$. The delta method approximates this as:\n$$ \\sigma_g^2 \\approx [g'(\\mu)]^2 \\operatorname{Var}(X) = [g'(\\mu)]^2 \\sigma^2 $$\nFor $g(x) = \\log x$, the derivative is $g'(x) = 1/x$. At $x=\\mu$, $g'(\\mu) = 1/\\mu$.\n$$ \\sigma_g^2 \\approx \\left(\\frac{1}{\\mu}\\right)^2 \\sigma^2 = \\left(\\frac{\\sigma}{\\mu}\\right)^2 $$\nThe standard deviation on the log scale is $\\sigma_g \\approx \\frac{\\sigma}{\\mu}$.\n\nNext, we relate the half-width $w$ on the original scale to the half-width $w_g$ on the transformed scale, as specified, using the delta method. A CI for $\\mu_g = \\log \\mu$ can be used to construct a CI for $\\mu$. A symmetric a CI for $\\mu_g$ is of the form $[\\hat{\\mu}_g - w_g, \\hat{\\mu}_g + w_g]$. Back-transforming via $g^{-1}(y) = e^y$ yields an asymmetric CI for $\\mu$: $[e^{\\hat{\\mu}_g - w_g}, e^{\\hat{\\mu}_g + w_g}]$.\nThe problem asks for the half-width of this back-transformed interval to be $w$. For an asymmetric interval, \"half-width\" can be ambiguous. The problem directs us to use the delta method to relate the widths. This corresponds to a linearization. A CI for $\\mu$ of the form $[\\bar{X}-w, \\bar{X}+w]$ is mapped to a CI for $g(\\mu)$ with endpoints $g(\\bar{X} \\pm w)$. Using a first-order Taylor expansion of $g(x)$ around $\\bar{X}$:\n$$ g(\\bar{X} \\pm w) \\approx g(\\bar{X}) \\pm w \\cdot g'(\\bar{X}) $$\nThe half-width on the transformed scale is therefore $w_g \\approx w \\cdot |g'(\\bar{X})|$. Since $\\bar{X}$ is an estimator for $\\mu$, we use the approximation at $\\mu$:\n$$ w_g \\approx w \\cdot |g'(\\mu)| $$\nFor $g(x) = \\log x$, this becomes $w_g = w \\cdot |1/\\mu| = w/\\mu$ (since $\\mu0$).\n\nNow, we calculate the sample size required on the transformed scale, $n_{\\text{trans}}$. The formula is analogous to the one on the original scale, but using the parameters for the transformed variable:\n$$ n_{\\text{trans}} = \\left( \\frac{z_{1-\\alpha/2} \\sigma_g}{w_g} \\right)^2 $$\nSubstitute the expressions for $\\sigma_g$ and $w_g$:\n$$ n_{\\text{trans}} = \\left( \\frac{z_{1-\\alpha/2} (\\sigma/\\mu)}{w/\\mu} \\right)^2 = \\left( \\frac{z_{1-\\alpha/2} \\sigma}{w} \\frac{1/\\mu}{1/\\mu} \\right)^2 = \\left( \\frac{z_{1-\\alpha/2} \\sigma}{w} \\right)^2 $$\nThis is identical to the formula for $n_{\\text{orig}}$.\n$$ n_{\\text{trans}} = n_{\\text{orig}} $$\nThus, under the delta method approximation, planning on the original scale or the log-scale (with correctly mapped width) yields the same required sample size.\n\nNumerically:\n$\\mu = 50$, $\\sigma = 20$, $w = 5$.\n$w_g = w/\\mu = 5/50 = 0.1$.\n$\\sigma_g = \\sigma/\\mu = 20/50 = 0.4$.\n$n_{\\text{trans}} = \\left( \\frac{1.96 \\cdot 0.4}{0.1} \\right)^2 = (1.96 \\cdot 4)^2 = (7.84)^2 = 61.4656$.\nRounding up, $n_{\\text{trans}} = 62$. This confirms that $n_{\\text{trans}} = n_{\\text{orig}}$.\n\n### Option-by-Option Analysis\n\n**A. The correct mapping is $w_g = \\lvert g'(\\mu) \\rvert \\, w$. For $g(x) = \\log x$ and $\\mu = 50$, this gives $w_g = \\frac{1}{50} \\cdot 5 = 0.1$. With this mapping, planning on either scale yields the same required sample size, numerically $n \\approx \\left( \\frac{1.96 \\cdot 20}{5} \\right)^2 \\approx 61.47$, so rounding up gives $n = 62$.**\n- **Justification**: This statement correctly identifies the relationship $w_g = |g'(\\mu)|w$ as derived from the delta method. It correctly calculates $g'(\\mu) = 1/50$ and subsequently $w_g = 5/50 = 0.1$. It correctly concludes that this mapping leads to the same sample size on both scales. The numerical calculation for the sample size is also correct: $n = (1.96 \\cdot 20/5)^2 \\approx 61.47$, which rounds up to $62$. All parts of this statement are consistent with our derivation.\n- **Verdict**: Correct.\n\n**B. Because $g$ is monotone, one may set $w_g = w = 5$ on the $g$-scale and obtain the same required sample size as planning on the original scale.**\n- **Justification**: This statement is incorrect. The half-width on the original scale, $w=5$, has units of $\\mathrm{ng/mL}$, while the half-width on the log scale, $w_g$, is unitless. Equating them is physically and mathematically meaningless. Monotonicity ensures that the CI endpoints can be back-transformed, but it does not justify equating the widths. Setting $w_g = 5$ would correspond to an astronomically large and imprecise CI on the original scale.\n- **Verdict**: Incorrect.\n\n**C. The correct mapping is $w_g = \\frac{w}{\\lvert g'(\\mu) \\rvert}$, so with $g(x) = \\log x$ and $\\mu = 50$ one has $w_g = 250$, which implies a much smaller required sample size on the $g$-scale than on the original scale.**\n- **Justification**: The proposed mapping $w_g = w/|g'(\\mu)|$ is the inverse of the correct relationship derived from the delta method. Consequently, the calculation $w_g = 5 / (1/50) = 250$ is based on a false premise. A larger target width $w_g$ would indeed lead to a smaller sample size, but the premise for setting $w_g = 250$ is fundamentally wrong.\n- **Verdict**: Incorrect.\n\n**D. Even if $w_g$ is set by the delta method, planning on the $\\log$-scale necessarily reduces the required sample size because $\\operatorname{Var}(\\log X)$ is smaller than $\\operatorname{Var}(X)$ for $X0$.**\n- **Justification**: This statement makes a fallacious argument. While it is true that $\\operatorname{Var}(\\log X) \\approx (\\sigma/\\mu)^2 = (20/50)^2 = 0.16$ is much smaller than $\\operatorname{Var}(X) = \\sigma^2 = 400$, the sample size formula depends on the ratio of the standard deviation to the half-width, i.e., $\\sigma_g/w_g$. As shown in the derivation, the delta method scales both $\\sigma_g$ and $w_g$ by the same factor $|g'(\\mu)| = 1/\\mu$ relative to their original-scale counterparts. This factor cancels out, making the required sample size identical. The premise that a smaller variance implies a smaller sample size is incomplete because it ignores the change in the target width.\n- **Verdict**: Incorrect.\n\n**E. If one sets $w_g = 0.1$ on the $\\log$-scale, the required sample size is $n \\approx \\left( \\frac{1.96 \\cdot 20}{0.1} \\right)^2 = 153{,}664$, which is far larger than on the original scale; therefore, planning on the transformed scale inflates $n$ relative to the original scale.**\n- **Justification**: This statement uses an incorrect formula for the sample size calculation on the transformed scale. The formula used, $n = (z \\cdot \\sigma / w_g)^2$, incorrectly mixes the standard deviation from the original scale ($\\sigma=20$) with the half-width from the transformed scale ($w_g=0.1$). The correct formula is $n_{\\text{trans}} = (z \\cdot \\sigma_g / w_g)^2$. Using the correct value $\\sigma_g \\approx \\sigma/\\mu = 0.4$, the sample size is $n_{\\text{trans}} = (1.96 \\cdot 0.4/0.1)^2 \\approx 62$. The calculation shown in the option is flawed, and its conclusion is false.\n- **Verdict**: Incorrect.", "answer": "$$\\boxed{A}$$", "id": "4950147"}, {"introduction": "Real-world study designs are often more complex than simple random sampling and are always constrained by a budget. This exercise [@problem_id:4950146] presents a realistic scenario involving two-stage cluster sampling, where you must determine the optimal number of clusters and individuals per cluster to minimize cost while achieving a specified precision. This problem will introduce you to cost-efficiency optimization, a critical skill for designing large-scale health studies.", "problem": "In a two-stage cluster sampling design to estimate the population mean systolic blood pressure, you plan to sample $k$ clinics (clusters) and $m$ patients per clinic, with all clinics having the same per-clinic sample size. Each clinic incurs a fixed overhead cost of $c_{0}$ dollars, and each patient incurs a marginal cost of $c_{1}$ dollars. From prior data, assume a random-effects model $Y_{ij} = \\mu + B_{i} + E_{ij}$, where $B_{i}$ are independent across clinics with mean $0$ and variance $\\sigma_{b}^{2}$, and $E_{ij}$ are independent within and across clinics with mean $0$ and variance $\\sigma_{w}^{2}$. Assume $B_{i}$ and $E_{ij}$ are mutually independent. You require that a two-sided $(1-\\alpha)$ Confidence Interval (CI) for the population mean has half-width $w$ expressed in $\\mathrm{mmHg}$. Use the large-sample normal approximation.\n\nGiven the scientifically plausible values $\\sigma_{b}^{2} = 9$ $\\mathrm{mmHg}^{2}$, $\\sigma_{w}^{2} = 36$ $\\mathrm{mmHg}^{2}$, $c_{0} = 400$ dollars, and $c_{1} = 4$ dollars, do the following:\n\n- Starting from the variance properties of independent sums and averages under the stated random-effects model, derive the sampling variance of the overall mean across all sampled units when $k$ clinics are sampled with $m$ patients per clinic (equal $m$ in each clinic).\n- Connect this sampling variance to the CI half-width $w$ via the large-sample normal approximation, and formulate the constrained optimization problem that minimizes the total cost subject to meeting the half-width requirement.\n- Solve this optimization problem for the continuous-optimal $k^{\\star}$ and $m^{\\star}$ (ignore integer constraints), and report your final expressions in closed form in terms of $z_{1-\\alpha/2}$ and $w$ where appropriate.\n\nState your final answer as a row matrix $\\left(k^{\\star},\\,m^{\\star}\\right)$, and express $w$ in $\\mathrm{mmHg}$. No rounding is required.", "solution": "The problem asks for the optimal allocation of sampling units in a two-stage cluster design to minimize total cost subject to a precision constraint on the estimate of the population mean. We are given a random-effects model, cost parameters, and variance components. We will solve this by first deriving the variance of the sample mean, formulating the constrained optimization problem, and then solving it using the method of Lagrange multipliers for continuous variables.\n\nThe statistical model for the systolic blood pressure $Y_{ij}$ of the $j$-th patient in the $i$-th clinic is given by:\n$$Y_{ij} = \\mu + B_i + E_{ij}$$\nwhere $\\mu$ is the overall population mean, $B_i$ is the random effect for clinic $i$ with $E[B_i] = 0$ and $\\text{Var}(B_i) = \\sigma_b^2$, and $E_{ij}$ is the random error for patient $j$ in clinic $i$ with $E[E_{ij}] = 0$ and $\\text{Var}(E_{ij}) = \\sigma_w^2$. All $B_i$ and $E_{ij}$ are mutually independent.\n\nThe estimator for the population mean $\\mu$ is the grand mean of all observations, $\\bar{Y}$, from a sample of $k$ clinics and $m$ patients per clinic.\n$$\\bar{Y} = \\frac{1}{km} \\sum_{i=1}^{k} \\sum_{j=1}^{m} Y_{ij}$$\nSubstituting the model into the expression for $\\bar{Y}$:\n$$\\bar{Y} = \\frac{1}{km} \\sum_{i=1}^{k} \\sum_{j=1}^{m} (\\mu + B_i + E_{ij}) = \\mu + \\frac{1}{k} \\sum_{i=1}^{k} B_i + \\frac{1}{km} \\sum_{i=1}^{k} \\sum_{j=1}^{m} E_{ij}$$\nThe estimator is unbiased since $E[B_i]=0$ and $E[E_{ij}]=0$.\n\nThe sampling variance of $\\bar{Y}$, denoted $\\text{Var}(\\bar{Y})$, is derived using the properties of variances of sums of independent random variables:\n$$\\text{Var}(\\bar{Y}) = \\text{Var}\\left(\\frac{1}{k} \\sum_{i=1}^{k} B_i\\right) + \\text{Var}\\left(\\frac{1}{km} \\sum_{i=1}^{k} \\sum_{j=1}^{m} E_{ij}\\right)$$\n$$\\text{Var}(\\bar{Y}) = \\frac{1}{k^2} \\sum_{i=1}^{k} \\text{Var}(B_i) + \\frac{1}{(km)^2} \\sum_{i=1}^{k} \\sum_{j=1}^{m} \\text{Var}(E_{ij})$$\nSubstituting the given variances, $\\text{Var}(B_i) = \\sigma_b^2$ and $\\text{Var}(E_{ij}) = \\sigma_w^2$:\n$$\\text{Var}(\\bar{Y}) = \\frac{1}{k^2} (k \\sigma_b^2) + \\frac{1}{(km)^2} (km \\sigma_w^2) = \\frac{\\sigma_b^2}{k} + \\frac{\\sigma_w^2}{km}$$\nThis is the sampling variance of the overall mean.\n\nNext, we connect this variance to the confidence interval (CI) half-width, $w$. Using the large-sample normal approximation, a two-sided $(1-\\alpha)$ CI for $\\mu$ is given by $\\bar{Y} \\pm z_{1-\\alpha/2} \\sqrt{\\text{Var}(\\bar{Y})}$. The half-width $w$ is therefore:\n$$w = z_{1-\\alpha/2} \\sqrt{\\frac{\\sigma_b^2}{k} + \\frac{\\sigma_w^2}{km}}$$\nSquaring both sides gives the precision constraint:\n$$\\frac{w^2}{z_{1-\\alpha/2}^2} = \\frac{\\sigma_b^2}{k} + \\frac{\\sigma_w^2}{km}$$\n\nThe total cost of the study, $C$, is a function of $k$ and $m$:\n$$C(k,m) = c_0 k + c_1 km$$\nThe problem is to minimize $C(k,m)$ subject to the precision constraint. We formulate this as a constrained optimization problem. For convenience, let $V_0 = \\frac{w^2}{z_{1-\\alpha/2}^2}$, which is the target variance of the estimator $\\bar{Y}$.\nMinimize: $C(k,m) = c_0 k + c_1 km$\nSubject to: $g(k,m) = \\frac{\\sigma_b^2}{k} + \\frac{\\sigma_w^2}{km} - V_0 = 0$\n\nWe use the method of Lagrange multipliers, treating $k$ and $m$ as continuous variables. The Lagrangian function $\\mathcal{L}$ is:\n$$\\mathcal{L}(k,m,\\lambda) = C(k,m) + \\lambda g(k,m) = c_0 k + c_1 km + \\lambda \\left( \\frac{\\sigma_b^2}{k} + \\frac{\\sigma_w^2}{km} - V_0 \\right)$$\nWe find the critical points by setting the partial derivatives with respect to $k$, $m$, and $\\lambda$ to zero.\n$$\\frac{\\partial \\mathcal{L}}{\\partial k} = c_0 + c_1 m - \\lambda \\left( \\frac{\\sigma_b^2}{k^2} + \\frac{\\sigma_w^2}{k^2 m} \\right) = 0 \\quad (1)$$\n$$\\frac{\\partial \\mathcal{L}}{\\partial m} = c_1 k - \\lambda \\frac{\\sigma_w^2}{k m^2} = 0 \\quad (2)$$\nFrom equation $(2)$, since $c_1, k, \\sigma_w^2 > 0$:\n$$c_1 k = \\frac{\\lambda \\sigma_w^2}{k m^2} \\implies \\lambda = \\frac{c_1 k^2 m^2}{\\sigma_w^2}$$\nSubstitute this expression for $\\lambda$ into equation $(1)$:\n$$c_0 + c_1 m = \\frac{c_1 k^2 m^2}{\\sigma_w^2} \\left( \\frac{\\sigma_b^2}{k^2} + \\frac{\\sigma_w^2}{k^2 m} \\right) = \\frac{c_1 m^2}{\\sigma_w^2} \\left( \\sigma_b^2 + \\frac{\\sigma_w^2}{m} \\right)$$\n$$c_0 + c_1 m = \\frac{c_1 \\sigma_b^2}{\\sigma_w^2} m^2 + c_1 m$$\n$$c_0 = \\frac{c_1 \\sigma_b^2}{\\sigma_w^2} m^2$$\nSolving for $m$ gives the optimal per-clinic sample size, $m^\\star$:\n$$m^{\\star 2} = \\frac{c_0 \\sigma_w^2}{c_1 \\sigma_b^2} \\implies m^\\star = \\sqrt{\\frac{c_0 \\sigma_w^2}{c_1 \\sigma_b^2}} = \\frac{\\sigma_w}{\\sigma_b} \\sqrt{\\frac{c_0}{c_1}}$$\nTo find the optimal number of clinics, $k^\\star$, we substitute $m^\\star$ back into the constraint equation:\n$$\\frac{\\sigma_b^2}{k^\\star} + \\frac{\\sigma_w^2}{k^\\star m^\\star} = V_0 \\implies \\frac{1}{k^\\star} \\left(\\sigma_b^2 + \\frac{\\sigma_w^2}{m^\\star}\\right) = V_0$$\n$$k^\\star = \\frac{1}{V_0} \\left(\\sigma_b^2 + \\frac{\\sigma_w^2}{m^\\star}\\right) = \\frac{z_{1-\\alpha/2}^2}{w^2} \\left(\\sigma_b^2 + \\frac{\\sigma_w^2}{m^\\star}\\right)$$\nWe now substitute the provided numerical values: $\\sigma_b^2 = 9$, $\\sigma_w^2 = 36$, $c_0 = 400$, and $c_1 = 4$.\nFrom these, we have $\\sigma_b = \\sqrt{9} = 3$ and $\\sigma_w = \\sqrt{36} = 6$.\nFirst, we compute the numerical value for $m^\\star$:\n$$m^\\star = \\frac{6}{3} \\sqrt{\\frac{400}{4}} = 2 \\sqrt{100} = 2 \\times 10 = 20$$\nNext, we find the expression for $k^\\star$ by substituting the value of $m^\\star = 20$ into its formula:\n$$k^\\star = \\frac{z_{1-\\alpha/2}^2}{w^2} \\left(9 + \\frac{36}{20}\\right) = \\frac{z_{1-\\alpha/2}^2}{w^2} \\left(9 + \\frac{9}{5}\\right)$$\n$$k^\\star = \\frac{z_{1-\\alpha/2}^2}{w^2} \\left(\\frac{45}{5} + \\frac{9}{5}\\right) = \\frac{z_{1-\\alpha/2}^2}{w^2} \\left(\\frac{54}{5}\\right)$$\nThe final expressions for the continuous-optimal sample sizes are $m^\\star = 20$ and $k^\\star = \\frac{54}{5} \\frac{z_{1-\\alpha/2}^2}{w^2}$. The problem requires the answer as a row matrix $(k^\\star, m^\\star)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{54}{5} \\frac{z_{1-\\alpha/2}^2}{w^2}  20 \\end{pmatrix}}\n$$", "id": "4950146"}]}