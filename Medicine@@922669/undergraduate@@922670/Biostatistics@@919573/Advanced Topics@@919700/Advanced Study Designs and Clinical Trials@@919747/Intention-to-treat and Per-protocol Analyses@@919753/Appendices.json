{"hands_on_practices": [{"introduction": "To truly understand an estimator, we must grasp its statistical properties, particularly its precision or variance. This first exercise [@problem_id:4917211] grounds the Intention-to-Treat (ITT) principle in fundamental statistics by asking you to derive the variance of the standard difference-in-means estimator. Mastering this calculation is key to appreciating how we quantify uncertainty, construct confidence intervals, and perform hypothesis tests for an ITT effect.", "problem": "Consider a randomized clinical trial with $N$ participants. Each participant $i \\in \\{1,\\dots,N\\}$ is independently assigned to the treatment arm with probability $\\pi$ and to the control arm with probability $1 - \\pi$ via Bernoulli randomization, so the assignment indicator $A_i \\sim \\text{Bernoulli}(\\pi)$, independently across $i$. The outcome $Y_i$ is binary and is observed for all participants; define the arm-specific outcome distributions by $Y_i \\mid (A_i = 1) \\sim \\text{Bernoulli}(p_1)$ and $Y_i \\mid (A_i = 0) \\sim \\text{Bernoulli}(p_0)$, independently across $i$. Let $n_1 = \\sum_{i=1}^{N} \\mathbf{1}\\{A_i = 1\\}$ and $n_0 = \\sum_{i=1}^{N} \\mathbf{1}\\{A_i = 0\\}$ denote the realized sample sizes in the treatment and control arms, respectively, and assume $n_1 \\ge 1$ and $n_0 \\ge 1$.\n\nThe Intention-To-Treat (ITT) estimator is the difference in sample means by randomized assignment:\n$$\n\\hat{\\Delta}_{\\mathrm{ITT}} \\equiv \\bar{Y}_1 - \\bar{Y}_0,\n$$\nwhere\n$$\n\\bar{Y}_1 = \\frac{1}{n_1} \\sum_{i: A_i=1} Y_i\n\\quad \\text{and} \\quad\n\\bar{Y}_0 = \\frac{1}{n_0} \\sum_{i: A_i=0} Y_i.\n$$\nUsing only fundamental definitions and properties of expectation and variance for independent random variables, derive the variance of $\\hat{\\Delta}_{\\mathrm{ITT}}$ conditional on the realized arm sizes $n_1$ and $n_0$, and express your final answer as a closed-form function of the arm-specific variances and the sample sizes. For binary $Y$, recall that the variance in arm $a \\in \\{0,1\\}$ equals $p_a(1 - p_a)$.\n\nProvide the final expression for $\\operatorname{Var}(\\hat{\\Delta}_{\\mathrm{ITT}} \\mid n_1,n_0)$ in terms of $p_1$, $p_0$, $n_1$, and $n_0$. No numerical approximation is required; give a single exact analytic expression without rounding.", "solution": "The problem asks for the variance of the Intention-To-Treat (ITT) estimator, $\\hat{\\Delta}_{\\mathrm{ITT}}$, conditional on the realized sample sizes in the treatment and control arms, $n_1$ and $n_0$. The ITT estimator is defined as the difference in sample means:\n$$\n\\hat{\\Delta}_{\\mathrm{ITT}} = \\bar{Y}_1 - \\bar{Y}_0.\n$$\nWe seek to compute $\\operatorname{Var}(\\hat{\\Delta}_{\\mathrm{ITT}} \\mid n_1, n_0)$. Substituting the definition of $\\hat{\\Delta}_{\\mathrm{ITT}}$, we have:\n$$\n\\operatorname{Var}(\\hat{\\Delta}_{\\mathrm{ITT}} \\mid n_1, n_0) = \\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_0 \\mid n_1, n_0).\n$$\nThe problem states that participants are independently assigned to the arms and that outcomes $Y_i$ are independent across participants, conditional on their assignments. The sample mean for the treatment arm, $\\bar{Y}_1$, is calculated using only the outcomes of participants for whom $A_i=1$. Similarly, the sample mean for the control arm, $\\bar{Y}_0$, is calculated using only the outcomes of participants for whom $A_i=0$. Since these two sets of participants are disjoint and outcomes are independent across all participants, the random variables $\\bar{Y}_1$ and $\\bar{Y}_0$ are independent, conditional on the sets of participants in each arm. Conditioning on the sizes $n_1$ and $n_0$ is sufficient to maintain this independence because the within-arm outcomes are identically distributed.\n\nFor independent random variables, the variance of their difference is the sum of their variances. Therefore, we can write:\n$$\n\\operatorname{Var}(\\bar{Y}_1 - \\bar{Y}_0 \\mid n_1, n_0) = \\operatorname{Var}(\\bar{Y}_1 \\mid n_1, n_0) + \\operatorname{Var}(\\bar{Y}_0 \\mid n_1, n_0).\n$$\nThe variance of $\\bar{Y}_1$ depends only on the size of the treatment arm, $n_1$, and not on $n_0$. A similar argument holds for $\\bar{Y}_0$. Thus, we can simplify the expression to:\n$$\n\\operatorname{Var}(\\hat{\\Delta}_{\\mathrm{ITT}} \\mid n_1, n_0) = \\operatorname{Var}(\\bar{Y}_1 \\mid n_1) + \\operatorname{Var}(\\bar{Y}_0 \\mid n_0).\n$$\nWe will now derive each term separately. Let's start with the treatment arm. The sample mean is defined as:\n$$\n\\bar{Y}_1 = \\frac{1}{n_1} \\sum_{i: A_i=1} Y_i.\n$$\nUsing the property of variance that for a constant $c$, $\\operatorname{Var}(cX) = c^2 \\operatorname{Var}(X)$, we have:\n$$\n\\operatorname{Var}(\\bar{Y}_1 \\mid n_1) = \\operatorname{Var}\\left(\\frac{1}{n_1} \\sum_{i: A_i=1} Y_i \\mid n_1\\right) = \\frac{1}{n_1^2} \\operatorname{Var}\\left(\\sum_{i: A_i=1} Y_i \\mid n_1\\right).\n$$\nConditional on being in the treatment arm (i.e., $A_i=1$), the outcomes $Y_i$ are independent and identically distributed as $\\text{Bernoulli}(p_1)$. Since the sum is over $n_1$ such independent participants, the variance of the sum is the sum of their variances:\n$$\n\\operatorname{Var}\\left(\\sum_{i: A_i=1} Y_i \\mid n_1\\right) = \\sum_{i: A_i=1} \\operatorname{Var}(Y_i \\mid A_i=1).\n$$\nThe problem specifies that the variance for an outcome in arm $a$ is $p_a(1 - p_a)$. For the treatment arm, this is $\\operatorname{Var}(Y_i \\mid A_i=1) = p_1(1-p_1)$. The sum consists of $n_1$ identical terms:\n$$\n\\sum_{i: A_i=1} \\operatorname{Var}(Y_i \\mid A_i=1) = \\sum_{j=1}^{n_1} p_1(1-p_1) = n_1 p_1(1-p_1).\n$$\nSubstituting this result back into the expression for $\\operatorname{Var}(\\bar{Y}_1 \\mid n_1)$:\n$$\n\\operatorname{Var}(\\bar{Y}_1 \\mid n_1) = \\frac{1}{n_1^2} \\left[ n_1 p_1(1-p_1) \\right] = \\frac{p_1(1-p_1)}{n_1}.\n$$\nThis is the standard formula for the variance of the sample mean of $n_1$ i.i.d. Bernoulli trials.\n\nBy an identical line of reasoning for the control arm, where there are $n_0$ participants and the outcomes $Y_i$ are i.i.d. $\\text{Bernoulli}(p_0)$, we find the variance of the control group's sample mean:\n$$\n\\operatorname{Var}(\\bar{Y}_0 \\mid n_0) = \\frac{p_0(1-p_0)}{n_0}.\n$$\nFinally, we combine the two terms to find the total conditional variance of the ITT estimator:\n$$\n\\operatorname{Var}(\\hat{\\Delta}_{\\mathrm{ITT}} \\mid n_1, n_0) = \\operatorname{Var}(\\bar{Y}_1 \\mid n_1) + \\operatorname{Var}(\\bar{Y}_0 \\mid n_0) = \\frac{p_1(1-p_1)}{n_1} + \\frac{p_0(1-p_0)}{n_0}.\n$$\nThis final expression is a function of the arm-specific variances, $p_1(1-p_1)$ and $p_0(1-p_0)$, and the sample sizes, $n_1$ and $n_0$, as required.", "answer": "$$\n\\boxed{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_0(1-p_0)}{n_0}}\n$$", "id": "4917211"}, {"introduction": "The choice between ITT and Per-Protocol (PP) analysis is not merely academic; it can fundamentally alter a trial's conclusions, especially in non-inferiority studies designed to show a new treatment is \"not unacceptably worse\" than a standard one. This exercise [@problem_id:4917191] delves into this high-stakes scenario, where the typically conservative ITT analysis can become liberal, potentially leading to the false conclusion of non-inferiority. Working through this problem will sharpen your critical thinking about the direction of bias and the importance of the chosen analysis population.", "problem": "A two-arm randomized non-inferiority trial compares a new therapy assigned indicator $A=1$ to a standard therapy assigned indicator $A=0$ on a continuous outcome $Y$ measured at $12$ weeks, where larger values of $Y$ indicate better outcomes. The non-inferiority margin is pre-specified as $\\Delta$, with $\\Delta>0$. All randomized participants have observed outcomes at $12$ weeks. The Intention-To-Treat (ITT) principle is used to compute group means based on randomized assignment, irrespective of adherence or protocol deviations.\n\nStarting only from the formal non-inferiority hypothesis in terms of the population means $\\mu_{1}=\\mathbb{E}[Y\\mid A=1]$ and $\\mu_{0}=\\mathbb{E}[Y\\mid A=0]$, and from the definition of ITT sample means $\\bar{Y}_{A=1}$ and $\\bar{Y}_{A=0}$ as unbiased estimators of $\\mu_{1}$ and $\\mu_{0}$ under randomization, derive an unstandardized test statistic $T$ suitable for testing non-inferiority under ITT. Your derivation should begin from the formal null and alternative hypotheses and proceed by identifying the corresponding sample analogue.\n\nIn a particular trial, $n_{1}=\\;210$ participants are randomized to $A=1$ and $n_{0}=\\;190$ to $A=0$. There are protocol deviations in both groups (e.g., crossovers and premature discontinuations): $58$ participants in $A=1$ and $31$ participants in $A=0$ deviate from protocol. Nevertheless, ITT means are computed using all randomized participants: $\\bar{Y}_{A=1}=\\;73.85$ and $\\bar{Y}_{A=0}=\\;72.40$. The non-inferiority margin is $\\Delta=\\;3.25$.\n\nCompute the numerical value of your derived ITT non-inferiority test statistic $T$ for this trial. Round your answer to four significant figures. No units are required because $Y$ is a unitless score. In your solution, also explain how protocol deviations affect the interpretation of ITT versus Per-Protocol (PP) analyses in non-inferiority settings, without changing the requested numerical calculation.", "solution": "The problem requires the derivation of an unstandardized test statistic for a non-inferiority trial, its subsequent calculation using provided data, and an explanation of the roles of Intention-To-Treat (ITT) and Per-Protocol (PP) analyses in this context.\n\n**Derivation of the Unstandardized Test Statistic $T$**\nThe goal of this non-inferiority trial is to demonstrate that the new therapy ($A=1$) is not worse than the standard therapy ($A=0$) by more than a pre-specified margin $\\Delta$. Since larger values of the outcome $Y$ are better, \"worse\" for the new therapy means its population mean $\\mu_1$ is lower than the standard therapy's mean $\\mu_0$.\n\nThe formal hypotheses for non-inferiority are stated as follows:\nThe null hypothesis ($H_0$) is that the new therapy is inferior by at least the margin $\\Delta$:\n$$ H_0: \\mu_{1} \\le \\mu_{0} - \\Delta $$\nThis is equivalent to:\n$$ H_0: \\mu_{1} - \\mu_{0} \\le -\\Delta $$\nThe alternative hypothesis ($H_A$) is that the new therapy is non-inferior. This means the new therapy is not worse by the margin $\\Delta$:\n$$ H_A: \\mu_{1} > \\mu_{0} - \\Delta $$\nThis is equivalent to:\n$$ H_A: \\mu_{1} - \\mu_{0} > -\\Delta $$\n\nThe parameter of interest is the true difference in means, $\\delta = \\mu_{1} - \\mu_{0}$. The hypotheses are tested on this parameter: $H_0: \\delta \\le -\\Delta$ versus $H_A: \\delta > -\\Delta$.\n\nAccording to the problem statement, the Intention-To-Treat (ITT) sample means, $\\bar{Y}_{A=1}$ and $\\bar{Y}_{A=0}$, are unbiased estimators of the true population means $\\mu_1$ and $\\mu_0$, respectively. Consequently, the sample analogue, or estimator, for the parameter $\\delta$ is $\\hat{\\delta} = \\bar{Y}_{A=1} - \\bar{Y}_{A=0}$.\n\nA test statistic is constructed to measure the evidence against the null hypothesis. We evaluate this evidence at the boundary of the null hypothesis region, which is $\\delta = -\\Delta$. An unstandardized test statistic $T$ can be defined as the difference between the observed estimate $\\hat{\\delta}$ and the value at the null boundary, $-\\Delta$. This quantity measures how far the observed data falls into the region defined by the alternative hypothesis.\n\nTherefore, the unstandardized test statistic $T$ is:\n$$ T = \\hat{\\delta} - (-\\Delta) = (\\bar{Y}_{A=1} - \\bar{Y}_{A=0}) + \\Delta $$\nA positive value of $T$ suggests that the observed difference is more favorable than the non-inferiority boundary, providing evidence in favor of $H_A$. A statistical test would typically standardize $T$ by dividing it by its standard error to obtain a $p$-value, but the problem explicitly asks for the unstandardized form $T$.\n\n**Calculation of $T$**\nWe are given the following numerical values for a specific trial:\n- $\\bar{Y}_{A=1} = 73.85$\n- $\\bar{Y}_{A=0} = 72.40$\n- $\\Delta = 3.25$\n\nSubstituting these values into the derived expression for $T$:\n$$ T = (73.85 - 72.40) + 3.25 $$\n$$ T = 1.45 + 3.25 $$\n$$ T = 4.70 $$\nThe problem requires the answer to be rounded to four significant figures. Thus, the value is $4.700$.\n\n**ITT versus Per-Protocol (PP) Analysis in Non-Inferiority Trials**\nThe distinction between ITT and PP analysis is critical in the context of non-inferiority trials.\n\nThe **Intention-To-Treat (ITT)** analysis includes all participants in the statistical analysis according to the group to which they were originally randomized, regardless of protocol deviations such as non-adherence, withdrawal, or crossover to the other treatment arm. The ITT principle preserves the prognostic balance achieved by randomization and avoids selection bias. It provides an estimate of the treatment's effectiveness in a pragmatic, real-world setting, i.e., the effect of *assigning* a treatment.\n\nThe **Per-Protocol (PP)** analysis includes only those participants who sufficiently adhered to the trial protocol. This population provides an estimate of the treatment's efficacy under ideal circumstances, i.e., the effect of *receiving* the treatment as intended.\n\nIn a **superiority trial** (e.g., new drug vs. placebo), where the goal is to show a difference, protocol deviations typically dilute the true treatment effect, biasing the result towards the null hypothesis of no difference. Therefore, the ITT analysis is considered conservative. If superiority is demonstrated under ITT, the conclusion is robust.\n\nThe situation is reversed in a **non-inferiority trial**. Here, the objective is to show that two treatments are not too different. The null hypothesis is that of a meaningful difference (inferiority), and the alternative is that of no meaningful difference (non-inferiority). Protocol deviations that dilute the treatment effect will make the two groups appear more similar. This biases the result towards finding no difference, which supports the alternative hypothesis of non-inferiority. Consequently, for non-inferiority trials, the ITT analysis is considered **anti-conservative** or liberal, as it may increase the chance of falsely concluding non-inferiority.\n\nBecause of this bias, regulatory bodies often require that non-inferiority be demonstrated in both the ITT and PP analysis sets. The PP analysis, by focusing on adherent patients, is more likely to reveal any true inferiority of the new treatment, and is thus considered the more **conservative** analysis for establishing a non-inferiority claim. A consistent finding of non-inferiority in both the full ITT population and the \"cleaner\" PP population provides the most convincing evidence.", "answer": "$$\\boxed{4.700}$$", "id": "4917191"}, {"introduction": "The ITT principle—\"analyze as you randomize\"—is a cornerstone of clinical trials for preventing bias from post-randomization events like non-adherence. However, it is not a panacea, especially when faced with missing outcome data. This final practice [@problem_id:4917170] explores a scenario where data are missing dependent on the outcome itself, a challenging situation known as Missing Not At Random (MNAR). You will mathematically demonstrate how a simple complete-case ITT analysis becomes biased, revealing the crucial need for careful assumptions and potentially more advanced methods to handle missing data.", "problem": "A parallel two-arm randomized trial assigns participants to treatment $A \\in \\{0,1\\}$ with equal probability. The primary binary outcome is $Y \\in \\{0,1\\}$, measured at the end of follow-up. There is loss to follow-up, encoded by an indicator $R \\in \\{0,1\\}$ where $R=1$ if $Y$ is observed and $R=0$ otherwise. The estimand is the Intention-to-Treat (ITT) causal risk difference $\\Delta = \\mathbb{E}[Y \\mid \\operatorname{do}(A=1)] - \\mathbb{E}[Y \\mid \\operatorname{do}(A=0)]$, which under randomization equals $\\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0]$. Assume the following data-generating mechanism:\n- Under randomization, $A$ is independent of potential outcomes and missingness given $Y$.\n- Conditional on $A=a$, the outcome is distributed $Y \\mid A=a \\sim \\operatorname{Bernoulli}(p_{a})$ with $p_{1} = 0.35$ and $p_{0} = 0.20$.\n- The observation mechanism is outcome-dependent (Missing Not At Random (MNAR) given $A$ alone): $R \\mid (Y=1) \\sim \\operatorname{Bernoulli}(r_{1})$ with $r_{1} = 0.60$, and $R \\mid (Y=0) \\sim \\operatorname{Bernoulli}(r_{0})$ with $r_{0} = 0.90$, independent of $A$ given $Y$.\n\nConsider three estimators for $\\Delta$:\n- Complete-case Intention-to-Treat (ITT): the difference in sample means of $Y$ between $A=1$ and $A=0$ among those with $R=1$.\n- Inverse Probability of Censoring Weighting (IPCW): a weighted difference in sample means using weights $w(Y) = 1/\\pi(Y)$ for observed cases with $R=1$, where $\\pi(Y)=\\mathbb{P}(R=1 \\mid Y)$ is correctly specified by the data-generating mechanism above.\n- Multiple Imputation (MI) under a standard Missing At Random (MAR) working model that imputes $Y$ using only $A$ (no auxiliary variables), fit to the observed data.\n\nStarting from fundamental definitions of conditional expectation, Bayes’ rule, and properties of randomized treatment assignment, derive the large-sample expected values of the complete-case ITT and IPCW estimators under the data-generating mechanism above. Then, using these derivations and recognizing the behavior of the standard MAR MI estimator in this setting, compute the large-sample bias of the complete-case ITT estimator (equivalently, the MAR MI estimator) relative to the true ITT estimand $\\Delta$. Provide your final numeric answer as a single real number. Round your answer to $4$ significant figures.", "solution": "The primary goal is to compute the large-sample bias of the complete-case (CC) Intention-to-Treat (ITT) estimator. This bias is defined as the difference between the large-sample expected value of the estimator and the true value of the estimand.\n\nFirst, we define and calculate the true ITT estimand, $\\Delta$. The estimand is the causal risk difference, which under randomization is equivalent to the associational risk difference.\n$$ \\Delta = \\mathbb{E}[Y \\mid \\operatorname{do}(A=1)] - \\mathbb{E}[Y \\mid \\operatorname{do}(A=0)] = \\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0] $$\nGiven that the outcome $Y$ conditional on the treatment arm $A=a$ follows a Bernoulli distribution, $Y \\mid A=a \\sim \\operatorname{Bernoulli}(p_a)$, the expectation is simply the success probability:\n$$ \\mathbb{E}[Y \\mid A=a] = \\mathbb{P}(Y=1 \\mid A=a) = p_a $$\nUsing the provided values $p_{1} = 0.35$ and $p_{0} = 0.20$:\n$$ \\mathbb{E}[Y \\mid A=1] = p_1 = 0.35 $$\n$$ \\mathbb{E}[Y \\mid A=0] = p_0 = 0.20 $$\nTherefore, the true ITT estimand is:\n$$ \\Delta = p_1 - p_0 = 0.35 - 0.20 = 0.15 $$\n\nNext, we derive the large-sample expected value of the complete-case ITT estimator, denoted $\\Delta_{CC}$. This estimator uses only the participants with observed outcomes ($R=1$). Its large-sample value is the difference in the conditional expectation of $Y$ given $A$ among the complete cases.\n$$ \\Delta_{CC} = \\mathbb{E}[Y \\mid A=1, R=1] - \\mathbb{E}[Y \\mid A=0, R=1] $$\nWe need to calculate the term $\\mathbb{E}[Y \\mid A=a, R=1] = \\mathbb{P}(Y=1 \\mid A=a, R=1)$ for each treatment arm $a \\in \\{0, 1\\}$. Using Bayes' rule:\n$$ \\mathbb{P}(Y=1 \\mid A=a, R=1) = \\frac{\\mathbb{P}(R=1 \\mid Y=1, A=a) \\mathbb{P}(Y=1 \\mid A=a)}{\\mathbb{P}(R=1 \\mid A=a)} $$\nThe denominator, $\\mathbb{P}(R=1 \\mid A=a)$, can be expanded using the law of total probability, conditioning on $Y$:\n$$ \\mathbb{P}(R=1 \\mid A=a) = \\mathbb{P}(R=1 \\mid Y=1, A=a)\\mathbb{P}(Y=1 \\mid A=a) + \\mathbb{P}(R=1 \\mid Y=0, A=a)\\mathbb{P}(Y=0 \\mid A=a) $$\nAccording to the data-generating mechanism, the observation process $R$ is independent of treatment $A$ conditional on outcome $Y$. This is a Missing Not At Random (MNAR) mechanism. This independence allows us to simplify the conditional probabilities of $R$:\n$$ \\mathbb{P}(R=1 \\mid Y=y, A=a) = \\mathbb{P}(R=1 \\mid Y=y) = r_y $$\nWe are given $r_1 = \\mathbb{P}(R=1 \\mid Y=1) = 0.60$ and $r_0 = \\mathbb{P}(R=1 \\mid Y=0) = 0.90$. We also have $\\mathbb{P}(Y=1 \\mid A=a) = p_a$ and $\\mathbb{P}(Y=0 \\mid A=a) = 1-p_a$. Substituting these into our expressions:\n$$ \\mathbb{P}(R=1 \\mid A=a) = r_1 p_a + r_0 (1-p_a) $$\nAnd the complete-case probability of success becomes:\n$$ \\mathbb{P}(Y=1 \\mid A=a, R=1) = \\frac{r_1 p_a}{r_1 p_a + r_0 (1-p_a)} $$\n\nNow, we compute this for each arm:\nFor the treatment arm $A=1$, with $p_1 = 0.35$:\n$$ \\mathbb{E}[Y \\mid A=1, R=1] = \\frac{0.60 \\times 0.35}{0.60 \\times 0.35 + 0.90 \\times (1-0.35)} = \\frac{0.21}{0.21 + 0.90 \\times 0.65} = \\frac{0.21}{0.21 + 0.585} = \\frac{0.21}{0.795} = \\frac{210}{795} = \\frac{14}{53} $$\n\nFor the control arm $A=0$, with $p_0 = 0.20$:\n$$ \\mathbb{E}[Y \\mid A=0, R=1] = \\frac{0.60 \\times 0.20}{0.60 \\times 0.20 + 0.90 \\times (1-0.20)} = \\frac{0.12}{0.12 + 0.90 \\times 0.80} = \\frac{0.12}{0.12 + 0.72} = \\frac{0.12}{0.84} = \\frac{12}{84} = \\frac{1}{7} $$\n\nThe large-sample value of the complete-case estimator is:\n$$ \\Delta_{CC} = \\frac{14}{53} - \\frac{1}{7} = \\frac{98 - 53}{371} = \\frac{45}{371} $$\n\nThe problem asks to also consider the Inverse Probability of Censoring Weighting (IPCW) estimator. The large-sample expected value of the IPCW-estimated mean outcome in arm $a$ is $\\mathbb{E}\\left[\\frac{R Y}{\\mathbb{P}(R=1 \\mid Y,A)} \\mid A=a\\right]$. With correctly specified weights $\\mathbb{P}(R=1 \\mid Y,A) = \\mathbb{P}(R=1 \\mid Y) = \\pi(Y)$, this becomes:\n$$ \\mathbb{E}\\left[\\frac{R Y}{\\pi(Y)} \\mid A=a\\right] = \\mathbb{E}\\left[ \\mathbb{E}\\left[\\frac{R Y}{\\pi(Y)} \\mid Y,A=a\\right] \\mid A=a \\right] = \\mathbb{E}\\left[ \\frac{Y}{\\pi(Y)} \\mathbb{E}[R \\mid Y,A=a] \\mid A=a \\right] $$\nSince $\\mathbb{E}[R \\mid Y,A=a] = \\mathbb{P}(R=1 \\mid Y,A=a) = \\pi(Y)$, the terms cancel:\n$$ \\mathbb{E}\\left[ \\frac{Y}{\\pi(Y)} \\pi(Y) \\mid A=a \\right] = \\mathbb{E}[Y \\mid A=a] = p_a $$\nThus, the IPCW estimator is consistent for $\\Delta$. Its large-sample value is $\\Delta_{IPCW} = p_1 - p_0 = \\Delta$. This confirms it is an unbiased estimator in large samples.\n\nThe problem states that a standard Multiple Imputation (MI) procedure under a Missing At Random (MAR) assumption, using only $A$ to impute $Y$, is equivalent to the complete-case estimator. This is because the imputation model for $Y$ given $A$ is fit to the observed data, for which $R=1$. The model learns $\\mathbb{P}(Y=1 \\mid A=a, R=1)$. Missing values are then imputed from this distribution. Consequently, the mean of $Y$ in the imputed dataset for arm $a$ converges to $\\mathbb{E}[Y \\mid A=a, R=1]$, making the MI estimate equal to the CC estimate. The bias of this MI estimator is therefore the same as the bias of the CC-ITT estimator.\n\nFinally, we compute the large-sample bias of the complete-case ITT estimator.\n$$ \\text{Bias}(\\Delta_{CC}) = \\Delta_{CC} - \\Delta $$\nSubstituting the computed values:\n$$ \\text{Bias}(\\Delta_{CC}) = \\frac{45}{371} - 0.15 = \\frac{45}{371} - \\frac{3}{20} $$\n$$ \\text{Bias}(\\Delta_{CC}) = \\frac{45 \\times 20 - 3 \\times 371}{371 \\times 20} = \\frac{900 - 1113}{7420} = -\\frac{213}{7420} $$\nNow we compute the numerical value and round to $4$ significant figures:\n$$ \\text{Bias}(\\Delta_{CC}) \\approx -0.028706199... $$\nRounding to $4$ significant figures gives $-0.02871$.", "answer": "$$\\boxed{-0.02871}$$", "id": "4917170"}]}