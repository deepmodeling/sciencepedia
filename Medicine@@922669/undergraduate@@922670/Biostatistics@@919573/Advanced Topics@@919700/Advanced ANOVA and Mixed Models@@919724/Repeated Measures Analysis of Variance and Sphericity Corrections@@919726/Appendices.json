{"hands_on_practices": [{"introduction": "The foundation of repeated measures ANOVA is the within-subjects F-test, which assesses whether measurements change significantly over time. This first practice focuses on the essential parameters that shape this test: the degrees of freedom. By working through this problem, you will learn to derive the numerator and denominator degrees of freedom directly from the study's design parameters, providing a crucial first step for any repeated measures analysis [@problem_id:4948291].", "problem": "A longitudinal biomarker study measures a continuous outcome at $t=6$ equally spaced follow-up visits for each of $n=30$ participants, with no missing data. Consider a one-factor repeated measures analysis of variance with a fixed within-subject factor (time) and a subject blocking effect. Starting from the linear model representation and the identifiability constraints that define unique parameterization of subject and time effects, derive the number of independent contrasts for the time factor and for the residual term against which the time factor is tested in the within-subject F-test. Then, compute the numerical values of the numerator and denominator degrees of freedom for this F-test using $t=6$ and $n=30$.\n\nIn addition, articulate the distributional assumptions of normality and sphericity that justify the use of the standard within-subject F-test in this design, and explain qualitatively how a violation of sphericity leads to adjusted degrees of freedom via a correction factor. The final answer must consist only of the two degrees of freedom values, expressed without units. No rounding is required.", "solution": "The problem is valid as it is scientifically grounded in the principles of biostatistics, specifically repeated measures analysis of variance (ANOVA). It is well-posed, providing all necessary data ($t=6$, $n=30$) for a unique solution, and is expressed in objective, formal language. We will proceed with the derivation and calculation.\n\nA one-way repeated measures ANOVA can be conceptualized using a linear model. For a study with $n$ subjects measured at $t$ time points, the observation $Y_{ij}$ for subject $i$ at time $j$ can be modeled as:\n$$Y_{ij} = \\mu + \\pi_i + \\tau_j + (\\pi\\tau)_{ij}$$\nwhere $i=1, 2, \\dots, n$ and $j=1, 2, \\dots, t$. In this model:\n- $\\mu$ is the overall grand mean.\n- $\\pi_i$ is the effect of subject $i$, which is unique to each individual and accounts for the baseline differences between subjects. It is treated as a random effect, representing a random sample from a population of subjects. The subjects serve as blocks.\n- $\\tau_j$ is the fixed effect of the $j$-th level of the within-subject factor, which in this case is time.\n- $(\\pi\\tau)_{ij}$ represents the interaction between subject $i$ and time $j$. This term captures how the effect of time might differ across subjects. In repeated measures ANOVA, this interaction is inseparable from random error and serves as the error term for testing the significance of the time effect.\n\nFor the model parameters to be uniquely identifiable, we impose sum-to-zero constraints. For the fixed time effects, the constraint is $\\sum_{j=1}^{t} \\tau_j = 0$. This constraint means that once $t-1$ of the $\\tau_j$ values are known, the last one is determined. Consequently, there are $t-1$ independent parameters associated with the time factor. The number of independent parameters corresponds to the degrees of freedom. Therefore, the number of independent contrasts for the time factor is $t-1$.\n\nThe total variability in the data is partitioned into between-subjects and within-subjects sources of variation. The within-subjects variation is further partitioned into variation due to the time factor and residual (or error) variation.\nThe degrees of freedom ($df$) for each source are as follows:\n- $df_{\\text{Between-Subjects}} = n-1$\n- $df_{\\text{Within-Subjects}} = n(t-1)$\n\nThe within-subjects degrees of freedom are then partitioned:\n- $df_{\\text{Time}} = t-1$\n- $df_{\\text{Residual}} = df_{\\text{Within-Subjects}} - df_{\\text{Time}} = n(t-1) - (t-1) = (n-1)(t-1)$\n\nThe residual term, $df_{\\text{Residual}}$, corresponds to the Subject $\\times$ Time interaction. It represents the $n-1$ subject degrees of freedom interacting with the $t-1$ time degrees of freedom. The number of independent contrasts for this residual term is therefore $(n-1)(t-1)$.\n\nThe $F$-test for the within-subject effect of time is the ratio of the mean square for time to the mean square for the residual (Subject $\\times$ Time interaction):\n$$F = \\frac{MS_{\\text{Time}}}{MS_{\\text{Residual}}} = \\frac{SS_{\\text{Time}} / df_{\\text{Time}}}{SS_{\\text{Residual}} / df_{\\text{Residual}}}$$\nThe numerator degrees of freedom for this test are $df_{\\text{num}} = df_{\\text{Time}}$, and the denominator degrees of freedom are $df_{\\text{den}} = df_{\\text{Residual}}$.\n\nUsing the provided values $t=6$ and $n=30$:\n- Numerator degrees of freedom: $df_{\\text{num}} = t-1 = 6-1 = 5$.\n- Denominator degrees of freedom: $df_{\\text{den}} = (n-1)(t-1) = (30-1)(6-1) = 29 \\times 5 = 145$.\n\nThe validity of this standard $F$-test depends on several assumptions. The critical assumptions for the within-subject test are:\n1.  **Independence of Subjects**: The observations for different subjects must be independent of one another. This is typically ensured by the study design (i.e., random sampling of participants).\n2.  **Multivariate Normality**: The dependent variable vector for each subject is assumed to be drawn from a multivariate normal distribution. This also implies that the differences between treatment levels are normally distributed.\n3.  **Sphericity (or Circularity)**: This assumption requires that the variances of the differences between all possible pairs of levels of the within-subject factor (time) are equal. Formally, for any two time points $j$ and $k$:\n    $$\\text{Var}(Y_{ij} - Y_{ik}) = \\text{constant}$$\n    Sphericity is a less strict condition than compound symmetry, which requires both homogeneity of variances at each time point and homogeneity of covariances between pairs of time points.\n\nA violation of the sphericity assumption is common in longitudinal studies where measurements closer in time tend to be more correlated than those further apart. When sphericity is violated, the denominator of the $F$-statistic, $MS_{\\text{Residual}}$, is, on average, too small. This inflates the $F$-ratio, leading to an increased probability of a Type I error (i.e., falsely rejecting the null hypothesis). The standard $F$-test becomes too liberal.\n\nTo address this, a correction is applied to the degrees of freedom. The correction involves estimating a parameter, $\\epsilon$ (epsilon), which quantifies the extent of the departure from sphericity. The value of $\\epsilon$ is bounded by $\\frac{1}{t-1} \\le \\epsilon \\le 1$. A value of $\\epsilon = 1$ indicates that the sphericity assumption holds perfectly. A value of $\\epsilon = \\frac{1}{t-1}$ indicates a maximal violation.\n\nThe original numerator and denominator degrees of freedom are multiplied by an estimate of $\\epsilon$ (e.g., the Greenhouse-Geisser $\\hat{\\epsilon}_{GG}$ or Huynh-Feldt $\\hat{\\epsilon}_{HF}$ estimate) to obtain adjusted degrees of freedom:\n- Adjusted $df_{\\text{num}} = \\hat{\\epsilon} (t-1)$\n- Adjusted $df_{\\text{den}} = \\hat{\\epsilon} (n-1)(t-1)$\n\nBy reducing the degrees of freedom, this correction increases the critical $F$-value required to achieve statistical significance, thereby yielding a more conservative test that effectively controls the Type I error rate at the desired level.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n5  145\n\\end{pmatrix}\n}\n$$", "id": "4948291"}, {"introduction": "The standard F-test relies on a critical assumption known as sphericity, which is often violated in longitudinal data. This next exercise takes you \"under the hood\" of the most common fix, the Greenhouse-Geisser correction. You will perform the direct calculation of the correction factor, $\\hat{\\epsilon}_{GG}$, from a sample covariance matrix, demystifying how we quantify the severity of a sphericity violation [@problem_id:4948284].", "problem": "A longitudinal biomedical study measures a continuous biomarker on $n$ subjects at $T=3$ equally spaced visits. For a repeated measures analysis of variance, the validity of the standard within-subject F-test depends on the sphericity assumption, which can be corrected using the Greenhouse–Geisser (GG) adjustment. The Greenhouse–Geisser (GG) estimator of the sphericity parameter uses the sample covariance matrix of the repeated measurements and the projection onto the contrast space orthogonal to the grand mean.\n\nSuppose the sample covariance matrix of the three within-subject measurements is\n$$\n\\hat{\\Sigma} \\;=\\;\n\\begin{pmatrix}\n1.50  0.90  0.60 \\\\\n0.90  1.80  0.75 \\\\\n0.60  0.75  1.40\n\\end{pmatrix}.\n$$\nLet the contrast-space projector be defined as\n$$\nC \\;=\\; I_3 \\;-\\; \\frac{1}{3}\\mathbf{1}\\mathbf{1}^{\\top},\n$$\nwhere $I_3$ is the $3\\times 3$ identity matrix and $\\mathbf{1}$ is the $3\\times 1$ vector of ones. Starting from the definition of sphericity as equality of variances of all possible differences of within-subject levels and the representation of within-subject contrasts as a projection onto the subspace orthogonal to $\\mathbf{1}$, derive the Greenhouse–Geisser estimator $\\hat{\\epsilon}_{GG}$ in terms of invariants of the covariance that do not depend on the particular choice of contrast basis, and then compute $\\hat{\\epsilon}_{GG}$ for the given $\\hat{\\Sigma}$ and $C$.\n\nExpress your final answer as a simplified rational number. No rounding is required.", "solution": "The problem asks for the derivation of the Greenhouse-Geisser estimator of sphericity, $\\hat{\\epsilon}_{GG}$, in a form that is invariant to the choice of contrast basis, and then to compute its value for a given sample covariance matrix $\\hat{\\Sigma}$ from a study with $T=3$ repeated measures.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Number of repeated measurements: $T=3$.\n- Sample covariance matrix:\n$$\n\\hat{\\Sigma} \\;=\\;\n\\begin{pmatrix}\n1.50  0.90  0.60 \\\\\n0.90  1.80  0.75 \\\\\n0.60  0.75  1.40\n\\end{pmatrix}\n$$\n- Contrast-space projector:\n$$\nC \\;=\\; I_3 \\;-\\; \\frac{1}{3}\\mathbf{1}\\mathbf{1}^{\\top}\n$$\nwhere $I_3$ is the $3 \\times 3$ identity matrix and $\\mathbf{1}$ is the $3 \\times 1$ vector of ones.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the theory of multivariate statistics, specifically repeated measures ANOVA, a core topic in biostatistics. The concepts of sphericity, covariance matrices, contrast spaces, and the Greenhouse-Geisser correction are well-established. The provided sample covariance matrix $\\hat{\\Sigma}$ is symmetric. Its principal minors are all positive ($1.5 > 0$, $1.89 > 0$, and $\\det(\\hat{\\Sigma}) = 1.96425 > 0$), confirming it is positive definite and thus a valid sample covariance matrix. The problem is well-posed, objective, and contains all necessary information for a unique solution. It is a standard, non-trivial problem in its field.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We will proceed with the solution.\n\n### Derivation of the Greenhouse-Geisser Estimator $\\hat{\\epsilon}_{GG}$\n\nThe Greenhouse-Geisser estimator $\\hat{\\epsilon}$ for a given population covariance matrix $\\Sigma$ of size $T \\times T$ is defined in terms of a full-rank matrix of orthonormal contrasts, $M$, which is a $T \\times (T-1)$ matrix whose columns are orthogonal to the vector $\\mathbf{1}$ (i.e., $M^{\\top}\\mathbf{1} = \\mathbf{0}$) and are orthonormal ($M^{\\top}M = I_{T-1}$). The estimator is given by:\n$$\n\\epsilon = \\frac{\\left( \\text{tr}(M^{\\top}\\Sigma M) \\right)^2}{(T-1) \\text{tr}\\left( (M^{\\top}\\Sigma M)^2 \\right)}\n$$\nThe problem requires showing that this expression can be written in terms of invariants that do not depend on the specific choice of $M$. The matrix $MM^{\\top}$ represents the orthogonal projection onto the contrast space, which is the subspace orthogonal to the vector $\\mathbf{1}$. This projection matrix is uniquely defined as $C = I_T - \\frac{1}{T}\\mathbf{1}\\mathbf{1}^{\\top}$. Thus, we have the identity $MM^{\\top} = C$. We can use this identity and the cyclic property of the trace operator ($\\text{tr}(AB) = \\text{tr}(BA)$) to rewrite the terms in the expression for $\\epsilon$.\n\nFor the numerator, we have:\n$$\n\\text{tr}(M^{\\top}\\Sigma M) = \\text{tr}(\\Sigma M M^{\\top}) = \\text{tr}(\\Sigma C)\n$$\nThus, the numerator is $(\\text{tr}(\\Sigma C))^2$.\n\nFor the denominator, we analyze the term $\\text{tr}((M^{\\top}\\Sigma M)^2)$:\n$$\n\\text{tr}\\left( (M^{\\top}\\Sigma M)^2 \\right) = \\text{tr}(M^{\\top}\\Sigma M M^{\\top}\\Sigma M)\n$$\nSubstituting $MM^{\\top} = C$:\n$$\n\\text{tr}(M^{\\top}\\Sigma C \\Sigma M)\n$$\nApplying the cyclic property of the trace:\n$$\n\\text{tr}(\\Sigma C \\Sigma M M^{\\top}) = \\text{tr}(\\Sigma C \\Sigma C) = \\text{tr}((\\Sigma C)^2)\n$$\nThus, the denominator is $(T-1)\\text{tr}((\\Sigma C)^2)$.\n\nCombining these results, the expression for $\\epsilon$ becomes:\n$$\n\\epsilon = \\frac{(\\text{tr}(\\Sigma C))^2}{(T-1)\\text{tr}((\\Sigma C)^2)}\n$$\nThis expression depends only on $\\Sigma$, $T$, and the fixed projector $C$, and is therefore invariant to the choice of the orthonormal contrast basis $M$. The Greenhouse-Geisser estimator $\\hat{\\epsilon}_{GG}$ is obtained by replacing the population covariance matrix $\\Sigma$ with the sample covariance matrix $\\hat{\\Sigma}$:\n$$\n\\hat{\\epsilon}_{GG} = \\frac{(\\text{tr}(\\hat{\\Sigma} C))^2}{(T-1)\\text{tr}((\\hat{\\Sigma} C)^2)}\n$$\n\n### Computation of $\\hat{\\epsilon}_{GG}$\n\nWe are given $T=3$ and the sample covariance matrix $\\hat{\\Sigma}$. To ensure precision, we convert the decimal entries to fractions:\n$$\n\\hat{\\Sigma} = \\begin{pmatrix} 1.50  0.90  0.60 \\\\ 0.90  1.80  0.75 \\\\ 0.60  0.75  1.40 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2}  \\frac{9}{10}  \\frac{3}{5} \\\\ \\frac{9}{10}  \\frac{9}{5}  \\frac{3}{4} \\\\ \\frac{3}{5}  \\frac{3}{4}  \\frac{7}{5} \\end{pmatrix}\n$$\nThe projector $C$ for $T=3$ is:\n$$\nC = I_3 - \\frac{1}{3}\\mathbf{1}\\mathbf{1}^{\\top} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} - \\frac{1}{3}\\begin{pmatrix} 1  1  1 \\\\ 1  1  1 \\\\ 1  1  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{3}  -\\frac{1}{3}  -\\frac{1}{3} \\\\ -\\frac{1}{3}  \\frac{2}{3}  -\\frac{1}{3} \\\\ -\\frac{1}{3}  -\\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}\n$$\nFirst, we compute the matrix product $\\hat{\\Sigma} C$:\n$$\n\\hat{\\Sigma} C = \\begin{pmatrix} \\frac{3}{2}  \\frac{9}{10}  \\frac{3}{5} \\\\ \\frac{9}{10}  \\frac{9}{5}  \\frac{3}{4} \\\\ \\frac{3}{5}  \\frac{3}{4}  \\frac{7}{5} \\end{pmatrix} \\begin{pmatrix} \\frac{2}{3}  -\\frac{1}{3}  -\\frac{1}{3} \\\\ -\\frac{1}{3}  \\frac{2}{3}  -\\frac{1}{3} \\\\ -\\frac{1}{3}  -\\frac{1}{3}  \\frac{2}{3} \\end{pmatrix}\n$$\nThe entries of the product matrix $\\hat{\\Sigma} C$ are:\n$(\\hat{\\Sigma} C)_{11} = \\frac{3}{2}(\\frac{2}{3}) + \\frac{9}{10}(-\\frac{1}{3}) + \\frac{3}{5}(-\\frac{1}{3}) = 1 - \\frac{3}{10} - \\frac{1}{5} = \\frac{10-3-2}{10} = \\frac{5}{10} = \\frac{1}{2}$\n$(\\hat{\\Sigma} C)_{12} = \\frac{3}{2}(-\\frac{1}{3}) + \\frac{9}{10}(\\frac{2}{3}) + \\frac{3}{5}(-\\frac{1}{3}) = -\\frac{1}{2} + \\frac{3}{5} - \\frac{1}{5} = -\\frac{5}{10} + \\frac{6}{10} - \\frac{2}{10} = -\\frac{1}{10}$\n$(\\hat{\\Sigma} C)_{13} = \\frac{3}{2}(-\\frac{1}{3}) + \\frac{9}{10}(-\\frac{1}{3}) + \\frac{3}{5}(\\frac{2}{3}) = -\\frac{1}{2} - \\frac{3}{10} + \\frac{2}{5} = -\\frac{5}{10} - \\frac{3}{10} + \\frac{4}{10} = -\\frac{4}{10} = -\\frac{2}{5}$\n$(\\hat{\\Sigma} C)_{21} = \\frac{9}{10}(\\frac{2}{3}) + \\frac{9}{5}(-\\frac{1}{3}) + \\frac{3}{4}(-\\frac{1}{3}) = \\frac{3}{5} - \\frac{3}{5} - \\frac{1}{4} = -\\frac{1}{4}$\n$(\\hat{\\Sigma} C)_{22} = \\frac{9}{10}(-\\frac{1}{3}) + \\frac{9}{5}(\\frac{2}{3}) + \\frac{3}{4}(-\\frac{1}{3}) = -\\frac{3}{10} + \\frac{6}{5} - \\frac{1}{4} = \\frac{-6+24-5}{20} = \\frac{13}{20}$\n$(\\hat{\\Sigma} C)_{23} = \\frac{9}{10}(-\\frac{1}{3}) + \\frac{9}{5}(-\\frac{1}{3}) + \\frac{3}{4}(\\frac{2}{3}) = -\\frac{3}{10} - \\frac{3}{5} + \\frac{1}{2} = \\frac{-3-6+5}{10} = -\\frac{4}{10} = -\\frac{2}{5}$\n$(\\hat{\\Sigma} C)_{31} = \\frac{3}{5}(\\frac{2}{3}) + \\frac{3}{4}(-\\frac{1}{3}) + \\frac{7}{5}(-\\frac{1}{3}) = \\frac{2}{5} - \\frac{1}{4} - \\frac{7}{15} = \\frac{24-15-28}{60} = -\\frac{19}{60}$\n$(\\hat{\\Sigma} C)_{32} = \\frac{3}{5}(-\\frac{1}{3}) + \\frac{3}{4}(\\frac{2}{3}) + \\frac{7}{5}(-\\frac{1}{3}) = -\\frac{1}{5} + \\frac{1}{2} - \\frac{7}{15} = \\frac{-6+15-14}{30} = -\\frac{5}{30} = -\\frac{1}{6}$\n$(\\hat{\\Sigma} C)_{33} = \\frac{3}{5}(-\\frac{1}{3}) + \\frac{3}{4}(-\\frac{1}{3}) + \\frac{7}{5}(\\frac{2}{3}) = -\\frac{1}{5} - \\frac{1}{4} + \\frac{14}{15} = \\frac{-12-15+56}{60} = \\frac{29}{60}$\nSo, the matrix $\\hat{\\Sigma}C$ is:\n$$\n\\hat{\\Sigma} C = \\begin{pmatrix} \\frac{1}{2}  -\\frac{1}{10}  -\\frac{2}{5} \\\\ -\\frac{1}{4}  \\frac{13}{20}  -\\frac{2}{5} \\\\ -\\frac{19}{60}  -\\frac{1}{6}  \\frac{29}{60} \\end{pmatrix} = \\frac{1}{60} \\begin{pmatrix} 30  -6  -24 \\\\ -15  39  -24 \\\\ -19  -10  29 \\end{pmatrix}\n$$\nNow, we compute the numerator term, $(\\text{tr}(\\hat{\\Sigma} C))^2$:\n$$\n\\text{tr}(\\hat{\\Sigma} C) = \\frac{1}{2} + \\frac{13}{20} + \\frac{29}{60} = \\frac{30+39+29}{60} = \\frac{98}{60} = \\frac{49}{30}\n$$\n$$\n(\\text{tr}(\\hat{\\Sigma} C))^2 = \\left(\\frac{49}{30}\\right)^2 = \\frac{2401}{900}\n$$\nNext, we compute the denominator term, $(T-1)\\text{tr}((\\hat{\\Sigma} C)^2) = 2\\text{tr}((\\hat{\\Sigma} C)^2)$. We need $\\text{tr}((\\hat{\\Sigma} C)^2) = \\sum_{i} \\sum_{j} (\\hat{\\Sigma} C)_{ij}(\\hat{\\Sigma} C)_{ji}$. Let $X = \\hat{\\Sigma} C$.\n$\\text{tr}(X^2) = X_{11}^2 + X_{12}X_{21} + X_{13}X_{31} + X_{21}X_{12} + X_{22}^2 + X_{23}X_{32} + X_{31}X_{13} + X_{32}X_{23} + X_{33}^2$.\nUsing the matrix $X = \\frac{1}{60}M$ where $M$ is the integer matrix above:\n$\\text{tr}(X^2) = \\frac{1}{60^2} \\text{tr}(M^2) = \\frac{1}{3600}\\left( (M^2)_{11} + (M^2)_{22} + (M^2)_{33} \\right)$.\n$(M^2)_{11} = M_{11}M_{11} + M_{12}M_{21} + M_{13}M_{31} = (30)(30) + (-6)(-15) + (-24)(-19) = 900 + 90 + 456 = 1446$.\n$(M^2)_{22} = M_{21}M_{12} + M_{22}M_{22} + M_{23}M_{32} = (-15)(-6) + (39)(39) + (-24)(-10) = 90 + 1521 + 240 = 1851$.\n$(M^2)_{33} = M_{31}M_{13} + M_{32}M_{23} + M_{33}M_{33} = (-19)(-24) + (-10)(-24) + (29)(29) = 456 + 240 + 841 = 1537$.\nThe trace is the sum of these diagonal elements:\n$$\n\\text{tr}(M^2) = 1446 + 1851 + 1537 = 4834\n$$\n$$\n\\text{tr}((\\hat{\\Sigma} C)^2) = \\frac{4834}{3600} = \\frac{2417}{1800}\n$$\nThe denominator for $\\hat{\\epsilon}_{GG}$ is:\n$$\n(T-1)\\text{tr}((\\hat{\\Sigma} C)^2) = 2 \\times \\frac{2417}{1800} = \\frac{2417}{900}\n$$\nFinally, we compute $\\hat{\\epsilon}_{GG}$:\n$$\n\\hat{\\epsilon}_{GG} = \\frac{(\\text{tr}(\\hat{\\Sigma} C))^2}{(T-1)\\text{tr}((\\hat{\\Sigma} C)^2)} = \\frac{\\frac{2401}{900}}{\\frac{2417}{900}} = \\frac{2401}{2417}\n$$\nThe value is between $1/(T-1) = 0.5$ and $1$, as expected. The result is a simplified rational number as requested.", "answer": "$$\\boxed{\\frac{2401}{2417}}$$", "id": "4948284"}, {"introduction": "Once a violation of sphericity is confirmed and a correction factor is estimated, the final step is to adjust the analysis to ensure valid conclusions. This concluding practice demonstrates how to apply the Greenhouse-Geisser epsilon to the original degrees of freedom, creating a more conservative and accurate test. This skill is vital for robustly interpreting the results of repeated measures ANOVA in real-world research scenarios [@problem_id:4836009].", "problem": "A longitudinal clinical trial investigates the effect of a novel antihypertensive treatment on systolic blood pressure trajectories across time. A total of $n=30$ patients are measured at $k=5$ prespecified clinic visits, yielding a within-subject factor with $k$ levels. The primary inferential target is the main effect of time in a univariate repeated measures analysis of variance (ANOVA), treating time as a within-subject factor. Assume the standard univariate repeated measures ANOVA model with subject-specific random intercepts, homoscedastic residuals, and the usual constraint on cell means, and recall that the uncorrected F-test for the within-subject time effect relies on the sphericity assumption concerning the covariance structure of repeated measures.\n\nSuppose Mauchly’s test provides strong evidence against sphericity, and the Greenhouse–Geisser (GG) sphericity correction factor is estimated as $\\hat{\\epsilon}_{\\mathrm{GG}}=0.6$. Starting from the fundamental definitions of degrees of freedom in univariate repeated measures ANOVA for a within-subject factor and the role of sphericity in the exact F distribution, derive the Greenhouse–Geisser–adjusted numerator and denominator degrees of freedom for testing the time effect. Then, at a type I error rate of $\\alpha=0.05$, interpret qualitatively how these adjusted degrees of freedom will change the $F$ critical value relative to the uncorrected sphericity case.\n\nProvide the corrected degrees of freedom as a two-entry row matrix in the order numerator, denominator. If rounding were necessary, round to four significant figures; however, report exact values when available. Do not include any units in your final answer.", "solution": "The problem statement is deemed valid as it is scientifically grounded, well-posed, objective, and provides a self-contained and consistent set of parameters for a standard statistical procedure.\n\nThe problem asks for the derivation of the Greenhouse–Geisser (GG) adjusted degrees of freedom for the main effect of a within-subject factor in a repeated measures ANOVA and a qualitative interpretation of the effect of this adjustment on the critical value of the F-test.\n\nFirst, we establish the standard (uncorrected) degrees of freedom for the F-test of the within-subject factor, which is 'time' in this clinical trial context. Let $n$ be the number of subjects and $k$ be the number of repeated measures (levels of the within-subject factor).\nThe provided values are $n=30$ and $k=5$.\n\nIn a one-way repeated measures ANOVA, the F-statistic for the within-subject effect is constructed as the ratio of the mean square for the factor (time) to the mean square for the error (time $\\times$ subject interaction). The degrees of freedom for this F-statistic, under the assumption of sphericity, are:\nThe numerator degrees of freedom, $df_{\\text{num}}$, correspond to the main effect of time:\n$$df_{\\text{num}} = k - 1$$\nThe denominator degrees of freedom, $df_{\\text{den}}$, correspond to the interaction between time and subjects, which serves as the error term:\n$$df_{\\text{den}} = (k - 1)(n - 1)$$\n\nSubstituting the given values:\n$$df_{\\text{num}} = 5 - 1 = 4$$\n$$df_{\\text{den}} = (5 - 1)(30 - 1) = 4 \\times 29 = 116$$\nThus, under the sphericity assumption, the test statistic follows an $F$ distribution with $4$ and $116$ degrees of freedom, denoted as $F(4, 116)$.\n\nThe problem states that Mauchly’s test provides strong evidence against sphericity. When the sphericity assumption is violated, the Type I error rate of the uncorrected F-test is inflated. To control for this inflation, a correction is applied to the degrees of freedom. The F-statistic itself remains unchanged, but it is compared to a critical value from an F-distribution with adjusted degrees of freedom.\n\nThe Greenhouse–Geisser correction involves multiplying both the numerator and denominator degrees of freedom by an estimate of the sphericity parameter, $\\epsilon$. The value of $\\epsilon$ ranges from $\\frac{1}{k-1}$ (for maximal violation of sphericity) to $1$ (for perfect sphericity). The problem provides the Greenhouse–Geisser estimate, $\\hat{\\epsilon}_{\\mathrm{GG}} = 0.6$.\n\nThe adjusted degrees of freedom, denoted $df'_{\\text{num}}$ and $df'_{\\text{den}}$, are calculated as follows:\n$$df'_{\\text{num}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times df_{\\text{num}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times (k - 1)$$\n$$df'_{\\text{den}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times df_{\\text{den}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times (k - 1)(n - 1)$$\n\nUsing the given values $\\hat{\\epsilon}_{\\mathrm{GG}} = 0.6$, $k=5$, and $n=30$:\n$$df'_{\\text{num}} = 0.6 \\times (5 - 1) = 0.6 \\times 4 = 2.4$$\n$$df'_{\\text{den}} = 0.6 \\times (5 - 1)(30 - 1) = 0.6 \\times 4 \\times 29 = 2.4 \\times 29 = 69.6$$\nThese are the Greenhouse–Geisser–adjusted numerator and denominator degrees of freedom for the test of the time effect.\n\nNext, we interpret qualitatively how these adjusted degrees of freedom affect the F critical value. The critical value for the test, $F_{\\text{crit}}$, is the value from the F-distribution that cuts off the upper $\\alpha$ proportion of the area. For a given significance level $\\alpha=0.05$, the critical value is a function of the numerator and denominator degrees of freedom.\n\nUncorrected case: $F_{\\text{crit, uncorrected}} = F_{1-\\alpha}(df_{\\text{num}}, df_{\\text{den}}) = F_{0.95}(4, 116)$\nCorrected case: $F_{\\text{crit, corrected}} = F_{1-\\alpha}(df'_{\\text{num}}, df'_{\\text{den}}) = F_{0.95}(2.4, 69.6)$\n\nThe Greenhouse-Geisser correction, by its nature (since $\\hat{\\epsilon}_{\\mathrm{GG}}  1$), reduces both the numerator and denominator degrees of freedom. A reduction in degrees of freedom causes the probability density function of the F-distribution to become more spread out (more platykurtic) and shifts the mass towards the right tail. Consequently, to maintain the same tail area $\\alpha$, the critical value must be larger.\n\nTherefore, $F_{\\text{crit, corrected}} > F_{\\text{crit, uncorrected}}$. This increase in the critical value makes the test more conservative, meaning a larger observed F-statistic is required to reject the null hypothesis. This conservativeness is the desired outcome, as it corrects the inflated Type I error rate that occurs when using the uncorrected degrees of freedom in the presence of a sphericity violation.\n\nThe final answer requires the corrected degrees of freedom as a two-entry row matrix. These are the calculated values $df'_{\\text{num}} = 2.4$ and $df'_{\\text{den}} = 69.6$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.4  69.6\n\\end{pmatrix}\n}\n$$", "id": "4836009"}]}