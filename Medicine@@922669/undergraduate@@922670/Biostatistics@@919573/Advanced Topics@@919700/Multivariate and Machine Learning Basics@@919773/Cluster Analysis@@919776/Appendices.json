{"hands_on_practices": [{"introduction": "The foundation of any cluster analysis is the choice of a distance or dissimilarity measure. While Euclidean distance is a common default, it can be misleading for certain data types, such as the count data found in RNA-sequencing experiments. This exercise guides you through deriving a more appropriate dissimilarity measure based on the Poisson deviance, a concept rooted in statistical likelihood theory, which naturally accounts for the mean-variance relationship inherent to count data [@problem_id:4900189].", "problem": "A biostatistician is clustering samples from a small RNA-sequencing experiment with zero-inflated count data. There are $3$ samples, labeled $A$, $B$, and $C$, and $4$ genes, labeled $g_1, g_2, g_3, g_4$. The observed counts (in the order $(g_1,g_2,g_3,g_4)$) are:\n- Sample $A$: $(0, 3, 12, 0)$\n- Sample $B$: $(1, 0, 7, 2)$\n- Sample $C$: $(0, 1, 15, 0)$\n\nAssume independence of genes and equal exposure across samples. To define a dissimilarity between two samples based on the Poisson model, proceed as follows. For a given gene $g$ and a pair of samples $(i,j)$ with observed counts $x_{gi}$ and $x_{gj}$, consider the Poisson probability mass function and the definition of deviance as twice the difference between the maximized log-likelihood under a saturated model and under a constrained model in which the two Poisson means are equal, that is, $\\lambda_{gi}=\\lambda_{gj}=\\mu_g$. Starting from these fundamental definitions, derive the per-gene contribution to the deviance and thereby the total deviance-based dissimilarity between two samples as the sum over genes. Use the natural logarithm, and adopt the conventions $0 \\ln(0/\\mu_g)=0$ and that a gene with $x_{gi}=x_{gj}=0$ contributes $0$ to the deviance. Do not introduce any additional pseudo-counts.\n\nCompute the pairwise deviance-based dissimilarities for the three pairs $(A,B)$, $(A,C)$, and $(B,C)$ using your derived expression, and then compute the average of these three pairwise dissimilarities. Round your final average to four significant figures. Express the final number without units.\n\nBriefly justify, based on your derivation, why this deviance-based dissimilarity is more robust to the mean-variance relationship inherent to count data than a Euclidean distance on raw counts.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, objective, and complete.\n\n### Step 1: Extract Givens\n-   Number of samples: $3$, labeled $A, B, C$.\n-   Number of genes: $4$, labeled $g_1, g_2, g_3, g_4$.\n-   Observed counts (in order $(g_1, g_2, g_3, g_4)$):\n    -   Sample $A$: $(0, 3, 12, 0)$\n    -   Sample $B$: $(1, 0, 7, 2)$\n    -   Sample $C$: $(0, 1, 15, 0)$\n-   Model: Poisson probability mass function.\n-   Assumptions: Independence of genes, equal exposure across samples.\n-   Dissimilarity definition: Deviance, defined as $D = 2 \\times (\\text{maximized log-likelihood of saturated model} - \\text{maximized log-likelihood of constrained model})$.\n-   Constraint for dissimilarity between samples $i$ and $j$: For a given gene $g$, the Poisson means are equal, $\\lambda_{gi} = \\lambda_{gj} = \\mu_g$.\n-   Logarithm: Natural logarithm, $\\ln$.\n-   Conventions: $0 \\ln(0/\\mu_g) = 0$; contribution is $0$ if $x_{gi}=x_{gj}=0$.\n-   No pseudo-counts are to be used.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, using standard principles of statistical modeling (Poisson distribution, likelihood, deviance) common in biostatistics for analyzing count data. It is well-posed, providing all necessary data, assumptions, and definitions to derive a unique solution. The terminology is objective and precise. The problem is complete and internally consistent. The calculations are feasible.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived and presented.\n\n### Derivation of Deviance-Based Dissimilarity\n\nLet us consider a single gene $g$ and a pair of samples $(i, j)$ with observed counts $x_{gi}$ and $x_{gj}$. The Poisson probability mass function for an observation $x$ with mean parameter $\\lambda$ is $P(x; \\lambda) = \\frac{\\exp(-\\lambda)\\lambda^x}{x!}$. The log-likelihood is $\\ell(\\lambda; x) = \\ln(P(x; \\lambda)) = x \\ln(\\lambda) - \\lambda - \\ln(x!)$.\n\n**1. Saturated Model Log-Likelihood:**\nIn the saturated model, each observation has its own parameter. For the pair of observations $(x_{gi}, x_{gj})$, the parameters are $\\lambda_{gi}$ and $\\lambda_{gj}$. The total log-likelihood is the sum of individual log-likelihoods due to the independence assumption:\n$$L_{sat}(\\lambda_{gi}, \\lambda_{gj}) = \\ell(\\lambda_{gi}; x_{gi}) + \\ell(\\lambda_{gj}; x_{gj}) = (x_{gi} \\ln \\lambda_{gi} - \\lambda_{gi} - \\ln(x_{gi}!)) + (x_{gj} \\ln \\lambda_{gj} - \\lambda_{gj} - \\ln(x_{gj}!))$$\nThe maximum likelihood estimates (MLEs) for the parameters are found by setting the partial derivatives to zero:\n$\\frac{\\partial L_{sat}}{\\partial \\lambda_{gi}} = \\frac{x_{gi}}{\\lambda_{gi}} - 1 = 0 \\implies \\hat{\\lambda}_{gi}^{\\text{sat}} = x_{gi}$\n$\\frac{\\partial L_{sat}}{\\partial \\lambda_{gj}} = \\frac{x_{gj}}{\\lambda_{gj}} - 1 = 0 \\implies \\hat{\\lambda}_{gj}^{\\text{sat}} = x_{gj}$\nSubstituting these MLEs back gives the maximized log-likelihood for the saturated model, $\\ell_{sat}$:\n$$\\ell_{sat} = (x_{gi} \\ln x_{gi} - x_{gi} - \\ln(x_{gi}!)) + (x_{gj} \\ln x_{gj} - x_{gj} - \\ln(x_{gj}!))$$\nHere we use the convention that $x \\ln x = 0$ if $x=0$.\n\n**2. Constrained Model Log-Likelihood:**\nIn the constrained model, we impose the null hypothesis that the means are equal: $\\lambda_{gi} = \\lambda_{gj} = \\mu_g$. The log-likelihood is:\n$$L_{con}(\\mu_g) = (x_{gi} \\ln \\mu_g - \\mu_g - \\ln(x_{gi}!)) + (x_{gj} \\ln \\mu_g - \\mu_g - \\ln(x_{gj}!))$$\n$$L_{con}(\\mu_g) = (x_{gi} + x_{gj}) \\ln \\mu_g - 2\\mu_g - \\ln(x_{gi}!) - \\ln(x_{gj}!)$$\nThe MLE for $\\mu_g$ is:\n$\\frac{\\partial L_{con}}{\\partial \\mu_g} = \\frac{x_{gi} + x_{gj}}{\\mu_g} - 2 = 0 \\implies \\hat{\\mu}_g = \\frac{x_{gi} + x_{gj}}{2}$\nSubstituting this back gives the maximized log-likelihood for the constrained model, $\\ell_{con}$:\n$$\\ell_{con} = (x_{gi} + x_{gj}) \\ln\\left(\\frac{x_{gi} + x_{gj}}{2}\\right) - 2\\left(\\frac{x_{gi} + x_{gj}}{2}\\right) - \\ln(x_{gi}!) - \\ln(x_{gj}!)$$\n$$\\ell_{con} = (x_{gi} + x_{gj}) \\ln\\left(\\frac{x_{gi} + x_{gj}}{2}\\right) - (x_{gi} + x_{gj}) - \\ln(x_{gi}!) - \\ln(x_{gj}!)$$\n\n**3. Per-Gene Deviance Contribution:**\nThe deviance contribution for gene $g$, denoted $d_g(i,j)$, is twice the difference in maximized log-likelihoods:\n$$d_g(i,j) = 2 (\\ell_{sat} - \\ell_{con})$$\n$$d_g(i,j) = 2 \\left[ (x_{gi} \\ln x_{gi} - x_{gi} + x_{gj} \\ln x_{gj} - x_{gj}) - \\left( (x_{gi} + x_{gj}) \\ln\\left(\\frac{x_{gi} + x_{gj}}{2}\\right) - (x_{gi} + x_{gj}) \\right) \\right]$$\nThe terms involving $-x_{gi}$ and $-x_{gj}$ cancel out:\n$$d_g(i,j) = 2 \\left[ x_{gi} \\ln x_{gi} + x_{gj} \\ln x_{gj} - (x_{gi} + x_{gj}) \\ln\\left(\\frac{x_{gi} + x_{gj}}{2}\\right) \\right]$$\nRearranging the terms using logarithm properties:\n$$d_g(i,j) = 2 \\left[ x_{gi} \\ln\\left(\\frac{x_{gi}}{(x_{gi} + x_{gj})/2}\\right) + x_{gj} \\ln\\left(\\frac{x_{gj}}{(x_{gi} + x_{gj})/2}\\right) \\right]$$\nThis is the general formula for the per-gene deviance contribution. If $x_{gi} = x_{gj} = 0$, the expression is $0$. If one count is zero (e.g., $x_{gi}=0, x_{gj}>0$), let $\\mu_g = x_{gj}/2$. The contribution from the first term is $0$ by the $0 \\ln(0/\\mu_g)=0$ convention. The contribution is $d_g(i,j) = 2 \\left[ x_{gj} \\ln\\left(\\frac{x_{gj}}{x_{gj}/2}\\right) \\right] = 2 x_{gj} \\ln(2)$.\n\n### Calculation of Pairwise Dissimilarities\nThe total dissimilarity $D_{ij}$ is the sum of per-gene deviances: $D_{ij} = \\sum_{g=1}^{4} d_g(i, j)$.\nData: $A=(0, 3, 12, 0)$, $B=(1, 0, 7, 2)$, $C=(0, 1, 15, 0)$.\n\n**Dissimilarity $D_{AB}$:**\n- $g_1$: $(x_{g1,A}, x_{g1,B}) = (0, 1)$. $d_1 = 2 \\times 1 \\times \\ln(2) = 2\\ln(2)$.\n- $g_2$: $(x_{g2,A}, x_{g2,B}) = (3, 0)$. $d_2 = 2 \\times 3 \\times \\ln(2) = 6\\ln(2)$.\n- $g_3$: $(x_{g3,A}, x_{g3,B}) = (12, 7)$. Mean $\\hat{\\mu}_{g3} = (12+7)/2 = 9.5$.\n$d_3 = 2 \\left[ 12 \\ln\\left(\\frac{12}{9.5}\\right) + 7 \\ln\\left(\\frac{7}{9.5}\\right) \\right]$.\n- $g_4$: $(x_{g4,A}, x_{g4,B}) = (0, 2)$. $d_4 = 2 \\times 2 \\times \\ln(2) = 4\\ln(2)$.\n$D_{AB} = 2\\ln(2) + 6\\ln(2) + d_3 + 4\\ln(2) = 12\\ln(2) + 2 \\left[ 12 \\ln\\left(\\frac{12}{9.5}\\right) + 7 \\ln\\left(\\frac{7}{9.5}\\right) \\right]$\n$D_{AB} \\approx 12(0.69315) + 2 [12(0.23363) + 7(-0.30538)] = 8.3178 + 2[2.80356 - 2.13766] = 8.3178 + 1.3318 = 9.6496$.\n\n**Dissimilarity $D_{AC}$:**\n- $g_1$: $(x_{g1,A}, x_{g1,C}) = (0, 0)$. $d_1 = 0$.\n- $g_2$: $(x_{g2,A}, x_{g2,C}) = (3, 1)$. Mean $\\hat{\\mu}_{g2} = (3+1)/2 = 2$.\n$d_2 = 2 \\left[ 3 \\ln\\left(\\frac{3}{2}\\right) + 1 \\ln\\left(\\frac{1}{2}\\right) \\right] = 6\\ln(1.5) - 2\\ln(2)$.\n- $g_3$: $(x_{g3,A}, x_{g3,C}) = (12, 15)$. Mean $\\hat{\\mu}_{g3} = (12+15)/2 = 13.5$.\n$d_3 = 2 \\left[ 12 \\ln\\left(\\frac{12}{13.5}\\right) + 15 \\ln\\left(\\frac{15}{13.5}\\right) \\right]$.\n- $g_4$: $(x_{g4,A}, x_{g4,C}) = (0, 0)$. $d_4 = 0$.\n$D_{AC} = d_2 + d_3 = (6\\ln(1.5) - 2\\ln(2)) + 2 \\left[ 12 \\ln\\left(\\frac{12}{13.5}\\right) + 15 \\ln\\left(\\frac{15}{13.5}\\right) \\right]$\n$D_{AC} \\approx (6(0.40547) - 2(0.69315)) + 2 [12(-0.11778) + 15(0.10536)] = (2.43282 - 1.3863) + 2[-1.41336 + 1.5804] = 1.04652 + 0.33408 = 1.3806$.\n\n**Dissimilarity $D_{BC}$:**\n- $g_1$: $(x_{g1,B}, x_{g1,C}) = (1, 0)$. $d_1 = 2 \\times 1 \\times \\ln(2) = 2\\ln(2)$.\n- $g_2$: $(x_{g2,B}, x_{g2,C}) = (0, 1)$. $d_2 = 2 \\times 1 \\times \\ln(2) = 2\\ln(2)$.\n- $g_3$: $(x_{g3,B}, x_{g3,C}) = (7, 15)$. Mean $\\hat{\\mu}_{g3} = (7+15)/2 = 11$.\n$d_3 = 2 \\left[ 7 \\ln\\left(\\frac{7}{11}\\right) + 15 \\ln\\left(\\frac{15}{11}\\right) \\right]$.\n- $g_4$: $(x_{g4,B}, x_{g4,C}) = (2, 0)$. $d_4 = 2 \\times 2 \\times \\ln(2) = 4\\ln(2)$.\n$D_{BC} = 2\\ln(2) + 2\\ln(2) + d_3 + 4\\ln(2) = 8\\ln(2) + 2 \\left[ 7 \\ln\\left(\\frac{7}{11}\\right) + 15 \\ln\\left(\\frac{15}{11}\\right) \\right]$\n$D_{BC} \\approx 8(0.69315) + 2 [7(-0.45199) + 15(0.31015)] = 5.5452 + 2[-3.16393 + 4.65225] = 5.5452 + 2.97664 = 8.5218$.\n\n### Final Average Calculation\nThe three pairwise dissimilarities are $D_{AB} \\approx 9.6496$, $D_{AC} \\approx 1.3806$, and $D_{BC} \\approx 8.5218$.\nThe average dissimilarity is:\n$$\\text{Average} = \\frac{D_{AB} + D_{AC} + D_{BC}}{3} = \\frac{9.6496 + 1.3806 + 8.5218}{3} = \\frac{19.5520}{3} \\approx 6.51733...$$\nRounding to four significant figures, the average is $6.517$.\n\n### Justification of Robustness\nThe deviance-based dissimilarity is more robust to the mean-variance relationship of count data than Euclidean distance for fundamental statistical reasons.\n1.  **Model-Based Foundation**: The deviance is derived directly from the log-likelihood of the Poisson model. This means it inherently accounts for the statistical properties of Poisson-distributed data, most notably the property that the variance equals the mean ($\\text{Var}(X) = \\text{E}[X] = \\lambda$).\n2.  **Variance Stabilization**: Euclidean distance is sensitive to the raw magnitude of counts. A difference of $5$ between counts of $10$ and $15$ contributes the same to the squared distance as a difference of $5$ between $100$ and $105$. However, in a Poisson framework, the variance for a mean of $100$ is much larger than for a mean of $10$. Therefore, a difference of $5$ is less significant for larger counts. The deviance formula, with terms of the form $x \\ln(x/\\mu)$, evaluates the discrepancy on a logarithmic scale relative to the mean. This transformation effectively stabilizes the variance, giving more appropriate weight to differences across the full range of expression levels. It correctly assesses that a change from $0$ to $3$ (as in gene $g_2$ for sample A vs B) is more significant evidence of a difference than a change from $7$ to $12$ (as in gene $g_3$), a fact reflected in their respective deviance contributions ($6\\ln(2) \\approx 4.16$ vs. $\\approx 1.33$), which is the opposite of the conclusion from squared Euclidean distances ($3^2=9$ vs. $5^2=25$).\n3.  **Measure of Evidence**: The deviance is fundamentally a statistical test statistic (related to the likelihood-ratio test) that quantifies the evidence against the null hypothesis that the two samples share the same mean expression level for a given gene. Euclidean distance is a purely geometric measure that lacks this statistical interpretation and is thus blind to the underlying data-generating process.\n\nIn summary, the deviance-based dissimilarity provides a statistically principled measure of distance that properly handles the heteroscedasticity (non-constant variance) inherent to count data.", "answer": "$$\n\\boxed{6.517}\n$$", "id": "4900189"}, {"introduction": "Clustering algorithms are powerful, but not infallible; understanding their limitations is key to robust data analysis. The popular $k$-means algorithm, for example, is notoriously sensitive to outliers, which can pull cluster centroids astray and lead to biologically nonsensical groupings. This practice problem provides a hands-on demonstration of this vulnerability and explores how a robust variant, trimmed $k$-means, can overcome this challenge by systematically ignoring extreme data points [@problem_id:4900186].", "problem": "A biostatistics researcher is analyzing a univariate gene expression biomarker measured across $n=11$ subjects. Due to a batch artifact, one subject exhibits an extreme value. Ignoring measurement noise for clarity, the data consist of two biologically meaningful groups and one outlier, specifically $n_{1}=5$ subjects with value $0$, $n_{2}=5$ subjects with value $10$, and one outlier at value $L>10$. The goal is to cluster the subjects into $k=2$ groups using the squared Euclidean distance. The biologically meaningful partition is that the $0$-valued subjects form one cluster and the $10$-valued subjects form the other, with the outlier handled by a robust procedure.\n\nThe definition of the $k$-means objective is the sum of squared deviations from the cluster means; formally, for a partition $\\{C_{1},C_{2}\\}$ with cluster means $m_{1}$ and $m_{2}$, the objective is $\\sum_{x\\in C_{1}}(x-m_{1})^{2}+\\sum_{x\\in C_{2}}(x-m_{2})^{2}$. Consider two plausible partitions of the dataset:\n- Partition I (biologically correct groups): cluster the $0$-valued subjects together and the $10$-valued subjects together, and assign the outlier to the cluster whose mean is closer to $L$.\n- Partition II (adversarial outlier isolation): place the outlier alone in one cluster and merge the two biological groups into the other cluster.\n\nUsing first principles and the objective definition, derive the critical outlier magnitude $L^{\\ast}$ such that for all $L>L^{\\ast}$, the global minimizer of the standard $k$-means objective over all $k=2$ partitions is Partition II rather than Partition I. Then, explain why an $\\alpha$-trimmed $k$-means procedure with trimming proportion $\\alpha=\\frac{1}{11}$ (which discards the $\\alpha$ fraction of observations with the largest squared residuals before computing cluster means) recovers the biologically correct two-group structure for any $L>L^{\\ast}$.\n\nExpress your final answer as the exact value of $L^{\\ast}$. Do not round.", "solution": "The relevant foundation is the definition of the $k$-means objective as the sum of squared deviations from cluster means. We will compare the objective values of the two candidate partitions and determine for which values of the outlier magnitude $L$ each partition yields the smaller objective.\n\nWe denote the dataset as $D=\\{0,0,0,0,0,10,10,10,10,10,L\\}$, with $n_{1}=5$ observations at $0$, $n_{2}=5$ observations at $10$, and one outlier at $L>10$. We use $k=2$ clusters and squared Euclidean distance.\n\nPartition I places the $0$-valued subjects in one cluster and the $10$-valued subjects in another cluster. Since $L>10$, the outlier is closer to $10$ than to $0$ and therefore, for the purpose of comparing objective values, it is natural to consider assigning $L$ to the cluster initially centered near $10$. Under this partition:\n- Cluster $C_{1}$ contains the five $0$-valued subjects, so its mean is $m_{1}=0$ and its within-cluster sum of squares is $\\sum_{x\\in C_{1}}(x-m_{1})^{2}=0$.\n- Cluster $C_{2}$ contains the five $10$-valued subjects and the outlier $L$, so its mean is \n$$\nm_{2}=\\frac{10\\cdot n_{2}+L}{n_{2}+1}=\\frac{50+L}{6}.\n$$\nThe sum of squared deviations in $C_{2}$ is\n$$\n\\sum_{x\\in C_{2}}(x-m_{2})^{2}=n_{2}\\,(10-m_{2})^{2}+(L-m_{2})^{2}.\n$$\nWe compute the deviations explicitly. First,\n$$\n10-m_{2}=10-\\frac{50+L}{6}=\\frac{60-(50+L)}{6}=\\frac{10-L}{6},\n$$\nand second,\n$$\nL-m_{2}=L-\\frac{50+L}{6}=\\frac{6L-(50+L)}{6}=\\frac{5L-50}{6}=\\frac{5(L-10)}{6}.\n$$\nTherefore,\n$$\n\\sum_{x\\in C_{2}}(x-m_{2})^{2}=5\\left(\\frac{10-L}{6}\\right)^{2}+\\left(\\frac{5(L-10)}{6}\\right)^{2}\n=\\frac{5(10-L)^{2}}{36}+\\frac{25(L-10)^{2}}{36}\n=\\frac{30(L-10)^{2}}{36}=\\frac{5}{6}(L-10)^{2}.\n$$\nThe total $k$-means objective for Partition I is thus\n$$\n\\text{SSE}_{\\text{I}}=0+\\frac{5}{6}(L-10)^{2}=\\frac{5}{6}(L-10)^{2}.\n$$\n\nPartition II isolates the outlier in its own cluster and merges the two biological groups into the other cluster. Under this partition:\n- Cluster $C_{1}$ contains the outlier alone, with mean $m_{1}=L$ and within-cluster sum of squares $0$.\n- Cluster $C_{2}$ contains the five $0$-valued subjects and the five $10$-valued subjects. Its mean is \n$$\nm_{2}=\\frac{0\\cdot n_{1}+10\\cdot n_{2}}{n_{1}+n_{2}}=\\frac{50}{10}=5.\n$$\nThe sum of squared deviations in $C_{2}$ is\n$$\n\\sum_{x\\in C_{2}}(x-m_{2})^{2}=5\\,(0-5)^{2}+5\\,(10-5)^{2}=5\\cdot 25+5\\cdot 25=250.\n$$\nThus the total objective for Partition II is\n$$\n\\text{SSE}_{\\text{II}}=0+250=250.\n$$\n\nWe determine the critical outlier magnitude $L^{\\ast}$ where the two partitions have equal objective:\n$$\n\\text{SSE}_{\\text{I}}=\\text{SSE}_{\\text{II}}\n\\quad\\Longleftrightarrow\\quad\n\\frac{5}{6}(L-10)^{2}=250.\n$$\nSolving for $L$,\n$$\n(L-10)^{2}=250\\cdot\\frac{6}{5}=50\\cdot 6=300,\n$$\nso\n$$\nL-10=\\sqrt{300}=10\\sqrt{3}.\n$$\nSince we are considering $L>10$, the relevant solution is\n$$\nL^{\\ast}=10+10\\sqrt{3}.\n$$\nFor any $L>L^{\\ast}$, we have $\\text{SSE}_{\\text{I}}>\\text{SSE}_{\\text{II}}$, so the global minimizer of the standard $k$-means objective with $k=2$ is Partition II, which isolates the outlier and merges the two biological groups, thereby failing to recover the biologically correct clusters.\n\nFinally, consider the $\\alpha$-trimmed $k$-means procedure with trimming proportion $\\alpha=\\frac{1}{11}$. Trimming at level $\\alpha=\\frac{1}{11}$ discards exactly one observation (since $n=11$) with the largest squared residual relative to the current centroids. For $L>10$, the outlier is the farthest point from either centroid in both candidate partitions and thus is the unique point that will be trimmed. After trimming $L$, the remaining dataset consists of five $0$-valued and five $10$-valued subjects. The optimal $k$-means partition of this trimmed dataset into $k=2$ clusters has means $0$ and $10$ and zero within-cluster dispersion, thereby recovering the biologically correct clustering irrespective of the magnitude of $L$ above $L^{\\ast}$. This demonstrates that the robust trimming recovers the correct clusters even in the adversarial regime where standard $k$-means fails due to the outlier.\n\nThe exact critical outlier magnitude is $L^{\\ast}=10+10\\sqrt{3}$.", "answer": "$$\\boxed{10+10\\sqrt{3}}$$", "id": "4900186"}, {"introduction": "In many biomedical studies, we obtain multiple clusterings of the same set of subjects from different data sources, such as transcriptomics and proteomics. A critical task is to quantify the degree of agreement between these partitions. This exercise introduces the Adjusted Rand Index (ARI), a powerful metric for comparing two clusterings, by deriving it from first principles and showing how it cleverly corrects for the amount of agreement that would be expected purely by chance [@problem_id:4900171].", "problem": "A biostatistics team evaluates the agreement between two unsupervised clusterings of patient subtypes obtained from transcriptomic and proteomic profiles of the same $n$ patients. Let partition $\\mathcal{U}$ have $r$ clusters and partition $\\mathcal{V}$ have $s$ clusters. For each pair $(i,j)$, let $n_{ij}$ denote the number of patients simultaneously in cluster $i$ of $\\mathcal{U}$ and cluster $j$ of $\\mathcal{V}$. Let the row sums be $a_{i}=\\sum_{j=1}^{s} n_{ij}$ and the column sums be $b_{j}=\\sum_{i=1}^{r} n_{ij}$, so that $\\sum_{i=1}^{r} a_{i}=\\sum_{j=1}^{s} b_{j}=n$. The biostatistics team uses the Adjusted Rand Index (ARI) to compare $\\mathcal{U}$ and $\\mathcal{V}$, defined by adjusting the Rand Index (RI), which is the fraction of patient pairs on which the two partitions agree, for chance agreement. The adjustment is with respect to a generalized hypergeometric model that preserves $\\{a_{i}\\}$ and $\\{b_{j}\\}$.\n\nStarting from the definition of the Rand Index as the fraction of agreeing pairs and using only basic combinatorial reasoning on pairs of patients, perform the following:\n\n1) Derive a closed-form expression for the Adjusted Rand Index in terms of $\\{n_{ij}\\}$, $\\{a_{i}\\}$, $\\{b_{j}\\}$, and $\\binom{\\cdot}{2}$, without introducing any new definitions beyond those given above.\n\n2) Under the generalized hypergeometric random labeling model that preserves $\\{a_{i}\\}$ and $\\{b_{j}\\}$, use first principles to compute the expected value of the unadjusted agreeing-pair count and explain why the Adjusted Rand Index has expected value $0$ under this model.\n\n3) Consider $n=\\;12$ patients labeled $\\{\\,1,2,3,4,5,6,7,8,9,10,11,12\\,\\}$. The transcriptomic clustering $\\mathcal{U}$ has $r=\\;3$ subtypes:\n- $U_{1}=\\{\\,1,2,3,4,5\\,\\}$,\n- $U_{2}=\\{\\,6,7,8,9\\,\\}$,\n- $U_{3}=\\{\\,10,11,12\\,\\}$.\n\nThe proteomic clustering $\\mathcal{V}$ has $s=\\;3$ subtypes:\n- $V_{1}=\\{\\,1,2,6,7\\,\\}$,\n- $V_{2}=\\{\\,3,4,8,9,10\\,\\}$,\n- $V_{3}=\\{\\,5,11,12\\,\\}$.\n\nCompute the Adjusted Rand Index between $\\mathcal{U}$ and $\\mathcal{V}$. Round your answer to four significant figures. No units are required.", "solution": "The problem statement is evaluated for validity.\n\n### Step 1: Extract Givens\n-   $n$: total number of patients.\n-   $\\mathcal{U}$: a partition of the $n$ patients into $r$ clusters, $\\{U_1, \\dots, U_r\\}$.\n-   $\\mathcal{V}$: a partition of the $n$ patients into $s$ clusters, $\\{V_1, \\dots, V_s\\}$.\n-   $n_{ij}$: the number of patients in cluster $i$ of $\\mathcal{U}$ and cluster $j$ of $\\mathcal{V}$, i.e., $n_{ij} = |U_i \\cap V_j|$.\n-   $a_i$: the size of cluster $i$ in $\\mathcal{U}$, $a_i = \\sum_{j=1}^{s} n_{ij}$.\n-   $b_j$: the size of cluster $j$ in $\\mathcal{V}$, $b_j = \\sum_{i=1}^{r} n_{ij}$.\n-   $\\sum_{i=1}^{r} a_{i}=\\sum_{j=1}^{s} b_{j}=n$.\n-   Rand Index (RI): the fraction of patient pairs on which the two partitions agree.\n-   Adjusted Rand Index (ARI): the RI adjusted for chance agreement, under a generalized hypergeometric model that preserves the marginal sums $\\{a_{i}\\}$ and $\\{b_{j}\\}$.\n-   Task 1: Derive a closed-form expression for ARI.\n-   Task 2: Under the specified model, compute the expected value of the unadjusted agreeing-pair count and explain why $E[\\text{ARI}]=0$.\n-   Task 3: For a specific case with $n=12$ and given partitions $\\mathcal{U}$ and $\\mathcal{V}$, compute the ARI rounded to four significant figures.\n    -   $n=12$.\n    -   $U_1=\\{\\,1,2,3,4,5\\,\\}$, $U_2=\\{\\,6,7,8,9\\,\\}$, $U_3=\\{\\,10,11,12\\,\\}$.\n    -   $V_1=\\{\\,1,2,6,7\\,\\}$, $V_2=\\{\\,3,4,8,9,10\\,\\}$, $V_3=\\{\\,5,11,12\\,\\}$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is grounded in the established statistical field of cluster analysis. The Rand Index, Adjusted Rand Index, and the generalized hypergeometric null model are standard, well-defined concepts in this field. It is a canonical problem in biostatistics.\n-   **Well-Posed**: The problem is well-posed. It asks for a derivation and a calculation based on clear and standard definitions. All necessary information is provided. A unique, meaningful solution exists.\n-   **Objective**: The problem is stated in precise, objective mathematical language, free from subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution\n\nThe solution is divided into the three tasks requested.\n\n#### 1) Derivation of the Adjusted Rand Index (ARI)\n\nThe total number of distinct pairs of patients is $\\binom{n}{2}$. The Rand Index (RI) is the fraction of these pairs that are \"agreeing\". An agreeing pair is a pair of patients that are either placed in the same cluster in both partitions or in different clusters in both partitions. We can categorize all pairs into four types based on the contingency table $(n_{ij})$:\n1.  Pairs in the same cluster in $\\mathcal{U}$ and the same cluster in $\\mathcal{V}$. The number of such pairs is $N_{11} = \\sum_{i=1}^{r} \\sum_{j=1}^{s} \\binom{n_{ij}}{2}$.\n2.  Pairs in the same cluster in $\\mathcalU$ but different clusters in $\\mathcalV$. The number of such pairs is $N_{10}$.\n3.  Pairs in different clusters in $\\mathcalU$ but the same cluster in $\\mathcalV$. The number of such pairs is $N_{01}$.\n4.  Pairs in different clusters in both $\\mathcalU$ and $\\mathcalV$. The number of such pairs is $N_{00}$.\n\nThe total number of pairs in the same cluster in $\\mathcal{U}$ is $S_U = \\sum_{i=1}^{r} \\binom{a_i}{2}$. The total number of pairs in the same cluster in $\\mathcal{V}$ is $S_V = \\sum_{j=1}^{s} \\binom{b_j}{2}$.\nFrom these, we can express $N_{10}$ and $N_{01}$:\n$N_{10} = S_U - N_{11} = \\sum_{i=1}^{r} \\binom{a_i}{2} - \\sum_{i=1}^{r} \\sum_{j=1}^{s} \\binom{n_{ij}}{2}$\n$N_{01} = S_V - N_{11} = \\sum_{j=1}^{s} \\binom{b_j}{2} - \\sum_{i=1}^{r} \\sum_{j=1}^{s} \\binom{n_{ij}}{2}$\n\nThe total number of pairs is $\\binom{n}{2} = N_{11} + N_{10} + N_{01} + N_{00}$.\nThe number of agreeing pairs is $A = N_{11} + N_{00}$. We can find $N_{00}$ by subtraction:\n$N_{00} = \\binom{n}{2} - N_{11} - N_{10} - N_{01} = \\binom{n}{2} - N_{11} - (S_U - N_{11}) - (S_V - N_{11}) = \\binom{n}{2} - S_U - S_V + N_{11}$.\nSo, the total number of agreeing pairs is:\n$A = N_{11} + N_{00} = N_{11} + \\left( \\binom{n}{2} - S_U - S_V + N_{11} \\right) = \\binom{n}{2} - S_U - S_V + 2N_{11}$.\nThe Rand Index is $RI = A / \\binom{n}{2}$.\n\nThe Adjusted Rand Index is defined in the form $\\text{ARI} = \\frac{\\text{Index} - E[\\text{Index}]}{\\text{Max Index} - E[\\text{Index}]}$. A common choice for the \"Index\" is $N_{11} = \\sum_{i,j}\\binom{n_{ij}}{2}$, the count of pairs in the same cluster in both partitions.\nUnder the generalized hypergeometric model, the partitions $\\mathcal{U}$ and $\\mathcal{V}$ are assumed to be independent, given the fixed marginal counts $\\{a_i\\}$ and $\\{b_j\\}$. The probability that a randomly chosen pair of patients is in the same cluster in $\\mathcal{U}$ is $p_U = S_U / \\binom{n}{2}$. The probability that a random pair is in the same cluster in $\\mathcal{V}$ is $p_V = S_V / \\binom{n}{2}$. Due to independence, the probability that a random pair is in the same cluster in both is $p_U p_V$.\nThe expected number of such pairs, $E[N_{11}]$, is the total number of pairs times this probability:\n$E[N_{11}] = \\binom{n}{2} \\times p_U \\times p_V = \\binom{n}{2} \\frac{S_U}{\\binom{n}{2}} \\frac{S_V}{\\binom{n}{2}} = \\frac{S_U S_V}{\\binom{n}{2}}$.\n$E\\left[\\sum_{i,j}\\binom{n_{ij}}{2}\\right] = \\frac{\\left(\\sum_i\\binom{a_i}{2}\\right) \\left(\\sum_j\\binom{b_j}{2}\\right)}{\\binom{n}{2}}$.\n\nThe \"Max Index\" is the maximum possible value of the index, which occurs under maximum agreement. This depends on the marginals $\\{a_i\\}$ and $\\{b_j\\}$. The value is not unique, but $\\frac{1}{2}(S_U + S_V)$ is used as a representative value, an average of the maximum possible $N_{11}$ if one partition is a refinement of the other.\nThus, the ARI is:\n$$ \\text{ARI} = \\frac{N_{11} - E[N_{11}]}{\\frac{1}{2}(S_U + S_V) - E[N_{11}]} $$\nSubstituting the expressions for $N_{11}$, $S_U$, $S_V$, and $E[N_{11}]$ gives the closed-form expression:\n$$ \\text{ARI} = \\frac{\\sum_{i,j}\\binom{n_{ij}}{2} - \\frac{\\left(\\sum_i\\binom{a_i}{2}\\right) \\left(\\sum_j\\binom{b_j}{2}\\right)}{\\binom{n}{2}}}{\\frac{1}{2}\\left(\\sum_i\\binom{a_i}{2} + \\sum_j\\binom{b_j}{2}\\right) - \\frac{\\left(\\sum_i\\binom{a_i}{2}\\right) \\left(\\sum_j\\binom{b_j}{2}\\right)}{\\binom{n}{2}}} $$\n\n#### 2) Expected Value of Agreeing-Pair Count and ARI\n\nThe unadjusted agreeing-pair count is $A = \\binom{n}{2} - S_U - S_V + 2N_{11}$.\nUnder the random labeling model, the marginals, and thus $S_U$ and $S_V$, are fixed. We must find the expectation of $A$. Using the linearity of expectation:\n$E[A] = E\\left[ \\binom{n}{2} - S_U - S_V + 2N_{11} \\right] = \\binom{n}{2} - S_U - S_V + 2E[N_{11}]$.\nSubstituting a previous result:\n$E[A] = \\binom{n}{2} - \\sum_i\\binom{a_i}{2} - \\sum_j\\binom{b_j}{2} + 2\\frac{\\left(\\sum_i\\binom{a_i}{2}\\right) \\left(\\sum_j\\binom{b_j}{2}\\right)}{\\binom{n}{2}}$.\n\nThe Adjusted Rand Index is constructed to have an expected value of $0$ under the null model. Let the index be a random variable $X = N_{11} = \\sum_{i,j}\\binom{n_{ij}}{2}$. The denominator of the ARI formula, $D = \\frac{1}{2}(S_U + S_V) - E[X]$, is a constant since the marginals are fixed. The ARI is the random variable $Y = \\frac{X - E[X]}{D}$.\nTo find its expectation:\n$E[\\text{ARI}] = E[Y] = E\\left[ \\frac{X - E[X]}{D} \\right]$.\nSince $D$ and $E[X]$ are constants, we can write:\n$E[\\text{ARI}] = \\frac{1}{D} E[X - E[X]] = \\frac{1}{D} (E[X] - E[E[X]])$.\nThe expectation of a constant is the constant itself, so $E[E[X]] = E[X]$.\nTherefore, $E[\\text{ARI}] = \\frac{1}{D} (E[X] - E[X]) = 0$.\nThe adjustment process subtracts the expected value of the index from the observed value in the numerator, which by construction centers the distribution of the numerator, and thus the entire index, at $0$ under the null hypothesis.\n\n#### 3) Calculation for the Specific Case\n\nGiven $n=12$.\nThe partitions are:\n$\\mathcal{U}: U_1=\\{\\,1,2,3,4,5\\,\\}$, $U_2=\\{\\,6,7,8,9\\,\\}$, $U_3=\\{\\,10,11,12\\,\\}$.\nThe cluster sizes are $a_1=5$, $a_2=4$, $a_3=3$.\n$\\mathcal{V}: V_1=\\{\\,1,2,6,7\\,\\}$, $V_2=\\{\\,3,4,8,9,10\\,\\}$, $V_3=\\{\\,5,11,12\\,\\}$.\nThe cluster sizes are $b_1=4$, $b_2=5$, $b_3=3$.\n\nFirst, we construct the contingency table of counts $n_{ij} = |U_i \\cap V_j|$:\n$n_{11} = |U_1 \\cap V_1| = |\\{\\,1,2\\,\\}| = 2$\n$n_{12} = |U_1 \\cap V_2| = |\\{\\,3,4\\,\\}| = 2$\n$n_{13} = |U_1 \\cap V_3| = |\\{\\,5\\,\\}| = 1$\n$n_{21} = |U_2 \\cap V_1| = |\\{\\,6,7\\,\\}| = 2$\n$n_{22} = |U_2 \\cap V_2| = |\\{\\,8,9\\,\\}| = 2$\n$n_{23} = |U_2 \\cap V_3| = |\\emptyset| = 0$\n$n_{31} = |U_3 \\cap V_1| = |\\emptyset| = 0$\n$n_{32} = |U_3 \\cap V_2| = |\\{\\,10\\,\\}| = 1$\n$n_{33} = |U_3 \\cap V_3| = |\\{\\,11,12\\,\\}| = 2$\nThe contingency table is:\n$$(n_{ij}) = \\begin{pmatrix} 2 & 2 & 1 \\\\ 2 & 2 & 0 \\\\ 0 & 1 & 2 \\end{pmatrix}$$\n\nNow we compute the terms for the ARI formula:\n1.  Index: $N_{11} = \\sum_{i,j}\\binom{n_{ij}}{2} = \\binom{2}{2}+\\binom{2}{2}+\\binom{1}{2}+\\binom{2}{2}+\\binom{2}{2}+\\binom{0}{2}+\\binom{0}{2}+\\binom{1}{2}+\\binom{2}{2}$\n    $N_{11} = 1 + 1 + 0 + 1 + 1 + 0 + 0 + 0 + 1 = 5$.\n2.  Sum of pairs for $\\mathcal{U}$: $S_U = \\sum_i\\binom{a_i}{2} = \\binom{5}{2} + \\binom{4}{2} + \\binom{3}{2} = 10 + 6 + 3 = 19$.\n3.  Sum of pairs for $\\mathcal{V}$: $S_V = \\sum_j\\binom{b_j}{2} = \\binom{4}{2} + \\binom{5}{2} + \\binom{3}{2} = 6 + 10 + 3 = 19$.\n4.  Total pairs: $\\binom{n}{2} = \\binom{12}{2} = \\frac{12 \\times 11}{2} = 66$.\n\nNow, we compute the components of the ARI formula:\n-   Expected Index: $E[N_{11}] = \\frac{S_U S_V}{\\binom{n}{2}} = \\frac{19 \\times 19}{66} = \\frac{361}{66}$.\n-   Max Index term: $\\frac{1}{2}(S_U + S_V) = \\frac{1}{2}(19+19) = 19$.\n\nFinally, we compute the ARI:\n$$ \\text{ARI} = \\frac{N_{11} - E[N_{11}]}{\\frac{1}{2}(S_U + S_V) - E[N_{11}]} = \\frac{5 - \\frac{361}{66}}{19 - \\frac{361}{66}} $$\n$$ \\text{ARI} = \\frac{\\frac{5 \\times 66 - 361}{66}}{\\frac{19 \\times 66 - 361}{66}} = \\frac{330 - 361}{1254 - 361} = \\frac{-31}{893} $$\nAs a decimal, this is $\\frac{-31}{893} \\approx -0.0347144456...$.\nRounding to four significant figures gives $-0.03471$.", "answer": "$$ \\boxed{-0.03471} $$", "id": "4900171"}]}