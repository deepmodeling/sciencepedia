{"hands_on_practices": [{"introduction": "Informed consent is a cornerstone of ethical medical practice, ensuring patient autonomy. However, the process of obtaining consent can create barriers that inadvertently limit participation. This exercise uses basic probability theory to model how technological improvements, such as transitioning to an electronic consent system, can impact completion rates. By quantifying the effects of improved accessibility and reduced dropout, you will learn to analyze how operational designs can either support or hinder the fulfillment of this core ethical principle. [@problem_id:4366350]", "problem": "A pathology biobank is transitioning its informed consent process from paper-based consent to Electronic Consent (e-consent). Informed consent, as defined by biomedical ethics, requires that participants receive adequate information, comprehend it, and voluntarily agree, without coercion. In the operational pathway for consent completion, two ethically relevant process factors often influence whether consent is completed: accessibility of the consent materials (which affects whether potential participants can engage with the process) and dropout during the consent process (which affects whether participants who begin the process ultimately finish). Under the paper-based process, the observed consent completion probability is $p_0$, defined as the probability that a randomly selected eligible patient completes consent under the existing paper workflow.\n\nThe biobank expects two ethical-process improvements with e-consent:\n- Improved accessibility: suppose that improved accessibility converts a fraction $\\Delta a$ of those who would not have completed under paper into completers under e-consent. Interpret $\\Delta a$ as a probability in the closed interval $[0,1]$ applied to the baseline non-completer pool.\n- Dropout reduction: suppose that reduced dropout converts a fraction $\\Delta d$ of those who would not have completed under paper into completers under e-consent. Interpret $\\Delta d$ as a probability in the closed interval $[0,1]$ applied to the baseline non-completer pool.\n\nAssume the two improvement mechanisms act independently on the baseline non-completer population and that they do not induce any unethical coercion that would inflate completion outside the ethically permissible domain, so all probabilities remain in $[0,1]$. Starting from the axioms of probability (complement rule and independence) and the operational definition of consent completion, derive the expected consent completion probability under e-consent as a single closed-form analytic expression in terms of $p_0$, $\\Delta a$, and $\\Delta d$. Express your final answer as a dimensionless probability (decimal or fraction). No numerical rounding is required for this problem.", "solution": "Let $p_0$ be the initial probability of consent completion under the paper-based process. The probability that a randomly selected patient is in the non-completer pool is, by the complement rule, $1 - p_0$.\n\nThe e-consent process introduces two independent mechanisms that can convert a patient from the non-completer pool into a completer.\n1.  **Improved Accessibility**: A fraction $\\Delta a$ of the non-completer pool is converted. The probability that a patient from this pool is *not* converted by this mechanism is $(1 - \\Delta a)$.\n2.  **Reduced Dropout**: A fraction $\\Delta d$ of the non-completer pool is converted. The probability that a patient from this pool is *not* converted by this mechanism is $(1 - \\Delta d)$.\n\nSince these two mechanisms are independent, the probability that a patient from the non-completer pool remains a non-completer (i.e., is not converted by *either* mechanism) is the product of the individual probabilities of non-conversion: $(1 - \\Delta a)(1 - \\Delta d)$.\n\nThe overall probability of a patient being a non-completer under the new e-consent system is the probability of being an initial non-completer multiplied by the probability of not being converted.\n$$ P(\\text{non-completion}_\\text{e-consent}) = (1 - p_0) \\times (1 - \\Delta a)(1 - \\Delta d) $$\nThe new probability of consent completion, $p_e$, is the complement of the new non-completion probability:\n$$ p_e = 1 - P(\\text{non-completion}_\\text{e-consent}) $$\nSubstituting the expression for the non-completion probability yields the final analytical expression:\n$$ p_e = 1 - (1 - p_0)(1 - \\Delta a)(1 - \\Delta d) $$\nThis expression represents the new total probability of consent completion, which is the sum of the original completers and the newly converted patients from the non-completer pool.", "answer": "$$\\boxed{1 - (1 - p_0)(1 - \\Delta a)(1 - \\Delta d)}$$", "id": "4366350"}, {"introduction": "A pathologist's duty to maintain patient confidentiality is paramount, especially when sharing valuable data for secondary research. This practice delves into a practical method for safeguarding privacy: $k$-anonymity. You will work with a hypothetical dataset to determine the minimum level of anonymization required to meet a specific ethical risk target. This exercise provides a concrete link between the abstract principle of privacy and the quantitative steps needed to uphold it in practice. [@problem_id:4366371]", "problem": "A hospital pathology service intends to share a de-identified dataset for secondary research under the ethical principle of confidentiality and regulatory expectations of privacy protection articulated in the Health Insurance Portability and Accountability Act (HIPAA). To bound re-identification risk while retaining analytic utility, the service adopts $k$-anonymity on quasi-identifiers: age, residential zipcode, and diagnosis. The team constrains generalization to clinically acceptable groupings: age is binned into decades, zipcode is truncated to its three-digit prefix, and diagnosis is grouped into three clinically meaningful categories.\n\nUnder these approved generalizations, the dataset forms equivalence classes defined by the triplet (age decade, three-digit zipcode prefix, diagnosis category). The counts of records in each equivalence class are:\n(30–39, 021**, infectious): $28$, (30–39, 021**, neoplasm): $31$, (30–39, 021**, autoimmune): $26$; (30–39, 022**, infectious): $24$, (30–39, 022**, neoplasm): $29$, (30–39, 022**, autoimmune): $33$; (40–49, 021**, infectious): $27$, (40–49, 021**, neoplasm): $35$, (40–49, 021**, autoimmune): $25$; (40–49, 022**, infectious): $32$, (40–49, 022**, neoplasm): $36$, (40–49, 022**, autoimmune): $30$.\n\nIn the absence of additional background knowledge beyond the quasi-identifiers, the service defines the per-equivalence-class re-identification risk as the probability that an attacker correctly matches a record when the attacker knows only the quasi-identifiers. The ethical requirement is that this per-class risk must not exceed a target $r$, with $r$ specified as $r=\\frac{1}{24}$.\n\nStarting from first principles of $k$-anonymity and the stated risk model, compute the minimal $k$ such that, after applying the approved generalizations, every equivalence class in the dataset simultaneously satisfies the requirement that the per-class re-identification risk is less than or equal to $r$. Report $k$ as an exact integer; no rounding is required.", "solution": "The problem requires the determination of the minimal integer $k$ for $k$-anonymity such that a specified re-identification risk constraint is met for all equivalence classes in a dataset.\n\nFirst, let us formalize the principles and definitions provided in the problem statement.\nThe quasi-identifiers are age, residential zipcode, and diagnosis. Generalizations are applied to these identifiers to form equivalence classes. An equivalence class is a set of records that are indistinguishable based on the generalized quasi-identifiers. In this problem, an equivalence class is defined by a unique triplet: (age decade, three-digit zipcode prefix, diagnosis category).\n\nLet $N_i$ be the number of records, or the size, of the $i$-th equivalence class. The problem provides the sizes for all equivalence classes resulting from the specified generalizations:\n$N_1 = 28$ for (30–39, 021**, infectious)\n$N_2 = 31$ for (30–39, 021**, neoplasm)\n$N_3 = 26$ for (30–39, 021**, autoimmune)\n$N_4 = 24$ for (30–39, 022**, infectious)\n$N_5 = 29$ for (30–39, 022**, neoplasm)\n$N_6 = 33$ for (30–39, 022**, autoimmune)\n$N_7 = 27$ for (40–49, 021**, infectious)\n$N_8 = 35$ for (40–49, 021**, neoplasm)\n$N_9 = 25$ for (40–49, 021**, autoimmune)\n$N_{10} = 32$ for (40–49, 022**, infectious)\n$N_{11} = 36$ for (40–49, 022**, neoplasm)\n$N_{12} = 30$ for (40–49, 022**, autoimmune)\n\nThe problem defines the per-equivalence-class re-identification risk. For a given equivalence class of size $N$, an attacker who knows the quasi-identifiers of a target individual knows that the individual's record is one of the $N$ records in that class. In the absence of additional background knowledge, each of these $N$ records is equally likely to be the correct one. Therefore, the probability of a correct match, defined as the re-identification risk $R$, is:\n$$ R = \\frac{1}{N} $$\n\nThe ethical requirement is that this per-class risk must not exceed a target value $r$. For each equivalence class $i$ with size $N_i$, the risk $R_i = \\frac{1}{N_i}$ must satisfy:\n$$ R_i \\le r $$\nSubstituting the definition of risk, we get:\n$$ \\frac{1}{N_i} \\le r $$\nThis inequality can be rearranged to find the minimum required size for any equivalence class:\n$$ N_i \\ge \\frac{1}{r} $$\nThis condition must hold for all equivalence classes in the dataset.\n\nThe problem specifies the target risk $r$ as:\n$$ r = \\frac{1}{24} $$\nSubstituting this value into our inequality for class size:\n$$ N_i \\ge \\frac{1}{\\frac{1}{24}} $$\n$$ N_i \\ge 24 $$\nThus, to satisfy the risk constraint, every equivalence class in the dataset must contain at least $24$ records.\n\nNext, we relate this requirement to the principle of $k$-anonymity. A dataset is said to be $k$-anonymous if every equivalence class contains at least $k$ records. Formally, for a dataset to satisfy $k$-anonymity, the size $N_i$ of every equivalence class must satisfy:\n$$ N_i \\ge k $$\nThe problem asks for the minimal integer $k$ such that this property ($k$-anonymity) ensures that the risk constraint is met. To ensure the risk constraint ($N_i \\ge 24$) is met for all classes, we must choose a value of $k$ that guarantees this condition.\n\nIf we set the anonymity level to $k$, we have $N_i \\ge k$ for all $i$. To guarantee that $N_i \\ge 24$, we must require that $k$ itself is at least $24$.\n$$ k \\ge 24 $$\nThe problem asks for the *minimal* integer $k$ that satisfies this condition. The smallest integer value for $k$ that is greater than or equal to $24$ is $24$.\nTherefore, the minimal $k$ is $24$.\n\nWe can verify this conclusion with the provided data. For the specified generalizations, the dataset's equivalence classes have sizes $\\{28, 31, 26, 24, 29, 33, 27, 35, 25, 32, 36, 30\\}$. The minimum size among these is:\n$$ N_{\\min} = \\min\\{28, 31, 26, 24, 29, 33, 27, 35, 25, 32, 36, 30\\} = 24 $$\nSince the minimum class size is $24$, the dataset as given is $24$-anonymous. Every class size $N_i$ satisfies $N_i \\ge 24$, which means the risk for every class, $R_i = \\frac{1}{N_i}$, satisfies $R_i \\le \\frac{1}{24}$. This confirms that the requirement is met for $k=24$. The dataset is not $25$-anonymous, because there is an equivalence class with only $24$ records. Thus, $24$ is indeed the minimal value of $k$ that both describes the required level of anonymity and is achieved by the given dataset.\nThe minimal $k$ is determined by the risk threshold $r$, not by the observed data, but the data confirms the consistency and feasibility of achieving this $k$ value. The minimal required $k$ is $\\lceil \\frac{1}{r} \\rceil$.\n$$ k = \\left\\lceil \\frac{1}{\\frac{1}{24}} \\right\\rceil = \\lceil 24 \\rceil = 24 $$", "answer": "$$\\boxed{24}$$", "id": "4366371"}, {"introduction": "At the heart of diagnostic pathology lies the challenge of making a definitive call from complex data, a decision that always carries the risk of error. This exercise provides a powerful framework for navigating the trade-off between missing a disease (a false negative) and an incorrect diagnosis (a false positive). By assigning 'utilities' to correct outcomes and 'costs' to errors, you will derive an optimal decision threshold that maximizes expected utility, translating abstract ethical priorities into a concrete, justifiable decision rule. [@problem_id:4366335]", "problem": "A pathology laboratory is validating a quantitative digital histopathology classifier that outputs a continuous malignancy score $x$ for each case. The lab must choose a decision threshold $t$ such that cases with $x \\geq t$ are called “malignant” and those with $x < t$ are called “benign.” The ethical impact of the decision is modeled by an expected utility function that aggregates clinical benefit and harm across outcomes. Let the disease prevalence be $p$, and let $U_{TP}$ and $U_{TN}$ denote the net ethical utility of true positive and true negative decisions, respectively. Let $U_{FP}$ and $U_{FN}$ denote the nonnegative magnitudes of ethical harm (treated as costs) for false positive and false negative decisions, respectively. The expected utility as a function of threshold $t$ is\n$$\nU(t) \\;=\\; p \\cdot U_{TP}\\cdot \\mathrm{TPR}(t)\\;+\\;(1-p)\\cdot U_{TN}\\cdot \\big(1-\\mathrm{FPR}(t)\\big)\\;-\\;(1-p)\\cdot U_{FP}\\cdot \\mathrm{FPR}(t)\\;-\\;p \\cdot U_{FN}\\cdot \\big(1-\\mathrm{TPR}(t)\\big),\n$$\nwhere $\\mathrm{TPR}(t)$ is the True Positive Rate (TPR) at threshold $t$, and $\\mathrm{FPR}(t)$ is the False Positive Rate (FPR) at threshold $t$.\n\nAssume the classifier score $x$ follows a Gaussian distribution conditional on disease status:\n- for malignant cases, $x \\sim \\mathcal{N}(\\mu_{D},\\sigma^{2})$;\n- for benign cases, $x \\sim \\mathcal{N}(\\mu_{N},\\sigma^{2})$,\nwith equal variance $\\sigma^{2}$ and means $\\mu_{D} > \\mu_{N}$. Under the decision rule “malignant if $x \\geq t$,” the rates are\n$$\n\\mathrm{TPR}(t) \\;=\\; \\int_{t}^{\\infty} f_{D}(x)\\,dx,\\qquad \\mathrm{FPR}(t) \\;=\\; \\int_{t}^{\\infty} f_{N}(x)\\,dx,\n$$\nwhere $f_{D}$ and $f_{N}$ are the respective normal probability density functions.\n\nStarting from the core definitions of expected utility and these probability laws, derive the threshold $t^{*}$ that maximizes $U(t)$ and then compute its numerical value for the following scientifically plausible parameterization reflecting ethical priorities in cancer diagnosis:\n- prevalence $p = 0.15$,\n- malignant-score mean $\\mu_{D} = 3.2$,\n- benign-score mean $\\mu_{N} = 1.8$,\n- common standard deviation $\\sigma = 0.6$,\n- $U_{TP} = 9$, $U_{TN} = 3$, $U_{FP} = 2$, $U_{FN} = 20$.\n\nExpress the final threshold in score units, and round your answer to four significant figures.", "solution": "The goal is to find the decision threshold $t^*$ that maximizes the expected utility function $U(t)$. This is an optimization problem that can be solved by setting the derivative of $U(t)$ with respect to $t$ to zero.\n\nFirst, we rewrite the expected utility function to group terms by the True Positive Rate ($\\mathrm{TPR}(t)$) and False Positive Rate ($\\mathrm{FPR}(t)$):\n$$\nU(t) = p(U_{TP} + U_{FN})\\mathrm{TPR}(t) - (1-p)(U_{TN} + U_{FP})\\mathrm{FPR}(t) + \\mathrm{Constant}\n$$\nTo find the maximum, we compute the derivative $\\frac{dU}{dt}$. Using the Fundamental Theorem of Calculus, the derivatives of the rates are $\\frac{d}{dt}\\mathrm{TPR}(t) = -f_{D}(t)$ and $\\frac{d}{dt}\\mathrm{FPR}(t) = -f_{N}(t)$, where $f_D$ and $f_N$ are the probability density functions for the malignant and benign scores, respectively.\n\nDifferentiating the utility function gives:\n$$\n\\frac{dU}{dt} = -p(U_{TP} + U_{FN})f_{D}(t) + (1-p)(U_{TN} + U_{FP})f_{N}(t)\n$$\nSetting the derivative to zero at the optimal threshold $t^*$ yields:\n$$\np(U_{TP} + U_{FN})f_{D}(t^*) = (1-p)(U_{TN} + U_{FP})f_{N}(t^*)\n$$\nThis can be expressed as a condition on the likelihood ratio:\n$$\n\\frac{f_D(t^*)}{f_N(t^*)} = \\frac{(1-p)(U_{TN} + U_{FP})}{p(U_{TP} + U_{FN})}\n$$\nThe scores are modeled as normal distributions with PDFs $f_{D}(t) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(t-\\mu_D)^2}{2\\sigma^2}\\right)$ and $f_{N}(t) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(t-\\mu_N)^2}{2\\sigma^2}\\right)$. The likelihood ratio becomes:\n$$\n\\frac{f_D(t^*)}{f_N(t^*)} = \\exp\\left(\\frac{(t^*-\\mu_N)^2 - (t^*-\\mu_D)^2}{2\\sigma^2}\\right)\n$$\nLet the constant term on the right side of the likelihood ratio equation be $C$. Taking the natural logarithm of both sides and solving for $t^*$ gives:\n$$\n\\frac{(t^*-\\mu_N)^2 - (t^*-\\mu_D)^2}{2\\sigma^2} = \\ln(C)\n$$\n$$\n2t^*(\\mu_D - \\mu_N) - (\\mu_D^2 - \\mu_N^2) = 2\\sigma^2\\ln(C)\n$$\nSolving for $t^*$, we arrive at the general formula for the optimal threshold:\n$$\nt^* = \\frac{\\mu_D + \\mu_N}{2} + \\frac{\\sigma^2}{\\mu_D - \\mu_N} \\ln\\left( \\frac{(1-p)(U_{TN} + U_{FP})}{p(U_{TP} + U_{FN})} \\right)\n$$\nNow, we substitute the given numerical values:\n- $p = 0.15$, $\\mu_{D} = 3.2$, $\\mu_{N} = 1.8$, $\\sigma = 0.6$\n- $U_{TP} = 9$, $U_{TN} = 3$, $U_{FP} = 2$, $U_{FN} = 20$\n\nFirst, calculate the components of the formula:\n- First term: $\\frac{\\mu_D + \\mu_N}{2} = \\frac{3.2 + 1.8}{2} = 2.5$\n- Denominator of the second term: $\\mu_D - \\mu_N = 3.2 - 1.8 = 1.4$\n- Numerator of the second term: $\\sigma^2 = (0.6)^2 = 0.36$\n- The argument of the logarithm, $C$:\n$$\nC = \\frac{(1-0.15)(3 + 2)}{0.15(9 + 20)} = \\frac{0.85 \\times 5}{0.15 \\times 29} = \\frac{4.25}{4.35} \\approx 0.977011\n$$\nSubstitute these into the expression for $t^*$:\n$$\nt^* = 2.5 + \\frac{0.36}{1.4} \\ln\\left(\\frac{4.25}{4.35}\\right)\n$$\n$$\nt^* \\approx 2.5 + (0.25714) \\times \\ln(0.977011)\n$$\n$$\nt^* \\approx 2.5 + (0.25714) \\times (-0.023258)\n$$\n$$\nt^* \\approx 2.5 - 0.005981\n$$\n$$\nt^* \\approx 2.494019\n$$\nRounding to four significant figures, the optimal threshold is $2.494$.", "answer": "$$\n\\boxed{2.494}\n$$", "id": "4366335"}]}