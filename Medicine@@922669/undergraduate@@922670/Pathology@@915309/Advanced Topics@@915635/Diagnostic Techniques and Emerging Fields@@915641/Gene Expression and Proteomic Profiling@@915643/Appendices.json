{"hands_on_practices": [{"introduction": "Before collecting any data, designing a robust experiment is the most critical step for ensuring meaningful results. This practice explores the statistical advantages of using paired samples, a common and powerful technique in pathology where tissues are matched within the same individual. By working through the derivation, you will gain a quantitative understanding of why pairing samples, such as tumor and adjacent normal tissue from the same patient, can dramatically increase statistical power by reducing inter-individual biological variability [@problem_id:4373689].", "problem": "In a pathology study of gene expression using Deoxyribonucleic Acid (DNA) microarrays, investigators compare log-base-2 expression values between tumor tissue and patient-matched adjacent normal tissue to detect a mean difference in expression. Consider two experimental designs that use the same total number of tissue samples, $N$: (i) an unpaired design with $N/2$ independent tumor samples and $N/2$ independent normal samples, and (ii) a paired design with $N/2$ matched pairs, each pair consisting of a tumor and its adjacent normal from the same patient.\n\nAssume the following scientifically realistic and widely used modeling assumptions for log-base-2 expression of a given gene:\n- Within each condition (tumor or normal), individual-level expression has the same variance, denoted $\\sigma^{2}$.\n- Across conditions within the same patient, the tumor and normal expression measurements have correlation $\\rho$ and covariance $\\rho \\sigma^{2}$.\n- The true mean difference in expression (tumor minus normal) is $\\delta$.\n- Large-sample normal approximations apply for test statistics based on sample means.\n\nStarting only from the core definitions of variance, covariance, and correlation, derive how the paired design reduces the variance of the estimator of the mean difference compared to the unpaired design. Define the “power gain factor” as the ratio of the noncentrality parameter under the paired design to that under the unpaired design when both designs use the same total $N$ and target the same $\\delta$. Using a correlation $\\rho = 0.60$, compute this power gain factor as a single number. Round your answer to four significant figures. No units are required in the final answer.", "solution": "The problem statement is first validated against the required criteria.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Total number of samples: $N$.\n- Unpaired design: $n_T = N/2$ independent tumor samples and $n_N = N/2$ independent normal samples.\n- Paired design: $n_p = N/2$ matched pairs of (tumor, normal) samples.\n- Variance of log-base-2 expression for any sample (tumor or normal): $\\sigma^2$.\n- Correlation between paired tumor and normal samples from the same patient: $\\rho$.\n- Covariance between paired tumor and normal samples: $\\rho\\sigma^2$.\n- True mean difference in expression (tumor minus normal): $\\delta$.\n- Assumption: Large-sample normal approximations apply for test statistics.\n- Task: Derive the variance reduction of the paired design's estimator compared to the unpaired design's.\n- Task: Define and calculate the \"power gain factor\" as the ratio of noncentrality parameters (paired to unpaired) for $\\rho = 0.60$, rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is based on standard statistical principles applied to a common scenario in biomedical research (microarray analysis). The assumptions of equal variance, correlation in paired samples, and the use of large-sample theory are scientifically sound and routine in biostatistics.\n- **Well-Posed:** The problem is clearly defined with all necessary variables and parameters ($\\sigma^2$, $\\rho$, $\\delta$, $N$). The objectives are specific and lead to a unique, derivable solution.\n- **Objective:** The language is formal, precise, and free of any subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, scientifically grounded problem in biostatistics. The solution process may proceed.\n\n### Derivation and Solution\n\nThe objective is to compare the statistical properties of the estimators for the mean difference, $\\delta$, under two different experimental designs.\n\n**1. Unpaired Design Analysis**\n\nIn the unpaired design, we have two independent groups of samples: tumor samples $T_1, T_2, \\ldots, T_{N/2}$ and normal samples $N_1, N_2, \\ldots, N_{N/2}$.\nThe sample mean for the tumor group is $\\bar{T} = \\frac{2}{N}\\sum_{i=1}^{N/2} T_i$, and for the normal group is $\\bar{N} = \\frac{2}{N}\\sum_{j=1}^{N/2} N_j$.\nThe estimator for the mean difference $\\delta$ is $\\hat{\\delta}_{\\text{unpaired}} = \\bar{T} - \\bar{N}$.\n\nTo assess the precision of this estimator, we compute its variance. Since the two groups of samples are independent, their sample means $\\bar{T}$ and $\\bar{N}$ are also independent. The variance of a difference of independent random variables is the sum of their variances:\n$$\n\\text{Var}(\\hat{\\delta}_{\\text{unpaired}}) = \\text{Var}(\\bar{T} - \\bar{N}) = \\text{Var}(\\bar{T}) + \\text{Var}(\\bar{N})\n$$\nThe variance of a sample mean of $k$ independent, identically distributed random variables with variance $\\sigma^2$ is $\\frac{\\sigma^2}{k}$.\nFor the tumor group, with $k = N/2$ samples:\n$$\n\\text{Var}(\\bar{T}) = \\frac{\\text{Var}(T_i)}{N/2} = \\frac{\\sigma^2}{N/2} = \\frac{2\\sigma^2}{N}\n$$\nSimilarly, for the normal group, with $k = N/2$ samples:\n$$\n\\text{Var}(\\bar{N}) = \\frac{\\text{Var}(N_j)}{N/2} = \\frac{\\sigma^2}{N/2} = \\frac{2\\sigma^2}{N}\n$$\nSubstituting these into the expression for the variance of the estimator:\n$$\n\\text{Var}(\\hat{\\delta}_{\\text{unpaired}}) = \\frac{2\\sigma^2}{N} + \\frac{2\\sigma^2}{N} = \\frac{4\\sigma^2}{N}\n$$\n\n**2. Paired Design Analysis**\n\nIn the paired design, we have $n_p = N/2$ pairs of samples $(T_i, N_i)$ for $i=1, 2, \\ldots, N/2$. The key difference from the unpaired design is that $T_i$ and $N_i$ are correlated. We analyze the differences within each pair, $D_i = T_i - N_i$.\nThe estimator for the mean difference $\\delta$ is the mean of these individual differences:\n$$\n\\hat{\\delta}_{\\text{paired}} = \\bar{D} = \\frac{1}{N/2}\\sum_{i=1}^{N/2} D_i = \\frac{2}{N}\\sum_{i=1}^{N/2} (T_i - N_i)\n$$\nThe variance of this estimator is the variance of the sample mean of the differences:\n$$\n\\text{Var}(\\hat{\\delta}_{\\text{paired}}) = \\text{Var}(\\bar{D}) = \\frac{\\text{Var}(D_i)}{N/2}\n$$\nTo proceed, we must find the variance of a single difference, $\\text{Var}(D_i) = \\text{Var}(T_i - N_i)$. Using the general formula for the variance of a difference of two random variables, $\\text{Var}(X - Y) = \\text{Var}(X) + \\text{Var}(Y) - 2\\text{Cov}(X, Y)$:\n$$\n\\text{Var}(D_i) = \\text{Var}(T_i) + \\text{Var}(N_i) - 2\\text{Cov}(T_i, N_i)\n$$\nWe are given $\\text{Var}(T_i) = \\sigma^2$, $\\text{Var}(N_i) = \\sigma^2$, and $\\text{Cov}(T_i, N_i) = \\rho\\sigma^2$. Substituting these values:\n$$\n\\text{Var}(D_i) = \\sigma^2 + \\sigma^2 - 2\\rho\\sigma^2 = 2\\sigma^2 - 2\\rho\\sigma^2 = 2\\sigma^2(1 - \\rho)\n$$\nNow we can find the variance of the estimator for the paired design:\n$$\n\\text{Var}(\\hat{\\delta}_{\\text{paired}}) = \\frac{\\text{Var}(D_i)}{N/2} = \\frac{2\\sigma^2(1 - \\rho)}{N/2} = \\frac{4\\sigma^2(1 - \\rho)}{N}\n$$\n\n**3. Variance Reduction and Power Gain Factor**\n\nFirst, we compare the variances to show the reduction. The ratio of the variances is:\n$$\n\\frac{\\text{Var}(\\hat{\\delta}_{\\text{paired}})}{\\text{Var}(\\hat{\\delta}_{\\text{unpaired}})} = \\frac{4\\sigma^2(1 - \\rho)/N}{4\\sigma^2/N} = 1 - \\rho\n$$\nSince patient-matched tissues typically exhibit positive correlation ($\\rho  0$), the factor $(1 - \\rho)$ is less than $1$. This demonstrates that the paired design reduces the variance of the estimator of the mean difference by a factor of $(1 - \\rho)$ compared to an unpaired design with the same total number of samples.\n\nNext, we address the power gain factor. Under large-sample assumptions, the statistical power of a test is a monotonically increasing function of the magnitude of its noncentrality parameter (NCP), typically denoted $\\lambda$. The NCP for a z-test of a mean is defined as the true mean divided by the standard error of the estimator: $\\lambda = \\frac{\\delta}{\\sqrt{\\text{Var}(\\hat{\\delta})}}$.\n\nFor the unpaired design, the NCP is:\n$$\n\\lambda_{\\text{unpaired}} = \\frac{\\delta}{\\sqrt{\\text{Var}(\\hat{\\delta}_{\\text{unpaired}})}} = \\frac{\\delta}{\\sqrt{4\\sigma^2/N}} = \\frac{\\delta\\sqrt{N}}{2\\sigma}\n$$\nFor the paired design, the NCP is:\n$$\n\\lambda_{\\text{paired}} = \\frac{\\delta}{\\sqrt{\\text{Var}(\\hat{\\delta}_{\\text{paired}})}} = \\frac{\\delta}{\\sqrt{4\\sigma^2(1-\\rho)/N}} = \\frac{\\delta\\sqrt{N}}{2\\sigma\\sqrt{1-\\rho}}\n$$\nThe power gain factor is defined as the ratio of these noncentrality parameters:\n$$\n\\text{Power Gain Factor} = \\frac{\\lambda_{\\text{paired}}}{\\lambda_{\\text{unpaired}}} = \\frac{\\frac{\\delta\\sqrt{N}}{2\\sigma\\sqrt{1-\\rho}}}{\\frac{\\delta\\sqrt{N}}{2\\sigma}} = \\frac{1}{\\sqrt{1-\\rho}}\n$$\n\n**4. Numerical Calculation**\n\nWe are asked to compute this factor for a correlation of $\\rho = 0.60$:\n$$\n\\text{Power Gain Factor} = \\frac{1}{\\sqrt{1 - 0.60}} = \\frac{1}{\\sqrt{0.40}}\n$$\nNumerically, this is:\n$$\n\\frac{1}{\\sqrt{0.40}} \\approx \\frac{1}{0.6324555...} \\approx 1.5811388...\n$$\nRounding the result to four significant figures gives $1.581$.", "answer": "$$\n\\boxed{1.581}\n$$", "id": "4373689"}, {"introduction": "Once expression data is generated, the fundamental task is to identify which genes or proteins show a statistically significant difference between conditions. This exercise focuses on the core statistical tool for this comparison: the two-sample Student's $t$-test. This practice will solidify your understanding of hypothesis testing by having you compute the test statistic from summary data, a foundational skill for interpreting the results of any differential expression analysis [@problem_id:4373782].", "problem": "In a pathology study using high-density gene expression microarrays, investigators compare the Messenger Ribonucleic Acid (mRNA) expression of a matrix metalloproteinase gene between invasive carcinoma tissue and adjacent histologically normal tissue. After robust normalization and batch correction, replicate expression intensities for a single gene within each group are treated as independent and approximately normally distributed with a common variance due to the equal-variance post-normalization assumption.\n\nLet the carcinoma group have sample size $n_{1}$ and the normal group have sample size $n_{2}$. Denote the sample means by $\\bar{x}_{1}$ and $\\bar{x}_{2}$, respectively. A pooled estimate of the within-group standard deviation is available and denoted $s_{p}$. Under the model that each group consists of independent measurements with common variance and that the difference of group means is assessed by standardizing with the pooled standard deviation, derive the appropriate standardized test statistic for the difference in means from first principles and compute its numerical value for the following data:\n$\\bar{x}_{1} = 7.8$, $\\bar{x}_{2} = 6.9$, $s_{p} = 0.45$, $n_{1} = 5$, and $n_{2} = 6$.\n\nState your final numerical result for the standardized test statistic. Round your answer to four significant figures. No units are required for the final answer.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and internally consistent, meeting all criteria for a valid problem. We proceed with the solution.\n\nThe task is to derive and compute the standardized test statistic for the difference in means between two independent groups, assuming normality and a common variance. This corresponds to the two-sample Student's t-test.\n\nLet the gene expression measurements from the carcinoma group be $X_{1,1}, X_{1,2}, \\dots, X_{1,n_1}$ and from the normal group be $X_{2,1}, X_{2,2}, \\dots, X_{2,n_2}$. According to the problem statement, we model these as independent random samples from normal distributions with a common variance $\\sigma^2$. Specifically, $X_{1,i} \\sim N(\\mu_1, \\sigma^2)$ for $i=1, \\dots, n_1$ and $X_{2,j} \\sim N(\\mu_2, \\sigma^2)$ for $j=1, \\dots, n_2$.\n\nThe objective is to test a hypothesis about the difference between the population means, $\\mu_1 - \\mu_2$. The standard null hypothesis, $H_0$, posits no difference between the means, i.e., $H_0: \\mu_1 - \\mu_2 = 0$.\n\nThe point estimator for the difference in population means is the difference in sample means, $\\bar{X}_1 - \\bar{X}_2$. To standardize this estimator, we must determine its sampling distribution. The expected value of the difference is:\n$$E[\\bar{X}_1 - \\bar{X}_2] = E[\\bar{X}_1] - E[\\bar{X}_2] = \\mu_1 - \\mu_2$$\nBecause the two samples are independent, the variance of the difference is the sum of the variances of the individual sample means:\n$$\\text{Var}(\\bar{X}_1 - \\bar{X}_2) = \\text{Var}(\\bar{X}_1) + \\text{Var}(\\bar{X}_2)$$\nThe variance of a sample mean from a population with variance $\\sigma^2$ is $\\frac{\\sigma^2}{n}$. Thus,\n$$\\text{Var}(\\bar{X}_1 - \\bar{X}_2) = \\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2} = \\sigma^2 \\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)$$\nThe standard deviation of the difference of the means, referred to as the standard error of the difference, is:\n$$\\text{SE}(\\bar{X}_1 - \\bar{X}_2) = \\sigma \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}$$\nIn a typical scenario, the population standard deviation $\\sigma$ is unknown. It must be estimated from the sample data. The problem provides a pooled estimate of the within-group standard deviation, denoted by $s_p$. This is the square root of the pooled variance, $s_p^2$, which is the unbiased estimator for the common variance $\\sigma^2$. It is calculated by taking a weighted average of the individual sample variances, $s_1^2$ and $s_2^2$:\n$$s_p^2 = \\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}$$\nWe replace the unknown population standard deviation $\\sigma$ with its estimate $s_p$. This gives the estimated standard error of the difference:\n$$\\text{SE}_{\\text{est}}(\\bar{x}_1 - \\bar{x}_2) = s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}$$\nThe standardized test statistic is formed by taking the difference between the observed value $(\\bar{x}_1 - \\bar{x}_2)$ and its expected value under the null hypothesis $(\\mu_1 - \\mu_2 = 0)$, and dividing by its estimated standard error. This statistic follows a Student's t-distribution with $df = n_1 + n_2 - 2$ degrees of freedom.\nThe derivation from first principles yields the following formula for the t-statistic:\n$$t = \\frac{(\\bar{x}_1 - \\bar{x}_2) - (\\mu_1 - \\mu_2)}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\nUnder the null hypothesis $H_0: \\mu_1 - \\mu_2 = 0$, this simplifies to:\n$$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}$$\nThis is the required test statistic. We now compute its value using the provided data:\nSample mean of carcinoma group: $\\bar{x}_1 = 7.8$\nSample mean of normal group: $\\bar{x}_2 = 6.9$\nSample size of carcinoma group: $n_1 = 5$\nSample size of normal group: $n_2 = 6$\nPooled standard deviation: $s_p = 0.45$\n\nFirst, compute the numerator, which is the difference in sample means:\n$$\\bar{x}_1 - \\bar{x}_2 = 7.8 - 6.9 = 0.9$$\nNext, compute the term in the denominator involving the sample sizes:\n$$\\frac{1}{n_1} + \\frac{1}{n_2} = \\frac{1}{5} + \\frac{1}{6} = \\frac{6}{30} + \\frac{5}{30} = \\frac{11}{30}$$\nNow, substitute these values into the t-statistic formula:\n$$t = \\frac{0.9}{0.45 \\sqrt{\\frac{11}{30}}}$$\nThis expression can be simplified algebraically:\n$$t = \\frac{2}{\\sqrt{\\frac{11}{30}}} = 2 \\sqrt{\\frac{30}{11}}$$\nWe compute the numerical value of this expression:\n$$t \\approx 2 \\sqrt{2.727272...} \\approx 2 \\times 1.6514455... \\approx 3.302891$$\nThe problem requires the final answer to be rounded to four significant figures.\n$$t \\approx 3.303$$", "answer": "$$\\boxed{3.303}$$", "id": "4373782"}, {"introduction": "A key challenge in modern 'omics' research is the sheer scale of the data; a single experiment can involve testing tens of thousands of hypotheses simultaneously. This creates a significant risk of accumulating false positives. This final practice demonstrates how to manage this issue by applying the Benjamini–Hochberg procedure to control the False Discovery Rate (FDR), providing you with a hands-on walkthrough of a crucial step needed to produce a reliable list of differentially expressed genes [@problem_id:4373694].", "problem": "A pathology laboratory compares messenger ribonucleic acid (mRNA) expression between tumor and adjacent normal tissue using a complementary deoxyribonucleic acid (cDNA) microarray. For each gene, a two-sample Student's $t$-test evaluates the null hypothesis that the mean expression is equal across conditions. The resulting $p$-values arise from $m$ independent hypotheses. In high-dimensional settings like gene expression profiling, controlling the rate of false positives across many simultaneous tests is essential; the False Discovery Rate (FDR) is defined as the expected proportion of false positives among all declared discoveries. The Benjamini–Hochberg (BH) procedure is a step-up method designed to control the FDR at a chosen target level.\n\nYou are given $m = 20$ raw $p$-values from the tumor-versus-normal differential expression analysis:\n$$\n\\{\\,0.021,\\;0.200,\\;0.0030,\\;0.041,\\;0.012,\\;0.00030,\\;0.026,\\;0.052,\\;0.073,\\;0.032,\\;0.110,\\;0.018,\\;0.061,\\;0.0075,\\;0.350,\\;0.0011,\\;0.0042,\\;0.088,\\;0.0090,\\;0.0027\\,\\}.\n$$\n\nStarting from foundational principles of multiple hypothesis testing and the definition of the False Discovery Rate, apply the Benjamini–Hochberg FDR control at target level $q^{*} = 0.050$ to determine the number $k$ of genes to declare differentially expressed. Express your final answer as the single integer $k$ (no units). Do not round.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It provides a complete set of data and a clearly defined task based on established principles of statistical analysis in genomics. All necessary components—the number of tests $m$, the set of raw $p$-values, and the target False Discovery Rate (FDR) level $q^{*}$—are provided. The Benjamini–Hochberg procedure is a standard and appropriate method for this context. Therefore, the problem is valid and a solution can be derived.\n\nThe problem requires the application of the Benjamini–Hochberg (BH) procedure to control the False Discovery Rate (FDR) in a multiple hypothesis testing scenario. The FDR is defined as the expected proportion of false positives (incorrectly rejected null hypotheses) among all hypotheses declared significant. The BH procedure controls the FDR at a target level $q^{*}$ under the assumption that the $m$ hypothesis tests are independent.\n\nThe steps of the Benjamini–Hochberg procedure are as follows:\n1.  Let $p_1, p_2, \\ldots, p_m$ be the $p$-values from the $m$ hypothesis tests.\n2.  Order these $p$-values in ascending order: $p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(m)}$.\n3.  For a given FDR target level $q^{*}$, find the largest integer $k$ such that the $k$-th ordered $p$-value, $p_{(k)}$, satisfies the condition:\n    $$\n    p_{(k)} \\le \\frac{k}{m} q^{*}\n    $$\n4.  If such a $k$ exists, reject the null hypotheses corresponding to the $p$-values $p_{(1)}, p_{(2)}, \\ldots, p_{(k)}$. The number of discoveries is then $k$. If no such $k$ exists, no hypotheses are rejected.\n\nWe are given the following information:\n- The total number of hypotheses (genes) is $m = 20$.\n- The target FDR level is $q^{*} = 0.050$.\n- The set of $m = 20$ raw $p$-values is:\n  $\\{0.021, 0.200, 0.0030, 0.041, 0.012, 0.00030, 0.026, 0.052, 0.073, 0.032, 0.110, 0.018, 0.061, 0.0075, 0.350, 0.0011, 0.0042, 0.088, 0.0090, 0.0027\\}$\n\nFirst, we order the $p$-values from smallest to largest and assign them a rank $i$ from $1$ to $20$:\n- $p_{(1)} = 0.00030$\n- $p_{(2)} = 0.0011$\n- $p_{(3)} = 0.0027$\n- $p_{(4)} = 0.0030$\n- $p_{(5)} = 0.0042$\n- $p_{(6)} = 0.0075$\n- $p_{(7)} = 0.0090$\n- $p_{(8)} = 0.012$\n- $p_{(9)} = 0.018$\n- $p_{(10)} = 0.021$\n- $p_{(11)} = 0.026$\n- $p_{(12)} = 0.032$\n- $p_{(13)} = 0.041$\n- $p_{(14)} = 0.052$\n- $p_{(15)} = 0.061$\n- $p_{(16)} = 0.073$\n- $p_{(17)} = 0.088$\n- $p_{(18)} = 0.110$\n- $p_{(19)} = 0.200$\n- $p_{(20)} = 0.350$\n\nNext, we must find the largest integer $k$ that satisfies the condition $p_{(k)} \\le \\frac{k}{m} q^{*}$. With $m = 20$ and $q^{*} = 0.050$, the condition becomes $p_{(k)} \\le \\frac{k}{20}(0.050)$, which simplifies to $p_{(k)} \\le k \\times 0.0025$.\n\nWe now test this condition for each rank $i$, starting from the largest, or we can check sequentially from $i=1$ until the condition is violated. Let's inspect the values around the expected cutoff.\n\nFor $i = 10$:\n- $p_{(10)} = 0.021$\n- The BH threshold is $\\frac{10}{20} \\times 0.050 = 0.5 \\times 0.050 = 0.025$.\n- Since $0.021 \\le 0.025$, the condition holds for $i = 10$.\n\nFor $i = 11$:\n- $p_{(11)} = 0.026$\n- The BH threshold is $\\frac{11}{20} \\times 0.050 = 0.55 \\times 0.050 = 0.0275$.\n- Since $0.026 \\le 0.0275$, the condition holds for $i = 11$.\n\nFor $i = 12$:\n- $p_{(12)} = 0.032$\n- The BH threshold is $\\frac{12}{20} \\times 0.050 = 0.6 \\times 0.050 = 0.030$.\n- Since $0.032  0.030$, the condition is violated for $i = 12$.\n\nBecause the sequence of ordered $p$-values, $p_{(i)}$, is non-decreasing and the slope of the threshold line $\\frac{i}{m} q^{*}$ is typically smaller than the rate of increase of sorted $p$-values in the tail, once the condition $p_{(i)}  \\frac{i}{m} q^{*}$ is met, it will continue to be met for all subsequent values of $i$.\n\nThe largest rank $i$ for which the condition $p_{(i)} \\le \\frac{i}{m} q^{*}$ is satisfied is $i = 11$. Therefore, $k = 11$.\n\nAccording to the Benjamini–Hochberg procedure, we reject the null hypotheses for the first $k=11$ genes. This means we declare the $11$ genes with the smallest $p$-values as being differentially expressed, while controlling the False Discovery Rate at or below the target level of $5\\%$. The number of genes to declare differentially expressed is $11$.", "answer": "$$\n\\boxed{11}\n$$", "id": "4373694"}]}