{"hands_on_practices": [{"introduction": "Chromosomal Microarray Analysis (CMA) is a cornerstone of modern cytogenetics, valued for its high-resolution detection of genomic imbalances. This practice [@problem_id:4354912] explores the fundamental principle of how CMA quantifies copy number by calculating the log base 2 ratio from sample and reference DNA. By working through this idealized scenario, you will solidify your understanding of how deletions are detected and, just as importantly, why copy-number neutral rearrangements like balanced translocations are invisible to this powerful technology.", "problem": "A laboratory is evaluating Chromosomal Microarray Analysis (CMA) for diagnosing structural chromosomal abnormalities in autosomes. The platform is a two-color array Comparative Genomic Hybridization (aCGH), where a patient sample (test) and a sex-matched normal sample (reference) are co-hybridized. Assume the following foundational facts:\n- In aCGH, under ideal hybridization conditions, the measured fluorescence intensity at a probe is proportional to the underlying DNA copy number at that genomic locus.\n- The log base 2 ratio, defined as $\\log_{2}\\!\\left(I_{\\text{test}}/I_{\\text{ref}}\\right)$, is the reported metric at each probe, where $I_{\\text{test}}$ and $I_{\\text{ref}}$ are the test and reference probe intensities, respectively.\n- The reference genome is normal diploid for autosomes, with copy number $2$ across chromosome $18$.\n\nA patient is found to have a heterozygous terminal deletion spanning $10$ megabases on the short arm of chromosome $18$ (region $18p$), with no other copy number changes elsewhere. Under the idealized assumptions above, compute the expected segment-level log base $2$ ratio value reported by CMA across the deleted region. Then, using the same principles, explain why a balanced translocation between $18p$ and $7q$ in another patient would not produce the same segment-level log base $2$ ratio deviation on CMA.\n\nProvide only the numerical value for the expected log base $2$ ratio for the deletion as your final answer. No rounding is required.", "solution": "The problem requires the calculation of an expected log base $2$ ratio for a specific chromosomal deletion detected by array Comparative Genomic Hybridization (aCGH), and an explanation for why a balanced translocation would yield a different result. The problem's validity will be assessed first.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- The technique is two-color array Comparative Genomic Hybridization (aCGH).\n- The measured fluorescence intensity, $I$, is proportional to the DNA copy number, $CN$. Thus, $I \\propto CN$.\n- The reported metric is the log base $2$ ratio, defined as $M = \\log_{2}(I_{\\text{test}}/I_{\\text{ref}})$.\n- The reference sample is a normal diploid for autosomes, with a copy number of $2$ for chromosome $18$. Therefore, $CN_{\\text{ref}} = 2$.\n- Patient 1 has a heterozygous terminal deletion on chromosome $18p$. No other copy number changes are present.\n- Patient 2 has a balanced translocation between chromosome $18p$ and $7q$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is grounded in the fundamental principles of molecular cytogenetics and specifically aCGH. The relationship between fluorescence intensity and copy number, and the use of a log ratio, are core concepts of this technology. Heterozygous deletions and balanced translocations are canonical examples of chromosomal abnormalities.\n- **Well-Posed**: The problem is well-posed. It provides all necessary information and assumptions (ideal hybridization, proportionality) to calculate a unique, meaningful numerical value for the deletion scenario. The conceptual question regarding the balanced translocation is also clearly stated and answerable from the given principles.\n- **Objective**: The language is precise, technical, and free of subjectivity.\n\nThe problem is scientifically sound, self-contained, and objective. It does not violate any of the invalidity criteria. Therefore, the problem is deemed **valid**.\n\n**Solution**\n\nThe core principle of aCGH is that the measured fluorescence intensity at a specific probe location on the array is directly proportional to the total number of copies of that specific DNA sequence in the sample. We can express this relationship as $I = k \\cdot CN$, where $I$ is the intensity, $CN$ is the copy number, and $k$ is a proportionality constant that depends on probe-specific factors and experimental conditions.\n\nThe reported metric is the log base $2$ ratio of the test (patient) intensity to the reference (normal) intensity:\n$$M = \\log_{2}\\left(\\frac{I_{\\text{test}}}{I_{\\text{ref}}}\\right)$$\nSubstituting the proportionality relationship, we get:\n$$M = \\log_{2}\\left(\\frac{k \\cdot CN_{\\text{test}}}{k \\cdot CN_{\\text{ref}}}\\right)$$\nUnder the assumption of ideal co-hybridization on the same array, the constant $k$ is identical for both test and reference samples for a given probe. It therefore cancels, simplifying the expression to be dependent only on the copy numbers:\n$$M = \\log_{2}\\left(\\frac{CN_{\\text{test}}}{CN_{\\text{ref}}}\\right)$$\n\n**Part 1: Heterozygous Deletion on Chromosome 18p**\n\nWe are given that the reference sample is from a normal diploid individual. For an autosome like chromosome $18$, a normal diploid state corresponds to two copies.\n$$CN_{\\text{ref}} = 2$$\nThe patient has a heterozygous deletion on chromosome $18p$. In a diploid organism, \"heterozygous\" in this context implies that the aberration affects only one of the two homologous chromosomes. A normal individual has two copies of the $18p$ region. A deletion on one of these two copies results in the loss of that segment, leaving only one intact copy. Therefore, the copy number for the DNA sequences within the deleted region in the patient's sample is:\n$$CN_{\\text{test}} = 1$$\nNow, we can compute the expected log base $2$ ratio for the probes spanning this deleted segment:\n$$M = \\log_{2}\\left(\\frac{1}{2}\\right)$$\nUsing the properties of logarithms, $\\log_{b}(a^{-c}) = -c \\log_{b}(a)$:\n$$M = \\log_{2}(2^{-1}) = -1 \\cdot \\log_{2}(2) = -1$$\nThe expected segment-level log base $2$ ratio for the heterozygous deletion is $-1$.\n\n**Part 2: Balanced Translocation between 18p and 7q**\n\nA balanced translocation is a chromosomal rearrangement where segments are exchanged between non-homologous chromosomes, but there is no net gain or loss of genetic material. In the case of a balanced translocation between $18p$ and $7q$, a piece of chromosome $18p$ has broken off and attached to chromosome $7q$, while a piece of $7q$ has attached to $18p$.\n\nThe crucial point is that the total inventory of genetic material in the patient's cells remains unchanged. Consider a DNA sequence (and its corresponding aCGH probe) located within the translocated segment of $18p$. Although this sequence is now located on chromosome $7$ in one of the two copies, the cell still contains a total of two copies of that sequence. One copy is on the normal chromosome $18$, and the other is on the derivative chromosome $7$.\n\nArray CGH is a quantitative method; it measures the *total amount* of a DNA sequence in the genome, but it does not provide information about the *chromosomal location* of that sequence. Therefore, for any probe within the translocated regions (or anywhere else in the genome), the patient's total copy number is two.\n$$CN_{\\text{test}} = 2$$\nThe reference copy number remains two:\n$$CN_{\\text{ref}} = 2$$\nThe expected log base $2$ ratio for a patient with a balanced translocation is:\n$$M = \\log_{2}\\left(\\frac{CN_{\\text{test}}}{CN_{\\text{ref}}}\\right) = \\log_{2}\\left(\\frac{2}{2}\\right) = \\log_{2}(1) = 0$$\nA log base $2$ ratio of $0$ signifies a normal copy number state. This is fundamentally different from the ratio of $-1$ observed for the heterozygous deletion, which signifies a copy number loss. Consequently, standard aCGH is unable to detect balanced rearrangements like translocations because they do not alter the overall copy number of the DNA sequences being interrogated.", "answer": "$$\\boxed{-1}$$", "id": "4354912"}, {"introduction": "Genetic mosaicism, where an individual has multiple, genetically distinct cell populations, poses a unique diagnostic puzzle that requires integrating data from different testing modalities. This exercise [@problem_id:4354823] bridges the gap between a classic cytogenetic observation from karyotyping and the quantitative signal produced by a modern microarray. You will practice translating a finding of mosaicism into the standardized ISCN nomenclature and then calculate the expected log ratio, learning how a bulk DNA measurement reflects an underlying mixture of normal and aneuploid cells.", "problem": "A newborn male has cytogenetic testing consistent with mosaic Down syndrome: a fraction $0.30$ of peripheral blood metaphase cells carry an extra copy of chromosome $21$, and the remainder have a typical male karyotype. Use the International System for Human Cytogenomic Nomenclature (ISCN) to write the karyotype string that reflects mosaicism and includes counted cell numbers if exactly $N=50$ metaphase cells are analyzed. Then, considering that chromosomal microarray measures relative DNA dosage over bulk DNA, compute the expected base-$2$ logarithm of the copy-number ratio across chromosome $21$ for this specimen, taking the diploid baseline to be $2$ copies. Round the calculated logarithmic ratio to $4$ significant figures and report it as a dimensionless quantity. For grading purposes, report only the calculated logarithmic ratio.", "solution": "Begin from core definitions in cytogenetics and copy-number analysis. The International System for Human Cytogenomic Nomenclature (ISCN) expresses a karyotype as a standardized string that includes the total chromosome count, sex chromosome constitution, and any abnormalities; mosaicism is denoted by the prefix “mos,” with individual cell-line karyotypes separated by a slash and optional bracketed counts indicating how many cells of each line were observed. Mosaic aneuploidy with a fraction $p$ of cells carrying a trisomy implies that $p$ of cells have $3$ copies of the trisomic chromosome, and $1-p$ have $2$ copies.\n\nFor the ISCN string: the abnormal cell line is trisomy $21$ in a male, written as $47,\\mathrm{XY},+21$, and the normal male cell line is $46,\\mathrm{XY}$. With $p=0.30$ and $N=50$ cells scored, the expected counts are\n\n$$\nN_{\\text{trisomy}} = pN = 0.30 \\times 50 = 15, \\quad N_{\\text{normal}} = (1-p)N = 0.70 \\times 50 = 35.\n$$\n\nThus, the ISCN string would be written as\n\n$$\n\\mathrm{mos}\\ 47,\\mathrm{XY},+21[15]/46,\\mathrm{XY}[35].\n$$\n\nComponent explanations: “$\\mathrm{mos}$” indicates mosaicism; “$47,\\mathrm{XY},+21$” denotes a male cell line with $47$ chromosomes including an extra chromosome $21$; “$46,\\mathrm{XY}$” denotes a normal male cell line; bracketed numbers $[15]$ and $[35]$ indicate the counted numbers of cells observed for each line; the slash “/” separates the distinct cell lines.\n\nFor the chromosomal microarray expectation, use the standard definition that a copy-number log ratio is the logarithm base $2$ of the observed copy number divided by the diploid baseline $2$. In a mosaic mixture, the bulk average copy number for chromosome $21$ is the expectation over cell lines:\n\n$$\n\\overline{C} = 3 \\cdot p + 2 \\cdot (1-p) = 3p + 2 - 2p = 2 + p.\n$$\n\nSubstituting $p=0.30$ gives\n\n$$\n\\overline{C} = 2 + 0.30 = 2.30.\n$$\n\nThe ratio to the diploid baseline is\n\n$$\nR = \\frac{\\overline{C}}{2} = \\frac{2.30}{2} = 1.15.\n$$\n\nTherefore, the expected base-$2$ logarithmic copy-number ratio is\n\n$$\n\\log_{2}(R) = \\log_{2}(1.15) = \\frac{\\ln(1.15)}{\\ln(2)}.\n$$\n\nEvaluating numerically for the requested rounded result,\n\n$$\n\\ln(1.15) \\approx 0.139762,\\quad \\ln(2) \\approx 0.693147,\\quad \\frac{0.139762}{0.693147} \\approx 0.2016.\n$$\n\nRounded to $4$ significant figures as required, the expected dimensionless log-base-$2$ copy-number ratio across chromosome $21$ is $0.2016$.", "answer": "$$\\boxed{0.2016}$$", "id": "4354823"}, {"introduction": "The advent of Whole-Exome Sequencing (WES) has transformed the diagnosis of rare diseases, but it also presents the challenge of sifting through thousands of genetic variants to find a single pathogenic cause. Success hinges on a logical and rigorous filtration strategy that integrates multiple lines of evidence. This practice [@problem_id:4354893] places you in the role of a clinical geneticist, tasking you with designing an optimal variant filtration pipeline for a classic trio case, combining principles of population genetics, inheritance patterns, and functional prediction to pinpoint the most likely disease-causing variant.", "problem": "A pediatric trio case (proband and both parents) undergoes Whole-Exome Sequencing (WES). The proband is a male with severe, early-onset neurodevelopmental features and no family history; both parents are unaffected. The clinical suspicion is of a highly penetrant, monogenic disorder. The observed prevalence of clinically similar disorders in the general population is approximately $p = \\dfrac{1}{50{,}000}$. You are asked to select the most scientifically justified variant filtration pipeline to prioritize truly pathogenic variants from the WES dataset, using the following pillars: allele frequency from population databases such as the Genome Aggregation Database (gnomAD), functional impact prediction (for example, identifying protein-truncating Loss-of-Function (LoF) variants and high Combined Annotation Dependent Depletion (CADD) scores), and Mendelian inheritance constraints (de novo autosomal dominant, hemizygous X-linked in males, or biallelic autosomal recessive).\n\nYour choice should be grounded in:\n- The Central Dogma of molecular biology, which establishes that changes in deoxyribonucleic acid (DNA) can alter ribonucleic acid (RNA) and protein and thereby cause disease.\n- Basic Mendelian genetics for dominant, recessive, and X-linked modes of inheritance.\n- Population genetics under Hardy-Weinberg Equilibrium (HWE), linking prevalence to allele frequency for rare diseases.\n- The empirical observation that severe, early-onset monogenic disorders are typically caused by high-effect variants under strong negative selection, making such variants extremely rare in reference populations.\n\nWhich pipeline best aligns with these principles?\n\nA. Filter out variants with gnomAD minor allele frequency (MAF) $\\geq 0.01$ and retain all missense or LoF variants with CADD $\\geq 20$. Require that candidates show de novo occurrence or biallelic inheritance in autosomal recessive models, and allow hemizygous X-linked variants in the male proband. Perform phenotype matching post hoc.\n\nB. Retain variants with gnomAD MAF $\\leq 0.05$ to avoid losing potentially common disease alleles; include synonymous variants because splice effects are unpredictable; ignore parental genotypes and rely primarily on CADD $\\geq 10$ to identify deleterious changes.\n\nC. Use gnomAD MAF thresholds informed by prevalence and inheritance: for suspected autosomal dominant de novo or X-linked disease in the male proband, require MAF $< 1 \\times 10^{-6}$; for autosomal recessive candidates, require per-allele MAF $< 1 \\times 10^{-3}$. Prioritize predicted LoF variants and damaging missense (for example, CADD $\\geq 20$) especially in genes with high Probability of Loss-of-function Intolerance (pLI $\\geq 0.9$). Enforce Mendelian constraints (de novo in the proband, hemizygous X-linked in the male, and biallelic recessive), exclude variants present in unaffected parents for dominant/X-linked models, and then perform phenotype-to-gene matching using Human Phenotype Ontology (HPO) terms.\n\nD. Only accept variants entirely absent from gnomAD (MAF $= 0$), restrict to stop-gain LoF variants, and require strict de novo status; ignore missense and splice defects to minimize false positives. Perform no phenotype matching to avoid bias.", "solution": "The user has requested a critical evaluation of a problem in clinical genomics, specifically regarding the construction of a variant filtration pipeline for a pediatric trio case undergoing Whole-Exome Sequencing (WES). I will first validate the problem statement and, if it is valid, proceed to a detailed solution.\n\n### Step 1: Extract Givens\n- **Case Information**: Pediatric trio (proband, mother, father).\n- **Sequencing**: Whole-Exome Sequencing (WES).\n- **Proband**: A male with severe, early-onset neurodevelopmental features.\n- **Family History**: No family history of the disorder.\n- **Parental Phenotypes**: Both parents are unaffected.\n- **Clinical Hypothesis**: Highly penetrant, monogenic disorder.\n- **Population Data**: Prevalence ($p$) of clinically similar disorders is approximately $p = \\dfrac{1}{50{,}000}$.\n- **Task**: Select the most scientifically justified variant filtration pipeline from the given options.\n- **Guiding Scientific Principles**:\n    1.  The Central Dogma of molecular biology.\n    2.  Mendelian genetics (autosomal dominant, autosomal recessive, X-linked inheritance).\n    3.  Population genetics under Hardy-Weinberg Equilibrium (HWE).\n    4.  Empirical observation that severe, early-onset disorders are often due to high-effect variants under strong negative selection, making them extremely rare in the general population.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement must be evaluated for scientific soundness, completeness, and objectivity.\n\n- **Scientific Grounding**: The problem is well-grounded in the established principles and practices of medical genetics and bioinformatics. The use of WES in a trio setting, analysis of allele frequency (using gnomAD), prediction of functional impact (CADD), and application of Mendelian inheritance patterns are all standard-of-care methodologies for diagnosing rare genetic disorders. The scenario described is a classic presentation for identifying a causal variant.\n- **Well-Posedness**: The question asks to identify the *best* pipeline among a set of choices, based on provided scientific principles and case details. The information is sufficient to perform a comparative analysis and determine which option adheres most closely to a rigorous, evidence-based approach. The problem is structured to have a unique best answer among the options.\n- **Objectivity**: The problem is stated using precise, technical language devoid of subjective or ambiguous terminology. All provided information is quantitative or factual.\n- **Flaw Analysis**:\n    - The problem does not violate any fundamental scientific laws.\n    - It is directly relevant to the topic and readily formalizable.\n    - The setup is self-contained and internally consistent. The unaffected parents and severe proband phenotype strongly suggest a *de novo* dominant, *de novo* or maternally inherited X-linked, or an autosomal recessive pattern, all of which are standard considerations.\n    - The scenario is realistic and commonly encountered in clinical genetics.\n    - The question is well-structured and leads to a meaningful solution.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. It is a well-formulated question in clinical genomics that requires the application of fundamental principles to evaluate different analytical strategies. I will now proceed to derive the solution.\n\n### Derivation of the Optimal Filtration Strategy\n\nThe goal is to design a filtration pipeline that maximizes the probability of identifying the single causal variant for a severe, highly penetrant, early-onset disorder, while minimizing the number of false-positive candidates. The provided case information (trio, phenotype, prevalence) is crucial for tailoring the strategy.\n\n1.  **Inheritance Model and Trio Analysis**: The family structure (unaffected parents, affected proband) is the most powerful filter. It strongly suggests three primary possibilities:\n    - **Autosomal Dominant (AD), *de novo***: The variant appeared for the first time in the proband and is absent in both parents.\n    - **X-linked (XL)**: The male proband has one copy of a variant on his X chromosome. Since the mother is unaffected, this could be a *de novo* variant on the maternally contributed X chromosome, or she could be an asymptomatic carrier (due to skewed X-inactivation or incomplete penetrance), or she could be mosaic. A *de novo* event is a strong a priori hypothesis given the severity and lack of family history.\n    - **Autosomal Recessive (AR)**: The proband inherited one pathogenic variant from his mother and a second pathogenic variant in the same gene from his father. The parents are heterozygous carriers and thus unaffected.\n\n2.  **Allele Frequency Filtering (Population Genetics)**: The specified disease prevalence of $p = 1/50{,}000$ allows for the estimation of maximum plausible allele frequencies ($q$) under different inheritance models, assuming Hardy-Weinberg Equilibrium. This is a critical step to remove common, benign polymorphisms.\n    - **For AD or XL models**: For a dominant disease, the prevalence $p$ is approximately $2q$ for rare alleles (since $p = q^2 + 2q(1-q) \\approx 2q$). For an X-linked disease in males, prevalence in males equals $q$.\n        - AD: $q \\approx p/2 = (\\dfrac{1}{50{,}000})/2 = \\dfrac{1}{100{,}000} = 1 \\times 10^{-5}$.\n        - XL: $q = p = \\dfrac{1}{50{,}000} = 2 \\times 10^{-5}$.\n        In both cases, the causal allele must be exceptionally rare. An aggressive minor allele frequency (MAF) filter, such as MAF $< 1 \\times 10^{-5}$ or even more stringently (e.g., absent or only a few counts in a large database like gnomAD), is scientifically justified. A threshold of MAF $< 1 \\times 10^{-6}$ is very stringent but appropriately reflects the strong negative selection acting on such variants.\n    - **For AR models**: The prevalence is $p = q^2$.\n        - $q = \\sqrt{p} = \\sqrt{\\dfrac{1}{50{,}000}} = \\sqrt{2 \\times 10^{-5}} \\approx 0.00447$.\n        Therefore, the allele frequency for a recessive allele can be substantially higher than for a dominant one. A MAF threshold of $< 0.01$ ($1\\%$) is often used, but a more conservative threshold like $< 0.005$ or $< 1 \\times 10^{-3}$ ($0.1\\%$) offers a better balance for identifying rare recessive causes while still filtering effectively.\n\n3.  **Functional Impact Prediction**: A severe neurodevelopmental disorder is expected to be caused by a variant with a significant biological effect.\n    - **Variant Type**: Prioritize variants that are highly likely to disrupt protein function: Loss-of-Function (LoF) variants such as nonsense (leading to a stop codon), frameshift, or canonical splice-site variants are top candidates.\n    - **Variant Effect Scores**: For missense variants, computational predictors are essential. The Combined Annotation Dependent Depletion (CADD) score is a widely used metric. A score of CADD $\\geq 20$ indicates that the variant is predicted to be in the top $1\\%$ of most deleterious substitutions in the genome and is a standard threshold for high-confidence candidates in rare disease analysis.\n    - **Gene-level Constraints**: Metrics like the Probability of Loss-of-function Intolerance (pLI) score are valuable. A high pLI (e.g., pLI $\\geq 0.9$) indicates that the gene is highly intolerant to LoF variation in the general population, making any LoF variant found in such a gene a stronger candidate for causing a dominant disorder (haploinsufficiency).\n\n4.  **Phenotype-Genotype Correlation**: After filtering, the final step involves comparing the proband's clinical features (phenotype) with the known disease associations of the genes harboring the candidate variants. This is typically done using standardized vocabularies like the Human Phenotype Ontology (HPO). This step is crucial for confirming the clinical relevance of a genetic finding.\n\n### Evaluation of Options\n\n**A. Filter out variants with gnomAD minor allele frequency (MAF) $\\geq 0.01$ and retain all missense or LoF variants with CADD $\\geq 20$. Require that candidates show de novo occurrence or biallelic inheritance in autosomal recessive models, and allow hemizygous X-linked variants in the male proband. Perform phenotype matching post hoc.**\n- **Analysis**: This pipeline uses a single, overly permissive MAF threshold ($0.01$) for all inheritance models. As derived above, a suspected *de novo* dominant or X-linked variant should have a MAF far lower than $1\\%$. This filter is insufficiently stringent for those models and will retain too many non-pathogenic variants. While other steps (functional prediction, Mendelian model) are correct, the initial MAF filtering is not optimally designed based on population genetics principles.\n- **Verdict**: **Incorrect**.\n\n**B. Retain variants with gnomAD MAF $\\leq 0.05$ to avoid losing potentially common disease alleles; include synonymous variants because splice effects are unpredictable; ignore parental genotypes and rely primarily on CADD $\\geq 10$ to identify deleterious changes.**\n- **Analysis**: This pipeline is severely flawed. An MAF of $5\\%$ is the definition of a common polymorphism, completely inappropriate for a rare disorder with prevalence $1/50{,}000$. Including all synonymous variants is computationally inefficient and noisy. Ignoring parental genotypes discards the single most powerful source of information in a trio analysis. A CADD score of $\\geq 10$ is a weak filter for a severe disease. This approach contradicts all best practices.\n- **Verdict**: **Incorrect**.\n\n**C. Use gnomAD MAF thresholds informed by prevalence and inheritance: for suspected autosomal dominant de novo or X-linked disease in the male proband, require MAF $< 1 \\times 10^{-6}$; for autosomal recessive candidates, require per-allele MAF $< 1 \\times 10^{-3}$. Prioritize predicted LoF variants and damaging missense (for example, CADD $\\geq 20$) especially in genes with high Probability of Loss-of-function Intolerance (pLI $\\geq 0.9$). Enforce Mendelian constraints (de novo in the proband, hemizygous X-linked in the male, and biallelic recessive), exclude variants present in unaffected parents for dominant/X-linked models, and then perform phenotype-to-gene matching using Human Phenotype Ontology (HPO) terms.**\n- **Analysis**: This pipeline is excellent and aligns perfectly with the principles derived. It uses distinct, well-justified MAF thresholds based on the inheritance model and prevalence data. It prioritizes high-impact variants using strong functional evidence (LoF, CADD $\\geq 20$, pLI $\\geq 0.9$). It makes full and correct use of the trio data to enforce Mendelian inheritance patterns. Finally, it incorporates phenotype matching as a critical final validation step. This represents a state-of-the-art, scientifically rigorous approach.\n- **Verdict**: **Correct**.\n\n**D. Only accept variants entirely absent from gnomAD (MAF $= 0$), restrict to stop-gain LoF variants, and require strict de novo status; ignore missense and splice defects to minimize false positives. Perform no phenotype matching to avoid bias.**\n- **Analysis**: This pipeline is overly restrictive and simplistic, leading to a high risk of false negatives.\n    - Requiring MAF $= 0$ is too strict; a true positive variant might exist at an extremely low frequency in gnomAD.\n    - Restricting only to stop-gain variants incorrectly excludes frameshift, splice-site, and pathogenic missense variants, all of which are common causes of severe genetic disease.\n    - Requiring strict *de novo* status completely ignores the valid possibility of autosomal recessive inheritance.\n    - Performing no phenotype matching is illogical; confirming that the gene's function matches the patient's disease is a fundamental part of a clinical diagnosis, not a source of prohibited bias.\n- **Verdict**: **Incorrect**.", "answer": "$$\\boxed{C}$$", "id": "4354893"}]}