{"hands_on_practices": [{"introduction": "The power of a microscope is fundamentally limited by the physics of light itself. This exercise delves into the concept of diffraction-limited resolution, which defines the smallest detail a perfect optical system can distinguish. By applying the Rayleigh criterion, you will calculate the theoretical lateral resolution for a high-performance objective and explore why real-world measurements can fall short of this ideal due to practical issues like spherical aberration caused by refractive index mismatches [@problem_id:4877601]. Understanding this baseline is the first step toward critically evaluating and optimizing image quality.", "problem": "A histology lab is imaging fluorescently labeled cell membranes in an early embryonic specimen using a point-scanning confocal microscope equipped with an oil-immersion objective of numerical aperture (NA) and a photodetector. The fluorophore emits with a dominant wavelength centered at $\\lambda = 520\\,\\mathrm{nm}$, and the objective has a specified numerical aperture of $ \\mathrm{NA} = 1.4 $. Assume an ideal, aberration-free, diffraction-limited system and that fluorescence emission is incoherent. Using only first principles of diffraction from a circular pupil and the definition of numerical aperture, determine the theoretical lateral resolution at the specimen plane according to the conventional Rayleigh separation criterion for two point sources. Express the final numerical value in $ \\mathrm{nm} $ and round to $ 3 $ significant figures.\n\nIn the same experiment, the embryo is mounted in an aqueous medium whose refractive index does not match that of the immersion oil and coverglass stack. Briefly explain, using fundamental optical reasoning, why the experimentally measured full width at half maximum (FWHM) of the point spread function (PSF) in the resulting digital image may deviate from the theoretical value you computed. No quantitative correction is required for this explanation; provide only a qualitative justification. Your final numerical answer should be the theoretical lateral resolution in $ \\mathrm{nm} $ rounded as specified.", "solution": "The problem presents two tasks. The first is to calculate the theoretical lateral resolution of a confocal microscope based on fundamental principles. The second is to provide a qualitative explanation for the expected deviation of the experimental performance from this theoretical ideal under specific conditions.\n\nThe solution proceeds in two parts, addressing each task in turn.\n\nPart 1: Calculation of Theoretical Lateral Resolution\n\nThe theoretical lateral resolution of an optical microscope is determined by the diffraction of light. For an ideal, aberration-free system with a circular aperture (the objective lens), a point source of light is not imaged to a point but to a diffraction pattern known as the Airy pattern. This pattern consists of a bright central spot, the Airy disk, surrounded by a series of concentric dark and bright rings. The resolution is a measure of the system's ability to distinguish between two closely spaced point sources.\n\nThe problem specifies the use of the Rayleigh separation criterion for incoherent sources, which is appropriate for fluorescence microscopy. The Rayleigh criterion states that two point sources are just resolvable when the center of the Airy disk of one source is superimposed on the first minimum (the first dark ring) of the Airy pattern of the other source. The separation distance between the two sources at this limit is defined as the lateral resolution, $d$.\n\nTo derive the expression for $d$, we begin with the principles of Fraunhofer diffraction. The intensity profile of the Airy pattern in the object plane is a function of the radial coordinate $\\rho$ and is given by\n$$\nI(\\rho) \\propto \\left[ \\frac{2 J_1(x)}{x} \\right]^2\n$$\nwhere $J_1$ is the Bessel function of the first kind of order one. The argument $x$ is given by\n$$\nx = k \\rho \\sin(\\alpha_{\\text{max}})\n$$\nHere, $k$ is the wavenumber of the light in the medium in which the object is located, $\\rho$ is the radial distance from the center of the pattern in the object plane, and $\\alpha_{\\text{max}}$ is the maximum half-angle of the cone of light collected by the objective lens.\n\nThe wavenumber $k$ is related to the vacuum wavelength of the light, $\\lambda$, and the refractive index of the medium, $n$, by $k = \\frac{2\\pi n}{\\lambda}$. The problem statement provides the emission wavelength $\\lambda = 520 \\text{ nm}$, which is interpreted as the vacuum wavelength. The definition of the numerical aperture (NA) of the objective is $\\text{NA} = n \\sin(\\alpha_{\\text{max}})$.\n\nThe first minimum of the Airy pattern occurs at the first zero of the Bessel function $J_1(x)$. This occurs when its argument $x \\approx 3.8317$. According to the Rayleigh criterion, the resolution limit $d$ is the radial distance $\\rho$ to this first minimum. Therefore, we set:\n$$\nk d \\sin(\\alpha_{\\text{max}}) = 3.8317\n$$\nSubstituting the expressions for $k$ and NA, we have:\n$$\n\\left(\\frac{2\\pi n}{\\lambda}\\right) d \\sin(\\alpha_{\\text{max}}) = 3.8317\n$$\nRearranging the terms to group $n \\sin(\\alpha_{\\text{max}})$ gives:\n$$\n\\frac{2\\pi}{\\lambda} d \\left(n \\sin(\\alpha_{\\text{max}})\\right) = 3.8317\n$$\n$$\n\\frac{2\\pi}{\\lambda} d (\\text{NA}) = 3.8317\n$$\nSolving for the resolution limit $d$:\n$$\nd = \\frac{3.8317}{2\\pi} \\frac{\\lambda}{\\text{NA}}\n$$\nEvaluating the constant term $\\frac{3.8317}{2\\pi} \\approx 0.60984$. For practical purposes, this value is conventionally rounded to $0.61$. Thus, the Rayleigh resolution limit is given by the well-known formula:\n$$\nd = 0.61 \\frac{\\lambda}{\\text{NA}}\n$$\nWe are given the values $\\lambda = 520 \\text{ nm}$ and $\\text{NA} = 1.4$. Substituting these into the equation:\n$$\nd = 0.61 \\times \\frac{520 \\text{ nm}}{1.4}\n$$\n$$\nd = \\frac{317.2}{1.4} \\text{ nm} \\approx 226.5714 \\text{ nm}\n$$\nThe problem requires the result to be rounded to $3$ significant figures.\n$$\nd \\approx 227 \\text{ nm}\n$$\n\nPart 2: Qualitative Explanation for Deviation from Theoretical Value\n\nThe theoretical resolution of $d \\approx 227 \\text{ nm}$ was calculated under the assumption of an ideal, aberration-free system. The second part of the problem describes a more realistic experimental scenario where the embryo is mounted in an aqueous medium. This introduces a mismatch in the refractive index ($n$) between the immersion medium (oil, for which $n_{oil} \\approx 1.515$) and the sample mounting medium (aqueous, $n_{water} \\approx 1.33$). The coverglass typically has a refractive index matched to the oil ($n_{glass} \\approx 1.515$).\n\nHigh-NA oil-immersion objectives are meticulously designed to be aberration-free only when the optical path from the front lens of the objective to the focal point within the specimen is optically homogeneous. This means the objective, immersion oil, coverglass, and the medium immediately under the coverglass are all expected to have the same refractive index.\n\nWhen there is a refractive index mismatch at the interface between the coverglass and the aqueous mounting medium, the light rays are refracted according to Snell's Law ($n_1 \\sin\\theta_1 = n_2 \\sin\\theta_2$). This refraction violates the design conditions of the objective lens, leading to optical aberrations. The primary aberration introduced by such a planar-interface refractive index mismatch is **spherical aberration**.\n\nSpherical aberration causes rays of light passing through the objective's pupil at different radial distances to be focused at different axial positions. Peripheral rays are focused closer to the lens than paraxial rays. The consequence of this aberration is that the light from a point source is no longer focused to a sharp, diffraction-limited Airy disk. Instead, the energy of the focal spot is spread out, blurring the point spread function (PSF). This blurring manifests as a widening of the central maximum of the PSF and a transfer of energy into its outer rings.\n\nThe full width at half maximum (FWHM) is a direct measure of the width of the central peak of the PSF. Since spherical aberration broadens this peak, the experimentally measured FWHM of the PSF will be larger than the theoretical, diffraction-limited value. This degradation in the PSF directly corresponds to a loss of effective lateral and axial resolution, as well as a reduction in image contrast and signal-to-noise ratio. The severity of this aberration increases with the magnitude of the refractive index mismatch and with the depth of focusing into the specimen.", "answer": "$$\n\\boxed{227}\n$$", "id": "4877601"}, {"introduction": "A beautiful image is not always a quantitative one. This practice focuses on the crucial step of converting detected photons into meaningful digital values. For quantitative analysis, the relationship between light intensity and the recorded number must be linear. You will explore how to properly adjust detector gain and offset to map the full dynamic range of your sample's fluorescence signal into the bit depth of the detector, avoiding the irreversible data loss from saturation (bright signals) or clipping (dark signals) [@problem_id:4877583]. Mastering this setup is essential for any experiment where you intend to measure and compare intensities.", "problem": "A graduate-level histology and embryology laboratory uses point-scanning confocal microscopy to image weakly fluorescent proteins in embryonic tissues. The detector is a Photomultiplier Tube (PMT), and the excitation source is Light Amplification by Stimulated Emission of Radiation (LASER). Acquisition is configured at $16$-bit depth, meaning the digital intensity values span from $0$ to $65535$. The live histogram shows a pronounced spike in the rightmost bin at $65535$ in some regions of the specimen, indicating saturated pixels, while much of the tissue exhibits very weak signals near the dark end of the histogram. The user must adjust detector gain and offset before acquisition in order to avoid clipping of bright structures while preserving weak signals for downstream quantitative analysis.\n\nUsing first principles of digital imaging and detector response, choose the best strategy for adjusting gain and offset under these conditions.\n\nA. Decrease detector gain until the brightest structures no longer produce values at $65535$, then adjust offset so the background mode sits just above $0$ without left-side clipping; verify no saturated (at $65535$) or crushed (at $0$) pixels using the range indicator, and if additional sensitivity is needed, use averaging rather than increasing gain.\n\nB. Increase detector gain to amplify weak signals and lower offset to spread the histogram across the full range; accept some clipping at $65535$ as inevitable in order to maximize contrast.\n\nC. Increase offset until the saturated peak at $65535$ disappears while keeping gain constant, then rely on post-acquisition contrast stretching to recover weak features.\n\nD. Keep gain fixed, set offset to $0$, and reduce LASER power until saturation is eliminated; apply gamma correction during acquisition to redistribute intensities and preserve weak signals.", "solution": "The user's problem statement is a standard, well-posed scenario in the field of quantitative biological imaging, specifically confocal microscopy. It requires applying first principles of signal detection and digital imaging to establish an optimal acquisition protocol.\n\n**Validation of the Problem Statement**\n\n**Step 1: Extract Givens**\n-   Microscope Type: Point-scanning confocal microscopy\n-   Detector: Photomultiplier Tube (PMT)\n-   Excitation Source: Light Amplification by Stimulated Emission of Radiation (LASER)\n-   Specimen: Embryonic tissues with weakly fluorescent proteins\n-   Acquisition Bit Depth: $16$-bit\n-   Digital Intensity Range: $0$ to $65535$\n-   Observed State: Histogram shows a spike at $65535$ (saturation) and many weak signals near $0$.\n-   Objective: Adjust detector gain and offset to avoid clipping (at $0$ and $65535$) for downstream quantitative analysis.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically and logically sound.\n1.  **Scientific Grounding:** The scenario is based on the real-world operation of confocal microscopes. PMTs, LASERs, gain, offset, bit depth, histograms, and saturation are all fundamental concepts. The challenge of imaging samples with a high dynamic range (both very bright and very dim regions) 캐릭터 a classic problem in fluorescence microscopy.\n2.  **Well-Posedness:** The initial conditions (saturation and weak signal) and the objective (prepare for quantitative analysis) are clearly defined. The question asks for the best strategy among a set of choices, which leads to a unique, correct answer based on established best practices.\n3.  **Objectivity:** The terminology is precise and standard in the field. The goal of \"quantitative analysis\" imposes a strict, objective constraint: a linear relationship must be preserved between the number of photons detected and the final digital intensity value.\n4.  **Completeness:** The information provided is sufficient to determine the correct procedure. No essential data is missing.\n\n**Step 3: Verdict and Action**\nThe problem statement is **valid**. The solution process will now proceed.\n\n**Derivation of the Solution from First Principles**\n\nFor an imaging system to be quantitative, the recorded digital intensity, $I_{dig}$, must be linearly proportional to the number of photons, $N_{ph}$, collected from a given point in the specimen. This can be expressed as:\n$$I_{dig} = k \\cdot N_{ph} + I_{dark}$$\nwhere $k$ is a proportionality constant and $I_{dark}$ is the signal recorded in the absence of light (dark noise). This linear relationship is only valid within the dynamic range of the detector and the analog-to-digital converter (ADC).\n\nThe components of the system work as follows:\n1.  **LASER:** Provides excitation photons. The number of emitted fluorescence photons, $N_{ph}$, is proportional to the LASER power, assuming no saturation of the fluorophore itself.\n2.  **PMT Detector:** Converts incoming photons into an analog electrical signal. The PMT's **gain** ($G$) is a controllable amplification factor, typically adjusted by changing the high voltage across its dynodes. The analog output voltage, $V_{out}$, is proportional to the product of the number of photons and the gain: $V_{out} \\propto N_{ph} \\cdot G$. Increasing gain amplifies both the signal and the inherent electronic noise of the PMT.\n3.  **Electronics and ADC:** Before being digitized, a controllable DC voltage, the **offset** ($O$), is added to the signal. The final analog voltage sent to the ADC is $V_{ADC} = V_{out} + O$. The ADC converts $V_{ADC}$ into a $16$-bit integer, which ranges from $I_{min} = 0$ to $I_{max} = 2^{16}-1 = 65535$.\n\nThere are two critical non-linearities to avoid for quantitative analysis:\n-   **Saturation (Upper Clipping):** If $V_{ADC}$ exceeds the maximum input voltage of the ADC, the ADC outputs the maximum value, $I_{max} = 65535$. Any information about the brightness of pixels brighter than this saturation point is lost. The problem states this is occurring.\n-   **Crushing/Dark Clipping (Lower Clipping):** If $V_{ADC}$ is below the minimum input voltage of the ADC, the ADC outputs the minimum value, $I_{min} = 0$. The background signal in a PMT is never truly zero; it's a distribution of noise (e.g., thermal noise, dark current). If the offset is set too low, parts of this distribution will be clipped to $0$, losing information about the true background level and its statistical properties.\n\nThe optimal strategy must therefore use gain and offset to fit the entire signal, from the darkest background to the brightest pixel of interest, within the linear range of the ADC ($0 < I_{dig} < 65535$).\n\nThe initial state is saturation, meaning the signal ($N_{ph} \\cdot G$) is too high for the brightest pixels.\n-   **Step 1:** Reduce the signal. This can be done by decreasing the gain ($G$) or by decreasing the LASER power (which reduces $N_{ph}$). The primary adjustment for scaling the detector response to the ADC range is the gain. The gain must be decreased until the signal from the brightest region of the sample falls just below $65535$.\n-   **Step 2:** Set the black level. After the upper limit is set, the offset ($O$) must be adjusted. Its purpose is to ensure that the background noise is not clipped at $0$. The correct procedure is to adjust the offset so that the mean of the background signal is a small positive value, and no (or very few) pixels are recorded as $0$. This preserves the background for accurate subtraction or statistical analysis.\n-   **Step 3:** Improve Signal-to-Noise Ratio (SNR). If, after these adjustments, the weak signals are still noisy, the SNR can be improved by collecting more photons. This is correctly achieved by signal averaging (e.g., line or frame averaging), which increases the signal linearly with the number of averages ($N$) but the random noise only by $\\sqrt{N}$, thus improving SNR by $\\sqrt{N}$. Increasing gain at this stage would cause the bright pixels to saturate again.\n\n**Evaluation of Options**\n\n**A. Decrease detector gain until the brightest structures no longer produce values at $65535$, then adjust offset so the background mode sits just above $0$ without left-side clipping; verify no saturated (at $65535$) or crushed (at $0$) pixels using the range indicator, and if additional sensitivity is needed, use averaging rather than increasing gain.**\nThis option precisely follows the correct procedure derived from first principles. It correctly identifies that gain controls the upper limit of the signal range and that its primary adjustment should be to prevent saturation. It correctly describes the function of offset as setting the black level to prevent dark clipping. It correctly identifies the use of a range indicator (often a color lookup table, or LUT, that highlights pixels at $0$ and $65535$) for verification. Finally, it correctly proposes averaging as the method to improve SNR for weak signals once the dynamic range is properly set. This entire workflow preserves the linearity required for quantitative analysis.\n**Verdict: Correct**\n\n**B. Increase detector gain to amplify weak signals and lower offset to spread the histogram across the full range; accept some clipping at $65535$ as inevitable in order to maximize contrast.**\nThis option contains multiple fundamental errors. First, the problem starts with saturation, so increasing gain is the opposite of the required action. Second, accepting clipping at $65535$ is fundamentally incompatible with the goal of \"quantitative analysis,\" as it represents an irreversible loss of information. This approach is only suitable for creating visually appealing but non-scientific images.\n**Verdict: Incorrect**\n\n**C. Increase offset until the saturated peak at $65535$ disappears while keeping gain constant, then rely on post-acquisition contrast stretching to recover weak features.**\nThis option misunderstands the function of offset. Offset is an additive shift, not a multiplicative scaling factor. Increasing the offset adds a positive DC voltage to the entire signal. If the brightest pixels are already saturating the ADC, adding a positive offset will not change this; they will remain saturated. A large negative offset would be required to pull the signal down, but this is not the function of offset and would crush all background and weak signals to $0$. Information lost to clipping (at either end) cannot be \"recovered\" by post-acquisition processing.\n**Verdict: Incorrect**\n\n**D. Keep gain fixed, set offset to $0$, and reduce LASER power until saturation is eliminated; apply gamma correction during acquisition to redistribute intensities and preserve weak signals.**\nWhile reducing LASER power is a valid method to control saturation (and is often preferred for reducing phototoxicity), this option has two critical flaws. First, setting the offset to exactly $0$ is poor practice as it guarantees clipping of any background noise fluctuations that fall below the mean, biasing background measurements. Second, applying gamma correction during acquisition is a non-linear operation. It fundamentally breaks the linear relationship between photon count and intensity, rendering the data unusable for quantitative analysis. Gamma correction is a tool for display, not for scientific data acquisition.\n**Verdict: Incorrect**", "answer": "$$\\boxed{A}$$", "id": "4877583"}, {"introduction": "Multi-color imaging allows us to visualize the interplay between different biological molecules, but it comes with a common challenge: spectral cross-talk. This occurs when fluorescence from one label \"bleeds\" into the detector channel intended for another, creating artificial colocalization. This hands-on computational exercise will guide you through the process of spectral unmixing, using linear algebra to correct these artifacts [@problem_id:4877527]. By learning to computationally separate mixed signals using data from control samples, you can ensure that your conclusions about molecular proximity are based on reality, not optical artifacts.", "problem": "A three-channel Confocal Laser Scanning Microscopy (CLSM) system acquires fluorescence signals from three fluorophores that predominantly emit into one of three detector channels but exhibit spectral cross-talk (bleed-through) into the others. In histological sections, assume linear detector response and linear superposition of emitted photons from different fluorophores. The detector outputs for each channel are measured in arbitrary units (a.u.). Using single-labeled control samples for each fluorophore, you must estimate the cross-talk coefficients between channels and then apply a numerically stable compensation procedure to correct a three-color dataset.\n\nStarting from the principles of detector linearity and superposition, treat the measured three-channel observation as a linear combination of fluorophore contributions. For each fluorophore, use its single-labeled control measurement to estimate how much of its signal appears in each channel relative to its dominant (primary) channel. Construct a $3 \\times 3$ cross-talk matrix whose columns correspond to these relative contributions. Then, for each pixel in a mixed (three-color) dataset, compute the estimated fluorophore contributions by solving the corresponding linear system in a numerically stable manner. If the system is ill-conditioned, use a robust approach based on decompositions rather than direct inversion. Enforce non-negativity by setting any negative compensated intensities to $0$ a.u. Finally, round all compensated intensities to three decimal places.\n\nYour program must implement the above logic and produce results for the following test suite, using the provided single-labeled control measurements (means over Regions of Interest (ROI), in a.u.) and mixed three-color datasets (per-pixel observations, in a.u.). In each case, assume fluorophore $1$ has its primary signal in channel $1$, fluorophore $2$ in channel $2$, and fluorophore $3$ in channel $3$.\n\nTest Case $1$ (happy path, moderate cross-talk):\n- Single-labeled controls (means, in a.u.):\n  - Fluorophore $1$: $[1000, 120, 90]$\n  - Fluorophore $2$: $[80, 1100, 150]$\n  - Fluorophore $3$: $[60, 140, 900]$\n- Mixed dataset pixels (in a.u.):\n  - $\\text{p}_1$: $[1400, 500, 300]$\n  - $\\text{p}_2$: $[250, 1200, 500]$\n  - $\\text{p}_3$: $[300, 400, 1300]$\n  - $\\text{p}_4$: $[600, 600, 600]$\n\nTest Case $2$ (ill-conditioned cross-talk, near collinearity between two fluorophores):\n- Single-labeled controls (means, in a.u.):\n  - Fluorophore $1$: $[1000, 800, 100]$\n  - Fluorophore $2$: $[950, 1000, 120]$\n  - Fluorophore $3$: $[100, 50, 900]$\n- Mixed dataset pixels (in a.u.):\n  - $\\text{p}_1$: $[1800, 1600, 300]$\n  - $\\text{p}_2$: $[900, 850, 200]$\n  - $\\text{p}_3$: $[150, 120, 950]$\n\nTest Case $3$ (boundary condition, zero observation):\n- Single-labeled controls (use the same as Test Case $1$).\n- Mixed dataset pixels (in a.u.):\n  - $\\text{p}_1$: $[0, 0, 0]$\n  - $\\text{p}_2$: $[0, 0, 0]$\n\nTest Case $4$ (edge case, observation outside the positive cone spanned by control columns, requires non-negativity clipping after compensation):\n- Single-labeled controls (use the same as Test Case $1$).\n- Mixed dataset pixels (in a.u.):\n  - $\\text{p}_1$: $[50, 10, 200]$\n  - $\\text{p}_2$: $[20, 5, 80]$\n\nRequirements:\n- Estimate the cross-talk matrix columns by normalizing each single-labeled control vector by its primary channel value.\n- Compensate each mixed dataset pixel by solving the linear system implied by the cross-talk matrix using a numerically stable method that does not rely on direct inversion when instability is present.\n- Clip any negative compensated intensities to $0$ a.u.\n- Round all compensated intensities to three decimal places.\n- Express all outputs in arbitrary units (a.u.), rounded to three decimal places.\n- Final Output Format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result should be a list of per-pixel compensated intensities, where each pixel is a list of three floats. For example, a valid overall structure is $[[[x_{11},x_{12},x_{13}],\\ldots],[[\\ldots]],[[\\ldots]],[[\\ldots]]]$ with no extra text before or after the brackets.", "solution": "The problem requires the implementation of a spectral unmixing algorithm to correct for cross-talk in three-channel confocal microscopy images. The process is grounded in the principles of linear algebra and numerical analysis, assuming a linear superposition model for fluorescence signals.\n\n**1. Mathematical Model of Spectral Cross-Talk**\n\nThe fundamental assumption is that the measured signal in each detector channel is a linear combination of the true fluorescence intensities of the fluorophores present. For a three-channel system, this can be expressed as a matrix equation for each pixel:\n\n$$\n\\mathbf{y} = M \\mathbf{x}\n$$\n\nwhere:\n- $\\mathbf{y} = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\end{pmatrix}$ is the vector of measured intensities in the three detector channels (the mixed signal).\n- $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$ is the vector of the true, unknown fluorescence contributions from each of the three fluorophores (the unmixed signal).\n- $M$ is the $3 \\times 3$ cross-talk matrix (or mixing matrix).\n\nThe element $M_{ij}$ of the matrix $M$ represents the fraction of signal from fluorophore $j$ that is detected in channel $i$. Our objective is to determine $\\mathbf{x}$ given the measurement $\\mathbf{y}$ and the matrix $M$.\n\n**2. Estimation of the Cross-Talk Matrix $M$**\n\nThe cross-talk matrix $M$ characterizes the spectral properties of the fluorophores and the detection system. It is determined empirically using single-labeled control samples, where only one fluorophore is present.\n\nLet $\\mathbf{c}_j$ be the vector of mean measured intensities for a sample labeled only with fluorophore $j$.\n$$\n\\mathbf{c}_1 = \\begin{pmatrix} c_{11} \\\\ c_{21} \\\\ c_{31} \\end{pmatrix}, \\quad\n\\mathbf{c}_2 = \\begin{pmatrix} c_{12} \\\\ c_{22} \\\\ c_{32} \\end{pmatrix}, \\quad\n\\mathbf{c}_3 = \\begin{pmatrix} c_{13} \\\\ c_{23} \\\\ c_{33} \\end{pmatrix}\n$$\nHere, $c_{ij}$ is the signal in channel $i$ from fluorophore $j$. The problem states that fluorophore $j$ has its primary (strongest) signal in channel $j$. Thus, $c_{11}$, $c_{22}$, and $c_{33}$ are the primary channel signals for fluorophores $1$, $2$, and $3$, respectively.\n\nThe columns of the matrix $M$ are the normalized spectral signatures of each fluorophore. The $j$-th column of $M$, denoted $\\mathbf{m}_j$, is the control vector $\\mathbf{c}_j$ normalized by its primary channel value, $c_{jj}$. This normalization makes the diagonal elements of $M$ equal to $1$.\n\n$$\n\\mathbf{m}_j = \\frac{\\mathbf{c}_j}{c_{jj}} = \\begin{pmatrix} c_{1j}/c_{jj} \\\\ c_{2j}/c_{jj} \\\\ \\vdots \\\\ c_{jj}/c_{jj} \\\\ \\vdots \\end{pmatrix}\n$$\n\nThus, the full cross-talk matrix is constructed as:\n\n$$\nM = \\begin{pmatrix} | & | & | \\\\ \\mathbf{m}_1 & \\mathbf{m}_2 & \\mathbf{m}_3 \\\\ | & | & | \\end{pmatrix} = \\begin{pmatrix}\n\\frac{c_{11}}{c_{11}} & \\frac{c_{12}}{c_{22}} & \\frac{c_{13}}{c_{33}} \\\\\n\\frac{c_{21}}{c_{11}} & \\frac{c_{22}}{c_{22}} & \\frac{c_{23}}{c_{33}} \\\\\n\\frac{c_{31}}{c_{11}} & \\frac{c_{32}}{c_{22}} & \\frac{c_{33}}{c_{33}}\n\\end{pmatrix} = \\begin{pmatrix}\n1 & \\frac{c_{12}}{c_{22}} & \\frac{c_{13}}{c_{33}} \\\\\n\\frac{c_{21}}{c_{11}} & 1 & \\frac{c_{23}}{c_{33}} \\\\\n\\frac{c_{31}}{c_{11}} & \\frac{c_{32}}{c_{22}} & 1\n\\end{pmatrix}\n$$\n\n**3. Solving for the Unmixed Contributions $\\mathbf{x}$**\n\nTo find the true fluorophore contributions $\\mathbf{x}$, we must solve the linear system $\\mathbf{y} = M \\mathbf{x}$. The formal solution is $\\mathbf{x} = M^{-1} \\mathbf{y}$. However, direct computation of the matrix inverse $M^{-1}$ is often numerically unstable, particularly if $M$ is ill-conditioned. An ill-conditioned matrix arises when the spectral signatures of two or more fluorophores are very similar (i.e., the column vectors of $M$ are nearly linearly dependent), making the system sensitive to small amounts of noise in the measurement $\\mathbf{y}$.\n\nA more robust and numerically stable approach is to solve the system using matrix decomposition methods, such as LU decomposition with pivoting. Standard numerical libraries provide solvers that implement these stable algorithms. For example, `numpy.linalg.solve` is a suitable function that avoids explicit inversion and is robust for most well-posed, non-singular systems.\n\n**4. Physical Constraint: Non-Negativity**\n\nThe elements of the solution vector $\\mathbf{x}$ represent fluorescence intensities, which are physical quantities that cannot be negative. However, due to measurement noise or slight inaccuracies in the linear model, the mathematical solution to $\\mathbf{y} = M\\mathbf{x}$ may yield small negative values. These unphysical results must be corrected. The standard procedure is to enforce a non-negativity constraint by clipping any negative values to zero.\n\nIf $\\mathbf{x}_{\\text{raw}} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix}$ is the raw solution from the linear solver, the physically corrected compensated signal $\\mathbf{x}_{\\text{comp}}$ is given by:\n\n$$\n(\\mathbf{x}_{\\text{comp}})_i = \\max(0, (\\mathbf{x}_{\\text{raw}})_i) \\quad \\text{for } i=1, 2, 3\n$$\n\n**5. Algorithmic Implementation Summary**\n\nThe complete algorithm to be applied to each test case is as follows:\n\n1.  **For each test case:**\n    a.  Using the provided single-labeled control measurements $(\\mathbf{c}_1, \\mathbf{c}_2, \\mathbf{c}_3)$, construct the $3 \\times 3$ cross-talk matrix $M$ by normalizing each control vector by its primary channel intensity: $M = [\\mathbf{c}_1/c_{11}, \\mathbf{c}_2/c_{22}, \\mathbf{c}_3/c_{33}]$.\n    b.  **For each mixed-signal pixel vector $\\mathbf{y}$ in the dataset:**\n        i.   Solve the linear system $M\\mathbf{x} = \\mathbf{y}$ for $\\mathbf{x}$ using a numerically stable linear solver.\n        ii.  Apply the non-negativity constraint to the solution vector $\\mathbf{x}$ by setting any negative components to $0$.\n        iii. Round each component of the resulting vector to three decimal places.\n\nThis procedure yields the estimated true intensities of the three fluorophores for each pixel, corrected for spectral cross-talk.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the spectral unmixing problem for all given test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"controls\": [\n                [1000, 120, 90],  # Fluorophore 1\n                [80, 1100, 150], # Fluorophore 2\n                [60, 140, 900],   # Fluorophore 3\n            ],\n            \"pixels\": [\n                [1400, 500, 300],\n                [250, 1200, 500],\n                [300, 400, 1300],\n                [600, 600, 600],\n            ],\n        },\n        {\n            \"controls\": [\n                [1000, 800, 100], # Fluorophore 1\n                [950, 1000, 120], # Fluorophore 2\n                [100, 50, 900],   # Fluorophore 3\n            ],\n            \"pixels\": [\n                [1800, 1600, 300],\n                [900, 850, 200],\n                [150, 120, 950],\n            ],\n        },\n        {\n            \"controls\": [\n                [1000, 120, 90],\n                [80, 1100, 150],\n                [60, 140, 900],\n            ],\n            \"pixels\": [\n                [0, 0, 0],\n                [0, 0, 0],\n            ],\n        },\n        {\n            \"controls\": [\n                [1000, 120, 90],\n                [80, 1100, 150],\n                [60, 140, 900],\n            ],\n            \"pixels\": [\n                [50, 10, 200],\n                [20, 5, 80],\n            ],\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Convert control data to numpy arrays\n        c1 = np.array(case[\"controls\"][0], dtype=float)\n        c2 = np.array(case[\"controls\"][1], dtype=float)\n        c3 = np.array(case[\"controls\"][2], dtype=float)\n\n        # Construct the cross-talk matrix M.\n        # Each column is the spectral signature of a fluorophore,\n        # normalized by its primary channel's intensity.\n        # Fluorophore j has its primary signal in channel j (index j-1).\n        m1 = c1 / c1[0]\n        m2 = c2 / c2[1]\n        m3 = c3 / c3[2]\n        \n        # Assemble columns into the matrix M.\n        # np.array([m1, m2, m3]) would create a matrix with signatures as rows.\n        # We need them as columns, so we transpose (.T).\n        M = np.array([m1, m2, m3]).T\n\n        case_results = []\n        for pixel_data in case[\"pixels\"]:\n            y = np.array(pixel_data, dtype=float)\n\n            # Solve the linear system Mx = y for the unmixed contributions x.\n            # np.linalg.solve uses a stable decomposition-based method.\n            try:\n                x_raw = np.linalg.solve(M, y)\n            except np.linalg.LinAlgError:\n                # Handle singular matrix case, though not expected with given data.\n                # A least-squares solution would be an alternative here.\n                x_raw = np.linalg.lstsq(M, y, rcond=None)[0]\n\n            # Enforce non-negativity constraint by clipping negative values to 0.\n            x_clipped = np.maximum(0, x_raw)\n\n            # Round the final compensated intensities to three decimal places.\n            x_final = np.round(x_clipped, 3)\n\n            case_results.append(x_final.tolist())\n        \n        all_results.append(case_results)\n    \n    # Format the output string to exactly match the required format,\n    # which is a standard list representation with no extra spaces.\n    # str(list) generates spaces, so we remove them.\n    final_output_string = str(all_results).replace(\" \", \"\")\n\n    print(final_output_string)\n\nsolve()\n```", "id": "4877527"}]}