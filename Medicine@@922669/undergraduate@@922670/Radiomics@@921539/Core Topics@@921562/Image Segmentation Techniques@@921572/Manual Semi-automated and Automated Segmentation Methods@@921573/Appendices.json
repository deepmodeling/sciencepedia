{"hands_on_practices": [{"introduction": "Comparing segmentations from different sources, such as a manual delineation by a radiologist versus an automated algorithm's output, is a fundamental task in radiomics. A basic yet crucial first step is to assess the agreement in their overall size. This exercise introduces a simple, symmetric metric for quantifying volume difference and directly connects this discrepancy to the core concept of radiomic feature stability, revealing how geometric disagreements impact the reliability of downstream analysis [@problem_id:4550673].", "problem": "A radiomics pipeline compares two three-dimensional binary segmentation masks of a single lesion acquired from different methods: one mask produced by manual delineation and another produced by an automated algorithm. The masks are defined on the same imaging grid with identical voxel dimensions, and their volumes, computed as the sum of voxel volumes within the Region Of Interest (ROI), are measured to be $V_{\\text{manual}} = 120$ milliliters and $V_{\\text{auto}} = 108$ milliliters. Assuming no ground-truth volume is available for this lesion and that a symmetric, reference-free notion of percent volume difference should be used to characterize disagreement between the masks, determine the percent volume difference between the two masks. Express the final value as a decimal number without a percentage sign and round your answer to four significant figures.\n\nThen, by reasoning from fundamental definitions of mask volume and radiomic feature computation, explain qualitatively how a discrepancy of this magnitude would be expected to influence the stability of intensity-based first-order features and shape features, assuming all other preprocessing steps (such as resampling and intensity normalization) are held constant. You do not need to provide any additional numerical values for the qualitative discussion; focus on the conceptual implications based on the computed difference.", "solution": "The problem requires a two-part response: first, a quantitative calculation of the symmetric percent volume difference between two segmentation masks, and second, a qualitative explanation of how this difference influences the stability of specific classes of radiomic features.\n\nFirst, we address the quantitative part of the problem. We are given the volumes of two segmentation masks, one manual and one automated:\n$V_{\\text{manual}} = 120$ milliliters\n$V_{\\text{auto}} = 108$ milliliters\n\nThe problem asks for a \"symmetric, reference-free notion of percent volume difference.\" A standard percentage difference, such as $\\frac{|V_1 - V_2|}{V_1}$, is asymmetric because it depends on which volume is chosen as the reference ($V_1$). A symmetric percent difference normalizes the absolute difference by a term that treats both measurements equally. The most common symmetric formulation uses the average of the two measurements in the denominator. Let the symmetric volume difference be denoted by $\\Delta_V$. The formula is:\n$$ \\Delta_V = \\frac{|V_{\\text{manual}} - V_{\\text{auto}}|}{\\frac{1}{2}(V_{\\text{manual}} + V_{\\text{auto}})} $$\nThis metric gives the difference as a fraction of the mean volume, providing a balanced measure of disagreement without privileging either segmentation method, which is appropriate since no ground truth is available.\n\nSubstituting the given values into the formula:\n$$ \\Delta_V = \\frac{|120 - 108|}{\\frac{1}{2}(120 + 108)} $$\n$$ \\Delta_V = \\frac{12}{\\frac{1}{2}(228)} $$\n$$ \\Delta_V = \\frac{12}{114} $$\n\nTo express this as a decimal rounded to four significant figures, we perform the division:\n$$ \\Delta_V = 0.105263157... $$\nRounding to four significant figures, we obtain:\n$$ \\Delta_V \\approx 0.1053 $$\nThis value corresponds to a $10.53\\%$ symmetric difference in volume.\n\nNext, we provide the qualitative explanation for the influence of this volume discrepancy on radiomic feature stability. A volume difference of this magnitude ($10.53\\%$) indicates a non-trivial disagreement in the delineated Region Of Interest (ROI). This disagreement arises from a set of voxels that are included in one mask but excluded from the other. The stability of a radiomic feature is its robustness to such variations in segmentation.\n\nInfluence on Intensity-Based First-Order Features:\nFirst-order features describe the statistical distribution of voxel intensities within the ROI, computed from the intensity histogram. Examples include Mean, Variance, Skewness, and Kurtosis. These features are calculated over the set of all voxel intensities $\\{I_i\\}$ for all voxels $i$ within the ROI. A change in the ROI boundary directly alters this set of voxels. The $10.53\\%$ volume difference means there is a substantial set of disputed voxels, primarily along the boundary of the lesion.\n\nThe impact on first-order features depends critically on the intensity characteristics of these disputed voxels relative to the core of the lesion.\n1.  If the lesion is relatively homogeneous and has a sharp, well-defined border with the surrounding tissue, the intensities of the disputed boundary voxels may differ significantly from the intensities within the lesion core. For instance, including darker peritumoral tissue would lower the mean intensity and could increase the variance.\n2.  Higher-order moments like Skewness (measuring histogram asymmetry) and Kurtosis (measuring tailedness) are particularly sensitive to outliers. The inclusion or exclusion of a small number of voxels with extreme intensity values at the boundary can disproportionately affect these features, leading to high instability.\nTherefore, a volume discrepancy of this size is expected to introduce significant instability in first-order statistics, especially for heterogeneous lesions or those with poorly defined borders where the segmentation disagreement is most pronounced.\n\nInfluence on Shape Features:\nShape features quantify the geometry of the ROI, independent of voxel intensities. Examples include Volume, Surface Area, Sphericity, and Compactness. These features are, by their very definition, derived directly from the segmentation mask.\n1.  The `Volume` feature itself is directly affected; we have already quantified its instability with our calculation, showing a $10.53\\%$ symmetric difference.\n2.  `Surface Area` is calculated by summing the areas of the exposed faces of the voxels on the ROI's boundary. A change in the boundary voxels directly alters the surface area. Automated segmentations can sometimes produce boundaries that are less smooth (more \"jagged\") than manual ones, which could lead to a significant difference in calculated surface area even for a similar volume. The disputed voxels contribute directly to this difference.\n3.  Features that are ratios of surface area and volume, such as `Sphericity` ($\\propto \\frac{V^{2/3}}{A}$) and `Compactness` ($\\propto \\frac{V}{A^{3/2}}$), will be highly unstable. Since both the numerator ($V$) and the denominator ($A$, surface area) are functions of the mask geometry and are both unstable, their ratio is compounded in its instability. A $10.53\\%$ change in volume, coupled with a potentially larger percentage change in surface area, will result in poor reproducibility for these complex shape descriptors.\n\nIn summary, a symmetric volume difference of $10.53\\%$ is substantial and indicates that both intensity-based first-order features and, most notably, shape features will likely exhibit poor stability and reproducibility between the manual and automated segmentation methods.", "answer": "$$\\boxed{0.1053}$$", "id": "4550673"}, {"introduction": "While volume provides a general sense of agreement, it fails to capture discrepancies in the precise location of a segmentation's boundary. This practice delves into the Hausdorff distance, a standard metric for comparing the shapes of two point sets, which is essential for evaluating boundary-level accuracy. You will calculate the 95th percentile Hausdorff distance (HD95), a variant designed to be robust against a small number of outlier points, giving you a concrete understanding of how boundary disagreements are quantified in a clinically meaningful way [@problem_id:4550563].", "problem": "An advanced undergraduate radiomics team is comparing manual segmentation and automated segmentation of a liver lesion on a single axial slice of Computed Tomography (CT). For reproducibility across segmentation method types (manual, semi-automated, and fully automated) and to quantify boundary agreement, they use the 95th percentile Hausdorff distance (HD95). The team adopts the following fundamental base: the Euclidean distance in the plane, point-to-set distance as the minimum Euclidean distance to any point in a set, the classical Hausdorff distance as the supremum of directed point-set distances, and quantiles defined by the nearest-rank rule.\n\nConsider two finite sets of boundary points, in millimeters, representing the manual contour, $M$, and the automated contour, $A$, on the same slice:\n$$\nM = \\{(0,0),\\,(0,4),\\,(6,4),\\,(9,0),\\,(0,2),\\,(3,4),\\,(6,2),\\,(3,0),\\,(2,4),\\,(-3,0)\\}\n$$\n$$\nA = \\{(0.4,0.3),\\,(0.4,4.3),\\,(6.4,4.3),\\,(6.4,4.3),\\,(0.4,2.3),\\,(3.4,4.3),\\,(6.4,2.3),\\,(3.4,0.3),\\,(2.4,4.3),\\,(-2.6,0.3)\\}\n$$\nUse the Euclidean distance in $\\mathbb{R}^{2}$, defined for points $\\mathbf{x}=(x_{1},x_{2})$ and $\\mathbf{y}=(y_{1},y_{2})$ as\n$$\nd(\\mathbf{x},\\mathbf{y}) = \\sqrt{(x_{1}-y_{1})^{2} + (x_{2}-y_{2})^{2}}.\n$$\nFor each $m \\in M$, define the directed point-to-set distance $d(m,A) = \\min_{a \\in A} d(m,a)$. For each $a \\in A$, define $d(a,M) = \\min_{m \\in M} d(a,m)$. Form the multiset $D$ containing all directed nearest-neighbor distances in both directions, that is,\n$$\nD = \\{d(m,A) \\,:\\, m \\in M\\} \\cup \\{d(a,M) \\,:\\, a \\in A\\}.\n$$\nLet $N$ be the total number of elements of $D$ and write the nondecreasing order statistics $x_{(1)} \\le x_{(2)} \\le \\cdots \\le x_{(N)}$. The 95th percentile under the nearest-rank rule is $x_{(k)}$ with $k = \\lceil 0.95\\,N \\rceil$. Define the 95th percentile Hausdorff distance (HD95) as this $x_{(k)}$.\n\nCompute HD95 for the given $M$ and $A$. Express the final HD95 in millimeters and round your answer to four significant figures. Briefly, based on an acceptance criterion that HD95 less than $2$ millimeters indicates clinically acceptable agreement between an automated segmentation and a manual reference, interpret the clinical significance of your computed HD95.", "solution": "The problem requires the computation of the 95th percentile Hausdorff distance (HD95) between two sets of points, $M$ and $A$, representing manual and automated segmentations of a lesion. The solution proceeds by first validating the problem statement and then executing the defined computational steps.\n\nFirst, we address a minor ambiguity in the problem statement. The point set $A$ is defined using set notation $\\{...\\}$, but contains a duplicate point $(6.4, 4.3)$. In strict set theory, duplicates are ignored, which would mean $|A|=9$. This would lead to a total of $N = |M| + |A| = 10 + 9 = 19$ distances. The rank for the 95th percentile would be $k = \\lceil 0.95 \\times 19 \\rceil = \\lceil 18.05 \\rceil = 19$. The HD95 would then be the 19th value out of 19, i.e., the maximum value in the distance set, which is the classical Hausdorff distance. This undermines the purpose of using a percentile-based metric, which is to provide robustness against outliers.\n\nA more plausible interpretation, consistent with practices in medical image analysis, is to treat the given points in $M$ and $A$ as lists or multisets representing the vertices of the segmentation contours. Under this interpretation, we consider all $10$ listed points for both $M$ and $A$, leading to a total of $N=10+10=20$ distances. The rank for the 95th percentile is then $k = \\lceil 0.95 \\times 20 \\rceil = \\lceil 19 \\rceil = 19$. This means the HD95 will be the 19th largest distance out of 20, effectively discarding the single largest outlier, which is the intended function of HD95. We will proceed with this interpretation, taking $|M| = 10$ and $|A| = 10$.\n\nThe sets of points are:\n$$\nM = \\{(0,0),\\,(0,4),\\,(6,4),\\,(9,0),\\,(0,2),\\,(3,4),\\,(6,2),\\,(3,0),\\,(2,4),\\,(-3,0)\\}\n$$\n$$\nA = \\{(0.4,0.3),\\,(0.4,4.3),\\,(6.4,4.3),\\,(6.4,4.3),\\,(0.4,2.3),\\,(3.4,4.3),\\,(6.4,2.3),\\,(3.4,0.3),\\,(2.4,4.3),\\,(-2.6,0.3)\\}\n$$\nThe Euclidean distance is $d(\\mathbf{x},\\mathbf{y}) = \\sqrt{(x_{1}-y_{1})^{2} + (x_{2}-y_{2})^{2}}$.\n\nStep 1: Compute the directed distances $d(m,A) = \\min_{a \\in A} d(m,a)$ for all $m \\in M$.\nThe points in $A$ appear to be constructed by perturbing the points in $M$. For nearly every point $m \\in M$, there is a clear corresponding point $a \\in A$ such that the distance is $\\sqrt{(\\pm 0.4)^2 + (\\pm 0.3)^2} = \\sqrt{0.16 + 0.09} = \\sqrt{0.25} = 0.5$. A quick inspection confirms this distance is the minimum for these points.\n\n- For $m=(0,0)$, the nearest point in $A$ is $(0.4,0.3)$, with $d((0,0), (0.4,0.3)) = 0.5$.\n- For $m=(0,4)$, the nearest point in $A$ is $(0.4,4.3)$, with $d((0,4), (0.4,4.3)) = 0.5$.\n- For $m=(6,4)$, the nearest point in $A$ is $(6.4,4.3)$, with $d((6,4), (6.4,4.3)) = 0.5$.\n- For $m=(0,2)$, the nearest point in $A$ is $(0.4,2.3)$, with $d((0,2), (0.4,2.3)) = 0.5$.\n- For $m=(3,4)$, the nearest point in $A$ is $(3.4,4.3)$, with $d((3,4), (3.4,4.3)) = 0.5$.\n- For $m=(6,2)$, the nearest point in $A$ is $(6.4,2.3)$, with $d((6,2), (6.4,2.3)) = 0.5$.\n- For $m=(3,0)$, the nearest point in $A$ is $(3.4,0.3)$, with $d((3,0), (3.4,0.3)) = 0.5$.\n- For $m=(2,4)$, the nearest point in $A$ is $(2.4,4.3)$, with $d((2,4), (2.4,4.3)) = 0.5$.\n- For $m=(-3,0)$, the nearest point in $A$ is $(-2.6,0.3)$, with $d((-3,0), (-2.6,0.3)) = 0.5$.\n\nThe point $m=(9,0)$ is an exception. We must find its minimum distance to any point in $A$.\nThe closest point in $A$ to $(9,0)$ is $(6.4,2.3)$.\n$d((9,0), (6.4,2.3)) = \\sqrt{(9-6.4)^2 + (0-2.3)^2} = \\sqrt{2.6^2 + (-2.3)^2} = \\sqrt{6.76 + 5.29} = \\sqrt{12.05}$.\n\nSo, the multiset of distances from $M$ to $A$ is $\\{0.5, 0.5, 0.5, \\sqrt{12.05}, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5\\}$.\n\nStep 2: Compute the directed distances $d(a,M) = \\min_{m \\in M} d(a,m)$ for all $a \\in A$.\nFor each point $a \\in A$, we find its closest point in $M$. As observed, each point in $A$ (except for those corresponding to the outlier region) is a small perturbation of a point in $M$. The minimum distance between any two distinct points in $M$ is $d((3,4), (2,4)) = 1$. Since this minimum separation is greater than $2 \\times 0.5 = 1$, the closest point in $M$ for any $a \\in A$ will be its \"partner\" point from which it was generated.\nThe calculations confirm this:\n- For $a=(0.4,0.3)$, the nearest point in $M$ is $(0,0)$, with distance $0.5$.\n- For $a=(0.4,4.3)$, the nearest point in $M$ is $(0,4)$, with distance $0.5$.\n- For both instances of $a=(6.4,4.3)$, the nearest point in $M$ is $(6,4)$, with distance $0.5$.\n- For $a=(0.4,2.3)$, the nearest point in $M$ is $(0,2)$, with distance $0.5$.\n- For $a=(3.4,4.3)$, the nearest point in $M$ is $(3,4)$, with distance $0.5$.\n- For $a=(6.4,2.3)$, the nearest point in $M$ is $(6,2)$, with distance $0.5$.\n- For $a=(3.4,0.3)$, the nearest point in $M$ is $(3,0)$, with distance $0.5$.\n- For $a=(2.4,4.3)$, the nearest point in $M$ is $(2,4)$, with distance $0.5$.\n- For $a=(-2.6,0.3)$, the nearest point in $M$ is $(-3,0)$, with distance $0.5$.\nSo, the multiset of distances from $A$ to $M$ contains ten values, all equal to $0.5$.\n$\\{0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5\\}$.\n\nStep 3: Form the multiset $D$ and compute HD95.\nThe multiset $D$ is the union of all $20$ computed distances:\n$D = \\{0.5, 0.5, 0.5, \\sqrt{12.05}, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5\\}$.\nThis multiset contains $19$ instances of the value $0.5$ and one instance of the value $\\sqrt{12.05} \\approx 3.4713$.\nThe total number of elements in $D$ is $N=20$.\nLet the nondecreasing order statistics of $D$ be $x_{(1)} \\le x_{(2)} \\le \\cdots \\le x_{(20)}$.\n$x_{(1)} = x_{(2)} = \\dots = x_{(19)} = 0.5$.\n$x_{(20)} = \\sqrt{12.05}$.\n\nThe 95th percentile rank is $k = \\lceil 0.95 \\, N \\rceil = \\lceil 0.95 \\times 20 \\rceil = \\lceil 19 \\rceil = 19$.\nThe HD95 is defined as $x_{(k)} = x_{(19)}$.\nTherefore, $\\text{HD95} = 0.5$ millimeters.\n\nStep 4: Round and interpret the result.\nThe problem requires the answer to be rounded to four significant figures.\n$\\text{HD95} = 0.5000$ millimeters.\n\nThe clinical acceptance criterion is given as HD95 less than $2$ millimeters. Our computed value is $\\text{HD95} = 0.5000$ mm.\nSince $0.5000 < 2$, the agreement between the automated and manual segmentation is considered clinically acceptable. The use of the 95th percentile successfully makes the metric robust to the single large discrepancy (distance of $\\sqrt{12.05} \\approx 3.47$ mm), which might correspond to a localized segmentation error or an artifact in the manual contour. The vast majority of the boundary points align very closely.", "answer": "$$\\boxed{0.5000}$$", "id": "4550563"}, {"introduction": "Modern automated segmentation algorithms often produce a probability map rather than a final binary mask, with each voxel assigned a likelihood of belonging to the region of interest. This programming exercise challenges you to tackle the critical post-processing step of binarizing this map by finding the threshold that maximizes the Sørensen-Dice coefficient. Successfully completing this task involves designing an efficient algorithm, moving beyond naive methods to develop a practical and computationally sound solution for optimizing segmentation performance [@problem_id:4550608].", "problem": "You are given a discrete probability map representing an automated segmentation output and a binary ground truth mask representing a manual segmentation. For a fixed threshold, a binary prediction mask is obtained by classifying each element as positive if its probability is greater than or equal to the threshold, and negative otherwise. The similarity between the prediction and ground truth is measured using the Sørensen–Dice coefficient. From first principles, consider the following definitions for a dataset indexed by $i \\in \\{1,2,\\dots,N\\}$:\n- The probability map is $p_i \\in [0,1]$.\n- The ground truth mask is $g_i \\in \\{0,1\\}$.\n- For a threshold $t \\in \\mathbb{R}$, define the predicted label $\\hat{g}_i(t) = 1$ if $p_i \\ge t$, and $\\hat{g}_i(t) = 0$ otherwise.\n- Let $TP(t)$ denote the number of true positives at threshold $t$, that is $TP(t) = \\sum_{i=1}^{N} \\mathbf{1}\\big(\\hat{g}_i(t) = 1 \\wedge g_i = 1\\big)$, where $\\mathbf{1}(\\cdot)$ is the indicator function. Let $FP(t)$ denote the false positives and $FN(t)$ denote the false negatives analogously.\n- The Sørensen–Dice coefficient is defined as $D(t) = \\dfrac{2\\,TP(t)}{2\\,TP(t) + FP(t) + FN(t)}$. Using the identities $FP(t) = \\sum_{i=1}^{N} \\mathbf{1}\\big(\\hat{g}_i(t) = 1 \\wedge g_i = 0\\big)$, $FN(t) = \\sum_{i=1}^{N} \\mathbf{1}\\big(\\hat{g}_i(t) = 0 \\wedge g_i = 1\\big)$, and $\\sum_{i=1}^{N} g_i = |G|$, it follows that $D(t)$ can be expressed equivalently as $D(t) = \\dfrac{2\\,TP(t)}{|\\hat{G}(t)| + |G|}$ where $|\\hat{G}(t)|$ is the number of predicted positives at threshold $t$ and $|G|$ is the number of ground truth positives.\n- Edge case convention: If $|G| = 0$, define $D(t) = 1$ when $|\\hat{G}(t)| = 0$ and $D(t) = 0$ when $|\\hat{G}(t)| > 0$.\n\nYour task is to write a complete, runnable program that, for each test case, computes the threshold that maximizes $D(t)$ over the domain $t \\in [0,1]$, with the additional candidate threshold representing an empty prediction set as $t_{\\emptyset} = 1.0 + 10^{-6}$ (which ensures $p_i < t_{\\emptyset}$ for all $p_i \\in [0,1]$). Among all thresholds that achieve the maximal $D(t)$, return the smallest threshold in $[0,1]$; when the maximizer corresponds to the empty prediction set, return $t_{\\emptyset}$. You must justify the computational optimization that avoids naive scanning of a dense grid of thresholds, by using sorting and cumulative counts to achieve at most $\\mathcal{O}(N \\log N)$ time per test case, where $N$ is the number of elements.\n\nYou must implement the following test suite, each case provided as lists:\n\n- Case $1$: $p = [0.1, 0.9, 0.8, 0.2, 0.7]$, $g = [0, 1, 1, 0, 0]$.\n- Case $2$: $p = [0.2, 0.3, 0.8, 0.99]$, $g = [0, 0, 0, 0]$.\n- Case $3$: $p = [0.3, 0.3, 0.3, 0.3, 0.3]$, $g = [1, 0, 1, 0, 0]$.\n- Case $4$: $p = [0.6, 0.55, 0.54, 0.1, 0.09]$, $g = [1, 0, 1, 0, 0]$.\n- Case $5$: $p = [1.0, 0.0, 1.0, 0.0]$, $g = [1, 0, 0, 1]$.\n\nProgram requirements:\n- The program must compute, for each case, the threshold value that maximizes $D(t)$ under the specified tie-breaking rule.\n- The final output must be a single line containing a comma-separated list of the thresholds, each rounded to $6$ decimal places. The list must be enclosed in square brackets, for example $[0.123456,0.500000,1.000001]$.\n- No external input is allowed; use the test suite defined above directly inside the program.\n\nOptimization justification requirement:\n- Derive and implement an algorithm that only evaluates $D(t)$ at a finite set of candidate thresholds given by the unique probability values in $p$ (interpreted with the rule $p_i \\ge t$) plus the extremes $t = 0$ and $t = t_{\\emptyset}$; show that these candidates suffice to capture all distinct prediction masks and thus all distinct values of $D(t)$.\n- Argue the computational complexity improvement compared to a naive dense scan of $M$ thresholds over $[0,1]$ with $M \\gg N$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[result1,result2,result3,result4,result5]$), where each $resultk$ is the threshold for case $k$ as a float rounded to $6$ decimal places.", "solution": "The problem requires finding a threshold $t$ that maximizes the Sørensen–Dice coefficient $D(t)$ for a given probability map $p$ and a ground truth binary mask $g$. The domain of thresholds to consider is $t \\in [0,1]$, with an additional special candidate $t_{\\emptyset} = 1.0 + 10^{-6}$ for an empty prediction set.\n\nThe Sørensen–Dice coefficient is defined as:\n$$\nD(t) = \\frac{2\\,TP(t)}{2\\,TP(t) + FP(t) + FN(t)}\n$$\nwhere $TP(t)$, $FP(t)$, and $FN(t)$ are the counts of true positives, false positives, and false negatives at threshold $t$, respectively. Using the identity $2\\,TP(t) + FP(t) + FN(t) = (TP(t)+FP(t)) + (TP(t)+FN(t)) = |\\hat{G}(t)| + |G|$, where $|\\hat{G}(t)|$ is the number of predicted positive elements and $|G|$ is the total number of true positive elements in the ground truth, the coefficient can be written as:\n$$\nD(t) = \\frac{2\\,TP(t)}{|\\hat{G}(t)| + |G|}\n$$\nThe predicted label for element $i$ is $\\hat{g}_i(t) = 1$ if its probability $p_i \\ge t$, and $\\hat{g}_i(t) = 0$ otherwise.\n\nA naive approach to find the optimal threshold would be to evaluate $D(t)$ over a dense grid of $M$ thresholds spanning $[0,1]$. For each threshold, calculating $TP(t)$ and $|\\hat{G}(t)|$ requires iterating through all $N$ elements, leading to a computational complexity of $\\mathcal{O}(MN)$. If $M$ is large to ensure sufficient precision, this method becomes prohibitively expensive. The problem mandates a more efficient approach with complexity at most $\\mathcal{O}(N \\log N)$.\n\n### Optimization and Algorithmic Design\n\nThe key to an efficient algorithm lies in a critical observation about the behavior of $D(t)$. The prediction mask $\\hat{G}(t)$, and consequently the values of $TP(t)$, $|\\hat{G}(t)|$, and $D(t)$, are piecewise constant functions of $t$. The values of these functions change only when the threshold $t$ crosses one of the probability values $\\{p_i\\}_{i=1}^N$.\nSpecifically, for any two thresholds $t_a$ and $t_b$ such that no $p_i$ lies in the interval $(t_a, t_b]$, the set of predicted positives $\\hat{G}(t) = \\{i | p_i \\ge t\\}$ remains identical for all $t \\in (t_a, t_b]$. This implies that $D(t)$ is constant over such intervals.\n\nTherefore, to find the maximum value of $D(t)$, it is sufficient to evaluate it only at a finite set of candidate thresholds that can induce a change in the prediction mask. These candidate thresholds are the unique probability values present in the input map $p$. Additionally, we must consider the boundary cases: a threshold that predicts all elements as positive (e.g., $t=0$) and a threshold that predicts no elements as positive. The problem specifies $t_{\\emptyset} = 1.0 + 10^{-6}$ as the candidate for the empty prediction. Thus, the complete set of candidate thresholds is $\\mathcal{T} = \\text{unique}(\\{p_i\\}) \\cup \\{0, t_{\\emptyset}\\}$.\n\nEven with this reduced set of candidates (at most $N+2$ thresholds), naively re-calculating $D(t)$ for each candidate would require $\\mathcal{O}(N)$ work per candidate, leading to a worst-case complexity of $\\mathcal{O}(N^2)$ if all $p_i$ are unique.\n\nTo achieve the desired $\\mathcal{O}(N \\log N)$ complexity, a sweep-line algorithm is employed. The algorithm proceeds as follows:\n1.  **Sorting**: The pairs of (probability, ground truth) i.e., $(p_i, g_i)$, are sorted in descending order based on the probability $p_i$. This step is the dominant cost, taking $\\mathcal{O}(N \\log N)$ time.\n2.  **Initialization**: We handle the edge cases.\n    - If the ground truth is empty ($|G| = \\sum g_i = 0$), the problem defines $D(t)=1$ for an empty prediction ($|\\hat{G}(t)|=0$) and $D(t)=0$ otherwise. The maximum $D(t)$ is $1$, achieved by an empty prediction. Per the problem, we return $t_{\\emptyset}$ in this situation.\n    - For $|G|>0$, an empty prediction yields $TP(t)=0$ and $|\\hat{G}(t)|=0$, so $D(t)=0$. We initialize the best score found so far to `best_dice` $= 0$ with the corresponding threshold `best_thresh` $= t_{\\emptyset}$.\n3.  **Sweep and Update**: We iterate through the sorted list of points. This process simulates sweeping the threshold $t$ from a value greater than $1$ down to $0$. As we encounter each point $(p_j, g_j)$ in the sorted list, we add it to the set of predicted positives. We maintain running counts of true positives ($TP$) and false positives ($FP$).\n    - For each point $(p_i, g_i)$ processed, we increment $TP$ if $g_i=1$ and $FP$ if $g_i=0$.\n    - After processing a point (or a block of points with the same probability value $p_i$), we have the statistics for the prediction set corresponding to the threshold $t = p_i$. The number of predicted positives $|\\hat{G}(p_i)|$ is the count of points processed so far.\n    - We calculate $D(p_i) = \\frac{2 \\cdot TP}{|\\hat{G}(p_i)| + |G|}$.\n    - This new Dice score is compared with the best score found so far. If it is greater, we update `best_dice` and `best_thresh` to the current score and threshold ($p_i$). If the score is equal, we update `best_thresh` only if the current threshold $p_i$ is smaller, satisfying the tie-breaking rule.\n4.  **Finalization**: The loop evaluates the Dice score for thresholds corresponding to each unique value in $p$. One final check is required. The state of $TP$ and $FP$ after the loop completes corresponds to all elements being predicted positive. This state is achieved for any threshold $t \\in [0, \\min(p)]$ (if $\\min(p)>0$). The smallest threshold that yields this state is $t=0$. We therefore calculate the Dice score for this \"all positive\" state and update our best result if this score is better, or if it is equal but the threshold $t=0$ is smaller than the current `best_thresh`.\n\nThis sweep-line approach processes each point once after the initial sort, with constant-time work for updating counts and calculating the Dice score at each distinct probability level. The overall complexity is therefore dominated by the sort, resulting in an efficient $\\mathcal{O}(N \\log N)$ algorithm that correctly identifies the optimal threshold according to the problem's criteria.", "answer": "```python\nimport numpy as np\n\ndef find_best_threshold(p_list, g_list):\n    \"\"\"\n    Computes the threshold that maximizes the Sørensen–Dice coefficient.\n    \n    This function implements an O(N log N) sweep-line algorithm.\n    \"\"\"\n    p = np.array(p_list, dtype=float)\n    g = np.array(g_list, dtype=int)\n    \n    t_emptyset = 1.0 + 1e-6\n    \n    total_g = np.sum(g)\n    N = len(p)\n\n    # Edge Case: As per the problem, if the ground truth is empty, the optimal\n    # Dice score is 1, achieved with an empty prediction set. The required\n    # threshold to return is t_emptyset.\n    if total_g == 0:\n        return t_emptyset\n\n    # Combine probabilities and ground truth labels into a structured array\n    # and sort them in descending order based on probability.\n    pg = np.array(list(zip(p, g)), dtype=[('p', float), ('g', int)])\n    pg_sorted = np.sort(pg, order='p')[::-1]\n    \n    # Initialize with the empty prediction case. For t > max(p), the prediction\n    # set is empty, yielding TP=0, |G_hat|=0, and thus Dice=0.\n    # The problem specifies returning t_emptyset for this case if it's optimal.\n    best_dice = 0.0\n    best_thresh = t_emptyset\n    \n    tp = 0\n    fp = 0\n    \n    # Sweep through the sorted probabilities\n    for i in range(N):\n        p_val = pg_sorted['p'][i]\n        g_val = pg_sorted['g'][i]\n        \n        if g_val == 1:\n            tp += 1\n        else:\n            fp += 1\n            \n        # To handle tied probabilities correctly, we only calculate Dice\n        # at the end of a block of points with the same probability.\n        is_last_in_block = (i == N - 1) or (pg_sorted['p'][i+1] != p_val)\n        \n        if is_last_in_block:\n            num_pred_pos = i + 1\n            \n            # Denominator: |G_hat(t)| + |G|. Since total_g > 0, this is never zero.\n            dice = (2.0 * tp) / (num_pred_pos + total_g)\n            \n            current_thresh = p_val\n            \n            # Update if we found a better Dice score, or an equal score\n            # with a smaller threshold.\n            if dice > best_dice:\n                best_dice = dice\n                best_thresh = current_thresh\n            elif dice == best_dice:\n                best_thresh = min(best_thresh, current_thresh)\n\n    # After the loop, the counts (tp, fp) are for the \"all positive\" prediction set.\n    # This set is achieved for any threshold t <= min(p). The smallest such\n    # threshold is 0. We must check if t=0 gives an optimal or better result.\n    all_pos_dice = (2.0 * tp) / (N + total_g)\n    \n    if all_pos_dice > best_dice:\n        # best_dice = all_pos_dice # not strictly needed, just best_thresh matters\n        best_thresh = 0.0\n    elif all_pos_dice == best_dice:\n        best_thresh = min(best_thresh, 0.0)\n        \n    return best_thresh\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        ([0.1, 0.9, 0.8, 0.2, 0.7], [0, 1, 1, 0, 0]),\n        ([0.2, 0.3, 0.8, 0.99], [0, 0, 0, 0]),\n        ([0.3, 0.3, 0.3, 0.3, 0.3], [1, 0, 1, 0, 0]),\n        ([0.6, 0.55, 0.54, 0.1, 0.09], [1, 0, 1, 0, 0]),\n        ([1.0, 0.0, 1.0, 0.0], [1, 0, 0, 1])\n    ]\n\n    results = []\n    for p, g in test_cases:\n        threshold = find_best_threshold(p, g)\n        results.append(f\"{threshold:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "4550608"}]}