{"hands_on_practices": [{"introduction": "To truly understand the Precision-Recall curve, there is no substitute for building one from scratch. This exercise takes you through the fundamental process of converting raw classifier scores and ground-truth labels into a series of $(R, P)$ points. By manually sweeping the decision threshold and calculating precision and recall at each step, you will gain a concrete understanding of how the curve is generated and how to compute the area under it using the standard Average Precision method. [@problem_id:4556368]", "problem": "A radiomics classifier processes computed tomography imaging data to assign a malignancy likelihood score to each patient. The classifier outputs a real-valued score between $0$ and $1$ for each case. The ground truth is binary, where $1$ denotes malignancy present and $0$ denotes malignancy absent. In Precision-Recall (PR) analysis, precision $P$ and recall $R$ are defined from first principles by $P = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}$ and $R = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$, where $\\mathrm{TP}$ is the number of true positives, $\\mathrm{FP}$ is the number of false positives, and $\\mathrm{FN}$ is the number of false negatives. For a decision threshold $\\tau$, a case is predicted positive if its score is at least $\\tau$.\n\nYou are given $8$ patients with known ground-truth labels and classifier scores:\n- Patient $\\mathrm{A}$: score $0.92$, label $1$.\n- Patient $\\mathrm{B}$: score $0.90$, label $0$.\n- Patient $\\mathrm{C}$: score $0.90$, label $1$.\n- Patient $\\mathrm{D}$: score $0.85$, label $1$.\n- Patient $\\mathrm{E}$: score $0.85$, label $0$.\n- Patient $\\mathrm{F}$: score $0.80$, label $0$.\n- Patient $\\mathrm{G}$: score $0.75$, label $1$.\n- Patient $\\mathrm{H}$: score $0.75$, label $1$.\n\nStarting only from the definitions above, do the following:\n1. Derive the exact sequence of decision thresholds $\\tau$ (from high to low) that generates all distinct $(R, P)$ points on the PR curve. Explicitly state how identical scores must be handled to ensure a scientifically valid and internally consistent PR sweep.\n2. Compute the area under the PR curve using a step-function interpretation justified from these definitions. Your final output must be a single real number. Round your final numeric answer to four significant figures. No units are required. Express any intermediate proportions or rates as decimals or fractions, not with a percentage sign.", "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n### Step 1: Extract Givens\n- **Definitions**:\n  - Precision: $P = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}$\n  - Recall: $R = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FN}}$\n  - $\\mathrm{TP}$: True Positives, $\\mathrm{FP}$: False Positives, $\\mathrm{FN}$: False Negatives.\n- **Classification Rule**: A case is predicted positive if its score is greater than or equal to a decision threshold $\\tau$.\n- **Data**: A set of $8$ patients with scores and ground-truth labels ($1$ for malignant, $0$ for absent).\n  - Patient A: score $0.92$, label $1$\n  - Patient B: score $0.90$, label $0$\n  - Patient C: score $0.90$, label $1$\n  - Patient D: score $0.85$, label $1$\n  - Patient E: score $0.85$, label $0$\n  - Patient F: score $0.80$, label $0$\n  - Patient G: score $0.75$, label $1$\n  - Patient H: score $0.75$, label $1$\n- **Tasks**:\n  1. Derive the sequence of decision thresholds $\\tau$ generating all distinct $(R, P)$ points, explaining the handling of tied scores.\n  2. Compute the area under the PR curve (AUPRC) using a step-function interpretation, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined, internally consistent, and scientifically grounded in the fields of machine learning and medical image analysis. The definitions of precision and recall are standard. The dataset is complete and sufficient for the task. The instructions are clear and objective. The problem does not violate any scientific principles, is not ambiguous, and possesses a unique, meaningful solution.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution\n\nThe solution proceeds in two parts as requested. First, we determine the thresholds and the corresponding Precision-Recall points. Second, we compute the area under the resulting PR curve.\n\nFirst, we must establish the total number of positive and negative cases in the dataset. By counting the labels, we find:\n- Total positive cases ($P_{total} = \\mathrm{TP} + \\mathrm{FN}$) = $5$ (Patients A, C, D, G, H).\n- Total negative cases ($N_{total}$) = $3$ (Patients B, E, F).\nThe total number of patients is $N = P_{total} + N_{total} = 5 + 3 = 8$.\n\nRecall is defined as $R = \\frac{\\mathrm{TP}}{P_{total}} = \\frac{\\mathrm{TP}}{5}$. Precision is $P = \\frac{\\mathrm{TP}}{\\mathrm{TP} + \\mathrm{FP}}$.\n\n#### Part 1: Thresholds, Tie-Handling, and (R, P) Points\n\nTo generate the PR curve, we vary the decision threshold $\\tau$ from a value higher than the maximum score down to the minimum score. The $(R, P)$ coordinates change only at thresholds equal to the scores of the patients. Therefore, the sequence of thresholds that generates all distinct $(R, P)$ points is the set of unique scores in the data, sorted in descending order.\n\nThe patient data is sorted by score, from highest to lowest:\n1. Patient A: score $0.92$, label $1$\n2. Patient C: score $0.90$, label $1$\n3. Patient B: score $0.90$, label $0$\n4. Patient D: score $0.85$, label $1$\n5. Patient E: score $0.85$, label $0$\n6. Patient F: score $0.80$, label $0$\n7. Patient G: score $0.75$, label $1$\n8. Patient H: score $0.75$, label $1$\n\n**Handling of Identical Scores**: When scores are tied, as for patients (B, C), (D, E), and (G, H), a scientifically valid and internally consistent sweep of the threshold $\\tau$ requires that all cases at a given score value are classified simultaneously. For example, when $\\tau$ is lowered to $0.90$, both patients B and C are newly classified as positive. The counts of $\\mathrm{TP}$ and $\\mathrm{FP}$ are updated by considering all cases at that score as a single block, and one distinct $(R, P)$ point is computed.\n\nThe sequence of decision thresholds that generate new $(R, P)$ points is the ordered set of unique scores: $\\{\\tau_1, \\tau_2, \\tau_3, \\tau_4, \\tau_5\\} = \\{0.92, 0.90, 0.85, 0.80, 0.75\\}$.\n\nWe now calculate the cumulative counts of $\\mathrm{TP}$ and $\\mathrm{FP}$, and the resulting $(R, P)$ values for each threshold.\n\n- **Initial state ($\\tau > 0.92$)**: No patients are classified as positive. $\\mathrm{TP}=0, \\mathrm{FP}=0$. This gives $R=0$. Precision is undefined ($\\frac{0}{0}$). By convention, the PR curve can be initiated at $(R, P)=(0, 1)$, representing the state of a classifier that makes no positive predictions.\n\n- **$\\tau = 0.92$**: Patient A (label $1$) is now classified as positive.\n  - $\\mathrm{TP}$ increases by $1$, $\\mathrm{FP}$ by $0$. Cumulative: $\\mathrm{TP}=1, \\mathrm{FP}=0$.\n  - $R = \\frac{1}{5} = 0.2$.\n  - $P = \\frac{1}{1+0} = 1$.\n  - Point 1: $(0.2, 1.0)$.\n\n- **$\\tau = 0.90$**: Patients C (label $1$) and B (label $0$) are now classified as positive.\n  - $\\mathrm{TP}$ increases by $1$, $\\mathrm{FP}$ by $1$. Cumulative: $\\mathrm{TP}=1+1=2, \\mathrm{FP}=0+1=1$.\n  - $R = \\frac{2}{5} = 0.4$.\n  - $P = \\frac{2}{2+1} = \\frac{2}{3}$.\n  - Point 2: $(0.4, \\frac{2}{3})$.\n\n- **$\\tau = 0.85$**: Patients D (label $1$) and E (label $0$) are now classified as positive.\n  - $\\mathrm{TP}$ increases by $1$, $\\mathrm{FP}$ by $1$. Cumulative: $\\mathrm{TP}=2+1=3, \\mathrm{FP}=1+1=2$.\n  - $R = \\frac{3}{5} = 0.6$.\n  - $P = \\frac{3}{3+2} = \\frac{3}{5}$.\n  - Point 3: $(0.6, 0.6)$.\n\n- **$\\tau = 0.80$**: Patient F (label $0$) is now classified as positive.\n  - $\\mathrm{TP}$ increases by $0$, $\\mathrm{FP}$ by $1$. Cumulative: $\\mathrm{TP}=3, \\mathrm{FP}=2+1=3$.\n  - $R = \\frac{3}{5} = 0.6$. (Recall does not change).\n  - $P = \\frac{3}{3+3} = \\frac{3}{6} = 0.5$.\n  - Point 4: $(0.6, 0.5)$.\n\n- **$\\tau = 0.75$**: Patients G (label $1$) and H (label $1$) are now classified as positive.\n  - $\\mathrm{TP}$ increases by $2$, $\\mathrm{FP}$ by $0$. Cumulative: $\\mathrm{TP}=3+2=5, \\mathrm{FP}=3+0=3$.\n  - $R = \\frac{5}{5} = 1.0$.\n  - $P = \\frac{5}{5+3} = \\frac{5}{8}$.\n  - Point 5: $(1.0, \\frac{5}{8})$.\n\nThe sequence of distinct $(R, P)$ points generated is $(0.2, 1)$, $(0.4, 2/3)$, $(0.6, 3/5)$, $(0.6, 1/2)$, and $(1.0, 5/8)$.\n\n#### Part 2: Area Under the PR Curve (AUPRC)\n\nThe \"step-function interpretation\" for the AUPRC corresponds to the computation of Average Precision (AP), which is the area under the non-interpolated PR curve. This is calculated as a sum of rectangular areas, where each rectangle's width is the increase in recall and its height is the precision at that point. The formula is:\n$$ \\mathrm{AUPRC} = \\sum_{k} (R_k - R_{k-1}) P_k $$\nwhere the sum is over the points $k$ where recall increases. The term $(R_k - R_{k-1})$ represents the increase in recall, and $P_k$ is the precision measured at recall level $R_k$.\n\nWe identify the thresholds where recall increases and calculate the corresponding area contributions:\n\n1.  At $\\tau = 0.92$, one true positive is found. Recall increases from $R_0 = 0$ to $R_1 = 0.2$. The precision is $P_1 = 1$.\n    Area contribution: $(0.2 - 0) \\times 1 = 0.2$.\n\n2.  At $\\tau = 0.90$, one true positive is found. Recall increases from $R_1 = 0.2$ to $R_2 = 0.4$. The precision is $P_2 = \\frac{2}{3}$.\n    Area contribution: $(0.4 - 0.2) \\times \\frac{2}{3} = 0.2 \\times \\frac{2}{3} = \\frac{1}{5} \\times \\frac{2}{3} = \\frac{2}{15}$.\n\n3.  At $\\tau = 0.85$, one true positive is found. Recall increases from $R_2 = 0.4$ to $R_3 = 0.6$. The precision is $P_3 = \\frac{3}{5}$.\n    Area contribution: $(0.6 - 0.4) \\times \\frac{3}{5} = 0.2 \\times \\frac{3}{5} = \\frac{1}{5} \\times \\frac{3}{5} = \\frac{3}{25}$.\n\n4.  At $\\tau = 0.80$, only a false positive is found. Recall does not change. Thus, this step contributes no area to the AUPRC calculation, i.e., $(R_3-R_3) \\times P_4 = 0$. This point simply creates a vertical drop on the PR plot.\n\n5.  At $\\tau = 0.75$, two true positives are found. Recall increases from $R_3 = 0.6$ to $R_5 = 1.0$. The precision is $P_5 = \\frac{5}{8}$.\n    Area contribution: $(1.0 - 0.6) \\times \\frac{5}{8} = 0.4 \\times \\frac{5}{8} = \\frac{2}{5} \\times \\frac{5}{8} = \\frac{10}{40} = \\frac{1}{4}$.\n\nThe total AUPRC is the sum of these contributions:\n$$ \\mathrm{AUPRC} = \\left( \\frac{1}{5} \\times 1 \\right) + \\left( \\frac{1}{5} \\times \\frac{2}{3} \\right) + \\left( \\frac{1}{5} \\times \\frac{3}{5} \\right) + \\left( \\frac{2}{5} \\times \\frac{5}{8} \\right) $$\n$$ \\mathrm{AUPRC} = \\frac{1}{5} + \\frac{2}{15} + \\frac{3}{25} + \\frac{10}{40} = \\frac{1}{5} + \\frac{2}{15} + \\frac{3}{25} + \\frac{1}{4} $$\nTo sum these fractions, we find a common denominator, which is $\\mathrm{LCM}(5, 15, 25, 4) = \\mathrm{LCM}(5, 3 \\cdot 5, 5^2, 2^2) = 3 \\cdot 5^2 \\cdot 2^2 = 300$.\n$$ \\mathrm{AUPRC} = \\frac{1 \\times 60}{300} + \\frac{2 \\times 20}{300} + \\frac{3 \\times 12}{300} + \\frac{1 \\times 75}{300} $$\n$$ \\mathrm{AUPRC} = \\frac{60 + 40 + 36 + 75}{300} = \\frac{211}{300} $$\nAs a decimal, this is $211 \\div 300 \\approx 0.703333...$.\nRounding to four significant figures, the final result is $0.7033$.", "answer": "$$\n\\boxed{0.7033}\n$$", "id": "4556368"}, {"introduction": "While calculating the Area Under the PR Curve (PR-AUC) seems straightforward, the specific method used can significantly impact the result. This problem highlights a critical distinction between the standard, stepwise Average Precision (AP) and a common but potentially misleading trapezoidal approximation. By working through a carefully constructed example, you will quantify the optimistic bias introduced by linear interpolation and understand why the stepwise method is the scientifically preferred standard for evaluating ranked predictions. [@problem_id:4556339]", "problem": "In a radiomics classification study using Magnetic Resonance Imaging (MRI), a model ranks lesion candidates by a continuous malignancy score derived from quantitative radiomic features. Let the dataset contain $6$ candidates, with $3$ truly malignant (positive) and $3$ benign (negative). The candidates are sorted by the model score in descending order, and their ground-truth labels along this order are:\n$$[1,\\,0,\\,0,\\,1,\\,0,\\,1],$$\nwhere $1$ denotes malignant and $0$ denotes benign. The conventional Precision-Recall Area Under the Curve (PR-AUC) is sometimes approximated by linearly interpolating precision between successive recall points and summing trapezoid areas. Average Precision (AP) is defined via the area under the stepwise precision-recall function that holds precision constant over each recall increment. Use the fundamental definitions of precision $P$ and recall $R$,\n$$P=\\frac{\\text{True Positives (TP)}}{\\text{TP}+\\text{False Positives (FP)}}, \\quad R=\\frac{\\text{TP}}{\\text{TP}+\\text{False Negatives (FN)}},$$\nto compute the precision-recall points at the thresholds where recall changes (i.e., immediately after each new true positive is included). Then:\n1. Compute the stepwise area that defines Average Precision (AP) over the recall axis.\n2. Compute the trapezoidal PR-AUC using linear interpolation in precision between successive recall-change points. For interpolation, include the conventional initial point at $(R,P)=(0,1)$.\n3. Define the bias as $b=\\text{PR-AUC}_{\\text{trap}}-\\text{AP}$ and compute it exactly.\n\nDemonstrate that, for this ranked example, trapezoidal PR-AUC overestimates AP and determine the exact bias $b$. Express the final bias as a simplified fraction with no units. No rounding is required.", "solution": "The problem requires the computation and comparison of two different metrics for the area under the Precision-Recall (PR) curve: Average Precision (AP), which is based on a stepwise interpolation, and a trapezoidal PR Area Under the Curve (PR-AUC), which is based on linear interpolation. The goal is to find the bias, defined as the difference between these two values for a given ranked list of classification outcomes.\n\nFirst, we establish the ground truth from the provided information. The dataset has $6$ candidates. The number of truly malignant (positive) instances is $P_{total} = 3$, and the number of truly benign (negative) instances is $N_{total} = 3$. The total number of positives is also given by the sum of True Positives (TP) and False Negatives (FN), so $\\text{TP}+\\text{FN} = P_{total} = 3$. The definitions for precision ($P$) and recall ($R$) are:\n$$P = \\frac{\\text{TP}}{\\text{TP}+\\text{FP}}$$\n$$R = \\frac{\\text{TP}}{\\text{TP}+\\text{FN}} = \\frac{\\text{TP}}{3}$$\n\nThe model's output is a ranked list of the ground-truth labels, from highest score to lowest: $[1, 0, 0, 1, 0, 1]$, where $1$ denotes a positive class (malignant) and $0$ denotes a negative class (benign).\n\nWe will process this list sequentially to determine the values of TP, FP, precision, and recall at each rank. The recall value changes only when a true positive instance is encountered. We need to identify the precision-recall points at these specific ranks.\n\nLet $k$ be the rank from $1$ to $6$.\n- At rank $k=1$: Label is $1$.\n  - We have processed one positive. TP$=1$, FP$=0$.\n  - $P_1 = \\frac{1}{1+0} = 1$.\n  - $R_1 = \\frac{1}{3}$. This is our first recall-change point: $(R_1, P_1) = (\\frac{1}{3}, 1)$.\n\n- At rank $k=2$: Label is $0$.\n  - TP$=1$, FP$=1$. Recall does not change.\n  - $P = \\frac{1}{1+1} = \\frac{1}{2}$.\n\n- At rank $k=3$: Label is $0$.\n  - TP$=1$, FP$=2$. Recall does not change.\n  - $P = \\frac{1}{1+2} = \\frac{1}{3}$.\n\n- At rank $k=4$: Label is $1$.\n  - We have now processed two positives. TP$=2$. There are two negatives ahead of this rank. FP$=2$.\n  - $P_2 = \\frac{2}{2+2} = \\frac{1}{2}$.\n  - $R_2 = \\frac{2}{3}$. This is our second recall-change point: $(R_2, P_2) = (\\frac{2}{3}, \\frac{1}{2})$.\n\n- At rank $k=5$: Label is $0$.\n  - TP$=2$, FP$=3$. Recall does not change.\n  - $P = \\frac{2}{2+3} = \\frac{2}{5}$.\n\n- At rank $k=6$: Label is $1$.\n  - We have now processed three positives. TP$=3$. There are three negatives in total. FP$=3$.\n  - $P_3 = \\frac{3}{3+3} = \\frac{1}{2}$.\n  - $R_3 = \\frac{3}{3} = 1$. This is our third recall-change point: $(R_3, P_3) = (1, \\frac{1}{2})$.\n\nThe recall-change points are: $(\\frac{1}{3}, 1)$, $(\\frac{2}{3}, \\frac{1}{2})$, and $(1, \\frac{1}{2})$.\n\n**1. Compute Average Precision (AP)**\nAverage Precision is the weighted average of precisions at each rank where a true positive is found, weighted by the change in recall. This is equivalent to the area under the stepwise PR curve.\nThe AP is calculated as a sum of rectangular areas:\n$$\\text{AP} = \\sum_{k} P(k) \\Delta R(k)$$\nwhere the sum is over the ranks $k$ where the item is positive, $P(k)$ is the precision at rank $k$, and $\\Delta R(k)$ is the change in recall, which is $\\frac{1}{P_{total}} = \\frac{1}{3}$ for each positive item.\nThe precisions at the ranks of the positive items are:\n- Rank $1$: $P(1) = 1$.\n- Rank $4$: $P(4) = \\frac{2}{4} = \\frac{1}{2}$.\n- Rank $6$: $P(6) = \\frac{3}{6} = \\frac{1}{2}$.\n\n$$\\text{AP} = \\left(P(1)\\times\\frac{1}{3}\\right) + \\left(P(4)\\times\\frac{1}{3}\\right) + \\left(P(6)\\times\\frac{1}{3}\\right) = \\frac{1}{3} (P(1) + P(4) + P(6))$$\n$$\\text{AP} = \\frac{1}{3} \\left(1 + \\frac{1}{2} + \\frac{1}{2}\\right) = \\frac{1}{3} (2) = \\frac{2}{3}$$\n\n**2. Compute Trapezoidal PR-AUC**\nThis metric is computed by summing the areas of trapezoids formed by linearly interpolating between successive recall-change points. The problem specifies including an initial point $(R_0, P_0)=(0, 1)$. The points for interpolation are:\n- Point $0$: $(R_0, P_0) = (0, 1)$\n- Point $1$: $(R_1, P_1) = (\\frac{1}{3}, 1)$\n- Point $2$: $(R_2, P_2) = (\\frac{2}{3}, \\frac{1}{2})$\n- Point $3$: $(R_3, P_3) = (1, \\frac{1}{2})$\n\nThe area of a trapezoid between points $(R_{i-1}, P_{i-1})$ and $(R_i, P_i)$ is $\\frac{1}{2}(P_{i-1} + P_i)(R_i - R_{i-1})$.\n\n- Area of Trapezoid $1$ (between points $0$ and $1$):\n$$A_1 = \\frac{1}{2}(P_0 + P_1)(R_1 - R_0) = \\frac{1}{2}(1 + 1)\\left(\\frac{1}{3} - 0\\right) = \\frac{1}{2}(2)\\left(\\frac{1}{3}\\right) = \\frac{1}{3}$$\n\n- Area of Trapezoid $2$ (between points $1$ and $2$):\n$$A_2 = \\frac{1}{2}(P_1 + P_2)(R_2 - R_1) = \\frac{1}{2}\\left(1 + \\frac{1}{2}\\right)\\left(\\frac{2}{3} - \\frac{1}{3}\\right) = \\frac{1}{2}\\left(\\frac{3}{2}\\right)\\left(\\frac{1}{3}\\right) = \\frac{1}{4}$$\n\n- Area of Trapezoid $3$ (between points $2$ and $3$):\n$$A_3 = \\frac{1}{2}(P_2 + P_3)(R_3 - R_2) = \\frac{1}{2}\\left(\\frac{1}{2} + \\frac{1}{2}\\right)\\left(1 - \\frac{2}{3}\\right) = \\frac{1}{2}(1)\\left(\\frac{1}{3}\\right) = \\frac{1}{6}$$\n\nThe total trapezoidal PR-AUC is the sum of these areas:\n$$\\text{PR-AUC}_{\\text{trap}} = A_1 + A_2 + A_3 = \\frac{1}{3} + \\frac{1}{4} + \\frac{1}{6}$$\nTo sum these fractions, we find a common denominator, which is $12$:\n$$\\text{PR-AUC}_{\\text{trap}} = \\frac{4}{12} + \\frac{3}{12} + \\frac{2}{12} = \\frac{9}{12} = \\frac{3}{4}$$\n\n**3. Compute the bias, $b$**\nThe bias is defined as $b = \\text{PR-AUC}_{\\text{trap}} - \\text{AP}$.\n$$b = \\frac{3}{4} - \\frac{2}{3}$$\nAgain, we use a common denominator of $12$:\n$$b = \\frac{9}{12} - \\frac{8}{12} = \\frac{1}{12}$$\n\nThe value of the trapezoidal PR-AUC is $\\frac{3}{4} = 0.75$, while the value of AP is $\\frac{2}{3} \\approx 0.667$. The trapezoidal approximation indeed overestimates the AP, and the bias $b = \\frac{1}{12}$ is positive. The bias arises from any segment where precision decreases between two recall points, as the linear interpolation line segment will lie strictly above the piecewise-constant function used for AP. In this case, the bias is entirely generated in the interval of recall from $\\frac{1}{3}$ to $\\frac{2}{3}$.", "answer": "$$\\boxed{\\frac{1}{12}}$$", "id": "4556339"}, {"introduction": "A high Average Precision score is desirable, but does it tell the whole story? This practice moves beyond single-metric evaluation to explore how PR curves inform practical, decision-making scenarios with real-world consequences. By analyzing two models with identical AP but different performance characteristics, you will learn to apply a clinical utility function to find the optimal operating point, demonstrating that the best model often depends on the specific costs and benefits of its application. [@problem_id:4556382]", "problem": "A radiomics team is developing binary classifiers to identify malignant lesions from computed tomography scans. They compare two models using the Precision-Recall (PR) analysis. Let the total number of malignant lesions be $N_{+}$ and the total number of benign lesions be $N_{-}$. In this study, $N_{+} = 400$ and $N_{-} = 1600$. Precision is defined as $P = \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FP})$ and recall is defined as $R = \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FN})$, where $\\mathrm{TP}$, $\\mathrm{FP}$, and $\\mathrm{FN}$ denote the numbers of true positives, false positives, and false negatives, respectively. Average Precision (AP) is the area under the PR curve $P(R)$ over $R \\in [0,1]$.\n\nModel $\\mathrm{A}$ has a PR curve that is flat at $P_{\\mathrm{A}}(R) = 0.8$ for all $R \\in [0,1]$. Model $\\mathrm{B}$ has $P_{\\mathrm{B}}(R) = 1$ for $R \\in [0,0.2]$ and $P_{\\mathrm{B}}(R) = 0.75$ for $R \\in (0.2,1]$. Both models are calibrated and monotonic in score, so any operating threshold selects a point $(P(R), R)$ on the corresponding PR curve. The clinical team evaluates each threshold via a utility function that assigns $b$ utility units for each true positive and incurs a cost of $c$ utility units for each false positive. For this application, $b = 1$ and $c = 3$.\n\nStarting only from the definitions of precision, recall, and AP, and treating the PR curves above as the achievable operating characteristics, determine the difference between the maximum attainable expected utility of Model $\\mathrm{A}$ and Model $\\mathrm{B}$ when the threshold is optimally chosen for each model. Express your final answer as a single real number.", "solution": "The fundamental definitions are precision $P = \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FP})$ and recall $R = \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FN})$. From recall, since $N_{+} = \\mathrm{TP} + \\mathrm{FN}$, one obtains $\\mathrm{TP}(R) = R \\, N_{+}$. From precision, rearranging $P = \\mathrm{TP} / (\\mathrm{TP} + \\mathrm{FP})$ yields\n$$\n\\mathrm{FP} = \\mathrm{TP}\\left(\\frac{1}{P} - 1\\right).\n$$\nTherefore, for a given operating point with recall $R$ and precision $P(R)$, the false positives are\n$$\n\\mathrm{FP}(R) = R \\, N_{+}\\left(\\frac{1}{P(R)} - 1\\right).\n$$\nThe expected utility at an operating point is defined as\n$$\nU(R) = b \\cdot \\mathrm{TP}(R) - c \\cdot \\mathrm{FP}(R) = R \\, N_{+} \\left[ b - c\\left(\\frac{1}{P(R)} - 1\\right) \\right].\n$$\nFor Model $\\mathrm{A}$, $P_{\\mathrm{A}}(R) = 0.8$ for all $R \\in [0,1]$. Thus,\n$$\n\\frac{1}{P_{\\mathrm{A}}(R)} - 1 = \\frac{1}{0.8} - 1 = \\frac{5}{4} - 1 = \\frac{1}{4}.\n$$\nWith $b = 1$ and $c = 3$, the bracketed term becomes\n$$\nb - c\\left(\\frac{1}{P_{\\mathrm{A}}(R)} - 1\\right) = 1 - 3 \\cdot \\frac{1}{4} = 1 - \\frac{3}{4} = \\frac{1}{4}.\n$$\nTherefore,\n$$\nU_{\\mathrm{A}}(R) = R \\, N_{+} \\cdot \\frac{1}{4}.\n$$\nSince this is linear and increasing in $R$ over $[0,1]$, the maximum is attained at $R = 1$:\n$$\nU_{\\mathrm{A}}^{\\ast} = 1 \\cdot N_{+} \\cdot \\frac{1}{4} = \\frac{N_{+}}{4} = \\frac{400}{4} = 100.\n$$\n\nFor Model $\\mathrm{B}$, consider the two regions.\n\nFor $R \\in [0,0.2]$, $P_{\\mathrm{B}}(R) = 1$, so\n$$\n\\frac{1}{P_{\\mathrm{B}}(R)} - 1 = \\frac{1}{1} - 1 = 0,\n$$\nand\n$$\nU_{\\mathrm{B}}(R) = R \\, N_{+} \\left[ b - c \\cdot 0 \\right] = R \\, N_{+} \\cdot b = R \\cdot 400 \\cdot 1 = 400 R.\n$$\nThis is increasing on $[0,0.2]$ and reaches\n$$\nU_{\\mathrm{B}}(0.2) = 400 \\cdot 0.2 = 80.\n$$\n\nFor $R \\in (0.2,1]$, $P_{\\mathrm{B}}(R) = 0.75 = \\frac{3}{4}$, so\n$$\n\\frac{1}{P_{\\mathrm{B}}(R)} - 1 = \\frac{4}{3} - 1 = \\frac{1}{3},\n$$\nand\n$$\nb - c\\left(\\frac{1}{P_{\\mathrm{B}}(R)} - 1\\right) = 1 - 3 \\cdot \\frac{1}{3} = 1 - 1 = 0.\n$$\nHence,\n$$\nU_{\\mathrm{B}}(R) = R \\, N_{+} \\cdot 0 = 0 \\quad \\text{for } R \\in (0.2,1].\n$$\nTherefore, the maximum attainable utility for Model $\\mathrm{B}$ is achieved at $R = 0.2$ and equals $U_{\\mathrm{B}}^{\\ast} = 80$.\n\nWe also confirm the scenario’s identical Average Precision (AP): for Model $\\mathrm{A}$,\n$$\n\\mathrm{AP}_{\\mathrm{A}} = \\int_{0}^{1} 0.8 \\, dR = 0.8,\n$$\nand for Model $\\mathrm{B}$,\n$$\n\\mathrm{AP}_{\\mathrm{B}} = \\int_{0}^{0.2} 1 \\, dR + \\int_{0.2}^{1} 0.75 \\, dR = 1 \\cdot 0.2 + 0.75 \\cdot 0.8 = 0.2 + 0.6 = 0.8.\n$$\nThus both models have identical AP, yet their maximum attainable utilities differ due to divergent high-recall precision behavior.\n\nThe requested difference between the models’ maximum attainable expected utilities is\n$$\n\\Delta U = U_{\\mathrm{A}}^{\\ast} - U_{\\mathrm{B}}^{\\ast} = 100 - 80 = 20.\n$$", "answer": "$$\\boxed{20}$$", "id": "4556382"}]}