{"hands_on_practices": [{"introduction": "At the heart of resampling is the geometric transformation that links the new voxel grid to the original one. This exercise [@problem_id:4546648] challenges you to build this transformation from the ground up, combining anisotropic scaling, rotation, and translation into a single, elegant affine matrix. Mastering this foundational step is crucial for understanding how software tools perform resampling under the hood.", "problem": "A Computed Tomography (CT) volume used for radiomics feature extraction is defined on a discrete source grid with anisotropic voxel spacings $s_{x} = 0.8$ millimeters, $s_{y} = 1.2$ millimeters, and $s_{z} = 2.5$ millimeters, and with a rigid orientation and position in scanner physical coordinates given by a rotation about the $z$-axis by $30$ degrees and a translation of $\\boldsymbol{t}_{s} = [12, -6, 4]^{\\top}$ millimeters. The target grid for resampling is isotropic with spacing $\\Delta = 1.0$ millimeters, aligned with the scanner axes (identity orientation), and with origin at $\\boldsymbol{t}_{t} = [0,0,0]^{\\top}$ millimeters. Angles are specified in degrees.\n\nStarting only from foundational definitions about affine mappings between index coordinates and physical coordinates, and the principle of backward mapping for interpolation, derive the composite affine transformation in homogeneous coordinates that maps target grid indices to source grid indices. Use these base definitions:\n\n- The mapping from source index coordinates $\\boldsymbol{u} = [u_{x},\\,u_{y},\\,u_{z}]^{\\top}$ to source physical coordinates $\\boldsymbol{p}_{s}$ is $\\boldsymbol{p}_{s} = \\boldsymbol{R}_{s}\\,\\boldsymbol{S}_{s}\\,\\boldsymbol{u} + \\boldsymbol{t}_{s}$, where $\\boldsymbol{S}_{s} = \\mathrm{diag}(s_{x},\\,s_{y},\\,s_{z})$ and $\\boldsymbol{R}_{s}$ is the rotation matrix corresponding to $30$ degrees about the $z$-axis.\n- The mapping from target index coordinates $\\boldsymbol{v} = [v_{x},\\,v_{y},\\,v_{z}]^{\\top}$ to target physical coordinates $\\boldsymbol{p}_{t}$ is $\\boldsymbol{p}_{t} = \\boldsymbol{R}_{t}\\,\\boldsymbol{S}_{t}\\,\\boldsymbol{v} + \\boldsymbol{t}_{t}$, where $\\boldsymbol{R}_{t}$ is the identity matrix, $\\boldsymbol{S}_{t} = \\Delta\\,\\boldsymbol{I}$, and $\\boldsymbol{I}$ is the identity matrix.\n\nUse the backward mapping principle that sampling locations in the source are obtained by equating physical coordinates $\\boldsymbol{p}_{t} = \\boldsymbol{p}_{s}$, and then solving for $\\boldsymbol{u}$ as a function of $\\boldsymbol{v}$. Construct the homogeneous $4 \\times 4$ affine matrix $\\boldsymbol{A}$ such that\n$$\n\\begin{pmatrix}\n\\boldsymbol{u} \\\\\n1\n\\end{pmatrix}\n=\n\\boldsymbol{A}\n\\begin{pmatrix}\n\\boldsymbol{v} \\\\\n1\n\\end{pmatrix}.\n$$\nExplicitly show the composition steps from the base definitions, and state the backward mapping formula that turns a target index $\\boldsymbol{v}$ into a continuous source sampling location $\\boldsymbol{u}$ for subsequent interpolation. Express the final affine $\\boldsymbol{A}$ in exact analytic form using radicals for trigonometric values and fractions for scalings; do not round. The final answer must be the single homogeneous matrix $\\boldsymbol{A}$, with no units included in the matrix entries.", "solution": "The user wants to derive the composite affine transformation in homogeneous coordinates that maps target grid indices to source grid indices.\n\nThe provided problem is **valid** as it is scientifically grounded in the principles of medical image processing and coordinate transformations, is well-posed with all necessary information, and is stated objectively.\n\n### Introduction to Coordinate Transformations\n\nThe problem requires us to find a transformation from the target grid's index coordinates, denoted by $\\boldsymbol{v}$, to the source grid's index coordinates, denoted by $\\boldsymbol{u}$. The process involves mapping from an index space to a physical space, and then back to another index space. This is a standard procedure in image resampling, where the value of a target voxel is determined by sampling the source image at a corresponding location.\n\n### Foundational Definitions\n\nLet's first establish the given transformations from index coordinates to physical coordinates.\n\n**1. Source Grid Transformation:**\nThe mapping from source index coordinates $\\boldsymbol{u} = [u_{x}, u_{y}, u_{z}]^{\\top}$ to source physical coordinates $\\boldsymbol{p}_{s}$ is given by the affine transformation:\n$$ \\boldsymbol{p}_{s} = \\boldsymbol{R}_{s} \\boldsymbol{S}_{s} \\boldsymbol{u} + \\boldsymbol{t}_{s} $$\nwhere:\n*   $\\boldsymbol{S}_{s}$ is the diagonal scaling matrix from the anisotropic voxel spacings $s_{x} = 0.8 = \\frac{4}{5}$, $s_{y} = 1.2 = \\frac{6}{5}$, and $s_{z} = 2.5 = \\frac{5}{2}$ (all in millimeters):\n    $$ \\boldsymbol{S}_{s} = \\begin{pmatrix} \\frac{4}{5}  0  0 \\\\ 0  \\frac{6}{5}  0 \\\\ 0  0  \\frac{5}{2} \\end{pmatrix} $$\n*   $\\boldsymbol{R}_{s}$ is the rotation matrix for a rotation about the $z$-axis by an angle $\\theta = 30^{\\circ}$. Using $\\cos(30^{\\circ}) = \\frac{\\sqrt{3}}{2}$ and $\\sin(30^{\\circ}) = \\frac{1}{2}$:\n    $$ \\boldsymbol{R}_{s} = \\begin{pmatrix} \\cos(\\theta)  -\\sin(\\theta)  0 \\\\ \\sin(\\theta)  \\cos(\\theta)  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2}  -\\frac{1}{2}  0 \\\\ \\frac{1}{2}  \\frac{\\sqrt{3}}{2}  0 \\\\ 0  0  1 \\end{pmatrix} $$\n*   $\\boldsymbol{t}_{s}$ is the translation vector:\n    $$ \\boldsymbol{t}_{s} = \\begin{pmatrix} 12 \\\\ -6 \\\\ 4 \\end{pmatrix} $$\n\n**2. Target Grid Transformation:**\nThe mapping from target index coordinates $\\boldsymbol{v} = [v_{x}, v_{y}, v_{z}]^{\\top}$ to target physical coordinates $\\boldsymbol{p}_{t}$ is:\n$$ \\boldsymbol{p}_{t} = \\boldsymbol{R}_{t} \\boldsymbol{S}_{t} \\boldsymbol{v} + \\boldsymbol{t}_{t} $$\nwhere:\n*   $\\boldsymbol{S}_{t}$ is the isotropic scaling matrix with spacing $\\Delta = 1.0$:\n    $$ \\boldsymbol{S}_{t} = \\Delta \\boldsymbol{I} = 1.0 \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} = \\boldsymbol{I} $$\n*   $\\boldsymbol{R}_{t}$ is the identity rotation matrix:\n    $$ \\boldsymbol{R}_{t} = \\boldsymbol{I} $$\n*   $\\boldsymbol{t}_{t}$ is the null translation vector:\n    $$ \\boldsymbol{t}_{t} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThe target transformation simplifies to $\\boldsymbol{p}_{t} = \\boldsymbol{I} \\boldsymbol{I} \\boldsymbol{v} + \\boldsymbol{0} = \\boldsymbol{v}$. This means the target index coordinates are identical to their physical coordinates.\n\n### Backward Mapping Principle\n\nThe principle of backward mapping requires that for any point in the target grid, we find its corresponding location in the source grid. This is achieved by equating their physical coordinates:\n$$ \\boldsymbol{p}_{s} = \\boldsymbol{p}_{t} $$\nSubstituting the definitions of the transformations:\n$$ \\boldsymbol{R}_{s} \\boldsymbol{S}_{s} \\boldsymbol{u} + \\boldsymbol{t}_{s} = \\boldsymbol{R}_{t} \\boldsymbol{S}_{t} \\boldsymbol{v} + \\boldsymbol{t}_{t} $$\nWe need to solve this equation for $\\boldsymbol{u}$ as a function of $\\boldsymbol{v}$. Let $\\boldsymbol{M}_{s} = \\boldsymbol{R}_{s} \\boldsymbol{S}_{s}$ and $\\boldsymbol{M}_{t} = \\boldsymbol{R}_{t} \\boldsymbol{S}_{t}$.\n$$ \\boldsymbol{M}_{s} \\boldsymbol{u} + \\boldsymbol{t}_{s} = \\boldsymbol{M}_{t} \\boldsymbol{v} + \\boldsymbol{t}_{t} $$\n$$ \\boldsymbol{M}_{s} \\boldsymbol{u} = \\boldsymbol{M}_{t} \\boldsymbol{v} + (\\boldsymbol{t}_{t} - \\boldsymbol{t}_{s}) $$\n$$ \\boldsymbol{u} = \\boldsymbol{M}_{s}^{-1} (\\boldsymbol{M}_{t} \\boldsymbol{v} + \\boldsymbol{t}_{t} - \\boldsymbol{t}_{s}) = (\\boldsymbol{M}_{s}^{-1} \\boldsymbol{M}_{t}) \\boldsymbol{v} + \\boldsymbol{M}_{s}^{-1} (\\boldsymbol{t}_{t} - \\boldsymbol{t}_{s}) $$\nSubstituting the target grid's specifics ($\\boldsymbol{M}_{t} = \\boldsymbol{I}$ and $\\boldsymbol{t}_{t} = \\boldsymbol{0}$):\n$$ \\boldsymbol{u} = (\\boldsymbol{M}_{s}^{-1} \\boldsymbol{I}) \\boldsymbol{v} + \\boldsymbol{M}_{s}^{-1} (\\boldsymbol{0} - \\boldsymbol{t}_{s}) = \\boldsymbol{M}_{s}^{-1} \\boldsymbol{v} - \\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s} $$\nThis expression is the backward mapping formula that gives the continuous source index location $\\boldsymbol{u}$ for a given target index $\\boldsymbol{v}$.\n\n### Homogeneous Transformation\n\nThe affine transformation $\\boldsymbol{u} = \\boldsymbol{L} \\boldsymbol{v} + \\boldsymbol{c}$ can be expressed in homogeneous coordinates using a $4 \\times 4$ matrix $\\boldsymbol{A}$:\n$$ \\begin{pmatrix} \\boldsymbol{u} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\boldsymbol{L}  \\boldsymbol{c} \\\\ \\boldsymbol{0}^{\\top}  1 \\end{pmatrix} \\begin{pmatrix} \\boldsymbol{v} \\\\ 1 \\end{pmatrix} = \\boldsymbol{A} \\begin{pmatrix} \\boldsymbol{v} \\\\ 1 \\end{pmatrix} $$\nFrom our derived formula, the linear part is $\\boldsymbol{L} = \\boldsymbol{M}_{s}^{-1}$ and the translation part is $\\boldsymbol{c} = -\\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s}$.\nThus, the composite affine transformation matrix $\\boldsymbol{A}$ is:\n$$ \\boldsymbol{A} = \\begin{pmatrix} \\boldsymbol{M}_{s}^{-1}  -\\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s} \\\\ \\boldsymbol{0}^{\\top}  1 \\end{pmatrix} $$\nThis is precisely the inverse of the homogeneous matrix $\\boldsymbol{H}_{s}$ that maps source indices to physical space:\n$$ \\boldsymbol{H}_{s} = \\begin{pmatrix} \\boldsymbol{M}_{s}  \\boldsymbol{t}_{s} \\\\ \\boldsymbol{0}^{\\top}  1 \\end{pmatrix} \\implies \\boldsymbol{H}_{s}^{-1} = \\begin{pmatrix} \\boldsymbol{M}_{s}^{-1}  -\\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s} \\\\ \\boldsymbol{0}^{\\top}  1 \\end{pmatrix} = \\boldsymbol{A} $$\n\n### Calculation of Matrix Components\n\nWe now compute the components of $\\boldsymbol{A}$.\n\n**1. Inverse of the Linear Part $\\boldsymbol{M}_{s}^{-1}$:**\n$$ \\boldsymbol{M}_{s}^{-1} = (\\boldsymbol{R}_{s} \\boldsymbol{S}_{s})^{-1} = \\boldsymbol{S}_{s}^{-1} \\boldsymbol{R}_{s}^{-1} $$\n*   The inverse of the scaling matrix $\\boldsymbol{S}_{s}$ is:\n    $$ \\boldsymbol{S}_{s}^{-1} = \\begin{pmatrix} \\frac{5}{4}  0  0 \\\\ 0  \\frac{5}{6}  0 \\\\ 0  0  \\frac{2}{5} \\end{pmatrix} $$\n*   The inverse of the rotation matrix $\\boldsymbol{R}_{s}$ is its transpose, $\\boldsymbol{R}_{s}^{-1} = \\boldsymbol{R}_{s}^{\\top}$:\n    $$ \\boldsymbol{R}_{s}^{-1} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2}  \\frac{1}{2}  0 \\\\ -\\frac{1}{2}  \\frac{\\sqrt{3}}{2}  0 \\\\ 0  0  1 \\end{pmatrix} $$\n*   Now, we compute the product $\\boldsymbol{M}_{s}^{-1} = \\boldsymbol{S}_{s}^{-1} \\boldsymbol{R}_{s}^{-1}$:\n    $$ \\boldsymbol{M}_{s}^{-1} = \\begin{pmatrix} \\frac{5}{4}  0  0 \\\\ 0  \\frac{5}{6}  0 \\\\ 0  0  \\frac{2}{5} \\end{pmatrix} \\begin{pmatrix} \\frac{\\sqrt{3}}{2}  \\frac{1}{2}  0 \\\\ -\\frac{1}{2}  \\frac{\\sqrt{3}}{2}  0 \\\\ 0  0  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{5\\sqrt{3}}{8}  \\frac{5}{8}  0 \\\\ -\\frac{5}{12}  \\frac{5\\sqrt{3}}{12}  0 \\\\ 0  0  \\frac{2}{5} \\end{{pmatrix} $$\n\n**2. Translation Vector $\\boldsymbol{c} = -\\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s}$:**\nWe first calculate $\\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s}$:\n$$ \\boldsymbol{M}_{s}^{-1} \\boldsymbol{t}_{s} = \\begin{pmatrix} \\frac{5\\sqrt{3}}{8}  \\frac{5}{8}  0 \\\\ -\\frac{5}{12}  \\frac{5\\sqrt{3}}{12}  0 \\\\ 0  0  \\frac{2}{5} \\end{pmatrix} \\begin{pmatrix} 12 \\\\ -6 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} (\\frac{5\\sqrt{3}}{8})(12) + (\\frac{5}{8})(-6) \\\\ (-\\frac{5}{12})(12) + (\\frac{5\\sqrt{3}}{12})(-6) \\\\ (\\frac{2}{5})(4) \\end{pmatrix} $$\n$$ = \\begin{pmatrix} \\frac{15\\sqrt{3}}{2} - \\frac{15}{4} \\\\ -5 - \\frac{5\\sqrt{3}}{2} \\\\ \\frac{8}{5} \\end{pmatrix} $$\nThe translation part of matrix $\\boldsymbol{A}$ is the negative of this vector:\n$$ \\boldsymbol{c} = -\\begin{pmatrix} \\frac{15\\sqrt{3}}{2} - \\frac{15}{4} \\\\ -5 - \\frac{5\\sqrt{3}}{2} \\\\ \\frac{8}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{15}{4} - \\frac{15\\sqrt{3}}{2} \\\\ 5 + \\frac{5\\sqrt{3}}{2} \\\\ -\\frac{8}{5} \\end{pmatrix} $$\n\n### Final Homogeneous Matrix A\n\nBy assembling the calculated components, we obtain the final $4 \\times 4$ homogeneous transformation matrix $\\boldsymbol{A}$:\n$$ \\boldsymbol{A} = \\begin{pmatrix} \\frac{5\\sqrt{3}}{8}  \\frac{5}{8}  0  \\frac{15}{4} - \\frac{15\\sqrt{3}}{2} \\\\ -\\frac{5}{12}  \\frac{5\\sqrt{3}}{12}  0  5 + \\frac{5\\sqrt{3}}{2} \\\\ 0  0  \\frac{2}{5}  -\\frac{8}{5} \\\\ 0  0  0  1 \\end{pmatrix} $$\nThis matrix $\\boldsymbol{A}$ fully describes the transformation from target index coordinates $\\boldsymbol{v}$ to the corresponding continuous source index coordinates $\\boldsymbol{u}$.", "answer": "$$ \\boxed{\n\\begin{pmatrix}\n\\frac{5\\sqrt{3}}{8}  \\frac{5}{8}  0  \\frac{15}{4} - \\frac{15\\sqrt{3}}{2} \\\\\n-\\frac{5}{12}  \\frac{5\\sqrt{3}}{12}  0  5 + \\frac{5\\sqrt{3}}{2} \\\\\n0  0  \\frac{2}{5}  -\\frac{8}{5} \\\\\n0  0  0  1\n\\end{pmatrix}\n} $$", "id": "4546648"}, {"introduction": "Not all image data is the same, and the choice of interpolation method must respect the underlying meaning of the pixel values. This practice [@problem_id:4546655] explores a critical distinction between intensity images and categorical label maps. Through a targeted calculation, you will see firsthand how an otherwise sophisticated method like cubic interpolation can corrupt a segmentation by creating nonsensical, \"spurious\" labels.", "problem": "In radiomics preprocessing, a label image is a function $L:\\Omega\\subset\\mathbb{Z}^d\\to\\mathcal{C}$ where $\\mathcal{C}$ is a finite set of categorical codes (e.g., background, organ, lesion). Unlike intensity images $I:\\Omega\\to\\mathbb{R}$, label images carry categorical semantics without a meaningful linear order or vector-space structure on $\\mathcal{C}$. Resampling an image from one voxel grid to another relies on interpolation, which, by definition, assumes the underlying quantity has algebraic structure that supports forming weighted averages. Consider the widely used cubic convolution (also called bicubic in $2\\text{D}$) interpolation with the Keys kernel, parameterized by $a=-\\frac{1}{2}$, which defines a $1\\text{D}$ kernel $h:\\mathbb{R}\\to\\mathbb{R}$ by\n$$\nh(x)=\\begin{cases}\n(a+2)|x|^3-(a+3)|x|^2+1,0\\le |x|1,\\\\\na|x|^3-5a|x|^2+8a|x|-4a,1\\le |x|2,\\\\\n0,|x|\\ge 2,\n\\end{cases}\n$$\nwith $a=-\\frac{1}{2}$. The interpolated value at a fractional offset $t\\in[0,1]$ between samples $y_1$ and $y_2$ uses the four neighboring samples $y_0,y_1,y_2,y_3$ (indices increasing left to right) and weights\n$$\nw_0=h(1+t),\\quad w_1=h(t),\\quad w_2=h(1-t),\\quad w_3=h(2-t),\n$$\nso that $y(t)=w_0y_0+w_1y_1+w_2y_2+w_3y_3$.\n\nSuppose a binary segmentation label image along a $1\\text{D}$ scanline encodes background as $c=0$ and vessel as $c=2$ (i.e., $\\mathcal{C}=\\{0,2\\}$), with consecutive samples $\\{y_0,y_1,y_2,y_3\\}=\\{0,0,2,2\\}$ at integer positions $\\{x=0,1,2,3\\}$. You resample to a finer grid by interpolating at $x=1.5$ (i.e., $t=\\frac{1}{2}$ between $y_1$ at $x=1$ and $y_2$ at $x=2$), then naively cast the interpolated value to an integer label via a rounding operator $\\mathrm{round}(\\cdot)$, without projecting onto the valid code set $\\mathcal{C}$.\n\nWhich option correctly justifies, from first principles, why nearest-neighbor interpolation is preferred for label images, and also correctly computes the interpolated value $y\\!\\left(\\frac{1}{2}\\right)$ with the Keys cubic kernel and identifies the resulting spurious class and its implication for the label partition?\n\nA. Label images are categorical; averaging codes has no semantic meaning because $\\mathcal{C}$ lacks a vector-space structure. Nearest-neighbor preserves membership by selecting an existing code. Using the Keys cubic kernel with $a=-\\frac{1}{2}$ at $t=\\frac{1}{2}$, the weights are $w_1=h\\!\\left(\\frac{1}{2}\\right)=\\frac{9}{16}$, $w_2=h\\!\\left(\\frac{1}{2}\\right)=\\frac{9}{16}$, and $w_0=w_3=h\\!\\left(\\frac{3}{2}\\right)=-\\frac{1}{16}$, yielding $y\\!\\left(\\frac{1}{2}\\right)=0\\cdot\\!\\left(-\\frac{1}{16}\\right)+0\\cdot\\!\\left(\\frac{9}{16}\\right)+2\\cdot\\!\\left(\\frac{9}{16}\\right)+2\\cdot\\!\\left(-\\frac{1}{16}\\right)=1$. Rounding produces the integer label $1$, which is not in $\\mathcal{C}$, thereby introducing a spurious class and changing the label partition from $\\{0,2\\}$ to $\\{0,1,2\\}$.\n\nB. Nearest-neighbor is dispreferred for label images because it causes aliasing at boundaries; cubic interpolation is safe since rounding will always recover a valid label. For the given data, $y\\!\\left(\\frac{1}{2}\\right)=\\frac{1}{2}(0+2)=1$, but rounding to the nearest valid label yields $2$, so no spurious classes appear.\n\nC. Cubic interpolation on monotone segments is bounded by the convex hull of the samples, so it cannot create intermediate labels. With $\\{0,0,2,2\\}$, $y\\!\\left(\\frac{1}{2}\\right)=2$, and nearest-neighbor is unnecessary because cubic preserves topology.\n\nD. Label codes can be treated as probabilities; cubic interpolation computes a smooth probabilistic mixture and rounding simply recovers the maximum a posteriori class. With the given samples, $y\\!\\left(\\frac{1}{2}\\right)=\\frac{3}{2}$, which rounds to $2$ and preserves the original classes.", "solution": "The problem statement is valid. It is scientifically grounded in the principles of digital image processing and radiomics, well-posed with all necessary data and definitions provided, and written in objective, formal language. There are no contradictions, ambiguities, or factual errors.\n\nThe problem requires a two-part analysis: first, a conceptual justification for the choice of interpolation method for categorical label images, and second, a specific calculation using cubic convolution interpolation.\n\n**Part 1: Conceptual Justification (Interpolation of Categorical Data)**\n\nA label image is a function $L:\\Omega\\subset\\mathbb{Z}^d\\to\\mathcal{C}$, where $\\mathcal{C}$ is a finite set of categorical codes. In this problem, $\\mathcal{C}=\\{0,2\\}$, representing background and vessel, respectively. These codes are identifiers or labels, not quantities on a continuous scale. The set $\\mathcal{C}$ is not a vector space; operations such as addition and scalar multiplication are not semantically meaningful. For example, what is the meaning of $0.5 \\times (\\text{background}) + 0.5 \\times (\\text{vessel})$? The result is not a defined category.\n\nInterpolation methods such as linear, cubic, or spline are based on computing weighted averages of neighboring sample values. This mathematical structure implicitly assumes that the underlying data space is a continuum where such averages are meaningful (e.g., a real vector space, $\\mathbb{R}$). When applied to categorical data like image labels, these methods can produce values outside the original set of codes $\\mathcal{C}$. For instance, interpolating between a label of $0$ and a label of $2$ may yield $1$, $1.5$, or any other real number, which are not valid labels. This introduces spurious classes and corrupts the segmentation map.\n\nIn contrast, nearest-neighbor interpolation assigns the value of the closest sample in the original grid to the new grid location. It performs no arithmetic on the label codes themselves. Consequently, the output value is always an element of the original set $\\mathcal{C}$. This property of preserving the label set is why nearest-neighbor interpolation is the standard and conceptually correct method for resampling categorical images such as segmentations or masks.\n\n**Part 2: Calculation with Keys Cubic Kernel**\n\nWe are asked to compute the interpolated value at $x=1.5$. This point lies halfway between the sample at $x=1$ (with value $y_1=0$) and the sample at $x=2$ (with value $y_2=2$). The fractional offset is thus $t = 1.5 - 1 = 0.5$, or $t=\\frac{1}{2}$. The interpolation uses the four neighboring samples $\\{y_0, y_1, y_2, y_3\\} = \\{0, 0, 2, 2\\}$.\n\nThe interpolated value is given by $y(t) = w_0 y_0 + w_1 y_1 + w_2 y_2 + w_3 y_3$.\nThe weights for $t=\\frac{1}{2}$ are:\n$w_1 = h(t) = h(\\frac{1}{2})$\n$w_2 = h(1-t) = h(1-\\frac{1}{2}) = h(\\frac{1}{2})$\n$w_0 = h(1+t) = h(1+\\frac{1}{2}) = h(\\frac{3}{2})$\n$w_3 = h(2-t) = h(2-\\frac{1}{2}) = h(\\frac{3}{2})$\n\nWe use the Keys kernel formula with parameter $a=-\\frac{1}{2}$:\n$$\nh(x)=\\begin{cases}\n(a+2)|x|^3-(a+3)|x|^2+1,0\\le |x|1,\\\\\na|x|^3-5a|x|^2+8a|x|-4a,1\\le |x|2,\\\\\n0,|x|\\ge 2,\n\\end{cases}\n$$\n\nFirst, we calculate the weights.\nFor $x = \\frac{1}{2}$ (which is in $[0, 1)$), we use the first case of $h(x)$:\nWith $a = -\\frac{1}{2}$, we have $a+2 = \\frac{3}{2}$ and $a+3 = \\frac{5}{2}$.\n$$\nw_1 = w_2 = h\\left(\\frac{1}{2}\\right) = \\left(\\frac{3}{2}\\right)\\left|\\frac{1}{2}\\right|^3 - \\left(\\frac{5}{2}\\right)\\left|\\frac{1}{2}\\right|^2 + 1 = \\frac{3}{2}\\cdot\\frac{1}{8} - \\frac{5}{2}\\cdot\\frac{1}{4} + 1 = \\frac{3}{16} - \\frac{5}{8} + 1 = \\frac{3}{16} - \\frac{10}{16} + \\frac{16}{16} = \\frac{9}{16}\n$$\n\nFor $x = \\frac{3}{2}$ (which is in $[1, 2)$), we use the second case of $h(x)$:\n$$\nw_0 = w_3 = h\\left(\\frac{3}{2}\\right) = a\\left|\\frac{3}{2}\\right|^3 - 5a\\left|\\frac{3}{2}\\right|^2 + 8a\\left|\\frac{3}{2}\\right| - 4a\n$$\nFactoring out $a$:\n$$\nh\\left(\\frac{3}{2}\\right) = a \\left[ \\left(\\frac{3}{2}\\right)^3 - 5\\left(\\frac{3}{2}\\right)^2 + 8\\left(\\frac{3}{2}\\right) - 4 \\right] = -\\frac{1}{2} \\left[ \\frac{27}{8} - 5\\left(\\frac{9}{4}\\right) + 12 - 4 \\right]\n$$\n$$\nh\\left(\\frac{3}{2}\\right) = -\\frac{1}{2} \\left[ \\frac{27}{8} - \\frac{90}{8} + \\frac{64}{8} \\right] = -\\frac{1}{2} \\left[ \\frac{27 - 90 + 64}{8} \\right] = -\\frac{1}{2} \\left[ \\frac{1}{8} \\right] = -\\frac{1}{16}\n$$\n\nNow, we compute the interpolated value $y\\left(\\frac{1}{2}\\right)$:\n$$\ny\\left(\\frac{1}{2}\\right) = w_0 y_0 + w_1 y_1 + w_2 y_2 + w_3 y_3 = \\left(-\\frac{1}{16}\\right)(0) + \\left(\\frac{9}{16}\\right)(0) + \\left(\\frac{9}{16}\\right)(2) + \\left(-\\frac{1}{16}\\right)(2)\n$$\n$$\ny\\left(\\frac{1}{2}\\right) = 0 + 0 + \\frac{18}{16} - \\frac{2}{16} = \\frac{16}{16} = 1\n$$\nThe interpolated value is $1$. The problem states this is naively cast to an integer using a rounding operator. Since $y\\left(\\frac{1}{2}\\right) = 1$ is an integer, $\\mathrm{round}(1) = 1$.\n\n**Part 3: Implication of the Result**\n\nThe resulting label is $1$. The original set of valid labels was $\\mathcal{C}=\\{0,2\\}$. The new label $1$ is not a member of $\\mathcal{C}$. This is a **spurious class**. The interpolation has created a new, non-existent category at the boundary between the background and the vessel. This fundamentally alters the label partition of the image, changing the set of active labels from $\\{0,2\\}$ to $\\{0,1,2\\}$. This corrupts the segmentation and would lead to errors in any downstream quantitative analysis (radiomics). The phenomenon of generating values outside the range of local samples (an \"overshoot\", although here it's an \"undershoot\" relative to the $\\{0,2\\}$ local values, but an intermediate value globally) is a known characteristic of the Keys kernel, caused by its negative lobes.\n\n**Option-by-Option Analysis**\n\n*   **A**: This option correctly states that label images are categorical and averaging has no meaning. It correctly identifies nearest-neighbor as the preferred method. It correctly calculates the weights $w_1=w_2=\\frac{9}{16}$ and $w_0=w_3=-\\frac{1}{16}$. It correctly computes the interpolated value $y(\\frac{1}{2}) = 1$. Finally, it correctly identifies the result as a spurious class $1$ not in $\\mathcal{C}=\\{0,2\\}$, which changes the label partition. This option is entirely correct.\n    **Verdict: Correct**\n\n*   **B**: This option incorrectly claims nearest-neighbor is dispreferred. It is the preferred method for categorical data. It incorrectly claims cubic interpolation is \"safe\" and that rounding recovers a valid label, which our calculation proves false. The calculation $y(\\frac{1}{2})=\\frac{1}{2}(0+2)=1$ corresponds to linear interpolation, not the specified cubic interpolation. The claim that no spurious classes appear is false.\n    **Verdict: Incorrect**\n\n*   **C**: This option makes the false claim that cubic interpolation is bounded by the convex hull of the samples. The existence of negative weights ($-\\frac{1}{16}$) proves this is false and that over/undershoots can occur. The calculation $y(\\frac{1}{2}) = 2$ is incorrect. The claim that cubic interpolation preserves topology is also false; creating new labels can fundamentally alter object connectivity.\n    **Verdict: Incorrect**\n\n*   **D**: This option is based on the flawed premise that label codes can be treated as probabilities, which is a conceptual error. The problem defines them as categorical codes. The calculation $y(\\frac{1}{2}) = \\frac{3}{2}$ is incorrect; the correct value is $1$. The subsequent reasoning based on this incorrect value is also invalid.\n    **Verdict: Incorrect**", "answer": "$$\\boxed{A}$$", "id": "4546655"}, {"introduction": "The Shannon-Nyquist theorem is not just an abstract concept; its violation has direct and detrimental consequences for radiomic analysis. In this practical coding exercise [@problem_id:4546567], you will create a synthetic image, resample it both properly (with anti-aliasing) and improperly, and then quantify the damage. By measuring the changes in texture features like Contrast and Homogeneity, you will connect resampling theory directly to the integrity of your quantitative results.", "problem": "You are to study how aliasing from improper image resampling alters gray-level co-occurrence matrix features in a synthetic two-dimensional phantom designed to contain both sharp edges and fine gratings, which are common structures in radiomics. The analysis must be grounded in first principles: the Shannon–Nyquist sampling theorem for signal sampling and the formal definitions of gray-level co-occurrence matrices and their derived features.\n\nConstruct a synthetic image phantom as follows. Let the image be a discrete array of size $256 \\times 256$ with integer pixel indices $(x,y)$ where $x \\in \\{0,\\dots,255\\}$ and $y \\in \\{0,\\dots,255\\}$. Define an intensity field $I(x,y)$ with three components:\n1. A uniform background of intensity $0.2$.\n2. A sharp-edged bright square region with intensity $0.8$ inside the axis-aligned bounds $x \\in [64,192)$ and $y \\in [64,192)$.\n3. An optional cosine grating confined to $x \\in [32,224)$ and $y \\in [96,160)$, given by an additive term $A \\cos\\left(2\\pi x/p\\right)$ with amplitude $A = 0.2$ and grating period $p$ measured in pixels. When present, add the grating term only within the defined stripe and leave other pixels unaffected by the grating. Clip the final intensity to the interval $[0,1]$.\n\nResample this image to new spatial resolution using two distinct pipelines:\n- Improper resampling (aliased): direct nearest-neighbor resampling by a scaling factor $s$ isotropically in both axes (no anti-alias prefilter).\n- Proper resampling (anti-aliased): if $s  1$, first apply a Gaussian low-pass filter with standard deviation $\\sigma = 0.6/s$ pixels in both axes (to attenuate frequencies beyond the new Nyquist limit), then resample using bilinear interpolation; if $s = 1$, skip the low-pass filter and use bilinear interpolation with unit scale.\n\nQuantize each image (original and both resampled versions) to $N_g = 32$ gray levels via rounding: map each intensity $v \\in [0,1]$ to an integer $q \\in \\{0,1,\\dots,31\\}$ by $q = \\operatorname{round}\\left( v (N_g - 1) \\right)$, then clip to the allowed range.\n\nDefine the gray-level co-occurrence matrix (GLCM) for a specified offset as follows. For an image of discrete gray levels $q(x,y) \\in \\{0,1,\\dots, N_g - 1\\}$ and offset $(\\Delta x,\\Delta y)$, the co-occurrence matrix $P \\in \\mathbb{R}^{N_g \\times N_g}$ has entries\n$$\nP(i,j) = \\#\\left\\{(x,y) \\,\\big|\\, q(x,y) = i,\\; q(x+\\Delta x,y+\\Delta y) = j\\right\\},\n$$\ncounting only valid pairs where both $(x,y)$ and $(x+\\Delta x,y+\\Delta y)$ are inside the image domain. Use the symmetric form by adding counts in both directions, i.e., accumulate both $(i,j)$ and $(j,i)$. Normalize to obtain a probability matrix $\\hat{P} = P / \\sum_{i,j} P(i,j)$. Using $\\hat{P}$, compute the feature contrast $C$ and homogeneity $H$ defined by\n$$\nC = \\sum_{i=0}^{N_g-1} \\sum_{j=0}^{N_g-1} (i - j)^2 \\, \\hat{P}(i,j),\n\\quad\nH = \\sum_{i=0}^{N_g-1} \\sum_{j=0}^{N_g-1} \\frac{\\hat{P}(i,j)}{1 + (i - j)^2}.\n$$\nUse the horizontal offset $(\\Delta x, \\Delta y) = (1,0)$.\n\nBase your reasoning on the Shannon–Nyquist sampling theorem: a discrete sampling grid with unit spacing has a Nyquist limit of $0.5$ cycles per pixel, and downsampling by a factor $s$ reduces the new Nyquist frequency proportionally. Improper resampling (without sufficient low-pass filtering) permits frequency components above the new Nyquist limit to fold into lower frequencies (aliasing), altering local gray-level relationships and hence the GLCM features.\n\nYour program must implement the above construction and evaluate the following test suite of parameter settings, each creating a distinct phantom and resampling scenario:\n- Test case $1$: grating period $p = 3$ pixels, scale $s = 0.5$.\n- Test case $2$: grating period $p = 12$ pixels, scale $s = 0.5$.\n- Test case $3$: no grating (omit component $3$), scale $s = 0.5$.\n- Test case $4$: grating period $p = 3$ pixels, scale $s = 1.0$.\n\nFor each test case:\n1. Generate the phantom $I(x,y)$ (with or without grating as specified).\n2. Compute $C_{\\mathrm{orig}}$ and $H_{\\mathrm{orig}}$ on the original phantom (no resampling).\n3. Compute $C_{\\mathrm{improper}}$ and $H_{\\mathrm{improper}}$ on the improperly resampled image.\n4. Compute $C_{\\mathrm{proper}}$ and $H_{\\mathrm{proper}}$ on the properly resampled image.\n\nReport for each test the pair of differences\n$$\n\\Delta C = C_{\\mathrm{improper}} - C_{\\mathrm{proper}},\n\\quad\n\\Delta H = H_{\\mathrm{improper}} - H_{\\mathrm{proper}},\n$$\neach rounded to six decimal places. Aggregate the results for all tests into a single list in the order of the test cases, interleaving the two differences per test. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[dC1,dH1,dC2,dH2,dC3,dH3,dC4,dH4]\"). Angles are not used; offsets are specified directly in pixels so no angle unit is needed. All outputs are pure floats without units, rounded to six decimal places.", "solution": "The problem requires an analysis of the effects of aliasing on radiomic features derived from the gray-level co-occurrence matrix (GLCM). This will be accomplished by constructing a synthetic image phantom, subjecting it to two different resampling pipelines (one proper, one improper), and quantifying the resulting differences in the GLCM features of Contrast and Homogeneity. The entire process is grounded in fundamental principles of signal processing and image analysis.\n\n### Principles of Sampling and Aliasing\n\nThe Shannon-Nyquist sampling theorem is the theoretical foundation for this analysis. It states that to perfectly reconstruct a continuous-time signal from its discrete samples, the sampling frequency must be at least twice the maximum frequency component present in the signal. This minimum required sampling frequency is known as the Nyquist rate. Equivalently, for a discrete signal with a sampling interval of $\\Delta t$, the highest frequency that can be uniquely represented is the Nyquist frequency, $f_N = 1/(2\\Delta t)$. For a digital image with a normalized pixel spacing of $1$, the Nyquist frequency is $f_N = 0.5$ cycles per pixel.\n\nDownsampling an image by an isotropic scaling factor $s  1$ effectively increases the sampling interval from $1$ to $1/s$. Consequently, the Nyquist frequency of the new, coarser grid is reduced to $f_{N, \\text{new}} = 0.5 \\times s$, measured in cycles per original pixel spacing.\n\nAliasing occurs when the original image contains frequencies higher than this new Nyquist frequency, $f_{N, \\text{new}}$. These high-frequency components are not simply lost; they are \"folded\" or \"aliased\" into the lower frequency range $[0, f_{N, \\text{new}}]$, masquerading as new, artificial patterns that were not present in the original signal. The \"improper\" resampling method, which uses direct nearest-neighbor interpolation without any pre-filtering, does nothing to prevent this and will therefore exhibit aliasing artifacts if the input image contains sufficiently high frequencies.\n\nTo avoid aliasing, one must perform anti-aliasing. This involves applying a low-pass filter to the original image to remove any frequency components above $f_{N, \\text{new}}$ *before* resampling. The \"proper\" resampling pipeline implements this. For a scaling factor $s  1$, it first applies a Gaussian low-pass filter with a standard deviation $\\sigma = 0.6/s$. This value of $\\sigma$ is a standard heuristic chosen to set the filter's cutoff frequency approximately at the new Nyquist limit, effectively attenuating the frequencies that would cause aliasing. Following this filtering step, bilinear interpolation is used to perform the resampling, which provides a smoother result compared to the blocky artifacts of nearest-neighbor interpolation.\n\n### Principles of GLCM and Texture Features\n\nThe Gray-Level Co-occurrence Matrix (GLCM) is a statistical tool used to analyze texture by tabulating the frequency of different gray-level pairs occurring at a specific spatial offset. For an image quantized to $N_g$ gray levels, the GLCM, denoted $P$, is an $N_g \\times N_g$ matrix. An entry $P(i,j)$ for an offset $(\\Delta x, \\Delta y)$ counts the number of times a pixel with gray level $i$ is found adjacent to a pixel with gray level $j$ in the specified direction. The problem specifies a symmetric GLCM, which is achieved by summing the GLCM for the offset $(\\Delta x, \\Delta y)$ with its transpose. This makes the analysis insensitive to the direction of the relationship (i.e., the pair $(i,j)$ is treated the same as $(j,i)$). The matrix is then normalized to form a probability distribution, $\\hat{P}$.\n\nFrom this probability matrix, texture features are computed. The problem specifies two:\n1.  **Contrast**: $C = \\sum_{i=0}^{N_g-1} \\sum_{j=0}^{N_g-1} (i - j)^2 \\hat{P}(i,j)$. This feature measures the amount of local variation in the image. The $(i-j)^2$ term weights pairs of pixels with large differences in gray level more heavily. High contrast indicates sharp transitions and a high degree of local change. Aliasing, which can introduce spurious high-frequency patterns, is expected to increase the Contrast feature.\n2.  **Homogeneity**: $H = \\sum_{i=0}^{N_g-1} \\sum_{j=0}^{N_g-1} \\frac{\\hat{P}(i,j)}{1 + (i - j)^2}$. Also known as Inverse Difference Moment, this feature is inversely related to Contrast. The weighting factor $1/(1+(i-j)^2)$ gives higher values to pixel pairs with similar gray levels. A high Homogeneity value indicates that an image has few local changes and a more uniform texture. Aliasing is expected to decrease Homogeneity.\n\n### Algorithmic Implementation\n\nThe solution is implemented by following the steps laid out in the problem statement.\n\n1.  **Phantom Generation**: A $256 \\times 256$ phantom is created. It starts with a uniform background of intensity $0.2$. A square region from $(64,64)$ to $(191,191)$ is set to an intensity of $0.8$. For test cases including a grating, a sinusoidal pattern $0.2 \\cos(2\\pi x/p)$ is added within a horizontal stripe. The final intensity values are clipped to the range $[0,1]$.\n2.  **Resampling**:\n    *   **Improper resampling** is implemented using nearest-neighbor interpolation via `scipy.ndimage.zoom` with the parameter `order=0`.\n    *   **Proper resampling** is implemented conditionally. If the scale factor $s  1$, a Gaussian filter (`scipy.ndimage.gaussian_filter`) with $\\sigma=0.6/s$ is first applied to the original phantom. Then, the filtered image is resampled using bilinear interpolation (`scipy.ndimage.zoom` with `order=1`). If $s=1$, the filtering step is skipped, and only bilinear interpolation is applied.\n3.  **Quantization**: All images (original, improper, and proper) are quantized to $N_g=32$ gray levels using the specified rounding formula $q = \\operatorname{round}(v(N_g-1))$, where $v$ is the pixel intensity.\n4.  **Feature Computation**: For each quantized image, a symmetric GLCM is computed for the horizontal offset $(\\Delta x, \\Delta y) = (1,0)$. This is done efficiently by creating 1D arrays of gray levels from adjacent pixel columns and using `numpy.histogram2d`. The resulting matrix is made symmetric, normalized, and then used to compute Contrast and Homogeneity according to their definitions.\n5.  **Difference Calculation**: For each test case, the features from the improperly resampled image ($C_{\\mathrm{improper}}, H_{\\mathrm{improper}}$) and the properly resampled image ($C_{\\mathrm{proper}}, H_{\\mathrm{proper}}$) are used to calculate the differences $\\Delta C = C_{\\mathrm{improper}} - C_{\\mathrm{proper}}$ and $\\Delta H = H_{\\mathrm{improper}} - H_{\\mathrm{proper}}$.\n\nThis procedure is applied to the four specified test cases. The differences $\\Delta C$ and $\\Delta H$ quantify the impact of aliasing. A large positive $\\Delta C$ and a large negative $\\Delta H$ indicate a significant divergence between the two resampling pipelines, attributable to aliasing artifacts in the improper method that are mitigated by the anti-aliasing filter in the proper method.\n\nFor case 1 ($p=3, s=0.5$), the grating frequency $f = 1/3 \\approx 0.333$ cycles/pixel is greater than the new Nyquist frequency $f_{N, \\text{new}} = 0.5 \\times 0.5 = 0.25$ cycles/pixel, leading to strong aliasing. We expect large differences. For case 2 ($p=12, s=0.5$), the grating frequency $f = 1/12 \\approx 0.083$ is below the new Nyquist limit, so aliasing of the grating is not expected, and differences should be small. Case 3 (no grating, $s=0.5$) isolates the effect on sharp edges. Case 4 ($p=3, s=1.0$) serves as a control where no downsampling occurs, and thus no aliasing from sampling is expected.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import ndimage\n\ndef generate_phantom(p=None, size=256):\n    \"\"\"\n    Constructs the synthetic image phantom.\n    \"\"\"\n    I = np.full((size, size), 0.2, dtype=np.float64)\n    I[64:192, 64:192] = 0.8\n    \n    if p is not None:\n        A = 0.2\n        x, y = np.meshgrid(np.arange(size), np.arange(size), indexing='xy')\n        \n        grating_mask = (x = 32)  (x  224)  (y = 96)  (y  160)\n        grating_term = A * np.cos(2 * np.pi * x / p)\n        \n        I[grating_mask] += grating_term[grating_mask]\n\n    return np.clip(I, 0.0, 1.0)\n\ndef quantize_image(img, Ng=32):\n    \"\"\"\n    Quantizes an image with intensities in [0,1] to Ng gray levels.\n    \"\"\"\n    quant_img = np.round(img * (Ng - 1))\n    return np.clip(quant_img, 0, Ng - 1).astype(int)\n\ndef resample_improper(img, s):\n    \"\"\"\n    Improper resampling using nearest-neighbor interpolation.\n    \"\"\"\n    return ndimage.zoom(img, s, order=0, mode='nearest')\n\ndef resample_proper(img, s):\n    \"\"\"\n    Proper resampling with anti-aliasing filter and bilinear interpolation.\n    \"\"\"\n    if s  1.0:\n        sigma = 0.6 / s\n        img_filtered = ndimage.gaussian_filter(img, sigma=sigma, mode='mirror')\n        return ndimage.zoom(img_filtered, s, order=1, mode='nearest')\n    else:  # s = 1.0\n        return ndimage.zoom(img, s, order=1, mode='nearest')\n\ndef compute_glcm_features(quant_img, Ng=32):\n    \"\"\"\n    Computes a symmetric GLCM and its Contrast and Homogeneity features.\n    Offset is fixed to (dx=1, dy=0).\n    \"\"\"\n    if quant_img.shape[1] = 1:\n        return 0.0, 0.0\n\n    # Extract pixel pairs for a (1,0) offset\n    i_vals = quant_img[:, :-1].ravel()\n    j_vals = quant_img[:, 1:].ravel()\n\n    # Compute GLCM using histogram2d\n    glcm = np.histogram2d(\n        i_vals, j_vals,\n        bins=(np.arange(Ng + 1), np.arange(Ng + 1))\n    )[0]\n\n    # Make the GLCM symmetric\n    glcm = glcm + glcm.T\n\n    # Normalize the GLCM to get a probability matrix\n    glcm_sum = glcm.sum()\n    if glcm_sum == 0:\n        return 0.0, 0.0\n    p_hat = glcm / glcm_sum\n\n    # Compute features\n    i_matrix, j_matrix = np.meshgrid(np.arange(Ng), np.arange(Ng), indexing='ij')\n    \n    # Contrast\n    weight_c = (i_matrix - j_matrix)**2\n    contrast = np.sum(weight_c * p_hat)\n\n    # Homogeneity\n    weight_h = 1.0 / (1.0 + (i_matrix - j_matrix)**2)\n    homogeneity = np.sum(weight_h * p_hat)\n\n    return contrast, homogeneity\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'p': 3, 's': 0.5},   # Case 1\n        {'p': 12, 's': 0.5},  # Case 2\n        {'p': None, 's': 0.5},# Case 3\n        {'p': 3, 's': 1.0},   # Case 4\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p = case['p']\n        s = case['s']\n\n        # 1. Generate the original phantom\n        I_orig = generate_phantom(p=p)\n\n        # 2. Improper resampling pipeline\n        I_improper = resample_improper(I_orig, s)\n        Q_improper = quantize_image(I_improper)\n        C_improper, H_improper = compute_glcm_features(Q_improper)\n        \n        # 3. Proper resampling pipeline\n        I_proper = resample_proper(I_orig, s)\n        Q_proper = quantize_image(I_proper)\n        C_proper, H_proper = compute_glcm_features(Q_proper)\n\n        # 4. Calculate and store differences\n        delta_C = C_improper - C_proper\n        delta_H = H_improper - H_proper\n\n        all_results.extend([f\"{delta_C:.6f}\", f\"{delta_H:.6f}\"])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "4546567"}]}