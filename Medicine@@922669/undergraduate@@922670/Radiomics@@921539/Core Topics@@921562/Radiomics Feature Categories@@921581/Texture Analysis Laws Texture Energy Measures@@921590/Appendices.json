{"hands_on_practices": [{"introduction": "A fundamental characteristic of the high-pass Laws' filters, such as $E_5$ or $S_5$, is that their coefficients sum to zero. This 'zero-sum' property ensures the filter has no response to a constant, or DC, signal component in an image. In this exercise ([@problem_id:4565057]), you will write a program to numerically verify this essential property, demonstrating how it can be used as a powerful sanity check to detect errors in a filter implementation or preprocessing pipeline.", "problem": "In radiomics texture analysis, Laws' texture energy measures rely on convolving an image with separable high-pass masks derived from one-dimensional Laws vectors, followed by computing an energy summary statistic. A foundational property of high-pass masks is that the sum of all mask coefficients is zero. Consequently, when such a mask is convolved with a constant image, the response should be near zero everywhere except at boundaries, which can be eliminated by using the valid convolution region. This property can be used to numerically detect preprocessing errors such as incorrect normalization or unintended offsets.\n\nStarting from these fundamental bases:\n- The definition of two-dimensional (2D) discrete convolution between a discrete image $I$ and a discrete filter $H$,\n$$\n(I * H)[i,j] \\;=\\; \\sum_{p}\\sum_{q} I[i - p, j - q]\\, H[p, q],\n$$\nwith sums taken over the finite support of $H$.\n- The standard Laws one-dimensional (1D) vectors of length $5$, given by\n$$\nL_5 = [\\,1,\\,4,\\,6,\\,4,\\,1\\,],\\quad\nE_5 = [\\,-1,\\,-2,\\,0,\\,2,\\,1\\,],\\quad\nS_5 = [\\,-1,\\,0,\\,2,\\,0,\\,-1\\,],\n$$\n$$\nW_5 = [\\,-1,\\,2,\\,0,\\,-2,\\,1\\,],\\quad\nR_5 = [\\,1,\\,-4,\\,6,\\,-4,\\,1\\,],\n$$\nand the construction of 2D separable masks by the outer product of two 1D vectors,\n$$\nH \\;=\\; u\\, v^{\\top},\n$$\nwhere $u \\in \\{L_5, E_5, S_5, W_5, R_5\\}$ and $v \\in \\{L_5, E_5, S_5, W_5, R_5\\}$.\n\nYour task is to implement a program that, for a given small test suite of such masks and constant images, numerically verifies the following two criteria for each test case:\n- Zero-sum property: the absolute sum of all mask coefficients is less than or equal to a specified tolerance $\\tau_s$.\n- Near-zero response on constant images: when convolving a constant image $I[i,j] = c$ with the mask using valid convolution, the texture energy defined as the mean absolute response,\n$$\nTE(I,H) \\;=\\; \\frac{1}{M} \\sum_{(i,j)\\in \\Omega_{\\text{valid}}} \\big| (I * H)[i,j] \\big|,\n$$\nis less than or equal to a specified tolerance $\\tau_e$, where $\\Omega_{\\text{valid}}$ denotes the valid convolution region and $M$ is its cardinality.\n\nFor each test case, output a boolean value that is true if and only if both of the above criteria are satisfied. The program must construct the indicated 2D mask $H$ by the specified outer product, optionally scale it by a scalar factor, and optionally perturb a single coefficient by a small additive value to simulate a preprocessing error. Then, it must convolve $H$ with a constant image of specified size and constant level $c$, compute $TE(I,H)$ over the valid region, and evaluate both criteria.\n\nImplement the following test suite. Each test case specifies:\n- The row vector $u$ and column vector $v$ selected from $\\{L_5, E_5, S_5, W_5, R_5\\}$,\n- A scaling factor $s$ to multiply the mask,\n- An optional perturbation triplet $(i_p, j_p, \\delta)$ indicating that $\\delta$ should be added to the single mask entry at row index $i_p$ and column index $j_p$ (zero-based indexing) after scaling,\n- The image size $N$ for an $N \\times N$ constant image,\n- The image constant level $c$,\n- Tolerances $\\tau_s$ and $\\tau_e$.\n\nUse the following six test cases:\n1. $u = E_5$, $v = L_5$, $s = 1.0$, no perturbation, $N = 64$, $c = 7.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n2. $u = L_5$, $v = L_5$, $s = 1.0$, no perturbation, $N = 32$, $c = 2.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n3. $u = W_5$, $v = S_5$, $s = 3.0$, no perturbation, $N = 48$, $c = 5.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n4. $u = E_5$, $v = S_5$, $s = 1.0$, perturbation $(i_p, j_p, \\delta) = (2, 2, 10^{-6})$, $N = 40$, $c = 1.0$, $\\tau_s = 10^{-8}$, $\\tau_e = 10^{-8}$.\n5. $u = R_5$, $v = R_5$, $s = 1.0$, no perturbation, $N = 5$, $c = 10.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n6. $u = L_5$, $v = E_5$, $s = 1.0$, no perturbation, $N = 64$, $c = 3.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n\nImplementation details:\n- Construct $H = s \\cdot (u\\, v^{\\top})$, then apply the optional perturbation if specified.\n- Perform 2D convolution using valid convolution to avoid boundary effects; only the valid portion contributes to $TE(I,H)$.\n- All computations are dimensionless; no physical units are required.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots,result_6]$), where each $result_k$ is a boolean corresponding to test case $k$ in order.", "solution": "The problem requires the numerical verification of fundamental properties of Laws' texture masks, specifically their behavior when applied to constant images. The solution involves implementing an algorithm based on the principles of digital signal processing and linear algebra.\n\nThe foundation of Laws' method lies in a set of one-dimensional (1D) vectors of length $5$. The problem provides the standard set:\n$$L_5 = [\\,1,\\,4,\\,6,\\,4,\\,1\\,]$$\n$$E_5 = [\\,-1,\\,-2,\\,0,\\,2,\\,1\\,]$$\n$$S_5 = [\\,-1,\\,0,\\,2,\\,0,\\,-1\\,]$$\n$$W_5 = [\\,-1,\\,2,\\,0,\\,-2,\\,1\\,]$$\n$$R_5 = [\\,1,\\,-4,\\,6,\\,-4,\\,1\\,]$$\n\nThese vectors can be classified based on their filtering characteristics. The vector $L_5$ (Level) is a low-pass averaging filter. The other four vectors—$E_5$ (Edge), $S_5$ (Spot), $W_5$ (Wave), and $R_5$ (Ripple)—are high-pass or band-pass filters designed to detect specific textural primitives. A defining characteristic of these high-pass filters is that the sum of their coefficients is zero. This can be verified by direct summation:\n$\\sum E_5 = -1 - 2 + 0 + 2 + 1 = 0$\n$\\sum S_5 = -1 + 0 + 2 + 0 - 1 = 0$\n$\\sum W_5 = -1 + 2 + 0 - 2 + 1 = 0$\n$\\sum R_5 = 1 - 4 + 6 - 4 + 1 = 0$\nIn contrast, the low-pass filter $L_5$ does not have this property: $\\sum L_5 = 1 + 4 + 6 + 4 + 1 = 16$.\n\nTwo-dimensional (2D) separable masks $H$ are constructed by taking the outer product of two 1D vectors, $u$ and $v$:\n$$H = u v^\\top$$\nThe sum of all coefficients in the resulting 2D mask $H$ can be expressed as:\n$$\\sum_{i,j} H[i, j] = \\sum_{i,j} u[i] v[j] = \\left(\\sum_i u[i]\\right) \\left(\\sum_j v[j]\\right)$$\nThis identity shows that the 2D mask $H$ is a zero-sum mask if at least one of its constituent 1D vectors, $u$ or $v$, is zero-sum. Therefore, any mask constructed with at least one vector from $\\{E_5, S_5, W_5, R_5\\}$ will be a zero-sum mask. The only combination that results in a non-zero-sum mask is $L_5 L_5^\\top$.\n\nThe core principle to be verified is the response of these masks to a constant input. Consider a discrete image $I$ that is constant everywhere, i.e., $I[i,j] = c$ for some constant $c$. The 2D convolution of $I$ with a mask $H$ is given by:\n$$(I * H)[i,j] = \\sum_{p}\\sum_{q} I[i - p, j - q] H[p, q]$$\nSince $I$ is constant, $I[i - p, j - q] = c$ for all $p, q$. Thus, the expression simplifies:\n$$(I * H)[i,j] = \\sum_{p}\\sum_{q} c \\, H[p, q] = c \\left(\\sum_{p,q} H[p, q]\\right)$$\nIf $H$ is a zero-sum mask, then $\\sum_{p,q} H[p, q] = 0$, and the result of the convolution is $(I * H)[i, j] = c \\cdot 0 = 0$ for all output pixels $(i,j)$. This is true for the 'valid' convolution region, where the kernel $H$ is fully contained within the image, thereby avoiding any boundary effects.\n\nThe problem asks for numerical verification of this property, which requires two checks to account for floating-point inaccuracies and potential introduced errors.\n\n**Criterion 1: Zero-sum property of the mask.**\nThis check directly verifies if the constructed mask $H$ is zero-sum, within a given numerical tolerance $\\tau_s$. A mask might be perturbed, for instance by adding a small value $\\delta$ to one of its coefficients. The check is:\n$$\\left| \\sum_{i,j} H[i, j] \\right| \\le \\tau_s$$\nIf a mask is formed from at least one zero-sum vector and is not perturbed, its sum will be exactly $0$ in ideal arithmetic. In floating-point computation, this sum should be extremely close to $0$. A non-zero-sum mask (like $L_5 L_5^\\top$) or a perturbed zero-sum mask will likely fail this check if the resulting sum exceeds the tolerance.\n\n**Criterion 2: Near-zero response on a constant image.**\nThis check verifies the ultimate consequence of the zero-sum property. The texture energy, $TE(I,H)$, is defined as the mean absolute response in the valid convolution region $\\Omega_{\\text{valid}}$:\n$$TE(I,H) = \\frac{1}{M} \\sum_{(i,j)\\in \\Omega_{\\text{valid}}} \\big| (I * H)[i,j] \\big| \\le \\tau_e$$\nwhere $M$ is the number of pixels in $\\Omega_{\\text{valid}}$. If Criterion 1 holds and the mask sum is (close to) zero, the convolution output $(I * H)[i,j]$ should also be (close to) zero everywhere. Consequently, the texture energy $TE$ should be very small and satisfy this condition.\n\nThe overall algorithm for each test case is as follows:\n1.  Select the specified 1D vectors $u$ and $v$.\n2.  Construct the 2D mask $H$ via the scaled outer product: $H = s \\cdot (u v^\\top)$.\n3.  If a perturbation $(i_p, j_p, \\delta)$ is specified, modify the mask: $H[i_p, j_p] \\leftarrow H[i_p, j_p] + \\delta$.\n4.  Compute the absolute sum of the mask's coefficients and check if it is within tolerance $\\tau_s$.\n5.  Generate the constant $N \\times N$ image with value $c$.\n6.  Perform 2D convolution of the image with the mask, retaining only the 'valid' portion of the output.\n7.  Compute the texture energy $TE$ by taking the mean of the absolute values of the valid convolution output.\n8.  Check if the texture energy is within tolerance $\\tau_e$.\n9.  The result for the test case is `True` if and only if both checks (from steps 4 and 8) pass.\n\nFor example, in test case 2 ($u=L_5, v=L_5$), the sum of the mask coefficients is $s \\cdot (\\sum L_5) \\cdot (\\sum L_5) = 1.0 \\cdot 16 \\cdot 16 = 256$. Since $|256|$ is not less than or equal to $\\tau_s=10^{-12}$, this case fails Criterion 1, and the final result is `False`. In contrast, for test case 1 ($u=E_5, v=L_5$), the sum of coefficients is $s \\cdot (\\sum E_5) \\cdot (\\sum L_5) = 1.0 \\cdot 0 \\cdot 16 = 0$. This passes Criterion 1. The subsequent convolution with a constant image yields a near-zero response, passing Criterion 2. Thus, the result is `True`. Test case 4 introduces a perturbation $\\delta=10^{-6}$, causing the mask sum to become $10^{-6}$, which is not less than or equal to the tolerance $\\tau_s=10^{-8}$, so it fails Criterion 1.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef solve():\n    \"\"\"\n    Validates Laws' texture masks against zero-sum and near-zero response properties.\n    \"\"\"\n    laws_vectors = {\n        'L5': np.array([1, 4, 6, 4, 1], dtype=np.float64),\n        'E5': np.array([-1, -2, 0, 2, 1], dtype=np.float64),\n        'S5': np.array([-1, 0, 2, 0, -1], dtype=np.float64),\n        'W5': np.array([-1, 2, 0, -2, 1], dtype=np.float64),\n        'R5': np.array([1, -4, 6, -4, 1], dtype=np.float64),\n    }\n\n    test_cases = [\n        {'u': 'E5', 'v': 'L5', 's': 1.0, 'pert': None, 'N': 64, 'c': 7.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'L5', 'v': 'L5', 's': 1.0, 'pert': None, 'N': 32, 'c': 2.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'W5', 'v': 'S5', 's': 3.0, 'pert': None, 'N': 48, 'c': 5.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'E5', 'v': 'S5', 's': 1.0, 'pert': (2, 2, 1e-6), 'N': 40, 'c': 1.0, 'tau_s': 1e-8, 'tau_e': 1e-8},\n        {'u': 'R5', 'v': 'R5', 's': 1.0, 'pert': None, 'N': 5, 'c': 10.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'L5', 'v': 'E5', 's': 1.0, 'pert': None, 'N': 64, 'c': 3.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n    ]\n\n    results = []\n    for case in test_cases:\n        u_vec = laws_vectors[case['u']]\n        v_vec = laws_vectors[case['v']]\n\n        # 1. Construct the 2D mask = s * (u v^T)\n        H = case['s'] * np.outer(u_vec, v_vec)\n\n        # 2. Apply optional perturbation\n        if case['pert']:\n            i_p, j_p, delta = case['pert']\n            H[i_p, j_p] += delta\n\n        # 3. Criterion 1: Verify the zero-sum property of the mask\n        mask_sum_abs = np.abs(np.sum(H))\n        criterion1_passed = mask_sum_abs = case['tau_s']\n\n        # 4. Create the constant image\n        image = np.full((case['N'], case['N']), case['c'], dtype=np.float64)\n\n        # 5. Perform 2D convolution with 'valid' mode\n        conv_output = convolve2d(image, H, mode='valid')\n\n        # 6. Criterion 2: Verify near-zero response\n        texture_energy = 0.0\n        if conv_output.size > 0:\n            texture_energy = np.mean(np.abs(conv_output))\n        \n        criterion2_passed = texture_energy = case['tau_e']\n\n        # The final result is true if and only if both criteria are satisfied.\n        results.append(criterion1_passed and criterion2_passed)\n\n    # Format the final output as a comma-separated list of booleans in a string\n    # Python's `str(bool)` converts True to \"True\" and False to \"False\"\n    # The problem asks for lowercase \"true\" and \"false\", so we adjust.\n    output_str = f\"[{','.join(str(r).lower() for r in results)}]\"\n    print(output_str)\n\nsolve()\n```", "id": "4565057"}, {"introduction": "Beyond verifying a filter's response at zero frequency, a more comprehensive test involves checking its behavior at various non-zero frequencies. This practice ([@problem_id:4565096]) guides you through a powerful technique from signal processing: using a synthetic sinusoidal image as input to your filter. You will verify that the amplitude of the filtered output matches the filter's theoretical frequency response, building a robust proof-of-correctness test and deepening your intuition for the link between a filter's spatial structure and its frequency-domain behavior.", "problem": "You are given the task to design a proof-of-correctness test for a Laws filter implementation grounded in the mathematical behavior of Linear Shift-Invariant (LSI) systems. In texture analysis for Radiomics, Laws' Texture Energy Measures (TEM) use small, separable, two-dimensional filters constructed from one-dimensional kernels to accentuate specific texture patterns. Your test must verify, on synthetic data containing a single sinusoidal component, that the amplitude of the filtered output matches the magnitude of the filter’s frequency response at the sinusoid’s spatial frequency. The verification must be conducted under circular convolution to avoid border artifacts, and the comparison must be expressed numerically.\n\nStart from the following base definitions:\n- A Linear Shift-Invariant (LSI) system with impulse response $h[n]$ produces an output by discrete convolution of an input signal $x[n]$ with $h[n]$.\n- The Discrete-Time Fourier Transform (DTFT) of a finite impulse response $h[n]$ is defined by $H(\\omega) = \\sum_{n=0}^{M-1} h[n] e^{-j \\omega n}$ for a mask of length $M$, where $\\omega$ is the angular frequency in radians.\n- For a two-dimensional separable mask $C = a b^{\\top}$, where $a$ is the vertical component applied along the $y$-axis and $b$ is the horizontal component applied along the $x$-axis, the two-dimensional convolution is equivalent to consecutive one-dimensional convolutions along $y$ and $x$.\n- Under LSI, a single-frequency sinusoidal input of unit amplitude remains sinusoidal at the same frequency after filtering, with its amplitude scaled by the magnitude of the system’s frequency response at that frequency. The phase may change but does not affect the Root-Mean-Square (RMS) amplitude.\n\nUse the canonical one-dimensional Laws vectors of length $5$:\n- $L5 = [1,4,6,4,1]$,\n- $E5 = [-1,-2,0,2,1]$,\n- $S5 = [-1,0,2,0,-1]$,\n- $W5 = [-1, 2, 0, -2, 1]$,\n- $R5 = [1, -4, 6, -4, 1]$.\n\nConstruct two-dimensional masks $C = a b^{\\top}$ from these vectors. Work on a synthetic image $I[x,y]$ of size $128 \\times 128$ with coordinates $x \\in \\{0,1,\\dots,127\\}$ and $y \\in \\{0,1,\\dots,127\\}$. The image shall contain a single sinusoid of unit amplitude:\n$$\nI[x,y] = \\sin\\left(2\\pi\\left(\\frac{k_x}{128} x + \\frac{k_y}{128} y\\right) + \\phi\\right),\n$$\nwhere $k_x$ and $k_y$ are integer spatial frequencies expressed as cycles per image dimension, and $\\phi$ is a phase offset. Use radians for $\\phi$.\n\nFor each test case, proceed as follows:\n- Convolve $I[x,y]$ with $C$ using two-dimensional circular convolution to produce an output $O[x,y]$ of the same size.\n- Compute the measured amplitude of $O[x,y]$ via the RMS: first compute $R = \\sqrt{\\frac{1}{128^2}\\sum_{x=0}^{127}\\sum_{y=0}^{127} O[x,y]^2}$, then convert to sinusoidal amplitude by $A_{\\text{meas}} = \\sqrt{2}\\,R$.\n- Derive the predicted amplitude $A_{\\text{pred}}$ for the separable mask from first principles, starting from the DTFT of the one-dimensional kernels and the separability of the two-dimensional frequency response. Use the magnitude of the complex frequency response at the angular frequencies $\\omega_x = 2\\pi \\frac{k_x}{128}$ and $\\omega_y = 2\\pi \\frac{k_y}{128}$. Do not assume any pre-derived shortcut formulas; justify the construction from the DTFT definition and the properties of separable convolution and LSI systems.\n- Report the relative error for each case as a float:\n$$\ne = \\frac{\\left|A_{\\text{meas}} - A_{\\text{pred}}\\right|}{\\max\\left(10^{-12}, A_{\\text{pred}}\\right)}.\n$$\n\nDesign the test suite with the following six cases, which together probe low and high spatial frequencies, directional selectivity, separability, and near-Nyquist behavior. In each tuple, the first element is the vertical kernel $a$, the second is the horizontal kernel $b$, followed by $(k_x,k_y,\\phi)$:\n1. $(E5, L5, 8, 0, 0.0)$,\n2. $(L5, E5, 0, 8, 1.0)$,\n3. $(S5, S5, 32, 0, 0.5)$,\n4. $(R5, R5, 60, 60, 0.0)$,\n5. $(W5, L5, 1, 0, 0.0)$,\n6. $(E5, E5, 16, 16, 0.25)$.\n\nYour program must compute the relative error $e$ for each of the six test cases and print the results in a single line in the exact format:\n- A comma-separated Python list of six floats enclosed in square brackets, for example, $[e_1,e_2,e_3,e_4,e_5,e_6]$.\n\nNo external input or files are permitted, and all angles must be in radians. The program must use two-dimensional circular convolution (boundary wrapping) and return only the specified single line of output.", "solution": "The problem is valid as it presents a well-defined, scientifically sound task based on foundational principles of digital signal processing. The objective is to verify an implementation of Laws' texture filters by comparing the empirically measured response to a sinusoidal input with the theoretically predicted response derived from the filter's frequency characteristics.\n\nThe core principle is that a Linear Shift-Invariant (LSI) system, when subjected to a sinusoidal input, produces a sinusoidal output of the same frequency. The amplitude of the output sinusoid is the product of the input amplitude and the magnitude of the system's frequency response evaluated at the input frequency.\n\nThe input signal is a 2D sinusoid of unit amplitude:\n$$\nI[x,y] = \\sin\\left(2\\pi\\left(\\frac{k_x}{N} x + \\frac{k_y}{N} y\\right) + \\phi\\right)\n$$\nwhere $N=128$ is the image dimension. The input amplitude is $A_{\\text{in}} = 1$. The angular spatial frequencies are $\\omega_x = 2\\pi k_x/N$ and $\\omega_y = 2\\pi k_y/N$.\n\nThe filter is a $5 \\times 5$ separable mask $C = a b^{\\top}$, where $a$ is the vertical kernel (applied along the $y$-axis) and $b$ is the horizontal kernel (applied along the $x$-axis). The output image is $O = I \\circledast C$, where $\\circledast$ denotes 2D circular convolution.\n\n**1. Predicted Amplitude ($A_{\\text{pred}}$) Derivation**\n\nAccording to LSI system theory, the amplitude of the output signal, $A_{\\text{out}}$, is given by:\n$$\nA_{\\text{out}} = A_{\\textin} \\cdot |H_C(\\omega_x, \\omega_y)|\n$$\nwhere $H_C(\\omega_x, \\omega_y)$ is the 2D frequency response of the filter $C$. Since the input amplitude $A_{\\text{in}}$ is $1$, the predicted output amplitude is simply $A_{\\text{pred}} = |H_C(\\omega_x, \\omega_y)|$.\n\nA key property of separable filters is that their 2D frequency response is the product of the 1D frequency responses of the constituent kernels. The kernel $a$ is applied vertically (along $y$) and $b$ is applied horizontally (along $x$). Therefore, the 2D frequency response is:\n$$\nH_C(\\omega_x, \\omega_y) = H_b(\\omega_x) \\cdot H_a(\\omega_y)\n$$\nwhere $H_b(\\omega_x)$ is the frequency response of kernel $b$ at frequency $\\omega_x$, and $H_a(\\omega_y)$ is the frequency response of kernel $a$ at frequency $\\omega_y$.\n\nThe predicted amplitude is thus:\n$$\nA_{\\text{pred}} = |H_b(\\omega_x) \\cdot H_a(\\omega_y)| = |H_b(\\omega_x)| \\cdot |H_a(\\omega_y)|\n$$\nThe 1D frequency response $H_h(\\omega)$ for a given kernel $h$ of length $M=5$ is calculated using the Discrete-Time Fourier Transform (DTFT) as defined in the problem:\n$$\nH_h(\\omega) = \\sum_{n=0}^{M-1} h[n] e^{-j \\omega n}\n$$\nHere, $h[n]$ are the elements of the Laws vector, indexed from $n=0$ to $n=4$. The magnitude $|H_h(\\omega)|$ is computed by taking the absolute value of this complex sum.\n\n**2. Measured Amplitude ($A_{\\text{meas}}$) Procedure**\n\nThe measured amplitude is determined empirically from the output of the convolution.\nFirst, for each test case, the $128 \\times 128$ input image $I[x,y]$ is generated.\nSecond, the $5 \\times 5$ filter kernel $C$ is constructed as the outer product of the vertical kernel $a$ and the horizontal kernel $b$, i.e., $C = ab^{\\top}$.\nThird, the output image $O[x,y]$ is computed by performing a 2D circular convolution of the input image $I$ with the kernel $C$.\n\nThe output signal $O[x,y]$ will be a sinusoid of the form $A_{\\text{meas}} \\sin(\\omega_x x + \\omega_y y + \\phi')$. The Root-Mean-Square (RMS) value of such a signal is $R = A_{\\text{meas}}/\\sqrt{2}$. The problem provides the formula to calculate the RMS of the discrete output image:\n$$\nR = \\sqrt{\\frac{1}{N^2}\\sum_{x=0}^{N-1}\\sum_{y=0}^{N-1} O[x,y]^2}\n$$\nwhere $N=128$. By rearranging the relationship between RMS and amplitude, we can compute the measured amplitude as:\n$$\nA_{\\text{meas}} = \\sqrt{2} \\cdot R\n$$\n\n**3. Error Calculation**\n\nThe theoretical prediction and empirical measurement are compared using the relative error $e$:\n$$\ne = \\frac{\\left|A_{\\text{meas}} - A_{\\text{pred}}\\right|}{\\max\\left(10^{-12}, A_{\\text{pred}}\\right)}\n$$\nThe term $\\max(10^{-12}, A_{\\text{pred}})$ in the denominator is a safeguard against division by zero for cases where the filter is expected to completely nullify the input sinusoid (i.e., $A_{\\text{pred}} = 0$).\n\nThe following program implements this entire procedure for the six specified test cases. It calculates $A_{\\text{pred}}$ from the DTFT formula, $A_{\\text{meas}}$ via circular convolution and RMS, and finally the relative error for each case.", "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef solve():\n    \"\"\"\n    Solves the Laws' filter proof-of-correctness test.\n    \"\"\"\n    \n    # Define canonical one-dimensional Laws' vectors of length 5\n    LAWS_KERNELS = {\n        'L5': np.array([1, 4, 6, 4, 1], dtype=np.float64),\n        'E5': np.array([-1, -2, 0, 2, 1], dtype=np.float64),\n        'S5': np.array([-1, 0, 2, 0, -1], dtype=np.float64),\n        'W5': np.array([-1, 2, 0, -2, 1], dtype=np.float64),\n        'R5': np.array([1, -4, 6, -4, 1], dtype=np.float64),\n    }\n\n    # Define the test suite\n    test_cases = [\n        # (vertical_kernel, horizontal_kernel, (kx, ky, phi))\n        ('E5', 'L5', (8, 0, 0.0)),\n        ('L5', 'E5', (0, 8, 1.0)),\n        ('S5', 'S5', (32, 0, 0.5)),\n        ('R5', 'R5', (60, 60, 0.0)),\n        ('W5', 'L5', (1, 0, 0.0)),\n        ('E5', 'E5', (16, 16, 0.25)),\n    ]\n\n    def calc_freq_resp_mag(kernel, omega):\n        \"\"\"\n        Calculates the magnitude of the frequency response for a 1D kernel at a\n        given angular frequency, using the DTFT definition.\n        H(omega) = sum_{n=0}^{M-1} h[n] * exp(-j * omega * n)\n        \"\"\"\n        n_indices = np.arange(len(kernel))\n        complex_exponentials = np.exp(-1j * omega * n_indices)\n        H = np.sum(kernel * complex_exponentials)\n        return np.abs(H)\n\n    results = []\n    N = 128\n    x_coords = np.arange(N)\n    y_coords = np.arange(N)\n    xx, yy = np.meshgrid(x_coords, y_coords)\n\n    for case in test_cases:\n        a_name, b_name, params = case\n        kx, ky, phi = params\n        \n        a_kernel = LAWS_KERNELS[a_name]\n        b_kernel = LAWS_KERNELS[b_name]\n\n        # 1. Derive the predicted amplitude (A_pred) from first principles\n        omega_x = 2 * np.pi * kx / N\n        omega_y = 2 * np.pi * ky / N\n        \n        # Frequency response of vertical kernel 'a' at frequency 'omega_y'\n        pred_amp_a = calc_freq_resp_mag(a_kernel, omega_y)\n        # Frequency response of horizontal kernel 'b' at frequency 'omega_x'\n        pred_amp_b = calc_freq_resp_mag(b_kernel, omega_x)\n        \n        # A_pred for the separable 2D filter is the product of 1D responses\n        A_pred = pred_amp_a * pred_amp_b\n\n        # 2. Compute the measured amplitude (A_meas)\n        # Generate the synthetic image with a single sinusoidal component\n        I = np.sin(2 * np.pi * (kx * xx / N + ky * yy / N) + phi)\n\n        # Construct the 2D separable mask C = a * b^T\n        C_2D_kernel = np.outer(a_kernel, b_kernel)\n\n        # Perform 2D circular convolution to get the output image O\n        O = convolve2d(I, C_2D_kernel, boundary='wrap', mode='same')\n\n        # Compute RMS of the output, then convert to sinusoidal amplitude\n        R = np.sqrt(np.mean(np.square(O)))\n        A_meas = np.sqrt(2) * R\n\n        # 3. Report the relative error\n        error = np.abs(A_meas - A_pred) / np.maximum(1e-12, A_pred)\n        results.append(error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.14f}' for r in results)}]\")\n\nsolve()\n```", "id": "4565096"}, {"introduction": "In a typical radiomics study, dozens of texture features are computed, often using filter banks that share common components. This final practice ([@problem_id:4565070]) shifts our focus from the correctness of a single filter to the efficiency of the entire feature extraction process. You will implement and analyze a caching strategy that exploits the separable nature of Laws' filters, learning how to quantify the theoretical speedup and avoid redundant computations in a practical workflow.", "problem": "You are asked to design and analyze a computational strategy for computing Laws' texture energy measures using separable one-dimensional filters in the context of radiomics. The fundamental base to start from is the definition of separable convolution and a simple, operation-based cost model. A Laws' two-dimensional mask is formed by the outer product of two one-dimensional kernels and can be implemented by two sequential one-dimensional convolutions: one along the horizontal direction and one along the vertical direction. Assume Five-Tap Laws one-dimensional kernels are given by\n$$\\mathrm{L5} = [\\,1,\\,4,\\,6,\\,4,\\,1\\,],\\quad \\mathrm{E5} = [\\,-1,\\,-2,\\,0,\\,2,\\,1\\,],\\quad \\mathrm{S5} = [\\,-1,\\,0,\\,2,\\,0,\\,-1\\,],$$\n$$\\mathrm{R5} = [\\,1,\\,-4,\\,6,\\,-4,\\,1\\,],\\quad \\mathrm{W5} = [\\,-1,\\,2,\\,0,\\,-2,\\,1\\,].$$\nSeparable convolution means that convolving an image with the two-dimensional mask formed by the outer product of kernels $a$ and $b$ is equivalent to first applying a one-dimensional convolution along the horizontal direction with kernel $a$ and then a one-dimensional convolution along the vertical direction with kernel $b$. Let the image have dimensions $H \\times W$.\n\nAdopt the following well-tested cost model for one-dimensional convolution passes: for a kernel of length $k$, each output element costs $k$ multiplications and $k-1$ additions. Use this as the foundational starting point to derive your method and quantify computational speedups.\n\nYour tasks are:\n- Propose and implement a method that caches intermediate one-dimensional filtered images to avoid recomputation when generating multiple masks that share the same first-stage kernel (the first horizontal pass). Implement two methods: a baseline that recomputes both passes per mask and a cached method that reuses the horizontal pass per unique first-stage kernel.\n- Compute Laws' texture energy for each mask as the global mean of the absolute value of the filtered image. Use symmetric reflection at the borders so that the output size remains $H \\times W$.\n- Using the cost model above, derive and compute the theoretical speedup factor for the cached method relative to the baseline for each test case. The speedup factor should be expressed as a float, defined strictly from counts of one-dimensional convolution passes and the kernel length $k$, and must not rely on wall-clock timing.\n\nDesign a test suite of four cases that exercise different aspects of the problem:\n1. A general case with a random image of size $64 \\times 64$ (seeded deterministically) and masks that share the same first-stage kernel: $(\\mathrm{L5}, \\mathrm{E5})$, $(\\mathrm{L5}, \\mathrm{S5})$, $(\\mathrm{L5}, \\mathrm{W5})$.\n2. A boundary-size image of size $5 \\times 5$ with constant intensity, using masks $(\\mathrm{E5}, \\mathrm{L5})$, $(\\mathrm{E5}, \\mathrm{E5})$, $(\\mathrm{E5}, \\mathrm{S5})$, $(\\mathrm{E5}, \\mathrm{R5})$.\n3. An anisotropic image of size $32 \\times 48$ consisting of horizontal stripes, with masks $(\\mathrm{E5}, \\mathrm{L5})$, $(\\mathrm{E5}, \\mathrm{E5})$, $(\\mathrm{E5}, \\mathrm{S5})$, $(\\mathrm{S5}, \\mathrm{E5})$.\n4. A small image of size $5 \\times 7$ with a simple gradient, using masks $(\\mathrm{L5}, \\mathrm{L5})$, $(\\mathrm{L5}, \\mathrm{E5})$, $(\\mathrm{L5}, \\mathrm{S5})$, $(\\mathrm{L5}, \\mathrm{R5})$, $(\\mathrm{L5}, \\mathrm{W5})$.\n\nFor each test case, your program must:\n- Compute the texture energies using both the baseline and cached methods and verify they are numerically equal up to a reasonable tolerance.\n- Compute and return the theoretical speedup factor for the cached method relative to the baseline using the cost model and the specific mask set for that test case.\n\nYour program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets (for example, $[s_1,s_2,s_3,s_4]$ where each $s_i$ is the speedup factor as a float). No physical units are involved. Angles are not used. Percentages must not appear; express all quantities as plain decimals. The final output line must be exactly in the specified format.", "solution": "The problem is well-posed, scientifically grounded, and computationally verifiable. It addresses a standard optimization technique—caching of intermediate results in separable convolutions—applied to the well-established field of Laws' texture energy measures. The problem provides all necessary definitions, constants, and a clear cost model to proceed with a formal derivation and implementation.\n\n### 1. Principle of Separable Convolution\n\nA two-dimensional ($2$D) filter kernel $K$ of size $m \\times n$ is termed separable if it can be expressed as the outer product of two one-dimensional ($1$D) vectors, a column vector $a$ of size $m \\times 1$ and a row vector $b$ of size $1 \\times n$.\n$$K = a \\cdot b^T$$\nThe convolution of an image $I$ with a separable kernel $K$, denoted $I * K$, can be decomposed into two sequential $1$D convolutions due to the associative property of convolution:\n$$I * K = I * (a \\cdot b^T) = (I * a) * b^T$$\nHere, $I * a$ represents the convolution of the image $I$ with the vertical kernel $a$ (applied to each column), and $(...) * b^T$ represents the convolution of the resulting intermediate image with the horizontal kernel $b$ (applied to each row). The order can be swapped. For this problem, we define the first pass as horizontal convolution and the second as vertical. Given a $2$D mask formed by an outer product of kernels $k_1$ and $k_2$, the filtered image $I_{filtered}$ is computed as:\n$$I_{intermediate} = I * k_1^T \\quad (\\text{1D convolution along each row})$$\n$$I_{filtered} = I_{intermediate} * k_2 \\quad (\\text{1D convolution along each column})$$\n\n### 2. Computational Cost Model and Speedup Derivation\n\nThe problem specifies a cost model for a single $1$D convolution pass. For an input of size $N_{in}$ and a kernel of length $k$, producing an output of size $N_{out}$, where each output element requires $k$ multiplications and $k-1$ additions, the total number of operations is $N_{out} \\times (k + (k-1)) = N_{out} \\times (2k-1)$.\n\nLet the image have dimensions $H \\times W$. The boundary handling mode is symmetric reflection, so the output dimensions remain $H \\times W$.\n\n- **Cost of a horizontal 1D convolution pass ($C_{horiz}$):** This operation is applied to $H$ rows. Each row convolution produces $W$ output elements.\n$$C_{horiz} = H \\times W \\times (2k - 1)$$\n- **Cost of a vertical 1D convolution pass ($C_{vert}$):** This operation is applied to the $W$ columns of the intermediate image. Each column convolution produces $H$ output elements.\n$$C_{vert} = W \\times H \\times (2k - 1)$$\nThe costs are identical: $C_{horiz} = C_{vert}$. The total cost for producing one filtered image using separable convolution is $C_{2D} = C_{horiz} + C_{vert} = 2HW(2k-1)$.\n\nWe now analyze the cost for a set of $N$ masks, $\\{(k_{1,i}, k_{2,i})\\}_{i=1}^N$. Let $U$ be the number of unique first-stage (horizontal) kernels in this set. All kernels are of length $k=5$.\n\n**Baseline Method Cost ($Cost_{baseline}$):**\nThe baseline method recomputes both the horizontal and vertical passes for each of the $N$ masks.\n$$Cost_{baseline} = \\sum_{i=1}^{N} (C_{horiz} + C_{vert}) = N \\times (C_{horiz} + C_{vert})$$\n$$Cost_{baseline} = N \\times [HW(2k-1) + HW(2k-1)] = 2N \\cdot HW(2k-1)$$\n\n**Cached Method Cost ($Cost_{cached}$):**\nThe cached method computes the horizontal pass only once for each unique horizontal kernel. There are $U$ such unique kernels. After this, it performs a vertical pass for each of the $N$ total masks.\n- Cost of all unique horizontal passes: $U \\times C_{horiz} = U \\cdot HW(2k-1)$.\n- Cost of all vertical passes: $N \\times C_{vert} = N \\cdot HW(2k-1)$.\n$$Cost_{cached} = (U \\cdot C_{horiz}) + (N \\cdot C_{vert}) = (U+N) \\cdot HW(2k-1)$$\n\n**Theoretical Speedup Factor ($S$):**\nThe speedup is the ratio of the baseline cost to the cached cost.\n$$S = \\frac{Cost_{baseline}}{Cost_{cached}} = \\frac{2N \\cdot HW(2k-1)}{(U+N) \\cdot HW(2k-1)}$$\nThe term $HW(2k-1)$ cancels out, yielding a general formula for speedup that depends only on the number of masks and the number of unique first-stage kernels:\n$$S = \\frac{2N}{U+N}$$\n\n### 3. Application to Test Cases\n\nThe provided Laws' kernels are all of length $k=5$. The speedup factor $S$ is independent of $k$, $H$, and $W$.\n\n**Case 1:**\n- Masks: $(\\mathrm{L5}, \\mathrm{E5})$, $(\\mathrm{L5}, \\mathrm{S5})$, $(\\mathrm{L5}, \\mathrm{W5})$\n- Total masks $N=3$.\n- Unique first-stage kernels: $\\{\\mathrm{L5}\\}$. Thus, $U=1$.\n- Speedup $S_1 = \\frac{2 \\times 3}{1+3} = \\frac{6}{4} = 1.5$.\n\n**Case 2:**\n- Masks: $(\\mathrm{E5}, \\mathrm{L5})$, $(\\mathrm{E5}, \\mathrm{E5})$, $(\\mathrm{E5}, \\mathrm{S5})$, $(\\mathrm{E5}, \\mathrm{R5})$\n- Total masks $N=4$.\n- Unique first-stage kernels: $\\{\\mathrm{E5}\\}$. Thus, $U=1$.\n- Speedup $S_2 = \\frac{2 \\times 4}{1+4} = \\frac{8}{5} = 1.6$.\n\n**Case 3:**\n- Masks: $(\\mathrm{E5}, \\mathrm{L5})$, $(\\mathrm{E5}, \\mathrm{E5})$, $(\\mathrm{E5}, \\mathrm{S5})$, $(\\mathrm{S5}, \\mathrm{E5})$\n- Total masks $N=4$.\n- Unique first-stage kernels: $\\{\\mathrm{E5}, \\mathrm{S5}\\}$. Thus, $U=2$.\n- Speedup $S_3 = \\frac{2 \\times 4}{2+4} = \\frac{8}{6} = \\frac{4}{3} \\approx 1.333...$.\n\n**Case 4:**\n- Masks: $(\\mathrm{L5}, \\mathrm{L5})$, $(\\mathrm{L5}, \\mathrm{E5})$, $(\\mathrm{L5}, \\mathrm{S5})$, $(\\mathrm{L5}, \\mathrm{R5})$, $(\\mathrm{L5}, \\mathrm{W5})$\n- Total masks $N=5$.\n- Unique first-stage kernels: $\\{\\mathrm{L5}\\}$. Thus, $U=1$.\n- Speedup $S_4 = \\frac{2 \\times 5}{1+5} = \\frac{10}{6} = \\frac{5}{3} \\approx 1.666...$.\n\n### 4. Implementation Strategy\n\nThe implementation will consist of two primary functions, `baseline_method` and `cached_method`, which compute the Laws' texture energies for a given set of masks and an input image.\n\n- **Convolution:** The $1$D convolutions are performed using `scipy.ndimage.convolve1d`. The horizontal pass is specified by `axis=1`, and the vertical pass by `axis=0`. The boundary condition is `mode='reflect'`, corresponding to symmetric reflection, which ensures the filtered image has the same dimensions as the input.\n- **Baseline Method:** This method iterates through the list of $N$ masks. For each mask, it sequentially performs a horizontal convolution followed by a vertical convolution, computes the energy, and stores it.\n- **Cached Method:** This method maintains a dictionary to store the results of the unique horizontal convolutions. It iterates through the list of $N$ masks. For each mask, it checks if the result of the required horizontal convolution is already in the cache. If not, it computes it and stores it. It then retrieves the (possibly newly computed) intermediate image from the cache and performs a single vertical convolution to get the final filtered image.\n- **Texture Energy:** For each filtered image, a single scalar texture energy value is computed as the global mean of the absolute values of its pixels, i.e., $E = \\frac{1}{HW} \\sum_{i=1}^{H} \\sum_{j=1}^{W} |I_{filtered}(i,j)|$.\n- **Verification:** The numerical correctness of the cached implementation is verified by asserting that the list of energies it produces is element-wise close to the list produced by the baseline method, using a small tolerance.\n- **Final Result:** For each test case, the theoretically derived speedup $S = \\frac{2N}{U+N}$ is computed and reported.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import convolve1d\n\ndef solve():\n    \"\"\"\n    Solves the problem of computing Laws' texture energy and theoretical speedup.\n    \"\"\"\n    \n    # Define the 5-tap Laws' kernels\n    kernels = {\n        'L5': np.array([1, 4, 6, 4, 1], dtype=np.float64),\n        'E5': np.array([-1, -2, 0, 2, 1], dtype=np.float64),\n        'S5': np.array([-1, 0, 2, 0, -1], dtype=np.float64),\n        'R5': np.array([1, -4, 6, -4, 1], dtype=np.float64),\n        'W5': np.array([-1, 2, 0, -2, 1], dtype=np.float64),\n    }\n\n    # Normalize kernels to have a sum of zero, except for the smoothing kernel L5\n    for name, kernel in kernels.items():\n        if name != 'L5':\n            kernels[name] = kernel - np.mean(kernel)\n    kernels['L5'] = kernels['L5'] / np.sum(kernels['L5'])\n\n\n    def compute_energy(image):\n        \"\"\"Computes a single texture energy value for a filtered image.\"\"\"\n        return np.mean(np.abs(image))\n\n    def baseline_method(image, masks, kernels_map):\n        \"\"\"Computes energies by recomputing both passes for each mask.\"\"\"\n        energies = []\n        for k1_name, k2_name in masks:\n            k1 = kernels_map[k1_name]\n            k2 = kernels_map[k2_name]\n            \n            # Horizontal pass (on each row)\n            intermediate = convolve1d(image, k1, axis=1, mode='reflect')\n            \n            # Vertical pass (on each column)\n            filtered = convolve1d(intermediate, k2, axis=0, mode='reflect')\n            \n            energies.append(compute_energy(filtered))\n        return energies\n\n    def cached_method(image, masks, kernels_map):\n        \"\"\"Computes energies by caching results of the horizontal pass.\"\"\"\n        energies = []\n        intermediate_cache = {}\n        \n        for k1_name, k2_name in masks:\n            # Horizontal pass (with caching)\n            if k1_name not in intermediate_cache:\n                k1 = kernels_map[k1_name]\n                intermediate_cache[k1_name] = convolve1d(image, k1, axis=1, mode='reflect')\n            \n            intermediate = intermediate_cache[k1_name]\n            \n            # Vertical pass\n            k2 = kernels_map[k2_name]\n            filtered = convolve1d(intermediate, k2, axis=0, mode='reflect')\n            \n            energies.append(compute_energy(filtered))\n        return energies\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"image_gen\": lambda: np.random.default_rng(seed=42).random((64, 64)),\n            \"masks\": [('L5', 'E5'), ('L5', 'S5'), ('L5', 'W5')]\n        },\n        {\n            \"image_gen\": lambda: np.full((5, 5), 100.0, dtype=np.float64),\n            \"masks\": [('E5', 'L5'), ('E5', 'E5'), ('E5', 'S5'), ('E5', 'R5')]\n        },\n        {\n            \"image_gen\": lambda: (np.arange(32)[:, np.newaxis] % 2).astype(np.float64) * np.ones((32, 48)),\n            \"masks\": [('E5', 'L5'), ('E5', 'E5'), ('E5', 'S5'), ('S5', 'E5')]\n        },\n        {\n            \"image_gen\": lambda: np.arange(5 * 7, dtype=np.float64).reshape((5, 7)),\n            \"masks\": [('L5', 'L5'), ('L5', 'E5'), ('L5', 'S5'), ('L5', 'R5'), ('L5', 'W5')]\n        },\n    ]\n\n    speedup_results = []\n    for case in test_cases:\n        image = case[\"image_gen\"]()\n        masks = case[\"masks\"]\n\n        # Calculate N and U for the theoretical speedup formula\n        N = len(masks)\n        first_stage_kernels = [m[0] for m in masks]\n        U = len(set(first_stage_kernels))\n\n        # Compute the theoretical speedup factor\n        speedup = (2 * N) / (U + N)\n        speedup_results.append(speedup)\n\n        # Verification step: ensure both methods produce the same results\n        baseline_energies = baseline_method(image, masks, kernels)\n        cached_energies = cached_method(image, masks, kernels)\n        np.testing.assert_allclose(baseline_energies, cached_energies, rtol=1e-9, atol=1e-9)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, speedup_results))}]\")\n\nsolve()\n```", "id": "4565070"}]}