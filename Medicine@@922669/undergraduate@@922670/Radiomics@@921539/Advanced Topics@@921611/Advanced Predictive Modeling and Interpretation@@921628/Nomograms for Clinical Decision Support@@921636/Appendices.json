{"hands_on_practices": [{"introduction": "Before a single data point is collected, rigorous planning is essential for developing a trustworthy clinical nomogram. A model built on an insufficient sample size is prone to overfitting and will likely fail to generalize to new patients. This exercise introduces the \"Events-Per-Variable\" (EPV) heuristic, a critical rule-of-thumb for determining the necessary sample size in logistic regression, ensuring your model has a solid statistical foundation. [@problem_id:4553768]", "problem": "You are planning a radiomics-based logistic regression nomogram to support clinical decision making for a binary outcome (e.g., treatment response versus non-response) with expected prevalence $\\pi = 0.3$. The nomogram will be constructed from $k = 15$ candidate radiomic features, and you will fit all $k$ as parameters in the initial model to represent a worst-case requirement. The goal is to ensure adequate sample size for model development so that the estimated regression coefficients yield stable calibration and low overfitting.\n\nUse only fundamental definitions and widely accepted guidance to derive the sample size constraints. Start from the following bases:\n\n- In logistic regression for a binary outcome, the expected number of outcome events in a sample of size $N$ is $E = \\pi N$.\n- The events-per-variable (EPV) heuristic requires at least $10$ events per parameter.\n- Recent simulation-based guidance for prediction modeling targeting a calibration slope close to $1$ and limiting overfitting recommends at least $20$ events per parameter under moderate signal-to-noise conditions.\n\nFrom these bases, derive an algebraic relationship linking the total sample size $N$, the number of parameters $k$, the prevalence $\\pi$, and an EPV target $c$. Use that relationship to compute the minimum $N$ that simultaneously satisfies both constraints ($c = 10$ and $c = 20$) when $\\pi = 0.3$ and $k = 15$. Provide the final answer as the smallest integer $N$ that meets both requirements. No rounding instruction is needed, and there are no physical units to express for $N$.", "solution": "The user has provided a problem statement that requires validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   Model Type: Logistic regression nomogram for clinical decision support.\n-   Outcome: Binary (e.g., treatment response vs. non-response).\n-   Expected Prevalence: $\\pi = 0.3$.\n-   Number of Candidate Parameters: $k = 15$.\n-   Requirement Basis 1: The expected number of outcome events in a sample of size $N$ is $E = \\pi N$.\n-   Requirement Basis 2: Events-Per-Variable (EPV) heuristic, defined as the ratio of events to the number of parameters, requires a minimum of $c=10$ events per parameter.\n-   Requirement Basis 3: Recent simulation-based guidance recommends a minimum of $c=20$ events per parameter to ensure good model calibration and limit overfitting.\n-   Objective: Derive an algebraic relationship for sample size $N$ and compute the minimum integer $N$ that satisfies both EPV constraints ($c=10$ and $c=20$) for the given $k$ and $\\pi$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the validation criteria.\n\n-   **Scientifically Grounded**: The problem is set within the standard framework of biostatistics and predictive modeling. Logistic regression, sample size calculation, the Events-Per-Variable (EPV) heuristic, and the concern for model calibration and overfitting are all fundamental and well-established concepts in this field. The specified values for prevalence ($\\pi=0.3$) and number of parameters ($k=15$) are realistic for a radiomics study.\n-   **Well-Posed**: The problem is clear, internally consistent, and self-contained. It provides all necessary data and definitions to derive a relationship and compute a specific numerical answer. The objective is to find the minimum integer sample size that satisfies a set of well-defined constraints, which leads to a unique solution.\n-   **Objective**: The language is precise, technical, and free of any subjective or ambiguous terminology.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or infeasibility. It is a standard, formalizable problem in statistical planning for a clinical study.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be provided.\n\n### Solution Derivation\nThe problem requires the derivation of a general relationship for the minimum sample size $N$ based on the Events-Per-Variable (EPV) criterion, and then the application of this relationship to find the required $N$ for the given parameters.\n\nFirst, we formalize the EPV concept as per the problem description. The Events-Per-Variable (EPV) is the ratio of the number of events (the less frequent outcome in a binary classification setting) to the number of parameters (or variables) included in the model. Let $E$ be the number of events, $k$ be the number of parameters, and $c$ be the target minimum number of events per parameter. The constraint is expressed as:\n$$ \\frac{E}{k} \\ge c $$\n\nThe problem states that for a total sample size $N$ and an outcome prevalence $\\pi$, the expected number of events is given by $E = \\pi N$. For this relationship to hold, $\\pi$ must represent the prevalence of the event of interest, which is conventionally the less frequent outcome to ensure a conservative sample size estimate. Given $\\pi = 0.3$, the prevalence of the alternative outcome is $1-\\pi = 0.7$. Since $0.3 < 0.7$, $\\pi=0.3$ correctly represents the prevalence of the limiting (less frequent) event category.\n\nWe substitute the expression for $E$ into the EPV inequality:\n$$ \\frac{\\pi N}{k} \\ge c $$\nThis is the algebraic relationship linking total sample size $N$, prevalence $\\pi$, number of parameters $k$, and the EPV target $c$.\n\nTo find the minimum required sample size $N$, we solve this inequality for $N$:\n$$ \\pi N \\ge c k $$\n$$ N \\ge \\frac{c k}{\\pi} $$\nThis inequality provides the lower bound for the sample size required to meet a specific EPV target $c$.\n\nThe problem specifies two constraints that must be met simultaneously:\n1.  The traditional heuristic: $c_1 = 10$.\n2.  The more stringent, modern guidance: $c_2 = 20$.\n\nWe calculate the minimum required sample size for each constraint using the given values $k=15$ and $\\pi=0.3$.\n\nFor the first constraint ($c_1 = 10$):\nLet $N_1$ be the minimum sample size for this case.\n$$ N_1 \\ge \\frac{c_1 k}{\\pi} $$\n$$ N_1 \\ge \\frac{10 \\times 15}{0.3} = \\frac{150}{0.3} $$\n$$ N_1 \\ge 500 $$\nThus, a minimum sample size of $500$ is required to satisfy the EPV $\\ge 10$ rule.\n\nFor the second, more stringent constraint ($c_2 = 20$):\nLet $N_2$ be the minimum sample size for this case.\n$$ N_2 \\ge \\frac{c_2 k}{\\pi} $$\n$$ N_2 \\ge \\frac{20 \\times 15}{0.3} = \\frac{300}{0.3} $$\n$$ N_2 \\ge 1000 $$\nThus, a minimum sample size of $1000$ is required to satisfy the EPV $\\ge 20$ rule, which is intended to provide better model stability and calibration.\n\nThe problem asks for the minimum sample size $N$ that **simultaneously satisfies both constraints**. This means $N$ must satisfy both $N \\ge 500$ and $N \\ge 1000$. To satisfy both inequalities, $N$ must be greater than or equal to the maximum of the two required minimums:\n$$ N \\ge \\max(500, 1000) $$\n$$ N \\ge \\max(500, 1000) $$\n$$ N \\ge 1000 $$\nThe smallest integer value for $N$ that satisfies this condition is $1000$. Therefore, to meet the modern guidance for prediction model development while also satisfying the traditional heuristic, a minimum sample size of $1000$ is required.", "answer": "$$\n\\boxed{1000}\n$$", "id": "4553768"}, {"introduction": "A nomogram's power lies in its ability to translate a complex regression model into a simple, point-based scoring system. This exercise reveals the engine behind the display, showing how a specific patient characteristic is converted into points and how those points directly influence the final predicted probability. By working through this process, you will gain a concrete understanding of the link between a feature's value, the model's linear predictor, and the risk estimate provided by the nomogram. [@problem_id:4553775]", "problem": "A radiomics-based clinical decision support tool uses a logistic regression risk model summarized by a nomogram. Predictors are standardized to zero mean and unit variance. In this framework, the linear predictor (log-odds) is additive in predictor contributions, and the nomogram maps predictor contributions to points on a linear scale. Assume the following conditions hold: a single standardized radiomics feature $x_{1}$ has value $x_{1}=1.5$ and regression coefficient $\\beta_{1}=0.6$, and the nomogram is calibrated so that one point corresponds to an increment $\\Delta \\eta=0.05$ in the linear predictor. Also assume a baseline odds of $1:1$ for the clinical event of interest.\n\nUsing only the definitions of odds, log-odds, and the logistic link function as the fundamental base, determine:\n- the number of points contributed by the feature value $x_{1}=1.5$ under the given point scale, and\n- the implied change in predicted probability from the baseline when this feature contribution is added.\n\nExpress the final result as two quantities in a single row vector: first the total points, then the change in predicted probability. For the change in predicted probability, provide an exact analytic expression in terms of $\\exp(\\cdot)$; do not round or approximate. No units are required and no percentage signs should be used.", "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It provides a self-contained and consistent set of givens rooted in standard statistical methodology (logistic regression) and its application in clinical decision support (nomograms). All provided values are physically and statistically plausible, and the questions asked have unique, verifiable answers.\n\nThe solution proceeds by first principles, as requested. The core of the problem relates a feature's value to its impact on the linear predictor (log-odds) in a logistic regression model, and subsequently to the change in predicted probability.\n\nLet $P$ be the probability of the clinical event of interest. The odds of the event are defined as $O = \\frac{P}{1-P}$.\nThe logistic regression model uses the natural logarithm of the odds, known as the log-odds or linear predictor $\\eta$, as the response variable:\n$$ \\eta = \\ln(O) = \\ln\\left(\\frac{P}{1-P}\\right) $$\nThe linear predictor $\\eta$ is modeled as a linear combination of predictor variables $x_i$ with coefficients $\\beta_i$, plus an intercept $\\beta_0$:\n$$ \\eta = \\beta_0 + \\sum_{i} \\beta_i x_i $$\nThe contribution of a single predictor $x_1$ to the linear predictor is the term $\\Delta\\eta_1 = \\beta_1 x_1$.\n\nThe problem provides the following values:\n- Standardized feature value: $x_1 = 1.5$\n- Regression coefficient: $\\beta_1 = 0.6$\n\nThe contribution of this feature to the linear predictor is calculated as:\n$$ \\Delta\\eta_1 = \\beta_1 x_1 = (0.6)(1.5) = 0.9 $$\n\nThe first quantity to find is the number of points this contribution represents on the nomogram. The problem states that the nomogram is calibrated such that one point corresponds to an increment of $\\Delta\\eta = 0.05$ in the linear predictor. Thus, the total number of points, $N_p$, for the contribution $\\Delta\\eta_1$ is:\n$$ N_p = \\frac{\\Delta\\eta_1}{0.05} = \\frac{0.9}{0.05} = \\frac{90}{5} = 18 $$\nSo, the feature value $x_1=1.5$ contributes $18$ points to the nomogram score.\n\nThe second quantity to find is the implied change in predicted probability from the baseline. To do this, we must first establish the baseline probability and then the new probability after including the feature's contribution.\nThe probability $P$ can be expressed as a function of the linear predictor $\\eta$ by rearranging the log-odds equation. This yields the logistic function:\n$$ P(\\eta) = \\frac{\\exp(\\eta)}{1+\\exp(\\eta)} $$\nThe problem specifies a baseline odds of $1:1$, which means $O_{base} = 1$. The corresponding baseline linear predictor $\\eta_{base}$ is:\n$$ \\eta_{base} = \\ln(O_{base}) = \\ln(1) = 0 $$\nThe baseline probability $P_{base}$ is therefore:\n$$ P_{base} = P(\\eta_{base}) = P(0) = \\frac{\\exp(0)}{1+\\exp(0)} = \\frac{1}{1+1} = \\frac{1}{2} $$\nThe new linear predictor, $\\eta_{new}$, is the sum of the baseline predictor and the contribution from the feature $x_1$:\n$$ \\eta_{new} = \\eta_{base} + \\Delta\\eta_1 = 0 + 0.9 = 0.9 $$\nThe new probability, $P_{new}$, corresponding to this updated linear predictor is:\n$$ P_{new} = P(\\eta_{new}) = P(0.9) = \\frac{\\exp(0.9)}{1+\\exp(0.9)} $$\nThe change in predicted probability, $\\Delta P$, is the difference between the new probability and the baseline probability:\n$$ \\Delta P = P_{new} - P_{base} = \\frac{\\exp(0.9)}{1+\\exp(0.9)} - \\frac{1}{2} $$\nTo obtain a single fractional expression, we find a common denominator:\n$$ \\Delta P = \\frac{2\\exp(0.9)}{2(1+\\exp(0.9))} - \\frac{1+\\exp(0.9)}{2(1+\\exp(0.9))} = \\frac{2\\exp(0.9) - (1+\\exp(0.9))}{2(1+\\exp(0.9))} $$\nSimplifying the numerator yields the final exact analytical expression for the change in probability:\n$$ \\Delta P = \\frac{\\exp(0.9) - 1}{2(1+\\exp(0.9))} $$\nThe two required quantities are the number of points, $18$, and the change in probability, $\\frac{\\exp(0.9) - 1}{2(1+\\exp(0.9))}$. These are to be presented in a single row vector.", "answer": "$$ \\boxed{\\begin{pmatrix} 18 & \\frac{\\exp(0.9) - 1}{2(1 + \\exp(0.9))} \\end{pmatrix}} $$", "id": "4553775"}, {"introduction": "A predictive model is not a static tool; its performance can degrade when applied to new patient populations, a phenomenon known as calibration drift. This exercise tackles this vital real-world problem by demonstrating how to recalibrate a nomogram that has lost its accuracy. You will learn how to use a calibration model to adjust the original predictions, ensuring the nomogram remains a reliable decision support tool even as clinical environments change. [@problem_id:4553785]", "problem": "A radiomics-based clinical nomogram for binary outcome prediction was originally derived using a logistic regression model. By construction of the nomogram’s total point scale, the model’s linear predictor is an affine function of the total points $T$, so that the original predicted probability for a patient with total points $T$ is\n$$\np_{\\text{orig}}(T) \\;=\\; \\operatorname{logit}^{-1}\\!\\big(a + b\\,T\\big) \\;=\\; \\frac{1}{1 + \\exp\\!\\big(-\\big(a + b\\,T\\big)\\big)} ,\n$$\nwhere $a$ is the model intercept on the linear predictor scale and $b$ is the slope per point on the same scale.\n\nAn external validation cohort shows calibration drift. Following standard calibration-in-the-large and slope assessment, you fit the calibration model\n$$\n\\operatorname{logit}\\!\\big(p_{\\text{true}}\\big) \\;=\\; \\alpha \\;+\\; \\gamma \\,\\operatorname{logit}\\!\\big(p_{\\text{orig}}(T)\\big),\n$$\nwhich yields estimates $\\alpha$ and $\\gamma$ for the external setting. This motivates two recalibration options for the nomogram:\n- Intercept-only recalibration (adjusting the intercept $\\,\\beta_{0}\\,$): set $\\gamma = 1$ and adjust the intercept by $\\alpha$.\n- Intercept-and-slope recalibration (adjusting both $\\,\\beta_{0}\\,$ and the global slope): use the estimated $\\alpha$ and $\\gamma$.\n\nStarting from the definitions of the logistic link $\\operatorname{logit}(p) = \\ln\\!\\big(\\frac{p}{1-p}\\big)$ and its inverse $\\operatorname{logit}^{-1}(x) = \\frac{1}{1+\\exp(-x)}$, and the linear mapping between nomogram points and the original linear predictor, derive the recalibrated probability function $p_{\\text{recal}}(T)$ for both intercept-only and intercept-and-slope recalibration in terms of $a$, $b$, $\\alpha$, $\\gamma$, and $T$. Then, using the intercept-and-slope recalibration, compute the recalibrated predicted probability for a patient with total points $T = 120$ when $a = -3.0$, $b = 0.02$, $\\alpha = -0.3$, and $\\gamma = 0.9$. Round your final numeric answer to four significant figures and express it as a decimal (no percent sign).", "solution": "The problem requires the derivation of recalibrated probability functions based on a logistic regression model and a subsequent calibration model, followed by a numerical calculation for a specific case.\n\nFirst, we validate the problem statement.\nAll givens have been extracted and analyzed. The problem is scientifically grounded in standard statistical methodology for clinical prediction models (logistic regression, nomogram calibration), is well-posed with all necessary information provided and no contradictions, and is expressed in objective, formal language. The problem is therefore deemed valid.\n\nWe begin the derivation. The original predicted probability, $p_{\\text{orig}}(T)$, is defined via its linear predictor, $\\eta_{\\text{orig}} = a + bT$, as:\n$$\np_{\\text{orig}}(T) = \\operatorname{logit}^{-1}(\\eta_{\\text{orig}}) = \\operatorname{logit}^{-1}(a + bT)\n$$\nBy applying the logit function, which is the inverse of the $\\operatorname{logit}^{-1}$ function, to both sides of this definition, we obtain a direct expression for the logit of the original probability:\n$$\n\\operatorname{logit}\\big(p_{\\text{orig}}(T)\\big) = \\operatorname{logit}\\big(\\operatorname{logit}^{-1}(a + bT)\\big) = a + bT\n$$\nThis relationship is the key to connecting the original model to the calibration model.\n\nThe calibration model relates the \"true\" probability in the new population, which we will denote as the recalibrated probability $p_{\\text{recal}}(T)$, to the original predicted probability $p_{\\text{orig}}(T)$:\n$$\n\\operatorname{logit}\\big(p_{\\text{recal}}(T)\\big) = \\alpha + \\gamma \\operatorname{logit}\\big(p_{\\text{orig}}(T)\\big)\n$$\nHere, $\\alpha$ is the calibration intercept (related to calibration-in-the-large) and $\\gamma$ is the calibration slope. The left-hand side of this equation is the recalibrated linear predictor, $\\eta_{\\text{recal}}$.\n\nBy substituting the expression for $\\operatorname{logit}\\big(p_{\\text{orig}}(T)\\big)$ into the calibration model, we get the recalibrated linear predictor in terms of the original model parameters and the calibration parameters:\n$$\n\\eta_{\\text{recal}} = \\operatorname{logit}\\big(p_{\\text{recal}}(T)\\big) = \\alpha + \\gamma (a + bT)\n$$\nWe can rearrange this into the form of a new linear predictor:\n$$\n\\operatorname{logit}\\big(p_{\\text{recal}}(T)\\big) = (\\alpha + \\gamma a) + (\\gamma b)T\n$$\nTo find the recalibrated probability $p_{\\text{recal}}(T)$, we apply the inverse logit function to this recalibrated linear predictor:\n$$\np_{\\text{recal}}(T) = \\operatorname{logit}^{-1}\\big((\\alpha + \\gamma a) + (\\gamma b)T\\big)\n$$\nUsing the definition $\\operatorname{logit}^{-1}(x) = \\frac{1}{1 + \\exp(-x)}$, this becomes:\n$$\np_{\\text{recal}}(T) = \\frac{1}{1 + \\exp\\big(-((\\alpha + \\gamma a) + (\\gamma b)T)\\big)}\n$$\nThis is the general formula for the **intercept-and-slope recalibration**.\n\nFor the special case of **intercept-only recalibration**, we set the calibration slope $\\gamma = 1$. Substituting $\\gamma=1$ into the general formula gives:\n$$\np_{\\text{recal}}(T) = \\frac{1}{1 + \\exp\\big(-((\\alpha + 1 \\cdot a) + (1 \\cdot b)T)\\big)} = \\frac{1}{1 + \\exp\\big(-((\\alpha+a) + bT)\\big)}\n$$\nThis corresponds to adjusting the original model's intercept $a$ by the calibration intercept $\\alpha$, while leaving the slope $b$ unchanged.\n\nNext, we perform the numerical calculation as requested, using the intercept-and-slope recalibration formula. The given values are:\n-   Total points $T = 120$\n-   Original intercept $a = -3.0$\n-   Original slope per point $b = 0.02$\n-   Calibration intercept $\\alpha = -0.3$\n-   Calibration slope $\\gamma = 0.9$\n\nWe first compute the recalibrated linear predictor, $\\eta_{\\text{recal}}$:\n$$\n\\eta_{\\text{recal}} = (\\alpha + \\gamma a) + (\\gamma b)T\n$$\nSubstituting the numerical values:\n$$\n\\eta_{\\text{recal}} = (-0.3 + (0.9)(-3.0)) + ((0.9)(0.02))(120)\n$$\n$$\n\\eta_{\\text{recal}} = (-0.3 - 2.7) + (0.018)(120)\n$$\n$$\n\\eta_{\\text{recal}} = -3.0 + 2.16\n$$\n$$\n\\eta_{\\text{recal}} = -0.84\n$$\nNow, we compute the recalibrated probability $p_{\\text{recal}}(T=120)$ by applying the inverse logit function:\n$$\np_{\\text{recal}}(120) = \\frac{1}{1 + \\exp(-\\eta_{\\text{recal}})} = \\frac{1}{1 + \\exp(-(-0.84))} = \\frac{1}{1 + \\exp(0.84)}\n$$\nCalculating the value:\n$$\n\\exp(0.84) \\approx 2.3163668\n$$\n$$\np_{\\text{recal}}(120) \\approx \\frac{1}{1 + 2.3163668} = \\frac{1}{3.3163668} \\approx 0.301535\n$$\nThe problem requires rounding the final answer to four significant figures. The first four significant figures are $3$, $0$, $1$, and $5$. The following digit is $3$, so we round down.\n$$\np_{\\text{recal}}(120) \\approx 0.3015\n$$", "answer": "$$\\boxed{0.3015}$$", "id": "4553785"}]}