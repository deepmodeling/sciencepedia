{"hands_on_practices": [{"introduction": "One of the most direct paths to explainability is to build models that are inherently simple. This exercise [@problem_id:4538105] delves into $\\ell_{1}$-regularized logistic regression (LASSO), a powerful technique that achieves simplicity through sparsity by forcing the coefficients of less important features to exactly zero. By working through the optimization from first principles, you will gain a deep, hands-on understanding of how feature selection is embedded directly into the model training process.", "problem": "In a radiomics study, you build a binary classifier to predict malignancy ($y_i \\in \\{0,1\\}$) from two handcrafted imaging features: gray-level co-occurrence matrix (GLCM) contrast and sphericity. To promote interpretability in Explainable Artificial Intelligence (XAI), you decide to use logistic regression with an $\\ell_1$ penalty (Least Absolute Shrinkage and Selection Operator (LASSO)) on the feature coefficients, leaving the intercept unpenalized.\n\nStarting from first principles appropriate for this context, use the following base:\n- The conditional distribution of the labels is Bernoulli with parameter $\\Pr(y_i=1 \\mid \\boldsymbol{x}_i) = \\sigma(z_i)$, where $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ is the logistic function and $z_i = \\beta_0 + \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}$.\n- The negative log-likelihood is the sum over samples of the negative log of the Bernoulli probability mass function.\n\nTasks:\n1) Derive the convex optimization objective for $\\ell_1$-regularized logistic regression that minimizes the average negative log-likelihood plus an $\\ell_1$ penalty of strength $\\lambda$ applied only to $\\boldsymbol{\\beta}$ (the intercept $\\beta_0$ is not penalized). Write the objective explicitly as a function of $\\beta_0$ and $\\boldsymbol{\\beta}$.\n2) Using first-order optimality with subgradients (Karush–Kuhn–Tucker conditions), specialize these conditions at $\\boldsymbol{\\beta}=\\boldsymbol{0}$ with $\\beta_0$ set to the maximum-likelihood intercept under $\\boldsymbol{\\beta}=\\boldsymbol{0}$. Derive an explicit formula for the smallest $\\lambda$ value, denoted $\\lambda_{\\max}$, such that $\\boldsymbol{\\beta}=\\boldsymbol{0}$ satisfies the optimality conditions. Your expression must be in terms of $\\{y_i\\}_{i=1}^{n}$, $\\{\\boldsymbol{x}_i\\}_{i=1}^{n}$, and $n$.\n3) Compute $\\lambda_{\\max}$ for the mini-cohort of $n=8$ patients below. The features have been centered to zero mean across the cohort. Report $\\lambda_{\\max}$ as a dimensionless value. Round your answer to four significant figures.\n\n- Labels $y$: $[\\,1,\\ 0,\\ 1,\\ 0,\\ 0,\\ 1,\\ 0,\\ 1\\,]$.\n- Feature vector for GLCM contrast ($x_{i1}$): $[\\,1.2,\\ -0.8,\\ 0.5,\\ -1.0,\\ -0.4,\\ 0.9,\\ -0.6,\\ 0.2\\,]$.\n- Feature vector for sphericity ($x_{i2}$): $[\\,-0.5,\\ 1.1,\\ -1.3,\\ 0.7,\\ 0.4,\\ -0.9,\\ 1.5,\\ -1.0\\,]$.\n\nFinally, in one to two sentences, explain why sparsity can lead to simpler explanations in radiomics and why high collinearity among features can make these explanations unstable.\n\nExpress the final numerical answer for $\\lambda_{\\max}$ as instructed above.", "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n- **Model:** Binary classifier for malignancy $y_i \\in \\{0, 1\\}$.\n- **Features:** Two handcrafted imaging features: GLCM contrast ($x_{i1}$) and sphericity ($x_{i2}$). The feature vector for the $i$-th patient is $\\boldsymbol{x}_i = [x_{i1}, x_{i2}]^{\\top}$.\n- **Classifier form:** Logistic regression. The conditional probability of a positive label is $\\Pr(y_i=1 \\mid \\boldsymbol{x}_i) = \\sigma(z_i)$, where $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$ is the logistic sigmoid function.\n- **Linear model:** $z_i = \\beta_0 + \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}$, where $\\beta_0$ is the intercept and $\\boldsymbol{\\beta} = [\\beta_1, \\beta_2]^{\\top}$ is the vector of feature coefficients.\n- **Objective function:** Minimize the average negative log-likelihood plus an $\\ell_{1}$ penalty.\n- **Regularization:** The $\\ell_{1}$ penalty applies only to the feature coefficients $\\boldsymbol{\\beta}$, not the intercept $\\beta_0$. The penalty strength is $\\lambda$.\n- **Data:** A cohort of $n=8$ patients.\n- **Labels:** $\\boldsymbol{y_s} = [1, 0, 1, 0, 0, 1, 0, 1]$.\n- **Feature 1 (GLCM contrast):** $\\boldsymbol{x_1} = [1.2, -0.8, 0.5, -1.0, -0.4, 0.9, -0.6, 0.2]$.\n- **Feature 2 (Sphericity):** $\\boldsymbol{x_2} = [-0.5, 1.1, -1.3, 0.7, 0.4, -0.9, 1.5, -1.0]$.\n- **Data Preprocessing:** The features have been centered to have zero mean.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria:\n- **Scientifically Grounded:** The problem is firmly rooted in statistical machine learning. It involves logistic regression, negative log-likelihood, and $\\ell_{1}$ (LASSO) regularization, all of which are standard and fundamental concepts. The context of radiomics and Explainable AI (XAI) is appropriate and realistic.\n- **Well-Posed:** The tasks are clearly defined mathematical derivations and calculations. Deriving the objective function, finding the analytical form for $\\lambda_{\\max}$ using KKT conditions, and computing its value for the given dataset are all procedures that lead to a unique and meaningful solution.\n- **Objective:** The problem is stated in precise, formal language, free of ambiguity or subjective claims.\n- **Completeness and Consistency:** All necessary information, including the model structure, penalty form, base functions, and a complete dataset, is provided. The condition that features are centered is explicitly stated and can be verified with the data, ensuring consistency.\n- **Feasibility:** The numerical values are reasonable for centered features. The tasks are computationally feasible.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, and internally consistent. It is deemed **valid**. The solution process will now proceed.\n\n---\n\n## Solution\n\n### 1) Derivation of the Optimization Objective\n\nThe problem asks for the objective function for $\\ell_1$-regularized logistic regression. We begin from the likelihood of the data. For a single observation $(y_i, \\boldsymbol{x}_i)$, the conditional probability of the label $y_i$ is given by the Bernoulli probability mass function:\n$$\n\\Pr(y_i \\mid \\boldsymbol{x}_i, \\beta_0, \\boldsymbol{\\beta}) = p_i^{y_i} (1 - p_i)^{1-y_i}\n$$\nwhere $p_i = \\Pr(y_i=1 \\mid \\boldsymbol{x}_i) = \\sigma(\\beta_0 + \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta})$.\n\nThe log-likelihood for a single observation is:\n$$\n\\ell_i(\\beta_0, \\boldsymbol{\\beta}) = \\ln \\left( p_i^{y_i} (1 - p_i)^{1-y_i} \\right) = y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i)\n$$\nWe use the properties of the logistic function $\\sigma(z) = \\frac{1}{1+\\exp(-z)}$:\n$$\n\\ln(p_i) = \\ln(\\sigma(z_i)) = \\ln\\left(\\frac{1}{1+\\exp(-z_i)}\\right) = -\\ln(1+\\exp(-z_i))\n$$\n$$\n\\ln(1-p_i) = \\ln(1-\\sigma(z_i)) = \\ln\\left(\\frac{\\exp(-z_i)}{1+\\exp(-z_i)}\\right) = -z_i - \\ln(1+\\exp(-z_i))\n$$\nSubstituting these into the log-likelihood expression:\n$$\n\\ell_i(\\beta_0, \\boldsymbol{\\beta}) = y_i(-\\ln(1+\\exp(-z_i))) + (1-y_i)(-z_i - \\ln(1+\\exp(-z_i)))\n$$\n$$\n\\ell_i(\\beta_0, \\boldsymbol{\\beta}) = -y_i\\ln(1+\\exp(-z_i)) - z_i + y_iz_i - \\ln(1+\\exp(-z_i)) + y_i\\ln(1+\\exp(-z_i))\n$$\n$$\n\\ell_i(\\beta_0, \\boldsymbol{\\beta}) = y_iz_i - z_i - \\ln(1+\\exp(-z_i))\n$$\nUsing the identity $\\ln(1+\\exp(z_i)) = z_i + \\ln(1+\\exp(-z_i))$, we can write this more compactly as:\n$$\n\\ell_i(\\beta_0, \\boldsymbol{\\beta}) = y_iz_i - \\ln(1+\\exp(z_i))\n$$\nThe total log-likelihood for $n$ samples is the sum $L(\\beta_0, \\boldsymbol{\\beta}) = \\sum_{i=1}^n \\ell_i$. The negative log-likelihood (NLL) is:\n$$\n\\text{NLL}(\\beta_0, \\boldsymbol{\\beta}) = -\\sum_{i=1}^n \\left( y_iz_i - \\ln(1+\\exp(z_i)) \\right) = \\sum_{i=1}^n \\left( \\ln(1+\\exp(z_i)) - y_iz_i \\right)\n$$\nThe optimization objective, $J(\\beta_0, \\boldsymbol{\\beta})$, is the average NLL plus the $\\ell_1$ penalty on $\\boldsymbol{\\beta}$.\n$$\nJ(\\beta_0, \\boldsymbol{\\beta}) = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\ln(1+\\exp(\\beta_0 + \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta})) - y_i (\\beta_0 + \\boldsymbol{x}_i^{\\top}\\boldsymbol{\\beta}) \\right] + \\lambda \\|\\boldsymbol{\\beta}\\|_1\n$$\nwhere $\\|\\boldsymbol{\\beta}\\|_1 = \\sum_{j=1}^p |\\beta_j|$, and in this problem, the number of features is $p=2$.\n\n### 2) Derivation of $\\lambda_{\\max}$\n\nThe value $\\lambda_{\\max}$ is the smallest $\\lambda \\ge 0$ for which the optimal solution is $\\boldsymbol{\\beta} = \\boldsymbol{0}$. We use the Karush–Kuhn–Tucker (KKT) conditions for optimality. The objective function is convex but non-differentiable at $\\beta_j=0$ due to the $\\ell_1$ norm. We use subgradients.\nThe objective is $J(\\beta_0, \\boldsymbol{\\beta}) = f(\\beta_0, \\boldsymbol{\\beta}) + \\lambda g(\\boldsymbol{\\beta})$, where $f$ is the average NLL and $g(\\boldsymbol{\\beta}) = \\|\\boldsymbol{\\beta}\\|_1$.\n\nThe optimality conditions at a solution $(\\hat{\\beta}_0, \\hat{\\boldsymbol{\\beta}})$ are:\n1. For the unpenalized intercept $\\beta_0$: $\\frac{\\partial f}{\\partial \\beta_0}\\Big|_{(\\hat{\\beta}_0, \\hat{\\boldsymbol{\\beta}})} = 0$.\n2. For the penalized coefficients $\\boldsymbol{\\beta}$: $\\boldsymbol{0} \\in \\nabla_{\\boldsymbol{\\beta}} f(\\hat{\\beta}_0, \\hat{\\boldsymbol{\\beta}}) + \\lambda \\partial g(\\hat{\\boldsymbol{\\beta}})$, where $\\partial g$ is the subgradient of the $\\ell_1$ norm.\n\nLet's evaluate these conditions for a solution where $\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{0}$.\nFirst, we find the gradient of $f$:\n$$\n\\frac{\\partial f}{\\partial \\beta_0} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{\\exp(z_i)}{1+\\exp(z_i)} - y_i \\right] = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(z_i) - y_i)\n$$\n$$\n\\frac{\\partial f}{\\partial \\beta_j} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{\\exp(z_i)x_{ij}}{1+\\exp(z_i)} - y_i x_{ij} \\right] = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(z_i) - y_i)x_{ij}\n$$\nWhen $\\boldsymbol{\\beta} = \\boldsymbol{0}$, we have $z_i = \\beta_0$. The first optimality condition determines the value of the intercept, $\\hat{\\beta}_0$:\n$$\n\\frac{\\partial f}{\\partial \\beta_0}\\Big|_{(\\hat{\\beta}_0, \\boldsymbol{0})} = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\hat{\\beta}_0) - y_i) = 0 \\implies n\\sigma(\\hat{\\beta}_0) = \\sum_{i=1}^n y_i\n$$\nThis gives $\\sigma(\\hat{\\beta}_0) = \\frac{1}{n}\\sum_{i=1}^n y_i = \\bar{y}$. This is the maximum-likelihood estimate for the intercept when all feature coefficients are zero.\n\nNow, we use this result in the second optimality condition. The gradient with respect to $\\boldsymbol{\\beta}$ evaluated at $(\\hat{\\beta}_0, \\boldsymbol{0})$ has components:\n$$\n\\frac{\\partial f}{\\partial \\beta_j}\\Big|_{(\\hat{\\beta}_0, \\boldsymbol{0})} = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\hat{\\beta}_0) - y_i)x_{ij} = \\frac{1}{n} \\sum_{i=1}^n (\\bar{y} - y_i)x_{ij}\n$$\nThe subgradient of the $\\ell_1$ norm at $\\boldsymbol{\\beta} = \\boldsymbol{0}$ is the set $[-1, 1]^p$. The second condition for the $j$-th component is:\n$$\n0 \\in \\frac{\\partial f}{\\partial \\beta_j}\\Big|_{(\\hat{\\beta}_0, \\boldsymbol{0})} + \\lambda [-1, 1] \\implies -\\frac{\\partial f}{\\partial \\beta_j}\\Big|_{(\\hat{\\beta}_0, \\boldsymbol{0})} \\in \\lambda [-1, 1]\n$$\nThis is equivalent to the inequality:\n$$\n\\left| \\frac{\\partial f}{\\partial \\beta_j}\\Big|_{(\\hat{\\beta}_0, \\boldsymbol{0})} \\right| \\leq \\lambda \\implies \\left| \\frac{1}{n} \\sum_{i=1}^n (\\bar{y} - y_i)x_{ij} \\right| \\leq \\lambda\n$$\nFor $\\boldsymbol{\\beta} = \\boldsymbol{0}$ to be an optimal solution, this inequality must hold for all $j=1, \\dots, p$. Thus, $\\lambda$ must be greater than or equal to the maximum of these absolute values. The smallest value of $\\lambda$ that ensures this is $\\lambda_{\\max}$, where the inequality is tight for at least one $j$:\n$$\n\\lambda_{\\max} = \\max_{j \\in \\{1,\\dots,p\\}} \\left| \\frac{1}{n} \\sum_{i=1}^n (y_i - \\bar{y})x_{ij} \\right|\n$$\nThe problem states that the features are centered, meaning $\\frac{1}{n}\\sum_{i=1}^n x_{ij} = 0$ for each feature $j$. This simplifies the expression:\n$$\n\\frac{1}{n} \\sum_{i=1}^n (y_i - \\bar{y})x_{ij} = \\frac{1}{n} \\left( \\sum_{i=1}^n y_i x_{ij} - \\bar{y} \\sum_{i=1}^n x_{ij} \\right) = \\frac{1}{n} \\left( \\sum_{i=1}^n y_i x_{ij} - \\bar{y} \\cdot 0 \\right) = \\frac{1}{n} \\sum_{i=1}^n y_i x_{ij}\n$$\nTherefore, the final formula for $\\lambda_{\\max}$ is:\n$$\n\\lambda_{\\max} = \\max_{j \\in \\{1,\\dots,p\\}} \\left| \\frac{1}{n} \\sum_{i=1}^n y_i x_{ij} \\right|\n$$\n\n### 3) Computation of $\\lambda_{\\max}$\n\nWe apply the derived formula to the given data.\n- Sample size: $n=8$.\n- Labels: $y \\in [1, 0, 1, 0, 0, 1, 0, 1]$.\n- Feature 1 (GLCM): $x_1 \\in [1.2, -0.8, 0.5, -1.0, -0.4, 0.9, -0.6, 0.2]$.\n- Feature 2 (Sphericity): $x_2 \\in [-0.5, 1.1, -1.3, 0.7, 0.4, -0.9, 1.5, -1.0]$.\n\nThe indices $i$ for which $y_i=1$ are $\\{1, 3, 6, 8\\}$. We only need to sum the feature values at these indices.\n\nFor feature $j=1$ (GLCM):\n$$\nC_1 = \\frac{1}{n} \\sum_{i=1}^n y_i x_{i1} = \\frac{1}{8} (x_{1,1} + x_{3,1} + x_{6,1} + x_{8,1})\n$$\n$$\nC_1 = \\frac{1}{8} (1.2 + 0.5 + 0.9 + 0.2) = \\frac{1}{8} (2.8) = 0.35\n$$\n\nFor feature $j=2$ (Sphericity):\n$$\nC_2 = \\frac{1}{n} \\sum_{i=1}^n y_i x_{i2} = \\frac{1}{8} (x_{1,2} + x_{3,2} + x_{6,2} + x_{8,2})\n$$\n$$\nC_2 = \\frac{1}{8} (-0.5 + (-1.3) + (-0.9) + (-1.0)) = \\frac{1}{8} (-3.7) = -0.4625\n$$\n\nFinally, $\\lambda_{\\max}$ is the maximum of the absolute values of these correlations:\n$$\n\\lambda_{\\max} = \\max(|C_1|, |C_2|) = \\max(|0.35|, |-0.4625|) = \\max(0.35, 0.4625)\n$$\n$$\n\\lambda_{\\max} = 0.4625\n$$\nThis value has four significant figures as required.\n\n### 4) Conceptual Explanation\n\nSparsity from $\\ell_1$ regularization produces simpler explanations in radiomics by performing automatic feature selection, forcing the coefficients of less relevant features to become exactly zero. An explanation based on a small subset of features is more interpretable and clinically actionable than a complex model involving dozens of variables. However, if features are highly collinear (e.g., different texture features capturing similar information), LASSO may arbitrarily select one feature over others, making the selection unstable; small perturbations in the data could lead to a different feature being chosen, undermining the reliability of the explanation.", "answer": "$$\\boxed{0.4625}$$", "id": "4538105"}, {"introduction": "Beyond understanding a model's general behavior, we often want to explain a single prediction. Counterfactual explanations provide an intuitive answer by identifying the minimal change to an input that would alter the model's decision. This practice [@problem_id:4538076] challenges you to formulate and solve this \"what-if\" scenario as a constrained optimization problem, providing a concrete, actionable explanation for a linear radiomics classifier.", "problem": "A radiomics classifier for lung nodules uses a linear decision function with sign output, mapping a feature vector $x \\in \\mathbb{R}^{4}$ (mean intensity in Hounsfield units, gray-level co-occurrence matrix contrast, sphericity, and wavelet energy) to a score $f(x) = w^{\\top}x + b$. A negative score indicates predicted benign and a positive score indicates predicted malignant. According to the principles of explainable artificial intelligence (XAI), an actionable counterfactual explanation seeks the smallest change $\\delta$ to the current case $x$ that flips the sign of $f(x)$ while respecting clinically plausible bounds on feature changes. Assume the following are valid foundational facts: a linear decision rule is determined by a separating hyperplane, the $L_2$-distance to a hyperplane is well-defined, and convex quadratic programs with linear constraints have unique global minima when feasible.\n\nYou are given $w = (0.8,\\,-0.5,\\,0.2,\\,0.1)^{\\top}$, $b = -50$, and the current patient’s features $x = (60,\\,1.5,\\,0.6,\\,2.0)^{\\top}$. For an actionable counterfactual, only bounded adjustments to features are allowed to reflect clinically plausible post-processing: the mean intensity can be adjusted by at most $\\pm 5$ Hounsfield units, the gray-level co-occurrence matrix contrast by at most $\\pm 0.5$, the sphericity by at most $\\pm 0.05$, and the wavelet energy is immutable. Formally, the perturbation $\\delta \\in \\mathbb{R}^{4}$ must satisfy the bound constraints $\\delta_{1} \\in [-5,\\,5]$, $\\delta_{2} \\in [-0.5,\\,0.5]$, $\\delta_{3} \\in [-0.05,\\,0.05]$, and $\\delta_{4} = 0$.\n\nStarting from these principles and definitions, derive from first principles and solve the optimization problem that seeks the minimal $L_2$-norm perturbation $\\delta$ that flips the sign of the decision function, that is, minimizes $\\|\\delta\\|_{2}$ subject to $w^{\\top}(x+\\delta) + b \\ge 0$ and the given bounds. Because the minimal $L_2$-norm counterfactual occurs on the decision boundary when feasible, you may impose $w^{\\top}(x+\\delta) + b = 0$ in your derivation.\n\nWhat is the value of the minimal $L_2$-norm $\\|\\delta\\|_{2}$? Round your answer to four significant figures.", "solution": "The problem asks for the minimal $L_2$-norm of a perturbation vector $\\delta$ that alters the prediction of a linear classifier, subject to certain constraints on the components of $\\delta$. This is a classic problem of finding an actionable counterfactual explanation, which can be formulated as a constrained optimization problem.\n\nFirst, we establish the mathematical formulation of the problem from the provided information.\nThe decision function is given by $f(x) = w^{\\top}x + b$, where $x \\in \\mathbb{R}^{4}$ is the feature vector, $w \\in \\mathbb{R}^{4}$ is the weight vector, and $b \\in \\mathbb{R}$ is the bias.\nThe specific values are:\n$w = (0.8,\\, -0.5,\\, 0.2,\\, 0.1)^{\\top}$\n$b = -50$\n$x = (60,\\, 1.5,\\, 0.6,\\, 2.0)^{\\top}$\n\nThe initial score for the patient is:\n$$f(x) = w^{\\top}x + b = (0.8)(60) + (-0.5)(1.5) + (0.2)(0.6) + (0.1)(2.0) - 50$$\n$$f(x) = 48 - 0.75 + 0.12 + 0.2 - 50 = 47.57 - 50 = -2.43$$\nSince $f(x)  0$, the initial prediction is \"benign\".\n\nWe seek a perturbation $\\delta = (\\delta_1, \\delta_2, \\delta_3, \\delta_4)^{\\top}$ that flips the prediction. The problem states that the minimal $L_2$-norm counterfactual will lie on the decision boundary, so the target condition is $f(x+\\delta) = 0$.\n$$w^{\\top}(x+\\delta) + b = 0$$\n$$w^{\\top}x + b + w^{\\top}\\delta = 0$$\nSubstituting the value of $f(x) = w^{\\top}x + b = -2.43$, we get:\n$$-2.43 + w^{\\top}\\delta = 0 \\implies w^{\\top}\\delta = 2.43$$\nThe perturbation vector $\\delta$ is subject to bound constraints:\n$\\delta_1 \\in [-5, 5]$\n$\\delta_2 \\in [-0.5, 0.5]$\n$\\delta_3 \\in [-0.05, 0.05]$\n$\\delta_4 = 0$\n\nSubstituting the components of $w$ and the constraint $\\delta_4=0$ into the equality constraint:\n$$0.8\\delta_1 - 0.5\\delta_2 + 0.2\\delta_3 + (0.1)(0) = 2.43$$\n$$0.8\\delta_1 - 0.5\\delta_2 + 0.2\\delta_3 = 2.43$$\n\nThe objective is to minimize the $L_2$-norm of $\\delta$, which is $\\|\\delta\\|_2 = \\sqrt{\\delta_1^2 + \\delta_2^2 + \\delta_3^2 + \\delta_4^2}$. Minimizing $\\|\\delta\\|_2$ is equivalent to minimizing its square, $\\|\\delta\\|_2^2$. Given $\\delta_4=0$, the objective function is to minimize $\\delta_1^2 + \\delta_2^2 + \\delta_3^2$.\n\nThe complete optimization problem is:\n$$ \\text{minimize} \\quad F(\\delta) = \\delta_1^2 + \\delta_2^2 + \\delta_3^2 $$\n$$ \\text{subject to:} $$\n$$ 0.8\\delta_1 - 0.5\\delta_2 + 0.2\\delta_3 = 2.43 $$\n$$ -5 \\le \\delta_1 \\le 5 $$\n$$ -0.5 \\le \\delta_2 \\le 0.5 $$\n$$ -0.05 \\le \\delta_3 \\le 0.05 $$\nThis is a convex Quadratic Program (QP), which has a unique global minimum. We can solve this using the Karush-Kuhn-Tucker (KKT) conditions.\n\nFirst, let's solve the problem without the box constraints, using the method of Lagrange multipliers, to see if the unconstrained solution is feasible.\nThe Lagrangian is $\\mathcal{L}(\\delta_1, \\delta_2, \\delta_3, \\lambda) = \\delta_1^2 + \\delta_2^2 + \\delta_3^2 - \\lambda(0.8\\delta_1 - 0.5\\delta_2 + 0.2\\delta_3 - 2.43)$.\nSetting the gradients with respect to $\\delta_i$ to zero:\n$$ \\frac{\\partial\\mathcal{L}}{\\partial\\delta_1} = 2\\delta_1 - 0.8\\lambda = 0 \\implies \\delta_1 = 0.4\\lambda $$\n$$ \\frac{\\partial\\mathcal{L}}{\\partial\\delta_2} = 2\\delta_2 + 0.5\\lambda = 0 \\implies \\delta_2 = -0.25\\lambda $$\n$$ \\frac{\\partial\\mathcal{L}}{\\partial\\delta_3} = 2\\delta_3 - 0.2\\lambda = 0 \\implies \\delta_3 = 0.1\\lambda $$\nSubstituting these into the equality constraint:\n$$ 0.8(0.4\\lambda) - 0.5(-0.25\\lambda) + 0.2(0.1\\lambda) = 2.43 $$\n$$ 0.32\\lambda + 0.125\\lambda + 0.02\\lambda = 2.43 $$\n$$ 0.465\\lambda = 2.43 \\implies \\lambda = \\frac{2.43}{0.465} \\approx 5.2258 $$\nThis gives the unconstrained solution:\n$$ \\delta_1 = 0.4 \\times 5.2258... \\approx 2.0903 $$\n$$ \\delta_2 = -0.25 \\times 5.2258... \\approx -1.3065 $$\n$$ \\delta_3 = 0.1 \\times 5.2258... \\approx 0.5226 $$\nChecking the box constraints:\n- $\\delta_1 \\approx 2.0903 \\in [-5, 5]$ (satisfied)\n- $\\delta_2 \\approx -1.3065 \\notin [-0.5, 0.5]$ (violated)\n- $\\delta_3 \\approx 0.5226 \\notin [-0.05, 0.05]$ (violated)\n\nThe unconstrained solution is not feasible. This indicates that the optimal solution must lie on the boundary defined by the box constraints. The violations suggest that $\\delta_2$ should be at its lower bound and $\\delta_3$ at its upper bound. Let's hypothesize that the optimal solution has $\\delta_2 = -0.5$ and $\\delta_3 = 0.05$.\n\nWe now solve for $\\delta_1$ using the equality constraint with these fixed values:\n$$ 0.8\\delta_1 - 0.5(-0.5) + 0.2(0.05) = 2.43 $$\n$$ 0.8\\delta_1 + 0.25 + 0.01 = 2.43 $$\n$$ 0.8\\delta_1 = 2.43 - 0.26 = 2.17 $$\n$$ \\delta_1 = \\frac{2.17}{0.8} = 2.7125 $$\nThis value for $\\delta_1$ is within its bounds $[-5, 5]$.\nSo, we have a candidate optimal solution $\\delta^* = (2.7125, -0.5, 0.05, 0)^{\\top}$.\n\nTo confirm this is the optimum, we verify the full KKT conditions. The stationarity condition for this QP is $\\delta = \\lambda w - \\mu + \\nu$, where $\\mu$ and $\\nu$ are the vectors of Lagrange multipliers for the upper and lower bounds, respectively.\n- For $\\delta_1 = 2.7125$, it is not at a bound, so its multipliers are zero. Thus, $\\delta_1 = \\lambda w_1$.\n$2.7125 = \\lambda(0.8) \\implies \\lambda = \\frac{2.7125}{0.8} = 3.390625$. Wait... this is not the right approach for verification. A different formulation of the Lagrangian may have a different sign for $\\lambda$. The rigorous approach follows.\n\nThe Lagrangian with multipliers for the active constraints is:\n$\\mathcal{L} = (\\delta_1^2 + \\delta_2^2 + \\delta_3^2) + \\lambda_0(0.8\\delta_1 - 0.5\\delta_2 + 0.2\\delta_3 - 2.43) + \\lambda_1(-\\delta_2 - 0.5) + \\lambda_2(\\delta_3 - 0.05)$\nwith $\\lambda_1, \\lambda_2 \\ge 0$.\nThe stationarity conditions are $\\nabla L = 0$:\n$$ \\frac{\\partial\\mathcal{L}}{\\partial\\delta_1}: 2\\delta_1 + 0.8\\lambda_0 = 0 $$\n$$ \\frac{\\partial\\mathcal{L}}{\\partial\\delta_2}: 2\\delta_2 - 0.5\\lambda_0 - \\lambda_1 = 0 $$\n$$ \\frac{\\partial\\mathcal{L}}{\\partial\\delta_3}: 2\\delta_3 + 0.2\\lambda_0 + \\lambda_2 = 0 $$\nSubstitute $\\delta_1 = 2.7125$ into the first equation:\n$$ 2(2.7125) + 0.8\\lambda_0 = 0 \\implies 5.425 = -0.8\\lambda_0 \\implies \\lambda_0 = -\\frac{5.425}{0.8} = -6.78125 $$\nSubstitute $\\delta_2 = -0.5$ and $\\lambda_0 = -6.78125$ into the second equation to find $\\lambda_1$:\n$$ 2(-0.5) - 0.5(-6.78125) - \\lambda_1 = 0 $$\n$$ -1 + 3.390625 - \\lambda_1 = 0 \\implies \\lambda_1 = 2.390625 $$\nSince $\\lambda_1 \\ge 0$, this condition is satisfied.\nSubstitute $\\delta_3 = 0.05$ and $\\lambda_0 = -6.78125$ into the third equation to find $\\lambda_2$:\n$$ 2(0.05) + 0.2(-6.78125) + \\lambda_2 = 0 $$\n$$ 0.1 - 1.35625 + \\lambda_2 = 0 \\implies \\lambda_2 = 1.25625 $$\nSince $\\lambda_2 \\ge 0$, this condition is also satisfied.\n\nAll KKT conditions (primal feasibility, dual feasibility, complementary slackness, and stationarity) are met. Thus, the solution $\\delta^* = (2.7125, -0.5, 0.05, 0)^{\\top}$ is indeed the unique global minimum.\n\nFinally, we calculate the minimal $L_2$-norm, $\\|\\delta\\|_{2}$:\n$$ \\|\\delta\\|_{2} = \\sqrt{\\delta_1^2 + \\delta_2^2 + \\delta_3^2 + \\delta_4^2} $$\n$$ \\|\\delta\\|_{2} = \\sqrt{(2.7125)^2 + (-0.5)^2 + (0.05)^2 + 0^2} $$\n$$ \\|\\delta\\|_{2} = \\sqrt{7.35765625 + 0.25 + 0.0025} $$\n$$ \\|\\delta\\|_{2} = \\sqrt{7.61015625} $$\n$$ \\|\\delta\\|_{2} \\approx 2.758651138 $$\nRounding to four significant figures, we get:\n$$ \\|\\delta\\|_{2} \\approx 2.759 $$", "answer": "$$ \\boxed{2.759} $$", "id": "4538076"}, {"introduction": "For complex models like Convolutional Neural Networks, saliency maps help us visualize what parts of an image the model focuses on. This exercise [@problem_id:4538134] explores the mechanics of Grad-CAM, a widely used technique, by deconstructing its components in a simplified clinical scenario. You will discover how a seemingly minor detail—the ReLU activation—can fundamentally alter the explanation by concealing evidence that argues against a prediction, highlighting the importance of critically evaluating the tools we use.", "problem": "A deep radiomics classifier is trained to predict malignancy from computed tomography (CT) patches using a convolutional neural network whose final convolutional layer outputs feature maps $\\{A_k\\}_{k=1}^{K}$ on a spatial grid of $P$ locations. The downstream classifier is linear in the global average pooled features: for class $c$ with logit $y^c$, the model is $y^c = \\sum_{k=1}^{K} w_k \\, \\overline{A_k} + b$, where $\\overline{A_k} = \\frac{1}{P}\\sum_{i=1}^{P} A_k(i)$ is the spatial average of $A_k$. By definition, the gradient $\\frac{\\partial y^c}{\\partial A_k(i)}$ indicates the local sensitivity of the class score to a small change in $A_k(i)$; a negative gradient means that increasing $A_k(i)$ would decrease $y^c$. Gradient-weighted Class Activation Mapping (Grad-CAM) computes channel weights $\\alpha_k^c = \\frac{1}{P} \\sum_{i=1}^{P} \\frac{\\partial y^c}{\\partial A_k(i)}$ and a class activation map $L^c = \\mathrm{ReLU}\\!\\left(\\sum_{k=1}^{K} \\alpha_k^c A_k \\right)$, where $\\mathrm{ReLU}(x) = \\max(x,0)$.\n\nConsider a single test CT patch where two clinically interpretable channels dominate the final convolutional layer: $A_1$ highlights a spiculated lesion core (commonly associated with malignancy), and $A_2$ highlights a perilesional fat rim (commonly associated with benignity, that is, protection against malignancy). Suppose $K = 2$, $P = 10$, $w_1 = +2$, $w_2 = -1$, and $b$ is arbitrary. Assume $A_1(i) = 1$ on exactly $5$ locations corresponding to the lesion core and $A_1(i) = 0$ elsewhere; $A_2(i) = 1$ on the complementary $5$ locations corresponding to the fat rim and $A_2(i) = 0$ elsewhere. All other channels are absent. Using only the definitions above and standard properties of gradients and the Rectified Linear Unit (ReLU), reason about how Grad-CAM treats positive versus negative evidence in this setting.\n\nWhich of the following statements are correct?\n\nA. In this setup, $\\frac{\\partial y^c}{\\partial A_2(i)}$ is negative and contributes a negative term to $\\sum_{k} \\alpha_k^c A_k$ on the fat rim; applying $\\mathrm{ReLU}$ sets these negative values to $0$, thereby suppressing a clinically protective region. A signed visualization without $\\mathrm{ReLU}$ (for example, using a diverging colormap) or separate maps for positive versus negative contributions would reveal both risk and protection.\n\nB. Removing $\\mathrm{ReLU}$ can only change the overall scale of the heatmap but not which pixels are highlighted; therefore the effect of $\\mathrm{ReLU}$ on interpretability is negligible in this example.\n\nC. Negative gradients in $\\frac{\\partial y^c}{\\partial A_k(i)}$ should be treated as spurious because $A_k(i) \\ge 0$ after upstream activations; hence clipping them with $\\mathrm{ReLU}$ is necessary to avoid misleading maps.\n\nD. A symmetric alternative to $\\mathrm{ReLU}$ is to decompose the map into $L^c_{+} = \\sum_{k} \\max(\\alpha_k^c, 0) \\, A_k$ and $L^c_{-} = \\sum_{k} \\max(-\\alpha_k^c, 0) \\, A_k$, enabling clinicians to view evidence for ($L^c_{+}$) and against ($L^c_{-}$) the class separately.\n\nE. Replacing $\\mathrm{ReLU}$ by an absolute value map, $| \\sum_{k} \\alpha_k^c A_k |$, preserves the clinically protective information while still producing a nonnegative heatmap, making it equivalent in interpretability to a signed visualization.", "solution": "### Problem Validation\n\n**Step 1: Extract Givens**\n- A deep radiomics classifier using a convolutional neural network (CNN).\n- The final convolutional layer produces feature maps $\\{A_k\\}_{k=1}^{K}$ on a spatial grid of $P$ locations.\n- The downstream classifier logit for class $c$ is given by $y^c = \\sum_{k=1}^{K} w_k \\, \\overline{A_k} + b$.\n- Global Average Pooling (GAP) is defined as $\\overline{A_k} = \\frac{1}{P}\\sum_{i=1}^{P} A_k(i)$.\n- Gradient-weighted Class Activation Mapping (Grad-CAM) definitions:\n    - Channel weights: $\\alpha_k^c = \\frac{1}{P} \\sum_{i=1}^{P} \\frac{\\partial y^c}{\\partial A_k(i)}$.\n    - Class activation map: $L^c = \\mathrm{ReLU}\\!\\left(\\sum_{k=1}^{K} \\alpha_k^c A_k \\right)$.\n    - Rectified Linear Unit (ReLU): $\\mathrm{ReLU}(x) = \\max(x,0)$.\n- Specific parameters for the problem instance:\n    - Number of channels, $K = 2$.\n    - Number of spatial locations, $P = 10$.\n    - Classifier weights, $w_1 = +2$ and $w_2 = -1$.\n    - Bias term $b$ is arbitrary.\n- Feature map specifications:\n    - $A_1$ (lesion core, malignancy-associated): $A_1(i) = 1$ on exactly $5$ locations, $A_1(i) = 0$ on the other $5$.\n    - $A_2$ (perilesional fat rim, benignity-associated): $A_2(i) = 1$ on the $5$ locations where $A_1(i)=0$, and $A_2(i) = 0$ where $A_1(i)=1$.\n    - All other channels $A_k$ for $k  2$ are absent (i.e., $A_k = 0$).\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is scientifically grounded, well-posed, and objective. It describes a standard, albeit simplified, architecture (CNN with a GAP layer) and a canonical explainable AI method (Grad-CAM). All variables and functions are explicitly defined, and the provided numerical values and conditions are self-consistent and sufficient to derive a unique solution. The clinical scenario is a realistic simplification used to probe the conceptual behavior of the XAI method. The problem does not violate any fundamental principles, is not ambiguous, and presents a non-trivial conceptual challenge.\n\n**Step 3: Verdict and Action**\nThe problem statement is **valid**. We may proceed to the solution.\n\n###\n### Derivation of the Grad-CAM Map\n\nFirst, we must compute the necessary components of the Grad-CAM map $L^c$ based on the provided definitions. The class of interest $c$ corresponds to malignancy.\n\n**1. Compute the Gradients**\nThe logit for the class $c$ is given by $y^c = \\sum_{k=1}^{K} w_k \\, \\overline{A_k} + b$. With $K=2$, this is:\n$$ y^c = w_1 \\overline{A_1} + w_2 \\overline{A_2} + b $$\nSubstituting the definition of the GAP, $\\overline{A_k} = \\frac{1}{P}\\sum_{j=1}^{P} A_k(j)$:\n$$ y^c = w_1 \\left(\\frac{1}{P}\\sum_{j=1}^{P} A_1(j)\\right) + w_2 \\left(\\frac{1}{P}\\sum_{j=1}^{P} A_2(j)\\right) + b $$\nWe take the partial derivative of $y^c$ with respect to the activation $A_k(i)$ at a single spatial location $i$ for each channel $k$:\nFor channel $k=1$:\n$$ \\frac{\\partial y^c}{\\partial A_1(i)} = \\frac{\\partial}{\\partial A_1(i)} \\left( \\frac{w_1}{P}\\sum_{j=1}^{P} A_1(j) \\right) = \\frac{w_1}{P} $$\nFor channel $k=2$:\n$$ \\frac{\\partial y^c}{\\partial A_2(i)} = \\frac{\\partial}{\\partial A_2(i)} \\left( \\frac{w_2}{P}\\sum_{j=1}^{P} A_2(j) \\right) = \\frac{w_2}{P} $$\nNote that for this specific architecture (linear classifier on top of GAP), the gradient $\\frac{\\partial y^c}{\\partial A_k(i)}$ is constant over all spatial locations $i$. Using the given values $w_1 = 2$, $w_2 = -1$, and $P = 10$:\n$$ \\frac{\\partial y^c}{\\partial A_1(i)} = \\frac{2}{10} = 0.2 $$\n$$ \\frac{\\partial y^c}{\\partial A_2(i)} = \\frac{-1}{10} = -0.1 $$\nThe gradient for channel $1$ is positive, indicating its contribution to the malignancy score, while the gradient for channel $2$ is negative, indicating evidence against malignancy.\n\n**2. Compute the Grad-CAM Channel Weights**\nThe channel weights $\\alpha_k^c$ are defined as the average of the gradients over the spatial locations:\n$$ \\alpha_k^c = \\frac{1}{P} \\sum_{i=1}^{P} \\frac{\\partial y^c}{\\partial A_k(i)} $$\nSince the gradients are constant for each channel:\n$$ \\alpha_1^c = \\frac{1}{10} \\sum_{i=1}^{10} (0.2) = \\frac{1}{10} (10 \\times 0.2) = 0.2 $$\n$$ \\alpha_2^c = \\frac{1}{10} \\sum_{i=1}^{10} (-0.1) = \\frac{1}{10} (10 \\times -0.1) = -0.1 $$\n\n**3. Compute the Linear Combination of Feature Maps**\nThe pre-ReLU activation map is the weighted sum $\\sum_{k=1}^{K} \\alpha_k^c A_k$. With $K=2$:\n$$ S^c = \\alpha_1^c A_1 + \\alpha_2^c A_2 = (0.2)A_1 + (-0.1)A_2 $$\nLet's evaluate this map $S^c$ at the different spatial locations. Let the set of $5$ locations for the lesion core be $R_{core}$ and the set of the other $5$ locations for the fat rim be $R_{rim}$.\n- For any location $i \\in R_{core}$: $A_1(i)=1$ and $A_2(i)=0$.\n  $$ S^c(i) = (0.2)(1) + (-0.1)(0) = 0.2 $$\n- For any location $i \\in R_{rim}$: $A_1(i)=0$ and $A_2(i)=1$.\n  $$ S^c(i) = (0.2)(0) + (-0.1)(1) = -0.1 $$\n\n**4. Apply the ReLU to Obtain the Final Grad-CAM Map**\nThe final Grad-CAM map is $L^c = \\mathrm{ReLU}(S^c)$.\n- For any location $i \\in R_{core}$:\n  $$ L^c(i) = \\mathrm{ReLU}(0.2) = \\max(0.2, 0) = 0.2 $$\n- For any location $i \\in R_{rim}$:\n  $$ L^c(i) = \\mathrm{ReLU}(-0.1) = \\max(-0.1, 0) = 0 $$\nThe resulting Grad-CAM map highlights the lesion core (positive evidence for malignancy) but assigns a value of zero to the perilesional fat rim, completely suppressing the visualization of this region which provides negative evidence (i.e., is protective).\n\n### Option-by-Option Analysis\n\n**A. In this setup, $\\frac{\\partial y^c}{\\partial A_2(i)}$ is negative and contributes a negative term to $\\sum_{k} \\alpha_k^c A_k$ on the fat rim; applying $\\mathrm{ReLU}$ sets these negative values to $0$, thereby suppressing a clinically protective region. A signed visualization without $\\mathrm{ReLU}$ (for example, using a diverging colormap) or separate maps for positive versus negative contributions would reveal both risk and protection.**\nThis statement is a precise summary of our derivation. The gradient for channel $2$ is $\\frac{\\partial y^c}{\\partial A_2(i)} = -0.1$, which is negative. On the fat rim, this leads to a pre-ReLU map value of $-0.1$. The $\\mathrm{ReLU}$ function maps this to $0$, suppressing this region from the final heatmap. The fat rim is described as clinically protective, so its suppression is a loss of important explanatory information. A signed map (valuing $0.2$ on the core and $-0.1$ on the rim) would indeed visualize both the risk-contributing and protective regions.\n**Verdict:** Correct.\n\n**B. Removing $\\mathrm{ReLU}$ can only change the overall scale of the heatmap but not which pixels are highlighted; therefore the effect of $\\mathrm{ReLU}$ on interpretability is negligible in this example.**\nThis is incorrect. Without $\\mathrm{ReLU}$, the map has non-zero values on all $10$ locations ($0.2$ on the core, $-0.1$ on the rim). With $\\mathrm{ReLU}$, the map has non-zero values only on the $5$ locations of the core. The set of highlighted pixels fundamentally changes. The effect on interpretability is not negligible; it is critical, as it determines whether the evidence against malignancy is visualized.\n**Verdict:** Incorrect.\n\n**C. Negative gradients in $\\frac{\\partial y^c}{\\partial A_k(i)}$ should be treated as spurious because $A_k(i) \\ge 0$ after upstream activations; hence clipping them with $\\mathrm{ReLU}$ is necessary to avoid misleading maps.**\nThis statement presents a flawed argument. A negative gradient $\\frac{\\partial y^c}{\\partial A_k(i)}$ means that an increase in feature $A_k(i)$ leads to a decrease in the class score $y^c$. This is the definition of counter-evidence. In our example, the feature $A_2$ (fat rim) has a negative weight $w_2=-1$, representing its protective nature. The resulting negative gradient is therefore not spurious but a core part of the model's logic. Clipping this information with $\\mathrm{ReLU}$ does not avoid a misleading map; it creates one by presenting an incomplete picture of the model's reasoning.\n**Verdict:** Incorrect.\n\n**D. A symmetric alternative to $\\mathrm{ReLU}$ is to decompose the map into $L^c_{+} = \\sum_{k} \\max(\\alpha_k^c, 0) \\, A_k$ and $L^c_{-} = \\sum_{k} \\max(-\\alpha_k^c, 0) \\, A_k$, enabling clinicians to view evidence for ($L^c_{+}$) and against ($L^c_{-}$) the class separately.**\nLet's analyze this proposed decomposition.\nWe have $\\alpha_1^c = 0.2$ and $\\alpha_2^c = -0.1$.\nFor the positive evidence map $L^c_{+}$:\n$$ L^c_{+} = \\max(0.2, 0)A_1 + \\max(-0.1, 0)A_2 = 0.2 A_1 + 0 \\cdot A_2 = 0.2 A_1 $$\nThis map highlights the lesion core, which is the evidence *for* malignancy.\nFor the negative evidence map $L^c_{-}$:\n$$ L^c_{-} = \\max(-0.2, 0)A_1 + \\max(-(-0.1), 0)A_2 = 0 \\cdot A_1 + \\max(0.1, 0)A_2 = 0.1 A_2 $$\nThis map highlights the fat rim, which is the evidence *against* malignancy. This decomposition method successfully separates the two types of evidence into distinct, interpretable maps.\n**Verdict:** Correct.\n\n**E. Replacing $\\mathrm{ReLU}$ by an absolute value map, $| \\sum_{k} \\alpha_k^c A_k |$, preserves the clinically protective information while still producing a nonnegative heatmap, making it equivalent in interpretability to a signed visualization.**\nThe proposed map is $|S^c| = |(0.2)A_1 - (0.1)A_2|$.\n- On the core ($R_{core}$), the value is $|0.2| = 0.2$.\n- On the rim ($R_{rim}$), the value is $|-0.1| = 0.1$.\nThis map does highlight both regions. However, it is not \"equivalent in interpretability to a signed visualization.\" A signed visualization would use different colors or signifiers to distinguish positive contributions from negative ones. The absolute value map highlights both regions with positive values, confounding the evidence for malignancy with the evidence against it. A user cannot distinguish the meaning of the highlighted regions from the map alone.\n**Verdict:** Incorrect.", "answer": "$$\\boxed{AD}$$", "id": "4538134"}]}