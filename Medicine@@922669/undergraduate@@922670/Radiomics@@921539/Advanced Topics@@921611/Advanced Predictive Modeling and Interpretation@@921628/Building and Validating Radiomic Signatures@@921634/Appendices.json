{"hands_on_practices": [{"introduction": "Before we can analyze texture, the continuous intensity values in a medical image must be grouped into a finite number of discrete grey levels, a process known as discretization or binning. This exercise will guide you through the fundamental choice of bin width, a critical hyperparameter in any radiomics study. By calculating the number of resulting grey levels and considering its effect on a texture feature like entropy, you will gain insight into the crucial trade-off between capturing fine textural detail and ensuring feature stability across different scanners and datasets [@problem_id:4531368].", "problem": "In the context of building and validating radiomic signatures, intensity discretization is a common preprocessing step that maps continuous voxel intensities to discrete grey levels prior to computing texture features such as those based on the Grey Level Co-occurrence Matrix (GLCM). Consider a Computed Tomography (CT) Region of Interest (ROI) whose Hounsfield unit intensities span from $-100$ to $400$. Using a fixed bin width discretization of size $25$ based on the ROIâ€™s minimum and maximum intensities, determine the total number of discrete grey levels produced by this discretization. Then, starting from the definition of GLCM entropy as a measure of uncertainty in the normalized co-occurrence probabilities over discretized grey levels, explain how the choice of bin width influences the magnitude and stability of the entropy feature, and how this impacts the construction and validation of radiomic signatures across datasets and scanners. Report the number of bins as an integer; no rounding is required.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, objective, and self-contained, and is therefore deemed valid. The solution proceeds with two parts: a quantitative calculation and a qualitative explanation based on established principles of radiomics.\n\n**Part 1: Calculation of the Number of Discrete Grey Levels**\n\nThe problem requires determining the number of discrete grey levels resulting from a fixed bin width discretization of a given intensity range.\n\nThe given parameters are:\n- Minimum intensity of the Region of Interest (ROI), $I_{min} = -100$ Hounsfield Units (HU).\n- Maximum intensity of the ROI, $I_{max} = 400$ HU.\n- The fixed bin width, $W_b = 25$ HU.\n\nThe total range of intensities in the ROI is calculated as:\n$$R = I_{max} - I_{min} = 400 - (-100) = 500$$\n\nThe number of discrete grey levels, denoted as $N_g$, is the number of bins required to partition the entire intensity range $[I_{min}, I_{max}]$. A standard method for this calculation, consistent with implementations in radiomics software (e.g., PyRadiomics), maps an intensity $I$ to a discrete level $k$ using a formula such as $k = \\lfloor \\frac{I - I_{min}}{W_b} \\rfloor + 1$. To find the total number of levels, we can determine the level corresponding to the maximum intensity value, $I_{max}$. Note that this formula accounts for all values within the range, including the endpoints.\n\nThe maximum intensity $I_{max} = 400$ is mapped to the level:\n$$N_g = \\left\\lfloor \\frac{I_{max} - I_{min}}{W_b} \\right\\rfloor + 1$$\nSubstituting the given values:\n$$N_g = \\left\\lfloor \\frac{400 - (-100)}{25} \\right\\rfloor + 1 = \\left\\lfloor \\frac{500}{25} \\right\\rfloor + 1 = \\lfloor 20 \\rfloor + 1 = 20 + 1 = 21$$\nThis calculation implies that the discretization creates $21$ distinct bins or grey levels. For instance, the first bin would correspond to level $1$ and contain intensities in the interval $[-100, -75)$, while the value $I_{max}=400$ falls into the $21^{st}$ bin. Thus, the total number of discrete grey levels is $21$.\n\n**Part 2: Influence of Bin Width on GLCM Entropy and Signature Validation**\n\nThe second part of the problem requires an explanation of how the choice of bin width influences the Grey Level Co-occurrence Matrix (GLCM) entropy feature and the broader process of building and validating radiomic signatures.\n\nThe GLCM is a matrix that captures the spatial relationship between voxels with different grey levels. Let $N_g$ be the number of discrete grey levels determined by the bin width. The GLCM is an $N_g \\times N_g$ matrix where each element $C(i, j)$ is the number of times a voxel with grey level $i$ co-occurs with a voxel with grey level $j$ at a specific spatial offset (distance and direction). This matrix is typically normalized to obtain a probability matrix $P$, where $p(i, j) = \\frac{C(i, j)}{\\sum_{i,j} C(i, j)}$.\n\nThe GLCM entropy, a measure of textural complexity and randomness, is defined as:\n$$H = -\\sum_{i=1}^{N_g} \\sum_{j=1}^{N_g} p(i, j) \\ln(p(i, j))$$\nwhere the convention $0 \\ln(0) = 0$ is used. A higher entropy value corresponds to a more random or unpredictable texture, where the $p(i, j)$ values are more uniformly distributed. A lower entropy value indicates a more orderly or predictable texture, where probabilities are concentrated on a few $(i, j)$ pairs.\n\n**Influence on Entropy Magnitude and Stability:**\n\nThe bin width, $W_b$, is inversely related to the number of grey levels, $N_g$. This relationship is the primary mechanism through which $W_b$ affects entropy.\n\n1.  **Large Bin Width ($W_b \\uparrow \\implies N_g \\downarrow$):**\n    -   **Magnitude:** When the bin width is large, a wider range of continuous intensity values are mapped to the same discrete grey level. This acts as a smoothing or averaging filter on the image intensities. Fine textural details are lost. The resulting GLCM is smaller, and the co-occurrence probabilities tend to be concentrated in fewer cells. This less uniform distribution of probabilities leads to a **lower entropy value**. The texture is perceived as more homogeneous.\n    -   **Stability:** Features calculated with a large bin width are generally **more stable and reproducible**. Small fluctuations in voxel intensity due to imaging noise or scanner differences are less likely to shift a voxel's assigned grey level to an adjacent bin. This robustness makes the feature less sensitive to acquisition variations.\n\n2.  **Small Bin Width ($W_b \\downarrow \\implies N_g \\uparrow$):**\n    -   **Magnitude:** A small bin width preserves finer variations in voxel intensity, resulting in a larger number of discrete grey levels ($N_g$). The GLCM becomes larger and, for complex textures, sparser. The co-occurrence counts are distributed over a greater number of $(i,j)$ pairs. This typically leads to a more uniform probability distribution and thus a **higher entropy value**.\n    -   **Stability:** Features calculated with a small bin width are **less stable**. Minor changes in voxel intensity, such as those caused by noise, can easily push a voxel's intensity across a bin boundary, altering its grey level. This can cause significant changes in the GLCM and, consequently, large fluctuations in the calculated entropy. This makes the feature highly sensitive to the specific imaging system and protocol used.\n\n**Impact on Signature Construction and Validation:**\n\nA radiomic signature is a predictive model derived from a set of quantitative image features. The choice of bin width is a critical preprocessing step that fundamentally impacts the signature's performance and generalizability.\n\n1.  **Signature Construction:** The bin width choice represents a trade-off.\n    -   Using a small $W_b$ might produce features that are highly discriminative on the training data by capturing fine, dataset-specific texture patterns. However, this carries a high risk of **overfitting**, as the unstable features may be modeling noise rather than true biological signal.\n    -   Using a large $W_b$ creates more stable, robust features that are less prone to noise. This may lead to a model that is less discriminative but has better potential for **generalization**. It might, however, lead to **underfitting** if the binning is so coarse that it discards clinically relevant textural information.\n\n2.  **Signature Validation:** Validation, particularly external validation on data from different scanners or institutions, is essential for establishing the clinical utility of a radiomic signature.\n    -   **Standardization is critical:** For a signature to be validly tested, the exact same preprocessing pipeline, including the identical bin width ($W_b$), must be applied to the validation dataset. Comparing features or models derived using different bin widths is scientifically invalid, as they exist in fundamentally different feature spaces.\n    -   **Impact on Generalizability:** A signature built on unstable features (small $W_b$) is likely to perform poorly during external validation. The performance drop between internal and external validation will be significant because the features are not reproducible across different acquisition conditions. In contrast, a signature built on robust features (large $W_b$) has a higher probability of maintaining its predictive performance on external datasets, demonstrating its generalizability and potential for clinical translation.\n\nIn summary, the choice of bin width is a foundational decision in radiomics that balances the desire for feature-based discrimination against the necessity for feature stability and model robustness. This choice directly influences the calculated values of texture features like entropy and is a key determinant of whether a derived radiomic signature will be a reproducible and generalizable biomarker.", "answer": "$$\\boxed{21}$$", "id": "4531368"}, {"introduction": "Once an image's intensities are discretized, we can begin extracting features that quantify its texture. This practice delves into the mechanics of one of the most powerful tools for this purpose: the Grey Level Co-occurrence Matrix ($GLCM$). By manually constructing a $GLCM$ and computing the 'Contrast' feature for a small, simplified image region, you will demystify how these algorithms transform spatial relationships between voxels into meaningful quantitative descriptors [@problem_id:4531346].", "problem": "A single-modality computed tomography region-of-interest has been intensity-quantized into $16$ gray-level bins labeled $1$ through $16$. Consider the following $3 \\times 3$ in-plane slice of bin indices (one voxel thick in the out-of-plane direction), where the entry at row $y$ and column $x$ is the bin index at spatial location $(x,y)$:\n$$\n\\begin{pmatrix}\n1 & 2 & 3\\\\\n2 & 2 & 4\\\\\n3 & 4 & 5\n\\end{pmatrix}.\n$$\nUsing the gray-level co-occurrence matrix (GLCM) definition, construct a non-symmetric co-occurrence matrix for displacement $\\mathbf{d}_1=(1,0,0)$ by counting ordered pairs $(i,j)$ formed by in-bounds voxel pairs $\\big(I(x,y),\\,I(x+1,y)\\big)$ in voxel units. Then normalize to obtain the probability matrix $P_{\\mathbf{d}_1}(i,j)$ by dividing by the total number of such pairs. Repeat this procedure for displacement $\\mathbf{d}_2=(1,1,0)$, forming ordered pairs $\\big(I(x,y),\\,I(x+1,y+1)\\big)$ and normalizing to obtain $P_{\\mathbf{d}_2}(i,j)$. Using the standard definition of the GLCM contrast feature, compute the contrast for each displacement and report the ratio\n$$\nr \\;=\\; \\frac{C(\\mathbf{d}_2)}{C(\\mathbf{d}_1)}.\n$$\nAssume only in-bounds pairs are counted (no wrap-around) and no symmetrization is applied. Provide the exact value of $r$ with no rounding.", "solution": "The problem is well-defined and requires a standard calculation from the field of radiomics. All necessary data and definitions are provided, and there are no scientific or logical inconsistencies. The problem is therefore valid.\n\nThe solution proceeds by first constructing the Gray-Level Co-occurrence Matrix (GLCM) for each displacement vector. The input image is a $3 \\times 3$ slice of bin indices, denoted as $I(x,y)$, where $x$ is the column index ($1, 2, 3$) and $y$ is the row index ($1, 2, 3$):\n$$\nI = \\begin{pmatrix}\n1 & 2 & 3\\\\\n2 & 2 & 4\\\\\n3 & 4 & 5\n\\end{pmatrix}\n$$\nThe number of gray levels is $N_g=16$.\n\nStep 1: Compute the GLCM and contrast for displacement $\\mathbf{d}_1=(1,0,0)$.\nThe displacement $\\mathbf{d}_1=(1,0,0)$ corresponds to a horizontal shift of one voxel. We form ordered pairs $(i,j)$ by considering in-bounds voxel pairs $\\big(I(x,y), I(x+1,y)\\big)$.\nWe iterate over valid spatial coordinates $(x,y)$. Here, $x$ can range from $1$ to $2$, and $y$ from $1$ to $3$.\nThe pairs are:\n\\begin{itemize}\n    \\item For $y=1$: $\\big(I(1,1), I(2,1)\\big)=(1,2)$; $\\big(I(2,1), I(3,1)\\big)=(2,3)$.\n    \\item For $y=2$: $\\big(I(1,2), I(2,2)\\big)=(2,2)$; $\\big(I(2,2), I(3,2)\\big)=(2,4)$.\n    \\item For $y=3$: $\\big(I(1,3), I(2,3)\\big)=(3,4)$; $\\big(I(2,3), I(3,3)\\big)=(4,5)$.\n\\end{itemize}\nThe total number of pairs is $N_{\\mathbf{d}_1} = 6$. The non-symmetric GLCM count matrix, $G_{\\mathbf{d}_1}$, will have the following non-zero entries for $(i,j)$:\n$G_{\\mathbf{d}_1}(1,2)=1$, $G_{\\mathbf{d}_1}(2,2)=1$, $G_{\\mathbf{d}_1}(2,3)=1$, $G_{\\mathbf{d}_1}(2,4)=1$, $G_{\\mathbf{d}_1}(3,4)=1$, $G_{\\mathbf{d}_1}(4,5)=1$.\n\nThe normalized probability matrix $P_{\\mathbf{d}_1}(i,j) = G_{\\mathbf{d}_1}(i,j) / N_{\\mathbf{d}_1}$. Thus, each of the non-zero entries is $1/6$.\nThe GLCM contrast feature is defined as $C = \\sum_{i=1}^{N_g} \\sum_{j=1}^{N_g} (i-j)^2 P(i,j)$.\nFor displacement $\\mathbf{d}_1$:\n$$\nC(\\mathbf{d}_1) = (1-2)^2 P_{\\mathbf{d}_1}(1,2) + (2-2)^2 P_{\\mathbf{d}_1}(2,2) + (2-3)^2 P_{\\mathbf{d}_1}(2,3) + (2-4)^2 P_{\\mathbf{d}_1}(2,4) + (3-4)^2 P_{\\mathbf{d}_1}(3,4) + (4-5)^2 P_{\\mathbf{d}_1}(4,5)\n$$\n$$\nC(\\mathbf{d}_1) = (-1)^2\\left(\\frac{1}{6}\\right) + (0)^2\\left(\\frac{1}{6}\\right) + (-1)^2\\left(\\frac{1}{6}\\right) + (-2)^2\\left(\\frac{1}{6}\\right) + (-1)^2\\left(\\frac{1}{6}\\right) + (-1)^2\\left(\\frac{1}{6}\\right)\n$$\n$$\nC(\\mathbf{d}_1) = \\frac{1}{6} \\left( 1 + 0 + 1 + 4 + 1 + 1 \\right) = \\frac{8}{6} = \\frac{4}{3}.\n$$\n\nStep 2: Compute the GLCM and contrast for displacement $\\mathbf{d}_2=(1,1,0)$.\nThe displacement $\\mathbf{d}_2=(1,1,0)$ corresponds to a diagonal shift. We form ordered pairs $(i,j)$ by considering in-bounds voxel pairs $\\big(I(x,y), I(x+1,y+1)\\big)$.\nWe iterate over valid spatial coordinates $(x,y)$. Here, $x$ can range from $1$ to $2$, and $y$ from $1$ to $2$.\nThe pairs are:\n\\begin{itemize}\n    \\item For $y=1$: $\\big(I(1,1), I(2,2)\\big)=(1,2)$; $\\big(I(2,1), I(3,2)\\big)=(2,4)$.\n    \\item For $y=2$: $\\big(I(1,2), I(2,3)\\big)=(2,4)$; $\\big(I(2,2), I(3,3)\\big)=(2,5)$.\n\\end{itemize}\nThe total number of pairs is $N_{\\mathbf{d}_2} = 4$. The non-symmetric GLCM count matrix, $G_{\\mathbf{d}_2}$, will have the following non-zero entries for $(i,j)$:\n$G_{\\mathbf{d}_2}(1,2)=1$, $G_{\\mathbf{d}_2}(2,4)=2$, $G_{\\mathbf{d}_2}(2,5)=1$.\n\nThe normalized probability matrix $P_{\\mathbf{d}_2}(i,j) = G_{\\mathbf{d}_2}(i,j) / N_{\\mathbf{d}_2}$. The non-zero entries are:\n$P_{\\mathbf{d}_2}(1,2) = 1/4$, $P_{\\mathbf{d}_2}(2,4) = 2/4 = 1/2$, $P_{\\mathbf{d}_2}(2,5) = 1/4$.\n\nFor displacement $\\mathbf{d}_2$, the contrast is:\n$$\nC(\\mathbf{d}_2) = (1-2)^2 P_{\\mathbf{d}_2}(1,2) + (2-4)^2 P_{\\mathbf{d}_2}(2,4) + (2-5)^2 P_{\\mathbf{d}_2}(2,5)\n$$\n$$\nC(\\mathbf{d}_2) = (-1)^2\\left(\\frac{1}{4}\\right) + (-2)^2\\left(\\frac{2}{4}\\right) + (-3)^2\\left(\\frac{1}{4}\\right)\n$$\n$$\nC(\\mathbf{d}_2) = \\frac{1}{4}\\left(1\\right) + \\frac{4}{4}\\left(2\\right) + \\frac{9}{4}\\left(1\\right) = \\frac{1+8+9}{4} = \\frac{18}{4} = \\frac{9}{2}.\n$$\n\nStep 3: Compute the ratio $r$.\nThe problem asks for the ratio $r = C(\\mathbf{d}_2) / C(\\mathbf{d}_1)$.\n$$\nr = \\frac{C(\\mathbf{d}_2)}{C(\\mathbf{d}_1)} = \\frac{9/2}{4/3} = \\frac{9}{2} \\times \\frac{3}{4} = \\frac{27}{8}.\n$$\nThe exact value of the ratio is $27/8$.", "answer": "$$\n\\boxed{\\frac{27}{8}}\n$$", "id": "4531346"}, {"introduction": "For a radiomic signature to be clinically reliable, its constituent features must be robust against minor variations that occur in real-world practice, such as subtle differences in how a tumor is outlined. This exercise simulates this crucial quality control step, known as feature stability analysis. You will implement and interpret two workhorse statistical metrics, the Coefficient of Variation ($CV$) and the Intraclass Correlation Coefficient ($ICC$), to filter out unstable features and select only the most reproducible ones for building a predictive model [@problem_id:4531341].", "problem": "You are given a stability selection task for radiomic features subjected to simulated Region of Interest (ROI) perturbations. For each subject, each feature has been measured repeatedly under multiple perturbations. Your goal is to determine which features are robust across perturbations and subjects by computing two stability metrics for each feature: the coefficient of variation and the Intraclass Correlation Coefficient (ICC). You must start from first principles and derive the necessary computations from core definitions of sample mean, sample variance, and one-way analysis of variance (ANOVA).\n\nAssume the following setup. There are $S$ subjects, $K$ perturbations per subject, and $F$ features. Let $x_{s,k,f}$ denote the value of feature $f$ for subject $s$ under perturbation $k$, with $s \\in \\{0,\\dots,S-1\\}$, $k \\in \\{0,\\dots,K-1\\}$, and $f \\in \\{0,\\dots,F-1\\}$.\n\nFundamental base for the derivation:\n- Use the definitions of the sample mean and sample variance. For a set of $K$ repeated measurements $\\{y_k\\}_{k=0}^{K-1}$, the sample mean is $m = \\frac{1}{K}\\sum_{k=0}^{K-1} y_k$, and the unbiased sample variance is $s^2 = \\frac{1}{K-1}\\sum_{k=0}^{K-1} (y_k - m)^2$, with sample standard deviation $s = \\sqrt{s^2}$.\n- Use the one-way analysis of variance decomposition across subjects with repeated measurements to compute the Intraclass Correlation Coefficient (ICC) of type one-way random effects, single measurement, denoted here as $ICC(1,1)$. The derivation must proceed from sums of squares and mean squares: the between-subject sum of squares and the within-subject sum of squares, with their respective degrees of freedom, without shortcut formulas.\n\nDefinitions to implement:\n1. For each feature $f$ and subject $s$, compute the subject-level coefficient of variation across perturbations:\n   - Compute the sample mean $\\mu_{s,f} = \\frac{1}{K}\\sum_{k=0}^{K-1} x_{s,k,f}$.\n   - Compute the sample standard deviation $\\sigma_{s,f} = \\sqrt{\\frac{1}{K-1}\\sum_{k=0}^{K-1} \\left(x_{s,k,f} - \\mu_{s,f}\\right)^2}$.\n   - Define the coefficient of variation for subject $s$ and feature $f$ as $CV_{s,f} = \\frac{\\sigma_{s,f}}{|\\mu_{s,f}|}$ if $|\\mu_{s,f}| \\neq 0$. If $|\\mu_{s,f}| = 0$ and $\\sigma_{s,f} = 0$, set $CV_{s,f} = 0$. If $|\\mu_{s,f}| = 0$ and $\\sigma_{s,f} > 0$, define $CV_{s,f}$ to be $+\\infty$.\n   - Aggregate to a single per-feature value by taking the median across subjects: $CV_f = \\operatorname{median}\\left(\\{CV_{s,f}\\}_{s=0}^{S-1}\\right)$.\n2. For each feature $f$, compute $ICC(1,1)$ from the one-way ANOVA decomposition across subjects:\n   - For each subject $s$, compute the subject mean across perturbations: $\\bar{x}_{s,f} = \\frac{1}{K}\\sum_{k=0}^{K-1} x_{s,k,f}$.\n   - Compute the grand mean $\\bar{x}_f = \\frac{1}{S}\\sum_{s=0}^{S-1} \\bar{x}_{s,f}$.\n   - Compute the between-subject sum of squares $SS_B = K \\sum_{s=0}^{S-1} \\left(\\bar{x}_{s,f} - \\bar{x}_f\\right)^2$ with degrees of freedom $df_B = S - 1$, and hence $MS_B = \\frac{SS_B}{df_B}$ for $S \\ge 2$.\n   - Compute the within-subject sum of squares $SS_W = \\sum_{s=0}^{S-1}\\sum_{k=0}^{K-1} \\left(x_{s,k,f} - \\bar{x}_{s,f}\\right)^2$ with degrees of freedom $df_W = S\\,(K-1)$ for $K \\ge 2$, and hence $MS_W = \\frac{SS_W}{df_W}$.\n   - Define $ICC_f$ as follows: if $MS_B = 0$ and $MS_W = 0$, set $ICC_f = 1$. Otherwise, set\n     $$ ICC_f = \\frac{MS_B - MS_W}{MS_B + (K-1)\\,MS_W}. $$\n   This quantity reflects the proportion of variance attributable to differences between subjects under a one-way random effects model.\n\nRobustness decision rule:\n- Given thresholds $\\tau_{CV}$ and $\\tau_{ICC}$, a feature $f$ is deemed robust if and only if $CV_f \\le \\tau_{CV}$ and $ICC_f \\ge \\tau_{ICC}$.\n\nTest suite:\n- Use $S = 3$, $K = 4$, $F = 4$, with data $x_{s,k,f}$ specified per feature as follows, listed by subject (outer), then perturbation (inner), for each feature index $f \\in \\{0,1,2,3\\}$:\n  - Feature $f=0$:\n    - Subject $s=0$: $[\\,10.0,\\,10.1,\\,9.9,\\,10.0\\,]$\n    - Subject $s=1$: $[\\,12.0,\\,12.1,\\,11.9,\\,12.0\\,]$\n    - Subject $s=2$: $[\\,8.0,\\,8.1,\\,7.9,\\,8.0\\,]$\n  - Feature $f=1$:\n    - Subject $s=0$: $[\\,5.0,\\,7.0,\\,3.0,\\,9.0\\,]$\n    - Subject $s=1$: $[\\,6.0,\\,10.0,\\,2.0,\\,8.0\\,]$\n    - Subject $s=2$: $[\\,4.0,\\,12.0,\\,1.0,\\,11.0\\,]$\n  - Feature $f=2$:\n    - Subject $s=0$: $[\\,{-0.1},\\,0.1,\\,{-0.1},\\,0.1\\,]$\n    - Subject $s=1$: $[\\,{-0.2},\\,0.2,\\,{-0.2},\\,0.2\\,]$\n    - Subject $s=2$: $[\\,{-0.05},\\,0.05,\\,{-0.05},\\,0.05\\,]$\n  - Feature $f=3$:\n    - Subject $s=0$: $[\\,7.0,\\,7.0,\\,7.0,\\,7.0\\,]$\n    - Subject $s=1$: $[\\,7.0,\\,7.0,\\,7.0,\\,7.0\\,]$\n    - Subject $s=2$: $[\\,7.0,\\,7.0,\\,7.0,\\,7.0\\,]$\n- Evaluate three threshold cases to test different facets:\n  1. Case $A$: $\\tau_{CV} = 0.05$, $\\tau_{ICC} = 0.9$ (general case).\n  2. Case $B$: $\\tau_{CV} = 0.0$, $\\tau_{ICC} = 1.0$ (boundary case with exact equality allowed).\n  3. Case $C$: $\\tau_{CV} = 0.55$, $\\tau_{ICC} = {-0.4}$ (edge case allowing negative $ICC$ but still constrained by $CV$).\n\nRequired final output format:\n- Your program must produce a single line containing a list of lists of integers, where each inner list contains the ascending indices of robust features for cases $A$, $B$, and $C$ respectively. The line must contain no whitespace. For example, an output with two cases might look like $[[0,2],[1]]$. For this problem with three cases, the required output is of the form $[[\\dots],[\\dots],[\\dots]]$ with no spaces anywhere in the line.", "solution": "The problem is valid as it is scientifically grounded in standard statistical methods for assessing measurement stability (Coefficient of Variation and Intraclass Correlation Coefficient), is well-posed with all necessary data and definitions provided, and is presented in an objective, formalizable manner. We proceed with a step-by-step solution based on first principles as requested.\n\nThe task is to identify robust radiomic features from a dataset containing measurements for $S=3$ subjects, under $K=4$ perturbations per subject, across $F=4$ features. Let $x_{s,k,f}$ be the value of feature $f$ for subject $s$ and perturbation $k$. A feature is robust if its aggregated coefficient of variation $CV_f$ and its intraclass correlation coefficient $ICC_f$ meet specified thresholds.\n\n**Step 1: Compute Feature-wise Stability Metrics ($CV_f$ and $ICC_f$)**\n\nWe will compute $CV_f$ and $ICC_f$ for each feature $f \\in \\{0, 1, 2, 3\\}$.\n\n**Feature $f=0$**\nThe data are:\n- Subject $s=0$: $[\\,10.0,\\,10.1,\\,9.9,\\,10.0\\,]$\n- Subject $s=1$: $[\\,12.0,\\,12.1,\\,11.9,\\,12.0\\,]$\n- Subject $s=2$: $[\\,8.0,\\,8.1,\\,7.9,\\,8.0\\,]$\n\n*1. Coefficient of Variation ($CV_0$)*\nFor each subject $s$, we compute the mean $\\mu_{s,0}$ and standard deviation $\\sigma_{s,0}$ across the $K=4$ perturbations.\n- Subject $s=0$:\n  - $\\mu_{0,0} = \\frac{1}{4}(10.0 + 10.1 + 9.9 + 10.0) = 10.0$.\n  - $\\sigma_{0,0}^2 = \\frac{1}{4-1}((10.0-10.0)^2 + (10.1-10.0)^2 + (9.9-10.0)^2 + (10.0-10.0)^2) = \\frac{1}{3}(0 + 0.01 + 0.01 + 0) = \\frac{0.02}{3}$.\n  - $\\sigma_{0,0} = \\sqrt{\\frac{0.02}{3}} \\approx 0.08165$.\n  - $CV_{0,0} = \\frac{\\sigma_{0,0}}{|\\mu_{0,0}|} = \\frac{\\sqrt{0.02/3}}{10.0} \\approx 0.008165$.\n- Subject $s=1$:\n  - $\\mu_{1,0} = \\frac{1}{4}(12.0 + 12.1 + 11.9 + 12.0) = 12.0$.\n  - $\\sigma_{1,0}^2 = \\frac{1}{3}((12.0-12.0)^2 + (12.1-12.0)^2 + (11.9-12.0)^2 + (12.0-12.0)^2) = \\frac{0.02}{3}$.\n  - $\\sigma_{1,0} = \\sqrt{\\frac{0.02}{3}} \\approx 0.08165$.\n  - $CV_{1,0} = \\frac{\\sigma_{1,0}}{|\\mu_{1,0}|} = \\frac{\\sqrt{0.02/3}}{12.0} \\approx 0.006804$.\n- Subject $s=2$:\n  - $\\mu_{2,0} = \\frac{1}{4}(8.0 + 8.1 + 7.9 + 8.0) = 8.0$.\n  - $\\sigma_{2,0}^2 = \\frac{1}{3}((8.0-8.0)^2 + (8.1-8.0)^2 + (7.9-8.0)^2 + (8.0-8.0)^2) = \\frac{0.02}{3}$.\n  - $\\sigma_{2,0} = \\sqrt{\\frac{0.02}{3}} \\approx 0.08165$.\n  - $CV_{2,0} = \\frac{\\sigma_{2,0}}{|\\mu_{2,0}|} = \\frac{\\sqrt{0.02/3}}{8.0} \\approx 0.010206$.\nThe aggregated $CV_0$ is the median of the subject-level CVs:\n$CV_0 = \\operatorname{median}(\\{0.008165, 0.006804, 0.010206\\}) = 0.008165$.\n\n*2. Intraclass Correlation Coefficient ($ICC_0$)*\nWe perform a one-way ANOVA. The subject means $\\bar{x}_{s,0}$ are identical to the $\\mu_{s,0}$ calculated above: $\\bar{x}_{0,0}=10.0$, $\\bar{x}_{1,0}=12.0$, $\\bar{x}_{2,0}=8.0$.\n- Grand mean: $\\bar{x}_0 = \\frac{1}{S}\\sum_{s=0}^{S-1} \\bar{x}_{s,0} = \\frac{1}{3}(10.0 + 12.0 + 8.0) = 10.0$.\n- Between-subject sum of squares ($SS_B$): $SS_B = K \\sum_{s=0}^{S-1} (\\bar{x}_{s,0} - \\bar{x}_0)^2 = 4 \\times ((10.0-10.0)^2 + (12.0-10.0)^2 + (8.0-10.0)^2) = 4 \\times (0 + 4 + 4) = 32$.\n- Between-subject mean square ($MS_B$): $df_B = S-1 = 2$. $MS_B = \\frac{SS_B}{df_B} = \\frac{32}{2} = 16$.\n- Within-subject sum of squares ($SS_W$): $SS_W = \\sum_{s=0}^{S-1}\\sum_{k=0}^{K-1} (x_{s,k,0} - \\bar{x}_{s,0})^2 = \\sum_{s=0}^{S-1} (K-1)\\sigma_{s,0}^2 = 3 \\times (\\frac{0.02}{3}) \\times 3 = 0.06$.\n- Within-subject mean square ($MS_W$): $df_W = S(K-1) = 3(3) = 9$. $MS_W = \\frac{SS_W}{df_W} = \\frac{0.06}{9} = \\frac{1}{150}$.\n- $ICC_0 = \\frac{MS_B - MS_W}{MS_B + (K-1)MS_W} = \\frac{16 - 1/150}{16 + (3)(1/150)} = \\frac{16 - 1/150}{16 + 1/50} = \\frac{2399/150}{2403/150} = \\frac{2399}{2403} \\approx 0.998335$.\n\n**Feature $f=1$**\nThe data are:\n- Subject $s=0$: $[\\,5.0,\\,7.0,\\,3.0,\\,9.0\\,]$\n- Subject $s=1$: $[\\,6.0,\\,10.0,\\,2.0,\\,8.0\\,]$\n- Subject $s=2$: $[\\,4.0,\\,12.0,\\,1.0,\\,11.0\\,]$\n\n*1. Coefficient of Variation ($CV_1$)*\n- Subject $s=0$: $\\mu_{0,1} = 6.0$, $\\sigma_{0,1}^2 = \\frac{20}{3}$, $\\sigma_{0,1} = \\sqrt{20/3}$. $CV_{0,1} = \\frac{\\sqrt{20/3}}{6.0} \\approx 0.43033$.\n- Subject $s=1$: $\\mu_{1,1} = 6.5$, $\\sigma_{1,1}^2 = \\frac{35}{3}$, $\\sigma_{1,1} = \\sqrt{35/3}$. $CV_{1,1} = \\frac{\\sqrt{35/3}}{6.5} \\approx 0.52548$.\n- Subject $s=2$: $\\mu_{2,1} = 7.0$, $\\sigma_{2,1}^2 = \\frac{86}{3}$, $\\sigma_{2,1} = \\sqrt{86/3}$. $CV_{2,1} = \\frac{\\sqrt{86/3}}{7.0} \\approx 0.76488$.\n$CV_1 = \\operatorname{median}(\\{0.43033, 0.52548, 0.76488\\}) = 0.52548$.\n\n*2. Intraclass Correlation Coefficient ($ICC_1$)*\n- Subject means: $\\bar{x}_{0,1}=6.0$, $\\bar{x}_{1,1}=6.5$, $\\bar{x}_{2,1}=7.0$.\n- Grand mean: $\\bar{x}_1 = \\frac{1}{3}(6.0+6.5+7.0) = 6.5$.\n- $SS_B = 4 \\times ((6.0-6.5)^2 + (6.5-6.5)^2 + (7.0-6.5)^2) = 4 \\times (0.25+0+0.25) = 2$.\n- $MS_B = \\frac{2}{2} = 1$.\n- $SS_W = (4-1)(\\sigma_{0,1}^2 + \\sigma_{1,1}^2 + \\sigma_{2,1}^2) = 3(\\frac{20}{3} + \\frac{35}{3} + \\frac{86}{3}) = 20+35+86 = 141$.\n- $MS_W = \\frac{141}{9} = \\frac{47}{3}$.\n- $ICC_1 = \\frac{1 - 47/3}{1 + 3(47/3)} = \\frac{-44/3}{1+47} = \\frac{-44/3}{48} = -\\frac{44}{144} = -\\frac{11}{36} \\approx -0.30556$.\n\n**Feature $f=2$**\nThe data are:\n- Subject $s=0$: $[\\,{-0.1},\\,0.1,\\,{-0.1},\\,0.1\\,]$\n- Subject $s=1$: $[\\,{-0.2},\\,0.2,\\,{-0.2},\\,0.2\\,]$\n- Subject $s=2$: $[\\,{-0.05},\\,0.05,\\,{-0.05},\\,0.05\\,]$\n\n*1. Coefficient of Variation ($CV_2$)*\nFor all subjects $s \\in \\{0,1,2\\}$, the mean $\\mu_{s,2} = 0$. However, the standard deviation $\\sigma_{s,2} > 0$ as the values are not all zero. According to the problem definition, if $|\\mu_{s,f}| = 0$ and $\\sigma_{s,f} > 0$, then $CV_{s,f} = +\\infty$.\n- $CV_{0,2} = +\\infty$, $CV_{1,2} = +\\infty$, $CV_{2,2} = +\\infty$.\n$CV_2 = \\operatorname{median}(\\{+\\infty, +\\infty, +\\infty\\}) = +\\infty$.\n\n*2. Intraclass Correlation Coefficient ($ICC_2$)*\n- Subject means: $\\bar{x}_{0,2}=0$, $\\bar{x}_{1,2}=0$, $\\bar{x}_{2,2}=0$.\n- Grand mean: $\\bar{x}_2 = 0$.\n- $SS_B = 4 \\times ((0-0)^2 + (0-0)^2 + (0-0)^2) = 0$. Thus, $MS_B = 0$.\n- $SS_W$:\n  - $s=0: (-0.1)^2 + 0.1^2 + (-0.1)^2 + 0.1^2 = 0.04$.\n  - $s=1: (-0.2)^2 + 0.2^2 + (-0.2)^2 + 0.2^2 = 0.16$.\n  - $s=2: (-0.05)^2 + 0.05^2 + (-0.05)^2 + 0.05^2 = 0.01$.\n  - $SS_W = 0.04 + 0.16 + 0.01 = 0.21$.\n- $MS_W = \\frac{0.21}{9}$.\n- $ICC_2 = \\frac{0 - 0.21/9}{0 + 3(0.21/9)} = \\frac{-0.21/9}{3(0.21/9)} = -\\frac{1}{3}$.\n\n**Feature $f=3$**\nThe data are identical for all subjects and perturbations: $[\\,7.0,\\,7.0,\\,7.0,\\,7.0\\,]$.\n\n*1. Coefficient of Variation ($CV_3$)*\nFor all subjects $s \\in \\{0,1,2\\}$, the mean is $\\mu_{s,3}=7.0$ and the standard deviation is $\\sigma_{s,3}=0$.\n- $CV_{s,3} = \\frac{0}{|7.0|} = 0$.\n$CV_3 = \\operatorname{median}(\\{0, 0, 0\\}) = 0$.\n\n*2. Intraclass Correlation Coefficient ($ICC_3$)*\n- Subject means: $\\bar{x}_{0,3}=7.0$, $\\bar{x}_{1,3}=7.0$, $\\bar{x}_{2,3}=7.0$.\n- Grand mean: $\\bar{x}_3 = 7.0$.\n- $SS_B = K \\sum (\\bar{x}_{s,3}-\\bar{x}_3)^2 = 0$. Thus, $MS_B=0$.\n- $SS_W = \\sum\\sum(x_{s,k,3}-\\bar{x}_{s,3})^2 = 0$. Thus, $MS_W=0$.\nWe encounter the special case where $MS_B = 0$ and $MS_W = 0$. As per the problem definition, we set $ICC_3 = 1$.\n\n**Summary of Metrics**\n\n| Feature $f$ | $CV_f$            | $ICC_f$               |\n|:-----------:|:-----------------:|:---------------------:|\n| $0$         | $\\approx 0.00817$ | $\\approx 0.99834$     |\n| $1$         | $\\approx 0.52548$ | $\\approx -0.30556$    |\n| $2$         | $+\\infty$         | $\\approx -0.33333$    |\n| $3$         | $0.0$             | $1.0$                 |\n\n**Step 2: Apply Robustness Decision Rule**\n\nWe now evaluate each feature against the thresholds for the three cases.\n\n**Case A: $\\tau_{CV} = 0.05$, $\\tau_{ICC} = 0.9$**\n- Feature $f=0$: $CV_0 \\approx 0.00817 \\le 0.05$ (True) AND $ICC_0 \\approx 0.99834 \\ge 0.9$ (True) $\\implies$ **Robust**.\n- Feature $f=1$: $CV_1 \\approx 0.52548 \\le 0.05$ (False) $\\implies$ Not robust.\n- Feature $f=2$: $CV_2 = +\\infty \\le 0.05$ (False) $\\implies$ Not robust.\n- Feature $f=3$: $CV_3 = 0.0 \\le 0.05$ (True) AND $ICC_3 = 1.0 \\ge 0.9$ (True) $\\implies$ **Robust**.\nRobust feature indices for Case A: `[0, 3]`.\n\n**Case B: $\\tau_{CV} = 0.0$, $\\tau_{ICC} = 1.0$**\n- Feature $f=0$: $CV_0 \\approx 0.00817 \\le 0.0$ (False) $\\implies$ Not robust.\n- Feature $f=1$: $CV_1 \\approx 0.52548 \\le 0.0$ (False) $\\implies$ Not robust.\n- Feature $f=2$: $CV_2 = +\\infty \\le 0.0$ (False) $\\implies$ Not robust.\n- Feature $f=3$: $CV_3 = 0.0 \\le 0.0$ (True) AND $ICC_3 = 1.0 \\ge 1.0$ (True) $\\implies$ **Robust**.\nRobust feature indices for Case B: `[3]`.\n\n**Case C: $\\tau_{CV} = 0.55$, $\\tau_{ICC} = -0.4$**\n- Feature $f=0$: $CV_0 \\approx 0.00817 \\le 0.55$ (True) AND $ICC_0 \\approx 0.99834 \\ge -0.4$ (True) $\\implies$ **Robust**.\n- Feature $f=1$: $CV_1 \\approx 0.52548 \\le 0.55$ (True) AND $ICC_1 \\approx -0.30556 \\ge -0.4$ (True) $\\implies$ **Robust**.\n- Feature $f=2$: $CV_2 = +\\infty \\le 0.55$ (False) $\\implies$ Not robust.\n- Feature $f=3$: $CV_3 = 0.0 \\le 0.55$ (True) AND $ICC_3 = 1.0 \\ge -0.4$ (True) $\\implies$ **Robust**.\nRobust feature indices for Case C: `[0, 1, 3]`.\n\n**Final Result**\n\nThe final output is a list of lists containing the ascending indices of robust features for cases A, B, and C.\n- Case A: `[0, 3]`\n- Case B: `[3]`\n- Case C: `[0, 1, 3]`\nThis compiles to the final string `[[0,3],[3],[0,1,3]]`.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes stability metrics for radiomic features and determines robustness\n    based on given thresholds.\n    \"\"\"\n    \n    # Define constants based on the problem statement.\n    S = 3  # Number of subjects\n    K = 4  # Number of perturbations\n    F = 4  # Number of features\n    \n    # Define the dataset as a 3D numpy array of shape (F, S, K).\n    X = np.array([\n        # Feature f=0: High ICC, low CV\n        [[10.0, 10.1, 9.9, 10.0],\n         [12.0, 12.1, 11.9, 12.0],\n         [8.0, 8.1, 7.9, 8.0]],\n        \n        # Feature f=1: Low ICC, high CV\n        [[5.0, 7.0, 3.0, 9.0],\n         [6.0, 10.0, 2.0, 8.0],\n         [4.0, 12.0, 1.0, 11.0]],\n        \n        # Feature f=2: Zero mean, leading to infinite CV\n        [[-0.1, 0.1, -0.1, 0.1],\n         [-0.2, 0.2, -0.2, 0.2],\n         [-0.05, 0.05, -0.05, 0.05]],\n         \n        # Feature f=3: No variation, perfect stability\n        [[7.0, 7.0, 7.0, 7.0],\n         [7.0, 7.0, 7.0, 7.0],\n         [7.0, 7.0, 7.0, 7.0]]\n    ])\n\n    # Define the threshold cases to test.\n    threshold_cases = [\n        # Case A: (tau_cv, tau_icc)\n        (0.05, 0.9),\n        # Case B:\n        (0.0, 1.0),\n        # Case C:\n        (0.55, -0.4)\n    ]\n    \n    feature_metrics = []\n\n    # Iterate through each feature to calculate its stability metrics (CV and ICC).\n    for f in range(F):\n        feature_data = X[f, :, :]  # Data for the current feature, shape (S, K)\n\n        # --- 1. Calculate Coefficient of Variation (CV) ---\n        cv_per_subject = []\n        for s in range(S):\n            subject_data = feature_data[s, :]\n            \n            # Unbiased sample standard deviation (ddof=1 for N-1 in denominator)\n            sigma_sf = np.std(subject_data, ddof=1)\n            mu_sf = np.mean(subject_data)\n            \n            # Handle special cases for CV calculation as per the problem definition.\n            if mu_sf == 0.0:\n                if sigma_sf == 0.0:\n                    cv_sf = 0.0\n                else:\n                    cv_sf = np.inf\n            else:\n                cv_sf = sigma_sf / abs(mu_sf)\n            cv_per_subject.append(cv_sf)\n            \n        # Aggregate to a single per-feature value by taking the median across subjects.\n        cv_f = np.median(cv_per_subject)\n\n        # --- 2. Calculate Intraclass Correlation Coefficient (ICC) ---\n        # Subject means across perturbations\n        subject_means = np.mean(feature_data, axis=1) # Shape (S,)\n        \n        # Grand mean across all subjects and perturbations\n        grand_mean = np.mean(subject_means)\n\n        # Between-subject sum of squares (SS_B)\n        df_b = S - 1\n        ss_b = K * np.sum((subject_means - grand_mean)**2)\n        ms_b = ss_b / df_b if df_b > 0 else 0\n\n        # Within-subject sum of squares (SS_W)\n        df_w = S * (K - 1)\n        # Use broadcasting to subtract subject means from their respective measurements\n        ss_w = np.sum((feature_data - subject_means.reshape(-1, 1))**2)\n        ms_w = ss_w / df_w if df_w > 0 else 0\n\n        # Handle special case for ICC calculation\n        if ms_b == 0.0 and ms_w == 0.0:\n            icc_f = 1.0\n        else:\n            # Formula for ICC(1,1)\n            numerator = ms_b - ms_w\n            denominator = ms_b + (K - 1) * ms_w\n            icc_f = numerator / denominator if denominator != 0 else -1.0\n        \n        feature_metrics.append((cv_f, icc_f))\n\n    all_case_results = []\n    \n    # Apply the robustness decision rule for each case.\n    for tau_cv, tau_icc in threshold_cases:\n        robust_indices = []\n        for f in range(F):\n            cv_f, icc_f = feature_metrics[f]\n            if cv_f = tau_cv and icc_f >= tau_icc:\n                robust_indices.append(f)\n        all_case_results.append(robust_indices)\n\n    # Format the final output string exactly as specified, with no whitespace.\n    inner_results_as_strings = [f\"[{','.join(map(str, inner_list))}]\" for inner_list in all_case_results]\n    final_output = f\"[{','.join(inner_results_as_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "4531341"}]}