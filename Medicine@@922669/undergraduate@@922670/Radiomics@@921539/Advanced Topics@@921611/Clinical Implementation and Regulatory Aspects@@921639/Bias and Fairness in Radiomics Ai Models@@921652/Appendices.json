{"hands_on_practices": [{"introduction": "When we call an AI model \"fair,\" what do we actually mean? This question is more complex than it appears, as different intuitive notions of fairness can be mathematically incompatible. This exercise explores a classic conflict between two common fairness criteria: subgroup calibration and demographic parity. You will construct a concrete counterexample to demonstrate that a model cannot simultaneously be perfectly calibrated for different subgroups and also assign a positive prediction to an equal fraction of individuals in those groups, except in very specific, often unrealistic, circumstances [@problem_id:4530653]. This practice is fundamental to understanding that achieving fairness is not about finding a single \"correct\" definition, but about navigating inherent trade-offs.", "problem": "A radiomics Artificial Intelligence (AI) model is deployed to estimate lung malignancy risk from Computed Tomography (CT) scans. The hospital population is partitioned into two subgroups, denoted by $A$ and $B$, representing two different referral pathways with different disease base rates. The model outputs a calibrated risk score per subgroup in the following sense: for each subgroup $G \\in \\{A, B\\}$ and each possible score value $r$, subgroup calibration means that the conditional prevalence equals the score, that is, $\\mathbb{E}[Y \\mid R = r, G] = r$, where $Y \\in \\{0,1\\}$ indicates malignancy and $R \\in \\{r_{L}, r_{H}\\}$ is the model score taking two values $r_{L}$ and $r_{H}$ with $0 < r_{L} < r_{H} < 1$. Assume the subgroup base rates are $p_{A} = \\mathbb{P}(Y = 1 \\mid G = A)$ and $p_{B} = \\mathbb{P}(Y = 1 \\mid G = B)$, and the model is subgroup-calibrated with the two-point score distribution: in subgroup $G$, the score equals $r_{L}$ with probability $q_{G}$ and equals $r_{H}$ with probability $1 - q_{G}$, for some $q_{G} \\in [0,1]$.\n\nThe hospital applies a single decision threshold $t$ to the score, independent of subgroup membership, and flags a scan as positive if and only if $R \\geq t$. Assume the threshold satisfies $r_{L} < t < r_{H}$, so that only scans with $R = r_{H}$ are flagged. Demographic parity is the requirement that the fraction of flagged scans be equal across subgroups. Define the demographic parity gap as\n$$\\Delta \\equiv \\mathbb{P}(R \\geq t \\mid G = B) - \\mathbb{P}(R \\geq t \\mid G = A).$$\n\nUsing only the definition of subgroup calibration and the law of total probability, compute $\\Delta$ for the concrete, scientifically plausible radiomics setting with $r_{L} = 0.1$, $r_{H} = 0.9$, $p_{A} = 0.2$, and $p_{B} = 0.5$. Express your final answer as a simplified fraction. In doing this calculation, you will construct a counterexample showing that subgroup calibration and demographic parity (under a single threshold applied uniformly across subgroups) are incompatible except in degenerate cases. No rounding is required.", "solution": "The problem asks for the computation of the demographic parity gap, $\\Delta$, defined as\n$$ \\Delta \\equiv \\mathbb{P}(R \\geq t \\mid G = B) - \\mathbb{P}(R \\geq t \\mid G = A) $$\nwhere $R$ is the model's risk score, $t$ is the decision threshold, and $G \\in \\{A, B\\}$ denotes the subgroup.\n\nThe model's score $R$ can take only two values, $r_L$ and $r_H$. The decision threshold $t$ is specified to be in the interval $r_L < t < r_H$. Therefore, a scan is flagged as positive, which occurs if and only if $R \\geq t$, is equivalent to the event $R = r_H$.\nWith this simplification, the demographic parity gap $\\Delta$ can be expressed as:\n$$ \\Delta = \\mathbb{P}(R = r_H \\mid G = B) - \\mathbb{P}(R = r_H \\mid G = A) $$\nThe problem states that for any subgroup $G$, the score $R$ equals $r_L$ with probability $q_G$ and $r_H$ with probability $1 - q_G$.\nThus, $\\mathbb{P}(R = r_H \\mid G) = 1 - q_G$. Substituting this into the expression for $\\Delta$ gives:\n$$ \\Delta = (1 - q_B) - (1 - q_A) = q_A - q_B $$\nTo find $\\Delta$, we must first determine the values of $q_A$ and $q_B$. We are instructed to use the law of total probability and the definition of subgroup calibration.\n\nFor any subgroup $G$, the base rate of malignancy, $p_G = \\mathbb{P}(Y = 1 \\mid G)$, can be expressed using the law of total probability by conditioning on the score $R$:\n$$ p_G = \\mathbb{P}(Y=1 \\mid G) = \\sum_{r \\in \\{r_L, r_H\\}} \\mathbb{P}(Y=1 \\mid R=r, G) \\mathbb{P}(R=r \\mid G) $$\nThis expands to:\n$$ p_G = \\mathbb{P}(Y=1 \\mid R=r_L, G) \\mathbb{P}(R=r_L \\mid G) + \\mathbb{P}(Y=1 \\mid R=r_H, G) \\mathbb{P}(R=r_H \\mid G) $$\nThe problem defines subgroup calibration as $\\mathbb{E}[Y \\mid R=r, G] = r$. Since $Y$ is a Bernoulli variable ($Y \\in \\{0, 1\\}$), its conditional expectation is equal to the conditional probability of $Y=1$. Therefore, subgroup calibration implies:\n$$ \\mathbb{P}(Y=1 \\mid R=r, G) = r $$\nApplying this condition, we have $\\mathbb{P}(Y=1 \\mid R=r_L, G) = r_L$ and $\\mathbb{P}(Y=1 \\mid R=r_H, G) = r_H$.\n\nSubstituting these calibration conditions and the given score probabilities, $\\mathbb{P}(R=r_L \\mid G) = q_G$ and $\\mathbb{P}(R=r_H \\mid G) = 1-q_G$, into the equation for $p_G$:\n$$ p_G = r_L \\cdot q_G + r_H \\cdot (1 - q_G) $$\nThis equation establishes a direct relationship between the subgroup's base rate $p_G$ and its score distribution parameter $q_G$. We can now solve for $q_G$:\n$$ p_G = r_L q_G + r_H - r_H q_G $$\n$$ p_G - r_H = q_G (r_L - r_H) $$\n$$ q_G = \\frac{p_G - r_H}{r_L - r_H} = \\frac{-(r_H - p_G)}{-(r_H - r_L)} = \\frac{r_H - p_G}{r_H - r_L} $$\nThis expression for $q_G$ holds for both subgroups, $A$ and $B$.\n\nNow we can substitute the expressions for $q_A$ and $q_B$ back into our equation for $\\Delta$:\n$$ \\Delta = q_A - q_B = \\left( \\frac{r_H - p_A}{r_H - r_L} \\right) - \\left( \\frac{r_H - p_B}{r_H - r_L} \\right) $$\nCombining the terms over the common denominator:\n$$ \\Delta = \\frac{(r_H - p_A) - (r_H - p_B)}{r_H - r_L} = \\frac{r_H - p_A - r_H + p_B}{r_H - r_L} $$\n$$ \\Delta = \\frac{p_B - p_A}{r_H - r_L} $$\nThis general result demonstrates that for a subgroup-calibrated model with a two-point score distribution, the demographic parity gap under a single threshold is non-zero whenever the subgroup base rates are different ($p_A \\neq p_B$). Demographic parity ($\\Delta = 0$) is achieved only in the degenerate case where $p_A = p_B$.\n\nThe final step is to compute the numerical value of $\\Delta$ using the provided data:\n$r_L = 0.1$\n$r_H = 0.9$\n$p_A = 0.2$\n$p_B = 0.5$\n\nSubstituting these values into the derived formula for $\\Delta$:\n$$ \\Delta = \\frac{0.5 - 0.2}{0.9 - 0.1} = \\frac{0.3}{0.8} $$\nTo express this as a simplified fraction:\n$$ \\Delta = \\frac{3/10}{8/10} = \\frac{3}{8} $$", "answer": "$$\n\\boxed{\\frac{3}{8}}\n$$", "id": "4530653"}, {"introduction": "Theoretical conflicts in fairness become concrete problems when models are deployed in the real world. A common scenario involves using a single AI model, developed with a fixed decision threshold, across different hospitals or patient populations which may have varying disease prevalences. In this hands-on coding practice, you will build a simulation to quantify how these differences in prevalence cause disparities in clinical outcomes, even if the model's intrinsic error rates ($TPR$ and $FPR$) are the same for everyone [@problem_id:4530612]. By calculating differences in treatment rates, predictive accuracy, and clinical utility, you will gain a practical understanding of how an apparently unbiased model can lead to inequitable outcomes.", "problem": "You are asked to formalize and implement a deterministic simulation to quantify how small shifts in disease prevalence across two sites propagate to disparities in clinical decisions when a fixed operating point of a classifier is used. Assume a radiomics Artificial Intelligence (AI) model that outputs a binary decision $\\hat{Y} \\in \\{0,1\\}$ at a fixed threshold chosen once and then held constant across sites. Let $Y \\in \\{0,1\\}$ denote the true disease status. Denote by $S \\in \\{A,B\\}$ the site indicator. At the fixed operating point, assume site-invariant error rates: the True Positive Rate (TPR) is $tpr = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1,S=s)$ and the False Positive Rate (FPR) is $fpr = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0,S=s)$ for both $s \\in \\{A,B\\}$. Let the site-specific disease prevalence be $p_s = \\mathbb{P}(Y=1 \\mid S=s)$. The decision policy is to treat if and only if $\\hat{Y}=1$, so the treatment rate at site $s$ is $\\tau_s = \\mathbb{P}(\\hat{Y}=1 \\mid S=s)$. The Positive Predictive Value (PPV) at site $s$ is $\\pi_s = \\mathbb{P}(Y=1 \\mid \\hat{Y}=1,S=s)$. Consider a simple linear utility model per patient with benefit $b$ for each true positive treated and harm $h$ for each false positive treated. The expected net utility per patient at site $s$ is $u_s = b \\cdot \\mathbb{P}(Y=1,\\hat{Y}=1 \\mid S=s) - h \\cdot \\mathbb{P}(Y=0,\\hat{Y}=1 \\mid S=s)$.\n\nStarting only from the law of total probability and Bayesâ€™ theorem, derive formulas for $\\tau_s$, $\\pi_s$, and $u_s$ in terms of $p_s$, $tpr$, $fpr$, $b$, and $h$. Then, define three disparity metrics between sites $A$ and $B$:\n- the absolute difference in treatment rates $\\Delta_{\\tau} = \\lvert \\tau_A - \\tau_B \\rvert$,\n- the absolute difference in Positive Predictive Values $\\Delta_{\\pi} = \\lvert \\pi_A - \\pi_B \\rvert$,\n- the absolute difference in expected utility $\\Delta_{u} = \\lvert u_A - u_B \\rvert$.\n\nYour task is to implement a program that computes, for each test case, the vector $[\\Delta_{\\tau}, \\Delta_{\\pi}, \\Delta_{u}]$ as decimal numbers. If a denominator required to evaluate any expression is zero, define the corresponding fraction to be zero to avoid division by zero.\n\nThe program must use the following test suite, where each case is a tuple $(tpr, fpr, p_A, p_B, b, h)$:\n- Case $1$: $(0.85, 0.10, 0.20, 0.25, 1.0, 0.2)$,\n- Case $2$: $(0.85, 0.10, 0.20, 0.20, 1.0, 0.2)$,\n- Case $3$: $(0.90, 0.05, 0.02, 0.03, 1.0, 0.1)$,\n- Case $4$: $(0.95, 0.01, 0.50, 0.55, 1.0, 0.5)$,\n- Case $5$: $(0.70, 0.30, 0.98, 0.99, 1.0, 0.4)$,\n- Case $6$: $(0.00, 0.00, 0.40, 0.60, 1.0, 1.0)$,\n- Case $7$: $(0.80, 0.00, 0.10, 0.30, 1.0, 0.2)$.\n\nAll quantities must be treated as unitless probabilities or utilities; do not use percentage signs and do not introduce any physical units. Each output number must be rounded to exactly $6$ decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list of per-test-case vectors enclosed in square brackets, for example, $[[x_{11},x_{12},x_{13}],[x_{21},x_{22},x_{23}],\\dots]$, where each $x_{ij}$ is a float rounded to exactly $6$ decimals corresponding to $[\\Delta_{\\tau}, \\Delta_{\\pi}, \\Delta_{u}]$ for a test case.", "solution": "The problem statement has been analyzed and is determined to be valid. It is scientifically grounded in probability theory and its application to evaluating AI models, well-posed with all necessary information provided, and objective in its formulation. The task is to derive and implement formulas to quantify disparities in AI-driven clinical decisions arising from differences in disease prevalence between two sites.\n\nWe begin by deriving the required formulas for a generic site $s \\in \\{A, B\\}$, where all probabilities are implicitly conditioned on the site $S=s$. The given parameters are the site-specific disease prevalence $p_s = \\mathbb{P}(Y=1 \\mid S=s)$, the site-invariant True Positive Rate $tpr = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1)$, and the site-invariant False Positive Rate $fpr = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0)$. The utility parameters are a benefit $b$ for a true positive treatment and a harm $h$ for a false positive treatment.\n\n**1. Derivation of Treatment Rate ($\\tau_s$)**\n\nThe treatment rate at site $s$, $\\tau_s = \\mathbb{P}(\\hat{Y}=1 \\mid S=s)$, is the overall probability of a positive model prediction for a patient from that site. We derive this using the law of total probability by conditioning on the true disease status $Y \\in \\{0, 1\\}$.\n$$\n\\tau_s = \\mathbb{P}(\\hat{Y}=1 \\mid S=s) = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, S=s)\\mathbb{P}(Y=1 \\mid S=s) + \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, S=s)\\mathbb{P}(Y=0 \\mid S=s)\n$$\nSubstituting the provided definitions:\n- $\\mathbb{P}(\\hat{Y}=1 \\mid Y=1, S=s) = tpr$\n- $\\mathbb{P}(Y=1 \\mid S=s) = p_s$\n- $\\mathbb{P}(\\hat{Y}=1 \\mid Y=0, S=s) = fpr$\n- $\\mathbb{P}(Y=0 \\mid S=s) = 1 - p_s$\n\nWe obtain the expression for the treatment rate at site $s$:\n$$\n\\tau_s = tpr \\cdot p_s + fpr \\cdot (1 - p_s)\n$$\n\n**2. Derivation of Positive Predictive Value ($\\pi_s$)**\n\nThe Positive Predictive Value (PPV) at site $s$, $\\pi_s = \\mathbb{P}(Y=1 \\mid \\hat{Y}=1, S=s)$, is the probability that a patient with a positive prediction truly has the disease. We apply Bayes' theorem:\n$$\n\\pi_s = \\mathbb{P}(Y=1 \\mid \\hat{Y}=1, S=s) = \\frac{\\mathbb{P}(\\hat{Y}=1 \\mid Y=1, S=s) \\mathbb{P}(Y=1 \\mid S=s)}{\\mathbb{P}(\\hat{Y}=1 \\mid S=s)}\n$$\nThe numerator is $tpr \\cdot p_s$, and the denominator is the treatment rate $\\tau_s$ derived above.\n$$\n\\pi_s = \\frac{tpr \\cdot p_s}{tpr \\cdot p_s + fpr \\cdot (1 - p_s)} = \\frac{tpr \\cdot p_s}{\\tau_s}\n$$\nAs per the problem specification, if the denominator $\\tau_s$ is zero, we define $\\pi_s = 0$. This case arises if and only if $tpr=0$ (for $p_s>0$) and $fpr=0$ (for $1-p_s>0$), meaning the classifier never predicts positive, hence $\\mathbb{P}(\\hat{Y}=1 \\mid S=s)=0$.\n\n**3. Derivation of Expected Net Utility ($u_s$)**\n\nThe expected net utility per patient at site $s$ is defined as:\n$$\nu_s = b \\cdot \\mathbb{P}(Y=1, \\hat{Y}=1 \\mid S=s) - h \\cdot \\mathbb{P}(Y=0, \\hat{Y}=1 \\mid S=s)\n$$\nWe express the joint probabilities using the definition of conditional probability, $\\mathbb{P}(A, B \\mid C) = \\mathbb{P}(A \\mid B, C)\\mathbb{P}(B \\mid C)$.\nThe probability of a true positive treatment at site $s$ is:\n$$\n\\mathbb{P}(Y=1, \\hat{Y}=1 \\mid S=s) = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, S=s)\\mathbb{P}(Y=1 \\mid S=s) = tpr \\cdot p_s\n$$\nThe probability of a false positive treatment at site $s$ is:\n$$\n\\mathbb{P}(Y=0, \\hat{Y}=1 \\mid S=s) = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, S=s)\\mathbb{P}(Y=0 \\mid S=s) = fpr \\cdot (1 - p_s)\n$$\nSubstituting these into the utility formula yields:\n$$\nu_s = b \\cdot tpr \\cdot p_s - h \\cdot fpr \\cdot (1 - p_s)\n$$\n\n**4. Disparity Metrics**\n\nWith the formulas for $\\tau_s$, $\\pi_s$, and $u_s$ established for each site $s \\in \\{A, B\\}$, the disparity metrics are calculated as the absolute differences between the sites:\n- Absolute difference in treatment rates: $\\Delta_{\\tau} = \\lvert \\tau_A - \\tau_B \\rvert$\n- Absolute difference in Positive Predictive Values: $\\Delta_{\\pi} = \\lvert \\pi_A - \\pi_B \\rvert$\n- Absolute difference in expected utility: $\\Delta_{u} = \\lvert u_A - u_B \\rvert$\n\nThese formulas are implemented to compute the required vector $[\\Delta_{\\tau}, \\Delta_{\\pi}, \\Delta_{u}]$ for each specified test case.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates and prints disparity metrics for a series of test cases based on a\n    probabilistic model of AI-driven clinical decisions.\n    \"\"\"\n    test_cases = [\n        # (tpr, fpr, p_A, p_B, b, h)\n        (0.85, 0.10, 0.20, 0.25, 1.0, 0.2),\n        (0.85, 0.10, 0.20, 0.20, 1.0, 0.2),\n        (0.90, 0.05, 0.02, 0.03, 1.0, 0.1),\n        (0.95, 0.01, 0.50, 0.55, 1.0, 0.5),\n        (0.70, 0.30, 0.98, 0.99, 1.0, 0.4),\n        (0.00, 0.00, 0.40, 0.60, 1.0, 1.0),\n        (0.80, 0.00, 0.10, 0.30, 1.0, 0.2),\n    ]\n\n    def calculate_site_metrics(tpr, fpr, p, b, h):\n        \"\"\"\n        Calculates treatment rate, PPV, and expected utility for a single site.\n\n        Args:\n            tpr (float): True Positive Rate.\n            fpr (float): False Positive Rate.\n            p (float): Disease prevalence at the site.\n            b (float): Benefit for a true positive.\n            h (float): Harm for a false positive.\n\n        Returns:\n            tuple: A tuple containing (tau, pi, u).\n        \"\"\"\n        # Treatment Rate (tau_s)\n        tau = tpr * p + fpr * (1.0 - p)\n        \n        # Positive Predictive Value (pi_s)\n        # Handle division by zero as specified\n        if tau == 0.0:\n            pi = 0.0\n        else:\n            pi = (tpr * p) / tau\n            \n        # Expected Net Utility (u_s)\n        u = b * tpr * p - h * fpr * (1.0 - p)\n        \n        return tau, pi, u\n\n    all_results = []\n    for case in test_cases:\n        tpr, fpr, p_A, p_B, b, h = case\n        \n        # Calculate metrics for site A\n        tau_A, pi_A, u_A = calculate_site_metrics(tpr, fpr, p_A, b, h)\n        \n        # Calculate metrics for site B\n        tau_B, pi_B, u_B = calculate_site_metrics(tpr, fpr, p_B, b, h)\n        \n        # Calculate disparity metrics\n        delta_tau = np.abs(tau_A - tau_B)\n        delta_pi = np.abs(pi_A - pi_B)\n        delta_u = np.abs(u_A - u_B)\n        \n        result_vector = [delta_tau, delta_pi, delta_u]\n        all_results.append(result_vector)\n\n    # Format the output string as per the problem specification.\n    # Each number is rounded to 6 decimal places.\n    # The final output is a list of lists: [[v11,v12,v13],[v21,v22,v23],...]\n    formatted_results = []\n    for res_vec in all_results:\n        formatted_vec = [f\"{x:.6f}\" for x in res_vec]\n        formatted_results.append(f\"[{','.join(formatted_vec)}]\")\n        \n    final_output_string = f\"[{','.join(formatted_results)}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "4530612"}, {"introduction": "After identifying and quantifying bias, the next step is to mitigate it. This advanced practice moves from diagnosis to intervention, introducing a framework for making principled decisions that balance clinical effectiveness with fairness. You will work with the concept of Net Benefit from Decision Curve Analysis to quantify a model's clinical value and combine it with a fairness metric to create a single objective function [@problem_id:4530616]. By optimizing this function, you will learn a practical method for selecting different decision thresholds for different subgroups, navigating the complex trade-off between maximizing overall utility and ensuring that error rates are equitable across groups.", "problem": "You are given a stylized decision-making setting for Artificial Intelligence (AI) in radiomics, where a model outputs calibrated risk scores $r \\in [0,1]$ for patients, and a threshold-based rule of the form \"treat if $r \\ge t$\" is applied. For two demographic or clinical subgroups $s \\in \\{A,B\\}$, the conditional score distributions are modeled as independent Beta distributions for diseased and non-diseased populations. Specifically, for subgroup $s$, let the positive-class scores $R_{+}^{s}$ follow a Beta distribution with shape parameters $(\\alpha_{+}^{s}, \\beta_{+}^{s})$, and the negative-class scores $R_{-}^{s}$ follow a Beta distribution with shape parameters $(\\alpha_{-}^{s}, \\beta_{-}^{s})$. Let the disease prevalence be $\\pi^{s} \\in (0,1)$.\n\nFundamental basis to use:\n- The True Positive Rate (TPR) and False Positive Rate (FPR) for a threshold $t^{s}$ are defined by the survival functions of the conditional score distributions: $TPR^{s}(t^{s}) = \\mathbb{P}(R_{+}^{s} \\ge t^{s})$ and $FPR^{s}(t^{s}) = \\mathbb{P}(R_{-}^{s} \\ge t^{s})$.\n- The decision threshold probability $p_{t} \\in (0,1)$ encodes the trade-off between the clinical benefit of correctly treating a diseased patient and the clinical harm of treating a non-diseased patient; its interpretation must be derived from first principles of expected utility.\n- The notion of equalized odds fairness requires comparable error rates across subgroups; define a fairness loss for thresholds $(t^{A}, t^{B})$ that penalizes deviations in error rates across subgroups.\n\nTask:\n1. Derive, from the fundamental basis, a mathematically grounded expression for the net clinical benefit for a threshold-based policy in subgroup $s$, denoted $NB^{s}(t^{s}; p_{t})$, as a function of $\\pi^{s}$, $TPR^{s}(t^{s})$, $FPR^{s}(t^{s})$, and $p_{t}$. Your derivation must not invoke or assume the target expression; it must start from expected utility principles and the definition of $p_{t}$ as an indifference point between treating and not treating.\n2. Using the derived $NB^{s}(t^{s}; p_{t})$, define a composite objective that balances clinical utility and fairness across subgroups for a chosen threshold pair $(t^{A}, t^{B})$. Let the fairness loss be\n$$\nL(t^{A}, t^{B}) = \\left|TPR^{A}(t^{A}) - TPR^{B}(t^{B})\\right| + \\left|FPR^{A}(t^{A}) - FPR^{B}(t^{B})\\right|.\n$$\nLet $\\lambda \\ge 0$ be a fairness weight. Define the overall objective as\n$$\nJ(t^{A}, t^{B}; p_{t}, \\lambda) = \\frac{1}{2}\\left(NB^{A}(t^{A}; p_{t}) + NB^{B}(t^{B}; p_{t})\\right) - \\lambda \\, L(t^{A}, t^{B}).\n$$\n3. Implement a program that, for each test case below, evaluates $TPR^{s}(t)$ and $FPR^{s}(t)$ using the Beta cumulative distribution function, computes $NB^{s}(t; p_{t})$ via your derived expression, and performs a grid search over thresholds $t \\in \\{0.05, 0.10, 0.15, \\dots, 0.95\\}$ to find $(t^{A}, t^{B})$ that maximizes $J(t^{A}, t^{B}; p_{t}, \\lambda)$. If multiple pairs achieve the same maximal value of $J$, select the first encountered pair under lexicographic ordering of $(t^{A}, t^{B})$ when iterating the grid in ascending order.\n4. For each test case, output the following four quantities as decimals:\n- The optimal mean net benefit $\\frac{1}{2}\\left(NB^{A}(t^{A*}; p_{t}) + NB^{B}(t^{B*}; p_{t})\\right)$.\n- The corresponding fairness loss $L(t^{A*}, t^{B*})$.\n- The optimal threshold $t^{A*}$.\n- The optimal threshold $t^{B*}$.\nHere $(t^{A*}, t^{B*})$ denotes the threshold pair maximizing $J(t^{A}, t^{B}; p_{t}, \\lambda)$.\n\nAll probabilities, prevalences, and thresholds must be treated and expressed as decimals (not as percentages). There are no physical units. Angles are not involved.\n\nTest suite:\n- Case $1$ (happy path, moderate separability, balanced prevalence):\n  - Subgroup $A$: $(\\alpha_{+}^{A}, \\beta_{+}^{A}) = (5, 2)$, $(\\alpha_{-}^{A}, \\beta_{-}^{A}) = (2, 5)$, $\\pi^{A} = 0.3$.\n  - Subgroup $B$: $(\\alpha_{+}^{B}, \\beta_{+}^{B}) = (4, 3)$, $(\\alpha_{-}^{B}, \\beta_{-}^{B}) = (3, 4)$, $\\pi^{B} = 0.3$.\n  - Threshold probability $p_{t} = 0.25$, fairness weight $\\lambda = 0.5$.\n- Case $2$ (prevalence disparity, similar class-conditional distributions):\n  - Subgroup $A$: $(\\alpha_{+}^{A}, \\beta_{+}^{A}) = (3, 3)$, $(\\alpha_{-}^{A}, \\beta_{-}^{A}) = (2, 5)$, $\\pi^{A} = 0.5$.\n  - Subgroup $B$: $(\\alpha_{+}^{B}, \\beta_{+}^{B}) = (3, 3)$, $(\\alpha_{-}^{B}, \\beta_{-}^{B}) = (2, 5)$, $\\pi^{B} = 0.1$.\n  - Threshold probability $p_{t} = 0.2$, fairness weight $\\lambda = 1.0$.\n- Case $3$ (strong fairness weight, asymmetric separability):\n  - Subgroup $A$: $(\\alpha_{+}^{A}, \\beta_{+}^{A}) = (6, 2)$, $(\\alpha_{-}^{A}, \\beta_{-}^{A}) = (2, 6)$, $\\pi^{A} = 0.25$.\n  - Subgroup $B$: $(\\alpha_{+}^{B}, \\beta_{+}^{B}) = (2.5, 2.5)$, $(\\alpha_{-}^{B}, \\beta_{-}^{B}) = (2.5, 2.5)$, $\\pi^{B} = 0.25$.\n  - Threshold probability $p_{t} = 0.4$, fairness weight $\\lambda = 10.0$.\n- Case $4$ (low threshold probability, different separabilities, equal prevalence):\n  - Subgroup $A$: $(\\alpha_{+}^{A}, \\beta_{+}^{A}) = (7, 3)$, $(\\alpha_{-}^{A}, \\beta_{-}^{A}) = (3, 7)$, $\\pi^{A} = 0.2$.\n  - Subgroup $B$: $(\\alpha_{+}^{B}, \\beta_{+}^{B}) = (5, 5)$, $(\\alpha_{-}^{B}, \\beta_{-}^{B}) = (5, 5)$, $\\pi^{B} = 0.2$.\n  - Threshold probability $p_{t} = 0.05$, fairness weight $\\lambda = 0.0$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the four cases as a comma-separated list of four inner lists, each inner list containing the four quantities in the order specified above. The exact format is\n$$\n\\text{[}[mnb_{1},fl_{1},tA_{1},tB_{1}],[mnb_{2},fl_{2},tA_{2},tB_{2}],[mnb_{3},fl_{3},tA_{3},tB_{3}],[mnb_{4},fl_{4},tA_{4},tB_{4}]\\text{]},\n$$\nwhere $mnb_{i}$ is the mean net benefit, $fl_{i}$ is the fairness loss, and $tA_{i}, tB_{i}$ are the optimal thresholds for subgroups $A$ and $B$ respectively, all expressed as decimals. Round $mnb_{i}$ and $fl_{i}$ to $6$ decimal places and report $tA_{i}$ and $tB_{i}$ to $2$ decimal places.", "solution": "The problem is assessed to be valid. It is scientifically grounded in statistical decision theory and the study of algorithmic fairness, is well-posed with a clear objective and constraints, and is specified using precise, objective mathematical language. We may therefore proceed with the solution.\n\n### Part 1: Derivation of the Net Benefit Expression\n\nThe first task is to derive the expression for Net Benefit, $NB^{s}(t^{s}; p_{t})$, from first principles of expected utility theory. Net Benefit quantifies the clinical value of a decision-making policy on a scale that is comparable across different models and populations.\n\nLet us consider a single patient from subgroup $s$. We drop the superscript $s$ for notational clarity during the derivation. There are four possible outcomes when applying a treatment decision (Treat or Not Treat) to a patient who is either Diseased (D) or Not Diseased (ND):\n\\begin{itemize}\n    \\item True Positive (TP): Treat a diseased patient. Utility: $U_{TP}$.\n    \\item False Positive (FP): Treat a non-diseased patient. Utility: $U_{FP}$.\n    \\item True Negative (TN): Do not treat a non-diseased patient. Utility: $U_{TN}$.\n    \\item False Negative (FN): Do not treat a diseased patient. Utility: $U_{FN}$.\n\\end{itemize}\nWe assume that correctly treating a diseased patient is most preferable ($U_{TP}$) and correctly withholding treatment from a non-diseased patient is also beneficial ($U_{TN}$). Incorrect decisions lead to lower utility. Specifically, we assume $U_{TP} > U_{FN}$ and $U_{TN} > U_{FP}$.\n\nThe decision threshold probability, $p_t$, is defined as the probability of disease at which a clinician would be indifferent between treating and not treating the patient. At this indifference point, the expected utility of treating equals the expected utility of not treating. For an individual with disease probability $p_t$, we have:\n$$\n\\mathbb{E}[\\text{Utility} | \\text{Treat}] = p_t \\cdot U_{TP} + (1 - p_t) \\cdot U_{FP}\n$$\n$$\n\\mathbb{E}[\\text{Utility} | \\text{Not Treat}] = p_t \\cdot U_{FN} + (1 - p_t) \\cdot U_{TN}\n$$\nEquating these two expressions gives:\n$$\np_t \\cdot U_{TP} + (1 - p_t) \\cdot U_{FP} = p_t \\cdot U_{FN} + (1 - p_t) \\cdot U_{TN}\n$$\nRearranging the terms to group by $p_t$:\n$$\np_t (U_{TP} - U_{FN}) = (1 - p_t) (U_{TN} - U_{FP})\n$$\nLet's define the net gain from a true positive decision as $\\Delta B = U_{TP} - U_{FN}$ and the net loss (cost) from a false positive decision as $\\Delta C = U_{TN} - U_{FP}$. Both $\\Delta B$ and $\\Delta C$ are positive quantities. The equation becomes:\n$$\np_t \\cdot \\Delta B = (1 - p_t) \\cdot \\Delta C\n$$\nThis yields the fundamental relationship between the threshold probability $p_t$ and the utility-based cost-benefit ratio:\n$$\n\\frac{\\Delta C}{\\Delta B} = \\frac{p_t}{1 - p_t}\n$$\nThis ratio quantifies the trade-off: for every one unit of benefit from a true positive, we are willing to accept $\\frac{p_t}{1-p_t}$ units of cost from a false positive.\n\nNow, we derive the Net Benefit for a population (subgroup $s$) with disease prevalence $\\pi^s$. A policy using a decision threshold $t^s$ will have a true positive rate $TPR^s(t^s)$ and a false positive rate $FPR^s(t^s)$. The probabilities of the four outcomes are:\n\\begin{itemize}\n    \\item $\\mathbb{P}(\\text{TP}) = \\pi^s \\cdot TPR^s(t^s)$\n    \\item $\\mathbb{P}(\\text{FN}) = \\pi^s \\cdot (1 - TPR^s(t^s))$\n    \\item $\\mathbb{P}(\\text{FP}) = (1 - \\pi^s) \\cdot FPR^s(t^s)$\n    \\item $\\mathbb{P}(\\text{TN}) = (1 - \\pi^s) \\cdot (1 - FPR^s(t^s))$\n\\end{itemize}\nThe average utility of applying this policy is:\n$$\n\\mathbb{E}[U(t^s)] = \\mathbb{P}(\\text{TP}) U_{TP} + \\mathbb{P}(\\text{FN}) U_{FN} + \\mathbb{P}(\\text{FP}) U_{FP} + \\mathbb{P}(\\text{TN}) U_{TN}\n$$\nNet Benefit is defined as the improvement in average utility over a default strategy, typically \"treat none\". The average utility of the \"treat none\" policy is:\n$$\n\\mathbb{E}[U(\\text{none})] = \\pi^s U_{FN} + (1 - \\pi^s) U_{TN}\n$$\nThe difference in utility is:\n$$\n\\mathbb{E}[U(t^s)] - \\mathbb{E}[U(\\text{none})] = \\pi^s TPR^s(t^s) (U_{TP} - U_{FN}) - (1 - \\pi^s) FPR^s(t^s) (U_{TN} - U_{FP})\n$$\nSubstituting $\\Delta B$ and $\\Delta C$:\n$$\n\\text{Utility Gain} = \\pi^s TPR^s(t^s) \\Delta B - (1 - \\pi^s) FPR^s(t^s) \\Delta C\n$$\nBy convention, Net Benefit is expressed in units of true positive benefits. We achieve this by dividing the utility gain by $\\Delta B$:\n$$\nNB^s(t^s) = \\frac{\\text{Utility Gain}}{\\Delta B} = \\pi^s TPR^s(t^s) - (1 - \\pi^s) FPR^s(t^s) \\frac{\\Delta C}{\\Delta B}\n$$\nFinally, we substitute the cost-benefit ratio with its expression in terms of $p_t$:\n$$\nNB^s(t^s; p_t) = \\pi^s \\cdot TPR^s(t^s) - (1 - \\pi^s) \\cdot FPR^s(t^s) \\cdot \\frac{p_t}{1 - p_t}\n$$\nThis is the derived, mathematically grounded expression for Net Benefit for subgroup $s$ as a function of its prevalence, error rates, and the decision threshold probability.\n\n### Part 2 & 3: Algorithmic Solution Design\n\nThe problem requires maximizing the objective function $J(t^{A}, t^{B}; p_{t}, \\lambda)$ over a discrete grid of thresholds.\n$$\nJ(t^{A}, t^{B}; p_{t}, \\lambda) = \\frac{1}{2}\\left(NB^{A}(t^{A}; p_{t}) + NB^{B}(t^{B}; p_{t})\\right) - \\lambda \\left( \\left|TPR^{A}(t^{A}) - TPR^{B}(t^{B})\\right| + \\left|FPR^{A}(t^{A}) - FPR^{B}(t^{B})\\right| \\right)\n$$\nThe solution proceeds as follows:\n1.  **Define the Grid**: The search space for thresholds is $t \\in \\{0.05, 0.10, \\dots, 0.95\\}$. We create a discrete grid for the pair $(t^A, t^B)$ of size $19 \\times 19$.\n2.  **Calculate Error Rates**: For each subgroup $s \\in \\{A, B\\}$ and for each threshold $t$ in the grid, we calculate the $TPR^s(t)$ and $FPR^s(t)$. These are computed using the survival function (1 - CDF) of the Beta distribution, which is available in scientific computing libraries.\n    $$ TPR^s(t) = \\mathbb{P}(R_+^s \\ge t) = 1 - F_{Beta(\\alpha_+^s, \\beta_+^s)}(t) $$\n    $$ FPR^s(t) = \\mathbb{P}(R_-^s \\ge t) = 1 - F_{Beta(\\alpha_-^s, \\beta_-^s)}(t) $$\n    To optimize the computation, these values are pre-calculated for all subgroups and all possible thresholds and stored, for instance, in dictionaries.\n3.  **Grid Search**: We iterate through every pair of thresholds $(t^A, t^B)$ from the grid. The iteration order is lexicographical, with $t^A$ as the outer loop and $t^B$ as the inner loop, both in ascending order.\n4.  **Evaluate Objective Function**: For each pair $(t^A, t^B)$:\n    a. We retrieve the pre-calculated $TPR^A, FPR^A, TPR^B, FPR^B$.\n    b. We calculate $NB^A(t^A; p_t)$ and $NB^B(t^B; p_t)$ using the derived formula.\n    c. We calculate the mean net benefit component: $\\frac{1}{2}(NB^A + NB^B)$.\n    d. We calculate the fairness loss component: $L(t^A, t^B)$.\n    e. We combine these to compute the total objective value $J(t^A, t^B)$.\n5.  **Identify Maximum**: We maintain a variable for the maximum value of $J$ found so far, along with the corresponding thresholds $(t^A, t^B)$ and the associated metric values (mean net benefit and fairness loss). We update these whenever a strictly greater value of $J$ is found. The specified iteration order and the use of a strict inequality (`>`) for updates ensure that the first pair encountered in lexicographical order that achieves the maximum value is selected, satisfying the tie-breaking rule.\n6.  **Store and format results**: After the grid search is complete for a given test case, the optimal mean net benefit, fairness loss, $t^A$, and $t^B$ are formatted according to the specified rounding rules and stored. This process is repeated for all test cases.\n\n### Part 4: Final Output Generation\nAfter processing all test cases, the collected results are assembled into a single string with the specified format `[[mnb1,fl1,tA1,tB1],[mnb2,fl2,tA2,tB2],...]`.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta\n\ndef solve():\n    \"\"\"\n    Solves the radiomics AI fairness problem by performing a grid search\n    to optimize a composite objective function balancing clinical utility\n    and fairness.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {   # Case 1\n            \"A\": {\"alpha_p\": 5.0, \"beta_p\": 2.0, \"alpha_n\": 2.0, \"beta_n\": 5.0, \"pi\": 0.3},\n            \"B\": {\"alpha_p\": 4.0, \"beta_p\": 3.0, \"alpha_n\": 3.0, \"beta_n\": 4.0, \"pi\": 0.3},\n            \"pt\": 0.25,\n            \"lambda\": 0.5\n        },\n        {   # Case 2\n            \"A\": {\"alpha_p\": 3.0, \"beta_p\": 3.0, \"alpha_n\": 2.0, \"beta_n\": 5.0, \"pi\": 0.5},\n            \"B\": {\"alpha_p\": 3.0, \"beta_p\": 3.0, \"alpha_n\": 2.0, \"beta_n\": 5.0, \"pi\": 0.1},\n            \"pt\": 0.2,\n            \"lambda\": 1.0\n        },\n        {   # Case 3\n            \"A\": {\"alpha_p\": 6.0, \"beta_p\": 2.0, \"alpha_n\": 2.0, \"beta_n\": 6.0, \"pi\": 0.25},\n            \"B\": {\"alpha_p\": 2.5, \"beta_p\": 2.5, \"alpha_n\": 2.5, \"beta_n\": 2.5, \"pi\": 0.25},\n            \"pt\": 0.4,\n            \"lambda\": 10.0\n        },\n        {   # Case 4\n            \"A\": {\"alpha_p\": 7.0, \"beta_p\": 3.0, \"alpha_n\": 3.0, \"beta_n\": 7.0, \"pi\": 0.2},\n            \"B\": {\"alpha_p\": 5.0, \"beta_p\": 5.0, \"alpha_n\": 5.0, \"beta_n\": 5.0, \"pi\": 0.2},\n            \"pt\": 0.05,\n            \"lambda\": 0.0\n        }\n    ]\n\n    # Create the grid of thresholds.\n    # Using np.round to avoid floating point inaccuracies.\n    thresholds = np.round(np.arange(0.05, 0.95 + 0.01, 0.05), 2)\n    \n    all_case_results = []\n\n    for case in test_cases:\n        pt = case[\"pt\"]\n        lambda_val = case[\"lambda\"]\n        cost_benefit_ratio = pt / (1.0 - pt)\n        \n        params_A = case[\"A\"]\n        params_B = case[\"B\"]\n\n        # Pre-calculate TPR and FPR for all thresholds to optimize the grid search.\n        tpr_A = {t: beta.sf(t, params_A[\"alpha_p\"], params_A[\"beta_p\"]) for t in thresholds}\n        fpr_A = {t: beta.sf(t, params_A[\"alpha_n\"], params_A[\"beta_n\"]) for t in thresholds}\n        tpr_B = {t: beta.sf(t, params_B[\"alpha_p\"], params_B[\"beta_p\"]) for t in thresholds}\n        fpr_B = {t: beta.sf(t, params_B[\"alpha_n\"], params_B[\"beta_n\"]) for t in thresholds}\n\n        # Pre-calculate Net Benefit for all thresholds.\n        nb_A = {t: params_A[\"pi\"] * tpr_A[t] - (1 - params_A[\"pi\"]) * fpr_A[t] * cost_benefit_ratio for t in thresholds}\n        nb_B = {t: params_B[\"pi\"] * tpr_B[t] - (1 - params_B[\"pi\"]) * fpr_B[t] * cost_benefit_ratio for t in thresholds}\n\n        max_J = -np.inf\n        # Initialize placeholders for optimal values.\n        best_tA, best_tB = -1.0, -1.0\n        best_mean_nb, best_fairness_loss = -1.0, -1.0\n        \n        # Perform grid search.\n        # The loop order ensures lexicographical tie-breaking.\n        for tA in thresholds:\n            for tB in thresholds:\n                # Calculate components of the objective function J.\n                mean_nb = 0.5 * (nb_A[tA] + nb_B[tB])\n                \n                fairness_loss = abs(tpr_A[tA] - tpr_B[tB]) + abs(fpr_A[tA] - fpr_B[tB])\n                \n                current_J = mean_nb - lambda_val * fairness_loss\n                \n                # Update if a better objective value is found.\n                if current_J > max_J:\n                    max_J = current_J\n                    best_tA = tA\n                    best_tB = tB\n                    best_mean_nb = mean_nb\n                    best_fairness_loss = fairness_loss\n\n        # Format the results for the current case.\n        result_str = (\n            f\"[{round(best_mean_nb, 6)},\"\n            f\"{round(best_fairness_loss, 6)},\"\n            f\"{best_tA:.2f},\"\n            f\"{best_tB:.2f}]\"\n        )\n        all_case_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_case_results)}]\")\n\nsolve()\n```", "id": "4530616"}]}