{"hands_on_practices": [{"introduction": "While federated learning avoids direct data sharing, it introduces communication as a potential bottleneck. This practice delves into the core mechanics of communication efficiency by analyzing how techniques like sparsification and quantization impact the overall training time. By working through this hypothetical scenario [@problem_id:4540789], you will learn to calculate the communication cost from first principles and appreciate how the slowest participant, or 'straggler,' dictates the pace of synchronous training.", "problem": "A multi-center radiomics study is training a predictive model using Federated Learning (FL), where each of $m$ centers transmits sparse model updates to a central server and receives the aggregated global model each round. Let the global model have $d$ trainable parameters. Each client applies top-$k$ sparsification to its local update, transmitting only the $k$ largest-magnitude parameter updates, and uses $8$-bit quantization for all transmitted values. To identify which parameters are selected under top-$k$, assume fixed-length binary coding for indices with minimal length $\\lceil \\log_{2}(d) \\rceil$ bits per index. Each uplink message includes a constant metadata header of $h_{\\text{up}}$ bits, and each downlink message includes a constant metadata header of $h_{\\text{down}}$ bits.\n\nFor a synchronous FL round, the wall-clock duration is determined by the slowest center. Assume there are $m = 8$ centers, of which $7$ have an uplink bandwidth of $12 \\times 10^{6}$ bits per second and a downlink bandwidth of $24 \\times 10^{6}$ bits per second, and $1$ constrained center has an uplink bandwidth of $6 \\times 10^{6}$ bits per second and a downlink bandwidth of $8 \\times 10^{6}$ bits per second. The one-way network latency is $L = 0.025$ seconds, and each round consists of one uplink transmission and one downlink transmission, incurring a total latency of $2L$. Ignore server computation time and any parallelization effects on downlink beyond the per-client bandwidth constraint.\n\nStarting from first principles of information representation and network throughput, derive the communication cost per client in bits for the uplink under top-$k$ sparsification with $8$-bit quantization and fixed-length index coding, and for the downlink when broadcasting the full quantized model. Then, using the constrained center’s bandwidths, calculate the per-round wall-clock time. Use the following parameters: $d = 1{,}000{,}000$, $k = 50{,}000$, $h_{\\text{up}} = 1024$ bits, $h_{\\text{down}} = 512$ bits. Express the final wall-clock time in seconds, and round your answer to three significant figures.", "solution": "The problem statement is subjected to rigorous validation.\n\n### Step 1: Extract Givens\nThe data and conditions explicitly provided are:\n-   Number of centers, $m = 8$.\n-   Total number of trainable parameters in the global model, $d = 1,000,000$.\n-   Sparsification parameter, $k = 50,000$.\n-   Quantization level for transmitted values, $b_{\\text{val}} = 8$ bits.\n-   Index coding scheme: fixed-length binary with size $b_{\\text{idx}} = \\lceil \\log_{2}(d) \\rceil$ bits per index.\n-   Uplink metadata header size, $h_{\\text{up}} = 1024$ bits.\n-   Downlink metadata header size, $h_{\\text{down}} = 512$ bits.\n-   Number of normal centers: $7$.\n-   Uplink bandwidth of normal centers, $B_{\\text{up, normal}} = 12 \\times 10^{6}$ bits per second.\n-   Downlink bandwidth of normal centers, $B_{\\text{down, normal}} = 24 \\times 10^{6}$ bits per second.\n-   Number of constrained centers: $1$.\n-   Uplink bandwidth of constrained center, $B_{\\text{up, constrained}} = 6 \\times 10^{6}$ bits per second.\n-   Downlink bandwidth of constrained center, $B_{\\text{down, constrained}} = 8 \\times 10^{6}$ bits per second.\n-   One-way network latency, $L = 0.025$ seconds.\n-   Total latency per round (one uplink and one downlink), $T_{\\text{latency}} = 2L$.\n-   The training is synchronous, and the total round time is determined by the slowest center.\n-   Server computation time is to be ignored.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established criteria:\n-   **Scientifically Grounded:** The problem is firmly rooted in the principles of communication-efficient federated learning, a standard topic in distributed machine learning and computer science. The use of top-$k$ sparsification, quantization, bandwidth, and latency are all standard, well-defined concepts. The setup is scientifically and technically sound.\n-   **Well-Posed:** All necessary variables and parameters for calculating the communication cost and time are provided. The objective is clear and unambiguous: to compute the wall-clock time for a single synchronous round, limited by the most resource-constrained client. The problem structure guarantees a unique and meaningful solution.\n-   **Objective:** The problem is described using precise, quantitative, and unbiased language.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is self-contained, scientifically sound, and well-posed. No flaws were detected. We may now proceed with the solution.\n\nThe objective is to calculate the per-round wall-clock time, $T_{\\text{round}}$, for a synchronous Federated Learning process. In a synchronous setting, the duration of each round is determined by the participant that takes the longest time to complete its tasks. This is the \"straggler\" or, in this case, the \"constrained center\". The total time for one round consists of the network latency and the data transmission time.\n\nThe total round time $T_{\\text{round}}$ is given by:\n$$T_{\\text{round}} = T_{\\text{latency}} + T_{\\text{transmission}}$$\nThe total latency for a round involving one uplink and one downlink is given as $T_{\\text{latency}} = 2L$. The total transmission time is the sum of the uplink time, $T_{\\text{up}}$, and the downlink time, $T_{\\text{down}}$, for the constrained center.\n$$T_{\\text{round}} = 2L + T_{\\text{up}} + T_{\\text{down}}$$\nWe must calculate $T_{\\text{up}}$ and $T_{\\text{down}}$ from first principles.\n\n**1. Uplink Communication Cost and Time**\n\nThe uplink transmission from a client consists of a metadata header and the payload. The payload contains the top-$k$ sparsified model updates. Each update comprises the value of the parameter change and its corresponding index.\n\nThe total size of the uplink message, $S_{\\text{up}}$, is:\n$$S_{\\text{up}} = h_{\\text{up}} + S_{\\text{payload, up}}$$\nThe payload size, $S_{\\text{payload, up}}$, corresponds to $k$ updates. The size of each update is the sum of the bits for the index and the bits for the quantized value.\n-   The size of each quantized value is given as $b_{\\text{val}} = 8$ bits.\n-   The size of each index, $b_{\\text{idx}}$, is determined by the minimum number of bits required to uniquely identify any of the $d$ parameters using fixed-length coding. This is calculated as:\n$$b_{\\text{idx}} = \\lceil \\log_{2}(d) \\rceil$$\nSubstituting $d = 1,000,000$:\n$$b_{\\text{idx}} = \\lceil \\log_{2}(10^6) \\rceil = \\lceil 6 \\log_{2}(10) \\rceil$$\nUsing the approximation $\\log_{2}(10) \\approx 3.3219$:\n$$b_{\\text{idx}} = \\lceil 6 \\times 3.3219 \\rceil = \\lceil 19.9314 \\rceil = 20 \\text{ bits}$$\nEach of the $k$ updates requires $(b_{\\text{idx}} + b_{\\text{val}})$ bits. The total uplink payload size is:\n$$S_{\\text{payload, up}} = k \\times (b_{\\text{idx}} + b_{\\text{val}})$$\nSubstituting the values $k = 50,000$, $b_{\\text{idx}}=20$, and $b_{\\text{val}}=8$:\n$$S_{\\text{payload, up}} = 50,000 \\times (20 + 8) = 50,000 \\times 28 = 1,400,000 \\text{ bits}$$\nThe total uplink message size, including the header $h_{\\text{up}} = 1024$ bits, is:\n$$S_{\\text{up}} = 1024 + 1,400,000 = 1,401,024 \\text{ bits}$$\nThe uplink transmission time for the constrained center, $T_{\\text{up}}$, is this size divided by its uplink bandwidth, $B_{\\text{up, constrained}} = 6 \\times 10^{6}$ bits/s:\n$$T_{\\text{up}} = \\frac{S_{\\text{up}}}{B_{\\text{up, constrained}}} = \\frac{1,401,024}{6 \\times 10^{6}} \\text{ seconds}$$\n\n**2. Downlink Communication Cost and Time**\n\nThe downlink transmission from the server to each client consists of a metadata header and the full, dense global model. The problem specifies this is a \"full quantized model\", which we interpret as all $d$ parameters being quantized to $b_{\\text{val}}$ bits each. Since the model is dense, indices are not needed; the position of each parameter is implicit.\n\nThe total size of the downlink message, $S_{\\text{down}}$, is:\n$$S_{\\text{down}} = h_{\\text{down}} + S_{\\text{payload, down}}$$\nThe payload consists of $d$ quantized parameter values:\n$$S_{\\text{payload, down}} = d \\times b_{\\text{val}}$$\nSubstituting the values $d = 1,000,000$ and $b_{\\text{val}} = 8$:\n$$S_{\\text{payload, down}} = 1,000,000 \\times 8 = 8,000,000 \\text{ bits}$$\nThe total downlink message size, including the header $h_{\\text{down}} = 512$ bits, is:\n$$S_{\\text{down}} = 512 + 8,000,000 = 8,000,512 \\text{ bits}$$\nThe downlink transmission time for the constrained center, $T_{\\text{down}}$, is this size divided by its downlink bandwidth, $B_{\\text{down, constrained}} = 8 \\times 10^{6}$ bits/s:\n$$T_{\\text{down}} = \\frac{S_{\\text{down}}}{B_{\\text{down, constrained}}} = \\frac{8,000,512}{8 \\times 10^{6}} \\text{ seconds}$$\n\n**3. Total Wall-Clock Time**\n\nNow we assemble the components to find the total round time, $T_{\\text{round}}$.\n$$T_{\\text{round}} = 2L + T_{\\text{up}} + T_{\\text{down}}$$\nSubstituting the given and derived expressions:\n$$T_{\\text{round}} = (2 \\times 0.025) + \\frac{1,401,024}{6 \\times 10^{6}} + \\frac{8,000,512}{8 \\times 10^{6}}$$\nCalculating each term:\n-   Latency: $T_{\\text{latency}} = 2 \\times 0.025 = 0.05$ s.\n-   Uplink Time: $T_{\\text{up}} = \\frac{1,401,024}{6,000,000} \\approx 0.233504$ s.\n-   Downlink Time: $T_{\\text{down}} = \\frac{8,000,512}{8,000,000} = 1.000064$ s.\n\nSumming these terms:\n$$T_{\\text{round}} \\approx 0.05 + 0.233504 + 1.000064 = 1.283568 \\text{ s}$$\nThe problem requires the answer to be rounded to three significant figures.\n$$T_{\\text{round}} \\approx 1.28 \\text{ s}$$", "answer": "$$\n\\boxed{1.28}\n$$", "id": "4540789"}, {"introduction": "A major challenge in multi-center studies is data heterogeneity, where data characteristics differ across institutions. This exercise tackles a common form of this challenge known as 'label distribution shift' [@problem_id:4540746]. You will derive and apply an importance weighting scheme to correct for biases introduced by differing class prevalence, and conceptualize how this can be achieved without compromising privacy through secure aggregation.", "problem": "A radiomics classification study is being conducted across two clinical centers using Federated Learning (FL). Assume the scenario satisfies label shift: for all centers $k \\in \\{1,2\\}$ and classes $y \\in \\{0,1\\}$, the conditional distribution of radiomic features given the class is identical across centers, that is $p_{k}(x \\mid y) = p(x \\mid y)$, while the class priors $p_{k}(y)$ may differ by center. The goal is to train a single classifier with cross-entropy loss that is appropriate for the global population mixture characterized by a target prior $p(y)$.\n\nYou are asked to derive, from first principles, a correction scheme that reweights the per-center contributions so that the weighted empirical risk computed at each center under label shift equals the global risk under the target prior. Then propose a privacy-preserving protocol, relying on Secure Aggregation (SA), by which the target prior can be estimated without revealing any center’s individual label counts.\n\nConstruct the following synthetic example consistent with the scenario:\n- Center $1$ has $n_{1} = 800$ labeled patients, with $560$ malignant cases ($y=1$) and $240$ benign cases ($y=0$), so $p_{1}(1) = 0.7$ and $p_{1}(0) = 0.3$.\n- Center $2$ has $n_{2} = 1200$ labeled patients, with $360$ malignant cases ($y=1$) and $840$ benign cases ($y=0$), so $p_{2}(1) = 0.3$ and $p_{2}(0) = 0.7$.\n\nUsing only the assumption $p_{k}(x \\mid y) = p(x \\mid y)$ and the definition of cross-entropy risk, derive the unique class-dependent weights per center that produce an unbiased estimate of the global cross-entropy risk under the mixture prior $p(y)$, where $p(y)$ must be computed from the aggregated sample across centers via Secure Aggregation of one-hot label counts. Then, for the synthetic example, compute the numerical values of these weights for both centers and both classes.\n\nExpress your final numerical weights in a row matrix in the order $\\left(\\beta_{1}(0), \\beta_{1}(1), \\beta_{2}(0), \\beta_{2}(1)\\right)$ and round your answer to four significant figures.", "solution": "The problem is scientifically grounded, well-posed, and objective. It describes a realistic scenario in federated learning for medical imaging, known as label distribution shift, and asks for a standard correction method (importance sampling) and a privacy-preserving computation protocol (Secure Aggregation). The premises are consistent and the data provided is sufficient for a unique solution. Therefore, the problem is valid and I will proceed with a full solution.\n\nThe objective is to train a model with parameters $\\theta$ by minimizing a global risk function $R(\\theta)$, which is the expected loss over the target global data distribution $p(x, y)$. The loss function is the cross-entropy loss, $L(y, f(x; \\theta))$, where $f(x; \\theta)$ is the model's predicted probability for class $y=1$. The global risk is:\n$$R(\\theta) = \\mathbb{E}_{p(x,y)}[L(y, f(x; \\theta))]$$\nBy the law of total expectation, we can write the risk as a sum over the classes $y \\in \\{0,1\\}$:\n$$R(\\theta) = \\sum_{y \\in \\{0,1\\}} p(y) \\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$$\nwhere $p(y)$ is the target global class prior and $p(x|y)$ is the class-conditional feature distribution.\n\nIn the federated setting, each center $k$ has its own local data distribution, $p_k(x, y)$. The local risk at center $k$ is:\n$$R_k(\\theta) = \\mathbb{E}_{p_k(x,y)}[L(y, f(x; \\theta))]$$\nThe problem states the label shift assumption, which posits that the class-conditional distributions are identical across centers, i.e., $p_k(x|y) = p(x|y)$ for all $k$. The local class priors $p_k(y)$ may differ. Under this assumption, the local risk can be written as:\n$$R_k(\\theta) = \\sum_{y \\in \\{0,1\\}} p_k(y) \\mathbb{E}_{p_k(x|y)}[L(y, f(x; \\theta))] = \\sum_{y \\in \\{0,1\\}} p_k(y) \\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$$\nWe seek a reweighting scheme with weights $\\beta_k(y)$ applied to the loss of each sample from center $k$ with label $y$, such that the expectation of the weighted local loss equals the global risk. Let this weighted local risk be $R_k^w(\\theta)$.\n$$R_k^w(\\theta) = \\mathbb{E}_{p_k(x,y)}[\\beta_k(y) L(y, f(x; \\theta))]$$\nExpanding this expectation:\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\int \\beta_k(y) L(y, f(x; \\theta)) p_k(x,y) dx$$\nUsing $p_k(x,y) = p_k(y)p_k(x|y) = p_k(y)p(x|y)$:\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\int \\beta_k(y) L(y, f(x; \\theta)) p_k(y) p(x|y) dx$$\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\beta_k(y) p_k(y) \\int L(y, f(x; \\theta)) p(x|y) dx$$\n$$R_k^w(\\theta) = \\sum_{y \\in \\{0,1\\}} \\beta_k(y) p_k(y) \\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$$\nFor this weighted local risk to equal the global risk $R(\\theta)$ for any model $f(x; \\theta)$, the coefficients of the terms $\\mathbb{E}_{p(x|y)}[L(y, f(x; \\theta))]$ must be equal. Thus, for each class $y$, we must have:\n$$\\beta_k(y) p_k(y) = p(y)$$\nThis uniquely defines the correction weight for a sample from class $y$ at center $k$ as:\n$$\\beta_k(y) = \\frac{p(y)}{p_k(y)}$$\nThis is the principle of importance sampling applied to the label shift scenario. In practice, the empirical risk at center $k$ is calculated as a weighted average: $\\hat{R}_k^w(\\theta) = \\frac{1}{n_k} \\sum_{i=1}^{n_k} \\beta_k(y_i) L(y_i, f(x_i; \\theta))$. An FL algorithm like FedAvg would then average the gradients of this weighted risk across centers.\n\nTo compute these weights, the centers need the global prior $p(y)$ and their local priors $p_k(y)$. The local priors can be computed privately by each center. To compute the global prior $p(y) = \\frac{\\sum_k n_k(y)}{\\sum_k n_k}$ without revealing the local counts $n_k(y)$, a Secure Aggregation (SA) protocol is used. Here is a proposal for such a protocol:\n1.  **Local Computation**: Each center $k$ computes its vector of label counts by summing the one-hot encoded labels of its $n_k$ patients. For a binary problem, this results in a vector $\\mathbf{v}_k = [n_k(0), n_k(1)]^T$. This vector is private. The total sample counts per center, $n_1$ and $n_2$, are considered public.\n2.  **Masking**: To hide $\\mathbf{v}_k$, each center $k$ generates a set of pairwise random masks. For a two-center scenario, Center $1$ and Center $2$ establish a shared secret (e.g., via Diffie-Hellman key exchange) to seed a pseudorandom number generator, creating a shared random vector $\\mathbf{p}_{12}$. By convention, $\\mathbf{p}_{21} = -\\mathbf{p}_{12}$.\n3.  **Transmission**: Center $1$ sends the masked vector $\\tilde{\\mathbf{v}}_1 = \\mathbf{v}_1 + \\mathbf{p}_{12}$ to the aggregator. Center $2$ sends $\\tilde{\\mathbf{v}}_2 = \\mathbf{v}_2 + \\mathbf{p}_{21} = \\mathbf{v}_2 - \\mathbf{p}_{12}$. An individual masked vector reveals no information about the underlying private vector $\\mathbf{v}_k$.\n4.  **Aggregation**: The aggregator sums the received masked vectors:\n    $$\\tilde{\\mathbf{V}} = \\tilde{\\mathbf{v}}_1 + \\tilde{\\mathbf{v}}_2 = (\\mathbf{v}_1 + \\mathbf{p}_{12}) + (\\mathbf{v}_2 - \\mathbf{p}_{12}) = \\mathbf{v}_1 + \\mathbf{v}_2$$\n    The random masks cancel out, leaving the aggregator with the sum of the private count vectors, $\\mathbf{V}_{sum} = [n_1(0)+n_2(0), n_1(1)+n_2(1)]^T = [N(0), N(1)]^T$.\n5.  **Global Prior Calculation**: The aggregator computes the total number of samples $N = N(0) + N(1)$ (or receives it as $n_1+n_2$). It then computes the target global priors $p(y) = N(y)/N$ and broadcasts them to the centers.\nWith $p(y)$, each center $k$ can compute its required weights $\\beta_k(y) = p(y)/p_k(y)$.\n\nNow we apply this to the synthetic example.\nThe givens are:\n- Center $1$: $n_1 = 800$, with $n_1(1) = 560$ and $n_1(0) = 240$.\n- Center $2$: $n_2 = 1200$, with $n_2(1) = 360$ and $n_2(0) = 840$.\n\nFirst, we compute the local priors $p_k(y) = n_k(y)/n_k$:\n- $p_1(1) = \\frac{560}{800} = 0.7$\n- $p_1(0) = \\frac{240}{800} = 0.3$\n- $p_2(1) = \\frac{360}{1200} = 0.3$\n- $p_2(0) = \\frac{840}{1200} = 0.7$\n\nNext, we compute the target global prior $p(y)$ from the aggregated data, which would be calculated via the SA protocol.\n- Total samples: $N = n_1 + n_2 = 800 + 1200 = 2000$.\n- Total malignant cases ($y=1$): $N(1) = n_1(1) + n_2(1) = 560 + 360 = 920$.\n- Total benign cases ($y=0$): $N(0) = n_1(0) + n_2(0) = 240 + 840 = 1080$.\nThe target global priors are:\n- $p(1) = \\frac{N(1)}{N} = \\frac{920}{2000} = 0.46$.\n- $p(0) = \\frac{N(0)}{N} = \\frac{1080}{2000} = 0.54$.\n\nFinally, we compute the weights $\\beta_k(y) = p(y)/p_k(y)$:\n- For Center $1$, class $0$: $\\beta_1(0) = \\frac{p(0)}{p_1(0)} = \\frac{0.54}{0.3} = 1.8$.\n- For Center $1$, class $1$: $\\beta_1(1) = \\frac{p(1)}{p_1(1)} = \\frac{0.46}{0.7} = \\frac{46}{70} = \\frac{23}{35} \\approx 0.6571428...$\n- For Center $2$, class $0$: $\\beta_2(0) = \\frac{p(0)}{p_2(0)} = \\frac{0.54}{0.7} = \\frac{54}{70} = \\frac{27}{35} \\approx 0.7714285...$\n- For Center $2$, class $1$: $\\beta_2(1) = \\frac{p(1)}{p_2(1)} = \\frac{0.46}{0.3} = \\frac{46}{30} = \\frac{23}{15} \\approx 1.5333333...$\n\nRounding these values to four significant figures, we get:\n- $\\beta_1(0) = 1.800$\n- $\\beta_1(1) = 0.6571$\n- $\\beta_2(0) = 0.7714$\n- $\\beta_2(1) = 1.533$\n\nThe final answer is presented as a row matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.800 & 0.6571 & 0.7714 & 1.533\n\\end{pmatrix}\n}\n$$", "id": "4540746"}, {"introduction": "A well-trained model is not just accurate, but also reliable, meaning its confidence scores reflect the true likelihood of events. This practice explores how to assess model calibration in a federated study, a crucial step for clinical trust [@problem_id:4540753]. You will learn how to securely aggregate sufficient statistics to compute a global calibration curve and the Expected Calibration Error ($ECE$), demonstrating that sophisticated model evaluation is possible without compromising data privacy.", "problem": "A multi-center radiomics study trains a probabilistic classifier to predict a binary clinical endpoint from radiomic features. To assess calibration across centers without sharing patient-level data, the consortium agrees to use histogram binning with secure aggregation of sufficient statistics. Bins are fixed globally as four disjoint intervals: bin $1$ is $[0,0.25)$, bin $2$ is $[0.25,0.5)$, bin $3$ is $[0.5,0.75)$, and bin $4$ is $[0.75,1]$. Each center $c$ computes, for each bin $b \\in \\{1,2,3,4\\}$, three values: the count $n_{c,b}$, the sum of predicted probabilities $S^{(p)}_{c,b}$, and the sum of binary outcomes $S^{(y)}_{c,b}$. The secure aggregation protocol reveals to the server only the global sums $N_{b}=\\sum_{c} n_{c,b}$, $S^{(p)}_{b}=\\sum_{c} S^{(p)}_{c,b}$, and $S^{(y)}_{b}=\\sum_{c} S^{(y)}_{c,b}$, but not any center’s individual contributions.\n\nStarting from the core definitions that a calibration curve plots, for each bin $b$, the pair $\\left(\\bar{p}_{b}, \\bar{y}_{b}\\right)$ where $\\bar{p}_{b}$ is the mean predicted probability within the bin and $\\bar{y}_{b}$ is the empirical event rate within the bin, and that the Expected Calibration Error (ECE) is defined as the weighted average of absolute deviations between $\\bar{p}_{b}$ and $\\bar{y}_{b}$ with weights equal to the fraction of samples in each bin, derive expressions for $\\bar{p}_{b}$, $\\bar{y}_{b}$, and the ECE in terms of $N_{b}$, $S^{(p)}_{b}$, and $S^{(y)}_{b}$ only. Use only algebraic manipulation and the linearity of summation as fundamental tools.\n\nThen, three centers $c \\in \\{1,2,3\\}$ participate and report the following per-bin sufficient statistics via secure aggregation:\n\n- Center $1$: \n  - Bin $1$: $n_{1,1}=4$, $S^{(p)}_{1,1}=0.80$, $S^{(y)}_{1,1}=1$.\n  - Bin $2$: $n_{1,2}=3$, $S^{(p)}_{1,2}=1.05$, $S^{(y)}_{1,2}=1$.\n  - Bin $3$: $n_{1,3}=2$, $S^{(p)}_{1,3}=1.10$, $S^{(y)}_{1,3}=1$.\n  - Bin $4$: $n_{1,4}=1$, $S^{(p)}_{1,4}=0.90$, $S^{(y)}_{1,4}=1$.\n- Center $2$: \n  - Bin $1$: $n_{2,1}=3$, $S^{(p)}_{2,1}=0.60$, $S^{(y)}_{2,1}=0$.\n  - Bin $2$: $n_{2,2}=4$, $S^{(p)}_{2,2}=1.60$, $S^{(y)}_{2,2}=2$.\n  - Bin $3$: $n_{2,3}=3$, $S^{(p)}_{2,3}=1.95$, $S^{(y)}_{2,3}=2$.\n  - Bin $4$: $n_{2,4}=2$, $S^{(p)}_{2,4}=1.60$, $S^{(y)}_{2,4}=2$.\n- Center $3$: \n  - Bin $1$: $n_{3,1}=5$, $S^{(p)}_{3,1}=1.00$, $S^{(y)}_{3,1}=1$.\n  - Bin $2$: $n_{3,2}=3$, $S^{(p)}_{3,2}=1.35$, $S^{(y)}_{3,2}=1$.\n  - Bin $3$: $n_{3,3}=4$, $S^{(p)}_{3,3}=2.60$, $S^{(y)}_{3,3}=3$.\n  - Bin $4$: $n_{3,4}=3$, $S^{(p)}_{3,4}=2.55$, $S^{(y)}_{3,4}=3$.\n\nCompute the federated Expected Calibration Error (ECE) using only the securely aggregated $N_{b}$, $S^{(p)}_{b}$, and $S^{(y)}_{b}$. Express the final ECE as a decimal and round your answer to four significant figures.", "solution": "The problem statement is deemed valid. It is scientifically grounded in the principles of machine learning model evaluation, specifically calibration assessment. It is well-posed, providing all necessary definitions and data for a unique solution. The language is objective and the scenario is a realistic application of federated learning in a medical context. All provided numerical values are consistent with their definitions.\n\nThe problem asks for two tasks: first, to derive expressions for key calibration metrics using only securely aggregated statistics, and second, to compute the Expected Calibration Error (ECE) for a given dataset.\n\n### Part 1: Derivation of Federated Calibration Metrics\n\nLet there be a set of centers indexed by $c$ and a set of globally defined bins indexed by $b$. For a given patient sample $i$, let $p_i$ be the model's predicted probability and $y_i \\in \\{0, 1\\}$ be the true binary outcome.\n\nThe problem defines the following quantities computed at each center $c$ for each bin $b$:\n- $n_{c,b}$: The number of samples from center $c$ whose predicted probabilities fall into bin $b$.\n- $S^{(p)}_{c,b}$: The sum of predicted probabilities for these $n_{c,b}$ samples.\n- $S^{(y)}_{c,b}$: The sum of true outcomes for these $n_{c,b}$ samples.\n\nThe securely aggregated statistics available at the central server are:\n- $N_{b} = \\sum_{c} n_{c,b}$: The total number of samples in bin $b$ across all centers.\n- $S^{(p)}_{b} = \\sum_{c} S^{(p)}_{c,b}$: The total sum of predicted probabilities for all samples in bin $b$.\n- $S^{(y)}_{b} = \\sum_{c} S^{(y)}_{c,b}$: The total sum of true outcomes for all samples in bin $b$.\n\nThe goal is to derive expressions for the mean predicted probability in a bin ($\\bar{p}_{b}$), the empirical event rate in a bin ($\\bar{y}_{b}$), and the overall Expected Calibration Error (ECE).\n\n**1. Mean Predicted Probability ($\\bar{p}_{b}$)**\n\nBy definition, the mean predicted probability in bin $b$, $\\bar{p}_{b}$, is the sum of all predicted probabilities for samples in that bin, divided by the total number of samples in that bin. Let $\\mathcal{I}_b$ be the set of indices of all samples (across all centers) that fall into bin $b$.\n$$\n\\bar{p}_{b} = \\frac{\\sum_{i \\in \\mathcal{I}_b} p_i}{|\\mathcal{I}_b|}\n$$\nThe denominator, $|\\mathcal{I}_b|$, is by definition the total count of samples in bin $b$, which is $N_b$.\nThe numerator, $\\sum_{i \\in \\mathcal{I}_b} p_i$, is the sum of predicted probabilities of all samples in bin $b$. Due to the linearity of summation, this sum can be decomposed across centers:\n$$\n\\sum_{i \\in \\mathcal{I}_b} p_i = \\sum_{c} \\left( \\sum_{\\substack{i \\text{ at center } c \\\\ \\text{ and in bin } b}} p_i \\right)\n$$\nThe inner sum is precisely the definition of $S^{(p)}_{c,b}$, the sum of probabilities for bin $b$ at center $c$. Therefore, the total sum is:\n$$\n\\sum_{i \\in \\mathcal{I}_b} p_i = \\sum_{c} S^{(p)}_{c,b} = S^{(p)}_{b}\n$$\nSubstituting these into the definition of $\\bar{p}_{b}$:\n$$\n\\bar{p}_{b} = \\frac{S^{(p)}_{b}}{N_{b}}\n$$\n\n**2. Empirical Event Rate ($\\bar{y}_{b}$)**\n\nSimilarly, the empirical event rate (or mean outcome) in bin $b$, $\\bar{y}_{b}$, is the sum of all true outcomes for samples in that bin, divided by the total number of samples in that bin.\n$$\n\\bar{y}_{b} = \\frac{\\sum_{i \\in \\mathcal{I}_b} y_i}{|\\mathcal{I}_b|}\n$$\nThe denominator is again $N_b$. The numerator is the sum of outcomes for all samples in bin $b$. Using the linearity of summation again:\n$$\n\\sum_{i \\in \\mathcal{I}_b} y_i = \\sum_{c} \\left( \\sum_{\\substack{i \\text{ at center } c \\\\ \\text{ and in bin } b}} y_i \\right) = \\sum_{c} S^{(y)}_{c,b} = S^{(y)}_{b}\n$$\nSubstituting these results:\n$$\n\\bar{y}_{b} = \\frac{S^{(y)}_{b}}{N_{b}}\n$$\n\n**3. Expected Calibration Error (ECE)**\n\nThe ECE is defined as the weighted average of the absolute difference between the mean predicted probability and the empirical event rate in each bin. The weight for each bin is the fraction of total samples that fall into that bin.\n$$\n\\text{ECE} = \\sum_{b} \\frac{N_{b}}{N_{\\text{total}}} |\\bar{p}_{b} - \\bar{y}_{b}|\n$$\nwhere $N_{\\text{total}} = \\sum_{b} N_{b}$ is the total number of samples in the study.\n\nSubstituting the expressions for $\\bar{p}_{b}$ and $\\bar{y}_{b}$:\n$$\n\\text{ECE} = \\sum_{b} \\frac{N_{b}}{N_{\\text{total}}} \\left| \\frac{S^{(p)}_{b}}{N_{b}} - \\frac{S^{(y)}_{b}}{N_{b}} \\right|\n$$\nWe can factor out the common denominator $N_{b}$ from the absolute value term:\n$$\n\\text{ECE} = \\sum_{b} \\frac{N_{b}}{N_{\\text{total}}} \\frac{|S^{(p)}_{b} - S^{(y)}_{b}|}{N_{b}}\n$$\nThe term $N_{b}$ in the numerator and denominator cancels out for each bin (assuming $N_b > 0$, which is true for any bin containing data).\n$$\n\\text{ECE} = \\sum_{b} \\frac{|S^{(p)}_{b} - S^{(y)}_{b}|}{N_{\\text{total}}}\n$$\nSince $N_{\\text{total}}$ is constant with respect to the summation over $b$, we can write the final expression as:\n$$\n\\text{ECE} = \\frac{1}{N_{\\text{total}}} \\sum_{b} |S^{(p)}_{b} - S^{(y)}_{b}| = \\frac{\\sum_{b} |S^{(p)}_{b} - S^{(y)}_{b}|}{\\sum_{b} N_{b}}\n$$\nThis demonstrates that the federated ECE can be computed using only the aggregated sufficient statistics $N_b$, $S^{(p)}_b$, and $S^{(y)}_b$.\n\n### Part 2: Calculation of the Federated ECE\n\nFirst, we calculate the aggregated statistics $N_b$, $S^{(p)}_b$, and $S^{(y)}_b$ for each bin $b \\in \\{1, 2, 3, 4\\}$ by summing the contributions from the three centers.\n\nFor bin $b=1$:\n$N_1 = n_{1,1} + n_{2,1} + n_{3,1} = 4 + 3 + 5 = 12$\n$S^{(p)}_1 = S^{(p)}_{1,1} + S^{(p)}_{2,1} + S^{(p)}_{3,1} = 0.80 + 0.60 + 1.00 = 2.40$\n$S^{(y)}_1 = S^{(y)}_{1,1} + S^{(y)}_{2,1} + S^{(y)}_{3,1} = 1 + 0 + 1 = 2$\n\nFor bin $b=2$:\n$N_2 = n_{1,2} + n_{2,2} + n_{3,2} = 3 + 4 + 3 = 10$\n$S^{(p)}_2 = S^{(p)}_{1,2} + S^{(p)}_{2,2} + S^{(p)}_{3,2} = 1.05 + 1.60 + 1.35 = 4.00$\n$S^{(y)}_2 = S^{(y)}_{1,2} + S^{(y)}_{2,2} + S^{(y)}_{3,2} = 1 + 2 + 1 = 4$\n\nFor bin $b=3$:\n$N_3 = n_{1,3} + n_{2,3} + n_{3,3} = 2 + 3 + 4 = 9$\n$S^{(p)}_3 = S^{(p)}_{1,3} + S^{(p)}_{2,3} + S^{(p)}_{3,3} = 1.10 + 1.95 + 2.60 = 5.65$\n$S^{(y)}_3 = S^{(y)}_{1,3} + S^{(y)}_{2,3} + S^{(y)}_{3,3} = 1 + 2 + 3 = 6$\n\nFor bin $b=4$:\n$N_4 = n_{1,4} + n_{2,4} + n_{3,4} = 1 + 2 + 3 = 6$\n$S^{(p)}_4 = S^{(p)}_{1,4} + S^{(p)}_{2,4} + S^{(p)}_{3,4} = 0.90 + 1.60 + 2.55 = 5.05$\n$S^{(y)}_4 = S^{(y)}_{1,4} + S^{(y)}_{2,4} + S^{(y)}_{3,4} = 1 + 2 + 3 = 6$\n\nNext, calculate the total number of samples, $N_{\\text{total}}$:\n$N_{\\text{total}} = N_1 + N_2 + N_3 + N_4 = 12 + 10 + 9 + 6 = 37$\n\nNow, we compute the absolute differences $|S^{(p)}_{b} - S^{(y)}_{b}|$ for each bin:\nFor $b=1$: $|S^{(p)}_{1} - S^{(y)}_{1}| = |2.40 - 2| = 0.40$\nFor $b=2$: $|S^{(p)}_{2} - S^{(y)}_{2}| = |4.00 - 4| = 0.00$\nFor $b=3$: $|S^{(p)}_{3} - S^{(y)}_{3}| = |5.65 - 6| = |-0.35| = 0.35$\nFor $b=4$: $|S^{(p)}_{4} - S^{(y)}_{4}| = |5.05 - 6| = |-0.95| = 0.95$\n\nSum these absolute differences:\n$\\sum_{b=1}^{4} |S^{(p)}_{b} - S^{(y)}_{b}| = 0.40 + 0.00 + 0.35 + 0.95 = 1.70$\n\nFinally, compute the ECE using the derived formula:\n$\\text{ECE} = \\frac{\\sum_{b} |S^{(p)}_{b} - S^{(y)}_{b}|}{N_{\\text{total}}} = \\frac{1.70}{37}$\n\n$\\text{ECE} \\approx 0.0459459...$\n\nRounding to four significant figures, we get $0.04595$.", "answer": "$$\\boxed{0.04595}$$", "id": "4540753"}]}