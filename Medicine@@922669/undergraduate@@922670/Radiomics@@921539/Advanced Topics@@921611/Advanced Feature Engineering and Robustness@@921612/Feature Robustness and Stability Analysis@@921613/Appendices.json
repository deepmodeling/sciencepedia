{"hands_on_practices": [{"introduction": "Before assessing feature stability, it is essential to perform quality control to identify and handle anomalous measurements that can skew results. This practice [@problem_id:4538489] introduces a robust outlier detection workflow using the Median Absolute Deviation (MAD), a method that is itself resilient to the influence of extreme values. By implementing this fundamental data-cleaning step, you will learn how to ensure that your subsequent stability metrics are more reliable and meaningful.", "problem": "You are asked to implement a robust outlier detection and quality control routine for radiomic feature robustness assessment. The setting is that a single radiomic feature is measured repeatedly under perturbations of acquisition or segmentation, and robustness is evaluated by removing outliers and checking the variability of the remaining measurements. Your program must be a complete, runnable program that performs the analysis on a predefined test suite and outputs the results in the specified format.\n\nFundamental base to use:\n- The median of a set of real numbers $x_1,\\dots,x_n$ is the value $m$ such that at least half the data are not greater than $m$ and at least half the data are not less than $m$.\n- The Median Absolute Deviation (MAD) is defined as $\\operatorname{MAD} = \\operatorname{median}(|x_i - m|)$ where $m$ is the median of the sample.\n- For a normally distributed variable with standard deviation $\\sigma$, the expected value of the Median Absolute Deviation is proportional to $\\sigma$. The proportionality constant is the median of the absolute value of a standard normal random variable, which equals a positive constant often approximated as $c \\approx 0.67448975$. This yields the standard normal consistency relationship.\n- The sample mean is $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i$ and the unbiased sample standard deviation is $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2}$ for $n \\ge 2$.\n- The coefficient of variation (CV) is defined as $\\operatorname{CV} = \\frac{s}{|\\bar{x}|}$, which is dimensionless and quantifies relative variability.\n\nAlgorithm requirements to implement:\n1. For each feature measurement vector $x = [x_1,\\dots,x_n]$, detect outliers using a robust $z$-score defined by scaling deviations from the median by the Median Absolute Deviation (MAD) with the standard normal consistency constant. If $\\operatorname{MAD} > 0$, compute the robust $z$-scores and flag a measurement $x_i$ as an outlier if its absolute robust $z$-score exceeds a given threshold $\\tau_z$.\n2. If $\\operatorname{MAD} = 0$, fall back to an interquartile range (IQR)-based rule: compute the first and third quartiles $Q_1$ and $Q_3$, the interquartile range $\\operatorname{IQR} = Q_3 - Q_1$, and flag an observation $x_i$ as an outlier if $x_i  Q_1 - k \\cdot \\operatorname{IQR}$ or $x_i > Q_3 + k \\cdot \\operatorname{IQR}$ with $k = 1.5$. If $\\operatorname{IQR} = 0$, this rule reduces to flagging any $x_i$ outside the interval $[Q_1, Q_3]$.\n3. Remove outliers and compute the fraction of remaining observations $f = \\frac{n_{\\text{remain}}}{n}$. Also compute the sample coefficient of variation $\\operatorname{CV}$ on the remaining observations using the unbiased sample standard deviation $s$ and the absolute value of the sample mean $|\\bar{x}|$. If $n_{\\text{remain}}  2$ or $|\\bar{x}| = 0$, treat $\\operatorname{CV}$ as $+\\infty$ for decision purposes.\n4. A feature passes quality control if and only if both conditions hold: $f \\ge p_{\\min}$ and $\\operatorname{CV} \\le \\tau_{\\text{cv}}$.\n\nYour program must implement the above logic precisely and evaluate the following test suite, where each test case is a tuple consisting of the feature vector $x$, the robust $z$-score threshold $\\tau_z$, the coefficient of variation threshold $\\tau_{\\text{cv}}$, and the minimum fraction $p_{\\min}$ required to remain after outlier removal. All numerical values are real numbers, and any fractional thresholds should be interpreted as pure decimals, not percentages.\n\nTest suite:\n- Case A (typical, small variability, no outliers): $x = [0.99, 1.02, 1.01, 0.98, 1.00, 1.03, 0.97]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.025$, $p_{\\min} = 0.8$.\n- Case B (two gross outliers, sufficient remaining fraction): $x = [1.00, 0.99, 1.01, 1.02, 0.98, 3.00, -1.50]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.03$, $p_{\\min} = 0.7$.\n- Case C (several moderate deviations, strict outlier threshold leads to low remaining fraction): $x = [1.00, 1.00, 1.00, 2.00, -3.00, 2.20, -2.50]$, $\\tau_z = 1.0$, $\\tau_{\\text{cv}} = 0.10$, $p_{\\min} = 0.8$.\n- Case D (zero Median Absolute Deviation with extreme values; fall back to interquartile range rule): $x = [5.00, 5.00, 5.00, 5.00, 5.00, 10.00, -10.00]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.001$, $p_{\\min} = 0.7$.\n- Case E (mean near zero causing unbounded coefficient of variation): $x = [0.01, -0.01, 0.02, -0.02, 0.00, 0.005, -0.005]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 1.0$, $p_{\\min} = 1.0$.\n- Case F (all values identical): $x = [2.50, 2.50, 2.50, 2.50]$, $\\tau_z = 3.5$, $\\tau_{\\text{cv}} = 0.001$, $p_{\\min} = 1.0$.\n\nOutput specification:\n- For each case, output a boolean indicating whether the feature passes quality control under the rules above.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[{\\tt True},{\\tt False},\\dots]$ with one entry per test case in the order presented.\n- No physical units are involved in this problem.", "solution": "The problem requires the implementation of a statistical routine for assessing the robustness of a radiomic feature. This is achieved by quantifying the feature's stability after removing outliers from a set of repeated measurements. The procedure involves two main stages: robust outlier detection and stability analysis of the remaining data points. A feature is deemed robust if it satisfies criteria for both the fraction of data remaining and the coefficient of variation after outlier removal.\n\nThe analytical procedure for a given vector of feature measurements $x = [x_1, x_2, \\dots, x_n]$ is as follows:\n\n**1. Outlier Detection**\n\nA two-tiered approach is employed for outlier detection, prioritizing a robust statistical method that is resilient to the presence of extreme values.\n\n**1.1. Median Absolute Deviation (MAD) Method**\n\nThe primary method for identifying outliers is based on the Median Absolute Deviation (MAD), a robust measure of statistical dispersion. First, the sample median, $m$, is calculated.\n$$\nm = \\operatorname{median}(x)\n$$\nThe MAD is then computed as the median of the absolute deviations from the sample median:\n$$\n\\operatorname{MAD} = \\operatorname{median}(|x_i - m|)\n$$\nIf $\\operatorname{MAD} > 0$, we can define a robust $z$-score, also known as the modified $z$-score. This score standardizes the deviations from the median using a robust estimate of the standard deviation derived from the MAD. For a normal distribution, the standard deviation $\\sigma$ can be estimated by $\\hat{\\sigma} = \\operatorname{MAD}/c$, where $c \\approx 0.67448975$ is a consistency constant equal to the median of the absolute value of a standard normal variable. The robust $z$-score for each measurement $x_i$ is therefore:\n$$\nz_{\\text{robust}, i} = \\frac{x_i - m}{\\hat{\\sigma}} = \\frac{c \\cdot (x_i - m)}{\\operatorname{MAD}}\n$$\nA measurement $x_i$ is flagged as an outlier if its absolute robust $z$-score exceeds a predefined threshold $\\tau_z$:\n$$\n|z_{\\text{robust}, i}| > \\tau_z\n$$\n\n**1.2. Interquartile Range (IQR) Fallback Method**\n\nIn cases where $\\operatorname{MAD} = 0$, which typically occurs when more than half of the data points are identical, the robust $z$-score is undefined. For these situations, the algorithm falls back to the widely used IQR method, proposed by John Tukey. First, the first quartile ($Q_1$, the $25^{th}$ percentile) and the third quartile ($Q_3$, the $75^{th}$ percentile) of the data are computed. The interquartile range is the difference between them:\n$$\n\\operatorname{IQR} = Q_3 - Q_1\n$$\nA measurement $x_i$ is identified as an outlier if it lies outside the range defined by:\n$$\nx_i  Q_1 - k \\cdot \\operatorname{IQR} \\quad \\text{or} \\quad x_i > Q_3 + k \\cdot \\operatorname{IQR}\n$$\nwhere the problem specifies a constant $k=1.5$. If $\\operatorname{IQR}=0$, this rule correctly simplifies to flagging any point not equal to the value $Q_1=Q_3$.\n\n**2. Stability Analysis after Outlier Removal**\n\nAfter identifying and removing all outliers, the stability of the feature is assessed using the remaining $n_{\\text{remain}}$ data points.\n\n**2.1. Fraction of Remaining Observations ($f$)**\n\nThe fraction of data points that are not outliers is computed as:\n$$\nf = \\frac{n_{\\text{remain}}}{n}\n$$\nThis quantity measures the concordance of the measurements. A low fraction indicates a large number of outliers and thus poor reproducibility.\n\n**2.2. Coefficient of Variation (CV)**\n\nThe relative variability of the remaining data is quantified by the sample Coefficient of Variation ($\\operatorname{CV}$). First, the sample mean $\\bar{x}$ and the unbiased sample standard deviation $s$ of the filtered data are calculated:\n$$\n\\bar{x} = \\frac{1}{n_{\\text{remain}}} \\sum_{i=1}^{n_{\\text{remain}}} x_{i, \\text{filtered}}\n$$\n$$\ns = \\sqrt{\\frac{1}{n_{\\text{remain}}-1}\\sum_{i=1}^{n_{\\text{remain}}} (x_{i, \\text{filtered}} - \\bar{x})^2}\n$$\nThe CV is then the ratio of the standard deviation to the absolute value of the mean:\n$$\n\\operatorname{CV} = \\frac{s}{|\\bar{x}|}\n$$\nSpecial conditions are defined for the CV calculation. If the number of remaining data points $n_{\\text{remain}}  2$, the sample standard deviation is undefined. If the sample mean $\\bar{x} = 0$, the CV is mathematically undefined. In both scenarios, the CV is treated as functionally infinite ($+\\infty$) for decision-making purposes, representing maximal variability.\n\n**3. Quality Control Decision**\n\nA feature is considered robust and passes the quality control check if and only if both of the following conditions are met:\n1.  The fraction of remaining observations is not less than a minimum threshold $p_{\\min}$: $f \\ge p_{\\min}$.\n2.  The coefficient of variation of the remaining observations does not exceed a maximum threshold $\\tau_{\\text{cv}}$: $\\operatorname{CV} \\le \\tau_{\\text{cv}}$.\n\nThis algorithmic framework provides a rigorous, automated procedure for evaluating feature robustness based on established statistical principles.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for radiomic feature robustness analysis.\n    \"\"\"\n    \n    def evaluate_feature_robustness(x, tau_z, tau_cv, p_min):\n        \"\"\"\n        Performs outlier detection and quality control for a single feature vector.\n\n        Args:\n            x (list): A list of feature measurements.\n            tau_z (float): The threshold for the robust z-score.\n            tau_cv (float): The threshold for the coefficient of variation.\n            p_min (float): The minimum required fraction of remaining observations.\n\n        Returns:\n            bool: True if the feature passes quality control, False otherwise.\n        \"\"\"\n        x_arr = np.array(x, dtype=np.float64)\n        n = len(x_arr)\n\n        if n == 0:\n            # An empty feature vector has no data remaining.\n            # It fails unless p_min is 0, but CV is still infinite.\n            # Assuming it fails.\n            return p_min == 0\n\n        # Constants for outlier detection\n        c = 0.67448975  # Normal distribution consistency constant for MAD\n        k = 1.5         # Multiplier for IQR rule\n\n        # 1. Compute median and Median Absolute Deviation (MAD)\n        m = np.median(x_arr)\n        # Calculate absolute deviations from the median\n        abs_dev = np.abs(x_arr - m)\n        mad = np.median(abs_dev)\n\n        # 2. Detect outliers based on MAD or IQR\n        if mad > 0:\n            # Primary method: Robust z-score using MAD\n            # The robust z-score is c * (x_i - m) / MAD\n            robust_z_scores = c * abs_dev / mad\n            is_outlier = robust_z_scores > tau_z\n        else:\n            # Fallback method: Interquartile Range (IQR) rule\n            q1 = np.percentile(x_arr, 25)\n            q3 = np.percentile(x_arr, 75)\n            iqr = q3 - q1\n            lower_bound = q1 - k * iqr\n            upper_bound = q3 + k * iqr\n            is_outlier = (x_arr  lower_bound) | (x_arr > upper_bound)\n        \n        # 3. Filter data and compute stability metrics\n        x_filtered = x_arr[~is_outlier]\n        n_remain = len(x_filtered)\n\n        # Compute fraction of remaining observations\n        f = n_remain / n if n > 0 else 0\n\n        # Compute Coefficient of Variation (CV)\n        cv = np.inf  # Default to infinity as per problem spec\n        if n_remain >= 2:\n            mean_filtered = np.mean(x_filtered)\n            # Check for mean being close to zero to avoid division by zero\n            if not np.isclose(mean_filtered, 0):\n                std_filtered = np.std(x_filtered, ddof=1) # Unbiased sample std dev\n                cv = std_filtered / np.abs(mean_filtered)\n        \n        # 4. Apply quality control criteria\n        passes_f_check = f >= p_min\n        passes_cv_check = cv = tau_cv\n        \n        return passes_f_check and passes_cv_check\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (typical, small variability, no outliers)\n        ([0.99, 1.02, 1.01, 0.98, 1.00, 1.03, 0.97], 3.5, 0.025, 0.8),\n        # Case B (two gross outliers, sufficient remaining fraction)\n        ([1.00, 0.99, 1.01, 1.02, 0.98, 3.00, -1.50], 3.5, 0.03, 0.7),\n        # Case C (several moderate deviations, strict outlier threshold)\n        ([1.00, 1.00, 1.00, 2.00, -3.00, 2.20, -2.50], 1.0, 0.10, 0.8),\n        # Case D (zero MAD; fallback to IQR rule)\n        ([5.00, 5.00, 5.00, 5.00, 5.00, 10.00, -10.00], 3.5, 0.001, 0.7),\n        # Case E (mean near zero causing unbounded CV)\n        ([0.01, -0.01, 0.02, -0.02, 0.00, 0.005, -0.005], 3.5, 1.0, 1.0),\n        # Case F (all values identical)\n        ([2.50, 2.50, 2.50, 2.50], 3.5, 0.001, 1.0),\n    ]\n\n    results = []\n    for params in test_cases:\n        x_data, z_thresh, cv_thresh, p_min_thresh = params\n        result = evaluate_feature_robustness(x_data, z_thresh, cv_thresh, p_min_thresh)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4538489"}, {"introduction": "A core task in radiomics is to quantify feature stability using controlled experiments, such as those involving imaging phantoms. This practice [@problem_id:4538492] guides you through the process of analyzing data from a simulated test-retest phantom experiment from first principles. You will implement calibration to correct for systematic drift between acquisition sessions and use quantitative metrics like the within-subject coefficient of variation ($w\\text{CV}$) to assess improvements in feature repeatability and bias.", "problem": "You are given a simplified, self-contained phantom study to assess radiomics feature robustness under calibration drift. A phantom with known reference insert values is scanned in two sessions, denoted by $s \\in \\{1,2\\}$, each with $R$ repeated acquisitions per object. For each feature, two calibration inserts with known reference (ground-truth) values are provided. Your tasks are to calibrate each session to the reference scale using only the calibration inserts, apply the calibration to all repeated measurements, and then quantify robustness according to precisely defined, first-principles metrics.\n\nFundamental base for derivation:\n- Sample mean: For any finite set $\\{y_j\\}_{j=1}^{n}$, the sample mean is $\\bar{y} = \\frac{1}{n}\\sum_{j=1}^{n} y_j$.\n- Sample variance via sum of squared residuals: For residuals $e_j = y_j - \\bar{y}$, the sum of squared residuals is $\\mathrm{SSR} = \\sum_{j=1}^{n} e_j^2$, and the unbiased variance estimate is $\\hat{\\sigma}^2 = \\mathrm{SSR}/(n-1)$ when the mean is estimated from the same $n$ points.\n- Linear least squares affine fit: Given pairs $\\{(x_k, t_k)\\}_{k=1}^{K}$, the affine mapping $y = a x + b$ that minimizes $\\sum_{k=1}^{K} (a x_k + b - t_k)^2$ follows from the normal equations for linear least squares.\n\nDefinitions to be implemented from these bases:\n1) Session-wise calibration by linear least squares. For each session $s$, determine real scalars $(a_s, b_s)$ that minimize $\\sum_{k=1}^{K} (a_s x_{s,k} + b_s - t_k)^2$, where $x_{s,k}$ are the measured calibration values in session $s$, and $t_k$ are the corresponding reference values. The calibrated value for any measurement $x$ in session $s$ is then $y = a_s x + b_s$.\n2) Within-session pooled repeatability standard deviation. For each session $s$ and object $i$, let the $R$ repeated measurements be $\\{x_{s,i,r}\\}_{r=1}^{R}$ with mean $\\bar{x}_{s,i} = \\frac{1}{R}\\sum_{r=1}^{R} x_{s,i,r}$. Define the residuals $e_{s,i,r} = x_{s,i,r} - \\bar{x}_{s,i}$. The pooled within-session standard deviation $s_r$ across both sessions is the square root of\n$$\n\\hat{\\sigma}_r^2 = \\frac{\\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} e_{s,i,r}^2}{\\sum_{s=1}^{2}\\sum_{i=1}^{N}(R-1)}.\n$$\n3) Grand mean across both sessions and all repeats:\n$$\n\\mu = \\frac{1}{2 N R} \\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} x_{s,i,r}.\n$$\n4) Within-subject coefficient of variation (dimensionless), defined as $w\\text{CV} = s_r / \\mu$.\n5) Between-session bias using per-object session means. For each object $i$, compute $\\bar{x}_{1,i}$ and $\\bar{x}_{2,i}$, then define $d_i = \\bar{x}_{2,i} - \\bar{x}_{1,i}$ and the bias as $b = \\frac{1}{N}\\sum_{i=1}^{N} d_i$. The relative bias is $|b|/\\mu$.\n6) Relative reduction in absolute bias after calibration. If the pre-calibration relative bias is $\\beta_{\\mathrm{pre}}$ and the post-calibration relative bias is $\\beta_{\\mathrm{post}}$, define the reduction\n$$\n\\rho_{\\mathrm{red}} =\n\\begin{cases}\n1,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} = 0,\\\\\n0,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} > 0,\\\\\n\\max\\left(0, \\min\\left(1, \\frac{\\beta_{\\mathrm{pre}} - \\beta_{\\mathrm{post}}}{\\beta_{\\mathrm{pre}}}\\right)\\right),  \\text{if } \\beta_{\\mathrm{pre}} > 0.\n\\end{cases}\n$$\n\nRobustness decision rule (to be applied after calibration): A feature is declared robust if and only if all of the following hold simultaneously:\n- $w\\text{CV}_{\\mathrm{post}} \\le \\tau$,\n- $\\beta_{\\mathrm{post}} \\le \\delta$,\n- $\\rho_{\\mathrm{red}} \\ge \\eta$,\nwhere thresholds are fixed at $\\tau = 0.02$, $\\delta = 0.01$, and $\\eta = 0.5$.\n\nAll values in this problem are unitless. There are no angle quantities.\n\nData to use. There are $F = 3$ independent features. For each feature $f \\in \\{1,2,3\\}$, you are given:\n- Two calibration inserts with reference values $\\{t_k\\}_{k=1}^{2}$.\n- Measured calibration values in session $1$: $\\{x_{1,k}\\}_{k=1}^{2}$ and in session $2$: $\\{x_{2,k}\\}_{k=1}^{2}$.\n- Non-calibration objects: $N = 4$ objects with $R = 3$ repeated measurements in each session. For session $1$, you have the matrix $\\{x_{1,i,r}\\}$ of size $4 \\times 3$; for session $2$, you have $\\{x_{2,i,r}\\}$ of size $4 \\times 3$. Calibration inserts must not be used in repeatability or bias calculations; only the $N=4$ non-calibration objects are used for those metrics.\n\nFeature $1$:\n- Calibration references: $[\\, $50$, $150$ \\,]$.\n- Session $1$ calibration measurements: $[\\, $50$, $140$ \\,]$.\n- Session $2$ calibration measurements: $[\\, $47$, $157$ \\,]$.\n- Session $1$ non-calibration repeated measurements (rows are objects $i=1,\\dots,4$, columns are repeats $r=1,2,3$):\n  [\n    [ $67.5$, $68.0$, $68.5$ ],\n    [ $94.7$, $95.1$, $95.3$ ],\n    [ $121.6$, $122.0$, $122.4$ ],\n    [ $148.3$, $149.0$, $149.7$ ]\n  ]\n- Session $2$ non-calibration repeated measurements:\n  [\n    [ $68.4$, $69.0$, $69.6$ ],\n    [ $101.6$, $102.1$, $102.5$ ],\n    [ $134.5$, $135.1$, $135.6$ ],\n    [ $167.4$, $168.0$, $168.6$ ]\n  ]\n\nFeature $2$:\n- Calibration references: $[\\, $40$, $80$ \\,]$.\n- Session $1$ calibration measurements: $[\\, $40$, $80$ \\,]$.\n- Session $2$ calibration measurements: $[\\, $44$, $88$ \\,]$.\n- Session $1$ non-calibration repeated measurements:\n  [\n    [ $45$, $50$, $55$ ],\n    [ $57$, $60$, $63$ ],\n    [ $84$, $90$, $96$ ],\n    [ $112$, $120$, $128$ ]\n  ]\n- Session $2$ non-calibration repeated measurements:\n  [\n    [ $60$, $55$, $50$ ],\n    [ $72$, $66$, $60$ ],\n    [ $105$, $99$, $93$ ],\n    [ $140$, $132$, $124$ ]\n  ]\n\nFeature $3$:\n- Calibration references: $[\\, $30$, $60$ \\,]$.\n- Session $1$ calibration measurements: $[\\, $27$, $54$ \\,]$.\n- Session $2$ calibration measurements: $[\\, $33$, $66$ \\,]$.\n- Session $1$ non-calibration repeated measurements:\n  [\n    [ $36$, $36$, $36$ ],\n    [ $45$, $45$, $45$ ],\n    [ $63$, $63$, $63$ ],\n    [ $81$, $81$, $81$ ]\n  ]\n- Session $2$ non-calibration repeated measurements:\n  [\n    [ $44$, $44$, $44$ ],\n    [ $55$, $55$, $55$ ],\n    [ $77$, $77$, $77$ ],\n    [ $99$, $99$, $99$ ]\n  ]\n\nProgramming task:\n- For each feature independently, compute the pre-calibration relative bias $\\beta_{\\mathrm{pre}}$ and the post-calibration $w\\text{CV}_{\\mathrm{post}}$, $\\beta_{\\mathrm{post}}$, and the reduction $\\rho_{\\mathrm{red}}$ as defined above, using only the fundamental bases and definitions provided.\n- Decide robustness according to the rule with $\\tau = 0.02$, $\\delta = 0.01$, $\\eta = 0.5$.\n\nTest suite:\n- The three features together constitute three test cases that cover a typical case, a high-variance case, and a boundary case with zero within-session variance.\n\nFinal output format:\n- Your program should produce a single line of output containing the three robustness decisions for features $1$, $2$, and $3$ as a comma-separated list of booleans enclosed in square brackets (for example, $[\\,\\mathrm{True},\\mathrm{False},\\mathrm{True}\\,]$). The output must be exactly one line with no extra text.", "solution": "The problem requires a quantitative assessment of radiomics feature robustness based on a simplified phantom study. The analysis involves three independent features, each evaluated against a set of precisely defined metrics and thresholds. The process for each feature comprises three main stages: calculation of pre-calibration bias, determination and application of a session-specific linear calibration, and calculation of post-calibration robustness metrics. A feature is deemed robust if it simultaneously satisfies three criteria related to its post-calibration repeatability, bias, and the reduction in bias achieved by calibration.\n\nThe methodology adheres strictly to the definitions provided. Let $x_{s,i,r}$ denote the measured value for session $s \\in \\{1,2\\}$, non-calibration object $i \\in \\{1,\\dots,N\\}$, and repeat $r \\in \\{1,\\dots,R\\}$, where $N=4$ and $R=3$.\n\nThe analysis proceeds as follows:\n\nFirst, we compute the pre-calibration relative bias, $\\beta_{\\mathrm{pre}}$. This serves as a baseline to evaluate the effectiveness of the calibration. For each object $i$, the mean measurement is computed for each session:\n$$ \\bar{x}_{s,i} = \\frac{1}{R}\\sum_{r=1}^{R} x_{s,i,r} $$\nThe between-session difference for object $i$ is $d_i = \\bar{x}_{2,i} - \\bar{x}_{1,i}$. The pre-calibration bias, $b_{\\mathrm{pre}}$, is the average of these differences over all $N$ objects:\n$$ b_{\\mathrm{pre}} = \\frac{1}{N}\\sum_{i=1}^{N} d_i $$\nThis bias is normalized by the pre-calibration grand mean, $\\mu_{\\mathrm{pre}}$, which is the average of all $2NR$ measurements:\n$$ \\mu_{\\mathrm{pre}} = \\frac{1}{2NR} \\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} x_{s,i,r} $$\nThe pre-calibration relative bias is then $\\beta_{\\mathrm{pre}} = |b_{\\mathrm{pre}}| / \\mu_{\\mathrm{pre}}$.\n\nSecond, we perform session-wise calibration. For each session $s$, we are given $K=2$ pairs of measured calibration values $\\{x_{s,k}\\}_{k=1}^{2}$ and their corresponding known reference values $\\{t_k\\}_{k=1}^{2}$. We seek an affine transformation $y = a_s x + b_s$ that maps the measured scale to the reference scale. The parameters $(a_s, b_s)$ are found by minimizing the sum of squared differences $\\sum_{k=1}^{K} (a_s x_{s,k} + b_s - t_k)^2$. For $K=2$, this corresponds to finding the unique line passing through the two points $(x_{s,1}, t_1)$ and $(x_{s,2}, t_2)$. The solution to the system of linear equations\n\\begin{align*} a_s x_{s,1} + b_s = t_1 \\\\ a_s x_{s,2} + b_s = t_2 \\end{align*}\nis given by:\n$$ a_s = \\frac{t_1 - t_2}{x_{s,1} - x_{s,2}} \\quad \\text{and} \\quad b_s = t_1 - a_s x_{s,1} $$\nprovided $x_{s,1} \\neq x_{s,2}$, which is true for all features in this problem. Two distinct calibration functions, $(a_1, b_1)$ for session $1$ and $(a_2, b_2)$ for session $2$, are thus determined for each feature.\n\nThird, we apply these transformations to the non-calibration measurements to obtain calibrated values $y_{s,i,r}$:\n$$ y_{s,i,r} = a_s x_{s,i,r} + b_s $$\nAll subsequent robustness metrics are computed using this calibrated dataset $\\{y_{s,i,r}\\}$.\n\nWe calculate the three post-calibration metrics required for the robustness decision:\n\n1.  The within-subject coefficient of variation, $w\\text{CV}_{\\mathrm{post}}$. This metric quantifies the repeatability of the feature. We first calculate the pooled within-session standard deviation, $s_{r, \\mathrm{post}}$. For each object $i$ in each session $s$, we find the mean of its calibrated repeats, $\\bar{y}_{s,i} = \\frac{1}{R}\\sum_{r=1}^{R} y_{s,i,r}$. The sum of squared residuals (SSR) is accumulated over all measurements:\n    $$ \\mathrm{SSR}_{\\mathrm{post}} = \\sum_{s=1}^{2}\\sum_{i=1}^{N}\\sum_{r=1}^{R} (y_{s,i,r} - \\bar{y}_{s,i})^2 $$\n    The pooled variance is this SSR divided by the total degrees of freedom, $DF = \\sum_{s=1}^{2}\\sum_{i=1}^{N}(R-1) = 2N(R-1)$:\n    $$ \\hat{\\sigma}_{r, \\mathrm{post}}^2 = \\frac{\\mathrm{SSR}_{\\mathrm{post}}}{2N(R-1)} $$\n    The standard deviation is $s_{r, \\mathrm{post}} = \\sqrt{\\hat{\\sigma}_{r, \\mathrm{post}}^2}$. This is normalized by the post-calibration grand mean, $\\mu_{\\mathrm{post}} = \\frac{1}{2NR} \\sum_{s,i,r} y_{s,i,r}$, to yield the dimensionless coefficient:\n    $$ w\\text{CV}_{\\mathrm{post}} = \\frac{s_{r, \\mathrm{post}}}{\\mu_{\\mathrm{post}}} $$\n\n2.  The post-calibration relative bias, $\\beta_{\\mathrm{post}}$. This metric quantifies the systematic difference remaining between sessions after calibration. The calculation mirrors that of the pre-calibration bias, but uses the calibrated means $\\bar{y}_{s,i}$. The post-calibration bias is $b_{\\mathrm{post}} = \\frac{1}{N}\\sum_{i=1}^{N} (\\bar{y}_{2,i} - \\bar{y}_{1,i})$. The relative bias is:\n    $$ \\beta_{\\mathrm{post}} = \\frac{|b_{\\mathrm{post}}|}{\\mu_{\\mathrm{post}}} $$\n\n3.  The relative reduction in absolute bias, $\\rho_{\\mathrm{red}}$. This metric evaluates the effectiveness of the calibration at reducing systematic error. It is defined as:\n    $$ \\rho_{\\mathrm{red}} =\n    \\begin{cases}\n    1,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} = 0,\\\\\n    0,  \\text{if } \\beta_{\\mathrm{pre}} = 0 \\text{ and } \\beta_{\\mathrm{post}} > 0,\\\\\n    \\max\\left(0, \\min\\left(1, \\frac{\\beta_{\\mathrm{pre}} - \\beta_{\\mathrm{post}}}{\\beta_{\\mathrm{pre}}}\\right)\\right),  \\text{if } \\beta_{\\mathrm{pre}} > 0.\n    \\end{cases}\n    $$\n\nFinally, a feature is declared robust if and only if all three of the following conditions are met, using the given thresholds $\\tau = 0.02$, $\\delta = 0.01$, and $\\eta = 0.5$:\n- $w\\text{CV}_{\\mathrm{post}} \\le \\tau$\n- $\\beta_{\\mathrm{post}} \\le \\delta$\n- $\\rho_{\\mathrm{red}} \\ge \\eta$\n\nThis complete procedure is applied independently to each of the three features provided. The final output is a list of boolean values indicating the robustness status of each feature.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the radiomics feature robustness problem for three given features.\n    \"\"\"\n    # Thresholds\n    TAU = 0.02\n    DELTA = 0.01\n    ETA = 0.5\n\n    # Number of objects and repeats\n    N = 4\n    R = 3\n    \n    # Structure to hold data for the three features\n    features_data = [\n        {\n            \"cal_ref\": np.array([50.0, 150.0]),\n            \"cal_s1\": np.array([50.0, 140.0]),\n            \"cal_s2\": np.array([47.0, 157.0]),\n            \"meas_s1\": np.array([\n                [67.5, 68.0, 68.5],\n                [94.7, 95.1, 95.3],\n                [121.6, 122.0, 122.4],\n                [148.3, 149.0, 149.7]\n            ]),\n            \"meas_s2\": np.array([\n                [68.4, 69.0, 69.6],\n                [101.6, 102.1, 102.5],\n                [134.5, 135.1, 135.6],\n                [167.4, 168.0, 168.6]\n            ])\n        },\n        {\n            \"cal_ref\": np.array([40.0, 80.0]),\n            \"cal_s1\": np.array([40.0, 80.0]),\n            \"cal_s2\": np.array([44.0, 88.0]),\n            \"meas_s1\": np.array([\n                [45.0, 50.0, 55.0],\n                [57.0, 60.0, 63.0],\n                [84.0, 90.0, 96.0],\n                [112.0, 120.0, 128.0]\n            ]),\n            \"meas_s2\": np.array([\n                [60.0, 55.0, 50.0],\n                [72.0, 66.0, 60.0],\n                [105.0, 99.0, 93.0],\n                [140.0, 132.0, 124.0]\n            ])\n        },\n        {\n            \"cal_ref\": np.array([30.0, 60.0]),\n            \"cal_s1\": np.array([27.0, 54.0]),\n            \"cal_s2\": np.array([33.0, 66.0]),\n            \"meas_s1\": np.array([\n                [36.0, 36.0, 36.0],\n                [45.0, 45.0, 45.0],\n                [63.0, 63.0, 63.0],\n                [81.0, 81.0, 81.0]\n            ]),\n            \"meas_s2\": np.array([\n                [44.0, 44.0, 44.0],\n                [55.0, 55.0, 55.0],\n                [77.0, 77.0, 77.0],\n                [99.0, 99.0, 99.0]\n            ])\n        }\n    ]\n\n    robustness_decisions = []\n\n    for feature in features_data:\n        x1 = feature[\"meas_s1\"]\n        x2 = feature[\"meas_s2\"]\n\n        # 1. Pre-calibration relative bias (beta_pre)\n        x1_means = np.mean(x1, axis=1)\n        x2_means = np.mean(x2, axis=1)\n        \n        b_pre = np.mean(x2_means - x1_means)\n        mu_pre = np.mean(np.concatenate((x1, x2)))\n        \n        # Handle case where mu_pre is zero, although not expected with this data\n        beta_pre = np.abs(b_pre) / mu_pre if mu_pre != 0 else 0\n\n        # 2. Session-wise calibration\n        t_k = feature[\"cal_ref\"]\n        \n        # Session 1 calibration\n        x1_k = feature[\"cal_s1\"]\n        a1 = (t_k[0] - t_k[1]) / (x1_k[0] - x1_k[1])\n        b1 = t_k[0] - a1 * x1_k[0]\n\n        # Session 2 calibration\n        x2_k = feature[\"cal_s2\"]\n        a2 = (t_k[0] - t_k[1]) / (x2_k[0] - x2_k[1])\n        b2 = t_k[0] - a2 * x2_k[0]\n\n        # Apply calibration\n        y1 = a1 * x1 + b1\n        y2 = a2 * x2 + b2\n\n        # 3. Post-calibration metrics\n        \n        # wCV_post\n        ssr_post = 0.0\n        # SSR for session 1\n        for i in range(N):\n            ssr_post += np.sum((y1[i, :] - np.mean(y1[i, :]))**2)\n        # SSR for session 2\n        for i in range(N):\n            ssr_post += np.sum((y2[i, :] - np.mean(y2[i, :]))**2)\n        \n        df = 2 * N * (R - 1)\n        pooled_var_post = ssr_post / df if df > 0 else 0\n        s_r_post = np.sqrt(pooled_var_post)\n        \n        mu_post = np.mean(np.concatenate((y1, y2)))\n        wCV_post = s_r_post / mu_post if mu_post != 0 else 0\n\n        # beta_post\n        y1_means = np.mean(y1, axis=1)\n        y2_means = np.mean(y2, axis=1)\n        \n        b_post = np.mean(y2_means - y1_means)\n        beta_post = np.abs(b_post) / mu_post if mu_post != 0 else 0\n\n        # rho_red\n        if beta_pre == 0:\n            rho_red = 1.0 if beta_post == 0 else 0.0\n        else:\n            reduction = (beta_pre - beta_post) / beta_pre\n            rho_red = max(0.0, min(1.0, reduction))\n\n        # 4. Robustness decision\n        is_robust = (wCV_post = TAU) and (beta_post = DELTA) and (rho_red >= ETA)\n        robustness_decisions.append(is_robust)\n        \n    print(f\"[{','.join(map(str, robustness_decisions))}]\")\n\nsolve()\n```", "id": "4538492"}, {"introduction": "When combining radiomics data from multiple scanners or institutions, non-biological variations known as \"batch effects\" can obscure true biological signals. This advanced practice [@problem_id:4538487] challenges you to derive and implement a harmonization technique to correct for these batch-specific location and scale shifts. Mastering this skill is critical for building robust models that can generalize across different data sources.", "problem": "Construct a program that performs harmonization and batch effect correction for a single radiomics feature measured across multiple acquisition batches, and evaluates robustness and stability before and after correction. The program must start from the fundamental statistical definitions of mean and variance and from an additive-multiplicative batch effect model. Assume the following base: an observed scalar feature value $x_i$ is measured for subject $s_i$ in batch $b_i$, and batches induce location and scale shifts. Let the global mean be denoted by $\\mu$ and the global standard deviation by $\\sigma$, and let the batch-specific mean and standard deviation for batch $k$ be denoted by $\\mu_k$ and $\\sigma_k$, respectively. Assume an affine transformation per batch is used for harmonization, constrained to make each batch’s transformed distribution have the same global mean and variance across batches. Use the population definitions for mean and variance. To handle the boundary condition of zero batch standard deviation, use a strictly positive stabilization parameter $\\varepsilon$ to avoid division by zero.\n\nYour tasks are:\n- Derive, from first principles and the constraints on mean and variance, the batch-wise affine transformation that maps each $x_i$ to a harmonized value $x_i^{(h)}$ such that $\\mathbb{E}[x^{(h)} \\mid b=k] = \\mu$ and $\\operatorname{Var}(x^{(h)} \\mid b=k] = \\sigma^2$ for every batch $k$. Use the additive-multiplicative batch effect model and the definitions of expectation and variance to determine the transformation parameters.\n- Implement the harmonization using the derived affine form and the stabilization $\\varepsilon$ by replacing any divisor $\\sigma_k$ with $\\max(\\sigma_k, \\varepsilon)$ wherever a division by $\\sigma_k$ would occur. Use $\\varepsilon = 10^{-8}$.\n- Quantify batch effects before and after harmonization using the explained variance ratio by batch, defined via sums of squares. Let the total sum of squares be $SS_{\\text{tot}} = \\sum_{i=1}^{N} (x_i - \\mu)^2$ and the between-batch sum of squares be $SS_{\\text{bet}} = \\sum_{k} n_k (\\mu_k - \\mu)^2$, where $n_k$ is the number of observations in batch $k$. Define the fraction of variance explained by batch as $\\eta^2 = SS_{\\text{bet}} / SS_{\\text{tot}}$. If $SS_{\\text{tot}} = 0$, define $\\eta^2 = 0$.\n- Quantify within-subject stability using the mean absolute within-subject difference. For each subject label $s$, let $I_s$ be the index set of its repeated measurements. Define the subject’s mean absolute difference as the average of $|x_i - x_j|$ over all unordered distinct pairs $(i,j)$ with $i,j \\in I_s$. Define the overall mean absolute within-subject difference as the average of the subjects’ mean absolute differences. Compute this both before and after harmonization.\n- Define a boolean improvement criterion that is true if and only if the batch-explained fraction decreases and the mean absolute within-subject difference does not increase beyond numerical tolerance. Specifically, let $\\tau = 10^{-12}$, and set $\\text{improved} = (\\eta^2_{\\text{post}}  \\eta^2_{\\text{pre}}) \\land (D_{\\text{post}} \\le D_{\\text{pre}} + \\tau)$, where $D$ denotes the mean absolute within-subject difference.\n\nImplement the program to process the following test suite. Each test case is a tuple $(x, b, s)$ consisting of a list $x$ of observed values, a list $b$ of batch labels of the same length, and a list $s$ of subject labels of the same length. The lists for each test case are:\n\n- Test Case $1$ (happy path, two batches with distinct location-scale effects, two acquisitions per subject):\n  - $x = [-1.55, -1.22, -1.02, -0.71, -0.51, 3.52, 4.21, 5.03, 5.70, 6.51]$\n  - $b = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]$\n  - $s = [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]$\n- Test Case $2$ (boundary condition, a batch with zero variance):\n  - $x = [5.00, 5.00, 5.00, 6.00, 8.00, 10.00]$\n  - $b = [0, 0, 0, 1, 1, 1]$\n  - $s = [0, 1, 2, 0, 1, 2]$\n- Test Case $3$ (edge case, single batch only):\n  - $x = [1.00, 2.00, 3.00, 1.10, 1.90, 3.05]$\n  - $b = [0, 0, 0, 0, 0, 0]$\n  - $s = [0, 1, 2, 0, 1, 2]$\n- Test Case $4$ (outlier stress test, strong outlier in one batch):\n  - $x = [2.00, 2.50, 3.00, 3.50, 2.20, 2.60, 3.10, 50.00]$\n  - $b = [0, 0, 0, 0, 1, 1, 1, 1]$\n  - $s = [0, 1, 2, 3, 0, 1, 2, 3]$\n\nFor each test case, your program must:\n- Compute the pre-harmonization batch-explained fraction $\\eta^2_{\\text{pre}}$.\n- Harmonize $x$ to obtain $x^{(h)}$ using your derived affine transformation with stabilization $\\varepsilon = 10^{-8}$.\n- Compute the post-harmonization batch-explained fraction $\\eta^2_{\\text{post}}$.\n- Compute the pre- and post-harmonization mean absolute within-subject differences $D_{\\text{pre}}$ and $D_{\\text{post}}$.\n- Compute the boolean $\\text{improved}$ using $\\tau = 10^{-12}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case’s result must be a list of the form $[\\eta^2_{\\text{pre}}, \\eta^2_{\\text{post}}, \\text{improved}, D_{\\text{pre}}, D_{\\text{post}}]$. For example, the overall output should look like $[[\\text{case1}], [\\text{case2}], [\\text{case3}], [\\text{case4}]]$ where each $\\text{case}i$ is the list of the five quantities in the order specified. All numeric quantities are real numbers; the boolean is either $\\text{True}$ or $\\text{False}$. No units are involved.", "solution": "### Part 1: Derivation of the Affine Harmonization Transformation\n\nThe goal is to find a batch-specific affine transformation, $x_i^{(h)} = f_k(x_i)$, that maps an observed value $x_i$ from batch $k$ to a harmonized value $x_i^{(h)}$. The transformation must satisfy two constraints for every batch $k$:\n1. The conditional expectation of the harmonized values in batch $k$ must equal the global mean $\\mu$ of the original data.\n   $$ \\mathbb{E}[x^{(h)} \\mid b=k] = \\mu $$\n2. The conditional variance of the harmonized values in batch $k$ must equal the global variance $\\sigma^2$ of the original data.\n   $$ \\operatorname{Var}(x^{(h)} \\mid b=k] = \\sigma^2 $$\n\nLet the affine transformation for batch $k$ be of the form:\n$$ x_i^{(h)} = a_k x_i + c_k $$\nwhere $a_k$ and $c_k$ are the scaling and shifting coefficients for batch $k$.\n\n**Applying the Expectation Constraint:**\n\nWe take the expectation of the transformation equation, conditional on the data being from batch $k$:\n$$ \\mathbb{E}[x_i^{(h)} \\mid b_i=k] = \\mathbb{E}[a_k x_i + c_k \\mid b_i=k] $$\nUsing the linearity of the expectation operator, $\\mathbb{E}[aX+c] = a\\mathbb{E}[X]+c$:\n$$ \\mathbb{E}[x_i^{(h)} \\mid b_i=k] = a_k \\mathbb{E}[x_i \\mid b_i=k] + c_k $$\nBy definition, the conditional expectation of $x_i$ in batch $k$ is the batch mean, $\\mu_k = \\mathbb{E}[x_i \\mid b_i=k]$. Substituting this and the constraint $\\mathbb{E}[x^{(h)} \\mid b=k] = \\mu$ yields our first equation relating $a_k$ and $c_k$:\n$$ \\mu = a_k \\mu_k + c_k $$\nFrom this, we can express the shift coefficient $c_k$ in terms of the scaling coefficient $a_k$:\n$$ c_k = \\mu - a_k \\mu_k \\quad (*)$$\n\n**Applying the Variance Constraint:**\n\nNext, we apply the variance constraint. We compute the variance of the transformation, conditional on the data being from batch $k$:\n$$ \\operatorname{Var}(x_i^{(h)} \\mid b_i=k) = \\operatorname{Var}(a_k x_i + c_k \\mid b_i=k) $$\nUsing the property of variance, $\\operatorname{Var}(aX+c) = a^2 \\operatorname{Var}(X)$:\n$$ \\operatorname{Var}(x_i^{(h)} \\mid b_i=k) = a_k^2 \\operatorname{Var}(x_i \\mid b_i=k) $$\nBy definition, the conditional variance of $x_i$ in batch $k$ is the batch variance, $\\sigma_k^2 = \\operatorname{Var}(x_i \\mid b_i=k)$. Substituting this and the constraint $\\operatorname{Var}(x^{(h)} \\mid b=k) = \\sigma^2$ yields our second equation:\n$$ \\sigma^2 = a_k^2 \\sigma_k^2 $$\nSolving for the scaling coefficient $a_k$, and choosing the positive root to preserve the relative ordering of values, we get:\n$$ a_k = \\frac{\\sigma}{\\sigma_k} \\quad (**) $$\nThis assumes $\\sigma_k > 0$. The case where $\\sigma_k=0$ will be handled by the stabilization parameter $\\varepsilon$.\n\n**Final Form of the Transformation:**\n\nNow we substitute the expression for $a_k$ from $(**)$ back into the expression for $c_k$ in $(*)$:\n$$ c_k = \\mu - \\left(\\frac{\\sigma}{\\sigma_k}\\right) \\mu_k $$\nFinally, we substitute the expressions for both $a_k$ and $c_k$ into the affine transformation equation:\n$$ x_i^{(h)} = \\left(\\frac{\\sigma}{\\sigma_k}\\right) x_i + \\left(\\mu - \\frac{\\sigma \\mu_k}{\\sigma_k}\\right) $$\nThis expression can be rearranged to a more intuitive form:\n$$ x_i^{(h)} = \\frac{\\sigma}{\\sigma_k} (x_i - \\mu_k) + \\mu $$\nThis transformation first standardizes the data within each batch (by subtracting the batch mean $\\mu_k$ and dividing by the batch standard deviation $\\sigma_k$) to have a mean of $0$ and a standard deviation of $1$. It then scales the result by the global standard deviation $\\sigma$ and shifts it by the global mean $\\mu$, thereby mapping the batch-specific distribution to a target distribution with mean $\\mu$ and variance $\\sigma^2$.\n\nTo handle the boundary condition where $\\sigma_k = 0$, the problem specifies using a stabilization parameter $\\varepsilon=10^{-8}$. The divisor $\\sigma_k$ is replaced with $\\max(\\sigma_k, \\varepsilon)$. The final, stabilized transformation is:\n$$ x_i^{(h)} = \\sigma \\left(\\frac{x_i - \\mu_k}{\\max(\\sigma_k, \\varepsilon)}\\right) + \\mu $$\n\n### Part 2: Implementation of Quantification Metrics\n\nThe logic for implementing the required metrics follows directly from their definitions.\n\n**Fraction of Variance Explained by Batch ($\\eta^2$):**\nThis is computed as $\\eta^2 = SS_{\\text{bet}} / SS_{\\text{tot}}$.\n- Total Sum of Squares: $SS_{\\text{tot}} = \\sum_{i=1}^{N} (x_i - \\mu)^2$, where $\\mu$ is the global mean and $N$ is the total number of samples. This is equivalent to $N \\times \\operatorname{Var}_{\\text{pop}}(x)$.\n- Between-Batch Sum of Squares: $SS_{\\text{bet}} = \\sum_{k} n_k (\\mu_k - \\mu)^2$, where the sum is over all unique batches $k$, $n_k$ is the number of samples in batch $k$, and $\\mu_k$ is the mean of batch $k$.\n- The calculation is performed on the original data $x$ to get $\\eta^2_{\\text{pre}}$ and on the harmonized data $x^{(h)}$ to get $\\eta^2_{\\text{post}}$. For the post-harmonization calculation, the global and batch-specific means are re-calculated from the harmonized data $x^{(h)}$.\n\n**Mean Absolute Within-Subject Difference ($D$):**\nThis metric quantifies the stability of measurements for the same subject.\n1. Group all measurements by their subject label $s$.\n2. For each subject with at least two measurements, identify all unique pairs of their measurements $(x_i, x_j)$.\n3. For each such pair, calculate the absolute difference $|x_i - x_j|$.\n4. For each subject, compute the average of these absolute differences. This is the subject's mean absolute difference.\n5. The overall metric $D$ is the average of these per-subject mean absolute differences.\n- This calculation is performed on both $x$ (for $D_{\\text{pre}}$) and $x^{(h)}$ (for $D_{\\text{post}}$).\n\n**Improvement Criterion:**\nThe boolean flag `improved` is set to `True` if both of the following conditions are met, indicating successful batch effect mitigation without degrading subject-level measurement consistency:\n1. The fraction of variance explained by batch decreases: $\\eta^2_{\\text{post}}  \\eta^2_{\\text{pre}}$.\n2. The mean absolute within-subject difference does not increase beyond a small numerical tolerance $\\tau = 10^{-12}$: $D_{\\text{post}} \\le D_{\\text{pre}} + \\tau$.\n\nThe implementation will apply these derivations and definitions to each test case provided.", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: Happy path\n        (\n            [-1.55, -1.22, -1.02, -0.71, -0.51, 3.52, 4.21, 5.03, 5.70, 6.51],\n            [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n            [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]\n        ),\n        # Test Case 2: Boundary condition (zero variance batch)\n        (\n            [5.00, 5.00, 5.00, 6.00, 8.00, 10.00],\n            [0, 0, 0, 1, 1, 1],\n            [0, 1, 2, 0, 1, 2]\n        ),\n        # Test Case 3: Edge case (single batch)\n        (\n            [1.00, 2.00, 3.00, 1.10, 1.90, 3.05],\n            [0, 0, 0, 0, 0, 0],\n            [0, 1, 2, 0, 1, 2]\n        ),\n        # Test Case 4: Outlier stress test\n        (\n            [2.00, 2.50, 3.00, 3.50, 2.20, 2.60, 3.10, 50.00],\n            [0, 0, 0, 0, 1, 1, 1, 1],\n            [0, 1, 2, 3, 0, 1, 2, 3]\n        ),\n    ]\n\n    all_results = [process_case(x, b, s) for x, b, s in test_cases]\n    \n    # Format the final output string\n    def format_result(res):\n        eta2_pre, eta2_post, improved, d_pre, d_post = res\n        return f\"[{eta2_pre},{eta2_post},{improved},{d_pre},{d_post}]\"\n\n    output_str = \"[\" + \",\".join([format_result(res) for res in all_results]) + \"]\"\n    print(output_str)\n\n\ndef process_case(x_list, b_list, s_list):\n    \"\"\"\n    Performs harmonization and computes all required metrics for a single test case.\n    \"\"\"\n    x = np.array(x_list, dtype=np.float64)\n    b = np.array(b_list)\n    s = np.array(s_list)\n    epsilon = 1e-8\n    tau = 1e-12\n\n    # --- Metric Calculation Helper Functions ---\n\n    def calculate_eta_sq(values, batches):\n        \"\"\"Computes the fraction of variance explained by batch (eta-squared).\"\"\"\n        if values.size == 0:\n            return 0.0\n        \n        mu_global = np.mean(values)\n        ss_tot = np.sum((values - mu_global)**2)\n        \n        if ss_tot == 0:\n            return 0.0\n        \n        ss_bet = 0.0\n        unique_batches = np.unique(batches)\n        for k in unique_batches:\n            batch_values = values[batches == k]\n            n_k = batch_values.size\n            mu_k = np.mean(batch_values)\n            ss_bet += n_k * (mu_k - mu_global)**2\n            \n        return ss_bet / ss_tot\n\n    def calculate_within_subject_diff(values, subjects):\n        \"\"\"Computes the mean absolute within-subject difference.\"\"\"\n        subject_data = {}\n        for i, sid in enumerate(subjects):\n            if sid not in subject_data:\n                subject_data[sid] = []\n            subject_data[sid].append(values[i])\n        \n        subject_mean_diffs = []\n        for sid, s_values in subject_data.items():\n            if len(s_values)  2:\n                continue\n            \n            pair_diffs = [abs(p[0] - p[1]) for p in combinations(s_values, 2)]\n            if pair_diffs:\n                subject_mean_diffs.append(np.mean(pair_diffs))\n        \n        if not subject_mean_diffs:\n            return 0.0\n        \n        return np.mean(subject_mean_diffs)\n    \n    # --- Pre-Harmonization Analysis ---\n    \n    eta2_pre = calculate_eta_sq(x, b)\n    d_pre = calculate_within_subject_diff(x, s)\n\n    # --- Harmonization ---\n\n    x_h = np.copy(x)\n    unique_batches = np.unique(b)\n\n    if len(unique_batches) > 1:\n        mu_global_orig = np.mean(x)\n        sigma_global_orig = np.std(x) # ddof=0 for population std dev\n\n        for k in unique_batches:\n            batch_mask = (b == k)\n            x_k = x[batch_mask]\n            \n            mu_k = np.mean(x_k)\n            sigma_k = np.std(x_k)\n            \n            # The derived transformation with stabilization\n            divisor = max(sigma_k, epsilon)\n            x_h[batch_mask] = sigma_global_orig * (x_k - mu_k) / divisor + mu_global_orig\n    # If only one batch, x_h remains a copy of x, as harmonization is an identity op.\n\n    # --- Post-Harmonization Analysis ---\n    \n    eta2_post = calculate_eta_sq(x_h, b)\n    d_post = calculate_within_subject_diff(x_h, s)\n    \n    # --- Improvement Criterion ---\n    \n    improved = (eta2_post  eta2_pre) and (d_post = d_pre + tau)\n    \n    return [eta2_pre, eta2_post, improved, d_pre, d_post]\n\nif __name__ == '__main__':\n    solve()\n```", "id": "4538487"}]}