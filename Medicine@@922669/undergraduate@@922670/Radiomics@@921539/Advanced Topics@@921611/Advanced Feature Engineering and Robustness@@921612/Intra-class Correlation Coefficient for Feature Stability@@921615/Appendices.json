{"hands_on_practices": [{"introduction": "The first step in mastering feature stability is learning to calculate the Intra-class Correlation Coefficient (ICC) in its most common form. This practice guides you through a typical test-retest scenario, where you will use the output of an Analysis of Variance (ANOVA) to compute the single-measure ICC, often denoted as $ICC(1,1)$. By working through this problem, you'll gain a foundational understanding of how total measurement variability is partitioned and used to quantify reliability [@problem_id:4547420].", "problem": "A radiomics test–retest study evaluates the stability of a scalar imaging feature across two sessions separated by $48$ hours. There are $n=25$ subjects, each scanned twice. A one-way random-effects analysis of variance partitions variability into a between-subjects component and a within-subject (residual) component and yields the following mean squares: between-subjects mean square $MS_{B}=3.6$ and within-subject mean square $MS_{W}=0.9$. Under the one-way random-effects framework for single-measure reliability, compute the single-measure Intra-Class Correlation Coefficient (ICC) denoted $ICC(1,1)$ using the provided mean squares and the fact that there are $k=2$ repeated measurements per subject. Then, using the criterion that the feature is considered stable if $ICC \\geq 0.75$, indicate whether the feature is stable. Express the ICC as a pure number with no units. If you choose to round, round to four significant figures.", "solution": "The problem asks for the computation of the single-measure Intra-Class Correlation Coefficient, denoted $ICC(1,1)$, and an assessment of feature stability based on a given criterion. The context is a radiomics test-retest study analyzed using a one-way random-effects model.\n\nThe one-way random-effects model for a measurement $x_{ij}$ (for subject $i$ and measurement $j$) is given by $x_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}$, where $\\mu$ is the overall mean, $\\alpha_i$ is the random effect of subject $i$ with variance $\\sigma^2_B$ (between-subjects variance), and $\\epsilon_{ij}$ is the random error term with variance $\\sigma^2_W$ (within-subject variance).\n\nThe Intra-Class Correlation Coefficient is defined as the proportion of the total variance that is attributable to the between-subjects variance. For a single measurement, the total variance is $\\sigma^2_B + \\sigma^2_W$. Therefore, the single-measure ICC is:\n$$ICC(1,1) = \\frac{\\sigma^2_B}{\\sigma^2_B + \\sigma^2_W}$$\nIn the framework of Analysis of Variance (ANOVA), the variance components $\\sigma^2_B$ and $\\sigma^2_W$ can be estimated from the mean squares. The expected values for the between-subjects mean square ($MS_B$) and the within-subject mean square ($MS_W$) are related to the variance components as follows:\n$$E(MS_W) = \\sigma^2_W$$\n$$E(MS_B) = \\sigma^2_W + k \\sigma^2_B$$\nwhere $k$ is the number of repeated measurements for each subject.\n\nUsing the observed mean squares as estimates for their expected values, we can express the estimated variance components as:\n$$\\hat{\\sigma}^2_W = MS_W$$\n$$\\hat{\\sigma}^2_B = \\frac{MS_B - MS_W}{k}$$\nSubstituting these estimators into the formula for $ICC(1,1)$ yields an expression in terms of the mean squares:\n$$ICC(1,1) = \\frac{\\frac{MS_B - MS_W}{k}}{\\left(\\frac{MS_B - MS_W}{k}\\right) + MS_W}$$\nTo simplify this expression, we multiply the numerator and denominator by $k$:\n$$ICC(1,1) = \\frac{MS_B - MS_W}{(MS_B - MS_W) + k \\cdot MS_W}$$\n$$ICC(1,1) = \\frac{MS_B - MS_W}{MS_B + (k-1)MS_W}$$\nThis is the standard computational formula for $ICC(1,1)$.\n\nThe problem provides the following values:\n- Between-subjects mean square: $MS_B = 3.6$\n- Within-subject mean square: $MS_W = 0.9$\n- Number of repeated measurements per subject: $k=2$\n- Number of subjects: $n=25$ (note that $n$ is not required for this calculation, as its effect is already incorporated into the mean square values).\n\nWe substitute the given values into the formula for $ICC(1,1)$:\n$$ICC(1,1) = \\frac{3.6 - 0.9}{3.6 + (2-1) \\times 0.9}$$\n$$ICC(1,1) = \\frac{2.7}{3.6 + (1) \\times 0.9}$$\n$$ICC(1,1) = \\frac{2.7}{3.6 + 0.9}$$\n$$ICC(1,1) = \\frac{2.7}{4.5}$$\nThe calculation gives an exact value:\n$$ICC(1,1) = 0.6$$\nThe problem provides a criterion for stability: the feature is considered stable if $ICC \\geq 0.75$. Our calculated value is $ICC(1,1) = 0.6$.\nComparing the calculated value to the criterion:\n$$0.6  0.75$$\nTherefore, based on the provided data and criterion, the imaging feature is **not** considered stable. The final answer required is the numerical value of the ICC.", "answer": "$$\\boxed{0.6}$$", "id": "4547420"}, {"introduction": "Beyond basic calculation, it is crucial to understand that not all ICCs are the same. This exercise explores an inter-observer study to highlight the critical distinction between 'consistency' and 'absolute agreement'. You will compute two different forms of ICC from the same dataset and see firsthand how systematic differences between raters affect the final reliability score, a vital consideration when deciding which ICC is appropriate for your research question [@problem_id:4547472].", "problem": "A radiomics team evaluates the stability of a single scalar radiomic feature across three human observers who independently segment the same set of images. For each of $n$ subjects, the feature is computed from each observer’s segmentation. The team wishes to quantify reliability using the Intraclass Correlation Coefficient (ICC) under two definitions that reflect different scientific intents: absolute agreement versus consistency.\n\nThe study is balanced with $n=6$ subjects and $k=3$ observers (raters). Let $x_{ij}$ denote the feature value for subject $i$ measured by rater $j$, with $i \\in \\{1,\\dots,6\\}$ and $j \\in \\{1,2,3\\}$. The observed data matrix is\n$$\nX \\;=\\; \\begin{pmatrix}\n10  13  8 \\\\\n12  15  10 \\\\\n14  17  12 \\\\\n17  20  15 \\\\\n21  24  19 \\\\\n23  26  21\n\\end{pmatrix},\n$$\nwhere rows index subjects and columns index raters. The laboratory has independent reasons to expect systematic rater offsets (e.g., one rater tends to draw slightly larger regions of interest), which may affect absolute agreement but not consistency.\n\nStarting from the two-way analysis of variance decomposition for a balanced two-factor layout with subjects and raters, treat the subject effect as random and the rater effect as random for absolute agreement and fixed for consistency. Use the standard mean-square components from this decomposition to derive the expressions for the single-measure absolute-agreement coefficient $ICC(2,1)$ and the single-measure consistency coefficient $ICC(3,1)$ in terms of the mean squares. Compute both $ICC(2,1)$ and $ICC(3,1)$ from the data, then provide a concise explanation for any discrepancy between the two values in the context of radiomics feature stability across observers.\n\nReport as your final numerical answer the difference $ICC(3,1) - ICC(2,1)$, rounded to four significant figures. The ICC is dimensionless; do not include units.", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in standard statistical methodology (Analysis of Variance, ANOVA, and Intraclass Correlation Coefficient, ICC) as applied in radiomics research, is well-posed with all necessary information provided, and is expressed in objective, unambiguous language. The data, while constructed to yield a specific outcome ($MS_E=0$), represents a perfectly formalizable scenario that highlights the conceptual difference between consistency and absolute agreement, which is a key learning objective in reliability studies.\n\nThe solution proceeds by first conducting a two-way ANOVA to partition the total variance into components attributable to subjects (rows), raters (columns), and residual error (interaction). These variance components, represented by their Mean Squares ($MS$), are then used to compute the two forms of the ICC.\n\nLet $x_{ij}$ be the feature value for subject $i \\in \\{1, \\dots, n\\}$ and rater $j \\in \\{1, \\dots, k\\}$. The study parameters are $n=6$ subjects and $k=3$ raters.\n\nFirst, we compute the necessary summary statistics from the data matrix $X$.\nThe grand total is $\\sum_{i=1}^n \\sum_{j=1}^k x_{ij} = 297$.\nThe total number of observations is $N=nk = 6 \\times 3 = 18$.\nThe grand mean is $\\bar{x}_{..} = \\frac{297}{18} = 16.5$.\n\nThe sum of squares for all observations is $\\sum_{i=1}^n \\sum_{j=1}^k x_{ij}^2 = 5369$.\n\nThe Total Sum of Squares ($SS_{TOT}$) is:\n$$ SS_{TOT} = \\sum_{i=1}^n \\sum_{j=1}^k (x_{ij} - \\bar{x}_{..})^2 = \\sum_{i=1}^n \\sum_{j=1}^k x_{ij}^2 - \\frac{(\\sum \\sum x_{ij})^2}{nk} $$\n$$ SS_{TOT} = 5369 - \\frac{297^2}{18} = 5369 - \\frac{88209}{18} = 5369 - 4900.5 = 468.5 $$\nThe total degrees of freedom are $df_{TOT} = nk - 1 = 18-1=17$.\n\nNext, we calculate the Between-Subjects Sum of Squares ($SS_R$, for rows). The subject totals are $T_{1.}=31$, $T_{2.}=37$, $T_{3.}=43$, $T_{4.}=52$, $T_{5.}=64$, $T_{6.}=70$.\n$$ SS_R = \\frac{1}{k} \\sum_{i=1}^n (\\sum_{j=1}^k x_{ij})^2 - \\frac{(\\sum \\sum x_{ij})^2}{nk} = \\frac{1}{3}(31^2+37^2+43^2+52^2+64^2+70^2) - 4900.5 $$\n$$ SS_R = \\frac{1}{3}(961+1369+1849+2704+4096+4900) - 4900.5 = \\frac{15879}{3} - 4900.5 = 5293 - 4900.5 = 392.5 $$\nThe degrees of freedom for subjects are $df_R = n - 1 = 6-1=5$.\n\nNext, we calculate the Between-Raters Sum of Squares ($SS_C$, for columns). The rater totals are $T_{.1}=97$, $T_{.2}=115$, $T_{.3}=85$.\n$$ SS_C = \\frac{1}{n} \\sum_{j=1}^k (\\sum_{i=1}^n x_{ij})^2 - \\frac{(\\sum \\sum x_{ij})^2}{nk} = \\frac{1}{6}(97^2+115^2+85^2) - 4900.5 $$\n$$ SS_C = \\frac{1}{6}(9409+13225+7225) - 4900.5 = \\frac{29859}{6} - 4900.5 = 4976.5 - 4900.5 = 76 $$\nThe degrees of freedom for raters are $df_C = k - 1 = 3-1=2$.\n\nFinally, the Residual (Error) Sum of Squares ($SS_E$) is found by subtraction:\n$$ SS_E = SS_{TOT} - SS_R - SS_C = 468.5 - 392.5 - 76 = 0 $$\nThe degrees of freedom for error are $df_E = (n-1)(k-1) = 5 \\times 2 = 10$.\n\nNow, we compute the Mean Squares ($MS$):\nMean Square for Subjects: $MS_R = \\frac{SS_R}{df_R} = \\frac{392.5}{5} = 78.5$.\nMean Square for Raters: $MS_C = \\frac{SS_C}{df_C} = \\frac{76}{2} = 38$.\nMean Square for Error: $MS_E = \\frac{SS_E}{df_E} = \\frac{0}{10} = 0$.\n\nWith these values, we can compute the ICCs.\n\n**$ICC(2,1)$: Single-Measure, Absolute Agreement**\nThis form uses a two-way random effects model, where both subjects and raters are considered random samples from larger populations. It quantifies the reliability of a single rating, penalizing for systematic biases between raters. The formula is:\n$$ ICC(2,1) = \\frac{MS_R - MS_E}{MS_R + (k-1)MS_E + \\frac{k}{n}(MS_C - MS_E)} $$\nSubstituting our calculated values:\n$$ ICC(2,1) = \\frac{78.5 - 0}{78.5 + (3-1)(0) + \\frac{3}{6}(38 - 0)} = \\frac{78.5}{78.5 + 0 + 0.5(38)} = \\frac{78.5}{78.5 + 19} = \\frac{78.5}{97.5} $$\n$$ ICC(2,1) \\approx 0.805128... $$\n\n**$ICC(3,1)$: Single-Measure, Consistency**\nThis form uses a two-way mixed effects model, where subjects are random effects and the specific raters are fixed effects. It quantifies how consistently the raters rank the subjects, ignoring systematic differences in their mean ratings. The formula is:\n$$ ICC(3,1) = \\frac{MS_R - MS_E}{MS_R + (k-1)MS_E} $$\nSubstituting our calculated values:\n$$ ICC(3,1) = \\frac{78.5 - 0}{78.5 + (2)(0)} = \\frac{78.5}{78.5} = 1 $$\n\n**Explanation of the Discrepancy**\nThe value $ICC(3,1) = 1$ indicates perfect consistency among the three raters. This is a direct consequence of the Mean Square for Error ($MS_E$) being $0$. An $MS_E$ of $0$ means there is no subject-rater interaction; the effect of changing from one rater to another is perfectly constant for all subjects. For example, rater 2's measurements are always exactly $3$ units higher than rater 1's. Thus, the relative ordering and spacing of subjects' feature values are identical across all raters.\n\nThe value $ICC(2,1) \\approx 0.8051$ is less than $1$ because it measures absolute agreement. This ICC form is penalized by any source of variance not attributable to the subjects, including systematic bias between raters. The Mean Square for Raters ($MS_C = 38$) is non-zero, indicating that the raters have different mean values for their measurements. This systematic offset between raters constitutes a source of measurement error from an absolute agreement perspective, thus lowering the ICC value below $1$. In a radiomics context, this implies that while the feature is perfectly stable for ranking subjects, the absolute values are not interchangeable due to rater-specific tendencies, which could be problematic if fixed decision thresholds are used.\n\n**Final Calculation**\nThe problem asks for the difference $ICC(3,1) - ICC(2,1)$, rounded to four significant figures.\n$$ \\text{Difference} = 1 - \\frac{78.5}{97.5} = 1 - \\frac{157}{195} = \\frac{195-157}{195} = \\frac{38}{195} $$\n$$ \\text{Difference} \\approx 0.19487179... $$\nRounding to four significant figures gives $0.1949$.", "answer": "$$\\boxed{0.1949}$$", "id": "4547472"}, {"introduction": "Why does a low ICC matter? This advanced practice moves from measuring stability to understanding its impact on downstream applications like predictive modeling. You will derive and apply the concept of regression attenuation, which shows how measurement error (quantified by the ICC) systematically weakens the observed relationship between a radiomic feature and a clinical outcome [@problem_id:4547452]. This provides a tangible reason for the stringent stability requirements in radiomics research.", "problem": "A radiomics study evaluates the test–retest stability of a scalar imaging feature measured on $n$ subjects, each scanned twice within $48$ hours under identical acquisition and reconstruction. The feature is modeled by a one-way random effects repeated-measures framework in which the observed measurement on subject $i$ and scan $j$ is $X_{ij}^{\\ast} = X_{i} + U_{ij}$, where $X_{i}$ is the subject-specific true feature value and $U_{ij}$ is an additive, mean-zero, within-subject measurement error independent of $X_{i}$ and independent across replicates. The test–retest analysis yields an Intra-class Correlation Coefficient (ICC) of $0.55$, computed under the standard assumption that the between-subject variance is $ \\operatorname{Var}(X_{i})$ and the within-subject variance is $\\operatorname{Var}(U_{ij})$, so that the ICC equals the ratio of between-subject variance to total variance.\n\nSuppose a downstream continuous outcome $Y$ is generated according to a linear model $Y = \\alpha + \\beta X + \\varepsilon$, where $X$ denotes the subject’s true feature value, $\\alpha$ and $\\beta$ are constants, and $\\varepsilon$ is a mean-zero error independent of $X$ and of the measurement error process. In practice, a regression of $Y$ on the observed, error-prone feature $X^{\\ast}$ is fit using ordinary least squares. Assume the classical additive error structure above holds and that $X$, $U$, and $\\varepsilon$ are mutually independent.\n\nStarting only from the definition of the ICC as the ratio of between-subject variance to total variance in a one-way random effects model for repeated measures, and from the defining expression of the ordinary least squares slope as the ratio of covariance to variance, derive the expected attenuation factor linking the fitted slope to the true slope. Then, given $\\beta = 1.20$, compute the expected fitted slope when regressing $Y$ on $X^{\\ast}$ under these assumptions. Round your final numerical answer to four significant figures. No units are required.", "solution": "The user wants to solve a problem that involves deriving the relationship between the true and observed regression slopes in an errors-in-variables model and then using this relationship to calculate an expected fitted slope. The connection is made through the Intra-class Correlation Coefficient (ICC).\n\nFirst, we formalize the quantities defined in the problem statement. The observed feature value for subject $i$ from scan $j$ is given by the one-way random effects model:\n$$ X_{ij}^{\\ast} = X_{i} + U_{ij} $$\nwhere $X_i$ is the true subject-specific feature value and $U_{ij}$ is the random measurement error. We are given that $E[U_{ij}] = 0$, and that $X_i$ and $U_{ij}$ are independent.\n\nThe between-subject variance is defined as $\\sigma_X^2 = \\operatorname{Var}(X_i)$.\nThe within-subject variance is defined as $\\sigma_U^2 = \\operatorname{Var}(U_{ij})$.\n\nThe problem states that the ICC is the ratio of between-subject variance to total variance. The total variance of a single observation $X_{ij}^{\\ast}$ is:\n$$ \\operatorname{Var}(X_{ij}^{\\ast}) = \\operatorname{Var}(X_i + U_{ij}) $$\nDue to the independence of $X_i$ and $U_{ij}$, this becomes:\n$$ \\operatorname{Var}(X_{ij}^{\\ast}) = \\operatorname{Var}(X_i) + \\operatorname{Var}(U_{ij}) = \\sigma_X^2 + \\sigma_U^2 $$\nTherefore, the ICC is given by:\n$$ \\text{ICC} = \\frac{\\sigma_X^2}{\\sigma_X^2 + \\sigma_U^2} $$\n\nNext, we consider the linear regression model for a continuous outcome $Y$. The true relationship is:\n$$ Y = \\alpha + \\beta X + \\varepsilon $$\nwhere $X$ is the true feature value, $\\beta$ is the true slope, and $\\varepsilon$ is a mean-zero error term. We are given that $X$, $U$, and $\\varepsilon$ are mutually independent.\n\nIn practice, the regression is performed using the error-prone measurement $X^{\\ast}$ instead of the true value $X$. For the regression analysis, we consider a single measurement per subject, so we can simplify the notation to $X^{\\ast} = X + U$. The OLS estimator for the slope in a simple linear regression of $Y$ on $X^{\\ast}$ is a random variable. The problem asks for the *expected* fitted slope, which in the context of measurement error models refers to the population parameter that the OLS estimator converges to. This theoretical slope, which we denote as $\\beta^{\\ast}$, is given by the ratio of the covariance of $Y$ and $X^{\\ast}$ to the variance of $X^{\\ast}$, as specified in the problem statement.\n$$ \\beta^{\\ast} = \\frac{\\operatorname{Cov}(Y, X^{\\ast})}{\\operatorname{Var}(X^{\\ast})} $$\n\nWe now derive the expressions for the numerator and the denominator.\n\nThe denominator is the variance of the observed feature $X^{\\ast}$:\n$$ \\operatorname{Var}(X^{\\ast}) = \\operatorname{Var}(X + U) $$\nSince $X$ and $U$ are independent, we have:\n$$ \\operatorname{Var}(X^{\\ast}) = \\operatorname{Var}(X) + \\operatorname{Var}(U) = \\sigma_X^2 + \\sigma_U^2 $$\n\nThe numerator is the covariance of the outcome $Y$ and the observed feature $X^{\\ast}$:\n$$ \\operatorname{Cov}(Y, X^{\\ast}) = \\operatorname{Cov}(\\alpha + \\beta X + \\varepsilon, X + U) $$\nUsing the bilinearity property of covariance:\n$$ \\operatorname{Cov}(Y, X^{\\ast}) = \\operatorname{Cov}(\\alpha, X+U) + \\operatorname{Cov}(\\beta X, X+U) + \\operatorname{Cov}(\\varepsilon, X+U) $$\nSince $\\alpha$ is a constant, $\\operatorname{Cov}(\\alpha, X+U) = 0$.\nThe terms involving $\\beta X$ can be expanded:\n$$ \\operatorname{Cov}(\\beta X, X+U) = \\operatorname{Cov}(\\beta X, X) + \\operatorname{Cov}(\\beta X, U) = \\beta \\operatorname{Cov}(X, X) + \\beta \\operatorname{Cov}(X, U) $$\nSince $\\operatorname{Cov}(X,X) = \\operatorname{Var}(X) = \\sigma_X^2$ and $X$ and $U$ are independent, $\\operatorname{Cov}(X, U) = 0$. Thus, this term simplifies to $\\beta \\sigma_X^2$.\nThe terms involving $\\varepsilon$ can be expanded:\n$$ \\operatorname{Cov}(\\varepsilon, X+U) = \\operatorname{Cov}(\\varepsilon, X) + \\operatorname{Cov}(\\varepsilon, U) $$\nSince $\\varepsilon$ is independent of both $X$ and $U$, both covariance terms are $0$.\nCombining these results, the numerator is:\n$$ \\operatorname{Cov}(Y, X^{\\ast}) = \\beta \\sigma_X^2 $$\n\nNow we can write the expression for the expected fitted slope $\\beta^{\\ast}$:\n$$ \\beta^{\\ast} = \\frac{\\beta \\sigma_X^2}{\\sigma_X^2 + \\sigma_U^2} $$\n\nThe first part of the task is to derive the expected attenuation factor, which is the ratio of the expected fitted slope $\\beta^{\\ast}$ to the true slope $\\beta$.\n$$ \\text{Attenuation Factor} = \\frac{\\beta^{\\ast}}{\\beta} = \\frac{1}{\\beta} \\left( \\frac{\\beta \\sigma_X^2}{\\sigma_X^2 + \\sigma_U^2} \\right) = \\frac{\\sigma_X^2}{\\sigma_X^2 + \\sigma_U^2} $$\nComparing this expression to the definition of the ICC, we see that the attenuation factor is equal to the ICC.\n$$ \\text{Attenuation Factor} = \\text{ICC} $$\nThis completes the derivation. This result is a classic finding in errors-in-variables literature, showing that measurement error in the predictor variable biases the OLS slope estimate towards zero. The magnitude of this bias is determined by the reliability of the measurement, as quantified by the ICC.\n\nThe second part of the task is to compute the expected fitted slope $\\beta^{\\ast}$ given the specific values $\\beta = 1.20$ and $\\text{ICC} = 0.55$.\nFrom our derivation, we have the relationship:\n$$ \\beta^{\\ast} = \\beta \\times (\\text{Attenuation Factor}) = \\beta \\times \\text{ICC} $$\nSubstituting the given values:\n$$ \\beta^{\\ast} = 1.20 \\times 0.55 $$\n$$ \\beta^{\\ast} = 0.66 $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ \\beta^{\\ast} = 0.6600 $$", "answer": "$$\\boxed{0.6600}$$", "id": "4547452"}]}