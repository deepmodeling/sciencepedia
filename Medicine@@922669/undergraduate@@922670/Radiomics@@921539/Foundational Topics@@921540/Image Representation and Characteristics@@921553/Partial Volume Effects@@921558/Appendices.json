{"hands_on_practices": [{"introduction": "The cornerstone of the partial volume effect (PVE) is the subvoxel occupancy fraction, the fraction of a voxel's volume occupied by a specific tissue, often denoted as $f$. This exercise [@problem_id:4554678] provides a hands-on computational method to estimate this crucial quantity for any arbitrary shape using Monte Carlo simulation. By implementing this estimator, you will gain an intuitive understanding of PVE at the single-voxel level and appreciate the power of computational methods where exact analytic formulas are not feasible.", "problem": "Consider a three-dimensional imaging voxel modeled as an axis-aligned cube $V = [0,1]^3 \\subset \\mathbb{R}^3$. A binary lesion region $\\Omega \\subset \\mathbb{R}^3$ is defined by an indicator function $\\mathbb{1}_{\\Omega}(\\mathbf{x})$ that is $1$ when $\\mathbf{x} \\in \\Omega$ and $0$ otherwise. In radiomics, partial volume effects arise because the measured intensity within a voxel is a mixture of tissue classes proportional to their subvoxel occupancy. The subvoxel occupancy fraction of the lesion within a voxel is the volume fraction given by\n$$\nf \\;=\\; \\frac{1}{|V|} \\int_{V} \\mathbb{1}_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x},\n$$\nwhere $|V|$ denotes the volume of the voxel. \n\nConstruct a Monte Carlo estimator for $f$ by sampling $N$ independent and identically distributed points $\\mathbf{X}_1, \\dots, \\mathbf{X}_N$ uniformly in $V$ and using their lesion membership. From first principles, derive whether this estimator is biased or unbiased, and derive its variance in terms of $f$ and $N$. Contrast these properties with analytic intersection formulas for simple shapes, which yield an exact $f$ with zero variance when available.\n\nYour program must:\n- Implement a function that, given $V = [0,1]^3$, a specification of $\\Omega$, a sample size $N$, and a random seed, returns the Monte Carlo estimate $\\hat{f}_N$ of $f$ by uniformly sampling within $V$ and averaging $\\mathbb{1}_{\\Omega}(\\mathbf{X}_i)$.\n- Implement analytic formulas for $f$ for the following lesion geometries:\n  1. A half-space $\\Omega = \\{\\mathbf{x} \\in \\mathbb{R}^3 \\mid x \\le t\\}$ intersected with $V$, where $t \\in \\mathbb{R}$. For this geometry, $f$ equals the clamped length along the $x$-dimension divided by $1$, namely $f = \\max(0,\\min(1,t))$.\n  2. An axis-aligned rectangular box $\\Omega = [a_x,b_x]\\times[a_y,b_y]\\times[a_z,b_z]$ intersected with $V$. For this geometry, $f$ equals the overlap volume divided by $|V|$, with overlap volume computed by the product of overlapped lengths across dimensions:\n     $$\n     f \\;=\\; \\prod_{d\\in\\{x,y,z\\}} \\max\\!\\big(0,\\min(1,b_d) - \\max(0,a_d)\\big).\n     $$\n- For each test case below, compute both the analytic $f$ and the Monte Carlo estimate $\\hat{f}_N$, then report the absolute error $|\\hat{f}_N - f|$.\n\nUse the following test suite, each on $V=[0,1]^3$ with the specified lesion geometry, sample size $N$, and random seed:\n- Case 1 (general half-space): $\\Omega = \\{\\mathbf{x}\\mid x \\le 0.30\\}$, $N = 50000$, seed $= 123$.\n- Case 2 (axis-aligned box, interior partial overlap): $\\Omega = [0.20,0.80]\\times[0.20,0.80]\\times[0.20,0.80]$, $N = 50000$, seed $= 12345$.\n- Case 3 (axis-aligned box, tiny overlap): $\\Omega = [0.99,1.50]\\times[0,1]\\times[0,1]$, $N = 1000$, seed $= 42$.\n- Case 4 (axis-aligned box, full coverage): $\\Omega = [-1,2]\\times[-1,2]\\times[-1,2]$, $N = 1000$, seed $= 7$.\n- Case 5 (axis-aligned box, no coverage): $\\Omega = [2,3]\\times[2,3]\\times[2,3]$, $N = 1000$, seed $= 11$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The $i$-th entry must be the absolute error $|\\hat{f}_N - f|$ for Case $i$, expressed as a decimal number in $[0,1]$ with no units. For example, an output for three cases would look like: $[e_1,e_2,e_3]$.", "solution": "The problem is valid. It is scientifically grounded in the principles of integral calculus and probability theory, specifically Monte Carlo methods, as applied to the field of radiomics. The problem is well-posed, objective, and provides all necessary information to derive the theoretical properties of the estimator and to implement a computational solution for the specified test cases.\n\nThe problem asks for two main components: a theoretical derivation of the properties of a Monte Carlo estimator for subvoxel occupancy fraction, and a computational implementation to compare this estimator against analytic formulas for specific geometries.\n\nFirst, we address the theoretical derivation. The subvoxel occupancy fraction $f$ of a lesion $\\Omega$ within a voxel $V = [0,1]^3$ is defined as the volume integral of the lesion's indicator function $\\mathbb{1}_{\\Omega}(\\mathbf{x})$ over the voxel, normalized by the voxel's volume $|V|$. Given $|V| = |[0,1]^3| = 1$, the expression simplifies to:\n$$\nf = \\int_V \\mathbb{1}_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}\n$$\nThe Monte Carlo estimator, $\\hat{f}_N$, is constructed by drawing $N$ independent and identically distributed (i.i.d.) random points, $\\mathbf{X}_1, \\dots, \\mathbf{X}_N$, from a uniform distribution over the voxel $V$. The estimator is the sample mean of the indicator function evaluated at these points:\n$$\n\\hat{f}_N = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{1}_{\\Omega}(\\mathbf{X}_i)\n$$\nLet $Y_i = \\mathbb{1}_{\\Omega}(\\mathbf{X}_i)$. Each $Y_i$ is a random variable. Since $\\mathbf{X}_i$ is uniformly distributed in $V$, the probability that $\\mathbf{X}_i$ falls within $\\Omega$ is the ratio of the volume of the intersection of $\\Omega$ and $V$ to the volume of $V$. This is precisely the definition of $f$.\n$$\nP(Y_i=1) = P(\\mathbf{X}_i \\in \\Omega) = \\frac{|\\Omega \\cap V|}{|V|} = f\n$$\nThus, each $Y_i$ is a Bernoulli random variable, $Y_i \\sim \\text{Bernoulli}(f)$.\n\nTo determine if the estimator is biased, we compute its expected value, $E[\\hat{f}_N]$.\n$$\nE[\\hat{f}_N] = E\\left[\\frac{1}{N} \\sum_{i=1}^N Y_i\\right]\n$$\nBy the linearity of expectation:\n$$\nE[\\hat{f}_N] = \\frac{1}{N} \\sum_{i=1}^N E[Y_i]\n$$\nThe expected value of a Bernoulli variable $Y_i$ with parameter $f$ is $E[Y_i] = f$. Since the samples are i.i.d., this holds for all $i=1, \\dots, N$.\n$$\nE[\\hat{f}_N] = \\frac{1}{N} \\sum_{i=1}^N f = \\frac{1}{N} (Nf) = f\n$$\nThe bias of an estimator is defined as $E[\\hat{f}_N] - f$. In this case, the bias is $f - f = 0$. Therefore, the Monte Carlo estimator $\\hat{f}_N$ is an **unbiased** estimator of the true fraction $f$.\n\nNext, we derive the variance of the estimator, $\\text{Var}(\\hat{f}_N)$.\n$$\n\\text{Var}(\\hat{f}_N) = \\text{Var}\\left(\\frac{1}{N} \\sum_{i=1}^N Y_i\\right)\n$$\nFor a sum of independent random variables, the variance of the sum is the sum of the variances.\n$$\n\\text{Var}(\\hat{f}_N) = \\frac{1}{N^2} \\text{Var}\\left(\\sum_{i=1}^N Y_i\\right) = \\frac{1}{N^2} \\sum_{i=1}^N \\text{Var}(Y_i)\n$$\nThe variance of a Bernoulli random variable $Y_i$ with parameter $f$ is $\\text{Var}(Y_i) = f(1-f)$. Since all $Y_i$ are identically distributed:\n$$\n\\text{Var}(\\hat{f}_N) = \\frac{1}{N^2} \\sum_{i=1}^N f(1-f) = \\frac{1}{N^2} (Nf(1-f)) = \\frac{f(1-f)}{N}\n$$\nThe variance of the estimator is $\\frac{f(1-f)}{N}$. This result is fundamental to Monte Carlo methods: the standard error of the estimate, which is the square root of the variance, decreases proportionally to $1/\\sqrt{N}$. This means that to halve the error, one must quadruple the number of samples $N$.\n\nIn contrast, the analytic intersection formulas provided are deterministic calculations. For a given geometry, they yield the single, exact value of $f$. There is no random sampling involved. Consequently, the result of an analytic formula has **zero variance** and **zero error**. This is ideal, but such formulas are only tractable for simple, regular geometries like the ones specified. The Monte Carlo method, while having non-zero variance, offers a powerful and general alternative for complex or arbitrary lesion shapes $\\Omega$ where analytic integration is infeasible.\n\nThe implementation will consist of three main parts:\n$1$. A function for the Monte Carlo estimation, `monte_carlo_estimate`, which generates $N$ random $3$D points in $[0,1]^3$, checks for each point if it lies inside the specified geometry $\\Omega$, and returns the fraction of points that do. The function will be parameterized by the geometry type, its parameters, the number of samples $N$, and a random seed for reproducibility.\n$2$. Functions for the analytic calculations, `analytic_half_space` and `analytic_box`, which implement the exact formulas provided in the problem description.\n$3$. A main execution block that iterates through the specified test cases. For each case, it will call both the Monte Carlo and the appropriate analytic function to compute $\\hat{f}_N$ and $f$, respectively. It will then calculate the absolute error $|\\hat{f}_N - f|$ and store it. Finally, it will print all errors in the required format.\n\nFor the half-space $\\Omega = \\{\\mathbf{x} \\in \\mathbb{R}^3 \\mid x \\le t\\}$, the analytic fraction $f$ is the volume of the region $[0,t] \\times [0,1] \\times [0,1]$ within the unit cube. This simplifies to the length of the interval $[0,1] \\cap (-\\infty, t]$. The length is $\\min(1,t)$ if $t>0$ and $0$ otherwise, which is correctly captured by $f = \\max(0, \\min(1,t))$.\n\nFor the axis-aligned box $\\Omega = [a_x,b_x]\\times[a_y,b_y]\\times[a_z,b_z]$, the intersection with the voxel $V=[0,1]^3$ is another axis-aligned box. The volume of this intersection is the product of the lengths of the overlapping intervals in each dimension. The length of the overlap between $[0,1]$ and $[a_d, b_d]$ for any dimension $d$ is $\\max(0, \\min(1,b_d) - \\max(0,a_d))$. The product of these three lengths gives the exact fraction $f$, as $|V|=1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing and comparing Monte Carlo estimates and analytic\n    values for subvoxel occupancy fractions for several test cases.\n    \"\"\"\n\n    def analytic_half_space(t: float) -> float:\n        \"\"\"\n        Computes the exact volume fraction for a half-space intersected with the unit cube.\n        \n        Args:\n            t: The threshold defining the half-space x <= t.\n\n        Returns:\n            The exact fraction f.\n        \"\"\"\n        # The voxel is V = [0,1]^3. The intersection volume is the product of\n        # interval lengths. For y and z, the length is 1. For x, it's the\n        # length of [0,1] intersected with (-inf, t], which is max(0, min(1,t)).\n        return max(0.0, min(1.0, t))\n\n    def analytic_box(bounds: tuple) -> float:\n        \"\"\"\n        Computes the exact volume fraction for an axis-aligned box intersected with the unit cube.\n\n        Args:\n            bounds: A tuple (ax, bx, ay, by, az, bz) defining the box.\n\n        Returns:\n            The exact fraction f.\n        \"\"\"\n        ax, bx, ay, by, az, bz = bounds\n        # For each dimension, calculate the length of the intersection of [0,1] and [a,b].\n        # The length is max(0, end_of_intersection - start_of_intersection).\n        # end_of_intersection = min(1, b)\n        # start_of_intersection = max(0, a)\n        overlap_x = max(0.0, min(1.0, bx) - max(0.0, ax))\n        overlap_y = max(0.0, min(1.0, by) - max(0.0, ay))\n        overlap_z = max(0.0, min(1.0, bz) - max(0.0, az))\n        \n        # Since |V|=1, the volume is the product of the overlap lengths.\n        return overlap_x * overlap_y * overlap_z\n\n    def monte_carlo_estimate(\n        geom_type: str, \n        geom_params: tuple, \n        n_samples: int, \n        seed: int\n    ) -> float:\n        \"\"\"\n        Estimates the subvoxel occupancy fraction f using a Monte Carlo method.\n\n        Args:\n            geom_type: The type of geometry ('half_space' or 'box').\n            geom_params: Parameters defining the geometry.\n            n_samples: The number of random points to sample (N).\n            seed: The random seed for reproducibility.\n\n        Returns:\n            The Monte Carlo estimate of f.\n        \"\"\"\n        # Use NumPy's recommended random number generator\n        rng = np.random.default_rng(seed)\n        \n        # Generate N points uniformly distributed in the unit cube [0,1]^3\n        points = rng.uniform(0.0, 1.0, size=(n_samples, 3))\n        \n        if geom_type == 'half_space':\n            t = geom_params[0]\n            # Check if the x-coordinate of each point is within the lesion\n            inside = points[:, 0] <= t\n        elif geom_type == 'box':\n            ax, bx, ay, by, az, bz = geom_params\n            # Check if each point is within the box bounds for all three dimensions\n            inside = (\n                (points[:, 0] >= ax) & (points[:, 0] <= bx) &\n                (points[:, 1] >= ay) & (points[:, 1] <= by) &\n                (points[:, 2] >= az) & (points[:, 2] <= bz)\n            )\n        else:\n            raise ValueError(f\"Unknown geometry type: {geom_type}\")\n            \n        # The estimate is the fraction of points that fall inside the lesion\n        count = np.sum(inside)\n        return float(count / n_samples)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'half_space', 'params': (0.30,), 'N': 50000, 'seed': 123},\n        {'type': 'box', 'params': (0.20, 0.80, 0.20, 0.80, 0.20, 0.80), 'N': 50000, 'seed': 12345},\n        {'type': 'box', 'params': (0.99, 1.50, 0.0, 1.0, 0.0, 1.0), 'N': 1000, 'seed': 42},\n        {'type': 'box', 'params': (-1.0, 2.0, -1.0, 2.0, -1.0, 2.0), 'N': 1000, 'seed': 7},\n        {'type': 'box', 'params': (2.0, 3.0, 2.0, 3.0, 2.0, 3.0), 'N': 1000, 'seed': 11}\n    ]\n\n    absolute_errors = []\n    for case in test_cases:\n        geom_type = case['type']\n        geom_params = case['params']\n        N = case['N']\n        seed = case['seed']\n\n        # Compute Monte Carlo estimate\n        f_hat = monte_carlo_estimate(geom_type, geom_params, N, seed)\n\n        # Compute exact analytic value\n        if geom_type == 'half_space':\n            f_exact = analytic_half_space(geom_params[0])\n        else: # geom_type == 'box'\n            f_exact = analytic_box(geom_params)\n            \n        # Calculate and store the absolute error\n        error = abs(f_hat - f_exact)\n        absolute_errors.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, absolute_errors))}]\")\n\nsolve()\n\n```", "id": "4554678"}, {"introduction": "With an understanding of the occupancy fraction $f$, we can now explore its consequences on quantitative measurements. This practice [@problem_id:4554638] demonstrates how a common segmentation method, intensity thresholding, leads to a systematic bias in volume estimation due to PVE. Deriving this bias analytically will highlight the limitations of simple approaches and reveal the principle behind more accurate, occupancy-aware corrections.", "problem": "A solid lesion with a smooth boundary is imaged using a three-dimensional modality with isotropic cubic voxels of edge length $s$. The observed voxel intensity arises from linear mixing of two tissue classes due to the partial volume effect (PVE), such that for a given voxel the measured intensity is $I = f \\mu_{L} + (1 - f) \\mu_{B}$, where $f \\in [0,1]$ is the fraction of the voxel volume occupied by the lesion, $\\mu_{L}$ is the lesion tissue mean intensity, and $\\mu_{B}$ is the background tissue mean intensity. A binary segmentation classifies a voxel as lesion if $I \\ge \\tau$, for a fixed threshold $\\tau$, and estimates the lesion volume by counting all classified voxels and multiplying by the voxel volume $s^{3}$.\n\nAssume the following well-tested and widely used modeling approximations for high-resolution imaging of smooth interfaces:\n1. In the set of boundary voxels intersected by the lesion interface, the subvoxel occupancy fraction $f$ is uniformly distributed on $[0,1]$ due to random relative positioning of the interface within voxels.\n2. The expected number of such boundary voxels is $S / s^{2}$, where $S$ is the continuous lesion surface area, because each boundary voxel subtends approximately one voxel-face area $s^{2}$ on the interface.\n3. The true continuous lesion volume can be decomposed as the sum of fully interior voxels (occupancy $f=1$) and boundary voxels with fractional occupancy $f \\in (0,1)$.\n\nStarting from these assumptions and the linear mixing model, derive an analytical expression for the expected bias $\\Delta V = V_{\\text{thresh}} - V_{\\text{true}}$ of the thresholded voxel-count volume estimate $V_{\\text{thresh}}$ relative to the true continuous volume $V_{\\text{true}}$. Then, using the same assumptions, derive the occupancy-weighted correction that would remove this bias in expectation by weighting each boundary voxel by its occupancy $f$ rather than by $1$.\n\nFinally, for the specific parameter values $s = 2\\,\\text{mm}$, $S = 1500\\,\\text{mm}^{2}$, $\\mu_{L} = 120$ (arbitrary intensity units), $\\mu_{B} = 20$ (arbitrary intensity units), and threshold $\\tau = 80$ (arbitrary intensity units), compute the expected signed bias $\\Delta V$ in cubic millimeters. Round your answer to four significant figures and express it in $\\text{mm}^{3}$. Do not include units in your final boxed answer.", "solution": "The problem is to derive the expected bias of a threshold-based volume estimation method under a partial volume effect model, and then to compute this bias for a specific set of parameters.\n\nFirst, we formalize the quantities involved. The voxel intensity $I$ is given by the linear mixing model $I = f \\mu_{L} + (1 - f) \\mu_{B}$, where $f$ is the fraction of the voxel occupied by the lesion, $\\mu_{L}$ is the lesion intensity, and $\\mu_{B}$ is the background intensity. A voxel is classified as part of the lesion if its intensity $I$ is greater than or equal to a threshold $\\tau$. We assume $\\mu_L > \\mu_B$. The problem states that the threshold is set such that $\\mu_B < \\tau < \\mu_L$.\n\nThe condition for a voxel to be classified as lesion is:\n$$f \\mu_{L} + (1 - f) \\mu_{B} \\geq \\tau$$\nRearranging for $f$:\n$$f \\mu_{L} + \\mu_{B} - f \\mu_{B} \\geq \\tau$$\n$$f (\\mu_{L} - \\mu_{B}) \\geq \\tau - \\mu_{B}$$\nSince $\\mu_{L} > \\mu_{B}$, we can divide by $(\\mu_{L} - \\mu_{B})$ without changing the inequality direction:\n$$f \\geq \\frac{\\tau - \\mu_{B}}{\\mu_{L} - \\mu_{B}}$$\nLet us define the normalized threshold $\\tau'$ as:\n$$\\tau' = \\frac{\\tau - \\mu_{B}}{\\mu_{L} - \\mu_{B}}$$\nThe condition simplifies to $f \\geq \\tau'$. Since $\\mu_B < \\tau < \\mu_L$, it follows that $0 < \\tau' < 1$.\n\nThe volume estimated by thresholding, $V_{\\text{thresh}}$, is the product of the voxel volume $s^3$ and the count of voxels that satisfy the classification criterion. We can analyze the contribution from three types of voxels:\n1.  **Interior voxels**: These are fully occupied by the lesion, so $f=1$. Since $1 > \\tau'$, all interior voxels are correctly classified.\n2.  **Exterior voxels**: These are fully background, so $f=0$. Since $0 < \\tau'$, they are never classified as lesion.\n3.  **Boundary voxels**: These are partially occupied, with $f \\in (0,1)$. A boundary voxel is counted if and only if its occupancy $f$ is at least $\\tau'$.\n\nLet $N_{\\text{int}}$ be the number of interior voxels and $N_{b}$ be the number of boundary voxels. The expected thresholded volume $E[V_{\\text{thresh}}]$ is:\n$$E[V_{\\text{thresh}}] = \\left( N_{\\text{int}} + E[N_{b, \\text{counted}}] \\right) s^3$$\nwhere $E[N_{b, \\text{counted}}]$ is the expected number of boundary voxels classified as lesion. This is the expected total number of boundary voxels, $E[N_b]$, multiplied by the probability that a single boundary voxel is counted, $P(f \\geq \\tau')$.\nFrom Assumption 1, $f$ is uniformly distributed on $[0,1]$ for boundary voxels, so its probability density function is $p(f) = 1$ for $f \\in [0,1]$.\n$$P(f \\geq \\tau') = \\int_{\\tau'}^{1} p(f) df = \\int_{\\tau'}^{1} 1 \\,df = 1 - \\tau'$$\nFrom Assumption 2, the expected number of boundary voxels is $E[N_b] = S/s^2$.\nThus, $E[N_{b, \\text{counted}}] = E[N_b] P(f \\geq \\tau') = \\frac{S}{s^2} (1 - \\tau')$.\nSubstituting this into the expression for $E[V_{\\text{thresh}}]$:\n$$E[V_{\\text{thresh}}] = \\left( N_{\\text{int}} + \\frac{S}{s^2} (1 - \\tau') \\right) s^3 = N_{\\text{int}} s^3 + Ss(1 - \\tau')$$\n\nNext, we determine the expected true lesion volume, $E[V_{\\text{true}}]$. The true volume is the sum of the fractional volumes contributed by all voxels.\n$$V_{\\text{true}} = \\sum_{i \\in \\text{all voxels}} f_i s^3 = N_{\\text{int}}(1)s^3 + \\sum_{j=1}^{N_b} f_j s^3$$\nTaking the expectation:\n$$E[V_{\\text{true}}] = N_{\\text{int}}s^3 + s^3 E\\left[\\sum_{j=1}^{N_b} f_j\\right]$$\nUsing the properties of compound random variables (or Wald's identity), this is $s^3 E[N_b] E[f]$. The expected occupancy fraction $E[f]$ for a boundary voxel, given $f \\sim U(0,1)$, is:\n$$E[f] = \\int_{0}^{1} f \\cdot p(f) df = \\int_{0}^{1} f \\,df = \\left[ \\frac{f^2}{2} \\right]_0^1 = \\frac{1}{2}$$\nSo, the expected contribution from boundary voxels is $s^3 \\left(\\frac{S}{s^2}\\right) \\left(\\frac{1}{2}\\right) = \\frac{Ss}{2}$.\nThe expected true volume is:\n$$E[V_{\\text{true}}] = N_{\\text{int}}s^3 + \\frac{Ss}{2}$$\n\nThe expected bias, $E[\\Delta V]$, is the difference between the expected estimated volume and the expected true volume:\n$$E[\\Delta V] = E[V_{\\text{thresh}}] - E[V_{\\text{true}}]$$\n$$E[\\Delta V] = \\left( N_{\\text{int}}s^3 + Ss(1 - \\tau') \\right) - \\left( N_{\\text{int}}s^3 + \\frac{Ss}{2} \\right)$$\n$$E[\\Delta V] = Ss(1 - \\tau') - \\frac{Ss}{2} = Ss\\left( 1 - \\tau' - \\frac{1}{2} \\right)$$\n$$E[\\Delta V] = Ss\\left( \\frac{1}{2} - \\tau' \\right)$$\nSubstituting the expression for $\\tau'$ gives the final analytical expression for the expected bias:\n$$E[\\Delta V] = Ss\\left( \\frac{1}{2} - \\frac{\\tau - \\mu_{B}}{\\mu_{L} - \\mu_{B}} \\right)$$\n\nFor the second part of the problem, we consider an occupancy-weighted volume correction. Instead of counting a voxel as $1$ or $0$, we weight each voxel by its estimated occupancy fraction, $\\hat{f}$. From the linear mixing model, we can invert the equation to estimate $f$ from $I$:\n$$\\hat{f} = \\frac{I - \\mu_B}{\\mu_L - \\mu_B}$$\nUnder the noiseless model, $I = f \\mu_{L} + (1 - f) \\mu_{B}$, so the estimated fraction is:\n$$\\hat{f} = \\frac{(f \\mu_{L} + (1 - f) \\mu_{B}) - \\mu_B}{\\mu_L - \\mu_B} = \\frac{f(\\mu_L - \\mu_B)}{\\mu_L - \\mu_B} = f$$\nThe occupancy-weighted volume estimate, $V_{\\text{corr}}$, is the sum of these estimated fractional volumes:\n$$V_{\\text{corr}} = \\sum_{i \\in \\text{all voxels}} \\hat{f}_i s^3 = \\sum_{i \\in \\text{all voxels}} f_i s^3$$\nThis is identical to the definition of the true volume, $V_{\\text{true}}$. Therefore, the bias of this corrected estimator is $V_{\\text{corr}} - V_{\\text{true}} = 0$, and its expected bias is $E[V_{\\text{corr}} - V_{\\text{true}}] = 0$. This occupancy-weighting scheme thus removes the bias in expectation.\n\nFinally, we compute the expected signed bias for the given parameters: $s = 2\\,\\text{mm}$, $S = 1500\\,\\text{mm}^{2}$, $\\mu_{L} = 120$, $\\mu_{B} = 20$, and $\\tau = 80$.\nFirst, calculate the normalized threshold $\\tau'$:\n$$\\tau' = \\frac{80 - 20}{120 - 20} = \\frac{60}{100} = 0.6$$\nNow, substitute the values into the derived expression for the expected bias:\n$$E[\\Delta V] = Ss\\left( \\frac{1}{2} - \\tau' \\right) = (1500\\,\\text{mm}^2)(2\\,\\text{mm})\\left( 0.5 - 0.6 \\right)$$\n$$E[\\Delta V] = (3000\\,\\text{mm}^3)(-0.1)$$\n$$E[\\Delta V] = -300\\,\\text{mm}^3$$\nThe problem requires the answer to be rounded to four significant figures. Thus, we express the result as $-300.0\\,\\text{mm}^3$.", "answer": "$$\\boxed{-300.0}$$", "id": "4554638"}, {"introduction": "Beyond geometric features like volume, PVE also corrupts intensity-based radiomic features. This exercise [@problem_id:4554626] investigates how different statistical summaries of intensity are affected by PVE, contrasting the familiar sample mean with the more robust sample median. This practice is key to understanding feature robustness, a critical concept for building reliable radiomic models in the presence of imaging artifacts.", "problem": "You are studying the impact of the Partial Volume Effect (PVE) on region-of-interest radiomic intensity summaries in positron emission tomography, where measured voxel intensity is the volume-fraction weighted average of underlying tissue intensities due to finite voxel size and system blurring. Consider a lesion embedded in background tissue. The true lesion intensity is $I_{L} = 8.0$ standardized uptake value (SUV) and the surrounding background intensity is $I_{B} = 2.0$ SUV. An analyst has segmented a region of interest and computed both the sample mean and the sample median of the voxel intensities. The region comprises a very large number of voxels, of which a fraction $p = 0.6$ are boundary voxels affected by PVE. In boundary voxels, the lesion volume fraction $F$ is assumed to be independent and uniformly distributed on $[0,1]$, and the measured intensity is given by $I = F I_{L} + (1 - F) I_{B}$. The remaining fraction $1 - p$ of voxels are pure lesion voxels with $F = 1$ and measured intensity $I = I_{L}$. Assume the number of voxels is sufficiently large that the sample mean and sample median can be identified with the distributional mean and distributional median, respectively.\n\nStarting only from the definitions of the mean and median and the linear mixing model for PVE, derive the expected mean and the median of the measured intensities in this region for the specified parameters, then compute the absolute relative biases of these two summaries with respect to $I_{L}$, defined by $b_{\\mathrm{mean}} = \\left|\\frac{\\mathbb{E}[I] - I_{L}}{I_{L}}\\right|$ and $b_{\\mathrm{median}} = \\left|\\frac{\\mathrm{median}(I) - I_{L}}{I_{L}}\\right|$. Finally, compute the ratio $\\rho = \\frac{b_{\\mathrm{median}}}{b_{\\mathrm{mean}}}$. Round your final ratio to four significant figures. Express the final ratio as a pure number with no units.", "solution": "The problem as stated is scientifically grounded, well-posed, and contains sufficient information for a unique solution. We may therefore proceed with the derivation.\n\nThe problem describes a statistical mixture model for the measured voxel intensities within a region of interest. Let $I$ be the random variable representing the measured intensity of a voxel chosen uniformly from the region. The region contains two distinct populations of voxels:\n1.  Pure lesion voxels, which constitute a fraction $1-p$ of the total. For these voxels, the intensity is constant, $I_{\\mathrm{pure}} = I_{L}$.\n2.  Boundary voxels affected by the partial volume effect (PVE), which constitute a fraction $p$ of the total. For these voxels, the intensity is given by the linear mixing model $I_{\\mathrm{bnd}} = F I_{L} + (1 - F) I_{B}$, where $F$ is the lesion volume fraction.\n\nThe problem states that $F$ is a random variable that is uniformly distributed on the interval $[0, 1]$, denoted $F \\sim U(0,1)$. We first determine the distribution of $I_{\\mathrm{bnd}}$. We can rewrite the expression for $I_{\\mathrm{bnd}}$ as:\n$$I_{\\mathrm{bnd}} = F(I_{L} - I_{B}) + I_{B}$$\nThis is a linear transformation of the random variable $F$. Since $F \\sim U(0,1)$ and $I_{L} > I_{B}$, the resulting distribution for $I_{\\mathrm{bnd}}$ is also uniform. The range of $I_{\\mathrm{bnd}}$ is determined by the values at the endpoints of the support of $F$:\nFor $F=0$, $I_{\\mathrm{bnd}} = I_{B}$.\nFor $F=1$, $I_{\\mathrm{bnd}} = I_{L}$.\nTherefore, the intensity of a boundary voxel is uniformly distributed on the interval $[I_B, I_L]$, i.e., $I_{\\mathrm{bnd}} \\sim U(I_B, I_L)$.\n\nThe overall distribution of $I$ is a mixture of a discrete distribution (a point mass at $I_L$) and a continuous uniform distribution.\n\nFirst, we derive the expected mean intensity, $\\mathbb{E}[I]$. Using the law of total expectation:\n$$\\mathbb{E}[I] = P(\\text{pure}) \\cdot \\mathbb{E}[I|\\text{pure}] + P(\\text{boundary}) \\cdot \\mathbb{E}[I|\\text{boundary}]$$\nThe probabilities are $P(\\text{pure}) = 1-p$ and $P(\\text{boundary}) = p$. The conditional expectations are:\n$\\mathbb{E}[I|\\text{pure}] = I_{L}$.\n$\\mathbb{E}[I|\\text{boundary}] = \\mathbb{E}[I_{\\mathrm{bnd}}]$. For a uniform distribution $U(a,b)$, the mean is $\\frac{a+b}{2}$. Thus, $\\mathbb{E}[I_{\\mathrm{bnd}}] = \\frac{I_B + I_L}{2}$.\nSubstituting these into the expression for $\\mathbb{E}[I]$:\n$$\\mathbb{E}[I] = (1-p)I_L + p \\left( \\frac{I_B + I_L}{2} \\right)$$\nRearranging this gives:\n$$\\mathbb{E}[I] = I_L - pI_L + \\frac{pI_L}{2} + \\frac{pI_B}{2} = I_L - \\frac{p}{2}(I_L - I_B)$$\nUsing the given values $I_L=8.0$, $I_B=2.0$, and $p=0.6$:\n$$\\mathbb{E}[I] = 8.0 - \\frac{0.6}{2}(8.0 - 2.0) = 8.0 - 0.3(6.0) = 8.0 - 1.8 = 6.2$$\n\nNext, we derive the median intensity, $\\mathrm{median}(I)$. The median, which we denote as $m$, is the value such that $P(I \\le m) = 0.5$. To find this, we first construct the cumulative distribution function (CDF) of $I$, which we denote $G(i) = P(I \\le i)$. Using the law of total probability:\n$$G(i) = (1-p)P(I_{\\mathrm{pure}} \\le i) + p P(I_{\\mathrm{bnd}} \\le i)$$\nThe CDF for the pure voxels (a point mass at $I_L$) is $P(I_{\\mathrm{pure}} \\le i) = H(i-I_L)$, where $H$ is the Heaviside step function ($0$ for argument $<0$, $1$ for argument $\\ge 0$).\nThe CDF for the boundary voxels, $I_{\\mathrm{bnd}} \\sim U(I_B, I_L)$, is:\n$$P(I_{\\mathrm{bnd}} \\le i) = \\begin{cases} 0 & \\text{if } i < I_B \\\\ \\frac{i - I_B}{I_L - I_B} & \\text{if } I_B \\le i \\le I_L \\\\ 1 & \\text{if } i > I_L \\end{cases}$$\nCombining these, the overall CDF $G(i)$ is:\n$$G(i) = \\begin{cases} 0 & \\text{if } i < I_B \\\\ p\\left(\\frac{i - I_B}{I_L - I_B}\\right) & \\text{if } I_B \\le i < I_L \\\\ 1 & \\text{if } i \\ge I_L \\end{cases}$$\nWe check the value of the CDF as $i$ approaches $I_L$ from below: $\\lim_{i \\to I_L^-} G(i) = p\\left(\\frac{I_L - I_B}{I_L - I_B}\\right) = p$.\nWith $p=0.6$, the cumulative probability reaches $0.6$ at $I_L$. Since we seek the median where the cumulative probability is $0.5$, and $0.5 < p$, the median must lie in the interval $[I_B, I_L)$. We solve for $m$ by setting $G(m)=0.5$:\n$$p\\left(\\frac{m - I_B}{I_L - I_B}\\right) = 0.5$$\n$$m - I_B = \\frac{0.5}{p}(I_L - I_B)$$\n$$m = I_B + \\frac{0.5}{p}(I_L - I_B)$$\nSubstituting the numerical values:\n$$m = 2.0 + \\frac{0.5}{0.6}(8.0 - 2.0) = 2.0 + \\frac{5}{6}(6.0) = 2.0 + 5.0 = 7.0$$\nSo, the median intensity is $\\mathrm{median}(I) = m = 7.0$.\n\nNow, we compute the absolute relative biases with respect to the true lesion intensity $I_L = 8.0$.\nThe bias of the mean is:\n$$b_{\\mathrm{mean}} = \\left|\\frac{\\mathbb{E}[I] - I_{L}}{I_{L}}\\right| = \\left|\\frac{6.2 - 8.0}{8.0}\\right| = \\left|\\frac{-1.8}{8.0}\\right| = \\frac{1.8}{8.0} = \\frac{9}{40} = 0.225$$\nThe bias of the median is:\n$$b_{\\mathrm{median}} = \\left|\\frac{\\mathrm{median}(I) - I_{L}}{I_{L}}\\right| = \\left|\\frac{7.0 - 8.0}{8.0}\\right| = \\left|\\frac{-1.0}{8.0}\\right| = \\frac{1.0}{8.0} = \\frac{1}{8} = 0.125$$\n\nFinally, we compute the ratio $\\rho = \\frac{b_{\\mathrm{median}}}{b_{\\mathrm{mean}}}$:\n$$\\rho = \\frac{0.125}{0.225} = \\frac{1/8}{9/40} = \\frac{1}{8} \\cdot \\frac{40}{9} = \\frac{5}{9}$$\nAs a decimal, $\\rho = 0.5555...$. Rounding to four significant figures, we get $0.5556$.\n\nTo confirm, we can derive a general expression for $\\rho$.\n$$b_{\\mathrm{mean}} = \\left|\\frac{(I_L - \\frac{p}{2}(I_L - I_B)) - I_L}{I_L}\\right| = \\left|\\frac{-\\frac{p}{2}(I_L - I_B)}{I_L}\\right| = \\frac{p(I_L - I_B)}{2I_L}$$\n$$b_{\\mathrm{median}} = \\left|\\frac{(I_B + \\frac{0.5}{p}(I_L - I_B)) - I_L}{I_L}\\right| = \\left|\\frac{(I_B - I_L) + \\frac{0.5}{p}(I_L - I_B)}{I_L}\\right| = \\left|\\frac{-(I_L - I_B) + \\frac{0.5}{p}(I_L - I_B)}{I_L}\\right|$$\n$$b_{\\mathrm{median}} = \\frac{I_L - I_B}{I_L} \\left|\\frac{0.5}{p} - 1\\right| = \\frac{I_L - I_B}{I_L} \\left(1 - \\frac{0.5}{p}\\right) \\quad (\\text{since } p=0.6 > 0.5)$$\n$$b_{\\mathrm{median}} = \\frac{I_L - I_B}{I_L} \\left(\\frac{p - 0.5}{p}\\right)$$\nThe ratio is:\n$$\\rho = \\frac{b_{\\mathrm{median}}}{b_{\\mathrm{mean}}} = \\frac{\\frac{I_L - I_B}{I_L} \\left(\\frac{p - 0.5}{p}\\right)}{\\frac{p(I_L - I_B)}{2I_L}} = \\frac{2(p - 0.5)}{p^2}$$\nSubstituting $p=0.6$ into this general expression:\n$$\\rho = \\frac{2(0.6 - 0.5)}{(0.6)^2} = \\frac{2(0.1)}{0.36} = \\frac{0.2}{0.36} = \\frac{20}{36} = \\frac{5}{9} \\approx 0.5556$$\nThe result is independent of $I_L$ and $I_B$, and the calculation is confirmed.", "answer": "$$\\boxed{0.5556}$$", "id": "4554626"}]}