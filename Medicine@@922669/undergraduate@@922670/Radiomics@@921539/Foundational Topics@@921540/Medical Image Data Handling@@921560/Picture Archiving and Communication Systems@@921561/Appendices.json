{"hands_on_practices": [{"introduction": "In multi-center radiomics research, aggregating data from different hospitals is a common but perilous task. Before any scientific analysis, one must solve a critical data management problem: how to uniquely and reliably identify each imaging study. This thought experiment [@problem_id:4555309] challenges you to navigate the real-world pitfalls of common Digital Imaging and Communications in Medicine (DICOM) identifiers and devise a robust strategy to build a coherent research cohort without errors.", "problem": "A radiomics consortium is aggregating computed tomography studies from $3$ hospitals into a single Picture Archiving and Communication System (PACS). Each site exports Digital Imaging and Communications in Medicine (DICOM) datasets with the following characteristics.\n\nFundamental context. In DICOM, Study Instance Unique Identifier (StudyInstanceUID) is a Unique Identifier (UID) intended to be globally unique per study, whereas Accession Number is an identifier for the imaging order issued by the Radiology Information System (RIS) that may be reused across time or institutions and may be truncated due to Value Representation limits. De-identification pipelines can preserve, deterministically remap, or non-deterministically regenerate UIDs.\n\nSite profiles. Site $A$ assigns Accession Numbers that are reused every calendar year; DICOM Issuer of Accession Number Sequence is often empty; de-identification preserves StudyInstanceUID. Site $B$ uses long alphanumeric accession strings; when written to DICOM, they are truncated to the Short String limit, causing collisions; de-identification deterministically remaps StudyInstanceUIDs but does so consistently across exports. Site $C$ uses a single Accession Number to cover multi-day protocols that produce multiple studies (distinct StudyInstanceUIDs) over $2$ to $3$ days; de-identification regenerates new, non-deterministic StudyInstanceUIDs on each export event for the same underlying study. Across the $3$ sites, some objects have empty Accession Number fields due to optional population. Data arrive in $2$ batches months apart; the consortium must deduplicate within and across batches and reconcile identifiers into a stable cohort key appropriate for radiomics.\n\nBased only on the definitions above and realistic DICOM/PACS behavior, which strategy is the safest to identify and reconcile unique studies across institutions and exports without over-merging unrelated studies or splitting the same study, while still permitting quality control?\n\nA. Use Accession Number as the global study key after normalizing case and stripping punctuation, and disambiguate by concatenating with Institution Name. This prefers the clinical order concept and will unify related studies while avoiding collisions due to normalization.\n\nB. Use StudyInstanceUID as the global study key across all sites. For Site $C$ where remapping varies by export, fall back to PatientID to join duplicates of the same study across exports, since patients are unique and persistent across de-identification.\n\nC. Use a composite key $(\\text{source\\_site}, \\text{StudyInstanceUID})$ as the primary identifier for each study within a batch. Maintain a per-site mapping table so that if the same site re-exports and changes StudyInstanceUID (as in Site $C$), join studies across exports by a content-derived fingerprint $H$ computed over the multiset of per-instance content hashes $h$, where $h$ includes non-personal-health-information acquisition invariants and pixel checksums (for example, concatenate Rows, Columns, Modality, Image Orientation values, and a cryptographic hash of Pixel Data for each instance), sorted before hashing. Use Accession Number only as an ancillary quality control attribute and consider Issuer of Accession Number Sequence when present; never merge based solely on Accession Number.\n\nD. Discard UIDs due to remapping variability and identify studies by clustering on Accession Number and Study Date (normalized to local time) so that multi-day protocols are split by date boundaries while keeping all series for the same clinical order together across exports; this avoids UID-related inconsistencies.\n\nSelect the single best option.", "solution": "### Problem Validation\n\nThis section validates the problem statement as a mandatory prerequisite to providing a solution.\n\n#### Step 1: Extract Givens\n\nThe problem provides the following information:\n\n*   **Objective:** Aggregate computed tomography (CT) studies from $3$ hospitals into a single Picture Archiving and Communication System (PACS) for a radiomics consortium.\n*   **Institutions:** Site $A$, Site $B$, Site $C$.\n*   **Data Delivery:** Data arrives in $2$ batches, months apart.\n*   **Core Task:** Deduplicate studies within and across batches and reconcile identifiers into a stable cohort key suitable for radiomics.\n*   **Constraints:** The solution must avoid over-merging unrelated studies and avoid splitting the same study. It must also permit quality control.\n*   **DICOM Context:**\n    *   `StudyInstanceUID`: Intended to be a globally unique identifier (UID) per study.\n    *   `Accession Number`: An identifier for the imaging order from a Radiology Information System (RIS). It may be reused across time or institutions and may be truncated.\n    *   `De-identification`: Can preserve, deterministically remap, or non-deterministically regenerate UIDs.\n*   **Site-Specific Profiles:**\n    *   **Site $A$:**\n        *   `Accession Number`s are reused every calendar year.\n        *   `Issuer of Accession Number Sequence` is often empty.\n        *   De-identification preserves `StudyInstanceUID`.\n    *   **Site $B$:**\n        *   Long alphanumeric `Accession Number` strings are truncated, causing collisions.\n        *   De-identification deterministically remaps `StudyInstanceUID`s consistently across exports.\n    *   **Site $C$:**\n        *   A single `Accession Number` is used for multi-day protocols that generate multiple distinct studies (each with a unique `StudyInstanceUID`) over $2$ to $3$ days.\n        *   De-identification regenerates new, non-deterministic `StudyInstanceUID`s on each export for the same underlying study.\n*   **General Condition:** Across all $3$ sites, some DICOM objects have empty `Accession Number` fields.\n\n#### Step 2: Validate Using Extracted Givens\n\n*   **Scientifically Grounded:** The problem is firmly grounded in the field of medical informatics and data engineering. The described behaviors of DICOM attributes (`StudyInstanceUID`, `Accession Number`), PACS, and de-identification pipelines are highly realistic and represent common, well-documented challenges in multi-center research studies.\n*   **Well-Posed:** The problem is well-posed. It presents a clear objective (create a stable study key), provides specific constraints (no over-merging/splitting), and details the complex behaviors of the available identifiers. The question asks for the \"safest\" strategy, which is defined by adherence to the given constraints. A unique best practice can be determined from the available options.\n*   **Objective:** The problem is stated using precise, objective, and technical language common to the field of medical imaging informatics. There are no subjective or opinion-based claims.\n*   **Completeness and Consistency:** The problem provides sufficient detail to systematically evaluate the proposed strategies. The characteristics of each site are distinct and create a complex but logically consistent set of challenges that a robust solution must address. There are no contradictions in the setup. For instance, the varied behaviors of `StudyInstanceUID` (preserved, deterministically remapped, non-deterministically regenerated) across sites are realistic scenarios.\n*   **Realism:** The scenario is not just realistic but is a classic representation of the data harmonization problems faced by research consortia. The fallibility of identifiers like `Accession Number` and the complexities introduced by de-identification are standard concerns.\n\n#### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a scientifically and technically sound problem that is well-posed, objective, and realistic. I will now proceed to the solution.\n\n### Derivation of the Optimal Strategy\n\nThe goal is to establish a stable, unique identifier for each study across all sites and both data batches. Let us analyze the suitability of the primary available identifiers.\n\n1.  **Analysis of `Accession Number`:**\n    *   At Site $A$, it is reused annually. Using `Accession Number` alone, or even with an institution identifier `($\\text{Site A}$, $\\text{Accession Number})$`, would lead to collisions and incorrect merging of studies from different years.\n    *   At Site $B$, it is truncated, leading to collisions where different original accession numbers map to the same truncated value. This would cause incorrect merging of unrelated studies.\n    *   At Site $C$, a single `Accession Number` is associated with multiple, distinct studies. Using it as a key would cause severe over-merging, conflating separate studies into one.\n    *   Furthermore, the field can be empty, making it unusable as a primary key.\n    *   **Conclusion:** `Accession Number` is fundamentally unreliable as a primary key for unique study identification across this consortium. Its use must be limited to an ancillary, non-definitive role, perhaps for quality control or manual review.\n\n2.  **Analysis of `StudyInstanceUID`:**\n    *   By DICOM definition, this is the intended unique identifier for a study.\n    *   At Site $A$, it is preserved, making it a perfect, stable key for studies from this site.\n    *   At Site $B$, it is deterministically remapped. This means that for a given original study, the remapped `StudyInstanceUID` is always the same across different exports (Batch $1$ and Batch $2$). Therefore, it is a stable and unique identifier for Site $B$ studies within the aggregated dataset.\n    *   At Site $C$, it is non-deterministically regenerated with each export. This is the critical failure point. A study from Site $C$ in Batch $1$ will have a different `StudyInstanceUID` than the exact same study re-exported in Batch $2$. `StudyInstanceUID` alone cannot be used to link these identical studies across batches.\n    *   **Conclusion:** `StudyInstanceUID` is a highly reliable identifier for Sites $A$ and $B$, but it fails for cross-batch reconciliation at Site $C$. A global strategy cannot rely solely on it.\n\n3.  **Synthesizing a Robust Strategy:**\n    *   A robust key must handle all sites and batches. Since `StudyInstanceUID` is largely reliable, the strategy should be based on it, with a specific mechanism to handle the failure case at Site $C$.\n    *   To prevent any potential (though theoretically unlikely) cross-site UID collisions, it is safest to use a composite key, such as $(\\text{source\\_site}, \\text{StudyInstanceUID})$, as a preliminary identifier.\n    *   For Site $C$, to identify that a study from Batch $2$ is the same as one from Batch $1$ despite having a different `StudyInstanceUID`, one must look at the data's *content*. This requires creating a \"fingerprint\" or \"content hash\" of the study that is invariant to metadata changes like UID regeneration.\n    *   A study's content is defined by the set of images (instances) it contains. A robust fingerprint for a study, let's call it $H$, can be computed by first generating a hash for each instance, $h$, and then combining these instance hashes.\n    *   The instance hash $h$ should be based on data that is invariant under the given de-identification rules. This includes the pixel data itself (which can be hashed using a cryptographic function like SHA-$256$) and fundamental acquisition parameters that are not PHI (e.g., `Modality`, `Rows`, `Columns`, `Image Orientation`).\n    *   To make the study-level hash $H$ deterministic, the set of instance hashes $\\{h_1, h_2, ..., h_n\\}$ must be combined in a fixed order. A standard way to do this is to sort the instance hashes before hashing the entire sequence: $H = \\text{hash}(\\text{sort}(\\{h_1, h_2, ..., h_n\\}))$.\n    *   The final strategy would involve:\n        a. For each incoming study, compute its content hash $H$.\n        b. Maintain a mapping table that links $(\\text{source\\_site}, H)$ to a canonical, persistent study identifier for the consortium.\n        c. For Sites $A$ and $B$, the `StudyInstanceUID` is stable and can be used as the primary means of identification, with the content hash $H$ serving as a powerful verification tool.\n        d. For Site $C$, the content hash $H$ is the *only* reliable way to link identical studies across the two batches.\n        e. `Accession Number` should be stored as metadata for manual review but never used for automated merging logic.\n\nThis derived strategy is the safest and most robust way to handle the specified conditions without over-merging or splitting studies.\n\n### Evaluation of Options\n\n**A. Use Accession Number as the global study key after normalizing case and stripping punctuation, and disambiguate by concatenating with Institution Name. This prefers the clinical order concept and will unify related studies while avoiding collisions due to normalization.**\n\nThis option is fundamentally flawed. It relies on `Accession Number`, which the problem statement explicitly describes as unreliable: it is reused at Site $A$, truncated causing collisions at Site $B$, and represents multiple studies at Site $C$. Normalization does not solve truncation, reuse, or the one-to-many relationship. This strategy would lead to massive over-merging and incorrect data linkage.\n\n**Verdict:** Incorrect.\n\n**B. Use StudyInstanceUID as the global study key across all sites. For Site $C$ where remapping varies by export, fall back to PatientID to join duplicates of the same study across exports, since patients are unique and persistent across de-identification.**\n\nThis option fails for two major reasons. First, the assumption that `PatientID` is persistent and unique after de-identification is unsafe and generally false in multi-center research contexts; patient identifiers are typically pseudonymized, and the mapping may not be stable or consistent. Second, and more critically, a patient can have multiple, distinct studies. Using `PatientID` to link studies would incorrectly merge all studies belonging to the same patient, failing the objective of identifying unique *studies*. For example, a patient's head CT and abdomen CT would be treated as duplicates of each other if re-exported.\n\n**Verdict:** Incorrect.\n\n**C. Use a composite key $(\\text{source\\_site}, \\text{StudyInstanceUID})$ as the primary identifier for each study within a batch. Maintain a per-site mapping table so that if the same site re-exports and changes StudyInstanceUID (as in Site $C$), join studies across exports by a content-derived fingerprint $H$ computed over the multiset of per-instance content hashes $h$, where $h$ includes non-personal-health-information acquisition invariants and pixel checksums (for example, concatenate Rows, Columns, Modality, Image Orientation values, and a cryptographic hash of Pixel Data for each instance), sorted before hashing. Use Accession Number only as an ancillary quality control attribute and consider Issuer of Accession Number Sequence when present; never merge based solely on Accession Number.**\n\nThis option perfectly aligns with the robust strategy derived from first principles. It correctly identifies the strengths and weaknesses of `StudyInstanceUID` and `Accession Number`. It proposes using a namespaced UID, which is good practice. Most importantly, it provides the correct and technically sound solution for the most difficult part of the problem—reconciling Site $C$ data across batches—by using a content-derived fingerprint ($H$). It also correctly relegates `Accession Number` to a secondary, non-merging role. This strategy is the safest as it is the most resilient to the identifier-related issues described.\n\n**Verdict:** Correct.\n\n**D. Discard UIDs due to remapping variability and identify studies by clustering on Accession Number and Study Date (normalized to local time) so that multi-day protocols are split by date boundaries while keeping all series for the same clinical order together across exports; this avoids UID-related inconsistencies.**\n\nThis option is poor. Discarding `StudyInstanceUID`s is a mistake, as they are perfectly good identifiers for Site $A$ and Site $B$. Relying on `Accession Number` and `Study Date` is problematic due to truncation at Site $B$ and the one-to-many problem at Site $C$. For Site $C$, the goal of \"keeping all series for the same clinical order together\" is the exact opposite of what is needed, as it would merge distinct studies. Splitting by date boundaries is a fragile heuristic that can easily fail (e.g., studies crossing a midnight boundary). This approach discards reliable information and replaces it with unreliable heuristics.\n\n**Verdict:** Incorrect.", "answer": "$$\\boxed{C}$$", "id": "4555309"}, {"introduction": "Once a collection of images is correctly identified as a single series, its geometric integrity must be verified before it can be used for 3D analysis. A valid series requires that all its constituent slices share consistent spatial parameters, such as pixel spacing and orientation. This hands-on coding practice [@problem_id:4555330] guides you through designing an essential quality control tool: a preflight checker that automatically validates the geometric consistency of a DICOM series.", "problem": "You are working within the context of Picture Archiving and Communication Systems (PACS) and Digital Imaging and Communications in Medicine (DICOM) in radiomics. Before feature extraction, series-level geometric consistency must be validated to avoid mixing slices with incompatible spatial descriptors. A series is a collection of slices. Each slice provides three metadata elements: Pixel Spacing (two values in millimeters for the row and column spacing), Slice Thickness (in millimeters), and Image Orientation (Patient) consisting of six real numbers representing two direction cosine vectors, the row direction vector and the column direction vector.\n\nFundamental base:\n- In DICOM, Pixel Spacing is defined as the physical distance in millimeters between the centers of adjacent pixels in the image plane for rows and columns. Let the pixel spacing vector for slice $i$ be $\\mathbf{p}_i = \\left(p^{\\text{row}}_i, p^{\\text{col}}_i\\right)$ in millimeters.\n- Slice Thickness is the nominal slice width in millimeters and is denoted by $t_i$ for slice $i$.\n- Image Orientation (Patient) stores two direction cosines: the unit vectors $\\mathbf{r}_i \\in \\mathbb{R}^3$ and $\\mathbf{c}_i \\in \\mathbb{R}^3$, representing the orientation of the image rows and columns in the patient coordinate system. By definition, $\\mathbf{r}_i$ and $\\mathbf{c}_i$ should be orthonormal, meaning $\\lVert \\mathbf{r}_i \\rVert = 1$, $\\lVert \\mathbf{c}_i \\rVert = 1$, and $\\mathbf{r}_i \\cdot \\mathbf{c}_i = 0$.\n\nDesign and implement a preflight consistency checker for a series that flags inconsistency if any of the following conditions is violated:\n1. Pixel Spacing consistency across slices: for a tolerance $\\tau_{\\text{ps}}$ in millimeters, require $\\lVert \\mathbf{p}_i - \\mathbf{p}_0 \\rVert_{\\infty} \\le \\tau_{\\text{ps}}$ for all slices $i$, where $\\lVert \\cdot \\rVert_{\\infty}$ is the max norm and slice $0$ is the reference.\n2. Slice Thickness consistency across slices: for a tolerance $\\tau_{\\text{thick}}$ in millimeters, require $\\lvert t_i - t_0 \\rvert \\le \\tau_{\\text{thick}}$ for all slices $i$.\n3. Image Orientation (Patient) orthonormality per slice: for a tolerance $\\tau_{\\text{ortho}}$ (dimensionless), require $\\lvert \\lVert \\mathbf{r}_i \\rVert - 1 \\rvert \\le \\tau_{\\text{ortho}}$, $\\lvert \\lVert \\mathbf{c}_i \\rVert - 1 \\rvert \\le \\tau_{\\text{ortho}}$, and $\\lvert \\mathbf{r}_i \\cdot \\mathbf{c}_i \\rvert \\le \\tau_{\\text{ortho}}$ for all slices $i$.\n4. Image Orientation (Patient) consistency across slices: for a tolerance $\\tau_{\\text{ori}}$ (dimensionless), require that for all slices $i$ either\n   $\\max\\left(\\lVert \\mathbf{r}_i - \\mathbf{r}_0 \\rVert_{\\infty}, \\lVert \\mathbf{c}_i - \\mathbf{c}_0 \\rVert_{\\infty}\\right) \\le \\tau_{\\text{ori}}$\n   or\n   $\\max\\left(\\lVert \\mathbf{r}_i + \\mathbf{r}_0 \\rVert_{\\infty}, \\lVert \\mathbf{c}_i + \\mathbf{c}_0 \\rVert_{\\infty}\\right) \\le \\tau_{\\text{ori}}$,\n   which allows for a simultaneous sign flip of both $\\mathbf{r}$ and $\\mathbf{c}$ without changing the image plane orientation.\n\nIf any check fails, the series must be flagged as inconsistent, otherwise it is consistent. Treat an empty series as inconsistent.\n\nUse the following tolerances:\n- $\\tau_{\\text{ps}} = 0.001$ millimeters,\n- $\\tau_{\\text{thick}} = 0.001$ millimeters,\n- $\\tau_{\\text{ortho}} = 0.001$,\n- $\\tau_{\\text{ori}} = 0.001$.\n\nTest suite:\nProvide seven series. Each slice is represented by a tuple $(\\mathbf{p}_i, t_i, \\mathbf{r}_i, \\mathbf{c}_i)$ where $\\mathbf{p}_i$ is $(p^{\\text{row}}_i, p^{\\text{col}}_i)$ in millimeters, $t_i$ is in millimeters, and $\\mathbf{r}_i$, $\\mathbf{c}_i$ are $(x,y,z)$ direction cosines.\n\nSeries $1$ (consistent, small noise within tolerance):\n- Slice $1$: $\\mathbf{p}_1 = (0.7, 0.7)$, $t_1 = 2.5$, $\\mathbf{r}_1 = (1, 0, 0)$, $\\mathbf{c}_1 = (0, 1, 0)$.\n- Slice $2$: $\\mathbf{p}_2 = (0.7000004, 0.7)$, $t_2 = 2.5000003$, $\\mathbf{r}_2 = (1, 0, 0)$, $\\mathbf{c}_2 = (0, 1, 0)$.\n- Slice $3$: $\\mathbf{p}_3 = (0.7, 0.6999995)$, $t_3 = 2.5$, $\\mathbf{r}_3 = (1, 0, 0)$, $\\mathbf{c}_3 = (0, 1, 0)$.\n\nSeries $2$ (inconsistent pixel spacing beyond tolerance on one slice):\n- Slice $1$: $\\mathbf{p}_1 = (0.7, 0.7)$, $t_1 = 2.5$, $\\mathbf{r}_1 = (1, 0, 0)$, $\\mathbf{c}_1 = (0, 1, 0)$.\n- Slice $2$: $\\mathbf{p}_2 = (0.7009, 0.7)$, $t_2 = 2.5$, $\\mathbf{r}_2 = (1, 0, 0)$, $\\mathbf{c}_2 = (0, 1, 0)$.\n- Slice $3$: $\\mathbf{p}_3 = (0.7, 0.702)$, $t_3 = 2.5$, $\\mathbf{r}_3 = (1, 0, 0)$, $\\mathbf{c}_3 = (0, 1, 0)$.\n\nSeries $3$ (inconsistent slice thickness):\n- Slice $1$: $\\mathbf{p}_1 = (1.0, 1.0)$, $t_1 = 1.0$, $\\mathbf{r}_1 = (0, 1, 0)$, $\\mathbf{c}_1 = (1, 0, 0)$.\n- Slice $2$: $\\mathbf{p}_2 = (1.0, 1.0)$, $t_2 = 1.001$, $\\mathbf{r}_2 = (0, 1, 0)$, $\\mathbf{c}_2 = (1, 0, 0)$.\n- Slice $3$: $\\mathbf{p}_3 = (1.0, 1.0)$, $t_3 = 1.002$, $\\mathbf{r}_3 = (0, 1, 0)$, $\\mathbf{c}_3 = (1, 0, 0)$.\n\nSeries $4$ (inconsistent orientation across slices):\n- Slice $1$: $\\mathbf{p}_1 = (0.9, 0.9)$, $t_1 = 3.0$, $\\mathbf{r}_1 = (1, 0, 0)$, $\\mathbf{c}_1 = (0, 1, 0)$.\n- Slice $2$: $\\mathbf{p}_2 = (0.9, 0.9)$, $t_2 = 3.0$, $\\mathbf{r}_2 = (1, 0, 0)$, $\\mathbf{c}_2 = (0, 1, 0)$.\n- Slice $3$: $\\mathbf{p}_3 = (0.9, 0.9)$, $t_3 = 3.0$, $\\mathbf{r}_3 = (1, 0, 0)$, $\\mathbf{c}_3 = (0, 0.999, 0.04472)$.\n\nSeries $5$ (consistent orientation via simultaneous sign flip):\n- Slice $1$: $\\mathbf{p}_1 = (0.8, 0.8)$, $t_1 = 4.0$, $\\mathbf{r}_1 = (1, 0, 0)$, $\\mathbf{c}_1 = (0, 1, 0)$.\n- Slice $2$: $\\mathbf{p}_2 = (0.8, 0.8)$, $t_2 = 4.0$, $\\mathbf{r}_2 = (-1, 0, 0)$, $\\mathbf{c}_2 = (0, -1, 0)$.\n- Slice $3$: $\\mathbf{p}_3 = (0.8, 0.8)$, $t_3 = 4.0$, $\\mathbf{r}_3 = (-1, 0, 0)$, $\\mathbf{c}_3 = (0, -1, 0)$.\n\nSeries $6$ (single slice, orthonormal orientation, consistent by definition across slices):\n- Slice $1$: $\\mathbf{p}_1 = (0.6, 0.6)$, $t_1 = 5.0$, $\\mathbf{r}_1 = (0.70710678, 0.70710678, 0)$, $\\mathbf{c}_1 = (-0.70710678, 0.70710678, 0)$.\n\nSeries $7$ (boundary case: pixel spacing differences exactly equal to tolerance):\n- Slice $1$: $\\mathbf{p}_1 = (0.8, 0.8)$, $t_1 = 5.0$, $\\mathbf{r}_1 = (1, 0, 0)$, $\\mathbf{c}_1 = (0, 1, 0)$.\n- Slice $2$: $\\mathbf{p}_2 = (0.801, 0.8)$, $t_2 = 5.0$, $\\mathbf{r}_2 = (1, 0, 0)$, $\\mathbf{c}_2 = (0, 1, 0)$.\n- Slice $3$: $\\mathbf{p}_3 = (0.8, 0.799)$, $t_3 = 5.0$, $\\mathbf{r}_3 = (1, 0, 0)$, $\\mathbf{c}_3 = (0, 1, 0)$.\n\nRequired program behavior:\n- Implement the four checks above with the given tolerances.\n- For each series, output a boolean that is $True$ if the series is inconsistent (flagged) and $False$ if it is consistent.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\text{True},\\text{False},\\dots\\right]$). Since booleans are unitless, no physical units are included in the output.\n\nYour program must not read any input and must use the test suite values provided above, embedded in code. The program must run deterministically and produce booleans for the seven series in the specified format.", "solution": "The problem requires the design and implementation of a preflight consistency checker for a series of medical images, specifically within the context of the DICOM standard used in radiomics. A series is deemed consistent only if all its constituent slices satisfy a set of strict geometric criteria, both individually and relative to each other. An inconsistent series is flagged to prevent its use in subsequent analyses, which demand high data quality and homogeneity.\n\nThe validation is predicated on four specific checks, with any failure resulting in the entire series being flagged as inconsistent. The algorithm is designed to systematically apply these checks.\n\nFirst, we address the edge case of an empty series. Such a series contains no information and is axiomatically defined as inconsistent. For a non-empty series, the first slice (at index $i=0$) is designated as the reference against which all other slices are compared for inter-slice consistency. The algorithm iterates through each slice in the series, performing the requisite checks.\n\nThe four consistency checks are detailed as follows:\n\n1.  **Image Orientation (Patient) Orthonormality (Intra-slice)**: This is the most fundamental check, ensuring the geometric integrity of each slice's coordinate system. For each slice $i$, the direction cosine vectors for the rows, $\\mathbf{r}_i \\in \\mathbb{R}^3$, and columns, $\\mathbf{c}_i \\in \\mathbb{R}^3$, must be orthonormal. This property is verified using three conditions with a specified tolerance $\\tau_{\\text{ortho}}$:\n    - The row vector must be a unit vector: $\\lvert \\lVert \\mathbf{r}_i \\rVert_2 - 1 \\rvert \\le \\tau_{\\text{ortho}}$, where $\\lVert \\cdot \\rVert_2$ is the Euclidean norm.\n    - The column vector must be a unit vector: $\\lvert \\lVert \\mathbf{c}_i \\rVert_2 - 1 \\rvert \\le \\tau_{\\text{ortho}}$.\n    - The row and column vectors must be orthogonal: $\\lvert \\mathbf{r}_i \\cdot \\mathbf{c}_i \\rvert \\le \\tau_{\\text{ortho}}$.\n    This check is performed for every slice, including the reference slice. A failure in any slice immediately invalidates the series.\n\n2.  **Pixel Spacing Consistency (Inter-slice)**: This check ensures that the in-plane resolution is uniform across the series. For each slice $i$ (where $i>0$), its pixel spacing vector $\\mathbf{p}_i = (p^{\\text{row}}_i, p^{\\text{col}}_i)$ is compared to that of the reference slice, $\\mathbf{p}_0$. The difference is quantified using the infinity norm (or max norm), $\\lVert \\mathbf{d} \\rVert_{\\infty} = \\max(\\lvert d_1 \\rvert, \\lvert d_2 \\rvert, \\dots)$. The condition for consistency is:\n    $$ \\lVert \\mathbf{p}_i - \\mathbf{p}_0 \\rVert_{\\infty} \\le \\tau_{\\text{ps}} $$\n    where $\\tau_{\\text{ps}}$ is the pixel spacing tolerance.\n\n3.  **Slice Thickness Consistency (Inter-slice)**: This ensures that the thickness of the slices is constant throughout the series. For each slice $i$ (where $i>0$), its thickness $t_i$ is compared to the reference thickness $t_0$. The condition is:\n    $$ \\lvert t_i - t_0 \\rvert \\le \\tau_{\\text{thick}} $$\n    where $\\tau_{\\text{thick}}$ is the slice thickness tolerance.\n\n4.  **Image Orientation (Patient) Consistency (Inter-slice)**: This check verifies that all slices are spatially aligned in the same plane. The orientation of any slice $i$ (where $i>0$) must match that of the reference slice $0$. A special case is permitted where the orientation vectors $(\\mathbf{r}_i, \\mathbf{c}_i)$ are simultaneously flipped relative to the reference $(\\mathbf{r}_0, \\mathbf{c}_0)$, i.e., $(\\mathbf{r}_i, \\mathbf{c}_i) \\approx (-\\mathbf{r}_0, -\\mathbf{c}_0)$, as this represents the same imaging plane. The check is formulated as a disjunction: a slice is consistent if its orientation is either nearly identical to the reference or nearly identical to the flipped reference. Using the infinity norm for vector comparison and a tolerance $\\tau_{\\text{ori}}$, the condition is:\n    $$ \\max\\left(\\lVert \\mathbf{r}_i - \\mathbf{r}_0 \\rVert_{\\infty}, \\lVert \\mathbf{c}_i - \\mathbf{c}_0 \\rVert_{\\infty}\\right) \\le \\tau_{\\text{ori}} \\quad \\lor \\quad \\max\\left(\\lVert \\mathbf{r}_i + \\mathbf{r}_0 \\rVert_{\\infty}, \\lVert \\mathbf{c}_i + \\mathbf{c}_0 \\rVert_{\\infty}\\right) \\le \\tau_{\\text{ori}} $$\n    A slice fails this check if neither of these conditions is met.\n\nThe implementation iterates through the series. For the first slice ($i=0$), only the orthonormality check is performed. For all subsequent slices ($i>0$), all four checks are performed. If any check fails at any point, the process terminates, and the series is flagged as inconsistent (returning `True`). If the loop completes without any failures, the series is deemed consistent (returning `False`). A single-slice series is consistent if it passes the orthonormality check, as the inter-slice comparisons are not applicable.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef check_series_consistency(series):\n    \"\"\"\n    Validates a DICOM series for geometric consistency.\n\n    Args:\n        series: A list of slices. Each slice is a tuple containing:\n                - p (np.array): Pixel spacing (row, col) in mm.\n                - t (float): Slice thickness in mm.\n                - r (np.array): Row direction cosine vector (x, y, z).\n                - c (np.array): Column direction cosine vector (x, y, z).\n\n    Returns:\n        bool: True if the series is inconsistent, False otherwise.\n    \"\"\"\n    # Define tolerances as per the problem statement\n    tau_ps = 0.001\n    tau_thick = 0.001\n    tau_ortho = 0.001\n    tau_ori = 0.001\n\n    # An empty series is inconsistent.\n    if not series:\n        return True\n\n    # Establish the first slice as the reference for inter-slice comparisons.\n    p0, t0, r0, c0 = series[0]\n\n    # Iterate through all slices to perform checks.\n    for i in range(len(series)):\n        pi, ti, ri, ci = series[i]\n\n        # Check 3: Image Orientation (Patient) orthonormality (for every slice).\n        # This check must pass for all slices, including the reference.\n        norm_r = np.linalg.norm(ri)\n        norm_c = np.linalg.norm(ci)\n        dot_rc = np.dot(ri, ci)\n\n        if (abs(norm_r - 1) > tau_ortho or\n            abs(norm_c - 1) > tau_ortho or\n            abs(dot_rc) > tau_ortho):\n            return True  # Inconsistent due to non-orthonormality.\n\n        # Inter-slice checks are only performed for slices after the reference slice (i > 0).\n        if i == 0:\n            continue\n\n        # Check 1: Pixel Spacing consistency\n        if np.linalg.norm(pi - p0, ord=np.inf) > tau_ps:\n            return True  # Inconsistent pixel spacing.\n\n        # Check 2: Slice Thickness consistency\n        if abs(ti - t0) > tau_thick:\n            return True  # Inconsistent slice thickness.\n\n        # Check 4: Image Orientation (Patient) consistency\n        # Check for same orientation\n        err_same = max(np.linalg.norm(ri - r0, ord=np.inf),\n                       np.linalg.norm(ci - c0, ord=np.inf))\n        \n        # Check for flipped orientation\n        err_flipped = max(np.linalg.norm(ri + r0, ord=np.inf),\n                          np.linalg.norm(ci + c0, ord=np.inf))\n        \n        # A slice is inconsistent if its orientation is neither same nor flipped.\n        if err_same > tau_ori and err_flipped > tau_ori:\n            return True  # Inconsistent orientation across slices.\n\n    # If all checks pass for all slices, the series is consistent.\n    return False\n\ndef solve():\n    \"\"\"\n    Defines the test suite and runs the consistency checker on each series.\n    \"\"\"\n    # Define the 7 test series from the problem statement.\n    # Each slice is a tuple: (pixel_spacing, slice_thickness, row_vector, col_vector)\n    test_cases = [\n        # Series 1 (consistent, small noise within tolerance)\n        [\n            (np.array([0.7, 0.7]), 2.5, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.7000004, 0.7]), 2.5000003, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.7, 0.6999995]), 2.5, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n        ],\n        # Series 2 (inconsistent pixel spacing)\n        [\n            (np.array([0.7, 0.7]), 2.5, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.7009, 0.7]), 2.5, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.7, 0.702]), 2.5, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n        ],\n        # Series 3 (inconsistent slice thickness)\n        [\n            (np.array([1.0, 1.0]), 1.0, np.array([0.0, 1.0, 0.0]), np.array([1.0, 0.0, 0.0])),\n            (np.array([1.0, 1.0]), 1.001, np.array([0.0, 1.0, 0.0]), np.array([1.0, 0.0, 0.0])),\n            (np.array([1.0, 1.0]), 1.002, np.array([0.0, 1.0, 0.0]), np.array([1.0, 0.0, 0.0])),\n        ],\n        # Series 4 (inconsistent orientation across slices)\n        [\n            (np.array([0.9, 0.9]), 3.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.9, 0.9]), 3.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.9, 0.9]), 3.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 0.999, 0.04472])),\n        ],\n        # Series 5 (consistent orientation via simultaneous sign flip)\n        [\n            (np.array([0.8, 0.8]), 4.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.8, 0.8]), 4.0, np.array([-1.0, 0.0, 0.0]), np.array([0.0, -1.0, 0.0])),\n            (np.array([0.8, 0.8]), 4.0, np.array([-1.0, 0.0, 0.0]), np.array([0.0, -1.0, 0.0])),\n        ],\n        # Series 6 (single slice, consistent by definition)\n        [\n            (np.array([0.6, 0.6]), 5.0, np.array([0.70710678, 0.70710678, 0.0]), np.array([-0.70710678, 0.70710678, 0.0])),\n        ],\n        # Series 7 (boundary case, consistent)\n        [\n            (np.array([0.8, 0.8]), 5.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.801, 0.8]), 5.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n            (np.array([0.8, 0.799]), 5.0, np.array([1.0, 0.0, 0.0]), np.array([0.0, 1.0, 0.0])),\n        ],\n    ]\n\n    # Calculate results for each test case.\n    results = [check_series_consistency(series) for series in test_cases]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4555330"}, {"introduction": "The final step in preparing an image for quantitative analysis is to map its internal voxel coordinates to the physical patient space. This transformation is fundamental for integrating imaging data with other clinical information, like radiation therapy plans or follow-up scans. In this exercise [@problem_id:4555353], you will derive the affine transformation matrix from core DICOM attributes, a crucial skill that bridges the gap between the image grid and real-world anatomical location.", "problem": "A radiomics workflow within a Picture Archiving and Communication System (PACS) archive must map voxel indices to patient coordinates for three-dimensional Computed Tomography (CT) volumes using Digital Imaging and Communications in Medicine (DICOM) attributes. In the DICOM patient coordinate system, the axes are defined as Left-Posterior-Superior (LPS), meaning the $x$-axis points toward the patient’s left, the $y$-axis toward the patient’s posterior, and the $z$-axis toward the patient’s superior. The CT series has the following DICOM attributes for a representative slice:\n- Pixel Spacing $(0028,0030)$ is $[0.80,\\,0.80]$ in millimeters, where the first value is the spacing along the row direction and the second value is the spacing along the column direction.\n- Slice Thickness $(0018,0050)$ is $1.5$ millimeters.\n- Image Orientation (Patient) $(0020,0037)$ is $\\left[\\frac{\\sqrt{3}}{2},\\,\\frac{1}{2},\\,0,\\,-\\frac{1}{2},\\,\\frac{\\sqrt{3}}{2},\\,0\\right]$, which gives the direction cosines of the row and column axes of the image plane, respectively.\n- Image Position (Patient) $(0020,0032)$ for the first slice $(k=0)$ is $\\left[-120,\\,-90,\\,-50\\right]$ in millimeters, giving the patient-space coordinates of the voxel center at zero-based index $(i,j,k)=(0,0,0)$.\n\nAssume the image plane axes form an orthonormal basis embedded in the LPS patient coordinate system, and the slice-to-slice direction is given by the right-handed normal obtained from the row and column direction vectors. Use zero-based voxel indices $(i,j,k)$ with $i$ increasing along image columns, $j$ increasing along image rows, and $k$ increasing with slice number in acquisition order. Starting from first principles (coordinate bases, direction cosines, and linear mappings in $\\mathbb{R}^{3}$), derive the affine transform that maps homogeneous voxel indices to homogeneous patient coordinates, i.e., find the $4\\times 4$ matrix $A$ such that\n$$\n\\begin{pmatrix}\nx \\\\\ny \\\\\nz \\\\\n1\n\\end{pmatrix}\n=\nA\n\\begin{pmatrix}\ni \\\\\nj \\\\\nk \\\\\n1\n\\end{pmatrix}.\n$$\nReport the entries of $A$ in millimeters, in row-major order as a single row vector. Use exact analytic values; do not round. Express distances in millimeters and angles, if any appear in intermediate reasoning, in radians or degrees as appropriate; the final reported transform entries must be in millimeters. The final answer must be a single analytical expression (the row vector of the matrix entries) presented exactly as instructed.", "solution": "The user wants to solve for the affine transformation matrix A, which maps homogeneous voxel indices (i, j, k) to homogeneous patient coordinates (x, y, z). My approach is as follows:\n\n1.  **Problem Validation:**\n    *   **Step 1: Extract Givens:**\n        *   Patient coordinate system: Left-Posterior-Superior (LPS).\n        *   Voxel indices: $(i, j, k)$, zero-based. $i$ increases along columns, $j$ along rows, $k$ along slices.\n        *   Pixel Spacing (0028,0030): $[\\Delta j, \\Delta i] = [0.80, 0.80]$ in millimeters. So, row spacing $\\Delta j = 0.80$ mm and column spacing $\\Delta i = 0.80$ mm.\n        *   Slice Thickness (0018,0050): $\\Delta k = 1.5$ mm.\n        *   Image Orientation (Patient) (0020,0037): $[\\frac{\\sqrt{3}}{2}, \\frac{1}{2}, 0, -\\frac{1}{2}, \\frac{\\sqrt{3}}{2}, 0]$. This defines the row direction vector $\\vec{F} = (\\frac{\\sqrt{3}}{2}, \\frac{1}{2}, 0)$ and the column direction vector $\\vec{G} = (-\\frac{1}{2}, \\frac{\\sqrt{3}}{2}, 0)$.\n        *   Image Position (Patient) (0020,0032): For voxel $(i, j, k) = (0, 0, 0)$, the coordinates are $\\vec{P}_{000} = [-120, -90, -50]$ in millimeters.\n        *   Task: Find the $4 \\times 4$ matrix $A$ in the equation $\\begin{pmatrix} x \\\\ y \\\\ z \\\\ 1 \\end{pmatrix} = A \\begin{pmatrix} i \\\\ j \\\\ k \\\\ 1 \\end{pmatrix}$.\n    *   **Step 2: Validate Using Extracted Givens:**\n        *   The problem is scientifically grounded in the DICOM standard for medical imaging and linear algebra. The provided values and concepts are standard in radiology and medical physics.\n        *   The problem is well-posed. All information required to construct the transformation matrix is provided, and the objective is clearly stated.\n        *   The problem is objective, using precise, standardized terminology from the DICOM specification.\n        *   The data is consistent. For instance, the given orientation vectors $\\vec{F}$ and $\\vec{G}$ are unit vectors and are mutually orthogonal as required for an orthonormal basis of the image plane.\n    *   **Step 3: Verdict and Action:** The problem is valid. I will proceed with the solution.\n\n2.  **Solution Derivation:**\n\nThe problem requires the derivation of a $4 \\times 4$ affine transformation matrix, $A$, which maps the homogeneous coordinates of a voxel index $(i, j, k)$ to the homogeneous coordinates of its position $(x, y, z)$ in the patient coordinate system. The transformation is defined as:\n$$\n\\begin{pmatrix}\nx \\\\\ny \\\\\nz \\\\\n1\n\\end{pmatrix}\n=\nA\n\\begin{pmatrix}\ni \\\\\nj \\\\\nk \\\\\n1\n\\end{pmatrix}\n$$\nThe general form of the matrix $A$ is:\n$$\nA =\n\\begin{pmatrix}\nM_{11} & M_{12} & M_{13} & T_x \\\\\nM_{21} & M_{22} & M_{23} & T_y \\\\\nM_{31} & M_{32} & M_{33} & T_z \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\nHere, the $3 \\times 3$ submatrix $M$ represents the scaling and rotation part of the transformation, and the vector $\\vec{T} = (T_x, T_y, T_z)$ represents the translation part.\n\nThe position $\\vec{P}(i, j, k) = (x, y, z)$ of the center of a voxel with indices $(i, j, k)$ can be expressed as a linear combination of basis vectors scaled by the indices, plus an offset corresponding to the position of the origin voxel.\n$$\n\\vec{P}(i,j,k) = \\vec{P}(0,0,0) + i \\cdot \\vec{d_i} + j \\cdot \\vec{d_j} + k \\cdot \\vec{d_k}\n$$\nThis can be written in matrix form as:\n$$\n\\begin{pmatrix}\nx \\\\\ny \\\\\nz\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n| & | & | \\\\\n\\vec{d_i} & \\vec{d_j} & \\vec{d_k} \\\\\n| & | & |\n\\end{pmatrix}\n\\begin{pmatrix}\ni \\\\\nj \\\\\nk\n\\end{pmatrix}\n+\n\\begin{pmatrix}\nP_{000,x} \\\\\nP_{000,y} \\\\\nP_{000,z}\n\\end{pmatrix}\n$$\nThe vectors $\\vec{d_i}$, $\\vec{d_j}$, and $\\vec{d_k}$ are the displacement vectors in patient coordinates corresponding to a unit increment in the voxel indices $i$, $j$, and $k$, respectively. These vectors form the first three columns of the matrix $A$. The translation vector $\\vec{T}$ is the coordinate of the origin voxel, $\\vec{P}(0,0,0)$, and forms the first three elements of the fourth column of $A$.\n\nWe will now determine these vectors from the provided DICOM attributes.\n\n**1. Direction Vectors:**\nThe DICOM attribute Image Orientation (Patient) $(0020,0037)$ provides the direction cosines for the row and column axes.\nThe row direction vector $\\vec{F}$ corresponds to an increment in the $j$ index.\n$$ \\vec{F} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2} \\\\ 0 \\end{pmatrix} $$\nThe column direction vector $\\vec{G}$ corresponds to an increment in the $i$ index.\n$$ \\vec{G} = \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix} $$\nThe slice progression direction, $\\vec{H}$, is given by the cross product of the row and column vectors, $\\vec{H} = \\vec{F} \\times \\vec{G}$.\n$$ \\vec{H} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2} \\\\ 0 \\end{pmatrix} \\times \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (\\frac{1}{2})(0) - (0)(\\frac{\\sqrt{3}}{2}) \\\\ (0)(-\\frac{1}{2}) - (\\frac{\\sqrt{3}}{2})(0) \\\\ (\\frac{\\sqrt{3}}{2})(\\frac{\\sqrt{3}}{2}) - (\\frac{1}{2})(-\\frac{1}{2}) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\frac{3}{4} + \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} $$\n\n**2. Spacing and Scaled Direction Vectors:**\nThese unit vectors must be scaled by the spacing between voxels along each direction.\n- The spacing for the $i$ index (columns) is the second value of Pixel Spacing, $\\Delta i = 0.80 \\, \\text{mm} = \\frac{4}{5} \\, \\text{mm}$.\n- The spacing for the $j$ index (rows) is the first value of Pixel Spacing, $\\Delta j = 0.80 \\, \\text{mm} = \\frac{4}{5} \\, \\text{mm}$.\n- The spacing for the $k$ index (slices) is the Slice Thickness, $\\Delta k = 1.5 \\, \\text{mm} = \\frac{3}{2} \\, \\text{mm}$.\n\nThe scaled vectors that form the columns of the matrix $M$ are:\n- For index $i$: $\\vec{d_i} = \\Delta i \\cdot \\vec{G} = \\frac{4}{5} \\begin{pmatrix} -\\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -\\frac{2}{5} \\\\ \\frac{2\\sqrt{3}}{5} \\\\ 0 \\end{pmatrix}$. This is the first column of $M$.\n- For index $j$: $\\vec{d_j} = \\Delta j \\cdot \\vec{F} = \\frac{4}{5} \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{2\\sqrt{3}}{5} \\\\ \\frac{2}{5} \\\\ 0 \\end{pmatrix}$. This is the second column of $M$.\n- For index $k$: $\\vec{d_k} = \\Delta k \\cdot \\vec{H} = \\frac{3}{2} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\frac{3}{2} \\end{pmatrix}$. This is the third column of $M$.\n\n**3. Translation Vector:**\nThe translation vector $\\vec{T}$ is given by the Image Position (Patient) attribute $(0020,0032)$, which specifies the coordinates of the center of voxel $(i,j,k)=(0,0,0)$.\n$$ \\vec{T} = \\vec{P}(0,0,0) = \\begin{pmatrix} -120 \\\\ -90 \\\\ -50 \\end{pmatrix} $$\n\n**4. Assembling the Affine Matrix A:**\nWe now assemble the $4 \\times 4$ matrix $A$ using the vectors $\\vec{d_i}$, $\\vec{d_j}$, $\\vec{d_k}$ as the first three columns and $\\vec{T}$ as the translation part of the fourth column. The last row is $[0, 0, 0, 1]$ to complete the homogeneous transformation.\n$$\nA = \\begin{pmatrix}\n\\vec{d_i} & \\vec{d_j} & \\vec{d_k} & \\vec{T} \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n-\\frac{2}{5} & \\frac{2\\sqrt{3}}{5} & 0 & -120 \\\\\n\\frac{2\\sqrt{3}}{5} & \\frac{2}{5} & 0 & -90 \\\\\n0 & 0 & \\frac{3}{2} & -50 \\\\\n0 & 0 & 0 & 1\n\\end{pmatrix}\n$$\nThe problem asks for the sixteen entries of this matrix in row-major order.\nThe entries are:\nRow 1: $[-\\frac{2}{5}, \\frac{2\\sqrt{3}}{5}, 0, -120]$\nRow 2: $[\\frac{2\\sqrt{3}}{5}, \\frac{2}{5}, 0, -90]$\nRow 3: $[0, 0, \\frac{3}{2}, -50]$\nRow 4: $[0, 0, 0, 1]$\nConcatenated into a single row vector, these entries form the final answer.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{2}{5} & \\frac{2\\sqrt{3}}{5} & 0 & -120 & \\frac{2\\sqrt{3}}{5} & \\frac{2}{5} & 0 & -90 & 0 & 0 & \\frac{3}{2} & -50 & 0 & 0 & 0 & 1\n\\end{pmatrix}\n}\n$$", "id": "4555353"}]}