{"hands_on_practices": [{"introduction": "A core function of a Personal Health Record (PHR) is to aggregate data from multiple sources, which often use different units. To enable meaningful analysis and visualization, this data must first be standardized. This practice will guide you through the essential process of data harmonization and normalization using a common clinical example, fasting glucose levels, demonstrating how to transform raw, mixed-unit data into a standardized score for longitudinal health tracking [@problem_id:4852386].", "problem": "A patient maintains a Personal Health Record (PHR) aggregating fasting plasma glucose measurements from multiple sources. Because sources record glucose in different units, the PHR must harmonize units and apply a single normalization step to enable consistent trend visualization over time. The PHR policy is to convert all values to milligrams per deciliter using the well-tested unit relationship $1\\,\\mathrm{mmol/L} = 18\\,\\mathrm{mg/dL}$, then compute a standardized score (a $z$-score) of the most recent measurement with respect to a baseline window comprising earlier values in the record.\n\nYou are given the following baseline window of ten prior fasting glucose entries, recorded either in milligrams per deciliter (mg/dL) or millimoles per liter (mmol/L):\n- Device A (mg/dL): $92$, $87$, $95$, $100$\n- Device B (mmol/L): $4.8$, $5.2$, $4.5$\n- Laboratory portal (mg/dL): $89$, $93$, $85$\n\nThe most recent fasting glucose entry, to be visualized next in the trend, is from Device B: $5.1\\,\\mathrm{mmol/L}$.\n\nStarting from fundamental definitions:\n- Unit conversion for physical quantities must produce a common unit before aggregation, here using $1\\,\\mathrm{mmol/L} = 18\\,\\mathrm{mg/dL}$.\n- The arithmetic mean $\\mu$ of $n$ measurements $x_1,\\dots,x_n$ is $\\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i$.\n- The sample standard deviation $s$ of $n$ measurements $x_1,\\dots,x_n$ is $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\mu)^2}$.\n- The standardized score (z-score) of a measurement $x$ relative to a baseline characterized by mean $\\mu$ and sample standard deviation $s$ is $z = \\frac{x - \\mu}{s}$.\n\nApply the unit harmonization and normalization pipeline described above to compute the $z$-score of the most recent fasting glucose measurement. Round your final numerical answer to four significant figures. The $z$-score is dimensionless; report it without units.", "solution": "The problem will be validated by first extracting all given information and then assessing its scientific validity, consistency, and completeness.\n\n### Step 1: Extract Givens\n\n- **Unit Conversion Relationship**: $1\\,\\mathrm{mmol/L} = 18\\,\\mathrm{mg/dL}$.\n- **Baseline Data (Prior Measurements)**:\n    - Device A (mg/dL): $92$, $87$, $95$, $100$\n    - Device B (mmol/L): $4.8$, $5.2$, $4.5$\n    - Laboratory portal (mg/dL): $89$, $93$, $85$\n    - The total number of baseline measurements is $n=10$.\n- **Most Recent Measurement**: $x_{new} = 5.1\\,\\mathrm{mmol/L}$ from Device B.\n- **Fundamental Definitions**:\n    - Arithmetic Mean: $\\mu = \\frac{1}{n}\\sum_{i=1}^{n} x_i$\n    - Sample Standard Deviation: $s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\mu)^2}$\n    - Z-score: $z = \\frac{x - \\mu}{s}$\n- **Task**: Compute the $z$-score of the most recent measurement after harmonizing units to mg/dL.\n- **Rounding Requirement**: The final numerical answer must be rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n\n1.  **Scientifically Grounded**: The problem is grounded in standard practices of medical data analysis and statistics. The units (mg/dL, mmol/L) and the conversion factor for glucose are standard in medicine. The concepts of mean, sample standard deviation, and z-score are fundamental statistical measures. The glucose values provided are within a physiologically plausible range for fasting plasma glucose. The problem is scientifically sound.\n2.  **Well-Posed**: The problem provides all necessary data (baseline measurements, a new measurement), formulas, and a clear objective (calculate the z-score). A unique solution exists and can be computed directly from the given information. The problem is well-posed.\n3.  **Objective**: The problem is stated in precise, quantitative, and unbiased language. It does not contain subjective statements or opinions. It is objective.\n4.  **Completeness and Consistency**: All required data and definitions are provided. There are no contradictions. The data sources and units are clearly specified, and the harmonization rule is explicit. The problem is complete and consistent.\n\n### Step 3: Verdict and Action\n\nThe problem statement is valid. It is scientifically grounded, well-posed, objective, and complete. A solution will be derived following the specified methodology.\n\n### Solution Derivation\n\nThe solution requires a three-step process:\n1.  Harmonize all baseline measurements to the common unit of milligrams per deciliter (mg/dL).\n2.  Compute the sample mean ($\\mu$) and sample standard deviation ($s$) of the harmonized baseline data.\n3.  Harmonize the new measurement to mg/dL and compute its $z$-score relative to the baseline mean and standard deviation.\n\n**Step 1: Unit Harmonization of Baseline Data**\n\nThe baseline measurements from Device A and the laboratory portal are already in mg/dL. The measurements from Device B must be converted from mmol/L to mg/dL using the given conversion factor $1\\,\\mathrm{mmol/L} = 18\\,\\mathrm{mg/dL}$.\n\nThe three measurements from Device B are $4.8\\,\\mathrm{mmol/L}$, $5.2\\,\\mathrm{mmol/L}$, and $4.5\\,\\mathrm{mmol/L}$.\nThe converted values are:\n- $4.8\\,\\mathrm{mmol/L} \\times \\frac{18\\,\\mathrm{mg/dL}}{1\\,\\mathrm{mmol/L}} = 86.4\\,\\mathrm{mg/dL}$\n- $5.2\\,\\mathrm{mmol/L} \\times \\frac{18\\,\\mathrm{mg/dL}}{1\\,\\mathrm{mmol/L}} = 93.6\\,\\mathrm{mg/dL}$\n- $4.5\\,\\mathrm{mmol/L} \\times \\frac{18\\,\\mathrm{mg/dL}}{1\\,\\mathrm{mmol/L}} = 81\\,\\mathrm{mg/dL}$\n\nThe complete baseline dataset in mg/dL, denoted as $\\{x_i\\}$, consists of $n=10$ values:\n$\\{92, 87, 95, 100, 86.4, 93.6, 81, 89, 93, 85\\}$\n\n**Step 2: Calculation of Baseline Mean and Standard Deviation**\n\nFirst, we compute the sample mean ($\\mu$) of the harmonized baseline data.\n$$ \\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n$$ \\mu = \\frac{1}{10} (92 + 87 + 95 + 100 + 86.4 + 93.6 + 81 + 89 + 93 + 85) $$\n$$ \\mu = \\frac{902}{10} = 90.2 $$\n\nNext, we compute the sample standard deviation ($s$).\n$$ s = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\mu)^2} $$\nThe sum of squared differences from the mean, $\\sum_{i=1}^{n} (x_i - \\mu)^2$, is calculated:\n- $(92 - 90.2)^2 = (1.8)^2 = 3.24$\n- $(87 - 90.2)^2 = (-3.2)^2 = 10.24$\n- $(95 - 90.2)^2 = (4.8)^2 = 23.04$\n- $(100 - 90.2)^2 = (9.8)^2 = 96.04$\n- $(86.4 - 90.2)^2 = (-3.8)^2 = 14.44$\n- $(93.6 - 90.2)^2 = (3.4)^2 = 11.56$\n- $(81 - 90.2)^2 = (-9.2)^2 = 84.64$\n- $(89 - 90.2)^2 = (-1.2)^2 = 1.44$\n- $(93 - 90.2)^2 = (2.8)^2 = 7.84$\n- $(85 - 90.2)^2 = (-5.2)^2 = 27.04$\n\nThe sum is:\n$$ \\sum_{i=1}^{10} (x_i - 90.2)^2 = 3.24 + 10.24 + 23.04 + 96.04 + 14.44 + 11.56 + 84.64 + 1.44 + 7.84 + 27.04 = 279.52 $$\nNow we can compute the sample variance, $s^2$, and then the sample standard deviation, $s$. The number of degrees of freedom is $n-1 = 10-1 = 9$.\n$$ s^2 = \\frac{279.52}{9} $$\n$$ s = \\sqrt{\\frac{279.52}{9}} \\approx 5.5729505 $$\n\n**Step 3: Calculation of the Z-score**\n\nThe most recent measurement is $5.1\\,\\mathrm{mmol/L}$. We first convert this value, denoted by $x$, to mg/dL.\n$$ x = 5.1\\,\\mathrm{mmol/L} \\times \\frac{18\\,\\mathrm{mg/dL}}{1\\,\\mathrm{mmol/L}} = 91.8\\,\\mathrm{mg/dL} $$\n\nNow, we compute the $z$-score using the formula $z = \\frac{x - \\mu}{s}$.\n$$ z = \\frac{91.8 - 90.2}{5.5729505} $$\n$$ z = \\frac{1.6}{5.5729505} \\approx 0.2870908 $$\n\nThe problem requires rounding the final answer to four significant figures.\n$$ z \\approx 0.2871 $$\n\nThe computed $z$-score of $0.2871$ indicates that the most recent fasting glucose measurement is approximately $0.2871$ standard deviations above the mean of the baseline measurements.", "answer": "$$\\boxed{0.2871}$$", "id": "4852386"}, {"introduction": "Beyond simply storing data, PHRs are powerful tools for assessing health behaviors like medication adherence. This exercise challenges you to move from processing individual data points to analyzing a sequence of events over time. You will design and apply an algorithm to calculate the Medication Possession Ratio (MPR), a standard industry metric, learning to handle real-world complexities like early refills and gaps in treatment [@problem_id:4852329].", "problem": "A Personal Health Record (PHR) contains patient-entered and pharmacy-sourced data on medication refills. You are tasked with designing an adherence estimation algorithm that uses only refill events and dosage instructions to compute the Medication Possession Ratio (MPR) over a fixed observation window. Start from the core definition that MPR is the fraction of observation-window days for which the patient has medication on hand. Construct the algorithm from first principles, using only accepted assumptions and basic time-interval arithmetic. Then apply your algorithm to the PHR data below.\n\nAssumptions permitted:\n- Each dispense event immediately adds to medication on hand.\n- The intended dosing rate is constant and known from instructions in the PHR.\n- Early refills create stockpiles; possession days must not be double-counted. When a refill occurs before prior supply is exhausted, the start of the new supply is deferred to the first day after the previous supply would have ended.\n- If a refill occurs after prior supply runs out, uncovered gap days result; the new supply starts on the actual pickup date.\n- Each dispense event with quantity $Q_i$ and daily dosing rate $r$ yields a days-supply of $s_i = Q_i / r$ calendar days.\n- Each $s_i$-day supply starting on its assigned start date covers $s_i$ consecutive calendar days, inclusive.\n- The observation window is a closed interval; coverage must be clipped at window boundaries. The MPR is capped above by $1$.\n\nObservation window:\n- Start: January $1$, $2023$\n- End: March $31$, $2023$\n- Use a non-leap year calendar. Treat the window as $90$ consecutive days.\n\nPHR refill events for a once-daily medication (Sig: “Take $1$ tablet by mouth daily”):\n- Fill $1$: January $1$, $2023$, dispensed quantity $30$ tablets.\n- Fill $2$: January $25$, $2023$, dispensed quantity $30$ tablets.\n- Fill $3$: March $5$, $2023$, dispensed quantity $30$ tablets.\n\nTasks:\n1. From the above assumptions and the definition of MPR, derive a clear algorithm to compute covered days within a fixed window using only refill dates and quantities, handling early overlaps with carryover and late gaps.\n2. Apply your algorithm to compute the MPR over the January $1$ to March $31$, $2023$ window. Express the final MPR as a unitless decimal rounded to four significant figures.", "solution": "The problem is valid as it is scientifically grounded in the field of medical informatics, well-posed with sufficient and consistent data, and objectively stated. It requests the derivation and application of an algorithm based on standard principles of medication adherence calculation.\n\n### Part 1: Derivation of the Medication Possession Ratio (MPR) Algorithm\n\nThe objective is to compute the Medication Possession Ratio (MPR), defined as the fraction of days within a specified observation window for which a patient has medication available. The algorithm must handle stockpiling from early refills and gaps from late refills.\n\nLet the observation window be the closed interval of calendar dates $[T_{\\text{start}}, T_{\\text{end}}]$. We can map these dates to an ordinal day numbering system, where $t_{\\text{start}}$ is the ordinal for $T_{\\text{start}}$ and $t_{\\text{end}}$ is the ordinal for $T_{\\text{end}}$. The duration of the window is $D = t_{\\text{end}} - t_{\\text{start}} + 1$ days.\n\nLet there be $N$ refill events, indexed by $i \\in \\{1, 2, \\dots, N\\}$. For each refill event $i$, we are given:\n- $d_i$: The ordinal day of the refill.\n- $Q_i$: The quantity of medication dispensed.\n\nWe are also given a constant daily dosing rate, $r$.\n\nThe days-supply provided by each refill is calculated as $s_i = \\frac{Q_i}{r}$.\n\nThe core of the algorithm is to construct a sequence of non-overlapping time intervals $[p_i, e_i]$ representing the periods of medication coverage. Here, $p_i$ is the effective start day and $e_i$ is the effective end day for the supply from refill $i$.\n\nThe algorithm proceeds as follows:\n\n1.  **Initialization**: Define a variable to track the projected end of the previous supply period. For the first refill, there is no prior supply. We can initialize a \"zeroth\" effective end day as $e_0 = -\\infty$ to formally handle the base case.\n\n2.  **Iterative Calculation of Coverage Intervals**: We iterate through each refill event from $i=1$ to $N$.\n    - The supply from the previous refill, $(i-1)$, is projected to cover all days up to and including day $e_{i-1}$. Therefore, the patient's need for the next supply begins on day $e_{i-1} + 1$.\n    - The effective start day, $p_i$, for the supply from refill $i$ is determined by the \"carryover\" rule. The patient can only start using the new supply on the later of two dates: the actual refill date ($d_i$) or the day after the previous supply is exhausted ($e_{i-1} + 1$). This is expressed as:\n      $$p_i = \\max(d_i, e_{i-1} + 1)$$\n      This single rule correctly models both scenarios:\n      - **Early Refill ($d_i  e_{i-1} + 1$)**: The start is deferred to $p_i = e_{i-1} + 1$, preventing double-counting of possession days.\n      - **Late or On-Time Refill ($d_i \\ge e_{i-1} + 1$)**: The new supply starts on the day it was picked up, $p_i = d_i$, which may create an uncovered gap if $d_i > e_{i-1} + 1$.\n    - The effective end day, $e_i$, for the supply from refill $i$ is calculated by adding its duration to its effective start day. Since a supply of $s_i$ days starting on $p_i$ covers days $p_i, p_i+1, \\dots, p_i+s_i-1$, the end day is:\n      $$e_i = p_i + s_i - 1$$\n    - The value of $e_i$ is then used as $e_{i-1}$ in the next iteration.\n\n3.  **Summation of Covered Days within the Observation Window**: After computing the sequence of disjoint coverage intervals $[p_i, e_i]$, we calculate the total number of days covered, $C_{\\text{total}}$, that fall within the observation window $[t_{\\text{start}}, t_{\\text{end}}]$.\n    - For each interval $[p_i, e_i]$, we find its intersection with $[t_{\\text{start}}, t_{\\text{end}}]$. The start of the intersection is $p'_i = \\max(p_i, t_{\\text{start}})$ and the end is $e'_i = \\min(e_i, t_{\\text{end}})$.\n    - The number of covered days contributed by refill $i$, denoted $c_i$, is the length of this intersection. If $p'_i > e'_i$, the intersection is empty.\n      $$c_i = \\max(0, e'_i - p'_i + 1)$$\n    - The total number of covered days is the sum of contributions from all refills:\n      $$C_{\\text{total}} = \\sum_{i=1}^{N} c_i$$\n\n4.  **Final MPR Calculation**: The MPR is the ratio of the total covered days to the duration of the observation window.\n    $$\\text{MPR} = \\frac{C_{\\text{total}}}{D}$$\n\n### Part 2: Application of the Algorithm\n\nWe apply the derived algorithm to the provided PHR data.\n\n**Givens**:\n- Observation Window: January $1$, $2023$ to March $31$, $2023$. In a non-leap year, this corresponds to $D = 31 + 28 + 31 = 90$ days.\n- Let January $1$ be ordinal day $1$. The window is the interval $[1, 90]$.\n- Dosing Rate: $r = 1$ tablet/day.\n- Refill Events:\n  - Fill $1$: $d_1 = 1$ (Jan $1$), $Q_1 = 30$. Days-supply $s_1 = 30/1 = 30$.\n  - Fill $2$: $d_2 = 25$ (Jan $25$), $Q_2 = 30$. Days-supply $s_2 = 30/1 = 30$.\n  - Fill $3$: $d_3 = 31 + 28 + 5 = 64$ (Mar $5$), $Q_3 = 30$. Days-supply $s_3 = 30/1 = 30$.\n\n**Step-by-Step Calculation**:\n\n- **For Fill 1 ($i=1$)**:\n  - As this is the first fill, its effective start day is the refill day: $p_1 = d_1 = 1$.\n  - The effective end day is $e_1 = p_1 + s_1 - 1 = 1 + 30 - 1 = 30$.\n  - The coverage interval is $[1, 30]$.\n  - The intersection with the window $[1, 90]$ is $[\\max(1, 1), \\min(30, 90)] = [1, 30]$.\n  - Covered days from this fill: $c_1 = 30 - 1 + 1 = 30$.\n\n- **For Fill 2 ($i=2$)**:\n  - The previous supply was projected to end on day $e_1 = 30$. The next day of need is $e_1 + 1 = 31$.\n  - The actual refill occurred on $d_2 = 25$. This is an early refill.\n  - The effective start day is $p_2 = \\max(d_2, e_1 + 1) = \\max(25, 31) = 31$.\n  - The effective end day is $e_2 = p_2 + s_2 - 1 = 31 + 30 - 1 = 60$.\n  - The coverage interval is $[31, 60]$.\n  - The intersection with the window $[1, 90]$ is $[\\max(31, 1), \\min(60, 90)] = [31, 60]$.\n  - Covered days from this fill: $c_2 = 60 - 31 + 1 = 30$.\n\n- **For Fill 3 ($i=3$)**:\n  - The previous supply was projected to end on day $e_2 = 60$. The next day of need is $e_2 + 1 = 61$.\n  - The actual refill occurred on $d_3 = 64$. This is a late refill, creating a gap from day $61$ to day $63$.\n  - The effective start day is $p_3 = \\max(d_3, e_2 + 1) = \\max(64, 61) = 64$.\n  - The effective end day is $e_3 = p_3 + s_3 - 1 = 64 + 30 - 1 = 93$.\n  - The coverage interval is $[64, 93]$.\n  - The intersection with the window $[1, 90]$ is $[\\max(64, 1), \\min(93, 90)] = [64, 90]$.\n  - Covered days from this fill: $c_3 = 90 - 64 + 1 = 27$. (Note the clipping at the window end).\n\n- **Total Covered Days**:\n  - $C_{\\text{total}} = c_1 + c_2 + c_3 = 30 + 30 + 27 = 87$ days.\n\n- **MPR Calculation**:\n  - $\\text{MPR} = \\frac{C_{\\text{total}}}{D} = \\frac{87}{90}$.\n  - $\\frac{87}{90} = \\frac{29}{30} = 0.9666\\overline{6}$.\n  - Rounding to four significant figures gives $0.9667$.", "answer": "$$\\boxed{0.9667}$$", "id": "4852329"}, {"introduction": "Perhaps the most fundamental challenge in creating a unified PHR is ensuring that records from different systems belong to the same person. This advanced practice introduces the principles of probabilistic record linkage, a sophisticated method used to match patient records under uncertainty. You will use Bayesian decision theory to compute a match score and a decision threshold, gaining insight into the statistical engine that powers robust patient identity management in health informatics [@problem_id:4852339].", "problem": "A hospital network is integrating Personal Health Records (PHRs) from multiple sources. To decide whether two records belong to the same individual, the data integration team uses a probabilistic matching framework grounded in Bayesian decision theory and the principle of conditional independence across fields. The team defines, for each field, the probability of agreement given that the pair is a true match (the $m$-probability) and the probability of agreement given that the pair is a true non-match (the $u$-probability). Assume field-level agreements or disagreements are conditionally independent given the match status.\n\nFor three fields—name, date of birth, and zip code—the $m$-probabilities are $(0.95, 0.90, 0.85)$ and the $u$-probabilities are $(0.10, 0.05, 0.02)$, respectively. Consider a candidate pair that agrees on name and date of birth but disagrees on zip code.\n\nUsing the independence assumption across fields and fundamental definitions from Bayesian decision theory, compute the natural-logarithm log-likelihood ratio for this candidate pair. Then, set a Bayes-optimal decision threshold on the log-likelihood ratio that separates matches from non-matches, given a prior match probability of $\\pi = 0.02$ for candidate pairs produced by blocking and misclassification costs where the cost of a false match is $C_{\\mathrm{FP}} = 10$ and the cost of a false non-match is $C_{\\mathrm{FN}} = 1$.\n\nReport a single number equal to the log-likelihood ratio minus the decision threshold, $s - t$, rounded to four significant figures. Express your answer as a pure number with no units.", "solution": "The problem requires the calculation of a log-likelihood ratio, a Bayes-optimal decision threshold, and their difference. The problem is well-posed and scientifically grounded in Bayesian decision theory as applied to probabilistic record linkage.\n\nFirst, we calculate the log-likelihood ratio, denoted by $s$, for the given candidate pair. The framework assumes that the agreement statuses of the fields are conditionally independent given the true match status of the pair (either a true match, $M$, or a true non-match, $U$).\n\nThe likelihood ratio, $LR$, is defined as the ratio of the probability of observing the evidence (the agreement pattern $\\gamma$) given a true match, to the probability of observing the evidence given a true non-match:\n$$LR = \\frac{P(\\gamma | M)}{P(\\gamma | U)}$$\nThe log-likelihood ratio is the natural logarithm of this quantity: $s = \\ln(LR)$.\n\nDue to the conditional independence assumption, the probability of the full agreement pattern is the product of the probabilities for each individual field. The log-likelihood ratio is thus the sum of the log-likelihood ratios for each field, often called \"weights\". For a field $i$, the weight $w_i$ is given by:\n- $w_i = \\ln\\left(\\frac{m_i}{u_i}\\right)$ if the field agrees.\n- $w_i = \\ln\\left(\\frac{1-m_i}{1-u_i}\\right)$ if the field disagrees.\nHere, $m_i$ is the probability of agreement given a true match, and $u_i$ is the probability of agreement given a true non-match.\n\nThe problem provides the following data for three fields:\n1.  Name: Agreement. $m_1 = 0.95$, $u_1 = 0.10$.\n2.  Date of Birth (DOB): Agreement. $m_2 = 0.90$, $u_2 = 0.05$.\n3.  Zip Code: Disagreement. $m_3 = 0.85$, $u_3 = 0.02$.\n\nThe total log-likelihood ratio $s$ is the sum of the weights for each field according to its agreement status:\n$$s = \\ln\\left(\\frac{m_1}{u_1}\\right) + \\ln\\left(\\frac{m_2}{u_2}\\right) + \\ln\\left(\\frac{1-m_3}{1-u_3}\\right)$$\nSubstituting the given values:\n$$s = \\ln\\left(\\frac{0.95}{0.10}\\right) + \\ln\\left(\\frac{0.90}{0.05}\\right) + \\ln\\left(\\frac{1 - 0.85}{1 - 0.02}\\right)$$\n$$s = \\ln(9.5) + \\ln(18) + \\ln\\left(\\frac{0.15}{0.98}\\right)$$\n\nNext, we determine the Bayes-optimal decision threshold, $t$. A Bayes-optimal decision rule seeks to minimize the expected cost of misclassification. The rule is to classify a pair as a match if the expected cost of doing so is less than the expected cost of classifying it as a non-match.\nLet $D_M$ be the decision to classify as a match, and $D_U$ be the decision to classify as a non-match. The expected costs are:\n$$E[\\text{Cost}|D_M] = C_{\\mathrm{FP}} \\cdot P(U|\\gamma)$$\n$$E[\\text{Cost}|D_U] = C_{\\mathrm{FN}} \\cdot P(M|\\gamma)$$\nwhere $C_{\\mathrm{FP}}$ is the cost of a false match, $C_{\\mathrm{FN}}$ is the cost of a false non-match, and $P(M|\\gamma)$ and $P(U|\\gamma)$ are the posterior probabilities of the pair being a match or non-match given the evidence $\\gamma$. The costs of correct classification are assumed to be $0$.\n\nThe optimal decision is to classify as a match if $E[\\text{Cost}|D_M]  E[\\text{Cost}|D_U]$, which means:\n$$C_{\\mathrm{FP}} \\cdot P(U|\\gamma)  C_{\\mathrm{FN}} \\cdot P(M|\\gamma)$$\nRearranging this inequality gives a condition on the posterior odds:\n$$\\frac{P(M|\\gamma)}{P(U|\\gamma)}  \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}}}$$\nBy Bayes' theorem, the posterior odds can be expressed in terms of the prior odds and the likelihood ratio:\n$$\\frac{P(M|\\gamma)}{P(U|\\gamma)} = \\frac{P(\\gamma|M) P(M)}{P(\\gamma|U) P(U)} = LR \\cdot \\frac{\\pi}{1-\\pi}$$\nwhere $\\pi = P(M)$ is the prior probability of a match.\n\nSubstituting this into the decision rule, we get:\n$$LR \\cdot \\frac{\\pi}{1-\\pi}  \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}}}$$\n$$LR  \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}}} \\cdot \\frac{1-\\pi}{\\pi}$$\nThe decision is made by comparing the log-likelihood ratio $s = \\ln(LR)$ to a threshold $t$. Taking the natural logarithm of both sides gives:\n$$s  \\ln\\left(\\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)$$\nThe Bayes-optimal decision threshold $t$ is the right-hand side of this inequality:\n$$t = \\ln\\left(\\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FN}}} \\cdot \\frac{1-\\pi}{\\pi}\\right)$$\nThe problem gives $C_{\\mathrm{FP}} = 10$, $C_{\\mathrm{FN}} = 1$, and $\\pi = 0.02$.\n$$t = \\ln\\left(\\frac{10}{1} \\cdot \\frac{1-0.02}{0.02}\\right) = \\ln\\left(10 \\cdot \\frac{0.98}{0.02}\\right) = \\ln(10 \\cdot 49) = \\ln(490)$$\n\nFinally, we compute the required value $s - t$:\n$$s - t = \\left[ \\ln(9.5) + \\ln(18) + \\ln\\left(\\frac{0.15}{0.98}\\right) \\right] - \\ln(490)$$\nUsing the properties of logarithms, $\\ln(a) + \\ln(b) = \\ln(ab)$ and $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$s - t = \\ln\\left( \\frac{9.5 \\times 18 \\times 0.15}{0.98 \\times 490} \\right)$$\n$$s - t = \\ln\\left( \\frac{171 \\times 0.15}{480.2} \\right)$$\n$$s - t = \\ln\\left( \\frac{25.65}{480.2} \\right)$$\n$$s - t \\approx \\ln(0.05341524364848)$$\n$$s - t \\approx -2.9296717$$\nRounding to four significant figures, we get $-2.930$.", "answer": "$$\\boxed{-2.930}$$", "id": "4852339"}]}