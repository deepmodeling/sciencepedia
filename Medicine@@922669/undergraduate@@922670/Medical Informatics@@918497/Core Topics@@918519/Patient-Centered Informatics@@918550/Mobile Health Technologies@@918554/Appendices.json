{"hands_on_practices": [{"introduction": "A core challenge in mobile health is managing the trade-off between continuous data collection and limited battery life. This exercise grounds this challenge in fundamental physics, asking you to model how an application's duty cycle—the fraction of time it is active—directly impacts a smartphone's operational longevity. By working from the core definitions of electric current and charge, you will gain practical insight into power management strategies essential for designing effective and sustainable mHealth interventions [@problem_id:4848914].", "problem": "A mobile health (mHealth) application continuously collects triaxial accelerometer data at a sampling frequency of $50\\,\\mathrm{Hz}$ on a smartphone with a rated battery capacity of $3000\\,\\mathrm{mAh}$. When the accelerometer is active and data are processed in the background with the screen off, the total average device current attributable to this sensing-and-processing workload is $20\\,\\mathrm{mA}$; when the accelerometer is inactive, this workload contributes $0\\,\\mathrm{mA}$. Assume that other system loads are negligible for this analysis, self-discharge and voltage dependence can be ignored, and the duty cycle $d$ is the fraction of time the accelerometer workload is active. Using only the core definitions that battery capacity in ampere-hours represents available charge and that electric current is charge per unit time, derive the average current as a function of duty cycle and the corresponding battery life in hours. Then evaluate the effect of reducing the duty cycle from continuous operation ($d=1$) to $d=0.25$ by computing the multiplicative change factor $\\phi$ defined as $\\phi = \\dfrac{T(d=0.25)}{T(d=1)}$, where $T(\\cdot)$ is battery life in hours. Express your final answer as a pure number with no units and round to four significant figures.", "solution": "The problem will first be validated for scientific correctness, consistency, and well-posedness.\n\n### Step 1: Extract Givens\n-   Sampling frequency: $50\\,\\mathrm{Hz}$\n-   Battery capacity, $C_{batt}$: $3000\\,\\mathrm{mAh}$\n-   Current during active workload (sensing-and-processing), $I_{on}$: $20\\,\\mathrm{mA}$\n-   Current during inactive workload, $I_{off}$: $0\\,\\mathrm{mA}$\n-   Duty cycle, $d$: fraction of time the accelerometer workload is active.\n-   Assumption: Other system loads are negligible.\n-   Assumption: Self-discharge and voltage dependence are ignored.\n-   Definition: Battery capacity in ampere-hours represents available charge.\n-   Definition: Electric current is charge per unit time.\n-   Objective 1: Derive the average current as a function of duty cycle.\n-   Objective 2: Derive the corresponding battery life in hours.\n-   Objective 3: Compute the multiplicative change factor $\\phi = \\dfrac{T(d=0.25)}{T(d=1)}$, where $T(\\cdot)$ is battery life in hours.\n-   Required format for final answer: pure number rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n\n-   **Scientifically Grounded**: The problem is based on fundamental principles of electricity. The definition of electric current as the rate of flow of charge ($I = \\frac{dQ}{dt}$) and the concept of battery capacity as total deliverable charge are core to basic circuit theory. The values provided ($3000\\,\\mathrm{mAh}$ for a battery, $20\\,\\mathrm{mA}$ for a sensor workload) are physically realistic for a modern smartphone. The sampling frequency of $50\\,\\mathrm{Hz}$ is typical for mHealth applications.\n-   **Well-Posed**: The problem is well-posed. It provides all necessary data and simplifying assumptions to derive a unique solution. The objectives are clearly stated and mathematically formalizable.\n-   **Objective**: The language is precise and unbiased. Terms like \"duty cycle\" are defined, and assumptions are explicitly listed.\n-   **Flaw Check**:\n    1.  **Scientific/Factual Unsoundness**: None. The problem adheres to the laws of physics.\n    2.  **Non-Formalizable/Irrelevant**: The problem is formalizable and directly relevant to the power consumption analysis of mHealth technologies, a key topic in medical informatics.\n    3.  **Incomplete or Contradictory Setup**: The problem is self-contained. The sampling frequency of $50\\,\\mathrm{Hz}$ is contextual information and does not create a contradiction or an insufficiency, as the current draw is given as an aggregate value for the \"sensing-and-processing workload\".\n    4.  **Unrealistic or Infeasible**: The conditions and data are realistic.\n    5.  **Ill-Posed or Poorly Structured**: The problem is well-structured, leading from first principles to a specific numerical result.\n    6.  **Pseudo-Profound, Trivial, or Tautological**: The problem is a straightforward application of fundamental definitions, but it is not trivial as it requires the correct assembly of these concepts to model the system.\n    7.  **Outside Scientific Verifiability**: The reasoning and result are verifiable through standard physics principles.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be provided.\n\n### Solution Derivation\nThe problem asks for a derivation based on the core definitions of current and charge. Let $Q$ be the electric charge and $t$ be time. The electric current $I$ is the rate of flow of charge, $I = \\frac{dQ}{dt}$. For a constant current, the total charge $\\Delta Q$ transferred over a time interval $\\Delta t$ is $\\Delta Q = I \\cdot \\Delta t$.\n\nBattery capacity, given in units of ampere-hours ($\\mathrm{Ah}$) or milliampere-hours ($\\mathrm{mAh}$), represents the total charge $C_{batt}$ that a battery can deliver.\nGiven $C_{batt} = 3000\\,\\mathrm{mAh}$.\n\nThe workload is periodic, characterized by a duty cycle $d$. Let $I_{on}$ be the current when the workload is active and $I_{off}$ be the current when it is inactive.\n-   $I_{on} = 20\\,\\mathrm{mA}$\n-   $I_{off} = 0\\,\\mathrm{mA}$\n\nThe average current, $I_{avg}$, is the weighted average of the currents in the two states, where the weights are the fractions of time spent in each state. The fraction of time the workload is active is $d$, and the fraction of time it is inactive is $(1 - d)$.\nTherefore, the average current as a function of the duty cycle $d$ is:\n$$I_{avg}(d) = d \\cdot I_{on} + (1 - d) \\cdot I_{off}$$\nSubstituting the given values:\n$$I_{avg}(d) = d \\cdot (20\\,\\mathrm{mA}) + (1 - d) \\cdot (0\\,\\mathrm{mA})$$\n$$I_{avg}(d) = 20d\\,\\mathrm{mA}$$\nThis is the first required derivation.\n\nNext, we derive the battery life, $T$, which is the total time until the battery is depleted. Assuming the device operates at a constant average current $I_{avg}$, the total charge consumed over the battery life $T$ is $Q_{consumed} = I_{avg} \\cdot T$. The battery is depleted when the consumed charge equals the battery's capacity, $Q_{consumed} = C_{batt}$.\n$$C_{batt} = I_{avg}(d) \\cdot T(d)$$\nSolving for the battery life $T(d)$:\n$$T(d) = \\frac{C_{batt}}{I_{avg}(d)}$$\nSubstituting the expressions for $C_{batt}$ and $I_{avg}(d)$:\n$$T(d) = \\frac{3000\\,\\mathrm{mAh}}{20d\\,\\mathrm{mA}} = \\frac{150}{d}\\,\\mathrm{h}$$\nThis is the second required derivation. Note that the units of $\\mathrm{mA}$ cancel, leaving the time unit of hours ($\\mathrm{h}$).\n\nFinally, we must compute the multiplicative change factor $\\phi = \\dfrac{T(d=0.25)}{T(d=1)}$.\nFirst, we calculate the battery life for continuous operation, where the duty cycle $d=1$:\n$$T(d=1) = \\frac{150}{1}\\,\\mathrm{h} = 150\\,\\mathrm{h}$$\nNext, we calculate the battery life for a reduced duty cycle of $d=0.25$:\n$$T(d=0.25) = \\frac{150}{0.25}\\,\\mathrm{h} = \\frac{150}{\\frac{1}{4}}\\,\\mathrm{h} = 150 \\cdot 4\\,\\mathrm{h} = 600\\,\\mathrm{h}$$\n\nNow, we compute the ratio $\\phi$:\n$$\\phi = \\frac{T(d=0.25)}{T(d=1)} = \\frac{600\\,\\mathrm{h}}{150\\,\\mathrm{h}}$$\n$$\\phi = 4$$\nAlternatively, using the symbolic expression for $T(d)$:\n$$\\phi = \\frac{\\frac{150}{0.25}}{\\frac{150}{1}} = \\frac{1}{0.25} = 4$$\nThe problem requires the answer to be expressed as a pure number rounded to four significant figures. The exact answer is the integer $4$. To express this with four significant figures, we write $4.000$.", "answer": "$$\\boxed{4.000}$$", "id": "4848914"}, {"introduction": "Even a highly accurate diagnostic algorithm can produce a surprising number of false alarms, a phenomenon critical to understand in clinical practice. This problem explores the concept of Positive Predictive Value (PPV) by applying Bayes' theorem to a hypothetical sepsis alert system [@problem_id:4848954]. You will derive the PPV from first principles to see how a condition's prevalence dramatically influences an alert's reliability and why this can lead to 'alert fatigue' among clinicians.", "problem": "A hospital deploys a mobile health (mHealth) sepsis early warning system that streams vital signs from wearable sensors to clinicians’ smartphones, generating a binary alert when sepsis is suspected. Assume the ward has a stable sepsis prevalence of $0.03$. The alert algorithm has sensitivity $0.85$ and specificity $0.95$. Using first principles—namely the definitions of sensitivity and specificity as conditional probabilities and Bayes’ theorem—derive from scratch the expression for the Positive Predictive Value (PPV), which is the probability that sepsis is present given a positive alert, denoted $\\Pr(\\text{sepsis} \\mid \\text{alert}+)$. Then compute the expected PPV for the given parameters. Based only on this computed PPV and without introducing any additional empirical assumptions, explain the implications for clinician alert fatigue in such an mHealth workflow. Express the PPV as a unitless decimal and round your numerical result to four significant figures.", "solution": "The problem requires the derivation of the Positive Predictive Value (PPV) from first principles, a subsequent calculation based on provided parameters, and an interpretation of the result in the context of clinician alert fatigue. The validation confirms the problem is scientifically grounded, well-posed, and objective.\n\nLet $S$ denote the event that a patient has sepsis, and $S^c$ be its complement, the event that the patient does not have sepsis. Let $A$ denote the event that the mHealth system generates a positive alert ($\\text{alert}+$), and $A^c$ be its complement, a negative alert.\n\nThe given parameters are translated into probabilistic terms:\n1.  The prevalence of sepsis, denoted $\\Pr(S)$, is $0.03$. Consequently, the probability of not having sepsis is $\\Pr(S^c) = 1 - \\Pr(S) = 1 - 0.03 = 0.97$.\n2.  The sensitivity of the alert algorithm, which is the conditional probability of a positive alert given that sepsis is present, is $\\Pr(A \\mid S) = 0.85$. This is the True Positive Rate (TPR).\n3.  The specificity of the algorithm, which is the conditional probability of a negative alert given that sepsis is not present, is $\\Pr(A^c \\mid S^c) = 0.95$. This is the True Negative Rate (TNR).\n\nThe target quantity is the Positive Predictive Value (PPV), defined as the probability that sepsis is present given a positive alert, denoted $\\Pr(S \\mid A)$.\n\n**Derivation from First Principles:**\n\nAccording to the definition of conditional probability, the PPV is given by:\n$$\n\\Pr(S \\mid A) = \\frac{\\Pr(S \\cap A)}{\\Pr(A)}\n$$\nwhere $\\Pr(S \\cap A)$ is the joint probability of a patient having sepsis and the system issuing a positive alert.\n\nUsing the definition of conditional probability again, the numerator can be re-expressed as:\n$$\n\\Pr(S \\cap A) = \\Pr(A \\mid S) \\Pr(S)\n$$\nThis expression directly uses two of the given quantities: sensitivity and prevalence.\n\nThe denominator, $\\Pr(A)$, is the total probability of receiving a positive alert. This can be determined using the law of total probability, which marginalizes over the patient's true state (sepsis or no sepsis):\n$$\n\\Pr(A) = \\Pr(A \\cap S) + \\Pr(A \\cap S^c)\n$$\nApplying the definition of conditional probability to both terms on the right-hand side, we get:\n$$\n\\Pr(A) = \\Pr(A \\mid S) \\Pr(S) + \\Pr(A \\mid S^c) \\Pr(S^c)\n$$\nThe first term, $\\Pr(A \\mid S) \\Pr(S)$, corresponds to true positive alerts. The second term, $\\Pr(A \\mid S^c) \\Pr(S^c)$, corresponds to false positive alerts.\n\nThe term $\\Pr(A \\mid S^c)$ is the False Positive Rate (FPR). It is not directly given but can be derived from the specificity. The events of a positive alert ($A$) and a negative alert ($A^c$) are mutually exclusive and exhaustive for a given condition. Therefore, for the condition $S^c$ (no sepsis):\n$$\n\\Pr(A \\mid S^c) + \\Pr(A^c \\mid S^c) = 1\n$$\nThis means the False Positive Rate is complementary to the True Negative Rate (specificity):\n$$\n\\Pr(A \\mid S^c) = 1 - \\Pr(A^c \\mid S^c) = 1 - \\text{specificity}\n$$\n\nSubstituting all these expressions back into the formula for PPV, we arrive at the complete expression derived from first principles:\n$$\n\\text{PPV} = \\Pr(S \\mid A) = \\frac{\\Pr(A \\mid S) \\Pr(S)}{\\Pr(A \\mid S) \\Pr(S) + (1 - \\Pr(A^c \\mid S^c)) \\Pr(S^c)}\n$$\nIn terms of sensitivity ($Se$), specificity ($Sp$), and prevalence ($P$):\n$$\n\\text{PPV} = \\frac{Se \\cdot P}{Se \\cdot P + (1 - Sp) \\cdot (1 - P)}\n$$\nThis derivation fulfills the first part of the task.\n\n**Computation of Expected PPV:**\n\nNow, we substitute the given numerical values into the derived formula:\n- Prevalence, $P = \\Pr(S) = 0.03$\n- Sensitivity, $Se = \\Pr(A \\mid S) = 0.85$\n- Specificity, $Sp = \\Pr(A^c \\mid S^c) = 0.95$\n\nThe probability of no sepsis is $1 - P = 1 - 0.03 = 0.97$.\nThe False Positive Rate is $1 - Sp = 1 - 0.95 = 0.05$.\n\nThe numerator is the probability of a true positive:\n$$\nSe \\cdot P = 0.85 \\times 0.03 = 0.0255\n$$\nThe probability of a false positive is:\n$$\n(1 - Sp) \\cdot (1 - P) = 0.05 \\times 0.97 = 0.0485\n$$\nThe total probability of an alert, $\\Pr(A)$, is the sum of the probabilities of a true positive and a false positive:\n$$\n\\Pr(A) = 0.0255 + 0.0485 = 0.0740\n$$\nFinally, the PPV is the ratio of the true positive probability to the total alert probability:\n$$\n\\text{PPV} = \\frac{0.0255}{0.0740} = \\frac{255}{740} = \\frac{51}{148} \\approx 0.34459459...\n$$\nRounding to four significant figures, the expected PPV is $0.3446$.\n\n**Implications for Clinician Alert Fatigue:**\n\nThe computed Positive Predictive Value (PPV) is $\\approx 0.3446$. This value represents the post-test probability that a patient has sepsis, given that the mHealth system has generated a positive alert. The direct implication of this PPV is that for any given alert, there is only a $34.46\\%$ chance that it is a true positive (i.e., the patient actually has sepsis).\n\nConversely, the probability that an alert is a false positive is given by $1 - \\text{PPV}$:\n$$\n\\Pr(S^c \\mid A) = 1 - \\Pr(S \\mid A) \\approx 1 - 0.3446 = 0.6554\n$$\nThis means that approximately $65.54\\%$ of the alerts generated by the system are false alarms. In a clinical workflow, this translates to clinicians being notified of a potential sepsis case, only to find out that the patient is fine nearly two-thirds of the time.\n\nThis high rate of false alarms is the primary driver of clinician alert fatigue. When a majority of alerts are non-actionable, clinicians may become desensitized or habituated to them. This can lead to a decrease in their responsiveness, causing them to ignore, override, or delay their reaction to subsequent alerts. The severe consequence of this phenomenon is that a true positive alert—representing a genuine, time-sensitive case of sepsis—might be missed or addressed too slowly, undermining the entire purpose of the early warning system and potentially leading to adverse patient outcomes. Therefore, despite a high sensitivity ($85\\%$) and specificity ($95\\%$), the relatively low prevalence of the condition results in a PPV that is problematically low, creating a workflow with a high propensity for inducing alert fatigue.", "answer": "$$\n\\boxed{0.3446}\n$$", "id": "4848954"}, {"introduction": "Choosing the right metric to evaluate a medical diagnostic model is as important as designing the model itself, especially when the condition being screened for is rare. This exercise contrasts two common metrics, the Area Under the ROC curve ($A_{\\mathrm{ROC}}$) and the Area Under the Precision-Recall curve ($A_{\\mathrm{PR}}$), in the context of an arrhythmia detector [@problem_id:4848941]. By calculating precision at a specific operating point, you will discover why metrics that incorporate precision are often more revealing of a model's clinical utility in low-prevalence settings.", "problem": "A smartwatch-based mobile health arrhythmia detector analyzes short single-lead electrocardiogram segments and outputs a continuous anomaly score. On a held-out validation set representative of ambulatory use, the prevalence of truly arrhythmic segments is $0.01$. Across thresholds, the model’s Area Under the Receiver Operating Characteristic ($A_{\\mathrm{ROC}}$) is $0.95$, and its Area Under the Precision-Recall Curve ($A_{\\mathrm{PR}}$) is $0.20$. At a clinically selected operating threshold intended for near-real-time triage, the detector achieves recall (sensitivity) $0.80$ and specificity $0.95$.\n\nUsing only core definitions from binary classification and probability, compute the expected precision at this operating threshold under the stated prevalence. Then, based on first principles, briefly justify which summary metric, $A_{\\mathrm{ROC}}$ or $A_{\\mathrm{PR}}$, better reflects clinical utility for low-prevalence mobile health arrhythmia detection and why. Round your numerical answer for precision to four significant figures and express it as a decimal (no percentage sign).", "solution": "The user-provided problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- Prevalence of truly arrhythmic segments: $0.01$\n- Area Under the Receiver Operating Characteristic ($A_{\\mathrm{ROC}}$): $0.95$\n- Area Under the Precision-Recall Curve ($A_{\\mathrm{PR}}$): $0.20$\n- Recall (sensitivity) at the selected operating threshold: $0.80$\n- Specificity at the selected operating threshold: $0.95$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the established validation criteria.\n\n- **Scientifically Grounded**: The problem is well-grounded in the principles of binary classification, probability theory, and medical diagnostics. All terms—prevalence, recall (sensitivity), specificity, ROC curves, and Precision-Recall curves—are standard concepts in statistics and machine learning. The provided numerical values are internally consistent and plausible for a real-world medical screening application. Specifically, a high $A_{\\mathrm{ROC}}$ ($0.95$) coupled with a low $A_{\\mathrm{PR}}$ ($0.20$) is a classic signature of a classifier's performance on a dataset with low prevalence (high class imbalance), which is correctly stated to be $0.01$. The problem does not violate any scientific or mathematical principles.\n- **Well-Posed**: The problem is clearly stated and provides all necessary information to compute the required value (precision). The question about the suitability of $A_{\\mathrm{ROC}}$ versus $A_{\\mathrm{PR}}$ is a standard conceptual question in model evaluation with a well-established theoretical answer. A unique and meaningful solution exists.\n- **Objective**: The problem is stated in precise, unbiased, and formal language. The terms are standard and not open to subjective interpretation.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is scientifically sound, well-posed, objective, and contains sufficient information for a complete solution. We may proceed with the solution.\n\n***\n\n### Solution\n\nThe solution is divided into two parts as requested: first, the computation of precision at the specified operating point, and second, a justification for the choice of summary metric.\n\n#### Part 1: Computation of Precision\n\nLet $A$ denote the event that an electrocardiogram segment is truly arrhythmic (positive class), and let $N$ denote the event that the segment is normal (negative class). Let $D^+$ be the event that the detector classifies a segment as anomalous (positive prediction), and $D^-$ be the event that the detector classifies it as normal (negative prediction).\n\nFrom the problem statement, we have the following probabilities:\n- The prevalence of arrhythmia, which is the prior probability of the positive class: $P(A) = 0.01$.\n- The prior probability of the negative class is therefore: $P(N) = 1 - P(A) = 1 - 0.01 = 0.99$.\n- The recall (or sensitivity, or True Positive Rate, TPR) at the operating threshold: $P(D^+ | A) = 0.80$.\n- The specificity (or True Negative Rate, TNR) at the operating threshold: $P(D^- | N) = 0.95$.\n\nWe are asked to compute the precision, also known as the Positive Predictive Value (PPV), which is the probability that a segment is truly arrhythmic given that the detector has classified it as such. In our notation, this is $P(A | D^+)$.\n\nWe use Bayes' theorem to calculate precision:\n$$ P(A | D^+) = \\frac{P(D^+ | A) P(A)}{P(D^+)} $$\nTo use this formula, we must first compute the marginal probability of a positive detection, $P(D^+)$. We use the law of total probability:\n$$ P(D^+) = P(D^+ | A) P(A) + P(D^+ | N) P(N) $$\nWe are given $P(D^+ | A)$ and $P(A)$. We need to find $P(D^+ | N)$, which is the False Positive Rate (FPR). The FPR is defined as $1$ minus the specificity (TNR):\n$$ \\text{FPR} = P(D^+ | N) = 1 - P(D^- | N) = 1 - 0.95 = 0.05 $$\nNow we can substitute the values into the equation for $P(D^+)$:\n$$ P(D^+) = (0.80)(0.01) + (0.05)(0.99) $$\n$$ P(D^+) = 0.008 + 0.0495 = 0.0575 $$\nFinally, we can compute the precision, $P(A | D^+)$:\n$$ \\text{Precision} = P(A | D^+) = \\frac{P(D^+ | A) P(A)}{P(D^+)} = \\frac{(0.80)(0.01)}{0.0575} = \\frac{0.008}{0.0575} $$\n$$ \\text{Precision} \\approx 0.1391304... $$\nRounding to four significant figures as requested, we obtain a precision of $0.1391$.\n\n#### Part 2: Justification of Summary Metric ($A_{\\mathrm{ROC}}$ vs. $A_{\\mathrm{PR}}$)\n\nFor a low-prevalence problem such as arrhythmia detection in a general ambulatory population, the Area Under the Precision-Recall Curve ($A_{\\mathrm{PR}}$) is a more informative and clinically relevant summary metric than the Area Under the Receiver Operating Characteristic curve ($A_{\\mathrm{ROC}}$). The justification is based on first principles concerning how each metric is affected by class imbalance.\n\nThe ROC curve plots the True Positive Rate ($\\text{TPR} = \\frac{TP}{TP+FN}$) against the False Positive Rate ($\\text{FPR} = \\frac{FP}{FP+TN}$), where $TP$, $FN$, $FP$, and $TN$ are the counts of true positives, false negatives, false positives, and true negatives, respectively. Note that both TPR and FPR are rates conditioned on the true class. In a low-prevalence setting, the number of true negatives ($TN$) is vastly larger than the number of true positives ($TP$). A classifier can achieve a very low FPR simply by correctly classifying the abundant negative cases, even if the absolute number of false positives ($FP$) is large relative to the number of true positives ($TP$). Consequently, the $A_{\\mathrm{ROC}}$ can be misleadingly optimistic, as it is not sensitive to the performance on the minority positive class, which is often the class of interest. The high $A_{\\mathrm{ROC}}$ of $0.95$ in this problem illustrates this point: it suggests excellent discrimination, yet the precision at a high-recall operating point is only $0.1391$.\n\nThe Precision-Recall (PR) curve plots precision ($\\text{Precision} = \\frac{TP}{TP+FP}$) against recall ($\\text{Recall} = \\text{TPR} = \\frac{TP}{TP+FN}$). Unlike the rates in the ROC curve, precision's denominator ($TP+FP$) depends on the classifier's predictions. In a low-prevalence scenario, a classifier that generates even a modest rate of false positives will produce a large absolute number of $FP$s, which can easily overwhelm the small number of $TP$s, causing precision to be very low. The PR curve explicitly visualizes this trade-off. Therefore, the $A_{\\mathrm{PR}}$ is highly sensitive to the performance on the minority (positive) class.\n\nIn a clinical context like mobile health arrhythmia triage, a positive detection triggers further investigation, which has costs in terms of clinical resources and patient anxiety. The practical utility of the detector is thus critically dependent on the reliability of its positive alerts, which is precisely what precision measures. A low precision indicates a high rate of false alarms. The $A_{\\mathrm{PR}}$ of $0.20$ accurately reflects that, across various thresholds, the detector struggles to achieve high precision, a critical weakness that is masked by the high $A_{\\mathrm{ROC}}$. Therefore, $A_{\\mathrm{PR}}$ provides a much more realistic and clinically relevant assessment of model performance for low-prevalence screening tasks.", "answer": "$$\\boxed{0.1391}$$", "id": "4848941"}]}