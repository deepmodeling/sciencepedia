{"hands_on_practices": [{"introduction": "To train a Named Entity Recognition model, we must first convert human-readable annotations into a format the machine can understand. The BILOU (Begin, Inside, Last, Outside, Unit-length) tagging scheme is a powerful method for this, as it explicitly marks the boundaries and extent of entities. In this exercise [@problem_id:4849564], you will practice applying this scheme to a clinical snippet, translating text-level entity spans into a precise sequence of token-level tags, a fundamental skill for preparing data for sequence labeling models.", "problem": "In clinical Natural Language Processing, Named Entity Recognition (NER) identifies spans of text referring to clinically meaningful concepts such as problems, tests, and medications. A widely used tagging scheme for span-level labeling is the Begin, Inside, Last, Outside, Unit-length (BILOU) scheme, which assigns a category letter to each token depending on its position in an entity: Begin for the first token of a multi-token entity, Inside for any interior token of a multi-token entity, Last for the final token of a multi-token entity, Outside for tokens not part of any entity, and Unit-length for a single-token entity. In this problem, you will apply the BILOU scheme to a tokenized clinical note snippet with entity spans annotated at the text level and then compute a numeric functional summary of the resulting category sequence.\n \nUse the following foundations:\n- Tokens are produced by splitting on whitespace and treating punctuation marks such as periods as separate tokens.\n- Braced annotations are meta-markup and not part of the token stream; they demarcate entity spans and their types. The text inside braces starts with the entity type name followed by a space and then the exact span tokens. For example, “{Problem chest pain}” marks a “Problem” entity spanning “chest pain” across two tokens.\n- The BILOU scheme assigns category letters at the token level, conditioned on each span’s exact token boundaries. Use the entity types only to decide span membership and to ensure correct BILOU position tagging; for the numeric computation below, you will use only the category letters and ignore the entity types.\n\nConsider the snippet (with annotations) from a clinical note:\nPt reports {Problem chest pain}. Started {Medication aspirin} {Dose 81 mg} daily. {Test ECG} normal. {Test CT chest} negative for {Problem PE}. Discharged home.\n\nAcronym definitions used in the snippet include Electrocardiogram (ECG), Computed Tomography (CT), and Pulmonary Embolism (PE).\n\nTask:\n1. Tokenize the snippet as specified and apply the BILOU scheme to produce the per-token category letters $c_{1}, c_{2}, \\dots, c_{N} \\in \\{\\text{B}, \\text{I}, \\text{L}, \\text{O}, \\text{U}\\}$, where $N$ is the number of tokens.\n2. Define the weight function $w$ on category letters by $w(\\text{B})=2$, $w(\\text{I})=3$, $w(\\text{L})=5$, $w(\\text{O})=0$, and $w(\\text{U})=7$.\n3. Compute the scalar\n$$\nS \\;=\\; \\sum_{i=1}^{N} i \\cdot w(c_{i}).\n$$\n\nReport the value of $S$ as an integer with no units. No rounding is necessary. Clearly show how single-token entities are represented under the BILOU scheme when deriving $c_{1},\\dots,c_{N}$.", "solution": "The problem statement is validated as sound and well-posed. It presents a clear, procedural task within the domain of computational linguistics and medical informatics, specifically concerning Named Entity Recognition (NER). All terms are defined, the given data are consistent, and the required computation is unambiguous. The problem is scientifically grounded, formalizable, and verifiable.\n\nThe solution proceeds in three steps: tokenization of the clinical note, application of the BILOU tagging scheme, and computation of the weighted sum $S$.\n\n### Step 1: Tokenization\n\nThe input snippet is:\n`Pt reports {Problem chest pain}. Started {Medication aspirin} {Dose 81 mg} daily. {Test ECG} normal. {Test CT chest} negative for {Problem PE}. Discharged home.`\n\nThe text content, excluding the meta-markup for annotations, is:\n`Pt reports chest pain. Started aspirin 81 mg daily. ECG normal. CT chest negative for PE. Discharged home.`\n\nAccording to the specified rules, this text is tokenized by splitting on whitespace, and treating punctuation marks (periods in this case) as separate tokens. This process yields a sequence of $N=23$ tokens. The 1-indexed list of tokens, $t_i$, is as follows:\n\n- $t_1$: `Pt`\n- $t_2$: `reports`\n- $t_3$: `chest`\n- $t_4$: `pain`\n- $t_5$: `.`\n- $t_6$: `Started`\n- $t_7$: `aspirin`\n- $t_8$: `81`\n- $t_9$: `mg`\n- $t_{10}$: `daily`\n- $t_{11}$: `.`\n- $t_{12}$: `ECG`\n- $t_{13}$: `normal`\n- $t_{14}$: `.`\n- $t_{15}$: `CT`\n- $t_{16}$: `chest`\n- $t_{17}$: `negative`\n- $t_{18}$: `for`\n- $t_{19}$: `PE`\n- $t_{20}$: `.`\n- $t_{21}$: `Discharged`\n- $t_{22}$: `home`\n- $t_{23}$: `.`\n\n### Step 2: BILOU Tagging\n\nThe BILOU tagging scheme assigns a category letter $c_i \\in \\{\\text{B}, \\text{I}, \\text{L}, \\text{O}, \\text{U}\\}$ to each token $t_i$. The tag depends on the token's position within an annotated entity span.\n- **B**: Begin token of a multi-token entity.\n- **I**: Inside token of a multi-token entity.\n- **L**: Last token of a multi-token entity.\n- **O**: Outside of any entity.\n- **U**: Unit-length (single-token) entity.\n\nThe annotated entity spans and their corresponding token indices are:\n- `{Problem chest pain}`: spans tokens $t_3$ (`chest`) and $t_4$ (`pain`).\n- `{Medication aspirin}`: spans token $t_7$ (`aspirin`).\n- `{Dose 81 mg}`: spans tokens $t_8$ (`81`) and $t_9$ (`mg`).\n- `{Test ECG}`: spans token $t_{12}$ (`ECG`).\n- `{Test CT chest}`: spans tokens $t_{15}$ (`CT`) and $t_{16}$ (`chest`).\n- `{Problem PE}`: spans token $t_{19}$ (`PE`).\n\nApplying the BILOU rules to this token sequence:\n- For `{Problem chest pain}` ($t_3, t_4$): $t_3$ is the first token, so its category is $c_3 = \\text{B}$. $t_4$ is the last token, so its category is $c_4 = \\text{L}$.\n- For `{Medication aspirin}` ($t_7$): This is a single-token entity. As specified, its category is $c_7 = \\text{U}$.\n- For `{Dose 81 mg}` ($t_8, t_9$): $t_8$ is the first token, so $c_8 = \\text{B}$. $t_9$ is the last token, so $c_9 = \\text{L}$.\n- For `{Test ECG}` ($t_{12}$): This is a single-token entity, so its category is $c_{12} = \\text{U}$.\n- For `{Test CT chest}` ($t_{15}, t_{16}$): $t_{15}$ is the first token, so $c_{15} = \\text{B}$. $t_{16}$ is the last token, so $c_{16} = \\text{L}$.\n- For `{Problem PE}` ($t_{19}$): This is a single-token entity, so its category is $c_{19} = \\text{U}$.\n- All other tokens are not part of any annotated entity. Therefore, their category is $\\text{O}$.\n\n### Step 3: Computation of S\n\nThe scalar $S$ is defined as $S = \\sum_{i=1}^{N} i \\cdot w(c_i)$, where weights are given by $w(\\text{B})=2$, $w(\\text{I})=3$, $w(\\text{L})=5$, $w(\\text{O})=0$, and $w(\\text{U})=7$. Since $w(\\text{O})=0$, tokens with category $\\text{O}$ do not contribute to the sum. We only need to sum the terms for tokens with categories $\\text{B}$, $\\text{L}$, or $\\text{U}$.\n\nThe following table summarizes the non-zero contributions to the sum:\n| Index $i$ | Token $t_i$ | Category $c_i$ | Weight $w(c_i)$ | Term $i \\cdot w(c_i)$ |\n|:---:|:---|:---:|:---:|:---:|\n| $3$ | `chest` | $\\text{B}$ | $2$ | $3 \\times 2 = 6$ |\n| $4$ | `pain` | $\\text{L}$ | $5$ | $4 \\times 5 = 20$ |\n| $7$ | `aspirin` | $\\text{U}$ | $7$ | $7 \\times 7 = 49$ |\n| $8$ | `81` | $\\text{B}$ | $2$ | $8 \\times 2 = 16$ |\n| $9$ | `mg` | $\\text{L}$ | $5$ | $9 \\times 5 = 45$ |\n| $12$ | `ECG` | $\\text{U}$ | $7$ | $12 \\times 7 = 84$ |\n| $15$ | `CT` | $\\text{B}$ | $2$ | $15 \\times 2 = 30$ |\n| $16$ | `chest` | $\\text{L}$ | $5$ | $16 \\times 5 = 80$ |\n| $19$ | `PE` | $\\text{U}$ | $7$ | $19 \\times 7 = 133$ |\n\nThe total sum $S$ is the sum of the values in the last column.\n$$\nS = (3 \\cdot w(\\text{B})) + (4 \\cdot w(\\text{L})) + (7 \\cdot w(\\text{U})) + (8 \\cdot w(\\text{B})) + (9 \\cdot w(\\text{L})) + (12 \\cdot w(\\text{U})) + (15 \\cdot w(\\text{B})) + (16 \\cdot w(\\text{L})) + (19 \\cdot w(\\text{U}))\n$$\n$$\nS = (3 \\cdot 2) + (4 \\cdot 5) + (7 \\cdot 7) + (8 \\cdot 2) + (9 \\cdot 5) + (12 \\cdot 7) + (15 \\cdot 2) + (16 \\cdot 5) + (19 \\cdot 7)\n$$\n$$\nS = 6 + 20 + 49 + 16 + 45 + 84 + 30 + 80 + 133\n$$\nSumming these terms:\n$$\nS = 26 + 49 + 16 + 45 + 84 + 30 + 80 + 133\n$$\n$$\nS = 75 + 16 + 45 + 84 + 30 + 80 + 133\n$$\n$$\nS = 91 + 45 + 84 + 30 + 80 + 133\n$$\n$$\nS = 136 + 84 + 30 + 80 + 133\n$$\n$$\nS = 220 + 30 + 80 + 133\n$$\n$$\nS = 250 + 80 + 133\n$$\n$$\nS = 330 + 133\n$$\n$$\nS = 463\n$$\nThe value of the scalar $S$ is $463$.", "answer": "$$\n\\boxed{463}\n$$", "id": "4849564"}, {"introduction": "Once data is appropriately tagged, a model can learn to predict tag sequences for new text. Conditional Random Fields (CRFs) are a class of statistical models well-suited for this task, as they consider the context of the entire sentence. This problem demystifies how a CRF arrives at its prediction by having you manually apply the Viterbi algorithm [@problem_id:4849527], a dynamic programming approach to efficiently find the single most probable tag sequence, providing a clear view into the model's core inference mechanism.", "problem": "A clinical Named Entity Recognition (NER) model for medication extraction is applied to the sentence from a clinical note: \"Take metformin 500 mg\". The tag set is $\\{O, DRUG, DOSE\\}$, where $O$ denotes outside any entity, $DRUG$ denotes a medication mention, and $DOSE$ denotes a dosage expression. Consider a linear-chain Conditional Random Field (CRF) with the following structure: a designated start state $\\text{START}$, position-specific unary log-potentials $u_t(y)$ for token position $t$ and tag $y$, and pairwise transition log-potentials $a(y', y)$ for transitions from tag $y'$ to tag $y$. The sentence has $T = 4$ tokens with indices $t = 1,2,3,4$ corresponding to $x_1 = \\text{\"Take\"}$, $x_2 = \\text{\"metformin\"}$, $x_3 = \\text{\"500\"}$, and $x_4 = \\text{\"mg\"}$.\n\nThe start-transition log-potentials are:\n- $a(\\text{START}, O) = 1$, $a(\\text{START}, DRUG) = 0$, $a(\\text{START}, DOSE) = -2$.\n\nThe transition log-potentials $a(y', y)$ for $y', y \\in \\{O, DRUG, DOSE\\}$ are:\n- $a(O, O) = 1$, $a(O, DRUG) = 1$, $a(O, DOSE) = -1$.\n- $a(DRUG, O) = -1$, $a(DRUG, DRUG) = 1$, $a(DRUG, DOSE) = 2$.\n- $a(DOSE, O) = 0$, $a(DOSE, DRUG) = -2$, $a(DOSE, DOSE) = 2$.\n\nThe unary log-potentials $u_t(y)$ are:\n- At $t = 1$ ($x_1 = \\text{\"Take\"}$): $u_1(O) = 2$, $u_1(DRUG) = -1$, $u_1(DOSE) = -3$.\n- At $t = 2$ ($x_2 = \\text{\"metformin\"}$): $u_2(DRUG) = 3$, $u_2(O) = 0$, $u_2(DOSE) = -2$.\n- At $t = 3$ ($x_3 = \\text{\"500\"}$): $u_3(DOSE) = 4$, $u_3(O) = -1$, $u_3(DRUG) = -2$.\n- At $t = 4$ ($x_4 = \\text{\"mg\"}$): $u_4(DOSE) = 3$, $u_4(O) = 0$, $u_4(DRUG) = -2$.\n\nUsing the principle of optimal substructure for a linear-chain model and the Viterbi algorithm, determine the most probable tag sequence for this sentence under the given log-potentials. Then, compute the total log-linear score $S^{\\star}$ of that optimal sequence, defined as the sum of the start-transition log-potential, the selected pairwise transition log-potentials along the sequence, and the selected unary log-potentials for each position. Report $S^{\\star}$ as a real number. No rounding is required. Express the final answer without units.", "solution": "### Step 1: Extract Givens\nThe problem provides the following information for a linear-chain Conditional Random Field (CRF) model:\n- **Tag Set**: $Y = \\{O, DRUG, DOSE\\}$\n- **Sentence Tokens**: $x_1 = \\text{\"Take\"}$, $x_2 = \\text{\"metformin\"}$, $x_3 = \\text{\"500\"}$, $x_4 = \\text{\"mg\"}$, with length $T=4$.\n- **Start-Transition Log-Potentials** $a(\\text{START}, y)$:\n  - $a(\\text{START}, O) = 1$\n  - $a(\\text{START}, DRUG) = 0$\n  - $a(\\text{START}, DOSE) = -2$\n- **Pairwise Transition Log-Potentials** $a(y', y)$:\n  - $a(O, O) = 1$, $a(O, DRUG) = 1$, $a(O, DOSE) = -1$\n  - $a(DRUG, O) = -1$, $a(DRUG, DRUG) = 1$, $a(DRUG, DOSE) = 2$\n  - $a(DOSE, O) = 0$, $a(DOSE, DRUG) = -2$, $a(DOSE, DOSE) = 2$\n- **Unary Log-Potentials** $u_t(y)$:\n  - $t = 1$: $u_1(O) = 2$, $u_1(DRUG) = -1$, $u_1(DOSE) = -3$\n  - $t = 2$: $u_2(O) = 0$, $u_2(DRUG) = 3$, $u_2(DOSE) = -2$\n  - $t = 3$: $u_3(O) = -1$, $u_3(DRUG) = -2$, $u_3(DOSE) = 4$\n  - $t = 4$: $u_4(O) = 0$, $u_4(DRUG) = -2$, $u_4(DOSE) = 3$\n- **Task**: Determine the most probable tag sequence and compute its total log-linear score $S^{\\star}$ using the Viterbi algorithm.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective.\n- **Scientific Grounding**: It describes a standard application of a linear-chain Conditional Random Field (CRF), a widely used model in natural language processing for sequence labeling. The Viterbi algorithm is the correct dynamic programming method for inference in such models. The provided log-potentials and structure are consistent with the principles of CRFs.\n- **Well-Posedness**: All necessary parameters (log-potentials) and data (the sentence) are provided. The task is clearly defined: find the tag sequence that maximizes the total log-linear score. This setup guarantees a unique and computable solution.\n- **Objectivity**: The problem is stated with precise numerical values and formal definitions, leaving no room for subjective interpretation.\n\n### Step 3: Verdict and Action\nThe problem is valid. The solution will proceed by applying the Viterbi algorithm.\n\n### Solution Derivation\nThe Viterbi algorithm finds the most likely sequence of hidden states (tags) that results from a sequence of observed events. For a linear-chain CRF, the score of a tag sequence $y = (y_1, y_2, \\dots, y_T)$ is defined as:\n$$ S(y) = a(\\text{START}, y_1) + \\sum_{t=1}^{T} u_t(y_t) + \\sum_{t=2}^{T} a(y_{t-1}, y_t) $$\nWe use a dynamic programming approach to find the sequence $y^\\star$ that maximizes this score. Let $v_t(y)$ be the maximum score of a sequence ending at position $t$ with tag $y$, and let $b_t(y)$ be the backpointer that stores the previous tag that leads to this maximum score.\n\nThe recurrence relations are:\n1.  **Initialization** (for $t=1$):\n    $$ v_1(y) = a(\\text{START}, y) + u_1(y) $$\n2.  **Recursion** (for $t=2, \\dots, T$):\n    $$ v_t(y) = \\max_{y' \\in Y} \\left( v_{t-1}(y') + a(y', y) \\right) + u_t(y) $$\n    $$ b_t(y) = \\arg\\max_{y' \\in Y} \\left( v_{t-1}(y') + a(y', y) \\right) $$\n\nLet's apply these steps to the given problem.\n\n**Step 1: Initialization ($t = 1$, token \"Take\")**\nWe compute $v_1(y)$ for each tag $y \\in \\{O, DRUG, DOSE\\}$.\n- $v_1(O) = a(\\text{START}, O) + u_1(O) = 1 + 2 = 3$\n- $v_1(DRUG) = a(\\text{START}, DRUG) + u_1(DRUG) = 0 + (-1) = -1$\n- $v_1(DOSE) = a(\\text{START}, DOSE) + u_1(DOSE) = -2 + (-3) = -5$\n\nThe scores at $t=1$ are: $v_1(O) = 3$, $v_1(DRUG) = -1$, $v_1(DOSE) = -5$.\n\n**Step 2: Recursion ($t = 2$, token \"metformin\")**\nWe compute $v_2(y)$ for each tag $y$.\n- For $y = O$:\n  - $v_1(O) + a(O, O) = 3 + 1 = 4$\n  - $v_1(DRUG) + a(DRUG, O) = -1 + (-1) = -2$\n  - $v_1(DOSE) + a(DOSE, O) = -5 + 0 = -5$\n  - $\\max = 4$ (from $y'=O$). $b_2(O) = O$.\n  - $v_2(O) = 4 + u_2(O) = 4 + 0 = 4$.\n- For $y = DRUG$:\n  - $v_1(O) + a(O, DRUG) = 3 + 1 = 4$\n  - $v_1(DRUG) + a(DRUG, DRUG) = -1 + 1 = 0$\n  - $v_1(DOSE) + a(DOSE, DRUG) = -5 + (-2) = -7$\n  - $\\max = 4$ (from $y'=O$). $b_2(DRUG) = O$.\n  - $v_2(DRUG) = 4 + u_2(DRUG) = 4 + 3 = 7$.\n- For $y = DOSE$:\n  - $v_1(O) + a(O, DOSE) = 3 + (-1) = 2$\n  - $v_1(DRUG) + a(DRUG, DOSE) = -1 + 2 = 1$\n  - $v_1(DOSE) + a(DOSE, DOSE) = -5 + 2 = -3$\n  - $\\max = 2$ (from $y'=O$). $b_2(DOSE) = O$.\n  - $v_2(DOSE) = 2 + u_2(DOSE) = 2 + (-2) = 0$.\n\nScores at $t=2$: $v_2(O)=4$, $v_2(DRUG)=7$, $v_2(DOSE)=0$.\nBackpointers at $t=2$: $b_2(O)=O$, $b_2(DRUG)=O$, $b_2(DOSE)=O$.\n\n**Step 3: Recursion ($t = 3$, token \"500\")**\nWe compute $v_3(y)$ for each tag $y$.\n- For $y = O$:\n  - $v_2(O) + a(O, O) = 4 + 1 = 5$\n  - $v_2(DRUG) + a(DRUG, O) = 7 + (-1) = 6$\n  - $v_2(DOSE) + a(DOSE, O) = 0 + 0 = 0$\n  - $\\max = 6$ (from $y'=DRUG$). $b_3(O) = DRUG$.\n  - $v_3(O) = 6 + u_3(O) = 6 + (-1) = 5$.\n- For $y = DRUG$:\n  - $v_2(O) + a(O, DRUG) = 4 + 1 = 5$\n  - $v_2(DRUG) + a(DRUG, DRUG) = 7 + 1 = 8$\n  - $v_2(DOSE) + a(DOSE, DRUG) = 0 + (-2) = -2$\n  - $\\max = 8$ (from $y'=DRUG$). $b_3(DRUG) = DRUG$.\n  - $v_3(DRUG) = 8 + u_3(DRUG) = 8 + (-2) = 6$.\n- For $y = DOSE$:\n  - $v_2(O) + a(O, DOSE) = 4 + (-1) = 3$\n  - $v_2(DRUG) + a(DRUG, DOSE) = 7 + 2 = 9$\n  - $v_2(DOSE) + a(DOSE, DOSE) = 0 + 2 = 2$\n  - $\\max = 9$ (from $y'=DRUG$). $b_3(DOSE) = DRUG$.\n  - $v_3(DOSE) = 9 + u_3(DOSE) = 9 + 4 = 13$.\n\nScores at $t=3$: $v_3(O)=5$, $v_3(DRUG)=6$, $v_3(DOSE)=13$.\nBackpointers at $t=3$: $b_3(O)=DRUG$, $b_3(DRUG)=DRUG$, $b_3(DOSE)=DRUG$.\n\n**Step 4: Recursion ($t = 4$, token \"mg\")**\nWe compute $v_4(y)$ for each tag $y$.\n- For $y = O$:\n  - $v_3(O) + a(O, O) = 5 + 1 = 6$\n  - $v_3(DRUG) + a(DRUG, O) = 6 + (-1) = 5$\n  - $v_3(DOSE) + a(DOSE, O) = 13 + 0 = 13$\n  - $\\max = 13$ (from $y'=DOSE$). $b_4(O) = DOSE$.\n  - $v_4(O) = 13 + u_4(O) = 13 + 0 = 13$.\n- For $y = DRUG$:\n  - $v_3(O) + a(O, DRUG) = 5 + 1 = 6$\n  - $v_3(DRUG) + a(DRUG, DRUG) = 6 + 1 = 7$\n  - $v_3(DOSE) + a(DOSE, DRUG) = 13 + (-2) = 11$\n  - $\\max = 11$ (from $y'=DOSE$). $b_4(DRUG) = DOSE$.\n  - $v_4(DRUG) = 11 + u_4(DRUG) = 11 + (-2) = 9$.\n- For $y = DOSE$:\n  - $v_3(O) + a(O, DOSE) = 5 + (-1) = 4$\n  - $v_3(DRUG) + a(DRUG, DOSE) = 6 + 2 = 8$\n  - $v_3(DOSE) + a(DOSE, DOSE) = 13 + 2 = 15$\n  - $\\max = 15$ (from $y'=DOSE$). $b_4(DOSE) = DOSE$.\n  - $v_4(DOSE) = 15 + u_4(DOSE) = 15 + 3 = 18$.\n\nScores at $t=4$: $v_4(O)=13$, $v_4(DRUG)=9$, $v_4(DOSE)=18$.\nBackpointers at $t=4$: $b_4(O)=DOSE$, $b_4(DRUG)=DOSE$, $b_4(DOSE)=DOSE$.\n\n**Step 5: Termination and Backtracking**\nThe total score $S^{\\star}$ of the optimal sequence is the maximum value in the final column of Viterbi scores:\n$$ S^{\\star} = \\max_{y \\in Y} v_4(y) = \\max(13, 9, 18) = 18 $$\nThe last tag of the optimal sequence is the one that gives this maximum score:\n$$ y_4^{\\star} = \\arg\\max_{y \\in Y} v_4(y) = \\text{DOSE} $$\nNow we backtrack to find the rest of the sequence:\n- $y_3^{\\star} = b_4(y_4^{\\star}) = b_4(\\text{DOSE}) = \\text{DOSE}$\n- $y_2^{\\star} = b_3(y_3^{\\star}) = b_3(\\text{DOSE}) = \\text{DRUG}$\n- $y_1^{\\star} = b_2(y_2^{\\star}) = b_2(\\text{DRUG}) = O$\n\nThe most probable tag sequence is $y^{\\star} = (O, \\text{DRUG}, \\text{DOSE}, \\text{DOSE})$.\n\n**Verification of the Total Score**\nLet's manually compute the score for the sequence $y^{\\star} = (O, \\text{DRUG}, \\text{DOSE}, \\text{DOSE})$ to verify the result.\n$S^{\\star} = a(\\text{START}, y_1^\\star) + u_1(y_1^\\star) + a(y_1^\\star, y_2^\\star) + u_2(y_2^\\star) + a(y_2^\\star, y_3^\\star) + u_3(y_3^\\star) + a(y_3^\\star, y_4^\\star) + u_4(y_4^\\star)$\n$S^{\\star} = a(\\text{START}, O) + u_1(O) + a(O, \\text{DRUG}) + u_2(\\text{DRUG}) + a(\\text{DRUG}, \\text{DOSE}) + u_3(\\text{DOSE}) + a(\\text{DOSE}, \\text{DOSE}) + u_4(\\text{DOSE})$\n$S^{\\star} = 1 + 2 + 1 + 3 + 2 + 4 + 2 + 3$\n$S^{\\star} = 3 + 4 + 6 + 5 = 18$\nThe calculated score matches the score obtained from the Viterbi algorithm. The total log-linear score of the optimal sequence is $18$.", "answer": "$$\\boxed{18}$$", "id": "4849527"}, {"introduction": "After a model makes predictions, we need to quantify its performance, but what does it mean for a prediction to be \"correct\"? This practice problem [@problem_id:4849523] explores this question by contrasting two common evaluation standards: strict matching, which requires a perfect match, and relaxed matching, which allows for minor boundary errors. By calculating the $F1$ score under both regimes, you will gain a crucial understanding of how the choice of metric can impact the interpretation of a model's performance and why forgiving small errors can be important in practical applications.", "problem": "A clinical note has been tokenized into indexed tokens. A human-annotated gold standard set of entities with types and token spans is provided, along with a model’s predicted entities. Consider two evaluation regimes for Named Entity Recognition (NER): strict matching and relaxed matching. Use the following scientifically grounded definitions as the base of your derivation: True Positive (TP) counts a predicted entity that correctly matches a gold entity under the regime’s matching rule; False Positive (FP) counts a predicted entity that does not match any gold entity under the regime’s rule; False Negative (FN) counts a gold entity that does not have any matching predicted entity under the regime’s rule. Precision $P$ is defined as $P=\\frac{\\text{TP}}{\\text{TP}+\\text{FP}}$, Recall $R$ is defined as $R=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}}$, and the $F1$ score is defined as the harmonic mean $F1=\\frac{2PR}{P+R}$.\n\nMatch definitions are as follows. Under strict matching, a predicted entity is considered a match if and only if its type exactly equals the gold entity’s type and its token span is identical to the gold entity’s span. Under relaxed matching, a predicted entity is considered a match if and only if its type equals the gold entity’s type and its token span overlaps the gold entity’s span in at least one token; apply a one-to-one constraint so that each gold entity can be matched to at most one predicted entity and each predicted entity can be matched to at most one gold entity. When multiple overlapping candidates exist, assume the evaluation selects matches to maximize the number of true positives.\n\nThe gold entities are:\n- $G_1$: type $\\text{Problem}$, span $[5,7]$.\n- $G_2$: type $\\text{Test}$, span $[10,11]$.\n- $G_3$: type $\\text{Treatment}$, span $[15,15]$.\n- $G_4$: type $\\text{Problem}$, span $[20,21]$.\n- $G_5$: type $\\text{Test}$, span $[25,27]$.\n- $G_6$: type $\\text{Treatment}$, span $[30,32]$.\n\nThe predicted entities are:\n- $P_1$: type $\\text{Problem}$, span $[5,7]$.\n- $P_2$: type $\\text{Test}$, span $[10,12]$.\n- $P_3$: type $\\text{Treatment}$, span $[14,15]$.\n- $P_4$: type $\\text{Problem}$, span $[20,22]$.\n- $P_5$: type $\\text{Test}$, span $[25,26]$.\n- $P_6$: type $\\text{Treatment}$, span $[31,32]$.\n- $P_7$: type $\\text{Problem}$, span $[2,3]$.\n- $P_8$: type $\\text{Test}$, span $[40,41]$.\n- $P_9$: type $\\text{Problem}$, span $[25,27]$.\n\nCompute the strict $F1$ score and the relaxed $F1$ score from first principles using the provided definitions and matching rules. Then compute the difference $\\Delta = F1_{\\text{relaxed}} - F1_{\\text{strict}}$. Express your final answer for $\\Delta$ as a reduced fraction. No rounding is required. Additionally, within your solution, explain the principal reason for any discrepancy between the strict and relaxed $F1$ scores in terms of boundary detection and type agreement in clinical NER.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It provides a complete and consistent set of definitions, data, and constraints required to compute the specified named entity recognition (NER) metrics. The rules for strict and relaxed matching are clearly defined, including the optimization criterion for the relaxed case, ensuring a unique solution can be determined. Therefore, the problem is valid, and we may proceed with the solution.\n\nThe problem requires the calculation of the $F1$ score under two different evaluation regimes: strict and relaxed matching. We are given $N_G = 6$ gold standard entities and $N_P = 9$ predicted entities. We will first calculate the scores for the strict regime, then for the relaxed regime, and finally compute their difference.\n\nThe fundamental quantities are True Positives ($TP$), False Positives ($FP$), and False Negatives ($FN$). From these, we compute Precision ($P$) and Recall ($R$):\n$$P = \\frac{TP}{TP+FP}$$\n$$R = \\frac{TP}{TP+FN}$$\nThe $F1$ score is the harmonic mean of Precision and Recall:\n$$F1 = \\frac{2PR}{P+R} = \\frac{2 \\cdot \\frac{TP}{TP+FP} \\cdot \\frac{TP}{TP+FN}}{\\frac{TP}{TP+FP} + \\frac{TP}{TP+FN}} = \\frac{2(TP)^2}{TP(TP+FN) + TP(TP+FP)} = \\frac{2TP}{2TP+FP+FN}$$\n\nFirst, we analyze the performance under the **strict matching** regime, which requires that both the entity type and the token span be identical for a match to occur.\n\nWe compare each predicted entity ($P_i$) against the set of gold entities ($G_j$):\n- $P_1$ (type $\\text{Problem}$, span $[5,7]$) is an exact match for $G_1$ (type $\\text{Problem}$, span $[5,7]$). This is a True Positive.\n- $P_2$ (type $\\text{Test}$, span $[10,12]$) has the same type as $G_2$ (type $\\text{Test}$, span $[10,11]$), but the span is different. Not a strict match.\n- $P_3$ (type $\\text{Treatment}$, span $[14,15]$) has the same type as $G_3$ (type $\\text{Treatment}$, span $[15,15]$), but the span is different. Not a strict match.\n- $P_4$ (type $\\text{Problem}$, span $[20,22]$) has the same type as $G_4$ (type $\\text{Problem}$, span $[20,21]$), but the span is different. Not a strict match.\n- $P_5$ (type $\\text{Test}$, span $[25,26]$) has the same type as $G_5$ (type $\\text{Test}$, span $[25,27]$), but the span is different. Not a strict match.\n- $P_6$ (type $\\text{Treatment}$, span $[31,32]$) has the same type as $G_6$ (type $\\text{Treatment}$, span $[30,32]$), but the span is different. Not a strict match.\n- $P_7$ (type $\\text{Problem}$, span $[2,3]$) does not correspond to any gold entity. Not a match.\n- $P_8$ (type $\\text{Test}$, span $[40,41]$) does not correspond to any gold entity. Not a match.\n- $P_9$ (type $\\text{Problem}$, span $[25,27]$) has the same span as $G_5$ (type $\\text{Test}$, span $[25,27]$), but the type is different ($\\text{Problem}$ vs. $\\text{Test}$). Not a strict match.\n\nBased on this analysis for strict matching:\n- The number of True Positives is $TP_{\\text{strict}} = 1$ (from the match between $P_1$ and $G_1$).\n- The total number of predictions is $N_P = 9$. The number of False Positives is the count of predicted entities that are not TPs: $FP_{\\text{strict}} = N_P - TP_{\\text{strict}} = 9 - 1 = 8$.\n- The total number of gold entities is $N_G = 6$. The number of False Negatives is the count of gold entities that are not matched: $FN_{\\text{strict}} = N_G - TP_{\\text{strict}} = 6 - 1 = 5$.\n\nNow we can compute the strict precision, recall, and $F1$ score:\n$P_{\\text{strict}} = \\frac{TP_{\\text{strict}}}{TP_{\\text{strict}} + FP_{\\text{strict}}} = \\frac{1}{1+8} = \\frac{1}{9}$\n$R_{\\text{strict}} = \\frac{TP_{\\text{strict}}}{TP_{\\text{strict}} + FN_{\\text{strict}}} = \\frac{1}{1+5} = \\frac{1}{6}$\n$F1_{\\text{strict}} = \\frac{2 P_{\\text{strict}} R_{\\text{strict}}}{P_{\\text{strict}} + R_{\\text{strict}}} = \\frac{2 \\cdot \\frac{1}{9} \\cdot \\frac{1}{6}}{\\frac{1}{9} + \\frac{1}{6}} = \\frac{\\frac{2}{54}}{\\frac{2+3}{18}} = \\frac{\\frac{1}{27}}{\\frac{5}{18}} = \\frac{1}{27} \\cdot \\frac{18}{5} = \\frac{2}{15}$\n\nNext, we analyze the performance under the **relaxed matching** regime. A match occurs if the entity types are identical and their spans overlap by at least one token. The matching is one-to-one and is chosen to maximize the number of TPs.\n\nWe identify all potential matches based on type agreement and span overlap. A span $[a, b]$ overlaps with $[c, d]$ if $\\max(a, c) \\le \\min(b, d)$.\n- $P_1$ (Problem, $[5,7]$) and $G_1$ (Problem, $[5,7]$): Types match, spans overlap. Potential match $(P_1, G_1)$.\n- $P_2$ (Test, $[10,12]$) and $G_2$ (Test, $[10,11]$): Types match, spans overlap. Potential match $(P_2, G_2)$.\n- $P_3$ (Treatment, $[14,15]$) and $G_3$ (Treatment, $[15,15]$): Types match, spans overlap. Potential match $(P_3, G_3)$.\n- $P_4$ (Problem, $[20,22]$) and $G_4$ (Problem, $[20,21]$): Types match, spans overlap. Potential match $(P_4, G_4)$.\n- $P_5$ (Test, $[25,26]$) and $G_5$ (Test, $[25,27]$): Types match, spans overlap. Potential match $(P_5, G_5)$.\n- $P_6$ (Treatment, $[31,32]$) and $G_6$ (Treatment, $[30,32]$): Types match, spans overlap. Potential match $(P_6, G_6)$.\n- $P_7$ (Problem, $[2,3]$): No overlapping gold entity. No match.\n- $P_8$ (Test, $[40,41]$): No overlapping gold entity. No match.\n- $P_9$ (Problem, $[25,27]$) and $G_5$ (Test, $[25,27]$): Spans overlap, but types differ. No match.\n\nThe potential matches are $(P_1, G_1)$, $(P_2, G_2)$, $(P_3, G_3)$, $(P_4, G_4)$, $(P_5, G_5)$, and $(P_6, G_6)$. Each involves a unique predicted entity and a unique gold entity, so there are no conflicts. To maximize the number of TPs, we accept all $6$ of these matches.\n\nBased on this analysis for relaxed matching:\n- The number of True Positives is $TP_{\\text{relaxed}} = 6$.\n- The number of False Positives is $FP_{\\text{relaxed}} = N_P - TP_{\\text{relaxed}} = 9 - 6 = 3$. The FPs are $P_7$, $P_8$, and $P_9$.\n- The number of False Negatives is $FN_{\\text{relaxed}} = N_G - TP_{\\text{relaxed}} = 6 - 6 = 0$.\n\nNow we compute the relaxed precision, recall, and $F1$ score:\n$P_{\\text{relaxed}} = \\frac{TP_{\\text{relaxed}}}{TP_{\\text{relaxed}} + FP_{\\text{relaxed}}} = \\frac{6}{6+3} = \\frac{6}{9} = \\frac{2}{3}$\n$R_{\\text{relaxed}} = \\frac{TP_{\\text{relaxed}}}{TP_{\\text{relaxed}} + FN_{\\text{relaxed}}} = \\frac{6}{6+0} = 1$\n$F1_{\\text{relaxed}} = \\frac{2 P_{\\text{relaxed}} R_{\\text{relaxed}}}{P_{\\text{relaxed}} + R_{\\text{relaxed}}} = \\frac{2 \\cdot \\frac{2}{3} \\cdot 1}{\\frac{2}{3} + 1} = \\frac{\\frac{4}{3}}{\\frac{5}{3}} = \\frac{4}{5}$\n\nFinally, we compute the difference $\\Delta = F1_{\\text{relaxed}} - F1_{\\text{strict}}$:\n$\\Delta = \\frac{4}{5} - \\frac{2}{15} = \\frac{12}{15} - \\frac{2}{15} = \\frac{10}{15}$\nReducing the fraction gives:\n$\\Delta = \\frac{2}{3}$\n\nThe principal reason for the substantial discrepancy between the strict and relaxed $F1$ scores lies in how they evaluate boundary detection versus type agreement. The strict score $F1_{\\text{strict}} = \\frac{2}{15}$ is very low because it penalizes any inaccuracy in boundary detection. In this problem, $5$ out of the $6$ correctly typed predictions ($P_2, P_3, P_4, P_5, P_6$) had minor boundary errors. The strict metric treats each of these as a complete failure, contributing to both a false positive and a false negative, drastically reducing the TP count to $1$. In contrast, the relaxed metric is designed to forgive such boundary inaccuracies. As long as the entity type is correct and the spans overlap, it counts the prediction as a success. This is why the TP count for the relaxed metric, $TP_{\\text{relaxed}}$, rises to $6$, leading to a much higher recall ($R_{\\text{relaxed}}=1$) and precision ($P_{\\text{relaxed}}=\\frac{2}{3}$), and consequently a high $F1_{\\text{relaxed}}$ score of $\\frac{4}{5}$. The discrepancy is therefore almost entirely attributable to the strict metric's intolerance for imperfect boundary detection, a task where models often produce near-misses that the relaxed metric correctly credits. Type agreement is a necessary condition for both regimes, as shown by $P_9$ being an FP in both cases.", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "4849523"}]}