{"hands_on_practices": [{"introduction": "Real-world research often involves combining data from different healthcare systems, each with its own way of structuring information. To make sense of this, data must be transformed from source formats like Fast Healthcare Interoperability Resources (FHIR) into a standardized structure like the Observational Medical Outcomes Partnership (OMOP) Common Data Model. A critical part of this Extract-Transform-Load (ETL) process involves checking for missing essential attributes, such as patient identifiers or valid event dates, which can render a record unusable for research. This practice provides hands-on experience with the logic of an ETL pipeline, where you will evaluate the quality of a data transformation by quantifying the proportion of records that cannot be mapped, a crucial first step in any RWE study ([@problem_id:4862815]).", "problem": "You are given an Electronic Health Record (EHR) Extract-Transform-Load (ETL) design task grounded in two widely used standards: Fast Healthcare Interoperability Resources (FHIR) and the Observational Medical Outcomes Partnership (OMOP) Common Data Model. Starting from core definitions, you must specify deterministic mapping logic to populate OMOP Condition Occurrence and Drug Exposure records from FHIR Observation and MedicationRequest resources, respectively, and then compute a quality metric: the proportion of source resources that are unmapped due to missing required attributes. Your solution must be a complete, runnable program that follows the rules below and returns the required numeric results for a test suite.\n\nFoundational base and definitions:\n- Electronic Health Record (EHR) data contain clinical events structured as resources in Fast Healthcare Interoperability Resources (FHIR), including Patient, Encounter, Observation, and MedicationRequest.\n- The OMOP Common Data Model (OMOP CDM) defines tables for standardized analytics, including Condition Occurrence and Drug Exposure.\n- For Condition Occurrence, the required fields are person identifier, condition concept identifier, and condition start date. Denote person identifier by $p$, condition concept identifier by $c$, and condition start date by $d_c$.\n- For Drug Exposure, the required fields are person identifier, drug concept identifier, and drug exposure start date. Denote person identifier by $p$, drug concept identifier by $g$, and drug start date by $d_g$.\n- Required attributes for mapping from FHIR:\n  - For Condition Occurrence derived from an Observation resource $o$: the resource must contain a subject reference, a code element, and an index date derivable as follows. Define the index date $d_c$ as:\n    - If $o$ has an effectiveDateTime, set $d_c$ to that date.\n    - Else, if $o$ references an Encounter that has a start date, set $d_c$ to that encounter start date.\n    - Else, $d_c$ is undefined.\n  - For Drug Exposure derived from a MedicationRequest resource $m$: the resource must contain a subject reference, a medication code element, and an index date derivable as follows. Define the index date $d_g$ as:\n    - If $m$ has an authoredOn date, set $d_g$ to that date.\n    - Else, if $m$ references an Encounter that has a start date, set $d_g$ to that encounter start date.\n    - Else, $d_g$ is undefined.\n- Vocabulary and crosswalk mappings (code-to-concept and patient-identifier mappings) are part of transform logic but are not considered “missing required attributes.” A resource fails “due to missing required attributes” only if the resource or its referenced Encounter lacks subject, code, or a derivable index date according to the above rules. The absence of a code-to-concept mapping or a subject-to-person mapping does not count toward this missing-attribute failure metric.\n\nTarget metric:\n- For a set of Observation resources $O$, define $N_O$ as the total number of Observation resources in the set. Define $U_O$ as the number of Observation resources that fail mapping due to missing required attributes according to the above definition. The unmapped proportion for conditions is $P_O = U_O / N_O$ if $N_O \\gt 0$, else $P_O = 0$.\n- For a set of MedicationRequest resources $M$, define $N_M$ as the total number of MedicationRequest resources in the set. Define $U_M$ as the number of MedicationRequest resources that fail mapping due to missing required attributes according to the above definition. The unmapped proportion for drug exposures is $P_M = U_M / N_M$ if $N_M \\gt 0$, else $P_M = 0$.\n- All dates are to be treated as ISO $8601$ strings, but only their presence or absence matters for this problem. Angles are not involved. No physical units are involved.\n\nIndex date derivation detail:\n- For condition index dates $d_c$, use Observation.effectiveDateTime if present; otherwise, use Encounter.period.start of the referenced Encounter if present; otherwise, $d_c$ is undefined.\n- For drug exposure index dates $d_g$, use MedicationRequest.authoredOn if present; otherwise, use Encounter.period.start of the referenced Encounter if present; otherwise, $d_g$ is undefined.\n\nMapping presence:\n- A code-to-concept map for conditions exists that maps the Observation.code text \"COND_A\" to a valid OMOP condition concept identifier. Any other Observation code (e.g., \"UNKNOWN\") has no mapping but does not count as a missing-attribute failure.\n- A code-to-concept map for drugs exists that maps the MedicationRequest.medicationCodeableConcept text \"DRUG_A\" to a valid OMOP drug concept identifier. Any other MedicationRequest code (e.g., \"UNKNOWN\") has no mapping but does not count as a missing-attribute failure.\n- A patient crosswalk exists that maps certain FHIR Patient identifiers such as \"p1\" and \"p2\" to internal person identifiers. The lack of a crosswalk entry does not count as a missing-attribute failure.\n\nYour task:\n- Implement the ETL logic to:\n  - Determine for each Observation whether it has missing required attributes per the above rules and, if not missing, derive its condition index date $d_c$.\n  - Determine for each MedicationRequest whether it has missing required attributes per the above rules and, if not missing, derive its drug exposure index date $d_g$.\n  - Compute the unmapped proportions $P_O$ and $P_M$ for each test case.\n\nTest suite:\nProvide a program that computes $P_O$ and $P_M$ for each of the following three test cases. For each test case, the transform must use the same rules, and the final output must be a flat list of floating-point numbers representing the condition then drug unmapped proportions for each case, in order, rounded to $4$ decimal places.\n\n- Test case A (mixed, includes missing attributes and unknown vocabulary codes):\n  - Patients: mapping for \"p1\" and \"p2\" exists (to any integers).\n  - Encounters:\n    - \"e1\" has a start date present.\n  - Observation-to-condition code map: \"COND_A\" is mapped; any other code (e.g., \"UNKNOWN\") is unmapped but does not count as missing-attribute failure.\n  - Medication-to-drug code map: \"DRUG_A\" is mapped; any other code (e.g., \"UNKNOWN\") is unmapped but does not count as missing-attribute failure.\n  - Observations (total $5$):\n    - o1: subject \"p1\", code \"COND_A\", effectiveDateTime present.\n    - o2: subject \"p1\", code \"COND_A\", effectiveDateTime missing, encounter \"e1\" present.\n    - o3: subject \"p2\", code \"UNKNOWN\", effectiveDateTime present.\n    - o4: subject missing, code \"COND_A\", effectiveDateTime present.\n    - o5: subject \"p1\", code \"COND_A\", both effectiveDateTime and encounter reference missing.\n  - MedicationRequests (total $5$):\n    - m1: subject \"p1\", code \"DRUG_A\", authoredOn present.\n    - m2: subject \"p2\", code \"DRUG_A\", authoredOn missing, encounter \"e1\" present.\n    - m3: subject \"p2\", code \"UNKNOWN\", authoredOn present.\n    - m4: subject missing, code \"DRUG_A\", authoredOn present.\n    - m5: subject \"p1\", code \"DRUG_A\", both authoredOn and encounter reference missing.\n\n- Test case B (edge: no Observations; all MedicationRequests fail due to missing attributes):\n  - Patients: mapping for \"p1\" exists (to any integer).\n  - Encounters: none with usable start dates.\n  - Observations: none (total $0$).\n  - MedicationRequests (total $2$):\n    - m1: subject missing, code \"DRUG_A\", authoredOn present.\n    - m2: subject \"p1\", code \"DRUG_A\", both authoredOn and encounter reference missing.\n\n- Test case C (happy path: all attributes present and derivable):\n  - Patients: mapping for \"p1\" and \"p2\" exists (to any integers).\n  - Encounters:\n    - \"e1\" has a start date present.\n    - \"e2\" has a start date present.\n  - Observations (total $2$):\n    - o1: subject \"p1\", code \"COND_A\", effectiveDateTime present.\n    - o2: subject \"p2\", code \"COND_A\", effectiveDateTime missing, encounter \"e2\" present.\n  - MedicationRequests (total $2$):\n    - m1: subject \"p1\", code \"DRUG_A\", authoredOn present.\n    - m2: subject \"p2\", code \"DRUG_A\", authoredOn missing, encounter \"e1\" present.\n\nComputation and output requirements:\n- For each test case, compute $P_O$ and $P_M$ as defined above.\n- If the denominator $N_O$ or $N_M$ equals $0$, define the corresponding proportion as $0$.\n- Round each proportion to $4$ decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order: $[P_O^{(A)}, P_M^{(A)}, P_O^{(B)}, P_M^{(B)}, P_O^{(C)}, P_M^{(C)}]$, for the three test cases A, B, C respectively, with no spaces, and each value rounded to $4$ decimal places as specified.", "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the domain of medical informatics, specifically regarding data transformation between the FHIR and OMOP standards. The problem is well-posed, self-contained, and provides unambiguous, deterministic rules for its resolution. The provided test cases are complete and consistent with the defined logic.\n\nThe objective is to compute a data quality metric—the proportion of source records that are unmappable due to missing required attributes—for an Extract-Transform-Load (ETL) process. This process transforms data from FHIR `Observation` and `MedicationRequest` resources into the OMOP Common Data Model's `Condition Occurrence` and `Drug Exposure` tables, respectively.\n\nFirst, we formalize the validation logic for each resource type based on the problem's definitions.\n\nA FHIR `Observation` resource, denoted by $o$, is considered successfully mappable if and only if it satisfies three conditions:\n$1$. The resource must have a subject reference (i.e., `subject` is not missing).\n$2$. The resource must have a code element (i.e., `code` is not missing).\n$3$. The resource must have a derivable index date, $d_c$. The date $d_c$ is derivable if the `effectiveDateTime` field is present within $o$, or, if it is absent, $o$ contains a reference to an `Encounter` resource that has a `start` date.\n\nA FHIR `MedicationRequest` resource, denoted by $m$, is considered successfully mappable if and only if it meets an analogous set of three conditions:\n$1$. The resource must have a subject reference (`subject` is not missing).\n$2$. The resource must have a medication code element (`code` is not missing).\n$3$. The resource must have a derivable index date, $d_g$. The date $d_g$ is derivable if the `authoredOn` field is present within $m$, or, if it is absent, $m$ contains a reference to an `Encounter` resource that has a `start` date.\n\nIt is crucial to note that failures in downstream mapping, such as the inability to find a corresponding concept identifier for a given code (e.g., \"UNKNOWN\") or the lack of a patient identifier crosswalk entry, do not contribute to the count of unmapped records for this specific quality metric. A record is unmapped *due to missing required attributes* only if one of the three conditions above (subject, code, or derivable date) is not met for the respective resource type.\n\nThe target metrics are the unmapped proportions for observations, $P_O$, and medication requests, $P_M$. These are defined as:\n$$P_O = \\frac{U_O}{N_O} \\quad \\text{if } N_O > 0, \\text{ else } P_O = 0$$\n$$P_M = \\frac{U_M}{N_M} \\quad \\text{if } N_M > 0, \\text{ else } P_M = 0$$\nwhere $N_O$ and $N_M$ are the total counts of `Observation` and `MedicationRequest` resources, respectively, and $U_O$ and $U_M$ are the counts of those resources that fail the validation logic described above.\n\nWe will now apply this logic to each of the three test cases provided.\n\n**Test Case A:**\n- **Encounters:** `e1` has a start date.\n- **Observations ($N_O = 5$):**\n  - `o1`: Has subject, code, and `effectiveDateTime`. Valid.\n  - `o2`: Has subject, code. `effectiveDateTime` is missing, but references encounter `e1`, which has a date. Valid.\n  - `o3`: Has subject, code, and `effectiveDateTime`. Valid. The code \"UNKNOWN\" does not cause a failure for this metric.\n  - `o4`: `subject` is missing. Invalid.\n  - `o5`: Has subject, code. `effectiveDateTime` is missing and no valid encounter reference exists. The index date is not derivable. Invalid.\n- Unmapped Observations: $U_O = 2$ (`o4`, `o5`).\n- Proportion: $P_O = U_O / N_O = 2 / 5 = 0.4$.\n\n- **MedicationRequests ($N_M = 5$):**\n  - `m1`: Has subject, code, and `authoredOn`. Valid.\n  - `m2`: Has subject, code. `authoredOn` is missing, but references encounter `e1`, which has a date. Valid.\n  - `m3`: Has subject, code, and `authoredOn`. Valid. The code \"UNKNOWN\" does not cause a failure.\n  - `m4`: `subject` is missing. Invalid.\n  - `m5`: Has subject, code. `authoredOn` is missing and no valid encounter reference exists. The index date is not derivable. Invalid.\n- Unmapped MedicationRequests: $U_M = 2$ (`m4`, `m5`).\n- Proportion: $P_M = U_M / N_M = 2 / 5 = 0.4$.\n\n**Test Case B:**\n- **Encounters:** No encounters have usable start dates.\n- **Observations ($N_O = 0$):**\n- Unmapped Observations: $U_O = 0$.\n- Proportion: $P_O = 0$ (since $N_O = 0$).\n\n- **MedicationRequests ($N_M = 2$):**\n  - `m1`: `subject` is missing. Invalid.\n  - `m2`: Has subject, code. `authoredOn` is missing, and there are no encounters with start dates to fall back on. The index date is not derivable. Invalid.\n- Unmapped MedicationRequests: $U_M = 2$ (`m1`, `m2`).\n- Proportion: $P_M = U_M / N_M = 2 / 2 = 1.0$.\n\n**Test Case C:**\n- **Encounters:** `e1` and `e2` have start dates.\n- **Observations ($N_O = 2$):**\n  - `o1`: Has subject, code, and `effectiveDateTime`. Valid.\n  - `o2`: Has subject, code. `effectiveDateTime` is missing, but references encounter `e2`, which has a date. Valid.\n- Unmapped Observations: $U_O = 0$.\n- Proportion: $P_O = U_O / N_O = 0 / 2 = 0.0$.\n\n- **MedicationRequests ($N_M = 2$):**\n  - `m1`: Has subject, code, and `authoredOn`. Valid.\n  - `m2`: Has subject, code. `authoredOn` is missing, but references encounter `e1`, which has a date. Valid.\n- Unmapped MedicationRequests: $U_M = 0$.\n- Proportion: $P_M = U_M / N_M = 0 / 2 = 0.0$.\n\nThe final results, rounded to $4$ decimal places, are:\n- Case A: $P_O = 0.4000$, $P_M = 0.4000$\n- Case B: $P_O = 0.0000$, $P_M = 1.0000$\n- Case C: $P_O = 0.0000$, $P_M = 0.0000$\n\nThese will be computed and formatted by the program in the `<final_answer>` section.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run ETL validation logic,\n    and print the formatted results.\n    \"\"\"\n    \n    # Test cases are structured to represent FHIR-like resources and encounter data.\n    # Missing attributes are represented by `None`. Any non-None string for dates \n    # or codes is considered present.\n    test_cases = [\n        # Test Case A\n        {\n            \"encounters\": {\"e1\": True},  # Encounter ID -> has_start_date\n            \"observations\": [\n                {\"subject\": \"p1\", \"code\": \"COND_A\", \"effectiveDateTime\": \"date1\", \"encounter\": None},\n                {\"subject\": \"p1\", \"code\": \"COND_A\", \"effectiveDateTime\": None, \"encounter\": \"e1\"},\n                {\"subject\": \"p2\", \"code\": \"UNKNOWN\", \"effectiveDateTime\": \"date3\", \"encounter\": None},\n                {\"subject\": None, \"code\": \"COND_A\", \"effectiveDateTime\": \"date4\", \"encounter\": None},\n                {\"subject\": \"p1\", \"code\": \"COND_A\", \"effectiveDateTime\": None, \"encounter\": None},\n            ],\n            \"medication_requests\": [\n                {\"subject\": \"p1\", \"code\": \"DRUG_A\", \"authoredOn\": \"date1\", \"encounter\": None},\n                {\"subject\": \"p2\", \"code\": \"DRUG_A\", \"authoredOn\": None, \"encounter\": \"e1\"},\n                {\"subject\": \"p2\", \"code\": \"UNKNOWN\", \"authoredOn\": \"date3\", \"encounter\": None},\n                {\"subject\": None, \"code\": \"DRUG_A\", \"authoredOn\": \"date4\", \"encounter\": None},\n                {\"subject\": \"p1\", \"code\": \"DRUG_A\", \"authoredOn\": None, \"encounter\": None},\n            ],\n        },\n        # Test Case B\n        {\n            \"encounters\": {},\n            \"observations\": [],\n            \"medication_requests\": [\n                {\"subject\": None, \"code\": \"DRUG_A\", \"authoredOn\": \"date1\", \"encounter\": None},\n                {\"subject\": \"p1\", \"code\": \"DRUG_A\", \"authoredOn\": None, \"encounter\": None},\n            ],\n        },\n        # Test Case C\n        {\n            \"encounters\": {\"e1\": True, \"e2\": True},\n            \"observations\": [\n                {\"subject\": \"p1\", \"code\": \"COND_A\", \"effectiveDateTime\": \"date1\", \"encounter\": None},\n                {\"subject\": \"p2\", \"code\": \"COND_A\", \"effectiveDateTime\": None, \"encounter\": \"e2\"},\n            ],\n            \"medication_requests\": [\n                {\"subject\": \"p1\", \"code\": \"DRUG_A\", \"authoredOn\": \"date1\", \"encounter\": None},\n                {\"subject\": \"p2\", \"code\": \"DRUG_A\", \"authoredOn\": None, \"encounter\": \"e1\"},\n            ],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        p_o, p_m = calculate_proportions(case)\n        results.extend([p_o, p_m])\n    \n    # Format the final list as specified, with 4 decimal places.\n    formatted_results = [f\"{r:.4f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef is_observation_valid(obs, encounters):\n    \"\"\"\n    Checks if an Observation resource has all required attributes for mapping.\n    \n    Args:\n        obs (dict): The Observation resource.\n        encounters (dict): A dictionary of encounters and their date status.\n        \n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    # 1. Check for subject\n    if obs.get(\"subject\") is None:\n        return False\n        \n    # 2. Check for code\n    if obs.get(\"code\") is None:\n        return False\n        \n    # 3. Check for derivable index date\n    has_primary_date = obs.get(\"effectiveDateTime\") is not None\n    \n    encounter_ref = obs.get(\"encounter\")\n    has_fallback_date = (\n        encounter_ref is not None and \n        encounters.get(encounter_ref, False)\n    )\n    \n    if not has_primary_date and not has_fallback_date:\n        return False\n        \n    return True\n\ndef is_med_request_valid(med, encounters):\n    \"\"\"\n    Checks if a MedicationRequest resource has all required attributes for mapping.\n    \n    Args:\n        med (dict): The MedicationRequest resource.\n        encounters (dict): A dictionary of encounters and their date status.\n        \n    Returns:\n        bool: True if valid, False otherwise.\n    \"\"\"\n    # 1. Check for subject\n    if med.get(\"subject\") is None:\n        return False\n        \n    # 2. Check for code\n    if med.get(\"code\") is None:\n        return False\n        \n    # 3. Check for derivable index date\n    has_primary_date = med.get(\"authoredOn\") is not None\n    \n    encounter_ref = med.get(\"encounter\")\n    has_fallback_date = (\n        encounter_ref is not None and \n        encounters.get(encounter_ref, False)\n    )\n    \n    if not has_primary_date and not has_fallback_date:\n        return False\n        \n    return True\n\ndef calculate_proportions(case_data):\n    \"\"\"\n    Calculates the unmapped proportions P_O and P_M for a single test case.\n    \n    Args:\n        case_data (dict): The data for one test case.\n        \n    Returns:\n        tuple: A tuple containing (P_O, P_M).\n    \"\"\"\n    observations = case_data[\"observations\"]\n    med_requests = case_data[\"medication_requests\"]\n    encounters = case_data[\"encounters\"]\n    \n    # Calculate for Observations\n    n_o = len(observations)\n    if n_o == 0:\n        p_o = 0.0\n    else:\n        u_o = sum(1 for obs in observations if not is_observation_valid(obs, encounters))\n        p_o = u_o / n_o\n        \n    # Calculate for MedicationRequests\n    n_m = len(med_requests)\n    if n_m == 0:\n        p_m = 0.0\n    else:\n        u_m = sum(1 for med in med_requests if not is_med_request_valid(med, encounters))\n        p_m = u_m / n_m\n        \n    return p_o, p_m\n\nsolve()\n\n```", "id": "4862815"}, {"introduction": "Once data is in a standardized database, researchers must identify patients with specific diseases or traits—a process called \"phenotyping.\" While structured data like billing codes are useful, much of the detailed clinical story is buried in unstructured text from physician notes. This exercise introduces how Natural Language Processing (NLP) can be used to create a phenotyping algorithm, moving beyond simple keyword searches to distinguish affirmed diagnoses from negated ones (e.g., \"pneumonia\" vs. \"no evidence of pneumonia\") within a relevant time frame. By building and evaluating a rule-based model ([@problem_id:4862788]), you will learn to measure its accuracy using standard metrics like sensitivity and Positive Predictive Value (PPV), a core skill for building reliable study cohorts from EHR data.", "problem": "You are given a text-processing and evaluation task grounded in Electronic Health Record (EHR) data for generating real-world evidence. The task is to implement a case-insensitive Natural Language Processing (NLP) rule to extract affirmed diagnoses of pneumonia from dated clinical notes and then compute sensitivity and Positive Predictive Value (PPV) of the extraction against chart-validated labels. Your program must be a complete, runnable program. The task is to be framed and solved in purely mathematical and logical terms without relying on any external data sources.\n\nFundamental base and core definitions: Clinical text mining can be modeled as a binary classification problem over patients, where a patient is predicted positive if an affirmed mention is present and predicted negative otherwise. Using the standard diagnostic test framework, sensitivity and Positive Predictive Value (PPV) are defined via the confusion matrix quantities true positives, false negatives, and false positives. Dates are used to restrict mentions to a clinically relevant observation window around a patient-specific index date.\n\nAffirmed mention rule: For a given note, split the note into sentences where a sentence is delimited by period, semicolon, or newline. A sentence affirms pneumonia if it contains the substring \"pneumonia\" and does not contain the substring \"no evidence of\"; both checks must be case-insensitive. A note affirms pneumonia if any of its sentences affirms pneumonia. A patient is predicted positive if any note dated within an inclusive window of $\\pm W$ days around the patient’s index date contains an affirmed mention according to the sentence rule.\n\nEvaluation quantities: For a set of patients, let $TP$ be the number of true positives, $FN$ the number of false negatives, and $FP$ the number of false positives, determined by comparing the program’s predicted patient-level labels to the chart-validated labels. Using standard definitions from diagnostic test evaluation, sensitivity and Positive Predictive Value (PPV) are to be computed as decimals. In edge cases where denominators would be $0$ (for example, no chart-validated positives or no predicted positives), define the corresponding metric to be $0.0$.\n\nYour program must implement the above rules and compute the metrics for the following test suite. In each test case, each patient has an index date, a binary chart-validated label, and a list of dated notes. A date is a string in ISO format \"YYYY-MM-DD\". The window size $W$ is supplied per test case and is in days.\n\nTest Suite:\nTest Case $1$ with window size $W = 30$:\n- Patient \"A\": index date $2021$-$03$-$15$, chart-validated label $1$. Notes: ($2021$-$03$-$10$, \"Patient with pneumonia, started antibiotics.\"), ($2021$-$02$-$01$, \"No evidence of pneumonia.\")\n- Patient \"B\": index date $2021$-$03$-$20$, chart-validated label $0$. Notes: ($2021$-$03$-$19$, \"CXR shows no evidence of pneumonia.\"), ($2021$-$03$-$01$, \"Follow-up visit.\")\n- Patient \"C\": index date $2021$-$03$-$25$, chart-validated label $1$. Notes: ($2021$-$03$-$26$, \"Pneumonia suspected.\")\n- Patient \"D\": index date $2021$-$03$-$05$, chart-validated label $0$. Notes: ($2021$-$04$-$10$, \"No evidence of pneumonia.\"), ($2021$-$03$-$04$, \"No fever.\")\n\nTest Case $2$ with window size $W = 14$:\n- Patient \"E\": index date $2020$-$11$-$01$, chart-validated label $1$. Notes: ($2020$-$11$-$02$, \"No evidence of pneumonia.\")\n- Patient \"F\": index date $2020$-$11$-$01$, chart-validated label $0$. Notes: ($2020$-$11$-$03$, \"No evidence of pneumonia on CT.\")\n- Patient \"G\": index date $2020$-$11$-$10$, chart-validated label $1$. Notes: ($2020$-$10$-$01$, \"Pneumonia confirmed.\")\n\nTest Case $3$ with window size $W = 7$:\n- Patient \"H\": index date $2022$-$01$-$15$, chart-validated label $1$. Notes: ($2022$-$01$-$15$, \"No evidence of pneumonia. However, later that day, pneumonia developed.\")\n- Patient \"I\": index date $2022$-$01$-$15$, chart-validated label $0$. Notes: ($2022$-$01$-$16$, \"No evidence of pneumonia; monitoring ongoing.\")\n- Patient \"J\": index date $2022$-$01$-$10$, chart-validated label $1$. Notes: ($2022$-$01$-$18$, \"Pneumonia.\")\n\nTest Case $4$ with window size $W = 90$:\n- Patient \"K\": index date $2019$-$05$-$01$, chart-validated label $0$. Notes: ($2019$-$04$-$01$, \"pNeUmOnIa noted in past.\")\n- Patient \"L\": index date $2019$-$05$-$01$, chart-validated label $1$. Notes: ($2019$-$05$-$20$, \"No evidence of severe pneumonia?\"), ($2019$-$05$-$21$, \"possible pneumonia vs bronchitis\")\n- Patient \"M\": index date $2019$-$05$-$01$, chart-validated label $1$. Notes: ($2019$-$01$-$01$, \"Pneumonia.\")\n- Patient \"N\": index date $2019$-$05$-$01$, chart-validated label $0$. Notes: ($2019$-$05$-$02$, \"No evidence of pneumonia.\")\n\nYour program must:\n- Implement the case-insensitive sentence-level affirmed mention rule as specified.\n- For each test case, predict patient-level labels based on notes within the specified window around the index date.\n- Compute sensitivity and PPV as decimals for each test case, applying the $0.0$ rule for zero denominators.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the results are ordered by test case and within each test case by sensitivity followed by PPV. Express each metric as a decimal rounded to $4$ decimal places. For example, if there are $4$ test cases, the output format must be \"[sens_1,ppv_1,sens_2,ppv_2,sens_3,ppv_3,sens_4,ppv_4]\".", "solution": "The problem requires the implementation and evaluation of a rule-based Natural Language Processing (NLP) system for detecting affirmed diagnoses of pneumonia from clinical notes. The evaluation is to be conducted using the standard metrics of sensitivity and Positive Predictive Value (PPV). The problem is well-defined, scientifically grounded in the principles of clinical informatics and diagnostic test evaluation, and provides all necessary data and rules for a unique, verifiable solution.\n\nThe solution can be constructed by formalizing a sequence of logical operations, which we will apply to each patient in the provided test suite.\n\nThe core of the problem is a binary classification task. For each patient, we predict a label, $y_{pred} \\in \\{0, 1\\}$, where $y_{pred}=1$ signifies a predicted pneumonia diagnosis and $y_{pred}=0$ signifies its absence. This prediction is then compared to a ground-truth, chart-validated label, $y_{true} \\in \\{0, 1\\}$.\n\nThe components of the algorithmic solution are as follows:\n\n1.  **Date and Window Logic**: A clinical note is considered relevant only if its date, $d_{note}$, falls within an inclusive window of $\\pm W$ days around a patient's index date, $d_{index}$. Mathematically, this condition is expressed as:\n    $$ |d_{note} - d_{index}| \\le W $$\n    where the date difference is measured in days. Dates are provided in \"YYYY-MM-DD\" format and must be parsed into a date object capable of arithmetic.\n\n2.  **Sentence-Level Affirmation Rule**: A single sentence is deemed to affirm pneumonia if it satisfies two conditions simultaneously. Let $s$ be a sentence. Let $s_{lower}$ be the lowercase version of $s$. The sentence affirms pneumonia if and only if:\n    $$ (\\text{\"pneumonia\"} \\in s_{lower}) \\land (\\text{\"no evidence of\"} \\notin s_{lower}) $$\n    Sentences within a note are delimited by a period (.), a semicolon (;), or a newline character (\n).\n\n3.  **Note-Level and Patient-Level Prediction**: A clinical note affirms pneumonia if at least one of its sentences affirms pneumonia. A patient is predicted to be positive ($y_{pred}=1$) if at least one of their relevant clinical notes (i.e., a note within the specified date window) affirms pneumonia. If no relevant note affirms pneumonia, the patient is predicted to be negative ($y_{pred}=0$).\n\n4.  **Evaluation Metrics**: The performance of the prediction algorithm is measured by comparing the set of predicted labels, $\\{y_{pred}\\}$, to the set of true labels, $\\{y_{true}\\}$. This comparison yields the counts of true positives ($TP$), false positives ($FP$), and false negatives ($FN$).\n    *   $TP$: The number of patients for whom $y_{true}=1$ and $y_{pred}=1$.\n    *   $FP$: The number of patients for whom $y_{true}=0$ and $y_{pred}=1$.\n    *   $FN$: The number of patients for whom $y_{true}=1$ and $y_{pred}=0$.\n\n    From these quantities, sensitivity and PPV are calculated:\n    $$ \\text{Sensitivity} = \\frac{TP}{TP + FN} $$\n    $$ \\text{Positive Predictive Value (PPV)} = \\frac{TP}{TP + FP} $$\n    As per the problem specification, if the denominator of either metric is $0$, the value of that metric is defined as $0.0$.\n\nWe now apply this formal procedure to each test case.\n\n**Test Case 1: Window Size $W = 30$ days**\n*   Patient A ($y_{true}=1$): Note from $2021-03-10$ is within the $30$-day window of index date $2021-03-15$. The note \"Patient with pneumonia...\" affirms pneumonia. Thus, $y_{pred}=1$. This is a True Positive ($TP$).\n*   Patient B ($y_{true}=0$): Note from $2021-03-19$ is within the window of index date $2021-03-20$. The sentence \"...no evidence of pneumonia\" contains the negation phrase and does not affirm pneumonia. Thus, $y_{pred}=0$. This is a True Negative ($TN$).\n*   Patient C ($y_{true}=1$): Note from $2021-03-26$ is a day after index date $2021-03-25$, within the window. \"Pneumonia suspected.\" affirms pneumonia. Thus, $y_{pred}=1$. This is a True Positive ($TP$).\n*   Patient D ($y_{true}=0$): Note from $2021-04-10$ is more than $30$ days after index date $2021-03-05$ and is ignored. Note from $2021-03-04$ is within the window but does not mention pneumonia. Thus, $y_{pred}=0$. This is a True Negative ($TN$).\n*   **Metrics**: $TP=2$, $FP=0$, $FN=0$. Total positives $TP+FN=2$. Predicted positives $TP+FP=2$.\n    *   Sensitivity = $2 / (2+0) = 1.0$.\n    *   PPV = $2 / (2+0) = 1.0$.\n\n**Test Case 2: Window Size $W = 14$ days**\n*   Patient E ($y_{true}=1$): Note from $2020-11-02$ is within the window of index date $2020-11-01$. \"No evidence of pneumonia.\" is negated. Thus, $y_{pred}=0$. This is a False Negative ($FN$).\n*   Patient F ($y_{true}=0$): Note from $2020-11-03$ is within the window of index date $2020-11-01$. \"No evidence of pneumonia on CT.\" is negated. Thus, $y_{pred}=0$. This is a True Negative ($TN$).\n*   Patient G ($y_{true}=1$): Note from $2020-10-01$ is outside the $14$-day window of index date $2020-11-10$ and is ignored. Thus, $y_{pred}=0$. This is a False Negative ($FN$).\n*   **Metrics**: $TP=0$, $FP=0$, $FN=2$. Total positives $TP+FN=2$. Predicted positives $TP+FP=0$.\n    *   Sensitivity = $0 / (0+2) = 0.0$.\n    *   PPV: Denominator $TP+FP=0$. By rule, PPV = $0.0$.\n\n**Test Case 3: Window Size $W = 7$ days**\n*   Patient H ($y_{true}=1$): Note from $2022-01-15$ is on the index date. The note text is \"No evidence of pneumonia. However, later that day, pneumonia developed.\". The first sentence is negated. The second sentence, \"However, ... pneumonia developed.\", affirms pneumonia. Since one sentence affirms, the note affirms. Thus, $y_{pred}=1$. This is a True Positive ($TP$).\n*   Patient I ($y_{true}=0$): Note from $2022-01-16$ is within the window of index date $2022-01-15$. The text \"No evidence of pneumonia; monitoring ongoing.\" contains a negated sentence and another without the keyword. The note does not affirm pneumonia. Thus, $y_{pred}=0$. This is a True Negative ($TN$).\n*   Patient J ($y_{true}=1$): Note from $2022-01-18$ is $8$ days after index date $2022-01-10$, which is outside the $7$-day window. The note is ignored. Thus, $y_{pred}=0$. This is a False Negative ($FN$).\n*   **Metrics**: $TP=1$, $FP=0$, $FN=1$. Total positives $TP+FN=2$. Predicted positives $TP+FP=1$.\n    *   Sensitivity = $1 / (1+1) = 0.5$.\n    *   PPV = $1 / (1+0) = 1.0$.\n\n**Test Case 4: Window Size $W = 90$ days**\n*   Patient K ($y_{true}=0$): Note from $2019-04-01$ is within the window of index date $2019-05-01$. The text \"pNeUmOnIa noted in past.\" affirms pneumonia (case-insensitive check). Thus, $y_{pred}=1$. This is a False Positive ($FP$).\n*   Patient L ($y_{true}=1$): Note from $2019-05-20$ contains a negated sentence. Note from $2019-05-21$ is also in the window and its text \"possible pneumonia vs bronchitis\" affirms pneumonia. Thus, $y_{pred}=1$. This is a True Positive ($TP$).\n*   Patient M ($y_{true}=1$): Note from $2019-01-01$ is outside the $90$-day window of index date $2019-05-01$ and is ignored. Thus, $y_{pred}=0$. This is a False Negative ($FN$).\n*   Patient N ($y_{true}=0$): Note from $2019-05-02$ is within the window. \"No evidence of pneumonia.\" is negated. Thus, $y_{pred}=0$. This is a True Negative ($TN$).\n*   **Metrics**: $TP=1$, $FP=1$, $FN=1$. Total positives $TP+FN=2$. Predicted positives $TP+FP=2$.\n    *   Sensitivity = $1 / (1+1) = 0.5$.\n    *   PPV = $1 / (1+1) = 0.5$.\n\nThe final results, rounded to $4$ decimal places, are compiled for the final output.", "answer": "```python\nimport numpy as np\nimport re\nfrom datetime import datetime, timedelta\n\ndef solve():\n    \"\"\"\n    Solves the pneumonia detection and evaluation task based on the provided rules and test suite.\n    \"\"\"\n    test_suite = [\n        {\n            \"W\": 30,\n            \"patients\": [\n                {\"id\": \"A\", \"index_date\": \"2021-03-15\", \"label\": 1, \"notes\": [(\"2021-03-10\", \"Patient with pneumonia, started antibiotics.\"), (\"2021-02-01\", \"No evidence of pneumonia.\")]},\n                {\"id\": \"B\", \"index_date\": \"2021-03-20\", \"label\": 0, \"notes\": [(\"2021-03-19\", \"CXR shows no evidence of pneumonia.\"), (\"2021-03-01\", \"Follow-up visit.\")]},\n                {\"id\": \"C\", \"index_date\": \"2021-03-25\", \"label\": 1, \"notes\": [(\"2021-03-26\", \"Pneumonia suspected.\")]},\n                {\"id\": \"D\", \"index_date\": \"2021-03-05\", \"label\": 0, \"notes\": [(\"2021-04-10\", \"No evidence of pneumonia.\"), (\"2021-03-04\", \"No fever.\")]}\n            ]\n        },\n        {\n            \"W\": 14,\n            \"patients\": [\n                {\"id\": \"E\", \"index_date\": \"2020-11-01\", \"label\": 1, \"notes\": [(\"2020-11-02\", \"No evidence of pneumonia.\")]},\n                {\"id\": \"F\", \"index_date\": \"2020-11-01\", \"label\": 0, \"notes\": [(\"2020-11-03\", \"No evidence of pneumonia on CT.\")]},\n                {\"id\": \"G\", \"index_date\": \"2020-11-10\", \"label\": 1, \"notes\": [(\"2020-10-01\", \"Pneumonia confirmed.\")]}\n            ]\n        },\n        {\n            \"W\": 7,\n            \"patients\": [\n                {\"id\": \"H\", \"index_date\": \"2022-01-15\", \"label\": 1, \"notes\": [(\"2022-01-15\", \"No evidence of pneumonia. However, later that day, pneumonia developed.\")]},\n                {\"id\": \"I\", \"index_date\": \"2022-01-15\", \"label\": 0, \"notes\": [(\"2022-01-16\", \"No evidence of pneumonia; monitoring ongoing.\")]},\n                {\"id\": \"J\", \"index_date\": \"2022-01-10\", \"label\": 1, \"notes\": [(\"2022-01-18\", \"Pneumonia.\")]}\n            ]\n        },\n        {\n            \"W\": 90,\n            \"patients\": [\n                {\"id\": \"K\", \"index_date\": \"2019-05-01\", \"label\": 0, \"notes\": [(\"2019-04-01\", \"pNeUmOnIa noted in past.\")]},\n                {\"id\": \"L\", \"index_date\": \"2019-05-01\", \"label\": 1, \"notes\": [(\"2019-05-20\", \"No evidence of severe pneumonia?\"), (\"2019-05-21\", \"possible pneumonia vs bronchitis\")]},\n                {\"id\": \"M\", \"index_date\": \"2019-05-01\", \"label\": 1, \"notes\": [(\"2019-01-01\", \"Pneumonia.\")]},\n                {\"id\": \"N\", \"index_date\": \"2019-05-01\", \"label\": 0, \"notes\": [(\"2019-05-02\", \"No evidence of pneumonia.\")]}\n            ]\n        }\n    ]\n\n    final_results = []\n\n    def sentence_affirms_pneumonia(sentence):\n        \"\"\"Checks if a single sentence affirms pneumonia.\"\"\"\n        s_lower = sentence.lower()\n        return \"pneumonia\" in s_lower and \"no evidence of\" not in s_lower\n\n    def note_affirms_pneumonia(note_text):\n        \"\"\"Checks if any sentence in a note affirms pneumonia.\"\"\"\n        sentences = re.split(r'[.;\\n]', note_text)\n        for sentence in sentences:\n            if sentence_affirms_pneumonia(sentence):\n                return True\n        return False\n\n    for test_case in test_suite:\n        W = test_case[\"W\"]\n        patients = test_case[\"patients\"]\n        \n        tp, fp, fn = 0, 0, 0\n\n        for patient in patients:\n            index_date = datetime.strptime(patient[\"index_date\"], \"%Y-%m-%d\")\n            true_label = patient[\"label\"]\n            \n            predicted_positive = False\n            for note_date_str, note_text in patient[\"notes\"]:\n                note_date = datetime.strptime(note_date_str, \"%Y-%m-%d\")\n                \n                # Check if the note is within the inclusive date window\n                if abs((note_date - index_date).days) <= W:\n                    if note_affirms_pneumonia(note_text):\n                        predicted_positive = True\n                        break # A single affirming note is sufficient\n            \n            pred_label = 1 if predicted_positive else 0\n\n            if true_label == 1 and pred_label == 1:\n                tp += 1\n            elif true_label == 0 and pred_label == 1:\n                fp += 1\n            elif true_label == 1 and pred_label == 0:\n                fn += 1\n\n        # Calculate metrics for the test case\n        total_positives = tp + fn\n        predicted_positives = tp + fp\n\n        sensitivity = 0.0\n        if total_positives > 0:\n            sensitivity = tp / total_positives\n\n        ppv = 0.0\n        if predicted_positives > 0:\n            ppv = tp / predicted_positives\n            \n        final_results.append(f\"{sensitivity:.4f}\")\n        final_results.append(f\"{ppv:.4f}\")\n\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```", "id": "4862788"}, {"introduction": "After preparing the data and defining a study cohort, the final step is analysis, but this stage has its own potential pitfalls. Observational data from EHRs can contain hidden biases that lead to incorrect conclusions if not addressed with careful methodology. This practice tackles a notorious analytical trap known as \"immortal time bias,\" which arises when analyzing treatments that start after a patient enters a study cohort, and can make an ineffective treatment appear beneficial. By comparing a flawed time-fixed analysis with a correct time-updated approach ([@problem_id:4862751]), you will gain a concrete understanding of how this bias occurs and why the correct handling of time-dependent exposures is essential for producing valid real-world evidence.", "problem": "You are given a cohort represented by Electronic Health Records (EHR) data, where each individual has a baseline time of $t=0$ months, a treatment initiation time $\\tau_i$ (which may be $\\infty$ if the individual never initiates treatment), a follow-up time $y_i$ measured from baseline to either the event or censoring in months, and a binary event indicator $\\delta_i \\in \\{0,1\\}$ where $\\delta_i=1$ denotes an event occurring at time $y_i$ and $\\delta_i=0$ denotes censoring at time $y_i$. Assume that, conditional on exposure state, the hazard within a group is approximately constant over time so that the empirical hazard in any exposure group $g \\in \\{0,1\\}$ can be estimated by $\\hat{h}_g = E_g / T_g$, where $E_g$ is the total number of observed events in group $g$ and $T_g$ is the total person-time in months accumulated by individuals while in group $g$. Define the hazard ratio as $\\widehat{HR} = \\hat{h}_1 / \\hat{h}_0$. You must compute $\\widehat{HR}$ twice: first under a time-fixed exposure definition, and second under a time-updated exposure definition, and then quantify the bias introduced by immortal time under the time-fixed exposure definition.\n\nThe time-fixed exposure definition classifies individuals based on whether they ever initiate treatment during follow-up. Specifically, for the time-fixed analysis, assign an individual to exposed group $g=1$ if $\\tau_i < \\infty$ and to unexposed group $g=0$ if $\\tau_i = \\infty$. For this time-fixed analysis, compute $T_1^{\\mathrm{fixed}}$ as the sum of $y_i$ over all individuals with $\\tau_i < \\infty$, and $T_0^{\\mathrm{fixed}}$ as the sum of $y_i$ over all individuals with $\\tau_i = \\infty$. Compute $E_1^{\\mathrm{fixed}}$ as the sum of $\\delta_i$ over all individuals with $\\tau_i < \\infty$, and $E_0^{\\mathrm{fixed}}$ as the sum of $\\delta_i$ over all individuals with $\\tau_i = \\infty$. The time-fixed hazard ratio is then $\\widehat{HR}_{\\mathrm{fixed}} = \\left(E_1^{\\mathrm{fixed}} / T_1^{\\mathrm{fixed}}\\right) \\big/ \\left(E_0^{\\mathrm{fixed}} / T_0^{\\mathrm{fixed}}\\right)$.\n\nThe time-updated exposure definition treats exposure as a time-dependent covariate. For an individual with finite $\\tau_i$, the unexposed person-time is the interval $[0, \\min(y_i,\\tau_i))$ and the exposed person-time is the interval $[\\tau_i, y_i)$ if $\\tau_i < y_i$. For an individual with $\\tau_i = \\infty$, all person-time $[0, y_i)$ is unexposed. Allocate events as occurring in the exposure state immediately preceding $y_i$; if $\\tau_i = y_i$, count the event as unexposed. Formally, compute $T_0^{\\mathrm{upd}}$ and $T_1^{\\mathrm{upd}}$ by summing the appropriate interval lengths in months as above across all individuals, and compute $E_0^{\\mathrm{upd}}$ and $E_1^{\\mathrm{upd}}$ by allocating events to the state active just before $y_i$ using the rule: if $\\delta_i=1$ and $y_i \\le \\tau_i$, increment $E_0^{\\mathrm{upd}}$ by $1$; if $\\delta_i=1$ and $y_i > \\tau_i$, increment $E_1^{\\mathrm{upd}}$ by $1$; if $\\delta_i=0$, do not increment any $E_g$. The time-updated hazard ratio is then $\\widehat{HR}_{\\mathrm{upd}} = \\left(E_1^{\\mathrm{upd}} / T_1^{\\mathrm{upd}}\\right) \\big/ \\left(E_0^{\\mathrm{upd}} / T_0^{\\mathrm{upd}}\\right)$.\n\nTo quantify immortal time bias, compute the relative bias as $b = \\left(\\widehat{HR}_{\\mathrm{fixed}} - \\widehat{HR}_{\\mathrm{upd}}\\right) / \\widehat{HR}_{\\mathrm{upd}}$, expressed as a decimal. All time quantities must be handled in months, and hazard ratios and bias are unitless. Your program must output each hazard ratio rounded to $3$ decimal places, and each bias rounded to $3$ decimal places.\n\nUse the following test suite of cohorts. Each cohort is a list of individuals given by tuples $(\\tau_i, y_i, \\delta_i)$, where all times are in months, $\\tau_i = \\infty$ denotes never treated, $y_i$ is the event or censoring time, and $\\delta_i \\in \\{0,1\\}$ is the event indicator.\n\nTest Case $1$ (happy path, mixed initiation times, some censoring):\n- Patients: $\\left[(2, 10, 1), (5, 12, 0), (\\infty, 8, 1), (0, 9, 1), (\\infty, 7, 0), (3, 6, 1)\\right]$.\n\nTest Case $2$ (late treatment initiation creating substantial immortal time, with events in both groups):\n- Patients: $\\left[(9, 12, 1), (10, 12, 0), (11, 14, 1), (\\infty, 6, 1), (\\infty, 12, 0)\\right]$.\n\nTest Case $3$ (event exactly at initiation boundary, immediate initiators, and never-treated individuals):\n- Patients: $\\left[(5, 5, 1), (0, 8, 0), (4, 9, 1), (\\infty, 7, 1), (\\infty, 10, 0)\\right]$.\n\nTest Case $4$ (early initiations and never-treated mix):\n- Patients: $\\left[(0, 4, 1), (1, 6, 0), (2, 3, 1), (\\infty, 5, 1), (\\infty, 6, 0)\\right]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, flattening the triplets [$\\widehat{HR}_{\\mathrm{fixed}}$, $\\widehat{HR}_{\\mathrm{upd}}$, $b$] for the $4$ test cases in order. For example, the output format must be [$\\widehat{HR}_{\\mathrm{fixed}}^{(1)}$, $\\widehat{HR}_{\\mathrm{upd}}^{(1)}$, $b^{(1)}$, $\\widehat{HR}_{\\mathrm{fixed}}^{(2)}$, $\\widehat{HR}_{\\mathrm{upd}}^{(2)}$, $b^{(2)}$, $\\widehat{HR}_{\\mathrm{fixed}}^{(3)}$, $\\widehat{HR}_{\\mathrm{upd}}^{(3)}$, $b^{(3)}$, $\\widehat{HR}_{\\mathrm{fixed}}^{(4)}$, $\\widehat{HR}_{\\mathrm{upd}}^{(4)}$, $b^{(4)}$], with all values rounded to $3$ decimal places. Times must be treated in months, and hazard ratios and bias are unitless floats.", "solution": "The user has provided a problem that is scientifically grounded in the principles of biostatistics and epidemiology, specifically concerning survival analysis and the methodological artifact known as immortal time bias. The problem is well-posed, providing explicit mathematical definitions and complete data for all calculations. There are no contradictions, ambiguities, or factual inaccuracies. Therefore, the problem is valid and a solution will be provided.\n\nThe core of this problem lies in comparing two different methods for defining exposure in a cohort study where treatment initiation is delayed. The goal is to calculate a hazard ratio ($\\widehat{HR}$) under each definition and quantify the discrepancy, which illustrates the concept of immortal time bias.\n\n**Fundamental Concepts**\n\nThe hazard rate, $h(t)$, represents the instantaneous risk of an event at time $t$, given survival up to time $t$. In this problem, we assume the hazard is constant within a specific exposure group $g \\in \\{0, 1\\}$, where $g=0$ denotes the unexposed state and $g=1$ denotes the exposed state. This assumption allows us to estimate the hazard empirically as:\n$$\n\\hat{h}_g = \\frac{E_g}{T_g}\n$$\nwhere $E_g$ is the total number of events observed in group $g$, and $T_g$ is the total person-time (in this case, person-months) of follow-up accumulated by individuals while they are in group $g$.\n\nThe hazard ratio ($\\widehat{HR}$) is the ratio of the hazard in the exposed group to the hazard in the unexposed group:\n$$\n\\widehat{HR} = \\frac{\\hat{h}_1}{\\hat{h}_0}\n$$\nAn $\\widehat{HR} > 1$ suggests the exposure is associated with an increased risk of the event, an $\\widehat{HR} < 1$ suggests a protective association, and an $\\widehat{HR} = 1$ suggests no association.\n\n**Analysis 1: Time-Fixed Exposure Definition**\n\nThis is a naive and methodologically flawed approach. An individual is classified into an exposure group based on their entire history, specifically whether they *ever* initiate treatment.\n- **Exposed Group ($g=1$)**: Individuals with a finite treatment initiation time, $\\tau_i < \\infty$.\n- **Unexposed Group ($g=0$)**: Individuals who never initiate treatment, $\\tau_i = \\infty$.\n\nFor this analysis, we calculate the total events and total person-time for each group:\n- $E_1^{\\mathrm{fixed}} = \\sum_{i: \\tau_i < \\infty} \\delta_i$\n- $T_1^{\\mathrm{fixed}} = \\sum_{i: \\tau_i < \\infty} y_i$\n- $E_0^{\\mathrm{fixed}} = \\sum_{i: \\tau_i = \\infty} \\delta_i$\n- $T_0^{\\mathrm{fixed}} = \\sum_{i: \\tau_i = \\infty} y_i$\n\nThe resulting time-fixed hazard ratio is:\n$$\n\\widehat{HR}_{\\mathrm{fixed}} = \\frac{E_1^{\\mathrm{fixed}} / T_1^{\\mathrm{fixed}}}{E_0^{\\mathrm{fixed}} / T_0^{\\mathrm{fixed}}}\n$$\n\nThe critical flaw here is the misattribution of person-time. For an individual who initiates treatment at $\\tau_i > 0$, the period from baseline $t=0$ to $\\tau_i$ is \"immortal time\" with respect to the exposed state. The individual *must* survive event-free to reach $\\tau_i$ and become treated. By classifying their entire follow-up time $y_i$ as \"exposed\" person-time, we are including a period ($[0, \\tau_i)$) during which an exposed event could not have possibly occurred. This practice artificially inflates the denominator $T_1^{\\mathrm{fixed}}$ without a corresponding possibility of increasing the numerator $E_1^{\\mathrm{fixed}}$, thereby biasing the estimated hazard $\\hat{h}_1^{\\mathrm{fixed}}$ downwards and biasing $\\widehat{HR}_{\\mathrm{fixed}}$ towards the null value of $1$.\n\n**Analysis 2: Time-Updated Exposure Definition**\n\nThis is the correct approach, treating exposure as a time-varying covariate. An individual can contribute person-time to both the unexposed and exposed states.\n- For an individual $i$, the time interval $[0, \\min(y_i, \\tau_i))$ is unexposed person-time.\n- If $\\tau_i < y_i$, the time interval $[\\tau_i, y_i)$ is exposed person-time.\n\nThe total person-times for the time-updated analysis are calculated by summing these contributions across all individuals:\n- $T_0^{\\mathrm{upd}} = \\sum_{i} \\min(y_i, \\tau_i)$\n- $T_1^{\\mathrm{upd}} = \\sum_{i} \\max(0, y_i - \\tau_i)$\n\nEvents are allocated to the exposure state the individual was in immediately prior to the event time $y_i$.\n- An event ($\\delta_i=1$) is counted in the unexposed group ($E_0^{\\mathrm{upd}}$) if it occurs at or before treatment initiation ($y_i \\le \\tau_i$).\n- An event ($\\delta_i=1$) is counted in the exposed group ($E_1^{\\mathrm{upd}}$) if it occurs after treatment initiation ($y_i > \\tau_i$).\n\nThe time-updated hazard ratio, which is the correct estimate under the given model, is:\n$$\n\\widehat{HR}_{\\mathrm{upd}} = \\frac{E_1^{\\mathrm{upd}} / T_1^{\\mathrm{upd}}}{E_0^{\\mathrm{upd}} / T_0^{\\mathrm{upd}}}\n$$\n\n**Quantifying Immortal Time Bias**\n\nThe bias introduced by the incorrect time-fixed method is quantified by comparing its result to the correct time-updated result. The relative bias, $b$, is given by:\n$$\nb = \\frac{\\widehat{HR}_{\\mathrm{fixed}} - \\widehat{HR}_{\\mathrm{upd}}}{\\widehat{HR}_{\\mathrm{upd}}}\n$$\nA negative value for $b$ indicates that the time-fixed analysis underestimates the hazard ratio, which is the expected direction of immortal time bias.\n\n**Algorithmic Implementation**\n\nThe solution will be implemented by a function that processes a given cohort of patients. This function will perform the following steps:\n1. Initialize counters for both fixed and updated analyses: $E_0^{\\mathrm{fixed}}$, $T_0^{\\mathrm{fixed}}$, $E_1^{\\mathrm{fixed}}$, $T_1^{\\mathrm{fixed}}$, $E_0^{\\mathrm{upd}}$, $T_0^{\\mathrm{upd}}$, $E_1^{\\mathrm{upd}}$, $T_1^{\\mathrm{upd}}$, all to $0$.\n2. Iterate through each patient $(\\tau_i, y_i, \\delta_i)$ in the cohort.\n3. For the **time-fixed analysis**, classify the patient based on $\\tau_i$. If $\\tau_i < \\infty$, add $y_i$ to $T_1^{\\mathrm{fixed}}$ and $\\delta_i$ to $E_1^{\\mathrm{fixed}}$. If $\\tau_i = \\infty$, add $y_i$ to $T_0^{\\mathrm{fixed}}$ and $\\delta_i$ to $E_0^{\\mathrm{fixed}}$.\n4. For the **time-updated analysis**, partition the patient's person-time. Add $\\min(y_i, \\tau_i)$ to $T_0^{\\mathrm{upd}}$ and $y_i - \\min(y_i, \\tau_i)$ to $T_1^{\\mathrm{upd}}$. If $\\delta_i=1$, allocate the event: increment $E_0^{\\mathrm{upd}}$ if $y_i \\le \\tau_i$, or increment $E_1^{\\mathrm{upd}}$ if $y_i > \\tau_i$.\n5. After iterating through all patients, calculate the four hazards ($\\hat{h}_0^{\\mathrm{fixed}}, \\hat{h}_1^{\\mathrm{fixed}}, \\hat{h}_0^{\\mathrm{upd}}, \\hat{h}_1^{\\mathrm{upd}}$), taking care to handle potential division by zero if a person-time denominator is $0$.\n6. Compute $\\widehat{HR}_{\\mathrm{fixed}}$ and $\\widehat{HR}_{\\mathrm{upd}}$.\n7. Compute the relative bias $b$.\n8. Return the triplet ($\\widehat{HR}_{\\mathrm{fixed}}, \\widehat{HR}_{\\mathrm{upd}}, b$).\n\nThis procedure will be applied to each test case, and the results will be collected and formatted as specified.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes time-fixed and time-updated hazard ratios and the resulting\n    relative bias for several EHR cohorts to demonstrate immortal time bias.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (happy path, mixed initiation times, some censoring)\n        [(2, 10, 1), (5, 12, 0), (np.inf, 8, 1), (0, 9, 1), (np.inf, 7, 0), (3, 6, 1)],\n        \n        # Test Case 2 (late treatment initiation creating substantial immortal time)\n        [(9, 12, 1), (10, 12, 0), (11, 14, 1), (np.inf, 6, 1), (np.inf, 12, 0)],\n        \n        # Test Case 3 (event at initiation boundary, immediate initiators)\n        [(5, 5, 1), (0, 8, 0), (4, 9, 1), (np.inf, 7, 1), (np.inf, 10, 0)],\n        \n        # Test Case 4 (early initiations and never-treated mix)\n        [(0, 4, 1), (1, 6, 0), (2, 3, 1), (np.inf, 5, 1), (np.inf, 6, 0)],\n    ]\n\n    all_results = []\n\n    for cohort in test_cases:\n        # --- Time-Fixed Analysis ---\n        E0_fixed, T0_fixed = 0.0, 0.0\n        E1_fixed, T1_fixed = 0.0, 0.0\n\n        for tau_i, y_i, delta_i in cohort:\n            if tau_i == np.inf:  # Unexposed group (never-treated)\n                T0_fixed += y_i\n                E0_fixed += delta_i\n            else:  # Exposed group (ever-treated)\n                T1_fixed += y_i\n                E1_fixed += delta_i\n\n        h0_fixed = E0_fixed / T0_fixed if T0_fixed > 0 else 0.0\n        h1_fixed = E1_fixed / T1_fixed if T1_fixed > 0 else 0.0\n        \n        hr_fixed = h1_fixed / h0_fixed if h0_fixed > 0 else np.inf\n\n        # --- Time-Updated Analysis ---\n        E0_upd, T0_upd = 0.0, 0.0\n        E1_upd, T1_upd = 0.0, 0.0\n\n        for tau_i, y_i, delta_i in cohort:\n            # Partition person-time\n            unexposed_pt = min(y_i, tau_i)\n            exposed_pt = y_i - unexposed_pt\n            \n            T0_upd += unexposed_pt\n            T1_upd += exposed_pt\n\n            # Allocate events\n            if delta_i == 1:\n                if y_i <= tau_i:\n                    E0_upd += 1\n                else:  # y_i > tau_i\n                    E1_upd += 1\n        \n        h0_upd = E0_upd / T0_upd if T0_upd > 0 else 0.0\n        h1_upd = E1_upd / T1_upd if T1_upd > 0 else 0.0\n        \n        hr_upd = h1_upd / h0_upd if h0_upd > 0 else np.inf\n\n        # --- Bias Calculation ---\n        # The problem cases ensure hr_upd is not zero\n        bias = (hr_fixed - hr_upd) / hr_upd\n        \n        all_results.extend([\n            round(hr_fixed, 3),\n            round(hr_upd, 3),\n            round(bias, 3)\n        ])\n\n    # Format the final output string\n    formatted_results = f\"[{','.join(map(str, all_results))}]\"\n    print(formatted_results)\n\nsolve()\n```", "id": "4862751"}]}