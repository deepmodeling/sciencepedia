{"hands_on_practices": [{"introduction": "In the burgeoning field of digital health, a crucial distinction exists between general wellness applications and regulated Digital Therapeutics (DTx). This hands-on problem challenges you to apply the foundational principles of medical device classification to a common scenario: a wellness app that promotes activity. By working through this exercise [@problem_id:4835969], you will learn to navigate the regulatory landscape by focusing on the single most important factor: the manufacturer's \"intended use.\"", "problem": "A smartphone application records daily step counts using on-device sensors and displays motivational messages tailored to recent activity (for example, encouraging more walking after a sedentary day). The developer explicitly avoids disease-specific claims and markets the product for general well-being, including a statement that it is not intended to diagnose, prevent, treat, or manage any disease. Using first principles from the classification of Software as a Medical Device (SaMD) by the International Medical Device Regulators Forum (IMDRF) and the definition of digital therapeutics by the Digital Therapeutics Alliance (DTA), decide whether such an application should be classified as a digital therapeutic or as a general wellness product. Base your reasoning on intended use and evidence requirements rather than on implementation details. In your reasoning, consider the following conceptual variables: intended medical use indicator $I \\in \\{0,1\\}$ (where $I=1$ denotes disease-targeted intended use), a qualitative mechanism descriptor $M$ (therapeutic versus wellness coaching), and a qualitative clinical evidence level $E$ (presence versus absence of disease-related clinical validation). Choose the single best option.\nA. It is not a digital therapeutic; it is a general wellness product, because without disease-targeted intended use ($I=0$), it is not SaMD and does not meet digital therapeutics criteria that require a therapeutic mechanism $M$ and disease-related clinical evidence $E$ supporting prevention, management, or treatment.\nB. It is a digital therapeutic because behavior change is inherently therapeutic, even if there are no disease-specific claims, and therefore intended use ($I$) does not affect classification.\nC. It is a digital therapeutic as long as the motivational messages are personalized by machine learning, because algorithmic personalization establishes a therapeutic mechanism $M$ independent of intended use $I$.\nD. It is a digital therapeutic if aggregate users exhibit improved health metrics (for example, lower resting heart rate) over time, because observed benefit is sufficient clinical evidence $E$ regardless of intended use $I$.", "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n**Step 1: Extract Givens**\n- A smartphone application records daily step counts.\n- It displays motivational messages tailored to recent activity.\n- The developer explicitly avoids disease-specific claims.\n- The product is marketed for general well-being.\n- A disclaimer is included: \"not intended to diagnose, prevent, treat, or manage any disease.\"\n- The task is to classify the application as either a digital therapeutic or a general wellness product.\n- The classification must be based on first principles from:\n    1. The International Medical Device Regulators Forum (IMDRF) classification of Software as a Medical Device (SaMD).\n    2. The Digital Therapeutics Alliance (DTA) definition of digital therapeutics.\n- The reasoning must be based on intended use and evidence requirements, not implementation details.\n- Conceptual variables are provided:\n    - Intended medical use indicator $I \\in \\{0,1\\}$, where $I=1$ denotes disease-targeted intended use.\n    - Qualitative mechanism descriptor $M$ (therapeutic versus wellness coaching).\n    - Qualitative clinical evidence level $E$ (presence versus absence of disease-related clinical validation).\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly grounded in the established regulatory and definitional frameworks of medical informatics, specifically those of the IMDRF and DTA. These are real-world, internationally recognized bodies. The conceptual variables $I$, $M$, and $E$ provide a valid and rigorous abstraction for analyzing these frameworks. The problem is scientifically sound within its domain.\n- **Well-Posed:** The problem provides a clear scenario and asks for a classification based on specific, named principles. The information is sufficient to derive a unique classification.\n- **Objective:** The problem is described using precise, unbiased language. The application's features and marketing posture are stated factually.\n- **Completeness and Consistency:** The problem is self-contained and internally consistent. The description of the app (marketed for general well-being, explicit disclaimer against medical use) directly informs the value of the conceptual variable $I$.\n- **Realism:** The scenario describes a common type of consumer health and fitness application, and highlights the central regulatory challenge in digital health: the boundary between wellness products and regulated medical devices.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-posed, objective, and scientifically grounded question in the field of medical informatics. I will proceed with deriving a solution.\n\n**Derivation from First Principles**\n\nThe classification of the software application depends on its \"intended use,\" which is the cornerstone of medical device regulation.\n\n1.  **IMDRF Framework for Software as a Medical Device (SaMD):**\n    The IMDRF defines SaMD as \"software intended to be used for one or more medical purposes that perform these purposes without being part of a hardware medical device.\" Medical purposes explicitly include the diagnosis, prevention, monitoring, treatment, or alleviation of disease. Crucially, the IMDRF framework distinguishes SaMD from software intended for general wellness. Software that is solely intended for \"maintaining or encouraging a healthy lifestyle\" and is unrelated to a specific disease or medical condition is not considered a medical device.\n\n2.  **DTA Definition of Digital Therapeutics (DTx):**\n    The Digital Therapeutics Alliance defines DTx as products that \"deliver evidence-based therapeutic interventions to patients that are driven by high-quality software programs to prevent, manage, or treat a medical disorder or disease.\" This definition has several core requirements:\n    - The product must have a medical purpose (prevent, manage, or treat a disease).\n    - The intervention must be \"therapeutic.\"\n    - The claims must be supported by clinical evidence.\n    - DTx are a subset of SaMD and are expected to undergo regulatory review.\n\n**Application to the Problem**\n\nThe problem statement specifies that the app is marketed for \"general well-being\" and includes a disclaimer that it is \"not intended to diagnose, prevent, treat, or manage any disease.\" This directly establishes the manufacturer's intended use.\n\n- **Intended Use ($I$):** Based on the explicit marketing and disclaimer, the intended use is not disease-targeted. Therefore, the intended medical use indicator is $I=0$.\n- **Classification as SaMD:** According to the IMDRF principles, since the intended use is not for a medical purpose ($I=0$), the application does not meet the definition of a SaMD. It is classified as a general wellness product.\n- **Classification as DTx:** According to the DTA definition, a product must be intended to prevent, manage, or treat a disease. Since this application has $I=0$, it fails this primary requirement. Consequently, it cannot be a digital therapeutic. A DTx must, by definition, be a SaMD first, and this application is not.\n\nTherefore, the application is a general wellness product. Its mechanism, $M$, is wellness coaching, not a therapeutic intervention for a disease. Similarly, it is not required to have, and would not be evaluated based on, disease-related clinical evidence, $E$. The entire classification hinges on the intended use, $I$.\n\n**Option-by-Option Analysis**\n\n**A. It is not a digital therapeutic; it is a general wellness product, because without disease-targeted intended use ($I=0$), it is not SaMD and does not meet digital therapeutics criteria that require a therapeutic mechanism $M$ and disease-related clinical evidence $E$ supporting prevention, management, or treatment.**\nThis option correctly follows the logic derived from first principles. It correctly identifies that an intended use for a non-medical purpose ($I=0$) means the software is not a SaMD. It correctly concludes that if it is not a SaMD, it cannot be a DTx, as DTx are a category of SaMD that inherently require a therapeutic mechanism ($M$) and clinical evidence ($E$) related to a disease. The reasoning aligns with the regulatory and definitional cascade perfectly.\n**Verdict: Correct**\n\n**B. It is a digital therapeutic because behavior change is inherently therapeutic, even if there are no disease-specific claims, and therefore intended use ($I$) does not affect classification.**\nThis statement is fundamentally flawed. The assertion that intended use ($I$) does not affect classification is a direct contradiction of the foundational principle of all medical device regulation, including the IMDRF and DTA frameworks. While behavior change can be used therapeutically, its application in a product intended for general wellness does not make that product a regulated digital therapeutic.\n**Verdict: Incorrect**\n\n**C. It is a digital therapeutic as long as the motivational messages are personalized by machine learning, because algorithmic personalization establishes a therapeutic mechanism $M$ independent of intended use $I$.**\nThis option incorrectly equates technological sophistication (machine learning) with therapeutic intent. The classification is determined by the *purpose* to which the technology is applied, not the technology itself. A personalized algorithm for general wellness coaching ($I=0$) does not constitute a \"therapeutic mechanism\" in the regulatory sense. The mechanism $M$ is only considered therapeutic if it's applied for a medical purpose ($I=1$).\n**Verdict: Incorrect**\n\n**D. It is a digital therapeutic if aggregate users exhibit improved health metrics (for example, lower resting heart rate) over time, because observed benefit is sufficient clinical evidence $E$ regardless of intended use $I$.**\nThis option confuses the consequence of use with the intended use. Regulatory classification is determined *a priori* by the manufacturer's stated intended use ($I$). While positive health outcomes might occur, they do not retroactively change a wellness product into a medical device. Clinical evidence ($E$) is required to *substantiate* a medical claim ($I=1$), not to *create* one in the absence of intent. If a manufacturer were to use such data to market the product for a medical purpose, its intended use would change, and it would then become subject to regulation.\n**Verdict: Incorrect**", "answer": "$$\\boxed{A}$$", "id": "4835969"}, {"introduction": "A key feature that sets many Digital Therapeutics apart from static content is their ability to personalize interventions in real-time. To be effective, a DTx should deliver the right content to the right person at the right time. This exercise [@problem_id:4835903] introduces the contextual bandit, a powerful machine learning framework used to formalize and solve this complex personalization problem, balancing the need to explore new strategies with exploiting known effective ones.", "problem": "A mobile Digital Therapeutic (DTx) delivers a single piece of intervention content daily to support self-management for individuals with Type $2$ Diabetes Mellitus. The design objective is to select, each day, which content to deliver so as to maximize a proximal engagement-and-motivation outcome that can be measured within the same day or by the next morning. You are asked to formalize this decision as a contextual bandit problem and pick the formulation that correctly specifies the features (context), actions, reward, and exploration strategy while respecting safety constraints.\n\nUse the following base definitions. In a contextual bandit, at round $t$ the system observes a context vector $x_t \\in \\mathbb{R}^d$ containing information available before choosing the action, selects a single action $a_t \\in \\mathcal{A}$, and immediately receives a scalar reward $r_t$ associated only with that action in that context. The goal is to maximize the expected cumulative reward $\\mathbb{E}\\big[\\sum_{t=1}^T r_t\\big]$ under uncertainty about the reward function. Exploration is required because the expected rewards of actions are initially uncertain; exploration must be performed within safety constraints that restrict the feasible action set to $\\mathcal{A}_t \\subseteq \\mathcal{A}$ at round $t$.\n\nConsider the following candidate formulations; choose the option that is a scientifically sound contextual bandit for daily intervention content selection in the DTx:\n\nA. Features: $x_t$ includes observable variables at the start of day $t$: day-of-week (one-hot encoded), local notification window, baseline characteristics (age and baseline glycated hemoglobin), prior $3$-day content completion indicators, prior $3$-day step counts, last-day medication adherence indicator, and whether any content is contraindicated today (e.g., high-intensity activity prompt if the user reported an injury). Actions: $\\mathcal{A}$ is the set of $K$ content modules $\\{$medication adherence reminder, physical activity prompt, mindful eating skill, stress reduction exercise, carb counting tip$\\}$, and the feasible set $\\mathcal{A}_t \\subseteq \\mathcal{A}$ excludes contraindicated modules. Reward: immediately measured proximal outcome $r_t \\in [0,1]$, defined as a weighted combination $r_t = 0.7 \\cdot \\mathbb{1}\\{\\text{content completed within } 24 \\text{ h}\\} + 0.3 \\cdot \\sigma(\\Delta m_t)$, where $\\Delta m_t$ is the change in self-reported motivation within $6$ h after delivery and $\\sigma(u) = \\min(1, \\max(0, u/2))$ maps motivation change into $[0,1]$. Exploration: $\\varepsilon$-greedy with context-based reward prediction (e.g., a linear model $\\hat{r}(x_t,a)$ fit online); choose $\\arg\\max_{a \\in \\mathcal{A}_t} \\hat{r}(x_t,a)$ with probability $1-\\varepsilon_t$ and a random $a \\in \\mathcal{A}_t$ uniformly with probability $\\varepsilon_t$, where $\\varepsilon_t = \\max(0.05, 0.2/\\sqrt{t})$.\n\nB. Features: $x_t$ includes current variables and planned $30$-day coaching schedule. Actions: select one of the $K$ modules. Reward: long-term clinical improvement $r_t$ defined as the change in glycated hemoglobin (HbA1c) after $90$ days relative to baseline. Exploration: none; instead, use a policy-gradient algorithm over multi-step trajectories to optimize the $90$-day objective. The policy produces a $30$-day schedule of modules per decision.\n\nC. Features: $x_t$ includes day-of-week and the model’s forecast of whether the user will complete the content if offered (computed using data from after delivery). Actions: choose a sequence of $3$ modules spaced across day $t$ to deliver. Reward: $r_t$ equals the sum of adherence (number of completions) over the next $7$ days. Exploration: deterministic cycling through all sequences in lexicographic order until each has been tried once, then always exploit the highest $7$-day sum.\n\nD. Features: $x_t$ includes baseline demographics, last-day engagement, and current mood. Actions: choose one of the $K$ modules without any contraindication filtering. Reward: $r_t = -\\text{friction}(a_t)$, where friction is the estimated time-to-complete the module in minutes, encouraging the shortest content regardless of engagement or motivation. Exploration: set $\\varepsilon_t = 0$ from the start (always exploit the current best predicted friction-minimizing action).\n\nWhich option correctly constructs a contextual bandit formulation suitable for daily intervention selection in the DTx under the base definitions and safety constraints?", "solution": "The user has requested a critical validation of the problem statement, followed by a detailed derivation of the correct solution and an evaluation of all provided options.\n\n**Problem Statement Validation**\n\nFirst, I will validate the problem statement according to the specified criteria.\n\n**Step 1: Extract Givens**\n\n*   **Domain:** A mobile Digital Therapeutic (DTx) for self-management of Type $2$ Diabetes Mellitus.\n*   **Intervention:** A single piece of intervention content is delivered daily.\n*   **Objective:** Maximize a proximal engagement-and-motivation outcome, measurable within the same day or by the next morning.\n*   **Method:** Formalize the daily content selection decision as a contextual bandit problem.\n*   **Contextual Bandit Definition:**\n    *   At each round $t$, the system observes a context vector $x_t \\in \\mathbb{R}^d$.\n    *   The system selects a single action $a_t \\in \\mathcal{A}$.\n    *   The system receives a scalar reward $r_t$ associated with the chosen action and context.\n    *   The goal is to maximize the expected cumulative reward, $\\mathbb{E}\\big[\\sum_{t=1}^T r_t\\big]$.\n    *   Exploration is required to handle uncertainty about the reward function.\n    *   Safety constraints restrict the action set at round $t$ to a feasible subset $\\mathcal{A}_t \\subseteq \\mathcal{A}$.\n*   **Task:** Identify the candidate formulation that correctly specifies features (context), actions, reward, and exploration strategy, while respecting safety constraints.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded:** The problem is grounded in the fields of medical informatics and machine learning. Using contextual bandits for personalizing interventions in digital health is a standard and scientifically valid approach. The application to Type $2$ Diabetes management is realistic and a common use case. All concepts (DTx, engagement, motivation, contraindications, contextual bandits) are well-established.\n2.  **Well-Posed:** The problem provides a clear definition of a contextual bandit and a specific application scenario. It asks to evaluate four distinct formulations against this definition and the scenario's constraints. This constitutes a well-posed problem with a unique correct answer among the options, assuming one is valid.\n3.  **Objective:** The problem is stated in precise, objective, and technical language, free from subjective claims or ambiguity.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is **valid**. It is scientifically sound, well-posed, and objective. I will now proceed with solving the problem by analyzing the provided options.\n\n**Solution Derivation and Option Analysis**\n\nA correct formulation of this problem as a contextual bandit must adhere to the following principles derived from the problem statement:\n\n1.  **Context ($x_t$):** The features in the context vector $x_t$ must be available *at the start of day $t$*, before the action (content selection) is taken. These features should be relevant for predicting the reward.\n2.  **Actions ($\\mathcal{A}$, $\\mathcal{A}_t$):** The action set $\\mathcal{A}$ must represent the available content modules. The decision process must incorporate the safety constraint by selecting an action $a_t$ from a feasible subset $\\mathcal{A}_t \\subseteq \\mathcal{A}$ that excludes contraindicated content.\n3.  **Reward ($r_t$):** The reward $r_t$ must be a scalar value that is received \"immediately\" after the action. The problem specifies this as a \"proximal engagement-and-motivation outcome that can be measured within the same day or by the next morning.\" The reward function must accurately reflect this objective.\n4.  **Exploration:** The algorithm must include a mechanism for exploration to learn the uncertain reward function, balancing it with exploitation of actions believed to be optimal.\n\nI will now evaluate each option against these four criteria.\n\n**A. Evaluation of Option A**\n\n*   **Features/Context ($x_t$):** The features listed are all \"observable variables at the start of day $t$\". This includes static data (baseline characteristics), recent historical data (prior $3$-day activities), and of utmost importance, a feature indicating \"whether any content is contraindicated today\". This adheres perfectly to the requirement that context precedes action.\n*   **Actions ($\\mathcal{A}$, $\\mathcal{A}_t$):** The action set $\\mathcal{A}$ is correctly defined as the set of $K$ content modules. The formulation explicitly respects safety by defining a feasible set $\\mathcal{A}_t \\subseteq \\mathcal{A}$ which \"excludes contraindicated modules\". The action selection then occurs from this safe set. This correctly implements the safety constraint.\n*   **Reward ($r_t$):** The reward is defined as a weighted sum of content completion within $24$ hours and self-reported motivation change within $6$ hours. This is a proximal outcome, measurable within the specified time frame (\"same day or by the next morning\"), and directly quantifies the stated goal of maximizing \"engagement-and-motivation\". The use of an indicator function $\\mathbb{1}\\{\\cdot\\}$ and a scaling function $\\sigma(\\cdot)$ to map outcomes to a consistent scale $[0,1]$ is a sound practice.\n*   **Exploration:** The strategy is $\\varepsilon$-greedy, a canonical bandit algorithm. It is made \"contextual\" by using a predictive model $\\hat{r}(x_t, a)$ for the greedy choice, which is standard. The exploration is performed safely by choosing a random action from the feasible set $\\mathcal{A}_t$. The decaying exploration rate $\\varepsilon_t = \\max(0.05, 0.2/\\sqrt{t})$ is a common and theoretically grounded heuristic to balance exploration and exploitation over time.\n\n**Verdict on Option A:** **Correct**. This formulation aligns with all principles of a contextual bandit and correctly operationalizes all constraints and objectives described in the problem statement.\n\n**B. Evaluation of Option B**\n\n*   **Reward ($r_t$):** The proposed reward is the \"change in glycated hemoglobin (HbA1c) after $90$ days\". This is a long-term, delayed, and sparse reward. It fundamentally violates the bandit framework's assumption of an \"immediately\" received reward $r_t$ at each round $t$. It also contradicts the problem's explicit objective of maximizing a *proximal* outcome. Such a reward structure is appropriate for a full reinforcement learning (RL) problem, not a contextual bandit problem as defined.\n*   **Exploration:** The formulation states \"none; instead, use a policy-gradient algorithm\". The absence of exploration violates a core tenet of bandit problems. Policy-gradient algorithms are designed for full RL with delayed rewards and complex state transitions, confirming that this formulation misidentifies the problem class.\n\n**Verdict on Option B:** **Incorrect**. The use of a long-term, delayed reward and the abandonment of the bandit structure in favor of a full RL approach without exploration are critical flaws.\n\n**C. Evaluation of Option C**\n\n*   **Features/Context ($x_t$):** The context is stated to include a forecast \"computed using data from after delivery\". This is a temporal violation. The context $x_t$ for a decision at time $t$ cannot include information that is only available *after* the decision has been made and its effects have been observed. This represents data leakage from the future.\n*   **Actions ($a_t$):** The action is \"a sequence of $3$ modules\". The problem statement specifies that the DTx \"delivers a single piece of intervention content daily\". This formulation violates a primary constraint of the problem setup.\n*   **Reward ($r_t$):** The reward is the \"sum of adherence over the next $7$ days\". This is a delayed reward, not one measured \"within the same day or by the next morning\" as required.\n\n**Verdict on Option C:** **Incorrect**. This option fails on three fundamental points: the context definition is temporally invalid, the action space contradicts the problem description, and the reward is not proximal.\n\n**D. Evaluation of Option D**\n\n*   **Actions ($\\mathcal{A}$, $\\mathcal{A}_t$):** The formulation specifies choosing an action \"without any contraindication filtering\". This directly violates the explicit safety requirement that the action must be chosen from a constrained feasible set $\\mathcal{A}_t \\subseteq \\mathcal{A}$. Proposing an action that could be harmful (e.g., a physical activity prompt to an injured user) is a critical failure in a medical application.\n*   **Reward ($r_t$):** The reward is $r_t = -\\text{friction}(a_t)$, aiming to minimize the time-to-complete. This reward function is misaligned with the stated objective of maximizing \"engagement-and-motivation\". Minimizing interaction time is often counterproductive to genuine engagement and learning.\n*   **Exploration:** The formulation sets the exploration rate $\\varepsilon_t = 0$ \"from the start\". This is a purely greedy algorithm, not a bandit algorithm. It completely removes exploration, which is essential for learning under uncertainty and is explicitly required by the problem's definition of a bandit.\n\n**Verdict on Option D:** **Incorrect**. This formulation is critically flawed due to its disregard for safety constraints, its misaligned reward function, and its complete lack of exploration.", "answer": "$$\\boxed{A}$$", "id": "4835903"}, {"introduction": "For a Digital Therapeutic to be successfully integrated into clinical practice, it must prove its value not just to patients, but also to the healthcare systems that pay for it. Health Technology Assessment (HTA) bodies rely on economic evaluations to make these decisions. In this practice problem [@problem_id:4835904], you will apply the core method of cost-utility analysis by calculating the Incremental Cost-Effectiveness Ratio ($ICER$), a fundamental skill for anyone involved in evaluating the real-world impact of DTx.", "problem": "A health system is evaluating a new Digital Therapeutic (DTx), defined as evidence-based software delivering an intervention to prevent, manage, or treat a medical disorder, for a chronic disease over a one-year horizon. In cost-utility analysis, health benefit is measured in Quality-Adjusted Life Years (QALYs), where a QALY quantifies the expected life-years weighted by health-related quality on $[0,1]$. The DTx costs $\\$500$ per patient per year and yields an additional $0.05$ QALYs over the year compared with standard care. Standard care costs $\\$200$ per patient per year and yields a baseline QALY level for the same population and horizon. The health system uses a willingness-to-pay threshold of $\\$50{,}000$ per QALY to judge cost-effectiveness.\n\nStarting from the fundamental economic evaluation principle that cost-effectiveness in cost-utility analysis is assessed by comparing the extra cost to the extra health effect (in QALYs) when moving from a comparator to an intervention, derive the Incremental Cost-Effectiveness Ratio (ICER) of the DTx versus standard care and compute its numerical value. Then, determine whether the DTx is cost-effective at the stated willingness-to-pay threshold.\n\nRound the ICER to four significant figures. Express the final ICER in dollars per QALY.", "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- Intervention: Digital Therapeutic (DTx).\n- Comparator: Standard Care.\n- Cost of DTx ($C_{DTx}$): $\\$500$ per patient per year.\n- Cost of Standard Care ($C_{Std}$): $\\$200$ per patient per year.\n- Incremental health benefit of DTx over standard care ($\\Delta E$): $0.05$ Quality-Adjusted Life Years (QALYs).\n- Willingness-to-pay (WTP) threshold ($\\lambda$): $\\$50,000$ per QALY.\n- Task 1: Derive and compute the Incremental Cost-Effectiveness Ratio (ICER).\n- Task 2: Determine if the DTx is cost-effective.\n- Formatting: Round the ICER to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is set within the standard, well-established framework of cost-utility analysis, a sub-discipline of health economics and medical informatics. The concepts used—QALYs, ICER, and willingness-to-pay threshold—are fundamental to the field. All data required for the calculation are provided, and the values are plausible. The problem is self-contained, consistent, and scientifically sound. It does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be provided.\n\nThe fundamental principle of cost-effectiveness analysis is to evaluate the ratio of additional costs to additional health benefits when comparing a new intervention to a standard comparator. This ratio is known as the Incremental Cost-Effectiveness Ratio (ICER).\n\nThe ICER is formally defined as:\n$$\n\\text{ICER} = \\frac{\\Delta C}{\\Delta E} = \\frac{C_{\\text{intervention}} - C_{\\text{comparator}}}{E_{\\text{intervention}} - E_{\\text{comparator}}}\n$$\nwhere $C$ represents cost and $E$ represents the health effect, measured in QALYs.\n\nFrom the problem statement, we identify the following values:\n- Cost of the intervention (DTx), $C_{DTx} = 500$ dollars.\n- Cost of the comparator (standard care), $C_{Std} = 200$ dollars.\n- Incremental health effect (QALYs gained), $\\Delta E = E_{DTx} - E_{Std} = 0.05$ QALYs.\n\nFirst, we calculate the incremental cost, $\\Delta C$:\n$$\n\\Delta C = C_{DTx} - C_{Std} = \\$500 - \\$200 = \\$300\n$$\nThe incremental cost of implementing the DTx instead of standard care is $\\$300$ per patient per year.\n\nNext, we substitute the incremental cost and incremental effect into the ICER formula to compute its numerical value:\n$$\n\\text{ICER} = \\frac{\\Delta C}{\\Delta E} = \\frac{\\$300}{0.05 \\text{ QALYs}}\n$$\nPerforming the division:\n$$\n\\text{ICER} = \\frac{300}{\\frac{5}{100}} = 300 \\times \\frac{100}{5} = 300 \\times 20 = 6000\n$$\nThe resulting ICER is $\\$6000$ per QALY. The problem requires the answer to be rounded to four significant figures. The calculated value is an exact integer, $6000$. To express this value unambiguously with four significant figures, we can write it in scientific notation as $6.000 \\times 10^{3}$.\n\nThe final step is to determine whether the DTx is cost-effective. An intervention is considered cost-effective if its ICER is less than or equal to the predetermined willingness-to-pay (WTP) threshold, $\\lambda$.\nThe decision rule is:\n- If $\\text{ICER} \\le \\lambda$, the intervention is cost-effective.\n- If $\\text{ICER}  \\lambda$, the intervention is not cost-effective.\n\nIn this case, the health system's WTP threshold is given as $\\lambda = \\$50,000$ per QALY. We compare the calculated ICER to this threshold:\n$$\n\\$6000 \\le \\$50,000\n$$\nSince the ICER of the DTx ($\\$6000$ per QALY) is substantially lower than the WTP threshold ($\\$50,000$ per QALY), the DTx is determined to be a cost-effective intervention for this health system.", "answer": "$$\n\\boxed{6.000 \\times 10^{3}}\n$$", "id": "4835904"}]}