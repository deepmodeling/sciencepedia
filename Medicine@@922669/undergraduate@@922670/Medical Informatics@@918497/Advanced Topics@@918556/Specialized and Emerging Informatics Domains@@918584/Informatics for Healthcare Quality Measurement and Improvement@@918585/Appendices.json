{"hands_on_practices": [{"introduction": "This first practice is a cornerstone of healthcare quality measurement. You will implement the logic for a common process-outcome measure—blood pressure control—by applying a series of rules to a sample of structured patient data, mimicking the function of standards like the Clinical Quality Language (CQL). This exercise will solidify your understanding of how patient cohorts are defined for a measure's denominator and numerator through precise, logical criteria. [@problem_id:4844528]", "problem": "You will write a complete program that evaluates a blood pressure control quality measure using a fixed set of sample Fast Healthcare Interoperability Resources (FHIR) resources and Clinical Quality Language (CQL) semantics, then returns the measure rate for multiple measurement windows. The task is to start from core definitions in informatics and set theory and implement the logic exactly as stated, without relying on any external CQL engine. The problem is self-contained.\n\nFundamental base and definitions to use:\n- A patient’s age in years at a reference date is the floor of the elapsed time in years between the date of birth and the reference date. For a birth date at $d_{\\text{birth}}$ and reference date at $d_{\\text{ref}}$, define age as $A = \\left\\lfloor \\frac{d_{\\text{ref}} - d_{\\text{birth}}}{\\text{one year}} \\right\\rfloor$, where one year is computed by calendrical difference of years followed by month and day comparison.\n- A time interval is a closed interval $[t_{\\min}, t_{\\max}]$ of dates. An event at date $t$ occurs within the interval if $t_{\\min} \\le t \\le t_{\\max}$.\n- The measure denominator is a set of patients defined by set membership predicates; the measure numerator is a subset defined by further predicates; the measure rate is the ratio $R = \\frac{|\\text{Numerator}|}{|\\text{Denominator}|}$, with the convention $R = 0.0$ if $|\\text{Denominator}| = 0$.\n- The logic follows Clinical Quality Language (CQL) semantics expressed in set and predicate terms. You will implement the predicates described below.\n\nData provided and to be used by your program:\n- Sample International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) code: `I10`.\n- Sample Logical Observation Identifiers Names and Codes (LOINC) codes:\n  - Blood pressure panel code: `85354-9`.\n  - Systolic blood pressure component: `8480-6`.\n  - Diastolic blood pressure component: `8462-4`.\n\nYou must embed the following fixed cohort of sample FHIR-like resources directly in your program. Representations are abstract; only the stated attributes are relevant.\n\n- Patient $P1$:\n  - birthDate: $1967$-$05$-$20$.\n  - Conditions: one hypertension condition (`I10`), onset at $2010$-$01$-$01$.\n  - Encounters: one encounter with period date $2022$-$06$-$01$ in $[t_{\\min}, t_{\\max}]$ if that date lies in the interval.\n  - Observations (blood pressure, code `85354-9`):\n    - $2022$-$06$-$01$: systolic (`8480-6`) $138$ mmHg, diastolic (`8462-4`) $88$ mmHg.\n    - $2022$-$09$-$01$: systolic $142$ mmHg, diastolic $85$ mmHg.\n- Patient $P2$:\n  - birthDate: $1955$-$02$-$10$.\n  - Conditions: one hypertension condition (`I10`), onset at $2015$-$01$-$01$.\n  - Encounters: one encounter on $2022$-$11$-$01$.\n  - Observations:\n    - $2022$-$03$-$03$: systolic $139$ mmHg, diastolic $91$ mmHg.\n    - $2022$-$11$-$01$: systolic $134$ mmHg, diastolic $88$ mmHg.\n- Patient $P3$:\n  - birthDate: $1977$-$08$-$01$.\n  - Conditions: one hypertension condition (`I10`), onset at $2020$-$06$-$01$.\n  - Encounters: one encounter on $2022$-$05$-$10$.\n  - Observations:\n    - $2021$-$12$-$30$: systolic $130$ mmHg, diastolic $80$ mmHg.\n- Patient $P4$:\n  - birthDate: $1938$-$01$-$01$.\n  - Conditions: one hypertension condition (`I10`), onset at $2000$-$01$-$01$.\n  - Encounters: one encounter on $2022$-$12$-$31$.\n  - Observations:\n    - $2022$-$12$-$31$: systolic $140$ mmHg, diastolic $90$ mmHg.\n- Patient $P5$:\n  - birthDate: $1992$-$09$-$15$.\n  - Conditions: none.\n  - Encounters: one encounter on $2022$-$10$-$10$.\n  - Observations:\n    - $2022$-$10$-$10$: systolic $120$ mmHg, diastolic $70$ mmHg.\n- Patient $P6$:\n  - birthDate: $2004$-$12$-$31$.\n  - Conditions: one hypertension condition (`I10`), onset at $2022$-$06$-$01$.\n  - Encounters: one encounter on $2022$-$07$-$01$.\n  - Observations:\n    - $2022$-$08$-$01$: systolic $138$ mmHg, diastolic $89$ mmHg.\n\nCQL-style predicates to implement precisely from first principles:\n- Adult cohort: a patient qualifies as adult at the measurement period end date $t_{\\max}$ if age in years at $t_{\\max}$ satisfies $18 \\le A \\le 85$.\n- Hypertension diagnosis: a patient has hypertension if there exists a Condition with code `I10` whose onset date is $\\le t_{\\max}$.\n- Encounter during measurement period: a patient meets the encounter requirement if there exists at least one Encounter whose date $t_{\\text{enc}}$ satisfies $t_{\\min} \\le t_{\\text{enc}} \\le t_{\\max}$.\n- Denominator membership: patient is in the denominator if and only if all three predicates above are true.\n- Blood pressure controlled numerator: among a patient’s blood pressure Observations (code `85354-9`) with both systolic (`8480-6`) and diastolic (`8462-4`) components, consider those with effective date $t_{\\text{obs}}$ satisfying $t_{\\min} \\le t_{\\text{obs}} \\le t_{\\max}$. If none exist, the patient is not in the numerator. Otherwise, take the most recent observation, i.e., the one with maximal $t_{\\text{obs}}$; the patient is in the numerator if and only if systolic $< 140$ and diastolic $< 90$ for that most recent observation. Values equal to $140$ systolic or $90$ diastolic are not considered controlled.\n\nMeasure rate computation:\n- For a given measurement period $[t_{\\min}, t_{\\max}]$, define the denominator count $D$ and numerator count $N$ as above. The measure rate $R$ is the decimal $R = \\frac{N}{D}$ if $D > 0$, else $R = 0.0$. Report $R$ rounded to three decimal places using conventional rounding half away from zero when the fourth decimal digit is $\\ge 5$.\n\nTest suite:\nYour program must compute $R$ for each of the following measurement periods, in the order listed:\n1. Case $1$: $t_{\\min} = 2022$-$01$-$01$, $t_{\\max} = 2022$-$12$-$31$.\n2. Case $2$: $t_{\\min} = 2022$-$09$-$02$, $t_{\\max} = 2022$-$12$-$31$.\n3. Case $3$: $t_{\\min} = 2022$-$01$-$01$, $t_{\\max} = 2022$-$06$-$30$.\n4. Case $4$: $t_{\\min} = 2023$-$01$-$01$, $t_{\\max} = 2023$-$12$-$31$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of the four decimal rates, each formatted to exactly three decimal places, enclosed in square brackets, with no spaces. For example, a valid output shape is “[$0.123$,$0.456$,$0.000$,$1.000$]” but with the values that result from this problem’s data and rules.\n\nAll dates are calendar dates. No external input is required; the program must embed the data above and strictly implement the logic as stated. All blood pressure values are in millimeters of mercury (mmHg). All reported rates must be decimals in $[0, 1]$.", "solution": "The problem requires the implementation of a clinical quality measure for blood pressure control, based on a predefined set of patient data and logical predicates inspired by the Clinical Quality Language (CQL). The solution involves a rigorous, step-by-step application of set theory and predicate logic to a fixed dataset for multiple time periods.\n\nThe core of the problem is to determine, for a given measurement period, the membership of two sets: the Denominator set, $D$, and the Numerator set, $N$. The universal set, $\\mathcal{P}$, consists of the six provided patients, $\\{P1, P2, P3, P4, P5, P6\\}$. The measurement period is defined by a closed interval of dates, $[t_{\\min}, t_{\\max}]$.\n\nThe final measure rate, $R$, is the ratio of the cardinalities of these sets:\n$$R = \\begin{cases} \\frac{|N|}{|D|} & \\text{if } |D| > 0 \\\\ 0.0 & \\text{if } |D| = 0 \\end{cases}$$\nThe rate $R$ must be rounded to three decimal places, with the rule that a value is rounded up if the fourth decimal digit is $5$ or greater.\n\nThe membership of the Denominator and Numerator sets is determined by a series of logical predicates.\n\n**1. Denominator ($D$) Predicates**\n\nA patient $p \\in \\mathcal{P}$ is a member of the denominator set $D$ if and only if they satisfy three conditions simultaneously:\n$p \\in D \\iff \\text{IsAdult}(p, t_{\\max}) \\land \\text{HasHypertension}(p, t_{\\max}) \\land \\text{HadEncounter}(p, [t_{\\min}, t_{\\max}])$\n\nLet us define each predicate:\n\n- $\\text{IsAdult}(p, t_{\\max})$: This predicate is true if the patient's age, $A$, on the measurement period end date, $t_{\\max}$, falls within the range $[18, 85]$. The age is calculated as $A = \\left\\lfloor \\frac{t_{\\max} - d_{\\text{birth}}}{\\text{one year}} \\right\\rfloor$, where $d_{\\text{birth}}$ is the patient's birth date. The calculation follows a calendrical difference: first the difference in years is taken, and then one year is subtracted if the month and day of $t_{\\max}$ precede the month and day of $d_{\\text{birth}}$.\n\n- $\\text{HasHypertension}(p, t_{\\max})$: This predicate is true if the patient has a recorded Condition with the ICD-10-CM code `I10` and the onset date of this condition is on or before $t_{\\max}$.\n\n- $\\text{HadEncounter}(p, [t_{\\min}, t_{\\max}])$: This predicate is true if the patient has at least one Encounter record whose date, $t_{\\text{enc}}$, occurs within the measurement period, i.e., $t_{\\min} \\le t_{\\text{enc}} \\le t_{\\max}$.\n\n**2. Numerator ($N$) Predicate**\n\nThe Numerator, $N$, is a subset of the Denominator, $D$. A patient $p \\in D$ is a member of the numerator set $N$ if they meet the blood pressure control criteria.\n$p \\in N \\iff p \\in D \\land \\text{IsControlled}(p, [t_{\\min}, t_{\\max}])$\n\n- $\\text{IsControlled}(p, [t_{\\min}, t_{\\max}])$: This predicate's evaluation involves several steps:\n    1. Identify all Blood Pressure Observations for patient $p$ that occurred within the measurement period $[t_{\\min}, t_{\\max}]$. An observation is valid only if it has both a systolic (`8480-6`) and a diastolic (`8462-4`) component.\n    2. If no such observations exist within the period, the predicate is false.\n    3. If one or more such observations exist, select the most recent one (the one with the maximum observation date, $t_{\\text{obs}}$).\n    4. For this most recent observation, the predicate is true if and only if its systolic value is less than $140$ mmHg and its diastolic value is less than $90$ mmHg. Note the strict inequalities: values of $140$ or $90$ are not considered controlled.\n\n**3. Algorithmic Implementation**\n\nThe solution is implemented by creating a computational workflow that processes each patient against the predicates for each of the four specified test cases (measurement periods).\n\nFirst, the patient data is stored in a structured format, such as a list of dictionaries, to facilitate access to attributes like `birthDate`, `conditions`, `encounters`, and `observations`.\n\nFor each test case $[t_{\\min}, t_{\\max}]$:\n1. Initialize a denominator count $D_{count} = 0$ and a numerator count $N_{count} = 0$.\n2. Iterate through each patient $p \\in \\mathcal{P}$.\n3. For each patient, evaluate the three denominator predicates: $\\text{IsAdult}$, $\\text{HasHypertension}$, and $\\text{HadEncounter}$.\n4. If all three are true, increment $D_{count}$ by $1$. Then, proceed to evaluate the numerator predicate $\\text{IsControlled}$ for this patient.\n5. If $\\text{IsControlled}$ is also true, increment $N_{count}$ by $1$.\n6. After iterating through all patients, calculate the rate $R$. If $D_{count} > 0$, $R = N_{count} / D_{count}$. Otherwise, $R = 0.0$.\n7. The calculated rate $R$ is rounded to $3$ decimal places. For a non-negative number $x$, this is achieved by computing $\\frac{\\lfloor x \\cdot 10^3 + 0.5 \\rfloor}{10^3}$.\n8. The final formatted string is generated for each rate, ensuring three decimal places are always displayed (e.g., $0.5$ becomes $0.500$). The results from all test cases are compiled into the required list format. This entire process is deterministic and produces a unique, verifiable result.", "answer": "```python\nimport numpy as np\nfrom datetime import date\n\ndef solve():\n    \"\"\"\n    Evaluates a blood pressure control quality measure for a fixed cohort of patients\n    across multiple measurement windows, based on specified CQL-like semantics.\n    \"\"\"\n    \n    # --- Data Representation ---\n    # The fixed cohort of sample FHIR-like resources, embedded directly.\n    patients = [\n        {\n            \"id\": \"P1\", \"birthDate\": \"1967-05-20\",\n            \"conditions\": [{\"code\": \"I10\", \"onset\": \"2010-01-01\"}],\n            \"encounters\": [{\"date\": \"2022-06-01\"}],\n            \"observations\": [\n                {\"date\": \"2022-06-01\", \"systolic\": 138, \"diastolic\": 88},\n                {\"date\": \"2022-09-01\", \"systolic\": 142, \"diastolic\": 85},\n            ],\n        },\n        {\n            \"id\": \"P2\", \"birthDate\": \"1955-02-10\",\n            \"conditions\": [{\"code\": \"I10\", \"onset\": \"2015-01-01\"}],\n            \"encounters\": [{\"date\": \"2022-11-01\"}],\n            \"observations\": [\n                {\"date\": \"2022-03-03\", \"systolic\": 139, \"diastolic\": 91},\n                {\"date\": \"2022-11-01\", \"systolic\": 134, \"diastolic\": 88},\n            ],\n        },\n        {\n            \"id\": \"P3\", \"birthDate\": \"1977-08-01\",\n            \"conditions\": [{\"code\": \"I10\", \"onset\": \"2020-06-01\"}],\n            \"encounters\": [{\"date\": \"2022-05-10\"}],\n            \"observations\": [\n                {\"date\": \"2021-12-30\", \"systolic\": 130, \"diastolic\": 80},\n            ],\n        },\n        {\n            \"id\": \"P4\", \"birthDate\": \"1938-01-01\",\n            \"conditions\": [{\"code\": \"I10\", \"onset\": \"2000-01-01\"}],\n            \"encounters\": [{\"date\": \"2022-12-31\"}],\n            \"observations\": [\n                {\"date\": \"2022-12-31\", \"systolic\": 140, \"diastolic\": 90},\n            ],\n        },\n        {\n            \"id\": \"P5\", \"birthDate\": \"1992-09-15\",\n            \"conditions\": [],\n            \"encounters\": [{\"date\": \"2022-10-10\"}],\n            \"observations\": [\n                {\"date\": \"2022-10-10\", \"systolic\": 120, \"diastolic\": 70},\n            ],\n        },\n        {\n            \"id\": \"P6\", \"birthDate\": \"2004-12-31\",\n            \"conditions\": [{\"code\": \"I10\", \"onset\": \"2022-06-01\"}],\n            \"encounters\": [{\"date\": \"2022-07-01\"}],\n            \"observations\": [\n                {\"date\": \"2022-08-01\", \"systolic\": 138, \"diastolic\": 89},\n            ],\n        },\n    ]\n\n    # Test cases defined by measurement periods [t_min, t_max].\n    test_cases = [\n        (\"2022-01-01\", \"2022-12-31\"),\n        (\"2022-09-02\", \"2022-12-31\"),\n        (\"2022-01-01\", \"2022-06-30\"),\n        (\"2023-01-01\", \"2023-12-31\"),\n    ]\n\n    # --- Predicate Implementations ---\n\n    def calculate_age(birth_date_obj, ref_date_obj):\n        \"\"\"Calculates age in years based on calendrical difference.\"\"\"\n        age = ref_date_obj.year - birth_date_obj.year\n        if (ref_date_obj.month, ref_date_obj.day) < (birth_date_obj.month, birth_date_obj.day):\n            age -= 1\n        return age\n\n    def is_adult(patient, t_max_obj):\n        \"\"\"Checks if patient is between 18 and 85 years old.\"\"\"\n        birth_date_obj = date.fromisoformat(patient[\"birthDate\"])\n        age = calculate_age(birth_date_obj, t_max_obj)\n        return 18 <= age <= 85\n\n    def has_hypertension(patient, t_max_obj):\n        \"\"\"Checks for an active hypertension diagnosis.\"\"\"\n        for condition in patient[\"conditions\"]:\n            if condition[\"code\"] == \"I10\":\n                onset_date_obj = date.fromisoformat(condition[\"onset\"])\n                if onset_date_obj <= t_max_obj:\n                    return True\n        return False\n\n    def had_encounter_in_period(patient, t_min_obj, t_max_obj):\n        \"\"\"Checks for an encounter within the measurement period.\"\"\"\n        for encounter in patient[\"encounters\"]:\n            encounter_date_obj = date.fromisoformat(encounter[\"date\"])\n            if t_min_obj <= encounter_date_obj <= t_max_obj:\n                return True\n        return False\n\n    def is_in_numerator(patient, t_min_obj, t_max_obj):\n        \"\"\"Checks if the patient's blood pressure is controlled.\"\"\"\n        valid_obs = []\n        for obs in patient[\"observations\"]:\n            obs_date_obj = date.fromisoformat(obs[\"date\"])\n            if t_min_obj <= obs_date_obj <= t_max_obj:\n                valid_obs.append(obs)\n        \n        if not valid_obs:\n            return False\n            \n        # Find the most recent observation by sorting\n        most_recent_obs = sorted(valid_obs, key=lambda x: x[\"date\"], reverse=True)[0]\n        \n        return most_recent_obs[\"systolic\"] < 140 and most_recent_obs[\"diastolic\"] < 90\n\n    # --- Main Calculation Loop ---\n    \n    results = []\n    for t_min_str, t_max_str in test_cases:\n        t_min_obj = date.fromisoformat(t_min_str)\n        t_max_obj = date.fromisoformat(t_max_str)\n        \n        denominator_count = 0\n        numerator_count = 0\n        \n        for p in patients:\n            in_denominator = (\n                is_adult(p, t_max_obj) and\n                has_hypertension(p, t_max_obj) and\n                had_encounter_in_period(p, t_min_obj, t_max_obj)\n            )\n            \n            if in_denominator:\n                denominator_count += 1\n                if is_in_numerator(p, t_min_obj, t_max_obj):\n                    numerator_count += 1\n        \n        if denominator_count == 0:\n            rate = 0.0\n        else:\n            rate = numerator_count / denominator_count\n        \n        # Round to 3 decimal places (half away from zero for positive numbers)\n        rounded_rate = np.floor(rate * 1000 + 0.5) / 1000\n        results.append(f\"{rounded_rate:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4844528"}, {"introduction": "While structured data is clean, much of the rich clinical narrative resides in free-text notes. This practice dives into the world of Natural Language Processing (NLP) to extract critical information for quality measurement—a patient's smoking status and whether cessation counseling was provided. You will build a rule-based system to classify notes and then evaluate its performance against a gold standard, learning firsthand about the essential metrics of precision and recall. [@problem_id:4844499]", "problem": "You are tasked with implementing a rule-based Natural Language Processing (NLP) pipeline to support a healthcare quality measurement concerning tobacco cessation counseling. The computational problem must start from foundational definitions and produce quantifiable outputs suitable for evaluation. The setting is the automated extraction of a patient's smoking status and documentation of tobacco cessation counseling from unstructured clinical notes, followed by quality measure numerator inclusion determination and metric evaluation.\n\nBegin with the following widely accepted foundational base: a patient’s smoking status can be operationally categorized into mutually exclusive classes for measurement purposes, and detection quality can be quantified using confusion-matrix-based metrics. Specifically, let the smoking status classification be one of the following labels: *current*, *former*, *never*, or *unknown*. Let the quality measure numerator inclusion be defined for a note as the event that the note documents tobacco cessation counseling for a patient who is a *current* tobacco user. For evaluation of the classifier that determines numerator inclusion from notes, use the following definitions. Define the true positives as $TP$, the false positives as $FP$, the false negatives as $FN$, and compute precision and recall using the well-tested formulas\n$$\\text{precision} = \\frac{TP}{TP + FP}$$\n$$\\text{recall} = \\frac{TP}{TP + FN}$$\nwith the convention that if the denominator of either fraction is $0$, the corresponding metric is defined to be $0$.\n\nYou must implement a deterministic, rule-based NLP that operates as follows, using only lowercased text normalization and whitespace or punctuation tokenization:\n- Use a negation detection window of $w$ tokens preceding a target term. A term is considered negated if any token from a specified negation set appears within $w$ tokens before the target token.\n- Smoking status classification rules:\n  1. Detect *current* if any current-indicator token appears un-negated. Current-indicator tokens include “smokes”, “smoker”, “smoking”, “cigarettes”, “ppd”, and the multiword phrase “tobacco user”.\n  2. If *current* is not detected, detect *former* if any former-indicator phrase appears. Former-indicator phrases include “former smoker”, “ex-smoker”, “quit smoking”, and “stopped smoking”.\n  3. If neither *current* nor *former* is detected, detect *never* if any never-indicator phrase appears. Never-indicator phrases include “never smoked”, “never smoker”, “non-smoker”, and “denies smoking”.\n  4. If none of the above rules apply, classify as *unknown*.\n  In case of conflicting mentions, *current* takes precedence over *former*, which takes precedence over *never*, by virtue of rule ordering. Negations should neutralize target terms within the window; for example, “not currently smoking” must not trigger *current*.\n- Counseling detection rules:\n  1. Counseling is present if any counseling head token appears un-negated. Counseling head tokens include “counseling”, “counseled”, “advised”, “advice”, “discussed”, “education”, “interviewing”, and the multiword phrase “nicotine patch discussed”.\n  2. Negation tokens include “no”, “not”, “denies”, “denied”, “without”, “declined”, and “refused”. If any negation token occurs within $w$ tokens before a counseling head token, treat the counseling mention as negated and therefore not present.\n- Numerator inclusion determination for each note: assign $N=1$ if the classified smoking status is *current* and counseling is detected; otherwise assign $N=0$.\n\nEvaluation procedure:\n- For each test case, you are given a list of clinical notes and a corresponding list of gold-standard numerator inclusion labels $G$ as integers in $\\{0,1\\}$. Apply the above rules to each note to compute predicted numerator inclusion $\\hat{N}$, form the counts $TP$, $FP$, and $FN$, and compute $\\text{precision}$ and $\\text{recall}$ as described above. All metric values must be reported as decimals rounded to $3$ decimal places (e.g., $0.875$), without any percentage sign.\n\nImplement the program to process the following test suite with window size $w=4$, producing results in the order of the test cases. For each test case, compute two floats: precision and recall. The final output must be a single line containing a comma-separated list enclosed in square brackets with the eight floats in the order $[\\text{precision}_1,\\text{recall}_1,\\text{precision}_2,\\text{recall}_2,\\text{precision}_3,\\text{recall}_3,\\text{precision}_4,\\text{recall}_4]$.\n\nTest Suite (each test case provides clinical notes and gold-standard numerator inclusion labels):\n- Test Case $1$ (general mixed documentation):\n  Notes:\n  1. “Patient smokes 1 ppd and received smoking cessation counseling today.”\n  2. “Former smoker, quit in 2018; advised to quit not applicable.”\n  3. “Non-smoker. No cessation counseling provided.”\n  4. “Smoker denies interest in quitting; counseled on nicotine replacement.”\n  5. “Denies smoking; offered stop smoking counseling.”\n  Gold $G$: $[1,0,0,1,0]$.\n- Test Case $2$ (negations and future intent):\n  Notes:\n  1. “Smokes cigars occasionally; declined cessation counseling.”\n  2. “Tobacco user; no counseling done.”\n  3. “Smoker; counseling provided.”\n  4. “Smokes daily; counseling at future visit.”\n  Gold $G$: $[0,0,1,0]$.\n- Test Case $3$ (boundary case: no current smokers):\n  Notes:\n  1. “Never smoked; counseled to maintain abstinence.”\n  2. “Non-smoker; smoking cessation counseling not indicated.”\n  3. “Denies smoking; no counseling.”\n  Gold $G$: $[0,0,0]$.\n- Test Case $4$ (conflicting mentions and window boundary):\n  Notes:\n  1. “Former smoker, not currently smoking; counseled.”\n  2. “Current smoker; no advice to quit.”\n  3. “Smoker with 2 ppd; brief advice to quit provided.”\n  4. “Quit smoking last year; still smokes socially.”\n  5. “Tobacco user, refused counseling.”\n  Gold $G$: $[0,0,1,0,0]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., “[$0.750,0.600,0.500,0.667,0.000,0.000,1.000,1.000]”). All computed metric values must be rounded to $3$ decimal places as decimals. No physical units are involved; do not use percentage signs.", "solution": "The user has provided a computational problem in the domain of clinical Natural Language Processing (NLP) for healthcare quality measurement. The task is to implement a specific, deterministic rule-based system and evaluate its performance on a provided test suite.\n\n### Step 1: Problem Validation\n\nThe problem statement is validated against the required criteria.\n\n**Extracted Givens:**\n- **Task**: Implement a rule-based NLP pipeline to determine numerator inclusion for a tobacco cessation counseling quality measure.\n- **Smoking Status Categories**: *current*, *former*, *never*, *unknown*.\n- **Numerator Inclusion Definition**: A note is included ($N=1$) if the classified smoking status is *current* and counseling is documented; otherwise, $N=0$.\n- **Evaluation Metrics**:\n    - True Positives ($TP$), False Positives ($FP$), False Negatives ($FN$).\n    - Precision: $\\text{precision} = \\frac{TP}{TP + FP}$. If $TP + FP = 0$, precision is $0$.\n    - Recall: $\\text{recall} = \\frac{TP}{TP + FN}$. If $TP + FN = 0$, recall is $0$.\n- **NLP Rules**:\n    - **Preprocessing**: Lowercased text, tokenization by whitespace or punctuation.\n    - **Negation**: Window size $w=4$ tokens preceding a target term.\n    - **Negation Tokens**: `no`, `not`, `denies`, `denied`, `without`, `declined`, `refused`.\n    - **Smoking Status Rules (in order of precedence)**:\n        1.  *current*: Un-negated mention of tokens `smokes`, `smoker`, `smoking`, `cigarettes`, `ppd`, or the phrase `tobacco user`.\n        2.  *former*: If not *current*, mention of phrases `former smoker`, `ex-smoker`, `quit smoking`, `stopped smoking`.\n        3.  *never*: If not *current* or *former*, mention of phrases `never smoked`, `never smoker`, `non-smoker`, `denies smoking`.\n        4.  *unknown*: Otherwise.\n    - **Counseling Detection Rules**:\n        1. Presence is indicated by an un-negated mention of tokens `counseling`, `counseled`, `advised`, `advice`, `discussed`, `education`, `interviewing`, or the phrase `nicotine patch discussed`.\n- **Test Suite**: Four test cases are provided, each with a list of clinical notes and a list of gold-standard numerator inclusion labels ($G$).\n- **Output Format**: A single-line comma-separated list of eight floating-point numbers (precision and recall for each of the four test cases), rounded to 3 decimal places, enclosed in square brackets.\n\n**Validation Verdict:**\nThe problem is **valid**. It is scientifically grounded in established NLP and healthcare quality measurement principles. The problem is well-posed, with a deterministic set of rules that allow for an unambiguous, unique solution. The language is objective and precise. The instructions are self-contained and consistent, providing all necessary definitions, rules, and data to solve the problem. The task is to implement the specified algorithm and report its performance, which is a standard scientific computing task.\n\n### Step 2: Solution Design\n\nThe solution will be implemented as a Python class that encapsulates the logic of the rule-based NLP system. This design promotes modularity and clarity. The process for each clinical note involves three main stages: preprocessing, rule-based classification, and numerator determination.\n\n**1. Preprocessing:**\nFirst, a preprocessing function will prepare the input text. This function will convert the entire text to lowercase, as specified. To handle the multi-word phrases (e.g., `tobacco user`, `former smoker`), they will be replaced with unique single-token representations (e.g., `tobacco_user`, `former_smoker`). This simplifies the subsequent token-level analysis. To ensure correctness with potentially overlapping phrases, the substitution will be performed on phrases sorted by length in descending order. Finally, the processed text will be tokenized. A regular expression, `\\b\\w+\\b`, will be used to extract alphanumeric sequences, which robustly interprets the \"whitespace or punctuation tokenization\" rule by treating words as the fundamental units.\n\n**2. Rule-Based Classification:**\nThe core of the system lies in two classification functions: one for smoking status and one for counseling detection. Both will operate on the tokenized text.\n\n- **Negation Detection**: A helper function, `_is_negated(tokens, index)`, will determine if a token at a given `index` is negated. It will inspect the $w=4$ tokens immediately preceding the target token. If any token in this window belongs to the specified set of negation terms, the target is considered negated.\n\n- **Smoking Status Classification**: This function, `get_smoking_status(text)`, will implement the specified hierarchical rule set.\n    1.  It iterates through the tokens to find any *current* indicator. If an un-negated indicator is found, it immediately returns *current*.\n    2.  If no *current* indicators are found, it then searches for any *former* indicator phrase (in its single-token form). If found, it returns *former*. Notably, the problem does not specify negation detection for *former* or *never* phrases, so they are matched directly.\n    3.  If neither of the above, it searches for *never* indicator phrases and returns *never* if one is found.\n    4.  If none of the rules fire, it returns *unknown*.\n\n- **Counseling Detection**: The function `has_counseling(text)` will iterate through the tokens to find any counseling indicator. For each potential indicator, it checks if it is negated using the same negation logic. If an un-negated counseling indicator is found, the function returns `True`. If the entire text is scanned without finding one, it returns `False`.\n\n**3. Numerator Inclusion and Evaluation:**\n- **Numerator Determination**: A function `get_numerator_inclusion(text)` will orchestrate the process. It will call the smoking status and counseling detection functions. It returns $1$ if the status is *current* and counseling is `True`, and $0$ otherwise.\n\n- **Evaluation**: An `evaluate_case` function will take the list of notes and gold-standard labels for a test case. It will generate a prediction for each note, then compute the total counts for $TP$, $FP$, and $FN$. From these counts, it will calculate `precision` and `recall` using the provided formulas, including the special condition for denominators equal to zero. The results will be rounded to $3$ decimal places.\n\nFinally, the main `solve` function will initialize the test suite data, instantiate the NLP pipeline, and iterate through each test case to compute and collect the metrics. The final aggregated results will be formatted into the required single-line string output.", "answer": "```python\nimport re\nimport numpy as np\n\nclass RuleBasedNLP:\n    \"\"\"\n    Implements a deterministic, rule-based NLP pipeline for healthcare quality measurement\n    concerning tobacco cessation counseling.\n    \"\"\"\n    def __init__(self, w=4):\n        \"\"\"\n        Initializes the NLP pipeline with a given negation window size.\n        \n        Args:\n            w (int): The number of preceding tokens to check for negation.\n        \"\"\"\n        self.w = w\n        self.negation_tokens = {'no', 'not', 'denies', 'denied', 'without', 'declined', 'refused'}\n\n        # Multi-word phrases are defined and will be replaced by single tokens.\n        # They are sorted by length (desc) to handle cases where one phrase is a substring of another.\n        phrases = {\n            'nicotine patch discussed': 'nicotine_patch_discussed',\n            'stopped smoking': 'stopped_smoking',\n            'denies smoking': 'denies_smoking',\n            'former smoker': 'former_smoker',\n            'quit smoking': 'quit_smoking',\n            'never smoked': 'never_smoked',\n            'never smoker': 'never_smoker',\n            'tobacco user': 'tobacco_user',\n            'non-smoker': 'non_smoker',\n            'ex-smoker': 'ex_smoker',\n        }\n        self.phrases = dict(sorted(phrases.items(), key=lambda item: len(item[0]), reverse=True))\n\n        # Define token sets for each category\n        self.current_indicators = {'smokes', 'smoker', 'smoking', 'cigarettes', 'ppd', 'tobacco_user'}\n        self.former_indicators = {'former_smoker', 'ex_smoker', 'quit_smoking', 'stopped_smoking'}\n        self.never_indicators = {'never_smoked', 'never_smoker', 'non_smoker', 'denies_smoking'}\n        self.counseling_indicators = {\n            'counseling', 'counseled', 'advised', 'advice', 'discussed', \n            'education', 'interviewing', 'nicotine_patch_discussed'\n        }\n\n    def _preprocess_and_tokenize(self, text):\n        \"\"\"\n        Lowercases, replaces multi-word phrases, and tokenizes the text.\n        \"\"\"\n        processed_text = text.lower()\n        for phrase, token in self.phrases.items():\n            processed_text = processed_text.replace(phrase, token)\n        return re.findall(r'\\b\\w+\\b', processed_text)\n\n    def _is_negated(self, tokens, index):\n        \"\"\"\n        Checks if a token at a given index is negated by a preceding token.\n        \"\"\"\n        start = max(0, index - self.w)\n        window = tokens[start:index]\n        return any(token in self.negation_tokens for token in window)\n\n    def get_smoking_status(self, text):\n        \"\"\"\n        Classifies smoking status based on a hierarchical rule set.\n        \"\"\"\n        tokens = self._preprocess_and_tokenize(text)\n        \n        # Rule 1: Detect \"current\" status. This has the highest precedence.\n        for i, token in enumerate(tokens):\n            if token in self.current_indicators and not self._is_negated(tokens, i):\n                return 'current'\n        \n        # Rule 2: Detect \"former\" status.\n        for token in tokens:\n            if token in self.former_indicators:\n                return 'former'\n        \n        # Rule 3: Detect \"never\" status.\n        for token in tokens:\n            if token in self.never_indicators:\n                return 'never'\n                \n        # Rule 4: Default to \"unknown\".\n        return 'unknown'\n\n    def has_counseling(self, text):\n        \"\"\"\n        Detects if counseling is documented and not negated.\n        \"\"\"\n        tokens = self._preprocess_and_tokenize(text)\n        for i, token in enumerate(tokens):\n            if token in self.counseling_indicators and not self._is_negated(tokens, i):\n                return True\n        return False\n\n    def get_numerator_inclusion(self, text):\n        \"\"\"\n        Determines numerator inclusion (N=1) if status is 'current' and counseling is present.\n        \"\"\"\n        smoking_status = self.get_smoking_status(text)\n        counseling_present = self.has_counseling(text)\n        \n        if smoking_status == 'current' and counseling_present:\n            return 1\n        return 0\n\ndef evaluate_case(nlp_pipeline, notes, gold_labels):\n    \"\"\"\n    Evaluates the NLP pipeline against gold standard labels for a single test case.\n    \"\"\"\n    tp, fp, fn = 0, 0, 0\n    predictions = [nlp_pipeline.get_numerator_inclusion(note) for note in notes]\n    \n    for pred, gold in zip(predictions, gold_labels):\n        if pred == 1 and gold == 1:\n            tp += 1\n        elif pred == 1 and gold == 0:\n            fp += 1\n        elif pred == 0 and gold == 1:\n            fn += 1\n            \n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    \n    return round(precision, 3), round(recall, 3)\n\ndef solve():\n    \"\"\"\n    Main function to run the NLP pipeline on the test suite and print results.\n    \"\"\"\n    test_suite = [\n        {\n            \"notes\": [\n                \"Patient smokes 1 ppd and received smoking cessation counseling today.\",\n                \"Former smoker, quit in 2018; advised to quit not applicable.\",\n                \"Non-smoker. No cessation counseling provided.\",\n                \"Smoker denies interest in quitting; counseled on nicotine replacement.\",\n                \"Denies smoking; offered stop smoking counseling.\",\n            ],\n            \"gold\": [1, 0, 0, 1, 0],\n        },\n        {\n            \"notes\": [\n                \"Smokes cigars occasionally; declined cessation counseling.\",\n                \"Tobacco user; no counseling done.\",\n                \"Smoker; counseling provided.\",\n                \"Smokes daily; counseling at future visit.\",\n            ],\n            \"gold\": [0, 0, 1, 0],\n        },\n        {\n            \"notes\": [\n                \"Never smoked; counseled to maintain abstinence.\",\n                \"Non-smoker; smoking cessation counseling not indicated.\",\n                \"Denies smoking; no counseling.\",\n            ],\n            \"gold\": [0, 0, 0],\n        },\n        {\n            \"notes\": [\n                \"Former smoker, not currently smoking; counseled.\",\n                \"Current smoker; no advice to quit.\",\n                \"Smoker with 2 ppd; brief advice to quit provided.\",\n                \"Quit smoking last year; still smokes socially.\",\n                \"Tobacco user, refused counseling.\",\n            ],\n            \"gold\": [0, 0, 1, 0, 0],\n        }\n    ]\n\n    nlp = RuleBasedNLP(w=4)\n    all_results = []\n    \n    for case in test_suite:\n        precision, recall = evaluate_case(nlp, case[\"notes\"], case[\"gold\"])\n        all_results.extend([precision, recall])\n        \n    print(f\"[{','.join(f'{x:.3f}' for x in all_results)}]\")\n\nsolve()\n```", "id": "4844499"}, {"introduction": "Quality measurement is not just about a single snapshot in time; it's about tracking performance to drive and sustain improvement. This final practice introduces you to statistical process control through the implementation of a Cumulative Sum (CUSUM) chart. You will use this powerful technique to monitor postoperative complication rates and determine if a quality improvement initiative has resulted in a statistically meaningful and lasting positive change. [@problem_id:4844492]", "problem": "You are tasked with implementing a one-sided cumulative sum (CUSUM) procedure to monitor postoperative complication rates and detect sustained improvements following a Quality Improvement (QI) intervention. The monitoring is based on binary observations for individual postoperative cases, where each case is an independent Bernoulli trial. Your program must compute decision interval thresholds, construct the CUSUM using the log-likelihood ratio, detect the earliest improvement signal after the QI intervention, and determine whether the improvement is sustained.\n\nFoundational base:\n\n- Let $x_i \\in \\{0,1\\}$ denote the outcome of case $i$, where $x_i = 1$ indicates a complication and $x_i = 0$ indicates no complication. The outcomes are modeled as independent Bernoulli random variables with parameter $p$, where $p$ is the complication rate.\n- Under the null hypothesis of no improvement, $H_0: p = p_0$, and under the alternative hypothesis of improvement, $H_1: p = p_1$, with $p_1 < p_0$. All rates must be expressed as decimals (e.g., $0.15$ for $15$ out of $100$).\n- The Bernoulli probability mass function is $f(x \\mid p) = p^x (1-p)^{1-x}$.\n- The Sequential Probability Ratio Test (SPRT) uses the log-likelihood ratio increment $$w_i = \\log\\left(\\frac{f(x_i \\mid p_1)}{f(x_i \\mid p_0)}\\right) = x_i \\log\\left(\\frac{p_1}{p_0}\\right) + (1-x_i)\\log\\left(\\frac{1-p_1}{1-p_0}\\right).$$\n- Page’s CUSUM statistic for improvement is defined recursively by $$S_t = \\max\\left(0, S_{t-1} + w_t\\right), \\quad S_0 = 0,$$ where the recursion is applied starting at the QI intervention index $t_{\\mathrm{QI}}$ and proceeding forward.\n- Decision interval thresholds derived from SPRT error control are $$h_+ = \\log\\left(\\frac{1-\\beta}{\\alpha}\\right) \\quad \\text{and} \\quad h_- = \\log\\left(\\frac{\\beta}{1-\\alpha}\\right),$$ where $\\alpha$ is the Type I error (false signal probability) under $H_0$ and $\\beta$ is the Type II error (missed detection probability) under $H_1$. For one-sided improvement detection, a signal occurs when $S_t \\ge h_+$.\n\nDetection and sustained improvement criteria:\n\n- Define the earliest improvement signal time $t^\\star$ as the smallest $t \\ge t_{\\mathrm{QI}}$ such that $S_t \\ge h_+$. If no such $t$ exists, set $t^\\star = -1$.\n- Sustained improvement is declared if and only if $t^\\star \\neq -1$, there are at least $w$ observations after $t^\\star$, and the empirical mean complication rate in the next $w$ observations, $$\\hat{p} = \\frac{1}{w}\\sum_{i=t^\\star+1}^{t^\\star+w} x_i,$$ satisfies $\\hat{p} \\le p_1$.\n\nImplementation requirements:\n\n- Input data for each test case consists of $(p_0, p_1, \\alpha, \\beta, t_{\\mathrm{QI}}, w, \\{x_i\\}_{i=0}^{n-1})$. All complication rates $p_0$ and $p_1$ must be decimals. The QI index $t_{\\mathrm{QI}}$ is the $0$-based index in the sequence at which the intervention begins, and the CUSUM should be accumulated starting at $t_{\\mathrm{QI}}$.\n- Your program should compute $h_+$ and $h_-$, the earliest detection index $t^\\star$, and the sustained improvement boolean for each test case.\n- For each test case, output a list of the form $[t^\\star, \\text{sustained}, h_+, h_-]$, where $t^\\star$ is an integer, sustained is a boolean, and $h_+, h_-$ are floats rounded to six decimal places.\n\nTest suite:\n\nUse the following four test cases to exercise different scenarios. For each case, the sequence $\\{x_i\\}$ is provided explicitly and the QI index $t_{\\mathrm{QI}}$ indicates where to start the CUSUM accumulation.\n\n- Case A (happy path with sustained improvement):\n    - $p_0 = 0.15$, $p_1 = 0.07$, $\\alpha = 0.20$, $\\beta = 0.20$, $t_{\\mathrm{QI}} = 20$, $w = 15$,\n    - $\\{x_i\\}$ (length $60$): $[0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,\\; 0,0,0,0,0,0,1,\\; 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$.\n- Case B (improvement too weak, no signal):\n    - $p_0 = 0.15$, $p_1 = 0.10$, $\\alpha = 0.10$, $\\beta = 0.20$, $t_{\\mathrm{QI}} = 20$, $w = 10$,\n    - $\\{x_i\\}$ (length $50$): $[0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,\\; 0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0]$.\n- Case C (no complications after QI, strong sustained improvement):\n    - $p_0 = 0.25$, $p_1 = 0.10$, $\\alpha = 0.10$, $\\beta = 0.10$, $t_{\\mathrm{QI}} = 10$, $w = 20$,\n    - $\\{x_i\\}$ (length $36$): $[0,1,0,0,1,0,0,0,1,0,\\; 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$.\n- Case D (signal occurs but insufficient follow-up for sustained improvement):\n    - $p_0 = 0.20$, $p_1 = 0.05$, $\\alpha = 0.15$, $\\beta = 0.15$, $t_{\\mathrm{QI}} = 30$, $w = 25$,\n    - $\\{x_i\\}$ (length $50$): $[0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,\\; 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]$.\n\nFinal output format:\n\n- Your program should produce a single line of output containing a list of the per-case results in order Case A, Case B, Case C, Case D, as a comma-separated list enclosed in square brackets. Each per-case result must be a list in the form $[t^\\star, \\text{sustained}, h_+, h_-]$, with $h_+$ and $h_-$ rounded to six decimal places. For example: $[[t^\\star_A,\\text{sustained}_A,h_{+,A},h_{-,A}], [t^\\star_B,\\text{sustained}_B,h_{+,B},h_{-,B}], [\\dots], [\\dots]]$.", "solution": "The problem statement is deemed valid. It is scientifically grounded in the established statistical theory of Sequential Probability Ratio Tests (SPRT) and Cumulative Sum (CUSUM) charts, which are standard methodologies in statistical process control and healthcare quality improvement. The problem is well-posed, providing all necessary definitions, data, and unambiguous criteria for a unique solution. The parameters and scenarios are realistic. A minor discrepancy was noted in the descriptive text for Test Case C, which states a data sequence length of $36$ while the original text suggested a length of $45$. This is interpreted as a non-fatal typographical error, and the solution will proceed using the explicitly provided data sequence, as its structure is complete and sufficient for the analysis.\n\nThe solution is implemented by following the defined statistical procedure. We analyze a series of postoperative outcomes, $\\{x_i\\}_{i=0}^{n-1}$, where each outcome is a Bernoulli trial. An outcome $x_i=1$ represents a complication, and $x_i=0$ represents no complication. The historical complication rate is $p_0$, and the target rate following a Quality Improvement (QI) intervention is $p_1$, with $p_1 < p_0$. The QI intervention is initiated at case index $t_{\\mathrm{QI}}$.\n\nThe core of the CUSUM procedure is the log-likelihood ratio, which quantifies the evidence provided by each observation in favor of the alternative hypothesis $H_1: p=p_1$ (improvement) against the null hypothesis $H_0: p=p_0$ (no improvement). The probability mass function of a Bernoulli random variable is $f(x \\mid p) = p^x (1-p)^{1-x}$. The log-likelihood ratio for a single observation $x_i$ is given by:\n$$w_i = \\log\\left(\\frac{f(x_i \\mid p_1)}{f(x_i \\mid p_0)}\\right) = x_i \\log\\left(\\frac{p_1}{p_0}\\right) + (1-x_i)\\log\\left(\\frac{1-p_1}{1-p_0}\\right)$$\nSince $p_1 < p_0$, the term $\\log(p_1/p_0)$ is negative, and $\\log((1-p_1)/(1-p_0))$ is positive. Thus, a complication ($x_i=1$) decreases the cumulative sum, providing evidence against improvement, while no complication ($x_i=0$) increases it, providing evidence for improvement.\n\nThe CUSUM statistic, $S_t$, is accumulated sequentially for each case $t$ at or after the intervention ($t \\ge t_{\\mathrm{QI}}$). It is defined by the recursion:\n$$S_t = \\max(0, S_{t-1} + w_t)$$\nThe CUSUM process is initialized with $S_{t_{\\mathrm{QI}}-1} = 0$. The $\\max(0, \\cdot)$ operation ensures the CUSUM resets to $0$ if the cumulative evidence trends against improvement, making it a one-sided test for improvement.\n\nA signal for improvement is triggered when the CUSUM statistic $S_t$ crosses a predefined upper decision threshold, $h_+$. This threshold is derived from the Type I error rate $\\alpha$ (the probability of a false signal) and the Type II error rate $\\beta$ (the probability of missing a true improvement). The upper and lower thresholds for a two-sided SPRT are:\n$$h_+ = \\log\\left(\\frac{1-\\beta}{\\alpha}\\right)$$\n$$h_- = \\log\\left(\\frac{\\beta}{1-\\alpha}\\right)$$\nFor this one-sided test for improvement, a signal occurs only when $S_t \\ge h_+$. The problem requires the calculation of both $h_+$ and $h_-$.\n\nThe algorithmic procedure for each test case is as follows:\n\n1.  **Initialization**: Given the parameters $(p_0, p_1, \\alpha, \\beta, t_{\\mathrm{QI}}, w, \\{x_i\\}_{i=0}^{n-1})$, first calculate the constant values for the decision thresholds $h_+$ and $h_-$ using the natural logarithm. Also, pre-calculate the two possible values for the log-likelihood increment: $w_0$ for $x_i=0$ and $w_1$ for $x_i=1$.\n\n2.  **CUSUM Monitoring**: Initialize the CUSUM statistic $S=0$ and the signal time $t^\\star = -1$. Iterate through the patient outcomes from the index $t = t_{\\mathrm{QI}}$ to the end of the data series, $n-1$. In each step:\n    a.  Determine the log-likelihood increment $w_t$ based on the outcome $x_t$.\n    b.  Update the CUSUM statistic: $S \\leftarrow \\max(0, S + w_t)$.\n    c.  Check for an improvement signal: If $S \\ge h_+$ and $t^\\star$ has not yet been set (i.e., $t^\\star = -1$), record the current index as the signal time: $t^\\star \\leftarrow t$.\n\n3.  **Sustained Improvement Assessment**: After iterating through all available data, evaluate if the detected improvement is sustained. This requires three conditions to be met:\n    a.  An improvement signal must have been detected, i.e., $t^\\star \\neq -1$.\n    b.  There must be sufficient follow-up data. Specifically, the analysis window requires $w$ observations following the signal, so the data must extend at least to index $t^\\star + w$. This check is formally $t^\\star + w \\le n-1$, where $n$ is the total number of observations.\n    c.  The empirical complication rate, $\\hat{p}$, in the $w$ cases immediately following the signal must be no greater than the target rate $p_1$. The empirical rate is calculated as:\n    $$\\hat{p} = \\frac{1}{w}\\sum_{i=t^\\star+1}^{t^\\star+w} x_i$$\n    If all three conditions are true, the improvement is declared sustained. Otherwise, it is not.\n\n4.  **Output Formulation**: Combine the results for the test case into a list of the form $[t^\\star, \\text{sustained}, \\text{round}(h_+, 6), \\text{round}(h_-, 6)]$, where `sustained` is a boolean value. This process is repeated for all provided test cases.\n\nThis structured approach ensures that the CUSUM chart is correctly implemented and that the criteria for signal detection and sustained improvement are rigorously applied according to the problem specification.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the one-sided CUSUM procedure to monitor postoperative\n    complication rates and detect sustained improvements.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"id\": \"A\",\n            \"p0\": 0.15, \"p1\": 0.07, \"alpha\": 0.20, \"beta\": 0.20,\n            \"t_qi\": 20, \"w\": 15,\n            \"x\": [0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0, 0,0,0,0,0,0,1, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n        },\n        {\n            \"id\": \"B\",\n            \"p0\": 0.15, \"p1\": 0.10, \"alpha\": 0.10, \"beta\": 0.20,\n            \"t_qi\": 20, \"w\": 10,\n            \"x\": [0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0, 0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0,0]\n        },\n        {\n            \"id\": \"C\",\n            \"p0\": 0.25, \"p1\": 0.10, \"alpha\": 0.10, \"beta\": 0.10,\n            \"t_qi\": 10, \"w\": 20,\n            \"x\": [0,1,0,0,1,0,0,0,1,0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n        },\n        {\n            \"id\": \"D\",\n            \"p0\": 0.20, \"p1\": 0.05, \"alpha\": 0.15, \"beta\": 0.15,\n            \"t_qi\": 30, \"w\": 25,\n            \"x\": [0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        p0 = case[\"p0\"]\n        p1 = case[\"p1\"]\n        alpha = case[\"alpha\"]\n        beta = case[\"beta\"]\n        t_qi = case[\"t_qi\"]\n        w_sustained = case[\"w\"]\n        x_seq = case[\"x\"]\n        n = len(x_seq)\n\n        # 1. Calculate thresholds and log-likelihood increments\n        h_plus = np.log((1 - beta) / alpha)\n        h_minus = np.log(beta / (1 - alpha))\n\n        w_comp = np.log(p1 / p0) # Increment for x_i = 1\n        w_no_comp = np.log((1 - p1) / (1 - p0)) # Increment for x_i = 0\n        \n        # 2. CUSUM monitoring\n        s_cusum = 0.0\n        t_star = -1\n        \n        for t in range(t_qi, n):\n            if x_seq[t] == 1:\n                w_t = w_comp\n            else:\n                w_t = w_no_comp\n            \n            s_cusum = max(0, s_cusum + w_t)\n            \n            if s_cusum >= h_plus and t_star == -1:\n                t_star = t\n\n        # 3. Sustained improvement assessment\n        sustained = False\n        if t_star != -1:\n            # Check for sufficient follow-up data\n            if t_star + w_sustained < n:\n                # Calculate empirical complication rate in the window\n                window_start = t_star + 1\n                window_end = t_star + w_sustained + 1\n                complications_in_window = sum(x_seq[window_start:window_end])\n                p_hat = complications_in_window / w_sustained\n                \n                # Check if rate is below or equal to target\n                if p_hat <= p1:\n                    sustained = True\n\n        # 4. Format output\n        case_result = [\n            t_star,\n            \"true\" if sustained else \"false\",\n            round(h_plus, 6),\n            round(h_minus, 6)\n        ]\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format without spaces\n    per_case_strings = []\n    for res in all_results:\n        # Convert boolean to lowercase string 'true' or 'false'\n        s = f\"[{res[0]},{str(res[1]).lower()},{res[2]:.6f},{res[3]:.6f}]\"\n        per_case_strings.append(s)\n    final_output_string = f\"[{','.join(per_case_strings)}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "4844492"}]}