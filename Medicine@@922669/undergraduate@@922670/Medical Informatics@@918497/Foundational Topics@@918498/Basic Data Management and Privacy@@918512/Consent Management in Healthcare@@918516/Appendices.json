{"hands_on_practices": [{"introduction": "Before diving into complex software, it is crucial to understand the logical foundation of how multiple consent documents interact. This exercise uses the clear and precise language of set theory to model the combination of different patient consents [@problem_id:4830922]. You will practice applying set operations like intersection, union, and difference to determine the final, effective permission set, paying close attention to a defined order of operations to see how composition rules can be formalized.", "problem": "A single patient has filed multiple consent artifacts that govern the disclosure of specific clinical data categories. To formalize the composition, represent each consent artifact as an ordered pair of sets, an allowed set and an excluded set, and model policy composition using standard set operations grounded in classical set theory. Let the universe of clinical data categories be $$U=\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}, \\mathrm{HIV}\\}.$$ For each consent artifact $C_i$, define the corresponding policy set $P_i$ by $$P_i = A_i \\setminus X_i,$$ where $A_i$ is the set of categories explicitly allowed by $C_i$ and $X_i$ is the set of categories explicitly excluded by $C_i$.\n\nThe patient’s four consent artifacts and one subsequent revocation are:\n- $C_1$: $A_1=\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}\\}$, $X_1=\\{\\mathrm{GEN}\\}$.\n- $C_2$: $A_2=\\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{GEN}, \\mathrm{MH}\\}$, $X_2=\\{\\mathrm{HIV}\\}$.\n- $C_3$: $A_3=\\{\\mathrm{LAB}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}\\}$, $X_3=\\{\\mathrm{IMG}\\}$.\n- $C_4$: $A_4=\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}, \\mathrm{HIV}\\}$, $X_4=\\{\\mathrm{GEN}, \\mathrm{MH}\\}$.\n- Revocation: $R=\\{\\mathrm{MH}, \\mathrm{HIV}\\}$.\n\nAssume the organization composes the effective allowed category set $E$ for the current disclosure scenario using the following expression without parentheses and with this fixed operator precedence:\n- Highest precedence: intersection $\\cap$,\n- Middle precedence: set difference $\\setminus$,\n- Lowest precedence: union $\\cup$,\nwith all binary operators left-associative at their precedence level.\n\nThe effective set is given by\n$$E = P_1 \\cap P_2 \\setminus P_3 \\cup P_4 \\setminus R.$$\n\nStarting from the foundational semantics that $P_i=A_i\\setminus X_i$ and the above precedence, compute the cardinality $|E|$. Report your final result as an integer. No rounding is required.", "solution": "The problem statement has been validated and found to be self-contained, scientifically grounded in classical set theory, and well-posed. The problem is a formal exercise in applying defined set operations according to a specified, non-standard order of precedence. All sets, operators, and evaluation rules are explicitly provided, allowing for the computation of a unique solution.\n\nThe task is to compute the cardinality of the effective allowed category set, $|E|$, where $E$ is defined by the expression $E = P_1 \\cap P_2 \\setminus P_3 \\cup P_4 \\setminus R$. First, we must determine the individual policy sets $P_i = A_i \\setminus X_i$ from the given consent artifacts.\n\nThe universe of clinical data categories is $U=\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}, \\mathrm{HIV}\\}$.\n\nThe individual policy sets are computed as follows:\nFor $C_1$: $A_1=\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}\\}$, $X_1=\\{\\mathrm{GEN}\\}$.\n$$P_1 = A_1 \\setminus X_1 = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}\\} \\setminus \\{\\mathrm{GEN}\\} = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}\\}$$\n\nFor $C_2$: $A_2=\\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{GEN}, \\mathrm{MH}\\}$, $X_2=\\{\\mathrm{HIV}\\}$.\n$$P_2 = A_2 \\setminus X_2 = \\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{GEN}, \\mathrm{MH}\\} \\setminus \\{\\mathrm{HIV}\\} = \\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{GEN}, \\mathrm{MH}\\}$$\n\nFor $C_3$: $A_3=\\{\\mathrm{LAB}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}\\}$, $X_3=\\{\\mathrm{IMG}\\}$.\n$$P_3 = A_3 \\setminus X_3 = \\{\\mathrm{LAB}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}\\} \\setminus \\{\\mathrm{IMG}\\} = \\{\\mathrm{LAB}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}\\}$$\n\nFor $C_4$: $A_4=\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}, \\mathrm{HIV}\\}$, $X_4=\\{\\mathrm{GEN}, \\mathrm{MH}\\}$.\n$$P_4 = A_4 \\setminus X_4 = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}, \\mathrm{HIV}\\} \\setminus \\{\\mathrm{GEN}, \\mathrm{MH}\\} = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}, \\mathrm{HIV}\\}$$\n\nThe revocation set is given as $R=\\{\\mathrm{MH}, \\mathrm{HIV}\\}$.\n\nNext, we evaluate the expression $E = P_1 \\cap P_2 \\setminus P_3 \\cup P_4 \\setminus R$ according to the specified operator precedence: intersection ($\\cap$) has the highest precedence, followed by set difference ($\\setminus$), and finally union ($\\cup$) with the lowest precedence. This order of operations dictates the following grouping:\n$$E = ((P_1 \\cap P_2) \\setminus P_3) \\cup (P_4 \\setminus R)$$\n\nWe proceed by evaluating the sub-expressions.\nFirst, we compute the intersection $P_1 \\cap P_2$:\n$$T_1 = P_1 \\cap P_2 = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{BILL}\\} \\cap \\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}, \\mathrm{GEN}, \\mathrm{MH}\\} = \\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}\\}$$\n\nNext, we compute the set difference $(P_1 \\cap P_2) \\setminus P_3$:\n$$T_2 = T_1 \\setminus P_3 = \\{\\mathrm{IMG}, \\mathrm{MED}, \\mathrm{NOTE}\\} \\setminus \\{\\mathrm{LAB}, \\mathrm{NOTE}, \\mathrm{BILL}, \\mathrm{GEN}, \\mathrm{MH}\\} = \\{\\mathrm{IMG}, \\mathrm{MED}\\}$$\nThe element $\\mathrm{NOTE}$ is removed because it is present in $P_3$.\n\nThen, we compute the set difference $P_4 \\setminus R$:\n$$T_3 = P_4 \\setminus R = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}, \\mathrm{HIV}\\} \\setminus \\{\\mathrm{MH}, \\mathrm{HIV}\\} = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}\\}$$\nThe element $\\mathrm{HIV}$ is removed because it is present in $R$.\n\nFinally, we compute the union of the two resulting sets to find $E$:\n$$E = T_2 \\cup T_3 = \\{\\mathrm{IMG}, \\mathrm{MED}\\} \\cup \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}\\} = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}\\}$$\n\nThe effective allowed category set is $E = \\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}\\}$. The problem asks for the cardinality of this set, $|E|$.\n$$|E| = |\\{\\mathrm{LAB}, \\mathrm{IMG}, \\mathrm{MED}, \\mathrm{BILL}\\}| = 4$$", "answer": "$$\\boxed{4}$$", "id": "4830922"}, {"introduction": "Real-world consent policies are rarely simple sets; they are collections of rules based on attributes like the purpose of data use or the role of the person accessing it. This practice challenges you to implement a decision engine based on a simplified model of the FHIR (Fast Healthcare Interoperability Resources) standard [@problem_id:4830907]. You will learn to apply critical access control principles such as rule specificity and \"deny-overrides\" to resolve conflicts between overlapping policies.", "problem": "You are given a simplified and formalized model of Fast Healthcare Interoperability Resources (FHIR) Consent provisions used to decide whether a data access request should be permitted. Each provision (called a \"policy\" below) is a rule with an effect of either \"permit\" or \"deny\" and a set of attribute constraints that can be specific values or wildcards. A request carries attribute values. Your task is to compute the effective decision for each request, based on fundamental access control principles applied to this model.\n\nFoundational principles and core definitions:\n- Principle of least privilege: in absence of an explicit permit, do not grant access. In other words, the default decision is deny.\n- Deny-overrides combining: when equally authoritative rules conflict, a deny takes precedence over a permit to avoid unintended disclosure.\n- Rule specificity: a more specific rule (with more concrete constraints) should take precedence over a less specific rule. Specificity is measured below.\n\nModel:\n- Attributes are: purpose of use, resource type, actor role, and time. Denote the attribute set as $\\mathcal{A} = \\{\\text{purpose}, \\text{resource}, \\text{actor}, \\text{time}\\}$.\n- A policy $p$ has:\n  - An effect $e(p) \\in \\{\\text{permit}, \\text{deny}\\}$.\n  - Constraints $c_{\\text{purpose}}(p)$, $c_{\\text{resource}}(p)$, $c_{\\text{actor}}(p)$, and a time window $[c_{\\text{start}}(p), c_{\\text{end}}(p)]$.\n  - An update timestamp $u(p)$ used for recency tie-breaking.\n- For non-time attributes, a constraint is either a concrete value (for example, \"research\") or a wildcard \"*\". For time, a constraint is a closed interval $[c_{\\text{start}}(p), c_{\\text{end}}(p)]$ in seconds since the Unix epoch, with the special unconstrained case represented by both endpoints being undefined (treated as $-\\infty$ and $+\\infty$ conceptually). All actual times in the input are given in seconds, in $s$.\n- A request $r$ has concrete values for purpose, resource, actor, and a time $t(r)$ in $s$.\n\nMatching:\n- Define a match predicate $M(p, r)$ that is true if and only if:\n  - For each non-time attribute $a \\in \\{\\text{purpose}, \\text{resource}, \\text{actor}\\}$, either $c_{a}(p) = *$ or $c_{a}(p)$ equals the request’s value for $a$.\n  - For time, if a policy’s time is unconstrained, it matches any $t(r)$. Otherwise $t(r)$ must satisfy $c_{\\text{start}}(p) \\le t(r) \\le c_{\\text{end}}(p)$, with all bounds in $s$.\n\nSpecificity:\n- For a matching policy $p$, define its specificity score with respect to $r$ as:\n  $$s(p, r) = \\mathbf{1}[c_{\\text{purpose}}(p) \\ne *] + \\mathbf{1}[c_{\\text{resource}}(p) \\ne *] + \\mathbf{1}[c_{\\text{actor}}(p) \\ne *] + \\mathbf{1}[\\text{time is constrained in } p],$$\n  where $\\mathbf{1}[\\cdot]$ is the indicator function equal to $1$ if the predicate is true and $0$ otherwise. The time is considered constrained if at least one of $c_{\\text{start}}(p)$ or $c_{\\text{end}}(p)$ is defined.\n\nDecision procedure to implement:\n- Given a finite set of policies $\\mathcal{P}$ and a request $r$:\n  1. Compute the set of matching policies $\\mathcal{P}_m = \\{p \\in \\mathcal{P} \\mid M(p, r)\\}$.\n  2. If $\\mathcal{P}_m$ is empty, return deny.\n  3. Compute $s_{\\max} = \\max_{p \\in \\mathcal{P}_m} s(p, r)$ and restrict to the maximally specific set $\\mathcal{T} = \\{p \\in \\mathcal{P}_m \\mid s(p, r) = s_{\\max}\\}$.\n  4. If $\\mathcal{T}$ contains both a permit and a deny, return deny (deny-overrides at equal specificity).\n  5. Otherwise, all effects in $\\mathcal{T}$ are the same; return that effect. If desired, to break ties deterministically among multiple policies with identical effect and specificity, you may choose the one with maximal update timestamp $u(p)$, but note that this does not change the effect.\n\nTest suite:\nFor each test case, you are given a policy set and a request. Times and timestamps are integers in $s$. Wildcards are denoted by the string \"*\". Effects are \"permit\" or \"deny\". Your program must evaluate each test case and output a list of booleans, where True corresponds to permit and False corresponds to deny.\n\n- Test case $1$ (more specific permit beats less specific deny):\n  - Policies:\n    - $p_1$: effect permit; purpose \"research\"; resource \"lab\"; actor \"*\"; time unconstrained; updated $1700000000$.\n    - $p_2$: effect deny; purpose \"*\"; resource \"lab\"; actor \"*\"; time unconstrained; updated $1600000000$.\n  - Request: purpose \"research\"; resource \"lab\"; actor \"clinician\"; time $1705000000$.\n  - Expected decision: True.\n\n- Test case $2$ (deny-overrides at equal specificity):\n  - Policies:\n    - $p_1$: effect permit; purpose \"research\"; resource \"lab\"; actor \"*\"; time unconstrained; updated $1700000000$.\n    - $p_2$: effect deny; purpose \"research\"; resource \"lab\"; actor \"*\"; time unconstrained; updated $1699000000$.\n  - Request: purpose \"research\"; resource \"lab\"; actor \"nurse\"; time $1701000000$.\n  - Expected decision: False.\n\n- Test case $3$ (default deny when no policy matches):\n  - Policies:\n    - $p_1$: effect permit; purpose \"treatment\"; resource \"imaging\"; actor \"*\"; time unconstrained; updated $1700000000$.\n  - Request: purpose \"research\"; resource \"lab\"; actor \"clinician\"; time $1700000100$.\n  - Expected decision: False.\n\n- Test case $4$ (tie with same effect and specificity, recency does not change effect):\n  - Policies:\n    - $p_1$: effect permit; purpose \"research\"; resource \"lab\"; actor \"clinician\"; time unconstrained; updated $1600000000$.\n    - $p_2$: effect permit; purpose \"research\"; resource \"lab\"; actor \"clinician\"; time unconstrained; updated $1800000000$.\n  - Request: purpose \"research\"; resource \"lab\"; actor \"clinician\"; time $1790000000$.\n  - Expected decision: True.\n\n- Test case $5$ (time constraint increases specificity and decides outcome):\n  - Policies:\n    - $p_1$: effect permit; purpose \"research\"; resource \"lab\"; actor \"*\"; time window $[1700000000, 1710000000]$; updated $1700000000$.\n    - $p_2$: effect deny; purpose \"research\"; resource \"lab\"; actor \"*\"; time unconstrained; updated $1600000000$.\n  - Request: purpose \"research\"; resource \"lab\"; actor \"clinician\"; time $1708000000$.\n  - Expected decision: True.\n\n- Test case $6$ (time outside window eliminates the more specific permit):\n  - Policies:\n    - $p_1$: effect permit; purpose \"research\"; resource \"lab\"; actor \"*\"; time window $[1700000000, 1710000000]$; updated $1700000000$.\n    - $p_2$: effect deny; purpose \"research\"; resource \"lab\"; actor \"*\"; time unconstrained; updated $1600000000$.\n  - Request: purpose \"research\"; resource \"lab\"; actor \"clinician\"; time $1720000000$.\n  - Expected decision: False.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[True,False,True,False,True,False]\"). There must be exactly $6$ boolean values in the order of test cases $1$ through $6$.", "solution": "The problem requires the implementation of a decision-making algorithm for a formalized access control model based on principles from medical informatics, specifically Fast Healthcare Interoperability Resources (FHIR) consent provisions. The solution involves applying a sequence of rules to determine if a data access request should be permitted or denied based on a given set of policies.\n\nThe core principles guiding the decision logic are the **principle of least privilege** (default deny), the **deny-overrides** principle for conflict resolution, and the **principle of specificity**, where more specific rules take precedence over more general ones. The problem provides a rigorous, step-by-step procedure to implement this logic.\n\nLet us formalize the components. A policy $p$ in the set of all policies $\\mathcal{P}$ is defined by its effect $e(p)$, its constraints on attributes from the set $\\mathcal{A} = \\{\\text{purpose}, \\text{resource}, \\text{actor}, \\text{time}\\}$, and its update timestamp $u(p)$. A request $r$ is defined by a set of concrete values for these same attributes.\n\nThe decision procedure is as follows:\n\n**Step 1: Identify Matching Policies**\n\nFirst, for a given request $r$, we must identify the subset of policies $\\mathcal{P}_m \\subseteq \\mathcal{P}$ that apply to it. A policy $p$ is considered matching if all its constraints are satisfied by the request's attributes. The matching predicate $M(p, r)$ is true if and only if:\n- For each non-time attribute $a \\in \\{\\text{purpose}, \\text{resource}, \\text{actor}\\}$, the policy's constraint $c_a(p)$ is either a wildcard (`*`) or is identical to the request's attribute value $v_a(r)$.\n- For the time attribute, the request's time $t(r)$ must fall within the policy's defined time interval $[c_{\\text{start}}(p), c_{\\text{end}}(p)]$. An unconstrained time interval in a policy, represented conceptually as $[-\\infty, +\\infty]$, matches any request time.\n\nIf the set of matching policies $\\mathcal{P}_m = \\{p \\in \\mathcal{P} \\mid M(p, r)\\}$ is empty, the principle of least privilege dictates that access is denied.\n\n**Step 2: Calculate Specificity**\n\nNext, we evaluate the specificity of each matching policy. The principle of specificity ensures that more targeted rules override broader ones. The specificity score $s(p, r)$ for a matching policy $p$ is defined as the count of its non-wildcard constraints. The formula is:\n$$s(p, r) = \\mathbf{1}[c_{\\text{purpose}}(p) \\ne *] + \\mathbf{1}[c_{\\text{resource}}(p) \\ne *] + \\mathbf{1}[c_{\\text{actor}}(p) \\ne *] + \\mathbf{1}[\\text{time is constrained in } p]$$\nwhere $\\mathbf{1}[\\cdot]$ is the indicator function. The time constraint is counted if the policy's time window is not $[-\\infty, +\\infty]$. This score can range from $0$ (all wildcards) to $4$ (all constraints are specific).\n\n**Step 3: Isolate Maximally Specific Policies**\n\nWe find the maximum specificity score $s_{\\max}$ among all matching policies:\n$$s_{\\max} = \\max_{p \\in \\mathcal{P}_m} s(p, r)$$\nWe then construct a new set $\\mathcal{T}$ containing only those policies from $\\mathcal{P}_m$ that achieve this maximum specificity:\n$$\\mathcal{T} = \\{p \\in \\mathcal{P}_m \\mid s(p, r) = s_{\\max}\\}$$\nThis step effectively filters the applicable rules to only the most relevant ones.\n\n**Step 4: Apply Conflict Resolution and Finalize Decision**\n\nThe final decision is derived from the effects of the policies in the maximally specific set $\\mathcal{T}$.\n- If $\\mathcal{T}$ contains policies with conflicting effects (i.e., at least one `permit` and at least one `deny`), the deny-overrides principle is applied. To prevent accidental data disclosure, the outcome is `deny`.\n- If all policies in $\\mathcal{T}$ have the same effect, that effect becomes the decision. For example, if all policies in $\\mathcal{T}$ are `permit`, the request is granted.\n\nThe problem also mentions an update timestamp $u(p)$ for tie-breaking. However, it correctly notes that for this decision logic, this tie-breaker does not alter the final effect, as all policies in the final candidate set $\\mathcal{T}$ will either have the same effect or the `deny-overrides` rule will be triggered regardless of which is more recent.\n\nBy systematically applying these four steps to each test case, we can determine the correct boolean outcome (`True` for permit, `False` for deny). For instance, in Test Case 1, a `permit` policy with specificity $2$ overrides a `deny` policy with specificity $1$. In Test Case 2, a `permit` and a `deny` policy both have the maximum specificity of $2$, so the `deny-overrides` rule results in a `deny`. In Test Case 3, no policy matches the request, leading to a default `deny`. This structured evaluation ensures that all principles are correctly and consistently applied.\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the FHIR consent policy evaluation problem for the given test suite.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each policy is a dict. Unconstrained time is represented by start/end keys being None.\n    # Each request is a dict.\n    test_cases = [\n        # Test case 1\n        (\n            [\n                {\"effect\": \"permit\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1700000000},\n                {\"effect\": \"deny\", \"purpose\": \"*\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1600000000},\n            ],\n            {\"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time\": 1705000000},\n        ),\n        # Test case 2\n        (\n            [\n                {\"effect\": \"permit\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1700000000},\n                {\"effect\": \"deny\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1699000000},\n            ],\n            {\"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"nurse\", \"time\": 1701000000},\n        ),\n        # Test case 3\n        (\n            [\n                {\"effect\": \"permit\", \"purpose\": \"treatment\", \"resource\": \"imaging\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1700000000},\n            ],\n            {\"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time\": 1700000100},\n        ),\n        # Test case 4\n        (\n            [\n                {\"effect\": \"permit\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time_start\": None, \"time_end\": None, \"updated\": 1600000000},\n                {\"effect\": \"permit\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time_start\": None, \"time_end\": None, \"updated\": 1800000000},\n            ],\n            {\"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time\": 1790000000},\n        ),\n        # Test case 5\n        (\n            [\n                {\"effect\": \"permit\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": 1700000000, \"time_end\": 1710000000, \"updated\": 1700000000},\n                {\"effect\": \"deny\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1600000000},\n            ],\n            {\"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time\": 1708000000},\n        ),\n        # Test case 6\n        (\n            [\n                {\"effect\": \"permit\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": 1700000000, \"time_end\": 1710000000, \"updated\": 1700000000},\n                {\"effect\": \"deny\", \"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"*\", \"time_start\": None, \"time_end\": None, \"updated\": 1600000000},\n            ],\n            {\"purpose\": \"research\", \"resource\": \"lab\", \"actor\": \"clinician\", \"time\": 1720000000},\n        ),\n    ]\n\n    results = []\n    for policies, request in test_cases:\n        # Step 1: Compute the set of matching policies\n        matching_policies = []\n        for p in policies:\n            # Check non-time attributes\n            purpose_match = (p[\"purpose\"] == \"*\" or p[\"purpose\"] == request[\"purpose\"])\n            resource_match = (p[\"resource\"] == \"*\" or p[\"resource\"] == request[\"resource\"])\n            actor_match = (p[\"actor\"] == \"*\" or p[\"actor\"] == request[\"actor\"])\n            \n            # Check time attribute\n            time_constrained = p[\"time_start\"] is not None or p[\"time_end\"] is not None\n            start = p[\"time_start\"] if p[\"time_start\"] is not None else float('-inf')\n            end = p[\"time_end\"] if p[\"time_end\"] is not None else float('inf')\n            time_match = start <= request[\"time\"] <= end\n            \n            if purpose_match and resource_match and actor_match and time_match:\n                matching_policies.append(p)\n\n        # Step 2: If no policies match, return deny (False)\n        if not matching_policies:\n            results.append(False)\n            continue\n            \n        # Calculate specificity for each matching policy\n        scored_policies = []\n        for p in matching_policies:\n            score = (\n                (1 if p[\"purpose\"] != \"*\" else 0) +\n                (1 if p[\"resource\"] != \"*\" else 0) +\n                (1 if p[\"actor\"] != \"*\" else 0) +\n                (1 if (p[\"time_start\"] is not None or p[\"time_end\"] is not None) else 0)\n            )\n            scored_policies.append({\"policy\": p, \"score\": score})\n            \n        # Step 3: Compute max specificity and restrict to the maximally specific set\n        max_specificity = -1\n        for sp in scored_policies:\n            if sp[\"score\"] > max_specificity:\n                max_specificity = sp[\"score\"]\n\n        maximally_specific_set = [sp[\"policy\"] for sp in scored_policies if sp[\"score\"] == max_specificity]\n        \n        # Step 4: Apply deny-overrides combining logic\n        effects = {p[\"effect\"] for p in maximally_specific_set}\n        \n        if \"deny\" in effects:\n            # Deny-overrides at equal specificity\n            results.append(False)\n        else:\n            # All effects are 'permit'\n            results.append(True)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "answer": "[True,False,False,True,True,False]", "id": "4830907"}, {"introduction": "A correctly designed policy can be rendered ineffective by a simple implementation error. In this exercise, you will investigate a common and dangerous misconfiguration known as \"shadowing,\" where a broad denial rule mistakenly hides a more specific permit [@problem_id:4830976]. Your task will be to analyze a series of access attempts, identify the true cases of shadowing, and use this data to calculate the $F_1$-score of a detector tool, giving you hands-on experience in the vital work of auditing and quality control for access control systems.", "problem": "A hospital-grade Electronic Health Record (EHR) system enforces Role-Based Access Control (RBAC) and patient consent policies. The intended combining semantics are \"most-specific permit overrides broad deny,\" but a misconfiguration deploys a \"broad deny overrides\" evaluation with a high-priority broad deny rule. This causes shadowing: specific permits that should authorize access are hidden by a more general deny. Consider the following consent and access control rules intended by compliance:\n\n- Specific permit $P_{\\text{cardio}}$: Permit if subject.role $=$ Cardiologist, resource.type $=$ cardiology\\_notes, purpose $=$ treatment, regardless of subject affiliation (internal versus external) when a patient has given consent for treatment.\n- Specific permit $P_{\\text{er}}$: Permit if subject.dept $=$ Emergency, resource.type $=$ allergies, purpose $=$ emergency.\n- Broad deny $D_{\\text{ext}}$: Deny if subject.affiliation $\\neq$ Hospital\\_H1 (an \"external\" provider). This deny is misconfigured to be evaluated with higher priority than specific permits in the deployed engine.\n- Broad deny $D_{\\text{research}}$: Deny if purpose $=$ research and patient.research\\_opt\\_out $=$ true.\n\nA security analyst evaluates a shadowing-misconfiguration detector that flags individual access requests as \"shadowed permit\" if, in that request’s policy path, a specific permit is overridden by a broader deny due to the engine’s misconfigured priority. The analyst executes the following $12$ test cases $T_{1}$ through $T_{12}$, each annotated with its intended decision under the compliance semantics (most-specific permit overrides), the actual engine decision under the misconfiguration (broad deny overrides), and whether the detector flagged it.\n\n- $T_{1}$: subject.affiliation $=$ external; subject.role $=$ Cardiologist; resource.type $=$ cardiology\\_notes; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false; emergency $=$ false. Intended: Permit; Actual: Deny; Detector: Flagged.\n- $T_{2}$: subject.affiliation $=$ internal; subject.role $=$ Cardiologist; resource.type $=$ cardiology\\_notes; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false; emergency $=$ false. Intended: Permit; Actual: Permit; Detector: Not Flagged.\n- $T_{3}$: subject.affiliation $=$ external; subject.dept $=$ Emergency; resource.type $=$ allergies; purpose $=$ emergency; patient.research\\_opt\\_out $=$ false. Intended: Permit; Actual: Deny; Detector: Flagged.\n- $T_{4}$: subject.affiliation $=$ external; subject.role $=$ Cardiologist; resource.type $=$ radiology\\_report; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false. Intended: Deny; Actual: Deny; Detector: Flagged.\n- $T_{5}$: subject.affiliation $=$ internal; subject.dept $=$ Emergency; resource.type $=$ allergies; purpose $=$ emergency; patient.research\\_opt\\_out $=$ false. Intended: Permit; Actual: Permit; Detector: Not Flagged.\n- $T_{6}$: subject.affiliation $=$ external; subject.role $=$ Nurse; resource.type $=$ cardiology\\_notes; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false. Intended: Deny; Actual: Deny; Detector: Not Flagged.\n- $T_{7}$: subject.affiliation $=$ external; subject.role $=$ Cardiologist; resource.type $=$ cardiology\\_notes; purpose $=$ research; patient.research\\_opt\\_out $=$ false. Intended: Deny; Actual: Deny; Detector: Flagged.\n- $T_{8}$: subject.affiliation $=$ internal; subject.role $=$ Researcher; resource.type $=$ lab\\_results; purpose $=$ research; patient.research\\_opt\\_out $=$ true. Intended: Deny; Actual: Deny; Detector: Not Flagged.\n- $T_{9}$: subject.affiliation $=$ external; subject.role $=$ Cardiologist; resource.type $=$ cardiology\\_notes; purpose $=$ treatment; emergency $=$ true; patient.research\\_opt\\_out $=$ false. Intended: Permit; Actual: Deny; Detector: Not Flagged.\n- $T_{10}$: subject.affiliation $=$ external; subject.dept $=$ Emergency; resource.type $=$ allergies; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false. Intended: Deny; Actual: Deny; Detector: Not Flagged.\n- $T_{11}$: subject.affiliation $=$ internal; subject.role $=$ Cardiologist; resource.type $=$ cardiology\\_notes; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false. Intended: Permit; Actual: Permit; Detector: Not Flagged.\n- $T_{12}$: subject.affiliation $=$ external; subject.role $=$ Cardiologist; resource.type $=$ cardiology\\_notes; purpose $=$ treatment; patient.research\\_opt\\_out $=$ false; eConsent\\_override $=$ true. Intended: Permit; Actual: Deny; Detector: Flagged.\n\nDefine a \"positive\" test as one where a specific permit should apply under the intended semantics (Permit) but is denied by the deployed engine due to the broad deny, i.e., a shadowed permit. Using only the data above, compute the $F_{1}$-score of the detector on this test suite, treating detections as \"positive\" predictions. Round your answer to four significant figures. Express the final value as a pure number without a percentage sign.", "solution": "The user-provided problem is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe problem provides a set of access control rules, a description of two different policy evaluation semantics, and a suite of $12$ test cases with their outcomes.\n\n**Access Control Rules:**\n- $P_{\\text{cardio}}$: Permit if subject.role $=$ Cardiologist, resource.type $=$ cardiology\\_notes, purpose $=$ treatment.\n- $P_{\\text{er}}$: Permit if subject.dept $=$ Emergency, resource.type $=$ allergies, purpose $=$ emergency.\n- $D_{\\text{ext}}$: Deny if subject.affiliation $\\neq$ Hospital\\_H1. This rule is misconfigured with high priority.\n- $D_{\\text{research}}$: Deny if purpose $=$ research and patient.research\\_opt\\_out $=$ true.\n\n**Policy Semantics:**\n- Intended Semantics: \"most-specific permit overrides broad deny\".\n- Actual (Misconfigured) Semantics: \"broad deny overrides\".\n\n**Detector Definition:**\n- A detector flags requests as \"shadowed permit\" if a specific permit is active but overridden by a broader deny.\n\n**Ground Truth Definition for Evaluation:**\n- A \"positive\" test case is defined as one representing a shadowed permit, which corresponds to an access request where the `Intended` decision is `Permit` and the `Actual` engine decision is `Deny`.\n\n**Prediction Definition for Evaluation:**\n- A \"positive\" prediction is a test case where the detector `Flagged` the request.\n\n**Test Cases ($T_1$ through $T_{12}$):**\n- $T_{1}$: Intended: Permit; Actual: Deny; Detector: Flagged.\n- $T_{2}$: Intended: Permit; Actual: Permit; Detector: Not Flagged.\n- $T_{3}$: Intended: Permit; Actual: Deny; Detector: Flagged.\n- $T_{4}$: Intended: Deny; Actual: Deny; Detector: Flagged.\n- $T_{5}$: Intended: Permit; Actual: Permit; Detector: Not Flagged.\n- $T_{6}$: Intended: Deny; Actual: Deny; Detector: Not Flagged.\n- $T_{7}$: Intended: Deny; Actual: Deny; Detector: Flagged.\n- $T_{8}$: Intended: Deny; Actual: Deny; Detector: Not Flagged.\n- $T_{9}$: Intended: Permit; Actual: Deny; Detector: Not Flagged.\n- $T_{10}$: Intended: Deny; Actual: Deny; Detector: Not Flagged.\n- $T_{11}$: Intended: Permit; Actual: Permit; Detector: Not Flagged.\n- $T_{12}$: Intended: Permit; Actual: Deny; Detector: Flagged.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the domain of computer security and medical informatics, using standard terminology like Role-Based Access Control (RBAC), policy evaluation, and shadowing. The problem is well-posed, as it provides a complete, self-contained dataset and a clear objective: to compute the $F_{1}$-score, a standard metric for binary classification accuracy. The language is objective and precise. The provided data, including the test case outcomes (`Intended`, `Actual`, `Detector`), forms a consistent basis for the calculation, even if the detector itself exhibits flaws (which is the point of the evaluation). The problem does not violate any fundamental principles, is not underspecified, and does not contain contradictory constraints.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A complete solution will be provided.\n\n### Solution Derivation\nThe objective is to calculate the $F_{1}$-score of the shadowing-misconfiguration detector based on its performance on the provided $12$ test cases. The $F_{1}$-score is the harmonic mean of precision and recall.\n\nFirst, we must establish the ground truth and the detector's predictions to construct a confusion matrix.\n- A **Condition Positive** case (a true instance of shadowing) is defined by the problem as a test where the `Intended` decision is `Permit` and the `Actual` decision is `Deny`.\n- A **Condition Negative** case is any other combination.\n- A **Prediction Positive** is a test case where the detector `Flagged` the request.\n- A **Prediction Negative** is a test case where the detector did `Not Flagged` the request.\n\nWe can now classify each of the $12$ test cases:\n\n- $T_1$: Intended `Permit`, Actual `Deny`. This is a **Condition Positive**. The detector `Flagged` it, which is a **Prediction Positive**. Therefore, $T_1$ is a True Positive ($TP$).\n- $T_2$: Intended `Permit`, Actual `Permit`. This is a **Condition Negative**. The detector `Not Flagged` it, which is a **Prediction Negative**. Therefore, $T_2$ is a True Negative ($TN$).\n- $T_3$: Intended `Permit`, Actual `Deny`. This is a **Condition Positive**. The detector `Flagged` it, a **Prediction Positive**. Therefore, $T_3$ is a True Positive ($TP$).\n- $T_4$: Intended `Deny`, Actual `Deny`. This is a **Condition Negative**. The detector `Flagged` it, a **Prediction Positive**. Therefore, $T_4$ is a False Positive ($FP$).\n- $T_5$: Intended `Permit`, Actual `Permit`. This is a **Condition Negative**. The detector `Not Flagged` it, a **Prediction Negative**. Therefore, $T_5$ is a True Negative ($TN$).\n- $T_6$: Intended `Deny`, Actual `Deny`. This is a **Condition Negative**. The detector `Not Flagged` it, a **Prediction Negative**. Therefore, $T_6$ is a True Negative ($TN$).\n- $T_7$: Intended `Deny`, Actual `Deny`. This is a **Condition Negative**. The detector `Flagged` it, a **Prediction Positive**. Therefore, $T_7$ is a False Positive ($FP$).\n- $T_8$: Intended `Deny`, Actual `Deny`. This is a **Condition Negative**. The detector `Not Flagged` it, a **Prediction Negative**. Therefore, $T_8$ is a True Negative ($TN$).\n- $T_9$: Intended `Permit`, Actual `Deny`. This is a **Condition Positive**. The detector `Not Flagged` it, a **Prediction Negative**. Therefore, $T_9$ is a False Negative ($FN$).\n- $T_{10}$: Intended `Deny`, Actual `Deny`. This is a **Condition Negative**. The detector `Not Flagged` it, a **Prediction Negative**. Therefore, $T_{10}$ is a True Negative ($TN$).\n- $T_{11}$: Intended `Permit`, Actual `Permit`. This is a **Condition Negative**. The detector `Not Flagged` it, a **Prediction Negative**. This is identical to $T_2$ and is a True Negative ($TN$).\n- $T_{12}$: Intended `Permit`, Actual `Deny`. This is a **Condition Positive**. The detector `Flagged` it, a **Prediction Positive**. Therefore, $T_{12}$ is a True Positive ($TP$).\n\nSummarizing the counts from the $12$ tests:\n- True Positives ($TP$): $3$ ($T_1, T_3, T_{12}$)\n- False Positives ($FP$): $2$ ($T_4, T_7$)\n- True Negatives ($TN$): $6$ ($T_2, T_5, T_6, T_8, T_{10}, T_{11}$)\n- False Negatives ($FN$): $1$ ($T_9$)\n\nThe total number of tests is $3 + 2 + 6 + 1 = 12$, which is correct.\n\nNext, we calculate Precision and Recall.\nPrecision is the ratio of correctly predicted positive observations to the total predicted positive observations.\n$$ \\text{Precision} = \\frac{TP}{TP + FP} $$\nSubstituting the values:\n$$ \\text{Precision} = \\frac{3}{3 + 2} = \\frac{3}{5} = 0.6 $$\n\nRecall (or Sensitivity) is the ratio of correctly predicted positive observations to all observations in the actual class.\n$$ \\text{Recall} = \\frac{TP}{TP + FN} $$\nSubstituting the values:\n$$ \\text{Recall} = \\frac{3}{3 + 1} = \\frac{3}{4} = 0.75 $$\n\nFinally, the $F_{1}$-score is calculated as the harmonic mean of Precision and Recall.\n$$ F_1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\nSubstituting the calculated values for Precision and Recall:\n$$ F_1 = 2 \\times \\frac{0.6 \\times 0.75}{0.6 + 0.75} = 2 \\times \\frac{0.45}{1.35} $$\nTo simplify the fraction:\n$$ F_1 = 2 \\times \\frac{45}{135} = 2 \\times \\frac{1}{3} = \\frac{2}{3} $$\nAs a decimal, $F_1 = 0.666666...$. The problem requires rounding to four significant figures.\n$$ F_1 \\approx 0.6667 $$", "answer": "$$ \\boxed{0.6667} $$", "id": "4830976"}]}