{"hands_on_practices": [{"introduction": "Before health data can be used for clinical care or research, it must be assessed for quality. This first practice exercise tackles the fundamental challenge of data cleaning by focusing on raw clinical observations, such as vital signs. You will implement two essential data quality techniques: checking for biological implausibility using predefined clinical rules and identifying statistical outliers using a robust method, providing a solid foundation for handling real-world data imperfections [@problem_id:4856383].", "problem": "You are given four test cases, each consisting of a small dataset of structured clinical observation data representing vital signs collected from patient encounters. Each record contains the patient age in years, sex coded as a string \"M\" or \"F\", heart rate in beats per minute (bpm), systolic blood pressure in millimeters of mercury (mmHg), and body temperature in degrees Celsius (°C). All input measurements must be treated as numeric quantities with their physical units as specified. The tasks are to compute biologically implausibility rates using age- and sex-specific bounds and to implement robust outlier detection via robust z-scores. The output is purely numerical and unitless; it must adhere to the specified format. The scenario is framed in medical informatics under the theme of sources and types of health data and focuses on observational numeric data derived from clinical measurement processes.\n\nFundamental base:\n- Clinical observation data are numeric measurements generated by a measurement process subject to error. Observed values are assessed for biological plausibility against conservative reference ranges that vary by age and sex.\n- Robust outlier detection uses statistics that are less sensitive to extreme values. Let $x_1,\\dots,x_n$ denote a set of observed values for one vital sign. Define the sample median as $m = \\operatorname{median}(x_1,\\dots,x_n)$ and the Median Absolute Deviation (MAD) as $\\operatorname{MAD} = \\operatorname{median}(|x_1 - m|,\\dots,|x_n - m|)$. The robust z-score for an observation $x_i$ is $z_i = \\dfrac{x_i - m}{c \\cdot \\operatorname{MAD}}$, where $c = 1.4826$ scales the MAD to be a consistent estimator of the standard deviation under a Gaussian model. A common robust threshold is $\\tau = 3.5$, classifying $x_i$ as an outlier if $|z_i| > \\tau$.\n\nAge binning and inclusivity rules:\n- Define age bins using the following inclusive boundaries:\n  - Bin $1$: $0 \\le a \\le 1$.\n  - Bin $2$: $1 < a \\le 5$.\n  - Bin $3$: $5 < a \\le 12$.\n  - Bin $4$: $12 < a \\le 64$.\n  - Bin $5$: $a > 64$.\n- Bounds are inclusive: a value is biologically plausible if it lies between the lower and upper bound inclusive for the corresponding age bin and sex.\n\nBiologically plausible ranges per vital, age bin, and sex (conservatively approximated from widely used clinical references):\n- Heart rate (bpm):\n  - Bin $1$: \"M\" and \"F\": $[70, 190]$.\n  - Bin $2$: \"M\" and \"F\": $[70, 150]$.\n  - Bin $3$: \"M\" and \"F\": $[60, 130]$.\n  - Bin $4$: \"M\": $[50, 110]$, \"F\": $[55, 115]$.\n  - Bin $5$: \"M\": $[50, 120]$, \"F\": $[55, 125]$.\n- Systolic blood pressure (mmHg):\n  - Bin $1$: \"M\" and \"F\": $[50, 100]$.\n  - Bin $2$: \"M\" and \"F\": $[70, 110]$.\n  - Bin $3$: \"M\" and \"F\": $[80, 120]$.\n  - Bin $4$: \"M\": $[90, 140]$, \"F\": $[90, 135]$.\n  - Bin $5$: \"M\": $[100, 160]$, \"F\": $[95, 155]$.\n- Body temperature (°C):\n  - Bin $1$: \"M\" and \"F\": $[35.5, 38.5]$.\n  - Bin $2$: \"M\" and \"F\": $[35.0, 38.2]$.\n  - Bin $3$: \"M\" and \"F\": $[35.0, 38.0]$.\n  - Bin $4$: \"M\": $[35.0, 37.8]$, \"F\": $[35.0, 37.9]$.\n  - Bin $5$: \"M\" and \"F\": $[35.0, 37.8]$.\n\nDefinitions to implement:\n- For a given dataset of $n$ records, the implausibility rate for a vital sign is the fraction $\\dfrac{\\text{count of records with value outside the age- and sex-specific bounds}}{n}$, rounded to four decimal places.\n- Robust outlier detection for a vital sign is performed across all records in the dataset (regardless of plausibility), using the robust z-scores defined above and threshold $\\tau = 3.5$. Count the number of records with $|z_i| > \\tau$. If $\\operatorname{MAD} = 0$, define all $z_i = 0$ and hence produce zero outliers for that vital sign.\n\nRequired units and representations:\n- Age $a$ is measured in years.\n- Heart rate is measured in beats per minute (bpm).\n- Systolic blood pressure is measured in millimeters of mercury (mmHg).\n- Body temperature is measured in degrees Celsius (°C).\n- Output values are dimensionless numbers (floats for rates, integers for counts), and the program must round rates to four decimal places.\n\nTest suite:\n- Test case $1$ (mixed plausible and implausible values):\n  - Records:\n    - $(30,\\ \"M\",\\ 72,\\ 118,\\ 36.8)$.\n    - $(4,\\ \"F\",\\ 140,\\ 95,\\ 37.5)$.\n    - $(75,\\ \"F\",\\ 130,\\ 170,\\ 36.0)$.\n    - $(0.5,\\ \"M\",\\ 200,\\ 45,\\ 39.0)$.\n    - $(12,\\ \"M\",\\ 65,\\ 125,\\ 38.1)$.\n    - $(50,\\ \"F\",\\ 30,\\ 85,\\ 34.5)$.\n    - $(7,\\ \"F\",\\ 95,\\ 100,\\ 37.0)$.\n    - $(68,\\ \"M\",\\ 55,\\ 155,\\ 37.5)$.\n- Test case $2$ (values exactly at bounds):\n  - Records:\n    - $(1,\\ \"F\",\\ 70,\\ 100,\\ 38.5)$.\n    - $(5,\\ \"M\",\\ 70,\\ 110,\\ 38.2)$.\n    - $(12,\\ \"F\",\\ 60,\\ 120,\\ 38.0)$.\n    - $(64,\\ \"M\",\\ 110,\\ 140,\\ 37.8)$.\n    - $(65,\\ \"F\",\\ 125,\\ 95,\\ 37.8)$.\n    - $(0.0,\\ \"M\",\\ 190,\\ 50,\\ 35.5)$.\n- Test case $3$ (Median Absolute Deviation equals zero):\n  - Records:\n    - $(30,\\ \"M\",\\ 80,\\ 120,\\ 37.0)$.\n    - $(40,\\ \"F\",\\ 80,\\ 120,\\ 37.0)$.\n    - $(60,\\ \"M\",\\ 80,\\ 120,\\ 37.0)$.\n    - $(20,\\ \"F\",\\ 80,\\ 120,\\ 37.0)$.\n    - $(13,\\ \"M\",\\ 80,\\ 120,\\ 37.0)$.\n- Test case $4$ (all implausible values, extreme measurements):\n  - Records:\n    - $(30,\\ \"M\",\\ 0,\\ 300,\\ 20.0)$.\n    - $(2,\\ \"F\",\\ 10,\\ 200,\\ 45.0)$.\n    - $(80,\\ \"M\",\\ 300,\\ 10,\\ 10.0)$.\n    - $(10,\\ \"F\",\\ 5,\\ 10,\\ 50.0)$.\n\nFinal output specification:\n- For each test case, compute a list $[r_{\\text{HR}}, r_{\\text{SBP}}, r_{\\text{TEMP}}, o_{\\text{HR}}, o_{\\text{SBP}}, o_{\\text{TEMP}}]$, where $r_{\\cdot}$ are implausibility rates rounded to four decimal places and $o_{\\cdot}$ are integer outlier counts.\n- Your program should produce a single line of output containing the results as a JSON-style array of these per-test-case lists with no spaces, in the order of the test cases, for example, $[[r_1,r_2,r_3,o_1,o_2,o_3],\\dots]$.\n- The program must be fully self-contained, require no external input, and adhere to the provided bounds and definitions.", "solution": "The problem requires the implementation of two distinct data quality assessment algorithms for structured clinical observation data: biological plausibility checking and robust outlier detection. The solution involves processing a given set of test cases, each containing records of patient vital signs, and computing specified metrics.\n\n**Problem Formalization and Data Structures**\nEach patient record is a tuple consisting of five fields: age ($a$ in years), sex ($s$, coded as \"M\" or \"F\"), heart rate ($HR$ in bpm), systolic blood pressure ($SBP$ in mmHg), and body temperature ($TEMP$ in °C). The core of the problem lies in defining and applying rules based on these inputs.\n\nThe biological plausibility ranges are provided in a structured manner, dependent on age and sex. A suitable data structure for these ranges is a nested dictionary, mapping a vital sign key to another dictionary that maps an age bin to sex-specific lower and upper bounds. For example, `bounds[vital][age_bin][sex]` would return a pair `(lower, upper)`.\n\n**1. Biological Plausibility Assessment**\n\nThis module checks if an observed measurement for a vital sign falls within a biologically credible range. The ranges are conditional on the patient's age and sex.\n\n**1.1. Age Binning**\nPatient age ($a$) is first categorized into one of five mutually exclusive bins, defined with inclusive boundaries:\n- Bin $1$: $0 \\le a \\le 1$\n- Bin $2$: $1 < a \\le 5$\n- Bin $3$: $5 < a \\le 12$\n- Bin $4$: $12 < a \\le 64$\n- Bin $5$: $a > 64$\n\nAn input age is assigned to the first bin whose condition it satisfies.\n\n**1.2. Plausibility Check**\nFor each record $(a, s, HR, SBP, TEMP)$, we determine the corresponding age bin. Using this bin and the sex $s$, we retrieve the lower bound ($L$) and upper bound ($U$) for each vital sign. A measurement $x$ is considered biologically plausible if it satisfies $L \\le x \\le U$. If $x < L$ or $x > U$, it is flagged as implausible.\n\n**1.3. Implausibility Rate Calculation**\nFor a given dataset with $n$ records and for each vital sign, the implausibility rate, $r$, is the fraction of records containing an implausible value for that sign.\n$$\nr = \\frac{\\text{count of implausible records}}{\\text{total number of records } n}\n$$\nThis rate must be rounded to four decimal places. For example, a value of $0.375$ would be represented as $0.375$.\n\n**2. Robust Outlier Detection**\n\nThis module identifies observations that are statistically extreme relative to the rest of the data, using a method that is resistant to the influence of the outliers themselves. The analysis is performed on the full set of measurements $\\{x_1, \\dots, x_n\\}$ for each vital sign across all records in a test case.\n\n**2.1. Robust Z-Score**\nThe core of this method is the robust z-score, $z_i$, for each observation $x_i$:\n$$\nz_i = \\frac{x_i - m}{c \\cdot \\text{MAD}}\n$$\nwhere:\n- $m = \\operatorname{median}(x_1, \\dots, x_n)$ is the sample median of the observations.\n- $\\text{MAD} = \\operatorname{median}(|x_1 - m|, \\dots, |x_n - m|)$ is the Median Absolute Deviation, which is the median of the absolute differences between each observation and the sample median $m$.\n- $c = 1.4826$ is a scaling constant. This constant makes the MAD a consistent estimator for the standard deviation of a normal distribution. It is derived from the inverse of the standard normal cumulative distribution function, specifically $c = 1 / \\Phi^{-1}(0.75)$.\n\n**2.2. Outlier Identification**\nAn observation $x_i$ is classified as a robust outlier if the absolute value of its robust z-score exceeds a specified threshold, $\\tau = 3.5$.\n$$\n|z_i| > 3.5 \\implies x_i \\text{ is an outlier}\n$$\nThe total number of outliers, $o$, is the count of such observations for a given vital sign.\n\nA special condition is defined for the case where $\\text{MAD} = 0$. This occurs if at least half of the data points are identical to the median. In this scenario, all robust z-scores $z_i$ are defined to be $0$, resulting in an outlier count of $o=0$.\n\n**3. Algorithmic Implementation**\n\nThe overall algorithm proceeds as follows for each test case:\n1. Initialize implausibility counters for $HR$, $SBP$, and $TEMP$ to $0$. Extract the complete lists of values for each vital sign. Let $n$ be the number of records.\n2. Iterate through each record $(a, s, HR_{val}, SBP_{val}, TEMP_{val})$:\n    a. Determine the age bin for age $a$.\n    b. Retrieve the plausibility bounds $(L, U)$ for each vital sign based on the age bin and sex $s$.\n    c. For each vital, check if its value is outside $[L, U]$. If so, increment the corresponding implausibility counter.\n3. Calculate the implausibility rates $r_{HR}$, $r_{SBP}$, $r_{TEMP}$ by dividing the counters by $n$ and rounding to four decimal places.\n4. For each vital sign's list of values (e.g., all $HR$ values):\n    a. Calculate the median $m$ and the MAD.\n    b. If $\\text{MAD} = 0$, the outlier count $o$ is $0$.\n    c. Otherwise, calculate the robust z-score $z_i$ for each value $x_i$ and count how many satisfy $|z_i| > 3.5$. This count is $o$.\n5. Assemble the final list for the test case: $[r_{HR}, r_{SBP}, r_{TEMP}, o_{HR}, o_{SBP}, o_{TEMP}]$.\n6. After processing all test cases, format the collected results into a single JSON-style array string with no spaces.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by processing clinical data test cases for biological\n    implausibility and robust outlier detection.\n    \"\"\"\n\n    # Define biological plausibility bounds: vital -> age_bin -> sex -> (lower, upper)\n    bounds = {\n        \"HR\": {\n            1: {\"M\": (70, 190), \"F\": (70, 190)},\n            2: {\"M\": (70, 150), \"F\": (70, 150)},\n            3: {\"M\": (60, 130), \"F\": (60, 130)},\n            4: {\"M\": (50, 110), \"F\": (55, 115)},\n            5: {\"M\": (50, 120), \"F\": (55, 125)},\n        },\n        \"SBP\": {\n            1: {\"M\": (50, 100), \"F\": (50, 100)},\n            2: {\"M\": (70, 110), \"F\": (70, 110)},\n            3: {\"M\": (80, 120), \"F\": (80, 120)},\n            4: {\"M\": (90, 140), \"F\": (90, 135)},\n            5: {\"M\": (100, 160), \"F\": (95, 155)},\n        },\n        \"TEMP\": {\n            1: {\"M\": (35.5, 38.5), \"F\": (35.5, 38.5)},\n            2: {\"M\": (35.0, 38.2), \"F\": (35.0, 38.2)},\n            3: {\"M\": (35.0, 38.0), \"F\": (35.0, 38.0)},\n            4: {\"M\": (35.0, 37.8), \"F\": (35.0, 37.9)},\n            5: {\"M\": (35.0, 37.8), \"F\": (35.0, 37.8)},\n        }\n    }\n\n    test_cases = [\n        # Test Case 1\n        [\n            (30, \"M\", 72, 118, 36.8), (4, \"F\", 140, 95, 37.5),\n            (75, \"F\", 130, 170, 36.0), (0.5, \"M\", 200, 45, 39.0),\n            (12, \"M\", 65, 125, 38.1), (50, \"F\", 30, 85, 34.5),\n            (7, \"F\", 95, 100, 37.0), (68, \"M\", 55, 155, 37.5)\n        ],\n        # Test Case 2\n        [\n            (1, \"F\", 70, 100, 38.5), (5, \"M\", 70, 110, 38.2),\n            (12, \"F\", 60, 120, 38.0), (64, \"M\", 110, 140, 37.8),\n            (65, \"F\", 125, 95, 37.8), (0.0, \"M\", 190, 50, 35.5)\n        ],\n        # Test Case 3\n        [\n            (30, \"M\", 80, 120, 37.0), (40, \"F\", 80, 120, 37.0),\n            (60, \"M\", 80, 120, 37.0), (20, \"F\", 80, 120, 37.0),\n            (13, \"M\", 80, 120, 37.0)\n        ],\n        # Test Case 4\n        [\n            (30, \"M\", 0, 300, 20.0), (2, \"F\", 10, 200, 45.0),\n            (80, \"M\", 300, 10, 10.0), (10, \"F\", 5, 10, 50.0)\n        ]\n    ]\n\n    def get_age_bin(age):\n        if age <= 1: return 1\n        if age <= 5: return 2\n        if age <= 12: return 3\n        if age <= 64: return 4\n        return 5\n\n    def calculate_outliers(data, c=1.4826, tau=3.5):\n        data_arr = np.array(data)\n        median_val = np.median(data_arr)\n        abs_devs = np.abs(data_arr - median_val)\n        mad = np.median(abs_devs)\n\n        if mad == 0:\n            return 0\n        \n        robust_z_scores = abs_devs / (c * mad)\n        outlier_count = np.sum(robust_z_scores > tau)\n        return int(outlier_count)\n\n    all_results = []\n    for case_data in test_cases:\n        n = len(case_data)\n        \n        implausibility_counts = {\"HR\": 0, \"SBP\": 0, \"TEMP\": 0}\n        \n        all_hr = []\n        all_sbp = []\n        all_temp = []\n\n        for record in case_data:\n            age, sex, hr_val, sbp_val, temp_val = record\n            all_hr.append(hr_val)\n            all_sbp.append(sbp_val)\n            all_temp.append(temp_val)\n\n            age_bin = get_age_bin(age)\n            \n            hr_bounds = bounds[\"HR\"][age_bin][sex]\n            if not (hr_bounds[0] <= hr_val <= hr_bounds[1]):\n                implausibility_counts[\"HR\"] += 1\n\n            sbp_bounds = bounds[\"SBP\"][age_bin][sex]\n            if not (sbp_bounds[0] <= sbp_val <= sbp_bounds[1]):\n                implausibility_counts[\"SBP\"] += 1\n            \n            temp_bounds = bounds[\"TEMP\"][age_bin][sex]\n            if not (temp_bounds[0] <= temp_val <= temp_bounds[1]):\n                implausibility_counts[\"TEMP\"] += 1\n\n        r_hr = round(implausibility_counts[\"HR\"] / n, 4)\n        r_sbp = round(implausibility_counts[\"SBP\"] / n, 4)\n        r_temp = round(implausibility_counts[\"TEMP\"] / n, 4)\n\n        o_hr = calculate_outliers(all_hr)\n        o_sbp = calculate_outliers(all_sbp)\n        o_temp = calculate_outliers(all_temp)\n\n        all_results.append([r_hr, r_sbp, r_temp, o_hr, o_sbp, o_temp])\n\n    # Format the final output string as a JSON-style array with no spaces\n    result_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "4856383"}, {"introduction": "Once data quality has been assessed, the next step is often to transform and aggregate raw data into a more meaningful representation. This exercise simulates the common task of creating a longitudinal patient summary from structured Electronic Health Record (EHR) data. By converting raw blood pressure readings into a time-ordered Mean Arterial Pressure ($MAP$) trajectory, you will practice handling critical challenges like unit normalization and aggregating multiple measurements into a single, clinically relevant data point [@problem_id:4856328].", "problem": "You are given a simplified, relational view of Electronic Health Record (EHR) data, which is a canonical example of structured health data within medical informatics. The data consist of three tables representing distinct sources and types of health data: encounters (administrative/visit records), observations (vital signs and measurements), and medications (orders). Your task is to write a program that computes a patient’s time-varying blood pressure trajectory by transforming and aggregating observations into a clinically meaningful scalar time series, adhering strictly to unit normalization and a defined policy for handling multiple measurements per encounter.\n\nFundamental base. Use the following foundational definitions and well-tested facts as the basis for your derivation and algorithm design:\n- Structured EHR data represent discrete, coded fields such as vital sign measurements and timestamps; these are a core type of health data originating from clinical encounters.\n- Blood pressure is commonly recorded as systolic blood pressure ($SBP$) and diastolic blood pressure ($DBP$). The pulse pressure is defined as $PP = SBP - DBP$.\n- The Mean Arterial Pressure (MAP) is a widely used scalar summary of arterial pressure approximated by $MAP = DBP + \\frac{1}{3} \\cdot (SBP - DBP)$. This formula is a well-tested clinical approximation.\n- Units may vary across sources; for blood pressure, a common unit conversion is $1 \\ \\mathrm{kPa} = 7.500616 \\ \\mathrm{mmHg}$, which is a linear transformation.\n\nSchema. Consider the following simplified schema:\n- Encounters table with rows $(enc\\_id, patient\\_id, start\\_time)$, where $start\\_time$ is an integer Unix epoch time in seconds.\n- Observations table with rows $(enc\\_id, patient\\_id, concept, value, unit, obs\\_time)$, where $concept \\in \\{\\text{\"SBP\"}, \\text{\"DBP\"}\\}$, $value$ is numeric, $unit \\in \\{\\text{\"mmHg\"}, \\text{\"kPa\"}\\}$, and $obs\\_time$ is integer Unix epoch seconds.\n- Medications table with rows $(enc\\_id, patient\\_id, med\\_code, dose, dose\\_unit)$; medications are included to reflect multiple data sources but are not used in the computation.\n\nRequired computation and policies.\n1. Unit normalization. Convert all observation values to $\\mathrm{mmHg}$. If $unit = \\text{\"kPa\"}$, compute $value\\_{\\mathrm{mmHg}} = value\\_{\\mathrm{kPa}} \\times c$ with $c = 7.500616$. If $unit = \\text{\"mmHg\"}$, keep the value as is.\n2. Multiple measurements per encounter. For each encounter, aggregate all normalized $SBP$ values by the median to obtain a per-encounter $SBP$ summary, and similarly aggregate all normalized $DBP$ values by the median to obtain a per-encounter $DBP$ summary. If an encounter lacks either $SBP$ or $DBP$, exclude that encounter from the trajectory since $MAP$ cannot be computed.\n3. Trajectory definition. For each encounter that has both $SBP$ and $DBP$, compute $MAP = DBP + \\frac{1}{3}(SBP - DBP)$ in $\\mathrm{mmHg}$, and round the result to $2$ decimal places. The trajectory is the list of these $MAP$ values, ordered by time.\n4. Time ordering. Order encounters for a patient by ascending $start\\_time$. In the event of ties (identical $start\\_time$), break ties by ascending lexicographic order of $enc\\_id$.\n5. Final output. For each test case below, output the patient’s $MAP$ trajectory as a list of floats in $\\mathrm{mmHg}$ rounded to $2$ decimal places. The program should produce a single line of output containing the results as a comma-separated list of these lists enclosed in square brackets (for example, $[\\,[x\\_1,x\\_2],\\,[y\\_1]\\,]$). No additional text should be printed.\n\nAngle units are not applicable. If you encounter percentages, express them as decimals, but this problem does not require percentages.\n\nTest suite. Your program must compute results for the following four test cases, each specifying the tables’ rows explicitly. All times are integer Unix epochs in seconds, and all blood pressure outputs must be in $\\mathrm{mmHg}$ rounded to $2$ decimal places.\n\n- Test case $1$ (happy path, multiple measurements in $\\mathrm{mmHg}$):\n  - Encounters:\n    - $(\"e1\",\"P1\",1000)$\n    - $(\"e2\",\"P1\",2000)$\n  - Observations:\n    - $(\"e1\",\"P1\",\"SBP\",120.0,\"mmHg\",1001)$\n    - $(\"e1\",\"P1\",\"SBP\",124.0,\"mmHg\",1002)$\n    - $(\"e1\",\"P1\",\"DBP\",80.0,\"mmHg\",1001)$\n    - $(\"e1\",\"P1\",\"DBP\",78.0,\"mmHg\",1003)$\n    - $(\"e2\",\"P1\",\"SBP\",130.0,\"mmHg\",2002)$\n    - $(\"e2\",\"P1\",\"SBP\",128.0,\"mmHg\",2003)$\n    - $(\"e2\",\"P1\",\"DBP\",85.0,\"mmHg\",2001)$\n  - Medications: may be non-empty but are ignored for computation.\n  - Expected behavior: medians per encounter produce valid $MAP$ values in order of $start\\_time$.\n\n- Test case $2$ (mixed units $\\mathrm{kPa}$ and $\\mathrm{mmHg}$, ordering sensitivity):\n  - Encounters:\n    - $(\"f2\",\"P2\",1400)$\n    - $(\"f1\",\"P2\",1500)$\n  - Observations:\n    - $(\"f1\",\"P2\",\"SBP\",16.0,\"kPa\",1502)$\n    - $(\"f1\",\"P2\",\"DBP\",10.5,\"kPa\",1501)$\n    - $(\"f2\",\"P2\",\"SBP\",125.0,\"mmHg\",1404)$\n    - $(\"f2\",\"P2\",\"DBP\",82.0,\"mmHg\",1401)$\n  - Medications: any rows; ignored for computation.\n\n- Test case $3$ (edge case: missing diastolic blood pressure in one encounter):\n  - Encounters:\n    - $(\"g1\",\"P3\",3000)$\n    - $(\"g2\",\"P3\",3100)$\n  - Observations:\n    - $(\"g1\",\"P3\",\"SBP\",110.0,\"mmHg\",3001)$\n    - $(\"g2\",\"P3\",\"SBP\",118.0,\"mmHg\",3103)$\n    - $(\"g2\",\"P3\",\"DBP\",76.0,\"mmHg\",3101)$\n    - $(\"g2\",\"P3\",\"DBP\",78.0,\"mmHg\",3102)$\n  - Medications: any rows; ignored for computation.\n\n- Test case $4$ (boundary: same $start\\_time$ tie across encounters, $\\mathrm{kPa}$ only, odd and even counts for medians):\n  - Encounters:\n    - $(\"h1\",\"P4\",5000)$\n    - $(\"h2\",\"P4\",5000)$\n  - Observations:\n    - $(\"h1\",\"P4\",\"SBP\",18.0,\"kPa\",5001)$\n    - $(\"h1\",\"P4\",\"SBP\",17.0,\"kPa\",5002)$\n    - $(\"h1\",\"P4\",\"SBP\",19.0,\"kPa\",5003)$\n    - $(\"h1\",\"P4\",\"DBP\",12.0,\"kPa\",5001)$\n    - $(\"h1\",\"P4\",\"DBP\",13.0,\"kPa\",5002)$\n    - $(\"h2\",\"P4\",\"SBP\",17.0,\"kPa\",5004)$\n    - $(\"h2\",\"P4\",\"DBP\",11.0,\"kPa\",5004)$\n  - Medications: any rows; ignored for computation.\n  - Tie-breaking: $enc\\_id$ lexicographic order places $\"h1\"$ before $\"h2\"$.\n\nYour program must implement the above logic exactly and produce a single line containing a list of $4$ elements, each of which is the computed list of $MAP$ values (in $\\mathrm{mmHg}$, rounded to $2$ decimals) for the corresponding test case, ordered by the policy described.", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and complete. All necessary data, formulae, and processing policies are provided to construct a unique and verifiable solution.\n\nThe task is to compute a patient's time-varying blood pressure trajectory from structured Electronic Health Record (EHR) data. This involves several steps of data transformation, aggregation, and calculation, guided by specified clinical and data-handling policies. The process begins with raw observations and concludes with a time-ordered series of Mean Arterial Pressure ($MAP$) values.\n\nThe algorithm proceeds as follows:\n\n1.  **Data Structuring and Grouping:** The initial step is to organize the raw observations. The `Observations` table provides a flat list of measurements. To perform per-encounter calculations, it is logical to first group these observations by their associated encounter identifier, `enc_id`. A dictionary is a suitable data structure for this, where each key is an `enc_id` and the value is another structure containing lists of Systolic Blood Pressure ($SBP$) and Diastolic Blood Pressure ($DBP$) measurements for that encounter.\n\n2.  **Unit Normalization:** The problem states that blood pressure values can be in one of two units: millimeters of mercury ($\\mathrm{mmHg}$) or kilopascals ($\\mathrm{kPa}$). To ensure consistency for subsequent calculations, all measurements must be converted to a single standard unit, which is specified as $\\mathrm{mmHg}$. The given conversion factor is $1 \\ \\mathrm{kPa} = 7.500616 \\ \\mathrm{mmHg}$. For each observation, we apply this linear transformation:\n    $$\n    \\text{value}_{\\mathrm{mmHg}} = \n    \\begin{cases} \n    \\text{value} & \\text{if unit} = \\text{\"mmHg\"} \\\\\n    \\text{value} \\times 7.500616 & \\text{if unit} = \\text{\"kPa\"}\n    \\end{cases}\n    $$\n    This normalization is performed as the data is ingested and grouped, ensuring all values used in later steps are in $\\mathrm{mmHg}$.\n\n3.  **Per-Encounter Aggregation and Filtering:** Clinical encounters can have multiple blood pressure measurements. Policy #2 dictates that these multiple measurements be aggregated into a single representative value for $SBP$ and $DBP$ for each encounter. The specified aggregation function is the median. For each encounter $i$, we compute summary statistics:\n    $$\n    SBP_{\\text{summary}, i} = \\mathrm{median}(\\{ SBP_{i,1}, SBP_{i,2}, \\dots \\})\n    $$\n    $$\n    DBP_{\\text{summary}, i} = \\mathrm{median}(\\{ DBP_{i,1}, DBP_{i,2}, \\dots \\})\n    $$\n    A critical rule is that if an encounter does not have at least one $SBP$ measurement AND at least one $DBP$ measurement, it is invalid for the purpose of $MAP$ calculation and must be excluded from the final trajectory.\n\n4.  **Mean Arterial Pressure (MAP) Calculation:** For each valid encounter (i.e., one with both $SBP$ and $DBP$ summary values), we compute the $MAP$. The problem provides the standard clinical approximation formula:\n    $$\n    MAP = DBP_{\\text{summary}} + \\frac{1}{3} (SBP_{\\text{summary}} - DBP_{\\text{summary}})\n    $$\n    This formula can also be written as $MAP = \\frac{1}{3} SBP_{\\text{summary}} + \\frac{2}{3} DBP_{\\text{summary}}$. The result of this calculation is in $\\mathrm{mmHg}$ and must be rounded to $2$ decimal places as per Policy #3.\n\n5.  **Temporal Trajectory Ordering:** The set of computed $MAP$ values constitutes the patient's trajectory, but it must be ordered chronologically. Policy #4 specifies a two-level sorting procedure. The primary sort key is the encounter `start_time`, in ascending order. In the case of a tie, where two or more encounters have the identical `start_time`, the tie is broken by sorting on the `enc_id` in ascending lexicographical order. This composite key ensures a deterministic and unique ordering for the final trajectory. To implement this, we form a list of tuples for all valid encounters, with each tuple containing the sorting keys and the calculated $MAP$ value, e.g., `(start_time, enc_id, MAP_value)`. After sorting this list, we extract the `MAP_value` component to form the final ordered list.\n\nBy executing these steps for each test case, we can generate the required output, which is a list containing the computed trajectory for each patient.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    \n    # Conversion constant from kPa to mmHg\n    KPA_TO_MMHG = 7.500616\n\n    # Test suite as defined in the problem statement\n    test_cases = [\n        # Test case 1\n        (\n            [(\"e1\", \"P1\", 1000), (\"e2\", \"P1\", 2000)],\n            [\n                (\"e1\", \"P1\", \"SBP\", 120.0, \"mmHg\", 1001),\n                (\"e1\", \"P1\", \"SBP\", 124.0, \"mmHg\", 1002),\n                (\"e1\", \"P1\", \"DBP\", 80.0, \"mmHg\", 1001),\n                (\"e1\", \"P1\", \"DBP\", 78.0, \"mmHg\", 1003),\n                (\"e2\", \"P1\", \"SBP\", 130.0, \"mmHg\", 2002),\n                (\"e2\", \"P1\", \"SBP\", 128.0, \"mmHg\", 2003),\n                (\"e2\", \"P1\", \"DBP\", 85.0, \"mmHg\", 2001),\n            ]\n        ),\n        # Test case 2\n        (\n            [(\"f2\", \"P2\", 1400), (\"f1\", \"P2\", 1500)],\n            [\n                (\"f1\", \"P2\", \"SBP\", 16.0, \"kPa\", 1502),\n                (\"f1\", \"P2\", \"DBP\", 10.5, \"kPa\", 1501),\n                (\"f2\", \"P2\", \"SBP\", 125.0, \"mmHg\", 1404),\n                (\"f2\", \"P2\", \"DBP\", 82.0, \"mmHg\", 1401),\n            ]\n        ),\n        # Test case 3\n        (\n            [(\"g1\", \"P3\", 3000), (\"g2\", \"P3\", 3100)],\n            [\n                (\"g1\", \"P3\", \"SBP\", 110.0, \"mmHg\", 3001),\n                (\"g2\", \"P3\", \"SBP\", 118.0, \"mmHg\", 3103),\n                (\"g2\", \"P3\", \"DBP\", 76.0, \"mmHg\", 3101),\n                (\"g2\", \"P3\", \"DBP\", 78.0, \"mmHg\", 3102),\n            ]\n        ),\n        # Test case 4\n        (\n            [(\"h1\", \"P4\", 5000), (\"h2\", \"P4\", 5000)],\n            [\n                (\"h1\", \"P4\", \"SBP\", 18.0, \"kPa\", 5001),\n                (\"h1\", \"P4\", \"SBP\", 17.0, \"kPa\", 5002),\n                (\"h1\", \"P4\", \"SBP\", 19.0, \"kPa\", 5003),\n                (\"h1\", \"P4\", \"DBP\", 12.0, \"kPa\", 5001),\n                (\"h1\", \"P4\", \"DBP\", 13.0, \"kPa\", 5002),\n                (\"h2\", \"P4\", \"SBP\", 17.0, \"kPa\", 5004),\n                (\"h2\", \"P4\", \"DBP\", 11.0, \"kPa\", 5004),\n            ]\n        )\n    ]\n\n    def process_case(encounters, observations):\n        \"\"\"\n        Processes a single test case to compute the MAP trajectory.\n        \"\"\"\n        \n        # 1. Structure data: map enc_id to start_time and group observations by enc_id\n        enc_info = {enc_id: start_time for enc_id, _, start_time in encounters}\n        \n        obs_by_enc = {}\n        for enc_id, _, concept, value, unit, _ in observations:\n            if enc_id not in obs_by_enc:\n                obs_by_enc[enc_id] = {\"SBP\": [], \"DBP\": []}\n            \n            # 2. Unit normalization to mmHg\n            normalized_value = value\n            if unit == \"kPa\":\n                normalized_value *= KPA_TO_MMHG\n            \n            obs_by_enc[enc_id][concept].append(normalized_value)\n\n        results_to_sort = []\n        for enc_id, pressures in obs_by_enc.items():\n            sbp_values = pressures[\"SBP\"]\n            dbp_values = pressures[\"DBP\"]\n\n            # 3. Filter encounters without both SBP and DBP\n            if not sbp_values or not dbp_values:\n                continue\n\n            # 3. Per-encounter aggregation using median\n            sbp_median = np.median(sbp_values)\n            dbp_median = np.median(dbp_values)\n\n            # 4. MAP Calculation\n            map_val = dbp_median + (sbp_median - dbp_median) / 3.0\n            \n            rounded_map = round(map_val, 2)\n\n            start_time = enc_info[enc_id]\n            results_to_sort.append((start_time, enc_id, rounded_map))\n        \n        # 5. Temporal Ordering\n        # Sort by start_time (primary) and enc_id (secondary)\n        results_to_sort.sort(key=lambda x: (x[0], x[1]))\n        \n        # Extract the sorted MAP values to form the trajectory\n        trajectory = [item[2] for item in results_to_sort]\n        \n        return trajectory\n\n    # Process all test cases\n    final_results = [process_case(enc, obs) for enc, obs in test_cases]\n    \n    # 6. Format final output string as per specifications\n    # e.g., [[93.33,99.67],[96.33,92.51],...]\n    results_as_strings = []\n    for trajectory in final_results:\n        trajectory_str = f\"[{','.join(map(str, trajectory))}]\"\n        results_as_strings.append(trajectory_str)\n        \n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```", "id": "4856328"}, {"introduction": "Many powerful applications in medical informatics rely on integrating diverse types of health data to answer complex questions. This advanced practice guides you through the process of building and evaluating \"computable phenotypes\"—algorithms that identify patients with a specific condition. You will learn to synthesize information from diagnosis codes, medication orders, and laboratory results to define several distinct phenotyping rules and then measure their performance, mirroring the work done to create patient cohorts for research and quality improvement [@problem_id:4856368].", "problem": "You are given a small, synthetic Electronic Health Record (EHR) dataset constructed from standard sources and types of health data used in medical informatics: International Classification of Diseases (ICD) diagnosis codes, antidiabetic medication orders, and laboratory measurements (fasting plasma glucose and hemoglobin A1c). Your task is to implement four computable phenotyping algorithms for type $2$ diabetes mellitus and evaluate each algorithm’s sensitivity and positive predictive value (PPV) against a chart review gold standard, then compute the F-score to support algorithm selection. All computations must be expressed in purely mathematical and logical terms using set membership, counting events, and threshold comparisons.\n\nFundamental base to use:\n- Confusion matrix definitions grounded in frequency-based probabilities: sensitivity and positive predictive value (PPV). Sensitivity is recall and PPV is precision. The F-score is the harmonic mean of precision and recall.\n- Standard clinical lab thresholds for type $2$ diabetes mellitus adapted for computation: hemoglobin A1c threshold $t_{\\text{A1c}} = 0.065$ (A1c expressed as a decimal fraction, not with a percent sign), and fasting plasma glucose threshold $t_{\\text{FPG}} = 126$ mg/dL.\n\nCore definitions:\n- Sensitivity (recall) $S = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}$, where $\\text{TP}$ is true positives and $\\text{FN}$ is false negatives.\n- Positive predictive value (PPV, precision) $P = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}$, where $\\text{FP}$ is false positives.\n- F-score $F = \\dfrac{2 \\cdot P \\cdot S}{P + S}$ when $P + S > 0$, else $F = 0$.\n- Edge-case conventions: if $\\text{TP} + \\text{FN} = 0$, set sensitivity $S = 0$. If $\\text{TP} + \\text{FP} = 0$, set PPV $P = 0$.\n\nData model and source types:\n- Diagnosis events: a list of pairs $(c_i, d_i)$, where $c_i$ is an ICD code and $d_i$ is a day index (integer). The type $2$ diabetes code list is $\\mathcal{C}_{\\text{T2D}} = \\{\\text{\"E11\"}, \\text{\"E11.9\"}, \\text{\"250.00\"}\\}$.\n- Medication events: a list of pairs $(m_j, d_j)$, where $m_j$ is a medication code and $d_j$ is a day index. The antidiabetic medication list is $\\mathcal{M}_{\\text{T2D}} = \\{\\text{\"MET\"}, \\text{\"SULF\"}, \\text{\"INS\"}, \\text{\"GLP1\"}\\}$.\n- Laboratory measurements: two lists, A1c values as pairs $(a_k, d_k)$ with $a_k$ in decimal fraction, and fasting plasma glucose values as pairs $(g_\\ell, d_\\ell)$ with $g_\\ell$ in mg/dL.\n- Chart review gold standard: a boolean label $y \\in \\{0,1\\}$ per patient indicating presence ($1$) or absence ($0$) of type $2$ diabetes mellitus.\n\nPhenotyping algorithms to implement:\n- Algorithm $\\mathcal{A}$ (inclusive): predicts positive if any of the following holds:\n  1. At least one diagnosis event with $c_i \\in \\mathcal{C}_{\\text{T2D}}$.\n  2. At least two antidiabetic medication events within $180$ days: there exist $(m_{j_1}, d_{j_1})$ and $(m_{j_2}, d_{j_2})$ with $m_{j_1}, m_{j_2} \\in \\mathcal{M}_{\\text{T2D}}$ and $|d_{j_2} - d_{j_1}| \\le 180$.\n  3. Any A1c value $a_k$ satisfies $a_k \\ge t_{\\text{A1c}}$.\n  4. At least two fasting plasma glucose values $g_{\\ell}$ satisfy $g_{\\ell} \\ge t_{\\text{FPG}}$ on different days.\n- Algorithm $\\mathcal{B}$ (specific): predicts positive if any of the following holds:\n  1. At least two diagnosis events with $c_i \\in \\mathcal{C}_{\\text{T2D}}$ on distinct days.\n  2. At least one antidiabetic medication event ($m_j \\in \\mathcal{M}_{\\text{T2D}}$) and at least one lab criterion positive: $(\\exists k: a_k \\ge t_{\\text{A1c}})$ or $(\\exists \\ell: g_{\\ell} \\ge t_{\\text{FPG}})$.\n  3. Both lab types positive: $(\\exists k: a_k \\ge t_{\\text{A1c}})$ and $(\\exists \\ell: g_{\\ell} \\ge t_{\\text{FPG}})$.\n- Algorithm $\\mathcal{C}$ (minimal): predicts positive if any single signal is present:\n  1. At least one diagnosis event with $c_i \\in \\mathcal{C}_{\\text{T2D}}$.\n  2. At least one antidiabetic medication event with $m_j \\in \\mathcal{M}_{\\text{T2D}}$.\n  3. $(\\exists k: a_k \\ge t_{\\text{A1c}})$.\n  4. $(\\exists \\ell: g_{\\ell} \\ge t_{\\text{FPG}})$.\n- Algorithm $\\mathcal{D}$ (stringent conjunction): predicts positive only if all of the following hold simultaneously:\n  1. At least two diagnosis events with $c_i \\in \\mathcal{C}_{\\text{T2D}}$ on distinct days.\n  2. At least two antidiabetic medication events within $180$ days.\n  3. $(\\exists k: a_k \\ge t_{\\text{A1c}})$.\n  4. At least two fasting plasma glucose values $g_{\\ell}$ satisfy $g_{\\ell} \\ge t_{\\text{FPG}}$ on different days.\n\nTest suite (patients $1$ through $12$):\nFor each patient, data are given as sets of events and labels. All day indices are integers; all A1c values are decimal fractions; fasting plasma glucose values are in mg/dL.\n\n- Patient $1$, $y=1$:\n  - Diagnoses: $(\\text{\"E11\"}, 10)$, $(\\text{\"E11.9\"}, 80)$.\n  - Medications: $(\\text{\"MET\"}, 15)$.\n  - A1c: $(0.072, 12)$.\n  - FPG: $(145, 11)$, $(150, 85)$.\n- Patient $2$, $y=1$:\n  - Diagnoses: none.\n  - Medications: $(\\text{\"MET\"}, 5)$, $(\\text{\"MET\"}, 100)$.\n  - A1c: $(0.062, 30)$.\n  - FPG: $(130, 35)$.\n- Patient $3$, $y=0$:\n  - Diagnoses: none.\n  - Medications: none.\n  - A1c: $(0.058, 25)$.\n  - FPG: $(110, 27)$.\n- Patient $4$, $y=1$:\n  - Diagnoses: none.\n  - Medications: none.\n  - A1c: $(0.068, 44)$.\n  - FPG: $(118, 46)$.\n- Patient $5$, $y=0$:\n  - Diagnoses: $(\\text{\"E11\"}, 200)$.\n  - Medications: none.\n  - A1c: $(0.059, 210)$.\n  - FPG: $(115, 212)$.\n- Patient $6$, $y=1$:\n  - Diagnoses: none.\n  - Medications: none.\n  - A1c: none.\n  - FPG: $(128, 60)$, $(130, 190)$.\n- Patient $7$, $y=0$:\n  - Diagnoses: none.\n  - Medications: $(\\text{\"MET\"}, 300)$.\n  - A1c: $(0.060, 302)$.\n  - FPG: $(100, 303)$.\n- Patient $8$, $y=1$:\n  - Diagnoses: $(\\text{\"E11\"}, 120)$.\n  - Medications: none.\n  - A1c: $(0.070, 121)$.\n  - FPG: $(125, 119)$.\n- Patient $9$, $y=1$:\n  - Diagnoses: $(\\text{\"E11.9\"}, 50)$.\n  - Medications: $(\\text{\"INS\"}, 51)$, $(\\text{\"MET\"}, 200)$.\n  - A1c: $(0.066, 52)$.\n  - FPG: $(140, 53)$.\n- Patient $10$, $y=0$:\n  - Diagnoses: $(\\text{\"E11\"}, 160)$, $(\\text{\"E11.9\"}, 161)$.\n  - Medications: none.\n  - A1c: $(0.061, 162)$.\n  - FPG: $(120, 163)$.\n- Patient $11$, $y=1$:\n  - Diagnoses: none.\n  - Medications: $(\\text{\"SULF\"}, 70)$.\n  - A1c: $(0.067, 71)$.\n  - FPG: $(129, 72)$.\n- Patient $12$, $y=0$:\n  - Diagnoses: none.\n  - Medications: none.\n  - A1c: $(0.064, 15)$.\n  - FPG: $(125, 16)$.\n\nRequirements:\n1. Implement the four algorithms $\\mathcal{A}$, $\\mathcal{B}$, $\\mathcal{C}$, and $\\mathcal{D}$ exactly as defined above using the given code lists and lab thresholds $t_{\\text{A1c}} = 0.065$ and $t_{\\text{FPG}} = 126$ mg/dL.\n2. For each algorithm, compute sensitivity $S$, PPV $P$, and F-score $F$ against the chart review gold standard for the $12$ patients. Apply the edge-case conventions for zero denominators specified above.\n3. Round each $S$, $P$, and $F$ to $3$ decimal places.\n4. Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The $i$-th element must be a list $[S_i,P_i,F_i]$ for algorithm $i$ in the order $\\mathcal{A}, \\mathcal{B}, \\mathcal{C}, \\mathcal{D}$. For example, the output must look like $[[S_{\\mathcal{A}},P_{\\mathcal{A}},F_{\\mathcal{A}}],[S_{\\mathcal{B}},P_{\\mathcal{B}},F_{\\mathcal{B}}],[S_{\\mathcal{C}},P_{\\mathcal{C}},F_{\\mathcal{C}}],[S_{\\mathcal{D}},P_{\\mathcal{D}},F_{\\mathcal{D}}]]$.", "solution": "The user has provided a problem statement that is internally consistent, scientifically grounded in the domain of medical informatics, and well-posed. All data, definitions, thresholds, and logical rules required for a unique solution are explicitly provided. The problem is a valid exercise in implementing and evaluating computable phenotyping algorithms. Therefore, a complete solution is warranted.\n\nThe task is to implement four distinct computable phenotyping algorithms ($\\mathcal{A}$, $\\mathcal{B}$, $\\mathcal{C}$, and $\\mathcal{D}$) for type $2$ diabetes mellitus, apply them to a dataset of $12$ synthetic patients, and evaluate their performance against a gold standard. The performance metrics to be computed are sensitivity ($S$), positive predictive value ($P$), and the F-score ($F$).\n\nFirst, we formalize the given parameters and definitions.\nThe laboratory thresholds are $t_{\\text{A1c}} = 0.065$ and $t_{\\text{FPG}} = 126$ mg/dL.\nThe set of relevant ICD codes is $\\mathcal{C}_{\\text{T2D}} = \\{\\text{\"E11\"}, \\text{\"E11.9\"}, \\text{\"250.00\"}\\}$.\nThe set of relevant antidiabetic medications is $\\mathcal{M}_{\\text{T2D}} = \\{\\text{\"MET\"}, \\text{\"SULF\"}, \\text{\"INS\"}, \\text{\"GLP1\"}\\}$.\nThe gold standard for patient $p$ is denoted $y_p \\in \\{0, 1\\}$. An algorithm's prediction is $\\hat{y}_p \\in \\{0, 1\\}$.\n\nThe evaluation metrics are defined as:\n- Sensitivity: $S = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FN}}$\n- Positive Predictive Value (PPV): $P = \\dfrac{\\text{TP}}{\\text{TP} + \\text{FP}}$\n- F-score: $F = \\dfrac{2 \\cdot P \\cdot S}{P + S}$\n\nHere, $\\text{TP}$ is the count of true positives ($\\hat{y}_p = 1, y_p = 1$), $\\text{FP}$ is the count of false positives ($\\hat{y}_p = 1, y_p = 0$), and $\\text{FN}$ is the count of false negatives ($\\hat{y}_p = 0, y_p = 1$). The edge cases are handled by setting $S=0$ if $\\text{TP} + \\text{FN} = 0$, $P=0$ if $\\text{TP} + \\text{FP} = 0$, and $F=0$ if $P+S=0$.\n\nTo systematically apply the algorithms, we define a set of binary feature indicators for each patient based on their data:\n1.  $f_{\\text{dx1}}(p)$: True if the patient has at least one diagnosis in $\\mathcal{C}_{\\text{T2D}}$.\n2.  $f_{\\text{dx2}}(p)$: True if the patient has at least two diagnoses in $\\mathcal{C}_{\\text{T2D}}$ on distinct days.\n3.  $f_{\\text{med1}}(p)$: True if the patient has at least one medication in $\\mathcal{M}_{\\text{T2D}}$.\n4.  $f_{\\text{med2}}(p)$: True if the patient has at least two medications in $\\mathcal{M}_{\\text{T2D}}$ with order dates $d_{j_1}, d_{j_2}$ such that $|d_{j_2} - d_{j_1}| \\le 180$.\n5.  $f_{\\text{a1c}}(p)$: True if the patient has any A1c measurement $a_k \\ge t_{\\text{A1c}}$.\n6.  $f_{\\text{fpg1}}(p)$: True if the patient has any fasting plasma glucose measurement $g_\\ell \\ge t_{\\text{FPG}}$.\n7.  $f_{\\text{fpg2}}(p)$: True if the patient has at least two fasting plasma glucose measurements $g_\\ell \\ge t_{\\text{FPG}}$ on distinct days.\n\nUsing these indicators, the algorithms are defined as:\n-   $\\mathcal{A}(p) = f_{\\text{dx1}}(p) \\lor f_{\\text{med2}}(p) \\lor f_{\\text{a1c}}(p) \\lor f_{\\text{fpg2}}(p)$\n-   $\\mathcal{B}(p) = f_{\\text{dx2}}(p) \\lor (f_{\\text{med1}}(p) \\land (f_{\\text{a1c}}(p) \\lor f_{\\text{fpg1}}(p))) \\lor (f_{\\text{a1c}}(p) \\land f_{\\text{fpg1}}(p))$\n-   $\\mathcal{C}(p) = f_{\\text{dx1}}(p) \\lor f_{\\text{med1}}(p) \\lor f_{\\text{a1c}}(p) \\lor f_{\\text{fpg1}}(p)$\n-   $\\mathcal{D}(p) = f_{\\text{dx2}}(p) \\land f_{\\text{med2}}(p) \\land f_{\\text{a1c}}(p) \\land f_{\\text{fpg2}}(p)$\n\nWe evaluate these features for each of the $12$ patients:\n\n| Patient ($p$) | $y_p$ | $f_{\\text{dx1}}$ | $f_{\\text{dx2}}$ | $f_{\\text{med1}}$ | $f_{\\text{med2}}$ | $f_{\\text{a1c}}$ | $f_{\\text{fpg1}}$ | $f_{\\text{fpg2}}$ |\n|:-------------:|:-----:|:----------------:|:----------------:|:-----------------:|:-----------------:|:----------------:|:------------------:|:------------------:|\n| 1             | 1     | T                | T                | T                 | F                 | T                | T                  | T                  |\n| 2             | 1     | F                | F                | T                 | T                 | F                | T                  | F                  |\n| 3             | 0     | F                | F                | F                 | F                 | F                | F                  | F                  |\n| 4             | 1     | F                | F                | F                 | F                 | T                | F                  | F                  |\n| 5             | 0     | T                | F                | F                 | F                 | F                | F                  | F                  |\n| 6             | 1     | F                | F                | F                 | F                 | F                | T                  | T                  |\n| 7             | 0     | F                | F                | T                 | F                 | F                | F                  | F                  |\n| 8             | 1     | T                | F                | F                 | F                 | T                | F                  | F                  |\n| 9             | 1     | T                | F                | T                 | T                 | T                | T                  | F                  |\n| 10            | 0     | T                | T                | F                 | F                 | F                | F                  | F                  |\n| 11            | 1     | F                | F                | T                 | F                 | T                | T                  | F                  |\n| 12            | 0     | F                | F                | F                 | F                 | F                | F                  | F                  |\n\nThe total number of positive cases in the gold standard is $N_P = \\text{TP} + \\text{FN} = 7$.\nThe total number of negative cases is $N_N = \\text{FP} + \\text{TN} = 5$.\n\nNext, we determine the prediction $\\hat{y}_p$ for each algorithm and patient, and then compute the confusion matrix elements.\n\n**Algorithm $\\mathcal{A}$ Evaluation:**\n- Predictions ($\\hat{y}_{\\mathcal{A}}$): P1(1), P2(1), P3(0), P4(1), P5(1), P6(1), P7(0), P8(1), P9(1), P10(1), P11(1), P12(0).\n- $\\text{TP} = 7$ (P1, P2, P4, P6, P8, P9, P11)\n- $\\text{FP} = 2$ (P5, P10)\n- $\\text{TN} = 3$ (P3, P7, P12)\n- $\\text{FN} = 0$\n- $S = \\frac{7}{7+0} = 1.0$\n- $P = \\frac{7}{7+2} = \\frac{7}{9} \\approx 0.778$\n- $F = \\frac{2 \\cdot 0.778 \\cdot 1.0}{0.778 + 1.0} = \\frac{1.556}{1.778} \\approx 0.875$\n\n**Algorithm $\\mathcal{B}$ Evaluation:**\n- Predictions ($\\hat{y}_{\\mathcal{B}}$): P1(1), P2(1), P3(0), P4(0), P5(0), P6(0), P7(0), P8(0), P9(1), P10(1), P11(1), P12(0).\n- $\\text{TP} = 4$ (P1, P2, P9, P11)\n- $\\text{FP} = 1$ (P10)\n- $\\text{TN} = 4$ (P3, P5, P7, P12)\n- $\\text{FN} = 3$ (P4, P6, P8)\n- $S = \\frac{4}{4+3} = \\frac{4}{7} \\approx 0.571$\n- $P = \\frac{4}{4+1} = \\frac{4}{5} = 0.8$\n- $F = \\frac{2 \\cdot 0.8 \\cdot 0.571}{0.8 + 0.571} = \\frac{0.9136}{1.371} \\approx 0.667$\n\n**Algorithm $\\mathcal{C}$ Evaluation:**\n- Predictions ($\\hat{y}_{\\mathcal{C}}$): P1(1), P2(1), P3(0), P4(1), P5(1), P6(1), P7(1), P8(1), P9(1), P10(1), P11(1), P12(0).\n- $\\text{TP} = 7$ (P1, P2, P4, P6, P8, P9, P11)\n- $\\text{FP} = 3$ (P5, P7, P10)\n- $\\text{TN} = 2$ (P3, P12)\n- $\\text{FN} = 0$\n- $S = \\frac{7}{7+0} = 1.0$\n- $P = \\frac{7}{7+3} = \\frac{7}{10} = 0.7$\n- $F = \\frac{2 \\cdot 0.7 \\cdot 1.0}{0.7 + 1.0} = \\frac{1.4}{1.7} \\approx 0.824$\n\n**Algorithm $\\mathcal{D}$ Evaluation:**\n- Predictions ($\\hat{y}_{\\mathcal{D}}$): P1(0), P2(0), P3(0), P4(0), P5(0), P6(0), P7(0), P8(0), P9(0), P10(0), P11(0), P12(0).\n- $\\text{TP} = 0$\n- $\\text{FP} = 0$\n- $\\text{TN} = 5$ (P3, P5, P7, P10, P12)\n- $\\text{FN} = 7$ (P1, P2, P4, P6, P8, P9, P11)\n- $S = \\frac{0}{0+7} = 0.0$\n- $P = \\frac{0}{0+0} = 0.0$ (by edge-case rule)\n- $F = 0.0$ (since $P+S=0$)\n\nThe final results, rounded to $3$ decimal places, are:\n- Algorithm $\\mathcal{A}$: $[S, P, F] = [1.000, 0.778, 0.875]$\n- Algorithm $\\mathcal{B}$: $[S, P, F] = [0.571, 0.800, 0.667]$\n- Algorithm $\\mathcal{C}$: $[S, P, F] = [1.000, 0.700, 0.824]$\n- Algorithm $\\mathcal{D}$: $[S, P, F] = [0.000, 0.000, 0.000]$\n\nThese results will be formatted into the required list of lists for the final output.", "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Implements and evaluates four computable phenotyping algorithms for Type 2 Diabetes.\n    \"\"\"\n    \n    # Define constants and code lists\n    C_T2D = {\"E11\", \"E11.9\", \"250.00\"}\n    M_T2D = {\"MET\", \"SULF\", \"INS\", \"GLP1\"}\n    T_A1C = 0.065\n    T_FPG = 126\n\n    # Test suite data for 12 patients\n    test_cases = [\n        {\"id\": 1, \"y\": 1, \"dx\": [(\"E11\", 10), (\"E11.9\", 80)], \"med\": [(\"MET\", 15)], \"a1c\": [(0.072, 12)], \"fpg\": [(145, 11), (150, 85)]},\n        {\"id\": 2, \"y\": 1, \"dx\": [], \"med\": [(\"MET\", 5), (\"MET\", 100)], \"a1c\": [(0.062, 30)], \"fpg\": [(130, 35)]},\n        {\"id\": 3, \"y\": 0, \"dx\": [], \"med\": [], \"a1c\": [(0.058, 25)], \"fpg\": [(110, 27)]},\n        {\"id\": 4, \"y\": 1, \"dx\": [], \"med\": [], \"a1c\": [(0.068, 44)], \"fpg\": [(118, 46)]},\n        {\"id\": 5, \"y\": 0, \"dx\": [(\"E11\", 200)], \"med\": [], \"a1c\": [(0.059, 210)], \"fpg\": [(115, 212)]},\n        {\"id\": 6, \"y\": 1, \"dx\": [], \"med\": [], \"a1c\": [], \"fpg\": [(128, 60), (130, 190)]},\n        {\"id\": 7, \"y\": 0, \"dx\": [], \"med\": [(\"MET\", 300)], \"a1c\": [(0.060, 302)], \"fpg\": [(100, 303)]},\n        {\"id\": 8, \"y\": 1, \"dx\": [(\"E11\", 120)], \"med\": [], \"a1c\": [(0.070, 121)], \"fpg\": [(125, 119)]},\n        {\"id\": 9, \"y\": 1, \"dx\": [(\"E11.9\", 50)], \"med\": [(\"INS\", 51), (\"MET\", 200)], \"a1c\": [(0.066, 52)], \"fpg\": [(140, 53)]},\n        {\"id\": 10, \"y\": 0, \"dx\": [(\"E11\", 160), (\"E11.9\", 161)], \"med\": [], \"a1c\": [(0.061, 162)], \"fpg\": [(120, 163)]},\n        {\"id\": 11, \"y\": 1, \"dx\": [], \"med\": [(\"SULF\", 70)], \"a1c\": [(0.067, 71)], \"fpg\": [(129, 72)]},\n        {\"id\": 12, \"y\": 0, \"dx\": [], \"med\": [], \"a1c\": [(0.064, 15)], \"fpg\": [(125, 16)]},\n    ]\n\n    # --- Helper functions for algorithm conditions ---\n    def f_dx1(p): return any(c in C_T2D for c, d in p[\"dx\"])\n    def f_dx2(p):\n        t2d_dx_days = {d for c, d in p[\"dx\"] if c in C_T2D}\n        return len(t2d_dx_days) >= 2\n    def f_med1(p): return any(m in M_T2D for m, d in p[\"med\"])\n    def f_med2(p):\n        t2d_meds = [(m, d) for m, d in p[\"med\"] if m in M_T2D]\n        if len(t2d_meds) < 2: return False\n        return any(abs(d1 - d2) <= 180 for (_, d1), (_, d2) in combinations(t2d_meds, 2))\n    def f_a1c(p): return any(a >= T_A1C for a, d in p[\"a1c\"])\n    def f_fpg1(p): return any(g >= T_FPG for g, d in p[\"fpg\"])\n    def f_fpg2(p):\n        high_fpg_days = {d for g, d in p[\"fpg\"] if g >= T_FPG}\n        return len(high_fpg_days) >= 2\n\n    # --- Phenotyping Algorithms ---\n    def algo_A(p): return f_dx1(p) or f_med2(p) or f_a1c(p) or f_fpg2(p)\n    def algo_B(p): return f_dx2(p) or (f_med1(p) and (f_a1c(p) or f_fpg1(p))) or (f_a1c(p) and f_fpg1(p))\n    def algo_C(p): return f_dx1(p) or f_med1(p) or f_a1c(p) or f_fpg1(p)\n    def algo_D(p): return f_dx2(p) and f_med2(p) and f_a1c(p) and f_fpg2(p)\n\n    algorithms = [algo_A, algo_B, algo_C, algo_D]\n    all_results = []\n\n    for algo in algorithms:\n        tp, fp, tn, fn = 0, 0, 0, 0\n        for patient in test_cases:\n            y_true = patient[\"y\"]\n            y_pred = 1 if algo(patient) else 0\n            \n            if y_pred == 1 and y_true == 1:\n                tp += 1\n            elif y_pred == 1 and y_true == 0:\n                fp += 1\n            elif y_pred == 0 and y_true == 0:\n                tn += 1\n            elif y_pred == 0 and y_true == 1:\n                fn += 1\n\n        # Calculate metrics with edge-case handling\n        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n        ppv = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n        f_score = (2 * ppv * sensitivity) / (ppv + sensitivity) if (ppv + sensitivity) > 0 else 0.0\n        \n        # Round to 3 decimal places\n        s_rounded = round(sensitivity, 3)\n        p_rounded = round(ppv, 3)\n        f_rounded = round(f_score, 3)\n        \n        # Ensure floating point representation\n        all_results.append([float(s_rounded), float(p_rounded), float(f_rounded)])\n\n    # Format the final output string\n    # Using a nested list comprehension and str.format for precise output\n    result_str = '[' + ','.join([f'[{s},{p},{f}]' for s, p, f in all_results]) + ']'\n    print(result_str)\n\nsolve()\n```", "id": "4856368"}]}