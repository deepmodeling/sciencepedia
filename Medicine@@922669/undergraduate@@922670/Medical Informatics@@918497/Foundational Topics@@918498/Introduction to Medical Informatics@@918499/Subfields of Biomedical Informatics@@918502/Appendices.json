{"hands_on_practices": [{"introduction": "Clinical data is often recorded using a variety of different coding systems, creating a major barrier to data sharing and large-scale analysis. This exercise immerses you in the fundamental task of terminology mapping, where data from local or specialized systems are translated into universal standards like SNOMED CT and LOINC. By implementing and evaluating these mappings, you will practice a core skill for achieving data interoperability and learn to quantify your success using standard information retrieval metrics like precision, recall, and the $F_1$ score [@problem_id:4857505].", "problem": "You are given a scenario from clinical terminology and standards mapping, a subfield of biomedical informatics focused on interoperable representations of clinical concepts. An Electronic Health Record (EHR) contains a problem list encoded in the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) and a lab panel encoded in local laboratory codes. Your task is to design a program that maps these source codes to Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT) for problems and Logical Observation Identifiers Names and Codes (LOINC) for labs using provided crosswalk dictionaries, and then evaluate mapping quality against a provided gold standard concept alignment.\n\nFundamental base for evaluation draws from set theory and Information Retrieval: given a set of predicted alignments $P$ and a set of gold alignments $G$, the counts are defined as true positives $TP = |P \\cap G|$, false positives $FP = |P \\setminus G|$, and false negatives $FN = |G \\setminus P|$. Precision, recall, and harmonic mean $F_1$ are then defined as\n$$\\text{precision} = \\begin{cases}\n\\frac{TP}{|P|} & \\text{if } |P| > 0 \\\\\n0 & \\text{if } |P| = 0\n\\end{cases},\\quad\n\\text{recall} = \\begin{cases}\n\\frac{TP}{|G|} & \\text{if } |G| > 0 \\\\\n0 & \\text{if } |G| = 0\n\\end{cases},\\quad\nF_1 = \\begin{cases}\n\\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}} & \\text{if } \\text{precision} + \\text{recall} > 0 \\\\\n0 & \\text{otherwise}\n\\end{cases}.$$\n\nDesign assumptions and constraints:\n- Mapping is by exact code equivalence using provided crosswalks:\n  - ICD-10-CM to SNOMED CT mapping function $f_{\\text{diag}}$ is a dictionary from ICD-10-CM codes to SNOMED CT concept identifiers.\n  - Local lab to LOINC mapping function $f_{\\text{lab}}$ is a dictionary from local lab codes to LOINC codes.\n- For a source code not present in the corresponding crosswalk, no predicted alignment is produced.\n- Concept equivalence under the gold standard is by exact equality of target codes. If a predicted target code differs from the gold target code for the same source, it contributes one $FP$ and one $FN$ in aggregate counts (because the incorrect predicted pair is not in $G$ and the correct gold pair is not in $P$).\n- All EHR items are treated independently; the predicted alignment set $P$ is the union of all pairs produced by $f_{\\text{diag}}$ and $f_{\\text{lab}}$ for the case’s EHR inputs.\n\nProvided global crosswalk dictionaries to be used for all test cases:\n- ICD-10-CM to SNOMED CT ($f_{\\text{diag}}$):\n  - $ \\texttt{I10} \\mapsto \\texttt{59621000} $ (Essential hypertension)\n  - $ \\texttt{E11.9} \\mapsto \\texttt{44054006} $ (Type 2 diabetes mellitus)\n  - $ \\texttt{J45.909} \\mapsto \\texttt{195967001} $ (Asthma)\n  - $ \\texttt{R79.9} \\mapsto \\texttt{165346000} $ (Abnormal blood chemistry)\n  - $ \\texttt{M54.5} \\mapsto \\texttt{279039007} $ (Low back pain)\n- Local lab to LOINC ($f_{\\text{lab}}$):\n  - $ \\texttt{LIPID\\_PANEL} \\mapsto \\texttt{24331-1} $\n  - $ \\texttt{GLU\\_FAST} \\mapsto \\texttt{1557-8} $\n  - $ \\texttt{A1C} \\mapsto \\texttt{4548-4} $\n  - $ \\texttt{CREA\\_SER} \\mapsto \\texttt{2160-0} $\n\nTest suite:\n- Case $1$ (general case with an intentionally over-mapped ambiguous diagnosis):\n  - EHR problems: $[\\texttt{I10}, \\texttt{E11.9}, \\texttt{J45.909}, \\texttt{R79.9}]$\n  - EHR labs: $[\\texttt{LIPID\\_PANEL}, \\texttt{A1C}, \\texttt{CREA\\_SER}]$\n  - Gold alignments $G$:\n    - Problems: $(\\texttt{I10}, \\texttt{59621000})$, $(\\texttt{E11.9}, \\texttt{44054006})$, $(\\texttt{J45.909}, \\texttt{195967001})$\n    - Labs: $(\\texttt{LIPID\\_PANEL}, \\texttt{24331-1})$, $(\\texttt{A1C}, \\texttt{4548-4})$, $(\\texttt{CREA\\_SER}, \\texttt{2160-0})$\n- Case $2$ (empty inputs):\n  - EHR problems: $[\\ ]$\n  - EHR labs: $[\\ ]$\n  - Gold alignments $G$: empty set\n- Case $3$ (partial coverage and a unit-system mismatch on fasting glucose):\n  - EHR problems: $[\\texttt{I10}, \\texttt{E11.65}, \\texttt{M54.5}]$\n  - EHR labs: $[\\texttt{GLU\\_FAST}, \\texttt{A1C}]$\n  - Gold alignments $G$:\n    - Problems: $(\\texttt{I10}, \\texttt{59621000})$, $(\\texttt{E11.65}, \\texttt{237599002})$, $(\\texttt{M54.5}, \\texttt{279039007})$\n    - Labs: $(\\texttt{GLU\\_FAST}, \\texttt{1558-6})$, $(\\texttt{A1C}, \\texttt{4548-4})\n- Case $4$ (no mappings available in crosswalk but gold expects one):\n  - EHR problems: $[\\texttt{E11.65}]$\n  - EHR labs: $[\\ ]$\n  - Gold alignments $G$: $(\\texttt{E11.65}, \\texttt{237599002})$\n- Case $5$ (gold excludes mappings for ambiguous or context-dependent items):\n  - EHR problems: $[\\texttt{R79.9}]$\n  - EHR labs: $[\\texttt{LIPID\\_PANEL}]$\n  - Gold alignments $G$: empty set\n- Case $6$ (perfect mapping):\n  - EHR problems: $[\\texttt{I10}, \\texttt{E11.9}]$\n  - EHR labs: $[\\texttt{A1C}]$\n  - Gold alignments $G$: $(\\texttt{I10}, \\texttt{59621000})$, $(\\texttt{E11.9}, \\texttt{44054006})$, $(\\texttt{A1C}, \\texttt{4548-4})\n\nProgramming requirements:\n- Implement mapping by applying $f_{\\text{diag}}$ to the problems list and $f_{\\text{lab}}$ to the labs list, omitting any source code without a crosswalk entry. The predicted alignment set $P$ is the union of the pairs from both domains for the case.\n- For each case, compute $\\text{precision}$, $\\text{recall}$, and $F_1$ from the definitions above.\n- Final output format: your program should produce a single line of output containing the $F_1$ values for cases $1$ through $6$ in order, each rounded to $4$ decimal places, as a comma-separated list enclosed in square brackets, for example $[\\ldots]$.\n- There are no physical units or angles in this task.", "solution": "The problem is valid. It is a well-posed, scientifically grounded problem in the field of biomedical informatics, specifically concerning the evaluation of terminology mapping. All necessary data, including mapping functions (crosswalks) and gold standard sets for evaluation, are provided. The evaluation metrics—precision, recall, and $F_1$ score—are standard and clearly defined. The procedure is deterministic and computationally verifiable.\n\nThe task is to map source codes from an Electronic Health Record (EHR) to standard terminologies and evaluate the quality of this mapping. The source terminologies are ICD-10-CM for problems and local codes for labs. The target terminologies are SNOMED CT and LOINC, respectively.\n\nThe core of the methodology involves set-theoretic comparison between a set of predicted alignments, $P$, and a set of gold standard alignments, $G$. Both $P$ and $G$ are sets of pairs of the form $(\\text{source\\_code, target\\_code})$.\n\nThe predicted set $P$ for each case is generated by applying the provided crosswalk dictionaries, $f_{\\text{diag}}$ for problems and $f_{\\text{lab}}$ for labs, to the input EHR data.\n- $f_{\\text{diag}} = \\{ \\texttt{I10}: \\texttt{59621000}, \\texttt{E11.9}: \\texttt{44054006}, \\texttt{J45.909}: \\texttt{195967001}, \\texttt{R79.9}: \\texttt{165346000}, \\texttt{M54.5}: \\texttt{279039007} \\}$\n- $f_{\\text{lab}} = \\{ \\texttt{LIPID\\_PANEL}: \\texttt{24331-1}, \\texttt{GLU\\_FAST}: \\texttt{1557-8}, \\texttt{A1C}: \\texttt{4548-4}, \\texttt{CREA\\_SER}: \\texttt{2160-0} \\}$\n\nIf a source code from the EHR is not a key in the corresponding dictionary, no alignment is predicted for it.\n\nThe evaluation metrics are based on the counts of true positives ($TP$), false positives ($FP$), and false negatives ($FN$):\n$$ TP = |P \\cap G| $$\n$$ FP = |P \\setminus G| $$\n$$ FN = |G \\setminus P| $$\n\nFrom these counts, precision, recall, and the $F_1$ score are calculated as follows:\n$$ \\text{precision} = \\frac{TP}{|P|} = \\frac{TP}{TP + FP} \\quad (\\text{if } |P| > 0) $$\n$$ \\text{recall} = \\frac{TP}{|G|} = \\frac{TP}{TP + FN} \\quad (\\text{if } |G| > 0) $$\n$$ F_1 = \\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}} \\quad (\\text{if } \\text{precision} + \\text{recall} > 0) $$\nIf the denominator in any of these expressions is zero, the value of the metric is defined as $0$.\n\nThe analysis for each test case is as follows:\n\n**Case 1:**\n- EHR Inputs: Problems $[\\texttt{I10}, \\texttt{E11.9}, \\texttt{J45.909}, \\texttt{R79.9}]$, Labs $[\\texttt{LIPID\\_PANEL}, \\texttt{A1C}, \\texttt{CREA\\_SER}]$\n- Predicted set $P = \\{(\\texttt{I10}, \\texttt{59621000}), (\\texttt{E11.9}, \\texttt{44054006}), (\\texttt{J45.909}, \\texttt{195967001}), (\\texttt{R79.9}, \\texttt{165346000}), (\\texttt{LIPID\\_PANEL}, \\texttt{24331-1}), (\\texttt{A1C}, \\texttt{4548-4}), (\\texttt{CREA\\_SER}, \\texttt{2160-0})\\}$. So $|P|=7$.\n- Gold set $G = \\{(\\texttt{I10}, \\texttt{59621000}), (\\texttt{E11.9}, \\texttt{44054006}), (\\texttt{J45.909}, \\texttt{195967001}), (\\texttt{LIPID\\_PANEL}, \\texttt{24331-1}), (\\texttt{A1C}, \\texttt{4548-4}), (\\texttt{CREA\\_SER}, \\texttt{2160-0})\\}$. So $|G|=6$.\n- $TP = |P \\cap G| = 6$.\n- $FP = |P \\setminus G| = 1$, for the pair $(\\texttt{R79.9}, \\texttt{165346000})$.\n- $FN = |G \\setminus P| = 0$.\n- $\\text{precision} = 6/7$, $\\text{recall} = 6/6=1$.\n- $F_1 = (2 \\cdot (6/7) \\cdot 1) / (6/7 + 1) = (12/7) / (13/7) = 12/13 \\approx 0.9231$.\n\n**Case 2:**\n- EHR Inputs: Problems $[\\ ]$, Labs $[\\ ]$.\n- Predicted set $P = \\emptyset$, so $|P|=0$.\n- Gold set $G = \\emptyset$, so $|G|=0$.\n- $TP = 0, FP = 0, FN = 0$.\n- Since $|P|=0$, $\\text{precision}=0$. Since $|G|=0$, $\\text{recall}=0$.\n- $F_1 = 0$.\n\n**Case 3:**\n- EHR Inputs: Problems $[\\texttt{I10}, \\texttt{E11.65}, \\texttt{M54.5}]$, Labs $[\\texttt{GLU\\_FAST}, \\texttt{A1C}]$\n- Predicted set $P = \\{(\\texttt{I10}, \\texttt{59621000}), (\\texttt{M54.5}, \\texttt{279039007}), (\\texttt{GLU\\_FAST}, \\texttt{1557-8}), (\\texttt{A1C}, \\texttt{4548-4})\\}$. So $|P|=4$.\n- Gold set $G = \\{(\\texttt{I10}, \\texttt{59621000}), (\\texttt{E11.65}, \\texttt{237599002}), (\\texttt{M54.5}, \\texttt{279039007}), (\\texttt{GLU\\_FAST}, \\texttt{1558-6}), (\\texttt{A1C}, \\texttt{4548-4})\\}$. So $|G|=5$.\n- $TP = |P \\cap G| = 3$. The correct pairs are for $\\texttt{I10}$, $\\texttt{M54.5}$, and $\\texttt{A1C}$.\n- $FP = |P \\setminus G| = 1$, for the pair $(\\texttt{GLU\\_FAST}, \\texttt{1557-8})$.\n- $FN = |G \\setminus P| = 2$, for the pairs $(\\texttt{E11.65}, \\texttt{237599002})$ and $(\\texttt{GLU\\_FAST}, \\texttt{1558-6})$.\n- $\\text{precision} = 3/4 = 0.75$, $\\text{recall} = 3/5 = 0.6$.\n- $F_1 = (2 \\cdot 0.75 \\cdot 0.6) / (0.75 + 0.6) = 0.9 / 1.35 = 2/3 \\approx 0.6667$.\n\n**Case 4:**\n- EHR Inputs: Problems $[\\texttt{E11.65}]$, Labs $[\\ ]$.\n- Predicted set $P = \\emptyset$ (since $\\texttt{E11.65}$ is not in $f_{\\text{diag}}$). So $|P|=0$.\n- Gold set $G = \\{(\\texttt{E11.65}, \\texttt{237599002})\\}$. So $|G|=1$.\n- $TP = 0, FP = 0, FN = 1$.\n- $\\text{precision}=0$, $\\text{recall}=0/1=0$.\n- $F_1 = 0$.\n\n**Case 5:**\n- EHR Inputs: Problems $[\\texttt{R79.9}]$, Labs $[\\texttt{LIPID\\_PANEL}]$.\n- Predicted set $P = \\{(\\texttt{R79.9}, \\texttt{165346000}), (\\texttt{LIPID\\_PANEL}, \\texttt{24331-1})\\}$. So $|P|=2$.\n- Gold set $G = \\emptyset$. So $|G|=0$.\n- $TP = 0, FP = 2, FN = 0$.\n- $\\text{precision}=0/2=0$, $\\text{recall}=0$.\n- $F_1 = 0$.\n\n**Case 6:**\n- EHR Inputs: Problems $[\\texttt{I10}, \\texttt{E11.9}]$, Labs $[\\texttt{A1C}]$.\n- Predicted set $P = \\{(\\texttt{I10}, \\texttt{59621000}), (\\texttt{E11.9}, \\texttt{44054006}), (\\texttt{A1C}, \\texttt{4548-4})\\}$. So $|P|=3$.\n- Gold set $G = \\{(\\texttt{I10}, \\texttt{59621000}), (\\texttt{E11.9}, \\texttt{44054006}), (\\texttt{A1C}, \\texttt{4548-4})\\}$. So $|G|=3$.\n- $P$ and $G$ are identical.\n- $TP = 3, FP = 0, FN = 0$.\n- $\\text{precision} = 3/3=1$, $\\text{recall} = 3/3=1$.\n- $F_1 = (2 \\cdot 1 \\cdot 1) / (1+1) = 1.0$.\n\nSummary of $F_1$ scores:\n- Case 1: $0.9231$\n- Case 2: $0.0000$\n- Case 3: $0.6667$\n- Case 4: $0.0000$\n- Case 5: $0.0000$\n- Case 6: $1.0000$", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the clinical terminology mapping evaluation problem for all test cases.\n    \"\"\"\n\n    # Global crosswalk dictionaries as defined in the problem\n    f_diag = {\n        'I10': '59621000',\n        'E11.9': '44054006',\n        'J45.909': '195967001',\n        'R79.9': '165346000',\n        'M54.5': '279039007',\n    }\n    f_lab = {\n        'LIPID_PANEL': '24331-1',\n        'GLU_FAST': '1557-8',\n        'A1C': '4548-4',\n        'CREA_SER': '2160-0',\n    }\n\n    # Test suite data\n    test_cases = [\n        {\n            \"ehr_problems\": ['I10', 'E11.9', 'J45.909', 'R79.9'],\n            \"ehr_labs\": ['LIPID_PANEL', 'A1C', 'CREA_SER'],\n            \"gold_alignments\": {\n                ('I10', '59621000'), ('E11.9', '44054006'), ('J45.909', '195967001'),\n                ('LIPID_PANEL', '24331-1'), ('A1C', '4548-4'), ('CREA_SER', '2160-0')\n            }\n        },\n        {\n            \"ehr_problems\": [],\n            \"ehr_labs\": [],\n            \"gold_alignments\": set()\n        },\n        {\n            \"ehr_problems\": ['I10', 'E11.65', 'M54.5'],\n            \"ehr_labs\": ['GLU_FAST', 'A1C'],\n            \"gold_alignments\": {\n                ('I10', '59621000'), ('E11.65', '237599002'), ('M54.5', '279039007'),\n                ('GLU_FAST', '1558-6'), ('A1C', '4548-4')\n            }\n        },\n        {\n            \"ehr_problems\": ['E11.65'],\n            \"ehr_labs\": [],\n            \"gold_alignments\": {('E11.65', '237599002')}\n        },\n        {\n            \"ehr_problems\": ['R79.9'],\n            \"ehr_labs\": ['LIPID_PANEL'],\n            \"gold_alignments\": set()\n        },\n        {\n            \"ehr_problems\": ['I10', 'E11.9'],\n            \"ehr_labs\": ['A1C'],\n            \"gold_alignments\": {\n                ('I10', '59621000'), ('E11.9', '44054006'), ('A1C', '4548-4')\n            }\n        }\n    ]\n\n    f1_results = []\n\n    for case in test_cases:\n        # Step 1: Generate the predicted alignment set, P\n        predicted_alignments = set()\n        for prob_code in case[\"ehr_problems\"]:\n            if prob_code in f_diag:\n                predicted_alignments.add((prob_code, f_diag[prob_code]))\n        for lab_code in case[\"ehr_labs\"]:\n            if lab_code in f_lab:\n                predicted_alignments.add((lab_code, f_lab[lab_code]))\n\n        # Step 2: Get the gold standard alignment set, G\n        gold_alignments = case[\"gold_alignments\"]\n\n        # Step 3: Calculate TP, FP, FN using set operations\n        tp = len(predicted_alignments.intersection(gold_alignments))\n        fp = len(predicted_alignments.difference(gold_alignments))\n        fn = len(gold_alignments.difference(predicted_alignments))\n\n        # Step 4: Calculate precision, recall, and F1 score\n        # Precision = TP / |P| = TP / (TP + FP)\n        if (tp + fp) > 0:\n            precision = tp / (tp + fp)\n        else:\n            precision = 0.0\n\n        # Recall = TP / |G| = TP / (TP + FN)\n        if (tp + fn) > 0:\n            recall = tp / (tp + fn)\n        else:\n            recall = 0.0\n\n        # F1 = 2 * (precision * recall) / (precision + recall)\n        if (precision + recall) > 0:\n            f1_score = 2 * (precision * recall) / (precision + recall)\n        else:\n            f1_score = 0.0\n            \n        f1_results.append(f1_score)\n\n    # Format the final output as specified\n    formatted_results = [f\"{score:.4f}\" for score in f1_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```", "id": "4857505"}, {"introduction": "Once data is standardized, we can begin to identify patient groups with specific diseases or characteristics, a process known as computable phenotyping. This practice challenges you to build a phenotype algorithm for Type 2 Diabetes Mellitus by combining diagnosis codes, lab results, and medication data from electronic health records. You will formalize clinical knowledge into a set of logical rules and then evaluate your algorithm's performance against a physician-reviewed gold standard, using essential metrics like sensitivity, specificity, and predictive values [@problem_id:4857553].", "problem": "You are working within Clinical Informatics (a subfield of Biomedical Informatics) to design a computable phenotype for Type $2$ Diabetes Mellitus (T2DM) using structured Electronic Health Record (EHR) data. Using well-established diagnostic criteria and the logic of binary classification, you must formalize an algorithm that classifies patients into predicted T2DM case status from diagnosis codes, laboratory measurements, and medications, and then compute performance metrics against a chart-reviewed gold standard.\n\nFundamental base to use:\n- Widely accepted diagnostic thresholds for diabetes from the American Diabetes Association (ADA), stated here as well-tested facts:\n  - Hemoglobin A1c (HbA1c) criterion: HbA1c fraction $\\geq 0.065$ (fractional form, not a percentage).\n  - Fasting plasma glucose (FPG) criterion: FPG $\\geq 126$ mg/dL.\n  - Random plasma glucose (RPG) criterion: RPG $\\geq 200$ mg/dL.\n- Core binary classification definitions grounded in the confusion matrix:\n  - True Positive ($TP$), False Positive ($FP$), True Negative ($TN$), False Negative ($FN$).\n  - Positive Predictive Value (PPV), Negative Predictive Value (NPV), sensitivity, specificity.\n\nTask:\n1. Define a computable phenotype function that maps each patient's structured record to a predicted case label $\\hat{Y} \\in \\{0,1\\}$ using only the following rule set, which integrates diagnosis codes, laboratories, and medications in a scientifically realistic manner:\n   - Let $C$ denote the count of International Classification of Diseases (ICD) diagnosis codes indicative of T2DM.\n   - Let $A$ denote the HbA1c fraction (unitless, expressed as a fraction such as $0.072$), $F$ denote fasting plasma glucose in mg/dL, $R$ denote random plasma glucose in mg/dL.\n   - Let $M$ denote a boolean indicator for the presence of medications predominantly used to treat T2DM.\n   - Define the laboratory-positive indicator\n     $$L := (A \\geq 0.065) \\lor (F \\geq 126) \\lor (R \\geq 200).$$\n   - The predicted case label is\n     $$\\hat{Y} := \\begin{cases}\n     1 & \\text{if } (C \\geq 2) \\lor L \\lor (M \\land (C \\geq 1)) \\\\\n     0 & \\text{otherwise.}\n     \\end{cases}$$\n   This rule set reflects clinical informatics practice: diagnosis codes, canonical lab thresholds, and medications are combined to balance sensitivity and specificity.\n\n2. Using the above $\\hat{Y}$, compute $TP$, $FP$, $TN$, and $FN$ against the provided chart-reviewed gold standard labels $Y \\in \\{0,1\\}$, then compute:\n   - $$\\mathrm{PPV} = \\frac{TP}{TP + FP},\\quad \\mathrm{NPV} = \\frac{TN}{TN + FN},$$\n   - $$\\text{sensitivity} = \\frac{TP}{TP + FN},\\quad \\text{specificity} = \\frac{TN}{TN + FP}.$$\n   Express each metric as a decimal number. No percentage signs are permitted.\n\nTest suite (each record is a tuple $(C, A, F, R, M, Y)$):\n- Record $1$: $(3, 0.072, 160, 210, \\text{True}, 1)$\n- Record $2$: $(0, 0.050, 95, 100, \\text{False}, 0)$\n- Record $3$: $(0, 0.065, 110, 170, \\text{False}, 1)$\n- Record $4$: $(0, 0.060, 100, 150, \\text{True}, 0)$\n- Record $5$: $(1, 0.058, 100, 130, \\text{False}, 1)$\n- Record $6$: $(0, 0.062, 110, 200, \\text{False}, 1)$\n- Record $7$: $(0, 0.064, 125, 180, \\text{False}, 0)$\n- Record $8$: $(0, 0.060, 130, 160, \\text{False}, 1)$\n- Record $9$: $(1, 0.055, 95, 100, \\text{True}, 0)$\n- Record $10$: $(2, 0.055, 100, 120, \\text{False}, 1)$\n\nCoverage rationale:\n- Boundary cases at exact thresholds: $A = 0.065$ (Record $3$), $R = 200$ (Record $6$), $F = 130 \\geq 126$ (Record $8$).\n- Medication-only scenario (Record $4$).\n- Single-code scenario without labs or meds (Record $5$).\n- Multi-code scenario with normal labs (Record $10$).\n- Clear negatives (Records $2$ and $7$).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $[\\mathrm{PPV}, \\mathrm{NPV}, \\text{sensitivity}, \\text{specificity}]$, each rounded to three decimal places. For example, an output line could look like $[0.833,0.750,0.833,0.750]$.\n- No units are required in the output because the performance metrics are dimensionless.", "solution": "The problem is valid. It is a well-posed, scientifically grounded, and objective task in the field of clinical informatics. The problem provides a clear, deterministic algorithm for a computable phenotype, a complete set of test data, and standard definitions for the performance metrics to be calculated. The inputs are consistent, and the required output is unambiguously defined.\n\nThe objective is to operationalize a computable phenotype for Type $2$ Diabetes Mellitus (T2DM) and evaluate its performance against a gold standard. This is a binary classification problem where each patient is classified as either a case ($\\hat{Y}=1$) or a non-case ($\\hat{Y}=0$).\n\nThe classification rule is based on structured Electronic Health Record (EHR) data:\n- $C$: The count of T$2$DM-specific International Classification of Diseases (ICD) codes.\n- $A$: The Hemoglobin A1c (HbA1c) value, expressed as a fraction.\n- $F$: The fasting plasma glucose level in mg/dL.\n- $R$: The random plasma glucose level in mg/dL.\n- $M$: A boolean indicator for the prescription of T$2$DM-specific medications.\n\nFirst, we define a laboratory-positive indicator, $L$, based on the American Diabetes Association (ADA) diagnostic thresholds. A patient is considered positive by laboratory criteria if any of the following conditions are met:\n$$L := (A \\geq 0.065) \\lor (F \\geq 126) \\lor (R \\geq 200)$$\nThe logical operator $\\lor$ represents \"OR\".\n\nThe final predicted case status, $\\hat{Y}$, is determined by a composite rule integrating diagnosis codes, laboratory results, and medications:\n$$\\hat{Y} := \\begin{cases}\n1 & \\text{if } (C \\geq 2) \\lor L \\lor (M \\land (C \\geq 1)) \\\\\n0 & \\text{otherwise.}\n\\end{cases}$$\nHere, the logical operator $\\land$ represents \"AND\". This rule classifies a patient as a T$2$DM case if they have: at least two relevant diagnosis codes, or at least one positive laboratory value, or at least one relevant diagnosis code and are on T$2$DM medication.\n\nWe apply this rule to each of the $10$ patient records. For each record, we compare the predicted label $\\hat{Y}$ to the gold standard chart-reviewed label $Y$ to determine the classification outcome:\n- True Positive ($TP$): $\\hat{Y}=1$ and $Y=1$.\n- False Positive ($FP$): $\\hat{Y}=1$ and $Y=0$.\n- True Negative ($TN$): $\\hat{Y}=0$ and $Y=0$.\n- False Negative ($FN$): $\\hat{Y}=0$ and $Y=1$.\n\nThe following table details the classification for each record:\n- **Record 1**: $(3, 0.072, 160, 210, \\text{True}, 1)$. Condition $(C \\geq 2)$ is true since $C=3$. Thus, $\\hat{Y}=1$. With $Y=1$, this is a $TP$.\n- **Record 2**: $(0, 0.050, 95, 100, \\text{False}, 0)$. Condition $L$ is false ($A < 0.065, F < 126, R < 200$). All other conditions are false. Thus, $\\hat{Y}=0$. With $Y=0$, this is a $TN$.\n- **Record 3**: $(0, 0.065, 110, 170, \\text{False}, 1)$. Condition $L$ is true since $A=0.065$. Thus, $\\hat{Y}=1$. With $Y=1$, this is a $TP$.\n- **Record 4**: $(0, 0.060, 100, 150, \\text{True}, 0)$. Condition $L$ is false. The condition $(M \\land (C \\geq 1))$ is false since $C=0$. Thus, $\\hat{Y}=0$. With $Y=0$, this is a $TN$.\n- **Record 5**: $(1, 0.058, 100, 130, \\text{False}, 1)$. Condition $L$ is false. The condition $(M \\land (C \\geq 1))$ is false since $M$ is False. The condition $(C \\geq 2)$ is false. Thus, $\\hat{Y}=0$. With $Y=1$, this is an $FN$.\n- **Record 6**: $(0, 0.062, 110, 200, \\text{False}, 1)$. Condition $L$ is true since $R=200$. Thus, $\\hat{Y}=1$. With $Y=1$, this is a $TP$.\n- **Record 7**: $(0, 0.064, 125, 180, \\text{False}, 0)$. Condition $L$ is false ($A < 0.065, F < 126, R < 200$). All other conditions are false. Thus, $\\hat{Y}=0$. With $Y=0$, this is a $TN$.\n- **Record 8**: $(0, 0.060, 130, 160, \\text{False}, 1)$. Condition $L$ is true since $F=130 \\geq 126$. Thus, $\\hat{Y}=1$. With $Y=1$, this is a $TP$.\n- **Record 9**: $(1, 0.055, 95, 100, \\text{True}, 0)$. Condition $L$ is false. The condition $(M \\land (C \\geq 1))$ is true since $M$ is True and $C=1$. Thus, $\\hat{Y}=1$. With $Y=0$, this is an $FP$.\n- **Record 10**: $(2, 0.055, 100, 120, \\text{False}, 1)$. Condition $(C \\geq 2)$ is true since $C=2$. Thus, $\\hat{Y}=1$. With $Y=1$, this is a $TP$.\n\nSumming these outcomes yields the confusion matrix counts:\n- $TP = 5$\n- $FP = 1$\n- $TN = 3$\n- $FN = 1$\n\nFinally, we compute the standard performance metrics.\n1. Positive Predictive Value (PPV), or precision:\n   $$\\mathrm{PPV} = \\frac{TP}{TP + FP} = \\frac{5}{5 + 1} = \\frac{5}{6} \\approx 0.833$$\n\n2. Negative Predictive Value (NPV):\n   $$\\mathrm{NPV} = \\frac{TN}{TN + FN} = \\frac{3}{3 + 1} = \\frac{3}{4} = 0.750$$\n\n3. Sensitivity, or recall:\n   $$\\text{sensitivity} = \\frac{TP}{TP + FN} = \\frac{5}{5 + 1} = \\frac{5}{6} \\approx 0.833$$\n\n4. Specificity:\n   $$\\text{specificity} = \\frac{TN}{TN + FP} = \\frac{3}{3 + 1} = \\frac{3}{4} = 0.750$$\n\nThese four metrics, rounded to three decimal places, provide a quantitative evaluation of the computable phenotype's performance on the given dataset.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are necessary for this problem.\n\ndef classify_patient(C, A, F, R, M):\n    \"\"\"\n    Applies the computable phenotype rule to classify a patient.\n\n    Args:\n        C (int): Count of T2DM ICD codes.\n        A (float): HbA1c fraction.\n        F (float): Fasting plasma glucose in mg/dL.\n        R (float): Random plasma glucose in mg/dL.\n        M (bool): Indicator for T2DM medications.\n\n    Returns:\n        int: Predicted case label (1 for case, 0 for non-case).\n    \"\"\"\n    lab_positive = (A >= 0.065) or (F >= 126) or (R >= 200)\n    \n    # The rule for predicting the case label Y_hat\n    # Y_hat = 1 if (C >= 2) or L or (M and (C >= 1))\n    if (C >= 2) or lab_positive or (M and (C >= 1)):\n        return 1\n    else:\n        return 0\n\ndef solve():\n    \"\"\"\n    Solves the problem by classifying patients and calculating performance metrics.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each record is a tuple (C, A, F, R, M, Y)\n    test_cases = [\n        (3, 0.072, 160, 210, True, 1),\n        (0, 0.050, 95, 100, False, 0),\n        (0, 0.065, 110, 170, False, 1),\n        (0, 0.060, 100, 150, True, 0),\n        (1, 0.058, 100, 130, False, 1),\n        (0, 0.062, 110, 200, False, 1),\n        (0, 0.064, 125, 180, False, 0),\n        (0, 0.060, 130, 160, False, 1),\n        (1, 0.055, 95, 100, True, 0),\n        (2, 0.055, 100, 120, False, 1),\n    ]\n\n    # Initialize confusion matrix counters\n    tp, fp, tn, fn = 0, 0, 0, 0\n\n    for case in test_cases:\n        C, A, F, R, M, Y_true = case\n        Y_pred = classify_patient(C, A, F, R, M)\n\n        if Y_pred == 1 and Y_true == 1:\n            tp += 1\n        elif Y_pred == 1 and Y_true == 0:\n            fp += 1\n        elif Y_pred == 0 and Y_true == 0:\n            tn += 1\n        elif Y_pred == 0 and Y_true == 1:\n            fn += 1\n            \n    # Calculate performance metrics\n    # Handle division by zero for robustness, though not strictly required by this problem's data\n    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0.0\n    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n\n    # Format results to three decimal places\n    results = [round(ppv, 3), round(npv, 3), round(sensitivity, 3), round(specificity, 3)]\n    \n    # Final print statement in the exact required format.\n    # The format requirement of \"0.750\" means we need to format the float.\n    formatted_results = [f\"{res:.3f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "4857553"}, {"introduction": "A key goal of clinical informatics is to deliver timely, relevant knowledge to clinicians at the point of care. This exercise simulates the logic behind a modern Clinical Decision Support (CDS) service that warns prescribers about potentially harmful drug-drug interactions. You will not only implement the alerting mechanism but also analyze its real-world effectiveness by calculating alert precision, override rates, and applying decision curve analysis to determine if the benefits of the alerts outweigh the costs of potential over-alerting [@problem_id:4857560].", "problem": "You are asked to implement, in code, a simplified Clinical Decision Support (CDS) Hooks service logic for drug–drug interaction (DDI) checks, and then compute evaluation metrics and decision-analytic quantities. This exercise operates within the subfields of Clinical Decision Support and Pharmacy Informatics in Biomedical Informatics. The problem is defined purely in mathematical and logical terms, abstracting away any network or external service aspects, and requires programmatic computation of the metrics from given inputs.\n\nYou will implement a function that emulates the CDS Hooks behavior in the following way: given a current set of medications and a set of newly ordered medications, along with a knowledge base mapping medication pairs to an interaction risk probability (a value in the interval $[0,1]$), the service produces an alert for any pair whose interaction risk probability is greater than or equal to a service threshold $p_s$. You will then compute evaluation metrics, and quantify net benefit via decision curve analysis.\n\nFundamental bases and definitions to be used in your reasoning and implementation include:\n- The definition of a classification decision rule based on a threshold on a risk score in $[0,1]$.\n- The definitions of true positives, false positives, and derived rates from counts over a finite population of instances.\n- The concept of decision curve analysis (DCA) using threshold probability to weigh the relative value of true positives versus false positives in net benefit.\n\nImplement the following steps in code:\n1. Create an alert-generation function that, for each ordered medication, checks all existing medications and creates an alert for each pair whose risk probability is greater than or equal to $p_s$. Only the cross-product pairs that appear in the knowledge base mapping are considered; pairs absent from the knowledge base are treated as having no alertable interaction at any threshold.\n2. Compute alert precision using the standard definition based on counts of true positives and false positives among the fired alerts. If there are zero fired alerts, define precision to be $0$.\n3. Compute the override rate, defined as the number of fired alerts that are overridden divided by the total number of fired alerts. If there are zero fired alerts, define the override rate to be $0$. All rates must be expressed as decimals (for example, $0.25$) and not as percentages.\n4. Perform decision curve analysis for a supplied set of threshold probabilities. For each threshold probability $p_t$, treat any instance whose risk probability is greater than or equal to $p_t$ as a positive decision, then compute the net benefit. Explicitly use the threshold probability $p_t$ to weigh the harm of false positives relative to true positives. The total population size $N$ is the total number of candidate pairs examined (the full cross-product of current medications and ordered medications that are present in the knowledge base). In this exercise, you will compute the net benefit for the service decision rule at each supplied threshold probability and return the values.\n5. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The required format is a list of lists, one inner list per test case. Each inner list must contain, in order, the alert precision, the override rate, and the net benefit values for the supplied thresholds, all as decimal floats. For example, your output should look like $[[\\dots],[\\dots],[\\dots]]$ with each inner list having values ordered as $[\\text{precision},\\text{override\\_rate},\\text{NB}_{p_{t1}},\\text{NB}_{p_{t2}},\\text{NB}_{p_{t3}}]$.\n\nUse the following test suite. Each test case specifies:\n- A set of existing medications.\n- A set of newly ordered medications.\n- A knowledge base mapping for risk probabilities for the cross-product pairs that are considered.\n- Ground truth labels indicating whether each pair is truly a clinically significant interaction ($1$) or not ($0$).\n- A mapping of override decisions for fired alerts ($\\text{True}$ indicates overridden, $\\text{False}$ indicates not overridden).\n- A fixed CDS service threshold $p_s$ for alert generation.\n- A list of threshold probabilities for decision curve analysis.\n\nTest case $1$ (general case):\n- Existing medications: $\\{\\text{warfarin},\\ \\text{simvastatin}\\}$.\n- New orders: $\\{\\text{trimethoprim},\\ \\text{clarithromycin}\\}$.\n- Knowledge base risk probabilities $r_{ij}$:\n  - $(\\text{warfarin},\\ \\text{trimethoprim}) \\mapsto 0.72$\n  - $(\\text{warfarin},\\ \\text{clarithromycin}) \\mapsto 0.40$\n  - $(\\text{simvastatin},\\ \\text{clarithromycin}) \\mapsto 0.85$\n  - $(\\text{simvastatin},\\ \\text{trimethoprim}) \\mapsto 0.12$\n- Ground truth labels $y_{ij}$:\n  - $(\\text{warfarin},\\ \\text{trimethoprim}) \\mapsto 1$\n  - $(\\text{warfarin},\\ \\text{clarithromycin}) \\mapsto 0$\n  - $(\\text{simvastatin},\\ \\text{clarithromycin}) \\mapsto 1$\n  - $(\\text{simvastatin},\\ \\text{trimethoprim}) \\mapsto 0$\n- Override decisions $o_{ij}$ for fired alerts:\n  - $(\\text{warfarin},\\ \\text{trimethoprim}) \\mapsto \\text{False}$\n  - $(\\text{warfarin},\\ \\text{clarithromycin}) \\mapsto \\text{True}$\n  - $(\\text{simvastatin},\\ \\text{clarithromycin}) \\mapsto \\text{True}$\n  - $(\\text{simvastatin},\\ \\text{trimethoprim}) \\mapsto \\text{False}$\n- CDS service threshold: $p_s = 0.50$.\n- DCA thresholds: $[0.20,\\ 0.50,\\ 0.80]$.\n\nTest case $2$ (boundary with zero alerts):\n- Existing medications: $\\{\\text{metformin}\\}$.\n- New orders: $\\{\\text{amoxicillin}\\}$.\n- Knowledge base risk probabilities $r_{ij}$:\n  - $(\\text{metformin},\\ \\text{amoxicillin}) \\mapsto 0.10$\n- Ground truth labels $y_{ij}$:\n  - $(\\text{metformin},\\ \\text{amoxicillin}) \\mapsto 0$\n- Override decisions $o_{ij}$:\n  - $(\\text{metformin},\\ \\text{amoxicillin}) \\mapsto \\text{True}$\n- CDS service threshold: $p_s = 0.50$.\n- DCA thresholds: $[0.20,\\ 0.50,\\ 0.80]$.\n\nTest case $3$ (edge with equality to threshold and extreme probabilities):\n- Existing medications: $\\{\\text{lisinopril},\\ \\text{spironolactone}\\}$.\n- New orders: $\\{\\text{potassium\\_chloride},\\ \\text{ibuprofen}\\}$.\n- Knowledge base risk probabilities $r_{ij}$:\n  - $(\\text{lisinopril},\\ \\text{potassium\\_chloride}) \\mapsto 0.50$\n  - $(\\text{lisinopril},\\ \\text{ibuprofen}) \\mapsto 0.30$\n   - $(\\text{spironolactone},\\ \\text{potassium\\_chloride}) \\mapsto 0.95$\n  - $(\\text{spironolactone},\\ \\text{ibuprofen}) \\mapsto 0.20$\n- Ground truth labels $y_{ij}$:\n  - $(\\text{lisinopril},\\ \\text{potassium\\_chloride}) \\mapsto 1$\n  - $(\\text{lisinopril},\\ \\text{ibuprofen}) \\mapsto 0$\n  - $(\\text{spironolactone},\\ \\text{potassium\\_chloride}) \\mapsto 1$\n  - $(\\text{spironolactone},\\ \\text{ibuprofen}) \\mapsto 0$\n- Override decisions $o_{ij}$:\n  - $(\\text{lisinopril},\\ \\text{potassium\\_chloride}) \\mapsto \\text{False}$\n  - $(\\text{lisinopril},\\ \\text{ibuprofen}) \\mapsto \\text{True}$\n  - $(\\text{spironolactone},\\ \\text{potassium\\_chloride}) \\mapsto \\text{False}$\n  - $(\\text{spironolactone},\\ \\text{ibuprofen}) \\mapsto \\text{True}$\n- CDS service threshold: $p_s = 0.50$.\n- DCA thresholds: $[0.20,\\ 0.50,\\ 0.80]$.\n\nAdditional requirements:\n- Comparison against thresholds must use the relation “greater than or equal to” (i.e., $r_{ij} \\ge p$).\n- If the denominator in a rate is $0$, define the rate to be $0$.\n- All rates must be decimals (e.g., $0.25$) and not percentages.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the top-level list contains one inner list per test case. Each inner list must be ordered as $[\\text{precision},\\ \\text{override\\_rate},\\ \\text{NB}_{0.20},\\ \\text{NB}_{0.50},\\ \\text{NB}_{0.80}]$.", "solution": "The problem is valid and requires the implementation and evaluation of a simplified Clinical Decision Support (CDS) logic for drug-drug interactions. The evaluation involves computing standard classification metrics and performing a decision curve analysis. The process is entirely deterministic and based on provided data sets and formal definitions.\n\nFirst, we formalize the components of the problem. Let $P$ be the set of all medication pairs $(i, j)$ for which a risk is defined in the knowledge base. The size of this population is $N = |P|$. For each pair $(i, j) \\in P$, we are provided with a risk probability $r_{ij} \\in [0, 1]$, a ground truth label $y_{ij} \\in \\{0, 1\\}$, and an override decision $o_{ij} \\in \\{\\text{True}, \\text{False}\\}$.\n\nThe CDS service operates based on a fixed service threshold, $p_s$. An alert is generated for a pair $(i, j)$ if its risk probability meets or exceeds this threshold. Let $A$ be the set of pairs for which an alert is fired:\n$$A = \\{ (i, j) \\in P \\mid r_{ij} \\ge p_s \\}$$\nThe total number of fired alerts is $|A|$. The required metrics are defined as follows:\n\n1.  **Alert Precision**: The proportion of fired alerts that correspond to true interactions.\n    Let $TP_{alert} = |\\{ (i, j) \\in A \\mid y_{ij} = 1 \\}|$.\n    $$ \\text{Precision} = \\begin{cases} \\frac{TP_{alert}}{|A|} & \\text{if } |A| > 0 \\\\ 0 & \\text{if } |A| = 0 \\end{cases} $$\n\n2.  **Override Rate**: The proportion of fired alerts that were overridden.\n    Let $O_{alert} = |\\{ (i, j) \\in A \\mid o_{ij} = \\text{True} \\}|$.\n    $$ \\text{Override Rate} = \\begin{cases} \\frac{O_{alert}}{|A|} & \\text{if } |A| > 0 \\\\ 0 & \\text{if } |A| = 0 \\end{cases} $$\n\n3.  **Decision Curve Analysis (DCA)**: For a given decision threshold $p_t$, we classify a pair as positive if $r_{ij} \\ge p_t$.\n    -   $TP(p_t) = |\\{ (i, j) \\in P \\mid r_{ij} \\ge p_t \\text{ and } y_{ij} = 1 \\}|$\n    -   $FP(p_t) = |\\{ (i, j) \\in P \\mid r_{ij} \\ge p_t \\text{ and } y_{ij} = 0 \\}|$\n    The net benefit, $\\text{NB}(p_t)$, is:\n    $$ \\text{NB}(p_t) = \\frac{TP(p_t)}{N} - \\frac{FP(p_t)}{N} \\times \\frac{p_t}{1-p_t} $$\n\nThe analysis for each test case is as follows:\n\n**Case 1 Analysis:**\n- Population $P$: 4 pairs, $N=4$.\n- $p_s = 0.50$. Fired alerts $A = \\{(\\text{warfarin}, \\text{trimethoprim}), (\\text{simvastatin}, \\text{clarithromycin})\\}$ since their risks ($0.72, 0.85$) are $\\ge 0.50$. So, $|A|=2$.\n- $TP_{alert}$: Both pairs in $A$ have ground truth $y=1$. Thus, $TP_{alert}=2$.\n- **Precision** = $2/2 = 1.0$.\n- Overrides: $(\\text{simvastatin}, \\text{clarithromycin})$ is overridden. So, $O_{alert}=1$.\n- **Override Rate** = $1/2 = 0.5$.\n- DCA:\n  - $p_t=0.20$: Pairs with risk $\\ge 0.20$ are $\\{(\\text{w},\\text{t}), (\\text{w},\\text{c}), (\\text{s},\\text{c})\\}$. $TP(0.20)=2$, $FP(0.20)=1$.\n    $\\text{NB}(0.20) = (2/4) - (1/4) \\times (0.2/0.8) = 0.5 - 0.25 \\times 0.25 = 0.4375$.\n  - $p_t=0.50$: Pairs with risk $\\ge 0.50$ are $\\{(\\text{w},\\text{t}), (\\text{s},\\text{c})\\}$. $TP(0.50)=2, FP(0.50)=0$.\n    $\\text{NB}(0.50) = (2/4) - 0 = 0.5$.\n  - $p_t=0.80$: Pair with risk $\\ge 0.80$ is $\\{(\\text{s},\\text{c})\\}$. $TP(0.80)=1, FP(0.80)=0$.\n    $\\text{NB}(0.80) = (1/4) - 0 = 0.25$.\n- Results: $[1.0, 0.5, 0.4375, 0.5, 0.25]$.\n\n**Case 2 Analysis:**\n- Population $P$: 1 pair, $N=1$.\n- $p_s = 0.50$. The pair's risk is $0.10  0.50$. No alerts are fired. $|A|=0$.\n- **Precision** = $0.0$.\n- **Override Rate** = $0.0$.\n- DCA: For all thresholds $p_t \\in [0.20, 0.50, 0.80]$, no pair has risk $\\ge p_t$. Thus $TP=0, FP=0$ for all.\n  $\\text{NB}(0.20)=0, \\text{NB}(0.50)=0, \\text{NB}(0.80)=0$.\n- Results: $[0.0, 0.0, 0.0, 0.0, 0.0]$.\n\n**Case 3 Analysis:**\n- Population $P$: 4 pairs, $N=4$.\n- $p_s = 0.50$. Fired alerts $A = \\{(\\text{lisinopril}, \\text{potassium\\_chloride}), (\\text{spironolactone}, \\text{potassium\\_chloride})\\}$ since their risks ($0.50, 0.95$) are $\\ge 0.50$. So, $|A|=2$.\n- $TP_{alert}$: Both pairs in $A$ have ground truth $y=1$. Thus, $TP_{alert}=2$.\n- **Precision** = $2/2 = 1.0$.\n- Overrides: Neither pair in $A$ is overridden. Thus, $O_{alert}=0$.\n- **Override Rate** = $0/2 = 0.0$.\n- DCA:\n  - $p_t=0.20$: All 4 pairs have risk $\\ge 0.20$. $TP(0.20)=2$, $FP(0.20)=2$.\n    $\\text{NB}(0.20) = (2/4) - (2/4) \\times (0.2/0.8) = 0.5 - 0.5 \\times 0.25 = 0.375$.\n  - $p_t=0.50$: Pairs with risk $\\ge 0.50$ are $\\{(\\text{l},\\text{kcl}), (\\text{s},\\text{kcl})\\}$. $TP(0.50)=2, FP(0.50)=0$.\n    $\\text{NB}(0.50) = (2/4) - 0 = 0.5$.\n  - $p_t=0.80$: Pair with risk $\\ge 0.80$ is $\\{(\\text{s},\\text{kcl})\\}$. $TP(0.80)=1, FP(0.80)=0$.\n    $\\text{NB}(0.80) = (1/4) - 0 = 0.25$.\n- Results: $[1.0, 0.0, 0.375, 0.5, 0.25]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and compute the required metrics.\n    \"\"\"\n    \n    test_cases = [\n        # Test case 1 (general case)\n        {\n            \"existing_meds\": {\"warfarin\", \"simvastatin\"},\n            \"new_orders\": {\"trimethoprim\", \"clarithromycin\"},\n            \"kb_risks\": {\n                (\"warfarin\", \"trimethoprim\"): 0.72,\n                (\"warfarin\", \"clarithromycin\"): 0.40,\n                (\"simvastatin\", \"clarithromycin\"): 0.85,\n                (\"simvastatin\", \"trimethoprim\"): 0.12,\n            },\n            \"ground_truth\": {\n                (\"warfarin\", \"trimethoprim\"): 1,\n                (\"warfarin\", \"clarithromycin\"): 0,\n                (\"simvastatin\", \"clarithromycin\"): 1,\n                (\"simvastatin\", \"trimethoprim\"): 0,\n            },\n            \"overrides\": {\n                (\"warfarin\", \"trimethoprim\"): False,\n                (\"warfarin\", \"clarithromycin\"): True,\n                (\"simvastatin\", \"clarithromycin\"): True,\n                (\"simvastatin\", \"trimethoprim\"): False,\n            },\n            \"p_s\": 0.50,\n            \"dca_thresholds\": [0.20, 0.50, 0.80],\n        },\n        # Test case 2 (boundary with zero alerts)\n        {\n            \"existing_meds\": {\"metformin\"},\n            \"new_orders\": {\"amoxicillin\"},\n            \"kb_risks\": {\n                (\"metformin\", \"amoxicillin\"): 0.10,\n            },\n            \"ground_truth\": {\n                (\"metformin\", \"amoxicillin\"): 0,\n            },\n            \"overrides\": {\n                (\"metformin\", \"amoxicillin\"): True,\n            },\n            \"p_s\": 0.50,\n            \"dca_thresholds\": [0.20, 0.50, 0.80],\n        },\n        # Test case 3 (edge with equality to threshold)\n        {\n            \"existing_meds\": {\"lisinopril\", \"spironolactone\"},\n            \"new_orders\": {\"potassium_chloride\", \"ibuprofen\"},\n            \"kb_risks\": {\n                (\"lisinopril\", \"potassium_chloride\"): 0.50,\n                (\"lisinopril\", \"ibuprofen\"): 0.30,\n                (\"spironolactone\", \"potassium_chloride\"): 0.95,\n                (\"spironolactone\", \"ibuprofen\"): 0.20,\n            },\n            \"ground_truth\": {\n                (\"lisinopril\", \"potassium_chloride\"): 1,\n                (\"lisinopril\", \"ibuprofen\"): 0,\n                (\"spironolactone\", \"potassium_chloride\"): 1,\n                (\"spironolactone\", \"ibuprofen\"): 0,\n            },\n            \"overrides\": {\n                (\"lisinopril\", \"potassium_chloride\"): False,\n                (\"lisinopril\", \"ibuprofen\"): True,\n                (\"spironolactone\", \"potassium_chloride\"): False,\n                (\"spironolactone\", \"ibuprofen\"): True,\n            },\n            \"p_s\": 0.50,\n            \"dca_thresholds\": [0.20, 0.50, 0.80],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(process_case(case))\n\n    # Format the final output as a string representing a list of lists.\n    # e.g., [[1.0,0.5,0.4375,0.5,0.25],[0.0,0.0,0.0,0.0,0.0],...]\n    output_str = \"[\" + \",\".join([\"[\" + \",\".join(map(str, res)) + \"]\" for res in results]) + \"]\"\n    print(output_str)\n\n\ndef process_case(case_data):\n    \"\"\"\n    Processes a single test case to compute precision, override rate, and net benefits.\n    \"\"\"\n    kb_risks = case_data[\"kb_risks\"]\n    ground_truth = case_data[\"ground_truth\"]\n    overrides = case_data[\"overrides\"]\n    p_s = case_data[\"p_s\"]\n    dca_thresholds = case_data[\"dca_thresholds\"]\n\n    population_pairs = list(kb_risks.keys())\n    N = len(population_pairs)\n\n    # 1. Alert Generation and associated metrics (Precision, Override Rate)\n    fired_alerts = []\n    for pair in population_pairs:\n        risk = kb_risks[pair]\n        if risk >= p_s:\n            fired_alerts.append(pair)\n    \n    num_fired_alerts = len(fired_alerts)\n    \n    if num_fired_alerts == 0:\n        precision = 0.0\n        override_rate = 0.0\n    else:\n        # Calculate True Positives among fired alerts\n        tp_alerts = sum(1 for pair in fired_alerts if ground_truth[pair] == 1)\n        precision = tp_alerts / num_fired_alerts\n        \n        # Calculate Overridden alerts\n        overridden_alerts = sum(1 for pair in fired_alerts if overrides[pair] is True)\n        override_rate = overridden_alerts / num_fired_alerts\n        \n    # 2. Decision Curve Analysis (DCA)\n    net_benefits = []\n    for p_t in dca_thresholds:\n        if N == 0:\n            net_benefits.append(0.0)\n            continue\n            \n        tp_dca = 0\n        fp_dca = 0\n        \n        for pair in population_pairs:\n            risk = kb_risks[pair]\n            if risk >= p_t:\n                if ground_truth[pair] == 1:\n                    tp_dca += 1\n                else:\n                    fp_dca += 1\n        \n        # NB = (TP/N) - (FP/N) * (pt / (1-pt))\n        # The problem states pt is in [0,1], but the formula is undefined for pt=1.\n        # Test cases do not include pt=1, so we don't need to handle that edge case.\n        if p_t == 1.0:\n            # Net benefit for \"treat none\" is 0 if prevalence is > 0.\n            # If we decide based on risk >= 1, we get TP and FP.\n            # The weight becomes infinite, so any FP leads to -inf NB.\n            # This is not a standard case, but for completeness, we can set NB to a value.\n            # For this problem, we assume p_t  1 based on test data.\n            pass\n\n        weight = p_t / (1 - p_t)\n        nb = (tp_dca / N) - (fp_dca / N) * weight\n        net_benefits.append(nb)\n\n    return [precision, override_rate] + net_benefits\n\nsolve()\n```", "id": "4857560"}]}