{"hands_on_practices": [{"introduction": "The Point Spread Function ($PSF$) is the cornerstone of LTI system theory, but how do we measure it for a real-world imaging system like a microscope? This exercise walks you through the design of a classic bead phantom experiment, a practical method to estimate a system's $PSF$. By analyzing the image of a sub-resolution fluorescent bead, you will learn not only how to characterize the system's blur but also how to mathematically deconvolve the finite size of the bead itself to achieve a more accurate estimate of the true system $PSF$ [@problem_id:4897191].", "problem": "An optical widefield microscope is operated in a regime where its imaging can be modeled as a Linear Shift-Invariant (LSI) system, also commonly referred to in signal processing as a Linear Time-Invariant (LTI) system by analogy. The object intensity distribution $f(\\mathbf{r})$ is imaged to a measured intensity $m(\\mathbf{r})$ through the Point Spread Function (PSF), denoted $h(\\mathbf{r})$, via spatial convolution. You are tasked with designing and analyzing a bead phantom experiment to estimate the system PSF and to remove the broadening introduced by the finite bead size.\n\nThe fundamental base you must use consists of:\n- The definition of an LSI imaging model: $m(\\mathbf{r}) = (h * f)(\\mathbf{r})$, where $*$ is spatial convolution.\n- The definition of the PSF as the image of an impulse-like object.\n- The properties of spatial moments under convolution for normalized kernels.\n- The parametric form of a Gaussian function.\n\nDesign a plausible experiment and derive the deconvolution relationship from first principles as follows:\n1. Consider fluorescent microspheres (beads) with known radius $a$ that emit uniformly within their volume. In the focal plane, each bead can be modeled as a uniform disc of radius $a$ with unit integral when normalized, i.e., an areal “top-hat” kernel $b(\\mathbf{r})$ supported on $|\\mathbf{r}| \\leq a$ and zero elsewhere, normalized so that $\\int_{\\mathbb{R}^{2}} b(\\mathbf{r}) \\,\\mathrm{d}\\mathbf{r} = 1$. Place beads sparsely to avoid overlap and image them under identical conditions to minimize variability.\n2. Assume the lateral PSF of the microscope is isotropic and well-approximated by a zero-mean Gaussian $h(\\mathbf{r})$ with unknown standard deviation $\\sigma_{\\mathrm{sys}}$ along any lateral axis. The measured bead image $m(\\mathbf{r})$ is then the convolution of $h(\\mathbf{r})$ and $b(\\mathbf{r})$, and you fit the lateral cross-section of $m(\\mathbf{r})$ through a bead center with a Gaussian to obtain a measured standard deviation $\\sigma_{\\mathrm{meas}}$.\n3. Starting from the definitions above and without invoking any shortcut formulas, derive an analytic expression for $\\sigma_{\\mathrm{sys}}$ in terms of $\\sigma_{\\mathrm{meas}}$ and $a$ by using moment properties of convolution for normalized kernels and by computing the second central moment of the uniform disc model.\n4. From your derived $\\sigma_{\\mathrm{sys}}$, obtain the Full Width at Half Maximum (FWHM) of the system’s Gaussian PSF along one lateral axis.\n\nFor a specific experiment, take the bead radius to be $a = 120\\,\\mathrm{nm}$ and the Gaussian fit to the measured bead image to give $\\sigma_{\\mathrm{meas}} = 200\\,\\mathrm{nm}$ for the lateral cross-section. Using your derivations, compute the system PSF lateral FWHM and express your final numerical answer in micrometers. Round your answer to four significant figures. The final answer must be a single real number.", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It presents a standard task in optical microscopy characterization that can be solved using fundamental principles of signal processing and statistics. We may therefore proceed with the derivation and calculation.\n\nThe problem describes an imaging process modeled as a Linear Shift-Invariant (LSI) system. The measured image intensity $m(\\mathbf{r})$ is the spatial convolution of the object's intrinsic intensity distribution $f(\\mathbf{r})$ and the system's Point Spread Function (PSF) $h(\\mathbf{r})$.\n$$m(\\mathbf{r}) = (h * f)(\\mathbf{r}) = \\int_{\\mathbb{R}^2} h(\\mathbf{r} - \\mathbf{r'}) f(\\mathbf{r'}) \\, \\mathrm{d}\\mathbf{r'}$$\nIn this experiment, the object is a single, isolated fluorescent bead, which is modeled as a uniform disc of radius $a$. Its intensity distribution, denoted $b(\\mathbf{r})$, replaces $f(\\mathbf{r})$. The system's PSF, $h(\\mathbf{r})$, is assumed to be an isotropic, zero-mean Gaussian. The resulting measured bead image is $m(\\mathbf{r}) = (h * b)(\\mathbf{r})$. Both $h(\\mathbf{r})$ and $b(\\mathbf{r})$ are normalized to have unit integral, which is a requirement for them to be treated as probability density functions for the purpose of moment analysis.\n\nOur derivation hinges on the property that for a convolution of two zero-mean, normalized functions, the variance of the resulting function is the sum of the variances of the individual functions. Let us first prove this property. The variance of a normalized, 2D function $g(x,y)$ along the $x$-axis is its second central moment. Since the functions are zero-mean, this is $\\sigma_{g,x}^2 = \\int_{\\mathbb{R}^2} x^2 g(x,y) \\, \\mathrm{d}x\\mathrm{d}y$.\nThe variance of the measured image $m(x,y)$ along the $x$-axis is:\n$$\\sigma_{m,x}^2 = \\int_{\\mathbb{R}^2} x^2 m(x,y) \\, \\mathrm{d}x\\mathrm{d}y = \\int_{\\mathbb{R}^2} x^2 \\left( \\int_{\\mathbb{R}^2} h(x-x', y-y') b(x',y') \\, \\mathrm{d}x'\\mathrm{d}y' \\right) \\mathrm{d}x\\mathrm{d}y$$\nLet $u = x-x'$ and $v = y-y'$, so $x = u+x'$ and $y=v+y'$. The differential element $\\mathrm{d}x\\mathrm{d}y$ becomes $\\mathrm{d}u\\mathrm{d}v$.\n$$\\sigma_{m,x}^2 = \\int_{\\mathbb{R}^2} \\int_{\\mathbb{R}^2} (u+x')^2 h(u,v) b(x',y') \\, \\mathrm{d}u\\mathrm{d}v \\, \\mathrm{d}x'\\mathrm{d}y'$$\nExpanding the squared term $(u+x')^2 = u^2 + 2ux' + (x')^2$:\n$$\\sigma_{m,x}^2 = \\int_{\\mathbb{R}^2} \\int_{\\mathbb{R}^2} (u^2 + 2ux' + (x')^2) h(u,v) b(x',y') \\, \\mathrm{d}u\\mathrm{d}v \\, \\mathrm{d}x'\\mathrm{d}y'$$\nWe can separate this into three terms:\n$$1. \\quad \\int_{\\mathbb{R}^2} u^2 h(u,v) \\, \\mathrm{d}u\\mathrm{d}v \\int_{\\mathbb{R}^2} b(x',y') \\, \\mathrm{d}x'\\mathrm{d}y' = \\sigma_{h,x}^2 \\cdot 1 = \\sigma_{h,x}^2$$\n$$2. \\quad 2 \\int_{\\mathbb{R}^2} u h(u,v) \\, \\mathrm{d}u\\mathrm{d}v \\int_{\\mathbb{R}^2} x' b(x',y') \\, \\mathrm{d}x'\\mathrm{d}y' = 2 \\cdot (\\text{mean of } h) \\cdot (\\text{mean of } b) = 2 \\cdot 0 \\cdot 0 = 0$$\n$$3. \\quad \\int_{\\mathbb{R}^2} h(u,v) \\, \\mathrm{d}u\\mathrm{d}v \\int_{\\mathbb{R}^2} (x')^2 b(x',y') \\, \\mathrm{d}x'\\mathrm{d}y' = 1 \\cdot \\sigma_{b,x}^2 = \\sigma_{b,x}^2$$\nSumming these terms yields the additivity of variances:\n$$\\sigma_{m,x}^2 = \\sigma_{h,x}^2 + \\sigma_{b,x}^2$$\nDue to the isotropy of both the PSF and the bead model, the variances are the same along any lateral axis, so we can drop the subscript $x$.\nThe problem states that the measured profile is fitted with a Gaussian, yielding a standard deviation $\\sigma_{\\mathrm{meas}}$. This corresponds to $\\sigma_m$. The system PSF is a Gaussian with standard deviation $\\sigma_{\\mathrm{sys}}$, which corresponds to $\\sigma_h$. Thus, the relationship is:\n$$\\sigma_{\\mathrm{meas}}^2 = \\sigma_{\\mathrm{sys}}^2 + \\sigma_{b}^2$$\n\nNext, we must compute the variance, $\\sigma_{b}^2$, of the uniform disc model for the bead. The bead is a uniform disc of radius $a$. Its intensity distribution $b(\\mathbf{r})$ is given by:\n$$b(x,y) = \\begin{cases} C  \\text{if } x^2+y^2 \\leq a^2 \\\\ 0  \\text{otherwise} \\end{cases}$$\nThe normalization condition $\\int_{\\mathbb{R}^2} b(x,y) \\, \\mathrm{d}x\\mathrm{d}y = 1$ requires $C \\cdot (\\pi a^2) = 1$, so $C = \\frac{1}{\\pi a^2}$. The model is symmetric about the origin, so its mean is zero. The variance along the $x$-axis is:\n$$\\sigma_{b}^2 = \\int_{\\mathbb{R}^2} x^2 b(x,y) \\, \\mathrm{d}x\\mathrm{d}y = \\frac{1}{\\pi a^2} \\iint_{x^2+y^2 \\leq a^2} x^2 \\, \\mathrm{d}x\\mathrm{d}y$$\nWe convert to polar coordinates, with $x = r\\cos\\theta$ and $\\mathrm{d}x\\mathrm{d}y = r\\,\\mathrm{d}r\\mathrm{d}\\theta$.\n$$\\sigma_{b}^2 = \\frac{1}{\\pi a^2} \\int_0^{2\\pi} \\int_0^a (r\\cos\\theta)^2 r \\, \\mathrm{d}r\\mathrm{d}\\theta = \\frac{1}{\\pi a^2} \\int_0^{2\\pi} \\int_0^a r^3 \\cos^2\\theta \\, \\mathrm{d}r\\mathrm{d}\\theta$$\nThe integral is separable:\n$$\\sigma_{b}^2 = \\frac{1}{\\pi a^2} \\left(\\int_0^a r^3 \\, \\mathrm{d}r\\right) \\left(\\int_0^{2\\pi} \\cos^2\\theta \\, \\mathrm{d}\\theta\\right)$$\nThe radial integral is $\\int_0^a r^3 \\, \\mathrm{d}r = \\left[\\frac{r^4}{4}\\right]_0^a = \\frac{a^4}{4}$.\nThe angular integral is $\\int_0^{2\\pi} \\cos^2\\theta \\, \\mathrm{d}\\theta = \\int_0^{2\\pi} \\frac{1+\\cos(2\\theta)}{2} \\, \\mathrm{d}\\theta = \\left[\\frac{\\theta}{2} + \\frac{\\sin(2\\theta)}{4}\\right]_0^{2\\pi} = \\pi$.\nSubstituting these results:\n$$\\sigma_{b}^2 = \\frac{1}{\\pi a^2} \\left(\\frac{a^4}{4}\\right) (\\pi) = \\frac{a^2}{4}$$\nNow we can write the expression for $\\sigma_{\\mathrm{sys}}$. Substituting $\\sigma_b^2 = a^2/4$ into the variance addition formula:\n$$\\sigma_{\\mathrm{meas}}^2 = \\sigma_{\\mathrm{sys}}^2 + \\frac{a^2}{4}$$\nSolving for $\\sigma_{\\mathrm{sys}}$ gives the desired analytical expression:\n$$\\sigma_{\\mathrm{sys}} = \\sqrt{\\sigma_{\\mathrm{meas}}^2 - \\frac{a^2}{4}}$$\nThis completes the first part of the derivation.\n\nFor the second part, we must find the Full Width at Half Maximum (FWHM) of the system's Gaussian PSF. A 1D cross-section of the PSF is given by $h(x) = A \\exp\\left(-\\frac{x^2}{2\\sigma_{\\mathrm{sys}}^2}\\right)$ for some amplitude $A$. The maximum value is $h(0) = A$. The FWHM is the width $2x_{HM}$ where $h(x_{HM}) = A/2$.\n$$A \\exp\\left(-\\frac{x_{HM}^2}{2\\sigma_{\\mathrm{sys}}^2}\\right) = \\frac{A}{2}$$\n$$\\exp\\left(-\\frac{x_{HM}^2}{2\\sigma_{\\mathrm{sys}}^2}\\right) = \\frac{1}{2}$$\nTaking the natural logarithm of both sides:\n$$-\\frac{x_{HM}^2}{2\\sigma_{\\mathrm{sys}}^2} = \\ln\\left(\\frac{1}{2}\\right) = -\\ln(2)$$\n$$x_{HM}^2 = 2 \\sigma_{\\mathrm{sys}}^2 \\ln(2) \\implies x_{HM} = \\sigma_{\\mathrm{sys}} \\sqrt{2 \\ln(2)}$$\nThe FWHM is twice this value:\n$$\\text{FWHM}_{\\mathrm{sys}} = 2 x_{HM} = 2 \\sqrt{2 \\ln(2)} \\sigma_{\\mathrm{sys}}$$\nSubstituting our expression for $\\sigma_{\\mathrm{sys}}$:\n$$\\text{FWHM}_{\\mathrm{sys}} = 2 \\sqrt{2 \\ln(2)} \\sqrt{\\sigma_{\\mathrm{meas}}^2 - \\frac{a^2}{4}}$$\nNow we substitute the given numerical values: $a = 120\\,\\mathrm{nm}$ and $\\sigma_{\\mathrm{meas}} = 200\\,\\mathrm{nm}$. All calculations will be performed in units of nanometers (nm).\n$$\\sigma_{\\mathrm{sys}}^2 = (200)^2 - \\frac{(120)^2}{4} = 40000 - \\frac{14400}{4} = 40000 - 3600 = 36400\\,\\mathrm{nm}^2$$\n$$\\sigma_{\\mathrm{sys}} = \\sqrt{36400}\\,\\mathrm{nm}$$\nNow we compute the FWHM:\n$$\\text{FWHM}_{\\mathrm{sys}} = 2 \\sqrt{2 \\ln(2)} \\sqrt{36400}\\,\\mathrm{nm}$$\nUsing the value $\\ln(2) \\approx 0.693147$:\n$$\\text{FWHM}_{\\mathrm{sys}} = 2 \\sqrt{2 \\cdot 0.693147} \\cdot \\sqrt{36400}\\,\\mathrm{nm}$$\n$$\\text{FWHM}_{\\mathrm{sys}} \\approx 2 \\sqrt{1.386294} \\cdot 190.7878...\\,\\mathrm{nm}$$\n$$\\text{FWHM}_{\\mathrm{sys}} \\approx 2.35482 \\cdot 190.7878...\\,\\mathrm{nm} \\approx 449.284\\,\\mathrm{nm}$$\nThe problem requires the answer in micrometers ($\\mu$m), rounded to four significant figures.\n$$1\\,\\mathrm{nm} = 10^{-3}\\,\\mu\\mathrm{m}$$\n$$\\text{FWHM}_{\\mathrm{sys}} \\approx 449.284 \\times 10^{-3}\\,\\mu\\mathrm{m} = 0.449284\\,\\mu\\mathrm{m}$$\nRounding to four significant figures gives $0.4493\\,\\mu\\mathrm{m}$.", "answer": "$$\\boxed{0.4493}$$", "id": "4897191"}, {"introduction": "Once a system's $PSF$ is known, we often perform convolutions computationally, typically using the highly efficient Fast Fourier Transform ($FFT$). However, the convolution theorem for discrete signals corresponds to circular convolution, not the linear convolution that describes physical imaging systems. This practice challenges you to derive from first principles the precise zero-padding required to use the $FFT$ to obtain a correct linear convolution, preventing the wrap-around errors that can corrupt image data near the boundaries [@problem_id:4897204].", "problem": "Consider a two-dimensional linear, shift-invariant (LSI) imaging system in the foundations of medical imaging. The system’s point spread function (PSF) is the discrete impulse response $h[i,j]$ with finite rectangular support of size $K_x \\times K_y$, meaning $h[i,j] = 0$ for any $i \\notin \\{0,1,\\dots,K_x-1\\}$ or $j \\notin \\{0,1,\\dots,K_y-1\\}$. A discrete object $f[m,n]$ of size $N_x \\times N_y$ produces the ideal image $g[m,n]$ via linear convolution, so that the mapping from $f$ to $g$ is linear and shift-invariant.\n\nIn practice, convolution is implemented using the Fast Fourier Transform (FFT) of the Discrete Fourier Transform (DFT): one zero-pads $f$ and $h$ to size $P_x \\times P_y$, computes their DFTs, multiplies them, and applies the inverse DFT to obtain a circular convolution on the $P_x \\times P_y$ grid. The result is then cropped to $N_x \\times N_y$.\n\nStarting from the core definitions of linear convolution, circular convolution, and finite support, derive how zero-padding imposes a spatially varying, position-dependent “effective PSF” at the borders when the object is assumed zero outside its support. Specifically, express the effective PSF at a given pixel location $(m,n)$ as a truncated version of $h[i,j]$ determined by the available indices of $f[m-i,n-j]$. Then, using the fundamental relationship between linear and circular convolution and nonzero support extents, derive the minimal padding lengths $P_x$ and $P_y$ required so that FFT-based convolution produces the exact linear convolution everywhere (i.e., no circular overlap or wrap-around in either dimension) when cropping back to $N_x \\times N_y$.\n\nYour final answer must be the closed-form analytic expression for the minimal $P_x$ and $P_y$ as functions of $N_x$, $N_y$, $K_x$, and $K_y$. Express the final answer with no units. No rounding is required.", "solution": "The problem asks for two derivations concerning the convolution of a discrete object with a point spread function (PSF) in an imaging system. First, to describe the position-dependent \"effective PSF\" that arises from finite object support, and second, to derive the minimal zero-padding dimensions required to compute the exact linear convolution using the DFT/FFT method.\n\nLet the discrete object be $f[m,n]$ and the system's PSF be $h[i,j]$.\nThe problem states that $f[m,n]$ has a support of size $N_x \\times N_y$, meaning it is non-zero only for indices $(m,n)$ where $m \\in \\{0, 1, \\dots, N_x-1\\}$ and $n \\in \\{0, 1, \\dots, N_y-1\\}$.\nThe PSF $h[i,j]$ has a finite rectangular support of size $K_x \\times K_y$, meaning it is non-zero only for indices $(i,j)$ where $i \\in \\{0, 1, \\dots, K_x-1\\}$ and $j \\in \\{0, 1, \\dots, K_y-1\\}$.\n\nThe ideal image, $g[m,n]$, is given by the two-dimensional linear convolution of $f$ and $h$, denoted by $(f * h)[m,n]$. The convolution sum can be expressed as:\n$$g[m,n] = \\sum_{i=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} h[i,j] f[m-i, n-j]$$\nGiven the finite support of the PSF $h[i,j]$, the summation indices are restricted:\n$$g[m,n] = \\sum_{i=0}^{K_x-1} \\sum_{j=0}^{K_y-1} h[i,j] f[m-i, n-j]$$\n\n**Part 1: The Effective Point Spread Function**\n\nThe concept of a spatially varying \"effective PSF\" arises because the object $f$ is also of finite support. The term $f[m-i, n-j]$ in the summation is non-zero only if its indices lie within the support of $f$. That is, we must have:\n$$0 \\le m-i \\le N_x-1$$\n$$0 \\le n-j \\le N_y-1$$\nFor a given output pixel location $(m,n)$, these conditions impose constraints on the indices $(i,j)$ of the PSF $h[i,j]$ that can contribute to the sum. For pixels $(m,n)$ close to the boundaries of the object domain, some values of $(i,j)$ (for which $h[i,j]$ is non-zero) will cause the argument $(m-i, n-j)$ to fall outside the support of $f$. In these cases, the product $h[i,j] f[m-i, n-j]$ is zero.\n\nFor example, consider an output pixel at $m=0, n=0$. The convolution is:\n$$g[0,0] = \\sum_{i=0}^{K_x-1} \\sum_{j=0}^{K_y-1} h[i,j] f[-i, -j]$$\nSince $f$'s support is on non-negative indices, $f[-i,-j]$ is non-zero only for $i=0$ and $j=0$. Thus, the sum collapses to a single term: $g[0,0] = h[0,0] f[0,0]$. The convolution at this location only \"sees\" the tap $h[0,0]$ of the PSF.\n\nThis demonstrates that for each output location $(m,n)$, the convolution is performed with an \"effective PSF\", let's call it $h_{\\text{eff}, (m,n)}[i,j]$, which is a truncated version of the true PSF $h[i,j]$. This effective PSF can be expressed as:\n$$h_{\\text{eff}, (m,n)}[i,j] = \\begin{cases} h[i,j]  \\text{if } 0 \\le m-i \\le N_x-1 \\text{ and } 0 \\le n-j \\le N_y-1 \\\\ 0  \\text{otherwise} \\end{cases}$$\nThe output image can then be thought of as:\n$$g[m,n] = \\sum_{i=0}^{K_x-1} \\sum_{j=0}^{K_y-1} h_{\\text{eff}, (m,n)}[i,j] f[m-i, n-j]$$\nThis effective PSF is position-dependent. Only for output pixels $(m,n)$ far enough from the borders (specifically, for $m \\ge K_x-1$ and $n \\ge K_y-1$ such that $m-i$ and $n-j$ for all $i,j$ in the support of $h$ map to valid indices in $f$) does the effective PSF equal the full PSF, $h_{\\text{eff}, (m,n)}[i,j]=h[i,j]$. This boundary effect is a direct consequence of convolving two finite-support signals.\n\n**Part 2: Minimal Padding for FFT-Based Convolution**\n\nThe convolution theorem states that linear convolution in the spatial domain is equivalent to multiplication in the frequency domain. Computationally, this is performed using the Discrete Fourier Transform (DFT), often implemented via the Fast Fourier Transform (FFT). The DFT, however, inherently assumes periodic signals, and its multiplication-in-frequency-domain property corresponds to circular convolution in the spatial/time domain, not linear convolution.\n\nTo compute linear convolution using the DFT, we must zero-pad the signals $f$ and $h$ to a sufficiently large size, say $P_x \\times P_y$, to prevent wrap-around (aliasing) effects inherent in circular convolution. Let the padded signals be $f_p[m,n]$ and $h_p[m,n]$, both of size $P_x \\times P_y$. Their circular convolution is:\n$$g_{\\text{circ}}[m,n] = (f_p \\circledast h_p)[m,n] = \\sum_{i=0}^{P_x-1} \\sum_{j=0}^{P_y-1} h_p[i,j] f_p[(m-i) \\pmod{P_x}, (n-j) \\pmod{P_y}]$$\nGiven the support of $h_p[i,j]$ is the same as $h[i,j]$, this simplifies to:\n$$g_{\\text{circ}}[m,n] = \\sum_{i=0}^{K_x-1} \\sum_{j=0}^{K_y-1} h[i,j] f_p[(m-i) \\pmod{P_x}, (n-j) \\pmod{P_y}]$$\nWe require this result to be identical to the linear convolution result, $g[m,n]$, for all output pixels in the region of interest, i.e., for $m \\in \\{0, \\dots, N_x-1\\}$ and $n \\in \\{0, \\dots, N_y-1\\}$.\n\nComparing the expression for $g_{\\text{circ}}[m,n]$ with that for $g[m,n]$, equality is achieved if:\n$$f_p[(m-i) \\pmod{P_x}, (n-j) \\pmod{P_y}] = f[m-i, n-j]$$\nfor all $(m,n)$ in the output region $\\{0, \\dots, N_x-1\\} \\times \\{0, \\dots, N_y-1\\}$ and all $(i,j)$ in the PSF support $\\{0, \\dots, K_x-1\\} \\times \\{0, \\dots, K_y-1\\}$.\n\nLet's analyze the range of indices required for the argument of $f$ along the first dimension. Let this index be $u = m-i$.\nThe range of $m$ is $[0, N_x-1]$.\nThe range of $i$ is $[0, K_x-1]$.\nThe minimum value of $u$ is $0 - (K_x-1) = -(K_x-1)$.\nThe maximum value of $u$ is $(N_x-1) - 0 = N_x-1$.\nSo, to compute the output over the specified region, we need to access values of $f[u, \\cdot]$ for $u \\in [-(K_x-1), N_x-1]$.\n\nThe signal $f_p$ is constructed by placing $f$ in a $P_x \\times P_y$ grid of zeros. The circular convolution effectively treats this grid as one period of a periodic signal. The wrap-around effect is captured by the modulo operation. Let's analyze its consequences for the index $u$:\n1. For $u \\in [0, N_x-1]$:\n   In this range, $f[u, \\cdot]$ is potentially non-zero. The term in the circular convolution is $f_p[u \\pmod{P_x}, \\cdot]$. If we choose $P_x > N_x-1$, then $u \\pmod{P_x} = u$. Since $f_p[u, \\cdot] = f[u, \\cdot]$ for this range by definition of zero-padding, the equality holds.\n2. For $u \\in [-(K_x-1), -1]$:\n   In this range, $f[u, \\cdot] = 0$ by definition of its support. We need the circular convolution term to also be zero. The term is $f_p[u \\pmod{P_x}, \\cdot]$. For negative $u$, $u \\pmod{P_x} = u + P_x$. So we require $f_p[u+P_x, \\cdot] = 0$.\n   The padded signal $f_p$ is non-zero only for indices in the range $[0, N_x-1]$. We must ensure that the wrapped-around negative indices do not fall into this range. This means we must have:\n   $$u + P_x > N_x-1$$\n   This condition must hold for all $u$ in the range $[-(K_x-1), -1]$. The worst case (the smallest value of $u+P_x$) occurs at the minimum value of $u$, which is $u = -(K_x-1)$.\n   $$-(K_x-1) + P_x > N_x-1$$\n   $$P_x - K_x + 1 > N_x - 1$$\n   $$P_x > N_x + K_x - 2$$\n   Since $P_x$ must be an integer, the minimal value for $P_x$ that satisfies this strict inequality is $P_x = N_x + K_x - 1$.\n\nThis choice of $P_x$ ensures that the \"tail\" of the PSF that extends to require negative indices from the object signal wraps around into a region of the padded DFT grid that is guaranteed to be zero, thus avoiding aliasing and correctly replicating the linear convolution boundary condition where the object is assumed to be zero outside its support.\n\nThe same derivation applies independently to the second dimension, leading to the condition $P_y > N_y + K_y - 2$. The minimal integer value is $P_y = N_y + K_y - 1$.\n\nTherefore, to ensure that the FFT-based circular convolution produces the exact linear convolution result within the desired $N_x \\times N_y$ output grid, the minimal padding dimensions must be:\n$$P_x = N_x + K_x - 1$$\n$$P_y = N_y + K_y - 1$$\nThis size is precisely the size of the full support of the linear convolution output, ensuring that no information is lost to aliasing.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nN_x + K_x - 1  N_y + K_y - 1\n\\end{pmatrix}\n}\n$$", "id": "4897204"}, {"introduction": "Computing convolutions for large, three-dimensional datasets like those in CT or MRI can be extremely computationally intensive. Fortunately, we can often exploit the mathematical structure of the $PSF$ to achieve massive speedups. This exercise guides you to prove a fundamental property of separable kernels—that a three-dimensional convolution can be decomposed into three, far less costly, one-dimensional convolutions—and to quantify the resulting gain in efficiency [@problem_id:4897196].", "problem": "A three-dimensional imaging system in the foundations of medical imaging can be modeled as a linear, shift-invariant (also called linear, time-invariant) system with impulse response (point spread function) $h(\\mathbf{r})$, where $\\mathbf{r} = (x,y,z)$ indexes a discrete cubic grid. The output $g$ of such a system to an input volume $f$ is the discrete convolution\n$$\ng(x,y,z) = (f * h)(x,y,z) = \\sum_{u}\\sum_{v}\\sum_{w} f(x-u, y-v, z-w)\\, h(u,v,w),\n$$\nwhere the sums are over all integer indices where $f$ and $h$ are supported. Suppose the impulse response is separable, i.e., it can be written as $h(u,v,w) = h_x(u)\\, h_y(v)\\, h_z(w)$ for some one-dimensional kernels $h_x$, $h_y$, and $h_z$.\n\n(a) Starting only from the definition of discrete convolution and the algebraic properties of finite sums (linearity, commutativity, and associativity of addition and scalar multiplication), show that $g$ can be computed by three successive one-dimensional convolutions applied to $f$ along the $x$-, $y$-, and $z$-axes (in any order), each with the corresponding kernel $h_x$, $h_y$, and $h_z$.\n\n(b) Let the input volume be of size $N \\times N \\times N$, and assume circular convolution in each dimension so that every output voxel involves the full kernel support. Let each one-dimensional kernel have finite length $K$ (so that $h$ has support $K \\times K \\times K$). Define arithmetic complexity as the total number of scalar multiplications required to compute all $N^3$ output voxels. Compute the multiplicative speedup factor of using three one-dimensional convolutions instead of a single direct three-dimensional convolution, defined as the ratio\n$$\nS(K) = \\frac{\\text{multiplications required by direct } 3\\text{D convolution}}{\\text{multiplications required by three successive } 1\\text{D convolutions}}.\n$$\nExpress your final answer as a single simplified analytic expression in terms of $K$ only. Do not include units.", "solution": "The problem statement is first validated against the required criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **System**: A three-dimensional imaging system modeled as a linear, shift-invariant (LSI) system.\n- **Impulse Response (PSF)**: $h(\\mathbf{r})$, where $\\mathbf{r} = (x,y,z)$ on a discrete cubic grid.\n- **Input**: $f$.\n- **Output**: $g$.\n- **3D Convolution Definition**: $g(x,y,z) = (f * h)(x,y,z) = \\sum_{u}\\sum_{v}\\sum_{w} f(x-u, y-v, z-w)\\, h(u,v,w)$. The sums are over all integer indices where $f$ and $h$ are supported.\n- **Separable Impulse Response**: $h(u,v,w) = h_x(u)\\, h_y(v)\\, h_z(w)$ for 1D kernels $h_x, h_y, h_z$.\n- **Part (a) Objective**: Show that $g$ can be computed by three successive 1D convolutions along the axes, using only the definition of convolution and algebraic properties of finite sums. The order of convolutions should not matter.\n- **Part (b) Parameters**:\n    - Input volume size: $N \\times N \\times N$.\n    - Convolution type: Circular convolution in each dimension.\n    - Kernel support: Each 1D kernel ($h_x, h_y, h_z$) has length $K$. The 3D kernel $h$ has support $K \\times K \\times K$.\n    - Complexity measure: Total number of scalar multiplications.\n- **Part (b) Objective**: Compute the multiplicative speedup factor $S(K) = \\frac{\\text{multiplications required by direct } 3\\text{D convolution}}{\\text{multiplications required by three successive } 1\\text{D convolutions}}$ as a function of $K$ only.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is well-grounded in the principles of linear systems theory, a cornerstone of signal processing and its applications in medical imaging. The concepts of LSI systems, impulse response (PSF), convolution, and separable kernels are standard and fundamental.\n- **Well-Posed**: The problem is well-posed. Part (a) is a request for a mathematical proof based on given axioms (definition of convolution and properties of sums). Part (b) is a computational complexity analysis with all parameters ($N$, $K$) and calculation rules (circular convolution, counting multiplications) clearly defined, leading to a unique analytical expression for the speedup.\n- **Objective**: The problem is stated in precise, objective, and mathematical language. There are no subjective or ambiguous terms.\n- **Flaw Analysis**:\n    1.  **Scientific/Factual Unsoundness**: None. The mathematical and physical models are standard.\n    2.  **Non-Formalizable/Irrelevant**: None. The problem is perfectly formalizable and directly relevant to the topic of LTI systems in medical imaging.\n    3.  **Incomplete/Contradictory Setup**: None. All necessary definitions and constraints are provided. The mention of \"finite sums\" is consistent with kernels of finite support ($K$).\n    4.  **Unrealistic/Infeasible**: None. Separable PSFs are a common and computationally important special case in practice.\n    5.  **Ill-Posed/Poorly Structured**: None. The questions are clear and lead to uniquely determinable answers.\n    6.  **Pseudo-Profound/Trivial**: None. While a standard result, its derivation in part (a) requires a careful application of first principles. The calculation in part (b) demonstrates a practically significant computational principle.\n    7.  **Outside Scientific Verifiability**: None. The proof and calculation are mathematically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. Proceed with the solution.\n\n### Solution\n\n**(a) Proof of Separable Convolution**\n\nWe begin with the definition of the three-dimensional discrete convolution for the output $g(x,y,z)$:\n$$\ng(x,y,z) = \\sum_{u}\\sum_{v}\\sum_{w} f(x-u, y-v, z-w)\\, h(u,v,w)\n$$\nThe problem states that the impulse response $h$ is separable. We substitute the given form $h(u,v,w) = h_x(u)\\, h_y(v)\\, h_z(w)$ into the convolution sum:\n$$\ng(x,y,z) = \\sum_{u}\\sum_{v}\\sum_{w} f(x-u, y-v, z-w)\\, h_x(u)\\, h_y(v)\\, h_z(w)\n$$\nThe sums are finite, as the kernels have finite support. Using the algebraic properties of finite sums (specifically, the distributive law which allows factoring terms not dependent on the summation index), we can rearrange the order of summation and group the terms. Let's group the summation over $u$ first.\n$$\ng(x,y,z) = \\sum_{v}\\sum_{w} h_y(v)\\, h_z(w) \\left[ \\sum_{u} f(x-u, y-v, z-w)\\, h_x(u) \\right]\n$$\nThe expression inside the brackets is a one-dimensional convolution of a slice of the input volume $f$ with the kernel $h_x$. Let us define an intermediate volume $g_1$ where each $x$-oriented line of $f$ is convolved with $h_x$:\n$$\ng_1(x, y', z') = \\sum_{u} f(x-u, y', z')\\, h_x(u)\n$$\nSubstituting this definition back into our expression for $g(x,y,z)$ with $y' = y-v$ and $z' = z-w$:\n$$\ng(x,y,z) = \\sum_{v}\\sum_{w} h_y(v)\\, h_z(w)\\, g_1(x, y-v, z-w)\n$$\nNext, we can group the summation over $v$:\n$$\ng(x,y,z) = \\sum_{w} h_z(w) \\left[ \\sum_{v} g_1(x, y-v, z-w)\\, h_y(v) \\right]\n$$\nThe expression inside the new set of brackets is a one-dimensional convolution of a slice of the intermediate volume $g_1$ with the kernel $h_y$. Let us define a second intermediate volume $g_2$ where each $y$-oriented line of $g_1$ is convolved with $h_y$:\n$$\ng_2(x', y, z') = \\sum_{v} g_1(x', y-v, z')\\, h_y(v)\n$$\nSubstituting this into the expression for $g(x,y,z)$ with $x' = x$ and $z' = z-w$:\n$$\ng(x,y,z) = \\sum_{w} g_2(x, y, z-w)\\, h_z(w)\n$$\nThis final expression is the one-dimensional convolution of a $z$-oriented line of the volume $g_2$ with the kernel $h_z$. Thus, the final output $g$ is obtained by:\n$$\ng(x,y,z) = \\sum_{w} g_2(x, y, z-w)\\, h_z(w)\n$$\nThis demonstrates that the 3D convolution can be computed by three successive 1D convolutions: first along an axis (e.g., $x$), then along a second axis (e.g., $y$), and finally along the third axis (e.g., $z$).\n\nTo show that this can be done in any order, we recognize that the ability to re-group the sums is a consequence of the commutativity and associativity of addition over finite sets. For instance, we could have started by isolating the sum over $w$ first:\n$$\ng(x,y,z) = \\sum_{u}\\sum_{v} h_x(u)\\, h_y(v) \\left[ \\sum_{w} f(x-u, y-v, z-w)\\, h_z(w) \\right]\n$$\nThis corresponds to performing the convolution along the $z$-axis first. Since the three summation indices $u,v,w$ are independent, the summations can be performed in any of the $3! = 6$ possible orders, which directly corresponds to the six possible orderings of the 1D convolutions along the $x,y,z$ axes. This completes the proof for part (a).\n\n**(b) Multiplicative Speedup Factor**\n\nWe define the arithmetic complexity as the total number of scalar multiplications required to compute the entire $N \\times N \\times N$ output volume.\n\n**1. Complexity of Direct 3D Convolution**\n\nTo compute a single output voxel $g(x,y,z)$ using the direct method, we evaluate:\n$$\ng(x,y,z) = \\sum_{u}\\sum_{v}\\sum_{w} f(\\dots)\\, h(u,v,w)\n$$\nThe problem states that the 1D kernels have length $K$, so the 3D kernel $h(u,v,w)$ is non-zero over a support of $K \\times K \\times K$. This means the sums over $u$, $v$, and $w$ each run over $K$ values. The total number of terms in the summation for a single output voxel is $K \\times K \\times K = K^3$. Each term consists of one multiplication.\nTherefore, the number of multiplications per output voxel is $K^3$.\nThe output volume has $N \\times N \\times N = N^3$ voxels.\nThe total number of multiplications for the direct 3D convolution, $C_{3D}$, is:\n$$\nC_{3D} = (\\text{voxels}) \\times (\\text{multiplications per voxel}) = N^3 \\times K^3\n$$\n\n**2. Complexity of Separable 1D Convolutions**\n\nThis computation proceeds in three stages as shown in part (a).\n\n*   **Stage 1: Convolution along the $x$-axis.**\n    We convolve the input $f$ with $h_x$. This involves performing a 1D convolution for each \"row\" of the volume, where a row is defined by a constant $(y,z)$ pair. There are $N \\times N = N^2$ such rows.\n    For each row, we are performing a 1D circular convolution of an $N$-point signal with a $K$-point kernel. To compute each of the $N$ output points in this 1D convolution requires $K$ multiplications.\n    Multiplications for one row: $N \\times K$.\n    Total multiplications for Stage 1: $(\\text{number of rows}) \\times (\\text{multiplications per row}) = N^2 \\times (NK) = N^3 K$.\n\n*   **Stage 2: Convolution along the $y$-axis.**\n    We convolve the intermediate volume $g_1$ from Stage 1 with $h_y$. This is done for each \"column\", where a column is defined by a constant $(x,z)$ pair. There are $N^2$ such columns.\n    Similar to Stage 1, the computation for each column requires $N \\times K$ multiplications.\n    Total multiplications for Stage 2: $N^2 \\times (NK) = N^3 K$.\n\n*   **Stage 3: Convolution along the $z$-axis.**\n    We convolve the intermediate volume $g_2$ from Stage 2 with $h_z$. This is done for each \"fiber\", where a fiber is defined by a constant $(x,y)$ pair. There are $N^2$ such fibers.\n    The computation for each fiber requires $N \\times K$ multiplications.\n    Total multiplications for Stage 3: $N^2 \\times (NK) = N^3 K$.\n\nThe total number of multiplications for the separable method, $C_{sep}$, is the sum of the multiplications from the three stages:\n$$\nC_{sep} = N^3 K + N^3 K + N^3 K = 3 N^3 K\n$$\n\n**3. Speedup Factor $S(K)$**\n\nThe speedup factor is the ratio of the two complexities:\n$$\nS(K) = \\frac{C_{3D}}{C_{sep}} = \\frac{N^3 K^3}{3 N^3 K}\n$$\nThe $N^3$ term cancels out, as expected, since the speedup is a property of the kernel size.\n$$\nS(K) = \\frac{K^3}{3K} = \\frac{K^2}{3}\n$$\nThis is the simplified analytic expression for the speedup factor in terms of $K$.", "answer": "$$\\boxed{\\frac{K^2}{3}}$$", "id": "4897196"}]}