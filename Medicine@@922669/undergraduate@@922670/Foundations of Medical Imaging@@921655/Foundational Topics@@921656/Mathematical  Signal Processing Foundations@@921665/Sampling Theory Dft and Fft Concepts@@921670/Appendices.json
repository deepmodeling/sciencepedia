{"hands_on_practices": [{"introduction": "The Fast Fourier Transform (FFT) provides a highly efficient method for performing convolution, a cornerstone operation in signal and image processing. However, the FFT's convolution theorem inherently computes circular convolution, not the linear convolution typically required. This exercise [@problem_id:4920806] challenges you to derive the precise zero-padding condition necessary to ensure the result of circular convolution is identical to linear convolution, a critical step for preventing wrap-around errors in practical applications.", "problem": "A one-dimensional digital imaging system in a medical imaging pipeline applies a known discrete impulse response to a discrete reflectivity profile. Let $x[n]$ denote the discrete object reflectivity with finite support $x[n]=0$ for $n \\notin \\{0,\\dots,N_{x}-1\\}$, and let $h[n]$ denote the discrete impulse response with finite support $h[n]=0$ for $n \\notin \\{0,\\dots,N_{h}-1\\}$. The desired output is the linear convolution $y[n] = \\sum_{m=-\\infty}^{\\infty} x[m]\\,h[n-m]$. For computational efficiency, the output is computed by zero-padding both sequences to a common length $L$ and then using the Discrete Fourier Transform (DFT) and its efficient implementation via the Fast Fourier Transform (FFT). Specifically, the algorithm computes the pointwise product of the $L$-point DFTs of the zero-padded sequences and then applies the inverse $L$-point DFT, which yields the $L$-point circular convolution of the zero-padded sequences.\n\nStarting from the definitions of linear convolution, circular convolution modulo $L$, and the convolution theorem for the DFT, derive the condition on $L$ such that this $L$-point circular convolution exactly equals the linear convolution $y[n]$ for all indices where $y[n]$ may be nonzero. Then provide the minimal such $L$ as a closed-form expression in terms of $N_{x}$ and $N_{h}$. Express your final answer as a single analytic expression for this minimal $L$ in terms of $N_{x}$ and $N_{h}$.", "solution": "The problem requires the derivation of the condition on the length $L$ of the Discrete Fourier Transform (DFT) such that the circular convolution of two zero-padded sequences equals the linear convolution of the original sequences. We are given two discrete sequences, the object reflectivity $x[n]$ and the impulse response $h[n]$.\n\nFirst, we analyze the properties of the linear convolution, denoted by $y[n]$. The definition of linear convolution is given by:\n$$y[n] = (x * h)[n] = \\sum_{m=-\\infty}^{\\infty} x[m]\\,h[n-m]$$\nThe sequence $x[n]$ has finite support for $n \\in \\{0, 1, \\dots, N_x-1\\}$, meaning it has a length of $N_x$. The sequence $h[n]$ has finite support for $n \\in \\{0, 1, \\dots, N_h-1\\}$, meaning it has a length of $N_h$. Due to the finite support of both sequences, the summation can be restricted to the indices where $x[m]$ is non-zero:\n$$y[n] = \\sum_{m=0}^{N_x-1} x[m]\\,h[n-m]$$\nFor the product $x[m]h[n-m]$ to be non-zero, the argument of $h$, which is $n-m$, must also fall within its support, i.e., $0 \\le n-m \\le N_h-1$.\nThe resulting sequence $y[n]$ will also have finite support. The first non-zero sample of $y[n]$ occurs at the smallest value of $n$ for which the supports of $x[m]$ and $h[n-m]$ overlap. This happens when $m=0$ and $n-m=0$, which implies $n=0$. So, the support of $y[n]$ starts at $n=0$.\nThe last non-zero sample of $y[n]$ occurs at the largest value of $n$ for which the supports overlap. This corresponds to the largest index of $x[m]$, which is $m=N_x-1$, and the largest index for the argument of $h$, which is $n-m=N_h-1$. Substituting $m=N_x-1$ into the second equation gives $n-(N_x-1) = N_h-1$, which solves to $n = N_x + N_h - 2$.\nTherefore, the support of the linear convolution $y[n]$ is for indices $n \\in \\{0, 1, \\dots, N_x + N_h - 2\\}$. The length of the sequence $y[n]$, denoted $N_y$, is the number of points in this support, which is $(N_x + N_h - 2) - 0 + 1 = N_x + N_h - 1$.\n\nThe computational procedure described involves zero-padding $x[n]$ and $h[n]$ to a common length $L$. Let these padded sequences be $x_p[n]$ and $h_p[n]$.\n$$x_p[n] = \\begin{cases} x[n] & 0 \\le n \\le N_x-1 \\\\ 0 & N_x \\le n \\le L-1 \\end{cases}$$\n$$h_p[n] = \\begin{cases} h[n] & 0 \\le n \\le N_h-1 \\\\ 0 & N_h \\le n \\le L-1 \\end{cases}$$\nThe algorithm then computes the $L$-point DFTs $X_p[k]$ and $H_p[k]$, their product $Y_p[k] = X_p[k]H_p[k]$, and the inverse $L$-point DFT of the product. According to the convolution theorem for the DFT, this result is the $L$-point circular convolution of $x_p[n]$ and $h_p[n]$, which we denote as $y_c[n]$.\n$$y_c[n] = \\sum_{m=0}^{L-1} x_p[m]\\,h_p[(n-m) \\pmod L]$$\nThe relationship between the linear convolution $y[n]$ and the circular convolution $y_c[n]$ (of the padded sequences) is given by:\n$$y_c[n] = \\sum_{k=-\\infty}^{\\infty} y[n+kL] \\quad \\text{for } n \\in \\{0, 1, \\dots, L-1\\}$$\nThis equation shows that the circular convolution is a time-aliased version of the linear convolution, where the linear convolution result is wrapped around and summed with period $L$.\n\nFor the circular convolution $y_c[n]$ to be identical to the linear convolution $y[n]$ over the interval where $y[n]$ may be non-zero (i.e., for $n \\in \\{0, \\dots, N_x+N_h-2\\}$), we must ensure that no wrap-around (aliasing) occurs. This means that for each $n$ in the interval $\\{0, \\dots, L-1\\}$, the sum $\\sum_{k=-\\infty}^{\\infty} y[n+kL]$ must contain only one non-zero term, which is $y[n]$ for $k=0$. This requires that $y[n+kL]=0$ for all integers $k \\neq 0$.\n\nLet's analyze this condition:\n1.  For $k \\ge 1$: We need $y[n+kL]=0$ for all $n \\in \\{0, \\dots, L-1\\}$. The smallest index is $n+kL = 0+1\\cdot L = L$. Thus, we require that the linear convolution $y[j]$ be zero for all indices $j \\ge L$. Since the support of $y[n]$ ends at $n=N_x+N_h-2$, this condition is satisfied if $L > N_x+N_h-2$.\n\n2.  For $k \\le -1$: We need $y[n+kL]=0$ for all $n \\in \\{0, \\dots, L-1\\}$. Let's consider $k=-1$. The largest index is $n-L = (L-1)-L = -1$. We require that $y[j]$ be zero for all indices $j \\le -1$. The support of $y[n]$ begins at $n=0$, so this condition is always met. The conditions for $k \\le -2$ are even less restrictive.\n\nCombining these observations, the sole condition to prevent time-domain aliasing is that the length $L$ must be large enough to contain the entire linear convolution result without wrap-around. The length of the linear convolution result $y[n]$ is $N_y = N_x+N_h-1$. Therefore, the circular convolution buffer must be at least this long.\nThe condition is $L \\ge N_y$, which translates to:\n$$L \\ge N_x + N_h - 1$$\nThis inequality is the derived condition on $L$.\n\nThe problem asks for the minimal such $L$. Given that $L$ must be an integer that satisfies $L \\ge N_x + N_h - 1$, the minimum possible value for $L$ is the smallest integer that meets this condition. This minimum value is precisely $N_x + N_h - 1$.\nThus, the minimal length $L$ for which the $L$-point circular convolution equals the linear convolution is:\n$$L_{\\text{min}} = N_x + N_h - 1$$", "answer": "$$\\boxed{N_{x} + N_{h} - 1}$$", "id": "4920806"}, {"introduction": "The Discrete Fourier Transform (DFT) provides a frequency-domain view of a signal, but it is fundamentally a projection onto a discrete set of frequencies, often likened to looking through a \"picket fence\". This practice [@problem_id:4920820] explores what happens when a signal's true frequency falls between these DFT bins, leading to spectral leakage. By deriving the magnitude of the spectrum, you will gain a quantitative understanding of this important artifact and learn how it impacts the interpretation of spectral data from systems like MRI.", "problem": "In magnetic resonance imaging, a one-dimensional readout along the frequency-encoding direction produces a complex-valued time sequence that is subsequently analyzed using the Discrete Fourier Transform (DFT), typically computed via the Fast Fourier Transform (FFT). Consider a single complex exponential component in the readout that does not align exactly with a DFT frequency bin, a situation that leads to the picket-fence effect and spectral leakage due to the implicit rectangular window from finite-length sampling.\n\nLet the sampled signal be\n$$\nx[n] = A\\,\\exp\\!\\left(j\\,2\\pi\\,\\frac{k_{0}+\\delta}{N}\\,n\\right), \\quad n = 0,1,\\dots,N-1,\n$$\nwhere $A \\in \\mathbb{C}$ is a constant amplitude, $N \\in \\mathbb{N}$ is the DFT length, $k_{0} \\in \\mathbb{Z}$ is an integer identifying the nearest DFT bin to the tone, and $\\delta \\in (0,\\,\\tfrac{1}{2})$ is a fractional offset indicating that the toneâ€™s frequency is between bins. The DFT is defined by\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n]\\,\\exp\\!\\left(-j\\,2\\pi\\,\\frac{k}{N}\\,n\\right), \\quad k = 0,1,\\dots,N-1.\n$$\n\nStarting from the DFT definition and fundamental properties of geometric series and complex exponentials, derive a closed-form expression for $X[k]$ in terms of $A$, $N$, $k$, $k_{0}$, and $\\delta$. Then, use your result to quantify spectral leakage into the adjacent bin by deriving the power ratio\n$$\nR(\\delta, N) = \\frac{|X[k_{0}+1]|^{2}}{|X[k_{0}]|^{2}}.\n$$\n\nExpress your final answer as a single closed-form analytic expression in terms of $\\delta$ and $N$. No numerical evaluation or rounding is required. The answer must be a single expression, not an inequality or equation to be solved.", "solution": "The signal is\n$$\nx[n] = A\\,\\exp\\!\\left(j\\,2\\pi\\,\\frac{k_{0}+\\delta}{N}\\,n\\right),\n$$\nand the Discrete Fourier Transform (DFT) is\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n]\\,\\exp\\!\\left(-j\\,2\\pi\\,\\frac{k}{N}\\,n\\right).\n$$\nSubstituting $x[n]$ into the DFT definition gives\n$$\nX[k] = A \\sum_{n=0}^{N-1} \\exp\\!\\left(j\\,2\\pi\\,\\frac{k_{0}+\\delta - k}{N}\\,n\\right).\n$$\nDefine\n$$\n\\alpha \\triangleq k_{0} + \\delta - k,\n$$\nso that\n$$\nX[k] = A \\sum_{n=0}^{N-1} \\left(\\exp\\!\\left(j\\,2\\pi\\,\\frac{\\alpha}{N}\\right)\\right)^{n}.\n$$\nThis is a finite geometric series with ratio $r = \\exp\\!\\left(j\\,2\\pi\\,\\frac{\\alpha}{N}\\right)$, hence\n$$\n\\sum_{n=0}^{N-1} r^{n} = \\frac{1 - r^{N}}{1 - r} = \\frac{1 - \\exp\\!\\left(j\\,2\\pi\\,\\alpha\\right)}{1 - \\exp\\!\\left(j\\,2\\pi\\,\\frac{\\alpha}{N}\\right)}.\n$$\nTo obtain a form that reveals the magnitude behavior, use the identity\n$$\n1 - \\exp(j\\theta) = \\exp\\!\\left(j\\frac{\\theta}{2}\\right)\\left(\\exp\\!\\left(-j\\frac{\\theta}{2}\\right) - \\exp\\!\\left(j\\frac{\\theta}{2}\\right)\\right) = -2j\\,\\exp\\!\\left(j\\frac{\\theta}{2}\\right)\\sin\\!\\left(\\frac{\\theta}{2}\\right).\n$$\nApplying this to numerator and denominator with $\\theta = 2\\pi\\alpha$ and $\\theta = 2\\pi\\frac{\\alpha}{N}$ yields\n$$\n\\frac{1 - \\exp\\!\\left(j\\,2\\pi\\,\\alpha\\right)}{1 - \\exp\\!\\left(j\\,2\\pi\\,\\frac{\\alpha}{N}\\right)}\n= \\frac{-2j\\,\\exp\\!\\left(j\\,\\pi\\,\\alpha\\right)\\,\\sin\\!\\left(\\pi\\alpha\\right)}{-2j\\,\\exp\\!\\left(j\\,\\pi\\,\\frac{\\alpha}{N}\\right)\\,\\sin\\!\\left(\\frac{\\pi\\alpha}{N}\\right)}\n= \\exp\\!\\left(j\\,\\pi\\,\\alpha\\left(1 - \\frac{1}{N}\\right)\\right)\\,\\frac{\\sin\\!\\left(\\pi\\alpha\\right)}{\\sin\\!\\left(\\frac{\\pi\\alpha}{N}\\right)}.\n$$\nTherefore,\n$$\nX[k] = A\\,\\exp\\!\\left(j\\,\\pi\\,\\alpha\\,\\frac{N-1}{N}\\right)\\,\\frac{\\sin\\!\\left(\\pi\\alpha\\right)}{\\sin\\!\\left(\\frac{\\pi\\alpha}{N}\\right)}.\n$$\nThe magnitude of $X[k]$ is\n$$\n|X[k]| = |A|\\,\\left|\\frac{\\sin\\!\\left(\\pi\\alpha\\right)}{\\sin\\!\\left(\\frac{\\pi\\alpha}{N}\\right)}\\right|.\n$$\nWe now evaluate $|X[k]|$ at the main bin $k = k_{0}$ and the adjacent higher bin $k = k_{0}+1$.\n\nFor $k = k_{0}$, we have $\\alpha = k_{0} + \\delta - k_{0} = \\delta$, hence\n$$\n|X[k_{0}]| = |A|\\,\\left|\\frac{\\sin\\!\\left(\\pi\\delta\\right)}{\\sin\\!\\left(\\frac{\\pi\\delta}{N}\\right)}\\right|.\n$$\nFor $k = k_{0}+1$, we have $\\alpha = k_{0} + \\delta - (k_{0}+1) = \\delta - 1$, hence\n$$\n|X[k_{0}+1]|\n= |A|\\,\\left|\\frac{\\sin\\!\\left(\\pi(\\delta - 1)\\right)}{\\sin\\!\\left(\\frac{\\pi(\\delta - 1)}{N}\\right)}\\right|.\n$$\nUsing $\\sin(\\pi(\\delta - 1)) = \\sin(\\pi\\delta - \\pi) = -\\sin(\\pi\\delta)$ and $\\sin\\!\\left(\\frac{\\pi(\\delta - 1)}{N}\\right) = -\\sin\\!\\left(\\frac{\\pi(1 - \\delta)}{N}\\right)$, we obtain\n$$\n|X[k_{0}+1]| = |A|\\,\\frac{|\\sin(\\pi\\delta)|}{\\left|\\sin\\!\\left(\\frac{\\pi(1 - \\delta)}{N}\\right)\\right|}.\n$$\nThe desired power leakage ratio into the adjacent bin is\n$$\nR(\\delta, N) = \\frac{|X[k_{0}+1]|^{2}}{|X[k_{0}]|^{2}}\n= \\frac{|A|^{2}\\,\\dfrac{|\\sin(\\pi\\delta)|^{2}}{\\left|\\sin\\!\\left(\\dfrac{\\pi(1 - \\delta)}{N}\\right)\\right|^{2}}}{|A|^{2}\\,\\dfrac{|\\sin(\\pi\\delta)|^{2}}{\\left|\\sin\\!\\left(\\dfrac{\\pi\\delta}{N}\\right)\\right|^{2}}}\n= \\frac{\\left|\\sin\\!\\left(\\dfrac{\\pi\\delta}{N}\\right)\\right|^{2}}{\\left|\\sin\\!\\left(\\dfrac{\\pi(1 - \\delta)}{N}\\right)\\right|^{2}}.\n$$\nBecause $\\delta \\in (0, \\tfrac{1}{2})$ and $N \\in \\mathbb{N}$, the arguments of the sine functions are in $(0, \\tfrac{\\pi}{2})$, so the absolute values can be dropped without changing the result:\n$$\nR(\\delta, N) = \\left(\\frac{\\sin\\!\\left(\\dfrac{\\pi\\delta}{N}\\right)}{\\sin\\!\\left(\\dfrac{\\pi(1 - \\delta)}{N}\\right)}\\right)^{2}.\n$$\nThis closed-form expression quantifies the spectral leakage into the adjacent bin due to the picket-fence effect in terms of the fractional offset $\\delta$ and transform length $N$.", "answer": "$$\\boxed{\\left(\\frac{\\sin\\!\\left(\\dfrac{\\pi\\delta}{N}\\right)}{\\sin\\!\\left(\\dfrac{\\pi(1-\\delta)}{N}\\right)}\\right)^{2}}$$", "id": "4920820"}, {"introduction": "In any real-world data acquisition system, the timing of each sample is subject to small, random fluctuations known as jitter. While seemingly minor, this imperfection can have a significant impact on signal quality, especially at high frequencies. This exercise [@problem_id:4920799] guides you through a first-principles derivation to quantify how timing jitter attenuates the coherent signal component in the DFT, ultimately degrading the signal-to-noise ratio ($SNR$). Mastering this analysis connects abstract sampling theory to the tangible limitations of physical hardware.", "problem": "A data acquisition chain in Magnetic Resonance Imaging (MRI) samples a complex sinusoidal readout signal modeled as $s(t) = A \\exp(i 2\\pi f t)$, where $A$ is a real amplitude and $f$ is the sinusoid frequency. The samples are taken at nominal times $t_{n} = n T_{s}$, $n = 0, 1, \\dots, N-1$, with sampling period $T_{s}$, but the actual sampling instants suffer independent Gaussian timing jitter so that the true sampling times are $t_{n}^{\\text{true}} = n T_{s} + \\delta t_{n}$. The jitter terms $\\delta t_{n}$ are independent and identically distributed zero-mean Gaussian random variables with variance $\\sigma_{t}^{2}$. The measured samples are further corrupted by independent additive measurement noise $w_{n}$ with zero mean and variance $\\sigma_{w}^{2}$, independent of $\\delta t_{n}$ and of the signal. A Discrete Fourier Transform (DFT) is computed at the bin corresponding to frequency $f$, and the Fast Fourier Transform (FFT) is used only as a computational method to evaluate this DFT.\n\nUsing the core definitions of the DFT, Gaussian random variables, and the signal-to-noise ratio (SNR) defined as the ratio of the expected squared magnitude of the coherent signal contribution at the DFT bin to the expected noise power in that bin, derive a closed-form expression, in terms of $f$ and $\\sigma_{t}$ only, for the multiplicative factor by which timing jitter changes the SNR relative to the ideal case of zero jitter. Your derivation must start from first principles and clearly state the assumptions and approximations. Provide your final answer as a single analytical expression with no units. No numerical evaluation is required.", "solution": "The core of the problem is to compare the Signal-to-Noise Ratio (SNR) in two scenarios: the ideal case with no timing jitter ($\\sigma_t = 0$) and the realistic case with timing jitter. The problem's definition of SNR is \"the ratio of the expected squared magnitude of the coherent signal contribution at the DFT bin to the expected noise power in that bin\". A critical step is interpreting \"expected noise power\". The constraint that the final expression depends only on $f$ and $\\sigma_t$ implies that \"noise power\" in this context refers only to the power of the additive measurement noise component $w_n$, not the additional variance introduced by the jitter itself. We will proceed with this interpretation, which treats jitter as a source of signal distortion rather than a component of the noise term in the SNR definition.\n\nLet the measured signal be $y_n$. In the presence of both jitter and additive noise, the sample at the actual time $t_{n}^{\\text{true}} = nT_s + \\delta t_n$ is:\n$$ y_n = s(t_n^{\\text{true}}) + w_n = A \\exp(i 2\\pi f (nT_s + \\delta t_n)) + w_n $$\nThe Discrete Fourier Transform (DFT) is defined as $Y[k] = \\sum_{n=0}^{N-1} y_n \\exp(-i 2\\pi \\frac{kn}{N})$. The problem specifies that we evaluate the DFT at the bin corresponding to the signal's own frequency, $f$. The frequency of the $k$-th DFT bin is $f_k = k/(NT_s)$. We therefore are interested in the bin $k_f$ such that $f_{k_f} = f$, which implies $k_f = fNT_s$. The DFT output at this specific frequency is:\n$$ Y[k_f] = \\sum_{n=0}^{N-1} y_n \\exp(-i 2\\pi f n T_s) $$\nSubstituting the expression for $y_n$:\n$$ Y[k_f] = \\sum_{n=0}^{N-1} \\left( A \\exp(i 2\\pi f (nT_s + \\delta t_n)) + w_n \\right) \\exp(-i 2\\pi f n T_s) $$\n$$ Y[k_f] = \\sum_{n=0}^{N-1} A \\exp(i 2\\pi f nT_s) \\exp(i 2\\pi f \\delta t_n) \\exp(-i 2\\pi f n T_s) + \\sum_{n=0}^{N-1} w_n \\exp(-i 2\\pi f n T_s) $$\nThis simplifies to:\n$$ Y[k_f] = A \\sum_{n=0}^{N-1} \\exp(i 2\\pi f \\delta t_n) + \\sum_{n=0}^{N-1} w_n \\exp(-i 2\\pi f n T_s) $$\nLet's denote the signal component of the DFT as $S_{\\text{jitter}}$ and the noise component as $W$:\n$$ S_{\\text{jitter}} = A \\sum_{n=0}^{N-1} \\exp(i 2\\pi f \\delta t_n) \\quad , \\quad W = \\sum_{n=0}^{N-1} w_n \\exp(-i 2\\pi f n T_s) $$\nSo, $Y[k_f] = S_{\\text{jitter}} + W$.\n\n### SNR in the Ideal Case (No Jitter)\n\nIn the ideal case, there is no timing jitter, so $\\delta t_n = 0$ for all $n$. The signal component of the DFT becomes deterministic:\n$$ S_{\\text{ideal}} = A \\sum_{n=0}^{N-1} \\exp(i 2\\pi f \\cdot 0) = A \\sum_{n=0}^{N-1} 1 = NA $$\nThe coherent signal contribution is $\\mathbb{E}[S_{\\text{ideal}}] = NA$, and its squared magnitude is $|NA|^2 = N^2 A^2$.\nThe expected noise power is the variance of the noise component $W$. Since the $w_n$ are i.i.d. with $\\mathbb{E}[w_n]=0$ and $\\mathbb{E}[w_n w_m^*] = \\sigma_w^2 \\delta_{nm}$ (where $\\delta_{nm}$ is the Kronecker delta and we assume complex circular noise, a standard model):\n$$ \\mathbb{E}[|W|^2] = \\mathbb{E}\\left[ \\left(\\sum_{n=0}^{N-1} w_n \\phi_n\\right) \\left(\\sum_{m=0}^{N-1} w_m^* \\phi_m^*\\right) \\right] \\quad \\text{where } \\phi_n = \\exp(-i 2\\pi f n T_s) $$\n$$ \\mathbb{E}[|W|^2] = \\sum_{n=0}^{N-1} \\sum_{m=0}^{N-1} \\mathbb{E}[w_n w_m^*] \\phi_n \\phi_m^* = \\sum_{n=0}^{N-1} \\sum_{m=0}^{N-1} \\sigma_w^2 \\delta_{nm} \\phi_n \\phi_m^* = \\sum_{n=0}^{N-1} \\sigma_w^2 |\\phi_n|^2 $$\nSince $|\\phi_n|^2 = |\\exp(-i 2\\pi f n T_s)|^2 = 1$, the noise power is:\n$$ \\mathbb{E}[|W|^2] = \\sum_{n=0}^{N-1} \\sigma_w^2 = N \\sigma_w^2 $$\nThe SNR for the ideal case is:\n$$ \\text{SNR}_{\\text{ideal}} = \\frac{| \\mathbb{E}[S_{\\text{ideal}}] |^2}{\\mathbb{E}[|W|^2]} = \\frac{N^2 A^2}{N \\sigma_w^2} = \\frac{NA^2}{\\sigma_w^2} $$\n\n### SNR in the Jittery Case\n\nNow we consider the case with timing jitter. The numerator of the SNR is the squared magnitude of the coherent signal contribution, $|\\mathbb{E}[Y[k_f]]|^2$. Since $\\mathbb{E}[W]=0$ and $W$ is independent of $S_{\\text{jitter}}$, $\\mathbb{E}[Y[k_f]] = \\mathbb{E}[S_{\\text{jitter}}]$.\n$$ \\mathbb{E}[S_{\\text{jitter}}] = \\mathbb{E}\\left[ A \\sum_{n=0}^{N-1} \\exp(i 2\\pi f \\delta t_n) \\right] = A \\sum_{n=0}^{N-1} \\mathbb{E}[\\exp(i 2\\pi f \\delta t_n)] $$\nThe expectation $\\mathbb{E}[\\exp(i u X)]$ is the characteristic function of the random variable $X$. For a Gaussian random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, the characteristic function is $\\phi_X(u) = \\exp(i u \\mu - \\frac{1}{2} u^2 \\sigma^2)$. Here, our random variable is $\\delta t_n \\sim \\mathcal{N}(0, \\sigma_t^2)$, and we evaluate the characteristic function at $u = 2\\pi f$.\n$$ \\mathbb{E}[\\exp(i 2\\pi f \\delta t_n)] = \\exp\\left(i (2\\pi f) \\cdot 0 - \\frac{1}{2} (2\\pi f)^2 \\sigma_t^2\\right) = \\exp(-2 \\pi^2 f^2 \\sigma_t^2) $$\nSince the jitter terms $\\delta t_n$ are i.i.d., this expectation is the same for all $n$. Therefore, the coherent signal is:\n$$ \\mathbb{E}[S_{\\text{jitter}}] = A \\sum_{n=0}^{N-1} \\exp(-2 \\pi^2 f^2 \\sigma_t^2) = NA \\exp(-2 \\pi^2 f^2 \\sigma_t^2) $$\nThe squared magnitude of the coherent signal contribution is:\n$$ |\\mathbb{E}[S_{\\text{jitter}}]|^2 = |NA \\exp(-2 \\pi^2 f^2 \\sigma_t^2)|^2 = N^2 A^2 \\exp(-4 \\pi^2 f^2 \\sigma_t^2) $$\nThe denominator of the SNR is the expected noise power in the bin. As established, we interpret this as solely the contribution from the additive noise $w_n$. The statistical properties of $w_n$ are independent of the jitter, so the expected power of its DFT component remains unchanged:\n$$ \\mathbb{E}[|W|^2] = N \\sigma_w^2 $$\nThe SNR for the jittery case is therefore:\n$$ \\text{SNR}_{\\text{jitter}} = \\frac{|\\mathbb{E}[S_{\\text{jitter}}]|^2}{\\mathbb{E}[|W|^2]} = \\frac{N^2 A^2 \\exp(-4 \\pi^2 f^2 \\sigma_t^2)}{N \\sigma_w^2} = \\frac{NA^2}{\\sigma_w^2} \\exp(-4 \\pi^2 f^2 \\sigma_t^2) $$\n\n### Multiplicative Factor\n\nThe multiplicative factor by which timing jitter changes the SNR is the ratio $\\text{SNR}_{\\text{jitter}} / \\text{SNR}_{\\text{ideal}}$.\n$$ \\frac{\\text{SNR}_{\\text{jitter}}}{\\text{SNR}_{\\text{ideal}}} = \\frac{\\frac{NA^2}{\\sigma_w^2} \\exp(-4 \\pi^2 f^2 \\sigma_t^2)}{\\frac{NA^2}{\\sigma_w^2}} $$\n$$ \\frac{\\text{SNR}_{\\text{jitter}}}{\\text{SNR}_{\\text{ideal}}} = \\exp(-4 \\pi^2 f^2 \\sigma_t^2) $$\nThis expression depends only on the signal frequency $f$ and the jitter standard deviation $\\sigma_t$ (via its variance $\\sigma_t^2$), as required by the problem statement. It shows that the SNR is attenuated by a factor that depends exponentially on the square of the product of frequency and jitter standard deviation.", "answer": "$$\\boxed{\\exp(-4 \\pi^{2} f^{2} \\sigma_{t}^{2})}$$", "id": "4920799"}]}