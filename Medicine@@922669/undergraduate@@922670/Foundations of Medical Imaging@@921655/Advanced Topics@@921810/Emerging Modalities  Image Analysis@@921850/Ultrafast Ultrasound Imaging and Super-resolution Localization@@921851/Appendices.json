{"hands_on_practices": [{"introduction": "Ultrafast imaging often relies on transmitting steered plane waves to insonify a large field of view at very high frame rates. This practice delves into the fundamental wave physics of linear array transducers, exploring how the physical spacing of transducer elements can give rise to imaging artifacts known as grating lobes. By deriving the conditions for grating lobe formation [@problem_id:4939171], you will gain a crucial understanding of the engineering constraints that govern transducer design and ensure artifact-free imaging across a desired range of steering angles.", "problem": "An idealized one-dimensional linear ultrasound array aligned along the $x$-axis transmits a plane wave in a homogeneous medium of speed of sound $c$ using uniform amplitude excitation and a linear phase progression to steer the transmit wavefront by an angle $\\theta_{0}$ relative to the array normal (the $z$-axis). Let the element pitch (center-to-center spacing) be $d$, the operating wavelength be $\\lambda$, and the wavenumber be $k = 2 \\pi / \\lambda$. Consider the far-field response formed by the coherent superposition of monochromatic contributions from all elements.\n\nStarting only from the following foundational principles:\n- Superposition of complex exponentials for coherent waves.\n- The far-field phase from an element at position $x_{n} = n d$ toward an observation angle $\\theta$ relative to the array normal is $k x_{n} \\sin \\theta$.\n- A linear transmit steering phase progression produces a constant phase increment $\\psi$ between adjacent elements.\n- Constructive interference between adjacent elements occurs when the phase increment between their contributions equals $2 \\pi m$ for some integer $m$,\n\nperform the steps below.\n\n1) Derive the angular locations $\\theta$ of all principal maxima (including the main lobe and any grating lobes) as a function of $\\theta_{0}$, $d$, and $\\lambda$.\n\n2) From your result, obtain a closed-form inequality on $d / \\lambda$ that guarantees no visible grating lobes (that is, no maxima other than the main lobe) for any steering angle satisfying $|\\theta_{0}| \\leq \\theta_{\\max}$, where an angular maximum is considered visible if its sine argument magnitude is $\\leq 1$. Simplify this to a single closed-form expression for the maximum allowable pitch $d_{\\max}$ in terms of $\\lambda$ and $\\theta_{\\max}$.\n\n3) Using your expression, compute $d_{\\max}$ for ultrafast plane-wave ultrasound imaging with center frequency $f_{0} = 7.5$ MHz, speed of sound $c = 1540$ m/s, and a symmetric steering range $|\\theta_{0}| \\leq \\theta_{\\max} = 20$ degrees. Express your final numerical answer in millimeters (mm) and round to four significant figures. Use degrees for all angles in any trigonometric functions when evaluating numerically.\n\nYour final response should be a single number: the value of $d_{\\max}$ in mm, rounded to four significant figures.", "solution": "The problem is validated as scientifically grounded, well-posed, objective, and complete. All provided principles and data are standard in the field of wave physics and medical imaging. The derivation proceeds in three steps as requested.\n\n### Part 1: Derivation of the Angular Locations of Principal Maxima\n\nThe problem requires deriving the locations of far-field maxima starting from foundational principles. Let the one-dimensional linear array be aligned along the $x$-axis. An element at position $x_n = n d$ is excited with a phase $\\phi_{\\text{steer}}(n)$, where $n$ is an integer indexing the element and $d$ is the pitch. The problem states a linear phase progression, so the phase increment $\\psi$ between adjacent elements is constant. The phase of the $n$-th element is thus $\\phi_{\\text{steer}}(n) = n\\psi$.\n\nThe beam is to be steered to an angle $\\theta_0$. This means that in the direction $\\theta_0$, waves from all elements must interfere constructively. The far-field phase contribution due to the path length from an element at $x_n$ to an observer at angle $\\theta$ is given as $\\phi_{\\text{geom}}(n, \\theta) = k x_n \\sin\\theta = k n d \\sin\\theta$, where $k = 2\\pi/\\lambda$ is the wavenumber.\n\nFor the main beam to form at $\\theta_0$, the total phase difference between adjacent elements in this direction must be zero. The total phase difference is the sum of the applied electronic phase difference and the geometric phase difference.\n$$ \\Delta\\Phi(\\theta_0) = \\psi + \\Delta\\phi_{\\text{geom}}(\\theta_0) = 0 $$\nThe geometric phase difference between adjacent elements is $\\Delta\\phi_{\\text{geom}}(\\theta_0) = k(x_{n+1} - x_n)\\sin\\theta_0 = k d \\sin\\theta_0$.\nThus, to steer the beam to $\\theta_0$, the applied phase increment must be:\n$$ \\psi = -k d \\sin\\theta_0 $$\nNow, consider the total phase from element $n$ in an arbitrary observation direction $\\theta$. It is the sum of the steering phase and the geometric phase:\n$$ \\Phi_n(\\theta) = \\phi_{\\text{steer}}(n) + \\phi_{\\text{geom}}(n, \\theta) = n\\psi + k n d \\sin\\theta $$\nSubstituting the expression for $\\psi$:\n$$ \\Phi_n(\\theta) = n(-k d \\sin\\theta_0) + k n d \\sin\\theta = n k d (\\sin\\theta - \\sin\\theta_0) $$\nThe phase difference between adjacent elements in the direction $\\theta$ is:\n$$ \\Delta\\Phi(\\theta) = \\Phi_{n+1}(\\theta) - \\Phi_n(\\theta) = (n+1) k d (\\sin\\theta - \\sin\\theta_0) - n k d (\\sin\\theta - \\sin\\theta_0) = k d (\\sin\\theta - \\sin\\theta_0) $$\nAccording to the principle of constructive interference, principal maxima (the main lobe and grating lobes) occur when this phase difference is an integer multiple of $2\\pi$.\n$$ \\Delta\\Phi(\\theta) = 2\\pi m, \\quad \\text{for integer } m $$\nSubstituting the expression for $\\Delta\\Phi(\\theta)$ and $k=2\\pi/\\lambda$:\n$$ \\frac{2\\pi}{\\lambda} d (\\sin\\theta - \\sin\\theta_0) = 2\\pi m $$\nDividing by $2\\pi$ and rearranging gives the locations of the principal maxima:\n$$ \\sin\\theta - \\sin\\theta_0 = m \\frac{\\lambda}{d} $$\n$$ \\sin\\theta = \\sin\\theta_0 + m \\frac{\\lambda}{d} $$\nThe integer $m=0$ corresponds to the main lobe at $\\theta = \\theta_0$. Integers $m \\neq 0$ correspond to grating lobes.\n\n### Part 2: Derivation of the Maximum Allowable Pitch $d_{\\max}$\n\nA grating lobe is \"visible\" if its angular location $\\theta$ is real, which corresponds to the condition $|\\sin\\theta| \\leq 1$. To guarantee no visible grating lobes, we must ensure that for all non-zero integers $m$, $|\\sin\\theta| > 1$.\n$$ \\left| \\sin\\theta_0 + m \\frac{\\lambda}{d} \\right| > 1, \\quad \\text{for } m = \\pm 1, \\pm 2, \\dots $$\nThe grating lobes closest to the main lobe occur for $m=1$ and $m=-1$. If we can make these invisible, all other grating lobes with $|m|>1$ will also be invisible.\n\nThe condition must hold for any steering angle in the range $|\\theta_0| \\leq \\theta_{\\max}$, which means $\\sin\\theta_0$ is in the range $[-\\sin\\theta_{\\max}, \\sin\\theta_{\\max}]$. We must find the \"worst-case\" scenario that is most likely to produce a visible grating lobe and prevent it.\n\nFor $m=1$: We require $\\sin\\theta_0 + \\frac{\\lambda}{d} > 1$.\nThis must hold for all $\\theta_0 \\in [-\\theta_{\\max}, \\theta_{\\max}]$. The left side is minimized when $\\sin\\theta_0$ is at its minimum, which is $-\\sin\\theta_{\\max}$. So, we must satisfy:\n$$ -\\sin\\theta_{\\max} + \\frac{\\lambda}{d} > 1 \\implies \\frac{\\lambda}{d} > 1 + \\sin\\theta_{\\max} $$\nFor $m=-1$: We require $\\sin\\theta_0 - \\frac{\\lambda}{d} < -1$.\nThis must hold for all $\\theta_0 \\in [-\\theta_{\\max}, \\theta_{\\max}]$. The left side is maximized when $\\sin\\theta_0$ is at its maximum, which is $\\sin\\theta_{\\max}$. So, we must satisfy:\n$$ \\sin\\theta_{\\max} - \\frac{\\lambda}{d} < -1 \\implies \\frac{\\lambda}{d} > 1 + \\sin\\theta_{\\max} $$\nBoth cases yield the same condition. Therefore, to avoid visible grating lobes for any steering angle up to $\\theta_{\\max}$, the pitch $d$ must satisfy:\n$$ \\frac{\\lambda}{d} > 1 + \\sin\\theta_{\\max} $$\nInverting this gives the inequality on $d/\\lambda$:\n$$ \\frac{d}{\\lambda} < \\frac{1}{1 + \\sin\\theta_{\\max}} $$\nThe maximum allowable pitch, $d_{\\max}$, is the value that makes this an equality. Any pitch larger than this value would violate the condition.\n$$ d_{\\max} = \\frac{\\lambda}{1 + \\sin\\theta_{\\max}} $$\n\n### Part 3: Calculation of $d_{\\max}$\n\nWe are given the following parameters:\n- Center frequency, $f_0 = 7.5 \\, \\text{MHz} = 7.5 \\times 10^6 \\, \\text{Hz}$.\n- Speed of sound in the medium, $c = 1540 \\, \\text{m/s}$.\n- Maximum steering angle, $\\theta_{\\max} = 20^{\\circ}$.\n\nFirst, we calculate the wavelength $\\lambda$ using the relation $c = f_0 \\lambda$:\n$$ \\lambda = \\frac{c}{f_0} = \\frac{1540 \\, \\text{m/s}}{7.5 \\times 10^6 \\, \\text{s}^{-1}} \\approx 2.05333 \\times 10^{-4} \\, \\text{m} $$\nNext, we evaluate $\\sin\\theta_{\\max}$:\n$$ \\sin\\theta_{\\max} = \\sin(20^{\\circ}) \\approx 0.342020 $$\nNow, we substitute these values into the expression for $d_{\\max}$:\n$$ d_{\\max} = \\frac{\\lambda}{1 + \\sin\\theta_{\\max}} \\approx \\frac{2.05333 \\times 10^{-4} \\, \\text{m}}{1 + 0.342020} \\approx \\frac{2.05333 \\times 10^{-4} \\, \\text{m}}{1.342020} $$\n$$ d_{\\max} \\approx 1.53002 \\times 10^{-4} \\, \\text{m} $$\nThe problem asks for the answer in millimeters (mm). Since $1 \\, \\text{m} = 1000 \\, \\text{mm}$, we have:\n$$ d_{\\max} \\approx 1.53002 \\times 10^{-4} \\times 10^3 \\, \\text{mm} \\approx 0.153002 \\, \\text{mm} $$\nRounding to four significant figures, we get:\n$$ d_{\\max} \\approx 0.1530 \\, \\text{mm} $$", "answer": "$$\n\\boxed{0.1530}\n$$", "id": "4939171"}, {"introduction": "A critical challenge in microbubble-based super-resolution is distinguishing the faint, transient echoes from individual bubbles from the overwhelmingly strong and slow-changing signals from surrounding tissue. This hands-on coding exercise [@problem_id:4939195] introduces a powerful signal processing technique to solve this problem by modeling the distinct statistical properties of tissue and bubble signals. You will learn to analyze their power spectral densities and design a temporal filter to effectively isolate the bubble events, a cornerstone of any super-resolution localization pipeline.", "problem": "You are given a simplified temporal model for ultrafast ultrasound imaging with microbubble contrast agents, aimed at super-resolution localization. The goal is to suppress slowly varying tissue echoes while preserving stochastic microbubble events by designing a temporal high-pass filter and computing an appropriate cutoff frequency that separates the dominant spectral content of tissue and bubbles.\n\nAssume the following signal models in continuous time. The tissue echo is modeled as a stationary Gaussian process with exponential autocorrelation $$R_{t}(\\tau) = \\sigma_{t}^{2} e^{-|\\tau|/\\tau_{t}},$$ where $\\sigma_{t}$ is the tissue amplitude standard deviation and $\\tau_{t}$ is the tissue correlation time. A stochastic microbubble train is modeled as a Poisson shot-noise process with rate $\\lambda$ and deterministic pulse shape $$h(t) = A_{b} e^{-t/\\tau_{b}} u(t),$$ where $A_{b}$ is the bubble pulse amplitude, $\\tau_{b}$ is the bubble decay time, and $u(t)$ is the unit step function.\n\nUse the standard relationships between autocorrelation and Power Spectral Density (PSD), and between shot-noise and PSD, to derive PSD expressions for tissue and bubble components as functions of temporal frequency $f$ measured in Hertz. Let the sampling frequency be $f_{s}$ (in Hz), so the Nyquist frequency is $f_{N} = f_{s}/2$. Define the spectral density ratio $$\\mathrm{SDR}(f) = \\frac{S_{b}(f)}{S_{t}(f)},$$ where $S_{b}(f)$ and $S_{t}(f)$ are the PSDs of bubble and tissue respectively.\n\nDesign a temporal high-pass filter whose cutoff frequency $f_{c}$ (in Hz) is chosen by the following criterion:\n- Find the smallest $f$ (with $0 \\le f \\le f_{N}$) such that $\\mathrm{SDR}(f) \\ge \\gamma$, where $\\gamma$ is a specified positive threshold.\n- If $\\mathrm{SDR}(f)$ is already $\\ge \\gamma$ at $f = 0$, set $f_{c} = 0$.\n- If $\\mathrm{SDR}(f)$ never reaches $\\gamma$ within $[0, f_{N}]$, set $f_{c} = f_{N}$.\n\nThen, with this $f_{c}$, one may choose any stable, causal high-pass filter (for instance, a fourth-order Butterworth) with cutoff at $f_{c}$ for practical implementation; however, for this task you only need to compute $f_{c}$ in Hz.\n\nImplement a program that, for each test case, computes $f_{c}$ according to the above criterion and prints the cutoff frequencies. Express each cutoff frequency in Hz, rounded to three decimals.\n\nUse the following test suite, where each tuple is $(f_{s}, \\sigma_{t}, \\tau_{t}, A_{b}, \\tau_{b}, \\lambda, \\gamma)$:\n- Case A (typical \"happy path\"): $(2000, 1.0, 0.05, 1.0, 0.001, 200.0, 2.0)$\n- Case B (threshold already met at zero frequency): $(2000, 1.0, 0.05, 1.0, 0.001, 200.0, 0.001)$\n- Case C (threshold unattainable within the band): $(2000, 1.0, 0.05, 1.0, 0.001, 200.0, 10.0)$\n- Case D (different parameter regime): $(5000, 0.5, 0.08, 0.8, 0.0008, 150.0, 8.0)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[$f_{c}^{(A)},$ $f_{c}^{(B)},$ $f_{c}^{(C)},$ $f_{c}^{(D)}]\"), where each entry is in Hz rounded to three decimals.", "solution": "The problem is deemed valid as it is scientifically grounded, well-posed, and objective. It is based on standard, albeit simplified, models from signal processing and medical imaging, and its parameters are clearly defined, leading to a unique and meaningful solution. We may therefore proceed with the derivation and computation.\n\nThe objective is to compute a cutoff frequency, $f_c$, for a temporal high-pass filter. This frequency is determined by the point at which the Power Spectral Density (PSD) of the desired microbubble signal, $S_b(f)$, sufficiently exceeds the PSD of the undesired tissue signal, $S_t(f)$. The criterion is based on their ratio, $\\mathrm{SDR}(f) = S_b(f) / S_t(f)$.\n\nFirst, we must derive the analytical expressions for the PSD of the tissue and microbubble components. The frequency variable is denoted by $f$, measured in Hertz (Hz).\n\n1. Tissue Power Spectral Density, $S_t(f)$\n\nThe tissue signal is modeled as a stationary Gaussian process with an exponential autocorrelation function given by:\n$$R_t(\\tau) = \\sigma_t^2 e^{-|\\tau|/\\tau_t}$$\nwhere $\\sigma_t$ is the amplitude standard deviation and $\\tau_t$ is the correlation time. The PSD, $S_t(f)$, is the Fourier transform of the autocorrelation function, $R_t(\\tau)$, according to the Wiener-Khinchin theorem. We use the standard Fourier transform pair:\n$$\\mathcal{F}\\{e^{-a|\\tau|}\\}(f) = \\frac{2a}{a^2 + (2\\pi f)^2}$$\nBy setting the parameter $a = 1/\\tau_t$, we obtain the PSD for the tissue component:\n$$S_t(f) = \\sigma_t^2 \\mathcal{F}\\{e^{-|\\tau|/\\tau_t}\\}(f) = \\sigma_t^2 \\frac{2/\\tau_t}{(1/\\tau_t)^2 + (2\\pi f)^2}$$\nMultiplying the numerator and denominator by $\\tau_t^2$ simplifies this to:\n$$S_t(f) = \\frac{2\\sigma_t^2\\tau_t}{1 + (2\\pi f \\tau_t)^2}$$\nThis is a Lorentzian function, characteristic of exponentially correlated noise, which has its maximum power at $f=0$ and decays as $f$ increases, consistent with a low-pass characteristic.\n\n2. Microbubble Power Spectral Density, $S_b(f)$\n\nThe microbubble signal is modeled as a Poisson shot-noise process. The PSD of such a process is given by a standard result from stochastic process theory (related to Campbell's and Carson's theorems):\n$$S_b(f) = \\lambda |H(f)|^2$$\nwhere $\\lambda$ is the average rate of event occurrences (the Poisson rate) and $H(f)$ is the Fourier transform of the individual pulse shape, $h(t)$. The pulse shape is given by a decaying exponential:\n$$h(t) = A_b e^{-t/\\tau_b} u(t)$$\nwhere $A_b$ is the pulse amplitude, $\\tau_b$ is the decay time, and $u(t)$ is the Heaviside unit step function. We compute its Fourier transform, $H(f) = \\mathcal{F}\\{h(t)\\}$:\n$$H(f) = \\int_{-\\infty}^{\\infty} A_b e^{-t/\\tau_b} u(t) e^{-i 2\\pi f t} dt = A_b \\int_{0}^{\\infty} e^{-t(1/\\tau_b + i 2\\pi f)} dt$$\n$$H(f) = A_b \\left[ \\frac{e^{-t(1/\\tau_b + i 2\\pi f)}}{-(1/\\tau_b + i 2\\pi f)} \\right]_{0}^{\\infty} = \\frac{A_b}{1/\\tau_b + i 2\\pi f} = \\frac{A_b \\tau_b}{1 + i 2\\pi f \\tau_b}$$\nThe squared magnitude, $|H(f)|^2$, is:\n$$|H(f)|^2 = H(f)H^*(f) = \\left(\\frac{A_b \\tau_b}{1 + i 2\\pi f \\tau_b}\\right) \\left(\\frac{A_b \\tau_b}{1 - i 2\\pi f \\tau_b}\\right) = \\frac{A_b^2 \\tau_b^2}{1 + (2\\pi f \\tau_b)^2}$$\nSubstituting this into the shot-noise PSD formula gives:\n$$S_b(f) = \\frac{\\lambda A_b^2 \\tau_b^2}{1 + (2\\pi f \\tau_b)^2}$$\nThis PSD also has a low-pass characteristic, but as we expect $\\tau_b \\ll \\tau_t$, its spectral content extends to much higher frequencies than the tissue signal's content.\n\n3. Spectral Density Ratio, $\\mathrm{SDR}(f)$, and Cutoff Frequency, $f_c$\n\nThe spectral density ratio is defined as:\n$$\\mathrm{SDR}(f) = \\frac{S_b(f)}{S_t(f)} = \\frac{\\frac{\\lambda A_b^2 \\tau_b^2}{1 + (2\\pi f \\tau_b)^2}}{\\frac{2\\sigma_t^2\\tau_t}{1 + (2\\pi f \\tau_t)^2}} = \\left( \\frac{\\lambda A_b^2 \\tau_b^2}{2\\sigma_t^2\\tau_t} \\right) \\frac{1 + (2\\pi f \\tau_t)^2}{1 + (2\\pi f \\tau_b)^2}$$\nLet's define a constant $K = \\frac{\\lambda A_b^2 \\tau_b^2}{2\\sigma_t^2\\tau_t}$. Then $\\mathrm{SDR}(f) = K \\frac{1 + (2\\pi f \\tau_t)^2}{1 + (2\\pi f \\tau_b)^2}$.\nPhysically, tissue echoes are slow phenomena ($\\tau_t$ is large) while microbubbles are fast events ($\\tau_b$ is small), so we expect $\\tau_t > \\tau_b$. Under this condition, the numerator of the frequency-dependent term grows faster with $f$ than the denominator, meaning $\\mathrm{SDR}(f)$ is a monotonically increasing function for $f \\ge 0$.\n\nWe need to find the smallest frequency $f_c$ in the range $[0, f_N]$ (where $f_N = f_s/2$ is the Nyquist frequency) such that $\\mathrm{SDR}(f_c) \\ge \\gamma$.\nThe algorithm is as follows:\n-   First, evaluate $\\mathrm{SDR}(f)$ at $f=0$. $\\mathrm{SDR}(0) = K$. If $K \\ge \\gamma$, then the condition is met at the lowest possible frequency, and we set $f_c = 0$.\n-   Next, evaluate $\\mathrm{SDR}(f)$ at the upper bound of the frequency range, $f=f_N$. If $\\mathrm{SDR}(f_N) < \\gamma$, the condition is never met within the allowed band. In this case, we set $f_c = f_N$.\n-   Otherwise, if $K < \\gamma$ and $\\mathrm{SDR}(f_N) \\ge \\gamma$, the monotonicity of $\\mathrm{SDR}(f)$ guarantees there is a unique solution $f_c \\in (0, f_N)$ where the equality holds. We solve $\\mathrm{SDR}(f_c) = \\gamma$:\n    $$K \\frac{1 + (2\\pi f_c \\tau_t)^2}{1 + (2\\pi f_c \\tau_b)^2} = \\gamma$$\n    $$K(1 + (2\\pi f_c)^2 \\tau_t^2) = \\gamma(1 + (2\\pi f_c)^2 \\tau_b^2)$$\n    $$K + K(2\\pi f_c)^2 \\tau_t^2 = \\gamma + \\gamma(2\\pi f_c)^2 \\tau_b^2$$\n    $$(2\\pi f_c)^2 (K \\tau_t^2 - \\gamma \\tau_b^2) = \\gamma - K$$\n    $$(2\\pi f_c)^2 = \\frac{\\gamma - K}{K \\tau_t^2 - \\gamma \\tau_b^2}$$\n    Solving for $f_c$:\n    $$f_c = \\frac{1}{2\\pi} \\sqrt{\\frac{\\gamma - K}{K \\tau_t^2 - \\gamma \\tau_b^2}}$$\nThis formula is used to compute the cutoff frequency for the cases where the solution lies strictly between $0$ and $f_N$. The provided Python code implements this logic for each test case, calculates the numerical values, and formats them as requested.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_fc(fs, sigma_t, tau_t, A_b, tau_b, lam, gamma):\n    \"\"\"\n    Computes the cutoff frequency f_c based on the derived model.\n    \"\"\"\n    f_nyquist = fs / 2.0\n\n    # Calculate the frequency-independent constant K\n    K = (lam * A_b**2 * tau_b**2) / (2 * sigma_t**2 * tau_t)\n\n    # Case 1: Threshold is met at f = 0\n    # SDR(0) = K\n    if K >= gamma:\n        return 0.0\n\n    # Calculate SDR at the Nyquist frequency\n    term_t_nyquist = (2 * np.pi * f_nyquist * tau_t)**2\n    term_b_nyquist = (2 * np.pi * f_nyquist * tau_b)**2\n    sdr_nyquist = K * (1 + term_t_nyquist) / (1 + term_b_nyquist)\n\n    # Case 2: Threshold is never met within the frequency band\n    if sdr_nyquist  gamma:\n        return f_nyquist\n\n    # Case 3: Threshold is met within (0, f_N), solve for f_c\n    # (2*pi*f_c)^2 = (gamma - K) / (K * tau_t^2 - gamma * tau_b^2)\n    numerator = gamma - K\n    denominator = K * tau_t**2 - gamma * tau_b**2\n\n    # As derived in the theory, for a solution to exist in (0, f_N)\n    # when SDR is monotonic increasing, the denominator must be positive.\n    # This is a safe calculation under the problem's premises.\n    if denominator = 0:\n        # This branch should not be reached if the SDR is monotonic increasing\n        # and SDR(0)  gamma = SDR(f_N). It would imply a mathematical\n        # contradiction or a different regime (e.g. tau_t  tau_b).\n        # We return f_N as the most robust fallback.\n        return f_nyquist\n\n    fc_squared = (1 / (4 * np.pi**2)) * (numerator / denominator)\n    fc = np.sqrt(fc_squared)\n\n    return fc\n\ndef solve():\n    \"\"\"\n    Defines test cases, computes the cutoff frequency for each,\n    and prints the results in the specified format.\n    \"\"\"\n    # Test cases defined as tuples of:\n    # (f_s, sigma_t, tau_t, A_b, tau_b, lambda, gamma)\n    test_cases = [\n        (2000, 1.0, 0.05, 1.0, 0.001, 200.0, 2.0),     # Case A\n        (2000, 1.0, 0.05, 1.0, 0.001, 200.0, 0.001),    # Case B\n        (2000, 1.0, 0.05, 1.0, 0.001, 200.0, 10.0),    # Case C\n        (5000, 0.5, 0.08, 0.8, 0.0008, 150.0, 8.0)     # Case D\n    ]\n\n    results = []\n    for case in test_cases:\n        fs, st, tt, Ab, tb, l, g = case\n        fc = calculate_fc(fs, st, tt, Ab, tb, l, g)\n        results.append(f\"{fc:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "4939195"}, {"introduction": "The final output of a super-resolution algorithm is a map of localized events, but how accurate is this map? This practical exercise [@problem_id:4939224] guides you through the essential process of quantifying the performance of a localization system using fundamental statistical metrics. By implementing estimators for bias and Root Mean Square Error (RMSE) from a series of repeated measurements, you will develop the skills to rigorously assess and validate the accuracy of your imaging results, moving beyond qualitative observation to quantitative analysis.", "problem": "Consider the task of quantifying localization accuracy in ultrafast ultrasound imaging for super-resolution localization of point targets such as microbubbles. A point target located at a true spatial position $\\mathbf{r}_0 = [x_0, z_0]^\\top$ in the imaging plane is repeatedly localized in $N$ ultrafast frames, yielding measured positions $\\mathbf{r}_i = [x_i, z_i]^\\top$ for $i = 1, 2, \\dots, N$. The measurement model is defined by $\\mathbf{r}_i = \\mathbf{r}_0 + \\mathbf{b} + \\boldsymbol{\\varepsilon}_i$, where $\\mathbf{b}$ is an unknown fixed bias vector, and $\\boldsymbol{\\varepsilon}_i$ are independent, identically distributed random errors introduced by the system’s Point Spread Function (PSF), sampling, and noise. The fundamental base comprises the following definitions:\n- The expectation operator $\\mathbb{E}[\\cdot]$ and the sample average over $N$ realizations.\n- The Euclidean norm $\\lVert \\cdot \\rVert_2$ over $\\mathbb{R}^2$.\n- Bias is defined as the expected error vector between the estimator and the true parameter.\n- Root Mean Square Error (RMSE) is defined as the square root of the expected squared error magnitude.\n\nFrom these definitions, derive computable estimators for the bias components along the lateral ($x$) and axial ($z$) directions, and for RMSE along each axis and in the radial sense. Implement these estimators in a program that takes the provided test suite of repeated measurements and true positions and computes the following for each case:\n- The estimated bias components in micrometers along $x$ and $z$: $b_x$ and $b_z$.\n- The estimated RMSE in micrometers along $x$ and $z$: $\\mathrm{RMSE}_x$ and $\\mathrm{RMSE}_z$.\n- The estimated radial RMSE in micrometers: $\\mathrm{RMSE}_{\\mathrm{rad}}$ computed from the two-dimensional error vectors.\n\nExpress all outputs in micrometers and round each reported value to three decimal places. Angles are not involved in this problem. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list in the order $[b_x, b_z, \\mathrm{RMSE}_x, \\mathrm{RMSE}_z, \\mathrm{RMSE}_{\\mathrm{rad}}]$.\n\nUse the following test suite. Each case specifies $\\mathbf{r}_0$ and the list of measured positions $\\{\\mathbf{r}_i\\}_{i=1}^N$, all in micrometers:\n\nCase $1$ (happy path, near-unbiased, isotropic small noise):\n- $\\mathbf{r}_0 = [\\,0,\\,0\\,]$\n- Measurements:\n  $[\\,1.2,\\,-0.8\\,]$, $[\\,-0.5,\\,0.3\\,]$, $[\\,0.9,\\,-0.2\\,]$, $[\\,-1.1,\\,0.7\\,]$, $[\\,0.0,\\,0.0\\,]$, $[\\,0.4,\\,-0.5\\,]$, $[\\,-0.8,\\,0.6\\,]$, $[\\,0.3,\\,-0.1\\,]$, $[\\,-0.2,\\,0.2\\,]$, $[\\,0.1,\\,-0.3\\,]$\n\nCase $2$ (anisotropic noise, lateral spread larger than axial):\n- $\\mathbf{r}_0 = [\\,0,\\,0\\,]$\n- Measurements:\n  $[\\,8.0,\\,1.5\\,]$, $[\\,-9.5,\\,-1.0\\,]$, $[\\,10.2,\\,2.0\\,]$, $[\\,-7.8,\\,-1.8\\,]$, $[\\,0.5,\\,0.2\\,]$, $[\\,5.5,\\,-0.7\\,]$, $[\\,-6.3,\\,1.1\\,]$, $[\\,9.1,\\,-2.2\\,]$, $[\\,-8.9,\\,0.9\\,]$, $[\\,7.7,\\,-0.4\\,]$\n\nCase $3$ (systematic bias due to calibration; nonzero true position):\n- $\\mathbf{r}_0 = [\\,50,\\,-30\\,]$\n- Measurements:\n  $[\\,55.8,\\,-33.2\\,]$, $[\\,54.1,\\,-32.5\\,]$, $[\\,55.0,\\,-33.1\\,]$, $[\\,56.3,\\,-33.4\\,]$, $[\\,55.5,\\,-33.0\\,]$, $[\\,54.7,\\,-32.8\\,]$, $[\\,55.9,\\,-33.6\\,]$, $[\\,55.2,\\,-33.3\\,]$, $[\\,54.9,\\,-32.7\\,]$, $[\\,56.1,\\,-33.5\\,]$\n\nCase $4$ (boundary case: single measurement):\n- $\\mathbf{r}_0 = [\\,-20,\\,40\\,]$\n- Measurements:\n  $[\\,-18,\\,35\\,]$\n\nCase $5$ (edge case: zero noise):\n- $\\mathbf{r}_0 = [\\,100,\\,100\\,]$\n- Measurements:\n  $[\\,100,\\,100\\,]$, $[\\,100,\\,100\\,]$, $[\\,100,\\,100\\,]$, $[\\,100,\\,100\\,]$, $[\\,100,\\,100\\,]$\n\nYour program must compute the requested metrics for each case and output a single line in the format:\n$[\\,[b_{x,1},b_{z,1},\\mathrm{RMSE}_{x,1},\\mathrm{RMSE}_{z,1},\\mathrm{RMSE}_{\\mathrm{rad},1}],\\,[b_{x,2},b_{z,2},\\mathrm{RMSE}_{x,2},\\mathrm{RMSE}_{z,2},\\mathrm{RMSE}_{\\mathrm{rad},2}],\\,\\dots\\,]$\nwhere each numeric entry is expressed in micrometers and rounded to three decimal places.", "solution": "The problem is scientifically and mathematically sound, self-contained, and well-posed. All the necessary information and definitions are provided to derive estimators for the requested statistical quantities and compute their values for the given test cases. We proceed with the solution.\n\nThe core of the problem is to derive computable estimators for bias and Root Mean Square Error (RMSE) from a finite set of $N$ measurements. Let the true position of the point target be a vector $\\mathbf{r}_0 = [x_0, z_0]^\\top$. The $i$-th measured position is $\\mathbf{r}_i = [x_i, z_i]^\\top$, for $i = 1, 2, \\dots, N$.\n\nThe total error for the $i$-th measurement is the vector difference between the measured position and the true position:\n$$ \\mathbf{e}_i = \\mathbf{r}_i - \\mathbf{r}_0 = [x_i - x_0, z_i - z_0]^\\top = [e_{x,i}, e_{z,i}]^\\top $$\nThe problem defines a measurement model $\\mathbf{r}_i = \\mathbf{r}_0 + \\mathbf{b} + \\boldsymbol{\\varepsilon}_i$, where $\\mathbf{b}$ is a fixed bias and $\\boldsymbol{\\varepsilon}_i$ are independent, identically distributed random errors with an expected value of zero, $\\mathbb{E}[\\boldsymbol{\\varepsilon}_i] = \\mathbf{0}$. Therefore, the expected error is $\\mathbb{E}[\\mathbf{e}_i] = \\mathbb{E}[\\mathbf{r}_i - \\mathbf{r}_0] = \\mathbb{E}[\\mathbf{b} + \\boldsymbol{\\varepsilon}_i] = \\mathbf{b} + \\mathbb{E}[\\boldsymbol{\\varepsilon}_i] = \\mathbf{b}$.\n\n### Bias Estimation\n\nThe problem defines bias as the expected error vector. For a population of infinite measurements, the bias vector $\\mathbf{b} = [b_x, b_z]^\\top$ is given by the expectation of the error vector:\n$$ \\mathbf{b} = \\mathbb{E}[\\mathbf{e}_i] $$\nThe components of the bias are $b_x = \\mathbb{E}[e_{x,i}]$ and $b_z = \\mathbb{E}[e_{z,i}]$. To estimate these population parameters from a finite sample of $N$ measurements, we use the sample mean as the estimator for the expectation. The estimator for the bias vector, which we will denote as $\\hat{\\mathbf{b}}$, is the average of the observed error vectors:\n$$ \\hat{\\mathbf{b}} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{e}_i = \\frac{1}{N} \\sum_{i=1}^N (\\mathbf{r}_i - \\mathbf{r}_0) $$\nThe estimators for the bias components $b_x$ and $b_z$ are therefore:\n$$ \\hat{b}_x = \\frac{1}{N} \\sum_{i=1}^N (x_i - x_0) $$\n$$ \\hat{b}_z = \\frac{1}{N} \\sum_{i=1}^N (z_i - z_0) $$\n\n### Root Mean Square Error (RMSE) Estimation\n\nThe problem defines RMSE as the square root of the expected squared error magnitude. We will derive estimators for the RMSE along each axis ($\\mathrm{RMSE}_x$, $\\mathrm{RMSE}_z$) and for the total radial error ($\\mathrm{RMSE}_{\\mathrm{rad}}$).\n\nThe Mean Squared Error (MSE) along the $x$-axis is the expected value of the squared error component $e_{x,i}$:\n$$ \\mathrm{MSE}_x = \\mathbb{E}[e_{x,i}^2] = \\mathbb{E}[(x_i - x_0)^2] $$\nThe $\\mathrm{RMSE}_x$ is the square root of the $\\mathrm{MSE}_x$. The estimator for $\\mathrm{MSE}_x$ from the sample is the sample mean of the squared errors:\n$$ \\widehat{\\mathrm{MSE}}_x = \\frac{1}{N} \\sum_{i=1}^N (x_i - x_0)^2 $$\nTherefore, the estimator for $\\mathrm{RMSE}_x$ is:\n$$ \\widehat{\\mathrm{RMSE}}_x = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - x_0)^2} $$\nBy perfect analogy, the estimator for $\\mathrm{RMSE}_z$ is:\n$$ \\widehat{\\mathrm{RMSE}}_z = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (z_i - z_0)^2} $$\nFor the radial RMSE, we consider the squared magniude of the two-dimensional error vector $\\mathbf{e}_i$, which is $\\lVert \\mathbf{e}_i \\rVert_2^2 = e_{x,i}^2 + e_{z,i}^2$. The radial MSE is the expectation of this quantity:\n$$ \\mathrm{MSE}_{\\mathrm{rad}} = \\mathbb{E}[\\lVert \\mathbf{e}_i \\rVert_2^2] = \\mathbb{E}[e_{x,i}^2 + e_{z,i}^2] = \\mathbb{E}[e_{x,i}^2] + \\mathbb{E}[e_{z,i}^2] = \\mathrm{MSE}_x + \\mathrm{MSE}_z $$\nThe estimator for $\\mathrm{MSE}_{\\mathrm{rad}}$ is the sample average of the squared error magnitudes:\n$$ \\widehat{\\mathrm{MSE}}_{\\mathrm{rad}} = \\frac{1}{N} \\sum_{i=1}^N \\lVert \\mathbf{e}_i \\rVert_2^2 = \\frac{1}{N} \\sum_{i=1}^N \\left( (x_i - x_0)^2 + (z_i-z_0)^2 \\right) $$\nThis can be decomposed as:\n$$ \\widehat{\\mathrm{MSE}}_{\\mathrm{rad}} = \\frac{1}{N} \\sum_{i=1}^N (x_i - x_0)^2 + \\frac{1}{N} \\sum_{i=1}^N (z_i-z_0)^2 = \\widehat{\\mathrm{MSE}}_x + \\widehat{\\mathrm{MSE}}_z = (\\widehat{\\mathrm{RMSE}}_x)^2 + (\\widehat{\\mathrm{RMSE}}_z)^2 $$\nThe estimator for the radial RMSE is the square root of the radial MSE estimator:\n$$ \\widehat{\\mathrm{RMSE}}_{\\mathrm{rad}} = \\sqrt{\\widehat{\\mathrm{MSE}}_{\\mathrm{rad}}} = \\sqrt{(\\widehat{\\mathrm{RMSE}}_x)^2 + (\\widehat{\\mathrm{RMSE}}_z)^2} $$\nThese derived estimators—$\\hat{b}_x$, $\\hat{b}_z$, $\\widehat{\\mathrm{RMSE}}_x$, $\\widehat{\\mathrm{RMSE}}_z$, and $\\widehat{\\mathrm{RMSE}}_{\\mathrm{rad}}$—provide the complete set of formulas needed to process the test cases. The implementation will compute these five quantities for each case, round them to three decimal places, and format the final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"r0\": [0.0, 0.0],\n            \"measurements\": [\n                [1.2, -0.8], [-0.5, 0.3], [0.9, -0.2], [-1.1, 0.7], [0.0, 0.0],\n                [0.4, -0.5], [-0.8, 0.6], [0.3, -0.1], [-0.2, 0.2], [0.1, -0.3]\n            ]\n        },\n        {\n            \"r0\": [0.0, 0.0],\n            \"measurements\": [\n                [8.0, 1.5], [-9.5, -1.0], [10.2, 2.0], [-7.8, -1.8], [0.5, 0.2],\n                [5.5, -0.7], [-6.3, 1.1], [9.1, -2.2], [-8.9, 0.9], [7.7, -0.4]\n            ]\n        },\n        {\n            \"r0\": [50.0, -30.0],\n            \"measurements\": [\n                [55.8, -33.2], [54.1, -32.5], [55.0, -33.1], [56.3, -33.4], [55.5, -33.0],\n                [54.7, -32.8], [55.9, -33.6], [55.2, -33.3], [54.9, -32.7], [56.1, -33.5]\n            ]\n        },\n        {\n            \"r0\": [-20.0, 40.0],\n            \"measurements\": [\n                [-18.0, 35.0]\n            ]\n        },\n        {\n            \"r0\": [100.0, 100.0],\n            \"measurements\": [\n                [100.0, 100.0], [100.0, 100.0], [100.0, 100.0], [100.0, 100.0], [100.0, 100.0]\n            ]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = calculate_metrics(case[\"r0\"], case[\"measurements\"])\n        all_results.append(result)\n\n    # Format the final output string exactly as required.\n    # Convert each numeric result to a string with 3 decimal places.\n    # Join these into comma-separated strings for each case.\n    # Enclose each case's results in square brackets.\n    # Join all case strings with a comma.\n    # Enclose the final string in square brackets.\n    case_strings = []\n    for result_list in all_results:\n        formatted_list = [f\"{x:.3f}\" for x in result_list]\n        case_strings.append(f\"[{','.join(formatted_list)}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\ndef calculate_metrics(r0_list, measurements_list):\n    \"\"\"\n    Calculates bias and RMSE metrics for a single test case.\n\n    Args:\n        r0_list (list): The true position [x0, z0].\n        measurements_list (list of lists): The list of measured positions [[x1, z1], ...].\n\n    Returns:\n        list: A list of 5 floats [b_x, b_z, RMSE_x, RMSE_z, RMSE_rad].\n    \"\"\"\n    # Convert inputs to NumPy arrays for vectorized operations.\n    r0 = np.array(r0_list, dtype=float)\n    measurements = np.array(measurements_list, dtype=float)\n\n    # Number of measurements (N)\n    N = measurements.shape[0]\n\n    # Calculate the error vectors: e_i = r_i - r_0 for all i.\n    # This results in a (N, 2) array of errors.\n    errors = measurements - r0\n\n    # 1. Estimate bias components (b_x, b_z)\n    # The estimator for bias is the sample mean of the error vectors.\n    # np.mean(errors, axis=0) computes the mean of the x-components and z-components.\n    b_x, b_z = np.mean(errors, axis=0)\n\n    # 2. Estimate RMSE components (RMSE_x, RMSE_z)\n    # The estimator for MSE is the sample mean of the squared errors.\n    # The estimator for RMSE is the square root of the MSE estimator.\n    squared_errors = errors ** 2\n    mse_components = np.mean(squared_errors, axis=0)\n    rmse_x, rmse_z = np.sqrt(mse_components)\n\n    # 3. Estimate radial RMSE (RMSE_rad)\n    # The radial RMSE is sqrt(RMSE_x^2 + RMSE_z^2).\n    rmse_rad = np.sqrt(rmse_x**2 + rmse_z**2)\n    # Alternative calculation for validation:\n    # rmse_rad_alt = np.sqrt(np.mean(np.sum(errors**2, axis=1)))\n    # assert np.isclose(rmse_rad, rmse_rad_alt)\n    \n    # Return the metrics. Rounding is handled during final print formatting.\n    return [b_x, b_z, rmse_x, rmse_z, rmse_rad]\n\nsolve()\n```", "id": "4939224"}]}