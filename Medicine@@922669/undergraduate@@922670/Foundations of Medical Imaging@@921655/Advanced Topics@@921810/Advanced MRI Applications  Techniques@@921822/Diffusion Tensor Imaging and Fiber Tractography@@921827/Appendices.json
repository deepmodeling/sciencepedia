{"hands_on_practices": [{"introduction": "The diffusion tensor provides a mathematical description of water mobility in tissue. To be physically meaningful, this description must have properties that are independent of the arbitrary coordinate system used for the measurement. This practice problem delves into the fundamental concept of tensor invariants by examining how the tensor's components transform under a coordinate rotation, allowing you to prove from first principles why key scalar metrics remain constant.", "problem": "A diffusion tensor imaging (DTI) measurement at a voxel is modeled by a second-order, symmetric, positive-definite diffusion tensor $\\mathbf{D}$ that describes the local apparent diffusion coefficients along different directions. In fiber tractography, invariants of $\\mathbf{D}$ such as its trace and determinant are used to construct scalar maps that are independent of the choice of coordinate axes.\n\nConsider the diffusion tensor\n$$\n\\mathbf{D} \\;=\\; \\begin{pmatrix}\n1.7 \\times 10^{-3} & 0.2 \\times 10^{-3} & 0 \\\\\n0.2 \\times 10^{-3} & 0.9 \\times 10^{-3} & 0 \\\\\n0 & 0 & 0.6 \\times 10^{-3}\n\\end{pmatrix},\n$$\nwith entries in $\\mathrm{mm}^2/\\mathrm{s}$. Let the coordinate frame be rotated by the orthonormal matrix\n$$\n\\mathbf{R} \\;=\\; \\begin{pmatrix}\n\\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2} & 0 \\\\\n\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n$$\nwhich corresponds to a rotation in the $\\{x,y\\}$-plane that leaves the $z$-axis unchanged.\n\nUsing only the fundamental definition of how the components of a second-order tensor transform under an orthonormal change of basis, derive the rotated tensor $\\mathbf{D}'$ in the rotated coordinate system defined by $\\mathbf{R}$. Then, from first principles of linear algebra about orthonormal transformations, justify whether the tensor invariants $\\operatorname{tr}(\\mathbf{D})$ and $\\det(\\mathbf{D})$ remain unchanged by this rotation, and compute their values for $\\mathbf{D}'$.\n\nExpress the trace in $\\mathrm{mm}^2/\\mathrm{s}$ and the determinant in $\\mathrm{mm}^6/\\mathrm{s}^3$. For the boxed final answer, report the ordered pair $\\big(\\operatorname{tr}(\\mathbf{D}'),\\,\\det(\\mathbf{D}')\\big)$ numerically in scientific notation without units. No rounding is necessary.", "solution": "The problem is addressed in three parts: first, the derivation of the rotated tensor $\\mathbf{D}'$; second, the justification of the invariance of its trace and determinant from first principles; and third, the calculation of these invariants.\n\n**1. Derivation of the Rotated Tensor $\\mathbf{D}'$**\n\nThe fundamental definition of how a second-order tensor $\\mathbf{D}$ transforms under an orthonormal change of basis defined by a matrix $\\mathbf{R}$ is given by the similarity transformation:\n$$\n\\mathbf{D}' = \\mathbf{R} \\mathbf{D} \\mathbf{R}^T\n$$\nwhere $\\mathbf{R}^T$ is the transpose of $\\mathbf{R}$.\n\nLet's factor out the common term $d_0 = 10^{-3} \\; \\mathrm{mm}^2/\\mathrm{s}$ from $\\mathbf{D}$ for simpler matrix multiplication:\n$$\n\\mathbf{D} = d_0 \\begin{pmatrix} 1.7 & 0.2 & 0 \\\\ 0.2 & 0.9 & 0 \\\\ 0 & 0 & 0.6 \\end{pmatrix}\n$$\nThe rotation matrix $\\mathbf{R}$ and its transpose $\\mathbf{R}^T$ are:\n$$\n\\mathbf{R} = \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2} & 0 \\\\ \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}, \\quad \\mathbf{R}^T = \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\ -\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\nWe compute the product $\\mathbf{D}' = \\mathbf{R} (\\mathbf{D} \\mathbf{R}^T)$. Let's first compute the intermediate product $\\mathbf{D} \\mathbf{R}^T$:\n$$\n\\mathbf{D} \\mathbf{R}^T = d_0 \\begin{pmatrix} 1.7 & 0.2 & 0 \\\\ 0.2 & 0.9 & 0 \\\\ 0 & 0 & 0.6 \\end{pmatrix} \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\ -\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\n$$\n\\mathbf{D} \\mathbf{R}^T = d_0 \\begin{pmatrix}\n1.7(\\frac{\\sqrt{2}}{2}) + 0.2(-\\frac{\\sqrt{2}}{2}) & 1.7(\\frac{\\sqrt{2}}{2}) + 0.2(\\frac{\\sqrt{2}}{2}) & 0 \\\\\n0.2(\\frac{\\sqrt{2}}{2}) + 0.9(-\\frac{\\sqrt{2}}{2}) & 0.2(\\frac{\\sqrt{2}}{2}) + 0.9(\\frac{\\sqrt{2}}{2}) & 0 \\\\\n0 & 0 & 0.6(1)\n\\end{pmatrix}\n$$\n$$\n\\mathbf{D} \\mathbf{R}^T = d_0 \\begin{pmatrix}\n1.5 \\frac{\\sqrt{2}}{2} & 1.9 \\frac{\\sqrt{2}}{2} & 0 \\\\\n-0.7 \\frac{\\sqrt{2}}{2} & 1.1 \\frac{\\sqrt{2}}{2} & 0 \\\\\n0 & 0 & 0.6\n\\end{pmatrix}\n$$\nNow, we pre-multiply this result by $\\mathbf{R}$ to find $\\mathbf{D}'$:\n$$\n\\mathbf{D}' = \\mathbf{R}(\\mathbf{D}\\mathbf{R}^T) = \\begin{pmatrix} \\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2} & 0 \\\\ \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} d_0 \\begin{pmatrix}\n1.5 \\frac{\\sqrt{2}}{2} & 1.9 \\frac{\\sqrt{2}}{2} & 0 \\\\\n-0.7 \\frac{\\sqrt{2}}{2} & 1.1 \\frac{\\sqrt{2}}{2} & 0 \\\\\n0 & 0 & 0.6\n\\end{pmatrix}\n$$\n$$\n\\mathbf{D}' = d_0 \\begin{pmatrix}\n\\frac{\\sqrt{2}}{2}(1.5 \\frac{\\sqrt{2}}{2}) - \\frac{\\sqrt{2}}{2}(-0.7 \\frac{\\sqrt{2}}{2}) & \\frac{\\sqrt{2}}{2}(1.9 \\frac{\\sqrt{2}}{2}) - \\frac{\\sqrt{2}}{2}(1.1 \\frac{\\sqrt{2}}{2}) & 0 \\\\\n\\frac{\\sqrt{2}}{2}(1.5 \\frac{\\sqrt{2}}{2}) + \\frac{\\sqrt{2}}{2}(-0.7 \\frac{\\sqrt{2}}{2}) & \\frac{\\sqrt{2}}{2}(1.9 \\frac{\\sqrt{2}}{2}) + \\frac{\\sqrt{2}}{2}(1.1 \\frac{\\sqrt{2}}{2}) & 0 \\\\\n0 & 0 & 1(0.6)\n\\end{pmatrix}\n$$\n$$\n\\mathbf{D}' = d_0 \\begin{pmatrix}\n\\frac{1}{2}(1.5+0.7) & \\frac{1}{2}(1.9-1.1) & 0 \\\\\n\\frac{1}{2}(1.5-0.7) & \\frac{1}{2}(1.9+1.1) & 0 \\\\\n0 & 0 & 0.6\n\\end{pmatrix} = d_0 \\begin{pmatrix}\n\\frac{2.2}{2} & \\frac{0.8}{2} & 0 \\\\\n\\frac{0.8}{2} & \\frac{3.0}{2} & 0 \\\\\n0 & 0 & 0.6\n\\end{pmatrix}\n$$\n$$\n\\mathbf{D}' = d_0 \\begin{pmatrix}\n1.1 & 0.4 & 0 \\\\\n0.4 & 1.5 & 0 \\\\\n0 & 0 & 0.6\n\\end{pmatrix} = \\begin{pmatrix}\n1.1 \\times 10^{-3} & 0.4 \\times 10^{-3} & 0 \\\\\n0.4 \\times 10^{-3} & 1.5 \\times 10^{-3} & 0 \\\\\n0 & 0 & 0.6 \\times 10^{-3}\n\\end{pmatrix}\n$$\nThis is the rotated diffusion tensor $\\mathbf{D}'$. Note that it remains symmetric, as expected.\n\n**2. Justification of Invariance from First Principles**\n\nThe problem asks to justify from first principles of linear algebra why the trace and determinant are invariants of this transformation.\n\n**Invariance of the Trace ($\\operatorname{tr}$):**\nThe trace of a matrix is the sum of its diagonal elements. A fundamental property of the trace operator is its cyclic property: for any square matrices $\\mathbf{A}$, $\\mathbf{B}$, and $\\mathbf{C}$ of compatible dimensions, $\\operatorname{tr}(\\mathbf{A}\\mathbf{B}\\mathbf{C}) = \\operatorname{tr}(\\mathbf{B}\\mathbf{C}\\mathbf{A}) = \\operatorname{tr}(\\mathbf{C}\\mathbf{A}\\mathbf{B})$.\nThe rotated tensor is $\\mathbf{D}' = \\mathbf{R}\\mathbf{D}\\mathbf{R}^T$. The trace of $\\mathbf{D}'$ is:\n$$\n\\operatorname{tr}(\\mathbf{D}') = \\operatorname{tr}(\\mathbf{R}\\mathbf{D}\\mathbf{R}^T)\n$$\nApplying the cyclic property by moving $\\mathbf{R}$ from the front to the back:\n$$\n\\operatorname{tr}(\\mathbf{D}') = \\operatorname{tr}(\\mathbf{D}\\mathbf{R}^T\\mathbf{R})\n$$\nSince $\\mathbf{R}$ is an orthonormal matrix, by definition, $\\mathbf{R}^T\\mathbf{R} = \\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix. Substituting this into the equation:\n$$\n\\operatorname{tr}(\\mathbf{D}') = \\operatorname{tr}(\\mathbf{D}\\mathbf{I}) = \\operatorname{tr}(\\mathbf{D})\n$$\nThis proves from first principles that the trace of the tensor is an invariant under an orthonormal transformation.\n\n**Invariance of the Determinant ($\\det$):**\nA fundamental property of the determinant is that for any two square matrices $\\mathbf{A}$ and $\\mathbf{B}$ of the same size, $\\det(\\mathbf{A}\\mathbf{B}) = \\det(\\mathbf{A})\\det(\\mathbf{B})$.\nApplying this property to the transformation $\\mathbf{D}' = \\mathbf{R}\\mathbf{D}\\mathbf{R}^T$:\n$$\n\\det(\\mathbf{D}') = \\det(\\mathbf{R}\\mathbf{D}\\mathbf{R}^T) = \\det(\\mathbf{R}) \\det(\\mathbf{D}) \\det(\\mathbf{R}^T)\n$$\nAnother basic property is that the determinant of a matrix is equal to the determinant of its transpose, i.e., $\\det(\\mathbf{R}^T) = \\det(\\mathbf{R})$.\n$$\n\\det(\\mathbf{D}') = \\det(\\mathbf{D}) \\det(\\mathbf{R}) \\det(\\mathbf{R}) = \\det(\\mathbf{D}) (\\det(\\mathbf{R}))^2\n$$\nFor an orthonormal matrix $\\mathbf{R}$, we have $\\mathbf{R}\\mathbf{R}^T = \\mathbf{I}$. Taking the determinant of both sides:\n$$\n\\det(\\mathbf{R}\\mathbf{R}^T) = \\det(\\mathbf{I}) \\implies \\det(\\mathbf{R})\\det(\\mathbf{R}^T) = 1 \\implies (\\det(\\mathbf{R}))^2 = 1\n$$\nThis implies $\\det(\\mathbf{R}) = \\pm 1$.  Substituting $(\\det(\\mathbf{R}))^2 = 1$ into our expression for $\\det(\\mathbf{D}')$:\n$$\n\\det(\\mathbf{D}') = \\det(\\mathbf{D}) \\times 1 = \\det(\\mathbf{D})\n$$\nThis proves from first principles that the determinant of the tensor is also an invariant under any orthonormal transformation.\n\n**3. Computation of $\\operatorname{tr}(\\mathbf{D}')$ and $\\det(\\mathbf{D}')$**\n\nAs proven above, the trace and determinant are invariant. Therefore, we can compute them using the simpler, original tensor $\\mathbf{D}$ to find the values for $\\mathbf{D}'$.\n$$\n\\mathbf{D} \\;=\\; \\begin{pmatrix}\n1.7 \\times 10^{-3} & 0.2 \\times 10^{-3} & 0 \\\\\n0.2 \\times 10^{-3} & 0.9 \\times 10^{-3} & 0 \\\\\n0 & 0 & 0.6 \\times 10^{-3}\n\\end{pmatrix} \\; \\mathrm{mm}^2/\\mathrm{s}\n$$\n**Trace computation:**\n$$\n\\operatorname{tr}(\\mathbf{D}') = \\operatorname{tr}(\\mathbf{D}) = (1.7 \\times 10^{-3}) + (0.9 \\times 10^{-3}) + (0.6 \\times 10^{-3})\n$$\n$$\n\\operatorname{tr}(\\mathbf{D}') = (1.7 + 0.9 + 0.6) \\times 10^{-3} = 3.2 \\times 10^{-3} \\; \\mathrm{mm}^2/\\mathrm{s}\n$$\n**Determinant computation:**\n$$\n\\det(\\mathbf{D}') = \\det(\\mathbf{D})\n$$\nSince $\\mathbf{D}$ is block-diagonal, its determinant is the product of the determinants of its diagonal blocks.\n$$\n\\det(\\mathbf{D}) = \\det \\begin{pmatrix} 1.7 \\times 10^{-3} & 0.2 \\times 10^{-3} \\\\ 0.2 \\times 10^{-3} & 0.9 \\times 10^{-3} \\end{pmatrix} \\times (0.6 \\times 10^{-3})\n$$\n$$\n\\det(\\mathbf{D}) = \\left[ (1.7 \\times 10^{-3})(0.9 \\times 10^{-3}) - (0.2 \\times 10^{-3})(0.2 \\times 10^{-3}) \\right] \\times (0.6 \\times 10^{-3})\n$$\n$$\n\\det(\\mathbf{D}) = \\left[ 1.53 \\times 10^{-6} - 0.04 \\times 10^{-6} \\right] \\times (0.6 \\times 10^{-3})\n$$\n$$\n\\det(\\mathbf{D}) = (1.49 \\times 10^{-6}) \\times (0.6 \\times 10^{-3})\n$$\n$$\n\\det(\\mathbf{D}) = 0.894 \\times 10^{-9} \\; \\mathrm{mm}^6/\\mathrm{s}^3\n$$\nExpressing this in standard scientific notation:\n$$\n\\det(\\mathbf{D}') = 8.94 \\times 10^{-10} \\; \\mathrm{mm}^6/\\mathrm{s}^3\n$$\nThe final answer requires the ordered pair $\\big(\\operatorname{tr}(\\mathbf{D}'),\\,\\det(\\mathbf{D}')\\big)$ in scientific notation.\n$$\n\\operatorname{tr}(\\mathbf{D}') = 3.2 \\times 10^{-3}\n$$\n$$\n\\det(\\mathbf{D}') = 8.94 \\times 10^{-10}\n$$", "answer": "$$\n\\boxed{(3.2 \\times 10^{-3}, 8.94 \\times 10^{-10})}\n$$", "id": "4877353"}, {"introduction": "While the diffusion tensor offers a complete local picture of diffusion, we often need a simple scalar value to quantify the degree of anisotropy. This exercise challenges you to derive the formula for Fractional Anisotropy (FA), the most common of these metrics, directly from a set of fundamental physical requirements. By building FA from the ground up, you will gain a profound understanding of how it captures the shape of the diffusion ellipsoid and its relationship to the tensor's eigenvalues.", "problem": "A single voxel in Diffusion Tensor Imaging (DTI) is modeled by a symmetric, positive-definite diffusion tensor with eigenvalues $\\lambda_{1}$, $\\lambda_{2}$, and $\\lambda_{3}$, expressed in $\\mathrm{mm^{2}/s}$. The mean diffusivity is defined as $\\bar{\\lambda} = (\\lambda_{1} + \\lambda_{2} + \\lambda_{3})/3$. Consider constructing a scalar anisotropy index that satisfies the following fundamental requirements:\n- It is invariant under rotation of the diffusion tensor principal axes.\n- It is invariant under uniform scaling of the tensor (that is, multiplying all $\\lambda_{i}$ by the same positive constant does not change the index).\n- It is zero if and only if the tensor is isotropic (that is, $\\lambda_{1} = \\lambda_{2} = \\lambda_{3}$).\n- It equals one for an idealized linearly anisotropic (stick-like) tensor with eigenvalues proportional to $(a, 0, 0)$ for any $a > 0$.\n\nStarting from these requirements and the definitions above, derive a suitable expression for the widely used Fractional Anisotropy (FA) in terms of $\\lambda_{1}$, $\\lambda_{2}$, $\\lambda_{3}$, and $\\bar{\\lambda}$, and then compute the FA for a voxel with eigenvalues\n$\\lambda_{1} = 1.6 \\times 10^{-3}\\ \\mathrm{mm^{2}/s}$, $\\lambda_{2} = 0.5 \\times 10^{-3}\\ \\mathrm{mm^{2}/s}$, and $\\lambda_{3} = 0.4 \\times 10^{-3}\\ \\mathrm{mm^{2}/s}$.\n\nFinally, based on your derived expression, explain qualitatively how the FA changes when the dispersion among $\\lambda_{i}$ increases or decreases, under either of the following constraints:\n- Holding the mean diffusivity $\\bar{\\lambda}$ fixed.\n- Holding the sum of squares $\\lambda_{1}^{2} + \\lambda_{2}^{2} + \\lambda_{3}^{2}$ fixed.\n\nExpress the final reported FA as a dimensionless number rounded to four significant figures. Do not include units with your final numerical value.", "solution": "The problem is valid. It is scientifically grounded in the principles of Diffusion Tensor Imaging (DTI), well-posed, and objective. We will proceed with the derivation, calculation, and qualitative analysis as requested.\n\n### Derivation of the Fractional Anisotropy (FA) Index\n\nWe are tasked with constructing a scalar anisotropy index from a set of four fundamental requirements. Let the eigenvalues of the diffusion tensor be $\\lambda_1, \\lambda_2, \\lambda_3$. The mean diffusivity is $\\bar{\\lambda} = \\frac{\\lambda_1 + \\lambda_2 + \\lambda_3}{3}$.\n\n1.  **Requirement 1: Rotational Invariance**\n    The eigenvalues of a tensor are invariant under a rotation of the coordinate system. Therefore, any index that is exclusively a function of $\\lambda_1, \\lambda_2, \\lambda_3$ will automatically be rotationally invariant. We will adhere to this principle.\n\n2.  **Requirement 3: Zero for Isotropy**\n    Anisotropy measures the degree of deviation from an isotropic state, where diffusion is equal in all directions. The isotropic condition is $\\lambda_1 = \\lambda_2 = \\lambda_3$. In this case, all eigenvalues are equal to the mean diffusivity, $\\lambda_i = \\bar{\\lambda}$.\n    A natural measure for the deviation from the mean is the sum of squared differences, which is analogous to variance in statistics:\n    $$ V = (\\lambda_1 - \\bar{\\lambda})^2 + (\\lambda_2 - \\bar{\\lambda})^2 + (\\lambda_3 - \\bar{\\lambda})^2 = \\sum_{i=1}^{3} (\\lambda_i - \\bar{\\lambda})^2 $$\n    This quantity, $V$, is non-negative and is zero if and only if $\\lambda_1 = \\lambda_2 = \\lambda_3 = \\bar{\\lambda}$, thus satisfying the \"zero for isotropy\" requirement.\n\n3.  **Requirement 2: Scale Invariance**\n    The index must be invariant under uniform scaling, i.e., if we replace each $\\lambda_i$ with $c\\lambda_i$ for some positive constant $c$, the index should not change.\n    Let's test our variance-like term $V$. If $\\lambda_i \\to c\\lambda_i$, then $\\bar{\\lambda} \\to \\frac{c\\lambda_1 + c\\lambda_2 + c\\lambda_3}{3} = c\\bar{\\lambda}$.\n    The new variance term $V'$ becomes:\n    $$ V' = \\sum_{i=1}^{3} (c\\lambda_i - c\\bar{\\lambda})^2 = \\sum_{i=1}^{3} c^2(\\lambda_i - \\bar{\\lambda})^2 = c^2 V $$\n    Since $V$ is not scale-invariant, we must normalize it by a quantity that also scales with $c^2$. A natural candidate for normalization is a measure of the total magnitude of the tensor. The squared Frobenius norm of the tensor, which in the principal axis system is simply the sum of squared eigenvalues, $\\sum_{i=1}^{3} \\lambda_i^2$, has the desired scaling property:\n    $$ \\sum_{i=1}^{3} (c\\lambda_i)^2 = c^2 \\sum_{i=1}^{3} \\lambda_i^2 $$\n    Thus, the ratio of these two quantities is scale-invariant. To maintain the same units in the numerator and denominator (in a dimensional sense), we can work with their square roots. Let's define a preliminary index based on the ratio of the root of the variance to the root of the sum of squares:\n    $$ I_{prelim} = \\frac{\\sqrt{\\sum_{i=1}^{3} (\\lambda_i - \\bar{\\lambda})^2}}{\\sqrt{\\sum_{i=1}^{3} \\lambda_i^2}} $$\n    This preliminary index $I_{prelim}$ is rotationally invariant, scale-invariant, and is zero if and only if the tensor is isotropic.\n\n4.  **Requirement 4: Unity for Linear Anisotropy**\n    The final requirement is that the index must equal $1$ for an idealized \"stick-like\" diffusion profile, which is represented by eigenvalues proportional to $(a, 0, 0)$ for any $a > 0$. Due to scale invariance, we can simply set the eigenvalues to $\\lambda_1 = a$, $\\lambda_2 = 0$, and $\\lambda_3 = 0$.\n    For this case, the mean diffusivity is $\\bar{\\lambda} = \\frac{a+0+0}{3} = \\frac{a}{3}$.\n    The numerator term becomes:\n    $$ \\sqrt{\\sum (\\lambda_i - \\bar{\\lambda})^2} = \\sqrt{\\left(a - \\frac{a}{3}\\right)^2 + \\left(0 - \\frac{a}{3}\\right)^2 + \\left(0 - \\frac{a}{3}\\right)^2} = \\sqrt{\\left(\\frac{2a}{3}\\right)^2 + \\left(-\\frac{a}{3}\\right)^2 + \\left(-\\frac{a}{3}\\right)^2} = \\sqrt{\\frac{4a^2}{9} + \\frac{a^2}{9} + \\frac{a^2}{9}} = \\sqrt{\\frac{6a^2}{9}} = a\\sqrt{\\frac{2}{3}} $$\n    The denominator term is:\n    $$ \\sqrt{\\sum \\lambda_i^2} = \\sqrt{a^2 + 0^2 + 0^2} = a $$\n    Plugging these into our preliminary index gives:\n    $$ I_{prelim} = \\frac{a\\sqrt{2/3}}{a} = \\sqrt{\\frac{2}{3}} $$\n    This is not equal to $1$. To satisfy the fourth requirement, we must introduce a constant scaling factor, $C$, such that our final index, FA, is $FA = C \\cdot I_{prelim}$. We require that for the linear case, $C \\cdot \\sqrt{2/3} = 1$. This implies $C = \\sqrt{3/2}$.\n    Therefore, the expression for Fractional Anisotropy that satisfies all four requirements is:\n    $$ \\mathrm{FA} = \\sqrt{\\frac{3}{2}} \\frac{\\sqrt{(\\lambda_1 - \\bar{\\lambda})^2 + (\\lambda_2 - \\bar{\\lambda})^2 + (\\lambda_3 - \\bar{\\lambda})^2}}{\\sqrt{\\lambda_1^2 + \\lambda_2^2 + \\lambda_3^2}} $$\n    This is the desired expression.\n\n### Numerical Calculation of FA\n\nGiven the eigenvalues:\n$\\lambda_{1} = 1.6 \\times 10^{-3}\\ \\mathrm{mm^{2}/s}$\n$\\lambda_{2} = 0.5 \\times 10^{-3}\\ \\mathrm{mm^{2}/s}$\n$\\lambda_{3} = 0.4 \\times 10^{-3}\\ \\mathrm{mm^{2}/s}$\n\nSince FA is a dimensionless, scale-invariant quantity, we can omit the factor of $10^{-3}$ for the calculation. Let $\\lambda_1' = 1.6$, $\\lambda_2' = 0.5$, $\\lambda_3' = 0.4$.\n\nFirst, calculate the mean diffusivity, $\\bar{\\lambda}'$:\n$$ \\bar{\\lambda}' = \\frac{1.6 + 0.5 + 0.4}{3} = \\frac{2.5}{3} $$\n\nNext, calculate the sum of squared differences for the numerator:\n$$ \\sum_{i=1}^{3} (\\lambda_i' - \\bar{\\lambda}')^2 = \\left(1.6 - \\frac{2.5}{3}\\right)^2 + \\left(0.5 - \\frac{2.5}{3}\\right)^2 + \\left(0.4 - \\frac{2.5}{3}\\right)^2 $$\n$$ = \\left(\\frac{4.8 - 2.5}{3}\\right)^2 + \\left(\\frac{1.5 - 2.5}{3}\\right)^2 + \\left(\\frac{1.2 - 2.5}{3}\\right)^2 $$\n$$ = \\left(\\frac{2.3}{3}\\right)^2 + \\left(\\frac{-1.0}{3}\\right)^2 + \\left(\\frac{-1.3}{3}\\right)^2 = \\frac{5.29 + 1.00 + 1.69}{9} = \\frac{7.98}{9} $$\n\nNext, calculate the sum of squared eigenvalues for the denominator:\n$$ \\sum_{i=1}^{3} (\\lambda_i')^2 = (1.6)^2 + (0.5)^2 + (0.4)^2 = 2.56 + 0.25 + 0.16 = 2.97 $$\n\nFinally, substitute these values into the FA formula:\n$$ \\mathrm{FA} = \\sqrt{\\frac{3}{2}} \\frac{\\sqrt{7.98 / 9}}{\\sqrt{2.97}} = \\sqrt{\\frac{3}{2} \\cdot \\frac{7.98/9}{2.97}} = \\sqrt{\\frac{1.5 \\cdot (0.8866...)}{2.97}} = \\sqrt{\\frac{1.33}{2.97}} $$\n$$ \\mathrm{FA} \\approx \\sqrt{0.4478114478...} \\approx 0.66918716 $$\nRounding to four significant figures, the Fractional Anisotropy is $0.6692$.\n\n### Qualitative Analysis of FA Behavior\n\nThe derived expression for FA is:\n$$ \\mathrm{FA} = \\sqrt{\\frac{3}{2}} \\frac{\\sqrt{\\sum (\\lambda_i - \\bar{\\lambda})^2}}{\\sqrt{\\sum \\lambda_i^2}} $$\nThe term $\\sum (\\lambda_i - \\bar{\\lambda})^2$ quantifies the \"dispersion\" among the eigenvalues. An increase in dispersion means this term increases.\n\n- **Constraint 1: Holding the mean diffusivity $\\bar{\\lambda}$ fixed.**\nIf $\\bar{\\lambda}$ is constant, an increase in dispersion (i.e., an increase in $\\sum (\\lambda_i - \\bar{\\lambda})^2$) means the eigenvalues are spreading further apart while maintaining the same average value. Using the identity $\\sum (\\lambda_i - \\bar{\\lambda})^2 = \\sum \\lambda_i^2 - 3\\bar{\\lambda}^2$, we see that an increase in dispersion directly implies an increase in the denominator term $\\sum \\lambda_i^2$. The FA expression can be viewed as an increasing function of the dispersion term relative to the total magnitude. As dispersion increases, the numerator $\\sqrt{\\sum (\\lambda_i - \\bar{\\lambda})^2}$ grows. Although the denominator $\\sqrt{\\sum \\lambda_i^2}$ also grows, the numerator's growth has a stronger effect on the ratio within the defined range ($0 \\le \\mathrm{FA} \\le 1$). An increase in dispersion at constant mean diffusivity signifies a shift from a more spherical (isotropic) diffusion profile to a more elongated or planar (anisotropic) one. Therefore, **FA increases as dispersion increases**.\n\n- **Constraint 2: Holding the sum of squares $\\sum \\lambda_i^2$ fixed.**\nLet $S = \\sum \\lambda_i^2$ be constant. The FA formula can be written as:\n$$ \\mathrm{FA} = \\sqrt{\\frac{3}{2} \\frac{S - 3\\bar{\\lambda}^2}{S}} = \\sqrt{\\frac{3}{2}\\left(1 - \\frac{3\\bar{\\lambda}^2}{S}\\right)} $$\nUnder the constraint of fixed $S$, FA depends only on $\\bar{\\lambda}$. An increase in dispersion corresponds to moving away from the isotropic state ($\\lambda_1 = \\lambda_2 = \\lambda_3$). By the Cauchy-Schwarz inequality, for a fixed sum of squares $S$, the sum $\\sum \\lambda_i$ (and thus $\\bar{\\lambda}$) is maximized when the eigenvalues are equal (minimum dispersion). As dispersion increases, $\\sum \\lambda_i$ and hence $\\bar{\\lambda}$ must decrease.\nSince increasing dispersion leads to a decrease in $\\bar{\\lambda}$, the term $\\frac{3\\bar{\\lambda}^2}{S}$ in the expression for FA decreases. Consequently, the term $\\left(1 - \\frac{3\\bar{\\lambda}^2}{S}\\right)$ increases, and thus **FA increases as dispersion increases**.\n\nIn both scenarios, an increase in the dispersion among eigenvalues corresponds to a more anisotropic diffusion tensor, which is reflected as a higher FA value. Conversely, a decrease in dispersion makes the tensor more isotropic, lowering the FA value.", "answer": "$$\\boxed{0.6692}$$", "id": "4877363"}, {"introduction": "Fiber tractography aims to reconstruct the brain's white matter pathways by \"connecting the dots\" between local diffusion tensor estimates. However, are these reconstructed streamlines a faithful representation of true axonal connections? This practice problem places you in the role of a validation scientist, using a phantom with known connections to quantitatively assess the performance of a tractography algorithm and confront the fundamental limitations that challenge its interpretation as a true map of neural connectivity.", "problem": "A research team seeks to quantitatively compare streamline-based fiber tractography derived from Diffusion Magnetic Resonance Imaging (dMRI) using the Diffusion Tensor Imaging (DTI) model against known ground-truth connectivity from a physical phantom with engineered fiber pathways. The phantom is constructed with four labeled regions $\\{A, B, C, D\\}$ embedded in a gel containing oriented fiber bundles that mimic coherent white matter tracts. The acquisition uses a monoexponential Stejskal–Tanner attenuation model for diffusion-weighted signal, with signal along a unit gradient direction $\\mathbf{g}$ described by $E(b,\\mathbf{g}) \\approx \\exp\\!\\left(-b\\,\\mathbf{g}^{\\top}\\mathbf{D}\\,\\mathbf{g}\\right)$, where $\\mathbf{D}$ is the diffusion tensor and $b$ is the diffusion weighting parameter. Streamline propagation follows the local principal eigenvector of $\\mathbf{D}$ with a standard stopping rule based on fractional anisotropy thresholding and curvature constraints. The phantom’s ground-truth fiber connections are known from manufacturing specifications and verified by destructive imaging.\n\nTo test quantitative agreement, connections are operationally defined as present if the tractography yields at least $50$ streamlines between the corresponding region pair. Consider the $6$ unordered region pairs $\\{A\\!-\\!B, A\\!-\\!C, B\\!-\\!C, A\\!-\\!D, B\\!-\\!D, C\\!-\\!D\\}$. Ground-truth physical connections exist for $A\\!-\\!B$, $A\\!-\\!C$, and $B\\!-\\!D$ only. The tractography, under a streamline threshold of $50$, reports the following connections with streamline counts: $A\\!-\\!B: 120$, $A\\!-\\!C: 80$, $B\\!-\\!C: 60$, $A\\!-\\!D: 55$. No other pair meets the threshold.\n\nUsing first principles of diffusion and tractography physics, and standard definitions of classification metrics, answer the following:\n\nWhich of the following statements are correct?\n\nA. The sensitivity and precision (positive predictive value) of the thresholded tractography regarding connection presence in this phantom are $2/3$ and $1/2$, respectively; low precision here is consistent with known false positives caused by crossing fiber configurations and gyral biases in streamline termination.\n\nB. Increasing the streamline threshold from $50$ to $100$ will necessarily increase sensitivity without affecting precision, because higher thresholds eliminate spurious streamlines while preserving true ones.\n\nC. Even with perfect estimation of the diffusion tensor $\\mathbf{D}$, streamline count is not proportional to axon count, due to distance-dependent propagation biases, curvature constraints, and variable tract cross-sectional areas; therefore, tractography should not be used to infer true axonal connectivity strength.\n\nD. The specificity in this setup is $4/6$ because there are $4$ true negatives, demonstrating that tractography excels at rejecting non-existing connections in this phantom.\n\nE. Directionality of connections (afferent versus efferent) can be inferred from DTI by following the principal eigenvector from source to target, so tractography can recover the polarity of anatomical pathways.\n\nSelect all that apply. Justify your choice from the physical meaning of the diffusion signal, the geometry of $\\mathbf{D}$, and the operational definitions used above, without appealing to heuristic rules beyond these foundations. All numerical evaluations must be based on the data provided.", "solution": "The core of the problem is to evaluate the performance of a streamline-based fiber tractography algorithm against a known ground truth using standard classification metrics.\n\nFirst, we must formally define the classification categories based on the provided data. There are $6$ total possible connections between the four regions $\\{A, B, C, D\\}$.\n\nThe ground truth is given as:\n-   **Condition Positive (P)**: Connections that physically exist. These are $\\{A\\!-\\!B, A\\!-\\!C, B\\!-\\!D\\}$. The total number of positives is $P = 3$.\n-   **Condition Negative (N)**: Connections that do not physically exist. By exclusion, these are $\\{B\\!-\\!C, A\\!-\\!D, C\\!-\\!D\\}$. The total number of negatives is $N = 3$.\n\nThe tractography outcome is determined by a streamline count threshold of $50$. A connection is \"detected\" if its streamline count is $\\geq 50$.\n-   Detected connections:\n    -   $A\\!-\\!B$ (count $120 \\geq 50$)\n    -   $A\\!-\\!C$ (count $80 \\geq 50$)\n    -   $B\\!-\\!C$ (count $60 \\geq 50$)\n    -   $A\\!-\\!D$ (count $55 \\geq 50$)\n-   Undetected connections: Pairs for which no count is given are stated to not meet the threshold. These are $\\{B\\!-\\!D, C\\!-\\!D\\}$.\n\nNow we can populate the confusion matrix:\n-   **True Positives (TP)**: Connections that are both ground truth and detected by tractography.\n    -   $A\\!-\\!B$ is ground truth and detected.\n    -   $A\\!-\\!C$ is ground truth and detected.\n    -   Therefore, $TP = 2$.\n-   **False Negatives (FN)**: Connections that are ground truth but are not detected by tractography.\n    -   $B\\!-\\!D$ is ground truth but was not detected.\n    -   Therefore, $FN = 1$.\n-   **False Positives (FP)**: Connections that are not ground truth but are detected by tractography.\n    -   $B\\!-\\!C$ is not ground truth but was detected.\n    -   $A\\!-\\!D$ is not ground truth but was detected.\n    -   Therefore, $FP = 2$.\n-   **True Negatives (TN)**: Connections that are not ground truth and are not detected by tractography.\n    -   $C\\!-\\!D$ is not ground truth and was not detected.\n    -   Therefore, $TN = 1$.\n\nWe verify the totals: $P = TP + FN = 2 + 1 = 3$. $N = FP + TN = 2 + 1 = 3$. The total number of pairs is $P+N=6$. The classification is self-consistent.\n\nWith these values, we define and calculate the required metrics:\n-   **Sensitivity** (True Positive Rate): $Sens = \\frac{TP}{P} = \\frac{TP}{TP+FN}$\n-   **Specificity** (True Negative Rate): $Spec = \\frac{TN}{N} = \\frac{TN}{TN+FP}$\n-   **Precision** (Positive Predictive Value, PPV): $Prec = \\frac{TP}{TP+FP}$\n\nNow, we evaluate each statement.\n\n**A. The sensitivity and precision (positive predictive value) of the thresholded tractography regarding connection presence in this phantom are $2/3$ and $1/2$, respectively; low precision here is consistent with known false positives caused by crossing fiber configurations and gyral biases in streamline termination.**\n\n-   **Calculation**:\n    -   Sensitivity = $\\frac{TP}{P} = \\frac{2}{3}$.\n    -   Precision = $\\frac{TP}{TP+FP} = \\frac{2}{2+2} = \\frac{2}{4} = \\frac{1}{2}$.\n-   **Scientific Rationale**: The calculated values match the statement. A precision of $1/2$ means that $50\\%$ of the detected connections are false positives, which can be considered low. The DTI model's inability to resolve crossing fibers is a primary physical reason for tractography algorithms generating anatomically invalid pathways (false positives). While gyral bias is specific to brain anatomy, the phantom is designed to \"mimic coherent white matter tracts,\" and could easily include crossing or kissing fiber bundles that pose a similar challenge to the algorithm. The explanation is therefore a valid and well-established reason for the occurrence of false positives in DTI tractography, which in turn leads to low precision.\n\n-   **Verdict**: Correct.\n\n**B. Increasing the streamline threshold from $50$ to $100$ will necessarily increase sensitivity without affecting precision, because higher thresholds eliminate spurious streamlines while preserving true ones.**\n\n-   Let's re-evaluate the classification with a new threshold $\\geq 100$.\n-   New detected connections: Only $A\\!-\\!B$ (count $120 \\geq 100$).\n-   New Confusion Matrix:\n    -   $TP$: $\\{A\\!-\\!B\\}$. So, $TP_{new} = 1$.\n    -   $FN$: $\\{A\\!-\\!C, B\\!-\\!D\\}$. So, $FN_{new} = 2$.\n    -   $FP$: None. So, $FP_{new} = 0$.\n    -   $TN$: $\\{B\\!-\\!C, A\\!-\\!D, C\\!-\\!D\\}$. So, $TN_{new} = 3$.\n-   **New Metrics**:\n    -   New Sensitivity = $\\frac{TP_{new}}{P} = \\frac{1}{3}$. This is a *decrease* from the original $2/3$.\n    -   New Precision = $\\frac{TP_{new}}{TP_{new}+FP_{new}} = \\frac{1}{1+0} = 1$. This is an *increase* from the original $1/2$.\n-   **Analysis**: The statement claims that sensitivity will increase and precision will be unaffected. Both are false. The reason provided is also flawed; a higher threshold can eliminate both true and false positives, as happened here with the elimination of the true positive connection $A\\!-\\!C$ and the false positive connections $B\\!-\\!C$ and $A\\!-\\!D$. There is an inherent trade-off between sensitivity and specificity/precision when adjusting a detection threshold.\n\n-   **Verdict**: Incorrect.\n\n**C. Even with perfect estimation of the diffusion tensor $\\mathbf{D}$, streamline count is not proportional to axon count, due to distance-dependent propagation biases, curvature constraints, and variable tract cross-sectional areas; therefore, tractography should not be used to infer true axonal connectivity strength.**\n\n-   **Scientific Rationale**: This statement addresses a fundamental limitation of streamline tractography. The number of virtual streamlines reconstructed by an algorithm is influenced by many factors unrelated to the true underlying biology of axon count. These biases include:\n    1.  **Distance and Curvature**: Longer and more tortuous pathways have a cumulatively higher probability of a streamline terminating prematurely due to noise, partial volume effects, or exceeding an algorithmic curvature threshold.\n    2.  **Seeding Strategy**: The streamline count is highly dependent on the location and density of seed points.\n    3.  **Anatomical Geometry**: Tracts that fan out (e.g., corticospinal tract) or pass through bottlenecks will have streamline densities that do not reflect a constant axon count.\n-   These factors confound any simple relationship between streamline count and the biological \"strength\" of a connection. Even with a perfectly measured local tensor $\\mathbf{D}$, the integration process of tractography introduces these biases. The conclusion that streamline count is not a valid measure of \"true axonal connectivity strength\" is a correct and critical concept in the field of connectomics.\n\n-   **Verdict**: Correct.\n\n**D. The specificity in this setup is $4/6$ because there are $4$ true negatives, demonstrating that tractography excels at rejecting non-existing connections in this phantom.**\n\n-   **Calculation**:\n    -   Specificity = $\\frac{TN}{N} = \\frac{1}{3}$.\n-   **Analysis**: The statement claims specificity is $4/6$. This is numerically incorrect. The stated reason, \"because there are $4$ true negatives,\" is also factually incorrect; we calculated $TN = 1$. The number $4$ corresponds to the total number of detected connections ($TP+FP = 2+2=4$), which is irrelevant to true negatives or specificity. A specificity of $1/3$ indicates that the method correctly identified only $1$ out of the $3$ non-existent connections, meaning it performed poorly at rejecting non-existing connections, not that it \"excels.\"\n\n-   **Verdict**: Incorrect.\n\n**E. Directionality of connections (afferent versus efferent) can be inferred from DTI by following the principal eigenvector from source to target, so tractography can recover the polarity of anatomical pathways.**\n\n-   **Physical Principles**: The diffusion tensor $\\mathbf{D}$ is a real, symmetric $3 \\times 3$ matrix. For any eigenvector $\\mathbf{v}$ of $\\mathbf{D}$, $-\\mathbf{v}$ is also an eigenvector with the same eigenvalue. The diffusion process modeled by $E(b,\\mathbf{g}) \\approx \\exp\\!\\left(-b\\,\\mathbf{g}^{\\top}\\mathbf{D}\\,\\mathbf{g}\\right)$ is symmetric with respect to the gradient direction $\\mathbf{g}$, i.e., $E(b,\\mathbf{g}) = E(b,-\\mathbf{g})$. This physical symmetry means the measured signal contains information about the orientation (axis) of diffusion, but not its direction (polarity). The principal eigenvector indicates the axis of maximal diffusion, but it cannot distinguish between \"forward\" and \"backward\" movement along that axis. Therefore, DTI is fundamentally unable to determine the afferent vs. efferent nature of a neural pathway.\n\n-   **Verdict**: Incorrect.", "answer": "$$\\boxed{AC}$$", "id": "4877385"}]}