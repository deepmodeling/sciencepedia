{"hands_on_practices": [{"introduction": "The foundation of compressed sensing lies not merely in acquiring fewer measurements, but in designing a sampling strategy that makes the resulting artifacts manageable. A key insight is that structured undersampling creates coherent, \"ghost-like\" artifacts that are difficult to remove, while randomized sampling creates incoherent, noise-like artifacts that sparsity-promoting algorithms can effectively suppress. This practice allows you to computationally verify this fundamental principle by comparing the point spread functions (PSFs) generated by both structured and random undersampling schemes, providing a tangible understanding of why incoherent sampling is a cornerstone of CS-MRI [@problem_id:4870620].", "problem": "You are given a task grounded in the relationship between sampling in the frequency domain and aliasing in the image domain for Magnetic Resonance Imaging (MRI). Use the Discrete Fourier Transform (DFT) framework as follows.\n\nFundamental base: In two-dimensional imaging, a discrete object on an image grid, when transformed to the frequency domain by the two-dimensional Discrete Fourier Transform (DFT), yields its frequency representation. Undersampling in the frequency domain corresponds to multiplying the fully sampled frequency data by a binary sampling mask. In the image domain, this multiplication corresponds to convolution with the inverse DFT of the sampling mask, which is the point spread function (PSF). Hence, for a sampling mask, the aliasing artifacts in the image domain are characterized by the PSF. Structured, periodic sampling typically produces coherent aliasing (ghosts), while randomized sampling produces incoherent, noise-like artifacts. These are standard, well-tested facts in the foundations of medical imaging and compressed sensing.\n\nObjective: Write a program that constructs two types of frequency-domain sampling masks on a two-dimensional grid of size $N \\times N$ (with $N$ given), along the phase-encode direction (the $k_y$ axis), and compares the coherence of the aliasing ghosts induced by each mask using a PSF-based metric.\n\nDefinitions to use:\n- The two-dimensional inverse DFT (denoted $\\mathrm{IDFT}_2$) of a sampling mask yields the point spread function $p(\\mathbf{r})$, where $\\mathbf{r}$ indexes image-domain pixels. You may implement $\\mathrm{IDFT}_2$ with any normalization, as the metric below is defined by a ratio that cancels consistent scaling.\n- The magnitude of the PSF is $|p(\\mathbf{r})|$.\n- Let $p_0$ be the central pixel of the shifted PSF (i.e., after applying a shift so that the zero-frequency component is centered), and let $\\mathcal{R}$ denote the set of all pixels except the center. Define the coherence ratio of the aliasing ghosts for a mask as\n$$\nC \\;=\\; \\frac{\\max_{\\mathbf{r} \\in \\mathcal{R}} |p(\\mathbf{r})|}{\\operatorname{mean}_{\\mathbf{r} \\in \\mathcal{R}} |p(\\mathbf{r})|}.\n$$\nIf $|p(\\mathbf{r})|$ is identically zero on $\\mathcal{R}$, define $C = 0$.\n\nSampling masks to construct for each test case $(N, R)$:\n- Randomly shifted Cartesian mask: Choose a random integer shift $s$ uniformly from $\\{0, 1, \\dots, R-1\\}$, and select all phase-encode lines $k_y$ such that $(k_y - s) \\bmod R = 0$. For each selected $k_y$, include the entire line across all $k_x$ (i.e., set those rows in the mask to $1$, others to $0$). This yields a periodic set of lines with a random cyclic shift.\n- Fully random mask with matched sampling density: Let $M$ be the number of lines selected by the randomly shifted Cartesian mask for the given $(N, R)$ realization. Independently choose a set of $M$ distinct $k_y$ indices uniformly at random from $\\{0,1,\\dots,N-1\\}$, and include those full lines across all $k_x$.\n\nFor each mask, compute the PSF $p(\\mathbf{r})$ as the two-dimensional inverse DFT of the mask, apply a frequency shift so that the central lobe is at the center, exclude the center pixel, and compute the coherence ratio $C$ as above.\n\nComparison task: For each test case $(N, R)$, compute:\n- $C_{\\mathrm{shift}}$: the coherence ratio for the randomly shifted Cartesian mask.\n- $C_{\\mathrm{rand}}$: the coherence ratio for the fully random mask with matched line count.\n\nProduce a boolean result per test case indicating whether $C_{\\mathrm{rand}} < C_{\\mathrm{shift}}$.\n\nRandomness and reproducibility:\n- Use a fixed random seed $s_0 = 2025$ for the base generator.\n- For test case index $i$ starting at $0$, use seed $s_0 + i$ to generate both the shift $s$ and the random line subset for that case, ensuring reproducibility.\n\nTest suite:\n- Case $1$: $(N, R) = (64, 4)$.\n- Case $2$: $(N, R) = (64, 8)$.\n- Case $3$: $(N, R) = (64, 1)$.\n- Case $4$: $(N, R) = (60, 7)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[\\mathrm{True},\\mathrm{False},\\mathrm{True},\\mathrm{True}]$.\n- The result for each test case is the boolean indicating whether $C_{\\mathrm{rand}} < C_{\\mathrm{shift}}$ for that case, in the same order as the test suite.\n\nNo physical units are involved in this problem. Angles are not part of the computation. All numerical outputs are booleans as specified. The program must be self-contained and require no input.", "solution": "The problem requires an algorithmic comparison of aliasing artifact coherence resulting from two distinct k-space undersampling strategies in Magnetic Resonance Imaging (MRI). The foundation of this analysis is the Fourier relationship between the k-space sampling mask and the image-domain point spread function (PSF). The PSF, defined as the inverse Discrete Fourier Transform (IDFT) of the sampling mask, describes how a single point in the object spreads out in the reconstructed image. The structure of the PSF's sidelobes, which manifest as aliasing artifacts or \"ghosts,\" is dictated by the geometry of the sampling mask. A periodic, structured mask is expected to produce a PSF with sparse, high-amplitude sidelobes (coherent aliasing), while a randomized mask is expected to produce a PSF with numerous, low-amplitude, noise-like sidelobes (incoherent aliasing). This problem quantifies this coherence using a peak-to-average ratio of the PSF's sidelobe magnitudes.\n\nThe procedure is executed for each test case, which is defined by a grid-size parameter $N$ and a sampling rate parameter $R$. A unique, reproducible random seed is used for each case.\n\n**Step 1: Mask Generation**\n\nFor a given test case $(N, R)$ and its corresponding random seed, two $N \\times N$ binary sampling masks are constructed. Sampling is performed along the phase-encode direction, represented by the $k_y$ axis, meaning entire rows of the k-space grid are either fully sampled or fully skipped.\n\n1.  **Randomly Shifted Cartesian Mask ($M_{\\mathrm{shift}}$):** This mask simulates a periodically undersampled acquisition with a random starting position. A random integer shift, $s$, is chosen uniformly from the set $\\{0, 1, \\dots, R-1\\}$. A phase-encode line at index $k_y$ (where $k_y \\in \\{0, 1, \\dots, N-1\\}$) is selected if and only if it satisfies the condition $(k_y - s) \\bmod R = 0$. For every selected $k_y$, the corresponding row in the mask $M_{\\mathrm{shift}}$ is set to $1$; all other entries are $0$.\n\n2.  **Fully Random Mask ($M_{\\mathrm{rand}}$):** This mask is designed to have the same sampling density (i.e., the same total number of sampled lines) as the Cartesian mask, but with the lines chosen randomly. First, the number of lines, $M$, selected in $M_{\\mathrm{shift}}$ is counted. Then, a new set of $M$ distinct line indices is chosen uniformly at random from $\\{0, 1, \\dots, N-1\\}$. The mask $M_{\\mathrm{rand}}$ is constructed by setting the rows corresponding to these randomly chosen indices to $1$.\n\n**Step 2: Point Spread Function and Coherence Ratio Calculation**\n\nFor each mask, its corresponding PSF and coherence ratio are computed.\n\n1.  **Point Spread Function (PSF):** The two-dimensional PSF, $p(\\mathbf{r})$, is the inverse Discrete Fourier Transform of the k-space mask. To facilitate analysis of its structure, the PSF is shifted such that its main lobe, corresponding to the zero-frequency component of k-space, is located at the center of the $N \\times N$ image grid. This is accomplished computationally by applying a two-dimensional inverse Fast Fourier Transform ($\\mathrm{IDFT}_2$) followed by a circular shift (`fftshift`).\n\n2.  **Coherence Ratio ($C$):** The coherence ratio is a metric designed to quantify the \"peakiness\" of the aliasing artifacts relative to their average intensity. Let $|p(\\mathbf{r})|$ be the magnitude of the shifted PSF. The central pixel, $p_0$, represents the main lobe and is excluded from the analysis of artifacts. Let $\\mathcal{R}$ be the set of all non-central pixel locations. The coherence ratio is defined as:\n    $$\n    C \\;=\\; \\frac{\\max_{\\mathbf{r} \\in \\mathcal{R}} |p(\\mathbf{r})|}{\\operatorname{mean}_{\\mathbf{r} \\in \\mathcal{R}} |p(\\mathbf{r})|}\n    $$\n    In the specific case where a mask is fully sampled (e.g., for $R=1$), the PSF is a perfect delta function, meaning $|p(\\mathbf{r})| = 0$ for all $\\mathbf{r} \\in \\mathcal{R}$. In this scenario, the expression for $C$ becomes an indeterminate form $0/0$. The problem prescribes that in this case, $C$ shall be defined as $0$.\n\n**Step 3: Comparison and Final Output**\n\nThe core of the task is to compare the coherence of the artifacts produced by the two sampling schemes. For each test case $(N, R)$:\n\n1.  The coherence ratio for the randomly shifted Cartesian mask, $C_{\\mathrm{shift}}$, is calculated.\n2.  The coherence ratio for the fully random mask, $C_{\\mathrm{rand}}$, is calculated.\n3.  The boolean expression $C_{\\mathrm{rand}} < C_{\\mathrm{shift}}$ is evaluated. This tests the hypothesis that random sampling leads to less coherent (more noise-like) artifacts than structured, periodic sampling.\n\nThis procedure is repeated for all cases in the test suite, using a base random seed $s_0 = 2025$ and incrementing it for each subsequent test case ($s_0+i$ for case index $i$) to ensure reproducibility. The final output is a list of these boolean results. For the edge case $(N=64, R=1)$, both masks correspond to full sampling, yielding $C_{\\mathrm{shift}} = 0$ and $C_{\\mathrm{rand}} = 0$. The comparison $0 < 0$ evaluates to False. For all other cases, where $R > 1$, we expect $C_{\\mathrm{rand}} < C_{\\mathrm{shift}}$ to be True, confirming a fundamental principle of compressed sensing.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_coherence_ratio(mask):\n    \"\"\"\n    Computes the PSF and its coherence ratio for a given k-space mask.\n\n    Args:\n        mask (np.ndarray): A 2D numpy array representing the k-space sampling mask.\n\n    Returns:\n        float: The coherence ratio C.\n    \"\"\"\n    N, _ = mask.shape\n\n    # 1. Compute the PSF as the inverse DFT of the mask, then center it.\n    psf = np.fft.ifft2(mask)\n    psf_shifted = np.fft.fftshift(psf)\n    psf_mag = np.abs(psf_shifted)\n\n    # 2. Extract sidelobes by excluding the central pixel.\n    center_y, center_x = N // 2, N // 2\n    \n    # Create a boolean mask for the region of interest R (all pixels except the center).\n    roi_mask = np.ones((N, N), dtype=bool)\n    roi_mask[center_y, center_x] = False\n    sidelobes = psf_mag[roi_mask]\n\n    # 3. Handle the special case of zero sidelobes (full sampling).\n    # This also handles the potential division by zero.\n    if np.all(sidelobes == 0):\n        return 0.0\n\n    # 4. Compute the coherence ratio.\n    max_sidelobe = np.max(sidelobes)\n    mean_sidelobe = np.mean(sidelobes)\n    \n    C = max_sidelobe / mean_sidelobe\n    return C\n\ndef calculate_comparison(N, R, seed):\n    \"\"\"\n    Generates two masks, computes their coherence ratios, and compares them.\n\n    Args:\n        N (int): The grid size (N x N).\n        R (int): The Cartesian sampling rate parameter.\n        seed (int): The random seed for this test case.\n\n    Returns:\n        bool: The result of C_rand < C_shift.\n    \"\"\"\n    # Initialize a random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # --- Mask 1: Randomly Shifted Cartesian ---\n    mask_shift = np.zeros((N, N), dtype=float)\n    s = rng.integers(R)\n    ky_indices_shift = [ky for ky in range(N) if (ky - s) % R == 0]\n    mask_shift[ky_indices_shift, :] = 1.0\n\n    # --- Mask 2: Fully Random with Matched Density ---\n    M = len(ky_indices_shift)\n    mask_rand = np.zeros((N, N), dtype=float)\n    # Choose M distinct ky indices uniformly at random.\n    ky_indices_rand = rng.choice(N, size=M, replace=False)\n    mask_rand[ky_indices_rand, :] = 1.0\n\n    # --- Compute Coherence Ratios ---\n    C_shift = compute_coherence_ratio(mask_shift)\n    C_rand = compute_coherence_ratio(mask_rand)\n\n    # --- Perform Comparison ---\n    return C_rand < C_shift\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (64, 4),  # Case 1\n        (64, 8),  # Case 2\n        (64, 1),  # Case 3\n        (60, 7),  # Case 4\n    ]\n\n    base_seed = 2025\n    results = []\n\n    for i, (N, R) in enumerate(test_cases):\n        seed = base_seed + i\n        result = calculate_comparison(N, R, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Python's str(bool) outputs 'True' or 'False' which is the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "4870620"}, {"introduction": "After understanding why incoherent sampling is beneficial, the next step is to explore how we can reconstruct a high-quality image from such undersampled data. The solution lies in iterative algorithms that enforce both data consistency and sparsity in a chosen transform domain. This exercise guides you through the derivation and implementation of the complex soft-thresholding operator, the fundamental building block for promoting sparsity in many state-of-the-art reconstruction algorithms [@problem_id:4870640]. By working through its formulation as a proximal operator, you will gain a deep appreciation for its mathematical elegance and its essential role in processing complex-valued MRI data.", "problem": "You are to implement and analyze complex-valued soft-thresholding for wavelet coefficients in the context of Magnetic Resonance Imaging (MRI), using principles from compressed sensing. Consider that MRI images and their wavelet coefficients are complex-valued due to quadrature detection and phase-encoding. Compressed Sensing (CS) promotes sparsity in a transform domain, here the wavelet domain, by penalizing the sum of magnitudes of coefficients.\n\nFundamental base:\n- A complex number is written as $z = r e^{i \\phi}$ where $r = |z| \\geq 0$ is the magnitude and $\\phi = \\arg(z) \\in (-\\pi,\\pi]$ is the phase, and $i = \\sqrt{-1}$ is the imaginary unit.\n- The complex $\\ell_1$ norm of a vector $x \\in \\mathbb{C}^n$ is $\\|x\\|_1 = \\sum_{k=1}^n |x_k|$.\n- The proximal operator of a function $g$ at $y$ is defined by $\\mathrm{prox}_g(y) = \\arg\\min_x \\left( \\tfrac{1}{2}\\|x-y\\|_2^2 + g(x) \\right)$, a well-tested concept in convex optimization frequently used in CS MRI.\n\nTask:\n- Starting from the above base, derive the complex-valued soft-thresholding operator applied coefficient-wise as the proximal operator of the complex $\\ell_1$ norm. Your derivation must justify why the operator preserves phase while shrinking magnitudes to promote sparsity in the complex domain.\n- Implement a program that applies complex-valued soft-thresholding to given arrays of complex numbers representing wavelet coefficients. The program must compute, for each test case, the maximum absolute phase difference in radians between the original coefficients and the thresholded coefficients among those coefficients that remain nonzero after thresholding. If all thresholded coefficients are zero, return $0$ for that case. Angles must be measured in radians.\n\nInput specification (embedded in the program):\n- You will be given a test suite consisting of arrays of complex coefficients and nonnegative thresholds $\\tau$.\n- Apply coefficient-wise complex soft-thresholding with threshold $\\tau$ to each array.\n\nTest suite to implement:\n- Case $1$ (happy path): coefficients $\\left[ 1 + i,\\; -0.5 + 2 i,\\; 0.3 - 0.4 i,\\; 0 + 0 i \\right]$ with threshold $\\tau = 0.5$.\n- Case $2$ (boundary condition equals threshold): coefficients $\\left[ 0.5 + 0 i,\\; 0 - 0.5 i,\\; 0.3535533905932738 + 0.3535533905932738 i \\right]$ with threshold $\\tau = 0.5$.\n- Case $3$ (zero threshold): coefficients $\\left[ -2 + 3 i,\\; 4 + 0 i,\\; 0 + 5 i,\\; -1 - 1 i \\right]$ with threshold $\\tau = 0$.\n- Case $4$ (high threshold causing all zeros): coefficients $\\left[ 1 + 2 i,\\; -3 + 4 i,\\; 5 - 6 i \\right]$ with threshold $\\tau = 10$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output a single real number (a float) equal to the maximum absolute phase difference in radians as defined above. The final output must be of the form $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$.\n\nScientific realism requirements:\n- Treat the wavelet transform as a linear, unitary transform on complex images; the thresholding acts on the complex wavelet coefficients directly.\n- Justify rigorously in your derivation why preserving phase while shrinking magnitudes arises from minimizing a convex objective grounded in the proximal operator definition, not from heuristic shortcuts.\n\nAnswer format:\n- Provide a complete derivation and explanation.\n- Provide runnable code that internally defines and runs the test suite.\n- The final printed output must be a single line in the exact format specified above.", "solution": "The problem requires the derivation of the complex-valued soft-thresholding operator and its implementation to analyze its phase-preserving properties. This operator is fundamental to many compressed sensing reconstruction algorithms, including those used in MRI, where sparsity is promoted in a transform domain (e.g., wavelet) to enable undersampled acquisition.\n\nThe derivation begins with the definition of the proximal operator. For a given function $g$, its proximal operator at a point $y$ is defined as:\n$$\n\\mathrm{prox}_g(y) = \\arg\\min_x \\left( \\frac{1}{2}\\|x-y\\|_2^2 + g(x) \\right)\n$$\nIn the context of compressed sensing, the function $g(x)$ is typically a scaled $\\ell_1$ norm used to promote sparsity. For a vector of complex coefficients $x \\in \\mathbb{C}^n$, we use $g(x) = \\tau \\|x\\|_1 = \\tau \\sum_{k=1}^n |x_k|$, where $\\tau \\geq 0$ is a non-negative threshold parameter. The objective function to minimize is:\n$$\nJ(x) = \\frac{1}{2}\\|x-y\\|_2^2 + \\tau \\|x\\|_1 = \\frac{1}{2} \\sum_{k=1}^n |x_k - y_k|^2 + \\tau \\sum_{k=1}^n |x_k|\n$$\nSince the objective function is a sum of terms, each involving only a single coefficient pair $(x_k, y_k)$, the minimization is separable. We can find the optimal vector $x$ by minimizing each component's contribution to the total objective independently. Therefore, for each coefficient $k$, we solve the following minimization problem over the complex variable $x \\in \\mathbb{C}$, given the complex measurement $y \\in \\mathbb{C}$:\n$$\n\\hat{x} = \\arg\\min_{x \\in \\mathbb{C}} \\left( \\frac{1}{2} |x - y|^2 + \\tau |x| \\right)\n$$\nLet us represent the complex variables $x$ and $y$ in polar coordinates: $x = r_x e^{i\\phi_x}$ and $y = r_y e^{i\\phi_y}$, where $r_x = |x|$, $\\phi_x = \\arg(x)$, $r_y = |y|$, and $\\phi_y = \\arg(y)$. The objective function becomes:\n$$\nj(r_x, \\phi_x) = \\frac{1}{2} |r_x e^{i\\phi_x} - r_y e^{i\\phi_y}|^2 + \\tau r_x\n$$\nExpanding the squared magnitude term:\n$$\n|r_x e^{i\\phi_x} - r_y e^{i\\phi_y}|^2 = (r_x e^{i\\phi_x} - r_y e^{i\\phi_y}})(r_x e^{-i\\phi_x} - r_y e^{-i\\phi_y}}) = r_x^2 - 2 r_x r_y \\cos(\\phi_x - \\phi_y) + r_y^2\n$$\nThe objective function is thus:\n$$\nj(r_x, \\phi_x) = \\frac{1}{2} (r_x^2 - 2 r_x r_y \\cos(\\phi_x - \\phi_y) + r_y^2) + \\tau r_x\n$$\nWe seek to minimize this function with respect to the magnitude $r_x \\geq 0$ and the phase $\\phi_x \\in (-\\pi, \\pi]$. If $y = 0$, then $r_y=0$, and the objective becomes $\\frac{1}{2}r_x^2 + \\tau r_x$, which is clearly minimized at $r_x = 0$, implying $\\hat{x} = 0$.\n\nIf $y \\neq 0$ (so $r_y > 0$), we can first minimize with respect to the phase $\\phi_x$. The only term dependent on $\\phi_x$ is $-2 r_x r_y \\cos(\\phi_x - \\phi_y)$. To minimize the objective $j$, this term must be minimized, which is equivalent to maximizing $\\cos(\\phi_x - \\phi_y)$. The maximum value of the cosine function is $1$, which occurs when its argument is $0$ (or any integer multiple of $2\\pi$). This implies that the optimal phase $\\phi_x$ must be equal to the phase of the input coefficient, $\\phi_y$. This is a crucial result: the proximal operator of the complex $\\ell_1$ norm preserves the phase of the input coefficient, $\\arg(\\hat{x}) = \\arg(y)$.\n\nHaving established that $\\phi_x = \\phi_y$, we can substitute $\\cos(\\phi_x - \\phi_y) = 1$ into the objective function, which now depends only on the magnitude $r_x$:\n$$\nj(r_x) = \\frac{1}{2} (r_x^2 - 2 r_x r_y + r_y^2) + \\tau r_x = \\frac{1}{2} (r_x - r_y)^2 + \\tau r_x\n$$\nThis is the objective function for real-valued soft-thresholding, which we must minimize for $r_x \\geq 0$. This function is convex but not differentiable at $r_x = 0$. We use subgradient calculus. The subdifferential $\\partial j(r_x)$ is given by:\n$$\n\\partial j(r_x) = (r_x - r_y) + \\tau \\cdot \\partial r_x\n$$\nwhere $\\partial r_x$ is the subdifferential of the absolute value function for a non-negative variable. The minimum occurs when $0 \\in \\partial j(r_x)$.\n\nCase 1: The solution is at $r_x > 0$. Here, $\\partial r_x = \\{1\\}$, so we set the derivative to zero: $r_x - r_y + \\tau = 0 \\implies r_x = r_y - \\tau$. Since we assumed $r_x > 0$, this solution is valid only if $r_y - \\tau > 0$, i.e., $r_y > \\tau$.\n\nCase 2: The solution is at $r_x = 0$. The subdifferential is $\\partial r_x = [0, 1]$ for a non-negative variable (or more properly, the subdifferential of $\\tau |x|$ where $x$ can be positive or negative is $\\tau [-1, 1]$, and for a minimizer at $x=0$, subgradient optimality requires $y \\in \\tau [-1, 1]$ which is $|y| \\leq \\tau$). Let's re-verify with the one-sided derivative for $r_x \\ge 0$. The optimality condition at a boundary point $r_x=0$ is that the directional derivative is non-negative. $j'(0^+) = -r_y + \\tau$. For $r_x=0$ to be the minimum, we must have $j'(0^+) \\geq 0$, which means $-r_y + \\tau \\geq 0$, or $r_y \\leq \\tau$.\n\nCombining these two cases, the optimal magnitude $r_x=|\\hat{x}|$ is:\n$$\n|\\hat{x}| = \\begin{cases} r_y - \\tau, & \\text{if } r_y > \\tau \\\\ 0, & \\text{if } r_y \\leq \\tau \\end{cases}\n$$\nThis can be written compactly as $|\\hat{x}| = \\max(0, r_y - \\tau) = (|y| - \\tau)_+$.\n\nCombining the results for magnitude and phase, the complex soft-thresholding operator is:\n$$\n\\hat{x} = |\\hat{x}| e^{i\\phi_x} = \\max(0, |y| - \\tau) e^{i\\arg(y)}\n$$\nFor $y \\neq 0$, we can write $e^{i\\arg(y)} = y/|y|$. The operator can thus be expressed as:\n$$\n\\hat{x} = \\max(0, |y| - \\tau) \\frac{y}{|y|} = \\left(1 - \\frac{\\tau}{|y|}\\right)_+ y\n$$\nThis derivation rigorously shows that for any coefficient $y$ whose magnitude $|y|$ is greater than the threshold $\\tau$, the resulting coefficient $\\hat{x}$ is non-zero and has a phase identical to that of $y$. Its magnitude is shrunk by $\\tau$. If $|y| \\leq \\tau$, the coefficient is set to zero. This selective shrinkage of small coefficients is what promotes sparsity.\n\nThe computational task is to implement this operator and compute the maximum absolute phase difference between the original and thresholded coefficients for the subset of coefficients that remain non-zero. Based on the derivation, this phase difference must be identically zero in theory. The numerical computation serves as a verification of this fundamental property. For any test case where all coefficients are thresholded to zero, the maximum phase difference is defined to be $0$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements complex soft-thresholding and computes the maximum phase difference\n    for a suite of test cases, as per the problem description.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1 + 1j, -0.5 + 2j, 0.3 - 0.4j, 0 + 0j], dtype=complex), 0.5),\n        (np.array([0.5 + 0j, 0 - 0.5j, 0.3535533905932738 + 0.3535533905932738j], dtype=complex), 0.5),\n        (np.array([-2 + 3j, 4 + 0j, 0 + 5j, -1 - 1j], dtype=complex), 0.0),\n        (np.array([1 + 2j, -3 + 4j, 5 - 6j], dtype=complex), 10.0),\n    ]\n\n    results = []\n\n    for y, tau in test_cases:\n        # Complex soft-thresholding operator: S_tau(y)\n        # S_tau(y_k) = max(0, |y_k| - tau) * (y_k / |y_k|)\n        # This is numerically robustly implemented as:\n        # x = y * scale, where scale = max(0, |y|-tau) / |y|\n        \n        magnitudes = np.abs(y)\n        \n        # Calculate the shrunk magnitudes.\n        shrunk_magnitudes = np.maximum(0, magnitudes - tau)\n        \n        # Calculate the thresholded coefficients.\n        # We use np.divide to handle division by zero safely.\n        # Where magnitude is 0, the numerator shrunk_magnitudes is also 0 (since tau>=0).\n        # We specify out=np.zeros_like(...) so that 0/0 results in 0.\n        scale = np.divide(shrunk_magnitudes, magnitudes, \n                          out=np.zeros_like(magnitudes, dtype=float), \n                          where=(magnitudes != 0))\n        \n        x = y * scale\n\n        # Identify the coefficients that remain non-zero after thresholding.\n        # A small tolerance is used for floating point comparisons.\n        nonzero_mask = np.abs(x) > 1e-15\n\n        if not np.any(nonzero_mask):\n            # If all thresholded coefficients are zero, the max phase difference is 0.\n            max_phase_diff = 0.0\n        else:\n            # Select the original and thresholded coefficients that are non-zero.\n            y_nonzero = y[nonzero_mask]\n            x_nonzero = x[nonzero_mask]\n            \n            # Calculate the phase difference.\n            # np.angle(z2 * np.conj(z1)) gives angle(z2) - angle(z1) in (-pi, pi].\n            # This is numerically more stable than np.angle(z2) - np.angle(z1).\n            phase_diffs = np.angle(x_nonzero * np.conj(y_nonzero))\n            \n            # Find the maximum absolute phase difference.\n            max_phase_diff = np.max(np.abs(phase_diffs))\n            \n        results.append(max_phase_diff)\n\n    # Format the results into the required output string.\n    # The str() conversion ensures standard float representation.\n    # The derived theory predicts all results will be 0.0\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "4870640"}, {"introduction": "Having established the principles of incoherent sampling and the mechanics of the sparsity-promoting soft-thresholding operator, we can now integrate these components into a complete, powerful reconstruction framework. The Alternating Direction Method of Multipliers (ADMM) is a widely used algorithm that elegantly splits the complex CS-MRI optimization problem into simpler, solvable sub-problems, one of which is precisely the soft-thresholding operation you explored previously. This final practice challenges you to derive the ADMM update equations from first principles and execute a single iteration for a concrete numerical example, demystifying the step-by-step process of an advanced iterative image reconstruction algorithm [@problem_id:4870662].", "problem": "Consider a compressed sensing Magnetic Resonance Imaging (MRI) reconstruction problem in which the unknown image vector is $x \\in \\mathbb{R}^{N}$, the k-space data are $y \\in \\mathbb{R}^{N}$, the undersampling mask is a diagonal selector $M \\in \\mathbb{R}^{N \\times N}$, and the Fourier encoding operator is the unitary Discrete Fourier Transform (DFT) $F \\in \\mathbb{R}^{N \\times N}$ (assume real-valued for the specific case below). Let the sparsifying transform be $\\Psi \\in \\mathbb{R}^{N \\times N}$ and suppose $\\Psi$ is orthonormal. The regularized reconstruction seeks to minimize the objective\n$$\n\\min_{x \\in \\mathbb{R}^{N}} \\; \\frac{\\beta}{2} \\| M F x - y \\|_{2}^{2} + \\lambda \\| \\Psi x \\|_{1},\n$$\nwhere $\\beta > 0$ and $\\lambda > 0$ are given weights. Introduce the splitting variable $z \\in \\mathbb{R}^{N}$ enforcing the constraint $z = \\Psi x$, and solve the problem using the Alternating Direction Method of Multipliers (ADMM). Use the scaled dual variable $u \\in \\mathbb{R}^{N}$ and penalty parameter $\\rho > 0$. Derive from first principles (starting from the augmented Lagrangian definition for ADMM and standard properties of unitary and orthonormal transforms) the closed-form expressions for the iterative updates $x^{k+1}$, $z^{k+1}$, and $u^{k+1}$. Explain why the $z$-update reduces to a component-wise soft-thresholding operation and why the $u$-update is a dual ascent.\n\nThen, specialize to the following concrete, fully specified instance:\n- Dimension $N = 2$.\n- The unitary $2$-point DFT is\n$$\nF = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}.\n$$\n- The mask selects only the first k-space component,\n$$\nM = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}.\n$$\n- The sparsifying transform is the identity, $\\Psi = I$.\n- Parameters are $\\beta = 1$, $\\rho = 2$, $\\lambda = 0.5$.\n- The measured k-space data are $y = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$.\n- At iteration $k$, the variables are $z^{k} = \\begin{bmatrix} 1 \\\\ -0.5 \\end{bmatrix}$ and $u^{k} = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix}$.\n\nUsing your derived update rules and the given numerical values, compute the second component of the updated dual variable $u^{k+1}$ as an exact, closed-form real expression. Do not approximate and do not round; report the exact value with radicals if they appear. The final answer must be a single expression with no units.", "solution": "The problem is to derive the Alternating Direction Method of Multipliers (ADMM) update steps for a compressed sensing MRI reconstruction problem and then to compute a specific value for a given instance.\n\n### Step 1: Problem Validation\n\nFirst, the givens of the problem are extracted verbatim.\n- Unknown image vector: $x \\in \\mathbb{R}^{N}$\n- k-space data: $y \\in \\mathbb{R}^{N}$\n- Undersampling mask: $M \\in \\mathbb{R}^{N \\times N}$ (diagonal selector)\n- Fourier encoding operator: $F \\in \\mathbb{R}^{N \\times N}$ (unitary DFT, real-valued)\n- Sparsifying transform: $\\Psi \\in \\mathbb{R}^{N \\times N}$ (orthonormal)\n- Objective function: $\\min_{x \\in \\mathbb{R}^{N}} \\; \\frac{\\beta}{2} \\| M F x - y \\|_{2}^{2} + \\lambda \\| \\Psi x \\|_{1}$\n- Parameters: $\\beta > 0$, $\\lambda > 0$\n- ADMM formulation:\n    - Splitting variable: $z = \\Psi x$\n    - Scaled dual variable: $u \\in \\mathbb{R}^{N}$\n    - Penalty parameter: $\\rho > 0$\n- Specific instance:\n    - $N = 2$\n    - $F = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$\n    - $M = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$\n    - $\\Psi = I$\n    - $\\beta = 1$, $\\rho = 2$, $\\lambda = 0.5$\n    - $y = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$\n    - $z^{k} = \\begin{bmatrix} 1 \\\\ -0.5 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ -1/2 \\end{bmatrix}$\n    - $u^{k} = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix} = \\begin{bmatrix} 1/5 \\\\ -1/10 \\end{bmatrix}$\n- Task: Compute the second component of the updated dual variable $u^{k+1}$.\n\nThe problem is scientifically grounded, representing a standard application of ADMM to compressed sensing, a core topic in medical imaging. It is well-posed, with all variables, constants, and matrices properly defined, and the objective function is convex, ensuring a minimum exists. The problem is self-contained, objective, and provides all necessary information for a unique solution to the posed calculation. The given matrices and values are dimensionally consistent. There are no contradictions, ambiguities, or factual errors. The problem is deemed valid.\n\n### Step 2: Derivation of ADMM Update Rules\n\nThe original problem is rewritten as a constrained optimization problem by introducing the splitting variable $z = \\Psi x$:\n$$ \\min_{x, z} \\frac{\\beta}{2} \\| M F x - y \\|_{2}^{2} + \\lambda \\| z \\|_{1} \\quad \\text{subject to} \\quad \\Psi x - z = 0 $$\nThe scaled-form augmented Lagrangian $L_{\\rho}(x, z, u)$ for this problem is:\n$$ L_{\\rho}(x, z, u) = \\frac{\\beta}{2} \\| M F x -y \\|_{2}^{2} + \\lambda \\| z \\|_{1} + \\frac{\\rho}{2} \\| \\Psi x - z + u \\|_{2}^{2} - \\frac{\\rho}{2} \\| u \\|_{2}^{2} $$\nADMM iteratively minimizes this Lagrangian with respect to $x$ and $z$, followed by an update of the dual variable $u$.\n\n**1. The $x$-update:**\nThe update for $x$ is found by minimizing $L_{\\rho}$ with respect to $x$, holding $z$ and $u$ fixed at their values from iteration $k$:\n$$ x^{k+1} = \\arg\\min_{x} L_{\\rho}(x, z^k, u^k) = \\arg\\min_{x} \\left( \\frac{\\beta}{2} \\| M F x - y \\|_{2}^{2} + \\frac{\\rho}{2} \\| \\Psi x - z^k + u^k \\|_{2}^{2} \\right) $$\nThis is a least-squares problem. The minimum is found by setting the gradient with respect to $x$ to zero. The gradient is:\n$$ \\nabla_x L_{\\rho} = \\beta F^T M^T (M F x - y) + \\rho \\Psi^T (\\Psi x - z^k + u^k) = 0 $$\nSince $M$ is a diagonal selector, $M^T=M$ and $M^2=M$. Since $\\Psi$ is orthonormal, $\\Psi^T \\Psi = I$.\n$$ \\beta F^T M F x + \\rho x = \\beta F^T M y + \\rho \\Psi^T(z^k - u^k) $$\n$$ (\\beta F^T M F + \\rho I) x = \\beta F^T M y + \\rho \\Psi^T(z^k - u^k) $$\nThe matrix $(\\beta F^T M F + \\rho I)$ is positive definite and thus invertible. The closed-form solution for $x^{k+1}$ is:\n$$ x^{k+1} = (\\beta F^T M F + \\rho I)^{-1} \\left( \\beta F^T M y + \\rho \\Psi^T(z^k - u^k) \\right) $$\n\n**2. The $z$-update:**\nThe update for $z$ is found by minimizing $L_{\\rho}$ with respect to $z$, using the newly computed $x^{k+1}$ and the previous $u^k$:\n$$ z^{k+1} = \\arg\\min_{z} L_{\\rho}(x^{k+1}, z, u^k) = \\arg\\min_{z} \\left( \\lambda \\| z \\|_{1} + \\frac{\\rho}{2} \\| \\Psi x^{k+1} - z + u^k \\|_{2}^{2} \\right) $$\nLet $v = \\Psi x^{k+1} + u^k$. The minimization problem is:\n$$ z^{k+1} = \\arg\\min_{z} \\left( \\lambda \\| z \\|_{1} + \\frac{\\rho}{2} \\| z - v \\|_{2}^{2} \\right) $$\nThis expression is separable, meaning we can minimize for each component $z_i$ independently:\n$$ z_i^{k+1} = \\arg\\min_{z_i} \\left( \\lambda |z_i| + \\frac{\\rho}{2} (z_i - v_i)^2 \\right) $$\nThis is the well-known proximal operator of the L1-norm, whose solution is the soft-thresholding function, denoted by $\\mathcal{S}_{\\tau}(\\cdot)$, where the threshold is $\\tau = \\lambda/\\rho$.\nThe operator is defined component-wise as $z_i^{k+1} = \\mathcal{S}_{\\lambda/\\rho}(v_i) = \\text{sgn}(v_i) \\max(|v_i| - \\lambda/\\rho, 0)$. In vector form:\n$$ z^{k+1} = \\mathcal{S}_{\\lambda/\\rho}(\\Psi x^{k+1} + u^k) $$\nThis is why the $z$-update reduces to a component-wise soft-thresholding operation.\n\n**3. The $u$-update:**\nThe update for the scaled dual variable $u$ is a gradient ascent step on the dual problem. The update rule is given by:\n$$ u^{k+1} = u^k + (\\Psi x^{k+1} - z^{k+1}) $$\nThe term $r^{k+1} = \\Psi x^{k+1} - z^{k+1}$ is the primal residual at iteration $k+1$. The update moves the dual variable in the direction of the constraint violation, which is characteristic of dual ascent methods.\n\n### Step 3: Numerical Computation\n\nWe now specialize to the given instance and compute the second component of $u^{k+1}$.\nThe parameters are: $N=2$, $\\beta=1$, $\\rho=2$, $\\lambda=0.5$, $\\Psi=I$.\n$F = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}$, $M = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}$, $y = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$, $z^{k} = \\begin{bmatrix} 1 \\\\ -0.5 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ -1/2 \\end{bmatrix}$, $u^{k} = \\begin{bmatrix} 0.2 \\\\ -0.1 \\end{bmatrix} = \\begin{bmatrix} 1/5 \\\\ -1/10 \\end{bmatrix}$.\n\nThe required value is $(u^{k+1})_2$, where $u^{k+1} = u^k + x^{k+1} - z^{k+1}$ (since $\\Psi=I$).\nThis requires computing $x^{k+1}$ and $z^{k+1}$.\n\n**A. Compute $x^{k+1}$**\nThe update is $x^{k+1} = A^{-1} b$, with $A = \\beta F^T M F + \\rho I$ and $b = \\beta F^T M y + \\rho (z^k - u^k)$.\nFirst, compute the matrix $A$:\n$F$ is real and symmetric, so $F^T=F$.\n$M F = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix} \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix}$.\n$F M F = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix} \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 0 & 0 \\end{bmatrix} = \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}$.\n$A = 1 \\cdot \\frac{1}{2}\\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} + 2 \\cdot \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 1/2 & 1/2 \\\\ 1/2 & 1/2 \\end{bmatrix} + \\begin{bmatrix} 2 & 0 \\\\ 0 & 2 \\end{bmatrix} = \\begin{bmatrix} 5/2 & 1/2 \\\\ 1/2 & 5/2 \\end{bmatrix} = \\frac{1}{2}\\begin{bmatrix} 5 & 1 \\\\ 1 & 5 \\end{bmatrix}$.\nThe inverse is $A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A) = \\frac{1}{(5/2)^2 - (1/2)^2} \\begin{bmatrix} 5/2 & -1/2 \\\\ -1/2 & 5/2 \\end{bmatrix} = \\frac{1}{24/4} \\begin{bmatrix} 5/2 & -1/2 \\\\ -1/2 & 5/2 \\end{bmatrix} = \\frac{1}{6} \\frac{1}{2} \\begin{bmatrix} 5 & -1 \\\\ -1 & 5 \\end{bmatrix} = \\frac{1}{12}\\begin{bmatrix} 5 & -1 \\\\ -1 & 5 \\end{bmatrix}$.\n\nNext, compute the vector $b$:\n$M y = \\begin{bmatrix} 1 & 0 \\\\ 0 & 0 \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$.\n$F M y = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}\\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} \\sqrt{2} \\\\ \\sqrt{2} \\end{bmatrix}$.\n$z^k - u^k = \\begin{bmatrix} 1 \\\\ -1/2 \\end{bmatrix} - \\begin{bmatrix} 1/5 \\\\ -1/10 \\end{bmatrix} = \\begin{bmatrix} 4/5 \\\\ -5/10 + 1/10 \\end{bmatrix} = \\begin{bmatrix} 4/5 \\\\ -4/10 \\end{bmatrix} = \\begin{bmatrix} 4/5 \\\\ -2/5 \\end{bmatrix}$.\n$b = 1 \\cdot \\begin{bmatrix} \\sqrt{2} \\\\ \\sqrt{2} \\end{bmatrix} + 2 \\cdot \\begin{bmatrix} 4/5 \\\\ -2/5 \\end{bmatrix} = \\begin{bmatrix} \\sqrt{2} + 8/5 \\\\ \\sqrt{2} - 4/5 \\end{bmatrix}$.\n\nNow, $x^{k+1} = A^{-1}b$:\n$x^{k+1} = \\frac{1}{12}\\begin{bmatrix} 5 & -1 \\\\ -1 & 5 \\end{bmatrix} \\begin{bmatrix} \\sqrt{2} + 8/5 \\\\ \\sqrt{2} - 4/5 \\end{bmatrix} = \\frac{1}{12} \\begin{bmatrix} 5(\\sqrt{2} + 8/5) - (\\sqrt{2} - 4/5) \\\\ -(\\sqrt{2} + 8/5) + 5(\\sqrt{2} - 4/5) \\end{bmatrix}$\n$x^{k+1} = \\frac{1}{12} \\begin{bmatrix} 5\\sqrt{2} + 8 - \\sqrt{2} + 4/5 \\\\ -\\sqrt{2} - 8/5 + 5\\sqrt{2} - 4 \\end{bmatrix} = \\frac{1}{12} \\begin{bmatrix} 4\\sqrt{2} + 44/5 \\\\ 4\\sqrt{2} - 28/5 \\end{bmatrix} = \\begin{bmatrix} \\frac{\\sqrt{2}}{3} + \\frac{11}{15} \\\\ \\frac{\\sqrt{2}}{3} - \\frac{7}{15} \\end{bmatrix}$.\n\n**B. Compute $z^{k+1}$**\nThe update is $z^{k+1} = \\mathcal{S}_{\\lambda/\\rho}(x^{k+1} + u^k)$.\nThe threshold is $\\tau = \\lambda/\\rho = 0.5/2 = 0.25 = 1/4$.\nLet $v = x^{k+1} + u^k$. We need its second component, $v_2$.\n$v_2 = (x^{k+1})_2 + (u^k)_2 = \\left(\\frac{\\sqrt{2}}{3} - \\frac{7}{15}\\right) + \\left(-\\frac{1}{10}\\right)$.\n$v_2 = \\frac{10\\sqrt{2}}{30} - \\frac{14}{30} - \\frac{3}{30} = \\frac{10\\sqrt{2} - 17}{30}$.\nTo apply the soft-thresholding operator, we check the magnitude of $v_2$.\n$10\\sqrt{2} \\approx 10 \\times 1.414 = 14.14$. So, $v_2 \\approx (14.14 - 17)/30 = -2.86/30 \\approx -0.095$.\nThe threshold is $\\tau = 1/4 = 0.25$.\nSince $|v_2| \\approx 0.095 < 0.25$, $v_2$ is in the \"dead zone\" of the soft-thresholding operator.\nTo be rigorous, we compare $|v_2| = \\frac{17 - 10\\sqrt{2}}{30}$ with $\\tau = \\frac{1}{4} = \\frac{7.5}{30}$.\nWe compare $17 - 10\\sqrt{2}$ with $7.5$, which is equivalent to comparing $9.5$ with $10\\sqrt{2}$.\nSquaring both sides, we compare $9.5^2 = 90.25$ with $(10\\sqrt{2})^2 = 200$.\nSince $90.25 < 200$, we have $9.5 < 10\\sqrt{2}$, which implies $|v_2| < \\tau$.\nTherefore, $(z^{k+1})_2 = \\mathcal{S}_{\\tau}(v_2) = 0$.\n\n**C. Compute $(u^{k+1})_2$**\nThe update rule is $(u^{k+1})_2 = (u^k)_2 + (x^{k+1})_2 - (z^{k+1})_2$.\nPlugging in the computed values:\n$(u^{k+1})_2 = -\\frac{1}{10} + \\left(\\frac{\\sqrt{2}}{3} - \\frac{7}{15}\\right) - 0$.\n$(u^{k+1})_2 = -\\frac{3}{30} + \\frac{10\\sqrt{2}}{30} - \\frac{14}{30}$.\n$(u^{k+1})_2 = \\frac{10\\sqrt{2} - 3 - 14}{30} = \\frac{10\\sqrt{2} - 17}{30}$.\n\nThe final requested value is the second component of $u^{k+1}$, which is an exact, closed-form real expression.", "answer": "$$ \\boxed{\\frac{10\\sqrt{2} - 17}{30}} $$", "id": "4870662"}]}