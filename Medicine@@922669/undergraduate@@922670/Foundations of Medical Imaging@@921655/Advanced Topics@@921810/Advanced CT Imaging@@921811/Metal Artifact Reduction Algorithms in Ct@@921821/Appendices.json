{"hands_on_practices": [{"introduction": "A critical first step in nearly all modern Metal Artifact Reduction (MAR) algorithms is to accurately identify which parts of an image contain metal. This exercise [@problem_id:4900160] guides you through building a probabilistic metal mask using a Naive Bayes classifier, a fundamental technique in machine learning. By combining multiple features like voxel intensity, local image gradient, and proximity to known implants, you will learn to compute the probability that any given voxel is metallic, forming the basis for subsequent correction steps.", "problem": "You are designing a probabilistic metal mask as part of a Metal Artifact Reduction (MAR) pipeline in Computed Tomography (CT). Using a Bayesian classifier, you classify each voxel as metal or non-metal based on a feature vector consisting of intensity in Hounsfield Units (HU), image gradient magnitude in HU per millimeter, and proximity in millimeters to known high-attenuation structures (e.g., dental fillings, hip prostheses). You must formalize the classification using Bayes’ theorem and compute the posterior probability that a voxel contains metal.\n\nAssume the following:\n\n- Classes: metal, denoted by the label $M$, and non-metal, denoted by the label $N$.\n- Prior probabilities: $\\mathbb{P}(M)=0.03$ and $\\mathbb{P}(N)=0.97$.\n- Likelihood model: Given the class, the three features are conditionally independent and each feature follows a normal distribution (Gaussian) with the specified class-dependent mean and standard deviation.\n- Feature definitions and units:\n  1. Intensity $I$ in Hounsfield Units (HU).\n  2. Gradient magnitude $G$ in HU per millimeter.\n  3. Proximity $D$ in millimeters.\n\nClass-conditional Gaussian parameters (means and standard deviations) for each feature are:\n- For $M$ (metal):\n  - $I \\sim \\mathcal{N}(\\mu_{I|M}=3500,\\ \\sigma_{I|M}=400)$,\n  - $G \\sim \\mathcal{N}(\\mu_{G|M}=1200,\\ \\sigma_{G|M}=400)$,\n  - $D \\sim \\mathcal{N}(\\mu_{D|M}=0.5,\\ \\sigma_{D|M}=0.5)$.\n- For $N$ (non-metal):\n  - $I \\sim \\mathcal{N}(\\mu_{I|N}=300,\\ \\sigma_{I|N}=600)$,\n  - $G \\sim \\mathcal{N}(\\mu_{G|N}=100,\\ \\sigma_{G|N}=100)$,\n  - $D \\sim \\mathcal{N}(\\mu_{D|N}=12,\\ \\sigma_{D|N}=6)$.\n\nYour task is to:\n- Starting from Bayes’ theorem and the stated modeling assumptions, derive the posterior probability $\\mathbb{P}(M \\mid I,G,D)$ for a voxel with features $(I,G,D)$.\n- Implement a program that evaluates $\\mathbb{P}(M \\mid I,G,D)$ for each of the specified test cases and returns a binary detection decision for the presence of a metal trace, defined as $1$ if $\\mathbb{P}(M \\mid I,G,D) \\ge 0.5$ and $0$ otherwise.\n- All numerical answers must be expressed as floating point numbers. The posterior probabilities must be rounded to $6$ decimal places. The detection decisions must be integers in $\\{0,1\\}$.\n\nUse the following test suite of feature vectors $(I,G,D)$ with units:\n- Case $1$: $(4200,\\ 1800,\\ 0.2)$.\n- Case $2$: $(30,\\ 20,\\ 25)$.\n- Case $3$: $(1200,\\ 200,\\ 18)$.\n- Case $4$: $(900,\\ 700,\\ 2.0)$.\n- Case $5$: $(3500,\\ 0,\\ 5)$.\n- Case $6$: $(500,\\ 150,\\ 0.1)$.\n\nCompute:\n- The posterior probabilities $\\mathbb{P}(M \\mid I,G,D)$ for the six cases as floats rounded to $6$ decimal places.\n- The detection decisions as integers in $\\{0,1\\}$ using the threshold rule stated above.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with two lists: the first containing the six posterior probabilities in order, and the second containing the six detection decisions in order. For example, the required output format is $[[p_1,p_2,p_3,p_4,p_5,p_6],[d_1,d_2,d_3,d_4,d_5,d_6]]$ where each $p_i$ is a float rounded to $6$ decimal places and each $d_i$ is an integer equal to $0$ or $1$.", "solution": "The problem is reviewed and found to be valid. It is a well-posed Bayesian classification problem grounded in established principles of medical image analysis and statistical pattern recognition. All necessary data, including prior probabilities and class-conditional likelihood models, are provided, and the objective is clearly defined.\n\nThe task is to compute the posterior probability that a voxel contains metal, $\\mathbb{P}(M \\mid I,G,D)$, given a feature vector $(I,G,D)$ representing intensity, gradient magnitude, and proximity. The classification is performed using a Naive Bayes classifier.\n\nAccording to Bayes' theorem, the posterior probability of class $M$ (metal) given the evidence $(I,G,D)$ is:\n$$\n\\mathbb{P}(M \\mid I,G,D) = \\frac{\\mathbb{P}(I,G,D \\mid M) \\mathbb{P}(M)}{\\mathbb{P}(I,G,D)}\n$$\nThe term in the denominator, $\\mathbb{P}(I,G,D)$, is the marginal probability of observing the evidence, which can be expanded using the law of total probability over the two classes, $M$ (metal) and $N$ (non-metal):\n$$\n\\mathbb{P}(I,G,D) = \\mathbb{P}(I,G,D \\mid M) \\mathbb{P}(M) + \\mathbb{P}(I,G,D \\mid N) \\mathbb{P}(N)\n$$\nSubstituting this into the Bayes' formula yields:\n$$\n\\mathbb{P}(M \\mid I,G,D) = \\frac{\\mathbb{P}(I,G,D \\mid M) \\mathbb{P}(M)}{\\mathbb{P}(I,G,D \\mid M) \\mathbb{P}(M) + \\mathbb{P}(I,G,D \\mid N) \\mathbb{P}(N)}\n$$\nThe problem states that the features $I$, $G$, and $D$ are conditionally independent given the class. This is the \"naive\" assumption in the Naive Bayes classifier. This allows us to express the joint class-conditional likelihoods as the product of the individual feature likelihoods:\n$$\n\\mathbb{P}(I,G,D \\mid C) = \\mathbb{P}(I \\mid C) \\cdot \\mathbb{P}(G \\mid C) \\cdot \\mathbb{P}(D \\mid C) \\quad \\text{for } C \\in \\{M, N\\}\n$$\nEach feature's likelihood, $\\mathbb{P}(x \\mid C)$, is modeled by a normal (Gaussian) distribution, $\\mathcal{N}(\\mu_{x|C}, \\sigma_{x|C})$. The probability density function (PDF) for a normal distribution is:\n$$\nf(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)\n$$\nDirect computation of the posterior probability can be susceptible to numerical underflow, as the product of small likelihood values can become zero in floating-point arithmetic. A more stable approach is to work with log-probabilities. Let's define a score for each class, $S_C$, as the logarithm of the joint probability of the class and the evidence:\n$$\nS_C = \\log\\left( \\mathbb{P}(I,G,D \\mid C) \\mathbb{P}(C) \\right) = \\log\\mathbb{P}(I,G,D \\mid C) + \\log\\mathbb{P}(C)\n$$\nUsing the conditional independence assumption, this expands to:\n$$\nS_C = \\sum_{x \\in \\{I,G,D\\}} \\log\\mathbb{P}(x \\mid C) + \\log\\mathbb{P}(C)\n$$\nThe logarithm of the Gaussian PDF is:\n$$\n\\log f(x; \\mu, \\sigma) = -\\log(\\sigma) - \\frac{1}{2}\\log(2\\pi) - \\frac{(x - \\mu)^2}{2\\sigma^2}\n$$\nThe posterior probability $\\mathbb{P}(M \\mid I,G,D)$ can be expressed in terms of the scores $S_M$ and $S_N$:\n$$\n\\mathbb{P}(M \\mid I,G,D) = \\frac{e^{S_M}}{e^{S_M} + e^{S_N}}\n$$\nTo further improve numerical stability, this can be rearranged as:\n$$\n\\mathbb{P}(M \\mid I,G,D) = \\frac{1}{1 + \\frac{e^{S_N}}{e^{S_M}}} = \\frac{1}{1 + e^{S_N - S_M}}\n$$\nThis is the logistic sigmoid function applied to the difference of scores, which is robust against both underflow and overflow.\n\nThe detection decision is based on a threshold of $0.5$. A voxel is classified as metal if $\\mathbb{P}(M \\mid I,G,D) \\ge 0.5$. This condition is equivalent to:\n$$\n\\frac{1}{1 + e^{S_N - S_M}} \\ge 0.5 \\implies 1 \\ge 0.5(1 + e^{S_N - S_M}) \\implies 2 \\ge 1 + e^{S_N - S_M} \\implies 1 \\ge e^{S_N - S_M}\n$$\nTaking the natural logarithm of both sides, we get:\n$$\n\\log(1) \\ge S_N - S_M \\implies 0 \\ge S_N - S_M \\implies S_M \\ge S_N\n$$\nThis is the maximum a posteriori (MAP) decision rule: we select the class with the higher score.\n\nThe implementation will proceed as follows:\n1.  Define the means, standard deviations, and prior probabilities for both classes ($M$ and $N$) as given.\n2.  Create a function to calculate the log-PDF of a Gaussian distribution for a given value $x$, mean $\\mu$, and standard deviation $\\sigma$.\n3.  For each test case vector $(I,G,D)$:\n    a. Calculate the score $S_M$ by summing the log-PDFs of $I$, $G$, and $D$ using metal-class parameters, and adding the log of the prior $\\mathbb{P}(M)$.\n    b. Similarly, calculate the score $S_N$ for the non-metal class.\n    c. Compute the posterior probability $\\mathbb{P}(M \\mid I,G,D)$ using the formula $1 / (1 + e^{S_N - S_M})$.\n    d. Round the posterior probability to $6$ decimal places.\n    e. Determine the detection decision: $1$ if the posterior is $\\ge 0.5$, and $0$ otherwise.\n4.  Collect the computed probabilities and decisions into two separate lists.\n5.  Format the final output as a string representing a list of these two lists.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the posterior probability of a voxel being metal and makes a binary\n    detection decision using a Naive Bayes classifier.\n    \"\"\"\n\n    # Class-conditional parameters and priors from the problem statement\n    params = {\n        'M': {  # Metal\n            'prior': 0.03,\n            'I': {'mu': 3500, 'sigma': 400},\n            'G': {'mu': 1200, 'sigma': 400},\n            'D': {'mu': 0.5, 'sigma': 0.5}\n        },\n        'N': {  # Non-metal\n            'prior': 0.97,\n            'I': {'mu': 300, 'sigma': 600},\n            'G': {'mu': 100, 'sigma': 100},\n            'D': {'mu': 12, 'sigma': 6}\n        }\n    }\n\n    # Test cases: (I, G, D)\n    test_cases = [\n        (4200.0, 1800.0, 0.2),\n        (30.0, 20.0, 25.0),\n        (1200.0, 200.0, 18.0),\n        (900.0, 700.0, 2.0),\n        (3500.0, 0.0, 5.0),\n        (500.0, 150.0, 0.1)\n    ]\n\n    features = ['I', 'G', 'D']\n    \n    def log_gaussian_pdf(x, mu, sigma):\n        \"\"\"\n        Calculates the logarithm of the Gaussian Probability Density Function.\n        \"\"\"\n        # Ensure sigma is not zero to avoid division errors\n        if sigma == 0:\n            return -np.inf\n        log_pdf = -np.log(sigma * np.sqrt(2 * np.pi)) - 0.5 * ((x - mu) / sigma) ** 2\n        return log_pdf\n\n    posterior_probabilities = []\n    detection_decisions = []\n\n    for case_values in test_cases:\n        case_dict = dict(zip(features, case_values))\n        \n        # Calculate scores S_M and S_N\n        log_prob_m = np.log(params['M']['prior'])\n        log_prob_n = np.log(params['N']['prior'])\n\n        for feat in features:\n            val = case_dict[feat]\n            \n            # Add log-likelihood for Metal class\n            mu_m = params['M'][feat]['mu']\n            sigma_m = params['M'][feat]['sigma']\n            log_prob_m += log_gaussian_pdf(val, mu_m, sigma_m)\n            \n            # Add log-likelihood for Non-metal class\n            mu_n = params['N'][feat]['mu']\n            sigma_n = params['N'][feat]['sigma']\n            log_prob_n += log_gaussian_pdf(val, mu_n, sigma_n)\n\n        # Calculate posterior probability for Metal class using the numerically stable formula\n        # P(M|x) = 1 / (1 + exp(S_N - S_M))\n        score_diff = log_prob_n - log_prob_m\n        if score_diff > 700: # Avoid overflow in np.exp\n            posterior_m = 0.0\n        else:\n            posterior_m = 1.0 / (1.0 + np.exp(score_diff))\n        \n        # Round the posterior probability to 6 decimal places\n        rounded_posterior = round(posterior_m, 6)\n        \n        # Apply threshold for detection decision\n        decision = 1 if rounded_posterior >= 0.5 else 0\n        \n        posterior_probabilities.append(rounded_posterior)\n        detection_decisions.append(decision)\n\n    # Format the final output string exactly as required\n    prob_str = ','.join([f\"{p:.6f}\" for p in posterior_probabilities])\n    dec_str = ','.join(map(str, detection_decisions))\n    \n    print(f\"[[{prob_str}],[{dec_str}]]\")\n\nsolve()\n```", "id": "4900160"}, {"introduction": "Once metal-corrupted projections are identified, the corrupted data within the sinogram must be replaced or \"inpainted.\" This practice [@problem_id:4900085] introduces a foundational inpainting technique based on directional interpolation. You will derive and apply a method to estimate a missing sinogram value by minimizing a smoothness functional, which intelligently weighs information from neighboring data points based on the local orientation of sinogram structures, providing a principled way to fill data gaps.", "problem": "A parallel-beam computed tomography (CT) system acquires line integrals of the linear attenuation coefficient via the Radon transform, producing a two-dimensional sinogram indexed by projection angle $\\theta$ and detector coordinate $t$. A small sinogram patch around a fixed location $(\\theta_{1}, t_{1})$ is corrupted by high-attenuation metal, leaving the center sample $s(\\theta_{1}, t_{1})$ unknown while its four axis-aligned neighbors $s(\\theta_{1}, t_{1}\\pm \\Delta t)$ and $s(\\theta_{1}\\pm \\Delta \\theta, t_{1})$ remain reliable. To reduce metal-induced artifacts, consider a directional interpolation that minimizes a local anisotropic smoothness functional constructed from sinogram gradients.\n\nUse the following foundations:\n\n- The sinogram encodes line integrals: $s(\\theta, t) = \\int \\mu(x, y) \\,\\mathrm{d}\\ell$, where $\\mu$ is the linear attenuation coefficient and $\\mathrm{d}\\ell$ integrates along the ray defined by $(\\theta, t)$.\n- Local smoothness can be enforced by penalizing squared directional differences along the axes $(\\theta, t)$ with weights determined by local sinogram gradients estimated from reliable neighbor data.\n\nLet the unknown center value be denoted by $x := s(\\theta_{1}, t_{1})$. Define discrete central-difference estimates of the local sinogram gradients at $(\\theta_{1}, t_{1})$ using only reliable samples:\n$$\ng_{t} \\approx \\frac{s(\\theta_{1}, t_{1}+\\Delta t) - s(\\theta_{1}, t_{1}-\\Delta t)}{2\\,\\Delta t},\\quad\ng_{\\theta} \\approx \\frac{s(\\theta_{1}+\\Delta \\theta, t_{1}) - s(\\theta_{1}-\\Delta \\theta, t_{1})}{2\\,\\Delta \\theta}.\n$$\nConstruct an anisotropic smoothness functional for the single unknown $x$,\n$$\n\\mathcal{J}(x) = w_{t}\\Big[(x - s(\\theta_{1}, t_{1}-\\Delta t))^{2} + (s(\\theta_{1}, t_{1}+\\Delta t) - x)^{2}\\Big] + w_{\\theta}\\Big[(x - s(\\theta_{1}-\\Delta \\theta, t_{1}))^{2} + (s(\\theta_{1}+\\Delta \\theta, t_{1}) - x)^{2}\\Big],\n$$\nwhere the weights are defined from the gradient magnitudes by\n$$\nw_{t} = \\frac{1}{1 + \\left(\\frac{|g_{t}|}{g_{0t}}\\right)^{2}},\\quad\nw_{\\theta} = \\frac{1}{1 + \\left(\\frac{|g_{\\theta}|}{g_{0\\theta}}\\right)^{2}},\n$$\nwith contrast parameters $g_{0t} > 0$ and $g_{0\\theta} > 0$.\n\nAssume the following reliable neighbor data and sampling steps:\n- $s(\\theta_{1}, t_{1}-\\Delta t) = 0.51$, $s(\\theta_{1}, t_{1}+\\Delta t) = 0.63$, $s(\\theta_{1}-\\Delta \\theta, t_{1}) = 0.52$, $s(\\theta_{1}+\\Delta \\theta, t_{1}) = 0.54$.\n- $\\Delta t = 1$, $\\Delta \\theta = 0.02$ (radians).\n- $g_{0t} = 0.05$, $g_{0\\theta} = 0.50$.\n\nStarting from the above foundational definitions and the smoothness functional, derive the expression for the minimizer $x^{\\star}$ that interpolates the missing sinogram value by minimizing $\\mathcal{J}(x)$ subject to the boundary constraints provided by the reliable neighbors. Then evaluate $x^{\\star}$ numerically from the given data. Round your final numerical answer to four significant figures. Express the interpolated sinogram value in $\\mathrm{cm}^{-1}$.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, objective, and complete.\n\n### Step 1: Extract Givens\nThe given information is as follows:\n- An unknown sinogram value $x := s(\\theta_{1}, t_{1})$.\n- Reliable neighbor data:\n  - $s(\\theta_{1}, t_{1}-\\Delta t) = 0.51$\n  - $s(\\theta_{1}, t_{1}+\\Delta t) = 0.63$\n  - $s(\\theta_{1}-\\Delta \\theta, t_{1}) = 0.52$\n  - $s(\\theta_{1}+\\Delta \\theta, t_{1}) = 0.54$\n- Sampling intervals:\n  - $\\Delta t = 1$\n  - $\\Delta \\theta = 0.02$\n- Gradient definitions for central differences:\n  - $g_{t} \\approx \\frac{s(\\theta_{1}, t_{1}+\\Delta t) - s(\\theta_{1}, t_{1}-\\Delta t)}{2\\,\\Delta t}$\n  - $g_{\\theta} \\approx \\frac{s(\\theta_{1}+\\Delta \\theta, t_{1}) - s(\\theta_{1}-\\Delta \\theta, t_{1})}{2\\,\\Delta \\theta}$\n- Anisotropic smoothness functional to be minimized:\n  - $\\mathcal{J}(x) = w_{t}\\Big[(x - s(\\theta_{1}, t_{1}-\\Delta t))^{2} + (s(\\theta_{1}, t_{1}+\\Delta t) - x)^{2}\\Big] + w_{\\theta}\\Big[(x - s(\\theta_{1}-\\Delta \\theta, t_{1}))^{2} + (s(\\theta_{1}+\\Delta \\theta, t_{1}) - x)^{2}\\Big]$\n- Weight definitions:\n  - $w_{t} = \\frac{1}{1 + \\left(\\frac{|g_{t}|}{g_{0t}}\\right)^{2}}$\n  - $w_{\\theta} = \\frac{1}{1 + \\left(\\frac{|g_{\\theta}|}{g_{0\\theta}}\\right)^{2}}$\n- Contrast parameters:\n  - $g_{0t} = 0.05$\n  - $g_{0\\theta} = 0.50$\n- The final interpolated value should be rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem describes a sinogram inpainting task using a weighted-average interpolation scheme, where the weights are derived from an anisotropic smoothness functional. This approach is a standard technique in image processing and medical imaging, often related to anisotropic diffusion. The functional $\\mathcal{J}(x)$ is a quadratic function of the unknown $x$. The weights $w_{t}$ and $w_{\\theta}$ are derived from gradient magnitudes and are always positive. Therefore, $\\mathcal{J}(x)$ is a convex parabola opening upwards, which guarantees the existence of a unique minimum. The problem is self-contained, with all necessary data and definitions provided. There are no scientific or logical contradictions. The request for units of $\\mathrm{cm}^{-1}$ on a sinogram value (which is a line integral $\\int \\mu \\, \\mathrm{d}\\ell$ and thus should have units of $\\text{length}^{-1} \\times \\text{length} = \\text{dimensionless}$) is a minor terminological ambiguity but does not affect the mathematical validity of the optimization problem itself. The problem is deemed valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe objective is to find the value of $x$ that minimizes the functional $\\mathcal{J}(x)$. This value, denoted $x^{\\star}$, can be found by taking the derivative of $\\mathcal{J}(x)$ with respect to $x$ and setting it to zero.\n\nLet's simplify the notation for the neighbor values:\n- $s_{t-} = s(\\theta_{1}, t_{1}-\\Delta t)$\n- $s_{t+} = s(\\theta_{1}, t_{1}+\\Delta t)$\n- $s_{\\theta-} = s(\\theta_{1}-\\Delta \\theta, t_{1})$\n- $s_{\\theta+} = s(\\theta_{1}+\\Delta \\theta, t_{1})$\n\nThe functional is:\n$$\n\\mathcal{J}(x) = w_{t}\\Big[(x - s_{t-})^{2} + (s_{t+} - x)^{2}\\Big] + w_{\\theta}\\Big[(x - s_{\\theta-})^{2} + (s_{\\theta+} - x)^{2}\\Big]\n$$\nTo find the minimum, we compute the derivative $\\frac{\\mathrm{d}\\mathcal{J}}{\\mathrm{d}x}$:\n$$\n\\frac{\\mathrm{d}\\mathcal{J}}{\\mathrm{d}x} = w_{t}\\Big[2(x - s_{t-})(1) + 2(s_{t+} - x)(-1)\\Big] + w_{\\theta}\\Big[2(x - s_{\\theta-})(1) + 2(s_{\\theta+} - x)(-1)\\Big]\n$$\n$$\n\\frac{\\mathrm{d}\\mathcal{J}}{\\mathrm{d}x} = 2w_{t}(x - s_{t-} - s_{t+} + x) + 2w_{\\theta}(x - s_{\\theta-} - s_{\\theta+} + x)\n$$\n$$\n\\frac{\\mathrm{d}\\mathcal{J}}{\\mathrm{d}x} = 2w_{t}\\Big(2x - (s_{t-} + s_{t+})\\Big) + 2w_{\\theta}\\Big(2x - (s_{\\theta-} + s_{\\theta+})\\Big)\n$$\nSetting the derivative to zero to find the critical point $x^{\\star}$:\n$$\n2w_{t}\\Big(2x^{\\star} - (s_{t-} + s_{t+})\\Big) + 2w_{\\theta}\\Big(2x^{\\star} - (s_{\\theta-} + s_{\\theta+})\\Big) = 0\n$$\nDividing by $2$:\n$$\nw_{t}\\Big(2x^{\\star} - (s_{t-} + s_{t+})\\Big) + w_{\\theta}\\Big(2x^{\\star} - (s_{\\theta-} + s_{\\theta+})\\Big) = 0\n$$\nNow, we solve for $x^{\\star}$:\n$$\n2x^{\\star}w_{t} - w_{t}(s_{t-} + s_{t+}) + 2x^{\\star}w_{\\theta} - w_{\\theta}(s_{\\theta-} + s_{\\theta+}) = 0\n$$\n$$\n2x^{\\star}(w_{t} + w_{\\theta}) = w_{t}(s_{t-} + s_{t+}) + w_{\\theta}(s_{\\theta-} + s_{\\theta+})\n$$\n$$\nx^{\\star} = \\frac{w_{t}(s_{t-} + s_{t+}) + w_{\\theta}(s_{\\theta-} + s_{\\theta+})}{2(w_{t} + w_{\\theta})}\n$$\nThis expression gives the optimal interpolated value $x^{\\star}$. It can be interpreted as a weighted average of the mean values of the neighbors along each axis.\n\nNow, we will compute the numerical value of $x^{\\star}$ using the given data.\n\nFirst, calculate the local gradients $g_{t}$ and $g_{\\theta}$:\n$$\ng_{t} = \\frac{s_{t+} - s_{t-}}{2\\Delta t} = \\frac{0.63 - 0.51}{2(1)} = \\frac{0.12}{2} = 0.06\n$$\n$$\ng_{\\theta} = \\frac{s_{\\theta+} - s_{\\theta-}}{2\\Delta \\theta} = \\frac{0.54 - 0.52}{2(0.02)} = \\frac{0.02}{0.04} = 0.5\n$$\nNext, calculate the weights $w_{t}$ and $w_{\\theta}$:\n$$\nw_{t} = \\frac{1}{1 + \\left(\\frac{|g_{t}|}{g_{0t}}\\right)^{2}} = \\frac{1}{1 + \\left(\\frac{0.06}{0.05}\\right)^{2}} = \\frac{1}{1 + (1.2)^{2}} = \\frac{1}{1 + 1.44} = \\frac{1}{2.44}\n$$\n$$\nw_{\\theta} = \\frac{1}{1 + \\left(\\frac{|g_{\\theta}|}{g_{0\\theta}}\\right)^{2}} = \\frac{1}{1 + \\left(\\frac{0.5}{0.50}\\right)^{2}} = \\frac{1}{1 + 1^{2}} = \\frac{1}{2}\n$$\nNow, substitute the weights and neighbor values into the expression for $x^{\\star}$:\n- Sum of neighbors along $t$: $s_{t-} + s_{t+} = 0.51 + 0.63 = 1.14$\n- Sum of neighbors along $\\theta$: $s_{\\theta-} + s_{\\theta+} = 0.52 + 0.54 = 1.06$\n\n$$\nx^{\\star} = \\frac{w_{t}(1.14) + w_{\\theta}(1.06)}{2(w_{t} + w_{\\theta})}\n$$\nSubstitute the values of the weights:\n$$\nx^{\\star} = \\frac{(\\frac{1}{2.44})(1.14) + (\\frac{1}{2})(1.06)}{2(\\frac{1}{2.44} + \\frac{1}{2})}\n$$\nCalculate the numerator:\n$$\n\\text{Numerator} = \\frac{1.14}{2.44} + \\frac{1.06}{2} = \\frac{1.14}{2.44} + 0.53\n$$\nCalculate the denominator:\n$$\n\\text{Denominator} = 2\\left(\\frac{1}{2.44} + \\frac{1}{2}\\right) = 2\\left(\\frac{1 + 1.22}{2.44}\\right) = 2\\left(\\frac{2.22}{2.44}\\right) = \\frac{4.44}{2.44}\n$$\nSo, we have:\n$$\nx^{\\star} = \\frac{\\frac{1.14}{2.44} + 0.53}{\\frac{4.44}{2.44}} = \\frac{1.14 + 0.53(2.44)}{4.44} = \\frac{1.14 + 1.2932}{4.44} = \\frac{2.4332}{4.44}\n$$\n$$\nx^{\\star} \\approx 0.547995495...\n$$\nThe problem requires the final answer to be rounded to four significant figures.\n$$\nx^{\\star} \\approx 0.5480\n$$\nAlthough the problem requests the unit of the interpolated value to be expressed in $\\mathrm{cm}^{-1}$, the calculation is based on dimensionless numerical inputs. The final result is a dimensionless number. Following the output format rules, units are not included in the boxed answer. The numerical value represents the interpolated sinogram data point, which is physically related to the line integral of linear attenuation coefficients.", "answer": "$$\\boxed{0.5480}$$", "id": "4900085"}, {"introduction": "This capstone exercise [@problem_id:4900122] integrates the core concepts of MAR into a complete, physically realistic simulation of the Normalized Metal Artifact Reduction (NMAR) pipeline. You will generate CT data from first principles using the polychromatic Beer-Lambert law, create training targets by simulating an ideal artifact-free scan, and then train and evaluate a simple inpainting model. This comprehensive practice illuminates the entire workflow and introduces advanced challenges like evaluating model robustness against a \"domain shift\" in the X-ray spectrum.", "problem": "You are tasked with implementing a computational pipeline that formalizes Normalized Metal Artifact Reduction (NMAR) for Computed Tomography (CT) as a principled inverse problem based on the Beer–Lambert law. The goal is to compute training targets by generating normalized sinograms, design a simple inpainting predictor, and evaluate performance under domain shifts in the X-ray energy spectrum $S(E)$. The final outputs must be numerical and derived from first principles.\n\nFundamental base:\n- The Beer–Lambert law for a polychromatic X-ray beam states that the measured intensity $I$ along a ray is\n$$\nI = \\int_{E_{\\min}}^{E_{\\max}} S(E) \\exp\\left(-\\int \\mu(x,E)\\,dx\\right)\\,dE,\n$$\nwhere $S(E)$ is the energy-dependent source spectrum and $\\mu(x,E)$ is the linear attenuation coefficient at position $x$ and energy $E$. The air intensity is\n$$\nI_0 = \\int_{E_{\\min}}^{E_{\\max}} S(E)\\,dE.\n$$\nThe projection value is\n$$\np = -\\log\\left(\\frac{I}{I_0}\\right).\n$$\n- For a ray passing through homogeneous water-equivalent path length $t$ with no metal, the forward model is\n$$\nI_{\\text{water}}(t) = \\int_{E_{\\min}}^{E_{\\max}} S(E)\\,\\exp\\left(-\\mu_w(E)\\,t\\right)\\,dE,\n$$\nwith the corresponding projection $p_{\\text{water}}(t) = -\\log\\left(\\frac{I_{\\text{water}}(t)}{I_0}\\right)$.\n\nNormalized sinogram definition:\n- Given any measured projection $p$ from a ray through an object with unknown material composition, define the water-equivalent thickness $t$ by solving the scalar equation\n$$\np_{\\text{water}}(t) = p,\n$$\nwhich is well-posed because $p_{\\text{water}}(t)$ is strictly increasing in $t$. The normalized sinogram is the array of these water-equivalent thicknesses $t$ for all rays.\n\nPhantom and geometry:\n- Consider a parallel-beam CT geometry scanning a cylindrical water phantom of radius $R_w$ (in millimeters) centered at the origin. A circular metal implant of radius $R_m$ (in millimeters) is embedded within the phantom with center at $(x_m,y_m)$ (in millimeters). For a projection ray specified by angle $\\theta$ (in radians) and signed detector coordinate $s$ (in millimeters), the length of intersection through a circle of radius $R$ centered at $(x_c,y_c)$ is\n$$\n\\ell_{\\text{circle}} = \n\\begin{cases}\n2\\sqrt{R^2 - d^2}, & |d| \\le R,\\\\\n0, & |d| > R,\n\\end{cases}\n$$\nwhere $d = |x_c\\cos\\theta + y_c\\sin\\theta - s|$.\n- For each ray, define $L_w^{\\text{full}}$ as the chord length through the water cylinder, and $L_m$ as the chord length through the metal disc. The water chord length with metal present is $L_w = \\max(L_w^{\\text{full}} - L_m, 0)$ under the assumption that the metal disc replaces water.\n\nMaterial model:\n- Use energy-dependent attenuation models\n$$\n\\mu_w(E) = b_w + \\frac{a_w}{E^3},\\quad\n\\mu_m(E) = b_m + \\frac{a_m}{E^3},\n$$\nwith $E$ measured in kiloelectronvolts (keV) and $\\mu_w,\\mu_m$ in inverse millimeters (mm$^{-1}$).\n\nSpectrum and domain shift:\n- Use parametric source spectra\n$$\nS(E) \\propto E^\\gamma \\exp\\left(-\\frac{E}{E_0}\\right),\n$$\nfor $E \\in [E_{\\min}, E_{\\max}]$, with a given shape parameter $\\gamma$ and scale parameter $E_0$. Normalize $S(E)$ so that $\\int S(E)\\,dE = 1$ numerically.\n- Domain shift is induced by changing $E_0$ between training and testing, while keeping all else fixed.\n\nTraining targets and predictor:\n- Compute the measured intensity for each ray with the metal present,\n$$\nI_{\\text{meas}} = \\int S(E)\\,\\exp\\big(-\\mu_w(E)\\,L_w - \\mu_m(E)\\,L_m\\big)\\,dE,\n$$\nand its normalized thickness $t_{\\text{meas}}$ by inverting $p_{\\text{water}}(t_{\\text{meas}}) = -\\log(I_{\\text{meas}}/I_0)$.\n- Define the target intensity for inpainting by replacing metal with water,\n$$\nI_{\\text{targ}} = \\int S(E)\\,\\exp\\big(-\\mu_w(E)\\,L_w^{\\text{full}}\\big)\\,dE,\n$$\nand its normalized thickness $t_{\\text{targ}}$ via $p_{\\text{water}}(t_{\\text{targ}}) = -\\log(I_{\\text{targ}}/I_0)$.\n- Design a one-dimensional convolutional inpainting predictor along the detector dimension with kernel half-width $K$. For a masked center index $j$, define the input vector\n$$\n\\mathbf{x}_j = [t_{\\text{meas}}(j-K),\\dots,t_{\\text{meas}}(j-1),t_{\\text{meas}}(j+1),\\dots,t_{\\text{meas}}(j+K),1]^\\top \\in \\mathbb{R}^{2K+1},\n$$\nwhere the last component is a bias term, and predict\n$$\n\\hat{t}(j) = \\mathbf{w}^\\top \\mathbf{x}_j.\n$$\nEstimate weights $\\mathbf{w}$ by minimizing a regularized least squares objective over training windows with valid (unmasked) neighbors:\n$$\n\\min_{\\mathbf{w}} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2,\n$$\nwhere rows of $\\mathbf{X}$ are neighbor vectors $\\mathbf{x}_j$ for masked centers $j$ with valid neighbors and $\\mathbf{y}$ are the corresponding $t_{\\text{targ}}(j)$.\n\nNoise model:\n- Optionally add zero-mean Gaussian noise of relative amplitude $\\sigma$ to the measured intensity $I_{\\text{meas}}$ before computing $p$; clip intensities to a small positive value to maintain physical realism.\n\nPerformance metrics:\n- Evaluate Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) between $\\hat{t}(j)$ and $t_{\\text{targ}}(j)$ over test masked rays with valid neighbors. Both metrics must be expressed in millimeters (mm) and printed as floats. If no masked rays or no valid windows exist, return $0.0$ for both metrics.\n\nAngles must be treated in radians. All lengths are in millimeters. Energies are in kiloelectronvolts.\n\nYour program must implement the above pipeline and produce a single line of output containing results as a comma-separated list enclosed in square brackets, in the order specified by the test suite below. Round each float to six decimal places.\n\nTest suite:\n- Case 1 (happy path):\n    - $R_w = 60$ mm, $R_m = 12$ mm, $(x_m,y_m) = (20,0)$ mm, $K = 3$, $\\lambda = 10^{-3}$, $\\gamma = 2$, $E_{\\min} = 20$ keV, $E_{\\max} = 120$ keV, $E_0^{\\text{train}} = 30$ keV, $E_0^{\\text{test}} = 40$ keV, noise level $\\sigma = 0.0$, number of angles $N_\\theta = 48$, number of detector samples $N_s = 96$.\n- Case 2 (boundary, no metal):\n    - Same as Case 1 but $R_m = 0$ mm and $(x_m,y_m) = (0,0)$ mm; use $E_0^{\\text{train}} = 30$ keV and $E_0^{\\text{test}} = 35$ keV; $\\sigma = 0.0$.\n- Case 3 (edge case, strong domain shift and noise):\n    - $R_w = 60$ mm, $R_m = 25$ mm, $(x_m,y_m) = (0,10)$ mm, $K = 3$, $\\lambda = 10^{-3}$, $\\gamma = 2$, $E_{\\min} = 20$ keV, $E_{\\max} = 120$ keV, $E_0^{\\text{train}} = 25$ keV, $E_0^{\\text{test}} = 50$ keV, noise level $\\sigma = 0.02$, $N_\\theta = 48$, $N_s = 96$.\n\nMaterial parameters (fixed across cases):\n- Water: $a_w = 20$ mm$^{-1}\\cdot$keV$^3$, $b_w = 0.0015$ mm$^{-1}$.\n- Metal: $a_m = 150$ mm$^{-1}\\cdot$keV$^3$, $b_m = 0.010$ mm$^{-1}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the six floats\n$$\n[\\text{MAE}_1,\\text{RMSE}_1,\\text{MAE}_2,\\text{RMSE}_2,\\text{MAE}_3,\\text{RMSE}_3],\n$$\nrounded to six decimal places, where the subscript denotes the case number.", "solution": "The problem presents a comprehensive and scientifically well-grounded task to implement a computational pipeline for Normalized Metal Artifact Reduction (NMAR) in Computed Tomography (CT). The model is based on first principles, including the polychromatic Beer–Lambert law, and involves generating simulated training and testing data, designing a simple machine learning predictor, and evaluating its performance under a domain shift. The problem is self-contained, with all necessary physical models, parameters, and evaluation metrics clearly defined. The mathematical and physical formalisms are sound, and the computational steps are logically structured. Therefore, the problem is deemed valid and a full solution is provided below.\n\nThe solution is developed through a series of principled steps:\n\n1.  **Physical Modeling**: At the core of the simulation is the Beer–Lambert law for a polychromatic X-ray source. The intensity $I$ of a ray after passing through a medium is given by the integral of the source spectrum $S(E)$ attenuated by the material's energy-dependent linear attenuation coefficient $\\mu(x, E)$:\n    $$\n    I = \\int_{E_{\\min}}^{E_{\\max}} S(E) \\exp\\left(-\\int_{\\text{ray}} \\mu(x,E)\\,dx\\right)\\,dE\n    $$\n    The problem specifies the source spectrum $S(E) \\propto E^\\gamma \\exp(-E/E_0)$ and material-specific attenuation models $\\mu_w(E)$ for water and $\\mu_m(E)$ for metal, which are functions of energy $E$. These integrals are computed numerically. The source spectrum $S(E)$ is first normalized such that its integral over the energy range $[E_{\\min}, E_{\\max}]$ is unity. The air-scan intensity is then $I_0 = \\int S(E)\\,dE = 1$ by this normalization.\n\n2.  **Geometric Path Length Calculation**: The simulation employs a parallel-beam geometry. For each ray, defined by its angle $\\theta$ and detector coordinate $s$, the path lengths through the cylindrical water phantom ($L_w^{\\text{full}}$) and the embedded circular metal implant ($L_m$) are calculated using analytic geometry. The chord length $\\ell$ through a circle of radius $R$ centered at $(x_c, y_c)$ is given by $\\ell=2\\sqrt{R^2-d^2}$ for $|d|\\le R$ and $0$ otherwise, where $d = |x_c\\cos\\theta + y_c\\sin\\theta - s|$ is the perpendicular distance from the ray to the circle's center. Since the metal implant replaces water, the actual water path length is $L_w = L_w^{\\text{full}} - L_m$.\n\n3.  **Sinogram Generation**: Two types of sinograms are generated. First, the \"measured\" sinogram, which simulates a scan with the metal implant present. The intensity for each ray is:\n    $$\n    I_{\\text{meas}} = \\int_{E_{\\min}}^{E_{\\max}} S(E)\\,\\exp\\big(-\\mu_w(E)\\,L_w - \\mu_m(E)\\,L_m\\big)\\,dE\n    $$\n    Second, the \"target\" sinogram, which represents the ideal, artifact-free scan where the metal is replaced by water. Its intensity is:\n    $$\n    I_{\\text{targ}} = \\int_{E_{\\min}}^{E_{\\max}} S(E)\\,\\exp\\big(-\\mu_w(E)\\,L_w^{\\text{full}}\\big)\\,dE\n    $$\n    For the noisy case, zero-mean Gaussian noise with relative amplitude $\\sigma$ is added to $I_{\\text{meas}}$ before subsequent processing, and the result is clipped to a small positive value to prevent non-physical negative or zero intensities.\n\n4.  **Sinogram Normalization**: The raw projection values $p = -\\log(I/I_0)$ are subject to non-linear beam hardening effects. The NMAR method linearizes the data by converting projections into a water-equivalent thickness, $t$. This is achieved by inverting the forward model for a homogeneous water path: $p_{\\text{water}}(t) = -\\log\\left(\\int S(E)\\exp(-\\mu_w(E)t)dE / I_0\\right)$. Since $p_{\\text{water}}(t)$ is a strictly monotonic function of $t$, a unique inverse exists for any valid projection value $p$. To perform this inversion efficiently, we pre-compute a look-up table (LUT) of $(t, p_{\\text{water}}(t))$ pairs over a plausible range of thicknesses and use linear interpolation to find the water-equivalent thickness $t$ corresponding to any given projection $p$. This process yields the normalized sinograms $t_{\\text{meas}}$ and $t_{\\text{targ}}$.\n\n5.  **Inpainting Predictor Design and Training**: The goal is to predict the true value $t_{\\text{targ}}$ in regions corrupted by metal artifacts, using information from surrounding, uncorrupted regions in the measured sinogram $t_{\\text{meas}}$. A simple linear predictor is designed. For each corrupted ray (i.e., one passing through metal), a feature vector $\\mathbf{x}$ is constructed from its $2K$ nearest uncorrupted neighbors along the detector dimension, augmented with a bias term. The prediction is $\\hat{t} = \\mathbf{w}^\\top \\mathbf{x}$. The weight vector $\\mathbf{w}$ is learned by solving a regularized least-squares problem:\n    $$\n    \\mathbf{w}^* = \\arg\\min_{\\mathbf{w}} \\|\\mathbf{X}\\mathbf{w} - \\mathbf{y}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n    $$\n    where the rows of matrix $\\mathbf{X}$ consist of the feature vectors from valid training windows (a corrupted ray surrounded by uncorrupted neighbors), and $\\mathbf{y}$ contains the corresponding ground truth values from $t_{\\text{targ}}$. The training is performed on data generated using the training spectrum $S(E; E_0^{\\text{train}})$. The closed-form solution is $\\mathbf{w} = (\\mathbf{X}^\\top\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^\\top\\mathbf{y}$.\n\n6.  **Performance Evaluation under Domain Shift**: The robustness of the trained predictor is tested against a domain shift, simulated by changing the X-ray spectrum to $S(E; E_0^{\\text{test}})$. A new set of test sinograms ($t_{\\text{meas}}^{\\text{test}}$, $t_{\\text{targ}}^{\\text{test}}$) is generated using this new spectrum. The previously learned weights $\\mathbf{w}$ are then used to predict $\\hat{t}$ for the corrupted rays in the test set. Performance is quantified by computing the Mean Absolute Error (MAE) and Root Mean Square Error (RMSE) between the predictions $\\hat{t}$ and the true values $t_{\\text{targ}}^{\\text{test}}$ over all test samples from valid windows.\n\n7.  **Edge Case Management**: The problem defines specific behaviors for edge cases. If no metal is present ($R_m=0$), no rays are corrupted, resultings in no training or testing samples. Similarly, if a large metal object makes it impossible to find any corrupted rays with fully uncorrupted neighborhoods, the training or testing sets might be empty. In any case where the set of test rays with valid windows is empty, the MAE and RMSE are defined to be $0.0$, which is handled by the implementation.", "answer": "```python\nimport numpy as np\nfrom scipy import integrate\nfrom scipy.interpolate import interp1d\n\ndef solve():\n    \"\"\"\n    Main function to run the NMAR simulation for all test cases and print results.\n    \"\"\"\n    \n    # Material parameters (fixed across cases)\n    material_params = {\n        'a_w': 20.0, 'b_w': 0.0015,\n        'a_m': 150.0, 'b_m': 0.010\n    }\n\n    # Test suite\n    test_cases = [\n        # Case 1 (happy path)\n        {'R_w': 60.0, 'R_m': 12.0, 'x_m': 20.0, 'y_m': 0.0, 'K': 3, 'lambda': 1e-3, \n         'gamma': 2.0, 'E_min': 20.0, 'E_max': 120.0, 'E0_train': 30.0, 'E0_test': 40.0, \n         'sigma': 0.0, 'N_theta': 48, 'N_s': 96},\n        # Case 2 (boundary, no metal)\n        {'R_w': 60.0, 'R_m': 0.0, 'x_m': 0.0, 'y_m': 0.0, 'K': 3, 'lambda': 1e-3, \n         'gamma': 2.0, 'E_min': 20.0, 'E_max': 120.0, 'E0_train': 30.0, 'E0_test': 35.0, \n         'sigma': 0.0, 'N_theta': 48, 'N_s': 96},\n        # Case 3 (edge case, strong domain shift and noise)\n        {'R_w': 60.0, 'R_m': 25.0, 'x_m': 0.0, 'y_m': 10.0, 'K': 3, 'lambda': 1e-3, \n         'gamma': 2.0, 'E_min': 20.0, 'E_max': 120.0, 'E0_train': 25.0, 'E0_test': 50.0, \n         'sigma': 0.02, 'N_theta': 48, 'N_s': 96}\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        params = {**case_params, **material_params}\n        mae, rmse = process_case(params)\n        all_results.extend([mae, rmse])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\ndef process_case(params):\n    \"\"\"\n    Processes a single test case from training to evaluation.\n    \"\"\"\n    # Unpack parameters\n    K = params['K']\n    lambda_reg = params['lambda']\n\n    # --- Training Phase ---\n    train_data = generate_sinograms(params, params['E0_train'], 0.0)\n    X_train, y_train = build_dataset(train_data['t_meas'], train_data['t_targ'], train_data['mask'], K)\n\n    if X_train.shape[0] == 0:\n        w = np.zeros(2 * K + 1)\n    else:\n        # Solve regularized least squares: (X'X + lambda*I)w = X'y\n        A = X_train.T @ X_train + lambda_reg * np.identity(2 * K + 1)\n        b = X_train.T @ y_train\n        w = np.linalg.solve(A, b)\n        \n    # --- Testing Phase ---\n    test_data = generate_sinograms(params, params['E0_test'], params['sigma'])\n    X_test, y_test = build_dataset(test_data['t_meas'], test_data['t_targ'], test_data['mask'], K)\n\n    if X_test.shape[0] == 0:\n        return 0.0, 0.0\n\n    # Predict on test data\n    y_pred = X_test @ w\n\n    # Calculate metrics\n    mae = np.mean(np.abs(y_pred - y_test))\n    rmse = np.sqrt(np.mean((y_pred - y_test)**2))\n\n    return mae, rmse\n\n\ndef generate_sinograms(params, E0, sigma):\n    \"\"\"\n    Generates measured and target sinograms based on the provided parameters.\n    \"\"\"\n    # Unpack parameters\n    R_w, R_m = params['R_w'], params['R_m']\n    x_m, y_m = params['x_m'], params['y_m']\n    a_w, b_w = params['a_w'], params['b_w']\n    a_m, b_m = params['a_m'], params['b_m']\n    gamma, E_min, E_max = params['gamma'], params['E_min'], params['E_max']\n    N_theta, N_s = params['N_theta'], params['N_s']\n\n    # Define sinogram grid\n    thetas = np.linspace(0, np.pi, N_theta, endpoint=False)\n    s_coords = np.linspace(-R_w, R_w, N_s)\n\n    # Energy grid for integration\n    Es = np.linspace(E_min, E_max, 200)\n\n    # Material models\n    mu_w = lambda E: b_w + a_w / E**3\n    mu_m = lambda E: b_m + a_m / E**3\n    \n    # Create normalized spectrum function\n    unnormalized_S_integrand = lambda E: E**gamma * np.exp(-E / E0)\n    norm_const, _ = integrate.quad(unnormalized_S_integrand, E_min, E_max)\n    S = lambda E: unnormalized_S_integrand(E) / norm_const\n\n    # Pre-calculate p_water to t inversion LUT\n    t_lut_vals = np.linspace(0, 2 * R_w, 2048)\n    p_lut_vals = np.zeros_like(t_lut_vals)\n    for i, t in enumerate(t_lut_vals):\n        integrand = lambda E: S(E) * np.exp(-mu_w(E) * t)\n        I_water_t = integrate.quad(integrand, E_min, E_max)[0]\n        # I0 is 1 due to normalization\n        p_lut_vals[i] = -np.log(I_water_t) if I_water_t > 0 else np.inf\n    \n    invert_p_water = interp1d(p_lut_vals, t_lut_vals, bounds_error=False, \n                              fill_value=(t_lut_vals[0], t_lut_vals[-1]))\n\n    # Initialize sinograms\n    t_meas = np.zeros((N_theta, N_s))\n    t_targ = np.zeros((N_theta, N_s))\n    mask = np.zeros((N_theta, N_s), dtype=int)\n    \n    rng = np.random.default_rng(seed=42) # for reproducible noise\n\n    for i, theta in enumerate(thetas):\n        c, s = np.cos(theta), np.sin(theta)\n        for j, s_val in enumerate(s_coords):\n            # Calculate chord lengths\n            # Water phantom (centered at origin)\n            d_w = np.abs(-s_val)\n            L_w_full = 2 * np.sqrt(R_w**2 - d_w**2) if d_w = R_w else 0.0\n\n            # Metal implant\n            d_m = np.abs(x_m * c + y_m * s - s_val)\n            L_m = 2 * np.sqrt(R_m**2 - d_m**2) if (R_m > 0 and d_m = R_m) else 0.0\n\n            L_w = L_w_full - L_m\n            \n            if L_m > 1e-9: # Ray passes through metal\n                mask[i, j] = 1\n\n            # Calculate intensities\n            integrand_meas = lambda E: S(E) * np.exp(-mu_w(E) * L_w - mu_m(E) * L_m)\n            integrand_targ = lambda E: S(E) * np.exp(-mu_w(E) * L_w_full)\n\n            I_meas = integrate.quad(integrand_meas, E_min, E_max)[0]\n            I_targ = integrate.quad(integrand_targ, E_min, E_max)[0]\n\n            # Add noise if specified\n            if sigma > 0:\n                I_meas += rng.normal(0, sigma * I_meas)\n                I_meas = np.maximum(I_meas, 1e-10)\n\n            # Calculate projections (I0=1)\n            p_meas = -np.log(I_meas) if I_meas > 0 else np.inf\n            p_targ = -np.log(I_targ) if I_targ > 0 else np.inf\n\n            # Normalize to water-equivalent thickness\n            t_meas[i, j] = invert_p_water(p_meas)\n            t_targ[i, j] = invert_p_water(p_targ)\n            \n    return {'t_meas': t_meas, 't_targ': t_targ, 'mask': mask}\n\n\ndef build_dataset(t_meas, t_targ, mask, K):\n    \"\"\"\n    Constructs the design matrix X and target vector y for training or evaluation.\n    \"\"\"\n    N_theta, N_s = t_meas.shape\n    X_list, y_list = [], []\n\n    for i in range(N_theta):\n        for j in range(K, N_s - K):\n            if mask[i, j] == 1: # Center pixel is masked\n                # Get indices of neighbors\n                neighbor_indices = list(range(j - K, j)) + list(range(j + 1, j + K + 1))\n                \n                # Check if all neighbors are unmasked\n                if np.any(mask[i, neighbor_indices] == 1):\n                    continue\n\n                # Valid window found, create feature vector\n                neighbors_t = t_meas[i, neighbor_indices]\n                x_vec = np.concatenate((neighbors_t, [1.0]))\n                \n                X_list.append(x_vec)\n                y_list.append(t_targ[i, j])\n\n    if not X_list:\n        return np.empty((0, 2*K + 1)), np.empty((0,))\n        \n    return np.array(X_list), np.array(y_list)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "4900122"}]}