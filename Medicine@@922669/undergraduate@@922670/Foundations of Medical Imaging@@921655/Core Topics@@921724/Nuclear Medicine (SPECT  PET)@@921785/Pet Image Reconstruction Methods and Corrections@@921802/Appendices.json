{"hands_on_practices": [{"introduction": "Before we can reconstruct a PET image, we must first understand how the scanner measures radioactivity within the body, a process described by the \"forward model.\" This exercise [@problem_id:4907970] provides a practical application of this model by asking you to calculate the expected raw data, or sinogram, for a simple yet fundamental object: a uniform cylindrical phantom. By working through this, you will see how an object's physical properties—its shape and activity concentration—are translated into the signal measured by the scanner, including the effects of true coincidences, scatter, and randoms.", "problem": "A uniform cylindrical phantom of diameter $D$ and activity concentration $x_{0}$ is imaged with Positron Emission Tomography (PET). Consider a two-dimensional parallel-beam acquisition in a single axial slice through the cylinder’s center. Let the sinogram coordinate be $(p,\\varphi)$, where $p$ is the signed perpendicular distance from the origin to the line-of-response and $\\varphi$ is the view angle. Assume the following physically justified forward model for the expected sinogram:\n- The expected true-coincidence counts along a ray at offset $p$ are proportional to the line integral of the activity concentration along that ray, with an effective constant $\\gamma$ that lumps acquisition time, geometric sensitivity, and detection efficiency, so that the true term is $\\gamma \\int x(\\boldsymbol{r})\\,\\mathrm{d}\\ell$.\n- The randoms $r$ and scatter $s$ contributions are uniform across $(p,\\varphi)$ and add linearly to the expectation for each sinogram bin.\n- The phantom is centered at the origin, has radius $R = D/2$, and $x(\\boldsymbol{r}) = x_{0}$ for $|\\boldsymbol{r}| \\le R$ and $x(\\boldsymbol{r}) = 0$ otherwise.\n- You may assume rotational invariance of the uniform cylinder so that the expected counts depend only on $p$.\n\nStarting from the fundamental emission-tomography forward model and planar geometry, derive the expected sinogram value $\\bar{y}(p)$ for offsets satisfying $|p| \\le R$ and identify explicitly its dependence on the chord length of intersection between the ray and the cylinder. Then, for the specific values\n- $D = 24\\,\\mathrm{cm}$,\n- $x_{0} = 4.0 \\times 10^{3}\\,\\mathrm{Bq\\,cm^{-3}}$,\n- $\\gamma = 7.5 \\times 10^{-2}\\,\\mathrm{counts}\\,\\mathrm{(Bq^{-1}\\,cm^{2})}$,\n- $r = 120\\,\\mathrm{counts}$,\n- $s = 80\\,\\mathrm{counts}$,\nprovide the closed-form expression for $\\bar{y}(p)$ as a function of $p$ for $|p| \\le R$.\n\nExpress your final expression in counts. No rounding is required.", "solution": "## PROBLEM VALIDATION\n\n### Step 1: Extract Givens\n- Phantom: Uniform cylinder of diameter $D$.\n- Activity concentration: $x_0$.\n- Sinogram coordinates: $(p, \\varphi)$, where $p$ is the signed perpendicular distance from the origin to the line-of-response (LOR) and $\\varphi$ is the view angle.\n- Expected true-coincidence counts: Proportional to the line integral of activity, given by $\\gamma \\int x(\\boldsymbol{r})\\,\\mathrm{d}\\ell$.\n- Constant of proportionality: $\\gamma$.\n- Randoms contribution: $r$, uniform across $(p,\\varphi)$.\n- Scatter contribution: $s$, uniform across $(p,\\varphi)$.\n- Additive model: Trues, randoms, and scatter add linearly.\n- Phantom geometry: Centered at the origin, radius $R = D/2$.\n- Activity distribution: $x(\\boldsymbol{r}) = x_0$ for $|\\boldsymbol{r}| \\le R$ and $x(\\boldsymbol{r}) = 0$ otherwise.\n- Rotational invariance is assumed, so the expected counts depend only on $p$.\n- Specific values:\n  - $D = 24\\,\\mathrm{cm}$\n  - $x_0 = 4.0 \\times 10^3\\,\\mathrm{Bq\\,cm^{-3}}$\n  - $\\gamma = 7.5 \\times 10^{-2}\\,\\mathrm{counts}\\,\\mathrm{(Bq^{-1}\\,cm^2)}$\n  - $r = 120\\,\\mathrm{counts}$\n  - $s = 80\\,\\mathrm{counts}$\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against the validation criteria.\n\n- **Scientifically Grounded (Critical)**: The problem is firmly grounded in the fundamental principles of Positron Emission Tomography (PET). The forward model, which describes the expected sinogram data as the sum of true coincidences (modeled by the Radon transform of the activity distribution), scatter, and random coincidences, is a standard and widely accepted model in emission tomography. The geometry of a uniform cylindrical phantom is a standard object used for quality control and calibration in PET scanners. All aspects of the problem are scientifically sound.\n- **Well-Posed**: The problem is well-posed. It provides a complete set of parameters and a clear physical model. The task is to derive a specific function, $\\bar{y}(p)$, based on these inputs. The provided information is sufficient and consistent, ensuring a unique solution exists.\n- **Objective (Critical)**: The problem is stated in precise, objective language using standard mathematical and physical terminology. There are no subjective or ambiguous statements.\n\nThe problem does not exhibit any of the flaws listed in the validation checklist (e.g., scientific unsoundness, incompleteness, unrealism, etc.).\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n## SOLUTION\n\nThe problem asks for the derivation of the expected sinogram value, $\\bar{y}(p)$, for a uniform cylindrical phantom.\n\nThe forward model for the expected number of counts in a sinogram bin $(p, \\varphi)$ is given by the sum of true coincidences, random coincidences, and scattered coincidences.\n$$\n\\bar{y}(p, \\varphi) = \\bar{t}(p, \\varphi) + r + s\n$$\nwhere $\\bar{t}(p, \\varphi)$ is the expected number of true coincidences, and $r$ and $s$ are the contributions from randoms and scatter, respectively. The problem states that $r$ and $s$ are uniform constants.\n\nThe true-coincidence term $\\bar{t}(p, \\varphi)$ is modeled as the Radon transform of the activity distribution $x(\\boldsymbol{r})$, scaled by a constant factor $\\gamma$.\n$$\n\\bar{t}(p, \\varphi) = \\gamma \\int_{\\text{LOR}(p, \\varphi)} x(\\boldsymbol{r})\\,\\mathrm{d}\\ell\n$$\nThe integral is taken along the line-of-response (LOR) defined by the coordinates $(p, \\varphi)$.\n\nThe phantom is a uniform cylinder of radius $R$ centered at the origin, with a constant activity concentration $x_0$ inside and zero outside.\n$$\nx(\\boldsymbol{r}) =\n\\begin{cases}\nx_0 & \\text{if } |\\boldsymbol{r}| \\le R \\\\\n0 & \\text{if } |\\boldsymbol{r}| > R\n\\end{cases}\n$$\nSince the activity distribution $x(\\boldsymbol{r})$ is radially symmetric, its Radon transform is also radially symmetric, meaning it depends only on the distance $p$ from the origin, not on the angle $\\varphi$. We can thus write $\\bar{t}(p, \\varphi) = \\bar{t}(p)$ and $\\bar{y}(p, \\varphi) = \\bar{y}(p)$.\n\nFor a given $p$, the integral for the true counts becomes:\n$$\n\\bar{t}(p) = \\gamma \\int_{\\text{LOR}(p)} x_0 \\,\\mathrm{d}\\ell\n$$\nSince $x_0$ is a constant, it can be taken out of the integral.\n$$\n\\bar{t}(p) = \\gamma x_0 \\int_{\\text{LOR}(p) \\cap \\text{Cylinder}} \\mathrm{d}\\ell\n$$\nThe integral $\\int_{\\text{LOR}(p) \\cap \\text{Cylinder}} \\mathrm{d}\\ell$ is simply the length of the chord, $L(p)$, formed by the intersection of the LOR at offset $p$ with the cylindrical phantom. Therefore, the true counts are explicitly dependent on this chord length:\n$$\n\\bar{t}(p) = \\gamma x_0 L(p)\n$$\nWe need to find the expression for $L(p)$ for $|p| \\le R$. Consider a cross-section of the cylinder, which is a circle of radius $R$ centered at the origin, with equation $u^2 + v^2 = R^2$. Due to rotational symmetry, we can orient the coordinate system such that the LOR is a vertical line $u=p$. The intersection points of this line with the circle have coordinates $(p, v)$ where $p^2 + v^2 = R^2$. Solving for $v$, we get $v = \\pm\\sqrt{R^2 - p^2}$. The two intersection points are $(p, -\\sqrt{R^2-p^2})$ and $(p, \\sqrt{R^2-p^2})$. The distance between these two points, which is the chord length $L(p)$, is:\n$$\nL(p) = \\sqrt{(p-p)^2 + (\\sqrt{R^2-p^2} - (-\\sqrt{R^2-p^2}))^2} = \\sqrt{0 + (2\\sqrt{R^2-p^2})^2} = 2\\sqrt{R^2-p^2}\n$$\nThis expression is valid for $|p| \\le R$. For $|p| > R$, the LOR does not intersect the phantom, and $L(p)=0$.\n\nSubstituting the expression for $L(p)$ back into the equation for $\\bar{t}(p)$:\n$$\n\\bar{t}(p) = 2 \\gamma x_0 \\sqrt{R^2 - p^2}\n$$\nThe total expected sinogram value $\\bar{y}(p)$ is then:\n$$\n\\bar{y}(p) = \\bar{t}(p) + r + s = 2 \\gamma x_0 \\sqrt{R^2 - p^2} + r + s\n$$\nThis is the general closed-form expression for the expected sinogram for $|p| \\le R$.\n\nNow, we substitute the given numerical values:\n- $D = 24\\,\\mathrm{cm}$, which implies the radius is $R = D/2 = 12\\,\\mathrm{cm}$.\n- $x_0 = 4.0 \\times 10^3\\,\\mathrm{Bq\\,cm^{-3}}$.\n- $\\gamma = 7.5 \\times 10^{-2}\\,\\mathrm{counts}\\,\\mathrm{(Bq^{-1}\\,cm^2)}$.\n- $r = 120\\,\\mathrm{counts}$.\n- $s = 80\\,\\mathrm{counts}$.\n\nFirst, we calculate the coefficient of the true-counts term, $2 \\gamma x_0$:\n$$\n2 \\gamma x_0 = 2 \\times (7.5 \\times 10^{-2}\\,\\mathrm{counts}\\,\\mathrm{Bq^{-1}\\,cm^2}) \\times (4.0 \\times 10^3\\,\\mathrm{Bq\\,cm^{-3}})\n$$\n$$\n2 \\gamma x_0 = (15.0 \\times 10^{-2}) \\times (4.0 \\times 10^3) \\,\\mathrm{counts\\,cm^{-1}} = 60.0 \\times 10^1 \\,\\mathrm{counts\\,cm^{-1}} = 600 \\,\\mathrm{counts\\,cm^{-1}}\n$$\nThe term $\\sqrt{R^2 - p^2}$ has units of cm, so the true-counts term $2 \\gamma x_0 \\sqrt{R^2 - p^2}$ has units of counts, which is consistent.\n\nNext, we calculate the sum of the constant background terms:\n$$\nr + s = 120\\,\\mathrm{counts} + 80\\,\\mathrm{counts} = 200\\,\\mathrm{counts}\n$$\n\nFinally, we assemble the complete expression for $\\bar{y}(p)$ using the numerical values, with $R=12\\,\\mathrm{cm}$:\n$$\n\\bar{y}(p) = 600 \\sqrt{(12)^2 - p^2} + 200\n$$\n$$\n\\bar{y}(p) = 600 \\sqrt{144 - p^2} + 200\n$$\nThis is the final closed-form expression for the expected sinogram value in counts, as a function of the offset $p$ (in cm), valid for $|p| \\le 12$.", "answer": "$$\n\\boxed{600 \\sqrt{144 - p^2} + 200}\n$$", "id": "4907970"}, {"introduction": "Raw PET data is heavily distorted by physical effects, most notably the attenuation of photons as they travel through tissue. Accurate image reconstruction, especially for quantitative analysis, depends critically on correcting for this effect. This problem [@problem_id:4907936] explores a clinically relevant scenario where a metal artifact leads to an incorrect attenuation map, demonstrating how such errors propagate through the processing chain to create a significant bias in the final reconstructed activity and the widely used Standardized Uptake Value (SUV). This highlights the principle that accurate quantitative imaging is only possible with accurate physical corrections.", "problem": "A positron emission tomography (PET) system performs attenuation correction using a linear attenuation coefficient map (commonly called a $\\mu$-map) derived from computed tomography (CT) and scaled to $511\\,\\text{keV}$. Consider a small spherical lesion whose activity concentration is uniform. All lines of response (LORs) that contribute to the reconstruction of this lesion traverse a localized metal artifact region in the $\\mu$-map where the linear attenuation coefficient has been overestimated relative to its true $511\\,\\text{keV}$ value. The artifact region has thickness $L_{\\text{art}} = 1.8\\,\\text{cm}$ along each such LOR. The true coefficient within the artifact region is $\\mu_{\\text{true}} = 0.18\\,\\text{cm}^{-1}$, whereas the $\\mu$-map value used for attenuation correction in that region is $\\mu_{\\text{est}} = 0.28\\,\\text{cm}^{-1}$. Everywhere else along each LOR, the $\\mu$-map equals the true coefficient.\n\nAssume the following idealized conditions:\n- Annihilation photon transport obeys the Beer–Lambert law along each LOR.\n- The measured sinogram values are corrected by multiplicative attenuation correction factors computed from the $\\mu$-map.\n- Normalization, calibration, scatter, randoms, and dead-time corrections are perfect.\n- The reconstruction algorithm is unbiased and locally linear with respect to the corrected sinogram, so that any multiplicative error in attenuation correction along LORs intersecting the lesion propagates multiplicatively into the reconstructed lesion activity concentration.\n- The Standardized Uptake Value (SUV) is defined as $\\text{SUV} = c/A_{\\text{norm}}$, where $c$ is the reconstructed activity concentration and $A_{\\text{norm}}$ is the injected activity normalized by body mass. Under the above assumptions, $A_{\\text{norm}}$ is unaffected by the artifact.\n\nStarting from the Beer–Lambert law and the operational definition of attenuation correction factors in PET reconstruction, derive an expression for the multiplicative bias factor on the reconstructed lesion activity concentration caused by the overestimated $\\mu$ in the artifact region, and from it determine the resulting fractional bias in the local SUV for the lesion, expressed as a decimal number (dimensionless). Use the numerical values provided above. Round your final answer to four significant figures and express it as a decimal fraction without units.", "solution": "The problem requires the calculation of the fractional bias in the Standardized Uptake Value (SUV) of a lesion due to an error in the attenuation map used for PET image reconstruction. The solution begins with the fundamental principles of photon attenuation and PET data correction.\n\nLet an LOR (line of response) pass through the patient. According to the Beer–Lambert law, if a number of photon pairs $N_0$ are emitted along this LOR, the number of pairs detected, $m$ (which corresponds to a sinogram value), is reduced by an attenuation factor, $A_{\\text{true}}$.\nThe true attenuation factor is determined by the line integral of the true linear attenuation coefficient, $\\mu_{\\text{true}}(l)$, along the LOR path, $L$:\n$$A_{\\text{true}} = \\exp\\left(-\\int_L \\mu_{\\text{true}}(l) \\, dl\\right)$$\nThe measured sinogram value $m$ is thus related to the unattenuated signal $p_0$ (which is proportional to the line integral of the activity concentration) by:\n$$m = p_0 \\cdot A_{\\text{true}} = p_0 \\exp\\left(-\\int_L \\mu_{\\text{true}}(l) \\, dl\\right)$$\n\nIn PET reconstruction, the measured data $m$ are corrected for this attenuation by multiplying them by an Attenuation Correction Factor (ACF). The ACF is calculated as the inverse of the attenuation factor, but it is computed using the estimated attenuation map, $\\mu_{\\text{est}}(l)$, derived from CT.\n$$\\text{ACF}_{\\text{est}} = \\frac{1}{\\exp\\left(-\\int_L \\mu_{\\text{est}}(l) \\, dl\\right)} = \\exp\\left(\\int_L \\mu_{\\text{est}}(l) \\, dl\\right)$$\nThe corrected sinogram value, $p_{\\text{est}}$, which is input to the reconstruction algorithm, is the product of the measured data and the estimated ACF:\n$$p_{\\text{est}} = m \\cdot \\text{ACF}_{\\text{est}}$$\nSubstituting the expressions for $m$ and $\\text{ACF}_{\\text{est}}$:\n$$p_{\\text{est}} = \\left[p_0 \\exp\\left(-\\int_L \\mu_{\\text{true}}(l) \\, dl\\right)\\right] \\cdot \\left[\\exp\\left(\\int_L \\mu_{\\text{est}}(l) \\, dl\\right)\\right]$$\n$$p_{\\text{est}} = p_0 \\exp\\left(\\int_L \\mu_{\\text{est}}(l) \\, dl - \\int_L \\mu_{\\text{true}}(l) \\, dl\\right) = p_0 \\exp\\left(\\int_L \\left[\\mu_{\\text{est}}(l) - \\mu_{\\text{true}}(l)\\right] \\, dl\\right)$$\n\nThe problem states that the estimated attenuation coefficient $\\mu_{\\text{est}}$ is incorrect only within a specific artifact region of thickness $L_{\\text{art}}$, and correct everywhere else. Therefore, the difference $\\mu_{\\text{est}}(l) - \\mu_{\\text{true}}(l)$ is zero everywhere except in this region. The integral simplifies to an integral over just the artifact region:\n$$\\int_L \\left[\\mu_{\\text{est}}(l) - \\mu_{\\text{true}}(l)\\right] \\, dl = \\int_{\\text{artifact}} (\\mu_{\\text{est}} - \\mu_{\\text{true}}) \\, dl$$\nWithin this region, the coefficients are constant. Let the values be $\\mu_{\\text{est}}$ and $\\mu_{\\text{true}}$ as given. The integral becomes:\n$$\\int_{\\text{artifact}} (\\mu_{\\text{est}} - \\mu_{\\text{true}}) \\, dl = (\\mu_{\\text{est}} - \\mu_{\\text{true}}) L_{\\text{art}}$$\nSo, the corrected sinogram data is:\n$$p_{\\text{est}} = p_0 \\exp\\left((\\mu_{\\text{est}} - \\mu_{\\text{true}}) L_{\\text{art}}\\right)$$\n\nIdeally, if the attenuation map were perfect ($\\mu_{\\text{est}}(l) = \\mu_{\\text{true}}(l)$), the corrected data, $p_{\\text{true}}$, would be:\n$$p_{\\text{true}} = p_0 \\exp\\left(\\int_L \\left[\\mu_{\\text{true}}(l) - \\mu_{\\text{true}}(l)\\right] \\, dl\\right) = p_0 \\exp(0) = p_0$$\nThis confirms that a perfect correction recovers the original unattenuated signal.\n\nThe multiplicative bias factor, $B$, on the corrected sinogram data is the ratio of the estimated corrected data to the ideal corrected data:\n$$B = \\frac{p_{\\text{est}}}{p_{\\text{true}}} = \\frac{p_0 \\exp\\left((\\mu_{\\text{est}} - \\mu_{\\text{true}}) L_{\\text{art}}\\right)}{p_0} = \\exp\\left((\\mu_{\\text{est}} - \\mu_{\\text{true}}) L_{\\text{art}}\\right)$$\n\nThe problem states that the reconstruction algorithm is linear, so this multiplicative bias on the sinogram data propagates directly as a multiplicative bias on the reconstructed activity concentration, $c$. If $c_{\\text{true}}$ is the true concentration and $c_{\\text{est}}$ is the reconstructed concentration with the artifact, then:\n$$c_{\\text{est}} = B \\cdot c_{\\text{true}}$$\nThe SUV is defined as $\\text{SUV} = c/A_{\\text{norm}}$. Since $A_{\\text{norm}}$ is unaffected, the SUV is also biased by the same factor:\n$$\\text{SUV}_{\\text{est}} = \\frac{c_{\\text{est}}}{A_{\\text{norm}}} = \\frac{B \\cdot c_{\\text{true}}}{A_{\\text{norm}}} = B \\cdot \\text{SUV}_{\\text{true}}$$\n\nThe fractional bias, $F$, in the SUV is defined as the change relative to the true value:\n$$F = \\frac{\\text{SUV}_{\\text{est}} - \\text{SUV}_{\\text{true}}}{\\text{SUV}_{\\text{true}}} = \\frac{B \\cdot \\text{SUV}_{\\text{true}} - \\text{SUV}_{\\text{true}}}{\\text{SUV}_{\\text{true}}} = B - 1$$\nSubstituting the expression for $B$, the fractional bias is:\n$$F = \\exp\\left((\\mu_{\\text{est}} - \\mu_{\\text{true}}) L_{\\text{art}}\\right) - 1$$\n\nNow, we substitute the numerical values provided:\n$L_{\\text{art}} = 1.8\\,\\text{cm}$\n$\\mu_{\\text{true}} = 0.18\\,\\text{cm}^{-1}$\n$\\mu_{\\text{est}} = 0.28\\,\\text{cm}^{-1}$\n\nThe difference in attenuation coefficients is:\n$$\\Delta\\mu = \\mu_{\\text{est}} - \\mu_{\\text{true}} = 0.28\\,\\text{cm}^{-1} - 0.18\\,\\text{cm}^{-1} = 0.10\\,\\text{cm}^{-1}$$\nThe exponent in the expression for $F$ is:\n$$(\\mu_{\\text{est}} - \\mu_{\\text{true}}) L_{\\text{art}} = (0.10\\,\\text{cm}^{-1}) \\cdot (1.8\\,\\text{cm}) = 0.18$$\nThis quantity is dimensionless, as expected.\n\nThe fractional bias $F$ is:\n$$F = \\exp(0.18) - 1$$\nCalculating the numerical value:\n$$F \\approx 1.19721736 - 1 = 0.19721736$$\nRounding to four significant figures as requested, we get:\n$$F \\approx 0.1972$$\nThis positive value indicates an overestimation of the SUV by approximately $19.72\\%$.", "answer": "$$\\boxed{0.1972}$$", "id": "4907936"}, {"introduction": "Once the raw data has been acquired and corrected, the central task of reconstruction begins: solving the \"inverse problem\" to create an image from the projection data. This exercise [@problem_id:4907890] takes you into the heart of modern statistical reconstruction by guiding you through one iteration of the foundational Maximum Likelihood Expectation Maximization (ML-EM) algorithm. By applying the ML-EM update equation to a simple toy problem, you will gain a tangible feel for how this iterative method works, progressively refining an image estimate to better explain the measured PET data according to a statistical model.", "problem": "In positron emission tomography (PET), assume a discrete forward model where the measured sinogram counts are modeled as independent Poisson random variables with means given by a linear transform of the unknown voxel activities. Let the measurement model be $y_{i} \\sim \\text{Poisson}(\\lambda_{i})$ with $\\lambda_{i} = \\sum_{j} a_{ij} x_{j} + r_{i} + s_{i}$, where $x_{j}$ are the unknown voxel activities, $a_{ij}$ are elements of the system matrix, $r_{i}$ are randoms, and $s_{i}$ are scatters. Consider the case with no randoms and no scatters, so $r_{i} = 0$ and $s_{i} = 0$ for all $i$.\n\nStarting from the Poisson likelihood of the data under this model and the Expectation Maximization (EM) principle, derive the Maximum Likelihood Expectation Maximization (ML-EM) fixed-point update for one iteration that maps $x^{k}$ to $x^{k+1}$ in terms of $A$, $y$, and $x^{k}$. Then, apply your derived expression to compute a single iteration from the initial estimate $x^{0}$ for the following toy system:\n- System matrix $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$.\n- Measured counts $y = \\begin{bmatrix} 10 \\\\ 6 \\end{bmatrix}$.\n- Randoms and scatters $r = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ and $s = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$.\n- Initial activity estimate $x^{0} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n\nExpress the updated activity estimate $x^{1}$ as exact numbers (no rounding) in arbitrary units. Provide the final answer as a two-element row vector. Do not include units in your final answer.", "solution": "The user-provided problem is evaluated against the validation criteria.\n\n### Problem Validation\n**Step 1: Extract Givens**\n-   **Model**: The measured sinogram counts $y_{i}$ are independent Poisson random variables, $y_{i} \\sim \\text{Poisson}(\\lambda_{i})$.\n-   **Mean of Poisson distribution**: $\\lambda_{i} = \\sum_{j} a_{ij} x_{j} + r_{i} + s_{i}$.\n-   **Variables**:\n    -   $x_{j}$: unknown voxel activities.\n    -   $a_{ij}$: elements of the system matrix $A$.\n    -   $r_{i}$: randoms.\n    -   $s_{i}$: scatters.\n-   **Conditions**: No randoms and no scatters, so $r_{i} = 0$ and $s_{i} = 0$ for all $i$. The model simplifies to $\\lambda_{i} = \\sum_{j} a_{ij} x_{j}$.\n-   **Task 1**: Derive the Maximum Likelihood Expectation Maximization (ML-EM) fixed-point update for one iteration, mapping an estimate $x^{k}$ to $x^{k+1}$.\n-   **Task 2**: Apply the derived expression to compute one iteration, $x^{1}$, for a specific toy system.\n-   **Toy System Data**:\n    -   System matrix: $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$.\n    -   Measured counts: $y = \\begin{bmatrix} 10 \\\\ 6 \\end{bmatrix}$.\n    -   Randoms and scatters: $r = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ and $s = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$.\n    -   Initial activity estimate: $x^{0} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$.\n-   **Output Requirement**: $x^{1}$ as a two-element row vector with exact numbers.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is fundamentally sound. The Poisson model for photon-counting events in PET is a cornerstone of statistical image reconstruction. The Expectation-Maximization algorithm is the standard method for finding the maximum likelihood estimate for this model. The problem is scientifically correct and relevant to the field of medical imaging.\n-   **Well-Posed**: The problem is well-posed. The derivation of the ML-EM algorithm is a standard procedure in the literature, and the provided numerical example is complete and internally consistent, guaranteeing a unique solution for one iteration.\n-   **Objectivity**: The problem is stated using precise and unambiguous mathematical language.\n-   **Conclusion**: There are no scientific or logical flaws, no missing information, and no ambiguities.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A full solution will be provided.\n\n### Solution Derivation and Calculation\n\nThe problem requires the derivation of the Maximum Likelihood Expectation Maximization (ML-EM) update equation for Positron Emission Tomography (PET) and its application to a toy problem.\n\n**Part 1: Derivation of the ML-EM Update Equation**\n\nThe measurement model for PET, in the absence of randoms and scatters, is given by a set of independent Poisson random variables $y_i$, where $i$ indexes the detector pairs (lines of response, LORs):\n$$y_i \\sim \\text{Poisson}(\\lambda_i)$$\nThe mean counts $\\lambda_i$ are related to the unknown voxel activities $x_j$ (where $j$ indexes the voxels) through the system matrix $A$ with elements $a_{ij}$:\n$$\\lambda_i = \\sum_{j=1}^{N} a_{ij} x_j$$\nHere, $N$ is the total number of voxels and $M$ is the total number of LORs.\n\nThe likelihood of observing the measurement vector $y = (y_1, ..., y_M)$ given the activity distribution $x = (x_1, ..., x_N)$ is the product of the individual Poisson probabilities:\n$$L(x) = P(y|x) = \\prod_{i=1}^{M} \\frac{\\lambda_i^{y_i} \\exp(-\\lambda_i)}{y_i!} = \\prod_{i=1}^{M} \\frac{\\left(\\sum_{j=1}^{N} a_{ij} x_j\\right)^{y_i} \\exp\\left(-\\sum_{j=1}^{N} a_{ij} x_j\\right)}{y_i!}$$\nThe log-likelihood function $\\mathcal{L}(x) = \\ln(L(x))$ is:\n$$\\mathcal{L}(x) = \\sum_{i=1}^{M} \\left( y_i \\ln\\left(\\sum_{j=1}^{N} a_{ij} x_j\\right) - \\sum_{j=1}^{N} a_{ij} x_j \\right) - \\sum_{i=1}^{M} \\ln(y_i!)$$\nMaximizing this log-likelihood directly is difficult due to the logarithm of a sum. The EM algorithm circumvents this by introducing \"complete\" but unobserved (hidden) data.\n\nLet the complete data be $Z_{ij}$, representing the number of emissions from voxel $j$ that are detected in LOR $i$. These are modeled as independent Poisson variables:\n$$Z_{ij} \\sim \\text{Poisson}(a_{ij} x_j)$$\nThe observed data $y_i$ are the sum of these hidden variables over all voxels:\n$$y_i = \\sum_{j=1}^{N} Z_{ij}$$\nThe log-likelihood of the complete data $Z = \\{Z_{ij}\\}$ is much simpler:\n$$\\mathcal{L}_C(x; Z) = \\ln(P(Z|x)) = \\sum_{i=1}^{M} \\sum_{j=1}^{N} \\left( Z_{ij} \\ln(a_{ij} x_j) - a_{ij} x_j - \\ln(Z_{ij}!) \\right)$$\n\nThe EM algorithm is an iterative two-step process:\n1.  **E-step (Expectation):** Compute the expected value of the complete-data log-likelihood, conditioned on the observed data $y$ and the current parameter estimate $x^k$. Let this function be $Q(x|x^k)$.\n    $$Q(x|x^k) = E[\\mathcal{L}_C(x; Z) | y, x^k]$$\n    This requires finding the conditional expectation of the hidden data, $\\hat{Z}_{ij}^k = E[Z_{ij} | y, x^k]$. For a fixed LOR $i$, given the total count $y_i = \\sum_j Z_{ij}$, the conditional distribution of $\\{Z_{ij}\\}_{j=1,...,N}$ is multinomial. The conditional expectation of $Z_{ij}$ is:\n    $$\\hat{Z}_{ij}^k = E[Z_{ij} | y_i, x^k] = y_i \\frac{a_{ij} x_j^k}{\\sum_{l=1}^{N} a_{il} x_l^k}$$\n    Substituting this into the expression for $Q(x|x^k)$ and dropping terms independent of $x$:\n    $$Q(x|x^k) = \\sum_{i=1}^{M} \\sum_{j=1}^{N} \\left( \\hat{Z}_{ij}^k \\ln(a_{ij} x_j) - a_{ij} x_j \\right) + \\text{const.}$$\n\n2.  **M-step (Maximization):** Find the new estimate $x^{k+1}$ that maximizes $Q(x|x^k)$. We can do this by taking the partial derivative with respect to each $x_j$ and setting it to zero.\n    $$\\frac{\\partial Q(x|x^k)}{\\partial x_j} = \\sum_{i=1}^{M} \\left( \\frac{\\hat{Z}_{ij}^k}{x_j} - a_{ij} \\right) = 0$$\n    Solving for $x_j$ gives the updated estimate $x_j^{k+1}$:\n    $$x_j^{k+1} \\sum_{i=1}^{M} a_{ij} = \\sum_{i=1}^{M} \\hat{Z}_{ij}^k$$\n    $$x_j^{k+1} = \\frac{\\sum_{i=1}^{M} \\hat{Z}_{ij}^k}{\\sum_{i=1}^{M} a_{ij}}$$\n    Substituting the expression for $\\hat{Z}_{ij}^k$:\n    $$x_j^{k+1} = \\frac{\\sum_{i=1}^{M} y_i \\frac{a_{ij} x_j^k}{\\sum_{l=1}^{N} a_{il} x_l^k}}{\\sum_{i=1}^{M} a_{ij}}$$\n    Rearranging the terms yields the final ML-EM update equation:\n    $$x_j^{k+1} = \\frac{x_j^k}{\\sum_{i=1}^{M} a_{ij}} \\sum_{i=1}^{M} \\frac{a_{ij} y_i}{\\sum_{l=1}^{N} a_{il} x_l^k}$$\nThis is the required fixed-point update expression.\n\n**Part 2: Application to the Toy System**\n\nWe apply the derived formula for one iteration, to compute $x^1$ from $x^0$.\nThe given data are:\n-   System matrix $A = \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix}$\n-   Measured counts $y = \\begin{bmatrix} 10 \\\\ 6 \\end{bmatrix}$\n-   Initial estimate $x^0 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n\nThe system has $N=2$ voxels and $M=2$ LORs. The components are $x_1^0 = 1$, $x_2^0 = 1$, $y_1=10$, $y_2=6$, and the matrix elements are $a_{11}=1, a_{12}=1, a_{21}=0, a_{22}=1$.\n\nFirst, we calculate the denominators in the update equation.\nThe forward-projected estimates $\\sum_{l=1}^2 a_{il} x_l^0$ for $i=1, 2$:\n-   For $i=1$: $\\sum_{l=1}^2 a_{1l} x_l^0 = a_{11} x_1^0 + a_{12} x_2^0 = (1)(1) + (1)(1) = 2$.\n-   For $i=2$: $\\sum_{l=1}^2 a_{2l} x_l^0 = a_{21} x_1^0 + a_{22} x_2^0 = (0)(1) + (1)(1) = 1$.\n\nThe sensitivity factors (column sums of $A$) $\\sum_{i=1}^2 a_{ij}$ for $j=1, 2$:\n-   For $j=1$: $\\sum_{i=1}^2 a_{i1} = a_{11} + a_{21} = 1 + 0 = 1$.\n-   For $j=2$: $\\sum_{i=1}^2 a_{i2} = a_{12} + a_{22} = 1 + 1 = 2$.\n\nNow, we compute the updated voxel activities $x_1^1$ and $x_2^1$.\n\nFor voxel $j=1$:\n$$x_1^{1} = \\frac{x_1^0}{\\sum_{i=1}^{2} a_{i1}} \\sum_{i=1}^{2} \\frac{a_{i1} y_i}{\\sum_{l=1}^{2} a_{il} x_l^0} = \\frac{1}{1} \\left( \\frac{a_{11} y_1}{\\sum_{l} a_{1l} x_l^0} + \\frac{a_{21} y_2}{\\sum_{l} a_{2l} x_l^0} \\right)$$\n$$x_1^{1} = 1 \\cdot \\left( \\frac{1 \\cdot 10}{2} + \\frac{0 \\cdot 6}{1} \\right) = \\frac{10}{2} + 0 = 5$$\n\nFor voxel $j=2$:\n$$x_2^{1} = \\frac{x_2^0}{\\sum_{i=1}^{2} a_{i2}} \\sum_{i=1}^{2} \\frac{a_{i2} y_i}{\\sum_{l=1}^{2} a_{il} x_l^0} = \\frac{1}{2} \\left( \\frac{a_{12} y_1}{\\sum_{l} a_{1l} x_l^0} + \\frac{a_{22} y_2}{\\sum_{l} a_{2l} x_l^0} \\right)$$\n$$x_2^{1} = \\frac{1}{2} \\left( \\frac{1 \\cdot 10}{2} + \\frac{1 \\cdot 6}{1} \\right) = \\frac{1}{2} \\left( 5 + 6 \\right) = \\frac{11}{2}$$\n\nThe updated activity estimate after one iteration is $x^1 = \\begin{bmatrix} 5 \\\\ \\frac{11}{2} \\end{bmatrix}$. The problem asks for the answer as a two-element row vector.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n5 & \\frac{11}{2}\n\\end{pmatrix}\n}\n$$", "id": "4907890"}]}