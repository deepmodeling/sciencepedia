{"hands_on_practices": [{"introduction": "The energy resolution of a detector system is not arbitrary; it is fundamentally limited by the underlying physics of signal generation. This first practice explores the ultimate performance boundary set by the statistical nature of light production and detection in a scintillator. By modeling the process from gamma-ray interaction to photoelectron counting, you will derive the photostatistics-limited energy resolution from first principles and see how intrinsic material properties like light yield and decay time dictate the best possible performance [@problem_id:4883258].", "problem": "Consider three inorganic scintillators used in medical imaging energy measurement of annihilation photons: sodium iodide activated with thallium $\\mathrm{NaI(Tl)}$, cerium-doped lutetium–yttrium oxyorthosilicate $\\mathrm{LYSO:Ce}$, and cerium-doped lanthanum bromide $\\mathrm{LaBr_{3}:Ce}$. Each produces scintillation photons with a tabulated light yield $Y$ (in photons per megaelectronvolt) and an exponential emission time profile with decay constant $\\tau$. A $E = 0.511~\\mathrm{MeV}$ gamma ray deposits all its energy in each crystal. Assume identical optical coupling and a common photosensor with photon detection efficiency (PDE) $\\eta = 0.25$ for all three crystals. The charge integrator uses a fixed rectangular gate of duration $T = 100~\\mathrm{ns}$ starting at the scintillation onset.\n\nTabulated properties:\n- $\\mathrm{NaI(Tl)}$: $Y_{\\mathrm{NaI}} = 3.8 \\times 10^{4}~\\mathrm{photons/MeV}$, $\\tau_{\\mathrm{NaI}} = 230~\\mathrm{ns}$.\n- $\\mathrm{LYSO:Ce}$: $Y_{\\mathrm{LYSO}} = 3.0 \\times 10^{4}~\\mathrm{photons/MeV}$, $\\tau_{\\mathrm{LYSO}} = 40~\\mathrm{ns}$.\n- $\\mathrm{LaBr_{3}:Ce}$: $Y_{\\mathrm{LaBr3}} = 6.3 \\times 10^{4}~\\mathrm{photons/MeV}$, $\\tau_{\\mathrm{LaBr3}} = 16~\\mathrm{ns}$.\n\nStarting from first principles:\n1. Use Poisson statistics for photoelectron counting to connect the variance in detected photoelectrons to the fractional spread of the measured pulse height.\n2. For a Gaussian peak, use the relationship between full width at half maximum (FWHM) and the standard deviation.\n3. Model the scintillation photon emission as $I(t) \\propto \\exp(-t/\\tau)$ and compute the fraction of light collected within the gate $T$.\n4. Derive an expression for the photostatistics-limited energy resolution $R$ (defined as $\\mathrm{FWHM}/E$) in terms of $Y$, $\\eta$, $E$, $\\tau$, and $T$.\n5. Evaluate $R$ numerically for the three materials using the tabulated values, under the assumptions of linear detector response, no electronic noise, and no gain fluctuations.\n\nThen, briefly state how light-yield non-proportionality (energy-dependent scintillation yield and track structure effects) would modify the measured $R$ relative to the photostatistics limit, without performing additional calculations.\n\nExpress each $R$ as a unitless decimal and round to three significant figures.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. All necessary data and conditions for calculating the photostatistics-limited energy resolution are provided, and the physical principles involved—scintillation, Poisson statistics, and Gaussian peak analysis—are standard in the field of radiation detection. The provided material properties and experimental parameters are realistic. Therefore, the problem is valid, and I will proceed with a full solution.\n\nThe derivation follows the steps outlined in the problem statement.\n\nThe energy resolution, $R$, of a scintillation detector is fundamentally limited by statistical fluctuations in the number of signal carriers, which in this case are the photoelectrons detected by the photosensor. We assume the measured pulse height, $H$, is directly proportional to the number of detected photoelectrons, $N_{pe}$.\n\nStep 1: Connection between Poisson statistics and pulse height spread.\nThe process begins with the deposition of energy $E$ from a gamma ray. This creates an average number of scintillation photons, $N_{photons}$, given by:\n$$\n\\bar{N}_{photons} = Y \\cdot E\n$$\nwhere $Y$ is the scintillator's light yield in photons per unit energy. These photons are then detected by a photosensor with photon detection efficiency $\\eta$. The detection of each photon is a Bernoulli trial. For a large number of initial photons and a constant probability of detection, the number of detected photoelectrons, $N_{pe}$, follows a Poisson distribution. The mean number of detected photoelectrons, $\\bar{N}_{pe}$, is:\n$$\n\\bar{N}_{pe} = \\eta \\cdot \\bar{N}_{photons} = \\eta \\cdot Y \\cdot E\n$$\nA key property of the Poisson distribution is that its variance is equal to its mean:\n$$\n\\sigma^2_{N_{pe}} = \\bar{N}_{pe}\n$$\nThe standard deviation of the number of photoelectrons is therefore $\\sigma_{N_{pe}} = \\sqrt{\\bar{N}_{pe}}$.\nThe measured pulse height, $H$, is proportional to $N_{pe}$, so $H = k N_{pe}$ for some constant gain $k$. The mean pulse height is $\\bar{H} = k \\bar{N}_{pe}$ and its standard deviation is $\\sigma_H = k \\sigma_{N_{pe}}$. The fractional spread of the measured pulse height is the ratio of its standard deviation to its mean:\n$$\n\\frac{\\sigma_H}{\\bar{H}} = \\frac{k \\sigma_{N_{pe}}}{k \\bar{N}_{pe}} = \\frac{\\sqrt{\\bar{N}_{pe}}}{\\bar{N}_{pe}} = \\frac{1}{\\sqrt{\\bar{N}_{pe}}}\n$$\n\nStep 2: Relation between FWHM and standard deviation for a Gaussian peak.\nFor a large mean value, the Poisson distribution of $N_{pe}$ can be accurately approximated by a Gaussian distribution. The relationship between the full width at half maximum (FWHM) and the standard deviation ($\\sigma$) of a Gaussian distribution is:\n$$\n\\mathrm{FWHM} = 2\\sqrt{2\\ln(2)} \\sigma\n$$\nThe energy resolution $R$ is defined as the FWHM of the photopeak in the energy spectrum divided by the position of the peak's centroid (the mean energy $E$). Since energy is proportional to pulse height, this is equivalent to the FWHM of the pulse height distribution divided by the mean pulse height:\n$$\nR = \\frac{\\mathrm{FWHM}_H}{\\bar{H}} = \\frac{2\\sqrt{2\\ln(2)} \\sigma_H}{\\bar{H}}\n$$\nSubstituting the result from Step 1, we get:\n$$\nR = 2\\sqrt{2\\ln(2)} \\left(\\frac{1}{\\sqrt{\\bar{N}_{pe}}}\\right) = \\frac{2\\sqrt{2\\ln(2)}}{\\sqrt{\\bar{N}_{pe}}}\n$$\n\nStep 3: Fraction of light collected within the integration gate.\nThe scintillation light emission follows an exponential decay with time constant $\\tau$. The normalized intensity profile is $I(t) = \\frac{1}{\\tau}\\exp(-t/\\tau)$ for $t \\ge 0$. The charge integrator collects light only for a finite duration $T$ starting at $t=0$. The fraction of the total light collected, $f_c$, is the integral of the intensity profile from $t=0$ to $t=T$:\n$$\nf_c = \\int_{0}^{T} \\frac{1}{\\tau} \\exp(-t/\\tau) \\,dt = \\left[ -\\exp(-t/\\tau) \\right]_{0}^{T} = -\\exp(-T/\\tau) - (-1) = 1 - \\exp(-T/\\tau)\n$$\n\nStep 4: Derivation of the full expression for energy resolution $R$.\nWe must modify the expression for $\\bar{N}_{pe}$ to account for the incomplete light collection. The mean number of photoelectrons is now based only on the fraction of photons collected within the gate $T$.\n$$\n\\bar{N}_{pe} = \\eta \\cdot f_c \\cdot \\bar{N}_{photons} = \\eta \\cdot (1 - \\exp(-T/\\tau)) \\cdot Y \\cdot E\n$$\nSubstituting this corrected $\\bar{N}_{pe}$ into the expression for $R$ from Step 2 gives the final expression for the photostatistics-limited energy resolution:\n$$\nR(Y, \\eta, E, \\tau, T) = \\frac{2\\sqrt{2\\ln(2)}}{\\sqrt{\\eta \\cdot E \\cdot Y \\cdot (1 - \\exp(-T/\\tau))}}\n$$\n\nStep 5: Numerical evaluation for the three scintillators.\nWe are given $E = 0.511~\\mathrm{MeV}$, $\\eta = 0.25$, and $T = 100~\\mathrm{ns}$. The numerical factor is $2\\sqrt{2\\ln(2)} \\approx 2.355$.\n\nFor $\\mathrm{NaI(Tl)}$:\n$Y_{\\mathrm{NaI}} = 3.8 \\times 10^{4}~\\mathrm{MeV}^{-1}$, $\\tau_{\\mathrm{NaI}} = 230~\\mathrm{ns}$.\nThe collection fraction is $f_{c, \\mathrm{NaI}} = 1 - \\exp(-100/230) \\approx 0.3528$.\nThe mean number of photoelectrons is $\\bar{N}_{pe, \\mathrm{NaI}} = (0.25) \\cdot (0.511) \\cdot (3.8 \\times 10^4) \\cdot (0.3528) \\approx 1711.6$.\nThe energy resolution is $R_{\\mathrm{NaI}} = \\frac{2.355}{\\sqrt{1711.6}} \\approx \\frac{2.355}{41.37} \\approx 0.05692$.\nRounded to three significant figures, $R_{\\mathrm{NaI}} = 0.0569$.\n\nFor $\\mathrm{LYSO:Ce}$:\n$Y_{\\mathrm{LYSO}} = 3.0 \\times 10^{4}~\\mathrm{MeV}^{-1}$, $\\tau_{\\mathrm{LYSO}} = 40~\\mathrm{ns}$.\nThe collection fraction is $f_{c, \\mathrm{LYSO}} = 1 - \\exp(-100/40) = 1 - \\exp(-2.5) \\approx 0.9179$.\nThe mean number of photoelectrons is $\\bar{N}_{pe, \\mathrm{LYSO}} = (0.25) \\cdot (0.511) \\cdot (3.0 \\times 10^4) \\cdot (0.9179) \\approx 3517.8$.\nThe energy resolution is $R_{\\mathrm{LYSO}} = \\frac{2.355}{\\sqrt{3517.8}} \\approx \\frac{2.355}{59.31} \\approx 0.03971$.\nRounded to three significant figures, $R_{\\mathrm{LYSO}} = 0.0397$.\n\nFor $\\mathrm{LaBr_{3}:Ce}$:\n$Y_{\\mathrm{LaBr3}} = 6.3 \\times 10^{4}~\\mathrm{MeV}^{-1}$, $\\tau_{\\mathrm{LaBr3}} = 16~\\mathrm{ns}$.\nThe collection fraction is $f_{c, \\mathrm{LaBr3}} = 1 - \\exp(-100/16) = 1 - \\exp(-6.25) \\approx 0.9981$.\nThe mean number of photoelectrons is $\\bar{N}_{pe, \\mathrm{LaBr3}} = (0.25) \\cdot (0.511) \\cdot (6.3 \\times 10^4) \\cdot (0.9981) \\approx 8033.4$.\nThe energy resolution is $R_{\\mathrm{LaBr3}} = \\frac{2.355}{\\sqrt{8033.4}} \\approx \\frac{2.355}{89.63} \\approx 0.02627$.\nRounded to three significant figures, $R_{\\mathrm{LaBr3}} = 0.0263$.\n\nBrief statement on light-yield non-proportionality:\nThe preceding calculation assumes that the light yield, $Y$, is a constant, meaning the number of scintillation photons is strictly proportional to the deposited energy $E$. In reality, scintillators exhibit non-proportionality, where the light yield per unit energy, $dL/dE$, depends on the energy of the ionizing particle. A gamma ray deposits its energy by creating a cascade of secondary electrons with a distribution of energies. Since the light yield is different for each of these secondary electrons, the total light output for a fixed total deposited energy $E$ will have a statistical fluctuation that depends on the specific history of the electron cascade. This effect introduces an additional source of variance in the signal, known as the intrinsic resolution of the scintillator. This variance adds in quadrature to the photostatistical variance. Consequently, the measured energy resolution $R_{measured}$ will always be worse (i.e., a larger value) than the ideal photostatistics-limited resolution $R$ calculated above.", "answer": "$$\\boxed{\\begin{pmatrix} 0.0569 & 0.0397 & 0.0263 \\end{pmatrix}}$$", "id": "4883258"}, {"introduction": "While theoretical limits provide crucial insight, a key practical skill is the ability to determine energy resolution from actual experimental data. This exercise simulates a common laboratory workflow: calibrating a detector system and analyzing a measured photopeak to quantify its performance [@problem_id:4883305]. You will work through the essential steps of converting raw channel data from a multi-channel analyzer into a calibrated energy spectrum and then calculating the energy resolution, bridging the gap between abstract theory and concrete measurement.", "problem": "A scintillation detector is coupled to a Multi-Channel Analyzer (MCA), which records a pulse-height spectrum along a channel coordinate $C$. The energy-to-channel relationship is known to be linear. Two calibration peaks of known photon energies are observed at channels $C_1$ and $C_2$, respectively, and are used to determine the linear calibration. An unknown peak of interest is then measured.\n\nThe calibration data are:\n- Known energy $E_1 = 511 \\text{ keV}$ at channel $C_1 = 420.0$.\n- Known energy $E_2 = 1274.5 \\text{ keV}$ at channel $C_2 = 1030.0$.\n\nAssume a linear calibration $E = a + b\\,C$, where $a$ and $b$ are constants to be determined from the calibration data.\n\nAn unknown peak is measured with centroid at $C_0 = 600.0$. The spectrum has been rebinned so that each histogram bin spans $\\Delta C = 2.0$ channels along the $C$-axis. A Gaussian model is fitted to the rebinned peak, yielding a standard deviation $\\sigma_C = 1.8$ expressed in the number of bins.\n\nStarting from the fundamental definition that the energy resolution is the full width at half maximum divided by the peak energy, and using the property of a Gaussian that the full width at half maximum is $2\\sqrt{2\\ln 2}$ times its standard deviation, do the following:\n1. Determine the calibration parameters $a$ and $b$, and compute the peak energy $E$ at $C_0$.\n2. Convert the fitted width to an energy-domain standard deviation, carefully accounting for the bin width $\\Delta C$.\n3. Derive and compute the energy resolution $R$ defined by $R = \\text{FWHM} / E$, where FWHM is the full width at half maximum in energy.\n\nExpress the final value of $R$ as a pure decimal (no unit), rounded to four significant figures. Energies should be treated in $\\text{keV}$.", "solution": "The problem statement is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n### Step 1: Extract Givens\n- Energy-to-channel relationship: $E = a + b\\,C$ (linear)\n- Calibration point 1: $E_1 = 511 \\text{ keV}$ at channel $C_1 = 420.0$.\n- Calibration point 2: $E_2 = 1274.5 \\text{ keV}$ at channel $C_2 = 1030.0$.\n- Unknown peak centroid: $C_0 = 600.0$.\n- Histogram bin width: $\\Delta C = 2.0$ channels.\n- Fitted Gaussian standard deviation: $\\sigma_C = 1.8$ bins.\n- FWHM for a Gaussian: $\\text{FWHM} = (2\\sqrt{2\\ln 2}) \\times (\\text{standard deviation})$.\n- Definition of energy resolution: $R = \\text{FWHM} / E$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem uses standard principles of nuclear spectroscopy, including linear detector calibration, Gaussian peak modeling, and the definition of energy resolution. The energy values ($511 \\text{ keV}$ and $1274.5 \\text{ keV}$) are realistic, corresponding to common calibration sources (positron annihilation and $^{22}\\text{Na}$). The entire setup is scientifically correct.\n- **Well-Posedness**: The problem provides two distinct calibration points to determine the two parameters of a linear equation, ensuring a unique solution for the calibration. All subsequent data required for the calculation of energy and resolution are provided.\n- **Objectivity and Completeness**: The problem is stated with precise, quantitative data and definitions, free from ambiguity or subjective interpretation. It is self-contained and consistent.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be formulated.\n\nThe solution proceeds in three parts as requested.\n\n**1. Determine the calibration parameters and peak energy**\n\nThe linear calibration model is given by $E = a + bC$, where $E$ is the energy in $\\text{keV}$ and $C$ is the channel number. We have two data points, $(C_1, E_1)$ and $(C_2, E_2)$, which we can use to form a system of two linear equations:\n$$E_1 = a + bC_1$$\n$$E_2 = a + bC_2$$\nSubtracting the first equation from the second yields:\n$$E_2 - E_1 = b(C_2 - C_1)$$\nSolving for the slope $b$, which represents the energy per channel (gain):\n$$b = \\frac{E_2 - E_1}{C_2 - C_1}$$\nSubstituting the given values:\n$$b = \\frac{1274.5 \\text{ keV} - 511 \\text{ keV}}{1030.0 - 420.0} = \\frac{763.5 \\text{ keV}}{610.0} \\approx 1.25164 \\text{ keV/channel}$$\nNow, we can solve for the intercept $a$ using the first equation:\n$$a = E_1 - bC_1$$\nSubstituting the value of $b$ and the first data point:\n$$a = 511 - (1.251639344...) \\times 420.0 \\approx 511 - 525.68852 \\approx -14.68852 \\text{ keV}$$\nSo the full calibration equation is $E(C) = -14.68852 + 1.25164 C$.\n\nThe energy $E_0$ corresponding to the unknown peak at channel $C_0 = 600.0$ is:\n$$E_0 = a + bC_0 \\approx -14.68852 + (1.251639344...) \\times 600.0 \\approx -14.68852 + 750.98361 \\approx 736.295 \\text{ keV}$$\n\n**2. Convert the fitted width to an energy-domain standard deviation**\n\nThe standard deviation from the Gaussian fit is given as $\\sigma_C = 1.8$ bins. This must be converted to the channel domain first. The bin width is given as $\\Delta C = 2.0$ channels/bin. The standard deviation in units of channels, denoted $\\sigma_{\\text{ch}}$, is:\n$$\\sigma_{\\text{ch}} = \\sigma_C \\times \\Delta C = 1.8 \\text{ bins} \\times 2.0 \\frac{\\text{channels}}{\\text{bin}} = 3.6 \\text{ channels}$$\nSince the energy calibration is linear, a width in the channel domain can be converted to a width in the energy domain by multiplying by the slope $b$ of the calibration line. The standard deviation in energy, $\\sigma_E$, is:\n$$\\sigma_E = b \\times \\sigma_{\\text{ch}} \\approx 1.25164 \\frac{\\text{keV}}{\\text{channel}} \\times 3.6 \\text{ channels} \\approx 4.5059 \\text{ keV}$$\n\n**3. Derive and compute the energy resolution**\n\nThe energy resolution $R$ is defined as the ratio of the full width at half maximum in energy ($\\text{FWHM}_E$) to the peak energy $E_0$:\n$$R = \\frac{\\text{FWHM}_E}{E_0}$$\nThe problem states that for a Gaussian distribution, the FWHM is related to the standard deviation $\\sigma_E$ by:\n$$\\text{FWHM}_E = (2\\sqrt{2\\ln 2}) \\sigma_E$$\nThe constant factor is approximately $2\\sqrt{2\\ln 2} \\approx 2.35482$.\nFirst, we calculate $\\text{FWHM}_E$:\n$$\\text{FWHM}_E \\approx 2.35482 \\times \\sigma_E \\approx 2.35482 \\times 4.5059 \\text{ keV} \\approx 10.610 \\text{ keV}$$\nNow, we can compute the energy resolution $R$:\n$$R = \\frac{\\text{FWHM}_E}{E_0} \\approx \\frac{10.610 \\text{ keV}}{736.295 \\text{ keV}} \\approx 0.014410$$\nRounding the result to four significant figures as requested, we obtain $R = 0.01441$.\nThe expression for $R$ in terms of the initial parameters is:\n$$R = \\frac{(2\\sqrt{2\\ln 2}) \\times (\\sigma_C \\times \\Delta C) \\times b}{a + bC_0} = \\frac{(2\\sqrt{2\\ln 2}) \\times (\\sigma_C \\times \\Delta C) \\times \\frac{E_2 - E_1}{C_2 - C_1}}{(E_1 - bC_1) + bC_0} = \\frac{(2\\sqrt{2\\ln 2})(\\sigma_C \\Delta C) \\frac{E_2 - E_1}{C_2 - C_1}}{E_1 + \\frac{E_2 - E_1}{C_2 - C_1}(C_0 - C_1)}$$", "answer": "$$\\boxed{0.01441}$$", "id": "4883305"}, {"introduction": "An ideal detector would register every incoming photon, but real systems require a finite processing time, leading to a \"dead time\" during which subsequent events are missed. This effect is a critical consideration at the high event rates encountered in many medical imaging applications, as it can lead to inaccurate quantification. This exercise guides you through deriving the mathematical models for the two primary types of dead time—paralyzable and non-paralyzable—and then challenges you to use experimental data to identify which model best describes a given system [@problem_id:4883310].", "problem": "A gamma spectroscopy system based on a sodium iodide scintillator with a Photomultiplier Tube (PMT) and a Pulse Height Analyzer (PHA) records photon interaction pulses drawn from a homogeneous Poisson process with true arrival rate $\\lambda$ (in $\\text{s}^{-1}$). The shaping amplifier and discriminator chain impose a fixed dead time $\\tau$ after each recorded pulse. Two standard dead-time models are considered: non-paralyzable (dead intervals do not extend when events arrive during dead time) and paralyzable (any event arriving during dead time extends the dead interval by $\\tau$ beyond its arrival). These mechanisms affect both the count rate and, through pulse pile-up and baseline shifts, the effective energy resolution in pulse height analysis.\n\nUsing only fundamental definitions of a Poisson process and the operational definitions of non-paralyzable and paralyzable dead time, perform the following:\n\n1. Derive the functional relationship between the measured count rate $m$ and the true rate $\\lambda$ for the non-paralyzable dead-time model in terms of $\\lambda$ and $\\tau$.\n2. Derive the functional relationship between the measured count rate $m$ and the true rate $\\lambda$ for the paralyzable dead-time model in terms of $\\lambda$ and $\\tau$.\n3. A calibration experiment is performed by adjusting source activity to produce two different true rates (verified independently with a fast reference counter of negligible dead time). The system under test reports measured rates:\n   - At true rate $\\lambda_1 = 4.00\\times 10^{4}\\ \\text{s}^{-1}$, the measured rate is $m_1 = 2.20\\times 10^{4}\\ \\text{s}^{-1}$.\n   - At true rate $\\lambda_2 = 8.00\\times 10^{4}\\ \\text{s}^{-1}$, the measured rate is $m_2 = 2.41\\times 10^{4}\\ \\text{s}^{-1}$.\n   Using the first pair $(\\lambda_1, m_1)$, compute the dead time $\\tau$ implied by each model. Then, using each $\\tau$ estimate, predict the measured rate at $\\lambda_2$ and compare to $m_2$ to determine which dead-time model is better supported by these data.\n4. Report the selected model’s estimated dead time $\\tau$ as the final answer. Round your answer to four significant figures. Express the final dead time in microseconds.\n\nYour derivations must start from the definitions of dead time and properties of the Poisson process (interarrival times and memorylessness), without invoking target formulas. Your reasoning should clearly articulate why the resulting throughput functions emerge from these foundations and how the data allow model identification.", "solution": "The problem requires the derivation of measured count rates for two dead-time models, followed by model selection and parameter estimation using provided experimental data. The derivation will be built from the fundamental properties of a Poisson process and the definitions of each dead-time model.\n\n**1. Derivation for the Non-Paralyzable Dead-Time Model**\n\nIn a non-paralyzable system, after an event is successfully recorded, the detection system becomes insensitive (dead) for a fixed duration $\\tau$. Events arriving during this dead time are ignored and do not affect the duration of the dead period.\n\nLet $\\lambda$ be the true rate of incoming events, which follow a homogeneous Poisson process. Let $m$ be the measured rate of recorded events.\nConsider a long observation time $T$. The total number of recorded events is $N_{meas} = m T$.\nEach recorded event introduces a dead time of duration $\\tau$. Thus, the total time the system is dead during the observation period $T$ is given by $T_{dead} = N_{meas} \\times \\tau = m T \\tau$.\nThe system is only capable of recording new events when it is \"live\". The total live time during the observation period is the total time minus the total dead time:\n$$T_{live} = T - T_{dead} = T - m T \\tau = T(1 - m \\tau)$$\nThe recorded events are simply the true events that happen to arrive when the system is live. Since the underlying process is Poisson, the rate of events during the live periods is still $\\lambda$. Therefore, the total number of recorded events, $N_{meas}$, must be equal to the true rate $\\lambda$ multiplied by the total live time $T_{live}$.\n$$N_{meas} = \\lambda T_{live}$$\nSubstituting the expressions for $N_{meas}$ and $T_{live}$:\n$$m T = \\lambda [T(1 - m \\tau)]$$\nDividing by the total observation time $T$ (which is non-zero), we obtain the relationship between $m$ and $\\lambda$:\n$$m = \\lambda(1 - m \\tau)$$\nThis is an implicit equation for $m$. To find the functional relationship, we solve for $m$:\n$$m = \\lambda - \\lambda m \\tau$$\n$$m + \\lambda m \\tau = \\lambda$$\n$$m(1 + \\lambda \\tau) = \\lambda$$\n$$m = \\frac{\\lambda}{1 + \\lambda \\tau}$$\nThis is the required functional relationship for the non-paralyzable model.\n\n**2. Derivation for the Paralyzable Dead-Time Model**\n\nIn a paralyzable system, any event arriving at the detector, whether recorded or not, initiates a new dead time of duration $\\tau$. This means an event arriving during an existing dead period extends it.\nAn incoming event will be successfully recorded only if it is not preceded by any other event for a duration of at least $\\tau$.\nLet's consider the stream of incoming events from the Poisson process. The time intervals between successive events, or interarrival times, are independent and identically distributed according to an exponential probability distribution with rate parameter $\\lambda$. The probability density function for an interarrival time $t$ is $p(t) = \\lambda \\exp(-\\lambda t)$ for $t \\geq 0$.\n\nAn event is recorded if and only if the time interval separating it from the preceding event is greater than $\\tau$. Therefore, the probability that any given event is recorded is the probability that its interarrival time $t$ is greater than $\\tau$.\n$$P(\\text{event recorded}) = P(t > \\tau)$$\nWe calculate this probability by integrating the probability density function from $\\tau$ to infinity:\n$$P(t > \\tau) = \\int_{\\tau}^{\\infty} \\lambda \\exp(-\\lambda t) dt$$\n$$P(t > \\tau) = \\left[ -\\exp(-\\lambda t) \\right]_{\\tau}^{\\infty}$$\n$$P(t > \\tau) = \\lim_{t \\to \\infty} (-\\exp(-\\lambda t)) - (-\\exp(-\\lambda \\tau))$$\n$$P(t > \\tau) = 0 + \\exp(-\\lambda \\tau) = \\exp(-\\lambda \\tau)$$\nThis probability represents the fraction of true events that are successfully recorded. The measured rate $m$ is therefore the true rate $\\lambda$ multiplied by this probability:\n$$m = \\lambda \\times P(\\text{event recorded})$$\n$$m = \\lambda \\exp(-\\lambda \\tau)$$\nThis is the required functional relationship for the paralyzable model. It is noteworthy that for this model, the measured rate $m$ does not increase monotonically with $\\lambda$. It reaches a maximum value and then decreases, a phenomenon known as paralysis.\n\n**3. Model Selection and Parameter Estimation**\n\nWe are given two data points:\n- $(\\lambda_1, m_1) = (4.00 \\times 10^4 \\text{ s}^{-1}, 2.20 \\times 10^4 \\text{ s}^{-1})$\n- $(\\lambda_2, m_2) = (8.00 \\times 10^4 \\text{ s}^{-1}, 2.41 \\times 10^4 \\text{ s}^{-1})$\n\nWe will use the first data point $(\\lambda_1, m_1)$ to estimate the dead time $\\tau$ for each model.\n\n**Non-Paralyzable Model Estimation:**\nUsing the formula $m = \\frac{\\lambda}{1 + \\lambda \\tau}$, we solve for $\\tau$:\n$$m(1 + \\lambda \\tau) = \\lambda \\implies 1 + \\lambda \\tau = \\frac{\\lambda}{m} \\implies \\lambda \\tau = \\frac{\\lambda}{m} - 1 = \\frac{\\lambda - m}{m}$$\n$$\\tau = \\frac{\\lambda - m}{m \\lambda}$$\nSubstituting the values from the first data point:\n$$\\tau_{np} = \\frac{4.00 \\times 10^4 - 2.20 \\times 10^4}{(2.20 \\times 10^4)(4.00 \\times 10^4)} = \\frac{1.80 \\times 10^4}{8.80 \\times 10^8} \\text{ s} \\approx 2.045 \\times 10^{-5} \\text{ s}$$\nNow, we predict the measured rate $m_2$ for the true rate $\\lambda_2$ using this value of $\\tau_{np}$:\n$$m_{2, \\text{pred, np}} = \\frac{\\lambda_2}{1 + \\lambda_2 \\tau_{np}} = \\frac{8.00 \\times 10^4}{1 + (8.00 \\times 10^4)(2.045\\dots \\times 10^{-5})} = \\frac{8.00 \\times 10^4}{1 + 1.636\\dots} = \\frac{8.00 \\times 10^4}{2.636\\dots} \\approx 3.03 \\times 10^4 \\text{ s}^{-1}$$\n\n**Paralyzable Model Estimation:**\nUsing the formula $m = \\lambda \\exp(-\\lambda \\tau)$, we solve for $\\tau$:\n$$\\frac{m}{\\lambda} = \\exp(-\\lambda \\tau) \\implies \\ln\\left(\\frac{m}{\\lambda}\\right) = -\\lambda \\tau$$\n$$\\tau = -\\frac{1}{\\lambda} \\ln\\left(\\frac{m}{\\lambda}\\right)$$\nSubstituting the values from the first data point:\n$$\\tau_p = -\\frac{1}{4.00 \\times 10^4} \\ln\\left(\\frac{2.20 \\times 10^4}{4.00 \\times 10^4}\\right) = -\\frac{1}{4.00 \\times 10^4} \\ln(0.55)$$\n$$\\tau_p \\approx -\\frac{1}{4.00 \\times 10^4} (-0.597837) \\approx 1.4946 \\times 10^{-5} \\text{ s}$$\nNow, we predict the measured rate $m_2$ for the true rate $\\lambda_2$ using this value of $\\tau_p$:\n$$m_{2, \\text{pred, p}} = \\lambda_2 \\exp(-\\lambda_2 \\tau_p) = (8.00 \\times 10^4) \\exp\\left(-(8.00 \\times 10^4)(1.4946 \\times 10^{-5})\\right)$$\n$$m_{2, \\text{pred, p}} = (8.00 \\times 10^4) \\exp(-1.19567) \\approx (8.00 \\times 10^4)(0.3025) \\approx 2.42 \\times 10^4 \\text{ s}^{-1}$$\n\n**Comparison and Model Selection:**\nWe compare the predicted rates with the experimentally measured rate $m_2 = 2.41 \\times 10^4 \\text{ s}^{-1}$:\n- Non-paralyzable model prediction: $m_{2, \\text{pred, np}} \\approx 3.03 \\times 10^4 \\text{ s}^{-1}$.\n- Paralyzable model prediction: $m_{2, \\text{pred, p}} \\approx 2.42 \\times 10^4 \\text{ s}^{-1}$.\n\nThe prediction from the paralyzable model ($2.42 \\times 10^4 \\text{ s}^{-1}$) is significantly closer to the measured value ($2.41 \\times 10^4 \\text{ s}^{-1}$) than the prediction from the non-paralyzable model ($3.03 \\times 10^4 \\text{ s}^{-1}$). The relative error for the paralyzable model is approximately $\\frac{|2.42 - 2.41|}{2.41} \\approx 0.4\\%$, while for the non-paralyzable model it is approximately $\\frac{|3.03 - 2.41|}{2.41} \\approx 25.7\\%$.\nTherefore, the paralyzable dead-time model is much better supported by the data. The data also exhibits the characteristic behavior of a paralyzable system where the measured rate increases less steeply at higher true rates, and can even decrease. Here, doubling the true rate from $4.00 \\times 10^4$ to $8.00 \\times 10^4 \\text{ s}^{-1}$ only slightly increased the measured rate from $2.20 \\times 10^4$ to $2.41 \\times 10^4 \\text{ s}^{-1}$, suggesting the system is operating near or beyond its maximum throughput.\n\n**4. Final Answer Calculation**\n\nThe selected model is the paralyzable model. The estimated dead time is the value calculated for this model:\n$$\\tau = \\tau_p \\approx 1.49459 \\times 10^{-5} \\text{ s}$$\nThe problem asks for this value in microseconds ($\\mu\\text{s}$) and rounded to four significant figures.\n$$1 \\text{ s} = 10^6 \\mu\\text{s}$$\n$$\\tau = 1.49459 \\times 10^{-5} \\text{ s} \\times \\frac{10^6 \\mu\\text{s}}{1 \\text{ s}} = 14.9459 \\mu\\text{s}$$\nRounding to four significant figures, we get:\n$$\\tau \\approx 14.95 \\mu\\text{s}$$\nThis is the final answer.", "answer": "$$\n\\boxed{14.95}\n$$", "id": "4883310"}]}