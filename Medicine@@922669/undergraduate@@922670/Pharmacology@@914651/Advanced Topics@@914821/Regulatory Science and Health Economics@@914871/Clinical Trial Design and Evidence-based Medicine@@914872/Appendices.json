{"hands_on_practices": [{"introduction": "Once a clinical trial concludes, its results must be translated from raw data into meaningful metrics that clinicians and policymakers can use. This exercise focuses on the fundamental calculations at the heart of evidence-based medicine. By working through a typical scenario from a cardiovascular trial, you will practice computing the Absolute Risk Reduction ($ARR$), Relative Risk ($RR$), Odds Ratio ($OR$), and Number Needed to Treat ($NNT$), each of which provides a unique perspective on the treatment's impact. [@problem_id:4934300]", "problem": "A multicenter, Phase III randomized controlled trial (RCT) in pharmacology evaluates a new lipid-lowering drug versus placebo for prevention of a composite cardiovascular endpoint over a fixed follow-up. In the control arm, the observed event probability (risk) over follow-up is $p_{0}=0.2$. In the treatment arm, the observed event probability (risk) is $p_{1}=0.14$. Using the core definitions in Evidence-Based Medicine (EBM), compute the absolute risk reduction (ARR), the relative risk (RR), the odds ratio (OR), and the number needed to treat (NNT) for benefit, assuming the treatment reduces risk.\n\nExpress your final answers as exact fractions or decimals. No rounding is required. Report the four quantities in the order $(\\text{ARR}, \\text{RR}, \\text{OR}, \\text{NNT})$. Do not use the percentage sign.", "solution": "The problem as stated will be validated against the required criteria before a solution is attempted.\n\n### Step 1: Extract Givens\nThe data and conditions explicitly provided are:\n- A multicenter, Phase III randomized controlled trial (RCT) is conducted.\n- The trial compares a new lipid-lowering drug against a placebo.\n- The outcome is a composite cardiovascular endpoint over a fixed follow-up period.\n- The observed event probability (risk) in the control (placebo) arm is $p_{0}=0.2$.\n- The observed event probability (risk) in the treatment arm is $p_{1}=0.14$.\n- The quantities to be computed are:\n    1. Absolute Risk Reduction (ARR)\n    2. Relative Risk (RR)\n    3. Odds Ratio (OR)\n    4. Number Needed to Treat (NNT) for benefit\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n- **Scientifically Grounded**: The problem is firmly grounded in the principles of evidence-based medicine (EBM) and biostatistics, which are central to pharmacology and clinical trial analysis. The concepts of ARR, RR, OR, and NNT are standard, well-defined metrics for quantifying treatment effects. The provided risk values, $p_0=0.2$ and $p_1=0.14$, are plausible for a cardiovascular outcomes trial.\n- **Well-Posed**: The problem is well-posed. It provides all necessary data ($p_0$ and $p_1$) to calculate the four requested metrics using their standard mathematical definitions. A unique, stable, and meaningful solution exists.\n- **Objective**: The problem is stated in precise, objective language. It presents quantitative data and asks for the calculation of standard metrics without introducing any subjective or ambiguous elements.\n- **Consistency**: The problem is self-contained and consistent. The condition that the treatment reduces risk is confirmed by the data, as $p_1  p_0$.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. It is scientifically sound, well-posed, and objective. A solution will be provided.\n\n### Solution Derivation\n\nThe problem requires the calculation of four standard metrics used in evidence-based medicine to describe the outcome of a clinical trial. The given quantities are the risk in the control group, $p_0 = 0.2$, and the risk in the treatment group, $p_1 = 0.14$.\n\n1.  **Absolute Risk Reduction (ARR)**\n    The ARR is the simple arithmetic difference in the event rates between the control and treatment groups. It quantifies the absolute decrease in risk attributable to the treatment. The definition is:\n    $$\n    \\text{ARR} = p_0 - p_1\n    $$\n    Substituting the given values:\n    $$\n    \\text{ARR} = 0.2 - 0.14 = 0.06\n    $$\n\n2.  **Relative Risk (RR)**\n    The RR, also known as the risk ratio, is the ratio of the risk of an event in the treatment group to the risk in the control group. An RR less than $1$ indicates that the treatment reduces the risk. The definition is:\n    $$\n    \\text{RR} = \\frac{p_1}{p_0}\n    $$\n    Substituting the given values:\n    $$\n    \\text{RR} = \\frac{0.14}{0.2} = \\frac{14}{20} = \\frac{7}{10} = 0.7\n    $$\n\n3.  **Odds Ratio (OR)**\n    The OR is the ratio of the odds of an event in the treatment group to the odds of an event in the control group. The odds of an event with probability $p$ is defined as $O = \\frac{p}{1-p}$.\n    First, we calculate the odds for each group:\n    - Odds in the control group, $O_0$:\n      $$\n      O_0 = \\frac{p_0}{1-p_0} = \\frac{0.2}{1-0.2} = \\frac{0.2}{0.8} = \\frac{2}{8} = \\frac{1}{4}\n      $$\n    - Odds in the treatment group, $O_1$:\n      $$\n      O_1 = \\frac{p_1}{1-p_1} = \\frac{0.14}{1-0.14} = \\frac{0.14}{0.86} = \\frac{14}{86} = \\frac{7}{43}\n      $$\n    The OR is the ratio of these odds:\n    $$\n    \\text{OR} = \\frac{O_1}{O_0} = \\frac{7/43}{1/4} = \\frac{7}{43} \\times 4 = \\frac{28}{43}\n    $$\n    As the problem requires an exact answer, the rational number $\\frac{28}{43}$ is the precise form.\n\n4.  **Number Needed to Treat (NNT)**\n    The NNT represents the average number of patients who need to be treated to prevent one additional bad outcome. For a treatment that is beneficial (i.e., reduces risk), the NNT is the reciprocal of the ARR. The definition is:\n    $$\n    \\text{NNT} = \\frac{1}{\\text{ARR}}\n    $$\n    Using the calculated value of ARR:\n    $$\n    \\text{NNT} = \\frac{1}{0.06} = \\frac{1}{6/100} = \\frac{100}{6} = \\frac{50}{3}\n    $$\n    Again, the exact fraction is the appropriate form for the answer.\n\nThe four required quantities, in the specified order $(\\text{ARR}, \\text{RR}, \\text{OR}, \\text{NNT})$, are $(0.06, 0.7, \\frac{28}{43}, \\frac{50}{3})$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.06  0.7  \\frac{28}{43}  \\frac{50}{3}\n\\end{pmatrix}\n}\n$$", "id": "4934300"}, {"introduction": "The validity of a clinical trial's conclusion hinges on choosing a primary endpoint that accurately captures the drug's effect, which is not always straightforward when a treatment's benefit is not constant over time. This practice presents a realistic, albeit hypothetical, scenario of non-proportional effects where a drug shows a strong early benefit that diminishes later. It challenges you to select the most appropriate endpoint to avoid a misleading conclusion, demonstrating the crucial link between a drug's pharmacological profile and the statistical design of its trial. [@problem_id:4934246]", "problem": "A randomized, double-blind trial in moderate inflammatory bowel disease is designed to compare a new oral anti-inflammatory agent versus placebo. The scientific question is to quantify how the treatment changes the timing of clinical remission. Clinical remission is defined as a composite score falling below a prespecified threshold and remaining there for at least $2$ consecutive weeks. Patients are enrolled uniformly over $20$ weeks and followed for a maximum of $24$ weeks after randomization. Investigators must select the primary endpoint as either time-to-event (time to clinical remission) or a dichotomous endpoint at a fixed time-point (remission status at a prespecified week).\n\nFrom pharmacology and clinical trial methodology, use the following foundational facts and definitions to reason to a choice:\n\n- Time-to-event endpoints are modeled by the survival function $S(t)$, which is the probability of remaining non-remitted by time $t$, and the hazard function $h(t)$, which is the instantaneous remission rate at time $t$. The cumulative hazard is $\\Lambda(t)=\\int_{0}^{t} h(u)\\,du$, and for a piecewise-constant hazard the survival function satisfies $S(t)=\\exp\\left[-\\Lambda(t)\\right]$. Right-censoring is accounted for under the assumption of non-informative censoring, meaning the censoring time is independent of the event time conditional on treatment.\n- A dichotomous endpoint at time $t^{\\ast}$ compares proportions remitted by $t^{\\ast}$, which are $1-S(t^{\\ast})$. This discards information about the ordering of event times and all events occurring after $t^{\\ast}$.\n- The Restricted Mean Survival Time (RMST) is defined as the expected time in the non-remitted state up to a truncation time $\\tau$, $\\int_{0}^{\\tau} S(t)\\,dt$, and its difference between groups is a valid time-to-event estimand that captures shifts in the distribution of event times without requiring proportional hazards.\n\nInvestigators expect non-proportional hazards with early acceleration of remission under the drug and later catch-up on placebo due to standard-of-care optimization. Specifically, they anticipate the following piecewise-constant remission hazards (per week) and independent dropout (right-censoring) hazards (per week):\n\n- Treatment remission hazard:\n\n$$\nh_{T}(t)=\\begin{cases}\n0.12,  0\\le t\\le 8\\\\\n0.015,  8 t\\le 24\n\\end{cases}\n$$\n\n- Control remission hazard:\n\n$$\nh_{C}(t)=\\begin{cases}\n0.04,  0\\le t\\le 8\\\\\n0.055,  8 t\\le 24\n\\end{cases}\n$$\n\n- Dropout hazard (both arms): $h_{d}(t)=0.01$ for $0\\le t\\le 24$.\n\nInvestigators will ascertain remission status continuously via weekly assessments, so event times are approximated within $\\pm 1$ week. Assume non-informative right-censoring.\n\nBased on these expectations, which choice of primary endpoint most appropriately aligns with the scientific question, preserves information, and maximizes statistical efficiency under the anticipated event-time distribution and censoring pattern?\n\nA. Select a time-to-event primary endpoint (time to clinical remission), and analyze using a time-to-event estimand such as the difference in Restricted Mean Survival Time up to $24$ weeks, because most of the treatment effect manifests as earlier remission with later catch-up, and right-censoring is present.\n\nB. Select a dichotomous endpoint at $24$ weeks, because both arms are expected to have similar cumulative remission proportions by $24$ weeks, making the comparison straightforward and robust to censoring.\n\nC. Select a dichotomous endpoint at $8$ weeks, because the largest absolute difference in remission proportions is expected early, which maximizes power and avoids assumptions about hazards or censoring.\n\nD. Select a time-to-event primary endpoint only if censoring is negligible; otherwise, favor a dichotomous endpoint to avoid bias introduced by censored data.", "solution": "The user has requested a critical validation of the problem statement, followed by a full solution and evaluation of the provided options.\n\n### Step 1: Extract Givens\n- **Study Design:** Randomized, double-blind trial comparing a new agent to placebo.\n- **Population:** Patients with moderate inflammatory bowel disease.\n- **Scientific Question:** \"...to quantify how the treatment changes the timing of clinical remission.\"\n- **Event Definition:** Clinical remission is a composite score falling below a threshold and remaining there for at least $2$ consecutive weeks.\n- **Enrollment and Follow-up:** Patients enrolled uniformly over $20$ weeks and followed for a maximum of $24$ weeks post-randomization.\n- **Endpoint Choice:** Time-to-event (time to remission) versus a dichotomous endpoint (remission status at a prespecified week).\n- **Definitions:**\n    - Survival function $S(t)$: probability of remaining non-remitted by time $t$.\n    - Hazard function $h(t)$: instantaneous remission rate at time $t$.\n    - Cumulative hazard $\\Lambda(t) = \\int_{0}^{t} h(u)\\,du$.\n    - For piecewise-constant hazard, $S(t) = \\exp[-\\Lambda(t)]$.\n    - Censoring is right-censoring and assumed to be non-informative.\n    - Dichotomous endpoint at $t^{\\ast}$ compares proportions $1-S(t^{\\ast})$.\n    - Restricted Mean Survival Time (RMST) up to time $\\tau$: $\\int_{0}^{\\tau} S(t)\\,dt$.\n- **Anticipated Hazard Functions (per week):**\n    - Treatment remission hazard:\n    $$\n    h_{T}(t)=\\begin{cases}\n    0.12,  0\\le t\\le 8\\\\\n    0.015,  8 t\\le 24\n    \\end{cases}\n    $$\n    - Control remission hazard:\n    $$\n    h_{C}(t)=\\begin{cases}\n    0.04,  0\\le t\\le 8\\\\\n    0.055,  8 t\\le 24\n    \\end{cases}\n    $$\n    - Dropout hazard (both arms): $h_{d}(t)=0.01$ for $0\\le t\\le 24$.\n- **Question:** Which primary endpoint choice best aligns with the scientific question, preserves information, and maximizes statistical efficiency under the given expectations?\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is evaluated against standard criteria for validity.\n\n- **Scientifically Grounded:** The problem is firmly rooted in the established principles of biostatistics, clinical trial design, and survival analysis. The concepts of hazard functions, survival functions, censoring, non-proportional hazards, and estimands like RMST are all standard and correctly defined. The scenario of a treatment showing early benefit with later catch-up by the control group is a realistic and important challenge in trial design. The provided hazard values are hypothetical but plausible. The problem is scientifically sound.\n- **Well-Posed:** The problem provides all necessary quantitative information (hazard functions for the event of interest and for dropout, study duration) to compare the different endpoint strategies. The question is clearly stated, asking for the \"most appropriate\" choice based on three explicit criteria: alignment with the scientific question, information preservation, and statistical efficiency. This structure allows for a unique and meaningful solution to be derived through quantitative analysis and logical reasoning.\n- **Objective:** The language is technical, precise, and free of subjective or opinion-based statements. The anticipated hazard functions are presented as the basis for a design-stage decision, which is standard practice.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity. The mention of a uniform enrollment period followed by a maximum follow-up time is a realistic feature of clinical trials; the problem simplifies this by focusing on the maximum follow-up of $24$ weeks as the truncation time for analysis, which is a reasonable simplification for a theoretical problem of this nature.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A full solution will be derived.\n\n### Derivation of Solution\nThe optimal choice of endpoint must be guided by the scientific question, the expected data structure, and the principles of statistical efficiency.\n\n1.  **Analyze the Scientific Question:** The primary aim is to \"quantify how the treatment changes the *timing* of clinical remission.\" This question is intrinsically about the distribution of event times. A time-to-event endpoint directly models this timing. A dichotomous endpoint at a fixed time $t^{\\ast}$ only captures the cumulative incidence by that time, collapsing all information about when events occurred before $t^{\\ast}$ and ignoring all events that occur after $t^{\\ast}$. Therefore, a time-to-event endpoint is inherently better aligned with the stated scientific goal.\n\n2.  **Analyze the Anticipated Hazard Functions:** The problem specifies non-proportional hazards. We can quantify this by examining the hazard ratio, $HR(t) = h_{T}(t)/h_{C}(t)$.\n    - For $0 \\le t \\le 8$ weeks: $HR(t) = 0.12 / 0.04 = 3.0$. This indicates a strong positive treatment effect (patients on treatment are $3$ times as likely to enter remission at any given moment).\n    - For $8  t \\le 24$ weeks: $HR(t) = 0.015 / 0.055 \\approx 0.27$. Here, the hazard ratio is less than $1$, meaning the control group has a higher remission rate. This is the \"catch-up\" effect.\n    This crossing of the hazard functions is a severe violation of the proportional hazards assumption. Standard time-to-event analyses that rely on this assumption (e.g., the log-rank test or a simple Cox proportional hazards model) would be inappropriate and have reduced power, as they effectively average the hazard ratio over time. The problem correctly identifies that an estimand robust to non-proportionality, such as the difference in RMST, would be necessary.\n\n3.  **Evaluate Dichotomous Endpoint Options:** We must calculate the expected proportion of patients in remission, $P(t) = 1 - S(t) = 1 - \\exp[-\\Lambda(t)]$, at the proposed time points.\n\n    - **At $t=8$ weeks:**\n        - Treatment: $\\Lambda_T(8) = 0.12 \\times 8 = 0.96$. $P_T(8) = 1 - \\exp(-0.96) \\approx 1 - 0.3829 = 0.6171$.\n        - Control: $\\Lambda_C(8) = 0.04 \\times 8 = 0.32$. $P_C(8) = 1 - \\exp(-0.32) \\approx 1 - 0.7261 = 0.2739$.\n        - The difference in proportions is large: $\\Delta P(8) \\approx 0.6171 - 0.2739 = 0.3432$. Choosing an endpoint at $8$ weeks would likely yield a statistically significant result. However, it fails to capture the full dynamics of the treatment effect, particularly the later catch-up. It answers a different, more limited question than the one posed.\n\n    - **At $t=24$ weeks:**\n        - Treatment: $\\Lambda_T(24) = \\Lambda_T(8) + \\int_{8}^{24} 0.015\\,du = 0.96 + 0.015 \\times (24-8) = 0.96 + 0.015 \\times 16 = 0.96 + 0.24 = 1.20$.\n        - $P_T(24) = 1 - \\exp(-1.20) \\approx 1 - 0.3012 = 0.6988$.\n        - Control: $\\Lambda_C(24) = \\Lambda_C(8) + \\int_{8}^{24} 0.055\\,du = 0.32 + 0.055 \\times (24-8) = 0.32 + 0.055 \\times 16 = 0.32 + 0.88 = 1.20$.\n        - $P_C(24) = 1 - \\exp(-1.20) \\approx 1 - 0.3012 = 0.6988$.\n        - The difference in proportions is approximately zero: $\\Delta P(24) \\approx 0$. Choosing an endpoint at $24$ weeks would completely miss the significant early benefit of the treatment and lead to the incorrect conclusion that the treatment has no effect. This would be a catastrophic design choice.\n\n4.  **Evaluate Time-to-Event Endpoint with RMST:** A time-to-event analysis uses the full follow-up data for each patient. The RMST, defined as $\\int_{0}^{\\tau} S(t)\\,dt$, represents the average time a patient remains event-free up to a truncation time $\\tau$. The difference in RMST between arms is a robust measure of the treatment effect, even with non-proportional hazards. As calculated in the thought process, the difference is substantial: $\\Delta \\text{RMST} = \\text{RMST}_C - \\text{RMST}_T \\approx 4.0$ weeks up to $\\tau = 24$ weeks. This means that on average, a patient in the treatment group enjoys approximately $4$ additional weeks of being in the non-remitted state compared to a patient in the control group within the $24$-week follow-up period (The RMST is the mean time *in the non-remitted state*, so a smaller value is better). A more clinically useful measure is the difference in restricted mean *time-to-remission*, but the difference in RMST (non-remitted) captures the same effect size. This approach utilizes all the timing information and summarizes it into a single, clinically meaningful number, directly addressing the scientific question while being robust to the anticipated hazard profile.\n\n5.  **Consider Censoring:** The presence of right-censoring (due to dropout, $h_d(t)=0.01$, and administrative censoring at $24$ weeks) is a key feature of the data. Time-to-event methodologies (like Kaplan-Meier estimation for $S(t)$, which underlies RMST estimation) are specifically designed to correctly incorporate information from censored subjects under the non-informative censoring assumption. Far from being a reason to avoid time-to-event analysis, the presence of censoring makes it the most appropriate and necessary tool.\n\n### Option-by-Option Analysis\n\n**A. Select a time-to-event primary endpoint (time to clinical remission), and analyze using a time-to-event estimand such as the difference in Restricted Mean Survival Time up to $24$ weeks, because most of the treatment effect manifests as earlier remission with later catch-up, and right-censoring is present.**\n- This option correctly identifies that a time-to-event endpoint is superior for assessing the *timing* of events. It correctly recommends a specific estimand, RMST, that is appropriate for the anticipated non-proportional hazards (\"earlier remission with later catch-up\"). It also correctly states that the presence of censoring is a reason for, not against, using such methods. This option aligns perfectly with our derivation.\n- **Verdict: Correct.**\n\n**B. Select a dichotomous endpoint at $24$ weeks, because both arms are expected to have similar cumulative remission proportions by $24$ weeks, making the comparison straightforward and robust to censoring.**\n- The premise (similar proportions at $24$ weeks) is correct based on our calculations. However, this is precisely why it is a poor endpoint; a study using it would have almost no power to detect the true, significant difference in the timing of remission. The conclusion that this makes the comparison \"straightforward\" is misleading; it makes the comparison meaningless.\n- **Verdict: Incorrect.**\n\n**C. Select a dichotomous endpoint at $8$ weeks, because the largest absolute difference in remission proportions is expected early, which maximizes power and avoids assumptions about hazards or censoring.**\n- This endpoint would capture a large effect at $8$ weeks but would discard all information about the timing of events before week $8$ and all information about what happens after week $8$. It does not fully address the scientific question about the entire time course of remission. The claim that it \"avoids assumptions about...censoring\" is false; any analysis of a proportion at time $t^{\\ast}$ must properly account for subjects censored before $t^{\\ast}$, which requires assumptions (e.g., non-informative censoring for a Kaplan-Meier-based estimate of the proportion).\n- **Verdict: Incorrect.**\n\n**D. Select a time-to-event primary endpoint only if censoring is negligible; otherwise, favor a dichotomous endpoint to avoid bias introduced by censored data.**\n- This statement represents a fundamental misunderstanding of survival analysis. Time-to-event methods are the gold standard for analyzing censored data in an unbiased manner (assuming non-informative censoring). In contrast, analyzing a dichotomous endpoint can introduce significant bias if censoring is not handled properly, and the methods for doing so are often less efficient or more assumption-laden than a full time-to-event analysis.\n- **Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "4934246"}, {"introduction": "A single clinical trial, no matter how well-designed, provides only one piece of the puzzle; true evidence-based practice relies on the synthesis of all available data. Meta-analysis is the statistical technique used to combine results from multiple independent studies, providing a more robust and precise estimate of the treatment effect. This comprehensive exercise guides you through the essential steps of a random-effects meta-analysis—a cornerstone of modern medical evidence—from calculating study-specific effects to quantifying between-study heterogeneity. [@problem_id:4934274]", "problem": "A pharmacology research group evaluates a new antihypertensive drug against standard care in $5$ independently conducted randomized controlled trials. For each study, the number of patients with a primary cardiovascular event (event) and without an event (non-event) are recorded for the treatment and control arms. Assume a binomial model for event counts within each arm and asymptotic normality of study-level log risk ratios.\n\nThe study data are:\n- Study $1$: Treatment $24$ events of $200$; Control $36$ events of $190$.\n- Study $2$: Treatment $15$ events of $150$; Control $22$ events of $145$.\n- Study $3$: Treatment $40$ events of $300$; Control $55$ events of $295$.\n- Study $4$: Treatment $48$ events of $220$; Control $28$ events of $210$.\n- Study $5$: Treatment $18$ events of $160$; Control $27$ events of $155$.\n\nUsing the principles of evidence synthesis under a random-effects model and the method-of-moments estimator of between-study variance due to DerSimonian and Laird (DerSimonian–Laird), do the following:\n1) Compute each study’s risk ratio, transform to the natural logarithm scale, and compute the within-study sampling variance of the log risk ratio under the binomial model.\n2) Using these, construct the DerSimonian–Laird random-effects meta-analysis to obtain the pooled log risk ratio and then back-transform to the pooled risk ratio.\n3) Quantify heterogeneity by computing Cochran’s $Q$, the DerSimonian–Laird between-study variance, and the inconsistency statistic $I^2$ defined as the proportion of total observed variance attributable to between-study heterogeneity.\n\nReport two quantities:\n- The pooled risk ratio.\n- The inconsistency statistic $I^2$ as a decimal in $[0,1]$.\n\nRound the pooled risk ratio to three significant figures and $I^2$ to three significant figures. Express the pooled risk ratio as a plain ratio (unitless) and $I^2$ as a decimal (do not use a percent sign).", "solution": "The problem requires performing a random-effects meta-analysis using the DerSimonian-Laird method on data from $k=5$ clinical trials. The final outputs are the pooled risk ratio and the $I^2$ statistic for heterogeneity.\n\nLet the data for study $i$ (for $i=1, \\dots, 5$) be denoted as follows:\n- $a_i$: number of events in the treatment group\n- $n_{iT}$: total number of patients in the treatment group\n- $c_i$: number of events in the control group\n- $n_{iC}$: total number of patients in the control group\n\nThe problem provides the following data:\n- Study $1$: $a_1=24$, $n_{1T}=200$; $c_1=36$, $n_{1C}=190$.\n- Study $2$: $a_2=15$, $n_{2T}=150$; $c_2=22$, $n_{2C}=145$.\n- Study $3$: $a_3=40$, $n_{3T}=300$; $c_3=55$, $n_{3C}=295$.\n- Study $4$: $a_4=48$, $n_{4T}=220$; $c_4=28$, $n_{4C}=210$.\n- Study $5$: $a_5=18$, $n_{5T}=160$; $c_5=27$, $n_{5C}=155$.\n\n**Step 1: Compute study-specific estimates and their variances**\n\nFor each study $i$, we first compute the risk ratio ($RR_i$) and then its natural logarithm, the log risk ratio ($y_i$).\nThe risk in the treatment arm is $p_{iT} = a_i/n_{iT}$ and in the control arm is $p_{iC} = c_i/n_{iC}$.\nThe risk ratio is $RR_i = p_{iT}/p_{iC}$. The log risk ratio is $y_i = \\ln(RR_i)$.\nThe variance of the log risk ratio, $v_i$, is estimated using the asymptotic formula for binomial data:\n$$v_i = \\frac{1}{a_i} - \\frac{1}{n_{iT}} + \\frac{1}{c_i} - \\frac{1}{n_{iC}}$$\nSince none of the event counts $a_i$ or $c_i$ are zero, no continuity correction is necessary.\n\n- **Study 1**:\n$y_1 = \\ln\\left(\\frac{24/200}{36/190}\\right) = \\ln(0.6333\\dots) \\approx -0.4564$\n$v_1 = \\frac{1}{24} - \\frac{1}{200} + \\frac{1}{36} - \\frac{1}{190} \\approx 0.05918$\n\n- **Study 2**:\n$y_2 = \\ln\\left(\\frac{15/150}{22/145}\\right) = \\ln(0.6590\\dots) \\approx -0.4169$\n$v_2 = \\frac{1}{15} - \\frac{1}{150} + \\frac{1}{22} - \\frac{1}{145} \\approx 0.09856$\n\n- **Study 3**:\n$y_3 = \\ln\\left(\\frac{40/300}{55/295}\\right) = \\ln(0.7151\\dots) \\approx -0.3353$\n$v_3 = \\frac{1}{40} - \\frac{1}{300} + \\frac{1}{55} - \\frac{1}{295} \\approx 0.03646$\n\n- **Study 4**:\n$y_4 = \\ln\\left(\\frac{48/220}{28/210}\\right) = \\ln(1.6363\\dots) \\approx 0.4925$\n$v_4 = \\frac{1}{48} - \\frac{1}{220} + \\frac{1}{28} - \\frac{1}{210} \\approx 0.04724$\n\n- **Study 5**:\n$y_5 = \\ln\\left(\\frac{18/160}{27/155}\\right) = \\ln(0.6458\\dots) \\approx -0.4372$\n$v_5 = \\frac{1}{18} - \\frac{1}{160} + \\frac{1}{27} - \\frac{1}{155} \\approx 0.07989$\n\n**Step 2: Quantify heterogeneity**\n\nTo apply the DerSimonian-Laird method, we first need to quantify the between-study heterogeneity using Cochran's $Q$ statistic. This requires calculating fixed-effect weights, $w_i = 1/v_i$.\n\nThe fixed-effect weights are:\n$w_1 = 1/0.05918 \\approx 16.897$\n$w_2 = 1/0.09856 \\approx 10.146$\n$w_3 = 1/0.03646 \\approx 27.428$\n$w_4 = 1/0.04724 \\approx 21.168$\n$w_5 = 1/0.07989 \\approx 12.517$\n\nCochran's $Q$ is calculated as $Q = \\sum_{i=1}^k w_i (y_i - \\hat{\\theta}_{FE})^2$, where $\\hat{\\theta}_{FE} = (\\sum w_i y_i) / (\\sum w_i)$ is the pooled estimate under a fixed-effect model. A more direct computational formula for $Q$ is:\n$$Q = \\sum_{i=1}^k w_i y_i^2 - \\frac{\\left(\\sum_{i=1}^k w_i y_i\\right)^2}{\\sum_{i=1}^k w_i}$$\nCalculating the required sums:\n$\\sum w_i \\approx 88.158$\n$\\sum w_i y_i \\approx -16.188$\n$\\sum w_i y_i^2 \\approx 15.893$\n\nSubstituting these values into the formula for $Q$:\n$$Q \\approx 15.893 - \\frac{(-16.188)^2}{88.158} \\approx 15.893 - 2.972 = 12.921$$\nThe degrees of freedom for $Q$ are $df = k-1 = 5-1=4$. Since $Q > 4$, there is evidence of heterogeneity.\n\nThe DerSimonian-Laird estimator for the between-study variance, $\\hat{\\tau}^2$, is given by:\n$$\\hat{\\tau}^2 = \\max\\left(0, \\frac{Q - (k-1)}{C}\\right)$$\nwhere $C = \\sum w_i - \\frac{\\sum w_i^2}{\\sum w_i}$. We need $\\sum w_i^2 \\approx 1745.56$.\n$$C \\approx 88.158 - \\frac{1745.56}{88.158} \\approx 88.158 - 19.799 = 68.359$$\nNow we compute $\\hat{\\tau}^2$:\n$$\\hat{\\tau}^2 = \\frac{12.921 - 4}{68.359} = \\frac{8.921}{68.359} \\approx 0.1305$$\n\n**Step 3: Compute the random-effects pooled estimate**\n\nUnder the random-effects model, the weights for each study, $w_i^*$, are adjusted to include the between-study variance:\n$$w_i^* = \\frac{1}{v_i + \\hat{\\tau}^2}$$\n- $w_1^* = 1/(0.05918 + 0.1305) \\approx 5.272$\n- $w_2^* = 1/(0.09856 + 0.1305) \\approx 4.366$\n- $w_3^* = 1/(0.03646 + 0.1305) \\approx 5.990$\n- $w_4^* = 1/(0.04724 + 0.1305) \\approx 5.626$\n- $w_5^* = 1/(0.07989 + 0.1305) \\approx 4.753$\n\nThe random-effects pooled log risk ratio, $\\hat{\\theta}_{RE}$, is the weighted average of the individual log risk ratios using these new weights:\n$$\\hat{\\theta}_{RE} = \\frac{\\sum_{i=1}^k w_i^* y_i}{\\sum_{i=1}^k w_i^*}$$\nCalculating the quantities:\n$\\sum w_i^* \\approx 26.007$\n$\\sum w_i^* y_i \\approx (5.272 \\times -0.4564) + \\dots + (4.753 \\times -0.4372) \\approx -5.546$\n$$\\hat{\\theta}_{RE} \\approx \\frac{-5.546}{26.007} \\approx -0.21326$$\nThe pooled risk ratio, $RR_{RE}$, is obtained by back-transforming the pooled log risk ratio:\n$$RR_{RE} = \\exp(\\hat{\\theta}_{RE}) = \\exp(-0.21326) \\approx 0.80795$$\nRounding to three significant figures, the pooled risk ratio is $0.808$.\n\n**Step 4: Compute the inconsistency statistic $I^2$**\n\nThe $I^2$ statistic describes the percentage of total variation across studies that is due to heterogeneity rather than chance. It is calculated from $Q$:\n$$I^2 = \\max\\left(0, \\frac{Q-(k-1)}{Q}\\right)$$\nUsing our values for $Q$ and $k$:\n$$I^2 = \\frac{12.921 - 4}{12.921} = \\frac{8.921}{12.921} \\approx 0.6904$$\nRounding to three significant figures, the inconsistency statistic $I^2$ is $0.690$.\n\nThe two required quantities are the pooled risk ratio ($RR_{RE}$) and the inconsistency statistic ($I^2$).\n- Pooled risk ratio: $0.808$\n- Inconsistency statistic $I^2$: $0.690$", "answer": "$$\\boxed{\\begin{pmatrix} 0.808  0.690 \\end{pmatrix}}$$", "id": "4934274"}]}