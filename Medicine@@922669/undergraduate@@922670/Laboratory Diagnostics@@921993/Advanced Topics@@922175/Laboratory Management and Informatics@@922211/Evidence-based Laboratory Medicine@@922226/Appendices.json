{"hands_on_practices": [{"introduction": "This exercise builds the foundational skill of translating raw experimental data from a classic $2 \\times 2$ contingency table into the core performance characteristics of a diagnostic test. By deriving metrics such as sensitivity, specificity, and predictive values from first principles, you will gain a robust understanding of how a test's accuracy is quantified. This practice is essential for critically appraising any diagnostic tool and forms the bedrock of evidence-based test evaluation [@problem_id:5221406].", "problem": "A clinical laboratory evaluates a new qualitative immunoassay as an index test for a binary disease state adjudicated by a reference standard. Results from a prospective cohort of consecutively enrolled patients are summarized in a $2 \\times 2$ table with the following counts: $120$ true positives, $30$ false positives, $20$ false negatives, and $330$ true negatives. Starting from the core definitions of conditional probabilities in diagnostic testing and without appealing to any lookup formulas, derive estimators for sensitivity, specificity, positive predictive value, negative predictive value, and the diagnostic odds ratio using only the counts provided. Then compute these five quantities from the data. Express sensitivity, specificity, positive predictive value, and negative predictive value as decimals in the interval $\\left[0,1\\right]$ rather than as percentages. For the final reported quantity, give the diagnostic odds ratio as a unitless number rounded to four significant figures. Provide only this final value (the diagnostic odds ratio) as your answer.", "solution": "The problem is well-posed and scientifically sound, providing all necessary information for a complete solution. We are given the counts of a $2 \\times 2$ contingency table for a diagnostic test evaluation. Let $D^+$ denote the event that a patient has the disease, and $D^-$ denote the event of not having the disease. Let $T^+$ be the event of a positive test result, and $T^-$ be the event of a negative test result.\n\nThe provided counts are:\n-   True Positives ($TP$): The number of subjects with the disease who test positive, $N(D^+ \\cap T^+) = 120$.\n-   False Positives ($FP$): The number of subjects without the disease who test positive, $N(D^- \\cap T^+) = 30$.\n-   False Negatives ($FN$): The number of subjects with the disease who test negative, $N(D^+ \\cap T^-) = 20$.\n-   True Negatives ($TN$): The number of subjects without the disease who test negative, $N(D^- \\cap T^-) = 330$.\n\nFrom these counts, we can determine the marginal totals:\n-   Total number of subjects with the disease: $N(D^+) = TP + FN = 120 + 20 = 140$.\n-   Total number of subjects without the disease: $N(D^-) = FP + TN = 30 + 330 = 360$.\n-   Total number of subjects with a positive test: $N(T^+) = TP + FP = 120 + 30 = 150$.\n-   Total number of subjects with a negative test: $N(T^-) = FN + TN = 20 + 330 = 350$.\n-   Total number of subjects in the cohort: $N = TP + FP + FN + TN = 120 + 30 + 20 + 330 = 500$.\n\nThe task is to derive estimators for five diagnostic accuracy metrics from the core definition of conditional probability, $P(A|B) = \\frac{P(A \\cap B)}{P(B)}$, where probabilities are estimated by sample frequencies, i.e., $P(E) \\approx \\frac{N(E)}{N}$.\n\n**1. Sensitivity ($Sens$)**\nSensitivity is the probability of a positive test result given that the patient has the disease. It is defined as the conditional probability $P(T^+|D^+)$.\nStarting from the definition of conditional probability:\n$$Sens = P(T^+ | D^+) = \\frac{P(T^+ \\cap D^+)}{P(D^+)}$$\nThe estimator, $\\widehat{Sens}$, is found by substituting the sample frequencies (counts):\n$$\\widehat{Sens} = \\frac{N(T^+ \\cap D^+)}{N(D^+)} = \\frac{TP}{TP + FN}$$\nUsing the given values:\n$$\\widehat{Sens} = \\frac{120}{120 + 20} = \\frac{120}{140} = \\frac{6}{7} \\approx 0.8571$$\n\n**2. Specificity ($Spec$)**\nSpecificity is the probability of a negative test result given that the patient does not have the disease. It is defined as the conditional probability $P(T^-|D^-)$.\nStarting from the definition of conditional probability:\n$$Spec = P(T^- | D^-) = \\frac{P(T^- \\cap D^-)}{P(D^-)}$$\nThe estimator, $\\widehat{Spec}$, is:\n$$\\widehat{Spec} = \\frac{N(T^- \\cap D^-)}{N(D^-)} = \\frac{TN}{FP + TN}$$\nUsing the given values:\n$$\\widehat{Spec} = \\frac{330}{30 + 330} = \\frac{330}{360} = \\frac{11}{12} \\approx 0.9167$$\n\n**3. Positive Predictive Value ($PPV$)**\nPositive predictive value is the probability that a patient has the disease given a positive test result. It is defined as the conditional probability $P(D^+|T^+)$.\nStarting from the definition of conditional probability:\n$$PPV = P(D^+ | T^+) = \\frac{P(D^+ \\cap T^+)}{P(T^+)}$$\nThe estimator, $\\widehat{PPV}$, is:\n$$\\widehat{PPV} = \\frac{N(D^+ \\cap T^+)}{N(T^+)} = \\frac{TP}{TP + FP}$$\nUsing the given values:\n$$\\widehat{PPV} = \\frac{120}{120 + 30} = \\frac{120}{150} = \\frac{4}{5} = 0.8$$\n\n**4. Negative Predictive Value ($NPV$)**\nNegative predictive value is the probability that a patient does not have the disease given a negative test result. It is defined as the conditional probability $P(D^-|T^-)$.\nStarting from the definition of conditional probability:\n$$NPV = P(D^- | T^-) = \\frac{P(D^- \\cap T^-)}{P(T^-)}$$\nThe estimator, $\\widehat{NPV}$, is:\n$$\\widehat{NPV} = \\frac{N(D^- \\cap T^-)}{N(T^-)} = \\frac{TN}{FN + TN}$$\nUsing the given values:\n$$\\widehat{NPV} = \\frac{330}{20 + 330} = \\frac{330}{350} = \\frac{33}{35} \\approx 0.9429$$\n\n**5. Diagnostic Odds Ratio ($DOR$)**\nThe diagnostic odds ratio is the ratio of the odds of testing positive if the patient has the disease to the odds of testing positive if the patient does not have the disease.\nThe odds of an event $A$ is defined as $\\frac{P(A)}{1-P(A)}$.\nThe odds of a positive test in the diseased group is:\n$$\\text{Odds}(T^+|D^+) = \\frac{P(T^+|D^+)}{P(T^-|D^+)} = \\frac{P(T^+|D^+)}{1 - P(T^+|D^+)} = \\frac{Sens}{1-Sens}$$\nThe odds of a positive test in the non-diseased group is:\n$$\\text{Odds}(T^+|D^-) = \\frac{P(T^+|D^-)}{P(T^-|D^-)} = \\frac{1 - P(T^-|D^-)}{P(T^-|D^-)} = \\frac{1-Spec}{Spec}$$\nThe $DOR$ is the ratio of these two odds:\n$$DOR = \\frac{\\text{Odds}(T^+|D^+)}{\\text{Odds}(T^+|D^-)} = \\frac{Sens / (1-Sens)}{(1-Spec) / Spec}$$\nNow, we substitute the estimators derived from the counts:\n$\\widehat{Sens} = \\frac{TP}{TP+FN}$, so $1-\\widehat{Sens} = \\frac{FN}{TP+FN}$.\n$\\widehat{Spec} = \\frac{TN}{FP+TN}$, so $1-\\widehat{Spec} = \\frac{FP}{FP+TN}$.\nThe estimator for the odds in the diseased group is:\n$$\\widehat{\\text{Odds}}(T^+|D^+) = \\frac{TP/(TP+FN)}{FN/(TP+FN)} = \\frac{TP}{FN}$$\nThe estimator for the odds in the non-diseased group is:\n$$\\widehat{\\text{Odds}}(T^+|D^-) = \\frac{FP/(FP+TN)}{TN/(FP+TN)} = \\frac{FP}{TN}$$\nTherefore, the estimator for the $DOR$ is the ratio of these two estimated odds, which simplifies to the cross-product ratio:\n$$\\widehat{DOR} = \\frac{TP/FN}{FP/TN} = \\frac{TP \\times TN}{FP \\times FN}$$\nUsing the given values:\n$$\\widehat{DOR} = \\frac{120 \\times 330}{30 \\times 20} = \\frac{39600}{600} = \\frac{396}{6} = 66$$\nThe problem requires this value to be rounded to four significant figures. The calculated value is an exact integer, $66$. To express this with four significant figures, we write it as $66.00$.", "answer": "$$\n\\boxed{66.00}\n$$", "id": "5221406"}, {"introduction": "Moving beyond a test's intrinsic properties, this practice demonstrates how to dynamically update diagnostic certainty using Bayesian reasoning [@problem_id:5221343]. You will use likelihood ratios, powerful tools that summarize a test's performance, to convert a pretest probability of disease into a more informed post-test probability. This skill is central to making evidence-based clinical decisions and highlights how diagnostic information refines clinical judgment.", "problem": "A clinical laboratory is evaluating a new biomarker assay for a disease in a population where the pretest probability of disease is $0.20$. From meta-analytic validation studies, the assay’s positive likelihood ratio is $LR_{+}=8$ and its negative likelihood ratio is $LR_{-}=0.2$. Using first principles from Bayesian reasoning in diagnostic testing, begin with the definition of conditional probability and Bayes theorem, and the definitions of likelihood ratios in terms of conditional probabilities. From these foundations, derive how to update from pretest probability to post-test probability after a positive result and after a negative result. Then, using the given values, compute the numerical post-test probabilities for a positive result and for a negative result. Express both post-test probabilities as decimals, rounded to four significant figures. Report your answers in the order: positive-result probability, negative-result probability.", "solution": "The problem is valid as it is scientifically grounded in the principles of Bayesian statistics as applied to medical diagnostics, is well-posed with sufficient and consistent data, and is expressed in objective, formalizable language.\n\nLet $D$ be the event that a patient has the disease, and $D^c$ be the event that the patient does not have the disease. Let $T+$ be the event of a positive test result and $T-$ be the event of a negative test result. The provided information is:\n- Pretest probability of disease: $P(D) = 0.20$.\n- Positive likelihood ratio: $LR_{+} = 8$.\n- Negative likelihood ratio: $LR_{-} = 0.2$.\n\nOur objective is to derive the post-test probabilities of disease given a positive result, $P(D|T+)$, and given a negative result, $P(D|T-)$, starting from first principles.\n\n**1. First Principles and Definitions**\n\nThe definition of conditional probability for two events $A$ and $B$, where $P(B) > 0$, is:\n$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\nFrom this, we can write $P(A \\cap B) = P(A|B)P(B)$. By symmetry, $P(B \\cap A) = P(B|A)P(A)$. Since $P(A \\cap B) = P(B \\cap A)$, we can equate these to get $P(A|B)P(B) = P(B|A)P(A)$. Rearranging for $P(A|B)$ yields Bayes' theorem:\n$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n\nThe likelihood ratios are defined in terms of conditional probabilities. The positive likelihood ratio, $LR_{+}$, is the ratio of the true positive rate (sensitivity) to the false positive rate.\n$$LR_{+} = \\frac{P(T+|D)}{P(T+|D^c)}$$\nThe negative likelihood ratio, $LR_{-}$, is the ratio of the false negative rate to the true negative rate (specificity).\n$$LR_{-} = \\frac{P(T-|D)}{P(T-|D^c)}$$\n\n**2. Derivation using the Odds Formulation**\n\nTo update from pretest to post-test probability, it is convenient to work with odds. The odds of an event $A$ are defined as $O(A) = \\frac{P(A)}{1-P(A)} = \\frac{P(A)}{P(A^c)}$.\n\nThe pretest odds of disease are:\n$$O_{pre} = \\frac{P(D)}{P(D^c)}$$\nThe post-test odds of disease, given a positive result $T+$, are:\n$$O_{post,+} = \\frac{P(D|T+)}{P(D^c|T+)}$$\nUsing Bayes' theorem for the numerator and denominator:\n$$P(D|T+) = \\frac{P(T+|D)P(D)}{P(T+)}$$\n$$P(D^c|T+) = \\frac{P(T+|D^c)P(D^c)}{P(T+)}$$\nSubstituting these into the expression for $O_{post,+}$:\n$$O_{post,+} = \\frac{\\frac{P(T+|D)P(D)}{P(T+)}}{\\frac{P(T+|D^c)P(D^c)}{P(T+)}} = \\frac{P(T+|D)P(D)}{P(T+|D^c)P(D^c)}$$\nThis can be rearranged into two parts:\n$$O_{post,+} = \\left(\\frac{P(T+|D)}{P(T+|D^c)}\\right) \\left(\\frac{P(D)}{P(D^c)}\\right)$$\nWe recognize the first term as the positive likelihood ratio, $LR_{+}$, and the second term as the pretest odds, $O_{pre}$. Thus, we have derived the fundamental relationship for a positive test:\n$$O_{post,+} = LR_{+} \\times O_{pre}$$\nAn analogous derivation for a negative test result $T-$ yields:\n$$O_{post,-} = \\frac{P(D|T-)}{P(D^c|T-)} = \\left(\\frac{P(T-|D)}{P(T-|D^c)}\\right) \\left(\\frac{P(D)}{P(D^c)}\\right) = LR_{-} \\times O_{pre}$$\n\nFinally, to convert odds back to probability, we use the relationship $P(A) = \\frac{O(A)}{1+O(A)}$.\nTherefore, the post-test probabilities are:\n$$P(D|T+) = \\frac{O_{post,+}}{1 + O_{post,+}}$$\n$$P(D|T-) = \\frac{O_{post,-}}{1 + O_{post,-}}$$\n\n**3. Numerical Computation**\n\nGiven the values: $P(D) = 0.20$, $LR_{+} = 8$, and $LR_{-} = 0.2$.\n\nFirst, calculate the pretest odds. The probability of not having the disease is $P(D^c) = 1 - P(D) = 1 - 0.20 = 0.80$.\n$$O_{pre} = \\frac{P(D)}{P(D^c)} = \\frac{0.20}{0.80} = 0.25$$\n\nNext, calculate the post-test odds for a positive result:\n$$O_{post,+} = LR_{+} \\times O_{pre} = 8 \\times 0.25 = 2.0$$\nConvert these odds back to a probability:\n$$P(D|T+) = \\frac{O_{post,+}}{1 + O_{post,+}} = \\frac{2.0}{1 + 2.0} = \\frac{2}{3} \\approx 0.666666...$$\nRounding to four significant figures, we get $P(D|T+) \\approx 0.6667$.\n\nNow, calculate the post-test odds for a negative result:\n$$O_{post,-} = LR_{-} \\times O_{pre} = 0.2 \\times 0.25 = 0.05$$\nConvert these odds back to a probability:\n$$P(D|T-) = \\frac{O_{post,-}}{1 + O_{post,-}} = \\frac{0.05}{1 + 0.05} = \\frac{0.05}{1.05} = \\frac{5}{105} = \\frac{1}{21} \\approx 0.047619...$$\nRounding to four significant figures, we get $P(D|T-) \\approx 0.04762$.\n\nThe post-test probability of disease after a positive result is $0.6667$, and after a negative result it is $0.04762$.", "answer": "$$\\boxed{\\begin{pmatrix} 0.6667 & 0.04762 \\end{pmatrix}}$$", "id": "5221343"}, {"introduction": "This practice bridges the gap between analytical performance goals and the daily operational decisions needed to ensure reliable results. You will calculate the \"sigma metric,\" a key performance indicator that quantifies process capability by relating the total allowable error ($TE_a$) to the observed bias and imprecision ($\\mathrm{CV}$). Subsequently, you will evaluate different Quality Control (QC) rules to learn how to design a statistical process control strategy that effectively detects errors while minimizing costly false alarms [@problem_id:5221369].", "problem": "A clinical chemistry laboratory is implementing internal Quality Control (QC) for a high-volume immunoassay. The assay’s allowable analytical performance is governed by Total Allowable Error (TEa). The laboratory has characterized its current method and found a relative systematic error (bias) and relative imprecision, expressed by the Coefficient of Variation (CV). The laboratory measures two QC materials (one low control and one high control) once per run. Assume that the in-control QC measurement errors at both levels are independent and normally distributed about their respective target means.\n\nGiven $TE_{a} = 0.10$, bias $= 0.02$, and $\\mathrm{CV} = 0.02$, first derive from fundamental definitions a capability index (the “sigma metric”) that counts how many standard deviations of imprecision fit within the allowable error after accounting for bias. Then, under the in-control assumption and using properties of the standard normal distribution, compute the expected false rejection probability per run for each of the following candidate QC rule sets (each set is applied across the two single measurements per run):\n\n- Set $1$: The $1\\_2s$ rule applied to each control independently; the run is rejected if at least one control result is outside $\\pm 2$ standard deviations (SD) from its mean.\n- Set $2$: The $1\\_3s$ rule applied to each control independently; the run is rejected if at least one control result is outside $\\pm 3$ SD from its mean.\n- Set $3$: The $2\\_2s$ rule applied across the two controls; the run is rejected if both control results are on the same side of the mean and each is more extreme than $+2$ SD or each is less extreme than $-2$ SD.\n\nUse the standard normal cumulative distribution function $\\Phi(\\cdot)$ and assume independence of the two QC results. Select the single QC rule set whose expected false rejection probability is strictly less than $0.05$ and is closest to $0.05$ among the qualifying sets. Report your final answer as a row matrix $\\begin{pmatrix}\\sigma & k\\end{pmatrix}$, where $\\sigma$ is the sigma metric rounded to three significant figures, and $k \\in \\{1,2,3\\}$ is the index of the selected QC rule set. No units are required in the final answer.", "solution": "The problem is assessed to be valid as it is scientifically grounded in the principles of laboratory statistical quality control, is well-posed with sufficient information for a unique solution, and is expressed objectively.\n\nThe solution is approached in two main parts: first, the derivation and calculation of the sigma metric ($\\sigma$); second, the calculation of the false rejection probability ($P_{fr}$) for each of the three candidate Quality Control (QC) rule sets, followed by the selection of the optimal set based on the given criteria.\n\n**Part 1: Derivation and Calculation of the Sigma Metric**\n\nThe sigma metric is a measure of process capability, quantifying how many standard deviations ($SD$) of the process's random error (imprecision) fit within the tolerance limits remaining after accounting for systematic error (bias). The total tolerance is defined by the Total Allowable Error, $TE_a$.\n\nThe given parameters are all relative (dimensionless):\n- Total Allowable Error: $TE_a = 0.10$\n- Systematic Error: $\\text{bias} = 0.02$\n- Random Error (Imprecision): $\\mathrm{CV} = 0.02$\n\nThe total error budget is $TE_a$. The systematic error, bias, consumes a portion of this budget. The remaining analytical space available to accommodate random error is the difference between the total allowable error and the bias.\n$$ \\text{Allowable space for random error} = TE_a - |\\text{bias}| $$\nThe imprecision of the method is given by the Coefficient of Variation, $\\mathrm{CV}$, which represents one standard deviation of the measurement process in relative terms.\n\nThe sigma metric, $\\sigma$, is defined as the ratio of the allowable space for random error to the magnitude of the random error itself (one standard deviation).\n$$ \\sigma = \\frac{TE_a - |\\text{bias}|}{\\mathrm{CV}} $$\nSubstituting the given values into this derived formula:\n$$ \\sigma = \\frac{0.10 - 0.02}{0.02} = \\frac{0.08}{0.02} = 4 $$\nThe problem requires this value to be rounded to three significant figures. Thus, the sigma metric is $\\sigma = 4.00$.\n\n**Part 2: Calculation of False Rejection Probabilities and Rule Selection**\n\nA false rejection occurs when an in-control process is incorrectly flagged as out-of-control. The problem states that the process is in-control, meaning the QC measurements are drawn from a normal distribution centered on their respective target means. Let $Z_1$ and $Z_2$ represent the standardized results for the low and high controls, respectively. Under the in-control assumption, $Z_1$ and $Z_2$ are independent random variables from the standard normal distribution, $N(0, 1)$. The probability of a rejection is denoted as $P_{fr}$. We utilize the standard normal cumulative distribution function, $\\Phi(z) = P(Z \\le z)$.\n\n**Set 1: $1_{2s}$ rule applied independently to each control.**\nThe run is rejected if at least one control result is outside $\\pm 2$ standard deviations from its mean. This corresponds to the event $(|Z_1| > 2) \\cup (|Z_2| > 2)$.\nThe probability of rejection, $P_{fr,1}$, is the complement of the probability of acceptance, where acceptance requires both controls to be within $\\pm 2$ standard deviations: $(|Z_1| \\le 2) \\cap (|Z_2| \\le 2)$.\n$$ P_{fr,1} = 1 - P(|Z_1| \\le 2 \\text{ and } |Z_2| \\le 2) $$\nDue to independence, this becomes:\n$$ P_{fr,1} = 1 - P(|Z_1| \\le 2) \\times P(|Z_2| \\le 2) = 1 - [P(|Z| \\le 2)]^2 $$\nThe probability $P(|Z| \\le 2)$ is given by $\\Phi(2) - \\Phi(-2)$. Using the symmetry $\\Phi(-z) = 1 - \\Phi(z)$, this is $\\Phi(2) - (1 - \\Phi(2)) = 2\\Phi(2) - 1$.\n$$ P_{fr,1} = 1 - (2\\Phi(2) - 1)^2 $$\nUsing the standard value $\\Phi(2) \\approx 0.97725$:\n$$ P_{fr,1} \\approx 1 - (2 \\times 0.97725 - 1)^2 = 1 - (1.9545 - 1)^2 = 1 - (0.9545)^2 \\approx 1 - 0.91107 \\approx 0.08893 $$\n\n**Set 2: $1_{3s}$ rule applied independently to each control.**\nThe logic is identical to Set 1, but with a limit of $3$ standard deviations. The run is rejected if $(|Z_1| > 3) \\cup (|Z_2| > 3)$.\n$$ P_{fr,2} = 1 - [P(|Z| \\le 3)]^2 = 1 - (2\\Phi(3) - 1)^2 $$\nUsing the standard value $\\Phi(3) \\approx 0.99865$:\n$$ P_{fr,2} \\approx 1 - (2 \\times 0.99865 - 1)^2 = 1 - (1.9973 - 1)^2 = 1 - (0.9973)^2 \\approx 1 - 0.99461 \\approx 0.00539 $$\n\n**Set 3: $2_{2s}$ rule applied across the two controls.**\nThe run is rejected if both control results are on the same side of the mean and outside $\\pm 2$ standard deviations. This corresponds to the event $((Z_1 > 2) \\cap (Z_2 > 2)) \\cup ((Z_1 < -2) \\cap (Z_2 < -2))$.\nThese two compound events are mutually exclusive. Therefore, the total probability is the sum of their individual probabilities.\n$$ P_{fr,3} = P((Z_1 > 2) \\cap (Z_2 > 2)) + P((Z_1 < -2) \\cap (Z_2 < -2)) $$\nDue to independence:\n$$ P_{fr,3} = P(Z_1 > 2)P(Z_2 > 2) + P(Z_1 < -2)P(Z_2 < -2) $$\nSince $P(Z > z) = 1 - \\Phi(z)$ and $P(Z < -z) = \\Phi(-z) = 1 - \\Phi(z)$:\n$$ P_{fr,3} = (1 - \\Phi(2))^2 + (1 - \\Phi(2))^2 = 2(1 - \\Phi(2))^2 $$\nUsing $\\Phi(2) \\approx 0.97725$:\n$$ P_{fr,3} \\approx 2(1 - 0.97725)^2 = 2(0.02275)^2 \\approx 2(0.00051756) \\approx 0.001035 $$\n\n**Selection of the QC Rule Set**\nThe selection criterion is that the expected false rejection probability, $P_{fr}$, must be strictly less than $0.05$ and be the closest to $0.05$ among the qualifying sets.\n\nSummary of probabilities:\n- Set 1: $P_{fr,1} \\approx 0.0889$. This does not satisfy $P_{fr} < 0.05$.\n- Set 2: $P_{fr,2} \\approx 0.00539$. This satisfies $P_{fr} < 0.05$.\n- Set 3: $P_{fr,3} \\approx 0.001035$. This satisfies $P_{fr} < 0.05$.\n\nWe now compare the qualifying sets (Set 2 and Set 3) to see which is closer to $0.05$:\n- Distance for Set 2: $|0.05 - 0.00539| = 0.04461$\n- Distance for Set 3: $|0.05 - 0.001035| = 0.048965$\n\nSince $0.04461 < 0.048965$, the false rejection probability for Set 2 is closer to $0.05$. Therefore, the selected QC rule set is Set 2, which corresponds to the index $k=2$.\n\nThe final answer requires the sigma metric, $\\sigma=4.00$, and the index of the selected rule set, $k=2$.", "answer": "$$ \\boxed{\n\\begin{pmatrix}\n4.00 & 2\n\\end{pmatrix}\n} $$", "id": "5221369"}]}