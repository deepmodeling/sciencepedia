{"hands_on_practices": [{"introduction": "Clinical decision support tools are increasingly common, promising objective and data-driven insights. However, without careful evaluation, these tools can inadvertently amplify existing societal biases. This exercise [@problem_id:4866404] provides a direct method for assessing such algorithmic inequity by analyzing a tool's performance across different patient populations. By calculating and comparing the False Negative Rates, you will quantify how often the tool fails to identify a condition in different groups, a crucial step in evaluating its ethical implications under fairness criteria like Equal Opportunity.", "problem": "A regional health system deploys a binary clinical decision support tool to flag patients for urgent follow-up for a condition with significant morbidity if missed. The tool is evaluated separately in two patient cohorts distinguished by socioeconomic context: Group $G_1$ (patients from historically under-resourced neighborhoods) and Group $G_2$ (patients from well-resourced neighborhoods). The ethical concern is whether the tool produces structurally inequitable outcomes through differential error rates that could lead to under-treatment of $G_1$.\n\nYou are provided the following counts from the confusion matrices for each group over the same evaluation period:\n- For $G_1$: true positives $TP_1 = 186$, false negatives $FN_1 = 54$, true negatives $TN_1 = 672$, and false positives $FP_1 = 88$.\n- For $G_2$: true positives $TP_2 = 205$, false negatives $FN_2 = 35$, true negatives $TN_2 = 701$, and false positives $FP_2 = 59$.\n\nIn algorithmic fairness, Equal Opportunity (EO) requires that the True Positive Rate (TPR) be equal across protected groups. False Negative Rate (FNR) is the proportion of actual positive cases that the classifier fails to identify. Using these definitions and the given counts, compute the difference in false negative rates defined as $FNR_{G_1} - FNR_{G_2}$. Round your final numerical answer to four significant figures. Then, based on first principles, assess whether EO is violated and briefly justify your assessment in terms of the relationship between TPR and FNR in this context. Your final boxed answer must be the single real-valued number corresponding to $FNR_{G_1} - FNR_{G_2}$, rounded as specified.", "solution": "The problem asks for the calculation of the difference in False Negative Rates ($FNR$) between two patient groups, $G_1$ and $G_2$, and an assessment of whether the Equal Opportunity (EO) fairness criterion is violated.\n\nFirst, we must define the relevant metrics based on the provided confusion matrix counts: True Positives ($TP$), False Negatives ($FN$), True Negatives ($TN$), and False Positives ($FP$).\n\nThe total number of individuals who actually have the condition (actual positives) in a group is the sum of the true positives and false negatives. For a group $i$, this is denoted as $P_i$.\n$$P_i = TP_i + FN_i$$\n\nThe False Negative Rate ($FNR$) is the proportion of actual positive cases that are incorrectly classified as negative. It is defined as:\n$$FNR_i = \\frac{FN_i}{P_i} = \\frac{FN_i}{TP_i + FN_i}$$\nThis metric quantifies the rate of \"misses\" for patients who genuinely have the condition.\n\nThe True Positive Rate ($TPR$), also known as sensitivity or recall, is the proportion of actual positive cases that are correctly classified as positive. It is defined as:\n$$TPR_i = \\frac{TP_i}{P_i} = \\frac{TP_i}{TP_i + FN_i}$$\nThis metric quantifies the rate of \"hits\" for patients who genuinely have the condition.\n\nA fundamental relationship exists between $TPR$ and $FNR$:\n$$TPR_i + FNR_i = \\frac{TP_i}{TP_i + FN_i} + \\frac{FN_i}{TP_i + FN_i} = \\frac{TP_i + FN_i}{TP_i + FN_i} = 1$$\nTherefore, $FNR_i = 1 - TPR_i$.\n\nNow, let's apply these definitions to the given data for Group $G_1$ and Group $G_2$.\n\nFor Group $G_1$:\n- $TP_1 = 186$\n- $FN_1 = 54$\n\nThe number of actual positives in $G_1$ is:\n$$P_1 = TP_1 + FN_1 = 186 + 54 = 240$$\nThe False Negative Rate for $G_1$ is:\n$$FNR_{G_1} = \\frac{FN_1}{P_1} = \\frac{54}{240}$$\n\nFor Group $G_2$:\n- $TP_2 = 205$\n- $FN_2 = 35$\n\nThe number of actual positives in $G_2$ is:\n$$P_2 = TP_2 + FN_2 = 205 + 35 = 240$$\nThe False Negative Rate for $G_2$ is:\n$$FNR_{G_2} = \\frac{FN_2}{P_2} = \\frac{35}{240}$$\n\nThe problem asks for the difference in false negative rates, $FNR_{G_1} - FNR_{G_2}$.\n$$FNR_{G_1} - FNR_{G_2} = \\frac{54}{240} - \\frac{35}{240} = \\frac{54 - 35}{240} = \\frac{19}{240}$$\n\nTo obtain the numerical value, we perform the division:\n$$\\frac{19}{240} \\approx 0.0791666...$$\nRounding this result to four significant figures gives:\n$$FNR_{G_1} - FNR_{G_2} \\approx 0.07917$$\n\nNext, we must assess whether the Equal Opportunity (EO) criterion is violated. The EO criterion requires that the True Positive Rate ($TPR$) be equal across the protected groups. In this case, it requires:\n$$TPR_{G_1} = TPR_{G_2}$$\nUsing the relationship $TPR_i = 1 - FNR_i$, the EO condition can be equivalently expressed in terms of False Negative Rates:\n$$1 - FNR_{G_1} = 1 - FNR_{G_2}$$\nThis simplifies to:\n$$FNR_{G_1} = FNR_{G_2}$$\nLet's compare the calculated FNR values:\n$$FNR_{G_1} = \\frac{54}{240} = 0.225$$\n$$FNR_{G_2} = \\frac{35}{240} \\approx 0.14583$$\nSince $0.225 \\neq 0.14583...$, we have $FNR_{G_1} \\neq FNR_{G_2}$. It directly follows that $TPR_{G_1} \\neq TPR_{G_2}$, and therefore the Equal Opportunity criterion is violated.\n\nThe justification is rooted in the identity $TPR + FNR = 1$. A difference in False Negative Rates between the groups mathematically necessitates a difference in True Positive Rates, which is the definition of a violation of Equal Opportunity. The positive difference $FNR_{G_1} - FNR_{G_2}  0$ indicates that the clinical decision support tool has a higher rate of false negatives for the under-resourced group ($G_1$) than for the well-resourced group ($G_2$). This means that a patient from $G_1$ who actually has the condition is more likely to be missed by the tool than a similar patient from $G_2$, leading to a higher risk of under-treatment for the under-resourced population. This is a clear example of structurally inequitable outcomes produced by the algorithm.", "answer": "$$\\boxed{0.07917}$$", "id": "4866404"}, {"introduction": "After identifying disparate outcomes, the next step is to understand the underlying mechanisms of bias. Signal Detection Theory (SDT) offers a powerful model for deconstructing diagnostic decisions into two components: the ability to distinguish a signal from noise (sensitivity, $d'$) and the decision threshold used to act (criterion, $c$). This practice [@problem_id:4866513] challenges you to apply the SDT framework to see how implicit bias, modeled as a shift in the decision criterion, can systematically alter false positive and false negative rates for different groups, even when diagnostic sensitivity remains the same.", "problem": "A hospital uses a standardized diagnostic score to decide whether to initiate a resource-intensive intervention for suspected sepsis. Assume the score for patients without sepsis (the \"noise\" condition) is normally distributed with mean $0$ and variance $1$, and the score for patients with sepsis (the \"signal\" condition) is normally distributed with mean $d'$ and variance $1$. Clinicians diagnose sepsis (and initiate the intervention) if the score is at least a decision criterion $c$. Under unbiased practice, clinicians use a baseline criterion $c_{0}$. Implicit bias is modeled as a shift in the decision criterion $c$ that is not accompanied by any change in sensitivity $d'$.\n\nUsing Signal Detection Theory (SDT), and starting from the definitions of normal distributions and decision rules, do the following:\n\n1. Derive the false positive rate $\\mathrm{FPR}(c)$ and the false negative rate $\\mathrm{FNR}(c)$ as functions of the criterion $c$ and sensitivity $d'$ under the equal-variance Gaussian model described above.\n\n2. Consider two patient groups, $A$ and $B$, who share the same underlying score distributions (so $d'$ is the same across groups), but experience different biased criteria. Take $d' = 1.0$ and $c_{0} = 0.0$. Due to implicit bias and structural inequity, the criterion for group $A$ is increased to $c_{A} = c_{0} + 0.5$, while the criterion for group $B$ is decreased to $c_{B} = c_{0} - 0.3$. For each group, compute the change in false positive rate $\\Delta \\mathrm{FPR} = \\mathrm{FPR}(c_{\\text{group}}) - \\mathrm{FPR}(c_{0})$ and the change in false negative rate $\\Delta \\mathrm{FNR} = \\mathrm{FNR}(c_{\\text{group}}) - \\mathrm{FNR}(c_{0})$.\n\n3. Define a composite inequity index\n$$\nS \\equiv \\left|\\Delta \\mathrm{FPR}_{A}\\right| + \\left|\\Delta \\mathrm{FNR}_{A}\\right| + \\left|\\Delta \\mathrm{FPR}_{B}\\right| + \\left|\\Delta \\mathrm{FNR}_{B}\\right| ,\n$$\nwhich summarizes the total magnitude of change in error rates across both groups due to biased criteria. Compute $S$ numerically and round your final answer to four significant figures. Express all rates and the final $S$ as decimals without any percentage sign.", "solution": "The problem asks for an analysis of diagnostic error rates using the framework of Signal Detection Theory (SDT). We are given a scenario with two underlying states: \"noise\" (patient without sepsis) and \"signal\" (patient with sepsis). The diagnostic scores for these states are modeled by Gaussian distributions with equal variance.\n\nThe noise distribution, for patients without sepsis, is a standard normal distribution, $\\mathcal{N}(0, 1)$. The signal distribution, for patients with sepsis, is a normal distribution $\\mathcal{N}(d', 1)$. A diagnosis of sepsis is made if the observed score $x$ meets or exceeds a decision criterion $c$.\n\n**1. Derivation of False Positive and False Negative Rates**\n\nThe false positive rate, $\\mathrm{FPR}(c)$, is the probability of diagnosing sepsis ($x \\ge c$) when the patient does not have it (noise condition). This is the upper tail probability of the standard normal distribution. Let $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution.\n$$\n\\mathrm{FPR}(c) = P(x \\ge c \\,|\\, \\text{Noise}) = 1 - \\Phi(c)\n$$\n\nThe false negative rate, $\\mathrm{FNR}(c)$, is the probability of not diagnosing sepsis ($x  c$) when the patient does have it (signal condition). This is the lower tail probability of the signal distribution.\n$$\n\\mathrm{FNR}(c) = P(x  c \\,|\\, \\text{Signal}) = \\Phi\\left(\\frac{c - \\mu_S}{\\sigma_S}\\right) = \\Phi(c - d')\n$$\n\n**2. Computation of Changes in Error Rates**\n\nWe are given the parameters: sensitivity $d' = 1.0$ and baseline criterion $c_{0} = 0.0$. For group A, the criterion is $c_{A} = 0.5$. For group B, the criterion is $c_{B} = -0.3$.\n\nWe use standard values for the normal CDF $\\Phi(z)$:\n$\\Phi(0.0) = 0.50000$\n$\\Phi(0.3) = 0.61791$\n$\\Phi(0.5) = 0.69146$\n$\\Phi(-0.3) = 1 - \\Phi(0.3) = 0.38209$\n$\\Phi(-0.5) = 1 - \\Phi(0.5) = 0.30854$\n$\\Phi(-1.0) = 0.15866$\n$\\Phi(-1.3) = 1 - \\Phi(1.3) = 1 - 0.90320 = 0.09680$\n\nFirst, we compute the baseline error rates at $c_{0} = 0.0$:\n$\\mathrm{FPR}(c_0) = 1 - \\Phi(0.0) = 0.50000$\n$\\mathrm{FNR}(c_0) = \\Phi(0.0 - 1.0) = \\Phi(-1.0) = 0.15866$\n\nNext, we compute the error rates for Group A at $c_{A} = 0.5$:\n$\\mathrm{FPR}(c_A) = 1 - \\Phi(0.5) = 1 - 0.69146 = 0.30854$\n$\\mathrm{FNR}(c_A) = \\Phi(0.5 - 1.0) = \\Phi(-0.5) = 0.30854$\n\nNext, we compute the error rates for Group B at $c_{B} = -0.3$:\n$\\mathrm{FPR}(c_B) = 1 - \\Phi(-0.3) = \\Phi(0.3) = 0.61791$\n$\\mathrm{FNR}(c_B) = \\Phi(-0.3 - 1.0) = \\Phi(-1.3) = 0.09680$\n\nNow, we calculate the changes in error rates ($\\Delta$) relative to the baseline for each group.\nFor Group A:\n$\\Delta \\mathrm{FPR}_{A} = \\mathrm{FPR}(c_A) - \\mathrm{FPR}(c_0) = 0.30854 - 0.50000 = -0.19146$\n$\\Delta \\mathrm{FNR}_{A} = \\mathrm{FNR}(c_A) - \\mathrm{FNR}(c_0) = 0.30854 - 0.15866 = 0.14988$\n\nFor Group B:\n$\\Delta \\mathrm{FPR}_{B} = \\mathrm{FPR}(c_B) - \\mathrm{FPR}(c_0) = 0.61791 - 0.50000 = 0.11791$\n$\\Delta \\mathrm{FNR}_{B} = \\mathrm{FNR}(c_B) - \\mathrm{FNR}(c_0) = 0.09680 - 0.15866 = -0.06186$\n\n**3. Computation of the Composite Inequity Index S**\n\nThe composite inequity index $S$ is defined as the sum of the absolute magnitudes of these changes.\n$$\nS \\equiv |\\Delta \\mathrm{FPR}_{A}| + |\\Delta \\mathrm{FNR}_{A}| + |\\Delta \\mathrm{FPR}_{B}| + |\\Delta \\mathrm{FNR}_{B}|\n$$\nSubstituting the calculated values:\n$$\nS = |-0.19146| + |0.14988| + |0.11791| + |-0.06186|\n$$\n$$\nS = 0.19146 + 0.14988 + 0.11791 + 0.06186\n$$\nPerforming the summation:\n$$\nS = 0.52111\n$$\nRounding the final answer to four significant figures gives:\n$$\nS \\approx 0.5211\n$$", "answer": "$$\\boxed{0.5211}$$", "id": "4866513"}, {"introduction": "Measuring the real-world impact of implicit bias is a complex causal inference task, and seemingly intuitive analytical choices can lead to profoundly wrong conclusions. This reasoning exercise [@problem_id:4866442] explores a common methodological pitfall known as collider bias, using the formal logic of Directed Acyclic Graphs (DAGs). By analyzing the given causal structure, you will understand why adjusting for a variable that is a common effect of both bias and an unmeasured factor can paradoxically create a spurious association, compromising the validity of the study.", "problem": "A hospital ethics committee investigates whether clinician implicit bias affects $30$-day mortality among patients from structurally marginalized communities. Let $A \\in \\{0,1\\}$ indicate exposure to higher clinician implicit bias ($A=1$) versus lower clinician implicit bias ($A=0$). Let $Y \\in \\{0,1\\}$ denote $30$-day mortality. Define potential outcomes $Y(1)$ and $Y(0)$ as the mortality that would be observed under $A=1$ and $A=0$, respectively, under the Stable Unit Treatment Value Assumption (SUTVA). Suppose there exist baseline covariates $X$ that, if conditioned on, would render $Y(a)$ independent of $A$ (conditional exchangeability), i.e., $Y(a) \\perp A \\mid X$ for $a \\in \\{0,1\\}$, and positivity $P(A=a \\mid X)0$. Let $U$ denote unmeasured clinical need/severity driven by structural inequities (for example, chronic under-resourcing) that affects both mortality and healthcare utilization. Let healthcare utilization $H$ be the number of clinical encounters or intensity of services received during the episode, with $H$ affected by both $A$ and $U$ due to differential ordering of tests/referrals and differential clinical need.\n\nInvestigators plan to estimate the effect of clinician implicit bias on mortality by either restricting to patients with $H \\ge 1$ or adjusting for $H$ in regression. Using the potential outcomes framework and the principle that conditioning on a collider induces selection bias, identify the statement that correctly explains why conditioning on healthcare utilization $H$ can bias the assessment of the effect of clinician implicit bias $A$ on mortality $Y$. Assume a Directed Acyclic Graph (DAG) in which $A \\rightarrow H \\leftarrow U \\rightarrow Y$, and recall that consistency implies $Y = Y(A)$.\n\nA. Conditioning on $H$ violates conditional exchangeability because $H$ is a collider on the path $A \\rightarrow H \\leftarrow U \\rightarrow Y$. Even if $Y(a) \\perp A \\mid X$ holds, conditioning on $H$ generally implies $Y(a) \\not\\perp A \\mid X,H$, so $E[Y \\mid A=a, H=h, X] \\ne E[Y(a) \\mid H=h, X]$ and selection bias is induced.\n\nB. Conditioning on $H$ blocks the causal pathway from $A$ to $Y$ because $H$ is a mediator, thereby eliminating bias and identifying the direct effect of $A$ on $Y$ without additional assumptions.\n\nC. Conditioning on $H$ improves positivity by ensuring $P(A=a \\mid H=h, X)  0$, which in turn guarantees unbiased estimation of $E[Y(a)]$.\n\nD. Because implicit bias $A$ is non-differential with respect to $Y$, conditioning on $H$ cannot change causal estimation, so $E[Y \\mid A=a] = E[Y(a)]$ regardless of $H$.\n\nE. Berksonâ€™s selection bias arises only when $H$ is continuous; when $H$ is discrete (for example, a count), conditioning on $H$ does not induce selection bias.", "solution": "The problem asks to identify the source of bias when conditioning on healthcare utilization ($H$) in an analysis of the effect of clinician bias ($A$) on mortality ($Y$), given the causal structure $A \\rightarrow H \\leftarrow U \\rightarrow Y$.\n\n1.  **Analyze the Causal Structure:** In the provided Directed Acyclic Graph (DAG), the variable $H$ (healthcare utilization) is a **collider**. A collider is a variable on a causal path that has two arrows pointing into it. Here, $H$ is caused by both clinician bias ($A \\rightarrow H$) and unmeasured patient severity ($U \\rightarrow H$). This creates the structure $A \\rightarrow H \\leftarrow U$.\n\n2.  **Apply the Principle of Collider Bias:** According to the rules of d-separation in DAGs, a path containing a collider is naturally \"blocked.\" This means the variables at the ends of the path (here, $A$ and $U$) are independent, assuming no other open paths exist between them. However, **conditioning on a collider opens the path**. When investigators adjust for $H$ in a regression model or restrict their analysis to a specific level of $H$ (e.g., hospitalized patients), they are conditioning on the collider.\n\n3.  **Identify the Induced Bias:** Conditioning on $H$ creates a spurious statistical association between $A$ and $U$ within strata of $H$. Since $U$ (unmeasured severity) is also a direct cause of the outcome $Y$ (mortality, via $U \\rightarrow Y$), this induced association between $A$ and $U$ opens a non-causal pathway from $A$ to $Y$ ($A \\rightarrow H \\leftarrow U \\rightarrow Y$). This is a form of selection bias.\n\n4.  **Evaluate in the Potential Outcomes Framework:** The initial assumption is that of conditional exchangeability, $Y(a) \\perp A \\mid X$, meaning that given the measured covariates $X$, the treatment assignment $A$ is independent of the potential outcomes. By conditioning on the post-treatment collider $H$, we introduce a new dependency. Within strata of $X$ and $H$, $A$ becomes associated with $U$, and since $U$ is a cause of $Y$, $A$ is no longer independent of the potential outcomes. Thus, conditional exchangeability is violated: $Y(a) \\not\\perp A \\mid X, H$. Consequently, any estimate of the effect of $A$ on $Y$ that adjusts for $H$ will be biased because $E[Y \\mid A=a, H=h, X] \\ne E[Y(a) \\mid H=h, X]$.\n\n**Evaluating the Options:**\n\n*   **A:** This statement correctly identifies $H$ as a collider and accurately explains that conditioning on it violates conditional exchangeability ($Y(a) \\not\\perp A \\mid X, H$), leading to selection bias. This aligns perfectly with the analysis above.\n*   **B:** This is incorrect. $H$ is a collider on the path between $A$ and $U$, not a mediator on a path from $A$ to $Y$. Conditioning on a collider *induces* bias, it does not eliminate it.\n*   **C:** This is incorrect. Conditioning on $H$ does not improve positivity and, more importantly, it introduces a violation of exchangeability, which is the primary source of bias here.\n*   **D:** This is incorrect. Conditioning on a post-exposure variable like a collider changes the causal estimation by introducing bias.\n*   **E:** This is incorrect. Collider bias is a general principle of causal graphs and is not limited to continuous variables. It applies equally to discrete or categorical variables.\n\nTherefore, statement A provides the correct explanation for the induced bias.", "answer": "$$\\boxed{A}$$", "id": "4866442"}]}