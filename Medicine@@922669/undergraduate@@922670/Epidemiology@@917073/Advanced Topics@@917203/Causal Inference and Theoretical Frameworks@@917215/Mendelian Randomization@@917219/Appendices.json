{"hands_on_practices": [{"introduction": "Mendelian randomization begins with a simple, powerful idea: estimating a causal effect by relating a gene's effect on an exposure to its effect on an outcome. This exercise [@problem_id:4611689] provides a hands-on opportunity to perform the most fundamental calculation in two-sample MR, the Wald ratio. By working through this problem, you will learn how to compute the causal effect estimate from summary statistics and assess its statistical significance, forming the bedrock of your understanding for all MR analyses.", "problem": "A single genetic variant is proposed as an instrumental variable for a continuous exposure in a two-sample Mendelian randomization (MR) analysis. Assume the standard instrumental variable conditions hold: relevance (the genetic variant affects the exposure), independence (the genetic variant is independent of confounders of the exposure-outcome relationship), and exclusion restriction (the genetic variant affects the outcome only through the exposure). In a large sample from Study A, a linear regression of the exposure on the genetic variant yields a summary association estimate $\\hat{\\beta}_{XG}$ with standard error $SE(\\hat{\\beta}_{XG})$. In an independent large sample from Study B, a logistic regression of the binary outcome on the same genetic variant yields a log-odds association estimate $\\hat{\\beta}_{YG}$ with standard error $SE(\\hat{\\beta}_{YG})$. Treat the two samples as independent and interpret the effect of the genetic variant on the outcome on the log-odds scale.\n\nYou are given the following summary statistics:\n- Study A: $\\hat{\\beta}_{XG} = 0.08$ and $SE(\\hat{\\beta}_{XG}) = 0.01$.\n- Study B: $\\hat{\\beta}_{YG} = 0.024$ and $SE(\\hat{\\beta}_{YG}) = 0.006$.\n\nUsing the core instrumental variable identity that under these assumptions the causal effect equals the ratio of the genetic association with the outcome to the genetic association with the exposure, construct the ratio estimator for the causal log-odds effect of the exposure on the outcome. Then, using a first-order Taylor series (delta method) approximation for a smooth function of independent estimates, derive the approximate standard error of the ratio estimator. Finally, compute the Wald test statistic $z = \\hat{\\beta}_{W} / SE(\\hat{\\beta}_{W})$ for testing the null hypothesis that the causal effect is zero.\n\nReport only the value of $z$, rounded to four significant figures. Do not include any units in your final answer.", "solution": "The user wants to compute the Wald test statistic for a causal effect estimated using two-sample Mendelian randomization (MR).\n\n### Step 1: Problem Validation\nThe problem statement is validated according to the specified criteria.\n\n**1. Extract Givens:**\n- A single genetic variant is an instrumental variable (IV) for a continuous exposure ($X$) and a binary outcome ($Y$).\n- The three core IV assumptions (relevance, independence, exclusion restriction) are assumed to hold.\n- The analysis is a two-sample MR, with estimates from two independent studies.\n- Study A (exposure sample):\n    - Genetic association with exposure: $\\hat{\\beta}_{XG} = 0.08$.\n    - Standard error of the association: $SE(\\hat{\\beta}_{XG}) = 0.01$.\n- Study B (outcome sample):\n    - Genetic association with the log-odds of the outcome: $\\hat{\\beta}_{YG} = 0.024$.\n    - Standard error of the association: $SE(\\hat{\\beta}_{YG}) = 0.006$.\n- The task is to compute the Wald test statistic $z = \\hat{\\beta}_{W} / SE(\\hat{\\beta}_{W})$ for the null hypothesis of no causal effect, where $\\hat{\\beta}_{W}$ is the ratio estimator of the causal effect.\n\n**2. Validate Using Extracted Givens:**\n- **Scientifically Grounded:** The problem describes a standard two-sample Mendelian randomization analysis, a widely used and validated method in epidemiology. The instrumental variable assumptions, the ratio estimator, and the use of the delta method are all core components of this methodology.\n- **Well-Posed:** The problem provides all necessary data and clearly specifies the methods to be used (ratio estimation, delta method) to compute a single, well-defined quantity (the Wald statistic).\n- **Objective:** The problem is stated using precise, quantitative, and objective language.\n\n**3. Verdict and Action:**\nThe problem is scientifically sound, well-posed, objective, and complete. It is therefore deemed **valid**. The solution will now be constructed.\n\n### Step 2: Solution\nThe causal effect of the exposure $X$ on the log-odds of the outcome $Y$ is denoted by $\\beta_W$. Under the instrumental variable assumptions, the genetic association with the outcome ($\\beta_{YG}$) is the product of the causal effect and the genetic association with the exposure ($\\beta_{XG}$):\n$$ \\beta_{YG} = \\beta_W \\cdot \\beta_{XG} $$\nThe ratio estimator, also known as the Wald estimator, for the causal effect is therefore given by the ratio of the two association estimates:\n$$ \\hat{\\beta}_W = \\frac{\\hat{\\beta}_{YG}}{\\hat{\\beta}_{XG}} $$\nUsing the provided values, we can compute the point estimate of the causal effect:\n$$ \\hat{\\beta}_W = \\frac{0.024}{0.08} = 0.3 $$\nThis value represents an estimated increase of $0.3$ in the log-odds of the outcome for each one-unit increase in the exposure.\n\nTo construct the Wald test statistic, we need the standard error of this estimator, $SE(\\hat{\\beta}_W)$. The problem specifies using a first-order Taylor series approximation (the delta method) to find this. Let our estimator be a function of two random variables, $f(x, y) = y/x$, where $x = \\hat{\\beta}_{XG}$ and $y = \\hat{\\beta}_{YG}$. The variance of this function can be approximated as:\n$$ \\text{Var}(f(x, y)) \\approx \\left(\\frac{\\partial f}{\\partial x}\\right)^2 \\text{Var}(x) + \\left(\\frac{\\partial f}{\\partial y}\\right)^2 \\text{Var}(y) + 2 \\left(\\frac{\\partial f}{\\partial x}\\right) \\left(\\frac{\\partial f}{\\partial y}\\right) \\text{Cov}(x, y) $$\nThe partial derivatives of $f(x, y)$ are:\n$$ \\frac{\\partial f}{\\partial x} = -\\frac{y}{x^2} \\quad \\text{and} \\quad \\frac{\\partial f}{\\partial y} = \\frac{1}{x} $$\nSince the estimates $\\hat{\\beta}_{XG}$ and $\\hat{\\beta}_{YG}$ come from two independent samples, their covariance is zero, i.e., $\\text{Cov}(\\hat{\\beta}_{XG}, \\hat{\\beta}_{YG}) = 0$. The variance formula simplifies to:\n$$ \\text{Var}(\\hat{\\beta}_W) \\approx \\left(-\\frac{\\hat{\\beta}_{YG}}{\\hat{\\beta}_{XG}^2}\\right)^2 \\text{Var}(\\hat{\\beta}_{XG}) + \\left(\\frac{1}{\\hat{\\beta}_{XG}}\\right)^2 \\text{Var}(\\hat{\\beta}_{YG}) $$\nThe variance of an estimate is the square of its standard error, so $\\text{Var}(\\hat{\\beta}) = [SE(\\hat{\\beta})]^2$. Substituting this relationship into the formula gives the expression for the squared standard error of the causal effect estimate:\n$$ [SE(\\hat{\\beta}_W)]^2 \\approx \\frac{\\hat{\\beta}_{YG}^2}{\\hat{\\beta}_{XG}^4} [SE(\\hat{\\beta}_{XG})]^2 + \\frac{1}{\\hat{\\beta}_{XG}^2} [SE(\\hat{\\beta}_{YG})]^2 $$\nNow we substitute the given numerical values:\n- $\\hat{\\beta}_{XG} = 0.08$\n- $SE(\\hat{\\beta}_{XG}) = 0.01$\n- $\\hat{\\beta}_{YG} = 0.024$\n- $SE(\\hat{\\beta}_{YG}) = 0.006$\n\n$$ [SE(\\hat{\\beta}_W)]^2 \\approx \\frac{(0.024)^2}{(0.08)^4} (0.01)^2 + \\frac{1}{(0.08)^2} (0.006)^2 $$\n$$ [SE(\\hat{\\beta}_W)]^2 \\approx \\frac{0.000576}{0.00004096} (0.0001) + \\frac{1}{0.0064} (0.000036) $$\n$$ [SE(\\hat{\\beta}_W)]^2 \\approx (14.0625) \\times (0.0001) + (156.25) \\times (0.000036) $$\n$$ [SE(\\hat{\\beta}_W)]^2 \\approx 0.00140625 + 0.005625 $$\n$$ [SE(\\hat{\\beta}_W)]^2 \\approx 0.00703125 $$\nThe standard error is the square root of the variance:\n$$ SE(\\hat{\\beta}_W) = \\sqrt{0.00703125} \\approx 0.08385256... $$\nFinally, we compute the Wald test statistic, $z$, for the null hypothesis $H_0: \\beta_W = 0$:\n$$ z = \\frac{\\hat{\\beta}_W}{SE(\\hat{\\beta}_W)} $$\n$$ z = \\frac{0.3}{0.08385256...} \\approx 3.57770876... $$\nRounding to four significant figures, we get:\n$$ z \\approx 3.578 $$", "answer": "$$\\boxed{3.578}$$", "id": "4611689"}, {"introduction": "A Mendelian randomization study is only as reliable as the genetic instruments it employs. Before estimating a causal effect, we must ensure our instruments are sufficiently strong, meaning they have a robust association with the exposure. This practice [@problem_id:4611703] walks you through the crucial step of quantifying instrument strength by calculating the proportion of exposure variance ($R^2$) explained by a set of genetic variants, a direct test of the 'relevance' assumption.", "problem": "A researcher is conducting a Mendelian randomization analysis using multiple independent single nucleotide polymorphisms (SNPs) as instruments for a continuous exposure. The first-stage model is a linear regression of the exposure on each SNP coded additively as allele counts in $\\{0,1,2\\}$. Assume the following widely accepted facts hold:\n- Under Hardy–Weinberg equilibrium (HWE), if the effect allele frequency is $p$, then the additive genotype has variance $\\operatorname{Var}(G)=2p(1-p)$.\n- In a simple linear regression of a continuous exposure $X$ on a single regressor $G$, the proportion of variance in $X$ explained by $G$ is $R^{2}=\\operatorname{Var}\\left(\\mathbb{E}[X\\mid G]\\right)/\\operatorname{Var}(X)$.\n- When including multiple independent regressors $\\{G_{i}\\}$, the variance explained by their linear combination is the sum of the explained variances because covariances are zero.\n\nYou are given summary association estimates from a Genome-Wide Association Study (GWAS) of the exposure for $4$ independent SNPs. For SNP $i$, denote by $\\hat{\\beta}_{XG,i}$ the estimated per-allele association with the exposure and by $p_{i}$ the effect allele frequency. The exposure variance in the GWAS sample is $\\operatorname{Var}(X)=0.81$.\n\nData:\n- SNP A: $p_{A}=0.30$, $\\hat{\\beta}_{XG,A}=0.08$.\n- SNP B: $p_{B}=0.45$, $\\hat{\\beta}_{XG,B}=0.05$.\n- SNP C: $p_{C}=0.15$, $\\hat{\\beta}_{XG,C}=0.10$.\n- SNP D: $p_{D}=0.10$, $\\hat{\\beta}_{XG,D}=0.04$.\n\nTasks:\n1. Starting from the definitions above and without invoking any pre-stated target formula, derive a closed-form expression for the first-stage variance explained $R^{2}_{i}$ by a single SNP $i$ in terms of $p_{i}$, $\\hat{\\beta}_{XG,i}$, and $\\operatorname{Var}(X)$.\n2. Using the independence of the SNPs, generalize your expression to obtain the combined first-stage variance explained $R^{2}_{\\text{total}}$ by the instrument set $\\{\\text{A},\\text{B},\\text{C},\\text{D}\\}$.\n3. Compute $R^{2}_{\\text{total}}$ as a decimal. Round your final answer to $4$ significant figures. Express your answer as a pure number (unitless).", "solution": "The user has provided a problem in the field of genetic epidemiology, specifically concerning Mendelian randomization (MR). The task is to derive an expression for the variance in an exposure explained by genetic instruments and then to compute this value using provided summary statistics.\n\n### Problem Validation\n\nFirst, the problem statement must be validated for scientific soundness, clarity, and completeness.\n\n**Step 1: Extract Givens**\n-   The first-stage model is a linear regression of a continuous exposure $X$ on a single nucleotide polymorphism (SNP) $G_i$, where $G_i$ is coded additively as the number of effect alleles, taking values in $\\{0, 1, 2\\}$.\n-   Under Hardy-Weinberg equilibrium (HWE), the variance of an additive genotype $G$ is given by $\\operatorname{Var}(G)=2p(1-p)$, where $p$ is the effect allele frequency.\n-   The proportion of variance in $X$ explained by $G$, denoted $R^2$, is defined as $R^{2}=\\operatorname{Var}\\left(\\mathbb{E}[X\\mid G]\\right)/\\operatorname{Var}(X)$.\n-   For multiple independent SNPs $\\{G_i\\}$, the total variance explained is the sum of the variances explained by each SNP individually.\n-   The analysis involves $4$ independent SNPs: A, B, C, and D.\n-   For each SNP $i$, the per-allele association estimate is $\\hat{\\beta}_{XG,i}$ and the effect allele frequency is $p_i$.\n-   The variance of the exposure is $\\operatorname{Var}(X)=0.81$.\n-   Data provided:\n    -   SNP A: $p_{A}=0.30$, $\\hat{\\beta}_{XG,A}=0.08$.\n    -   SNP B: $p_{B}=0.45$, $\\hat{\\beta}_{XG,B}=0.05$.\n    -   SNP C: $p_{C}=0.15$, $\\hat{\\beta}_{XG,C}=0.10$.\n    -   SNP D: $p_{D}=0.10$, $\\hat{\\beta}_{XG,D}=0.04$.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem is firmly rooted in the established statistical and genetic principles underlying Mendelian randomization. The formula $\\operatorname{Var}(G)=2p(1-p)$ is a standard result for an additively coded SNP under HWE. The definition of $R^2$ is a fundamental concept in regression analysis. The method of combining explained variance from independent predictors is also standard. All concepts are central to the field of genetic epidemiology.\n-   **Well-Posed:** The problem is clearly structured into three tasks: derivation, generalization, and computation. The provided data are sufficient and necessary to complete all tasks. The question leads to a unique and meaningful solution.\n-   **Objective:** The problem is stated in precise, technical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, and objective. It meets all criteria for a valid problem. Therefore, a full solution will be provided.\n\n---\n\n### Solution Derivation and Calculation\n\n**Task 1: Derive a closed-form expression for $R^{2}_{i}$ for a single SNP.**\n\nThe first-stage model is a simple linear regression of the exposure $X$ on the genotype $G_i$ for a single SNP $i$. The conditional expectation of $X$ given $G_i$ is:\n$$\n\\mathbb{E}[X \\mid G_i] = \\alpha_i + \\beta_{XG,i} G_i\n$$\nwhere $\\beta_{XG,i}$ is the per-allele association of the SNP with the exposure.\n\nThe proportion of variance in $X$ explained by $G_i$, denoted $R^2_i$, is given by the definition:\n$$\nR^2_i = \\frac{\\operatorname{Var}(\\mathbb{E}[X \\mid G_i])}{\\operatorname{Var}(X)}\n$$\n\nWe need to find the variance of the conditional expectation, which is the numerator. Using the properties of variance, where $\\alpha_i$ and $\\beta_{XG,i}$ are considered fixed coefficients from the regression:\n$$\n\\operatorname{Var}(\\mathbb{E}[X \\mid G_i]) = \\operatorname{Var}(\\alpha_i + \\beta_{XG,i} G_i) = \\beta_{XG,i}^2 \\operatorname{Var}(G_i)\n$$\n\nThe problem states that under HWE, the variance of the additively coded genotype $G_i$ is:\n$$\n\\operatorname{Var}(G_i) = 2p_i(1-p_i)\n$$\nwhere $p_i$ is the effect allele frequency of SNP $i$.\n\nSubstituting this expression for $\\operatorname{Var}(G_i)$ into the equation for the variance of the conditional expectation, we get:\n$$\n\\operatorname{Var}(\\mathbb{E}[X \\mid G_i]) = \\beta_{XG,i}^2 [2p_i(1-p_i)]\n$$\n\nFinally, substituting this result back into the definition of $R^2_i$, we obtain the closed-form expression. In practice, we use the estimated coefficient $\\hat{\\beta}_{XG,i}$ from a GWAS, so the estimated variance explained is:\n$$\nR^2_i = \\frac{2p_i(1-p_i)\\hat{\\beta}_{XG,i}^2}{\\operatorname{Var}(X)}\n$$\nThis completes the first task.\n\n**Task 2: Generalize the expression for the combined first-stage variance explained $R^{2}_{\\text{total}}$.**\n\nThe problem states that the $4$ SNPs are independent. A key property of independent random variables is that the variance explained by a linear model containing them is the sum of the variances explained by each variable individually. Therefore, the total proportion of variance explained, $R^2_{\\text{total}}$, is the sum of the individual $R^2_i$ values for each SNP in the set $\\{\\text{A}, \\text{B}, \\text{C}, \\text{D}\\}$.\n$$\nR^2_{\\text{total}} = \\sum_{i \\in \\{\\text{A,B,C,D}\\}} R^2_i\n$$\n\nSubstituting the expression derived in Task 1:\n$$\nR^2_{\\text{total}} = \\sum_{i \\in \\{\\text{A,B,C,D}\\}} \\frac{2p_i(1-p_i)\\hat{\\beta}_{XG,i}^2}{\\operatorname{Var}(X)}\n$$\n\nSince $\\operatorname{Var}(X)$ and the factor of $2$ are common to all terms, we can write the expression as:\n$$\nR^2_{\\text{total}} = \\frac{2}{\\operatorname{Var}(X)} \\sum_{i \\in \\{\\text{A,B,C,D}\\}} p_i(1-p_i)\\hat{\\beta}_{XG,i}^2\n$$\nThis is the generalized expression for the combined variance explained.\n\n**Task 3: Compute $R^{2}_{\\text{total}}$ as a decimal rounded to 4 significant figures.**\n\nWe are given $\\operatorname{Var}(X) = 0.81$. We will now compute the term $p_i(1-p_i)\\hat{\\beta}_{XG,i}^2$ for each of the four SNPs.\n\n-   **SNP A:**\n    $p_A(1-p_A)\\hat{\\beta}_{XG,A}^2 = (0.30)(1-0.30)(0.08)^2 = (0.30)(0.70)(0.0064) = (0.21)(0.0064) = 0.001344$\n\n-   **SNP B:**\n    $p_B(1-p_B)\\hat{\\beta}_{XG,B}^2 = (0.45)(1-0.45)(0.05)^2 = (0.45)(0.55)(0.0025) = (0.2475)(0.0025) = 0.00061875$\n\n-   **SNP C:**\n    $p_C(1-p_C)\\hat{\\beta}_{XG,C}^2 = (0.15)(1-0.15)(0.10)^2 = (0.15)(0.85)(0.01) = (0.1275)(0.01) = 0.001275$\n\n-   **SNP D:**\n    $p_D(1-p_D)\\hat{\\beta}_{XG,D}^2 = (0.10)(1-0.10)(0.04)^2 = (0.10)(0.90)(0.0016) = (0.09)(0.0016) = 0.000144$\n\nNext, we sum these values:\n$$\n\\sum_{i} p_i(1-p_i)\\hat{\\beta}_{XG,i}^2 = 0.001344 + 0.00061875 + 0.001275 + 0.000144 = 0.00338175\n$$\n\nNow, we use the formula for $R^2_{\\text{total}}$:\n$$\nR^2_{\\text{total}} = \\frac{2}{\\operatorname{Var}(X)} \\sum_{i} p_i(1-p_i)\\hat{\\beta}_{XG,i}^2 = \\frac{2}{0.81} (0.00338175)\n$$\n$$\nR^2_{\\text{total}} = \\frac{0.0067635}{0.81} = 0.00835\n$$\nThe result is exactly $0.00835$. The problem requires rounding the final answer to $4$ significant figures. The non-zero significant figures are $8$, $3$, and $5$. To express this with four significant figures, we add a zero at the end.\n\n$R^2_{\\text{total}} \\approx 0.008350$.", "answer": "$$\n\\boxed{0.008350}\n$$", "id": "4611703"}, {"introduction": "Moving from a single instrument to a full suite of genetic variants unlocks powerful diagnostic capabilities in Mendelian randomization. This hands-on coding challenge [@problem_id:2404096] guides you through implementing the core statistical methods, like Inverse-Variance Weighted (IVW) and MR-Egger regression, that are used to analyze multiple instruments. You will generate the key numerical components for scatter and funnel plots, learning to visually and quantitatively inspect your data for heterogeneity and directional pleiotropy, which are critical for validating your causal conclusions.", "problem": "You are given summary association data from Genome-Wide Association Study (GWAS) instruments, each being a Single Nucleotide Polymorphism (SNP), in the setting of Mendelian randomization (MR). For each SNP, you have the association with an exposure, denoted $\\beta_{GX,i}$, and the association with an outcome, denoted $\\beta_{GY,i}$, together with the standard error of the outcome association $\\sigma_{GY,i}$. Assume the following fundamental base: (i) a linear causal model for the exposure–outcome relationship; (ii) instruments affect the outcome only through the exposure apart from any potential horizontal pleiotropy; (iii) sampling variability in $\\beta_{GY,i}$ is quantified by $\\sigma_{GY,i}$, and uncertainty in $\\beta_{GX,i}$ is negligible relative to $\\sigma_{GY,i}$ for the purpose of weighting; (iv) the causal effect is estimable by aggregating per-variant information using weighted least squares.\n\nYour task is to write a complete program that, for each test case described below, computes the numerical objects required to generate (a) a scatter plot of $\\beta_{GY}$ versus $\\beta_{GX}$ with both the intercept-constrained Inverse-Variance Weighted (IVW) regression line and the Mendelian randomization Egger (MR-Egger) regression line, and (b) a funnel plot of ratio estimates versus their standard errors to visually inspect for heterogeneity and pleiotropy. Instead of drawing any plot, your program must return the precise numerical quantities that define those plots.\n\nStarting only from the base principles above, implement the following computations for each test case:\n- Use weights $w_i$ defined by the inverse of the outcome variance, i.e., $w_i$ proportional to $1 / \\sigma_{GY,i}^2$.\n- Compute the intercept-constrained IVW estimate of the causal slope, by solving the weighted least squares problem with intercept fixed to zero that minimizes $\\sum_i w_i ( \\beta_{GY,i} - b \\, \\beta_{GX,i} )^2$ over $b$.\n- Compute the MR-Egger weighted regression line with an unconstrained intercept, by minimizing $\\sum_i w_i ( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} )^2$ over $a$ and $b$.\n- Compute Cochran’s $Q$ statistic for heterogeneity under the IVW fit and the corresponding $I^2$ heterogeneity metric, where $Q$ compares the dispersion of the weighted residuals to their expected value under homogeneity.\n- For the funnel plot, compute the per-variant ratio estimate $\\theta_i$ and its approximate standard error $s_i$ under the assumption that uncertainty in $\\beta_{GX,i}$ is negligible relative to $\\sigma_{GY,i}$. Then compute the pseudo $95\\%$ funnel bounds for each variant around the pooled IVW effect as $\\theta_{\\text{IVW}} \\pm 1.96 \\, s_i$.\n\nYour program must apply these computations to the following test suite. Each test case is defined by three lists of equal length: $\\beta_{GX}$, $\\beta_{GY}$, and $\\sigma_{GY}$.\n\nTest case A (happy path; consistent instruments):\n- $\\beta_{GX} = [\\, 0.08, \\, 0.12, \\, 0.10, \\, 0.15, \\, 0.07, \\, 0.11 \\,]$\n- $\\beta_{GY} = [\\, 0.040, \\, 0.060, \\, 0.051, \\, 0.072, \\, 0.033, \\, 0.057 \\,]$\n- $\\sigma_{GY} = [\\, 0.020, \\, 0.018, \\, 0.022, \\, 0.019, \\, 0.021, \\, 0.020 \\,]$\n\nTest case B (directional pleiotropy; nonzero intercept expected):\n- $\\beta_{GX} = [\\, 0.05, \\, -0.04, \\, 0.09, \\, 0.12, \\, 0.03, \\, 0.07 \\,]$\n- $\\beta_{GY} = [\\, 0.037, \\, 0.007, \\, 0.048, \\, 0.054, \\, 0.029, \\, 0.042 \\,]$\n- $\\sigma_{GY} = [\\, 0.020, \\, 0.021, \\, 0.019, \\, 0.018, \\, 0.022, \\, 0.020 \\,]$\n\nTest case C (heterogeneity and a weak instrument):\n- $\\beta_{GX} = [\\, 0.20, \\, 0.15, \\, 0.10, \\, 0.05, \\, 0.004 \\,]$\n- $\\beta_{GY} = [\\, 0.080, \\, 0.070, \\, 0.045, \\, 0.050, \\, 0.010 \\,]$\n- $\\sigma_{GY} = [\\, 0.015, \\, 0.015, \\, 0.016, \\, 0.020, \\, 0.020 \\,]$\n\nTest case D (balanced pleiotropy; heterogeneity with approximately zero intercept):\n- $\\beta_{GX} = [\\, 0.10, \\, 0.12, \\, 0.09, \\, 0.11, \\, 0.08 \\,]$\n- $\\beta_{GY} = [\\, 0.080, \\, 0.052, \\, 0.064, \\, 0.056, \\, 0.048 \\,]$\n- $\\sigma_{GY} = [\\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020, \\, 0.020 \\,]$\n\nImplementation and numerical requirements:\n- Treat all weights as $w_i = 1 / \\sigma_{GY,i}^2$.\n- For the funnel plot, compute $\\theta_i = \\beta_{GY,i} / \\beta_{GX,i}$ and $s_i = \\sigma_{GY,i} / |\\beta_{GX,i}|$.\n- Use the IVW slope for the pooled effect in the funnel plot bounds $\\theta_{\\text{IVW}} \\pm 1.96 \\, s_i$.\n- For Cochran’s heterogeneity statistic under the IVW fit, compute $Q$ and then $I^2 = \\max(0, \\frac{Q - (M - 1)}{Q})$ with $M$ the number of variants. If $Q = 0$, set $I^2 = 0$.\n- Your program must output, for each test case, a list of nine elements in the following order:\n  1. the IVW slope (a float),\n  2. the MR-Egger slope (a float),\n  3. the MR-Egger intercept (a float),\n  4. the IVW Cochran’s $Q$ (a float),\n  5. the IVW $I^2$ (a float),\n  6. the list of ratio estimates $[\\theta_i]$,\n  7. the list of ratio standard errors $[s_i]$,\n  8. the list of lower funnel bounds $[\\theta_{\\text{IVW}} - 1.96 \\, s_i]$,\n  9. the list of upper funnel bounds $[\\theta_{\\text{IVW}} + 1.96 \\, s_i]$.\n- Express all floats rounded to six decimal places.\n- Final output format: Your program should produce a single line of output containing the four per-test-case results aggregated as a comma-separated list enclosed in square brackets, with no spaces. That is, a single line of the form $[r_A, r_B, r_C, r_D]$ where each $r_\\cdot$ is the nine-element list described above.\n\nEdge conditions and scientific realism:\n- Enforce that $|\\beta_{GX,i}|$ is not zero to avoid division by zero in ratio computations. The provided test suite satisfies this; in general, if any $|\\beta_{GX,i}|$ were below a small threshold $\\varepsilon$, the variant should be excluded from the ratio and funnel components while remaining consistent in regression fits if handled appropriately. In this test suite, no exclusions are necessary.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the established principles of Mendelian randomization (MR), a standard method in genetic epidemiology. The problem is well-posed, providing all necessary data and explicit mathematical definitions for the required computations. The language is objective and formal, free of ambiguity or subjective claims. It presents a solvable computational task based on verifiable statistical and mathematical principles.\n\nWe will now proceed with a systematic derivation of the required quantities. The context is the estimation of a causal effect of an exposure on an outcome using genetic variants as instrumental variables. For each of $M$ genetic variants (SNPs), we are given its estimated association with the exposure, $\\beta_{GX,i}$, its estimated association with the outcome, $\\beta_{GY,i}$, and the standard error of the latter, $\\sigma_{GY,i}$.\n\nThe weights for all weighted calculations are defined by the inverse of the outcome variance, assuming uncertainty in $\\beta_{GX,i}$ is negligible for this purpose:\n$$\nw_i = \\frac{1}{\\sigma_{GY,i}^2}\n$$\n\n**1. Intercept-Constrained Inverse-Variance Weighted (IVW) Slope**\n\nThe IVW method estimates the causal effect, $b$, by solving a weighted least squares problem that forces the regression line through the origin. This corresponds to the assumption of no horizontal pleiotropy. The objective is to minimize the sum of weighted squared residuals:\n$$\nS(b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right)^2\n$$\nTo find the minimum, we set the derivative with respect to $b$ to zero:\n$$\n\\frac{dS}{db} = -2 \\sum_{i=1}^{M} w_i \\beta_{GX,i} \\left( \\beta_{GY,i} - b \\, \\beta_{GX,i} \\right) = 0\n$$\nSolving for $b$ yields the IVW estimate, which we denote $\\theta_{\\text{IVW}}$:\n$$\n\\theta_{\\text{IVW}} = \\frac{\\sum_{i=1}^{M} w_i \\beta_{GX,i} \\beta_{GY,i}}{\\sum_{i=1}^{M} w_i \\beta_{GX,i}^2}\n$$\n\n**2. Mendelian Randomization Egger (MR-Egger) Regression**\n\nThe MR-Egger method relaxes the no-pleiotropy assumption of the IVW method by allowing for a non-zero intercept in the regression of $\\beta_{GY,i}$ on $\\beta_{GX,i}$. The intercept, $a$, can be interpreted as an estimate of the average directional pleiotropic effect, while the slope, $b$, remains the estimate of the causal effect. We minimize the following objective function over both $a$ and $b$:\n$$\nS(a, b) = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - a - b \\, \\beta_{GX,i} \\right)^2\n$$\nThis is a standard weighted linear regression problem. The solutions for the MR-Egger slope ($b_{\\text{Egger}}$) and intercept ($a_{\\text{Egger}}$) are given by the normal equations:\n$$\nb_{\\text{Egger}} = \\frac{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i} \\beta_{GY,i}\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right) \\left(\\sum w_i \\beta_{GY,i}\\right) }{ \\left(\\sum w_i\\right) \\left(\\sum w_i \\beta_{GX,i}^2\\right) - \\left(\\sum w_i \\beta_{GX,i}\\right)^2 }\n$$\n$$\na_{\\text{Egger}} = \\frac{\\sum w_i \\beta_{GY,i}}{\\sum w_i} - b_{\\text{Egger}} \\frac{\\sum w_i \\beta_{GX,i}}{\\sum w_i}\n$$\nThese formulas correspond to the standard solution for weighted least squares regression coefficients.\n\n**3. Cochran’s Q Statistic and I² Heterogeneity Metric**\n\nHeterogeneity among the instrument-specific causal estimates can indicate either violation of the MR assumptions (such as pleiotropy) or that the true causal effect differs for subsets of the population targeted by different instruments. Cochran’s $Q$ statistic for the IVW model quantifies this heterogeneity by summing the weighted squared differences between the individual ratio estimates and the pooled IVW estimate. It is calculated as:\n$$\nQ = \\sum_{i=1}^{M} w_i \\left( \\frac{\\beta_{GY,i}}{\\beta_{GX,i}} - \\theta_{\\text{IVW}} \\right)^2 \\beta_{GX,i}^2 = \\sum_{i=1}^{M} w_i \\left( \\beta_{GY,i} - \\theta_{\\text{IVW}} \\beta_{GX,i} \\right)^2\n$$\nUnder the null hypothesis of homogeneity (i.e., all instruments estimate the same causal effect), $Q$ follows a chi-squared distribution with $M-1$ degrees of freedom.\n\nThe $I^2$ statistic describes the percentage of variation across instruments that is due to heterogeneity rather than sampling error. It is derived from $Q$:\n$$\nI^2 = \\max\\left(0, \\frac{Q - (M-1)}{Q}\\right)\n$$\nIf $Q=0$, which is highly unlikely in practice, $I^2$ is defined as $0$.\n\n**4. Funnel Plot Components**\n\nA funnel plot is a visual tool to investigate heterogeneity and publication bias. It plots the effect size of each instrument against a measure of its precision.\n\n-   **Per-variant ratio estimate ($\\theta_i$):** This is the causal effect estimated from a single instrument $i$:\n    $$\n    \\theta_i = \\frac{\\beta_{GY,i}}{\\beta_{GX,i}}\n    $$\n-   **Standard error of the ratio estimate ($s_i$):** Using the delta method and the assumption that $\\beta_{GX,i}$ is measured with negligible error, the standard error of $\\theta_i$ is approximated as:\n    $$\n    s_i = \\text{SE}(\\theta_i) \\approx \\frac{\\sigma_{GY,i}}{\\lvert \\beta_{GX,i} \\rvert}\n    $$\n-   **Funnel plot bounds:** The funnel is constructed around the pooled IVW causal estimate, $\\theta_{\\text{IVW}}$. For a pseudo $95\\%$ confidence interval, the bounds for each variant $i$ are:\n    $$\n    \\text{Bounds}_i = \\theta_{\\text{IVW}} \\pm 1.96 \\, s_i\n    $$\n    The lower and upper bounds are $\\theta_{\\text{IVW}} - 1.96 \\, s_i$ and $\\theta_{\\text{IVW}} + 1.96 \\, s_i$, respectively.\n\nThe implementation will compute these nine quantities for each provided test case: the IVW slope, the MR-Egger slope and intercept, the Cochran's $Q$ and $I^2$ statistics for the IVW fit, and the lists of ratio estimates, their standard errors, and the corresponding lower and upper funnel bounds. All floating-point numbers will be rounded to six decimal places as required.", "answer": "```python\nimport numpy as np\n\ndef calculate_mr_metrics(beta_gx: list[float], beta_gy: list[float], sigma_gy: list[float]) -> list:\n    \"\"\"\n    Computes Mendelian randomization metrics for a given set of summary statistics.\n\n    Args:\n        beta_gx: List of SNP-exposure associations.\n        beta_gy: List of SNP-outcome associations.\n        sigma_gy: List of standard errors for SNP-outcome associations.\n\n    Returns:\n        A list containing nine elements as specified in the problem description.\n    \"\"\"\n    # Convert lists to NumPy arrays for vectorized operations\n    bgx = np.array(beta_gx)\n    bgy = np.array(beta_gy)\n    sgy = np.array(sigma_gy)\n    \n    # 1. Weights\n    # w_i = 1 / sigma_GY,i^2\n    w = 1.0 / (sgy**2)\n    \n    # 2. IVW Slope (Intercept-constrained)\n    # theta_ivw = (sum w_i * beta_gx_i * beta_gy_i) / (sum w_i * beta_gx_i^2)\n    ivw_numerator = np.sum(w * bgx * bgy)\n    ivw_denominator = np.sum(w * bgx**2)\n    ivw_slope = ivw_numerator / ivw_denominator\n    \n    # 3. MR-Egger Slope and Intercept\n    # Weighted least squares regression of bgy on bgx with weights w\n    W = np.sum(w)\n    Swx = np.sum(w * bgx)\n    Swy = np.sum(w * bgy)\n    Swxx = np.sum(w * bgx**2)\n    Swxy = np.sum(w * bgx * bgy)\n    \n    egger_denominator = (W * Swxx - Swx**2)\n    if egger_denominator == 0:\n        # This case is unlikely with real data but handle for robustness\n        mr_egger_slope = np.nan\n        mr_egger_intercept = np.nan\n    else:\n        mr_egger_slope = (W * Swxy - Swx * Swy) / egger_denominator\n        mr_egger_intercept = (Swy / W) - mr_egger_slope * (Swx / W)\n\n    # 4. Cochran's Q for IVW\n    # Q = sum w_i * (beta_gy_i - theta_ivw * beta_gx_i)^2\n    cochran_q = np.sum(w * (bgy - ivw_slope * bgx)**2)\n    \n    # 5. I^2 for IVW\n    M = len(bgx)\n    df = M - 1\n    if cochran_q == 0:\n        i_squared = 0.0\n    else:\n        i_squared = max(0.0, (cochran_q - df) / cochran_q)\n\n    # 6. Ratio estimates (theta_i)\n    # theta_i = beta_gy_i / beta_gx_i\n    theta_i = bgy / bgx\n    \n    # 7. Ratio standard errors (s_i)\n    # s_i = sigma_gy_i / |beta_gx_i|\n    s_i = sgy / np.abs(bgx)\n    \n    # 8.  9. Funnel plot bounds\n    # lower/upper = theta_ivw +/- 1.96 * s_i\n    z_score = 1.96\n    funnel_lower_bounds = ivw_slope - z_score * s_i\n    funnel_upper_bounds = ivw_slope + z_score * s_i\n    \n    # Assemble results and round to 6 decimal places\n    results = [\n        round(ivw_slope, 6),\n        round(mr_egger_slope, 6),\n        round(mr_egger_intercept, 6),\n        round(cochran_q, 6),\n        round(i_squared, 6),\n        [round(val, 6) for val in theta_i],\n        [round(val, 6) for val in s_i],\n        [round(val, 6) for val in funnel_lower_bounds],\n        [round(val, 6) for val in funnel_upper_bounds],\n    ]\n    \n    return results\n\ndef format_result_list(res_list: list) -> str:\n    \"\"\"Formats a single test case result list into the required string format.\"\"\"\n    str_parts = []\n    for item in res_list:\n        if isinstance(item, list):\n            formatted_list = f\"[{','.join([f'{x:.6f}' for x in item])}]\"\n            str_parts.append(formatted_list)\n        else:\n            str_parts.append(f\"{item:.6f}\")\n    return f\"[{','.join(str_parts)}]\"\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = {\n        'A': {\n            \"beta_gx\": [0.08, 0.12, 0.10, 0.15, 0.07, 0.11],\n            \"beta_gy\": [0.040, 0.060, 0.051, 0.072, 0.033, 0.057],\n            \"sigma_gy\": [0.020, 0.018, 0.022, 0.019, 0.021, 0.020]\n        },\n        'B': {\n            \"beta_gx\": [0.05, -0.04, 0.09, 0.12, 0.03, 0.07],\n            \"beta_gy\": [0.037, 0.007, 0.048, 0.054, 0.029, 0.042],\n            \"sigma_gy\": [0.020, 0.021, 0.019, 0.018, 0.022, 0.020]\n        },\n        'C': {\n            \"beta_gx\": [0.20, 0.15, 0.10, 0.05, 0.004],\n            \"beta_gy\": [0.080, 0.070, 0.045, 0.050, 0.010],\n            \"sigma_gy\": [0.015, 0.015, 0.016, 0.020, 0.020]\n        },\n        'D': {\n            \"beta_gx\": [0.10, 0.12, 0.09, 0.11, 0.08],\n            \"beta_gy\": [0.080, 0.052, 0.064, 0.056, 0.048],\n            \"sigma_gy\": [0.020, 0.020, 0.020, 0.020, 0.020]\n        }\n    }\n\n    all_results_str = []\n    # Process cases in alphabetical order to match output format\n    for key in sorted(test_cases.keys()):\n        case = test_cases[key]\n        result = calculate_mr_metrics(case[\"beta_gx\"], case[\"beta_gy\"], case[\"sigma_gy\"])\n        all_results_str.append(format_result_list(result))\n\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```", "id": "2404096"}]}