{"hands_on_practices": [{"introduction": "Sir Austin Bradford Hill's first guideline for causal inference is \"Strength.\" This practice [@problem_id:4574269] provides a foundational exercise in quantifying this concept by calculating the key epidemiological measures of association—the Risk Difference ($RD$), Risk Ratio ($RR$), and Odds Ratio ($OR$)—from raw data. By engaging with these calculations, you will learn to interpret the magnitude of an association on different scales and critically evaluate which measure provides the most stable evidence for causality when baseline risks are not uniform.", "problem": "A cohort study of an exposure and a dichotomous outcome is summarized by a $2\\times 2$ table with cell counts as follows: exposed cases $=120$, exposed noncases $=480$, unexposed cases $=30$, unexposed noncases $=570$. Starting from the foundational epidemiologic definitions that risk is the probability of the outcome within a group and odds is the ratio of the probability of the outcome to the probability of no outcome, derive and compute the Risk Difference (RD), the Risk Ratio (RR), and the Odds Ratio (OR) using only these counts. Then, interpret the Bradford Hill guideline of “strength” of association on each scale in terms of what each magnitude implies about the plausibility of a causal effect, and argue which scale is most diagnostic of causality when baseline risk varies across subpopulations.\n\nRound each computed metric ($RD$, $RR$, and $OR$) to four significant figures. Express $RD$ as a decimal fraction (e.g., $0.05$) without a percentage sign, and express $RR$ and $OR$ as unitless ratios. Provide the final numeric triplet in the order $RD$, $RR$, $OR$ as a single row matrix.", "solution": "The foundational quantities are derived from the $2\\times 2$ table counts. Let the exposed group have total $n_{1} = 120 + 480$ and the unexposed group have total $n_{0} = 30 + 570$. The risk in the exposed group, denoted $p_{1}$, is the probability of being a case among the exposed, computed as the number of exposed cases divided by the exposed total. Similarly, the risk in the unexposed group, denoted $p_{0}$, is the probability of being a case among the unexposed. The odds in each group are defined as the risk divided by one minus the risk.\n\nCompute the group totals:\n$$\nn_{1} = 120 + 480 = 600, \\quad n_{0} = 30 + 570 = 600.\n$$\nCompute the risks:\n$$\np_{1} = \\frac{120}{600} = 0.2, \\quad p_{0} = \\frac{30}{600} = 0.05.\n$$\nCompute the Risk Difference (RD):\n$$\nRD = p_{1} - p_{0} = 0.2 - 0.05 = 0.15.\n$$\nCompute the Risk Ratio (RR):\n$$\nRR = \\frac{p_{1}}{p_{0}} = \\frac{0.2}{0.05} = 4.\n$$\nCompute the odds in each group. The odds in the exposed group, $o_{1}$, are\n$$\no_{1} = \\frac{p_{1}}{1 - p_{1}} = \\frac{0.2}{0.8} = \\frac{120}{480} = 0.25,\n$$\nand the odds in the unexposed group, $o_{0}$, are\n$$\no_{0} = \\frac{p_{0}}{1 - p_{0}} = \\frac{0.05}{0.95} = \\frac{30}{570} = \\frac{1}{19} \\approx 0.0526315789.\n$$\nTherefore, the Odds Ratio (OR) is\n$$\nOR = \\frac{o_{1}}{o_{0}} = \\frac{0.25}{1/19} = 0.25 \\times 19 = \\frac{19}{4} = 4.75.\n$$\n\nRounding each metric to four significant figures gives:\n$$\nRD = 0.1500, \\quad RR = 4.000, \\quad OR = 4.750.\n$$\n\nInterpretation of “strength” under Bradford Hill’s guidelines centers on the magnitude of association and its implications for causal inference. A larger magnitude is less likely to be wholly explained by residual confounding or bias, though it is not definitive proof of causality. On the absolute scale, $RD = 0.15$ indicates an increase of $0.15$ in probability of the outcome attributable to exposure; given the baseline risk $p_{0} = 0.05$, this absolute difference is substantial in public health terms. On the relative scale, $RR = 4$ indicates that the risk among the exposed is quadruple that among the unexposed, a strong association. The $OR = 4.75$ similarly indicates a strong association but is numerically larger than the $RR$ because the outcome is not rare and the odds ratio diverges from the risk ratio as prevalence increases.\n\nRegarding which scale is most diagnostic of causality in the presence of baseline risk heterogeneity, it is crucial to consider how each measure behaves when baseline risk varies across subpopulations. The Risk Difference is highly sensitive to baseline risk: even under a constant multiplicative causal effect, $RD$ will vary with $p_{0}$, making comparisons across strata potentially misleading and providing less stable evidence for “strength” when baseline risks differ. The Odds Ratio is noncollapsible, meaning it can change with stratification even in the absence of confounding, and it tends to exaggerate the magnitude relative to the Risk Ratio as outcome prevalence rises, complicating interpretation across heterogeneous baselines. The Risk Ratio, by contrast, is collapsible and often more stable under multiplicative causal structures that are common in epidemiology; it provides a more interpretable and comparable measure of “strength” across strata when baseline risks vary. Thus, in the presence of baseline risk heterogeneity, the Risk Ratio is typically the most diagnostic scale for assessing the “strength” criterion in Bradford Hill’s framework, acknowledging that causal inference requires triangulation with other guidelines (such as temporality, dose-response, consistency, and specificity) and the elimination of alternative explanations.\n\nThe final numeric triplet in the order $RD$, $RR$, $OR$ is\n$$\n\\begin{pmatrix}\n0.1500  4.000  4.750\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0.1500  4.000  4.750\\end{pmatrix}}$$", "id": "4574269"}, {"introduction": "The \"Biological Gradient\" guideline suggests that if an association is causal, the risk of the outcome should increase with greater exposure. This hands-on practice [@problem_id:4574335] moves beyond simple association to formally test this dose-response relationship using the Cochran–Armitage test for trend. By working through this problem, you will gain practical skills in evaluating whether an observed monotonic increase in risk across exposure levels is statistically significant, thereby adding a more rigorous layer of evidence to your causal assessment.", "problem": "A cohort study examines an ordered categorical exposure divided into four quartiles corresponding to increasing dose. In each quartile, there are $n_{i} = 500$ participants, and the observed risks of a binary adverse outcome are $0.05$, $0.08$, $0.12$, and $0.20$, respectively, for $i = 1,2,3,4$. To formally assess the Bradford Hill guideline of a dose–response gradient, compute the standardized test statistic for the Cochran–Armitage test for trend (CATT) across the ordered quartiles, assuming equally spaced exposure scores $w_{i} = 1, 2, 3, 4$. Provide the exact closed-form analytical expression for the standardized statistic in simplest radicals. Then, based on first principles of hypothesis testing and the dose–response consideration in Bradford Hill’s guidelines for causal inference, interpret whether the observed gradient supports a causal relationship.\n\nExpress the final standardized Cochran–Armitage trend test statistic as an exact analytical expression. Do not round. No units are required.", "solution": "The Bradford Hill guidelines for causal inference include the dose–response (biological gradient) consideration: if risk increases monotonically with increasing exposure, this supports (but does not prove) causality. A statistically sound way to assess a monotonic gradient in a binary outcome across ordered exposure categories is the Cochran–Armitage test for trend (CATT), which tests the null hypothesis of no linear trend in outcome probability across scores assigned to ordered categories.\n\nFundamental base:\n- For each group $i$, the number of observed cases $x_{i}$ and total $n_{i}$ define the empirical risk $p_{i} = x_{i}/n_{i}$.\n- The pooled risk is $p = \\left(\\sum_{i=1}^{k} x_{i}\\right) / \\left(\\sum_{i=1}^{k} n_{i}\\right)$ for $k$ ordered groups.\n- With fixed scores $w_{i}$ on ordered groups, the CATT constructs a linear statistic\n$$\nT = \\sum_{i=1}^{k} w_{i} \\left(x_{i} - n_{i} p\\right),\n$$\nwhich, under the null of no linear trend, has variance\n$$\n\\operatorname{Var}(T) = p(1-p) \\sum_{i=1}^{k} n_{i} \\left(w_{i} - \\bar{w}\\right)^{2}, \\quad \\text{where} \\quad \\bar{w} = \\frac{\\sum_{i=1}^{k} n_{i} w_{i}}{\\sum_{i=1}^{k} n_{i}}.\n$$\nThe standardized test statistic is\n$$\nZ = \\frac{T}{\\sqrt{\\operatorname{Var}(T)}}.\n$$\n\nWe have $k = 4$ ordered quartiles with equal group sizes $n_{1} = n_{2} = n_{3} = n_{4} = 500$ and risks $p_{1} = 0.05$, $p_{2} = 0.08$, $p_{3} = 0.12$, $p_{4} = 0.20$. The exposure scores are equally spaced: $w_{1} = 1$, $w_{2} = 2$, $w_{3} = 3$, $w_{4} = 4$.\n\nCompute case counts from risks:\n$$\nx_{1} = 500 \\times 0.05 = 25, \\quad x_{2} = 500 \\times 0.08 = 40, \\quad x_{3} = 500 \\times 0.12 = 60, \\quad x_{4} = 500 \\times 0.20 = 100.\n$$\nTotal cases and total sample:\n$$\n\\sum_{i=1}^{4} x_{i} = 25 + 40 + 60 + 100 = 225, \\quad \\sum_{i=1}^{4} n_{i} = 4 \\times 500 = 2000.\n$$\nPooled risk:\n$$\np = \\frac{225}{2000} = \\frac{9}{80}.\n$$\nCompute the weighted mean of scores:\n$$\n\\bar{w} = \\frac{\\sum_{i=1}^{4} n_{i} w_{i}}{\\sum_{i=1}^{4} n_{i}} = \\frac{500(1+2+3+4)}{2000} = \\frac{500 \\times 10}{2000} = \\frac{5}{2}.\n$$\n\nCompute $T$:\nFirst, compute $n_{i} p$ for each group: $n_{i} p = 500 \\times \\frac{9}{80} = \\frac{500 \\times 9}{80} = \\frac{4500}{80} = \\frac{225}{4} = 56.25$.\nThus,\n$$\nx_{1} - n_{1} p = 25 - \\frac{225}{4} = -\\frac{125}{4}, \\quad\nx_{2} - n_{2} p = 40 - \\frac{225}{4} = -\\frac{65}{4}, \\quad\nx_{3} - n_{3} p = 60 - \\frac{225}{4} = \\frac{15}{4}, \\quad\nx_{4} - n_{4} p = 100 - \\frac{225}{4} = \\frac{175}{4}.\n$$\nMultiply by scores and sum:\n$$\nT = 1\\left(-\\frac{125}{4}\\right) + 2\\left(-\\frac{65}{4}\\right) + 3\\left(\\frac{15}{4}\\right) + 4\\left(\\frac{175}{4}\\right)\n= -\\frac{125}{4} - \\frac{130}{4} + \\frac{45}{4} + \\frac{700}{4}\n= \\frac{-125 - 130 + 45 + 700}{4}\n= \\frac{490}{4}\n= \\frac{245}{2}.\n$$\n\nCompute $\\operatorname{Var}(T)$:\nFirst compute the score deviations squared,\n$$\n(1 - \\tfrac{5}{2})^{2} = \\left(-\\tfrac{3}{2}\\right)^{2} = \\tfrac{9}{4}, \\quad\n(2 - \\tfrac{5}{2})^{2} = \\left(-\\tfrac{1}{2}\\right)^{2} = \\tfrac{1}{4}, \\quad\n(3 - \\tfrac{5}{2})^{2} = \\left(\\tfrac{1}{2}\\right)^{2} = \\tfrac{1}{4}, \\quad\n(4 - \\tfrac{5}{2})^{2} = \\left(\\tfrac{3}{2}\\right)^{2} = \\tfrac{9}{4}.\n$$\nSum weighted by equal $n_{i}$:\n$$\n\\sum_{i=1}^{4} n_{i} \\left(w_{i} - \\bar{w}\\right)^{2} = 500\\left(\\tfrac{9}{4} + \\tfrac{1}{4} + \\tfrac{1}{4} + \\tfrac{9}{4}\\right) = 500 \\times \\tfrac{20}{4} = 500 \\times 5 = 2500.\n$$\nCompute $p(1-p)$:\n$$\np(1-p) = \\frac{9}{80}\\left(1 - \\frac{9}{80}\\right) = \\frac{9}{80} \\cdot \\frac{71}{80} = \\frac{639}{6400}.\n$$\nTherefore,\n$$\n\\operatorname{Var}(T) = \\frac{639}{6400} \\times 2500 = \\frac{639 \\times 2500}{6400} = \\frac{639 \\times 25}{64} = \\frac{15975}{64}.\n$$\n\nStandardized statistic:\n$$\nZ = \\frac{T}{\\sqrt{\\operatorname{Var}(T)}} = \\frac{\\frac{245}{2}}{\\sqrt{\\frac{15975}{64}}} = \\frac{\\frac{245}{2}}{\\frac{\\sqrt{15975}}{8}} = \\frac{245}{2} \\cdot \\frac{8}{\\sqrt{15975}} = \\frac{980}{\\sqrt{15975}}.\n$$\nThis is the exact closed-form expression.\n\nInterpretation relative to Bradford Hill’s dose–response guideline:\nThe ordered risks $0.05, 0.08, 0.12, 0.20$ show a clear monotonic increase with exposure quartile. The large standardized trend statistic $Z = \\frac{980}{\\sqrt{15975}}$ corresponds to a very small two-sided tail probability under the standard normal approximation, indicating strong statistical evidence for a positive linear trend in outcome risk across exposure categories. This statistically significant monotonic gradient supports the biological gradient consideration in Bradford Hill’s guidelines, strengthening the case for a causal relationship between exposure and outcome. However, as with all Bradford Hill considerations, gradient alone does not establish causality; confounding, bias, and other alternative explanations must still be evaluated and ruled out.", "answer": "$$\\boxed{\\frac{980}{\\sqrt{15975}}}$$", "id": "4574335"}, {"introduction": "Perhaps the most compelling of the Bradford Hill guidelines is \"Experiment,\" where direct manipulation of the exposure provides the strongest evidence of causality. This exercise [@problem_id:4574333] introduces a powerful quasi-experimental technique—Instrumental Variable (IV) analysis—that allows us to emulate an experiment in an observational setting. You will calculate the Local Average Treatment Effect (LATE) to see how an external \"encouragement\" can help isolate a causal effect from confounding, providing a much stronger basis for inference than a simple observational comparison.", "problem": "Consider an observational cohort study in epidemiology evaluating the effect of a preventive exposure $A$ on a binary health outcome $Y$, where $Y=1$ denotes occurrence of the outcome within a fixed follow-up period. A binary encouragement $Z$ is implemented at some clinics (for example, default scheduling or cost-sharing removal) that increases the probability that individuals receive $A$. You are told that the data satisfy the standard instrumental variables conditions used in causal inference with instruments in epidemiology: relevance, independence, exclusion, and monotonicity. These conditions are: relevance ($E[A \\mid Z=1] \\neq E[A \\mid Z=0]$), independence ($Z$ is statistically independent of the joint distribution of potential outcomes and potential treatments), exclusion (the instrument affects the outcome only through the exposure), and monotonicity (no individual is less likely to be exposed when encouraged than when not encouraged). Assume these conditions hold and that the encouragement approximates random assignment, thereby invoking the spirit of Bradford Hill’s guidelines for causal inference, specifically the experiment guideline.\n\nYou are provided the following empirical summaries: $E[Y \\mid Z=1] = 0.12$, $E[Y \\mid Z=0] = 0.08$, $E[A \\mid Z=1] = 0.60$, and $E[A \\mid Z=0] = 0.30$.\n\nUsing only these summaries and first principles from the potential outcomes framework and instrumental variables logic, derive the estimand for the Local Average Treatment Effect (LATE) among compliers and compute its value. Express your final answer as a single number representing the risk difference in outcome probability due to exposure among compliers. You may provide an exact fraction. If you choose a decimal, round your answer to four significant figures. Do not use a percentage sign in your answer.\n\nAdditionally, briefly interpret whether the resulting causal estimate is more aligned with the Bradford Hill experiment guideline than a purely observational comparison of $E[Y \\mid A=1]$ versus $E[Y \\mid A=0]$ would be, and justify your reasoning from the instrumental variables assumptions and the potential outcomes framework. Your final reported answer must be the single numerical value of the LATE.", "solution": "The problem requires the derivation and computation of the Local Average Treatment Effect (LATE) using the provided empirical summaries and the standard assumptions of instrumental variable (IV) analysis within the potential outcomes framework.\n\nWe begin by formally defining the relevant quantities and assumptions. Let $Z_i \\in \\{0, 1\\}$ be the binary instrument (encouragement), $A_i \\in \\{0, 1\\}$ be the binary exposure, and $Y_i \\in \\{0, 1\\}$ be the binary outcome for an individual $i$. The potential outcomes framework defines $A_i(z)$ as the potential exposure status of individual $i$ if their instrument status were $z$, and $Y_i(a)$ as the potential outcome of individual $i$ if their exposure status were $a$. The latter definition, $Y_i(a)$, implicitly uses the exclusion restriction, which posits that the instrument $Z$ affects the outcome $Y$ only through the exposure $A$, i.e., $Y_i(z, a) = Y_i(a)$ for $z \\in \\{0, 1\\}$.\n\nThe monotonicity assumption, $A_i(1) \\ge A_i(0)$ for all $i$, rules out the existence of \"defiers\" (individuals for whom $A_i(1)=0$ and $A_i(0)=1$). This allows us to partition the population into three principal strata based on their potential exposure behavior:\n1.  **Compliers (C)**: Individuals for whom $A_i(1)=1$ and $A_i(0)=0$. They receive the exposure if and only if they are encouraged.\n2.  **Always-takers (AT)**: Individuals for whom $A_i(1)=1$ and $A_i(0)=1$. They always receive the exposure, regardless of encouragement.\n3.  **Never-takers (NT)**: Individuals for whom $A_i(1)=0$ and $A_i(0)=0$. They never receive the exposure, regardless of encouragement.\n\nThe estimand of interest is the LATE, which is the average causal effect of the exposure on the outcome for the subpopulation of compliers. It is formally defined as:\n$$ \\text{LATE} = E[Y_i(1) - Y_i(0) \\mid A_i(1)=1, A_i(0)=0] $$\nOur goal is to express this unobservable quantity in terms of the observable expectations provided: $E[Y \\mid Z=1]$, $E[Y \\mid Z=0]$, $E[A \\mid Z=1]$, and $E[A \\mid Z=0]$. This is achieved by analyzing the well-known IV or Wald estimand:\n$$ \\frac{E[Y \\mid Z=1] - E[Y \\mid Z=0]}{E[A \\mid Z=1] - E[A \\mid Z=0]} $$\n\nFirst, let us analyze the denominator, $E[A \\mid Z=1] - E[A \\mid Z=0]$. The observed exposure $A$ is determined by the instrument $Z$ and the individual's potential exposure type. Specifically, $A_i = A_i(Z_i)$. The term $E[A \\mid Z=z]$ is equivalent to $P(A=1 \\mid Z=z)$.\nUnder the independence assumption ($Z$ is independent of potential outcomes and types), we have $Z \\perp (A(1), A(0))$. Thus, conditioning on $Z$ does not alter the distribution of potential exposure types.\n$$ E[A \\mid Z=1] = P(A=1 \\mid Z=1) = P(A(1)=1) $$\nThe individuals for whom $A(1)=1$ are the compliers and the always-takers. Therefore:\n$$ E[A \\mid Z=1] = P(\\text{Compliers}) + P(\\text{Always-takers}) = P(C) + P(AT) $$\nSimilarly, for the unencouraged group:\n$$ E[A \\mid Z=0] = P(A=1 \\mid Z=0) = P(A(0)=1) $$\nThe only individuals for whom $A(0)=1$ are the always-takers. Therefore:\n$$ E[A \\mid Z=0] = P(\\text{Always-takers}) = P(AT) $$\nSubtracting the two expressions gives the proportion of compliers in the population:\n$$ E[A \\mid Z=1] - E[A \\mid Z=0] = (P(C) + P(AT)) - P(AT) = P(C) $$\n\nNext, we analyze the numerator, $E[Y \\mid Z=1] - E[Y \\mid Z=0]$. The observed outcome is $Y_i = Y_i(A_i(Z_i))$. We use the law of total expectation, stratifying by the principal strata.\n$$ E[Y \\mid Z=1] = E[Y(A(1))] $$\nThis step uses the independence assumption $Z \\perp (Y(a), A(z))$. We expand over the strata:\n$$ E[Y(A(1))] = E[Y(A(1)) \\mid C]P(C) + E[Y(A(1)) \\mid AT]P(AT) + E[Y(A(1)) \\mid NT]P(NT) $$\nFor compliers, $A(1)=1$, so $E[Y(A(1)) \\mid C] = E[Y(1) \\mid C]$.\nFor always-takers, $A(1)=1$, so $E[Y(A(1)) \\mid AT] = E[Y(1) \\mid AT]$.\nFor never-takers, $A(1)=0$, so $E[Y(A(1)) \\mid NT] = E[Y(0) \\mid NT]$.\nSubstituting these in gives:\n$$ E[Y \\mid Z=1] = E[Y(1) \\mid C]P(C) + E[Y(1) \\mid AT]P(AT) + E[Y(0) \\mid NT]P(NT) $$\nSimilarly for the unencouraged group:\n$$ E[Y \\mid Z=0] = E[Y(A(0))] = E[Y(A(0)) \\mid C]P(C) + E[Y(A(0)) \\mid AT]P(AT) + E[Y(A(0)) \\mid NT]P(NT) $$\nFor compliers, $A(0)=0$, so $E[Y(A(0)) \\mid C] = E[Y(0) \\mid C]$.\nFor always-takers, $A(0)=1$, so $E[Y(A(0)) \\mid AT] = E[Y(1) \\mid AT]$.\nFor never-takers, $A(0)=0$, so $E[Y(A(0)) \\mid NT] = E[Y(0) \\mid NT]$.\nSubstituting these in gives:\n$$ E[Y \\mid Z=0] = E[Y(0) \\mid C]P(C) + E[Y(1) \\mid AT]P(AT) + E[Y(0) \\mid NT]P(NT) $$\nNow, we compute the difference in the numerator:\n$$ E[Y \\mid Z=1] - E[Y \\mid Z=0] = (E[Y(1) \\mid C]P(C) + E[Y(1) \\mid AT]P(AT) + E[Y(0) \\mid NT]P(NT)) - (E[Y(0) \\mid C]P(C) + E[Y(1) \\mid AT]P(AT) + E[Y(0) \\mid NT]P(NT)) $$\nThe terms for always-takers and never-takers cancel out, leaving:\n$$ E[Y \\mid Z=1] - E[Y \\mid Z=0] = E[Y(1) \\mid C]P(C) - E[Y(0) \\mid C]P(C) = (E[Y(1) - Y(0) \\mid C]) P(C) $$\nThe term $E[Y(1) - Y(0) \\mid C]$ is, by definition, the LATE. So, the numerator is LATE $\\times$ $P(C)$.\n\nCombining the results for the numerator and denominator:\n$$ \\text{LATE} = \\frac{E[Y \\mid Z=1] - E[Y \\mid Z=0]}{E[A \\mid Z=1] - E[A \\mid Z=0]} = \\frac{(\\text{LATE}) \\cdot P(C)}{P(C)} $$\nThis confirms that the IV estimand, under the stated assumptions, identifies the LATE.\n\nNow, we substitute the provided numerical values into the formula:\n$$ \\text{LATE} = \\frac{0.12 - 0.08}{0.60 - 0.30} = \\frac{0.04}{0.30} = \\frac{4}{30} = \\frac{2}{15} $$\nThe causal risk difference for compliers is $\\frac{2}{15}$, which is approximately $0.1333$. Since the risk difference is defined as the risk in the exposed minus the risk in the unexposed ($Y(1) - Y(0)$), this positive value indicates that the exposure *increases* the risk of the outcome by about 0.1333 for the subpopulation of compliers. This finding is contrary to the initial description of the exposure as \"preventive,\" highlighting that the data, not prior labels, must drive the causal conclusion.\n\nRegarding the Bradford Hill guidelines, the \"experiment\" criterion is considered the strongest form of evidence for causality. A purely observational comparison of exposed versus unexposed individuals, $E[Y \\mid A=1]$ versus $E[Y \\mid A=0]$, is notoriously susceptible to confounding. For instance, individuals who choose to receive exposure $A$ might be systematically different from those who do not in ways that independently affect outcome $Y$. This confounding breaks the link between the observed association and a true causal effect. The IV estimate of the LATE is far more aligned with the experiment guideline. The core of this alignment is the independence assumption, which posits that the instrument $Z$ is distributed independently of the factors that would otherwise confound the $A$-$Y$ relationship. This makes the instrument behave like a randomizer. By comparing the groups defined by $Z=1$ and $Z=0$, we leverage this \"as-if\" randomization to isolate a causal effect, mimicking what a true randomized controlled trial (RCT) of the encouragement would achieve. The LATE then scales this intention-to-treat effect on the encouragement to estimate the causal effect of the exposure itself for the specific subpopulation that responded to the encouragement (the compliers). Thus, while it's not a full-population causal effect, the LATE is a valid causal estimate, whereas the simple observational comparison is likely a biased, non-causal association.", "answer": "$$\\boxed{\\frac{2}{15}}$$", "id": "4574333"}]}