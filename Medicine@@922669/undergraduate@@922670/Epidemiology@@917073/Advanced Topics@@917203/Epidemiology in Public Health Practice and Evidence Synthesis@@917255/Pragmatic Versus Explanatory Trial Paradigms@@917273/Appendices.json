{"hands_on_practices": [{"introduction": "The first, and most critical, step in designing any trial is defining the causal question you want to answer. In pragmatic trials, the focus shifts from a treatment's pure biological efficacy to its real-world effectiveness when implemented as a policy. This exercise explores why the Intention-to-Treat (ITT) principle is the analytical cornerstone of pragmatic trials, as it directly evaluates the impact of the *assignment* to a treatment strategy, faithfully reflecting the realities of non-adherence and contamination. [@problem_id:4622860]", "problem": "A health system runs a pragmatic cluster-randomized trial to evaluate a new mobile application for hypertension self-management. Clinics are randomized to either offer the application with standard onboarding or continue usual care. Let $Z \\in \\{0,1\\}$ denote random assignment at the clinic level, with $Z=1$ for clinics assigned to offer the application and $Z=0$ for usual care. Let $A \\in \\{0,1\\}$ indicate whether an individual adheres to the application use protocol (defined as use on at least $80\\%$ of days during the first $6$ months), and let $Y$ be systolic blood pressure at $6$ months. In the trial, adherence is imperfect: in $Z=1$ clinics, about $45\\%$ of patients meet the adherence definition ($A=1$), while in $Z=0$ clinics, about $15\\%$ of patients independently adopt similar applications ($A=1$). The health system is considering two policies: Policy $P_1$ is to offer the application without enforcement, and Policy $P_2$ is to mandate use with monitoring and incentives sufficient to ensure near-perfect adherence (e.g., $A \\approx 1$ for all assigned).\n\nUsing the foundational epidemiologic definitions that (i) randomization of $Z$ ensures exchangeability for the potential outcomes $Y(1)$ and $Y(0)$ defined under assignment, (ii) the Intention-To-Treat (ITT) estimand is the causal effect of assignment, expressed as $E[Y \\mid Z=1] - E[Y \\mid Z=0]$, and (iii) per-protocol contrasts target the causal effect of the treatment strategy actually followed, expressed informally as a contrast of $Y$ under $A=1$ versus $A=0$, answer the following:\n\nWhich option best explains why ITT is typically favored in pragmatic trials and identifies conditions under which per-protocol analysis may be more policy-relevant?\n\nA. ITT is favored because randomization of $Z$ ensures exchangeability for $Y(1)$ and $Y(0)$, so $E[Y \\mid Z=1] - E[Y \\mid Z=0]$ answers the causal question for Policy $P_1$ (offer without enforcement) in the presence of real-world nonadherence and contamination. Per-protocol analyses condition on $A$, a post-randomization variable influenced by prognosis, and are generally biased unless adherence is randomized or fully controlled. Per-protocol becomes more policy-relevant when the policy itself enforces adherence (as in Policy $P_2$) and when adherence-induced selection can be treated as randomized or validly controlled by design or analysis.\n\nB. ITT is only preferred when contamination is $0\\%$; otherwise per-protocol is always more appropriate because it removes noise from nonadherence and estimates the biological efficacy of the application.\n\nC. ITT equals the complier average causal effect for any randomized trial and therefore is always unbiased for the effect in compliers; per-protocol is more policy-relevant whenever nonadherence exceeds $50\\%$.\n\nD. ITT is preferred when internal validity is the sole concern, but per-protocol is more policy-relevant in pragmatic trials whenever adherence rates are higher than $80\\%$ in the intervention clinics and lower than $20\\%$ in control clinics, regardless of how adherence is achieved.\n\nChoose the single best option.", "solution": "The problem statement describes a pragmatic cluster-randomized trial and asks for the best explanation of the role and preference for Intention-To-Treat (ITT) analysis versus per-protocol analysis in the context of specific policy questions.\n\n### Step 1: Extract Givens\n\n-   **Study Design**: Pragmatic cluster-randomized trial.\n-   **Randomization Unit**: Clinics.\n-   **Random Assignment Variable**: $Z \\in \\{0, 1\\}$, where $Z=1$ is assignment to offer a mobile application and $Z=0$ is assignment to usual care.\n-   **Adherence Variable**: $A \\in \\{0, 1\\}$, where $A=1$ indicates adherence (use on $\\geq 80\\%$ of days for the first $6$ months).\n-   **Outcome Variable**: $Y$, systolic blood pressure at $6$ months.\n-   **Observed Data**:\n    -   In clinics with $Z=1$, the proportion of patients with $A=1$ is approximately $45\\%$.\n    -   In clinics with $Z=0$, the proportion of patients with $A=1$ (contamination) is approximately $15\\%$.\n-   **Policies**:\n    -   Policy $P_1$: Offer the application without enforcement.\n    -   Policy $P_2$: Mandate use of the application with near-perfect adherence ($A \\approx 1$).\n-   **Provided Definitions**:\n    -   Randomization of $Z$ ensures exchangeability for potential outcomes $Y(1)$ and $Y(0)$ (potential outcomes under assignment $Z=1$ and $Z=0$, respectively).\n    -   ITT estimand: $E[Y \\mid Z=1] - E[Y \\mid Z=0]$. This is stated to be the causal effect of assignment.\n    -   Per-protocol contrast: An informal contrast of $Y$ under $A=1$ versus $A=0$, targeting the causal effect of the treatment strategy actually followed.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement provides a clear and standard scenario from the field of clinical epidemiology and causal inference. All terms ($Z, A, Y$, ITT, per-protocol, exchangeability, potential outcomes) are used consistently with their established scientific definitions. The scenario involving a pragmatic trial, non-adherence, contamination, and distinct policy questions ($P_1$ vs. $P_2$) is realistic and well-defined. The problem is scientifically grounded, well-posed, and objective. It does not violate any fundamental principles of logic or science, nor does it contain any of the flaws listed in the validation checklist. The problem is a valid conceptual question about the interpretation of trial results.\n\n### Step 3: Derivation and Option Analysis\n\nThe core of the problem lies in the distinction between two types of causal questions and the analyses that address them.\n\n1.  **The Pragmatic Question (Effect of Policy $P_1$)**: What is the effect of a policy of *offering* the intervention in a real-world setting? This setting includes whatever levels of non-adherence and contamination naturally occur. The Intention-To-Treat (ITT) analysis is designed to answer precisely this question. By comparing all individuals in the group assigned to the intervention ($Z=1$) with all individuals in the group assigned to control ($Z=0$), regardless of their actual behavior ($A$), the analysis preserves the balance created by randomization. Randomization ensures that the groups $Z=1$ and $Z=0$ are, on average, exchangeable with respect to all baseline characteristics (both measured and unmeasured). Therefore, the ITT estimand, $E[Y(1)] - E[Y(0)]$, which is unbiasedly estimated by the observed difference $E[Y \\mid Z=1] - E[Y \\mid Z=0]$, represents the causal effect of the assignment to treatment. This directly corresponds to the effect of implementing Policy $P_1$.\n\n2.  **The Explanatory Question (Effect of Policy $P_2$)**: What is the effect of *actually using* the intervention, assuming perfect adherence? This question is about the efficacy of the intervention if taken as prescribed. This aligns with the goal of Policy $P_2$, which seeks to enforce adherence. A naive per-protocol analysis attempts to answer this by comparing individuals who adhered ($A=1$) to those who did not ($A=0$). However, this comparison is almost always biased. The variable $A$ (adherence) is a post-randomization variable. The groups of people who choose to adhere versus not to adhere are likely different in ways that also affect the outcome $Y$ (e.g., motivation, baseline health status, health literacy). This is known as confounding by indication or selection bias. Comparing $E[Y \\mid A=1]$ to $E[Y \\mid A=0]$ does not yield a valid causal effect of the application itself because the groups are not exchangeable. For a per-protocol type of analysis to be valid and relevant to Policy $P_2$, one must either be in a situation where adherence is itself randomized (which is not the case here) or use advanced statistical methods (e.g., instrumental variable analysis, g-estimation) that rely on strong, untestable assumptions to control for the selection bias. The relevance of this type of effect is directly tied to a policy that would enforce adherence, like $P_2$.\n\nWith this foundation, we evaluate the options.\n\n**Option A: ITT is favored because randomization of $Z$ ensures exchangeability for $Y(1)$ and $Y(0)$, so $E[Y \\mid Z=1] - E[Y \\mid Z=0]$ answers the causal question for Policy $P_1$ (offer without enforcement) in the presence of real-world nonadherence and contamination. Per-protocol analyses condition on $A$, a post-randomization variable influenced by prognosis, and are generally biased unless adherence is randomized or fully controlled. Per-protocol becomes more policy-relevant when the policy itself enforces adherence (as in Policy $P_2$) and when adherence-induced selection can be treated as randomized or validly controlled by design or analysis.**\n\nThis option is a precise and comprehensive summary of the concepts.\n-   It correctly states that ITT is favored because it preserves the exchangeability guaranteed by randomization.\n-   It correctly links the ITT estimand to the pragmatic question about Policy $P_1$, acknowledging that it correctly accounts for non-adherence and contamination.\n-   It correctly identifies the fundamental flaw of naive per-protocol analysis: conditioning on a post-randomization variable ($A$) induces selection bias.\n-   It correctly identifies the specific scenario where a per-protocol-like effect is policy-relevant (Policy $P_2$) and correctly states the stringent conditions required for its valid estimation.\n**Verdict: Correct.**\n\n**Option B: ITT is only preferred when contamination is $0\\%$; otherwise per-protocol is always more appropriate because it removes noise from nonadherence and estimates the biological efficacy of the application.**\n\nThis option is incorrect on multiple grounds.\n-   ITT is preferred precisely *because* it can handle real-world issues like non-adherence and contamination in an unbiased way to answer a pragmatic question. Its value is not restricted to contamination-free scenarios.\n-   Claiming per-protocol is \"always more appropriate\" is false. It ignores the severe selection bias that typically invalidates naive per-protocol analyses. What it calls \"remov[ing] noise\" is more accurately described as \"introducing bias.\"\n**Verdict: Incorrect.**\n\n**Option C: ITT equals the complier average causal effect for any randomized trial and therefore is always unbiased for the effect in compliers; per-protocol is more policy-relevant whenever nonadherence exceeds $50\\%$.**\n\nThis option contains two major errors.\n-   The ITT effect is generally not equal to the Complier Average Causal Effect (CACE). Under the instrumental variable assumptions, the CACE is the ITT effect divided by the proportion of \"compliers\" (those who would take the treatment if and only if assigned to it). Here, the proportion of compliers can be estimated as $P(A=1|Z=1) - P(A=1|Z=0) = 0.45 - 0.15 = 0.30$, or $30\\%$. Since this is not $1$, the ITT effect does not equal the CACE.\n-   The relevance of a per-protocol analysis is not determined by an arbitrary threshold of non-adherence like $50\\%$. Its relevance is tied to the policy question. High non-adherence might make the selection bias problem in a per-protocol analysis even worse.\n**Verdict: Incorrect.**\n\n**Option D: ITT is preferred when internal validity is the sole concern, but per-protocol is more policy-relevant in pragmatic trials whenever adherence rates are higher than $80\\%$ in the intervention clinics and lower than $20\\%$ in control clinics, regardless of how adherence is achieved.**\n\nThis option is also flawed.\n-   The initial statement creates a false dichotomy. ITT has high internal validity, and its pragmatic nature makes it highly relevant for policy and external validity considerations.\n-   The introduction of arbitrary numerical thresholds ($>80\\%$ and $<20\\%$) for adherence is unprincipled. The validity of an analysis does not depend on hitting these specific numbers.\n-   The phrase \"regardless of how adherence is achieved\" is the most critical error. It explicitly ignores the mechanism of selection into adherence, which is the very source of bias that makes naive per-protocol analyses invalid.\n**Verdict: Incorrect.**\n\nBased on the analysis, Option A provides the most accurate and complete explanation of the roles and rationales for ITT and per-protocol analyses in the given context.", "answer": "$$\\boxed{A}$$", "id": "4622860"}, {"introduction": "To maximize real-world relevance, pragmatic trials are often implemented within existing structures like clinics, hospitals, or schools, making cluster randomization a practical and common design. However, individuals within the same cluster (e.g., patients at the same clinic) tend to be more similar to each other than to individuals in other clusters. This exercise guides you through the concept of the design effect, a crucial metric that quantifies how this intra-cluster correlation reduces a study's statistical precision compared to an individually randomized trial of the same size. [@problem_id:4622830]", "problem": "A public health team is planning a cluster randomized pragmatic trial across $C$ primary care clinics to evaluate a screening intervention, and they aim to compare its precision to that of an individually randomized explanatory trial with the same total number of enrolled individuals. Each clinic enrolls the same number of patients, $m$, and the outcome is a continuous variable with common variance $\\sigma^{2}$ across all individuals. The intra-cluster correlation coefficient (ICC) $\\rho$ is defined as the correlation between two outcomes from different individuals within the same clinic, and outcomes from different clinics are independent.\n\nStarting from the definitions of variance, covariance, and the intra-cluster correlation coefficient $\\rho$, derive the ratio of the variance of the overall sample mean under the cluster design to that under simple random sampling with independent individuals. Interpret this ratio as the design effect $DE$ in terms of $m$ and $\\rho$.\n\nThen, for $m=40$, $\\rho=0.01$, and a total enrollment of $N=800$ individuals across all clinics (so $N=C\\,m$), compute the numeric value of the design effect and determine the effective sample size $N_{\\mathrm{eff}}$ that would yield the same variance of the sample mean under individual randomization. Round $N_{\\mathrm{eff}}$ to three significant figures. If the design effect is a terminating decimal, report it exactly; otherwise round the design effect to four significant figures.\n\nProvide your final numeric values for $DE$ and $N_{\\mathrm{eff}}$ in that order.", "solution": "The problem is valid as it is scientifically grounded in the principles of biostatistics and epidemiology, well-posed with a clear objective and sufficient data, and objective in its formulation.\n\nLet $Y_{ij}$ denote the continuous outcome for the $j$-th individual within the $i$-th clinic, for $i \\in \\{1, 2, \\dots, C\\}$ and $j \\in \\{1, 2, \\dots, m\\}$. The total number of individuals is $N = C\\,m$.\n\nThe overall sample mean, $\\bar{Y}$, is given by:\n$$ \\bar{Y} = \\frac{1}{N} \\sum_{i=1}^{C} \\sum_{j=1}^{m} Y_{ij} $$\nThe variance of the sample mean under the cluster design, $\\mathrm{Var}_{\\mathrm{cluster}}(\\bar{Y})$, is:\n$$ \\mathrm{Var}_{\\mathrm{cluster}}(\\bar{Y}) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{C} \\sum_{j=1}^{m} Y_{ij}\\right) = \\frac{1}{N^2} \\mathrm{Var}\\left(\\sum_{i=1}^{C} \\sum_{j=1}^{m} Y_{ij}\\right) $$\nThe variance of a sum of random variables is the sum of all their pairwise covariances:\n$$ \\mathrm{Var}\\left(\\sum_{i=1}^{C} \\sum_{j=1}^{m} Y_{ij}\\right) = \\sum_{i=1}^{C} \\sum_{j=1}^{m} \\sum_{i'=1}^{C} \\sum_{j'=1}^{m} \\mathrm{Cov}(Y_{ij}, Y_{i'j'}) $$\nWe can partition this sum into three cases based on the problem's definitions:\n1.  When $i=i'$ and $j=j'$, the term is the variance of a single observation: $\\mathrm{Cov}(Y_{ij}, Y_{ij}) = \\mathrm{Var}(Y_{ij}) = \\sigma^2$. There are $N = C\\,m$ such terms.\n2.  When $i=i'$ but $j \\neq j'$, the individuals are from the same cluster. The covariance is defined by the intra-cluster correlation coefficient $\\rho$: $\\mathrm{Cov}(Y_{ij}, Y_{ij'}) = \\rho \\sigma^2$. For each of the $C$ clusters, there are $m$ individuals, so there are $m(m-1)$ ordered pairs of distinct individuals. Thus, there are $C\\,m(m-1)$ such terms in total.\n3.  When $i \\neq i'$, the individuals are from different clusters. The problem states their outcomes are independent, so their covariance is zero: $\\mathrm{Cov}(Y_{ij}, Y_{i'j'}) = 0$.\n\nSumming the non-zero covariance terms:\n$$ \\mathrm{Var}\\left(\\sum_{i=1}^{C} \\sum_{j=1}^{m} Y_{ij}\\right) = N \\sigma^2 + C\\,m(m-1) \\rho \\sigma^2 $$\nSubstituting this back into the expression for $\\mathrm{Var}_{\\mathrm{cluster}}(\\bar{Y})$:\n$$ \\mathrm{Var}_{\\mathrm{cluster}}(\\bar{Y}) = \\frac{1}{N^2} [N \\sigma^2 + C\\,m(m-1) \\rho \\sigma^2] $$\nSince $N = C\\,m$, we can rewrite $C\\,m(m-1)$ as $N(m-1)$.\n$$ \\mathrm{Var}_{\\mathrm{cluster}}(\\bar{Y}) = \\frac{\\sigma^2}{N^2} [N + N(m-1) \\rho] = \\frac{\\sigma^2}{N} [1 + (m-1)\\rho] $$\nThis is the variance of the sample mean for the cluster randomized design.\n\nFor comparison, consider a simple random sample (SRS) of $N$ independent individuals. The variance of the sample mean, $\\mathrm{Var}_{\\mathrm{SRS}}(\\bar{Y})$, is:\n$$ \\mathrm{Var}_{\\mathrm{SRS}}(\\bar{Y}) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{k=1}^{N} Y_k\\right) = \\frac{1}{N^2} \\sum_{k=1}^{N} \\mathrm{Var}(Y_k) = \\frac{N \\sigma^2}{N^2} = \\frac{\\sigma^2}{N} $$\nThe design effect, $DE$, is the ratio of these two variances:\n$$ DE = \\frac{\\mathrm{Var}_{\\mathrm{cluster}}(\\bar{Y})}{\\mathrm{Var}_{\\mathrm{SRS}}(\\bar{Y})} = \\frac{\\frac{\\sigma^2}{N} [1 + (m-1)\\rho]}{\\frac{\\sigma^2}{N}} $$\n$$ DE = 1 + (m-1)\\rho $$\nThe design effect represents the factor by which the variance of the sample mean is inflated due to the clustered nature of the sample, compared to a simple random sample of the same total size. This inflation arises from the correlation between outcomes within the same cluster.\n\nNow, we compute the numeric value of the design effect $DE$ using the given parameters: $m=40$ and $\\rho=0.01$.\n$$ DE = 1 + (40-1)(0.01) = 1 + (39)(0.01) = 1 + 0.39 = 1.39 $$\nSince $1.39$ is a terminating decimal, it is reported exactly.\n\nThe effective sample size, $N_{\\mathrm{eff}}$, is the size of an individually randomized sample (SRS) that would yield the same precision (i.e., the same variance of the mean) as the clustered sample of size $N$. We equate the variances:\n$$ \\mathrm{Var}_{\\mathrm{SRS}}(N_{\\mathrm{eff}}) = \\mathrm{Var}_{\\mathrm{cluster}}(N) $$\n$$ \\frac{\\sigma^2}{N_{\\mathrm{eff}}} = \\frac{\\sigma^2}{N} [1 + (m-1)\\rho] = \\frac{\\sigma^2}{N} DE $$\nSolving for $N_{\\mathrm{eff}}$:\n$$ N_{\\mathrm{eff}} = \\frac{N}{DE} $$\nGiven $N=800$ and our calculated $DE=1.39$:\n$$ N_{\\mathrm{eff}} = \\frac{800}{1.39} \\approx 575.539568... $$\nRounding to three significant figures as required, we get:\n$$ N_{\\mathrm{eff}} \\approx 576 $$\nThis means the clustered trial with $800$ participants provides the same statistical precision for estimating the mean as a simple random sample with only $576$ participants.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.39 & 576\n\\end{pmatrix}\n}\n$$", "id": "4622830"}, {"introduction": "Ultimately, the results of pragmatic trials are meant to inform real-world policy and resource allocation. A key question for any health system is whether a new, effective intervention offers good value for money. This practice bridges the gap between clinical effectiveness and economic evaluation by demonstrating how to calculate the Incremental Cost-Effectiveness Ratio (ICER), using data that would be generated from a pragmatic trial to help decision-makers weigh an intervention's costs against its health benefits. [@problem_id:4622846]", "problem": "A health system is evaluating a new intervention using a pragmatic randomized controlled trial (RCT) analyzed by intention-to-treat (ITT), designed to estimate real-world effectiveness under usual practice conditions. The trial reports mean per-participant costs and mean effectiveness measured in quality-adjusted life years (QALYs), where a quality-adjusted life year (QALY) is defined as the expected time in perfect health equivalent produced by an intervention over the study horizon. Let the mean cost in the intervention arm be $C_1 = 5000$ and in the control arm be $C_0 = 4500$. Let the mean QALYs in the intervention arm be $E_1 = 0.85$ and in the control arm be $E_0 = 0.80$. The health system applies a willingness-to-pay threshold of $50{,}000$ per QALY.\n\nStarting from first principles in cost-effectiveness analysis, where the economic value of an intervention is established by comparing marginal expected costs and marginal expected effectiveness between two interventions, derive the quantity that represents the cost per unit of effectiveness gained when moving from control to intervention, using the trialâ€™s arm-specific mean outcomes. Then, compute its numeric value using the provided estimates and interpret its magnitude relative to the stated threshold to assess whether the intervention is economically favorable in a pragmatic paradigm. Express the computed quantity in United States dollars (USD) per QALY and round your numerical answer to three significant figures.", "solution": "The problem statement is evaluated to be valid as it is scientifically grounded in the principles of health economics and epidemiology, well-posed with all necessary data provided, and objective in its language. The problem is self-contained, consistent, and requires the application of standard, verifiable methods.\n\nThe task is to derive a quantity representing the cost per unit of effectiveness gained for a new intervention compared to a control, compute its value, and interpret it against a given threshold. The analysis is situated within the context of a pragmatic randomized controlled trial (RCT) with an intention-to-treat (ITT) analysis.\n\nFrom first principles, cost-effectiveness analysis compares the change in costs to the change in health outcomes (effectiveness) between two alternatives. Let the intervention arm be denoted by the subscript $1$ and the control arm by the subscript $0$.\n\nThe data provided are:\n- Mean cost in the intervention arm: $C_1 = 5000$ USD\n- Mean cost in the control arm: $C_0 = 4500$ USD\n- Mean effectiveness in the intervention arm: $E_1 = 0.85$ quality-adjusted life years (QALYs)\n- Mean effectiveness in the control arm: $E_0 = 0.80$ QALYs\n- Willingness-to-pay threshold: $WTP = 50{,}000$ USD per QALY\n\nThe marginal or incremental cost, denoted as $\\Delta C$, is the difference in the mean costs between the intervention and control arms. It represents the additional cost incurred when choosing the intervention.\n$$ \\Delta C = C_1 - C_0 $$\n\nThe marginal or incremental effectiveness, denoted as $\\Delta E$, is the difference in the mean effectiveness between the two arms. It represents the additional health gain produced by the intervention.\n$$ \\Delta E = E_1 - E_0 $$\n\nThe quantity representing the cost per unit of effectiveness gained is the ratio of the incremental cost to the incremental effectiveness. This is formally known as the Incremental Cost-Effectiveness Ratio (ICER). The ICER quantifies the additional cost required to achieve one additional unit of health outcome (in this case, one QALY).\n$$ \\text{ICER} = \\frac{\\Delta C}{\\Delta E} = \\frac{C_1 - C_0}{E_1 - E_0} $$\nThis expression is derived directly from the fundamental definition of comparing marginal costs and marginal benefits.\n\nWe now substitute the given numerical values into this formula to compute the ICER.\nThe incremental cost is:\n$$ \\Delta C = 5000 - 4500 = 500 \\text{ USD} $$\n\nThe incremental effectiveness is:\n$$ \\Delta E = 0.85 - 0.80 = 0.05 \\text{ QALYs} $$\n\nNow, we compute the ICER:\n$$ \\text{ICER} = \\frac{500}{0.05} = \\frac{500}{\\frac{5}{100}} = 500 \\times \\frac{100}{5} = 100 \\times 100 = 10000 $$\nThe units of this ratio are dollars per QALY. So, the ICER is $10{,}000$ USD/QALY.\n\nThe problem requires the answer to be rounded to three significant figures. The calculated value is exactly $10000$. To express this unambiguously with three significant figures, we can use scientific notation: $1.00 \\times 10^4$.\n\nThe final step is to interpret this result relative to the stated willingness-to-pay threshold of $50{,}000$ USD per QALY. The decision rule in cost-effectiveness analysis is that an intervention is considered economically favorable, or \"cost-effective,\" if its ICER is less than the willingness-to-pay threshold.\n$$ \\text{ICER} < \\text{WTP} $$\nIn this case, we compare the calculated ICER to the threshold:\n$$ 10{,}000 < 50{,}000 $$\nSince the ICER is less than the threshold, the new intervention is judged to be economically favorable. This means that the cost of achieving one additional QALY with the new intervention ($10{,}000$) is less than the maximum amount the health system is willing to pay for that same health gain ($50{,}000$). The use of a pragmatic trial design and ITT analysis implies that this conclusion is based on an estimate of real-world effectiveness, lending it high external validity for policy decisions.\n\nThe problem asks for the computed numeric value of the quantity representing the cost per unit of effectiveness gained. This is the ICER value.", "answer": "$$\\boxed{1.00 \\times 10^4}$$", "id": "4622846"}]}