{"hands_on_practices": [{"introduction": "A cornerstone of epidemiological surveillance is the ability to construct a case definition from multiple sources of information, such as clinical signs, laboratory results, and exposure history. This first exercise provides practice in translating a common case definition structure—one that requires at least one of several criteria to be met—into a formal probabilistic expression. By working through this problem [@problem_id:4591588], you will apply fundamental probability principles, specifically the complement rule, to understand how the likelihood of identifying a case is determined by the probabilities of its individual, independent components.", "problem": "A public health department is establishing a surveillance case definition for a newly emerging respiratory disease. A person is classified as a case if at least one of three independent criteria is present in that person at the time of assessment: criterion $\\mathcal{C}_{1}$ (clinical syndrome consistent with the disease), criterion $\\mathcal{C}_{2}$ (a positive antigen test), and criterion $\\mathcal{C}_{3}$ (documented close contact with a confirmed case within the previous $7$ days). Let $p_{1}$, $p_{2}$, and $p_{3}$ denote the probabilities that a randomly selected person from the surveillance population meets $\\mathcal{C}_{1}$, $\\mathcal{C}_{2}$, and $\\mathcal{C}_{3}$, respectively. Assume the occurrence of these criteria in any given person is independent across criteria.\n\nUsing only foundational probability principles and the independence assumption, derive a closed-form analytic expression, in terms of $p_{1}$, $p_{2}$, and $p_{3}$, for the probability that a randomly selected person meets the case definition (that is, has at least one of the three criteria). Provide your final expression in simplest form. No numerical evaluation is required.", "solution": "We begin by formalizing the event structure. Define events $A_{1}$, $A_{2}$, and $A_{3}$ corresponding to the presence of criteria $\\mathcal{C}_{1}$, $\\mathcal{C}_{2}$, and $\\mathcal{C}_{3}$, respectively, in a randomly selected person. By definition, $\\Pr(A_{1}) = p_{1}$, $\\Pr(A_{2}) = p_{2}$, and $\\Pr(A_{3}) = p_{3}$. The case definition is met if at least one of these events occurs, which is the union event $A_{1} \\cup A_{2} \\cup A_{3}$.\n\nOur objective is to compute $\\Pr(A_{1} \\cup A_{2} \\cup A_{3})$ using basic probability axioms and the independence assumption. A standard approach begins with the complement rule from the Kolmogorov axioms of probability: for any event $E$, $\\Pr(E) = 1 - \\Pr(E^{c})$, where $E^{c}$ denotes the complement of $E$.\n\nApplying De Morgan’s laws to sets, the complement of a union equals the intersection of complements:\n$$\n(A_{1} \\cup A_{2} \\cup A_{3})^{c} = A_{1}^{c} \\cap A_{2}^{c} \\cap A_{3}^{c}.\n$$\nTherefore,\n$$\n\\Pr(A_{1} \\cup A_{2} \\cup A_{3}) = 1 - \\Pr\\!\\left( A_{1}^{c} \\cap A_{2}^{c} \\cap A_{3}^{c} \\right).\n$$\n\nNext, we use the definition of independence. The problem states that the criteria occur independently in a person. Independence of $A_{1}$, $A_{2}$, and $A_{3}$ implies independence of their complements $A_{1}^{c}$, $A_{2}^{c}$, and $A_{3}^{c}$, since for independent events $A$ and $B$, both $(A, B)$, $(A^{c}, B)$, $(A, B^{c})$, and $(A^{c}, B^{c})$ are independent. Consequently, the probability of the intersection of the complements factorizes into the product of their probabilities:\n$$\n\\Pr\\!\\left( A_{1}^{c} \\cap A_{2}^{c} \\cap A_{3}^{c} \\right) = \\Pr(A_{1}^{c}) \\, \\Pr(A_{2}^{c}) \\, \\Pr(A_{3}^{c}).\n$$\n\nUsing the complement rule for each marginal event,\n$$\n\\Pr(A_{i}^{c}) = 1 - \\Pr(A_{i}) = 1 - p_{i} \\quad \\text{for} \\quad i \\in \\{1,2,3\\}.\n$$\nSubstituting these into the factorized expression yields:\n$$\n\\Pr\\!\\left( A_{1}^{c} \\cap A_{2}^{c} \\cap A_{3}^{c} \\right) = (1 - p_{1})(1 - p_{2})(1 - p_{3}).\n$$\n\nFinally, substituting back into the expression for the union probability,\n$$\n\\Pr(A_{1} \\cup A_{2} \\cup A_{3}) = 1 - (1 - p_{1})(1 - p_{2})(1 - p_{3}).\n$$\n\nThis is the closed-form analytic expression for the probability that a randomly selected person meets the case definition (has at least one of the three criteria) under independence.", "answer": "$$\\boxed{1 - (1 - p_{1})(1 - p_{2})(1 - p_{3})}$$", "id": "4591588"}, {"introduction": "No diagnostic test or case definition is perfect. Understanding the impact of its inherent limitations on surveillance data is a critical skill for any epidemiologist. This practice problem [@problem_id:4591586] delves into the practical consequences of imperfect sensitivity—the failure to identify all true cases. You will derive and quantify the degree to which an observed incidence rate underestimates the true rate, demonstrating how to mathematically adjust for the systematic error introduced by false negatives.", "problem": "A public health department monitors a cohort for an infectious disease over a period producing $T$ person-time units. Case identification relies on a standardized case definition implemented through a diagnostic algorithm. The algorithm has sensitivity $Se$ and specificity $Sp$ as follows: sensitivity $Se$ is the probability of a positive classification given a true incident case, and specificity $Sp$ is the probability of a negative classification given a true non-case. During surveillance, a total of $C_{\\text{obs}}$ incident cases are classified positive by the algorithm.\n\nAssume that the case definition yields $Se=0.9$, $Sp=1.0$, and that there are no other sources of misclassification beyond false negatives implied by sensitivity less than $1.0$. Let the true incidence rate be defined as $I_{\\text{true}} = \\frac{C_{\\text{true}}}{T}$, where $C_{\\text{true}}$ is the true number of incident cases in the cohort, and let the observed incidence rate be $I_{\\text{obs}} = \\frac{C_{\\text{obs}}}{T}$. Using only the fundamental probabilistic definitions of sensitivity and specificity and the definition of incidence rate, derive the multiplicative factor by which the true incidence rate exceeds the observed incidence rate due solely to the $10\\%$ false negative proportion inherent in $Se=0.9$. Then compute the numerical value of this factor. Round your answer to four significant figures. Provide only the multiplicative factor as your final answer.", "solution": "The problem is well-posed, scientifically grounded in the principles of epidemiology, and contains all necessary information for a unique solution. The definitions of sensitivity, specificity, and incidence rate are standard, and the numerical values provided are plausible. We may therefore proceed with a formal derivation.\n\nLet $C_{\\text{true}}$ be the true number of incident cases and $C_{\\text{obs}}$ be the observed number of incident cases (i.e., those classified as positive by the diagnostic algorithm). Let $T$ be the total person-time of observation.\n\nThe true incidence rate, $I_{\\text{true}}$, is defined as:\n$$I_{\\text{true}} = \\frac{C_{\\text{true}}}{T}$$\nThe observed incidence rate, $I_{\\text{obs}}$, is defined as:\n$$I_{\\text{obs}} = \\frac{C_{\\text{obs}}}{T}$$\nWe are asked to find the multiplicative factor, which we will denote by $k$, by which the true incidence rate exceeds the observed incidence rate. This factor is the ratio of $I_{\\text{true}}$ to $I_{\\text{obs}}$:\n$$k = \\frac{I_{\\text{true}}}{I_{\\text{obs}}} = \\frac{C_{\\text{true}}/T}{C_{\\text{obs}}/T} = \\frac{C_{\\text{true}}}{C_{\\text{obs}}}$$\nThe task is thus reduced to finding the relationship between the true number of cases and the observed number of cases.\n\nThe total population under surveillance can be categorized into four groups based on their true disease status and the test result:\n1.  True Positives ($TP$): Individuals who are true cases and are correctly classified as positive.\n2.  False Positives ($FP$): Individuals who are not true cases but are incorrectly classified as positive.\n3.  True Negatives ($TN$): Individuals who are not true cases and are correctly classified as negative.\n4.  False Negatives ($FN$): Individuals who are true cases but are incorrectly classified as negative.\n\nThe total number of true cases, $C_{\\text{true}}$, is the sum of those correctly and incorrectly classified:\n$$C_{\\text{true}} = TP + FN$$\nThe total number of observed cases, $C_{\\text{obs}}$, is the sum of all individuals classified as positive:\n$$C_{\\text{obs}} = TP + FP$$\n\nSensitivity, $Se$, is the probability that a true case tests positive. It is formally defined as:\n$$Se = \\frac{TP}{TP + FN} = \\frac{TP}{C_{\\text{true}}}$$\nSpecificity, $Sp$, is the probability that a true non-case tests negative. It is formally defined as:\n$$Sp = \\frac{TN}{TN + FP}$$\nThe problem states that the specificity is $Sp = 1.0$. From the definition of specificity, if there is a non-zero number of true non-cases, $TN+FP > 0$, then $Sp=1.0$ implies that $FP=0$. This aligns with the problem's simplifying assumption that the only source of misclassification is false negatives.\n\nWith $FP = 0$, the equation for the observed number of cases simplifies to:\n$$C_{\\text{obs}} = TP + 0 = TP$$\nThis indicates that every observed case is a true positive.\n\nNow, we substitute this result into the definition of sensitivity:\n$$Se = \\frac{TP}{C_{\\text{true}}} = \\frac{C_{\\text{obs}}}{C_{\\text{true}}}$$\nOur goal is to find the factor $k = \\frac{C_{\\text{true}}}{C_{\\text{obs}}}$. We can rearrange the sensitivity equation to solve for this ratio:\n$$\\frac{C_{\\text{true}}}{C_{\\text{obs}}} = \\frac{1}{Se}$$\nThus, the multiplicative factor is simply the reciprocal of the sensitivity. This result is independent of the person-time $T$ and the true incidence in the population.\n\nThe problem provides the numerical value for sensitivity as $Se = 0.9$. Substituting this value into our derived expression for the factor $k$:\n$$k = \\frac{1}{0.9} = \\frac{1}{9/10} = \\frac{10}{9}$$\nPerforming the division gives:\n$$k = 1.1111...$$\nThe problem requires the answer to be rounded to four significant figures.\n$$k \\approx 1.111$$\nThis factor signifies that the true incidence rate is approximately $1.111$ times the observed incidence rate, due to the $1 - 0.9 = 0.1$ or $10\\%$ of true cases being missed by the diagnostic algorithm (i.e., the false negative proportion).", "answer": "$$\n\\boxed{1.111}\n$$", "id": "4591586"}, {"introduction": "When a case definition relies on a continuous measurement, like the concentration of a biomarker, the choice of a threshold for positivity is a crucial decision with direct trade-offs between sensitivity and specificity. This exercise [@problem_id:4591632] guides you through finding an \"optimal\" threshold by maximizing the Youden index, a common metric that balances these two properties. More importantly, it challenges you to think beyond the mathematical optimum and consider whether this balanced approach is truly aligned with the specific priorities of a public health program, such as maximizing case detection during the early stages of an outbreak.", "problem": "A public health agency is establishing a case definition for a novel enteric pathogen for syndromic surveillance. A continuous biomarker, denoted $A$ (antigen concentration), is measured in nanograms per milliliter (ng/mL). In validation data, individuals known to be true cases have biomarker values distributed as a normal distribution with mean $\\mu_{1}$ and variance $\\sigma^{2}$, written $A_{1} \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$, and individuals known to be true non-cases have biomarker values distributed as $A_{0} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$, with the same variance $\\sigma^{2}$ but a lower mean $\\mu_{0} < \\mu_{1}$. The operational rule under consideration defines an individual as a suspected case if $A \\ge t$, where $t$ is a threshold to be chosen.\n\nThe Receiver Operating Characteristic (ROC) curve, defined as the locus of points given by sensitivity versus the false positive rate as the threshold $t$ varies, is induced by this classification rule and these distributions. For a given threshold $t$, sensitivity is $\\Pr(A_{1} \\ge t)$ and specificity is $\\Pr(A_{0} < t)$. The Youden index, denoted $J$, is defined by $J(t) = \\text{sensitivity}(t) + \\text{specificity}(t) - 1$.\n\nUsing only these foundational definitions, derive the analytic expression for the threshold $t^{\\ast}$ that maximizes $J(t)$ over all real $t$. Then, given the scientifically plausible parameter values $\\mu_{0} = 7$ ng/mL, $\\mu_{1} = 12$ ng/mL, and $\\sigma = 3$ ng/mL, compute the numerical value of $t^{\\ast}$, rounding your answer to four significant figures. Express your final threshold in ng/mL.\n\nFinally, the surveillance program’s stated priority is to maximize sensitivity in early outbreak detection, accepting an increase in false positives, in a setting with low prevalence $p = 0.01$. Based on first principles and the properties of $t^{\\ast}$, justify whether the threshold $t^{\\ast}$ that maximizes $J$ aligns with these surveillance priorities. Your justification should be qualitative but supported by expressions derived from the model. The calculation part of your answer is the numerical value of $t^{\\ast}$.", "solution": "The problem is first subjected to validation.\n\n### Step 1: Extract Givens\n- A continuous biomarker, $A$, is measured in nanograms per milliliter ($\\text{ng/mL}$).\n- The biomarker distribution for true cases is $A_{1} \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$.\n- The biomarker distribution for true non-cases is $A_{0} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$.\n- The variances of the two distributions are equal, $\\sigma^{2}$.\n- The mean for cases is greater than the mean for non-cases: $\\mu_{0} < \\mu_{1}$.\n- A suspected case is defined by the rule $A \\ge t$, where $t$ is a threshold.\n- Sensitivity is defined as $\\text{sensitivity}(t) = \\Pr(A_{1} \\ge t)$.\n- Specificity is defined as $\\text{specificity}(t) = \\Pr(A_{0} < t)$.\n- The Youden index is defined as $J(t) = \\text{sensitivity}(t) + \\text{specificity}(t) - 1$.\n- The first task is to derive the analytic expression for the threshold $t^{\\ast}$ that maximizes $J(t)$.\n- The second task is to compute the numerical value of $t^{\\ast}$ given the parameter values $\\mu_{0} = 7 \\text{ ng/mL}$, $\\mu_{1} = 12 \\text{ ng/mL}$, and $\\sigma = 3 \\text{ ng/mL}$, rounded to four significant figures.\n- The third task is to justify whether $t^{\\ast}$ aligns with the surveillance priority of maximizing sensitivity, given a prevalence $p = 0.01$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is firmly grounded in biostatistics and epidemiology. The use of normal distributions to model biomarker data, and the definitions of sensitivity, specificity, and the Youden index, are standard concepts in medical diagnostics and public health surveillance. The assumption of equal variances is a common simplifying assumption (homoscedasticity) in such models.\n- **Well-Posed:** The problem is well-posed. It asks to maximize a function $J(t)$ that is continuous and differentiable, formed from the cumulative distribution functions of normal distributions. A unique maximum is expected because the underlying probability density functions cross at a single point.\n- **Objective:** The problem is stated in precise, objective, and unambiguous mathematical and epidemiological terms.\n- **Completeness and Consistency:** All necessary definitions and parameters are provided to solve the problem. The conditions are internally consistent (e.g., $\\mu_{0} < \\mu_{1}$ is consistent with the biomarker being an indicator of disease).\n- **Unrealistic or Infeasible:** The provided numerical values for $\\mu_0$, $\\mu_1$, and $\\sigma$ are plausible for a biological marker, resulting in two overlapping but distinct population distributions.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid as it is scientifically grounded, well-posed, objective, and complete. A solution will be derived.\n\n### Derivation of the Optimal Threshold $t^{\\ast}$\nThe Youden index is given by $J(t) = \\text{sensitivity}(t) + \\text{specificity}(t) - 1$.\nLet $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$, and let $\\phi(z)$ be its probability density function (PDF).\n\nThe sensitivity is the probability that a true case is correctly classified:\n$$\n\\text{sensitivity}(t) = \\Pr(A_{1} \\ge t) = \\Pr\\left(\\frac{A_{1} - \\mu_{1}}{\\sigma} \\ge \\frac{t - \\mu_{1}}{\\sigma}\\right) = \\Pr\\left(Z \\ge \\frac{t - \\mu_{1}}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)\n$$\nThe specificity is the probability that a true non-case is correctly classified:\n$$\n\\text{specificity}(t) = \\Pr(A_{0} < t) = \\Pr\\left(\\frac{A_{0} - \\mu_{0}}{\\sigma} < \\frac{t - \\mu_{0}}{\\sigma}\\right) = \\Pr\\left(Z < \\frac{t - \\mu_{0}}{\\sigma}\\right) = \\Phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right)\n$$\nSubstituting these expressions into the definition of the Youden index:\n$$\nJ(t) = \\left(1 - \\Phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)\\right) + \\Phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right) - 1 = \\Phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right) - \\Phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)\n$$\nTo find the threshold $t^{\\ast}$ that maximizes $J(t)$, we must find the critical points by taking the derivative of $J(t)$ with respect to $t$ and setting it to zero. Using the chain rule and the fact that $\\frac{d}{dz}\\Phi(z) = \\phi(z)$:\n$$\n\\frac{dJ}{dt} = \\frac{d}{dt}\\left[\\Phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right) - \\Phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)\\right] = \\phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right) \\cdot \\frac{1}{\\sigma} - \\phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right) \\cdot \\frac{1}{\\sigma}\n$$\nSetting the derivative to zero:\n$$\n\\frac{1}{\\sigma} \\left[ \\phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right) - \\phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right) \\right] = 0\n$$\n$$\n\\phi\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right) = \\phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)\n$$\nThe standard normal PDF is $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$. Since this function is symmetric about $z=0$ (i.e., $\\phi(z) = \\phi(-z)$), the equality holds if the arguments are equal or if they are negatives of each other.\n$$\n\\left(\\frac{t - \\mu_{0}}{\\sigma}\\right)^2 = \\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)^2\n$$\nThis yields two possibilities:\n$1$. $\\frac{t - \\mu_{0}}{\\sigma} = \\frac{t - \\mu_{1}}{\\sigma}$, which implies $t - \\mu_{0} = t - \\mu_{1}$, leading to $\\mu_{0} = \\mu_{1}$. This contradicts the given condition $\\mu_{0} < \\mu_{1}$ and must be discarded.\n$2$. $\\frac{t - \\mu_{0}}{\\sigma} = -\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)$, which implies $t - \\mu_{0} = -(t - \\mu_{1}) = \\mu_{1} - t$.\nSolving for $t$:\n$$\n2t = \\mu_{0} + \\mu_{1}\n$$\n$$\nt^{\\ast} = \\frac{\\mu_{0} + \\mu_{1}}{2}\n$$\nThis result is intuitively sound: for two normal distributions with the same variance, the point where their PDFs are equal is the midpoint of their means. This is the point where the misclassification probabilities are balanced in a specific way that maximizes the Youden index. The second derivative test confirms this is a maximum, as $\\frac{d^2 J}{dt^2}|_{t=t^{\\ast}} < 0$.\n\n### Numerical Calculation of $t^{\\ast}$\nGiven the parameter values $\\mu_{0} = 7$, $\\mu_{1} = 12$, and $\\sigma = 3$, we calculate the numerical value of $t^{\\ast}$:\n$$\nt^{\\ast} = \\frac{7 + 12}{2} = \\frac{19}{2} = 9.5\n$$\nThe problem requires the answer to be rounded to four significant figures. Thus, the value is $9.500$. The units are $\\text{ng/mL}$.\n\n### Qualitative Justification on Surveillance Priorities\nThe threshold $t^{\\ast}$ that maximizes the Youden index, $J(t)$, is derived by giving equal importance to sensitivity and specificity. Maximizing $J(t) = \\text{sensitivity}(t) + \\text{specificity}(t) - 1$ is equivalent to maximizing the sum of sensitivity and specificity. The solution $t^{\\ast} = \\frac{\\mu_0 + \\mu_1}{2}$ represents a balanced trade-off between correctly identifying cases and correctly identifying non-cases.\n\nThe stated priority of the surveillance program is to **maximize sensitivity**, even at the cost of an increase in false positives (which is equivalent to a decrease in specificity). Sensitivity, $\\text{sensitivity}(t) = 1 - \\Phi\\left(\\frac{t - \\mu_{1}}{\\sigma}\\right)$, is a monotonically decreasing function of the threshold $t$. To maximize sensitivity, one must choose the lowest possible threshold. A surveillance program with this priority would therefore select a threshold $t_{sens} < t^{\\ast}$.\n\nBy choosing a threshold $t < t^{\\ast}$, the program would achieve a higher sensitivity than is possible at $t^{\\ast}$, but this would come at the expense of a lower specificity. For example, at $t^{\\ast} = 9.5$, the sensitivity is $\\Pr(A_1 \\ge 9.5) = 1 - \\Phi(\\frac{9.5 - 12}{3}) = 1 - \\Phi(-0.8333) = \\Phi(0.8333) \\approx 0.7977$. If the threshold were lowered to $t=7$ (the mean of the non-case distribution), the sensitivity would increase to $\\Pr(A_1 \\ge 7) = 1 - \\Phi(\\frac{7-12}{3}) = 1 - \\Phi(-1.6667) = \\Phi(1.6667) \\approx 0.9522$. However, the specificity would drop to $\\Pr(A_0 < 7) = \\Phi(\\frac{7-7}{3}) = \\Phi(0) = 0.5$, meaning a false positive rate of $50\\%$.\n\nThe low prevalence of $p=0.01$ further complicates the strategy. The Positive Predictive Value (PPV) is given by:\n$$ \\text{PPV}(t) = \\frac{\\text{sensitivity}(t) \\cdot p}{\\text{sensitivity}(t) \\cdot p + (1-\\text{specificity}(t)) \\cdot (1-p)} $$\nA strategy that lowers $t$ to maximize sensitivity will necessarily decrease specificity, thereby increasing the false positive rate ($1-\\text{specificity}$). In a low-prevalence setting where $(1-p)$ is close to $1$, any substantial increase in the false positive rate will cause the denominator to grow much faster than the numerator, leading to a very low PPV. While the goal is early detection (high sensitivity), the operational consequence will be a large number of false alarms for every true case detected, which may overwhelm public health resources.\n\nIn conclusion, the threshold $t^{\\ast}$ that maximizes the Youden index represents a balanced compromise. The stated priority of maximizing sensitivity is an explicit move away from this balance toward one end of the sensitivity-specificity spectrum. Therefore, the threshold $t^{\\ast}$ does **not** align with the stated surveillance priorities, which would be better served by a threshold lower than $t^{\\ast}$.", "answer": "$$\\boxed{9.500}$$", "id": "4591632"}]}