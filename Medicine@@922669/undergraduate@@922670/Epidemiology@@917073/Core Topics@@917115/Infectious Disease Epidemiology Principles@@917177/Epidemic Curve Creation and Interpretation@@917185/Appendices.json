{"hands_on_practices": [{"introduction": "Epidemic curves rarely conform to simple statistical models. Real-world transmission is often characterized by heterogeneity, such as super-spreading events, which can lead to more variability in case counts than expected. This practice [@problem_id:4590076] challenges you to move beyond visual inspection and formally test for this phenomenon, known as overdispersion, by deriving a goodness-of-fit statistic from first principles. Mastering this skill is crucial for selecting appropriate statistical models and accurately interpreting the dynamics of an outbreak.", "problem": "An outbreak of a respiratory infection occurs on a university campus. The epidemic curve (histogram of incident cases in equal-duration daily bins) shows two conspicuous peaks and a long tail. Investigators suspect that super-spreading events have occurred, producing a curve with multiple modes and heavy tails. Using the definition of an epidemic curve as daily counts and the well-tested property of a homogeneous-count Poisson process that each bin has independent increments with equal mean and variance, and using the Central Limit Theorem (CLT) approximation for sums of standardized residuals, derive from first principles a goodness-of-fit statistic based solely on the curveâ€™s bin counts that quantifies overdispersion relative to the Poisson assumption. Then, compute its numerical value for the following $12$ consecutive daily counts:\n$$(x_1,\\dots,x_{12})=(2,3,4,5,22,7,5,4,3,18,6,5).$$\nRound your final numeric answer to four significant figures and express it as a dimensionless number.", "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of epidemiology and statistics, well-posed with sufficient and consistent information, and objectively phrased. The task is a standard exercise in biostatistics: deriving and calculating a goodness-of-fit statistic to test for overdispersion in count data against a Poisson model.\n\nThe objective is to derive a goodness-of-fit statistic that quantifies overdispersion in daily case counts, relative to the assumption of a homogeneous Poisson process. Let the sequence of daily case counts be denoted by $(x_1, x_2, \\dots, x_N)$, where $N$ is the total number of days (bins). In this problem, $N=12$.\n\nThe null hypothesis, $H_0$, is that the counts are generated by a homogeneous Poisson process. This implies that the counts $x_i$ are realizations of $N$ independent and identically distributed (i.i.d.) random variables, $X_1, X_2, \\dots, X_N$, each following a Poisson distribution with a single, constant rate parameter $\\lambda$. We write this as $X_i \\sim \\text{Pois}(\\lambda)$ for $i=1, \\dots, N$.\n\nA fundamental property of the Poisson distribution is that its mean and variance are equal, i.e., $E[X_i] = \\lambda$ and $\\text{Var}(X_i) = \\lambda$. Overdispersion occurs when the observed variance in the data is significantly greater than the mean, which would constitute evidence against the Poisson model.\n\nThe problem directs us to derive the statistic from first principles using standardized residuals and the Central Limit Theorem (CLT). For a single observation $x_i$, the standardized residual under the true model would be:\n$$ Z_i = \\frac{x_i - E[X_i]}{\\sqrt{\\text{Var}(X_i)}} = \\frac{x_i - \\lambda}{\\sqrt{\\lambda}} $$\nUnder $H_0$, the random variables $Z_i$ would have a mean of $0$ and a variance of $1$.\n\nHowever, the parameter $\\lambda$ is unknown and must be estimated from the data. The maximum likelihood estimator (and method of moments estimator) for $\\lambda$ is the sample mean:\n$$ \\hat{\\lambda} = \\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i $$\nWe substitute this estimate $\\bar{x}$ into the expression for the standardized residuals. A goodness-of-fit statistic can be constructed by summing the squares of these estimated standardized residuals. This statistic is the Pearson chi-squared statistic for a Poisson model, often referred to as the Poisson dispersion statistic or index of dispersion statistic. It is defined as:\n$$ D = \\sum_{i=1}^{N} \\left( \\frac{x_i - \\bar{x}}{\\sqrt{\\bar{x}}} \\right)^2 = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})^2}{\\bar{x}} $$\nThis statistic, $D$, measures the total squared deviation of the observations from the estimated mean, scaled by the estimated mean itself. As the numerator and denominator have the same units (counts), the statistic $D$ is a dimensionless quantity. Under the null hypothesis, for sufficiently large $N$ and $\\lambda$, $D$ follows approximately a chi-squared distribution with $N-1$ degrees of freedom. A large value of $D$ relative to $N-1$ suggests that the variance in the data is larger than the mean, indicating overdispersion.\n\nWe now compute the numerical value of this statistic for the given data.\nThe data are the $N=12$ consecutive daily counts:\n$$ (x_1, \\dots, x_{12}) = (2, 3, 4, 5, 22, 7, 5, 4, 3, 18, 6, 5) $$\nFirst, we calculate the sample mean, $\\bar{x}$:\n$$ \\sum_{i=1}^{12} x_i = 2+3+4+5+22+7+5+4+3+18+6+5 = 84 $$\n$$ \\bar{x} = \\frac{84}{12} = 7 $$\nNext, we calculate the sum of the squared deviations from the mean, $\\sum_{i=1}^{12} (x_i - \\bar{x})^2$:\n\\begin{align*}\n\\sum_{i=1}^{12} (x_i - 7)^2 = (2-7)^2 + (3-7)^2 + (4-7)^2 + (5-7)^2 + (22-7)^2 + (7-7)^2 \\\\\n\\quad + (5-7)^2 + (4-7)^2 + (3-7)^2 + (18-7)^2 + (6-7)^2 + (5-7)^2 \\\\\n= (-5)^2 + (-4)^2 + (-3)^2 + (-2)^2 + (15)^2 + (0)^2 \\\\\n\\quad + (-2)^2 + (-3)^2 + (-4)^2 + (11)^2 + (-1)^2 + (-2)^2 \\\\\n= 25 + 16 + 9 + 4 + 225 + 0 + 4 + 9 + 16 + 121 + 1 + 4 \\\\\n= 434\n\\end{align*}\nFinally, we compute the statistic $D$:\n$$ D = \\frac{\\sum_{i=1}^{12} (x_i - \\bar{x})^2}{\\bar{x}} = \\frac{434}{7} = 62 $$\nThe problem requires the answer to be rounded to four significant figures. The exact value is $62$, which expressed to four significant figures is $62.00$.", "answer": "$$\\boxed{62.00}$$", "id": "4590076"}, {"introduction": "To better visualize the underlying trend in an epidemic, analysts frequently apply smoothing techniques like moving averages to raw case data. While this reduces noise, it can also distort the signal by introducing bias and a temporal lag, especially when confounded by regular patterns like weekend reporting delays. This hands-on problem [@problem_id:4590031] provides a rigorous framework to quantify these trade-offs, allowing you to understand precisely how smoothing affects the shape and timing of an epidemic curve. This analysis is vital for making accurate inferences from smoothed data.", "problem": "An epidemic curve is a time series of daily reported case counts. To reduce high-frequency variation in such curves, analysts often apply a trailing moving average, but this smoothing can introduce bias and temporal lag, especially when there are systematic day-of-week reporting effects (\"weekend effects\"). Consider the following scientifically grounded model for daily reported counts.\n\nAssume the latent daily mean incidence is a slowly varying function over short windows and, within the last seven days, is well-approximated by a linear trend $m_t = \\alpha + \\beta t$, where $t$ is the day index in whole days and $\\alpha$ and $\\beta$ are constants. The observed daily count on day $t$, denoted $Y_t$, is subject to a multiplicative reporting factor that depends on the day of week. Let $r_{\\mathrm{dow}(t)}$ be the day-of-week factor for day $t$. Model the observed counts as independent Poisson random variables $Y_t \\sim \\mathrm{Poisson}(r_{\\mathrm{dow}(t)}\\, m_t)$, and define the trailing $7$-day moving average estimator $M_t = \\frac{1}{7}\\sum_{i=0}^{6} Y_{t-i}$.\n\nYou are told the following empirical weekend pattern is in force in the window ending on a Monday: $r_{\\mathrm{Mon}} = 1.9$, $r_{\\mathrm{Sun}} = 0.5$, $r_{\\mathrm{Sat}} = 0.6$, and $r_{\\mathrm{Tue}} = r_{\\mathrm{Wed}} = r_{\\mathrm{Thu}} = r_{\\mathrm{Fri}} = 1.0$. For this specific window, treat $t$ as Monday, so the seven contributing days to $M_t$ are Monday ($i=0$), Sunday ($i=1$), Saturday ($i=2$), Friday ($i=3$), Thursday ($i=4$), Wednesday ($i=5$), and Tuesday ($i=6$).\n\nStarting from the definitions of expectation and variance for the Poisson distribution, and the independence of daily counts, derive:\n\n- The bias of the moving average estimator at day $t$, defined as $B_t = \\mathbb{E}[M_t] - m_t$, under the stated linear trend model.\n- The variance of the moving average estimator, $\\mathrm{Var}(M_t)$.\n- The effective lag in days introduced by the estimator at day $t$, defined as the centroid of the weights on the latent means in $\\mathbb{E}[M_t]$, that is $L_t = \\frac{\\sum_{i=0}^{6} i\\, r_{t-i}}{\\sum_{i=0}^{6} r_{t-i}}$, where $r_{t-i}$ denotes the appropriate day-of-week factor for the day $t-i$.\n\nThen compute the numerical values of $B_t$, $\\mathrm{Var}(M_t)$, and $L_t$ given that the current latent mean is $m_t = 280$ and the local slope is $\\beta = 20$ (counts per day). Express the bias and variance in cases and the lag in days. Round your final numeric answers to four significant figures. State the final results as a row vector in the order bias, variance, lag.", "solution": "The problem statement is scientifically grounded, well-posed, and objective. It presents a simplified but standard model used in epidemiology for analyzing epidemic curves, incorporating Poisson-distributed case counts, day-of-week reporting effects, and a local linear trend for the latent incidence. All variables, constants, and objectives are clearly defined, and sufficient information is provided to derive a unique, meaningful solution. The problem is valid and can be solved as stated.\n\nThe solution requires deriving expressions for the bias ($B_t$), variance ($\\mathrm{Var}(M_t)$), and effective lag ($L_t$) of a $7$-day trailing moving average estimator $M_t$, and then computing their numerical values.\n\nFirst, we establish the necessary properties of the daily counts, $Y_t$. Given that $Y_t \\sim \\mathrm{Poisson}(r_{\\mathrm{dow}(t)}\\, m_t)$, the expectation and variance are equal to the rate parameter:\n$$\n\\mathbb{E}[Y_t] = \\mathrm{Var}(Y_t) = r_{\\mathrm{dow}(t)}\\, m_t\n$$\nThe problem states that the daily counts are independent random variables.\n\nThe trailing $7$-day moving average estimator is defined as:\n$$\nM_t = \\frac{1}{7}\\sum_{i=0}^{6} Y_{t-i}\n$$\n\n**1. Derivation of the Bias, $B_t$**\n\nThe bias of the estimator $M_t$ is defined as $B_t = \\mathbb{E}[M_t] - m_t$. We begin by calculating the expectation of $M_t$. Using the linearity of expectation:\n$$\n\\mathbb{E}[M_t] = \\mathbb{E}\\left[\\frac{1}{7}\\sum_{i=0}^{6} Y_{t-i}\\right] = \\frac{1}{7}\\sum_{i=0}^{6} \\mathbb{E}[Y_{t-i}]\n$$\nSubstituting the expectation for each $Y_{t-i}$:\n$$\n\\mathbb{E}[M_t] = \\frac{1}{7}\\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)}\\, m_{t-i}\n$$\nNext, we use the linear trend model for the latent mean, $m_t = \\alpha + \\beta t$. This allows us to express $m_{t-i}$ in terms of $m_t$:\n$$\nm_{t-i} = \\alpha + \\beta(t-i) = (\\alpha + \\beta t) - \\beta i = m_t - \\beta i\n$$\nSubstituting this into the expression for $\\mathbb{E}[M_t]$:\n$$\n\\mathbb{E}[M_t] = \\frac{1}{7}\\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)} (m_t - \\beta i)\n$$\nWe can separate the terms in the summation:\n$$\n\\mathbb{E}[M_t] = \\frac{1}{7}\\left( m_t \\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)} - \\beta \\sum_{i=0}^{6} i\\, r_{\\mathrm{dow}(t-i)} \\right)\n$$\nNow we can write the expression for the bias, $B_t$:\n$$\nB_t = \\mathbb{E}[M_t] - m_t = \\left[ \\frac{m_t}{7} \\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)} - \\frac{\\beta}{7} \\sum_{i=0}^{6} i\\, r_{\\mathrm{dow}(t-i)} \\right] - m_t\n$$\nRearranging the terms, we obtain the general formula for the bias:\n$$\nB_t = m_t \\left( \\frac{1}{7} \\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)} - 1 \\right) - \\frac{\\beta}{7} \\sum_{i=0}^{6} i\\, r_{\\mathrm{dow}(t-i)}\n$$\n\n**2. Derivation of the Variance, $\\mathrm{Var}(M_t)$**\n\nThe variance of the estimator $M_t$ is calculated as follows:\n$$\n\\mathrm{Var}(M_t) = \\mathrm{Var}\\left(\\frac{1}{7}\\sum_{i=0}^{6} Y_{t-i}\\right)\n$$\nUsing the property $\\mathrm{Var}(cX) = c^2\\mathrm{Var}(X)$, we have:\n$$\n\\mathrm{Var}(M_t) = \\left(\\frac{1}{7}\\right)^2 \\mathrm{Var}\\left(\\sum_{i=0}^{6} Y_{t-i}\\right) = \\frac{1}{49} \\mathrm{Var}\\left(\\sum_{i=0}^{6} Y_{t-i}\\right)\n$$\nSince the daily counts $Y_{t-i}$ are independent, the variance of their sum is the sum of their variances:\n$$\n\\mathrm{Var}(M_t) = \\frac{1}{49} \\sum_{i=0}^{6} \\mathrm{Var}(Y_{t-i})\n$$\nSubstituting $\\mathrm{Var}(Y_{t-i}) = r_{\\mathrm{dow}(t-i)}\\, m_{t-i}$:\n$$\n\\mathrm{Var}(M_t) = \\frac{1}{49} \\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)}\\, m_{t-i}\n$$\nThis sum is identical to the one in the expression for $\\mathbb{E}[M_t]$, so we can state that $\\mathrm{Var}(M_t) = \\frac{1}{7}\\mathbb{E}[M_t]$. Substituting the linear trend model $m_{t-i} = m_t - \\beta i$, we get the general formula for the variance:\n$$\n\\mathrm{Var}(M_t) = \\frac{1}{49} \\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)} (m_t - \\beta i) = \\frac{1}{49} \\left( m_t \\sum_{i=0}^{6} r_{\\mathrm{dow}(t-i)} - \\beta \\sum_{i=0}^{6} i\\, r_{\\mathrm{dow}(t-i)} \\right)\n$$\n\n**3. Derivation of the Effective Lag, $L_t$**\n\nThe effective lag $L_t$ is defined in the problem statement as the centroid of the weights $r_{t-i}$ on the lag index $i$:\n$$\nL_t = \\frac{\\sum_{i=0}^{6} i\\, r_{t-i}}{\\sum_{i=0}^{6} r_{t-i}}\n$$\nwhere $r_{t-i}$ is shorthand for $r_{\\mathrm{dow}(t-i)}$. No further derivation is needed; this is a definitional formula to be computed.\n\n**Numerical Computation**\n\nWe are given the following values for a window ending on a Monday (day $t$):\n- $r_{t-0}$ (Mon): $r_0 = 1.9$\n- $r_{t-1}$ (Sun): $r_1 = 0.5$\n- $r_{t-2}$ (Sat): $r_2 = 0.6$\n- $r_{t-3}$ (Fri): $r_3 = 1.0$\n- $r_{t-4}$ (Thu): $r_4 = 1.0$\n- $r_{t-5}$ (Wed): $r_5 = 1.0$\n- $r_{t-6}$ (Tue): $r_6 = 1.0$\n- Latent mean at day $t$: $m_t = 280$\n- Local slope: $\\beta = 20$\n\nFirst, we compute the required sums:\n$$\n\\sum_{i=0}^{6} r_{t-i} = 1.9 + 0.5 + 0.6 + 1.0 + 1.0 + 1.0 + 1.0 = 7.0\n$$\n$$\n\\sum_{i=0}^{6} i\\, r_{t-i} = (0)(1.9) + (1)(0.5) + (2)(0.6) + (3)(1.0) + (4)(1.0) + (5)(1.0) + (6)(1.0)\n$$\n$$\n\\sum_{i=0}^{6} i\\, r_{t-i} = 0 + 0.5 + 1.2 + 3.0 + 4.0 + 5.0 + 6.0 = 19.7\n$$\n\nNow we compute $B_t$, $\\mathrm{Var}(M_t)$, and $L_t$.\n\n- **Lag ($L_t$):**\n$$\nL_t = \\frac{\\sum_{i=0}^{6} i\\, r_{t-i}}{\\sum_{i=0}^{6} r_{t-i}} = \\frac{19.7}{7.0} \\approx 2.8142857... \\text{ days}\n$$\nRounding to four significant figures, $L_t = 2.814$ days.\n\n- **Bias ($B_t$):**\n$$\nB_t = m_t \\left( \\frac{1}{7} \\sum_{i=0}^{6} r_{t-i} - 1 \\right) - \\frac{\\beta}{7} \\sum_{i=0}^{6} i\\, r_{t-i}\n$$\n$$\nB_t = 280 \\left( \\frac{7.0}{7} - 1 \\right) - \\frac{20}{7} (19.7) = 280(0) - \\frac{394}{7} = -56.285714... \\text{ cases}\n$$\nRounding to four significant figures, $B_t = -56.29$ cases. The negative bias indicates that the moving average estimator lags behind the true rising trend.\n\n- **Variance ($\\mathrm{Var}(M_t)$):**\n$$\n\\mathrm{Var}(M_t) = \\frac{1}{49} \\left( m_t \\sum_{i=0}^{6} r_{t-i} - \\beta \\sum_{i=0}^{6} i\\, r_{t-i} \\right)\n$$\n$$\n\\mathrm{Var}(M_t) = \\frac{1}{49} \\left( (280)(7.0) - (20)(19.7) \\right) = \\frac{1}{49} (1960 - 394) = \\frac{1566}{49}\n$$\n$$\n\\mathrm{Var}(M_t) = 31.959183... \\text{ cases}^2\n$$\nRounding to four significant figures, $\\mathrm{Var}(M_t) = 31.96$ cases$^2$.\n\nThe final results for bias, variance, and lag, rounded to four significant figures, are $-56.29$, $31.96$, and $2.814$, respectively.", "answer": "$$\n\\boxed{\\begin{pmatrix} -56.29  31.96  2.814\\end{pmatrix}}\n$$", "id": "4590031"}, {"introduction": "Identifying the peak of an epidemic is crucial for assessing the effectiveness of interventions and communicating with the public. However, due to inherent randomness in disease transmission and reporting, the observed peak day is only an estimate. This practice [@problem_id:4590034] introduces the bootstrap, a powerful computational method, to quantify the uncertainty around this estimate by simulating thousands of plausible epidemic curves. By constructing a confidence interval for the peak time, you will learn to move beyond a single point estimate and provide a more honest and robust assessment of an outbreak's key turning point.", "problem": "You are given incident counts over equally spaced time intervals for several hypothetical outbreaks. An epidemic curve is defined as a sequence of incident counts per time interval, where each count is modeled as an independent realization of a counting process. To quantify uncertainty in peak timing, your task is to construct a Confidence Interval (CI) for the peak time using bootstrap resampling of incident counts. For clarity, define peak time as the earliest time index at which the maximum count is observed.\n\nBase assumptions and definitions:\n- Incident counts per interval are modeled as realizations of independent Poisson random variables, a commonly used model for count data. Let the observed count at time index $t$ be $c_t$, where $t$ ranges from $0$ to $T - 1$ and $T$ is the number of intervals in the epidemic curve.\n- The peak time estimator is the earliest index at which the maximum of the observed counts occurs, expressed as an integer index where the first interval is $0$.\n- A Bootstrap Confidence Interval (BCI) is constructed by repeatedly resampling synthetic incident counts and recomputing the peak time for each resample. Use the percentile method: the lower bound is the empirical $q_{\\ell}$ quantile and the upper bound is the empirical $q_u$ quantile of the bootstrap distribution of peak times.\n\nYou must write a complete, runnable program that, for each test case, computes:\n- The observed peak time index (earliest index of the maximum observed count).\n- The lower and upper bounds of a percentile BCI for the peak time using parametric bootstrap resampling where, for each interval $t$, bootstrap counts are independently drawn from a Poisson distribution with mean equal to the observed count $c_t$.\n\nScientific and computational requirements:\n- Use $B$ bootstrap replicates.\n- Use quantile probabilities $q_{\\ell}$ and $q_u$, where $q_{\\ell} \\in (0,1)$ and $q_u \\in (0,1)$ with $q_{\\ell} lt; q_u$, expressed as decimals (not with a percentage sign).\n- Break ties in peak identification by selecting the earliest index among those attaining the maximum.\n- Time units are intervals indexed by integers, which you must report as integer indices. Express the final peak time estimates and bounds as integer indices (unit: time intervals, with the first interval labeled $0$).\n\nTest suite:\nFor each test case, you are provided a tuple consisting of $(\\text{counts}, B, q_{\\ell}, q_u, s)$ where $\\text{counts}$ is the list of incident counts per interval, $B$ is the number of bootstrap replicates, $q_{\\ell}$ is the lower quantile probability, $q_u$ is the upper quantile probability, and $s$ is the random seed for reproducibility.\n\n- Test case $1$ (unimodal curve):\n  - $\\text{counts} = [\\,0,\\,1,\\,3,\\,7,\\,12,\\,20,\\,27,\\,23,\\,15,\\,9,\\,5,\\,3,\\,2,\\,1,\\,0\\,]$\n  - $B = 4000$\n  - $q_{\\ell} = 0.025$\n  - $q_u = 0.975$\n  - $s = 12345$\n\n- Test case $2$ (two equal peaks, tie handled by earliest index):\n  - $\\text{counts} = [\\,0,\\,2,\\,5,\\,9,\\,12,\\,15,\\,15,\\,12,\\,9,\\,5,\\,2,\\,0\\,]$\n  - $B = 4000$\n  - $q_{\\ell} = 0.025$\n  - $q_u = 0.975$\n  - $s = 67890$\n\n- Test case $3$ (flat zeros, boundary case):\n  - $\\text{counts} = [\\,0,\\,0,\\,0,\\,0,\\,0\\,]$\n  - $B = 4000$\n  - $q_{\\ell} = 0.025$\n  - $q_u = 0.975$\n  - $s = 13579$\n\nFinal output specification:\n- For each test case, output a list of three integers $[\\,\\hat{t}_{\\text{peak}},\\,L,\\,U\\,]$, where $\\hat{t}_{\\text{peak}}$ is the observed peak index, $L$ is the lower bound of the percentile BCI, and $U$ is the upper bound of the percentile BCI.\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, with each test case represented by its own bracketed list (e.g., $[\\,[\\,a,b,c\\,],\\,[\\,d,e,f\\,],\\,[\\,g,h,i\\,]\\,]$). All reported values must be integers in the specified unit (time intervals), with the first interval labeled $0$.", "solution": "The problem is well-defined, scientifically sound, and computationally feasible. All necessary data, parameters, and definitions are provided. The assumptions, such as modeling incident counts as independent Poisson random variables and using a parametric bootstrap for confidence interval estimation, are standard and appropriate within the field of epidemiology. The problem is therefore deemed **valid**.\n\nThe task is to compute the observed peak time and a percentile-based Bootstrap Confidence Interval (BCI) for the peak time of several epidemic curves. The peak time is defined as the earliest time index at which the maximum incident count occurs.\n\n**1. Theoretical Framework**\n\nLet the sequence of observed incident counts be denoted by $\\mathbf{c} = (c_0, c_1, \\ldots, c_{T-1})$, where $c_t$ is the count at time index $t$ and $T$ is the total number of time intervals.\n\n**Observed Peak Time Estimator ($\\hat{t}_{\\text{peak}}$):**\nThe peak time estimator, $\\hat{t}_{\\text{peak}}$, is defined as the earliest time index corresponding to the maximum observed count. Mathematically, this is expressed as:\n$$\n\\hat{t}_{\\text{peak}} = \\min \\{ t \\in \\{0, 1, \\ldots, T-1\\} \\mid c_t = \\max_{i=0}^{T-1} c_i \\}\n$$\nThis is equivalent to the `argmax` function in many numerical libraries, which returns the index of the first occurrence of the maximum value.\n\n**Parametric Bootstrap for Uncertainty Estimation:**\nThe problem specifies a parametric bootstrap procedure to quantify the uncertainty in the $\\hat{t}_{\\text{peak}}$ estimate. This involves the following assumptions and steps:\n\n- **Model Assumption:** Each observed count $c_t$ is treated as a realization of an independent Poisson random variable, $C_t \\sim \\text{Poisson}(\\lambda_t)$.\n- **Parameter Estimation:** The rate parameter $\\lambda_t$ of the Poisson distribution for each time $t$ is estimated by the observed count $c_t$. That is, $\\hat{\\lambda}_t = c_t$.\n- **Resampling:** A large number, $B$, of \"bootstrap replicates\" or synthetic epidemic curves are generated. For each replicate $b \\in \\{1, 2, \\ldots, B\\}$, a new sequence of counts $\\mathbf{c}^{*(b)} = (c_0^{*(b)}, c_1^{*(b)}, \\ldots, c_{T-1}^{*(b)})$ is created. Each synthetic count $c_t^{*(b)}$ is an independent random draw from the estimated distribution:\n$$\nc_t^{*(b)} \\sim \\text{Poisson}(\\hat{\\lambda}_t) = \\text{Poisson}(c_t)\n$$\n- **Bootstrap Distribution of the Estimator:** For each synthetic curve $\\mathbf{c}^{*(b)}$, the peak time estimator is re-calculated, yielding a bootstrap peak time $\\hat{t}_{\\text{peak}}^{*(b)}$.\n$$\n\\hat{t}_{\\text{peak}}^{*(b)} = \\min \\{ t \\in \\{0, 1, \\ldots, T-1\\} \\mid c_t^{*(b)} = \\max_{i=0}^{T-1} c_i^{*(b)} \\}\n$$\nThe collection of these $B$ values, $\\{\\hat{t}_{\\text{peak}}^{*(1)}, \\hat{t}_{\\text{peak}}^{*(2)}, \\ldots, \\hat{t}_{\\text{peak}}^{*(B)}\\}$, forms the empirical bootstrap distribution of the peak time.\n\n**Percentile Confidence Interval:**\nThe $(1 - (\\alpha_{\\ell} + \\alpha_u)) \\times 100\\%$ percentile BCI is constructed by taking the empirical quantiles of the sorted bootstrap distribution. Given lower and upper quantile probabilities $q_{\\ell}$ and $q_u$ (where, for a symmetric CI, $q_{\\ell} = \\alpha/2$ and $q_u = 1 - \\alpha/2$), the confidence interval bounds $[L, U]$ are:\n- $L$: The $q_{\\ell}$-th empirical quantile of the bootstrap distribution $\\{\\hat{t}_{\\text{peak}}^*\\}$.\n- $U$: The $q_u$-th empirical quantile of the bootstrap distribution $\\{\\hat{t}_{\\text{peak}}^*\\}$.\n\nThe final values for $\\hat{t}_{\\text{peak}}$, $L$, and $U$ must be reported as integers, as they represent time indices.\n\n**2. Algorithmic Implementation**\n\nFor each test case specified by $(\\text{counts}, B, q_{\\ell}, q_u, s)$:\n\n1.  **Initialization:** Set the random number generator seed to $s$ for reproducibility. Convert the input `counts` list to a NumPy array, let's call it $\\mathbf{c}_{\\text{obs}}$. Let $T$ be the length of this array.\n\n2.  **Calculate Observed Peak Time:** Compute $\\hat{t}_{\\text{peak}}$ from $\\mathbf{c}_{\\text{obs}}$ using `numpy.argmax()`, which directly implements the required definition (earliest index of the maximum).\n\n3.  **Bootstrap Loop:**\n    a. Initialize an empty list or array, `bootstrap_peak_times`, to store the peak time from each replicate.\n    b. Repeat $B$ times:\n        i. Generate a synthetic count vector $\\mathbf{c}^*$ of length $T$. This is done by drawing from Poisson distributions in a vectorized manner, where the $t$-th element is drawn from $\\text{Poisson}(c_{\\text{obs}, t})$. In NumPy, this is `rng.poisson(c_obs)`.\n        ii. Calculate the peak time for this synthetic vector, $\\hat{t}_{\\text{peak}}^* = \\text{np.argmax}(\\mathbf{c}^*)$.\n        iii. Append $\\hat{t}_{\\text{peak}}^*$ to the `bootstrap_peak_times` list.\n\n4.  **Determine Confidence Bounds:**\n    a. After the loop, convert `bootstrap_peak_times` to a NumPy array.\n    b. Calculate the lower bound $L$ and upper bound $U$ by computing the $q_{\\ell}$ and $q_u$ quantiles of the `bootstrap_peak_times` array. The `numpy.quantile()` function is used for this.\n    c. Convert the resulting quantile values, which may be floats due to interpolation, into integers as required by the problem statement. Truncation via casting to `int` is a direct and standard way to satisfy this.\n\n5.  **Format Output:** Store the triplet $[\\hat{t}_{\\text{peak}}, L, U]$ for the current test case. After processing all cases, format the collected results into the specified final string.\n\nThis procedure will be applied to each test case provided. The use of a fixed random seed $s$ ensures that the stochastic bootstrap process yields a deterministic and verifiable answer for each case. For the test case with all zero counts, the Poisson rate parameter $\\lambda$ is $0$ for all time points. A Poisson distribution with $\\lambda=0$ only produces the value $0$. Thus, every bootstrap replicate will also be a vector of zeros, and its peak time will always be $0$, leading to a confidence interval of $[0, 0]$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the observed peak time and a percentile-based Bootstrap Confidence Interval (BCI)\n    for the peak time of epidemic curves.\n    \"\"\"\n    \n    # Test suite: (counts, B, q_l, q_u, s)\n    test_cases = [\n        # Test case 1 (unimodal curve)\n        (\n            [0, 1, 3, 7, 12, 20, 27, 23, 15, 9, 5, 3, 2, 1, 0],\n            4000, 0.025, 0.975, 12345\n        ),\n        # Test case 2 (two equal peaks, tie handled by earliest index)\n        (\n            [0, 2, 5, 9, 12, 15, 15, 12, 9, 5, 2, 0],\n            4000, 0.025, 0.975, 67890\n        ),\n        # Test case 3 (flat zeros, boundary case)\n        (\n            [0, 0, 0, 0, 0],\n            4000, 0.025, 0.975, 13579\n        )\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        counts, B, q_l, q_u, s = case\n        \n        # Convert counts to a NumPy array\n        observed_counts = np.array(counts, dtype=np.int64)\n\n        # Step 1: Calculate the observed peak time (earliest index of max)\n        observed_peak_time = np.argmax(observed_counts)\n\n        # Step 2: Set up the random number generator for reproducibility\n        rng = np.random.default_rng(s)\n\n        # Step 3: Perform parametric bootstrap resampling\n        bootstrap_peak_times = np.zeros(B, dtype=np.int64)\n        \n        # In the edge case where all observed counts are 0, the Poisson parameter is 0.\n        # A Poisson(0) distribution always yields 0. Thus, every bootstrap sample will be\n        # all zeros, and the argmax will always be 0. We can optimize this.\n        if np.all(observed_counts == 0):\n            # bootstrap_peak_times is already initialized to all zeros.\n            pass\n        else:\n            for i in range(B):\n                # Generate one synthetic epidemic curve\n                # Each new count is drawn from a Poisson distribution with mean = observed count\n                synthetic_counts = rng.poisson(lam=observed_counts)\n                \n                # Calculate the peak time for the synthetic curve\n                bootstrap_peak_times[i] = np.argmax(synthetic_counts)\n\n        # Step 4: Construct the percentile confidence interval\n        # Calculate the lower and upper quantiles of the bootstrap distribution\n        # The problem requires integer indices as output. We cast the float result\n        # of the quantile function to int.\n        lower_bound = int(np.quantile(bootstrap_peak_times, q_l))\n        upper_bound = int(np.quantile(bootstrap_peak_times, q_u))\n        \n        # Step 5: Collect results for this case\n        result = [int(observed_peak_time), lower_bound, upper_bound]\n        all_results.append(result)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```", "id": "4590034"}]}