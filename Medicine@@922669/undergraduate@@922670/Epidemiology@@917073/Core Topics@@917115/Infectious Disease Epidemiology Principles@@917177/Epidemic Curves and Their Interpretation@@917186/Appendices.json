{"hands_on_practices": [{"introduction": "In the early stages of an outbreak, an epidemic curve often exhibits exponential growth. While the exponential growth rate, $r$, is a key parameter in mathematical models, the 'doubling time' is a more intuitive metric for communicating the epidemic's speed to the public and policymakers. This exercise [@problem_id:4590055] bridges this gap, guiding you to derive the doubling time from the growth rate and, crucially, to quantify the uncertainty in your estimate, a fundamental skill in epidemiological reporting.", "problem": "An outbreak is monitored by aggregating reported incident cases by day to build an epidemic curve. In the early phase when the susceptible fraction is large, the expected daily incidence can be approximated by an exponential growth model, $I(t) = I_{0} \\exp(r t)$, where $I(t)$ is the expected incidence at time $t$, $I_{0}$ is a positive constant, and $r$ is the exponential growth rate. The doubling time $T_{d}$ is defined as the time interval for which the expected incidence doubles under constant $r$. A Generalized Linear Model (GLM) with a log link fitted to the first $12$ days of the epidemic curve yields a growth rate estimate $\\hat{r} = 0.245$ day$^{-1}$ with standard error $s_{r} = 0.021$ day$^{-1}$. \n\nUsing only the exponential growth model and the definition of doubling time as the time $T_{d}$ satisfying $I(t + T_{d}) = 2 I(t)$, derive an expression for $T_{d}$ in terms of $r$. Then use first-order uncertainty propagation (the delta method) to derive the approximate standard error of the estimated doubling time $\\hat{T}_{d}$ in terms of $\\hat{r}$ and $s_{r}$. Finally, compute the numerical value of the estimated doubling time using $\\hat{r} = 0.245$. Round your answer to four significant figures. Express the final answer in days.", "solution": "The problem requires three-part reasoning: first, to derive an analytical expression for the doubling time $T_{d}$ from the exponential growth model; second, to derive an expression for the standard error of the estimated doubling time, $s_{\\hat{T}_{d}}$, using the delta method; and third, to compute the numerical value for the estimated doubling time $\\hat{T}_{d}$.\n\nThe problem statement has been validated and is found to be scientifically grounded, well-posed, objective, and contains all necessary information to proceed.\n\nFirst, we derive the expression for the doubling time $T_{d}$. The doubling time is defined as the time interval over which the incidence doubles. This is expressed by the equation $I(t + T_{d}) = 2 I(t)$.\nThe model for the expected incidence at time $t$ is given as:\n$$I(t) = I_{0} \\exp(r t)$$\nwhere $I_{0}$ is a positive constant and $r$ is the exponential growth rate.\n\nSubstituting this model into the definition of doubling time, we get:\n$$I_{0} \\exp(r (t + T_{d})) = 2 \\cdot I_{0} \\exp(r t)$$\nSince $I_{0}$ is a positive constant, we can divide both sides by $I_{0}$:\n$$\\exp(r (t + T_{d})) = 2 \\exp(r t)$$\nUsing the property of exponential functions $\\exp(a+b) = \\exp(a)\\exp(b)$, we can write the left side as:\n$$\\exp(r t) \\exp(r T_{d}) = 2 \\exp(r t)$$\nSince $\\exp(r t)$ is always positive, we can divide both sides by it:\n$$\\exp(r T_{d}) = 2$$\nTo solve for $T_{d}$, we take the natural logarithm of both sides:\n$$\\ln(\\exp(r T_{d})) = \\ln(2)$$\n$$r T_{d} = \\ln(2)$$\nFinally, isolating $T_{d}$ gives the expression in terms of $r$:\n$$T_{d} = \\frac{\\ln(2)}{r}$$\n\nSecond, we derive the approximate standard error of the estimated doubling time, denoted $\\hat{T}_{d}$. The relationship between the estimated doubling time $\\hat{T}_{d}$ and the estimated growth rate $\\hat{r}$ is given by the formula derived above:\n$$\\hat{T}_{d} = f(\\hat{r}) = \\frac{\\ln(2)}{\\hat{r}}$$\nTo find the standard error of $\\hat{T}_{d}$, we use the first-order uncertainty propagation formula, also known as the delta method. For a function $Y=f(X)$, the variance of $Y$ can be approximated as $\\text{Var}(Y) \\approx (\\frac{df}{dX})^{2} \\text{Var}(X)$. The standard error is the square root of the variance, so $s_{Y} \\approx |\\frac{df}{dX}| s_{X}$.\nIn our case, the variable is $\\hat{r}$ with standard error $s_{r}$, and the function is $T_{d}(r) = \\frac{\\ln(2)}{r}$. We need to compute the derivative of $T_{d}$ with respect to $r$:\n$$\\frac{dT_{d}}{dr} = \\frac{d}{dr} \\left( \\frac{\\ln(2)}{r} \\right) = \\ln(2) \\frac{d}{dr} (r^{-1})$$\n$$\\frac{dT_{d}}{dr} = \\ln(2) (-1 \\cdot r^{-2}) = -\\frac{\\ln(2)}{r^2}$$\nThe standard error of the estimated doubling time, $s_{\\hat{T}_{d}}$, is then approximated by:\n$$s_{\\hat{T}_{d}} \\approx \\left| \\frac{dT_{d}}{dr} \\right|_{r=\\hat{r}} s_{r}$$\n$$s_{\\hat{T}_{d}} \\approx \\left| -\\frac{\\ln(2)}{\\hat{r}^2} \\right| s_{r}$$\nSince the growth rate $\\hat{r}$ is positive, $\\hat{r}^2$ is positive, and $\\ln(2)$ is also positive. Therefore, the absolute value simplifies to:\n$$s_{\\hat{T}_{d}} \\approx \\frac{\\ln(2)}{\\hat{r}^2} s_{r}$$\nThis is the required expression for the approximate standard error of the estimated doubling time.\n\nThird, we compute the numerical value of the estimated doubling time $\\hat{T}_{d}$. We are given the estimated growth rate $\\hat{r} = 0.245 \\text{ day}^{-1}$. Using the formula for $T_{d}$:\n$$\\hat{T}_{d} = \\frac{\\ln(2)}{\\hat{r}}$$\nSubstituting the given value of $\\hat{r}$:\n$$\\hat{T}_{d} = \\frac{\\ln(2)}{0.245} \\text{ days}$$\nUsing the value $\\ln(2) \\approx 0.693147$:\n$$\\hat{T}_{d} \\approx \\frac{0.693147}{0.245} \\text{ days} \\approx 2.829172 \\text{ days}$$\nThe problem asks to round the answer to four significant figures.\nThe first four significant figures are $2$, $8$, $2$, and $9$. The fifth digit is $1$, so we round down.\n$$\\hat{T}_{d} \\approx 2.829 \\text{ days}$$", "answer": "$$\\boxed{2.829}$$", "id": "4590055"}, {"introduction": "The epidemic curve you see is rarely the curve of what is actually happening in real time, as there is an inevitable lag between when a person gets sick (onset date) and when their case is officially recorded (report date). This practice [@problem_id:4590082] explores the mathematical relationship between the 'onset curve' and the 'report curve' using the concept of convolution. Understanding this relationship is essential for correctly interpreting real-world surveillance data and avoiding misjudgments about the timing of an epidemic's peak.", "problem": "An outbreak in a city is monitored with two daily curves: an onset-date curve and a report-date curve. The onset-date curve represents expected incident onsets as a continuous-time function $I(t)$ (cases per day), centered around a calendar time $t$ measured in days. Each case is subject to an independent reporting delay $D$ (in days) from onset to report. The epidemiology team has estimated from a line list that the delays have empirical mean $\\mathbb{E}[D]=4$ days and variance $\\operatorname{Var}(D)=9$ days$^{2}$. Assume delays are independent of onset times.\n\nStarting from the core definitions of conditional expectation and the transformation from onset time $S$ to report time $T=S+D$, derive an integral expression for the expected report-date curve $R(t)$ as a function of $I(t)$ and the delay distribution. Using this expression, justify why the report-date curve is a smoothed and right-shifted version of the onset-date curve, and explain specifically why the right tail of the report-date curve lags the right tail of the onset-date curve.\n\nThen, specialize to the case where the onset-date curve $I(t)$ is well-approximated by a scaled normal function in $t$ with mean $\\mu_{I}$ and variance $\\sigma_{I}^{2}$, and the delay $D$ is approximately normal with mean $\\mu_{D}=4$ days and variance $\\sigma_{D}^{2}=9$ days$^{2}$. Under these assumptions and independence, determine the expected shift in the calendar time of the peak of the report-date curve relative to the peak of the onset-date curve.\n\nExpress your final numerical answer in days. No rounding is required; report the exact value.", "solution": "The problem requires a derivation of the relationship between an onset-date curve and a report-date curve, an interpretation of this relationship, and a specific calculation under normality assumptions. The validation of the problem statement is the first step.\n\n**Problem Validation**\n\n**Step 1: Extract Givens**\n- Onset-date curve: $I(t)$ (cases per day), a continuous-time function.\n- Report-date curve: $R(t)$, the expected report-date curve.\n- Reporting delay: $D$ (in days), a random variable.\n- Mean of delay: $\\mathbb{E}[D] = 4$ days.\n- Variance of delay: $\\operatorname{Var}(D) = 9$ days$^2$.\n- Relationship between onset time $S$ and report time $T$: $T = S + D$.\n- Assumption: Delay $D$ is independent of onset time $S$.\n- Specialization A: Onset curve $I(t)$ is a scaled normal function with mean $\\mu_{I}$ and variance $\\sigma_{I}^{2}$.\n- Specialization B: Delay $D$ is approximately normal with mean $\\mu_{D} = 4$ days and variance $\\sigma_{D}^{2} = 9$ days$^2$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is grounded in fundamental principles of epidemiology and probability theory. The modeling of a reported case curve as a convolution of an incidence curve and a delay distribution is a standard and robust technique in infectious disease surveillance.\n- **Well-Posed**: The problem is well-posed. It provides a clear theoretical framework and sufficient information to derive the required expressions and calculate the final quantity. The progression from a general derivation to a specific case is logically structured.\n- **Objective**: The problem is stated using precise, objective, and quantitative language.\n- **Flaw Analysis**:\n  1.  **Scientific/Factual Unsoundness**: None. The model is a valid and widely used simplification of reality.\n  2.  **Non-Formalizable/Irrelevant**: None. The problem is directly formalizable using probability theory and is central to the topic of epidemic curve interpretation.\n  3.  **Incomplete/Contradictory**: None. The provided data are sufficient and consistent. For instance, the general parameters $\\mathbb{E}[D]=4$ and $\\operatorname{Var}(D)=9$ are consistent with the specific parameters $\\mu_{D}=4$ and $\\sigma_{D}^{2}=9$ used in the second part.\n  4.  **Unrealistic/Infeasible**: None. The mean and variance of the reporting delay are plausible values for many real-world diseases.\n  5.  **Ill-Posed**: None. The assumptions of normality and independence lead to a unique, stable solution for the peak shift.\n  6.  **Pseudo-Profound/Trivial**: None. The problem requires a solid understanding of convolution, expectation, variance, and the properties of the normal distribution.\n  7.  **Outside Scientific Verifiability**: None. The derivation and result are mathematically verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A full solution will be provided.\n\n**Solution Derivation**\n\nLet $S$ be the random variable representing the time of disease onset for a randomly selected case, and let $D$ be the random variable for the reporting delay for that case. The time of report is then the random variable $T = S + D$.\n\nThe onset-date curve, $I(t)$, represents the rate of new cases with onset at time $t$. If we let $N$ be the total number of cases in the outbreak, $N = \\int_{-\\infty}^{\\infty} I(\\tau) d\\tau$, then the probability density function (PDF) of the onset time $S$ is $f_S(s) = \\frac{I(s)}{N}$. The report-date curve, $R(t)$, similarly corresponds to the PDF of the report time $T$, such that the PDF of $T$ is $f_T(t) = \\frac{R(t)}{N}$.\n\nThe problem states that the delay $D$ is independent of the onset time $S$. A fundamental theorem in probability theory states that the PDF of the sum of two independent random variables is the convolution of their individual PDFs. Let $f_D(d)$ be the PDF of the delay $D$. Then the PDF of the report time $T$ is given by:\n$$f_T(t) = (f_S * f_D)(t) = \\int_{-\\infty}^{\\infty} f_S(s) f_D(t-s) ds$$\nSubstituting the expressions for $f_S(s)$ and $f_T(t)$ in terms of $I(s)$ and $R(t)$:\n$$\\frac{R(t)}{N} = \\int_{-\\infty}^{\\infty} \\frac{I(s)}{N} f_D(t-s) ds$$\nMultiplying by $N$, we obtain the integral expression for the expected report-date curve $R(t)$:\n$$R(t) = \\int_{-\\infty}^{\\infty} I(s) f_D(t-s) ds$$\nThis is the convolution of the onset-date curve $I(t)$ and the delay distribution's PDF $f_D(t)$, commonly written as $R(t) = (I * f_D)(t)$. Since a delay must be non-negative, $f_D(d) = 0$ for $d  0$. This implies $f_D(t-s) = 0$ for $t-s  0$, or $s  t$. Therefore, the upper limit of integration can be set to $t$:\n$$R(t) = \\int_{-\\infty}^{t} I(s) f_D(t-s) ds$$\n\nNext, we justify why $R(t)$ is a smoothed and right-shifted version of $I(t)$. We analyze the mean and variance of the underlying time distributions. The mean time of the report curve corresponds to the expectation $\\mathbb{E}[T]$, and its spread corresponds to the variance $\\operatorname{Var}(T)$.\nThe mean onset time is $\\mathbb{E}[S]$ and the mean delay is $\\mathbb{E}[D]$. By the linearity of expectation:\n$$\\mathbb{E}[T] = \\mathbb{E}[S+D] = \\mathbb{E}[S] + \\mathbb{E}[D]$$\nSince $\\mathbb{E}[D]=4  0$, the mean time of the reports, $\\mathbb{E}[T]$, is greater than the mean time of the onsets, $\\mathbb{E}[S]$. This means the entire report curve $R(t)$ is shifted to the right (later in time) relative to the onset curve $I(t)$, centered around a point that is $\\mathbb{E}[D]$ days later. This explains the \"right-shifted\" property.\n\nFor the \"smoothed\" property, we examine the variance. Since $S$ and $D$ are independent, the variance of their sum is the sum of their variances:\n$$\\operatorname{Var}(T) = \\operatorname{Var}(S+D) = \\operatorname{Var}(S) + \\operatorname{Var}(D)$$\nWe are given that $\\operatorname{Var}(D) = 9 \\text{ days}^2$, which is a positive quantity. Therefore, $\\operatorname{Var}(T)  \\operatorname{Var}(S)$. Variance is a measure of the spread or dispersion of a distribution. A larger variance for the report times $T$ compared to the onset times $S$ means that the report curve $R(t)$ is more spread out and has a lower peak than the onset curve $I(t)$ (assuming the same total area under both curves). This process of increasing the spread and lowering the peak is precisely what is meant by \"smoothing\".\n\nThe right tail of the report-date curve lags the right tail of the onset-date curve because of the convolution operation. From $R(t) = \\int_{-\\infty}^{t} I(s) f_D(t-s) ds$, we see that the value of $R(t)$ at any time $t$ is a weighted average of past values of the onset curve $I(s)$ for $s  t$. Even after the onset curve $I(t)$ has peaked and declined to negligible levels, $R(t)$ can still be substantial. This occurs because cases that had their onset during the peak of the epidemic may experience long delays, as described by the tail of the delay distribution $f_D(d)$. These long-delay cases continue to be reported long after new onsets have ceased, creating a fatter, more slowly decaying right tail for the report curve $R(t)$.\n\nNow, we specialize to the case where both distributions are normal. The onset time $S$ follows a distribution whose PDF is proportional to $I(t)$, so we can state $S \\sim \\mathcal{N}(\\mu_{I}, \\sigma_{I}^{2})$. The delay $D$ is given as approximately normal, $D \\sim \\mathcal{N}(\\mu_{D}, \\sigma_{D}^{2})$, with $\\mu_{D}=4$ and $\\sigma_{D}^{2}=9$.\nA property of the normal distribution is that the sum of two independent normal random variables is also a normal random variable. Thus, the report time $T=S+D$ is normally distributed.\nThe mean of the resulting distribution is the sum of the means:\n$$\\mu_{T} = \\mu_{S} + \\mu_{D} = \\mu_{I} + \\mu_{D}$$\nThe variance of the resulting distribution is the sum of the variances:\n$$\\sigma_{T}^{2} = \\sigma_{S}^{2} + \\sigma_{D}^{2} = \\sigma_{I}^{2} + \\sigma_{D}^{2}$$\nTherefore, $T \\sim \\mathcal{N}(\\mu_{I} + \\mu_{D}, \\sigma_{I}^{2} + \\sigma_{D}^{2})$.\n\nThe peak of a normal distribution occurs at its mean.\n- The peak of the onset-date curve $I(t)$ occurs at time $t = \\mu_{I}$.\n- The peak of the report-date curve $R(t)$, which is proportional to the PDF of $T$, occurs at time $t = \\mu_{T} = \\mu_{I} + \\mu_{D}$.\n\nThe shift in the calendar time of the peak is the difference between the time of the report curve's peak and the time of the onset curve's peak:\n$$\\text{Shift} = (\\text{Peak time of } R(t)) - (\\text{Peak time of } I(t)) = \\mu_{T} - \\mu_{I}$$\nSubstituting the expression for $\\mu_{T}$:\n$$\\text{Shift} = (\\mu_{I} + \\mu_{D}) - \\mu_{I} = \\mu_{D}$$\nThe problem provides the value for the mean of the delay distribution, $\\mu_{D} = 4$ days. Therefore, the expected shift in the peak is $4$ days.\nThe fact that this shift depends only on the mean of the delay distribution and not its variance, nor on the parameters of the onset curve, is a direct consequence of the properties of convolution and expectation, which holds more generally, but is particularly simple to demonstrate in the case of normal distributions.", "answer": "$$\\boxed{4}$$", "id": "4590082"}, {"introduction": "Epidemiologists often aggregate data from multiple locations to assess the overall trend of an outbreak. However, this 'big picture' view can sometimes be deceptive, completely masking critical, opposing trends in different subgroups—a statistical pitfall known as Simpson's paradox. This exercise [@problem_id:4590632] provides a striking, hands-on example of this paradox in action, demonstrating why disaggregated analysis is crucial for effective public health surveillance and intervention.", "problem": "An infectious disease is spreading in two regions, labeled region A and region B. Assume a discrete-time renewal process with a two-point generation interval distribution such that the total infectiousness in region $i$ at time $t$ is given by $\\Lambda_{t}^{(i)} = w_{1} I_{t-1}^{(i)} + w_{2} I_{t-2}^{(i)}$, where $w_{1} = 0.7$ and $w_{2} = 0.3$, and $I_{t}^{(i)}$ is the incidence in region $i$ at time $t$. The effective reproduction number $R_{t}^{(i)}$ is defined by the renewal equation $I_{t}^{(i)} = R_{t}^{(i)} \\Lambda_{t}^{(i)}$. The combined (aggregated) incidence is $I_{t}^{\\mathrm{agg}} = I_{t}^{(A)} + I_{t}^{(B)}$, with combined infectiousness $\\Lambda_{t}^{\\mathrm{agg}} = w_{1} I_{t-1}^{\\mathrm{agg}} + w_{2} I_{t-2}^{\\mathrm{agg}}$, and combined reproduction number $R_{t}^{\\mathrm{agg}} = I_{t}^{\\mathrm{agg}} / \\Lambda_{t}^{\\mathrm{agg}}$.\n\nYou observe the following incidence counts (all counts are nonnegative integers):\n- Region A: $I_{-1}^{(A)} = 10$, $I_{0}^{(A)} = 50$, $I_{1}^{(A)} = 40$, $I_{2}^{(A)} = 50$.\n- Region B: $I_{-1}^{(B)} = 200$, $I_{0}^{(B)} = 180$, $I_{1}^{(B)} = 160$, $I_{2}^{(B)} = 120$.\n\nStarting from the definitions above:\n- Compute $R_{1}^{(A)}$, $R_{2}^{(A)}$, $R_{1}^{(B)}$, and $R_{2}^{(B)}$.\n- Compute $R_{1}^{\\mathrm{agg}}$ and $R_{2}^{\\mathrm{agg}}$.\n- Briefly reason whether the combined trend between $t=1$ and $t=2$ obscures the opposite regional trends (one region’s $R_{t}$ increasing while the other’s $R_{t}$ decreasing), illustrating Simpson’s paradox in this context.\n\nAs a hierarchical modeling remedy, model each region’s incidence at time $t$ as conditionally Poisson given its effective reproduction number, $I_{t}^{(i)} \\mid R_{t}^{(i)} \\sim \\mathrm{Poisson}\\!\\left(R_{t}^{(i)} \\Lambda_{t}^{(i)}\\right)$, and place a conjugate Gamma prior that is shared across regions, $R_{t}^{(i)} \\sim \\mathrm{Gamma}(a,b)$ with $a = 10$ and $b = 10$. Using only these assumptions and the incidence data above, derive the posterior mean of $R_{2}^{(A)}$ under this hierarchical Gamma–Poisson model. Round your final numerical answer to four significant figures. Express the final answer as a unitless quantity.", "solution": "The problem is evaluated to be valid as it is scientifically grounded in standard epidemiological models (the renewal equation), internally consistent, and provides all necessary information for a well-posed set of calculations. No flaws related to scientific soundness, completeness, or objectivity were found.\n\nThe problem is solved in four parts as requested. The given parameters are the generation interval weights $w_{1} = 0.7$ and $w_{2} = 0.3$. The total infectiousness in region $i$ at time $t$ is $\\Lambda_{t}^{(i)} = w_{1} I_{t-1}^{(i)} + w_{2} I_{t-2}^{(i)}$, and the effective reproduction number is $R_{t}^{(i)} = I_{t}^{(i)} / \\Lambda_{t}^{(i)}$.\n\nPart 1: Computation of regional effective reproduction numbers.\n\nFor Region A, we have the incidence data $I_{-1}^{(A)} = 10$, $I_{0}^{(A)} = 50$, $I_{1}^{(A)} = 40$, and $I_{2}^{(A)} = 50$.\nFirst, we compute the total infectiousness at times $t=1$ and $t=2$:\n$$\n\\Lambda_{1}^{(A)} = w_{1} I_{0}^{(A)} + w_{2} I_{-1}^{(A)} = (0.7)(50) + (0.3)(10) = 35 + 3 = 38\n$$\n$$\n\\Lambda_{2}^{(A)} = w_{1} I_{1}^{(A)} + w_{2} I_{0}^{(A)} = (0.7)(40) + (0.3)(50) = 28 + 15 = 43\n$$\nNow, we compute the effective reproduction numbers $R_{1}^{(A)}$ and $R_{2}^{(A)}$:\n$$\nR_{1}^{(A)} = \\frac{I_{1}^{(A)}}{\\Lambda_{1}^{(A)}} = \\frac{40}{38} = \\frac{20}{19} \\approx 1.0526\n$$\n$$\nR_{2}^{(A)} = \\frac{I_{2}^{(A)}}{\\Lambda_{2}^{(A)}} = \\frac{50}{43} \\approx 1.1628\n$$\n\nFor Region B, we have the incidence data $I_{-1}^{(B)} = 200$, $I_{0}^{(B)} = 180$, $I_{1}^{(B)} = 160$, and $I_{2}^{(B)} = 120$.\nThe total infectiousness at times $t=1$ and $t=2$ is:\n$$\n\\Lambda_{1}^{(B)} = w_{1} I_{0}^{(B)} + w_{2} I_{-1}^{(B)} = (0.7)(180) + (0.3)(200) = 126 + 60 = 186\n$$\n$$\n\\Lambda_{2}^{(B)} = w_{1} I_{1}^{(B)} + w_{2} I_{0}^{(B)} = (0.7)(160) + (0.3)(180) = 112 + 54 = 166\n$$\nThe effective reproduction numbers $R_{1}^{(B)}$ and $R_{2}^{(B)}$ are:\n$$\nR_{1}^{(B)} = \\frac{I_{1}^{(B)}}{\\Lambda_{1}^{(B)}} = \\frac{160}{186} = \\frac{80}{93} \\approx 0.8602\n$$\n$$\nR_{2}^{(B)} = \\frac{I_{2}^{(B)}}{\\Lambda_{2}^{(B)}} = \\frac{120}{166} = \\frac{60}{83} \\approx 0.7229\n$$\n\nPart 2: Computation of aggregated effective reproduction numbers.\n\nFirst, we compute the aggregated incidence $I_{t}^{\\mathrm{agg}} = I_{t}^{(A)} + I_{t}^{(B)}$:\n$I_{-1}^{\\mathrm{agg}} = 10 + 200 = 210$\n$I_{0}^{\\mathrm{agg}} = 50 + 180 = 230$\n$I_{1}^{\\mathrm{agg}} = 40 + 160 = 200$\n$I_{2}^{\\mathrm{agg}} = 50 + 120 = 170$\n\nNext, we compute the aggregated infectiousness $\\Lambda_{t}^{\\mathrm{agg}} = w_{1} I_{t-1}^{\\mathrm{agg}} + w_{2} I_{t-2}^{\\mathrm{agg}}$:\n$$\n\\Lambda_{1}^{\\mathrm{agg}} = w_{1} I_{0}^{\\mathrm{agg}} + w_{2} I_{-1}^{\\mathrm{agg}} = (0.7)(230) + (0.3)(210) = 161 + 63 = 224\n$$\n$$\n\\Lambda_{2}^{\\mathrm{agg}} = w_{1} I_{1}^{\\mathrm{agg}} + w_{2} I_{0}^{\\mathrm{agg}} = (0.7)(200) + (0.3)(230) = 140 + 69 = 209\n$$\nFinally, we compute the aggregated reproduction numbers $R_{1}^{\\mathrm{agg}}$ and $R_{2}^{\\mathrm{agg}}$:\n$$\nR_{1}^{\\mathrm{agg}} = \\frac{I_{1}^{\\mathrm{agg}}}{\\Lambda_{1}^{\\mathrm{agg}}} = \\frac{200}{224} = \\frac{25}{28} \\approx 0.8929\n$$\n$$\nR_{2}^{\\mathrm{agg}} = \\frac{I_{2}^{\\mathrm{agg}}}{\\Lambda_{2}^{\\mathrm{agg}}} = \\frac{170}{209} \\approx 0.8134\n$$\n\nPart 3: Analysis of trends and Simpson's Paradox.\n\nComparing the trends in the effective reproduction numbers from $t=1$ to $t=2$:\n- Region A: $R_{t}^{(A)}$ increases from approximately $1.05$ to $1.16$. This indicates accelerating epidemic growth.\n- Region B: $R_{t}^{(B)}$ decreases from approximately $0.86$ to $0.72$. This indicates a decelerating epidemic (decline).\n- Aggregated: $R_{t}^{\\mathrm{agg}}$ decreases from approximately $0.89$ to $0.81$. This indicates an overall decline.\n\nThe combined trend does indeed obscure the opposite regional trends. An analysis of only the aggregated data suggests the epidemic is waning overall, as indicated by the decreasing $R_{t}^{\\mathrm{agg}}$. However, this masks the critical fact that the epidemic is accelerating in Region A, where transmissibility is increasing. This reversal of trend upon aggregation is an illustration of Simpson's paradox. The discrepancy occurs because Region B has substantially higher incidence counts than Region A, so its declining trend dominates the calculation of the aggregated reproduction number. This demonstrates the potential for misleading conclusions when analyzing heterogeneous populations in aggregate.\n\nPart 4: Derivation of the posterior mean of $R_{2}^{(A)}$ under the hierarchical model.\n\nWe are given a hierarchical model where the prior for the reproduction number $R$ is a Gamma distribution and the likelihood for the incidence count $I$ is a Poisson distribution. Specifically, for region $A$ at time $t=2$, we have:\nPrior: $R_{2}^{(A)} \\sim \\mathrm{Gamma}(a, b)$, with shape $a=10$ and rate $b=10$.\nLikelihood: $I_{2}^{(A)} \\mid R_{2}^{(A)} \\sim \\mathrm{Poisson}(R_{2}^{(A)} \\Lambda_{2}^{(A)})$, with $I_{2}^{(A)} = 50$ and $\\Lambda_{2}^{(A)} = 43$.\n\nThe Gamma distribution is a conjugate prior to the Poisson likelihood. We can derive the posterior distribution for $R_{2}^{(A)}$. Let $R \\equiv R_{2}^{(A)}$, $I \\equiv I_{2}^{(A)}$, and $\\Lambda \\equiv \\Lambda_{2}^{(A)}$.\nThe prior probability density function (PDF) is $p(R) = \\frac{b^a}{\\Gamma(a)} R^{a-1} \\exp(-bR)$.\nThe likelihood function is $L(R \\mid I) = P(I \\mid R) = \\frac{(R\\Lambda)^I \\exp(-R\\Lambda)}{I!}$.\n\nAccording to Bayes' theorem, the posterior PDF, $p(R \\mid I)$, is proportional to the product of the likelihood and the prior:\n$p(R \\mid I) \\propto L(R \\mid I) p(R)$\n$p(R \\mid I) \\propto \\left( \\frac{(R\\Lambda)^I \\exp(-R\\Lambda)}{I!} \\right) \\left( \\frac{b^a}{\\Gamma(a)} R^{a-1} \\exp(-bR) \\right)$\n\nWe can drop the terms that do not depend on $R$ to find the kernel of the posterior distribution:\n$p(R \\mid I) \\propto (R\\Lambda)^I \\exp(-R\\Lambda) R^{a-1} \\exp(-bR)$\n$p(R \\mid I) \\propto R^I \\exp(-R\\Lambda) R^{a-1} \\exp(-bR)$\n$p(R \\mid I) \\propto R^{I+a-1} \\exp(-R(\\Lambda+b))$\n\nThis is the kernel of a Gamma distribution with updated parameters:\nShape: $a' = a + I$\nRate: $b' = b + \\Lambda$\nSo, the posterior distribution is $R \\mid I \\sim \\mathrm{Gamma}(a+I, b+\\Lambda)$.\n\nThe mean of a Gamma distribution with shape $a'$ and rate $b'$ is $\\mathbb{E}[R] = a'/b'$. Thus, the posterior mean of $R_{2}^{(A)}$ is:\n$$\n\\mathbb{E}[R_{2}^{(A)} \\mid I_{2}^{(A)}] = \\frac{a + I_{2}^{(A)}}{b + \\Lambda_{2}^{(A)}}\n$$\nSubstituting the given values: $a=10$, $b=10$, $I_{2}^{(A)}=50$, and $\\Lambda_{2}^{(A)}=43$.\n$$\n\\mathbb{E}[R_{2}^{(A)} \\mid I_{2}^{(A)}=50] = \\frac{10 + 50}{10 + 43} = \\frac{60}{53}\n$$\nThe numerical value is approximately $1.13207547...$. Rounding to four significant figures, we get $1.132$.", "answer": "$$\n\\boxed{1.132}\n$$", "id": "4590632"}]}