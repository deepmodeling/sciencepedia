{"hands_on_practices": [{"introduction": "Before we can correct for observer bias, we must first learn how to measure it. A key step in ensuring data quality is to assess the consistency between different observers, a concept known as inter-rater reliability. This practice introduces Cohen's kappa ($\\kappa$), a robust statistic that measures agreement between two raters while accounting for the possibility of agreement occurring by chance. By working through this exercise [@problem_id:4605389], you will gain a practical understanding of how to quantify the reliability of outcome assessment in a study, which is the first line of defense against observer-driven errors.", "problem": "A population-based cross-sectional study is conducted to assess a binary outcome (present versus absent) for a respiratory symptom. To evaluate potential interviewer and observer bias, two trained interviewers independently classify each participant’s outcome. Agreement beyond chance is quantified using Cohen’s kappa, denoted by $\\kappa$, which is a measure used in Inter-Rater Reliability (IRR). \n\nFrom a sample of $N = 100$ participants, the joint classification counts are as follows:\n- Both interviewers classify as outcome present: $40$.\n- Both interviewers classify as outcome absent: $50$.\n- Interviewer $1$ classifies present while Interviewer $2$ classifies absent: $5$.\n- Interviewer $1$ classifies absent while Interviewer $2$ classifies present: $5$.\n\nStarting from fundamental definitions of agreement probability, compute the observed agreement proportion and the expected agreement proportion under independence of interviewers given the marginal distributions. Then, derive Cohen’s kappa $\\kappa$ from these quantities. Express your final answer as an exact fraction. Do not convert to a percentage.", "solution": "To compute Cohen's kappa, $\\kappa$, we first organize the provided data into a $2 \\times 2$ contingency table. Let 'Present' be the positive classification and 'Absent' be the negative classification for the respiratory symptom.\n\nThe counts are:\n$a$: Interviewer $1$ 'Present', Interviewer $2$ 'Present' = $40$\n$b$: Interviewer $1$ 'Present', Interviewer $2$ 'Absent' = $5$\n$c$: Interviewer $1$ 'Absent', Interviewer $2$ 'Present' = $5$\n$d$: Interviewer $1$ 'Absent', Interviewer $2$ 'Absent' = $50$\n\nThe total number of participants is $N = a+b+c+d = 40+5+5+50 = 100$.\n\nThe contingency table is:\n|                   | Interviewer 2: Present | Interviewer 2: Absent | Row Totals      |\n|-------------------|:----------------------:|:---------------------:|:---------------:|\n| **Int 1: Present**| $a = 40$               | $b = 5$               | $n_{1P} = 45$   |\n| **Int 1: Absent** | $c = 5$                | $d = 50$              | $n_{1A} = 55$   |\n| **Column Totals** | $n_{2P} = 45$          | $n_{2A} = 55$         | $N = 100$       |\n\nHere, $n_{1P}$ is the number of times Interviewer $1$ classified as 'Present', $n_{1A}$ as 'Absent', and similarly for Interviewer $2$ with $n_{2P}$ and $n_{2A}$.\n\nThe first step is to calculate the observed agreement proportion, $P_o$. This is the proportion of participants for whom the two interviewers' classifications agree. Agreement occurs in cells $a$ and $d$.\n$$P_o = \\frac{a+d}{N}$$\nSubstituting the given values:\n$$P_o = \\frac{40+50}{100} = \\frac{90}{100} = \\frac{9}{10}$$\n\nThe second step is to calculate the expected agreement proportion, $P_e$, which is the hypothetical probability of agreement by chance. This calculation assumes that the interviewers' ratings are independent, given their individual marginal distributions of classifications.\nThe probability that Interviewer $1$ classifies as 'Present' is $P_{1P} = \\frac{n_{1P}}{N} = \\frac{45}{100}$.\nThe probability that Interviewer $1$ classifies as 'Absent' is $P_{1A} = \\frac{n_{1A}}{N} = \\frac{55}{100}$.\nThe probability that Interviewer $2$ classifies as 'Present' is $P_{2P} = \\frac{n_{2P}}{N} = \\frac{45}{100}$.\nThe probability that Interviewer $2$ classifies as 'Absent' is $P_{2A} = \\frac{n_{2A}}{N} = \\frac{55}{100}$.\n\nUnder independence, the probability that both classify as 'Present' is the product of their individual probabilities:\n$$P_{e,Present} = P_{1P} \\times P_{2P} = \\left(\\frac{45}{100}\\right) \\times \\left(\\frac{45}{100}\\right)$$\nThe probability that both classify as 'Absent' is:\n$$P_{e,Absent} = P_{1A} \\times P_{2A} = \\left(\\frac{55}{100}\\right) \\times \\left(\\frac{55}{100}\\right)$$\nThe total expected agreement proportion $P_e$ is the sum of these probabilities:\n$$P_e = P_{e,Present} + P_{e,Absent} = \\left(\\frac{45}{100}\\right)^2 + \\left(\\frac{55}{100}\\right)^2$$\n$$P_e = \\frac{45^2 + 55^2}{100^2} = \\frac{2025 + 3025}{10000} = \\frac{5050}{10000} = \\frac{505}{1000} = \\frac{101}{200}$$\n\nFinally, Cohen's kappa coefficient, $\\kappa$, is defined as the ratio of the actual agreement beyond chance ($P_o - P_e$) to the maximum possible agreement beyond chance ($1 - P_e$).\n$$\\kappa = \\frac{P_o - P_e}{1 - P_e}$$\nSubstituting the calculated values for $P_o$ and $P_e$:\n$$P_o - P_e = \\frac{9}{10} - \\frac{101}{200} = \\frac{9 \\times 20}{10 \\times 20} - \\frac{101}{200} = \\frac{180}{200} - \\frac{101}{200} = \\frac{79}{200}$$\n$$1 - P_e = 1 - \\frac{101}{200} = \\frac{200}{200} - \\frac{101}{200} = \\frac{99}{200}$$\nNow, we compute $\\kappa$:\n$$\\kappa = \\frac{\\frac{79}{200}}{\\frac{99}{200}} = \\frac{79}{99}$$\nThe fraction $\\frac{79}{99}$ is in its simplest form, since $79$ is a prime number and does not divide $99$.", "answer": "$$\\boxed{\\frac{79}{99}}$$", "id": "4605389"}, {"introduction": "Understanding the mechanism of bias is crucial for interpreting study results correctly. This exercise provides a hands-on demonstration of how interviewer bias can systematically distort a measure of association, specifically the odds ratio ($OR$) in a case-control study. You will explore a hypothetical scenario where an interviewer's knowledge of a participant's disease status leads to differential misclassification of their exposure history [@problem_id:4605310]. By calculating the observed odds ratio and comparing it to the true odds ratio, you will see firsthand how bias can create a misleading impression of the exposure-disease relationship, reinforcing the importance of blinding in study design.", "problem": "A case-control study investigates whether a binary exposure is associated with a disease. Assume a single interviewer knows case status and elicits exposure histories, leading to differential misclassification of exposure consistent with interviewer bias. Let the true exposure prevalences be $p_{1} = 0.45$ among cases and $p_{0} = 0.30$ among controls. The interviewer’s classification of exposure has sensitivity (Se) $0.95$ in cases and $0.75$ in controls, and specificity (Sp) $0.90$ in both groups.\n\nStarting from the core definitions of sensitivity, specificity, and the law of total probability, derive the expected observed exposure prevalences in cases and controls, compute the observed odds ratio (OR), calculated using the formula $OR = \\frac{p_1/(1-p_1)}{p_0/(1-p_0)}$ with the observed prevalences, and use this to predict the direction of bias relative to the true odds ratio. Round your final numerical odds ratio to four significant figures.", "solution": "The problem asks for the derivation of observed exposure prevalences under differential misclassification, the computation of the observed odds ratio, and the characterization of the resulting bias.\n\nFirst, let us define the relevant events and parameters with formal notation.\nLet $D$ be the event that an individual is a case, and $\\bar{D}$ be the event that an individual is a control.\nLet $E$ be the event of true exposure, and $E^*$ be the event of being classified as exposed (observed exposure).\nLet $\\bar{E}$ and $\\bar{E}^*$ be the complementary events of non-exposure and being classified as not exposed, respectively.\n\nThe problem provides the following givens:\nThe true prevalence of exposure among cases is $p_1 = P(E|D) = 0.45$.\nThe true prevalence of exposure among controls is $p_0 = P(E|\\bar{D}) = 0.30$.\n\nThe classification of exposure is subject to misclassification, characterized by sensitivity and specificity, which differ between cases and controls (differential misclassification).\nThe sensitivity of exposure classification among cases is $\\text{Se}_1 = P(E^*|E, D) = 0.95$.\nThe sensitivity of exposure classification among controls is $\\text{Se}_0 = P(E^*|E, \\bar{D}) = 0.75$.\nThe specificity of exposure classification is the same for both groups: $\\text{Sp} = P(\\bar{E}^*|\\bar{E}, D) = P(\\bar{E}^*|\\bar{E}, \\bar{D}) = 0.90$.\n\nFrom the specificity, we can determine the probability of a false positive classification, which is $1 - \\text{Sp}$.\n$P(E^*|\\bar{E}, D) = 1 - P(\\bar{E}^*|\\bar{E}, D) = 1 - \\text{Sp} = 1 - 0.90 = 0.10$.\n$P(E^*|\\bar{E}, \\bar{D}) = 1 - P(\\bar{E}^*|\\bar{E}, \\bar{D}) = 1 - \\text{Sp} = 1 - 0.90 = 0.10$.\n\nOur first goal is to derive the expected observed exposure prevalences, which are $p_1^* = P(E^*|D)$ for cases and $p_0^* = P(E^*|\\bar{D})$ for controls. We use the law of total probability, conditioning on the true exposure status $E$.\n\nFor cases:\nThe observed prevalence $p_1^*$ is the sum of probabilities of two mutually exclusive events: a truly exposed case being correctly classified, and a truly unexposed case being incorrectly classified.\n$$p_1^* = P(E^*|D) = P(E^*|E, D)P(E|D) + P(E^*|\\bar{E}, D)P(\\bar{E}|D)$$\nSubstituting the defined terms:\n$$p_1^* = (\\text{Se}_1)(p_1) + (1-\\text{Sp})(1-p_1)$$\nPlugging in the numerical values:\n$$p_1^* = (0.95)(0.45) + (0.10)(1 - 0.45)$$\n$$p_1^* = 0.4275 + (0.10)(0.55)$$\n$$p_1^* = 0.4275 + 0.055 = 0.4825$$\n\nFor controls:\nSimilarly, the observed prevalence $p_0^*$ is given by:\n$$p_0^* = P(E^*|\\bar{D}) = P(E^*|E, \\bar{D})P(E|\\bar{D}) + P(E^*|\\bar{E}, \\bar{D})P(\\bar{E}|\\bar{D})$$\nSubstituting the defined terms:\n$$p_0^* = (\\text{Se}_0)(p_0) + (1-\\text{Sp})(1-p_0)$$\nPlugging in the numerical values:\n$$p_0^* = (0.75)(0.30) + (0.10)(1 - 0.30)$$\n$$p_0^* = 0.225 + (0.10)(0.70)$$\n$$p_0^* = 0.225 + 0.07 = 0.295$$\n\nSo, the expected observed exposure prevalences are $0.4825$ in cases and $0.295$ in controls.\n\nNext, we compute the true odds ratio ($\\text{OR}_{\\text{true}}$) and the observed odds ratio ($\\text{OR}_{\\text{obs}}$) to predict the direction of bias.\nThe odds ratio is defined as $OR = \\frac{p_1/(1-p_1)}{p_0/(1-p_0)}$.\n\nThe true odds ratio is calculated using the true prevalences $p_1$ and $p_0$:\n$$\\text{OR}_{\\text{true}} = \\frac{p_1/(1-p_1)}{p_0/(1-p_0)} = \\frac{0.45/(1-0.45)}{0.30/(1-0.30)} = \\frac{0.45/0.55}{0.30/0.70}$$\nTo compute this exactly, we use fractions:\n$$\\text{OR}_{\\text{true}} = \\frac{45/55}{30/70} = \\frac{9/11}{3/7} = \\frac{9}{11} \\times \\frac{7}{3} = \\frac{21}{11} \\approx 1.9090...$$\n\nThe observed odds ratio is calculated using the observed prevalences $p_1^*$ and $p_0^*$:\n$$\\text{OR}_{\\text{obs}} = \\frac{p_1^*/(1-p_1^*)}{p_0^*/(1-p_0^*)} = \\frac{0.4825/(1-0.4825)}{0.295/(1-0.295)} = \\frac{0.4825/0.5175}{0.295/0.705}$$\nTo avoid floating-point errors, we convert these decimals to fractions:\n$0.4825 = \\frac{4825}{10000} = \\frac{193}{400}$ and $0.5175 = \\frac{5175}{10000} = \\frac{207}{400}$.\n$0.295 = \\frac{295}{1000} = \\frac{59}{200}$ and $0.705 = \\frac{705}{1000} = \\frac{141}{200}$.\nSubstituting these into the formula for $\\text{OR}_{\\text{obs}}$:\n$$\\text{OR}_{\\text{obs}} = \\frac{(193/400) / (207/400)}{(59/200) / (141/200)} = \\frac{193/207}{59/141} = \\frac{193}{207} \\times \\frac{141}{59}$$\nWe can simplify the fraction by finding common factors. Since $141 = 3 \\times 47$ and $207 = 3 \\times 69$:\n$$\\text{OR}_{\\text{obs}} = \\frac{193}{3 \\times 69} \\times \\frac{3 \\times 47}{59} = \\frac{193 \\times 47}{69 \\times 59} = \\frac{9071}{4071}$$\nConverting the final fraction to a decimal:\n$$\\text{OR}_{\\text{obs}} \\approx 2.228224...$$\nRounding to four significant figures, the observed odds ratio is $2.228$.\n\nFinally, to predict the direction of bias, we compare the observed odds ratio to the true odds ratio:\n$\\text{OR}_{\\text{obs}} \\approx 2.228$\n$\\text{OR}_{\\text{true}} \\approx 1.909$\nSince $\\text{OR}_{\\text{obs}} > \\text{OR}_{\\text{true}}$, the observed odds ratio is an overestimation of the true odds ratio. The interviewer bias, which resulted in differential misclassification (higher sensitivity of exposure detection in cases, $0.95$, than in controls, $0.75$), has caused a bias away from the null value of $\\text{OR}=1$, exaggerating the strength of the association between the exposure and the disease.", "answer": "$$\\boxed{2.228}$$", "id": "4605310"}, {"introduction": "While preventing bias is always the primary goal, epidemiologists have developed methods to correct for bias when it cannot be avoided. This practice moves from theory to application by demonstrating how to mathematically adjust for information bias using data from a validation substudy. Given observed risks and known values for sensitivity and specificity, you will derive and apply a formula to back-calculate the true, unbiased risk in both exposed and unexposed groups [@problem_id:4605378]. This powerful technique allows researchers to estimate the true measure of effect, providing a more accurate understanding of the association under investigation.", "problem": "A prospective cohort study evaluates the effect of an exposure on a binary health outcome that is ascertained by interviewers who are aware of participants’ exposure status. A validation substudy provides estimates of differential misclassification of the outcome due to observer bias: among exposed participants, the outcome assessment has sensitivity (probability of correctly classifying a truly diseased individual) $Se_{1}$ and specificity (probability of correctly classifying a truly non-diseased individual) $Sp_{1}$; among unexposed participants, sensitivity is $Se_{0}$ and specificity is $Sp_{0}$. Let $A \\in \\{0,1\\}$ denote exposure, $Y \\in \\{0,1\\}$ the true outcome, and $Y^{\\ast} \\in \\{0,1\\}$ the observed (possibly misclassified) outcome. The observed risks of the recorded outcome are $\\tilde{p}_{1} = \\mathbb{P}(Y^{\\ast} = 1 \\mid A=1)$ for the exposed and $\\tilde{p}_{0} = \\mathbb{P}(Y^{\\ast} = 1 \\mid A=0)$ for the unexposed. Assume that the validation parameters apply to the full cohort and that there is no other source of bias.\n\nStarting from the fundamental definitions of sensitivity and specificity and the law of total probability, derive expressions to back-calculate the corrected risks $p_{1} = \\mathbb{P}(Y=1 \\mid A=1)$ and $p_{0} = \\mathbb{P}(Y=1 \\mid A=0)$ in terms of $(\\tilde{p}_{a}, Se_{a}, Sp_{a})$ for $a \\in \\{0,1\\}$. Then, using the values $Se_{1} = 0.90$, $Sp_{1} = 0.95$, $Se_{0} = 0.80$, $Sp_{0} = 0.95$, $\\tilde{p}_{1} = 0.33$, and $\\tilde{p}_{0} = 0.18$, compute the bias-corrected risk ratio defined as $RR = p_1/p_0$. Provide your final answer as a simplified exact fraction. No rounding is required.", "solution": "The primary task is to derive an expression for the true risks of the outcome, $p_a = \\mathbb{P}(Y=1 \\mid A=a)$ for $a \\in \\{0,1\\}$, given the observed risks, $\\tilde{p}_a = \\mathbb{P}(Y^{\\ast}=1 \\mid A=a)$, and the parameters of differential outcome misclassification: sensitivities ($Se_0, Se_1$) and specificities ($Sp_0, Sp_1$).\n\nWe begin by applying the law of total probability to the observed risk, $\\tilde{p}_a$, conditioning on the true outcome status $Y$. For a given exposure status $A=a$, the probability of observing the outcome is the sum of the probability of observing it among truly diseased individuals and the probability of observing it among truly non-diseased individuals.\n\n$$ \\tilde{p}_a = \\mathbb{P}(Y^{\\ast}=1 \\mid A=a) = \\mathbb{P}(Y^{\\ast}=1 \\mid Y=1, A=a)\\mathbb{P}(Y=1 \\mid A=a) + \\mathbb{P}(Y^{\\ast}=1 \\mid Y=0, A=a)\\mathbb{P}(Y=0 \\mid A=a) $$\n\nWe can substitute the given definitions into this equation:\n- The true risk is $p_a = \\mathbb{P}(Y=1 \\mid A=a)$.\n- The probability of being truly non-diseased is $\\mathbb{P}(Y=0 \\mid A=a) = 1 - p_a$.\n- The sensitivity is $Se_a = \\mathbb{P}(Y^{\\ast}=1 \\mid Y=1, A=a)$.\n- The specificity is $Sp_a = \\mathbb{P}(Y^{\\ast}=0 \\mid Y=0, A=a)$. The probability of a false positive is therefore $1 - Sp_a = \\mathbb{P}(Y^{\\ast}=1 \\mid Y=0, A=a)$.\n\nSubstituting these terms into the equation yields:\n$$ \\tilde{p}_a = (Se_a)(p_a) + (1 - Sp_a)(1 - p_a) $$\n\nThis is a linear equation in $p_a$. We now solve for $p_a$ to derive the expression for the corrected risk.\n$$ \\tilde{p}_a = Se_a \\cdot p_a + 1 - Sp_a - p_a + p_a \\cdot Sp_a $$\n$$ \\tilde{p}_a = p_a (Se_a + Sp_a - 1) + (1 - Sp_a) $$\n$$ \\tilde{p}_a - (1 - Sp_a) = p_a (Se_a + Sp_a - 1) $$\n$$ p_a = \\frac{\\tilde{p}_a - 1 + Sp_a}{Se_a + Sp_a - 1} $$\nThis is the general formula for the bias-corrected risk, $p_a$, in terms of the observed risk, $\\tilde{p}_a$, and the stratum-specific sensitivity, $Se_a$, and specificity, $Sp_a$. The denominator, $Se_a + Sp_a - 1$, must be non-zero for the correction to be possible.\n\nNow, we use this formula and the provided numerical values to calculate the corrected risks for the exposed ($p_1$) and unexposed ($p_0$) groups. The given values are:\n- $Se_1 = 0.90$\n- $Sp_1 = 0.95$\n- $\\tilde{p}_1 = 0.33$\n- $Se_0 = 0.80$\n- $Sp_0 = 0.95$\n- $\\tilde{p}_0 = 0.18$\n\nFirst, we calculate the corrected risk in the exposed group ($a=1$):\n$$ p_1 = \\frac{\\tilde{p}_1 + Sp_1 - 1}{Se_1 + Sp_1 - 1} = \\frac{0.33 + 0.95 - 1}{0.90 + 0.95 - 1} = \\frac{0.28}{0.85} $$\nTo express this as an exact fraction:\n$$ p_1 = \\frac{28/100}{85/100} = \\frac{28}{85} $$\n\nNext, we calculate the corrected risk in the unexposed group ($a=0$):\n$$ p_0 = \\frac{\\tilde{p}_0 + Sp_0 - 1}{Se_0 + Sp_0 - 1} = \\frac{0.18 + 0.95 - 1}{0.80 + 0.95 - 1} = \\frac{0.13}{0.75} $$\nTo express this as an exact fraction:\n$$ p_0 = \\frac{13/100}{75/100} = \\frac{13}{75} $$\n\nFinally, we compute the bias-corrected risk ratio, $RR = p_1 / p_0$.\n$$ RR = \\frac{p_1}{p_0} = \\frac{28/85}{13/75} $$\n$$ RR = \\frac{28}{85} \\times \\frac{75}{13} $$\nWe can simplify this expression. Note that $85 = 5 \\times 17$ and $75 = 5 \\times 15$.\n$$ RR = \\frac{28}{5 \\times 17} \\times \\frac{5 \\times 15}{13} = \\frac{28 \\times 15}{17 \\times 13} $$\nNow, we perform the multiplication:\n$$ 28 \\times 15 = 420 $$\n$$ 17 \\times 13 = 17 \\times (10 + 3) = 170 + 51 = 221 $$\nSo the risk ratio is:\n$$ RR = \\frac{420}{221} $$\nThe prime factors of the denominator are $13$ and $17$. The numerator $420 = 2^2 \\times 3 \\times 5 \\times 7$ is not divisible by $13$ or $17$. Thus, the fraction is in its simplest form.", "answer": "$$\\boxed{\\frac{420}{221}}$$", "id": "4605378"}]}