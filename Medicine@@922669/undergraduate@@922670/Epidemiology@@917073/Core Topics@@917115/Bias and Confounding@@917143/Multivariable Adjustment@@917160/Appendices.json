{"hands_on_practices": [{"introduction": "The first and most crucial step in multivariable adjustment is deciding which covariates to include in your model. Directed Acyclic Graphs (DAGs) provide a rigorous, principle-based framework for this decision, moving beyond simple heuristics. This exercise [@problem_id:4612668] will guide you through applying the rules of causal inference to identify a valid adjustment set and, more importantly, to understand the critical error of conditioning on a collider.", "problem": "An investigator wants to identify the total causal effect of an exposure $A$ on an outcome $Y$ using a Directed Acyclic Graph (DAG). The measured covariates are $L_1$, $L_2$, and $L_3$. There is also an unmeasured variable $U$. The causal structure is as follows:\n- $L_1 \\to A$, $L_1 \\to Y$,\n- $L_3 \\to A$, $L_3 \\to Y$,\n- $A \\to Y$,\n- $A \\to L_2$, $U \\to L_2$, and $U \\to Y$,\nwith no other arrows. All variables $L_1$, $L_2$, and $L_3$ are distinct baseline or follow-up measurements as indicated by the arrows; specifically, $L_1$ and $L_3$ temporally precede $A$ and $Y$, while $L_2$ occurs after $A$. The variable $U$ is unmeasured and cannot be adjusted for. The goal is to decide whether adjusting for the set $S=\\{L_1,L_3\\}$ is valid for identifying the total causal effect of $A$ on $Y$, and to justify whether $L_2$ should be excluded from the adjustment set.\n\nUse the definitions of backdoor paths, colliders, and $d$-separation as your fundamental base: a backdoor path between $A$ and $Y$ is any path that starts with an arrow into $A$; a path is blocked by a set if it contains an unconditioned collider or any noncollider that is conditioned on; and a set $S$ is a valid adjustment set if it blocks all backdoor paths from $A$ to $Y$ without conditioning on descendants of $A$ when identifying the total causal effect.\n\nWhich statement is most accurate?\n\nA. $S=\\{L_1,L_3\\}$ is a valid adjustment set. $L_2$ should be excluded because it is a collider on the path $A \\to L_2 \\leftarrow U \\to Y$, and conditioning on $L_2$ would open that noncausal path.\n\nB. $S=\\{L_1,L_3\\}$ is not valid; $L_2$ must be included because it lies on a path between $A$ and $Y$, and adjusting for all variables associated with $A$ and $Y$ is required to remove confounding.\n\nC. $S=\\{L_1,L_3\\}$ is not valid because $L_1$ induces $M$-bias when adjusted for; one should exclude $L_1$ and adjust for $L_2$ instead.\n\nD. $S=\\{L_1,L_3\\}$ is valid only if one also adjusts for $L_2$ to block the path through $U$, since $U$ is unmeasured.", "solution": "The validity of the problem statement is established as follows.\n\n**Step 1: Extract Givens**\n-   **Exposure:** $A$\n-   **Outcome:** $Y$\n-   **Measured Covariates:** $L_1$, $L_2$, $L_3$\n-   **Unmeasured Covariate:** $U$\n-   **Proposed Adjustment Set:** $S = \\{L_1, L_3\\}$\n-   **Causal Structure (Directed Acyclic Graph - DAG):**\n    -   $L_1 \\to A$\n    -   $L_1 \\to Y$\n    -   $L_3 \\to A$\n    -   $L_3 \\to Y$\n    -   $A \\to Y$\n    -   $A \\to L_2$\n    -   $U \\to L_2$\n    -   $U \\to Y$\n-   **Temporal Information:** $L_1$ and $L_3$ precede $A$; $L_2$ occurs after $A$.\n-   **Definitions:**\n    -   A backdoor path from $A$ to $Y$ is a path starting with an arrow into $A$.\n    -   A path is blocked by a set if it contains an unconditioned collider or a conditioned non-collider.\n    -   A valid adjustment set $S$ for the total causal effect must block all backdoor paths from $A$ to $Y$ and must not contain any descendants of $A$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the established theory of causal inference using DAGs. The provided definitions are standard and internally consistent. The causal structure is explicitly given, and the question is precise and unambiguous. The problem is well-posed, as a unique solution can be derived from the given structure and rules. The temporal information is consistent with the DAG structure (e.g., $A \\to L_2$ is consistent with $L_2$ occurring after $A$). There are no contradictions, missing pieces of information, or violations of scientific principles.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. We will proceed with a full derivation and analysis.\n\n**Derivation**\n\nThe primary goal is to determine if the set $S = \\{L_1, L_3\\}$ is a valid adjustment set for estimating the total causal effect of $A$ on $Y$. According to the backdoor criterion for total effects, a set of covariates $S$ is valid if and only if two conditions are met:\n1.  $S$ blocks all backdoor paths between the exposure $A$ and the outcome $Y$.\n2.  No variable in $S$ is a descendant of the exposure $A$.\n\nFirst, we must identify all paths between $A$ and $Y$ in the provided DAG.\n\n**Path Identification and Analysis:**\n\n1.  **Causal Path:** $A \\to Y$. This is the direct effect of $A$ on $Y$, which is part of the total causal effect we wish to identify. This path should remain open.\n\n2.  **Backdoor Paths:** These are non-causal paths that have an arrow pointing into $A$.\n    -   **Path 1:** $A \\leftarrow L_1 \\to Y$. This is a backdoor path because it starts with an arrow into $A$. The variable $L_1$ is a common cause of $A$ and $Y$, thus acting as a confounding variable. This path is open by default because $L_1$ is a non-collider.\n    -   **Path 2:** $A \\leftarrow L_3 \\to Y$. This is also a backdoor path for the same reason as Path 1. $L_3$ is a common cause of $A$ and $Y$, acting as a confounder. This path is open by default.\n    -   There are no other backdoor paths. Any path that begins by moving backwards from $A$ must go via $L_1$ or $L_3$. From those nodes, the only path to $Y$ is the direct arrow.\n\n3.  **Other Non-Causal Paths:**\n    -   **Path 3:** $A \\to L_2 \\leftarrow U \\to Y$. This path is not a backdoor path because it begins with an arrow leaving $A$. The node $L_2$ on this path is a **collider** because two arrows point into it ($A \\to L_2$ and $U \\to L_2$). According to the rules of d-separation, a path containing an unconditioned collider is **blocked**. Therefore, this path is naturally blocked and does not create a spurious association between $A$ and $Y$.\n\n**Evaluating the Proposed Adjustment Set $S = \\{L_1, L_3\\}$:**\n\n-   **Condition 1 (Blocking Backdoor Paths):**\n    -   To block the backdoor path $A \\leftarrow L_1 \\to Y$, we must condition on the non-collider $L_1$. The set $S$ includes $L_1$, so this path is successfully blocked.\n    -   To block the backdoor path $A \\leftarrow L_3 \\to Y$, we must condition on the non-collider $L_3$. The set $S$ includes $L_3$, so this path is also blocked.\n    -   Since these are the only two backdoor paths, the set $S = \\{L_1, L_3\\}$ successfully blocks all backdoor paths. This condition is satisfied.\n\n-   **Condition 2 (No Descendants of A):**\n    -   A descendant of $A$ is any variable that can be reached by following a sequence of directed arrows starting from $A$.\n    -   From the DAG, the descendants of $A$ are $Y$ and $L_2$ (due to the arrow $A \\to L_2$).\n    -   The proposed set $S = \\{L_1, L_3\\}$ contains neither $Y$ nor $L_2$. The variables $L_1$ and $L_3$ are ancestors of $A$, not descendants.\n    -   Therefore, this condition is also satisfied.\n\n-   **Conclusion on $S$:** Because both conditions of the backdoor criterion are met, the set $S = \\{L_1, L_3\\}$ is a **valid adjustment set** for identifying the total causal effect of $A$ on $Y$.\n\n**Evaluating the Role of $L_2$:**\n\nNow, we must consider whether $L_2$ should be included or excluded from the adjustment set.\n-   As established, $L_2$ is a descendant of $A$. Adjusting for a descendant of the exposure is forbidden when identifying the *total* causal effect, as it would block a portion of the effect we aim to measure.\n-   Furthermore, consider the path $A \\to L_2 \\leftarrow U \\to Y$. We identified $L_2$ as a collider on this path, which means the path is blocked by default. If we were to condition on (adjust for) $L_2$, we would open this path. Opening this path creates a spurious, non-causal association between $A$ and $Y$ through the unmeasured common cause $U$. This phenomenon is known as collider-stratification bias or M-bias.\n-   Since $U$ is unmeasured, we cannot then block this newly opened path by adjusting for $U$. Thus, adjusting for $L_2$ would introduce bias into the estimate of the effect of $A$ on $Y$.\n-   Therefore, $L_2$ **must be excluded** from the adjustment set.\n\n**Option-by-Option Analysis**\n\n**A. $S=\\{L_1,L_3\\}$ is a valid adjustment set. $L_2$ should be excluded because it is a collider on the path $A \\to L_2 \\leftarrow U \\to Y$, and conditioning on $L_2$ would open that noncausal path.**\n-   Our analysis concluded that $S=\\{L_1,L_3\\}$ is a valid adjustment set.\n-   Our analysis also concluded that $L_2$ must be excluded, and the reason provided (it is a collider on a path involving an unmeasured variable $U$, and conditioning on it would open this path and induce bias) is precisely correct.\n-   Verdict: **Correct**.\n\n**B. $S=\\{L_1,L_3\\}$ is not valid; $L_2$ must be included because it lies on a path between $A$ and $Y$, and adjusting for all variables associated with $A$ and $Y$ is required to remove confounding.**\n-   This statement claims $S=\\{L_1,L_3\\}$ is not valid, which is false.\n-   It claims $L_2$ must be included, which is false.\n-   The reasoning \"adjusting for all variables associated with $A$ and $Y$\" is a common but incorrect heuristic. As shown, adjusting for $L_2$ would introduce bias, not remove it.\n-   Verdict: **Incorrect**.\n\n**C. $S=\\{L_1,L_3\\}$ is not valid because $L_1$ induces $M$-bias when adjusted for; one should exclude $L_1$ and adjust for $L_2$ instead.**\n-   This statement claims $S=\\{L_1,L_3\\}$ is not valid, which is false.\n-   The claim that adjusting for $L_1$ induces M-bias is incorrect. M-bias requires the adjusted variable to be a collider, but in the given DAG, no arrows point into $L_1$. $L_1$ is a standard confounder that must be adjusted for.\n-   The suggestion to adjust for $L_2$ is also incorrect.\n-   Verdict: **Incorrect**.\n\n**D. $S=\\{L_1,L_3\\}$ is valid only if one also adjusts for $L_2$ to block the path through $U$, since $U$ is unmeasured.**\n-   The premise that validity requires adjusting for $L_2$ is false. Adjusting for $L_2$ would introduce bias.\n-   The reasoning is also flawed. The path through $U$ ($A \\to L_2 \\leftarrow U \\to Y$) is already blocked because $L_2$ is an unconditioned collider. Adjusting for $L_2$ *opens* this path; it does not block it.\n-   Verdict: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4612668"}, {"introduction": "One of the most transparent methods for adjusting for confounding is direct standardization, which creates a 'fair' comparison by re-weighting the stratum-specific effects to a common population structure. It directly answers the question: what would the effect be if the confounder distribution was identical across exposure groups? This practice [@problem_id:4612700] provides a concrete, hands-on application of this logic, asking you to calculate an adjusted risk difference from first principles.", "problem": "An investigator studies the effect of an exposure on a binary health outcome in an observational cohort with two strata of a single confounder (for example, age categories). Let $x \\in \\{0,1\\}$ index exposure status, with $x=1$ for exposed and $x=0$ for unexposed, and let $l \\in \\{1,2\\}$ index the two strata. The stratum-specific risks (probabilities of the outcome within each stratum and exposure level) are given by $\\{r_{x,l}\\}$. A standard population distribution across strata is given by $\\{w_{l}\\}$, where $w_{l}$ represents the proportion of the standard population in stratum $l$ and satisfies $w_{1}+w_{2}=1$.\n\nFrom first principles, interpret direct standardization as computing the expected risk that would be observed if the stratum-specific risks for a given exposure level were applied to the standard population’s stratum distribution. Using this definition, and the definition of the risk difference as the difference between risks in the exposed and unexposed groups, compute the direct standardized risk difference for the following two-stratum example:\n- Exposed risks: $r_{1,1}=0.048$, $r_{1,2}=0.135$.\n- Unexposed risks: $r_{0,1}=0.022$, $r_{0,2}=0.081$.\n- Standard population weights: $w_{1}=0.55$, $w_{2}=0.45$.\n\nReport the direct standardized risk difference as a decimal. Round your answer to four significant figures. Do not use a percent sign.", "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a unique solution. The data are consistent, and the concepts are standard in epidemiology.\n\nThe problem asks for the computation of the direct standardized risk difference. This is achieved in three steps: First, we calculate the standardized risk for the exposed group. Second, we calculate the standardized risk for the unexposed group. Third, we take the difference between these two standardized risks.\n\nThe problem defines direct standardization as \"computing the expected risk that would be observed if the stratum-specific risks for a given exposure level were applied to the standard population’s stratum distribution.\" Let $R_S(x)$ denote the direct standardized risk for exposure level $x \\in \\{0, 1\\}$. The standard population has a distribution across strata $l \\in \\{1, 2\\}$ given by the weights $\\{w_l\\}$. The stratum-specific risks for exposure level $x$ are given by $\\{r_{x,l}\\}$. Following the definition, the standardized risk is the weighted average of the stratum-specific risks, where the weights are the proportions of the standard population in each stratum.\n\nFor a general exposure level $x$, the standardized risk $R_S(x)$ is given by the formula:\n$$ R_S(x) = \\sum_{l=1}^{2} w_l r_{x,l} = w_1 r_{x,1} + w_2 r_{x,2} $$\n\nFirst, we calculate the standardized risk for the exposed group ($x=1$). The given values are:\n- Stratum-specific risks for the exposed: $r_{1,1} = 0.048$ and $r_{1,2} = 0.135$.\n- Standard population weights: $w_1 = 0.55$ and $w_2 = 0.45$.\n\nSubstituting these values into the formula for $R_S(1)$:\n$$ R_S(1) = w_1 r_{1,1} + w_2 r_{1,2} = (0.55)(0.048) + (0.45)(0.135) $$\n$$ R_S(1) = 0.0264 + 0.06075 = 0.08715 $$\n\nSecond, we calculate the standardized risk for the unexposed group ($x=0$). The given values are:\n- Stratum-specific risks for the unexposed: $r_{0,1} = 0.022$ and $r_{0,2} = 0.081$.\n- The standard population weights remain $w_1 = 0.55$ and $w_2 = 0.45$.\n\nSubstituting these values into the formula for $R_S(0)$:\n$$ R_S(0) = w_1 r_{0,1} + w_2 r_{0,2} = (0.55)(0.022) + (0.45)(0.081) $$\n$$ R_S(0) = 0.0121 + 0.03645 = 0.04855 $$\n\nFinally, the direct standardized risk difference, which we denote as $RD_S$, is defined as the difference between the standardized risk in the exposed group and the standardized risk in the unexposed group:\n$$ RD_S = R_S(1) - R_S(0) $$\nSubstituting the calculated standardized risks:\n$$ RD_S = 0.08715 - 0.04855 = 0.0386 $$\n\nThe problem requires the answer to be reported as a decimal rounded to four significant figures. The calculated value is $0.0386$. The significant figures are $3$, $8$, and $6$. This is a total of three significant figures. To express this result with four significant figures, a trailing zero must be added.\n$$ RD_S \\approx 0.03860 $$\nThis is the direct standardized risk difference.", "answer": "$$\n\\boxed{0.03860}\n$$", "id": "4612700"}, {"introduction": "While statistical software makes running a multiple regression model seem simple, a deep understanding requires looking 'under the hood' to see how adjustment is mathematically achieved. This practice [@problem_id:4612709] demystifies the process by asking you to compute an adjusted effect estimate directly from the covariances between variables. By doing so, you will see precisely how a regression model isolates an exposure's effect from the influence of confounders.", "problem": "An observational cohort study investigates the association between a continuous outcome $Y$ and an exposure $X$, adjusting for two confounders $Z_{1}$ and $Z_{2}$. All variables are mean-centered so that the intercept in the linear model is zero. The analysis fits a multiple linear regression using Ordinary Least Squares (OLS), estimating coefficients $\\hat{\\beta}_{X}$, $\\hat{\\beta}_{Z_{1}}$, and $\\hat{\\beta}_{Z_{2}}$ in the model\n$$\nY = \\beta_{X} X + \\beta_{Z_{1}} Z_{1} + \\beta_{Z_{2}} Z_{2} + \\varepsilon,\n$$\nwhere $\\varepsilon$ is the random error term with mean zero.\n\nYou are given the sample covariance matrix of the regressors $\\Sigma$,\n$$\n\\Sigma = \n\\begin{pmatrix}\n4 & 3 & -4 \\\\\n3 & 9 & -6 \\\\\n-4 & -6 & 16\n\\end{pmatrix},\n$$\nwhere each entry is the empirical covariance $n^{-1}\\sum_{i=1}^{n} W_{i}^{(j)} W_{i}^{(k)}$ for $W^{(j)}, W^{(k)} \\in \\{X, Z_{1}, Z_{2}\\}$. You are also given the vector of empirical covariances between $Y$ and each regressor,\n$$\n\\begin{pmatrix}\n\\operatorname{Cov}(Y,X) \\\\\n\\operatorname{Cov}(Y,Z_{1}) \\\\\n\\operatorname{Cov}(Y,Z_{2})\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n8 \\\\\n-6 \\\\\n2\n\\end{pmatrix}.\n$$\n\nStarting from the defining properties of Ordinary Least Squares and the covariance identities for mean-centered variables, derive the normal equations that determine the OLS estimates and compute the adjusted effect estimate $\\hat{\\beta}_{X}$. Express your final answer as an exact value without rounding. No units are required.", "solution": "The problem requires the computation of the Ordinary Least Squares (OLS) estimate $\\hat{\\beta}_{X}$ for the coefficient of the exposure $X$ in the multiple linear regression model $Y = \\beta_{X} X + \\beta_{Z_{1}} Z_{1} + \\beta_{Z_{2}} Z_{2} + \\varepsilon$. All variables are stipulated to be mean-centered, which simplifies the underlying calculations.\n\nThe OLS method determines the coefficient estimates $(\\hat{\\beta}_{X}, \\hat{\\beta}_{Z_{1}}, \\hat{\\beta}_{Z_{2}})$ by minimizing the sum of squared residuals (SSR). For a sample of size $n$, the SSR is defined as:\n$$\nSSR = \\sum_{i=1}^{n} \\varepsilon_i^2 = \\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2 = \\sum_{i=1}^{n} (Y_i - (\\hat{\\beta}_{X} X_i + \\hat{\\beta}_{Z_{1}} Z_{1i} + \\hat{\\beta}_{Z_{2}} Z_{2i}))^2\n$$\nTo find the coefficients that minimize this quantity, we must take the partial derivative of the $SSR$ with respect to each coefficient and set the resulting expression to zero. This yields a system of equations known as the normal equations.\n\nThe partial derivative with respect to $\\hat{\\beta}_{X}$ is:\n$$\n\\frac{\\partial SSR}{\\partial \\hat{\\beta}_{X}} = -2 \\sum_{i=1}^{n} X_i (Y_i - \\hat{\\beta}_{X} X_i - \\hat{\\beta}_{Z_{1}} Z_{1i} - \\hat{\\beta}_{Z_{2}} Z_{2i}) = 0\n$$\nDividing by $-2n$ and applying the distributive property of the summation, we get:\n$$\n\\frac{1}{n} \\sum_{i=1}^{n} X_i Y_i - \\hat{\\beta}_{X} \\frac{1}{n} \\sum_{i=1}^{n} X_i^2 - \\hat{\\beta}_{Z_{1}} \\frac{1}{n} \\sum_{i=1}^{n} X_i Z_{1i} - \\hat{\\beta}_{Z_{2}} \\frac{1}{n} \\sum_{i=1}^{n} X_i Z_{2i} = 0\n$$\nFor any two mean-centered variables $A$ and $B$, their sample covariance is given by the formula $\\operatorname{Cov}(A,B) = \\frac{1}{n} \\sum_{i=1}^{n} A_i B_i$. The sample variance is a special case where $A=B$, i.e., $\\operatorname{Var}(A) = \\operatorname{Cov}(A,A) = \\frac{1}{n} \\sum_{i=1}^{n} A_i^2$. Using this, the equation transforms into:\n$$\n\\operatorname{Cov}(Y,X) = \\hat{\\beta}_{X} \\operatorname{Var}(X) + \\hat{\\beta}_{Z_{1}} \\operatorname{Cov}(X, Z_1) + \\hat{\\beta}_{Z_{2}} \\operatorname{Cov}(X, Z_2)\n$$\nThis derivation can be repeated for $\\hat{\\beta}_{Z_{1}}$ and $\\hat{\\beta}_{Z_{2}}$, yielding a system of three linear equations:\n$$\n\\operatorname{Cov}(Y,X) = \\hat{\\beta}_{X} \\operatorname{Var}(X) + \\hat{\\beta}_{Z_1} \\operatorname{Cov}(X, Z_1) + \\hat{\\beta}_{Z_{2}} \\operatorname{Cov}(X, Z_2)\n$$\n$$\n\\operatorname{Cov}(Y,Z_1) = \\hat{\\beta}_{X} \\operatorname{Cov}(Z_1, X) + \\hat{\\beta}_{Z_1} \\operatorname{Var}(Z_1) + \\hat{\\beta}_{Z_{2}} \\operatorname{Cov}(Z_1, Z_2)\n$$\n$$\n\\operatorname{Cov}(Y,Z_2) = \\hat{\\beta}_{X} \\operatorname{Cov}(Z_2, X) + \\hat{\\beta}_{Z_1} \\operatorname{Cov}(Z_2, Z_1) + \\hat{\\beta}_{Z_{2}} \\operatorname{Var}(Z_2)\n$$\nThis system can be written compactly in matrix form as $\\Sigma \\hat{\\boldsymbol{\\beta}} = \\mathbf{c}$, where $\\Sigma$ is the empirical covariance matrix of the regressors, $\\hat{\\boldsymbol{\\beta}}$ is the vector of coefficient estimates, and $\\mathbf{c}$ is the vector of empirical covariances between the outcome and the regressors.\n$$\n\\Sigma = \n\\begin{pmatrix}\n\\operatorname{Var}(X) & \\operatorname{Cov}(X,Z_1) & \\operatorname{Cov}(X,Z_2) \\\\\n\\operatorname{Cov}(Z_1,X) & \\operatorname{Var}(Z_1) & \\operatorname{Cov}(Z_1,Z_2) \\\\\n\\operatorname{Cov(Z_2,X)} & \\operatorname{Cov}(Z_2,Z_1) & \\operatorname{Var}(Z_2)\n\\end{pmatrix},\n\\quad\n\\hat{\\boldsymbol{\\beta}} = \n\\begin{pmatrix}\n\\hat{\\beta}_{X} \\\\\n\\hat{\\beta}_{Z_{1}} \\\\\n\\hat{\\beta}_{Z_{2}}\n\\end{pmatrix},\n\\quad\n\\mathbf{c} =\n\\begin{pmatrix}\n\\operatorname{Cov}(Y,X) \\\\\n\\operatorname{Cov}(Y,Z_{1}) \\\\\n\\operatorname{Cov}(Y,Z_{2})\n\\end{pmatrix}\n$$\nSubstituting the values provided in the problem statement, we obtain the specific linear system:\n$$\n\\begin{pmatrix}\n4 & 3 & -4 \\\\\n3 & 9 & -6 \\\\\n-4 & -6 & 16\n\\end{pmatrix}\n\\begin{pmatrix}\n\\hat{\\beta}_{X} \\\\\n\\hat{\\beta}_{Z_{1}} \\\\\n\\hat{\\beta}_{Z_{2}}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n8 \\\\\n-6 \\\\\n2\n\\end{pmatrix}\n$$\nTo solve for the component $\\hat{\\beta}_{X}$, we can utilize Cramer's rule, which states that $\\hat{\\beta}_{X} = \\frac{\\det(\\Sigma_X)}{\\det(\\Sigma)}$, where $\\Sigma_X$ is the matrix formed by replacing the first column of $\\Sigma$ with the vector $\\mathbf{c}$. First, we compute the determinant of $\\Sigma$:\n$$\n\\det(\\Sigma) = 4(9 \\cdot 16 - (-6)^2) - 3(3 \\cdot 16 - (-4)(-6)) + (-4)(3(-6) - 9(-4))\n$$\n$$\n\\det(\\Sigma) = 4(144 - 36) - 3(48 - 24) - 4(-18 + 36)\n$$\n$$\n\\det(\\Sigma) = 4(108) - 3(24) - 4(18) = 432 - 72 - 72 = 288\n$$\nNext, we form the matrix $\\Sigma_X$ and compute its determinant:\n$$\n\\Sigma_X = \n\\begin{pmatrix}\n8 & 3 & -4 \\\\\n-6 & 9 & -6 \\\\\n2 & -6 & 16\n\\end{pmatrix}\n$$\n$$\n\\det(\\Sigma_X) = 8(9 \\cdot 16 - (-6)^2) - 3((-6) \\cdot 16 - (-6) \\cdot 2) + (-4)((-6)(-6) - 9 \\cdot 2)\n$$\n$$\n\\det(\\Sigma_X) = 8(144 - 36) - 3(-96 + 12) - 4(36 - 18)\n$$\n$$\n\\det(\\Sigma_X) = 8(108) - 3(-84) - 4(18) = 864 + 252 - 72 = 1044\n$$\nFinally, we compute $\\hat{\\beta}_{X}$ as the ratio of these determinants and simplify the resulting fraction:\n$$\n\\hat{\\beta}_{X} = \\frac{\\det(\\Sigma_X)}{\\det(\\Sigma)} = \\frac{1044}{288} = \\frac{261}{72} = \\frac{29}{8}\n$$", "answer": "$$\\boxed{\\frac{29}{8}}$$", "id": "4612709"}]}