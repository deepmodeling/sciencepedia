{"hands_on_practices": [{"introduction": "This problem provides a foundational exercise in understanding the mechanics of selection bias. To effectively identify and correct for bias, we must first be able to describe it with mathematical precision. This practice guides you through the derivation of the exact multiplicative bias factor for a risk ratio when study selection is dependent on the outcome, a common and important form of bias encountered in many study designs. [@problem_id:4633341]", "problem": "Consider a cohort study with a binary exposure $X \\in \\{0,1\\}$, a binary outcome $Y \\in \\{0,1\\}$, and a binary selection indicator $S \\in \\{0,1\\}$ indicating whether an individual is included in the analytic sample. Let the target parameter be the population risk ratio $RR_{\\text{pop}} = \\frac{P(Y=1 \\mid X=1)}{P(Y=1 \\mid X=0)}$. Suppose selection depends only on the outcome, in the sense that $P(S=1 \\mid Y=y, X=x) = P(S=1 \\mid Y=y)$ for all $x \\in \\{0,1\\}$ and $y \\in \\{0,1\\}$, and consider the risk ratio computed in the selected sample, $RR_{\\text{sel}} = \\frac{P(Y=1 \\mid X=1, S=1)}{P(Y=1 \\mid X=0, S=1)}$. Define the multiplicative bias factor $BF$ for the risk ratio by the relationship $RR_{\\text{sel}} = RR_{\\text{pop}} \\times BF$. Starting only from the laws of conditional probability and Bayes’ theorem, derive $BF$ and express it in terms of the ratio $r = \\frac{P(S=1 \\mid Y=1)}{P(S=1 \\mid Y=0)}$ and the population risks $P(Y=1 \\mid X=1)$ and $P(Y=1 \\mid X=0)$. Provide your final expression for $BF$. No numerical approximation is required, and no units apply.", "solution": "The problem is valid as it is scientifically grounded in the principles of epidemiology and probability theory, is well-posed with sufficient and consistent information, and is stated objectively. We can therefore proceed with the derivation.\n\nOur goal is to derive an expression for the multiplicative bias factor, $BF$, defined by the relationship $RR_{\\text{sel}} = RR_{\\text{pop}} \\times BF$. The quantities $RR_{\\text{sel}}$ and $RR_{\\text{pop}}$ are the risk ratios in the selected sample and the total population, respectively.\n\nThe population risk ratio is given by:\n$$RR_{\\text{pop}} = \\frac{P(Y=1 \\mid X=1)}{P(Y=1 \\mid X=0)}$$\n\nThe risk ratio calculated in the selected sample (where the selection indicator $S=1$) is:\n$$RR_{\\text{sel}} = \\frac{P(Y=1 \\mid X=1, S=1)}{P(Y=1 \\mid X=0, S=1)}$$\n\nTo find the bias factor, we must first express the terms in $RR_{\\text{sel}}$ using population-level probabilities. Let us analyze the general term for the risk in the selected subpopulation, $P(Y=1 \\mid X=x, S=1)$, for a given exposure status $x \\in \\{0,1\\}$.\n\nUsing Bayes' theorem, we can reverse the conditioning on the event $S=1$:\n$$P(Y=1 \\mid X=x, S=1) = \\frac{P(S=1 \\mid Y=1, X=x) P(Y=1 \\mid X=x)}{P(S=1 \\mid X=x)}$$\n\nThe problem states that selection depends only on the outcome, which corresponds to the conditional independence statement $S \\perp X \\mid Y$. Formally, this is given as $P(S=1 \\mid Y=y, X=x) = P(S=1 \\mid Y=y)$ for all $x, y$. Applying this to the numerator of our expression, we have:\n$$P(S=1 \\mid Y=1, X=x) = P(S=1 \\mid Y=1)$$\n\nNext, we expand the denominator, $P(S=1 \\mid X=x)$, using the law of total probability by marginalizing over the outcome $Y$:\n$$P(S=1 \\mid X=x) = \\sum_{y \\in \\{0,1\\}} P(S=1, Y=y \\mid X=x)$$\n$$P(S=1 \\mid X=x) = P(S=1 \\mid Y=1, X=x) P(Y=1 \\mid X=x) + P(S=1 \\mid Y=0, X=x) P(Y=0 \\mid X=x)$$\nApplying the conditional independence assumption $S \\perp X \\mid Y$ again, we get:\n$$P(S=1 \\mid X=x) = P(S=1 \\mid Y=1) P(Y=1 \\mid X=x) + P(S=1 \\mid Y=0) P(Y=0 \\mid X=x)$$\nSince $Y$ is binary, $P(Y=0 \\mid X=x) = 1 - P(Y=1 \\mid X=x)$. Substituting this gives:\n$$P(S=1 \\mid X=x) = P(S=1 \\mid Y=1) P(Y=1 \\mid X=x) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=x))$$\n\nNow we substitute the simplified numerator and the expanded denominator back into the expression for the risk in the selected group:\n$$P(Y=1 \\mid X=x, S=1) = \\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=x)}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=x) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=x))}$$\n\nWith this general expression, we can construct $RR_{\\text{sel}}$ by taking the ratio for $x=1$ and $x=0$:\n$$RR_{\\text{sel}} = \\frac{P(Y=1 \\mid X=1, S=1)}{P(Y=1 \\mid X=0, S=1)}$$\nSubstituting our derived expressions:\n$$RR_{\\text{sel}} = \\frac{\\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=1)}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=1) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=1))}}{\\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=0)}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=0) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=0))}}$$\nThis complex fraction can be simplified. We rearrange the terms to isolate the population risk ratio:\n$$RR_{\\text{sel}} = \\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=1)}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=0)} \\times \\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=0) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=0))}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=1) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=1))}$$\nThe term $P(S=1 \\mid Y=1)$ cancels in the first fraction, leaving the population risk ratio, $RR_{\\text{pop}}$:\n$$RR_{\\text{sel}} = \\frac{P(Y=1 \\mid X=1)}{P(Y=1 \\mid X=0)} \\times \\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=0) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=0))}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=1) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=1))}$$\nBy comparing this to the definition $RR_{\\text{sel}} = RR_{\\text{pop}} \\times BF$, we can identify the bias factor $BF$ as:\n$$BF = \\frac{P(S=1 \\mid Y=1) P(Y=1 \\mid X=0) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=0))}{P(S=1 \\mid Y=1) P(Y=1 \\mid X=1) + P(S=1 \\mid Y=0) (1 - P(Y=1 \\mid X=1))}$$\n\nFinally, we must express $BF$ in terms of the specified ratio $r = \\frac{P(S=1 \\mid Y=1)}{P(S=1 \\mid Y=0)}$ and the population risks $P(Y=1 \\mid X=1)$ and $P(Y=1 \\mid X=0)$. To do this, we divide the numerator and the denominator of the expression for $BF$ by $P(S=1 \\mid Y=0)$, assuming $P(S=1 \\mid Y=0) \\neq 0$:\n$$BF = \\frac{\\frac{P(S=1 \\mid Y=1)}{P(S=1 \\mid Y=0)} P(Y=1 \\mid X=0) + (1 - P(Y=1 \\mid X=0))}{\\frac{P(S=1 \\mid Y=1)}{P(S=1 \\mid Y=0)} P(Y=1 \\mid X=1) + (1 - P(Y=1 \\mid X=1))}$$\nSubstituting $r$ into this expression yields the final result:\n$$BF = \\frac{r P(Y=1 \\mid X=0) + 1 - P(Y=1 \\mid X=0)}{r P(Y=1 \\mid X=1) + 1 - P(Y=1 \\mid X=1)}$$\nThis expression quantifies the multiplicative bias on the risk ratio that arises from selecting the study sample based on the outcome variable.", "answer": "$$\n\\boxed{\\frac{r P(Y=1 \\mid X=0) + 1 - P(Y=1 \\mid X=0)}{r P(Y=1 \\mid X=1) + 1 - P(Y=1 \\mid X=1)}}\n$$", "id": "4633341"}, {"introduction": "Building on theoretical derivations, this exercise grounds your understanding in a concrete numerical scenario. You will be presented with results from a hypothetical study where selection bias has distorted the findings, making an exposure appear more harmful than it truly is. Your task is to calculate the observed biased effect, quantify the distortion using a derived bias factor, and ultimately compute a corrected estimate that removes the selection bias. [@problem_id:4633382]", "problem": "An investigator studies the association between an exposure $E \\in \\{0,1\\}$ and a binary outcome $D \\in \\{0,1\\}$ in an observational cohort. Let $S \\in \\{0,1\\}$ indicate selection into the analyzed sample, where $S=1$ denotes inclusion. The investigator reports, among the selected individuals, that the risk of the outcome is $0.24$ in the exposed group and $0.08$ in the unexposed group. In symbols, $P(D=1 \\mid E=1, S=1)=0.24$ and $P(D=1 \\mid E=0, S=1)=0.08$. \n\nIt later becomes clear that selection into the analysis depended jointly on $E$ and $D$ through the following empirically supported probabilities:\n- $P(S=1 \\mid E=1, D=1)=0.90$,\n- $P(S=1 \\mid E=1, D=0)=0.30$,\n- $P(S=1 \\mid E=0, D=1)=0.30$,\n- $P(S=1 \\mid E=0, D=0)=0.20$.\n\nAssume the outcome is rare in the source population within levels of $E$ (rare outcome approximation), and that there is no other source of bias aside from selection. Using only core probability definitions and the definition of the risk ratio (risk ratio (RR) = $P(D=1 \\mid E=1)/P(D=1 \\mid E=0)$), proceed as follows:\n\n1. Compute the observed risk ratio among selected individuals, $\\mathrm{RR}_{\\text{obs}}$.\n2. Derive, from first principles and under the stated rare outcome approximation, the multiplicative selection bias factor $\\mathrm{BF}$ implied by the given selection probabilities, where the bias factor quantifies how selection multiplicatively distorts the risk ratio. Then compute $\\mathrm{BF}^{-1}$.\n3. Compute the selection-corrected risk ratio as $\\mathrm{RR}_{\\text{corr}}=\\mathrm{RR}_{\\text{obs}} \\times \\mathrm{BF}^{-1}$ and report this value.\n\nExpress the final answer as a single real number (no units, no percentage sign). If any approximation is needed, you may use the rare outcome approximation stated above; otherwise, provide exact values.", "solution": "The problem requires computing a selection-bias-corrected risk ratio from observed data and a set of known selection probabilities. The problem is well-posed, scientifically grounded in epidemiological principles, and provides all necessary data for a unique solution under the specified rare outcome approximation. Therefore, the problem is valid.\n\nThe solution proceeds in three steps as requested by the problem statement.\n\nStep 1: Compute the observed risk ratio, $\\mathrm{RR}_{\\text{obs}}$.\nThe observed risk ratio, $\\mathrm{RR}_{\\text{obs}}$, is the ratio of the risk of the outcome ($D=1$) in the exposed group ($E=1$) to the risk in the unexposed group ($E=0$), measured among the selected individuals ($S=1$). The problem provides these risks directly.\nGiven:\nRisk in exposed selected individuals: $P(D=1 \\mid E=1, S=1) = 0.24$\nRisk in unexposed selected individuals: $P(D=1 \\mid E=0, S=1) = 0.08$\n\nThe observed risk ratio is therefore:\n$$\n\\mathrm{RR}_{\\text{obs}} = \\frac{P(D=1 \\mid E=1, S=1)}{P(D=1 \\mid E=0, S=1)} = \\frac{0.24}{0.08} = 3\n$$\n\nStep 2: Derive the multiplicative selection bias factor, $\\mathrm{BF}$, and compute its inverse, $\\mathrm{BF}^{-1}$.\nThe selection bias factor, $\\mathrm{BF}$, is the multiplicative factor by which the true risk ratio, $\\mathrm{RR}$, is distorted to produce the observed risk ratio, $\\mathrm{RR}_{\\text{obs}}$. The true risk ratio is defined in the source population as $\\mathrm{RR} = \\frac{P(D=1 \\mid E=1)}{P(D=1 \\mid E=0)}$. The relationship is:\n$$\n\\mathrm{RR}_{\\text{obs}} = \\mathrm{RR} \\times \\mathrm{BF}\n$$\nTo derive $\\mathrm{BF}$, we express $\\mathrm{RR}_{\\text{obs}}$ in terms of the true risks and the selection probabilities. Using Bayes' theorem, we can write the risk conditional on selection as:\n$$\nP(D=1 \\mid E, S=1) = \\frac{P(S=1 \\mid D=1, E) P(D=1 \\mid E)}{P(S=1 \\mid E)}\n$$\nSubstituting this into the expression for $\\mathrm{RR}_{\\text{obs}}$:\n$$\n\\mathrm{RR}_{\\text{obs}} = \\frac{\\frac{P(S=1 \\mid D=1, E=1) P(D=1 \\mid E=1)}{P(S=1 \\mid E=1)}}{\\frac{P(S=1 \\mid D=1, E=0) P(D=1 \\mid E=0)}{P(S=1 \\mid E=0)}}\n$$\nRearranging the terms to isolate the true risk ratio, $\\mathrm{RR}$:\n$$\n\\mathrm{RR}_{\\text{obs}} = \\left( \\frac{P(D=1 \\mid E=1)}{P(D=1 \\mid E=0)} \\right) \\times \\left( \\frac{P(S=1 \\mid D=1, E=1)}{P(S=1 \\mid D=1, E=0)} \\right) \\times \\left( \\frac{P(S=1 \\mid E=0)}{P(S=1 \\mid E=1)} \\right)\n$$\n$$\n\\mathrm{RR}_{\\text{obs}} = \\mathrm{RR} \\times \\underbrace{\\left( \\frac{P(S=1 \\mid D=1, E=1)}{P(S=1 \\mid D=1, E=0)} \\right) \\times \\left( \\frac{P(S=1 \\mid E=0)}{P(S=1 \\mid E=1)} \\right)}_{\\mathrm{BF}}\n$$\nThe bias factor, $\\mathrm{BF}$, contains the terms $P(S=1 \\mid E=1)$ and $P(S=1 \\mid E=0)$, which need to be simplified. We expand these using the law of total probability, conditioning on the outcome $D$:\n$$\nP(S=1 \\mid E) = P(S=1 \\mid D=1, E)P(D=1 \\mid E) + P(S=1 \\mid D=0, E)P(D=0 \\mid E)\n$$\nSince $P(D=0 \\mid E) = 1 - P(D=1 \\mid E)$, this becomes:\n$$\nP(S=1 \\mid E) = P(S=1 \\mid D=1, E)P(D=1 \\mid E) + P(S=1 \\mid D=0, E)(1 - P(D=1 \\mid E))\n$$\nNow, we apply the \"rare outcome approximation\", which states that the outcome is rare in the source population within each stratum of exposure. This means $P(D=1 \\mid E=1) \\approx 0$ and $P(D=1 \\mid E=0) \\approx 0$.\nUnder this approximation:\n- $1 - P(D=1 \\mid E) \\approx 1$.\n- The term $P(S=1 \\mid D=1, E)P(D=1 \\mid E)$ becomes negligibly small compared to the second term.\nTherefore, the expression for $P(S=1 \\mid E)$ simplifies to:\n$$\nP(S=1 \\mid E) \\approx P(S=1 \\mid D=0, E)\n$$\nApplying this approximation for $E=1$ and $E=0$:\n$P(S=1 \\mid E=1) \\approx P(S=1 \\mid D=0, E=1)$\n$P(S=1 \\mid E=0) \\approx P(S=1 \\mid D=0, E=0)$\nSubstituting these approximations back into the formula for $\\mathrm{BF}$:\n$$\n\\mathrm{BF} \\approx \\left( \\frac{P(S=1 \\mid D=1, E=1)}{P(S=1 \\mid D=1, E=0)} \\right) \\times \\left( \\frac{P(S=1 \\mid D=0, E=0)}{P(S=1 \\mid D=0, E=1)} \\right)\n$$\nNow, we substitute the given numerical values for the selection probabilities:\n- $P(S=1 \\mid E=1, D=1) = 0.90$\n- $P(S=1 \\mid E=0, D=1) = 0.30$\n- $P(S=1 \\mid E=1, D=0) = 0.30$\n- $P(S=1 \\mid E=0, D=0) = 0.20$\n$$\n\\mathrm{BF} \\approx \\frac{0.90}{0.30} \\times \\frac{0.20}{0.30} = 3 \\times \\frac{2}{3} = 2\n$$\nThe problem requires the inverse of the bias factor, $\\mathrm{BF}^{-1}$:\n$$\n\\mathrm{BF}^{-1} \\approx \\frac{1}{2} = 0.5\n$$\n\nStep 3: Compute the selection-corrected risk ratio, $\\mathrm{RR}_{\\text{corr}}$.\nThe corrected risk ratio is defined as $\\mathrm{RR}_{\\text{corr}} = \\mathrm{RR}_{\\text{obs}} \\times \\mathrm{BF}^{-1}$. This is equivalent to solving for the true risk ratio, $\\mathrm{RR} = \\mathrm{RR}_{\\text{obs}} / \\mathrm{BF}$.\nUsing the results from the previous steps:\n$\\mathrm{RR}_{\\text{obs}} = 3$\n$\\mathrm{BF}^{-1} \\approx 0.5$\nTherefore, the selection-corrected risk ratio is:\n$$\n\\mathrm{RR}_{\\text{corr}} \\approx 3 \\times 0.5 = 1.5\n$$\nThis value represents the estimated risk ratio in the source population after accounting for the selection bias.", "answer": "$$\\boxed{1.5}$$", "id": "4633382"}, {"introduction": "This final practice transitions from static calculations to a dynamic, computational exploration of selection bias using Monte Carlo simulation. Simulations are a powerful tool in modern epidemiology for understanding the properties of estimators under various complex scenarios. In this exercise, you will implement a simulation to generate data under different mechanisms of selection bias, including collider bias, and compare the performance of naïve analysis, covariate adjustment, and inverse probability weighting (IPW) to correct for it. [@problem_id:4633363]", "problem": "You are asked to design and implement a Monte Carlo simulation study to quantify selection bias under outcome attrition and to compare three estimators of a marginal exposure effect: a naïve unadjusted complete-case estimator, an adjusted complete-case estimator, and an inverse probability weighting (IPW) estimator. The central phenomenon of interest is selection bias induced by informative attrition, particularly when the attrition probability depends on variables that also predict the outcome.\n\nFundamental base for the derivation: You must begin from the core definitions of selection bias, missingness mechanisms, and identification by conditioning or reweighting. Specifically: selection bias arises when conditioning on a variable that is a common effect (collider) of exposure and another predictor; missing at random given covariates means the missingness indicator is independent of the outcome conditional on observed covariates; inverse probability weighting recovers a target marginal distribution by reweighting each complete observation by the inverse of its probability of selection.\n\nData generating mechanism to be used in all simulations:\n- For each replicate, generate a sample of size $n$ with binary exposure $A \\in \\{0,1\\}$, baseline covariate $Z \\in \\mathbb{R}$, and possibly an unmeasured covariate $U \\in \\mathbb{R}$. Draw $A \\sim \\text{Bernoulli}(p_A)$, $Z \\sim \\mathcal{N}(0,1)$, and, when present, $U \\sim \\mathcal{N}(0,1)$ independent of $A$ and $Z$.\n- Generate a continuous outcome\n$$\nY \\;=\\; \\beta_0 \\;+\\; \\beta_A A \\;+\\; \\beta_Z Z \\;+\\; \\beta_U U \\;+\\; \\varepsilon,\n$$\nwhere $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$ is independent noise, and $\\beta_U$ is set to $0$ in scenarios without $U$.\n- Generate an attrition indicator $R \\in \\{0,1\\}$ such that $R=1$ indicates that $Y$ is observed. The selection model is logistic:\n$$\n\\Pr(R=1 \\mid A,Z,U) \\;=\\; \\operatorname{expit}\\left(\\alpha_0 + \\alpha_A A + \\alpha_Z Z + \\alpha_U U\\right),\n$$\nwith $\\operatorname{expit}(x)=\\frac{1}{1+e^{-x}}$. In scenarios without $U$, set $\\alpha_U=0$. The observed outcome is $Y_{\\text{obs}} = Y$ if $R=1$ and missing otherwise. The analyst always observes $(A,Z,R)$ for all individuals and $Y$ only when $R=1$.\n\nEstimand:\n- The target estimand is the marginal exposure effect\n$$\n\\Delta \\;=\\; \\mathbb{E}[Y \\mid A=1] \\;-\\; \\mathbb{E}[Y \\mid A=0].\n$$\nUnder the above linear model with $A$ independent of $Z$ and $U$, and with $\\mathbb{E}[Z]=0$ and $\\mathbb{E}[U]=0$, the estimand equals $\\Delta = \\beta_A$.\n\nEstimators to compare:\n- Naïve unadjusted complete-case estimator $\\widehat{\\Delta}_{\\text{naive}}$: the difference in sample means of $Y$ between $A=1$ and $A=0$ computed only among individuals with $R=1$, ignoring $Z$.\n- Adjusted complete-case estimator $\\widehat{\\Delta}_{\\text{cc}}$: the coefficient of $A$ from ordinary least squares regression of $Y$ on an intercept, $A$, and $Z$, fitted only on individuals with $R=1$.\n- IPW estimator $\\widehat{\\Delta}_{\\text{ipw}}$: define weights $w = 1/\\Pr(R=1 \\mid A,Z)$ for individuals with $R=1$ (only the measured predictors $A$ and $Z$ enter the weights). Estimate weighted means $\\widehat{\\mu}_a = \\sum_{i: R_i=1, A_i=a} w_i Y_i / \\sum_{i: R_i=1, A_i=a} w_i$ for $a \\in \\{0,1\\}$, and set $\\widehat{\\Delta}_{\\text{ipw}} = \\widehat{\\mu}_1 - \\widehat{\\mu}_0$. In scenarios where the selection model uses only $A$ and $Z$, use the true selection probabilities for weights. In the scenario where selection depends on an unmeasured $U$, compute weights using the misspecified model that omits $U$ (i.e., use $\\Pr(R=1 \\mid A,Z)$, which is incorrect), to illustrate residual bias.\n\nBias definition:\n- For each estimator $\\widehat{\\Delta}$, define bias as\n$\\text{bias}(\\widehat{\\Delta}) \\;=\\; \\mathbb{E}[\\widehat{\\Delta}] \\;-\\; \\Delta.$\nApproximate expectations by Monte Carlo averages across replicates.\n\nSimulation and test suite:\n- Fix the following constants across all simulations: $p_A = 0.5$, $\\beta_0 = 0$, $\\beta_A = 1$, $\\beta_Z = 1$, $\\sigma^2=1$. When present, set $\\beta_U=1$.\n- Use $n=5000$ individuals per replicate and $M=200$ replicates, with a fixed random number generator seed $12345$.\n- Implement the following five scenarios, each defined by $(\\alpha_0,\\alpha_A,\\alpha_Z,\\alpha_U,\\beta_U)$:\n    1. Scenario A (non-informative attrition): $(\\alpha_0,\\alpha_A,\\alpha_Z,\\alpha_U,\\beta_U) = (0.5, 0, 0, 0, 0)$.\n    2. Scenario B (attrition depends on exposure only): $(\\alpha_0,\\alpha_A,\\alpha_Z,\\alpha_U,\\beta_U) = (0, 1, 0, 0, 0)$.\n    3. Scenario C (attrition depends on covariate only): $(\\alpha_0,\\alpha_A,\\alpha_Z,\\alpha_U,\\beta_U) = (0, 0, 1, 0, 0)$.\n    4. Scenario D (collider-induced selection: depends on exposure and covariate): $(\\alpha_0,\\alpha_A,\\alpha_Z,\\alpha_U,\\beta_U) = (0, 1, 1, 0, 0)$.\n    5. Scenario E (missing not at random due to unmeasured predictor): $(\\alpha_0,\\alpha_A,\\alpha_Z,\\alpha_U,\\beta_U) = (0, 1, 1, 1, 1)$.\n- For scenarios A–D, compute IPW with the true $\\Pr(R=1 \\mid A,Z)$ as specified; for scenario E, compute IPW with the misspecified model that omits $U$, i.e., use $\\Pr(R=1 \\mid A,Z)$ instead of $\\Pr(R=1 \\mid A,Z,U)$.\n\nRequired outputs:\n- For each scenario, compute the Monte Carlo average bias for each estimator across the $M$ replicates. Denote these by $b_{\\text{naive}}, b_{\\text{cc}}, b_{\\text{ipw}}$. Aggregate the outputs for scenarios A through E into a single flat list of length $15$ in the following fixed order:\n$$\n[b_{\\text{naive}}^{(A)}, b_{\\text{cc}}^{(A)}, b_{\\text{ipw}}^{(A)}, b_{\\text{naive}}^{(B)}, b_{\\text{cc}}^{(B)}, b_{\\text{ipw}}^{(B)}, b_{\\text{naive}}^{(C)}, b_{\\text{cc}}^{(C)}, b_{\\text{ipw}}^{(C)}, b_{\\text{naive}}^{(D)}, b_{\\text{cc}}^{(D)}, b_{\\text{ipw}}^{(D)}, b_{\\text{naive}}^{(E)}, b_{\\text{cc}}^{(E)}, b_{\\text{ipw}}^{(E)} ].\n$$\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$x_1,x_2,\\dots,x_{15}$]\"). Express biases as real numbers (floats). No physical units are involved.\n\nScientific realism constraints:\n- Ensure that selection probabilities remain in the open interval $(0,1)$ via the logistic link.\n- Use the definitions for selection bias and missingness mechanisms as the fundamental base; do not rely on undocumented shortcuts or pre-derived bias formulas.\n\nYour task is to implement the simulation as specified and to print the required single-line output. No user input should be read by the program. Use the random seed and parameters exactly as specified to ensure reproducibility.", "solution": "The problem statement is valid. It presents a well-defined and scientifically grounded Monte Carlo simulation study to investigate selection bias in epidemiology. The data generating mechanism, estimand, and estimators are specified with mathematical precision, and the simulation parameters are complete. The scenarios are designed to illustrate fundamental concepts, such as collider bias and bias from unmeasured confounders, which are central to the study of causal inference and missing data. The problem is objective and requires a quantitative, reproducible solution.\n\nThe goal is to implement this simulation to quantify the bias of three distinct estimators for a marginal exposure effect, $\\Delta$, under five different scenarios of data attrition. The true value of the estimand is known to be $\\Delta = \\beta_A = 1$. The bias for any estimator $\\widehat{\\Delta}$ is computed via Monte Carlo approximation as $\\text{bias}(\\widehat{\\Delta}) = \\mathbb{E}[\\widehat{\\Delta}] - \\Delta \\approx \\left(\\frac{1}{M} \\sum_{j=1}^{M} \\widehat{\\Delta}^{(j)}\\right) - 1$, where $M=200$ is the number of simulation replicates.\n\nThe overall logical flow involves a nested loop structure. The outer loop iterates through the five specified scenarios, and the inner loop runs $M=200$ replicates for each scenario. Within each replicate, the following steps are executed:\n\n1.  **Data Generation**: A dataset of size $n=5000$ is generated according to the specified Data Generating Mechanism (DGM).\n    -   The binary exposure $A$ is drawn from a Bernoulli distribution, $A \\sim \\text{Bernoulli}(p_A)$, with $p_A=0.5$.\n    -   The baseline covariate $Z$ is drawn from a standard normal distribution, $Z \\sim \\mathcal{N}(0,1)$.\n    -   For Scenario E, an unmeasured covariate $U$ is also drawn from a standard normal distribution, $U \\sim \\mathcal{N}(0,1)$. For all other scenarios, its effect $\\beta_U$ is $0$.\n    -   An error term $\\varepsilon$ is drawn from a normal distribution with mean $0$ and variance $\\sigma^2=1$, i.e., $\\varepsilon \\sim \\mathcal{N}(0,1)$.\n    -   The continuous outcome $Y$ is generated as a linear function: $Y = \\beta_0 + \\beta_A A + \\beta_Z Z + \\beta_U U + \\varepsilon$, with parameters $\\beta_0=0$, $\\beta_A=1$, $\\beta_Z=1$, and $\\beta_U$ being $1$ for Scenario E and $0$ otherwise.\n    -   The attrition indicator $R \\in \\{0, 1\\}$ is generated from a Bernoulli trial where the probability of being observed ($R=1$) is given by a logistic model: $\\Pr(R=1 \\mid A,Z,U) = \\operatorname{expit}(\\alpha_0 + \\alpha_A A + \\alpha_Z Z + \\alpha_U U)$. The coefficients $(\\alpha_0, \\alpha_A, \\alpha_Z, \\alpha_U)$ are defined by the specific scenario.\n    -   The dataset available for analysis consists of $(A_i, Z_i, R_i)$ for all $i=1, \\dots, n$, and the outcome $Y_i$ only for those individuals with $R_i=1$.\n\n2.  **Estimation**: The marginal effect $\\Delta$ is estimated from the generated data using three different methods. All estimators operate on the complete-case subset of the data (where $R=1$).\n    -   **Naïve Unadjusted Estimator ($\\widehat{\\Delta}_{\\text{naive}}$)**: This is the simple difference in the sample mean of the observed outcomes $Y_{\\text{obs}}$ between the exposed ($A=1$) and unexposed ($A=0$) groups.\n        $$ \\widehat{\\Delta}_{\\text{naive}} = \\frac{\\sum_{i: R_i=1, A_i=1} Y_i}{\\sum_{i: R_i=1} I(A_i=1)} - \\frac{\\sum_{i: R_i=1, A_i=0} Y_i}{\\sum_{i: R_i=1} I(A_i=0)} $$\n    -   **Adjusted Complete-Case Estimator ($\\widehat{\\Delta}_{\\text{cc}}$)**: This estimator is the coefficient for the exposure $A$ obtained from an ordinary least squares (OLS) regression of the outcome $Y$ on an intercept, the exposure $A$, and the covariate $Z$. The regression is fitted only on the subset of individuals with $R=1$. This is implemented using `numpy.linalg.lstsq` on the model $Y_{\\text{obs}} \\sim \\beta'_0 + \\beta'_A A_{\\text{obs}} + \\beta'_Z Z_{\\text{obs}}$. $\\widehat{\\Delta}_{\\text{cc}}$ is the resulting estimate $\\beta'_A$.\n    -   **Inverse Probability Weighting Estimator ($\\widehat{\\Delta}_{\\text{ipw}}$)**: This estimator calculates a weighted difference of means among the complete cases. Each observed individual $i$ is assigned a weight $w_i$ equal to the inverse of their probability of being observed.\n        -   For Scenarios A–D, the weights are calculated using the true selection model, which depends only on $A$ and $Z$: $w_i = 1 / \\Pr(R_i=1 \\mid A_i, Z_i) = 1 / \\operatorname{expit}(\\alpha_0 + \\alpha_A A_i + \\alpha_Z Z_i)$.\n        -   For Scenario E, the true selection mechanism includes the unmeasured variable $U$. The IPW estimator is deliberately misspecified as instructed, using weights based on a model that omits $U$: $w_i = 1 / \\operatorname{expit}(\\alpha_0 + \\alpha_A A_i + \\alpha_Z Z_i)$, where the coefficients are those specified for Scenario E. This mimics an analysis where the researcher is unaware of $U$.\n        The estimate is then computed as $\\widehat{\\Delta}_{\\text{ipw}} = \\widehat{\\mu}_1 - \\widehat{\\mu}_0$, where $\\widehat{\\mu}_a = \\frac{\\sum_{i: R_i=1, A_i=a} w_i Y_i}{\\sum_{i: R_i=1, A_i=a} w_i}$.\n\n3.  **Bias Aggregation**: After the $M=200$ replicates are completed for a given scenario, the average estimate for each of the three methods is calculated. The bias is then found by subtracting the true effect $\\Delta=1$. This process is repeated for all five scenarios.\n\nThe final output is a flattened list containing the three computed bias values ($b_{\\text{naive}}, b_{\\text{cc}}, b_{\\text{ipw}}$) for each of the five scenarios, in the specified order. The implementation uses the `numpy` library for numerical operations and random number generation, and `scipy.special.expit` for the logistic function, adhering to the specified environment constraints. The random seed is fixed at $12345$ to ensure reproducibility.", "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Implements a Monte Carlo simulation to quantify selection bias for three estimators\n    of a marginal exposure effect across five scenarios of outcome attrition.\n    \"\"\"\n    \n    # --- Simulation Constants ---\n    N = 5000  # Sample size per replicate\n    M = 200   # Number of replicates\n    P_A = 0.5 # Probability of exposure A=1\n    BETA_0 = 0.0\n    BETA_A = 1.0 # True marginal effect (Delta)\n    BETA_Z = 1.0\n    SIGMA_SQ = 1.0\n    \n    SEED = 12345\n    rng = np.random.default_rng(SEED)\n\n    # --- Scenario Definitions ---\n    # Each scenario is (alpha_0, alpha_A, alpha_Z, alpha_U, beta_U)\n    scenarios = {\n        'A': {'alpha_0': 0.5, 'alpha_A': 0.0, 'alpha_Z': 0.0, 'alpha_U': 0.0, 'beta_U': 0.0}, # Non-informative\n        'B': {'alpha_0': 0.0, 'alpha_A': 1.0, 'alpha_Z': 0.0, 'alpha_U': 0.0, 'beta_U': 0.0}, # Depends on exposure\n        'C': {'alpha_0': 0.0, 'alpha_A': 0.0, 'alpha_Z': 1.0, 'alpha_U': 0.0, 'beta_U': 0.0}, # Depends on covariate\n        'D': {'alpha_0': 0.0, 'alpha_A': 1.0, 'alpha_Z': 1.0, 'alpha_U': 0.0, 'beta_U': 0.0}, # Collider-induced\n        'E': {'alpha_0': 0.0, 'alpha_A': 1.0, 'alpha_Z': 1.0, 'alpha_U': 1.0, 'beta_U': 1.0}, # Unmeasured predictor\n    }\n    \n    scenario_order = ['A', 'B', 'C', 'D', 'E']\n    all_biases = []\n\n    for scen_key in scenario_order:\n        params = scenarios[scen_key]\n        \n        estimates_naive = []\n        estimates_cc = []\n        estimates_ipw = []\n\n        for _ in range(M):\n            # 1. Generate Data\n            A = rng.binomial(1, P_A, N)\n            Z = rng.normal(0, 1, N)\n            \n            U = np.zeros(N)\n            if params['beta_U'] != 0:\n                U = rng.normal(0, 1, N)\n            \n            epsilon = rng.normal(0, np.sqrt(SIGMA_SQ), N)\n            \n            Y = BETA_0 + BETA_A * A + BETA_Z * Z + params['beta_U'] * U + epsilon\n            \n            logit_p_R = params['alpha_0'] + params['alpha_A'] * A + params['alpha_Z'] * Z + params['alpha_U'] * U\n            p_R = expit(logit_p_R)\n            R = rng.binomial(1, p_R, N)\n            \n            # 2. Filter for Complete Cases\n            observed_mask = (R == 1)\n            A_obs = A[observed_mask]\n            Z_obs = Z[observed_mask]\n            Y_obs = Y[observed_mask]\n            \n            # Handle rare cases where an exposure group has no observed subjects\n            if np.sum(A_obs == 1) == 0 or np.sum(A_obs == 0) == 0:\n                estimates_naive.append(np.nan)\n                estimates_cc.append(np.nan)\n                estimates_ipw.append(np.nan)\n                continue\n\n            # 3. Estimate Delta with three methods\n            \n            # 3.1 Naïve Unadjusted Complete-Case Estimator\n            mean_y_a1 = np.mean(Y_obs[A_obs == 1])\n            mean_y_a0 = np.mean(Y_obs[A_obs == 0])\n            delta_naive = mean_y_a1 - mean_y_a0\n            estimates_naive.append(delta_naive)\n            \n            # 3.2 Adjusted Complete-Case Estimator\n            X_cc = np.vstack([np.ones(len(A_obs)), A_obs, Z_obs]).T\n            try:\n                coeffs_cc = np.linalg.lstsq(X_cc, Y_obs, rcond=None)[0]\n                delta_cc = coeffs_cc[1]\n                estimates_cc.append(delta_cc)\n            except np.linalg.LinAlgError:\n                estimates_cc.append(np.nan)\n\n            # 3.3 IPW Estimator\n            # Calculate weights for observed subjects\n            A_for_weights = A[observed_mask]\n            Z_for_weights = Z[observed_mask]\n\n            if scen_key == 'E':\n                # Use misspecified model for weights, omitting U\n                logit_p_R_w = params['alpha_0'] + params['alpha_A'] * A_for_weights + params['alpha_Z'] * Z_for_weights\n            else:\n                # Use correctly specified model for weights\n                logit_p_R_w = params['alpha_0'] + params['alpha_A'] * A_for_weights + params['alpha_Z'] * Z_for_weights\n            \n            p_R_w = expit(logit_p_R_w)\n            weights = 1.0 / p_R_w\n            \n            mask_a1_obs = (A_obs == 1)\n            mask_a0_obs = (A_obs == 0)\n\n            # Weighted mean for A=1\n            sum_w_a1 = np.sum(weights[mask_a1_obs])\n            mu_1_ipw = np.sum(weights[mask_a1_obs] * Y_obs[mask_a1_obs]) / sum_w_a1 if sum_w_a1 > 0 else 0\n            \n            # Weighted mean for A=0\n            sum_w_a0 = np.sum(weights[mask_a0_obs])\n            mu_0_ipw = np.sum(weights[mask_a0_obs] * Y_obs[mask_a0_obs]) / sum_w_a0 if sum_w_a0 > 0 else 0\n\n            delta_ipw = mu_1_ipw - mu_0_ipw\n            estimates_ipw.append(delta_ipw)\n\n        # 4. Calculate Average Bias for the Scenario\n        # Use nanmean to be robust to any failed estimations\n        bias_naive = np.nanmean(estimates_naive) - BETA_A\n        bias_cc = np.nanmean(estimates_cc) - BETA_A\n        bias_ipw = np.nanmean(estimates_ipw) - BETA_A\n        \n        all_biases.extend([bias_naive, bias_cc, bias_ipw])\n\n    # 5. Format and Print Final Output\n    print(f\"[{','.join(map(str, all_biases))}]\")\n\nsolve()\n```", "id": "4633363"}]}