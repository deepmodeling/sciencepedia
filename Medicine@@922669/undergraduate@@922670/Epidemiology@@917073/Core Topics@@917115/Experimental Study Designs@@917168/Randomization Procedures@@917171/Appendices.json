{"hands_on_practices": [{"introduction": "Simple randomization, akin to flipping a fair coin for each participant, is the most basic method for assigning treatments in a clinical trial. To fully appreciate its strengths and weaknesses, we must first understand its statistical behavior. This practice guides you through deriving the expected group sizes and their variability, which are the foundational properties from which all other analyses of this method stem [@problem_id:4627424].", "problem": "A two-arm individually randomized controlled trial (RCT) in epidemiology enrolls $N$ subjects. Each subject $i \\in \\{1,2,\\dots,N\\}$ is assigned to the treatment arm independently with probability $p \\in (0,1)$, and otherwise to the control arm. Let the treatment indicator be $T_i \\in \\{0,1\\}$, where $T_i = 1$ denotes assignment to treatment and $T_i = 0$ denotes assignment to control. Define the sample treatment proportion as $$\\hat{\\pi} = \\frac{1}{N}\\sum_{i=1}^{N} T_i.$$\n\nStarting from the core definitions of expectation, variance, independence, and the properties of indicator variables, derive closed-form expressions for the expectation and variance of $T_i$ and for the expectation and variance of $\\hat{\\pi}$. Express your final answer as a single row vector in the order $$\\mathbb{E}[T_i],\\ \\operatorname{Var}(T_i),\\ \\mathbb{E}[\\hat{\\pi}],\\ \\operatorname{Var}(\\hat{\\pi}).$$\n\nProvide exact symbolic expressions; no numerical approximation or rounding is required. No physical units are involved.", "solution": "The problem specifies independent treatment assignment for each subject with probability $p$. This implies that, for each $i$, the treatment indicator $T_i$ is a Bernoulli random variable with parameter $p$, denoted $T_i \\sim \\operatorname{Bernoulli}(p)$, and $\\{T_i\\}_{i=1}^{N}$ are independent and identically distributed.\n\nWe begin with the core definitions:\n- For any random variable $X$, the expectation is $\\mathbb{E}[X]$.\n- The variance is $\\operatorname{Var}(X) = \\mathbb{E}[X^{2}] - (\\mathbb{E}[X])^{2}$.\n- For independent random variables $X_1,\\dots,X_N$, $\\operatorname{Var}\\left(\\sum_{i=1}^{N} X_i\\right) = \\sum_{i=1}^{N} \\operatorname{Var}(X_i)$.\n- For any scalar $a$, $\\operatorname{Var}(aX) = a^{2}\\operatorname{Var}(X)$ and $\\mathbb{E}[aX] = a\\,\\mathbb{E}[X]$.\n- For an indicator variable $I_A$ of an event $A$, $\\mathbb{E}[I_A] = \\Pr(A)$ and since $I_A \\in \\{0,1\\}$, $I_A^{2} = I_A$.\n\nExpectation and variance of $T_i$:\nSince $T_i$ indicates treatment assignment, $\\Pr(T_i=1) = p$ and $\\Pr(T_i=0) = 1-p$. Using the indicator property,\n$$\\mathbb{E}[T_i] = 1 \\cdot \\Pr(T_i=1) + 0 \\cdot \\Pr(T_i=0) = p.$$\nFor the variance,\n$$\\operatorname{Var}(T_i) = \\mathbb{E}[T_i^{2}] - (\\mathbb{E}[T_i])^{2}.$$\nBecause $T_i^{2} = T_i$ for $T_i \\in \\{0,1\\}$, we have $\\mathbb{E}[T_i^{2}] = \\mathbb{E}[T_i] = p$. Therefore,\n$$\\operatorname{Var}(T_i) = p - p^{2} = p(1-p).$$\n\nExpectation and variance of $\\hat{\\pi}$:\nDefine the sum of treatment indicators as $S_N = \\sum_{i=1}^{N} T_i$. Then $\\hat{\\pi} = \\frac{1}{N} S_N$. Using linearity of expectation,\n$$\\mathbb{E}\\left[\\frac{1}{N} \\sum_{i=1}^{N} T_i\\right] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}[T_i] = \\frac{1}{N} \\cdot N \\cdot p = p.$$\nFor the variance, using independence of $\\{T_i\\}_{i=1}^{N}$ and variance scaling,\n$$\\operatorname{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} T_i\\right) = \\frac{1}{N^{2}} \\sum_{i=1}^{N} \\operatorname{Var}(T_i) = \\frac{1}{N^{2}} \\cdot N \\cdot p(1-p) = \\frac{p(1-p)}{N}.$$\n\nAlternatively, one may observe that $S_N \\sim \\operatorname{Binomial}(N,p)$ by independence and identical Bernoulli trials, which yields $\\mathbb{E}[S_N] = Np$ and $\\operatorname{Var}(S_N) = Np(1-p)$; scaling by $1/N$ leads directly to the same $\\mathbb{E}[\\hat{\\pi}] = p$ and $\\operatorname{Var}(\\hat{\\pi}) = \\frac{p(1-p)}{N}$.\n\nCollecting the four quantities in the requested order gives\n$$\\mathbb{E}[T_i] = p,\\quad \\operatorname{Var}(T_i) = p(1-p),\\quad \\mathbb{E}[\\hat{\\pi}] = p,\\quad \\operatorname{Var}(\\hat{\\pi}) = \\frac{p(1-p)}{N}.$$", "answer": "$$\\boxed{\\begin{pmatrix} p & p(1-p) & p & \\frac{p(1-p)}{N} \\end{pmatrix}}$$", "id": "4627424"}, {"introduction": "While simple randomization is unbiased in the long run, it does not guarantee balance in any single trial, a problem that becomes particularly acute in small studies or centers. This exercise asks you to quantify the risk of a severe imbalance occurring by chance in a small group of participants. Understanding this probability highlights a key practical limitation of simple randomization and motivates the search for alternative procedures [@problem_id:4627370].", "problem": "A multicenter Randomized Controlled Trial (RCT) assigns participants to a treatment arm or a control arm using simple randomization, meaning each participant independently has probability $0.5$ of being assigned to the treatment arm and probability $0.5$ of being assigned to the control arm. Consider a small clinical center that will enroll exactly $6$ participants. Define a center to have a complete imbalance if all $6$ participants in that center end up in the same arm (either all treatment or all control).\n\nUsing only fundamental probability principles (independence of assignments and basic counting of equally likely outcomes), derive the probability that this center experiences complete imbalance under simple randomization. Then, based on your derivation and the core idea of permuted block randomization within centers, propose a concrete safeguard using permuted blocks that eliminates complete imbalance for this center and briefly justify why it works, without performing any additional numerical computation.\n\nProvide your final probability as a reduced fraction. Do not round. Your final answer must be a single real-valued number.", "solution": "Under simple randomization, each participant’s allocation is an independent Bernoulli trial with success probability $0.5$ for the treatment arm and $0.5$ for the control arm. For $6$ participants, there are $2^{6}$ equally likely treatment assignment sequences because each participant has $2$ possible assignments and the $6$ assignments are independent.\n\nA complete imbalance occurs if all $6$ participants are assigned to the treatment arm or if all $6$ participants are assigned to the control arm. There are exactly $2$ such sequences: one in which all $6$ are treatment and one in which all $6$ are control.\n\nBy the classical definition of probability on a finite sample space with equally likely outcomes, the probability of complete imbalance is the ratio of the number of favorable sequences to the total number of sequences:\n$$\nP(\\text{complete imbalance}) \\;=\\; \\frac{2}{2^{6}} \\;=\\; 2^{1-6} \\;=\\; \\frac{1}{32}.\n$$\n\nSafeguard using permuted blocks: Implement permuted block randomization within the center using a fixed block size $b=4$ with equal allocation within each block. In a permuted block of size $4$, each block contains exactly $2$ treatment and $2$ control assignments in a random order. Because the center enrolls $6$ participants, at least one complete block of size $4$ will be filled, guaranteeing that the center has at least $2$ treatment and $2$ control assignments among the first $4$ participants. The remaining $2$ participants belong to the next block and cannot undo the presence of both arms in the center’s accumulated assignments. Therefore, under permuted blocks of size $b=4$ within the center, the probability of complete imbalance is $0$ for this center. This conclusion follows directly from the enforced balance within each complete block and does not require any additional numerical calculation.", "answer": "$$\\boxed{\\frac{1}{32}}$$", "id": "4627370"}, {"introduction": "Block randomization is a popular solution to the problem of imbalance, as it forces the number of participants in each arm to be equal at regular intervals. However, this very mechanism can create a new vulnerability: predictability, which may allow investigators to guess the next treatment assignment. This practice challenges you to calculate the probability of correctly guessing the next assignment, revealing a critical aspect of maintaining allocation concealment in clinical trials [@problem_id:4627374].", "problem": "A two-arm randomized clinical trial uses fixed block randomization with equal allocation within each block. Let the block size be $b$, where $b$ is an even positive integer. Within each block, exactly $b/2$ participants are assigned to treatment $A$ and exactly $b/2$ to treatment $B$, and the order within a block is generated as a uniformly random permutation of these $b$ labels.\n\nConsider the current, partially filled block. Suppose that $k$ participants in the current block have already been assigned, with $a$ assigned to treatment $A$ and $k-a$ assigned to treatment $B$. Assume $0 \\leq k \\leq b-1$, $0 \\leq a \\leq \\min\\{k, b/2\\}$, and $k-a \\leq b/2$. A recruiter knows $b$, $k$, and $a$, but not the concealed assignment order. The recruiter will make a single guess for the next participant’s assignment using the strategy that maximizes the probability of guessing correctly.\n\nUsing only core definitions of fixed block randomization and basic conditional probability for sampling without replacement from a finite population, derive a closed-form analytic expression for this maximum probability of a correct guess as a function of $b$, $k$, and $a$. Express your final answer as a single simplified analytic expression. Do not round and do not include units.", "solution": "A block of size $b$ contains $b/2$ assignments to treatment A and $b/2$ to treatment B. The sequence of these assignments is a uniformly random permutation.\n\nAfter $k$ assignments have been revealed, there are $b-k$ assignments remaining in the block.\nThe number of assignments to treatment A that have already occurred is $a$. Therefore, the number of remaining assignments to treatment A is:\n$$N_A = \\frac{b}{2} - a$$\nThe number of assignments to treatment B that have already occurred is $k-a$. Therefore, the number of remaining assignments to treatment B is:\n$$N_B = \\frac{b}{2} - (k-a) = \\frac{b}{2} - k + a$$\nThe total number of remaining assignments is $N_A + N_B = (\\frac{b}{2} - a) + (\\frac{b}{2} - k + a) = b-k$.\n\nSince the initial sequence was a random permutation, the next assignment is equivalent to drawing one label from the $b-k$ remaining labels. The probability that the next assignment is to treatment A is:\n$$P(\\text{next is A}) = \\frac{N_A}{b-k} = \\frac{\\frac{b}{2} - a}{b - k}$$\nThe probability that the next assignment is to treatment B is:\n$$P(\\text{next is B}) = \\frac{N_B}{b-k} = \\frac{\\frac{b}{2} - k + a}{b - k}$$\nA recruiter aiming to maximize their chance of guessing correctly will choose the treatment with the higher probability. The maximum probability of a correct guess, $P_{\\text{max}}$, is the maximum of these two values:\n$$P_{\\text{max}} = \\max\\left( \\frac{\\frac{b}{2} - a}{b - k}, \\frac{\\frac{b}{2} - k + a}{b - k} \\right)$$\nSince the denominator $b-k$ is positive, we can simplify this to:\n$$P_{\\text{max}} = \\frac{1}{b - k} \\max\\left( \\frac{b}{2} - a, \\frac{b}{2} - k + a \\right)$$\nUsing the identity $\\max(X, Y) = \\frac{1}{2}(X + Y + |X - Y|)$ on the numerators, we have:\n- Sum of numerators: $(\\frac{b}{2} - a) + (\\frac{b}{2} - k + a) = b - k$\n- Difference of numerators: $(\\frac{b}{2} - a) - (\\frac{b}{2} - k + a) = k - 2a$\nSubstituting these into the identity gives the maximum numerator value:\n$$\\max\\left(\\dots\\right) = \\frac{1}{2} \\left( (b - k) + |k - 2a| \\right)$$\nFinally, dividing by the total number of remaining assignments, $b-k$, we get the maximum probability:\n$$P_{\\text{max}} = \\frac{\\frac{1}{2} \\left( (b - k) + |k - 2a| \\right)}{b-k} = \\frac{1}{2} + \\frac{|k - 2a|}{2(b - k)}$$\nThis expression shows that the predictability increases from the baseline of $1/2$ as the imbalance in the already assigned treatments, represented by $|k-2a|$, grows.", "answer": "$$\\boxed{\\frac{1}{2} + \\frac{|k - 2a|}{2(b - k)}}$$", "id": "4627374"}]}