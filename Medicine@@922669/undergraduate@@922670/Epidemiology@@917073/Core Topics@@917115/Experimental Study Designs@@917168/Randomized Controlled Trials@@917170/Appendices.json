{"hands_on_practices": [{"introduction": "Before a single participant is enrolled in a Randomized Controlled Trial, investigators must answer a crucial question: how many participants do we need? This exercise guides you through deriving the sample size formula from fundamental statistical principles. By building the formula from the ground up, you will gain a deep understanding of the interplay between statistical power, the desired effect size ($ \\Delta $), and the required sample size, a cornerstone of designing ethically and scientifically robust trials [@problem_id:4628034].", "problem": "Consider a two-arm randomized controlled trial with equal allocation to intervention and control, evaluating a binary outcome observed once per participant at a common follow-up time under stable conditions. Let $p_0$ denote the true event probability in the control arm and $p_1$ the true event probability in the intervention arm. The target effect is the risk difference $\\Delta = p_1 - p_0$, and suppose the design aims to test the null hypothesis $H_0: p_1 - p_0 = 0$ against the two-sided alternative $H_1: p_1 - p_0 \\neq 0$ at type I error $\\,\\alpha\\,$ and achieve power $\\,1 - \\beta\\,$ to detect the prespecified nonzero risk difference $\\,\\Delta\\,$.\n\nUse the following fundamental base:\n- Under independent sampling, the sample proportion $\\hat{p}_a$ in arm $a \\in \\{0,1\\}$ has large-sample distribution $\\hat{p}_a \\approx \\mathcal{N}\\!\\left(p_a,\\, p_a(1 - p_a)/n\\right)$ for $n$ participants per arm, by the Central Limit Theorem, and the two arms are independent under equal allocation.\n- The difference in sample proportions $D = \\hat{p}_1 - \\hat{p}_0$ is approximately normal with mean $p_1 - p_0$ and variance $p_1(1 - p_1)/n + p_0(1 - p_0)/n$ by independence.\n- For a $2$-sided $\\alpha$-level test of $H_0$, a rejection threshold is set using the standard normal quantile function $\\Phi^{-1}(\\cdot)$ and a design-stage null variance. Let the design-stage pooled planning value be $p_{\\ast} = (p_0 + p_1)/2$, giving a null standard deviation $\\sqrt{2\\,p_{\\ast}(1 - p_{\\ast})/n}$ for $D$.\n\nStarting from these bases and without invoking any pre-memorized sample size formula, derive the closed-form analytic expression for the required per-arm sample size $n$ (an integer is not required; ignore any integer rounding) that ensures type I error $\\,\\alpha\\,$ and power $\\,1 - \\beta\\,$ to detect the risk difference $\\Delta$ under equal allocation. Express your final answer as a single analytic expression in terms of $p_0$, $p_1$, $\\alpha$, $\\beta$, and $\\Delta$, and the standard normal quantile function $\\Phi^{-1}(\\cdot)$. You may assume $\\Delta \\neq 0$. No numerical evaluation is required, and no rounding is required. The answer must be the per-arm sample size.", "solution": "The problem statement is a valid, well-posed question in the field of biostatistics, specifically concerning the design of randomized controlled trials. It provides a complete and consistent set of givens and assumptions from which a unique, analytical solution can be derived.\n\n### Step 1: Extract Givens\n-   **Study Design**: Two-arm randomized controlled trial with equal allocation ($n$ participants per arm).\n-   **Outcome**: Binary.\n-   **Parameters**: $p_0$ is the true event probability in the control arm; $p_1$ is the true event probability in the intervention arm.\n-   **Effect Measure**: Risk difference, $\\Delta = p_1 - p_0$.\n-   **Hypotheses**: Null hypothesis $H_0: p_1 - p_0 = 0$; alternative hypothesis $H_1: p_1 - p_0 \\neq 0$.\n-   **Error Rates**: Type I error rate is $\\alpha$; Type II error rate is $\\beta$, corresponding to a power of $1 - \\beta$.\n-   **Distributional Assumptions**:\n    1.  The sample proportion in arm $a \\in \\{0,1\\}$, denoted $\\hat{p}_a$, is approximately normally distributed: $\\hat{p}_a \\sim \\mathcal{N}(p_a, \\frac{p_a(1-p_a)}{n})$.\n    2.  The difference in sample proportions, $D = \\hat{p}_1 - \\hat{p}_0$, is approximately normally distributed: $D \\sim \\mathcal{N}(p_1 - p_0, \\frac{p_1(1-p_1)}{n} + \\frac{p_0(1-p_0)}{n})$.\n-   **Test Construction**:\n    1.  The test uses the standard normal quantile function $\\Phi^{-1}(\\cdot)$.\n    2.  For design, the null variance of $D$ is based on a planning value $p_{\\ast} = (p_0 + p_1)/2$, yielding a standard deviation for $D$ under $H_0$ of $\\sqrt{2 p_{\\ast}(1-p_{\\ast})/n}$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is based on the well-established statistical theory for comparing two proportions using the normal approximation to the binomial distribution, which is a fundamental concept in designing clinical trials.\n-   **Well-Posed**: The problem is clearly defined, providing all necessary parameters ($\\alpha, \\beta, p_0, p_1$) and distributional foundations to derive the required sample size, $n$. The instructions are explicit and lead to a unique solution.\n-   **Objective**: The language is formal, precise, and devoid of any subjectivity or ambiguity.\n\nThe problem is valid as it satisfies all criteria for a well-formulated scientific question.\n\n### Derivation of the Sample Size Formula\n\nThe objective is to derive an expression for the per-arm sample size, $n$, that satisfies the specified type I and type II error constraints. The derivation proceeds from the given first principles.\n\n**1. Type I Error and the Rejection Rule**\n\nThe null hypothesis is $H_0: \\Delta = p_1 - p_0 = 0$. The test statistic is the observed difference in proportions, $D = \\hat{p}_1 - \\hat{p}_0$.\n\nAccording to the problem statement, for the purpose of trial design, the distribution of $D$ under $H_0$ is taken to be approximately normal with a mean of $0$ and a variance, $\\text{Var}_0(D)$, constructed using the planning value $p_{\\ast} = (p_0 + p_1)/2$.\n$$ \\text{Var}_0(D) = \\frac{2 p_{\\ast}(1 - p_{\\ast})}{n} = \\frac{2 \\left(\\frac{p_0+p_1}{2}\\right) \\left(1 - \\frac{p_0+p_1}{2}\\right)}{n} $$\nFor a two-sided test with a type I error rate of $\\alpha$, we reject $H_0$ if the observed difference $|D|$ is greater than a critical value, $C$. This critical value is determined by the tails of the null distribution. The standardized statistic under $H_0$ would be $Z = D / \\sqrt{\\text{Var}_0(D)}$. We reject if $|Z| > \\Phi^{-1}(1 - \\alpha/2)$.\nThis implies that the rejection region for the unstandardized difference $D$ is $|D| > C$, where:\n$$ C = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{\\text{Var}_0(D)} = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{\\frac{2 p_{\\ast}(1 - p_{\\ast})}{n}} $$\n\n**2. Type II Error and Power**\n\nPower is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_1$ is true. Under $H_1$, the true difference is $\\Delta = p_1 - p_0 \\neq 0$.\n\nThe distribution of $D$ under $H_1$ is approximately normal with mean $\\Delta$ and variance $\\text{Var}_1(D)$:\n$$ D \\sim \\mathcal{N}\\left(\\Delta, \\text{Var}_1(D)\\right) \\quad \\text{where} \\quad \\text{Var}_1(D) = \\frac{p_1(1-p_1)}{n} + \\frac{p_0(1-p_0)}{n} $$\nThe power, $1 - \\beta$, is the probability that $D$ falls in the rejection region, i.e., $P(|D| > C | H_1)$.\n$$ 1 - \\beta = P(D > C | H_1) + P(D < -C | H_1) $$\nAssuming $\\Delta > 0$ (the case for $\\Delta < 0$ is symmetric), the term $P(D < -C | H_1)$ is typically negligible for a well-powered study, as the distribution of $D$ is centered far from $-C$. Thus, we can approximate the power by the first term:\n$$ 1 - \\beta \\approx P(D > C | H_1) $$\nTo evaluate this probability, we standardize $D$ using its distribution under $H_1$:\n$$ 1 - \\beta \\approx P\\left( \\frac{D - \\Delta}{\\sqrt{\\text{Var}_1(D)}} > \\frac{C - \\Delta}{\\sqrt{\\text{Var}_1(D)}} \\right) $$\nThe term on the left inside the probability is a standard normal variable, $Z \\sim \\mathcal{N}(0,1)$.\n$$ P\\left( Z > \\frac{C - \\Delta}{\\sqrt{\\text{Var}_1(D)}} \\right) = 1 - \\beta $$\nFrom the definition of the standard normal cumulative distribution function, $\\Phi$, this implies:\n$$ \\frac{C - \\Delta}{\\sqrt{\\text{Var}_1(D)}} = \\Phi^{-1}(1 - (1-\\beta)) = \\Phi^{-1}(\\beta) $$\nSolving for the critical value $C$, we obtain a second expression for it, this time from the power requirement:\n$$ C = \\Delta + \\Phi^{-1}(\\beta) \\sqrt{\\text{Var}_1(D)} $$\n\n**3. Solving for the Sample Size, n**\n\nWe now have two expressions for the critical value $C$, one from the type I error constraint and one from the power constraint. By equating them, we can solve for $n$.\n$$ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{\\text{Var}_0(D)} = \\Delta + \\Phi^{-1}(\\beta) \\sqrt{\\text{Var}_1(D)} $$\nSubstitute the expressions for the variances, which both depend on $1/\\sqrt{n}$:\n$$ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\frac{\\sqrt{2 p_{\\ast}(1 - p_{\\ast})}}{\\sqrt{n}} = \\Delta + \\Phi^{-1}(\\beta) \\frac{\\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{\\sqrt{n}} $$\nRearrange the equation to isolate $\\Delta$:\n$$ \\Delta = \\frac{1}{\\sqrt{n}} \\left[ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} - \\Phi^{-1}(\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)} \\right] $$\nUsing the symmetry property of the standard normal quantile function, $\\Phi^{-1}(\\beta) = -\\Phi^{-1}(1-\\beta)$:\n$$ \\Delta = \\frac{1}{\\sqrt{n}} \\left[ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} + \\Phi^{-1}(1-\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)} \\right] $$\nNow, we solve for $\\sqrt{n}$ and then square the result to find $n$:\n$$ \\sqrt{n} = \\frac{\\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} + \\Phi^{-1}(1-\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{\\Delta} $$\n$$ n = \\left( \\frac{\\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} + \\Phi^{-1}(1-\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{\\Delta} \\right)^2 $$\nSubstituting the definition of $p_{\\ast} = (p_0+p_1)/2$ and writing the expression as a single fraction yields the final closed-form expression for the per-arm sample size $n$.\n$$ n = \\frac{\\left( \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 \\left(\\frac{p_0+p_1}{2}\\right)\\left(1 - \\frac{p_0+p_1}{2}\\right)} + \\Phi^{-1}(1-\\beta) \\sqrt{p_0(1-p_0) + p_1(1-p_1)} \\right)^2}{\\Delta^2} $$\nThis expression provides the required sample size per arm as a function of the specified parameters $p_0$, $p_1$, $\\alpha$, $\\beta$, and the risk difference $\\Delta = p_1-p_0$.", "answer": "$$ \\boxed{ \\frac{\\left( \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\sqrt{2 \\left(\\frac{p_0+p_1}{2}\\right) \\left(1 - \\frac{p_0+p_1}{2}\\right)} + \\Phi^{-1}(1-\\beta) \\sqrt{p_0(1-p_0) + p_1(1-p_1)} \\right)^{2}}{\\Delta^{2}} } $$", "id": "4628034"}, {"introduction": "With data from an RCT in hand, the next step is to quantify the intervention's effect. This practice challenges you to calculate and compare three key measures of association for binary outcomes: the risk difference ($RD$), risk ratio ($RR$), and odds ratio ($OR$). You will also explore the important statistical property of collapsibility, learning why the choice of effect measure can impact its interpretation when considering other patient characteristics [@problem_id:4628160].", "problem": "A Randomized Controlled Trial (RCT) evaluates a prophylactic intervention to reduce a binary outcome. Among $1000$ participants randomized to the intervention arm, $100$ experienced the outcome. Among $1000$ participants randomized to the control arm, $150$ experienced the outcome. Starting from first principles appropriate to epidemiology, use core definitions of probability, odds, and independence induced by randomization to derive and compute the following population effect measures from the observed data: the risk difference, the risk ratio, and the odds ratio. Then, reason from the definition of collapsibility (marginal effect equaling the common stratum-specific effect under randomization and no effect modification) to determine which of these three measures are collapsible in the context of randomized assignment with no unmeasured confounders. Express the final answer as a row matrix in the order $[\\text{risk difference}, \\text{risk ratio}, \\text{odds ratio}, I_{\\text{RD}}, I_{\\text{RR}}, I_{\\text{OR}}]$, where $I_{\\text{RD}}$, $I_{\\text{RR}}$, and $I_{\\text{OR}}$ are indicator variables taking value $1$ if the measure is collapsible and $0$ otherwise. Provide the risk difference, risk ratio, and odds ratio in exact fractional form if possible; if you choose to provide decimal approximations, round to $4$ significant figures. No physical units are involved; report all quantities as dimensionless numbers.", "solution": "The problem is valid as it is scientifically grounded in the principles of epidemiology and biostatistics, is well-posed with sufficient and consistent information, and is stated objectively.\n\nLet $X$ denote the treatment assignment, where $X=1$ for the intervention arm and $X=0$ for the control arm. Let $Y$ denote the binary outcome, where $Y=1$ if the outcome occurred and $Y=0$ if it did not. The problem provides the following data from a Randomized Controlled Trial (RCT):\nFor the intervention arm ($X=1$):\n- Number of participants: $N_1 = 1000$\n- Number with the outcome: $A_1 = 100$\n- Number without the outcome: $B_1 = N_1 - A_1 = 1000 - 100 = 900$\n\nFor the control arm ($X=0$):\n- Number of participants: $N_0 = 1000$\n- Number with the outcome: $A_0 = 150$\n- Number without the outcome: $B_0 = N_0 - A_0 = 1000 - 150 = 850$\n\nThe task is to derive and compute three effect measures (risk difference, risk ratio, odds ratio) and determine their collapsibility property.\n\nFirst, we define the risk (probability) of the outcome in each arm. The risk is the conditional probability of the outcome given the treatment assignment, $P(Y=1|X=x)$. In an RCT, these probabilities are estimated directly from the observed proportions in each arm.\n\nThe risk in the intervention arm is estimated as:\n$$ \\hat{R}_1 = \\frac{A_1}{N_1} = \\frac{100}{1000} = \\frac{1}{10} $$\nThe risk in the control arm is estimated as:\n$$ \\hat{R}_0 = \\frac{A_0}{N_0} = \\frac{150}{1000} = \\frac{15}{100} = \\frac{3}{20} $$\n\n**Part 1: Calculation of Effect Measures**\n\n1.  **Risk Difference (RD)**: The risk difference is the arithmetic difference in risks between the two arms.\n    $$ RD = R_1 - R_0 $$\n    Using the sample estimates:\n    $$ \\hat{RD} = \\hat{R}_1 - \\hat{R}_0 = \\frac{1}{10} - \\frac{3}{20} = \\frac{2}{20} - \\frac{3}{20} = -\\frac{1}{20} $$\n\n2.  **Risk Ratio (RR)**: The risk ratio is the ratio of the risks in the two arms.\n    $$ RR = \\frac{R_1}{R_0} $$\n    Using the sample estimates:\n    $$ \\hat{RR} = \\frac{\\hat{R}_1}{\\hat{R}_0} = \\frac{1/10}{3/20} = \\frac{1}{10} \\times \\frac{20}{3} = \\frac{20}{30} = \\frac{2}{3} $$\n\n3.  **Odds Ratio (OR)**: First, we define the odds of an outcome as the ratio of the probability of the outcome occurring to the probability of it not occurring.\n    $$ \\text{Odds}(x) = \\frac{P(Y=1|X=x)}{P(Y=0|X=x)} = \\frac{R_x}{1-R_x} $$\n    The odds ratio is the ratio of the odds in the intervention arm to the odds in the control arm.\n    $$ OR = \\frac{\\text{Odds}(1)}{\\text{Odds}(0)} = \\frac{R_1 / (1-R_1)}{R_0 / (1-R_0)} $$\n    The sample odds are:\n    $$ \\hat{\\text{Odds}}_1 = \\frac{\\hat{R}_1}{1-\\hat{R}_1} = \\frac{1/10}{1 - 1/10} = \\frac{1/10}{9/10} = \\frac{1}{9} $$\n    $$ \\hat{\\text{Odds}}_0 = \\frac{\\hat{R}_0}{1-\\hat{R}_0} = \\frac{3/20}{1 - 3/20} = \\frac{3/20}{17/20} = \\frac{3}{17} $$\n    The sample odds ratio is:\n    $$ \\hat{OR} = \\frac{\\hat{\\text{Odds}}_1}{\\hat{\\text{Odds}}_0} = \\frac{1/9}{3/17} = \\frac{1}{9} \\times \\frac{17}{3} = \\frac{17}{27} $$\n    Alternatively, the odds ratio can be computed as the cross-product ratio from the $2 \\times 2$ contingency table:\n    $$ \\hat{OR} = \\frac{A_1 B_0}{A_0 B_1} = \\frac{100 \\times 850}{150 \\times 900} = \\frac{85000}{135000} = \\frac{85}{135} = \\frac{17}{27} $$\n\n**Part 2: Collapsibility Analysis**\n\nCollapsibility refers to the property that a marginal (crude) measure of effect is equal to a common stratum-specific measure of effect, given there is no effect modification across strata. The stratification is done by a third variable, say $Z$. The problem specifies the context of \"randomized assignment with no unmeasured confounders\" and \"no effect modification\".\n\nLet $Z$ be a baseline covariate (e.g., age, sex) with levels $k=1, 2, \\dots, K$.\nThe marginal risk in arm $x$ is $R_x = P(Y=1|X=x)$. By the law of total probability, we can expand this over the strata of $Z$:\n$$ R_x = \\sum_{k=1}^{K} P(Y=1|X=x, Z=k) P(Z=k|X=x) $$\nLet $R_{xk} = P(Y=1|X=x, Z=k)$ be the stratum-specific risk.\nIn an RCT, randomization ensures that the treatment assignment $X$ is statistically independent of any baseline covariate $Z$. Thus, $P(Z=k|X=x) = P(Z=k)$ for all $x$. Let $p_k = P(Z=k)$.\nThe marginal risks are then a weighted average of the stratum-specific risks:\n$$ R_1 = \\sum_{k} R_{1k} p_k $$\n$$ R_0 = \\sum_{k} R_{0k} p_k $$\nThe condition \"no effect modification\" means the effect measure is constant across the strata of $Z$.\n\n- **Risk Difference (RD)**:\n  The marginal RD is $RD = R_1 - R_0$. The stratum-specific RD is $RD_k = R_{1k} - R_{0k}$.\n  The \"no effect modification\" condition implies $RD_k = RD_{\\text{common}}$ for all $k$.\n  $$ RD = R_1 - R_0 = \\sum_{k} R_{1k} p_k - \\sum_{k} R_{0k} p_k = \\sum_{k} (R_{1k} - R_{0k}) p_k = \\sum_{k} RD_k p_k $$\n  Substituting $RD_k = RD_{\\text{common}}$:\n  $$ RD = \\sum_{k} RD_{\\text{common}} p_k = RD_{\\text{common}} \\sum_{k} p_k = RD_{\\text{common}} \\times 1 = RD_{\\text{common}} $$\n  The marginal RD equals the common stratum-specific RD. Therefore, the risk difference is collapsible. $I_{\\text{RD}} = 1$.\n\n- **Risk Ratio (RR)**:\n  The marginal RR is $RR = R_1 / R_0$. The stratum-specific RR is $RR_k = R_{1k} / R_{0k}$.\n  The \"no effect modification\" condition implies $RR_k = RR_{\\text{common}}$ for all $k$, so $R_{1k} = RR_{\\text{common}} \\times R_{0k}$.\n  $$ RR = \\frac{R_1}{R_0} = \\frac{\\sum_{k} R_{1k} p_k}{\\sum_{k} R_{0k} p_k} $$\n  Substituting $R_{1k} = RR_{\\text{common}} R_{0k}$:\n  $$ RR = \\frac{\\sum_{k} (RR_{\\text{common}} R_{0k}) p_k}{\\sum_{k} R_{0k} p_k} = \\frac{RR_{\\text{common}} \\sum_{k} R_{0k} p_k}{\\sum_{k} R_{0k} p_k} = RR_{\\text{common}} $$\n  The marginal RR equals the common stratum-specific RR. Therefore, the risk ratio is collapsible. $I_{\\text{RR}} = 1$.\n\n- **Odds Ratio (OR)**:\n  The marginal OR is $OR = \\frac{R_1/(1-R_1)}{R_0/(1-R_0)}$. The stratum-specific OR is $OR_k = \\frac{R_{1k}/(1-R_{1k})}{R_{0k}/(1-R_{0k})}$.\n  The \"no effect modification\" condition implies $OR_k = OR_{\\text{common}}$ for all $k$.\n  The odds function, $f(p) = p/(1-p)$, is a non-linear convex function for $p \\in (0, 0.5)$ and concave for $p \\in (0.5, 1)$. Due to this non-linearity, the weighted average of risks does not translate into a simple form for the odds. The marginal odds are:\n  $$ \\text{Odds}_1 = \\frac{\\sum_k R_{1k}p_k}{1 - \\sum_k R_{1k}p_k} \\quad \\text{and} \\quad \\text{Odds}_0 = \\frac{\\sum_k R_{0k}p_k}{1 - \\sum_k R_{0k}p_k} $$\n  By Jensen's inequality, for a non-linear function $f$, $f(E[X]) \\neq E[f(X)]$. Here, the marginal risk $R_x$ is the expectation of the stratum-specific risks $R_{xk}$ over the distribution of $Z$. Thus, the marginal odds, $\\text{Odds}_x = f(R_x) = f(E[R_{xk}])$, are not equal to the weighted average of the stratum-specific odds, $E[f(R_{xk})] = \\sum_k f(R_{xk}) p_k$.\n  Consequently, the marginal odds ratio $OR = \\text{Odds}_1 / \\text{Odds}_0$ will not, in general, be equal to the common stratum-specific odds ratio $OR_{\\text{common}}$, unless $Z$ is not a risk factor for the outcome (i.e., $R_{0k}$ is constant over $k$) or the treatment has no effect ($OR_{\\text{common}}=1$). Since these exceptions are not generally true, the odds ratio is non-collapsible. $I_{\\text{OR}} = 0$.\n\nCombining the results, the final values are:\n- Risk Difference: $-\\frac{1}{20}$\n- Risk Ratio: $\\frac{2}{3}$\n- Odds Ratio: $\\frac{17}{27}$\n- $I_{\\text{RD}} = 1$ (collapsible)\n- $I_{\\text{RR}} = 1$ (collapsible)\n- $I_{\\text{OR}} = 0$ (non-collapsible)\n\nThe final answer will be presented as a row matrix.\n$$\n\\begin{pmatrix}\n-\\frac{1}{20} & \\frac{2}{3} & \\frac{17}{27} & 1 & 1 & 0\n\\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{1}{20} & \\frac{2}{3} & \\frac{17}{27} & 1 & 1 & 0\n\\end{pmatrix}\n}\n$$", "id": "4628160"}, {"introduction": "In the real world, not all participants adhere to their assigned intervention, a phenomenon known as non-compliance. This practice introduces a powerful method to handle this complexity by using the original random assignment as an 'instrumental variable'. You will derive the Wald estimator to determine the Complier Average Causal Effect (CACE), uncovering the treatment's effect specifically on those who adhered to their assignment and learning the critical assumptions that underpin this advanced analysis [@problem_id:4568066].", "problem": "Consider a randomized controlled trial (RCT) in preventive medicine evaluating a binary preventive intervention such as a falls-prevention program. Let random assignment be denoted by $Z \\in \\{0,1\\}$, where $Z=1$ indicates assignment to be offered the preventive program and $Z=0$ indicates control. Let actual uptake of the program be denoted by $D \\in \\{0,1\\}$, where $D=1$ indicates uptake and $D=0$ indicates no uptake. Let the primary outcome be a binary indicator $Y \\in \\{0,1\\}$ for the occurrence of the adverse event (for example, any fall during $12$ months).\n\nDefine the potential uptake $D(z)$ for $z \\in \\{0,1\\}$ and the potential outcome $Y(d)$ for $d \\in \\{0,1\\}$. Assume the Stable Unit Treatment Value Assumption (SUTVA), so the observed uptake is $D = D(Z)$ and the observed outcome is $Y = Y(D)$.\n\nStarting from the core definitions of potential outcomes and the properties guaranteed by random assignment in an RCT, derive, from first principles, the Wald estimator for the Complier Average Causal Effect (CACE), defined as the average causal effect of uptake on the outcome among compliers. Express your final estimator in terms of observable conditional expectations of $Y$ and $D$ given $Z$. In the derivation, formally state the monotonicity and exclusion restriction assumptions required for identification in this setting using the language of potential outcomes.\n\nYour final answer must be a single closed-form analytic expression. Do not provide numerical values. No rounding is required, and no units are to be reported in the final answer.", "solution": "The problem requires the derivation of the Wald estimator for the Complier Average Causal Effect (CACE) from first principles, within the context of a randomized controlled trial (RCT) with a binary treatment, binary uptake, and a binary outcome.\n\nFirst, we establish the theoretical framework using the provided definitions and the potential outcomes model. The assignment to treatment is $Z \\in \\{0, 1\\}$, the uptake of the treatment is $D \\in \\{0, 1\\}$, and the outcome is $Y \\in \\{0, 1\\}$. We are given potential uptake $D(z)$ for assignment $z \\in \\{0, 1\\}$ and potential outcome $Y(d)$ for uptake $d \\in \\{0, 1\\}$. The Stable Unit Treatment Value Assumption (SUTVA) is assumed, implying no interference between units and consistency, such that the observed uptake is $D = D(Z)$ and the observed outcome is $Y = Y(D)$.\n\nThe target quantity is the CACE, which is the average causal effect of the treatment on the outcome for the subpopulation of \"compliers\". To define compliers, we first categorize the population into four principal strata based on their potential uptake behavior, represented by the pair $(D(0), D(1))$:\n1.  **Compliers**: Individuals for whom $(D(0), D(1)) = (0, 1)$. They take the treatment if and only if they are assigned to it.\n2.  **Always-Takers**: Individuals for whom $(D(0), D(1)) = (1, 1)$. They take the treatment regardless of assignment.\n3.  **Never-Takers**: Individuals for whom $(D(0), D(1)) = (0, 0)$. They never take the treatment regardless of assignment.\n4.  **Defiers**: Individuals for whom $(D(0), D(1)) = (1, 0)$. They take the treatment if and only if they are assigned to the control group.\n\nThe CACE is formally defined as the average treatment effect for the group of compliers:\n$$\n\\text{CACE} \\equiv E[Y(1) - Y(0) | D(1)=1, D(0)=0]\n$$\nThis quantity is not directly observable because we can never simultaneously observe $Y(1)$ and $Y(0)$ for the same individual, nor can we directly identify the complier group from the data, as we only observe one of $D(1)$ or $D(0)$ for each person.\n\nTo identify the CACE from observable data, we must invoke several key assumptions.\n\n**Assumptions for Identification:**\n\n1.  **Random Assignment (Independence)**: As a core property of an RCT, the treatment assignment $Z$ is statistically independent of all potential outcomes and potential uptakes. Formally:\n    $$\n    Z \\perp (Y(1), Y(0), D(1), D(0))\n    $$\n2.  **Exclusion Restriction**: The assignment $Z$ affects the outcome $Y$ only through its effect on uptake $D$. The problem statement implies this by defining the potential outcome as $Y(d)$, a function of uptake only. A more fundamental definition would be $Y(z, d)$, the potential outcome under assignment $z$ and uptake $d$. The exclusion restriction states that $Y(z, d) = Y(d)$ for all $z, d$. This means the instrument $Z$ has no direct causal effect on the outcome $Y$ that bypasses the treatment $D$.\n3.  **Monotonicity**: There are no defiers in the population. This means that for any individual, being offered the treatment does not make them less likely to take it. Formally, for every individual in the population:\n    $$\n    D(1) \\ge D(0)\n    $$\n4.  **Relevance/Non-zero Effect of Z on D**: The assignment to treatment must have an influence on the actual uptake of the treatment on average. This means $E[D|Z=1] \\neq E[D|Z=0]$.\n\nWith these assumptions, we can proceed with the derivation. The Wald estimator is the ratio of the Intention-to-Treat (ITT) effect on the outcome $Y$ to the ITT effect on the uptake $D$.\n\n**Numerator: ITT Effect on the Outcome (Y)**\n\nThe ITT effect on the outcome is the difference in the average outcome between the treatment and control arms: $E[Y|Z=1] - E[Y|Z=0]$.\n\nUsing SUTVA, $Y = Y(D) = Y(D(Z))$.\nSo, $E[Y|Z=1] = E[Y(D(1))|Z=1]$. By the random assignment assumption, this is equal to $E[Y(D(1))]$.\nSimilarly, $E[Y|Z=0] = E[Y(D(0))|Z=0]$, which is equal to $E[Y(D(0))]$.\n\nThe ITT effect is therefore $E[Y(D(1))] - E[Y(D(0))]$. We can expand this expression by conditioning on the principal strata (compliance types). Let $\\pi_c, \\pi_a, \\pi_n, \\pi_d$ be the population proportions of compliers, always-takers, never-takers, and defiers, respectively.\n\n$E[Y(D(1))] = E[Y(1)]$ for compliers and always-takers (since $D(1)=1$), and $E[Y(0)]$ for never-takers and defiers (since $D(1)=0$).\n$$\nE[Y(D(1))] = E[Y(1)|D(1)=1, D(0)=0]\\pi_c + E[Y(1)|D(1)=1, D(0)=1]\\pi_a + E[Y(0)|D(1)=0, D(0)=0]\\pi_n + E[Y(0)|D(1)=0, D(0)=1]\\pi_d\n$$\n$E[Y(D(0))] = E[Y(0)]$ for compliers and never-takers (since $D(0)=0$), and $E[Y(1)]$ for always-takers and defiers (since $D(0)=1$).\n$$\nE[Y(D(0))] = E[Y(0)|D(1)=1, D(0)=0]\\pi_c + E[Y(1)|D(1)=1, D(0)=1]\\pi_a + E[Y(0)|D(1)=0, D(0)=0]\\pi_n + E[Y(1)|D(1)=0, D(0)=1]\\pi_d\n$$\nSubtracting the second expression from the first, the terms for always-takers and never-takers cancel out:\n$$\nE[Y|Z=1] - E[Y|Z=0] = \\pi_c (E[Y(1)|C] - E[Y(0)|C]) + \\pi_d (E[Y(0)|D] - E[Y(1)|D])\n$$\nwhere $C$ and $D$ denote the complier and defier groups. This simplifies to:\n$$\nE[Y|Z=1] - E[Y|Z=0] = \\pi_c \\text{CACE} - \\pi_d E[Y(1) - Y(0)|D]\n$$\nNow, we apply the **monotonicity assumption**, which posits that $\\pi_d = 0$. This eliminates the term involving defiers.\n$$\nE[Y|Z=1] - E[Y|Z=0] = \\pi_c \\cdot \\text{CACE}\n$$\n\n**Denominator: ITT Effect on Uptake (D)**\n\nThe ITT effect on uptake is the difference in the average uptake between the treatment and control arms: $E[D|Z=1] - E[D|Z=0]$.\n\nUsing SUTVA, $D=D(Z)$.\n$E[D|Z=1] = E[D(1)|Z=1]$. By random assignment, this is $E[D(1)]$.\n$E[D|Z=0] = E[D(0)|Z=0]$. By random assignment, this is $E[D(0)]$.\nSo the denominator is $E[D(1)] - E[D(0)]$.\nSince $D$ is a binary variable, $E[D(z)] = P(D(z)=1)$.\n$P(D(1)=1)$ is the proportion of the population that would take the treatment if assigned to it. These are the compliers and the always-takers. Thus, $E[D(1)] = \\pi_c + \\pi_a$.\n$P(D(0)=1)$ is the proportion of the population that would take the treatment if assigned to control. These are the always-takers and the defiers. Thus, $E[D(0)] = \\pi_a + \\pi_d$.\n\nThe difference is:\n$$\nE[D|Z=1] - E[D|Z=0] = (\\pi_c + \\pi_a) - (\\pi_a + \\pi_d) = \\pi_c - \\pi_d\n$$\nApplying the **monotonicity assumption** ($\\pi_d = 0$), the denominator simplifies to the proportion of compliers:\n$$\nE[D|Z=1] - E[D|Z=0] = \\pi_c\n$$\nThe relevance assumption ensures that this denominator is non-zero, i.e., $\\pi_c > 0$.\n\n**Combining Numerator and Denominator**\n\nWe now have the two necessary pieces:\n1.  Numerator: $E[Y|Z=1] - E[Y|Z=0] = \\pi_c \\cdot \\text{CACE}$\n2.  Denominator: $E[D|Z=1] - E[D|Z=0] = \\pi_c$\n\nDividing the first by the second yields the CACE:\n$$\n\\text{CACE} = \\frac{\\pi_c \\cdot \\text{CACE}}{\\pi_c} = \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[D|Z=1] - E[D|Z=0]}\n$$\nThis expression is the Wald estimator. It is expressed entirely in terms of conditional expectations of observable variables ($Y$, $D$, $Z$), and thus can be estimated from the data collected in the RCT. The numerator is the ITT effect on the outcome and the denominator is the proportion of compliers in the population.", "answer": "$$\n\\boxed{\\frac{E[Y | Z=1] - E[Y | Z=0]}{E[D | Z=1] - E[D | Z=0]}}\n$$", "id": "4568066"}]}