{"hands_on_practices": [{"introduction": "At the heart of reliability analysis is the idea that any observed score is a combination of a true score and measurement error. This first exercise provides a fundamental application of Classical Test Theory (CTT), allowing you to partition the total observed variance into its true and error components. Mastering this decomposition is the first step toward understanding and improving any measurement instrument in epidemiology. [@problem_id:4642602]", "problem": "An epidemiologic cohort study uses a quantitative immunoassay to measure an exposure biomarker on a continuous index scale. Repeated measurements on a subset of participants yield an estimate of reliability equal to $\\rho = 0.8$ based on the intraclass correlation coefficient (ICC), and the population-level observed variance of the biomarker index is $\\mathrm{Var}(X) = 100$ index points squared. Under classical test theory (CTT) assumptions—namely, that the observed score $X$ is the sum of a true score $T$ and an error score $E$, errors have zero mean, errors are uncorrelated with true scores, and replicate errors are independent—compute the error-score variance $\\mathrm{Var}(E)$ and the true-score variance $\\mathrm{Var}(T)$. Express your final variances in index points squared. Provide exact values with no rounding, and report your answers in the order $\\mathrm{Var}(E)$, $\\mathrm{Var}(T)$.", "solution": "The problem is valid. It is a well-posed question grounded in the established principles of Classical Test Theory (CTT), which is a standard framework for evaluating measurement reliability in epidemiology and other fields. The provided data are complete, consistent, and sufficient to derive a unique solution.\n\nThe problem requires us to compute the error-score variance, denoted as $\\mathrm{Var}(E)$, and the true-score variance, denoted as $\\mathrm{Var}(T)$, based on a set of given parameters and the assumptions of Classical Test Theory.\n\nThe fundamental tenet of CTT is that an observed score, $X$, is a composite of a true score, $T$, and a random error component, $E$. This relationship is expressed as a linear model:\n$$X = T + E$$\n\nThe problem states that we must adhere to CTT assumptions. A crucial assumption for the decomposition of variance is that the true score and the error score are uncorrelated. Mathematically, this is expressed as the covariance between $T$ and $E$ being zero:\n$$\\mathrm{Cov}(T, E) = 0$$\n\nUnder this assumption, the variance of the observed score, $\\mathrm{Var}(X)$, can be decomposed into the sum of the true-score variance and the error-score variance. The derivation is as follows:\n$$\\mathrm{Var}(X) = \\mathrm{Var}(T + E)$$\nUsing the general formula for the variance of a sum of two random variables, $\\mathrm{Var}(A+B) = \\mathrm{Var}(A) + \\mathrm{Var}(B) + 2\\mathrm{Cov}(A,B)$, we get:\n$$\\mathrm{Var}(X) = \\mathrm{Var}(T) + \\mathrm{Var}(E) + 2\\mathrm{Cov}(T, E)$$\nSince $\\mathrm{Cov}(T, E) = 0$, the equation simplifies to:\n$$\\mathrm{Var}(X) = \\mathrm{Var}(T) + \\mathrm{Var}(E)$$\n\nThe problem provides the total observed variance:\n$$\\mathrm{Var}(X) = 100 \\text{ index points squared}$$\nSo, we have our first equation:\n$$100 = \\mathrm{Var}(T) + \\mathrm{Var}(E)$$\n\nNext, we use the definition of reliability, $\\rho$. In the context of CTT, reliability is defined as the proportion of the observed-score variance that is attributable to the true-score variance. This is also the definition of the intraclass correlation coefficient (ICC) under this model.\n$$\\rho = \\frac{\\mathrm{Var}(T)}{\\mathrm{Var}(X)}$$\n\nThe problem provides the value for the reliability coefficient:\n$$\\rho = 0.8$$\n\nWe can use this definition to find the true-score variance, $\\mathrm{Var}(T)$. Rearranging the reliability equation and substituting the given values for $\\rho$ and $\\mathrm{Var}(X)$:\n$$\\mathrm{Var}(T) = \\rho \\times \\mathrm{Var}(X)$$\n$$\\mathrm{Var}(T) = 0.8 \\times 100$$\n$$\\mathrm{Var}(T) = 80 \\text{ index points squared}$$\n\nNow that we have the true-score variance, we can use the variance decomposition equation to solve for the error-score variance, $\\mathrm{Var}(E)$:\n$$\\mathrm{Var}(E) = \\mathrm{Var}(X) - \\mathrm{Var}(T)$$\nSubstituting the known values:\n$$\\mathrm{Var}(E) = 100 - 80$$\n$$\\mathrm{Var}(E) = 20 \\text{ index points squared}$$\n\nAlternatively, one could first derive an expression for $\\mathrm{Var}(E)$ directly in terms of $\\rho$ and $\\mathrm{Var}(X)$.\nFrom $\\mathrm{Var}(X) = \\mathrm{Var}(T) + \\mathrm{Var}(E)$ and $\\mathrm{Var}(T) = \\rho \\mathrm{Var}(X)$, we can substitute the second into the first:\n$$\\mathrm{Var}(X) = \\rho \\mathrm{Var}(X) + \\mathrm{Var}(E)$$\nSolving for $\\mathrm{Var}(E)$:\n$$\\mathrm{Var}(E) = \\mathrm{Var}(X) - \\rho \\mathrm{Var}(X) = (1 - \\rho)\\mathrm{Var}(X)$$\nSubstituting the given values:\n$$\\mathrm{Var}(E) = (1 - 0.8) \\times 100 = 0.2 \\times 100 = 20 \\text{ index points squared}$$\n\nThe problem requires the answers in the order $\\mathrm{Var}(E)$, $\\mathrm{Var}(T)$.\nTherefore, the error-score variance is $20$ index points squared, and the true-score variance is $80$ index points squared.", "answer": "$$\\boxed{\\begin{pmatrix} 20 & 80 \\end{pmatrix}}$$", "id": "4642602"}, {"introduction": "Building on the concept of variance decomposition, this practice explores a common strategy for improving measurement precision: averaging replicate measures. You will calculate how this averaging enhances reliability and, crucially, see how reliability directly impacts the results of a regression analysis through the attenuation factor. This exercise bridges the gap between abstract measurement theory and the tangible consequences of measurement error in epidemiological studies. [@problem_id:4642573]", "problem": "A cohort study aims to estimate the association between a continuous exposure and an outcome. Each participant’s exposure is assessed with two replicate measurements. Let the true exposure for participant $i$ be $X_{i}$, and the $j$-th observed replicate be $Y_{ij} = X_{i} + \\varepsilon_{ij}$, where $\\varepsilon_{ij}$ are independent errors with mean $0$ and variance $\\sigma_{w}^{2}$, independent of $X_{i}$, and the between-person variance is $\\operatorname{Var}(X_{i}) = \\sigma_{b}^{2}$. The intraclass correlation coefficient (ICC) for a single replicate, estimated from a two-replicate design under a one-way random effects model, is reported as $\\text{ICC} = 0.5$.\n\nUsing only the variance decomposition and the classical measurement error model specified above, compute:\n- the reliability of the mean of two replicates as the ratio $\\operatorname{Var}(X_{i}) / \\operatorname{Var}(\\bar{Y}_{i\\cdot})$, where $\\bar{Y}_{i\\cdot} = (Y_{i1} + Y_{i2})/2$,\n- the expected attenuation factor for the regression slope in a cohort analysis that uses the averaged exposure $\\bar{Y}_{i\\cdot}$ in place of $X_{i}$ under classical measurement error conditions.\n\nProvide both quantities as real numbers rounded to four significant figures. Present your final answer as a row vector, with the first entry being the reliability of the mean of two replicates and the second entry being the attenuation factor.", "solution": "The problem asks for two quantities related to measurement error in a cohort study: the reliability of the mean of two replicate measurements, and the expected attenuation factor when using this mean in a regression analysis. The validation of the problem statement proceeds as follows.\n\n### Step 1: Extract Givens\n- The model for the $j$-th observed replicate for participant $i$ is $Y_{ij} = X_{i} + \\varepsilon_{ij}$.\n- $X_{i}$ is the true exposure for participant $i$.\n- $\\varepsilon_{ij}$ are independent measurement errors with mean $E[\\varepsilon_{ij}] = 0$ and variance $\\operatorname{Var}(\\varepsilon_{ij}) = \\sigma_{w}^{2}$.\n- The errors $\\varepsilon_{ij}$ are independent of the true exposure $X_{i}$.\n- The between-person variance is $\\operatorname{Var}(X_{i}) = \\sigma_{b}^{2}$.\n- The intraclass correlation coefficient (ICC) for a single replicate is given as $\\text{ICC} = 0.5$.\n- The mean of two replicates for participant $i$ is $\\bar{Y}_{i\\cdot} = (Y_{i1} + Y_{i2})/2$.\n- The first quantity to compute is the reliability of the mean of two replicates, defined as $\\operatorname{Var}(X_{i}) / \\operatorname{Var}(\\bar{Y}_{i\\cdot})$.\n- The second quantity is the expected attenuation factor for the regression slope using $\\bar{Y}_{i\\cdot}$ as the exposure.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined within the framework of the classical measurement error model, a standard topic in biostatistics and epidemiology. The definitions and relationships are consistent with established theory. The provided value for the ICC is scientifically plausible. The problem is self-contained and objective. No flaws related to scientific unsoundness, incompleteness, or ambiguity are present.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A solution will be provided.\n\n### Solution Derivation\nThe solution requires a step-by-step derivation of the two requested quantities based on the principles of variance decomposition and measurement error theory.\n\nFirst, we use the given intraclass correlation coefficient (ICC) to establish a relationship between the between-person variance ($\\sigma_{b}^{2}$) and the within-person variance ($\\sigma_{w}^{2}$). The ICC for a single measurement is the proportion of the total variance that is due to between-person variation. The total variance of a single observation $Y_{ij}$ is:\n$$\n\\operatorname{Var}(Y_{ij}) = \\operatorname{Var}(X_i + \\varepsilon_{ij})\n$$\nSince $X_i$ and $\\varepsilon_{ij}$ are independent, the variance of their sum is the sum of their variances:\n$$\n\\operatorname{Var}(Y_{ij}) = \\operatorname{Var}(X_i) + \\operatorname{Var}(\\varepsilon_{ij}) = \\sigma_{b}^{2} + \\sigma_{w}^{2}\n$$\nThe ICC is defined as:\n$$\n\\text{ICC} = \\frac{\\text{between-person variance}}{\\text{total variance}} = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{w}^{2}}\n$$\nWe are given that $\\text{ICC} = 0.5$. Therefore:\n$$\n0.5 = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{w}^{2}}\n$$\n$$\n0.5(\\sigma_{b}^{2} + \\sigma_{w}^{2}) = \\sigma_{b}^{2}\n$$\n$$\n0.5\\sigma_{b}^{2} + 0.5\\sigma_{w}^{2} = \\sigma_{b}^{2}\n$$\n$$\n0.5\\sigma_{w}^{2} = 0.5\\sigma_{b}^{2}\n$$\nThis implies a crucial relationship:\n$$\n\\sigma_{b}^{2} = \\sigma_{w}^{2}\n$$\nThis means that the variance from true differences between individuals is equal to the variance from random measurement error for a single measurement.\n\nNext, we compute the first requested quantity: the reliability of the mean of two replicates, $\\bar{Y}_{i\\cdot}$. The reliability is defined as the ratio of the true variance to the observed variance of the averaged measurement: $\\operatorname{Var}(X_i) / \\operatorname{Var}(\\bar{Y}_{i\\cdot})$.\nWe must first find the variance of $\\bar{Y}_{i\\cdot}$.\n$$\n\\bar{Y}_{i\\cdot} = \\frac{Y_{i1} + Y_{i2}}{2} = \\frac{(X_i + \\varepsilon_{i1}) + (X_i + \\varepsilon_{i2})}{2} = \\frac{2X_i + \\varepsilon_{i1} + \\varepsilon_{i2}}{2} = X_i + \\frac{\\varepsilon_{i1} + \\varepsilon_{i2}}{2}\n$$\nThe variance of $\\bar{Y}_{i\\cdot}$ is:\n$$\n\\operatorname{Var}(\\bar{Y}_{i\\cdot}) = \\operatorname{Var}\\left(X_i + \\frac{\\varepsilon_{i1} + \\varepsilon_{i2}}{2}\\right)\n$$\nBased on the problem statement, $X_i$, $\\varepsilon_{i1}$, and $\\varepsilon_{i2}$ are mutually independent. Therefore:\n$$\n\\operatorname{Var}(\\bar{Y}_{i\\cdot}) = \\operatorname{Var}(X_i) + \\operatorname{Var}\\left(\\frac{\\varepsilon_{i1} + \\varepsilon_{i2}}{2}\\right)\n$$\n$$\n\\operatorname{Var}(\\bar{Y}_{i\\cdot}) = \\sigma_{b}^{2} + \\frac{1}{4}\\operatorname{Var}(\\varepsilon_{i1} + \\varepsilon_{i2})\n$$\nSince $\\varepsilon_{i1}$ and $\\varepsilon_{i2}$ are independent:\n$$\n\\operatorname{Var}(\\varepsilon_{i1} + \\varepsilon_{i2}) = \\operatorname{Var}(\\varepsilon_{i1}) + \\operatorname{Var}(\\varepsilon_{i2}) = \\sigma_{w}^{2} + \\sigma_{w}^{2} = 2\\sigma_{w}^{2}\n$$\nSubstituting this back, we get:\n$$\n\\operatorname{Var}(\\bar{Y}_{i\\cdot}) = \\sigma_{b}^{2} + \\frac{1}{4}(2\\sigma_{w}^{2}) = \\sigma_{b}^{2} + \\frac{\\sigma_{w}^{2}}{2}\n$$\nNow we can compute the reliability of the mean of two replicates, which we denote as $\\text{Reliability}(\\bar{Y}_{i\\cdot})$:\n$$\n\\text{Reliability}(\\bar{Y}_{i\\cdot}) = \\frac{\\operatorname{Var}(X_i)}{\\operatorname{Var}(\\bar{Y}_{i\\cdot})} = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{w}^{2}/2}\n$$\nUsing the relationship $\\sigma_{b}^{2} = \\sigma_{w}^{2}$ derived from the ICC:\n$$\n\\text{Reliability}(\\bar{Y}_{i\\cdot}) = \\frac{\\sigma_{b}^{2}}{\\sigma_{b}^{2} + \\sigma_{b}^{2}/2} = \\frac{\\sigma_{b}^{2}}{\\frac{3}{2}\\sigma_{b}^{2}} = \\frac{1}{3/2} = \\frac{2}{3}\n$$\nAs a decimal rounded to four significant figures, this value is $0.6667$.\n\nFinally, we compute the second requested quantity: the expected attenuation factor. In a regression of an outcome $Z$ on the true exposure $X$, the model is $Z_i = \\beta_0 + \\beta_1 X_i + \\delta_i$. The coefficient $\\beta_1$ represents the true association. When we use the error-prone measurement $\\bar{Y}_{i\\cdot}$ instead of $X_i$, the observed regression model is $Z_i = \\beta'_0 + \\beta'_1 \\bar{Y}_{i\\cdot} + \\delta'_i$. The estimated slope, $\\beta'_1$, will be biased towards the null. The attenuation factor, $\\lambda$, is the ratio of the expected value of the observed slope to the true slope, $\\lambda = E[\\hat{\\beta'}_1]/\\beta_1$.\nUnder the classical measurement error model, the observed slope is related to the true slope by:\n$$\nE[\\hat{\\beta'}_1] = \\beta_1 \\frac{\\operatorname{Cov}(X_i, \\bar{Y}_{i\\cdot})}{\\operatorname{Var}(\\bar{Y}_{i\\cdot})}\n$$\nLet's compute the covariance term:\n$$\n\\operatorname{Cov}(X_i, \\bar{Y}_{i\\cdot}) = \\operatorname{Cov}\\left(X_i, X_i + \\frac{\\varepsilon_{i1} + \\varepsilon_{i2}}{2}\\right)\n$$\nUsing the bilinearity of covariance:\n$$\n\\operatorname{Cov}(X_i, \\bar{Y}_{i\\cdot}) = \\operatorname{Cov}(X_i, X_i) + \\operatorname{Cov}\\left(X_i, \\frac{\\varepsilon_{i1} + \\varepsilon_{i2}}{2}\\right)\n$$\nSince $X_i$ is independent of the measurement errors $\\varepsilon_{ij}$, the second term is zero. Thus:\n$$\n\\operatorname{Cov}(X_i, \\bar{Y}_{i\\cdot}) = \\operatorname{Cov}(X_i, X_i) = \\operatorname{Var}(X_i) = \\sigma_{b}^{2}\n$$\nSo, the expected observed slope is:\n$$\nE[\\hat{\\beta'}_1] = \\beta_1 \\frac{\\operatorname{Var}(X_i)}{\\operatorname{Var}(\\bar{Y}_{i\\cdot})}\n$$\nThe attenuation factor $\\lambda$ is therefore:\n$$\n\\lambda = \\frac{E[\\hat{\\beta'}_1]}{\\beta_1} = \\frac{\\operatorname{Var}(X_i)}{\\operatorname{Var}(\\bar{Y}_{i\\cdot})}\n$$\nThis expression is identical to the definition of the reliability of the measurement $\\bar{Y}_{i\\cdot}$. The attenuation factor is the reliability coefficient of the exposure variable used in the regression.\nThus, the attenuation factor is also equal to $2/3$.\n$$\n\\lambda = \\frac{2}{3} \\approx 0.6667\n$$\n\nThe two quantities requested are the reliability of the mean of two replicates and the attenuation factor. Both are equal to $2/3$.\n1. Reliability of the mean of two replicates: $2/3 \\approx 0.6667$\n2. Attenuation factor: $2/3 \\approx 0.6667$\n\nPreparing the final answer as a row vector rounded to four significant figures.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.6667 & 0.6667\n\\end{pmatrix}\n}\n$$", "id": "4642573"}, {"introduction": "While previous exercises focused on analyzing the reliability of existing measures, this final practice equips you with a powerful tool for prospective study design. The Spearman-Brown prophecy formula allows researchers to predict how changes in test length will affect reliability. This exercise demonstrates how to calculate the necessary adjustments to an instrument to achieve a desired level of precision, a vital skill for designing robust questionnaires and checklists. [@problem_id:4642628]", "problem": "A public health researcher in epidemiology is validating a symptom checklist used to monitor respiratory disease burden in a community cohort. The checklist is a sum score over multiple items, each designed to be parallel and tau-equivalent (that is, items have equal variance and equal true-score correlation structure). The observed score of each item is assumed to follow classical test theory, where the observed score is the sum of a true score and an error term, and reliability is defined as the proportion of observed-score variance attributable to the true score.\n\nStarting from the classical test theory definition that reliability is the ratio of true-score variance to observed-score variance for a composite formed by the sum of $n$ items, and using the standard expression for reliability of tau-equivalent items in terms of the number of items, the average item variance, and the average inter-item covariance, derive an expression for the reliability of the test after the number of items is multiplied by a positive factor $k$ under the assumption that added items are parallel to the original items. Then, use that expression to compute the required multiplier $k$ to increase reliability from $0.6$ to $0.8$.\n\nProvide the final value of $k$ as a dimensionless multiplier. Round your answer to three significant figures.", "solution": "The problem asks for two things: first, to derive an expression for the reliability of a test after its length is changed by a multiplicative factor $k$, and second, to use this expression to calculate the specific factor $k$ required to increase a test's reliability from an initial value of $0.6$ to a final value of $0.8$. The problem is situated within the framework of Classical Test Theory (CTT) and assumes the test items are tau-equivalent.\n\nThe reliability of a test composite score, formed by the sum of $n$ items that are tau-equivalent, is given by the standardized Cronbach's alpha formula, which is a specific form of the Spearman-Brown prophecy formula. This formula relates the total test reliability, which we denote as $\\rho_n$ for a test with $n$ items, to the average inter-item correlation, $\\bar{r}$. The formula is:\n$$ \\rho_n = \\frac{n \\bar{r}}{1 + (n-1)\\bar{r}} $$\nHere, $\\bar{r}$ represents the average correlation between any two items in the test. The problem assumes that any new items added to the test are parallel to the original items, which implies they share the same statistical properties. Therefore, the value of $\\bar{r}$ can be considered constant as the test length changes.\n\nOur first goal is to derive a formula for the new reliability, $\\rho_{kn}$, of a test whose length has been changed from $n$ items to $N = kn$ items, where $k$ is a positive multiplier. The new reliability, $\\rho_{kn}$, will be given by the same formula, but with $kn$ in place of $n$:\n$$ \\rho_{kn} = \\frac{kn \\bar{r}}{1 + (kn-1)\\bar{r}} $$\nTo find an expression for $\\rho_{kn}$ in terms of $\\rho_n$ and $k$, we must eliminate the term $\\bar{r}$ from these equations. A robust method is to rearrange the first equation to solve for a quantity involving $\\bar{r}$. A particularly useful rearrangement involves the odds ratio of reliability, $\\frac{\\rho_n}{1-\\rho_n}$:\n$$ \\frac{\\rho_n}{1-\\rho_n} = \\frac{\\frac{n \\bar{r}}{1 + (n-1)\\bar{r}}}{1 - \\frac{n \\bar{r}}{1 + (n-1)\\bar{r}}} = \\frac{\\frac{n \\bar{r}}{1 + (n-1)\\bar{r}}}{\\frac{1 + (n-1)\\bar{r} - n \\bar{r}}{1 + (n-1)\\bar{r}}} = \\frac{n \\bar{r}}{1 + n\\bar{r} - \\bar{r} - n\\bar{r}} = \\frac{n \\bar{r}}{1 - \\bar{r}} $$\nSo, we have the elegant relationship:\n$$ \\frac{\\rho_n}{1-\\rho_n} = n \\left( \\frac{\\bar{r}}{1-\\bar{r}} \\right) $$\nThis relationship holds for any test length. For the new test with $kn$ items, we can write the analogous expression:\n$$ \\frac{\\rho_{kn}}{1-\\rho_{kn}} = kn \\left( \\frac{\\bar{r}}{1-\\bar{r}} \\right) $$\nNow, we can find the ratio of these two expressions to eliminate the term involving $\\bar{r}$:\n$$ \\frac{\\frac{\\rho_{kn}}{1-\\rho_{kn}}}{\\frac{\\rho_n}{1-\\rho_n}} = \\frac{kn \\left( \\frac{\\bar{r}}{1-\\bar{r}} \\right)}{n \\left( \\frac{\\bar{r}}{1-\\bar{r}} \\right)} = k $$\nThis gives us a direct relationship between the old reliability, the new reliability, and the multiplier $k$:\n$$ \\frac{\\rho_{kn}}{1-\\rho_{kn}} = k \\left( \\frac{\\rho_n}{1-\\rho_n} \\right) $$\nTo complete the first part of the task, we solve this equation for $\\rho_{kn}$. Let the quantity $R_{kn} = \\frac{\\rho_{kn}}{1-\\rho_{kn}}$. Then $\\rho_{kn} = \\frac{R_{kn}}{1+R_{kn}}$. Substituting the expression involving $k$ and $\\rho_n$:\n$$ \\rho_{kn} = \\frac{k \\left( \\frac{\\rho_n}{1-\\rho_n} \\right)}{1 + k \\left( \\frac{\\rho_n}{1-\\rho_n} \\right)} $$\nTo simplify, we multiply the numerator and denominator by $(1-\\rho_n)$:\n$$ \\rho_{kn} = \\frac{k \\rho_n}{(1-\\rho_n) + k \\rho_n} = \\frac{k \\rho_n}{1 - \\rho_n + k \\rho_n} $$\nThis yields the final derived expression, which is the Spearman-Brown prophecy formula:\n$$ \\rho_{kn} = \\frac{k \\rho_n}{1 + (k-1)\\rho_n} $$\nThis is the expression for the reliability of the test after the number of items is multiplied by the factor $k$.\n\nFor the second part of the task, we use this formula to find the value of $k$ required to increase the reliability from an initial value $\\rho_n = 0.6$ to a target value $\\rho_{kn} = 0.8$. We rearrange the relationship we found earlier to solve for $k$:\n$$ k = \\frac{\\frac{\\rho_{kn}}{1-\\rho_{kn}}}{\\frac{\\rho_n}{1-\\rho_n}} = \\frac{\\rho_{kn}(1-\\rho_n)}{\\rho_n(1-\\rho_{kn})} $$\nNow, we substitute the given numerical values:\nInitial reliability, $\\rho_n = 0.6$.\nTarget reliability, $\\rho_{kn} = 0.8$.\n\n$$ k = \\frac{0.8 (1 - 0.6)}{0.6 (1 - 0.8)} $$\n$$ k = \\frac{0.8 \\times 0.4}{0.6 \\times 0.2} $$\n$$ k = \\frac{0.32}{0.12} $$\n$$ k = \\frac{32}{12} = \\frac{8}{3} $$\nThe question requires the answer to be rounded to three significant figures.\n$$ k = 2.6666... \\approx 2.67 $$\nThus, the number of items in the checklist must be multiplied by a factor of approximately $2.67$ to achieve the desired reliability of $0.8$.", "answer": "$$\\boxed{2.67}$$", "id": "4642628"}]}