{"hands_on_practices": [{"introduction": "For a causal comparison to be valid, the exposed and unexposed groups must be exchangeable, meaning they should be comparable in all respects other than the exposure itself. This exercise [@problem_id:4635157] explores a fundamental threat to exchangeability that arises at the study design phase: selecting groups from different source populations. By working through a plausible scenario involving two distinct clinical referral networks, you will uncover how this seemingly practical design choice can introduce a severe form of selection bias, even when adjusting for measured confounders.", "problem": "An investigator wants to estimate the causal effect of a new clinic-based exposure $X$ on a binary outcome $Y$ using observational data. Let $Y^x$ denote the potential outcome under exposure level $x \\in \\{0,1\\}$. The target exchangeability condition is $Y^x \\perp X \\mid Z$, where $Z$ is a measured covariate. The investigator assembles the exposed group from one referral network and the unexposed group from a different referral network. Consider the following explicit data-generating process, which is scientifically plausible for clinic-based exposures:\n\n- Let $Z \\in \\{0,1\\}$ denote age group, with $P(Z=1)=0.5$. For simplicity, assume $Z$ is independent of other baseline variables below.\n- Let $U \\in \\{0,1\\}$ denote an unmeasured care-seeking tendency that increases both the chance of being referred to a particular network and the risk of the outcome. Let $P(U=1)=0.5$ and $U \\perp Z$.\n- Let $R \\in \\{0,1\\}$ denote referral network, where $R=1$ is a large tertiary network and $R=0$ is a community network. Care-seeking $U$ strongly influences referral: $P(R=1 \\mid U=1)=0.9$ and $P(R=1 \\mid U=0)=0.1$.\n- The clinic exposure $X$ is available only in the tertiary network: $P(X=1 \\mid R=1)=0.5$ and $P(X=1 \\mid R=0)=0$. Thus $X \\perp (U,Z)$ given $R=1$, but $X=0$ almost surely when $R=0$.\n- The outcome $Y \\in \\{0,1\\}$ has potential outcome risks driven by $U$ and exposure benefit: $P(Y^1=1 \\mid U=1)=0.3$, $P(Y^1=1 \\mid U=0)=0.1$, $P(Y^0=1 \\mid U=1)=0.4$, and $P(Y^0=1 \\mid U=0)=0.2$. Thus, for any fixed $U$, exposure reduces risk.\n- The assembled study samples only individuals with selection indicator $S=1$, where the design is: exposed are taken from the tertiary network and unexposed from the community network. Formally, $S=1$ if and only if $(X=1 \\wedge R=1)$ or $(X=0 \\wedge R=0)$; otherwise $S=0$. This captures “exposed from network $R=1$” and “unexposed from network $R=0$.”\n\nWorking within the assembled sample with $S=1$:\n\n- Show, by reasoning from the definitions above, whether $Y^x \\perp X \\mid Z$ holds.\n- Briefly justify the causal mechanism that succeeds or fails, referencing the structure relating $U$, $R$, $X$, $S$, $Z$, and $Y^x$.\n\nWhich option best describes whether $Y^x \\perp X \\mid Z$ holds in this assembled sample and the mechanism?\n\nA. No. Selecting unexposed from a different referral network induces association between $X$ and the unmeasured $U$ within $S=1$ through the path $X \\rightarrow S \\leftarrow R \\leftarrow U$, violating $Y^x \\perp X \\mid Z$ even after adjusting for $Z$. Moreover, within $S=1$ there is a positivity violation with respect to $R$ ($P(X=1 \\mid R=0, S=1)=0$ and $P(X=0 \\mid R=1, S=1)=0$), so adjusting for $R$ cannot recover exchangeability.\n\nB. Yes. Because exposure assignment is randomized within $R=1$ and controls from $R=0$ represent the same source population within levels of $Z$, we have $Y^x \\perp X \\mid Z$.\n\nC. No. Exchangeability fails, but it can be restored by adjusting for referral network $R$, which blocks all backdoor paths, so $Y^x \\perp X \\mid (Z,R)$ holds and the effect is identifiable.\n\nD. Yes. Age group $Z$ fully captures care-seeking differences relevant to both $R$ and $Y$, so conditioning on $Z$ suffices for $Y^x \\perp X \\mid Z$ even with different networks.", "solution": "The user wants me to validate and solve a problem in epidemiology regarding causal inference and selection bias.\n\n### Step 1: Extract Givens\n\nThe problem statement provides the following information:\n-   **Goal**: Estimate the causal effect of a binary exposure $X \\in \\{0,1\\}$ on a binary outcome $Y \\in \\{0,1\\}$.\n-   **Potential Outcomes**: $Y^x$ for $x \\in \\{0,1\\}$.\n-   **Target Condition**: Exchangeability, $Y^x \\perp X \\mid Z$.\n-   **Measured Covariate**: $Z \\in \\{0,1\\}$ (age group), with $P(Z=1)=0.5$. $Z$ is independent of other baseline variables.\n-   **Unmeasured Covariate**: $U \\in \\{0,1\\}$ (care-seeking tendency), with $P(U=1)=0.5$.\n-   **Independence**: $U \\perp Z$.\n-   **Referral Network**: $R \\in \\{0,1\\}$, where $R=1$ is tertiary and $R=0$ is community.\n-   **Relationship between $U$ and $R$**: $P(R=1 \\mid U=1)=0.9$ and $P(R=1 \\mid U=0)=0.1$.\n-   **Relationship between $R$ and $X$**: Exposure $X$ is available only in network $R=1$. Formally, $P(X=1 \\mid R=1)=0.5$ and $P(X=1 \\mid R=0)=0$.\n-   **Conditional Independence**: $X \\perp (U,Z)$ given $R=1$.\n-   **Relationship between $U$ and $Y^x$**:\n    -   $P(Y^1=1 \\mid U=1)=0.3$\n    -   $P(Y^1=1 \\mid U=0)=0.1$\n    -   $P(Y^0=1 \\mid U=1)=0.4$\n    -   $P(Y^0=1 \\mid U=0)=0.2$\n-   **Study Selection**: The analysis is restricted to a sample where selection indicator $S=1$. The selection rule is: $S=1$ if and only if $(X=1 \\wedge R=1)$ or $(X=0 \\wedge R=0)$.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is a well-defined exercise in causal inference, specifically examining the impact of selection bias on exchangeability.\n\n-   **Scientifically Grounded**: The problem uses standard potential outcome notation and concepts from modern epidemiology, such as exchangeability, confounding, and selection bias. The scenario of drawing exposed and unexposed groups from different clinical populations is a realistic and common challenge in observational research. The probabilistic model is internally consistent.\n-   **Well-Posed**: The problem provides a complete quantitative data-generating process and asks a precise mathematical question: to determine if the conditional independence statement $Y^x \\perp X \\mid Z$ holds true within the subpopulation defined by $S=1$. A definite answer can be derived from the given probabilities.\n-   **Objective**: The problem is stated in objective, formal language. All terms are defined probabilistically.\n\nThe problem does not violate any of the invalidity criteria. It is a scientifically sound, well-posed, and objective problem that is central to the field of epidemiology.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. I will proceed with the solution.\n\n### Derivation\n\nThe primary task is to determine whether the exchangeability condition $Y^x \\perp X \\mid Z$ holds within the assembled sample, which is the stratum where $S=1$.\n\nThe condition $Y^x \\perp X \\mid Z$ holds if, within strata of $Z$, the distribution of potential outcomes $Y^x$ is the same for the exposed ($X=1$) and the unexposed ($X=0$). In this problem, the potential outcomes $Y^x$ are directly caused by the unmeasured variable $U$. Therefore, exchangeability holds if and only if the distribution of $U$ is the same for the exposed and unexposed groups, conditional on $Z$. That is, we must check if $U \\perp X \\mid Z, S=1$.\n\nThe problem states that $Z$ is independent of all other baseline variables, including $U$. Furthermore, $Z$ does not influence $R$, $X$, or $Y^x$ according to the specified probabilities. Therefore, conditioning on $Z$ does not alter the relationship between $U$ and $X$. The condition simplifies to testing whether $U \\perp X \\mid S=1$. To check this, we will compute and compare $P(U=1 \\mid X=1, S=1)$ and $P(U=1 \\mid X=0, S=1)$.\n\n1.  **Analyze the sample composition:**\n    -   The sample is defined by $S=1$, which means $(X=1 \\wedge R=1)$ or $(X=0 \\wedge R=0)$.\n    -   This implies that within the sample, an individual is exposed ($X=1$) if and only if they are from the tertiary network ($R=1$).\n    -   Similarly, an individual is unexposed ($X=0$) if and only if they are from the community network ($R=0$).\n    -   Therefore, within the $S=1$ stratum, the events $\\{X=1\\}$ and $\\{R=1\\}$ are identical, and the events $\\{X=0\\}$ and $\\{R=0\\}$ are identical.\n\n2.  **Calculate the distribution of $U$ in the exposed group ($X=1, S=1$):**\n    We need to find $P(U=1 \\mid X=1, S=1)$. Given the sample definition, this is equivalent to $P(U=1 \\mid R=1)$.\n    We use Bayes' theorem:\n    $$ P(U=1 \\mid R=1) = \\frac{P(R=1 \\mid U=1)P(U=1)}{P(R=1)} $$\n    First, we find the marginal probability $P(R=1)$:\n    $$ P(R=1) = P(R=1 \\mid U=1)P(U=1) + P(R=1 \\mid U=0)P(U=0) $$\n    $$ P(R=1) = (0.9)(0.5) + (0.1)(0.5) = 0.45 + 0.05 = 0.5 $$\n    Now, substitute this back:\n    $$ P(U=1 \\mid R=1) = \\frac{(0.9)(0.5)}{0.5} = 0.9 $$\n    So, in the exposed group, $90\\%$ of individuals have the high care-seeking tendency ($U=1$).\n\n3.  **Calculate the distribution of $U$ in the unexposed group ($X=0, S=1$):**\n    We need to find $P(U=1 \\mid X=0, S=1)$. This is equivalent to $P(U=1 \\mid R=0)$.\n    We use Bayes' theorem again:\n    $$ P(U=1 \\mid R=0) = \\frac{P(R=0 \\mid U=1)P(U=1)}{P(R=0)} $$\n    We know $P(R=0) = 1 - P(R=1) = 1 - 0.5 = 0.5$.\n    And $P(R=0 \\mid U=1) = 1 - P(R=1 \\mid U=1) = 1 - 0.9 = 0.1$.\n    $$ P(U=1 \\mid R=0) = \\frac{(0.1)(0.5)}{0.5} = 0.1 $$\n    So, in the unexposed group, only $10\\%$ of individuals have the high care-seeking tendency ($U=1$).\n\n4.  **Conclusion on Exchangeability:**\n    We found that $P(U=1 \\mid X=1, S=1, Z) = 0.9$ while $P(U=1 \\mid X=0, S=1, Z) = 0.1$. Since these probabilities are not equal, the distribution of the confounder $U$ is drastically different between the exposed and unexposed groups in the study sample. Because $U$ is a direct cause of the potential outcomes $Y^x$, this imbalance in $U$ translates to an imbalance in the baseline risk of the outcome.\n    Therefore, $Y^x \\not\\perp X \\mid Z$ in the sample with $S=1$. The exchangeability condition fails.\n\n5.  **Causal Mechanism:**\n    The failure of exchangeability is a form of selection bias. The study design, by selecting exposed individuals from one network ($R=1$) and unexposed from another ($R=0$), creates a spurious association between exposure $X$ and the unmeasured confounder $U$. The causal structure can be represented by a Directed Acyclic Graph (DAG), where we have the paths $U \\rightarrow R \\rightarrow X$ and $U \\rightarrow Y^x$. The variable $S$ is a collider, determined by both $X$ and $R$. Conditioning on $S=1$ (i.e., selecting the study sample) induces an association between $X$ and $U$. The path $X \\rightarrow S \\leftarrow R \\leftarrow U$ is opened by conditioning on the collider $S$, creating a non-causal association between $X$ and $U$. Since $U$ is a cause of $Y^x$, this leads to confounding. The exposed and unexposed groups are not comparable because a much higher proportion of the exposed group has the high-risk factor $U=1$.\n\n### Option-by-Option Analysis\n\n**A. No. Selecting unexposed from a different referral network induces association between $X$ and the unmeasured $U$ within $S=1$ through the path $X \\rightarrow S \\leftarrow R \\leftarrow U$, violating $Y^x \\perp X \\mid Z$ even after adjusting for $Z$. Moreover, within $S=1$ there is a positivity violation with respect to $R$ ($P(X=1 \\mid R=0, S=1)=0$ and $P(X=0 \\mid R=1, S=1)=0$), so adjusting for $R$ cannot recover exchangeability.**\n-   This option correctly states that exchangeability ($Y^x \\perp X \\mid Z$) fails.\n-   It correctly identifies the mechanism: the selection process induces an association between exposure $X$ and the unmeasured confounder $U$. The description of the path $X \\rightarrow S \\leftarrow R \\leftarrow U$ accurately depicts the collider stratification bias mechanism.\n-   It correctly identifies a critical secondary issue: a positivity violation. Within the sample ($S=1$), if we know a person is from network $R=0$, they must have $X=0$. So, $P(X=1 \\mid R=0, S=1)=0$. Conversely, if they are from network $R=1$, they must have $X=1$, so $P(X=0 \\mid R=1, S=1)=0$. This lack of positivity means it is impossible to adjust for the referral network $R$ to try to fix the bias, as there are no exposed subjects in the $R=0$ stratum and no unexposed subjects in the $R=1$ stratum.\n-   **Verdict: Correct.**\n\n**B. Yes. Because exposure assignment is randomized within $R=1$ and controls from $R=0$ represent the same source population within levels of $Z$, we have $Y^x \\perp X \\mid Z$.**\n-   This option incorrectly claims that exchangeability holds.\n-   The critical flaw in reasoning is the assertion that controls from $R=0$ \"represent the same source population\" as the cases from $R=1$. As demonstrated by our calculation, the distribution of the unmeasured prognostic factor $U$ is $90\\%$ for the exposed group ($R=1$) and $10\\%$ for the unexposed group ($R=0$). These are fundamentally different populations.\n-   **Verdict: Incorrect.**\n\n**C. No. Exchangeability fails, but it can be restored by adjusting for referral network $R$, which blocks all backdoor paths, so $Y^x \\perp X \\mid (Z,R)$ holds and the effect is identifiable.**\n-   This option correctly states that exchangeability fails.\n-   However, it incorrectly claims the issue can be resolved by adjusting for $R$. As analyzed for option A, the study design creates a perfect correlation between $X$ and $R$ within the selected sample ($X=R$ when $S=1$). This results in a complete lack of positivity, making it impossible to perform an adjustment for $R$. One cannot compare exposed and unexposed subjects within the same stratum of $R$.\n-   **Verdict: Incorrect.**\n\n**D. Yes. Age group $Z$ fully captures care-seeking differences relevant to both $R$ and $Y$, so conditioning on $Z$ suffices for $Y^x \\perp X \\mid Z$ even with different networks.**\n-   This option incorrectly claims that exchangeability holds.\n-   The reasoning is factually wrong based on the problem statement. The problem explicitly states that $U$ is the care-seeking tendency and that $U \\perp Z$. Therefore, the measured variable $Z$ captures *none* of the differences in care-seeking tendency $U$.\n-   **Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "4635157"}, {"introduction": "Bias in selecting comparison groups can also arise from decisions made about follow-up time, not just from the initial sampling. A common error in longitudinal studies is to define the \"unexposed\" group by selecting individuals who remain free of the exposure throughout the entire study period. This practice [@problem_id:4635169] provides a quantitative demonstration of the bias introduced by such a design, where selection of the comparator is based on a post-exposure event. Calculating the magnitude of this bias will reinforce the critical principle that comparability must be assessed at the time of exposure initiation.", "problem": "Consider a longitudinal cohort with two time points $t \\in \\{1,2\\}$. Let $L \\in \\{0,1\\}$ be a baseline covariate measured before $t=1$, $A_1 \\in \\{0,1\\}$ be the exposure at $t=1$, $A_2 \\in \\{0,1\\}$ be a subsequent exposure at $t=2$, and $Y \\in \\{0,1\\}$ be the final outcome measured at $t=2$. Define the potential outcome $Y^a$ as the outcome that would be observed at $t=2$ if the exposure at $t=1$ were set to $a \\in \\{0,1\\}$, with all subsequent events evolving as they naturally would under that intervention. The target estimand is the average treatment effect (ATE), $E[Y^1] - E[Y^0]$.\n\nAssume the following scientifically plausible data-generating mechanism:\n- Baseline covariate: $P(L=1) = 0.5$.\n- Exposure at $t=1$: $P(A_1=1 \\mid L=1) = 0.8$ and $P(A_1=1 \\mid L=0) = 0.2$.\n- Subsequent exposure at $t=2$ among those unexposed at $t=1$: $P(A_2=1 \\mid A_1=0, L=1) = 0.7$ and $P(A_2=1 \\mid A_1=0, L=0) = 0.1$. Individuals exposed at $t=1$ remain exposed at $t=2$, that is, $A_2=1$ deterministically if $A_1=1$.\n- Outcome model under consistency: for individuals with $A_1=a$, the conditional mean equals the corresponding potential outcome mean given $L$, that is, $E(Y \\mid L, A_1=a) = E(Y^a \\mid L)$. Specifically,\n  - $E(Y^1 \\mid L=1) = 0.6$, $E(Y^1 \\mid L=0) = 0.2$,\n  - $E(Y^0 \\mid L=1) = 0.3$, $E(Y^0 \\mid L=0) = 0.1$.\n\nA researcher incorrectly defines the unexposed comparison group at $t=1$ by restricting to individuals who are unexposed at both $t=1$ and $t=2$ (the so-called “never-exposed” up to $t=2$), and then computes the naive difference in observed means $E(Y \\mid A_1=1) - E(Y \\mid A_1=0, A_2=0)$ to estimate $E[Y^1] - E[Y^0]$.\n\nCompute the bias of this incorrect estimator relative to the true $E[Y^1] - E[Y^0]$. Express your final answer as an exact fraction. No rounding is required, and no units are involved.", "solution": "The user wants me to validate and solve a problem from the field of epidemiology, focusing on causal inference.\n\n### Step 1: Extract Givens\n-   **Study Design**: A longitudinal cohort with two time points, $t \\in \\{1,2\\}$.\n-   **Variables**:\n    -   $L \\in \\{0,1\\}$: a baseline covariate.\n    -   $A_1 \\in \\{0,1\\}$: exposure at $t=1$.\n    -   $A_2 \\in \\{0,1\\}$: exposure at $t=2$.\n    -   $Y \\in \\{0,1\\}$: outcome at $t=2$.\n-   **Potential Outcome**: $Y^a$ is the outcome under intervention $A_1=a$, for $a \\in \\{0,1\\}$.\n-   **Target Estimand**: The Average Treatment Effect (ATE), defined as $E[Y^1] - E[Y^0]$.\n-   **Data-Generating Mechanism**:\n    -   $P(L=1) = 0.5$.\n    -   $P(A_1=1 \\mid L=1) = 0.8$.\n    -   $P(A_1=1 \\mid L=0) = 0.2$.\n    -   $P(A_2=1 \\mid A_1=0, L=1) = 0.7$.\n    -   $P(A_2=1 \\mid A_1=0, L=0) = 0.1$.\n    -   $A_2=1$ deterministically if $A_1=1$.\n-   **Outcome Model**: The consistency and conditional exchangeability assumptions are combined into the relation $E(Y \\mid L, A_1=a) = E(Y^a \\mid L)$.\n    -   $E(Y^1 \\mid L=1) = 0.6$.\n    -   $E(Y^1 \\mid L=0) = 0.2$.\n    -   $E(Y^0 \\mid L=1) = 0.3$.\n    -   $E(Y^0 \\mid L=0) = 0.1$.\n-   **Incorrect Estimator**: A naive difference in means, $E(Y \\mid A_1=1) - E(Y \\mid A_1=0, A_2=0)$.\n-   **Objective**: Compute the bias of the incorrect estimator, defined as $(E(Y \\mid A_1=1) - E(Y \\mid A_1=0, A_2=0)) - (E[Y^1] - E[Y^0])$. The answer must be an exact fraction.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is a well-formulated exercise in causal inference, a core area of epidemiology and biostatistics. It uses standard concepts like potential outcomes, confounding, and selection bias. The setup is a simplified but conceptually sound model of a longitudinal study. All assumptions, such as consistency and the given probabilities, are standard for such pedagogical problems.\n-   **Well-Posed**: All necessary numerical values and probabilistic relationships are provided to calculate both the true ATE and the value of the incorrect estimator. The objective is clearly stated. The assumption $E(Y \\mid L, A_1=a) = E(Y^a \\mid L)$ implies that the outcome expectation is not dependent on $A_2$ given $L$ and $A_1$, which makes the problem fully specified.\n-   **Objective**: The problem is stated in precise, formal language without ambiguity or subjective elements.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically sound, well-posed, objective, and contains all necessary information for a unique solution. I will proceed with the calculation.\n\n### Solution\n\nThe objective is to compute the bias of the researcher's estimator. The bias is the difference between the expected value of the estimator and the true parameter of interest.\n$$\n\\text{Bias} = \\left( E(Y \\mid A_1=1) - E(Y \\mid A_1=0, A_2=0) \\right) - \\left( E[Y^1] - E[Y^0] \\right)\n$$\nWe will compute each of the four expectation terms. For precision, we convert all given decimal probabilities to fractions: $0.1 = \\frac{1}{10}$, $0.2 = \\frac{1}{5}$, $0.3 = \\frac{3}{10}$, $0.5 = \\frac{1}{2}$, $0.6 = \\frac{3}{5}$, $0.7 = \\frac{7}{10}$, $0.8 = \\frac{4}{5}$.\n\n**1. Calculation of the True Average Treatment Effect (ATE), $E[Y^1] - E[Y^0]$**\n\nWe use the law of total expectation, marginalizing over the covariate $L$.\n$$\nE[Y^a] = E[E[Y^a \\mid L]] = E[Y^a \\mid L=1]P(L=1) + E[Y^a \\mid L=0]P(L=0)\n$$\nGiven $P(L=1) = \\frac{1}{2}$, it follows that $P(L=0) = 1 - \\frac{1}{2} = \\frac{1}{2}$.\n\n-   For the potential outcome under exposure ($a=1$):\n    $$\n    E[Y^1] = \\left(\\frac{3}{5}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{5}\\right)\\left(\\frac{1}{2}\\right) = \\frac{3}{10} + \\frac{1}{10} = \\frac{4}{10} = \\frac{2}{5}\n    $$\n-   For the potential outcome under no exposure ($a=0$):\n    $$\n    E[Y^0] = \\left(\\frac{3}{10}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{10}\\right)\\left(\\frac{1}{2}\\right) = \\frac{3}{20} + \\frac{1}{20} = \\frac{4}{20} = \\frac{1}{5}\n    $$\n-   The true ATE is:\n    $$\n    E[Y^1] - E[Y^0] = \\frac{2}{5} - \\frac{1}{5} = \\frac{1}{5}\n    $$\n\n**2. Calculation of the Incorrect Estimator, $E(Y \\mid A_1=1) - E(Y \\mid A_1=0, A_2=0)$**\n\nThis requires calculating two conditional expectations from the observed data distribution.\n\n**a. Calculate $E(Y \\mid A_1=1)$**\n\nWe use the law of total expectation, conditioning on $L$:\n$$\nE(Y \\mid A_1=1) = E(Y \\mid A_1=1, L=1)P(L=1 \\mid A_1=1) + E(Y \\mid A_1=1, L=0)P(L=0 \\mid A_1=1)\n$$\nFrom the problem's outcome model, $E(Y \\mid L, A_1=a) = E(Y^a \\mid L)$.\nThus, $E(Y \\mid A_1=1, L=1) = E(Y^1 \\mid L=1) = \\frac{3}{5}$ and $E(Y \\mid A_1=1, L=0) = E(Y^1 \\mid L=0) = \\frac{1}{5}$.\n\nWe find the conditional probabilities $P(L=l \\mid A_1=1)$ using Bayes' theorem, which requires the marginal probability $P(A_1=1)$:\n$$\nP(A_1=1) = P(A_1=1 \\mid L=1)P(L=1) + P(A_1=1 \\mid L=0)P(L=0) = \\left(\\frac{4}{5}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{1}{5}\\right)\\left(\\frac{1}{2}\\right) = \\frac{4}{10} + \\frac{1}{10} = \\frac{5}{10} = \\frac{1}{2}\n$$\nNow, applying Bayes' theorem:\n$$\nP(L=1 \\mid A_1=1) = \\frac{P(A_1=1 \\mid L=1)P(L=1)}{P(A_1=1)} = \\frac{(\\frac{4}{5})(\\frac{1}{2})}{\\frac{1}{2}} = \\frac{4}{5}\n$$\nAnd $P(L=0 \\mid A_1=1) = 1 - P(L=1 \\mid A_1=1) = 1 - \\frac{4}{5} = \\frac{1}{5}$.\n\nSubstituting these into the expression for $E(Y \\mid A_1=1)$:\n$$\nE(Y \\mid A_1=1) = \\left(\\frac{3}{5}\\right)\\left(\\frac{4}{5}\\right) + \\left(\\frac{1}{5}\\right)\\left(\\frac{1}{5}\\right) = \\frac{12}{25} + \\frac{1}{25} = \\frac{13}{25}\n$$\n\n**b. Calculate $E(Y \\mid A_1=0, A_2=0)$**\n\nWe condition on $L$:\n$$\nE(Y \\mid A_1=0, A_2=0) = E(Y \\mid A_1=0, A_2=0, L=1)P(L=1|A_1=0, A_2=0) + E(Y \\mid A_1=0, A_2=0, L=0)P(L=0|A_1=0, A_2=0)\n$$\nThe problem's outcome model $E(Y \\mid L, A_1=a) = E(Y^a \\mid L)$ implies that the expectation of $Y$ does not depend on $A_2$ after conditioning on $A_1$ and $L$. Therefore, $E(Y \\mid A_1=0, A_2=0, L=l) = E(Y \\mid A_1=0, L=l) = E(Y^0 \\mid L=l)$.\nSo, $E(Y \\mid A_1=0, A_2=0, L=1) = \\frac{3}{10}$ and $E(Y \\mid A_1=0, A_2=0, L=0) = \\frac{1}{10}$.\n\nWe find the weights $P(L=l \\mid A_1=0, A_2=0)$ using Bayes' theorem. First, we compute the joint probabilities $P(A_1=0, A_2=0 \\mid L=l)$:\n- For $L=1$: $P(A_1=0 \\mid L=1) = 1 - \\frac{4}{5} = \\frac{1}{5}$. $P(A_2=0 \\mid A_1=0, L=1) = 1 - \\frac{7}{10} = \\frac{3}{10}$.\n  $$\n  P(A_1=0, A_2=0 \\mid L=1) = P(A_2=0 \\mid A_1=0, L=1) P(A_1=0 \\mid L=1) = \\left(\\frac{3}{10}\\right)\\left(\\frac{1}{5}\\right) = \\frac{3}{50}\n  $$\n- For $L=0$: $P(A_1=0 \\mid L=0) = 1 - \\frac{1}{5} = \\frac{4}{5}$. $P(A_2=0 \\mid A_1=0, L=0) = 1 - \\frac{1}{10} = \\frac{9}{10}$.\n  $$\n  P(A_1=0, A_2=0 \\mid L=0) = P(A_2=0 \\mid A_1=0, L=0) P(A_1=0 \\mid L=0) = \\left(\\frac{9}{10}\\right)\\left(\\frac{4}{5}\\right) = \\frac{36}{50} = \\frac{18}{25}\n  $$\nThe marginal probability $P(A_1=0, A_2=0)$ is:\n$$\nP(A_1=0, A_2=0) = P(A_1=0, A_2=0 \\mid L=1)P(L=1) + P(A_1=0, A_2=0 \\mid L=0)P(L=0) = \\left(\\frac{3}{50}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{36}{50}\\right)\\left(\\frac{1}{2}\\right) = \\frac{3}{100} + \\frac{36}{100} = \\frac{39}{100}\n$$\nNow, by Bayes' theorem:\n$$\nP(L=1 \\mid A_1=0,A_2=0) = \\frac{P(A_1=0,A_2=0 \\mid L=1)P(L=1)}{P(A_1=0,A_2=0)} = \\frac{\\frac{3}{100}}{\\frac{39}{100}} = \\frac{3}{39} = \\frac{1}{13}\n$$\nSo, $P(L=0 \\mid A_1=0,A_2=0) = 1 - \\frac{1}{13} = \\frac{12}{13}$.\n\nSubstituting these values:\n$$\nE(Y \\mid A_1=0, A_2=0) = \\left(\\frac{3}{10}\\right)\\left(\\frac{1}{13}\\right) + \\left(\\frac{1}{10}\\right)\\left(\\frac{12}{13}\\right) = \\frac{3}{130} + \\frac{12}{130} = \\frac{15}{130} = \\frac{3}{26}\n$$\n\n**3. Calculation of the Bias**\n\nThe value of the incorrect estimator is:\n$$\nE(Y \\mid A_1=1) - E(Y \\mid A_1=0, A_2=0) = \\frac{13}{25} - \\frac{3}{26} = \\frac{13 \\times 26 - 3 \\times 25}{25 \\times 26} = \\frac{338 - 75}{650} = \\frac{263}{650}\n$$\nThe bias is the difference between this value and the true ATE:\n$$\n\\text{Bias} = \\frac{263}{650} - \\text{ATE} = \\frac{263}{650} - \\frac{1}{5}\n$$\nTo subtract, we find a common denominator: $\\frac{1}{5} = \\frac{1 \\times 130}{5 \\times 130} = \\frac{130}{650}$.\n$$\n\\text{Bias} = \\frac{263}{650} - \\frac{130}{650} = \\frac{133}{650}\n$$\nThe fraction $\\frac{133}{650}$ is in its simplest form, as the prime factors of $133$ are $7$ and $19$, while the prime factors of $650=2 \\times 5^2 \\times 13$ do not include $7$ or $19$.", "answer": "$$\n\\boxed{\\frac{133}{650}}\n$$", "id": "4635169"}, {"introduction": "After designing a study and collecting data, we need practical tools to assess whether the exposed and unexposed groups are sufficiently comparable across a range of measured covariates. This hands-on problem [@problem_id:4635182] introduces the propensity score, $e(X)$, as a diagnostic tool to evaluate the \"positivity\" or \"overlap\" assumption. You will learn to interpret the distribution of propensity scores in both groups to identify practical violations of positivity and propose a principled trimming strategy, clarifying the trade-offs between ensuring comparability and defining the population to which your causal effect estimate applies.", "problem": "A cohort study evaluates the causal effect of a binary intervention $A$ (exposed versus unexposed) on a binary outcome $Y$, with confounding controlled through the propensity score $e(X) = P(A=1 \\mid X)$, where $X$ denotes measured baseline covariates. The causal estimand of interest prior to any restrictions is the average treatment effect (ATE), defined as $E[Y^{1} - Y^{0}]$, where $Y^{1}$ and $Y^{0}$ are the potential outcomes under exposure and no exposure, respectively. Identification of the ATE using propensity score-based methods requires the positivity (overlap) assumption: for all covariate values $x$ with positive density, $0  P(A=1 \\mid X=x)  1$ (equivalently, $0  e(x)  1$).\n\nYou fit a logistic regression for $A$ on $X$ to estimate the propensity score and then inspect the empirical support of the estimated propensity score, $\\hat{e}(X)$, by exposure status. The following summary is obtained:\n\n- Among exposed ($A=1$): the observed $\\hat{e}(X)$ values range from $0.22$ to $0.96$, with $15\\%$ of exposed having $\\hat{e}(X)  0.30$, $70\\%$ between $0.30$ and $0.80$, and $15\\%$ above $0.80$.\n- Among unexposed ($A=0$): the observed $\\hat{e}(X)$ values range from $0.03$ to $0.62$, with $40\\%$ having $\\hat{e}(X)  0.20$, $55\\%$ between $0.20$ and $0.60$, and $5\\%$ above $0.60$.\n\nAssume a large sample and that the propensity score model is correctly specified. You wish to diagnose practical positivity violations by inspecting the support of the propensity score and to propose a principled trimming rule that ensures adequate overlap for causal estimation. You must also state the causal estimand that remains after implementing your proposed trimming.\n\nWhich option best diagnoses the overlap, proposes an appropriate trimming rule, and correctly states the remaining estimand?\n\nA. Practical positivity is violated for $\\hat{e}(X)$ values below $0.22$ and above $0.62$ because one exposure group has essentially no support there. Trim to the intersection of supports, $\\hat{e}(X) \\in [0.22, 0.62]$. The remaining estimand is $E[Y^{1} - Y^{0} \\mid \\hat{e}(X) \\in [0.22, 0.62]]$, the ATE in the trimmed population (the region of common support).\n\nB. Practical positivity is violated at both low and high $\\hat{e}(X)$ values, but trimming is unnecessary; instead, retain all observations with $\\hat{e}(X) \\in [0.03, 0.96]$ (the union of supports) and estimate the original ATE using inverse probability weighting. The remaining estimand is $E[Y^{1} - Y^{0}]$ for the full population.\n\nC. There is no practical positivity problem because there is some overlap between exposure groups. Do not trim; use unstabilized inverse probability weights. The remaining estimand is $E[Y^{1} - Y^{0}]$.\n\nD. The overlap is poor outside high-density regions; trim aggressively to $\\hat{e}(X) \\in [0.30, 0.60]$ to improve precision. The remaining estimand is the average treatment effect in the treated (ATT), $E[Y^{1} - Y^{0} \\mid A=1]$.\n\nE. The overlap is inadequate at extreme $\\hat{e}(X)$ values; trim to $\\hat{e}(X) \\in [0.22, 0.60]$ because unexposed units above $0.60$ are rare. The remaining estimand is $E[Y^{1} - Y^{0} \\mid \\hat{e}(X) \\in [0.22, 0.60]]$, the ATE in the trimmed population.", "solution": "The user wants a critical evaluation of a problem in causal inference concerning the positivity assumption for propensity score analysis.\n\n### Step 1: Extract Givens\n\n- **Causal Model:** A cohort study with a binary intervention $A$ ($1$ for exposed, $0$ for unexposed), a binary outcome $Y$, and a set of measured baseline covariates $X$.\n- **Propensity Score (PS):** The probability of exposure conditional on covariates, $e(X) = P(A=1 \\mid X)$.\n- **Initial Estimand:** Average Treatment Effect (ATE), $E[Y^{1} - Y^{0}]$.\n- **Identification Assumption (Positivity):** For all covariate profiles $x$ with positive probability density, $0  e(x)  1$.\n- **Empirical Data (Estimated PS):** A logistic regression model is used to estimate $e(X)$. The study is assumed to have a large sample and the model for $e(X)$ is correctly specified.\n- **Support of $\\hat{e}(X)$ for Exposed ($A=1$):**\n    - Range: $[0.22, 0.96]$.\n    - Distribution: $15\\%$ of exposed have $\\hat{e}(X)  0.30$, $70\\%$ have $\\hat{e}(X) \\in [0.30, 0.80]$, and $15\\%$ have $\\hat{e}(X)  0.80$.\n- **Support of $\\hat{e}(X)$ for Unexposed ($A=0$):**\n    - Range: $[0.03, 0.62]$.\n    - Distribution: $40\\%$ of unexposed have $\\hat{e}(X)  0.20$, $55\\%$ have $\\hat{e}(X) \\in [0.20, 0.60]$, and $5\\%$ have $\\hat{e}(X)  0.60$.\n- **Objective:** To diagnose practical positivity violations, propose a principled trimming rule, and state the resulting causal estimand.\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem statement is scientifically grounded, well-posed, and objective. It describes a classic and realistic scenario in applied causal inference using propensity scores.\n\n1.  **Scientific Soundness:** The concepts presented—ATE, potential outcomes, propensity scores, the positivity assumption, and trimming—are fundamental to modern causal inference methodology in epidemiology and related fields. The logic is sound.\n2.  **Well-Posedness:** The problem provides sufficient quantitative information about the empirical distribution of the estimated propensity score to allow for a clear diagnosis of the overlap problem. The question asks for a specific set of deliverables (diagnosis, rule, estimand) that can be derived from the provided data.\n3.  **Objectivity:** The problem is stated in precise, quantitative terms, free from subjective language. The data about the propensity score distributions are clear and unambiguous.\n4.  **Consistency:** The provided ranges and percentages for the propensity score distributions are internally consistent and do not contain contradictions.\n5.  **Relevance:** The problem directly addresses the selection of exposed and unexposed groups based on covariate distributions, which is a core topic in epidemiology.\n\n### Step 3: Verdict and Action\n\nThe problem is **valid**. A solution will be derived by analyzing the provided data based on the principles of causal inference.\n\n### Derivation of Solution\n\nThe positivity assumption, also known as the overlap or common support condition, requires that for any given value of the propensity score $e(X)$, there is a non-zero probability of observing both exposed ($A=1$) and unexposed ($A=0$) individuals. In practice, this means we must have subjects from both exposure groups across the range of propensity scores used for estimation.\n\n1.  **Diagnosing the Positivity Violation:**\n    We are given the empirical support (range) of the estimated propensity score, $\\hat{e}(X)$, for each exposure group:\n    - Support for exposed ($A=1$): $S_1 = [0.22, 0.96]$\n    - Support for unexposed ($A=0$): $S_0 = [0.03, 0.62]$\n\n    For a causal effect to be identifiable for a given subpopulation defined by $\\hat{e}(X) = e$, we must have subjects from both groups in that subpopulation. The region where this holds is the *common support*, which is the intersection of the individual supports:\n    $$ S_{\\text{common}} = S_1 \\cap S_0 $$\n    $$ S_{\\text{common}} = [0.22, 0.96] \\cap [0.03, 0.62] $$\n    The intersection of two closed intervals $[a, b]$ and $[c, d]$ is $[\\max(a, c), \\min(b, d)]$.\n    $$ S_{\\text{common}} = [\\max(0.22, 0.03), \\min(0.96, 0.62)] = [0.22, 0.62] $$\n    Outside of this interval, the positivity assumption is empirically violated:\n    - In the range $\\hat{e}(X) \\in [0.03, 0.22)$, there are unexposed subjects but no exposed subjects.\n    - In the range $\\hat{e}(X) \\in (0.62, 0.96]$, there are exposed subjects but no unexposed subjects.\n    In these regions of non-overlap, it is impossible to estimate the causal effect because there is no one in the counterfactual group to compare with. For instance, an exposed subject with $\\hat{e}(X) = 0.80$ has no unexposed counterpart with a similar propensity score. Methods like inverse probability weighting (IPW) become unstable and invalid in these regions, as weights $1/\\hat{e}(X)$ or $1/(1-\\hat{e}(X))$ become extremely large where the denominator approaches zero.\n\n2.  **Proposing a Principled Trimming Rule:**\n    A principled and standard approach to handle this lack of overlap is to restrict the analysis to the population within the region of common support. This is known as *trimming*. The most direct trimming rule based on the non-overlap diagnosis is to discard all individuals with propensity scores outside the common support region.\n    - Proposed trimming rule: Restrict the analysis to individuals with $\\hat{e}(X) \\in [0.22, 0.62]$.\n\n3.  **Stating the Remaining Estimand:**\n    The original goal was to estimate the ATE for the entire population, $E[Y^{1} - Y^{0}]$. By trimming the sample, we are explicitly changing the target population of inference. We are no longer making a statement about the entire original population, but only about the subpopulation that has characteristics (as summarized by $X$) compatible with both exposure and non-exposure. The estimand for this new, trimmed population is the ATE conditional on being in that population.\n    - Remaining estimand: $E[Y^{1} - Y^{0} \\mid \\hat{e}(X) \\in [0.22, 0.62]]$. This is the \"ATE in the trimmed population\" or \"ATE in the region of common support\".\n\n### Option-by-Option Analysis\n\n**A. Practical positivity is violated for $\\hat{e}(X)$ values below $0.22$ and above $0.62$ because one exposure group has essentially no support there. Trim to the intersection of supports, $\\hat{e}(X) \\in [0.22, 0.62]$. The remaining estimand is $E[Y^{1} - Y^{0} \\mid \\hat{e}(X) \\in [0.22, 0.62]]$, the ATE in the trimmed population (the region of common support).**\n- This option correctly identifies the regions of non-overlap ($ 0.22$ and $> 0.62$). It proposes the correct, principled trimming rule based on the intersection of the empirical supports. It also correctly identifies the resulting estimand as the ATE in the trimmed subpopulation defined by the trimming rule.\n- **Verdict: Correct.**\n\n**B. Practical positivity is violated at both low and high $\\hat{e}(X)$ values, but trimming is unnecessary; instead, retain all observations with $\\hat{e}(X) \\in [0.03, 0.96]$ (the union of supports) and estimate the original ATE using inverse probability weighting. The remaining estimand is $E[Y^{1} - Y^{0}]$ for the full population.**\n- This option correctly notes the violation but proposes an incorrect solution. Attempting to estimate the ATE over the *union* of supports ($[0.03, 0.96]$) is precisely where the positivity violation causes estimators like IPW to fail due to extreme weights and lack of counterfactuals. One cannot reliably estimate the original ATE under these conditions.\n- **Verdict: Incorrect.**\n\n**C. There is no practical positivity problem because there is some overlap between exposure groups. Do not trim; use unstabilized inverse probability weights. The remaining estimand is $E[Y^{1} - Y^{0}]$.**\n- This option incorrectly claims there is no practical positivity problem. The existence of regions of complete non-overlap ($[0.03, 0.22)$ and $(0.62, 0.96]$) is the definition of a practical positivity violation. Ignoring this and proceeding without trimming is methodologically unsound.\n- **Verdict: Incorrect.**\n\n**D. The overlap is poor outside high-density regions; trim aggressively to $\\hat{e}(X) \\in [0.30, 0.60]$ to improve precision. The remaining estimand is the average treatment effect in the treated (ATT), $E[Y^{1} - Y^{0} \\mid A=1]$.**\n- While aggressive trimming to high-density regions is a possible strategy for variance reduction, this option makes a critical error in identifying the remaining estimand. Trimming based on the propensity score $\\hat{e}(X)$ defines a subpopulation based on covariates $X$, not on the treatment status $A$. The resulting estimand is an ATE for that covariate-defined subpopulation, not the average treatment effect in the treated (ATT), which is $E[Y^{1} - Y^{0} \\mid A=1]$. The ATT has a different target population (all individuals who received treatment).\n- **Verdict: Incorrect.**\n\n**E. The overlap is inadequate at extreme $\\hat{e}(X)$ values; trim to $\\hat{e}(X) \\in [0.22, 0.60]$ because unexposed units above $0.60$ are rare. The remaining estimand is $E[Y^{1} - Y^{0} \\mid \\hat{e}(X) \\in [0.22, 0.60]]$, the ATE in the trimmed population.**\n- This option proposes a trimming rule of $[0.22, 0.60]$. This is a subset of the region of common support, which is $[0.22, 0.62]$. The justification (rarity of unexposed units between $0.60$ and $0.62$) is a plausible heuristic for improving estimator precision. However, the most principled and direct rule to *ensure overlap* is to trim to the full common support region. Option A's rule, $[0.22, 0.62]$, is the direct and complete answer to the non-overlap problem. Option E's rule is slightly arbitrary and less fundamental than A's. Therefore, A is the superior choice as it exactly defines the boundary of common support based on the givens.\n- **Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "4635182"}]}