{"hands_on_practices": [{"introduction": "To truly grasp the difference between observational and experimental studies, we must first quantify the primary bias that experiments are designed to prevent: confounding. This exercise provides a hands-on opportunity to see exactly how a shared cause of an exposure and an outcome can create a spurious association. By working through the mathematics of a hypothetical scenario [@problem_id:4616228], you will derive the magnitude of confounding bias and demonstrate how statistical adjustment can recover the true causal effect, laying the mathematical groundwork for why randomization is so crucial.", "problem": "Consider an observational cohort study aiming to learn the effect of a binary exposure $A \\in \\{0,1\\}$ on a continuous outcome $Y$, where a pre-exposure covariate $X$ is a common cause of both $A$ and $Y$. Suppose the data-generating mechanism satisfies the following structural relationships:\n\n- The covariate is distributed as $X \\sim \\mathrm{Uniform}(-1,1)$.\n- The exposure is generated according to a linear probability model $A \\mid X=x \\sim \\mathrm{Bernoulli}(p(x))$ with $p(x) = \\alpha_{0} + \\alpha_{1} x$, where $\\alpha_{0} = 0.5$ and $\\alpha_{1} = 0.4$. This ensures positivity because $p(x) \\in [0.1,0.9]$ for $x \\in [-1,1]$.\n- The outcome is generated by a linear model $Y = \\beta_{0} + \\beta_{A} A + \\beta_{X} X + \\varepsilon$, where $\\varepsilon$ is mean-zero noise satisfying $\\mathbb{E}[\\varepsilon \\mid A, X] = 0$. Let $\\beta_{0} = 10$, $\\beta_{A} = 2$, and $\\beta_{X} = 1.5$.\n\nDefine the average causal effect (ACE) as $\\mathbb{E}\\!\\left[Y^{1} - Y^{0}\\right]$, where $Y^{a}$ denotes the potential outcome under intervention setting $A$ to $a$. In contrast, the naive observational estimator is the difference in observed mean outcomes, $\\Delta_{\\mathrm{obs}} = \\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0]$.\n\nUsing only core definitions (potential outcomes and conditional expectation), the law of total expectation, and algebra, perform the following:\n\n1. Derive $\\Delta_{\\mathrm{obs}}$ in terms of $\\beta_{A}$, $\\beta_{X}$, $\\alpha_{0}$, $\\alpha_{1}$, and properties of $X$.\n2. Quantify the bias $B = \\Delta_{\\mathrm{obs}} - \\mathbb{E}\\!\\left[Y^{1} - Y^{0}\\right]$ under the specified parameter values.\n3. Compute the regression-adjusted estimate defined by the standardization identity $\\Delta_{\\mathrm{adj}} = \\int \\left(\\mathbb{E}[Y \\mid A=1, X=x] - \\mathbb{E}[Y \\mid A=0, X=x]\\right) f_{X}(x) \\, dx$, where $f_{X}$ is the density of $X$.\n\nExpress the final answer as the single numerical value of $\\Delta_{\\mathrm{adj}}$. Do not round.", "solution": "The problem will be validated and, if valid, solved in three parts as requested.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Covariate distribution: $X \\sim \\mathrm{Uniform}(-1,1)$.\n-   Exposure model: $A \\mid X=x \\sim \\mathrm{Bernoulli}(p(x))$, where $p(x) = \\alpha_{0} + \\alpha_{1} x$.\n-   Exposure model parameters: $\\alpha_{0} = 0.5$, $\\alpha_{1} = 0.4$.\n-   Outcome model: $Y = \\beta_{0} + \\beta_{A} A + \\beta_{X} X + \\varepsilon$.\n-   Outcome model parameters: $\\beta_{0} = 10$, $\\beta_{A} = 2$, $\\beta_{X} = 1.5$.\n-   Noise property: $\\mathbb{E}[\\varepsilon \\mid A, X] = 0$.\n-   Definition 1: Average Causal Effect (ACE) is $\\mathbb{E}[Y^{1} - Y^{0}]$.\n-   Definition 2: Naive observational estimator is $\\Delta_{\\mathrm{obs}} = \\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0]$.\n-   Definition 3: Confounding bias is $B = \\Delta_{\\mathrm{obs}} - \\mathbb{E}[Y^{1} - Y^{0}]$.\n-   Definition 4: Regression-adjusted estimate is $\\Delta_{\\mathrm{adj}} = \\int (\\mathbb{E}[Y \\mid A=1, X=x] - \\mathbb{E}[Y \\mid A=0, X=x]) f_{X}(x) \\, dx$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded in the principles of causal inference and statistics. It describes a standard scenario of confounding, a core concept in epidemiology. The data-generating process is specified with a linear structural equation model and a linear probability model for the exposure, which are common and valid modeling choices. The positivity assumption, $P(A=a \\mid X=x)  0$ for all $a, x$, is explicitly verified: for $x \\in [-1,1]$, $p(x) = 0.5 + 0.4x$ ranges from $0.5 - 0.4 = 0.1$ to $0.5 + 0.4 = 0.9$, so $p(x) \\in [0.1, 0.9]$, which is strictly between $0$ and $1$. The problem is well-posed, with all necessary parameters and distributions defined. The language is objective and precise. The questions asked are standard derivations in this context. The problem is self-contained and free of contradictions.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n### Solution\n\nThe solution is divided into the three tasks outlined in the problem statement.\n\n**1. Derivation of $\\Delta_{\\mathrm{obs}}$**\n\nThe naive observational estimator is defined as $\\Delta_{\\mathrm{obs}} = \\mathbb{E}[Y \\mid A=1] - \\mathbb{E}[Y \\mid A=0]$. We compute each term separately using the law of total expectation, conditioning on the covariate $X$.\n\nFor a given exposure level $a \\in \\{0,1\\}$, the conditional expectation of the outcome is:\n$$ \\mathbb{E}[Y \\mid A=a] = \\mathbb{E}_{X}[\\mathbb{E}[Y \\mid A=a, X] \\mid A=a] $$\nFirst, we find the inner expectation, $\\mathbb{E}[Y \\mid A=a, X=x]$. Using the given linear model for $Y$ and the property $\\mathbb{E}[\\varepsilon \\mid A, X] = 0$:\n$$ \\mathbb{E}[Y \\mid A=a, X=x] = \\mathbb{E}[\\beta_{0} + \\beta_{A} A + \\beta_{X} X + \\varepsilon \\mid A=a, X=x] $$\n$$ = \\beta_{0} + \\beta_{A} a + \\beta_{X} x + \\mathbb{E}[\\varepsilon \\mid A=a, X=x] = \\beta_{0} + \\beta_{A} a + \\beta_{X} x $$\nNow we take the outer expectation over the distribution of $X$ conditional on $A=a$:\n$$ \\mathbb{E}[Y \\mid A=a] = \\mathbb{E}[\\beta_{0} + \\beta_{A} a + \\beta_{X} X \\mid A=a] = \\beta_{0} + \\beta_{A} a + \\beta_{X} \\mathbb{E}[X \\mid A=a] $$\nApplying this to $a=1$ and $a=0$:\n$$ \\mathbb{E}[Y \\mid A=1] = \\beta_{0} + \\beta_{A}(1) + \\beta_{X} \\mathbb{E}[X \\mid A=1] $$\n$$ \\mathbb{E}[Y \\mid A=0] = \\beta_{0} + \\beta_{A}(0) + \\beta_{X} \\mathbb{E}[X \\mid A=0] $$\nThe difference is:\n$$ \\Delta_{\\mathrm{obs}} = (\\beta_{0} + \\beta_{A} + \\beta_{X} \\mathbb{E}[X \\mid A=1]) - (\\beta_{0} + \\beta_{X} \\mathbb{E}[X \\mid A=0]) $$\n$$ \\Delta_{\\mathrm{obs}} = \\beta_{A} + \\beta_{X} (\\mathbb{E}[X \\mid A=1] - \\mathbb{E}[X \\mid A=0]) $$\nTo complete the derivation, we must find $\\mathbb{E}[X \\mid A=a]$. We use the definition of conditional expectation and Bayes' theorem:\n$$ f_{X|A}(x|a) = \\frac{P(A=a|X=x)f_X(x)}{P(A=a)} $$\nThe density of $X$ is $f_X(x) = \\frac{1}{2}$ for $x \\in [-1,1]$. The propensity score is $p(x) = P(A=1|X=x) = \\alpha_0 + \\alpha_1 x$. The marginal probability of $A=1$ is:\n$$ P(A=1) = \\int_{-1}^{1} P(A=1|X=x)f_X(x) dx = \\int_{-1}^{1} (\\alpha_0 + \\alpha_1 x) \\frac{1}{2} dx = \\frac{1}{2} \\left[ \\alpha_0 x + \\frac{\\alpha_1 x^2}{2} \\right]_{-1}^{1} = \\frac{1}{2} [(\\alpha_0 + \\frac{\\alpha_1}{2}) - (-\\alpha_0 + \\frac{\\alpha_1}{2})] = \\alpha_0 $$\nSimilarly, $P(A=0) = 1 - P(A=1) = 1 - \\alpha_0$.\n\nNow we compute the conditional expectations of $X$:\n$$ \\mathbb{E}[X \\mid A=1] = \\int_{-1}^{1} x f_{X|A}(x|1) dx = \\int_{-1}^{1} x \\frac{(\\alpha_0 + \\alpha_1 x) (1/2)}{\\alpha_0} dx = \\frac{1}{2\\alpha_0} \\int_{-1}^{1} (\\alpha_0 x + \\alpha_1 x^2) dx $$\n$$ = \\frac{1}{2\\alpha_0} \\left[ \\frac{\\alpha_0 x^2}{2} + \\frac{\\alpha_1 x^3}{3} \\right]_{-1}^{1} = \\frac{1}{2\\alpha_0} \\left[ (\\frac{\\alpha_0}{2} + \\frac{\\alpha_1}{3}) - (\\frac{\\alpha_0}{2} - \\frac{\\alpha_1}{3}) \\right] = \\frac{1}{2\\alpha_0} \\left( \\frac{2\\alpha_1}{3} \\right) = \\frac{\\alpha_1}{3\\alpha_0} $$\nAnd for $A=0$:\n$$ \\mathbb{E}[X \\mid A=0] = \\int_{-1}^{1} x \\frac{P(A=0|X=x)f_X(x)}{P(A=0)} dx = \\int_{-1}^{1} x \\frac{(1 - (\\alpha_0 + \\alpha_1 x)) (1/2)}{1-\\alpha_0} dx = \\frac{1}{2(1-\\alpha_0)} \\int_{-1}^{1} ((1-\\alpha_0)x - \\alpha_1 x^2) dx $$\n$$ = \\frac{1}{2(1-\\alpha_0)} \\left[ \\frac{(1-\\alpha_0) x^2}{2} - \\frac{\\alpha_1 x^3}{3} \\right]_{-1}^{1} = \\frac{1}{2(1-\\alpha_0)} \\left[ (\\frac{1-\\alpha_0}{2} - \\frac{\\alpha_1}{3}) - (\\frac{1-\\alpha_0}{2} + \\frac{\\alpha_1}{3}) \\right] = \\frac{1}{2(1-\\alpha_0)} \\left( -\\frac{2\\alpha_1}{3} \\right) = -\\frac{\\alpha_1}{3(1-\\alpha_0)} $$\nThe difference is:\n$$ \\mathbb{E}[X \\mid A=1] - \\mathbb{E}[X \\mid A=0] = \\frac{\\alpha_1}{3\\alpha_0} - \\left(-\\frac{\\alpha_1}{3(1-\\alpha_0)}\\right) = \\frac{\\alpha_1}{3} \\left( \\frac{1}{\\alpha_0} + \\frac{1}{1-\\alpha_0} \\right) = \\frac{\\alpha_1}{3} \\left( \\frac{1-\\alpha_0+\\alpha_0}{\\alpha_0(1-\\alpha_0)} \\right) = \\frac{\\alpha_1}{3\\alpha_0(1-\\alpha_0)} $$\nSubstituting this back into the expression for $\\Delta_{\\mathrm{obs}}$ yields the final derived form:\n$$ \\Delta_{\\mathrm{obs}} = \\beta_A + \\beta_X \\left( \\frac{\\alpha_1}{3\\alpha_0(1-\\alpha_0)} \\right) $$\n\n**2. Quantification of the Bias $B$**\n\nThe Average Causal Effect (ACE) is $\\mathbb{E}[Y^1 - Y^0]$. The potential outcomes $Y^a$ are defined by intervening on the structural equation for $Y$:\n$$ Y^a = \\beta_{0} + \\beta_{A} a + \\beta_{X} X + \\varepsilon $$\nwhere $X$ and $\\varepsilon$ follow their original distributions.\n$$ \\mathrm{ACE} = \\mathbb{E}[Y^1 - Y^0] = \\mathbb{E}[(\\beta_0 + \\beta_A(1) + \\beta_X X + \\varepsilon) - (\\beta_0 + \\beta_A(0) + \\beta_X X + \\varepsilon)] $$\n$$ = \\mathbb{E}[\\beta_A] = \\beta_A $$\nThe bias $B$ is the difference between the observational estimate and the causal effect:\n$$ B = \\Delta_{\\mathrm{obs}} - \\mathrm{ACE} = \\left(\\beta_A + \\beta_X \\frac{\\alpha_1}{3\\alpha_0(1-\\alpha_0)}\\right) - \\beta_A = \\beta_X \\frac{\\alpha_1}{3\\alpha_0(1-\\alpha_0)} $$\nThis term represents the confounding bias due to the common cause $X$. Now, we substitute the given numerical values: $\\beta_{X} = 1.5$, $\\alpha_1 = 0.4$, and $\\alpha_0 = 0.5$.\n$$ B = 1.5 \\times \\frac{0.4}{3 \\times 0.5 \\times (1-0.5)} = 1.5 \\times \\frac{0.4}{3 \\times 0.5 \\times 0.5} = 1.5 \\times \\frac{0.4}{0.75} = \\frac{3}{2} \\times \\frac{0.4}{3/4} = \\frac{3}{2} \\times 0.4 \\times \\frac{4}{3} = 2 \\times 0.4 = 0.8 $$\nThe bias is $0.8$.\n\n**3. Computation of the Regression-Adjusted Estimate $\\Delta_{\\mathrm{adj}}$**\n\nThe regression-adjusted estimate is defined by the standardization formula:\n$$ \\Delta_{\\mathrm{adj}} = \\int \\left(\\mathbb{E}[Y \\mid A=1, X=x] - \\mathbb{E}[Y \\mid A=0, X=x]\\right) f_{X}(x) \\, dx $$\nFrom Part 1, we have already determined the conditional expectation $\\mathbb{E}[Y \\mid A=a, X=x] = \\beta_0 + \\beta_A a + \\beta_X x$. The difference inside the integral is:\n$$ \\mathbb{E}[Y \\mid A=1, X=x] - \\mathbb{E}[Y \\mid A=0, X=x] = (\\beta_0 + \\beta_A(1) + \\beta_X x) - (\\beta_0 + \\beta_A(0) + \\beta_X x) = \\beta_A $$\nThe integrand simplifies to a constant, $\\beta_A$. Therefore, the integral becomes:\n$$ \\Delta_{\\mathrm{adj}} = \\int_{-1}^{1} \\beta_A f_{X}(x) \\, dx $$\nSince $\\beta_A$ is a constant, we can pull it out of the integral:\n$$ \\Delta_{\\mathrm{adj}} = \\beta_A \\int_{-1}^{1} f_{X}(x) \\, dx $$\nThe integral of a probability density function over its entire support is equal to $1$.\n$$ \\int_{-1}^{1} f_{X}(x) \\, dx = 1 $$\nThus, the adjusted estimate is:\n$$ \\Delta_{\\mathrm{adj}} = \\beta_A \\times 1 = \\beta_A $$\nThis demonstrates that standardization over the confounder $X$ recovers the true average causal effect. Using the given parameter value $\\beta_A = 2$:\n$$ \\Delta_{\\mathrm{adj}} = 2 $$\nThis is the final numerical value requested.", "answer": "$$\\boxed{2}$$", "id": "4616228"}, {"introduction": "Beyond classical confounding, observational studies can suffer from subtle structural biases that arise from the study design itself. This practice problem explores one of the most notorious pitfalls: immortal time bias, which occurs when patients are classified into exposure groups based on information from the future. By analyzing a scenario where treatment is delayed [@problem_id:4616202], you will uncover how a seemingly harmless analytical choice can create a powerful illusion of treatment benefit and learn about modern strategies like Target Trial Emulation that are designed to prevent it.", "problem": "An observational cohort study aims to compare mortality between patients who receive a new therapy and those who do not, over a fixed follow-up period of $T = 120$ days after cohort entry. All patients are eligible at day $0$. In practice, the therapy is initiated at $t^\\star = 60$ days only among those who are still alive at that time; exactly $n_T = 274$ patients start therapy at day $60$ and no one starts earlier. All other patients ($N - n_T$) remain untreated. The true causal effect of therapy after initiation is null (the instantaneous hazard of death remains unchanged by treatment). Suppose death times follow an exponential distribution with constant hazard $\\lambda = 0.01$ per day for all individuals, regardless of whether they initiate therapy. \n\nA naive analysis classifies exposure as “ever treated” versus “never treated,” with “ever treated” defined from cohort entry (day $0$) onward. It then computes the cumulative incidence (risk) of death by $120$ days in each group and forms a ratio. \n\nUsing only core definitions of cumulative incidence and conditional probability, derive the expected direction and approximate magnitude of the bias introduced by this naive classification when treatment is assigned based on future information (survival to $t^\\star$), and explain the mechanism in terms of immortal time. Then, identify a time-zero alignment strategy that would eliminate this bias by making the observational analysis structurally analogous to a randomized controlled trial (Randomized Controlled Trial (RCT)) in which eligibility, treatment assignment, and start of follow-up are synchronized.\n\nWhich option most accurately states both the biased naive risk ratio and a valid correction strategy?\n\nA. The naive “ever treated from baseline” cumulative incidence ratio is approximately $0.65$ (spurious protective) because the exposed group is defined by survival through $t^\\star$, which creates immortal time; a valid correction is to align time zero with treatment assignment by emulating a randomized trial: either model treatment as a time-varying exposure or use a design that assigns comparable index dates to untreated comparators at the same $t^\\star$ (Target Trial Emulation (TTE)).\n\nB. The naive cumulative incidence ratio is approximately $1.00$ (no bias); adjustment for baseline confounders alone suffices to correct any issues without changing time origin.\n\nC. The naive cumulative incidence ratio is approximately $2.00$ (spurious harm) because exposed patients accumulate more person-time; a valid correction is to left-truncate exposed follow-up at treatment initiation while keeping unexposed follow-up starting at cohort entry.\n\nD. The naive cumulative incidence ratio is approximately $0.50$ (strong protective) due to excluding events for exposed before $t^\\star$; a valid correction is to exclude deaths before $t^\\star$ in both groups while keeping time zero at cohort entry.", "solution": "The user wants a detailed validation and solution for a problem in epidemiology concerning immortal time bias.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Study Type**: Observational cohort study.\n-   **Follow-up Period**: $T = 120$ days from cohort entry at day $0$.\n-   **Treatment Time**: Therapy is initiated at $t^\\star = 60$ days.\n-   **Treatment Condition**: Only patients still alive at $t^\\star = 60$ days are eligible for and receive therapy.\n-   **Treated group size**: $n_T = 274$ patients start therapy at day $60$.\n-   **True Causal Effect**: Null. The hazard of death is not changed by the therapy.\n-   **Survival Model**: Time to death follows an exponential distribution.\n-   **Hazard Rate**: Constant hazard $\\lambda = 0.01$ per day for all individuals, regardless of treatment status.\n-   **Naive Analysis**:\n    -   Exposure is classified at baseline (day $0$) as \"ever treated\" vs \"never treated\".\n    -   The analysis computes the cumulative incidence (risk) of death by day $120$ in each group.\n    -   A risk ratio is formed.\n-   **Required Derivations**:\n    1.  Derive the bias (direction and magnitude) using core definitions.\n    2.  Explain the mechanism in terms of immortal time.\n    3.  Identify a valid correction strategy (time-zero alignment).\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is well-grounded in the fundamental principles of epidemiology and biostatistics. It describes a classic scenario of immortal time bias, a well-documented structural bias in observational studies. The use of an exponential distribution with a constant hazard is a standard and valid modeling assumption for demonstrating such concepts.\n-   **Well-Posedness**: The problem is well-posed. All parameters needed for calculation ($\\lambda$, $t^\\star$, $T$) are provided. The \"naive analysis\" protocol is described with sufficient clarity to allow for the calculation of the biased estimate. A unique solution for the expected risk ratio can be derived. The specific number of treated patients, $n_T = 274$, is not required for the calculation of the expected risks, but its inclusion does not create a contradiction.\n-   **Objectivity**: The language is precise and objective, using standard terminology from the field.\n\nThe problem statement does not violate any of the invalidity criteria. It is a scientifically sound, well-posed, and standard problem designed to test the understanding of a critical concept in epidemiological methods.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. I will proceed with the solution.\n\n### Solution Derivation\n\nThe problem requires calculating the biased risk ratio resulting from a naive analysis that mischaracterizes follow-up time. The true causal effect of the therapy is null, so the hazard rate $\\lambda = 0.01$ per day is constant for all individuals at all times. The correctly analyzed risk ratio should be $1.0$. Any deviation from $1.0$ is bias.\n\nThe survival function for any individual is $S(t) = P(\\text{Time to death}  t) = e^{-\\lambda t}$.\nThe cumulative incidence of death (risk) by time $t$ is $CI(t) = P(\\text{Time to death} \\le t) = 1 - S(t) = 1 - e^{-\\lambda t}$.\n\n**1. Cumulative Incidence in the \"Ever Treated\" Group ($CI_E$)**\n\nThe naive analysis classifies individuals who receive the therapy at day $60$ as \"ever treated\" from the beginning of the cohort at day $0$. A defining characteristic of this group is that every member *must* survive from day $0$ to day $60$ to receive the treatment. This period, $[0, 60)$ days, is \"immortal time\" for this group. By definition, they cannot experience the event (death) during this period.\n\nThe naive analysis computes the cumulative incidence by day $T=120$. For an individual in the \"ever treated\" group, who is defined by their survival to $t^\\star=60$, the risk of death by day $120$ is the conditional probability of dying by day $120$ *given* they survived past day $60$.\n\n$$ CI_E = P(D \\le 120 \\mid D  60) $$\n\nUsing the definition of conditional probability, $P(A|B) = P(A \\cap B) / P(B)$:\nThe event \"$D \\le 120$ and $D  60$\" is a death in the interval $(60, 120]$.\n$$ CI_E = \\frac{P(60  D \\le 120)}{P(D  60)} = \\frac{S(60) - S(120)}{S(60)} = 1 - \\frac{S(120)}{S(60)} $$\nSubstituting the survival function $S(t) = e^{-\\lambda t}$:\n$$ CI_E = 1 - \\frac{e^{-\\lambda \\times 120}}{e^{-\\lambda \\times 60}} = 1 - e^{-\\lambda(120-60)} = 1 - e^{-60\\lambda} $$\nWith $\\lambda = 0.01$ day$^{-1}$:\n$$ CI_E = 1 - e^{-60 \\times 0.01} = 1 - e^{-0.6} $$\nUsing the approximation $e^{-0.6} \\approx 0.5488$:\n$$ CI_E \\approx 1 - 0.5488 = 0.4512 $$\n\n**2. Cumulative Incidence in the \"Never Treated\" Group ($CI_U$)**\n\nThe \"never treated\" group acts as the comparator. In this naive design, this group consists of all other patients, including those who die before day $60$. As such, its risk profile represents that of the entire cohort without any conditioning on survival. They are at risk of death from day $0$. The cumulative incidence of death by day $120$ for this group is the unconditional probability:\n\n$$ CI_U = P(D \\le 120) = 1 - e^{-120\\lambda} $$\nWith $\\lambda = 0.01$ day$^{-1}$:\n$$ CI_U = 1 - e^{-120 \\times 0.01} = 1 - e^{-1.2} $$\nUsing the approximation $e^{-1.2} \\approx 0.3012$:\n$$ CI_U \\approx 1 - 0.3012 = 0.6988 $$\n\n**3. Naive Risk Ratio ($RR_{naive}$)**\n\nThe biased risk ratio is the ratio of these two cumulative incidences:\n$$ RR_{naive} = \\frac{CI_E}{CI_U} = \\frac{1 - e^{-0.6}}{1 - e^{-1.2}} \\approx \\frac{0.4512}{0.6988} \\approx 0.6456 $$\nThe naive risk ratio is approximately $0.65$. Since the true risk ratio is $1.0$, this represents a spurious protective effect. The bias is created because the treated group is guaranteed a period of \"immortal\" survival for which they get credit in the analysis, while the untreated group accrues deaths during that same period.\n\n**4. Valid Correction Strategy**\n\nThe bias arises from the misalignment of the start of follow-up. In a randomized controlled trial (RCT), eligibility is determined, treatment is assigned (randomized), and follow-up begins at the same moment (time zero). To eliminate the immortal time bias, the observational analysis must emulate this structure.\n\n-   **Aligning Time Zero:** The correct approach is to start follow-up for both treated and untreated groups at the time of treatment initiation, $t^\\star = 60$ days. The analysis would only include individuals who are still alive and eligible at day $60$. The treated group would be the $n_T$ patients who start therapy. The untreated comparison group would be drawn from other patients also alive and eligible at day $60$ who did not start therapy. For both groups, we would then compare the risk of death over the subsequent period, e.g., from day $60$ to day $120$. This is the principle behind **Target Trial Emulation (TTE)**, where one \"assigns comparable index dates to untreated comparators\".\n-   **Time-Varying Covariate Models:** An alternative analytical approach is to treat exposure status as a time-varying covariate in a survival model (like a Cox proportional hazards model). An individual contributes person-time to the \"unexposed\" risk set from day $0$ until day $59$. At day $60$, if they receive treatment, they switch to the \"exposed\" risk set. This correctly allocates person-time and avoids immortal time bias.\n\n### Option-by-Option Analysis\n\n**A. The naive “ever treated from baseline” cumulative incidence ratio is approximately $0.65$ (spurious protective) because the exposed group is defined by survival through $t^\\star$, which creates immortal time; a valid correction is to align time zero with treatment assignment by emulating a randomized trial: either model treatment as a time-varying exposure or use a design that assigns comparable index dates to untreated comparators at the same $t^\\star$ (Target Trial Emulation (TTE)).**\n-   **Risk Ratio Calculation**: The calculated risk ratio is $\\approx 0.65$. This matches the option. The direction \"spurious protective\" is correct.\n-   **Explanation**: The reason provided, \"defined by survival through $t^\\star$, which creates immortal time,\" is precisely correct.\n-   **Correction Strategy**: The suggested corrections, including modeling treatment as a time-varying exposure and Target Trial Emulation, are the standard, state-of-the-art methods for addressing this type of bias.\n-   **Verdict**: **Correct**.\n\n**B. The naive cumulative incidence ratio is approximately $1.00$ (no bias); adjustment for baseline confounders alone suffices to correct any issues without changing time origin.**\n-   **Risk Ratio Calculation**: The ratio is not $1.00$. My calculation shows significant bias, yielding a ratio of $\\approx 0.65$.\n-   **Explanation/Correction**: The bias is structural (immortal time), not due to confounding. Adjusting for baseline confounders will not correct it. The time origin must be addressed.\n-   **Verdict**: **Incorrect**.\n\n**C. The naive cumulative incidence ratio is approximately $2.00$ (spurious harm) because exposed patients accumulate more person-time; a valid correction is to left-truncate exposed follow-up at treatment initiation while keeping unexposed follow-up starting at cohort entry.**\n-   **Risk Ratio Calculation**: The ratio is $\\approx 0.65$ (protective), not $2.00$ (harm).\n-   **Explanation/Correction**: The reasoning is flawed. The correction proposed—aligning time for one group but not the other—is itself a biased design and does not solve the problem.\n-   **Verdict**: **Incorrect**.\n\n**D. The naive cumulative incidence ratio is approximately $0.50$ (strong protective) due to excluding events for exposed before $t^\\star$; a valid correction is to exclude deaths before $t^\\star$ in both groups while keeping time zero at cohort entry.**\n-   **Risk Ratio Calculation**: The value $0.50$ is not the cumulative incidence ratio. It is the ratio of the cumulative hazards ($H_E/H_U = (\\lambda \\times 60) / (\\lambda \\times 120) = 0.5$). While related, the risk ratio is the explicitly requested quantity, and my calculation gives $\\approx 0.65$.\n-   **Explanation/Correction**: The reason for bias is stated correctly. The correction method described is a landmark analysis, which is a valid approach. However, the quantitative claim is inaccurate based on a strict interpretation of \"cumulative incidence (risk) ratio\". Option A is more precise both quantitatively and in its description of corrective measures.\n-   **Verdict**: **Incorrect**.", "answer": "$$\\boxed{A}$$", "id": "4616202"}, {"introduction": "Randomized controlled trials (RCTs) are the gold standard for causal inference, but their real-world application is rarely straightforward due to issues like non-adherence and treatment switching. This advanced problem moves beyond the idealized RCT to explore the critical challenges of interpretation when the protocol is not followed perfectly [@problem_id:4616199]. You will weigh the pragmatic \"intention-to-treat\" (ITT) estimate against more specific causal questions about the effect of actually receiving treatment, revealing the trade-offs between unbiasedness, relevance, and the assumptions required for different analytical approaches.", "problem": "A public health team runs a $2$-arm randomized controlled trial (RCT) evaluating an angiotensin receptor blocker versus usual care in adults with stage $2$ hypertension. The primary outcome is the occurrence of a major adverse cardiovascular event by $12$ months. The trial is double-blind with respect to the randomized assignment. However, a prespecified rescue policy allows usual-care patients to be switched to the active drug if repeated blood pressure checks remain above a safety threshold; in practice, about $30\\%$ of usual-care patients are switched to the active drug for this reason. Among those randomized to the active drug, about $20\\%$ discontinue due to cough and dizziness. Both rescue switching and discontinuation are more likely in participants with worse blood pressure trajectories and higher short-term cardiovascular risk. Outcome ascertainment is near complete at $12$ months. Investigators plan an intention-to-treat (ITT) analysis and are considering whether it might understate clinically relevant effects, and when alternative estimands would be preferable.\n\nUsing only core causal definitions in epidemiology and trial design (e.g., potential outcomes indexed by randomized assignment and by treatment actually received, exchangeability by randomization at baseline, and definitions of per-protocol, as-treated, and principal stratification estimands), choose all statements that are most appropriate about when ITT may understate clinically relevant effects and when alternative estimands are preferable, including risks of interpretational pitfalls.\n\nA. In the presence of substantial post-randomization switching to the active drug in the usual-care arm and discontinuation in the active arm, the ITT estimand (effect of assignment) can dilute the biologic effect of taking the drug as intended. A per-protocol estimand or a complier average causal effect estimand can be more clinically relevant for the effect of adhering to treatment, but valid estimation requires accounting for prognostic factors that influence adherence and switching, which otherwise induce selection bias.\n\nB. Because rescue therapy is triggered by a prespecified rule, censoring follow-up at the time of rescue switching and comparing remaining active versus usual-care patients yields an unbiased per-protocol effect by virtue of baseline randomization; no additional adjustment for post-randomization prognostic factors is necessary.\n\nC. If a secondary patient-reported outcome at $12$ months is only defined among those alive at $12$ months, then the ITT contrast on that outcome can understate the effect among those who would survive regardless of assignment. A more clinically targeted estimand is the survivor average causal effect within the principal stratum of individuals who would be alive under either assignment, but identifying this estimand generally requires strong, unverifiable assumptions and is prone to interpretational pitfalls.\n\nD. Because the trial is double-blind at baseline, adherence behaviors are by design independent of prognosis; therefore, an as-treated analysis that compares patients by the treatment actually received without adjustment will consistently estimate the causal effect of treatment received.\n\nE. For policy decisions about offering the drug under real-world adherence, the ITT estimand is appropriate. For estimating the effect in patients who would take the drug if offered (compliers), the complier average causal effect using randomization as an instrument can be preferable, but one must be cautious: with switching triggered by worsening blood pressure in the usual-care arm, assumptions such as exclusion restriction can be violated if assignment affects outcomes through rescue pathways beyond treatment receipt, leading to interpretational pitfalls.", "solution": "The problem statement describes a randomized controlled trial (RCT) with post-randomization events, specifically treatment discontinuation in the active arm and treatment switching (crossover) in the control arm. These events are not random; they are associated with prognostic factors. The task is to evaluate several statements regarding the intention-to-treat (ITT) estimand and alternative estimands in this context.\n\nFirst, let us formalize the scenario using the potential outcomes framework.\nLet $Z_i$ be the randomized assignment for participant $i$, where $Z_i=1$ if assigned to the angiotensin receptor blocker (ARB) and $Z_i=0$ if assigned to usual care.\nLet $D_i$ be the treatment actually received by participant $i$. Due to discontinuation and switching, $D_i$ is not necessarily equal to $Z_i$.\nLet $Y_i$ be the outcome for participant $i$, which is the occurrence of a major adverse cardiovascular event (MACE) by $12$ months. A potential outcome is denoted as $Y_i(z)$, the outcome that would be observed for participant $i$ under assignment $z$.\n\nThe problem states:\n-   The trial is a $2$-arm RCT. Randomization ensures that at baseline, the two groups defined by $Z$ are, on average, exchangeable: $E[Y(z=1)] = E[Y(z=1)|Z=1] = E[Y(z=1)|Z=0]$ and $E[Y(z=0)] = E[Y(z=0)|Z=1] = E[Y(z=0)|Z=0]$.\n-   The ITT estimand is the average causal effect of treatment *assignment*: $E[Y(z=1) - Y(z=0)]$. This is estimated by comparing the average outcomes in the two randomized groups: $E[Y|Z=1] - E[Y|Z=0]$. Because randomization holds, this is an unbiased estimate of the effect of assignment.\n-   In the usual-care arm ($Z=0$), about $30\\%$ of patients switch to the active drug.\n-   In the active-drug arm ($Z=1$), about $20\\%$ of patients discontinue.\n-   Crucially, \"Both rescue switching and discontinuation are more likely in participants with worse blood pressure trajectories and higher short-term cardiovascular risk.\" This means that the adherence behavior is a post-randomization variable that is also a prognostic factor for the outcome.\n\nNow, we will evaluate each option.\n\n**A. In the presence of substantial post-randomization switching to the active drug in the usual-care arm and discontinuation in the active arm, the ITT estimand (effect of assignment) can dilute the biologic effect of taking the drug as intended. A per-protocol estimand or a complier average causal effect estimand can be more clinically relevant for the effect of adhering to treatment, but valid estimation requires accounting for prognostic factors that influence adherence and switching, which otherwise induce selection bias.**\nThis statement makes three claims:\n1.  The ITT estimand can dilute the biologic effect. The ITT analysis compares a group where nominally $100\\%$ are assigned the drug (but only about $80\\%$ take it for the duration) with a group where $0\\%$ are assigned the drug (but about $30\\%$ end up receiving it). The true exposure contrast is not $100\\%$ versus $0\\%$, but closer to $80\\%$ versus $30\\%$. This will naturally lead to an estimated effect magnitude that is smaller (diluted) compared to the hypothetical effect of $100\\%$ adherence versus $0\\%$ adherence. This claim is correct.\n2.  Per-protocol (PP) or complier average causal effect (CACE) estimands can be more clinically relevant for the effect of adhering to treatment. These estimands are designed to estimate the effect of *receiving* or *adhering to* the treatment, rather than being *assigned* to it. This effect is often of great interest to clinicians and patients wondering about the consequences of actually taking the drug. This claim is correct.\n3.  Valid estimation of PP or CACE requires accounting for prognostic factors that influence adherence, which would otherwise induce selection bias. This is the central challenge. As stated in the problem, adherence and switching are related to prognosis. A naive PP or \"as-treated\" analysis that simply compares groups based on treatment received would be biased. For instance, in an as-treated analysis, the group receiving the ARB would include healthier patients from the $Z=1$ arm and sicker patients from the $Z=0$ arm who required rescue. This breaks the randomization and introduces confounding or selection bias. Valid estimation of these effects requires advanced statistical methods (e.g., inverse probability weighting for PP, instrumental variable analysis for CACE) that must properly account for the factors driving non-adherence. This claim is correct.\nGiven that all parts of the statement are accurate, the statement as a whole is correct.\n**Verdict: Correct.**\n\n**B. Because rescue therapy is triggered by a prespecified rule, censoring follow-up at the time of rescue switching and comparing remaining active versus usual-care patients yields an unbiased per-protocol effect by virtue of baseline randomization; no additional adjustment for post-randomization prognostic factors is necessary.**\nThis statement describes a naive per-protocol analysis where participants are censored when they deviate from the protocol. The claim is that this is unbiased because the rule is \"prespecified\". This is incorrect. The reason for switching is high blood pressure, which is a strong predictor of the outcome (MACE). By censoring the sickest patients from the usual-care arm (those who switch), while retaining comparable sick patients in the active-drug arm, the analysis would compare a healthier-than-average usual-care group to the full-risk active-drug group. This introduces severe selection bias, making the treatment appear less effective or even harmful. The fact that the rule is prespecified does not prevent the bias; the rule itself institutionalizes the selection bias by conditioning on a post-randomization prognostic factor. Baseline randomization does not protect against post-randomization bias.\n**Verdict: Incorrect.**\n\n**C. If a secondary patient-reported outcome at $12$ months is only defined among those alive at $12$ months, then the ITT contrast on that outcome can understate the effect among those who would survive regardless of assignment. A more clinically targeted estimand is the survivor average causal effect within the principal stratum of individuals who would be alive under either assignment, but identifying this estimand generally requires strong, unverifiable assumptions and is prone to interpretational pitfalls.**\nThis option addresses the issue of competing risks (death) when the outcome of interest is defined only for survivors.\n1.  Analyzing an outcome only among survivors is conditioning on a post-randomization variable. If the treatment affects survival, the groups of survivors in the two arms may not be comparable, even if the full groups were comparable at baseline due to randomization. For example, if the drug saves frail people who would otherwise have died (and who would report poor outcomes), the average patient-reported outcome in the treatment arm's survivor pool might look worse, leading to a biased estimate. The direction of bias is not always \"understatement,\" but the general point that the ITT contrast among survivors is biased for the effect in any well-defined causal population is correct.\n2.  The statement proposes the survivor average causal effect (SACE) as a more targeted estimand. The SACE is defined on the principal stratum of \"always survivors\", i.e., those individuals who would have survived to $12$ months regardless of their treatment assignment ($Z=0$ or $Z=1$). This is the correct, causally-defined estimand that avoids conditioning on a post-randomization event.\n3.  The statement correctly notes that identifying this estimand is difficult. We cannot empirically identify the \"always survivors\" stratum from the data. Its estimation relies on strong, often untestable assumptions about the relationship between survival and the outcome (e.g., monotonicity of the treatment effect on survival). This makes the SACE approach methodologically challenging and its results subject to interpretation conditional on the validity of those assumptions.\nThe entire statement is a correct and nuanced description of a key problem in causal inference.\n**Verdict: Correct.**\n\n**D. Because the trial is double-blind at baseline, adherence behaviors are by design independent of prognosis; therefore, an as-treated analysis that compares patients by the treatment actually received without adjustment will consistently estimate the causal effect of treatment received.**\nThis statement is fundamentally flawed. Double-blinding prevents knowledge of assignment from influencing behavior. However, it does not prevent the physiological effects (or lack thereof) of the treatment from influencing behavior. Here, discontinuation is caused by side effects (\"cough and dizziness\") experienced only by those on the active drug. Switching is caused by a lack of efficacy (\"blood pressure checks remain above a safety threshold\") experienced by those in the usual-care arm. The problem explicitly states that these behaviors are more likely in those with a worse prognosis. Therefore, adherence is *not* independent of prognosis. An as-treated analysis, which groups patients by the treatment they actually received, destroys the randomization and compares groups that differ systematically in their baseline prognosis. Such an analysis without adjustment for all confounding factors (which here are post-randomization and time-varying) would be severely biased.\n**Verdict: Incorrect.**\n\n**E. For policy decisions about offering the drug under real-world adherence, the ITT estimand is appropriate. For estimating the effect in patients who would take the drug if offered (compliers), the complier average causal effect using randomization as an instrument can be preferable, but one must be cautious: with switching triggered by worsening blood pressure in the usual-care arm, assumptions such as exclusion restriction can be violated if assignment affects outcomes through rescue pathways beyond treatment receipt, leading to interpretational pitfalls.**\nThis statement evaluates the utility of ITT and CACE in this specific context.\n1.  \"For policy decisions..., the ITT estimand is appropriate.\" This is the classic justification for the ITT analysis. It estimates the effectiveness of the *strategy* or *policy* of offering a drug, accounting for the expected levels of non-adherence in a similar population. This is highly relevant for public health and policy. This claim is correct.\n2.  \"For estimating the effect in... compliers, the CACE using randomization as an instrument can be preferable...\". CACE, estimated using instrumental variables (IV) with random assignment as the instrument, targets the causal effect in the sub-population of individuals who would adhere to whatever assignment they received. This is a valid way to estimate an \"efficacy\" effect, which can be more scientifically or clinically relevant than the \"effectiveness\" ITT effect. This claim is correct.\n3.  \"...one must be cautious: ...assumptions such as exclusion restriction can be violated...\". The exclusion restriction assumption for IV states that the instrument (random assignment $Z$) affects the outcome ($Y$) only through its effect on the treatment received ($D$). In this trial, a \"rescue policy\" is triggered for the $Z=0$ arm. This policy involves \"repeated blood pressure checks\". It is plausible that this heightened monitoring and the entire management strategy under the \"rescue policy\" could affect a patient's outcome (MACE) through pathways other than simply receiving the active drug. For example, the increased clinical attention could lead to advice on diet/exercise or other co-interventions. If so, a path $Z \\rightarrow \\text{Rescue Policy} \\rightarrow Y$ exists that does not pass through $D$. This would be a violation of the exclusion restriction, leading to a biased CACE estimate. The statement correctly identifies this important and subtle risk.\nThe entire statement provides a correct and sophisticated analysis of the situation.\n**Verdict: Correct.**\n\nIn summary, statements A, C, and E are appropriate and correct descriptions of the methodological issues and interpretational pitfalls in this trial scenario.", "answer": "$$\\boxed{ACE}$$", "id": "4616199"}]}