{"hands_on_practices": [{"introduction": "The proliferation of digital health tools, from wrist-worn sensors to smart scales, demands rigorous validation. Before a new device can be trusted for clinical use, we must quantify how well its measurements agree with an established 'gold standard.' This exercise will guide you through the Bland–Altman method, a cornerstone of clinical measurement comparison, to assess both the systematic bias and the random error of a hypothetical wearable heart rate monitor against a clinical-grade ECG. [@problem_id:4955177]", "problem": "A telemedicine program evaluates a wrist-worn wearable’s heart rate readings against simultaneous measurements from a clinical-grade Electrocardiogram (ECG). For each of $n=12$ adults at rest, the wearable heart rate (in beats per minute, $\\mathrm{bpm}$) and the ECG heart rate (in $\\mathrm{bpm}$) were recorded as paired measurements: \n$$(\\text{Wearable}, \\text{ECG}) = (65, 62),\\ (74, 75),\\ (93, 88),\\ (66, 70),\\ (95, 95),\\ (82, 80),\\ (74, 76),\\ (88, 84),\\ (69, 72),\\ (91, 90),\\ (77, 78),\\ (83, 83).$$\nAssume the measurement error (wearable minus ECG) is approximately normally distributed across subjects and apply the Bland–Altman method to quantify agreement. Starting from fundamental statistical principles for measurement error assessment in clinical validation, compute:\n- the mean bias (defined as the average of wearable minus ECG differences), and \n- the two-sided $95\\%$ limits of agreement.\n\nThen, interpret clinical acceptability using the following predefined thresholds for resting heart rate monitoring in digital health: the wearable is considered clinically acceptable if the magnitude of the mean bias is less than or equal to $1\\,\\mathrm{bpm}$ and the two-sided $95\\%$ limits of agreement lie within $\\pm 5\\,\\mathrm{bpm}$ around zero.\n\nReport your final numeric results as a row vector in the order $[\\text{mean bias},\\ \\text{lower limit of agreement},\\ \\text{upper limit of agreement}]$. Round your answer to three significant figures. Express all intermediate and final quantities in $\\mathrm{bpm}$, but do not include units in the final boxed vector.", "solution": "The problem requires the application of the Bland–Altman method to assess the agreement between a wearable device and a clinical-grade ECG for heart rate measurement. The analysis is based on a set of $n=12$ paired measurements. The core of this method involves calculating the mean and standard deviation of the differences between the two measurement techniques.\n\nFirst, we define the difference, $d_i$, for each of the $i=1, \\dots, 12$ subjects as the wearable measurement minus the ECG measurement.\nLet the paired measurements be denoted by $(W_i, E_i)$. Then $d_i = W_i - E_i$. The calculated differences are:\n$d_1 = 65 - 62 = 3$\n$d_2 = 74 - 75 = -1$\n$d_3 = 93 - 88 = 5$\n$d_4 = 66 - 70 = -4$\n$d_5 = 95 - 95 = 0$\n$d_6 = 82 - 80 = 2$\n$d_7 = 74 - 76 = -2$\n$d_8 = 88 - 84 = 4$\n$d_9 = 69 - 72 = -3$\n$d_{10} = 91 - 90 = 1$\n$d_{11} = 77 - 78 = -1$\n$d_{12} = 83 - 83 = 0$\n\nThe set of differences is $\\{3, -1, 5, -4, 0, 2, -2, 4, -3, 1, -1, 0\\}$.\n\nThe first quantity to compute is the mean bias, which is the sample mean of these differences, denoted by $\\bar{d}$.\n$$\n\\bar{d} = \\frac{1}{n} \\sum_{i=1}^{n} d_i\n$$\nThe sum of the differences is:\n$$\n\\sum_{i=1}^{12} d_i = 3 + (-1) + 5 + (-4) + 0 + 2 + (-2) + 4 + (-3) + 1 + (-1) + 0 = 4\n$$\nTherefore, the mean bias is:\n$$\n\\bar{d} = \\frac{4}{12} = \\frac{1}{3} \\approx 0.3333... \\ \\mathrm{bpm}\n$$\n\nNext, we calculate the sample standard deviation of the differences, $s_d$. The formula for the sample standard deviation is:\n$$\ns_d = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (d_i - \\bar{d})^2}\n$$\nTo compute this, we can use the computational formula $\\sum_{i=1}^{n} (d_i - \\bar{d})^2 = \\sum_{i=1}^{n} d_i^2 - \\frac{(\\sum_{i=1}^{n} d_i)^2}{n}$.\nFirst, we find the sum of the squares of the differences:\n$$\n\\sum_{i=1}^{12} d_i^2 = 3^2 + (-1)^2 + 5^2 + (-4)^2 + 0^2 + 2^2 + (-2)^2 + 4^2 + (-3)^2 + 1^2 + (-1)^2 + 0^2\n$$\n$$\n\\sum_{i=1}^{12} d_i^2 = 9 + 1 + 25 + 16 + 0 + 4 + 4 + 16 + 9 + 1 + 1 + 0 = 86\n$$\nNow we can compute the sum of squared deviations:\n$$\n\\sum_{i=1}^{12} (d_i - \\bar{d})^2 = 86 - \\frac{4^2}{12} = 86 - \\frac{16}{12} = 86 - \\frac{4}{3} = \\frac{258 - 4}{3} = \\frac{254}{3}\n$$\nThe sample variance, $s_d^2$, is:\n$$\ns_d^2 = \\frac{1}{12-1} \\left( \\frac{254}{3} \\right) = \\frac{254}{33}\n$$\nThe sample standard deviation is:\n$$\ns_d = \\sqrt{\\frac{254}{33}} \\approx 2.7743... \\ \\mathrm{bpm}\n$$\n\nThe two-sided $95\\%$ limits of agreement (LOA) are defined to capture the interval within which $95\\%$ of future measurement differences are expected to lie. Assuming the differences are normally distributed, this interval is estimated from the sample data as $\\bar{d} \\pm 1.96 s_d$. The value $1.96$ is the z-score corresponding to the central $95\\%$ of a standard normal distribution.\n$$\n\\text{LOA} = \\bar{d} \\pm 1.96 s_d\n$$\nThe half-width of the agreement interval is:\n$$\n1.96 s_d = 1.96 \\times \\sqrt{\\frac{254}{33}} \\approx 1.96 \\times 2.7743... \\approx 5.4377... \\ \\mathrm{bpm}\n$$\nThe lower limit of agreement (LLA) is:\n$$\n\\text{LLA} = \\bar{d} - 1.96 s_d \\approx \\frac{1}{3} - 5.4377... \\approx 0.3333... - 5.4377... \\approx -5.1044... \\ \\mathrm{bpm}\n$$\nThe upper limit of agreement (ULA) is:\n$$\n\\text{ULA} = \\bar{d} + 1.96 s_d \\approx \\frac{1}{3} + 5.4377... \\approx 0.3333... + 5.4377... \\approx 5.7710... \\ \\mathrm{bpm}\n$$\nThe problem requires reporting the final numeric results rounded to three significant figures.\nMean bias $= 0.333 \\ \\mathrm{bpm}$.\nLower limit of agreement $= -5.10 \\ \\mathrm{bpm}$.\nUpper limit of agreement $= 5.77 \\ \\mathrm{bpm}$.\n\nFinally, we interpret the clinical acceptability based on the predefined thresholds.\n1. Magnitude of mean bias: $|\\bar{d}| \\approx |0.333| = 0.333 \\ \\mathrm{bpm}$. Since $0.333 \\le 1$, this criterion is met. The systematic bias is clinically acceptable.\n2. $95\\%$ limits of agreement: The interval is approximately $[-5.10, 5.77]$. The criterion requires this interval to lie within $\\pm 5 \\ \\mathrm{bpm}$ around zero, i.e., within $[-5, 5]$. The calculated lower limit ($-5.10$) is below $-5$ and the upper limit ($5.77$) is above $5$. Therefore, this criterion is not met.\n\nThe wearable shows an acceptably small systematic error (bias), but its random error (variability) is too large for it to be considered clinically acceptable under the specified criteria.\n\nThe final reportable values are the mean bias, the lower limit of agreement, and the upper limit of agreement, rounded to three significant figures.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.333 & -5.10 & 5.77\n\\end{pmatrix}\n}\n$$", "id": "4955177"}, {"introduction": "Digital health studies often draw data from specific populations, such as users of a particular smartphone app, who may differ systematically from the general population. This can lead to selection bias, a dangerous pitfall that can create spurious associations or mask real ones. This thought experiment demonstrates a subtle but powerful form of this bias known as collider bias, showing how conditioning on a common effect (like app usage) can distort the true relationship between its causes. [@problem_id:4955183]", "problem": "A hospital system is piloting a smartphone telemedicine application to monitor patients with chronic disease. The informatics team wants to use app-collected data to infer associations that hold in the general patient population. Let $A$ denote age category ($A=1$ for young adults and $A=0$ for older adults), $D$ denote genetic risk status for a chronic disease ($D=1$ for high-risk genotype and $D=0$ otherwise), and $U$ denote app usage ($U=1$ if a patient uses the app, $U=0$ otherwise). Assume that in the general population $A$ and $D$ are independent with $P(A=1)=0.5$ and $P(D=1)=0.5$. App usage is affected by both $A$ and $D$, with the following selection mechanism:\n- $P(U=1 \\mid A=1, D=1) = 0.9$\n- $P(U=1 \\mid A=1, D=0) = 0.5$\n- $P(U=1 \\mid A=0, D=1) = 0.5$\n- $P(U=1 \\mid A=0, D=0) = 0.1$\n\nThe informatics team restricts their analysis to app users (i.e., conditions on $U=1$) and reports an apparent association between $A$ and $D$ among users.\n\nUsing only core definitions from probability (independence, conditional probability, and Bayes’ rule), and the epidemiologic concepts of selection bias and collider bias, determine which of the following statements are correct about this scenario in digital health research:\n\nA. In the full population (not restricted by $U$), $A$ and $D$ are independent, so $P(D=1 \\mid A=1)=P(D=1 \\mid A=0)=0.5$.\n\nB. Among app users ($U=1$), $P(D=1 \\mid A=1, U=1)  P(D=1 \\mid A=0, U=1)$, demonstrating that conditioning on app usage induces an association between $A$ and $D$.\n\nC. Among app users ($U=1$), the odds ratio between $A$ and $D$ equals $1$, indicating no association.\n\nD. Conditioning on $U=1$ is conditioning on a collider, because both $A$ and $D$ causally influence $U$; therefore, conditioning on $U=1$ can induce an association between $A$ and $D$ even if they are independent in the population.\n\nE. The induced association between $A$ and $D$ among users reflects a true causal effect of $A$ on $D$.\n\nF. Under the given numbers, the odds ratio between $A$ and $D$ among app users ($U=1$) equals $0.36$.\n\nSelect all that apply.", "solution": "This problem illustrates collider bias, a form of selection bias that can create a spurious association between two independent variables when conditioning on their common effect. Here, age ($A$) and genetic risk ($D$) are independent causes of app usage ($U$). The causal structure is $A \\to U \\leftarrow D$. We will evaluate each statement systematically.\n\n**Statement A: Correct.**\nThe problem explicitly states that in the general population, $A$ and $D$ are independent, with $P(A=1)=0.5$ and $P(D=1)=0.5$. The definition of independence means that $P(D=1 \\mid A=1) = P(D=1) = 0.5$ and $P(D=1 \\mid A=0) = P(D=1) = 0.5$.\n\n**Statement D: Correct.**\nIn causal graphical models, a \"collider\" is a variable that is a common effect of two or more other variables. Here, both age ($A$) and genetic risk ($D$) are described as influencing app usage ($U$). Thus, $U$ is a collider. A fundamental principle of causal inference is that conditioning on a collider (or a descendant of a collider) can induce a non-causal association between its otherwise independent causes. This is precisely what happens when the analysis is restricted to app users ($U=1$).\n\nTo evaluate the remaining statements, we need to calculate the conditional probabilities within the stratum of app users ($U=1$). We use Bayes' rule.\n\nFirst, let's find the conditional probability of having the high-risk genotype ($D=1$) for young adults ($A=1$) who are app users ($U=1$), i.e., $P(D=1 \\mid A=1, U=1)$.\n$$ P(D=1 \\mid A=1, U=1) = \\frac{P(U=1 \\mid A=1, D=1) P(D=1 \\mid A=1)}{P(U=1 \\mid A=1)} $$\nSince $A$ and $D$ are independent, $P(D=1 \\mid A=1) = P(D=1) = 0.5$.\nThe denominator is $P(U=1 \\mid A=1) = P(U=1 \\mid A=1, D=1)P(D=1 \\mid A=1) + P(U=1 \\mid A=1, D=0)P(D=0 \\mid A=1) = (0.9)(0.5) + (0.5)(0.5) = 0.45 + 0.25 = 0.7$.\nSo, $P(D=1 \\mid A=1, U=1) = \\frac{0.9 \\times 0.5}{0.7} = \\frac{0.45}{0.7} = \\frac{45}{70} = \\frac{9}{14} \\approx 0.643$.\n\nNext, let's find the conditional probability of having the high-risk genotype ($D=1$) for older adults ($A=0$) who are app users ($U=1$), i.e., $P(D=1 \\mid A=0, U=1)$.\n$$ P(D=1 \\mid A=0, U=1) = \\frac{P(U=1 \\mid A=0, D=1) P(D=1 \\mid A=0)}{P(U=1 \\mid A=0)} $$\nAgain, $P(D=1 \\mid A=0) = P(D=1) = 0.5$.\nThe denominator is $P(U=1 \\mid A=0) = P(U=1 \\mid A=0, D=1)P(D=1 \\mid A=0) + P(U=1 \\mid A=0, D=0)P(D=0 \\mid A=0) = (0.5)(0.5) + (0.1)(0.5) = 0.25 + 0.05 = 0.3$.\nSo, $P(D=1 \\mid A=0, U=1) = \\frac{0.5 \\times 0.5}{0.3} = \\frac{0.25}{0.3} = \\frac{25}{30} = \\frac{5}{6} \\approx 0.833$.\n\n**Statement B: Correct.**\nThis statement claims that $P(D=1 \\mid A=1, U=1)  P(D=1 \\mid A=0, U=1)$.\nWe calculated these probabilities as $9/14$ and $5/6$. Is $9/14  5/6$? This is equivalent to asking if $9 \\times 6  14 \\times 5$, which is $54  70$. The inequality is true. Conditioning on app usage has induced a negative association between being young and having the high-risk genotype.\n\n**Statement F: Correct.**\nThis statement asks for the odds ratio (OR) between $A$ and $D$ among app users ($U=1$). The OR is the ratio of the odds of having the disease ($D=1$) for the exposed group ($A=1$) to the odds of having the disease for the unexposed group ($A=0$).\nOdds for young users ($A=1$): $\\frac{P(D=1 \\mid A=1, U=1)}{P(D=0 \\mid A=1, U=1)} = \\frac{9/14}{1 - 9/14} = \\frac{9/14}{5/14} = \\frac{9}{5} = 1.8$.\nOdds for older users ($A=0$): $\\frac{P(D=1 \\mid A=0, U=1)}{P(D=0 \\mid A=0, U=1)} = \\frac{5/6}{1 - 5/6} = \\frac{5/6}{1/6} = 5$.\nThe Odds Ratio is $\\frac{\\text{Odds for } A=1}{\\text{Odds for } A=0} = \\frac{1.8}{5} = \\frac{18}{50} = \\frac{9}{25} = 0.36$.\nThe statement is correct.\n\n**Statement C: Incorrect.**\nThis statement claims the odds ratio is $1$. We just calculated it to be $0.36$. An odds ratio of $1$ would indicate no association, but conditioning on the collider has induced an association.\n\n**Statement E: Incorrect.**\nThe association between $A$ and $D$ found among app users is a statistical artifact of selection bias (collider bias). It does not reflect a true causal relationship between age and genotype in the underlying population. Age does not cause a person's genotype.\n\nFinal Conclusion: The correct statements are A, B, D, and F.", "answer": "$$\\boxed{ABDF}$$", "id": "4955183"}, {"introduction": "A predictive AI model can achieve high accuracy on paper, but its real-world value depends on whether it improves clinical decision-making. Decision Curve Analysis (DCA) is a powerful method for evaluating this clinical utility by weighing the benefits of a model's correct predictions against the harms of its errors. In this practice, you will calculate the 'net benefit' of a risk prediction model to determine if, and for whom, it is more helpful than simple strategies like treating all patients or treating none. [@problem_id:4955199]", "problem": "A telemedicine service uses a supervised classification model to estimate, for each remote consultation, the probability that a patient truly requires urgent same-day in-person evaluation. This risk estimate is used to decide whether to recommend in-person evaluation when the estimated risk exceeds a threshold. You are given a cohort of $N=30$ telemedicine encounters with model-predicted risks $\\{p_i\\}_{i=1}^{30}$ and binary outcomes $\\{y_i\\}_{i=1}^{30}$, where $y_i=1$ indicates that the patient truly required urgent same-day in-person evaluation and $y_i=0$ indicates that the patient did not. The pairs $(p_i,y_i)$ are:\n$(0.45,1)$, $(0.42,1)$, $(0.38,1)$, $(0.35,1)$, $(0.33,1)$, $(0.31,0)$, $(0.29,1)$, $(0.28,0)$, $(0.27,0)$, $(0.25,1)$, $(0.24,0)$, $(0.23,0)$, $(0.22,1)$, $(0.21,0)$, $(0.19,1)$, $(0.18,0)$, $(0.17,0)$, $(0.16,0)$, $(0.15,0)$, $(0.14,0)$, $(0.13,0)$, $(0.12,0)$, $(0.11,0)$, $(0.10,0)$, $(0.09,0)$, $(0.08,0)$, $(0.07,0)$, $(0.06,0)$, $(0.05,0)$, $(0.03,0)$.\n\nAdopt the decision rule “recommend in-person evaluation” if and only if $p_i \\ge t$, where $t$ is the risk threshold. Using the foundational definitions of confusion-matrix counts and the net benefit construct from Decision Curve Analysis (DCA), and starting from first principles of benefit and harm trade-offs at a risk threshold, perform the following:\n\n1. For thresholds $t \\in \\{0.1,\\,0.2,\\,0.3\\}$, compute the model’s net benefit at each $t$.\n2. Construct the corresponding decision curve conceptually by comparing the model’s net benefit to “treat-all” and “treat-none” strategies over the specified thresholds.\n3. Interpret whether the model provides clinical utility relative to “treat-all” and “treat-none” at each threshold.\n\nExpress the final numeric net benefits for the model at $t \\in \\{0.1,\\,0.2,\\,0.3\\}$ in “benefit units per $100$ patients,” and round each value to four significant figures. Do not include units in your final boxed answer.", "solution": "### Foundational Principles of Decision Curve Analysis (DCA)\nDecision Curve Analysis evaluates a model's clinical utility by calculating its \"net benefit.\" The net benefit of a decision rule (in this case, recommending in-person evaluation based on a risk threshold $t$) is defined as the proportion of true positives (benefit) minus a weighted proportion of false positives (harm). The weight for the false positives is the odds of the event at the threshold, $\\frac{t}{1-t}$, which represents the trade-off between the harm of an unnecessary evaluation and the benefit of a necessary one.\n\nThe net benefit (NB) for a population of size $N$ is:\n$$\n\\text{NB}(t) = \\frac{\\text{TP}(t)}{N} - \\frac{\\text{FP}(t)}{N} \\left(\\frac{t}{1-t}\\right)\n$$\nwhere $\\text{TP}(t)$ and $\\text{FP}(t)$ are the number of true positives and false positives at threshold $t$.\n\nThe model's utility is assessed by comparing its net benefit to two reference strategies:\n1.  **Treat-None**: The net benefit is always zero, so $\\text{NB}_{\\text{none}}(t) = 0$.\n2.  **Treat-All**: The net benefit is $\\text{NB}_{\\text{all}}(t) = \\pi - (1-\\pi) \\left(\\frac{t}{1-t}\\right)$, where $\\pi$ is the prevalence of the condition.\n\n### Data Analysis and Counts\nFrom the provided data ($N=30$), we first count the number of patients who truly required evaluation ($y_i=1$).\n-   Number of positive cases ($P$): There are $9$ patients with $y_i=1$.\n-   Number of negative cases ($N_{neg}$): There are $30 - 9 = 21$ patients with $y_i=0$.\n-   The prevalence in the cohort is $\\pi = \\frac{9}{30} = 0.3$.\n\nNow, we compute the confusion matrix counts ($\\text{TP}$ and $\\text{FP}$) for the model at each threshold $t$.\n\n**1. Analysis for Threshold $t=0.1$**\nWe recommend evaluation if $p_i \\ge 0.1$.\n-   **True Positives ($\\text{TP}(0.1)$)**: Patients with $y_i=1$ and $p_i \\ge 0.1$. All $9$ positive cases have risks $\\ge 0.1$. Thus, $\\text{TP}(0.1) = 9$.\n-   **False Positives ($\\text{FP}(0.1)$)**: Patients with $y_i=0$ and $p_i \\ge 0.1$. Counting from the data, we find $15$ negative cases with risks $\\ge 0.1$. Thus, $\\text{FP}(0.1) = 15$.\n-   **Net Benefit of the Model**:\n    $$\n    \\text{NB}_{\\text{model}}(0.1) = \\frac{9}{30} - \\frac{15}{30} \\left(\\frac{0.1}{1-0.1}\\right) = 0.3 - 0.5 \\left(\\frac{1}{9}\\right) = \\frac{2.2}{9} \\approx 0.24444\n    $$\n\n**2. Analysis for Threshold $t=0.2$**\nWe recommend evaluation if $p_i \\ge 0.2$.\n-   **True Positives ($\\text{TP}(0.2)$)**: Patients with $y_i=1$ and $p_i \\ge 0.2$. The positive case with risk $0.19$ is now excluded. Thus, $\\text{TP}(0.2) = 8$.\n-   **False Positives ($\\text{FP}(0.2)$)**: Patients with $y_i=0$ and $p_i \\ge 0.2$. Counting from the data, we find $6$ negative cases with risks $\\ge 0.2$. Thus, $\\text{FP}(0.2) = 6$.\n-   **Net Benefit of the Model**:\n    $$\n    \\text{NB}_{\\text{model}}(0.2) = \\frac{8}{30} - \\frac{6}{30} \\left(\\frac{0.2}{1-0.2}\\right) = \\frac{8}{30} - \\frac{6}{30} \\left(\\frac{1}{4}\\right) = \\frac{1}{30} (8 - 1.5) = \\frac{6.5}{30} \\approx 0.21667\n    $$\n\n**3. Analysis for Threshold $t=0.3$**\nWe recommend evaluation if $p_i \\ge 0.3$.\n-   **True Positives ($\\text{TP}(0.3)$)**: Patients with $y_i=1$ and $p_i \\ge 0.3$. The positive cases with risks $\\{0.45, 0.42, 0.38, 0.35, 0.33\\}$ meet this criterion. Thus, $\\text{TP}(0.3) = 5$.\n-   **False Positives ($\\text{FP}(0.3)$)**: Patients with $y_i=0$ and $p_i \\ge 0.3$. The only negative case with risk $\\ge 0.3$ is the one at $0.31$. Thus, $\\text{FP}(0.3) = 1$.\n-   **Net Benefit of the Model**:\n    $$\n    \\text{NB}_{\\text{model}}(0.3) = \\frac{5}{30} - \\frac{1}{30} \\left(\\frac{0.3}{1-0.3}\\right) = \\frac{1}{30} \\left(5 - \\frac{3}{7}\\right) = \\frac{1}{30} \\left(\\frac{32}{7}\\right) = \\frac{32}{210} \\approx 0.15238\n    $$\n\n### Decision Curve and Clinical Utility Interpretation\nA decision curve plots net benefit against the risk threshold. To interpret the model's utility, we compare its net benefit to that of the \"treat-all\" and \"treat-none\" strategies.\n\n| Threshold ($t$) | $\\text{NB}_{\\text{model}}(t)$ | $\\text{NB}_{\\text{all}}(t)$ | $\\text{NB}_{\\text{none}}(t)$ |\n|:---------------:|:-------------------------:|:-----------------------:|:-----------------------:|\n| $0.1$           | $\\approx 0.244$           | $\\approx 0.222$         | $0$                     |\n| $0.2$           | $\\approx 0.217$           | $0.125$                 | $0$                     |\n| $0.3$           | $\\approx 0.152$           | $0$                     | $0$                     |\n\n-   At all three thresholds ($0.1, 0.2, 0.3$), the net benefit of the model is positive and greater than the net benefit of both the \"treat-all\" and \"treat-none\" strategies.\n-   This means that for decision-makers whose risk tolerance falls within this range, using the model to guide recommendations provides more clinical value than either recommending evaluations for everyone or for no one.\n-   The model's decision curve would lie above the curves for both reference strategies across this range of thresholds, indicating clear clinical utility.\n\n### Final Answer Calculation\nThe problem asks for the net benefits for the model, expressed in units per $100$ patients and rounded to four significant figures. This requires multiplying the per-patient NB values by $100$.\n\n-   For $t=0.1$: $\\text{NB}_{\\text{model}} \\times 100 = 0.24444... \\times 100 \\approx 24.44$\n-   For $t=0.2$: $\\text{NB}_{\\text{model}} \\times 100 = 0.21666... \\times 100 \\approx 21.67$\n-   For $t=0.3$: $\\text{NB}_{\\text{model}} \\times 100 = 0.15238... \\times 100 \\approx 15.24$", "answer": "$$\n\\boxed{\\begin{pmatrix} 24.44  21.67  15.24 \\end{pmatrix}}\n$$", "id": "4955199"}]}