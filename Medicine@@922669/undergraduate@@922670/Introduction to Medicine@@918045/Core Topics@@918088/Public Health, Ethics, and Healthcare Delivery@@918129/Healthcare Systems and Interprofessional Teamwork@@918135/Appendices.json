{"hands_on_practices": [{"introduction": "In modern healthcare systems, automated alerts are crucial for flagging urgent conditions like sepsis, enabling a rapid response from interprofessional teams. However, no alert is perfect, and frequent false alarms can lead to \"alert fatigue,\" where clinicians start to ignore them. This practice will guide you through the fundamental epidemiological evaluation of a clinical alert system, using concepts like sensitivity, specificity, and positive predictive value to quantify its accuracy and understand its tangible impact on clinical workload [@problem_id:4961551].", "problem": "A tertiary-care hospital deploys an Electronic Health Record (EHR) sepsis alert to trigger an early response by an interprofessional team comprising nurses, physicians, pharmacists, and respiratory therapists. Over one month, the hospital monitors $N=2{,}000$ adult inpatients admitted to general wards, and an independent clinical audit applying Sepsis-3 criteria finds a sepsis prevalence of $p=0.15$ in this monitored cohort. The EHR alert fires for $A=400$ unique patients during the monitoring window. Among the audit-confirmed sepsis cases, the alert correctly identified $TP=240$ patients.\n\nAssume each patient contributes at most one alert event in the relevant window, independence across patients, and stable operating characteristics of the alert. Starting from the foundational definitions of binary test metrics used in clinical epidemiology and decision support, derive from first principles and compute the Positive Predictive Value (PPV), the sensitivity, and the specificity of the EHR sepsis alert for this cohort. In your reasoning, explain what the positive predictive value means for interprofessional triage workload in this context.\n\nReport your three numerical results in the order: PPV, sensitivity, specificity. Express each as a decimal and round to four significant figures. No units are required.", "solution": "The problem is valid as it is scientifically grounded in the principles of clinical epidemiology, is well-posed with sufficient and consistent data, and is expressed objectively.\n\nThe first step is to formalize the problem using a standard $2 \\times 2$ contingency table, which cross-classifies patients by their true condition (sepsis or no sepsis) and the EHR alert status (alert fired or did not fire).\n\nThe given quantities are:\n- Total number of patients, $N = 2,000$.\n- Prevalence of sepsis, $p = 0.15$.\n- Total number of patients with a positive alert, $N_{T+} = 400$.\n- Number of true positive alerts, $TP = 240$.\n\nFrom these givens, we can derive the fundamental counts for our contingency table.\n\n1.  **Total number of patients with sepsis (Condition Positive):**\n    The number of patients who actually have sepsis is the product of the total patient count and the prevalence.\n    $$N_{C+} = N \\times p = 2,000 \\times 0.15 = 300$$\n\n2.  **Total number of patients without sepsis (Condition Negative):**\n    The number of patients who do not have sepsis is the remainder of the total cohort.\n    $$N_{C-} = N - N_{C+} = 2,000 - 300 = 1,700$$\n\nNow we can determine the four values of the contingency table: True Positives ($TP$), False Positives ($FP$), False Negatives ($FN$), and True Negatives ($TN$).\n\n- **True Positives ($TP$):** These are patients with sepsis who were correctly identified by the alert. This is given as:\n  $$TP = 240$$\n\n- **False Negatives ($FN$):** These are patients with sepsis whom the alert failed to identify. This is the difference between the total number of septic patients and the true positives.\n  $$FN = N_{C+} - TP = 300 - 240 = 60$$\n\n- **False Positives ($FP$):** These are patients without sepsis for whom the alert incorrectly fired. This is the difference between the total number of alerts that fired and the true positive alerts.\n  $$FP = N_{T+} - TP = 400 - 240 = 160$$\n\n- **True Negatives ($TN$):** These are patients without sepsis who were correctly identified as such (the alert did not fire). This is the difference between the total number of non-septic patients and the false positives.\n  $$TN = N_{C-} - FP = 1,700 - 160 = 1,540$$\n\nWe can summarize these values in a contingency table:\n\n|                  | Condition: Sepsis | Condition: No Sepsis | Total             |\n|------------------|-------------------|----------------------|-------------------|\n| **Alert: Fired** | $TP = 240$        | $FP = 160$           | $N_{T+} = 400$    |\n| **Alert: Silent**| $FN = 60$         | $TN = 1,540$         | $N_{T-} = 1,600$  |\n| **Total**        | $N_{C+} = 300$    | $N_{C-} = 1,700$     | $N = 2,000$       |\n\nWith these values, we can now derive the requested performance metrics from their foundational definitions.\n\n**1. Positive Predictive Value (PPV)**\nThe PPV is the probability that a patient for whom the alert fires actually has sepsis. It is the proportion of true positives among all positive tests.\n$$PPV = \\frac{TP}{TP + FP}$$\nSubstituting the values:\n$$PPV = \\frac{240}{240 + 160} = \\frac{240}{400} = 0.6$$\nRounded to four significant figures, this is $0.6000$.\n\nThe PPV is a critical metric for assessing the clinical utility of an alert and its impact on workload. In this context, a PPV of $0.6000$ means that $60\\%$ of the alerts that fire are for patients who genuinely have sepsis. Conversely, this implies that $40\\%$ of the alerts are false alarms ($1 - PPV = 1 - 0.6 = 0.4$). For every $10$ times an interprofessional team is mobilized by this alert, on average, $4$ of those responses will be for patients who do not have sepsis. This high false alarm rate consumes significant clinical resources—including the time of nurses, physicians, pharmacists, and respiratory therapists—that could be allocated to other patients. It can lead to \"alert fatigue,\" a phenomenon where clinicians become desensitized to frequent, low-yield alerts, potentially leading to delayed responses even for true positive cases, thereby undermining the very purpose of the alert system.\n\n**2. Sensitivity (True Positive Rate)**\nSensitivity measures the ability of the test to correctly identify patients who have the condition. It is the proportion of septic patients who are correctly identified by the alert.\n$$Sensitivity = \\frac{TP}{TP + FN}$$\nSubstituting the values:\n$$Sensitivity = \\frac{240}{240 + 60} = \\frac{240}{300} = 0.8$$\nRounded to four significant figures, this is $0.8000$.\n\n**3. Specificity (True Negative Rate)**\nSpecificity measures the ability of the test to correctly identify patients who do not have the condition. It is the proportion of non-septic patients for whom the alert correctly remained silent.\n$$Specificity = \\frac{TN}{TN + FP}$$\nSubstituting the values:\n$$Specificity = \\frac{1,540}{1,540 + 160} = \\frac{1,540}{1,700} \\approx 0.90588235...$$\nRounding to four significant figures, this is $0.9059$.\n\nThe three numerical results, in the requested order (PPV, sensitivity, specificity) and rounded to four significant figures, are $0.6000$, $0.8000$, and $0.9059$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.6000 & 0.8000 & 0.9059\n\\end{pmatrix}\n}\n$$", "id": "4961551"}, {"introduction": "Effective healthcare systems do not just treat illness; they continuously monitor their own performance to improve quality and patient safety. Statistical Process Control (SPC) provides a rigorous framework for this task, helping teams distinguish random, \"common-cause\" variation from significant, \"special-cause\" events that require investigation. In this exercise, you will derive and apply a p-chart, a fundamental SPC tool, to monitor weekly medication error rates—a core function for any interprofessional patient safety committee [@problem_id:4961587].", "problem": "A hospital’s interprofessional Medication Safety Committee uses Statistical Process Control (SPC) to monitor the weekly proportion of medication orders with at least one clinically significant error. In a stable six-month baseline period, the committee estimates the true error probability to be $p$ and, going forward, audits a simple random sample of $n$ orders each week. Assume independent Bernoulli trials for orders within a week, and that $n$ is large enough for a normal approximation to be appropriate under the Central Limit Theorem (CLT).\n\nStarting from the Bernoulli model and Binomial distribution definition for the count of errors in a weekly sample, derive the approximate three-standard-deviation ($3$-standard-deviation) control limits for a $p$-chart in terms of the baseline $p$ and the weekly sample size $n$. Then, for a baseline error probability of $p = 0.05$ and a weekly sample size of $n = 1000$, compute the numerical values of the lower control limit (LCL) and upper control limit (UCL).\n\nExpress both limits as decimal proportions (no percentage sign), and round your final numeric answers to four significant figures.", "solution": "The process under monitoring is the weekly sample proportion of medication orders with at least one clinically significant error. Model each audited order in a given week as an independent Bernoulli random variable $Y_{i}$ with $P(Y_{i}=1)=p$ (error) and $P(Y_{i}=0)=1-p$ (no error), for $i=1,\\dots,n$. The weekly error count is then\n$$\nX=\\sum_{i=1}^{n} Y_{i}.\n$$\nBy the Bernoulli and Binomial model, $X \\sim \\mathrm{Binomial}(n,p)$ with\n$$\n\\mathbb{E}[X]=np, \\quad \\mathrm{Var}(X)=np(1-p).\n$$\nThe weekly sample proportion is\n$$\n\\hat{p}=\\frac{X}{n}.\n$$\nUsing linearity of expectation and variance scaling,\n$$\n\\mathbb{E}[\\hat{p}]=\\mathbb{E}\\!\\left[\\frac{X}{n}\\right]=\\frac{1}{n}\\mathbb{E}[X]=p, \\quad \\mathrm{Var}(\\hat{p})=\\mathrm{Var}\\!\\left(\\frac{X}{n}\\right)=\\frac{1}{n^{2}}\\mathrm{Var}(X)=\\frac{p(1-p)}{n}.\n$$\nFor large $n$ with $np$ and $n(1-p)$ not too small, the Central Limit Theorem (CLT) justifies the normal approximation\n$$\n\\hat{p} \\approx \\mathcal{N}\\!\\left(p,\\; \\frac{p(1-p)}{n}\\right).\n$$\nA $p$-chart with three-standard-deviation limits uses the process mean and three times the process standard deviation of $\\hat{p}$. Therefore, the approximate control limits are\n$$\n\\mathrm{LCL}=p-3\\sqrt{\\frac{p(1-p)}{n}}, \\qquad \\mathrm{UCL}=p+3\\sqrt{\\frac{p(1-p)}{n}}.\n$$\nThese expressions are the desired derivation in terms of $p$ and $n$. In applications, if $\\mathrm{LCL}<0$, it is truncated at $0$ because a proportion cannot be negative; here we will compute and verify positivity for the given parameters.\n\nNow compute the limits for $p=0.05$ and $n=1000$:\n$$\n\\sqrt{\\frac{p(1-p)}{n}}=\\sqrt{\\frac{0.05 \\times 0.95}{1000}}=\\sqrt{\\frac{0.0475}{1000}}=\\sqrt{0.0000475}.\n$$\nEvaluate the square root symbolically to the extent needed for the final numeric result:\n$$\n\\sqrt{0.0000475} \\approx 0.006892024376,\n$$\nso\n$$\n3\\sqrt{\\frac{p(1-p)}{n}} \\approx 3 \\times 0.006892024376 \\approx 0.02067607313.\n$$\nHence,\n$$\n\\mathrm{UCL}=0.05+0.02067607313 \\approx 0.07067607313,\n$$\n$$\n\\mathrm{LCL}=0.05-0.02067607313 \\approx 0.02932392687.\n$$\nBoth limits are positive, so no truncation is needed. Rounding each to four significant figures (and expressing as decimal proportions with no percentage sign) gives\n$$\n\\mathrm{LCL} \\approx 0.02932, \\qquad \\mathrm{UCL} \\approx 0.07068.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0.02932 & 0.07068\\end{pmatrix}}$$", "id": "4961587"}, {"introduction": "When deciding whether to adopt a major new intervention, such as an interprofessional chronic disease management program, healthcare leaders must look beyond immediate outcomes to project long-term value. Health economic models, particularly the Markov model, are essential for this strategic analysis, simulating patient journeys over many years to estimate cumulative costs and health benefits (like Quality-Adjusted Life Years, or QALYs). This advanced, hands-on practice challenges you to build a complete cost-utility Markov model in code, providing a powerful, practical understanding of how large-scale healthcare investment decisions are made [@problem_id:4961571].", "problem": "You are to write a complete, runnable program that derives and implements a time-homogeneous discrete-time Markov cost-utility cohort model for a chronic disease management program delivered by an interprofessional team, and computes expected total discounted Quality-Adjusted Life Years (QALYs) and costs over multiple cycles. The model must be derived from first principles using foundational definitions of a Markov chain, expected value, and discounting, without invoking any shortcut formulas.\n\nA cohort of size $1$ is distributed across $3$ mutually exclusive and collectively exhaustive health states indexed by $0,1,2$ with the following interpretation: state $0$ is a stable chronic condition, state $1$ is a complication state, and state $2$ is death. The process evolves in discrete cycles of length $L$ years. Let $\\mathbf{s}_t \\in \\mathbb{R}^3$ be the row vector of state occupancy proportions at the start of cycle $t$ with $\\sum_i s_t(i) = 1$, and let $\\mathbf{P} \\in \\mathbb{R}^{3 \\times 3}$ be the transition matrix under usual care, where each row sums to $1$ and state $2$ is absorbing. The Markov property requires that $\\mathbf{s}_{t+1} = \\mathbf{s}_t \\mathbf{P}$ for all cycles $t \\in \\{0,1,\\dots,T-1\\}$, where $T$ is the number of cycles.\n\nLet $\\mathbf{u} \\in \\mathbb{R}^3$ be the vector of health state utility weights measured in Quality-Adjusted Life Years (QALYs) per year, and let $\\mathbf{c} \\in \\mathbb{R}^3$ be the vector of per-cycle costs in United States Dollar (USD) for each health state. Let $r$ be the nonnegative annual discount rate. Define the discount factor for cycle $t$ as $d(t) = \\left(1 + r\\right)^{-tL}$. The expected discounted QALYs accumulated in cycle $t$ are given by the product of cycle length and the expected utility in that cycle multiplied by the discount factor based on the principle of expected value and time preference. The expected discounted costs accumulated in cycle $t$ are given by the product of cycle length and the expected cost in that cycle multiplied by the same discount factor.\n\nThe interprofessional team program is modeled as a transformation of $\\mathbf{P}$ into a program transition matrix $\\mathbf{P}_{\\text{prog}}$ using a nonnegative effectiveness parameter $\\alpha \\in [0,1)$ that represents a proportional reduction in deterioration transitions with mass reallocated to better outcomes while preserving stochasticity of each row. Apply the following transformation, which is constrained to be scientifically plausible and row-stochastic:\n- For row $0$ (stable): reduce transitions to worse states ($0 \\to 1$ and $0 \\to 2$) by the factor $(1 - \\alpha)$ and reallocate the reduced probability mass to $0 \\to 0$; that is, set $p^{\\text{prog}}_{00} = p_{00} + \\alpha \\left(p_{01} + p_{02}\\right)$, $p^{\\text{prog}}_{01} = (1 - \\alpha) p_{01}$, $p^{\\text{prog}}_{02} = (1 - \\alpha) p_{02}$.\n- For row $1$ (complication): reduce transitions to death ($1 \\to 2$) by the factor $(1 - \\alpha)$ and reallocate the reduced probability mass to improvement ($1 \\to 0$); that is, set $p^{\\text{prog}}_{10} = p_{10} + \\alpha p_{12}$, $p^{\\text{prog}}_{11} = p_{11}$, $p^{\\text{prog}}_{12} = (1 - \\alpha) p_{12}$.\n- For row $2$ (death): enforce absorbing behavior $[0,0,1]$.\n\nThe program also incurs an added per-cycle management cost $k \\ge 0$ applied to the living population (states $0$ and $1$ only) each cycle and an initial setup cost $c_0 \\ge 0$ applied at cycle $t = 0$ to the living population only. All costs must be expressed in USD per cohort of size $1$ and discounted consistently with $d(t)$. All QALYs must be expressed in years. Assume death has zero utility and zero cost.\n\nStarting from the core definitions of a Markov chain, expected value, and discounting, implement a cohort simulation that:\n- Computes the expected discounted total QALYs and total costs over $T$ cycles for usual care (using $\\mathbf{P}$) and for the program (using $\\mathbf{P}_{\\text{prog}}$ and the additional costs $k$ and $c_0$).\n- Returns the incremental results defined as $\\Delta \\text{QALYs} = \\text{QALYs}_{\\text{prog}} - \\text{QALYs}_{\\text{usual}}$ and $\\Delta \\text{Cost} = \\text{Cost}_{\\text{prog}} - \\text{Cost}_{\\text{usual}}$.\n\nYour program must implement the above for each of the following test cases and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case yields a two-element list $[\\Delta \\text{QALYs}, \\Delta \\text{Cost}]$. Round $\\Delta \\text{QALYs}$ to $4$ decimal places (in years) and $\\Delta \\text{Cost}$ to $2$ decimal places (in USD). The required final output format is:\n- A single line: $[[\\Delta \\text{QALYs}_1,\\Delta \\text{Cost}_1],[\\Delta \\text{QALYs}_2,\\Delta \\text{Cost}_2],\\dots]$.\n\nTest Suite:\n- Case A (baseline, happy path):\n  - $\\mathbf{P} = \\begin{bmatrix}0.88 & 0.10 & 0.02 \\\\ 0.15 & 0.75 & 0.10 \\\\ 0.00 & 0.00 & 1.00\\end{bmatrix}$, $\\alpha = 0.20$, $T = 10$, $L = 1.0$, $r = 0.03$.\n  - $\\mathbf{u} = [0.85, 0.60, 0.00]$, $\\mathbf{c} = [1200, 6000, 0]$ (USD per cycle).\n  - $k = 200$ (USD per cycle per living person), $c_0 = 50$ (USD per living person at $t=0$).\n  - Initial state distribution $\\mathbf{s}_0 = [1.0, 0.0, 0.0]$.\n- Case B (boundary with zero program effectiveness and zero discounting):\n  - $\\mathbf{P} = \\begin{bmatrix}0.90 & 0.09 & 0.01 \\\\ 0.20 & 0.70 & 0.10 \\\\ 0.00 & 0.00 & 1.00\\end{bmatrix}$, $\\alpha = 0.00$, $T = 5$, $L = 1.0$, $r = 0.00$.\n  - $\\mathbf{u} = [0.85, 0.60, 0.00]$, $\\mathbf{c} = [1000, 7000, 0]$ (USD per cycle).\n  - $k = 150$ (USD per cycle per living person), $c_0 = 0$ (USD per living person at $t=0$).\n  - Initial state distribution $\\mathbf{s}_0 = [0.8, 0.2, 0.0]$.\n- Case C (edge with higher mortality and positive discounting):\n  - $\\mathbf{P} = \\begin{bmatrix}0.70 & 0.20 & 0.10 \\\\ 0.10 & 0.60 & 0.30 \\\\ 0.00 & 0.00 & 1.00\\end{bmatrix}$, $\\alpha = 0.25$, $T = 8$, $L = 1.0$, $r = 0.05$.\n  - $\\mathbf{u} = [0.80, 0.50, 0.00]$, $\\mathbf{c} = [1500, 8000, 0]$ (USD per cycle).\n  - $k = 300$ (USD per cycle per living person), $c_0 = 100$ (USD per living person at $t=0$).\n  - Initial state distribution $\\mathbf{s}_0 = [1.0, 0.0, 0.0]$.\n\nYour program must use only these test cases, compute the incremental results for each, and print a single line with the nested list of results in the exact format described. All QALYs must be expressed in years and rounded to $4$ decimals; all costs must be expressed in USD and rounded to $2$ decimals. All probabilities must remain within $[0,1]$ and each row of any transition matrix must sum to $1$.", "solution": "The problem requires the derivation and implementation of a time-homogeneous discrete-time Markov cost-utility model to evaluate a chronic disease management program. The evaluation is based on computing the incremental Quality-Adjusted Life Years (QALYs) and costs over a finite time horizon compared to usual care. The solution must be derived from first principles.\n\nLet the set of health states be $\\mathcal{S} = \\{0, 1, 2\\}$, representing a stable condition, a complication, and death, respectively. The model evolves in discrete time steps called cycles, indexed by $t \\in \\{0, 1, \\dots, T-1\\}$, where $T$ is the total number of cycles. Each cycle has a length of $L$ years.\n\nA cohort, normalized to size $1$, is distributed among these states. The state occupancy at the start of cycle $t$ is described by a row vector $\\mathbf{s}_t = [s_t(0), s_t(1), s_t(2)]$, where $s_t(i)$ is the proportion of the cohort in state $i$ and $\\sum_{i=0}^{2} s_t(i) = 1$. The process starts with an initial distribution $\\mathbf{s}_0$.\n\nThe evolution of the cohort is governed by a time-homogeneous transition probability matrix $\\mathbf{M}$. According to the Markov property, the state distribution at the beginning of the next cycle is given by the matrix-vector product:\n$$\n\\mathbf{s}_{t+1} = \\mathbf{s}_t \\mathbf{M}\n$$\nThis equation forms the basis of the cohort simulation. Starting from $\\mathbf{s}_0$, we can iteratively compute the state distribution for all subsequent cycles.\n\nThe model calculates two primary outcomes: QALYs and costs. These are accumulated during each cycle and discounted to their present value. The annual discount rate is $r$. The discount factor for outcomes occurring in cycle $t$ (at time $tL$) is $d(t) = (1+r)^{-tL}$.\n\nLet $\\mathbf{u} = [u_0, u_1, u_2]^T$ be the column vector of utility weights (in QALYs per year) and $\\mathbf{c} = [c_0, c_1, c_2]^T$ be the column vector of per-cycle costs. The cohort is assumed to remain in the states defined by $\\mathbf{s}_t$ for the entire duration of cycle $t$.\n\nThe expected utility rate during cycle $t$ is the inner product of the state distribution and the utility vector: $\\mathbb{E}[U_t] = \\mathbf{s}_t \\cdot \\mathbf{u} = \\sum_{i=0}^2 s_t(i) u_i$. The total QALYs accumulated in cycle $t$, which has length $L$ years, is $L \\cdot (\\mathbf{s}_t \\cdot \\mathbf{u})$. After discounting, the contribution of cycle $t$ to the total discounted QALYs is:\n$$\n\\text{QALY}_t = L \\cdot (\\mathbf{s}_t \\cdot \\mathbf{u}) \\cdot (1+r)^{-tL}\n$$\nThe expected state-dependent cost incurred during cycle $t$ is $\\mathbb{E}[C_t] = \\mathbf{s}_t \\cdot \\mathbf{c} = \\sum_{i=0}^2 s_t(i) c_i$. The discounted state-dependent cost for cycle $t$ is:\n$$\n\\text{Cost}_{\\text{state},t} = (\\mathbf{s}_t \\cdot \\mathbf{c}) \\cdot (1+r)^{-tL}\n$$\nThe total discounted QALYs and costs over the time horizon $T$ are the sums of the per-cycle outcomes:\n$$\n\\text{Total QALYs} = \\sum_{t=0}^{T-1} \\text{QALY}_t = \\sum_{t=0}^{T-1} L \\cdot (\\mathbf{s}_t \\cdot \\mathbf{u}) \\cdot (1+r)^{-tL}\n$$\n$$\n\\text{Total Cost}_{\\text{base}} = \\sum_{t=0}^{T-1} \\text{Cost}_{\\text{state},t} = \\sum_{t=0}^{T-1} (\\mathbf{s}_t \\cdot \\mathbf{c}) \\cdot (1+r)^{-tL}\n$$\nThis framework is applied to two scenarios: usual care and the program.\n\n**Usual Care Scenario**\nFor usual care, the transition matrix is $\\mathbf{M} = \\mathbf{P}$. The total QALYs and costs are calculated as follows:\n1.  Initialize total outcomes: $\\text{QALYs}_{\\text{usual}} = 0$, $\\text{Cost}_{\\text{usual}} = 0$.\n2.  Set the initial state vector $\\mathbf{s}_t = \\mathbf{s}_0$.\n3.  For each cycle $t$ from $0$ to $T-1$:\n    a. Calculate the discount factor $d(t) = (1+r)^{-tL}$.\n    b. Add discounted QALYs for the current cycle: $\\text{QALYs}_{\\text{usual}} \\leftarrow \\text{QALYs}_{\\text{usual}} + L \\cdot (\\mathbf{s}_t \\cdot \\mathbf{u}) \\cdot d(t)$.\n    c. Add discounted costs for the current cycle: $\\text{Cost}_{\\text{usual}} \\leftarrow \\text{Cost}_{\\text{usual}} + (\\mathbf{s}_t \\cdot \\mathbf{c}) \\cdot d(t)$.\n    d. Update the state vector for the next cycle: $\\mathbf{s}_{t+1} = \\mathbf{s}_t \\mathbf{P}$. Set $\\mathbf{s}_t \\leftarrow \\mathbf{s}_{t+1}$.\n\n**Program Scenario**\nThe program scenario involves a modified transition matrix, $\\mathbf{P}_{\\text{prog}}$, and additional costs.\nFirst, $\\mathbf{P}_{\\text{prog}}$ is constructed from $\\mathbf{P}$ and the effectiveness parameter $\\alpha \\in [0,1)$ based on the specified rules:\n-   $p^{\\text{prog}}_{00} = p_{00} + \\alpha (p_{01} + p_{02})$\n-   $p^{\\text{prog}}_{01} = (1 - \\alpha) p_{01}$\n-   $p^{\\text{prog}}_{02} = (1 - \\alpha) p_{02}$\n-   $p^{\\text{prog}}_{10} = p_{10} + \\alpha p_{12}$\n-   $p^{\\text{prog}}_{11} = p_{11}$\n-   $p^{\\text{prog}}_{12} = (1 - \\alpha) p_{12}$\n-   $p^{\\text{prog}}_{20} = 0$, $p^{\\text{prog}}_{21} = 0$, $p^{\\text{prog}}_{22} = 1$\n\nThe additional costs are an initial setup cost $c_0$ and a per-cycle management cost $k$.\n-   The initial cost $c_0$ is applied at $t=0$ to the living population, $s_0(0) + s_0(1)$. Its discounted value is $c_0 \\cdot (s_0(0) + s_0(1))$, as the discount factor at $t=0$ is $1$.\n-   The per-cycle cost $k$ is applied in each cycle $t$ to the living population at that time, $s^{\\text{prog}}_t(0) + s^{\\text{prog}}_t(1)$. The discounted additional cost for cycle $t$ is $k \\cdot (s^{\\text{prog}}_t(0) + s^{\\text{prog}}_t(1)) \\cdot (1+r)^{-tL}$.\n\nThe total QALYs and costs for the program are calculated as follows:\n1.  Initialize outcomes: $\\text{QALYs}_{\\text{prog}} = 0$. Initialize total cost with the initial setup cost: $\\text{Cost}_{\\text{prog}} = c_0 \\cdot (s_0(0) + s_0(1))$.\n2.  Set the initial state vector $\\mathbf{s}_t = \\mathbf{s}_0$.\n3.  For each cycle $t$ from $0$ to $T-1$:\n    a. Calculate the discount factor $d(t) = (1+r)^{-tL}$.\n    b. Add discounted QALYs: $\\text{QALYs}_{\\text{prog}} \\leftarrow \\text{QALYs}_{\\text{prog}} + L \\cdot (\\mathbf{s}_t \\cdot \\mathbf{u}) \\cdot d(t)$.\n    c. Calculate total cost for the cycle: $\\text{Cost}_{\\text{cycle},t} = (\\mathbf{s}_t \\cdot \\mathbf{c}) + k \\cdot (s_t(0) + s_t(1))$.\n    d. Add discounted cycle cost: $\\text{Cost}_{\\text{prog}} \\leftarrow \\text{Cost}_{\\text{prog}} + \\text{Cost}_{\\text{cycle},t} \\cdot d(t)$.\n    e. Update state vector: $\\mathbf{s}_{t+1} = \\mathbf{s}_t \\mathbf{P}_{\\text{prog}}$. Set $\\mathbf{s}_t \\leftarrow \\mathbf{s}_{t+1}$.\n\n**Incremental Analysis**\nFinally, the incremental outcomes are computed as the difference between the program and usual care scenarios:\n$$\n\\Delta \\text{QALYs} = \\text{QALYs}_{\\text{prog}} - \\text{QALYs}_{\\text{usual}}\n$$\n$$\n\\Delta \\text{Cost} = \\text{Cost}_{\\text{prog}} - \\text{Cost}_{\\text{usual}}\n$$\nThe results for each test case are obtained by applying this complete algorithm to the provided parameters. The implementation will follow this logic directly, creating a function to perform the core simulation for an arbitrary set of inputs and then calling it for both scenarios to compute the final incremental results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    Derives and implements a time-homogeneous discrete-time Markov cost-utility model.\n    \"\"\"\n    \n    test_cases = [\n        {\n            # Case A\n            \"P\": np.array([[0.88, 0.10, 0.02], [0.15, 0.75, 0.10], [0.00, 0.00, 1.00]]),\n            \"alpha\": 0.20,\n            \"T\": 10,\n            \"L\": 1.0,\n            \"r\": 0.03,\n            \"u\": np.array([0.85, 0.60, 0.00]),\n            \"c\": np.array([1200, 6000, 0]),\n            \"k\": 200.0,\n            \"c0\": 50.0,\n            \"s0\": np.array([1.0, 0.0, 0.0])\n        },\n        {\n            # Case B\n            \"P\": np.array([[0.90, 0.09, 0.01], [0.20, 0.70, 0.10], [0.00, 0.00, 1.00]]),\n            \"alpha\": 0.00,\n            \"T\": 5,\n            \"L\": 1.0,\n            \"r\": 0.00,\n            \"u\": np.array([0.85, 0.60, 0.00]),\n            \"c\": np.array([1000, 7000, 0]),\n            \"k\": 150.0,\n            \"c0\": 0.0,\n            \"s0\": np.array([0.8, 0.2, 0.0])\n        },\n        {\n            # Case C\n            \"P\": np.array([[0.70, 0.20, 0.10], [0.10, 0.60, 0.30], [0.00, 0.00, 1.00]]),\n            \"alpha\": 0.25,\n            \"T\": 8,\n            \"L\": 1.0,\n            \"r\": 0.05,\n            \"u\": np.array([0.80, 0.50, 0.00]),\n            \"c\": np.array([1500, 8000, 0]),\n            \"k\": 300.0,\n            \"c0\": 100.0,\n            \"s0\": np.array([1.0, 0.0, 0.0])\n        }\n    ]\n\n    def run_simulation(M, s0, u, c, T, L, r, k=0.0, c0=0.0):\n        \"\"\"\n        Runs a Markov cohort simulation from first principles.\n\n        Args:\n            M (np.ndarray): The 3x3 transition probability matrix.\n            s0 (np.ndarray): The initial state occupancy row vector.\n            u (np.ndarray): The utility column vector (shape (3,)).\n            c (np.ndarray): The per-cycle cost column vector (shape (3,)).\n            T (int): The number of cycles.\n            L (float): The cycle length in years.\n            r (float): The annual discount rate.\n            k (float): Additional per-cycle cost for living population.\n            c0 (float): Initial setup cost for living population.\n\n        Returns:\n            tuple: A tuple containing (total_discounted_qaly, total_discounted_cost).\n        \"\"\"\n        total_qaly = 0.0\n        \n        # Initial cost applied at t=0\n        living_pop_initial = s0[0] + s0[1]\n        total_cost = c0 * living_pop_initial\n        \n        s_current = s0.copy()\n\n        for t in range(T):\n            # Discount factor for cycle t\n            discount_factor = (1 + r)**(-t * L)\n\n            # --- QALY Calculation ---\n            # Expected utility rate (QALYs/year) for the cohort in cycle t\n            expected_utility_rate = np.dot(s_current, u)\n            # QALYs accumulated during cycle t (length L years)\n            qaly_in_cycle = L * expected_utility_rate\n            # Add discounted QALYs to total\n            total_qaly += qaly_in_cycle * discount_factor\n            \n            # --- Cost Calculation ---\n            # Expected state-dependent cost in cycle t\n            expected_state_cost = np.dot(s_current, c)\n            # Additional program management cost in cycle t for living population\n            living_pop_t = s_current[0] + s_current[1]\n            additional_cost = k * living_pop_t\n            # Total cost incurred during cycle t\n            cost_in_cycle = expected_state_cost + additional_cost\n            # Add discounted cost to total\n            total_cost += cost_in_cycle * discount_factor\n            \n            # Update state vector for the start of the next cycle\n            s_current = np.dot(s_current, M)\n            \n        return total_qaly, total_cost\n\n    final_results = []\n    \n    for case in test_cases:\n        P, alpha, T, L, r, u, c, k, c0, s0 = \\\n            case[\"P\"], case[\"alpha\"], case[\"T\"], case[\"L\"], case[\"r\"], \\\n            case[\"u\"], case[\"c\"], case[\"k\"], case[\"c0\"], case[\"s0\"]\n            \n        # 1. Usual Care Simulation\n        qaly_usual, cost_usual = run_simulation(P, s0, u, c, T, L, r)\n\n        # 2. Program Simulation\n        # Construct the program transition matrix P_prog\n        P_prog = P.copy()\n        p01, p02 = P[0, 1], P[0, 2]\n        P_prog[0, 0] = P[0, 0] + alpha * (p01 + p02)\n        P_prog[0, 1] = (1 - alpha) * p01\n        P_prog[0, 2] = (1 - alpha) * p02\n        \n        p12 = P[1, 2]\n        P_prog[1, 0] = P[1, 0] + alpha * p12\n        P_prog[1, 2] = (1 - alpha) * p12\n        \n        # P_prog[1, 1] remains unchanged, P_prog[2, :] remains [0, 0, 1]\n        \n        qaly_prog, cost_prog = run_simulation(P_prog, s0, u, c, T, L, r, k, c0)\n        \n        # 3. Incremental Results\n        delta_qaly = qaly_prog - qaly_usual\n        delta_cost = cost_prog - cost_usual\n        \n        # Round according to specifications\n        rounded_delta_qaly = round(delta_qaly, 4)\n        rounded_delta_cost = round(delta_cost, 2)\n        \n        final_results.append([rounded_delta_qaly, rounded_delta_cost])\n        \n    # Format the final output string\n    # e.g., [[0.0617, 335.71], [-0.0, 1140.0], [0.2458, 1279.03]]\n    output_str = \"[\" + \",\".join([f\"[{q},{c}]\" for q, c in final_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "4961571"}]}