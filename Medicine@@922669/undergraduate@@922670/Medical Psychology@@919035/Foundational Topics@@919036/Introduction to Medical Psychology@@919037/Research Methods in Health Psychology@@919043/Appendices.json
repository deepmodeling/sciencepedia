{"hands_on_practices": [{"introduction": "Before we can test complex health psychology theories, we must ensure our measurement tools are reliable. This exercise introduces Cronbach's alpha, a key metric for assessing the internal consistency of a scale, which tells us if a group of items effectively measures the same underlying concept. By working through this problem [@problem_id:4743307], you will learn how the variability within items and across the total score combine to determine whether a set of questions truly coheres to measure a single psychological construct.", "problem": "A health psychology research team is validating a five-item patient-reported questionnaire intended to measure perceived medication adherence in a chronic illness clinic. Under the framework of Classical Test Theory (CTT), internal consistency reliability quantifies the degree to which items cohere to measure a single construct. The team collected pilot data and computed item-level variances $\\,\\sigma_{i}^{2}\\,$ for each of the $\\,k\\,$ items and the variance of the total score (the sum of the five items), denoted $\\,\\sigma_{T}^{2}\\,$. The observed item variances are $\\,\\sigma_{i}^{2} = \\{\\,1.2,\\,0.8,\\,1.0,\\,1.1,\\,0.9\\,\\}\\,$, the number of items is $\\,k=5\\,$, and the total score variance is $\\,\\sigma_{T}^{2}=8.4\\,$. Using only fundamental definitions from Classical Test Theory and properties of variance and covariance of sums of random variables, derive the reliability estimator known as the Cronbach’s alpha coefficient $\\,\\alpha\\,$ for this scale and compute its value for the given data. Then, interpret the magnitude of the obtained $\\,\\alpha\\,$ in terms of internal consistency for scale development in health psychology.\n\nExpress the final numerical value of $\\,\\alpha\\,$ as a unitless decimal and round your answer to four significant figures.", "solution": "The problem as stated is valid. It is scientifically grounded in Classical Test Theory (CTT), a standard psychometric framework. It is well-posed, objective, and provides a complete and consistent set of data required for a unique solution. The task is to derive and compute a standard statistical estimator, Cronbach's alpha, and provide a technical interpretation of the result, which is a standard procedure in quantitative psychology and related fields.\n\nThe derivation of the Cronbach’s alpha coefficient, $\\alpha$, begins with the fundamental principles of Classical Test Theory and the properties of variance. Let the score on each of the $k$ items be represented by the random variables $Y_1, Y_2, \\dots, Y_k$. The total score on the questionnaire, $X_T$, is the sum of the individual item scores:\n$$X_T = \\sum_{i=1}^{k} Y_i$$\nAccording to the properties of variance, the variance of a sum of random variables is the sum of their individual variances plus twice the sum of all unique pairwise covariances. For the total score $X_T$, its variance, which the problem denotes as $\\sigma_T^2$, is given by:\n$$\\sigma_T^2 = \\text{Var}(X_T) = \\text{Var}\\left(\\sum_{i=1}^{k} Y_i\\right) = \\sum_{i=1}^{k} \\text{Var}(Y_i) + \\sum_{i \\neq j} \\text{Cov}(Y_i, Y_j)$$\nUsing the notation provided in the problem, where $\\sigma_i^2 = \\text{Var}(Y_i)$, this equation becomes:\n$$\\sigma_T^2 = \\sum_{i=1}^{k} \\sigma_i^2 + \\sum_{i \\neq j} \\text{Cov}(Y_i, Y_j)$$\nInternal consistency reliability is a measure of the extent to which the items on a scale measure the same underlying construct. This coherence is reflected in the inter-item covariances. A high degree of internal consistency implies that the items are strongly inter-correlated. The total inter-item covariance, $\\sum_{i \\neq j} \\text{Cov}(Y_i, Y_j)$, represents the portion of the total score variance that is shared among the items. We can isolate this term from the variance equation:\n$$\\sum_{i \\neq j} \\text{Cov}(Y_i, Y_j) = \\sigma_T^2 - \\sum_{i=1}^{k} \\sigma_i^2$$\nCronbach's alpha, $\\alpha$, is defined as an estimator of reliability based on these variance components. It is the ratio of the total inter-item covariance to the total score variance, multiplied by a correction factor $\\frac{k}{k-1}$. The correction factor adjusts for the fact that the sum is over a finite number of items, $k$. The definition is:\n$$\\alpha = \\frac{k}{k-1} \\left( \\frac{\\sum_{i \\neq j} \\text{Cov}(Y_i, Y_j)}{\\sigma_T^2} \\right)$$\nSubstituting the expression for the sum of covariances, we derive the standard computational formula for Cronbach's alpha:\n$$\\alpha = \\frac{k}{k-1} \\left( \\frac{\\sigma_T^2 - \\sum_{i=1}^{k} \\sigma_i^2}{\\sigma_T^2} \\right)$$\nThis can be simplified to:\n$$\\alpha = \\frac{k}{k-1} \\left( 1 - \\frac{\\sum_{i=1}^{k} \\sigma_i^2}{\\sigma_T^2} \\right)$$\nThis formula expresses the reliability estimator $\\alpha$ solely in terms of the number of items ($k$), the sum of the individual item variances ($\\sum \\sigma_i^2$), and the variance of the total score ($\\sigma_T^2$), all of which are provided or can be computed from the given data.\n\nNext, we compute the value of $\\alpha$ for the given data.\nThe number of items is $k=5$.\nThe individual item variances are given as the set $\\{1.2, 0.8, 1.0, 1.1, 0.9\\}$.\nThe sum of the item variances is:\n$$\\sum_{i=1}^{k} \\sigma_i^2 = 1.2 + 0.8 + 1.0 + 1.1 + 0.9 = 5.0$$\nThe variance of the total score is given as $\\sigma_T^2 = 8.4$.\n\nSubstituting these values into the derived formula for $\\alpha$:\n$$\\alpha = \\frac{5}{5-1} \\left( 1 - \\frac{5.0}{8.4} \\right)$$\n$$\\alpha = \\frac{5}{4} \\left( 1 - \\frac{5.0}{8.4} \\right) = 1.25 \\left( 1 - 0.595238095...\\right)$$\n$$\\alpha = 1.25 \\left( 0.404761904...\\right)$$\n$$\\alpha = 0.50595238...$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\\alpha \\approx 0.5060$$\n\nFinally, we interpret the magnitude of the obtained $\\alpha$ value. An $\\alpha$ of approximately $0.5060$ indicates a poor level of internal consistency for the five-item questionnaire. In CTT, $\\alpha$ is a lower-bound estimate of the true reliability, which is the proportion of total score variance attributable to true score variance. This result suggests that only about $51\\%$ of the variance in the total scores is shared variance among the items, which is a proxy for true score variance under certain assumptions. Conversely, about $49\\%$ of the variance may be attributable to random error or item-specific factors not related to the intended construct of medication adherence.\nIn developmental research for psychological scales, particularly in a health context where measurement precision is important, conventional guidelines often suggest a minimum $\\alpha$ value of $0.70$ for a scale to be considered 'acceptable'. A value in the range of $0.50$ to $0.60$ is typically deemed 'poor'. Therefore, a research team obtaining this result would conclude that the current version of the questionnaire is not reliable enough for use. They would be advised to revise the scale, which could involve rewriting ambiguous items, removing items that do not correlate well with the others, or adding new items that better capture the underlying construct, before proceeding with further validation studies.", "answer": "$$\\boxed{0.5060}$$", "id": "4743307"}, {"introduction": "Effective research in health psychology often moves beyond asking *if* an intervention works to understanding *how* it works. This practice introduces mediation analysis, a powerful statistical technique for uncovering the psychological mechanisms that explain the relationship between a predictor and an outcome. In this problem [@problem_id:4743379], you will calculate a mediated (or indirect) effect and use the modern method of bootstrapping to evaluate its significance, giving you the tools to test more nuanced theoretical models.", "problem": "A research team in medical psychology investigates whether patient self-efficacy mediates the relationship between health literacy training and medication adherence. Let $X$ denote the intensity of health literacy training (scaled to the range $0$ to $3$ sessions), $M$ denote patient self-efficacy (standardized score), and $Y$ denote proportion of doses taken over a $30$-day period (continuous between $0$ and $1$). They fit two Ordinary Least Squares (OLS) regressions: first, $M$ on $X$ to estimate the path from $X$ to $M$, and second, $Y$ on $M$ and $X$ to estimate the paths from $M$ to $Y$ controlling for $X$ and the direct path from $X$ to $Y$ controlling for $M$. The sample size is $n=420$.\n\nThe regression outputs are:\n- For $M$ on $X$: the coefficient for $X$ is $\\hat{a}=0.52$ with standard error $\\text{SE}(\\hat{a})=0.06$.\n- For $Y$ on $M$ and $X$: the coefficient for $M$ is $\\hat{b}=0.31$ with standard error $\\text{SE}(\\hat{b})=0.09$, and the coefficient for $X$ is $\\hat{c}'=0.12$ with standard error $\\text{SE}(\\hat{c}')=0.08$.\n\nA nonparametric bootstrap with $B=2000$ resamples was conducted by resampling participants with replacement and re-estimating the two regressions per resample. The empirical distribution of the resampled indirect effect estimates yields the following percentile information: the $0.025$ quantile is $0.082$ and the $0.975$ quantile is $0.245$.\n\nUsing the definitions of mediation in linear models and the percentile bootstrap method:\n- Compute the indirect effect of $X$ on $Y$ through $M$.\n- Construct the bootstrap percentile confidence interval at confidence level $0.95$ for the indirect effect.\n- Decide whether the indirect effect is statistically significant at $\\alpha=0.05$ based on the bootstrap interval.\n\nRound your indirect effect to four significant figures. For assessment, provide only the indirect effect value as your final numerical answer.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It describes a standard mediation analysis, a well-established statistical methodology in health psychology and related fields. The variables, data, and analytical approach (Ordinary Least Squares regression and nonparametric bootstrapping) are all appropriate and consistently defined. All necessary information for a solution is provided. Therefore, the problem is valid.\n\nThe problem asks for the computation and interpretation of an indirect effect in a mediation model. The proposed model posits that the effect of an independent variable $X$ (health literacy training) on a dependent variable $Y$ (medication adherence) is mediated by a third variable $M$ (patient self-efficacy).\n\nThe mediation model can be represented by two linear regression equations:\n1.  The effect of $X$ on the mediator $M$:\n    $$ M = \\beta_{M0} + a X + \\epsilon_M $$\n    Here, the coefficient $a$ represents the path from $X$ to $M$. The estimate for this coefficient is given as $\\hat{a} = 0.52$.\n\n2.  The effect of $X$ and $M$ on the dependent variable $Y$:\n    $$ Y = \\beta_{Y0} + c' X + b M + \\epsilon_Y $$\n    In this equation, the coefficient $b$ represents the path from $M$ to $Y$ while controlling for $X$, and $c'$ represents the direct effect of $X$ on $Y$ while controlling for $M$. The estimates for these coefficients are given as $\\hat{b} = 0.31$ and $\\hat{c}' = 0.12$.\n\nThe total effect of $X$ on $Y$ is composed of a direct effect and an indirect effect. The indirect effect is the portion of the relationship between $X$ and $Y$ that is transmitted through the mediator $M$.\n\n**Step 1: Compute the indirect effect**\nThe indirect effect of $X$ on $Y$ through $M$ is defined as the product of the path coefficient $a$ and the path coefficient $b$. The point estimate of this indirect effect, denoted as $\\hat{a}\\hat{b}$, is calculated using the estimated coefficients from the regression models.\n\nGiven:\n- Estimate of the path from $X$ to $M$: $\\hat{a} = 0.52$\n- Estimate of the path from $M$ to $Y$: $\\hat{b} = 0.31$\n\nThe point estimate of the indirect effect is:\n$$ \\hat{a}\\hat{b} = (0.52) \\times (0.31) = 0.1612 $$\nThe problem asks for this value to be rounded to four significant figures. The calculated value $0.1612$ already has four significant figures.\n\n**Step 2: Construct the bootstrap percentile confidence interval**\nThe problem provides information from a nonparametric bootstrap procedure with $B=2000$ resamples. The percentile bootstrap method constructs a confidence interval directly from the quantiles of the empirical distribution of the bootstrapped estimates. A $(1-\\alpha)$ confidence interval is formed by the $(\\alpha/2)$ and $(1-\\alpha/2)$ quantiles of the bootstrap distribution.\n\nFor a confidence level of $0.95$, we have $\\alpha = 0.05$. The required quantiles are:\n- Lower bound: The $\\alpha/2 = 0.05/2 = 0.025$ quantile.\n- Upper bound: The $1 - \\alpha/2 = 1 - 0.025 = 0.975$ quantile.\n\nThe problem explicitly provides these values from the distribution of $2000$ bootstrapped indirect effect estimates:\n- $0.025$ quantile = $0.082$\n- $0.975$ quantile = $0.245$\n\nTherefore, the $95\\%$ bootstrap percentile confidence interval for the indirect effect $ab$ is $[0.082, 0.245]$.\n\n**Step 3: Decide on statistical significance**\nThe statistical significance of the indirect effect is assessed by checking if its confidence interval contains the null value. The null hypothesis ($H_0$) for the indirect effect is that it is zero, i.e., $H_0: ab = 0$.\n\nThe test is conducted at a significance level of $\\alpha = 0.05$, corresponding to the $95\\%$ confidence interval.\n- The calculated $95\\%$ confidence interval is $[0.082, 0.245]$.\n- The null value is $0$.\n- Since the interval $[0.082, 0.245]$ does not contain the value $0$, the null hypothesis can be rejected at the $\\alpha = 0.05$ level.\n- This means the indirect effect of health literacy training on medication adherence through patient self-efficacy is statistically significant. The interpretation is that there is a positive mediating effect: higher intensity of training is associated with higher self-efficacy, which in turn is associated with better medication adherence.\n\nThe final answer required is only the numerical value of the indirect effect.\nIndirect Effect = $0.1612$.", "answer": "$$\\boxed{0.1612}$$", "id": "4743379"}, {"introduction": "Scientific discovery requires both disciplined hypothesis testing and open-minded exploration, but confusing the two can lead to false conclusions and undermine the credibility of research. This problem tackles the critical issue of research transparency and the role of preregistration in distinguishing planned (confirmatory) analyses from data-inspired (exploratory) ones. By working through a realistic research scenario [@problem_id:4743329], you will learn how to navigate deviations from a study plan while maintaining statistical rigor and reporting integrity.", "problem": "A randomized controlled trial in health psychology evaluates whether a mobile mindfulness intervention reduces perceived stress compared to usual care among adults with chronic illness. The study is preregistered with the following primary analysis: test the difference in mean change on the Perceived Stress Scale (PSS) from baseline to $12$ weeks between intervention and control using a Linear Mixed-Effects Model (LMM) with random intercepts for participants, fixed effects for treatment, baseline PSS, and site, with a two-sided significance level $\\alpha=0.05$. The preregistration includes a contingency plan: if the LMM residuals are markedly non-normal or the LMM fails to converge, use Generalized Estimating Equations (GEE) with exchangeable correlation and robust sandwich standard errors. No subgroup analyses are prespecified. Outliers are to be retained. Missing data are to be handled by multiple imputation under a Missing At Random assumption with $20$ imputations.\n\nUpon conducting the study, the team documents the following deviations:\n\n$1.$ The LMM fails to converge; the team uses GEE as specified in the contingency plan.\n\n$2.$ Ten participants have extreme baseline PSS values; the team applies Winsorization to the top and bottom $1\\%$ of PSS values before imputation, which was not prespecified.\n\n$3.$ Due to pandemic delays, many participants have data at $24$ weeks; the team shifts focus to the $24$-week PSS change and considers reporting it as the primary endpoint, even though $12$ weeks was preregistered.\n\n$4.$ After visualizing the data, the team runs $4$ subgroup analyses (gender, age group, baseline stress tertile, and site) on $12$-week PSS, none prespecified.\n\nFrom first principles of Null Hypothesis Significance Testing (NHST), define the roles of preregistration and deviations relative to Type I error control. Use the definition of Type I error rate per test as $\\alpha$ and the independence approximation under the global null for $m$ tests to reason about the family-wise error rate $\\text{FWER}$. Then, classify each deviation as exploratory or confirmatory, and select the reporting plan that preserves inferential integrity by appropriately separating confirmatory from exploratory findings and controlling multiplicity where relevant. In your reasoning, compute the family-wise error rate $\\text{FWER}$ if the $4$ subgroup analyses were reported with unadjusted $\\alpha=0.05$, and compute the Bonferroni-corrected per-test threshold for those $4$ subgroup tests.\n\nWhich option best satisfies these requirements?\n\nA. Redefine the $24$-week outcome as the new primary and treat all $4$ subgroup analyses as confirmatory, applying a Bonferroni correction across all confirmatory tests including the original $12$-week test; set per-test $\\alpha=0.01$ and incorporate Winsorization into the confirmatory pipeline without flagging the deviation from the preregistration.\n\nB. Retain the preregistered $12$-week PSS effect as the single confirmatory test, using GEE per the prespecified contingency if LMM fails to converge; label Winsorization and the $24$-week analyses as exploratory sensitivity or descriptive analyses; treat the $4$ subgroup analyses as exploratory and control multiplicity with Bonferroni at per-test $\\alpha=0.05/4=0.0125$; explicitly report that unadjusted subgroup testing would have $\\text{FWER}=1-(1-0.05)^4\\approx0.1855$; clearly separate confirmatory and exploratory results in the manuscript.\n\nC. Treat all deviations, including the switch to GEE and the original primary $12$-week analysis, as exploratory; report unadjusted $p$-values for all analyses, arguing that labeling analyses as exploratory suffices to preserve inferential integrity.\n\nD. Split the $\\alpha=0.05$ equally between the preregistered primary and the $4$ subgroup analyses for a per-test threshold of $0.01$, elevate the $24$-week outcome to co-primary to reflect pandemic realities, and include Winsorization in the primary analysis to protect against outliers, without separately labeling deviations from the preregistration.", "solution": "The user has provided a problem statement regarding a randomized controlled trial in health psychology, focusing on the principles of preregistration, deviations from a prespecified analysis plan, and the control of Type I error. The task is to validate the problem, and if valid, to derive the correct reporting strategy based on first principles.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **Study Design:** Randomized controlled trial (RCT).\n*   **Intervention:** Mobile mindfulness vs. usual care.\n*   **Population:** Adults with chronic illness.\n*   **Preregistered Primary Endpoint:** Mean change on the Perceived Stress Scale (PSS) from baseline to $12$ weeks.\n*   **Preregistered Primary Analysis:** Linear Mixed-Effects Model (LMM).\n    *   **Model Specification:** Random intercepts for participants; fixed effects for treatment, baseline PSS, and site.\n    *   **Significance Level:** Two-sided $\\alpha=0.05$.\n*   **Preregistered Contingency Plan:** If LMM residuals are markedly non-normal or the LMM fails to converge, use Generalized Estimating Equations (GEE) with exchangeable correlation and robust sandwich standard errors.\n*   **Preregistered Subgroup Analyses:** None prespecified.\n*   **Preregistered Outlier Handling:** Outliers are to be retained.\n*   **Preregistered Missing Data Handling:** Multiple imputation under a Missing At Random (MAR) assumption with $20$ imputations.\n*   **Documented Deviations from Preregistration:**\n    1.  The LMM fails to converge; the team uses GEE.\n    2.  Winsorization is applied to the top and bottom $1\\%$ of baseline PSS values before imputation (not prespecified).\n    3.  The team considers shifting the primary endpoint to the $24$-week PSS change (not prespecified).\n    4.  Four subgroup analyses (gender, age group, baseline stress tertile, and site) are run on the $12$-week PSS outcome (not prespecified).\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded:** The problem is firmly rooted in the established principles of biostatistics, clinical trial methodology, and research ethics. Concepts such as RCTs, preregistration, LMM, GEE, Null Hypothesis Significance Testing (NHST), Type I error, family-wise error rate (FWER), Bonferroni correction, and the distinction between confirmatory and exploratory analysis are all standard and fundamental to the field.\n*   **Well-Posed:** The problem is clearly structured. It presents a realistic scenario of a clinical trial with common analytical challenges and deviations. The question asks for a specific evaluation of these deviations and a choice of the best reporting plan based on first principles. A unique, meaningful solution can be derived.\n*   **Objective:** The language is Factual and precise. It describes the study plan and deviations without subjective bias. The evaluation is to be based on objective statistical principles.\n\nThe problem statement exhibits no flaws. It is not scientifically unsound, non-formalizable, incomplete, unrealistic, or ill-posed. The scenario is a textbook example used to teach best practices in statistical analysis and reporting.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. The solution will now be derived.\n\n### Derivation and Option Analysis\n\n**First Principles: Preregistration, NHST, and Type I Error**\n\nThe core principle of Null Hypothesis Significance Testing (NHST) is to control the rate of Type I error—the rejection of a true null hypothesis ($H_0$)—at a prespecified level, $\\alpha$. For a single, primary hypothesis test, this is straightforward. A confirmatory analysis is one where the hypothesis, outcome, and statistical plan are all specified *a priori* (before data are observed). This ensures that the long-run Type I error rate is controlled at $\\alpha$. Preregistration is the formal mechanism for documenting this *a priori* plan, creating a firewall between confirmatory (hypothesis-testing) and exploratory (hypothesis-generating) research.\n\nAny deviation from the preregistered plan that is based on observations of the data (e.g., choosing a new outcome, adding post-hoc subgroup analyses, changing outlier handling) introduces \"researcher degrees of freedom.\" This practice, also known as \"p-hacking\" or \"data-dredging,\" inflates the Type I error rate because the researcher can select the analysis that produces a desirable result. Such analyses are, by definition, **exploratory**. Their results cannot be interpreted with the same inferential confidence as a confirmatory test and should be treated as preliminary and hypothesis-generating.\n\n**Multiplicity and Family-Wise Error Rate (FWER)**\n\nWhen multiple hypothesis tests are conducted, the probability of making at least one Type I error across the \"family\" of tests, known as the Family-Wise Error Rate (FWER), increases. If $m$ independent tests are performed, each at a significance level $\\alpha$, the FWER under the global null hypothesis (that all $H_0$ are true) is given by:\n\n$$ \\text{FWER} = 1 - (1 - \\alpha)^m $$\n\nFor the $4$ non-prespecified subgroup analyses, $m=4$ and $\\alpha=0.05$. The FWER would be:\n\n$$ \\text{FWER} = 1 - (1 - 0.05)^4 = 1 - (0.95)^4 = 1 - 0.81450625 \\approx 0.1855 $$\n\nThis means there is an $18.55\\%$ chance of finding at least one \"significant\" result by chance alone, even if no true subgroup effects exist. To control FWER at $\\alpha_{FW} = 0.05$, a multiplicity correction is required. The Bonferroni correction is a common, albeit conservative, method that adjusts the per-test significance threshold, $\\alpha'$, to:\n\n$$ \\alpha' = \\frac{\\alpha_{FW}}{m} $$\n\nFor the $4$ subgroup tests, the Bonferroni-corrected threshold would be:\n\n$$ \\alpha' = \\frac{0.05}{4} = 0.0125 $$\n\n**Classification of Deviations**\n\n1.  **Switch to GEE:** This deviation was specified in the preregistered contingency plan. The LMM's failure to converge is an objective, pre-defined trigger. Therefore, executing this plan is part of the confirmatory analysis pathway. This analysis remains **confirmatory**.\n2.  **Winsorization:** The plan was to retain outliers. Applying Winsorization is a post-hoc, data-driven decision. This redefines the data itself. Any analysis using this modified data is **exploratory** and should be reported as a sensitivity analysis to assess the impact of extreme values.\n3.  **Shift to 24-week Endpoint:** The primary endpoint was preregistered as the $12$-week change. Shifting focus to the $24$-week change is a post-hoc decision that capitalizes on a different, un-prespecified outcome. This analysis is **exploratory**.\n4.  **$4$ Subgroup Analyses:** These were not prespecified and were conducted \"after visualizing the data.\" This is a classic example of data-dredging. These analyses are unequivocally **exploratory**.\n\n**Optimal Reporting Plan**\n\nThe plan that preserves inferential integrity must:\n*   Clearly distinguish the single confirmatory test from all exploratory analyses.\n*   Identify the $12$-week PSS analysis using GEE as the sole confirmatory test, with its result judged against $\\alpha = 0.05$.\n*   Label all other analyses (Winsorization, $24$-week outcome, $4$ subgroups) as exploratory.\n*   Acknowledge and control for multiplicity in a principled way for families of exploratory tests, such as the subgroup analyses.\n*   Be fully transparent about all deviations from the preregistered plan.\n\n### Evaluation of Options\n\n**A. Redefine the $24$-week outcome as the new primary and treat all $4$ subgroup analyses as confirmatory, applying a Bonferroni correction across all confirmatory tests including the original $12$-week test; set per-test $\\alpha=0.01$ and incorporate Winsorization into the confirmatory pipeline without flagging the deviation from the preregistration.**\n\nThis option is profoundly flawed. It commits the statistical error of HARKing (Hypothesizing After the Results are Known) by treating post-hoc, exploratory analyses as confirmatory. It misapplies a Bonferroni correction to a mixture of *a priori* and post-hoc tests. Furthermore, it advocates for a lack of transparency by incorporating an un-prespecified data transformation (Winsorization) and not flagging deviations. This approach undermines the entire purpose of preregistration.\n\n*Verdict:* **Incorrect**.\n\n**B. Retain the preregistered $12$-week PSS effect as the single confirmatory test, using GEE per the prespecified contingency if LMM fails to converge; label Winsorization and the $24$-week analyses as exploratory sensitivity or descriptive analyses; treat the $4$ subgroup analyses as exploratory and control multiplicity with Bonferroni at per-test $\\alpha=0.05/4=0.0125$; explicitly report that unadjusted subgroup testing would have $\\text{FWER}=1-(1-0.05)^4\\approx0.1855$; clearly separate confirmatory and exploratory results in the manuscript.**\n\nThis option correctly follows the principles of inferential integrity.\n1.  It correctly identifies the single confirmatory test ($12$-week outcome using GEE).\n2.  It correctly classifies all other analyses (Winsorization, $24$-week, subgroups) as exploratory.\n3.  It correctly proposes a multiplicity correction (Bonferroni) for the family of exploratory subgroup tests and calculates the correct adjusted threshold ($\\alpha' = 0.0125$).\n4.  It correctly calculates the inflated FWER ($\\approx 0.1855$) to justify the need for correction, demonstrating a full understanding of the issue.\n5.  It emphasizes transparent reporting and the crucial separation of confirmatory and exploratory findings.\n\nThis plan is the only one that adheres to best practices for statistical reporting and rigor.\n\n*Verdict:* **Correct**.\n\n**C. Treat all deviations, including the switch to GEE and the original primary $12$-week analysis, as exploratory; report unadjusted $p$-values for all analyses, arguing that labeling analyses as exploratory suffices to preserve inferential integrity.**\n\nThis option is incorrect for two main reasons. First, it misunderstands the role of a prespecified contingency plan. The switch to GEE was part of the *a priori* plan, so the resulting analysis remains confirmatory. Downgrading it to exploratory is an unnecessary abdication of a planned hypothesis test. Second, while labeling is necessary, it may not be sufficient. For a known family of exploratory tests, failing to address the inflated FWER is poor practice and can be misleading to readers. The problem asks for a plan that *controls* multiplicity, which this option fails to do.\n\n*Verdict:* **Incorrect**.\n\n**D. Split the $\\alpha=0.05$ equally between the preregistered primary and the $4$ subgroup analyses for a per-test threshold of $0.01$, elevate the $24$-week outcome to co-primary to reflect pandemic realities, and include Winsorization in the primary analysis to protect against outliers, without separately labeling deviations from the preregistration.**\n\nThis option is incorrect for the same fundamental reasons as option A. It improperly elevates post-hoc analyses to confirmatory status and misuses an alpha-spending strategy. The alpha budget for confirmatory tests cannot be shared with exploratory tests invented after data collection. It also advocates for non-transparent reporting by incorporating un-prespecified methods into the primary analysis without documentation.\n\n*Verdict:* **Incorrect**.", "answer": "$$\\boxed{B}$$", "id": "4743329"}]}