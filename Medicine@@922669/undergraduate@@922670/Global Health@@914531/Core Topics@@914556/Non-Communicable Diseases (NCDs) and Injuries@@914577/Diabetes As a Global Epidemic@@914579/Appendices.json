{"hands_on_practices": [{"introduction": "The first step in confronting any public health challenge, including the global diabetes epidemic, is to accurately measure its scale. This exercise provides foundational practice in biostatistics by asking you to calculate the prevalence of diabetes from survey data. By deriving a confidence interval, you will also learn how to quantify the statistical uncertainty around this estimate, a crucial skill for interpreting public health reports and scientific literature [@problem_id:4972716].", "problem": "In a nationally representative cross-sectional survey framed to monitor diabetes as a global epidemic, a simple random sample of $n=2000$ adults is drawn from a large population. Among them, $x=300$ report physician-diagnosed diabetes mellitus. Using the core definition that point prevalence is the proportion of individuals in the population with the condition at a specified time, and using the Central Limit Theorem (CLT) for a sample proportion as the foundational approximation for interval estimation, address the following:\n\n1. Compute the point estimate of the diabetes prevalence $\\hat{p}$ using the observed data $(x,n)$.\n2. Starting from the CLT for the sample proportion and the quantile of the standard normal distribution corresponding to a two-sided confidence level of $0.95$, derive the two-sided Wald confidence interval for the true population prevalence $p$ without assuming any finite population correction.\n3. From your derived interval, compute its total length $L$ (upper bound minus lower bound).\n\nReport only the interval length $L$ as your final answer. Round your reported $L$ to four significant figures and express it as a decimal proportion (for example, use $0.12$ rather than a percentage).", "solution": "The problem requires the calculation of the total length, $L$, of a two-sided $95\\%$ confidence interval for the true population prevalence of diabetes, $p$. The provided data are from a simple random sample of size $n=2000$, within which $x=300$ individuals were found to have physician-diagnosed diabetes mellitus. The method to be used is the Wald confidence interval, which relies on the Central Limit Theorem (CLT) approximation for a sample proportion.\n\nFirst, we calculate the point estimate of the population prevalence, denoted by $\\hat{p}$. This estimate is the sample proportion of individuals with the condition.\n$$ \\hat{p} = \\frac{x}{n} $$\nSubstituting the given values, $x=300$ and $n=2000$:\n$$ \\hat{p} = \\frac{300}{2000} = \\frac{3}{20} = 0.15 $$\n\nNext, we establish the formula for the two-sided Wald confidence interval for the population proportion $p$. According to the Central Limit Theorem, for a sufficiently large sample size $n$, the sampling distribution of the sample proportion $\\hat{p}$ is approximately normal. The mean of this distribution is the true population proportion $p$, and its standard deviation, known as the standard error of the proportion, is $SE(\\hat{p}) = \\sqrt{\\frac{p(1-p)}{n}}$.\n\nThe Wald interval is constructed by approximating this standard error using the point estimate $\\hat{p}$ in place of the unknown $p$. The estimated standard error, $\\widehat{SE}(\\hat{p})$, is:\n$$ \\widehat{SE}(\\hat{p}) = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} $$\nThe general formula for a two-sided confidence interval for $p$ is given by the point estimate plus or minus a margin of error:\n$$ \\text{CI} = \\hat{p} \\pm z_{\\alpha/2} \\cdot \\widehat{SE}(\\hat{p}) $$\nHere, $z_{\\alpha/2}$ is the critical value from the standard normal distribution corresponding to a confidence level of $1-\\alpha$.\n\nThe problem specifies a confidence level of $0.95$. This implies a significance level of $\\alpha = 1 - 0.95 = 0.05$. For a two-sided interval, the critical value is determined by $\\alpha/2 = 0.05/2 = 0.025$. The quantile $z_{0.025}$ is the value such that the area in the upper tail of the standard normal distribution is $0.025$. From standard statistical tables, this value is:\n$$ z_{0.025} \\approx 1.96 $$\n\nThe confidence interval is defined by its lower bound (LB) and upper bound (UB):\n$$ \\text{LB} = \\hat{p} - z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} $$\n$$ \\text{UB} = \\hat{p} + z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} $$\n\nThe total length of the confidence interval, $L$, is the difference between the upper and lower bounds:\n$$ L = \\text{UB} - \\text{LB} $$\n$$ L = \\left( \\hat{p} + z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\right) - \\left( \\hat{p} - z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\right) $$\nBy simplifying this expression, we find that the length is twice the margin of error:\n$$ L = 2 \\cdot z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} $$\n\nWe now substitute the numerical values into this formula to compute $L$:\n-   $z_{\\alpha/2} = z_{0.025} \\approx 1.96$\n-   $\\hat{p} = 0.15$\n-   $n = 2000$\n\n$$ L = 2 \\times 1.96 \\times \\sqrt{\\frac{0.15 \\times (1 - 0.15)}{2000}} $$\n$$ L = 3.92 \\times \\sqrt{\\frac{0.15 \\times 0.85}{2000}} $$\n$$ L = 3.92 \\times \\sqrt{\\frac{0.1275}{2000}} $$\n$$ L = 3.92 \\times \\sqrt{0.00006375} $$\nWe proceed with the numerical calculation:\n$$ \\sqrt{0.00006375} \\approx 0.0079843596... $$\n$$ L \\approx 3.92 \\times 0.0079843596... $$\n$$ L \\approx 0.03129988... $$\n\nThe problem requires the final answer to be rounded to four significant figures. The first four significant figures of $L$ are $3$, $1$, $2$, and $9$. The fifth significant figure is $9$, which means we must round up the fourth significant figure. Rounding $0.03129$ up results in $0.03130$. The trailing zero is significant and is necessary to represent the accuracy of four significant figures.\n$$ L \\approx 0.03130 $$", "answer": "$$\\boxed{0.03130}$$", "id": "4972716"}, {"introduction": "Once we have an idea of a disease's prevalence, the next challenge is identifying individuals who have it, often through screening programs. This practice delves into the real-world performance of a diagnostic test, going beyond its intrinsic properties of sensitivity and specificity. You will calculate its predictive values and, through a hypothetical scenario, explore the critical principle that a test's usefulness is deeply connected to the prevalence of the disease in the population, a concept with major implications for designing effective screening policies [@problem_id:4972665].", "problem": "A public health team is evaluating a single-threshold Hemoglobin A1c (HbA1c) screening test for Type 2 Diabetes Mellitus (T2DM) in an urban adult population. The test has sensitivity $0.80$ and specificity $0.90$. The point prevalence of T2DM in the target population is $0.10$. Using only the core definitions of diagnostic test performance and standard probability laws (including the law of total probability and Bayes’ theorem), derive from first principles the expressions needed to compute the positive predictive value and the negative predictive value. Then compute sensitivity, specificity, positive predictive value, and negative predictive value numerically for these parameters. Finally, explain—using your derived expressions and formal reasoning—why positive predictive value varies with prevalence and why that matters for screening policy in global health. Report your four final numerical values in the order $($sensitivity, specificity, positive predictive value, negative predictive value$)$ as decimals, and round each to four significant figures. Do not use percentage signs anywhere in your answer.", "solution": "The problem is valid as it is scientifically grounded in epidemiology and probability theory, well-posed with sufficient information, and uses realistic parameters for a public health scenario.\n\nFirst, we define the relevant events and probabilities based on the problem statement.\nLet $D$ be the event that an individual has Type 2 Diabetes Mellitus (T2DM).\nLet $\\bar{D}$ be the event that an individual does not have T2DM.\nLet $T$ be the event that the screening test result is positive.\nLet $\\bar{T}$ be the event that the screening test result is negative.\n\nThe givens can be expressed in probabilistic terms:\nThe prevalence of T2DM is the probability of having the disease, $P(D)$.\n$$P(D) = 0.10$$\nThe sensitivity of the test is the probability of a positive test result given that the individual has the disease, $P(T|D)$.\n$$P(T|D) = 0.80$$\nThe specificity of the test is the probability of a negative test result given that the individual does not have the disease, $P(\\bar{T}|\\bar{D})$.\n$$P(\\bar{T}|\\bar{D}) = 0.90$$\n\nWe can also define the probabilities of the complementary events:\nThe probability of not having the disease is $P(\\bar{D})$.\n$$P(\\bar{D}) = 1 - P(D) = 1 - 0.10 = 0.90$$\nThe probability of a false negative is $P(\\bar{T}|D)$.\n$$P(\\bar{T}|D) = 1 - P(T|D) = 1 - 0.80 = 0.20$$\nThe probability of a false positive is $P(T|\\bar{D})$.\n$$P(T|\\bar{D}) = 1 - P(\\bar{T}|\\bar{D}) = 1 - 0.90 = 0.10$$\n\nThe problem requires us to derive expressions for the positive predictive value (PPV) and negative predictive value (NPV) from first principles.\n\nThe positive predictive value, $P(D|T)$, is the probability that an individual has the disease given a positive test result. Using Bayes’ theorem:\n$$P(D|T) = \\frac{P(T|D) P(D)}{P(T)}$$\nTo find the denominator, $P(T)$, we use the law of total probability:\n$$P(T) = P(T|D)P(D) + P(T|\\bar{D})P(\\bar{D})$$\nSubstituting this into the Bayes' theorem expression for PPV gives its full form in terms of the initial parameters:\n$$P(D|T) = \\frac{P(T|D)P(D)}{P(T|D)P(D) + P(T|\\bar{D})P(\\bar{D})}$$\nSymbolically, if we let $s_e$ be sensitivity, $s_p$ be specificity, and $p$ be prevalence, the expression is:\n$$PPV = \\frac{s_e \\cdot p}{s_e \\cdot p + (1 - s_p)(1 - p)}$$\n\nThe negative predictive value, $P(\\bar{D}|\\bar{T})$, is the probability that an individual does not have the disease given a negative test result. Using Bayes’ theorem:\n$$P(\\bar{D}|\\bar{T}) = \\frac{P(\\bar{T}|\\bar{D}) P(\\bar{D})}{P(\\bar{T})}$$\nTo find the denominator, $P(\\bar{T})$, we again use the law of total probability:\n$$P(\\bar{T}) = P(\\bar{T}|D)P(D) + P(\\bar{T}|\\bar{D})P(\\bar{D})$$\nSubstituting this into the Bayes' theorem expression for NPV gives its full form:\n$$P(\\bar{D}|\\bar{T}) = \\frac{P(\\bar{T}|\\bar{D})P(\\bar{D})}{P(\\bar{T}|D)P(D) + P(\\bar{T}|\\bar{D})P(\\bar{D})}$$\nIn terms of sensitivity, specificity, and prevalence:\n$$NPV = \\frac{s_p \\cdot (1-p)}{(1 - s_e) \\cdot p + s_p (1 - p)}$$\n\nNow, we compute the numerical values.\nThe sensitivity is given as $0.80$.\nThe specificity is given as $0.90$.\n\nTo compute the positive predictive value, we first compute $P(T)$:\n$$P(T) = (0.80)(0.10) + (0.10)(0.90) = 0.08 + 0.09 = 0.17$$\nThen, the PPV is:\n$$P(D|T) = \\frac{P(T|D) P(D)}{P(T)} = \\frac{(0.80)(0.10)}{0.17} = \\frac{0.08}{0.17} \\approx 0.470588...$$\n\nTo compute the negative predictive value, we first compute $P(\\bar{T})$:\n$$P(\\bar{T}) = P(\\bar{T}|D)P(D) + P(\\bar{T}|\\bar{D})P(\\bar{D}) = (0.20)(0.10) + (0.90)(0.90) = 0.02 + 0.81 = 0.83$$\nThen, the NPV is:\n$$P(\\bar{D}|\\bar{T}) = \\frac{P(\\bar{T}|\\bar{D}) P(\\bar{D})}{P(\\bar{T})} = \\frac{(0.90)(0.90)}{0.83} = \\frac{0.81}{0.83} \\approx 0.975903...$$\n\nRounding the four values to four significant figures:\nSensitivity: $0.8000$\nSpecificity: $0.9000$\nPositive Predictive Value (PPV): $0.4706$\nNegative Predictive Value (NPV): $0.9759$\n\nFinally, we explain why PPV varies with prevalence and its importance for policy.\nThe derived expression for PPV is:\n$$PPV(p) = \\frac{s_e \\cdot p}{s_e \\cdot p + (1 - s_p)(1 - p)}$$\nwhere $p$ is the prevalence. This equation explicitly shows that PPV is a function of prevalence $p$. To formally demonstrate the dependence, we can examine the derivative of PPV with respect to $p$, holding sensitivity $s_e$ and specificity $s_p$ constant.\n$$\\frac{d(PPV)}{dp} = \\frac{d}{dp} \\left( \\frac{s_e p}{s_e p + (1-s_p)(1-p)} \\right)$$\nUsing the quotient rule, the derivative is:\n$$\\frac{d(PPV)}{dp} = \\frac{s_e [s_e p + (1-s_p)(1-p)] - s_e p [s_e - (1-s_p)(-1)]}{[s_e p + (1-s_p)(1-p)]^2}$$\n$$\\frac{d(PPV)}{dp} = \\frac{s_e [s_e p + 1 - s_p - p + s_p p] - s_e p [s_e + 1 - s_p]}{[P(T)]^2}$$\n$$\\frac{d(PPV)}{dp} = \\frac{s_e^2 p + s_e - s_e s_p - s_e p + s_e s_p p - s_e^2 p - s_e p + s_e s_p p}{[P(T)]^2}$$\nSimplifying the numerator:\n$$s_e - s_e s_p = s_e(1 - s_p)$$\nSo the derivative is:\n$$\\frac{d(PPV)}{dp} = \\frac{s_e (1-s_p)}{[s_e p + (1-s_p)(1-p)]^2}$$\nFor any useful diagnostic test, $s_e > 0$ and $s_p < 1$. Therefore, the numerator $s_e(1-s_p)$ is positive. The denominator is a squared term, so it is also positive. Thus, $\\frac{d(PPV)}{dp} > 0$, which proves that the positive predictive value is a monotonically increasing function of prevalence.\n\nThis relationship is critically important for global health screening policy. The PPV represents the probability that a person who tests positive actually has the disease.\nIn a low-prevalence population, the PPV will be low, even for a test with high sensitivity and specificity. For example, if we applied this same test to a population where the prevalence was only $0.01$ ($1\\%$), the PPV would be:\n$$PPV = \\frac{0.80 \\times 0.01}{0.80 \\times 0.01 + (1-0.90)(1-0.01)} = \\frac{0.008}{0.008 + 0.099} \\approx 0.0748$$\nIn this case, less than $8\\%$ of positive tests would be true positives. Screening such a population would generate a large number of false positives, leading to unnecessary follow-up diagnostic tests (which may be costly and invasive), patient anxiety, and a significant burden on the healthcare system. The potential harm and costs could outweigh the benefits.\nConversely, in a high-prevalence population (e.g., a targeted high-risk group where prevalence is $0.30$ or $30\\%$), the PPV increases substantially:\n$$PPV = \\frac{0.80 \\times 0.30}{0.80 \\times 0.30 + (1-0.90)(1-0.30)} = \\frac{0.24}{0.24 + 0.07} \\approx 0.774$$\nHere, over $77\\%$ of positive tests are true positives, making the screening program much more efficient and clinically valuable.\n\nTherefore, global health policy for disease screening cannot be \"one-size-fits-all.\" The decision to implement a screening program, and how to do it, must be informed by the prevalence of the disease in the specific target population. Universal screening is often not appropriate or cost-effective in low-prevalence settings, whereas targeted screening in high-risk groups is a cornerstone of effective public health strategy.", "answer": "$$\\boxed{\\begin{pmatrix} 0.8000 & 0.9000 & 0.4706 & 0.9759 \\end{pmatrix}}$$", "id": "4972665"}, {"introduction": "Moving beyond observation and diagnosis, a core task in global health is to evaluate whether our interventions are effective. This final exercise introduces you to the powerful difference-in-differences method, a cornerstone of modern causal inference used to assess the impact of policies like a sugar tax. By working through this thought experiment, you will learn how to distinguish a policy's true effect from other background trends, providing a robust way to determine if public health strategies are genuinely making a difference [@problem_id:4972737].", "problem": "A national public health institute evaluates the causal effect of a city-wide sugar-sweetened beverage excise tax on population glycated hemoglobin (HbA1c), a key biomarker of chronic hyperglycemia relevant to diabetes as a global epidemic. Investigators collect repeated cross-sectional data from a treatment city that implemented the tax and from a control city without a tax. For each city, they compute the pre–post change in the mean HbA1c. The treatment city shows a pre–post mean change of $-0.10\\%$ (an absolute reduction in percentage points), while the control city shows a pre–post mean change of $+0.02\\%$ over the same calendar interval. Assume identical measurement protocols and stable population composition across time within each city, and adopt the standard parallel trends assumption from the potential outcomes framework.\n\nStarting from the core causal inference definitions of potential outcomes and the parallel trends assumption (without invoking any unintroduced shortcut formulas), derive the appropriate difference-in-differences causal contrast for the tax effect on mean HbA1c and compute its value using the provided changes. Express the final estimate as a decimal proportion (for example, $0.001$ corresponds to $0.1\\%$) without a percentage sign, and round your final answer to $2$ significant figures.", "solution": "Let $Y_{it}$ denote the expected mean HbA1c for a city $i$ in a time period $t$.\nLet $i \\in \\{T, C\\}$, where $T$ represents the treatment city and $C$ represents the control city.\nLet $t \\in \\{0, 1\\}$, where $t=0$ is the pre-intervention period and $t=1$ is the post-intervention period.\n\nWe use the potential outcomes framework. Let $Y_{it}(1)$ be the potential outcome (mean HbA1c) for city $i$ at time $t$ if it is exposed to the treatment (the tax). Let $Y_{it}(0)$ be the potential outcome if it is not exposed to the treatment.\n\nThe treatment is applied only to city $T$ in the post-intervention period ($t=1$). The relationship between the observed outcomes ($Y_{it}$) and potential outcomes is as follows:\n-   For the treatment city at $t=1$: $Y_{T,1} = Y_{T,1}(1)$ (observed under treatment).\n-   For the treatment city at $t=0$: $Y_{T,0} = Y_{T,0}(0)$ (observed without treatment, as the pre-period is before the tax).\n-   For the control city at $t=1$: $Y_{C,1} = Y_{C,1}(0)$ (observed without treatment, as the control city never gets the tax).\n-   For the control city at $t=0$: $Y_{C,0} = Y_{C,0}(0)$ (observed without treatment).\n\nThe causal effect of interest is the Average Treatment effect on the Treated (ATT). This is the effect of the tax on the city that actually received it. For the post-intervention period, the ATT is the difference between the treatment city's outcome with the tax and what its outcome would have been without the tax.\n$$ \\text{ATT} = E[Y_{T,1}(1) - Y_{T,1}(0)] $$\nWe can observe $E[Y_{T,1}(1)]$, which is the mean HbA1c in the treatment city in the post-period, $E[Y_{T,1}]$. However, $E[Y_{T,1}(0)]$ is the counterfactual outcome—what the mean HbA1c would have been in the treatment city in the post-period if the tax had not been implemented. This quantity is fundamentally unobservable.\n\nTo estimate this unobservable counterfactual, we invoke the parallel trends assumption. This assumption states that, in the absence of treatment, the outcome in the treatment group would have followed the same trend as the outcome in the control group. Mathematically, the change in the non-treated potential outcome is the same for both groups:\n$$ E[Y_{T,1}(0) - Y_{T,0}(0)] = E[Y_{C,1}(0) - Y_{C,0}(0)] $$\nUsing the relationships between potential and observed outcomes, we can rewrite the right-hand side using observed quantities for the control group, and the second term on the left-hand side using the observed quantity for the pre-period treatment group:\n$$ E[Y_{T,1}(0)] - E[Y_{T,0}] = E[Y_{C,1}] - E[Y_{C,0}] $$\nWe can now solve for the unobserved counterfactual, $E[Y_{T,1}(0)]$:\n$$ E[Y_{T,1}(0)] = E[Y_{T,0}] + (E[Y_{C,1}] - E[Y_{C,0}]) $$\nThis expression states that the counterfactual outcome for the treatment group is its baseline outcome plus the change observed in the control group.\n\nNow, we substitute this expression for the counterfactual back into the definition of the ATT:\n$$ \\text{ATT} = E[Y_{T,1}(1)] - E[Y_{T,1}(0)] $$\n$$ \\text{ATT} = E[Y_{T,1}] - \\left( E[Y_{T,0}] + (E[Y_{C,1}] - E[Y_{C,0}]) \\right) $$\nRearranging the terms to group the changes within each city gives the difference-in-differences estimator:\n$$ \\text{ATT} = (E[Y_{T,1}] - E[Y_{T,0}]) - (E[Y_{C,1}] - E[Y_{C,0}]) $$\nThis is the causal contrast. It is the difference between the pre–post change in the treatment group and the pre–post change in the control group.\n\nThe problem provides these changes directly:\n-   Pre–post change in the treatment city: $\\Delta_T = E[Y_{T,1}] - E[Y_{T,0}] = -0.10\\%$.\n-   Pre–post change in the control city: $\\Delta_C = E[Y_{C,1}] - E[Y_{C,0}] = +0.02\\%$.\n\nSubstituting these values into the derived formula:\n$$ \\text{ATT} = \\Delta_T - \\Delta_C = (-0.10\\%) - (+0.02\\%) = -0.12\\% $$\nThe estimated causal effect of the tax is a reduction in mean HbA1c of $0.12$ percentage points.\n\nThe final step is to convert this percentage to a decimal proportion and round to $2$ significant figures.\nTo convert a percentage to a proportion, we divide by $100$:\n$$ -0.12\\% = \\frac{-0.12}{100} = -0.0012 $$\nThe number $-0.0012$ has two significant figures (the digits $1$ and $2$), so no rounding is necessary.", "answer": "$$\\boxed{-0.0012}$$", "id": "4972737"}]}