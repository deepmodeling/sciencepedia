{"hands_on_practices": [{"introduction": "Evaluating the effectiveness of a digital health intervention often requires a Randomized Controlled Trial (RCT). However, when interventions are delivered to entire groups, such as clinics or villages, the data are 'clustered', which has important statistical implications. This practice exercise guides you through the process of calculating the necessary sample size for a cluster RCT, teaching you how to account for the intracluster correlation coefficient ($\\rho$) that arises when individuals within a group are more similar to each other than to individuals in other groups [@problem_id:4973577]. Mastering this skill is essential for designing robust and adequately powered studies in global health.", "problem": "A Ministry of Health is evaluating a Mobile Health (mHealth) decision-support application for hypertension management in primary care clinics across a middle-income country. They plan a two-arm, parallel, cluster Randomized Controlled Trial (RCT) with equal numbers of clinics per arm and equal cluster size. The primary outcome is the change in systolic blood pressure measured in millimeters of mercury, modeled as a continuous variable. Within each clinic, individual outcomes are positively correlated due to shared providers and local workflow; this correlation is captured by the intracluster correlation coefficient (ICC), denoted by $\\rho$.\n\nAssume the following fundamental base:\n- Individuals within the same clinic have identical marginal variance $\\sigma^{2}$ and pairwise covariance $\\rho \\sigma^{2}$; outcomes from different clinics are independent.\n- The difference in arm means is tested using a two-sided normal approximation with significance level $\\alpha$ and power $1 - \\beta$.\n- Let $m$ denote the number of individuals per clinic and $J$ the number of clinics per arm. Let $\\delta$ be the true difference in arm means to be detected.\n\nTasks:\n1. Starting from the variance definition for sums of correlated random variables and the normal approximation for a two-sample mean difference test, derive the sample size formula for the required number of clinics per arm, $J$, as a function of $\\sigma^{2}$, $\\rho$, $m$, $\\delta$, $\\alpha$, and $\\beta$. Your derivation must explicitly show how the intracluster correlation coefficient inflates the variance via the design effect induced by clustering.\n2. Using the derived formula, compute the required number of clinics per arm for the following scientifically plausible parameters for this mHealth evaluation:\n   - Two-sided significance level $\\alpha = 0.05$ and power $1 - \\beta = 0.9$,\n   - Standard deviation $\\sigma = 12$,\n   - Intracluster correlation coefficient $\\rho = 0.02$,\n   - Equal cluster size $m = 35$,\n   - Target mean difference $\\delta = 4$.\nReport the required $J$ as the smallest integer greater than or equal to the computed value. Provide the final answer as a single number with no units in the box.", "solution": "We model the outcome for individual $i$ in clinic (cluster) $j$ in arm $a \\in \\{T, C\\}$ as $Y_{a, j i}$, with $\\mathbb{E}[Y_{a, j i}] = \\mu_{a}$ and $\\operatorname{Var}(Y_{a, j i}) = \\sigma^{2}$. For any two distinct individuals $i \\neq i'$ in the same clinic $j$, we assume $\\operatorname{Cov}(Y_{a, j i}, Y_{a, j i'}) = \\rho \\sigma^{2}$, and for individuals in different clinics, covariance is $0$. Let there be $J$ clinics per arm and $m$ individuals per clinic, so the arm-level sample size is $n = J m$ individuals per arm.\n\nDefine the arm mean as\n$$\n\\bar{Y}_{a} = \\frac{1}{J m} \\sum_{j=1}^{J} \\sum_{i=1}^{m} Y_{a, j i}.\n$$\nWe first derive $\\operatorname{Var}(\\bar{Y}_{a})$ under clustering. Using the variance of a sum,\n$$\n\\operatorname{Var}\\!\\left(\\sum_{j=1}^{J} \\sum_{i=1}^{m} Y_{a, j i}\\right)\n= \\sum_{j=1}^{J} \\left[ \\sum_{i=1}^{m} \\operatorname{Var}(Y_{a, j i}) + \\sum_{\\substack{i, i' = 1 \\\\ i \\neq i'}}^{m} \\operatorname{Cov}(Y_{a, j i}, Y_{a, j i'}) \\right].\n$$\nInside each clinic $j$, there are $m$ variance terms $\\sigma^{2}$ and $m(m-1)$ pairwise covariance terms $\\rho \\sigma^{2}$. Therefore,\n$$\n\\operatorname{Var}\\!\\left(\\sum_{j=1}^{J} \\sum_{i=1}^{m} Y_{a, j i}\\right)\n= \\sum_{j=1}^{J} \\left[ m \\sigma^{2} + m (m-1) \\rho \\sigma^{2} \\right]\n= J m \\sigma^{2} \\left[ 1 + (m-1) \\rho \\right].\n$$\nDividing by $(J m)^{2}$ gives the variance of the arm mean,\n$$\n\\operatorname{Var}(\\bar{Y}_{a}) = \\frac{\\sigma^{2} \\left[ 1 + (m-1) \\rho \\right]}{J m}.\n$$\nThe difference in arm means $\\bar{Y}_{T} - \\bar{Y}_{C}$ has variance\n$$\n\\operatorname{Var}(\\bar{Y}_{T} - \\bar{Y}_{C})\n= \\operatorname{Var}(\\bar{Y}_{T}) + \\operatorname{Var}(\\bar{Y}_{C})\n= \\frac{2 \\sigma^{2} \\left[ 1 + (m-1) \\rho \\right]}{J m},\n$$\nusing independence between arms.\n\nFor a two-sided test at significance level $\\alpha$ with power $1 - \\beta$, the normal approximation requires the detectable difference $\\delta$ to satisfy\n$$\n\\delta = \\left( z_{1 - \\alpha/2} + z_{1 - \\beta} \\right) \\sqrt{ \\operatorname{Var}(\\bar{Y}_{T} - \\bar{Y}_{C}) },\n$$\nwhere $z_{p}$ is the $p$th quantile of the standard normal distribution. Substituting the variance,\n$$\n\\delta = \\left( z_{1 - \\alpha/2} + z_{1 - \\beta} \\right) \\sqrt{ \\frac{2 \\sigma^{2} \\left[ 1 + (m-1) \\rho \\right]}{J m} }.\n$$\nSolving for $J$,\n$$\nJ = \\frac{2 \\sigma^{2} \\left[ 1 + (m-1) \\rho \\right] \\left( z_{1 - \\alpha/2} + z_{1 - \\beta} \\right)^{2} }{ m \\, \\delta^{2} }.\n$$\nThis expression reveals the classical design effect\n$$\n\\text{Design effect} = 1 + (m-1) \\rho,\n$$\nmultiplying the variance relative to individual randomization. Equivalently, one may write $J = \\left( \\text{DE} \\times n_{\\text{indiv, per arm}} \\right) / m$, where $n_{\\text{indiv, per arm}} = \\frac{2 \\sigma^{2} \\left( z_{1 - \\alpha/2} + z_{1 - \\beta} \\right)^{2}}{\\delta^{2}}$ is the per-arm sample size under individual randomization, and $\\text{DE} = 1 + (m-1)\\rho$.\n\nWe now compute $J$ for the given parameters. With $\\alpha = 0.05$ (two-sided) and $1 - \\beta = 0.9$, we have $z_{1 - \\alpha/2} = z_{0.975} \\approx 1.96$ and $z_{1 - \\beta} = z_{0.9} \\approx 1.2816$. Let $\\sigma = 12$ so $\\sigma^{2} = 144$, $\\rho = 0.02$, $m = 35$, and $\\delta = 4$ so $\\delta^{2} = 16$.\n\nCompute the design effect:\n$$\n\\text{DE} = 1 + (m-1)\\rho = 1 + 34 \\times 0.02 = 1 + 0.68 = 1.68.\n$$\nCompute the quantile sum and its square:\n$$\nz_{1 - \\alpha/2} + z_{1 - \\beta} \\approx 1.96 + 1.2816 = 3.2416, \\quad (3.2416)^{2} \\approx 10.50797056.\n$$\nSubstitute into the formula:\n$$\nJ = \\frac{2 \\cdot 144 \\cdot 1.68 \\cdot 10.50797056}{35 \\cdot 16}.\n$$\nFirst, compute the numerator factor without $m$ and $\\delta^{2}$:\n$$\n2 \\cdot 144 \\cdot 10.50797056 = 288 \\cdot 10.50797056 \\approx 3026.293533,\n$$\nthen multiply by $\\text{DE} = 1.68$:\n$$\n3026.293533 \\times 1.68 \\approx 5084.179138.\n$$\nDivide by $m \\delta^{2} = 35 \\cdot 16 = 560$:\n$$\nJ \\approx \\frac{5084.179138}{560} \\approx 9.079.\n$$\nThe required number of clinics per arm is the smallest integer greater than or equal to $9.079$, which is $10$.", "answer": "$$\\boxed{10}$$", "id": "4973577"}, {"introduction": "The power of digital health is often realized by linking data from multiple sources, such as an mHealth app and a national health registry. However, this linkage process is rarely perfect, introducing errors that can systematically bias your results. This exercise will demonstrate how to formalize the impact of linkage sensitivity ($s$) and false-match rates ($f$) on a key epidemiological measure—disease prevalence—and derive a method to correct for this bias [@problem_id:4973560]. This practice is fundamental for any analyst working with real-world linked data, ensuring the integrity of your findings.", "problem": "A mobile health (mHealth) program for hypertension monitoring in a low- and middle-income country is integrating app-collected data with a national Chronic Disease Registry (CDR) to obtain validated hypertension diagnoses. The program links app users to the CDR using deterministic rules, and the analyst uses the linked registry diagnosis as the observed disease status. If no registry link is found for an app user, the analyst imputes the disease status as not hypertensive. In a validation substudy, the linkage performance was characterized as follows: among app users who truly have a registry-confirmed hypertension diagnosis, the probability that the linkage returns the correct match is $s$, and among app users who truly do not have a registry-confirmed hypertension diagnosis, the probability that the linkage erroneously assigns a hypertensive status via a false match is $f$. Assume that when a false match occurs for a truly non-hypertensive user, the assigned status is hypertensive with probability $f$; otherwise, the user remains labeled not hypertensive. Let the true hypertension prevalence among app users be $p = \\mathbb{P}(D=1)$, where $D \\in \\{0,1\\}$ denotes the true registry-confirmed hypertension status, and let the observed status after linkage and imputation be $Y \\in \\{0,1\\}$.\n\nIn the full analytic dataset of $N = 50{,}000$ app users, the analyst observes $3{,}600$ users labeled hypertensive after linkage and imputation, so the observed prevalence is $p_{\\text{obs}} = 3{,}600/50{,}000$. The validation substudy estimates $s = 0.85$ and $f = 0.01$ for the linkage algorithm when applied to this population.\n\nUsing only core probability definitions (such as the law of total probability) and the definitions of sensitivity $s$ and false match rate $f$ given above, perform the following:\n\n1. Formalize how linkage errors propagate into the observed prevalence by expressing $\\mathbb{P}(Y=1)$ in terms of $p$, $s$, and $f$.\n2. Derive an analytic bias-correction expression for the true prevalence $p$ in terms of the observed prevalence $p_{\\text{obs}}$, the linkage sensitivity $s$, and the false match rate $f$.\n3. Compute the bias-corrected prevalence using the provided numerical values $p_{\\text{obs}} = 3{,}600/50{,}000$, $s = 0.85$, and $f = 0.01$.\n\nExpress the final corrected prevalence as a decimal proportion and round your answer to four significant figures.", "solution": "The solution is presented in three parts as requested by the problem statement.\n\n**Part 1: Formalize the relationship between observed and true prevalence**\n\nWe want to express the observed prevalence, $\\mathbb{P}(Y=1)$, as a function of the true prevalence, $p$, and the linkage error parameters, $s$ and $f$. We use the law of total probability, conditioning on the true disease status $D$.\n\nThe universe of app users is partitioned into two disjoint sets: those who are truly hypertensive ($D=1$) and those who are not ($D=0$). The probabilities of these states are:\n$$\n\\mathbb{P}(D=1) = p\n$$\n$$\n\\mathbb{P}(D=0) = 1 - p\n$$\n\nThe probability of being observed as hypertensive, $\\mathbb{P}(Y=1)$, can be written as:\n$$\n\\mathbb{P}(Y=1) = \\mathbb{P}(Y=1 | D=1)\\mathbb{P}(D=1) + \\mathbb{P}(Y=1 | D=0)\\mathbb{P}(D=0)\n$$\n\nFrom the problem statement, we can establish the conditional probabilities for being observed as hypertensive:\n-   The probability of being observed as hypertensive given true hypertensive status is the sensitivity of the linkage/imputation process, which is given as $s$. If a true positive user is not linked correctly, they are imputed as negative.\n    $$\n    \\mathbb{P}(Y=1 | D=1) = s\n    $$\n-   The probability of being observed as hypertensive given true non-hypertensive status is the false-positive rate from erroneous linkage, which is given as $f$.\n    $$\n    \\mathbb{P}(Y=1 | D=0) = f\n    $$\n\nSubstituting these terms into the law of total probability equation yields the expression for the observed prevalence, which we denote $p_{\\text{obs}}$:\n$$\np_{\\text{obs}} = \\mathbb{P}(Y=1) = s \\cdot p + f \\cdot (1-p)\n$$\nThis formula shows how linkage errors (represented by $s$ and $f$) systematically bias the observed prevalence.\n\n**Part 2: Derive the bias-correction expression for true prevalence $p$**\n\nWe now rearrange the expression derived in Part 1 to solve for the true prevalence $p$ in terms of the observed prevalence $p_{\\text{obs}}$ and the parameters $s$ and $f$.\n\nStarting with the equation:\n$$\np_{\\text{obs}} = sp + f(1-p)\n$$\nWe distribute the term $f$:\n$$\np_{\\text{obs}} = sp + f - fp\n$$\nNext, we isolate the terms containing $p$:\n$$\np_{\\text{obs}} - f = sp - fp\n$$\nFactor out $p$ from the right-hand side:\n$$\np_{\\text{obs}} - f = p(s - f)\n$$\nAssuming $s \\neq f$, which is true for the given values ($s=0.85$ and $f=0.01$) and is a necessary condition for the classification to be informative, we can divide by $(s-f)$ to solve for $p$:\n$$\np = \\frac{p_{\\text{obs}} - f}{s - f}\n$$\nThis is the analytic bias-correction expression for the true prevalence $p$.\n\n**Part 3: Compute the bias-corrected prevalence**\n\nFirst, we calculate the numerical value of the observed prevalence $p_{\\text{obs}}$ from the given data:\n$$\np_{\\text{obs}} = \\frac{3,600}{50,000} = \\frac{36}{500} = \\frac{72}{1,000} = 0.072\n$$\nThe other given values are $s=0.85$ and $f=0.01$.\n\nNow, we substitute these numerical values into the bias-correction formula derived in Part 2:\n$$\np = \\frac{0.072 - 0.01}{0.85 - 0.01}\n$$\nPerforming the subtraction in the numerator and denominator:\n$$\np = \\frac{0.062}{0.84}\n$$\nNow we perform the division:\n$$\np = \\frac{62}{840} = \\frac{31}{420} \\approx 0.0738095238...\n$$\nThe problem requires the final answer to be rounded to four significant figures. The first significant figure is $7$. The first four significant figures are $7$, $3$, $8$, and $0$. The fifth significant figure is $9$. Since $9 \\geq 5$, we round up the fourth significant figure ($0$) to $1$.\n\nTherefore, the computed bias-corrected prevalence, rounded to four significant figures, is $0.07381$.", "answer": "$$\\boxed{0.07381}$$", "id": "4973560"}, {"introduction": "A predictive model that outputs a risk score is only useful if it can guide clinical decisions effectively. The choice of a threshold—above which an action is recommended—is a critical step that must balance the benefits of correct identification against the harms of false alarms. This problem introduces you to decision-analytic principles, showing how to derive an optimal risk threshold that maximizes the 'net benefit' for a given clinical preference [@problem_id:4973582]. By connecting Bayes decision theory to the practicalities of a deployed mHealth system, this exercise provides a framework for making data-driven predictions actionable.", "problem": "A Mobile Health (mHealth) application deploys a binary risk model on smartphones to triage patients for an acute event within a $7$-day window based on wearable sensor data. The model outputs a calibrated log-odds score $z \\in \\mathbb{R}$ for the event, where larger $z$ indicates higher risk. The population event prevalence is $\\pi$, and the developer faces class imbalance because the event is rare.\n\nTo address imbalance during model development, the team considers a weighted empirical risk with class weights. At deployment, a clinical stakeholder specifies a decision-analytic preference through a decision curve: acting on a positive prediction yields net benefit that trades off false positives against true positives according to a threshold probability $p_{t}$, with net benefit defined as\n$$\n\\mathrm{NB}(p_{t}; \\text{policy}) \\equiv \\frac{\\mathrm{TP}}{N} - \\frac{p_{t}}{1-p_{t}} \\cdot \\frac{\\mathrm{FP}}{N},\n$$\nwhere $N$ is the cohort size, $\\mathrm{TP}$ is the number of true positives, and $\\mathrm{FP}$ is the number of false positives. Assume perfect probability calibration of the model scores and that the decision maker fixes $p_{t}$ in advance.\n\nAssume that, conditional on the true class $Y \\in \\{0,1\\}$, the deployed score $z$ follows a Gaussian distribution with equal variance,\n$$\nz \\mid (Y=1) \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2}) \\quad \\text{and} \\quad z \\mid (Y=0) \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2}),\n$$\nwith $\\mu_{1} > \\mu_{0}$. Let the triage policy be a deterministic threshold on $z$: predict positive if and only if $z \\ge z_{\\ast}$.\n\nTasks:\n1. Starting from the definitions of expected loss and Bayes decision theory, formalize class imbalance handling via weighted misclassification costs and show that maximizing $\\mathrm{NB}(p_{t}; z_{\\ast})$ over thresholds $z_{\\ast}$ is equivalent to minimizing an expected cost with false negative cost equal to $1$ and false positive cost equal to $w \\equiv \\frac{p_{t}}{1-p_{t}}$. Derive, from first principles, the optimal likelihood-ratio threshold and express the corresponding optimal threshold on $z$ in terms of $\\mu_{0}$, $\\mu_{1}$, \\sigma^{2}, \\pi$, and $p_{t}$.\n2. For a deployment in which the population prevalence is $\\pi = 0.04$, the stakeholder sets $p_{t} = 0.1$, and the score distributions are parameterized by $\\mu_{1} = 1.2$, $\\mu_{0} = -0.3$, and $\\sigma = 0.9$, compute the optimal score threshold $z_{\\ast}$ that maximizes net benefit at the specified decision preference.\n\nRound your final numerical answer for $z_{\\ast}$ to four significant figures. No units are required.", "solution": "### Part 1: Derivation of the Optimal Threshold\n\nThe first task is to formalize the equivalence between maximizing the Net Benefit, $\\mathrm{NB}(p_{t})$, and minimizing a weighted expected misclassification cost, and then to derive the optimal decision threshold $z_{\\ast}$.\n\nLet $Y \\in \\{0, 1\\}$ be the true class label, where $Y=1$ denotes the occurrence of the event and $Y=0$ denotes its absence. The population prevalence of the event is $P(Y=1) = \\pi$. The decision policy is to predict an event if the score $z$ exceeds a threshold $z_{\\ast}$.\n\nThe Net Benefit is defined as:\n$$\n\\mathrm{NB}(p_{t}; z_{\\ast}) \\equiv \\frac{\\mathrm{TP}(z_{\\ast})}{N} - \\frac{p_{t}}{1-p_{t}} \\cdot \\frac{\\mathrm{FP}(z_{\\ast})}{N}\n$$\nwhere $N$ is the total number of individuals, $\\mathrm{TP}(z_{\\ast})$ is the number of true positives, and $\\mathrm{FP}(z_{\\ast})$ is the number of false positives for a given threshold $z_{\\ast}$.\n\nWe can express $\\mathrm{TP}(z_{\\ast})$ and $\\mathrm{FP}(z_{\\ast})$ in terms of the true positive rate ($\\mathrm{TPR}$) and false positive rate ($\\mathrm{FPR}$):\n$\\mathrm{TP}(z_{\\ast}) = N \\cdot \\pi \\cdot \\mathrm{TPR}(z_{\\ast})$, where $\\mathrm{TPR}(z_{\\ast}) = P(z \\ge z_{\\ast} \\mid Y=1)$.\n$\\mathrm{FP}(z_{\\ast}) = N \\cdot (1-\\pi) \\cdot \\mathrm{FPR}(z_{\\ast})$, where $\\mathrm{FPR}(z_{\\ast}) = P(z \\ge z_{\\ast} \\mid Y=0)$.\n\nSubstituting these into the $\\mathrm{NB}$ equation gives:\n$$\n\\mathrm{NB}(p_{t}; z_{\\ast}) = \\frac{N \\pi \\mathrm{TPR}(z_{\\ast})}{N} - \\frac{p_{t}}{1-p_{t}} \\frac{N (1-\\pi) \\mathrm{FPR}(z_{\\ast})}{N} = \\pi \\mathrm{TPR}(z_{\\ast}) - \\frac{p_{t}}{1-p_{t}} (1-\\pi) \\mathrm{FPR}(z_{\\ast})\n$$\n\nNow, consider the expected cost (or risk) of misclassification for a decision rule. Let $C_{FN}$ be the cost of a false negative (predicting $0$ when $Y=1$) and $C_{FP}$ be the cost of a false positive (predicting $1$ when $Y=0$). The costs of true positives and true negatives are assumed to be $0$. The expected cost, $E[\\text{Cost}]$, is:\n$$\nE[\\text{Cost}(z_{\\ast})] = C_{FP} P(\\text{predict } 1, Y=0) + C_{FN} P(\\text{predict } 0, Y=1)\n$$\nUsing conditional probabilities:\n$$\nE[\\text{Cost}(z_{\\ast})] = C_{FP} P(z \\ge z_{\\ast} \\mid Y=0) P(Y=0) + C_{FN} P(z < z_{\\ast} \\mid Y=1) P(Y=1)\n$$\nLet FNR be the false negative rate, $\\mathrm{FNR}(z_{\\ast}) = P(z < z_{\\ast} \\mid Y=1) = 1 - \\mathrm{TPR}(z_{\\ast})$.\nThe expected cost is:\n$$\nE[\\text{Cost}(z_{\\ast})] = C_{FP} (1-\\pi) \\mathrm{FPR}(z_{\\ast}) + C_{FN} \\pi \\mathrm{FNR}(z_{\\ast})\n$$\n$$\nE[\\text{Cost}(z_{\\ast})] = C_{FP} (1-\\pi) \\mathrm{FPR}(z_{\\ast}) + C_{FN} \\pi (1 - \\mathrm{TPR}(z_{\\ast}))\n$$\nThe problem asks to show equivalence with $C_{FN}=1$ and $C_{FP} = w \\equiv \\frac{p_{t}}{1-p_{t}}$. Substituting these costs:\n$$\nE[\\text{Cost}(z_{\\ast})] = \\frac{p_{t}}{1-p_{t}} (1-\\pi) \\mathrm{FPR}(z_{\\ast}) + 1 \\cdot \\pi (1 - \\mathrm{TPR}(z_{\\ast}))\n$$\n$$\nE[\\text{Cost}(z_{\\ast})] = \\pi - \\left( \\pi \\mathrm{TPR}(z_{\\ast}) - \\frac{p_{t}}{1-p_{t}} (1-\\pi) \\mathrm{FPR}(z_{\\ast}) \\right)\n$$\n$$\nE[\\text{Cost}(z_{\\ast})] = \\pi - \\mathrm{NB}(p_{t}; z_{\\ast})\n$$\nSince $\\pi$ is a constant with respect to the choice of threshold $z_{\\ast}$, minimizing the expected cost $E[\\text{Cost}(z_{\\ast})]$ is equivalent to maximizing the Net Benefit $\\mathrm{NB}(p_{t}; z_{\\ast})$. This establishes the required equivalence.\n\nNext, we derive the optimal threshold $z_{\\ast}$ from first principles. According to Bayes decision theory, the optimal rule is to choose the class that minimizes the posterior expected cost. For any given score $z$, we predict class $1$ if the expected cost of doing so is less than the expected cost of predicting class $0$.\n\n$\\text{Cost}(\\text{predict } 1 \\mid z) = 0 \\cdot P(Y=1 \\mid z) + C_{FP} \\cdot P(Y=0 \\mid z) = C_{FP} P(Y=0 \\mid z)$\n$\\text{Cost}(\\text{predict } 0 \\mid z) = C_{FN} \\cdot P(Y=1 \\mid z) + 0 \\cdot P(Y=0 \\mid z) = C_{FN} P(Y=1 \\mid z)$\n\nPredict class $1$ if $\\text{Cost}(\\text{predict } 1 \\mid z) < \\text{Cost}(\\text{predict } 0 \\mid z)$:\n$$\nC_{FP} P(Y=0 \\mid z) < C_{FN} P(Y=1 \\mid z)\n$$\nUsing Bayes' rule, $P(Y=k \\mid z) = \\frac{p(z \\mid Y=k) P(Y=k)}{p(z)}$, this becomes:\n$$\nC_{FP} p(z \\mid Y=0) (1-\\pi) < C_{FN} p(z \\mid Y=1) \\pi\n$$\nRearranging gives the likelihood-ratio test: predict class $1$ if\n$$\n\\frac{p(z \\mid Y=1)}{p(z \\mid Y=0)} > \\frac{C_{FP} (1-\\pi)}{C_{FN} \\pi}\n$$\nThe optimal threshold $z_{\\ast}$ is found where equality holds. Substituting $C_{FN}=1$ and $C_{FP} = \\frac{p_{t}}{1-p_{t}}$:\n$$\n\\frac{p(z_{\\ast} \\mid Y=1)}{p(z_{\\ast} \\mid Y=0)} = \\frac{\\frac{p_{t}}{1-p_{t}} (1-\\pi)}{1 \\cdot \\pi} = \\frac{p_t}{1-p_t} \\frac{1-\\pi}{\\pi}\n$$\nThe problem states that the class-conditional distributions of the score $z$ are Gaussian with equal variance:\n$p(z \\mid Y=1) = \\mathcal{N}(\\mu_1, \\sigma^2)$ and $p(z \\mid Y=0) = \\mathcal{N}(\\mu_0, \\sigma^2)$. The likelihood ratio is:\n$$\n\\frac{p(z \\mid Y=1)}{p(z \\mid Y=0)} = \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(z-\\mu_1)^2}{2\\sigma^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(z-\\mu_0)^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{(z-\\mu_0)^2 - (z-\\mu_1)^2}{2\\sigma^2}\\right)\n$$\nThe exponent simplifies to:\n$(z^2 - 2z\\mu_0 + \\mu_0^2) - (z^2 - 2z\\mu_1 + \\mu_1^2) = 2z(\\mu_1 - \\mu_0) - (\\mu_1^2 - \\mu_0^2) = (\\mu_1 - \\mu_0)(2z - (\\mu_1 + \\mu_0))$.\nTaking the natural logarithm of the threshold equation:\n$$\n\\ln\\left( \\frac{p(z_{\\ast} \\mid Y=1)}{p(z_{\\ast} \\mid Y=0)} \\right) = \\frac{(\\mu_1 - \\mu_0)(2z_{\\ast} - (\\mu_1 + \\mu_0))}{2\\sigma^2} = \\ln\\left(\\frac{p_t}{1-p_t} \\frac{1-\\pi}{\\pi}\\right)\n$$\nWe solve for $z_{\\ast}$:\n$$\n2z_{\\ast} - (\\mu_1 + \\mu_0) = \\frac{2\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{p_t(1-\\pi)}{\\pi(1-p_t)}\\right)\n$$\n$$\n2z_{\\ast} = (\\mu_1 + \\mu_0) + \\frac{2\\sigma^2}{\\mu_1 - \\mu_0} \\left[ \\ln\\left(\\frac{p_t}{1-p_t}\\right) - \\ln\\left(\\frac{\\pi}{1-\\pi}\\right) \\right]\n$$\n$$\nz_{\\ast} = \\frac{\\mu_0 + \\mu_1}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\left[ \\ln\\left(\\frac{p_t}{1-p_t}\\right) - \\ln\\left(\\frac{\\pi}{1-\\pi}\\right) \\right]\n$$\nThis is the optimal threshold on the score $z$ in terms of the given parameters.\n\n### Part 2: Numerical Calculation\n\nThe second task is to compute the value of $z_{\\ast}$ given the specific parameters: $\\pi = 0.04$, $p_t = 0.1$, $\\mu_1 = 1.2$, $\\mu_0 = -0.3$, and $\\sigma = 0.9$.\n\nFirst, we calculate the components of the formula for $z_{\\ast}$:\n$\\mu_0 + \\mu_1 = -0.3 + 1.2 = 0.9$\n$\\mu_1 - \\mu_0 = 1.2 - (-0.3) = 1.5$\n$\\sigma^2 = (0.9)^2 = 0.81$\nThe midpoint term is $\\frac{\\mu_0 + \\mu_1}{2} = \\frac{0.9}{2} = 0.45$.\n\nNext, we calculate the logarithmic terms:\nThe odds for the decision threshold $p_t$ is $\\frac{p_t}{1-p_t} = \\frac{0.1}{1-0.1} = \\frac{0.1}{0.9} = \\frac{1}{9}$.\nThe odds for the prevalence $\\pi$ is $\\frac{\\pi}{1-\\pi} = \\frac{0.04}{1-0.04} = \\frac{0.04}{0.96} = \\frac{4}{96} = \\frac{1}{24}$.\n\nThe difference of the log-odds is:\n$$\n\\ln\\left(\\frac{p_t}{1-p_t}\\right) - \\ln\\left(\\frac{\\pi}{1-\\pi}\\right) = \\ln\\left(\\frac{1}{9}\\right) - \\ln\\left(\\frac{1}{24}\\right) = \\ln\\left(\\frac{1/9}{1/24}\\right) = \\ln\\left(\\frac{24}{9}\\right) = \\ln\\left(\\frac{8}{3}\\right)\n$$\n\nNow, we compute the adjustment term:\n$$\n\\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{8}{3}\\right) = \\frac{0.81}{1.5} \\ln\\left(\\frac{8}{3}\\right) = 0.54 \\ln\\left(\\frac{8}{3}\\right)\n$$\nUsing the value $\\ln(8/3) \\approx 0.98082925$:\n$$\n0.54 \\times 0.98082925 \\approx 0.529647795\n$$\n\nFinally, we combine the terms to find $z_{\\ast}$:\n$$\nz_{\\ast} = 0.45 + 0.529647795 = 0.979647795\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nz_{\\ast} \\approx 0.9796\n$$", "answer": "$$\\boxed{0.9796}$$", "id": "4973582"}]}