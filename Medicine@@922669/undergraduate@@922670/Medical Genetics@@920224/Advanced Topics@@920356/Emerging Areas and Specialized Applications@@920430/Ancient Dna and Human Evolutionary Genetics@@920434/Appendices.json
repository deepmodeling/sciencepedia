{"hands_on_practices": [{"introduction": "Working with ancient DNA (aDNA) is as much a forensic science as it is a genetic one. The single greatest challenge is contamination from modern DNA, which is far more abundant and intact than the fragmented, damaged molecules from ancient specimens. This first exercise presents a classic scenario to build your intuition for diagnosing contamination, asking you to identify the most plausible explanation for an unexpected genetic signal in a Neanderthal sample [@problem_id:1468888].", "problem": "A paleo-genetics team is analyzing a 50,000-year-old Neanderthal molar found in a Siberian cave. Their goal is to sequence the mitochondrial DNA (mtDNA), a small circular genome inherited maternally that is present in high copy numbers in cells, making it suitable for ancient DNA (aDNA) studies. The team extracts DNA from the tooth powder in an ultra-clean facility. They then use Polymerase Chain Reaction (PCR) to amplify a specific hypervariable region of the mtDNA, which is commonly used for identifying maternal lineages, or haplotypes.\n\nAfter sequencing the amplified DNA fragments, the analysis reveals two distinct and abundant haplotypes. Haplotype N is novel but shares a high degree of similarity with other published Neanderthal mtDNA sequences. Haplotype M, however, is a perfect match to the mtDNA haplotype of the lead researcher who performed the DNA extraction. Given this information, which of the following is the most scientifically sound explanation for the presence of Haplotype M in the sample?\n\nA. The Neanderthal individual was heteroplasmic, meaning they naturally possessed two distinct mtDNA lineages, one of which coincidentally matches a modern human.\n\nB. This finding provides definitive evidence for direct interbreeding between the maternal ancestor of this specific Neanderthal and an anatomically modern human.\n\nC. The sequence for Haplotype M is the result of random mutations introduced during the PCR amplification process that by chance accumulated to match the researcher's sequence.\n\nD. Both the Neanderthal and the modern researcher's maternal lineages underwent convergent evolution, independently arriving at an identical mtDNA sequence.\n\nE. The sample was contaminated with modern DNA from the lead researcher during sample handling or laboratory processing.", "solution": "We start by identifying the biological and methodological principles relevant to ancient DNA (aDNA) studies:\n- Mitochondrial DNA (mtDNA) is maternally inherited and typically exists as a single haplotype per individual, except in rare cases of heteroplasmy, where two closely related mtDNA variants may co-occur within an individual. Heteroplasmy usually involves a small number of variant sites rather than two fully distinct haplotypes.\n- aDNA is highly fragmented and chemically damaged (e.g., cytosine deamination), and such damage can reduce amplification efficiency.\n- PCR exponentially amplifies whatever template is present; even trace amounts of modern contaminant DNA, which is intact and undamaged, can outcompete authentic aDNA during amplification.\n- Contamination with modern human DNA is a pervasive risk in aDNA workflows and is often diagnosed by the occurrence of sequences that closely or exactly match the mtDNA of laboratory personnel.\n\nWe analyze the observations:\n- The sample yields two distinct and abundant mtDNA haplotypes: N (novel but Neanderthal-like) and M (a perfect match to the lead researcher).\n- The presence of a perfect match to a particular modern individual’s mtDNA, specifically the handler, is a hallmark of contamination.\n\nWe evaluate each option against established principles and the observations:\n- Option A (heteroplasmy): While heteroplasmy exists, it typically manifests as closely related variants, not two entirely distinct haplotypes where one is a perfect match to the modern handler. The probability that a Neanderthal’s secondary heteroplasmic haplotype exactly matches a specific modern human’s mtDNA across a hypervariable region is negligibly small. This is inconsistent with the observed perfect match to the researcher.\n- Option B (interbreeding): mtDNA is strictly maternally inherited; for a Neanderthal to carry modern human mtDNA, the maternal ancestor would have to be modern human. Even if such gene flow occurred, the chance that the mtDNA sequence would be an exact match to the contemporary researcher’s haplotype (rather than a related modern haplotype) is extremely small. Moreover, calling this “definitive evidence” is scientifically unjustified given the parsimonious explanation of contamination and the ubiquity of contamination in aDNA studies.\n- Option C (PCR errors): Random PCR misincorporation errors occur at low rates and would produce scattered mismatches, not a coherent haplotype that perfectly matches the researcher’s sequence. The probability that accumulated random errors transform a Neanderthal-like haplotype into an exact modern match across the amplified region is vanishingly small.\n- Option D (convergent evolution): Independent evolution leading to an identical mtDNA sequence over a hypervariable region is extraordinarily unlikely, especially to match the exact sequence of the handling researcher. Convergent evolution cannot plausibly account for a perfect haplotype identity at this resolution.\n- Option E (contamination): Modern human contamination, especially from personnel involved in extraction and PCR setup, is a well-known and frequent issue in aDNA research. The perfect identity of Haplotype M to the lead researcher’s mtDNA is direct, specific evidence pointing to contamination during handling or processing. The coexistence of a Neanderthal-like haplotype (N) and a modern human haplotype (M) in the same amplification is exactly what contamination would produce.\n\nBy parsimony and standard aDNA quality control logic, Option E is the most scientifically sound explanation.", "answer": "$$\\boxed{E}$$", "id": "1468888"}, {"introduction": "Once we are alert to the risk of contamination, the next step is to learn how to quantify it and disentangle it from the true endogenous signal. Real-world aDNA analysis requires integrating multiple, sometimes conflicting, lines of evidence. This practice challenges you to think like a paleogeneticist, using quantitative data on post-mortem damage (PMD) alongside independent estimates from nuclear DNA to resolve a complex case of mixed mitochondrial signals and make a final call on the sample's utility [@problem_id:5011615].", "problem": "An Upper Paleolithic skeletal sample is sequenced using standard ancient DNA protocols. Mitochondrial DNA (mtDNA; mitochondrial deoxyribonucleic acid) is covered at approximately $100\\times$ mean depth, and nuclear DNA is covered at approximately $0.8\\times$. Post-Mortem Damage (PMD) is assessed via the fraction of terminal cytosine-to-thymine misincorporations. It is known from many studies that typical PMD fractions in genuinely ancient molecules are substantially elevated relative to modern contamination; for this sample you may treat the characteristic damage probabilities as approximately $\\delta_{\\text{ancient}} \\approx 0.20$ and $\\delta_{\\text{modern}} \\approx 0.01$ for terminal positions.\n\nHaplogroup-defining mtDNA positions are interrogated. Reads supporting alleles diagnostic of haplogroup U total $N_U = 1700$ with $k_U = 425$ showing terminal PMD, while reads supporting alleles diagnostic of haplogroup H total $N_H = 1000$ with $k_H = 10$ showing terminal PMD. The mtDNA consensus constructed without damage filtering calls haplogroup H because more total reads at diagnostic positions support H-compatible substitutions across the full set of positions.\n\nIndependent nuclear contamination is estimated in the following way. Genetic sex determination indicates the individual is male ($XY$), and the nuclear contamination estimate derived from X chromosome apparent heterozygosity yields $\\hat{c}_{\\text{nuc}} = 0.03$ with a $95\\%$ confidence interval $[0.01, 0.05]$. You may assume the contaminant molecules are predominantly modern and lack elevated PMD relative to endogenous ancient molecules.\n\nStarting only from these fundamentals:\n- mtDNA is clonally maternally inherited and a single individual should carry one mtDNA haplogroup; discordant haplogroup signals across defining sites imply mixture.\n- Ancient molecules exhibit elevated PMD relative to modern contamination.\n- In a male individual, heterozygosity on the X chromosome arises primarily from contamination because the endogenous X is hemizygous.\n- Contamination acts as mixture: observed allele frequencies reflect $(1 - c) \\times$ endogenous contributions plus $c \\times$ contaminant contributions.\n\nUse first-principles reasoning to reconcile the discordant mtDNA haplogroup signals and decide whether the sample should be excluded from downstream population genetic analyses. Choose the single best option.\n\nA. Accept the damage-unfiltered mtDNA consensus as haplogroup H and include the sample in all downstream analyses, because the nuclear contamination estimate $\\hat{c}_{\\text{nuc}}$ is below $0.05$.\n\nB. Infer that haplogroup U represents the endogenous mtDNA based on damage patterns, treat haplogroup H reads as modern contamination, and retain the individual for nuclear DNA analyses (preferably using PMD-filtered reads). Exclude or re-call the mtDNA haplogroup using only damage-enriched molecules before reporting.\n\nC. Exclude the sample entirely from all analyses because the mtDNA shows evidence of contamination that invalidates both mtDNA and nuclear DNA signals.\n\nD. Interpret the discordance between haplogroups U and H as within-individual heteroplasmy and include both mtDNA haplogroups and all nuclear data in downstream analyses without special filtering.", "solution": "The central issue is the presence of reads supporting two distinct mitochondrial DNA (mtDNA) haplogroups, U and H. According to the first principle provided, a single individual should possess only one mtDNA haplogroup. The observation of two haplogroups is therefore strong evidence of a mixture of DNA from at least two different individuals. The problem requires us to determine the source of this mixture—specifically, which signal is endogenous to the ancient sample and which is from contamination.\n\nThe second principle states that ancient molecules exhibit elevated PMD relative to modern contamination. We are given characteristic probabilities for terminal cytosine-to-thymine misincorporations: $\\delta_{\\text{ancient}} \\approx 0.20$ for ancient DNA and $\\delta_{\\text{modern}} \\approx 0.01$ for modern DNA. We can calculate the empirical PMD fraction for the reads supporting each haplogroup.\n\nFor the reads supporting haplogroup U alleles:\n- Total reads: $N_U = 1700$.\n- Reads with terminal PMD: $k_U = 425$.\n- The empirical PMD fraction is $\\hat{\\delta}_U = \\frac{k_U}{N_U} = \\frac{425}{1700} = 0.25$.\n\nFor the reads supporting haplogroup H alleles:\n- Total reads: $N_H = 1000$.\n- Reads with terminal PMD: $k_H = 10$.\n- The empirical PMD fraction is $\\hat{\\delta}_H = \\frac{k_H}{N_H} = \\frac{10}{1000} = 0.01$.\n\nWe now compare these empirical fractions to the characteristic probabilities:\n- The PMD fraction for U-supporting reads, $\\hat{\\delta}_U = 0.25$, is highly consistent with the expected value for ancient DNA, $\\delta_{\\text{ancient}} \\approx 0.20$.\n- The PMD fraction for H-supporting reads, $\\hat{\\delta}_H = 0.01$, is identical to the expected value for modern DNA, $\\delta_{\\text{modern}} = 0.01$.\n\nThis analysis provides overwhelming evidence that the haplogroup U signal originates from the endogenous, ancient individual, while the haplogroup H signal originates from modern contamination. The damage-unfiltered mtDNA consensus call of haplogroup H is therefore an artifact of this contamination and is incorrect.\n\nNext, we consider the nuclear DNA. The problem provides an independent estimate of nuclear contamination, $\\hat{c}_{\\text{nuc}} = 0.03$ (or $3\\%$), derived from apparent heterozygosity on the X chromosome of this male individual. This is a standard and robust method. A contamination level of $3\\%$ is considered low and is often acceptable for downstream population genetic analyses, especially for rare and valuable samples from the Upper Paleolithic. The presence of mtDNA contamination does not automatically invalidate nuclear analyses; indeed, it is common for mtDNA contamination levels to be different from, and often higher than, nuclear contamination levels due to the vastly different copy numbers of the respective genomes.\n\nThe appropriate course of action is to correct the mtDNA haplogroup assignment based on the PMD evidence and proceed with the analysis of the nuclear genome while accounting for the quantified low level of contamination.\n\n**Option-by-Option Analysis**\n\nA. Accept the damage-unfiltered mtDNA consensus as haplogroup H and include the sample in all downstream analyses, because the nuclear contamination estimate $\\hat{c}_{\\text{nuc}}$ is below $0.05$.\nThis option is fundamentally flawed. It ignores the compelling PMD evidence that definitively identifies the haplogroup H signal as modern contamination. Accepting the unfiltered consensus call is poor scientific practice. The low nuclear contamination estimate justifies using the nuclear data, not accepting a demonstrably incorrect mtDNA result.\n**Verdict: Incorrect.**\n\nB. Infer that haplogroup U represents the endogenous mtDNA based on damage patterns, treat haplogroup H reads as modern contamination, and retain the individual for nuclear DNA analyses (preferably using PMD-filtered reads). Exclude or re-call the mtDNA haplogroup using only damage-enriched molecules before reporting.\nThis option is entirely consistent with our derivation. It correctly uses PMD to identify haplogroup U as endogenous and H as contaminant. It correctly concludes that the nuclear DNA, with its low and quantified contamination rate of $\\hat{c}_{\\text{nuc}} = 0.03$, is valuable and should be retained for analysis. Recommending the use of PMD-filtered reads for nuclear analysis and a re-evaluation of the mtDNA haplogroup using damage-positive reads are both standard best practices in paleogenomics for mitigating contamination.\n**Verdict: Correct.**\n\nC. Exclude the sample entirely from all analyses because the mtDNA shows evidence of contamination that invalidates both mtDNA and nuclear DNA signals.\nThis option is excessively conservative and demonstrates a misunderstanding of aDNA data analysis. While the mtDNA signal is contaminated, the nuclear DNA contamination has been independently quantified to be low ($3\\%$). Methods exist to work with such data, and discarding a rare Upper Paleolithic genome unnecessarily would be a major loss. The contamination of one part of the data (mtDNA) does not automatically render all other parts (nuclear DNA) useless, especially when the contamination can be characterized and mitigated.\n**Verdict: Incorrect.**\n\nD. Interpret the discordance between haplogroups U and H as within-individual heteroplasmy and include both mtDNA haplogroups and all nuclear data in downstream analyses without special filtering.\nThis option proposes a biologically implausible explanation. Heteroplasmy involving two phylogenetically distant haplogroups (U and H) co-existing at high proportions (reads for H are $\\frac{1000}{1700+1000} \\approx 37\\%$ of the total in this subset) is not a known biological phenomenon. True heteroplasmies are typically minor variants. Crucially, this interpretation completely ignores the stark difference in PMD patterns. If it were true heteroplasmy, both mtDNA lineages would be equally ancient and should exhibit similarly high PMD rates. The data clearly refutes this.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{B}$$", "id": "5011615"}, {"introduction": "After authenticating a sample, we face the challenge of its inherently poor quality, particularly low sequencing coverage. This exercise explores the statistical consequences of having only a few DNA reads at any given position in the genome. You will derive the probability of misidentifying a heterozygous site and, in doing so, understand why standard genotype calling methods fail for aDNA and why strategies like pseudo-haploid calling are essential for robust population genetic inference [@problem_id:5011595].", "problem": "Ancient Deoxyribonucleic Acid (aDNA) studies often confront low sequencing coverage at individual genomic sites, which challenges diploid genotype inference. Consider a single bi-allelic locus that is truly heterozygous in an ancient human genome. Assume that each of the $c$ independent sequencing reads covering the locus samples one of the two alleles with equal probability $1/2$ and that read errors and mapping biases are negligible so that the per-read probability of reporting either allele is exactly $1/2$. A standard heterozygote detection rule calls a site as heterozygous if the observed minor-allele fraction lies within the interval $\\left[\\tau, 1 - \\tau\\right]$, with $0 < \\tau \\leq \\frac{1}{2}$, and otherwise calls the site as homozygous. Equivalently, if $X$ is the number of reads supporting one arbitrarily labeled allele, the site is called heterozygous only when $X \\in \\{t, t+1, \\dots, c - t\\}$, where $t = \\lceil \\tau c \\rceil$ is the minimum minor-allele count required.\n\nStarting from the binomial sampling model and the definition of the decision rule above, derive a closed-form expression, in terms of $c$ and $\\tau$, for the expected error rate defined as the probability that a truly heterozygous site is miscalled as homozygous under this rule. Express your final answer as a single analytic expression involving $c$ and $\\tau$ only. No numerical evaluation is required.\n\nThen, using the derived expression and reasoning from first principles, explain why pseudo-haploid calling (one randomly chosen read per site to represent the allele state) is preferred in low coverage ancient genomes for downstream population genetic analyses. You must base your explanation on the consequences of low $c$ for the heterozygote misclassification probability under the diploid calling rule described above. No additional formulas beyond the derived expression should be introduced.", "solution": "The problem asks for two parts: first, to derive a closed-form expression for the probability that a truly heterozygous site is miscalled as homozygous, and second, to explain the rationale for using pseudo-haploid calling in low-coverage ancient DNA (aDNA) studies based on this expression.\n\nLet the two alleles at the truly heterozygous locus be $A_1$ and $A_2$. We are given that there are $c$ independent sequencing reads covering this locus. For each read, the probability of sampling allele $A_1$ is $1/2$, and the probability of sampling allele $A_2$ is $1/2$, as errors and biases are considered negligible.\n\nLet $X$ be the random variable representing the number of reads supporting allele $A_1$. The remaining $c-X$ reads will support allele $A_2$. Under the given assumptions, $X$ follows a binomial distribution with $c$ trials and a success probability of $p=1/2$. The probability mass function (PMF) of $X$ is given by:\n$$P(X=k) = \\binom{c}{k} \\left(\\frac{1}{2}\\right)^k \\left(1-\\frac{1}{2}\\right)^{c-k} = \\binom{c}{k} \\left(\\frac{1}{2}\\right)^c$$\nfor $k \\in \\{0, 1, 2, \\dots, c\\}$.\n\nThe decision rule states that a site is called heterozygous if the number of reads for one allele, $X$, falls within the range $\\{t, t+1, \\dots, c-t\\}$, where $t = \\lceil \\tau c \\rceil$. The parameter $\\tau$ is the minimum minor-allele fraction threshold, with $0 < \\tau \\leq 1/2$.\n\nAn error, as defined in the problem, occurs when a truly heterozygous site is miscalled as homozygous. This happens if the condition for calling a heterozygote is not met. The event of a miscall therefore corresponds to $X$ falling outside the specified range. The set of outcomes for $X$ that lead to a homozygous call is $\\{0, 1, \\dots, t-1\\} \\cup \\{c-t+1, c-t+2, \\dots, c\\}$.\n\nThe probability of this error event, which we denote as $P(\\text{error})$, is the sum of the probabilities of these outcomes:\n$$P(\\text{error}) = P(X \\leq t-1) + P(X \\geq c-t+1)$$\nWe can express these probabilities as sums of the PMF:\n$$P(\\text{error}) = \\sum_{k=0}^{t-1} P(X=k) + \\sum_{k=c-t+1}^{c} P(X=k)$$\nSubstituting the binomial PMF:\n$$P(\\text{error}) = \\sum_{k=0}^{t-1} \\binom{c}{k} \\left(\\frac{1}{2}\\right)^c + \\sum_{k=c-t+1}^{c} \\binom{c}{k} \\left(\\frac{1}{2}\\right)^c$$\nThe binomial distribution with $p=1/2$ is symmetric, meaning $P(X=k) = P(X=c-k)$ because $\\binom{c}{k} = \\binom{c}{c-k}$. We can demonstrate the symmetry of the two sums. Let's perform a change of index in the second sum. Let $j = c-k$. As $k$ goes from $c-t+1$ to $c$, the new index $j$ goes from $c-(c-t+1) = t-1$ down to $c-c = 0$.\n$$\\sum_{k=c-t+1}^{c} \\binom{c}{k} \\left(\\frac{1}{2}\\right)^c = \\sum_{j=0}^{t-1} \\binom{c}{c-j} \\left(\\frac{1}{2}\\right)^c = \\sum_{j=0}^{t-1} \\binom{c}{j} \\left(\\frac{1}{2}\\right)^c$$\nThis shows that the second sum is equal to the first sum, $P(X \\geq c-t+1) = P(X \\leq t-1)$.\nTherefore, the total error probability can be simplified to:\n$$P(\\text{error}) = 2 \\times P(X \\leq t-1) = 2 \\sum_{k=0}^{t-1} \\binom{c}{k} \\left(\\frac{1}{2}\\right)^c$$\nWe can factor the constant term $(1/2)^c$ out of the summation:\n$$P(\\text{error}) = 2 \\left(\\frac{1}{2}\\right)^c \\sum_{k=0}^{t-1} \\binom{c}{k} = 2^{1-c} \\sum_{k=0}^{t-1} \\binom{c}{k}$$\nReplacing $t$ with its definition in terms of $c$ and $\\tau$, we obtain the final closed-form expression for the error rate:\n$$P(\\text{error}) = 2^{1-c} \\sum_{k=0}^{\\lceil \\tau c \\rceil - 1} \\binom{c}{k}$$\nThis expression represents the probability of observing a number of minor allele reads less than the threshold $t$, multiplied by two to account for both alleles being potentially the minor one.\n\nFor the second part of the task, we must use this expression to explain the preference for pseudo-haploid calling in low-coverage aDNA.\n\nLow coverage in aDNA studies means that the number of reads, $c$, covering any given site is small. The derived expression, $P(\\text{error}) = 2^{1-c} \\sum_{k=0}^{\\lceil \\tau c \\rceil - 1} \\binom{c}{k}$, reveals the consequences of a small $c$. The sum represents the cumulative probability of the extreme tails of the binomial sampling distribution. When $c$ is small, random sampling variance is high. This means that even at a truly heterozygous site, it is highly probable to randomly sample reads representing only one of the two alleles (e.g., $X=0$ or $X=c$) or a highly skewed ratio of alleles.\n\nThe diploid calling rule requires a minimum count of the minor allele, $t = \\lceil \\tau c \\rceil$, to be observed. For low $c$, it is difficult to meet this criterion. For instance, if coverage $c=2$ and the threshold is $\\tau=1/3$, then $t = \\lceil 2/3 \\rceil = 1$. The site is called homozygous if $X=0$ or $X=2$. The error probability is $P(\\text{error}) = 2^{1-2}\\sum_{k=0}^{0} \\binom{2}{k} = (1/2)\\binom{2}{0} = 1/2$. A $50\\%$ error rate is extremely high. If coverage is $c=1$, it is impossible to meet any minor allele threshold $t \\ge 1$, so the error rate is $1$, meaning all heterozygotes are miscalled.\n\nThe derived expression formalizes this intuition: for small $c$, the sum $\\sum_{k=0}^{t-1} \\binom{c}{k}$ combined with the pre-factor $2^{1-c}$ results in a large value for $P(\\text{error})$. This systematic misclassification of true heterozygotes as homozygotes introduces a severe bias in downstream analyses. It leads to a significant underestimation of heterozygosity and genetic diversity, which in turn biases estimates of population differentiation, relatedness, and other key population genetic statistics.\n\nPseudo-haploid calling is a strategy to mitigate this bias. Instead of attempting to make a diploid genotype call, which is highly error-prone at low coverage, this method involves randomly selecting a single read at each site to represent the allele. At a truly heterozygous site, this procedure correctly samples one of the two alleles with probability $1/2$ each. While this approach discards information about the heterozygosity of an individual at a specific site, it provides an unbiased sample of alleles from that individual's genome. When data from many sites or many individuals are aggregated, the resulting allele frequencies are not systematically biased towards homozygosity. This makes the data more reliable for population-level inferences, where accurate allele frequency estimation is more critical than accurate individual diploid genotyping. Thus, the high heterozygote misclassification probability, quantified by our derived expression for low $c$, is the fundamental reason for preferring the less biased pseudo-haploid approach for low-coverage aDNA.", "answer": "$$\n\\boxed{2^{1-c} \\sum_{k=0}^{\\lceil \\tau c \\rceil - 1} \\binom{c}{k}}\n$$", "id": "5011595"}]}