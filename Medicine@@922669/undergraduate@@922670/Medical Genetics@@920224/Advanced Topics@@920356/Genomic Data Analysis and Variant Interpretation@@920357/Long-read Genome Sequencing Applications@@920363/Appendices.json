{"hands_on_practices": [{"introduction": "The foundation of any genomic analysis is an accurate consensus sequence. This exercise delves into the fundamental relationship between the quality of individual sequencing reads and the final accuracy of an assembled genome. By modeling how errors are overcome through majority voting at a given sequencing depth, you will learn how to determine the minimum coverage required to achieve a desired level of quality, a critical calculation in planning any sequencing project [@problem_id:5053428].", "problem": "A clinical genomics lab wants to assemble a high-accuracy consensus sequence for a human-sized diploid genome of length $3$ Gb using Pacific Biosciences (PacBio) High-Fidelity (HiFi) reads. Each read has a Phred quality score (Q) of $Q30$. The target consensus accuracy per base is $Q40$. Assume the following model and constraints to keep the analysis principled and mechanistic:\n\n- The Phred quality score $Q$ is related to the base error probability $p$ by $Q = -10 \\log_{10}(p)$, so that $p = 10^{-Q/10}$.\n- Read errors are independent and identically distributed across reads and sites, with per-read error probability $p$ and no systematic bias.\n- Errors at a site are treated as binary outcomes relative to the true base (correct versus incorrect), consistent with a binomial error model.\n- Reads can be perfectly partitioned by haplotype (perfect phasing), so the per-haplotype depth is exactly half of the total coverage.\n- A consensus base is called on each haplotype independently using strict majority voting among reads from that haplotype; to ensure a call at every site without ties, require that the per-haplotype depth $n$ is an odd integer. Under this rule, the consensus is incorrect if and only if the number of erroneous reads is at least $\\lfloor n/2 \\rfloor + 1$.\n- Ignore coverage variability across the genome (treat the per-site depth as exactly equal to the mean).\n\nUsing these assumptions, derive from first principles the smallest total coverage $C$ (in $X$-fold coverage units) for the diploid genome such that the per-base consensus error probability is at most $10^{-4}$ (i.e., consensus accuracy of at least $Q40$) on each haplotype. Report your final answer as a single integer in $X$-fold coverage units. No rounding instruction is needed beyond reporting an integer. Express the final coverage in $X$-fold units but do not include units in your final boxed answer.", "solution": "### Step 1: Extract Givens\n-   **Genome Length:** $3$ Gb (diploid)\n-   **Sequencing Data:** Pacific Biosciences (PacBio) High-Fidelity (HiFi) reads\n-   **Per-Read Quality:** Phred quality score $Q_{read} = 30$\n-   **Target Consensus Quality:** Per-base consensus accuracy $Q_{consensus} = 40$\n-   **Phred Score Formula:** $Q = -10 \\log_{10}(p)$, which implies a per-base error probability of $p = 10^{-Q/10}$\n-   **Error Model:** Read errors are independent and identically distributed (i.i.d.), with binary outcomes (correct vs. incorrect). The number of errors follows a binomial distribution.\n-   **Phasing and Coverage:** Reads are perfectly partitioned by haplotype. The per-haplotype depth, denoted by $n$, is exactly half of the total coverage, $C$. Thus, $n = C/2$.\n-   **Consensus Calling:** Performed independently on each haplotype via strict majority voting.\n-   **Constraint on Depth:** The per-haplotype depth $n$ must be an odd integer to avoid ties.\n-   **Consensus Error Condition:** A consensus base is incorrect if the number of erroneous reads is at least $\\lfloor n/2 \\rfloor + 1$.\n-   **Coverage Uniformity:** Coverage is constant across the genome.\n-   **Objective:** Find the smallest total coverage $C$ (an integer, in X-fold units) such that the per-base consensus error probability on each haplotype is at most $10^{-4}$.\n\n### Derivation of the Solution\nThe problem requires us to find the minimum total sequencing coverage $C$ needed to achieve a specified consensus quality. The derivation proceeds from first principles as follows.\n\n1.  **Translate Quality Scores into Probabilities:**\n    The Phred quality score $Q$ is related to the error probability $p$ by $p = 10^{-Q/10}$.\n    -   The per-base error probability for a single read with $Q_{read} = 30$ is:\n        $$ p = 10^{-30/10} = 10^{-3} $$\n    -   The target maximum error probability for a consensus base, corresponding to $Q_{consensus} = 40$, is:\n        $$ P_{target} = 10^{-40/10} = 10^{-4} $$\n\n2.  **Model the Consensus Error:**\n    Let $n$ be the per-haplotype depth of coverage. The problem states that $n$ must be an odd integer. At any given base on one haplotype, there are $n$ reads. Let $k$ be the number of these reads that contain an error at this base. Since errors are assumed to be i.i.d., the random variable $k$ follows a binomial distribution with parameters $n$ and $p$:\n    $$ k \\sim B(n, p) $$\n    The probability of observing exactly $k$ erroneous reads out of $n$ is given by the binomial probability mass function:\n    $$ P(k) = \\binom{n}{k} p^k (1-p)^{n-k} $$\n    A consensus error occurs under majority voting if the number of erroneous reads $k$ is greater than the number of correct reads $n-k$. This means $k > n-k$, or $2k > n$, which is equivalent to $k > n/2$. Since $n$ is an odd integer, we can write $n = 2j+1$ for some integer $j \\ge 0$. The condition $k > (2j+1)/2 = j+0.5$ for an integer $k$ is equivalent to $k \\ge j+1$. Note that $j+1 = (n-1)/2 + 1 = (n+1)/2$. This matches the problem's definition that an error occurs for $k \\ge \\lfloor n/2 \\rfloor + 1$.\n\n3.  **Formulate the Inequality:**\n    The probability of a consensus error for a given depth $n$, let's call it $P_{E,n}$, is the probability that the number of erroneous reads $k$ is at least $(n+1)/2$. This is calculated by summing the binomial probabilities over the upper tail of the distribution:\n    $$ P_{E,n} = P(k \\ge \\frac{n+1}{2}) = \\sum_{k=(n+1)/2}^{n} \\binom{n}{k} p^k (1-p)^{n-k} $$\n    Our goal is to find the smallest odd integer $n$ that satisfies the condition:\n    $$ P_{E,n} \\le P_{target} \\implies \\sum_{k=(n+1)/2}^{n} \\binom{n}{k} p^k (1-p)^{n-k} \\le 10^{-4} $$\n\n4.  **Solve the Inequality by Testing Smallest Odd Values of $n$:**\n    We must find the minimum odd integer $n$ that satisfies the inequality. We start with the smallest possible value, $n=1$.\n\n    -   **Case $n=1$**:\n        The condition for a consensus error is $k \\ge (1+1)/2 = 1$.\n        The probability of error is:\n        $$ P_{E,1} = P(k \\ge 1) = P(k=1) = \\binom{1}{1} p^1 (1-p)^0 = p = 10^{-3} $$\n        We check the condition: $10^{-3} \\le 10^{-4}$. This is false. Therefore, a per-haplotype depth of $n=1$ is insufficient.\n\n    -   **Case $n=3$**:\n        The condition for a consensus error is $k \\ge (3+1)/2 = 2$.\n        The probability of error is the sum of probabilities for $k=2$ and $k=3$:\n        $$ P_{E,3} = P(k \\ge 2) = P(k=2) + P(k=3) $$\n        $$ P_{E,3} = \\binom{3}{2} p^2 (1-p)^{3-2} + \\binom{3}{3} p^3 (1-p)^{3-3} $$\n        $$ P_{E,3} = 3 p^2 (1-p) + p^3 $$\n        Substituting $p=10^{-3}$:\n        $$ P_{E,3} = 3(10^{-3})^2 (1 - 10^{-3}) + (10^{-3})^3 $$\n        $$ P_{E,3} = 3 \\times 10^{-6} (0.999) + 10^{-9} $$\n        $$ P_{E,3} = 2.997 \\times 10^{-6} + 1 \\times 10^{-9} = 2.997001 \\times 10^{-6} $$\n        We check the condition: $2.997001 \\times 10^{-6} \\le 10^{-4}$. This is true, as $10^{-4} = 100 \\times 10^{-6}$.\n        Since $n=1$ is insufficient and $n=3$ is sufficient, the smallest odd integer per-haplotype depth required is $n=3$.\n\n5.  **Calculate the Total Coverage:**\n    The problem asks for the smallest *total* coverage $C$. The total coverage for the diploid genome is related to the per-haplotype depth $n$ by $C=2n$.\n    Using the minimum required per-haplotype depth $n=3$:\n    $$ C = 2 \\times n = 2 \\times 3 = 6 $$\n    The smallest total coverage required is $6$X. This is an integer, as required.\n\nThe genome length of $3$ Gb is extraneous information, as the calculation is for per-base accuracy under an assumption of uniform coverage.", "answer": "$$\n\\boxed{6}\n$$", "id": "5053428"}, {"introduction": "While base-level accuracy is essential, the true advantage of long-read sequencing lies in its ability to produce highly continuous genome assemblies. This practice problem introduces NG50, a standard metric for assessing assembly continuity, and challenges you to apply it in a clinical context. You will see firsthand how this single statistic can provide a powerful, high-level summary of whether an assembly is suitable for resolving complex and medically important regions of the genome [@problem_id:5053437].", "problem": "A medical genetics laboratory is evaluating the continuity of a draft genome assembly produced from long-read genome sequencing to determine whether the assembly is adequate for resolving paralogous genes at the survival motor neuron locus. In genome assembly evaluation, continuity metrics such as Genome N50 (NG50) are widely used. NG50 is summarized with respect to the known haploid reference genome length and is interpreted as follows: one orders all contigs by length in descending order and seeks the contig length at which the cumulative sum of contig lengths first reaches one-half of the reference genome length. The laboratory has an assembly whose contigs have lengths $[3, 5, 8, 12, 15]$ megabases (Mb). The haploid human reference genome length is $3$ gigabases (Gb). Assume $1$ Gb $=$ $1000$ Mb.\n\nUsing the accepted definition of Genome N50 (NG50), compute the NG50 for this assembly relative to the $3$ Gb reference. Express your answer in megabases (Mb). Then, based solely on this quantitative continuity assessment, justify whether this assembly’s long-read contiguity is likely adequate to fully resolve survival motor neuron $1$ (SMN1) and survival motor neuron $2$ (SMN2) in the chromosome $5q13$ locus for clinical interpretation of Spinal Muscular Atrophy (SMA). If the cumulative contig length never reaches one-half of the reference genome length, adhere to the convention that NG50 is reported as $0$ Mb. No rounding is required.", "solution": "The solution is approached in two parts as requested: first, the computation of the Genome N$50$ (NG$50$) value, and second, an evidence-based justification regarding the assembly's adequacy for resolving a specific genetic locus.\n\n**Part 1: Computation of the NG50**\n\nThe NG$50$ is a metric used to evaluate the continuity of a genome assembly relative to a known reference genome size. The definition provided requires us to order the contigs by length, sum their lengths cumulatively, and identify the length of the contig at which this sum first meets or exceeds $50\\%$ of the reference genome size.\n\nFirst, we establish the necessary values in consistent units.\nThe haploid human reference genome length, $G$, is given as $3$ gigabases (Gb).\n$$ G = 3 \\text{ Gb} $$\nThe problem states the conversion factor to be used is $1 \\text{ Gb} = 1000$ megabases (Mb).\nTherefore, the reference genome size in Mb is:\n$$ G = 3 \\text{ Gb} \\times \\frac{1000 \\text{ Mb}}{1 \\text{ Gb}} = 3000 \\text{ Mb} $$\nThe target for the cumulative sum is one-half of the reference genome length:\n$$ G_{target} = \\frac{1}{2} G = \\frac{1}{2} \\times 3000 \\text{ Mb} = 1500 \\text{ Mb} $$\nThe lengths of the contigs in the assembly are given as $[3, 5, 8, 12, 15]$, all in units of Mb.\n\nAccording to the definition of NG$50$, we must first order the contigs by length in descending order.\nThe ordered list of contig lengths, $L_{ord}$, is:\n$$ L_{ord} = [15, 12, 8, 5, 3] \\text{ Mb} $$\nNext, we calculate the cumulative sum of these lengths and check if the sum reaches the target of $1500$ Mb.\nThe total length of the assembly, $L_{total}$, is the sum of all contig lengths:\n$$ L_{total} = 15 + 12 + 8 + 5 + 3 = 43 \\text{ Mb} $$\nWe must compare the total assembly length to the target length.\n$$ L_{total} = 43 \\text{ Mb} $$\n$$ G_{target} = 1500 \\text{ Mb} $$\nClearly, $L_{total} < G_{target}$, since $43 < 1500$.\n\nThe cumulative sum of contig lengths ($43$ Mb) never reaches one-half of the reference genome length ($1500$ Mb). The problem specifies the convention for this scenario: \"If the cumulative contig length never reaches one-half of the reference genome length, adhere to the convention that NG$50$ is reported as $0$ Mb.\"\n\nTherefore, the NG$50$ for this assembly is $0$ Mb.\n\n**Part 2: Justification of Assembly Adequacy for SMN1/SMN2 Resolution**\n\nThe task is to justify, based *solely* on this quantitative continuity assessment (the NG$50$ value), whether the assembly is likely adequate to resolve the paralogous genes SMN$1$ and SMN$2$.\n\nThe computed NG$50$ value is $0$ Mb. An NG$50$ of $0$ Mb is the lowest possible value for this metric and signifies extremely poor continuity of the genome assembly on a genome-wide scale. The total size of the assembled sequence ($43$ Mb) represents only a minuscule fraction of the entire human genome ($\\frac{43}{3000} \\approx 1.4\\%$). This suggests that the sequencing and assembly process failed to recover the vast majority of the genome.\n\nResolving the SMN$1$ and SMN$2$ genes, which are located in a complex region on chromosome $5$q$13$ characterized by large, highly similar segmental duplications, requires high-quality, contiguous sequence data. To unambiguously distinguish these paralogs and determine their copy numbers for clinical interpretation of Spinal Muscular Atrophy (SMA), a contig must be long enough to span the entire locus, including unique flanking sequences, to anchor the reads correctly. This region spans several hundred kilobases (kb).\n\nWhile the longest contig in this assembly is $15$ Mb, which is theoretically long enough to cover the SMN locus (which is less than $1$ Mb), the assessment must be based on the NG$50$ metric as per the problem's constraint. An NG$50$ of $0$ indicates that the assembly is, as a whole, profoundly fragmented and incomplete. Relying on such a poor-quality assembly for clinical-grade analysis of a notoriously difficult genomic region would be scientifically unsound. The extremely low NG$50$ value implies a high probability of large-scale misassemblies, gaps, and an inability to correctly represent complex repeat structures anywhere in the genome.\n\nTherefore, based solely on the quantitative continuity assessment yielding an NG$50$ of $0$ Mb, the assembly's long-read contiguity is **not** likely adequate for the clinical-level resolution of SMN$1$ and SMN$2$. An assembly with such a catastrophic continuity metric cannot be considered reliable for any downstream analysis, especially one as sensitive as the interpretation of a complex disease locus.", "answer": "$$\n\\boxed{0}\n$$", "id": "5053437"}, {"introduction": "Detecting large structural variants (SVs) is a key application where long-read sequencing excels. This advanced exercise guides you through the process of modeling the statistical power to detect a heterozygous deletion. You will integrate concepts like read length distribution, coverage, and specific detection criteria (split and spanning reads) to calculate the experimental parameters needed to confidently identify these large-scale genomic changes [@problem_id:5053450].", "problem": "A diploid human sample harbors a heterozygous deletion of size $L_{d} = 50$ kilobases (kb) at a locus embedded in unique sequence. You are tasked with determining the minimal read span and the sequencing coverage (depth) needed to achieve $95\\%$ power to detect this deletion using long-read sequencing under the following assumptions.\n\nBase assumptions:\n1. Reads start along the genome according to the Lander–Waterman model: read start sites form a Poisson process with intensity $r$ (starts per base), and the per-base coverage (mean depth) is $\\lambda = r \\,\\bar{\\ell}$, where $\\bar{\\ell}$ is the mean read length.\n2. Read lengths are independent and identically distributed and follow an exponential distribution with mean $\\bar{\\ell} = 30\\,\\text{kb}$.\n3. Because the deletion is heterozygous, exactly one of the two homologous chromosomes carries the deletion. Therefore, exactly one-half of reads derive from the deleted haplotype and one-half from the intact haplotype in the region of interest.\n4. Detection criterion: The deletion is considered detected if both of the following are satisfied:\n   (i) There is at least one split-read from the deleted haplotype that spans the novel adjacency (the breakpoint junction created by the deletion) and contains at least $b = 1\\,\\text{kb}$ of uniquely mappable sequence on each side of the breakpoint within the read.\n   (ii) There is at least one intact haplotype read that spans the entire deleted interval and contains at least $b = 1\\,\\text{kb}$ of uniquely mappable sequence on each flank. This guards against a spurious homozygous call and supports heterozygosity.\n\nModel the number of qualifying reads for each of the two evidentiary classes as independent Poisson counts determined by the Poisson start process and the read length distribution. Use these to compute the probability of observing at least one qualifying read of each class. Under these assumptions, compute:\n\n- The minimal read span (in kb) needed by the intact haplotype read to satisfy criterion (ii).\n- The minimal per-base coverage $\\lambda$ (as a pure number, i.e., fold coverage) required to achieve $95\\%$ overall power for detecting the heterozygous deletion, defined as the product of the probabilities of observing at least one qualifying split-read and at least one qualifying intact spanning read.\n\nRound both the minimal read span and the required coverage to three significant figures. Express the minimal read span in kilobases (kb) and the coverage as a pure number (fold coverage).", "solution": "The problem asks for two quantities: the minimal read span required to identify an intact read supporting a heterozygous deletion, and the sequencing coverage needed to detect the deletion with $95\\%$ power.\n\n**Part 1: Minimal Read Span for an Intact Haplotype Read**\n\nThe problem defines the requirements for detecting an intact haplotype read (criterion ii). The read must span the entire deleted interval and contain at least $b$ of uniquely mappable sequence on each flank.\n\nThe size of the heterozygous deletion is given as $L_{d} = 50$ kb.\nThe required length of uniquely mappable sequence on each flank is $b = 1$ kb.\n\nOn the intact chromosome, the region corresponding to the deletion has length $L_d$. For a read to be considered evidence for the intact haplotype, it must cover this region of length $L_d$ as well as an additional length $b$ of sequence on the 5' flank and an additional length $b$ on the 3' flank. Therefore, the total contiguous genomic interval that a single read must span on the intact chromosome is the sum of these lengths.\n\nLet $S_{intact}$ be this minimal required span.\n$$S_{intact} = b + L_{d} + b = L_{d} + 2b$$\nSubstituting the given values:\n$$S_{intact} = 50 \\, \\text{kb} + 2 \\times (1 \\, \\text{kb}) = 52 \\, \\text{kb}$$\nRounding to three significant figures, the minimal read span is $52.0$ kb.\n\n**Part 2: Minimal Per-Base Coverage ($\\lambda$) for 95% Power**\n\nThe overall power to detect the heterozygous deletion is defined as the product of the probabilities of satisfying criteria (i) and (ii).\nLet $P_{detect}$ be the total power.\nLet $P_{split}$ be the probability of observing at least one qualifying split-read (criterion i).\nLet $P_{intact}$ be the probability of observing at least one qualifying intact read (criterion ii).\n$$P_{detect} = P_{split} \\times P_{intact}$$\nThe problem states that the number of qualifying reads of each type follows an independent Poisson distribution. Let $N_{split}$ and $N_{intact}$ be the random variables for the counts of qualifying split-reads and intact reads, with means $\\mu_{split}$ and $\\mu_{intact}$ respectively.\n$$N_{split} \\sim \\text{Poisson}(\\mu_{split})$$\n$$N_{intact} \\sim \\text{Poisson}(\\mu_{intact})$$\nThe probability of observing at least one event in a Poisson process with mean $\\mu$ is $1 - P(N=0) = 1 - e^{-\\mu}$. Thus:\n$$P_{split} = 1 - e^{-\\mu_{split}}$$\n$$P_{intact} = 1 - e^{-\\mu_{intact}}$$\nWe require $P_{detect} = (1 - e^{-\\mu_{split}})(1 - e^{-\\mu_{intact}}) = 0.95$.\n\nTo find the means $\\mu_{split}$ and $\\mu_{intact}$, we use the provided model. The expected number of reads spanning a genomic interval of length $S$, for reads whose lengths are exponentially distributed with mean $\\bar{\\ell}$, is given by $\\lambda_{eff} \\exp(-S/\\bar{\\ell})$, where $\\lambda_{eff}$ is the effective coverage for the haplotype of origin.\n\nThe total per-base coverage is $\\lambda$. Since the deletion is heterozygous, reads originate from the deleted and intact haplotypes in equal proportion. Therefore, the effective coverage for each haplotype is $\\lambda_{del} = \\lambda_{intact} = \\lambda/2$.\n\nFor qualifying intact reads (criterion ii), the required span is $S_{intact} = L_d + 2b = 52$ kb. The mean number of such reads is:\n$$\\mu_{intact} = \\lambda_{intact} \\exp\\left(-\\frac{S_{intact}}{\\bar{\\ell}}\\right) = \\frac{\\lambda}{2} \\exp\\left(-\\frac{L_d + 2b}{\\bar{\\ell}}\\right)$$\n\nFor qualifying split-reads (criterion i), a read must span the breakpoint junction and contain at least $b$ kb of mappable sequence on each side. The total length of sequence from the reference that must be contained within the read is $b+b=2b$. This constitutes the minimal span for a split-read, $S_{split}$.\n$$S_{split} = 2b = 2 \\times (1 \\, \\text{kb}) = 2 \\, \\text{kb}$$\nThe mean number of such reads is:\n$$\\mu_{split} = \\lambda_{del} \\exp\\left(-\\frac{S_{split}}{\\bar{\\ell}}\\right) = \\frac{\\lambda}{2} \\exp\\left(-\\frac{2b}{\\bar{\\ell}}\\right)$$\n\nNow, we can write the full power equation in terms of $\\lambda$:\n$$ \\left(1 - \\exp\\left[-\\frac{\\lambda}{2} \\exp\\left(-\\frac{2b}{\\bar{\\ell}}\\right)\\right]\\right) \\left(1 - \\exp\\left[-\\frac{\\lambda}{2} \\exp\\left(-\\frac{L_d + 2b}{\\bar{\\ell}}\\right)\\right]\\right) = 0.95 $$\nThe given parameters are $\\bar{\\ell} = 30$ kb, $L_d = 50$ kb, and $b=1$ kb. Let's evaluate the exponents:\n$$\\frac{2b}{\\bar{\\ell}} = \\frac{2}{30} = \\frac{1}{15}$$\n$$\\frac{L_d + 2b}{\\bar{\\ell}} = \\frac{50 + 2}{30} = \\frac{52}{30} = \\frac{26}{15}$$\nSince $26/15 \\gg 1/15$, we have $\\exp(-26/15) \\ll \\exp(-1/15)$. Consequently, for any given $\\lambda$, $\\mu_{intact} \\ll \\mu_{split}$. This implies that $P_{intact}$ will be much smaller than $P_{split}$ and will be the limiting factor for achieving the desired overall power.\n\nThe term $P_{split} = 1 - e^{-\\mu_{split}}$ will be very close to $1$. We can therefore approximate the power equation by setting $P_{split} \\approx 1$:\n$$1 \\times P_{intact} \\approx 0.95$$\n$$1 - \\exp(-\\mu_{intact}) \\approx 0.95$$\nThis simplifies to:\n$$\\exp(-\\mu_{intact}) \\approx 0.05$$\n$$-\\mu_{intact} \\approx \\ln(0.05) = -\\ln(20)$$\n$$\\mu_{intact} \\approx \\ln(20)$$\nNow, we substitute the expression for $\\mu_{intact}$:\n$$\\frac{\\lambda}{2} \\exp\\left(-\\frac{L_d + 2b}{\\bar{\\ell}}\\right) = \\ln(20)$$\nWe can now solve for the required coverage, $\\lambda$:\n$$\\lambda = 2 \\ln(20) \\exp\\left(\\frac{L_d + 2b}{\\bar{\\ell}}\\right)$$\nPlugging in the numerical values:\n$$\\lambda = 2 \\ln(20) \\exp\\left(\\frac{52}{30}\\right)$$\nUsing a calculator:\n$\\ln(20) \\approx 2.995732$\n$\\exp(52/30) = \\exp(26/15) \\approx 5.65958$\n$$\\lambda \\approx 2 \\times 2.995732 \\times 5.65958 \\approx 33.909$$\nWe must verify if the approximation $P_{split} \\approx 1$ was justified for this value of $\\lambda$.\nWith $\\lambda \\approx 33.909$:\n$$\\mu_{split} = \\frac{33.909}{2} \\exp\\left(-\\frac{2}{30}\\right) \\approx 16.9545 \\times \\exp(-0.06667) \\approx 16.9545 \\times 0.93551 \\approx 15.862$$\n$$P_{split} = 1 - \\exp(-15.862) \\approx 1 - 1.29 \\times 10^{-7}$$\nThis value is extremely close to $1$, so the approximation was valid. The overall power is $P_{detect} \\approx (1 - 1.29 \\times 10^{-7}) \\times 0.95 \\approx 0.95$.\n\nRounding the value of $\\lambda$ to three significant figures, we get $\\lambda = 33.9$.\nThe required minimal per-base coverage is $33.9$-fold.", "answer": "$$\\boxed{\\begin{pmatrix} 52.0 & 33.9 \\end{pmatrix}}$$", "id": "5053450"}]}