{"hands_on_practices": [{"introduction": "The journey from a patient's DNA sample to a clinical diagnosis begins with detecting variations in the genome. This initial step relies on interpreting complex patterns in sequencing data, where true signals must be carefully separated from technical noise. This practice will challenge you to analyze alignment signatures—such as soft-clipped and split reads—to differentiate a genuine genetic variant from common artifacts, a foundational skill in bioinformatics. [@problem_id:5091085]", "problem": "A clinical whole-genome sequencing case uses paired-end reads of length $L=150$ bases and an average physical insert size with mean $\\mu=350$ bases and standard deviation $\\sigma=50$ bases, sequenced to a mean depth of $30\\times$. At a candidate locus within an exonic homopolymer of adenines of length $8$ (an $A_8$ run), the alignments show two different patterns at two nearby positions:\n\nPattern $1$: At genomic coordinate $g_1$, there are $n_1=40$ reads covering the site. Of these, $k_1=18$ reads support a $5$ base pair deletion through either soft clipping at a common boundary or split-read alignment with a consistent $5$ base pair gap in the CIGAR. The soft-clipped or split-read breakpoints cluster within $\\pm 1$ base pair of each other, the mapping quality for the breakpoint-containing alignments is $Q \\geq 35$ (on the Phred scale), and the base quality of the clipped bases and their anchors is $q \\geq 30$. The supporting reads are balanced by strand orientation ($9$ forward, $9$ reverse), and the remaining reads align cleanly across the locus without soft clips. No anomalous read pairs are observed, which is expected for a $5$ base pair event given the insert size distribution.\n\nPattern $2$: At genomic coordinate $g_2$ within the same $A_8$ run, there are $n_2=38$ reads covering the site. Of these, $k_2=20$ reads exhibit soft clipping but with starting positions spread irregularly over a window of $12$ bases. The mapping qualities of these alignments are $Q \\leq 10$, the base qualities of clipped segments are $q \\leq 15$, and $19$ of the $20$ soft-clipped reads are on the forward strand. No split-read alignments consistently bridge a gap of a defined size, and the CIGAR strings show inconsistent indel sizes.\n\nFrom first principles of short-read alignment and error modeling, explain how soft-clipping and split-read signatures arise when reads span true insertions and deletions (indels) or structural variant breakpoints, and why homopolymer runs can produce alignment artifacts that mimic these signatures. Use the definitions that an aligner seeks to maximize sequence agreement subject to mismatch and gap penalties, that mapping quality $Q$ and base quality $q$ are on the Phred scale with $Q=-10\\log_{10}(p_{\\text{map\\_error}})$ and $q=-10\\log_{10}(p_{\\text{base\\_error}})$, and that in a diploid genome a heterozygous variant is expected to have an alternate allele fraction near $0.5$ subject to binomial sampling.\n\nWhich of the following option sets specifies robust, discriminative criteria to call a true indel or structural variant using soft-clipping and split-read evidence while filtering alignment artifacts near homopolymers? Select all that apply.\n\nA. For small indels shorter than the read length, require that soft-clipped and split-read breakpoints cluster tightly (within $\\pm 1$ base pair), that the implied indel size is consistent across supporting reads, that supporting alignments have high mapping quality ($Q \\geq 30$) and anchors with high base quality ($q \\geq 20$), and that supporting reads are approximately strand-balanced without a statistically significant bias under a binomial model. The observed alternate allele fraction should be consistent with the expected ploidy (for a heterozygous germline event at coverage $n \\gtrsim 30$, within sampling variation of $0.5$), and the signal should persist after local realignment. Do not require discordant read pairs for indels of size $\\leq 10$ base pairs.\n\nB. Accept an indel call near a homopolymer whenever a sizable number of soft-clipped reads are present, even if all supporting reads come from the same strand, the soft-clip starting positions vary by $>10$ bases, and the mapping quality is low ($Q \\leq 10$), because homopolymer context naturally reduces mapping quality and split-read consistency.\n\nC. Prefer depth-only evidence: call the indel if there is a localized coverage reduction of approximately $20\\%$ at the site relative to the chromosome-wide mean, regardless of soft-clip distribution, mapping quality, or strand orientation, because indels disrupt read mapping and should reduce depth.\n\nD. For structural variants larger than the read length, require both consistent split-read breakpoints (within $\\pm 2$ bases) and concordant discordant read-pair evidence whose orientation and insert size shift matches the expected signature of the event (for example, for a deletion, inward-facing pairs with apparent insert size substantially $>\\mu+3\\sigma$). Additionally require high mapping quality for the anchored segments, approximate strand balance of supporting reads, short breakpoint microhomology (for example, $\\leq 2$ bases) rather than long low-complexity runs, and absence of pervasive low-complexity that would cause multi-mapping. Do not accept events supported only by soft clips scattered across a long homopolymer with low $Q$ and $q$.\n\nAnswer choices are independent; select all that are correct.", "solution": "Soft clipping and split-read signatures are emergent properties of how short-read aligners optimize sequence alignment under mismatch and gap penalties. A read spanning a true insertion or deletion relative to the reference cannot align contiguously without introducing a gap. If the gap size is small relative to the read length, many aligners will either (i) place a gap in the CIGAR string and align both sides, or (ii) if local ambiguity or penalties make a gapped alignment less optimal, they will align the higher-scoring portion and soft-clip the remaining bases, producing a cluster of soft-clipped reads that begin (for deletions) or end (for insertions) at a consistent breakpoint. For structural variants larger than the read length, a single read may map in two parts to distinct reference loci, yielding a split-read alignment in which each segment (anchor) maps with high confidence to a unique location and the breakpoints cluster tightly across reads.\n\nHomopolymer runs such as an $A_8$ tract increase the probability of polymerase slippage during polymerase chain reaction or sequencing and reduce sequence complexity, increasing the rate of insertion and deletion-like errors and causing alignment ambiguity. These errors often have low base quality $q$ and lead to multiple nearly equivalent alignment placements with low mapping quality $Q$ because $Q=-10\\log_{10}(p_{\\text{map\\_error}})$, and $p_{\\text{map\\_error}}$ is elevated when many placements have similar scores. In such contexts, soft clips may start at diverse positions (reflecting ambiguous optimal alignments) and show strong strand bias, because systematic sequence-context and instrument-cycle effects can bias the errors to one read orientation or end. Conversely, a true variant in a diploid sample is expected to have an alternate allele fraction near $0.5$, with sampling variance governed by the binomial distribution $X \\sim \\text{Binomial}(n,p)$, where $n$ is the coverage and $p=0.5$ for a heterozygous event absent copy-number changes. Strand balance for true variants similarly follows a binomial split between forward and reverse orientations.\n\nApplying these principles to Pattern $1$ versus Pattern $2$, Pattern $1$ shows consistent breakpoints within $\\pm 1$ base pair, consistent $5$ base pair deletion size across CIGARs, high $Q$ and $q$, and balanced strand support ($9$ forward, $9$ reverse among $k_1=18$ supporting reads), with $k_1/n_1=18/40=0.45$ close to $0.5$ and well within binomial sampling variance at $n_1=40$. These features are expected for a true small deletion, and the absence of discordant pairs is not disqualifying because a $5$ base pair event does not significantly alter apparent insert sizes relative to $\\mu=350$ and $\\sigma=50$.\n\nPattern $2$ shows soft-clip starts spread across $12$ bases, low mapping quality ($Q \\leq 10$ implies $p_{\\text{map\\_error}} \\geq 10^{-1}$), low base qualities ($q \\leq 15$ implies $p_{\\text{base\\_error}} \\geq \\approx 10^{-1.5}$), and extreme strand bias ($19$ of $20$ supports on one strand). Under a null of no strand bias, the probability that $19$ or more of $20$ supporting reads fall on the same strand is $2 \\times \\sum_{i=19}^{20} \\binom{20}{i} (0.5)^{20} = 2 \\times \\left(\\binom{20}{19} + \\binom{20}{20}\\right) (0.5)^{20} = 2 \\times (20+1) \\times (0.5)^{20} \\approx 42 \\times 9.54 \\times 10^{-7} \\approx 4.0 \\times 10^{-5}$, which is highly unlikely for a true balanced event and suggests an artifact, especially in the presence of low $Q$ and $q$ and inconsistent indel sizes. This pattern is characteristic of homopolymer-associated alignment artifacts.\n\nOption-by-option analysis:\n\nA. This option encodes the expected hallmarks of a true small indel derived from alignment and error models. Tight breakpoint clustering within $\\pm 1$ base pair arises because the true genomic change occurs at a precise location; consistent indel size across CIGARs reflects the same event being observed by multiple reads. High mapping quality ($Q \\geq 30$ corresponds to $p_{\\text{map\\_error}} \\leq 10^{-3}$) and high base quality ($q \\geq 20$ corresponds to $p_{\\text{base\\_error}} \\leq 10^{-2}$) reduce the likelihood that the signal is due to misalignment or base-calling errors. Approximate strand balance and an alternate allele fraction near $0.5$ at coverage $n \\gtrsim 30$ are consistent with a heterozygous germline variant under a binomial model. For indels of size $\\leq 10$ base pairs, discordant read-pair evidence is not expected because the apparent insert size is not substantially perturbed relative to $\\mu$ and $\\sigma$. These are robust, discriminative criteria. Verdict — Correct.\n\nB. This option proposes to accept a call primarily on the count of soft-clipped reads while explicitly tolerating multiple red flags: extreme strand bias, widely variable soft-clip starts ($>10$ bases), and low $Q$. From first principles, such patterns are expected under homopolymer-induced artifacts where many nearly equivalent alignments exist and instrument context effects bias errors to one orientation. Low $Q$ values imply high $p_{\\text{map\\_error}}$, and inconsistent CIGAR indel sizes argue against a single true event. This is not a robust criterion set and would inflate false positives. Verdict — Incorrect.\n\nC. This option ignores the core signatures (breakpoint consistency, mapping quality, split-reads, strand balance) and relies instead on a modest depth change (approximately $20\\%$) as decisive. Depth fluctuations of this magnitude are common due to guanine-cytosine content and mapping biases and are not specific to small indels. Moreover, small indels, especially on the order of a few bases, do not reliably cause depth changes distinguishable from noise at typical $30\\times$ coverage. Therefore, this criterion is neither necessary nor sufficient and will misclassify sites. Verdict — Incorrect.\n\nD. For structural variants larger than the read length, the combination of consistent split-read breakpoints and discordant read pairs with the expected orientation and insert size shift is the principled, orthogonal evidence pair. For example, a deletion tends to produce read pairs with apparent insert sizes $>\\mu+3\\sigma$ and inward-facing orientation, while inversions or tandem duplications have characteristic orientation signatures. High mapping qualities of anchors, approximate strand balance, short breakpoint microhomology (for example, $\\leq 2$ bases) rather than long low-complexity runs, and avoidance of pervasive low-complexity that induces multi-mapping are appropriate filters to reduce homopolymer artifacts. Rejecting events supported only by scattered soft clips with low $Q$ and $q$ in long homopolymers aligns with the error model. These criteria are robust and discriminative for structural variants. Verdict — Correct.\n\nTherefore, the robust, discriminative criteria are specified in options A and D.", "answer": "$$\\boxed{AD}$$", "id": "5091085"}, {"introduction": "After a genetic variant has been confidently detected, it must be named using a universal language to ensure clear communication across clinics and research labs. The Human Genome Variation Society (HGVS) nomenclature provides this standard, but applying its rules requires precision, especially in complex regions of the genome. Through this exercise, you will practice converting a variant's genomic location to its official coding DNA description, mastering essential rules like left-normalization that ensure accuracy and consistency. [@problem_id:5091094]", "problem": "A clinical Whole Genome Sequencing (WGS) report identifies a single-base duplication within a homopolymer run in a protein-coding gene. In clinical practice, laboratories must describe variants using the Human Genome Variation Society (HGVS) nomenclature at genomic ($g.$), coding ($c.$), and protein ($p.$) levels. Foundational principles include the Central Dogma of molecular biology (deoxyribonucleic acid to ribonucleic acid to protein), exon–intron gene structure, and HGVS rules that coding deoxyribonucleic acid numbering starts at the adenosine of the translation initiation codon ($c.1$ at the $A$ in the canonical $ATG$), proceeds across exons, and that small insertions and deletions in repetitive sequence are left-normalized to the most 5-prime position on the reference sequence. Reference transcript selection must prioritize a stable, curated, protein-coding transcript appropriate for clinical reporting (for example, a National Center for Biotechnology Information Reference Sequence (RefSeq) NM accession or a Locus Reference Genomic (LRG) mapping when available).\n\nConsider a gene on chromosome $17$ (Genome Reference Consortium Human build $38$). The gene is on the forward strand and has three exons with genomic coordinates:\n- Exon $1$: $g.430{,}100$ to $g.430{,}199$.\n- Exon $2$: $g.430{,}300$ to $g.430{,}449$.\n- Exon $3$: $g.430{,}600$ to $g.430{,}849$.\n\nThe coding sequence (CDS) for curated transcript $\\mathrm{NM\\_000001}$ starts at $g.430{,}130$ (within exon $1$) and ends at $g.430{,}820$ (within exon $3$). An alternative transcript $\\mathrm{NM\\_000002}$ exists with a different translation start at $g.430{,}135$, but both transcripts share the same exon coordinates and gene orientation.\n\nThe WGS pipeline reports a raw variant call $g.430{,}380dupA$ within exon $2$. The local forward-strand reference sequence from $g.430{,}374$ to $g.430{,}384$ is:\n$$\n\\text{Position } g.430{,}374\\text{ to }g.430{,}384: \\quad \\text{A A A A A A A G T C G}\n$$\nso there are seven consecutive adenosines from $g.430{,}374$ through $g.430{,}380$.\n\nTasks:\n1. Using the foundational principles above, identify the appropriate transcript for clinical HGVS reporting and explain the implications for $c.$-level numbering.\n2. Apply HGVS left-normalization to the reported duplication in this homopolymer context and determine the left-normalized genomic description.\n3. Map the left-normalized genomic position to the coding coordinate for $\\mathrm{NM\\_000001}$ and construct the corresponding $c.$-level HGVS expression. Briefly indicate the conceptual $p.$-level consequence (frame-preserving or frameshifting), without requiring a specific amino acid sequence.\n4. Let $n$ denote the integer coding position used in the $c.$-level duplication after left-normalization for $\\mathrm{NM\\_000001}$. Compute $n$. Report only the integer value of $n$ as your final answer. No rounding is necessary; express your result as an exact integer with no units.", "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the principles of molecular biology and clinical genetics, well-posed with sufficient and consistent data, and objective in its formulation. We may therefore proceed with a formal solution.\n\nThe problem requires a multi-step analysis involving transcript selection, variant normalization, and coordinate mapping, based on the provided gene structure and Human Genome Variation Society (HGVS) nomenclature rules.\n\nFirst, we address the selection of the appropriate transcript for clinical reporting (Task $1$). The problem provides two transcripts, $\\mathrm{NM\\_000001}$ and $\\mathrm{NM\\_000002}$. Clinical practice, as stated, requires the use of a stable, curated, protein-coding transcript. While both are RefSeq transcripts, subsequent tasks specifically direct the analysis to be performed on $\\mathrm{NM\\_000001}$. Therefore, $\\mathrm{NM\\_000001}$ is selected as the reference transcript for this analysis. The implication for coding DNA ($c.$) level numbering is that the start of the numbering, $c.1$, corresponds to the adenosine ($A$) of the translation initiation codon ($ATG$). For $\\mathrm{NM\\_000001}$, the coding sequence (CDS) starts at genomic position $g.430{,}130$. Thus, $g.430{,}130$ is equivalent to $c.1$.\n\nSecond, we apply the HGVS left-normalization rule to the reported variant (Task $2$). The raw variant is given as $g.430{,}380dupA$. This variant occurs within a homopolymer run of seven consecutive adenosine bases, which the problem specifies spans from $g.430{,}374$ to $g.430{,}380$. The sequence is $\\text{A}_7$. A duplication of the adenosine at the 3'-most position ($g.430{,}380$) results in an allele with eight consecutive adenosines, $\\text{A}_8$. This resultant sequence is biologically indistinguishable from an allele where the duplication occurred at any other position within the homopolymer. The HGVS rules state that such variants in repetitive sequences must be \"left-normalized,\" meaning the variant is described at the most 5' (leftmost, or numerically smallest) possible coordinate. For the homopolymer run from $g.430{,}374$ to $g.430{,}380$, the most 5' position is $g.430{,}374$. Therefore, the left-normalized genomic description of the variant is $g.430{,}374dupA$.\n\nThird, we map this normalized genomic position to its corresponding coding DNA coordinate for transcript $\\mathrm{NM\\_000001}$ (Task $3$). The gene is on the forward strand, so CDS numbering increases with the genomic coordinates, accounting for introns. The normalized variant position, $g.430{,}374$, falls within exon $2$ (which spans $g.430{,}300$ to $g.430{,}449$). To find the coding position, we must calculate the number of coding bases that precede it.\n\n1.  Calculate the length of the coding sequence in exon $1$.\n    The CDS begins at $g.430{,}130$ within exon $1$ (which ends at $g.430{,}199$). The number of coding bases in exon $1$ is:\n    $$ L_1 = (g_{\\text{exon1\\_end}} - g_{\\text{CDS\\_start}}) + 1 $$\n    $$ L_1 = (430{,}199 - 430{,}130) + 1 = 69 + 1 = 70 \\text{ bases} $$\n    These bases correspond to positions $c.1$ through $c.70$.\n\n2.  Calculate the number of coding bases in exon $2$ up to the variant's position.\n    The CDS continues at the start of exon $2$, $g.430{,}300$. This position corresponds to coding position $c.71$. The normalized variant is at $g.430{,}374$. The number of coding bases from the start of exon $2$ up to and including the variant position is:\n    $$ L_2 = (g_{\\text{variant}} - g_{\\text{exon2\\_start}}) + 1 $$\n    $$ L_2 = (430{,}374 - 430{,}300) + 1 = 74 + 1 = 75 \\text{ bases} $$\n\n3.  Sum the contributions to find the final coding position, $n$.\n    The coding position of the variant is the sum of the coding length of the prior exon(s) and the offset within the current exon.\n    $$ n = L_1 + L_2 $$\n    $$ n = 70 + 75 = 145 $$\n    Thus, the genomic position $g.430{,}374$ corresponds to the coding position $c.145$.\n\nThe $c.$-level HGVS expression for the variant is therefore $c.145dupA$ (or more formally, $c.145dup$). This is a single-base duplication. Since the number of inserted bases ($1$) is not a multiple of three, this variant disrupts the translational reading frame. The conceptual consequence at the protein ($p.$) level is a **frameshift**.\n\nFourth, we identify the integer $n$ as requested (Task $4$). The problem defines $n$ as the integer coding position in the $c.$-level description of the left-normalized duplication. Based on our calculation, this value is $145$.", "answer": "$$\\boxed{145}$$", "id": "5091094"}, {"introduction": "Identifying a variant is only part of the puzzle; the ultimate goal is to understand its clinical significance. This process is not a simple yes-or-no decision but a careful weighing of evidence, akin to a detective's investigation. This problem simulates this critical task by using a quantitative Bayesian framework, allowing you to combine various lines of evidence to calculate a variant's probability of being pathogenic and assign a final classification based on established guidelines. [@problem_id:5091119]", "problem": "A patient undergoes Whole Genome Sequencing (WGS) in the workup of a suspected autosomal dominant cardiac arrhythmia. A rare missense variant in a disease gene is identified. You will assess this variant using the semi-quantitative adaptation of the American College of Medical Genetics and Genomics and the Association for Molecular Pathology (ACMG/AMP) framework that combines evidence in a Bayesian manner via odds of pathogenicity. Use the following scientifically plausible inputs grounded in Bayes’ theorem and likelihood ratios derived from calibrated evidence strengths.\n\nAssume a gene-specific prior probability of pathogenicity $P_{0} = 0.02$ for an arbitrary rare missense variant under consideration in this clinical context. Evidence applicable to this variant is:\n- One strong pathogenic criterion (denoted $S$) with likelihood ratio $LR_{S} = 18.7$.\n- One moderate pathogenic criterion (denoted $M$) with likelihood ratio $LR_{M} = 4.33$.\n- One supporting pathogenic criterion (denoted $P$) with likelihood ratio $LR_{P} = 2.08$.\n- One supporting benign criterion (denoted $bP$) with likelihood ratio $LR_{bP} = 0.48$.\n\nBy standard semi-quantitative practice, these likelihood ratios are multiplied to update the prior odds to posterior odds, which are then converted to a posterior probability of pathogenicity. Classification is determined by the posterior probability $P_{\\text{post}}$ using the following thresholds:\n- Pathogenic if $P_{\\text{post}} \\geq 0.99$.\n- Likely pathogenic if $0.95 \\leq P_{\\text{post}} < 0.99$.\n- Uncertain significance if $0.05 < P_{\\text{post}} < 0.95$.\n- Likely benign if $0.001 < P_{\\text{post}} \\leq 0.05$.\n- Benign if $P_{\\text{post}} \\leq 0.001$.\n\nTask:\n1. Compute the posterior probability of pathogenicity $P_{\\text{post}}$ for the baseline evidence set $\\{S, M, P, bP\\}$ defined above.\n2. Now suppose new data reduce the strength of the case-level evidence such that the former strong pathogenic criterion is downgraded to moderate (that is, replace $LR_{S}$ by $LR_{M}$ while the other criteria remain unchanged). Recompute the posterior probability of pathogenicity $P_{\\text{post}}$ for the modified evidence set $\\{M, M, P, bP\\}$.\n3. Report your answers for both scenarios as decimals, rounding each to four significant figures. No units are required.\n\nIn your reasoning, start from fundamental definitions of prior probability, odds, Bayes’ theorem, and likelihood ratios. Do not assume or quote any shortcut formulas that bypass these foundations. Justify how the evidence is combined and how the posterior probability is obtained from posterior odds. Although you will determine the classification category using the thresholds above, the requested final answer should consist only of the two rounded posterior probabilities (baseline and modified).", "solution": "The problem is valid. It is scientifically grounded in the principles of Bayesian statistics as applied to medical genetics, specifically the ACMG/AMP framework for variant classification. The problem is well-posed, objective, and contains all necessary information for a unique solution.\n\nThe core of this problem rests on Bayes' theorem, which provides a mathematical framework for updating the probability of a hypothesis in light of new evidence. In this context, the hypothesis is that a genetic variant is pathogenic.\n\nLet $D$ represent the event that the variant is pathogenic, and $\\neg D$ represent the event that the variant is benign (not pathogenic). The prior probability of pathogenicity is given as $P_0 = P(D) = 0.02$. The prior probability of the variant being benign is therefore $P(\\neg D) = 1 - P(D) = 1 - 0.02 = 0.98$.\n\nIt is often more convenient to work with odds rather than probabilities. The odds of an event are defined as the ratio of the probability of the event occurring to the probability of it not occurring. The prior odds of pathogenicity, $O_{\\text{prior}}$, are:\n$$\nO_{\\text{prior}} = \\frac{P(D)}{P(\\neg D)} = \\frac{P_0}{1 - P_0}\n$$\nSubstituting the given value:\n$$\nO_{\\text{prior}} = \\frac{0.02}{0.98} = \\frac{1}{49}\n$$\nEvidence is incorporated into this framework using a likelihood ratio ($LR$). For a piece of evidence $E$, the likelihood ratio is defined as:\n$$\nLR = \\frac{P(E|D)}{P(E|\\neg D)}\n$$\nThis ratio quantifies how much more likely the observed evidence is if the variant is pathogenic compared to if it is benign. Bayes' theorem in odds form states that the posterior odds, $O_{\\text{post}}$, are the product of the prior odds and the likelihood ratio:\n$$\nO_{\\text{post}} = O_{\\text{prior}} \\times LR\n$$\nThe problem states that when multiple independent pieces of evidence are considered, their likelihood ratios are multiplied. If we have a set of evidence $\\{E_1, E_2, \\dots, E_n\\}$ with corresponding likelihood ratios $\\{LR_1, LR_2, \\dots, LR_n\\}$, the combined likelihood ratio is $LR_{\\text{total}} = \\prod_{i=1}^{n} LR_i$. The posterior odds are then:\n$$\nO_{\\text{post}} = O_{\\text{prior}} \\times LR_{\\text{total}} = \\frac{P_0}{1 - P_0} \\times \\prod_{i=1}^{n} LR_i\n$$\nThe final step is to convert the posterior odds back into a posterior probability, $P_{\\text{post}}$. The relationship is given by:\n$$\nP_{\\text{post}} = \\frac{O_{\\text{post}}}{1 + O_{\\text{post}}}\n$$\nWe apply this procedure to the two scenarios described.\n\n**Task 1: Baseline Evidence Set $\\{S, M, P, bP\\}$**\n\nThe evidence consists of one strong pathogenic ($S$), one moderate pathogenic ($M$), one supporting pathogenic ($P$), and one supporting benign ($bP$) criterion. The respective likelihood ratios are:\n$LR_S = 18.7$\n$LR_M = 4.33$\n$LR_P = 2.08$\n$LR_{bP} = 0.48$\n\nThe combined likelihood ratio, $LR_{\\text{total},1}$, is the product of these individual likelihood ratios:\n$$\nLR_{\\text{total},1} = LR_S \\times LR_M \\times LR_P \\times LR_{bP} = 18.7 \\times 4.33 \\times 2.08 \\times 0.48\n$$\n$$\nLR_{\\text{total},1} = 80.85722112\n$$\nNow, we compute the posterior odds, $O_{\\text{post},1}$:\n$$\nO_{\\text{post},1} = O_{\\text{prior}} \\times LR_{\\text{total},1} = \\frac{1}{49} \\times 80.85722112 \\approx 1.649984104\n$$\nFinally, we convert these odds to the posterior probability, $P_{\\text{post},1}$:\n$$\nP_{\\text{post},1} = \\frac{O_{\\text{post},1}}{1 + O_{\\text{post},1}} = \\frac{1.649984104}{1 + 1.649984104} \\approx \\frac{1.649984104}{2.649984104} \\approx 0.622639\n$$\nRounding to four significant figures, the posterior probability for the first scenario is $0.6226$. Based on the given thresholds, this variant would be classified as of Uncertain Significance ($0.05 < 0.6226 < 0.95$).\n\n**Task 2: Modified Evidence Set $\\{M, M, P, bP\\}$**\n\nIn this scenario, the strong pathogenic criterion ($S$) is downgraded to a moderate one ($M$). The likelihood ratio $LR_S = 18.7$ is replaced by another $LR_M = 4.33$. The other criteria remain unchanged. The new set of likelihood ratios is:\n$LR_M = 4.33$\n$LR_M = 4.33$\n$LR_P = 2.08$\n$LR_{bP} = 0.48$\n\nThe new combined likelihood ratio, $LR_{\\text{total},2}$, is:\n$$\nLR_{\\text{total},2} = LR_M \\times LR_M \\times LR_P \\times LR_{bP} = 4.33 \\times 4.33 \\times 2.08 \\times 0.48\n$$\n$$\nLR_{\\text{total},2} = 18.71880016\n$$\nThe prior odds remain $O_{\\text{prior}} = 1/49$. We compute the new posterior odds, $O_{\\text{post},2}$:\n$$\nO_{\\text{post},2} = O_{\\text{prior}} \\times LR_{\\text{total},2} = \\frac{1}{49} \\times 18.71880016 \\approx 0.38201633\n$$\nFinally, we convert these odds to the posterior probability, $P_{\\text{post},2}$:\n$$\nP_{\\text{post},2} = \\frac{O_{\\text{post},2}}{1 + O_{\\text{post},2}} = \\frac{0.38201633}{1 + 0.38201633} \\approx \\frac{0.38201633}{1.38201633} \\approx 0.276416\n$$\nRounding to four significant figures, the posterior probability for the second scenario is $0.2764$. This variant would also be classified as of Uncertain Significance ($0.05 < 0.2764 < 0.95$).\n\nThe requested answers are the two posterior probabilities, rounded to four significant figures.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.6226 & 0.2764\n\\end{pmatrix}\n}\n$$", "id": "5091119"}]}