{"hands_on_practices": [{"introduction": "A crucial first step in any algorithmic fairness audit is to evaluate a model's performance across different demographic groups. This exercise provides a practical scenario where you will use the confusion matrix, a fundamental tool in machine learning, to calculate key performance metrics like the true positive rate ($\\text{TPR}$) and false positive rate ($\\text{FPR}$). By comparing these metrics between groups, you can directly assess whether the model satisfies the Equalized Odds criterion, a common group fairness standard that ensures a model is equally effective for both positive and negative cases, regardless of group membership [@problem_id:4390084].", "problem": "A hospital deploys a binary predictive model to flag patients at triage in the Emergency Department (ED) for urgent sepsis workup. To audit algorithmic fairness across two demographic groups under consideration, analysts compile confusion matrices from a representative evaluation cohort. For Group A, the confusion matrix counts are $\\text{TP}=80$, $\\text{FP}=20$, $\\text{FN}=40$, $\\text{TN}=860$. For Group B, the counts are $\\text{TP}=60$, $\\text{FP}=15$, $\\text{FN}=30$, $\\text{TN}=895$. Using standard classification metric definitions grounded in the confusion matrix, compute the true positive rate (TPR), false positive rate (FPR), and positive predictive value (PPV) for each group. Then, assess the equalized odds criterion, which requires equality of both the true positive rate and the false positive rate across the groups, and indicate whether it holds for this model.\n\nProvide your final results as unitless proportions (no percentage sign), rounded to four significant figures. Report your final answer as a single row matrix in the order $(\\text{TPR}_{A}, \\text{FPR}_{A}, \\text{PPV}_{A}, \\text{TPR}_{B}, \\text{FPR}_{B}, \\text{PPV}_{B}, I)$, where $I$ is $1$ if equalized odds holds and $0$ otherwise.", "solution": "The problem statement is first validated for scientific soundness, objectivity, and completeness.\n\n**Step 1: Extract Givens**\n-   For Group A, the confusion matrix counts are: True Positives ($\\text{TP}_A$) = $80$, False Positives ($\\text{FP}_A$) = $20$, False Negatives ($\\text{FN}_A$) = $40$, True Negatives ($\\text{TN}_A$) = $860$.\n-   For Group B, the confusion matrix counts are: True Positives ($\\text{TP}_B$) = $60$, False Positives ($\\text{FP}_B$) = $15$, False Negatives ($\\text{FN}_B$) = $30$, True Negatives ($\\text{TN}_B$) = $895$.\n-   Metrics to compute: True Positive Rate (TPR), False Positive Rate (FPR), and Positive Predictive Value (PPV) for each group.\n-   Fairness criterion to assess: Equalized odds, which requires equality of both TPR and FPR across groups.\n-   Output format: A row matrix $(\\text{TPR}_{A}, \\text{FPR}_{A}, \\text{PPV}_{A}, \\text{TPR}_{B}, \\text{FPR}_{B}, \\text{PPV}_{B}, I)$, where $I$ is an indicator variable ($1$ if equalized odds holds, $0$ otherwise).\n-   Rounding: Final proportions are to be rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem is based on standard, well-defined metrics from the field of machine learning and classification model evaluation (confusion matrix, TPR, FPR, PPV) and the established fairness criterion of equalized odds. The context of a clinical predictive model is a standard application area in health systems science. The problem is scientifically valid.\n-   **Well-Posed**: The problem provides all necessary data and clear definitions to compute the required metrics and make the requested assessment. The existence of a unique, stable solution is guaranteed.\n-   **Objective**: The problem is stated using precise, quantitative, and unbiased language.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is self-contained, scientifically grounded, and well-posed. A solution will be computed.\n\nThe required metrics are defined as follows:\n-   True Positive Rate (TPR), or Sensitivity: The proportion of actual positives that are correctly identified.\n$$ \\text{TPR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$\n-   False Positive Rate (FPR), or Fall-out: The proportion of actual negatives that are incorrectly identified as positive.\n$$ \\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} $$\n-   Positive Predictive Value (PPV), or Precision: The proportion of positive predictions that are actually correct.\n$$ \\text{PPV} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n\nWe now compute these metrics for each group using the provided data.\n\n**For Group A:**\n-   $\\text{TP}_A = 80$, $\\text{FP}_A = 20$, $\\text{FN}_A = 40$, $\\text{TN}_A = 860$.\n-   The number of actual positives is $\\text{TP}_A + \\text{FN}_A = 80 + 40 = 120$.\n-   The number of actual negatives is $\\text{FP}_A + \\text{TN}_A = 20 + 860 = 880$.\n-   The number of predicted positives is $\\text{TP}_A + \\text{FP}_A = 80 + 20 = 100$.\n\nThe metrics are calculated as:\n$$ \\text{TPR}_A = \\frac{80}{80 + 40} = \\frac{80}{120} = \\frac{2}{3} \\approx 0.66666... $$\nRounding to four significant figures, $\\text{TPR}_A = 0.6667$.\n\n$$ \\text{FPR}_A = \\frac{20}{20 + 860} = \\frac{20}{880} = \\frac{1}{44} \\approx 0.022727... $$\nRounding to four significant figures, $\\text{FPR}_A = 0.02273$.\n\n$$ \\text{PPV}_A = \\frac{80}{80 + 20} = \\frac{80}{100} = 0.8 $$\nExpressed with four significant figures, $\\text{PPV}_A = 0.8000$.\n\n**For Group B:**\n-   $\\text{TP}_B = 60$, $\\text{FP}_B = 15$, $\\text{FN}_B = 30$, $\\text{TN}_B = 895$.\n-   The number of actual positives is $\\text{TP}_B + \\text{FN}_B = 60 + 30 = 90$.\n-   The number of actual negatives is $\\text{FP}_B + \\text{TN}_B = 15 + 895 = 910$.\n-   The number of predicted positives is $\\text{TP}_B + \\text{FP}_B = 60 + 15 = 75$.\n\nThe metrics are calculated as:\n$$ \\text{TPR}_B = \\frac{60}{60 + 30} = \\frac{60}{90} = \\frac{2}{3} \\approx 0.66666... $$\nRounding to four significant figures, $\\text{TPR}_B = 0.6667$.\n\n$$ \\text{FPR}_B = \\frac{15}{15 + 895} = \\frac{15}{910} = \\frac{3}{182} \\approx 0.0164835... $$\nRounding to four significant figures, $\\text{FPR}_B = 0.01648$.\n\n$$ \\text{PPV}_B = \\frac{60}{60 + 15} = \\frac{60}{75} = \\frac{4}{5} = 0.8 $$\nExpressed with four significant figures, $\\text{PPV}_B = 0.8000$.\n\n**Assessment of Equalized Odds:**\nThe equalized odds criterion requires that the model satisfies both $\\text{TPR}_A = \\text{TPR}_B$ and $\\text{FPR}_A = \\text{FPR}_B$.\n-   Comparing TPRs: $\\text{TPR}_A = 0.6667$ and $\\text{TPR}_B = 0.6667$. The true positive rates are equal (within the specified precision).\n-   Comparing FPRs: $\\text{FPR}_A = 0.02273$ and $\\text{FPR}_B = 0.01648$. The false positive rates are not equal.\n\nSince the false positive rates are unequal, the equalized odds criterion is not satisfied. Therefore, the indicator variable $I$ is $0$.\n\nThe final results are assembled into the required row matrix format: $(\\text{TPR}_{A}, \\text{FPR}_{A}, \\text{PPV}_{A}, \\text{TPR}_{B}, \\text{FPR}_{B}, \\text{PPV}_{B}, I)$.\nThe values are $(0.6667, 0.02273, 0.8000, 0.6667, 0.01648, 0.8000, 0)$.", "answer": "$$ \\boxed{\\begin{pmatrix} 0.6667  0.02273  0.8000  0.6667  0.01648  0.8000  0 \\end{pmatrix}} $$", "id": "4390084"}, {"introduction": "While group fairness metrics are essential, they do not guarantee that similar individuals are treated similarly. To address this, we turn to the concept of individual fairness, which is operationalized in this exercise through a Lipschitz condition. This practice challenges you to apply a formal mathematical constraint to a predictive model, ensuring that small differences in patients' clinical features result in only small, bounded changes in their predicted risk, thereby preventing arbitrary or excessively sensitive predictions [@problem_id:4390112].", "problem": "A health system is deploying a predictive analytics model that estimates $30$-day hospital readmission risk from Electronic Health Record (EHR) data. The governance committee has adopted an individual fairness requirement formalized by a Lipschitz condition: for any two patients represented in a standardized feature space with metric distance $d$, the absolute prediction difference must satisfy the bound $\\lvert f(\\mathbf{x}) - f(\\mathbf{x}') \\rvert \\leq L\\, d(\\mathbf{x}, \\mathbf{x}')$, where $L$ is a fixed Lipschitz fairness constant.\n\nFeatures are standardized by $z$-scoring: for each raw feature $x_{j}$, $z_{j} = (x_{j} - \\mu_{j}) / \\sigma_{j}$, where $\\mu_{j}$ is the empirical mean and $\\sigma_{j}$ is the empirical standard deviation computed on the training population. The metric $d(\\mathbf{x}, \\mathbf{x}')$ is the Euclidean distance in this standardized space.\n\nConsider two patients, A and B, described by three clinically relevant features: age (years), Charlson Comorbidity Index (CCI, unitless score), and count of prior-year admissions (unitless count). The population parameters for standardization are $\\sigma_{\\text{age}} = 10$, $\\sigma_{\\text{CCI}} = 2$, and $\\sigma_{\\text{adm}} = 1$, with corresponding means $\\mu_{\\text{age}} = 50$, $\\mu_{\\text{CCI}} = 4$, and $\\mu_{\\text{adm}} = 2$. Patient A has age $60$, CCI $6$, and prior-year admissions $3$. Patient B has age $40$, CCI $2$, and prior-year admissions $2$. The model’s predicted $30$-day readmission risks are $f(\\mathbf{x}_{A}) = 0.62$ and $f(\\mathbf{x}_{B}) = 0.25$. The governance committee fixed the Lipschitz fairness constant at $L = 0.10$.\n\nUsing the core definitions of $z$-score standardization and Euclidean distance, and the formal Lipschitz individual fairness condition, derive the maximum allowable absolute prediction difference between these two patients and determine whether the model’s outputs violate the fairness bound. Your final reported answer must be the single numerical value of the maximum allowable difference $L\\, d(\\mathbf{x}_{A}, \\mathbf{x}_{B})$ expressed as a decimal. If rounding is needed, round your answer to four significant figures. Do not include any units in your final answer.", "solution": "The problem requires the calculation of the maximum allowable absolute prediction difference between two patients, A and B, based on a Lipschitz individual fairness constraint. It also asks for a determination of whether the model's predictions violate this constraint. The final answer must be a single numerical value representing this maximum allowable difference.\n\nThe fairness condition is formalized as a Lipschitz condition: $\\lvert f(\\mathbf{x}) - f(\\mathbf{x}') \\rvert \\leq L\\, d(\\mathbf{x}, \\mathbf{x}')$, where $f(\\mathbf{x})$ is the model's predicted risk, $L$ is the Lipschitz fairness constant, and $d(\\mathbf{x}, \\mathbf{x}')$ is the Euclidean distance between patient feature vectors in a standardized space.\n\nThe first step is to transform the raw feature vectors for Patient A and Patient B into the standardized $z$-score space. The standardization formula for each feature $j$ is $z_{j} = \\frac{x_{j} - \\mu_{j}}{\\sigma_{j}}$. The feature vectors consist of (age, Charlson Comorbidity Index, prior-year admissions).\n\nThe raw features for Patient A are $(\\text{age}, \\text{CCI}, \\text{adm}) = (60, 6, 3)$. The population parameters for standardization are given as $\\mu_{\\text{age}} = 50$ and $\\sigma_{\\text{age}} = 10$; $\\mu_{\\text{CCI}} = 4$ and $\\sigma_{\\text{CCI}} = 2$; $\\mu_{\\text{adm}} = 2$ and $\\sigma_{\\text{adm}} = 1$. The standardized vector for Patient A, $\\mathbf{z}_{A}$, is calculated as:\n$$z_{A, \\text{age}} = \\frac{60 - 50}{10} = \\frac{10}{10} = 1$$\n$$z_{A, \\text{CCI}} = \\frac{6 - 4}{2} = \\frac{2}{2} = 1$$\n$$z_{A, \\text{adm}} = \\frac{3 - 2}{1} = \\frac{1}{1} = 1$$\nThus, the standardized feature vector for Patient A is $\\mathbf{z}_{A} = (1, 1, 1)$.\n\nThe raw features for Patient B are $(\\text{age}, \\text{CCI}, \\text{adm}) = (40, 2, 2)$. Using the same population parameters, the standardized vector for Patient B, $\\mathbf{z}_{B}$, is:\n$$z_{B, \\text{age}} = \\frac{40 - 50}{10} = \\frac{-10}{10} = -1$$\n$$z_{B, \\text{CCI}} = \\frac{2 - 4}{2} = \\frac{-2}{2} = -1$$\n$$z_{B, \\text{adm}} = \\frac{2 - 2}{1} = \\frac{0}{1} = 0$$\nThus, the standardized feature vector for Patient B is $\\mathbf{z}_{B} = (-1, -1, 0)$.\n\nNext, we compute the Euclidean distance $d(\\mathbf{z}_{A}, \\mathbf{z}_{B})$ between the two standardized vectors. The formula for Euclidean distance in a $3$-dimensional space is $d(\\mathbf{u}, \\mathbf{v}) = \\sqrt{(u_1 - v_1)^2 + (u_2 - v_2)^2 + (u_3 - v_3)^2}$.\n$$d(\\mathbf{z}_{A}, \\mathbf{z}_{B}) = \\sqrt{(z_{A, \\text{age}} - z_{B, \\text{age}})^2 + (z_{A, \\text{CCI}} - z_{B, \\text{CCI}})^2 + (z_{A, \\text{adm}} - z_{B, \\text{adm}})^2}$$\nSubstituting the calculated $z$-scores:\n$$d(\\mathbf{z}_{A}, \\mathbf{z}_{B}) = \\sqrt{(1 - (-1))^2 + (1 - (-1))^2 + (1 - 0)^2}$$\n$$d(\\mathbf{z}_{A}, \\mathbf{z}_{B}) = \\sqrt{2^2 + 2^2 + 1^2}$$\n$$d(\\mathbf{z}_{A}, \\mathbf{z}_{B}) = \\sqrt{4 + 4 + 1} = \\sqrt{9} = 3$$\nThe distance between the patients in the standardized feature space is exactly $3$.\n\nThe maximum allowable absolute prediction difference is given by the term $L\\, d(\\mathbf{z}_{A}, \\mathbf{z}_{B})$. The Lipschitz fairness constant is fixed at $L = 0.10$.\n$$ \\text{Maximum allowable difference} = L \\times d(\\mathbf{z}_{A}, \\mathbf{z}_{B}) = 0.10 \\times 3 = 0.30 $$\nThis is the value requested for the final answer. The problem asks to express this as a decimal, and if rounding is needed, to four significant figures. The result $0.3$ is exact. To adhere to the implied precision standard by this instruction, we express this as $0.3000$, which has four significant figures.\n\nTo complete the full analysis requested by the prompt, we check if the model's actual predictions violate this fairness bound. The model's predictions are $f(\\mathbf{x}_{A}) = 0.62$ and $f(\\mathbf{x}_{B}) = 0.25$.\nThe actual absolute difference in predictions is:\n$$ \\lvert f(\\mathbf{x}_{A}) - f(\\mathbf{x}_{B}) \\rvert = |0.62 - 0.25| = 0.37 $$\nWe compare the actual difference ($0.37$) with the maximum allowable difference ($0.30$):\n$$0.37 > 0.30$$\nSince the actual difference is greater than the maximum allowable difference, the model's outputs for these two patients violate the defined fairness requirement.\n\nThe problem, however, asks only for the single numerical value of the maximum allowable difference, $L\\, d(\\mathbf{x}_{A}, \\mathbf{x}_{B})$.", "answer": "$$\\boxed{0.3000}$$", "id": "4390112"}, {"introduction": "In the real world, achieving fairness is rarely straightforward and often involves navigating complex tradeoffs. This advanced exercise explores the practical consequences of a common technique, group-specific recalibration, which aims to make a model's risk scores more accurate for each subpopulation. You will investigate how this intervention impacts Predictive Parity—a fairness metric requiring that a positive prediction has the same meaning for all groups—and in doing so, uncover the subtle tensions that can arise between improving a model's calibration and maintaining fairness across different definitions [@problem_id:4390107].", "problem": "A health system deploys a risk prediction model to flag patients likely to experience unplanned $30$-day readmission. The model outputs a continuous score $s \\in [0,1]$ for each patient. Consider two patient cohorts, Group $A$ and Group $B$, with binary outcome $Y \\in \\{0,1\\}$ indicating readmission ($Y=1$) or no readmission ($Y=0$). Let the base rates be $\\pi_{A} = 0.25$ and $\\pi_{B} = 0.40$, where $\\pi_{g} = \\mathbb{P}(Y=1 \\mid g)$ for group $g$.\n\nBefore recalibration, the score distributions conditional on the true outcome are:\n- Group $A$: $s \\mid Y=1 \\sim \\text{Uniform}[0.4,1.0]$ and $s \\mid Y=0 \\sim \\text{Uniform}[0.0,0.8]$.\n- Group $B$: $s \\mid Y=1 \\sim \\text{Uniform}[0.2,0.9]$ and $s \\mid Y=0 \\sim \\text{Uniform}[0.0,0.7]$.\n\nAn isotonic recalibration is performed separately for each group, yielding calibrated probabilities $r_{g}(s)$ equal to the group-specific estimated calibration curve $c_{g}(s)$. The isotonic calibration curves are:\n- Group $A$: \n$$\nc_{A}(s) = \\begin{cases}\n0.08,  0 \\leq s  0.4, \\\\\n0.22,  0.4 \\leq s  0.7, \\\\\n0.65,  0.7 \\leq s \\leq 1.\n\\end{cases}\n$$\n- Group $B$: \n$$\nc_{B}(s) = \\begin{cases}\n0.12,  0 \\leq s  0.3, \\\\\n0.28,  0.3 \\leq s  0.6, \\\\\n0.55,  0.6 \\leq s \\leq 1.\n\\end{cases}\n$$\n\nA fixed decision threshold $t = 0.5$ on predicted probability is used to flag patients for intervention.\n\nUsing first-principles definitions of calibration and predictive parity, perform the following:\n1. Define and compute, for each group $g \\in \\{A,B\\}$, the post-recalibration positive predictive value (PPV), $\\text{PPV}_{g}^{\\text{post}}(t) = \\mathbb{P}(Y=1 \\mid r_{g}(s) \\geq t)$, and the absolute predictive parity gap after recalibration, $|\\text{PPV}_{A}^{\\text{post}}(t) - \\text{PPV}_{B}^{\\text{post}}(t)|$.\n2. Define and compute the pre-recalibration positive predictive value (PPV), $\\text{PPV}_{g}^{\\text{pre}}(t) = \\mathbb{P}(Y=1 \\mid s \\geq t)$, and the corresponding absolute predictive parity gap before recalibration, $|\\text{PPV}_{A}^{\\text{pre}}(t) - \\text{PPV}_{B}^{\\text{pre}}(t)|$.\n3. Compute the change in the absolute predictive parity gap attributable to isotonic recalibration as $|\\text{PPV}_{A}^{\\text{pre}}(t) - \\text{PPV}_{B}^{\\text{pre}}(t)| - |\\text{PPV}_{A}^{\\text{post}}(t) - \\text{PPV}_{B}^{\\text{post}}(t)|$.\n\nExplain each step by starting from the definitions of positive predictive value and calibration, and using the provided distributions to evaluate the necessary probabilities. Conclude with a brief discussion of the tradeoffs of performing isotonic recalibration per group in terms of calibration, predictive parity, and decision consistency.\n\nExpress the final numeric answer to part $3$ as a decimal rounded to four significant figures. No units are required, and the final answer must be a single real number.", "solution": "The user has asked for a multi-part analysis of a risk prediction model's fairness properties before and after isotonic recalibration. This requires a systematic application of probability theory, specifically Bayes' theorem, to compute the Positive Predictive Value (PPV) under different conditions.\n\nFirst, we establish the necessary definitions and notation.\nLet $g \\in \\{A, B\\}$ denote the patient group.\nLet $s \\in [0,1]$ be the raw prediction score.\nLet $Y \\in \\{0, 1\\}$ be the binary outcome, with $Y=1$ indicating readmission.\nLet $\\pi_g = \\mathbb{P}(Y=1 \\mid g)$ be the group-specific base rate of readmission. We are given $\\pi_A = 0.25$ and $\\pi_B = 0.40$.\nLet $r_g(s)$ be the recalibrated score for group $g$.\nThe decision threshold is $t=0.5$.\n\nA positive test result corresponds to a predicted probability at or above the threshold. Predictive parity is a fairness criterion that requires the PPV to be equal across groups for a given decision threshold.\nThe PPV for a group $g$ and a given test condition (e.g., $s \\geq t$ or $r_g(s) \\geq t$) is defined as the probability of the event being true given a positive test result: $\\text{PPV} = \\mathbb{P}(Y=1 \\mid \\text{Test Positive})$.\nUsing Bayes' theorem for a generic event $C_g$ representing a positive test for group $g$:\n$$ \\text{PPV}_g = \\mathbb{P}(Y=1 \\mid C_g, g) = \\frac{\\mathbb{P}(C_g \\mid Y=1, g) \\mathbb{P}(Y=1 \\mid g)}{\\mathbb{P}(C_g \\mid g)} $$\nThe denominator can be expanded using the law of total probability:\n$$ \\mathbb{P}(C_g \\mid g) = \\mathbb{P}(C_g \\mid Y=1, g)\\mathbb{P}(Y=1 \\mid g) + \\mathbb{P}(C_g \\mid Y=0, g)\\mathbb{P}(Y=0 \\mid g) $$\nThe conditional score distributions $s \\mid Y, g$ are uniform. For a uniform distribution on an interval $[a, b]$, the probability density function is $f(x) = \\frac{1}{b-a}$ for $x \\in [a, b]$ and $0$ otherwise. The probability of $s$ falling into a sub-interval $[c,d] \\subseteq [a,b]$ is $\\frac{d-c}{b-a}$.\n\nThe provided conditional distributions are:\n- Group $A$: $s \\mid (Y=1, A) \\sim \\text{Uniform}[0.4, 1.0]$, $s \\mid (Y=0, A) \\sim \\text{Uniform}[0.0, 0.8]$.\n- Group $B$: $s \\mid (Y=1, B) \\sim \\text{Uniform}[0.2, 0.9]$, $s \\mid (Y=0, B) \\sim \\text{Uniform}[0.0, 0.7]$.\n\n### 1. Post-Recalibration Analysis\n\nThe positive test condition after recalibration is $r_g(s) \\geq t$, where $t=0.5$. We must first determine the range of raw scores $s$ that satisfies this condition for each group.\n\n**Group A:**\nThe condition is $r_A(s) = c_A(s) \\geq 0.5$. From the definition of $c_A(s)$, this holds only when $c_A(s) = 0.65$, which corresponds to $s \\in [0.7, 1.0]$. Let the event be $C_A^{\\text{post}} \\equiv s \\geq 0.7$. We compute the conditional probabilities:\n- $\\mathbb{P}(s \\geq 0.7 \\mid Y=1, A)$: For $s \\sim \\text{Uniform}[0.4, 1.0]$, this probability is $\\frac{1.0 - 0.7}{1.0 - 0.4} = \\frac{0.3}{0.6} = \\frac{1}{2}$.\n- $\\mathbb{P}(s \\geq 0.7 \\mid Y=0, A)$: For $s \\sim \\text{Uniform}[0.0, 0.8]$, this probability is $\\frac{0.8 - 0.7}{0.8 - 0.0} = \\frac{0.1}{0.8} = \\frac{1}{8}$.\n\nNow, we compute $\\text{PPV}_A^{\\text{post}}(0.5)$:\n$$ \\text{PPV}_{A}^{\\text{post}}(0.5) = \\frac{\\mathbb{P}(s \\geq 0.7 \\mid Y=1, A)\\pi_A}{\\mathbb{P}(s \\geq 0.7 \\mid Y=1, A)\\pi_A + \\mathbb{P}(s \\geq 0.7 \\mid Y=0, A)(1-\\pi_A)} $$\n$$ \\text{PPV}_{A}^{\\text{post}}(0.5) = \\frac{(\\frac{1}{2})(0.25)}{(\\frac{1}{2})(0.25) + (\\frac{1}{8})(0.75)} = \\frac{0.125}{0.125 + 0.09375} = \\frac{0.125}{0.21875} = \\frac{4}{7} $$\n\n**Group B:**\nThe condition is $r_B(s) = c_B(s) \\geq 0.5$. From the definition of $c_B(s)$, this holds only when $c_B(s) = 0.55$, which corresponds to $s \\in [0.6, 1.0]$. Let the event be $C_B^{\\text{post}} \\equiv s \\geq 0.6$. We compute the conditional probabilities:\n- $\\mathbb{P}(s \\geq 0.6 \\mid Y=1, B)$: For $s \\sim \\text{Uniform}[0.2, 0.9]$, this probability is $\\frac{0.9 - 0.6}{0.9 - 0.2} = \\frac{0.3}{0.7} = \\frac{3}{7}$.\n- $\\mathbb{P}(s \\geq 0.6 \\mid Y=0, B)$: For $s \\sim \\text{Uniform}[0.0, 0.7]$, this probability is $\\frac{0.7 - 0.6}{0.7 - 0.0} = \\frac{0.1}{0.7} = \\frac{1}{7}$.\n\nNow, we compute $\\text{PPV}_B^{\\text{post}}(0.5)$:\n$$ \\text{PPV}_{B}^{\\text{post}}(0.5) = \\frac{\\mathbb{P}(s \\geq 0.6 \\mid Y=1, B)\\pi_B}{\\mathbb{P}(s \\geq 0.6 \\mid Y=1, B)\\pi_B + \\mathbb{P}(s \\geq 0.6 \\mid Y=0, B)(1-\\pi_B)} $$\n$$ \\text{PPV}_{B}^{\\text{post}}(0.5) = \\frac{(\\frac{3}{7})(0.40)}{(\\frac{3}{7})(0.40) + (\\frac{1}{7})(0.60)} = \\frac{1.2/7}{1.2/7 + 0.6/7} = \\frac{1.2/7}{1.8/7} = \\frac{1.2}{1.8} = \\frac{2}{3} $$\n\nThe absolute predictive parity gap after recalibration is:\n$$ |\\text{PPV}_{A}^{\\text{post}}(0.5) - \\text{PPV}_{B}^{\\text{post}}(0.5)| = \\left|\\frac{4}{7} - \\frac{2}{3}\\right| = \\left|\\frac{12 - 14}{21}\\right| = \\frac{2}{21} $$\n\n### 2. Pre-Recalibration Analysis\n\nThe positive test condition before recalibration uses the raw score $s$. The event is $C_g^{\\text{pre}} \\equiv s \\geq t$, where $t=0.5$.\n\n**Group A:**\nThe event is $s \\geq 0.5$. We compute the conditional probabilities:\n- $\\mathbb{P}(s \\geq 0.5 \\mid Y=1, A)$: For $s \\sim \\text{Uniform}[0.4, 1.0]$, this probability is $\\frac{1.0 - 0.5}{1.0 - 0.4} = \\frac{0.5}{0.6} = \\frac{5}{6}$.\n- $\\mathbb{P}(s \\geq 0.5 \\mid Y=0, A)$: For $s \\sim \\text{Uniform}[0.0, 0.8]$, this probability is $\\frac{0.8 - 0.5}{0.8 - 0.0} = \\frac{0.3}{0.8} = \\frac{3}{8}$.\n\nNow, we compute $\\text{PPV}_A^{\\text{pre}}(0.5)$:\n$$ \\text{PPV}_{A}^{\\text{pre}}(0.5) = \\frac{(\\frac{5}{6})(0.25)}{(\\frac{5}{6})(0.25) + (\\frac{3}{8})(0.75)} = \\frac{5/24}{5/24 + 9/32} = \\frac{20/96}{20/96 + 27/96} = \\frac{20/96}{47/96} = \\frac{20}{47} $$\n\n**Group B:**\nThe event is $s \\geq 0.5$. We compute the conditional probabilities:\n- $\\mathbb{P}(s \\geq 0.5 \\mid Y=1, B)$: For $s \\sim \\text{Uniform}[0.2, 0.9]$, this probability is $\\frac{0.9 - 0.5}{0.9 - 0.2} = \\frac{0.4}{0.7} = \\frac{4}{7}$.\n- $\\mathbb{P}(s \\geq 0.5 \\mid Y=0, B)$: For $s \\sim \\text{Uniform}[0.0, 0.7]$, this probability is $\\frac{0.7 - 0.5}{0.7 - 0.0} = \\frac{0.2}{0.7} = \\frac{2}{7}$.\n\nNow, we compute $\\text{PPV}_B^{\\text{pre}}(0.5)$:\n$$ \\text{PPV}_{B}^{\\text{pre}}(0.5) = \\frac{(\\frac{4}{7})(0.40)}{(\\frac{4}{7})(0.40) + (\\frac{2}{7})(0.60)} = \\frac{1.6/7}{1.6/7 + 1.2/7} = \\frac{1.6/7}{2.8/7} = \\frac{1.6}{2.8} = \\frac{4}{7} $$\n\nThe absolute predictive parity gap before recalibration is:\n$$ |\\text{PPV}_{A}^{\\text{pre}}(0.5) - \\text{PPV}_{B}^{\\text{pre}}(0.5)| = \\left|\\frac{20}{47} - \\frac{4}{7}\\right| = \\left|\\frac{140 - 188}{329}\\right| = \\frac{48}{329} $$\n\n### 3. Change in Absolute Predictive Parity Gap\n\nThe change is the pre-recalibration gap minus the post-recalibration gap.\n$$ \\text{Change} = |\\text{PPV}_{A}^{\\text{pre}}(0.5) - \\text{PPV}_{B}^{\\text{pre}}(0.5)| - |\\text{PPV}_{A}^{\\text{post}}(0.5) - \\text{PPV}_{B}^{\\text{post}}(0.5)| $$\n$$ \\text{Change} = \\frac{48}{329} - \\frac{2}{21} $$\nTo compute the value, we convert to decimals:\n$$ \\frac{48}{329} \\approx 0.1458966... $$\n$$ \\frac{2}{21} \\approx 0.0952381... $$\n$$ \\text{Change} \\approx 0.1458966 - 0.0952381 = 0.0506585... $$\nRounding to four significant figures, the change is $0.05066$.\n\n### Discussion of Tradeoffs\n\nPerforming group-specific isotonic recalibration involves several tradeoffs between statistical properties and fairness principles.\n\n1.  **Calibration:** The procedure is designed to improve calibration within each group. The new scores $r_g(s)$ should, on average, be better estimates of the true conditional probability of readmission $\\mathbb{P}(Y=1 \\mid s, g)$ than the original scores $s$. This makes the model's outputs more interpretable and reliable for clinicians using them for group-specific risk assessment.\n\n2.  **Predictive Parity:** This fairness metric demands that the PPV be equal across groups ($\\text{PPV}_A = \\text{PPV}_B$). Our calculations show:\n    - Pre-recalibration gap: $|\\frac{20}{47} - \\frac{4}{7}| \\approx |0.426 - 0.571| = 0.145$.\n    - Post-recalibration gap: $|\\frac{4}{7} - \\frac{2}{3}| \\approx |0.571 - 0.667| = 0.096$.\n    In this specific case, group-specific recalibration reduced the predictive parity gap. The PPV for both groups increased, but the disparity between them lessened. This is a positive outcome from a predictive parity perspective. However, this is not a guaranteed outcome of group-specific recalibration; it could increase the gap in other scenarios.\n\n3.  **Decision Consistency (Individual Fairness):** This is where a significant tradeoff emerges. Before recalibration, any patient with a raw score $s \\geq 0.5$ would be flagged, regardless of their group. After recalibration, the decision to flag a patient depends on both their score *and* their group:\n    - A Group A patient is flagged if $s \\geq 0.7$.\n    - A Group B patient is flagged if $s \\geq 0.6$.\n    This creates a situation where two patients with the same initial risk score (e.g., $s=0.65$) receive different treatments based on their group membership. A patient from Group A with $s=0.65$ is not flagged, while a patient from Group B with the same score is flagged. This violates the principle of \"treatment equality\" or \"individual fairness,\" which posits that individuals with identical characteristics (in this case, the same raw score $s$) should be treated identically by the algorithm.\n\nIn summary, while group-specific recalibration can improve within-group calibration and, in this instance, also improved group-level fairness (predictive parity), it does so at the cost of violating individual-level fairness by creating group-dependent decision rules. This tradeoff is a central challenge in deploying fair machine learning models in practice.", "answer": "$$\n\\boxed{0.05066}\n$$", "id": "4390107"}]}