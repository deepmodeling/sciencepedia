{"hands_on_practices": [{"introduction": "Proactively identifying and prioritizing risks is a cornerstone of quality improvement. The Failure Mode and Effects Analysis (FMEA) is a widely used method for this purpose, but its traditional Risk Priority Number (RPN) has known limitations. This exercise [@problem_id:4393374] challenges you to not only apply the standard RPN calculation but also to critically evaluate its mathematical basis and develop a more robust, model-based metric for expected harm, grounding your risk assessment in sound quantitative principles.", "problem": "A hospital pharmacy undertakes a Failure Mode and Effects Analysis (FMEA) to improve safety in its medication-ordering process. The team rates three distinct failure modes using the standard $1$ to $10$ ordinal scales for severity, occurrence, and detection difficulty. Let severity be denoted by $s$, occurrence by $o$, and detection difficulty by $d$. The three failure modes and their ratings are:\n\nFailure mode $\\mathrm{A}$: $s=7$, $o=3$, $d=7$.\n\nFailure mode $\\mathrm{B}$: $s=5$, $o=8$, $d=2$.\n\nFailure mode $\\mathrm{C}$: $s=9$, $o=2$, $d=9$.\n\nUsing widely accepted practice, the Risk Priority Number (RPN) is defined as the multiplicative aggregation of the three ratings. Compute the RPN for each failure mode.\n\nNext, starting from core definitions in probability and expected value, critically examine whether multiplying three ordinal ratings yields a cardinal risk quantity that is interpretable on a meaningful scale. Then, derive a more principled prioritization metric based on expected harm per medication order under the following scientifically grounded modeling assumptions:\n\n- Severity mapping: Let the harm magnitude function be $h(s)=\\exp(\\alpha\\,(s-6))$. Calibrate $\\alpha$ using the anchor that a severity rating of $s=8$ represents four times the harm of a severity rating of $s=6$.\n\n- Occurrence mapping: Let the base probability of the failure mode occurring on a single medication order be $p(o)=\\gamma\\,o$. Assume that at $o=10$ the base probability is $p_{\\max}=0.02$ per order, and determine $\\gamma$ accordingly.\n\n- Detection mapping: Let the probability that the failure escapes detection be $q(d)=\\frac{d}{10}$.\n\nAssume independence between the occurrence of the failure and detection processes, and define the expected harm per order for failure mode $i$ as $E_i=h(s_i)\\,p(o_i)\\,q(d_i)$. For each failure mode, compute $E_i$ and identify which failure mode should be prioritized under this expected harm metric. Finally, report the expected harm of the prioritized failure mode per $1{,}000$ medication orders. Round your final numerical answer to four significant figures and express it in relative harm units per $1{,}000$ orders.", "solution": "The first part of the problem requires the computation of the Risk Priority Number (RPN) for three failure modes. The RPN is defined as the product of the ratings for severity ($s$), occurrence ($o$), and detection difficulty ($d$). The formula is $\\text{RPN} = s \\times o \\times d$.\n\nFor Failure Mode $\\mathrm{A}$, with $s_A=7$, $o_A=3$, and $d_A=7$:\n$$ \\text{RPN}_A = 7 \\times 3 \\times 7 = 147 $$\n\nFor Failure Mode $\\mathrm{B}$, with $s_B=5$, $o_B=8$, and $d_B=2$:\n$$ \\text{RPN}_B = 5 \\times 8 \\times 2 = 80 $$\n\nFor Failure Mode $\\mathrm{C}$, with $s_C=9$, $o_C=2$, and $d_C=9$:\n$$ \\text{RPN}_C = 9 \\times 2 \\times 9 = 162 $$\n\nBased on these RPN values, the prioritization order would be $\\mathrm{C} > \\mathrm{A} > \\mathrm{B}$.\n\nThe second part of the problem asks for a critical examination of the practice of multiplying ordinal ratings to yield a cardinal risk quantity. The ratings for severity, occurrence, and detection are provided on $1$-to-$10$ ordinal scales. Ordinal scales preserve only rank order; for instance, a severity of $s=8$ is understood to be more severe than $s=4$, but it cannot be concluded that it is \"twice as severe\". The intervals between consecutive numbers on the scale are not guaranteed to be uniform or meaningful. Arithmetic operations such as multiplication are mathematically defined for cardinal (specifically, ratio) scales, where there is a true, non-arbitrary zero and equal intervals between scale points. Multiplying numbers from ordinal scales is a mathematically invalid operation because it treats the ordinal ranks as if they were cardinal quantities. The resulting RPN is a dimensionless index, not a cardinal quantity with a clear, interpretable meaning. An RPN of $200$ is not necessarily twice the risk of an RPN of $100$. This method can also produce misleading priorities, as different combinations of $s$, $o$, and $d$ (e.g., $s=10, o=2, d=5$ versus $s=5, o=5, d=4$) can yield the same RPN ($100$) despite representing qualitatively different risk profiles. The multiplicative model implicitly assumes relationships (e.g., linearity, equal weight) between the scales and risk that are not justified a priori.\n\nThe third part requires deriving a more principled metric based on expected harm per order, $E_i=h(s_i)\\,p(o_i)\\,q(d_i)$. This requires calibrating the functions $h(s)$, $p(o)$, and $q(d)$.\n\nFirst, we calibrate the harm magnitude function, $h(s)=\\exp(\\alpha\\,(s-6))$.\nThe calibration condition is that a severity of $s=8$ represents four times the harm of $s=6$, which translates to $h(8) = 4 \\times h(6)$.\nSubstituting the function definition:\n$$ \\exp(\\alpha\\,(8-6)) = 4 \\times \\exp(\\alpha\\,(6-6)) $$\n$$ \\exp(2\\alpha) = 4 \\times \\exp(0) = 4 \\times 1 = 4 $$\nTaking the natural logarithm of both sides:\n$$ \\ln(\\exp(2\\alpha)) = \\ln(4) $$\n$$ 2\\alpha = \\ln(2^2) = 2\\ln(2) $$\n$$ \\alpha = \\ln(2) $$\nThus, the harm function is $h(s) = \\exp(\\ln(2)\\,(s-6)) = (\\exp(\\ln(2)))^{s-6} = 2^{s-6}$. The harm is measured in relative units where $h(6)=1$.\n\nNext, we calibrate the occurrence probability function, $p(o)=\\gamma\\,o$.\nThe condition is that at $o=10$, the probability is $p(10) = p_{\\max} = 0.02$.\n$$ \\gamma \\times 10 = 0.02 $$\n$$ \\gamma = \\frac{0.02}{10} = 0.002 $$\nThus, the occurrence probability function is $p(o) = 0.002\\,o$.\n\nThe probability of a failure escaping detection is given directly as $q(d) = \\frac{d}{10}$.\n\nNow we can write the full expression for the expected harm per order, $E_i$:\n$$ E_i = h(s_i) \\, p(o_i) \\, q(d_i) = (2^{s_i-6}) \\times (0.002 \\cdot o_i) \\times \\left(\\frac{d_i}{10}\\right) $$\n$$ E_i = (0.0002) \\cdot o_i \\cdot d_i \\cdot 2^{s_i-6} $$\n\nWe now compute $E_i$ for each failure mode.\n\nFor Failure Mode $\\mathrm{A}$ ($s_A=7$, $o_A=3$, $d_A=7$):\n$$ E_A = (0.0002) \\times 3 \\times 7 \\times 2^{7-6} = 0.0042 \\times 2^1 = 0.0084 $$\n\nFor Failure Mode $\\mathrm{B}$ ($s_B=5$, $o_B=8$, $d_B=2$):\n$$ E_B = (0.0002) \\times 8 \\times 2 \\times 2^{5-6} = 0.0032 \\times 2^{-1} = 0.0032 \\times 0.5 = 0.0016 $$\n\nFor Failure Mode $\\mathrm{C}$ ($s_C=9$, $o_C=2$, $d_C=9$):\n$$ E_C = (0.0002) \\times 2 \\times 9 \\times 2^{9-6} = 0.0036 \\times 2^3 = 0.0036 \\times 8 = 0.0288 $$\n\nComparing the expected harm values: $E_A = 0.0084$, $E_B = 0.0016$, and $E_C = 0.0288$.\nThe prioritization based on expected harm is $\\mathrm{C} > \\mathrm{A} > \\mathrm{B}$, since $0.0288 > 0.0084 > 0.0016$. In this specific case, the ranking matches the RPN-based ranking. However, the expected harm metric provides a cardinal measure of risk. For example, the risk of failure mode $\\mathrm{C}$ is $E_C/E_A = 0.0288 / 0.0084 \\approx 3.43$ times greater than that of mode $\\mathrm{A}$, whereas the RPN ratio of $\\text{RPN}_C/\\text{RPN}_A = 162/147 \\approx 1.10$ significantly understates this difference. The prioritized failure mode is $\\mathrm{C}$.\n\nThe final task is to report the expected harm of the prioritized failure mode ($\\mathrm{C}$) per $1{,}000$ medication orders. The expected harm per order is $E_C = 0.0288$ relative harm units.\nThe expected harm per $1{,}000$ orders is:\n$$ E_{C, 1000} = E_C \\times 1000 = 0.0288 \\times 1000 = 28.8 $$\nThe problem requires the answer to be rounded to four significant figures.\n$$ 28.80 $$", "answer": "$$\\boxed{28.80}$$", "id": "4393374"}, {"introduction": "Effective quality improvement relies on monitoring key processes to distinguish between normal variation and significant changes that require action. When tracking rates of events, such as infections per patient-days, the opportunity for an event (the denominator) often varies, making simple charts misleading. This practice [@problem_id:4393388] guides you through the derivation of a $u$-chart, a type of statistical process control chart specifically designed for this scenario, using first principles from the Poisson distribution to correctly adjust for varying exposure.", "problem": "A hospital Quality Improvement (QI) team is monitoring Catheter-Associated Urinary Tract Infection (CAUTI) events in an Intensive Care Unit (ICU). Because weekly catheter-day exposure varies, they need a control chart that accounts for variable denominators. Assume that weekly CAUTI counts are rare events occurring independently with a constant rate per catheter-day, and that counts conditional on exposure follow a Poisson model with rate proportional to exposure. Using only these assumptions and the definitions of expectation and variance for the Poisson distribution, derive from first principles the appropriate type of control chart and the expressions for the centerline and the three-standard-deviation control limits for a specified week. Then apply your derivation to the following data.\n\nOver $10$ consecutive weeks, the team collected weekly CAUTI counts $x_i$ and corresponding catheter-day exposures $n_i$:\n- Week $1$: $x_1=0$, $n_1=300$\n- Week $2$: $x_2=1$, $n_2=320$\n- Week $3$: $x_3=0$, $n_3=310$\n- Week $4$: $x_4=1$, $n_4=290$\n- Week $5$: $x_5=0$, $n_5=330$\n- Week $6$: $x_6=1$, $n_6=305$\n- Week $7$: $x_7=0$, $n_7=315$\n- Week $8$: $x_8=0$, $n_8=295$\n- Week $9$: $x_9=1$, $n_9=325$\n- Week $10$: $x_{10}=1$, $n_{10}=300$\n\nTasks:\n1. Justify the selection of a $u$-chart based on the stated assumptions and definitions.\n2. Derive the centerline $\\bar{u}$ from first principles using the pooled data across all weeks.\n3. For Week $6$, derive the three-standard-deviation control limits using your result in Task $2$ and the Poisson-based variance of the rate estimator, and apply the nonnegativity truncation for the lower limit if needed.\n\nReport, in this order, the following three quantities as infections per catheter-day: the centerline $\\bar{u}$ pooled across all weeks, the upper control limit for Week $6$, and the lower control limit for Week $6$. Round each value to four significant figures. Do not rescale to per $1000$ catheter-days; express answers per catheter-day as requested.", "solution": "We begin from the stated data-generating assumptions and core definitions. Let $X_i$ denote the number of CAUTI events in week $i$ with exposure $n_i$ catheter-days. Under the assumption of rare, independent events with a constant rate per catheter-day, a standard and well-tested model is that $X_i$ follows a Poisson distribution with mean proportional to exposure:\n$$\nX_i \\sim \\text{Poisson}(n_i u),\n$$\nwhere $u$ is the underlying CAUTI rate per catheter-day. For a Poisson random variable $Y \\sim \\text{Poisson}(\\lambda)$, the fundamental facts are $\\mathbb{E}[Y]=\\lambda$ and $\\operatorname{Var}(Y)=\\lambda$.\n\nTask $1$ (chart selection): Because the sample size $n_i$ varies by week and the quality characteristic is a count of nonconformities (infections) per unit of opportunity (catheter-day), the appropriate attribute control chart is a $u$-chart, which monitors the count per unit of exposure. The $u$-chart accommodates variable $n_i$ and is grounded in the Poisson model where the variance of the count scales with the exposure.\n\nTask $2$ (centerline derivation): The natural estimator of the weekly rate is\n$$\n\\hat{u}_i = \\frac{X_i}{n_i}.\n$$\nA pooled, unbiased estimator of the common rate $u$ across $k$ weeks is obtained by aggregating counts and exposures:\n$$\n\\bar{u} \\equiv \\frac{\\sum_{i=1}^{k} X_i}{\\sum_{i=1}^{k} n_i}.\n$$\nThis follows from the linearity of expectation:\n$$\n\\mathbb{E}\\!\\left[\\sum_{i=1}^{k} X_i\\right] = \\sum_{i=1}^{k} \\mathbb{E}[X_i] = \\sum_{i=1}^{k} n_i u = u \\sum_{i=1}^{k} n_i,\n$$\nso $\\mathbb{E}[\\bar{u}] = u$. For our data, $k=10$, and we compute\n$$\n\\sum_{i=1}^{10} X_i = x_1+\\cdots+x_{10} = 0+1+0+1+0+1+0+0+1+1 = 5,\n$$\n$$\n\\sum_{i=1}^{10} n_i = 300+320+310+290+330+305+315+295+325+300 = 3090.\n$$\nTherefore,\n$$\n\\bar{u} = \\frac{5}{3090} = \\frac{1}{618}.\n$$\n\nTask $3$ (control limits for Week $6$): For week $i$, the variance of the rate estimator $\\hat{u}_i = X_i/n_i$ is, by the delta method and Poisson variance,\n$$\n\\operatorname{Var}(\\hat{u}_i) = \\operatorname{Var}\\!\\left(\\frac{X_i}{n_i}\\right) = \\frac{\\operatorname{Var}(X_i)}{n_i^{2}} = \\frac{n_i u}{n_i^{2}} = \\frac{u}{n_i}.\n$$\nIn practice, $u$ is unknown and is estimated by $\\bar{u}$, giving an estimated standard deviation for week $i$ of\n$$\n\\widehat{\\sigma}_i = \\sqrt{\\frac{\\bar{u}}{n_i}}.\n$$\nThe three-standard-deviation control limits for week $i$ are then\n$$\n\\text{Centerline: } \\bar{u}, \\quad \\text{Upper limit: } \\bar{u} + 3 \\widehat{\\sigma}_i, \\quad \\text{Lower limit: } \\max\\!\\left(0,\\ \\bar{u} - 3 \\widehat{\\sigma}_i\\right).\n$$\nFor Week $6$, we have $n_6=305$. Using $\\bar{u} = 1/618$, the Week $6$ estimated standard deviation is\n$$\n\\widehat{\\sigma}_6 = \\sqrt{\\frac{\\bar{u}}{n_6}} = \\sqrt{\\frac{1/618}{305}} = \\sqrt{\\frac{1}{618 \\times 305}} = \\sqrt{\\frac{1}{188{,}490}}.\n$$\nThus the Week $6$ limits are\n$$\n\\text{UCL}_6 = \\bar{u} + 3\\widehat{\\sigma}_6 = \\frac{1}{618} + 3\\sqrt{\\frac{1}{188{,}490}},\n$$\n$$\n\\text{LCL}_6 = \\max\\!\\left(0,\\ \\bar{u} - 3\\widehat{\\sigma}_6\\right) = \\max\\!\\left(0,\\ \\frac{1}{618} - 3\\sqrt{\\frac{1}{188{,}490}}\\right).\n$$\nWe now compute numerical values and round to four significant figures, as infections per catheter-day. First, the centerline:\n$$\n\\bar{u} = \\frac{1}{618} \\approx 0.0016181229 \\ \\Rightarrow \\ \\bar{u} \\approx 0.001618 \\ (\\text{four significant figures}).\n$$\nNext, the Week $6$ standard deviation:\n$$\n\\widehat{\\sigma}_6 = \\sqrt{\\frac{1}{188{,}490}} \\approx 0.00230333.\n$$\nTherefore,\n$$\n\\text{UCL}_6 \\approx 0.0016181229 + 3 \\times 0.00230333 \\approx 0.0016181229 + 0.00690999 \\approx 0.00852811 \\ \\Rightarrow \\ 0.008528 \\ (\\text{four significant figures}),\n$$\n$$\n\\text{LCL}_6 \\approx \\max\\!\\left(0,\\ 0.0016181229 - 0.00690999\\right) = 0.\n$$\nReported in the requested order (centerline, Week $6$ upper limit, Week $6$ lower limit) and units (infections per catheter-day), each rounded to four significant figures, the results are:\n$$\n\\bar{u} \\approx 0.001618, \\quad \\text{UCL}_6 \\approx 0.008528, \\quad \\text{LCL}_6 = 0.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0.001618  0.008528  0\\end{pmatrix}}$$", "id": "4393388"}, {"introduction": "Once a process has been brought into a state of statistical control, the next critical question is whether it is capable of meeting performance specifications. This exercise [@problem_id:4393429] introduces process capability analysis, a fundamental QI tool used to quantify the relationship between the natural variation of a process and its required specification limits. You will compute and interpret the key indices $C_p$ and $C_{pk}$ to distinguish between a process's potential and its actual performance, helping to pinpoint where improvement efforts should be focused.", "problem": "A hospitalâ€™s Emergency Department (ED) is assessing the capability of its triage process time relative to an internal service specification defined by a lower specification limit (LSL) of $60$ minutes and an upper specification limit (USL) of $120$ minutes. Over the last month, with stable operations and subgroup sampling supporting approximate normality, the estimated short-term standard deviation is $\\sigma=10$ minutes and the current process mean is $\\mu=95$ minutes. Using only foundational definitions from capability analysis in quality improvement (namely, that the natural process spread is taken as $\\pm 3\\sigma$ under approximate normality and that capability compares specification width to this spread, while accounting for centering by comparing the mean to each specification boundary in standardized units), compute the process capability index $C_p$ and the centered process capability index $C_{pk}$. Report the pair $\\left(C_p,\\,C_{pk}\\right)$ as unitless numbers and round your answers to three significant figures. Then, based on capability analysis principles, briefly interpret which side (upper or lower specification) dominates the operational risk of out-of-specification performance and whether the process appears capable relative to the specification.", "solution": "The objective is to calculate the process capability indices $C_p$ and $C_{pk}$ and interpret the results. These indices measure how well the process output fits within the customer-defined specification limits.\n\nThe process capability index, $C_p$, measures the potential capability of the process by comparing the total specification width to the natural process spread. It does not account for the centering of the process. The problem defines the natural process spread as corresponding to a total width of $6\\sigma$.\n\nThe formula for $C_p$ is:\n$$C_p = \\frac{\\text{Specification Width}}{\\text{Process Spread}} = \\frac{USL - LSL}{6\\sigma}$$\nSubstituting the given values:\n- $USL = 120$ minutes\n- $LSL = 60$ minutes\n- $\\sigma = 10$ minutes\n\n$$C_p = \\frac{120 - 60}{6 \\times 10} = \\frac{60}{60} = 1$$\nTo report this to three significant figures, we write $C_p = 1.00$.\n\nThe centered process capability index, $C_{pk}$, measures the actual capability of the process by accounting for its centering relative to the specification limits. It is defined as the minimum of the upper and lower capability indices, $C_{pu}$ and $C_{pl}$, respectively. These indices measure the distance from the process mean to the nearest specification limit in units of $3\\sigma$.\n\nThe formulas for $C_{pl}$ and $C_{pu}$ are:\n$$C_{pl} = \\frac{\\mu - LSL}{3\\sigma}$$\n$$C_{pu} = \\frac{USL - \\mu}{3\\sigma}$$\nAnd $C_{pk}$ is given by:\n$$C_{pk} = \\min(C_{pl}, C_{pu})$$\nSubstituting the given values:\n- $\\mu = 95$ minutes\n- $LSL = 60$ minutes\n- $USL = 120$ minutes\n- $\\sigma = 10$ minutes\n\nFirst, calculate $C_{pl}$:\n$$C_{pl} = \\frac{95 - 60}{3 \\times 10} = \\frac{35}{30} = \\frac{7}{6} \\approx 1.1666...$$\nNext, calculate $C_{pu}$:\n$$C_{pu} = \\frac{120 - 95}{3 \\times 10} = \\frac{25}{30} = \\frac{5}{6} \\approx 0.8333...$$\nNow, find $C_{pk}$ by taking the minimum of these two values:\n$$C_{pk} = \\min\\left(\\frac{7}{6}, \\frac{5}{6}\\right) = \\frac{5}{6}$$\nConverting this fraction to a decimal and rounding to three significant figures:\n$$C_{pk} \\approx 0.8333... \\approx 0.833$$\nThe resulting pair is $\\left(C_p, C_{pk}\\right) = \\left(1.00, 0.833\\right)$.\n\n### Interpretation\n1.  **Dominant Operational Risk**: The operational risk is determined by a comparison of $C_{pl}$ and $C_{pu}$. Since $C_{pk}$ is the minimum of the two, the side corresponding to the minimum value is the one closer to its specification limit and thus presents the greater risk of producing out-of-specification results. Here, $C_{pu} \\approx 0.833$ is less than $C_{pl} \\approx 1.17$. This indicates that the process mean ($\\mu=95$) is closer to the upper specification limit ($USL=120$) than to the lower specification limit ($LSL=60$), in terms of process standard deviations. Therefore, the **upper specification side dominates the operational risk**, meaning there is a higher probability of triage times exceeding the $120$-minute maximum than falling below the $60$-minute minimum.\n\n2.  **Process Capability**: A widely accepted minimum value for a process to be considered \"capable\" is $C_{pk} \\ge 1.33$. A value of $C_{pk}  1.00$ indicates that the process is not capable, as parts of the natural process distribution fall outside the specification limits. In this case, $C_{pk} \\approx 0.833$, which is significantly less than $1.00$. Therefore, the process is **not capable** of consistently meeting the specified triage time requirements. The value $C_p = 1.00$ indicates that the process variability ($6\\sigma = 60$ min) is exactly as wide as the specification range ($USL - LSL = 60$ min). This means that even if the process were perfectly centered, it would just barely fit within the limits. The fact that $C_{pk}$ is substantially lower than $C_p$ confirms that the primary issue is the process being off-center.", "answer": "$$\\boxed{\\begin{pmatrix} 1.00  0.833 \\end{pmatrix}}$$", "id": "4393429"}]}