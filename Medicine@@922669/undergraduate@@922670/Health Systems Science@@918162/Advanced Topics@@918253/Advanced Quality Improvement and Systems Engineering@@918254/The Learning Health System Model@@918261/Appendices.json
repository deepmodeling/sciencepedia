{"hands_on_practices": [{"introduction": "A core function of the Learning Health System (LHS) is to rigorously evaluate whether changes in care delivery lead to better patient outcomes. This exercise provides hands-on practice with fundamental metrics used in quality improvement, such as Absolute Risk Reduction ($ARR$) and the Number Needed to Treat ($NNT$). By working through this hypothetical scenario of reducing hospital readmissions, you will learn how to quantify an intervention's real-world impact from raw data, a crucial skill for any health systems scientist. [@problem_id:4399949]", "problem": "A health system operating under the Learning Health System (LHS) model continuously measures and analyzes outcomes to iteratively improve care. In a quality improvement cycle aimed at reducing $30$-day unplanned readmissions for patients with chronic heart failure, the system compared a baseline (pre-intervention) quarter to a post-intervention quarter.\n\nDuring the baseline quarter, there were $n_{B} = 800$ discharges, with $x_{B} = 160$ readmissions within $30$ days. During the post-intervention quarter, there were $n_{A} = 900$ discharges, with $x_{A} = 135$ readmissions within $30$ days. Treat readmission risk as a binomial proportion in each quarter. Using only fundamental definitions (risk as proportion), binomial variance, and a Wald normal approximation for the difference in proportions, do the following:\n\n- Derive the baseline and post-intervention risks $p_{B}$ and $p_{A}$ from first principles.\n- Derive the absolute risk reduction (ARR) from these risks based on its definition in health systems science.\n- Derive a $95\\%$ confidence interval (CI) for the ARR using the Wald approximation for a difference in independent binomial proportions.\n- Using the definition connecting the number needed to treat (NNT) to ARR in quality improvement evaluation, obtain the point estimate of the NNT from the ARR and explain the logic of its derivation from the base definitions. You may discuss how one would obtain a CI for NNT by transformation of the ARR CI, but you must still present a single final numeric answer.\n\nRound your final reported number needed to treat to three significant figures. Do not include units in your final answer.", "solution": "The problem statement will first be validated for scientific soundness, completeness, and objectivity before a solution is attempted.\n\n### Step 1: Extract Givens\nThe following data and definitions are explicitly provided in the problem statement:\n- Baseline sample size (discharges): $n_{B} = 800$\n- Baseline number of events (readmissions): $x_{B} = 160$\n- Post-intervention sample size (discharges): $n_{A} = 900$\n- Post-intervention number of events (readmissions): $x_{A} = 135$\n- Confidence level for the confidence interval (CI): $95\\%$\n- Specified method: Wald normal approximation for the difference in independent binomial proportions.\n- Required derivations and definitions:\n    1. Risk as a proportion.\n    2. Absolute Risk Reduction ($ARR$) derived from the risks.\n    3. $95\\%$ CI for the $ARR$.\n    4. Number Needed to Treat ($NNT$) derived from the $ARR$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria:\n- **Scientifically Grounded:** The problem uses standard, well-established concepts from biostatistics and epidemiology, including binomial proportions, the Wald approximation for confidence intervals, Absolute Risk Reduction, and Number Needed to Treat. The context of a Learning Health System (LHS) is a recognized model in health systems science. The problem is scientifically and factually sound.\n- **Well-Posed:** All necessary data ($n_{B}, x_{B}, n_{A}, x_{A}$) and methodological constraints (Wald approximation, $95\\%$ CI) are provided. The tasks are clearly defined, leading to a unique and meaningful solution.\n- **Objective:** The problem is described using precise, quantitative, and unbiased language.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is scientifically sound, well-posed, and objective. A full, reasoned solution will now be provided.\n\n---\n\nThe solution proceeds by following the sequence of derivations requested in the problem statement.\n\n**1. Derivation of Baseline and Post-Intervention Risks**\nThe risk of an outcome in a given population is estimated by the proportion of individuals in a sample who experience that outcome. This is a fundamental principle of frequentist statistics. The problem states that readmission risk should be treated as a binomial proportion.\n\nThe baseline risk, denoted as $p_{B}$, is estimated by the sample proportion $\\hat{p}_{B}$:\n$$ \\hat{p}_{B} = \\frac{\\text{number of baseline readmissions}}{\\text{number of baseline discharges}} = \\frac{x_{B}}{n_{B}} $$\nSubstituting the given values:\n$$ \\hat{p}_{B} = \\frac{160}{800} = 0.2 $$\n\nSimilarly, the post-intervention risk, $p_{A}$, is estimated by the sample proportion $\\hat{p}_{A}$:\n$$ \\hat{p}_{A} = \\frac{\\text{number of post-intervention readmissions}}{\\text{number of post-intervention discharges}} = \\frac{x_{A}}{n_{A}} $$\nSubstituting the given values:\n$$ \\hat{p}_{A} = \\frac{135}{900} = 0.15 $$\n\n**2. Derivation of Absolute Risk Reduction (ARR)**\nIn health systems science and epidemiology, the Absolute Risk Reduction ($ARR$) is a measure of the effectiveness of an intervention. It is defined as the absolute difference between the event rate in the control group (baseline, $p_{B}$) and the event rate in the treatment group (post-intervention, $p_{A}$).\n$$ ARR = p_{B} - p_{A} $$\nA positive $ARR$ indicates that the intervention reduces the risk of the adverse outcome. The point estimate for the $ARR$, denoted $\\widehat{ARR}$, is calculated using the sample proportions:\n$$ \\widehat{ARR} = \\hat{p}_{B} - \\hat{p}_{A} $$\nUsing the derived risks:\n$$ \\widehat{ARR} = 0.2 - 0.15 = 0.05 $$\n\n**3. Derivation of the 95% Confidence Interval for ARR**\nThe problem requires the use of the Wald normal approximation. This method assumes that the sampling distribution of the difference in proportions, $\\hat{p}_{B} - \\hat{p}_{A}$, is approximately normal. The standard error ($SE$) of this difference is derived from the variances of the individual proportion estimates. Since the two samples are independent, the variance of the difference is the sum of their variances:\n$$ Var(\\hat{p}_{B} - \\hat{p}_{A}) = Var(\\hat{p}_{B}) + Var(\\hat{p}_{A}) = \\frac{p_{B}(1-p_{B})}{n_{B}} + \\frac{p_{A}(1-p_{A})}{n_{A}} $$\nThe Wald method estimates this variance by substituting the sample proportions $\\hat{p}_{B}$ and $\\hat{p}_{A}$ for the true population proportions $p_{B}$ and $p_{A}$. The standard error is the square root of this estimated variance:\n$$ SE(\\hat{p}_{B} - \\hat{p}_{A}) = \\sqrt{\\frac{\\hat{p}_{B}(1-\\hat{p}_{B})}{n_{B}} + \\frac{\\hat{p}_{A}(1-\\hat{p}_{A})}{n_{A}}} $$\nSubstituting the numerical values:\n$$ SE = \\sqrt{\\frac{0.2(1-0.2)}{800} + \\frac{0.15(1-0.15)}{900}} = \\sqrt{\\frac{0.16}{800} + \\frac{0.1275}{900}} $$\n$$ SE = \\sqrt{0.0002 + 0.000141\\overline{6}} = \\sqrt{0.000341\\overline{6}} \\approx 0.018484 $$\nA $95\\%$ confidence interval for the $ARR$ is constructed using the formula:\n$$ CI_{95\\%} = \\widehat{ARR} \\pm z_{1-\\alpha/2} \\cdot SE $$\nFor a $95\\%$ confidence level, $\\alpha=0.05$, so $1-\\alpha/2 = 0.975$. The corresponding critical value from the standard normal distribution is $z_{0.975} = 1.96$.\nThe margin of error ($ME$) is:\n$$ ME = 1.96 \\times 0.018484 \\approx 0.036229 $$\nThe $95\\%$ CI for the $ARR$ is therefore:\n$$ CI_{95\\%} = 0.05 \\pm 0.036229 = (0.013771, 0.086229) $$\n\n**4. Derivation and Calculation of the Number Needed to Treat (NNT)**\nThe Number Needed to Treat ($NNT$) is a metric representing the average number of patients who need to be treated with the specific intervention to prevent one additional adverse outcome. Its derivation follows directly from the definition of the $ARR$.\n\nThe $ARR$ is the number of adverse outcomes prevented per patient treated. If we treat a total of $N$ patients, the total number of adverse outcomes prevented is $N \\times ARR$. The $NNT$ is the specific value of $N$ for which exactly one adverse outcome is prevented. Thus, we set this product equal to $1$:\n$$ NNT \\times ARR = 1 $$\nSolving for $NNT$ gives its fundamental definition:\n$$ NNT = \\frac{1}{ARR} $$\nThe point estimate for the $NNT$, denoted $\\widehat{NNT}$, is the reciprocal of the point estimate for the $ARR$:\n$$ \\widehat{NNT} = \\frac{1}{\\widehat{ARR}} $$\nUsing the calculated $\\widehat{ARR}$:\n$$ \\widehat{NNT} = \\frac{1}{0.05} = 20 $$\nThis result signifies that, on average, $20$ patients with chronic heart failure must be managed under the new intervention protocol to prevent one unplanned $30$-day readmission.\n\nA confidence interval for the $NNT$ can be obtained by inverting the endpoints of the confidence interval for the $ARR$. It is important to note that the lower bound of the $ARR$ CI corresponds to the upper bound of the $NNT$ CI, and vice versa: $CI_{NNT} = (\\frac{1}{CI_{ARR, upper}}, \\frac{1}{CI_{ARR, lower}})$. Using our calculated values, this would be $(\\frac{1}{0.086229}, \\frac{1}{0.013771})$, which is approximately $(11.6, 72.6)$. As the problem requires a single final numeric answer for the NNT point estimate, we report the value of $20$.\n\nThe problem requires reporting this point estimate to three significant figures. To express $20$ with three significant figures, we write it as $20.0$.", "answer": "$$\\boxed{20.0}$$", "id": "4399949"}, {"introduction": "While measuring an intervention's effect is critical, interpreting that effect wisely is equally important, especially when using observational data common in an LHS. This practice introduces the E-value, a sensitivity analysis tool that helps us assess the robustness of our findings against potential unmeasured confounding. Calculating the E-value for an observed risk ratio allows you to quantify the strength of a hypothetical confounder needed to entirely explain away a result, adding a crucial layer of critical appraisal to evidence generated within the LHS cycle. [@problem_id:4399955]", "problem": "A hospital’s Learning Health System (LHS) is considering scale-up of a new inpatient care coordination program. A rapid-cycle evaluation compares outcomes for patients exposed to the program versus usual care and estimates a Risk Ratio (RR) for thirty-day readmission of $RR = 0.75$ after adjusting for measured covariates. Decision-makers ask whether unmeasured confounding could fully explain away the observed protective association, and they request the computation of the E-value to quantify the minimum strength of association that an unmeasured confounder would need to have with both the exposure and the outcome, conditional on measured covariates, to move the true effect to the null.\n\nStarting only from core definitions and well-tested facts acceptable in health systems science and epidemiology:\n- The Risk Ratio (RR) is defined as $RR = \\frac{P(Y=1 \\mid A=1)}{P(Y=1 \\mid A=0)}$, where $A$ denotes exposure to the program and $Y$ denotes readmission.\n- An unmeasured confounder $U$ can induce bias in the observed association. Let $RR_{EU}$ denote the association between exposure $A$ and the confounder $U$ on the risk ratio scale, and let $RR_{UD}$ denote the association between the confounder $U$ and the outcome $Y$ on the risk ratio scale, both conditional on measured covariates.\n- A well-tested bounding relationship for the bias from unmeasured confounding on the risk ratio scale is captured by a bias factor $B$ that depends on $RR_{EU}$ and $RR_{UD}$.\n\nUsing these foundations, derive the expression for the minimum value $E$ (the E-value) such that if $RR_{EU} \\leq E$ and $RR_{UD} \\leq E$, the bias could be large enough to move the true risk ratio to $1$ (the null), starting from an observed $RR = 0.75$. Then compute the E-value for $RR = 0.75$. Provide your final answer as a single real number. No rounding is required, and no units are to be reported in the final answer.", "solution": "The problem asks for the derivation of the formula for the E-value and its computation for an observed Risk Ratio ($RR$) of $0.75$. The E-value quantifies the minimum strength of association an unmeasured confounder would need to have with both the exposure and the outcome to explain away an observed association.\n\nLet the observed risk ratio be denoted by $RR_{obs}$. Let the true, unconfounded, causal risk ratio be denoted by $RR_{true}$. The observed and true risk ratios are related by a bias factor, $B$, which accounts for the effect of confounding. For an unmeasured confounder $U$, the relationship can be expressed as:\n$$ RR_{true} = RR_{obs} \\times B $$\nThe problem asks for the condition under which the observed protective association ($RR_{obs} = 0.75$) could be fully explained by confounding. This corresponds to a scenario where the true causal effect is null, i.e., $RR_{true} = 1$. Substituting $RR_{true} = 1$ into the equation gives:\n$$ 1 = RR_{obs} \\times B $$\nThis implies that to nullify the observed association, the bias factor must have a magnitude of:\n$$ B = \\frac{1}{RR_{obs}} $$\nFor the given value $RR_{obs} = 0.75$, the required bias factor is $B = \\frac{1}{0.75} = \\frac{4}{3}$.\n\nThe problem states that a well-tested bounding relationship exists for the bias factor. This relationship, derived from the work of Cornfield and others, provides an upper bound on the magnitude of the bias factor $B$ that can be produced by an unmeasured confounder $U$. Let $RR_{EU}$ be the risk ratio relating the exposure $A$ to the confounder $U$, i.e., $RR_{EU} = \\frac{P(U=1|A=1, C)}{P(U=1|A=0, C)}$, and let $RR_{UD}$ be the risk ratio relating the confounder $U$ to the outcome (disease) $Y$, i.e., $RR_{UD} = \\frac{P(Y=1|U=1, A, C)}{P(Y=1|U=0, A, C)}$, where $C$ represents the set of measured covariates. To create the bias necessary to shift a true null effect to an observed effect, or vice-versa, the bias factor $B$ is bounded by:\n$$ B \\leq \\frac{RR_{EU} \\cdot RR_{UD}}{RR_{EU} + RR_{UD} - 1} $$\nFor unmeasured confounding to be a complete explanation for the observed association, the maximum possible bias, $B_{max}$, must be at least as large as the required bias, $1/RR_{obs}$. Thus, we must have:\n$$ \\frac{1}{RR_{obs}} \\leq \\frac{RR_{EU} \\cdot RR_{UD}}{RR_{EU} + RR_{UD} - 1} $$\n\nThe E-value, which we will denote as $E$, is defined as the minimum value such that if $RR_{EU} \\leq E$ and $RR_{UD} \\leq E$, the bias could be large enough to explain away the effect. This corresponds to finding the minimum common value for $RR_{EU}$ and $RR_{UD}$ that satisfies this inequality. We set $RR_{EU} = E$ and $RR_{UD} = E$ and solve the equality condition, which represents the minimum threshold:\n$$ \\frac{1}{RR_{obs}} = \\frac{E \\cdot E}{E + E - 1} = \\frac{E^2}{2E - 1} $$\nLet us define $R' = \\frac{1}{RR_{obs}}$. Since we are given $RR_{obs} = 0.75 < 1$, we have $R' > 1$. The equation becomes:\n$$ R' = \\frac{E^2}{2E - 1} $$\nRearranging this equation gives a quadratic equation for $E$:\n$$ R'(2E - 1) = E^2 $$\n$$ 2R'E - R' = E^2 $$\n$$ E^2 - 2R'E + R' = 0 $$\nWe solve this equation for $E$ using the quadratic formula, $E = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$, with $a=1$, $b=-2R'$, and $c=R'$.\n$$ E = \\frac{-(-2R') \\pm \\sqrt{(-2R')^2 - 4(1)(R')}}{2(1)} $$\n$$ E = \\frac{2R' \\pm \\sqrt{4(R')^2 - 4R'}}{2} $$\n$$ E = \\frac{2R' \\pm 2\\sqrt{(R')^2 - R'}}{2} $$\n$$ E = R' \\pm \\sqrt{R'(R' - 1)} $$\nThe E-value must be greater than or equal to $1$, as it represents a risk ratio. Since $R' > 1$, the term under the square root is positive. The larger root is $E_+ = R' + \\sqrt{R'(R' - 1)}$. The smaller root is $E_- = R' - \\sqrt{R'(R' - 1)}$. We can show that $E_- \\leq 1$, which is not a meaningful value for the strength of a confounder association needed to create bias. The conventional definition of the E-value, therefore, takes the larger root, which is guaranteed to be greater than $1$ for $R' > 1$.\nThus, the expression for the E-value for a protective association ($RR_{obs} < 1$) is:\n$$ E = \\frac{1}{RR_{obs}} + \\sqrt{\\frac{1}{RR_{obs}} \\left( \\frac{1}{RR_{obs}} - 1 \\right)} $$\nNow we compute the E-value for the given observed risk ratio, $RR_{obs} = 0.75$.\nFirst, we find the risk ratio on the scale greater than $1$:\n$$ \\frac{1}{RR_{obs}} = \\frac{1}{0.75} = \\frac{1}{3/4} = \\frac{4}{3} $$\nSubstitute this value into the derived expression for $E$:\n$$ E = \\frac{4}{3} + \\sqrt{\\frac{4}{3} \\left( \\frac{4}{3} - 1 \\right)} $$\n$$ E = \\frac{4}{3} + \\sqrt{\\frac{4}{3} \\left( \\frac{4-3}{3} \\right)} $$\n$$ E = \\frac{4}{3} + \\sqrt{\\frac{4}{3} \\cdot \\frac{1}{3}} $$\n$$ E = \\frac{4}{3} + \\sqrt{\\frac{4}{9}} $$\n$$ E = \\frac{4}{3} + \\frac{2}{3} $$\n$$ E = \\frac{6}{3} $$\n$$ E = 2 $$\nThe E-value is $2$. This means that an unmeasured confounder associated with both the care coordination program and hospital readmission by a risk ratio of at least $2$ each, conditional on the measured covariates, could potentially explain away the observed protective effect of $RR = 0.75$.", "answer": "$$\\boxed{2}$$", "id": "4399955"}, {"introduction": "As Learning Health Systems increasingly deploy predictive algorithms to guide clinical decisions, ensuring these tools are fair and equitable is a paramount ethical and clinical responsibility. This practice simulates a model fairness audit, a vital activity in a mature LHS. You will calculate key performance metrics like sensitivity, specificity, and calibration for different demographic groups and check them against predefined fairness constraints, providing direct experience with the analytical work needed to prevent algorithmic bias in healthcare. [@problem_id:4399936]", "problem": "A hospital participating in a Learning Health System (LHS) deploys a readmission risk model and continuously evaluates its performance by subgroup to ensure equity. For two demographic subgroups, denoted Group A and Group B, the model outputs predicted probabilities $\\hat{p}$ for $n=8$ patients per group along with binary outcomes $y \\in \\{0,1\\}$ where $y=1$ indicates a readmission within $30$ days. Classification uses a fixed threshold $\\tau = 0.5$. The hospital’s governance committee has articulated fairness constraints for monitoring within the LHS as follows: absolute difference in sensitivity between groups must be at most $\\delta_{\\text{sens}} = 0.1$; absolute difference in specificity between groups must be at most $\\delta_{\\text{spec}} = 0.1$; and each group’s calibration slope must lie in the closed interval $[0.9, 1.1]$. For this problem, define the calibration slope for a group as the slope $\\beta$ of the Ordinary Least Squares (OLS) linear regression $y = \\alpha + \\beta \\hat{p} + \\varepsilon$ fit within that group.\n\nThe data for Group A (eight patients) are the $(y,\\hat{p})$ pairs:\n$(1, 0.95)$, $(1, 0.85)$, $(1, 0.60)$, $(1, 0.55)$, $(0, 0.45)$, $(0, 0.40)$, $(0, 0.15)$, $(0, 0.05)$.\n\nThe data for Group B (eight patients) are:\n$(1, 0.85)$, $(1, 0.60)$, $(1, 0.45)$, $(1, 0.15)$, $(0, 0.95)$, $(0, 0.55)$, $(0, 0.40)$, $(0, 0.05)$.\n\nUsing only fundamental definitions, do the following:\n1. For each group, compute sensitivity and specificity at threshold $\\tau = 0.5$.\n2. For each group, compute the calibration slope $\\beta$ as defined above.\n3. Determine if any fairness constraint is violated and encode the result as $v$, where $v=1$ if any of the constraints fail and $v=0$ otherwise.\n\nProvide the final answer as a single row matrix in the order\n$[\\text{sensitivity}_{A}, \\text{specificity}_{A}, \\text{slope}_{A}, \\text{sensitivity}_{B}, \\text{specificity}_{B}, \\text{slope}_{B}, v]$.\nExpress all quantities exactly as fractions where applicable; do not round. No units are required. Percentages, if any, must be expressed as decimals or fractions without the percentage sign.", "solution": "The problem requires the calculation of several performance and fairness metrics for a clinical prediction model applied to two demographic subgroups, Group A and Group B. We must compute sensitivity, specificity, and calibration slope for each group, and then determine if any of the specified fairness constraints are violated.\n\nFirst, we define the necessary quantities.\nThe number of patients in each group is $n=8$. The binary outcome is $y \\in \\{0,1\\}$, where $y=1$ signifies a readmission. The predicted probability of readmission is $\\hat{p}$. The classification threshold is $\\tau = 0.5$. A patient is predicted positive if $\\hat{p} \\geq 0.5$ and negative if $\\hat{p} < 0.5$.\n\nThe metrics are defined as:\n- Sensitivity (True Positive Rate): $\\text{sens} = \\frac{TP}{TP+FN}$, where $TP$ (True Positives) are cases with $y=1$ and $\\hat{p} \\geq \\tau$, and $FN$ (False Negatives) are cases with $y=1$ and $\\hat{p} < \\tau$. The denominator $TP+FN$ is the total number of actual positives, $P$.\n- Specificity (True Negative Rate): $\\text{spec} = \\frac{TN}{TN+FP}$, where $TN$ (True Negatives) are cases with $y=0$ and $\\hat{p} < \\tau$, and $FP$ (False Positives) are cases with $y=0$ and $\\hat{p} \\geq \\tau$. The denominator $TN+FP$ is the total number of actual negatives, $N$.\n- Calibration Slope: The slope $\\beta$ of the Ordinary Least Squares (OLS) regression line $y = \\alpha + \\beta \\hat{p} + \\varepsilon$. The formula for the OLS slope $\\beta$ is $\\beta = \\frac{\\sum_{i=1}^{n} (\\hat{p}_i - \\bar{\\hat{p}})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (\\hat{p}_i - \\bar{\\hat{p}})^2}$, where $\\bar{\\hat{p}}$ and $\\bar{y}$ are the sample means of $\\hat{p}$ and $y$ respectively.\n\nThe fairness constraints are:\n1. $|\\text{sens}_A - \\text{sens}_B| \\leq \\delta_{\\text{sens}} = 0.1$\n2. $|\\text{spec}_A - \\text{spec}_B| \\leq \\delta_{\\text{spec}} = 0.1$\n3. $\\beta_A \\in [0.9, 1.1]$ and $\\beta_B \\in [0.9, 1.1]$\n\nA violation indicator $v$ is set to $1$ if any constraint is violated, and $0$ otherwise.\n\n**Analysis for Group A**\nThe data for Group A are:\n$(1, 0.95), (1, 0.85), (1, 0.60), (1, 0.55), (0, 0.45), (0, 0.40), (0, 0.15), (0, 0.05)$.\nThere are $P_A=4$ actual positives and $N_A=4$ actual negatives.\n\nFor sensitivity and specificity at $\\tau = 0.5$:\n- For the $4$ actual positives ($y=1$), the predicted probabilities are $0.95, 0.85, 0.60, 0.55$. All are $\\geq 0.5$. Thus, $TP_A=4$ and $FN_A=0$.\n- For the $4$ actual negatives ($y=0$), the predicted probabilities are $0.45, 0.40, 0.15, 0.05$. All are $< 0.5$. Thus, $TN_A=4$ and $FP_A=0$.\n\nSensitivity for Group A:\n$\\text{sens}_A = \\frac{TP_A}{P_A} = \\frac{4}{4} = 1$.\n\nSpecificity for Group A:\n$\\text{spec}_A = \\frac{TN_A}{N_A} = \\frac{4}{4} = 1$.\n\nFor the calibration slope $\\beta_A$, we let $x_i = \\hat{p}_i$ and $y_i = y_i$.\n$\\sum y_i = 1+1+1+1 = 4$, so $\\bar{y}_A = \\frac{4}{8} = \\frac{1}{2}$.\n$\\sum x_i = 0.95+0.85+0.60+0.55+0.45+0.40+0.15+0.05 = 4.00$, so $\\bar{x}_A = \\frac{4}{8} = \\frac{1}{2}$.\nThe numerator of $\\beta_A$ is $S_{xy,A} = \\sum (x_i - \\bar{x}_A)(y_i - \\bar{y}_A) = \\sum x_i y_i - n\\bar{x}_A\\bar{y}_A$.\n$\\sum x_i y_i = (0.95 \\times 1) + (0.85 \\times 1) + (0.60 \\times 1) + (0.55 \\times 1) = 2.95$.\n$S_{xy,A} = 2.95 - 8 \\times \\frac{1}{2} \\times \\frac{1}{2} = 2.95 - 2 = 0.95 = \\frac{19}{20}$.\nThe denominator of $\\beta_A$ is $S_{xx,A} = \\sum (x_i - \\bar{x}_A)^2 = \\sum x_i^2 - n\\bar{x}_A^2$.\n$\\sum x_i^2 = 0.95^2 + 0.85^2 + 0.60^2 + 0.55^2 + 0.45^2 + 0.40^2 + 0.15^2 + 0.05^2 = 0.9025 + 0.7225 + 0.3600 + 0.3025 + 0.2025 + 0.1600 + 0.0225 + 0.0025 = 2.675$.\n$S_{xx,A} = 2.675 - 8 \\times (\\frac{1}{2})^2 = 2.675 - 2 = 0.675 = \\frac{675}{1000} = \\frac{27}{40}$.\n$\\beta_A = \\frac{S_{xy,A}}{S_{xx,A}} = \\frac{19/20}{27/40} = \\frac{19}{20} \\times \\frac{40}{27} = \\frac{38}{27}$.\n\n**Analysis for Group B**\nThe data for Group B are:\n$(1, 0.85), (1, 0.60), (1, 0.45), (1, 0.15), (0, 0.95), (0, 0.55), (0, 0.40), (0, 0.05)$.\nThere are $P_B=4$ actual positives and $N_B=4$ actual negatives.\n\nFor sensitivity and specificity at $\\tau = 0.5$:\n- For the $4$ actual positives ($y=1$), the predicted probabilities are $0.85, 0.60, 0.45, 0.15$. Two are $\\geq 0.5$ ($0.85, 0.60$) and two are $< 0.5$ ($0.45, 0.15$). Thus, $TP_B=2$ and $FN_B=2$.\n- For the $4$ actual negatives ($y=0$), the predicted probabilities are $0.95, 0.55, 0.40, 0.05$. Two are $< 0.5$ ($0.40, 0.05$) and two are $\\geq 0.5$ ($0.95, 0.55$). Thus, $TN_B=2$ and $FP_B=2$.\n\nSensitivity for Group B:\n$\\text{sens}_B = \\frac{TP_B}{P_B} = \\frac{2}{4} = \\frac{1}{2}$.\n\nSpecificity for Group B:\n$\\text{spec}_B = \\frac{TN_B}{N_B} = \\frac{2}{4} = \\frac{1}{2}$.\n\nFor the calibration slope $\\beta_B$: The set of $\\hat{p}$ values is identical to Group A, so $\\bar{x}_B = \\bar{x}_A = \\frac{1}{2}$ and $S_{xx,B} = S_{xx,A} = \\frac{27}{40}$.\n$\\sum y_i = 1+1+1+1 = 4$, so $\\bar{y}_B = \\frac{4}{8} = \\frac{1}{2}$.\n$S_{xy,B} = \\sum x_i y_i - n\\bar{x}_B\\bar{y}_B$.\n$\\sum x_i y_i = (0.85 \\times 1) + (0.60 \\times 1) + (0.45 \\times 1) + (0.15 \\times 1) = 2.05$.\n$S_{xy,B} = 2.05 - 8 \\times \\frac{1}{2} \\times \\frac{1}{2} = 2.05 - 2 = 0.05 = \\frac{1}{20}$.\n$\\beta_B = \\frac{S_{xy,B}}{S_{xx,B}} = \\frac{1/20}{27/40} = \\frac{1}{20} \\times \\frac{40}{27} = \\frac{2}{27}$.\n\n**Fairness Constraint Evaluation**\n1. Sensitivity difference: $|\\text{sens}_A - \\text{sens}_B| = |1 - \\frac{1}{2}| = \\frac{1}{2} = 0.5$. The constraint is $0.5 \\leq 0.1$, which is false. This constraint is **violated**.\n2. Specificity difference: $|\\text{spec}_A - \\text{spec}_B| = |1 - \\frac{1}{2}| = \\frac{1}{2} = 0.5$. The constraint is $0.5 \\leq 0.1$, which is false. This constraint is **violated**.\n3. Calibration slopes: The required interval is $[0.9, 1.1]$.\n   - For Group A, $\\beta_A = \\frac{38}{27} \\approx 1.407$. Since $1.407 > 1.1$, this constraint is **violated**.\n   - For Group B, $\\beta_B = \\frac{2}{27} \\approx 0.074$. Since $0.074  0.9$, this constraint is **violated**.\n\nSince at least one constraint is violated, the value of the violation indicator is $v=1$.\n\nThe final results are:\n$\\text{sensitivity}_A = 1$\n$\\text{specificity}_A = 1$\n$\\text{slope}_A = \\frac{38}{27}$\n$\\text{sensitivity}_B = \\frac{1}{2}$\n$\\text{specificity}_B = \\frac{1}{2}$\n$\\text{slope}_B = \\frac{2}{27}$\n$v = 1$", "answer": "$$\n\\boxed{\n\\begin{pmatrix} 1  1  \\frac{38}{27}  \\frac{1}{2}  \\frac{1}{2}  \\frac{2}{27}  1 \\end{pmatrix}\n}\n$$", "id": "4399936"}]}