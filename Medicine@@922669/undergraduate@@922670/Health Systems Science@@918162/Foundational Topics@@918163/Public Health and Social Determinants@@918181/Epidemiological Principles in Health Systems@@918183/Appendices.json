{"hands_on_practices": [{"introduction": "This problem will guide you through a fundamental task in epidemiology: comparing disease rates between two populations. Based on a hypothetical scenario comparing two healthcare networks, you will derive the rate ratio from first principles, starting with the Poisson likelihood model. This practice is essential for learning how to quantify the statistical uncertainty of an effect estimate by constructing a confidence interval, a core skill for evaluating health system performance [@problem_id:4370313].", "problem": "A regional health system is comparing two integrated primary care networks on the incidence of avoidable hospitalizations. In network A there were $120$ observed events accumulated over $5{,}000$ person-years, and in network B there were $90$ observed events accumulated over $6{,}000$ person-years. Assume events arise as independent counts that follow a Poisson process with constant hazard within each network over the observation window, and that person-time denominators are measured without error. Using only core definitions of incidence rate and large-sample likelihood theory for the Poisson model, derive from first principles an estimator for the incidence rate ratio comparing network A to network B and construct a two-sided Wald $95\\%$ confidence interval for the true rate ratio. Your derivation should begin from the Poisson likelihood for each group, identify the maximum likelihood estimators for the rates, obtain an estimator for the rate ratio, identify an approximately normal scale for inference, justify the large-sample variance on that scale, and then back-transform to obtain the interval on the original multiplicative scale. Finally, compute the numerical point estimate and the two confidence limits using the data above. Report your three numerical values in the order: point estimate, lower confidence limit, upper confidence limit. Round each reported value to three significant figures. Express all values as pure numbers without units.", "solution": "The problem is evaluated to be valid as it is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The underlying model, the Poisson process, is a standard and fundamental framework for analyzing count data in epidemiology. The derivation requested follows established principles of maximum likelihood estimation and large-sample theory.\n\nLet $Y_A$ and $Y_B$ denote the number of observed events (avoidable hospitalizations) in network A and network B, respectively. Let $T_A$ and $T_B$ be the corresponding total person-years of observation. The problem provides $Y_A = 120$, $T_A = 5{,}000$, $Y_B = 90$, and $T_B = 6{,}000$.\n\nLet $\\lambda_A$ and $\\lambda_B$ be the true, unknown, constant incidence rates in networks A and B, respectively. The problem states that the event counts follow a Poisson process. The number of events $Y$ in a period of person-time $T$ with a constant rate $\\lambda$ is a random variable following a Poisson distribution with mean $\\mu = \\lambda T$. Thus, we have:\n$$\nY_A \\sim \\text{Poisson}(\\lambda_A T_A)\n$$\n$$\nY_B \\sim \\text{Poisson}(\\lambda_B T_B)\n$$\nThe counts in the two networks are assumed to be independent.\n\nThe derivation proceeds from first principles, starting with the likelihood function. The probability mass function for a Poisson random variable $y$ with mean $\\mu$ is $ P(Y=y) = \\frac{e^{-\\mu}\\mu^y}{y!} $. The likelihood function is this probability viewed as a function of the parameter(s). The joint likelihood for the independent observations $(y_A, y_B)$ is the product of the individual likelihoods:\n$$\nL(\\lambda_A, \\lambda_B; y_A, y_B) = \\left( \\frac{e^{-\\lambda_A T_A}(\\lambda_A T_A)^{y_A}}{y_A!} \\right) \\left( \\frac{e^{-\\lambda_B T_B}(\\lambda_B T_B)^{y_B}}{y_B!} \\right)\n$$\nTo find the maximum likelihood estimators (MLEs) for $\\lambda_A$ and $\\lambda_B$, it is more convenient to work with the log-likelihood function, $\\ell = \\ln L$:\n$$\n\\ell(\\lambda_A, \\lambda_B) = \\ln(L) = - \\lambda_A T_A + y_A \\ln(\\lambda_A T_A) - \\ln(y_A!) - \\lambda_B T_B + y_B \\ln(\\lambda_B T_B) - \\ln(y_B!)\n$$\nWe can simplify this by separating terms involving the parameters from constants:\n$$\n\\ell(\\lambda_A, \\lambda_B) = - \\lambda_A T_A + y_A \\ln(\\lambda_A) + y_A\\ln(T_A) - \\ln(y_A!) - \\lambda_B T_B + y_B \\ln(\\lambda_B) + y_B\\ln(T_B) - \\ln(y_B!)\n$$\nTo maximize this function, we take the partial derivatives with respect to $\\lambda_A$ and $\\lambda_B$ and set them to zero.\n$$\n\\frac{\\partial \\ell}{\\partial \\lambda_A} = -T_A + \\frac{y_A}{\\lambda_A} = 0 \\implies \\hat{\\lambda}_A = \\frac{y_A}{T_A}\n$$\n$$\n\\frac{\\partial \\ell}{\\partial \\lambda_B} = -T_B + \\frac{y_B}{\\lambda_B} = 0 \\implies \\hat{\\lambda}_B = \\frac{y_B}{T_B}\n$$\nThese are the MLEs for the individual incidence rates.\n\nThe parameter of interest is the incidence rate ratio (IRR), defined as $\\theta = \\frac{\\lambda_A}{\\lambda_B}$. By the invariance property of maximum likelihood estimators, the MLE for a function of parameters is the function of the MLEs. Therefore, the MLE for $\\theta$ is:\n$$\n\\hat{\\theta} = \\frac{\\hat{\\lambda}_A}{\\hat{\\lambda}_B} = \\frac{y_A/T_A}{y_B/T_B}\n$$\nThe sampling distribution of $\\hat{\\theta}$ is typically skewed, especially in smaller samples. Inference is more reliable on a scale where the estimator's distribution is approximately normal. The natural logarithm is the standard transformation for ratios. Let $\\phi = \\ln(\\theta) = \\ln(\\lambda_A) - \\ln(\\lambda_B)$. The MLE for $\\phi$ is $\\hat{\\phi} = \\ln(\\hat{\\theta}) = \\ln(\\hat{\\lambda}_A) - \\ln(\\hat{\\lambda}_B)$.\n\nTo construct a Wald confidence interval for $\\phi$, we need its variance. According to large-sample theory, $\\hat{\\phi}$ is approximately normally distributed with mean $\\phi$ and variance $\\text{Var}(\\hat{\\phi})$. Since $\\hat{\\lambda}_A$ and $\\hat{\\lambda}_B$ are derived from independent samples, the variance of their difference on the log scale is the sum of their individual variances:\n$$\n\\text{Var}(\\hat{\\phi}) = \\text{Var}(\\ln(\\hat{\\lambda}_A)) + \\text{Var}(\\ln(\\hat{\\lambda}_B))\n$$\nWe use the Delta method to find an approximation for $\\text{Var}(\\ln(\\hat{\\lambda}))$. For a function $g(X)$, the first-order approximation is $\\text{Var}(g(X)) \\approx [g'(E[X])]^2 \\text{Var}(X)$. Here, the random variable is $\\hat{\\lambda} = Y/T$ and the function is $g(\\lambda) = \\ln(\\lambda)$. We have $E[\\hat{\\lambda}] = E[Y/T] = (\\lambda T)/T = \\lambda$ and $\\text{Var}(\\hat{\\lambda}) = \\text{Var}(Y/T) = \\frac{1}{T^2}\\text{Var}(Y) = \\frac{\\lambda T}{T^2} = \\frac{\\lambda}{T}$. The derivative is $g'(\\lambda) = 1/\\lambda$.\nApplying the Delta method:\n$$\n\\text{Var}(\\ln(\\hat{\\lambda})) \\approx \\left(\\frac{1}{\\lambda}\\right)^2 \\text{Var}(\\hat{\\lambda}) = \\frac{1}{\\lambda^2} \\frac{\\lambda}{T} = \\frac{1}{\\lambda T}\n$$\nThe term $\\lambda T$ is the expected number of events, $E[Y]$. The MLE for $\\lambda T$ is $Y$. Therefore, an estimated variance for $\\ln(\\hat{\\lambda})$ is obtained by substituting $y$ for $\\lambda T$:\n$$\n\\widehat{\\text{Var}}(\\ln(\\hat{\\lambda})) = \\frac{1}{y}\n$$\nThis estimator is valid for large $y$. Applying this to our problem, the estimated variance of $\\hat{\\phi}$ is:\n$$\n\\widehat{\\text{Var}}(\\hat{\\phi}) = \\widehat{\\text{Var}}(\\ln(\\hat{\\lambda}_A)) + \\widehat{\\text{Var}}(\\ln(\\hat{\\lambda}_B)) = \\frac{1}{y_A} + \\frac{1}{y_B}\n$$\nThe standard error of $\\hat{\\phi}$ is the square root of this estimated variance:\n$$\n\\text{SE}(\\hat{\\phi}) = \\sqrt{\\frac{1}{y_A} + \\frac{1}{y_B}}\n$$\nA two-sided $100(1-\\alpha)\\%$ Wald confidence interval for $\\phi=\\ln(\\theta)$ is given by:\n$$\n\\hat{\\phi} \\pm z_{1-\\alpha/2} \\times \\text{SE}(\\hat{\\phi})\n$$\nFor a $95\\%$ confidence interval, $\\alpha = 0.05$, and the critical value from the standard normal distribution is $z_{0.975} \\approx 1.96$. The CI for $\\ln(\\theta)$ is:\n$$\n\\ln(\\hat{\\theta}) \\pm 1.96 \\sqrt{\\frac{1}{y_A} + \\frac{1}{y_B}}\n$$\nTo obtain the confidence interval for the rate ratio $\\theta$ itself, we exponentiate the lower and upper bounds of the interval for $\\ln(\\theta)$:\n$$\n\\text{CI}_{95\\%}(\\theta) = \\left( \\hat{\\theta} \\exp\\left(-1.96 \\sqrt{\\frac{1}{y_A} + \\frac{1}{y_B}}\\right), \\hat{\\theta} \\exp\\left(1.96 \\sqrt{\\frac{1}{y_A} + \\frac{1}{y_B}}\\right) \\right)\n$$\nNow, we compute the numerical values using the provided data: $y_A = 120$ and $y_B = 90$.\n\nFirst, the point estimate for the IRR:\n$$\n\\hat{\\theta} = \\frac{120 / 5000}{90 / 6000} = \\frac{0.024}{0.015} = 1.6\n$$\nNext, we compute the standard error of the log-IRR:\n$$\n\\text{SE}(\\ln(\\hat{\\theta})) = \\sqrt{\\frac{1}{120} + \\frac{1}{90}} = \\sqrt{\\frac{3+4}{360}} = \\sqrt{\\frac{7}{360}} \\approx 0.139443\n$$\nThe $95\\%$ confidence interval for $\\ln(\\theta)$ is:\n$$\n\\ln(1.6) \\pm 1.96 \\times 0.139443 \\implies 0.470004 \\pm 0.273308\n$$\nThis gives the interval $(0.196696, 0.743312)$.\n\nFinally, we exponentiate the limits to get the CI for $\\theta$:\nLower Limit: $\\exp(0.196696) \\approx 1.21735$\nUpper Limit: $\\exp(0.743312) \\approx 2.10292$\n\nThe problem requires reporting the three numerical values (point estimate, lower limit, upper limit), rounded to three significant figures.\nPoint estimate: $1.6 \\to 1.60$\nLower confidence limit: $1.21735 \\to 1.22$\nUpper confidence limit: $2.10292 \\to 2.10$", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.60  1.22  2.10 \\end{pmatrix}}\n$$", "id": "4370313"}, {"introduction": "The odds ratio ($OR$) is a common measure of association, but it has a peculiar mathematical property called non-collapsibility. This exercise uses a carefully constructed hypothetical dataset to demonstrate how the overall, or marginal, $OR$ can differ from the stratum-specific $OR$ even when there is no confounding. Working through this example is crucial for understanding why we must be cautious when interpreting odds ratios and why analyzing data in relevant subgroups is so important [@problem_id:4370353].", "problem": "Consider a binary exposure $A \\in \\{0,1\\}$, a binary outcome $Y \\in \\{0,1\\}$, and a binary stratification variable $S \\in \\{0,1\\}$. Use the core epidemiological definitions that the odds of the outcome under a given exposure and stratum is $\\text{odds}(Y=1 \\mid A=a, S=s) = \\frac{P(Y=1 \\mid A=a, S=s)}{P(Y=0 \\mid A=a, S=s)}$ and the odds ratio (OR) comparing exposed to unexposed within a stratum is $\\text{OR}_{s} = \\frac{\\text{odds}(Y=1 \\mid A=1, S=s)}{\\text{odds}(Y=1 \\mid A=0, S=s)}$. Construct a stratified $2 \\times 2$ example that demonstrates non-collapsibility of the odds ratio, where the conditional odds ratio is identical across strata and the exposure is independent of the stratification variable (so there is no confounding), yet the marginal odds ratio obtained by pooling strata differs from the conditional odds ratio. To ensure scientific realism and to enforce independence of exposure and stratification, let each stratum have $600$ individuals with $300$ exposed and $300$ unexposed, so $P(A=1 \\mid S=0) = P(A=1 \\mid S=1) = \\frac{300}{600} = \\frac{1}{2}$. Impose different baseline risks among the unexposed across strata by setting, in stratum $S=0$, the unexposed counts to $a_{01,0} = 60$ cases and $a_{00,0} = 240$ non-cases, and the exposed counts to $a_{11,0} = 100$ cases and $a_{10,0} = 200$ non-cases. In stratum $S=1$, set the unexposed counts to $a_{01,1} = 100$ cases and $a_{00,1} = 200$ non-cases, and the exposed counts to $a_{11,1} = 150$ cases and $a_{10,1} = 150$ non-cases. \n\nUsing only the core definitions above (and without appealing to any shortcut formulas), do the following:\n\n- Verify the conditional odds ratio within each stratum.\n- Compute the marginal odds ratio obtained by pooling counts across $S=0$ and $S=1$, thereby ignoring $S$.\n- Argue from first principles why the exposure $A$ is independent of the stratification variable $S$ in this construction, and why $S$ is associated with the outcome $Y$, thus confirming the absence of confounding but the presence of differing baseline risks.\n- Quantify the non-collapsibility disparity as the absolute difference between the marginal odds ratio and the common conditional odds ratio.\n\nExpress the final disparity as a single exact fraction with no units. No rounding is required.", "solution": "The problem statement is deemed valid. It is scientifically grounded in established epidemiological principles, well-posed with sufficient and consistent data, and objective in its formulation. It requests a demonstration of the non-collapsibility of the odds ratio, a standard and important concept in biostatistics. The problem provides a concrete numerical example and asks for calculations and reasoning based on fundamental definitions.\n\nLet $A$ be the binary exposure ($A=1$ for exposed, $A=0$ for unexposed), $Y$ be the binary outcome ($Y=1$ for a case, $Y=0$ for a non-case), and $S$ be a binary stratification variable ($S \\in \\{0, 1\\}$). The number of individuals for a combination of exposure $i$, outcome $j$, and stratum $s$ is denoted by $a_{ij,s}$.\n\nThe provided data is as follows:\nIn stratum $S=0$:\n-   Unexposed ($A=0$): $a_{01,0} = 60$ cases, $a_{00,0} = 240$ non-cases. Total: $60+240=300$.\n-   Exposed ($A=1$): $a_{11,0} = 100$ cases, $a_{10,0} = 200$ non-cases. Total: $100+200=300$.\n\nIn stratum $S=1$:\n-   Unexposed ($A=0$): $a_{01,1} = 100$ cases, $a_{00,1} = 200$ non-cases. Total: $100+200=300$.\n-   Exposed ($A=1$): $a_{11,1} = 150$ cases, $a_{10,1} = 150$ non-cases. Total: $150+150=300$.\n\nThe core definitions are:\n-   Odds: $\\text{odds}(Y=1 \\mid A=a, S=s) = \\frac{P(Y=1 \\mid A=a, S=s)}{P(Y=0 \\mid A=a, S=s)}$\n-   Stratum-specific Odds Ratio: $\\text{OR}_{s} = \\frac{\\text{odds}(Y=1 \\mid A=1, S=s)}{\\text{odds}(Y=1 \\mid A=0, S=s)}$\n\n**1. Verification of the Conditional Odds Ratios**\n\nFirst, we compute the conditional odds ratio for stratum $S=0$. The probabilities of the outcome conditional on exposure are:\n-   For unexposed ($A=0$): $P(Y=1 \\mid A=0, S=0) = \\frac{a_{01,0}}{a_{01,0} + a_{00,0}} = \\frac{60}{60+240} = \\frac{60}{300} = \\frac{1}{5}$.\n-   Consequently, $P(Y=0 \\mid A=0, S=0) = 1 - \\frac{1}{5} = \\frac{4}{5}$.\n-   The odds for the unexposed are: $\\text{odds}(Y=1 \\mid A=0, S=0) = \\frac{1/5}{4/5} = \\frac{1}{4}$.\n-   For exposed ($A=1$): $P(Y=1 \\mid A=1, S=0) = \\frac{a_{11,0}}{a_{11,0} + a_{10,0}} = \\frac{100}{100+200} = \\frac{100}{300} = \\frac{1}{3}$.\n-   Consequently, $P(Y=0 \\mid A=1, S=0) = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n-   The odds for the exposed are: $\\text{odds}(Y=1 \\mid A=1, S=0) = \\frac{1/3}{2/3} = \\frac{1}{2}$.\n-   The odds ratio for stratum $S=0$ is: $\\text{OR}_{S=0} = \\frac{1/2}{1/4} = 2$.\n\nNext, we compute the conditional odds ratio for stratum $S=1$.\n-   For unexposed ($A=0$): $P(Y=1 \\mid A=0, S=1) = \\frac{a_{01,1}}{a_{01,1} + a_{00,1}} = \\frac{100}{100+200} = \\frac{100}{300} = \\frac{1}{3}$.\n-   Consequently, $P(Y=0 \\mid A=0, S=1) = 1 - \\frac{1}{3} = \\frac{2}{3}$.\n-   The odds for the unexposed are: $\\text{odds}(Y=1 \\mid A=0, S=1) = \\frac{1/3}{2/3} = \\frac{1}{2}$.\n-   For exposed ($A=1$): $P(Y=1 \\mid A=1, S=1) = \\frac{a_{11,1}}{a_{11,1} + a_{10,1}} = \\frac{150}{150+150} = \\frac{150}{300} = \\frac{1}{2}$.\n-   Consequently, $P(Y=0 \\mid A=1, S=1) = 1 - \\frac{1}{2} = \\frac{1}{2}$.\n-   The odds for the exposed are: $\\text{odds}(Y=1 \\mid A=1, S=1) = \\frac{1/2}{1/2} = 1$.\n-   The odds ratio for stratum $S=1$ is: $\\text{OR}_{S=1} = \\frac{1}{1/2} = 2$.\n\nThe conditional odds ratio is identical in both strata, $\\text{OR}_{S=0} = \\text{OR}_{S=1} = 2$. This is the common conditional odds ratio.\n\n**2. Computation of the Marginal Odds Ratio**\n\nTo compute the marginal odds ratio, we pool the data across the strata by summing the respective counts, effectively ignoring $S$.\n-   Total unexposed cases ($A=0, Y=1$): $a_{01,0} + a_{01,1} = 60 + 100 = 160$.\n-   Total unexposed non-cases ($A=0, Y=0$): $a_{00,0} + a_{00,1} = 240 + 200 = 440$.\n-   Total exposed cases ($A=1, Y=1$): $a_{11,0} + a_{11,1} = 100 + 150 = 250$.\n-   Total exposed non-cases ($A=1, Y=0$): $a_{10,0} + a_{10,1} = 200 + 150 = 350$.\n\nThe total number of unexposed individuals is $160+440=600$. The total number of exposed individuals is $250+350=600$.\n-   The marginal probability of the outcome for the unexposed is $P(Y=1 \\mid A=0) = \\frac{160}{600} = \\frac{4}{15}$.\n-   The marginal odds for the unexposed are $\\text{odds}(Y=1 \\mid A=0) = \\frac{P(Y=1 \\mid A=0)}{P(Y=0 \\mid A=0)} = \\frac{160/600}{440/600} = \\frac{160}{440} = \\frac{4}{11}$.\n-   The marginal probability of the outcome for the exposed is $P(Y=1 \\mid A=1) = \\frac{250}{600} = \\frac{5}{12}$.\n-   The marginal odds for the exposed are $\\text{odds}(Y=1 \\mid A=1) = \\frac{P(Y=1 \\mid A=1)}{P(Y=0 \\mid A=1)} = \\frac{250/600}{350/600} = \\frac{250}{350} = \\frac{5}{7}$.\n\nThe marginal odds ratio, $\\text{OR}_M$, is the ratio of these marginal odds:\n$$ \\text{OR}_M = \\frac{\\text{odds}(Y=1 \\mid A=1)}{\\text{odds}(Y=1 \\mid A=0)} = \\frac{5/7}{4/11} = \\frac{5}{7} \\times \\frac{11}{4} = \\frac{55}{28} $$\nThe marginal odds ratio is $\\frac{55}{28}$, which is not equal to the common conditional odds ratio of $2$.\n\n**3. Independence and Association Arguments**\n\n-   **Independence of $A$ and $S$**: The exposure $A$ is independent of the stratification variable $S$ if $P(A=a \\mid S=s) = P(A=a)$ for all $a, s$. In stratum $S=0$, there are $300$ exposed individuals out of a total of $600$, so $P(A=1 \\mid S=0) = \\frac{300}{600} = \\frac{1}{2}$. In stratum $S=1$, there are $300$ exposed individuals out of a total of $600$, so $P(A=1 \\mid S=1) = \\frac{300}{600} = \\frac{1}{2}$. Since $P(A=1 \\mid S=0) = P(A=1 \\mid S=1)$, the exposure allocation is independent of the stratum. This fulfills the condition of \"no confounding\", as a confounder must be associated with the exposure.\n\n-   **Association of $S$ and $Y$**: The stratification variable $S$ is associated with the outcome $Y$ if $P(Y=y \\mid S=s)$ is not constant across strata. We calculate the overall risk of the outcome within each stratum.\n    -   In $S=0$, the total number of cases is $60+100=160$. The risk is $P(Y=1 \\mid S=0) = \\frac{160}{600} = \\frac{4}{15}$.\n    -   In $S=1$, the total number of cases is $100+150=250$. The risk is $P(Y=1 \\mid S=1) = \\frac{250}{600} = \\frac{5}{12}$.\n    -   Since $P(Y=1 \\mid S=0) = \\frac{4}{15} \\approx 0.267$ and $P(Y=1 \\mid S=1) = \\frac{5}{12} \\approx 0.417$ are not equal, $S$ is a risk factor for $Y$. Furthermore, the baseline risks (risk in the unexposed) differ: $P(Y=1 \\mid A=0, S=0) = \\frac{1}{5}$ and $P(Y=1 \\mid A=0, S=1) = \\frac{1}{3}$. This confirms that $S$ is associated with the outcome and the baseline risk varies by stratum. The non-collapsibility of the odds ratio occurs even without confounding ($A \\perp S$) because the stratum variable $S$ is a risk factor for the outcome ($S$ is not independent of $Y$) and the effect of $A$ on $Y$ is homogeneous on the OR scale but not on the risk difference or risk ratio scale.\n\n**4. Quantifying the Non-Collapsibility Disparity**\n\nThe non-collapsibility disparity is the absolute difference between the marginal odds ratio and the common conditional odds ratio.\n-   Marginal OR: $\\text{OR}_M = \\frac{55}{28}$.\n-   Common Conditional OR: $\\text{OR}_s = 2$.\n-   Disparity = $|\\text{OR}_M - \\text{OR}_s| = \\left|\\frac{55}{28} - 2\\right| = \\left|\\frac{55}{28} - \\frac{56}{28}\\right| = \\left|-\\frac{1}{28}\\right| = \\frac{1}{28}$.\n\nThis example demonstrates that even when an exposure is independent of a stratification variable (no confounding), if that variable is a risk factor for the outcome, the marginal (crude) odds ratio will not be equal to the common conditional (stratum-specific) odds ratio. This mathematical property is known as the non-collapsibility of the odds ratio.", "answer": "$$\\boxed{\\frac{1}{28}}$$", "id": "4370353"}, {"introduction": "This practice demonstrates how epidemiologists translate real-time data from an outbreak into critical parameters for public health action. You will use the observed exponential growth rate of an epidemic and information about its generation interval to estimate the basic reproduction number, $R$. From this essential measure of transmissibility, you will then calculate the herd immunity threshold, linking a core epidemiological principle directly to policy targets for disease control [@problem_id:4370298].", "problem": "A respiratory pathogen is spreading in a fully susceptible population. During the early exponential growth phase, the incidence grows at a per-capita rate of $r = 0.08\\,\\text{day}^{-1}$. Contact tracing yields a continuous generation-interval distribution $w(\\tau)$ that is well approximated by a Gamma distribution with mean $5$ days and standard deviation $1.9$ days. Using first principles of the renewal process for transmission in a fully susceptible population and the definition of the basic reproduction number $R$, derive an expression that links $R$ to $r$ and $w(\\tau)$, and then evaluate $R$ for the given parameters. Next, under the classic susceptible–infectious–removed (SIR) model with homogeneous mixing, define the herd immunity threshold as the smallest fraction $h$ of the population that must be immune such that the effective reproduction number falls to $1$, and compute the implied value of $h$ from your estimate of $R$.\n\nReport your final answer as two numbers in a single row matrix $\\big[R,\\,h\\big]$, rounded to four significant figures. Express $h$ as a decimal fraction. Do not include units in your final reported matrix.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is based on established principles of mathematical epidemiology, contains sufficient and consistent information, and is free from ambiguity or pseudo-profound claims. The problem is therefore deemed valid, and a solution is provided below.\n\nThe problem asks for two quantities: the basic reproduction number $R$ and the herd immunity threshold $h$. We will address each in turn.\n\nFirst, we derive an expression for the basic reproduction number $R$. The spread of an epidemic in a fully susceptible population can be described by the renewal equation, which relates the incidence of new infections at time $t$, denoted by $i(t)$, to the incidence at previous times. The equation is:\n$$\ni(t) = R \\int_{0}^{\\infty} i(t-\\tau) w(\\tau) \\,d\\tau\n$$\nwhere $R$ is the basic reproduction number, and $w(\\tau)$ is the probability density function of the generation interval $\\tau$. The generation interval is the time elapsed between an individual getting infected and them infecting another individual.\n\nThe problem states that during the early phase, the incidence grows exponentially. This allows us to posit a solution of the form $i(t) = i_0 \\exp(rt)$, where $r$ is the given per-capita growth rate. Substituting this into the renewal equation yields:\n$$\ni_0 \\exp(rt) = R \\int_{0}^{\\infty} i_0 \\exp(r(t-\\tau)) w(\\tau) \\,d\\tau\n$$\nWe can cancel the term $i_0 \\exp(rt)$ from both sides of the equation:\n$$\n1 = R \\int_{0}^{\\infty} \\exp(-r\\tau) w(\\tau) \\,d\\tau\n$$\nThe integral on the right-hand side is the definition of the moment-generating function (MGF) of the random variable $\\tau$, denoted $M_{\\tau}(s)$, evaluated at $s = -r$. The MGF is defined as $M_{\\tau}(s) = E[\\exp(s\\tau)] = \\int_{-\\infty}^{\\infty} \\exp(s\\tau) w(\\tau) \\,d\\tau$. Therefore, we have:\n$$\n1 = R \\cdot M_{\\tau}(-r)\n$$\nThis gives the expression linking $R$ to $r$ and the generation interval distribution $w(\\tau)$, which is a form of the Lotka-Euler equation: $R = \\frac{1}{M_{\\tau}(-r)}$.\n\nThe problem specifies that $w(\\tau)$ follows a Gamma distribution with mean $\\mu = 5$ days and standard deviation $\\sigma = 1.9$ days. The Gamma distribution is defined by a shape parameter $k$ and a scale parameter $\\theta$. The mean and variance ($\\sigma^2$) are related to these parameters as follows:\n$$\n\\mu = k\\theta\n$$\n$$\n\\sigma^2 = k\\theta^2\n$$\nWe can solve for $k$ and $\\theta$ using the given values $\\mu=5$ and $\\sigma=1.9$.\nFirst, we find $\\theta$:\n$$\n\\theta = \\frac{\\sigma^2}{\\mu} = \\frac{(1.9)^2}{5} = \\frac{3.61}{5} = 0.722\\,\\text{days}\n$$\nNext, we find $k$:\n$$\nk = \\frac{\\mu}{\\theta} = \\frac{5}{0.722} = \\frac{5}{3.61/5} = \\frac{25}{3.61}\n$$\nIt is also common to express $k$ as $k = \\mu^2 / \\sigma^2$, which gives the same result:\n$$\nk = \\frac{5^2}{1.9^2} = \\frac{25}{3.61} \\approx 6.9252\n$$\nThe moment-generating function for a Gamma distribution with parameters $k$ and $\\theta$ is given by:\n$$\nM_{\\tau}(s) = (1 - \\theta s)^{-k}\n$$\nWe need to evaluate this at $s = -r$, where $r = 0.08\\,\\text{day}^{-1}$:\n$$\nM_{\\tau}(-r) = (1 - \\theta(-r))^{-k} = (1 + r\\theta)^{-k}\n$$\nSubstituting this into our expression for $R$:\n$$\nR = \\frac{1}{(1 + r\\theta)^{-k}} = (1 + r\\theta)^k\n$$\nNow, we can substitute the numerical values for $r$, $\\theta$, and $k$ to evaluate $R$:\n$$\nR = \\left(1 + (0.08) \\cdot (0.722)\\right)^{\\frac{25}{3.61}} = (1 + 0.05776)^{\\frac{25}{3.61}} = (1.05776)^{\\frac{25}{3.61}}\n$$\nCalculating the value:\n$$\nR \\approx (1.05776)^{6.925207756} \\approx 1.475354\n$$\nRounding to four significant figures, we get $R \\approx 1.475$.\n\nNext, we compute the herd immunity threshold, $h$. In the classic SIR model, the effective reproduction number, $R_e$, is the average number of secondary cases per infectious case in a population where a fraction $s$ is susceptible. It is given by $R_e = R \\cdot s$. The herd immunity threshold $h$ is defined as the smallest fraction of the population that must be immune to reduce the effective reproduction number to $1$. If a fraction $h$ is immune, the fraction of susceptible individuals is $s = 1 - h$. The threshold condition is $R_e = 1$.\n$$\nR \\cdot (1 - h) = 1\n$$\nSolving for $h$:\n$$\n1 - h = \\frac{1}{R}\n$$\n$$\nh = 1 - \\frac{1}{R}\n$$\nUsing our calculated value for $R$:\n$$\nh = 1 - \\frac{1}{1.475354} \\approx 1 - 0.677800 = 0.322200\n$$\nRounding to four significant figures, we get $h \\approx 0.3222$.\n\nThe problem requests the final answer as a row matrix $[R, h]$, with both numbers rounded to four significant figures.\n$R \\approx 1.475$\n$h \\approx 0.3222$\nThe final matrix is $\\begin{pmatrix} 1.475  0.3222 \\end{pmatrix}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.475  0.3222\n\\end{pmatrix}\n}\n$$", "id": "4370298"}]}