{"hands_on_practices": [{"introduction": "A neuron's primary computation involves converting incoming signals into a sequence of output spikes. The Leaky Integrate-and-Fire (LIF) model is a cornerstone for understanding this process, capturing the essential dynamics of membrane potential, spiking, and reset. This exercise guides you through the derivation of the frequency-current ($f$-$I$) curve, which describes a neuron's firing rate as a function of input current, and challenges you to analyze its sensitivity, or gain, a key measure of excitability. By working through this problem [@problem_id:5061370], you will see how intrinsic properties like the reset potential $V_r$ shape a neuron's fundamental input-output relationship.", "problem": "Consider a single neuron modeled by the Leaky Integrate-and-Fire (LIF) dynamics. The membrane potential $V(t)$ evolves according to the passive membrane equation\n$$C \\frac{dV}{dt} = -g_L \\left(V - V_{\\text{rest}}\\right) + I,$$\nwhere $C$ is the membrane capacitance, $g_L$ is the leak conductance, $V_{\\text{rest}}$ is the resting potential, and $I$ is a constant input current. Define the membrane time constant $\\tau_m = \\frac{C}{g_L}$ and the membrane resistance $R = \\frac{1}{g_L}$. When the membrane potential reaches the spike threshold $V_{\\text{th}}$, a spike is emitted, the voltage is instantaneously reset to $V_r$, and the neuron remains quiescent for an absolute refractory period $\\tau_{\\text{ref}}$.\n\nUnder constant current drive $I$, the firing rate $f(I)$ is defined as the reciprocal of the interspike interval, which consists of the time required for the membrane potential to evolve from $V_r$ to $V_{\\text{th}}$ plus the absolute refractory period. Using only the definitions above and the solution of the passive membrane equation, derive the expression for the slope $\\frac{df}{dI}$ of the frequency–current ($f$–$I$) relationship at a fixed current $I_0$, and evaluate it for two different reset values $V_r$ while keeping all other parameters fixed.\n\nUse the following parameter values:\n- $V_{\\text{rest}} = -65\\,\\mathrm{mV}$,\n- $V_{\\text{th}} = -50\\,\\mathrm{mV}$,\n- $V_r^{(1)} = -65\\,\\mathrm{mV}$,\n- $V_r^{(2)} = -60\\,\\mathrm{mV}$,\n- $\\tau_m = 20\\,\\mathrm{ms}$,\n- $\\tau_{\\text{ref}} = 2\\,\\mathrm{ms}$,\n- $R = 100\\,\\mathrm{M}\\Omega$,\n- $I_0 = 0.300\\,\\mathrm{nA}$.\n\nCompute $\\frac{df}{dI}$ at $I_0$ for $V_r^{(1)}$ and for $V_r^{(2)}$, with all quantities converted to volts, seconds, ohms, and amperes consistently. Report your two numerical answers in $\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$ and round each to four significant figures. Your final answer must consist only of the two values in a single row matrix, ordered as $\\left[\\frac{df}{dI}\\big|_{V_r^{(1)}},\\ \\frac{df}{dI}\\big|_{V_r^{(2)}}\\right]$.", "solution": "**Derivation of the Firing Rate $f(I)$**\n\nThe evolution of the membrane potential $V(t)$ is given by:\n$$C \\frac{dV}{dt} = -g_L (V - V_{\\text{rest}}) + I$$\nUsing the definitions $\\tau_m = \\frac{C}{g_L}$ and $R = \\frac{1}{g_L}$, we can rewrite the equation. Multiplying by $R$:\n$$\\tau_m \\frac{dV}{dt} = -(V - V_{\\text{rest}}) + RI$$\nLet's define the steady-state voltage for a constant current $I$ as $V_{\\infty}(I) = V_{\\text{rest}} + RI$. The equation becomes:\n$$\\tau_m \\frac{dV}{dt} = - (V - V_{\\infty}(I))$$\nThis is a first-order linear ordinary differential equation. With the initial condition $V(t=0) = V_0$, the solution is:\n$$V(t) = V_{\\infty}(I) + (V_0 - V_{\\infty}(I)) \\exp\\left(-\\frac{t}{\\tau_m}\\right)$$\nTo find the time $T_{\\text{charge}}$ it takes for the potential to rise from the reset value $V_r$ to the threshold $V_{\\text{th}}$, we set $V(0) = V_r$ and solve for the time $t = T_{\\text{charge}}$ at which $V(T_{\\text{charge}}) = V_{\\text{th}}$:\n$$V_{\\text{th}} = V_{\\infty}(I) + (V_r - V_{\\infty}(I)) \\exp\\left(-\\frac{T_{\\text{charge}}}{\\tau_m}\\right)$$\nSolving for $T_{\\text{charge}}$:\n$$\\exp\\left(-\\frac{T_{\\text{charge}}}{\\tau_m}\\right) = \\frac{V_{\\text{th}} - V_{\\infty}(I)}{V_r - V_{\\infty}(I)}$$\n$$T_{\\text{charge}}(I) = -\\tau_m \\ln\\left(\\frac{V_{\\text{th}} - V_{\\infty}(I)}{V_r - V_{\\infty}(I)}\\right) = \\tau_m \\ln\\left(\\frac{V_r - V_{\\infty}(I)}{V_{\\text{th}} - V_{\\infty}(I)}\\right)$$\nFor the neuron to fire, we must have $V_{\\infty}(I) > V_{\\text{th}}$, which ensures the argument of the logarithm is positive and greater than $1$ (since $V_r \\le V_{\\text{th}}$). The total interspike interval $T_{ISI}$ is the sum of $T_{\\text{charge}}$ and the absolute refractory period $\\tau_{\\text{ref}}$:\n$$T_{ISI}(I) = \\tau_{\\text{ref}} + \\tau_m \\ln\\left(\\frac{V_r - V_{\\text{rest}} - RI}{V_{\\text{th}} - V_{\\text{rest}} - RI}\\right)$$\nThe firing rate $f(I)$ is the reciprocal of the interspike interval:\n$$f(I) = \\left[ \\tau_{\\text{ref}} + \\tau_m \\ln\\left(\\frac{V_r - V_{\\text{rest}} - RI}{V_{\\text{th}} - V_{\\text{rest}} - RI}\\right) \\right]^{-1}$$\n\n**Derivation of the Slope $\\frac{df}{dI}$**\n\nTo find the slope of the frequency-current relationship, we differentiate $f(I)$ with respect to $I$. Using the chain rule, $\\frac{df}{dI} = \\frac{d}{dI} [T_{ISI}(I)]^{-1}$:\n$$\\frac{df}{dI} = -[T_{ISI}(I)]^{-2} \\frac{dT_{ISI}}{dI} = -f(I)^2 \\frac{dT_{ISI}}{dI}$$\nWe compute the derivative of $T_{ISI}(I)$:\n$$\\frac{dT_{ISI}}{dI} = \\frac{d}{dI} \\left[ \\tau_{\\text{ref}} + \\tau_m \\left( \\ln(V_r - V_{\\text{rest}} - RI) - \\ln(V_{\\text{th}} - V_{\\text{rest}} - RI) \\right) \\right]$$\n$$\\frac{dT_{ISI}}{dI} = \\tau_m \\left[ \\frac{1}{V_r - V_{\\text{rest}} - RI} \\cdot (-R) - \\frac{1}{V_{\\text{th}} - V_{\\text{rest}} - RI} \\cdot (-R) \\right]$$\n$$\\frac{dT_{ISI}}{dI} = -R\\tau_m \\left[ \\frac{1}{V_r - V_{\\text{rest}} - RI} - \\frac{1}{V_{\\text{th}} - V_{\\text{rest}} - RI} \\right]$$\nCombining terms:\n$$\\frac{dT_{ISI}}{dI} = -R\\tau_m \\frac{(V_{\\text{th}} - V_{\\text{rest}} - RI) - (V_r - V_{\\text{rest}} - RI)}{(V_r - V_{\\text{rest}} - RI)(V_{\\text{th}} - V_{\\text{rest}} - RI)} = - R\\tau_m \\frac{V_{\\text{th}} - V_r}{(V_r - V_{\\infty}(I))(V_{\\text{th}} - V_{\\infty}(I))}$$\nSubstituting this back into the expression for $\\frac{df}{dI}$:\n$$\\frac{df}{dI} = -f(I)^2 \\left( - R\\tau_m \\frac{V_{\\text{th}} - V_r}{(V_r - V_{\\infty}(I))(V_{\\text{th}} - V_{\\infty}(I))} \\right)$$\n$$\\frac{df}{dI} = f(I)^2 \\frac{R\\tau_m(V_{\\text{th}} - V_r)}{(V_r - V_{\\infty}(I))(V_{\\text{th}} - V_{\\infty}(I))}$$\n\n**Numerical Calculation**\n\nFirst, convert all parameters to base SI units:\n- $V_{\\text{rest}} = -0.065\\,\\mathrm{V}$\n- $V_{\\text{th}} = -0.050\\,\\mathrm{V}$\n- $V_r^{(1)} = -0.065\\,\\mathrm{V}$\n- $V_r^{(2)} = -0.060\\,\\mathrm{V}$\n- $\\tau_m = 0.020\\,\\mathrm{s}$\n- $\\tau_{\\text{ref}} = 0.002\\,\\mathrm{s}$\n- $R = 1.00 \\times 10^8\\,\\mathrm{\\Omega}$\n- $I_0 = 0.300 \\times 10^{-9}\\,\\mathrm{A}$\n\nCalculate the common intermediate quantities at $I = I_0$:\n- $RI_0 = (1.00 \\times 10^8\\,\\mathrm{\\Omega})(0.300 \\times 10^{-9}\\,\\mathrm{A}) = 0.030\\,\\mathrm{V}$\n- $V_{\\infty}(I_0) = V_{\\text{rest}} + RI_0 = -0.065\\,\\mathrm{V} + 0.030\\,\\mathrm{V} = -0.035\\,\\mathrm{V}$\n\n**Case 1: Reset potential $V_r^{(1)} = -0.065\\,\\mathrm{V}$**\n- $T_{\\text{charge}}^{(1)}(I_0) = \\tau_m \\ln\\left(\\frac{V_r^{(1)} - V_{\\infty}(I_0)}{V_{\\text{th}} - V_{\\infty}(I_0)}\\right) = 0.020 \\ln\\left(\\frac{-0.065 - (-0.035)}{-0.050 - (-0.035)}\\right) = 0.020 \\ln\\left(\\frac{-0.030}{-0.015}\\right) = 0.020 \\ln(2) \\approx 0.013863\\,\\mathrm{s}$.\n- $T_{ISI}^{(1)}(I_0) = \\tau_{\\text{ref}} + T_{\\text{charge}}^{(1)}(I_0) = 0.002\\,\\mathrm{s} + 0.013863\\,\\mathrm{s} = 0.015863\\,\\mathrm{s}$.\n- $f^{(1)}(I_0) = \\frac{1}{T_{ISI}^{(1)}(I_0)} = \\frac{1}{0.015863} \\approx 63.040\\,\\mathrm{s}^{-1}$.\n- Next, we calculate $\\frac{dT_{ISI}^{(1)}}{dI}\\bigg|_{I_0} = -R\\tau_m \\left[ \\frac{1}{V_r^{(1)} - V_{\\infty}(I_0)} - \\frac{1}{V_{\\text{th}} - V_{\\infty}(I_0)} \\right]$.\n- With $R\\tau_m = (10^8\\,\\Omega)(0.020\\,\\mathrm{s}) = 2.0 \\times 10^6\\,\\Omega\\cdot\\mathrm{s}$, we get:\n- $\\frac{dT_{ISI}^{(1)}}{dI}\\bigg|_{I_0} = -(2.0 \\times 10^6) \\left[ \\frac{1}{-0.030\\,\\mathrm{V}} - \\frac{1}{-0.015\\,\\mathrm{V}} \\right] = -(2.0 \\times 10^6) \\left[ \\frac{100}{3} \\right] = -\\frac{2}{3} \\times 10^8\\,\\mathrm{s/A}$.\n- $\\frac{df^{(1)}}{dI}\\bigg|_{I_0} = -f^{(1)}(I_0)^2 \\frac{dT_{ISI}^{(1)}}{dI}\\bigg|_{I_0} \\approx -(63.040)^2 \\left( -\\frac{2}{3} \\times 10^8 \\right) \\approx 2.6493 \\times 10^{11}\\,\\mathrm{s}^{-1}/\\mathrm{A}$.\n- To convert to $\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$, we multiply by $1\\,\\mathrm{A} / 10^9\\,\\mathrm{nA}$:\n- $\\frac{df^{(1)}}{dI}\\bigg|_{I_0} \\approx 2.6493 \\times 10^{11} \\times 10^{-9} = 264.93\\,\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$.\n- Rounding to four significant figures, the result is $264.9\\,\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$.\n\n**Case 2: Reset potential $V_r^{(2)} = -0.060\\,\\mathrm{V}$**\n- $T_{\\text{charge}}^{(2)}(I_0) = \\tau_m \\ln\\left(\\frac{V_r^{(2)} - V_{\\infty}(I_0)}{V_{\\text{th}} - V_{\\infty}(I_0)}\\right) = 0.020 \\ln\\left(\\frac{-0.060 - (-0.035)}{-0.050 - (-0.035)}\\right) = 0.020 \\ln(\\frac{5}{3}) \\approx 0.010217\\,\\mathrm{s}$.\n- $T_{ISI}^{(2)}(I_0) = \\tau_{\\text{ref}} + T_{\\text{charge}}^{(2)}(I_0) = 0.002\\,\\mathrm{s} + 0.010217\\,\\mathrm{s} = 0.012217\\,\\mathrm{s}$.\n- $f^{(2)}(I_0) = \\frac{1}{T_{ISI}^{(2)}(I_0)} = \\frac{1}{0.012217} \\approx 81.855\\,\\mathrm{s}^{-1}$.\n- Evaluate $\\frac{dT_{ISI}^{(2)}}{dI}$ at $I_0$:\n- $\\frac{dT_{ISI}^{(2)}}{dI}\\bigg|_{I_0} = -R\\tau_m \\left[ \\frac{1}{V_r^{(2)} - V_{\\infty}(I_0)} - \\frac{1}{V_{\\text{th}} - V_{\\infty}(I_0)} \\right]$\n- $\\frac{dT_{ISI}^{(2)}}{dI}\\bigg|_{I_0} = -(2.0 \\times 10^6) \\left[ \\frac{1}{-0.025\\,\\mathrm{V}} - \\frac{1}{-0.015\\,\\mathrm{V}} \\right] = -(2.0 \\times 10^6) \\left[ \\frac{80}{3} \\right] = -\\frac{16}{3} \\times 10^7\\,\\mathrm{s/A}$.\n- $\\frac{df^{(2)}}{dI}\\bigg|_{I_0} = -f^{(2)}(I_0)^2 \\frac{dT_{ISI}^{(2)}}{dI}\\bigg|_{I_0} \\approx -(81.8554)^2 \\left( -\\frac{16}{3} \\times 10^7 \\right) \\approx 3.5735 \\times 10^{11}\\,\\mathrm{s}^{-1}/\\mathrm{A}$.\n- Convert to $\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$:\n- $\\frac{df^{(2)}}{dI}\\bigg|_{I_0} \\approx 3.5735 \\times 10^{11} \\times 10^{-9} = 357.35\\,\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$.\n- Rounding to four significant figures, the result is $357.4\\,\\mathrm{s}^{-1}\\,\\mathrm{nA}^{-1}$.\n\nFinal answers are $264.9$ and $357.4$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n264.9  357.4\n\\end{pmatrix}\n}\n$$", "id": "5061370"}, {"introduction": "Synaptic plasticity, the ability of connections between neurons to strengthen or weaken, is the cellular basis of learning and memory. This practice delves into Hebbian plasticity, the famous \"fire together, wire together\" principle, by formalizing it mathematically. You will derive how the average change in synaptic weights relates directly to the statistical structure of the input, represented by the covariance matrix $\\Sigma$. This exercise [@problem_id:5061354] provides a critical link between neural activity and learning, demonstrating how a simple neuron can perform a powerful computation: learning to extract the most significant feature from its input data.", "problem": "Consider a single linear neuron with output $y$ defined by $y = \\mathbf{w}^{\\top} \\mathbf{x}$, where $\\mathbf{w} \\in \\mathbb{R}^{2}$ is the synaptic weight vector and $\\mathbf{x} \\in \\mathbb{R}^{2}$ is the input vector. Assume that the input $\\mathbf{x}$ is drawn from a zero-mean distribution with covariance matrix $\\Sigma \\in \\mathbb{R}^{2 \\times 2}$. According to the Hebbian plasticity principle, synapses strengthen when pre-synaptic and post-synaptic activities co-occur. Using this principle and the properties of expectations for zero-mean random vectors, derive the expected synaptic update in terms of $\\Sigma$ and $\\mathbf{w}$.\n\nNow, instead of evaluating the expectation exactly, approximate a single expected update step by simulating a one-sample Hebbian update. Use the current weight $\\mathbf{w} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$, the sample input $\\mathbf{x} = \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}$, and the learning rate $\\eta = 0.01$. Compute the simulated update $\\Delta \\mathbf{w}$ using $y = \\mathbf{w}^{\\top} \\mathbf{x}$.\n\nProvide your final numerical answer for the simulated update as a two-entry row matrix. No rounding is required.", "solution": "### Solution Derivation\n\nThe problem consists of two parts. First, a general derivation for the expected synaptic update, and second, a specific numerical calculation for a single update step.\n\n**Part 1: Derivation of the Expected Synaptic Update**\n\nThe principle of Hebbian plasticity states that the change in synaptic weight is proportional to the correlation between pre-synaptic and post-synaptic activity. The pre-synaptic activity is the input vector $\\mathbf{x}$, and the post-synaptic activity is the neuron's output scalar $y$. This principle is mathematically expressed by the Hebbian learning rule:\n$$\n\\Delta \\mathbf{w} = \\eta y \\mathbf{x}\n$$\nwhere $\\eta$ is the learning rate, a positive scalar constant.\n\nThe neuron's output is given as a linear function of the input:\n$$\ny = \\mathbf{w}^{\\top} \\mathbf{x}\n$$\nSubstituting the expression for $y$ into the learning rule gives the update for $\\Delta \\mathbf{w}$ in terms of the input $\\mathbf{x}$ and the current weight vector $\\mathbf{w}$:\n$$\n\\Delta \\mathbf{w} = \\eta (\\mathbf{w}^{\\top} \\mathbf{x}) \\mathbf{x}\n$$\nSince $\\mathbf{w}^{\\top} \\mathbf{x}$ is a scalar, we can rewrite this expression using matrix properties. Note that for a vector $\\mathbf{x}$ and a conformable vector $\\mathbf{w}$, $\\mathbf{x} (\\mathbf{w}^{\\top} \\mathbf{x}) = (\\mathbf{x} \\mathbf{x}^{\\top}) \\mathbf{w}$. Thus, the update rule can be written as:\n$$\n\\Delta \\mathbf{w} = \\eta (\\mathbf{x} \\mathbf{x}^{\\top}) \\mathbf{w}\n$$\nThe problem asks for the expected synaptic update, $E[\\Delta \\mathbf{w}]$. We take the expectation of this expression with respect to the distribution of the input vector $\\mathbf{x}$. The weight vector $\\mathbf{w}$ and the learning rate $\\eta$ are treated as constants for the purpose of calculating the expectation for a given state.\n$$\nE[\\Delta \\mathbf{w}] = E[\\eta (\\mathbf{x} \\mathbf{x}^{\\top}) \\mathbf{w}]\n$$\nUsing the linearity of the expectation operator, we can write:\n$$\nE[\\Delta \\mathbf{w}] = \\eta E[\\mathbf{x} \\mathbf{x}^{\\top}] \\mathbf{w}\n$$\nThe covariance matrix, $\\Sigma$, of a random vector $\\mathbf{x}$ is defined as $\\Sigma = E[(\\mathbf{x} - E[\\mathbf{x}])(\\mathbf{x} - E[\\mathbf{x}])^{\\top}]$. The problem states that the input $\\mathbf{x}$ is drawn from a zero-mean distribution, which means $E[\\mathbf{x}] = \\mathbf{0}$. In this specific case, the covariance matrix simplifies to:\n$$\n\\Sigma = E[(\\mathbf{x} - \\mathbf{0})(\\mathbf{x} - \\mathbf{0})^{\\top}] = E[\\mathbf{x} \\mathbf{x}^{\\top}]\n$$\nSubstituting this result back into the expression for the expected update yields the final result for the first part of the problem:\n$$\nE[\\Delta \\mathbf{w}] = \\eta \\Sigma \\mathbf{w}\n$$\nThis result shows that, on average, the weight vector $\\mathbf{w}$ changes in a direction determined by the action of the input covariance matrix $\\Sigma$ on $\\mathbf{w}$. This is the core of Oja's rule, a normalized version of Hebbian learning, which leads to the weight vector converging to the principal eigenvector of the covariance matrix.\n\n**Part 2: Numerical Simulation of a Single-Sample Update**\n\nThe second part of the problem requires calculating the update $\\Delta \\mathbf{w}$ for a single sample, which serves as a one-sample (stochastic) approximation of the expected update. The formula to use is the basic update rule, $\\Delta \\mathbf{w} = \\eta y \\mathbf{x}$, before taking any expectation.\n\nWe are given the following values:\n- Learning rate: $\\eta = 0.01$\n- Current weight vector: $\\mathbf{w} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$\n- Sample input vector: $\\mathbf{x} = \\begin{pmatrix}2 \\\\ 1\\end{pmatrix}$\n\nFirst, we calculate the post-synaptic activity $y$ for the given $\\mathbf{w}$ and $\\mathbf{x}$:\n$$\ny = \\mathbf{w}^{\\top} \\mathbf{x} = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = (1)(2) + (0)(1) = 2\n$$\nNow, we compute the synaptic update vector $\\Delta \\mathbf{w}$ using the calculated $y$:\n$$\n\\Delta \\mathbf{w} = \\eta y \\mathbf{x} = (0.01)(2) \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\Delta \\mathbf{w} = 0.02 \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0.02 \\times 2 \\\\ 0.02 \\times 1 \\end{pmatrix} = \\begin{pmatrix} 0.04 \\\\ 0.02 \\end{pmatrix}\n$$\nThe simulated update is $\\Delta \\mathbf{w} = \\begin{pmatrix} 0.04 \\\\ 0.02 \\end{pmatrix}$. The problem requires the final answer as a two-entry row matrix.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.04  0.02 \\end{pmatrix}}\n$$", "id": "5061354"}, {"introduction": "While the basic Hebbian rule provides a powerful framework, learning in the brain often depends on the precise timing of neural spikes, on a millisecond timescale. This practice explores this phenomenon through Spike-Timing-Dependent Plasticity (STDP), where the temporal order of pre- and postsynaptic spikes determines the sign and magnitude of synaptic change. You are challenged to apply the STDP rule in a biologically plausible scenario involving two oscillating neurons [@problem_id:5061378]. By carefully accounting for factors like phase differences and axonal conduction delays, you will discover how these physical constraints can flip the outcome of plasticity from potentiation to depression, highlighting the sophisticated nature of learning in neural circuits.", "problem": "Consider two leaky integrate-and-fire (LIF) neurons labeled $A$ and $B$ forming a bidirectionally connected loop. Each neuron fires exactly one spike per cycle of a stable oscillation with frequency $f=50$ Hz, giving a period $T=1/f$. Measured at their somata, neuron $A$ leads neuron $B$ by a fixed phase $\\phi=\\pi/3$ radians in every cycle. The axonal conduction delay from $A$ to $B$ is fixed at $d=5$ ms, and synaptic transmission plus postsynaptic integration at neuron $B$ introduces no additional delay beyond this axonal conduction delay. The plasticity at the $A \\to B$ synapse follows the classical spike-timing-dependent plasticity (STDP) rule, in which weight change depends only on the interval between the arrival time of a presynaptic spike at the synapse and the postsynaptic spike time. Use an exponential timing sensitivity with parameters $A_{+}=0.005$, $A_{-}=0.005$, $\\tau_{+}=20$ ms, and $\\tau_{-}=20$ ms. Assume that in each cycle there is exactly one correlated presynaptic spike from neuron $A$ and one postsynaptic spike from neuron $B$.\n\nStarting from the definitions of phase, period, and conduction delay and the principle that STDP assigns potentiation when presynaptic arrival precedes postsynaptic spiking and depression otherwise, derive the effective presynaptic–postsynaptic timing interval at the synapse and the resulting net synaptic weight change for the single $A \\to B$ spike pair per cycle. Determine whether the correlation produces potentiation or depression, and compute the numerical value of the weight change per cycle. Round your final numeric answer to four significant figures. Express the final answer in dimensionless weight units (do not include units in your final boxed answer).", "solution": "### Solution Derivation\nThe problem requires the calculation of the synaptic weight change, $\\Delta w$, at the synapse from neuron $A$ to neuron $B$. This change is governed by a spike-timing-dependent plasticity (STDP) rule, which is a function of the time interval $\\Delta t$ between the arrival of the presynaptic spike at the synapse and the firing of the postsynaptic spike.\n\nFirst, we define the relevant time points. Let $t_{spike, A}$ be the time at which neuron $A$ fires a spike at its soma, and $t_{spike, B}$ be the time at which neuron $B$ fires a spike at its soma.\n\nThe period of oscillation, $T$, is the inverse of the frequency, $f$:\n$$T = \\frac{1}{f}$$\nGiven $f = 50$ Hz, the period is:\n$$T = \\frac{1}{50 \\text{ Hz}} = 0.02 \\text{ s} = 20 \\text{ ms}$$\n\nNeuron $A$ leads neuron $B$ by a phase $\\phi = \\pi/3$ radians. This phase lead corresponds to a time lead. The time difference between the somatic spikes, $\\Delta t_{soma}$, is the fraction of the period corresponding to the phase difference:\n$$\\Delta t_{soma} = t_{spike, B} - t_{spike, A} = \\frac{\\phi}{2\\pi} T$$\nSubstituting the given values:\n$$\\Delta t_{soma} = \\frac{\\pi/3}{2\\pi} \\times 20 \\text{ ms} = \\frac{1}{6} \\times 20 \\text{ ms} = \\frac{10}{3} \\text{ ms}$$\nSince neuron $A$ leads neuron $B$, $t_{spike, A}$ occurs before $t_{spike, B}$, so their difference $t_{spike, B} - t_{spike, A}$ is positive.\n\nThe STDP rule depends on the timing at the synapse of the postsynaptic neuron $B$. We must account for the axonal conduction delay, $d$. The presynaptic spike fired by neuron $A$ at time $t_{spike, A}$ arrives at the synapse on neuron $B$ at a later time, $t_{pre, arrival}$.\n$$t_{pre, arrival} = t_{spike, A} + d$$\nThe postsynaptic event is the firing of neuron $B$ at time $t_{post} = t_{spike, B}$.\n\nThe critical timing interval for STDP, $\\Delta t$, is defined as the time of the postsynaptic spike minus the time of the presynaptic spike's arrival.\n$$\\Delta t = t_{post} - t_{pre, arrival} = t_{spike, B} - (t_{spike, A} + d)$$\nThis can be rewritten using the somatic time difference, $\\Delta t_{soma}$:\n$$\\Delta t = (t_{spike, B} - t_{spike, A}) - d = \\Delta t_{soma} - d$$\nSubstituting the calculated value for $\\Delta t_{soma}$ and the given value for $d = 5$ ms:\n$$\\Delta t = \\frac{10}{3} \\text{ ms} - 5 \\text{ ms} = \\frac{10}{3} \\text{ ms} - \\frac{15}{3} \\text{ ms} = -\\frac{5}{3} \\text{ ms}$$\n\nThe sign of $\\Delta t$ determines whether the synapse undergoes potentiation or depression. Since $\\Delta t  0$, the postsynaptic spike at the soma occurs before the presynaptic spike arrives at the synapse. This temporal order (post-before-pre) leads to Long-Term Depression (LTD).\n\nThe STDP rule for weight change is given as:\n$$\\Delta w = \\begin{cases} A_{+} \\exp(-\\Delta t / \\tau_{+})  \\text{if } \\Delta t > 0 \\\\ -A_{-} \\exp(\\Delta t / \\tau_{-})  \\text{if } \\Delta t  0 \\end{cases}$$\nSince $\\Delta t = -5/3$ ms is negative, we use the second case (LTD):\n$$\\Delta w = -A_{-} \\exp\\left(\\frac{\\Delta t}{\\tau_{-}}\\right)$$\nThe problem provides the parameters $A_{-} = 0.005$ and $\\tau_{-} = 20$ ms. Substituting these values along with our calculated $\\Delta t$:\n$$\\Delta w = -0.005 \\times \\exp\\left(\\frac{-5/3 \\text{ ms}}{20 \\text{ ms}}\\right) = -0.005 \\times \\exp\\left(-\\frac{5}{60}\\right) = -0.005 \\times \\exp\\left(-\\frac{1}{12}\\right)$$\n\nNow we compute the numerical value.\n$$\\exp\\left(-\\frac{1}{12}\\right) \\approx 0.920040434$$\n$$\\Delta w \\approx -0.005 \\times 0.920040434 \\approx -0.00460020217$$\nThe problem asks for the answer to be rounded to four significant figures.\n$$\\Delta w \\approx -0.004600$$\nThe synapse experiences depression, and the weight is reduced by approximately $0.004600$ units per spike pair.", "answer": "$$ \\boxed{-0.004600} $$", "id": "5061378"}]}