{"hands_on_practices": [{"introduction": "At the heart of any neural circuit is the fundamental computation performed by a single neuron: integrating inputs to decide whether to fire an action potential. This exercise provides a hands-on look at this process within the lateral amygdala ($LA$), the primary site where sensory information about a conditioned stimulus ($CS$) converges. By applying a simplified linear model, you will calculate the total synaptic drive onto an $LA$ neuron and determine its output, offering a clear, quantitative glimpse into the brain's basic building blocks of information processing [@problem_id:5069610].", "problem": "In auditory fear conditioning, neurons in the Lateral Amygdala (LA) integrate convergent excitatory inputs from the medial division of the medial geniculate nucleus (MGm) and auditory cortex (ctx). As a first-order approximation consistent with experimental neurophysiology, synaptic integration can be modeled as a linear sum in which the net synaptic drive depends on the presynaptic firing rates scaled by synaptic efficacies. Let the synaptic weights be $w_{\\mathrm{MGm}}$ and $w_{\\mathrm{ctx}}$ (dimensionless efficacies), and the presynaptic firing rates be $r_{\\mathrm{MGm}}$ and $r_{\\mathrm{ctx}}$ (in Hz). The combined synaptic drive to the LA neuron is then defined as\n$$D = w_{\\mathrm{MGm}}\\, r_{\\mathrm{MGm}} + w_{\\mathrm{ctx}}\\, r_{\\mathrm{ctx}}.$$\nAssume a simplified deterministic threshold model for spike initiation in which the neuron emits a spike only if the synaptic drive equals or exceeds a threshold $D^{*}$; otherwise it does not spike. Under this model, the predicted spiking probability is $1$ when $D \\ge D^{*}$ and $0$ when $D < D^{*}$.\n\nGiven $w_{\\mathrm{MGm}} = 0.6$, $w_{\\mathrm{ctx}} = 0.4$, $r_{\\mathrm{MGm}} = 50$ Hz, $r_{\\mathrm{ctx}} = 20$ Hz, and threshold $D^{*} = 40$ (in arbitrary units, A.U.), compute $D$ and use the threshold rule above to predict the LA spiking probability. Round the computed $D$ to four significant figures and express it in A.U. Report only the predicted LA spiking probability as your final answer.", "solution": "The user has provided a problem that requires validation before a solution can be attempted.\n\n### Step 1: Extract Givens\nThe givens extracted verbatim from the problem statement are:\n- The combined synaptic drive to the LA neuron is defined as: $$D = w_{\\mathrm{MGm}}\\, r_{\\mathrm{MGm}} + w_{\\mathrm{ctx}}\\, r_{\\mathrm{ctx}}$$\n- Synaptic weights (dimensionless efficacies): $w_{\\mathrm{MGm}}$, $w_{\\mathrm{ctx}}$\n- Presynaptic firing rates (in Hz): $r_{\\mathrm{MGm}}$, $r_{\\mathrm{ctx}}$\n- A deterministic threshold model for spike initiation:\n  - Predicted spiking probability is $1$ when $D \\ge D^{*}$\n  - Predicted spiking probability is $0$ when $D < D^{*}$\n- A given spiking threshold: $D^{*}$\n- Specific values provided:\n  - $w_{\\mathrm{MGm}} = 0.6$\n  - $w_{\\mathrm{ctx}} = 0.4$\n  - $r_{\\mathrm{MGm}} = 50$ Hz\n  - $r_{\\mathrm{ctx}} = 20$ Hz\n  - $D^{*} = 40$ (in arbitrary units, A.U.)\n- The task is to compute $D$, round it to four significant figures, express it in A.U., and use the threshold rule to predict the LA spiking probability, reporting only the probability as the final answer.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n\n- **Scientifically Grounded**: The problem statement is scientifically sound. It uses a simplified, but standard and well-established, linear summation model for synaptic integration in a neuron. The context of auditory fear conditioning involving inputs from the medial geniculate nucleus (MGm) and auditory cortex (ctx) to the lateral amygdala (LA) is a cornerstone of neurobiological research on fear and learning. The deterministic threshold model is a common first-order approximation for neuronal firing.\n- **Well-Posed**: The problem is well-posed. It provides a clear formula, all necessary numerical values for the variables in the formula, and a definitive rule for determining the output. A unique solution exists and can be computed directly.\n- **Objective**: The problem is stated in precise, quantitative, and unbiased language.\n\nThe problem does not exhibit any invalidating flaws. The use of \"arbitrary units\" (A.U.) for the drive $D$ and threshold $D^{*}$ is acceptable; it establishes a self-consistent system where the units of synaptic drive are defined by the problem itself. Since the weights $w$ are dimensionless and the rates $r$ are in Hz, the resulting drive $D$ has units of Hz. The problem implies that $1 \\text{ A.U.} = 1 \\text{ Hz}$, which is a valid internal definition. The problem is deemed **valid**.\n\n### Step 3: Solution\nThe problem is valid and a solution will be provided.\n\nThe synaptic drive $D$ to the Lateral Amygdala (LA) neuron is calculated using the provided linear summation model:\n$$D = w_{\\mathrm{MGm}}\\, r_{\\mathrm{MGm}} + w_{\\mathrm{ctx}}\\, r_{\\mathrm{ctx}}$$\nThe given values are substituted into this equation:\n- $w_{\\mathrm{MGm}} = 0.6$\n- $r_{\\mathrm{MGm}} = 50$ Hz\n- $w_{\\mathrm{ctx}} = 0.4$\n- $r_{\\mathrm{ctx}} = 20$ Hz\n\nThe calculation proceeds as follows:\n$$D = (0.6)(50) + (0.4)(20)$$\n$$D = 30 + 8$$\n$$D = 38$$\nThe problem specifies that the units of drive are arbitrary units (A.U.). Therefore, the computed synaptic drive is $D = 38$ A.U. The instruction to round this value to four significant figures yields $38.00$ A.U.\n\nNext, we apply the deterministic threshold model to determine the spiking probability. The model states:\n- Spiking probability is $1$ if $D \\ge D^{*}$\n- Spiking probability is $0$ if $D < D^{*}$\n\nThe given threshold is $D^{*} = 40$ A.U. We must compare the computed drive $D$ to this threshold.\nWe have $D = 38$ A.U. and $D^{*} = 40$ A.U. The comparison is:\n$$38 < 40$$\nTherefore, the condition $D < D^{*}$ is met.\n\nAccording to the specified rule, when $D < D^{*}$, the predicted spiking probability is $0$.", "answer": "$$\\boxed{0}$$", "id": "5069610"}, {"introduction": "Learning is a dynamic process where the brain updates its expectations based on experience. This practice moves beyond a static snapshot of a neuron to model the acquisition of fear conditioning over time using the foundational Rescorla-Wagner model. You will simulate trial-by-trial learning by calculating how the associative strength, $V$, changes in response to prediction error, which is the difference between the expected and actual outcome [@problem_id:5069627]. This exercise powerfully demonstrates how a simple, error-correcting rule can generate the negatively accelerated learning curves seen in countless behavioral experiments.", "problem": "In a Pavlovian fear conditioning paradigm, a tone conditioned stimulus (CS) is paired with a footshock unconditioned stimulus (US), and synaptic changes in the basolateral amygdala (BLA) are thought to encode the associative strength. Let the associative strength after $n$ CS–US pairings be denoted by $V_{n}$, which represents the expected US intensity on the next trial. Empirical and theoretical work in associative learning indicate that learning is driven by the prediction error, defined as the difference between the delivered US magnitude and the current expectation, and uses error-correction to reduce a squared loss.\n\nStarting from the following context-appropriate base:\n- The instantaneous prediction error is $\\delta = \\lambda - V$, where $\\lambda$ is the US magnitude and $V$ is the current expectation.\n- The loss function is the instantaneous squared error $E(V) = \\tfrac{1}{2}\\,\\delta^{2} = \\tfrac{1}{2}\\,(\\lambda - V)^{2}$.\n- Synaptic updates follow standard gradient descent on $E(V)$ with learning rate $\\alpha$, so that the change in associative strength on a single pairing is $\\Delta V = -\\alpha\\,\\dfrac{dE}{dV}$.\n\n(a) Derive the trial-by-trial learning update rule for $\\Delta V$ from these assumptions. Then write the recurrence for $V_{n+1}$ in terms of $V_{n}$, $\\alpha$, and $\\lambda$.\n\n(b) Consider acquisition with constant US magnitude $\\lambda = 1$ and learning rate $\\alpha = 0.1$, starting from $V_{0} = 0$. Using the update you derived, compute $V_{1}$, $V_{2}$, and $V_{3}$ after three CS–US pairings. Express the values as exact decimals with no rounding.\n\n(c) Briefly interpret the approach of $V_{n}$ to its asymptote in terms of the prediction error and whether learning will slow down or accelerate over trials as $n$ increases.\n\nIn your final answer, present the three numerical values from part (b) in order as a single row matrix. No units are required.", "solution": "The problem statement describes the Rescorla-Wagner model of associative learning, a foundational concept in computational neuroscience and psychology. The model proposes that learning is driven by prediction error, and it can be formalized using gradient descent on a squared-error loss function. The problem is scientifically grounded, well-posed, and all necessary information for its solution is provided.\n\n(a) Derivation of the learning update rule and recurrence relation.\n\nThe problem provides the following:\nThe loss function, or instantaneous squared error, is given by $E(V) = \\frac{1}{2}(\\lambda - V)^{2}$, where $\\lambda$ is the magnitude of the unconditioned stimulus (US) and $V$ is the current associative strength, or expectation of the US.\nThe rule for updating the associative strength is given as a form of gradient descent:\n$$\n\\Delta V = -\\alpha\\,\\dfrac{dE}{dV}\n$$\nwhere $\\alpha$ is the learning rate.\n\nTo find the specific update rule, we must first compute the derivative of the loss function $E(V)$ with respect to $V$. Using the chain rule, let $u = \\lambda - V$. Then $\\frac{du}{dV} = -1$.\n$$\n\\dfrac{dE}{dV} = \\dfrac{d}{dV} \\left( \\frac{1}{2}(\\lambda - V)^{2} \\right) = \\dfrac{d}{dV} \\left( \\frac{1}{2}u^{2} \\right) = \\dfrac{dE}{du}\\dfrac{du}{dV} = (u)(-1) = -(\\lambda - V)\n$$\nSubstituting this derivative back into the expression for $\\Delta V$:\n$$\n\\Delta V = -\\alpha \\left( -(\\lambda - V) \\right) = \\alpha(\\lambda - V)\n$$\nThis is the explicit trial-by-trial learning update rule. It states that the change in associative strength is proportional to the prediction error, $\\delta = \\lambda - V$.\n\nThe associative strength after trial $n+1$, denoted $V_{n+1}$, is the sum of the strength before the trial, $V_n$, and the change that occurred during the trial, $\\Delta V_n$. The change $\\Delta V_n$ is calculated based on the conditions at the start of trial $n$:\n$$\n\\Delta V_n = \\alpha(\\lambda - V_n)\n$$\nTherefore, the recurrence relation for $V_{n+1}$ is:\n$$\nV_{n+1} = V_n + \\Delta V_n = V_n + \\alpha(\\lambda - V_n)\n$$\n\n(b) Calculation of $V_{1}$, $V_{2}$, and $V_{3}$.\n\nWe are given the initial condition $V_{0} = 0$ and the constant parameters $\\lambda = 1$ and $\\alpha = 0.1$. We use the recurrence relation derived in part (a): $V_{n+1} = V_n + 0.1(1 - V_n)$.\n\nFor trial $1$ (calculating $V_1$ from $V_0$):\n$$\nV_{1} = V_{0} + \\alpha(\\lambda - V_{0}) = 0 + 0.1(1 - 0) = 0.1\n$$\n\nFor trial $2$ (calculating $V_2$ from $V_1$):\n$$\nV_{2} = V_{1} + \\alpha(\\lambda - V_{1}) = 0.1 + 0.1(1 - 0.1) = 0.1 + 0.1(0.9) = 0.1 + 0.09 = 0.19\n$$\n\nFor trial $3$ (calculating $V_3$ from $V_2$):\n$$\nV_{3} = V_{2} + \\alpha(\\lambda - V_{2}) = 0.19 + 0.1(1 - 0.19) = 0.19 + 0.1(0.81) = 0.19 + 0.081 = 0.271\n$$\nThus, after three CS-US pairings, the associative strengths are $V_1 = 0.1$, $V_2 = 0.19$, and $V_3 = 0.271$.\n\n(c) Interpretation of the learning dynamics.\n\nThe learning process is governed by the recurrence relation $V_{n+1} = V_n + \\alpha(\\lambda - V_n)$. Learning continues as long as there is a change in associative strength, i.e., as long as $\\Delta V_n = \\alpha(\\lambda - V_n) \\neq 0$. Since the learning rate $\\alpha$ is a positive constant, learning will stop only when the prediction error term, $\\delta_n = \\lambda - V_n$, becomes zero. This occurs when $V_n = \\lambda$. Therefore, the associative strength $V_n$ approaches an asymptotic value equal to the US magnitude, $V_{\\infty} = \\lambda$.\n\nIn the initial trials, when $V_n$ is far from $\\lambda$, the prediction error $\\delta_n$ is large. For example, on the first trial, $\\delta_0 = \\lambda - V_0 = 1 - 0 = 1$, which is the maximum possible error. This large prediction error drives a correspondingly large update to the associative strength, $\\Delta V_0 = \\alpha \\delta_0 = 0.1$.\n\nAs $n$ increases, $V_n$ gets progressively closer to $\\lambda = 1$. Consequently, the prediction error $\\delta_n = \\lambda - V_n$ decreases with each trial. Since the magnitude of the update, $\\Delta V_n$, is directly proportional to the prediction error, the increments in associative strength become smaller with each successive trial. For example, $\\Delta V_0 = 0.1$, $\\Delta V_1 = 0.09$, and $\\Delta V_2 = 0.081$.\n\nThis demonstrates that learning is fastest at the beginning of acquisition when the US is most surprising and **slows down** as the associative strength approaches the true US magnitude and the US becomes fully predicted. The learning curve is negatively accelerated, showing diminishing returns with each pairing.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.1 & 0.19 & 0.271\n\\end{pmatrix}\n}\n$$", "id": "5069627"}, {"introduction": "Having explored how individual neurons compute and learn, we now zoom out to the circuit level to understand how networks of neurons control behavior. This advanced practice challenges you to build a working computational model of the amygdala's output pathway, focusing on the critical interaction between the lateral ($CeL$) and medial ($CeM$) divisions of the central amygdala. By implementing a leaky integrate-and-fire model, you will directly simulate how inhibitory neurons in the $CeL$ can gate the activity of $CeM$ output neurons, thereby controlling the expression of a conditioned fear response like freezing [@problem_id:5069617]. This exercise provides an invaluable bridge from abstract theory to the biophysical mechanisms that govern behavior.", "problem": "You are asked to formalize, simulate, and analyze a minimal deterministic network model consisting of the central amygdala lateral division (CeL) inhibitory neurons and the central amygdala medial division (CeM) output neuron to demonstrate, using a principled biophysical framework, how increased CeL inhibitory drive reduces CeM firing below a threshold associated with freezing behavior. The goal is to derive the governing equations from first principles appropriate to neurobiology and implement a numerical simulation that outputs whether the CeM firing rate is above or below a specified freezing threshold for several test cases. Use the following foundational base and model specification.\n\nFundamental base:\n- The neuron membrane is treated as a resistor-capacitor circuit. Let the membrane capacitance be $C_m$ and the membrane resistance be $R_m$. The current balance equation is\n$$\nC_m \\frac{dV(t)}{dt} = -\\frac{V(t) - V_{\\mathrm{rest}}}{R_m} + I_{\\mathrm{tot}}(t),\n$$\nwhere $V(t)$ is the membrane potential in millivolts, $V_{\\mathrm{rest}}$ is the resting potential in millivolts, and $I_{\\mathrm{tot}}(t)$ is the total input current in nanoamperes. Define the membrane time constant $ \\tau_m = R_m C_m $ and rewrite the equation as\n$$\n\\frac{dV(t)}{dt} = \\frac{-(V(t)-V_{\\mathrm{rest}}) + R_m I_{\\mathrm{tot}}(t)}{\\tau_m}.\n$$\nThis is the leaky integrate-and-fire model with Ohmic leak.\n- The inhibitory synaptic current from CeL is modeled via a gating variable $s(t)$ that evolves according to\n$$\n\\frac{ds(t)}{dt} = -\\frac{s(t)}{\\tau_{\\mathrm{syn}}} + \\sum_k \\delta(t - t_k),\n$$\nwhere $\\tau_{\\mathrm{syn}}$ is the synaptic time constant in milliseconds, $\\delta(\\cdot)$ is the Dirac delta function, and $t_k$ are inhibitory spike times from CeL. The inhibitory current is\n$$\nI_{\\mathrm{inh}}(t) = w_{\\mathrm{inh}} \\, s(t),\n$$\nwith $w_{\\mathrm{inh}}$ in nanoamperes.\n- The conditioned stimulus (CS) drives a constant excitatory current into CeM:\n$$\nI_{\\mathrm{exc}}(t) = I_{\\mathrm{CS}},\n$$\nwith $I_{\\mathrm{CS}}$ in nanoamperes.\n- The total current to CeM is $I_{\\mathrm{tot}}(t) = I_{\\mathrm{exc}}(t) - I_{\\mathrm{inh}}(t)$.\n\nCeM spiking rule:\n- When $V(t)$ crosses a threshold $V_{\\mathrm{th}}$ from below, record a spike and reset $V(t)$ to $V_{\\mathrm{reset}}$. Implement an absolute refractory period of duration $t_{\\mathrm{ref}}$ milliseconds during which $V(t)$ is held at $V_{\\mathrm{reset}}$.\n\nNumerical method:\n- Use explicit Euler integration with fixed step size $\\Delta t$ to advance $V(t)$ and $s(t)$ in time. The CeL spike train is deterministic and periodic with frequency $f_{\\mathrm{CeL}}$ in hertz, yielding spike interval $T_{\\mathrm{CeL}} = 1000/f_{\\mathrm{CeL}}$ milliseconds. When $f_{\\mathrm{CeL}} = 0$, there are no CeL spikes.\n\nBehavioral decision rule:\n- Define the CeM firing rate $r_{\\mathrm{CeM}}$ in hertz as the number of CeM spikes divided by the simulation duration in seconds. Define the freezing threshold $r_{\\mathrm{freeze}}$ in hertz. Freezing is considered engaged if and only if $r_{\\mathrm{CeM}}$ is strictly greater than $r_{\\mathrm{freeze}}$.\n\nUnits:\n- Time variables ($t$, $\\tau_m$, $\\tau_{\\mathrm{syn}}$, $t_{\\mathrm{ref}}$, simulation duration) must be in milliseconds.\n- Membrane potentials ($V$, $V_{\\mathrm{rest}}$, $V_{\\mathrm{th}}$, $V_{\\mathrm{reset}}$) must be in millivolts.\n- Currents ($I_{\\mathrm{CS}}$, $I_{\\mathrm{inh}}$, $I_{\\mathrm{tot}}$) must be in nanoamperes.\n- Resistances ($R_m$) must be in megaohms, so that $R_m I$ yields millivolts when $I$ is in nanoamperes.\n- Frequencies ($f_{\\mathrm{CeL}}$, $r_{\\mathrm{CeM}}$, $r_{\\mathrm{freeze}}$) must be in hertz.\n\nImplementation requirements:\n- Implement the specified model and compute the CeM firing rate $r_{\\mathrm{CeM}}$ for each test case listed below, then compute the boolean indicating whether freezing is engaged ($r_{\\mathrm{CeM}} > r_{\\mathrm{freeze}}$).\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\").\n\nTest suite (each case specifies parameters; use exactly these values):\n- Case 1 (happy path, moderate inhibition): $T = 1000$ ms, $\\Delta t = 0.1$ ms, $V_{\\mathrm{rest}} = -65$ mV, $V_{\\mathrm{th}} = -50$ mV, $V_{\\mathrm{reset}} = -65$ mV, $\\tau_m = 20$ ms, $R_m = 100$ MOhm, $t_{\\mathrm{ref}} = 2$ ms, $\\tau_{\\mathrm{syn}} = 10$ ms, $I_{\\mathrm{CS}} = 0.25$ nA, $w_{\\mathrm{inh}} = 0.02$ nA, $f_{\\mathrm{CeL}} = 10$ Hz, $r_{\\mathrm{freeze}} = 10$ Hz.\n- Case 2 (increased inhibition, expected suppression): same as Case 1 except $w_{\\mathrm{inh}} = 0.08$ nA and $f_{\\mathrm{CeL}} = 25$ Hz, with $r_{\\mathrm{freeze}} = 10$ Hz.\n- Case 3 (boundary at zero CeL input): same as Case 1 except $w_{\\mathrm{inh}} = 0$ nA and $f_{\\mathrm{CeL}} = 0$ Hz, with $r_{\\mathrm{freeze}} = 10$ Hz.\n\nOutput specification:\n- For each case, output a boolean indicating whether $r_{\\mathrm{CeM}} > r_{\\mathrm{freeze}}$. Aggregate the three booleans into a single line of output in the format \"[b1,b2,b3]\".", "solution": "We construct the model by starting with the resistor-capacitor description of the neuronal membrane. The fundamental current balance for the membrane potential $V(t)$ is\n$$\nC_m \\frac{dV(t)}{dt} = -\\frac{V(t) - V_{\\mathrm{rest}}}{R_m} + I_{\\mathrm{tot}}(t),\n$$\nwhere $C_m$ is membrane capacitance, $R_m$ is membrane resistance, $V_{\\mathrm{rest}}$ is resting potential, and $I_{\\mathrm{tot}}(t)$ is the sum of all external currents entering the membrane. Defining the membrane time constant $ \\tau_m = R_m C_m $, we can express the leaky integrate-and-fire dynamics as\n$$\n\\frac{dV(t)}{dt} = \\frac{-(V(t)-V_{\\mathrm{rest}}) + R_m I_{\\mathrm{tot}}(t)}{\\tau_m}.\n$$\nThis formulation uses Ohm's law in the form $V=IR$ to map input currents (in nanoamperes) through $R_m$ (in megaohms) into millivolt-equivalent drive, ensuring consistent units.\n\nWe partition the total input current to the CeM neuron into an excitatory component $I_{\\mathrm{exc}}(t)$ representing the conditioned stimulus and an inhibitory component $I_{\\mathrm{inh}}(t)$ representing the effect of CeL:\n$$\nI_{\\mathrm{tot}}(t) = I_{\\mathrm{exc}}(t) - I_{\\mathrm{inh}}(t), \\quad I_{\\mathrm{exc}}(t) = I_{\\mathrm{CS}}.\n$$\nFor the inhibitory synapse, we use a standard first-order kinetic model for the gating variable $s(t)$:\n$$\n\\frac{ds(t)}{dt} = -\\frac{s(t)}{\\tau_{\\mathrm{syn}}} + \\sum_k \\delta(t - t_k),\n$$\nwhere $\\tau_{\\mathrm{syn}}$ is the synaptic decay time constant and $t_k$ are the deterministic inhibitory spike times from CeL. Each spike increments $s(t)$ instantaneously by $1$ and $s(t)$ decays exponentially between spikes. The inhibitory current is given by\n$$\nI_{\\mathrm{inh}}(t) = w_{\\mathrm{inh}} s(t),\n$$\nwith $w_{\\mathrm{inh}}$ setting the inhibitory strength per unit $s(t)$.\n\nCeM spikes are detected when $V(t)$ crosses $V_{\\mathrm{th}}$ from below. Upon a spike, the membrane potential is reset to $V_{\\mathrm{reset}}$ and held there during an absolute refractory period $t_{\\mathrm{ref}}$. The firing rate $r_{\\mathrm{CeM}}$ is the spike count divided by the simulation duration in seconds.\n\nAlgorithmic design using explicit Euler integration:\n1. Initialize $V(0) = V_{\\mathrm{rest}}$, $s(0) = 0$, spike count $N_{\\mathrm{spk}} = 0$, and refractory timer $t_{\\mathrm{ref,rem}} = 0$.\n2. Determine CeL spike interval $T_{\\mathrm{CeL}} = 1000/f_{\\mathrm{CeL}}$ ms. If $f_{\\mathrm{CeL}} = 0$, no inhibitory spikes occur.\n3. For discrete time steps of size $\\Delta t$ from $t=0$ to $t=T$:\n   - If $t$ reaches the next CeL spike time $t_k$, increment $s \\leftarrow s + 1$ and schedule the next spike at $t_k + T_{\\mathrm{CeL}}$.\n   - Update the synaptic gating variable using\n     $$\n     s \\leftarrow s + \\left(-\\frac{s}{\\tau_{\\mathrm{syn}}}\\right) \\Delta t.\n     $$\n   - Compute $I_{\\mathrm{inh}} = w_{\\mathrm{inh}} s$ and $I_{\\mathrm{tot}} = I_{\\mathrm{CS}} - I_{\\mathrm{inh}}$.\n   - If $t_{\\mathrm{ref,rem}} > 0$, set $V \\leftarrow V_{\\mathrm{reset}}$ and decrement $t_{\\mathrm{ref,rem}} \\leftarrow t_{\\mathrm{ref,rem}} - \\Delta t$.\n   - Otherwise, update the membrane potential using\n     $$\n     V \\leftarrow V + \\frac{-(V - V_{\\mathrm{rest}}) + R_m I_{\\mathrm{tot}}}{\\tau_m} \\Delta t.\n     $$\n   - If $V \\ge V_{\\mathrm{th}}$ (crossing from below in discrete time), record a spike ($N_{\\mathrm{spk}} \\leftarrow N_{\\mathrm{spk}} + 1$), set $V \\leftarrow V_{\\mathrm{reset}}$, and set $t_{\\mathrm{ref,rem}} \\leftarrow t_{\\mathrm{ref}}$.\n4. After the loop, compute\n   $$\n   r_{\\mathrm{CeM}} = \\frac{N_{\\mathrm{spk}}}{T/1000}.\n   $$\n5. Determine whether freezing is engaged by evaluating the boolean $r_{\\mathrm{CeM}} > r_{\\mathrm{freeze}}$.\n\nScientific interpretation:\n- At steady state for a periodic inhibitory spike train with frequency $f_{\\mathrm{CeL}}$, the gating variable satisfies $s_{\\mathrm{ss}} \\approx \\tau_{\\mathrm{syn}} f_{\\mathrm{CeL}}$ (since each spike adds $1$ and $s$ decays with time constant $\\tau_{\\mathrm{syn}}$), leading to an average inhibitory current\n$$\n\\langle I_{\\mathrm{inh}} \\rangle \\approx w_{\\mathrm{inh}} \\tau_{\\mathrm{syn}} f_{\\mathrm{CeL}}.\n$$\n- Increasing either $w_{\\mathrm{inh}}$ or $f_{\\mathrm{CeL}}$ increases $\\langle I_{\\mathrm{inh}} \\rangle$, lowers the driving term $R_m I_{\\mathrm{tot}}$ in the membrane equation, reduces the time $V(t)$ spends near threshold, and therefore decreases the spike count $N_{\\mathrm{spk}}$ and rate $r_{\\mathrm{CeM}}$.\n- If the inhibitory drive is strong enough, $r_{\\mathrm{CeM}}$ can be reduced below the behavioral threshold $r_{\\mathrm{freeze}}$, predicting the absence of freezing despite the presence of the excitatory CS.\n\nThe test suite explores:\n- Case 1: Moderate inhibition with expected $r_{\\mathrm{CeM}}$ above threshold ($r_{\\mathrm{freeze}} = 10$ Hz).\n- Case 2: Increased inhibition via higher $w_{\\mathrm{inh}}$ and $f_{\\mathrm{CeL}}$, expected suppression below threshold.\n- Case 3: Zero CeL inhibition (boundary at the lower bound of inhibitory drive), yielding the maximum $r_{\\mathrm{CeM}}$ for the given $I_{\\mathrm{CS}}$.\n\nThe program computes the boolean outcomes $[b_1, b_2, b_3]$ indicating $r_{\\mathrm{CeM}} > r_{\\mathrm{freeze}}$ for each case and prints them as a single line in the specified format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate_cem_cel_case(\n    T_ms,\n    dt_ms,\n    V_rest_mV,\n    V_thresh_mV,\n    V_reset_mV,\n    tau_m_ms,\n    R_m_MOhm,\n    t_ref_ms,\n    tau_syn_ms,\n    I_CS_nA,\n    w_inh_nA,\n    f_CeL_Hz,\n    r_freeze_Hz,\n):\n    \"\"\"\n    Simulate a minimal deterministic network:\n    - CeM: leaky integrate-and-fire neuron.\n    - CeL: periodic inhibitory spike train driving a decaying synaptic gating variable s(t).\n\n    Returns: boolean indicating whether freezing is engaged (CeM rate > r_freeze_Hz).\n    \"\"\"\n    n_steps = int(T_ms / dt_ms)\n    V = V_rest_mV\n    s_inh = 0.0\n    spikes = 0\n    ref_remaining_ms = 0.0\n\n    # CeL spike scheduling\n    if f_CeL_Hz > 0.0:\n        cel_interval_ms = 1000.0 / f_CeL_Hz\n        next_cel_spike_ms = 0.0\n    else:\n        cel_interval_ms = None\n        next_cel_spike_ms = None\n\n    t_ms = 0.0\n    for _ in range(n_steps):\n        # CeL spike occurs?\n        if next_cel_spike_ms is not None and t_ms >= next_cel_spike_ms:\n            s_inh += 1.0  # instantaneous increment per inhibitory spike\n            next_cel_spike_ms += cel_interval_ms\n\n        # Synaptic gating decay (explicit Euler)\n        s_inh += (-s_inh / tau_syn_ms) * dt_ms\n\n        # Inhibitory current\n        I_inh_nA = w_inh_nA * s_inh\n\n        # Total input current to CeM\n        I_tot_nA = I_CS_nA - I_inh_nA\n\n        if ref_remaining_ms > 0.0:\n            # Absolute refractory: hold at reset\n            V = V_reset_mV\n            ref_remaining_ms = max(0.0, ref_remaining_ms - dt_ms)\n        else:\n            # Membrane update (explicit Euler)\n            dVdt = (-(V - V_rest_mV) + R_m_MOhm * I_tot_nA) / tau_m_ms\n            V += dVdt * dt_ms\n\n            # Spike condition\n            if V >= V_thresh_mV:\n                spikes += 1\n                V = V_reset_mV\n                ref_remaining_ms = t_ref_ms\n\n        t_ms += dt_ms\n\n    duration_s = T_ms / 1000.0\n    r_CeM_Hz = spikes / duration_s\n    return r_CeM_Hz > r_freeze_Hz\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, moderate inhibition\n        {\n            \"T_ms\": 1000.0,\n            \"dt_ms\": 0.1,\n            \"V_rest_mV\": -65.0,\n            \"V_thresh_mV\": -50.0,\n            \"V_reset_mV\": -65.0,\n            \"tau_m_ms\": 20.0,\n            \"R_m_MOhm\": 100.0,\n            \"t_ref_ms\": 2.0,\n            \"tau_syn_ms\": 10.0,\n            \"I_CS_nA\": 0.25,\n            \"w_inh_nA\": 0.02,\n            \"f_CeL_Hz\": 10.0,\n            \"r_freeze_Hz\": 10.0,\n        },\n        # Case 2: increased inhibition, expected suppression\n        {\n            \"T_ms\": 1000.0,\n            \"dt_ms\": 0.1,\n            \"V_rest_mV\": -65.0,\n            \"V_thresh_mV\": -50.0,\n            \"V_reset_mV\": -65.0,\n            \"tau_m_ms\": 20.0,\n            \"R_m_MOhm\": 100.0,\n            \"t_ref_ms\": 2.0,\n            \"tau_syn_ms\": 10.0,\n            \"I_CS_nA\": 0.25,\n            \"w_inh_nA\": 0.08,\n            \"f_CeL_Hz\": 25.0,\n            \"r_freeze_Hz\": 10.0,\n        },\n        # Case 3: zero CeL input (boundary)\n        {\n            \"T_ms\": 1000.0,\n            \"dt_ms\": 0.1,\n            \"V_rest_mV\": -65.0,\n            \"V_thresh_mV\": -50.0,\n            \"V_reset_mV\": -65.0,\n            \"tau_m_ms\": 20.0,\n            \"R_m_MOhm\": 100.0,\n            \"t_ref_ms\": 2.0,\n            \"tau_syn_ms\": 10.0,\n            \"I_CS_nA\": 0.25,\n            \"w_inh_nA\": 0.0,\n            \"f_CeL_Hz\": 0.0,\n            \"r_freeze_Hz\": 10.0,\n        },\n    ]\n\n    results = []\n    for params in test_cases:\n        result = simulate_cem_cel_case(**params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "5069617"}]}