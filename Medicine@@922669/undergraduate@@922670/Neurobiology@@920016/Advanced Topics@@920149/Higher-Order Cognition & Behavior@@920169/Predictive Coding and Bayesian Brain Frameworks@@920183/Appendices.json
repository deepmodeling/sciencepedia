{"hands_on_practices": [{"introduction": "A fundamental task of the brain is to make categorical judgments from ambiguous sensory information. This exercise connects the abstract framework of Bayesian inference to the classic, experimentally-grounded concepts of Signal Detection Theory (SDT). By working through this problem, you will derive the optimal decision rule for a simple perceptual task, demonstrating how quantities like sensitivity ($d'$) and decision criterion ($c$) emerge directly from Bayesian principles [@problem_id:5052174].", "problem": "A simplified cortical circuit in a hierarchical predictive coding model performs Bayesian inference to identify one of two stimulus categories in a single-trial observation. On each trial, the measurement $y$ is the population firing rate over a fixed window, and the latent stimulus category is $x \\in \\{0,1\\}$. Under the generative model, the observation is conditionally Gaussian with equal variance: $y \\mid x=i \\sim \\mathcal{N}(\\mu_{i}, \\sigma^{2})$ for $i \\in \\{0,1\\}$, with equal priors $p(x=0)=p(x=1)=\\frac{1}{2}$ and symmetric decision costs. The brain is assumed to implement the optimal Bayesian decision rule by comparing the posterior probabilities via the likelihood ratio $\\Lambda(y)=\\frac{p(y \\mid x=1)}{p(y \\mid x=0)}$.\n\nStarting from Bayes theorem and these generative assumptions, derive the optimal decision rule and show that it is a threshold rule on $y$. Then, relate this threshold rule to standard Signal Detection Theory (SDT) quantities, defining $d'$ and the SDT decision criterion $c$ as follows: $d'=\\frac{\\mu_{1}-\\mu_{0}}{\\sigma}$ and $c=\\frac{k-\\mu_{0}}{\\sigma}$, where $k$ is the decision threshold on $y$ in physical units. Finally, for a Two-Alternative Forced Choice (2AFC) task between these two categories with parameters $\\mu_{0}=10$ spikes/s, $\\mu_{1}=30$ spikes/s, and $\\sigma=8$ spikes/s, compute the numerical values of the decision threshold $k$ (expressed in spikes/s), the sensitivity $d'$, and the criterion $c$.\n\nRound your numerical answers to four significant figures. Express $k$ in spikes/s. Provide your final result as the ordered triple $(k, d', c)$.", "solution": "The problem requires the derivation of an optimal Bayesian decision rule for classifying a stimulus into one of two categories, and then the computation of associated Signal Detection Theory (SDT) quantities.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- The latent stimulus category is $x \\in \\{0,1\\}$.\n- The observation is the population firing rate $y$.\n- The generative model for the observation is a conditional Gaussian: $p(y \\mid x=i) \\sim \\mathcal{N}(\\mu_{i}, \\sigma^{2})$ for $i \\in \\{0,1\\}$.\n- The variances are equal for both categories.\n- The priors are equal: $p(x=0) = p(x=1) = \\frac{1}{2}$.\n- Decision costs are symmetric.\n- The likelihood ratio is defined as $\\Lambda(y)=\\frac{p(y \\mid x=1)}{p(y \\mid x=0)}$.\n- SDT sensitivity is defined as $d'=\\frac{\\mu_{1}-\\mu_{0}}{\\sigma}$.\n- SDT decision criterion is defined as $c=\\frac{k-\\mu_{0}}{\\sigma}$, where $k$ is the decision threshold on $y$.\n- For numerical computation: $\\mu_{0}=10$ spikes/s, $\\mu_{1}=30$ spikes/s, $\\sigma=8$ spikes/s.\n- The task is a Two-Alternative Forced Choice (2AFC) task.\n- Numerical answers must be rounded to four significant figures.\n- The final answer is the ordered triple $(k, d', c)$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in Bayesian decision theory and Signal Detection Theory, both of which are standard and fundamental frameworks in computational neuroscience and psychophysics for modeling perception and decision-making. The assumptions of Gaussian distributions and equal variance are common and form the basis of standard SDT.\n- **Well-Posed:** All necessary information is provided. The generative model, priors, cost structure (implied by \"symmetric decision costs\"), and definitions are all specified, leading to a unique optimal decision rule. The numerical parameters are provided for the final calculation.\n- **Objective:** The problem is stated in precise mathematical and scientific language, free of ambiguity or subjectivity.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with the solution.\n\n### Derivation of the Optimal Decision Rule\n\nThe goal is to find a decision rule that minimizes the probability of error, given the symmetric costs. This is achieved by choosing the stimulus category $x$ that has the maximum a posteriori probability (MAP) given the observation $y$. The decision rule is: choose category $x=1$ if $p(x=1|y) > p(x=0|y)$, and choose category $x=0$ otherwise.\n\nUsing Bayes' theorem, the posterior probability for each category is:\n$$p(x=i|y) = \\frac{p(y|x=i)p(x=i)}{p(y)}$$\nwhere $p(y) = \\sum_{j=0}^{1} p(y|x=j)p(x=j)$ is the marginal probability of the observation, also known as the evidence.\n\nThe decision rule $p(x=1|y) > p(x=0|y)$ can be rewritten as:\n$$\\frac{p(y|x=1)p(x=1)}{p(y)} > \\frac{p(y|x=0)p(x=0)}{p(y)}$$\nSince $p(y)$ is a positive common factor, it can be cancelled:\n$$p(y|x=1)p(x=1) > p(y|x=0)p(x=0)$$\nThis can be expressed in terms of the likelihood ratio $\\Lambda(y)$:\n$$\\frac{p(y|x=1)}{p(y|x=0)} > \\frac{p(x=0)}{p(x=1)}$$\nGiven the equal priors $p(x=0) = p(x=1) = \\frac{1}{2}$, the ratio of priors is $\\frac{p(x=0)}{p(x=1)} = 1$. The decision rule simplifies to choosing $x=1$ if $\\Lambda(y) > 1$.\n\nNow, we substitute the expressions for the Gaussian likelihoods. The probability density function for $y$ given $x=i$ is:\n$$p(y|x=i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu_i)^2}{2\\sigma^2}\\right)$$\nThe likelihood ratio is therefore:\n$$\\Lambda(y) = \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu_1)^2}{2\\sigma^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu_0)^2}{2\\sigma^2}\\right)} = \\exp\\left(-\\frac{(y-\\mu_1)^2}{2\\sigma^2} + \\frac{(y-\\mu_0)^2}{2\\sigma^2}\\right)$$\nThe decision rule is $\\Lambda(y) > 1$. Since the natural logarithm is a monotonic function, we can take the log of both sides without changing the inequality:\n$$\\ln(\\Lambda(y)) > \\ln(1) \\implies \\ln(\\Lambda(y)) > 0$$\n$$\\frac{(y-\\mu_0)^2 - (y-\\mu_1)^2}{2\\sigma^2} > 0$$\nSince $2\\sigma^2 > 0$, we can multiply by it:\n$$(y-\\mu_0)^2 - (y-\\mu_1)^2 > 0$$\nExpanding the squared terms:\n$$(y^2 - 2y\\mu_0 + \\mu_0^2) - (y^2 - 2y\\mu_1 + \\mu_1^2) > 0$$\n$$y^2 - 2y\\mu_0 + \\mu_0^2 - y^2 + 2y\\mu_1 - \\mu_1^2 > 0$$\n$$2y\\mu_1 - 2y\\mu_0 > \\mu_1^2 - \\mu_0^2$$\n$$2y(\\mu_1 - \\mu_0) > (\\mu_1 - \\mu_0)(\\mu_1 + \\mu_0)$$\nAssuming $\\mu_1 \\neq \\mu_0$, and specifically $\\mu_1 > \\mu_0$ as given by the numerical values, we can divide by the positive term $2(\\mu_1 - \\mu_0)$:\n$$y > \\frac{\\mu_1 + \\mu_0}{2}$$\nThis demonstrates that the optimal decision rule is a threshold rule on the observation $y$. The system should decide stimulus category $x=1$ if $y > k$ and $x=0$ if $y < k$, where the decision threshold $k$ is:\n$$k = \\frac{\\mu_0 + \\mu_1}{2}$$\n\n### Computation of SDT Quantities\n\nWe are given the numerical values: $\\mu_{0}=10$ spikes/s, $\\mu_{1}=30$ spikes/s, and $\\sigma=8$ spikes/s.\n\n1.  **Decision Threshold, $k$**:\n    Using the derived expression for the optimal threshold:\n    $$k = \\frac{10 + 30}{2} = \\frac{40}{2} = 20$$\n    The units are spikes/s. Rounding to four significant figures, $k = 20.00$ spikes/s.\n\n2.  **Sensitivity, $d'$**:\n    Using the definition provided in the problem:\n    $$d' = \\frac{\\mu_1 - \\mu_0}{\\sigma} = \\frac{30 - 10}{8} = \\frac{20}{8} = 2.5$$\n    This is a dimensionless quantity. Rounding to four significant figures, $d' = 2.500$.\n\n3.  **Criterion, $c$**:\n    Using the definition provided in the problem and our calculated value for $k$:\n    $$c = \\frac{k - \\mu_0}{\\sigma} = \\frac{20 - 10}{8} = \\frac{10}{8} = 1.25$$\n    This is also a dimensionless quantity. Rounding to four significant figures, $c = 1.250$.\n\nThe optimal Bayesian observer in this scenario is unbiased, placing the criterion exactly midway between the two stimulus distribution means. This results in a criterion value $c = d'/2$, which is confirmed by our calculation: $1.250 = 2.500/2$.\n\nThe final ordered triple $(k, d', c)$ is $(20.00, 2.500, 1.250)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n20.00 & 2.500 & 1.250\n\\end{pmatrix}\n}\n$$", "id": "5052174"}, {"introduction": "Perception is not a one-shot event; the brain continuously updates its model of the world based on an incoming stream of sensory data. This practice delves into the core mechanism of dynamic belief updating that underpins many predictive coding theories. You will derive the celebrated Kalman filter equations from the first principles of Bayesian inference, revealing how prediction errors are optimally weighted by their respective precisions to refine our estimates of a changing world [@problem_id:5052165].", "problem": "A core hypothesis in predictive coding and Bayesian brain frameworks is that cortical circuits encode beliefs about latent causes of sensory input by performing approximate Bayesian inference in a generative model. Consider the linear-Gaussian generative model\n$$x_t = A x_{t-1} + \\omega_t,\\quad \\omega_t \\sim \\mathcal{N}(0,Q),$$\n$$y_t = C x_t + \\eta_t,\\quad \\eta_t \\sim \\mathcal{N}(0,R),$$\nwith an initial prior $p(x_0)=\\mathcal{N}(\\mu_0,P_0)$. Starting from Bayes' rule and properties of multivariate normal distributions, and without assuming any pre-existing filtering formulas, derive from first principles the one-step-ahead predictive distribution $p(x_t\\mid y_{1:t-1})$ and the posterior distribution $p(x_t\\mid y_{1:t})$ in closed form. Your derivation should proceed by (i) forming the predictive prior via marginalization over $x_{t-1}$ and (ii) performing the observation update by multiplying the predictive prior with the likelihood and completing the square in the exponent to extract the posterior mean and covariance. Interpret the observation update in terms of prediction error weighting by observation precision as used in predictive coding.\n\nThen, specialize to the scalar case where all variables are real-valued, and compute the posterior mean at time $t=1$ given the parameters\n$$A=\\frac{4}{5},\\quad C=\\frac{6}{5},\\quad Q=\\frac{1}{2},\\quad R=\\frac{3}{10},\\quad \\mu_0=1,\\quad P_0=\\frac{3}{2},\\quad y_1=2.$$\nExpress your final numerical result for the posterior mean at $t=1$ as an exact fraction. Do not include any units.", "solution": "The problem statement is valid. It presents a standard but non-trivial derivation in the context of state-space models and Bayesian inference, which is a cornerstone of modern computational neuroscience theories like predictive coding. The problem is self-contained, scientifically grounded, and well-posed. We proceed with the solution.\n\nThe problem asks for a derivation of the recursive Bayesian update for a linear-Gaussian state-space model, which is the mathematical foundation of the Kalman filter. We will derive this from first principles as requested, in two steps: a prediction step and an update step.\n\nLet the posterior distribution at time $t-1$ be given by $p(x_{t-1}\\mid y_{1:t-1})=\\mathcal{N}(x_{t-1};\\mu_{t-1|t-1}, P_{t-1|t-1})$. For the initial step at $t=1$, this corresponds to the given prior $p(x_0) = \\mathcal{N}(x_0;\\mu_0, P_0)$.\n\n**Part 1: Prediction Step (Derivation of the Predictive Prior)**\n\nThe first step is to compute the one-step-ahead predictive distribution, $p(x_t\\mid y_{1:t-1})$, also known as the predictive prior for time $t$. This distribution is obtained by marginalizing the joint distribution $p(x_t, x_{t-1}\\mid y_{1:t-1})$ over the previous state $x_{t-1}$:\n$$p(x_t\\mid y_{1:t-1}) = \\int p(x_t, x_{t-1}\\mid y_{1:t-1}) \\, dx_{t-1}$$\nUsing the product rule of probability, we can write the joint distribution as:\n$$p(x_t, x_{t-1}\\mid y_{1:t-1}) = p(x_t\\mid x_{t-1}, y_{1:t-1})p(x_{t-1}\\mid y_{1:t-1})$$\nThe generative model's state equation, $x_t = A x_{t-1} + \\omega_t$, implies that $x_t$ is conditionally independent of past observations $y_{1:t-1}$ given the immediately preceding state $x_{t-1}$. This is the Markov property. Thus, $p(x_t\\mid x_{t-1}, y_{1:t-1}) = p(x_t\\mid x_{t-1})$. From the state equation, this distribution is Gaussian:\n$$p(x_t\\mid x_{t-1}) = \\mathcal{N}(x_t; A x_{t-1}, Q)$$\nWe are convolving two Gaussian distributions: $p(x_t\\mid x_{t-1})$ and $p(x_{t-1}\\mid y_{1:t-1})$. The result is another Gaussian. The random variable $x_t$ is a linear transformation of the Gaussian variable $x_{t-1}$ plus an independent Gaussian noise term $\\omega_t$. The mean and covariance of $x_t$ (conditioned on $y_{1:t-1}$) can be found using the law of total expectation and total variance.\n\nThe mean of the predictive distribution, which we denote $\\mu_{t|t-1}$, is:\n$$\\mu_{t|t-1} = E[x_t\\mid y_{1:t-1}] = E[A x_{t-1} + \\omega_t \\mid y_{1:t-1}] = A E[x_{t-1}\\mid y_{1:t-1}] + E[\\omega_t] = A \\mu_{t-1|t-1} + 0$$\nSo, $\\mu_{t|t-1} = A \\mu_{t-1|t-1}$.\n\nThe covariance of the predictive distribution, denoted $P_{t|t-1}$, is:\n$$P_{t|t-1} = \\text{Cov}(x_t\\mid y_{1:t-1}) = \\text{Cov}(A x_{t-1} + \\omega_t \\mid y_{1:t-1})$$\nSince $x_{t-1}$ (given $y_{1:t-1}$) and $\\omega_t$ are independent, the covariance of their sum is the sum of their covariances:\n$$P_{t|t-1} = \\text{Cov}(A x_{t-1}\\mid y_{1:t-1}) + \\text{Cov}(\\omega_t) = A \\, \\text{Cov}(x_{t-1}\\mid y_{1:t-1}) \\, A^T + Q$$\nSo, $P_{t|t-1} = A P_{t-1|t-1} A^T + Q$.\n\nTherefore, the one-step-ahead predictive distribution is:\n$$p(x_t\\mid y_{1:t-1})_ = \\mathcal{N}(x_t; \\mu_{t|t-1}, P_{t|t-1})$$\nwith mean $\\mu_{t|t-1} = A\\mu_{t-1|t-1}$ and covariance $P_{t|t-1} = AP_{t-1|t-1}A^T+Q$.\n\n**Part 2: Update Step (Derivation of the Posterior)**\n\nThe second step is to update our belief about $x_t$ after observing $y_t$. We use Bayes' rule to find the posterior distribution $p(x_t\\mid y_{1:t}) = p(x_t\\mid y_t, y_{1:t-1})$:\n$$p(x_t\\mid y_{1:t}) \\propto p(y_t\\mid x_t, y_{1:t-1}) p(x_t\\mid y_{1:t-1})$$\nThe observation $y_t$ depends only on the current state $x_t$, so $p(y_t\\mid x_t, y_{1:t-1}) = p(y_t\\mid x_t)$. This is the likelihood, given by the observation equation as $\\mathcal{N}(y_t; C x_t, R)$. The prior is the predictive distribution derived in Part 1, $\\mathcal{N}(x_t; \\mu_{t|t-1}, P_{t|t-1})$.\n\nThe posterior is the product of two Gaussians, which is an unnormalized Gaussian. We analyze its form by examining the logarithm:\n$$\\ln p(x_t\\mid y_{1:t}) = \\ln p(y_t\\mid x_t) + \\ln p(x_t\\mid y_{1:t-1}) + \\text{const.}$$\n$$= -\\frac{1}{2}(y_t - C x_t)^T R^{-1} (y_t - C x_t) - \\frac{1}{2}(x_t - \\mu_{t|t-1})^T P_{t|t-1}^{-1} (x_t - \\mu_{t|t-1}) + \\text{const.}$$\nWe expand the quadratic forms and collect terms involving $x_t$ to identify the mean and covariance of the posterior. A general multivariate normal distribution $\\mathcal{N}(x; \\mu, P)$ has an exponent of the form $-\\frac{1}{2}x^T P^{-1}x + x^T P^{-1}\\mu - \\frac{1}{2}\\mu^T P^{-1}\\mu$.\n\nExpanding the exponent gives:\n$$\\text{exp-term} = -\\frac{1}{2}(x_t^T C^T R^{-1} C x_t - 2x_t^T C^T R^{-1} y_t) - \\frac{1}{2}(x_t^T P_{t|t-1}^{-1} x_t - 2x_t^T P_{t|t-1}^{-1} \\mu_{t|t-1}) + \\dots$$\nwhere `...` contains terms not dependent on $x_t$.\n\nThe quadratic term in $x_t$ is $-\\frac{1}{2}x_t^T(C^T R^{-1} C + P_{t|t-1}^{-1})x_t$. This tells us that the inverse covariance (precision) of the posterior distribution $p(x_t \\mid y_{1:t})=\\mathcal{N}(x_t; \\mu_{t|t}, P_{t|t})$ is:\n$$P_{t|t}^{-1} = P_{t|t-1}^{-1} + C^T R^{-1} C$$\n\nThe linear term in $x_t$ is $x_t^T(C^T R^{-1} y_t + P_{t|t-1}^{-1} \\mu_{t|t-1})$. Comparing this to the general form $x_t^T P_{t|t}^{-1} \\mu_{t|t}$, we find:\n$$P_{t|t}^{-1} \\mu_{t|t} = P_{t|t-1}^{-1} \\mu_{t|t-1} + C^T R^{-1} y_t$$\nMultiplying by $P_{t|t}$ gives the posterior mean:\n$$\\mu_{t|t} = P_{t|t} (P_{t|t-1}^{-1} \\mu_{t|t-1} + C^T R^{-1} y_t)$$\nTo arrive at the form used in predictive coding, we manipulate this expression. From the posterior precision equation, we have $P_{t|t-1}^{-1} = P_{t|t}^{-1} - C^T R^{-1} C$. Substituting this into the equation for $\\mu_{t|t}$:\n$$P_{t|t}^{-1} \\mu_{t|t} = (P_{t|t}^{-1} - C^T R^{-1} C) \\mu_{t|t-1} + C^T R^{-1} y_t$$\n$$P_{t|t}^{-1} \\mu_{t|t} = P_{t|t}^{-1} \\mu_{t|t-1} - C^T R^{-1} C \\mu_{t|t-1} + C^T R^{-1} y_t$$\n$$P_{t|t}^{-1} \\mu_{t|t} = P_{t|t}^{-1} \\mu_{t|t-1} + C^T R^{-1} (y_t - C \\mu_{t|t-1})$$\nMultiplying from the left by $P_{t|t}$ yields:\n$$\\mu_{t|t} = \\mu_{t|t-1} + P_{t|t} C^T R^{-1} (y_t - C \\mu_{t|t-1})$$\nDefining the Kalman gain as $K_t = P_{t|t} C^T R^{-1}$, we get the final update equations:\n$$p(x_t\\mid y_{1:t}) = \\mathcal{N}(x_t; \\mu_{t|t}, P_{t|t})$$\n$$\\mu_{t|t} = \\mu_{t|t-1} + K_t(y_t - C \\mu_{t|t-1})$$\n$$P_{t|t} = (P_{t|t-1}^{-1} + C^T R^{-1} C)^{-1}$$\nThis completes the derivation from first principles.\n\n**Interpretation in Predictive Coding**\n\nThe posterior mean update equation, $\\mu_{t|t} = \\mu_{t|t-1} + K_t(y_t - C \\mu_{t|t-1})$, has a clear interpretation in the context of predictive coding.\n1.  **Prediction:** $\\mu_{t|t-1}$ is the prior belief or prediction about the state $x_t$ before observing $y_t$. The term $C\\mu_{t|t-1}$ is the predicted sensory input based on this belief.\n2.  **Prediction Error:** The term $\\delta_t = y_t - C \\mu_{t|t-1}$ is the prediction error, i.e., the discrepancy between the actual sensory observation $y_t$ and the predicted observation $C \\mu_{t|t-1}$.\n3.  **Precision-Weighting:** The Kalman gain $K_t$ weights this prediction error. The gain can be shown to be equivalent to $K_t = P_{t|t-1} C^T (C P_{t|t-1} C^T + R)^{-1}$. It optimally balances the uncertainty of the prior belief (encoded in $P_{t|t-1}$) and the uncertainty of the sensory data (encoded in $R$). A high observation noise (large $R$) leads to a small gain, meaning the surprising observation is down-weighted. A high prior uncertainty (large $P_{t|t-1}$) leads to a large gain, meaning the new data is trusted more.\nThe update mechanism is thus one of correcting the prior belief in proportion to the prediction error, with the proportionality constant (the gain) determined by the relative precisions (inverse variances) of the prior and the likelihood. This process of belief updating via precision-weighted prediction error is the central computational principle of predictive coding frameworks.\n\n**Numerical Calculation**\n\nWe are asked to compute the scalar posterior mean $\\mu_{1|1}$ with parameters:\n$A=\\frac{4}{5}$, $C=\\frac{6}{5}$, $Q=\\frac{1}{2}$, $R=\\frac{3}{10}$, $\\mu_0=1$, $P_0=\\frac{3}{2}$, $y_1=2$.\n\nFirst, we perform the prediction step for $t=1$, starting from the prior at $t=0$: $\\mu_{0|0} = \\mu_0 = 1$ and $P_{0|0} = P_0 = \\frac{3}{2}$.\n\nPredictive mean $\\mu_{1|0}$:\n$$\\mu_{1|0} = A \\mu_{0|0} = \\frac{4}{5} \\times 1 = \\frac{4}{5}$$\n\nPredictive variance $P_{1|0}$:\n$$P_{1|0} = A^2 P_0 + Q = \\left(\\frac{4}{5}\\right)^2 \\left(\\frac{3}{2}\\right) + \\frac{1}{2} = \\frac{16}{25} \\times \\frac{3}{2} + \\frac{1}{2} = \\frac{24}{25} + \\frac{1}{2} = \\frac{48}{50} + \\frac{25}{50} = \\frac{73}{50}$$\n\nNext, we perform the update step for $t=1$. We need to compute the Kalman gain $K_1$ and the prediction error.\n\nThe Kalman gain $K_1$ for the scalar case is:\n$$K_1 = \\frac{P_{1|0} C}{C^2 P_{1|0} + R}$$\nNumerator:\n$$P_{1|0} C = \\frac{73}{50} \\times \\frac{6}{5} = \\frac{438}{250} = \\frac{219}{125}$$\nDenominator:\n$$C^2 P_{1|0} + R = \\left(\\frac{6}{5}\\right)^2 \\left(\\frac{73}{50}\\right) + \\frac{3}{10} = \\frac{36}{25} \\times \\frac{73}{50} + \\frac{3}{10} = \\frac{2628}{1250} + \\frac{3}{10} = \\frac{1314}{625} + \\frac{3}{10}$$\n$$= \\frac{2628}{1250} + \\frac{375}{1250} = \\frac{3003}{1250}$$\nSo, the gain is:\n$$K_1 = \\frac{\\frac{219}{125}}{\\frac{3003}{1250}} = \\frac{219}{125} \\times \\frac{1250}{3003} = 219 \\times \\frac{10}{3003} = \\frac{2190}{3003}$$\nWe simplify the fraction. $219 = 3 \\times 73$ and $3003 = 3 \\times 1001 = 3 \\times 7 \\times 11 \\times 13$.\n$$K_1 = \\frac{3 \\times 73 \\times 10}{3 \\times 1001} = \\frac{730}{1001}$$\n\nThe prediction error is:\n$$y_1 - C \\mu_{1|0} = 2 - \\left(\\frac{6}{5}\\right)\\left(\\frac{4}{5}\\right) = 2 - \\frac{24}{25} = \\frac{50}{25} - \\frac{24}{25} = \\frac{26}{25}$$\n\nFinally, we compute the posterior mean $\\mu_{1|1}$:\n$$\\mu_{1|1} = \\mu_{1|0} + K_1 (y_1 - C \\mu_{1|0}) = \\frac{4}{5} + \\left(\\frac{730}{1001}\\right) \\left(\\frac{26}{25}\\right)$$\nWe simplify the product term:\n$$K_1 (y_1 - C \\mu_{1|0}) = \\frac{730}{1001} \\times \\frac{26}{25} = \\frac{73 \\times 10}{7 \\times 11 \\times 13} \\times \\frac{2 \\times 13}{25} = \\frac{73 \\times 2 \\times 5}{7 \\times 11 \\times 13} \\times \\frac{2 \\times 13}{5 \\times 5}$$\n$$= \\frac{73 \\times 2 \\times 2}{7 \\times 11 \\times 5} = \\frac{292}{385}$$\nNow we add this correction to the prior mean:\n$$\\mu_{1|1} = \\frac{4}{5} + \\frac{292}{385}$$\nThe common denominator is $385$. $385 = 5 \\times 77$.\n$$\\mu_{1|1} = \\frac{4 \\times 77}{5 \\times 77} + \\frac{292}{385} = \\frac{308}{385} + \\frac{292}{385} = \\frac{600}{385}$$\nSimplifying the final fraction by dividing the numerator and denominator by their greatest common divisor, which is $5$:\n$$\\mu_{1|1} = \\frac{600 \\div 5}{385 \\div 5} = \\frac{120}{77}$$\nThe numbers $120$ and $77$ are coprime ($120=2^3 \\cdot 3 \\cdot 5$, $77=7 \\cdot 11$).", "answer": "$$\\boxed{\\frac{120}{77}}$$", "id": "5052165"}, {"introduction": "Neural systems face a fundamental design challenge: they must be sensitive enough to build rich, accurate models of the world, yet stable enough to avoid being misled by noisy or unreliable sensory input. This computational exercise allows you to explore this critical trade-off between coding efficiency and robustness. By deriving and implementing expressions for mutual information and noise sensitivity, you will gain a quantitative understanding of how the brain navigates this balance by adjusting the relative precision of its internal predictions and sensory evidence [@problem_id:5052097].", "problem": "Consider a single-neuron Predictive Coding (PC) model under the Bayesian Brain (BB) framework. The latent sensory cause $x$ is modeled with a Gaussian prior $x \\sim \\mathcal{N}(\\mu_0, \\sigma_p^2)$, and the measurement $y$ is generated by a linear-Gaussian likelihood $y = x + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma_l^2)$. Define the prior precision as $\\Pi_p = 1/\\sigma_p^2$ and the likelihood precision as $\\Pi_l = 1/\\sigma_l^2$, both strictly positive. In predictive coding, the neuron minimizes precision-weighted prediction errors to estimate $x$.\n\nYour tasks:\n\n1. Starting from Bayes' theorem and the Gaussian identities, derive the posterior distribution $p(x \\mid y)$ for the specified linear-Gaussian model. Then, starting from the principle that PC minimizes precision-weighted prediction errors, derive the fixed-point estimate $\\hat{x}$ at steady state in terms of $\\Pi_p$, $\\Pi_l$, $\\mu_0$, and $y$.\n\n2. Define coding efficiency as the Mutual Information (MI) between $x$ and $y$ in nats. Derive an expression for $\\mathrm{MI}(x; y)$ in terms of $\\Pi_p$ and $\\Pi_l$ only, without using any extraneous constants, and without assuming any special values of $\\mu_0$.\n\n3. Define robustness to sensory noise as the sensitivity of the estimator $\\hat{x}$ to additive measurement noise, quantified as the coefficient multiplying $\\epsilon$ in $\\hat{x}$ after substituting $y = x + \\epsilon$. Derive this sensitivity $S$ in terms of $\\Pi_p$ and $\\Pi_l$ only.\n\n4. Implement a complete, runnable program that computes, for each test case listed below, two quantities: the coding efficiency in nats and the robustness $S$. Each computed quantity must be rounded to $6$ decimal places. The final output must be a single line containing a comma-separated list of lists, where each inner list is $[\\mathrm{MI}, S]$, in the exact specified order.\n\nUse the following test suite of precision pairs $(\\Pi_p, \\Pi_l)$, which is chosen to probe a balanced case, strong prior, strong likelihood, and near-degenerate edge cases while maintaining strict positivity:\n\n- Case A (balanced): $(\\Pi_p, \\Pi_l) = (1, 1)$.\n- Case B (strong prior): $(\\Pi_p, \\Pi_l) = (100, 1)$.\n- Case C (strong likelihood): $(\\Pi_p, \\Pi_l) = (1, 100)$.\n- Case D (weak prior): $(\\Pi_p, \\Pi_l) = (10^{-6}, 1)$.\n- Case E (weak likelihood): $(\\Pi_p, \\Pi_l) = (1, 10^{-6})$.\n\nAll quantities are dimensionless. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with inner lists in the order of the test suite above (e.g., $[[\\mathrm{MI}_A,S_A],[\\mathrm{MI}_B,S_B],\\dots]$).", "solution": "The problem is scientifically grounded, well-posed, and objective. It presents a canonical problem in computational neuroscience, providing all necessary definitions and constraints to derive a unique and meaningful solution. The tasks require the application of fundamental principles from Bayesian statistics, information theory, and optimization, which are central to the study of predictive coding and the Bayesian brain.\n\n**1. Derivation of the Posterior and the Predictive Coding Fixed-Point Estimate**\n\nFirst, we derive the posterior distribution $p(x \\mid y)$ using Bayes' theorem. The theorem states that the posterior is proportional to the product of the likelihood and the prior: $p(x \\mid y) \\propto p(y \\mid x)p(x)$.\n\nThe prior distribution for the latent cause $x$ is given as a Gaussian:\n$$p(x) = \\mathcal{N}(x; \\mu_0, \\sigma_p^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_p^2}} \\exp\\left(-\\frac{(x - \\mu_0)^2}{2\\sigma_p^2}\\right)$$\nThe likelihood of the measurement $y$ given $x$ is also Gaussian, derived from the model $y = x + \\epsilon$ with $\\epsilon \\sim \\mathcal{N}(0, \\sigma_l^2)$:\n$$p(y \\mid x) = \\mathcal{N}(y; x, \\sigma_l^2) = \\frac{1}{\\sqrt{2\\pi\\sigma_l^2}} \\exp\\left(-\\frac{(y - x)^2}{2\\sigma_l^2}\\right)$$\nThe posterior probability is therefore proportional to the product of these two Gaussians. As the product of two Gaussian functions is another Gaussian, we can find its parameters by focusing on the terms in the exponent of the resulting distribution, ignoring constant normalization factors:\n$$\\log p(x \\mid y) \\propto -\\frac{(x - \\mu_0)^2}{2\\sigma_p^2} - \\frac{(y - x)^2}{2\\sigma_l^2}$$\nUsing the precision definitions, $\\Pi_p = 1/\\sigma_p^2$ and $\\Pi_l = 1/\\sigma_l^2$, the expression becomes:\n$$\\log p(x \\mid y) \\propto -\\frac{1}{2}\\left(\\Pi_p(x - \\mu_0)^2 + \\Pi_l(y - x)^2\\right)$$\nTo find the mean and variance of the posterior Gaussian, we expand the quadratic terms and complete the square for $x$:\n$$-\\frac{1}{2}\\left(\\Pi_p(x^2 - 2x\\mu_0 + \\mu_0^2) + \\Pi_l(y^2 - 2yx + x^2)\\right)$$\n$$-\\frac{1}{2}\\left( (\\Pi_p + \\Pi_l)x^2 - 2(\\Pi_p\\mu_0 + \\Pi_ly)x + \\text{const} \\right)$$\nThis quadratic form in $x$ corresponds to a Gaussian distribution $\\mathcal{N}(x; \\mu_{post}, \\sigma_{post}^2)$ whose log-probability has the form $-\\frac{(x-\\mu_{post})^2}{2\\sigma_{post}^2} = -\\frac{1}{2\\sigma_{post}^2}(x^2 - 2x\\mu_{post} + \\mu_{post}^2)$.\nBy comparing the coefficients of the $x^2$ term, we identify the posterior precision $\\Pi_{post} = 1/\\sigma_{post}^2$:\n$$\\Pi_{post} = \\Pi_p + \\Pi_l$$\nBy comparing the coefficients of the $x$ term, we find the posterior mean $\\mu_{post}$:\n$$\\Pi_{post}\\mu_{post} = \\Pi_p\\mu_0 + \\Pi_ly \\implies \\mu_{post} = \\frac{\\Pi_p\\mu_0 + \\Pi_ly}{\\Pi_p + \\Pi_l}$$\nThus, the posterior distribution is:\n$$p(x \\mid y) = \\mathcal{N}\\left(x; \\frac{\\Pi_p\\mu_0 + \\Pi_ly}{\\Pi_p + \\Pi_l}, \\frac{1}{\\Pi_p + \\Pi_l}\\right)$$\n\nNext, we derive the fixed-point estimate $\\hat{x}$ under the predictive coding framework. PC posits that the brain minimizes a cost function corresponding to the sum of precision-weighted squared prediction errors. For this model, the errors are the deviation of the estimate $\\hat{x}$ from the prior mean $\\mu_0$ and the deviation of the sensory prediction $\\hat{x}$ from the actual sensory input $y$. The cost function $L(\\hat{x})$ is:\n$$L(\\hat{x}) = \\frac{1}{2}\\Pi_p(\\hat{x} - \\mu_0)^2 + \\frac{1}{2}\\Pi_l(y - \\hat{x})^2$$\nTo find the optimal estimate $\\hat{x}$ that minimizes this cost, we take the derivative of $L(\\hat{x})$ with respect to $\\hat{x}$ and set it to zero, which defines the fixed point of the system's dynamics:\n$$\\frac{dL}{d\\hat{x}} = \\Pi_p(\\hat{x} - \\mu_0) - \\Pi_l(y - \\hat{x}) = 0$$\n$$\\Pi_p\\hat{x} - \\Pi_p\\mu_0 - \\Pi_ly + \\Pi_l\\hat{x} = 0$$\n$$\\hat{x}(\\Pi_p + \\Pi_l) = \\Pi_p\\mu_0 + \\Pi_ly$$\n$$\\hat{x} = \\frac{\\Pi_p\\mu_0 + \\Pi_ly}{\\Pi_p + \\Pi_l}$$\nThis fixed-point estimate $\\hat{x}$ is identical to the posterior mean $\\mu_{post}$. This demonstrates the equivalence between minimizing precision-weighted prediction errors in PC and performing optimal Bayesian inference for this linear-Gaussian model. The estimate $\\hat{x}$ is a precision-weighted average of the prior mean and the sensory evidence.\n\n**2. Derivation of Coding Efficiency (Mutual Information)**\n\nCoding efficiency is defined as the Mutual Information $\\mathrm{MI}(x; y)$. We use the relationship $\\mathrm{MI}(x; y) = H(x) - H(x \\mid y)$, where $H$ denotes differential entropy.\nThe entropy of a one-dimensional Gaussian variable $z \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is $H(z) = \\frac{1}{2}\\log(2\\pi e \\sigma^2)$.\nThe entropy of the prior distribution $p(x) \\sim \\mathcal{N}(\\mu_0, \\sigma_p^2)$ is:\n$$H(x) = \\frac{1}{2}\\log(2\\pi e \\sigma_p^2) = \\frac{1}{2}\\log\\left(\\frac{2\\pi e}{\\Pi_p}\\right)$$\nThe conditional entropy $H(x \\mid y)$ is the entropy of the posterior distribution $p(x \\mid y)$. From our previous derivation, the posterior variance is $\\sigma_{post}^2 = 1/(\\Pi_p + \\Pi_l)$. The entropy of the posterior is therefore:\n$$H(x \\mid y) = \\frac{1}{2}\\log(2\\pi e \\sigma_{post}^2) = \\frac{1}{2}\\log\\left(\\frac{2\\pi e}{\\Pi_p + \\Pi_l}\\right)$$\nThe mutual information is the difference between these two entropies:\n$$\\mathrm{MI}(x; y) = H(x) - H(x \\mid y) = \\frac{1}{2}\\log\\left(\\frac{2\\pi e}{\\Pi_p}\\right) - \\frac{1}{2}\\log\\left(\\frac{2\\pi e}{\\Pi_p + \\Pi_l}\\right)$$\nUsing the logarithm property $\\log(a) - \\log(b) = \\log(a/b)$:\n$$\\mathrm{MI}(x; y) = \\frac{1}{2}\\log\\left(\\frac{2\\pi e / \\Pi_p}{2\\pi e / (\\Pi_p + \\Pi_l)}\\right) = \\frac{1}{2}\\log\\left(\\frac{\\Pi_p + \\Pi_l}{\\Pi_p}\\right)$$\nThe final expression for coding efficiency in nats, which depends only on the precisions, is:\n$$\\mathrm{MI}(x; y) = \\frac{1}{2}\\log\\left(1 + \\frac{\\Pi_l}{\\Pi_p}\\right)$$\n\n**3. Derivation of Robustness to Sensory Noise**\n\nRobustness is defined as the sensitivity $S$ of the estimator $\\hat{x}$ to the additive measurement noise $\\epsilon$, where $y = x + \\epsilon$. We find this by substituting the expression for $y$ into the equation for $\\hat{x}$:\n$$\\hat{x} = \\frac{\\Pi_p\\mu_0 + \\Pi_l y}{\\Pi_p + \\Pi_l} = \\frac{\\Pi_p\\mu_0 + \\Pi_l (x + \\epsilon)}{\\Pi_p + \\Pi_l}$$\nWe can separate the terms to isolate the contribution of the noise term $\\epsilon$:\n$$\\hat{x} = \\frac{\\Pi_p\\mu_0 + \\Pi_l x}{\\Pi_p + \\Pi_l} + \\left(\\frac{\\Pi_l}{\\Pi_p + \\Pi_l}\\right)\\epsilon$$\nThe sensitivity $S$ is the coefficient multiplying the noise term $\\epsilon$. Therefore:\n$$S = \\frac{\\Pi_l}{\\Pi_p + \\Pi_l}$$\nThis value represents the gain applied to new sensory information. A high likelihood precision $\\Pi_l$ relative to the prior precision $\\Pi_p$ leads to a high sensitivity $S$, meaning the estimate is strongly influenced by the (potentially noisy) measurement. Conversely, a strong prior (high $\\Pi_p$) reduces $S$, making the estimate more robust to sensory noise by relying more on prior beliefs.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes coding efficiency (MI) and robustness (S) for a single-neuron\n    Predictive Coding model based on a set of precision pairs.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple (Pi_p, Pi_l).\n    test_cases = [\n        (1.0, 1.0),            # Case A (balanced)\n        (100.0, 1.0),          # Case B (strong prior)\n        (1.0, 100.0),          # Case C (strong likelihood)\n        (1e-6, 1.0),           # Case D (weak prior)\n        (1.0, 1e-6),           # Case E (weak likelihood)\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        pi_p, pi_l = case\n        \n        # 1. Calculate Coding Efficiency (Mutual Information)\n        # MI = 0.5 * log(1 + Pi_l / Pi_p)\n        # Using np.log for the natural logarithm (for units of nats).\n        # This formula is numerically stable even for very small pi_p.\n        mutual_information = 0.5 * np.log(1 + pi_l / pi_p)\n        \n        # 2. Calculate Robustness (Sensitivity to noise)\n        # S = Pi_l / (Pi_p + Pi_l)\n        sensitivity = pi_l / (pi_p + pi_l)\n        \n        # 3. Format the results for the current case.\n        # The problem requires rounding to 6 decimal places and a specific\n        # string format for each inner list without extra spaces.\n        # e.g., \"[MI,S]\"\n        # Using f-string formatting '{:.6f}' ensures 6 decimal places.\n        formatted_result = f\"[{mutual_information:.6f},{sensitivity:.6f}]\"\n        results.append(formatted_result)\n\n    # Final print statement must produce a single line in the exact required format.\n    # The format is a comma-separated list of the formatted inner lists,\n    # all enclosed in a single pair of square brackets.\n    # e.g., [[MI_A,S_A],[MI_B,S_B],...]\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "5052097"}]}